
[00:00:00.000 --> 00:00:06.400]   Coming up next, it's this week in tech with Ben Parr, Robert Scoble, Brian Alvey on myself, Jason Calicannis,
[00:00:06.400 --> 00:00:13.100]   where we will talk about Facebook, Tesla, self-driving cars, Twitter being sold to Google or somebody else,
[00:00:13.100 --> 00:00:15.800]   and Snapchats, Snap classes.
[00:00:15.800 --> 00:00:20.300]   Also, we'll see pictures of Robert Scoble in the shower. Stick with us.
[00:00:20.300 --> 00:00:25.400]   Netcast, you love.
[00:00:25.400 --> 00:00:27.500]   From people you trust.
[00:00:27.500 --> 00:00:32.500]   This is Twitter.
[00:00:32.500 --> 00:00:40.000]   Bandwidth for this week in tech is provided by CashFly at C-A-C-H-E-F-L-Y dot com.
[00:00:40.000 --> 00:00:54.000]   This is this week in tech, episode number 581 recorded September 25th, 2016.
[00:00:54.000 --> 00:00:56.500]   You can pay to see it all.
[00:00:57.000 --> 00:01:04.500]   This week in tech is brought to you by Automatic, the small adapter that turns your clunker into a smarter connected car.
[00:01:04.500 --> 00:01:09.500]   For more information on their brand new automatic pro adapter, visit automatic.com/twit
[00:01:09.500 --> 00:01:15.000]   and enter the limited time offer code TWIT for $20 off their newest device.
[00:01:15.000 --> 00:01:24.000]   And by E-Roe, why settle for just a Wi-Fi router when you can have a brilliant, hyper-fast, super-simple Wi-Fi system?
[00:01:24.000 --> 00:01:29.000]   No more buffering, no more dead zones, finally Wi-Fi, then works!
[00:01:29.000 --> 00:01:35.500]   For free overnight shipping visit E-Roe.com and at checkout, select overnight shipping and enter the code TWIT.
[00:01:35.500 --> 00:01:39.000]   And by go-to meeting.
[00:01:39.000 --> 00:01:42.000]   Why just phone conference when you can go high tech?
[00:01:42.000 --> 00:01:45.000]   Better meeting start with go-to meeting.
[00:01:45.000 --> 00:01:47.000]   HD video means you'll never miss a thing.
[00:01:47.000 --> 00:01:49.000]   Screen sharing keeps everyone on task.
[00:01:49.000 --> 00:01:50.500]   Don't phone it in.
[00:01:50.500 --> 00:01:52.000]   Go to meeting.
[00:01:52.000 --> 00:01:55.000]   Start your free 30-day trial at go-to meeting.com.
[00:01:55.000 --> 00:01:57.000]   And by...
[00:01:57.000 --> 00:02:01.500]   Gazelle, the online marketplace for buying and selling used gadgets.
[00:02:01.500 --> 00:02:06.500]   Shop from a variety of certified pre-owned electronics or trade one in for cash.
[00:02:06.500 --> 00:02:11.500]   Give new life to a used device, visit gazelle.com today.
[00:02:11.500 --> 00:02:17.000]   Hey everybody, welcome to another episode of This Week in Tech.
[00:02:17.000 --> 00:02:21.500]   I'm not Leo LaPorte, I'm Jason Calicana, sitting in for Leo.
[00:02:21.500 --> 00:02:25.500]   Who is taking a well-deserved vacation with me this week?
[00:02:25.500 --> 00:02:30.500]   Legends of Tech including Robert Scoble back on This Week in Tech.
[00:02:30.500 --> 00:02:31.500]   Welcome back to the program.
[00:02:31.500 --> 00:02:33.500]   Yeah, it's an honor to be here.
[00:02:33.500 --> 00:02:35.500]   You have been traveling around the world.
[00:02:35.500 --> 00:02:36.500]   Yeah.
[00:02:36.500 --> 00:02:37.500]   Stops in.
[00:02:37.500 --> 00:02:41.500]   In the last three weeks I've been in China, Brazil, Denmark.
[00:02:41.500 --> 00:02:44.500]   By the way, I go home in between these places.
[00:02:44.500 --> 00:02:45.500]   Oh my god.
[00:02:45.500 --> 00:02:48.500]   And Canada and Germany.
[00:02:48.500 --> 00:02:49.500]   Wow.
[00:02:49.500 --> 00:02:53.500]   And you've seen a lot of VR stuff and you've got a lot of information about what's going down at Google and Apple.
[00:02:53.500 --> 00:02:54.500]   We'll be getting to that in a minute.
[00:02:54.500 --> 00:02:55.500]   Ben Parr is with us.
[00:02:55.500 --> 00:02:57.500]   You've been on the program many times.
[00:02:57.500 --> 00:02:58.500]   You already know who.
[00:02:58.500 --> 00:02:59.500]   Hi everyone.
[00:02:59.500 --> 00:03:00.500]   I'm glad to be back.
[00:03:00.500 --> 00:03:07.500]   And my partner with Web Logs Inc, the co-founder of Engadget, and now doing clip-as-o-d.
[00:03:07.500 --> 00:03:08.500]   You're doing a secret project.
[00:03:08.500 --> 00:03:09.500]   I have an angel investor in it.
[00:03:09.500 --> 00:03:10.500]   Clip-as-o-d's.
[00:03:10.500 --> 00:03:11.500]   How do you get to that?
[00:03:11.500 --> 00:03:12.500]   Clip-as-o-d's.com?
[00:03:12.500 --> 00:03:13.500]   Clip-as-o-d.
[00:03:13.500 --> 00:03:14.500]   Go to www.clip-as-o-d.com.
[00:03:14.500 --> 00:03:15.500]   Clip-as-o-d.
[00:03:15.500 --> 00:03:16.500]   We got it.
[00:03:16.500 --> 00:03:17.500]   Yeah.
[00:03:17.500 --> 00:03:18.500]   Nobody knows what it is yet?
[00:03:18.500 --> 00:03:19.500]   Where's your little information website?
[00:03:19.500 --> 00:03:20.500]   That was actually a video.
[00:03:20.500 --> 00:03:21.500]   Oh, okay.
[00:03:21.500 --> 00:03:22.500]   Great.
[00:03:22.500 --> 00:03:23.500]   From a little launch conference.
[00:03:23.500 --> 00:03:24.500]   So you guys can check that out.
[00:03:24.500 --> 00:03:25.500]   A little plug there.
[00:03:25.500 --> 00:03:26.500]   And Brian, of course, was the co-founder of Engadget.
[00:03:26.500 --> 00:03:30.500]   It's been a huge week in the news and we're going to get right to it.
[00:03:30.500 --> 00:03:33.500]   Apple, of course, has been leading things off.
[00:03:33.500 --> 00:03:36.500]   And the iPhone 7, I got one.
[00:03:36.500 --> 00:03:38.500]   Robert, you've got yours?
[00:03:38.500 --> 00:03:41.500]   I got it still in the box because I haven't even set it up.
[00:03:41.500 --> 00:03:42.500]   The unboxing.
[00:03:42.500 --> 00:03:44.500]   It's basically the life of Robert Scobble.
[00:03:44.500 --> 00:03:45.500]   People just send you everything.
[00:03:45.500 --> 00:03:46.500]   No.
[00:03:46.500 --> 00:03:47.500]   Stuff you got.
[00:03:47.500 --> 00:03:48.500]   Apple, I know.
[00:03:48.500 --> 00:03:51.500]   Listen, do you think for the other three?
[00:03:51.500 --> 00:03:55.500]   Apple, if you tell me something about Apple VR, they're like Scobble, we don't want you
[00:03:55.500 --> 00:03:56.500]   using our product.
[00:03:56.500 --> 00:03:57.500]   Definitely.
[00:03:57.500 --> 00:04:00.500]   Do you think Walt Mossberg got free product?
[00:04:00.500 --> 00:04:01.500]   Does anybody get free product?
[00:04:01.500 --> 00:04:02.500]   No.
[00:04:02.500 --> 00:04:03.500]   Yeah.
[00:04:03.500 --> 00:04:04.500]   There's a few that get review units.
[00:04:04.500 --> 00:04:07.500]   But they have to send it back.
[00:04:07.500 --> 00:04:11.860]   You know, there's the ones that do send it back like Walt does, right?
[00:04:11.860 --> 00:04:15.500]   And there's a recode or have rules against keeping review product.
[00:04:15.500 --> 00:04:17.500]   And then there's people who keep theirs.
[00:04:17.500 --> 00:04:20.100]   But yeah, there's only a few.
[00:04:20.100 --> 00:04:21.700]   But you just basically get everything.
[00:04:21.700 --> 00:04:23.700]   Everybody sends you everything because if you review it.
[00:04:23.700 --> 00:04:25.500]   No, I stand in line and get in by it.
[00:04:25.500 --> 00:04:26.500]   The Apple.
[00:04:26.500 --> 00:04:27.500]   But for everything else, you get it all.
[00:04:27.500 --> 00:04:28.500]   No, I don't get it for free.
[00:04:28.500 --> 00:04:29.500]   Lots of us.
[00:04:29.500 --> 00:04:31.500]   It's the last time you bought an Android phone.
[00:04:31.500 --> 00:04:32.500]   Why?
[00:04:32.500 --> 00:04:33.500]   Exactly.
[00:04:33.500 --> 00:04:39.500]   So, I mean Huawei brought me to China to meet with their executive team and I've been playing
[00:04:39.500 --> 00:04:40.500]   with their phones.
[00:04:40.500 --> 00:04:41.500]   They're behind Apple.
[00:04:41.500 --> 00:04:43.500]   So let's get right to it.
[00:04:43.500 --> 00:04:46.500]   Let's talk first about the car project.
[00:04:46.500 --> 00:04:51.500]   Obviously, people were reading about Project Titan for the past couple of years.
[00:04:51.500 --> 00:04:54.500]   Actually, they hit somewhere around a thousand employees.
[00:04:54.500 --> 00:04:56.500]   It was reported.
[00:04:56.500 --> 00:05:00.500]   And then this week, Apple eyeing luxury car maker McLaren.
[00:05:00.500 --> 00:05:03.500]   If you don't know McLaren, it's a couple of thousand people.
[00:05:03.500 --> 00:05:08.500]   I think they make about 500 million pounds a year and they make, of course, 300 thousand
[00:05:08.500 --> 00:05:12.500]   dollar and 1.5 million dollar sports cars.
[00:05:12.500 --> 00:05:15.500]   They do do carbon fiber and a bunch of other materials.
[00:05:15.500 --> 00:05:17.500]   Apple obviously has said nothing.
[00:05:17.500 --> 00:05:22.500]   McLaren has denied it, which has obviously proved that it's obviously well underway.
[00:05:22.500 --> 00:05:24.500]   And they want to hire a price.
[00:05:24.500 --> 00:05:29.500]   What does this mean in terms of the Apple car?
[00:05:29.500 --> 00:05:34.500]   My best friend is one of the 12 guys who built the iPhone and his brother still works at
[00:05:34.500 --> 00:05:35.500]   Apple.
[00:05:35.500 --> 00:05:39.500]   And this is, when you get Apple people together, this is what we argue about incessantly.
[00:05:39.500 --> 00:05:40.500]   Are they building a car?
[00:05:40.500 --> 00:05:41.500]   Are they doing something else?
[00:05:41.500 --> 00:05:46.500]   But think about what a car, let's go 10 years, 15 years in the future.
[00:05:46.500 --> 00:05:49.500]   First of all, we're not going to buy a car, 15 years out.
[00:05:49.500 --> 00:05:50.500]   You're going to get it.
[00:05:50.500 --> 00:05:51.500]   No car ownership.
[00:05:51.500 --> 00:05:52.500]   You'll be just time sharing.
[00:05:52.500 --> 00:05:57.500]   Unless you just want an antique or a race car or something like that, a car to just be,
[00:05:57.500 --> 00:05:59.500]   you know, if you're a rich person, sure.
[00:05:59.500 --> 00:06:03.500]   Normal people are going to get their car delivered off of Uber.
[00:06:03.500 --> 00:06:07.500]   Because if you have a self-driving car, it's going to be way cheaper than owning your own
[00:06:07.500 --> 00:06:08.500]   car and better.
[00:06:08.500 --> 00:06:10.500]   And it's always going to be up to date.
[00:06:10.500 --> 00:06:17.500]   But think about, I like to think about Elon Musk.
[00:06:17.500 --> 00:06:22.500]   And I give him $1,000 in my money to buy the Tesla 3, right?
[00:06:22.500 --> 00:06:24.500]   So 400,000 other people.
[00:06:24.500 --> 00:06:28.500]   The largest Kickstarter in history, if you think about it, if the cars wind up being
[00:06:28.500 --> 00:06:32.500]   $45,000 each, you're talking about close to $20 billion Kickstarter.
[00:06:32.500 --> 00:06:35.500]   Now, what do we really want in a car?
[00:06:35.500 --> 00:06:38.500]   I've seen the F-35 fighter jet.
[00:06:38.500 --> 00:06:40.500]   It costs $1 billion.
[00:06:40.500 --> 00:06:42.500]   And I've talked to the pilots about it.
[00:06:42.500 --> 00:06:47.500]   And they said, "We'll never lose to an F-16, partly because I can see you and you can't
[00:06:47.500 --> 00:06:48.500]   see me."
[00:06:48.500 --> 00:06:52.500]   They're wearing augmented reality glasses as a pilot.
[00:06:52.500 --> 00:06:54.500]   And I want the same thing in my car.
[00:06:54.500 --> 00:06:56.500]   I don't want to see the sides of the car.
[00:06:56.500 --> 00:06:59.500]   And BMW and OGG already demonstrated this.
[00:06:59.500 --> 00:07:01.500]   Put cameras along the ridge of the car.
[00:07:01.500 --> 00:07:02.500]   And let me see.
[00:07:02.500 --> 00:07:05.500]   So if you put -- I've seen this video.
[00:07:05.500 --> 00:07:07.500]   It's on the internet 10 years ago.
[00:07:07.500 --> 00:07:09.500]   Somebody had done it in China as a proof of concept.
[00:07:09.500 --> 00:07:15.500]   They put cameras in the front of a car sort of like underneath the engine to see the road.
[00:07:15.500 --> 00:07:18.500]   Then they put screens where the floorboards were.
[00:07:18.500 --> 00:07:22.500]   And so when you look down, you have this incredible vertigo that, "Oh, my God, my feet are about
[00:07:22.500 --> 00:07:24.500]   to hit the ground and rip off."
[00:07:24.500 --> 00:07:25.500]   But you could see through it.
[00:07:25.500 --> 00:07:29.500]   So you're saying the ability to see with goggles, everything around you.
[00:07:29.500 --> 00:07:35.500]   Not only think about what Elon is doing, he's putting sensors in the car that help it
[00:07:35.500 --> 00:07:37.500]   self-driving, right?
[00:07:37.500 --> 00:07:40.500]   Front-facing radar, for instance.
[00:07:40.500 --> 00:07:44.500]   Dual cameras that do depth maps and all sorts of stuff.
[00:07:44.500 --> 00:07:50.500]   Why can't I see that data visualized in my glasses so that I can see through fog.
[00:07:50.500 --> 00:07:51.500]   I can see --
[00:07:51.500 --> 00:07:52.500]   All this though becomes --
[00:07:52.500 --> 00:07:55.500]   Threats to me in the car coming, right?
[00:07:55.500 --> 00:07:57.500]   Even if I'm manually driving.
[00:07:57.500 --> 00:08:00.500]   Brian, this all becomes moot when you have self-driving though.
[00:08:00.500 --> 00:08:04.500]   I think what he's describing is like a daredevil for race cars.
[00:08:04.500 --> 00:08:08.500]   You can see through a clammy, because if you think of the sensors that they're putting on these
[00:08:08.500 --> 00:08:10.500]   things, even the, was it Pittsburgh, they had those tests?
[00:08:10.500 --> 00:08:11.500]   Yeah.
[00:08:11.500 --> 00:08:13.500]   And half of the stuff isn't really visual.
[00:08:13.500 --> 00:08:17.500]   It's this radar stuff to see what's coming and descends all these threats.
[00:08:17.500 --> 00:08:19.500]   So it doesn't matter what the weather is, it doesn't matter if it's the night time.
[00:08:19.500 --> 00:08:20.500]   It's just pretty amazing.
[00:08:20.500 --> 00:08:25.500]   I want to bring that back to the part of what we're talking about Apple and why they're even
[00:08:25.500 --> 00:08:26.500]   thinking about this.
[00:08:26.500 --> 00:08:30.500]   It feels like Apple's been rebooting the car project in multiple different ways.
[00:08:30.500 --> 00:08:34.500]   So this is part of the Apple process, but never usually so publicly.
[00:08:34.500 --> 00:08:39.500]   Like the idea that acquisitions with leak would not have happened five years ago.
[00:08:39.500 --> 00:08:40.500]   Mass firings.
[00:08:40.500 --> 00:08:41.500]   Mass firings.
[00:08:41.500 --> 00:08:42.500]   And now it happens.
[00:08:42.500 --> 00:08:44.500]   And the style of acquisitions has certainly changed.
[00:08:44.500 --> 00:08:49.500]   Like when I was editor of Mashable, I think I wrote about two acquisitions, none of them were more than 30 million.
[00:08:49.500 --> 00:08:51.500]   And now you're talking about multiple multi-billion dollar acquisitions.
[00:08:51.500 --> 00:08:52.500]   But McLaren acquisition would be --
[00:08:52.500 --> 00:08:53.500]   At a bunch of two hundred.
[00:08:53.500 --> 00:08:54.500]   A couple of billion, two, three, four million.
[00:08:54.500 --> 00:08:56.500]   It would be the biggest.
[00:08:56.500 --> 00:08:59.500]   The first one obviously being beats.
[00:08:59.500 --> 00:09:04.500]   But this I think shows if they do buy this, that they might be willing to be a house of
[00:09:04.500 --> 00:09:07.500]   brands as opposed to the branded house.
[00:09:07.500 --> 00:09:13.500]   In that Apple would never let somebody else make something that has to be made here.
[00:09:13.500 --> 00:09:18.500]   But with Steve Gone, maybe Tim Cook's like, we could do what Facebook did, which is have
[00:09:18.500 --> 00:09:21.500]   Instagram, WhatsApp, and Facebook.
[00:09:21.500 --> 00:09:23.500]   Or Google has YouTube.
[00:09:23.500 --> 00:09:28.500]   Here's where I think Tim is going.
[00:09:28.500 --> 00:09:31.500]   He knows mixed reality glasses are coming.
[00:09:31.500 --> 00:09:38.500]   There's nine companies working on them, including Magic Leap, which got $1.3 billion without having a customer or a product.
[00:09:38.500 --> 00:09:46.500]   Microsoft has HoloLens cooking, and it's an amazing product, even though it's too big and too expensive for normal people.
[00:09:46.500 --> 00:09:47.500]   But we know this is coming.
[00:09:47.500 --> 00:09:48.500]   Sometime in our future.
[00:09:48.500 --> 00:09:49.500]   Is it two years?
[00:09:49.500 --> 00:09:51.500]   Mixed reality, augmented reality.
[00:09:51.500 --> 00:09:52.500]   Not virtual.
[00:09:52.500 --> 00:09:56.500]   You're going to see stuff on the table walking around these glasses, right?
[00:09:56.500 --> 00:10:03.500]   And Apple hired many, many people in this industry, including buying the company that invented it called PrimeSense.
[00:10:03.500 --> 00:10:05.500]   They make a 3D sensor.
[00:10:05.500 --> 00:10:13.500]   Google's bringing out a competitor to this in a month or in a few days on October 4th, the Tango sensor.
[00:10:13.500 --> 00:10:20.500]   And that's going to enable all sorts of new things on our face to sense the world and put interface objects on top of the world.
[00:10:20.500 --> 00:10:23.500]   It's a really deep shift in terms of user interface.
[00:10:23.500 --> 00:10:28.500]   And every time there is a deep shift in user interface, we call them paradigm shifts or something like that.
[00:10:28.500 --> 00:10:30.500]   My book calls them transformations.
[00:10:30.500 --> 00:10:32.500]   Big companies go away.
[00:10:32.500 --> 00:10:36.500]   When we went from DOS to Windows, Borland and WordPerfect went away.
[00:10:36.500 --> 00:10:39.500]   When we went from Windows to Touch on the phone.
[00:10:39.500 --> 00:10:40.500]   Blackberry.
[00:10:40.500 --> 00:10:42.500]   Blackberry and Nokia went away.
[00:10:42.500 --> 00:10:42.500]   Yep.
[00:10:42.500 --> 00:10:44.500]   People lose big.
[00:10:44.500 --> 00:10:46.500]   Who loses big when these glasses come out?
[00:10:46.500 --> 00:10:49.500]   And who's going to win augmented mixed reality?
[00:10:49.500 --> 00:10:52.500]   We had to pick one company, two companies.
[00:10:52.500 --> 00:10:54.500]   This is the big question.
[00:10:54.500 --> 00:10:55.500]   Yeah.
[00:10:55.500 --> 00:10:57.500]   Tim Cook knows what's coming.
[00:10:57.500 --> 00:11:00.500]   He's bought 13 or 15 companies to make these.
[00:11:00.500 --> 00:11:02.500]   So they're going to...
[00:11:02.500 --> 00:11:03.500]   Why is Apple...
[00:11:03.500 --> 00:11:04.500]   If he messes up...
[00:11:04.500 --> 00:11:07.500]   In other words, he has the recipe on the table.
[00:11:07.500 --> 00:11:11.500]   So if he messes up augmented reality, it could be Apple that goes away.
[00:11:11.500 --> 00:11:12.500]   No, not Apple.
[00:11:12.500 --> 00:11:15.500]   Because I think they have so much money they're not going away soon.
[00:11:15.500 --> 00:11:16.500]   It would take a long time.
[00:11:16.500 --> 00:11:17.500]   It would take a couple of misses.
[00:11:17.500 --> 00:11:18.500]   Yeah.
[00:11:18.500 --> 00:11:19.500]   Tim Cook's gone.
[00:11:19.500 --> 00:11:20.500]   Oh, Tim Cook's gone, if you mess with him.
[00:11:20.500 --> 00:11:21.500]   Tim Cook's...
[00:11:21.500 --> 00:11:26.500]   And here's how I think Tim has going to announce the iPhone 8 next year.
[00:11:26.500 --> 00:11:28.500]   September 2017.
[00:11:28.500 --> 00:11:30.500]   We're going to be sitting there.
[00:11:30.500 --> 00:11:32.500]   All three of us are all four of us.
[00:11:32.500 --> 00:11:34.500]   And the lights are going to go down.
[00:11:34.500 --> 00:11:36.500]   The music's going to go down.
[00:11:36.500 --> 00:11:40.500]   And there's going to be three quotes in white upon the projection screens.
[00:11:40.500 --> 00:11:42.500]   Somebody like Walt Mossberg saying, "Apple's..."
[00:11:42.500 --> 00:11:44.500]   Go on and again.
[00:11:44.500 --> 00:11:46.500]   No, Apple's innovation is dead.
[00:11:46.500 --> 00:11:47.500]   Right.
[00:11:47.500 --> 00:11:50.500]   And New York Times says Apple's boring again.
[00:11:50.500 --> 00:11:52.500]   And USA Today says something else.
[00:11:52.500 --> 00:11:53.500]   There's lots of quotes.
[00:11:53.500 --> 00:11:54.500]   I've said some of these quotes.
[00:11:54.500 --> 00:11:55.500]   Yeah.
[00:11:55.500 --> 00:12:02.500]   Fred Wilson, who's the co-founder of Wired, not Fred Wilson, Fred Davis, says that he's tired
[00:12:02.500 --> 00:12:03.500]   of Apple.
[00:12:03.500 --> 00:12:04.500]   Right.
[00:12:04.500 --> 00:12:05.500]   There's plenty of people who are saying this.
[00:12:05.500 --> 00:12:08.500]   So imagine those three quotes go up.
[00:12:08.500 --> 00:12:15.500]   And then Tim Cook walks out and says, "There are many in this community who think I haven't
[00:12:15.500 --> 00:12:16.500]   been doing my job for the last five years."
[00:12:16.500 --> 00:12:17.500]   Right.
[00:12:17.500 --> 00:12:23.100]   There's many in this community who think I lost Steve Jobs' playbook, even though he personally
[00:12:23.100 --> 00:12:24.500]   handed it to me.
[00:12:24.500 --> 00:12:25.500]   Right.
[00:12:25.500 --> 00:12:31.500]   And in this line he's going to say, or to you, he's going to say, "In the next 60 minutes,
[00:12:31.500 --> 00:12:36.500]   you're going to see more innovation from Apple than it has ever delivered in the past 40
[00:12:36.500 --> 00:12:38.500]   years, which is coming."
[00:12:38.500 --> 00:12:39.500]   You think so?
[00:12:39.500 --> 00:12:42.500]   I'm not sure if it's next year or the next year after that.
[00:12:42.500 --> 00:12:46.500]   There is so much new stuff coming that he could say.
[00:12:46.500 --> 00:12:48.500]   Well, I mean the car.
[00:12:48.500 --> 00:12:49.500]   iPhone 8, right?
[00:12:49.500 --> 00:12:53.500]   And iPhone 8 already has an edge-to-edge screen, which has 30% more pixels.
[00:12:53.500 --> 00:12:55.500]   He'll say, "Why do you need that virtual reality?"
[00:12:55.500 --> 00:12:56.500]   Yes.
[00:12:56.500 --> 00:13:00.100]   Then he'll turn the phone over and he goes, "You know this company, Microsoft?
[00:13:00.100 --> 00:13:02.420]   They have this product called HoloLens.
[00:13:02.420 --> 00:13:06.620]   That came from the Xbox team, the Connect Sensor.
[00:13:06.620 --> 00:13:08.500]   Where did the Connect Sensor come from?
[00:13:08.500 --> 00:13:09.500]   Yeah.
[00:13:09.500 --> 00:13:10.500]   PrimeSense.
[00:13:10.500 --> 00:13:11.500]   Right.
[00:13:11.500 --> 00:13:15.500]   And he's going to turn the phone over and over and over.
[00:13:15.500 --> 00:13:17.500]   He's going to bring out new things.
[00:13:17.500 --> 00:13:19.500]   Artificial intelligence, augmented reality.
[00:13:19.500 --> 00:13:20.500]   Blah, blah, blah.
[00:13:20.500 --> 00:13:22.500]   And it's going to be these classes.
[00:13:22.500 --> 00:13:24.500]   So what is Elon Musk going to do with glasses?
[00:13:24.500 --> 00:13:25.500]   That's what I'm wondering.
[00:13:25.500 --> 00:13:26.500]   Yeah.
[00:13:26.500 --> 00:13:27.500]   So what do you do?
[00:13:27.500 --> 00:13:29.500]   Because they're going to shift about the same time as I get my Model 3.
[00:13:29.500 --> 00:13:30.500]   Ben, what do you think?
[00:13:30.500 --> 00:13:37.500]   Is Apple so far behind now that they won't be able to catch up in the next few minutes?
[00:13:37.500 --> 00:13:42.860]   Apple so far behind now that they won't be able to catch up in augmented reality, virtual
[00:13:42.860 --> 00:13:43.860]   reality.
[00:13:43.860 --> 00:13:54.540]   Right now, just so people can recap, you have Oculus, Magic Leap, Sony, HTC, Google, Microsoft,
[00:13:54.540 --> 00:13:56.940]   all with major products in market.
[00:13:56.940 --> 00:13:57.940]   They're not.
[00:13:57.940 --> 00:13:58.940]   Magic Leap's not a market.
[00:13:58.940 --> 00:14:00.460]   That same Apple with tablet to buy back.
[00:14:00.460 --> 00:14:01.460]   I guess so.
[00:14:01.460 --> 00:14:02.460]   You know?
[00:14:02.460 --> 00:14:05.860]   Apple is not behind for how Apple does it.
[00:14:05.860 --> 00:14:11.820]   And I make this a very strong argument of how Apple's process is, is never to be first.
[00:14:11.820 --> 00:14:12.820]   Right.
[00:14:12.820 --> 00:14:13.820]   They will wait a couple of years.
[00:14:13.820 --> 00:14:14.820]   That's fine.
[00:14:14.820 --> 00:14:15.820]   Let the market develop.
[00:14:15.820 --> 00:14:18.500]   Honestly, the VR market is still not that big yet.
[00:14:18.500 --> 00:14:20.700]   They're still not super accessible.
[00:14:20.700 --> 00:14:22.580]   You're only starting to see- Too expensive.
[00:14:22.580 --> 00:14:23.580]   Too expensive.
[00:14:23.580 --> 00:14:24.580]   Too nerdy.
[00:14:24.580 --> 00:14:27.740]   Like, especially the high-end stuff, you have to buy a computer and you have to-
[00:14:27.740 --> 00:14:28.740]   And that's what you want.
[00:14:28.740 --> 00:14:29.740]   No.
[00:14:29.740 --> 00:14:30.740]   And Apple wants to be like- And Apple wants to be like-
[00:14:30.740 --> 00:14:31.740]   And Apple wants to be like- And Apple wants to be like-
[00:14:31.740 --> 00:14:33.740]   There's four problems with mobile-based VR.
[00:14:33.740 --> 00:14:35.640]   Six degrees of freedom is one.
[00:14:35.640 --> 00:14:39.820]   When you go- When you get a Vive and HTC Vive like I have- You have one in your house yet?
[00:14:39.820 --> 00:14:40.820]   I don't have a mask.
[00:14:40.820 --> 00:14:41.820]   I have one.
[00:14:41.820 --> 00:14:42.820]   You have one in your house.
[00:14:42.820 --> 00:14:45.300]   We can play- We can play Frisbee with each other, right?
[00:14:45.300 --> 00:14:46.300]   Over the internet.
[00:14:46.300 --> 00:14:47.540]   We can throw basketballs together.
[00:14:47.540 --> 00:14:48.540]   We can shoot each other.
[00:14:48.540 --> 00:14:50.420]   We can do our tree together.
[00:14:50.420 --> 00:14:51.660]   Infinite things we can do.
[00:14:51.660 --> 00:14:53.140]   Ski jumping is coming in December.
[00:14:53.140 --> 00:14:54.220]   Blah, blah, blah.
[00:14:54.220 --> 00:14:55.220]   That's what you want.
[00:14:55.220 --> 00:14:57.780]   You want the ability to play with other people over the internet.
[00:14:57.780 --> 00:15:00.740]   Using your hands, using your face, using your body.
[00:15:00.740 --> 00:15:02.100]   You can't do that with mobile.
[00:15:02.100 --> 00:15:03.100]   No.
[00:15:03.100 --> 00:15:04.100]   And it's coming.
[00:15:04.100 --> 00:15:05.100]   Yeah.
[00:15:05.100 --> 00:15:09.440]   It's going to be cheap because you already have a super computer in your-
[00:15:09.440 --> 00:15:13.360]   Yeah, I mean, and Apple realizes this and they understand that and they're building for
[00:15:13.360 --> 00:15:15.520]   that that they don't need to be first to market.
[00:15:15.520 --> 00:15:17.800]   They just need to be best at market, you know?
[00:15:17.800 --> 00:15:21.640]   It didn't matter that people put out 15 different kinds of tablets before.
[00:15:21.640 --> 00:15:24.960]   The counterpoint would be the Apple Watch has been completely underwhelming.
[00:15:24.960 --> 00:15:25.960]   Is anybody here wearing one?
[00:15:25.960 --> 00:15:26.960]   Nope.
[00:15:26.960 --> 00:15:28.460]   Does anyone here- Has anyone here bought one?
[00:15:28.460 --> 00:15:29.460]   Yeah.
[00:15:29.460 --> 00:15:30.460]   I bought one.
[00:15:30.460 --> 00:15:31.460]   You bought one?
[00:15:31.460 --> 00:15:32.460]   No, it's never bought one.
[00:15:32.460 --> 00:15:33.460]   It's the two out of four of us bought it.
[00:15:33.460 --> 00:15:34.460]   We don't wear it.
[00:15:34.460 --> 00:15:37.540]   Still not as good as my Fitbit or equal.
[00:15:37.540 --> 00:15:39.700]   That's a lackluster product launch.
[00:15:39.700 --> 00:15:43.900]   And the iPhone 7, I've been playing with it for a couple of days.
[00:15:43.900 --> 00:15:48.100]   The camera seems noticeably better, but not incredibly.
[00:15:48.100 --> 00:15:51.500]   The screen seems maybe perhaps noticeably better, but not incredible.
[00:15:51.500 --> 00:15:56.900]   And I have to say, taking the phone jack out, I didn't think that this would be a big deal.
[00:15:56.900 --> 00:16:01.620]   I've now had like two or three instances in a weekend that make it actually infuriating.
[00:16:01.620 --> 00:16:05.740]   Number one, I was driving and I was going to make a phone call.
[00:16:05.740 --> 00:16:08.020]   I like to use my headset because it's better fidelity.
[00:16:08.020 --> 00:16:11.340]   And I was charging and had a little better charge I had to choose between power and this.
[00:16:11.340 --> 00:16:15.500]   Then somebody had a stereo system at the house I was staying at this weekend and they wanted
[00:16:15.500 --> 00:16:19.860]   me to plug in to the jacket and have it and then have to go find the dongle.
[00:16:19.860 --> 00:16:21.340]   What a horrible idea.
[00:16:21.340 --> 00:16:26.500]   And really the horrible idea about this, we're moving the phone jack is they could have
[00:16:26.500 --> 00:16:30.700]   made the dongle have a pass through power.
[00:16:30.700 --> 00:16:33.940]   Why does the dongle not have passed through power?
[00:16:33.940 --> 00:16:39.300]   Just like when you get your MacBook, they have this new USB-C, you lose the Mac connector
[00:16:39.300 --> 00:16:40.300]   again.
[00:16:40.300 --> 00:16:43.620]   It's like, how many different concurrent plugs is that we're going to support?
[00:16:43.620 --> 00:16:47.060]   Steve Jobs has done this several times to us in his history.
[00:16:47.060 --> 00:16:48.540]   I know it's so courageous.
[00:16:48.540 --> 00:16:54.060]   He took away the floppy drive and people had the same arguments, the same exact arguments.
[00:16:54.060 --> 00:16:55.580]   What am I going to do without a floppy drive?
[00:16:55.580 --> 00:16:56.580]   I came to load software.
[00:16:56.580 --> 00:16:58.780]   So you don't buy it.
[00:16:58.780 --> 00:17:00.980]   There's a revolution in audio coming.
[00:17:00.980 --> 00:17:04.820]   Doppler Labs is one of the companies that's bringing this.
[00:17:04.820 --> 00:17:08.660]   They handed me headphones at Coachella.
[00:17:08.660 --> 00:17:09.660]   They're $200 headphones.
[00:17:09.660 --> 00:17:14.180]   They have a microphone processing and a speaker and they blocked the real audio from coming
[00:17:14.180 --> 00:17:19.740]   to your, and keep in mind, Greg Coachella, $2 million worth of audio gear aimed at your
[00:17:19.740 --> 00:17:20.740]   head.
[00:17:20.740 --> 00:17:24.020]   And you're going to put your pieces in and you're going to listen to it through those.
[00:17:24.020 --> 00:17:25.020]   It sounds better.
[00:17:25.020 --> 00:17:26.020]   Sounds better.
[00:17:26.020 --> 00:17:30.180]   But then $2 million of audio gear talk about, I tried those at Coachella.
[00:17:30.180 --> 00:17:31.180]   They're going to sign that.
[00:17:31.180 --> 00:17:32.180]   Process.
[00:17:32.180 --> 00:17:33.180]   No, no.
[00:17:33.180 --> 00:17:36.260]   They listen to the audio and processes it and lets you turn it down.
[00:17:36.260 --> 00:17:40.940]   Well, it's not just that you turn that down, but you can pick which kind of audio you turn
[00:17:40.940 --> 00:17:41.940]   up or down.
[00:17:41.940 --> 00:17:43.180]   You can turn up just voice.
[00:17:43.180 --> 00:17:44.820]   You can turn up just travel.
[00:17:44.820 --> 00:17:47.060]   There's all sorts of things that can do and I understand that.
[00:17:47.060 --> 00:17:50.700]   I still think it's not quite the right decision the way they did it.
[00:17:50.700 --> 00:17:51.700]   I understand.
[00:17:51.700 --> 00:17:52.700]   Five words.
[00:17:52.700 --> 00:17:53.700]   You're not going to care.
[00:17:53.700 --> 00:17:54.700]   Can those ear pieces make Dylan?
[00:17:54.700 --> 00:17:56.900]   Can you hear, understand the lyrics again or no?
[00:17:56.900 --> 00:17:59.340]   Can you recognize the songs if you have Dylan on?
[00:17:59.340 --> 00:18:01.460]   They're, they're coming.
[00:18:01.460 --> 00:18:04.700]   They're coming with all sorts of magical things.
[00:18:04.700 --> 00:18:08.700]   Once you cut that chord, and I think this is where Apple's going, once you cut the chord
[00:18:08.700 --> 00:18:10.260]   you can have a translator.
[00:18:10.260 --> 00:18:13.740]   If you're speaking Chinese, you can translate it on.
[00:18:13.740 --> 00:18:16.660]   You can do this kind of audio processing, get rid of noise.
[00:18:16.660 --> 00:18:20.580]   The noise canceling on Dauper Labs is way better than a Bose headphone, right?
[00:18:20.580 --> 00:18:25.380]   There's a revolution coming in audio and nobody has seen it because you have to have one
[00:18:25.380 --> 00:18:26.380]   of these in your head.
[00:18:26.380 --> 00:18:28.780]   Let's go back to, should we cut to a break?
[00:18:28.780 --> 00:18:30.060]   You need me to do a quick commercial here?
[00:18:30.060 --> 00:18:31.860]   All right, hold on a second.
[00:18:31.860 --> 00:18:32.860]   Hold that thought.
[00:18:32.860 --> 00:18:38.740]   When we get back, Apple is looking at a company called Lit Motors, up on my iPad screen here.
[00:18:38.740 --> 00:18:44.860]   Lit Motors makes essentially a motorcycle in a metal cage that has a gyroscope in it.
[00:18:44.860 --> 00:18:47.100]   We have this at the launch festival a couple of times.
[00:18:47.100 --> 00:18:48.620]   It does not fall over.
[00:18:48.620 --> 00:18:50.020]   You can't make it fall over.
[00:18:50.020 --> 00:18:54.180]   If you skid or you flip it, you're going to be wearing a three-point harness.
[00:18:54.180 --> 00:18:56.100]   Will Apple buy this company?
[00:18:56.100 --> 00:19:00.540]   And Snapchat has come out with their own glasses finally.
[00:19:00.540 --> 00:19:03.060]   And Google has their big announcement.
[00:19:03.060 --> 00:19:11.300]   And the person running Oculus, the co-founder, is a secret troll on Reddit maybe.
[00:19:11.300 --> 00:19:14.300]   And Robert wants them fired when we get back on this weekend tech.
[00:19:14.300 --> 00:19:16.660]   All right, we're going to have more with Twitch and the gang.
[00:19:16.660 --> 00:19:21.180]   I'm going to give the big brains the time to cool and rest.
[00:19:21.180 --> 00:19:23.020]   Smog them if you got them, kids.
[00:19:23.020 --> 00:19:25.740]   Well, I talk a little bit about automatic, our great sponsor.
[00:19:25.740 --> 00:19:29.220]   They've been a really good sponsor of all of our shows.
[00:19:29.220 --> 00:19:31.300]   But also, I think a really great product.
[00:19:31.300 --> 00:19:32.700]   I've loved it.
[00:19:32.700 --> 00:19:34.780]   It's for the OBD2 port.
[00:19:34.780 --> 00:19:40.460]   That's the onboard diagnostics port on every vehicle made since 1996.
[00:19:40.460 --> 00:19:41.780]   You've got one.
[00:19:41.780 --> 00:19:42.780]   You do.
[00:19:42.780 --> 00:19:43.780]   It's right.
[00:19:43.780 --> 00:19:44.780]   Look, you may never have seen it.
[00:19:44.780 --> 00:19:48.700]   We'll down there by where your knees are.
[00:19:48.700 --> 00:19:51.740]   And if you did see it by any chance, you probably just assumed we'll let support for
[00:19:51.740 --> 00:19:55.060]   the technician at the dealership to check the car.
[00:19:55.060 --> 00:19:56.060]   And that's true.
[00:19:56.060 --> 00:19:57.260]   That's its intent.
[00:19:57.260 --> 00:19:59.540]   But it's an open port.
[00:19:59.540 --> 00:20:01.060]   And it's an open standard.
[00:20:01.060 --> 00:20:03.700]   And automatic makes a really cool dongle.
[00:20:03.700 --> 00:20:08.220]   Just plugs right into the port, gets its power from the port without draining your battery,
[00:20:08.220 --> 00:20:12.340]   has Bluetooth, so pairs with your phone, Android or iOS.
[00:20:12.340 --> 00:20:15.900]   And then, you get all this information from your car.
[00:20:15.900 --> 00:20:18.220]   Makes your car smart.
[00:20:18.220 --> 00:20:20.580]   Like what that light on the dashboard means.
[00:20:20.580 --> 00:20:24.340]   In fact, it's a great thing if you've got teens to put in there because there's all
[00:20:24.340 --> 00:20:29.060]   sorts of features like geo-fencing and you can even, on Android, if it's on turn off
[00:20:29.060 --> 00:20:31.700]   texting automatically with the automatic.
[00:20:31.700 --> 00:20:33.660]   There's a lot of really nice stuff.
[00:20:33.660 --> 00:20:37.260]   Once you get that automatic on your OBD port and your automatic software.
[00:20:37.260 --> 00:20:39.180]   Now, the nice thing is there's no subscription.
[00:20:39.180 --> 00:20:40.460]   There's no monthly fee.
[00:20:40.460 --> 00:20:44.020]   The new automatic has added 3G.
[00:20:44.020 --> 00:20:45.860]   This is the automatic pro.
[00:20:45.860 --> 00:20:46.860]   It has 3G.
[00:20:46.860 --> 00:20:47.860]   I don't know.
[00:20:47.860 --> 00:20:48.860]   That's kind of amazing.
[00:20:48.860 --> 00:20:50.260]   In the automatic.
[00:20:50.260 --> 00:20:52.580]   And still no subscription fee.
[00:20:52.580 --> 00:20:53.580]   Free.
[00:20:53.580 --> 00:20:55.180]   3G.
[00:20:55.180 --> 00:21:00.260]   So you, for instance, you don't have to have your phone with you.
[00:21:00.260 --> 00:21:02.060]   This is why it's great for teenagers.
[00:21:02.060 --> 00:21:04.580]   You can see where the car is.
[00:21:04.580 --> 00:21:09.460]   You can see where it's parked even if you're not in the car.
[00:21:09.460 --> 00:21:13.020]   And it's really, really cool.
[00:21:13.020 --> 00:21:17.540]   They integrate with everything like concurrent, expensive if you track business versus pleasure,
[00:21:17.540 --> 00:21:18.780]   mileage.
[00:21:18.780 --> 00:21:20.260]   It works with your Nest thermostat.
[00:21:20.260 --> 00:21:25.860]   So like you're coming home and your house, you know, the heater comes on or the AC comes
[00:21:25.860 --> 00:21:26.980]   on.
[00:21:26.980 --> 00:21:30.100]   You can ask your Amazon Echo where you parked your car.
[00:21:30.100 --> 00:21:32.300]   There's a skill for the automatic.
[00:21:32.300 --> 00:21:33.300]   Where did I park my car?
[00:21:33.300 --> 00:21:34.940]   Or how much gas is in the tank?
[00:21:34.940 --> 00:21:35.940]   That's a really good one.
[00:21:35.940 --> 00:21:37.700]   I use that one a lot.
[00:21:37.700 --> 00:21:39.180]   And this is great.
[00:21:39.180 --> 00:21:44.300]   Automatic Pro detects severe accidents and will get you human help.
[00:21:44.300 --> 00:21:49.140]   Will actually call for help even if you can't.
[00:21:49.140 --> 00:21:51.620]   Train responders will call for help.
[00:21:51.620 --> 00:21:56.140]   That is a real piece of mind if you're a parent or for anybody.
[00:21:56.140 --> 00:21:58.460]   Automatic works on nearly every car made after 96.
[00:21:58.460 --> 00:22:01.060]   It just takes minutes to connect minutes, seconds.
[00:22:01.060 --> 00:22:02.060]   You just push it in.
[00:22:02.060 --> 00:22:05.700]   The hardest thing is figuring out where is my port and then oh yeah.
[00:22:05.700 --> 00:22:08.220]   And then you pair it with your phone and boom.
[00:22:08.220 --> 00:22:11.300]   By the way, it also works with the Apple Watch and the Pebble.
[00:22:11.300 --> 00:22:14.180]   So you can, I mean, this thing is so slick.
[00:22:14.180 --> 00:22:15.780]   It basically makes it a smart car.
[00:22:15.780 --> 00:22:18.260]   No matter what kind of car it is.
[00:22:18.260 --> 00:22:19.260]   Automatic Pro.
[00:22:19.260 --> 00:22:20.260]   Now normally it's $129.95.
[00:22:20.260 --> 00:22:24.420]   Remember there's no monthly fee, no subscription to 3G is free.
[00:22:24.420 --> 00:22:26.580]   But we have an offer code that will save you 20 bucks.
[00:22:26.580 --> 00:22:28.500]   Use the offer code TWIT.
[00:22:28.500 --> 00:22:31.420]   Go to automatic.com/twit.
[00:22:31.420 --> 00:22:34.460]   Automatic spelled the way it is in the dictionary.
[00:22:34.460 --> 00:22:36.060]   www.tuit.com/twit.
[00:22:36.060 --> 00:22:40.420]   And don't forget when you decide to buy use the offer code TWIT, 20 bucks off, the regular
[00:22:40.420 --> 00:22:45.100]   purchase price, automatic.com/twit.
[00:22:45.100 --> 00:22:46.540]   We thank you for their support.
[00:22:46.540 --> 00:22:48.700]   Now back to the show.
[00:22:48.700 --> 00:22:56.540]   Okay, thank you Leo and automatic for supporting independent media like this week in tech.
[00:22:56.540 --> 00:22:57.540]   Leo's voice is pretty great.
[00:22:57.540 --> 00:22:58.540]   He's a great radio guy.
[00:22:58.540 --> 00:23:00.740]   Thanks for letting us host and trash the studio.
[00:23:00.740 --> 00:23:01.740]   Oh, we don't know that part.
[00:23:01.740 --> 00:23:03.540]   We're not going to trash the studio.
[00:23:03.540 --> 00:23:07.820]   It's, hey, taking a quick detour.
[00:23:07.820 --> 00:23:15.380]   A person named Palmer Freeman Lucky is the co-founder of Oculus.
[00:23:15.380 --> 00:23:18.100]   Oculus makes VR, speaking of VR.
[00:23:18.100 --> 00:23:20.060]   And we don't want to drift too much into politics.
[00:23:20.060 --> 00:23:25.980]   But he is the co-founder of Oculus as I said, which is obviously a Facebook company.
[00:23:25.980 --> 00:23:29.100]   Facebook paid $2 billion for the company.
[00:23:29.100 --> 00:23:35.740]   And he has apologized for giving money to a company called Nimble America.
[00:23:35.740 --> 00:23:39.020]   Give 10 times to it, $10,000.
[00:23:39.020 --> 00:23:48.140]   And he is claiming that it wasn't him on Reddit trolling about Trump and doing a bunch
[00:23:48.140 --> 00:23:49.580]   of other stuff.
[00:23:49.580 --> 00:23:53.940]   He says, "I am a libertarian who has publicly supported Ron Paul and Gary Johnson in the
[00:23:53.940 --> 00:23:54.940]   past.
[00:23:54.940 --> 00:23:55.940]   I plan on Ron and Gary.
[00:23:55.940 --> 00:23:57.660]   I'm committed to the principles of fair play and equal treatment.
[00:23:57.660 --> 00:24:00.580]   I did not write the Nimble Rich Man post or did I delete the account reports that I'm
[00:24:00.580 --> 00:24:02.940]   the founder employees of Nimble America or false.
[00:24:02.940 --> 00:24:05.740]   I don't have plans to donate beyond what I've already given to Nimble America.
[00:24:05.740 --> 00:24:07.300]   Still my actions are my own and do not respond to Oculus.
[00:24:07.300 --> 00:24:09.860]   I'm sorry for the impact my actions are having in the community.
[00:24:09.860 --> 00:24:11.540]   This has created some kind of massive bruja.
[00:24:11.540 --> 00:24:12.540]   Brian, what's going on here?
[00:24:12.540 --> 00:24:14.300]   That's a great question.
[00:24:14.300 --> 00:24:17.580]   So, the funny thing is people are like, "I own a Vive.
[00:24:17.580 --> 00:24:18.580]   It's not in this."
[00:24:18.580 --> 00:24:19.580]   Yes.
[00:24:19.580 --> 00:24:23.580]   And, you know, because buying an Oculus Rift somehow makes you a Trump supporter in this.
[00:24:23.580 --> 00:24:26.500]   So he's kind of in trouble for having political opinion in one sense.
[00:24:26.500 --> 00:24:29.420]   He's also in trouble for helping people go nuts on people.
[00:24:29.420 --> 00:24:30.900]   That's the bad part, the bullying, right?
[00:24:30.900 --> 00:24:32.180]   So sponsoring the bullying.
[00:24:32.180 --> 00:24:35.060]   And his apology isn't a...
[00:24:35.060 --> 00:24:36.060]   It's not apology.
[00:24:36.060 --> 00:24:37.580]   So don't say it's an apology.
[00:24:37.580 --> 00:24:39.540]   It's more like his explanation.
[00:24:39.540 --> 00:24:41.340]   And he doesn't specifically...
[00:24:41.340 --> 00:24:45.740]   He apologizes for the fact that the company is now having problems with the community.
[00:24:45.740 --> 00:24:47.540]   I'm very sorry that this is happening.
[00:24:47.540 --> 00:24:49.540]   And he's not really sorry he did anything.
[00:24:49.540 --> 00:24:54.060]   And then what he also said was, that wasn't me, but the journalist who uncovered it all
[00:24:54.060 --> 00:24:57.620]   said, "Well, what he's doing is he's kind of parsing this in a crazy, crazy way."
[00:24:57.620 --> 00:24:59.860]   Which is, somebody else set up the account.
[00:24:59.860 --> 00:25:03.180]   I stepped in and wrote the stuff, sent the money, and then I got out again.
[00:25:03.180 --> 00:25:07.100]   So it's not really my account, but I'm the only person who ever posted under that name.
[00:25:07.100 --> 00:25:08.100]   See?
[00:25:08.100 --> 00:25:09.100]   So it's not...
[00:25:09.100 --> 00:25:10.100]   It's not...
[00:25:10.100 --> 00:25:11.100]   I didn't do it.
[00:25:11.100 --> 00:25:12.100]   It's not my account.
[00:25:12.100 --> 00:25:13.100]   Oh, who's the account is it?
[00:25:13.100 --> 00:25:14.100]   Somebody set it up for me to go in and type all the stuff.
[00:25:14.100 --> 00:25:15.100]   Got it!
[00:25:15.100 --> 00:25:16.100]   And then he'd tell the stuff in a chat.
[00:25:16.100 --> 00:25:20.020]   And now we know how to deflect this stuff in the future if I want to create trolling accounts.
[00:25:20.020 --> 00:25:27.180]   It's pretty amazing because what this Nimble group did was basically post like a lot of
[00:25:27.180 --> 00:25:30.860]   the abhorrent Hillary Clinton misogynistic crazy memes.
[00:25:30.860 --> 00:25:33.940]   It's kind of like a Reddit trolling kind of thing.
[00:25:33.940 --> 00:25:35.940]   Not that Reddit is only one thing, just to be clear.
[00:25:35.940 --> 00:25:41.180]   I think Reddit gets an unfair kind of reputation that it's all trolls.
[00:25:41.180 --> 00:25:45.780]   Reddit is like 99% probably not trolls, but the 1% of trolls are so vocal and so insane.
[00:25:45.780 --> 00:25:46.780]   They have free reign.
[00:25:46.780 --> 00:25:47.780]   They have free reign.
[00:25:47.780 --> 00:25:55.500]   But trolling seems to be this high art form that it's being lampooned in.
[00:25:55.500 --> 00:25:59.380]   I don't know if anybody's watching the South Park season 20, but it's essentially literally...
[00:25:59.380 --> 00:26:04.140]   If you haven't watched season 19 or 20, it's literally about Twitter and trolling.
[00:26:04.140 --> 00:26:10.420]   Robert, you wrote that Palmer, lucky, that Zuck should fire him.
[00:26:10.420 --> 00:26:12.180]   Zuck follows you.
[00:26:12.180 --> 00:26:13.900]   Zuck likes your posts.
[00:26:13.900 --> 00:26:15.340]   Now and again, not this one.
[00:26:15.340 --> 00:26:16.540]   You know Zuck personally.
[00:26:16.540 --> 00:26:19.380]   You've known him since the beginning.
[00:26:19.380 --> 00:26:21.540]   It's inevitable that he will read your post.
[00:26:21.540 --> 00:26:23.620]   Why do you feel that Palmer should be fired?
[00:26:23.620 --> 00:26:25.020]   For Palmer Lucky.
[00:26:25.020 --> 00:26:29.220]   I got to split up my ego in the two places.
[00:26:29.220 --> 00:26:35.020]   One is the politics, which I find abhorrent, but let's put those aside.
[00:26:35.020 --> 00:26:42.940]   I've gone around the world many times this year, and I met with many, many VR developers.
[00:26:42.940 --> 00:26:47.860]   And most of the coolest VR developers are developing only for the vibe, because it has
[00:26:47.860 --> 00:26:51.940]   room scale, and because it's out with controllers today.
[00:26:51.940 --> 00:26:56.180]   I don't have Oculus controllers, and I'm in the middle of the VR industry, so they haven't
[00:26:56.180 --> 00:26:57.820]   shipped yet.
[00:26:57.820 --> 00:27:00.180]   So this guy hasn't done his job.
[00:27:00.180 --> 00:27:06.420]   He's losing to a competitor that should not be losing to, and he's not positioned well
[00:27:06.420 --> 00:27:08.340]   for augmented reality.
[00:27:08.340 --> 00:27:14.420]   He's not positioned well for this coming fight, which is a multi-billion dollar fight.
[00:27:14.420 --> 00:27:19.980]   I mean NVIDIA and Qualcomm and Intel alone are spending billions of dollars in the GPU
[00:27:19.980 --> 00:27:20.980]   at the base level.
[00:27:20.980 --> 00:27:26.100]   That gives you a sense of how much importance this industry is putting on this stuff.
[00:27:26.100 --> 00:27:34.140]   And this other thing just was the fire that lit the fuel for me.
[00:27:34.140 --> 00:27:40.220]   But this guy's not doing his job, and Facebook has not positioned well in VR, and that they're
[00:27:40.220 --> 00:27:41.220]   not taking their jobs.
[00:27:41.220 --> 00:27:44.380]   So it's one thing if you're winning and you're trolling in your spare time.
[00:27:44.380 --> 00:27:45.460]   It's another thing if you're losing your problem.
[00:27:45.460 --> 00:27:47.980]   We would still have a problem even if he was winning.
[00:27:47.980 --> 00:27:48.980]   Yes.
[00:27:48.980 --> 00:27:51.780]   But I would have a harder time calling for his firing, right?
[00:27:51.780 --> 00:27:57.140]   Would you compare that to Nest, where the problems with the team morale and stuff like
[00:27:57.140 --> 00:27:59.460]   that kind of lead to them looking at it more closely and saying, "Actually, you haven't
[00:27:59.460 --> 00:28:02.220]   shipped anything in a while, and you're doing a bad job, and now you're out."
[00:28:02.220 --> 00:28:04.980]   So it's not really a failure.
[00:28:04.980 --> 00:28:10.300]   So one, he's not, like Palmer has not really been the person running.
[00:28:10.300 --> 00:28:15.340]   No, but he's the visual face, and he made promises over and over to the community that
[00:28:15.340 --> 00:28:16.340]   he can't see.
[00:28:16.340 --> 00:28:22.500]   I agree with you on for doing, like you're taking aside even the politics of the whole
[00:28:22.500 --> 00:28:25.980]   thing, which alone should probably be fired for.
[00:28:25.980 --> 00:28:29.500]   The like performance you're saying, like it needs new leadership.
[00:28:29.500 --> 00:28:31.540]   I can't disagree with that either.
[00:28:31.540 --> 00:28:37.740]   Like so much more press, so much more hype, so much more interest in the V.E.V. and it's
[00:28:37.740 --> 00:28:40.700]   just a stronger product at the moment.
[00:28:40.700 --> 00:28:44.180]   The entire lucky thing is just as well as abhorrent.
[00:28:44.180 --> 00:28:51.420]   Regardless of which side, spending your money to troll and to harass people is just not
[00:28:51.420 --> 00:28:53.580]   okay in general.
[00:28:53.580 --> 00:28:54.580]   And like-
[00:28:54.580 --> 00:28:55.580]   Certainly not.
[00:28:55.580 --> 00:29:00.300]   I mean, we have to separate also here that it's one thing to have political beliefs.
[00:29:00.300 --> 00:29:03.580]   So we all have friends who want to vote for one side or the other.
[00:29:03.580 --> 00:29:05.860]   I don't believe anybody should be fired for the political belief.
[00:29:05.860 --> 00:29:06.860]   Yes, half the country would be fired.
[00:29:06.860 --> 00:29:07.860]   We have to fire half the country.
[00:29:07.860 --> 00:29:08.860]   Right, yes.
[00:29:08.860 --> 00:29:09.860]   It's no sense.
[00:29:09.860 --> 00:29:13.060]   Even if you, and it's a very divisive time right now, I mean, I've never seen it, and
[00:29:13.060 --> 00:29:14.620]   we've never seen this in our life.
[00:29:14.620 --> 00:29:18.500]   It's the deepest choice we have to make as Americans that we've ever had to make.
[00:29:18.500 --> 00:29:19.500]   It's very divisive.
[00:29:19.500 --> 00:29:21.900]   We can get into that on this week in politics another time.
[00:29:21.900 --> 00:29:22.900]   Yeah.
[00:29:22.900 --> 00:29:28.380]   But there is something qualitatively different about a political opinion and active trolling.
[00:29:28.380 --> 00:29:32.980]   I think we all realize active trolling is, I know it's funny for 12 year old boys or
[00:29:32.980 --> 00:29:37.220]   50 year old men who want to be like 12 year old boys, but it's actually hurtful.
[00:29:37.220 --> 00:29:41.620]   It's kind of childish and it's not something a senior executive at a company should be
[00:29:41.620 --> 00:29:43.540]   doing unless they're putting their name on it.
[00:29:43.540 --> 00:29:46.220]   And like, I'm going to troll you by telling you your product sucks.
[00:29:46.220 --> 00:29:51.860]   Like the guy from T-Mobile does of AT&T or whatever, Verizon says you charge too much.
[00:29:51.860 --> 00:29:57.060]   There's something about this, you know, and then it came up with Peter Chill as well.
[00:29:57.060 --> 00:30:03.180]   If you do anonymous bad behavior or anonymous borderline behavior, it becomes 10 times worse.
[00:30:03.180 --> 00:30:05.420]   It's almost like the anonymity of it makes it.
[00:30:05.420 --> 00:30:07.300]   When people have brought that up, why was he hiding it?
[00:30:07.300 --> 00:30:08.300]   Yeah.
[00:30:08.300 --> 00:30:11.020]   Why didn't he just do it under his own name instead of, you know, anonymous rich guy, 32,
[00:30:11.020 --> 00:30:12.020]   right?
[00:30:12.020 --> 00:30:13.020]   Yeah.
[00:30:13.020 --> 00:30:14.020]   It's just weird.
[00:30:14.020 --> 00:30:17.940]   We're seeing a lot of weird things happen because of this election and with the companies
[00:30:17.940 --> 00:30:22.140]   because Facebook has gone out of their way, what's particularly maybe not problematic
[00:30:22.140 --> 00:30:24.740]   about this actually, now that I think about it, maybe the subject helps.
[00:30:24.740 --> 00:30:26.100]   It actually balances it out.
[00:30:26.100 --> 00:30:29.780]   But Facebook had their thumb on the scale when it came to liberal stuff.
[00:30:29.780 --> 00:30:36.220]   The people who were doing the trending topics were very clearly trending liberal.
[00:30:36.220 --> 00:30:40.700]   And Zuck went out of his way to have Glenn back in a bunch of, you know, conservatives.
[00:30:40.700 --> 00:30:42.860]   So actually maybe this helps Facebook.
[00:30:42.860 --> 00:30:44.860]   Maybe this whole thing was done intentionally.
[00:30:44.860 --> 00:30:45.860]   It might be a system.
[00:30:45.860 --> 00:30:50.180]   There was the other thing of like, what's the actual long term damage?
[00:30:50.180 --> 00:30:52.940]   And it's probably not this not that much.
[00:30:52.940 --> 00:30:56.700]   The longer term is like, can Oculus regain the position as number one?
[00:30:56.700 --> 00:30:57.700]   Yeah.
[00:30:57.700 --> 00:31:00.620]   But he was the public face of this, of this team.
[00:31:00.620 --> 00:31:01.780]   He was on stage.
[00:31:01.780 --> 00:31:06.460]   It comes as a upload has featured him many times interviewed him many times, right?
[00:31:06.460 --> 00:31:10.020]   And we would probably, we're probably going to interview him for our new show that we're
[00:31:10.020 --> 00:31:11.740]   going to do on VR.
[00:31:11.740 --> 00:31:15.380]   That Jason and I are starting a podcast next month.
[00:31:15.380 --> 00:31:21.500]   But he can't be anymore because he's so divisive in terms of the politics.
[00:31:21.500 --> 00:31:25.540]   And then the people who are going to go against him, that's not good for a company.
[00:31:25.540 --> 00:31:27.300]   It is really insane.
[00:31:27.300 --> 00:31:28.780]   He's losing.
[00:31:28.780 --> 00:31:29.780]   He's losing.
[00:31:29.780 --> 00:31:31.780]   Somebody needs to say that.
[00:31:31.780 --> 00:31:33.980]   But we're in the middle of the...
[00:31:33.980 --> 00:31:35.260]   It's not just politics either.
[00:31:35.260 --> 00:31:40.420]   Keep in mind the reason the community is against him and flipped so violently, including
[00:31:40.420 --> 00:31:44.780]   Noni D'Lampenia, who was in the room with him when he was inventing it.
[00:31:44.780 --> 00:31:48.180]   She came out very strongly.
[00:31:48.180 --> 00:31:51.700]   She really went over the line with her with this.
[00:31:51.700 --> 00:31:56.460]   Again, there was a precondition that was happening already.
[00:31:56.460 --> 00:32:01.460]   He made promises to the VR community that Oculus was going to be an open system.
[00:32:01.460 --> 00:32:03.860]   He had to take those words back.
[00:32:03.860 --> 00:32:07.300]   And he did several things like this in the public eye that set the...
[00:32:07.300 --> 00:32:10.420]   So now his character is being just sort of dismantled.
[00:32:10.420 --> 00:32:13.540]   And it's very hard when you're the evangelist to have these things.
[00:32:13.540 --> 00:32:15.740]   That's why you don't see Zuck or other people.
[00:32:15.740 --> 00:32:21.740]   And if you look, Jack at Twitter, to Segway, and obviously this week we saw that Twitter
[00:32:21.740 --> 00:32:23.140]   is obviously for sale.
[00:32:23.140 --> 00:32:26.620]   They're trying to sell it because they can't fix it so they could be part of something
[00:32:26.620 --> 00:32:27.620]   else.
[00:32:27.620 --> 00:32:33.940]   Jack has been known for being on the other side, being Black Lives Matter, very liberal.
[00:32:33.940 --> 00:32:37.820]   Now, A7 just said, "So you have to be a Democrat to sell VR."
[00:32:37.820 --> 00:32:38.820]   That's not true.
[00:32:38.820 --> 00:32:39.820]   That's not what you're...
[00:32:39.820 --> 00:32:41.220]   What we're saying.
[00:32:41.220 --> 00:32:46.740]   And you do have to have credibility with the community you serve if you're going to be
[00:32:46.740 --> 00:32:48.300]   a leader in a company.
[00:32:48.300 --> 00:32:53.420]   If you lose that credibility for any reason, a scandal or something, you're going to get
[00:32:53.420 --> 00:32:54.420]   removed, right?
[00:32:54.420 --> 00:32:56.460]   CEOs get fired all the time for some reason.
[00:32:56.460 --> 00:32:57.460]   Yeah.
[00:32:57.460 --> 00:33:03.820]   I mean, amongst the CEO crowd, there are a ton of people who I've spoken to and said,
[00:33:03.820 --> 00:33:04.820]   "Hey, what's your position?"
[00:33:04.820 --> 00:33:07.140]   And they say, "My position is X.
[00:33:07.140 --> 00:33:08.380]   Don't ever tell people my position.
[00:33:08.380 --> 00:33:09.380]   My position is..."
[00:33:09.380 --> 00:33:12.260]   You know, I hope that you vote this year.
[00:33:12.260 --> 00:33:15.620]   The intelligent people are just taking the position as one intelligent person told me,
[00:33:15.620 --> 00:33:20.220]   "Just tell people to vote because 75% of people who are not voters, if they vote,
[00:33:20.220 --> 00:33:21.580]   vote for Hillary Clinton."
[00:33:21.580 --> 00:33:24.540]   So that's why you're seeing the Democrats really pushing hard for more people to vote,
[00:33:24.540 --> 00:33:28.260]   Republicans pushing very hard for less people to vote and making it harder to vote because
[00:33:28.260 --> 00:33:29.940]   it just happens to be in this election.
[00:33:29.940 --> 00:33:33.980]   The people who are not registered will lean that way.
[00:33:33.980 --> 00:33:40.860]   Brian, when we look at all of this and Google, you have Twitter now is sort of too far to
[00:33:40.860 --> 00:33:42.580]   left.
[00:33:42.580 --> 00:33:44.180]   What do you think happens with Twitter?
[00:33:44.180 --> 00:33:46.860]   Is it Google who will buy it?
[00:33:46.860 --> 00:33:50.020]   I've thought about this all week long because they're...
[00:33:50.020 --> 00:33:52.100]   Could anybody conceivably fix it?
[00:33:52.100 --> 00:33:53.620]   That's the other sort of situation.
[00:33:53.620 --> 00:33:55.620]   Because Jack's been half-time.
[00:33:55.620 --> 00:33:59.020]   Jack's a pretty bright guy, obviously, but he's half-time.
[00:33:59.020 --> 00:34:02.300]   The product has not gotten demonstrably better.
[00:34:02.300 --> 00:34:03.300]   No, no, no.
[00:34:03.300 --> 00:34:04.300]   They haven't picked it.
[00:34:04.300 --> 00:34:06.780]   And he's made a lot of weird decisions like banning Milo and getting very involved in
[00:34:06.780 --> 00:34:07.780]   policing speech.
[00:34:07.780 --> 00:34:08.780]   Seems like a weirdly weird decision.
[00:34:08.780 --> 00:34:13.860]   Like, you don't see Zuck coming down to that level ever and picking what's in trending
[00:34:13.860 --> 00:34:18.260]   topics or taking stuff out like Jack's getting a little too emotionally involved in the
[00:34:18.260 --> 00:34:19.260]   world.
[00:34:19.260 --> 00:34:20.260]   It hasn't helped.
[00:34:20.260 --> 00:34:21.260]   It doesn't...
[00:34:21.260 --> 00:34:22.260]   It does not help, of course.
[00:34:22.260 --> 00:34:24.860]   So he shows up with a hashtag t-shirt on @arayet.
[00:34:24.860 --> 00:34:25.860]   Yeah.
[00:34:25.860 --> 00:34:26.860]   And that's wonderful.
[00:34:26.860 --> 00:34:27.860]   That's fantastic.
[00:34:27.860 --> 00:34:28.860]   Go.
[00:34:28.860 --> 00:34:29.860]   You don't have an opinion.
[00:34:29.860 --> 00:34:30.860]   But it hasn't helped the product and the company at all.
[00:34:30.860 --> 00:34:31.860]   I don't know who buys it.
[00:34:31.860 --> 00:34:33.980]   You know, media companies and other tech companies.
[00:34:33.980 --> 00:34:35.140]   And where does it fit in?
[00:34:35.140 --> 00:34:37.020]   And, you know, it's a phenomenon.
[00:34:37.020 --> 00:34:42.620]   It's a necessity to have this place for the free speech and the ability to reach out to
[00:34:42.620 --> 00:34:43.860]   a celebrity and get something back.
[00:34:43.860 --> 00:34:45.860]   It's not growing, but it won't go...
[00:34:45.860 --> 00:34:46.860]   But what is it?
[00:34:46.860 --> 00:34:47.860]   Good sh*t.
[00:34:47.860 --> 00:34:48.860]   What does it add?
[00:34:48.860 --> 00:34:49.860]   Like, what does it add?
[00:34:49.860 --> 00:34:50.860]   Like, people say, "Oh, Apple will buy it."
[00:34:50.860 --> 00:34:51.860]   I don't know, they're not.
[00:34:51.860 --> 00:34:52.860]   You know?
[00:34:52.860 --> 00:34:53.860]   Like, what does it add to Apple?
[00:34:53.860 --> 00:34:54.860]   To buy Twitter?
[00:34:54.860 --> 00:34:55.860]   Go look at any other sales force.
[00:34:55.860 --> 00:34:56.860]   Think about the same size.
[00:34:56.860 --> 00:34:57.860]   You disagree, Ben.
[00:34:57.860 --> 00:34:58.860]   Who should buy it?
[00:34:58.860 --> 00:34:59.860]   So, the one thing...
[00:34:59.860 --> 00:35:00.860]   It's not just the service.
[00:35:00.860 --> 00:35:01.860]   It's the data source.
[00:35:01.860 --> 00:35:07.660]   The data source is extraordinarily valuable to companies like Microsoft, to Salesforce,
[00:35:07.660 --> 00:35:09.660]   to Google, to Facebook.
[00:35:09.660 --> 00:35:10.660]   Okay, wait, wait, wait.
[00:35:10.660 --> 00:35:16.140]   We understand why it's interesting to Microsoft and Google because they both have search engines
[00:35:16.140 --> 00:35:19.580]   being in Google search because that data isn't been indexed, right?
[00:35:19.580 --> 00:35:21.340]   It's being put out for the first time.
[00:35:21.340 --> 00:35:22.340]   Why is it important to Salesforce?
[00:35:22.340 --> 00:35:23.740]   That I don't get.
[00:35:23.740 --> 00:35:24.740]   Why is Salesforce so interesting?
[00:35:24.740 --> 00:35:27.500]   I know Benning off loves Twitter reasons on Twitter all day long.
[00:35:27.500 --> 00:35:29.780]   Does anybody heard why it would be important to Salesforce?
[00:35:29.780 --> 00:35:36.260]   I think that they're thinking about expanding their business as part of his thinking.
[00:35:36.260 --> 00:35:37.260]   And this opens up...
[00:35:37.260 --> 00:35:38.260]   It's to what?
[00:35:38.260 --> 00:35:39.260]   Consumer.
[00:35:39.260 --> 00:35:40.260]   Ah.
[00:35:40.260 --> 00:35:41.260]   Salesforce has consumer.
[00:35:41.260 --> 00:35:46.620]   And they also, and also the social feeds feed a lot into their data engine, into Einstein,
[00:35:46.620 --> 00:35:50.260]   into the Einstein project, and into AI, and into a lot of the things they're doing.
[00:35:50.260 --> 00:35:51.260]   So I get it.
[00:35:51.260 --> 00:35:55.300]   Like, the purchase doesn't make sense in the sense that they don't have the money to buy
[00:35:55.300 --> 00:35:56.300]   it.
[00:35:56.300 --> 00:35:57.300]   Right.
[00:35:57.300 --> 00:35:58.700]   Like, I mean, then again, they try to get linked in.
[00:35:58.700 --> 00:36:01.300]   So, you know, that's not a...
[00:36:01.300 --> 00:36:03.940]   Lack of money is not going to stop Benning off.
[00:36:03.940 --> 00:36:10.220]   But it makes sense that they partner with the right company.
[00:36:10.220 --> 00:36:11.220]   It's like...
[00:36:11.220 --> 00:36:12.220]   It's a huge, huge, huge top company.
[00:36:12.220 --> 00:36:13.220]   It seems like Google.
[00:36:13.220 --> 00:36:14.220]   Yeah.
[00:36:14.220 --> 00:36:15.220]   It makes the most sense.
[00:36:15.220 --> 00:36:16.900]   Because Google has no horse in the world.
[00:36:16.900 --> 00:36:17.900]   Google's not done it.
[00:36:17.900 --> 00:36:23.180]   But if Google hasn't done it at this point, with multiple moomers and multiple times,
[00:36:23.180 --> 00:36:24.780]   they've had that discussion.
[00:36:24.780 --> 00:36:25.860]   Why now?
[00:36:25.860 --> 00:36:27.580]   Because I think capitulation.
[00:36:27.580 --> 00:36:29.780]   I think they got Jack back in there.
[00:36:29.780 --> 00:36:30.780]   He gave it his all.
[00:36:30.780 --> 00:36:32.900]   Or I should say he gave it half of his all.
[00:36:32.900 --> 00:36:33.900]   And it has...
[00:36:33.900 --> 00:36:34.900]   He gave it half.
[00:36:34.900 --> 00:36:35.900]   Right.
[00:36:35.900 --> 00:36:38.380]   And it has not even gotten marginally better.
[00:36:38.380 --> 00:36:40.620]   The product is not even marginally better.
[00:36:40.620 --> 00:36:41.620]   Let's call it what it is.
[00:36:41.620 --> 00:36:44.460]   No, every time they come up with a new feature, people kind of respond and they go, "Oh, that's
[00:36:44.460 --> 00:36:45.460]   great."
[00:36:45.460 --> 00:36:46.900]   And no longer counting the first @ mention.
[00:36:46.900 --> 00:36:48.060]   Can you fix trolling?
[00:36:48.060 --> 00:36:49.060]   Can I edit my tweet?
[00:36:49.060 --> 00:36:50.540]   Like, they list all the major stuff.
[00:36:50.540 --> 00:36:51.540]   And Twitter doesn't fix the major stuff.
[00:36:51.540 --> 00:36:54.140]   It just doesn't feel like there's any clear vision.
[00:36:54.140 --> 00:36:55.140]   Right.
[00:36:55.140 --> 00:36:56.140]   I think if Twitter...
[00:36:56.140 --> 00:36:59.580]   If Twitter was a European company, somebody would have bought it with their offshore cash
[00:36:59.580 --> 00:37:00.580]   already.
[00:37:00.580 --> 00:37:01.580]   Right?
[00:37:01.580 --> 00:37:02.580]   Oh, of course.
[00:37:02.580 --> 00:37:03.580]   Yeah, well, you get a third discount.
[00:37:03.580 --> 00:37:05.780]   You get a 35% discount on the price.
[00:37:05.780 --> 00:37:09.780]   And now there's this top $30 billion price, which makes no sense to me.
[00:37:09.780 --> 00:37:10.780]   Right.
[00:37:10.780 --> 00:37:12.260]   Yeah, a premium on top of failing.
[00:37:12.260 --> 00:37:16.100]   Yeah, I don't think failing companies get to get a premium.
[00:37:16.100 --> 00:37:18.580]   Robert, who's the most likely buyer?
[00:37:18.580 --> 00:37:24.260]   If you had to place a bet, if I had to say all your gadgets on the table, we each have
[00:37:24.260 --> 00:37:29.780]   to bet all of our gadgets on us and that we've bought in the last two years, what
[00:37:29.780 --> 00:37:30.780]   company do you bet?
[00:37:30.780 --> 00:37:32.780]   Buy us a Twitter?
[00:37:32.780 --> 00:37:33.780]   Yeah.
[00:37:33.780 --> 00:37:35.300]   Well, your gadgets are at stake.
[00:37:35.300 --> 00:37:38.020]   Every piece of electronics you've bought or that have been given to you in the last
[00:37:38.020 --> 00:37:39.460]   two years are at stake.
[00:37:39.460 --> 00:37:46.100]   Somebody like Verizon or Comcast or a company that's trying to switch up out of its business
[00:37:46.100 --> 00:37:47.820]   model as badly as possible.
[00:37:47.820 --> 00:37:48.820]   Okay.
[00:37:48.820 --> 00:37:49.820]   So, somebody who wants ad revenue?
[00:37:49.820 --> 00:37:55.380]   My kid, Google, R&D told me that we're not going to use the phone company in five years.
[00:37:55.380 --> 00:38:01.260]   We're going to use wireless coming from Google, from a plane, from a hot air balloon, and
[00:38:01.260 --> 00:38:02.340]   from a satellite network.
[00:38:02.340 --> 00:38:03.340]   Can you believe that?
[00:38:03.340 --> 00:38:04.340]   I do.
[00:38:04.340 --> 00:38:05.340]   Okay.
[00:38:05.340 --> 00:38:07.620]   Do you notice what blew up on that space?
[00:38:07.620 --> 00:38:10.060]   There was a Facebook satellite.
[00:38:10.060 --> 00:38:11.460]   And what was the satellite for?
[00:38:11.460 --> 00:38:14.340]   It was for low earth orbit internet in Africa.
[00:38:14.340 --> 00:38:15.340]   That's what this is.
[00:38:15.340 --> 00:38:16.620]   Built by an Israeli company.
[00:38:16.620 --> 00:38:21.460]   First of all, I don't believe when some executive like Mark Zuckerberg says, "I'm just building
[00:38:21.460 --> 00:38:23.740]   this for poor people in Africa."
[00:38:23.740 --> 00:38:24.740]   It's for everybody.
[00:38:24.740 --> 00:38:25.740]   Yeah, that's a fair point.
[00:38:25.740 --> 00:38:29.140]   I mean, I don't think you just trust anything Zuckerberg says to be a person.
[00:38:29.140 --> 00:38:34.580]   No, he's signaling to his employees that I have a new mission, which is bringing internet
[00:38:34.580 --> 00:38:38.020]   to everybody, right, to the world that it doesn't have it yet.
[00:38:38.020 --> 00:38:39.100]   Great mission.
[00:38:39.100 --> 00:38:41.580]   But it's not just for the poor people in Africa.
[00:38:41.580 --> 00:38:42.580]   It's for Africa.
[00:38:42.580 --> 00:38:46.380]   So, you think he wants to do a low earth or a satellite system?
[00:38:46.380 --> 00:38:48.060]   Google is building it too.
[00:38:48.060 --> 00:38:50.580]   They have a fiber network that is unparalleled.
[00:38:50.580 --> 00:38:51.740]   The Google has more fiber.
[00:38:51.740 --> 00:38:55.540]   They can get a packet from here to India faster than the phone company can, because they have
[00:38:55.540 --> 00:38:59.060]   more fiber from here to India.
[00:38:59.060 --> 00:39:01.700]   They're building and it's not just Apple and Google.
[00:39:01.700 --> 00:39:04.460]   There's startups that we know that building satellites.
[00:39:04.460 --> 00:39:05.460]   SpaceX is doing it.
[00:39:05.460 --> 00:39:06.460]   They've been public about it.
[00:39:06.460 --> 00:39:08.460]   They're going to do a low earth orbit satellite system.
[00:39:08.460 --> 00:39:10.260]   And so if people don't know what that is.
[00:39:10.260 --> 00:39:11.260]   And that's a back call.
[00:39:11.260 --> 00:39:15.220]   So that the satellites can share packets with each other and packets around the earth.
[00:39:15.220 --> 00:39:19.060]   And then distribute those packets down to something on the ground or something close
[00:39:19.060 --> 00:39:20.060]   to the ground.
[00:39:20.060 --> 00:39:21.260]   It's a pizza sized box.
[00:39:21.260 --> 00:39:23.620]   For people who haven't seen this, I guess somebody can Google it right now and I can
[00:39:23.620 --> 00:39:25.500]   tell us some of the names of the companies that do it.
[00:39:25.500 --> 00:39:30.420]   But the difference, as I understand it, as was explained to me by people involved, low
[00:39:30.420 --> 00:39:36.300]   earth orbit satellites have a narrower field of coverage, right?
[00:39:36.300 --> 00:39:39.620]   And they burn up, I don't know what you call that, aperture.
[00:39:39.620 --> 00:39:43.580]   But anyway, because they're lower, they don't cover as much land.
[00:39:43.580 --> 00:39:44.580]   It's opportunity.
[00:39:44.580 --> 00:39:47.660]   So if you're a geosynchronous one, you're too far away to get a good picture.
[00:39:47.660 --> 00:39:51.820]   But if you're low enough to get a good picture, you have 12 minutes of going across your
[00:39:51.820 --> 00:39:52.820]   house.
[00:39:52.820 --> 00:39:55.460]   And those are the only 12 minutes because I just explained it to my kids a couple of
[00:39:55.460 --> 00:39:56.460]   days ago.
[00:39:56.460 --> 00:40:02.620]   And so this low earth will require, I was told, 850 satellites to cover humanity, you
[00:40:02.620 --> 00:40:04.700]   know, major populations.
[00:40:04.700 --> 00:40:08.740]   And they will burn out of the atmosphere every number of years.
[00:40:08.740 --> 00:40:11.060]   They don't know exactly what that is, but call it three, four, five years.
[00:40:11.060 --> 00:40:13.780]   So you're constantly going to be putting up small satellites.
[00:40:13.780 --> 00:40:16.380]   But you're going to do anyways, because the technology is going to get better.
[00:40:16.380 --> 00:40:17.380]   Exactly.
[00:40:17.380 --> 00:40:18.700]   But the latency has changed.
[00:40:18.700 --> 00:40:21.380]   So somebody, a twisted mister, is saying all the latency is the issue.
[00:40:21.380 --> 00:40:24.900]   That's with the huge satellite system and all this other garbage that's up there already
[00:40:24.900 --> 00:40:28.340]   that take a second to bounce things back and forth because it's so far up and they want
[00:40:28.340 --> 00:40:32.620]   to have such a wide aperture because they want to, you know, the planes fly.
[00:40:32.620 --> 00:40:35.660]   The planes fly at 80,000 feet above air traffic.
[00:40:35.660 --> 00:40:38.220]   You're talking about the internet planes.
[00:40:38.220 --> 00:40:39.220]   Facebook has a plane.
[00:40:39.220 --> 00:40:40.220]   Imagine that.
[00:40:40.220 --> 00:40:43.220]   That's going to fly over your house out of visible range.
[00:40:43.220 --> 00:40:45.220]   That your devices are going to talk to you.
[00:40:45.220 --> 00:40:50.180]   JetBlue and Verizon Southwest will be in the 30s, 40s for some of the private jets.
[00:40:50.180 --> 00:40:57.540]   And then at 80,000, we're going to have fleets of balloons that stay there for months, right?
[00:40:57.540 --> 00:41:02.580]   This, this, a cool, a plane that Facebook's built is a drone and it stays up over your
[00:41:02.580 --> 00:41:10.100]   house for three months, four months off a solar power because it can work on.
[00:41:10.100 --> 00:41:11.420]   It has a big wood span.
[00:41:11.420 --> 00:41:12.420]   So it has a lot of solar.
[00:41:12.420 --> 00:41:15.020]   What happens, what happens to the phone companies?
[00:41:15.020 --> 00:41:16.260]   They're dead.
[00:41:16.260 --> 00:41:18.100]   That's why Verizon needs to buy Twitter.
[00:41:18.100 --> 00:41:19.100]   Yeah.
[00:41:19.100 --> 00:41:20.100]   All right.
[00:41:20.100 --> 00:41:21.100]   Well, that was your long story.
[00:41:21.100 --> 00:41:22.100]   We'll get back to that.
[00:41:22.100 --> 00:41:23.100]   All right.
[00:41:23.100 --> 00:41:27.500]   When we get back from this next important break, we're going to talk about Snapchat releasing
[00:41:27.500 --> 00:41:30.380]   spectacles.
[00:41:30.380 --> 00:41:37.180]   And if Scoble will make a spectacle of himself with Snapchat spectacles in his shower and
[00:41:37.180 --> 00:41:39.380]   we'll show the meme, the meme.
[00:41:39.380 --> 00:41:40.380]   Get me.
[00:41:40.380 --> 00:41:41.380]   Get me.
[00:41:41.380 --> 00:41:42.380]   Ever.
[00:41:42.380 --> 00:41:45.100]   I'm literally the curse of Scoble returns.
[00:41:45.100 --> 00:41:48.540]   If it's a great product, it won't be killed by any one person.
[00:41:48.540 --> 00:41:52.740]   As everybody knows, Robert Scoble killed Google Glass by wearing them naked in a shower
[00:41:52.740 --> 00:41:54.420]   and turning them on when we get back.
[00:41:54.420 --> 00:41:55.420]   A lot of things go good.
[00:41:55.420 --> 00:41:56.420]   Scoble.
[00:41:56.420 --> 00:41:57.420]   Skid naked is scary.
[00:41:57.420 --> 00:42:01.340]   Robert, if I had that much power, really take his shirt off and wear right now, Evan
[00:42:01.340 --> 00:42:03.660]   Spiegel has just given, I have a breaking news story.
[00:42:03.660 --> 00:42:08.100]   Evan Spiegel has given Robert Scoble 4% of Snapchat's equity.
[00:42:08.100 --> 00:42:13.380]   And the shame for never wearing snap glasses in the shower.
[00:42:13.380 --> 00:42:15.180]   We'll talk about it all.
[00:42:15.180 --> 00:42:20.300]   Please, we'll talk about it when we get back on this weekend tech.
[00:42:20.300 --> 00:42:22.780]   I have a new Wi-Fi router.
[00:42:22.780 --> 00:42:26.260]   I've tried them all.
[00:42:26.260 --> 00:42:30.380]   And I have to say, no matter what I used, I had airport extremes.
[00:42:30.380 --> 00:42:32.260]   I had that Asus.
[00:42:32.260 --> 00:42:36.900]   There was just never any Wi-Fi throughout the house or it would drop out.
[00:42:36.900 --> 00:42:41.660]   You know, my wife would complain and say, oh, you know, I'm not getting Wi-Fi in the
[00:42:41.660 --> 00:42:42.660]   bedroom.
[00:42:42.660 --> 00:42:44.420]   And it was just a constant battle.
[00:42:44.420 --> 00:42:46.580]   I think you probably know what I'm talking about.
[00:42:46.580 --> 00:42:49.980]   Wi-Fi was easy when you were the only person that had it.
[00:42:49.980 --> 00:42:51.540]   But now it's congested.
[00:42:51.540 --> 00:42:52.580]   The bands are congested.
[00:42:52.580 --> 00:42:54.220]   There's people everywhere.
[00:42:54.220 --> 00:42:55.780]   You know, the distances.
[00:42:55.780 --> 00:42:58.020]   It seems like it works worse than it ever did.
[00:42:58.020 --> 00:42:59.340]   Until I got an ERO.
[00:42:59.340 --> 00:43:00.340]   E-E-R-O.
[00:43:00.340 --> 00:43:03.580]   It is something very, very different.
[00:43:03.580 --> 00:43:08.500]   First of all, it's a whole home system.
[00:43:08.500 --> 00:43:11.100]   It blankets your entire house.
[00:43:11.100 --> 00:43:12.860]   And you know, you could start with one ERO.
[00:43:12.860 --> 00:43:17.380]   But you probably should get the-- if you have Wi-Fi issues, get the kit of three.
[00:43:17.380 --> 00:43:19.980]   And you put the one, you connect that one, you're cable modem.
[00:43:19.980 --> 00:43:22.660]   If you want, all of them can be connected.
[00:43:22.660 --> 00:43:27.860]   You don't have to, you know, but you can have one base station and then satellite units.
[00:43:27.860 --> 00:43:28.860]   It's mesh.
[00:43:28.860 --> 00:43:30.900]   So it's very flexible.
[00:43:30.900 --> 00:43:35.420]   And then there's an app, Android or iOS, that helps you pair the additional units, helps
[00:43:35.420 --> 00:43:37.380]   you place them and pair them.
[00:43:37.380 --> 00:43:44.220]   And now once they're paired-- oh, and by the way, that is the easiest thing in the world.
[00:43:44.220 --> 00:43:48.980]   I can get Wi-Fi now in places I never got it before, including as I walk up the drive
[00:43:48.980 --> 00:43:50.820]   and down the street.
[00:43:50.820 --> 00:43:51.820]   It's great.
[00:43:51.820 --> 00:43:53.500]   WPA2 encryption, don't worry.
[00:43:53.500 --> 00:43:55.140]   The best encryption.
[00:43:55.140 --> 00:43:59.700]   And the Wi-Fi app connects you to the ERO folks.
[00:43:59.700 --> 00:44:01.540]   So they are constantly updating.
[00:44:01.540 --> 00:44:02.540]   I get firmware updates.
[00:44:02.540 --> 00:44:08.580]   In fact, the first time you install it, it will examine your system and will add software
[00:44:08.580 --> 00:44:09.780]   depending on what kind of devices.
[00:44:09.780 --> 00:44:14.020]   If you have a Roku or an Apple TV, it goes, "Okay, okay, we're going to do QoS."
[00:44:14.020 --> 00:44:15.860]   It's so smart.
[00:44:15.860 --> 00:44:18.020]   You also can do the things if you want to do port forwarding.
[00:44:18.020 --> 00:44:19.020]   No problem.
[00:44:19.020 --> 00:44:20.480]   It even has reservations.
[00:44:20.480 --> 00:44:23.060]   It's a sophisticated system and it'll give you an idea of your bandwidth.
[00:44:23.060 --> 00:44:24.580]   It's doing bandwidth checks.
[00:44:24.580 --> 00:44:26.100]   And it looks great.
[00:44:26.100 --> 00:44:27.100]   It's sleek.
[00:44:27.100 --> 00:44:29.500]   No, it, you know, antennas everywhere.
[00:44:29.500 --> 00:44:34.420]   Oh, and by the way, a 30-day money back guarantee.
[00:44:34.420 --> 00:44:36.860]   You're not getting my ERO back.
[00:44:36.860 --> 00:44:39.660]   My wife, at least I'm killing me.
[00:44:39.660 --> 00:44:41.500]   It really works.
[00:44:41.500 --> 00:44:43.180]   And I really want you to try it.
[00:44:43.180 --> 00:44:44.460]   We've got free overnight shipping.
[00:44:44.460 --> 00:44:47.260]   So if you're in a Wi-Fi emergency, you can have it tomorrow.
[00:44:47.260 --> 00:44:51.700]   Go to ero.com and select overnight shipping at checkout.
[00:44:51.700 --> 00:44:57.060]   And then the code for that is Twit, of course, TWIT.
[00:44:57.060 --> 00:45:01.260]   I was skeptical at first.
[00:45:01.260 --> 00:45:05.180]   And I have even tried kind of things like Ubiquity, some really kind of complicated
[00:45:05.180 --> 00:45:06.620]   solutions.
[00:45:06.620 --> 00:45:10.940]   This has all the power of those more complicated enterprise systems.
[00:45:10.940 --> 00:45:15.460]   But the ease of use, it's the easiest Wi-Fi system I've ever set up.
[00:45:15.460 --> 00:45:16.460]   Anybody can do it.
[00:45:16.460 --> 00:45:18.660]   And it solves a massive problem.
[00:45:18.660 --> 00:45:19.660]   E-E-R-O.com.
[00:45:19.660 --> 00:45:24.420]   And don't forget, free overnight shipping when you use the offer code TWIT.
[00:45:24.420 --> 00:45:25.580]   Thank you, ERO.
[00:45:25.580 --> 00:45:28.580]   And now back to Twit.
[00:45:28.580 --> 00:45:32.980]   Thank you, ERO, for providing great Wi-Fi, blanketing my house.
[00:45:32.980 --> 00:45:33.980]   I use the product.
[00:45:33.980 --> 00:45:35.820]   And it's great that they're supporting independent media.
[00:45:35.820 --> 00:45:36.820]   I do.
[00:45:36.820 --> 00:45:37.820]   This week in Tech, use it too.
[00:45:37.820 --> 00:45:38.820]   Two out of four.
[00:45:38.820 --> 00:45:39.820]   What's up with you, other guys?
[00:45:39.820 --> 00:45:40.820]   You got to get on this.
[00:45:40.820 --> 00:45:43.260]   And maybe three out of four after next week.
[00:45:43.260 --> 00:45:44.420]   All right.
[00:45:44.420 --> 00:45:47.300]   This is the big news of the weekend, at least.
[00:45:47.300 --> 00:45:48.900]   You can pull out my screen here.
[00:45:48.900 --> 00:45:49.900]   Brace yourselves.
[00:45:49.900 --> 00:45:52.020]   If there's kids in the room, you want to get them out.
[00:45:52.020 --> 00:45:56.820]   Here is Robert Scowall wearing the new Snacks at the Spectacles.
[00:45:56.820 --> 00:45:58.820]   Don't you know about Snapchat?
[00:45:58.820 --> 00:45:59.820]   You can turn it off the screen.
[00:45:59.820 --> 00:46:00.820]   There's more to full of this photo.
[00:46:00.820 --> 00:46:01.820]   Thank you.
[00:46:01.820 --> 00:46:05.900]   I love the fact that the producers here are just so quick to get something off the screen.
[00:46:05.900 --> 00:46:06.900]   That's just absolutely abhorrent.
[00:46:06.900 --> 00:46:07.900]   OK.
[00:46:07.900 --> 00:46:08.900]   Here we go.
[00:46:08.900 --> 00:46:15.180]   I think we just had to put the explicit on the iTunes finish show.
[00:46:15.180 --> 00:46:16.580]   So let's watch the video here.
[00:46:16.580 --> 00:46:17.900]   And I think we can talk over it.
[00:46:17.900 --> 00:46:25.940]   But as people know, I don't know, four or five years ago Snapchat rather, bought a promising
[00:46:25.940 --> 00:46:29.540]   company that was making video sunglasses.
[00:46:29.540 --> 00:46:34.260]   And it was an indiegogo and a Kickstarter.
[00:46:34.260 --> 00:46:38.420]   It was one of these like Cluji hardware projects that you figured out.
[00:46:38.420 --> 00:46:39.260]   I'm never going to deliver it.
[00:46:39.260 --> 00:46:42.860]   I believe they did deliver their product.
[00:46:42.860 --> 00:46:44.700]   It was never shipped it.
[00:46:44.700 --> 00:46:45.700]   They never shipped it?
[00:46:45.700 --> 00:46:48.940]   One of the-- I went to one of the pages and they said they got it.
[00:46:48.940 --> 00:46:49.940]   My pictures of it.
[00:46:49.940 --> 00:46:50.940]   Nice snap.
[00:46:50.940 --> 00:46:51.940]   Anyways-- Pictures of the founder here.
[00:46:51.940 --> 00:46:52.940]   Yeah.
[00:46:52.940 --> 00:46:54.780]   Anyways-- These were the pictures of the prototypes.
[00:46:54.780 --> 00:46:55.780]   I don't know.
[00:46:55.780 --> 00:46:56.780]   Is there a camera here that came out?
[00:46:56.780 --> 00:46:58.340]   There's a camera looking at you.
[00:46:58.340 --> 00:46:59.340]   Yeah.
[00:46:59.340 --> 00:47:00.340]   Look at direction your face.
[00:47:00.340 --> 00:47:01.340]   Yeah.
[00:47:01.340 --> 00:47:02.740]   So there's the founder wearing them.
[00:47:02.740 --> 00:47:05.140]   And the way these work-- This is two years ago.
[00:47:05.140 --> 00:47:06.500]   This is two years ago.
[00:47:06.500 --> 00:47:12.900]   The way these product-- the product works is if you press a button on the corner, it
[00:47:12.900 --> 00:47:18.620]   lights up an LED circle for 10 seconds, records whatever you see, and post it automatically
[00:47:18.620 --> 00:47:20.220]   to your Snapchat.
[00:47:20.220 --> 00:47:22.420]   You never have to take your phone out of your pocket.
[00:47:22.420 --> 00:47:25.940]   You never have to authenticate or whatever it is.
[00:47:25.940 --> 00:47:30.300]   And critically-- and I think that this is the big difference-- Google Glass resulted
[00:47:30.300 --> 00:47:34.300]   in many people getting punched in the face, beat up, or many arguments and fights started
[00:47:34.300 --> 00:47:35.300]   because--
[00:47:35.300 --> 00:47:36.300]   No, they were funny.
[00:47:36.300 --> 00:47:37.300]   OK.
[00:47:37.300 --> 00:47:38.300]   Whatever.
[00:47:38.300 --> 00:47:39.300]   There's three of four that were well documented.
[00:47:39.300 --> 00:47:40.940]   One by a woman who I think was trying--
[00:47:40.940 --> 00:47:41.940]   Sure.
[00:47:41.940 --> 00:47:47.500]   --the sense I got when she was trying to provoke people with them.
[00:47:47.500 --> 00:47:48.500]   She was.
[00:47:48.500 --> 00:47:49.500]   I mean, let's be honest.
[00:47:49.500 --> 00:47:50.500]   That's who we are, right?
[00:47:50.500 --> 00:47:51.500]   No.
[00:47:51.500 --> 00:47:52.500]   No, that's strange.
[00:47:52.500 --> 00:47:53.500]   No, we're just walking up to people.
[00:47:53.500 --> 00:47:54.500]   We're just wrong.
[00:47:54.500 --> 00:47:55.500]   We're just wrong.
[00:47:55.500 --> 00:47:57.500]   We're wearing weird things on our face.
[00:47:57.500 --> 00:47:58.500]   You know what I mean?
[00:47:58.500 --> 00:47:59.500]   I don't think you're an pushed society.
[00:47:59.500 --> 00:48:00.500]   Go ahead.
[00:48:00.500 --> 00:48:01.860]   She was trying to pick fights.
[00:48:01.860 --> 00:48:02.860]   I remember that.
[00:48:02.860 --> 00:48:04.300]   She was picking fights with me.
[00:48:04.300 --> 00:48:05.860]   She was picking fights with you.
[00:48:05.860 --> 00:48:06.860]   She was just--
[00:48:06.860 --> 00:48:08.860]   No, she would walk up to you and be like, I'm recording you right now.
[00:48:08.860 --> 00:48:09.860]   What did I do?
[00:48:09.860 --> 00:48:11.620]   I don't think you were being insulted by paparazzi.
[00:48:11.620 --> 00:48:15.300]   And then she would do it in a bar in San Francisco, which by the way, I don't think
[00:48:15.300 --> 00:48:17.700]   you want to go into a bar in San Francisco or anywhere.
[00:48:17.700 --> 00:48:21.140]   And then, especially at the I've bar, then go up to somebody who's after drunk and say,
[00:48:21.140 --> 00:48:22.140]   can I record you?
[00:48:22.140 --> 00:48:23.620]   We're not even asked to start recording them.
[00:48:23.620 --> 00:48:25.380]   But spectacles, they're totally different.
[00:48:25.380 --> 00:48:26.540]   At least in my opinion.
[00:48:26.540 --> 00:48:28.740]   They're like-- the price is completely different.
[00:48:28.740 --> 00:48:29.740]   130.
[00:48:29.740 --> 00:48:30.740]   Yeah.
[00:48:30.740 --> 00:48:31.740]   Which is just a--
[00:48:31.740 --> 00:48:32.740]   Versus 1300.
[00:48:32.740 --> 00:48:34.380]   Which is a totally reasonable price for normal sunglasses.
[00:48:34.380 --> 00:48:36.340]   Times have changed.
[00:48:36.340 --> 00:48:37.780]   We have Snapchat now.
[00:48:37.780 --> 00:48:40.460]   And Snapchat is a daily video show about your life.
[00:48:40.460 --> 00:48:43.380]   It's split up into little segments.
[00:48:43.380 --> 00:48:46.980]   We might call them in TV land shots, right?
[00:48:46.980 --> 00:48:50.420]   Right now, somebody is choosing who to focus the camera's on.
[00:48:50.420 --> 00:48:51.420]   Yes.
[00:48:51.420 --> 00:48:52.420]   It's a shot.
[00:48:52.420 --> 00:48:57.220]   And probably we're on air for five seconds or 10 seconds, right, while we're talking.
[00:48:57.220 --> 00:48:59.180]   And in Snapchat, that's what you're doing.
[00:48:59.180 --> 00:49:01.540]   You're capturing videos in a small segment.
[00:49:01.540 --> 00:49:02.540]   Yeah.
[00:49:02.540 --> 00:49:05.460]   And it builds a narrative about your day.
[00:49:05.460 --> 00:49:10.180]   And you can actually grab the day and store it to your phone or share it out on other
[00:49:10.180 --> 00:49:12.820]   places like Facebook or YouTube, right?
[00:49:12.820 --> 00:49:18.740]   So they solve the problem of you want to punch the person in the face.
[00:49:18.740 --> 00:49:21.500]   Because they're recording you covertly because you're going to press them.
[00:49:21.500 --> 00:49:28.660]   However, it is inevitable, Brian, that these will result in people putting up no snap glasses
[00:49:28.660 --> 00:49:32.460]   in this bar, in this club, at this concert, correct?
[00:49:32.460 --> 00:49:33.460]   So it is.
[00:49:33.460 --> 00:49:34.460]   We'll go via backlash.
[00:49:34.460 --> 00:49:38.420]   And there was that woman who posted something on Snapchat from her gym, right?
[00:49:38.420 --> 00:49:41.980]   There was the person that was older, a little heavier, standing over a tub.
[00:49:41.980 --> 00:49:42.980]   I think.
[00:49:42.980 --> 00:49:44.620]   And she's like, I can't unsee this.
[00:49:44.620 --> 00:49:45.620]   Then you have to see it.
[00:49:45.620 --> 00:49:46.620]   That's a good philosophy.
[00:49:46.620 --> 00:49:48.020]   She meant to send it to a friend.
[00:49:48.020 --> 00:49:49.980]   And she sent it to her followers instead.
[00:49:49.980 --> 00:49:51.420]   Taking the pictures illegal.
[00:49:51.420 --> 00:49:52.420]   Right.
[00:49:52.420 --> 00:49:55.860]   Snapping a picture in a locker room is completely illegal, right?
[00:49:55.860 --> 00:49:57.420]   I didn't realize that was actually a law.
[00:49:57.420 --> 00:49:58.860]   I just thought that was a California.
[00:49:58.860 --> 00:49:59.860]   In California.
[00:49:59.860 --> 00:50:02.860]   That's also why the cameras on your phones make a noise.
[00:50:02.860 --> 00:50:06.060]   They don't have to make a noise, but they make a noise to alert people when you're in the
[00:50:06.060 --> 00:50:07.660]   gym club, you know, shower, right?
[00:50:07.660 --> 00:50:09.660]   It's like a light on.
[00:50:09.660 --> 00:50:10.660]   Right.
[00:50:10.660 --> 00:50:11.660]   So I think they're doing this the right way.
[00:50:11.660 --> 00:50:12.660]   These are crazy.
[00:50:12.660 --> 00:50:13.660]   You can't miss them.
[00:50:13.660 --> 00:50:14.660]   They're not a Google Glass.
[00:50:14.660 --> 00:50:17.020]   It's also used to open web browsers.
[00:50:17.020 --> 00:50:18.020]   And only you can see.
[00:50:18.020 --> 00:50:19.780]   And like all this other junk that that was supposed to do.
[00:50:19.780 --> 00:50:20.780]   These are single function.
[00:50:20.780 --> 00:50:21.780]   Single function.
[00:50:21.780 --> 00:50:23.180]   I'm here to do this crazy thing.
[00:50:23.180 --> 00:50:27.700]   And you really can't hide them in a shower somewhere, right?
[00:50:27.700 --> 00:50:32.820]   Most people don't understand why Google Glass caused these fights.
[00:50:32.820 --> 00:50:36.100]   It really doesn't have anything to do about the camera.
[00:50:36.100 --> 00:50:40.820]   Because I was in the Sahara tent at Coachella and everybody's recording.
[00:50:40.820 --> 00:50:41.820]   Yes.
[00:50:41.820 --> 00:50:42.820]   On their phones.
[00:50:42.820 --> 00:50:43.820]   Well, you know.
[00:50:43.820 --> 00:50:44.820]   But there was two guys in front of me.
[00:50:44.820 --> 00:50:48.260]   One talked to the other and said, "I need to get away from the Google Glass people."
[00:50:48.260 --> 00:50:51.060]   I wasn't wearing it because I didn't wear it then.
[00:50:51.060 --> 00:50:53.260]   There was two people behind me who had Google Glass on.
[00:50:53.260 --> 00:50:56.820]   So I grabbed these two guys and said, "What makes you nervous about this?
[00:50:56.820 --> 00:51:00.620]   You're in a place where everybody's recording so it's not about the camera."
[00:51:00.620 --> 00:51:02.500]   And they said, "It just makes me feel bad."
[00:51:02.500 --> 00:51:03.500]   Yes.
[00:51:03.500 --> 00:51:05.020]   Two reasons I pulled out of them.
[00:51:05.020 --> 00:51:10.220]   One, there's a screen between them that they can't see and they can't renegotiate the social
[00:51:10.220 --> 00:51:11.860]   contract that we have with each other.
[00:51:11.860 --> 00:51:14.540]   If you start playing with Facebook right now in the middle of the show, I'd...
[00:51:14.540 --> 00:51:15.540]   Yeah.
[00:51:15.540 --> 00:51:16.540]   ...see up your hand.
[00:51:16.540 --> 00:51:17.540]   Why are you doing that?
[00:51:17.540 --> 00:51:19.100]   When there's something more important to pay attention to.
[00:51:19.100 --> 00:51:27.420]   And the second thing is they felt that the person who had them on had information about
[00:51:27.420 --> 00:51:30.500]   them that they didn't have about the people that had them on.
[00:51:30.500 --> 00:51:33.420]   So they had an advantage, an information advantage.
[00:51:33.420 --> 00:51:38.100]   I'll tell you why I don't like it because I saw Google executive get on the dance floor
[00:51:38.100 --> 00:51:39.900]   and all the girls left the dance floor.
[00:51:39.900 --> 00:51:41.900]   And I thought that was the reason.
[00:51:41.900 --> 00:51:46.140]   I was like, "We just sit here dancing with 10 girls and you literally at Google executive
[00:51:46.140 --> 00:51:47.140]   somebody's like, "Hey!"
[00:51:47.140 --> 00:51:48.140]   But they're not...
[00:51:48.140 --> 00:51:49.140]   Everybody runs.
[00:51:49.140 --> 00:51:50.140]   They were not that fashionable.
[00:51:50.140 --> 00:51:52.140]   The spectacles, if you actually look at the fact...
[00:51:52.140 --> 00:51:53.140]   Well, look at these.
[00:51:53.140 --> 00:51:54.140]   Pull this one up.
[00:51:54.140 --> 00:51:55.940]   I mean, this is Evan Spiegel who's dating a supermodel.
[00:51:55.940 --> 00:51:56.940]   I don't know who would...
[00:51:56.940 --> 00:51:57.940]   Oh, she's...
[00:51:57.940 --> 00:51:58.940]   I think they're married or engaged.
[00:51:58.940 --> 00:51:59.940]   They're engaged.
[00:51:59.940 --> 00:52:00.940]   I mean, and look, this...
[00:52:00.940 --> 00:52:01.940]   I mean, he's from LA.
[00:52:01.940 --> 00:52:02.940]   He's a hip dude.
[00:52:02.940 --> 00:52:03.940]   And look at the side.
[00:52:03.940 --> 00:52:04.940]   No.
[00:52:04.940 --> 00:52:05.940]   He's got the side thing here.
[00:52:05.940 --> 00:52:06.940]   I mean, it looks good.
[00:52:06.940 --> 00:52:12.140]   Well, so the style is in right now for like teenagers like 13 to 18.
[00:52:12.140 --> 00:52:13.140]   So it's part of it.
[00:52:13.140 --> 00:52:15.620]   So, you know, I want to do one prediction with the group.
[00:52:15.620 --> 00:52:16.620]   Okay, here we go.
[00:52:16.620 --> 00:52:18.460]   A prediction along bet.
[00:52:18.460 --> 00:52:19.460]   Prediction along bet.
[00:52:19.460 --> 00:52:20.460]   Let's do a bet.
[00:52:20.460 --> 00:52:21.460]   Okay, here we go.
[00:52:21.460 --> 00:52:22.460]   Sales.
[00:52:22.460 --> 00:52:23.460]   Sales.
[00:52:23.460 --> 00:52:24.460]   Time frame.
[00:52:24.460 --> 00:52:25.460]   Sales.
[00:52:25.460 --> 00:52:27.020]   Total, let's see.
[00:52:27.020 --> 00:52:28.260]   2017 sales.
[00:52:28.260 --> 00:52:29.260]   Not 20...
[00:52:29.260 --> 00:52:31.260]   By the end of the year.
[00:52:31.260 --> 00:52:32.260]   By the end of the year.
[00:52:32.260 --> 00:52:33.260]   So 2017 was the first full year?
[00:52:33.260 --> 00:52:36.140]   No, start with the begin when they come out till the end of 2017.
[00:52:36.140 --> 00:52:37.660]   All right, well, no, no, no.
[00:52:37.660 --> 00:52:39.660]   Let's give them all again on the first X.
[00:52:39.660 --> 00:52:40.660]   Let's just say 2018.
[00:52:40.660 --> 00:52:43.780]   2018, total sales.
[00:52:43.780 --> 00:52:45.780]   Everybody write it down or type it on your computer.
[00:52:45.780 --> 00:52:47.900]   Or actually, no, somebody can set the line.
[00:52:47.900 --> 00:52:48.900]   That's the better way to do it.
[00:52:48.900 --> 00:52:49.900]   We'll set the line in the makeup bet.
[00:52:49.900 --> 00:52:50.900]   Who wants to set the line?
[00:52:50.900 --> 00:52:51.900]   What does that mean?
[00:52:51.900 --> 00:52:52.900]   To explain that over and under.
[00:52:52.900 --> 00:52:54.540]   We're going to do over and under.
[00:52:54.540 --> 00:52:58.540]   So if you pick 10 million, I can pick over and under.
[00:52:58.540 --> 00:52:59.660]   You set the line.
[00:52:59.660 --> 00:53:01.460]   Every teenager is going to have them.
[00:53:01.460 --> 00:53:02.460]   Every teenager, okay.
[00:53:02.460 --> 00:53:04.460]   30 to 20 million Americans.
[00:53:04.460 --> 00:53:06.460]   70, 80 million of them are under.
[00:53:06.460 --> 00:53:07.460]   That's $30.
[00:53:07.460 --> 00:53:08.460]   They have to.
[00:53:08.460 --> 00:53:11.580]   Let's say 20% of teenagers are going to have them in the first year.
[00:53:11.580 --> 00:53:12.580]   That's 14 million?
[00:53:12.580 --> 00:53:14.220]   Whatever number you got with them is already saying under.
[00:53:14.220 --> 00:53:16.740]   I'm going to say 3.5, yeah, okay.
[00:53:16.740 --> 00:53:17.740]   You have no clue.
[00:53:17.740 --> 00:53:18.740]   All right, here we go.
[00:53:18.740 --> 00:53:19.740]   It's going to make a good bet.
[00:53:19.740 --> 00:53:22.940]   This is so funny because I'm going to take half my ego.
[00:53:22.940 --> 00:53:24.740]   I'm going to park half over here.
[00:53:24.740 --> 00:53:29.140]   All right, you know your timing.
[00:53:29.140 --> 00:53:32.660]   I've been meeting with groups of teenagers to study this.
[00:53:32.660 --> 00:53:35.300]   All right, and every single teenager says they want one.
[00:53:35.300 --> 00:53:36.300]   Of course.
[00:53:36.300 --> 00:53:41.740]   So, and when I go to Coachella, when Thomas Hock and I went to Coachella and shot people
[00:53:41.740 --> 00:53:46.740]   with big cameras, the millennials came up and danced for us.
[00:53:46.740 --> 00:53:48.900]   They want their picture taken.
[00:53:48.900 --> 00:53:51.140]   What is this Snapchat era?
[00:53:51.140 --> 00:53:52.620]   It's a selfie era.
[00:53:52.620 --> 00:53:54.460]   It's a, oh, look at me era.
[00:53:54.460 --> 00:53:56.780]   This is going to be very, very popular.
[00:53:56.780 --> 00:53:59.740]   Okay, so the number, give us a number.
[00:53:59.740 --> 00:54:05.060]   I'd say, by the way, we're going to bet four, we're going to bet four, a pair of the glasses.
[00:54:05.060 --> 00:54:07.420]   Whatever the highest end pair is from Snapchat, we'll bet for glasses.
[00:54:07.420 --> 00:54:09.220]   In the first 18 months, basically?
[00:54:09.220 --> 00:54:10.900]   No, no, no, no, it's 2018.
[00:54:10.900 --> 00:54:11.900]   2018, 2018.
[00:54:11.900 --> 00:54:12.900]   That's calendar year 28.
[00:54:12.900 --> 00:54:13.900]   Calendar year 28.
[00:54:13.900 --> 00:54:16.180]   So wait, so it's just sales in there or total from before?
[00:54:16.180 --> 00:54:18.820]   Total sales in 2018 only, not counting the first year.
[00:54:18.820 --> 00:54:21.020]   Because the first year could be like, who knows?
[00:54:21.020 --> 00:54:23.260]   How many GoPros sell a year?
[00:54:23.260 --> 00:54:24.260]   That's a good question.
[00:54:24.260 --> 00:54:25.820]   That's the over under end.
[00:54:25.820 --> 00:54:27.700]   Will it beat GoPro?
[00:54:27.700 --> 00:54:28.700]   That's the over under.
[00:54:28.700 --> 00:54:30.420]   Because that's the real one.
[00:54:30.420 --> 00:54:35.420]   That's the real company that disrupts because the technology on this is so amazing.
[00:54:35.420 --> 00:54:39.780]   If you're saying if it's GoPro, I guarantee it sells more than GoPro in 2018.
[00:54:39.780 --> 00:54:40.780]   100%.
[00:54:40.780 --> 00:54:42.260]   As a matter of fact, I will bet.
[00:54:42.260 --> 00:54:43.260]   I'll take that to.
[00:54:43.260 --> 00:54:45.660]   Okay, I'll say it's double.
[00:54:45.660 --> 00:54:47.420]   Double GoPro sales in 2018.
[00:54:47.420 --> 00:54:50.140]   Of traditional GoPros, a GoGo comes out with one of these.
[00:54:50.140 --> 00:54:51.500]   I can't say that because they...
[00:54:51.500 --> 00:54:52.500]   That's like a GoPro.
[00:54:52.500 --> 00:54:54.260]   For sure, it'll outsell GoPro.
[00:54:54.260 --> 00:54:55.260]   What do you think, Brian?
[00:54:55.260 --> 00:54:56.260]   Where would you set the line?
[00:54:56.260 --> 00:54:57.820]   And the number that will be sold in 2018?
[00:54:57.820 --> 00:54:58.820]   I give up.
[00:54:58.820 --> 00:54:59.820]   He told me I was wrong.
[00:54:59.820 --> 00:55:00.820]   What do you think?
[00:55:00.820 --> 00:55:01.820]   Is it going to be...
[00:55:01.820 --> 00:55:02.820]   No, you know, so I totally get the kids using them.
[00:55:02.820 --> 00:55:06.620]   I actually like this angle where if I was thinking about getting a GoPro, which could
[00:55:06.620 --> 00:55:08.180]   cost hundreds of dollars or more, right?
[00:55:08.180 --> 00:55:09.180]   Yeah.
[00:55:09.180 --> 00:55:10.180]   I'm going to get these instead.
[00:55:10.180 --> 00:55:11.180]   For sure.
[00:55:11.180 --> 00:55:12.180]   But it's only eight or 10 seconds.
[00:55:12.180 --> 00:55:15.060]   It's not the whole three hours of my mountain climb, right?
[00:55:15.060 --> 00:55:18.020]   GoPros sold 1.6 billion in 2015.
[00:55:18.020 --> 00:55:19.020]   Billion?
[00:55:19.020 --> 00:55:20.020]   What?
[00:55:20.020 --> 00:55:21.020]   1.6 billion dollars.
[00:55:21.020 --> 00:55:23.020]   Sales, revenue, right?
[00:55:23.020 --> 00:55:24.020]   1.6 billion dollars.
[00:55:24.020 --> 00:55:25.020]   Revenue.
[00:55:25.020 --> 00:55:29.220]   So if you divide that by $400 average, you're talking about whatever, 40 million of them
[00:55:29.220 --> 00:55:30.220]   or something like that.
[00:55:30.220 --> 00:55:31.220]   All right.
[00:55:31.220 --> 00:55:32.220]   That's in 2015.
[00:55:32.220 --> 00:55:33.220]   So, and they're going to sell probably more than...
[00:55:33.220 --> 00:55:35.220]   I don't know how much they cost.
[00:55:35.220 --> 00:55:36.220]   Four million of them, actually.
[00:55:36.220 --> 00:55:37.220]   It'll be four million.
[00:55:37.220 --> 00:55:38.220]   Four million times 400?
[00:55:38.220 --> 00:55:41.700]   Yeah, four million times 400.
[00:55:41.700 --> 00:55:47.660]   I would say 2018 sales, I'll set the line at six million units.
[00:55:47.660 --> 00:55:48.660]   Slightly under.
[00:55:48.660 --> 00:55:49.660]   Under...
[00:55:49.660 --> 00:55:50.660]   Under...
[00:55:50.660 --> 00:55:51.660]   It's way over that.
[00:55:51.660 --> 00:55:52.660]   He thinks way over that.
[00:55:52.660 --> 00:55:53.660]   He's got me convinced.
[00:55:53.660 --> 00:55:54.660]   Slightly under.
[00:55:54.660 --> 00:55:55.660]   What do you say?
[00:55:55.660 --> 00:55:56.660]   I'll take it over.
[00:55:56.660 --> 00:55:57.660]   You take the over?
[00:55:57.660 --> 00:55:58.660]   Okay.
[00:55:58.660 --> 00:55:59.660]   Great.
[00:55:59.660 --> 00:56:00.660]   I'm going to take the under.
[00:56:00.660 --> 00:56:01.660]   So we have two unders, two overs.
[00:56:01.660 --> 00:56:02.660]   We'll bet...
[00:56:02.660 --> 00:56:03.660]   I hope I'm wrong.
[00:56:03.660 --> 00:56:04.660]   Please send me glasses.
[00:56:04.660 --> 00:56:05.660]   Oh, no, even better.
[00:56:05.660 --> 00:56:06.660]   We'll bet...
[00:56:06.660 --> 00:56:07.660]   We'll bet...
[00:56:07.660 --> 00:56:08.660]   Whatever the most expensive hamburger in San Francisco is.
[00:56:08.660 --> 00:56:09.660]   And hard...
[00:56:09.660 --> 00:56:10.660]   Hard to waste says...
[00:56:10.660 --> 00:56:11.660]   There's going to be $120 truffle hamburger.
[00:56:11.660 --> 00:56:12.660]   We'll find it.
[00:56:12.660 --> 00:56:14.660]   Hard to waste says kids will be over in 2018?
[00:56:14.660 --> 00:56:15.660]   No.
[00:56:15.660 --> 00:56:16.660]   No.
[00:56:16.660 --> 00:56:17.660]   Okay.
[00:56:17.660 --> 00:56:19.860]   So here's the feature that's missing from this that I thought I had just written about
[00:56:19.860 --> 00:56:22.140]   it last week because I heard this was coming.
[00:56:22.140 --> 00:56:25.780]   The piece that's missing is it's not a DVR.
[00:56:25.780 --> 00:56:29.300]   And what this really should be is it should always be recording.
[00:56:29.300 --> 00:56:30.300]   Yeah.
[00:56:30.300 --> 00:56:31.300]   I know this will get people punched in the face.
[00:56:31.300 --> 00:56:32.300]   But I...
[00:56:32.300 --> 00:56:35.660]   Really, where this is going and I think this will probably happen by 2020.
[00:56:35.660 --> 00:56:37.860]   And I would fund a startup to do this because it's inevitable anyway.
[00:56:37.860 --> 00:56:39.260]   So I'm not going to make a judgment call on it.
[00:56:39.260 --> 00:56:45.740]   But if it's a DVR and at any point in time I can press it and go back on the last hour,
[00:56:45.740 --> 00:56:47.820]   find that clip, right, and boom.
[00:56:47.820 --> 00:56:49.020]   So I don't have to press it.
[00:56:49.020 --> 00:56:50.220]   I say, wow, that was a funny moment.
[00:56:50.220 --> 00:56:51.220]   Now I'm pressing it.
[00:56:51.220 --> 00:56:52.900]   No, this is like, my wife says this all the time.
[00:56:52.900 --> 00:56:56.420]   If we could just go back five seconds, that thing you said, you say you didn't say.
[00:56:56.420 --> 00:56:57.420]   Yeah.
[00:56:57.420 --> 00:56:59.060]   And like, this is like divorce product, not happening.
[00:56:59.060 --> 00:57:00.060]   Really?
[00:57:00.060 --> 00:57:01.060]   Yeah.
[00:57:01.060 --> 00:57:02.060]   I didn't say that.
[00:57:02.060 --> 00:57:03.060]   You said that.
[00:57:03.060 --> 00:57:04.060]   Yeah, I know.
[00:57:04.060 --> 00:57:05.060]   Exactly.
[00:57:05.060 --> 00:57:06.060]   Never said that.
[00:57:06.060 --> 00:57:07.060]   My wife is going to wear it.
[00:57:07.060 --> 00:57:08.060]   I know.
[00:57:08.060 --> 00:57:09.060]   You said she won't wear it.
[00:57:09.060 --> 00:57:10.060]   I'm going to wear it.
[00:57:10.060 --> 00:57:11.060]   I'm going to wear it.
[00:57:11.060 --> 00:57:12.060]   I'm going to wear it.
[00:57:12.060 --> 00:57:13.260]   I'm on a date.
[00:57:13.260 --> 00:57:14.260]   But here's the other thing.
[00:57:14.260 --> 00:57:16.740]   I think you're going to see a big load on 2017.
[00:57:16.740 --> 00:57:21.740]   And it's going to be less, a little bit less in 2018 because it's a two every other year
[00:57:21.740 --> 00:57:22.940]   kind of product.
[00:57:22.940 --> 00:57:27.340]   The thing we're all missing is there's some real technology in this product.
[00:57:27.340 --> 00:57:29.220]   There's two lenses.
[00:57:29.220 --> 00:57:34.500]   There's a reason for that because with two lenses, you can do a computer on the diff and
[00:57:34.500 --> 00:57:38.060]   you can build a point cloud, a volumetric point cloud.
[00:57:38.060 --> 00:57:43.140]   So I can capture you in three dimensions for VR and AR.
[00:57:43.140 --> 00:57:48.460]   And the algorithms that they're developing for AR, putting things on your face are getting
[00:57:48.460 --> 00:57:50.340]   really advanced for 2D.
[00:57:50.340 --> 00:57:52.300]   Wait until they do it in three, D.
[00:57:52.300 --> 00:57:59.220]   It's fairly clear that this is a step, a very pragmatic step towards augmented reality.
[00:57:59.220 --> 00:58:00.220]   Correct.
[00:58:00.220 --> 00:58:01.220]   I think you all agree on that.
[00:58:01.220 --> 00:58:02.580]   Screams are just too expensive.
[00:58:02.580 --> 00:58:03.580]   The screens are very expensive.
[00:58:03.580 --> 00:58:08.300]   So if people get addicted to this, then I believe the second feature that's missing,
[00:58:08.300 --> 00:58:14.900]   that would be pretty neat after the life DVR, I'll call it, the life DVR, is over people's
[00:58:14.900 --> 00:58:20.460]   head putting their last snap if you're friends, who you're friends in common are.
[00:58:20.460 --> 00:58:24.100]   In other words, when you walk through the world and you go to a party, you don't know
[00:58:24.100 --> 00:58:25.100]   who you know.
[00:58:25.100 --> 00:58:26.100]   Yeah.
[00:58:26.100 --> 00:58:28.900]   And you don't know who you've met before and you may not remember who their wife or their
[00:58:28.900 --> 00:58:32.460]   husband is or their kid's names are or who they dated in your social circle.
[00:58:32.460 --> 00:58:35.780]   You're going to actually have all that information floating on top of people's heads.
[00:58:35.780 --> 00:58:38.660]   And that would really, really, really benefit snap.
[00:58:38.660 --> 00:58:40.980]   They can do a lot more than bokeh.
[00:58:40.980 --> 00:58:45.340]   People in the chat room are asking, "What does this mean that you can do?"
[00:58:45.340 --> 00:58:50.020]   If you have depth information, you can turn this entire world into Minecraft, for instance.
[00:58:50.020 --> 00:58:53.860]   And all of a sudden, Ben is a Minecraft character over there.
[00:58:53.860 --> 00:58:55.980]   And the whole world is bricks, right?
[00:58:55.980 --> 00:58:59.980]   And that helps me make better content.
[00:58:59.980 --> 00:59:01.660]   Most people suck at content.
[00:59:01.660 --> 00:59:05.740]   Most people just know how to do a selfie or a little picture at Yosemite or something.
[00:59:05.740 --> 00:59:06.740]   They don't know how to frame the shot.
[00:59:06.740 --> 00:59:07.740]   They don't know how to blur the back.
[00:59:07.740 --> 00:59:08.740]   They don't know how to tell a story.
[00:59:08.740 --> 00:59:11.900]   I read a lot of snapchats and look at a lot of snapchats.
[00:59:11.900 --> 00:59:15.660]   I don't look at a lot of people's behavior on Twitter and Facebook to understand them.
[00:59:15.660 --> 00:59:17.260]   Most people suck at content.
[00:59:17.260 --> 00:59:20.740]   And this augmented reality stuff that they're doing on the face helps you tell a better
[00:59:20.740 --> 00:59:22.140]   story about yourself.
[00:59:22.140 --> 00:59:23.620]   It makes you more interesting.
[00:59:23.620 --> 00:59:28.620]   It's funny to look at the feed and see Ben par wearing drag, you know?
[00:59:28.620 --> 00:59:29.620]   What's your name?
[00:59:29.620 --> 00:59:31.620]   I'm not the filter you did, Jim.
[00:59:31.620 --> 00:59:32.620]   I'm wearing drag.
[00:59:32.620 --> 00:59:36.820]   All right, brainbow vomit.
[00:59:36.820 --> 00:59:39.220]   After this final, I believe it's the final.
[00:59:39.220 --> 00:59:40.220]   No?
[00:59:40.220 --> 00:59:48.140]   Okay, after this break, we have a horrifying bizarre news.
[00:59:48.140 --> 00:59:58.220]   A Verge employee was concurrently and covertly working for Apple computer without the Verge
[00:59:58.220 --> 01:00:03.220]   and nowhere out of Apple if they knew and nobody can seem to understand exactly what
[01:00:03.220 --> 01:00:04.220]   this is.
[01:00:04.220 --> 01:00:07.260]   But we have some theories that we'll talk about when we get back.
[01:00:07.260 --> 01:00:10.500]   Don't have another phone conference call.
[01:00:10.500 --> 01:00:12.300]   Never stop it.
[01:00:12.300 --> 01:00:14.700]   You need to do go to meeting folks.
[01:00:14.700 --> 01:00:16.420]   I still set up phone conference calls.
[01:00:16.420 --> 01:00:21.300]   You know, this ostensibly audio-only conference calls, but I do it with go to meeting.
[01:00:21.300 --> 01:00:26.180]   And then that way, first of all, they've got a great conference bridge system.
[01:00:26.180 --> 01:00:28.180]   So it really, really works well.
[01:00:28.180 --> 01:00:30.340]   And you don't have to use a phone system if you want.
[01:00:30.340 --> 01:00:34.340]   You could do it on iPad with the built-in data with Wi-Fi.
[01:00:34.340 --> 01:00:35.340]   You could do it.
[01:00:35.340 --> 01:00:37.020]   I mean, it's very flexible, but here's the other thing.
[01:00:37.020 --> 01:00:40.260]   You're going to go to meeting and you say, "Well, I really need to show you this."
[01:00:40.260 --> 01:00:42.100]   You can pop up your screen.
[01:00:42.100 --> 01:00:43.100]   See?
[01:00:43.100 --> 01:00:46.460]   Or, "Hey, I want to see you."
[01:00:46.460 --> 01:00:49.860]   You can see each other through high-def video.
[01:00:49.860 --> 01:00:58.140]   Many participants, actually, I'm always hesitant to use something with a new client
[01:00:58.140 --> 01:00:59.140]   right.
[01:00:59.140 --> 01:01:01.180]   I imagine you are too, because you're pitching them and you don't want to make them jump
[01:01:01.180 --> 01:01:02.180]   through hoops.
[01:01:02.180 --> 01:01:03.500]   With go to meeting, it's really easy.
[01:01:03.500 --> 01:01:04.700]   They get a link in their email.
[01:01:04.700 --> 01:01:08.900]   So, "All right, Leo's going to have this meeting at two o'clock on Friday."
[01:01:08.900 --> 01:01:11.380]   Click the link when it's time.
[01:01:11.380 --> 01:01:14.060]   And if they don't have the software, it downloads it 30 seconds later.
[01:01:14.060 --> 01:01:15.300]   It's up and running.
[01:01:15.300 --> 01:01:16.300]   No problem.
[01:01:16.300 --> 01:01:17.700]   It's very easy.
[01:01:17.700 --> 01:01:19.100]   And you're having the conference call.
[01:01:19.100 --> 01:01:21.260]   You're seeing each other.
[01:01:21.260 --> 01:01:22.740]   And they're seeing your presentation.
[01:01:22.740 --> 01:01:24.180]   They didn't have to jump through hoops.
[01:01:24.180 --> 01:01:25.940]   Usually, they're very impressed.
[01:01:25.940 --> 01:01:26.940]   They said, "What is this?
[01:01:26.940 --> 01:01:27.940]   I want to try it."
[01:01:27.940 --> 01:01:29.540]   Well, you could try it right now.
[01:01:29.540 --> 01:01:30.540]   Free.
[01:01:30.540 --> 01:01:37.940]   For 30 days, go to meeting.com for a sales demo presentation for collaboration, for an ad
[01:01:37.940 --> 01:01:38.940]   hoc meeting.
[01:01:38.940 --> 01:01:40.940]   Every meeting counts.
[01:01:40.940 --> 01:01:42.500]   Nine-- I love this.
[01:01:42.500 --> 01:01:43.500]   I didn't know this.
[01:01:43.500 --> 01:01:48.420]   Nine out of ten go-to-meeting customers say they close deals more than 20 percent faster.
[01:01:48.420 --> 01:01:51.660]   It is a very powerful tool.
[01:01:51.660 --> 01:01:52.660]   You will love it.
[01:01:52.660 --> 01:01:53.740]   Your clients and colleagues will love it too.
[01:01:53.740 --> 01:01:54.740]   Go to meeting.com.
[01:01:54.740 --> 01:01:56.900]   Click the "Try it Free" button.
[01:01:56.900 --> 01:01:58.300]   And we thank Go to meeting.
[01:01:58.300 --> 01:02:01.580]   They've been with us forever.
[01:02:01.580 --> 01:02:04.940]   For instance, like before the podcast.
[01:02:04.940 --> 01:02:05.940]   Seriously.
[01:02:05.940 --> 01:02:09.540]   And we thank them so much for their support this week in tech.
[01:02:09.540 --> 01:02:12.220]   Now, back to our fabulous panel.
[01:02:12.220 --> 01:02:14.340]   There's lots more to talk about, guys.
[01:02:14.340 --> 01:02:15.340]   Okay.
[01:02:15.340 --> 01:02:16.340]   Thank you.
[01:02:16.340 --> 01:02:17.340]   Go to meeting.
[01:02:17.340 --> 01:02:18.340]   I've had an account for a decade.
[01:02:18.340 --> 01:02:19.340]   I love, love go-to meeting.
[01:02:19.340 --> 01:02:21.180]   So thank you for supporting.
[01:02:21.180 --> 01:02:22.180]   Twit.
[01:02:22.180 --> 01:02:30.140]   When we left, we were talking a bit about the bizarre case of a verge employee.
[01:02:30.140 --> 01:02:33.020]   For people who don't know, verge is like the third iteration of gizmo.
[01:02:33.020 --> 01:02:35.020]   Go to an Engadget.
[01:02:35.020 --> 01:02:37.660]   It's actually the team from Engadget left Engadget.
[01:02:37.660 --> 01:02:40.740]   AOL to go start the verge.
[01:02:40.740 --> 01:02:44.100]   And a reporter there, Chris Ziegler.
[01:02:44.100 --> 01:02:45.100]   Have you ever met Chris?
[01:02:45.100 --> 01:02:46.100]   Yeah.
[01:02:46.100 --> 01:02:47.100]   You met him.
[01:02:47.100 --> 01:02:48.100]   Yeah, I had press caxes and stuff.
[01:02:48.100 --> 01:02:49.100]   Yeah.
[01:02:49.100 --> 01:02:50.100]   Okay.
[01:02:50.100 --> 01:02:51.660]   So you got your eyes rolling, Ben.
[01:02:51.660 --> 01:02:53.740]   The whole thing is, I don't know him very well.
[01:02:53.740 --> 01:02:54.740]   He always seemed nice.
[01:02:54.740 --> 01:02:56.580]   I see like a nice person.
[01:02:56.580 --> 01:03:02.780]   A former founding editor of the verge was employed at Apple this summer while he worked
[01:03:02.780 --> 01:03:08.420]   for the tech and culture website, Verge, editor in chief, Patel announced that Opalera
[01:03:08.420 --> 01:03:15.340]   Friday, my good pal, Lockhart Steele, who has the greatest name in all of publishing,
[01:03:15.340 --> 01:03:21.100]   says that there was no editorial decision that he did that had any impact.
[01:03:21.100 --> 01:03:25.140]   And they hadn't heard from him in a month.
[01:03:25.140 --> 01:03:29.180]   You have met him before, Ben, you seem to know him a little bit better.
[01:03:29.180 --> 01:03:31.260]   Ben, who is this person?
[01:03:31.260 --> 01:03:32.740]   What the hell is going on?
[01:03:32.740 --> 01:03:34.100]   Is this performance art?
[01:03:34.100 --> 01:03:36.940]   Is this like a mother Jones investigative piece where he's going to come out and say,
[01:03:36.940 --> 01:03:42.380]   like, I went to work there and I did an investigative piece and I tried to find out about the car?
[01:03:42.380 --> 01:03:43.380]   What's going on?
[01:03:43.380 --> 01:03:44.380]   It makes no sense.
[01:03:44.380 --> 01:03:45.380]   Why would somebody do something like this?
[01:03:45.380 --> 01:03:48.460]   Well, it's doubly because it's out of character for him.
[01:03:48.460 --> 01:03:49.460]   Absolutely.
[01:03:49.460 --> 01:03:50.460]   Is it?
[01:03:50.460 --> 01:03:51.460]   What's he like?
[01:03:51.460 --> 01:03:53.460]   The normal person, neurojournalist?
[01:03:53.460 --> 01:03:59.860]   Generally, yes, every time amount of, he's a really, he is a really good editor and reporter,
[01:03:59.860 --> 01:04:03.980]   at least he was, and had really thoughtful pieces.
[01:04:03.980 --> 01:04:09.340]   And you know, he's been in this industry for a decent long time, but what, like, the whole,
[01:04:09.340 --> 01:04:13.340]   I'm still trying to piece it together, especially the part where he hasn't been tweeting or saying
[01:04:13.340 --> 01:04:16.900]   a thing for 40 something days, which is extremely weird.
[01:04:16.900 --> 01:04:22.020]   Like, you know, Frank, you know, John Gruber, during fireball was looking and it could
[01:04:22.020 --> 01:04:23.940]   not find his name in the Apple director.
[01:04:23.940 --> 01:04:26.100]   And you know, he has access to everything at Apple.
[01:04:26.100 --> 01:04:29.660]   So like, there's just like, what is Gruber have no everything about Apple?
[01:04:29.660 --> 01:04:30.660]   Is he?
[01:04:30.660 --> 01:04:31.660]   He has inside.
[01:04:31.660 --> 01:04:32.660]   He's the, he's the, he's the inside.
[01:04:32.660 --> 01:04:34.900]   He's the PR machine for Apple.
[01:04:34.900 --> 01:04:40.060]   But the people at Apple, like actively support him and give him inside.
[01:04:40.060 --> 01:04:41.060]   Yes.
[01:04:41.060 --> 01:04:42.060]   Absolutely.
[01:04:42.060 --> 01:04:44.740]   Because he's just like, is he like the greatest fanboy ever?
[01:04:44.740 --> 01:04:49.100]   They know where he comes from and they trust that he'll be pro.
[01:04:49.100 --> 01:04:50.100]   He's going to be pro.
[01:04:50.100 --> 01:04:51.100]   Apple.
[01:04:51.100 --> 01:04:52.100]   So they give him access.
[01:04:52.100 --> 01:04:53.100]   Not completely pro.
[01:04:53.100 --> 01:04:54.100]   I read him.
[01:04:54.100 --> 01:04:55.100]   He's not always pro.
[01:04:55.100 --> 01:04:56.100]   Right.
[01:04:56.100 --> 01:04:57.860]   No, but he's thought, but he's consistent.
[01:04:57.860 --> 01:05:03.380]   Like there's this in Apple land, you know, one, you have to earn your right as a journalist
[01:05:03.380 --> 01:05:05.100]   to be at the events.
[01:05:05.100 --> 01:05:08.500]   It took me a few years to earn their trust to even get to the events.
[01:05:08.500 --> 01:05:17.380]   Like they're going to always go to their default.
[01:05:17.380 --> 01:05:22.420]   The secret thing makes no sense at all because the moment like Apple's not going to let somebody,
[01:05:22.420 --> 01:05:27.500]   if they knowingly know, Apple's not going to let somebody work for both a tech publication
[01:05:27.500 --> 01:05:28.500]   and Apple.
[01:05:28.500 --> 01:05:31.340]   So they would, they had no firearm if they figured that out in its.
[01:05:31.340 --> 01:05:34.500]   On a logical basis, Apple did not know.
[01:05:34.500 --> 01:05:35.540]   And a logical basis.
[01:05:35.540 --> 01:05:36.540]   Absolutely did not know.
[01:05:36.540 --> 01:05:37.540]   Yeah, they couldn't have.
[01:05:37.540 --> 01:05:38.540]   George didn't know.
[01:05:38.540 --> 01:05:40.780]   Well, so they didn't even know he was gone.
[01:05:40.780 --> 01:05:41.780]   They didn't know he was alive.
[01:05:41.780 --> 01:05:42.780]   Right.
[01:05:42.780 --> 01:05:43.780]   Well, they didn't know he was gone.
[01:05:43.780 --> 01:05:44.780]   No, they didn't know he was gone.
[01:05:44.780 --> 01:05:46.340]   So, so he was part of that second wave of Engadget, right?
[01:05:46.340 --> 01:05:47.580]   Went and founded the Verge.
[01:05:47.580 --> 01:05:50.980]   So he and Josh Topolsky, they founded, they created the Verge.
[01:05:50.980 --> 01:05:51.980]   Right.
[01:05:51.980 --> 01:05:53.180]   So it was not like he's just a hired blogger for it.
[01:05:53.180 --> 01:05:54.180]   Right.
[01:05:54.180 --> 01:05:55.180]   Right.
[01:05:55.180 --> 01:05:56.180]   And so he was there.
[01:05:56.180 --> 01:06:00.780]   And then this thing happens in June, July, July, he starts working for Apple, right?
[01:06:00.780 --> 01:06:01.780]   But then he disappears.
[01:06:01.780 --> 01:06:05.260]   So he wrote a couple of things in July, maybe then in August, they're just writing them,
[01:06:05.260 --> 01:06:06.420]   hey, dude, are you alive?
[01:06:06.420 --> 01:06:07.420]   What's going on?
[01:06:07.420 --> 01:06:08.420]   What's happening with bloggers?
[01:06:08.420 --> 01:06:10.140]   We have 100 friends in common with this guy.
[01:06:10.140 --> 01:06:11.140]   Yeah.
[01:06:11.140 --> 01:06:14.780]   So I've seen a lot of these people, Josh Topolsky, these people come out and say, like, I love
[01:06:14.780 --> 01:06:15.780]   the guy.
[01:06:15.780 --> 01:06:16.780]   I don't know what happened here.
[01:06:16.780 --> 01:06:17.780]   Break from reality.
[01:06:17.780 --> 01:06:19.460]   You know, the people on Twitter are savage.
[01:06:19.460 --> 01:06:21.660]   There's a lot of funny things about this, you know, working two jobs.
[01:06:21.660 --> 01:06:22.740]   I wish I could work at the Verge.
[01:06:22.740 --> 01:06:24.740]   It seems like they have a great, you know, policies.
[01:06:24.740 --> 01:06:27.620]   On Facebook, he still lives on his Facebook.
[01:06:27.620 --> 01:06:32.820]   His last post was June 4th and he's still this deputy editor of the Verge's.
[01:06:32.820 --> 01:06:33.820]   He was very happy.
[01:06:33.820 --> 01:06:34.820]   You know, this is actually a pretty guy.
[01:06:34.820 --> 01:06:35.820]   He's Z power on Twitter.
[01:06:35.820 --> 01:06:36.820]   He's hilarious.
[01:06:36.820 --> 01:06:37.820]   He's like, what's going on?
[01:06:37.820 --> 01:06:38.820]   It was amazing.
[01:06:38.820 --> 01:06:39.820]   Why would he not have that?
[01:06:39.820 --> 01:06:40.820]   Well, I just want to let people know now.
[01:06:40.820 --> 01:06:41.820]   I guess I got to come clean.
[01:06:41.820 --> 01:06:46.140]   I have been working for Project Titan since the beginning and we're coming out with an
[01:06:46.140 --> 01:06:48.300]   electric, a submersible car.
[01:06:48.300 --> 01:06:49.860]   It's sort of like the James Bond car.
[01:06:49.860 --> 01:06:52.100]   And what does your friend Elon say about that?
[01:06:52.100 --> 01:06:54.100]   I haven't broken a TLA.
[01:06:54.100 --> 01:06:55.100]   I'm worried.
[01:06:55.100 --> 01:06:57.660]   I'm the head of Project Titan.
[01:06:57.660 --> 01:06:59.660]   For people who don't know.
[01:06:59.660 --> 01:07:00.660]   He's still not that I could.
[01:07:00.660 --> 01:07:04.780]   For people who don't know, Jason and I were out to dinner about 10 years ago and Jason says,
[01:07:04.780 --> 01:07:06.900]   hey, you want to see the new Tesla?
[01:07:06.900 --> 01:07:09.700]   And I said, of course I want to see the new Tesla.
[01:07:09.700 --> 01:07:11.580]   Elon had only had it for two weeks.
[01:07:11.580 --> 01:07:13.980]   Yeah, it wasn't even done for one.
[01:07:13.980 --> 01:07:17.380]   It was P1, which was the first prototype.
[01:07:17.380 --> 01:07:18.380]   He had P1.
[01:07:18.380 --> 01:07:20.820]   Yeah, two weeks after he got it.
[01:07:20.820 --> 01:07:21.820]   Yeah.
[01:07:21.820 --> 01:07:22.820]   Nobody knew.
[01:07:22.820 --> 01:07:26.380]   You had a Corvette and then he says to you, let's race.
[01:07:26.380 --> 01:07:27.380]   Right.
[01:07:27.380 --> 01:07:29.780]   And that's the legend, right?
[01:07:29.780 --> 01:07:30.780]   Well, this idiot.
[01:07:30.780 --> 01:07:34.380]   Because he blew you away and then you turn around and goes, buys a Tesla.
[01:07:34.380 --> 01:07:36.260]   You were like one of the first customers because that's right.
[01:07:36.260 --> 01:07:39.100]   Well, we were driving well within the speed limit.
[01:07:39.100 --> 01:07:40.100]   No, we weren't.
[01:07:40.100 --> 01:07:41.100]   And the 405.
[01:07:41.100 --> 01:07:43.100]   They got the videos gone.
[01:07:43.100 --> 01:07:46.540]   Yeah, but this idiot takes out his Nokia 451.
[01:07:46.540 --> 01:07:48.540]   What was that?
[01:07:48.540 --> 01:07:49.540]   The 1095.
[01:07:49.540 --> 01:07:54.340]   And 95, which at the time had quick, which was the first streaming video.
[01:07:54.340 --> 01:07:55.820]   It was basically like all the streaming video stuff.
[01:07:55.820 --> 01:07:56.820]   10 years ago.
[01:07:56.820 --> 01:07:57.820]   It barely worked.
[01:07:57.820 --> 01:07:58.820]   Yeah.
[01:07:58.820 --> 01:07:59.820]   But there we were.
[01:07:59.820 --> 01:08:02.020]   We had 1000 people watching us live broadcasting.
[01:08:02.020 --> 01:08:03.020]   Yeah.
[01:08:03.020 --> 01:08:04.020]   It was hilarious.
[01:08:04.020 --> 01:08:07.420]   People didn't know who Tesla was at the time, but yes, it's true.
[01:08:07.420 --> 01:08:08.700]   Elon was not Elon.
[01:08:08.700 --> 01:08:10.820]   It was just small letters.
[01:08:10.820 --> 01:08:11.820]   It is.
[01:08:11.820 --> 01:08:12.820]   Yeah.
[01:08:12.820 --> 01:08:13.820]   What was it?
[01:08:13.820 --> 01:08:15.140]   That was this kid with this guy.
[01:08:15.140 --> 01:08:17.460]   And I don't know if I must have met him.
[01:08:17.460 --> 01:08:19.300]   I don't think he was at Engagit when I was there.
[01:08:19.300 --> 01:08:22.020]   But I hope he's okay.
[01:08:22.020 --> 01:08:23.020]   Number one.
[01:08:23.020 --> 01:08:27.180]   And I hope if it is mental illness or some break from reality, I hope he gets help.
[01:08:27.180 --> 01:08:30.140]   Otherwise I hope some of his friends have been able to.
[01:08:30.140 --> 01:08:32.500]   Well, you know, it's also it goes to this whole trolling thing, right?
[01:08:32.500 --> 01:08:35.340]   Like we're all sitting here laughing about it because it is bizarre and it's unique.
[01:08:35.340 --> 01:08:37.940]   But maybe the person is suffering and maybe there's something going on like that.
[01:08:37.940 --> 01:08:41.740]   And you know, in that case, you know, it's great fodder for around table discussion, but
[01:08:41.740 --> 01:08:46.260]   I hope he's sincerely hope he's okay, which basically means I'm a 45 year old kids now
[01:08:46.260 --> 01:08:48.780]   that I'm not just making fun of him relentlessly.
[01:08:48.780 --> 01:08:51.500]   It is bizarre and sad, but I just hope he's okay.
[01:08:51.500 --> 01:08:59.060]   I don't think it really matters too much what it does show that some journalism outlets
[01:08:59.060 --> 01:09:01.780]   really take their ethics seriously.
[01:09:01.780 --> 01:09:06.100]   And that's a hard thing to do when you're getting free phones, right?
[01:09:06.100 --> 01:09:07.100]   Well, sure.
[01:09:07.100 --> 01:09:14.540]   I mean, listen, some the idea that tech journalism is honest and upfront.
[01:09:14.540 --> 01:09:15.540]   We know that train.
[01:09:15.540 --> 01:09:16.540]   We all are in the business.
[01:09:16.540 --> 01:09:18.300]   We know that train left the station a long time ago.
[01:09:18.300 --> 01:09:23.540]   The number of people who are doing it right is greatly outnumbered by the people who are
[01:09:23.540 --> 01:09:24.540]   doing it wrong.
[01:09:24.540 --> 01:09:26.900]   We all agree on that.
[01:09:26.900 --> 01:09:28.540]   I mean, people who do actual fact-checking.
[01:09:28.540 --> 01:09:30.540]   Well, no, I'm talking about fact-checking.
[01:09:30.540 --> 01:09:34.780]   You have tech crunch releasing a story that like, you know, Google bought a company for
[01:09:34.780 --> 01:09:37.260]   600 billion because they took it off the press wire and they don't even call.
[01:09:37.260 --> 01:09:41.700]   I mean, journalists don't have the time to make phone calls to check or call sources
[01:09:41.700 --> 01:09:42.700]   anymore.
[01:09:42.700 --> 01:09:44.780]   They just write posts without talking to anybody.
[01:09:44.780 --> 01:09:45.780]   It's madness.
[01:09:45.780 --> 01:09:46.780]   Yeah.
[01:09:46.780 --> 01:09:53.100]   More sources faster times, less work on little things like grammar and big things like fact-checking.
[01:09:53.100 --> 01:09:54.100]   Yeah.
[01:09:54.100 --> 01:09:56.220]   Less work on grammar and spelling.
[01:09:56.220 --> 01:09:57.220]   Less work on fact-checking.
[01:09:57.220 --> 01:09:58.980]   And then also- Speed matters.
[01:09:58.980 --> 01:10:00.820]   Speed matters a lot in this business.
[01:10:00.820 --> 01:10:04.260]   You know, I was the first person to tell Twitter that Steve Jobs had died.
[01:10:04.260 --> 01:10:05.260]   Why?
[01:10:05.260 --> 01:10:11.300]   Because Apple called Reuters and ABC Radio, ABC first.
[01:10:11.300 --> 01:10:16.460]   And I was listening to ABC Radio and they came on and they said, "We just got a note
[01:10:16.460 --> 01:10:18.420]   from Apple that Steve Jobs has died."
[01:10:18.420 --> 01:10:19.420]   I pulled over.
[01:10:19.420 --> 01:10:20.420]   It took me two minutes.
[01:10:20.420 --> 01:10:23.580]   Somebody had tweeted that Steve Jobs died.
[01:10:23.580 --> 01:10:24.580]   Who was that?
[01:10:24.580 --> 01:10:25.580]   The woman from-
[01:10:25.580 --> 01:10:26.580]   It took me two minutes to pull over.
[01:10:26.580 --> 01:10:30.660]   I called Steve Gilmore and told him.
[01:10:30.660 --> 01:10:36.340]   And then I posted to Twitter, ABC Radio just reported that Steve Jobs had died.
[01:10:36.340 --> 01:10:41.300]   And the number of retweets I got on that was extraordinary.
[01:10:41.300 --> 01:10:44.020]   And we know Speed matters in some things like this.
[01:10:44.020 --> 01:10:45.020]   It builds brands.
[01:10:45.020 --> 01:10:46.660]   It builds audiences.
[01:10:46.660 --> 01:10:49.860]   And so there's a lot of pressure to be first versus be right.
[01:10:49.860 --> 01:10:55.460]   Let me ask a serious question because we talk about Steve and obviously he's a big figure
[01:10:55.460 --> 01:10:58.260]   and cast a big shadow.
[01:10:58.260 --> 01:11:04.980]   How much different would Apple's fate be right now in terms of what we saw in the last launch?
[01:11:04.980 --> 01:11:07.100]   Just its prominence in the industry.
[01:11:07.100 --> 01:11:08.340]   How different would it be?
[01:11:08.340 --> 01:11:10.100]   10% different, 100% different.
[01:11:10.100 --> 01:11:11.260]   What do you think?
[01:11:11.260 --> 01:11:18.140]   I think you've got to live three more years to answer that question properly because if
[01:11:18.140 --> 01:11:20.380]   Tim Cook does what I'm thinking he's going to do.
[01:11:20.380 --> 01:11:21.820]   You think he's going to drop the microphone?
[01:11:21.820 --> 01:11:22.820]   Like just boom.
[01:11:22.820 --> 01:11:24.540]   He's going to drop so much knowledge and so much product.
[01:11:24.540 --> 01:11:25.540]   It's going to be blown away.
[01:11:25.540 --> 01:11:28.340]   Because it's the 10th anniversary of the iPhone next year.
[01:11:28.340 --> 01:11:30.500]   It's really an important year for Apple.
[01:11:30.500 --> 01:11:33.500]   And Huawei is chasing them really fast.
[01:11:33.500 --> 01:11:34.500]   This company is not--
[01:11:34.500 --> 01:11:39.700]   Would you say iPhone 7 was the worst launch of the iPhone ever?
[01:11:39.700 --> 01:11:41.500]   If you had to rank that.
[01:11:41.500 --> 01:11:44.300]   Well, I'm talking based on history the other side.
[01:11:44.300 --> 01:11:45.540]   I'm not talking on sales.
[01:11:45.540 --> 01:11:46.540]   I'm talking on products.
[01:11:46.540 --> 01:11:49.580]   There's nothing in here calling my name saying why aren't you using this?
[01:11:49.580 --> 01:11:50.580]   So therefore it is.
[01:11:50.580 --> 01:11:55.100]   Maybe it is a little bit worse than yours is because I don't have it set up yet.
[01:11:55.100 --> 01:11:57.380]   It's not calling my name like previous tries.
[01:11:57.380 --> 01:11:59.100]   iOS 10, same thing.
[01:11:59.100 --> 01:12:00.100]   Same thing, right?
[01:12:00.100 --> 01:12:01.100]   It's not it.
[01:12:01.100 --> 01:12:02.100]   It's a sleeper.
[01:12:02.100 --> 01:12:04.300]   It's an Apple fall through as a peak smartphone.
[01:12:04.300 --> 01:12:06.180]   Is there nothing left to get out of it?
[01:12:06.180 --> 01:12:09.140]   Is it just that we've reached like the PC did and eventually like--
[01:12:09.140 --> 01:12:10.140]   I can see.
[01:12:10.140 --> 01:12:11.620]   You know, it's as big as it's going to get.
[01:12:11.620 --> 01:12:17.300]   A huge number of innovations coming in the next 18 months to both Android and iPhone.
[01:12:17.300 --> 01:12:18.300]   VR be--
[01:12:18.300 --> 01:12:22.580]   You're getting 3D sensors that map the world in 3D and you're going to get augmented reality
[01:12:22.580 --> 01:12:27.980]   because the GPU in this phone is 10 times faster than the GPU in the Huawei phone which
[01:12:27.980 --> 01:12:29.740]   also has dual camera.
[01:12:29.740 --> 01:12:32.980]   And that's the number three manufacturer in the world.
[01:12:32.980 --> 01:12:35.740]   That GPU is going to matter to virtual reality.
[01:12:35.740 --> 01:12:39.540]   They're coming out with eye sensors that are going to watch where your eyes look and
[01:12:39.540 --> 01:12:44.860]   it's going to enable a new kind of rendering, a new kind of compression called foveated rendering
[01:12:44.860 --> 01:12:50.540]   where it only needs to un-compress all the polygons and all the bitmaps where you're
[01:12:50.540 --> 01:12:51.540]   looking.
[01:12:51.540 --> 01:12:54.100]   Everything else can remain a little bit blurry.
[01:12:54.100 --> 01:12:55.100]   And so the GPU--
[01:12:55.100 --> 01:12:57.020]   So it sharpens where your eyes are focused.
[01:12:57.020 --> 01:13:02.540]   The problem with VR right now is if you play Samsung's Gear VR, mine only can play for
[01:13:02.540 --> 01:13:03.540]   40 minutes.
[01:13:03.540 --> 01:13:04.540]   It overheats.
[01:13:04.540 --> 01:13:07.860]   It overheats and the phone goes off and the battery dies because it's sucking as much
[01:13:07.860 --> 01:13:11.620]   battery as possible because the GPU is underpowered.
[01:13:11.620 --> 01:13:16.980]   So this phone, I can see Apple coming out with a bunch of innovations for the phone.
[01:13:16.980 --> 01:13:18.460]   And so is Google.
[01:13:18.460 --> 01:13:22.060]   Google on October 4th this year is going to come out with some of these innovations,
[01:13:22.060 --> 01:13:23.060]   right?
[01:13:23.060 --> 01:13:25.620]   Now Google came out with-- it's a good segue here to jump off on.
[01:13:25.620 --> 01:13:29.900]   Google came out with their own WhatsApp, I guess, or their own telegram.
[01:13:29.900 --> 01:13:31.300]   No, no, no, no.
[01:13:31.300 --> 01:13:32.540]   It's-- Alo is different.
[01:13:32.540 --> 01:13:33.780]   It's more smart assistant.
[01:13:33.780 --> 01:13:34.780]   Okay.
[01:13:34.780 --> 01:13:38.980]   So they have a smart messaging app that has a smart assistant and explain what Alo is.
[01:13:38.980 --> 01:13:39.980]   A-L-L-O.
[01:13:39.980 --> 01:13:40.980]   I mean--
[01:13:40.980 --> 01:13:42.820]   And is it important or not?
[01:13:42.820 --> 01:13:45.700]   It's less like-- Google already has.
[01:13:45.700 --> 01:13:48.860]   It's a messaging platform that's like hangouts.
[01:13:48.860 --> 01:13:50.500]   They already have messaging.
[01:13:50.500 --> 01:13:55.340]   Alo is more like the M of Facebook's M or your Siri or--
[01:13:55.340 --> 01:13:56.340]   Explain what that is to you.
[01:13:56.340 --> 01:13:57.340]   What it's that doesn't know Facebook yet.
[01:13:57.340 --> 01:14:04.340]   I mean, it's a kind of chatbot in the sense that what Alo is doing is helping you with
[01:14:04.340 --> 01:14:07.380]   different tasks, is understanding you.
[01:14:07.380 --> 01:14:10.700]   It's less about WhatsApp communication from one person to another.
[01:14:10.700 --> 01:14:14.420]   At least from what I've known, I've only played with it just in brief bits and pieces.
[01:14:14.420 --> 01:14:16.420]   Because I don't have an Android.
[01:14:16.420 --> 01:14:17.420]   I'm just going to use--
[01:14:17.420 --> 01:14:18.420]   Are we going to play the video?
[01:14:18.420 --> 01:14:19.420]   I was going to play the video, yeah.
[01:14:19.420 --> 01:14:20.420]   Let's play the video.
[01:14:20.420 --> 01:14:21.420]   Watch it.
[01:14:21.420 --> 01:14:22.420]   [LAUGHTER]
[01:14:22.420 --> 01:14:23.420]   Play the music.
[01:14:23.420 --> 01:14:24.420]   [MUSIC PLAYING]
[01:14:24.420 --> 01:14:25.420]   But--
[01:14:25.420 --> 01:14:28.900]   So there's definitely messaging in it.
[01:14:28.900 --> 01:14:29.900]   It's fun messaging.
[01:14:29.900 --> 01:14:32.140]   Like all the iMessage auditions, right?
[01:14:32.140 --> 01:14:35.340]   But the problem, the thing that's biting them is they kind of came out and said, "We're
[01:14:35.340 --> 01:14:36.340]   going to encrypt it all.
[01:14:36.340 --> 01:14:37.340]   It's going to be fine.
[01:14:37.340 --> 01:14:38.580]   It's going to be like a Snapchat, right?
[01:14:38.580 --> 01:14:39.580]   Nobody can see your stuff."
[01:14:39.580 --> 01:14:42.380]   And they said, "Oh, wait a minute for us to help you with all the stuff you're saying.
[01:14:42.380 --> 01:14:44.020]   We have to listen to everything and then store it."
[01:14:44.020 --> 01:14:45.020]   Yeah, of course.
[01:14:45.020 --> 01:14:46.020]   So they backpedaled on all that.
[01:14:46.020 --> 01:14:50.220]   But also because they have a secret deal with the White House in order to not have the
[01:14:50.220 --> 01:14:54.380]   antitrust come down too hard on them that they're going to give back doors to everything
[01:14:54.380 --> 01:14:55.380]   in the White House.
[01:14:55.380 --> 01:15:00.780]   According, allegedly, from people I know who are smart, that there's some sort of relationship
[01:15:00.780 --> 01:15:04.980]   between Google and this White House, where it's a very cozy relationship.
[01:15:04.980 --> 01:15:08.700]   Google went to visit the White House a lot in the Obama administration.
[01:15:08.700 --> 01:15:15.220]   And they believe that the reason a lot of the FTC investigations got canned on Google
[01:15:15.220 --> 01:15:19.860]   for antitrust were because of the back doors and a lot of the helping them.
[01:15:19.860 --> 01:15:25.780]   This is a conspiracy theory, but there's a lot of smoke around this conspiracy theory.
[01:15:25.780 --> 01:15:28.540]   So they had to think of aloes like a combination.
[01:15:28.540 --> 01:15:31.420]   You're seeing this more in a lot of messaging products.
[01:15:31.420 --> 01:15:33.540]   Yes, there's the messaging and there's the fun stuff.
[01:15:33.540 --> 01:15:38.300]   But it has smart assistant, it has the Google assistant in there to add context into part
[01:15:38.300 --> 01:15:39.300]   of the conversation.
[01:15:39.300 --> 01:15:40.540]   Shopping, yes.
[01:15:40.540 --> 01:15:44.260]   Or locations, or suggestions.
[01:15:44.260 --> 01:15:48.420]   And I don't like in the end, the only thing you really care about in messaging is scale.
[01:15:48.420 --> 01:15:50.460]   Like why do you use Facebook Messenger?
[01:15:50.460 --> 01:15:51.460]   All your friends are on it.
[01:15:51.460 --> 01:15:54.940]   Why do you use WeChat, your friends in China are on it.
[01:15:54.940 --> 01:15:56.700]   But the smart assistant thing is happening more.
[01:15:56.700 --> 01:15:59.180]   The chat bot, whatever you want to call that.
[01:15:59.180 --> 01:16:07.380]   LinkedIn on Friday, a couple days ago had the launch of their bot, in bot.
[01:16:07.380 --> 01:16:09.180]   Oh really?
[01:16:09.180 --> 01:16:12.820]   So the in bot will go and delete all the incoming spam I have in my email.
[01:16:12.820 --> 01:16:14.980]   It just says yes to everything.
[01:16:14.980 --> 01:16:20.180]   I mean, literally the signal to noise ratio on LinkedIn is literally 0% signal.
[01:16:20.180 --> 01:16:23.820]   I can almost guarantee if you're emailing me through LinkedIn or messaging me through
[01:16:23.820 --> 01:16:26.060]   LinkedIn, it is not in my best interest.
[01:16:26.060 --> 01:16:29.380]   Every influencer post you write there, I like it and I share it.
[01:16:29.380 --> 01:16:30.380]   Which is amazing.
[01:16:30.380 --> 01:16:32.860]   There's parts of LinkedIn that are amazing.
[01:16:32.860 --> 01:16:38.020]   But the email system, the fact that they're overhauling it, they know it's not great.
[01:16:38.020 --> 01:16:39.020]   It's so horrible.
[01:16:39.020 --> 01:16:42.860]   It's not that it's bad, it's that it's horrible.
[01:16:42.860 --> 01:16:46.460]   It's literally like, I guess because they let people pay to email people who are not
[01:16:46.460 --> 01:16:48.140]   interested in the problem.
[01:16:48.140 --> 01:16:55.100]   So 100% of people who email me are literally trying to waste my time with something.
[01:16:55.100 --> 01:16:57.260]   It's just like, really?
[01:16:57.260 --> 01:17:01.780]   Are you not able to guess first name at whatever company name I work at?
[01:17:01.780 --> 01:17:04.780]   Or any of the 10 emails I put you at number one.
[01:17:04.780 --> 01:17:08.020]   This is the perfect time for you to plug lead IQ by the way.
[01:17:08.020 --> 01:17:12.300]   Well anyway, putting it aside, LinkedIn obviously is the directory of everything.
[01:17:12.300 --> 01:17:18.300]   But I just think it's just wacky, that that email even exists and that people think that
[01:17:18.300 --> 01:17:21.180]   it's working or something to get to me or to other people.
[01:17:21.180 --> 01:17:22.500]   Maybe it's because I'm a super router.
[01:17:22.500 --> 01:17:23.500]   Do you have this problem?
[01:17:23.500 --> 01:17:24.500]   Or do you even check your email?
[01:17:24.500 --> 01:17:28.020]   I said I decided like an hour and I just do it.
[01:17:28.020 --> 01:17:29.020]   You know what I mean?
[01:17:29.020 --> 01:17:30.020]   I don't respond to things like that.
[01:17:30.020 --> 01:17:33.580]   Have you ever had something come through email that is of high quality?
[01:17:33.580 --> 01:17:34.580]   I have.
[01:17:34.580 --> 01:17:36.180]   But it's very small percentage.
[01:17:36.180 --> 01:17:37.180]   Yeah.
[01:17:37.180 --> 01:17:38.180]   Compared to the same.
[01:17:38.180 --> 01:17:41.060]   I have to read 100 weird stupid things for the one.
[01:17:41.060 --> 01:17:48.180]   I have a really good idea for this which is they should let you have your first year.
[01:17:48.180 --> 01:17:50.460]   And I think they were going to do this with a report of which I was an investor in at
[01:17:50.460 --> 01:17:51.460]   some point.
[01:17:51.460 --> 01:17:56.300]   They should let you have your name at LinkedIn, mail.com or something like that.
[01:17:56.300 --> 01:17:57.940]   It wouldn't be a proper mail client.
[01:17:57.940 --> 01:18:00.100]   But have it just sort in tabs.
[01:18:00.100 --> 01:18:01.460]   These are people you don't know.
[01:18:01.460 --> 01:18:02.540]   These are people you're friends with.
[01:18:02.540 --> 01:18:04.260]   And just make it super clear.
[01:18:04.260 --> 01:18:05.580]   It's two different groups of people.
[01:18:05.580 --> 01:18:08.780]   I know that this business model is predicated on people to get to you.
[01:18:08.780 --> 01:18:10.580]   But it's gotten so overwrought.
[01:18:10.580 --> 01:18:11.780]   They do that on Facebook already.
[01:18:11.780 --> 01:18:12.780]   Yes.
[01:18:12.780 --> 01:18:13.780]   And so there's this hidden inbox.
[01:18:13.780 --> 01:18:14.780]   Yes.
[01:18:14.780 --> 01:18:15.780]   And you go there and there's something four years old.
[01:18:15.780 --> 01:18:17.780]   You're like, oh my God, I wish I'd seen that.
[01:18:17.780 --> 01:18:18.780]   You never even see that.
[01:18:18.780 --> 01:18:22.940]   Like Facebook has the three inboxes and it works really.
[01:18:22.940 --> 01:18:24.220]   It works as a system.
[01:18:24.220 --> 01:18:25.220]   Yes.
[01:18:25.220 --> 01:18:26.540]   And Gmail does it and it works well too.
[01:18:26.540 --> 01:18:29.020]   It's like here's forums and here's whatever.
[01:18:29.020 --> 01:18:34.420]   I think that you will see that happen with LinkedIn over the next 12 months and they see
[01:18:34.420 --> 01:18:35.420]   that.
[01:18:35.420 --> 01:18:36.580]   As Microsoft takes it up.
[01:18:36.580 --> 01:18:37.580]   Yes.
[01:18:37.580 --> 01:18:40.500]   As Microsoft embeds more of their attack into it.
[01:18:40.500 --> 01:18:42.340]   Messaging is important to Microsoft.
[01:18:42.340 --> 01:18:51.300]   OK, Samsung has 25% of their explosive phones being exchanged and they're giving people
[01:18:51.300 --> 01:18:53.620]   a super notice on this.
[01:18:53.620 --> 01:18:57.460]   When you go, I have to say, I think Samsung's doing the right thing here.
[01:18:57.460 --> 01:18:59.020]   They really have gone over the top.
[01:18:59.020 --> 01:19:02.860]   When you plug in your Samsung phone, if it's one of the ones that were, and Samsung 7S
[01:19:02.860 --> 01:19:05.900]   was the best phone reviewed ever in the history of all smartphones.
[01:19:05.900 --> 01:19:07.860]   So it's actually kind of a bummer for them I think.
[01:19:07.860 --> 01:19:10.900]   I feel bad for them because it really hurts them.
[01:19:10.900 --> 01:19:11.900]   It really is like--
[01:19:11.900 --> 01:19:13.900]   It's VR too because it keeps--
[01:19:13.900 --> 01:19:15.780]   You're going to put your phone on your face.
[01:19:15.780 --> 01:19:16.780]   Right, yeah, right.
[01:19:16.780 --> 01:19:17.780]   In front of your eyes.
[01:19:17.780 --> 01:19:18.780]   Oh, yeah, yeah.
[01:19:18.780 --> 01:19:19.780]   Let me know.
[01:19:19.780 --> 01:19:20.780]   Think about that.
[01:19:20.780 --> 01:19:21.780]   Wow.
[01:19:21.780 --> 01:19:22.780]   That's about.
[01:19:22.780 --> 01:19:23.780]   Got you.
[01:19:23.780 --> 01:19:24.780]   Got goggles between you and your phone.
[01:19:24.780 --> 01:19:25.780]   Oh, God.
[01:19:25.780 --> 01:19:26.780]   We just when we were starting to get comfortable with our phones.
[01:19:26.780 --> 01:19:27.780]   But they--
[01:19:27.780 --> 01:19:28.780]   But that message and then only charging at 80%.
[01:19:28.780 --> 01:19:29.780]   What other things are they doing?
[01:19:29.780 --> 01:19:30.780]   By the way, my friend and you--
[01:19:30.780 --> 01:19:31.780]   Oh, they're only charging at 80%.
[01:19:31.780 --> 01:19:32.780]   Yeah, that's what it's just smart.
[01:19:32.780 --> 01:19:35.540]   It won't let you make it so bad.
[01:19:35.540 --> 01:19:36.540]   Yeah.
[01:19:36.540 --> 01:19:38.620]   My friend-- that's one temporary fix.
[01:19:38.620 --> 01:19:44.100]   My friend who Andy Grignon who worked on the first iPhone team says he guarantees me
[01:19:44.100 --> 01:19:50.260]   Apple is spending thousands of hours rechecking all of their battery suppliers and data and
[01:19:50.260 --> 01:19:52.260]   making sure their phone doesn't do the same thing.
[01:19:52.260 --> 01:19:53.260]   Now what happened?
[01:19:53.260 --> 01:19:54.660]   Does anybody know the core of it?
[01:19:54.660 --> 01:19:56.460]   There was some foil between the batteries and--
[01:19:56.460 --> 01:19:57.460]   No, no.
[01:19:57.460 --> 01:20:00.460]   Lithium-ion batteries can explode if you need to.
[01:20:00.460 --> 01:20:01.460]   Well, we all know that.
[01:20:01.460 --> 01:20:03.060]   But there was some defect, right?
[01:20:03.060 --> 01:20:04.460]   There's a defect in the software.
[01:20:04.460 --> 01:20:06.860]   There's a defect in the manufacturing somewhere.
[01:20:06.860 --> 01:20:10.580]   There's a specific in the hardware in the software.
[01:20:10.580 --> 01:20:11.580]   Yeah.
[01:20:11.580 --> 01:20:13.740]   So there's the anode of lithium-ion batteries.
[01:20:13.740 --> 01:20:14.740]   Yeah.
[01:20:14.740 --> 01:20:17.500]   And then there's the middle-- I can't remember what you call the middle, the Permian barrier
[01:20:17.500 --> 01:20:20.580]   that prevents it to.
[01:20:20.580 --> 01:20:26.060]   If once you have a puncture or an issue with it, then when they-- you have a short circuit
[01:20:26.060 --> 01:20:32.700]   and that's what can cause the thermal-- whatever you call it-- the thermal cascade, that's what
[01:20:32.700 --> 01:20:33.700]   it's called.
[01:20:33.700 --> 01:20:34.700]   I think they're going to rebound.
[01:20:34.700 --> 01:20:35.700]   I mean, I know it's terrible.
[01:20:35.700 --> 01:20:36.700]   They have to replace them.
[01:20:36.700 --> 01:20:37.700]   It's going to cost them a lot of money.
[01:20:37.700 --> 01:20:38.700]   But they have a ton of money.
[01:20:38.700 --> 01:20:39.700]   And so I think they're rebound.
[01:20:39.700 --> 01:20:44.940]   Somebody who I think will never rebound at this point is Yahoo.
[01:20:44.940 --> 01:20:50.620]   Hundreds of millions of people had their-- I think it's 500 million--
[01:20:50.620 --> 01:20:51.620]   Yeah, 517 or something.
[01:20:51.620 --> 01:20:52.620]   The largest hack.
[01:20:52.620 --> 01:20:54.620]   The largest hack by a magnitude.
[01:20:54.620 --> 01:20:55.620]   Yeah.
[01:20:55.620 --> 01:20:57.700]   And it had people's security questions, data, birth passwords.
[01:20:57.700 --> 01:20:59.660]   I mean, it had everything.
[01:20:59.660 --> 01:21:06.700]   And they knew about it supposedly in 2014 and did not inform their users?
[01:21:06.700 --> 01:21:12.420]   Is that even possible that Marissa would do something so incredibly irresponsible and
[01:21:12.420 --> 01:21:13.420]   dumb?
[01:21:13.420 --> 01:21:15.700]   I mean, I'm not saying Marissa's dumb.
[01:21:15.700 --> 01:21:17.500]   I'm saying this is a dumb decision.
[01:21:17.500 --> 01:21:18.500]   I have to be careful.
[01:21:18.500 --> 01:21:20.300]   I don't want to ruin all my relationships.
[01:21:20.300 --> 01:21:22.620]   But I'm kind of not ship-as-sale at this point.
[01:21:22.620 --> 01:21:26.460]   I mean, this is-- I mean, it's one thing for Marissa to not have done a great job as CEO
[01:21:26.460 --> 01:21:34.300]   there and not been focused and gotten-- but to hide a hack, if that's in fact what happened.
[01:21:34.300 --> 01:21:40.100]   It seems like that's where the evidence is suggesting that they actively hit a hack.
[01:21:40.100 --> 01:21:46.140]   What is the liability on actively hiding a hack where people could have changed their
[01:21:46.140 --> 01:21:47.140]   passwords?
[01:21:47.140 --> 01:21:51.020]   I mean, it's beyond materially significant Omega project in the chat room.
[01:21:51.020 --> 01:21:55.900]   It sounds like a whole chapter in a NBA book in about 10 years.
[01:21:55.900 --> 01:21:57.820]   Now the Verizon deal is--
[01:21:57.820 --> 01:21:58.820]   How about that?
[01:21:58.820 --> 01:22:01.460]   Could be at stake.
[01:22:01.460 --> 01:22:07.700]   So does this mean that-- because I wonder if this ever got to the board level.
[01:22:07.700 --> 01:22:10.740]   So they've said recently the last couple days that there was something they only knew
[01:22:10.740 --> 01:22:11.740]   about recently.
[01:22:11.740 --> 01:22:12.740]   It was brought to them to the right.
[01:22:12.740 --> 01:22:15.940]   There was some team knew about it, but not like the people selling it to Verizon.
[01:22:15.940 --> 01:22:17.420]   That sounds like a huge lie.
[01:22:17.420 --> 01:22:18.420]   Right.
[01:22:18.420 --> 01:22:21.180]   Number one, that sounds like your analysis of the accounts.
[01:22:21.180 --> 01:22:24.580]   And even if it's not a lie, you're supposed to know you're supposed to have a security
[01:22:24.580 --> 01:22:25.580]   policy.
[01:22:25.580 --> 01:22:26.900]   You have a security policy.
[01:22:26.900 --> 01:22:28.900]   That major hacks went to the board level.
[01:22:28.900 --> 01:22:30.540]   The board is supposed to know.
[01:22:30.540 --> 01:22:37.020]   So if the board knew and didn't do this, that would be fraud, which means massive shareholder
[01:22:37.020 --> 01:22:38.020]   lawsuits.
[01:22:38.020 --> 01:22:39.020]   I mean, it would be actor fraud.
[01:22:39.020 --> 01:22:41.700]   It could be criminal fraud if they subverted this.
[01:22:41.700 --> 01:22:46.020]   I don't want to say-- I don't want to-- because we're on my relationship with anybody.
[01:22:46.020 --> 01:22:47.300]   But we do need more details.
[01:22:47.300 --> 01:22:51.180]   We need more details because we don't know the extent or how long they actually knew
[01:22:51.180 --> 01:22:56.620]   and which parts and which divisions all we know is there was a clear security, like
[01:22:56.620 --> 01:23:00.980]   enormous security breach that affects hundreds of millions of people.
[01:23:00.980 --> 01:23:05.700]   Their email accounts or Flickr accounts, very personal accounts.
[01:23:05.700 --> 01:23:09.340]   And like it just-- we're hearing about this just happened more and more.
[01:23:09.340 --> 01:23:15.620]   And the standard-- one, the standard for internet security is just horrendous in general.
[01:23:15.620 --> 01:23:19.820]   And just two, like it won't affect Verizon will still acquire that.
[01:23:19.820 --> 01:23:20.820]   It's still acquire Yahoo.
[01:23:20.820 --> 01:23:22.500]   Oh, it's got to cut half the price off.
[01:23:22.500 --> 01:23:23.500]   But it's good.
[01:23:23.500 --> 01:23:24.500]   What's the liability?
[01:23:24.500 --> 01:23:25.500]   A couple of dollars per user?
[01:23:25.500 --> 01:23:26.500]   I don't know.
[01:23:26.500 --> 01:23:28.380]   Billion dollar lawsuits everywhere.
[01:23:28.380 --> 01:23:29.380]   It's huge.
[01:23:29.380 --> 01:23:31.540]   And God knows why they did it.
[01:23:31.540 --> 01:23:37.660]   I had another friend who has a service that is a DNS service.
[01:23:37.660 --> 01:23:42.100]   And I asked him, why do you keep showing ISIS to the world?
[01:23:42.100 --> 01:23:45.940]   And he says, the government asked me not to shut it down.
[01:23:45.940 --> 01:23:47.620]   Is there something like this going on?
[01:23:47.620 --> 01:23:48.620]   I don't know.
[01:23:48.620 --> 01:23:49.620]   Oh, wow.
[01:23:49.620 --> 01:23:50.620]   So how we--
[01:23:50.620 --> 01:23:51.620]   So how we--
[01:23:51.620 --> 01:23:52.620]   How we really--
[01:23:52.620 --> 01:23:53.620]   On top of it.
[01:23:53.620 --> 01:23:54.620]   How we really--
[01:23:54.620 --> 01:23:56.020]   Well, they did like to-- I mean, let's be honest.
[01:23:56.020 --> 01:24:00.660]   What we learned from the Snowden releases-- and listen, I'm no fan of--
[01:24:00.660 --> 01:24:02.380]   They didn't say which state sponsored it.
[01:24:02.380 --> 01:24:03.380]   Right?
[01:24:03.380 --> 01:24:04.900]   They said it's a state sponsored hacking.
[01:24:04.900 --> 01:24:05.900]   Is it state sponsored?
[01:24:05.900 --> 01:24:06.900]   Yeah.
[01:24:06.900 --> 01:24:07.900]   That's what they said.
[01:24:07.900 --> 01:24:08.900]   They said which state, though.
[01:24:08.900 --> 01:24:11.620]   And if the Chinese are using something, we are, too.
[01:24:11.620 --> 01:24:12.620]   Right.
[01:24:12.620 --> 01:24:17.020]   Well, it's getting very interesting because if you think about the leaks coming out of
[01:24:17.020 --> 01:24:29.420]   WikiLeaks or all anti-democratic party, anti-Hillary, and they seem to be Russian-based, and Trump
[01:24:29.420 --> 01:24:33.220]   is got relationships with the Russians, a lot of investors.
[01:24:33.220 --> 01:24:35.020]   I have a relationship with the Russians.
[01:24:35.020 --> 01:24:36.020]   And the Russians--
[01:24:36.020 --> 01:24:37.020]   Well--
[01:24:37.020 --> 01:24:38.020]   And the Russians--
[01:24:38.020 --> 01:24:39.020]   Well--
[01:24:39.020 --> 01:24:40.020]   The Russian's had dinner with the Boris Yeltsin team the other day.
[01:24:40.020 --> 01:24:41.020]   Really?
[01:24:41.020 --> 01:24:42.020]   Yeah.
[01:24:42.020 --> 01:24:43.020]   And this guy is there running his foundation.
[01:24:43.020 --> 01:24:44.020]   I have a relationship with pierogies.
[01:24:44.020 --> 01:24:45.020]   This may or not.
[01:24:45.020 --> 01:24:46.020]   This may or not.
[01:24:46.020 --> 01:24:47.020]   This is a relationship with the Russians.
[01:24:47.020 --> 01:24:49.740]   A little bit of vodka.
[01:24:49.740 --> 01:24:54.500]   It does seem like our election--
[01:24:54.500 --> 01:24:59.180]   Forget about all of our personal effects and what we have in our Flickr accounts.
[01:24:59.180 --> 01:25:02.540]   It feels like the election is being impacted deeply by this hacking.
[01:25:02.540 --> 01:25:10.220]   I mean, Bernie Sanders, the Democrats actively subverted his candidacy and maybe cost him
[01:25:10.220 --> 01:25:11.220]   the candidacy.
[01:25:11.220 --> 01:25:12.220]   I don't know if that's actually correct or not.
[01:25:12.220 --> 01:25:13.220]   I probably wouldn't have won anyway.
[01:25:13.220 --> 01:25:14.220]   But it's pretty dark day.
[01:25:14.220 --> 01:25:20.740]   The extent of hacking impacting the world is getting very severe.
[01:25:20.740 --> 01:25:22.100]   It's not changing-- is it changing behavior?
[01:25:22.100 --> 01:25:26.620]   I mean, I now am setting massively long hashes for every--
[01:25:26.620 --> 01:25:27.620]   One of the reasons I have--
[01:25:27.620 --> 01:25:28.620]   --and different passwords on everything.
[01:25:28.620 --> 01:25:31.380]   One of the reasons-- when I get a new phone, I start out clean.
[01:25:31.380 --> 01:25:33.180]   I don't bring a backup over.
[01:25:33.180 --> 01:25:37.180]   I reset up all the apps and I change my passwords.
[01:25:37.180 --> 01:25:41.900]   And I really think through my passwords, my security profile.
[01:25:41.900 --> 01:25:43.700]   Two factor authentication on everything.
[01:25:43.700 --> 01:25:45.420]   A separate password for everything.
[01:25:45.420 --> 01:25:46.420]   A separate password for everything.
[01:25:46.420 --> 01:25:47.420]   If you're listening to this--
[01:25:47.420 --> 01:25:48.420]   Long password everything.
[01:25:48.420 --> 01:25:49.900]   --and you don't have two factor.
[01:25:49.900 --> 01:25:52.980]   You don't use a password manager that suggests long hashes.
[01:25:52.980 --> 01:25:53.980]   You have to--
[01:25:53.980 --> 01:25:55.620]   Even a password manager is a weakness, though, right?
[01:25:55.620 --> 01:25:56.620]   It's a single point of failure.
[01:25:56.620 --> 01:25:57.620]   It's a single point of failure.
[01:25:57.620 --> 01:25:58.620]   It's a single point of failure.
[01:25:58.620 --> 01:26:02.580]   But it's very hard to get into, especially if you have two factor on.
[01:26:02.580 --> 01:26:05.940]   My friend Steve Ball runs the identity team at Microsoft.
[01:26:05.940 --> 01:26:10.260]   And he says within five years he's going to get rid of passwords.
[01:26:10.260 --> 01:26:13.660]   And he has a variety of techniques that they're going to do to get rid of passwords.
[01:26:13.660 --> 01:26:15.660]   First of all, they're going to have eye sensors, right?
[01:26:15.660 --> 01:26:16.660]   And they're going to take a picture of your eyes.
[01:26:16.660 --> 01:26:18.660]   And they're just going to know it's Jason Calicana.
[01:26:18.660 --> 01:26:19.660]   It'll know.
[01:26:19.660 --> 01:26:20.660]   Because your eyes have a fingerprint.
[01:26:20.660 --> 01:26:23.660]   Minority report or mission impossible.
[01:26:23.660 --> 01:26:28.660]   And then they're going to use the different devices you wear on you to evaluate that it's
[01:26:28.660 --> 01:26:30.660]   you because your phone never gives you.
[01:26:30.660 --> 01:26:31.660]   But there's a--
[01:26:31.660 --> 01:26:34.660]   Can I just note though, there is a different security issue with that.
[01:26:34.660 --> 01:26:39.660]   And that's the security issue you saw with the government wanting to unlock that iPhone
[01:26:39.660 --> 01:26:41.660]   with, you know, like with fingerprints.
[01:26:41.660 --> 01:26:46.660]   And like if you want to keep your iPhone away from the government, don't put your fingerprint
[01:26:46.660 --> 01:26:49.660]   on it because they can force you to do the fingerprint, but they can't force you to type
[01:26:49.660 --> 01:26:50.660]   in the password.
[01:26:50.660 --> 01:26:56.660]   Get the $16,000 phone which has its own kernel inside that is shut off from the rest of the
[01:26:56.660 --> 01:26:58.660]   world and you can do conversations.
[01:26:58.660 --> 01:27:00.660]   I mean, this is how the--
[01:27:00.660 --> 01:27:02.660]   Only $16,000.
[01:27:02.660 --> 01:27:07.660]   But you are-- if you're a CEO of Apple and you don't want China to get into your secrets
[01:27:07.660 --> 01:27:13.660]   when you're sending information back home, which they're doing, right?
[01:27:13.660 --> 01:27:15.660]   They steal everything this way.
[01:27:15.660 --> 01:27:21.660]   You want top-rate encryption and you want a fingerprint that-- I'm sorry.
[01:27:21.660 --> 01:27:23.660]   You want a surface area that's really shut down.
[01:27:23.660 --> 01:27:25.660]   It shuts off the sensors on the phone, right?
[01:27:25.660 --> 01:27:28.660]   Did you see Mark Zuckerberg puts a piece of tape over and over?
[01:27:28.660 --> 01:27:29.660]   You can't remember it.
[01:27:29.660 --> 01:27:30.660]   I don't.
[01:27:30.660 --> 01:27:31.660]   I don't.
[01:27:31.660 --> 01:27:32.660]   Hey NSA, what's it going on?
[01:27:32.660 --> 01:27:35.660]   I'm actually going to put the tape on it very soon.
[01:27:35.660 --> 01:27:41.660]   Yeah, but that's what you're doing is reducing the surface area of attack on you.
[01:27:41.660 --> 01:27:42.660]   Yeah.
[01:27:42.660 --> 01:27:45.660]   You're removing sensors from possibly them being attacked.
[01:27:45.660 --> 01:27:46.660]   And this is a problem.
[01:27:46.660 --> 01:27:50.660]   This is going to be a deep problem for society for a long time because we're about to get
[01:27:50.660 --> 01:27:51.660]   cars they're going to self-drive.
[01:27:51.660 --> 01:27:56.660]   We're getting all sorts of digital information that runs our supply chains in our world, right?
[01:27:56.660 --> 01:27:57.660]   All right.
[01:27:57.660 --> 01:28:00.660]   When we get back from this final break, we're going to keep moving through the most important
[01:28:00.660 --> 01:28:07.660]   issues of our day, including Tesla is releasing their 8.0 software, which has a couple of
[01:28:07.660 --> 01:28:08.660]   really clever features.
[01:28:08.660 --> 01:28:11.660]   I'm downloading it tonight and actually have it set up to do that because they're rolling
[01:28:11.660 --> 01:28:14.660]   it out slowly now, not a lot at once.
[01:28:14.660 --> 01:28:20.660]   And Uber self-driving vehicles have been spotted on the streets of San Francisco, not just
[01:28:20.660 --> 01:28:21.660]   on the test on the East Coast.
[01:28:21.660 --> 01:28:29.660]   And we're going to ask our panelists to tell us when will the majority of rides in San
[01:28:29.660 --> 01:28:34.660]   Francisco be driven with level four autonomy?
[01:28:34.660 --> 01:28:35.660]   In other words, no steering wheel.
[01:28:35.660 --> 01:28:37.660]   When we get back on this weekend tech.
[01:28:37.660 --> 01:28:41.660]   Our show today brought to you by Gazelle.
[01:28:41.660 --> 01:28:42.660]   This is the season, isn't it?
[01:28:42.660 --> 01:28:43.660]   All the new phones.
[01:28:43.660 --> 01:28:51.660]   We're going to have, there's the new pixels from Google probably coming out next week.
[01:28:51.660 --> 01:28:54.660]   We got a new iPhone.
[01:28:54.660 --> 01:28:56.660]   Maybe you're ready for a new phone.
[01:28:56.660 --> 01:29:02.660]   The problem is, you know, I find, and I bet a lot of people do, the old phone works fine.
[01:29:02.660 --> 01:29:06.660]   You want the new stuff, you want the new features, but the old phone works fine and it's hard
[01:29:06.660 --> 01:29:07.660]   to justify the expense.
[01:29:07.660 --> 01:29:09.660]   That's why I love Gazelle.
[01:29:09.660 --> 01:29:14.660]   Gazelle is a place you can go and sell your old stuff to finance the new stuff and that
[01:29:14.660 --> 01:29:16.660]   makes it so easy.
[01:29:16.660 --> 01:29:21.660]   You don't have time to, you know, put a listing up and sell it and deal with the buyers and
[01:29:21.660 --> 01:29:22.660]   the phone calls.
[01:29:22.660 --> 01:29:23.660]   I mean, maybe you do.
[01:29:23.660 --> 01:29:26.660]   But with Gazelle, it's very straightforward.
[01:29:26.660 --> 01:29:27.660]   Go right now.
[01:29:27.660 --> 01:29:29.660]   Gazelle.com, so you got an iPhone 6.
[01:29:29.660 --> 01:29:34.660]   Find out what it's worth.
[01:29:34.660 --> 01:29:37.660]   That by the way is guaranteed for 30 days, that price.
[01:29:37.660 --> 01:29:41.660]   So now's the time to do it, even if you don't have your iPhone yet.
[01:29:41.660 --> 01:29:47.660]   Or you don't know if you're going to get a new Pixel phone because you have 30 days.
[01:29:47.660 --> 01:29:51.660]   So this will take you into the end of the month and then you can decide.
[01:29:51.660 --> 01:29:54.660]   You get the, by then you'll have the phone if you want it.
[01:29:54.660 --> 01:29:56.660]   If not, no harm, no foul, no commitment.
[01:29:56.660 --> 01:29:59.660]   The only commitment is on their part to pay you that amount of money.
[01:29:59.660 --> 01:30:00.660]   And you've got 30 days.
[01:30:00.660 --> 01:30:05.660]   Once you do get your new phone, you've transferred the data over, you like it, it's all working.
[01:30:05.660 --> 01:30:06.660]   Then you pull the trigger.
[01:30:06.660 --> 01:30:07.660]   Gazelle send you a box.
[01:30:07.660 --> 01:30:10.660]   They do all the shipping for free.
[01:30:10.660 --> 01:30:12.660]   You pile that gadget in.
[01:30:12.660 --> 01:30:13.660]   In fact, pile all your gadgets in.
[01:30:13.660 --> 01:30:14.660]   Get rid of them all.
[01:30:14.660 --> 01:30:15.660]   Clean out your drawers.
[01:30:15.660 --> 01:30:17.660]   There's money in those drawers.
[01:30:17.660 --> 01:30:18.660]   Send it to Gazelle.
[01:30:18.660 --> 01:30:20.660]   They'll wipe the data if you forget to.
[01:30:20.660 --> 01:30:22.660]   They even buy broken iPads and iPhones.
[01:30:22.660 --> 01:30:23.660]   They buy tablets.
[01:30:23.660 --> 01:30:24.660]   They buy computers.
[01:30:24.660 --> 01:30:25.660]   They buy screens.
[01:30:25.660 --> 01:30:27.660]   A large variety of stuff.
[01:30:27.660 --> 01:30:29.660]   A G-A-Z-E-L-L-E.
[01:30:29.660 --> 01:30:30.660]   By the way, they also sell.
[01:30:30.660 --> 01:30:35.660]   So if you lose a phone or you want to get a less expensive phone for your kids, Gazelle's
[01:30:35.660 --> 01:30:39.660]   a great place to get a gently used certified pre-owned.
[01:30:39.660 --> 01:30:42.660]   When I say certified, I mean it, they run it through a very rigorous check.
[01:30:42.660 --> 01:30:47.660]   30 point check, even things like scratches to make sure that phone is fully functional.
[01:30:47.660 --> 01:30:49.660]   Works in all the major carriers.
[01:30:49.660 --> 01:30:51.180]   No carrier contract though, see?
[01:30:51.180 --> 01:30:53.060]   So it's a good deal.
[01:30:53.060 --> 01:30:55.500]   And you can get a financing on checkout from a firm.
[01:30:55.500 --> 01:30:58.460]   You can get a warranty from a shurrent.
[01:30:58.460 --> 01:31:01.660]   Covers even things like cracked screens and water damage.
[01:31:01.660 --> 01:31:07.540]   Gazelle is really now full service for buying and for selling everything you need.
[01:31:07.540 --> 01:31:08.980]   Check it out.
[01:31:08.980 --> 01:31:13.940]   The new gadgets are here, which means you can get a great deal on a pre-owned gadget.
[01:31:13.940 --> 01:31:17.820]   That means a lot of people selling their iPhone successes, for instance.
[01:31:17.820 --> 01:31:20.220]   You can go in there and get a new one.
[01:31:20.220 --> 01:31:23.820]   Who needs a new, you know, it's got a headphone jack still.
[01:31:23.820 --> 01:31:29.020]   Gazelle, G-A-Z-E-L-L-E Gazelle.com to buy our cell.
[01:31:29.020 --> 01:31:34.220]   Now back we go to Twitch already in progress.
[01:31:34.220 --> 01:31:36.020]   Previously on Twitch.
[01:31:36.020 --> 01:31:37.020]   I drag it.
[01:31:37.020 --> 01:31:39.020]   And then I pin to zoom it.
[01:31:39.020 --> 01:31:40.420]   To zoom it, yeah.
[01:31:40.420 --> 01:31:42.220]   Get used to think, yeah, yeah.
[01:31:42.220 --> 01:31:43.220]   Ah.
[01:31:43.220 --> 01:31:44.220]   There we go.
[01:31:44.220 --> 01:31:45.220]   Oh wait.
[01:31:45.220 --> 01:31:46.220]   Okay.
[01:31:46.220 --> 01:31:51.740]   I am so glad I went to college.
[01:31:51.740 --> 01:31:52.740]   This week in Google.
[01:31:52.740 --> 01:31:56.780]   Hello is Google's kind of smart chat app.
[01:31:56.780 --> 01:31:59.980]   And it is now a thing that you can download on Android and iOS.
[01:31:59.980 --> 01:32:00.980]   I was downtown.
[01:32:00.980 --> 01:32:02.820]   What founders where I put in lunch?
[01:32:02.820 --> 01:32:03.820]   Quest Mart.
[01:32:03.820 --> 01:32:04.820]   It responded, let's find you something to eat.
[01:32:04.820 --> 01:32:06.580]   By the way, what kinds of food do you like?
[01:32:06.580 --> 01:32:07.580]   Oh, what is it?
[01:32:07.580 --> 01:32:08.580]   I'm gonna try fish.
[01:32:08.580 --> 01:32:10.620]   Red Lobster and Bubba Gum Shrimp Company.
[01:32:10.620 --> 01:32:11.620]   Jesus Google.
[01:32:11.620 --> 01:32:16.180]   Surely if you know me this well, you know I'm a classier guy than that.
[01:32:16.180 --> 01:32:17.380]   Windows weekly.
[01:32:17.380 --> 01:32:20.020]   You actually still can get Windows 10 as a free upgrade.
[01:32:20.020 --> 01:32:26.540]   You just have to use your existing Windows 7 or 8.1 product key and you can still unlock
[01:32:26.540 --> 01:32:30.340]   the free upgrade, which is something Microsoft's not actively advertising.
[01:32:30.340 --> 01:32:36.420]   This is actually a huge opportunity for us because I know Alex has been trying to update
[01:32:36.420 --> 01:32:38.420]   the Tri-Castor to Windows 10.
[01:32:38.420 --> 01:32:39.420]   I think Audrey, let me correct you.
[01:32:39.420 --> 01:32:40.660]   I really hope that nothing.
[01:32:40.660 --> 01:32:41.660]   Oh crap.
[01:32:41.660 --> 01:32:43.500]   Oh, you next time.
[01:32:43.500 --> 01:32:48.500]   Quit.
[01:32:48.500 --> 01:32:50.500]   Leo says hi.
[01:32:50.500 --> 01:32:53.500]   How do I know that this graphic has been used more gleefully on Macbreak Weekly and...
[01:32:53.500 --> 01:32:54.500]   Okay, hold on.
[01:32:54.500 --> 01:32:55.500]   Let me just, let me kick the track.
[01:32:55.500 --> 01:32:56.500]   Oh, okay.
[01:32:56.500 --> 01:32:57.500]   See, that's all you need.
[01:32:57.500 --> 01:32:58.500]   Hey, thanks Jason.
[01:32:58.500 --> 01:33:01.500]   Here's a look at a few things that we'll be keeping an eye on in the week ahead.
[01:33:01.500 --> 01:33:06.660]   On Monday, September 26th, a number of sites including YouTube, Facebook and Twitter will
[01:33:06.660 --> 01:33:09.420]   be streaming the first of three presidential debates.
[01:33:09.420 --> 01:33:16.100]   There will even be a virtual reality feed, courtesy of NBC starting at 8.30 p.m. Eastern
[01:33:16.100 --> 01:33:17.100]   time.
[01:33:17.100 --> 01:33:22.780]   On Tuesday, September 27th, Elon Musk will explain to everyone how he hopes to use SpaceX to colonize
[01:33:22.780 --> 01:33:29.480]   Mars someday during the Making Humans a Multi-Planitary Species keynote at the annual International
[01:33:29.480 --> 01:33:33.140]   Astronautical Congress in Guadalajara, Mexico.
[01:33:33.140 --> 01:33:38.460]   On Wednesday, September 28th, Samsung will resume sales of its Galaxy Note 7 after a tumultuous
[01:33:38.460 --> 01:33:42.500]   month of recalls thanks to its fiery battery debacle.
[01:33:42.500 --> 01:33:47.540]   Sales will begin in South Korea and will resume in other markets as conditions allow.
[01:33:47.540 --> 01:33:51.940]   And on Friday, September 30th, readability, a pretty popular read-it-later bookmarking
[01:33:51.940 --> 01:33:55.420]   service will be shutting down after five years in the business.
[01:33:55.420 --> 01:33:59.100]   You'll want to save out your bookmarks before that happens and they give you the tools to
[01:33:59.100 --> 01:34:00.860]   do so on their site.
[01:34:00.860 --> 01:34:05.700]   Mega Moroni and I cover all of this and more all week, every week on Tech News today, so
[01:34:05.700 --> 01:34:06.700]   don't miss it.
[01:34:06.700 --> 01:34:07.700]   Have a look at the week ahead.
[01:34:07.700 --> 01:34:08.700]   Back to you, Jason.
[01:34:08.700 --> 01:34:09.700]   All right, listen.
[01:34:09.700 --> 01:34:10.700]   I'm obviously conflicted.
[01:34:10.700 --> 01:34:15.940]   I'm a shareholder in Uber.
[01:34:15.940 --> 01:34:20.180]   And their self-driving vehicles have been spotted on the streets of San Francisco, not
[01:34:20.180 --> 01:34:22.500]   just Pittsburgh.
[01:34:22.500 --> 01:34:28.080]   Everybody knows they built a huge team of people, or may or may or may not know, from
[01:34:28.080 --> 01:34:34.020]   Carnegie Mellon's University's Robotic Center and they deployed a fleet of 14 Ford Fusions
[01:34:34.020 --> 01:34:36.060]   with radar cameras and all that kind of stuff.
[01:34:36.060 --> 01:34:38.260]   Obviously, they have a driver in the car.
[01:34:38.260 --> 01:34:40.780]   This is part of their beta.
[01:34:40.780 --> 01:34:45.220]   But these cars are now been seen in San Francisco.
[01:34:45.220 --> 01:34:52.100]   So Robert, obviously, self-driving cars, we're seeing massive progress.
[01:34:52.100 --> 01:34:59.740]   Google seems to have taken, I would think, the wrong route in waiting to deploy this and
[01:34:59.740 --> 01:35:02.260]   going with extremely expensive LiDAR systems.
[01:35:02.260 --> 01:35:07.020]   It seems like Uber and Tesla now are getting out there and getting much more real world
[01:35:07.020 --> 01:35:08.380]   experience.
[01:35:08.380 --> 01:35:14.220]   Why is Google so far behind why are Uber and Tesla seem to be so far behind?
[01:35:14.220 --> 01:35:16.220]   Don't assume they're far behind.
[01:35:16.220 --> 01:35:17.220]   I had dinner.
[01:35:17.220 --> 01:35:19.220]   But don't there seem to be a cost of $50,000?
[01:35:19.220 --> 01:35:21.060]   It doesn't matter.
[01:35:21.060 --> 01:35:27.260]   You know, technology gets really cheap, really fast when the numbers come up.
[01:35:27.260 --> 01:35:33.220]   I had dinner with Peter Norvick who runs Google's R&D about two weeks ago and he told me, he
[01:35:33.220 --> 01:35:38.300]   asked me, "Why do you think Google made the little self-driving cars, those little bubble
[01:35:38.300 --> 01:35:40.980]   cars that can only go 25 miles an hour?"
[01:35:40.980 --> 01:35:42.780]   And I said, "I have no idea why."
[01:35:42.780 --> 01:35:48.340]   And he said, "Because when we started handing the full-size Lexuses out with all the LiDARs
[01:35:48.340 --> 01:35:49.340]   to the employees--"
[01:35:49.340 --> 01:35:50.340]   Scared people?
[01:35:50.340 --> 01:35:52.220]   No, no, to the employees.
[01:35:52.220 --> 01:35:57.340]   We had them sign a form that said that you will be fired if you take your attention away
[01:35:57.340 --> 01:35:59.940]   from the road and from this machine driving.
[01:35:59.940 --> 01:36:02.180]   And what do they do?
[01:36:02.180 --> 01:36:06.260]   Keep in mind, they had to sign a form and you will be fired if you do this.
[01:36:06.260 --> 01:36:07.260]   Right.
[01:36:07.260 --> 01:36:11.620]   And there's a camera right here watching you and the sensors on the steering wheel that
[01:36:11.620 --> 01:36:12.620]   know you.
[01:36:12.620 --> 01:36:16.340]   They lose their job and they know they're under surveillance and these are highly intelligent
[01:36:16.340 --> 01:36:17.340]   Google employees.
[01:36:17.340 --> 01:36:18.340]   What do they do?
[01:36:18.340 --> 01:36:21.500]   Every single employee broke the role within three days.
[01:36:21.500 --> 01:36:22.500]   Why?
[01:36:22.500 --> 01:36:24.860]   Because it's so amazing.
[01:36:24.860 --> 01:36:25.860]   I'm sorry.
[01:36:25.860 --> 01:36:26.860]   It's freaking amazing.
[01:36:26.860 --> 01:36:30.260]   We'll have to take a timestamp at 131 and 48 seconds.
[01:36:30.260 --> 01:36:32.860]   So it gets so--
[01:36:32.860 --> 01:36:36.940]   You change your behavior because of technology.
[01:36:36.940 --> 01:36:40.060]   And this is a mistake that people in the industry make over and over and over again.
[01:36:40.060 --> 01:36:41.780]   I can't believe these Google employees.
[01:36:41.780 --> 01:36:42.780]   These people are idiots.
[01:36:42.780 --> 01:36:43.780]   No, they're not idiots because--
[01:36:43.780 --> 01:36:47.020]   I have self-driving level 2 in my Tesla.
[01:36:47.020 --> 01:36:48.740]   I've never taken my eyes off the road.
[01:36:48.740 --> 01:36:50.660]   You don't have a Google one.
[01:36:50.660 --> 01:36:53.220]   The Google one is three years ahead of Yvonne.
[01:36:53.220 --> 01:36:54.860]   It's three years ahead of Mercedes.
[01:36:54.860 --> 01:36:56.700]   It's three years ahead of everybody.
[01:36:56.700 --> 01:37:03.300]   And it is already so amazing that when you are threatened with being fired, you get bored
[01:37:03.300 --> 01:37:04.940]   watching the machine work.
[01:37:04.940 --> 01:37:06.500]   It is so good.
[01:37:06.500 --> 01:37:10.780]   And your phone rings or something goes being and all of a sudden you're looking at the
[01:37:10.780 --> 01:37:14.260]   phone and that's much more interesting than watching the car drive around.
[01:37:14.260 --> 01:37:15.940]   And today the little cars drive around.
[01:37:15.940 --> 01:37:17.380]   They don't have steering wheels.
[01:37:17.380 --> 01:37:20.180]   The ones I saw in Mountain View just a couple of days ago.
[01:37:20.180 --> 01:37:22.820]   They don't have-- you just ride in them and they take you places.
[01:37:22.820 --> 01:37:24.340]   But they go 25 miles an hour.
[01:37:24.340 --> 01:37:26.060]   Why 25 miles an hour?
[01:37:26.060 --> 01:37:31.660]   Because the lawyers were willing to take risk that a machine would do a mistake and
[01:37:31.660 --> 01:37:33.540]   hit somebody and hurt somebody.
[01:37:33.540 --> 01:37:34.540]   But not kill them.
[01:37:34.540 --> 01:37:35.540]   Not kill them.
[01:37:35.540 --> 01:37:39.060]   25 miles an hour is infast enough to kill a human being, particularly if you have airbags
[01:37:39.060 --> 01:37:41.860]   and other things to slow you down.
[01:37:41.860 --> 01:37:48.380]   And by the way, it's not going to ever-- it's going to kill people at very low rates.
[01:37:48.380 --> 01:37:51.940]   Things kill each other at 900,000 miles approximately, right?
[01:37:51.940 --> 01:37:54.780]   Once every 900,000 miles a human dies.
[01:37:54.780 --> 01:37:59.140]   Tesla killed somebody at 1.3 million miles on the first one.
[01:37:59.140 --> 01:38:02.900]   It's going to be 4 million on the second one and 8 million on the third one.
[01:38:02.900 --> 01:38:03.900]   Yeah, obviously.
[01:38:03.900 --> 01:38:04.860]   And by the way, the person who died--
[01:38:04.860 --> 01:38:06.540]   Who she was learning was not looking at all.
[01:38:06.540 --> 01:38:11.540]   The person who died was apparently-- listen, it's tragic, but this person was a super fan
[01:38:11.540 --> 01:38:15.820]   and was known to watch movies while using it.
[01:38:15.820 --> 01:38:19.260]   And this witnesses say it was watching Harry Potter, which, by the way, I don't mean to
[01:38:19.260 --> 01:38:22.060]   make light of it, but if you're going to die for a movie, that's the worst one I could
[01:38:22.060 --> 01:38:23.060]   ever think of.
[01:38:23.060 --> 01:38:25.060]   I mean, I know that's kind of dark, but--
[01:38:25.060 --> 01:38:26.540]   Was that too dark for us?
[01:38:26.540 --> 01:38:28.860]   Wow, I just lost the entire audience.
[01:38:28.860 --> 01:38:32.260]   And then really, that was a terrible story.
[01:38:32.260 --> 01:38:34.260]   I mean, no Oscars.
[01:38:34.260 --> 01:38:40.140]   We also assume that Google invested in self-driving cars to build self-driving cars.
[01:38:40.140 --> 01:38:46.380]   The technology of actually building a self-driving car pays many benefits to Google.
[01:38:46.380 --> 01:38:48.100]   Yes, they want people to do search.
[01:38:48.100 --> 01:38:49.100]   But they all want people to--
[01:38:49.100 --> 01:38:50.100]   No, like patents.
[01:38:50.100 --> 01:38:53.420]   I mean, they have a patent library now that they can license to all the other people,
[01:38:53.420 --> 01:38:54.420]   right?
[01:38:54.420 --> 01:38:55.420]   Yeah, sure.
[01:38:55.420 --> 01:38:56.820]   And second of all, it's training on us.
[01:38:56.820 --> 01:39:02.940]   They're parking it next to a school yard, for instance, to teach what a child looks like
[01:39:02.940 --> 01:39:07.260]   and what the behavior of a child looks like so that when it sees a child, it'll stop,
[01:39:07.260 --> 01:39:08.260]   right, in the future.
[01:39:08.260 --> 01:39:10.260]   Like the software is going to change the ball.
[01:39:10.260 --> 01:39:14.220]   Learning a lot about us, a scary amount about us.
[01:39:14.220 --> 01:39:19.180]   And keep in mind, maybe it's for the glasses, because the glasses have the same eyes that
[01:39:19.180 --> 01:39:20.820]   the self-driving car has on it.
[01:39:20.820 --> 01:39:22.380]   It has those two sensors, right?
[01:39:22.380 --> 01:39:26.700]   So look, Google is to clearly, I think, does have the best tech out of everybody.
[01:39:26.700 --> 01:39:31.820]   But everyone else is beating them to the commercial punch, for whatever reason.
[01:39:31.820 --> 01:39:33.420]   That area is a real problem with that.
[01:39:33.420 --> 01:39:35.900]   The Uber car has a human still in the car.
[01:39:35.900 --> 01:39:38.060]   It's not yet delivered.
[01:39:38.060 --> 01:39:40.420]   The full-- but you need to have that out there.
[01:39:40.420 --> 01:39:41.420]   They need to have that car.
[01:39:41.420 --> 01:39:42.820]   Yes, because they're training in too.
[01:39:42.820 --> 01:39:43.820]   They're training in.
[01:39:43.820 --> 01:39:44.820]   And it's not just them.
[01:39:44.820 --> 01:39:47.460]   It's like, you know, it's its general motors, it's all the others.
[01:39:47.460 --> 01:39:48.460]   Yes.
[01:39:48.460 --> 01:39:49.460]   Brian Avi, I want you to set the line.
[01:39:49.460 --> 01:39:51.860]   Let's see if you can do it here.
[01:39:51.860 --> 01:39:56.020]   When will the majority-- and it's very important when you're gambling, everybody knows this
[01:39:56.020 --> 01:40:01.140]   to be have very clear lines set, so we don't have-- after the fact people crying-- about
[01:40:01.140 --> 01:40:02.460]   losing a lot of money.
[01:40:02.460 --> 01:40:11.660]   When will the majority of rides, not cars, but rides, rides in San Francisco and the
[01:40:11.660 --> 01:40:14.100]   Bay Area, San Francisco Bay Area?
[01:40:14.100 --> 01:40:21.180]   When will the majority of the rides, 51%, what year will 51% of the rides be level four
[01:40:21.180 --> 01:40:22.180]   autonomous?
[01:40:22.180 --> 01:40:23.180]   To the year.
[01:40:23.180 --> 01:40:24.180]   Oh, that's good.
[01:40:24.180 --> 01:40:25.180]   2025.
[01:40:25.180 --> 01:40:27.180]   How did you get that ride?
[01:40:27.180 --> 01:40:28.180]   That's nine years from the--
[01:40:28.180 --> 01:40:29.180]   Mine is 2026, but it's--
[01:40:29.180 --> 01:40:30.180]   Really?
[01:40:30.180 --> 01:40:31.180]   No, 2025.
[01:40:31.180 --> 01:40:34.620]   2025, because 2025 is the future.
[01:40:34.620 --> 01:40:35.620]   You know?
[01:40:35.620 --> 01:40:37.620]   Technically speaking, 2020 is the whole idea of future.
[01:40:37.620 --> 01:40:38.620]   I was going to say that about 2020, but--
[01:40:38.620 --> 01:40:40.620]   Right, not 2020 is not the future anymore.
[01:40:40.620 --> 01:40:41.620]   That's like hindsight.
[01:40:41.620 --> 01:40:42.620]   But 2025?
[01:40:42.620 --> 01:40:43.620]   Okay.
[01:40:43.620 --> 01:40:44.620]   Yeah, 2025.
[01:40:44.620 --> 01:40:48.660]   And I think it's going to actually happen through weird sort of like land grabs where like all
[01:40:48.660 --> 01:40:50.900]   the buses convert and all of something else convert.
[01:40:50.900 --> 01:40:55.340]   Yes, because all the buses will really push a lot of people to self-driving, right?
[01:40:55.340 --> 01:40:56.340]   Sure.
[01:40:56.340 --> 01:40:57.340]   So if all those corporate buses--
[01:40:57.340 --> 01:40:59.420]   Well, it was 50% more than 50%.
[01:40:59.420 --> 01:41:01.140]   51% of the rides.
[01:41:01.140 --> 01:41:02.140]   Will be.
[01:41:02.140 --> 01:41:04.140]   So you can do it by autonomous.
[01:41:04.140 --> 01:41:05.140]   Ah, ah, ah.
[01:41:05.140 --> 01:41:07.140]   Bodies, total bodies that move around in the city and in a vehicle.
[01:41:07.140 --> 01:41:08.140]   Right.
[01:41:08.140 --> 01:41:10.140]   If you said 50% of the Uber rides, I would say--
[01:41:10.140 --> 01:41:11.620]   No, no, 51% of rides.
[01:41:11.620 --> 01:41:13.380]   So that means all rides.
[01:41:13.380 --> 01:41:19.140]   First of all, let's say every car and every new car instantly just right now became self-driving.
[01:41:19.140 --> 01:41:20.140]   Right.
[01:41:20.140 --> 01:41:24.900]   It still would take 12 years for all of the-- most of the cars on the road to turn over.
[01:41:24.900 --> 01:41:25.900]   To turn over, we know that.
[01:41:25.900 --> 01:41:28.860]   But not if they wall off the city and outlaw non-self-driving cars.
[01:41:28.860 --> 01:41:29.860]   Okay.
[01:41:29.860 --> 01:41:32.860]   So that would happen until a percentage gets built.
[01:41:32.860 --> 01:41:39.780]   But do we all agree that the government will at some point say you are not allowed to drive
[01:41:39.780 --> 01:41:40.940]   your car on these roads.
[01:41:40.940 --> 01:41:43.220]   If you want to drive your car, go to a private road.
[01:41:43.220 --> 01:41:46.220]   You have to be autonomous on the four or five attacks.
[01:41:46.220 --> 01:41:47.220]   No.
[01:41:47.220 --> 01:41:48.220]   Yes, eventually.
[01:41:48.220 --> 01:41:49.220]   Eventually.
[01:41:49.220 --> 01:41:50.220]   Well, let's align on that.
[01:41:50.220 --> 01:41:51.220]   Yeah, like Bloomberg in New York City.
[01:41:51.220 --> 01:41:52.220]   If you're going to drive in, you get taxed.
[01:41:52.220 --> 01:41:53.220]   You get the same.
[01:41:53.220 --> 01:41:54.220]   30 years from now.
[01:41:54.220 --> 01:41:55.220]   30 years from now.
[01:41:55.220 --> 01:41:56.220]   You're going to need a couple of these conversion rates.
[01:41:56.220 --> 01:41:57.220]   20, 35.
[01:41:57.220 --> 01:41:58.220]   20, 35.
[01:41:58.220 --> 01:41:59.220]   All right, 20 years.
[01:41:59.220 --> 01:42:03.500]   I think that's going to be really-- what's that?
[01:42:03.500 --> 01:42:04.660]   Red Bartlett and the Rush song.
[01:42:04.660 --> 01:42:06.660]   They don't actually drive cars anymore.
[01:42:06.660 --> 01:42:07.660]   Oh, really?
[01:42:07.660 --> 01:42:09.420]   And if the kids deals his uncle's car out of the garage and goes on a joint ride.
[01:42:09.420 --> 01:42:10.420]   Is that what that is?
[01:42:10.420 --> 01:42:11.420]   Yeah, Rush particularly.
[01:42:11.420 --> 01:42:12.420]   Oh, the general tab is talking about it.
[01:42:12.420 --> 01:42:13.420]   Oh, really?
[01:42:13.420 --> 01:42:14.420]   That's funny.
[01:42:14.420 --> 01:42:17.980]   I think that's really interesting because I think what will happen is they'll just pick
[01:42:17.980 --> 01:42:19.500]   one parallel highway.
[01:42:19.500 --> 01:42:24.260]   So in San Francisco, that'd be like 280 is autonomous, 101 is not.
[01:42:24.260 --> 01:42:29.100]   And then everyone's going to go, oh my god, on the 280, no idiots are fender-bendering.
[01:42:29.100 --> 01:42:33.540]   Everybody can go 15 miles faster.
[01:42:33.540 --> 01:42:34.540]   Things are in trains.
[01:42:34.540 --> 01:42:38.700]   Which isn't true because the cars are programmed to follow the rules.
[01:42:38.700 --> 01:42:39.700]   So it won't do anything.
[01:42:39.700 --> 01:42:42.740]   Well, but I think when I change the rules on that highway then because we're like, listen,
[01:42:42.740 --> 01:42:46.340]   there's no chance of a sitting, then the whole idea of being a car length for every
[01:42:46.340 --> 01:42:47.980]   10 miles per mile makes no sense.
[01:42:47.980 --> 01:42:54.060]   There's a great video from CGP Grey, one of my favorite YouTubers who does a detailed
[01:42:54.060 --> 01:42:59.020]   video of how with cars and self-driving, how they would change the interactions and how
[01:42:59.020 --> 01:43:03.580]   much faster would be because part of what happens with a lot of traffic is the chain
[01:43:03.580 --> 01:43:04.740]   reaction.
[01:43:04.740 --> 01:43:06.740]   You can avoid the entire chain reaction.
[01:43:06.740 --> 01:43:07.740]   Of course.
[01:43:07.740 --> 01:43:09.220]   And it explains it.
[01:43:09.220 --> 01:43:11.700]   Humans will never be able to avoid the chain reaction.
[01:43:11.700 --> 01:43:15.260]   Our reaction times just are not as good as machines can be.
[01:43:15.260 --> 01:43:18.220]   But also, at least people changing lanes constantly.
[01:43:18.220 --> 01:43:27.260]   Words head of safety told me they instrumented the fleets that they sell cars to and they
[01:43:27.260 --> 01:43:32.940]   found that 80% of humans do not fully break into an accident.
[01:43:32.940 --> 01:43:33.940]   Into an accident.
[01:43:33.940 --> 01:43:34.940]   Of course.
[01:43:34.940 --> 01:43:36.420]   You're about to hit something and you still haven't.
[01:43:36.420 --> 01:43:41.700]   Because you are scared of the impact of the fully breaking, right?
[01:43:41.700 --> 01:43:46.460]   That and you just don't have the reaction times to start getting into a new still texting
[01:43:46.460 --> 01:43:48.060]   or whatever.
[01:43:48.060 --> 01:43:52.620]   And in fact, this is where it's going to cause some accidents to self-driving cars technology.
[01:43:52.620 --> 01:43:55.820]   Because it can stop and it will stop.
[01:43:55.820 --> 01:44:01.820]   In fact, modern cars, even cars that don't have self-driving technologies are already
[01:44:01.820 --> 01:44:03.620]   helping you break.
[01:44:03.620 --> 01:44:08.340]   If you're on a freeway and you have your foot on the gas pedal all the way to 80 miles
[01:44:08.340 --> 01:44:12.420]   at 80 miles an hour and you take it off and you push hard on the brake, it knows you're
[01:44:12.420 --> 01:44:13.420]   in a panic stop.
[01:44:13.420 --> 01:44:16.300]   Because the only reason you do that is in a panic stop.
[01:44:16.300 --> 01:44:19.420]   And it pre-fires the brakes and helps you break.
[01:44:19.420 --> 01:44:21.540]   Because you have an unlock on a modern brake.
[01:44:21.540 --> 01:44:25.780]   You can steer and control a car even though it's fully breaking.
[01:44:25.780 --> 01:44:29.820]   And if you didn't want fully breaking, take your foot off the brake, right?
[01:44:29.820 --> 01:44:33.860]   If you're in a panic stop, you would appreciate the car saving your life and helping you scrub
[01:44:33.860 --> 01:44:36.380]   energy even if you're going to hit something.
[01:44:36.380 --> 01:44:41.700]   Interestingly, the 8.0 software is coming out for Tesla.
[01:44:41.700 --> 01:44:51.260]   And my understanding is that you are now going to be able to not just go on one highway,
[01:44:51.260 --> 01:44:54.820]   fully autonomous, but you're going to be able to switch, or very soon, I don't know if
[01:44:54.820 --> 01:44:58.460]   it's going to happen in 8, you're going to be able to switch from one highway to another
[01:44:58.460 --> 01:45:00.980]   and it will take you on the overpass across the highway.
[01:45:00.980 --> 01:45:02.220]   It doesn't do that currently.
[01:45:02.220 --> 01:45:06.700]   In other words, if you put it on, and even if your GPS says you're going to take the
[01:45:06.700 --> 01:45:11.780]   280 to the 380 to the 101 like Robert and I do all the time, it's not going to actually
[01:45:11.780 --> 01:45:13.140]   do that.
[01:45:13.140 --> 01:45:16.820]   You have to, it'll be self-driving on each of those roads, but you have to take the exit
[01:45:16.820 --> 01:45:17.820]   ramps.
[01:45:17.820 --> 01:45:20.020]   It's going to do the exit ramps supposedly where that's coming.
[01:45:20.020 --> 01:45:24.460]   But Elon says his favorite new feature is the always on max temperature control for
[01:45:24.460 --> 01:45:27.380]   keeping kids and pets safe from overheating.
[01:45:27.380 --> 01:45:32.900]   Tesla keeps temperature below 105 degrees by automatically venting the cabin and turning
[01:45:32.900 --> 01:45:36.140]   on the AC when needed can do this for up to a year on a full charge.
[01:45:36.140 --> 01:45:40.980]   It's really a brilliant feature when you think about it because in some places like we live
[01:45:40.980 --> 01:45:46.340]   here in California, my car today was at 110 inside.
[01:45:46.340 --> 01:45:47.900]   There's no reason not to vent the windows.
[01:45:47.900 --> 01:45:48.900]   I mean, who cares?
[01:45:48.900 --> 01:45:49.900]   I don't know if he's going to rob the car.
[01:45:49.900 --> 01:45:51.300]   It's easier to break the window.
[01:45:51.300 --> 01:45:53.540]   That would reduce it by 5 or 10 degrees.
[01:45:53.540 --> 01:45:57.980]   And turning on the AC just had a very low amount every once in a while.
[01:45:57.980 --> 01:46:02.580]   The idea that somebody would die a dog or a kid tragically or both of them are tragic
[01:46:02.580 --> 01:46:07.580]   obviously would be horrible.
[01:46:07.580 --> 01:46:13.180]   Mercedes let me get me a first ride in the self driving car out in the desert.
[01:46:13.180 --> 01:46:14.980]   And we ran over a tumbleweed.
[01:46:14.980 --> 01:46:15.980]   That's kind of cheating by the way.
[01:46:15.980 --> 01:46:19.980]   If you're self driving on the fly in like nothing you could possibly hit, I'm not super
[01:46:19.980 --> 01:46:20.980]   impressed.
[01:46:20.980 --> 01:46:21.980]   But okay, continue.
[01:46:21.980 --> 01:46:22.980]   We did hit something.
[01:46:22.980 --> 01:46:26.580]   We hit a tumbleweed that was about a six foot high tumbleweed.
[01:46:26.580 --> 01:46:27.980]   It was a sizable tumbleweed.
[01:46:27.980 --> 01:46:29.380]   I said, why didn't the car stop?
[01:46:29.380 --> 01:46:34.500]   And then he said, first of all, the machine learning is trained to recognize a cocaine
[01:46:34.500 --> 01:46:35.660]   versus a camera.
[01:46:35.660 --> 01:46:36.660]   You train it.
[01:46:36.660 --> 01:46:39.620]   You put 70,000 images of cocaine, 70,000 images of camera.
[01:46:39.620 --> 01:46:41.420]   And then all of a sudden the system learns.
[01:46:41.420 --> 01:46:44.620]   It can be taught how to recognize this too.
[01:46:44.620 --> 01:46:49.420]   And so the optical sensors he said didn't recognize that that was anything that was going
[01:46:49.420 --> 01:46:51.140]   to hurt the car.
[01:46:51.140 --> 01:46:54.660]   And to the radar sensor knows it didn't have any mass to it.
[01:46:54.660 --> 01:46:57.060]   So it knew it wasn't a child or a dog or a hawk.
[01:46:57.060 --> 01:46:58.660]   It was a carry on plastic bag.
[01:46:58.660 --> 01:47:03.460]   Or it was just a stupid thing that you could go through and it had no mass to it.
[01:47:03.460 --> 01:47:06.260]   And this was German engineers in the backseat telling me this, right?
[01:47:06.260 --> 01:47:12.900]   So I'm pretty convinced we're going to figure out how to train these systems to recognize
[01:47:12.900 --> 01:47:15.580]   a whole lot of things and not get into action.
[01:47:15.580 --> 01:47:20.060]   People in the chat room were having fun and, oh, what if a car decided to go off road
[01:47:20.060 --> 01:47:23.320]   and kill 20 kids instead of killing one in the cross-
[01:47:23.320 --> 01:47:27.140]   All those kind of like ethical moral things are kind of silly, right?
[01:47:27.140 --> 01:47:29.680]   Two bicycle riders, one has a helmet.
[01:47:29.680 --> 01:47:30.680]   So I'll only injure that one.
[01:47:30.680 --> 01:47:31.680]   The other one I would kill.
[01:47:31.680 --> 01:47:34.720]   Therefore I hit the person who's doing the right thing by wearing a helmet.
[01:47:34.720 --> 01:47:35.720]   Right?
[01:47:35.720 --> 01:47:36.720]   That's the ultimate.
[01:47:36.720 --> 01:47:41.120]   Or what I like is we have two people who are 70 years old.
[01:47:41.120 --> 01:47:46.360]   And then over here we have two 70 year olds and one child, who do you kill?
[01:47:46.360 --> 01:47:50.040]   Or you have two people here who are half the age or whatever.
[01:47:50.040 --> 01:47:56.560]   The Mercedes engineers say if we even get close to that kind of decision, our systems
[01:47:56.560 --> 01:47:58.200]   have failed.
[01:47:58.200 --> 01:48:03.240]   In other words, the fact that you're even considering such a question means our system.
[01:48:03.240 --> 01:48:04.520]   Our systems have failed.
[01:48:04.520 --> 01:48:08.640]   Our system didn't see the bicycle riders, didn't see the people, didn't see the stops
[01:48:08.640 --> 01:48:11.240]   on, didn't see all the rules.
[01:48:11.240 --> 01:48:13.440]   It's a false choice for sure.
[01:48:13.440 --> 01:48:17.320]   Like these systems are so much better than to ever get to that choice.
[01:48:17.320 --> 01:48:18.720]   Now, what is better than us?
[01:48:18.720 --> 01:48:25.640]   The Tesla is an interesting, the guy who died as an interesting example of artificial intelligence.
[01:48:25.640 --> 01:48:32.600]   Because you had to train it on what a white truck over the freeway might look like.
[01:48:32.600 --> 01:48:34.800]   And how that's different from a bridge.
[01:48:34.800 --> 01:48:38.920]   Now consider if your car went into emergency stop every time it saw a bridge.
[01:48:38.920 --> 01:48:39.920]   Or an overpass.
[01:48:39.920 --> 01:48:41.560]   It would cost 100 accidents.
[01:48:41.560 --> 01:48:44.400]   It would cause many more deaths than if it just continued.
[01:48:44.400 --> 01:48:48.200]   And probably it wasn't trained to see that.
[01:48:48.200 --> 01:48:52.360]   And you know Elon and his team has been retraining their systems.
[01:48:52.360 --> 01:48:58.560]   And in fact he said that the new autopilot has radar and optical that they turned on.
[01:48:58.560 --> 01:49:01.440]   And they changed the algorithms to see that thing in the future.
[01:49:01.440 --> 01:49:02.440]   Right.
[01:49:02.440 --> 01:49:03.440]   They said it could see through fog now.
[01:49:03.440 --> 01:49:08.000]   So theoretically if a UFO landed on the highway, I think it was the analogy.
[01:49:08.000 --> 01:49:10.520]   In the fog it would still stop.
[01:49:10.520 --> 01:49:11.520]   Which is great.
[01:49:11.520 --> 01:49:16.800]   But this person explicitly disregarded all the alarms.
[01:49:16.800 --> 01:49:21.880]   And I gotta tell you now with the latest updates the software is sending off so many goddamn
[01:49:21.880 --> 01:49:22.880]   alarms.
[01:49:22.880 --> 01:49:23.880]   I feel like turning off self driving.
[01:49:23.880 --> 01:49:25.040]   We're just not using it rather.
[01:49:25.040 --> 01:49:26.040]   You swear again.
[01:49:26.040 --> 01:49:27.040]   Go down.
[01:49:27.040 --> 01:49:28.040]   No.
[01:49:28.040 --> 01:49:31.040]   I don't think that would mean that.
[01:49:31.040 --> 01:49:32.040]   I'm not.
[01:49:32.040 --> 01:49:33.040]   I'm not.
[01:49:33.040 --> 01:49:34.040]   I'm not.
[01:49:34.040 --> 01:49:35.040]   Anyway.
[01:49:35.040 --> 01:49:37.640]   This whole section is gonna cut out of the recording.
[01:49:37.640 --> 01:49:42.680]   I know because I have my hands on the steering wheel and it's so sensitized now that a lot
[01:49:42.680 --> 01:49:43.920]   of times I put your hand on the steering wheel.
[01:49:43.920 --> 01:49:48.560]   I kind of have my hand on the steering wheel but okay I'll make sure I'm moving it a little
[01:49:48.560 --> 01:49:49.560]   bit.
[01:49:49.560 --> 01:49:52.440]   It's almost like I think what they should have done with this thing is you should have
[01:49:52.440 --> 01:49:57.880]   to sign like three times on the dashboard like a document sign that or like just the
[01:49:57.880 --> 01:50:02.320]   only people allowed to turn it on or part of a beta group or something because the people
[01:50:02.320 --> 01:50:06.800]   who are using it without actually keeping their eyes on the road.
[01:50:06.800 --> 01:50:11.440]   I mean please people if you happen to be lucky enough to be able to afford a Tesla and you
[01:50:11.440 --> 01:50:13.240]   have self driving.
[01:50:13.240 --> 01:50:14.240]   Use it properly.
[01:50:14.240 --> 01:50:17.760]   The manual is it tells you a thousand times a ride.
[01:50:17.760 --> 01:50:19.560]   Keep your hands and your wits about you.
[01:50:19.560 --> 01:50:21.960]   It's not level four.
[01:50:21.960 --> 01:50:23.600]   It's level two.
[01:50:23.600 --> 01:50:25.040]   These people are insane.
[01:50:25.040 --> 01:50:29.640]   It's infuriating to me because we all need to see this technology advance and I actually
[01:50:29.640 --> 01:50:34.680]   think that in China or some other countries you're gonna have this backlash of another
[01:50:34.680 --> 01:50:35.680]   person.
[01:50:35.680 --> 01:50:36.680]   European countries.
[01:50:36.680 --> 01:50:39.000]   Probably socialist countries like Europe.
[01:50:39.000 --> 01:50:40.000]   In China.
[01:50:40.000 --> 01:50:43.400]   In China I disagree with you.
[01:50:43.400 --> 01:50:46.600]   The people who are building self driving technologies there so it'll be adopted way
[01:50:46.600 --> 01:50:47.600]   faster over there.
[01:50:47.600 --> 01:50:48.600]   Listen it is.
[01:50:48.600 --> 01:50:52.320]   Because of the chaos on the street it has to learn way faster than our technology.
[01:50:52.320 --> 01:50:58.400]   I know but if somebody does what this person did where they just abdicate control.
[01:50:58.400 --> 01:50:59.400]   As human beings.
[01:50:59.400 --> 01:51:00.400]   No I know.
[01:51:00.400 --> 01:51:01.400]   We take risks sometimes.
[01:51:01.400 --> 01:51:06.000]   But also human beings will overreact and then say we have to get rid of it.
[01:51:06.000 --> 01:51:11.760]   And the problem is if it's already 50% or 100% better we need to keep investing.
[01:51:11.760 --> 01:51:13.760]   We need to keep letting people use this technology.
[01:51:13.760 --> 01:51:18.920]   Okay so I don't think that that's the biggest barrier to the adoption of self driving cars.
[01:51:18.920 --> 01:51:20.760]   The biggest adoption is the loss of jobs.
[01:51:20.760 --> 01:51:24.760]   You heard like German economic minister being like we're not gonna let them on the road.
[01:51:24.760 --> 01:51:28.280]   That's like take away taxi jobs and Uber jobs and other jobs.
[01:51:28.280 --> 01:51:31.120]   And that's that's what we're content.
[01:51:31.120 --> 01:51:32.680]   Except.
[01:51:32.680 --> 01:51:36.920]   We know these technologies already already save lives.
[01:51:36.920 --> 01:51:39.480]   Mercedes told me they sell 30% of the money.
[01:51:39.480 --> 01:51:40.480]   He's talking about.
[01:51:40.480 --> 01:51:42.080]   I know but that doesn't matter.
[01:51:42.080 --> 01:51:43.080]   But here's the lawsuit.
[01:51:43.080 --> 01:51:45.520]   Logic does not apply to politics.
[01:51:45.520 --> 01:51:51.880]   It does because if my kid gets killed in a car wreck and the government kept us self driving
[01:51:51.880 --> 01:51:55.280]   car from my local community I'm gonna sue as well.
[01:51:55.280 --> 01:51:57.320]   This is looked at the election.
[01:51:57.320 --> 01:51:58.320]   Logic is gone.
[01:51:58.320 --> 01:51:59.320]   I know.
[01:51:59.320 --> 01:52:00.320]   But there are.
[01:52:00.320 --> 01:52:04.960]   I'm trying to I'm trying to keep this away from the election.
[01:52:04.960 --> 01:52:08.360]   But you know what technology does mitigate a lot of our lives.
[01:52:08.360 --> 01:52:12.000]   And you know we are making it's interesting when you just think about this one discussion.
[01:52:12.000 --> 01:52:15.760]   It's gonna come down to do we want to save lives or jobs.
[01:52:15.760 --> 01:52:17.200]   And I think that's really profound.
[01:52:17.200 --> 01:52:20.040]   You know it's something we have to think about as a society.
[01:52:20.040 --> 01:52:22.280]   If we keep a million jobs.
[01:52:22.280 --> 01:52:24.600]   And humans always vote for a job.
[01:52:24.600 --> 01:52:26.000]   That's a bad decision.
[01:52:26.000 --> 01:52:28.000]   Humans always vote against jobs.
[01:52:28.000 --> 01:52:29.000]   We got cars.
[01:52:29.000 --> 01:52:32.600]   We knew they were gonna kill millions of jobs in horseshoes and other things.
[01:52:32.600 --> 01:52:35.600]   And think about all the horses that they put down after the cars came out.
[01:52:35.600 --> 01:52:36.600]   They just killed them.
[01:52:36.600 --> 01:52:38.600]   We're going to the future.
[01:52:38.600 --> 01:52:39.600]   You can try.
[01:52:39.600 --> 01:52:41.600]   Actually what did they do with all the horses after they got rid of them?
[01:52:41.600 --> 01:52:42.600]   They're gonna sell cars.
[01:52:42.600 --> 01:52:44.600]   They just the breeding programs.
[01:52:44.600 --> 01:52:46.600]   There was a video I watched on this actually.
[01:52:46.600 --> 01:52:49.600]   They must have been like because they must have had a ramp horse breeding video.
[01:52:49.600 --> 01:52:50.600]   Yeah.
[01:52:50.600 --> 01:52:56.920]   They must have had these discussions in India because they need self driving technologies
[01:52:56.920 --> 01:52:58.120]   for a whole lot of reasons.
[01:52:58.120 --> 01:53:00.120]   They don't have these conversations in China.
[01:53:00.120 --> 01:53:02.320]   By the way, do I have another commercial break or what?
[01:53:02.320 --> 01:53:03.320]   No, this is not a question.
[01:53:03.320 --> 01:53:04.320]   Okay, we're all done on the commercial breaks.
[01:53:04.320 --> 01:53:05.960]   Let me keep the show moving here.
[01:53:05.960 --> 01:53:11.360]   This is my favorite of all the robotic things after Cafe X which I'm an investor in.
[01:53:11.360 --> 01:53:14.280]   This is my favorite.
[01:53:14.280 --> 01:53:19.840]   This Starship robot which you can see on my screen is a little R2-D2.
[01:53:19.840 --> 01:53:21.520]   It's about knee high.
[01:53:21.520 --> 01:53:23.880]   And you can put a couple of boxes, maybe two or three bags of groceries.
[01:53:23.880 --> 01:53:24.880]   And it looks like to me.
[01:53:24.880 --> 01:53:29.600]   It looks like a little Tonka truck if anybody knows that reference.
[01:53:29.600 --> 01:53:36.360]   And it'll drive at a couple miles per hour to your house and deliver something to you.
[01:53:36.360 --> 01:53:42.720]   And I think that this, these little robots are gonna be huge.
[01:53:42.720 --> 01:53:50.400]   I think that this is so much better than drones because this can't fall out of the sky.
[01:53:50.400 --> 01:53:52.920]   This is gonna use much less batteries.
[01:53:52.920 --> 01:53:55.160]   It's not gonna cause noise pollution.
[01:53:55.160 --> 01:53:58.440]   And if somebody wants to steal this, I guess that's the one thing that somebody could pick
[01:53:58.440 --> 01:54:00.120]   it up or flip it over.
[01:54:00.120 --> 01:54:06.480]   It's gonna have a camera on it and you could potentially get arrested for some felonious
[01:54:06.480 --> 01:54:07.480]   activity.
[01:54:07.480 --> 01:54:10.640]   Like, I don't know if people know this, but like most mailboxes are not bolted to the
[01:54:10.640 --> 01:54:11.640]   ground.
[01:54:11.640 --> 01:54:13.680]   You just lift them up off and put them into a back of a truck, but you can also go to
[01:54:13.680 --> 01:54:14.680]   jail for it.
[01:54:14.680 --> 01:54:20.680]   I love this idea of little R2-D2s running around delivering your sunglasses as opposed
[01:54:20.680 --> 01:54:22.880]   to your spectacles from Snapchat.
[01:54:22.880 --> 01:54:25.200]   This will be the delivery mechanism, obviously.
[01:54:25.200 --> 01:54:30.320]   Rather than huge UPS trucks, rather than all that gas, these things could be out there
[01:54:30.320 --> 01:54:33.440]   just zipping along streets in the, in the burbs.
[01:54:33.440 --> 01:54:35.040]   This could work in cities.
[01:54:35.040 --> 01:54:38.880]   This thing could run, could walk 10 miles in the burbs to drop something off.
[01:54:38.880 --> 01:54:39.880]   It doesn't matter.
[01:54:39.880 --> 01:54:41.720]   It's such low energy consumption.
[01:54:41.720 --> 01:54:43.320]   And if there's sidewalks, it just works.
[01:54:43.320 --> 01:54:45.120]   Brian, what do you think?
[01:54:45.120 --> 01:54:46.120]   Wow.
[01:54:46.120 --> 01:54:47.920]   So that'd be a nice thing to have.
[01:54:47.920 --> 01:54:48.920]   They look cute.
[01:54:48.920 --> 01:54:50.640]   I think they're gonna be, you know, beat up.
[01:54:50.640 --> 01:54:51.640]   Super cute.
[01:54:51.640 --> 01:54:52.640]   Right?
[01:54:52.640 --> 01:54:54.560]   Well, so yes and no.
[01:54:54.560 --> 01:54:58.720]   If I was in New York right now, that actually looks like a pressure coconut on wheels.
[01:54:58.720 --> 01:54:59.880]   I would run away from that.
[01:54:59.880 --> 01:55:00.880]   Seriously.
[01:55:00.880 --> 01:55:02.560]   It does look like it could be a bomb.
[01:55:02.560 --> 01:55:03.560]   Right?
[01:55:03.560 --> 01:55:04.560]   Police driving something in.
[01:55:04.560 --> 01:55:05.560]   It's the fair point.
[01:55:05.560 --> 01:55:06.560]   It's really screwy looking.
[01:55:06.560 --> 01:55:08.560]   So I make it, I'd make it a lot less.
[01:55:08.560 --> 01:55:12.600]   Well, I mean, listen, we kid sometimes hear about, you know, the technology and some of
[01:55:12.600 --> 01:55:17.040]   the stuff, the darker uses of it, but there is an actual legitimate issue right now around
[01:55:17.040 --> 01:55:23.480]   drones where they believe ISIS is training, they're training ISIS members to use drones.
[01:55:23.480 --> 01:55:26.400]   I read this to deliver bombs and payload.
[01:55:26.400 --> 01:55:30.760]   You could conceivably do a lot of damage by just dropping a drone into the middle of
[01:55:30.760 --> 01:55:32.800]   any sports activity or whatever.
[01:55:32.800 --> 01:55:34.920]   Any, like with a vehicle or with that?
[01:55:34.920 --> 01:55:37.040]   Yeah, but it wouldn't be as terrorizing.
[01:55:37.040 --> 01:55:40.320]   When you put new technology on a bomb, it just makes it all the more terrorizing.
[01:55:40.320 --> 01:55:41.320]   Nobody, it's interesting.
[01:55:41.320 --> 01:55:42.320]   Yeah, I agree.
[01:55:42.320 --> 01:55:43.320]   People are like, oh my God.
[01:55:43.320 --> 01:55:44.320]   It's an issue.
[01:55:44.320 --> 01:55:45.320]   But I mean, hopefully.
[01:55:45.320 --> 01:55:48.360]   Also accessibility, like think about this.
[01:55:48.360 --> 01:55:53.240]   If the mayor, I don't mean to put anything in people's heads here, but if the mayor of
[01:55:53.240 --> 01:55:56.880]   some city is giving a talk and he's got a bunch of security around them, a drone can
[01:55:56.880 --> 01:56:01.360]   just drop out of the sky at a very quick pace with a bomb on it and assassinate anybody
[01:56:01.360 --> 01:56:02.360]   at once.
[01:56:02.360 --> 01:56:06.760]   When I'm at the White House, they do not let me do live video broadcasting.
[01:56:06.760 --> 01:56:10.720]   All of the video you see of the president in the White House has been taped delayed by
[01:56:10.720 --> 01:56:13.760]   five or 10 minutes for exactly that reason.
[01:56:13.760 --> 01:56:14.840]   They don't want exact time.
[01:56:14.840 --> 01:56:19.560]   They don't want somebody watching live broadcast somewhere else and being able to target the
[01:56:19.560 --> 01:56:21.760]   president by throwing a drone.
[01:56:21.760 --> 01:56:25.120]   This was the Bush presidency when I was there.
[01:56:25.120 --> 01:56:28.160]   And they have all sorts of jamming equipment around the president.
[01:56:28.160 --> 01:56:35.640]   That's what, when you see the motorcade going, you see a car with dozens of antennas.
[01:56:35.640 --> 01:56:42.280]   That's to jam all of the electronics that would possibly throw off a bomb or signal to a bomb
[01:56:42.280 --> 01:56:44.560]   near the president.
[01:56:44.560 --> 01:56:51.080]   I visited the bomb unit at Nellis Air Force Base and they said, "We already can block
[01:56:51.080 --> 01:56:52.080]   cell phones.
[01:56:52.080 --> 01:56:54.640]   We know how to do that really well."
[01:56:54.640 --> 01:56:59.040]   And that forced the terrorists to go to lower technology.
[01:56:59.040 --> 01:57:02.160]   They have now click plates when you roll over them.
[01:57:02.160 --> 01:57:06.560]   That count how many wheels have gone over the plate and then blow up something inside
[01:57:06.560 --> 01:57:09.360]   the train of the convoy.
[01:57:09.360 --> 01:57:10.360]   Convoy.
[01:57:10.360 --> 01:57:11.360]   Yeah.
[01:57:11.360 --> 01:57:15.360]   And that hit the first truck because that's a bomb truck that was designed to take a blast.
[01:57:15.360 --> 01:57:19.720]   It actually has a curved bottom shell, so a bomb blast doesn't kill them.
[01:57:19.720 --> 01:57:21.280]   And it's amazing.
[01:57:21.280 --> 01:57:25.680]   It's interesting to talk to these people about terrorism and bombs.
[01:57:25.680 --> 01:57:27.880]   I don't want to tell everything on there.
[01:57:27.880 --> 01:57:32.080]   RF2022 says, "They got a lot of ways to block your drone."
[01:57:32.080 --> 01:57:35.240]   You're not going to fly a DJI drone over the president.
[01:57:35.240 --> 01:57:37.280]   Actually, a good sound makes a good point.
[01:57:37.280 --> 01:57:41.520]   As if Brewster is flying a blimp nearby, look out, which is, what is that?
[01:57:41.520 --> 01:57:43.120]   Black Sunday, the name of that film?
[01:57:43.120 --> 01:57:45.120]   The famous Frankenheimer film.
[01:57:45.120 --> 01:57:47.200]   I shouldn't say it's famous in Subscure, actually.
[01:57:47.200 --> 01:57:48.840]   It's famous to me.
[01:57:48.840 --> 01:57:49.840]   All right.
[01:57:49.840 --> 01:57:52.640]   Listen, this has been an amazing program.
[01:57:52.640 --> 01:57:58.080]   Thank you to Leo for allowing us to host here and to take over the network.
[01:57:58.080 --> 01:58:01.560]   We'll be in your office for the next two or three hours with all the studio audience
[01:58:01.560 --> 01:58:03.760]   drinking and just trashing the place.
[01:58:03.760 --> 01:58:04.960]   It's going to be a great party.
[01:58:04.960 --> 01:58:07.560]   If anybody can hear my voice right now.
[01:58:07.560 --> 01:58:08.560]   Don't tempt them.
[01:58:08.560 --> 01:58:10.760]   We're having a huge party right now.
[01:58:10.760 --> 01:58:11.760]   That's great.
[01:58:11.760 --> 01:58:12.760]   Great.
[01:58:12.760 --> 01:58:16.360]   Gary Reiner, can I do this in Sonoma at a winery?
[01:58:16.360 --> 01:58:18.360]   Within a few hours, we had a lot of people.
[01:58:18.360 --> 01:58:21.320]   We're all out of here.
[01:58:21.320 --> 01:58:28.000]   Let me say thank you first to Ben Parr, Ben Parr.com, Ben Parr on Twitter, I believe,
[01:58:28.000 --> 01:58:32.080]   at Ben Parr, two Rs in Parr, because he's so rad.
[01:58:32.080 --> 01:58:34.560]   Ben Parr, you have a plug?
[01:58:34.560 --> 01:58:35.560]   Two plugs.
[01:58:35.560 --> 01:58:36.560]   Get some plugs in here.
[01:58:36.560 --> 01:58:37.560]   Very important to get plugs in.
[01:58:37.560 --> 01:58:38.920]   Two plugs, plug.
[01:58:38.920 --> 01:58:42.680]   The paperback of my book, Captivology, comes out on October 18th.
[01:58:42.680 --> 01:58:44.440]   If you want to grow your startup kit.
[01:58:44.440 --> 01:58:48.800]   For the order now on Amazon or anything else, or get the audiobook.
[01:58:48.800 --> 01:58:51.560]   And more announcements coming in about a month or so.
[01:58:51.560 --> 01:58:57.160]   I'm assuming you're going to announce your Apple gig running the fly on tires.
[01:58:57.160 --> 01:58:58.880]   I already did that two months ago.
[01:58:58.880 --> 01:58:59.880]   I'm already working for Apple.
[01:58:59.880 --> 01:59:00.880]   I wasn't sure.
[01:59:00.880 --> 01:59:01.880]   I wasn't sure.
[01:59:01.880 --> 01:59:02.880]   All right.
[01:59:02.880 --> 01:59:04.360]   Brian Alvey, you're up next for the plugs.
[01:59:04.360 --> 01:59:08.600]   BrianAlvey.com, and of course, @BrianAlvey on the Twitter.
[01:59:08.600 --> 01:59:10.600]   Brian Alvey working on clip-as-sewed.
[01:59:10.600 --> 01:59:12.160]   Yeah, @Clip-as-sewed.
[01:59:12.160 --> 01:59:14.320]   So, CLIP-I, SODE, clip-as-sewed.
[01:59:14.320 --> 01:59:17.440]   Go check it out, send it for the beta.
[01:59:17.440 --> 01:59:21.880]   And the thing that would transform your startup at this point, aside from a Series A investment,
[01:59:21.880 --> 01:59:28.440]   if you could get some high profile bloggers or videographers or vloggers, you know, with
[01:59:28.440 --> 01:59:32.200]   10,000 or more followers to use the product in beta, that would help.
[01:59:32.200 --> 01:59:33.200]   Exactly.
[01:59:33.200 --> 01:59:35.560]   And it's a table who wanted to know.
[01:59:35.560 --> 01:59:38.360]   So it's about that.
[01:59:38.360 --> 01:59:40.680]   It's for influencers or people who want to be influencers.
[01:59:40.680 --> 01:59:41.680]   So, correct.
[01:59:41.680 --> 01:59:42.680]   Explain what the product is just as we get a little bit lower.
[01:59:42.680 --> 01:59:43.680]   Yes, super quick.
[01:59:43.680 --> 01:59:48.360]   It's an app, an iPhone app, and Android app now, actually, that lets you become the host
[01:59:48.360 --> 01:59:50.600]   of your own daily five-minute video talk show.
[01:59:50.600 --> 01:59:52.920]   So a social and mobile video app, you would love this thing.
[01:59:52.920 --> 01:59:54.760]   You ask a question to all your fans.
[01:59:54.760 --> 01:59:55.840]   They all come back with responses.
[01:59:55.840 --> 01:59:57.320]   You can ask contacts as well.
[01:59:57.320 --> 02:00:00.720]   So if you're talking about, like, politics, you know, Jason loves to talk politics all
[02:00:00.720 --> 02:00:02.040]   through a tech show.
[02:00:02.040 --> 02:00:05.280]   You invite him, he comes on, you get video replies, you put them all together, it makes
[02:00:05.280 --> 02:00:07.120]   a little square video that you share out.
[02:00:07.120 --> 02:00:08.120]   Got it.
[02:00:08.120 --> 02:00:09.120]   Pretty cool.
[02:00:09.120 --> 02:00:10.120]   And you're spare time, so it's not live.
[02:00:10.120 --> 02:00:11.120]   Got it.
[02:00:11.120 --> 02:00:15.000]   So Robert Scoble is here.
[02:00:15.000 --> 02:00:16.000]   Thank you for coming, Robert.
[02:00:16.000 --> 02:00:19.560]   Scobleizer on the Twitter, Scobleizer.
[02:00:19.560 --> 02:00:23.560]   But really, I have to say, you have mastered Facebook.
[02:00:23.560 --> 02:00:25.200]   It's amazing.
[02:00:25.200 --> 02:00:27.960]   It's inspired me to start playing with Facebook a little bit more.
[02:00:27.960 --> 02:00:31.080]   You know anything on Facebook because I went through the social graph and I started
[02:00:31.080 --> 02:00:35.360]   because I just, I made a huge tactical error at the beginning of Facebook.
[02:00:35.360 --> 02:00:37.160]   Remember the early days, you just accepted everybody.
[02:00:37.160 --> 02:00:38.160]   Yep.
[02:00:38.160 --> 02:00:39.160]   I've done it, right?
[02:00:39.160 --> 02:00:40.520]   Yeah, we've all made this huge mistake.
[02:00:40.520 --> 02:00:44.320]   And now what I'm doing is I'm actually going in and saying acquaintance, close friend, acquaintance,
[02:00:44.320 --> 02:00:46.440]   close friend, and also muting some people on the main feed.
[02:00:46.440 --> 02:00:48.280]   And my feed's getting better and better.
[02:00:48.280 --> 02:00:50.080]   The way I feel a little bit more.
[02:00:50.080 --> 02:00:52.600]   The amount of comments, how many comments do you get on the average post?
[02:00:52.600 --> 02:00:53.600]   Hundreds?
[02:00:53.600 --> 02:00:57.160]   Sometimes, I don't know what the average is, but dozens.
[02:00:57.160 --> 02:00:58.160]   It's amazing.
[02:00:58.160 --> 02:01:01.880]   And I don't even care about the numbers, I care about who's coming.
[02:01:01.880 --> 02:01:04.160]   It's the who's who of the tech industry, right?
[02:01:04.160 --> 02:01:05.160]   Yeah.
[02:01:05.160 --> 02:01:07.200]   You got Gary Shapiro, a commenting who runs CES.
[02:01:07.200 --> 02:01:11.200]   You got all sorts of innovators and people who are going to tell me.
[02:01:11.200 --> 02:01:15.120]   But has a major impact on your speaking gigs, your business?
[02:01:15.120 --> 02:01:16.120]   Is this like the space for me?
[02:01:16.120 --> 02:01:20.840]   And now I'm in the center of the VR and Airworld at Upload VR, which is a co-working space in
[02:01:20.840 --> 02:01:23.840]   San Francisco, plus a media company that covers this space.
[02:01:23.840 --> 02:01:24.840]   Awesome.
[02:01:24.840 --> 02:01:25.840]   And we're doing a podcast together.
[02:01:25.840 --> 02:01:28.160]   We're doing this podcast inside VR and Airworld.
[02:01:28.160 --> 02:01:32.560]   I'm seeing the VR, Airworld, which is going to be really important in a couple years.
[02:01:32.560 --> 02:01:38.200]   It really is interesting how quickly we're starting to see a large number of companies
[02:01:38.200 --> 02:01:39.200]   invest in the space.
[02:01:39.200 --> 02:01:40.960]   I always think that that's the tell.
[02:01:40.960 --> 02:01:44.200]   If you have one or two people investing in it, it's kind of like, okay, some people
[02:01:44.200 --> 02:01:45.200]   are playing.
[02:01:45.200 --> 02:01:48.480]   But when you see every major tech company investing heavily, we're going to see something big
[02:01:48.480 --> 02:01:50.360]   out of Google next week, I think.
[02:01:50.360 --> 02:01:54.000]   Well, they're going to bring out mobile-based VR, which I think is the only way to do that.
[02:01:54.000 --> 02:01:56.400]   I'm going to launch another Google Glass or another hardware.
[02:01:56.400 --> 02:01:57.400]   I know.
[02:01:57.400 --> 02:01:58.400]   I'm not going to launch it.
[02:01:58.400 --> 02:01:59.400]   Not yet.
[02:01:59.400 --> 02:02:00.400]   Because it's not quite ready.
[02:02:00.400 --> 02:02:04.920]   Although Snapchat probably is being watched very carefully at these companies.
[02:02:04.920 --> 02:02:06.840]   That's scary for people.
[02:02:06.840 --> 02:02:08.400]   It's scary for competitors.
[02:02:08.400 --> 02:02:09.400]   That's what I'm saying.
[02:02:09.400 --> 02:02:10.400]   Now they're Snap.
[02:02:10.400 --> 02:02:12.200]   That's part of the big thing, too.
[02:02:12.200 --> 02:02:13.680]   What do you mean?
[02:02:13.680 --> 02:02:16.360]   Have you seen what their Twitter, it's now Snap being.
[02:02:16.360 --> 02:02:17.360]   They renamed.
[02:02:17.360 --> 02:02:18.360]   Oh, and they're-
[02:02:18.360 --> 02:02:19.360]   Can you get Snap.com?
[02:02:19.360 --> 02:02:20.360]   Yes.
[02:02:20.360 --> 02:02:21.360]   And if you go to Twitter, it just says Snap.
[02:02:21.360 --> 02:02:22.360]   A camera company.
[02:02:22.360 --> 02:02:23.360]   Correct.
[02:02:23.360 --> 02:02:24.360]   So they have two things.
[02:02:24.360 --> 02:02:25.360]   They have a big group of apps.
[02:02:25.360 --> 02:02:26.360]   And a spectacle.
[02:02:26.360 --> 02:02:28.360]   Snap being is a camera company.
[02:02:28.360 --> 02:02:32.480]   We believe that reinventing the camera represents our greatest opportunity to improve the way
[02:02:32.480 --> 02:02:33.880]   people live and communicate.
[02:02:33.880 --> 02:02:39.000]   Our products empower people to express themselves live in the moment, learn about the world,
[02:02:39.000 --> 02:02:40.000]   and have fun together.
[02:02:40.000 --> 02:02:42.080]   So remember for like a week, this was called Snap.
[02:02:42.080 --> 02:02:43.080]   So not a clip-as-o.
[02:02:43.080 --> 02:02:44.080]   Yeah.
[02:02:44.080 --> 02:02:46.320]   And my lawyers said, I know you're not doing the same thing they're doing.
[02:02:46.320 --> 02:02:47.320]   Yeah.
[02:02:47.320 --> 02:02:50.080]   But they heavily sue people who use Snap in their names.
[02:02:50.080 --> 02:02:51.880]   Six months later, they're named Snap.
[02:02:51.880 --> 02:02:52.880]   No longer even named Snapchat.
[02:02:52.880 --> 02:02:53.880]   And they got Snap.com.
[02:02:53.880 --> 02:02:54.880]   That shows some impression.
[02:02:54.880 --> 02:03:01.960]   There's a revolution coming to all sorts of things, driving, photography, audio.
[02:03:01.960 --> 02:03:04.160]   And the next show-
[02:03:04.160 --> 02:03:05.160]   Sure.
[02:03:05.160 --> 02:03:06.160]   Come on in and join me.
[02:03:06.160 --> 02:03:07.160]   For sure.
[02:03:07.160 --> 02:03:08.160]   Virtual shout-out.
[02:03:08.160 --> 02:03:09.760]   And that's actually the big of an app.
[02:03:09.760 --> 02:03:16.600]   And I hate to steal Larry and Sergey Slunder, but next week at the Google event, Robert was
[02:03:16.600 --> 02:03:21.600]   going to be releasing Shower with Robert exclusively on Google VR.
[02:03:21.600 --> 02:03:22.600]   It's a steam game.
[02:03:22.600 --> 02:03:23.600]   Shower with Scoble.
[02:03:23.600 --> 02:03:24.600]   It's a steam game.
[02:03:24.600 --> 02:03:25.600]   It's a steam game.
[02:03:25.600 --> 02:03:26.600]   It's incredible.
[02:03:26.600 --> 02:03:27.600]   You too can shower it's Scoble.
[02:03:27.600 --> 02:03:28.600]   But it's pixelated.
[02:03:28.600 --> 02:03:29.600]   So it's fine.
[02:03:29.600 --> 02:03:31.600]   If you look down at Automatically Pixelates, look up.
[02:03:31.600 --> 02:03:32.600]   You're fine.
[02:03:32.600 --> 02:03:33.600]   If you look down at Pixelates-
[02:03:33.600 --> 02:03:34.600]   There's a limit.
[02:03:34.600 --> 02:03:35.600]   If you pay, you can see it all.
[02:03:35.600 --> 02:03:36.600]   Wow.
[02:03:36.600 --> 02:03:37.600]   Wow.
[02:03:37.600 --> 02:03:38.600]   That's it.
[02:03:38.600 --> 02:03:39.600]   Yeah.
[02:03:39.600 --> 02:03:40.600]   Yeah.
[02:03:40.600 --> 02:03:41.600]   Yeah.
[02:03:41.600 --> 02:03:42.600]   We have a title.
[02:03:42.600 --> 02:03:43.600]   It was title of the episode.
[02:03:43.600 --> 02:03:47.600]   If you pay, then you see it all.
[02:03:47.600 --> 02:03:49.600]   Episode 581.
[02:03:49.600 --> 02:03:50.600]   Thanks.
[02:03:50.600 --> 02:03:52.600]   To Leo for letting me host.
[02:03:52.600 --> 02:03:56.600]   It's obviously an honor and privilege.
[02:03:56.600 --> 02:04:01.600]   Although this is the last time, I'm still very grateful to see you all next time.
[02:04:01.600 --> 02:04:02.600]   Bye bye.
[02:04:02.600 --> 02:04:03.600]   This is amazing.
[02:04:03.600 --> 02:04:04.600]   Stop.
[02:04:04.600 --> 02:04:05.600]   Bye bye.
[02:04:05.600 --> 02:04:06.600]   Do the twin.
[02:04:06.600 --> 02:04:07.600]   Do the twin.
[02:04:07.600 --> 02:04:08.600]   All right.
[02:04:08.600 --> 02:04:09.600]   Do the twin.
[02:04:09.600 --> 02:04:10.600]   Baby.
[02:04:10.600 --> 02:04:11.600]   Do the twin.
[02:04:11.600 --> 02:04:12.600]   All right.

