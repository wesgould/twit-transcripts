;FFMETADATA1
title=Headphones For Your Eyes
artist=Leo Laporte, Brianna Wu, Daniel Rubino, Sam Abuelsamid
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2022-10-17
track=897
language=English
genre=Podcast
comment=Future of Microsoft Office, Legs in VR, NVIDIA RTX 4090, Project Starline
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:01.540]   It's time for Tweth this weekend tech.
[00:00:01.540 --> 00:00:03.840]   Samable Samad is here, our car guy.
[00:00:03.840 --> 00:00:05.200]   Gran O'Woo, our car gal.
[00:00:05.200 --> 00:00:08.000]   They're gonna talk about cars, and pinball.
[00:00:08.000 --> 00:00:10.500]   And Daniel Rubino from Windows Central.
[00:00:10.500 --> 00:00:13.300]   There's lots to talk about meta's announcements this week.
[00:00:13.300 --> 00:00:16.080]   Microsoft's announcements this week.
[00:00:16.080 --> 00:00:20.240]   We'll talk about the N-Vidia RTX 4090.
[00:00:20.240 --> 00:00:21.640]   Look at the size of that thing.
[00:00:21.640 --> 00:00:24.360]   What Apple's gonna do with its announcements?
[00:00:24.360 --> 00:00:29.080]   And Elon Musk, his new demands from Twitter.
[00:00:29.080 --> 00:00:31.080]   It's all coming up next.
[00:00:31.080 --> 00:00:32.080]   Twit.
[00:00:32.080 --> 00:00:36.280]   Podcasts you love.
[00:00:36.280 --> 00:00:38.780]   From people you trust.
[00:00:38.780 --> 00:00:40.280]   This is Twit.
[00:00:40.280 --> 00:00:48.760]   This is Twit this weekend tech.
[00:00:48.760 --> 00:00:51.040]   Episode 897.
[00:00:51.040 --> 00:00:54.880]   Recorded Sunday, October 16, 2022.
[00:00:54.880 --> 00:00:57.720]   Headphones for your eyes.
[00:00:57.720 --> 00:01:02.360]   This episode of this week in tech is brought to you by Stamps.com.
[00:01:02.360 --> 00:01:04.800]   Get ahead of the holiday chaos this year.
[00:01:04.800 --> 00:01:08.760]   Sign up at Stamps.com, click the microphone at the top of the page,
[00:01:08.760 --> 00:01:12.840]   and enter the code Twit for a special offer that includes a four-week trial,
[00:01:12.840 --> 00:01:16.480]   plus free postage and a digital scale.
[00:01:16.480 --> 00:01:18.280]   And by Collide.
[00:01:18.280 --> 00:01:23.280]   Collide is an endpoint security solution that uses the most powerful untapped resource
[00:01:23.280 --> 00:01:25.520]   in IT and users.
[00:01:25.520 --> 00:01:31.640]   Visit collide.com/twit to learn more and activate a free 14-day trial today.
[00:01:31.640 --> 00:01:33.760]   No credit card required.
[00:01:33.760 --> 00:01:35.360]   And by Noom.
[00:01:35.360 --> 00:01:40.160]   With their psychology-first approach, Noom Weight empowers you to build more sustainable
[00:01:40.160 --> 00:01:42.120]   habits and behaviors.
[00:01:42.120 --> 00:01:46.280]   Sign up for your trial at noom.com/twit.
[00:01:46.280 --> 00:01:48.160]   And by Mint Mobile.
[00:01:48.160 --> 00:01:54.000]   Get premium wireless service from just 15 bucks a month with no unexpected plot twists.
[00:01:54.000 --> 00:02:05.840]   You'll make your wallet very happy by going to mintmobile.com/twit.
[00:02:05.840 --> 00:02:08.080]   It's time for Twit this week at Tech.
[00:02:08.080 --> 00:02:09.440]   Show we cover the weeks.
[00:02:09.440 --> 00:02:10.440]   Tech news.
[00:02:10.440 --> 00:02:12.280]   I'm still exhausted from last week's show.
[00:02:12.280 --> 00:02:14.800]   Maybe we can make this one a little bit shorter, gang.
[00:02:14.800 --> 00:02:15.800]   What do you say?
[00:02:15.800 --> 00:02:16.800]   No.
[00:02:16.800 --> 00:02:18.600]   It's not going to be short because guess who's here?
[00:02:18.600 --> 00:02:19.600]   Four hours.
[00:02:19.600 --> 00:02:20.600]   Four hours.
[00:02:20.600 --> 00:02:21.600]   Sam Apple.
[00:02:21.600 --> 00:02:22.600]   Sam-ed.
[00:02:22.600 --> 00:02:23.600]   My car guy.
[00:02:23.600 --> 00:02:25.160]   He's a host of the wheel bearings.
[00:02:25.160 --> 00:02:26.880]   We got a bunch of podcasters on the show.
[00:02:26.880 --> 00:02:29.840]   That means there could be a lot of talking going on.
[00:02:29.840 --> 00:02:31.840]   We just see you sing them.
[00:02:31.840 --> 00:02:32.840]   What are you driving?
[00:02:32.840 --> 00:02:36.760]   Besides the Miata, which is your regular vehicle, what are you driving?
[00:02:36.760 --> 00:02:37.760]   Let's see.
[00:02:37.760 --> 00:02:44.320]   This week I have the Ford Expedition Timberline, which is sort of off-road-ish version of the
[00:02:44.320 --> 00:02:47.000]   big, yeah, it's a full-size SUV.
[00:02:47.000 --> 00:02:49.280]   Last week I had a Ford Bronco Raptor.
[00:02:49.280 --> 00:02:50.280]   Jealous.
[00:02:50.280 --> 00:02:52.040]   Love those new Broncos.
[00:02:52.040 --> 00:02:54.320]   That was great until I got stuck in the mud.
[00:02:54.320 --> 00:02:55.640]   I saw the pictures.
[00:02:55.640 --> 00:02:59.240]   You said, make sure you change your wheels and bring a winch.
[00:02:59.240 --> 00:03:01.960]   Yes, absolutely.
[00:03:01.960 --> 00:03:05.480]   Also with this, somebody who very much loves her automobiles.
[00:03:05.480 --> 00:03:10.520]   Brianna Wu, a host of the Rocket podcast of Relay FM.
[00:03:10.520 --> 00:03:12.680]   What is your, you're driving a Boxster?
[00:03:12.680 --> 00:03:15.440]   I've got Boxster of two 911s.
[00:03:15.440 --> 00:03:17.440]   I have a Cayman GTS.
[00:03:17.440 --> 00:03:22.160]   And I also have some really big news I'm going to break today on this show.
[00:03:22.160 --> 00:03:24.040]   Frank is here to celebrate this with me.
[00:03:24.040 --> 00:03:27.520]   I'm happy to announce I'm not just the co-host of Rocket.
[00:03:27.520 --> 00:03:33.480]   I am also the number one Princess Peach speed runner in the entire.
[00:03:33.480 --> 00:03:35.200]   Princess Peach, baby.
[00:03:35.200 --> 00:03:37.360]   Oh my God.
[00:03:37.360 --> 00:03:40.840]   There we go.
[00:03:40.840 --> 00:03:45.440]   There's husband Frank celebrating how fast was your Princess Peach time and where can
[00:03:45.440 --> 00:03:47.200]   we see the speed run?
[00:03:47.200 --> 00:03:49.200]   It's on speedrun.com.
[00:03:49.200 --> 00:03:59.240]   And one for the normal run, it's nine minutes and for the run without saving and quitting.
[00:03:59.240 --> 00:04:02.240]   It is 15 minutes, which is an extraordinary time.
[00:04:02.240 --> 00:04:04.240]   So thank you, Frank.
[00:04:04.240 --> 00:04:08.040]   I'm very, very impressed.
[00:04:08.040 --> 00:04:10.480]   Speedrun.com folks.
[00:04:10.480 --> 00:04:12.480]   There we go later.
[00:04:12.480 --> 00:04:13.480]   Yeah, we were.
[00:04:13.480 --> 00:04:14.480]   Wow.
[00:04:14.480 --> 00:04:15.480]   Where's Princess Peach?
[00:04:15.480 --> 00:04:16.480]   I got to find it.
[00:04:16.480 --> 00:04:18.240]   Let's say hello to Daniel Robino.
[00:04:18.240 --> 00:04:21.080]   He is the executive editor at Windows Central.
[00:04:21.080 --> 00:04:23.840]   Great to see you, Daniel.
[00:04:23.840 --> 00:04:24.840]   Same here.
[00:04:24.840 --> 00:04:28.040]   Also the host of the Windows Central podcast.
[00:04:28.040 --> 00:04:29.040]   Is it Friday?
[00:04:29.040 --> 00:04:30.040]   Every Friday?
[00:04:30.040 --> 00:04:31.040]   Yeah.
[00:04:31.040 --> 00:04:35.480]   Friday is 1.30 p.m. Eastern time on our YouTube channel for then it gets posted later.
[00:04:35.480 --> 00:04:36.480]   Perfect.
[00:04:36.480 --> 00:04:41.480]   And are you, do you have any unusual accomplishments you'd like to share with us?
[00:04:41.480 --> 00:04:42.480]   No.
[00:04:42.480 --> 00:04:44.480]   I own a car.
[00:04:44.480 --> 00:04:47.480]   I own a car.
[00:04:47.480 --> 00:04:48.480]   Yeah.
[00:04:48.480 --> 00:04:52.280]   So the, so where would I find?
[00:04:52.280 --> 00:04:54.760]   I want to see your speedrun.
[00:04:54.760 --> 00:04:55.760]   Where would I find it?
[00:04:55.760 --> 00:04:56.760]   I just dropped it in the chat.
[00:04:56.760 --> 00:04:57.760]   Oh good.
[00:04:57.760 --> 00:04:58.760]   That makes it easy.
[00:04:58.760 --> 00:04:59.760]   Original one on a.
[00:04:59.760 --> 00:05:00.760]   Oh, there's a Vimeo of it.
[00:05:00.760 --> 00:05:01.760]   Yep.
[00:05:01.760 --> 00:05:02.760]   Nice.
[00:05:02.760 --> 00:05:04.680]   Because you've got to, you have to record it because you've got to prove it.
[00:05:04.680 --> 00:05:08.640]   You actually have nerds that go through it and like look at how.
[00:05:08.640 --> 00:05:11.040]   Oh no, I can tell that that was an edit point.
[00:05:11.040 --> 00:05:12.040]   Yeah.
[00:05:12.040 --> 00:05:13.040]   Yeah.
[00:05:13.040 --> 00:05:17.640]   So this is all in one, one run.
[00:05:17.640 --> 00:05:19.400]   You said you had a big breaking story.
[00:05:19.400 --> 00:05:21.480]   This was not the first thing that came to mind.
[00:05:21.480 --> 00:05:27.880]   I must say, is this, how many times have you, how long and how many times have you been
[00:05:27.880 --> 00:05:28.880]   playing?
[00:05:28.880 --> 00:05:29.880]   You've been playing this game.
[00:05:29.880 --> 00:05:30.880]   I've been playing this game since 1998.
[00:05:30.880 --> 00:05:31.880]   So 24 years.
[00:05:31.880 --> 00:05:36.960]   So you, and you've got, in order to do this speedrun, you have to have it completely memorized.
[00:05:36.960 --> 00:05:38.840]   I noticed you're not collecting all the coins.
[00:05:38.840 --> 00:05:39.840]   The ideas get through.
[00:05:39.840 --> 00:05:40.840]   Nope.
[00:05:40.840 --> 00:05:41.840]   You're not trying to do anything.
[00:05:41.840 --> 00:05:42.840]   You're just trying to get through.
[00:05:42.840 --> 00:05:43.840]   Yeah.
[00:05:43.840 --> 00:05:45.440]   You have to go through with no health.
[00:05:45.440 --> 00:05:47.360]   You can't stop and get in the mushrooms.
[00:05:47.360 --> 00:05:50.640]   You break the game and a ton of points.
[00:05:50.640 --> 00:05:55.520]   It's, I literally sit there and play the work fight at the end for like a few hours at
[00:05:55.520 --> 00:05:58.080]   a time just playing the same two minutes.
[00:05:58.080 --> 00:05:59.520]   It is absurd.
[00:05:59.520 --> 00:06:04.320]   Do you, as you're doing this, like you get here and you do screw up, you start over,
[00:06:04.320 --> 00:06:05.320]   right?
[00:06:05.320 --> 00:06:06.320]   I mean, you don't.
[00:06:06.320 --> 00:06:07.320]   Yeah.
[00:06:07.320 --> 00:06:08.320]   You've got to.
[00:06:08.320 --> 00:06:11.160]   And that's to me that now what, so you don't want to fight this guy.
[00:06:11.160 --> 00:06:13.640]   Oh, you knew he'd send you an egg.
[00:06:13.640 --> 00:06:15.920]   He could, you could pop him with the egg.
[00:06:15.920 --> 00:06:17.480]   Oh, you're good.
[00:06:17.480 --> 00:06:19.720]   So this, this works like this.
[00:06:19.720 --> 00:06:20.720]   Yes.
[00:06:20.720 --> 00:06:21.720]   This is Birdo.
[00:06:21.720 --> 00:06:25.080]   She throws a neck at you every 128 frames.
[00:06:25.080 --> 00:06:27.560]   So it doesn't matter.
[00:06:27.560 --> 00:06:29.640]   You can like be a little slower on this fight.
[00:06:29.640 --> 00:06:32.440]   It doesn't matter.
[00:06:32.440 --> 00:06:35.000]   Every she's, it's down to the frames.
[00:06:35.000 --> 00:06:36.000]   It is.
[00:06:36.000 --> 00:06:38.560]   Do you have some special tools that you use to analyze?
[00:06:38.560 --> 00:06:40.560]   How do you know it's under 28 frames?
[00:06:40.560 --> 00:06:44.160]   Oh God, you, you look at it in quick time after you do it.
[00:06:44.160 --> 00:06:45.160]   Oh my God.
[00:06:45.160 --> 00:06:46.160]   It's just obsessed about it.
[00:06:46.160 --> 00:06:47.160]   You're kidding.
[00:06:47.160 --> 00:06:50.880]   See how you go down here so you don't render and she moves faster.
[00:06:50.880 --> 00:06:53.440]   Oh, that's a trick.
[00:06:53.440 --> 00:06:54.440]   That's a trick.
[00:06:54.440 --> 00:06:57.640]   Get off screen and she will move faster.
[00:06:57.640 --> 00:06:59.480]   That's right.
[00:06:59.480 --> 00:07:02.280]   This is kind of a subcom.
[00:07:02.280 --> 00:07:03.840]   That's what this is.
[00:07:03.840 --> 00:07:05.800]   Oh, I read 128.
[00:07:05.800 --> 00:07:07.880]   Every 128 frames, you're going to get an egg.
[00:07:07.880 --> 00:07:09.240]   One, two, three.
[00:07:09.240 --> 00:07:10.240]   Okay.
[00:07:10.240 --> 00:07:12.280]   Do you know like what frame you're at right now?
[00:07:12.280 --> 00:07:14.120]   Like can you kind of tell?
[00:07:14.120 --> 00:07:16.120]   Like I know when the egg's coming in.
[00:07:16.120 --> 00:07:20.760]   You know when the bus is going to come and when you have to be there by so you can make
[00:07:20.760 --> 00:07:23.600]   a few frames.
[00:07:23.600 --> 00:07:25.160]   You should write a book on this.
[00:07:25.160 --> 00:07:26.160]   I really should.
[00:07:26.160 --> 00:07:29.240]   How many speedrun records have you got now?
[00:07:29.240 --> 00:07:34.320]   For like number one only two, but I've been working on my jail run for Resident Evil 3.
[00:07:34.320 --> 00:07:36.800]   So I'm going to be competitive and not Sam.
[00:07:36.800 --> 00:07:42.120]   So this is you are at this point the fastest person in this game.
[00:07:42.120 --> 00:07:43.760]   Game the entire world in the entire world.
[00:07:43.760 --> 00:07:46.200]   Do you think you will this record will be broken?
[00:07:46.200 --> 00:07:47.200]   Yeah.
[00:07:47.200 --> 00:07:48.200]   Yeah.
[00:07:48.200 --> 00:07:50.800]   There are a lot of mistakes I made and one of the things I want to encourage people to
[00:07:50.800 --> 00:07:53.320]   do is come be my talent.
[00:07:53.320 --> 00:07:56.600]   Like gutterspeedrun.com, join the discord.
[00:07:56.600 --> 00:07:58.080]   This is a lot of fun to play.
[00:07:58.080 --> 00:08:03.360]   One of the reasons the Game Boy version of it is a lot of fun to play is it renders really
[00:08:03.360 --> 00:08:05.800]   well on the Mac M1.
[00:08:05.800 --> 00:08:08.480]   So I use Open EMU.
[00:08:08.480 --> 00:08:10.320]   The community doesn't frown on emulators.
[00:08:10.320 --> 00:08:11.960]   Oh, you're doing this in an emulator.
[00:08:11.960 --> 00:08:12.960]   This you're not.
[00:08:12.960 --> 00:08:13.960]   I don't.
[00:08:13.960 --> 00:08:17.520]   I play on original hardware, but you don't have to with this community.
[00:08:17.520 --> 00:08:22.360]   So there's a really low barrier to entry as opposed to other games where you've got
[00:08:22.360 --> 00:08:27.600]   to buy a retro tank and an original NES and something to record it with.
[00:08:27.600 --> 00:08:29.920]   Like there's a really high barrier.
[00:08:29.920 --> 00:08:34.280]   So come join our community speedrun this game with me and maybe you can beat my princess
[00:08:34.280 --> 00:08:36.680]   for each time I'd love to see it.
[00:08:36.680 --> 00:08:38.520]   So fun.
[00:08:38.520 --> 00:08:39.520]   That's awesome.
[00:08:39.520 --> 00:08:40.520]   How much?
[00:08:40.520 --> 00:08:41.520]   Okay.
[00:08:41.520 --> 00:08:44.960]   Well, I'm not going to watch the whole thing, but I'm tempted to.
[00:08:44.960 --> 00:08:47.600]   I'm really enjoying it.
[00:08:47.600 --> 00:08:51.520]   If you want to watch it, it's on Vimeo and Brianna's channel, Brianna Wu, or you go to
[00:08:51.520 --> 00:08:55.080]   speedrun.com and there you go about it.
[00:08:55.080 --> 00:08:56.080]   Wow.
[00:08:56.080 --> 00:08:57.080]   That is so interesting.
[00:08:57.080 --> 00:09:01.720]   It's a good use of my time.
[00:09:01.720 --> 00:09:03.720]   Good use of my time.
[00:09:03.720 --> 00:09:09.800]   Back in the 1990s, can you imagine that people would be doing speedruns like this and posting
[00:09:09.800 --> 00:09:12.480]   them for records?
[00:09:12.480 --> 00:09:16.080]   What gets me is everyone there is like 20 years younger than me and they're obsessed
[00:09:16.080 --> 00:09:17.880]   with these games like we were back then.
[00:09:17.880 --> 00:09:18.880]   Yeah.
[00:09:18.880 --> 00:09:19.880]   I can understand why you're obsessed.
[00:09:19.880 --> 00:09:20.880]   You're like a baby duck.
[00:09:20.880 --> 00:09:22.480]   You got imprinted with it as you were a kid.
[00:09:22.480 --> 00:09:28.560]   But to for a young person a day to go back in time and play an old game is interesting.
[00:09:28.560 --> 00:09:31.600]   But I get are the games not as good these days or?
[00:09:31.600 --> 00:09:33.840]   I think it's because it's on a cartridge.
[00:09:33.840 --> 00:09:37.800]   They're just fewer ways to cheat these older NES games.
[00:09:37.800 --> 00:09:38.960]   There's something master.
[00:09:38.960 --> 00:09:41.480]   What's the emulator you recommend for the M1?
[00:09:41.480 --> 00:09:42.800]   I use OpenEME.
[00:09:42.800 --> 00:09:44.600]   It works better.
[00:09:44.600 --> 00:09:46.760]   Yeah, it's fantastic.
[00:09:46.760 --> 00:09:47.760]   Sorry Daniel.
[00:09:47.760 --> 00:09:48.760]   Now.
[00:09:48.760 --> 00:09:49.760]   No worries.
[00:09:49.760 --> 00:09:54.120]   Let's talk about Microsoft.
[00:09:54.120 --> 00:09:59.840]   This was an interesting week because first meta had an event on Tuesday and then Microsoft
[00:09:59.840 --> 00:10:08.680]   had an event on Wednesday and Satya Nadella, the CEO of Microsoft did not show up for
[00:10:08.680 --> 00:10:10.520]   the Microsoft Surface announcement.
[00:10:10.520 --> 00:10:12.040]   It was Panos Panay.
[00:10:12.040 --> 00:10:18.840]   He did show up for Mark Zuckerberg's meta announcement, which is a confusing signal to
[00:10:18.840 --> 00:10:19.840]   send.
[00:10:19.840 --> 00:10:25.000]   I know I know Satya was at the Ignite conference and there were many more talks later in the
[00:10:25.000 --> 00:10:26.000]   day.
[00:10:26.000 --> 00:10:30.920]   But it was a weird message to say, oh, and Mark Zuckerberg is walking us over, and oh,
[00:10:30.920 --> 00:10:31.920]   look, who's here?
[00:10:31.920 --> 00:10:33.640]   Satya Nadella.
[00:10:33.640 --> 00:10:39.240]   But this was I think important to their strategy because they were, my meta announced, of course,
[00:10:39.240 --> 00:10:48.360]   their new pro version of the Quest, $1,500 pro version of the Quest.
[00:10:48.360 --> 00:10:52.160]   And what was weird is they didn't focus on gaming at all.
[00:10:52.160 --> 00:10:54.600]   They focused on productivity.
[00:10:54.600 --> 00:10:58.880]   And Microsoft was there to announce that you're going to be able to use Windows 11 with the
[00:10:58.880 --> 00:11:03.920]   new Quest and you're going to be able to use Office with the new Quest.
[00:11:03.920 --> 00:11:09.440]   Is it, does it seem odd to you that Satya was at this event and not his own?
[00:11:09.440 --> 00:11:15.560]   I don't think so because Microsoft ever since he took his job as CEO is taking this position
[00:11:15.560 --> 00:11:21.000]   of Microsoft is very open and willing to work with any other company that will basically
[00:11:21.000 --> 00:11:22.800]   have them.
[00:11:22.800 --> 00:11:24.840]   You're getting away from the closed ecosystem thing.
[00:11:24.840 --> 00:11:28.920]   And while Microsoft is building its own metaverse and using its own tools and doing its
[00:11:28.920 --> 00:11:34.840]   own thing with HoloLens and whatever comes next after the recent reorganization, they
[00:11:34.840 --> 00:11:37.760]   want to be where the technology is going.
[00:11:37.760 --> 00:11:42.240]   Maybe Facebook's meta system will take off and do very well.
[00:11:42.240 --> 00:11:47.760]   And why would they want to join later on versus being on the bottom floor?
[00:11:47.760 --> 00:11:52.640]   If it takes off and becomes the next Facebook, they're right there with their own productivity
[00:11:52.640 --> 00:11:55.320]   tools with Microsoft Teams and everything else.
[00:11:55.320 --> 00:11:57.960]   So I think it's actually a smart move.
[00:11:57.960 --> 00:12:01.480]   We don't know the status of their own hardware, what they're going to do.
[00:12:01.480 --> 00:12:05.520]   There's rumors that they have a partnership with Samsung to build some kind of headset.
[00:12:05.520 --> 00:12:07.360]   We're not really too sure what that's going to be.
[00:12:07.360 --> 00:12:11.080]   We don't know the future of HoloLens in terms of enterprise use.
[00:12:11.080 --> 00:12:16.000]   So I think this is a safe bet for them in terms of making sure that their software and
[00:12:16.000 --> 00:12:20.280]   services are being continued to be used no matter who builds the hardware.
[00:12:20.280 --> 00:12:24.440]   I'm pretty positive, whatever Apple comes out with, Microsoft will want to be there as
[00:12:24.440 --> 00:12:28.840]   well and have all their apps and services that are relevant to that platform be right
[00:12:28.840 --> 00:12:30.320]   there for their customers.
[00:12:30.320 --> 00:12:34.920]   And I think it makes sense instead of just being everything focused on Microsoft, you
[00:12:34.920 --> 00:12:36.160]   know, in their hardware.
[00:12:36.160 --> 00:12:38.960]   They just want to be open and be wherever they can.
[00:12:38.960 --> 00:12:43.120]   It used to be Microsoft's mission statement that there would be a computer on every desk
[00:12:43.120 --> 00:12:47.000]   in every home running Microsoft software.
[00:12:47.000 --> 00:12:51.640]   Now Satya Nizala says we want to be where our customers are.
[00:12:51.640 --> 00:12:56.720]   So this is it hedging their bets that HoloLens won't take off or just saying we don't
[00:12:56.720 --> 00:12:57.720]   care anymore.
[00:12:57.720 --> 00:12:59.800]   We're not a platform company anymore.
[00:12:59.800 --> 00:13:02.640]   We're more of a services company, I guess.
[00:13:02.640 --> 00:13:04.920]   I think it's because there are services companies, right?
[00:13:04.920 --> 00:13:08.280]   And HoloLens, the mission statement there is a little bit, we're not really too sure
[00:13:08.280 --> 00:13:09.280]   anymore.
[00:13:09.280 --> 00:13:10.280]   HoloLens is augmented.
[00:13:10.280 --> 00:13:11.280]   That's an interesting mission statement.
[00:13:11.280 --> 00:13:12.280]   Yeah.
[00:13:12.280 --> 00:13:13.280]   But we're not sure.
[00:13:13.280 --> 00:13:14.280]   Right?
[00:13:14.280 --> 00:13:17.280]   I mean, my word, my not.
[00:13:17.280 --> 00:13:22.160]   Well, it's augmented reality and it's built, you know, like I was just said in Israel within
[00:13:22.160 --> 00:13:29.600]   tell, they're using it within the boundaries in the fab to both train people on how to
[00:13:29.600 --> 00:13:34.240]   fix the equipment and also for remote help using equipment.
[00:13:34.240 --> 00:13:38.440]   So someone's attack is having a problem fixing something so it can remote in, see what they're
[00:13:38.440 --> 00:13:44.040]   seeing, and then literally overlay in real time tools or pointing to things and you want
[00:13:44.040 --> 00:13:45.040]   to do this and that.
[00:13:45.040 --> 00:13:50.000]   So that's an example of how HoloLens in an industrial use is being used, but it's future
[00:13:50.000 --> 00:13:55.680]   in terms of more enterprise use for this idea of like being in virtual meetings.
[00:13:55.680 --> 00:14:00.440]   You know, I'm not really sure HoloLens quite has that role as is because this is more blurring
[00:14:00.440 --> 00:14:05.840]   into like a virtual reality where you're actually going to another world, you know, and Alex
[00:14:05.840 --> 00:14:10.840]   Kippman before he technically left Microsoft, although he's still there apparently as a
[00:14:10.840 --> 00:14:16.760]   consultant, you know, he did have this idea that eventually HoloLens would switch over
[00:14:16.760 --> 00:14:19.120]   to a virtual reality.
[00:14:19.120 --> 00:14:23.320]   There's this concept, of course, of having a clear glass where you can use AR and then
[00:14:23.320 --> 00:14:26.360]   it can change intent to dark mode.
[00:14:26.360 --> 00:14:28.600]   That's tech is probably still a little bit out.
[00:14:28.600 --> 00:14:33.040]   So instead of what these companies are doing or just using front-facing cameras to simulate
[00:14:33.040 --> 00:14:35.760]   the, you know, so you can actually see where you are.
[00:14:35.760 --> 00:14:39.400]   And then it's just usually on the inside where it's dark and you can create a virtual reality.
[00:14:39.400 --> 00:14:43.960]   That's sort of a, you know, a half step until this other technology, I think, becomes reality.
[00:14:43.960 --> 00:14:50.880]   Alex Kippman's keynote last year for HoloLens was the one that famously kind of descended
[00:14:50.880 --> 00:14:59.680]   into a Burning Man dance festival in some sort of weird way.
[00:14:59.680 --> 00:15:04.680]   And by the way, there's Gila LibertÃ©, who is the founder of Cirque du Soleil, about
[00:15:04.680 --> 00:15:12.440]   to take Alex on a magic carpet ride into the future.
[00:15:12.440 --> 00:15:17.320]   Interestingly, also in the news right about the same time, the US Army is starting to
[00:15:17.320 --> 00:15:22.640]   report that soldiers are getting sick in the HoloLens.
[00:15:22.640 --> 00:15:28.720]   Remember that Microsoft did a $22 billion deal with the army to provide HoloLens for
[00:15:28.720 --> 00:15:31.120]   combat troops.
[00:15:31.120 --> 00:15:37.360]   The devices would have gotten us killed according to an army report leaked.
[00:15:37.360 --> 00:15:41.440]   And they also said, this is Bloomberg and Business Society are the same, they saw this
[00:15:41.440 --> 00:15:42.440]   story.
[00:15:42.440 --> 00:15:49.040]   They also said that 80% of the soldiers were not seeated under three hours, not ideal for
[00:15:49.040 --> 00:15:52.360]   combat missions.
[00:15:52.360 --> 00:15:59.360]   So with Kippman leaving, the rumors flying that Microsoft is backing off on HoloLens.
[00:15:59.360 --> 00:16:02.520]   And then this satin et al is showing up at meta.
[00:16:02.520 --> 00:16:07.600]   You don't think that that's an indicator that Microsoft maybe has lost confidence in
[00:16:07.600 --> 00:16:08.600]   HoloLens?
[00:16:08.600 --> 00:16:13.080]   Well, they did split the organization into hardware and software.
[00:16:13.080 --> 00:16:17.000]   And so what you saw with Facebook and meta, I should say, is the software organization
[00:16:17.000 --> 00:16:18.680]   continuing their work.
[00:16:18.680 --> 00:16:20.360]   In terms of hardware, we don't know.
[00:16:20.360 --> 00:16:22.960]   They do have a hardware division dedicated to this.
[00:16:22.960 --> 00:16:25.760]   There was also this, so there's this contract with the military.
[00:16:25.760 --> 00:16:30.240]   There's also a supposed contract with Samsung where Samsung is going to build the hardware
[00:16:30.240 --> 00:16:32.400]   and use some of Microsoft's technology.
[00:16:32.400 --> 00:16:36.680]   We don't know much more about that in terms of what's the goal?
[00:16:36.680 --> 00:16:37.960]   Is that a consumer device?
[00:16:37.960 --> 00:16:38.960]   Is it more enterprise?
[00:16:38.960 --> 00:16:40.360]   We really don't know.
[00:16:40.360 --> 00:16:44.240]   And we don't know since the reorg, you know, what they're planning on doing.
[00:16:44.240 --> 00:16:49.160]   Are they going to continue with HoloLens 3, which was technically scrapped for a while?
[00:16:49.160 --> 00:16:52.160]   Are they going to try to aim more towards the consumer ends?
[00:16:52.160 --> 00:16:55.160]   So we're going to have to wait and find out what their plans are.
[00:16:55.160 --> 00:16:59.720]   I would imagine they still have a lot of tech that they innovated in this area.
[00:16:59.720 --> 00:17:04.240]   It would be weird that they would just give up and not use it right now.
[00:17:04.240 --> 00:17:08.600]   But we'll have to kind of see, you know, as links come out or Microsoft gives the presentation
[00:17:08.600 --> 00:17:10.560]   on what they are planning next.
[00:17:10.560 --> 00:17:14.560]   The new Quest is kind of a classic VR play.
[00:17:14.560 --> 00:17:19.080]   You can't see through it like you can with the HoloLens, but they do have outward facing
[00:17:19.080 --> 00:17:20.080]   cameras.
[00:17:20.080 --> 00:17:22.000]   And they say now it's in color.
[00:17:22.000 --> 00:17:28.360]   So it's kind of more like a mixed reality is the term that Microsoft uses and probably
[00:17:28.360 --> 00:17:32.560]   the right term for this, neither VR nor AR, but a mixed reality.
[00:17:32.560 --> 00:17:36.840]   But this is, I want to bring Brianna and Sam in on this as well.
[00:17:36.840 --> 00:17:43.560]   There's a lot of speculation that Meta has, somebody said, Meta should have made this
[00:17:43.560 --> 00:17:47.720]   an R&D project, not the future, not bet the future of the company on it.
[00:17:47.720 --> 00:17:52.720]   We spent $15 billion, they're doing about $10 billion a year on this.
[00:17:52.720 --> 00:18:02.280]   Brianna, do you, I feel like one of the reasons you're seeing Microsoft showing up at Meta,
[00:18:02.280 --> 00:18:06.240]   probably doing to deal with Apple is that no one really knows how this landscape is going
[00:18:06.240 --> 00:18:07.240]   to play out.
[00:18:07.240 --> 00:18:11.360]   So everybody's kind of hedging their bets until, you know, once somebody starts to win
[00:18:11.360 --> 00:18:15.600]   then everybody, then it all changes, of course, but that we've seen that before in our technologies.
[00:18:15.600 --> 00:18:18.520]   But my question is, is anybody going to win?
[00:18:18.520 --> 00:18:21.200]   Is this a technology anybody wants at all?
[00:18:21.200 --> 00:18:24.680]   Yeah, I had a really surreal experience.
[00:18:24.680 --> 00:18:27.400]   I mean this with all respect to Emily Chang.
[00:18:27.400 --> 00:18:28.400]   I love her.
[00:18:28.400 --> 00:18:30.760]   I've been on her show on Bloomberg many, many times.
[00:18:30.760 --> 00:18:33.560]   Fantastic person, love her.
[00:18:33.560 --> 00:18:39.240]   But something the last time I was on and noticed is it was a few times ago, it was the day
[00:18:39.240 --> 00:18:42.880]   that Facebook announced the Meta transformation.
[00:18:42.880 --> 00:18:44.760]   And there was this discussion on Wall Street.
[00:18:44.760 --> 00:18:48.040]   Oh, Meta, what is it going to be?
[00:18:48.040 --> 00:18:49.840]   What is, are they going to create?
[00:18:49.840 --> 00:18:56.800]   And it was all these Wall Street people like with these, you know, like, you know, Heinlein
[00:18:56.800 --> 00:18:59.600]   asked visions of the future about what it could be.
[00:18:59.600 --> 00:19:04.000]   And for me as a technologist, I'm saying they're listening to it, just analyzing the
[00:19:04.000 --> 00:19:07.040]   news that came out in a very different way.
[00:19:07.040 --> 00:19:11.760]   And the impression I got from that was this was more of a move for Wall Street to present
[00:19:11.760 --> 00:19:14.960]   a vision for Facebook in the future.
[00:19:14.960 --> 00:19:18.440]   Just like you were telling us before the show that you kind of had to be talked out
[00:19:18.440 --> 00:19:22.560]   of the Surface 9, you know, Meta comes out.
[00:19:22.560 --> 00:19:25.520]   I should say I did buy the Quest Pro.
[00:19:25.520 --> 00:19:26.520]   Oh, okay.
[00:19:26.520 --> 00:19:28.080]   There was the Quest Pro.
[00:19:28.080 --> 00:19:31.120]   That's partly because it has a 30 day return policy.
[00:19:31.120 --> 00:19:32.120]   Sure.
[00:19:32.120 --> 00:19:34.880]   But also I feel like it's important for me to do the due diligence.
[00:19:34.880 --> 00:19:35.880]   100%
[00:19:35.880 --> 00:19:40.560]   Every few, I was a, I did the Kickstarter for the original Oculus Quest.
[00:19:40.560 --> 00:19:42.320]   I want to give it a chance.
[00:19:42.320 --> 00:19:43.320]   Right.
[00:19:43.320 --> 00:19:44.440]   I don't want to write it off completely.
[00:19:44.440 --> 00:19:49.080]   But every time I try it, I say, well, clearly we're not ready for prime time.
[00:19:49.080 --> 00:19:50.080]   It's making me sick.
[00:19:50.080 --> 00:19:52.600]   It made 80% of the army sick.
[00:19:52.600 --> 00:19:53.600]   Right.
[00:19:53.600 --> 00:19:58.920]   I don't, I think that this is a technology that seems like a good idea.
[00:19:58.920 --> 00:20:00.120]   But we don't have the means yet.
[00:20:00.120 --> 00:20:01.680]   Yeah, that's 100%.
[00:20:01.680 --> 00:20:07.080]   And that's 100% my point that, you know, I bought the original, I've ever VR system to
[00:20:07.080 --> 00:20:09.560]   exist because I've done development on this.
[00:20:09.560 --> 00:20:10.560]   Oh, have you?
[00:20:10.560 --> 00:20:11.560]   Okay.
[00:20:11.560 --> 00:20:12.560]   Yeah.
[00:20:12.560 --> 00:20:13.560]   It makes sense for gaming.
[00:20:13.560 --> 00:20:14.560]   I think it completely makes sense for gaming.
[00:20:14.560 --> 00:20:18.080]   It can, but I have the exact same, I say, I buy a Quest.
[00:20:18.080 --> 00:20:21.000]   It's a really fun 28, 24 to 48 hours.
[00:20:21.000 --> 00:20:22.000]   Yeah.
[00:20:22.000 --> 00:20:23.000]   And then it's like never again.
[00:20:23.000 --> 00:20:24.000]   I bought the Quest 2.
[00:20:24.000 --> 00:20:25.000]   Yeah.
[00:20:25.000 --> 00:20:29.520]   I had a really fun, like seeing how much better Beat Saber was and then lived in a drawer.
[00:20:29.520 --> 00:20:34.520]   And I'm asking myself, when it comes to these kinds of meetings with people, do I think
[00:20:34.520 --> 00:20:39.520]   there's any chance I'm actually going to sit down and ever have a VR meeting with
[00:20:39.520 --> 00:20:40.520]   someone?
[00:20:40.520 --> 00:20:43.720]   I just, I don't see that ever happening.
[00:20:43.720 --> 00:20:46.880]   This isn't a new phase for Facebook.
[00:20:46.880 --> 00:20:52.240]   They acquired Oculus in 2014 when the stories for a story coming out.
[00:20:52.240 --> 00:20:56.000]   And now eight years later, the question is, where's the users?
[00:20:56.000 --> 00:20:57.520]   Where's the use case for this?
[00:20:57.520 --> 00:21:00.360]   Where are people wanting to have this experience?
[00:21:00.360 --> 00:21:03.360]   And it just, it does not exist, unfortunately.
[00:21:03.360 --> 00:21:09.480]   Ben Thompson writing about this in his trajectory, he got an interview with Zuck Ann Nadella.
[00:21:09.480 --> 00:21:14.640]   Together, kind of came out somewhat bullish on this.
[00:21:14.640 --> 00:21:17.480]   He says, VR does have real utility.
[00:21:17.480 --> 00:21:21.560]   But I think utility will be realized in the enterprise first, in part, because the value
[00:21:21.560 --> 00:21:25.240]   of VR only becomes apparent when you use it and you're more likely to use it if your
[00:21:25.240 --> 00:21:27.800]   company pays for it.
[00:21:27.800 --> 00:21:33.200]   He also says Microsoft is well placed to deliver that utility on top of Meta hardware.
[00:21:33.200 --> 00:21:37.000]   Meta is likely to be the catalyst for VR becoming a widely used technology.
[00:21:37.000 --> 00:21:40.840]   Now, he doesn't mention Apple at all.
[00:21:40.840 --> 00:21:46.440]   I also feel like a lot of this was a rush to get out in front of the market before Apple
[00:21:46.440 --> 00:21:48.360]   announces something early next year.
[00:21:48.360 --> 00:21:52.160]   Sam, do you think that's what's going on?
[00:21:52.160 --> 00:21:53.960]   That wouldn't surprise me.
[00:21:53.960 --> 00:22:00.880]   Meta has been, Facebook's been trying to find something new, aside from the things that
[00:22:00.880 --> 00:22:05.560]   they've bought and copied, they've never really created anything new since the beginning
[00:22:05.560 --> 00:22:06.560]   of Facebook.
[00:22:06.560 --> 00:22:11.120]   The news feed was the last car you see.
[00:22:11.120 --> 00:22:17.400]   But when you see a potential competitor, another potential competitor, one with very
[00:22:17.400 --> 00:22:23.880]   deep pockets that is potentially doing something that could be disruptive to your business,
[00:22:23.880 --> 00:22:26.640]   yeah, you may want to jump into that.
[00:22:26.640 --> 00:22:30.760]   A lot of companies said, "Oh, we should have paid attention when the iPhone came along.
[00:22:30.760 --> 00:22:34.160]   Microsoft famously, Steve Ballmer said, "Ah, it's too expensive.
[00:22:34.160 --> 00:22:35.360]   Nobody's going to buy it."
[00:22:35.360 --> 00:22:37.680]   And regretted that, lived to regret that.
[00:22:37.680 --> 00:22:40.920]   Do you think they're worried that the same thing will happen?
[00:22:40.920 --> 00:22:43.320]   That's certainly a possibility.
[00:22:43.320 --> 00:22:47.120]   Nobody wants to be left behind when there's something big.
[00:22:47.120 --> 00:22:54.960]   When you look at the smartphone space, Google and Samsung are the only ones who were able
[00:22:54.960 --> 00:23:01.440]   to respond quickly enough to the iPhone to put up real viable competition.
[00:23:01.440 --> 00:23:06.840]   Windows was too little, too late with Windows Phone.
[00:23:06.840 --> 00:23:15.200]   I think like most platforms, there's probably not room for more than maybe two at most three
[00:23:15.200 --> 00:23:17.200]   platforms.
[00:23:17.200 --> 00:23:26.440]   Whoever gets a foothold early on, it won't necessarily be the first one out the door.
[00:23:26.440 --> 00:23:31.280]   There were lots of companies that made MP3 players before the iPod came along.
[00:23:31.280 --> 00:23:35.320]   There were lots of smartphones before the iPhone.
[00:23:35.320 --> 00:23:40.920]   So it's not necessarily the first that is going to succeed, but whoever does it right
[00:23:40.920 --> 00:23:47.040]   first, whoever comes up with a good product first is going to have a better chance of
[00:23:47.040 --> 00:23:48.040]   success.
[00:23:48.040 --> 00:23:55.240]   And then maybe the second and the third, but most likely only the second will really
[00:23:55.240 --> 00:24:02.720]   have an opportunity to be competitive with them because of all the platform lock-in challenges.
[00:24:02.720 --> 00:24:11.960]   But going back to what Priana and Daniel said, and you said, this is not something that I
[00:24:11.960 --> 00:24:14.800]   want to use even in an editor.
[00:24:14.800 --> 00:24:17.760]   There are some good applications for this.
[00:24:17.760 --> 00:24:22.560]   Some of the training stuff that's done with systems like HoloLens is really useful.
[00:24:22.560 --> 00:24:27.480]   I've seen some really good applications for VR, for example, in design.
[00:24:27.480 --> 00:24:32.320]   And Ford showed us that every big vehicle maker uses.
[00:24:32.320 --> 00:24:38.680]   When I first saw the Lucid Air in 2016, I was with their head of design, and he put an
[00:24:38.680 --> 00:24:44.520]   HTC Vive on my head, and he gave me a design walk around with that before seeing the actual
[00:24:44.520 --> 00:24:46.000]   car.
[00:24:46.000 --> 00:24:54.040]   And it's not just cars, but any kind of product design, it's a great use case for that.
[00:24:54.040 --> 00:25:00.880]   But for meetings like meeting with people, I don't want to sit around with a headset
[00:25:00.880 --> 00:25:04.760]   on for four, five, six, eight hours a day.
[00:25:04.760 --> 00:25:09.080]   That is just not something people are not going to want to do that.
[00:25:09.080 --> 00:25:15.960]   I've done shorter stints, briefings with, I did a briefing with an automaker last year
[00:25:15.960 --> 00:25:24.960]   where they sent out Quest headsets to do this briefing in the Quest environment.
[00:25:24.960 --> 00:25:32.640]   And once you put that headset on, if I'm in a meeting or in a briefing, I want to take
[00:25:32.640 --> 00:25:38.960]   notes, whether it's handwritten notes or type, I want to be able to take notes.
[00:25:38.960 --> 00:25:44.040]   Sometimes recording stuff, you can't do that when you're in a VR headset.
[00:25:44.040 --> 00:25:47.840]   It's just a terrible environment to spend extended periods of time in for work.
[00:25:47.840 --> 00:25:50.400]   It really makes me ask, what's the problem it's trying to solve?
[00:25:50.400 --> 00:25:56.760]   I mean, Zoom meetings, maybe not the best thing in the world, but neither are in person
[00:25:56.760 --> 00:25:58.840]   meetings, but they work.
[00:25:58.840 --> 00:26:05.240]   And I'm not sure why it would be better to do teams in an Oculus Pro Daniel.
[00:26:05.240 --> 00:26:06.640]   Do you do agree, disagree?
[00:26:06.640 --> 00:26:08.840]   You think that that's the future of meetings?
[00:26:08.840 --> 00:26:09.840]   Yeah.
[00:26:09.840 --> 00:26:13.960]   You know, it's like, I see augmented reality where you still see that you're rolled around
[00:26:13.960 --> 00:26:19.680]   you and holograms and everything there is the real goal of all this.
[00:26:19.680 --> 00:26:22.040]   And that seems to me, it's going to be really interesting.
[00:26:22.040 --> 00:26:28.280]   But I feel like that's still so many years off from being a reality for average people,
[00:26:28.280 --> 00:26:30.720]   you know, who can't afford a $3,000 headset.
[00:26:30.720 --> 00:26:35.640]   And even there, the use case, it's like, we still need smarter technology to make use
[00:26:35.640 --> 00:26:38.800]   of it, you know, like this idea of like, and it's kind of scary, right?
[00:26:38.800 --> 00:26:43.800]   Walk it around, but you have a camera on there, visually IDs a person and brings up
[00:26:43.800 --> 00:26:49.080]   their info automatically, or you can ID stuff quickly and look it up.
[00:26:49.080 --> 00:26:50.600]   Almost like being a cyborg, right?
[00:26:50.600 --> 00:26:53.840]   Like, I feel like that's where all this will eventually go.
[00:26:53.840 --> 00:26:54.840]   And that makes sense.
[00:26:54.840 --> 00:26:59.080]   But this idea of like a VR headset and don't forget Microsoft years ago showed up like
[00:26:59.080 --> 00:27:00.080]   they called it a hollow portation.
[00:27:00.080 --> 00:27:04.640]   We would have used like a room and a bunch of cameras in it and would scan you and it
[00:27:04.640 --> 00:27:06.880]   would create a hologram with a person.
[00:27:06.880 --> 00:27:10.040]   And this idea like, you know, in the future, we may have like little setups in our homes
[00:27:10.040 --> 00:27:11.040]   that does that.
[00:27:11.040 --> 00:27:15.400]   It's a little bit more realistic in a sense because you're still like in your environment,
[00:27:15.400 --> 00:27:19.560]   you could still take note, you could still do stuff while you see a hologram of a person.
[00:27:19.560 --> 00:27:23.600]   And I think that makes sense for, but again, limited cases.
[00:27:23.600 --> 00:27:28.760]   And I bet Apple, you know, Apple's play here is rumored to be along the, you know,
[00:27:28.760 --> 00:27:32.080]   I message and, you know, making video calls.
[00:27:32.080 --> 00:27:35.840]   And I'm sure it's going to be something along those lines where it's connecting like FaceTime,
[00:27:35.840 --> 00:27:36.840]   a virtual FaceTime.
[00:27:36.840 --> 00:27:42.000]   And I think that might work in this idea of like you're making limited calls to people
[00:27:42.000 --> 00:27:45.400]   and have not, but not necessarily meetings.
[00:27:45.400 --> 00:27:48.440]   Yeah, I don't really see a huge use case for it.
[00:27:48.440 --> 00:27:50.920]   You know, Sam mentioned some really good issues, right?
[00:27:50.920 --> 00:27:55.640]   Taking notes, I think is a pretty big limitation if you're going to be in a meeting all day.
[00:27:55.640 --> 00:27:59.600]   But, um, yeah, I mean, is this a better way or is this just another way?
[00:27:59.600 --> 00:28:03.480]   So I think there's a group sync mentality when everybody in Silicon Valley is going,
[00:28:03.480 --> 00:28:08.360]   yeah, yeah, VR, VR, AR, AR, Mickstar, that there's this kind of thing like, oh, well,
[00:28:08.360 --> 00:28:09.800]   they must know what they're talking about.
[00:28:09.800 --> 00:28:16.720]   And the more people do it, but I, is it possible they just could be completely wrong and that
[00:28:16.720 --> 00:28:22.560]   there is that Facebook's been $10 a year and tens of thousands of engineers on something
[00:28:22.560 --> 00:28:26.240]   that is just never going to take off.
[00:28:26.240 --> 00:28:27.240]   Remember when 3D came back?
[00:28:27.240 --> 00:28:29.600]   Yeah, 3D TV is a really good example.
[00:28:29.600 --> 00:28:30.600]   3D TV's.
[00:28:30.600 --> 00:28:34.720]   It's been 3D's of movie theaters, like it just kind of came, it peaked a little bit and just,
[00:28:34.720 --> 00:28:36.960]   you know, no one did the 3D TV thing, right?
[00:28:36.960 --> 00:28:38.600]   And it seemed like a great idea.
[00:28:38.600 --> 00:28:39.600]   Like why not?
[00:28:39.600 --> 00:28:41.760]   But it just never caught on.
[00:28:41.760 --> 00:28:43.480]   Nobody wanted to wear the glasses.
[00:28:43.480 --> 00:28:44.480]   Yeah.
[00:28:44.480 --> 00:28:45.480]   And then that was the first.
[00:28:45.480 --> 00:28:46.480]   Can we go through history?
[00:28:46.480 --> 00:28:47.480]   Yeah.
[00:28:47.480 --> 00:28:48.480]   Sorry.
[00:28:48.480 --> 00:28:49.480]   I just want to say, can we go through history here a bit?
[00:28:49.480 --> 00:28:54.880]   Well, I find really interesting about all of this is think through the history of the
[00:28:54.880 --> 00:28:56.320]   computer industry.
[00:28:56.320 --> 00:29:00.840]   More word processors and spreadsheets were easy to use.
[00:29:00.840 --> 00:29:05.040]   Geeks, people like us, we saw that we were early adopters.
[00:29:05.040 --> 00:29:08.000]   We were like, this is such a good experience.
[00:29:08.000 --> 00:29:11.480]   We're willing to put up with the headaches and we pushed through.
[00:29:11.480 --> 00:29:16.840]   We did that exact same pattern for MP3 players before it became something like the iPhone.
[00:29:16.840 --> 00:29:20.880]   We did it with personal data assistance back when it was the Palm Pilot.
[00:29:20.880 --> 00:29:22.200]   We did it on the internet.
[00:29:22.200 --> 00:29:30.040]   When it was the 2400-bod modem that you were dialing into, there's a pattern of us for
[00:29:30.040 --> 00:29:35.640]   all of us here that we see the value in these things and we jump in early and we deal with
[00:29:35.640 --> 00:29:39.080]   the headaches and we put our foot down with all of that.
[00:29:39.080 --> 00:29:46.560]   I think it is so important to this that everyone on the show today has tried VR.
[00:29:46.560 --> 00:29:48.480]   We've given it a fair shake.
[00:29:48.480 --> 00:29:52.520]   And as we're all saying, it's something that lives in a drawer eventually.
[00:29:52.520 --> 00:29:59.280]   There is something that's just fundamentally not useful about any of this.
[00:29:59.280 --> 00:30:04.520]   And even for the case, like you're talking about Daniel, like the HoloLens presentation
[00:30:04.520 --> 00:30:08.880]   a while back, Zuckerberg had two avatars he put out.
[00:30:08.880 --> 00:30:11.760]   One was a cartoony, silly looking thing.
[00:30:11.760 --> 00:30:16.800]   The other one was like a photorealistic thing for him to put his vision forward.
[00:30:16.800 --> 00:30:23.280]   And I saw with that as a game developer with something that the average consumer is going
[00:30:23.280 --> 00:30:29.920]   to have to spend $25,000 having a team of people make with ZBrush and normal mapping
[00:30:29.920 --> 00:30:35.520]   and rigging and texture mapping and painting wrinkles into the skin and all this other
[00:30:35.520 --> 00:30:38.240]   stuff that no one is ever going to do.
[00:30:38.240 --> 00:30:42.440]   And I just don't see people spending that money.
[00:30:42.440 --> 00:30:47.240]   And I don't think this is a process that can be automated in a way that looks anywhere
[00:30:47.240 --> 00:30:48.480]   remotely real.
[00:30:48.480 --> 00:30:53.840]   Like you'll get to where it just looks like, do you remember the N64 contest where they
[00:30:53.840 --> 00:30:56.400]   would put your face on a Bond character for you?
[00:30:56.400 --> 00:30:58.240]   We'll get that good.
[00:30:58.240 --> 00:31:03.880]   But it's not going to look like what's, well, it was just cheesy.
[00:31:03.880 --> 00:31:07.040]   You can cheat it with displacement maps to a certain extent.
[00:31:07.040 --> 00:31:12.640]   You're talking about something so high poly that then you're talking the only way to make
[00:31:12.640 --> 00:31:17.760]   that data smaller is to decimation pass on it, which is a professional.
[00:31:17.760 --> 00:31:19.120]   You can't automate that.
[00:31:19.120 --> 00:31:20.280]   That is judgment.
[00:31:20.280 --> 00:31:22.680]   So there's just all these things here.
[00:31:22.680 --> 00:31:25.280]   And it's like, this is not going to be better than Zoom.
[00:31:25.280 --> 00:31:30.080]   And you're taking 100 times the processing power and it's going to cost more.
[00:31:30.080 --> 00:31:31.880]   And you're going to feel sick all day.
[00:31:31.880 --> 00:31:33.560]   You said something interesting.
[00:31:33.560 --> 00:31:38.000]   And first time you hit the slash key and visit Calc.
[00:31:38.000 --> 00:31:46.640]   The first time I saw an Instagram photo, I always, I think maybe it's editing retroactively,
[00:31:46.640 --> 00:31:50.680]   but I think you knew immediately this is something.
[00:31:50.680 --> 00:31:53.200]   And you said, yeah, this is, wow, I got it.
[00:31:53.200 --> 00:31:54.680]   This is something.
[00:31:54.680 --> 00:31:58.200]   And I don't think, I don't feel that way at all about VR.
[00:31:58.200 --> 00:32:01.680]   This is always the challenge for anybody's covering tech because there's a lot of stuff
[00:32:01.680 --> 00:32:06.760]   tech comes up with that isn't, that is a non-starter is James Bond, you know, characters on your
[00:32:06.760 --> 00:32:09.560]   face or vice versa.
[00:32:09.560 --> 00:32:12.440]   And then there's a lot of, then there's every once in a while, there's something you go,
[00:32:12.440 --> 00:32:14.080]   you look at and you go, yeah, that's something.
[00:32:14.080 --> 00:32:15.080]   That's it.
[00:32:15.080 --> 00:32:16.080]   That's going to change the world.
[00:32:16.080 --> 00:32:20.760]   The iPhone when it first came out really was kind of overpriced and kind of not very,
[00:32:20.760 --> 00:32:24.960]   it couldn't cut and paste, but there was something there.
[00:32:24.960 --> 00:32:29.160]   And the same time we looked at the Newton and it was like, there's nothing there.
[00:32:29.160 --> 00:32:36.400]   You just kind of, maybe that's my memory rather than the fact, but I think you kind of know
[00:32:36.400 --> 00:32:43.280]   there was a great tweet storm earlier this week by a guy who's working at Waymo now,
[00:32:43.280 --> 00:32:46.760]   Warren Craddock, but he has worked on a lot of, he tweets, I worked on a number of high
[00:32:46.760 --> 00:32:47.840]   profile failures.
[00:32:47.840 --> 00:32:53.400]   And he talks about the LITRO light field camera, the Google glass and Google clips was which
[00:32:53.400 --> 00:32:57.600]   is that little box that would take your life story and pictures.
[00:32:57.600 --> 00:33:01.160]   And he said, every one of them had a fatal flaw.
[00:33:01.160 --> 00:33:08.720]   Everyone working on them saw the flaw, but the teams that were working on purposely ignored
[00:33:08.720 --> 00:33:10.280]   the flaw.
[00:33:10.280 --> 00:33:12.880]   And he goes on in this and I think it's really interesting.
[00:33:12.880 --> 00:33:16.720]   The example of the clips thing, which I had was really cool.
[00:33:16.720 --> 00:33:17.720]   It was a little box.
[00:33:17.720 --> 00:33:20.960]   It would take pictures of your whole day, then upload them and you could go through your
[00:33:20.960 --> 00:33:21.960]   day.
[00:33:21.960 --> 00:33:26.040]   The problem was it wasn't where your eyes are, it was where your chest is.
[00:33:26.040 --> 00:33:30.840]   So all the pictures, and he says this, they were just wrong because that's not the point
[00:33:30.840 --> 00:33:34.200]   of view we're looking for.
[00:33:34.200 --> 00:33:40.240]   And the teams that make them aren't the best judges because they're invested now.
[00:33:40.240 --> 00:33:45.640]   But when end users get Google glass, they immediately go, what?
[00:33:45.640 --> 00:33:46.640]   No.
[00:33:46.640 --> 00:33:51.400]   Daniel, do you trust your instinct when it comes to new products like that?
[00:33:51.400 --> 00:33:52.960]   Do you say, yeah, I can tell?
[00:33:52.960 --> 00:33:57.080]   Yeah, I mean, so let me give an example of something I do think has value.
[00:33:57.080 --> 00:33:58.080]   And I think it's really interesting.
[00:33:58.080 --> 00:34:03.560]   It reminds me of when I was doing some neuroscience years ago, it was always funny because we do
[00:34:03.560 --> 00:34:07.960]   the human brain and we've learned a lot about neuroscience over the years.
[00:34:07.960 --> 00:34:13.040]   But we still don't understand how the mind works on a biological level, just no idea.
[00:34:13.040 --> 00:34:18.080]   And part of it's because we don't understand fundamentals of neurons yet.
[00:34:18.080 --> 00:34:21.280]   And there was a, there was a neurologist years ago and like he wrote a book and he said,
[00:34:21.280 --> 00:34:26.280]   we should, we should master how a snail brain works first and then work our way out.
[00:34:26.280 --> 00:34:28.080]   Is this Jeff Hawkins?
[00:34:28.080 --> 00:34:32.240]   No, but I'm sure he would agree with Jeff Hawkins wrote a great book about this.
[00:34:32.240 --> 00:34:33.320]   In fact, he started a company.
[00:34:33.320 --> 00:34:36.800]   He said, we're not, we're no von Neumann machine is ever going to duplicate the brain because
[00:34:36.800 --> 00:34:38.840]   it's not massively parallel enough.
[00:34:38.840 --> 00:34:42.440]   So he's trying to create, and I think with, and no success at this point, but trying to
[00:34:42.440 --> 00:34:46.080]   recreate chips that duplicate that massively parallel brain.
[00:34:46.080 --> 00:34:48.000]   Anyway, I'm sorry to me interrupt.
[00:34:48.000 --> 00:34:49.000]   No, it's fine.
[00:34:49.000 --> 00:34:54.280]   And so there's an example here with, you know, the VR AR and all that, which is like Lenovo
[00:34:54.280 --> 00:35:00.280]   just announced a couple of weeks ago, they're called the T1 glasses, I believe they're called.
[00:35:00.280 --> 00:35:02.560]   They're coming out early next year.
[00:35:02.560 --> 00:35:08.200]   And it's a stripped down simplified single purpose device.
[00:35:08.200 --> 00:35:09.840]   They're glasses you put on.
[00:35:09.840 --> 00:35:11.920]   They have a USB C cable.
[00:35:11.920 --> 00:35:15.760]   You can plug into your phone or you can plug into your computer.
[00:35:15.760 --> 00:35:17.680]   That doesn't require any software.
[00:35:17.680 --> 00:35:20.040]   And all it does is project a second display.
[00:35:20.040 --> 00:35:21.040]   It's just a screen.
[00:35:21.040 --> 00:35:24.240]   And it's just a screen that sits in front of you.
[00:35:24.240 --> 00:35:25.600]   It's got really nice resolution.
[00:35:25.600 --> 00:35:28.000]   You know, I could actually see this working.
[00:35:28.000 --> 00:35:29.000]   Yeah.
[00:35:29.000 --> 00:35:33.320]   So if you're on a PC, say you're in public, you could actually turn your PC's display
[00:35:33.320 --> 00:35:38.080]   off and just use these, which is really good if you think about for people working on sensitive
[00:35:38.080 --> 00:35:42.120]   documents or anything that they don't want other people to see around them.
[00:35:42.120 --> 00:35:44.920]   Or you can use it literally as a second display.
[00:35:44.920 --> 00:35:46.760]   So you could just have two displays floating.
[00:35:46.760 --> 00:35:52.520]   And it doesn't require any extra CPU power because they have another pair of glasses
[00:35:52.520 --> 00:35:57.480]   that do require a massive GPU that does all the AR stuff.
[00:35:57.480 --> 00:35:59.880]   These don't have a front-facing camera.
[00:35:59.880 --> 00:36:04.000]   You can almost wear them sort of like normal glasses because you could still see out in
[00:36:04.000 --> 00:36:05.520]   the world just fine.
[00:36:05.520 --> 00:36:07.160]   You can plug them into even your iPhone.
[00:36:07.160 --> 00:36:09.560]   They will have an adapter or work with your iPhone.
[00:36:09.560 --> 00:36:12.920]   And you can walk around with your phone in your pocket and be whatever.
[00:36:12.920 --> 00:36:13.920]   Wow.
[00:36:13.920 --> 00:36:16.120]   These be great on an airplane and a coach.
[00:36:16.120 --> 00:36:17.120]   Absolutely.
[00:36:17.120 --> 00:36:18.120]   This is so cool.
[00:36:18.120 --> 00:36:21.160]   And it's micro OLED, which is a very high end.
[00:36:21.160 --> 00:36:22.400]   These might be expensive.
[00:36:22.400 --> 00:36:23.800]   You don't have a price yet, right?
[00:36:23.800 --> 00:36:27.520]   They're trying to, they told me they were like to get them between five and $800.
[00:36:27.520 --> 00:36:28.880]   But they haven't said all the price.
[00:36:28.880 --> 00:36:32.160]   See, this is much more interesting than anything we've been talking about.
[00:36:32.160 --> 00:36:33.720]   It's less ambitious.
[00:36:33.720 --> 00:36:34.720]   Striped down.
[00:36:34.720 --> 00:36:35.720]   Yeah.
[00:36:35.720 --> 00:36:36.720]   Yeah.
[00:36:36.720 --> 00:36:40.120]   Like you look at it and you like, what I just described, you either need it or you don't,
[00:36:40.120 --> 00:36:41.120]   right?
[00:36:41.120 --> 00:36:43.840]   Like there's not going to be like really in between people like, yeah, but do I really,
[00:36:43.840 --> 00:36:46.480]   you know, was it do what problem does it solve?
[00:36:46.480 --> 00:36:49.800]   Well, it solves a simple problem, which is it just gives you a second virtual display
[00:36:49.800 --> 00:36:50.800]   in front of you.
[00:36:50.800 --> 00:36:54.240]   And if you think like if, you know, an Apple Watch is a great example, and this is something
[00:36:54.240 --> 00:36:59.240]   where Apple really has a leg up, you can use your phone in the pocket, use the Apple Watch
[00:36:59.240 --> 00:37:03.360]   someday could just become the actual mouse and thing you interact with to control the
[00:37:03.360 --> 00:37:05.080]   glasses and anything you're seeing, right?
[00:37:05.080 --> 00:37:08.120]   There's a lot of opportunity here for that kind of technology.
[00:37:08.120 --> 00:37:13.400]   I think if we step back and look at this, I think this, you know, is way more interesting,
[00:37:13.400 --> 00:37:16.840]   way more practical and pragmatic for real world.
[00:37:16.840 --> 00:37:19.200]   You say in your article, and when it's central, it just makes sense.
[00:37:19.200 --> 00:37:20.800]   This is exactly what it's talking about.
[00:37:20.800 --> 00:37:23.200]   You sometimes you look at a product, you go, Oh yeah.
[00:37:23.200 --> 00:37:27.440]   And you know why this makes it's like, this is like headphones for your eyes.
[00:37:27.440 --> 00:37:31.480]   This is like any place you would wear headphones, listen audio, these, you would wear these
[00:37:31.480 --> 00:37:34.120]   like an embed or on a plane.
[00:37:34.120 --> 00:37:35.240]   It's like headphones for your eyes.
[00:37:35.240 --> 00:37:38.360]   And then it clicks, you go, Oh yeah.
[00:37:38.360 --> 00:37:41.080]   Not necessarily everybody's going to buy this, but that makes sense.
[00:37:41.080 --> 00:37:42.080]   So that's interesting.
[00:37:42.080 --> 00:37:43.080]   Yeah.
[00:37:43.080 --> 00:37:44.080]   And you have speakers built in.
[00:37:44.080 --> 00:37:45.240]   You can like listen to it.
[00:37:45.240 --> 00:37:47.120]   So yeah, you can watch a movie on them, do whatever you want.
[00:37:47.120 --> 00:37:49.880]   I can see myself in bed at night, you know, and I don't want to keep everybody up.
[00:37:49.880 --> 00:37:50.880]   Yeah, another great example.
[00:37:50.880 --> 00:37:54.080]   Yeah, you could say in bed and do whatever and you won't wake up your partner.
[00:37:54.080 --> 00:37:55.080]   Yeah.
[00:37:55.080 --> 00:37:56.080]   I need to take a break.
[00:37:56.080 --> 00:37:57.640]   I want to show you another.
[00:37:57.640 --> 00:37:58.640]   We're not done with this.
[00:37:58.640 --> 00:38:03.360]   And I kind of want to tie this into in.
[00:38:03.360 --> 00:38:08.920]   So I saw and I'm sure you saw it too, Sam, an article that said, after hundreds of billions
[00:38:08.920 --> 00:38:15.000]   of dollars and 20 years self driving cars are no farther along than they're still not
[00:38:15.000 --> 00:38:16.000]   happening.
[00:38:16.000 --> 00:38:22.480]   And I'm wondering if we are in this situation in tech right now where we're kind of peak
[00:38:22.480 --> 00:38:27.760]   tech for smartphones and things like like Google's, you know, Pixel 7 is basically a
[00:38:27.760 --> 00:38:33.200]   Pixel 6 and Apple's iPhone 14 is basically iPhone 13.
[00:38:33.200 --> 00:38:38.240]   If we're at the stage where our existing technology is peaked and companies are scrambling to
[00:38:38.240 --> 00:38:43.920]   find the next new thing, but they're wasting a lot of money on stuff that isn't going
[00:38:43.920 --> 00:38:47.800]   to go anywhere like maybe AR VR, maybe self driving cars.
[00:38:47.800 --> 00:38:51.400]   So put a pin in that because I want to keep this conversation going.
[00:38:51.400 --> 00:38:52.400]   Great panel here.
[00:38:52.400 --> 00:38:55.520]   Sam will salmon our car guy from wheel bearings.
[00:38:55.520 --> 00:38:59.920]   The podcast also a principal researcher at Guide House insights.
[00:38:59.920 --> 00:39:03.920]   He lives in Ipcelante, fifth folks and drives a Miata.
[00:39:03.920 --> 00:39:06.360]   So you know he's cool, right?
[00:39:06.360 --> 00:39:07.960]   What year, Miata?
[00:39:07.960 --> 00:39:13.240]   1990 the original will to October of 89 built 33 33 years ago this month.
[00:39:13.240 --> 00:39:14.400]   Brianna's jealous.
[00:39:14.400 --> 00:39:16.200]   She's a boxer though.
[00:39:16.200 --> 00:39:17.200]   She likes her porsches.
[00:39:17.200 --> 00:39:20.440]   She's she's she's got a great fleet herself.
[00:39:20.440 --> 00:39:21.440]   Fleet is right.
[00:39:21.440 --> 00:39:24.120]   Brianna Wu is also here rebellion pack.
[00:39:24.120 --> 00:39:27.000]   Of course is her political action committee.
[00:39:27.000 --> 00:39:28.480]   Are you very busy right now?
[00:39:28.480 --> 00:39:32.400]   We've got a big important vital coming up.
[00:39:32.400 --> 00:39:37.600]   We are extremely busy right now, but my work is mostly done at this point.
[00:39:37.600 --> 00:39:39.080]   It's just getting the money in.
[00:39:39.080 --> 00:39:42.040]   So you got the checks and TDA ads, right?
[00:39:42.040 --> 00:39:43.520]   That's the focus.
[00:39:43.520 --> 00:39:44.520]   We've done a lot of that.
[00:39:44.520 --> 00:39:45.520]   Yeah.
[00:39:45.520 --> 00:39:46.520]   Yeah.
[00:39:46.520 --> 00:39:49.560]   Oh man, I'm crossing my fingers, Brianna, as I'm sure you see how it shakes out.
[00:39:49.560 --> 00:39:50.760]   Very important stuff.
[00:39:50.760 --> 00:39:53.280]   And from Windows Central, the great Daniel Rabino.
[00:39:53.280 --> 00:39:55.560]   So good panel today.
[00:39:55.560 --> 00:39:57.120]   Lots more to talk about.
[00:39:57.120 --> 00:39:59.200]   But first a word from our sponsor.
[00:39:59.200 --> 00:40:04.200]   I'll tell you one thing that when I first encountered it more than 10 years ago, I went
[00:40:04.200 --> 00:40:06.480]   oh brilliant.
[00:40:06.480 --> 00:40:12.720]   This is, this is, this is going to go somewhere stamps.com because you don't have to go to
[00:40:12.720 --> 00:40:14.280]   the post office to get stamps.
[00:40:14.280 --> 00:40:15.280]   Okay.
[00:40:15.280 --> 00:40:16.280]   That's obvious.
[00:40:16.280 --> 00:40:17.280]   That's great.
[00:40:17.280 --> 00:40:18.280]   You don't have to have a postage meter.
[00:40:18.280 --> 00:40:20.760]   Either you print them out with your computer and your printer.
[00:40:20.760 --> 00:40:22.600]   In fact, it gets better.
[00:40:22.600 --> 00:40:24.720]   You can do anything you can do at the post office.
[00:40:24.720 --> 00:40:26.720]   You could do it stamps.com.
[00:40:26.720 --> 00:40:27.720]   Prepare it all.
[00:40:27.720 --> 00:40:28.720]   Get it ready.
[00:40:28.720 --> 00:40:32.320]   And then a uniformed employee of the federal government will come and pick it up.
[00:40:32.320 --> 00:40:34.560]   You don't even have to get out of your seat.
[00:40:34.560 --> 00:40:35.960]   Now that's awesome.
[00:40:35.960 --> 00:40:41.800]   And stamps.com keeps getting better and better because now stamps.com has all the services
[00:40:41.800 --> 00:40:43.360]   of UPS.
[00:40:43.360 --> 00:40:46.800]   So now you sit down and stamps.com.
[00:40:46.800 --> 00:40:48.320]   You say this is what I need to mail.
[00:40:48.320 --> 00:40:51.520]   It will tell you it has a switch and save feature.
[00:40:51.520 --> 00:40:54.320]   It'll tell you what the rates are with both carriers.
[00:40:54.320 --> 00:40:58.600]   You know that you're getting the best deal you can choose.
[00:40:58.600 --> 00:41:03.880]   It's a amazing tool for anybody who does mailing, not just shipping, but mailing.
[00:41:03.880 --> 00:41:07.800]   So even if you're just sending out bills or brochures, need I remind you the holidays
[00:41:07.800 --> 00:41:09.000]   are coming.
[00:41:09.000 --> 00:41:11.880]   And that is, it's amateur hour at the post office.
[00:41:11.880 --> 00:41:14.200]   That's why everybody's in the post office.
[00:41:14.200 --> 00:41:15.600]   Getting their Christmas stuff mailed.
[00:41:15.600 --> 00:41:17.160]   You don't need to be there.
[00:41:17.160 --> 00:41:18.720]   Stamps.com can do it all.
[00:41:18.720 --> 00:41:25.040]   A 24/7 post office with no lines, no traffic, no hassle right in your office.
[00:41:25.040 --> 00:41:30.480]   Stamps.com has been a partner of our shows and we've been happy customers since 2012.
[00:41:30.480 --> 00:41:32.600]   So my question is you've heard me talking about them.
[00:41:32.600 --> 00:41:33.600]   Why haven't you?
[00:41:33.600 --> 00:41:34.600]   What are you waiting for?
[00:41:34.600 --> 00:41:35.600]   Why haven't you tried them?
[00:41:35.600 --> 00:41:42.280]   Now with UPS services, every dollar counts and you can save on USPS and UPS rates up
[00:41:42.280 --> 00:41:48.480]   to 86% off discounts you cannot get at the post office or the UPS store.
[00:41:48.480 --> 00:41:51.820]   You can use Stamps.com to print postage wherever you do business.
[00:41:51.820 --> 00:41:54.080]   Just a computer and a printer is all you need.
[00:41:54.080 --> 00:41:58.680]   If you need a package pick up, you schedule it through the Stamps.com dashboard.
[00:41:58.680 --> 00:42:02.440]   You'll always have the latest rates and the latest Stamps.
[00:42:02.440 --> 00:42:04.120]   Prices change.
[00:42:04.120 --> 00:42:09.560]   So you can always have the new Stamps always ready any time.
[00:42:09.560 --> 00:42:13.480]   A great way to do an online store because Stamps.com knows about online stores and will
[00:42:13.480 --> 00:42:18.280]   pick up the mailing addresses from your software, no typing at all on your part.
[00:42:18.280 --> 00:42:23.040]   It'll fill out forms for certified mail and express mail, all the different kinds of mail
[00:42:23.040 --> 00:42:26.520]   you need to do even customs forms if you mail internationally.
[00:42:26.520 --> 00:42:29.560]   You can put your return address on there automatically.
[00:42:29.560 --> 00:42:31.120]   Logos from your company.
[00:42:31.120 --> 00:42:32.600]   Write on envelopes.
[00:42:32.600 --> 00:42:33.600]   Write on envelopes even.
[00:42:33.600 --> 00:42:36.760]   Print out a sticker for your packages.
[00:42:36.760 --> 00:42:39.640]   Look, this is the time to get Stamps.com.
[00:42:39.640 --> 00:42:40.880]   Get ahead of the holiday chaos.
[00:42:40.880 --> 00:42:45.160]   It's just around the corner and you will be using it all year round.
[00:42:45.160 --> 00:42:46.160]   Stamps.com.
[00:42:46.160 --> 00:42:47.160]   Here's my deal.
[00:42:47.160 --> 00:42:51.680]   I want you to go to Stamps.com and click the microphone in the upper right hand corner.
[00:42:51.680 --> 00:42:55.040]   Use the offer code TWIT.
[00:42:55.040 --> 00:42:56.240]   This is the best deal they offer.
[00:42:56.240 --> 00:42:58.160]   A four week trial, of course.
[00:42:58.160 --> 00:43:02.920]   You get a free digital scale so you always have exactly the right amount of postage.
[00:43:02.920 --> 00:43:04.400]   Just makes you look more professional.
[00:43:04.400 --> 00:43:06.240]   You get a huge amount of free postage.
[00:43:06.240 --> 00:43:08.600]   You can use no long term commitments.
[00:43:08.600 --> 00:43:09.880]   There's no contract.
[00:43:09.880 --> 00:43:11.840]   Just months to months, go to Stamps.com.
[00:43:11.840 --> 00:43:14.520]   Click the microphone at the top of the page.
[00:43:14.520 --> 00:43:16.840]   Use the code TWIT though for this offer.
[00:43:16.840 --> 00:43:19.440]   Really good bonus offer.
[00:43:19.440 --> 00:43:20.960]   Stamps.com.
[00:43:20.960 --> 00:43:23.800]   We thank them so much for their support of this weekend.
[00:43:23.800 --> 00:43:29.080]   You support us too, by the way, when you go to Stamps.com and use that offer code TWIT.
[00:43:29.080 --> 00:43:31.400]   Google didn't want to be left out, by the way, of all of this.
[00:43:31.400 --> 00:43:36.840]   They showed the Verge, Jay Peters of the Verge, their project Starline.
[00:43:36.840 --> 00:43:39.040]   We saw this at Google I/O last year.
[00:43:39.040 --> 00:43:41.840]   I mean, talk about something that's going to cost a lot of money.
[00:43:41.840 --> 00:43:46.080]   You get a special booth with all of these cameras and stuff.
[00:43:46.080 --> 00:43:49.880]   However, Jay said it was very realistic.
[00:43:49.880 --> 00:43:55.080]   This is a 3D video chat booth.
[00:43:55.080 --> 00:43:59.640]   He said it was just like I was sitting across from the person.
[00:43:59.640 --> 00:44:05.120]   When they showed me an apple, I felt like I could reach out and touch it.
[00:44:05.120 --> 00:44:10.400]   Obviously, this is not something you're going to have in your house anytime soon.
[00:44:10.400 --> 00:44:17.920]   It is a very complicated, with array microphones and stereo cameras and infrared projectors.
[00:44:17.920 --> 00:44:21.520]   It works.
[00:44:21.520 --> 00:44:27.920]   In fact, maybe it's more natural than putting on a visor and going to a team's meeting.
[00:44:27.920 --> 00:44:31.080]   I don't know.
[00:44:31.080 --> 00:44:32.080]   I don't know.
[00:44:32.080 --> 00:44:37.760]   Anyway, Google says, "Well, we think there's another way to go."
[00:44:37.760 --> 00:44:43.920]   This is Silicon Valley Group Think, or is this really some insight into the future of business?
[00:44:43.920 --> 00:44:48.160]   I could see this working.
[00:44:48.160 --> 00:44:49.480]   This is interesting to me.
[00:44:49.480 --> 00:44:52.760]   It's kind of like they cribbed from the last Mission Impossible movie.
[00:44:52.760 --> 00:44:58.320]   It goes protocol, if you remember that scene at the Kremlin, where they're faking the perspective.
[00:44:58.320 --> 00:45:04.120]   You would definitely see this White House in Kremlin hotline working like this.
[00:45:04.120 --> 00:45:05.640]   It would work much better.
[00:45:05.640 --> 00:45:07.320]   Much, much better.
[00:45:07.320 --> 00:45:08.800]   I could see this working.
[00:45:08.800 --> 00:45:10.560]   I mean, it's feasible technology.
[00:45:10.560 --> 00:45:11.560]   It's existed for a while.
[00:45:11.560 --> 00:45:14.960]   It's a very expensive implementation of it.
[00:45:14.960 --> 00:45:17.680]   This is like Zoom meeting times a million.
[00:45:17.680 --> 00:45:22.060]   Maybe this is a better direction to go in than getting everybody sitting around in a
[00:45:22.060 --> 00:45:23.060]   visor.
[00:45:23.060 --> 00:45:25.680]   By the way, always one of my complaints.
[00:45:25.680 --> 00:45:32.840]   Apparently, I'm not alone, is that Project Horizon or Horizon World, which is Metas meeting
[00:45:32.840 --> 00:45:34.120]   place.
[00:45:34.120 --> 00:45:36.040]   You saw this in the HoloLens demo.
[00:45:36.040 --> 00:45:38.280]   Alex Kippman had no legs.
[00:45:38.280 --> 00:45:42.080]   These are hard, apparently.
[00:45:42.080 --> 00:45:46.320]   Meta announced Zuckerberg said, "Oh, no, we're going to have legs," except we now learned
[00:45:46.320 --> 00:45:50.680]   that that whole thing was motion captured and fake.
[00:45:50.680 --> 00:45:54.280]   Without sensors on your legs, they'd be flopping around.
[00:45:54.280 --> 00:45:56.000]   You don't know how to move them.
[00:45:56.000 --> 00:45:57.000]   Yeah, where is it?
[00:45:57.000 --> 00:46:00.320]   You've got controllers in your hands.
[00:46:00.320 --> 00:46:03.880]   You can figure out what the arms should be doing.
[00:46:03.880 --> 00:46:07.920]   Unless you put something on your legs, it's going to be hard to do that realistically.
[00:46:07.920 --> 00:46:12.000]   It was interesting that the Microsoft-- I'm sorry, Meta actually said this was the most
[00:46:12.000 --> 00:46:17.840]   demanded feature in Horizon World's legs.
[00:46:17.840 --> 00:46:23.480]   Interesting rumor that Apple, which I think the Apple VRs rumored to have 14 cameras,
[00:46:23.480 --> 00:46:26.120]   two of them are pointed at your legs.
[00:46:26.120 --> 00:46:27.120]   Hmm.
[00:46:27.120 --> 00:46:31.080]   So, I have a little bit of technical insight on this.
[00:46:31.080 --> 00:46:33.000]   So think about video game.
[00:46:33.000 --> 00:46:37.240]   Like, so like Resident Evil 3, where you're moving Jill around.
[00:46:37.240 --> 00:46:39.400]   You're using a thumbstick, right?
[00:46:39.400 --> 00:46:47.680]   So where Jill's feet go or where any 3D character, their feet go as your walk is actually a really
[00:46:47.680 --> 00:46:49.240]   complicated problem.
[00:46:49.240 --> 00:46:54.520]   Like you can cheat it with IK joints, inverse kinematic joints in the legs.
[00:46:54.520 --> 00:47:01.120]   But when it comes to like things like walking upstairs, we have all these like animation
[00:47:01.120 --> 00:47:07.120]   tree cheats that we use where your foot will magnetically snap to every single step as
[00:47:07.120 --> 00:47:08.320]   you go up it.
[00:47:08.320 --> 00:47:11.080]   It's actually a really hard problem.
[00:47:11.080 --> 00:47:17.720]   But one that we've been doing in video games for really since the PS2 era and people just
[00:47:17.720 --> 00:47:19.440]   generally don't notice it.
[00:47:19.440 --> 00:47:24.480]   So I saw this and thought it was honestly a really good implementation of something we
[00:47:24.480 --> 00:47:25.480]   don't-- Yeah.
[00:47:25.480 --> 00:47:27.600]   This is from the Meta video.
[00:47:27.600 --> 00:47:32.960]   These people, they even have stools, but there's nothing below the waist for them to--
[00:47:32.960 --> 00:47:34.880]   I can see how it's hard to do.
[00:47:34.880 --> 00:47:38.040]   Even if you have cameras, I can see how it'd be very hard to do.
[00:47:38.040 --> 00:47:39.560]   But that breaks the immersion.
[00:47:39.560 --> 00:47:40.800]   It totally does.
[00:47:40.800 --> 00:47:44.840]   It's creepy and weird.
[00:47:44.840 --> 00:47:48.080]   Okay.
[00:47:48.080 --> 00:47:55.800]   And apparently Meta hasn't solved it because the whole video that they showed of Mark and
[00:47:55.800 --> 00:48:00.200]   his co-host dancing around with their legs was faked.
[00:48:00.200 --> 00:48:02.080]   Oh my gosh.
[00:48:02.080 --> 00:48:03.080]   So we're not--
[00:48:03.080 --> 00:48:04.080]   Oh my gosh.
[00:48:04.080 --> 00:48:06.080]   You know, they know it's important.
[00:48:06.080 --> 00:48:09.440]   All they're doing is corporatizing second life that game.
[00:48:09.440 --> 00:48:11.440]   It does look like second life.
[00:48:11.440 --> 00:48:12.440]   Yeah.
[00:48:12.440 --> 00:48:13.440]   That's all this is.
[00:48:13.440 --> 00:48:14.440]   But then you-- Wait a minute.
[00:48:14.440 --> 00:48:15.440]   You got legs in second life.
[00:48:15.440 --> 00:48:16.440]   Right.
[00:48:16.440 --> 00:48:17.440]   Yeah.
[00:48:17.440 --> 00:48:18.440]   So there is that.
[00:48:18.440 --> 00:48:20.680]   How even as good a second life was 20 years ago?
[00:48:20.680 --> 00:48:21.680]   Right.
[00:48:21.680 --> 00:48:31.280]   I feel like there's clearly a disconnect here that these guys have read a lot of science
[00:48:31.280 --> 00:48:32.280]   fiction.
[00:48:32.280 --> 00:48:33.280]   So have we.
[00:48:33.280 --> 00:48:36.280]   We've read the Neil Stevenson books.
[00:48:36.280 --> 00:48:38.400]   We know Snow Crash.
[00:48:38.400 --> 00:48:39.640]   We're a long way off.
[00:48:39.640 --> 00:48:41.960]   In those books, they're jacking in.
[00:48:41.960 --> 00:48:44.200]   They're connecting something to the brain.
[00:48:44.200 --> 00:48:49.040]   This is not-- and one of the hardest things that is absolutely vital to reality is this
[00:48:49.040 --> 00:48:51.360]   thing about moving.
[00:48:51.360 --> 00:48:53.680]   Not just showing your legs just moving.
[00:48:53.680 --> 00:48:58.240]   Like, correct me if I'm wrong, Brianna, but in all the VR I've done, you have to have
[00:48:58.240 --> 00:49:01.840]   some work around for moving like a rubber band that you send with a controller and
[00:49:01.840 --> 00:49:07.480]   then it goes, sucks you over there because you can't really move because you'll walk into
[00:49:07.480 --> 00:49:09.160]   your real wall.
[00:49:09.160 --> 00:49:10.160]   Yeah.
[00:49:10.160 --> 00:49:11.160]   Your coffee table.
[00:49:11.160 --> 00:49:12.160]   This is a big--
[00:49:12.160 --> 00:49:13.160]   It's exactly right.
[00:49:13.160 --> 00:49:15.280]   It was the stop you from throwing up to you.
[00:49:15.280 --> 00:49:16.280]   And we don't have--
[00:49:16.280 --> 00:49:20.440]   I mean, we do have, but nobody really wants to use the Ready Player One omni.
[00:49:20.440 --> 00:49:21.440]   [LAUGHTER]
[00:49:21.440 --> 00:49:22.440]   To treadmill.
[00:49:22.440 --> 00:49:24.600]   To treadmill thing.
[00:49:24.600 --> 00:49:25.600]   That's weird.
[00:49:25.600 --> 00:49:29.480]   I mean, somebody doesn't make it, but you have to be suspended by ropes and it's not
[00:49:29.480 --> 00:49:31.440]   a good experience.
[00:49:31.440 --> 00:49:38.320]   I mean, why does anybody think this is even close to happening?
[00:49:38.320 --> 00:49:39.320]   I don't know.
[00:49:39.320 --> 00:49:40.760]   I see the leg thing.
[00:49:40.760 --> 00:49:43.160]   I see a technically good cheat.
[00:49:43.160 --> 00:49:46.520]   And I think at some point we're going to have to think about the computational power
[00:49:46.520 --> 00:49:47.520]   that you're losing on this stuff.
[00:49:47.520 --> 00:49:50.120]   How would you move without walking into the--
[00:49:50.120 --> 00:49:51.120]   Into the coffee table?
[00:49:51.120 --> 00:49:52.120]   You can't.
[00:49:52.120 --> 00:49:53.120]   You can't move.
[00:49:53.120 --> 00:49:54.120]   It's the bottom one.
[00:49:54.120 --> 00:49:55.120]   You need a big empty room.
[00:49:55.120 --> 00:49:56.120]   This is studies.
[00:49:56.120 --> 00:49:58.120]   I mean, a really big empty room.
[00:49:58.120 --> 00:49:59.120]   Yeah.
[00:49:59.120 --> 00:50:00.120]   Yeah.
[00:50:00.120 --> 00:50:04.360]   Studies have also shown that women are much more susceptible to VR sickness as well.
[00:50:04.360 --> 00:50:09.040]   So if you've played these early VR games where you just hold forward and you just walk
[00:50:09.040 --> 00:50:14.120]   through a level by pushing on a control stick, that is like a formula for making women throw
[00:50:14.120 --> 00:50:15.120]   up.
[00:50:15.120 --> 00:50:16.120]   It just is.
[00:50:16.120 --> 00:50:17.120]   And a lot of dudes too.
[00:50:17.120 --> 00:50:18.120]   I throw up too.
[00:50:18.120 --> 00:50:19.120]   Yeah.
[00:50:19.120 --> 00:50:20.120]   I get nauseated.
[00:50:20.120 --> 00:50:25.360]   Although, to be fair, the most nauseated I've ever gotten was playing Quake on a commuter
[00:50:25.360 --> 00:50:26.360]   bus.
[00:50:26.360 --> 00:50:27.360]   And that wasn't in VR.
[00:50:27.360 --> 00:50:31.200]   That was just because the bus was going this way and Quake was going that way.
[00:50:31.200 --> 00:50:34.440]   And it was not a pretty picture.
[00:50:34.440 --> 00:50:38.840]   I still get sick sometimes if I have a big enough screen on just a regular 2D game.
[00:50:38.840 --> 00:50:42.040]   So maybe I'm the bad example.
[00:50:42.040 --> 00:50:48.560]   Well, I mean, this past week I was moderating a conference here in Detroit on simulation
[00:50:48.560 --> 00:50:49.880]   put on by a company called V.I.
[00:50:49.880 --> 00:50:50.880]   Grade.
[00:50:50.880 --> 00:50:54.960]   And one of the things we talked about was one of the things that this company makes is
[00:50:54.960 --> 00:51:00.040]   these big motion simulators for driving dynamics development.
[00:51:00.040 --> 00:51:05.860]   So you basically put a vehicle, almost a full vehicle on there and it moves around and
[00:51:05.860 --> 00:51:07.640]   simulates all the motions.
[00:51:07.640 --> 00:51:12.640]   And we were talking about an example back in the late 90s when I was still working in
[00:51:12.640 --> 00:51:14.000]   engineering.
[00:51:14.000 --> 00:51:21.960]   We built a simulation system using it was powered by a Silicon Graphics Iris workstation.
[00:51:21.960 --> 00:51:25.760]   Big giant screen built it, you know, had a driving buck, but the driving buck had no
[00:51:25.760 --> 00:51:26.920]   motion.
[00:51:26.920 --> 00:51:32.080]   And we were using this for ABS and traction control and stability control development.
[00:51:32.080 --> 00:51:34.680]   And I always found it really hard.
[00:51:34.680 --> 00:51:37.960]   I could not drive this thing for more than a few minutes.
[00:51:37.960 --> 00:51:43.200]   And I do test driving all the time and even more so in those days.
[00:51:43.200 --> 00:51:45.160]   And doing all kinds of maneuvers.
[00:51:45.160 --> 00:51:50.200]   And I could not sit in this thing driving it for more than a few minutes because you've
[00:51:50.200 --> 00:51:57.520]   got this big screen that was quite immersive, but you had no physical feedback of the things
[00:51:57.520 --> 00:51:59.840]   that your eyes were seeing.
[00:51:59.840 --> 00:52:02.000]   And it was really hard.
[00:52:02.000 --> 00:52:06.520]   And you know, so this is a real issue.
[00:52:06.520 --> 00:52:12.120]   When you have that disconnect between your visual inputs and all of your other senses.
[00:52:12.120 --> 00:52:22.400]   Here we have, by the way, thanks to the Discord chat Brianna, the stair animation.
[00:52:22.400 --> 00:52:23.400]   It works perfectly.
[00:52:23.400 --> 00:52:24.400]   It's completely convincing.
[00:52:24.400 --> 00:52:29.720]   Yeah, it's the disconnect between what your eyes are telling you and what your body is
[00:52:29.720 --> 00:52:33.760]   telling you, your inner ear is telling you and your eyes are telling you.
[00:52:33.760 --> 00:52:35.240]   And it is the FUD.
[00:52:35.240 --> 00:52:40.400]   I think the FUD that's spread by the VR industry that, oh, all we have to do is get latency
[00:52:40.400 --> 00:52:44.680]   down and resolution up and you'll be fine.
[00:52:44.680 --> 00:52:46.000]   And I don't think that's it.
[00:52:46.000 --> 00:52:47.000]   I really don't.
[00:52:47.000 --> 00:52:54.000]   I think it's also the disconnect between your focal length that's being telegraphed by your
[00:52:54.000 --> 00:52:57.280]   convergence point because your eyes are looking at the screen that's right here.
[00:52:57.280 --> 00:53:00.040]   So you're converging on this screen that's inches from you.
[00:53:00.040 --> 00:53:04.720]   And what your brain is telling you, the focal point is, which is 10 feet out, if those
[00:53:04.720 --> 00:53:10.200]   don't match, as you know, your body says, you ate something bad, throw it up now.
[00:53:10.200 --> 00:53:11.200]   That is bad.
[00:53:11.200 --> 00:53:12.200]   Yeah.
[00:53:12.200 --> 00:53:15.520]   Plus, plus, I don't think we also know the long term effects of looking at a screen
[00:53:15.520 --> 00:53:17.320]   inches from your eye all day.
[00:53:17.320 --> 00:53:18.760]   Well, that's a good point.
[00:53:18.760 --> 00:53:19.760]   I know.
[00:53:19.760 --> 00:53:24.440]   I mean, I know with the pandemic, because I spent more time indoors and usual, my eyes
[00:53:24.440 --> 00:53:27.640]   I actually got worse because you don't have the distance focus, right?
[00:53:27.640 --> 00:53:28.640]   You're always right.
[00:53:28.640 --> 00:53:29.640]   Yeah.
[00:53:29.640 --> 00:53:32.080]   Yeah, you're supposed to like every was a 10 man or something like that.
[00:53:32.080 --> 00:53:34.080]   Look out a window and refocus your eyes.
[00:53:34.080 --> 00:53:38.880]   And if I don't do that, yeah, my eye and it's thanks if you go to the eye doctor and you
[00:53:38.880 --> 00:53:42.040]   didn't train them, you'll get a worse prescription, right?
[00:53:42.040 --> 00:53:44.800]   So like, I don't know how this is going to affect our eyes.
[00:53:44.800 --> 00:53:48.680]   It's going to be like the jerk with Steve Martin invented those glasses things.
[00:53:48.680 --> 00:53:50.680]   Everybody ends up cross side.
[00:53:50.680 --> 00:53:51.680]   Yeah.
[00:53:51.680 --> 00:53:57.360]   We've invented something that'll make everybody very, very nearsighted.
[00:53:57.360 --> 00:54:01.800]   Can we, can we come back to the Oculus Pro for just a second here because this ties into
[00:54:01.800 --> 00:54:03.520]   something we're talking about?
[00:54:03.520 --> 00:54:07.560]   You know, one of the things they're really promoting here versus the, the first version
[00:54:07.560 --> 00:54:09.640]   of the quest is the pass through on it.
[00:54:09.640 --> 00:54:15.440]   So it has cameras on it and you can push a button and it will show you the world around
[00:54:15.440 --> 00:54:16.440]   you in color.
[00:54:16.440 --> 00:54:20.200]   And they're trying to promote that as like, you know, AR, right?
[00:54:20.200 --> 00:54:22.440]   But it's, it's not augmented.
[00:54:22.440 --> 00:54:25.560]   It's a camera that's not where your eyesight is.
[00:54:25.560 --> 00:54:27.000]   Oh, that's really bad.
[00:54:27.000 --> 00:54:30.520]   Most certainly going to have a certain of latency.
[00:54:30.520 --> 00:54:37.000]   Every time I've used this feature on a quest or any VR system before, it makes me really,
[00:54:37.000 --> 00:54:38.000]   really nauseous.
[00:54:38.000 --> 00:54:43.080]   And I feel like they're just papering right over that problem when we're going to experience
[00:54:43.080 --> 00:54:44.080]   this.
[00:54:44.080 --> 00:54:48.560]   Like if you're in the supposed quest pro meeting and you're reaching down at your desk to take
[00:54:48.560 --> 00:54:51.360]   notes, you know, this camera is not going to solve it.
[00:54:51.360 --> 00:54:54.960]   You're still going to feel sick using that.
[00:54:54.960 --> 00:55:00.720]   So let me take this over to self driving vehicles because the same, this is that thing I posited
[00:55:00.720 --> 00:55:02.080]   before the last break.
[00:55:02.080 --> 00:55:08.720]   I saw an article that says we've spent hundreds of billions of dollars on self driving vehicles
[00:55:08.720 --> 00:55:10.200]   and they still aren't self driving.
[00:55:10.200 --> 00:55:14.520]   Is that a fair categorization, Sam?
[00:55:14.520 --> 00:55:19.960]   So you know, the industry as a whole has spent somewhere in the order of about $100 billion
[00:55:19.960 --> 00:55:25.240]   over the last 12, 15 years on automated driving.
[00:55:25.240 --> 00:55:28.200]   But there is a, there is a very big difference here.
[00:55:28.200 --> 00:55:35.320]   And, you know, if you take a Tesla and they're fake, full self driving, you know, I think
[00:55:35.320 --> 00:55:39.160]   the guy that wrote this got it got a lot wrong.
[00:55:39.160 --> 00:55:41.360]   This is Max Chefkin writing for business.
[00:55:41.360 --> 00:55:42.360]   Right.
[00:55:42.360 --> 00:55:43.360]   We should say.
[00:55:43.360 --> 00:55:48.160]   So, you know, this, this started from, you know, actually trying to solve some very specific
[00:55:48.160 --> 00:55:49.160]   problems.
[00:55:49.160 --> 00:55:53.440]   I mean, with the DARPA challenge, it started with, you know, trying to get vehicles that
[00:55:53.440 --> 00:56:00.320]   could go into combat zones, you know, and not have to take people in there.
[00:56:00.320 --> 00:56:05.480]   But you know, once it got into trying to get it, trying to commercialize the technology,
[00:56:05.480 --> 00:56:11.040]   you know, it was, it was trying to solve some real problems around safety, traffic safety,
[00:56:11.040 --> 00:56:16.560]   a mobility for people who can't drive, you know, to provide the mobility.
[00:56:16.560 --> 00:56:22.080]   And going back to what, you know, the example of these Lenovo glasses that Daniel brought
[00:56:22.080 --> 00:56:28.320]   up, you know, the rest of the industry, apart from Tesla, you know, has actually recognized
[00:56:28.320 --> 00:56:33.880]   that doing a more focused approach like what Lenovo is doing, you know, having a very specific
[00:56:33.880 --> 00:56:38.600]   task that you're doing with it, not trying to, you know, recognizing that, okay, this
[00:56:38.600 --> 00:56:41.640]   is a really hard problem to solve.
[00:56:41.640 --> 00:56:49.000]   You know, they have actually made tremendous progress over the last 15 years, but not trying
[00:56:49.000 --> 00:56:56.680]   to do everything, but rather, you know, focus it on specific tasks like robo taxis in urban
[00:56:56.680 --> 00:57:03.240]   environments, like last mile deliveries, automated trucking, where you're not trying
[00:57:03.240 --> 00:57:08.000]   to do, you're not trying to solve everything, but you're trying to do specific things.
[00:57:08.000 --> 00:57:10.960]   It can actually work quite well.
[00:57:10.960 --> 00:57:17.880]   I was just in a, in a couple of vehicles earlier this week with a company driving around
[00:57:17.880 --> 00:57:24.000]   Dearborn and it was not Ford, but, you know, driving around, actually riding around Dearborn,
[00:57:24.000 --> 00:57:27.400]   you know, and the system was working really, really well.
[00:57:27.400 --> 00:57:32.720]   I was in San Francisco last month with crews, you know, and the system worked very, very
[00:57:32.720 --> 00:57:33.720]   well.
[00:57:33.720 --> 00:57:37.480]   I've seen a tremendous amount of progress, you know, early on, you know, these systems
[00:57:37.480 --> 00:57:43.480]   were very crude, but they, you know, we are getting to the point, we've got some real
[00:57:43.480 --> 00:57:48.880]   world driverless deployments going on now in San Francisco and Arizona.
[00:57:48.880 --> 00:57:53.200]   We're going to have quite a few more coming in 2023 from a number of different companies
[00:57:53.200 --> 00:57:58.360]   in places like Austin, Miami, San Diego, Las Vegas.
[00:57:58.360 --> 00:58:04.760]   And it's slowly getting there, but the kind, you know, being more focused rather than trying
[00:58:04.760 --> 00:58:11.520]   to solve, rather than trying to boil the ocean as Tesla want, seems to want to do, you know,
[00:58:11.520 --> 00:58:14.280]   they're trying to boil a pot of water first.
[00:58:14.280 --> 00:58:19.800]   And then once they get that going, then go to move to a bigger pot and so on.
[00:58:19.800 --> 00:58:26.920]   The article quotes one of the early and best known pioneers of self driving Anthony Lewandowski,
[00:58:26.920 --> 00:58:30.520]   who of course, well, I wouldn't, I wouldn't trust anything that will happen to us.
[00:58:30.520 --> 00:58:36.880]   He left Google under a cloud taking a bunch of documents with him and Google students
[00:58:36.880 --> 00:58:42.760]   and so forth. He has a new startup that does dump trucks, basically.
[00:58:42.760 --> 00:58:45.600]   They're not even driving the roads. They're on industrial sites.
[00:58:45.600 --> 00:58:49.240]   He said, you'd be hard pressed to find another industry that's invested so many dollars
[00:58:49.240 --> 00:58:53.360]   in R and D that's delivered so little.
[00:58:53.360 --> 00:58:57.440]   Forget about profits. What's the combined revenue of all the robo taxi, robo truck,
[00:58:57.440 --> 00:59:02.160]   robo, whatever companies, it's like a million dollars or maybe not even that much, maybe
[00:59:02.160 --> 00:59:07.440]   zero. He also quotes George Hott's, who is, you know, pretty, I think,
[00:59:07.440 --> 00:59:09.720]   another person with zero credibility.
[00:59:09.720 --> 00:59:10.720]   Okay. All right.
[00:59:10.720 --> 00:59:16.160]   He's got a credit comma AI and has a kind of an add on that you can put in your car
[00:59:16.160 --> 00:59:19.560]   and turn itself driving. He says it's a scam.
[00:59:19.560 --> 00:59:22.320]   He's not his company, but well, self driving.
[00:59:22.320 --> 00:59:30.600]   You know, George Hott's, you know, back in 2016, I was chairing a conference in San Francisco.
[00:59:30.600 --> 00:59:33.520]   He was supposed to speak at that conference.
[00:59:33.520 --> 00:59:40.120]   And that morning I was walking into the event space for it, checked my messages and I saw
[00:59:40.120 --> 00:59:45.560]   a notification on their tech crunch story that the day before or a couple of days before,
[00:59:45.560 --> 00:59:49.960]   NHTSA had sent a letter to comma AI saying, hey, we would like some more information about
[00:59:49.960 --> 00:59:53.680]   what we were doing. It wasn't threatening. They just, they just was just asking for information
[00:59:53.680 --> 00:59:55.920]   about what they were doing.
[00:59:55.920 --> 01:00:01.120]   Hott's immediately pulled the plug on the whole project and said, nope, okay, we're not going
[01:00:01.120 --> 01:00:05.000]   to do this because, you know, he was the, he was the scammer.
[01:00:05.000 --> 01:00:08.440]   Yeah. I mean, if anybody knows what it's a scam is, it's him.
[01:00:08.440 --> 01:00:12.520]   All right. You know, what he was doing was never going to work.
[01:00:12.520 --> 01:00:16.960]   So these are two people who you would expect to actually be pretty dismissive of any attempt
[01:00:16.960 --> 01:00:21.160]   by Wayne Moore Cruz to do self driving.
[01:00:21.160 --> 01:00:25.880]   Yeah. What's the timeframe, Sam, for a level five?
[01:00:25.880 --> 01:00:29.600]   Level five probably never, never, or at least a very long time.
[01:00:29.600 --> 01:00:31.560]   Level five is true self driving, right?
[01:00:31.560 --> 01:00:36.880]   Well, no, so level four and level five are both true self driving. The distinction is
[01:00:36.880 --> 01:00:44.520]   level five can do it anywhere, anytime. Level four means you can do full self driving within
[01:00:44.520 --> 01:00:49.200]   some limited parameters. It might be limited to a geographic area. It might be limited
[01:00:49.200 --> 01:00:55.520]   based on weather conditions or specific tasks. It's just, it's just has some kind of limited
[01:00:55.520 --> 01:01:01.920]   operating domain. So, you know, it's still self driving. It's still fully automated.
[01:01:01.920 --> 01:01:06.760]   It's just, it can't necessarily do it everywhere. And you can still get tremendous value out
[01:01:06.760 --> 01:01:10.440]   of doing it even in a limited environment.
[01:01:10.440 --> 01:01:14.440]   I do. I'm like you. I remember the early grand darpa challenges. We used to make fun
[01:01:14.440 --> 01:01:18.360]   of them on the screen savers 20 years ago. These cars would go three feet and go off
[01:01:18.360 --> 01:01:23.680]   the road. I mean, it was, they were really terrible and very made a lot of progress really,
[01:01:23.680 --> 01:01:29.040]   really quickly. A few years later, they were, they were doing the whole challenge. They
[01:01:29.040 --> 01:01:32.720]   had to make it longer and more difficult because the cars got better. But isn't this always
[01:01:32.720 --> 01:01:39.000]   the case with AI that the early stuff, the first 80% is relatively easy. It's that last
[01:01:39.000 --> 01:01:40.640]   10% that kills you.
[01:01:40.640 --> 01:01:45.160]   Yeah. I mean, I was a rule of thumb. I learned very early on in my engineering career is
[01:01:45.160 --> 01:01:52.120]   the first 90% of any project takes 10% of the effort. And then the last 10% requires 90%
[01:01:52.120 --> 01:01:56.520]   of the effort. And, you know, we're, we're still, you know, very early on in that last
[01:01:56.520 --> 01:02:01.640]   10%. There's still a long way to go. But there are, there are real world applications
[01:02:01.640 --> 01:02:08.520]   where this is being used today and that will continue to grow over the next several years.
[01:02:08.520 --> 01:02:13.000]   I just, I want to back up what you're saying, Sam. I mean, I personally, like you can go
[01:02:13.000 --> 01:02:17.720]   to my Twitter, I'm very, very skeptical of Elon and full self-driving. And I really,
[01:02:17.720 --> 01:02:23.560]   I support the efforts of the National Highway and Traffic Safety Institute to look at what
[01:02:23.560 --> 01:02:29.200]   is happening there. That said, I would really encourage any of your listeners, viewers that
[01:02:29.200 --> 01:02:35.440]   are skeptical about this, go out and try GM supercruise. I am not a GM fan. I would not
[01:02:35.440 --> 01:02:41.240]   own one of those cars. But it's a really, really, really impressive technology. If I
[01:02:41.240 --> 01:02:46.520]   still had a job where like I had to drive into downtown Boston every single day, that's going
[01:02:46.520 --> 01:02:52.280]   to take care of 90% of it for you. And the reason is exactly what you're saying, Sam,
[01:02:52.280 --> 01:02:58.520]   it's a very limited use case. So I'm trying to drive down 95 and deal with the traffic there.
[01:02:58.520 --> 01:03:03.240]   And yes, I've got to keep my eyes on the road. I've got to be aware and ready to take over at
[01:03:03.240 --> 01:03:10.200]   every single minute. But it's going to do 90% of the work for me. That work is like that feature is
[01:03:10.200 --> 01:03:15.720]   something our industry has been able to deliver at this point. And it's good. Portia has a
[01:03:15.720 --> 01:03:23.080]   variation of this. I almost think like it's like we set our sights too high. It's not helped by
[01:03:23.080 --> 01:03:28.040]   Elon, like hyping something that I just, I frankly don't think is ever going to happen.
[01:03:28.040 --> 01:03:33.800]   From my point of view, I think if we had set more attainable, smaller goals and delivered that
[01:03:33.800 --> 01:03:38.760]   to people while working within this regulatory framework to keep the public safe, I think it
[01:03:38.760 --> 01:03:42.280]   wouldn't have been about our course of action. This is a yeah. And that's what the rest of the
[01:03:42.280 --> 01:03:47.720]   industry is trying to do is they're trying to do it safely, trying to, you know, each thing
[01:03:47.720 --> 01:03:53.240]   before they release it to the public, instead of having members of the public beta testing,
[01:03:53.240 --> 01:03:59.880]   safety critical software, they're doing it internally with professionals. And only when they are
[01:03:59.880 --> 01:04:03.960]   highly confident that it's going to work reliably, then they release it.
[01:04:05.160 --> 01:04:08.760]   I mean, that's definitely true. I'm just going to say it's also because they're doing all that
[01:04:08.760 --> 01:04:13.800]   work only because Tesla is like cowboys in the West, right? They did this. They're putting out
[01:04:13.800 --> 01:04:18.760]   in the streets already as you say beta testing it with just regular people. I mean, it was them
[01:04:18.760 --> 01:04:24.920]   that drove that drove this whole industry and our body. Most of this effort started long before
[01:04:24.920 --> 01:04:32.360]   Tesla got involved in it. Yeah, but I would say Tesla really didn't start at all. Yeah, Tesla
[01:04:32.360 --> 01:04:36.920]   brought it to the public's attention, but the work was happening many years before
[01:04:36.920 --> 01:04:42.040]   before Musk ever went down this path. Yeah. Right.
[01:04:42.040 --> 01:04:46.360]   As I mean, to be with electric cars, you know, he's taking all the sensors out, except the
[01:04:46.360 --> 01:04:49.880]   cameras, right? He's now says, yeah, he needs cameras. You don't need
[01:04:49.880 --> 01:04:57.960]   live or you did. Yeah. He's wrong. So yeah, that seems like a bad idea. So
[01:04:57.960 --> 01:05:09.000]   then why is he doing it? Because he's telling me now, because if he can get somebody to pay
[01:05:09.000 --> 01:05:16.680]   $15,000 for the full self driving option on the vehicles, that is about $14,800 worth of pure
[01:05:16.680 --> 01:05:23.320]   profit. I wasted $5,000 on my Model X for self driving, which I never got in it. And then finally,
[01:05:23.320 --> 01:05:29.480]   the lease ran out. And so I just gave it back. But I would never, never spend money on any
[01:05:29.480 --> 01:05:38.600]   promise of full self driving. Yeah, I mean, you know, on the radio show, you talk all and on the
[01:05:38.600 --> 01:05:44.520]   podcast, you have always talked about, you know, never buy a piece of hardware or product with the
[01:05:44.520 --> 01:05:50.040]   promise of what it might someday do, buy it based on what it does today. If you get,
[01:05:50.040 --> 01:05:57.080]   if you get if it improves over time, great, it's a bonus, but do not buy something expecting
[01:05:57.080 --> 01:06:02.840]   that someday it might do something it doesn't do today. I was kind of a loser for Elon. I also
[01:06:02.840 --> 01:06:10.440]   bought the bio weapon defense mode. I bought the ludicrous acceleration mode. I was a yeah, oh,
[01:06:10.440 --> 01:06:16.200]   boy, in hindsight, I look like an idiot, maybe even in foresight in middle sight, I look like an
[01:06:16.200 --> 01:06:21.720]   idiot. We had some reporting that came out that showed the Elon was trying to pressure all of his
[01:06:21.720 --> 01:06:26.760]   engineers to limit the camera to two cameras. Because he kept telling the engineering team that,
[01:06:26.760 --> 01:06:32.280]   look, humans have two eyes, that should be good. That should do. That should be fine. Well, even
[01:06:32.280 --> 01:06:37.240]   how can I be so stupid? You're not you got a car, you got two eyes, but you don't see everything
[01:06:37.240 --> 01:06:42.440]   that's happening around the car with your two eyes. Well, and cameras are cheap. How many cameras
[01:06:42.440 --> 01:06:49.400]   are going to be on the Quest Pro 11? How many going to be on the Apple reportedly 14? Why would
[01:06:49.400 --> 01:06:56.440]   you reduce it in a $100,000 vehicle to two? Well, and they've got eight cameras on Tesla
[01:06:56.440 --> 01:07:01.320]   vehicles today. And the thing is, they're not even configured the way our human eyes are. Our
[01:07:01.320 --> 01:07:06.280]   human eyes are both looking in the same direction. And you know, you can take advantage of the
[01:07:06.280 --> 01:07:11.800]   parallax of your two eyes, seeing the same object from slightly different points of view to do depth
[01:07:11.800 --> 01:07:16.200]   perception. Tesla doesn't even do that. The cameras are all pointing in different directions.
[01:07:16.200 --> 01:07:20.680]   So you can't even you can't even do accurate distance measurement with the way they have their
[01:07:20.680 --> 01:07:27.240]   cameras configured. It's all their distance measurement is done by inference, which is an
[01:07:27.240 --> 01:07:34.200]   inherently bad way to do it. Yeah. Yeah. Yeah. And I thought they had sensors on the goal wing
[01:07:34.200 --> 01:07:39.400]   or Falcon wing, whatever kind of wing doors they had that it wouldn't hit anything. Right.
[01:07:39.400 --> 01:07:44.280]   I mean, I was certainly given that impression, but it kept hitting Lisa in the head.
[01:07:44.280 --> 01:07:52.200]   She really hated that car. She called it Christine. She did not. She did not like that car. One bit.
[01:07:52.200 --> 01:07:58.280]   Let's take a little break. Lots more to talk about including Elon. We got a couple of Elon
[01:07:58.280 --> 01:08:07.560]   stories. So why not? You know, he's the gift that keeps on giving. But first, a word from our sponsor
[01:08:07.560 --> 01:08:15.320]   or show today brought to you by collide. This is a solution that has every company who uses slack
[01:08:15.320 --> 01:08:22.760]   should should adopt immediately. It's an endpoint security solution that instead of treating your
[01:08:22.760 --> 01:08:28.520]   users as the enemy. And so many MDM solutions do that. Right. Oh my God, you got to defend against
[01:08:28.520 --> 01:08:34.120]   not the bad guys out there, but your users, the other ones that there glue the USB ports shut.
[01:08:34.120 --> 01:08:39.640]   Don't let them don't let them do anything. The problem with that is when you criminalize
[01:08:39.640 --> 01:08:44.600]   your users in a company, your employees in a company, what do they do? They go out and they
[01:08:44.600 --> 01:08:50.760]   start using their phone and they're laptop. And now you got a real problem. When you're when you're
[01:08:50.760 --> 01:08:55.160]   trying to achieve security goals, whether for a third party audit or your own compliance standards,
[01:08:55.160 --> 01:09:00.360]   the conventional wisdom is you treat every device like Fort Knox. Just lock it down.
[01:09:00.360 --> 01:09:06.280]   And that means you start using old school device management tools like MDM's to force
[01:09:06.280 --> 01:09:11.880]   disruptive agents onto employees devices. Problem is employees know this. It slows performance.
[01:09:11.880 --> 01:09:16.040]   It treats privacy as an afterthought and treats them like the bad guys.
[01:09:17.160 --> 01:09:23.240]   That way of doing things turns your IT department into the enemies of the end users. It creates
[01:09:23.240 --> 01:09:27.720]   its own security problems. Users turn to shadow IT just to do their jobs. Collide does it a
[01:09:27.720 --> 01:09:34.040]   completely different way. Collide uses the most powerful untapped resource in IT, your end users.
[01:09:34.040 --> 01:09:39.800]   Instead of forcing changes on users, Collide sends them security recommendations via Slack.
[01:09:39.800 --> 01:09:45.480]   Now I know you're waiting to wait with that, but that all? But yes, because now your users are on
[01:09:45.480 --> 01:09:51.320]   your team. It'll automatically notify them when their devices are insecure. It explains why that's
[01:09:51.320 --> 01:09:56.040]   a problem and gives them step by step instructions on how to solve it. And now they're partners.
[01:09:56.040 --> 01:10:02.600]   They're doing it with you. By reaching out to employees via friendly Slack DM, educating them
[01:10:02.600 --> 01:10:08.680]   about company policies, Collide helps you build a culture, a much nicer, better culture in which
[01:10:08.680 --> 01:10:13.640]   everyone contributes to security because everyone understands how and why to do it. Your end users
[01:10:13.640 --> 01:10:20.760]   want to help. They want to help. You're giving them a chance. And now you're basically enrolling
[01:10:20.760 --> 01:10:25.480]   an entire army to help protect the company. And honestly, by now we all know that's the only way
[01:10:25.480 --> 01:10:29.480]   to do it. That's the only way to do it. For IT admins, you're going to love Collide. It gives
[01:10:29.480 --> 01:10:34.440]   you a single dashboard that lets you monitor the security of your entire fleet. And it's by the
[01:10:34.440 --> 01:10:38.840]   way, completely cross-platform Mac, Windows, and Linux. You'll be able to see at a glance
[01:10:38.840 --> 01:10:44.440]   which employees have their disks encrypted. Their OS is up to date. Which ones are using
[01:10:44.440 --> 01:10:51.880]   password managers? Collide, user-centered, cross-platform endpoint security for teams that slack. That's
[01:10:51.880 --> 01:10:59.080]   the one line. And let me tell you this. I know you might be skeptical. No, it really works. This
[01:10:59.080 --> 01:11:04.680]   is the best way to do it. It really is. You can meet your compliance goals by putting users first.
[01:11:04.680 --> 01:11:14.920]   I promise you, visit collide.com/twit. K-O-L-I-D-E.com/twit. Follow that link. They're going to hook you
[01:11:14.920 --> 01:11:20.280]   up with a goody bag. They've got some nice T-shirts. I've got some stickers for my laptop. A little
[01:11:20.280 --> 01:11:25.800]   coaster for my beer. And that's just for activating a free trial. By the way, the T-shirts are nice.
[01:11:25.800 --> 01:11:34.440]   K-O-L-I-D-E. Collide.com/twit. It's just the right way to do it. Thank you, Collide, for
[01:11:34.440 --> 01:11:39.960]   supporting this week in tech. And you support us. Don't forget to your listeners by using that
[01:11:39.960 --> 01:11:47.640]   address so they know you saw it here. Very important. I thought, okay, a little more on the Microsoft
[01:11:47.640 --> 01:11:52.920]   thing because there was a lot in there. The thing that kind of took my breath away was towards the
[01:11:52.920 --> 01:12:01.000]   end of the Panos Pane video in which they announced that Dolly 2 was going to be part of Microsoft's
[01:12:01.000 --> 01:12:07.560]   new designer product. That's their kind of their Figma or their Canva competitor. And built into
[01:12:07.560 --> 01:12:12.840]   Bing Image Creator. Now, did they explain? First of all, it's coming next year, right, Daniel?
[01:12:12.840 --> 01:12:17.640]   Yeah, I believe so. There's coming like an early access to for some people.
[01:12:17.640 --> 01:12:21.960]   And did they explain? Because with Dolly, you pay for it after a certain number.
[01:12:21.960 --> 01:12:22.360]   Right.
[01:12:22.360 --> 01:12:25.480]   Did they... Is Microsoft going to pay for it? How is that going to work?
[01:12:25.480 --> 01:12:29.240]   Yeah, I'm not sure about that part. I know it's just going to be like in part of Bing's search.
[01:12:29.240 --> 01:12:31.960]   It's just going to make another tab and you can just go right into it.
[01:12:31.960 --> 01:12:32.600]   Yeah.
[01:12:32.600 --> 01:12:38.440]   I mean, there have been kind of... I think they saw this early on as being a big thing. I remember
[01:12:38.440 --> 01:12:43.880]   they partnered with them pretty early. You can even use a Microsoft account to register with Dolly 2
[01:12:43.880 --> 01:12:49.560]   currently. But yeah, I'm not sure. It's after 50, I believe it is, but Dolly 2, you're going to
[01:12:49.560 --> 01:12:54.440]   get free ones. Dolly 2, by the way, is now open to everybody. It's no longer a wait list.
[01:12:54.440 --> 01:12:55.400]   Right.
[01:12:55.400 --> 01:12:55.960]   Get in there.
[01:12:55.960 --> 01:13:00.280]   Yeah. So maybe Microsoft is subsidizing it, which I think would probably make sense.
[01:13:00.280 --> 01:13:06.280]   It said a big investor. They were putting an investment in. So maybe they're giving a chunk
[01:13:06.280 --> 01:13:09.160]   of change and letting you use it, which is great.
[01:13:09.160 --> 01:13:10.600]   Yeah.
[01:13:10.600 --> 01:13:16.280]   That's to me. We're talking about technologies that are slow. They aren't coming along. Maybe
[01:13:16.280 --> 01:13:21.720]   they're never going to come along. Then all of a sudden out of nowhere, AI is interesting,
[01:13:21.720 --> 01:13:27.480]   because you get these weird wins. All of a sudden, AlphaGo can beat everybody at everything.
[01:13:27.480 --> 01:13:32.600]   Give it a game. In four hours, it'll kill you.
[01:13:32.600 --> 01:13:39.400]   Then now all of a sudden, you get Dolly 2 and stable diffusion in mid-journey. I think stable
[01:13:39.400 --> 01:13:42.280]   diffusion really powered it because it was open source and everybody could run it.
[01:13:42.280 --> 01:13:45.880]   All of a sudden, AI art is everywhere.
[01:13:45.880 --> 01:13:48.520]   Kind of amazing.
[01:13:48.520 --> 01:13:54.440]   Yeah. AI is like, there's like, again, bringing it down to just more realistic things. I just
[01:13:54.440 --> 01:13:59.560]   picked up the UFIDoorbell dual. So it's got two cameras on it, when it looks out, and then
[01:13:59.560 --> 01:14:02.360]   when it looks down to see if it's on the package.
[01:14:02.360 --> 01:14:02.840]   Yeah.
[01:14:02.840 --> 01:14:03.160]   Yeah.
[01:14:03.160 --> 01:14:09.080]   And it even has a new beta AI experiment where it'll detect if it's a package and
[01:14:09.080 --> 01:14:13.240]   alert you that a package was given. And then it can give you another reminder if you didn't
[01:14:13.240 --> 01:14:16.920]   pick it up yet. And it's been working. I've only had it for about 48 hours, and I already
[01:14:16.920 --> 01:14:20.600]   had a couple of Amazon packages. As soon as someone puts a package down, I get an alert,
[01:14:20.600 --> 01:14:24.120]   says, "Oh, there's something there for you." And it's been pretty accurate.
[01:14:24.120 --> 01:14:32.600]   I love that these little usages of AI to improve life versus these big ideas of robots
[01:14:32.600 --> 01:14:35.720]   and cyporegs and all this kind of stuff like taking over the world.
[01:14:35.720 --> 01:14:40.520]   But these little examples, including that using art, I think, is really, really intriguing,
[01:14:40.520 --> 01:14:43.080]   because it's just way more pragmatic and practical.
[01:14:43.080 --> 01:14:48.360]   Yeah. Maybe that's the... You do the easy things first and get people used to it.
[01:14:48.360 --> 01:14:49.320]   Right.
[01:14:49.320 --> 01:14:54.680]   Instead of trying to wash their dishes at the sink.
[01:14:54.680 --> 01:15:02.280]   Right. Well, to follow up on that and something that Daniel talked about earlier with us not
[01:15:02.280 --> 01:15:08.280]   really understanding how the human brain works. Applications like this, like for art or for
[01:15:08.280 --> 01:15:17.000]   doing image recognition for your doorbell, things like that are great ways of starting to get AI
[01:15:17.000 --> 01:15:22.760]   into some real applications where it's not necessarily safety critical.
[01:15:22.760 --> 01:15:29.320]   Because the reality is these AI systems, they don't work the way the human brain does.
[01:15:29.320 --> 01:15:34.680]   There's so much about the brain that we don't understand about the way we perceive the world.
[01:15:34.680 --> 01:15:43.320]   For all of our flaws, we're actually remarkably adaptable, much more so than AI systems are right
[01:15:43.320 --> 01:15:48.600]   now. Well, it's just like you were saying, Daniel, the neuroscience of it is the human brain is a
[01:15:48.600 --> 01:15:55.880]   vast mystery. A baby can recognize faces better than a machine can right now.
[01:15:55.880 --> 01:15:59.960]   Yeah, we're just brute forcing it at this point with microprocessors and machine learning.
[01:15:59.960 --> 01:16:04.840]   You just give it like a billion examples and then it learns. Humans don't require a billion
[01:16:04.840 --> 01:16:08.920]   examples to pick up a pattern. We do it quite easily and we can break that pattern just as easily.
[01:16:08.920 --> 01:16:10.920]   I think that's maybe the way to do it.
[01:16:10.920 --> 01:16:11.560]   I mean, that's just...
[01:16:11.560 --> 01:16:13.560]   To think about we're good at pattern recognition.
[01:16:13.560 --> 01:16:18.040]   Maybe these AIs should do the things we're not so good at.
[01:16:18.040 --> 01:16:18.280]   Right.
[01:16:18.280 --> 01:16:21.240]   Already, you know, memory is a good example.
[01:16:21.960 --> 01:16:27.560]   Memory, human memory is flawed, not great. And as I get older, it's worse and worse.
[01:16:27.560 --> 01:16:31.560]   But thank God for Google. I don't know how people in earlier generations survived
[01:16:31.560 --> 01:16:36.120]   getting older because I don't have to remember everything. I just Google it.
[01:16:36.120 --> 01:16:41.400]   And I often will say, oh, I can't remember what was...
[01:16:41.400 --> 01:16:49.000]   Yesterday, my board up at the radio show said there was a protest across the street.
[01:16:49.000 --> 01:16:52.520]   It was a flag, it was a green and white flag with a lion on it.
[01:16:52.520 --> 01:16:56.680]   And we were able with image search to find out what that was.
[01:16:56.680 --> 01:16:59.320]   It was the Iranian flag. It was an Iranian protest.
[01:16:59.320 --> 01:17:04.920]   You know, I don't know how you do it 50 years ago. You go to the library.
[01:17:04.920 --> 01:17:06.760]   Maybe in a week you'd find out. I don't know.
[01:17:06.760 --> 01:17:13.720]   Here's an example of AI, I guess, doing voice impersonations.
[01:17:13.720 --> 01:17:17.080]   This is a new podcast from podcast.ai.
[01:17:17.080 --> 01:17:25.000]   The first episode they had Bro Jogan, the famous broadcaster, interviewing a guy.
[01:17:25.000 --> 01:17:29.080]   They wouldn't say who it was. Well, here, let me play a little bit because the voices are pretty
[01:17:29.080 --> 01:17:33.880]   good. It came on the show. How's it going? Good to see you, buddy. It's been a long time since I've
[01:17:33.880 --> 01:17:39.560]   been on the show. I've missed this. It's always fun. How's it going? Come on, tell me about jobs.
[01:17:39.560 --> 01:17:46.760]   The laughter is not working. It's always good to see you, buddy. I'm so happy you came on,
[01:17:46.760 --> 01:17:51.320]   man. Yeah, it's great to be on the show. I don't listen to Joe Rogan, but I think this is actually
[01:17:51.320 --> 01:17:56.360]   pretty close to a real Joe Rogan. You know, it washes over you and tells you that everything is
[01:17:56.360 --> 01:18:01.240]   connected. You're not here by accident. You were put here for a purpose. And if you figure out what
[01:18:01.240 --> 01:18:07.080]   that is, clearly the AI was trained on actual Steve Jobs quotes. It's pretty intense. I mean,
[01:18:07.080 --> 01:18:11.240]   it's not a one. And then the voice as well. So some of these just reveals you for who and what
[01:18:11.240 --> 01:18:16.440]   you are sentences are actually. The JRO can stop us way better just because he's so
[01:18:16.440 --> 01:18:20.760]   prolific. There's a lot more of his voice. He was this in play so it could train easier.
[01:18:20.760 --> 01:18:25.640]   It's a new programming language and operating system. And then he became even more famous for
[01:18:25.640 --> 01:18:30.920]   making three applications for that computer. So it's just like word processor, a spreadsheet,
[01:18:30.920 --> 01:18:37.560]   and an image editor. That just showed me that this dude was brilliant, had amazing taste.
[01:18:37.560 --> 01:18:43.000]   They even have the microphone pops. That I could be one tenth of the genius that my friend today.
[01:18:43.000 --> 01:18:47.480]   What it lacks is the intonation and any kind of emotion that's still the area that it still needs
[01:18:47.480 --> 01:18:53.480]   to work on. And the content is lacking as well, am I? I do have to say one of the applications,
[01:18:53.480 --> 01:18:58.840]   this exact same tech. I'm not going to get into Twitch drama with Twitch streamers, but there is a
[01:18:58.840 --> 01:19:08.920]   very high profile Twitch streamer who uses this technology to one of his enemies in this and then
[01:19:08.920 --> 01:19:13.320]   has the enemy voicing terrible things. The chat is saying live on the show.
[01:19:13.320 --> 01:19:19.720]   Oh, no. You know, it's almost like we have been a technology and then we find out what the worst
[01:19:19.720 --> 01:19:27.240]   ways to use the worst human beings alive. I just want to say with Dolly, going back to that,
[01:19:27.240 --> 01:19:31.320]   look, this is a great technology. I'm really happy Microsoft is doing this.
[01:19:31.320 --> 01:19:38.680]   I love that it's an artistic tool for people to have the ideas that they have brought to life.
[01:19:38.680 --> 01:19:44.520]   But I also think you've got to ask yourself, like, where are these images coming from?
[01:19:44.520 --> 01:19:51.240]   What are the image libraries? What artists are they basing this work off of to generate this art
[01:19:51.240 --> 01:19:56.680]   that basically takes their style and emulate it? And I'm not going to get into it. I think there's
[01:19:56.680 --> 01:20:03.240]   some really ethically questionable decisions they made in how they got these large data sets and
[01:20:04.600 --> 01:20:10.680]   people being compensated for it. Well, we certainly talked about it mentioned a couple of weeks ago,
[01:20:10.680 --> 01:20:15.880]   Getty, the stock photo company won't allow you to use art generated by these AI or
[01:20:15.880 --> 01:20:22.600]   won't sell it because they pointed out they've scraped our entire database so the Getty's
[01:20:22.600 --> 01:20:29.160]   watermark shows up randomly when you use some of these. I think it's stable diffusion that did it.
[01:20:30.200 --> 01:20:35.320]   Yeah, there's clearly copyright problems. Greg Gukowski, who's the great illustrator,
[01:20:35.320 --> 01:20:43.160]   is very mad because he's the most commonly used term in stable diffusion, is draw a penguin
[01:20:43.160 --> 01:20:50.120]   standing on its head in the style of Greg Gukowski. And on the one hand, I think a lot of people
[01:20:50.120 --> 01:20:57.400]   now know who Greg Gukowski is that didn't. But on the other hand, his style that's kind of being
[01:20:58.600 --> 01:21:03.640]   wholesale lifted. And I guess the AI scraped his entire online database.
[01:21:03.640 --> 01:21:09.320]   I think about in the game industry, I can't tell you how many times I've gotten this back
[01:21:09.320 --> 01:21:14.440]   when I was running a game studio. How many times I got this resume? It was like, "Hey, Brianna,
[01:21:14.440 --> 01:21:23.240]   I am just out of school. I am an expert in illustrator. I need a job doing concept art.
[01:21:23.240 --> 01:21:29.560]   Do you have anything at all?" And these people are fighting the tooth and nail with these
[01:21:29.560 --> 01:21:34.040]   illustration degrees to just get their foot in the door. And there's nothing for them.
[01:21:34.040 --> 01:21:40.360]   Like the people that do that work at Blizzard have been there for a decade. And for a small
[01:21:40.360 --> 01:21:46.120]   indie studio, we'll throw out a $1,000 contract here and there. But it's not something a lot of
[01:21:46.120 --> 01:21:50.840]   people are going to be able to build. Do you say I generated stuff? I think you could use AI for
[01:21:50.840 --> 01:21:57.960]   a lot of this stuff now. There's a game that came out this week called Score. It's based on HR
[01:21:57.960 --> 01:22:05.640]   Geekers art style. So you could type all those things into Dali and say, "Give me a shredding machine
[01:22:05.640 --> 01:22:11.880]   in the style of HR Geekers." It could create something like that. So I do think this is going to
[01:22:11.880 --> 01:22:19.160]   have a very negative impact on already very limited art jobs. And I'm not saying it's bad or we
[01:22:19.160 --> 01:22:22.920]   shouldn't use it. I'm just saying there's going to be a consequence of the technology.
[01:22:22.920 --> 01:22:29.400]   We did score and use AI to do these things. No, I'm just saying this is an example of a game
[01:22:29.400 --> 01:22:34.120]   that really needed those concept artists. And I'm not sure they would if they designed it to me.
[01:22:34.120 --> 01:22:39.000]   Yeah. Yeah. There's an interesting article, Matt Welsh, who worked at Google and Apple as a
[01:22:39.000 --> 01:22:45.480]   coder, wrote a piece, "The End of Programming." Actually, I should give credit to
[01:22:46.440 --> 01:22:50.760]   Jeff Jarvis, who found this and wanted to talk about it on Twig. But I'll talk about it now.
[01:22:50.760 --> 01:22:55.240]   He says, "The End of Computer Science is coming. Programming will be obsolete
[01:22:55.240 --> 01:23:01.240]   because it'll be replaced by AI systems that are trained rather than programmed." And in a way,
[01:23:01.240 --> 01:23:07.960]   you are doing a kind of programming now when you write a prompt for Dali or stable diffusion,
[01:23:07.960 --> 01:23:14.600]   but it's not in C or C++. It's in English. And you're just telling the computer to generate what you
[01:23:14.600 --> 01:23:23.880]   want. He says things like GitHub's co-pilot is just scratching the surface. The future is clear that
[01:23:23.880 --> 01:23:33.160]   software will be written by AI, but controlled by humans. As a coder, does that make sense to you,
[01:23:33.160 --> 01:23:41.080]   Brianna? Yeah. I think that's true in some ways. I also think that there's another story that came
[01:23:41.080 --> 01:23:48.520]   out this week basically talking about how Moore's law in this constant growth of a processing
[01:23:48.520 --> 01:23:55.080]   power does seem to be coming to an end soon. And I think that when that happens, refactoring
[01:23:55.080 --> 01:24:00.840]   old code, writing efficient code, I do think, especially as we have energy crises more and more
[01:24:00.840 --> 01:24:05.240]   on Earth, I think that writing efficient code is going to be a highly valued skill.
[01:24:05.240 --> 01:24:08.600]   And I don't think that something AI is going to be able to do as well as humans.
[01:24:08.600 --> 01:24:13.560]   So I think it's a little hyperbolic to say the end of programming. I do think we're going to have
[01:24:13.560 --> 01:24:18.920]   better tools to help us write code. What you will be doing, though, more likely instead of writing,
[01:24:18.920 --> 01:24:26.920]   say, a binary tree search is you'll say, give me a binary tree search, and it will write the
[01:24:26.920 --> 01:24:31.640]   underlying code. And maybe probably write it better than you and I would.
[01:24:31.640 --> 01:24:36.200]   There's so much of programming is stack overflow. So sorry, go ahead.
[01:24:36.200 --> 01:24:37.320]   That's what they just copy.
[01:24:37.320 --> 01:24:41.000]   Like you look at the samples, certainly.
[01:24:41.000 --> 01:24:47.480]   Yeah, just going to say the same predictions have been made for news writing in general.
[01:24:47.480 --> 01:24:48.200]   That's happened.
[01:24:48.200 --> 01:24:49.960]   News writing in sports, right?
[01:24:49.960 --> 01:24:54.440]   Yeah, because it's just facts, right? And the idea is you can string it together.
[01:24:54.440 --> 01:24:59.480]   And in theory, you would actually weed out any kind of bias reporting and word usage,
[01:24:59.480 --> 01:25:03.240]   although that remains to be seen. But yeah, that's expected to happen too in the next
[01:25:03.240 --> 01:25:04.440]   couple years. So we'll see what happens.
[01:25:04.440 --> 01:25:11.000]   From starting in the late 90s, up until I left engineering in 2007,
[01:25:11.000 --> 01:25:18.360]   we, you know, in working on electronic control systems for vehicles, we put a lot of effort into
[01:25:18.360 --> 01:25:29.080]   developing and working with automatic code generation systems using tools like MATLAB, for example,
[01:25:29.080 --> 01:25:34.280]   that we used for development purposes for rapid prototyping.
[01:25:34.280 --> 01:25:39.640]   And then using that and other tools to generate code from the models.
[01:25:39.640 --> 01:25:46.520]   So we would create models, algorithmic models, and then generate auto generate code from that
[01:25:46.520 --> 01:25:52.520]   to run in vehicles. Now, you know, in those days, the code that it generated was not
[01:25:52.520 --> 01:25:58.760]   nearly efficient enough to fit in the amount of storage and memory that we had.
[01:25:58.760 --> 01:26:04.760]   So we ended up doing a lot of rewriting by hand. But, you know, I mean, this is not a new phenomenon.
[01:26:04.760 --> 01:26:08.760]   This is something that was started a long time ago. And it's still ongoing, you know,
[01:26:08.760 --> 01:26:15.400]   this idea of using, building models and then generating the code from that. And that's,
[01:26:15.400 --> 01:26:18.920]   that's what a lot of what's being done today is based on.
[01:26:18.920 --> 01:26:26.040]   There's a new startup that is doing videos in the same way as Dolly does
[01:26:27.240 --> 01:26:34.680]   still images. You give it a couple of images, a script, it will generate the whole, the whole video
[01:26:34.680 --> 01:26:42.360]   for you. So I think that, so, you know, it's clear that there are some things humans are going to
[01:26:42.360 --> 01:26:46.360]   have to do. And I think what's happening is we're starting to see the landscape of
[01:26:46.360 --> 01:26:52.760]   where AI can do a good job and where humans are needed. And it isn't as obvious, you might have
[01:26:52.760 --> 01:26:57.160]   said, well, humans are have to do the creative work. But Dolly has shown stable diffusion,
[01:26:57.160 --> 01:27:02.600]   have shown that that isn't necessarily true. Although, I think I write a surprise. Yeah. Yeah.
[01:27:02.600 --> 01:27:07.800]   Because like, I mean, we always thought AI would do like the menial tasks, which is still, you know,
[01:27:07.800 --> 01:27:13.720]   what's kind of happening. But I didn't predict this idea of like art and like, you know, of course,
[01:27:13.720 --> 01:27:18.360]   we've all heard the stories of like, AI art being entered into art contests and actually winning.
[01:27:19.240 --> 01:27:24.680]   Yeah. I mean, it's, it's, which calls it to question, you know, judging of art by humans versus, you
[01:27:24.680 --> 01:27:29.960]   know, AI is and everything. But yeah, it's a whole other world that just quickly came upon us.
[01:27:29.960 --> 01:27:33.640]   And I'm sure it's already happening with music, you know, music, there already no,
[01:27:33.640 --> 01:27:38.840]   especially pop music, you know, there's kind of a secret sauce to it in terms of
[01:27:38.840 --> 01:27:43.160]   absolutely everything that human brain responds to. So just a matter of time before we start getting
[01:27:43.160 --> 01:27:47.960]   AI generated music. Yeah, don't be fooled by the bad AI music we've heard so far.
[01:27:47.960 --> 01:27:50.680]   I think you're exactly right. It just is all of a sudden
[01:27:50.680 --> 01:27:56.520]   AI art exploded. I think AI music's going to explode. And I would not want to be a pop musician
[01:27:56.520 --> 01:28:02.040]   right now. I think that's that's going to be a tough world in the next couple of years.
[01:28:02.040 --> 01:28:10.840]   How about the Nvidia RTX 4090? How about that? A $1,600 video card. Nvidia has a problem because
[01:28:10.840 --> 01:28:16.360]   they were making bank when the video cards were in high demand from Bitcoin miners. But now that
[01:28:16.360 --> 01:28:23.560]   that's collapsed and there's all these old highly used GPU's on the market for pennies on the dollar.
[01:28:23.560 --> 01:28:28.760]   They've had to find some other way to make money. And I think they might have found it with this
[01:28:28.760 --> 01:28:35.160]   beast of a GPU, which is under a hardware reviewing it and gadget says it's the fastest consumer GPU
[01:28:35.160 --> 01:28:44.200]   we've ever seen. You could even run a K, but it's also, you know, as I said, $1,600.
[01:28:44.200 --> 01:28:50.120]   You know, maybe I'll sell the Oculus Pro Quest Pro and buy this instead. I'd have to get a machine
[01:28:50.120 --> 01:28:53.960]   to go in. How much does it take like more than one slot? It looks like it's
[01:28:53.960 --> 01:28:56.360]   two and a half slots.
[01:28:56.360 --> 01:28:59.000]   Jeez, Louise.
[01:28:59.000 --> 01:29:01.240]   And four power connectors.
[01:29:01.240 --> 01:29:02.840]   That's it for.
[01:29:02.840 --> 01:29:03.800]   Count them.
[01:29:03.800 --> 01:29:07.560]   Four power connectors. So how many what 700 watts?
[01:29:07.560 --> 01:29:09.240]   Probably some.
[01:29:09.240 --> 01:29:15.400]   You combine it with the 13 gen processor and you're going to have a little device that basically
[01:29:15.400 --> 01:29:17.160]   uses as much power as a space heater.
[01:29:17.160 --> 01:29:24.360]   You know, Christina had to talk me out of getting this. I have the RTX 3090. It's great.
[01:29:24.360 --> 01:29:29.160]   But I won't be honest with you. I already have not found a game. Literally, I cannot run
[01:29:29.160 --> 01:29:30.600]   missed out at all settings.
[01:29:30.600 --> 01:29:34.760]   No, I have a 38 in the 3080 runs fine at four.
[01:29:34.760 --> 01:29:35.560]   That's what I got to.
[01:29:35.560 --> 01:29:35.560]   Yeah.
[01:29:35.560 --> 01:29:41.720]   Yeah. And for me, we just Massachusetts is great. They have this fantastic program where you can
[01:29:41.720 --> 01:29:46.120]   get they basically paid the cost of your solar panels going on your roof.
[01:29:46.120 --> 01:29:51.400]   And they're just charging more for electricity and that slowly pays off the solar panels.
[01:29:51.400 --> 01:29:57.640]   So yeah, I saw this and I'm like, well, I don't have to worry so much about the power usage these
[01:29:57.640 --> 01:30:04.680]   days. But I mean, honestly, it's like if you can run cyberpunk at max settings and 100 FPS on a
[01:30:04.680 --> 01:30:08.760]   32 inch monitor, like like running of really good.
[01:30:08.760 --> 01:30:09.960]   That's VR.
[01:30:09.960 --> 01:30:18.040]   That's VR right there. Who needs a helmet? I'll just, you know, 30 inch though. I got a, I got a
[01:30:18.040 --> 01:30:24.360]   OLED 55 inch. That's that's because now it's almost peripheral vision, right? You can,
[01:30:24.360 --> 01:30:28.840]   you're in. It's immersive. When I play stray, I feel like a kitty cat.
[01:30:30.040 --> 01:30:35.560]   I live the kitty cat life. The race now is of course the frames per second. But again,
[01:30:35.560 --> 01:30:39.880]   that's also like the refresh rates on like laptops now are going over 300
[01:30:39.880 --> 01:30:43.560]   Hertz for the refresh rate, which is insane. But it's like, yeah, and it's like what Breanna
[01:30:43.560 --> 01:30:48.520]   was saying. I mean, it's diminishing returns ultimately, like it's nice to have. And if you're a video,
[01:30:48.520 --> 01:30:53.160]   if you're, if you're rendering video, I could see where this will be a big benefit. Maybe it'll
[01:30:53.160 --> 01:30:57.240]   definitely cut your time in half. But in terms of video games, which is usually the primary usage
[01:30:57.240 --> 01:31:01.000]   of them. Yeah, it's like, you know, how much better is this going to be for a lot of people?
[01:31:01.000 --> 01:31:06.120]   Well, nobody because, I mean, correct me if I'm wrong, Breanna, if you were a game studio,
[01:31:06.120 --> 01:31:09.960]   you could say, no, we're going to require the 40 90. Oh, but that would be suicide.
[01:31:09.960 --> 01:31:16.360]   You're going to make sure that it will run fine on a 30 60 or less a 1070
[01:31:16.360 --> 01:31:21.400]   to be a company that's really good. But we're going to have an ultra
[01:31:22.360 --> 01:31:29.640]   high resolution frame rate, you know, infinite distance, you know, the Z goes all the way.
[01:31:29.640 --> 01:31:34.200]   And then say, if you have a 40 90, we've got a mode for you.
[01:31:34.200 --> 01:31:39.480]   That's exactly it. Modern engines are really good at scaling. We're seeing the implementation
[01:31:39.480 --> 01:31:45.960]   of DLSS looks amazing. I do just have to, I hate to be the killjoy on this show, but
[01:31:46.520 --> 01:31:53.400]   there's a story that came out to my joy, Breanna. You know, one of Russia's Vladimir Putin's final
[01:31:53.400 --> 01:32:02.920]   his Hail Mary's in to win the war against Ukraine, being the sabotage his own pipeline. It's like the
[01:32:02.920 --> 01:32:09.720]   basically destroyed the energy supply throughout all of Europe, leaving like people literally
[01:32:09.720 --> 01:32:16.040]   choosing between heating their homes and eating. It was a 40 90. You don't have to choose,
[01:32:16.040 --> 01:32:22.680]   because it will heat your home and play again. I guess that's fair. I just say at some point here,
[01:32:22.680 --> 01:32:28.520]   a card that takes four connectors for you. There's an environmental
[01:32:28.520 --> 01:32:33.000]   question, I think is worth asking ourselves. That's all I'm saying. This has a
[01:32:33.000 --> 01:32:42.760]   TDP of I think they said 450 Watts, but they recommend that you have a 800
[01:32:43.480 --> 01:32:51.640]   watt 850 watt PSU in order to run it. Yeah, because you got to have some wattage for the rest of the
[01:32:51.640 --> 01:33:03.880]   computer. We're, you know what, Breanna, welcome to the modern world where 1% has everything they
[01:33:03.880 --> 01:33:10.840]   want, including, you know, giant screens and 40 90 cards. And the rest of us are walking barefoot
[01:33:10.840 --> 01:33:17.400]   through desiccated onion fields. I don't know where I'm going with this. I'm
[01:33:17.400 --> 01:33:25.000]   suddenly channeling Dolly too. But, you know, I mean, this is where we are headed with massive
[01:33:25.000 --> 01:33:36.840]   income inequality. And it's terrifying, frankly. It doesn't mean Nvidia shouldn't make it worse
[01:33:36.840 --> 01:33:41.720]   for the foreseeable future. Yeah, exactly. And then climate change really starts hitting hard and,
[01:33:41.720 --> 01:33:47.880]   you know, have whole parts of the world that are uninhabitable, which means massive refugee crises.
[01:33:47.880 --> 01:33:54.600]   Okay, I'm sorry. That my mind's going wrong. Sorry, I didn't mean to do that. Sixth extinction is on
[01:33:54.600 --> 01:33:57.800]   his way. Except for a pro nine. Meanwhile, let's talk about our
[01:33:57.800 --> 01:34:05.720]   action. I wanted to ask you about Nvidia because Sam, because Nvidia is not just making video
[01:34:05.720 --> 01:34:10.760]   game cards, they are making AI chips and they're making self driving chips, right? They're very
[01:34:10.760 --> 01:34:16.520]   much. Yeah, they are. In fact, a couple of weeks ago, when they had their fall GTC, they announced a
[01:34:16.520 --> 01:34:26.360]   new chip that's scheduled for 2025 production. It's called Thor. It's an SOC with 2000 tera ops
[01:34:26.360 --> 01:34:33.720]   integer performance and 2000 teraflops floating point performance, which is designed, you know,
[01:34:33.720 --> 01:34:40.200]   to be able to have this one chip power the entire car, at least in terms of computing performance.
[01:34:40.200 --> 01:34:48.120]   It's, you know, it's still, you know, it's three years away from production programs. But, you know,
[01:34:48.120 --> 01:34:54.280]   this is just, you know, they won't, they haven't said how much, how much how many watts this thing
[01:34:54.280 --> 01:35:03.000]   consumes. But as an example, other automated vehicles that I've seen, their compute platforms
[01:35:03.000 --> 01:35:08.120]   just just the compute, not including the sensors and everything else, can consume as much as four
[01:35:08.120 --> 01:35:15.320]   kilowatts just for the compute to do an automated vehicle. Yeah, God, we're going to need a bigger
[01:35:15.320 --> 01:35:25.240]   battery. Yep. Wow. That's actually what Devindra says is the 4090 is such a leap ahead. He likens it
[01:35:25.240 --> 01:35:32.520]   to a a black hole so massive at warp space time around it. This is the new standard. This is like,
[01:35:32.520 --> 01:35:38.120]   we're putting that, planning that flag way out ahead. And so you're going to see, you know, this is
[01:35:38.120 --> 01:35:43.480]   setting the mark in effect. And I guess that's what they're doing in automotive as well.
[01:35:43.480 --> 01:35:49.240]   Yeah. And, you know, that Thor chip, you know, last year at the spring GTC, they announced a
[01:35:49.240 --> 01:35:55.720]   chip called Atlin, which they canceled and replaced with Thor because they, since Atlin,
[01:35:55.720 --> 01:36:04.360]   they introduced an ARM SOC for data centers for servers called Grace. And then also a new GPU
[01:36:04.360 --> 01:36:10.440]   architecture called Hopper. And so what they did was they realized, well, we can take the technology
[01:36:10.440 --> 01:36:15.560]   we've got in Grace and Hopper, combine those with a bunch of other stuff to make this other chip
[01:36:15.560 --> 01:36:21.240]   that would give us twice the performance of what we had already announced. And, you know, those
[01:36:21.240 --> 01:36:27.240]   chips, you know, some of the some of the the areas that NVIDIA is involved in, you know,
[01:36:27.240 --> 01:36:33.400]   the some of the data centers that they're powering, you know, all kinds of robotics applications,
[01:36:33.400 --> 01:36:40.360]   it does go way beyond GPUs. GPUs is just one small part of their business now. And I think,
[01:36:40.360 --> 01:36:47.400]   you know, there was a story that was further down, I think, on the on the rundown about, you know,
[01:36:47.400 --> 01:36:52.760]   American exec, you know, chip, chip companies, American chip companies operating in China.
[01:36:52.760 --> 01:36:57.480]   Oh my God. In recent, a few weeks back, there was, you know, there was an announcement from the
[01:36:57.480 --> 01:37:04.040]   Biden administration. Yeah, you know, barring the export of a lot of these high performance
[01:37:04.040 --> 01:37:11.320]   data center chips and server chips to China. And NVIDIA is one of the companies that's impacted by
[01:37:11.320 --> 01:37:17.160]   that. So far, there was something else that just came up the other day that I haven't been able to
[01:37:17.160 --> 01:37:25.960]   dive into in in depth yet. But it it seems like they may maybe expanding those sanctions to cover
[01:37:25.960 --> 01:37:32.840]   other types of chips as well. So that might end up impacting both NVIDIA and Qualcomm,
[01:37:32.840 --> 01:37:35.880]   which is also selling. Yeah, I think they bumped up a
[01:37:35.880 --> 01:37:42.600]   they bumped up the nanometer to 16 nanometer, anything. So it's like even older legacy chips
[01:37:42.600 --> 01:37:48.440]   won't be able to be used. And it also affects actual people. If you're an American citizen
[01:37:48.440 --> 01:37:54.520]   working on this technology in China, you can either give up your citizenship or face arrest
[01:37:54.520 --> 01:37:57.800]   if you come back or leave the country. That's the one that's the one that's the one that's the
[01:37:57.800 --> 01:38:05.560]   journal story today. Yeah, at least 43 senior executives working with 16 listed Chinese semiconductor
[01:38:05.560 --> 01:38:11.560]   roles. Companies hold roles from CEO to vice president. They're the ones facing after the ban.
[01:38:12.120 --> 01:38:16.520]   This prospect of either you quit and come home now, or you're going to have to give up your
[01:38:16.520 --> 01:38:23.000]   citizenship and stay in China. It's a massive brain drain. It's going to really cripple China's
[01:38:23.000 --> 01:38:29.240]   like chip industry and for super chips used for weapons and the military primarily, but also for
[01:38:29.240 --> 01:38:35.480]   driving AI, self driving and all this other stuff. It almost it almost seems, I don't know,
[01:38:35.480 --> 01:38:40.600]   a little too much. They're really serious sanctions. I mean, it's it's going to really,
[01:38:40.600 --> 01:38:44.120]   really, really hobble China. And you got to wonder, of course, what's you know, what China's going
[01:38:44.120 --> 01:38:48.680]   to do in response to that, right? Because they're not going to just idly sit by. I think that's kind
[01:38:48.680 --> 01:38:52.520]   of the real big question that we have to wait now to see what happens. This is worse than a trade
[01:38:52.520 --> 01:38:58.280]   war. This is a shot across the bow. And I understand why the US government did it. There was real
[01:38:58.280 --> 01:39:03.800]   concern among the intelligence community. As you say, that they were using our technology to power
[01:39:03.800 --> 01:39:11.560]   their military and their AI for military uses so that we were in effect helping build up their
[01:39:11.560 --> 01:39:18.440]   military when they pose a real threat, at least to Taiwan, our ally, but also to the whole region
[01:39:18.440 --> 01:39:23.000]   and maybe even the whole world at some point. So I understand why you'd want to do something about
[01:39:23.000 --> 01:39:30.920]   it. But it seems like it almost seems like a war like action, especially with she president,
[01:39:30.920 --> 01:39:37.320]   she now going for his, you know, coronation is the emperor of China at the party Congress,
[01:39:37.320 --> 01:39:43.640]   such as going on now. And he's been in order to secure his power in his position, doing a lot of
[01:39:43.640 --> 01:39:51.080]   saber rattling. And I just worry that we're heating up. And this is about geopolitics as much as it
[01:39:51.080 --> 01:39:56.120]   is tech. But I just I agree with you, Daniel, I worry we're heating up this already volatile space.
[01:39:56.120 --> 01:40:02.840]   And maybe going to have consequences that we will long regret. Yeah, I mean, Ian Bremer, you know,
[01:40:02.840 --> 01:40:07.800]   made this good point about the future of the geopolitical atmosphere. Like, it's better when
[01:40:07.800 --> 01:40:15.560]   the Chinese and American economies are intertwined. I disagree. Yeah, that if a war would just be
[01:40:15.560 --> 01:40:19.400]   unfeasible, because it would just destroy both economies and just wouldn't be worth the risk. But
[01:40:19.400 --> 01:40:25.560]   as soon as we start, you know, separating ourselves from China and disengaging. And I get it, you know,
[01:40:25.560 --> 01:40:30.040]   we want to build up Intel, something happens to Taiwan. We want to make sure we have a fab here
[01:40:30.040 --> 01:40:34.040]   and all that. So I kind of get that. But yeah, I mean, there is a risk here that, you know, the
[01:40:34.040 --> 01:40:39.960]   more we go down this route, the more dangerous it's going to get. I guess we have to trust our
[01:40:39.960 --> 01:40:44.360]   government and our intelligence agencies. But that's historically hard for us to do.
[01:40:44.360 --> 01:40:51.400]   Especially in this country. Yeah, I don't know if it's the intelligence agencies as much as the
[01:40:51.400 --> 01:40:56.040]   state department. I think well, we're talking. Yeah. Here's here's for months administration
[01:40:56.040 --> 01:41:00.360]   officials have debated this from the New York Times, what they could do to hobble China's progress.
[01:41:00.360 --> 01:41:05.560]   China, according to the times was using super computing and artificial intelligence to develop
[01:41:05.560 --> 01:41:12.280]   stealth and hypersonic weapons systems, and maybe even worse, to crack our encryption.
[01:41:12.280 --> 01:41:20.920]   And this is according to intelligence reports. So you're giving another country the power to become
[01:41:21.720 --> 01:41:27.640]   a real enemy. But then at the same time, I agree with Bremer, the better it's better to
[01:41:27.640 --> 01:41:34.680]   be allies, you know, even if you're frenemies, because it preserves the peace. This is not the
[01:41:34.680 --> 01:41:39.960]   kind of move that preserves the peace. Yes, you're taking away an important weapon. But I also
[01:41:39.960 --> 01:41:47.320]   think that the Chinese given a little time, it's not they're not dumb. They have high smart people
[01:41:47.320 --> 01:41:53.560]   and high technology and great universities. I don't know why they couldn't duplicate our efforts.
[01:41:53.560 --> 01:41:57.880]   So I don't know what it's best to short term solutions. It's a short term solution.
[01:41:57.880 --> 01:42:04.760]   Well, I wanted to say was, you know, I think there's a longer term view to have here. You know,
[01:42:04.760 --> 01:42:09.720]   if you look at the Marshall Plan following World War II, I really feel like a lot of people on my
[01:42:09.720 --> 01:42:16.920]   own side really underestimate this. Like we've had the longest historical period of peace and
[01:42:16.920 --> 01:42:22.840]   prosperity in like worldwide history. Because of interdependence. Because of interdependency,
[01:42:22.840 --> 01:42:28.280]   because of the, you know, Bretton Woods, because of these alliances to create this
[01:42:28.280 --> 01:42:35.960]   basically economic dependency between nations. This has been good. And on one hand, when I see
[01:42:35.960 --> 01:42:41.800]   the United States doing things like shoring up domestic chip production, I 100% support that
[01:42:41.800 --> 01:42:47.080]   in many ways. I do think we need redundancies here, even though it doesn't make sense in some ways,
[01:42:47.080 --> 01:42:51.080]   because we don't have the tools you actually need to build those chips. But that's a whole
[01:42:51.080 --> 01:42:56.120]   another discussion. At the same time, you know, this really strikes me as being similar to the
[01:42:56.120 --> 01:43:01.480]   discussion we had in the 80s when, you know, the fear was Russia was going to copy American chips
[01:43:01.480 --> 01:43:06.280]   on this and that they were going to use it in nuclear missiles. So, you know, I think that,
[01:43:06.280 --> 01:43:12.600]   I don't think that the answers for us to withdraw from the world and to withdraw our industry from
[01:43:12.600 --> 01:43:17.720]   the world. I think we need to be doubling down and doing our own development in this area. That's
[01:43:17.720 --> 01:43:25.240]   my take on it, at least. Yeah, I agree. You know, that we don't want to completely withdraw. I mean,
[01:43:25.240 --> 01:43:31.480]   a big part of the strategy for the last 50, 60, 70 years has been the idea that, you know, if
[01:43:31.480 --> 01:43:38.200]   everybody is engaged, you know, in trade across borders, we become dependent on each other and we
[01:43:38.200 --> 01:43:44.760]   are less likely to go to war. I mean, that was the whole theory behind the European Union. You know,
[01:43:44.760 --> 01:43:50.280]   on the other hand, you know, what we, one of the downsides of the way it's been implemented
[01:43:50.280 --> 01:43:57.320]   over the last several decades is that we ended up with way too much consolidation of with too
[01:43:57.320 --> 01:44:04.680]   few companies producing stuff in too few places. And we got too dependent and we ended up with
[01:44:04.680 --> 01:44:09.480]   supply chains that became very brittle, which has led to the situation we've had over the last
[01:44:09.480 --> 01:44:15.000]   couple of years, where if you have any kind of disruption, whether it's a pandemic, natural
[01:44:15.000 --> 01:44:26.280]   disaster, geopolitical issues, you end up disrupting so many things in our in economies globally.
[01:44:26.280 --> 01:44:32.280]   And so what we're actually starting to see now over the last year or so is a lot of companies
[01:44:32.280 --> 01:44:40.040]   moving back, backing away from the consolidation approach we've had to becoming more diversified
[01:44:40.040 --> 01:44:46.440]   in their supply chains, getting things from more companies in more in more locations so that we're
[01:44:46.440 --> 01:44:50.840]   not totally dependent on any one location, which is actually, I think in the long term,
[01:44:50.840 --> 01:44:57.720]   going to be a better thing, because you don't necessarily want to have be totally self, I mean,
[01:44:57.720 --> 01:45:03.960]   ideally, it's good to be self sufficient, but you know, you want to have some trade across border
[01:45:03.960 --> 01:45:09.160]   trade to get, you know, some dependency, but you don't want to be totally dependent on any one
[01:45:09.160 --> 01:45:14.680]   location. Yes, and that's Apple's moving very quickly to do that. It's estimated in the next few
[01:45:14.680 --> 01:45:20.200]   years that at least half of iPhone production could be done in Vietnam, India, Brazil, other
[01:45:20.200 --> 01:45:29.320]   countries, not China. Yeah, that seems a reasonable long term goal. Here's an interesting use of AI,
[01:45:29.320 --> 01:45:36.360]   there's a charity called Give Directly, give directly dot org. The idea is it's an NGO, but
[01:45:36.360 --> 01:45:43.240]   instead of, you know, kind of wrapping your gift into a bunch of administrative costs and complex
[01:45:43.240 --> 01:45:47.800]   charities, you just give directly, they've been using, they're funded by the way by Google,
[01:45:47.800 --> 01:45:55.480]   Google dot org, their charitable arm, as well as USAID and other companies. They're one of the
[01:45:55.480 --> 01:46:05.160]   things they're doing now to help in the survivors of Hurricane Ian is using Google and AI to figure
[01:46:05.160 --> 01:46:13.800]   out where the greatest need is. And then algorithmically send people money, which I think is fascinating,
[01:46:13.800 --> 01:46:20.920]   3,500 residents of Collier Charlotte and Lee Counties got a push notification on their smartphones
[01:46:20.920 --> 01:46:27.400]   offering them $700 cash, no questions asked based on a Google algorithm deployed in partnership with
[01:46:27.400 --> 01:46:36.680]   Give Directly. They use satellite images to see where the need was greatest. What do you think?
[01:46:36.680 --> 01:46:44.360]   That's a good use of AI is that I think it's a positive. Yeah, I could definitely see that.
[01:46:44.360 --> 01:46:49.240]   I could see it going wrong too, I understand. Yeah, no, I mean, if it works, and you know,
[01:46:49.240 --> 01:46:54.840]   this, this seems like an application where, you know, vision systems, machine vision systems,
[01:46:54.840 --> 01:47:01.640]   could probably do a pretty good job. And it should be able to work pretty well, you know, to pick out,
[01:47:01.640 --> 01:47:08.520]   you know, with these locations where help is needed. AI for disaster response, a paper
[01:47:08.520 --> 01:47:15.720]   presented a couple of years ago at an academic workshop said an AI doing that could match those
[01:47:15.720 --> 01:47:22.600]   of human experts with 85 to 98% accuracy. So humans doing it probably has fast flaws too.
[01:47:23.480 --> 01:47:28.920]   So very interesting. You could probably get it, you know, find it a lot faster with this approach.
[01:47:28.920 --> 01:47:35.960]   Exactly. Rather than just sending people out into the field, you know, and trying to find the
[01:47:35.960 --> 01:47:41.640]   people that need help, you could probably do it a lot more quickly. And hopefully, you know,
[01:47:41.640 --> 01:47:47.080]   distribute the funds to people, you know, get money into people's pockets to help them,
[01:47:47.640 --> 01:47:54.520]   you know, find find someplace to stay, get food, you know, whatever, you know, to help them get
[01:47:54.520 --> 01:48:01.000]   through that initial period. Although, and this is a, I think an indication of life in the 21st
[01:48:01.000 --> 01:48:06.440]   century of the 700 people who got pushed notifications, only 200 responded. It's thought that the
[01:48:06.440 --> 01:48:12.680]   other 500 thought they were fishing scams and just, and just ignored not off not, not an unreasonable
[01:48:12.680 --> 01:48:18.200]   response. No, no, I think they're right. I think they're right. No, that was real money. Sorry,
[01:48:18.200 --> 01:48:24.520]   but it was it's buried in about 300 other text messages offering money from Nigerian princes
[01:48:24.520 --> 01:48:31.560]   and others. Brandon Wu, great to have you from the rebellion pack and the rocket podcast that
[01:48:31.560 --> 01:48:36.440]   great show you do is Simone de Roche for and our wonderful Christina Warren, who was a host
[01:48:36.440 --> 01:48:41.640]   at the festivities at Microsoft's Ignite this week, which is kind of cool.
[01:48:41.640 --> 01:48:44.760]   Sure. Proud to work with her. She's amazing. She's the greatest.
[01:48:44.760 --> 01:48:50.920]   And of course, Daniel Rubino from Windows Central, he's executive editor there. Did you watch
[01:48:50.920 --> 01:48:56.680]   all the Ignite videos yet? Some of them looked pretty interesting. I did not. I mean, I was in
[01:48:56.680 --> 01:49:01.640]   New York that day for the Surface stuff, but I still think I'm not being able to go watch it.
[01:49:01.640 --> 01:49:05.240]   Oh, so they had a, okay. So that's interesting. So there's this debate about whether Apple
[01:49:05.240 --> 01:49:09.240]   should have an event this month. They've got, you know, a half dozen new products to announce.
[01:49:09.240 --> 01:49:15.000]   And I thought Microsoft kind of punted and recorded a video, Panos, Panay. I mean,
[01:49:15.000 --> 01:49:21.400]   obviously all of that was recorded, but then released it at a specific time, 7 a.m. Pacific
[01:49:21.400 --> 01:49:27.560]   Wednesday and I had to get up for that. So it was, but they did. So, but they actually invited
[01:49:27.560 --> 01:49:34.520]   people to the to an event as well. Yes. And really sitting in, I believe LA had an event too for
[01:49:34.520 --> 01:49:37.640]   media. Did they have a hands on and stuff like that? Yeah. Yeah.
[01:49:37.640 --> 01:49:44.600]   All the stuff out there. That's what Apple did last month with the iPhone. They had a recorded
[01:49:44.600 --> 01:49:49.640]   event, but journalists went to the campus and got to do the hands on. I don't know why they
[01:49:49.640 --> 01:49:54.600]   wouldn't do that again this month, but the rumor mill seems to agree that's not going to happen.
[01:49:54.600 --> 01:49:58.520]   We'll talk about that in just a little bit. It's great to have you, Daniel.
[01:49:58.520 --> 01:50:05.560]   Also, Sammable, Sammied, my car guy. Well, he's our car guy. We'll bearing his podcast,
[01:50:05.560 --> 01:50:10.360]   a great podcast for people where it's auto enthusiasts. Our show today brought to you by
[01:50:10.360 --> 01:50:16.840]   Noom. I love, you know about Noom? You, you look like you might have done Noom there, Brianna.
[01:50:16.840 --> 01:50:24.360]   I lost over a hundred pounds with you. What? So I did. I did. So I had a running injury a while
[01:50:24.360 --> 01:50:31.880]   back. And I could not run for six months while I was waiting for surgery. They drilled six holes
[01:50:31.880 --> 01:50:38.360]   through my tibia to basically fix it. It was dreadful. And I put on just a ton of weight.
[01:50:38.360 --> 01:50:45.560]   At my heaviest, I was 220 pounds. I don't think I've ever known you this thin.
[01:50:45.560 --> 01:50:53.960]   And you transformed. How long did it take? I did. It took me about probably about six or seven
[01:50:53.960 --> 01:51:01.720]   months. And you know, it was honestly not hard. It was just recording the calories of what I ate.
[01:51:01.720 --> 01:51:07.240]   And just becoming more mindful. That's what Noom is so good about, I think. 100%.
[01:51:07.240 --> 01:51:12.040]   Yeah. It's not a diet. It's education, what you eat, affects your body.
[01:51:12.040 --> 01:51:17.320]   Well, you look gorgeous. I mean, it's, yeah, it's amazing the transformation. And you know,
[01:51:17.320 --> 01:51:21.400]   you're not the only one. We have a guy in the chatroom. I don't want to name names,
[01:51:21.400 --> 01:51:27.080]   but I think the chatroom knows who it is who went on our geek cruise. And I knew he was going
[01:51:27.080 --> 01:51:32.200]   on the cruise. And I hadn't seen him in a few months. And I couldn't find him. And I texted him.
[01:51:32.200 --> 01:51:37.960]   I said, where are you? He said, right next to you right here. And he just was, he'd lost 60 pounds
[01:51:37.960 --> 01:51:44.120]   on Noom. He was unrecognizable. I was like, you're a new man. He says, it's great. He's kept it off.
[01:51:44.120 --> 01:51:49.720]   My wife Lisa, the same thing. She didn't look like she needed as you know, didn't look like she
[01:51:49.720 --> 01:51:54.680]   needed to lose any weight. But she wanted to lose about 20 pounds. Little less. She did, I think,
[01:51:54.680 --> 01:52:00.520]   18 or 19 pounds. I've lost 20 pounds on him. It works because it isn't a diet. There are no
[01:52:00.520 --> 01:52:05.880]   restrictions. There are no foods you can't eat. It's a psychology first approach. Noom weight
[01:52:05.880 --> 01:52:11.000]   allows you to build more sustainable habits, a sustainable, so important with weight loss.
[01:52:11.000 --> 01:52:15.800]   Because the worst thing for you is to lose the weight and gain it back. With Noom, you get
[01:52:15.800 --> 01:52:23.720]   behaviors that last 3.6 million people have lost weight on Noom. Now, I have to tell you,
[01:52:23.720 --> 01:52:30.840]   our weight loss is not typical. On average, Noom users lose about 15 pounds in 16 weeks.
[01:52:30.840 --> 01:52:37.720]   100 pounds not guaranteed. But I have to say 95% of customers say Noom weight is a good long-term
[01:52:37.720 --> 01:52:41.640]   solution. And that's what you're looking for. It's based on scientific principles like
[01:52:41.640 --> 01:52:46.680]   cognitive behavioral therapy, CBT. So you understand your relationship with food.
[01:52:46.680 --> 01:52:51.960]   Lisa says she was a fog eater. And I am that way too. I'm an emotional eater,
[01:52:51.960 --> 01:52:55.000]   but she was a fog eater. Well, she would eat and not even know she was eating.
[01:52:55.000 --> 01:53:01.400]   I'm emotional. I get home and I reduce the stress by stuffing things in my mouth. Learning about that
[01:53:01.400 --> 01:53:08.600]   has been so valuable. One of the things we now do is we turn off the TV, we put away our phones,
[01:53:08.600 --> 01:53:14.520]   we sit down to a meal at a table with napkins, silverware, and we eat thoughtfully, mindfully,
[01:53:14.520 --> 01:53:19.400]   chewing every bite and really enjoying the food. Sometimes I'll even close my eyes and really
[01:53:19.400 --> 01:53:25.320]   taste it. And it's amazing what a difference that makes in how you eat. I'm eating consciously
[01:53:25.320 --> 01:53:30.440]   all of a sudden. Noom doesn't believe in restricting what you can or can't eat. So whatever your
[01:53:30.440 --> 01:53:35.960]   health goals are, the flexible non-restictive program focuses on progress, not perfection.
[01:53:35.960 --> 01:53:41.480]   And it's not just the lessons, which are great. You could choose how long
[01:53:41.480 --> 01:53:48.440]   those lessons are for you. It's also a coach, personal coaching. You choose the level of support.
[01:53:48.440 --> 01:53:54.440]   They have groups as well. You can participate in them or not. It's up to you. Five-minute daily
[01:53:54.440 --> 01:53:59.640]   checkings, personal coaching, whatever works for you. And the thing it's important to understand
[01:53:59.640 --> 01:54:04.200]   progress is not a straight line. So, Noom, you get off days. In fact, as you go with Noom,
[01:54:04.200 --> 01:54:08.680]   you'll get bonus days. In fact, my coach would say, "Okay, bonus day, eat whatever you want.
[01:54:08.680 --> 01:54:13.160]   Don't log it. It's fine." Both Lisa and I love it. And as you hear from many of our
[01:54:13.720 --> 01:54:18.120]   panelists, they love it too. Noom has published more than 30 peer-reviewed scientific articles
[01:54:18.120 --> 01:54:23.640]   that inform users, practitioners, scientists, and the public about their methods and affect them.
[01:54:23.640 --> 01:54:28.280]   And the state focused on what's important to you with Noom weight's psychology-based approach.
[01:54:28.280 --> 01:54:37.400]   Sign up for your trial today, NoomN-O-O-M.com/twit. Noom.com/twit. Sign up for your trial at
[01:54:37.400 --> 01:54:43.720]   Noom.com/twit. Can't thank you enough, Noom. You've made a huge difference in our lives.
[01:54:43.720 --> 01:54:48.520]   Brianna, I had no idea you'd lost 100 pounds. That's amazing.
[01:54:48.520 --> 01:54:55.560]   Oh, 100%. And since I lost, it's been almost a year. I have no issue putting it back on whatsoever.
[01:54:55.560 --> 01:55:01.720]   Because the weird thing is it changes what you think tastes good and where before I might have
[01:55:01.720 --> 01:55:08.760]   grabbed something, some chips or whatever, you want to eat like a yolk. It really changes your mind.
[01:55:08.760 --> 01:55:13.720]   It's kind of amazing that that's even possible. It's really great.
[01:55:13.720 --> 01:55:19.480]   Thank you, Noom. And thank you, dear listeners, for going to Noom.com/twit. Let
[01:55:19.480 --> 01:55:26.200]   know you saw it here. Oh, there's so many stories. So much to talk about so little time. How about
[01:55:26.200 --> 01:55:37.560]   this? CNN is backing down on its NFTs. They had a NFT market selling collectible moments
[01:55:37.560 --> 01:55:43.560]   tied to major news events. They've dropped it, but now this is the problem.
[01:55:43.560 --> 01:55:48.680]   Users are saying it's a rug pull. We've sent about thousands of dollars
[01:55:48.680 --> 01:55:53.560]   and we were sold in exclusive access and features and coming in the future.
[01:55:54.680 --> 01:56:01.240]   And now they're killing it. On Monday afternoon, CNN ended its big web three project by announcing
[01:56:01.240 --> 01:56:08.040]   we've decided it's time to say goodbye to the vault by CNN. I hate to tell you NFT users,
[01:56:08.040 --> 01:56:15.080]   get ready. There's a lot of rugs going to be pulled. Intentionally or not.
[01:56:15.080 --> 01:56:22.680]   I guess NBA is still doing the top shot, but here's the thing. NFT trading volumes have collapsed
[01:56:22.680 --> 01:56:27.800]   97% since the beginning of the year. Still not enough. It needs to be 99%.
[01:56:27.800 --> 01:56:34.760]   Well, but here's what's happening is people buy these things. Basically, it's a speculative
[01:56:34.760 --> 01:56:39.720]   thing. It's not an investment in art. I mean, some people say, I want to support the artists.
[01:56:39.720 --> 01:56:43.480]   That's fine. I wish the artists would sell a print so I could support them by buying something
[01:56:43.480 --> 01:56:49.720]   I can hang on my wall. But people buy these because they think they're going to be able to resell
[01:56:49.720 --> 01:56:54.520]   them for a lot of money later. It's an investment and a speculative investment at that.
[01:56:54.520 --> 01:57:01.080]   When the market tanks as it has, all these people, and you know what was going to happen,
[01:57:01.080 --> 01:57:08.280]   or left holding their board apes, just like, well, no, what do I do? There's no market for it.
[01:57:08.280 --> 01:57:10.920]   Well, what are board apes worth these days? You know,
[01:57:10.920 --> 01:57:15.720]   see, that's the question. You can say, what are they worth it? I can go tell you $300,000.
[01:57:16.600 --> 01:57:22.040]   But is anybody actually paying that? That's just a number somebody's attached to it.
[01:57:22.040 --> 01:57:29.720]   There were reports that a lot of these, like the board apes and a lot of the other NFTs,
[01:57:29.720 --> 01:57:37.160]   were they're going through, I forget the term for it, but basically, people would set up multiple
[01:57:37.160 --> 01:57:41.880]   accounts and they would sell it to themselves, trade it between different accounts.
[01:57:41.880 --> 01:57:43.720]   That's the problem. I think it's a little bit of hype.
[01:57:45.080 --> 01:57:53.400]   So there were a 38 board ape sold in the last week, $3.72 million. The average price is $98,000.
[01:57:53.400 --> 01:57:58.040]   I think the top price was over a million dollars for one board ape. Yeah.
[01:57:58.040 --> 01:58:06.120]   Board ape, yacht club, $1 million 15 days ago, the guy with a crown. Now, what makes this one
[01:58:06.120 --> 01:58:10.760]   worth a hundred, went through a million dollars when this one's worth $225,000?
[01:58:10.760 --> 01:58:18.360]   Because he's got a pipe, not a crown. It's just a stupid drawing of a vaguely racist nature.
[01:58:18.360 --> 01:58:26.760]   The only reason you'd spend a million dollars for this is because you think some nitwit's going
[01:58:26.760 --> 01:58:29.320]   to come along and give you a million and a half down the road.
[01:58:29.320 --> 01:58:36.200]   I think it's because the 1% of people have so much money that they could just afford to waste
[01:58:36.200 --> 01:58:41.640]   it on dumb stuff like this. It's pocket change where the rest of us are just looking at it like
[01:58:41.640 --> 01:58:47.160]   they're all nuts. But that's what happens when you have literal billionaires with $20, $30 billion or
[01:58:47.160 --> 01:58:53.880]   more. Like, Alison was going to lend you on Musk a billion dollars for Twitter. It's just like,
[01:58:53.880 --> 01:58:57.320]   it's insane. So I think they're just great people who've run out of things to buy.
[01:58:57.320 --> 01:59:05.160]   I think it was a lot of younger, a lot of younger, 20-something that got caught in this as well.
[01:59:05.160 --> 01:59:09.880]   Like thinking it was a legit way. That's what worries me is more naive and
[01:59:09.880 --> 01:59:17.720]   quote investors like my kids who, oh, this is great. This is the future. And there is this notion.
[01:59:17.720 --> 01:59:24.280]   I've talked about this before that somehow you're restoring equity to the world with Web3,
[01:59:24.280 --> 01:59:32.520]   DeFi, cryptocurrency, NFTs, that somehow you're taking the power away from big tech.
[01:59:33.320 --> 01:59:39.320]   That's the promise of Web3 somehow, some magical way. Except for, I got to point out that the
[01:59:39.320 --> 01:59:43.480]   primary proponents of Web3 are the big venture capitalist entries.
[01:59:43.480 --> 01:59:48.280]   Capitalists. Yeah, we're taking it. We're giving it the big tech.
[01:59:48.280 --> 01:59:56.280]   Not really. But I understand the motivation. When Jay Z started a school
[01:59:57.320 --> 02:00:03.400]   for poor black kids to teach him about crypto, I think he was thinking,
[02:00:03.400 --> 02:00:08.840]   this is a good thing to know because this is democratizing finance.
[02:00:08.840 --> 02:00:15.640]   Spike Lee put out that commercial, right? Where he had the white presidents on the dollar.
[02:00:15.640 --> 02:00:19.960]   And he's like, oh, we've got our new money now. And it was like, oh, I don't know about this,
[02:00:19.960 --> 02:00:26.600]   Spike Lee. But what I wanted to say about this story particularly is we've got real journalists
[02:00:26.600 --> 02:00:34.120]   here, not fictionalists like me. And think about all the rules that exist at CNN to make really
[02:00:34.120 --> 02:00:40.920]   sure that the reporters are not going to malign the reputation of the news network.
[02:00:40.920 --> 02:00:48.680]   Think of all the second guessing when you post on Twitter or the editing an article again and again
[02:00:48.680 --> 02:00:55.080]   or hunting down a source. And then you've got the money men at CNN. They're doing this cheap
[02:00:55.080 --> 02:01:03.240]   cash grab with web three. And think about how much this damages CNN as a news organization and
[02:01:03.240 --> 02:01:08.520]   the trust in it is just so very good point. They made it's estimated by the press Gazette.
[02:01:08.520 --> 02:01:15.720]   They made $300,000 on these T's. In fact, in this analysis from the news Gazette,
[02:01:15.720 --> 02:01:22.520]   with the press Gazette, news publishers have made nearly $12 million on NFT since March 2021.
[02:01:23.400 --> 02:01:32.840]   Yeah, that's really a lot. By the way, the number one money maker, Time magazine.
[02:01:32.840 --> 02:01:42.360]   CNN number three on the list. The key to making money on this stuff is to get in early.
[02:01:42.360 --> 02:01:48.520]   Sell them. Don't hang on to them. Sell them and take the money and run.
[02:01:48.520 --> 02:01:53.240]   Yeah, four made a half a million, but donated it to charity. The economist
[02:01:53.240 --> 02:02:01.400]   $422,000 donated it to charity as did Gannett. The New York Times raised $560,000 on NFTs,
[02:02:01.400 --> 02:02:09.000]   but donated it to charity, I hope, I guess. Time has earned the most from web three initiatives
[02:02:09.000 --> 02:02:15.640]   out of all the publishers. Here's their marketplace in OpenSea. Look at the fine things you can buy.
[02:02:17.240 --> 02:02:24.360]   This is crap. They're selling you crap for thousands of dollars.
[02:02:24.360 --> 02:02:30.680]   It comes in the expense of their credibility. It does. I think lots of them.
[02:02:30.680 --> 02:02:39.080]   And I really feel for any young person or naive person or person who can ill afford this,
[02:02:39.080 --> 02:02:44.040]   who bought into it being on the promise of it's democratizing, it's changing the world.
[02:02:45.640 --> 02:02:52.520]   That's it's not. You just being scammed. It's yet another grift. Welcome to the land of grift.
[02:02:52.520 --> 02:02:59.800]   All right. Well, thank you CNN for shutting it down. Of course, now all the people who bought
[02:02:59.800 --> 02:03:04.120]   those NFTs are pissed off without the marketplace. That's it.
[02:03:04.120 --> 02:03:13.080]   All right. One more break. And then we should talk about whether Apple's going to have an event.
[02:03:13.080 --> 02:03:18.760]   I'm curious what you think. PC shipments, Daniel, have down 20 percent. The steepest drop in more
[02:03:18.760 --> 02:03:24.440]   than 40 years. Not a good quarter for PCs, but Mac sales up 40 percent.
[02:03:24.440 --> 02:03:33.800]   Okay. Thank you. There's an honest response. Which side?
[02:03:33.800 --> 02:03:40.680]   So the problem here is there are actually three sets of numbers. There is IDC,
[02:03:40.680 --> 02:03:44.600]   analysis and Gartner, and they all say vastly different things.
[02:03:44.600 --> 02:03:46.760]   Yeah, because the companies themselves don't say.
[02:03:46.760 --> 02:03:53.000]   Correct. So you have to figure it out. Particularly tough. Yeah, because Apple does direct sales a
[02:03:53.000 --> 02:03:59.800]   lot of times. So IDC says, yeah, they're, Apple sold 10 million or shipped 10 million laptops,
[02:03:59.800 --> 02:04:04.680]   which was up from 7 million. So you got 40 percent growth, which is that's the headline.
[02:04:04.680 --> 02:04:12.040]   Like, oh my God. You go to Gartner, they said only 5.8 million were shipped, which is down from
[02:04:12.040 --> 02:04:18.920]   6.9 million. So it was a 15.6 percent drop. And in between that was Canalis, who said it was 8 million,
[02:04:18.920 --> 02:04:24.440]   and it was a 1.7 percent growth. They have no idea. They're making these numbers up.
[02:04:24.440 --> 02:04:29.720]   Right. And so it's in with the PC numbers are a little bit closer. I mean, I think there's
[02:04:29.720 --> 02:04:35.320]   definitely a trend here, which shouldn't be surprising that in general, laptop sales have dwindled.
[02:04:35.320 --> 02:04:41.160]   And everyone predicted this, right? Because the pandemic was going to be a big expansion of it.
[02:04:41.160 --> 02:04:47.000]   But the numbers are still higher than pre-pandemic, which is the good news.
[02:04:47.000 --> 02:04:52.520]   And now, we're entering into the market has changed. We do have remote workers and a lot
[02:04:52.520 --> 02:04:58.120]   more people are relying on PCs, which means within a couple of years, they're going to probably
[02:04:58.120 --> 02:05:02.360]   have things hold and we don't all return to the office in the old ways. There's going to be a
[02:05:02.360 --> 02:05:08.040]   cycle of companies buying new laptops and getting into that again, which benefits enterprise.
[02:05:08.040 --> 02:05:14.120]   In fact, I think it was, I think, oh yeah, it was Canalis who said desktop was actually up 10 percent.
[02:05:14.120 --> 02:05:18.840]   So desktop sales, apparently, are doing better than laptop sales. So I think the numbers are a little
[02:05:18.840 --> 02:05:24.200]   bit all over the place. But when it comes to the general trends, they're probably all going to be
[02:05:24.200 --> 02:05:29.880]   going down a little bit. I think that's not unheard of, especially we're entering into a possible
[02:05:29.880 --> 02:05:35.960]   recession. There's inflation right now. Every company I know of is pulling back either on advertising
[02:05:35.960 --> 02:05:40.920]   or on purchases because everybody's waiting to see what happens. But they say once the economy,
[02:05:40.920 --> 02:05:46.120]   when it recovers, things will probably return to a better state. But I think we shouldn't make
[02:05:46.120 --> 02:05:51.000]   too much of this where macro headwinds right now aren't very good for laptop sales.
[02:05:51.640 --> 02:05:59.000]   We should also point out that this is a declining growth. So they still sold 68 million PCs in
[02:05:59.000 --> 02:06:04.680]   the last three months. I mean, it's not. It's just that they sold higher than four million before.
[02:06:04.680 --> 02:06:09.640]   So last year, so it's still a huge number. And it's more than before the pandemic.
[02:06:09.640 --> 02:06:18.600]   I mean, 64 million piece or 68 million PCs in three months is a ton of computers. People are
[02:06:18.600 --> 02:06:23.880]   buying computers like crazy. It's just not growing maybe as much as it used to.
[02:06:23.880 --> 02:06:28.280]   I think the consumer market will be hit the hardest here, which I think makes sense.
[02:06:28.280 --> 02:06:31.720]   Whereas enterprise is a little bit more resilient because they know they're going to be around and
[02:06:31.720 --> 02:06:36.280]   they need this equipment. The big question, of course, is does this trend continue in a sense of,
[02:06:36.280 --> 02:06:42.280]   do we still need laptops and PCs and desktop going forward? Yeah, and I don't see that changing.
[02:06:42.280 --> 02:06:47.800]   This idea was years ago, we'd have tablets and phones. We don't need computers anymore.
[02:06:47.800 --> 02:06:52.920]   And now it doesn't seem like the case at all. So yeah, exactly. And a lot of there's a lot of
[02:06:52.920 --> 02:06:57.720]   trends and improvements in these devices that really make them worth it, especially when it
[02:06:57.720 --> 02:07:03.080]   comes to the cameras and being able to work remotely and the power. And of course,
[02:07:03.080 --> 02:07:06.520]   you know, the battery efficiency of them is improving as well. Yeah.
[02:07:06.520 --> 02:07:12.040]   All right. I think that the Apple number there is really interesting. I mean, Apple,
[02:07:12.040 --> 02:07:17.400]   their sales are going to be up because the M1 like laptops and like this entire generation
[02:07:17.400 --> 02:07:22.280]   MacBook is just absolutely amazing. Like everyone that owns them, myself included,
[02:07:22.280 --> 02:07:28.040]   thinks it's the best MacBook they've ever owned. So it's not surprising to me. Mac is doing very
[02:07:28.040 --> 02:07:34.440]   well. I'd love to see PC like come up with a way to deliver that long battery life and performance
[02:07:34.440 --> 02:07:40.760]   and the stuff they they put out because my my razor laptop has a battery that lasts about 40 minutes.
[02:07:40.760 --> 02:07:46.280]   We will talk a little bit about what Apple might be doing in the future, but I want to take a little
[02:07:46.280 --> 02:07:52.040]   break right now. I should mention Daniel, you're right about recession. And we're seeing this also
[02:07:52.040 --> 02:07:59.080]   at Twit where commitments for next year's ad sales have basically fallen off the face of them
[02:07:59.080 --> 02:08:05.560]   of the earth. Because of the economy, people don't know what's going on. A lot of companies are
[02:08:05.560 --> 02:08:10.840]   not necessarily going to stop, but they're just they're just saying, we're putting a hold on it.
[02:08:10.840 --> 02:08:14.520]   Wait and see. We don't know. And you can't Ukraine Russia is also weighing down
[02:08:14.520 --> 02:08:21.400]   absolutely absolutely and the and the coming World War three in China. All of this is not good for
[02:08:21.400 --> 02:08:26.840]   economy. So we're seeing this too. In fact, it's one of the reasons we mentioned more than usual.
[02:08:26.840 --> 02:08:34.280]   We've been mentioning Club Twit because it is for us the key to keeping the operation going,
[02:08:34.280 --> 02:08:37.480]   keeping the lights on, keeping the people we employ employed, keeping the shows going,
[02:08:37.480 --> 02:08:42.120]   keeping the shows growing if we can. So I want to just put in a plug for our club
[02:08:42.120 --> 02:08:46.920]   Twit. If you're not already a member, we just got a new corporate member and we're just really
[02:08:46.920 --> 02:08:55.960]   thrilled and grateful. It is it is a way of, I think supporting us, but also supporting your
[02:08:55.960 --> 02:09:00.760]   employees and supporting your brain. You get ad free versions of all of the shows. We thought
[02:09:00.760 --> 02:09:06.920]   that was the big, you know, pitch. Turns out, no, not even close. The big pitch, the big benefit is
[02:09:06.920 --> 02:09:14.600]   discord. You get access to a very active, very fun discord where people are chatting about not
[02:09:14.600 --> 02:09:18.120]   just the shows as they're going on. We have a, you know, this weekend tech chat going on right
[02:09:18.120 --> 02:09:25.400]   now, just like in our IC, but about everything else. I'm always talking and coding with my friends
[02:09:25.400 --> 02:09:34.840]   about about programming. We've got a beer wine and cocktail group pitching, you know, new concepts
[02:09:34.840 --> 02:09:42.520]   and cocktails. There is a crypto DeFi and NFT group. There's food. There's gaming. There's hardware.
[02:09:42.520 --> 02:09:47.720]   There's ham radio. There's hacking. There's Linux and more. Plus there are shows in the club
[02:09:47.720 --> 02:09:52.040]   that you don't get in public. That's where we launch new shows. That's how this week in space
[02:09:52.040 --> 02:09:58.440]   happened. We got together with Rod Pyle from the National Space Society, Taric Malick from space.com.
[02:09:58.440 --> 02:10:03.880]   They do a great show called this week in space. The club financed its launch, so to speak,
[02:10:03.880 --> 02:10:09.320]   a little cheaper than a Falcon 9. They financed the launch and now that it's off the ground,
[02:10:09.320 --> 02:10:13.640]   we've made it public. But we've got more shows in the club that we haven't yet made public,
[02:10:13.640 --> 02:10:19.640]   like Micah Sargent's Hands on Mac and Paul Therat's Hands on Windows, the untitled Linux show,
[02:10:19.640 --> 02:10:25.080]   Stacey's book club coming up October 27th. These are all shows you get as a club member.
[02:10:25.080 --> 02:10:32.120]   I should mention you can buy individual shows ad-free, including those shows for $2.99 a month,
[02:10:32.120 --> 02:10:36.120]   but why not just spend the $7 get access to the Discord, get the ad-free shows,
[02:10:36.120 --> 02:10:42.600]   get the special Twit Plus feed. I think it's a really worthwhile way to help us.
[02:10:42.600 --> 02:10:50.520]   And I ought to tell you, going forward, we're looking into the abyss of 2023, the club we're
[02:10:50.520 --> 02:10:57.000]   counting on to keep things going in 2023 as it becomes harder and harder to sell advertising.
[02:10:57.000 --> 02:11:04.280]   I don't just think it's the bad economy. I think Spotify, Amazon, Microsoft, iHeart,
[02:11:04.280 --> 02:11:09.080]   they're all Apple, they're all starting to do podcasts and they're starting to do exclusive
[02:11:09.080 --> 02:11:12.920]   podcasts and a lot of the advertising is going to these big companies. So I have a feeling it's
[02:11:12.920 --> 02:11:17.400]   going to get harder and harder for an independent network like Twit to survive without your help.
[02:11:17.400 --> 02:11:20.600]   That's why we started ClubTwit and we appreciate it. Thank you very much.
[02:11:20.600 --> 02:11:27.720]   Twit.tv/clubtwit, just a little self-serving plug, but I really appreciate it. Now, I also
[02:11:27.720 --> 02:11:32.680]   am very grateful for our existing sponsors because they're wonderful and we are very careful. You
[02:11:32.680 --> 02:11:37.400]   might know that we use the products we talk about in almost every case. We are very careful
[02:11:37.400 --> 02:11:44.280]   we pick, for example, Mint Mobile. Sure, I love Ryan Reynolds, but that's not why I use Mint Mobile.
[02:11:44.280 --> 02:11:50.520]   I use Mint Mobile because I get premium wireless starting at $15 a month. Now, what do you pay
[02:11:50.520 --> 02:11:56.920]   for your T-Mobile bill, for instance? Wouldn't it be nice to get the same great 5G service,
[02:11:56.920 --> 02:12:04.760]   unlimited nationwide talk and text, high-speed data on the nation's largest 5G network for $15
[02:12:04.760 --> 02:12:11.480]   a month? And now for the plot twist. There isn't one. Yeah, I know we're all used to these secret,
[02:12:11.480 --> 02:12:19.720]   hidden fees and fine print. There's not seriously Mint Mobile premium wireless starting at $15 a
[02:12:19.720 --> 02:12:25.800]   month. No trapping you into a two-year contract. No hidden fees. You open the bill and go, "What the
[02:12:25.800 --> 02:12:31.560]   heck's this?" There's no luring you in with free subscriptions or streaming services. You'll
[02:12:31.560 --> 02:12:36.280]   forget to cancel and be chill at far and charge full price for. There's none of that. This is clean.
[02:12:36.280 --> 02:12:40.920]   This is simple. This is the right way. For anybody who hates their phone bill, Mint Mobile offers
[02:12:40.920 --> 02:12:45.640]   wireless for just $15 a month. And of course, you should look at your existing bill. See how
[02:12:45.640 --> 02:12:50.840]   much data you need. You get 4GB a month for $15. If you need more, you can get more. They even have
[02:12:50.840 --> 02:12:57.960]   an unlimited plan. But it is the best rate I guarantee you. There's no one comes close. Mint Mobile
[02:12:57.960 --> 02:13:02.760]   gives you the best rate whether you're buying for one or a family. By the way, all plans come with
[02:13:02.760 --> 02:13:07.480]   unlimited talk and text, high-speed data. Use your own phone. If you want, Mint Mobile will send you
[02:13:07.480 --> 02:13:13.080]   a SIM for free. Or you can buy a phone from Mint Mobile. I got a great iPhone SE from them.
[02:13:13.720 --> 02:13:18.040]   $15 a month. Service $15 a month. That's $30 a month for a phone and service.
[02:13:18.040 --> 02:13:24.040]   Still a third what I pay the other guys. Switch to Mint Mobile. Get premium wireless service
[02:13:24.040 --> 02:13:31.160]   just $15 a month. No unexpected plot to us. Mintmobile.com/twit. These guys
[02:13:31.160 --> 02:13:37.400]   are really have now become the disruptors in this space. And I think maybe it's a little bit
[02:13:37.400 --> 02:13:42.200]   thanks to Ryan Reynolds. I feel like he's thrown his little bit of his Deadpool mojo into there.
[02:13:42.200 --> 02:13:49.800]   mintmobile.com/twit. You'll make your wallet happy. Mintmobile.com/twit. Thank you, Mint Mobile for
[02:13:49.800 --> 02:13:55.720]   your support. We had a great week this week on Twit. We've got a little mini video. Why don't you
[02:13:55.720 --> 02:14:02.440]   take a look. I was thinking of getting a Surface Pro 9 with the SQ3. Oh, do not get anything
[02:14:02.440 --> 02:14:10.440]   on base on Windows ever. No. Previously on Twit. Windows Weekly. This is a big day. We got up early
[02:14:10.440 --> 02:14:14.520]   for the Surface event. Each one of these things has a problem. Okay. They all have the same problem.
[02:14:14.520 --> 02:14:21.880]   Which is that they're the same exact design as before. Surface Studio 2 plus 11th Gen Intel
[02:14:21.880 --> 02:14:27.000]   chips not latest gen are you kidding. Quad core. That way Core is just an H series 12th gen
[02:14:27.000 --> 02:14:33.000]   chip set out now. 16. This is something like that. Quad core is like what's in my Synology.
[02:14:33.000 --> 02:14:39.000]   Tech news weekly. You actually have a chance to check out the meta quest Pro.
[02:14:39.720 --> 02:14:45.640]   There is potentially good usefulness here because they have things like say a Microsoft partnership
[02:14:45.640 --> 02:14:52.440]   where you can have virtual screens with Office and meta is just a massive company that has a lot
[02:14:52.440 --> 02:14:57.720]   of resources to throw at this. But hold ends and magically have also been trying to identify
[02:14:57.720 --> 02:15:02.600]   specific companies that need specific things and then tailor their devices toward them.
[02:15:02.600 --> 02:15:07.480]   And the Quest Pro seems much more like they just crammed as much futuristic stuff that they want
[02:15:07.480 --> 02:15:12.440]   in their next headset into this device. And now they hope that it's good for someone.
[02:15:12.440 --> 02:15:19.240]   Today on this week in space we visit Nancy Chibot of the Johns Hopkins Applied Physics Laboratory
[02:15:19.240 --> 02:15:25.560]   to talk about NASA's amazing dark mission. Dart has demonstrated one way to potentially deflect
[02:15:25.560 --> 02:15:29.400]   an asteroid from hitting the Earth in the future if this was needed. This method is called a
[02:15:29.400 --> 02:15:35.000]   kinetic impactor technology which is just a fancy way of saying crashing a spacecraft into an
[02:15:35.000 --> 02:15:40.040]   asteroid and giving it a small nudge. To it making the world safe for technology.
[02:15:40.040 --> 02:15:48.200]   Yeah, Rod told me that on the scale of their expectations for the Dart program
[02:15:48.200 --> 02:15:56.920]   they moved that asteroid right at the extreme end of the best case scenario. It was a huge success.
[02:15:56.920 --> 02:16:01.720]   Which if anybody's worried about an asteroid hitting us given Bruce Willis kind of retiring
[02:16:01.720 --> 02:16:08.040]   I think this is the next next best shot that we have so to speak at saving the world. It was a
[02:16:08.040 --> 02:16:14.440]   really interesting week this week thanks to Microsoft and Meta. Will next week be interesting
[02:16:14.440 --> 02:16:19.240]   thanks to Apple? Seems to be a little bit of a debate over. I think Apple should have an event
[02:16:19.240 --> 02:16:24.680]   if Microsoft could have an event for those things which were you know always interesting.
[02:16:25.880 --> 02:16:31.400]   It was similar to Apple's thing where we're going to take existing designs put more chips better
[02:16:31.400 --> 02:16:36.360]   chips in it that kind of thing. I think it's such a great opportunity to get the attention
[02:16:36.360 --> 02:16:41.080]   of the press get people listening and talking about it. It's a big hour long end why wouldn't you
[02:16:41.080 --> 02:16:47.480]   do it? But they're apparently going to Mark Herman and others in the know probably not going to
[02:16:47.480 --> 02:16:52.760]   have an event they're just going to put out a press release. Yeah I think the only reason
[02:16:52.760 --> 02:16:57.960]   Microsoft actually did an event was because it's its 10th anniversary of service.
[02:16:57.960 --> 02:17:03.480]   So they kind of want to have something there and really the Surface Pro 9 was
[02:17:03.480 --> 02:17:08.520]   the only real star of the show that actually had some interesting things to talk about it.
[02:17:08.520 --> 02:17:13.480]   Laptop 5 was you know purely expected although the bigger news there was they dropped AMD.
[02:17:13.480 --> 02:17:18.120]   But again I think that might also have to do with the fact that they're not anticipating a lot
[02:17:18.120 --> 02:17:21.640]   of laptop sales because of the current economic environment so maybe they just didn't want to
[02:17:21.640 --> 02:17:25.480]   have so much inventory with two chips it just had to make sense this time around.
[02:17:25.480 --> 02:17:32.040]   So I think that's probably why Microsoft actually had the event but I can understand with Apple too
[02:17:32.040 --> 02:17:36.360]   you know if they're just going to put new processors in there and let's be honest that's
[02:17:36.360 --> 02:17:41.080]   usually how Apple does it they do even less change than Microsoft does in its devices.
[02:17:41.080 --> 02:17:47.160]   Right well if you've got a perfect design you don't even get all the coverage anyway
[02:17:47.160 --> 02:17:51.880]   that's a new processor or an event. Yeah you okay the police outside?
[02:17:51.880 --> 02:17:55.880]   What's that you Daniel?
[02:17:55.880 --> 02:18:02.840]   Siren went off. What do you think Brownie you're just singing the praises of the M2 MacBooks?
[02:18:02.840 --> 02:18:10.920]   Well I mean look obviously I'm sorry Daniel I have an Apple fan girl we still be friends but
[02:18:10.920 --> 02:18:17.080]   you know I almost feel like these events have have lost something in the the post-COVID
[02:18:17.080 --> 02:18:22.600]   era just because they're so I mean they're beautifully produced right you've got the drum
[02:18:22.600 --> 02:18:29.400]   cams of everything flying through the air transitioning it's well done but I mean am I the
[02:18:29.400 --> 02:18:35.800]   only one thinks it feels just a little bit artificial? Well no in fact lately I've been saying this
[02:18:35.800 --> 02:18:40.840]   is just an infomercial why are we yeah why are we doing this you know we're just giving them all
[02:18:40.840 --> 02:18:49.640]   this airtime? 100% if they don't have like a really sexy interesting product to bring out I just
[02:18:49.640 --> 02:18:58.440]   I don't think in 2022 like slightly revised Apple Silicon hardware is something worth holding in.
[02:18:58.440 --> 02:19:01.640]   It came from the days when Apple was every time they were doing an event they were
[02:19:01.640 --> 02:19:04.920]   announcing some big breakthrough and you could do that for a while but eventually
[02:19:04.920 --> 02:19:09.160]   it's just going to be incremental improvements maybe next year when they do their
[02:19:09.880 --> 02:19:13.000]   mixed reality headset they'll for sure have a big event around that.
[02:19:13.000 --> 02:19:19.320]   Maybe you know the Apple Silicon Mac Pro might be a reason to do an event.
[02:19:19.320 --> 02:19:23.800]   Well that's what I thought maybe they do. So Apple's quarterly results come out the 27th.
[02:19:23.800 --> 02:19:31.160]   German says between now and then probably on the 24th they'll release iPadOS 16 which has been
[02:19:31.160 --> 02:19:37.560]   held back along with an announcement of new iPads. We're still waiting for the new MacOS
[02:19:37.560 --> 02:19:40.840]   Ventura. We were waiting because we thought well they'll release it with new Macs
[02:19:40.840 --> 02:19:44.840]   and they have promised they had promised a new Mac Pro this year.
[02:19:44.840 --> 02:19:51.000]   Thinking is it probably will announce something and then offer it for sale next year so
[02:19:51.000 --> 02:19:58.680]   we'll find out we'll find out. We passed the opportunity for the 18th we would have had some
[02:19:58.680 --> 02:20:05.800]   news about it before now so now now we're going to look at the 24th of 25th for an Apple event.
[02:20:06.760 --> 02:20:14.200]   All right it's time for the Elon Musk segment. I saved the worst of the best for last depending
[02:20:14.200 --> 02:20:21.800]   on your point of view. The information has seen the new proposal Elon has made to Twitter for
[02:20:21.800 --> 02:20:29.800]   ownership and according to these documents Elon will have absolute control.
[02:20:29.800 --> 02:20:35.320]   He will have sole discretion to decide whether to pursue a sale of the company
[02:20:35.320 --> 02:20:40.760]   and IPO or some other refinancing transaction involving the business. In other words the board
[02:20:40.760 --> 02:20:46.440]   no nothing to say about it. There won't be any shareholders because he's buying the company from
[02:20:46.440 --> 02:20:50.040]   the shareholders so there won't be any shareholders that's how. Well there will be some.
[02:20:50.040 --> 02:20:59.960]   I don't know if the employees will even have shares but certainly his other partners
[02:21:00.520 --> 02:21:06.520]   people like Larry Ellison and Jason Kalkana apparently and Saudi Arabia.
[02:21:06.520 --> 02:21:12.840]   Saudi Arabia is a Saudi sovereign fund. There'll be a bunch of investors but not publicly traded
[02:21:12.840 --> 02:21:18.280]   obviously. He is apparently considering an IPO as put it back in the public market. That's one way
[02:21:18.280 --> 02:21:23.400]   to try to make your $44 billion back. By the way I'm watching Twitter's stock price creep up it's
[02:21:23.400 --> 02:21:30.120]   over $50 now. His offer is for $54.20 as it gets close to that number it just means the stock
[02:21:30.120 --> 02:21:37.000]   market is starting to believe maybe Elon's going to close. Musk will have exclusive authority
[02:21:37.000 --> 02:21:41.720]   to appoint and remove members of the board. See this should send if you're an employee at
[02:21:41.720 --> 02:21:47.480]   Twitter this should send chills up and down your spine. All minority investors have to
[02:21:47.480 --> 02:21:58.120]   agree to vote. He has total control of Tesla. He owns enough of Tesla and SpaceX that
[02:21:59.640 --> 02:22:07.080]   he's got a very compliant board that basically just rubber stamps whatever he wants to do.
[02:22:07.080 --> 02:22:15.320]   He is effectively in total control of all of his enterprises. In years past that would have been
[02:22:15.320 --> 02:22:21.400]   a good thing. When we thought of him as Tony Stark that would have been a good thing.
[02:22:21.400 --> 02:22:24.680]   I never thought of him as Tony Stark.
[02:22:24.680 --> 02:22:31.000]   We've seen his Twitter, Bazaar Twitter tweets. Is he selling a perfume called
[02:22:31.000 --> 02:22:37.320]   burnt hair? Oh god. It's like something that's wild would do. A hundred dollars a bottle.
[02:22:37.320 --> 02:22:42.760]   Yeah but like his audience is so dumb that they bought it all. He made like a million
[02:22:42.760 --> 02:22:48.760]   dollars they said but like it's absurd. Well we have an honest discussion about what this is
[02:22:48.760 --> 02:22:56.920]   going to mean for free speech. A story that came out last week was reported that Elon had a talk
[02:22:56.920 --> 02:23:05.080]   with Vladimir Putin. And Putin. Exactly before coming out with this poll. Basically advocating
[02:23:05.080 --> 02:23:13.640]   hey y'all do you think Ukraine should forfeit the Crimea and also have to supply them with water
[02:23:13.640 --> 02:23:19.480]   literally coming out directly before that he's talking to. Pisser Russian talking points.
[02:23:19.480 --> 02:23:27.880]   That's correct. Then immediately after that they suddenly decide oh well I think we're going to cut
[02:23:27.880 --> 02:23:35.640]   off access in the Crimea with Starlink greatly hampering any efforts to retake that territory.
[02:23:35.640 --> 02:23:42.600]   And now you're talking about Elon Musk being in charge and what I believe and many in the
[02:23:42.600 --> 02:23:48.920]   state department believe is our most weaponizable battlespace when it comes to information warfare.
[02:23:48.920 --> 02:23:57.800]   And I have extreme concerns about all of this. I don't think this sale should go through.
[02:23:57.800 --> 02:24:02.920]   I think for a million different reasons I think it's going to be bad for free speech.
[02:24:02.920 --> 02:24:08.520]   I think it's going to be bad for women and black people and gay people. I think that
[02:24:10.200 --> 02:24:16.920]   I'm worried about national security. And I think if you followed how Elon runs any of his companies
[02:24:16.920 --> 02:24:23.480]   from Tesla to SpaceX it pops in with these crazy ideas but he's not an engineer. It doesn't lead
[02:24:23.480 --> 02:24:28.600]   to a better product. There's a lot of hype but there are very few promises to end up being
[02:24:28.600 --> 02:24:35.800]   delivered on. So my concerns here could not be more serious. Elon after tweeting his
[02:24:37.320 --> 02:24:43.480]   Russian-Ukraine peace plan. They've got the China one too. Yeah same thing.
[02:24:43.480 --> 02:24:50.920]   And he agreed not to sell Starlink service in China which would have been a way to circumvent
[02:24:50.920 --> 02:24:59.800]   the Great Firewall. Interesting. The Chinese said, "Yeah, we don't want Starlink here." Tesla is made in
[02:24:59.800 --> 02:25:07.400]   China. And they sell a lot of cars in China. But the Chinese government owns the land on which the
[02:25:07.400 --> 02:25:15.240]   Shanghai Tesla factory is situated. And the original loan agreement for that, the lease agreement
[02:25:15.240 --> 02:25:24.360]   gives them the right to basically take it back any time they want. So Tesla essentially has to
[02:25:24.360 --> 02:25:29.320]   do whatever the Chinese government wants. And we see this with Apple too. If you want to be in the
[02:25:29.320 --> 02:25:34.600]   Chinese market, you do whatever the Chinese government wants. So really the only question is,
[02:25:34.600 --> 02:25:41.400]   Tesla is just a businessman pretending to be a free speech advocate or is he some sort of
[02:25:41.400 --> 02:25:48.200]   bizarre libertarian? It's kind of hard to figure him out. When he proposed the peace plan on Twitter,
[02:25:48.200 --> 02:25:54.200]   the outgoing Ukrainian ambassador said F off. He said in the most diplomatic way, F off.
[02:25:55.080 --> 02:26:01.720]   Witchy Lunt says, "Hey, you know what? We don't want to pay for those Starlink base stations
[02:26:01.720 --> 02:26:10.760]   in Ukraine." Wrote a letter to the DOD saying, "It's costing us $400 million over the next year.
[02:26:10.760 --> 02:26:17.080]   Could you pay for this?" And then of course, it became- There was additional reporting that came out.
[02:26:17.080 --> 02:26:21.400]   Actually, the Pentagon has been paying for, I believe, 80% of those costs two days.
[02:26:21.400 --> 02:26:30.040]   Anyway, not to mention the massive subsidies he gets for SpaceX and so forth.
[02:26:30.040 --> 02:26:37.000]   He says now- It's the pettiness. Yeah. It's just baby-ish. In a tweet yesterday,
[02:26:37.000 --> 02:26:42.120]   he said, "Okay, the hell with it. Even though Starlink is still losing money and other companies
[02:26:42.120 --> 02:26:46.840]   are getting billions of taxpayers' dollars, we'll just continue to fund the Ukraine government for
[02:26:46.840 --> 02:26:51.400]   free." But you're saying that the DOD is already paying a big chunk of that?
[02:26:51.400 --> 02:27:01.000]   Most of SpaceX's revenue comes from NASA and the DOD. They do some private stuff for other
[02:27:01.000 --> 02:27:06.120]   company satellite launches, but the bulk of their revenue comes from NASA and the Department of Defense.
[02:27:08.520 --> 02:27:14.600]   Elon Musk and Kanye West kind of hand-in-hand.
[02:27:14.600 --> 02:27:21.320]   These billionaires should- I don't know what, go away. Billionaires should not be on Twitter.
[02:27:21.320 --> 02:27:25.400]   They shouldn't be on Twitter, that's for sure. But you know what, away, I said this about Trump,
[02:27:25.400 --> 02:27:31.000]   too. I was glad he was on Twitter because we saw his true self. We see the true Elon Musk.
[02:27:31.000 --> 02:27:34.520]   He doesn't really help, did it? No, it doesn't help, but at least we know.
[02:27:34.520 --> 02:27:42.040]   We don't have that fantasy anymore about who Elon Musk is or Kanye West is. We know the truth is
[02:27:42.040 --> 02:27:48.760]   out there. And so in a way, I don't- I think there's a value to having these people be in public.
[02:27:48.760 --> 02:27:54.920]   If I were their advisor, I'd say, "Shut the hell up." But I know everybody's told Elon to do that
[02:27:54.920 --> 02:28:02.520]   100 times. He ain't never going to do it. He says he talks to Kanye about the anti-whole
[02:28:02.520 --> 02:28:06.280]   anti-semesism thing. It's going to be- he got it. He got it.
[02:28:06.280 --> 02:28:11.720]   Although isn't Kanye on Twitter today with another interview and he's going off?
[02:28:11.720 --> 02:28:17.960]   Oh, the podcast. Oh my God. He's repeating every anti-Semitic trope
[02:28:17.960 --> 02:28:28.440]   from the elders of Zion on down. I mean, it's all complete and utter BS from the manual of anti-Semitism.
[02:28:28.440 --> 02:28:38.440]   He might as well be quoting "mine comp." Nuts. Anyway, you think Elon is just putting on a show and
[02:28:38.440 --> 02:28:47.240]   he's playing 12D chess? No. I think that he's not as much on the right or the left.
[02:28:47.240 --> 02:28:52.360]   No, I don't think he's political. Yeah. I think his text messages that were leaked in this lawsuit
[02:28:52.360 --> 02:29:00.600]   really show he's a billionaire. It's a reality all of its own. With a concern and a, honestly,
[02:29:00.600 --> 02:29:09.960]   like a victim complex that is really interesting considering the amount of power he wields in this
[02:29:09.960 --> 02:29:19.400]   world. Very 12. Yeah. One of the reasons why he does today runs his companies the way he does,
[02:29:20.040 --> 02:29:25.880]   in total control, is he never got over getting pushed out of PayPal.
[02:29:25.880 --> 02:29:35.560]   That was something that from what I've read and people I've talked to has always bothered him,
[02:29:35.560 --> 02:29:40.040]   the way he got pushed out there. This is one of the reasons why he's always
[02:29:40.040 --> 02:29:47.080]   interested in maintaining such a large equity stake in Tesla, in SpaceX in particular,
[02:29:47.640 --> 02:29:54.600]   and then his other ventures. He wants to retain control of everything that he's involved with.
[02:29:54.600 --> 02:30:07.720]   The one exception is at SpaceX where Gwyn shot well, the COO basically runs the business day to day.
[02:30:10.360 --> 02:30:17.720]   Is she an engineer? Or no? Or she's a business member? I don't think she's an engineer.
[02:30:17.720 --> 02:30:24.120]   But she does keep you on a base somewhat. Yeah. But she does a good job of running the company.
[02:30:24.120 --> 02:30:27.880]   Yeah. She knows how to manage the company, which is something that,
[02:30:27.880 --> 02:30:35.400]   all the capabilities that Elon's got, I mean, as a marketer and ideas person,
[02:30:35.960 --> 02:30:45.720]   he's accomplished a lot, but he's a terrible manager. If he was just executive chairman or
[02:30:45.720 --> 02:30:50.360]   something where he was kind of creating, providing the vision for the company and then letting
[02:30:50.360 --> 02:30:56.440]   competent people actually execute on that, I think all of his companies would probably be in a
[02:30:56.440 --> 02:31:05.720]   lot better shape. But he always feels like he needs to retain total control.
[02:31:05.720 --> 02:31:12.200]   And you see that, especially with Tesla over the years, the tweets about sleeping on the
[02:31:12.200 --> 02:31:18.360]   floor of the factory when they were having production problems, that's not something a CEO should be
[02:31:18.360 --> 02:31:25.560]   doing. A good CEO hires the right people to manage those sorts of things and then steps back and
[02:31:25.560 --> 02:31:31.800]   lets them do their job. You don't need one individual that does that, that is going to
[02:31:31.800 --> 02:31:38.520]   be hovering in micromanaging like that. And I think that's the problem you're going to see at
[02:31:38.520 --> 02:31:44.120]   Twitter, if he ultimately takes control of Twitter, is he's going to be micromanaging all kinds of
[02:31:44.120 --> 02:31:49.720]   things. And I think it's just going to turn into a even more of a mess than it always has been.
[02:31:50.920 --> 02:31:57.640]   He wants to turn into WeChat. He says that's the big vision. This one killer app calls X.
[02:31:57.640 --> 02:32:03.640]   Some of the ideas actually come from his time at PayPal speaking of when it comes to commerce,
[02:32:03.640 --> 02:32:08.600]   that he wants to finally build upon and build into Twitter. But yes, it's concept which,
[02:32:08.600 --> 02:32:12.920]   if you remember Skype even tried this years ago with bots and everything, a lot of companies have
[02:32:12.920 --> 02:32:18.920]   tried this idea in Western markets to emulate what has happened in China with building this one
[02:32:18.920 --> 02:32:26.200]   app to rule them all. But really, no one has had that success. And I don't see how this late in the
[02:32:26.200 --> 02:32:30.680]   game, Twitter is going to do that. But that's apparently what he's going to attempt to do with
[02:32:30.680 --> 02:32:35.640]   the service, which it's going to be like almost what Facebook did, where he just kept throwing
[02:32:35.640 --> 02:32:41.480]   stuff in there, hoping that people will start to use it and it'll be profitable at some point.
[02:32:41.480 --> 02:32:46.680]   I'm guessing that Elon knows that that's impossible, that WeChat happened in a climate,
[02:32:46.680 --> 02:32:52.520]   the Chinese government run climate that was very different than anything in the United States.
[02:32:52.520 --> 02:32:57.480]   And he's just saying that because he's trying to keep the investors quiet and happy. And in the
[02:32:57.480 --> 02:33:03.240]   long run, his hope is an IPO. If he can trick everybody into investing in Twitter, we'll get
[02:33:03.240 --> 02:33:09.480]   him out of this because he now knows he's stuck paying the $44 billion. By the way, I'd want to
[02:33:09.480 --> 02:33:16.520]   fully credit Gwen Shotwell. She has a degree, a Bachelor of Science in Mechanical Engineering,
[02:33:16.520 --> 02:33:23.880]   a Master's of Science in Applied Mathematics. She worked at the El Segundo Research Center of
[02:33:23.880 --> 02:33:28.840]   the Aerospace Corporation to technical work on military space research and development.
[02:33:28.840 --> 02:33:35.480]   Contract, she worked on STS 39. In thermal analysis, she worked as Space Systems Engineering and
[02:33:35.480 --> 02:33:43.320]   Project Management positions, joined SpaceX in 2002 and convinced Elon that SpaceX needed a
[02:33:43.320 --> 02:33:50.600]   dedicated employee to work on Biz Dev full-time. And since he's risen to company president,
[02:33:50.600 --> 02:33:56.520]   she is a business person at this point, but with an absolute aerospace background.
[02:33:57.160 --> 02:34:04.040]   So president and COO of SpaceX, probably her number one skill I would guess is strong.
[02:34:04.040 --> 02:34:10.840]   Keep an Elon at bay. Although he likes to tweet about how, yeah, I was just spent all night talking
[02:34:10.840 --> 02:34:18.040]   about how those jets should work on the fucking... I think that's the weird, the myth around him
[02:34:18.040 --> 02:34:23.320]   is so like, when you like, if you go into the responses on Twitter to people who defend him,
[02:34:23.320 --> 02:34:28.120]   which is a whole other weird thing, they all think like he literally
[02:34:28.120 --> 02:34:32.520]   enwends the stuff. He's a science, the rockets. Yeah, yeah, he's an engineer and you're like,
[02:34:32.520 --> 02:34:37.320]   he's one of the biggest inventors ever. Like, he's ever meant that anything. He's told people to
[02:34:37.320 --> 02:34:41.960]   invent things, invested and paid people to do things. Maybe if he's anything right, he's chosen the
[02:34:41.960 --> 02:34:46.280]   right people, choosing shot with the right movement. Which is a skill. That's a skill. Yeah.
[02:34:46.280 --> 02:34:51.880]   I also think something I really appreciate about Elon and this will probably be the only
[02:34:51.880 --> 02:34:57.560]   nice thing I say on this episode today. But I think something I respect about him is he is
[02:34:57.560 --> 02:35:03.800]   presenting an idealistic version of the future that really is straight from a 50s science fiction
[02:35:03.800 --> 02:35:08.120]   novel. Like he's pushing for automated... He's Tom Swift. He's not... Automated. Yeah.
[02:35:08.120 --> 02:35:14.200]   He's pushing for automated androids and we'll do work around the house, self-driving cars, rockets
[02:35:14.200 --> 02:35:20.680]   to go to the moon. You know, like all these things, it really is amazingly pushing for it. I think
[02:35:21.400 --> 02:35:29.880]   that his male, like very male younger supporters, they see that and they feel like they're in on
[02:35:29.880 --> 02:35:35.880]   this story where they can create their own reality. Yeah. And I think you have that there. And then
[02:35:35.880 --> 02:35:42.440]   I think you have the press over here that bought it for like the first five years. But now there's
[02:35:42.440 --> 02:35:49.000]   a lot more skepticism. So when Elon comes out and says like he did at the AI Tesla event, like,
[02:35:49.000 --> 02:35:54.760]   oh well, this robot can't stand up on its own now, but we'll be walking in a week. Well, maybe five
[02:35:54.760 --> 02:36:00.280]   years ago, the press would have believed him on that. Today, I don't think anyone does. And I think
[02:36:00.280 --> 02:36:05.000]   that's why you have these competing realities. Yeah. We've all learned a little bit of a lesson
[02:36:05.000 --> 02:36:12.040]   about hype masters, you know, and maybe we're not quite as credulous as we have been in the past.
[02:36:12.040 --> 02:36:18.520]   I certainly am not. One last story. I don't know about you. I am looking at Netflix thinking,
[02:36:18.520 --> 02:36:24.200]   is this worth $14.99 a month? Netflix knows that's that's kind of the thought everybody's going through
[02:36:24.200 --> 02:36:30.120]   right now. There is nothing on Netflix that is as commanding as some of their previous
[02:36:30.120 --> 02:36:36.440]   efforts like Stranger Things, the Queen's Gambit, the Crown. So they are looking at ad
[02:36:36.440 --> 02:36:45.160]   supported Netflix. They've announced it'll be $6.99 a month launching next month. Netflix
[02:36:45.160 --> 02:36:48.520]   basic will be available in 12 countries. So now you have three choices.
[02:36:48.520 --> 02:36:58.200]   Quit Netflix, keep it at the high price and hope something good comes on or $6.99 a month in watching
[02:36:58.200 --> 02:37:03.320]   ads. Don't forget the 4K tier is even higher. It's like 29. Oh, that's right. That's right.
[02:37:03.320 --> 02:37:09.320]   99. I spent a lot of money on Netflix. Yeah. You know, we were actually getting ready to cancel
[02:37:09.320 --> 02:37:16.280]   Netflix. And then I switched to a different T-Mobile plan that was going to save me some money.
[02:37:16.280 --> 02:37:21.800]   Now that I'm old enough to get the 55 plan. Are you getting the silver plan? Oh, good. Yeah,
[02:37:21.800 --> 02:37:26.840]   it was the 55 plus Max plan from T-Mobile. Can I tell you about me? We get Netflix for free.
[02:37:26.840 --> 02:37:33.720]   No, you don't get Netflix for free. Actually, yeah. Well, I mean, there are actually the reason
[02:37:33.720 --> 02:37:38.600]   why I stuck with T-Mobile because I was actually thinking about switching away is because they offer
[02:37:38.600 --> 02:37:48.600]   a version of the Google One plan that still has unlimited Google Photos original resolution.
[02:37:48.600 --> 02:37:55.800]   For 15 bucks a month, I get two terabytes of storage plus unlimited Google Photos storage on top of that.
[02:37:55.800 --> 02:38:04.200]   Netflix has lost over a million subscribers so far this year. I wonder if you're not alone,
[02:38:05.000 --> 02:38:10.920]   Sam. I think a lot of people are thinking, do I really need to? Well, I mean, we've been doing,
[02:38:10.920 --> 02:38:16.440]   you know, for the last several years, you know, Netflix is Netflix and Amazon Prime
[02:38:16.440 --> 02:38:20.600]   have basically been the only two that have stuck consistently Amazon Prime because,
[02:38:20.600 --> 02:38:25.560]   you know, we use it for shipping and other stuff and Netflix for obvious reasons.
[02:38:25.560 --> 02:38:32.680]   But all the other streaming services, I mean, we quit cable TV six, seven years ago. And all the
[02:38:32.680 --> 02:38:37.240]   other streaming services, we turn them on and off every few months, depending on what we're watching.
[02:38:37.240 --> 02:38:43.640]   So, you know, I just turned off HBO Max for a while and, you know, we'll probably come back to
[02:38:43.640 --> 02:38:49.400]   it at some point. When I have the Dragon comes back. So, actually, I'm after now watching
[02:38:49.400 --> 02:38:57.320]   both, I think the power rings a power really won the, what do you guys think? I like the rings
[02:38:57.320 --> 02:39:00.760]   of power a little bit in the house of the Dragon. I haven't seen it.
[02:39:00.760 --> 02:39:03.560]   I haven't seen it either.
[02:39:03.560 --> 02:39:08.920]   Kind of TV watchers. What kind of couch potatoes are you playing pinball,
[02:39:08.920 --> 02:39:14.360]   driving your boxer around? Come on, sit on the couch watching Bad Sisters on Apple TV.
[02:39:14.360 --> 02:39:17.960]   Oh, that's supposed to be good. Is it good? That's a good, yeah. That's good. That's good too.
[02:39:17.960 --> 02:39:23.960]   Oh my gosh. I really loved that rings of power. It took a while. It started really, really slowly.
[02:39:23.960 --> 02:39:28.840]   But by the last episode, it all gelled, I think. They've been.
[02:39:28.840 --> 02:39:32.680]   Does it have women in it? Because the movies don't. The star is glad.
[02:39:32.680 --> 02:39:37.720]   Oh, okay. She's the hero. In fact, that's one of the things that's interesting about both the
[02:39:37.720 --> 02:39:43.080]   house of the Dragon rings of power. It's about women in most, it really. Okay. Yeah. A little too
[02:39:43.080 --> 02:39:48.920]   much childbirth for me in the house of the Dragon. But let that slide, so to speak.
[02:39:48.920 --> 02:39:52.680]   Brianna, whoa. Thank you. You rock. Yes.
[02:39:52.680 --> 02:39:57.640]   Go host to the. Can I tell a super quick story before we jump off today? Yes.
[02:39:57.640 --> 02:40:02.120]   So I want to tell you all a story about a couple of weeks ago. So I'm sitting there on my phone
[02:40:02.120 --> 02:40:07.400]   in the afternoon. I'm just doing my job and my phone starts blowing up. And they're like,
[02:40:07.400 --> 02:40:13.960]   do you know Alex Jones is talking about you? What? At the Alex Jones trial. And I'm like,
[02:40:13.960 --> 02:40:22.600]   What? What? What's going on? So I go and I turn on core TV and I go back
[02:40:22.600 --> 02:40:30.920]   and I get the clip. Yeah. I see the Alex, the Sandy Hook families have brought up Alex Jones's lawsuit
[02:40:30.920 --> 02:40:36.280]   against me as part of the prosecution of their case. So just to give a little bit of background
[02:40:36.280 --> 02:40:43.080]   on this. You defamed Alex Jones? He said I did. Congratulations.
[02:40:43.080 --> 02:40:50.840]   So the Connecticut Post put out an article talking about the factual events that happened.
[02:40:50.840 --> 02:40:58.200]   This is a reputable local paper talking about how when Alex Jones turned over a bunch of information
[02:40:58.200 --> 02:41:04.200]   for discovery to the Sandy Hook parents, there was a bunch of child porn in that.
[02:41:04.200 --> 02:41:11.880]   So I saw that story and I accurately quote the Connecticut Post. I put none of my own opinion on
[02:41:11.880 --> 02:41:21.240]   that. And I linked to the story below. Very clear. This is reported just as neutral as I could possibly
[02:41:21.240 --> 02:41:29.400]   be. And Alex Jones, his lawyer threatens me on Twitter and goes, I'm going to see you if you don't
[02:41:29.400 --> 02:41:35.880]   take that down. Go and I look at that tweet down. I'm like, there's nothing there. They could possibly
[02:41:35.880 --> 02:41:43.080]   sue me. I'm just quoting, I'm linking to a reputable paper and quoting a story. So he's
[02:41:43.080 --> 02:41:51.880]   sued me. And the lawsuit itself is not a mystery to me why Alex Jones has lost so much in court
[02:41:51.880 --> 02:41:58.600]   because the court case is riddled with typos. It makes sense. He sued the Young Turks as well.
[02:41:59.240 --> 02:42:06.120]   The Young Turks and Andrew, who was a journalist for BuzzFeed at the time. So eventually,
[02:42:06.120 --> 02:42:10.840]   they're just forced to drop the entire suit because it makes absolutely no sense. Right.
[02:42:10.840 --> 02:42:15.480]   Here's where it gets interesting. By the way, did it cost you a penny?
[02:42:15.480 --> 02:42:21.000]   Nothing. I'm a pro bono lawyer that looked at this and said, I would love to represent you.
[02:42:21.000 --> 02:42:26.120]   This is third. And if he kept the case up, we would have brought it to Massachusetts,
[02:42:26.120 --> 02:42:29.720]   where I would have done anti-slap and sued him for triple damages.
[02:42:29.720 --> 02:42:35.160]   Awesome. You had no leg to stand on. So the Sandy Hook families
[02:42:35.160 --> 02:42:43.160]   looked at this and they're going, okay. So in our court case, Alex Jones is saying,
[02:42:43.160 --> 02:42:48.200]   free speech, I need to be able to claim this. Yeah, I need to be able to report on things.
[02:42:48.200 --> 02:42:54.840]   And then they try to, and then they bring up this court case, which the lawyers
[02:42:54.840 --> 02:43:00.680]   work so hard to suppress because they know it destroys their defense because Alex Jones
[02:43:00.680 --> 02:43:08.680]   wants free speech for himself, but for people like me to be able to put my opinion out there,
[02:43:08.680 --> 02:43:16.120]   he tried to shut me down. So obviously, this was a very small variable in a very well-argued
[02:43:16.120 --> 02:43:21.640]   legal case by how to small role to play in that billion dollar judgment against Alex Jones,
[02:43:21.640 --> 02:43:27.240]   which I am very proud of. That's something to celebrate. That is something to celebrate. Wow.
[02:43:27.240 --> 02:43:31.960]   So in what context were you brought up in the current trial, they just mentioned this or?
[02:43:31.960 --> 02:43:37.320]   So there was a whole thing. His lawyers work so hard to try to exclude this. It was a whole
[02:43:37.320 --> 02:43:43.400]   period of questioning where he brings me up and he's like, you see Brianna Wu because of this.
[02:43:43.400 --> 02:43:48.840]   Do you remember her? She was saying stuff on the internet, blah, blah, blah, and then they go
[02:43:48.840 --> 02:43:53.480]   into the free speech argument like, well, don't you see how you're saying one thing for yourself
[02:43:53.480 --> 02:44:01.240]   and another for other people? So unbelievable. One could hope that he'll be bankrupted by the
[02:44:01.240 --> 02:44:09.560]   billion dollar judgment, but one sadly knows he makes far more than that on his little grift.
[02:44:11.640 --> 02:44:16.600]   Brianna Wu, executive director of Rebellion Pack. RebellionPack.com?
[02:44:16.600 --> 02:44:20.600]   Yes, that's it. Help the rebellion. If you want to help us out, join the
[02:44:20.600 --> 02:44:25.400]   rebellion. Best place to go. I helped the rebellion, not join the rebellion that URL is taken.
[02:44:25.400 --> 02:44:32.680]   But you don't have to get a tattoo. That's the good news on this one.
[02:44:32.680 --> 02:44:38.920]   We won't ask you to do that. Help the rebellion. RebellionPack.com, progress in America starts
[02:44:38.920 --> 02:44:44.200]   with you. Awesome. Good job. And of course, listen to Brianna, as I started to say with
[02:44:44.200 --> 02:44:50.120]   Simonda Rush 4 and Christina Warren on her great podcast Rocket, which is bigger and better than
[02:44:50.120 --> 02:44:57.640]   ever at relay.fm. Just wonderful podcast. I just... Great show. I wish I could do a podcast. Half as
[02:44:57.640 --> 02:45:02.920]   good as that. Well, first of all, you do. But there's nothing else out there like Rocket.
[02:45:02.920 --> 02:45:08.760]   There's just so good. Yeah. So well done. Actually, relay's got a lot of good.
[02:45:08.760 --> 02:45:11.720]   Mike does a good job. He's got a lot of good podcasts on that network,
[02:45:11.720 --> 02:45:18.680]   including some from our own friends like Andy and Ico and Florence and material.
[02:45:18.680 --> 02:45:24.920]   And you and Christina, would you help us get ahold of Simone? She doesn't turn our calls.
[02:45:24.920 --> 02:45:28.840]   I want to get her back on the show. I think she's so wonderful.
[02:45:30.280 --> 02:45:33.640]   You should have a week where it's just the three of us. We come on and do
[02:45:33.640 --> 02:45:43.320]   Twitch. We can do a collab. Rocket meets Twitch. I'll talk to you. I like it. Thank you, Daniel
[02:45:43.320 --> 02:45:48.840]   Rubino. Wonderful job. It's not Rubino. Although, we could do it.
[02:45:48.840 --> 02:45:54.120]   It was Rubino, executive editor at Windows Central. I just kind of Latinized your name.
[02:45:54.120 --> 02:45:58.920]   Anything else you want to tell you, do the Windows Central podcast every Friday I know.
[02:46:00.040 --> 02:46:02.040]   What else? Anything else you want to plug?
[02:46:02.040 --> 02:46:08.920]   Oh, well, yeah. I'll just say stay tuned. We got until 13th gen desktop reviews coming out soon.
[02:46:08.920 --> 02:46:13.000]   Surface reviews, I'm sure will be out soon as well.
[02:46:13.000 --> 02:46:20.440]   I have the 12th gen Dell 15 and I like it. People have been kind of badmouthing the 12.
[02:46:20.440 --> 02:46:22.520]   You think the 13 would be better?
[02:46:22.520 --> 02:46:27.320]   So it depends what you value. If you value performance, the 12th and 13th gen,
[02:46:27.320 --> 02:46:31.560]   especially the 13th gen are very powerful processors. I'm running the Core i5 right now and
[02:46:31.560 --> 02:46:38.360]   why I can't reveal any numbers, it's powerful. I'm going to slap it in an i9 a little bit later
[02:46:38.360 --> 02:46:44.360]   to test that one. The problem with them is it comes to laptops, is the efficiency part is not
[02:46:44.360 --> 02:46:47.880]   quite there. They're very much aware of that. But right now, they're tackling power.
[02:46:47.880 --> 02:46:51.800]   Right. I was hoping for extraordinary, better life, but it's fine. It's good.
[02:46:52.360 --> 02:46:59.080]   And I love the idea on the 12th gen that I can run an i5 and get some pretty good
[02:46:59.080 --> 02:47:01.720]   profile. I didn't get an i7 or an i9 because I was worried about throttle.
[02:47:01.720 --> 02:47:02.600]   You don't need it. Yeah.
[02:47:02.600 --> 02:47:08.120]   And I feel like the i5 really is a very nice system. All right. Windows Central, read all about
[02:47:08.120 --> 02:47:16.200]   those reviews coming soon. Thank you, Daniel. And Sam, my friend, he appears every week on the tech
[02:47:16.200 --> 02:47:21.960]   guy show to talk about cars, Guide House Insights is his day job. His podcast, wheel bearings is
[02:47:21.960 --> 02:47:26.760]   available at wheel bearings.media, wherever you find podcasts. Always a pleasure when you're
[02:47:26.760 --> 02:47:33.960]   coming out here to drive a vehicle. Anytime soon. I will be in Palm Springs in a couple of weeks
[02:47:33.960 --> 02:47:41.480]   to drive some BMWs, including the new i7 electric. Such a good job. I'm so jealous.
[02:47:41.480 --> 02:47:50.520]   It's not the worst gig in the world. I'm lucky I get in both in my job as an analyst.
[02:47:51.560 --> 02:47:57.640]   And part time journalist, I get to talk to a lot of really interesting people,
[02:47:57.640 --> 02:48:03.880]   a lot of really smart people. This conference I was at this week on simulation. There's a lot
[02:48:03.880 --> 02:48:10.680]   of fascinating people there. Learned a lot of things. And so I've been in the auto industry
[02:48:10.680 --> 02:48:17.080]   over 30 years now in various roles. And this is, I've been saying for several years now,
[02:48:17.080 --> 02:48:23.720]   and it remains true that this is the most interesting time of my career. There's so many things happening.
[02:48:23.720 --> 02:48:30.200]   I'm always learning new stuff. And I really enjoy what I do. It was a legacy industry
[02:48:30.200 --> 02:48:34.760]   until about 10 years ago. And all of a sudden it's cutting edge, which is fascinating. It's
[02:48:34.760 --> 02:48:40.680]   just really interesting. Yeah. Thank you, Sam. Thank you, Brianna. Thank you. Just one more note.
[02:48:40.680 --> 02:48:45.560]   Yes. You know, I did buy, I bought a new Samsung Galaxy Book II a few months ago.
[02:48:45.560 --> 02:48:51.960]   The 12th gen i7 in it. And I really like it. And you know, it's a fabulous laptop. You know,
[02:48:51.960 --> 02:48:59.320]   it's light, thin, has, you know, great performance, you know, compared to what I had before.
[02:48:59.320 --> 02:49:04.600]   They're so thin. They're so beautiful. Yeah. Yeah. Performance on that laptop is better than
[02:49:04.600 --> 02:49:08.360]   you would think it was. It's one of the best performing laptops for that generation.
[02:49:08.360 --> 02:49:15.960]   And you ever use the pen, though, Amoled screen? Oh, nice. I have the regular Galaxy Book II,
[02:49:15.960 --> 02:49:20.840]   not the Pro. Oh, okay. So it's a sports pen, but I don't, it supports the pen, but I don't have one.
[02:49:20.840 --> 02:49:26.040]   I would never use it. But it's got a beautiful Amoled screen on there. How's the battery
[02:49:26.040 --> 02:49:30.920]   you want? Fantastic. They're claiming 21 hours. Are you getting? Well, I think that's for the new,
[02:49:30.920 --> 02:49:35.560]   that's for the three. Oh, maybe it is. No, Galaxy Book II Pro. This is my, the Pro. Yeah. Yeah.
[02:49:35.560 --> 02:49:40.760]   Oh, yeah. Okay. Oh, yeah. That's the, that's the Pro. I think mine is rated at like, I don't know,
[02:49:40.760 --> 02:49:47.720]   14 or 15 hours. I can get, you know, I've gotten, you know, seven, eight, nine hours,
[02:49:47.720 --> 02:49:51.320]   depending on what I'm doing. If I'm just writing, you know, it'll, it'll run nine hours.
[02:49:51.320 --> 02:49:54.360]   Well, I wish I'd known about this before about the Dell. This looks really nice.
[02:49:54.360 --> 02:49:59.080]   Yeah. I wish I could justify getting a new laptop, but I, I really,
[02:49:59.080 --> 02:50:05.240]   they don't wear out as fast as I wish they would. And I, you know, I don't hate Windows 11.
[02:50:05.800 --> 02:50:12.200]   Yeah. No, I love Windows 11. I don't, I think it's fine. Yeah. Yeah. Nothing wrong with Windows 11.
[02:50:12.200 --> 02:50:19.720]   Thank you, Sam Brietta. Daniel, you guys are great. Thanks to all of you for joining us.
[02:50:19.720 --> 02:50:25.320]   If you want to watch live, we do Twitter every Sunday afternoon, 2 p.m. Pacific, 5 p.m. Eastern,
[02:50:25.320 --> 02:50:32.760]   2100 UTC right after the tech guy show. You can watch us at live.twit.tv. If you're watching live,
[02:50:33.400 --> 02:50:39.480]   chat with us on our IRC. I just found out that IRC turned 34 years old yesterday.
[02:50:39.480 --> 02:50:44.600]   I thought it was older than that, to be honest with you, because we started using IRC just
[02:50:44.600 --> 02:50:53.240]   four years later in 1992. So we've been using IRC for 30 years of those 34 years. That's kind of
[02:50:53.240 --> 02:51:00.280]   amazing. Love that IRC IRC.twit.tv. Of course, you also can chat if you're a club twit member in
[02:51:00.280 --> 02:51:06.440]   our discord. After the fact, you can get shows on demand at twit.tv. There's a YouTube channel
[02:51:06.440 --> 02:51:11.080]   dedicated to this week in tech. In fact, all of our shows have their own YouTube channel,
[02:51:11.080 --> 02:51:15.560]   which is nice. Great way to share a little clips. If you want to do that, YouTube's really good for
[02:51:15.560 --> 02:51:21.640]   that. And of course, the easiest best way to get the show, any of our shows, I would say, is to get
[02:51:21.640 --> 02:51:29.640]   it through a podcast client. Pocketcast is very popular. Apple's podcast, Google podcast,
[02:51:29.640 --> 02:51:35.000]   because then it gets downloaded automatically. We finished cleaning it up, editing it, taking
[02:51:35.000 --> 02:51:43.320]   out the swear words. And if you're a podcast client, as many do allows for reviews, please leave a
[02:51:43.320 --> 02:51:48.280]   five star review. The one disadvantage of being the longest running tech podcast in the world
[02:51:48.280 --> 02:51:56.840]   since 2005, almost 18 years now, is that people forget that you're around. I can't email all the
[02:51:56.840 --> 02:52:04.120]   time said, I thought you were dead. So tell the world Leo's not dead. Twit lives on.
[02:52:04.120 --> 02:52:09.640]   Leave us a good review and maybe somebody will discover it. Thanks for joining us, everybody.
[02:52:09.640 --> 02:52:16.040]   We'll see you next time. Another twit is in the plan. Bye bye.
[02:52:16.040 --> 02:52:17.300]   >> Look amazing.
[02:52:17.300 --> 02:52:20.080]   [MUSIC]
[02:52:20.080 --> 02:52:20.660]   >> Do the Twitter.
[02:52:20.660 --> 02:52:21.300]   >> All right.
[02:52:21.300 --> 02:52:23.460]   >> Do the Twitter, baby.
[02:52:23.460 --> 02:52:24.900]   >> Do you want the Twitter?
[02:52:24.900 --> 02:52:25.180]   >> All right.
[02:52:25.180 --> 02:52:26.540]   >> Do you want the Twitter.

