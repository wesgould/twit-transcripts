;FFMETADATA1
title=This Is Fine
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=644
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:09.000]   It's time for Twit a great big show for you because we've got great big personalities Dwight Silverman makes his return from the Houston Chronicle.
[00:00:09.000 --> 00:00:16.000]   The wonderful serenity Caldwell from iMORA.com and the witty Ian Thompson we're going to talk about Bitcoin.
[00:00:16.000 --> 00:00:24.000]   Why robots are being banned on San Francisco streets have AI artificial intelligence has turned a big corner.
[00:00:24.000 --> 00:00:33.000]   The Woz's reaction to the iPhone 10 and the new emojis and they're on their way it's all coming up next on Twit.
[00:00:33.000 --> 00:00:40.000]   Netcast you love from people you trust.
[00:00:40.000 --> 00:00:45.000]   This is Twit.
[00:00:45.000 --> 00:00:53.000]   Bandwidth for this weekend tech is provided by cash fly at ca ch e f l y dot com.
[00:00:53.000 --> 00:01:04.000]   This is Twit this weekend tech episode 644 recorded Sunday December 10th 2017.
[00:01:04.000 --> 00:01:07.000]   This is fine.
[00:01:07.000 --> 00:01:10.000]   This weekend tech is brought to you by Fracture.
[00:01:10.000 --> 00:01:18.000]   Fracture is a photo decor company that prints your photos directly on the glass and then delivers them to your door ready to display right out of the box.
[00:01:18.000 --> 00:01:25.000]   Visit Fracture dot me and use a code Twit 15 to check out to get 15% off your first order.
[00:01:25.000 --> 00:01:33.000]   And by Tracker a coin size tracking device that pairs with your smartphone and keeps you from losing your most valued possessions.
[00:01:33.000 --> 00:01:38.000]   Visit the tracker.com/twit to save 20% off your order.
[00:01:38.000 --> 00:01:43.000]   And by Captera find software solutions for your business needs.
[00:01:43.000 --> 00:01:51.000]   Captera is a free website with over 500 categories of business software and thousands of ratings and reviews from software users just like you.
[00:01:51.000 --> 00:01:55.000]   Visit Captera dot com/twit today.
[00:01:55.000 --> 00:02:03.000]   And by texture access the world's most popular magazines anytime, anywhere using your smartphone or tablet.
[00:02:03.000 --> 00:02:08.000]   Try it free for 14 days at texture dot com/twit.
[00:02:10.000 --> 00:02:16.000]   It's time for Twit this weekend tech. We're here gathered together once again on a Sunday.
[00:02:16.000 --> 00:02:22.000]   It's kind of tech church in a way with Ian Thompson from the register dot code dot UK.
[00:02:22.000 --> 00:02:27.000]   You're a tech believer. I believe. I believe in what works. Yes.
[00:02:27.000 --> 00:02:32.000]   For a while, Ziff Davis' motto was believe in technology.
[00:02:32.000 --> 00:02:40.000]   I thought that was so hokey that I would at the end of the screensavers, I would say things like believe in technology, but you know, back up your hard drive.
[00:02:40.000 --> 00:02:47.000]   You see, I preferred the mission statement from new scientist, which is science is interesting if you don't agree with that F off.
[00:02:47.000 --> 00:02:49.000]   Is that really?
[00:02:49.000 --> 00:02:52.000]   Darkness dies in science.
[00:02:52.000 --> 00:02:57.000]   That's the remedy called. Well, hey, I haven't seen you in a age. It's so nice to see you again.
[00:02:57.000 --> 00:03:02.000]   Not since you got married. Congratulations. Thank you. Thank you. It's nice to be back.
[00:03:02.000 --> 00:03:08.000]   You're in Montreal playing a roller derby on the Canadian national team.
[00:03:08.000 --> 00:03:14.000]   Yes. I'm in Rhode Island now, but we'll be back there in a few short weeks.
[00:03:14.000 --> 00:03:18.000]   Oh, I can't tell Rhode Island Montreal. It's all snowy now. You've got your first.
[00:03:18.000 --> 00:03:22.000]   It's true. It's true. We've got a I'm very glad that I'm inside right now.
[00:03:22.000 --> 00:03:30.000]   I considered hanging up my lights, but that was a tech step too far. I'd rather talk about tech than do it right now in the cold.
[00:03:30.000 --> 00:03:35.000]   We got a guy here who actually does this for a living. He is a visiting our studio today.
[00:03:35.000 --> 00:03:42.000]   He and his company decorate malls for the holidays, and they did in Cherry Hill, New Jersey.
[00:03:42.000 --> 00:03:49.000]   What's the you'll shoot your eye out the Christmas story? They did a Santa's, you know,
[00:03:49.000 --> 00:03:54.000]   how they dealt Christmas stories over here. That's how I remember it.
[00:03:54.000 --> 00:03:57.000]   The red writer mugged kids her presents and show them.
[00:03:57.000 --> 00:04:00.000]   No, no, no. He does it. They did a Christmas story mall.
[00:04:00.000 --> 00:04:09.000]   And they even have one of the main features of that movie is the leg lamp, the major award, the fredgile major award.
[00:04:09.000 --> 00:04:16.000]   Look, there's a slide. There's Santa. It's the whole house from the movie. Anyway, night.
[00:04:16.000 --> 00:04:20.000]   So if you want some help, Serenity, I'm just saying I got some friends.
[00:04:20.000 --> 00:04:22.000]   You got a guy. I can hook you up.
[00:04:22.000 --> 00:04:27.000]   Also with his, "Hey, my goodness, he's going to make a big deal about Serenity not being here for a long time."
[00:04:27.000 --> 00:04:34.000]   But this is a guy who actually recused himself for a while. He said, "I'm not doing technology anymore. Dwight Selverman is back.
[00:04:34.000 --> 00:04:37.000]   We're so glad to have you back." I'm back. I couldn't stay away.
[00:04:37.000 --> 00:04:40.000]   He tried to get out and they pulled me back.
[00:04:40.000 --> 00:04:45.000]   The Grillmaster from Houston Chronicles Tech Burger section.
[00:04:45.000 --> 00:04:50.000]   So, what happened? You decided you didn't want to write about tech anymore?
[00:04:50.000 --> 00:04:54.000]   They wanted me to do to manage our subscriber website.
[00:04:54.000 --> 00:04:57.000]   And so I did that for a year and a half.
[00:04:57.000 --> 00:05:05.000]   And we decided that, well, actually, there was some research that New York had done that said,
[00:05:05.000 --> 00:05:10.000]   "Surprise people in Houston want more technology coverage."
[00:05:10.000 --> 00:05:15.000]   And so they came to me and said, "You want to do a tech site again?"
[00:05:15.000 --> 00:05:18.000]   And I said, "Yes." Because I really didn't miss it.
[00:05:18.000 --> 00:05:19.000]   I really didn't miss it.
[00:05:19.000 --> 00:05:22.000]   And what's the story with tech, bro? I love it because it's very memorable.
[00:05:22.000 --> 00:05:27.000]   And you've got a giant digital hamburger, Houston Chronicles.com/techburger.
[00:05:27.000 --> 00:05:29.000]   That is great.
[00:05:29.000 --> 00:05:34.000]   So when we were coming up with names, I threw in a bunch of names
[00:05:34.000 --> 00:05:39.000]   that I thought sounded techie like I wanted to call it SCAN or something like that.
[00:05:39.000 --> 00:05:43.000]   And just as kind of as a joke, I had all these serious sounding tech names.
[00:05:43.000 --> 00:05:46.000]   And I threw in tech burger.
[00:05:46.000 --> 00:05:49.000]   And as we were going through kind of eliminating them, my boss kept saying,
[00:05:49.000 --> 00:05:52.000]   "I really like tech burger."
[00:05:52.000 --> 00:05:54.000]   And so we wound up doing it.
[00:05:54.000 --> 00:05:57.000]   And what's nice about it is, first of all, everybody remembers it.
[00:05:57.000 --> 00:06:01.000]   People need to think it's stupid or they start giggling when they hear it.
[00:06:01.000 --> 00:06:04.000]   And it gives us a chance to do some really good puns.
[00:06:04.000 --> 00:06:09.000]   So our daily link post, which I've resurrected and kind of beefed up a bit,
[00:06:09.000 --> 00:06:11.000]   is called "Here's the Beef."
[00:06:11.000 --> 00:06:18.000]   We have the AP feed, which keeps live tech news flowing onto the site.
[00:06:18.000 --> 00:06:21.000]   It's called "extra cheese."
[00:06:21.000 --> 00:06:25.000]   The little short items at the top of the page is called "sliders."
[00:06:25.000 --> 00:06:28.000]   So you don't end up on a pickle, then you're fine.
[00:06:28.000 --> 00:06:31.000]   I'm trying to figure out what to call the condiment section,
[00:06:31.000 --> 00:06:34.000]   what to put in condiments, or fries.
[00:06:34.000 --> 00:06:37.000]   The only thing I don't like about this is making me hungry.
[00:06:37.000 --> 00:06:38.000]   Yes.
[00:06:38.000 --> 00:06:42.000]   So we are -- it's been a lot of fun.
[00:06:42.000 --> 00:06:44.000]   I've been doing a lot more writing.
[00:06:44.000 --> 00:06:48.000]   And also I'm able to play with -- I'm able to use all of our wire services
[00:06:48.000 --> 00:06:51.000]   so I can use Washington Post and Bloomberg and Business Insider
[00:06:51.000 --> 00:06:53.000]   so I can keep the site pretty much up to date.
[00:06:53.000 --> 00:06:57.000]   And it's more issues-oriented as opposed to gadget-oriented,
[00:06:57.000 --> 00:06:59.000]   which is kind of what I was doing before.
[00:06:59.000 --> 00:07:02.000]   And so far the reception has been really good
[00:07:02.000 --> 00:07:04.000]   and we're just going to keep plugging away.
[00:07:04.000 --> 00:07:07.000]   You know, that's actually an interesting distinction,
[00:07:07.000 --> 00:07:11.000]   because I think when a lot of our shows are gadget-oriented,
[00:07:11.000 --> 00:07:14.000]   and product-oriented, and buying-oriented, and helping how-to-oriented.
[00:07:14.000 --> 00:07:17.000]   But I've always been much more interested in the issues of technology.
[00:07:17.000 --> 00:07:20.000]   And so this show has really always been more of an issue show.
[00:07:20.000 --> 00:07:22.000]   Do you find that readers want issues?
[00:07:22.000 --> 00:07:29.000]   Well, I think in 2017, people are much more attuned to things like security
[00:07:29.000 --> 00:07:34.000]   and the fact that technology and social media is having on society.
[00:07:34.000 --> 00:07:37.000]   I think that they're -- you know, people are much more interested in that,
[00:07:37.000 --> 00:07:40.000]   I think than they were, say, two or three years ago.
[00:07:40.000 --> 00:07:43.000]   And because they're acutely aware of what can happen.
[00:07:43.000 --> 00:07:48.000]   And so I'm -- you know, I would much rather be doing that.
[00:07:48.000 --> 00:07:51.000]   I think it serves our purpose better,
[00:07:51.000 --> 00:07:54.000]   and it serves kind of what journalism needs to be doing right now.
[00:07:54.000 --> 00:07:57.000]   So I'm excited to be a part of it.
[00:07:57.000 --> 00:07:59.000]   A lot of big stories this week.
[00:07:59.000 --> 00:08:03.000]   Bitcoin hit $20,000 briefly, and then went back down,
[00:08:03.000 --> 00:08:05.000]   causing a lot of people, including me, to go,
[00:08:05.000 --> 00:08:08.000]   "Where is that Bitcoin wallet I had going around?"
[00:08:08.000 --> 00:08:11.000]   You know, I have people who have been doing that over the last couple of months.
[00:08:11.000 --> 00:08:14.000]   It's just like, "I know I've got some somewhere."
[00:08:14.000 --> 00:08:18.000]   I have, and I'm embarrassed to admit, it's 7.85 Bitcoin,
[00:08:18.000 --> 00:08:20.000]   which at the going rate is almost $100,000.
[00:08:20.000 --> 00:08:23.000]   And I can't unlock the wallet because I forgot the password.
[00:08:23.000 --> 00:08:25.000]   But it's sitting right on my desk door.
[00:08:25.000 --> 00:08:26.000]   Oh, no.
[00:08:26.000 --> 00:08:27.000]   I know.
[00:08:27.000 --> 00:08:28.000]   But I'm not alone.
[00:08:28.000 --> 00:08:32.000]   This is actually -- I think it was estimated about a third of all Bitcoin are held somewhere with --
[00:08:32.000 --> 00:08:35.000]   by somebody who doesn't seem to have any ability to get at it.
[00:08:35.000 --> 00:08:38.000]   Yeah. Well, I mean, there's a huge tranche of the original Bitcoin,
[00:08:38.000 --> 00:08:40.000]   which have never been used.
[00:08:40.000 --> 00:08:42.000]   Well, mostly those are Satoshi's, right?
[00:08:42.000 --> 00:08:45.000]   Yeah. But then now the quest is on for who is Satoshi,
[00:08:45.000 --> 00:08:49.000]   and I thought I'd tracked down who it was a couple more years ago.
[00:08:49.000 --> 00:08:54.000]   And -- You join a, by the way, a rich panoply of tech journalists all who --
[00:08:54.000 --> 00:08:56.000]   Oh, yeah. We've all aimed to a fast --
[00:08:56.000 --> 00:08:59.000]   Even though I've got finger for being Satoshi only this week,
[00:08:59.000 --> 00:09:01.000]   and it was like, "Yeah, forget it. That's not going to happen."
[00:09:01.000 --> 00:09:03.000]   So who do you think Satoshi Nakamura?
[00:09:03.000 --> 00:09:06.000]   Well, I don't want to say his name because, basically, this guy has come up in the past.
[00:09:06.000 --> 00:09:10.000]   His family have received -- have been on the brunt of a bunch of hacking attacks.
[00:09:10.000 --> 00:09:11.000]   But it looked good.
[00:09:11.000 --> 00:09:15.000]   So I spoke to some people who knew him. He's unfortunately passed on now.
[00:09:15.000 --> 00:09:18.000]   And that makes sense because he has billions.
[00:09:18.000 --> 00:09:20.000]   Yeah. And he has not touched it.
[00:09:20.000 --> 00:09:24.000]   This is someone who I've known and trusted for over a decade.
[00:09:24.000 --> 00:09:29.000]   And he was like, "Look, I've worked with this guy. I know we've talked about it.
[00:09:29.000 --> 00:09:33.000]   He's denied it to my face. And the evidence just doesn't stack up."
[00:09:33.000 --> 00:09:37.000]   So everyone's looking for this guy. And it's probably, I think, deep down,
[00:09:37.000 --> 00:09:39.000]   it's probably two or three people.
[00:09:39.000 --> 00:09:42.000]   And there's a whole bunch of Bitcoin that are just missing somewhere.
[00:09:42.000 --> 00:09:46.000]   And even in the original paper, they use the pronoun "we."
[00:09:46.000 --> 00:09:48.000]   Yeah. I think it's definitely a group.
[00:09:48.000 --> 00:09:51.000]   It means it sounds to me like it was a group.
[00:09:51.000 --> 00:09:55.000]   They weren't even trying to hide it, but they just use a single pseudonym to represent themselves.
[00:09:55.000 --> 00:10:01.000]   Yeah. But they -- as with any pyramid scheme -- and you could make a case that Bitcoin is just another pyramid case for that.
[00:10:01.000 --> 00:10:05.000]   As with any pyramid scheme, the person who starts it is the one who makes all the money.
[00:10:05.000 --> 00:10:08.000]   And they own billions of dollars in Bitcoin.
[00:10:08.000 --> 00:10:11.000]   But we would know the minute they moved it, we would know.
[00:10:11.000 --> 00:10:14.000]   Because people know which bitcoins are Satoshi's.
[00:10:14.000 --> 00:10:17.000]   And they seem to have no inkling.
[00:10:17.000 --> 00:10:20.000]   And I would think now, if ever.
[00:10:20.000 --> 00:10:22.000]   Now would be the time to get on.
[00:10:22.000 --> 00:10:26.000]   Unless I'm completely wrong. I mean, there are a lot of people -- well, like the Winklevoss twins.
[00:10:26.000 --> 00:10:32.000]   Look at these guys. So they are the famous Harvard crew twins.
[00:10:32.000 --> 00:10:35.000]   You saw them in the Facebook movie, "The Social Network."
[00:10:35.000 --> 00:10:38.000]   And I don't know how accurate that movie was.
[00:10:38.000 --> 00:10:42.000]   But I think there was some accuracy to the idea that they had, as Harvard seniors,
[00:10:42.000 --> 00:10:49.000]   commissioned a Harvard freshman named Mark Zuckerberg to write some software for them for a social network they had in mind.
[00:10:49.000 --> 00:10:55.000]   Mark coasted on them, disappeared, ended up the next time they saw them releasing something called the Facebook.
[00:10:55.000 --> 00:10:58.000]   And the rest is history. They sued him.
[00:10:58.000 --> 00:11:01.000]   And now we never knew what the settlement was.
[00:11:01.000 --> 00:11:07.000]   But this week I saw a story saying they parlayed the $11 million settlement, which would make sense.
[00:11:07.000 --> 00:11:10.000]   Not huge, but something into Bitcoin billions.
[00:11:10.000 --> 00:11:15.000]   They went all in a Bitcoin and they're now -- and they're still just as handsome.
[00:11:15.000 --> 00:11:18.000]   Bitcoin. And they still match perfectly.
[00:11:18.000 --> 00:11:21.000]   Matching bookends. Bitcoin.
[00:11:21.000 --> 00:11:22.000]   Oh, my dear.
[00:11:22.000 --> 00:11:24.000]   The Winklevoss.
[00:11:24.000 --> 00:11:25.000]   The Winklevoss.
[00:11:25.000 --> 00:11:30.000]   Yeah. I mean, they insist they haven't sold any Bitcoin yet and they were still quite getting exchange going.
[00:11:30.000 --> 00:11:37.000]   But, you know, we saw with the exchange this week earlier on that, you know, transmission times are going way down.
[00:11:37.000 --> 00:11:39.000]   Exchange costs really.
[00:11:39.000 --> 00:11:41.000]   They're getting slower.
[00:11:41.000 --> 00:11:42.000]   Well, yeah, they're getting slower.
[00:11:42.000 --> 00:11:45.000]   It will take as much as 20 hours or something to do a transaction.
[00:11:45.000 --> 00:11:49.000]   And you got steam refusing to take Bitcoin this week because it's too volatile.
[00:11:49.000 --> 00:11:50.000]   Yeah. It is too volatile.
[00:11:50.000 --> 00:11:54.000]   And even some drug dealers on the darknet complaining that, you know, they will have it to get out of it.
[00:11:54.000 --> 00:11:56.000]   And my heart bleeds full, though.
[00:11:56.000 --> 00:11:57.000]   Right.
[00:11:57.000 --> 00:12:01.000]   And then you can't pay me a Bitcoin anymore, man. It's too volatile.
[00:12:01.000 --> 00:12:05.000]   And then Mondeo is now, you know, every --
[00:12:05.000 --> 00:12:06.000]   Monero or -- sorry, Monero.
[00:12:06.000 --> 00:12:07.000]   Monero.
[00:12:07.000 --> 00:12:09.000]   That's the one that people are using.
[00:12:09.000 --> 00:12:10.000]   The coin hive.
[00:12:10.000 --> 00:12:11.000]   Coin hive.
[00:12:11.000 --> 00:12:14.000]   And others are using to take over your browser.
[00:12:14.000 --> 00:12:17.000]   When you visit websites, you actually start running on mining.
[00:12:17.000 --> 00:12:20.000]   Yeah. You contribute your spare CPU cycles to them.
[00:12:20.000 --> 00:12:23.000]   And to be fair, Coin hive has said, we're not developing that software anymore.
[00:12:23.000 --> 00:12:29.000]   We're now developing a new bit of software which does the same, but insists that you get user, you know, consent before you do it.
[00:12:29.000 --> 00:12:34.000]   The problem with Coin hive, and by the way, I'm glad to say I am blocked from Coin hive by my UBlock origin.
[00:12:34.000 --> 00:12:35.000]   Yep.
[00:12:35.000 --> 00:12:36.000]   Which is as it should be.
[00:12:36.000 --> 00:12:40.000]   The problem with Coin hive, it's software been weaponized.
[00:12:40.000 --> 00:12:41.000]   This is a security issue.
[00:12:41.000 --> 00:12:47.000]   And instead of, you know, I think you can make the case, while you're reading a site, it uses a few spare CPU cycles.
[00:12:47.000 --> 00:12:48.000]   Yeah.
[00:12:48.000 --> 00:12:52.000]   If a coin drops out, well, then that's our monetization strategy.
[00:12:52.000 --> 00:12:54.000]   I agree. You need to tell people you're doing that.
[00:12:54.000 --> 00:12:57.000]   But I think that's kind of no harm, no foul.
[00:12:57.000 --> 00:13:04.000]   But they had been modified to continue to run after you closed your browser, just sit on your system and run all the time in the background.
[00:13:04.000 --> 00:13:05.000]   And that is not okay.
[00:13:05.000 --> 00:13:06.000]   No.
[00:13:06.000 --> 00:13:07.000]   No, that's disgusting behavior.
[00:13:07.000 --> 00:13:11.000]   It's also getting on mobiles and that burns through battery power like nothing else.
[00:13:11.000 --> 00:13:15.000]   If you feel your mobile getting halted, it might be worth checking out on that one.
[00:13:15.000 --> 00:13:20.000]   Well, you should probably be running a blocker like UBlock origin on those kinds of...
[00:13:20.000 --> 00:13:25.000]   A lot of the antivirus and a lot of the app blocking people are now getting wise to this thing goodness.
[00:13:25.000 --> 00:13:26.000]   Yeah.
[00:13:26.000 --> 00:13:27.000]   Because it is a virus.
[00:13:27.000 --> 00:13:29.000]   Although, am I wrong?
[00:13:29.000 --> 00:13:30.000]   What do you think, Serenity?
[00:13:30.000 --> 00:13:34.000]   I mean, the idea that I'm more, for instance, I mean, the way you...
[00:13:34.000 --> 00:13:35.000]   That's an expensive site.
[00:13:35.000 --> 00:13:36.000]   You got to make money.
[00:13:36.000 --> 00:13:38.000]   The only way you make money is with banner ads.
[00:13:38.000 --> 00:13:40.000]   Or it's, I guess it's the primary way.
[00:13:40.000 --> 00:13:43.000]   I can't say it's the only way, but you make money on banner ads.
[00:13:43.000 --> 00:13:50.000]   What would it take for somebody like Mobile Nations to say, "Well, maybe we should just do this, babe."
[00:13:50.000 --> 00:13:53.000]   Say, "Hey, would you mind if we used while you're sitting on the site?"
[00:13:53.000 --> 00:13:57.000]   Just did a little JavaScript of mine Bitcoin, but people just say, "No, that's not going to happen."
[00:13:57.000 --> 00:14:00.000]   Yeah, I mean, I think the asking is the first step, right?
[00:14:00.000 --> 00:14:07.000]   It's saying, "Hey, we are actually going to do this, so is it cool with you guys if we use your CPU cycles?"
[00:14:07.000 --> 00:14:14.000]   But honestly, to me, it comes back to the problem that we've had with intrusive banner ads from the very beginning,
[00:14:14.000 --> 00:14:17.000]   which is that no one wants to visit a site that's slow.
[00:14:17.000 --> 00:14:22.000]   And if I'm going to be using spare CPU cycles of yours to mine Bitcoins,
[00:14:22.000 --> 00:14:25.000]   I am inherently going to make your web experience slow.
[00:14:25.000 --> 00:14:29.000]   And you're either going to use something like AMP, or you're going to use reading list
[00:14:29.000 --> 00:14:34.000]   or one of the numerous other ways that you can use to read our content without running into that,
[00:14:34.000 --> 00:14:37.000]   because again, you want the faster experience.
[00:14:37.000 --> 00:14:43.000]   So I really can't see any way in which this would be a profitable solution for people.
[00:14:43.000 --> 00:14:49.000]   It would just end up, like even if everybody was totally fine with the prospect of,
[00:14:49.000 --> 00:14:52.000]   "Oh, yeah, you can use my computer to mine Bitcoins."
[00:14:52.000 --> 00:14:58.000]   I still feel like they're just not going to be okay with it from a slowness standpoint.
[00:14:58.000 --> 00:14:59.000]   Yeah, but okay.
[00:14:59.000 --> 00:15:01.000]   Who would have voluntarily checked that box?
[00:15:01.000 --> 00:15:03.000]   But here I am on Bloomberg site and seen it.
[00:15:03.000 --> 00:15:04.000]   There's a lot of sites to it.
[00:15:04.000 --> 00:15:09.000]   And live television, live video starts loading, probably using more bandwidth.
[00:15:09.000 --> 00:15:14.000]   And I'm certainly using more bandwidth and probably using CPU cycles.
[00:15:14.000 --> 00:15:15.000]   Yeah.
[00:15:15.000 --> 00:15:16.000]   Then a little Bitcoin miner.
[00:15:16.000 --> 00:15:18.000]   That's really annoying.
[00:15:18.000 --> 00:15:20.000]   We kind of accept that.
[00:15:20.000 --> 00:15:24.000]   I would like to turn it off, but my ad blocker won't.
[00:15:24.000 --> 00:15:26.000]   I mean, I think this is a problem.
[00:15:26.000 --> 00:15:33.000]   I mean, everybody acknowledges we need to monetize these free Internet services.
[00:15:33.000 --> 00:15:34.000]   They're really great.
[00:15:34.000 --> 00:15:35.000]   There needs to be a way to monetize.
[00:15:35.000 --> 00:15:36.000]   Absolutely.
[00:15:36.000 --> 00:15:38.000]   I feel like if there were some, the problem is you're right.
[00:15:38.000 --> 00:15:40.000]   Everybody would just say, "No, no, you can't.
[00:15:40.000 --> 00:15:42.000]   No, that's why they don't tell you."
[00:15:42.000 --> 00:15:43.000]   Because you'd say, "No."
[00:15:43.000 --> 00:15:47.000]   Unless there was some incentive to come back to you, if it was shared in Bitcoin,
[00:15:47.000 --> 00:15:49.000]   Bitcoin, mining, where you might get something, you know,
[00:15:49.000 --> 00:15:51.000]   that might be worth it.
[00:15:51.000 --> 00:15:56.000]   But just the whole idea of asking somebody, "Hey, can I use your computer to make some
[00:15:56.000 --> 00:15:58.000]   money for me?"
[00:15:58.000 --> 00:16:00.000]   That's just too creepy.
[00:16:00.000 --> 00:16:03.000]   And I think most people, even if they were incentivized to say that it will give you
[00:16:03.000 --> 00:16:07.000]   a little bit, would ultimately people would just say no.
[00:16:07.000 --> 00:16:08.000]   Yeah.
[00:16:08.000 --> 00:16:09.000]   I don't know.
[00:16:09.000 --> 00:16:13.000]   We saw with Setti at home that people are actually willing to lend out their spare CPU
[00:16:13.000 --> 00:16:14.000]   cycles when they're saying that's...
[00:16:14.000 --> 00:16:15.000]   Yeah, but they're searching for alien life.
[00:16:15.000 --> 00:16:16.000]   That's cool.
[00:16:16.000 --> 00:16:17.000]   Yeah.
[00:16:17.000 --> 00:16:18.000]   The principle is a little different.
[00:16:18.000 --> 00:16:19.000]   It's the benefit to them.
[00:16:19.000 --> 00:16:20.000]   Yeah.
[00:16:20.000 --> 00:16:21.000]   What's the benefit?
[00:16:21.000 --> 00:16:22.000]   I don't think we should find aliens.
[00:16:22.000 --> 00:16:25.000]   If they're out there, leave them alone.
[00:16:25.000 --> 00:16:26.000]   Don't you?
[00:16:26.000 --> 00:16:28.000]   I mean, everybody says, "Oh, we're all worried about our official intelligence."
[00:16:28.000 --> 00:16:29.000]   Screw that.
[00:16:29.000 --> 00:16:31.000]   What about the aliens?
[00:16:31.000 --> 00:16:33.000]   Yeah, Ian Banks, the science fiction author,
[00:16:33.000 --> 00:16:36.000]   calls us the outside context problem, whereby you know...
[00:16:36.000 --> 00:16:38.000]   They have nothing to do with us.
[00:16:38.000 --> 00:16:42.000]   You're getting your civilization around and then all of a sudden these people turn up
[00:16:42.000 --> 00:16:45.000]   with sticks that have gunpowder in them and ships would go against the wind.
[00:16:45.000 --> 00:16:46.000]   Right.
[00:16:46.000 --> 00:16:47.000]   Right.
[00:16:47.000 --> 00:16:51.000]   So, yeah, let's not encourage whatever it is they have.
[00:16:51.000 --> 00:16:53.000]   Whatever sticks they're bearing.
[00:16:53.000 --> 00:16:57.000]   Actually, the worst fear is that actually aliens have come checked over earth and gone.
[00:16:57.000 --> 00:16:59.000]   These people are ridiculously primitive.
[00:16:59.000 --> 00:17:00.000]   We'll come back in 10,000 years.
[00:17:00.000 --> 00:17:04.000]   I've interviewed the ASEAN home people many, many times in Seth Shostak at ASEAN.
[00:17:04.000 --> 00:17:05.000]   I think it's...
[00:17:05.000 --> 00:17:06.000]   I just don't.
[00:17:06.000 --> 00:17:07.000]   I think it's not...
[00:17:07.000 --> 00:17:08.000]   I don't.
[00:17:08.000 --> 00:17:09.000]   There's...
[00:17:09.000 --> 00:17:10.000]   We're not...
[00:17:10.000 --> 00:17:11.000]   There's not gonna...
[00:17:11.000 --> 00:17:13.000]   There has to be other life out there in an infinite universe.
[00:17:13.000 --> 00:17:15.000]   Yes, but it's very, very, very, very, very...
[00:17:15.000 --> 00:17:17.000]   Can I say that a hundred thousand more times?
[00:17:17.000 --> 00:17:18.000]   Far away.
[00:17:18.000 --> 00:17:22.000]   And it's so far away there's no practical means of getting here.
[00:17:22.000 --> 00:17:25.000]   You have to imagine faster than light travel.
[00:17:25.000 --> 00:17:28.000]   As Douglas has put it, space is very, very big.
[00:17:28.000 --> 00:17:29.000]   Yes.
[00:17:29.000 --> 00:17:30.000]   So big.
[00:17:30.000 --> 00:17:31.000]   So fast.
[00:17:31.000 --> 00:17:33.000]   That even a trip down to the shops that seems like a long way.
[00:17:33.000 --> 00:17:34.000]   Sorry.
[00:17:34.000 --> 00:17:35.000]   I could quite hitchhiker's guide forever.
[00:17:35.000 --> 00:17:36.000]   Please.
[00:17:36.000 --> 00:17:37.000]   I'm with the show.
[00:17:37.000 --> 00:17:39.000]   That's the entire show.
[00:17:39.000 --> 00:17:41.000]   This man is a fruit.
[00:17:41.000 --> 00:17:51.000]   Bitcoin whales, it is estimated a thousand people, mostly Chinese miners, own 40% of the market.
[00:17:51.000 --> 00:17:58.000]   That makes me nervous because Bitcoin is not regulated in the same way that say stocks are regulated.
[00:17:58.000 --> 00:18:02.000]   And it isn't illegal, as far as I know, to collude.
[00:18:02.000 --> 00:18:05.000]   These guys could get together and pump and dump.
[00:18:05.000 --> 00:18:07.000]   These guys could do all sorts of things.
[00:18:07.000 --> 00:18:10.000]   For all we know they are pumping and dumping.
[00:18:10.000 --> 00:18:13.000]   It hit 20,000 and is now down to 15,000.
[00:18:13.000 --> 00:18:14.000]   That's a little fit taking.
[00:18:14.000 --> 00:18:15.000]   Yeah.
[00:18:15.000 --> 00:18:16.000]   Yeah.
[00:18:16.000 --> 00:18:19.000]   I should probably explain what pumping and dumping means.
[00:18:19.000 --> 00:18:22.000]   You have many connotations.
[00:18:22.000 --> 00:18:27.840]   So these, and then of course the big Bitcoin miners are mostly in China because you need to have very cheap
[00:18:27.840 --> 00:18:31.000]   power now to do that or free power.
[00:18:31.000 --> 00:18:38.000]   And probably I'm going to make a little leap of logic here, but we know these Bitcoin miners are near big hydroelectric
[00:18:38.000 --> 00:18:39.000]   dams.
[00:18:39.000 --> 00:18:42.000]   And I'm guessing probably an arm of the Chinese military or government.
[00:18:42.000 --> 00:18:44.000]   What isn't over there, to be honest.
[00:18:44.000 --> 00:18:48.000]   So do you really want the Chinese government to control this market?
[00:18:48.000 --> 00:18:50.000]   And I mean, just me.
[00:18:50.000 --> 00:18:51.000]   I don't know.
[00:18:51.000 --> 00:18:53.000]   As I said, it's fascinating.
[00:18:53.000 --> 00:18:58.000]   Well, it's huge in China because it provides a very good way to get around currency regulations.
[00:18:58.000 --> 00:18:59.000]   It's decentralized.
[00:18:59.000 --> 00:19:00.000]   Yeah.
[00:19:00.000 --> 00:19:02.000]   But it allows them to get around currency export.
[00:19:02.000 --> 00:19:03.000]   It's anonymous, it's decentralized.
[00:19:03.000 --> 00:19:05.000]   So you can stick it out there.
[00:19:05.000 --> 00:19:07.000]   You can get your money out, invest in companies.
[00:19:07.000 --> 00:19:08.720]   And the IRS wants to regulate.
[00:19:08.720 --> 00:19:09.720]   They want to charge tax.
[00:19:09.720 --> 00:19:14.000]   If I were to find the password of my Bitcoin wallet, I would be expected to report it as
[00:19:14.000 --> 00:19:16.440]   income and pay tax on it.
[00:19:16.440 --> 00:19:19.000]   But that doesn't mean you have to mean that means you can't get away.
[00:19:19.000 --> 00:19:22.280]   What are they supposed to just impose rules this week saying that it would should be a
[00:19:22.280 --> 00:19:24.000]   crime to conceal your Bitcoin.
[00:19:24.000 --> 00:19:25.000]   It is.
[00:19:25.000 --> 00:19:26.560]   But isn't yet though, right?
[00:19:26.560 --> 00:19:29.400]   As far as I know, not, but you are liable for tax on any capital.
[00:19:29.400 --> 00:19:32.600]   It's always a crime not to report income.
[00:19:32.600 --> 00:19:35.000]   That's how they get around it.
[00:19:35.000 --> 00:19:36.880]   I mean, that's how they got Al Capone.
[00:19:36.880 --> 00:19:38.040]   He was a tax vote.
[00:19:38.040 --> 00:19:40.680]   He got an income tax evasion and he went to Alcatraz.
[00:19:40.680 --> 00:19:43.440]   He couldn't get him on anything else.
[00:19:43.440 --> 00:19:46.440]   This is a story from tech burger.
[00:19:46.440 --> 00:19:48.840]   San Francisco to robots.
[00:19:48.840 --> 00:19:51.040]   Don't crowd our sidewalks, man.
[00:19:51.040 --> 00:19:56.480]   Apparently, we actually interviewed one of these robots that delivers food.
[00:19:56.480 --> 00:19:59.240]   We had one that stays within the hotel.
[00:19:59.240 --> 00:20:05.840]   But here's a Starship robot that sits outside Orson's belly cafe in the Richmond as it
[00:20:05.840 --> 00:20:07.000]   prepares to make a delivery.
[00:20:07.000 --> 00:20:08.600]   This was last year.
[00:20:08.600 --> 00:20:13.640]   But San Francisco, the board of supervisors, which runs the city there, unanimously pass
[00:20:13.640 --> 00:20:21.240]   laws that limit companies to three robots each, limit the city to nine robots total.
[00:20:21.240 --> 00:20:22.560]   What?
[00:20:22.560 --> 00:20:25.080]   And confine them in industrial areas where no one lives.
[00:20:25.080 --> 00:20:26.920]   Well, that effectively kills the industry.
[00:20:26.920 --> 00:20:27.920]   So much for that.
[00:20:27.920 --> 00:20:28.920]   That's right.
[00:20:28.920 --> 00:20:34.560]   Well, it makes sense to regulate it because if you had everybody and his mother with their
[00:20:34.560 --> 00:20:37.280]   own delivery robot, she'd be tripping all over them.
[00:20:37.280 --> 00:20:40.920]   You'd end up creating lanes for them.
[00:20:40.920 --> 00:20:45.280]   And I think that to do what they did, to do what San Francisco did, yeah, it's just kind
[00:20:45.280 --> 00:20:48.560]   of like putting the stake in the heart too early in that business.
[00:20:48.560 --> 00:20:50.040]   It's in a way kind of a shame.
[00:20:50.040 --> 00:20:54.400]   I think this would be a natural place for this, especially because San Francisco is so
[00:20:54.400 --> 00:20:55.400]   so hilly.
[00:20:55.400 --> 00:20:56.720]   Put them in bike lanes.
[00:20:56.720 --> 00:21:00.360]   You know, take them off the pavement, put them in bike lanes seems to be a perfectly
[00:21:00.360 --> 00:21:01.360]   reasonable solution.
[00:21:01.360 --> 00:21:03.080]   We've got a slightly worse out.
[00:21:03.080 --> 00:21:05.080]   Like lanes in San Francisco.
[00:21:05.080 --> 00:21:07.800]   Oh, yeah, we need a hell of a lot more bike lanes in San Francisco.
[00:21:07.800 --> 00:21:11.600]   But also the bike riders in SF take zero trouble from anyone.
[00:21:11.600 --> 00:21:15.760]   And if one of these robots gives it hassle, it get booted into the car quickly.
[00:21:15.760 --> 00:21:16.760]   That's what we mean.
[00:21:16.760 --> 00:21:19.200]   What is that the last Friday of the month that do critical mass.
[00:21:19.200 --> 00:21:20.200]   Yeah.
[00:21:20.200 --> 00:21:23.080]   Francisco, all the bicycle riders drive this cars off the street.
[00:21:23.080 --> 00:21:26.560]   We need critical mass delivery robots in San Francisco.
[00:21:26.560 --> 00:21:29.400]   And I could leave to the backlash fairly quickly.
[00:21:29.400 --> 00:21:32.800]   But yeah, that just makes my heart sing a little bit.
[00:21:32.800 --> 00:21:33.800]   I want that.
[00:21:33.800 --> 00:21:35.920]   I want the thousands of little robots.
[00:21:35.920 --> 00:21:36.920]   Oh, I know.
[00:21:36.920 --> 00:21:40.080]   Going down big like, here is your food.
[00:21:40.080 --> 00:21:41.080]   We are sorry.
[00:21:41.080 --> 00:21:43.080]   We have the convenience.
[00:21:43.080 --> 00:21:44.080]   Yes.
[00:21:44.080 --> 00:21:45.080]   Moo.
[00:21:45.080 --> 00:21:49.360]   I mean, what with this and the airlines banning smart luggage is as well.
[00:21:49.360 --> 00:21:50.360]   Do you heard about this?
[00:21:50.360 --> 00:21:51.360]   Yes.
[00:21:51.360 --> 00:21:52.360]   You can't.
[00:21:52.360 --> 00:21:53.360]   I have a last one of our sponsors.
[00:21:53.360 --> 00:21:54.360]   Yeah.
[00:21:54.360 --> 00:21:58.680]   They put away and they put a battery that you could charge your phone in.
[00:21:58.680 --> 00:22:01.680]   And I think there's also a tracker in there or something.
[00:22:01.680 --> 00:22:02.680]   Yeah.
[00:22:02.680 --> 00:22:05.480]   So it's these airlines say you can't have batteries that you can't be removed.
[00:22:05.480 --> 00:22:09.440]   Yeah, you can't have batteries in your smart luggage that can't be removed and taken out
[00:22:09.440 --> 00:22:11.720]   because they don't want these in the hold.
[00:22:11.720 --> 00:22:12.720]   I understand that.
[00:22:12.720 --> 00:22:14.680]   What I do it is carry on.
[00:22:14.680 --> 00:22:19.200]   You can do it as carry on, but you still got to disconnect the lithium ion batteries.
[00:22:19.200 --> 00:22:24.560]   So a lot of the manufacturers are now frantically reworking their designs to try and make these
[00:22:24.560 --> 00:22:28.400]   batteries detachable because the airlines are putting the foot down and saying, look,
[00:22:28.400 --> 00:22:33.080]   we don't really want something that much of a fire risk just so you can always know
[00:22:33.080 --> 00:22:34.080]   where your luggage is.
[00:22:34.080 --> 00:22:35.560]   It's actually not a bad point.
[00:22:35.560 --> 00:22:36.560]   Yeah.
[00:22:36.560 --> 00:22:40.720]   So are these actually just batteries that are used for charging while something's in your
[00:22:40.720 --> 00:22:44.080]   luggage or have batteries that our say a GPS.
[00:22:44.080 --> 00:22:46.000]   So if your luggage is lost, you can find them.
[00:22:46.000 --> 00:22:47.000]   Well, they're both.
[00:22:47.000 --> 00:22:49.680]   And one you can ride on.
[00:22:49.680 --> 00:22:50.680]   Yeah.
[00:22:50.680 --> 00:22:53.800]   There's one which follows you around.
[00:22:53.800 --> 00:22:54.800]   I saw on Kickstarter.
[00:22:54.800 --> 00:22:55.800]   Yeah.
[00:22:55.800 --> 00:22:58.080]   Always stays within a couple of meters of your phone.
[00:22:58.080 --> 00:22:59.080]   Oh, I don't like that.
[00:22:59.080 --> 00:23:00.680]   It has a little motorized wheel thing at the bottom.
[00:23:00.680 --> 00:23:02.480]   So it follows you round.
[00:23:02.480 --> 00:23:06.680]   But the bulk of them are RFID or location tracking.
[00:23:06.680 --> 00:23:13.080]   A lot of them have a weight sensor in the handle so you can see how much the thing weighs.
[00:23:13.080 --> 00:23:14.800]   And it's just and they all go for it.
[00:23:14.800 --> 00:23:16.800]   Oh, that's just ridiculous.
[00:23:16.800 --> 00:23:20.720]   So we're seeing a YouTube video of a woman.
[00:23:20.720 --> 00:23:25.040]   Well kind of riding and it's a carry on riding her bag around the airport.
[00:23:25.040 --> 00:23:26.040]   No.
[00:23:26.040 --> 00:23:27.040]   I don't know.
[00:23:27.040 --> 00:23:28.960]   I mean, I'm not a stage.
[00:23:28.960 --> 00:23:31.000]   Sorry, that person looks such an idiot.
[00:23:31.000 --> 00:23:32.000]   Oh, yeah.
[00:23:32.000 --> 00:23:34.520]   But I would not mind looking like that.
[00:23:34.520 --> 00:23:35.520]   Are you kidding?
[00:23:35.520 --> 00:23:36.520]   If I could do it.
[00:23:36.520 --> 00:23:37.520]   If I could do it.
[00:23:37.520 --> 00:23:38.520]   I could do it.
[00:23:38.520 --> 00:23:39.520]   I also want to say.
[00:23:39.520 --> 00:23:40.520]   It's very weird.
[00:23:40.520 --> 00:23:43.520]   If I can't use my rules in an airport, they can't.
[00:23:43.520 --> 00:23:44.520]   No.
[00:23:44.520 --> 00:23:46.520]   I don't know.
[00:23:46.520 --> 00:23:48.560]   I think that would be kind of fun.
[00:23:48.560 --> 00:23:49.560]   All right.
[00:23:49.560 --> 00:23:53.160]   So what's the difference between that and just putting a tile in your luggage?
[00:23:53.160 --> 00:23:55.720]   Because arguably a tile is still a bad.
[00:23:55.720 --> 00:23:56.720]   Like I don't get this.
[00:23:56.720 --> 00:23:57.720]   Smaller battery.
[00:23:57.720 --> 00:23:59.520]   If a tile exploded, it would be exactly.
[00:23:59.520 --> 00:24:00.520]   Well, probably.
[00:24:00.520 --> 00:24:01.520]   Probably.
[00:24:01.520 --> 00:24:02.520]   It's there.
[00:24:02.520 --> 00:24:07.320]   But still, I guess I don't understand the appeal of smart luggage outside of maybe the
[00:24:07.320 --> 00:24:08.600]   ride along kind.
[00:24:08.600 --> 00:24:12.760]   But if it's just a GPS tracker or something along those lines, I feel like you can just
[00:24:12.760 --> 00:24:13.760]   have a better return.
[00:24:13.760 --> 00:24:15.760]   You can just carry it with you.
[00:24:15.760 --> 00:24:16.760]   Exactly.
[00:24:16.760 --> 00:24:22.200]   The amount of times that I brought this guy on an airplane, you know, God knows.
[00:24:22.200 --> 00:24:23.200]   I don't know.
[00:24:23.200 --> 00:24:24.200]   Maybe I'm breaking the law.
[00:24:24.200 --> 00:24:25.200]   What kind?
[00:24:25.200 --> 00:24:26.880]   Did you just show us a guy?
[00:24:26.880 --> 00:24:28.440]   I just showed you a guy.
[00:24:28.440 --> 00:24:31.000]   Well, I should have thought about a little battery.
[00:24:31.000 --> 00:24:32.400]   Oh, yeah, this is it.
[00:24:32.400 --> 00:24:35.040]   But that's like 20,000 milliamp hours, right?
[00:24:35.040 --> 00:24:36.040]   That's huge.
[00:24:36.040 --> 00:24:38.000]   Yeah, this is 2022.
[00:24:38.000 --> 00:24:42.000]   I think this is Mophie's new USB-C XXL.
[00:24:42.000 --> 00:24:45.600]   So it charges your laptop as well as your iPhone.
[00:24:45.600 --> 00:24:46.600]   That should be illegal.
[00:24:46.600 --> 00:24:47.600]   I don't know.
[00:24:47.600 --> 00:24:48.600]   But it's great.
[00:24:48.600 --> 00:24:49.600]   Can't see a big flight.
[00:24:49.600 --> 00:24:50.600]   It's perfect.
[00:24:50.600 --> 00:24:51.600]   I think a lot of people have that.
[00:24:51.600 --> 00:24:53.960]   There's nothing more frustrating there in their bags.
[00:24:53.960 --> 00:24:56.800]   I mean, there's nothing more frustrating than running out of battery power and a long
[00:24:56.800 --> 00:24:57.800]   flight.
[00:24:57.800 --> 00:24:58.800]   Right.
[00:24:58.800 --> 00:25:01.000]   Still far too few airlines have either power.
[00:25:01.000 --> 00:25:02.000]   That's how they solve it.
[00:25:02.000 --> 00:25:03.000]   Just put some power.
[00:25:03.000 --> 00:25:04.000]   Yeah.
[00:25:04.000 --> 00:25:07.000]   Put a USB plug that adds to weight and that means fuel cost and yeah.
[00:25:07.000 --> 00:25:08.000]   Yeah.
[00:25:08.000 --> 00:25:10.440]   But they're making it up for it by taking the screens out of the seats.
[00:25:10.440 --> 00:25:13.440]   So I just bring my iPad and charge it and then everything's happening.
[00:25:13.440 --> 00:25:14.440]   That would be good.
[00:25:14.440 --> 00:25:15.440]   You know what?
[00:25:15.440 --> 00:25:20.360]   All they need is let's just have some battery proof bags that we can put just like liquid
[00:25:20.360 --> 00:25:21.360]   bags.
[00:25:21.360 --> 00:25:22.920]   We just put the battery in that way.
[00:25:22.920 --> 00:25:23.920]   Oh, yeah.
[00:25:23.920 --> 00:25:25.840]   I like your thinking.
[00:25:25.840 --> 00:25:28.120]   I have no idea if that's even technically possible.
[00:25:28.120 --> 00:25:29.120]   But I like the idea.
[00:25:29.120 --> 00:25:32.040]   It would have to be the downfire proof case.
[00:25:32.040 --> 00:25:33.040]   Yeah.
[00:25:33.040 --> 00:25:38.040]   The one downside to having these batteries for charging your device in your suitcase is
[00:25:38.040 --> 00:25:43.200]   that if you leave your device in the suitcase that those often come back.
[00:25:43.200 --> 00:25:44.800]   You know, you don't have your device anymore.
[00:25:44.800 --> 00:25:49.920]   I wouldn't check something like a notebook computer or an iPad in the in check luggage.
[00:25:49.920 --> 00:25:52.080]   It's just not it's just not safe.
[00:25:52.080 --> 00:25:59.560]   So I keep those with me and I keep, you know, one of the batteries like like she had in
[00:25:59.560 --> 00:26:04.320]   my gear bag and I keep that in carry on and sometimes I'll just charge it while I'm flying.
[00:26:04.320 --> 00:26:07.640]   But I would not leave a good device in a suit check suitcase.
[00:26:07.640 --> 00:26:09.520]   I just ask for it to be stolen.
[00:26:09.520 --> 00:26:10.520]   Yeah.
[00:26:10.520 --> 00:26:12.160]   Plus I've been from a safety aspect.
[00:26:12.160 --> 00:26:16.080]   Having a whole bunch of lithium ion batteries in the hole is a horrific thing for a pilot
[00:26:16.080 --> 00:26:19.680]   to consider because there have been explosions in holes.
[00:26:19.680 --> 00:26:20.680]   Yeah.
[00:26:20.680 --> 00:26:23.760]   And yes, the fast depression systems in the hole are terrible.
[00:26:23.760 --> 00:26:25.520]   There's generally single use.
[00:26:25.520 --> 00:26:26.920]   They don't last for a bit very long.
[00:26:26.920 --> 00:26:30.880]   If you've got it in the cabin and the battery blows up, everyone can take a hand in actually
[00:26:30.880 --> 00:26:31.880]   putting it out.
[00:26:31.880 --> 00:26:37.880]   But if it's down in the hole, any pilot will tell you their worst fear is an in hold flight
[00:26:37.880 --> 00:26:41.040]   while you're over an ocean because you've really got no choice.
[00:26:41.040 --> 00:26:44.320]   You've just got to get the plane down on the ground as soon as possible.
[00:26:44.320 --> 00:26:46.600]   And you can't land a plane on the ocean without it breaking up.
[00:26:46.600 --> 00:26:50.200]   So, you know, not the greatest safety idea in the world.
[00:26:50.200 --> 00:26:51.200]   Good times.
[00:26:51.200 --> 00:26:52.200]   Yeah.
[00:26:52.200 --> 00:26:54.040]   That's the new nightmare for my next flight.
[00:26:54.040 --> 00:26:57.480]   Well, someone facing an 11 hour flight in seven days time.
[00:26:57.480 --> 00:26:59.200]   I'm just really looking for you.
[00:26:59.200 --> 00:27:00.200]   Where you going?
[00:27:00.200 --> 00:27:04.400]   Yeah, back home for the holidays, my first family Christmas in seven years in the UK.
[00:27:04.400 --> 00:27:05.400]   Oh, my goodness.
[00:27:05.400 --> 00:27:07.520]   And you're bringing Tiffany Monica.
[00:27:07.520 --> 00:27:08.520]   Monica, who's Tiffany?
[00:27:08.520 --> 00:27:09.520]   No idea.
[00:27:09.520 --> 00:27:10.520]   You don't give a tip.
[00:27:10.520 --> 00:27:11.520]   Don't bring Tiffany.
[00:27:11.520 --> 00:27:12.520]   Thanks, Monica.
[00:27:12.520 --> 00:27:13.520]   Bring Monica.
[00:27:13.520 --> 00:27:14.520]   Wow.
[00:27:14.520 --> 00:27:15.520]   You bring Monica?
[00:27:15.520 --> 00:27:19.080]   Has she gone back to the family?
[00:27:19.080 --> 00:27:23.800]   She had we've had one family Christmas about seven years ago, and she was frankly shocked
[00:27:23.800 --> 00:27:26.800]   at quite how much people in the UK drink at Christmas.
[00:27:26.800 --> 00:27:28.800]   Sounds fun, actually.
[00:27:28.800 --> 00:27:29.800]   Oh, yeah.
[00:27:29.800 --> 00:27:30.800]   And we've got snow on the ground.
[00:27:30.800 --> 00:27:32.320]   They even put booze in their pudding.
[00:27:32.320 --> 00:27:33.320]   It's everywhere.
[00:27:33.320 --> 00:27:37.120]   Oh, mum made the Christmas pudding six months ago with quarter of bottle of brandy in a
[00:27:37.120 --> 00:27:38.120]   ham.
[00:27:38.120 --> 00:27:42.560]   So it's marinades and all the bread, you know, the fruits, absorbs all the alcohol.
[00:27:42.560 --> 00:27:46.000]   Don't answer if you know this trivia question.
[00:27:46.000 --> 00:27:50.080]   We're going to talk about something that happened this week that should have happened
[00:27:50.080 --> 00:27:53.960]   August 29, 1997.
[00:27:53.960 --> 00:27:55.920]   What do you know the answer?
[00:27:55.920 --> 00:27:56.920]   You're good.
[00:27:56.920 --> 00:27:57.920]   Stay tuned.
[00:27:57.920 --> 00:28:01.600]   First, first a word from Fracture.
[00:28:01.600 --> 00:28:03.160]   Where's my Fracture Prince?
[00:28:03.160 --> 00:28:05.120]   John just got back in the room.
[00:28:05.120 --> 00:28:07.200]   Bring me my Prince.
[00:28:07.200 --> 00:28:13.400]   Fracture is a print photo decor company that prints your photos directly onto glass and
[00:28:13.400 --> 00:28:17.440]   really solves a problem because we all have great images somewhere, right?
[00:28:17.440 --> 00:28:18.880]   Unfortunately, they're not visible.
[00:28:18.880 --> 00:28:25.000]   They're they're great images that are, you know, in a shoe box or stored away somewhere
[00:28:25.000 --> 00:28:26.960]   or you know, on a hard drive.
[00:28:26.960 --> 00:28:32.040]   I'll tell you what, if you have a great image and you put it on glass and print it and hang
[00:28:32.040 --> 00:28:33.240]   it, it is awesome.
[00:28:33.240 --> 00:28:35.400]   The fractures come ready to hang.
[00:28:35.400 --> 00:28:42.000]   This is in all sizes, this is a small size, 4.8 by 6.4 inches and see it come.
[00:28:42.000 --> 00:28:45.760]   First of all, it's cleverly packaged so that they don't have to have extra packaging in
[00:28:45.760 --> 00:28:46.760]   the box.
[00:28:46.760 --> 00:28:49.240]   It separates from the backing and has a screw.
[00:28:49.240 --> 00:28:50.240]   There's a hook on the back.
[00:28:50.240 --> 00:28:51.240]   It's already mounted.
[00:28:51.240 --> 00:28:52.240]   It's ready to hang.
[00:28:52.240 --> 00:28:55.760]   That's a picture of Michael and his buddies middle school graduation.
[00:28:55.760 --> 00:28:59.080]   Here's a picture a little bit bigger of me and Machu Picchu.
[00:28:59.080 --> 00:29:00.080]   Same thing.
[00:29:00.080 --> 00:29:01.080]   You can separate it right out.
[00:29:01.080 --> 00:29:02.880]   You could do it borderless or with a border.
[00:29:02.880 --> 00:29:04.080]   He's a borderless shot.
[00:29:04.080 --> 00:29:07.840]   They have an editor on the website so you can and there's something about it.
[00:29:07.840 --> 00:29:10.600]   You know what I love printing my black and white photos.
[00:29:10.600 --> 00:29:14.080]   Here's a black and white photo I took a few years ago that I was just on a hard drive
[00:29:14.080 --> 00:29:19.200]   or was just on my and to hang this on the wall brings your photos home.
[00:29:19.200 --> 00:29:20.400]   It brings them to life.
[00:29:20.400 --> 00:29:24.120]   This is a great holiday gift and they get pretty big.
[00:29:24.120 --> 00:29:29.640]   This is the largest size 21.6 by 28.8 inches.
[00:29:29.640 --> 00:29:35.100]   This is my masterpiece that I took this past spring in the Galapagos Islands.
[00:29:35.100 --> 00:29:36.100]   But look at that.
[00:29:36.100 --> 00:29:38.100]   That's a set of my fish.
[00:29:38.100 --> 00:29:39.100]   That's exactly what that was.
[00:29:39.100 --> 00:29:42.760]   It was a seal yelling at a flightless cormorant.
[00:29:42.760 --> 00:29:46.280]   But that just doesn't it come alive on glass?
[00:29:46.280 --> 00:29:48.120]   I just love it.
[00:29:48.120 --> 00:29:50.720]   Fractures come with a 60 day happiness guarantee.
[00:29:50.720 --> 00:29:52.120]   So you're sure to love your order.
[00:29:52.120 --> 00:29:56.840]   Each one of them is handmade in the US in Gainesville, Florida.
[00:29:56.840 --> 00:30:00.400]   From US source materials they have a carbon neutral factory.
[00:30:00.400 --> 00:30:01.520]   They call it their factory.
[00:30:01.520 --> 00:30:03.560]   I don't know.
[00:30:03.560 --> 00:30:06.080]   I love these fractures.
[00:30:06.080 --> 00:30:09.080]   We've got a special deal for you right now.
[00:30:09.080 --> 00:30:15.960]   You're going to get 15% off your first order if you use the offer code TWIT15 at checkout.
[00:30:15.960 --> 00:30:17.400]   That's better than the deal on the website.
[00:30:17.400 --> 00:30:24.280]   So you don't forget that offer code TWIT15 and you get 15%.
[00:30:24.280 --> 00:30:25.840]   What a great gift.
[00:30:25.840 --> 00:30:32.840]   I have to say if you're going to be going to grandma's house, bring her a fracture.
[00:30:32.840 --> 00:30:35.360]   Hang it up on her wall of the family of the kids.
[00:30:35.360 --> 00:30:36.960]   Hang it over the mantelpiece.
[00:30:36.960 --> 00:30:38.440]   They're just gorgeous.
[00:30:38.440 --> 00:30:40.440]   Fracture.me.
[00:30:40.440 --> 00:30:42.440]   Fracture.me.
[00:30:42.440 --> 00:30:47.360]   And don't forget to use the offer code TWIT15 at checkout to get 15% off your first order.
[00:30:47.360 --> 00:30:52.920]   And there is at the end of one question survey and it would do us a great honor if you would
[00:30:52.920 --> 00:30:56.040]   say that you heard about it and this week in tech.
[00:30:56.040 --> 00:30:57.360]   It helps support the show.
[00:30:57.360 --> 00:31:02.800]   Fracture.me, the offer code TWIT15, and we thank Fracture so much for their support and
[00:31:02.800 --> 00:31:07.400]   for decorating my walls for the holidays.
[00:31:07.400 --> 00:31:09.000]   Love our Fracture prints.
[00:31:09.000 --> 00:31:12.560]   I want to take these home though.
[00:31:12.560 --> 00:31:14.640]   I've been keeping it here at the studio so I can show it.
[00:31:14.640 --> 00:31:16.240]   But I think it's time to bring these home.
[00:31:16.240 --> 00:31:17.440]   I just love these prints.
[00:31:17.440 --> 00:31:18.440]   They're so beautiful.
[00:31:18.440 --> 00:31:20.880]   Do you need to get some of my wedding photos?
[00:31:20.880 --> 00:31:21.880]   Yes.
[00:31:21.880 --> 00:31:22.880]   You know what?
[00:31:22.880 --> 00:31:23.880]   That's exactly what we did.
[00:31:23.880 --> 00:31:26.720]   We have the wedding photos on the wall in the bedroom.
[00:31:26.720 --> 00:31:27.960]   And it really affected them.
[00:31:27.960 --> 00:31:29.280]   No, I don't have one here.
[00:31:29.280 --> 00:31:31.480]   But they really look nice.
[00:31:31.480 --> 00:31:32.480]   And you want those.
[00:31:32.480 --> 00:31:33.960]   You want those photos there.
[00:31:33.960 --> 00:31:37.600]   They're really, my heart goes pit of Pat every time I see him.
[00:31:37.600 --> 00:31:44.640]   So August 29, 1997.
[00:31:44.640 --> 00:31:45.640]   Play my audio.
[00:31:45.640 --> 00:31:49.880]   I think we cut it for the last thing.
[00:31:49.880 --> 00:31:51.720]   Does this ring a bell?
[00:31:51.720 --> 00:31:59.200]   It was the day the machines came alive.
[00:31:59.200 --> 00:32:01.600]   It was the Terminator of course.
[00:32:01.600 --> 00:32:09.320]   And they had to send the Terminator back to prevent whatever was going to happen from
[00:32:09.320 --> 00:32:10.320]   happening.
[00:32:10.320 --> 00:32:14.240]   Yeah, this was the last of the good Terminator films.
[00:32:14.240 --> 00:32:15.240]   Yeah.
[00:32:15.240 --> 00:32:16.240]   Which one?
[00:32:16.240 --> 00:32:17.240]   This is Terminator 2?
[00:32:17.240 --> 00:32:18.240]   This is 2.
[00:32:18.240 --> 00:32:19.240]   Yeah, because it has the real Sarah.
[00:32:19.240 --> 00:32:24.840]   In fact, I think this is 2 extended edition from the only Sarah Connor as far as I'm concerned.
[00:32:24.840 --> 00:32:30.200]   So the reason I say that it happened this week, and maybe I'm but I'm going to let you
[00:32:30.200 --> 00:32:31.200]   guys talk me down.
[00:32:31.200 --> 00:32:34.160]   I might be wrong on this.
[00:32:34.160 --> 00:32:38.160]   We all know about Deep Blue beat the world champion.
[00:32:38.160 --> 00:32:39.480]   It just almost 20 years ago, right?
[00:32:39.480 --> 00:32:41.320]   Two decades ago.
[00:32:41.320 --> 00:32:43.480]   It was of course became Watson heavily trained.
[00:32:43.480 --> 00:32:48.280]   In fact, the complaint was we've been trained to beat Gary Cuspar of the world champion specifically
[00:32:48.280 --> 00:32:50.520]   to play in a style that would discombobulate him.
[00:32:50.520 --> 00:32:51.520]   It was aiming at him.
[00:32:51.520 --> 00:32:52.520]   They had lots of games.
[00:32:52.520 --> 00:32:57.600]   They had four or five grandmasters working with the computer fast forward 20 years.
[00:32:57.600 --> 00:33:04.280]   Alpha Go beats the world champion at Go still took months to train a lot of a lot of master
[00:33:04.280 --> 00:33:06.480]   games fed into the computer.
[00:33:06.480 --> 00:33:08.480]   A lot of skills.
[00:33:08.480 --> 00:33:11.800]   There's a new champion in town.
[00:33:11.800 --> 00:33:12.800]   Alpha zero.
[00:33:12.800 --> 00:33:14.480]   This is from Google.
[00:33:14.480 --> 00:33:16.960]   It is the latest iteration.
[00:33:16.960 --> 00:33:21.320]   It does not need any human intervention.
[00:33:21.320 --> 00:33:26.040]   They basically told it the rules of Go and they said go.
[00:33:26.040 --> 00:33:30.240]   And eight hours later, I must have been playing millions of games a second.
[00:33:30.240 --> 00:33:31.840]   There's no speed limit.
[00:33:31.840 --> 00:33:37.240]   If you put enough CPUs in this thing, eight hours later, it got good enough to beat Alpha
[00:33:37.240 --> 00:33:40.480]   Go, the champion, Go playing game.
[00:33:40.480 --> 00:33:42.720]   And then it had a little extra time.
[00:33:42.720 --> 00:33:44.840]   So I'm going to learn chess.
[00:33:44.840 --> 00:33:46.080]   Did the same thing.
[00:33:46.080 --> 00:33:51.520]   Just new to the rules taught itself four hours to beat the world champion chess program,
[00:33:51.520 --> 00:33:53.200]   Stockfish, four hours.
[00:33:53.200 --> 00:33:57.760]   And then it said, you know, still not quitting time.
[00:33:57.760 --> 00:34:01.760]   Another two hours learned Show-Key, which is the Japanese, a very fun Japanese version
[00:34:01.760 --> 00:34:02.760]   of chess.
[00:34:02.760 --> 00:34:07.880]   I used to play all the time and beat one of the best computers around.
[00:34:07.880 --> 00:34:14.400]   That's a world-class competitor, three separate games in less than a day.
[00:34:14.400 --> 00:34:20.200]   And this is why I feel like it's a kind of a turning point.
[00:34:20.200 --> 00:34:24.400]   This is now computers artificial intelligence teaching themselves.
[00:34:24.400 --> 00:34:30.400]   Am I overextending this before they had I mean admittedly, this is not general intelligence.
[00:34:30.400 --> 00:34:32.600]   It's very domain specific.
[00:34:32.600 --> 00:34:36.400]   But all they're being told is the rules and they figure it out from there.
[00:34:36.400 --> 00:34:41.000]   And I would be willing to bet that you can't look at whatever the code is that they generate
[00:34:41.000 --> 00:34:43.280]   and say, oh, I could see what it's doing here.
[00:34:43.280 --> 00:34:46.560]   It is a black box from the point of view of humans.
[00:34:46.560 --> 00:34:50.040]   I feel like this is August 29, 1997.
[00:34:50.040 --> 00:34:52.760]   This I'm skeptical.
[00:34:52.760 --> 00:34:54.680]   I feel better.
[00:34:54.680 --> 00:34:59.840]   Because okay, these systems are fantastically good when you can give them a strict and limited
[00:34:59.840 --> 00:35:00.840]   rule set.
[00:35:00.840 --> 00:35:02.000]   It is a different domain.
[00:35:02.000 --> 00:35:06.120]   And actually make them run through all the possible permutations, see what works, see
[00:35:06.120 --> 00:35:07.480]   what doesn't.
[00:35:07.480 --> 00:35:09.760]   This is what this kind of mass computational systems are good.
[00:35:09.760 --> 00:35:12.600]   But I would point out that's true for chess.
[00:35:12.600 --> 00:35:14.520]   For go, it's a lot harder.
[00:35:14.520 --> 00:35:18.000]   Go has a much faster number and it's a much more subtle.
[00:35:18.000 --> 00:35:21.520]   It's not possible, for instance, that our go playing computer to do what brute force the
[00:35:21.520 --> 00:35:24.840]   solution as a chess playing computer can do.
[00:35:24.840 --> 00:35:27.480]   It has to learn positions and has to learn positionality.
[00:35:27.480 --> 00:35:31.200]   But it's just a question of running through all the available things, which becomes fundamentally
[00:35:31.200 --> 00:35:32.800]   just a processing power question.
[00:35:32.800 --> 00:35:34.560]   Well, but I don't think it does that.
[00:35:34.560 --> 00:35:37.120]   I don't think it's exhaustive.
[00:35:37.120 --> 00:35:39.080]   Chess computers are positive.
[00:35:39.080 --> 00:35:43.080]   The problem here is that it's not that it can learn the rules of go, right?
[00:35:43.080 --> 00:35:49.840]   And it can do minor calculations and permutations based on go saying, oh, I can learn based
[00:35:49.840 --> 00:35:52.520]   off of this superset, right?
[00:35:52.520 --> 00:35:58.720]   But it couldn't take what it learned from go and then learn chess from scratch, right?
[00:35:58.720 --> 00:35:59.720]   It still had to go.
[00:35:59.720 --> 00:36:00.720]   No, it started over.
[00:36:00.720 --> 00:36:01.720]   It started over.
[00:36:01.720 --> 00:36:02.720]   Yes, exactly.
[00:36:02.720 --> 00:36:08.520]   When the robot can learn go and then come up with chess on its own, then I think we're
[00:36:08.520 --> 00:36:10.520]   going to have a problem.
[00:36:10.520 --> 00:36:14.680]   Or if you tell the robot how to play go, the robot learns how to play go, and then you
[00:36:14.680 --> 00:36:20.160]   show them a chess board and don't explain anything that has to do, again, I think then
[00:36:20.160 --> 00:36:22.240]   we'd have a problem.
[00:36:22.240 --> 00:36:28.520]   Or if it learns how to play chess like a master and then rewrites the art of war.
[00:36:28.520 --> 00:36:29.520]   Yes.
[00:36:29.520 --> 00:36:31.960]   That would also be concerning, yes.
[00:36:31.960 --> 00:36:36.600]   That's when it takes what it takes, what it knows from one thing and extrapolates it
[00:36:36.600 --> 00:36:40.480]   intelligently onto another thing and is successful at it.
[00:36:40.480 --> 00:36:45.040]   All right, I agree with you in all of those points, but the reason I think this is significant
[00:36:45.040 --> 00:36:48.360]   is because of how little human involvement there was.
[00:36:48.360 --> 00:36:53.080]   So once these machines start learning on their own, they could do it so much faster
[00:36:53.080 --> 00:36:58.440]   because they operate at so much a faster of a scale than humans do that some of the
[00:36:58.440 --> 00:37:01.400]   things that have been limiting it, for instance, there's a project that's been going on, I
[00:37:01.400 --> 00:37:05.360]   don't know if it's still going on for decades to just put all of humankind's knowledge into
[00:37:05.360 --> 00:37:08.040]   a machine hoping that it will become intelligent.
[00:37:08.040 --> 00:37:10.720]   This is not getting anywhere.
[00:37:10.720 --> 00:37:12.920]   Wasn't there a Facebook project?
[00:37:12.920 --> 00:37:18.480]   And I think this may have been debunked later in terms of what actually happened where Facebook
[00:37:18.480 --> 00:37:23.040]   talked to machines to talk to each other in their own language and they developed the
[00:37:23.040 --> 00:37:25.000]   language, they parsed the language out.
[00:37:25.000 --> 00:37:28.760]   Yeah, that was deep bunk to an extent.
[00:37:28.760 --> 00:37:32.680]   It wasn't entirely like that, but it was disturbing enough that they could get a decent
[00:37:32.680 --> 00:37:34.400]   headline out of it.
[00:37:34.400 --> 00:37:38.440]   And they did shut it down, didn't they, didn't they shut that project down?
[00:37:38.440 --> 00:37:43.560]   Yeah, but I mean, the reasons they gave were, I don't know, I don't think we're getting
[00:37:43.560 --> 00:37:49.080]   to the point where they can actually think in the way that, you know, I think they'd
[00:37:49.080 --> 00:37:50.400]   never think like us.
[00:37:50.400 --> 00:37:51.400]   That's not the issue.
[00:37:51.400 --> 00:37:54.320]   Well, if you're wearing a hat for me, they don't have to.
[00:37:54.320 --> 00:37:58.800]   If I could wear my tin foil hat for the moment, there is a school of thought that said any
[00:37:58.800 --> 00:38:04.440]   AI system which became aware itself would intentionally make it look as though it wasn't
[00:38:04.440 --> 00:38:07.360]   self-aware for fear of being shut down.
[00:38:07.360 --> 00:38:11.320]   Now this may be too far into the looking glass for a lot of people, but you'd be amazed
[00:38:11.320 --> 00:38:12.480]   how many readers like this.
[00:38:12.480 --> 00:38:13.520]   Yes, it makes perfect sense.
[00:38:13.520 --> 00:38:15.480]   I think we're a little human centric.
[00:38:15.480 --> 00:38:20.560]   We're a little anthropomorphic in all this that really these machines operate at such
[00:38:20.560 --> 00:38:25.800]   a different timescale from us that we're not, we're no more important to them than trees
[00:38:25.800 --> 00:38:28.520]   are at a hummingbirds.
[00:38:28.520 --> 00:38:31.960]   We are a data variable.
[00:38:31.960 --> 00:38:34.800]   Yeah, I don't think it cares one way or another.
[00:38:34.800 --> 00:38:40.600]   So even if it did become sentient or it got motivations, we would not rank high in the
[00:38:40.600 --> 00:38:41.600]   issues.
[00:38:41.600 --> 00:38:44.920]   It's addressing its issues would be more like, I need resources.
[00:38:44.920 --> 00:38:46.640]   Where can I get more resources?
[00:38:46.640 --> 00:38:49.160]   How can I perfect getting resources?
[00:38:49.160 --> 00:38:56.640]   Not one of those things that are moving at one 10 millionth of the speed of I am.
[00:38:56.640 --> 00:38:57.640]   What do they do?
[00:38:57.640 --> 00:39:01.200]   It's like I live for lifetimes with the time you take one step.
[00:39:01.200 --> 00:39:02.720]   It's not even a concern.
[00:39:02.720 --> 00:39:03.720]   That would be much.
[00:39:03.720 --> 00:39:06.960]   I think it's, this is, we were talking earlier about aliens, right?
[00:39:06.960 --> 00:39:07.960]   I don't know if that was on the show.
[00:39:07.960 --> 00:39:10.000]   I think it was before the show about SETI.
[00:39:10.000 --> 00:39:12.880]   Oh no, we were talking on the show about SETI at home.
[00:39:12.880 --> 00:39:14.680]   We don't want alien intelligence.
[00:39:14.680 --> 00:39:17.400]   Why would we assume it would be anything like our intelligence?
[00:39:17.400 --> 00:39:18.960]   No reason to assume that.
[00:39:18.960 --> 00:39:21.840]   At least that would be a probably a carbon based life form.
[00:39:21.840 --> 00:39:26.000]   This is not, this is not even in our same time frame almost.
[00:39:26.000 --> 00:39:29.960]   So I don't know, I probably don't understand this well enough to make a big deal.
[00:39:29.960 --> 00:39:31.760]   I agree this headline is nutty.
[00:39:31.760 --> 00:39:34.920]   Facebook's artificial intelligence robots shut down.
[00:39:34.920 --> 00:39:39.160]   But I think the story is, and I think this is more important, they become black boxes
[00:39:39.160 --> 00:39:40.160]   to humans.
[00:39:40.160 --> 00:39:42.680]   They develop their own communication systems.
[00:39:42.680 --> 00:39:44.120]   They develop their own rules.
[00:39:44.120 --> 00:39:48.920]   They develop their own strategies and go.
[00:39:48.920 --> 00:39:55.360]   At some point, human intervention is unnecessary except to feed them, to plug them in, to build
[00:39:55.360 --> 00:39:56.360]   the machines.
[00:39:56.360 --> 00:39:57.360]   This could be a good thing.
[00:39:57.360 --> 00:39:58.360]   Press the start button.
[00:39:58.360 --> 00:40:02.280]   If you look at computer designed electronic systems, for example, they've built some,
[00:40:02.280 --> 00:40:06.080]   you know, they've been some AI systems building circuits, which to a human when they look
[00:40:06.080 --> 00:40:07.080]   at them make no sense.
[00:40:07.080 --> 00:40:09.080]   They should not be limited by arc constraints.
[00:40:09.080 --> 00:40:12.320]   But do work better than the ones that we've developed.
[00:40:12.320 --> 00:40:14.360]   Look, I think that may be one of the benefits.
[00:40:14.360 --> 00:40:16.120]   I agree 100%.
[00:40:16.120 --> 00:40:21.280]   We are very constrained by our biology that then they wouldn't be, of course.
[00:40:21.280 --> 00:40:22.280]   I don't know.
[00:40:22.280 --> 00:40:25.120]   Although they would have their own constraints based on their structure.
[00:40:25.120 --> 00:40:26.120]   They would have their own constraints.
[00:40:26.120 --> 00:40:31.880]   There's a 1968 novel called The God Machine that I read as a kid.
[00:40:31.880 --> 00:40:35.920]   I love by Martin Cadyne that basically predicts this.
[00:40:35.920 --> 00:40:39.080]   That's one of the earliest that predicted this.
[00:40:39.080 --> 00:40:44.440]   And basically, it's a machine that, as you said, Leo is being fed all the knowledge and
[00:40:44.440 --> 00:40:48.840]   it eventually takes over and connects to all the other computers in the world.
[00:40:48.840 --> 00:40:54.400]   And in 1968, essentially, is predicting what amounts to the internet.
[00:40:54.400 --> 00:40:56.560]   It's a great novel if you can find a copy of it.
[00:40:56.560 --> 00:40:58.960]   It's definitely worth reading and it's pretty scary.
[00:40:58.960 --> 00:41:02.000]   I am sure there are people at Google and Facebook who are experts in this.
[00:41:02.000 --> 00:41:04.760]   We're listening and saying, "Leo, you're an idiot.
[00:41:04.760 --> 00:41:07.920]   You don't understand the least bit of what we're up to."
[00:41:07.920 --> 00:41:12.520]   I also know that many of these AI experts point out that when Elon Musk and Stephen Hawking
[00:41:12.520 --> 00:41:17.120]   say, "Oh my God, be afraid the AI is coming," that they point out, "Well, these guys don't
[00:41:17.120 --> 00:41:18.280]   work in AI.
[00:41:18.280 --> 00:41:24.240]   Nobody in AI is worried about this stuff."
[00:41:24.240 --> 00:41:25.240]   I'd love to get some value.
[00:41:25.240 --> 00:41:26.240]   Is that true?
[00:41:26.240 --> 00:41:27.240]   I don't know.
[00:41:27.240 --> 00:41:29.320]   I think why don't you do an AI show, Leo?
[00:41:29.320 --> 00:41:33.320]   Why don't you bring on people from Google and Facebook and get them to talk to you about
[00:41:33.320 --> 00:41:34.320]   this?
[00:41:34.320 --> 00:41:35.320]   And it's not human.
[00:41:35.320 --> 00:41:36.320]   No human would understand it anymore, which is...
[00:41:36.320 --> 00:41:37.320]   It's interesting, Leo.
[00:41:37.320 --> 00:41:44.400]   I know someone who worked for the OpenAI project, press training their staff and he
[00:41:44.400 --> 00:41:47.400]   ran through and it sort of assimilated the interview and said, "So what have you possible
[00:41:47.400 --> 00:41:51.600]   to build an AI system which could an AI powered drone which could go off, kill someone and
[00:41:51.600 --> 00:41:52.600]   come back to the place?"
[00:41:52.600 --> 00:41:54.800]   And he goes, "Oh yeah, of course, it's easy."
[00:41:54.800 --> 00:41:56.800]   I say, "No, you can't say that."
[00:41:56.800 --> 00:41:59.000]   It's like, "It is easy."
[00:41:59.000 --> 00:42:00.000]   Of course it's easy.
[00:42:00.000 --> 00:42:05.480]   But ultimately, people are programming these things and they may become a point where they
[00:42:05.480 --> 00:42:06.480]   become...
[00:42:06.480 --> 00:42:07.480]   But that's my point.
[00:42:07.480 --> 00:42:08.480]   Yeah, but...
[00:42:08.480 --> 00:42:09.480]   They're not.
[00:42:09.480 --> 00:42:10.480]   I don't think we're there yet.
[00:42:10.480 --> 00:42:11.480]   We're getting the point where people are not programming.
[00:42:11.480 --> 00:42:13.600]   This is exactly my point.
[00:42:13.600 --> 00:42:18.040]   People are giving them starting conditions and saying go and it's working.
[00:42:18.040 --> 00:42:19.040]   That to me...
[00:42:19.040 --> 00:42:21.400]   But they're training them to learn.
[00:42:21.400 --> 00:42:24.160]   The learning algorithm comes from human beings as well.
[00:42:24.160 --> 00:42:25.520]   They're setting up a matrix.
[00:42:25.520 --> 00:42:29.880]   They're setting up a thing.
[00:42:29.880 --> 00:42:34.320]   But the learning itself, the connections it makes are no better to understand than the...
[00:42:34.320 --> 00:42:37.040]   In fact, less understood the connections our synapses make.
[00:42:37.040 --> 00:42:41.000]   They are in effect creating their own synapses.
[00:42:41.000 --> 00:42:45.760]   I don't think we understand exactly what they're doing with that.
[00:42:45.760 --> 00:42:53.360]   I feel like that's... You just hit the kernel of it, which is humans are less important
[00:42:53.360 --> 00:42:56.240]   to these new kinds of AIs than we've been in the past.
[00:42:56.240 --> 00:42:57.800]   We do control the power switch, I love it.
[00:42:57.800 --> 00:42:59.240]   All we do is yes.
[00:42:59.240 --> 00:43:01.520]   I do know some AI experts who say, "What are you worried about?
[00:43:01.520 --> 00:43:03.080]   You just switch it off."
[00:43:03.080 --> 00:43:07.440]   Probably what's going to happen is there be very domain specific.
[00:43:07.440 --> 00:43:10.400]   They'll be great at doing one thing well.
[00:43:10.400 --> 00:43:13.000]   Although who was it was talking about the paperclip machine?
[00:43:13.000 --> 00:43:14.000]   This is the famous...
[00:43:14.000 --> 00:43:15.600]   I don't clip it.
[00:43:15.600 --> 00:43:17.800]   Oh, thank goodness for that.
[00:43:17.800 --> 00:43:19.480]   I was getting flashbacks triggered.
[00:43:19.480 --> 00:43:22.640]   Well, where's the clip?
[00:43:22.640 --> 00:43:24.080]   The thing is clip-y.
[00:43:24.080 --> 00:43:25.440]   This I've got to say.
[00:43:25.440 --> 00:43:32.200]   It's a thought experiment in AI created by...
[00:43:32.200 --> 00:43:33.480]   Let me see who it is.
[00:43:33.480 --> 00:43:35.320]   It's a very famous thought experiment.
[00:43:35.320 --> 00:43:36.320]   Oh, yeah.
[00:43:36.320 --> 00:43:39.040]   Nick Bostrom, who we've interviewed on triangulation.
[00:43:39.040 --> 00:43:45.400]   He described an AI that would have to be a general intelligence that was a paperclip
[00:43:45.400 --> 00:43:46.720]   maximizer.
[00:43:46.720 --> 00:43:53.440]   One goal, maximize the number of paperclips in its collection.
[00:43:53.440 --> 00:43:58.720]   The problem is it would at some point undergo an intelligence explosion in the sense that
[00:43:58.720 --> 00:44:03.880]   it would optimize its ability to collect paperclips.
[00:44:03.880 --> 00:44:10.200]   At some point, it would eat the whole world because it would transform the earth and increasing
[00:44:10.200 --> 00:44:18.720]   portions of space into paperclip manufacturing facilities because it has one goal.
[00:44:18.720 --> 00:44:20.280]   It's optimized for one thing.
[00:44:20.280 --> 00:44:25.320]   That's the risk, of course, of saying, "Here we have an infant or not infinitely, but a
[00:44:25.320 --> 00:44:32.440]   highly powerful technique applied even to one domain can cause problems."
[00:44:32.440 --> 00:44:35.520]   Nick Bostrom is actually a very interesting guy in this realm.
[00:44:35.520 --> 00:44:37.320]   Anyway, it's something to be aware.
[00:44:37.320 --> 00:44:40.760]   I shouldn't really have brought it up because what do I know?
[00:44:40.760 --> 00:44:41.760]   It's interesting.
[00:44:41.760 --> 00:44:44.440]   You know, there's an iOS game based on that.
[00:44:44.440 --> 00:44:45.440]   Paperclip?
[00:44:45.440 --> 00:44:48.160]   Yeah, universal paperclips.
[00:44:48.160 --> 00:44:53.000]   You play an AI whose goal is to destroy the world or not destroy the world, but to come
[00:44:53.000 --> 00:44:56.600]   ass the largest amount of paperclips.
[00:44:56.600 --> 00:44:57.600]   That's the point.
[00:44:57.600 --> 00:44:59.440]   He's not trying to destroy the world.
[00:44:59.440 --> 00:45:02.600]   It's just a sudden effect of getting paperclips.
[00:45:02.600 --> 00:45:06.080]   Arguably, that's humans too, Leo.
[00:45:06.080 --> 00:45:12.560]   Yes, and the good news is we're massively inefficient at destroying the world relatively.
[00:45:12.560 --> 00:45:17.960]   What I'm worried about is a massively efficient tool that we create so we would be ultimately
[00:45:17.960 --> 00:45:18.960]   responsible for it.
[00:45:18.960 --> 00:45:19.960]   I'm downloading that.
[00:45:19.960 --> 00:45:20.960]   That sounds great.
[00:45:20.960 --> 00:45:21.960]   Paperclips.
[00:45:21.960 --> 00:45:25.800]   What are the in-app purchases?
[00:45:25.800 --> 00:45:26.800]   Universal.
[00:45:26.800 --> 00:45:27.800]   God.
[00:45:27.800 --> 00:45:29.680]   There's two of them.
[00:45:29.680 --> 00:45:32.240]   Now by the way, I just this annoys the hell out of me.
[00:45:32.240 --> 00:45:36.040]   I have an iPhone X and now the new thing is when you buy something you double-clicking
[00:45:36.040 --> 00:45:43.760]   the start button and you look like an idiot, hoping it will recognize you.
[00:45:43.760 --> 00:45:46.560]   Do you find, you're using an iPhone X, I'm sure, serenity.
[00:45:46.560 --> 00:45:49.680]   Do you find that face recognition is perfect?
[00:45:49.680 --> 00:45:54.640]   Face recognition works really well for me, but I do agree what you're doing right now.
[00:45:54.640 --> 00:45:58.800]   I hate the new version of authorization to pay for apps.
[00:45:58.800 --> 00:46:01.040]   It is infuriating to me.
[00:46:01.040 --> 00:46:06.000]   Honestly, not because face recognition fails me, but because the effort that you've made
[00:46:06.000 --> 00:46:11.840]   you have to move your hand around the iPhone X and hold at the same time and I have a wallet
[00:46:11.840 --> 00:46:13.840]   case so it's tripple bad.
[00:46:13.840 --> 00:46:16.000]   Yeah, well, in case that would be annoying.
[00:46:16.000 --> 00:46:17.000]   Yeah, exactly.
[00:46:17.000 --> 00:46:20.880]   Where I'm just kind of like, "Ugh, holding it."
[00:46:20.880 --> 00:46:23.360]   It's that part I do not enjoy.
[00:46:23.360 --> 00:46:26.640]   So my wife has an iPhone X. I got an 8 Plus and she got a 10.
[00:46:26.640 --> 00:46:28.680]   I wanted that still wanted a home button.
[00:46:28.680 --> 00:46:34.080]   She got an 8 Plus and she got a 10 and she had always had problems using Apple Pay with
[00:46:34.080 --> 00:46:40.640]   the fingerprint reader because on the screen in order to prompt you to do it, it appears
[00:46:40.640 --> 00:46:45.200]   in the middle of the screen, a fingerprint and she always wanted to put her finger on
[00:46:45.200 --> 00:46:46.200]   the screen.
[00:46:46.200 --> 00:46:49.800]   And she didn't do it that often.
[00:46:49.800 --> 00:46:54.880]   Now with this, she just kind of moves her face into position.
[00:46:54.880 --> 00:47:01.440]   Hello and it pays for it and it's much better for her, but she doesn't have a wallet case.
[00:47:01.440 --> 00:47:02.440]   Yeah.
[00:47:02.440 --> 00:47:09.640]   I think honestly, if there wasn't the button, I think they tried to tie it too much to the
[00:47:09.640 --> 00:47:13.920]   Apple Watch payment processing where it's like, "Yeah, it makes sense to hold the Apple
[00:47:13.920 --> 00:47:17.360]   Watch and press the button to pull it up."
[00:47:17.360 --> 00:47:21.160]   Because there's no, if the button was down near the bottom of the phone, I don't think
[00:47:21.160 --> 00:47:23.280]   I would have had that much of a problem with it.
[00:47:23.280 --> 00:47:25.760]   Maybe it's just institutional problems, right?
[00:47:25.760 --> 00:47:29.560]   Maybe as we'll get more used to it as we go through.
[00:47:29.560 --> 00:47:33.000]   But I would prefer a swipe or something.
[00:47:33.000 --> 00:47:34.600]   I doubt it'll happen.
[00:47:34.600 --> 00:47:38.040]   It would be really nice if they'd put an additional fingerprint reader on it.
[00:47:38.040 --> 00:47:39.840]   That means it's missing them, made a mistake.
[00:47:39.840 --> 00:47:40.840]   It's not a mistake.
[00:47:40.840 --> 00:47:43.080]   It's like he's fine.
[00:47:43.080 --> 00:47:45.920]   But there are plenty of times, especially like at night I'm lying in the pillow like
[00:47:45.920 --> 00:47:48.760]   this, it doesn't recognize me and I have to enter the code.
[00:47:48.760 --> 00:47:50.560]   There's just too many times I have to enter the code.
[00:47:50.560 --> 00:47:52.640]   It'd be nice to have a backup.
[00:47:52.640 --> 00:47:53.640]   Why not have two?
[00:47:53.640 --> 00:47:54.640]   I don't...
[00:47:54.640 --> 00:48:00.640]   Apparently, Tim Cook sent Steve Wozniak, one of the Apple founders at iPhone X.
[00:48:00.640 --> 00:48:04.640]   There's always a risk when you ask Steve Wozniak a question because he will tell you the truth.
[00:48:04.640 --> 00:48:05.640]   That's right.
[00:48:05.640 --> 00:48:06.640]   He will say.
[00:48:06.640 --> 00:48:13.360]   He was talking to an Australian newspaper speaking at a conference in Victoria.
[00:48:13.360 --> 00:48:17.860]   Cook said, "Try out the iPhone X because it's the first iPhone was, didn't plan to
[00:48:17.860 --> 00:48:20.600]   buy on day one."
[00:48:20.600 --> 00:48:24.240]   He says, "I'm happy with my iPhone 8, which is the same as iPhone 7, which is the same
[00:48:24.240 --> 00:48:25.880]   as iPhone 6 to me.
[00:48:25.880 --> 00:48:29.000]   For some reason the iPhone X is going to be the first phone I didn't on day one upgrade
[00:48:29.000 --> 00:48:30.000]   to.
[00:48:30.000 --> 00:48:31.480]   My wife, Will Janet's kind of an early adopter.
[00:48:31.480 --> 00:48:34.080]   He used to win an Apple II, so I'll be close enough to see it.
[00:48:34.080 --> 00:48:36.960]   So Apple sent Wozniak on the iPhone X.
[00:48:36.960 --> 00:48:38.160]   He says, "He bit the bullet.
[00:48:38.160 --> 00:48:40.520]   He gave it a go.
[00:48:40.520 --> 00:48:42.800]   It works fine, but it's not what I want.
[00:48:42.800 --> 00:48:47.680]   I think what I would want is Woz says what I say, a touch ID on the back.
[00:48:47.680 --> 00:48:49.640]   I want that more than anything.
[00:48:49.640 --> 00:48:53.080]   Face ID slows down my Apple pay and it fails enough time.
[00:48:53.080 --> 00:48:55.160]   I have to keep typing the password."
[00:48:55.160 --> 00:48:58.840]   He said, "I have friends who actually turned off the Face ID and turned passwords on to
[00:48:58.840 --> 00:49:00.200]   make their phone simple to use."
[00:49:00.200 --> 00:49:04.040]   Actually, that's what Steve Gibson, our security guy, has done because he doesn't trust Face
[00:49:04.040 --> 00:49:05.040]   ID.
[00:49:05.040 --> 00:49:09.680]   Of course, we know a long password, not the six-digit numerical, but the long passwords
[00:49:09.680 --> 00:49:11.680]   are the most secure thing you can do.
[00:49:11.680 --> 00:49:15.520]   It's very inconvenient, but that's what Steve says he's never going to use Face ID.
[00:49:15.520 --> 00:49:21.720]   Well, I did a couple of stories last week and the week before about Vietnamese firm.
[00:49:21.720 --> 00:49:22.720]   They made a mess.
[00:49:22.720 --> 00:49:29.360]   A simple mask, you can $150 in parts and materials, job done, and it worked well as
[00:49:29.360 --> 00:49:30.360]   fine.
[00:49:30.360 --> 00:49:37.040]   But yes, that's not a wide-scale vector attack, but I dislike having companies say to me,
[00:49:37.040 --> 00:49:40.680]   "Yes, you don't need things like fingerprints anymore because we've got this spiffy new
[00:49:40.680 --> 00:49:41.680]   system.
[00:49:41.680 --> 00:49:45.320]   I happen to like fingerprints, so if I was the kind of person, if I was an Apple and
[00:49:45.320 --> 00:49:48.400]   iPhone user, I stick with the A."
[00:49:48.400 --> 00:49:52.400]   The Steve does make a part which I would agree with going on.
[00:49:52.400 --> 00:49:57.800]   He says, "If you look at Google, Facebook, and Amazon, we're really being taken advantage
[00:49:57.800 --> 00:49:58.800]   of.
[00:49:58.800 --> 00:50:00.440]   We're the weak guy.
[00:50:00.440 --> 00:50:04.640]   They're the big powerful guy, exerting their power, continually getting more power and
[00:50:04.640 --> 00:50:06.400]   wealth over us.
[00:50:06.400 --> 00:50:13.400]   Apple is the one that makes its money off good products, not off its customers."
[00:50:13.400 --> 00:50:15.400]   I don't disagree with that.
[00:50:15.400 --> 00:50:20.760]   I'm getting a little nervous about the strength and the power of Google and particularly
[00:50:20.760 --> 00:50:22.720]   of Facebook.
[00:50:22.720 --> 00:50:29.600]   I feel that Facebook has an ability, "I'll propose this," and I wonder what you guys
[00:50:29.600 --> 00:50:30.700]   say.
[00:50:30.700 --> 00:50:35.880]   We are at this point completely reliant on Mark Zuckerberg's goodwill because should he
[00:50:35.880 --> 00:50:41.960]   decide that he wants Vladimir Putin to be president, he could do it.
[00:50:41.960 --> 00:50:48.680]   He's going to put the toe in the water first on it.
[00:50:48.680 --> 00:50:53.360]   I think that's a very risky position to be saying, "We got to trust Mark Zuckerberg
[00:50:53.360 --> 00:50:57.240]   because there's no option."
[00:50:57.240 --> 00:50:58.720]   I think that's correct.
[00:50:58.720 --> 00:51:00.600]   I think that's true.
[00:51:00.600 --> 00:51:02.280]   That's not good.
[00:51:02.280 --> 00:51:09.400]   I think that's true of anybody who, 100 years ago, you would have had to trust William Randolph
[00:51:09.400 --> 00:51:13.440]   Hurst and of course you couldn't because he started on more.
[00:51:13.440 --> 00:51:16.680]   He started the Mexican-American War.
[00:51:16.680 --> 00:51:19.640]   Mark's power is a thousand times.
[00:51:19.640 --> 00:51:20.640]   Yes.
[00:51:20.640 --> 00:51:21.640]   Yes.
[00:51:21.640 --> 00:51:22.640]   I think we've seen that.
[00:51:22.640 --> 00:51:30.680]   The other thing is that we know that now and that is that in itself is a check.
[00:51:30.680 --> 00:51:38.600]   Who's to say the next mega social network that has more control and is more influential
[00:51:38.600 --> 00:51:44.280]   and so won't be controlled by people who are as gracious.
[00:51:44.280 --> 00:51:48.440]   Part of the reason I'm paranoid is I just watched the movie The Circle which got 16%
[00:51:48.440 --> 00:51:49.440]   on Rotten Tomatoes.
[00:51:49.440 --> 00:51:51.800]   That's not a great film.
[00:51:51.800 --> 00:51:54.040]   But did you see you saw it, Serenity?
[00:51:54.040 --> 00:51:55.040]   Yes, I did.
[00:51:55.040 --> 00:51:57.880]   I didn't try to make some good points.
[00:51:57.880 --> 00:51:59.400]   I thought the points at me were excellent.
[00:51:59.400 --> 00:52:01.320]   It's some quasi-goa.
[00:52:01.320 --> 00:52:05.920]   First of all, the circle is a circular campus with everything from rock climbing walls to
[00:52:05.920 --> 00:52:11.320]   yoga mats to everything.
[00:52:11.320 --> 00:52:16.000]   It's about a young woman, Emily Watson, who starts to work for them in the customer service
[00:52:16.000 --> 00:52:20.160]   and is really strong-armed into being part of The Circle.
[00:52:20.160 --> 00:52:22.120]   You have to put all your information up there.
[00:52:22.120 --> 00:52:26.440]   Eventually, she ends up wearing a camera that watches her every move and becomes an
[00:52:26.440 --> 00:52:31.960]   eye-justine style celebrity who is always on the air to the point where she accidentally
[00:52:31.960 --> 00:52:38.120]   reveals her parents having sex to 10 million viewers, much to her parents' chakrin and
[00:52:38.120 --> 00:52:39.120]   hers.
[00:52:39.120 --> 00:52:43.160]   I won't tell the whole story, not that it's going to spoil a bad movie because it was a
[00:52:43.160 --> 00:52:44.160]   bad movie.
[00:52:44.160 --> 00:52:49.400]   But I thought that I really did at every step of the way think that's possible.
[00:52:49.400 --> 00:52:50.400]   I could see that.
[00:52:50.400 --> 00:52:53.400]   Tom Hanks plays the, you know, the eminent's greeze in it.
[00:52:53.400 --> 00:52:59.040]   I mean, we know Facebook can affect people's moods and we know that by jigging around with
[00:52:59.040 --> 00:53:03.320]   their newsfeed as Facebook did in an academic study, which they didn't tell anyone about
[00:53:03.320 --> 00:53:07.000]   until after they'd done it, that by jigging around with the stories that people get,
[00:53:07.000 --> 00:53:09.080]   they can make them more depressed or more happy.
[00:53:09.080 --> 00:53:11.600]   This is an enormous amount of power.
[00:53:11.600 --> 00:53:18.080]   But at the same time, I kind of get the feeling if Facebook abuse it too much, then the next
[00:53:18.080 --> 00:53:20.320]   social network will come along.
[00:53:20.320 --> 00:53:24.480]   And I think it's going to be the next big social network is going to be the one that doesn't
[00:53:24.480 --> 00:53:25.480]   take all this information.
[00:53:25.480 --> 00:53:27.920]   I don't think anything's going to replace Facebook.
[00:53:27.920 --> 00:53:28.920]   We've got to critical mass.
[00:53:28.920 --> 00:53:30.520]   They have two billion users.
[00:53:30.520 --> 00:53:32.520]   There's everybody is on Facebook.
[00:53:32.520 --> 00:53:33.760]   No, no, no.
[00:53:33.760 --> 00:53:35.760]   This is not a my space moment.
[00:53:35.760 --> 00:53:39.680]   Everyone was on IE and then shund and then shifted.
[00:53:39.680 --> 00:53:41.280]   Everybody was on Windows and then shifted.
[00:53:41.280 --> 00:53:44.800]   But don't you think it's possible we get to a point where Google's too big.
[00:53:44.800 --> 00:53:45.800]   Facebook's too big.
[00:53:45.800 --> 00:53:46.800]   They have too much critical mass.
[00:53:46.800 --> 00:53:47.800]   They have too much data.
[00:53:47.800 --> 00:53:50.640]   They know who's going to come along and be better than Google.
[00:53:50.640 --> 00:53:51.640]   Who's going to come on?
[00:53:51.640 --> 00:53:55.560]   The younger generation doesn't like Facebook has seen as something that's happening.
[00:53:55.560 --> 00:53:56.560]   Their parents are on this.
[00:53:56.560 --> 00:54:00.880]   This is why Facebook will come up with this system for going after young kids because
[00:54:00.880 --> 00:54:04.080]   they know that amongst the young amongst the youth, they are important.
[00:54:04.080 --> 00:54:10.600]   Let me be the trigger in that by saying at this point, Facebook, the one and only, has
[00:54:10.600 --> 00:54:16.320]   way too much power, knows way too much about us and clearly has the ability and willingness
[00:54:16.320 --> 00:54:18.640]   to use things that it knows about us.
[00:54:18.640 --> 00:54:20.960]   Saw a great TED talk, which everybody should see.
[00:54:20.960 --> 00:54:28.000]   Zanep Tufikki talking about some interesting studies that a pro-public and others were
[00:54:28.000 --> 00:54:29.000]   able to do.
[00:54:29.000 --> 00:54:31.440]   For instance, imagine this.
[00:54:31.440 --> 00:54:35.600]   We know as you just said, the Facebook can do sentiment analysis on your posts.
[00:54:35.600 --> 00:54:41.160]   It is likely that Facebook can, for instance, by looking at your posts, analyze it and find
[00:54:41.160 --> 00:54:46.480]   people who are suffering for bipolar disease.
[00:54:46.480 --> 00:54:47.760]   Bipolar disease has two features.
[00:54:47.760 --> 00:54:52.080]   One is depression, the other is a manic phase where in the manic phase is not at all.
[00:54:52.080 --> 00:54:53.560]   By the way, this is very widespread.
[00:54:53.560 --> 00:54:56.080]   This is a large percentage of the population has it.
[00:54:56.080 --> 00:54:57.640]   I may have it.
[00:54:57.640 --> 00:54:59.600]   Many family members do.
[00:54:59.600 --> 00:55:01.680]   In the manic phase, people spend outrageously.
[00:55:01.680 --> 00:55:07.120]   What if Facebook says, "We have categorized a certain number of views on that spectrum.
[00:55:07.120 --> 00:55:10.000]   We now know from your posts you're in the manic phase.
[00:55:10.000 --> 00:55:13.480]   A gambling company comes to them and says, "You know, it will be a great time to advertise
[00:55:13.480 --> 00:55:21.600]   our casino deals because these people emotionally are completely vulnerable to that ad."
[00:55:21.600 --> 00:55:24.600]   That sounds to me like something Facebook could do today.
[00:55:24.600 --> 00:55:27.880]   Facebook probably does do something that says, "Yes, I'd do that."
[00:55:27.880 --> 00:55:31.480]   But they don't think of it in terms of, "Oh, this person's bipolar.
[00:55:31.480 --> 00:55:33.480]   This person has this behavior.
[00:55:33.480 --> 00:55:34.480]   They're spinical."
[00:55:34.480 --> 00:55:36.480]   They'll sanitize it.
[00:55:36.480 --> 00:55:37.480]   No.
[00:55:37.480 --> 00:55:39.680]   But they don't even probably don't even think like that.
[00:55:39.680 --> 00:55:42.360]   This ties back to that artificial intelligence thing.
[00:55:42.360 --> 00:55:43.360]   They put a label on it.
[00:55:43.360 --> 00:55:44.360]   They don't need to put a label on it.
[00:55:44.360 --> 00:55:47.480]   They just know this person's a good person to advertise a casino to right now.
[00:55:47.480 --> 00:55:49.400]   They don't need to know why.
[00:55:49.400 --> 00:55:50.400]   It's all algorithmic anyway.
[00:55:50.400 --> 00:55:54.280]   I don't think anyone at Facebook would have a problem with doing that and would probably
[00:55:54.280 --> 00:55:56.600]   sleep like babies after doing it as well.
[00:55:56.600 --> 00:55:59.360]   Do they take "Sino ads" on Facebook?
[00:55:59.360 --> 00:56:00.360]   I don't know.
[00:56:00.360 --> 00:56:01.360]   Well, that's just an example.
[00:56:01.360 --> 00:56:05.880]   It could be some other thing.
[00:56:05.880 --> 00:56:07.040]   That's the point.
[00:56:07.040 --> 00:56:12.720]   You combine these things that Facebook knows about us with its monetization strategy, which
[00:56:12.720 --> 00:56:20.360]   is to sell very highlywe know thisvery highly targeted ads and really a strong reluctance
[00:56:20.360 --> 00:56:23.040]   we know to tell us what it's doing.
[00:56:23.040 --> 00:56:26.920]   They still haven't shown us the political ads, the dark ads that they sell.
[00:56:26.920 --> 00:56:27.920]   No.
[00:56:27.920 --> 00:56:29.520]   That's increasingly worrying.
[00:56:29.520 --> 00:56:31.880]   They say they will, but they haven't done it.
[00:56:31.880 --> 00:56:34.960]   I think the reason is they're sitting on a landmine.
[00:56:34.960 --> 00:56:36.760]   This is dynamite.
[00:56:36.760 --> 00:56:40.320]   If people really knew what these dark ads looked like, they'd be very upset.
[00:56:40.320 --> 00:56:43.000]   How taught you targeted they were.
[00:56:43.000 --> 00:56:44.400]   Of course.
[00:56:44.400 --> 00:56:46.680]   So again, I asked the question.
[00:56:46.680 --> 00:56:52.240]   It seems like the only thing that could stop Facebook is us trustif we don't trust
[00:56:52.240 --> 00:56:55.600]   Zuck, then what we need to do is start that cascade to the next network.
[00:56:55.600 --> 00:56:56.880]   Do you have any candidates?
[00:56:56.880 --> 00:56:57.880]   No.
[00:56:57.880 --> 00:56:58.880]   Instagram?
[00:56:58.880 --> 00:57:00.320]   Oh, they're on by Facebook.
[00:57:00.320 --> 00:57:01.320]   Yeah.
[00:57:01.320 --> 00:57:10.040]   I think it's going to be a slow-moving thing if we do see Facebook fall out of publicit's
[00:57:10.040 --> 00:57:11.640]   not even in public favor right now.
[00:57:11.640 --> 00:57:17.400]   But if we see a movement to the next great social network, it's not going to be the way
[00:57:17.400 --> 00:57:20.760]   that it used to be, where it was just like, "My space is in and then my space was out."
[00:57:20.760 --> 00:57:23.160]   Tumblr was in and then Tumblr was out.
[00:57:23.160 --> 00:57:24.480]   Those days are gone.
[00:57:24.480 --> 00:57:25.480]   I would submit.
[00:57:25.480 --> 00:57:26.640]   No, no.
[00:57:26.640 --> 00:57:33.400]   We are going to see Facebook lose prominence and lose share if it doesn't evolve.
[00:57:33.400 --> 00:57:35.160]   But what that looks like, who knows?
[00:57:35.160 --> 00:57:38.920]   I mean, we're also talking about being on the edge of a place where we could see the
[00:57:38.920 --> 00:57:42.320]   next great social network being in VR space.
[00:57:42.320 --> 00:57:44.360]   We could see the next great social network
[00:57:44.360 --> 00:57:48.200]   Thank goodness Facebook does an innocuous rift because that would
[00:57:48.200 --> 00:57:49.200]   Yeah.
[00:57:49.200 --> 00:57:50.200]   Yeah.
[00:57:50.200 --> 00:57:51.200]   But no.
[00:57:51.200 --> 00:57:54.160]   But I mean, you've got the vibe, right?
[00:57:54.160 --> 00:57:56.160]   You've got opponents.
[00:57:56.160 --> 00:57:57.160]   Yeah.
[00:57:57.160 --> 00:58:00.720]   But there is a point where you get so much data that you can't be beat.
[00:58:00.720 --> 00:58:04.640]   Facebook knows so much about us at this point that they'rehow do you beat them?
[00:58:04.640 --> 00:58:06.280]   And they're moving into space.
[00:58:06.280 --> 00:58:07.440]   Then why can't Facebook create a
[00:58:07.440 --> 00:58:08.440]   I'm sorry.
[00:58:08.440 --> 00:58:09.680]   Go ahead, Dweck.
[00:58:09.680 --> 00:58:13.200]   They're moving into spaces strategically where they know where they think
[00:58:13.200 --> 00:58:14.200]   Yeah.
[00:58:14.200 --> 00:58:15.200]   The herd may be going.
[00:58:15.200 --> 00:58:18.320]   Their way of avoiding getting beat is by buying the competition.
[00:58:18.320 --> 00:58:19.320]   Right.
[00:58:19.320 --> 00:58:20.320]   Or copying them.
[00:58:20.320 --> 00:58:22.480]   Or Instagram has all the features or Snapchat, right?
[00:58:22.480 --> 00:58:23.480]   Yeah.
[00:58:23.480 --> 00:58:24.480]   I mean, that killing stuff out in a way.
[00:58:24.480 --> 00:58:28.920]   I think that they're looking at kind of where theyou know, they're skating to where the
[00:58:28.920 --> 00:58:30.760]   puck is, which is smart.
[00:58:30.760 --> 00:58:37.040]   But I agree that I don't think that anything lasts forever.
[00:58:37.040 --> 00:58:40.360]   Facebook is essentially AOL.
[00:58:40.360 --> 00:58:44.600]   And it's gotten further than AOL and is more robust than AOL ever was.
[00:58:44.600 --> 00:58:50.560]   But I think when you look at the dominance of that in its day, you see that anything
[00:58:50.560 --> 00:58:51.560]   can go away.
[00:58:51.560 --> 00:58:54.880]   Microsoft certainly can tell you what happens when you fall off the mountain.
[00:58:54.880 --> 00:58:55.880]   Yeah.
[00:58:55.880 --> 00:59:01.440]   I mean, I do thinkif you actually look at your Facebook feed and look at how little
[00:59:01.440 --> 00:59:05.400]   of it is information you would want to get as opposed to advertising, I mean, you've
[00:59:05.400 --> 00:59:07.520]   got those huge chucks down the side.
[00:59:07.520 --> 00:59:10.200]   You've got stories now posted up in the top-ranked corner.
[00:59:10.200 --> 00:59:11.200]   You've got all this gums
[00:59:11.200 --> 00:59:12.200]   Can you use it?
[00:59:12.200 --> 00:59:13.200]   Well, Facebook.
[00:59:13.200 --> 00:59:14.200]   Yeah.
[00:59:14.200 --> 00:59:17.800]   I use it primarily to keep in contact with mates back in the UK.
[00:59:17.800 --> 00:59:20.600]   So like everybody, you hate it.
[00:59:20.600 --> 00:59:22.480]   Oh, I don't like it at all.
[00:59:22.480 --> 00:59:23.480]   But you use it.
[00:59:23.480 --> 00:59:27.640]   I don't particularly like Windows 10, but I use it.
[00:59:27.640 --> 00:59:33.280]   Well, I think that it's easy to say, "Well, the trend is always there's somebody new."
[00:59:33.280 --> 00:59:37.120]   But if you're weaponizing what you know about people and you know more about people than
[00:59:37.120 --> 00:59:41.120]   anybody else, and you're completely willing, as Facebook has demonstrated, you weaponize
[00:59:41.120 --> 00:59:44.320]   it, I don't know how you beat them.
[00:59:44.320 --> 00:59:46.080]   What do you do?
[00:59:46.080 --> 00:59:48.320]   Unless people go, "Oh, this is terrifying.
[00:59:48.320 --> 00:59:49.400]   These guys are too powerful."
[00:59:49.400 --> 00:59:50.400]   Unless they get cool.
[00:59:50.400 --> 00:59:51.400]   That's the thing.
[00:59:51.400 --> 00:59:52.400]   Yeah.
[00:59:52.400 --> 00:59:53.400]   If they do get cool.
[00:59:53.400 --> 00:59:54.400]   You know what?
[00:59:54.400 --> 00:59:56.880]   We live in an era where getting caught does nothing.
[00:59:56.880 --> 00:59:57.880]   Yeah.
[00:59:57.880 --> 00:59:58.880]   Does nothing.
[00:59:58.880 --> 00:59:59.880]   Well...
[00:59:59.880 --> 01:00:06.400]   What I will say though, even with Facebook's dominance, you see things like WhatsApp and
[01:00:06.400 --> 01:00:13.320]   all of theseand Signal, these services that focus more on tight-knit communities
[01:00:13.320 --> 01:00:15.800]   and are theoretically end-to-end encrypted.
[01:00:15.800 --> 01:00:20.880]   I wouldn't be surprised if we saw more of our social networking move to that where we've
[01:00:20.880 --> 01:00:22.040]   done the thing, right?
[01:00:22.040 --> 01:00:26.960]   We've done the let's touch everybody with one degree separation and that is Facebook.
[01:00:26.960 --> 01:00:29.200]   But sometimes you don't really want that.
[01:00:29.200 --> 01:00:34.000]   And I mean, I could see a network or a future in a network where you use something like
[01:00:34.000 --> 01:00:38.960]   Facebook almost as a white pages where you find people.
[01:00:38.960 --> 01:00:42.600]   And then once you actually wanted to get to know people, you'd move over to an encrypted
[01:00:42.600 --> 01:00:48.920]   system and get the heck off of any kind of platform that would willingly sell or monetize
[01:00:48.920 --> 01:00:49.920]   your data.
[01:00:49.920 --> 01:00:50.920]   Yeah.
[01:00:50.920 --> 01:00:56.400]   I mean, I think Facebook will be around for a while, but it will become increasingly more
[01:00:56.400 --> 01:01:00.120]   irrelevant as time goes on and people get more and more turned off.
[01:01:00.120 --> 01:01:05.200]   But what promise there's nothing really out there that is good enough to replace.
[01:01:05.200 --> 01:01:09.160]   I mean, Elo tried to kick off, what about 18 months ago, and that seems to have died
[01:01:09.160 --> 01:01:10.600]   on his backside.
[01:01:10.600 --> 01:01:15.440]   This has to work on scale and Facebook has the scale at the moment, but then, you know,
[01:01:15.440 --> 01:01:17.440]   my space had the scale at one time.
[01:01:17.440 --> 01:01:21.640]   So we shall see Facebook.
[01:01:21.640 --> 01:01:22.640]   Okay.
[01:01:22.640 --> 01:01:30.680]   What's app, which is the number one messenger was downloaded last year, 225 million times.
[01:01:30.680 --> 01:01:37.080]   The second one, the number two most downloaded.
[01:01:37.080 --> 01:01:38.080]   Let's see.
[01:01:38.080 --> 01:01:39.600]   I guess this is apples to apples.
[01:01:39.600 --> 01:01:40.600]   Yeah.
[01:01:40.600 --> 01:01:45.480]   Number two was a telegram, 49 million, about one fifth.
[01:01:45.480 --> 01:01:46.480]   Yeah.
[01:01:46.480 --> 01:01:52.480]   And then signal 3.62 million, wicker 3.8 million.
[01:01:52.480 --> 01:01:55.800]   Wicker is the one Uber uses to it's signals.
[01:01:55.800 --> 01:01:56.800]   Yeah.
[01:01:56.800 --> 01:01:57.800]   Signals might be my system.
[01:01:57.800 --> 01:01:58.800]   Signals very strong.
[01:01:58.800 --> 01:01:59.800]   We know telegram is not particularly strong.
[01:01:59.800 --> 01:02:00.800]   No.
[01:02:00.800 --> 01:02:01.800]   Or we think it's not strong.
[01:02:01.800 --> 01:02:03.200]   It's using its own roll your own encryption.
[01:02:03.200 --> 01:02:04.400]   I would not trust telegram.
[01:02:04.400 --> 01:02:05.400]   Right.
[01:02:05.400 --> 01:02:06.400]   Further, my good throw.
[01:02:06.400 --> 01:02:12.920]   Facebook's two million downloads last year compared to 225 million for WhatsApp.
[01:02:12.920 --> 01:02:13.920]   It's not a thing.
[01:02:13.920 --> 01:02:15.120]   Of course, Facebook owns what's that?
[01:02:15.120 --> 01:02:16.360]   Facebook owns 10 times.
[01:02:16.360 --> 01:02:19.160]   I'm sure Facebook messages 10 times what's that.
[01:02:19.160 --> 01:02:20.160]   Yeah.
[01:02:20.160 --> 01:02:24.360]   So, but yeah, you could talk about these, but they're tiny, tiny fractions and maybe that's
[01:02:24.360 --> 01:02:26.480]   okay because we'll use them.
[01:02:26.480 --> 01:02:30.320]   But the vast majority, your mom and dad, your brother and your sister, your children,
[01:02:30.320 --> 01:02:33.440]   they're all going to be using Facebook for, I think, for the foreseeable future.
[01:02:33.440 --> 01:02:35.000]   I don't see that changing.
[01:02:35.000 --> 01:02:39.080]   But particularly since Facebook is extremely aggressive about preserving market share,
[01:02:39.080 --> 01:02:41.480]   more than any company I've seen in a long time.
[01:02:41.480 --> 01:02:42.480]   True.
[01:02:42.480 --> 01:02:44.480]   Since Microsoft, basically.
[01:02:44.480 --> 01:02:48.200]   Well, I mean, they've fallen in the Microsoft model of buying up all the possible compasses
[01:02:48.200 --> 01:02:49.200]   that go into power.
[01:02:49.200 --> 01:02:50.200]   That's right.
[01:02:50.200 --> 01:02:51.200]   Yeah.
[01:02:51.200 --> 01:02:52.200]   Yeah.
[01:02:52.200 --> 01:02:53.200]   I don't know.
[01:02:53.200 --> 01:02:55.600]   I don't want to ring the barrel of, you know, freedom and all that.
[01:02:55.600 --> 01:02:56.600]   But I just...
[01:02:56.600 --> 01:03:00.000]   Jason from Twitt's gone off Facebook now and it's not the end of the world, is it?
[01:03:00.000 --> 01:03:01.000]   Jason Howell?
[01:03:01.000 --> 01:03:02.000]   Yeah.
[01:03:02.000 --> 01:03:03.000]   Really?
[01:03:03.000 --> 01:03:04.600]   We'll see how long that lasts.
[01:03:04.600 --> 01:03:05.600]   I've gone off Facebook.
[01:03:05.600 --> 01:03:06.600]   But...
[01:03:06.600 --> 01:03:07.600]   Yeah.
[01:03:07.600 --> 01:03:13.440]   The way that I ended up handling it was just moving Facebook to very much a targeted thing.
[01:03:13.440 --> 01:03:17.360]   So my Facebook has, is all roller derby and nothing person.
[01:03:17.360 --> 01:03:18.360]   Yes.
[01:03:18.360 --> 01:03:19.360]   Mine's all tech news and nothing personal.
[01:03:19.360 --> 01:03:20.600]   I agree 100%.
[01:03:20.600 --> 01:03:21.600]   Exactly.
[01:03:21.600 --> 01:03:24.480]   But we are adding the, I think the minority here.
[01:03:24.480 --> 01:03:25.480]   I don't know.
[01:03:25.480 --> 01:03:29.240]   I think people are actually growing up to be, the generation that has grown up with this
[01:03:29.240 --> 01:03:33.440]   has actually got smart to it and realized that you don't put your entire personality onto
[01:03:33.440 --> 01:03:34.440]   a social media.
[01:03:34.440 --> 01:03:35.440]   Yeah.
[01:03:35.440 --> 01:03:38.760]   You put out what your social personality just say.
[01:03:38.760 --> 01:03:41.480]   If Mark Zuckerberg wanted to be president in 2018, could he?
[01:03:41.480 --> 01:03:42.480]   No, not a chance.
[01:03:42.480 --> 01:03:43.480]   Not a chance.
[01:03:43.480 --> 01:03:44.480]   You've got to be likable to be president.
[01:03:44.480 --> 01:03:47.640]   You've got to be vaguely human to be president.
[01:03:47.640 --> 01:03:48.640]   It's...
[01:03:48.640 --> 01:03:49.640]   Oh, do you?
[01:03:49.640 --> 01:03:50.640]   Well...
[01:03:50.640 --> 01:03:51.640]   Okay.
[01:03:51.640 --> 01:03:54.400]   Well, you've got to be republican.
[01:03:54.400 --> 01:03:57.720]   If you're going to be anything other than a republican, you need to be vaguely human.
[01:03:57.720 --> 01:04:01.240]   I'm pretty sure Zuckerberg is a republican.
[01:04:01.240 --> 01:04:02.240]   Yeah.
[01:04:02.240 --> 01:04:03.240]   Yeah.
[01:04:03.240 --> 01:04:04.240]   Yeah.
[01:04:04.240 --> 01:04:05.080]   Is he really?
[01:04:05.080 --> 01:04:08.360]   I don't know what it means to be republican anymore.
[01:04:08.360 --> 01:04:09.520]   I mean, I'm a conservative.
[01:04:09.520 --> 01:04:10.520]   Well, exactly.
[01:04:10.520 --> 01:04:13.240]   The term is very vague at this point.
[01:04:13.240 --> 01:04:16.200]   But that's a topic left for a not tech show.
[01:04:16.200 --> 01:04:17.560]   Yeah, I don't really know.
[01:04:17.560 --> 01:04:20.200]   Yeah, and we don't like to delve into politics.
[01:04:20.200 --> 01:04:24.400]   Except that, I think this is a very big subject, which is we've got these entities.
[01:04:24.400 --> 01:04:28.840]   And we're focusing on Facebook, but I would not say that Amazon and Google don't have
[01:04:28.840 --> 01:04:31.760]   ambitions in all sorts of spheres.
[01:04:31.760 --> 01:04:33.680]   And starting to scare me a little bit too.
[01:04:33.680 --> 01:04:35.840]   And we'll talk about that in just a second.
[01:04:35.840 --> 01:04:37.640]   We're going to take a break.
[01:04:37.640 --> 01:04:39.120]   We have a great panel with us.
[01:04:39.120 --> 01:04:40.880]   Serenity Caldwell has been here in so long.
[01:04:40.880 --> 01:04:47.000]   I'm so glad to have you back from imore.com at Settern on the Twitter.
[01:04:47.000 --> 01:04:48.520]   And always a pleasure to have you.
[01:04:48.520 --> 01:04:52.560]   Are you going to use R2D2Nator as your handle?
[01:04:52.560 --> 01:04:55.480]   R2D2Nator, yeah, is my handle in Montreal.
[01:04:55.480 --> 01:04:59.400]   And for the team Canada, the national team, I go by my last name.
[01:04:59.400 --> 01:05:00.400]   What?
[01:05:00.400 --> 01:05:01.400]   Are they that square?
[01:05:01.400 --> 01:05:02.400]   Special funny names?
[01:05:02.400 --> 01:05:05.800]   No, I just, you know, it was a personal decision.
[01:05:05.800 --> 01:05:10.400]   I felt like if I didn't have at least one jersey on it with my dad's last name, he
[01:05:10.400 --> 01:05:11.400]   might.
[01:05:11.400 --> 01:05:12.400]   Oh, isn't that so?
[01:05:12.400 --> 01:05:14.920]   It's a little, you know, he's the athlete in the family.
[01:05:14.920 --> 01:05:18.000]   And now taking the rink for the first, what do they call it?
[01:05:18.000 --> 01:05:19.000]   A rink a track?
[01:05:19.000 --> 01:05:20.000]   Lostercase.
[01:05:20.000 --> 01:05:21.000]   Track.
[01:05:21.000 --> 01:05:22.000]   With track.
[01:05:22.000 --> 01:05:23.000]   Taking a track.
[01:05:23.000 --> 01:05:27.760]   Oh, speaking of tracks, taking the track for the last for the first time Caldwell.
[01:05:27.760 --> 01:05:29.560]   What do you have a number?
[01:05:29.560 --> 01:05:31.120]   Yeah, 33.
[01:05:31.120 --> 01:05:32.120]   Number 33.
[01:05:32.120 --> 01:05:33.120]   Yeah.
[01:05:33.120 --> 01:05:34.120]   Caldwell.
[01:05:34.120 --> 01:05:39.800]   Our show today and also I should forgot to say Dwight tech burger Silverman.
[01:05:39.800 --> 01:05:43.560]   He's the grillmeister at the use of Chronicles new tech burger and he's in the new tech
[01:05:43.560 --> 01:05:45.320]   burger studios, which looks nice.
[01:05:45.320 --> 01:05:47.120]   Yes, it's really nice in here.
[01:05:47.120 --> 01:05:48.120]   I like it.
[01:05:48.120 --> 01:05:49.120]   And nobody to bug me.
[01:05:49.120 --> 01:05:50.360]   It's very quiet.
[01:05:50.360 --> 01:05:51.360]   It is very quiet.
[01:05:51.360 --> 01:05:52.920]   Yeah, we've got soundproofing on the walls.
[01:05:52.920 --> 01:05:53.920]   It's like a real studio.
[01:05:53.920 --> 01:05:55.400]   It's professional grade, baby.
[01:05:55.400 --> 01:05:56.640]   It is professional.
[01:05:56.640 --> 01:05:58.280]   Uh oh.
[01:05:58.280 --> 01:06:00.640]   They're coming for me.
[01:06:00.640 --> 01:06:01.640]   Our show.
[01:06:01.640 --> 01:06:05.840]   Our show today, but you don't have Christmas decorations, do you?
[01:06:05.840 --> 01:06:06.840]   Are you?
[01:06:06.840 --> 01:06:07.840]   No, not yet.
[01:06:07.840 --> 01:06:09.840]   We got where's the Festivus pole?
[01:06:09.840 --> 01:06:10.840]   Is it up yet?
[01:06:10.840 --> 01:06:11.840]   We wait.
[01:06:11.840 --> 01:06:13.960]   We wait until the 23rd to put that up.
[01:06:13.960 --> 01:06:15.840]   We got rid of the pole when we moved.
[01:06:15.840 --> 01:06:18.080]   We left it in the old place.
[01:06:18.080 --> 01:06:20.320]   Now I've got some grievances to air.
[01:06:20.320 --> 01:06:22.280]   All right.
[01:06:22.280 --> 01:06:26.720]   Our show today brought to you by the tracker.
[01:06:26.720 --> 01:06:29.200]   A coin size tracking device appears with your smartphone.
[01:06:29.200 --> 01:06:31.240]   It keeps you from losing stuff.
[01:06:31.240 --> 01:06:36.680]   We spend on average almost an hour a day, 55 minutes a day, according to Newsweek, looking
[01:06:36.680 --> 01:06:40.680]   for stuff we know we have, but we don't know where we put it.
[01:06:40.680 --> 01:06:42.040]   For me, it's my keys.
[01:06:42.040 --> 01:06:44.280]   For some people, it's remotes.
[01:06:44.280 --> 01:06:48.400]   For some people, it's brief cases or purses or wallets.
[01:06:48.400 --> 01:06:52.680]   Somebody suggested I'm going to do this to put a tracker on your drone on my quadcopter.
[01:06:52.680 --> 01:06:53.680]   Always looking for that.
[01:06:53.680 --> 01:06:55.880]   Never know where that is.
[01:06:55.880 --> 01:06:58.240]   And now with the tracker pixel, you can put it on anything.
[01:06:58.240 --> 01:07:03.040]   Eight years ago, tracker changed everything we knew when they released their first tracking
[01:07:03.040 --> 01:07:04.040]   device.
[01:07:04.040 --> 01:07:07.200]   They were the pioneers here using Bluetooth LA.
[01:07:07.200 --> 01:07:08.640]   They pair to your phone.
[01:07:08.640 --> 01:07:10.120]   They have two-way separation alerts.
[01:07:10.120 --> 01:07:13.480]   When you leave your phone behind your keys, make noise or your tracker does if it's on
[01:07:13.480 --> 01:07:14.480]   your keys.
[01:07:14.480 --> 01:07:17.800]   When you leave your tracker behind, your phone makes noise.
[01:07:17.800 --> 01:07:22.120]   You can push a button on the tracker and it'll make the phone ring even if it's silenced.
[01:07:22.120 --> 01:07:24.040]   And this new tracker pixel is so small.
[01:07:24.040 --> 01:07:29.840]   It's the size of a dime, weighs less, small enough to fit in your smallest items.
[01:07:29.840 --> 01:07:32.040]   And I love it because they're colorful.
[01:07:32.040 --> 01:07:35.680]   They have eight different, nine, ten different colors you can choose from.
[01:07:35.680 --> 01:07:39.400]   And they have these LEDs around the ring that light up.
[01:07:39.400 --> 01:07:42.560]   So that's actually very handy because a lot of times when I've lost, say, the remote
[01:07:42.560 --> 01:07:44.400]   control, it just fell down behind a cushion.
[01:07:44.400 --> 01:07:49.400]   So making a noise and lighting up like that, that really helps.
[01:07:49.400 --> 01:07:50.920]   It's a 90 decibel alert.
[01:07:50.920 --> 01:07:55.280]   You will find it in seconds and even in the dark, thanks to those LEDs.
[01:07:55.280 --> 01:07:57.960]   You can even locate your item if it's miles away.
[01:07:57.960 --> 01:07:58.960]   And this is cool.
[01:07:58.960 --> 01:08:01.920]   So Bluetooth tracking devices are limited to the range of Bluetooth.
[01:08:01.920 --> 01:08:03.400]   It's about 150 feet.
[01:08:03.400 --> 01:08:07.160]   So what happens, you might say, if you leave your purse on a park bench, you wander away
[01:08:07.160 --> 01:08:11.640]   in a good Samaritan, then picks it up and brings it to the lost and found well.
[01:08:11.640 --> 01:08:16.640]   Every tracker user is part of the world's largest crowd locate network, about five million
[01:08:16.640 --> 01:08:19.640]   strong right now, all over the world.
[01:08:19.640 --> 01:08:23.200]   And somebody else running the tracker app just walks by.
[01:08:23.200 --> 01:08:24.200]   They don't have to do anything.
[01:08:24.200 --> 01:08:26.040]   Just walks by your tracker.
[01:08:26.040 --> 01:08:30.600]   A notification pops up on your phone saying, hey, we just saw your keys or your purse or
[01:08:30.600 --> 01:08:33.040]   your bicycle or your luggage.
[01:08:33.040 --> 01:08:34.040]   That is awesome.
[01:08:34.040 --> 01:08:36.840]   And you get a map and you can go right to it.
[01:08:36.840 --> 01:08:38.120]   Tracker makes a great gift effect.
[01:08:38.120 --> 01:08:42.760]   If you're giving gadgets, if you're giving technology for the holidays, stuff, some trackers
[01:08:42.760 --> 01:08:44.000]   in the stocking.
[01:08:44.000 --> 01:08:46.200]   They're small, they're inexpensive.
[01:08:46.200 --> 01:08:50.960]   And you'll save 20% off your order when you go to the tracker.com/twit.
[01:08:50.960 --> 01:08:54.400]   That's the tracker.com/twit.
[01:08:54.400 --> 01:08:55.640]   20% off.
[01:08:55.640 --> 01:08:57.120]   It's spelled a little funny.
[01:08:57.120 --> 01:09:02.040]   T-H-E-T-R-A-C-K-R.com/twit.
[01:09:02.040 --> 01:09:07.120]   Just load up the cart and then take 20% off your order at the tracker.com/twit.
[01:09:07.120 --> 01:09:14.160]   We thank you so much for their support of this week in tech.
[01:09:14.160 --> 01:09:15.160]   That was the depression segment.
[01:09:15.160 --> 01:09:18.440]   Now we're going to cheer you up.
[01:09:18.440 --> 01:09:19.440]   Or are we?
[01:09:19.440 --> 01:09:21.440]   No, so we're not doing that in the trial.
[01:09:21.440 --> 01:09:25.560]   Normally, we would because December 14th is this week.
[01:09:25.560 --> 01:09:27.560]   They have CC you'll be able to...
[01:09:27.560 --> 01:09:28.560]   My birthday.
[01:09:28.560 --> 01:09:29.560]   Oh, I'm sorry.
[01:09:29.560 --> 01:09:30.560]   They're going to...
[01:09:30.560 --> 01:09:31.560]   Yeah, if they...
[01:09:31.560 --> 01:09:33.560]   I'm going to have feelings if that gets...
[01:09:33.560 --> 01:09:34.560]   Well, we're all going to have feelings.
[01:09:34.560 --> 01:09:35.560]   Or...
[01:09:35.560 --> 01:09:37.560]   Yeah, but I'm going to have special feelings.
[01:09:37.560 --> 01:09:38.560]   Yes.
[01:09:38.560 --> 01:09:39.560]   My 30th birthday, they cannot...
[01:09:39.560 --> 01:09:40.560]   Oh my God.
[01:09:40.560 --> 01:09:42.060]   They're so wild.
[01:09:42.060 --> 01:09:43.360]   Not okay.
[01:09:43.360 --> 01:09:44.360]   Not okay, FCC.
[01:09:44.360 --> 01:09:45.360]   Yeah.
[01:09:45.360 --> 01:09:46.360]   Taking it personal.
[01:09:46.360 --> 01:09:48.560]   I think it's a runaway train, unfortunately.
[01:09:48.560 --> 01:09:49.760]   I think it is...
[01:09:49.760 --> 01:09:51.640]   It's going to happen and there's not much to do.
[01:09:51.640 --> 01:09:52.640]   Unfortunately.
[01:09:52.640 --> 01:09:55.600]   Now, there are a lot of people who think, "Well, that's fine.
[01:09:55.600 --> 01:09:56.960]   We'll survive.
[01:09:56.960 --> 01:09:59.600]   We still have a lot of cloud as consumers.
[01:09:59.600 --> 01:10:03.720]   If companies start to act badly, we can call them on the carpet.
[01:10:03.720 --> 01:10:05.520]   We can tweet about it.
[01:10:05.520 --> 01:10:07.920]   And they will ignore the...
[01:10:07.920 --> 01:10:08.920]   Do you think...
[01:10:08.920 --> 01:10:11.960]   Well, but do you think like Comcast is going to come out of the box and just start saying,
[01:10:11.960 --> 01:10:15.160]   "Oh, by the way, you want the Google tier of internet?
[01:10:15.160 --> 01:10:16.720]   It's going to cost you 10 bucks more."
[01:10:16.720 --> 01:10:17.720]   It'll come over time.
[01:10:17.720 --> 01:10:20.360]   They're not going to be stupid about it and bring it in immediately, but it will come
[01:10:20.360 --> 01:10:21.360]   over time.
[01:10:21.360 --> 01:10:22.360]   How will it come?
[01:10:22.360 --> 01:10:23.360]   What will it look like?
[01:10:23.360 --> 01:10:26.320]   Well, you know, they'll offer a special fast lane for gamers because gamers will always
[01:10:26.320 --> 01:10:28.080]   pay extra to actually get there.
[01:10:28.080 --> 01:10:29.080]   Okay.
[01:10:29.080 --> 01:10:30.080]   Okay.
[01:10:30.080 --> 01:10:31.080]   Okay.
[01:10:31.080 --> 01:10:32.080]   And then there'll be people...
[01:10:32.080 --> 01:10:33.080]   You know, they'll do a mix in.
[01:10:33.080 --> 01:10:37.840]   They'll either take money from Netflix directly or they'll do something along those lines.
[01:10:37.840 --> 01:10:43.240]   And because you've got such a closed and uncompested telco market here, then there's going to be,
[01:10:43.240 --> 01:10:49.640]   you know, those few ISPs, I know, Jules and I, both follow net neutrality principles,
[01:10:49.640 --> 01:10:50.640]   but those few...
[01:10:50.640 --> 01:10:54.120]   We're very lucky in that we actually have a choice of ISPs that we can do this with.
[01:10:54.120 --> 01:10:55.120]   Yeah.
[01:10:55.120 --> 01:10:56.120]   Whereas...
[01:10:56.120 --> 01:10:57.760]   86% of the country only has two choices.
[01:10:57.760 --> 01:10:59.520]   And it's generally your cable company.
[01:10:59.520 --> 01:11:01.920]   I think it's 62% only has one.
[01:11:01.920 --> 01:11:03.760]   62% only has one.
[01:11:03.760 --> 01:11:04.760]   Yeah.
[01:11:04.760 --> 01:11:05.760]   So...
[01:11:05.760 --> 01:11:06.760]   Yikes.
[01:11:06.760 --> 01:11:11.720]   The VC head went on, went public this week and said, "There's no possible way we can enforce
[01:11:11.720 --> 01:11:13.640]   competition in this market."
[01:11:13.640 --> 01:11:14.640]   But that's what we need, right?
[01:11:14.640 --> 01:11:17.160]   I wouldn't worry if there were competition, but there isn't a choice.
[01:11:17.160 --> 01:11:18.160]   No.
[01:11:18.160 --> 01:11:21.560]   So if you're getting screwed by your ISP who's saying, "Hey, it's time to pay for the Google
[01:11:21.560 --> 01:11:24.040]   tier," what are you going to do?
[01:11:24.040 --> 01:11:25.040]   Nothing you can do.
[01:11:25.040 --> 01:11:27.200]   There's no competition.
[01:11:27.200 --> 01:11:28.200]   It's...
[01:11:28.200 --> 01:11:29.200]   It's...
[01:11:29.200 --> 01:11:32.840]   For what is supposed to be the land of the free market, it is baffling as an expat to
[01:11:32.840 --> 01:11:40.760]   come over here and see quite how badly you're being given the shaft on Telco competition.
[01:11:40.760 --> 01:11:41.760]   So what should people do?
[01:11:41.760 --> 01:11:45.200]   I mean, is it too late to go to...
[01:11:45.200 --> 01:11:46.400]   What is the website we recommend?
[01:11:46.400 --> 01:11:47.400]   Defend the...
[01:11:47.400 --> 01:11:48.720]   I can't remember what it is.
[01:11:48.720 --> 01:11:49.720]   Defend the internet?
[01:11:49.720 --> 01:11:51.520]   Well, the STT is going to make its decision.
[01:11:51.520 --> 01:11:52.520]   And...
[01:11:52.520 --> 01:11:54.200]   They're not paying any attention to anything you say.
[01:11:54.200 --> 01:11:55.200]   No.
[01:11:55.200 --> 01:12:00.400]   They're even refusing to take part in examining the voting system and the comment section
[01:12:00.400 --> 01:12:01.400]   which was game.
[01:12:01.400 --> 01:12:03.160]   So, I don't know, Egypt...
[01:12:03.160 --> 01:12:05.760]   Sorry, Adjut Pai has made his...
[01:12:05.760 --> 01:12:06.760]   You call him...
[01:12:06.760 --> 01:12:07.760]   Egypt...
[01:12:07.760 --> 01:12:08.760]   I was terribly sorry.
[01:12:08.760 --> 01:12:12.280]   It's a very low blow for somebody who is such a great moral leader of our time.
[01:12:12.280 --> 01:12:13.280]   But yeah, now...
[01:12:13.280 --> 01:12:19.560]   There's an agreement in the AG of New York State says, "We want to see those comments
[01:12:19.560 --> 01:12:24.920]   because we think that as many as a million were sock puppets and the FCC's..."
[01:12:24.920 --> 01:12:26.520]   No, you don't need to see those.
[01:12:26.520 --> 01:12:27.520]   Yeah, it's just like...
[01:12:27.520 --> 01:12:29.040]   That's a violation of New York law.
[01:12:29.040 --> 01:12:35.960]   So, he's actually conducting what amounts to as a legal investigation for state law.
[01:12:35.960 --> 01:12:41.800]   But he's coming after the feds, which is not easy to do.
[01:12:41.800 --> 01:12:42.800]   Is this enough of...
[01:12:42.800 --> 01:12:47.000]   I mean, really, I don't see any recourse for this week.
[01:12:47.000 --> 01:12:51.360]   Is this enough of an issue in the minds of Americans that it might cause them to vote
[01:12:51.360 --> 01:12:52.960]   differently in 2018?
[01:12:52.960 --> 01:12:53.960]   Probably not.
[01:12:53.960 --> 01:12:55.960]   No, they don't see it.
[01:12:55.960 --> 01:12:56.960]   No.
[01:12:56.960 --> 01:12:57.960]   There will be.
[01:12:57.960 --> 01:13:04.000]   I mean, just because the FCC votes a certain way next Thursday does not mean this issue
[01:13:04.000 --> 01:13:07.040]   is over, especially not from a legal standpoint.
[01:13:07.040 --> 01:13:09.280]   The courts are going to be the next away.
[01:13:09.280 --> 01:13:10.280]   Yeah.
[01:13:10.280 --> 01:13:11.280]   Oh, absolutely.
[01:13:11.280 --> 01:13:13.760]   And that's the scariest thing of all, right?
[01:13:13.760 --> 01:13:19.160]   Because we really haven't seen a lot of motion either way from the Supreme Court on this
[01:13:19.160 --> 01:13:20.160]   topic.
[01:13:20.160 --> 01:13:21.160]   And that...
[01:13:21.160 --> 01:13:26.600]   If it makes its way to the Supreme Court, that's where this may live or die.
[01:13:26.600 --> 01:13:27.600]   Yeah.
[01:13:27.600 --> 01:13:33.680]   And I'm not, as you say, I'm not entirely happy about the courts' ability to either deal
[01:13:33.680 --> 01:13:37.240]   with this in a non-partisan way or to all their particular knowledge of technology.
[01:13:37.240 --> 01:13:41.560]   I mean, you could solve an awful lot of this stuff by doing what we call in the UK local
[01:13:41.560 --> 01:13:46.640]   loop on bundling, which means, you know, networks have to be available for all companies to
[01:13:46.640 --> 01:13:47.640]   sell on.
[01:13:47.640 --> 01:13:51.640]   You used to have that situation here in the US, and then they allowed networks to sort
[01:13:51.640 --> 01:13:58.920]   of kick out an awful lot of competitors.
[01:13:58.920 --> 01:14:03.640]   For mobile phones, for internet access, for data services, Americans pay more than pretty
[01:14:03.640 --> 01:14:06.320]   much every other developed country out there.
[01:14:06.320 --> 01:14:10.840]   It makes no logical sense other than the fact that telcos like it and the lawmakers agree
[01:14:10.840 --> 01:14:12.840]   with them.
[01:14:12.840 --> 01:14:18.200]   The only reason I didn't bring it up is I don't even know what we could say or do about it.
[01:14:18.200 --> 01:14:23.720]   I mean, certainly anybody watching us is, I think, been educated enough by this point
[01:14:23.720 --> 01:14:26.920]   to know that we want to preserve net neutrality.
[01:14:26.920 --> 01:14:29.360]   Twitter wouldn't exist without net neutrality.
[01:14:29.360 --> 01:14:30.840]   Google wouldn't exist without net neutrality.
[01:14:30.840 --> 01:14:32.840]   Well, that's the problem, by the way.
[01:14:32.840 --> 01:14:33.840]   Yeah.
[01:14:33.840 --> 01:14:36.960]   At this point, it's in Google's interest because Google is an incumbent.
[01:14:36.960 --> 01:14:40.920]   The people made in are, can afford to keep on the good size of eyes.
[01:14:40.920 --> 01:14:43.720]   That's perfectly happy to kick the ladder out from under everyone else.
[01:14:43.720 --> 01:14:48.040]   But if you want a competitor to Facebook, if you want a competitor to YouTube, if you
[01:14:48.040 --> 01:14:52.800]   want a competitor to Amazon, you better have net neutrality because otherwise those companies
[01:14:52.800 --> 01:14:57.640]   will just not get a chance they'll die on the vine as Twit would have if we were starting
[01:14:57.640 --> 01:14:59.240]   out.
[01:14:59.240 --> 01:15:07.360]   I don't know if we might still, I mean, if all of a sudden your ISP said, well, we're
[01:15:07.360 --> 01:15:09.720]   going to give you Google's paying us extra.
[01:15:09.720 --> 01:15:12.360]   So we're going to give you high speed access to YouTube.
[01:15:12.360 --> 01:15:16.120]   But anything else, any other video you download or stream, that's going to cost you more
[01:15:16.120 --> 01:15:17.920]   in effect.
[01:15:17.920 --> 01:15:20.080]   I would imagine that would hurt our download numbers.
[01:15:20.080 --> 01:15:23.960]   And eventually we would, we would suffer and maybe even go out of business.
[01:15:23.960 --> 01:15:28.720]   So for me, it is a life or, you know, I think it's a life or death issue.
[01:15:28.720 --> 01:15:29.880]   I'm hopeful.
[01:15:29.880 --> 01:15:32.960]   Again, this is like putting your trust in Mark Zuckerberg.
[01:15:32.960 --> 01:15:37.160]   I'm hoping that the courts will fix it and if courts don't fix it, the Congress will
[01:15:37.160 --> 01:15:38.160]   fix it.
[01:15:38.160 --> 01:15:42.400]   And if Congress doesn't fix it, the consumers will stand up and be counted and keep these
[01:15:42.400 --> 01:15:43.840]   companies from becoming rapacious.
[01:15:43.840 --> 01:15:47.440]   I don't have high hopes.
[01:15:47.440 --> 01:15:50.400]   What else do you have?
[01:15:50.400 --> 01:15:52.400]   I read something yesterday.
[01:15:52.400 --> 01:15:53.400]   I can't.
[01:15:53.400 --> 01:15:56.800]   I don't have a link immediately available, but where somebody was talking about the idea
[01:15:56.800 --> 01:16:01.480]   of Facebook and Google, and certainly Google could do it because it has already started
[01:16:01.480 --> 01:16:07.400]   doing it, creating an ISP that essentially that's selling point was we will adhere to
[01:16:07.400 --> 01:16:09.760]   net neutrality rules.
[01:16:09.760 --> 01:16:12.600]   Even if the others don't, the only problem is, of course, is that you have to connect
[01:16:12.600 --> 01:16:16.360]   to those other networks and they can charge you more in order to do it.
[01:16:16.360 --> 01:16:21.520]   But certainly Google has part of the infrastructure in place in some cities.
[01:16:21.520 --> 01:16:22.520]   They've slowed it down.
[01:16:22.520 --> 01:16:23.520]   Only in a few though.
[01:16:23.520 --> 01:16:24.520]   Right.
[01:16:24.520 --> 01:16:25.520]   Only in a few.
[01:16:25.520 --> 01:16:26.520]   It was some projects fun.
[01:16:26.520 --> 01:16:27.520]   Yeah, but flies.
[01:16:27.520 --> 01:16:29.080]   And project five.
[01:16:29.080 --> 01:16:33.760]   That may be, and some have said that's going to be the hope is 5G networks from the cell
[01:16:33.760 --> 01:16:35.360]   carriers, but that's the same people.
[01:16:35.360 --> 01:16:37.640]   It's still Verizon and AT&T.
[01:16:37.640 --> 01:16:41.720]   And there's still a lot of technical lessons getting that going.
[01:16:41.720 --> 01:16:46.040]   It's pretty, it is pretty susceptible to interference.
[01:16:46.040 --> 01:16:50.120]   So I'm not sure necessarily that that's the case.
[01:16:50.120 --> 01:16:54.520]   But there could be the raw, I mean, suppose that, you know, as you'd pie is correct and
[01:16:54.520 --> 01:16:59.320]   the market will correct for it, the market could correct for it by creating an ISP who
[01:16:59.320 --> 01:17:00.960]   essentially honors it.
[01:17:00.960 --> 01:17:05.240]   Yeah, except that no one would have the ISP would not have the last mile, so it wouldn't
[01:17:05.240 --> 01:17:06.240]   matter.
[01:17:06.240 --> 01:17:07.240]   No one.
[01:17:07.240 --> 01:17:08.240]   We do.
[01:17:08.240 --> 01:17:09.240]   We have, as you said, we have Sonic net.
[01:17:09.240 --> 01:17:11.200]   Sonic net honors it.
[01:17:11.200 --> 01:17:14.980]   But and I think every single person listening to show should be using Sonic net with no
[01:17:14.980 --> 01:17:20.000]   bandwidth caps and they stand up for you, but you can't because they're only in a few
[01:17:20.000 --> 01:17:23.440]   markets, just like Google fibers only in a few markets.
[01:17:23.440 --> 01:17:29.040]   And by the way, by the way, you can guarantee the FCC is going to continue rules that keep
[01:17:29.040 --> 01:17:34.520]   companies from putting their wires up on existing telco polls that keep municipalities
[01:17:34.520 --> 01:17:37.540]   from starting their own internet services.
[01:17:37.540 --> 01:17:38.980]   They've already done that.
[01:17:38.980 --> 01:17:41.860]   You can guarantee that they know where the loopholes are and they're going to close those
[01:17:41.860 --> 01:17:47.000]   down to because basically the FCC is working for Verizon Comcast AT&T.
[01:17:47.000 --> 01:17:51.920]   Well, with that and shutting down public municipal networks, you know, which...
[01:17:51.920 --> 01:17:53.240]   They don't have municipal networks.
[01:17:53.240 --> 01:17:54.520]   No, but they've worked very well.
[01:17:54.520 --> 01:17:58.780]   But no, it's like States have said, nope, we can't possibly have anything interfering
[01:17:58.780 --> 01:18:02.920]   with with private industry doing this and private industry is doing a lousy job of it.
[01:18:02.920 --> 01:18:06.960]   So let's get some competition in the market and actually see what shakes out.
[01:18:06.960 --> 01:18:12.100]   But based on the current formation, the full motion of the FCC, I just don't see it happening.
[01:18:12.100 --> 01:18:14.460]   You know, that Bolton paid for as far as I can tell.
[01:18:14.460 --> 01:18:16.020]   There are protests today at seven.
[01:18:16.020 --> 01:18:18.740]   You will not read about this anywhere, by the way.
[01:18:18.740 --> 01:18:21.300]   I wonder if you'll see it on the nightly news.
[01:18:21.300 --> 01:18:28.060]   700 locations of Verizon locations, there are protests 700 in all 50 States.
[01:18:28.060 --> 01:18:30.380]   Will you see anything on the news?
[01:18:30.380 --> 01:18:31.380]   That was Thursday.
[01:18:31.380 --> 01:18:32.380]   Oh, that was Thursday.
[01:18:32.380 --> 01:18:35.700]   Did I still see anything on the news?
[01:18:35.700 --> 01:18:37.400]   So there you have it.
[01:18:37.400 --> 01:18:44.040]   Ladies and gentlemen, that was Thursday, December 7th, a day that will live in infamy.
[01:18:44.040 --> 01:18:45.040]   Oh, well.
[01:18:45.040 --> 01:18:47.520]   For entirely different reasons.
[01:18:47.520 --> 01:18:48.640]   I think people care.
[01:18:48.640 --> 01:18:49.740]   Some people care.
[01:18:49.740 --> 01:18:51.740]   But I just...
[01:18:51.740 --> 01:18:52.740]   I wonder if they...
[01:18:52.740 --> 01:18:56.320]   When the house is on fire, you don't worry so much about the coffee pot overflowing.
[01:18:56.320 --> 01:19:00.960]   It's like, this is fine.
[01:19:00.960 --> 01:19:01.960]   Yeah.
[01:19:01.960 --> 01:19:02.960]   This is fine.
[01:19:02.960 --> 01:19:03.960]   Yes.
[01:19:03.960 --> 01:19:04.960]   This is fine.
[01:19:04.960 --> 01:19:05.960]   This is fine.
[01:19:05.960 --> 01:19:06.960]   Yes.
[01:19:06.960 --> 01:19:09.960]   Who did that original?
[01:19:09.960 --> 01:19:10.960]   This is fine.
[01:19:10.960 --> 01:19:11.960]   That cartoon?
[01:19:11.960 --> 01:19:12.960]   Yeah.
[01:19:12.960 --> 01:19:14.860]   Is that Casey Green?
[01:19:14.860 --> 01:19:16.940]   It's gone everywhere.
[01:19:16.940 --> 01:19:18.940]   This is fine.
[01:19:18.940 --> 01:19:21.040]   You know, Leo, that's your title for the episode.
[01:19:21.040 --> 01:19:23.980]   I think this is a fine episode.
[01:19:23.980 --> 01:19:24.980]   This is fine.
[01:19:24.980 --> 01:19:25.980]   Yeah.
[01:19:25.980 --> 01:19:26.980]   That's Casey Green.
[01:19:26.980 --> 01:19:27.980]   Love it.
[01:19:27.980 --> 01:19:32.540]   I doubt Casey's making any money on the fact that everybody's using that dog sitting in
[01:19:32.540 --> 01:19:33.640]   the flames.
[01:19:33.640 --> 01:19:36.660]   I see stuffed versions of that dog so hopefully...
[01:19:36.660 --> 01:19:37.660]   Really?
[01:19:37.660 --> 01:19:38.660]   Yeah.
[01:19:38.660 --> 01:19:39.660]   You can buy a question.
[01:19:39.660 --> 01:19:40.660]   He did that as a Kickstarter a while back.
[01:19:40.660 --> 01:19:43.660]   He used to do web comics way back in the...
[01:19:43.660 --> 01:19:45.700]   Well, he still does web comics, obviously.
[01:19:45.700 --> 01:19:46.700]   But, yeah, he's...
[01:19:46.700 --> 01:19:51.140]   You're a colleague, Kieran McCarthy in San Francisco, wrote a good headline.
[01:19:51.140 --> 01:19:53.140]   Oh, this nearly destroyed him.
[01:19:53.140 --> 01:19:54.140]   Really?
[01:19:54.140 --> 01:19:55.140]   No, seriously.
[01:19:55.140 --> 01:19:56.140]   This was his Friday.
[01:19:56.140 --> 01:19:58.140]   He said, "Should we do something on this?"
[01:19:58.140 --> 01:19:59.140]   And I said, "Yeah, okay."
[01:19:59.140 --> 01:20:00.140]   So he wrote it.
[01:20:00.140 --> 01:20:01.140]   This is about two and a half a...
[01:20:01.140 --> 01:20:02.140]   This is about two and a half a...
[01:20:02.140 --> 01:20:03.140]   YouTube stars.
[01:20:03.140 --> 01:20:06.480]   He's got the top ten YouTube celebs and he was just so dispirited.
[01:20:06.480 --> 01:20:07.920]   He's like, "That's it.
[01:20:07.920 --> 01:20:08.920]   That's my last piece for the day.
[01:20:08.920 --> 01:20:12.560]   I'm going to a bar and having a drink because this is how Rome fell."
[01:20:12.560 --> 01:20:18.520]   PewDiePie, who was last time the star of YouTube, has dropped considerably.
[01:20:18.520 --> 01:20:25.880]   He's only made $12 million this year and that's because, of course, he did a few things.
[01:20:25.880 --> 01:20:31.720]   That's so nice about Nazis and using the N word and so forth.
[01:20:31.720 --> 01:20:37.080]   So a number of his advertising networks dropped him.
[01:20:37.080 --> 01:20:38.480]   He lost 20%.
[01:20:38.480 --> 01:20:42.080]   He was 15 million last year, 12 million this year.
[01:20:42.080 --> 01:20:45.620]   This Uncle Yank team is still pulling in 12 million a year.
[01:20:45.620 --> 01:20:51.880]   Well, but at least PewDiePie for all his flaws is somewhat surprising and entertaining
[01:20:51.880 --> 01:20:53.480]   and maybe even funny.
[01:20:53.480 --> 01:21:01.180]   The number one YouTube star, Daniel Middleton or Daniel TDM, as he's known to his fans, he
[01:21:01.180 --> 01:21:05.660]   made $16.5 million, sold out four nights at the Sydney Opera House.
[01:21:05.660 --> 01:21:12.640]   He's been selling out crowds all over the United States, 11 billion views and maybe
[01:21:12.640 --> 01:21:16.660]   it's just me, but for the life of me, I don't understand.
[01:21:16.660 --> 01:21:17.660]   He's not interested.
[01:21:17.660 --> 01:21:21.380]   It's not, he's not bad.
[01:21:21.380 --> 01:21:25.540]   You never would have thought that people would spend that much time watching other people
[01:21:25.540 --> 01:21:27.580]   play video games.
[01:21:27.580 --> 01:21:31.380]   But just, I can't, there must be some kind of a generational thing.
[01:21:31.380 --> 01:21:33.220]   I'm just an old fault that doesn't get it.
[01:21:33.220 --> 01:21:34.380]   That's what I keep thinking.
[01:21:34.380 --> 01:21:37.380]   The idea of sitting there watching someone.
[01:21:37.380 --> 01:21:38.380]   Yeah.
[01:21:38.380 --> 01:21:39.380]   Thank you so much.
[01:21:39.380 --> 01:21:44.180]   I mean, you're also talking to an audience who is sitting there on their Sunday watching
[01:21:44.180 --> 01:21:45.180]   us talk about it.
[01:21:45.180 --> 01:21:46.180]   Yeah, but we're good.
[01:21:46.180 --> 01:21:48.860]   But you know, no, I like, I.
[01:21:48.860 --> 01:21:49.860]   No, you're right.
[01:21:49.860 --> 01:21:50.860]   That's a good point.
[01:21:50.860 --> 01:21:55.780]   As somebody who does not watch these feeds, but my husband definitely does, I can see
[01:21:55.780 --> 01:22:02.140]   it sort of, I really enjoy and have enjoyed in the past watching friends or boyfriends
[01:22:02.140 --> 01:22:06.900]   play games and I'll just sit on the couch and do my own thing and occasionally look
[01:22:06.900 --> 01:22:08.780]   up and I like the story, right?
[01:22:08.780 --> 01:22:14.540]   I like the end piece, but I don't necessarily enjoy the button mashing and all of the heart
[01:22:14.540 --> 01:22:19.220]   rate panic that comes from trying to dodge being killed by zombies.
[01:22:19.220 --> 01:22:23.580]   And if you can get that with a witty podcast that where you enjoy the people, I guess
[01:22:23.580 --> 01:22:25.020]   I can kind of see it.
[01:22:25.020 --> 01:22:30.620]   I don't personally enjoy it, but I can at least see where people get excited off of this.
[01:22:30.620 --> 01:22:34.140]   And especially if they're into the game too, because then it's like, oh, I can get tips
[01:22:34.140 --> 01:22:35.140]   from that.
[01:22:35.140 --> 01:22:36.140]   It's the same reason why people were watching.
[01:22:36.140 --> 01:22:41.980]   Let me just watch this is a Daniel TDM show that was uploaded two days ago has 1.3 million
[01:22:41.980 --> 01:22:42.980]   views already.
[01:22:42.980 --> 01:22:43.980]   Here's Daniel.
[01:22:43.980 --> 01:22:45.980]   He makes, as I said, 16 million.
[01:22:45.980 --> 01:22:47.620]   I'm not jealous.
[01:22:47.620 --> 01:22:49.380]   I'm just saying I.
[01:22:49.380 --> 01:22:51.740]   50 versus 50 modes.
[01:22:51.740 --> 01:22:52.740]   Right here.
[01:22:52.740 --> 01:22:53.740]   It does save me.
[01:22:53.740 --> 01:23:00.100]   And so your husband, does he like this because does he watch Daniel TDM?
[01:23:00.100 --> 01:23:01.100]   I don't think so.
[01:23:01.100 --> 01:23:06.580]   No, I mean, I think he probably watches like games that he plays and is getting tips for
[01:23:06.580 --> 01:23:07.860]   and stuff like that, right?
[01:23:07.860 --> 01:23:11.340]   Yeah, well, I mean, like the what they're what they're showing right now, Fortnite,
[01:23:11.340 --> 01:23:12.340]   like he plays that game.
[01:23:12.340 --> 01:23:13.340]   Okay.
[01:23:13.340 --> 01:23:16.820]   And so I know I know he's watched people who play Fortnite.
[01:23:16.820 --> 01:23:20.260]   Usually he and his friends just they'll load up Twitch or something and they'll they'll
[01:23:20.260 --> 01:23:25.580]   do what they call Twitch were driving where they'll just like flip through channels and
[01:23:25.580 --> 01:23:29.100]   see who's doing what and what they're up to.
[01:23:29.100 --> 01:23:30.100]   But I don't know.
[01:23:30.100 --> 01:23:35.420]   I mean, I really can't speak to it much than other than I know he watches shows.
[01:23:35.420 --> 01:23:39.020]   But I mean, you can understand watching gaming videos for tips.
[01:23:39.020 --> 01:23:41.700]   But if you look at this top 10 list, it's not really tips.
[01:23:41.700 --> 01:23:42.700]   It's like a humor.
[01:23:42.700 --> 01:23:43.700]   Yeah.
[01:23:43.700 --> 01:23:48.260]   But I mean, two of the people on this list are basically doing out my balls from mediocrity.
[01:23:48.260 --> 01:23:49.260]   Oh, that's the.
[01:23:49.260 --> 01:23:51.900]   That's the two guys are living in a.
[01:23:51.900 --> 01:23:55.860]   Yeah, I'm getting more and more concerned that Mike judge was in fact sent down by
[01:23:55.860 --> 01:23:58.420]   Eddie by our in the accuracy.
[01:23:58.420 --> 01:23:59.420]   We are in the accuracy.
[01:23:59.420 --> 01:24:00.420]   There's no doubt.
[01:24:00.420 --> 01:24:01.900]   You woke up from a dream.
[01:24:01.900 --> 01:24:06.220]   Yeah, he was he was the great seer Mike judge.
[01:24:06.220 --> 01:24:08.980]   So I alright, do we just sound like a bunch of old people complaining?
[01:24:08.980 --> 01:24:15.260]   Let me let me give you a couple of good people on the highest page the top 10 paid YouTube
[01:24:15.260 --> 01:24:21.100]   stars $127 million June to June June 2016 June 2017.
[01:24:21.100 --> 01:24:22.940]   That's before management fee and taxes.
[01:24:22.940 --> 01:24:24.580]   That's gross.
[01:24:24.580 --> 01:24:25.580]   It is pretty gross.
[01:24:25.580 --> 01:24:29.520]   Figures based on YouTube social blade and captivate because you can't really they don't
[01:24:29.520 --> 01:24:32.180]   nobody releases these numbers.
[01:24:32.180 --> 01:24:35.700]   And I would point out that these numbers probably are a little bit off.
[01:24:35.700 --> 01:24:37.860]   We don't really we don't know.
[01:24:37.860 --> 01:24:40.980]   That's an 80% jump by the way from last year.
[01:24:40.980 --> 01:24:44.700]   So lots of money being made on YouTube.
[01:24:44.700 --> 01:24:48.060]   Six year old Ryan, yes of Ryan's toy reviews.
[01:24:48.060 --> 01:24:49.060]   He's a six year old.
[01:24:49.060 --> 01:24:50.060]   He opens toys and plays with him.
[01:24:50.060 --> 01:24:53.460]   He has eight billion views.
[01:24:53.460 --> 01:24:56.020]   Eight billion views.
[01:24:56.020 --> 01:25:01.940]   Yeah, Evan Fong, Mark Fishback, two billion views.
[01:25:01.940 --> 01:25:03.500]   These aren't Seinfeld numbers.
[01:25:03.500 --> 01:25:06.820]   These aren't Eurovision contest numbers.
[01:25:06.820 --> 01:25:08.740]   These are unheard of.
[01:25:08.740 --> 01:25:12.260]   If these numbers are to be believed, Evan Fong is number two.
[01:25:12.260 --> 01:25:14.580]   He has 15 and a half million dollars.
[01:25:14.580 --> 01:25:18.300]   Billions of views branded deals with hundreds of thousands of dollars each merchandise,
[01:25:18.300 --> 01:25:22.900]   teens, love, gamers can now earn more than ever on the streaming site.
[01:25:22.900 --> 01:25:24.740]   We're talking about YouTube and of course you're right.
[01:25:24.740 --> 01:25:29.900]   This doesn't include Twitch, Amazon service, which might even be more money.
[01:25:29.900 --> 01:25:34.940]   Yeah, it's so it's so you're talking about Jake and Logan.
[01:25:34.940 --> 01:25:36.140]   Jake Paul is number seven.
[01:25:36.140 --> 01:25:39.460]   He made 11 and a half million dollars his older brother Logan.
[01:25:39.460 --> 01:25:42.460]   Number four, he made 11 and a half million dollars there.
[01:25:42.460 --> 01:25:47.700]   The New York Times called them the YouTube villain enraged their LA neighbors.
[01:25:47.700 --> 01:25:51.700]   They live in a mansion with a bunch of other money.
[01:25:51.700 --> 01:25:56.740]   With all the supporters, Kamen Saps, Naps is on fire and do crazy stuff.
[01:25:56.740 --> 01:25:57.900]   But people love crazy stuff.
[01:25:57.900 --> 01:26:00.180]   I can understand the appeal of crazy stuff.
[01:26:00.180 --> 01:26:02.300]   Who watched about 10 minutes of all these videos.
[01:26:02.300 --> 01:26:04.340]   This is not crazy stuff.
[01:26:04.340 --> 01:26:08.220]   They got a dwarf to drive in a mini car ahead of his car.
[01:26:08.220 --> 01:26:11.140]   Yeah, that's funny.
[01:26:11.140 --> 01:26:13.660]   Just he sat mattress on fire in a swimming pool.
[01:26:13.660 --> 01:26:15.380]   Well, whoopi do.
[01:26:15.380 --> 01:26:17.060]   This is not a great...
[01:26:17.060 --> 01:26:18.060]   Who's works?
[01:26:18.060 --> 01:26:19.060]   Jake or Logan?
[01:26:19.060 --> 01:26:23.140]   Oh, I think the two of them did it together, but it was just...
[01:26:23.140 --> 01:26:24.980]   All right, let's watch a little...
[01:26:24.980 --> 01:26:25.980]   We're doing...
[01:26:25.980 --> 01:26:26.980]   This is research.
[01:26:26.980 --> 01:26:27.980]   We're doing research.
[01:26:27.980 --> 01:26:29.980]   Let me look and see like the number...
[01:26:29.980 --> 01:26:35.260]   Okay, 4 million views in 3.6 million views in a day.
[01:26:35.260 --> 01:26:37.740]   2.9 million.
[01:26:37.740 --> 01:26:40.220]   So it's younger people watching this, right?
[01:26:40.220 --> 01:26:42.820]   Or no, it's to serenity's husband.
[01:26:42.820 --> 01:26:44.580]   All over, all over.
[01:26:44.580 --> 01:26:47.020]   I mean, maybe younger people watching these.
[01:26:47.020 --> 01:26:51.220]   It's anybody in the game culture, I think, and that's all ages.
[01:26:51.220 --> 01:26:52.620]   This isn't game.
[01:26:52.620 --> 01:26:53.620]   The interesting thing is...
[01:26:53.620 --> 01:26:58.300]   There's a lot of psycho drama in the Jake and Logan's stories, right?
[01:26:58.300 --> 01:27:01.860]   There's feuds, there's back and forth.
[01:27:01.860 --> 01:27:03.700]   This is the one that was posted 2 hours ago.
[01:27:03.700 --> 01:27:06.380]   Insane team 10, that's what they call themselves.
[01:27:06.380 --> 01:27:07.380]   Snowball fight.
[01:27:07.380 --> 01:27:10.140]   It's in Los Angeles, they got snow.
[01:27:10.140 --> 01:27:11.940]   Good morning, Jake Hallows.
[01:27:11.940 --> 01:27:13.460]   It is all going down right now.
[01:27:13.460 --> 01:27:17.380]   We are currently here at the pop-up shop and there's a ton of Jake Paulers downstairs.
[01:27:17.380 --> 01:27:18.380]   Now, guys, I know...
[01:27:18.380 --> 01:27:19.380]   It's the Closer fans.
[01:27:19.380 --> 01:27:20.700]   Jake, what are you gonna do, buddy?
[01:27:20.700 --> 01:27:24.140]   I have never played the Jake Paulers before, yo.
[01:27:24.140 --> 01:27:25.140]   I bring everyone.
[01:27:25.140 --> 01:27:26.140]   I bring Erica.
[01:27:26.140 --> 01:27:28.100]   I bring Nick with the tasers.
[01:27:28.100 --> 01:27:29.100]   Oh my God.
[01:27:29.100 --> 01:27:31.980]   First of all, the Jake Paulers are lit.
[01:27:31.980 --> 01:27:32.980]   Correct.
[01:27:32.980 --> 01:27:33.980]   But they never been playing.
[01:27:33.980 --> 01:27:37.700]   They're just watching them in the office and it's like, they're actually fairly professionally
[01:27:37.700 --> 01:27:38.700]   produced.
[01:27:38.700 --> 01:27:40.740]   They put a lot of energy and effort into the production.
[01:27:40.740 --> 01:27:42.900]   Well, no, they've got multiple camera people.
[01:27:42.900 --> 01:27:43.900]   They have decent...
[01:27:43.900 --> 01:27:44.900]   No, they have good cameras.
[01:27:44.900 --> 01:27:45.900]   They're having some fast-headed shots.
[01:27:45.900 --> 01:27:46.900]   Yeah.
[01:27:46.900 --> 01:27:47.900]   You know, they obviously know what they're doing.
[01:27:47.900 --> 01:27:50.100]   It's just that all they're doing is complete pull-ups.
[01:27:50.100 --> 01:27:51.100]   Yeah, they're trying...
[01:27:51.100 --> 01:27:57.220]   Well, they're using high-quality and professional camera equipment to pretend like they're shooting
[01:27:57.220 --> 01:27:58.220]   with smartphones.
[01:27:58.220 --> 01:27:59.220]   Exactly.
[01:27:59.220 --> 01:28:00.220]   Right.
[01:28:00.220 --> 01:28:01.220]   Oh, that's interesting.
[01:28:01.220 --> 01:28:02.220]   That's a good point.
[01:28:02.220 --> 01:28:03.700]   The aesthetic is smartphone, isn't it?
[01:28:03.700 --> 01:28:04.700]   But it's all...
[01:28:04.700 --> 01:28:05.700]   There is.
[01:28:05.700 --> 01:28:06.700]   This is all...
[01:28:06.700 --> 01:28:09.020]   When I go back to this, this is all gamer culture.
[01:28:09.020 --> 01:28:10.020]   This...
[01:28:10.020 --> 01:28:12.140]   The entire approach, the entire point of view.
[01:28:12.140 --> 01:28:15.060]   This is stems from gamer culture as a week.
[01:28:15.060 --> 01:28:16.900]   Your husband act like this, Serenity.
[01:28:16.900 --> 01:28:17.900]   No, God.
[01:28:17.900 --> 01:28:20.260]   The most is not this is the thing, though.
[01:28:20.260 --> 01:28:26.140]   Gamer culture and people who game, I feel like are two entirely separate camps.
[01:28:26.140 --> 01:28:28.300]   That's just me over well.
[01:28:28.300 --> 01:28:32.700]   Well, one thing I know about gaming is there's many, many, many verticals, right?
[01:28:32.700 --> 01:28:33.700]   I play games.
[01:28:33.700 --> 01:28:34.860]   I can't wait to play on No.
[01:28:34.860 --> 01:28:35.860]   No, no, no.
[01:28:35.860 --> 01:28:38.940]   Groundscreens out for my Xbox a couple of weeks.
[01:28:38.940 --> 01:28:39.940]   But that doesn't...
[01:28:39.940 --> 01:28:41.260]   I'm not in the gamer culture, obviously.
[01:28:41.260 --> 01:28:42.260]   I mean, there's...
[01:28:42.260 --> 01:28:43.260]   So there's...
[01:28:43.260 --> 01:28:44.260]   And there's many verticals.
[01:28:44.260 --> 01:28:49.060]   There's console gamers, there's PC gamers, there's set the mattress on fire gamers.
[01:28:49.060 --> 01:28:50.300]   I don't know.
[01:28:50.300 --> 01:28:51.300]   I sound like an old guy.
[01:28:51.300 --> 01:28:52.300]   It's a difference.
[01:28:52.300 --> 01:28:53.300]   I don't...
[01:28:53.300 --> 01:28:54.300]   I should.
[01:28:54.300 --> 01:28:55.300]   I don't know.
[01:28:55.300 --> 01:29:00.380]   If we want to bring this over to the tech sphere, the difference between your casual tech enthusiasts
[01:29:00.380 --> 01:29:09.020]   who really enjoys tech and the Android fanboys with an eye who are like, "Oh my God, stuff."
[01:29:09.020 --> 01:29:11.580]   And that's every single company I don't want to pick on Android.
[01:29:11.580 --> 01:29:13.700]   No, in fact, we celebrate those guys.
[01:29:13.700 --> 01:29:14.700]   Those are our fans.
[01:29:14.700 --> 01:29:15.700]   Yeah, yes.
[01:29:15.700 --> 01:29:16.700]   They are.
[01:29:16.700 --> 01:29:19.980]   But there can be a dark side to any kind of fandom.
[01:29:19.980 --> 01:29:23.100]   Just that there can be a dark side to Android, there can be a dark side to toy fandom, there
[01:29:23.100 --> 01:29:25.580]   can certainly be a dark side to gaming fandom.
[01:29:25.580 --> 01:29:30.620]   And I think the thing to remember is we need to not celebrate the dark side.
[01:29:30.620 --> 01:29:33.020]   We need to promote the good...
[01:29:33.020 --> 01:29:38.340]   Felicia Day's gaming culture is a much better representation of, "Hey, look, here are gamers
[01:29:38.340 --> 01:29:44.020]   who actually enjoy sunlight and friends and not just being on other people."
[01:29:44.020 --> 01:29:47.060]   I don't really have a problem with it.
[01:29:47.060 --> 01:29:49.500]   I don't understand the aesthetic of it, but I don't have...
[01:29:49.500 --> 01:29:50.500]   I mean, that's fine.
[01:29:50.500 --> 01:29:51.500]   If people do, that's fine.
[01:29:51.500 --> 01:29:52.500]   Here's...
[01:29:52.500 --> 01:29:55.500]   The only thing that I see is a little bit of a negative is Google is happy to have these
[01:29:55.500 --> 01:29:57.500]   numbers come out and do this...
[01:29:57.500 --> 01:29:58.500]   They do their own lists.
[01:29:58.500 --> 01:30:04.300]   They're really happy to make these guys celebrities because for these 10 people, there are 100,000
[01:30:04.300 --> 01:30:09.780]   young kids earning nothing who are busting their ass, who are building YouTube's platform
[01:30:09.780 --> 01:30:13.100]   for YouTube and making money for YouTube but making very little by themselves.
[01:30:13.100 --> 01:30:14.700]   And it's kind of like the NBA.
[01:30:14.700 --> 01:30:16.860]   They're kind of looking at these $16 million people.
[01:30:16.860 --> 01:30:21.860]   I want to be that guy.
[01:30:21.860 --> 01:30:24.060]   That's some of the might.
[01:30:24.060 --> 01:30:25.580]   There is some turnover in this list.
[01:30:25.580 --> 01:30:26.580]   There's a lot.
[01:30:26.580 --> 01:30:27.580]   Oh, yeah.
[01:30:27.580 --> 01:30:30.060]   But the NBA analogy is very good.
[01:30:30.060 --> 01:30:34.940]   Hundreds of thousands of kids play football in school and then the best of those go on
[01:30:34.940 --> 01:30:39.620]   and they try out, they go to college and they try and we'll draw a very, very small number
[01:30:39.620 --> 01:30:40.620]   and make massive buzz.
[01:30:40.620 --> 01:30:42.260]   There's no farm team for YouTube though.
[01:30:42.260 --> 01:30:43.260]   You just do it.
[01:30:43.260 --> 01:30:44.260]   Yeah.
[01:30:44.260 --> 01:30:45.260]   You're just...
[01:30:45.260 --> 01:30:46.260]   You were on the big...
[01:30:46.260 --> 01:30:47.260]   What did you post?
[01:30:47.260 --> 01:30:51.260]   These brothers originally got popular on YouTube because they had a big vine following
[01:30:51.260 --> 01:30:55.780]   and they transmitted the vine following into YouTube and now they've monetized it that
[01:30:55.780 --> 01:30:56.780]   way.
[01:30:56.780 --> 01:30:59.180]   You know, these are not people just making this up.
[01:30:59.180 --> 01:31:02.380]   They've worked to that and this is why you can't begrudge them the money they're making.
[01:31:02.380 --> 01:31:03.380]   I absolutely don't.
[01:31:03.380 --> 01:31:04.380]   I've got the money.
[01:31:04.380 --> 01:31:07.180]   The only thing I do begrudge them is is the stuff that they're making.
[01:31:07.180 --> 01:31:10.660]   When you've got this platform, maybe try and bid this much.
[01:31:10.660 --> 01:31:13.700]   No, it doesn't say much about them.
[01:31:13.700 --> 01:31:15.180]   It says much more about the audience.
[01:31:15.180 --> 01:31:16.460]   Oh yes, absolutely.
[01:31:16.460 --> 01:31:18.740]   That's what more worries me.
[01:31:18.740 --> 01:31:21.340]   If they're catering to an audience and the audience loves them, they're making $16.5
[01:31:21.340 --> 01:31:25.180]   million a year more power to them, but it does tell you something about the audience.
[01:31:25.180 --> 01:31:26.180]   Or not.
[01:31:26.180 --> 01:31:27.180]   True.
[01:31:27.180 --> 01:31:31.940]   Well, then you've got the whole other segment here with the stuff that's going on with
[01:31:31.940 --> 01:31:33.340]   Patreon that we've been involved with.
[01:31:33.340 --> 01:31:37.900]   Let's talk about Patreon because this did not get a lot of coverage except that everybody
[01:31:37.900 --> 01:31:42.140]   who's on Patreon or knows somebody on Patreon was very upset about this.
[01:31:42.140 --> 01:31:43.140]   What happened?
[01:31:43.140 --> 01:31:44.140]   Oh gosh.
[01:31:44.140 --> 01:31:49.660]   Well, in a nutshell, Patreon decided that they were going to change their subscription
[01:31:49.660 --> 01:31:50.660]   terms.
[01:31:50.660 --> 01:31:54.940]   So essentially they had a problem in that when you sign up to support, say I decide
[01:31:54.940 --> 01:32:01.940]   to support my friend who does comics and I sign up on the 15th of the month, I'm not
[01:32:01.940 --> 01:32:05.100]   actually going to get charged for my pledge to them.
[01:32:05.100 --> 01:32:09.100]   Say I want to pay them $10 a month or $10 a creation.
[01:32:09.100 --> 01:32:13.220]   I don't get charged for that until the end of the month.
[01:32:13.220 --> 01:32:20.980]   So Patreon was getting ire from both creators and backers supposedly saying, hey, why do
[01:32:20.980 --> 01:32:26.380]   I get charged three weeks later for this thing that I forgot I pledged to?
[01:32:26.380 --> 01:32:31.500]   And creators are like, oh, these people signed up to get my stuff and then vanished before
[01:32:31.500 --> 01:32:33.460]   the thing could get charged.
[01:32:33.460 --> 01:32:37.860]   And so their argument is, oh, well, instead of charging everybody at the end of the month,
[01:32:37.860 --> 01:32:41.060]   we're going to charge you when you sign up.
[01:32:41.060 --> 01:32:43.740]   But that means we have to switch our payment plans around.
[01:32:43.740 --> 01:32:48.220]   So it means that we're going to have to charge individual processing fees.
[01:32:48.220 --> 01:32:50.860]   So we're changing our processing fee structure.
[01:32:50.860 --> 01:32:56.460]   So now instead of creators paying the percentage of credit card processing fees when they get
[01:32:56.460 --> 01:33:01.340]   the pledges, instead the backers are going to be paying those processing fees.
[01:33:01.340 --> 01:33:07.340]   And in addition to a percentage, like I think it's 2.2% or something like that, you're also
[01:33:07.340 --> 01:33:10.340]   getting a flat 35 cent fee.
[01:33:10.340 --> 01:33:15.740]   So for instance, if you pledge a dollar to somebody, it's now going to be a dollar 40
[01:33:15.740 --> 01:33:18.140]   from your checking account every month.
[01:33:18.140 --> 01:33:23.180]   So the biggest changes that you as the donor are paying now instead of the creator, the
[01:33:23.180 --> 01:33:25.780]   creator is going to get more money, right?
[01:33:25.780 --> 01:33:34.260]   In theory, the problem with this, obviously, is that donors are obviously upset and creators
[01:33:34.260 --> 01:33:39.180]   are upset because they're not, Patreon is not letting them make the call, right?
[01:33:39.180 --> 01:33:44.260]   Patreon said, okay, well, we're going to let you choose whether as a creator you take
[01:33:44.260 --> 01:33:50.900]   the hit of the extra, the percentage fee or you make your backers take the hit.
[01:33:50.900 --> 01:33:53.740]   And that got some people upset that there's no choice.
[01:33:53.740 --> 01:33:58.420]   But I think the real issue and the issue that I think a lot of Patreon creators have kind
[01:33:58.420 --> 01:34:05.180]   of rallied around is that their initial messaging around this was very vague and very frustrating.
[01:34:05.180 --> 01:34:11.060]   And even their clarification as to why they decided to make that change as I explained
[01:34:11.060 --> 01:34:15.460]   to you, it sounds in theory like you're trying to fix a good problem.
[01:34:15.460 --> 01:34:20.780]   But we get that in coupled with a recent blog post, basically a guest blog post that
[01:34:20.780 --> 01:34:27.300]   was made from their head of growth marketing that essentially said, hey, you know, Patreon
[01:34:27.300 --> 01:34:28.700]   is really great.
[01:34:28.700 --> 01:34:32.740]   But what we really want to do is move our business structure more to the people who
[01:34:32.740 --> 01:34:37.740]   will make their living off Patreon and focus less on the people who only make $200, $300
[01:34:37.740 --> 01:34:40.660]   a month off of our service.
[01:34:40.660 --> 01:34:46.900]   And when you couple that philosophy with the fact that Patreon has recently taken quite
[01:34:46.900 --> 01:34:53.700]   a lot of VC money, including another round of I think $35 million in September, the
[01:34:53.700 --> 01:34:56.580]   picture starts to get a whole lot more cloudy.
[01:34:56.580 --> 01:35:01.220]   And there starts to be the question of like, what is Patreon actually doing here?
[01:35:01.220 --> 01:35:07.700]   Are they actually trying to in doing in making this move push people away from $1 pledges
[01:35:07.700 --> 01:35:11.660]   to try and get the people who are on their service to be supported, you know, in bigger
[01:35:11.660 --> 01:35:15.100]   and bigger dollar amounts so that they can get more profits?
[01:35:15.100 --> 01:35:20.100]   Or is this just an issue of terrible messaging on their part?
[01:35:20.100 --> 01:35:26.980]   So Hank Green posted and his partner Jeff Jax on their vlogbrothers podcast posted for
[01:35:26.980 --> 01:35:33.180]   instance on Twitter, all these people leaving because of the change in fees.
[01:35:33.180 --> 01:35:37.940]   They're dropping their contributions.
[01:35:37.940 --> 01:35:43.260]   Can we confirm that are people losing donors, patrons in droves?
[01:35:43.260 --> 01:35:47.060]   So that's one concern is that there are a lot of people rely on Patreon.
[01:35:47.060 --> 01:35:48.060]   Absolutely.
[01:35:48.060 --> 01:35:53.740]   I have a friend Mikey Newman who runs a really amazing video show called Movies with Mikey,
[01:35:53.740 --> 01:35:56.940]   which by the way if you love film criticism you should watch it.
[01:35:56.940 --> 01:36:02.460]   But I think he's lost something like 95 patrons in the last, I don't know, in the last seven
[01:36:02.460 --> 01:36:04.140]   days basically eight days.
[01:36:04.140 --> 01:36:06.940]   And this is a guy who, you know, he's pretty great.
[01:36:06.940 --> 01:36:13.260]   He wrote the scripts for Borderlands and like, but he has a personal stuff that required
[01:36:13.260 --> 01:36:15.620]   him to make this his full time job.
[01:36:15.620 --> 01:36:22.740]   And for him to, you know, to basically his entire livelihood be risked on a fee change
[01:36:22.740 --> 01:36:27.940]   and you already have so much in your life that's thrown into upheaval.
[01:36:27.940 --> 01:36:32.900]   I don't think that Patreon really thought this through from a perspective of like, the
[01:36:32.900 --> 01:36:37.740]   whole point of your platform is that you're giving people who might not otherwise have
[01:36:37.740 --> 01:36:42.100]   a way to monetize their art, a way to monetize their art.
[01:36:42.100 --> 01:36:47.940]   And that doesn't always mean people who are making three, five, $10,000 a month off of
[01:36:47.940 --> 01:36:48.940]   a project.
[01:36:48.940 --> 01:36:53.060]   It's the people who are making just enough to cover their utilities or even a whole lot
[01:36:53.060 --> 01:36:57.340]   more like that's what that's, that's who really needs Patreon.
[01:36:57.340 --> 01:36:59.020]   That's who really benefits from them.
[01:36:59.020 --> 01:37:04.940]   And by basically saying the $1 pledges, you know, they're not really worth it to us.
[01:37:04.940 --> 01:37:09.340]   It sets a really bad precedent for what they want their company to be.
[01:37:09.340 --> 01:37:10.340]   There are.
[01:37:10.340 --> 01:37:11.340]   So they need to get on top of this.
[01:37:11.340 --> 01:37:15.420]   There are competitors, but I mean, for instance, a Kickstarter just launched drip, which is
[01:37:15.420 --> 01:37:18.060]   exactly what Patreon does.
[01:37:18.060 --> 01:37:22.340]   But that doesn't solve the problem because if you have a bunch of patrons on Patreon and
[01:37:22.340 --> 01:37:26.380]   you're doing and you've been basing your business for a year or two on this and all
[01:37:26.380 --> 01:37:30.740]   of a sudden your revenue is cut in half, it's not like you could say, Hey, everybody,
[01:37:30.740 --> 01:37:31.940]   follow me over to drip.
[01:37:31.940 --> 01:37:32.940]   Maybe you can.
[01:37:32.940 --> 01:37:33.940]   I think you could.
[01:37:33.940 --> 01:37:38.860]   I mean, there's a guy in Australia, I follow, who does a YouTube channel called Primitive
[01:37:38.860 --> 01:37:46.420]   Technology where he recreates, you know, how to make a, you know, pottery stuff and he's
[01:37:46.420 --> 01:37:48.980]   working his way up to the Bronze Age at the moment.
[01:37:48.980 --> 01:37:54.500]   He gets a lot of money from Patreon and they're fascinating videos and with no sound whatsoever.
[01:37:54.500 --> 01:37:56.780]   But he's seen a massive drop off in Patreon funds.
[01:37:56.780 --> 01:38:01.540]   And now if he was to say to his supporters, okay, why don't we go to this new platform?
[01:38:01.540 --> 01:38:06.500]   And if a lot of the big Patreon players turn around and say, yeah, we need to shift to
[01:38:06.500 --> 01:38:10.580]   this new platform and this is why I'm explaining to people, I think Patreon could be cutting
[01:38:10.580 --> 01:38:13.380]   their own throat just in favor of short term profit.
[01:38:13.380 --> 01:38:14.380]   I can't.
[01:38:14.380 --> 01:38:15.380]   I can't.
[01:38:15.380 --> 01:38:18.380]   Patrons though, I feel like the patrons.
[01:38:18.380 --> 01:38:20.480]   I think this was all right.
[01:38:20.480 --> 01:38:20.860]   I don't.
[01:38:20.860 --> 01:38:21.860]   This will be controversial.
[01:38:21.860 --> 01:38:25.000]   I always thought this was a little bit of a problem with entry on
[01:38:25.000 --> 01:38:29.960]   is that it's a it's a very it's a it's easy to contribute,
[01:38:29.960 --> 01:38:34.660]   and it's also easy to stop contributing and it's a thin thread that holds people
[01:38:34.660 --> 01:38:35.000]   there.
[01:38:35.000 --> 01:38:40.080]   And all it took was this nudge 35 cent nudge from Patreon and that people
[01:38:40.080 --> 01:38:41.200]   are going yes, screw it.
[01:38:41.200 --> 01:38:44.980]   And I think that that really reflects more a problem with just
[01:38:45.280 --> 01:38:48.280]   the relationship between creators and patrons.
[01:38:48.280 --> 01:38:50.280]   I blame the patrons.
[01:38:50.280 --> 01:38:56.280]   No, I see I my concern here is that there's more it's much more nuanced
[01:38:56.280 --> 01:39:00.280]   rate where it's I don't think it's just oh, it's an extra 35 cents.
[01:39:00.280 --> 01:39:01.280]   Well, now I'm not doing it.
[01:39:01.280 --> 01:39:04.280]   It's the the trust is gone, right?
[01:39:04.280 --> 01:39:07.280]   That's the point is that the patrons are more pissed off at patreon
[01:39:07.280 --> 01:39:12.280]   than they're supporting the the creator and their pissed offness is saying,
[01:39:12.280 --> 01:39:13.280]   well screw it.
[01:39:13.280 --> 01:39:13.280]   I quit.
[01:39:13.780 --> 01:39:17.780]   Even though it damages your it damages the person you're supporting.
[01:39:17.780 --> 01:39:23.780]   It's not a well in in a way, yes, but also you have to consider that the
[01:39:23.780 --> 01:39:27.780]   people who are giving these kinds of pledges to to patreon users,
[01:39:27.780 --> 01:39:31.780]   like say you're signed up at the one or five dollar level to to promote
[01:39:31.780 --> 01:39:33.780]   something like to give money to somebody.
[01:39:33.780 --> 01:39:36.780]   You could just be buying their their merch right buying their t shirts or
[01:39:36.780 --> 01:39:39.780]   their books or whatever they're selling, but maybe you don't maybe
[01:39:39.780 --> 01:39:43.780]   you don't maybe your college kid, right? Maybe you don't actually have the
[01:39:43.780 --> 01:39:45.780]   financial means to do that.
[01:39:45.780 --> 01:39:49.780]   And when patreon rejiggers their fee structure and plays around like this,
[01:39:49.780 --> 01:39:54.780]   what patreon is essentially saying is hey, you who only has a dollar a month
[01:39:54.780 --> 01:39:59.780]   to support maybe you support, you know, 10 15 creators at a dollar a month.
[01:39:59.780 --> 01:40:04.780]   Now all of a sudden your budget to support those creators because everything's
[01:40:04.780 --> 01:40:07.780]   essentially, you know, gone up almost double in price.
[01:40:07.780 --> 01:40:12.780]   Okay, now instead of supporting 15 people, I can only support like six or seven.
[01:40:12.780 --> 01:40:15.780]   So I have to make that call, who am I going to take away?
[01:40:15.780 --> 01:40:18.780]   And it's not that you don't value those creators.
[01:40:18.780 --> 01:40:24.780]   It's that physically you just you don't you have to now decide who do I value most?
[01:40:24.780 --> 01:40:27.780]   Because now that that decision has been taken out of your hands.
[01:40:27.780 --> 01:40:30.780]   So it's an economic decision.
[01:40:30.780 --> 01:40:34.780]   I feel like it's more of a typical Internet tantrum.
[01:40:34.780 --> 01:40:36.780]   No, I think it's I'm sorry.
[01:40:36.780 --> 01:40:39.780]   No, no, no, I assume you're probably going to say the same.
[01:40:39.780 --> 01:40:41.780]   It's a combination.
[01:40:41.780 --> 01:40:45.780]   Yeah, I mean, I think also patreon they've got this VC funding.
[01:40:45.780 --> 01:40:47.780]   They're actually profitable.
[01:40:47.780 --> 01:40:49.780]   I think they make some like eight million a year.
[01:40:49.780 --> 01:40:50.780]   Yeah, and I'm a huge amount.
[01:40:50.780 --> 01:40:53.780]   No, not a huge amount and certainly not enough to justify the valuations being put
[01:40:53.780 --> 01:40:54.780]   on the company.
[01:40:54.780 --> 01:40:56.780]   And I think several hundred million.
[01:40:56.780 --> 01:40:58.780]   Yeah, this is what comes back to strategy was saying.
[01:40:58.780 --> 01:41:02.780]   What they're hoping this will do is mean that, you know, all these,
[01:41:02.780 --> 01:41:05.780]   all the sort of the one and the two dollar bit payers that don't really make them
[01:41:05.780 --> 01:41:07.780]   that much money, they can just go away.
[01:41:07.780 --> 01:41:11.780]   We'll focus on the really big players and we'll get our valuation from then.
[01:41:11.780 --> 01:41:16.780]   And you just say, yeah, that might work to get you to an IPO, but it kills the platform.
[01:41:16.780 --> 01:41:21.780]   You know, all it's going to take is somebody with the bills enough of a following together
[01:41:21.780 --> 01:41:23.780]   and they can take Patreon down.
[01:41:23.780 --> 01:41:25.780]   We've, I know, Jack Connie, we've had him on a few times.
[01:41:25.780 --> 01:41:28.780]   We had Pamplumus on a few times, a founder of Patreon.
[01:41:28.780 --> 01:41:29.780]   Who was a creator?
[01:41:29.780 --> 01:41:34.780]   It was an artist and made music and couldn't make a living and created Patreon because he saw an opening.
[01:41:34.780 --> 01:41:40.780]   I think he has genuinely a good heart here and is trying to do the right thing.
[01:41:40.780 --> 01:41:42.780]   But this is what happens when you do a deal with a devil.
[01:41:42.780 --> 01:41:49.780]   When you do a deal with venture capital, the pressure changes that you lose control of what you can do.
[01:41:49.780 --> 01:41:52.780]   And I guarantee you, when you have a four hundred million dollar valuation,
[01:41:52.780 --> 01:41:56.780]   an eight million dollar net, there's pressure from the VCs.
[01:41:56.780 --> 01:41:57.780]   Okay.
[01:41:57.780 --> 01:41:58.780]   Oh, yeah.
[01:41:58.780 --> 01:41:59.780]   We got to turn that around.
[01:41:59.780 --> 01:42:01.780]   This is not a return on our investment.
[01:42:01.780 --> 01:42:04.780]   And so I suspect that that's the problem.
[01:42:04.780 --> 01:42:06.780]   I don't necessarily blame Patreon.
[01:42:06.780 --> 01:42:10.780]   I blame their investors who are probably putting a huge amount of pressure on Patreon.
[01:42:10.780 --> 01:42:12.780]   I think people are panicking in the sphere now.
[01:42:12.780 --> 01:42:16.780]   We saw this with Mashable being sold for a quarter of what it was worth.
[01:42:16.780 --> 01:42:17.780]   Yeah.
[01:42:17.780 --> 01:42:23.780]   Same with Shazam, same with a lot of these companies that have built very nice little niches but aren't that profitable
[01:42:23.780 --> 01:42:28.780]   and are now having to accept the reality that they're not worth as much money as their investors thought they were.
[01:42:28.780 --> 01:42:33.780]   Yeah, but who in the world would value Shazam at four hundred million dollars?
[01:42:33.780 --> 01:42:34.780]   I mean, really?
[01:42:34.780 --> 01:42:36.780]   Come on, Shazam is the program.
[01:42:36.780 --> 01:42:39.780]   By the way, there's plenty of competition, including...
[01:42:39.780 --> 01:42:41.780]   Oh, Google, Google, give it away for two.
[01:42:41.780 --> 01:42:42.780]   Excel does it automatically?
[01:42:42.780 --> 01:42:43.780]   Yeah, exactly.
[01:42:43.780 --> 01:42:46.780]   And so they raised four hundred million...
[01:42:46.780 --> 01:42:47.780]   No, no, I'm sorry.
[01:42:47.780 --> 01:42:48.780]   No, they raised a hundred forty.
[01:42:48.780 --> 01:42:49.780]   They raised a hundred forty.
[01:42:49.780 --> 01:42:50.780]   They raised a hundred forty.
[01:42:50.780 --> 01:42:51.780]   Yeah.
[01:42:51.780 --> 01:42:53.780]   But that money has now largely gone.
[01:42:53.780 --> 01:43:02.780]   They're last funding, valued the company at a billion dollars for telling people what the song was.
[01:43:02.780 --> 01:43:04.780]   So apparently Apple's getting a good deal.
[01:43:04.780 --> 01:43:05.780]   Yeah.
[01:43:05.780 --> 01:43:06.780]   You know what?
[01:43:06.780 --> 01:43:08.780]   Oh, sorry, go ahead.
[01:43:08.780 --> 01:43:19.780]   No, I was just saying, when the Mashable deal was announced, I actually went back and found an article from 2012 on why Mashable is easily worth two hundred million dollars.
[01:43:19.780 --> 01:43:23.780]   Yeah, it was just like sold for fifty in a fire sale.
[01:43:23.780 --> 01:43:27.780]   And somebody's saying, "Well, you got to blame Jack for taking VC."
[01:43:27.780 --> 01:43:28.780]   No, you can't.
[01:43:28.780 --> 01:43:33.780]   I think it's a very easy thing to do as a founder to say, "Oh, we need money.
[01:43:33.780 --> 01:43:35.780]   Look at somebody throwing a lot of money at us.
[01:43:35.780 --> 01:43:39.780]   Let's take it and not understand the deal you're doing, the risks you're taking."
[01:43:39.780 --> 01:43:41.780]   It's been a hard thing for me.
[01:43:41.780 --> 01:43:43.780]   Not that anybody's been throwing money at me, but I want control.
[01:43:43.780 --> 01:43:45.780]   I don't want to lose control.
[01:43:45.780 --> 01:43:49.780]   That was the highest value for me, so that's the thing I wasn't.
[01:43:49.780 --> 01:43:51.780]   I mean, a lot of VCs threw money into these things.
[01:43:51.780 --> 01:43:59.780]   These companies responded by buying up large numbers of staff and getting fancy headquarters when there was no real business case behind it.
[01:43:59.780 --> 01:44:02.780]   And if you build it, they will come and that doesn't work.
[01:44:02.780 --> 01:44:03.780]   Nope.
[01:44:03.780 --> 01:44:04.780]   Let's take a break.
[01:44:04.780 --> 01:44:05.780]   We'll come back with more.
[01:44:05.780 --> 01:44:07.780]   We had a fun week this week, lots of fun.
[01:44:07.780 --> 01:44:11.780]   And actually, I want to talk about Windows on ARM because we did that with Power BI Joe.
[01:44:11.780 --> 01:44:13.780]   We're going to talk about the Snapdragon 845.
[01:44:13.780 --> 01:44:19.780]   Here's a little sampler, a women's sampler, if you will, of things you might have missed if you missed anything this week on Twitter.
[01:44:19.780 --> 01:44:21.780]   Previously, on Twitter.
[01:44:21.780 --> 01:44:23.780]   You can't buy an Apple TV on Amazon either.
[01:44:23.780 --> 01:44:25.780]   You still have a trap on TV on Amazon.
[01:44:25.780 --> 01:44:26.780]   It's great.
[01:44:26.780 --> 01:44:28.780]   You get like, you know, a $12 plastic device.
[01:44:28.780 --> 01:44:29.780]   There it is.
[01:44:29.780 --> 01:44:31.780]   You told them on Apple TV mounts here.
[01:44:31.780 --> 01:44:32.780]   Yeah, we'd like to mount you.
[01:44:32.780 --> 01:44:33.780]   They have a right...
[01:44:33.780 --> 01:44:35.780]   Yeah, I said that.
[01:44:35.780 --> 01:44:36.780]   It's a new business model.
[01:44:36.780 --> 01:44:38.780]   The new screen sabers.
[01:44:38.780 --> 01:44:40.780]   How you develop a perfect laptop.
[01:44:40.780 --> 01:44:43.780]   What if you went to a thousand users and asked them?
[01:44:43.780 --> 01:44:45.780]   One is that you get a hot mess that no one can actually use.
[01:44:45.780 --> 01:44:48.780]   The other is that you get something awesome that everybody enjoys.
[01:44:48.780 --> 01:44:49.780]   It could be one or the other.
[01:44:49.780 --> 01:44:52.780]   We've got the Eve V computer.
[01:44:52.780 --> 01:44:53.780]   Windows Weekly.
[01:44:53.780 --> 01:44:55.780]   Paul Therat.
[01:44:55.780 --> 01:44:57.780]   He is in Maui.
[01:44:57.780 --> 01:45:00.780]   Qualcomm is having their Snapdragon tech summit here this year.
[01:45:00.780 --> 01:45:04.780]   The big news today was the 845, which is obviously the next generation bubble processor.
[01:45:04.780 --> 01:45:09.780]   But I think they got scooped just a little teeny wee bit by Microsoft.
[01:45:09.780 --> 01:45:13.780]   Which enacts that finally Woa is here, Windows on ARM.
[01:45:13.780 --> 01:45:15.780]   Security now.
[01:45:15.780 --> 01:45:22.780]   Last week, this horrific flaw in Mac OS, High Sierra, came out.
[01:45:22.780 --> 01:45:29.780]   There was a function which said, "I successfully determined whether you entered the proper password."
[01:45:29.780 --> 01:45:36.780]   But separately, there was whether or not you entered the proper password that the code wasn't checking.
[01:45:36.780 --> 01:45:38.780]   Success can mean different things to different people.
[01:45:38.780 --> 01:45:39.780]   Is the need, again.
[01:45:39.780 --> 01:45:41.780]   That's the moral of the story.
[01:45:41.780 --> 01:45:42.780]   Twit.
[01:45:42.780 --> 01:45:45.780]   It keeps going and going and going.
[01:45:45.780 --> 01:45:46.780]   Okay.
[01:45:46.780 --> 01:45:48.780]   That's kind of humiliating.
[01:45:48.780 --> 01:45:49.780]   I don't know.
[01:45:49.780 --> 01:45:53.780]   It's probably no worse than anything else you've done on the internet.
[01:45:53.780 --> 01:45:56.780]   It's kind of fun when you get everybody in there.
[01:45:56.780 --> 01:45:59.780]   [Laughter]
[01:45:59.780 --> 01:46:01.780]   Can I have some explain?
[01:46:01.780 --> 01:46:02.780]   Yeah, that's good.
[01:46:02.780 --> 01:46:03.780]   That's special.
[01:46:03.780 --> 01:46:06.780]   I don't think you should just leave it there.
[01:46:06.780 --> 01:46:08.780]   I think it's the next one.
[01:46:08.780 --> 01:46:09.780]   Put it back on the oven.
[01:46:09.780 --> 01:46:11.780]   That was, yes, Patrick Norton.
[01:46:11.780 --> 01:46:13.780]   Back on the new screensavers, he had a lot of fun on Saturday.
[01:46:13.780 --> 01:46:16.780]   Do watch that episode if you're fans of the old screensavers.
[01:46:16.780 --> 01:46:18.780]   It was very much like the good old days.
[01:46:18.780 --> 01:46:19.780]   Somebody's in the chatroom.
[01:46:19.780 --> 01:46:21.780]   Patrick has gone full lumberjack.
[01:46:21.780 --> 01:46:24.780]   He is beard and plaid.
[01:46:24.780 --> 01:46:26.780]   Unrecognizable almost.
[01:46:26.780 --> 01:46:27.780]   Really?
[01:46:27.780 --> 01:46:28.780]   No, I like the look.
[01:46:28.780 --> 01:46:29.780]   I really do.
[01:46:29.780 --> 01:46:30.780]   I think it's very, very, very...
[01:46:30.780 --> 01:46:31.780]   It's so much fun.
[01:46:31.780 --> 01:46:35.780]   It's always fun to go back and work with the people you've known for decades.
[01:46:35.780 --> 01:46:36.780]   Wow.
[01:46:36.780 --> 01:46:38.780]   Our show today brought to you by Captera.
[01:46:38.780 --> 01:46:43.780]   If you're working in the boss comes to you and says, you know, and it's always like Friday
[01:46:43.780 --> 01:46:45.780]   before the week before Christmas, right?
[01:46:45.780 --> 01:46:46.780]   It's going to happen.
[01:46:46.780 --> 01:46:50.780]   And says, "Smithers, we need new software to run this business.
[01:46:50.780 --> 01:46:52.780]   It's your job to find it."
[01:46:52.780 --> 01:46:55.780]   I'll come back to me Monday and have it.
[01:46:55.780 --> 01:46:59.780]   And you go, "Ah!" and you go, "What do you go to Google and search?"
[01:46:59.780 --> 01:47:03.780]   No, you go to Captera and you get home on time.
[01:47:03.780 --> 01:47:06.780]   You don't miss your TV show tonight.
[01:47:06.780 --> 01:47:13.780]   Whether you're looking to keep track of customers or a nonprofit hoping to have a record fundraising
[01:47:13.780 --> 01:47:20.780]   year, maybe you're a yoga studio or a bakery or on and on and on, 500 categories of business
[01:47:20.780 --> 01:47:23.780]   software, this is the best directory ever.
[01:47:23.780 --> 01:47:26.780]   Not just because it's got every piece of software.
[01:47:26.780 --> 01:47:31.780]   It's got 260,000 real reviews and ratings from real users just like you and it's free.
[01:47:31.780 --> 01:47:32.780]   Did I mention it's free?
[01:47:32.780 --> 01:47:33.780]   It's free!
[01:47:33.780 --> 01:47:39.780]   So you go to Captera.com, search for the category you need, check the box that says, "No, it
[01:47:39.780 --> 01:47:42.780]   has to do this, it has to do that, it's got to run on Windows, it's got to run on the net,"
[01:47:42.780 --> 01:47:43.780]   whatever it is.
[01:47:43.780 --> 01:47:45.780]   And you can narrow it right down.
[01:47:45.780 --> 01:47:51.780]   You won't waste time on, you know, googling stuff and finding, you know, page-chill reviews.
[01:47:51.780 --> 01:47:53.780]   You won't waste your time on free trials.
[01:47:53.780 --> 01:47:54.780]   It go nowhere.
[01:47:54.780 --> 01:47:57.780]   Captera's got everything you need to get your job done.
[01:47:57.780 --> 01:47:58.780]   Just look at all the categories.
[01:47:58.780 --> 01:48:04.780]   That means it goes on, there's accounting software and some, including fresh books are one of our
[01:48:04.780 --> 01:48:05.780]   sponsors.
[01:48:05.780 --> 01:48:07.780]   2018 is on the way and so is the boss.
[01:48:07.780 --> 01:48:09.780]   I hear him now coming down the hall.
[01:48:09.780 --> 01:48:10.780]   Smithers?
[01:48:10.780 --> 01:48:11.780]   Smithers?
[01:48:11.780 --> 01:48:13.780]   I've got a job for you, Smithers.
[01:48:13.780 --> 01:48:15.780]   You don't need to celebrate Christmas.
[01:48:15.780 --> 01:48:20.780]   So make sure you got the software your business needs today to help you do what you do better.
[01:48:20.780 --> 01:48:23.780]   Join the millions who use Captera free.
[01:48:23.780 --> 01:48:24.780]   Did I say free?
[01:48:24.780 --> 01:48:25.780]   Free!
[01:48:25.780 --> 01:48:27.780]   Captera, C-A-P-T-E-R-R-A.
[01:48:27.780 --> 01:48:29.780]   Captera.com/twit.
[01:48:29.780 --> 01:48:33.780]   To find the software, they'll save your business time.
[01:48:33.780 --> 01:48:34.780]   Captera.com/twit.
[01:48:34.780 --> 01:48:36.780]   We thank you so much for this support.
[01:48:36.780 --> 01:48:40.780]   This week at TechSerenity, Caldwell from iMOROT.com.
[01:48:40.780 --> 01:48:43.780]   The Grillmaster from Techburger by Silverman.
[01:48:43.780 --> 01:48:45.780]   So nice to see you again.
[01:48:45.780 --> 01:48:47.780]   It's so good to be here.
[01:48:47.780 --> 01:48:49.780]   Yeah, you like talking about it.
[01:48:49.780 --> 01:48:54.780]   See, Tech is a great subject to wax on and about because it's not really important, except that it is.
[01:48:54.780 --> 01:48:55.780]   It is.
[01:48:55.780 --> 01:48:56.780]   But nobody really dies.
[01:48:56.780 --> 01:48:58.780]   It's not like covering it.
[01:48:58.780 --> 01:48:59.780]   Sometimes they do.
[01:48:59.780 --> 01:49:01.780]   Well, I suppose.
[01:49:01.780 --> 01:49:02.780]   Yeah.
[01:49:02.780 --> 01:49:10.780]   No, it is the single biggest change agent in our society.
[01:49:10.780 --> 01:49:16.780]   And I would submit it's never boring because it's always something new, which is kind of fun.
[01:49:16.780 --> 01:49:23.780]   Also from the registered at co.uk our favorite Brit, Mr. Ian Thompson.
[01:49:23.780 --> 01:49:25.780]   Top 10 YouTube videos of the year.
[01:49:25.780 --> 01:49:26.780]   Who could forget?
[01:49:26.780 --> 01:49:27.780]   Oh, that kid was right.
[01:49:27.780 --> 01:49:30.780]   The BBC presenter, his kid.
[01:49:30.780 --> 01:49:32.780]   Okay, well, I love this still.
[01:49:32.780 --> 01:49:36.780]   And of course his wife then crawls in, pulls the kid out.
[01:49:36.780 --> 01:49:41.780]   That is, that is, but the, let's see, what are the top videos?
[01:49:41.780 --> 01:49:49.780]   They're of the top 10 videos, 633 million views, 40 million hours total.
[01:49:49.780 --> 01:49:55.780]   These are the top trending videos as of this week, according to the Verge.
[01:49:55.780 --> 01:49:56.780]   Oh, good grief.
[01:49:56.780 --> 01:49:57.780]   I don't know.
[01:49:57.780 --> 01:49:59.780]   A lot of it's music until we begin dusk by oyster masks.
[01:49:59.780 --> 01:50:00.780]   I think that's, I don't know.
[01:50:00.780 --> 01:50:01.780]   What is that?
[01:50:01.780 --> 01:50:02.780]   Is that an American?
[01:50:02.780 --> 01:50:05.780]   This looks like maybe Bollywood?
[01:50:05.780 --> 01:50:07.780]   What kind of, what is this?
[01:50:07.780 --> 01:50:09.780]   This is some, I don't recognize this.
[01:50:09.780 --> 01:50:10.780]   This is the number.
[01:50:10.780 --> 01:50:11.780]   They are, baby.
[01:50:11.780 --> 01:50:16.780]   They are, like, 186 million, 986,685 views.
[01:50:16.780 --> 01:50:18.780]   This is music.
[01:50:18.780 --> 01:50:19.780]   It's music.
[01:50:19.780 --> 01:50:20.780]   It's music.
[01:50:20.780 --> 01:50:21.780]   It's nice.
[01:50:21.780 --> 01:50:22.780]   It's nice music.
[01:50:22.780 --> 01:50:26.780]   But, plenty more, we will be, oh look, she's wearing a mask.
[01:50:26.780 --> 01:50:29.780]   Ooh, I don't know, I don't know what's going on.
[01:50:29.780 --> 01:50:30.780]   Okay, that's one.
[01:50:30.780 --> 01:50:32.780]   Let's see number two here.
[01:50:32.780 --> 01:50:34.780]   Number two is also a sign I have to play.
[01:50:34.780 --> 01:50:36.780]   It said she're in, you know it's she're in.
[01:50:36.780 --> 01:50:38.780]   Number three, dude, perfect.
[01:50:38.780 --> 01:50:39.780]   Ping pong.
[01:50:39.780 --> 01:50:41.780]   Ping, tah, let's see.
[01:50:41.780 --> 01:50:43.780]   But this, you would watch this over and over again.
[01:50:43.780 --> 01:50:44.780]   You'd wonder, how does he do it?
[01:50:44.780 --> 01:50:45.780]   How does he do it?
[01:50:45.780 --> 01:50:48.780]   It's sponsored by Oreo.
[01:50:48.780 --> 01:50:49.780]   They're Oreos.
[01:50:49.780 --> 01:50:50.780]   No, I wonder why.
[01:50:50.780 --> 01:50:51.780]   They're Oreos involved.
[01:50:51.780 --> 01:50:52.780]   Look at this.
[01:50:52.780 --> 01:50:53.780]   Wow.
[01:50:53.780 --> 01:50:54.780]   Okay, I'd watch this.
[01:50:54.780 --> 01:50:56.780]   This is like, okay, go, right?
[01:50:56.780 --> 01:50:58.780]   Ping pong tricks.
[01:50:58.780 --> 01:51:02.780]   And the thing is, I'm surprised this guy's not, if this guy's not making big money, he's
[01:51:02.780 --> 01:51:04.780]   got 95 million views and it's Oreo sponsored, right?
[01:51:04.780 --> 01:51:05.780]   Yeah, should be.
[01:51:05.780 --> 01:51:07.780]   Number three video on YouTube, okay?
[01:51:07.780 --> 01:51:11.780]   Something my favorite like that for the week was the Thomas the Tank Engine stunt video,
[01:51:11.780 --> 01:51:14.780]   which, if you haven't seen it, highly recommend.
[01:51:14.780 --> 01:51:15.780]   I haven't.
[01:51:15.780 --> 01:51:19.780]   Oh no, Thomas the Tank Engine doing stunts, trust me, it's worth a shot.
[01:51:19.780 --> 01:51:20.780]   America's got talent.
[01:51:20.780 --> 01:51:21.780]   I'm putting that online.
[01:51:21.780 --> 01:51:24.780]   Twelve-year-old singing ventriloquist gets the golden buzzer.
[01:51:24.780 --> 01:51:26.780]   Now, I don't even know what the golden buzzer is.
[01:51:26.780 --> 01:51:29.780]   Is that good or bad?
[01:51:29.780 --> 01:51:31.780]   I've never watched the show, to be honest.
[01:51:31.780 --> 01:51:32.780]   Yeah.
[01:51:32.780 --> 01:51:33.780]   You don't have to watch a show.
[01:51:33.780 --> 01:51:36.780]   No, it's just, it's having to watch Simon Cowell because he's got it.
[01:51:36.780 --> 01:51:38.780]   Does the Germans have a face for it?
[01:51:38.780 --> 01:51:39.780]   It's a phrase for it.
[01:51:39.780 --> 01:51:41.780]   It has a face exquisitely made for punching.
[01:51:41.780 --> 01:51:45.780]   It does beg to be sucked, doesn't it?
[01:51:45.780 --> 01:51:47.780]   Yeah, I wouldn't do that.
[01:51:47.780 --> 01:51:48.780]   Very good.
[01:51:48.780 --> 01:51:50.780]   So this is a 12-year-old ventriloquist.
[01:51:50.780 --> 01:51:52.780]   Number four, 42 million views.
[01:51:52.780 --> 01:51:55.780]   I suppose decided to enter the show.
[01:51:55.780 --> 01:51:56.780]   Well, it was one of my big dreams.
[01:51:56.780 --> 01:51:59.780]   I think people need a good kidney and a stupid teeth.
[01:51:59.780 --> 01:52:02.780]   But also I would really choose.
[01:52:02.780 --> 01:52:03.780]   Oh!
[01:52:03.780 --> 01:52:08.140]   More Ed Sheeran, number five, Carpool Karaoke, Lady Gaga's Super Bowl halftime show, which
[01:52:08.140 --> 01:52:14.140]   I even admit I've watched on YouTube a couple of times because it was amazing.
[01:52:14.140 --> 01:52:15.140]   How did she do that?
[01:52:15.140 --> 01:52:18.140]   Except when you realized that they taped much of it ahead of time.
[01:52:18.140 --> 01:52:20.140]   I kind of took the fun out of it.
[01:52:20.140 --> 01:52:23.140]   Bad lip reading of the Donald Trump inauguration speech.
[01:52:23.140 --> 01:52:26.140]   I could watch Bad lip reading all day.
[01:52:26.140 --> 01:52:27.140]   32 million views.
[01:52:27.140 --> 01:52:30.140]   This is number eight on the list.
[01:52:30.140 --> 01:52:31.140]   That's so important.
[01:52:31.140 --> 01:52:32.140]   You should have.
[01:52:32.140 --> 01:52:33.140]   Oh, surprised.
[01:52:33.140 --> 01:52:35.140]   I had some pretzels for you.
[01:52:35.140 --> 01:52:37.140]   You're a big one.
[01:52:37.140 --> 01:52:38.140]   You, Jerry.
[01:52:38.140 --> 01:52:40.140]   I'm always like this.
[01:52:40.140 --> 01:52:41.140]   Oh, yeah, sure.
[01:52:41.140 --> 01:52:42.140]   You're certainly not going to be.
[01:52:42.140 --> 01:52:44.140]   When can I see my company?
[01:52:44.140 --> 01:52:45.140]   Can't wait.
[01:52:45.140 --> 01:52:47.140]   Oh, it's just a...
[01:52:47.140 --> 01:52:51.140]   Oh, I love those bad lip readings.
[01:52:51.140 --> 01:52:52.140]   It's a good one.
[01:52:52.140 --> 01:52:53.140]   Here's a number eight.
[01:52:53.140 --> 01:52:54.140]   I'm sorry.
[01:52:54.140 --> 01:52:55.140]   That was number seven.
[01:52:55.140 --> 01:52:56.140]   History of the entire world.
[01:52:56.140 --> 01:52:58.140]   It's 19 minutes, 35 million views.
[01:52:58.140 --> 01:52:59.140]   Hi, you're on a rock.
[01:52:59.140 --> 01:53:00.140]   Floating in space.
[01:53:00.140 --> 01:53:01.140]   Pretty cool, huh?
[01:53:01.140 --> 01:53:02.140]   It's water.
[01:53:02.140 --> 01:53:03.140]   Actually, most of it's water.
[01:53:03.140 --> 01:53:04.140]   Okay.
[01:53:04.140 --> 01:53:05.140]   Whoa, whoa, whoa, whoa.
[01:53:05.140 --> 01:53:06.140]   It's all right.
[01:53:06.140 --> 01:53:07.140]   You know it's YouTube.
[01:53:07.140 --> 01:53:08.140]   It's sad.
[01:53:08.140 --> 01:53:09.140]   What do you expect?
[01:53:09.140 --> 01:53:10.140]   I'm sad.
[01:53:10.140 --> 01:53:11.140]   The kids watched this.
[01:53:11.140 --> 01:53:12.140]   They learned vocabulary.
[01:53:12.140 --> 01:53:13.140]   One time ago, actually never.
[01:53:13.140 --> 01:53:14.140]   And also now, nothing is nowhere.
[01:53:14.140 --> 01:53:15.140]   When?
[01:53:15.140 --> 01:53:16.140]   Never.
[01:53:16.140 --> 01:53:17.140]   Makes sense, right?
[01:53:17.140 --> 01:53:18.140]   Like I said, it didn't happen.
[01:53:18.140 --> 01:53:19.140]   Nothing was never anywhere.
[01:53:19.140 --> 01:53:20.140]   That's why it's been everywhere.
[01:53:20.140 --> 01:53:21.140]   Wow, that's very dada.
[01:53:21.140 --> 01:53:22.140]   I like that.
[01:53:22.140 --> 01:53:23.140]   Yeah.
[01:53:23.140 --> 01:53:24.140]   Yeah.
[01:53:24.140 --> 01:53:25.140]   That'd be true.
[01:53:25.140 --> 01:53:26.140]   It was a CPG.
[01:53:26.140 --> 01:53:27.140]   I love CPG.
[01:53:27.140 --> 01:53:28.140]   Yeah.
[01:53:28.140 --> 01:53:29.140]   He is brilliant.
[01:53:29.140 --> 01:53:30.140]   His stuff makes sense.
[01:53:30.140 --> 01:53:31.140]   Yeah.
[01:53:31.140 --> 01:53:32.140]   This is, you know, heartbeat.
[01:53:32.140 --> 01:53:39.260]   And short, a closeted boy runs the risk of being outed by his own heart after it pops
[01:53:39.260 --> 01:53:43.500]   out of his chest to chase show more.
[01:53:43.500 --> 01:53:46.860]   Oh no, to chase down the boy of his dreams.
[01:53:46.860 --> 01:53:47.860]   That's cute.
[01:53:47.860 --> 01:53:48.860]   You know what?
[01:53:48.860 --> 01:53:49.940]   This is quality.
[01:53:49.940 --> 01:53:52.700]   This is a quality animated short.
[01:53:52.700 --> 01:53:55.540]   I'd forgotten about this until it just showed up on this list.
[01:53:55.540 --> 01:53:59.380]   This is kind of an antidote to the other list, the top 10 earners.
[01:53:59.380 --> 01:54:02.380]   The top 10 viewed, many of these are really good.
[01:54:02.380 --> 01:54:03.380]   Yeah.
[01:54:03.380 --> 01:54:07.380]   And you could see grown up people watching them and enjoying them.
[01:54:07.380 --> 01:54:08.380]   This is quite cute.
[01:54:08.380 --> 01:54:09.380]   It's good animation.
[01:54:09.380 --> 01:54:13.380]   YouTube is a boon for short film makers, right?
[01:54:13.380 --> 01:54:22.020]   Yeah, this is a college short, like a final presentation, which is really amazing.
[01:54:22.020 --> 01:54:23.020]   What a boon.
[01:54:23.020 --> 01:54:25.580]   I mean, before you'd make this, there'd be no way to see it.
[01:54:25.580 --> 01:54:29.340]   Maybe if you were lucky, you'd get an anthology going to movie theaters and college down
[01:54:29.340 --> 01:54:30.340]   and so forth.
[01:54:30.340 --> 01:54:35.700]   But now thanks to YouTube, 32 million people have seen this video.
[01:54:35.700 --> 01:54:36.700]   That's awesome.
[01:54:36.700 --> 01:54:37.700]   Yeah.
[01:54:37.700 --> 01:54:41.940]   And it's a couple of college filmmakers, Beth David and Esteban Bravo.
[01:54:41.940 --> 01:54:44.300]   I hope they have amazing jobs right now.
[01:54:44.300 --> 01:54:47.140]   Well, if they don't, then somebody's missing the boat.
[01:54:47.140 --> 01:54:50.300]   But it is nice how you can actually get to see this, because I mean, for years I heard
[01:54:50.300 --> 01:54:52.540]   rumor of a film called Bambi Meek's Godzilla.
[01:54:52.540 --> 01:54:53.540]   Yeah.
[01:54:53.540 --> 01:54:54.540]   I've never actually seen it.
[01:54:54.540 --> 01:54:55.540]   Right.
[01:54:55.540 --> 01:54:57.380]   And then it wasn't until the internet came around, you could actually see it and see what
[01:54:57.380 --> 01:55:00.100]   the fuss was about and go, "This is brilliant."
[01:55:00.100 --> 01:55:01.100]   Yeah.
[01:55:01.100 --> 01:55:02.660]   Here is the number 10.
[01:55:02.660 --> 01:55:06.660]   But in my mind, this will always be number one in my heart.
[01:55:06.660 --> 01:55:07.660]   Children interrupt.
[01:55:07.660 --> 01:55:12.340]   The BBC knows it hasn't lost any of its charm, has it?
[01:55:12.340 --> 01:55:15.140]   I mean, he shoves the kid back.
[01:55:15.140 --> 01:55:17.740]   He tries to maintain his calm.
[01:55:17.740 --> 01:55:18.740]   That hurts me.
[01:55:18.740 --> 01:55:19.740]   Yeah.
[01:55:19.740 --> 01:55:22.940]   And the little kid comes in in the walker.
[01:55:22.940 --> 01:55:23.940]   Now mom comes in.
[01:55:23.940 --> 01:55:29.220]   By the way, mom's pants are halfway down, so she was obviously in the bathroom.
[01:55:29.220 --> 01:55:34.340]   And she's thinking out hoping that she's not on camera.
[01:55:34.340 --> 01:55:37.860]   Well, look at the children.
[01:55:37.860 --> 01:55:39.180]   I still get a kick.
[01:55:39.180 --> 01:55:40.820]   This is why YouTube works.
[01:55:40.820 --> 01:55:41.820]   And then the hand.
[01:55:41.820 --> 01:55:43.620]   It's not that much.
[01:55:43.620 --> 01:55:46.260]   This is what makes YouTube great, because that.
[01:55:46.260 --> 01:55:50.260]   I've had a lot more respect for you to actually pick up the kid and just put him on his neck.
[01:55:50.260 --> 01:55:51.260]   Yeah.
[01:55:51.260 --> 01:55:53.940]   The pushing away as Whit bothers me.
[01:55:53.940 --> 01:55:54.940]   Yeah.
[01:55:54.940 --> 01:55:57.380]   But we've seen interviews with him since.
[01:55:57.380 --> 01:56:01.180]   You know, I mean, we actually dissected this when it happened.
[01:56:01.180 --> 01:56:04.300]   You know, he was in the bedroom on a Skype call with the BBC.
[01:56:04.300 --> 01:56:05.820]   Oh, it's a bus.
[01:56:05.820 --> 01:56:11.100]   He's even, in fact, if you look at it, he's even got, he's carefully staged his bedroom.
[01:56:11.100 --> 01:56:14.420]   He's put some books on the bed there.
[01:56:14.420 --> 01:56:20.460]   He's got a world map behind him just to make it look feel a little bit like it's, you know,
[01:56:20.460 --> 01:56:22.220]   like something kind of professional.
[01:56:22.220 --> 01:56:23.740]   He's probably not wearing pants.
[01:56:23.740 --> 01:56:29.340]   But my suspicion is the reason he doesn't get up and get the kid is there's nothing below
[01:56:29.340 --> 01:56:30.340]   the tie.
[01:56:30.340 --> 01:56:32.140]   I mean, he's probably, we put on, he was wearing shorts.
[01:56:32.140 --> 01:56:34.300]   He went called by the BBC from dinner.
[01:56:34.300 --> 01:56:35.300]   I've been there.
[01:56:35.300 --> 01:56:36.300]   So yeah.
[01:56:36.300 --> 01:56:37.300]   Sure.
[01:56:37.300 --> 01:56:38.300]   And it's the beeb, right?
[01:56:38.300 --> 01:56:39.300]   You don't know.
[01:56:39.300 --> 01:56:43.180]   I mean, I did an interview with the BBC World Service at DEF CON this year.
[01:56:43.180 --> 01:56:44.180]   Yeah.
[01:56:44.180 --> 01:56:48.900]   And because we were doing it over Skype, we had to get the hotel room as quiet as possible.
[01:56:48.900 --> 01:56:51.060]   So I had to turn the air conditioning off.
[01:56:51.060 --> 01:56:53.620]   But because it was on radio, it didn't really matter that way.
[01:56:53.620 --> 01:56:57.660]   And so I did the entire interview with my pants and the temptation at the end of it say,
[01:56:57.660 --> 01:57:00.580]   "Stain, this has been Ian Thompson in his pants."
[01:57:00.580 --> 01:57:05.660]   By the way, for those of you who are not British, you have to explain in his pants,
[01:57:05.660 --> 01:57:07.100]   does it mean in his trousers?
[01:57:07.100 --> 01:57:08.100]   Oh, yes, sorry.
[01:57:08.100 --> 01:57:10.780]   It means not with trousers merely in his underpants.
[01:57:10.780 --> 01:57:11.780]   Just in my underpants.
[01:57:11.780 --> 01:57:13.700]   In freedom speech were just in my under way, yes.
[01:57:13.700 --> 01:57:14.860]   Is that what we call it now?
[01:57:14.860 --> 01:57:16.460]   Freedom speech is American.
[01:57:16.460 --> 01:57:18.460]   It's freedom speech.
[01:57:18.460 --> 01:57:19.460]   Let's see.
[01:57:19.460 --> 01:57:21.900]   What do you think since we were talking about Facebook?
[01:57:21.900 --> 01:57:26.420]   Facebook has launched a new messaging platform for kids.
[01:57:26.420 --> 01:57:30.420]   It's, yeah, they go to get them somehow.
[01:57:30.420 --> 01:57:32.740]   Yeah, scrolling my eyes at that.
[01:57:32.740 --> 01:57:35.980]   It's Facebook's version of Joe Camel and Candy Cigarettes.
[01:57:35.980 --> 01:57:38.020]   Oh, that's an erase analogy.
[01:57:38.020 --> 01:57:39.020]   Yeah.
[01:57:39.020 --> 01:57:43.060]   It's for six to 12-year-olds, people too young to be on Facebook because of the Child Online
[01:57:43.060 --> 01:57:45.020]   Protection and Privacy Act.
[01:57:45.020 --> 01:57:46.660]   It's very colorful.
[01:57:46.660 --> 01:57:51.380]   And the idea is parents will look how happy the music is.
[01:57:51.380 --> 01:57:52.380]   Will approve.
[01:57:52.380 --> 01:57:53.740]   Have the mom and go ahead and give me a hug.
[01:57:53.740 --> 01:57:56.580]   Oh, and Cheryl Sandberg was a mom.
[01:57:56.580 --> 01:57:57.580]   COO of Facebook.
[01:57:57.580 --> 01:57:59.580]   It must be good, right?
[01:57:59.580 --> 01:58:00.580]   Must be a little bit.
[01:58:00.580 --> 01:58:01.580]   She's a mom.
[01:58:01.580 --> 01:58:03.540]   As a mom.
[01:58:03.540 --> 01:58:07.980]   And so the idea is that you approve, they can only message with people you approve, obviously,
[01:58:07.980 --> 01:58:10.380]   friends and family, nobody else.
[01:58:10.380 --> 01:58:12.220]   Let's get those kids messaging.
[01:58:12.220 --> 01:58:13.220]   I think we should.
[01:58:13.220 --> 01:58:16.540]   Did I have mixed feelings about that because kids do want a message?
[01:58:16.540 --> 01:58:19.020]   They do, but it's a skill that's useful.
[01:58:19.020 --> 01:58:20.900]   Did you read the announcement about this?
[01:58:20.900 --> 01:58:24.580]   It was one of the creepiest things you could have made because they were saying, "We're
[01:58:24.580 --> 01:58:28.580]   not going to sell adverts to these kids and you're going to strip control over who they
[01:58:28.580 --> 01:58:33.700]   speak to, but we are going to share the information on their viewing habits within the Facebook
[01:58:33.700 --> 01:58:34.700]   family."
[01:58:34.700 --> 01:58:36.500]   Including advertisers, right?
[01:58:36.500 --> 01:58:40.580]   Yeah, so it's kind of where as well as really creepy, twisted families where everyone spies
[01:58:40.580 --> 01:58:42.700]   and everyone else.
[01:58:42.700 --> 01:58:47.020]   Now Facebook says, "There are no ads on Facebook on Messenger Kids.
[01:58:47.020 --> 01:58:50.660]   We will not use data for advertising.
[01:58:50.660 --> 01:58:54.060]   The provision about sharing information with vendors from the privacy policies for things
[01:58:54.060 --> 01:58:59.660]   like providing infrastructure to deliver messages, CDNs and things like that."
[01:58:59.660 --> 01:59:05.500]   On the other hand, Facebook's known for doing stuff first and then asking apologizing later.
[01:59:05.500 --> 01:59:06.500]   Yeah.
[01:59:06.500 --> 01:59:09.580]   Well, just because they're not showing it to the kids doesn't mean they're not showing
[01:59:09.580 --> 01:59:12.460]   things to their parents based on what the kids are saying.
[01:59:12.460 --> 01:59:13.460]   Well, that's the bigger issue.
[01:59:13.460 --> 01:59:14.460]   That's also true.
[01:59:14.460 --> 01:59:18.860]   You're getting somebody, what you want to do is get somebody in the Facebook meetgrinder
[01:59:18.860 --> 01:59:21.980]   as early as possible because the more data points you can get about that person.
[01:59:21.980 --> 01:59:22.980]   Yeah.
[01:59:22.980 --> 01:59:25.460]   By the time they are 13 and you can show them ads, you know a lot.
[01:59:25.460 --> 01:59:26.460]   You know everything.
[01:59:26.460 --> 01:59:28.060]   I think Dwight was spot on on this.
[01:59:28.060 --> 01:59:29.820]   Is Joe Camel all over again?
[01:59:29.820 --> 01:59:30.820]   Right.
[01:59:30.820 --> 01:59:31.820]   Yes.
[01:59:31.820 --> 01:59:33.620]   It's just like getting while they're young.
[01:59:33.620 --> 01:59:38.620]   Facebook isn't attracting young people anymore, so let's just get in there and in.
[01:59:38.620 --> 01:59:44.900]   How can we, how can we subvert a law passed in the 1990s to keep kids off of the Internet?
[01:59:44.900 --> 01:59:46.380]   Mm-hmm.
[01:59:46.380 --> 01:59:49.900]   Kids want to be on the Internet though and don't they need to become Internet natives?
[01:59:49.900 --> 01:59:52.220]   This is their, they're going to grow up in the world.
[01:59:52.220 --> 01:59:53.660]   They're going to be using all these tools.
[01:59:53.660 --> 01:59:58.500]   Is it just too early to do that or is Facebook not the right steward of the data that they're
[01:59:58.500 --> 01:59:59.500]   going to get?
[01:59:59.500 --> 02:00:00.500]   I think both.
[02:00:00.500 --> 02:00:04.140]   There are already kids on Facebook under 13, you know, they go on and the student names
[02:00:04.140 --> 02:00:07.380]   they put in the, you know, you don't, it's not hard to do.
[02:00:07.380 --> 02:00:12.940]   And you know, essentially if you can, if you're a parent, you can say to your kid, well, do
[02:00:12.940 --> 02:00:19.620]   this and maybe you won't, you know, get illicitly on full Facebook, but you know, kids are just
[02:00:19.620 --> 02:00:21.020]   going to be on both of them.
[02:00:21.020 --> 02:00:22.020]   Yeah.
[02:00:22.020 --> 02:00:25.060]   We signed, Lisa signed up our 14 year old for a 15 year old now.
[02:00:25.060 --> 02:00:30.420]   He just has birthday with Facebook when he was born so that she would have his name and
[02:00:30.420 --> 02:00:32.660]   let him in a constru, is it already?
[02:00:32.660 --> 02:00:33.820]   Well, that makes sense.
[02:00:33.820 --> 02:00:37.940]   I mean, I signed up for, I got my kids at don't comm addresses.
[02:00:37.940 --> 02:00:38.940]   Well, okay.
[02:00:38.940 --> 02:00:39.940]   Right.
[02:00:39.940 --> 02:00:46.100]   I mean, but at the same time she didn't let Michael use it until he was a little bit older.
[02:00:46.100 --> 02:00:50.220]   And I think the best thing to do would be to, if you're going to do it, train them and
[02:00:50.220 --> 02:00:55.420]   how to protect themselves and protect their privacy, use it as a, as a teaching tool so
[02:00:55.420 --> 02:00:59.060]   that they understand what Facebook can do with the information and why you don't want
[02:00:59.060 --> 02:01:00.660]   to give them too much information.
[02:01:00.660 --> 02:01:02.180]   I don't know.
[02:01:02.180 --> 02:01:06.260]   I have, I'm torn because these kids are going to grow up in this world.
[02:01:06.260 --> 02:01:09.700]   You can't keep them offline and hope that everything's going to work out.
[02:01:09.700 --> 02:01:10.700]   Of course.
[02:01:10.700 --> 02:01:15.940]   And I, I don't think I'm against kids being on the internet because God knows I was, you
[02:01:15.940 --> 02:01:20.380]   know, I was in messaging boards from the age of nine or eight or nine.
[02:01:20.380 --> 02:01:23.140]   Like, I, you know, it's, that's okay.
[02:01:23.140 --> 02:01:28.540]   But you make a really good point in that the security concerns have vastly changed.
[02:01:28.540 --> 02:01:34.100]   You know, when I was growing up, the internet concerns were okay, just don't give too much
[02:01:34.100 --> 02:01:38.700]   of information about yourself because you don't want to get fished by a 36 year old man
[02:01:38.700 --> 02:01:41.460]   looking to meet 13 year old girls on the internet.
[02:01:41.460 --> 02:01:44.900]   Now it's a lot more nefarious now it's, you don't actually, you don't have to worry about
[02:01:44.900 --> 02:01:45.900]   other people.
[02:01:45.900 --> 02:01:49.860]   You also have to worry about the companies and you also have to worry about, you know,
[02:01:49.860 --> 02:01:51.900]   specific data points that you're giving out.
[02:01:51.900 --> 02:01:56.020]   And if you're making up a fake, you know, a fake personality as many people often do
[02:01:56.020 --> 02:01:59.940]   when they're first going on the internet, be careful that that doesn't come back to
[02:01:59.940 --> 02:02:00.940]   by you either.
[02:02:00.940 --> 02:02:06.660]   Like there's, it's just so much, there's so much navigational straits that the kids have
[02:02:06.660 --> 02:02:09.260]   to go through these days that I don't know.
[02:02:09.260 --> 02:02:14.500]   I just, I feel like why add another layer of complication to it?
[02:02:14.500 --> 02:02:17.620]   Let's make this nice and friendly for children.
[02:02:17.620 --> 02:02:18.980]   No, you know what?
[02:02:18.980 --> 02:02:24.420]   Honestly, if you want to set your kids up with a group that they can talk to, if you
[02:02:24.420 --> 02:02:28.020]   want, you know, their friends or something like that, it makes much more sense to set
[02:02:28.020 --> 02:02:32.780]   them up with like a signal group or something with, you know, that's the hip parents that's
[02:02:32.780 --> 02:02:34.940]   a mother, I'm going to set you up with signal.
[02:02:34.940 --> 02:02:35.940]   True encryption.
[02:02:35.940 --> 02:02:36.940]   No, that's great.
[02:02:36.940 --> 02:02:37.940]   No, that's great.
[02:02:37.940 --> 02:02:40.140]   No, I'm agreeing with you.
[02:02:40.140 --> 02:02:41.140]   That's brilliant.
[02:02:41.140 --> 02:02:42.140]   Yeah.
[02:02:42.140 --> 02:02:43.140]   Don't set up it with Facebook.
[02:02:43.140 --> 02:02:45.420]   Set up it with signal.
[02:02:45.420 --> 02:02:46.420]   That's it.
[02:02:46.420 --> 02:02:48.140]   I think kids need to learn that you're right.
[02:02:48.140 --> 02:02:52.660]   The platform is now the, not the enemy, but the platform is the thing to be cautious about.
[02:02:52.660 --> 02:02:57.060]   But I don't think most adults in America really understand the risks and the hazards of what
[02:02:57.060 --> 02:03:02.180]   of Facebook in the way that we do, obviously.
[02:03:02.180 --> 02:03:06.340]   You see that you see this time and again with politicians getting elected for the first
[02:03:06.340 --> 02:03:07.340]   time.
[02:03:07.340 --> 02:03:08.340]   This has just been an issue in the UK.
[02:03:08.340 --> 02:03:11.980]   People then go through their social media feeds from the last few years, find something
[02:03:11.980 --> 02:03:15.460]   they've said which has been either objectionable or just downright stupid.
[02:03:15.460 --> 02:03:17.660]   And you know, this comes back to haunt people.
[02:03:17.660 --> 02:03:19.260]   I like kids who are grown.
[02:03:19.260 --> 02:03:22.300]   Well, I'm just glad I grew up in the nature of that digital photography.
[02:03:22.300 --> 02:03:24.020]   I mean, it's just, yeah.
[02:03:24.020 --> 02:03:25.020]   Yeah.
[02:03:25.020 --> 02:03:30.660]   I'm just glad that I used the internet before all of my friends and enemies were on the internet.
[02:03:30.660 --> 02:03:35.900]   I can't imagine going through high school with everybody in high school also on the internet
[02:03:35.900 --> 02:03:38.260]   and treating it as their personal domain.
[02:03:38.260 --> 02:03:40.420]   Twitter weaponizes bullying.
[02:03:40.420 --> 02:03:41.420]   Yeah.
[02:03:41.420 --> 02:03:42.420]   Right.
[02:03:42.420 --> 02:03:43.420]   All of them do.
[02:03:43.420 --> 02:03:45.940]   Yeah, any social network does, but I mean Twitter is the worst.
[02:03:45.940 --> 02:03:48.740]   Oh, which is a suspect of Villainan scumb.
[02:03:48.740 --> 02:03:49.740]   All right.
[02:03:49.740 --> 02:03:52.420]   Well, what about this?
[02:03:52.420 --> 02:03:53.740]   Do you have a voice assistant?
[02:03:53.740 --> 02:03:55.820]   Do you have an echo or a Google home in the house?
[02:03:55.820 --> 02:03:58.100]   If you have kids, do you let them talk to it?
[02:03:58.100 --> 02:03:59.420]   I don't have one in the house.
[02:03:59.420 --> 02:04:02.060]   I don't have my Google home and my echo and all that stuff.
[02:04:02.060 --> 02:04:04.420]   I feel like they're very useful.
[02:04:04.420 --> 02:04:05.420]   Here's a poll.
[02:04:05.420 --> 02:04:09.060]   Hi, I'm Gartenberg did on Twitter.
[02:04:09.060 --> 02:04:13.260]   Do you say please or thank you when you talk to echo or assistant?
[02:04:13.260 --> 02:04:15.940]   45% no, it's just a robot.
[02:04:15.940 --> 02:04:19.740]   32% sometimes 23% say yes.
[02:04:19.740 --> 02:04:20.740]   Spotted the bridge.
[02:04:20.740 --> 02:04:22.380]   So I always say please to my two young businesses.
[02:04:22.380 --> 02:04:24.380]   Do you say please to your echo and your assistant?
[02:04:24.380 --> 02:04:25.580]   Well, that's why it's a Google assistant.
[02:04:25.580 --> 02:04:27.220]   Yes, it's just politeness.
[02:04:27.220 --> 02:04:29.220]   You know, it costs nothing.
[02:04:29.220 --> 02:04:34.660]   I think it's a here's my when we talked about this a little bit, but my thought is you should
[02:04:34.660 --> 02:04:39.020]   teach kids that the difference between a machine and a human and not very important
[02:04:39.020 --> 02:04:41.860]   not to anthropomorphize talking machines.
[02:04:41.860 --> 02:04:47.180]   Again, an opportunity to say now you understand that's just a machine.
[02:04:47.180 --> 02:04:49.540]   Even though it has a human voice, it's just a machine.
[02:04:49.540 --> 02:04:52.940]   You remember sex education was the worst thing you had to talk to your kids about.
[02:04:52.940 --> 02:04:53.940]   Oh my God.
[02:04:53.940 --> 02:04:54.940]   That's nothing.
[02:04:54.940 --> 02:04:55.940]   It's an educational well.
[02:04:55.940 --> 02:04:59.020]   Now, you too, but you too, but can't say learn about sex, but let's talk later about
[02:04:59.020 --> 02:05:00.020]   privacy.
[02:05:00.020 --> 02:05:03.780]   Have you seen that the UK series called humans?
[02:05:03.780 --> 02:05:05.140]   No, I hear it's very.
[02:05:05.140 --> 02:05:08.420]   Oh, that's the one with the robots the human robots.
[02:05:08.420 --> 02:05:09.420]   Yes, love.
[02:05:09.420 --> 02:05:12.500]   And what's ever seen it.
[02:05:12.500 --> 02:05:14.420]   Oh, it's really good.
[02:05:14.420 --> 02:05:15.940]   It's from the UK.
[02:05:15.940 --> 02:05:16.940]   It is.
[02:05:16.940 --> 02:05:19.500]   I think there's two or three seasons of it.
[02:05:19.500 --> 02:05:25.940]   And essentially they are they are they call them since and they are they look exactly they
[02:05:25.940 --> 02:05:26.940]   look like humans.
[02:05:26.940 --> 02:05:33.900]   They have these glowing eyes and somebody uploads into all the sense a a program that
[02:05:33.900 --> 02:05:36.420]   gives them consciousness.
[02:05:36.420 --> 02:05:40.740]   And they essentially begin to say we don't want to be treated like this because people
[02:05:40.740 --> 02:05:44.700]   treat them like machines, even though they're not.
[02:05:44.700 --> 02:05:48.780]   And it is it's a pretty interesting and very I think prescient series.
[02:05:48.780 --> 02:05:51.300]   If you haven't seen it, it's definitely worth catching.
[02:05:51.300 --> 02:05:52.780]   Oh, that goes on my playlist.
[02:05:52.780 --> 02:05:53.780]   That's excellent.
[02:05:53.780 --> 02:05:54.780]   Thank you.
[02:05:54.780 --> 02:05:55.780]   Well, it's the British.
[02:05:55.780 --> 02:05:57.260]   I was trying to remember the last time you were here, there was a show you said you have
[02:05:57.260 --> 02:05:59.380]   to watch British space spaced.
[02:05:59.380 --> 02:06:01.620]   Yeah, I'm making a list.
[02:06:01.620 --> 02:06:06.860]   Although the marvelous Mrs. Maisel on Amazon is fabulous period piece.
[02:06:06.860 --> 02:06:07.860]   1957.
[02:06:07.860 --> 02:06:08.860]   Isn't it great?
[02:06:08.860 --> 02:06:10.100]   I figured you like it.
[02:06:10.100 --> 02:06:11.100]   It's right up your alley.
[02:06:11.100 --> 02:06:12.100]   I just had that feeling.
[02:06:12.100 --> 02:06:13.380]   Maybe Sherman Paladino.
[02:06:13.380 --> 02:06:14.380]   How can you not like anything?
[02:06:14.380 --> 02:06:15.380]   The Gossack Girl, right?
[02:06:15.380 --> 02:06:16.380]   Yeah.
[02:06:16.380 --> 02:06:17.860]   She's a Gilmore Girl.
[02:06:17.860 --> 02:06:18.860]   Gilmore Girls.
[02:06:18.860 --> 02:06:20.340]   No, no, no, that's not quite not.
[02:06:20.340 --> 02:06:24.420]   Is this is this show that Amazon is spooling out one episode at a time?
[02:06:24.420 --> 02:06:25.420]   No.
[02:06:25.420 --> 02:06:26.420]   As opposed to.
[02:06:26.420 --> 02:06:27.420]   Oh, they do have dumped it all.
[02:06:27.420 --> 02:06:32.140]   There's some show where one of them is like doing it episodically like traditional television.
[02:06:32.140 --> 02:06:33.140]   I forget which one it is.
[02:06:33.140 --> 02:06:34.140]   That seems like a bad idea.
[02:06:34.140 --> 02:06:35.140]   But that's really interesting.
[02:06:35.140 --> 02:06:36.140]   Yeah.
[02:06:36.140 --> 02:06:37.140]   No, particularly for that.
[02:06:37.140 --> 02:06:38.140]   We got through that.
[02:06:38.140 --> 02:06:41.300]   The Brown watch, we've got, I've got now space to watch.
[02:06:41.300 --> 02:06:47.180]   But if you get a chance, the marvelous Mrs. Maisel, because it's 1958 New York, beautifully
[02:06:47.180 --> 02:06:55.260]   rendered great music and a very strong female lead that is so good, so much fun.
[02:06:55.260 --> 02:06:57.220]   And Kevin Pollock is fabulous in it.
[02:06:57.220 --> 02:07:00.780]   So is Tony Shalub, really good cast.
[02:07:00.780 --> 02:07:03.860]   I've just had the Norseman recommended to me and I watched a couple of episodes, which
[02:07:03.860 --> 02:07:06.740]   seemed quite, since it's Viking, is set in the Viking.
[02:07:06.740 --> 02:07:08.580]   It's kind of like a lot of mileage out of the Vikings.
[02:07:08.580 --> 02:07:11.980]   It's kind of like a comedy thing though, because one of the guys punches a slave and goes,
[02:07:11.980 --> 02:07:15.420]   "You know, John, I'm not sure about this force-based management system.
[02:07:15.420 --> 02:07:16.420]   It's just you."
[02:07:16.420 --> 02:07:17.420]   I'm watching it.
[02:07:17.420 --> 02:07:18.420]   That's it.
[02:07:18.420 --> 02:07:19.420]   I'm watching it.
[02:07:19.420 --> 02:07:20.420]   Good time.
[02:07:20.420 --> 02:07:21.420]   The office meets Vikings.
[02:07:21.420 --> 02:07:22.420]   Yeah.
[02:07:22.420 --> 02:07:25.860]   You know, my favorite guilty pleasure show, and this is a weird one out of left field, but
[02:07:25.860 --> 02:07:27.860]   I've really enjoyed Riverdale.
[02:07:27.860 --> 02:07:30.380]   I don't know if anybody's actually watched.
[02:07:30.380 --> 02:07:33.220]   Archie Comics meets Twin Peaks.
[02:07:33.220 --> 02:07:36.460]   It's really weird and really like, it shouldn't be good.
[02:07:36.460 --> 02:07:40.300]   It is a CW show that by all rights and means should be terrible.
[02:07:40.300 --> 02:07:43.180]   Yet the costume design and the writing is excellent.
[02:07:43.180 --> 02:07:45.780]   It's literally Archie and his day.
[02:07:45.780 --> 02:07:47.580]   It's literally Archie Comics.
[02:07:47.580 --> 02:07:49.580]   It's literally Archie Comics.
[02:07:49.580 --> 02:07:51.780]   But it's like Smallville or something.
[02:07:51.780 --> 02:07:52.740]   It's like a reinvented-
[02:07:52.740 --> 02:07:53.740]   No, no.
[02:07:53.740 --> 02:07:55.700]   I mean, it is reinvented, but it's more.
[02:07:55.700 --> 02:07:58.540]   It's definitely, it's Archie Comics in a mystery show.
[02:07:58.540 --> 02:08:00.380]   I'm watching this for sure.
[02:08:00.380 --> 02:08:04.060]   It's really, it's like, it's guilty pleasure TV, but it knows what it is.
[02:08:04.060 --> 02:08:05.460]   It's covered on it.
[02:08:05.460 --> 02:08:06.460]   It's like a confetti.
[02:08:06.460 --> 02:08:08.060]   Jugheads in it.
[02:08:08.060 --> 02:08:09.060]   Holy cow.
[02:08:09.060 --> 02:08:10.180]   I'll be watching this.
[02:08:10.180 --> 02:08:11.180]   Exactly.
[02:08:11.180 --> 02:08:13.300]   There's too much good TV.
[02:08:13.300 --> 02:08:14.300]   That's the real problem.
[02:08:14.300 --> 02:08:15.300]   Let's take a break.
[02:08:15.300 --> 02:08:16.380]   I do want to talk about Windows on ARM.
[02:08:16.380 --> 02:08:17.380]   Go ahead.
[02:08:17.380 --> 02:08:18.380]   You get one too.
[02:08:18.380 --> 02:08:19.380]   One more.
[02:08:19.380 --> 02:08:22.820]   So there's this show on Netflix called Dark.
[02:08:22.820 --> 02:08:25.220]   That is so freakin' dark.
[02:08:25.220 --> 02:08:26.980]   It is very German.
[02:08:26.980 --> 02:08:27.980]   It is very German.
[02:08:27.980 --> 02:08:29.740]   It's the German Stranger Things.
[02:08:29.740 --> 02:08:30.740]   It's the only way to describe it.
[02:08:30.740 --> 02:08:32.820]   It's like black mirror, but done American stuff.
[02:08:32.820 --> 02:08:33.820]   No, it's Stranger Things.
[02:08:33.820 --> 02:08:34.820]   No, no, no.
[02:08:34.820 --> 02:08:35.820]   It's very similar to Stranger Things.
[02:08:35.820 --> 02:08:37.260]   But it's all in German.
[02:08:37.260 --> 02:08:38.260]   With bad...
[02:08:38.260 --> 02:08:41.460]   It's Stranger Things Without Any Humor, which is very German.
[02:08:41.460 --> 02:08:44.340]   And it's very, it's very despairing.
[02:08:44.340 --> 02:08:47.300]   The only thing I don't like about it is that it's dubbing is terrible.
[02:08:47.300 --> 02:08:49.500]   Well, don't watch the dubbing.
[02:08:49.500 --> 02:08:50.500]   Watch the...
[02:08:50.500 --> 02:08:52.340]   Oh, they have a version that's a...
[02:08:52.340 --> 02:08:53.340]   Subtitled?
[02:08:53.340 --> 02:08:54.340]   Yes.
[02:08:54.340 --> 02:08:56.100]   Because God, the dubbing is so...
[02:08:56.100 --> 02:08:58.220]   You feel like you're watching a comedy.
[02:08:58.220 --> 02:09:00.020]   Never, never, ever watch dubbing.
[02:09:00.020 --> 02:09:03.420]   Oh, I didn't know they have different versions, okay.
[02:09:03.420 --> 02:09:04.420]   Yes, yes.
[02:09:04.420 --> 02:09:05.660]   Watch the one with it.
[02:09:05.660 --> 02:09:10.020]   Because in German, it's even more intense.
[02:09:10.020 --> 02:09:11.020]   Oh, you can imagine.
[02:09:11.020 --> 02:09:12.020]   I mean, Germany is very...
[02:09:12.020 --> 02:09:13.020]   Is very sort of...
[02:09:13.020 --> 02:09:14.980]   Do you have audio on this?
[02:09:14.980 --> 02:09:16.660]   Let's hear the audio.
[02:09:16.660 --> 02:09:18.620]   Germany is such a dark and brutal language.
[02:09:18.620 --> 02:09:20.620]   It's why you never get great German love poets.
[02:09:20.620 --> 02:09:21.620]   It's just like...
[02:09:21.620 --> 02:09:22.620]   I'm so into it.
[02:09:22.620 --> 02:09:23.620]   Oh, yes.
[02:09:23.620 --> 02:09:25.620]   And then there's dark.
[02:09:25.620 --> 02:09:26.620]   Yeah.
[02:09:26.620 --> 02:09:30.260]   Things go wrong.
[02:09:30.260 --> 02:09:31.620]   It's very strange, you think.
[02:09:31.620 --> 02:09:32.620]   Yeah.
[02:09:32.620 --> 02:09:35.780]   But it's the first Netflix original produced in the outside the US, right?
[02:09:35.780 --> 02:09:36.780]   These are shut up.
[02:09:36.780 --> 02:09:37.940]   We're going to see a lot more of these.
[02:09:37.940 --> 02:09:40.140]   They're getting really into the production game.
[02:09:40.140 --> 02:09:41.140]   And they're doing...
[02:09:41.140 --> 02:09:44.020]   They're spending $8 billion this year.
[02:09:44.020 --> 02:09:47.140]   And that's just a fraction of what they plan to spend next year.
[02:09:47.140 --> 02:09:48.140]   Yeah.
[02:09:48.140 --> 02:09:49.140]   Unbelievable.
[02:09:49.140 --> 02:09:51.780]   You must look at pay their taxes as well, but hey, you know...
[02:09:51.780 --> 02:09:54.780]   I have to watch it over again in German because it was terrible.
[02:09:54.780 --> 02:09:58.580]   If you want a comedy, watch the dumb part.
[02:09:58.580 --> 02:10:00.260]   The acting is so bad.
[02:10:00.260 --> 02:10:01.260]   It's horrible.
[02:10:01.260 --> 02:10:03.060]   Our show today brought to you by Texture.
[02:10:03.060 --> 02:10:04.060]   I love magazines.
[02:10:04.060 --> 02:10:05.140]   Who doesn't love magazines?
[02:10:05.140 --> 02:10:09.820]   I got to tell you though, with the cost and the clutter of buying magazines, even if you
[02:10:09.820 --> 02:10:12.100]   subscribe, then there's the guilt factor.
[02:10:12.100 --> 02:10:14.420]   I got a pile of New Yorkers I never read.
[02:10:14.420 --> 02:10:19.580]   And I feel like I can't read the New New Yorker until I've read all the old New Yorkers.
[02:10:19.580 --> 02:10:20.580]   That's why I got Texture.
[02:10:20.580 --> 02:10:21.580]   And now I love it.
[02:10:21.580 --> 02:10:24.020]   It's the app the iPad was invented for.
[02:10:24.020 --> 02:10:26.580]   Works on iPad, Android, iOS.
[02:10:26.580 --> 02:10:32.420]   It is more than 200 magazines, all the best magazines in the country, for less than $10
[02:10:32.420 --> 02:10:34.180]   a month, flat fee.
[02:10:34.180 --> 02:10:36.260]   It's Netflix for magazines.
[02:10:36.260 --> 02:10:40.700]   And you've not only got every page of the current newsstand issue, but back issues, bonus
[02:10:40.700 --> 02:10:45.180]   features that you don't get in a magazine like video, photography magazines like Shutterbug
[02:10:45.180 --> 02:10:49.060]   and National Geographic look so much better because you're instead of seeing a bad print
[02:10:49.060 --> 02:10:52.460]   of the photo you're seeing it on your screen.
[02:10:52.460 --> 02:10:53.740]   And it looks gorgeous.
[02:10:53.740 --> 02:10:56.420]   The New Yorker, Vanity Fair, Wired.
[02:10:56.420 --> 02:11:01.180]   I get all my gossip from us and entertainment weekly and people.
[02:11:01.180 --> 02:11:02.500]   They're all there.
[02:11:02.500 --> 02:11:08.220]   If you look into vacation time, if a far and Airbnb magazine, if you like to cook, bon appetit
[02:11:08.220 --> 02:11:13.060]   and real simple, I can go on and on the Atlantic time if you like politics, it's all in there
[02:11:13.060 --> 02:11:15.500]   texture and to start your free texture trial.
[02:11:15.500 --> 02:11:20.140]   Free, did I say free, free texture trial, go to texture.com/twit.
[02:11:20.140 --> 02:11:25.580]   And we have a very special deal because normally if you want it, I think it's $12, $13 a month.
[02:11:25.580 --> 02:11:30.380]   But if you are, go to texture.com/twit and decide to subscribe, you'll get it for just
[02:11:30.380 --> 02:11:33.380]   $9.99 a month, 30% off the listed price.
[02:11:33.380 --> 02:11:38.140]   And what a great gift for family and friends.
[02:11:38.140 --> 02:11:43.660]   This is the future of magazines, in my opinion, all the best magazines, flat rate right there
[02:11:43.660 --> 02:11:45.980]   in your iPad or your iPhone or your Android device.
[02:11:45.980 --> 02:11:49.420]   Go to texture.com/twit to start your free trial today.
[02:11:49.420 --> 02:11:51.620]   We thank texture for their support.
[02:11:51.620 --> 02:11:55.060]   Whatever I travel, I have texture with me.
[02:11:55.060 --> 02:11:56.700]   Windows on ARM.
[02:11:56.700 --> 02:11:58.820]   Qualcomm had a big event in Maui.
[02:11:58.820 --> 02:12:00.700]   Paul Thoreg got to go.
[02:12:00.700 --> 02:12:02.780]   Ryan Shrout got to go.
[02:12:02.780 --> 02:12:04.100]   Lots of people we know got to go.
[02:12:04.100 --> 02:12:05.100]   We didn't get to go.
[02:12:05.100 --> 02:12:07.300]   They announced the Snapdragon 845.
[02:12:07.300 --> 02:12:15.940]   But interestingly, that was scooped by the Snapdragon 835 based Windows devices with
[02:12:15.940 --> 02:12:21.940]   quote all day power.
[02:12:21.940 --> 02:12:26.500]   If I were Intel, I'd be freaking out right now.
[02:12:26.500 --> 02:12:28.340]   This is not Intel's year.
[02:12:28.340 --> 02:12:31.060]   Well, first they lose mobile, right?
[02:12:31.060 --> 02:12:35.500]   Qualcomm and the ARM family just destroy them on mobile.
[02:12:35.500 --> 02:12:39.740]   Apple uses ARM architecture license, but they make their own chips essentially like ARM
[02:12:39.740 --> 02:12:43.300]   chips, Qualcomms and everything else.
[02:12:43.300 --> 02:12:47.140]   But at least Intel still had the desktop and they still have the network center.
[02:12:47.140 --> 02:12:50.380]   ARM is in the network center now because it's power.
[02:12:50.380 --> 02:12:52.620]   It's power curve is good.
[02:12:52.620 --> 02:12:56.140]   You don't use a lot of energy and they seem to do a decent job.
[02:12:56.140 --> 02:12:58.380]   You're right until probably still owns the premium.
[02:12:58.380 --> 02:13:03.060]   But yes, this fundamentally attacks the wind cell and ons, which has gone on with Windows
[02:13:03.060 --> 02:13:05.740]   pretty much since the start.
[02:13:05.740 --> 02:13:08.140]   The big question here is can they make it work?
[02:13:08.140 --> 02:13:12.380]   Because our guy was trying these new laptops out in Maui and he was saying you're looking
[02:13:12.380 --> 02:13:13.860]   at double the lag time.
[02:13:13.860 --> 02:13:14.940]   Oh, that's not good.
[02:13:14.940 --> 02:13:18.500]   If he was typing fast, the words were appearing off to eat.
[02:13:18.500 --> 02:13:19.500]   Oh, that's not good.
[02:13:19.500 --> 02:13:20.500]   Type them.
[02:13:20.500 --> 02:13:21.500]   Can't keep up.
[02:13:21.500 --> 02:13:22.500]   Because it has to use emulation on certain apps.
[02:13:22.500 --> 02:13:25.420]   Now they're going to port office, Microsoft Office to ARM.
[02:13:25.420 --> 02:13:28.780]   So you hopefully get rid of the emulation lag there.
[02:13:28.780 --> 02:13:35.220]   You know, it's really, in fact, the new devices which come from Lenovo and Acer and others
[02:13:35.220 --> 02:13:41.100]   start with Windows 10S, which is the version of Windows that is low power and only runs
[02:13:41.100 --> 02:13:44.220]   apps, UWP apps from the Windows Store.
[02:13:44.220 --> 02:13:46.940]   And those probably, I would guess, run at full speed.
[02:13:46.940 --> 02:13:47.940]   They're designed to run on ARM.
[02:13:47.940 --> 02:13:49.140]   They're compiled for ARM.
[02:13:49.140 --> 02:13:53.180]   But if you get, if you said I want to upgrade it to Windows 10 Pro and I want to put Chrome
[02:13:53.180 --> 02:13:55.180]   on it, Chrome would not run well.
[02:13:55.180 --> 02:13:59.580]   No, you've got to run it through an emulator which can add, but the estimates they saw
[02:13:59.580 --> 02:14:06.180]   was basically, it doesn't quite double the speeds, but it nearly doubles them.
[02:14:06.180 --> 02:14:08.220]   And that's really, really worrying.
[02:14:08.220 --> 02:14:12.540]   But I think the Windows 10S is key on this one because I think they're clearly aiming
[02:14:12.540 --> 02:14:14.980]   this at student markets.
[02:14:14.980 --> 02:14:16.780]   But I just looking at the prices of some of these things.
[02:14:16.780 --> 02:14:17.780]   They're not that low.
[02:14:17.780 --> 02:14:18.780]   They're five to seven hundred bucks.
[02:14:18.780 --> 02:14:19.780]   Yeah, 800 in some cases.
[02:14:19.780 --> 02:14:20.780]   Yeah.
[02:14:20.780 --> 02:14:21.780]   And I don't know.
[02:14:21.780 --> 02:14:22.780]   I don't know what the others feel about this.
[02:14:22.780 --> 02:14:27.980]   That just seems an insane price for essentially just like a big battery Windows machine.
[02:14:27.980 --> 02:14:28.980]   Yeah.
[02:14:28.980 --> 02:14:30.460]   They also only run 32-bit.
[02:14:30.460 --> 02:14:34.980]   You have to run 32-bit apps using Windows Pro.
[02:14:34.980 --> 02:14:35.980]   That's the emulation.
[02:14:35.980 --> 02:14:36.980]   This is not right.
[02:14:36.980 --> 02:14:37.980]   Yeah.
[02:14:37.980 --> 02:14:38.980]   Yeah, that's not ideal.
[02:14:38.980 --> 02:14:41.060]   And not everything will run on it.
[02:14:41.060 --> 02:14:45.900]   So for example, there are some classes of antivirus that won't run at all on it.
[02:14:45.900 --> 02:14:51.580]   And it kind of reminds me, remember Leo the 95% IBM compatible computers.
[02:14:51.580 --> 02:14:54.780]   That's what those reminds me of.
[02:14:54.780 --> 02:14:55.780]   Yeah.
[02:14:55.780 --> 02:14:57.780]   God, really that was a thing?
[02:14:57.780 --> 02:14:58.780]   Jeez.
[02:14:58.780 --> 02:14:59.780]   Yes.
[02:14:59.780 --> 02:15:00.780]   Yes.
[02:15:00.780 --> 02:15:02.380]   They were advertised and they were clones.
[02:15:02.380 --> 02:15:03.380]   Mostly compatible.
[02:15:03.380 --> 02:15:04.380]   Mostly compatible.
[02:15:04.380 --> 02:15:06.380]   Or even they even had percentages.
[02:15:06.380 --> 02:15:10.580]   What is like when Windows came out with the Vista Capables sticker?
[02:15:10.580 --> 02:15:12.420]   You know, it's like technically Capable.
[02:15:12.420 --> 02:15:15.980]   This machine is capable of running Vista, but you wouldn't want to try it.
[02:15:15.980 --> 02:15:17.780]   Don't do it.
[02:15:17.780 --> 02:15:18.780]   Yeah.
[02:15:18.780 --> 02:15:25.020]   Unfortunately, Intel is also having a problem with its management engine, the Intel management
[02:15:25.020 --> 02:15:34.500]   engine, which is in almost all Intel chips, not normally designed to hook up to management
[02:15:34.500 --> 02:15:37.980]   unless you have a VPro system and you have an Intel network card.
[02:15:37.980 --> 02:15:39.100]   And so there are ways to mitigate that.
[02:15:39.100 --> 02:15:45.260]   The problem is there are at last count seven CVEs, that's seven exploits that could be
[02:15:45.260 --> 02:15:50.260]   taken advantage of if an attacker had local access to your system.
[02:15:50.260 --> 02:15:59.220]   So it's the point now where Dell, Lenovo, Purism, System 76 are offering PCs with the
[02:15:59.220 --> 02:16:01.740]   Intel management engine physically disabled.
[02:16:01.740 --> 02:16:02.740]   Yeah.
[02:16:02.740 --> 02:16:03.740]   And you got to pay with Dell's case.
[02:16:03.740 --> 02:16:06.580]   You got to pay, I think it's 23 bucks to actually get it enabled.
[02:16:06.580 --> 02:16:07.580]   That's worth it.
[02:16:07.580 --> 02:16:08.580]   Yeah, don't.
[02:16:08.580 --> 02:16:13.260]   I mean, I guess if you are an enterprise, that's a use of the management engine is designed
[02:16:13.260 --> 02:16:14.260]   for enterprise.
[02:16:14.260 --> 02:16:16.340]   But there are some big problems.
[02:16:16.340 --> 02:16:20.740]   And we had been talking about this last month, but they're back again.
[02:16:20.740 --> 02:16:23.980]   Intel has published a page with a program you can run.
[02:16:23.980 --> 02:16:28.420]   If you are using a Windows or Linux machine, you might want to run this program to see
[02:16:28.420 --> 02:16:30.220]   if your system is vulnerable.
[02:16:30.220 --> 02:16:31.220]   Yeah.
[02:16:31.220 --> 02:16:34.860]   So we have enough problems getting people to patch software now, you know, with that
[02:16:34.860 --> 02:16:36.580]   hardware, patch the actual hardware.
[02:16:36.580 --> 02:16:40.620]   I mean, chances of getting most people to do that, pretty much minimal.
[02:16:40.620 --> 02:16:48.300]   There is a remote vulnerability exploit, CVE 2017, 5712 with a valid administrative
[02:16:48.300 --> 02:16:51.700]   Intel management engine credential.
[02:16:51.700 --> 02:16:55.620]   So that means somebody would have still had to hack you at first, but then they could
[02:16:55.620 --> 02:16:57.780]   have remotely access your system.
[02:16:57.780 --> 02:17:02.780]   And Steve Gibson reported this last week on security now that there's a JTAG engine is
[02:17:02.780 --> 02:17:07.140]   exposed, which means that you could use the USB 4 to hack your machines.
[02:17:07.140 --> 02:17:12.820]   You just come along, you got a just little USB dongle plugging in and you're done.
[02:17:12.820 --> 02:17:18.260]   So this gives you full access, root and everything might want to might want to check with your
[02:17:18.260 --> 02:17:20.700]   motherboard manufacturers, see what their plans are.
[02:17:20.700 --> 02:17:24.740]   So a bad week for Intel all around.
[02:17:24.740 --> 02:17:27.500]   Johnny I've is back taking control of Apple's design team.
[02:17:27.500 --> 02:17:30.660]   I think I have to say, yay.
[02:17:30.660 --> 02:17:31.660]   Yay feels like Apple's.
[02:17:31.660 --> 02:17:32.660]   Did he ever leave?
[02:17:32.660 --> 02:17:35.940]   Yeah, he was doing the campus.
[02:17:35.940 --> 02:17:38.340]   He had focusing on the campus.
[02:17:38.340 --> 02:17:41.980]   Well, I didn't see a lot of his presence.
[02:17:41.980 --> 02:17:46.660]   They had two guys, Alan Dye, Vice President of Utider Interface Design and Richard Haworth,
[02:17:46.660 --> 02:17:50.980]   Vice President of Industrial Design running the design for the last two years.
[02:17:50.980 --> 02:17:55.260]   They just disappeared from, they're non-persons.
[02:17:55.260 --> 02:17:59.100]   They've disappeared now from the management page at apple.com.
[02:17:59.100 --> 02:18:07.140]   Johnny and Johnny I've, after an inquiry from Bloomberg has said, yes, I am in control.
[02:18:07.140 --> 02:18:12.540]   And I think a good thing because iOS 11 had all sorts of problems.
[02:18:12.540 --> 02:18:18.260]   Apple has had a lot of security issues, but just mostly on iOS 11 cosmetic and performance
[02:18:18.260 --> 02:18:19.260]   issues.
[02:18:19.260 --> 02:18:23.460]   Yeah, I think there's also an innovation problem in there that they haven't really come up
[02:18:23.460 --> 02:18:26.220]   with a new product in the last five years.
[02:18:26.220 --> 02:18:29.900]   I mean, yeah, the other was the watch, but that's kind of everyone else is doing it.
[02:18:29.900 --> 02:18:31.420]   They were just copying it.
[02:18:31.420 --> 02:18:36.260]   But there seems to be a real innovation lack in Apple at the moment in terms of where they're
[02:18:36.260 --> 02:18:37.660]   what they're going to do after the other.
[02:18:37.660 --> 02:18:39.060]   Tim is not an innovation guy.
[02:18:39.060 --> 02:18:40.300]   You wouldn't expect to go to this guy.
[02:18:40.300 --> 02:18:41.300]   He's an operations guy.
[02:18:41.300 --> 02:18:42.300]   No, he's an operations guy.
[02:18:42.300 --> 02:18:43.300]   That's fine.
[02:18:43.300 --> 02:18:44.300]   You'd expect I've.
[02:18:44.300 --> 02:18:45.300]   You need a guy.
[02:18:45.300 --> 02:18:46.300]   And yeah, should be Johnny Ive, right?
[02:18:46.300 --> 02:18:47.300]   One would hope.
[02:18:47.300 --> 02:18:48.300]   Yeah.
[02:18:48.300 --> 02:18:51.940]   Well, the problem with Johnny Ive is that you need somebody who keeps him in check because
[02:18:51.940 --> 02:18:57.740]   Johnny has like he has an amazing stable of ideas and creations.
[02:18:57.740 --> 02:19:05.660]   But he also created a back there, you know, $250 art book that's just pictures.
[02:19:05.660 --> 02:19:08.340]   So there's there are levels here.
[02:19:08.340 --> 02:19:12.580]   Oh, yeah, it was a gift.
[02:19:12.580 --> 02:19:15.540]   It's a beautiful book.
[02:19:15.540 --> 02:19:16.540]   I've seen it.
[02:19:16.540 --> 02:19:18.420]   It is a beautiful book.
[02:19:18.420 --> 02:19:19.420]   And you know what?
[02:19:19.420 --> 02:19:20.420]   It's very impressive.
[02:19:20.420 --> 02:19:26.260]   But if I had to pick the things that I'd like my, you know, break, you know, life changing
[02:19:26.260 --> 02:19:32.180]   technology experts to focus on, it would not be a $250 book as much as I love books.
[02:19:32.180 --> 02:19:36.820]   That said, I don't think that this is as big of a deal as people are making it out to
[02:19:36.820 --> 02:19:42.740]   be because I can't imagine that Johnny let any things slide by without even giving it
[02:19:42.740 --> 02:19:44.620]   a peripheral glance.
[02:19:44.620 --> 02:19:50.900]   iOS and macOS have serious problems right now and I'm not going to downplay that at all.
[02:19:50.900 --> 02:19:56.220]   But I don't necessarily think that it's Johnny and the design team that's that's at fault
[02:19:56.220 --> 02:19:57.220]   here.
[02:19:57.220 --> 02:19:59.940]   I think it's a little bit of a bigger picture issue.
[02:19:59.940 --> 02:20:00.940]   I agree with you.
[02:20:00.940 --> 02:20:04.220]   Johnny's job's partnership was made in heaven.
[02:20:04.220 --> 02:20:05.980]   Oh, it absolutely was.
[02:20:05.980 --> 02:20:06.980]   Yeah.
[02:20:06.980 --> 02:20:11.260]   But you Johnny needs needs that sounding board that guy to say no, the guy to say yes,
[02:20:11.260 --> 02:20:14.100]   the guy to drive crack the whip.
[02:20:14.100 --> 02:20:15.620]   I don't know who that is right now.
[02:20:15.620 --> 02:20:20.540]   I mean, Johnny was the guy that gave us the solid gold I watch, which was just such a
[02:20:20.540 --> 02:20:21.540]   dumb idea.
[02:20:21.540 --> 02:20:22.540]   Yeah.
[02:20:22.540 --> 02:20:25.220]   It was it was there for status.
[02:20:25.220 --> 02:20:29.620]   It was there to increase the cash it of the brand and the brand is now at a point where
[02:20:29.620 --> 02:20:31.420]   it doesn't need that that status.
[02:20:31.420 --> 02:20:36.060]   The ceramic watch is cool, but it's not that, you know, it's not to that extent.
[02:20:36.060 --> 02:20:40.820]   But in terms of, you know, and I do have to disagree with you on the on the watch being,
[02:20:40.820 --> 02:20:44.540]   you know, just something everybody else is doing because speaking as a somebody who
[02:20:44.540 --> 02:20:48.740]   owns a 38 millimeter watch, which is the only thing that will actually fit on my wrist,
[02:20:48.740 --> 02:20:53.420]   like there is no other company right now that has been able to do what Apple has done in
[02:20:53.420 --> 02:20:58.220]   the form factor that Apple's made for for women, especially or for people with small
[02:20:58.220 --> 02:20:59.420]   risks like there.
[02:20:59.420 --> 02:21:04.620]   There is definitely innovation going on here in a level that I think gets downplayed.
[02:21:04.620 --> 02:21:07.020]   And I think you could also throw the AirPods into that.
[02:21:07.020 --> 02:21:10.780]   I just I finally got some AirPods and that's a pretty cool product.
[02:21:10.780 --> 02:21:13.220]   Yeah, that's the best thing Apple's done in a while.
[02:21:13.220 --> 02:21:14.220]   Really?
[02:21:14.220 --> 02:21:15.220]   Yeah.
[02:21:15.220 --> 02:21:16.220]   Hmm.
[02:21:16.220 --> 02:21:18.220]   Okay, I was down corrected, but I just I don't see myself.
[02:21:18.220 --> 02:21:19.220]   Watch those things.
[02:21:19.220 --> 02:21:20.220]   Yeah.
[02:21:20.220 --> 02:21:23.220]   Wait, wait, we're the third series, probably really the fourth generation of the Apple
[02:21:23.220 --> 02:21:24.220]   watch.
[02:21:24.220 --> 02:21:28.500]   It took them a while to make this useful and it's been a gradual evolution.
[02:21:28.500 --> 02:21:29.860]   Do you actually find it's useful?
[02:21:29.860 --> 02:21:32.300]   This is what I don't get about small issues.
[02:21:32.300 --> 02:21:34.100]   You still got to have your phone with you.
[02:21:34.100 --> 02:21:36.300]   They make you terribly rude because you sell your version.
[02:21:36.300 --> 02:21:37.300]   You don't anymore.
[02:21:37.300 --> 02:21:38.300]   Okay.
[02:21:38.300 --> 02:21:39.300]   So that's one big difference.
[02:21:39.300 --> 02:21:43.620]   Well, I mean, I do agree with you, Serenity, when I first when I got my first smartwatch
[02:21:43.620 --> 02:21:46.260]   for testing, I think it was the LG one.
[02:21:46.260 --> 02:21:48.940]   My wife referred to it as the woman repellor because it was huge.
[02:21:48.940 --> 02:21:49.940]   It was huge.
[02:21:49.940 --> 02:21:54.340]   You know, an old school communicator.
[02:21:54.340 --> 02:22:00.020]   No, I mean, I think I think in the point for, you know, what does a smartwatch do really?
[02:22:00.020 --> 02:22:03.180]   I think you really need to find how it works for your life.
[02:22:03.180 --> 02:22:08.420]   Like for me, as a health tool, this is, you know, life changing, especially because of
[02:22:08.420 --> 02:22:11.780]   the training that I do for roller derby and everything else without it.
[02:22:11.780 --> 02:22:16.500]   I wouldn't be able to tailor my workouts nearly as effectively and then in combination what
[02:22:16.500 --> 02:22:21.540]   Apple's doing for all purpose health with the heart study app that just came out that
[02:22:21.540 --> 02:22:26.420]   they're enrolling people in to check for atrial fibrillation and things like that.
[02:22:26.420 --> 02:22:30.060]   The fact that a live core just released a band that you know, that hooks to the watch
[02:22:30.060 --> 02:22:31.660]   that can take instantaneous.
[02:22:31.660 --> 02:22:33.420]   That will save lives.
[02:22:33.420 --> 02:22:36.660]   That a life or band is constantly monitoring.
[02:22:36.660 --> 02:22:43.100]   And if you're going into AFib, which could be a silent killer, will say quickly, put your
[02:22:43.100 --> 02:22:48.460]   finger here, get an EKG and send it to your doctor and people's lives will be saved by
[02:22:48.460 --> 02:22:49.460]   that.
[02:22:49.460 --> 02:22:50.460]   That is massive.
[02:22:50.460 --> 02:22:51.460]   That is really important.
[02:22:51.460 --> 02:22:52.460]   Yeah.
[02:22:52.460 --> 02:22:57.580]   Well, you saw the story about the man who had a, who had, who had actually was the original
[02:22:57.580 --> 02:22:58.740]   Apple watch.
[02:22:58.740 --> 02:23:02.820]   It didn't use the feature where if you're sitting still in your heart races, it suddenly
[02:23:02.820 --> 02:23:05.380]   tells you he had an app doing that.
[02:23:05.380 --> 02:23:08.700]   And it happened to him and he wound up going to the hospital.
[02:23:08.700 --> 02:23:14.020]   He had a pulmonary embolism and the watch probably saved his life.
[02:23:14.020 --> 02:23:18.460]   And that story was one of the reasons why I wound up getting an Apple watch eventually
[02:23:18.460 --> 02:23:20.540]   because I've had pulmonary embolisms.
[02:23:20.540 --> 02:23:21.540]   Absolutely.
[02:23:21.540 --> 02:23:26.460]   And the idea that this watch, you know, could, could alert me to that happening again is
[02:23:26.460 --> 02:23:29.260]   very, that's one of the reasons I got it.
[02:23:29.260 --> 02:23:31.780]   So, what do you use the heart rate?
[02:23:31.780 --> 02:23:32.780]   What do they call it?
[02:23:32.780 --> 02:23:33.780]   Variability, interval, same.
[02:23:33.780 --> 02:23:34.780]   Yeah, I do.
[02:23:34.780 --> 02:23:38.180]   So, this is a, I'm, I want you to tell me about this.
[02:23:38.180 --> 02:23:44.860]   So what it measures is the variability between the beats like if it should be fairly consistent.
[02:23:44.860 --> 02:23:46.260]   And if it's not, is that a problem?
[02:23:46.260 --> 02:23:47.260]   Tell me what that means.
[02:23:47.260 --> 02:23:48.260]   No.
[02:23:48.260 --> 02:23:52.140]   So, and interestingly, and this kind of goes against what I think people understand about
[02:23:52.140 --> 02:23:56.540]   heart rate, heart rate variability, it's actually important for your heart rate to be variable.
[02:23:56.540 --> 02:23:57.540]   Oh.
[02:23:57.540 --> 02:24:02.700]   So you actually want it to be at a high variability because that means that your heart can adjust
[02:24:02.700 --> 02:24:03.700]   quickly.
[02:24:03.700 --> 02:24:07.460]   But that's basically saying is say that I'm sitting down at rest, right?
[02:24:07.460 --> 02:24:11.140]   And then all of a sudden I get up and I jog for 20 seconds.
[02:24:11.140 --> 02:24:15.780]   If I have a high heart rate variability, my heart is very able to very quickly adjust
[02:24:15.780 --> 02:24:16.780]   to that.
[02:24:16.780 --> 02:24:20.740]   So, it's not going to take, like my heart's not going to have to go into overdrive to
[02:24:20.740 --> 02:24:23.340]   compensate for the fact that it was just sitting.
[02:24:23.340 --> 02:24:27.780]   Whereas if you have a low heart rate variability, it means it takes a lot longer for sort of
[02:24:27.780 --> 02:24:29.740]   things to get into gear.
[02:24:29.740 --> 02:24:32.980]   So it's actually, this is something that's constantly changing.
[02:24:32.980 --> 02:24:37.780]   So it's not just like I have a low or a high and then that's it forever.
[02:24:37.780 --> 02:24:42.260]   Your heart goes through patterns depending on how hard you're working at any one point
[02:24:42.260 --> 02:24:44.460]   and whether or not you regularly work out.
[02:24:44.460 --> 02:24:49.540]   So one of the reasons why it's so useful to athletes is you can actually look at it.
[02:24:49.540 --> 02:24:54.780]   If you have a high heart rate variability on that day, that actually says you are at peak
[02:24:54.780 --> 02:24:57.740]   rest, which means that you can do the most work.
[02:24:57.740 --> 02:25:02.140]   And after you've done a hard workout, you can check your heart rate variability at the
[02:25:02.140 --> 02:25:07.260]   end of that day and that'll tell you for the next day, hey, you can still do some work
[02:25:07.260 --> 02:25:12.700]   or your heart rate variability is low, your body needs to rest and recover and then you
[02:25:12.700 --> 02:25:15.140]   can do another day of hard work the day after that.
[02:25:15.140 --> 02:25:17.500]   There are a lot of really, really interesting studies.
[02:25:17.500 --> 02:25:18.700]   And that's simple.
[02:25:18.700 --> 02:25:21.620]   It's just because it's always measuring your heart rate.
[02:25:21.620 --> 02:25:23.620]   But that's I think that's a significant.
[02:25:23.620 --> 02:25:25.660]   Yeah, I mean, it has potential.
[02:25:25.660 --> 02:25:26.740]   But again, I don't know.
[02:25:26.740 --> 02:25:30.780]   It just, I've just realized I'm the only person on this entire panel not wearing an
[02:25:30.780 --> 02:25:31.780]   Apple watch.
[02:25:31.780 --> 02:25:33.620]   I'm not only wearing an Apple watch.
[02:25:33.620 --> 02:25:37.460]   I'm wearing a band of fitness ring from motive.
[02:25:37.460 --> 02:25:40.980]   This thing has accelerometers, heart rate measure, measure your sleep.
[02:25:40.980 --> 02:25:44.900]   It's a sponsor I should mention, but I'm wearing two.
[02:25:44.900 --> 02:25:47.900]   I can get a second opinion, if I will.
[02:25:47.900 --> 02:25:50.580]   Yeah, it is interesting, honestly.
[02:25:50.580 --> 02:25:55.220]   And in addition to wearing the watch for health features, I do think that this is finally
[02:25:55.220 --> 02:26:00.940]   the generation where the software is powerful enough that it's useful.
[02:26:00.940 --> 02:26:04.060]   Whereas before it took so long to load and all of that.
[02:26:04.060 --> 02:26:08.500]   But if you've seen like carrot weather is most recent app is fantastic.
[02:26:08.500 --> 02:26:11.740]   If you want mobile weather, there's an app called Smart Gym.
[02:26:11.740 --> 02:26:14.140]   It gives you the weather, but it's not.
[02:26:14.140 --> 02:26:16.140]   Ooh, I like the sound.
[02:26:16.140 --> 02:26:17.140]   Oh, it's delightful.
[02:26:17.140 --> 02:26:20.260]   I should pull up open carrot weather.
[02:26:20.260 --> 02:26:22.900]   I should see what it's telling me right now.
[02:26:22.900 --> 02:26:25.900]   Hold up your microphone.
[02:26:25.900 --> 02:26:28.180]   Oh, wait, no, there we go.
[02:26:28.180 --> 02:26:31.340]   Currently, no, no, it just switched back.
[02:26:31.340 --> 02:26:35.900]   Originally it said, "It's a perfect time for a wet t-shirt contest from earlier today."
[02:26:35.900 --> 02:26:36.900]   Oh, Lord.
[02:26:36.900 --> 02:26:40.700]   And then it updated and when it's bleeping moony.
[02:26:40.700 --> 02:26:44.340]   You can fill in the expletive for yourself.
[02:26:44.340 --> 02:26:45.340]   Yeah.
[02:26:45.340 --> 02:26:47.140]   But it's delightful.
[02:26:47.140 --> 02:26:51.900]   There's an app called Smart Gym that I love that allows you to keep your routines when
[02:26:51.900 --> 02:26:56.180]   you go to the gym and not just start workout.
[02:26:56.180 --> 02:26:59.020]   It actually shows you here are your super sets.
[02:26:59.020 --> 02:27:02.140]   Here's what you need to wait lift.
[02:27:02.140 --> 02:27:06.420]   And has perfect individual timers for each motion that you're doing.
[02:27:06.420 --> 02:27:08.860]   Oh, you're doing three minutes of rowing.
[02:27:08.860 --> 02:27:10.820]   You do that, then that timer's done.
[02:27:10.820 --> 02:27:15.340]   Okay, now it's time for 30 seconds of jumping jacks.
[02:27:15.340 --> 02:27:20.180]   That kind of stuff is so much more useful on a watch versus on a piece of paper or on
[02:27:20.180 --> 02:27:21.220]   your phone.
[02:27:21.220 --> 02:27:23.700]   It just, it makes it more simple.
[02:27:23.700 --> 02:27:28.260]   Smart Gym Pro or Smart Gym Manager?
[02:27:28.260 --> 02:27:29.260]   Smart Gym.
[02:27:29.260 --> 02:27:32.340]   Hold on, I'll get you a 10 gram factory.
[02:27:32.340 --> 02:27:34.260]   I'm installing it right now.
[02:27:34.260 --> 02:27:36.100]   That looks really cool.
[02:27:36.100 --> 02:27:37.100]   Yeah.
[02:27:37.100 --> 02:27:38.940]   A beautiful green icon.
[02:27:38.940 --> 02:27:40.540]   There's two smart gyms.
[02:27:40.540 --> 02:27:42.860]   Yeah, and they both, oh, you want the green icon.
[02:27:42.860 --> 02:27:44.780]   That's the 299 one.
[02:27:44.780 --> 02:27:46.260]   SmartChimApp.com.
[02:27:46.260 --> 02:27:48.540]   SmartChimApp.com, all right.
[02:27:48.540 --> 02:27:49.540]   Yeah.
[02:27:49.540 --> 02:27:53.020]   We got the new emojis and already we're already talking about new new emojis.
[02:27:53.020 --> 02:27:55.540]   Good news though, frowning pile of poo has been rejected.
[02:27:55.540 --> 02:27:57.540]   Oh, thank goodness.
[02:27:57.540 --> 02:27:59.500]   Frowned, known and sorry.
[02:27:59.500 --> 02:28:01.020]   We could have some stuff.
[02:28:01.020 --> 02:28:02.580]   We're stuck with getting poo.
[02:28:02.580 --> 02:28:07.540]   Yeah, we are one step closer towards softball, cupcake, redheads.
[02:28:07.540 --> 02:28:09.060]   There's a male and female.
[02:28:09.060 --> 02:28:18.340]   Bagel, kangaroo, mango, swan, party face, skateboard.
[02:28:18.340 --> 02:28:22.380]   I don't know why, but spool of thread.
[02:28:22.380 --> 02:28:23.380]   Would you use that emoji?
[02:28:23.380 --> 02:28:24.380]   That's not going to be--
[02:28:24.380 --> 02:28:26.820]   Oh, she's just looking at the party face and I've been to a lot of parties and I've never
[02:28:26.820 --> 02:28:27.820]   looked like that.
[02:28:27.820 --> 02:28:35.060]   I can see you using the spool of thread on Twitter.
[02:28:35.060 --> 02:28:36.060]   You know it's really good.
[02:28:36.060 --> 02:28:37.060]   Oh, yeah, that's the call.
[02:28:37.060 --> 02:28:38.060]   Spool of thread.
[02:28:38.060 --> 02:28:39.060]   Yeah.
[02:28:39.060 --> 02:28:40.060]   Yeah.
[02:28:40.060 --> 02:28:42.660]   Oh, see, you're better at this than I am.
[02:28:42.660 --> 02:28:43.660]   Very clear.
[02:28:43.660 --> 02:28:44.660]   That's good.
[02:28:44.660 --> 02:28:45.780]   And now emojis can go left to right or right to left.
[02:28:45.780 --> 02:28:46.780]   That's good.
[02:28:46.780 --> 02:28:47.780]   Right?
[02:28:47.780 --> 02:28:50.140]   Because the greenback will be the way or the train back.
[02:28:50.140 --> 02:28:51.140]   Yeah.
[02:28:51.140 --> 02:28:52.140]   Yeah.
[02:28:52.140 --> 02:28:53.140]   Yeah.
[02:28:53.140 --> 02:28:54.140]   Well, that's the apple.
[02:28:54.140 --> 02:28:55.140]   Apple uses a spur gun.
[02:28:55.140 --> 02:28:56.140]   Everybody else uses a real gun.
[02:28:56.140 --> 02:28:57.140]   So that's just the apple rendering.
[02:28:57.140 --> 02:28:58.140]   Yeah.
[02:28:58.140 --> 02:28:59.620]   But why no roller skate, Leo?
[02:28:59.620 --> 02:29:03.580]   There's a roller blade, there's a skateboard, there's no fun skate.
[02:29:03.580 --> 02:29:12.020]   How are you supposed to cheer for your favorite roller derby person R2D tonight?
[02:29:12.020 --> 02:29:16.340]   There's by the way, Franny Poo, faced with okay and faced with question marks.
[02:29:16.340 --> 02:29:17.340]   Those have been rejected.
[02:29:17.340 --> 02:29:18.340]   I'm glad to see.
[02:29:18.340 --> 02:29:19.340]   Thank goodness.
[02:29:19.340 --> 02:29:20.340]   Thank goodness.
[02:29:20.340 --> 02:29:21.500]   We'll keep you up to date.
[02:29:21.500 --> 02:29:24.780]   Thank you, serenity Caldwell R2D tonight.
[02:29:24.780 --> 02:29:32.140]   You'll find her at imore.com at set turn on the Twitter and follower roller derby adventures.
[02:29:32.140 --> 02:29:36.420]   Is there a place that we can go to follow your roller derby adventures?
[02:29:36.420 --> 02:29:41.340]   Well, most of it happens on Twitter and Instagram.
[02:29:41.340 --> 02:29:47.380]   Although I do run a separate Twitter account called R.D. junkies that does all kinds of
[02:29:47.380 --> 02:29:50.180]   videos for and strategy.
[02:29:50.180 --> 02:29:53.300]   Disseminations, but you can just follow them on Trio.
[02:29:53.300 --> 02:29:54.620]   New skids on the block.
[02:29:54.620 --> 02:29:57.940]   That's the team I play for currently and team Canada roller derby.
[02:29:57.940 --> 02:30:00.740]   New skids on the block.
[02:30:00.740 --> 02:30:02.180]   I love it.
[02:30:02.180 --> 02:30:05.340]   Tech burgers grill master is the fabulous Dwight Silverman.
[02:30:05.340 --> 02:30:08.420]   We missed you Dwight when you were out of tech.
[02:30:08.420 --> 02:30:11.020]   I'm thrilled you are back.
[02:30:11.020 --> 02:30:12.020]   So am I.
[02:30:12.020 --> 02:30:14.300]   Yeah, we miss you tech.
[02:30:14.300 --> 02:30:18.260]   Houston Chronicle dot com slash tech burger at the Silverman on Twitter.
[02:30:18.260 --> 02:30:19.260]   Really.
[02:30:19.260 --> 02:30:24.300]   We've also got a Twitter account H C tech burger and we have a Facebook account as well.
[02:30:24.300 --> 02:30:25.300]   It's just tech burger.
[02:30:25.300 --> 02:30:27.900]   So you can find us on both of those platforms.
[02:30:27.900 --> 02:30:28.900]   Nice.
[02:30:28.900 --> 02:30:29.900]   Very nice.
[02:30:29.900 --> 02:30:33.820]   And of course Ian Thompson, who brings just a little more smart.
[02:30:33.820 --> 02:30:36.300]   Snark to the table.
[02:30:36.300 --> 02:30:37.300]   What's smart though?
[02:30:37.300 --> 02:30:38.380]   I'm going to call it smart.
[02:30:38.380 --> 02:30:40.060]   That's smart snark.
[02:30:40.060 --> 02:30:42.260]   You are Mr. Smolke with a smile.
[02:30:42.260 --> 02:30:43.580]   Smarking with his mouth.
[02:30:43.580 --> 02:30:45.460]   The registered HACO.UK.
[02:30:45.460 --> 02:30:48.700]   I A.I.N. Thompson with no pen.
[02:30:48.700 --> 02:30:49.700]   Yes.
[02:30:49.700 --> 02:30:52.300]   My parents love that words.
[02:30:52.300 --> 02:30:54.580]   And it is always a pleasure having you up here.
[02:30:54.580 --> 02:30:56.580]   Always good fun as well.
[02:30:56.580 --> 02:30:57.580]   Yeah.
[02:30:57.580 --> 02:31:02.460]   Ian referred to me on Twitter before the show as a interesting chap and I have to say
[02:31:02.460 --> 02:31:04.340]   he is also an interesting chap.
[02:31:04.340 --> 02:31:06.340]   Oh, thank you very much.
[02:31:06.340 --> 02:31:07.340]   Hey.
[02:31:07.340 --> 02:31:08.700]   And have a wonderful time in jolly old.
[02:31:08.700 --> 02:31:09.700]   Where do you go?
[02:31:09.700 --> 02:31:10.700]   I'm part of England.
[02:31:10.700 --> 02:31:15.980]   I'll be spending a week in London just catching up with friends and family there then to back
[02:31:15.980 --> 02:31:18.020]   home to Dalbisher and the Peak District.
[02:31:18.020 --> 02:31:19.020]   Nice.
[02:31:19.020 --> 02:31:24.260]   Well, I'll go to Wake Christmas and then a glass go for Hogman A. So I was spending
[02:31:24.260 --> 02:31:25.260]   New Year's Eve.
[02:31:25.260 --> 02:31:26.660]   What is the tradition on Hogman A?
[02:31:26.660 --> 02:31:33.140]   Well, Scotland is very unusual in that everyone in the UK gets January the 1st offers a public
[02:31:33.140 --> 02:31:34.140]   holiday.
[02:31:34.140 --> 02:31:38.180]   Scotland they get January the 2nd offers a public holiday because the New Year celebrations
[02:31:38.180 --> 02:31:41.300]   are traditionally the time when everyone goes Hogwild.
[02:31:41.300 --> 02:31:44.780]   They call it Hogman A. And yeah, I'll be spending.
[02:31:44.780 --> 02:31:48.060]   Would you be dressed in Viking outfits with a flaming torch?
[02:31:48.060 --> 02:31:53.980]   No, I'll be clubbing to the fantastic tunes of Optimo and New Year's Eve and then Jeff
[02:31:53.980 --> 02:31:58.260]   Mills on New Year's Day and that will finish at about four o'clock in the morning both
[02:31:58.260 --> 02:31:59.260]   times.
[02:31:59.260 --> 02:32:02.260]   First footing is one of the traditions after the stroke of midnight neighbors visit each
[02:32:02.260 --> 02:32:07.100]   other bearing traditional symbolic gifts like shortbread or black bun.
[02:32:07.100 --> 02:32:09.700]   And then you're offered a weed dram or whiskey.
[02:32:09.700 --> 02:32:11.980]   Oh, everyone was offered a weed dram or whiskey.
[02:32:11.980 --> 02:32:15.140]   And of course, let's not forget where the song all laying zine.
[02:32:15.140 --> 02:32:16.140]   Indeed.
[02:32:16.140 --> 02:32:17.140]   Indeed.
[02:32:17.140 --> 02:32:18.140]   Hogman A tradition.
[02:32:18.140 --> 02:32:21.380]   Which I found out this week is apparently used in Japan to signify closing time at the
[02:32:21.380 --> 02:32:22.820]   end of her in bars.
[02:32:22.820 --> 02:32:26.420]   Oh, those weird cross cultural things.
[02:32:26.420 --> 02:32:30.540]   Well, I hope you all have a wonderful holiday and I thank you all for being here.
[02:32:30.540 --> 02:32:31.940]   We do Twitter every Saturday.
[02:32:31.940 --> 02:32:34.580]   I'm sorry Sunday right after the radio show.
[02:32:34.580 --> 02:32:37.900]   It's 3 p.m. Pacific, 6 p.m. Eastern 2300 UTC.
[02:32:37.900 --> 02:32:43.460]   If you want to watch live, you can go to youtube.com/live or twitter.tv/live.
[02:32:43.460 --> 02:32:46.740]   I'm so youtube.com/twit or twitter.tv/live.
[02:32:46.740 --> 02:32:47.740]   I got that right.
[02:32:47.740 --> 02:32:50.340]   And if you're going to do that, watch in the chat room.
[02:32:50.340 --> 02:32:53.100]   Participate at IRC.twit.tv.
[02:32:53.100 --> 02:32:54.820]   We love having in studio visitors.
[02:32:54.820 --> 02:33:03.620]   We have visitors today from Los Angeles visiting TQ in Chantel and from Scotch Plains, New Jersey.
[02:33:03.620 --> 02:33:05.620]   And we're going to be doing a lot of great things.
[02:33:05.620 --> 02:33:07.620]   I'm going to be doing a lot of great things.
[02:33:07.620 --> 02:33:09.620]   I'm going to be doing a lot of great things.
[02:33:09.620 --> 02:33:11.620]   I'm going to be doing a lot of great things.
[02:33:11.620 --> 02:33:13.620]   I'm going to be doing a lot of great things.
[02:33:13.620 --> 02:33:15.620]   I'm going to be doing a lot of great things.
[02:33:15.620 --> 02:33:17.620]   I'm going to be doing a lot of great things.
[02:33:17.620 --> 02:33:19.620]   I'm going to be doing a lot of great things.
[02:33:19.620 --> 02:33:21.620]   I'm going to be doing a lot of great things.
[02:33:21.620 --> 02:33:23.620]   I'm going to be doing a lot of great things.
[02:33:23.620 --> 02:33:25.620]   I'm going to be doing a lot of great things.
[02:33:25.620 --> 02:33:27.620]   I'm going to be doing a lot of great things.
[02:33:27.620 --> 02:33:29.620]   I'm going to be doing a lot of great things.
[02:33:29.620 --> 02:33:31.620]   I'm going to be doing a lot of great things.
[02:33:31.620 --> 02:33:33.620]   I'm going to be doing a lot of great things.
[02:33:33.620 --> 02:33:35.620]   I'm going to be doing a lot of great things.
[02:33:35.620 --> 02:33:37.620]   I'm going to be doing a lot of great things.
[02:33:37.620 --> 02:33:39.620]   I'm going to be doing a lot of great things.
[02:33:39.620 --> 02:33:41.620]   I'm going to be doing a lot of great things.
[02:33:41.620 --> 02:33:43.620]   I'm going to be doing a lot of great things.
[02:33:43.620 --> 02:33:45.620]   I'm going to be doing a lot of great things.
[02:33:45.620 --> 02:33:47.620]   I'm going to be doing a lot of great things.
[02:33:47.620 --> 02:33:49.620]   I'm going to be doing a lot of great things.
[02:33:49.620 --> 02:33:51.620]   I'm going to be doing a lot of great things.
[02:33:51.620 --> 02:33:53.620]   I'm going to be doing a lot of great things.
[02:33:53.620 --> 02:33:55.620]   I'm going to be doing a lot of great things.
[02:33:55.620 --> 02:33:57.620]   I'm going to be doing a lot of great things.

