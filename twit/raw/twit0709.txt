;FFMETADATA1
title=Third-Party Dog Hats
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=709
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:01.540]   It's time for "Twit."
[00:00:01.540 --> 00:00:05.200]   This weekend tech, Paris Martin-O is here from Wired.com.
[00:00:05.200 --> 00:00:08.280]   We've got Patrick Bejah from France.
[00:00:08.280 --> 00:00:11.280]   From "Travels All Around the World," Mike Elgin is back.
[00:00:11.280 --> 00:00:14.320]   And boy, do we have a big agenda to talk about today.
[00:00:14.320 --> 00:00:18.760]   Mark Zuckerberg's post saying he's going to change the way Facebook works.
[00:00:18.760 --> 00:00:20.120]   Or will he?
[00:00:20.120 --> 00:00:24.480]   Elizabeth Warren says it's time to break up the tech giants and a trip down memory lane
[00:00:24.480 --> 00:00:25.920]   with Four Square.
[00:00:25.920 --> 00:00:28.200]   Turns out they're still watching your every move.
[00:00:28.200 --> 00:00:30.200]   It's all coming up next on "Twit."
[00:00:30.200 --> 00:00:33.000]   [MUSIC]
[00:00:33.000 --> 00:00:35.160]   Netcast you love.
[00:00:35.160 --> 00:00:36.440]   From people you trust.
[00:00:36.440 --> 00:00:40.240]   [MUSIC]
[00:00:40.240 --> 00:00:41.800]   This is "Twit."
[00:00:41.800 --> 00:00:50.520]   [MUSIC]
[00:00:50.520 --> 00:00:53.240]   This is "Twit," this weekend tech.
[00:00:53.240 --> 00:00:58.040]   Episode 709 recorded Sunday, March 10th, 2019.
[00:00:58.040 --> 00:01:00.000]   Third-party dog hats.
[00:01:00.000 --> 00:01:04.160]   This weekend tech is brought to you by Wasabi Hot Cloud Storage.
[00:01:04.160 --> 00:01:08.560]   And the founders of Carbonite comes the cloud storage technology that's disrupting the
[00:01:08.560 --> 00:01:09.560]   industry.
[00:01:09.560 --> 00:01:12.520]   See for yourself with free unlimited storage for a month.
[00:01:12.520 --> 00:01:16.840]   Go to wasabi.com, click the free trial and use the offer code "Twit."
[00:01:16.840 --> 00:01:18.960]   And by Wordpress.
[00:01:18.960 --> 00:01:23.640]   Turn your dreams into reality and launch your website at wordpress.com.
[00:01:23.640 --> 00:01:28.560]   And 15% off any new plan at wordpress.com/twit.
[00:01:28.560 --> 00:01:30.320]   And by Atlassian.
[00:01:30.320 --> 00:01:35.040]   Atlassian Software powers the full spectrum of collaboration between IT teams and the rest
[00:01:35.040 --> 00:01:36.680]   of your organization.
[00:01:36.680 --> 00:01:43.720]   Visit at Atlassian.com/IT to see what IT can be by giving their products a try for free.
[00:01:43.720 --> 00:01:45.600]   And by FreshBooks.
[00:01:45.600 --> 00:01:49.680]   The ridiculously easy to use, invoicing, and accounting software.
[00:01:49.680 --> 00:01:58.360]   If you don't believe us, try it free for 30 days at freshbooks.com/twit.
[00:01:58.360 --> 00:01:59.440]   It's time for "Twit."
[00:01:59.440 --> 00:02:01.960]   This week in tech, the show where we cover the weeks.
[00:02:01.960 --> 00:02:03.120]   Tech news.
[00:02:03.120 --> 00:02:07.040]   And there are some massive stories we're going to get into.
[00:02:07.040 --> 00:02:10.920]   Partly because South by Southwest is going on, but partly because, well, the news never
[00:02:10.920 --> 00:02:12.080]   sleeps.
[00:02:12.080 --> 00:02:13.080]   Mike Elgin is here.
[00:02:13.080 --> 00:02:14.240]   No one knows it better than Mike.
[00:02:14.240 --> 00:02:18.400]   In fact, it sleeps so little, Mike's actually moved to Europe to get away from it.
[00:02:18.400 --> 00:02:20.880]   I try to move as often as possible.
[00:02:20.880 --> 00:02:29.600]   Mike is, of course, a inventor at long time computer technology journalist, watcher of
[00:02:29.600 --> 00:02:30.800]   the trends.
[00:02:30.800 --> 00:02:32.880]   He blogs at Elgin.com.
[00:02:32.880 --> 00:02:35.520]   That's where his Mike's list is, which is a great newsletter.
[00:02:35.520 --> 00:02:39.680]   Actually, kind of an antidote to the daily tech news.
[00:02:39.680 --> 00:02:40.680]   It's fun stuff.
[00:02:40.680 --> 00:02:41.680]   It's fun.
[00:02:41.680 --> 00:02:42.680]   It's cynical.
[00:02:42.680 --> 00:02:45.600]   It's just bursting with sour notes.
[00:02:45.600 --> 00:02:48.600]   It's just, yes.
[00:02:48.600 --> 00:02:49.600]   Okay.
[00:02:49.600 --> 00:02:56.120]   What I do is I dig up the main list is 10 things that are most absurd things in technology.
[00:02:56.120 --> 00:02:57.960]   It's like sour patch kids of technology.
[00:02:57.960 --> 00:02:58.960]   Yes.
[00:02:58.960 --> 00:02:59.960]   Yes.
[00:02:59.960 --> 00:03:00.960]   Oh my God.
[00:03:00.960 --> 00:03:03.120]   Go back to that.
[00:03:03.120 --> 00:03:05.440]   That's the future right there you're looking at.
[00:03:05.440 --> 00:03:08.520]   That is Buscemi being...
[00:03:08.520 --> 00:03:11.320]   Steve Buscemi being Jennifer Lawrence.
[00:03:11.320 --> 00:03:12.320]   Buscemi?
[00:03:12.320 --> 00:03:13.320]   Buscemi.
[00:03:13.320 --> 00:03:14.320]   Buscemi.
[00:03:14.320 --> 00:03:16.200]   Being Jennifer, J-law meets Steve Busce.
[00:03:16.200 --> 00:03:17.200]   Yeah.
[00:03:17.200 --> 00:03:18.200]   This is a Deep Fake article that I wrote.
[00:03:18.200 --> 00:03:19.200]   Oh, a lot.
[00:03:19.200 --> 00:03:20.200]   I'm Lazy.
[00:03:20.200 --> 00:03:21.200]   Lazy.
[00:03:21.200 --> 00:03:24.240]   Long story short, Deep Fake is going to get so good that literally you won't be able
[00:03:24.240 --> 00:03:27.080]   to tell Deep Fake from me already.
[00:03:27.080 --> 00:03:28.560]   Yeah.
[00:03:28.560 --> 00:03:31.240]   Also joining us from Paris, Patrick Bezia.
[00:03:31.240 --> 00:03:32.240]   He is...
[00:03:32.240 --> 00:03:33.720]   I know, I'm sorry.
[00:03:33.720 --> 00:03:38.160]   He is from friendspin.com and he's in his kitchen apparently.
[00:03:38.160 --> 00:03:39.160]   Hello, Patrick.
[00:03:39.160 --> 00:03:40.160]   I am.
[00:03:40.160 --> 00:03:44.280]   I'm so happy that I'm joining you at a reasonable hour.
[00:03:44.280 --> 00:03:45.560]   Well, it never happens.
[00:03:45.560 --> 00:03:47.060]   Is it a reasonable hour?
[00:03:47.060 --> 00:03:48.440]   You kind of liked out in two ways.
[00:03:48.440 --> 00:03:52.960]   First of all, we did that silly thing that we do in America called spring forward.
[00:03:52.960 --> 00:03:55.360]   It's entering daylight saving time.
[00:03:55.360 --> 00:03:59.680]   But also we've moved the start time of twit up by about half an hour to 45 minutes.
[00:03:59.680 --> 00:04:00.840]   So now it's like it...
[00:04:00.840 --> 00:04:02.120]   What is it instead of midnight?
[00:04:02.120 --> 00:04:03.120]   It's 11.30.
[00:04:03.120 --> 00:04:07.320]   Well, yeah, not only that, but I'm also in Paris.
[00:04:07.320 --> 00:04:09.880]   I'm often joining you from Finland.
[00:04:09.880 --> 00:04:11.920]   So now it's 10 p.m.
[00:04:11.920 --> 00:04:12.920]   10.30 now.
[00:04:12.920 --> 00:04:13.920]   Nothing.
[00:04:13.920 --> 00:04:15.920]   It's time for dinner.
[00:04:15.920 --> 00:04:18.880]   Yeah, exactly.
[00:04:18.880 --> 00:04:22.200]   Always great to have Patrick here from French spin.
[00:04:22.200 --> 00:04:23.200]   Thank you.
[00:04:23.200 --> 00:04:25.040]   And not Patrick on the Twitter.
[00:04:25.040 --> 00:04:29.080]   And from Wired magazine, love to have Paris Martyn O on the show.
[00:04:29.080 --> 00:04:30.080]   Hi, Paris.
[00:04:30.080 --> 00:04:31.920]   Hi, how's it going?
[00:04:31.920 --> 00:04:32.920]   Great to have you.
[00:04:32.920 --> 00:04:33.920]   She's in San Francisco.
[00:04:33.920 --> 00:04:36.200]   So she's about to be eaten by the tech bros.
[00:04:36.200 --> 00:04:37.760]   I'm actually in New York.
[00:04:37.760 --> 00:04:38.760]   Oh, you're in New York.
[00:04:38.760 --> 00:04:39.760]   Oh, I apologize.
[00:04:39.760 --> 00:04:40.760]   I'm...
[00:04:40.760 --> 00:04:42.760]   Jason, I'm going to be eaten by the tech bros.
[00:04:42.760 --> 00:04:43.760]   Yeah, you too.
[00:04:43.760 --> 00:04:44.760]   All my coworkers, I will.
[00:04:44.760 --> 00:04:45.760]   You too.
[00:04:45.760 --> 00:04:46.760]   I'll survive.
[00:04:46.760 --> 00:04:48.040]   What's the status on HQ2?
[00:04:48.040 --> 00:04:55.120]   Because at first Amazon picked Long Island City just outside of Manhattan and the Queens
[00:04:55.120 --> 00:04:58.400]   to be headquarters too, then there was an outcry.
[00:04:58.400 --> 00:05:00.880]   And then they said, "Well, if you don't want us here, we're leaving."
[00:05:00.880 --> 00:05:04.040]   And then the last thing I heard is, "Well, maybe we won't."
[00:05:04.040 --> 00:05:05.040]   I don't know.
[00:05:05.040 --> 00:05:09.200]   The last thing I've heard is that Cuomo and a bunch of other people in New York politics
[00:05:09.200 --> 00:05:11.720]   fans, "Please come back, Amazon.
[00:05:11.720 --> 00:05:15.360]   We didn't mean it, but who knows?"
[00:05:15.360 --> 00:05:21.520]   I think it seems like all of the local politicians here are very against it, and as well as many
[00:05:21.520 --> 00:05:22.520]   of the unions.
[00:05:22.520 --> 00:05:23.520]   Yeah.
[00:05:23.520 --> 00:05:30.000]   It's probably going to stay either not happening or stay in a contentious space for a while.
[00:05:30.000 --> 00:05:33.360]   Oh, and you know how much Mr. Bezos loves contention.
[00:05:33.360 --> 00:05:36.040]   Gotta have it.
[00:05:36.040 --> 00:05:40.040]   So the big story of the week, well, there were several.
[00:05:40.040 --> 00:05:44.160]   On Wednesday, I thought the big story of the week was Mark Zuckerberg's blog post, which
[00:05:44.160 --> 00:05:51.080]   some say I thought maybe was a pivot of Facebook from a public facing network to a privacy facing
[00:05:51.080 --> 00:05:52.080]   network.
[00:05:52.080 --> 00:05:56.600]   Then Elizabeth Warren on Friday at South by Southwest announced, "We're going to break
[00:05:56.600 --> 00:05:57.600]   up.
[00:05:57.600 --> 00:06:02.560]   If I get elected president, we're going to break up Facebook, Google, Amazon."
[00:06:02.560 --> 00:06:05.680]   And then she threw in an interview with Neil Ipatel almost like she had a new really
[00:06:05.680 --> 00:06:06.680]   thought of it.
[00:06:06.680 --> 00:06:10.320]   Yeah, an apple too.
[00:06:10.320 --> 00:06:12.320]   So it was really kind of off-handed.
[00:06:12.320 --> 00:06:15.000]   He said, "You're going to break up apple too?"
[00:06:15.000 --> 00:06:17.920]   She said, "Yeah, we're going to break up apple too."
[00:06:17.920 --> 00:06:19.400]   Okay.
[00:06:19.400 --> 00:06:21.240]   Her complaint against apple is a little bit weird.
[00:06:21.240 --> 00:06:22.800]   We'll talk about that.
[00:06:22.800 --> 00:06:24.480]   We'll talk about Facebook.
[00:06:24.480 --> 00:06:30.320]   And then Paris wrote an article also coming out of South by about a company you haven't
[00:06:30.320 --> 00:06:34.640]   heard of in a while, a company that made its kind of famous debut at South by some years
[00:06:34.640 --> 00:06:35.640]   ago, Four Square.
[00:06:35.640 --> 00:06:36.640]   Ten years ago actually.
[00:06:36.640 --> 00:06:37.640]   It's exactly ten.
[00:06:37.640 --> 00:06:38.640]   Wow.
[00:06:38.640 --> 00:06:39.640]   Yeah.
[00:06:39.640 --> 00:06:42.640]   It took Austin by storm.
[00:06:42.640 --> 00:06:46.480]   It's taking Austin by something a little less than a storm this time with a new app called
[00:06:46.480 --> 00:06:47.640]   Hypertrending.
[00:06:47.640 --> 00:06:52.280]   But you got an interview with Dennis Crowley and saw something that I found bone-chilling,
[00:06:52.280 --> 00:06:54.200]   but we'll let you talk about all that.
[00:06:54.200 --> 00:06:55.200]   Yeah.
[00:06:55.200 --> 00:06:56.200]   It's a...
[00:06:56.200 --> 00:07:00.880]   I also hadn't thought about Four Square maybe in a decade since it was Four Square's heyday,
[00:07:00.880 --> 00:07:05.960]   but you could be forgiven for wondering whether Four Square even still existed.
[00:07:05.960 --> 00:07:13.640]   But the Four Square of today is this location data giant, rivaling the powers of Facebook
[00:07:13.640 --> 00:07:16.160]   and Google almost.
[00:07:16.160 --> 00:07:19.960]   You may not even think that you're a Four Square user if you've never used the app, but chances
[00:07:19.960 --> 00:07:22.360]   are that you are.
[00:07:22.360 --> 00:07:26.880]   Four Square's technology powers the geo filters in Snapchat, tags, we've done Twitter, it's
[00:07:26.880 --> 00:07:34.880]   in AccuWeather, Uber, Apple News, Airbnb, WeChat, most Samsung phones, the photo...
[00:07:34.880 --> 00:07:36.960]   their photo app on Samsung.
[00:07:36.960 --> 00:07:38.680]   And essentially, yeah, swarm.
[00:07:38.680 --> 00:07:40.760]   All Four Square's native apps.
[00:07:40.760 --> 00:07:45.320]   And I mean, as Four Square's website says, if it tells you where it's probably built on
[00:07:45.320 --> 00:07:52.960]   Four Square and all that amounts to that Four Square has the capability to track most people
[00:07:52.960 --> 00:07:57.080]   with smartphones, track their locations in real time.
[00:07:57.080 --> 00:08:02.040]   And hyper trending, which is a feature for Four Square's apps that they rolled out at
[00:08:02.040 --> 00:08:11.200]   South by Southwest, it shows this live map of Austin that shows basically the locations
[00:08:11.200 --> 00:08:15.320]   of all the phones, all the people with smartphones in Austin in real time.
[00:08:15.320 --> 00:08:18.360]   Albeit, it's aggregated and anonymized a bit.
[00:08:18.360 --> 00:08:22.880]   So you just see like a big circle if there's a bunch of people at one coffee shop versus
[00:08:22.880 --> 00:08:26.240]   a small circle if there's only two or three.
[00:08:26.240 --> 00:08:32.680]   But it's a real time tracking service that speaks to the amount of data that Four Square
[00:08:32.680 --> 00:08:34.680]   is collecting.
[00:08:34.680 --> 00:08:38.640]   And when I went to go meet with Crowley on Thursday, we were going to be talking about
[00:08:38.640 --> 00:08:43.920]   hyper trending, but he ended up showing me this internal game kind of app that Four Square
[00:08:43.920 --> 00:08:48.240]   had been developing just among its coworkers.
[00:08:48.240 --> 00:08:53.840]   And it essentially is kind of like Candyland button app and the, except for the cards that
[00:08:53.840 --> 00:08:58.880]   you draw in Candyland, you get cards in order to like move along the little row, the rainbow
[00:08:58.880 --> 00:09:06.760]   row, except for the cards in this app are based on real people's location data and where
[00:09:06.760 --> 00:09:08.560]   they are really going.
[00:09:08.560 --> 00:09:13.400]   So he had pulled up his phone when we were meeting and it was like, okay, well, the Candy
[00:09:13.400 --> 00:09:16.160]  land that he had was based on New York City.
[00:09:16.160 --> 00:09:19.160]   And so he's like, okay, well, I need to move to the Manhattan bar square next.
[00:09:19.160 --> 00:09:25.680]   So if I go look at whoever is in like proximity to my phone based on who has, for who Four
[00:09:25.680 --> 00:09:30.400]   Square has data on, I can see that there's one person who spends a lot of time at Midtown
[00:09:30.400 --> 00:09:31.400]   bars.
[00:09:31.400 --> 00:09:34.760]   So I'm going to add him to my team and next time he, this person in the real world goes
[00:09:34.760 --> 00:09:39.080]   to a Midtown bar and Four Square tracks him all moving forward in the game, which is just
[00:09:39.080 --> 00:09:42.520]   insane that this company has that sort of technology.
[00:09:42.520 --> 00:09:46.640]   I kind of blame myself because when Four Square launched 10 years ago, I jumped on it.
[00:09:46.640 --> 00:09:48.040]   I thought this is fun.
[00:09:48.040 --> 00:09:53.680]   And I would fight to be mayor of Twit with my wife or mayor of our local coffee shop.
[00:09:53.680 --> 00:09:57.040]   And then they pivoted to swarm, which was basically the same thing.
[00:09:57.040 --> 00:10:01.000]   Four Square became an app that would tell you about places, but swarm was where you checked
[00:10:01.000 --> 00:10:02.000]   in.
[00:10:02.000 --> 00:10:03.000]   And I use that for a while.
[00:10:03.000 --> 00:10:04.000]   I think Lisa still does.
[00:10:04.000 --> 00:10:08.520]   I think she's in a battle with one of our engineers to be mayor of the Twit Studios.
[00:10:08.520 --> 00:10:12.840]   But I stopped because I thought, you know, you've got to be mayor.
[00:10:12.840 --> 00:10:14.800]   It was kind of silly.
[00:10:14.800 --> 00:10:19.200]   But I thought, well, I've stopped so they don't know where I am anymore.
[00:10:19.200 --> 00:10:21.400]   I guess I was wrong.
[00:10:21.400 --> 00:10:25.120]   You mentioned that Crowley wasn't sure if it was cool or creepy.
[00:10:25.120 --> 00:10:28.280]   Dennis, it's creepy.
[00:10:28.280 --> 00:10:29.280]   It's creepy.
[00:10:29.280 --> 00:10:31.720]   I'll read from your article downstairs in the cafeteria.
[00:10:31.720 --> 00:10:35.840]   There are 40 people Crowley says he's looking at a coffee company, a real cafe on the first
[00:10:35.840 --> 00:10:36.840]   floor of the building.
[00:10:36.840 --> 00:10:39.000]   We're in 40 people.
[00:10:39.000 --> 00:10:40.960]   These are people that are actually there.
[00:10:40.960 --> 00:10:41.960]   We don't put their names.
[00:10:41.960 --> 00:10:45.160]   We just put their unique advertising ID.
[00:10:45.160 --> 00:10:49.040]   We turn that into a fake name and a fake avatar, but it is their unique advertising
[00:10:49.040 --> 00:10:50.540]   ID.
[00:10:50.540 --> 00:10:51.540]   So basically the same.
[00:10:51.540 --> 00:10:55.240]   And also you can definitely de-anonymize that if you see, okay, there's one person that
[00:10:55.240 --> 00:10:58.160]   only goes to these like four areas.
[00:10:58.160 --> 00:10:59.160]   This is my bar putty.
[00:10:59.160 --> 00:11:00.160]   I keep seeing him here.
[00:11:00.160 --> 00:11:03.160]   It must be 439 472 133419.
[00:11:03.160 --> 00:11:09.640]   And then, well, I have one question.
[00:11:09.640 --> 00:11:12.040]   Then you can ask yours, Patrick.
[00:11:12.040 --> 00:11:14.240]   This isn't from four square.
[00:11:14.240 --> 00:11:16.640]   This is like I'm using a Samsung phone.
[00:11:16.640 --> 00:11:19.200]   Is it sending location information to four square?
[00:11:19.200 --> 00:11:23.520]   So this, I believe in Samsung, it is four square powers.
[00:11:23.520 --> 00:11:28.560]   The geo tagging features, like whenever you take a photo, they're how it'll like show
[00:11:28.560 --> 00:11:29.560]   you like a little.
[00:11:29.560 --> 00:11:30.840]   Yeah, I just stand that.
[00:11:30.840 --> 00:11:31.840]   It's going to.
[00:11:31.840 --> 00:11:32.840]   It's also coming out.
[00:11:32.840 --> 00:11:35.200]   So it's a two way story.
[00:11:35.200 --> 00:11:36.200]   You do that.
[00:11:36.200 --> 00:11:37.200]   Yeah.
[00:11:37.200 --> 00:11:41.960]   Every time your phone takes a photo and tries to geo tag it like sends out signals like
[00:11:41.960 --> 00:11:46.400]   he uses Bluetooth, Wi-Fi, GPS, a couple of different things and then runs that by four
[00:11:46.400 --> 00:11:49.760]   squares like a whole list of locations.
[00:11:49.760 --> 00:11:52.400]   And then four squares like, oh, he's at Twit Studios.
[00:11:52.400 --> 00:11:56.160]   But you all, but four square also gets the data that you're at Twit Studios, you know?
[00:11:56.160 --> 00:11:57.440]   That's the part that's weird.
[00:11:57.440 --> 00:11:59.640]   And this is we're going to have a sign up for this.
[00:11:59.640 --> 00:12:00.640]   Yeah.
[00:12:00.640 --> 00:12:05.280]   So Verizon got in a little bit of heat because they were sending unique IDs from their Verizon
[00:12:05.280 --> 00:12:06.280]   phones.
[00:12:06.280 --> 00:12:07.680]   They even got fined for that.
[00:12:07.680 --> 00:12:11.840]   Remember how much trouble Uber got in because they had a God mode that did the same thing.
[00:12:11.840 --> 00:12:13.880]   But only with Uber.
[00:12:13.880 --> 00:12:15.360]   This is 10 times worse.
[00:12:15.360 --> 00:12:19.360]   And Uber, by the way, is one of the apps that sends information back to four square.
[00:12:19.360 --> 00:12:23.360]   Apple Maps, oh, the big privacy focused Apple sends it back.
[00:12:23.360 --> 00:12:26.080]   Airbnb, WeChat.
[00:12:26.080 --> 00:12:31.480]   Really any app or thing that uses location services that isn't connected directly to
[00:12:31.480 --> 00:12:37.880]   Facebook or Google is probably powered by four square because they have the most advanced,
[00:12:37.880 --> 00:12:43.960]   I guess, location technology when it comes to pin pointing where you are.
[00:12:43.960 --> 00:12:50.760]   But that's the back end of location services for four square who just happens to be very
[00:12:50.760 --> 00:12:57.000]   popular and so has location data on a lot of people in the same way that Facebook or
[00:12:57.000 --> 00:13:00.880]   Google, for example, has a lot of data on a lot of people.
[00:13:00.880 --> 00:13:05.400]   The thing that they're showing now, the hyper local app or mode or whatever they want to
[00:13:05.400 --> 00:13:10.560]   call it is completely anonymized, right?
[00:13:10.560 --> 00:13:16.480]   If we want to believe them, this is just an application of all the location data they
[00:13:16.480 --> 00:13:20.120]   already have and that many other people also have.
[00:13:20.120 --> 00:13:21.120]   This is real time data.
[00:13:21.120 --> 00:13:22.120]   This is real time data.
[00:13:22.120 --> 00:13:24.640]   Patrick, not coming from the four square swarm app.
[00:13:24.640 --> 00:13:26.280]   This is coming from all those other apps.
[00:13:26.280 --> 00:13:27.280]   I understand.
[00:13:27.280 --> 00:13:32.000]   So it's the location services that are used by many different apps and devices.
[00:13:32.000 --> 00:13:33.480]   Google can do the same thing, right?
[00:13:33.480 --> 00:13:34.480]   Because they get that information.
[00:13:34.480 --> 00:13:35.880]   Yes, Google does on the same way.
[00:13:35.880 --> 00:13:36.880]   It's way easier.
[00:13:36.880 --> 00:13:37.880]   Yeah.
[00:13:37.880 --> 00:13:38.880]   Yeah.
[00:13:38.880 --> 00:13:39.880]   That's my point.
[00:13:39.880 --> 00:13:44.000]   I think the difference is that most people probably don't realize that when you're using
[00:13:44.000 --> 00:13:51.280]   Uber or, I don't know, TripAdvisor or something or having Accu, whether alerts turned on the
[00:13:51.280 --> 00:13:55.560]   back of your phone, that you're one, consenting to give your data to these apps, but also
[00:13:55.560 --> 00:14:00.600]   consenting for it to be used in the future to create some hyper trending app.
[00:14:00.600 --> 00:14:04.760]   Or the thing that I find the most worrying is that when I was speaking to Crowley, he
[00:14:04.760 --> 00:14:08.000]   was saying that hyper trending, it's going to turn off after South by Southwest.
[00:14:08.000 --> 00:14:11.960]   But the reason why they're demoing it there is for developers to be like, "Oh, we could
[00:14:11.960 --> 00:14:16.000]   use it in this way or build this app off of it going forward."
[00:14:16.000 --> 00:14:20.600]   And so this same information that you didn't really consent to be used in this way, even
[00:14:20.600 --> 00:14:25.480]   though I suppose you technically did, could be used for any number of other apps.
[00:14:25.480 --> 00:14:27.480]   I think the thing that concerns me is-
[00:14:27.480 --> 00:14:28.480]   Right.
[00:14:28.480 --> 00:14:29.480]   Can I-
[00:14:29.480 --> 00:14:30.480]   Let Patrick finish.
[00:14:30.480 --> 00:14:31.480]   Then go ahead.
[00:14:31.480 --> 00:14:32.480]   Yeah.
[00:14:32.480 --> 00:14:33.480]   Very quickly.
[00:14:33.480 --> 00:14:36.880]   I can't believe I'm going to defend this, but just to explain exactly what he's trying
[00:14:36.880 --> 00:14:40.200]   to do with this long post.
[00:14:40.200 --> 00:14:49.120]   He's saying we can basically build a catalog of the popular places in this city at South
[00:14:49.120 --> 00:14:50.200]   by Southwest.
[00:14:50.200 --> 00:14:52.160]   And we're doing it now, showing it.
[00:14:52.160 --> 00:14:54.360]   We think it's cool or creepy.
[00:14:54.360 --> 00:14:56.840]   He acknowledges the creepy factor.
[00:14:56.840 --> 00:15:00.320]   And we're turning it off because we think there is something interesting here.
[00:15:00.320 --> 00:15:06.160]   And we want people to start thinking about these things and to kind of think about the
[00:15:06.160 --> 00:15:08.800]   uses and the guidelines and all of this.
[00:15:08.800 --> 00:15:16.520]   So the announcement here is the use of location data that sure, we might have not realized
[00:15:16.520 --> 00:15:20.680]   that they had so much of it, but we know Google has a lot of it, we know Facebook has
[00:15:20.680 --> 00:15:21.680]   a lot of it.
[00:15:21.680 --> 00:15:22.680]   It's not that different.
[00:15:22.680 --> 00:15:25.520]   The big new thing here is, I guess two things.
[00:15:25.520 --> 00:15:30.160]   First, 4square also has a lot of location data like the others.
[00:15:30.160 --> 00:15:40.040]   And they built this application with that hyper trending mode, which again is anonymized
[00:15:40.040 --> 00:15:44.880]   and only shows the popular places in the city.
[00:15:44.880 --> 00:15:50.760]   So it's a way to see which locations and stores and restaurants are popular in a way
[00:15:50.760 --> 00:15:52.200]   that you couldn't be for.
[00:15:52.200 --> 00:15:57.440]   So I don't know that there's something, I don't want to say new, but I don't know that
[00:15:57.440 --> 00:16:00.840]   it's that different from what Facebook or Google can already do.
[00:16:00.840 --> 00:16:06.560]   I'm not sure why it's that creepy if I want to play a little bit of devil's advocate.
[00:16:06.560 --> 00:16:09.560]   Well, here's the case on the other side.
[00:16:09.560 --> 00:16:12.640]   First of all, I think that they should release that game to the public because I think that
[00:16:12.640 --> 00:16:17.120]   would be a great consciousness raising exercise for people to see that this is real people,
[00:16:17.120 --> 00:16:18.520]   this is what they know.
[00:16:18.520 --> 00:16:20.280]   And because right now people just don't get it.
[00:16:20.280 --> 00:16:25.840]   The other point that I think is the bigger point is that the phone in your pocket, we
[00:16:25.840 --> 00:16:30.360]   all have a phone on us right now, all of us, everyone in this building and everyone in
[00:16:30.360 --> 00:16:34.640]   the world and Google is tracking everywhere you go.
[00:16:34.640 --> 00:16:36.480]   Facebook is tracking everywhere you go.
[00:16:36.480 --> 00:16:40.360]   The carrier is tracking and selling that information everywhere you go.
[00:16:40.360 --> 00:16:42.960]   Many of your apps on your phone are doing it.
[00:16:42.960 --> 00:16:45.800]   Most of them sending it to four square.
[00:16:45.800 --> 00:16:48.400]   How secure is that communications medium?
[00:16:48.400 --> 00:16:51.680]   The point is that it's not just somebody is tracking.
[00:16:51.680 --> 00:16:55.760]   Most of people are tracking you and we have no access or knowledge about how secure it
[00:16:55.760 --> 00:17:00.960]   is, how hackable it is, whether the Chinese government is tracking is tapping into this
[00:17:00.960 --> 00:17:05.440]   information, whether it's being sold, whether it's not being sold.
[00:17:05.440 --> 00:17:10.440]   What I do know is that it's all for the purpose of commerce and advertising and the advertising
[00:17:10.440 --> 00:17:12.240]   still sucks.
[00:17:12.240 --> 00:17:13.240]   It's not...
[00:17:13.240 --> 00:17:15.000]   I'll give you accurate in terms of...
[00:17:15.000 --> 00:17:17.920]   Yeah, nobody's getting any benefit from it is what you're saying.
[00:17:17.920 --> 00:17:20.320]   It would be okay if somebody were making money on this.
[00:17:20.320 --> 00:17:22.440]   Or they were showing me products I wanted to buy.
[00:17:22.440 --> 00:17:23.440]   That would be great.
[00:17:23.440 --> 00:17:24.440]   If I were getting some benefit from it.
[00:17:24.440 --> 00:17:28.280]   Yeah, because that's the common defense is like, "Oh, then you're able to have ads that
[00:17:28.280 --> 00:17:32.160]   people actually want to see," which I don't think anybody is thinking, "Wow, my ads are
[00:17:32.160 --> 00:17:33.480]   great now.
[00:17:33.480 --> 00:17:37.240]   I'm so happy that I'm seeing so many relevant ads."
[00:17:37.240 --> 00:17:42.320]   Google could do this if they, for instance, if Niantic turned on in Pokemon Go or Ingress
[00:17:42.320 --> 00:17:47.200]   turned on a map that showed you all the other players and where they are in the city.
[00:17:47.200 --> 00:17:50.920]   It would be such an eye-opener, I think these companies know very, very well.
[00:17:50.920 --> 00:17:51.920]   Maybe Denz does.
[00:17:51.920 --> 00:17:54.960]   Maybe that's his reason for doing this.
[00:17:54.960 --> 00:17:56.680]   There would be a hue and cry.
[00:17:56.680 --> 00:18:00.520]   Right now, nobody but the geeks at South Bay and the few people listening to the show
[00:18:00.520 --> 00:18:03.840]   know about it and read your wired piece.
[00:18:03.840 --> 00:18:05.560]   That's not the mass of general population.
[00:18:05.560 --> 00:18:07.040]   I think if the general population...
[00:18:07.040 --> 00:18:10.760]   I think if Elizabeth Warren saw this, she'd flip her lid.
[00:18:10.760 --> 00:18:16.800]   I can give you a nightmare scenario, Patrick, that will...
[00:18:16.800 --> 00:18:17.800]   It's anonymized.
[00:18:17.800 --> 00:18:19.560]   It's just an ID.
[00:18:19.560 --> 00:18:20.560]   It's not.
[00:18:20.560 --> 00:18:28.440]   I'm a rushing spy and I want to keep track of an NSA agent.
[00:18:28.440 --> 00:18:33.600]   I just hang out in a bar until that agent that I want to keep track of because I have
[00:18:33.600 --> 00:18:40.360]   his picture shows up and then I can start tracking his hyper-trending presence on 4
[00:18:40.360 --> 00:18:41.360]   square.
[00:18:41.360 --> 00:18:42.360]   Maybe it's not public.
[00:18:42.360 --> 00:18:44.000]   Maybe I have to buy the service.
[00:18:44.000 --> 00:18:47.240]   I can pretty quickly triangulate, "Oh, that's him.
[00:18:47.240 --> 00:18:51.120]   Once I've got his ID, I no longer have to surveil the guy.
[00:18:51.120 --> 00:18:53.080]   I know where he is at every moment of every day."
[00:18:53.080 --> 00:18:54.080]   It's exactly the same.
[00:18:54.080 --> 00:18:55.080]   I know who his girlfriend is.
[00:18:55.080 --> 00:18:56.080]   I know when he's at the office.
[00:18:56.080 --> 00:18:58.080]   I mean, hyper-trending isn't that specific thing.
[00:18:58.080 --> 00:18:59.080]   It is.
[00:18:59.080 --> 00:19:00.080]   It is hyper-public.
[00:19:00.080 --> 00:19:05.360]   It is because all you have to do, as you pointed out, you can de-anonymize it by figuring
[00:19:05.360 --> 00:19:07.320]   out who's that guy that's going to all these bars.
[00:19:07.320 --> 00:19:13.880]   If you had something that was individual where you had an individual like the...
[00:19:13.880 --> 00:19:16.920]   The game that Dennis showed me, the monopoly game.
[00:19:16.920 --> 00:19:17.920]   Okay, yes, you're right.
[00:19:17.920 --> 00:19:19.400]   Because hyper-trending is the blog, right?
[00:19:19.400 --> 00:19:20.400]   It's not.
[00:19:20.400 --> 00:19:22.200]   This is more of like a hyper-trending thing.
[00:19:22.200 --> 00:19:23.200]   Right.
[00:19:23.200 --> 00:19:30.120]   Hyper-trending shows you essentially a list of stores or restaurants, places of business,
[00:19:30.120 --> 00:19:32.120]   and tells you how many people are there.
[00:19:32.120 --> 00:19:33.120]   So it's a lot.
[00:19:33.120 --> 00:19:34.120]   That's that specific moment.
[00:19:34.120 --> 00:19:35.120]   So it's a lie.
[00:19:35.120 --> 00:19:38.000]   It's not in Dennis who says, "Yeah, I know this is controversial.
[00:19:38.000 --> 00:19:39.840]   That's why we're showing everybody."
[00:19:39.840 --> 00:19:45.720]   That's a lie, because if they show them the lollipop game and what they really know,
[00:19:45.720 --> 00:19:47.960]   people would freak the hell out.
[00:19:47.960 --> 00:19:51.120]   Well, just like the gut mode from Uber.
[00:19:51.120 --> 00:19:52.120]   Exactly.
[00:19:52.120 --> 00:19:53.400]   Data didn't disappear.
[00:19:53.400 --> 00:20:00.120]   It's just that interface was hopefully made forbidden.
[00:20:00.120 --> 00:20:04.320]   And no one has access to it except a few very authorized people.
[00:20:04.320 --> 00:20:09.640]   But the fact that hyper-trending exists or not doesn't change the fact that all of
[00:20:09.640 --> 00:20:11.640]   them, you know, has the same flow.
[00:20:11.640 --> 00:20:13.400]   Data exists.
[00:20:13.400 --> 00:20:17.160]   And as anonymous as you claim to make it, it can be de-anonymized.
[00:20:17.160 --> 00:20:23.400]   I do have to point out that both Apple and Google claim they use technique to deeply
[00:20:23.400 --> 00:20:27.600]   anonymize it, which is not to take the full trip but a segment of the trip so they don't
[00:20:27.600 --> 00:20:30.560]   have a starting point and an ending point.
[00:20:30.560 --> 00:20:33.480]   They make some, I think, better efforts.
[00:20:33.480 --> 00:20:37.800]   And there are claims that you can supposedly, mathematically, prove that this stuff is
[00:20:37.800 --> 00:20:38.800]   anonymous.
[00:20:38.800 --> 00:20:42.480]   It doesn't look like four squares making any attempt to do that at all.
[00:20:42.480 --> 00:20:47.760]   Every company trusts themselves and their message to the public is, hey, trust us.
[00:20:47.760 --> 00:20:50.400]   We're Google, Apple, four square, et cetera, et cetera.
[00:20:50.400 --> 00:20:51.400]   We're AT&T.
[00:20:51.400 --> 00:20:52.400]   We're this company.
[00:20:52.400 --> 00:20:53.400]   We're that company.
[00:20:53.400 --> 00:20:54.400]   Trust us.
[00:20:54.400 --> 00:20:55.680]   We will keep your data secure.
[00:20:55.680 --> 00:20:56.680]   We won't be hacked.
[00:20:56.680 --> 00:20:57.680]   We won't share it.
[00:20:57.680 --> 00:20:58.840]   We won't de-anonymize it.
[00:20:58.840 --> 00:21:00.000]   We none of that stuff is going to happen.
[00:21:00.000 --> 00:21:03.160]   Of course, all those things happen all the time.
[00:21:03.160 --> 00:21:07.280]   And it's just it's something that everybody needs to be much more aware of.
[00:21:07.280 --> 00:21:10.360]   And I think that we need help from all quarters.
[00:21:10.360 --> 00:21:19.400]   We need phones that can turn off location by default quickly, more conveniently, more
[00:21:19.400 --> 00:21:22.680]   transparently, and a whole bunch of other things.
[00:21:22.680 --> 00:21:24.680]   Because right now it's just it's getting to the point.
[00:21:24.680 --> 00:21:29.720]   And again, I'm kind of amazed at this conversation because this is almost exactly the conversation
[00:21:29.720 --> 00:21:31.440]   we're going to have about Facebook.
[00:21:31.440 --> 00:21:34.920]   There are many, many points and we're going to do all these things.
[00:21:34.920 --> 00:21:37.120]   It's actually a good table setter for the Facebook.
[00:21:37.120 --> 00:21:38.120]   A conversation.
[00:21:38.120 --> 00:21:43.120]   Paris, when you interviewed Dennis, what was the sense you got from him?
[00:21:43.120 --> 00:21:44.800]   Was he proud of this?
[00:21:44.800 --> 00:21:51.760]   Did he understand how upset people would be if they knew that he had this lollipop game?
[00:21:51.760 --> 00:21:54.720]   He was speaking about it like it was the most normal thing in the world.
[00:21:54.720 --> 00:21:58.640]   And I think at one point later in our conversation, I was like, this is honestly very surprising
[00:21:58.640 --> 00:21:59.640]   to me.
[00:21:59.640 --> 00:22:01.840]   Because one, I mean, I'm a tech reporter.
[00:22:01.840 --> 00:22:06.320]   I follow these faces pretty thoroughly and regularly.
[00:22:06.320 --> 00:22:11.360]   And it didn't seem obvious to me or my editor even when we had walked when we were talking
[00:22:11.360 --> 00:22:15.520]   about this conversation to begin with that this sort of granular level of data was something
[00:22:15.520 --> 00:22:19.280]   that Four Square had and was playing with on a regular basis.
[00:22:19.280 --> 00:22:24.240]   And I think he replied something, the effect of, oh, yeah, this happens to us all the time.
[00:22:24.240 --> 00:22:33.720]   We don't realize how, I guess, not callous or how blaise we are towards things that anybody
[00:22:33.720 --> 00:22:38.200]   outside of our company would be like, oh, my God, wow, you have this sort of information.
[00:22:38.200 --> 00:22:42.960]   I think he said that he often, whenever he has conversations with his mom or sister or
[00:22:42.960 --> 00:22:49.160]   family members and mentioned some of the things that they do, he gets shocked back and stepped
[00:22:49.160 --> 00:22:50.400]   back into reality.
[00:22:50.400 --> 00:22:56.720]   This is why these people should not be allowed to decide what this stuff, because they're
[00:22:56.720 --> 00:22:58.480]   completely in a way to its wife.
[00:22:58.480 --> 00:23:02.280]   Uber didn't realize how horrific God mode was.
[00:23:02.280 --> 00:23:07.960]   I mean, they're so callous about this that they should not be allowed to make decisions.
[00:23:07.960 --> 00:23:12.080]   Four Square even has a, it's like a tech ethicist panel.
[00:23:12.080 --> 00:23:17.600]   They have a group of thinkers in the space where they've hired any time somebody says,
[00:23:17.600 --> 00:23:19.800]   oh, this might be a controversial subject.
[00:23:19.800 --> 00:23:20.740]   They work for four-
[00:23:20.740 --> 00:23:21.740]   But it's this panel.
[00:23:21.740 --> 00:23:22.740]   Yeah.
[00:23:22.740 --> 00:23:26.840]   And I mean, but to what Mike was saying, how do we address this?
[00:23:26.840 --> 00:23:33.280]   You were saying we need an easy way to manage location services on the iPhone, at least.
[00:23:33.280 --> 00:23:36.560]   I'm guessing it's the same case on Android phones.
[00:23:36.560 --> 00:23:41.920]   It's very easy to go in and disable location services as a whole or per application.
[00:23:41.920 --> 00:23:46.480]   Yeah, but the minute you open your map, it starts sending data back to four Square.
[00:23:46.480 --> 00:23:47.480]   The minute you open.
[00:23:47.480 --> 00:23:49.840]   No, not if you disable it for applications.
[00:23:49.840 --> 00:23:52.920]   Well, then it's used because it doesn't know where you are.
[00:23:52.920 --> 00:23:53.920]   Yes, exactly.
[00:23:53.920 --> 00:23:59.360]   So, well, so people should stop using weather apps, map apps.
[00:23:59.360 --> 00:24:03.200]   I mean, so many apps know your location, stop using Yelp.
[00:24:03.200 --> 00:24:06.920]   Even if you only send location when the app is running, which is probably the right default
[00:24:06.920 --> 00:24:11.800]   setting for all of these, you're sending out enough information that could be.
[00:24:11.800 --> 00:24:18.200]   I think the real issue here is there are so many signals that somebody with the desire
[00:24:18.200 --> 00:24:22.800]   to combine signals is going to get a very complete map.
[00:24:22.800 --> 00:24:28.000]   So really, the only way is just to not carry a smartphone.
[00:24:28.000 --> 00:24:30.200]   But are people willing to do that?
[00:24:30.200 --> 00:24:37.640]   I think that the idea of consent, like, consent in these cases is an illusion when it's just
[00:24:37.640 --> 00:24:42.720]   a binary choice when it comes to our privacy settings, whether it's if it's you get this
[00:24:42.720 --> 00:24:46.520]   feature or you get access to Facebook and the things that you need to be a person in
[00:24:46.520 --> 00:24:52.720]   the world, unfortunately, nowadays, or you don't if you want to not send all of your
[00:24:52.720 --> 00:24:54.200]   information out.
[00:24:54.200 --> 00:24:57.600]   And even in the cases of, okay, let's say you turn off location services for one thing
[00:24:57.600 --> 00:25:02.680]   and you only use it for one second to order your Uber, you're still sending out just more
[00:25:02.680 --> 00:25:06.720]   -- when we think of location services, maybe we think of you're sending out one signal,
[00:25:06.720 --> 00:25:09.440]   but no, your phone is sending out.
[00:25:09.440 --> 00:25:12.680]   Here are the 10 Bluetooth signals I'm picking up next to me.
[00:25:12.680 --> 00:25:15.560]   Here are all the Wi-Fi networks that I can read.
[00:25:15.560 --> 00:25:21.240]   They're using GPS, GSM, and all of that's going to four square or Google or whoever,
[00:25:21.240 --> 00:25:26.320]   who is then going to check that against their range of locations to be like, oh, Paris is
[00:25:26.320 --> 00:25:27.920]   at World Trade Center.
[00:25:27.920 --> 00:25:29.560]   I'm going to send her Uber there.
[00:25:29.560 --> 00:25:35.880]   Just to flesh out what Patrick was saying, the situation with user control of location
[00:25:35.880 --> 00:25:37.960]   data apps is getting better.
[00:25:37.960 --> 00:25:43.280]   And I know on Android, it's constantly saying, hey, this app is using your location.
[00:25:43.280 --> 00:25:44.280]   Is that okay?
[00:25:44.280 --> 00:25:45.280]   And you can just write their changes.
[00:25:45.280 --> 00:25:46.280]   >> I always does that.
[00:25:46.280 --> 00:25:47.280]   Not right.
[00:25:47.280 --> 00:25:48.280]   >> Android does that too.
[00:25:48.280 --> 00:25:49.280]   So they both do it.
[00:25:49.280 --> 00:25:51.200]   They both made improvements.
[00:25:51.200 --> 00:25:56.280]   But the problem is that, like you mentioned Uber, the way it really should work is at the
[00:25:56.280 --> 00:26:00.520]   point when you're ready to order an Uber, you should have an explicit option to turn
[00:26:00.520 --> 00:26:05.880]   on location for Uber, the Uber app and say, okay, I'm going to turn this on until my
[00:26:05.880 --> 00:26:08.920]   car comes and then it goes off automatically or something like that.
[00:26:08.920 --> 00:26:13.200]   That would be the user advocacy default.
[00:26:13.200 --> 00:26:18.240]   But it's actually the industry advocacy default, which is that the Uber is tracking you all
[00:26:18.240 --> 00:26:19.240]   the time.
[00:26:19.240 --> 00:26:20.840]   >> And you have to actively say no.
[00:26:20.840 --> 00:26:21.840]   >> Yeah.
[00:26:21.840 --> 00:26:24.400]   And you have to- >> But in addition to that, that you
[00:26:24.400 --> 00:26:27.860]   should be able to say, okay, if I want to share my data and location data for that one
[00:26:27.860 --> 00:26:33.660]   moment to Uber, I can only consent to it being used for things related to my Uber ride.
[00:26:33.660 --> 00:26:34.660]   >> That's the key.
[00:26:34.660 --> 00:26:35.660]   There you go, Bingo.
[00:26:35.660 --> 00:26:39.420]   >> And they can't be used for any other services or it can't be shared with advertisers.
[00:26:39.420 --> 00:26:43.500]   It can't be used to be a hyperload, hyper trending map.
[00:26:43.500 --> 00:26:45.220]   >> Don't put the burden on the user.
[00:26:45.220 --> 00:26:50.220]   Put the burden on these companies not to aggregate and share this data because that's
[00:26:50.220 --> 00:26:51.740]   what's wrong.
[00:26:51.740 --> 00:26:56.580]   Why is it sent to four square in the first place, I guess is a good question.
[00:26:56.580 --> 00:26:58.620]   So do we need legislation?
[00:26:58.620 --> 00:27:00.460]   That's where I'm going to lose all of you.
[00:27:00.460 --> 00:27:01.460]   Oh yes, okay, excellent.
[00:27:01.460 --> 00:27:02.940]   >> Yeah, I think so.
[00:27:02.940 --> 00:27:06.500]   >> It's the only solution because they're not going to sell for a good way.
[00:27:06.500 --> 00:27:11.380]   And all you have to ask is if an adversary got access to this information, would that
[00:27:11.380 --> 00:27:12.620]   be a bad thing?
[00:27:12.620 --> 00:27:17.660]   If the Chinese government were able to get access to this four square information, would
[00:27:17.660 --> 00:27:19.540]   that be a bad thing?
[00:27:19.540 --> 00:27:24.820]   And if you say yes to that, then we've got to do something about it because there's no
[00:27:24.820 --> 00:27:28.020]   way that an adversary is not actively trying to get all this information.
[00:27:28.020 --> 00:27:30.100]   >> No way that they don't already have it.
[00:27:30.100 --> 00:27:31.420]   >> Well, they probably have it.
[00:27:31.420 --> 00:27:34.620]   >> The issue is that you can't really close the doors on data.
[00:27:34.620 --> 00:27:39.260]   There's no expiration date for your consent when it comes to the sort of data that you're
[00:27:39.260 --> 00:27:40.260]   handing over.
[00:27:40.260 --> 00:27:44.500]   Let's say, okay, four square allows one of, let's say Uber and some of the third parties
[00:27:44.500 --> 00:27:46.340]   that it works with.
[00:27:46.340 --> 00:27:50.060]   All it takes is one of those third parties breaking their contract with four square and
[00:27:50.060 --> 00:27:53.780]   sharing that data with somebody else who decided to pay them a million dollars for the data
[00:27:53.780 --> 00:27:54.780]   they have.
[00:27:54.780 --> 00:27:57.900]   And then that person shares it with someone else and so on and so forth.
[00:27:57.900 --> 00:27:58.900]   >> Who knows?
[00:27:58.900 --> 00:28:07.140]   Maybe there's some Chinese shell company posing as, I don't know, American massage parlor
[00:28:07.140 --> 00:28:12.820]   entrepreneur that is buying this data already from four square and from Google.
[00:28:12.820 --> 00:28:14.820]   It's from legitimate advertising.
[00:28:14.820 --> 00:28:16.580]   >> You'd have to think.
[00:28:16.580 --> 00:28:26.580]   You'd have to hope that when Uber or an app sends the data to four square, it's maybe
[00:28:26.580 --> 00:28:32.540]   somewhat identifiable, but then four square actually anonymizes it and you can't really
[00:28:32.540 --> 00:28:34.860]   be found afterwards.
[00:28:34.860 --> 00:28:38.580]   I mean, we don't know that for sure, but I would guess that's what they do.
[00:28:38.580 --> 00:28:44.660]   They have some kind of process so that you don't actually have your ID number that can
[00:28:44.660 --> 00:28:49.060]   be easily attached to you, I would guess.
[00:28:49.060 --> 00:28:53.940]   >> But to Leo's point, it's easily discernible to figure out who people are.
[00:28:53.940 --> 00:28:54.940]   >> Could be anonymizes.
[00:28:54.940 --> 00:28:58.900]   >> Right, and everything's ultimately associated with a phone number and the phone number is
[00:28:58.900 --> 00:29:01.300]   gold and you can figure out everything.
[00:29:01.300 --> 00:29:05.980]   This is like the, remember the conversations we used to have about the NSA spying and they're
[00:29:05.980 --> 00:29:07.500]   like, oh, it's just metadata.
[00:29:07.500 --> 00:29:09.180]   A metadata takes you everything.
[00:29:09.180 --> 00:29:10.180]   >> Yeah, we now know.
[00:29:10.180 --> 00:29:11.180]   >> Yeah.
[00:29:11.180 --> 00:29:12.180]   >> And this is like metadata.
[00:29:12.180 --> 00:29:15.620]   Even if it's anonymized, it's all the contextual data.
[00:29:15.620 --> 00:29:19.980]   Well, who is it that spends their days at this company and lives in this neighborhood
[00:29:19.980 --> 00:29:24.500]   and drops off their child at this daycare center and frequently goes to this other person's
[00:29:24.500 --> 00:29:28.740]   house, you can figure out who that is and even if you don't know who it is by name,
[00:29:28.740 --> 00:29:31.060]   you know everything else about that person.
[00:29:31.060 --> 00:29:33.620]   It's enough information to do anything you want to do.
[00:29:33.620 --> 00:29:36.620]   It's also, I mean, everything's a mixed bag and technology, right?
[00:29:36.620 --> 00:29:41.180]   So this knowledge about how many people are in the building and the cafeteria downstairs,
[00:29:41.180 --> 00:29:44.780]   really valuable knowledge for firefighters, for example.
[00:29:44.780 --> 00:29:48.060]   >> Or in all sorts of beneficial ways, you can think of it.
[00:29:48.060 --> 00:29:49.060]   >> Right.
[00:29:49.060 --> 00:29:52.540]   >> So it's even for you, you may not want to go because it's too busy to fast forward
[00:29:52.540 --> 00:29:53.540]   to what I think.
[00:29:53.540 --> 00:29:56.700]   >> Yeah, there's the thing on Google Maps that shows you, okay, that's the thing that's
[00:29:56.700 --> 00:29:57.700]   more busy around.
[00:29:57.700 --> 00:29:58.700]   >> Yeah.
[00:29:58.700 --> 00:29:59.700]   >> Yeah, right.
[00:29:59.700 --> 00:30:00.700]   >> And that's the exact same.
[00:30:00.700 --> 00:30:05.500]   >> I have to think it's Cinderella or Larry Page is going, Dennis, you knit with, you don't
[00:30:05.500 --> 00:30:07.180]   tell people this stuff.
[00:30:07.180 --> 00:30:08.180]   >> That's right.
[00:30:08.180 --> 00:30:09.180]   >> Keep it a secret.
[00:30:09.180 --> 00:30:11.700]   >> We're not going to put location.
[00:30:11.700 --> 00:30:16.340]   It reminded me, and this is going to be obscure to anybody over a certain age, but it reminded
[00:30:16.340 --> 00:30:18.260]   me of the Marauders map in Harry Potter.
[00:30:18.260 --> 00:30:19.940]   Paris knows what I'm talking about.
[00:30:19.940 --> 00:30:20.940]   >> Yeah.
[00:30:20.940 --> 00:30:25.020]   >> It was a map, and if you take your one, you go, I solemnly swear I'm up to no good
[00:30:25.020 --> 00:30:30.740]   and you tap it, all of a sudden it comes alive and shows the location of everybody in Hogwarts.
[00:30:30.740 --> 00:30:33.660]   As they walk around, it was hugely valuable to Harry and his team.
[00:30:33.660 --> 00:30:34.660]   It's good.
[00:30:34.660 --> 00:30:35.660]   Watch the movie, kids.
[00:30:35.660 --> 00:30:36.660]   It's fantastic.
[00:30:36.660 --> 00:30:37.660]   Anyway.
[00:30:37.660 --> 00:30:38.660]   >> Definitely a privacy violation.
[00:30:38.660 --> 00:30:40.740]   >> Or read the book, read the book, man.
[00:30:40.740 --> 00:30:44.180]   >> Yeah, I was just teasing, obviously read the book.
[00:30:44.180 --> 00:30:49.340]   It's like that, but what if Pokemon go, suddenly I solemnly swear I'm up to no good, you tapped
[00:30:49.340 --> 00:30:55.100]   it, and you could see every Pokemon player or anybody would install that ever in their
[00:30:55.100 --> 00:30:59.220]   location, it would immediately come home to the American public.
[00:30:59.220 --> 00:31:01.700]   That's the big, oh shoot moment.
[00:31:01.700 --> 00:31:02.700]   >> Yeah.
[00:31:02.700 --> 00:31:07.540]   >> I guess we know that Facebook and Google have profiles like these with that amount of
[00:31:07.540 --> 00:31:08.540]   sensitive data.
[00:31:08.540 --> 00:31:09.540]   >> You know in the back of our minds.
[00:31:09.540 --> 00:31:10.540]   >> I'm not kidding.
[00:31:10.540 --> 00:31:13.740]   >> Yeah, at least we know.
[00:31:13.740 --> 00:31:21.540]   I don't think any of us knew that Four Square had a profile with that much personal and
[00:31:21.540 --> 00:31:23.220]   here's my sensitive data, right?
[00:31:23.220 --> 00:31:28.020]   >> That there are many more big data brokers that we don't even know their name.
[00:31:28.020 --> 00:31:33.980]   I bet Paris knows some of them that are doing, they have exactly the same information.
[00:31:33.980 --> 00:31:37.620]   And the real fear is that somebody goes out and buys three or four of these databases
[00:31:37.620 --> 00:31:41.380]   in real time, and it gets a real time fire hose of them, because that now suddenly you've
[00:31:41.380 --> 00:31:44.260]   got this amazingly granular map of pretty much everybody.
[00:31:44.260 --> 00:31:50.260]   I don't think it should be on us as users not to have a smartphone or make sure we turn
[00:31:50.260 --> 00:31:51.260]   off privacy.
[00:31:51.260 --> 00:31:55.420]   I think it should be illegal to collect certain kinds of information and sell it and share.
[00:31:55.420 --> 00:31:58.740]   >> Here's what I think the theme of this show will be at the end of the show.
[00:31:58.740 --> 00:32:03.140]   I think the theme will be that clearly our laws don't reflect the 21st century.
[00:32:03.140 --> 00:32:04.140]   >> No.
[00:32:04.140 --> 00:32:05.740]   >> And we need a tech new deal.
[00:32:05.740 --> 00:32:06.980]   You heard it here first.
[00:32:06.980 --> 00:32:07.980]   >> Is it green?
[00:32:07.980 --> 00:32:12.140]   >> Yeah, that's another new deal.
[00:32:12.140 --> 00:32:14.100]   This isn't even a newer deal.
[00:32:14.100 --> 00:32:18.100]   We need to update our laws around antitrust, around privacy.
[00:32:18.100 --> 00:32:21.940]   I mean, back in the day, back in the 20th century, where all of our current laws were
[00:32:21.940 --> 00:32:27.820]   written, basically, we had laws sort of like public television had to have a certain number
[00:32:27.820 --> 00:32:32.820]   of hours of XYZ because they were using the public's resource, the airwaves, right?
[00:32:32.820 --> 00:32:34.660]   There was this idea that there was.
[00:32:34.660 --> 00:32:35.660]   >> Boy, is that coming?
[00:32:35.660 --> 00:32:38.420]   Nobody was like, oh my God, overregulation.
[00:32:38.420 --> 00:32:42.700]   Who owns the data about where you are?
[00:32:42.700 --> 00:32:43.980]   >> Do do's four squared?
[00:32:43.980 --> 00:32:46.820]   I mean, they're acting like they own it.
[00:32:46.820 --> 00:32:47.820]   >> You gave it to them.
[00:32:47.820 --> 00:32:48.820]   >> That's right.
[00:32:48.820 --> 00:32:51.500]   So maybe we need laws that say, okay, here's who owns that information.
[00:32:51.500 --> 00:32:55.300]   >> I confess I've been a bad boy for years.
[00:32:55.300 --> 00:32:57.780]   I've argued, oh, who cares?
[00:32:57.780 --> 00:32:59.780]   Let them have my data.
[00:32:59.780 --> 00:33:05.340]   There's so much value in this that I don't care if Google knows where I am.
[00:33:05.340 --> 00:33:08.820]   And that's why I think what actually Dennis did, and maybe he knew what he was doing,
[00:33:08.820 --> 00:33:13.180]   what Dennis actually did is kind of bring it home to some people.
[00:33:13.180 --> 00:33:18.140]   And I think if somebody made a map that was like this Marauders map, but it showed everybody
[00:33:18.140 --> 00:33:23.340]   in your town and where they were, there would be instant regulation.
[00:33:23.340 --> 00:33:27.100]   Instantly, I think there's no question about it.
[00:33:27.100 --> 00:33:28.100]   People would hop.
[00:33:28.100 --> 00:33:29.100]   They'd be so mad.
[00:33:29.100 --> 00:33:31.180]   >> I think you have a lot of faith in the public.
[00:33:31.180 --> 00:33:33.820]   >> Oh, I think if they saw it, they'd freak out.
[00:33:33.820 --> 00:33:35.020]   Wouldn't you freak out?
[00:33:35.020 --> 00:33:37.620]   If there were an app on your phone, somebody should do this.
[00:33:37.620 --> 00:33:41.020]   >> I mean, that's the snap map, but you have to agree to it.
[00:33:41.020 --> 00:33:43.420]   >> Yeah, it's only people who use Snapchat, right?
[00:33:43.420 --> 00:33:46.020]   >> Yeah, people who use ads on there.
[00:33:46.020 --> 00:33:47.020]   >> Yeah.
[00:33:47.020 --> 00:33:48.020]   >> But I think it's not so bad.
[00:33:48.020 --> 00:33:51.780]   I don't think it's okay if Leo knows where his friends are, what's so bad about that.
[00:33:51.780 --> 00:33:57.100]   But what if every one of us knew where every single, what if there were a Petaluma app that
[00:33:57.100 --> 00:34:01.100]   showed you where every single resident of Petaluma was at any every given time?
[00:34:01.100 --> 00:34:06.620]   >> But Leo, you keep saying that the fact that this data exists somewhere doesn't mean
[00:34:06.620 --> 00:34:08.220]   that people are doing it.
[00:34:08.220 --> 00:34:14.020]   It's like that that Marauder's map, it's essentially the Uber God mode, right?
[00:34:14.020 --> 00:34:18.860]   Someone did it indeed, and very quickly, they were shut down.
[00:34:18.860 --> 00:34:23.460]   I would hope that if someone was using the data the same way.
[00:34:23.460 --> 00:34:24.460]   >> They weren't shut down.
[00:34:24.460 --> 00:34:25.460]   They were told not to use it.
[00:34:25.460 --> 00:34:27.020]   >> I doubt very much it doesn't exist.
[00:34:27.020 --> 00:34:29.860]   >> But because, no, of course, of course, but it exists everywhere.
[00:34:29.860 --> 00:34:38.500]   I guess what we come back to is we need regulation for these types of data as, well, everyone
[00:34:38.500 --> 00:34:43.020]   was arguing that, I think, is possibly the conclusion of this conversation.
[00:34:43.020 --> 00:34:46.500]   It's so much and such important data.
[00:34:46.500 --> 00:34:51.460]   It needs to be regulated, and currently it is not regulated at all.
[00:34:51.460 --> 00:34:53.460]   >> I think that's the final word.
[00:34:53.460 --> 00:34:55.620]   We all agree, so say we all.
[00:34:55.620 --> 00:34:56.620]   >> All right.
[00:34:56.620 --> 00:34:57.620]   >> All right.
[00:34:57.620 --> 00:35:03.420]   I hate to say we got to regulate it, especially because we have such a dysfunctional government
[00:35:03.420 --> 00:35:04.420]   that I don't--
[00:35:04.420 --> 00:35:05.420]   >> Don't say--
[00:35:05.420 --> 00:35:07.820]   >> We've had this argument before, Patrick.
[00:35:07.820 --> 00:35:09.940]   >> Yes, we have.
[00:35:09.940 --> 00:35:17.420]   What happens when you say stuff like that is put into people's head this idea that government
[00:35:17.420 --> 00:35:24.020]   can't function to do what it's supposed to do while at the same time saying, but we need
[00:35:24.020 --> 00:35:25.860]   to be regulated.
[00:35:25.860 --> 00:35:29.220]   Of course, government is not going to be perfect, and of course, there are going to be some
[00:35:29.220 --> 00:35:34.540]   things that are not-- it's not understanding, and something it doesn't do properly, and maybe
[00:35:34.540 --> 00:35:41.140]   even the laws that it would pass would not be imperfect in many ways.
[00:35:41.140 --> 00:35:47.300]   But if you say, if you follow up the idea that it should be regulated by the caveat,
[00:35:47.300 --> 00:35:51.700]   oh, but the government can't really do it, then obviously, nothing's going to happen.
[00:35:51.700 --> 00:35:53.100]   >> You're right.
[00:35:53.100 --> 00:35:54.820]   I shouldn't come from despair.
[00:35:54.820 --> 00:35:56.420]   I should come from hope.
[00:35:56.420 --> 00:35:58.700]   >> Or it makes us go.
[00:35:58.700 --> 00:35:59.700]   >> Bill Clinton.
[00:35:59.700 --> 00:36:01.340]   Still believe in a place like called hope.
[00:36:01.340 --> 00:36:03.260]   >> I believe in a place called hope.
[00:36:03.260 --> 00:36:08.900]   I want to live there with my girlfriend and Hillary.
[00:36:08.900 --> 00:36:11.100]   We're going to take a little break after that.
[00:36:11.100 --> 00:36:16.700]   I should just edit that part out, which is because that was tasteless.
[00:36:16.700 --> 00:36:17.700]   We shall continue.
[00:36:17.700 --> 00:36:22.460]   I mean, this wasn't even-- this was going to be the-- the moose bush before we got to the
[00:36:22.460 --> 00:36:23.460]   main course.
[00:36:23.460 --> 00:36:24.460]   >> That's right.
[00:36:24.460 --> 00:36:25.460]   >> It's going to be a long main course.
[00:36:25.460 --> 00:36:27.860]   >> It's going to be a big main course because we still have to talk about--
[00:36:27.860 --> 00:36:28.860]   >> More like a big meal.
[00:36:28.860 --> 00:36:29.860]   >> --and it is related.
[00:36:29.860 --> 00:36:33.300]   Facebook's saying, no, privacy first.
[00:36:33.300 --> 00:36:35.580]   And Elizabeth Warren's saying, I got a solution.
[00:36:35.580 --> 00:36:36.580]   Don't regulate.
[00:36:36.580 --> 00:36:37.580]   I'm just break the hell.
[00:36:37.580 --> 00:36:38.580]   Break them all up.
[00:36:38.580 --> 00:36:42.220]   >> After we talk about Facebook, we're all going to wish 4 square health control of all
[00:36:42.220 --> 00:36:43.220]   the data.
[00:36:43.220 --> 00:36:45.060]   >> There's a lot more.
[00:36:45.060 --> 00:36:47.260]   And there's, I mean, a hundred other stories too.
[00:36:47.260 --> 00:36:49.020]   We'll try to get to as many of them as we can.
[00:36:49.020 --> 00:36:52.220]   But as always, it's the big stories that interest us the most.
[00:36:52.220 --> 00:36:55.380]   Patrick Végia is here representing the EU.
[00:36:55.380 --> 00:36:58.380]   >> All of the EU perspectives.
[00:36:58.380 --> 00:37:00.980]   >> I speak for all of us.
[00:37:00.980 --> 00:37:04.900]   >> All of the EU is French spin comments, always a pleasure.
[00:37:04.900 --> 00:37:10.600]   Actually, I really do like having you on, Patrick, because we often, especially on
[00:37:10.600 --> 00:37:16.580]   Twitter, but in general, all Americans kind of have a US-centric point of view.
[00:37:16.580 --> 00:37:20.460]   The EU has really been in the forefront, especially in these kinds of privacy regulations.
[00:37:20.460 --> 00:37:26.020]   So it's good to have you arguing for the sanctity of government.
[00:37:26.020 --> 00:37:32.220]   >> With a perfect example of what I was saying, which is the laws might be necessary, but
[00:37:32.220 --> 00:37:34.180]   they're not perfect and highly--
[00:37:34.180 --> 00:37:43.300]   >> I think I'd rather see a GDPR for the US than a breakup of Amazon, Google, Apple.
[00:37:43.300 --> 00:37:44.740]   >> Well, we're getting one for California.
[00:37:44.740 --> 00:37:47.020]   >> Yeah, we'll see how that works.
[00:37:47.020 --> 00:37:48.020]   >> I'm sorry.
[00:37:48.020 --> 00:37:49.020]   No, I have hope.
[00:37:49.020 --> 00:37:52.020]   >> I believe.
[00:37:52.020 --> 00:37:55.420]   >> Paris Martynos here, she is staff writer at Wired.
[00:37:55.420 --> 00:37:57.420]   I didn't realize you were in New York.
[00:37:57.420 --> 00:38:02.540]   I'm glad you were joining us all the way from far, far away.
[00:38:02.540 --> 00:38:03.540]   Good day.
[00:38:03.540 --> 00:38:04.540]   >> I am.
[00:38:04.540 --> 00:38:06.820]   I'm 29 floors up right now.
[00:38:06.820 --> 00:38:08.420]   >> Wow, nice.
[00:38:08.420 --> 00:38:11.140]   Is it the Condi Nast building?
[00:38:11.140 --> 00:38:13.380]   >> Yeah, it's Condi Nast.
[00:38:13.380 --> 00:38:14.780]   It's in World Trade Center.
[00:38:14.780 --> 00:38:15.860]   >> Oh, wow.
[00:38:15.860 --> 00:38:16.860]   That's a good location.
[00:38:16.860 --> 00:38:20.460]   >> Yeah, I'm surprised you can kind of see out the windows back here.
[00:38:20.460 --> 00:38:21.460]   >> Yeah.
[00:38:21.460 --> 00:38:24.300]   >> It could be incredibly foggy and you cannot see the-- basically, the entire building is
[00:38:24.300 --> 00:38:25.300]   gone.
[00:38:25.300 --> 00:38:29.580]   >> So you're at floor 29-- don't ever say gone in World Trade Center in the same sense.
[00:38:29.580 --> 00:38:34.220]   You're on floor 29 of one World Trade Center, which goes how many floors up?
[00:38:34.220 --> 00:38:36.540]   >> Oh, I honestly have no idea.
[00:38:36.540 --> 00:38:37.540]   >> A lot?
[00:38:37.540 --> 00:38:38.540]   >> Quite a few floors.
[00:38:38.540 --> 00:38:39.540]   >> Like a hundred or so.
[00:38:39.540 --> 00:38:41.500]   >> I know that the hundred at the very least, I think.
[00:38:41.500 --> 00:38:42.500]   Yeah.
[00:38:42.500 --> 00:38:45.700]   I know we have a coffee shop on the 64th and that's barely in the middle.
[00:38:45.700 --> 00:38:47.460]   So probably quite a bit.
[00:38:47.460 --> 00:38:48.460]   >> Wow.
[00:38:48.460 --> 00:38:49.460]   That's amazing.
[00:38:49.460 --> 00:38:51.460]   >> We need buildings like that in San Francisco.
[00:38:51.460 --> 00:38:52.860]   >> It's a really cool building.
[00:38:52.860 --> 00:38:53.860]   >> Yeah.
[00:38:53.860 --> 00:38:56.060]   And Mike Elgin is here, World Traveler.
[00:38:56.060 --> 00:38:57.060]   >> Yes.
[00:38:57.060 --> 00:38:59.660]   >> He most recently was in-- we're Morocco.
[00:38:59.660 --> 00:39:02.900]   And next week, we're going to Mexico City to do the Mexico City experience.
[00:39:02.900 --> 00:39:03.900]   >> What a life.
[00:39:03.900 --> 00:39:04.900]   >> What a life.
[00:39:04.900 --> 00:39:05.900]   >> And then back to Morocco for the Morocco experience.
[00:39:05.900 --> 00:39:11.940]   And yeah, Gastronomad.net if you want to find out what Mike's up to with that.
[00:39:11.940 --> 00:39:16.060]   And in fact, if you go to Gastronomad.net and click the experiences button, you can see
[00:39:16.060 --> 00:39:19.140]   upcoming Gastronomad experiences.
[00:39:19.140 --> 00:39:24.940]   >> Last year, before the Provence experience, I did the show and I said, "I want to twit
[00:39:24.940 --> 00:39:26.540]   Army fan to join us."
[00:39:26.540 --> 00:39:27.540]   >> Nice.
[00:39:27.540 --> 00:39:29.460]   >> And somebody joined us from Twit Army.
[00:39:29.460 --> 00:39:30.460]   >> Nice.
[00:39:30.460 --> 00:39:33.180]   >> And I want to do that again from Mexico City.
[00:39:33.180 --> 00:39:34.300]   We got a room for you.
[00:39:34.300 --> 00:39:36.300]   >> These are small groups.
[00:39:36.300 --> 00:39:38.660]   You all live in the same building.
[00:39:38.660 --> 00:39:44.580]   You guys, you and Amira, your beautiful wife, go to a place, find all the greatest chefs
[00:39:44.580 --> 00:39:49.340]   and interesting gastronomic experiences, find a wonderful place to stay and you all stay
[00:39:49.340 --> 00:39:50.340]   together.
[00:39:50.340 --> 00:39:51.340]   You have dinners together.
[00:39:51.340 --> 00:39:52.340]   You get plenty of time to tour as well.
[00:39:52.340 --> 00:39:53.340]   >> We make stuff.
[00:39:53.340 --> 00:39:57.340]   Like in Mexico, we make tacos, we make bread, we make all the stuff, chocolate from scratch.
[00:39:57.340 --> 00:39:58.340]   >> So fun.
[00:39:58.340 --> 00:40:00.780]   >> We plant the seed and wait for it to grow and then we make the chocolate.
[00:40:00.780 --> 00:40:01.780]   >> So fun.
[00:40:01.780 --> 00:40:04.180]   And is your Mexico City location near the Zocalo?
[00:40:04.180 --> 00:40:05.180]   Is that--?
[00:40:05.180 --> 00:40:06.460]   >> It is literally on the Zocalo.
[00:40:06.460 --> 00:40:07.820]   >> Oh, that's so cool.
[00:40:07.820 --> 00:40:09.860]   We have a view of the--.
[00:40:09.860 --> 00:40:10.860]   I think that's a surprise.
[00:40:10.860 --> 00:40:11.860]   My wife's going to kill me.
[00:40:11.860 --> 00:40:12.860]   We keep all these things surprising.
[00:40:12.860 --> 00:40:13.860]   >> It's a good location.
[00:40:13.860 --> 00:40:14.860]   >> It's a great location.
[00:40:14.860 --> 00:40:16.860]   >> Very central, shall we say.
[00:40:16.860 --> 00:40:17.860]   >> Yes.
[00:40:17.860 --> 00:40:18.860]   >> Look at that.
[00:40:18.860 --> 00:40:19.860]   Oh, man.
[00:40:19.860 --> 00:40:20.860]   >> Yeah.
[00:40:20.860 --> 00:40:21.860]   >> And then next Morocco, that's in Fez.
[00:40:21.860 --> 00:40:22.860]   >> That's a two-week experience.
[00:40:22.860 --> 00:40:23.860]   We're doing the whole country.
[00:40:23.860 --> 00:40:24.860]   >> Oh, nice.
[00:40:24.860 --> 00:40:25.940]   >> Yeah, yeah.
[00:40:25.940 --> 00:40:28.180]   And so, yeah, it's going to be fantastic.
[00:40:28.180 --> 00:40:31.820]   >> This is a nice little side kind of gig for you.
[00:40:31.820 --> 00:40:32.820]   >> It's--.
[00:40:32.820 --> 00:40:33.820]   I'm along for the ride.
[00:40:33.820 --> 00:40:34.980]   I mean, my wife does all the work.
[00:40:34.980 --> 00:40:37.980]   She literally spends months at every location putting these things--
[00:40:37.980 --> 00:40:39.900]   >> And Amira's one of the best cooks I've ever--
[00:40:39.900 --> 00:40:40.900]   I mean, just amazing.
[00:40:40.900 --> 00:40:41.900]   >> It really is.
[00:40:41.900 --> 00:40:42.900]   She really is.
[00:40:42.900 --> 00:40:46.900]   >> But you also bring in local chefs, and I know you've had bread makers and so forth.
[00:40:46.900 --> 00:40:47.900]   >> Yeah.
[00:40:47.900 --> 00:40:52.220]   >> Then Prosecco, Italy, and then Provence, and you're going to do Barcelona again.
[00:40:52.220 --> 00:40:53.220]   And this is cool.
[00:40:53.220 --> 00:40:54.220]   >> That's cool again.
[00:40:54.220 --> 00:40:55.220]   >> This is cool.
[00:40:55.220 --> 00:40:56.220]   >> Yeah, we're going to--.
[00:40:56.220 --> 00:40:59.020]   We keep adding them because for the Prosecco experience, it filled up just immediately.
[00:40:59.020 --> 00:41:00.020]   So we had to do another.
[00:41:00.020 --> 00:41:01.020]   >> Wow.
[00:41:01.020 --> 00:41:02.020]   >> Yeah.
[00:41:02.020 --> 00:41:03.020]   >> It's for you.
[00:41:03.020 --> 00:41:04.020]   >> Yeah, so we're doing three this year.
[00:41:04.020 --> 00:41:07.020]   We're going to see Mike's writing in Computer World and--
[00:41:07.020 --> 00:41:08.020]   >> Fast Company.
[00:41:08.020 --> 00:41:11.060]   >> Fast Company and not much on Google Plus anymore.
[00:41:11.060 --> 00:41:12.060]   >> Not really.
[00:41:12.060 --> 00:41:13.060]   I did a final--.
[00:41:13.060 --> 00:41:14.780]   >> Did you do a farewell?
[00:41:14.780 --> 00:41:16.580]   >> I did on Fast Company.
[00:41:16.580 --> 00:41:17.580]   >> Yeah.
[00:41:17.580 --> 00:41:21.620]   >> I think it was a eulogy for the last great social network that was the headline.
[00:41:21.620 --> 00:41:25.500]   >> Well, and in a way, and we'll talk about it, I think what Mark's proposing sounds a
[00:41:25.500 --> 00:41:27.420]   little bit like Google Plus.
[00:41:27.420 --> 00:41:29.220]   >> I'll tell you what it sounds--.
[00:41:29.220 --> 00:41:30.220]   Well, okay.
[00:41:30.220 --> 00:41:31.220]   We'll save it.
[00:41:31.220 --> 00:41:32.220]   >> We'll get to that next.
[00:41:32.220 --> 00:41:33.220]   >> I'll save it.
[00:41:33.220 --> 00:41:34.220]   >> From Wasabi.
[00:41:34.220 --> 00:41:37.140]   Wasabi is hot.
[00:41:37.140 --> 00:41:38.620]   Cloud storage, hot.
[00:41:38.620 --> 00:41:39.620]   That is.
[00:41:39.620 --> 00:41:41.460]   You know, cloud storage is on a roll.
[00:41:41.460 --> 00:41:43.940]   This is a huge category.
[00:41:43.940 --> 00:41:49.740]   Almost all businesses are at this point considering some move to the cloud of data.
[00:41:49.740 --> 00:41:58.660]   It's estimated in the next six years, by 2025, there'll be 163 zettabytes of data in the
[00:41:58.660 --> 00:42:03.700]   cloud that's 163 followed by 21 zeros.
[00:42:03.700 --> 00:42:05.620]   That's a lot of data.
[00:42:05.620 --> 00:42:10.060]   And choosing a cloud provider is a really, really big deal.
[00:42:10.060 --> 00:42:14.420]   Cloud data, if done right, is probably more secure than your on-premises storage.
[00:42:14.420 --> 00:42:15.940]   It can save you money.
[00:42:15.940 --> 00:42:18.780]   It's more robust, more reliable, but it has to be done right.
[00:42:18.780 --> 00:42:20.820]   And that's why I'm really glad to talk about Wasabi.
[00:42:20.820 --> 00:42:25.020]   It was started by my friend, David Friend, who was the founder of Carbonite, along with
[00:42:25.020 --> 00:42:28.460]   his CTO, Jeff Flowers.
[00:42:28.460 --> 00:42:33.580]   They came up at Carbonite with a patented method for writing to hard drives.
[00:42:33.580 --> 00:42:36.940]   It lays the data on the disks sequentially, not via blocks.
[00:42:36.940 --> 00:42:42.180]   And that makes it faster and more efficient, which means it's also less expensive.
[00:42:42.180 --> 00:42:47.820]   And that's the technology that patent technology that Wasabi is using to store efficiently
[00:42:47.820 --> 00:42:53.220]   and affordably the data your business wants to save up in the cloud.
[00:42:53.220 --> 00:42:56.580]   This is disruptive technology, but they got to get the word out.
[00:42:56.580 --> 00:43:01.380]   I said, "I, David, Jeff, I will help you because I am such a believer in this.
[00:43:01.380 --> 00:43:02.700]   I know it's the big three.
[00:43:02.700 --> 00:43:03.980]   You get all the attention.
[00:43:03.980 --> 00:43:07.380]   And probably if you're putting together a cloud strategy for your company, of course,
[00:43:07.380 --> 00:43:09.740]   you're thinking Amazon, Google, Microsoft.
[00:43:09.740 --> 00:43:17.100]   But what if I tell you that Wasabi is 80% cheaper and six times faster than Amazon's
[00:43:17.100 --> 00:43:18.340]   S3?
[00:43:18.340 --> 00:43:19.340]   It uses the S3 API.
[00:43:19.340 --> 00:43:20.980]   So you already know how to use it.
[00:43:20.980 --> 00:43:23.300]   All your software already knows how to use it.
[00:43:23.300 --> 00:43:26.620]   But it's 80% cheaper and six times the speed.
[00:43:26.620 --> 00:43:27.620]   And it's very simple.
[00:43:27.620 --> 00:43:29.260]   The pricing couldn't be more simple.
[00:43:29.260 --> 00:43:31.620]   There's just one tier of service.
[00:43:31.620 --> 00:43:34.060]   And unlike the other guys, they don't charge you for egress.
[00:43:34.060 --> 00:43:37.100]   You get free, unlimited egress.
[00:43:37.100 --> 00:43:39.980]   So that really helps your budgeting and planning because you don't even think about it.
[00:43:39.980 --> 00:43:41.620]   It's just how much are we going to put up there?
[00:43:41.620 --> 00:43:43.060]   That's all you think about.
[00:43:43.060 --> 00:43:46.340]   They have a form of data that is, I think, super vital.
[00:43:46.340 --> 00:43:47.340]   I love this idea.
[00:43:47.340 --> 00:43:48.860]   It's called immutable storage.
[00:43:48.860 --> 00:43:53.220]   You can designate some of your cloud storage unchangeable, not by malware.
[00:43:53.220 --> 00:43:54.220]   Not by a ransomware.
[00:43:54.220 --> 00:43:56.340]   Not by a fumble-fingered employee.
[00:43:56.340 --> 00:43:57.820]   That data is protected.
[00:43:57.820 --> 00:44:00.420]   You have to jump through hoops to write to it.
[00:44:00.420 --> 00:44:01.420]   And that's huge.
[00:44:01.420 --> 00:44:02.580]   I think that's brilliant.
[00:44:02.580 --> 00:44:04.220]   It's just as secure because of that.
[00:44:04.220 --> 00:44:07.940]   And of course, all the things they're doing then on-premises storage, I would say it's
[00:44:07.940 --> 00:44:09.980]   more secure in most cases.
[00:44:09.980 --> 00:44:14.100]   It's HIPAA compliant, FINRA compliant, CJIS compliant.
[00:44:14.100 --> 00:44:17.740]   And if you have a lot of data to start, you want to migrate a petabytes of data, you can
[00:44:17.740 --> 00:44:22.660]   do that with the Wasabi Ball, which is a really cool technology, a physical drive.
[00:44:22.660 --> 00:44:24.380]   You copy the data to send it to a Sabi.
[00:44:24.380 --> 00:44:26.020]   It's up in the cloud.
[00:44:26.020 --> 00:44:29.460]   Experience Wasabi for yourself with free unlimited storage for a month.
[00:44:29.460 --> 00:44:30.940]   That's better than the normal deal.
[00:44:30.940 --> 00:44:34.420]   You're going in through a special wasabi.com trial offer.
[00:44:34.420 --> 00:44:38.780]   Use the offer code TWIT to turn that terabyte of storage to an unlimited amount so you can
[00:44:38.780 --> 00:44:39.860]   really bang on it.
[00:44:39.860 --> 00:44:42.060]   Upload everything wasabi.com.
[00:44:42.060 --> 00:44:43.060]   W-A-S-A-B-I.com.
[00:44:43.060 --> 00:44:46.740]   Don't forget to use the offer code TWIT.
[00:44:46.740 --> 00:44:48.980]   All right.
[00:44:48.980 --> 00:44:53.420]   I think we need to go to Facebook now.
[00:44:53.420 --> 00:44:57.820]   I maybe got a little over-optimistic when I read this and I read it on Wednesday.
[00:44:57.820 --> 00:45:06.260]   Mark Zuckerberg's more than 3,000 word post, a privacy-focused vision for social networking.
[00:45:06.260 --> 00:45:08.660]   I got so excited by this.
[00:45:08.660 --> 00:45:10.140]   Oops.
[00:45:10.140 --> 00:45:11.140]   You had hope, Leo.
[00:45:11.140 --> 00:45:13.540]   First mistake of reading a Mark Zuckerberg 3.com.
[00:45:13.540 --> 00:45:14.540]   I know.
[00:45:14.540 --> 00:45:15.700]   I fell for it.
[00:45:15.700 --> 00:45:20.100]   I had deactivated my Facebook account back in August.
[00:45:20.100 --> 00:45:26.420]   I reactivated it and I posted for the first time in six months saying, "Wait a minute.
[00:45:26.420 --> 00:45:32.380]   Let me justify this saying, 'Look, I don't know if Mark's sincere, but if he is, this
[00:45:32.380 --> 00:45:37.540]   is the social network I want and I'm going to stay on Facebook to find out.'
[00:45:37.540 --> 00:45:43.940]   Now the minute he proves to be insincere about this, I will be gone again because anybody
[00:45:43.940 --> 00:45:45.100]   who uses Facebook.
[00:45:45.100 --> 00:45:48.500]   Incidentally, that number is dwindling.
[00:45:48.500 --> 00:45:53.980]   We just saw a statistic that said the number of posts on Facebook is down 25%.
[00:45:53.980 --> 00:45:59.260]   Number of people using Facebook under the age of 25 is dwindled by millions.
[00:45:59.260 --> 00:46:01.180]   Millions of people are leaving the platform.
[00:46:01.180 --> 00:46:07.820]   Facebook is under investigation by Congress, by Parliament in the UK.
[00:46:07.820 --> 00:46:12.140]   We keep hearing every week more horrific security stories.
[00:46:12.140 --> 00:46:18.900]   Next week, in fact, coincident with this announcement, it came out that Facebook was using your phone
[00:46:18.900 --> 00:46:23.060]   number that they asked for for two-factor authentication as a way of identifying you
[00:46:23.060 --> 00:46:26.380]   and that there was searchable and there was no way to turn that off.
[00:46:26.380 --> 00:46:28.220]   They're making it available to advertisers.
[00:46:28.220 --> 00:46:32.660]   They sell ads against it even though they were saying, "Oh, it's just two-factor."
[00:46:32.660 --> 00:46:34.660]   That day's a tenet time and time again.
[00:46:34.660 --> 00:46:38.820]   There's been no evidence that Facebook or Mark Zuckerberg cares the least for our privacy
[00:46:38.820 --> 00:46:40.020]   or security.
[00:46:40.020 --> 00:46:46.140]   It seems to be or our laws, the only thing Facebook cares about is making more money.
[00:46:46.140 --> 00:46:52.180]   Then Mark writes his post and I want to give people the benefit of the doubt.
[00:46:52.180 --> 00:46:54.980]   You guys, let me just say what Mark said.
[00:46:54.980 --> 00:46:56.780]   You guys can talk me off the...
[00:46:56.780 --> 00:46:58.500]   Actually, I was off the ledge.
[00:46:58.500 --> 00:46:59.500]   Talk me back on the ledge.
[00:46:59.500 --> 00:47:00.780]   Talk me back on the ledge.
[00:47:00.780 --> 00:47:03.260]   Talk me back on the ledge.
[00:47:03.260 --> 00:47:05.140]   My focus, Mark, I'm not going to read the whole thing.
[00:47:05.140 --> 00:47:06.140]   I'm going to set it up.
[00:47:06.140 --> 00:47:08.660]   My focus for the last couple of years has been understanding and addressing the biggest
[00:47:08.660 --> 00:47:09.660]   challenges Facebook.
[00:47:09.660 --> 00:47:13.340]   In fact, he said that was going to be his challenge for this year.
[00:47:13.340 --> 00:47:16.020]   He used to only eat food that he killed.
[00:47:16.020 --> 00:47:21.220]   Now he's saying, "I'm going to outline our vision and principles around building a privacy
[00:47:21.220 --> 00:47:22.220]   focused message."
[00:47:22.220 --> 00:47:24.500]   Now, this is important.
[00:47:24.500 --> 00:47:28.100]   Messaging and social networking platform.
[00:47:28.100 --> 00:47:31.980]   Essentially, I saw this as a pivot.
[00:47:31.980 --> 00:47:36.460]   Now, I've read a lot since I read this, but at the...
[00:47:36.460 --> 00:47:41.260]   I think it's still, if you read it at face value, if you give Mark credit for being sincere,
[00:47:41.260 --> 00:47:42.940]   it still is a pivot.
[00:47:42.940 --> 00:47:49.260]   He's saying public social networks would continue to be very important in people's lives.
[00:47:49.260 --> 00:47:50.900]   People find these valuable every day.
[00:47:50.900 --> 00:47:54.540]   There are a lot of services to build on them, but now with all the ways people also want
[00:47:54.540 --> 00:48:00.660]   to interact privately, there's an opportunity to build a simpler platform that's focused
[00:48:00.660 --> 00:48:02.060]   on privacy first.
[00:48:02.060 --> 00:48:03.380]   That's why I say it's a pivot.
[00:48:03.380 --> 00:48:06.180]   Facebook right now is public.
[00:48:06.180 --> 00:48:09.220]   Your stuff leaks out of it, even if you say it's private.
[00:48:09.220 --> 00:48:10.220]   He says, "I understand.
[00:48:10.220 --> 00:48:13.700]   Many people don't think Facebook can or you would even want to build this kind of privacy
[00:48:13.700 --> 00:48:18.860]   focused platform because frankly, we don't have a strong reputation for that.
[00:48:18.860 --> 00:48:25.020]   We've focused on tools for more open sharing, but I believe the future of communication
[00:48:25.020 --> 00:48:27.700]   will increasingly shift to private.
[00:48:27.700 --> 00:48:28.700]   Encrypted...
[00:48:28.700 --> 00:48:30.180]   Whoa, when I saw that, I went, "What?
[00:48:30.180 --> 00:48:31.180]   Services."
[00:48:31.180 --> 00:48:35.060]   When he says encrypted, he says, "I want to do end-to-end encryption.
[00:48:35.060 --> 00:48:39.100]   We won't even be able to read your transactions."
[00:48:39.100 --> 00:48:40.580]   Here's the principles.
[00:48:40.580 --> 00:48:41.580]   Private interactions.
[00:48:41.580 --> 00:48:45.500]   People should have simple, intimate places where they have clear control over who can communicate
[00:48:45.500 --> 00:48:46.780]   with them.
[00:48:46.780 --> 00:48:51.860]   I read that to be advertisers and confidence that no one else can access what they share.
[00:48:51.860 --> 00:48:53.980]   Even Facebook.
[00:48:53.980 --> 00:48:57.860]   People's communication should be encrypted end-to-end prevents anyone, including us from seeing
[00:48:57.860 --> 00:49:00.540]   what people share on our services.
[00:49:00.540 --> 00:49:01.540]   Here's another one.
[00:49:01.540 --> 00:49:06.460]   Straight from the Snapchat playbook, reducing permanence.
[00:49:06.460 --> 00:49:09.340]   One of the problems with Facebook and the web in general is everything posted there
[00:49:09.340 --> 00:49:10.340]   lives forever.
[00:49:10.340 --> 00:49:12.020]   You just said it yourself, Mike.
[00:49:12.020 --> 00:49:14.700]   People should be comfortable being themselves and should not have to worry about what they
[00:49:14.700 --> 00:49:16.700]   share coming back to hurt them later.
[00:49:16.700 --> 00:49:21.500]   In fact, many psychologists and others of social scientists have observed that it's
[00:49:21.500 --> 00:49:25.020]   really important, especially for young people, is the ability to try personas and then leave
[00:49:25.020 --> 00:49:26.780]   them behind.
[00:49:26.780 --> 00:49:28.140]   That's why young people love Snapchat.
[00:49:28.140 --> 00:49:32.740]   They can try stuff on, but it doesn't haunt them for the rest of their life.
[00:49:32.740 --> 00:49:37.780]   He says, "We won't keep messages or stories around for longer than necessary to deliver
[00:49:37.780 --> 00:49:40.740]   the service or longer than people want them."
[00:49:40.740 --> 00:49:42.540]   That's Snapchat.
[00:49:42.540 --> 00:49:43.540]   Safety.
[00:49:43.540 --> 00:49:46.140]   People should expect we'll do everything we can to keep them safe on our limits.
[00:49:46.140 --> 00:49:47.580]   This is really interesting.
[00:49:47.580 --> 00:49:51.820]   Within the limits of what's possible in an encrypted service, he's tacitly acknowledging
[00:49:51.820 --> 00:49:58.140]   that if we can't see the messages that are being sent, people could bully you.
[00:49:58.140 --> 00:50:01.460]   But presumably, they're going to give you strong controls that allow you to say, "I
[00:50:01.460 --> 00:50:03.540]   don't want to hear from that person ever again."
[00:50:03.540 --> 00:50:04.780]   Interoperability.
[00:50:04.780 --> 00:50:07.860]   This is a controversial one and it's not clear what he means.
[00:50:07.860 --> 00:50:10.380]   People should be able to use any of our apps.
[00:50:10.380 --> 00:50:15.260]   That means Facebook, Instagram, and WhatsApp to reach their friends.
[00:50:15.260 --> 00:50:17.460]   But then this is the sentence that I'm not sure what he means.
[00:50:17.460 --> 00:50:19.700]   They should be able to communicate across networks.
[00:50:19.700 --> 00:50:21.580]   Does that mean just within the Facebook network?
[00:50:21.580 --> 00:50:22.580]   Yes.
[00:50:22.580 --> 00:50:29.820]   He's mentioning text messages as well, which could open the door to other things.
[00:50:29.820 --> 00:50:34.460]   Obviously, he's not specifically naming other companies, but the fact that he's saying it
[00:50:34.460 --> 00:50:40.100]   could be used via SMS as well could arguably be.
[00:50:40.100 --> 00:50:42.340]   Finally, and this was another one that was a big deal.
[00:50:42.340 --> 00:50:47.460]   I thought, "Secure data storage, people should expect we won't store sensitive data in countries
[00:50:47.460 --> 00:50:49.580]   with weak records on human rights."
[00:50:49.580 --> 00:50:52.020]   Now we already know Facebook doesn't operate in China.
[00:50:52.020 --> 00:50:54.020]   China won't let it.
[00:50:54.020 --> 00:50:55.020]   But it does.
[00:50:55.020 --> 00:50:59.700]   It's a little shot across Tim Cookspow saying, "We're not going to, Apple stores your data
[00:50:59.700 --> 00:51:01.940]   in China with the keys.
[00:51:01.940 --> 00:51:03.380]   We're not going to do that.
[00:51:03.380 --> 00:51:05.740]   It means there's no way they could operate in China."
[00:51:05.740 --> 00:51:08.180]   Now, I love this.
[00:51:08.180 --> 00:51:13.660]   Obviously, this is turning your back on a significant amount of revenue, the ad revenue
[00:51:13.660 --> 00:51:14.660]   that Facebook gets.
[00:51:14.660 --> 00:51:16.620]   I think there are opportunities.
[00:51:16.620 --> 00:51:18.980]   Here's what I interpret this and I'm not alone in this.
[00:51:18.980 --> 00:51:23.460]   It seems to me, Facebook's looking at WeChat and China line in Japan.
[00:51:23.460 --> 00:51:28.740]   Those are messaging platforms that have turned into really platforms for almost every kind
[00:51:28.740 --> 00:51:35.140]   of interaction, including financial transactions, purchasing of plane tickets, socializing.
[00:51:35.140 --> 00:51:38.180]   The idea that I could control, who could talk to me?
[00:51:38.180 --> 00:51:41.660]   This is like Google+, this is what I like in the Google+, who could talk to me, who I
[00:51:41.660 --> 00:51:42.700]   would hear from.
[00:51:42.700 --> 00:51:46.580]   If a brand wanted to talk to me, they wouldn't get to unless I give them permission, permission
[00:51:46.580 --> 00:51:48.780]   which could be revoked at any time.
[00:51:48.780 --> 00:51:49.980]   I love this notion.
[00:51:49.980 --> 00:51:53.860]   I think this is exactly what people want for a social network.
[00:51:53.860 --> 00:51:58.500]   What they thought Facebook was, I will decide who gets to see my posts.
[00:51:58.500 --> 00:51:59.780]   It's going to be my family and friends.
[00:51:59.780 --> 00:52:01.300]   It's not going to be advertisers.
[00:52:01.300 --> 00:52:02.780]   It's not going to be Russia.
[00:52:02.780 --> 00:52:06.020]   I think this is what people thought they were getting with Facebook.
[00:52:06.020 --> 00:52:10.900]   I think this, here was my initial theory, talk me up on the ledge again.
[00:52:10.900 --> 00:52:17.460]   I thought Mark was seeing the horror of what he'd created maybe just because of the personal
[00:52:17.460 --> 00:52:25.580]   risk that he's facing from regulation, breakup, maybe going to jail, I don't know, and saying,
[00:52:25.580 --> 00:52:27.100]   "All right, all right, you don't like it.
[00:52:27.100 --> 00:52:28.940]   I got a new idea."
[00:52:28.940 --> 00:52:34.420]   An idea I think Facebook is looking at line in WeChat and saying, "They're doing pretty
[00:52:34.420 --> 00:52:35.420]   well."
[00:52:35.420 --> 00:52:41.140]   In fact, one of the reasons Facebook never had a chance in China is because of WeChat.
[00:52:41.140 --> 00:52:48.580]   I think, honestly, that if I were Mark Zuckerberg, I would like this plan.
[00:52:48.580 --> 00:52:50.060]   All right, I'm done.
[00:52:50.060 --> 00:52:53.340]   I'm with you, actually, Leo.
[00:52:53.340 --> 00:52:54.340]   I'm actually with you.
[00:52:54.340 --> 00:52:56.340]   I think this is momentous.
[00:52:56.340 --> 00:53:01.900]   Now, if we take it at face value, I think it's very easy to go, "Oh, of course, he has
[00:53:01.900 --> 00:53:09.540]   never been truthful or trustworthy with any of his declarations before.
[00:53:09.540 --> 00:53:10.900]   Why would we trust him now?"
[00:53:10.900 --> 00:53:14.500]   I don't think we should trust him just on this, but I think it has value.
[00:53:14.500 --> 00:53:18.340]   I don't think he can say all of these things and then do nothing.
[00:53:18.340 --> 00:53:27.380]   The list, as you remarked, is essentially the dream of any anti-Facebook person.
[00:53:27.380 --> 00:53:30.260]   This is the perfect social network he's describing.
[00:53:30.260 --> 00:53:33.140]   Except for law enforcement.
[00:53:33.140 --> 00:53:34.460]   They're going to hate this.
[00:53:34.460 --> 00:53:36.660]   Except for data collection and tracking.
[00:53:36.660 --> 00:53:43.140]   Except for people who accept all of his customers are going to hate it, but his users are going
[00:53:43.140 --> 00:53:44.140]   to love it.
[00:53:44.140 --> 00:53:50.740]   He even says we will work with law enforcement to do whatever we can do to help them do their
[00:53:50.740 --> 00:53:51.740]   job.
[00:53:51.740 --> 00:53:55.660]   But honestly, if I were Facebook, I know Apple wants to do this.
[00:53:55.660 --> 00:53:58.380]   I would just make it encrypted and say, "Hey, I'm sorry, but we can't."
[00:53:58.380 --> 00:54:00.220]   Yeah, but there's some awful lot.
[00:54:00.220 --> 00:54:01.220]   There's patterns.
[00:54:01.220 --> 00:54:03.900]   Yeah, then how are you supposed to moderate things?
[00:54:03.900 --> 00:54:04.900]   You can't.
[00:54:04.900 --> 00:54:05.900]   He said it.
[00:54:05.900 --> 00:54:08.940]   Yeah, I mean, then we're going to have the same issue that we have with WhatsApp in the
[00:54:08.940 --> 00:54:12.340]   sense that you can spread rap.
[00:54:12.340 --> 00:54:13.340]   You decide.
[00:54:13.340 --> 00:54:17.140]   And then when something happens exactly in the same cases, what's happening in India,
[00:54:17.140 --> 00:54:24.500]   or in regards to Myanmar and fake news bringing about death on such a massive scale, what
[00:54:24.500 --> 00:54:26.780]   do we suppose to then allow it to spread?
[00:54:26.780 --> 00:54:28.860]   Well, Myanmar's a little different.
[00:54:28.860 --> 00:54:35.500]   Myanmar was they were able to use the very public platform of Facebook to say, wipe out
[00:54:35.500 --> 00:54:36.500]   the Rohingya.
[00:54:36.500 --> 00:54:37.500]   Okay, we'll talk about it.
[00:54:37.500 --> 00:54:38.500]   But WhatsApp is a good example.
[00:54:38.500 --> 00:54:39.500]   Because that WhatsApp is an encrypted...
[00:54:39.500 --> 00:54:41.500]   And that is part of Facebook.
[00:54:41.500 --> 00:54:43.620]   One-to-one messaging with group messaging.
[00:54:43.620 --> 00:54:47.500]   It was used to cause people's deaths, mass rapes.
[00:54:47.500 --> 00:54:49.260]   It was a very, very bad thing.
[00:54:49.260 --> 00:54:50.660]   Child pornography is big on one of them.
[00:54:50.660 --> 00:54:51.660]   Using fake news.
[00:54:51.660 --> 00:54:54.060]   And they have a huge problem.
[00:54:54.060 --> 00:54:59.140]   They have limited the sizes of groups and things like that, which doesn't solve everything.
[00:54:59.140 --> 00:55:01.100]   But it's not like bad things will happen.
[00:55:01.100 --> 00:55:03.100]   That's easier to solve.
[00:55:03.100 --> 00:55:04.100]   That's easier to solve.
[00:55:04.100 --> 00:55:09.660]   But then the Myanmar issue and the Cambridge Analytic issue, which are much more intractable
[00:55:09.660 --> 00:55:12.420]   issues, if you continue to run a public network, that's really...
[00:55:12.420 --> 00:55:14.060]   What do you do about anti-vaxxers?
[00:55:14.060 --> 00:55:16.780]   It becomes really, really difficult.
[00:55:16.780 --> 00:55:23.540]   But I think this is akin to what Zuckerberg saw when he saw things moving in the mobile
[00:55:23.540 --> 00:55:25.260]   world.
[00:55:25.260 --> 00:55:28.860]   And he decided Facebook is going to be a mobile first company.
[00:55:28.860 --> 00:55:30.660]   And we're going to all focus on this.
[00:55:30.660 --> 00:55:36.980]   And he managed in what two years to make Facebook primarily a mobile company.
[00:55:36.980 --> 00:55:39.700]   I don't know that he's right, that everything has to go private.
[00:55:39.700 --> 00:55:42.700]   I think that is something a lot of people do want.
[00:55:42.700 --> 00:55:49.060]   And I think he has the power and determination to make it happen.
[00:55:49.060 --> 00:55:50.060]   He does.
[00:55:50.060 --> 00:55:51.060]   He does.
[00:55:51.060 --> 00:55:53.820]   Well, that's the question I have.
[00:55:53.820 --> 00:55:54.820]   That's the question I have.
[00:55:54.820 --> 00:55:55.820]   Privacy first.
[00:55:55.820 --> 00:55:58.380]   Some have said, "Oh, he's going to still have public Facebook.
[00:55:58.380 --> 00:55:59.940]   He's just going to do this with WhatsApp.
[00:55:59.940 --> 00:56:01.180]   He's going to just do this with Messenger."
[00:56:01.180 --> 00:56:07.740]   He's going to connect all the messaging platforms and Facebook together so that you can do
[00:56:07.740 --> 00:56:11.740]   and then encryption to and from and within all of them.
[00:56:11.740 --> 00:56:14.260]   And he's going to say that's this big privacy thing.
[00:56:14.260 --> 00:56:16.100]   That there's still a big public Facebook.
[00:56:16.100 --> 00:56:17.100]   Right, of course.
[00:56:17.100 --> 00:56:18.940]   And people are going to want to do whatever they want to do.
[00:56:18.940 --> 00:56:19.940]   That's not how I read it.
[00:56:19.940 --> 00:56:20.940]   I really read that he...
[00:56:20.940 --> 00:56:21.940]   No, me neither.
[00:56:21.940 --> 00:56:23.540]   He clarifies this in his interview.
[00:56:23.540 --> 00:56:27.780]   He did with Nick later that day on Wednesday or whatever it was.
[00:56:27.780 --> 00:56:32.620]   I believe says, "The thinking is that there needs to be two types of platforms in the
[00:56:32.620 --> 00:56:33.620]   world.
[00:56:33.620 --> 00:56:37.740]   One is a more public platform, like the digital equivalent of the town square, and then the
[00:56:37.740 --> 00:56:39.340]   other platform is a private space."
[00:56:39.340 --> 00:56:40.340]   Living room.
[00:56:40.340 --> 00:56:42.140]   The digital equivalent of a living room.
[00:56:42.140 --> 00:56:47.540]   And then you're going to have the Facebook and Instagrams and the WhatsApp and Messenger's.
[00:56:47.540 --> 00:56:52.420]   But they're both there, but they're both kind of separate and working for different groups
[00:56:52.420 --> 00:56:53.420]   and for different reasons.
[00:56:53.420 --> 00:56:55.220]   Leo, can I burn his whole post down?
[00:56:55.220 --> 00:56:56.220]   Yeah, burn it around the square.
[00:56:56.220 --> 00:56:57.900]   I burn it around the square.
[00:56:57.900 --> 00:56:59.700]   And I want you all to join me on this legend.
[00:56:59.700 --> 00:57:01.900]   We'll jump together holding hands on the weeds.
[00:57:01.900 --> 00:57:02.900]   Okay, good.
[00:57:02.900 --> 00:57:03.900]   I like it.
[00:57:03.900 --> 00:57:10.340]   Okay, so the way I look at this is he's trying to get credit for everything he's resisted.
[00:57:10.340 --> 00:57:14.340]   They wouldn't let him into China because China wants to control the Chinese public through
[00:57:14.340 --> 00:57:15.340]   WeChat.
[00:57:15.340 --> 00:57:17.460]   WeChat is the Mark Zuckerberg wet dream.
[00:57:17.460 --> 00:57:19.620]   You can't scratch your butt in China without WeChat.
[00:57:19.620 --> 00:57:20.660]   Yeah, you can't ride a train.
[00:57:20.660 --> 00:57:21.660]   You can't get a coffee.
[00:57:21.660 --> 00:57:22.660]   You can't spread a bill.
[00:57:22.660 --> 00:57:23.660]   Exactly.
[00:57:23.660 --> 00:57:24.660]   You can't get an opportunity.
[00:57:24.660 --> 00:57:25.660]   And he's like, "That's what I want."
[00:57:25.660 --> 00:57:34.300]   He wants to make Facebook 10 times more invasive and 10 times more of a monopoly in the whole
[00:57:34.300 --> 00:57:36.620]   non-Chinese world than it is today.
[00:57:36.620 --> 00:57:37.620]   He wants to make WeChat.
[00:57:37.620 --> 00:57:39.180]   That's what Molly Wood said in Wirehouse.
[00:57:39.180 --> 00:57:43.020]   He wants you using Facebook coin to buy everything through WeChat.
[00:57:43.020 --> 00:57:44.660]   He wants everything to happen through WeChat.
[00:57:44.660 --> 00:57:51.100]   He wants to know exactly where everyone is at all times far more information than Four
[00:57:51.100 --> 00:57:52.820]   Square has.
[00:57:52.820 --> 00:57:55.620]   He's going to know what you buy, who you buy it for, who you meet with.
[00:57:55.620 --> 00:57:58.980]   So there's plenty of opportunity to make money.
[00:57:58.980 --> 00:58:03.780]   He wants to make 10 times more money by being 10 times more of a monopoly.
[00:58:03.780 --> 00:58:07.780]   And the way to get there is to say, "We're going to be WeChat within encryption."
[00:58:07.780 --> 00:58:08.780]   Right.
[00:58:08.780 --> 00:58:12.900]   We're going to be the justifiably, morally superior version of WeChat because we're
[00:58:12.900 --> 00:58:13.900]   going to have encryption.
[00:58:13.900 --> 00:58:18.380]   Unlike WeChat, we just, you know, an entirely different thing altogether.
[00:58:18.380 --> 00:58:23.660]   What this blog post represents to me is he's basically announced that we got a few more
[00:58:23.660 --> 00:58:27.180]   things that were going to copy the remaining two things from Snapchat that we didn't copy
[00:58:27.180 --> 00:58:28.180]   previously.
[00:58:28.180 --> 00:58:29.660]   And then we're going to start copying WeChat.
[00:58:29.660 --> 00:58:31.660]   We're going to copy everything they do.
[00:58:31.660 --> 00:58:37.100]   And by the way, there's three stories a day recently about all the transgressions Facebook
[00:58:37.100 --> 00:58:39.380]   has committed against everybody.
[00:58:39.380 --> 00:58:42.100]   They're harvesting data about women's menstrual cycles.
[00:58:42.100 --> 00:58:45.020]   They're harvesting data about people's heart rates.
[00:58:45.020 --> 00:58:49.020]   They're taking phone, they're requiring you to use a phone for two-factor authentication.
[00:58:49.020 --> 00:58:51.580]   And they're selling your phone number to advertisers.
[00:58:51.580 --> 00:58:54.500]   All these stories are coming like this and he's like, "We got to distract everybody
[00:58:54.500 --> 00:58:56.380]   from this and give them some BS."
[00:58:56.380 --> 00:59:00.260]   And so they, he did this post and he said, "We're going to change all these things that
[00:59:00.260 --> 00:59:01.780]   aren't really the problem."
[00:59:01.780 --> 00:59:02.780]   He didn't mention tracking.
[00:59:02.780 --> 00:59:04.540]   He didn't mention shadow profiles.
[00:59:04.540 --> 00:59:06.580]   He didn't mention harvesting data.
[00:59:06.580 --> 00:59:11.940]   He didn't mention any of the things that are truly controversial.
[00:59:11.940 --> 00:59:17.340]   He came up with these other things that are less controversial, encrypted communication.
[00:59:17.340 --> 00:59:20.260]   He's basically saying you're going to be able to send email from CompuServe to Prodigy.
[00:59:20.260 --> 00:59:21.260]   Oh my God.
[00:59:21.260 --> 00:59:23.940]   It's like nobody has ever thought of it before and it's going to be encrypted.
[00:59:23.940 --> 00:59:24.940]   Who cares?
[00:59:24.940 --> 00:59:25.940]   Right.
[00:59:25.940 --> 00:59:26.940]   He doesn't care.
[00:59:26.940 --> 00:59:27.940]   It's not who cares, Mike.
[00:59:27.940 --> 00:59:28.940]   You're being disingenuous.
[00:59:28.940 --> 00:59:31.980]   It's still a big shift for a company like Facebook.
[00:59:31.980 --> 00:59:32.980]   It might...
[00:59:32.980 --> 00:59:33.980]   It's an inevitable shift.
[00:59:33.980 --> 00:59:36.740]   It has to offer encrypted communication.
[00:59:36.740 --> 00:59:38.580]   And what he wants to do is take all these...
[00:59:38.580 --> 00:59:40.740]   He's making a version of it in necessity.
[00:59:40.740 --> 00:59:41.740]   He wants to...
[00:59:41.740 --> 00:59:42.740]   He's got two million people on Facebook.
[00:59:42.740 --> 00:59:46.500]   He's got a one point something billion on this and that platform and another platform.
[00:59:46.500 --> 00:59:54.380]   He wants to take all four of them and combine them into one super network that's all connected.
[00:59:54.380 --> 00:59:59.260]   In China, there are a huge number of Chinese people who never use the actual internet.
[00:59:59.260 --> 01:00:00.860]   WeChat is everything online.
[01:00:00.860 --> 01:00:01.860]   That's what Facebook's...
[01:00:01.860 --> 01:00:02.860]   That's what Facebook's...
[01:00:02.860 --> 01:00:05.620]   You dream all along, by the way, with the internet.org.
[01:00:05.620 --> 01:00:12.100]   He's trying to convince everybody that it's a virtue for him to control all the users in
[01:00:12.100 --> 01:00:13.180]   a closed garden.
[01:00:13.180 --> 01:00:16.940]   It's a virtue that he has not allowed in China and I think he's going to get kicked out of
[01:00:16.940 --> 01:00:17.940]   Russia too.
[01:00:17.940 --> 01:00:20.780]   And I think he would be happy.
[01:00:20.780 --> 01:00:22.420]   I think he wants all the money.
[01:00:22.420 --> 01:00:25.780]   I think he wants the rubles and he would love to be in China.
[01:00:25.780 --> 01:00:26.780]   He tried really hard.
[01:00:26.780 --> 01:00:28.420]   He learned Mandarin, for God's sake.
[01:00:28.420 --> 01:00:29.420]   And then...
[01:00:29.420 --> 01:00:30.420]   Speaks it pretty well too.
[01:00:30.420 --> 01:00:31.420]   Yeah.
[01:00:31.420 --> 01:00:32.420]   And it didn't work.
[01:00:32.420 --> 01:00:34.260]   And so now he's trying to get credit for saying, "Oh, we're not going to work with those
[01:00:34.260 --> 01:00:38.540]   Chinese, the totalitarian countries anymore."
[01:00:38.540 --> 01:00:45.740]   It's a distraction and designed to make you feel comfortable about him becoming WeChat
[01:00:45.740 --> 01:00:48.020]   and really controlling everything.
[01:00:48.020 --> 01:00:49.020]   That's what I think.
[01:00:49.020 --> 01:00:50.020]   All right.
[01:00:50.020 --> 01:00:51.020]   We have polar opposites.
[01:00:51.020 --> 01:00:52.020]   Paris is in the middle.
[01:00:52.020 --> 01:00:53.020]   Yeah.
[01:00:53.020 --> 01:00:54.020]   I was just even on that note.
[01:00:54.020 --> 01:00:56.300]   Mike, it's not even that new of an announcement.
[01:00:56.300 --> 01:00:59.540]   What was it at the end of January?
[01:00:59.540 --> 01:01:04.300]   Zuckerberg had announced that he was planning on merging Facebook Messenger, Instagram and
[01:01:04.300 --> 01:01:08.500]   WhatsApp into one large pool that was encrypted, which is essentially the exact same thing.
[01:01:08.500 --> 01:01:10.860]   The same description as what he laid out in this post.
[01:01:10.860 --> 01:01:14.260]   I'll be out with more detail in 3000 more words.
[01:01:14.260 --> 01:01:20.780]   It is the logical business decision because Gen Z and people of that age, they don't go
[01:01:20.780 --> 01:01:21.780]   on Facebook.
[01:01:21.780 --> 01:01:26.380]   They're probably going to get Tired of Instagram by the time they have purchasing power and
[01:01:26.380 --> 01:01:28.060]   are going to be moving...
[01:01:28.060 --> 01:01:35.020]   Already have moved towards private communication as their primary social media platform.
[01:01:35.020 --> 01:01:38.980]   And the writing is in the wall and this is the best financial decision.
[01:01:38.980 --> 01:01:45.100]   And it is trying to spin it in a way that sounds appealing to consumers and sounds like
[01:01:45.100 --> 01:01:51.100]   a privacy-focused message and something that will distract people.
[01:01:51.100 --> 01:01:52.660]   Okay.
[01:01:52.660 --> 01:01:56.100]   I acknowledge that could be the case in which case I'll immediately delete my Facebook
[01:01:56.100 --> 01:01:57.100]   account again.
[01:01:57.100 --> 01:01:58.100]   All of the things...
[01:01:58.100 --> 01:02:00.740]   But shouldn't we encourage him to do the right thing?
[01:02:00.740 --> 01:02:02.620]   He's got the carrot.
[01:02:02.620 --> 01:02:04.540]   I mean, he's got the stick.
[01:02:04.540 --> 01:02:06.140]   You know, beating him.
[01:02:06.140 --> 01:02:08.340]   Shouldn't we put a carrot in front of him and say, "Yeah, Mark, that's it.
[01:02:08.340 --> 01:02:09.340]   Keep going that way."
[01:02:09.340 --> 01:02:10.340]   This is...
[01:02:10.340 --> 01:02:12.740]   He's trying to bulletproof the company from being broken up.
[01:02:12.740 --> 01:02:15.820]   Once everything is connected to these encrypted and then networks of...
[01:02:15.820 --> 01:02:18.780]   You can't get any broken up because it's not the reason for companies.
[01:02:18.780 --> 01:02:19.780]   Yeah.
[01:02:19.780 --> 01:02:22.060]   By the time they get around breaking it up, he's like, "Oh my God, we can't break it up.
[01:02:22.060 --> 01:02:24.100]   It's all so interconnected that it's all one big thing."
[01:02:24.100 --> 01:02:25.100]   It's a platform.
[01:02:25.100 --> 01:02:26.100]   Right.
[01:02:26.100 --> 01:02:27.900]   Well, I'm not...
[01:02:27.900 --> 01:02:32.140]   Paris, you believe that this is a cynical play on Mark's part.
[01:02:32.140 --> 01:02:36.380]   I mean, I just think that if we are talking about privacy, the issues, the fundamental
[01:02:36.380 --> 01:02:39.900]   issues when it comes to privacy in Facebook is not any...
[01:02:39.900 --> 01:02:44.980]   Most of the things from a consumer facing perspective as a platform, it is the back end,
[01:02:44.980 --> 01:02:50.500]   the advertising stuff, the tracking aspects of it, the shadow profiles, as you had mentioned
[01:02:50.500 --> 01:02:51.500]   before.
[01:02:51.500 --> 01:02:58.060]   It is this whole other separate side of Facebook that Zuckerberg doesn't address in these sort
[01:02:58.060 --> 01:02:59.060]   of posts.
[01:02:59.060 --> 01:03:04.500]   Sort of things that he is bringing up in his declaration, such as the one last week, is
[01:03:04.500 --> 01:03:11.460]   the consumer facing platform-centric decisions, which are ultimately missing the fundamental
[01:03:11.460 --> 01:03:15.060]   parts of this conversation that we're trying to have about privacy in Facebook.
[01:03:15.060 --> 01:03:17.420]   That blog post is right out of today's Washington, D.C.
[01:03:17.420 --> 01:03:23.860]   It was right out of Breitbart News or any of the spin control mechanisms that have been
[01:03:23.860 --> 01:03:28.380]   cultivated over the decades and are now in full force in Washington, D.C. and political
[01:03:28.380 --> 01:03:29.380]   speech.
[01:03:29.380 --> 01:03:31.100]   He's using them as a big distraction.
[01:03:31.100 --> 01:03:35.460]   He's trying to control the message around Facebook because it's gotten out of hand.
[01:03:35.460 --> 01:03:41.020]   Almost everything that Facebook has ever done that could be considered the right thing,
[01:03:41.020 --> 01:03:44.660]   they've been forced by bad press to do those things.
[01:03:44.660 --> 01:03:48.340]   It's like all this talk about giving them the benefit of the doubt, we've been giving
[01:03:48.340 --> 01:03:50.860]   him the benefit of the doubt for a decade.
[01:03:50.860 --> 01:03:52.580]   He's disappointed us every time.
[01:03:52.580 --> 01:03:58.180]   I've never seen anything come out of Facebook and Mark Zuckerberg that was preemptively doing
[01:03:58.180 --> 01:04:00.460]   the right thing because it was the right thing.
[01:04:00.460 --> 01:04:02.620]   But couldn't it be the first time?
[01:04:02.620 --> 01:04:03.620]   No.
[01:04:03.620 --> 01:04:04.620]   It's not like it.
[01:04:04.620 --> 01:04:12.260]   I mean, there's no doubt that this is at least also going to be making money.
[01:04:12.260 --> 01:04:16.540]   I think the reason why he's doing this is not because he's thinking, "Oh, we have to
[01:04:16.540 --> 01:04:19.940]   make humanity better and this is how..."
[01:04:19.940 --> 01:04:20.940]   He's...
[01:04:20.940 --> 01:04:25.100]   I completely believe that he's seeing the writing on the wall and he's thinking this
[01:04:25.100 --> 01:04:31.300]   is where this type of tool and platform has to go in order to survive and maybe even
[01:04:31.300 --> 01:04:32.580]   grow.
[01:04:32.580 --> 01:04:36.660]   But I do think that Mike and maybe Paris are being a little bit harsh.
[01:04:36.660 --> 01:04:45.900]   You make it sound like he is some kind of mustache-dwirling evil bond villain who's trying to enact the
[01:04:45.900 --> 01:04:47.820]   most amount of damage he can.
[01:04:47.820 --> 01:04:52.180]   I think he's looking at the industry and thinking, "Okay, where are we going?
[01:04:52.180 --> 01:04:54.220]   How can I keep my business safe?
[01:04:54.220 --> 01:04:56.060]   And where do I make my money?"
[01:04:56.060 --> 01:05:03.940]   There is, I think, a very little doubt that this is going to be from a revenue standpoint.
[01:05:03.940 --> 01:05:09.740]   I'm sorry, from a revenue standpoint, a little bit more challenging to create revenue streams
[01:05:09.740 --> 01:05:16.020]   or he's going to have to switch a few things to keep it working.
[01:05:16.020 --> 01:05:17.020]   But it doesn't mean...
[01:05:17.020 --> 01:05:23.540]   All of this doesn't mean that it can't also have some positive effects, right?
[01:05:23.540 --> 01:05:26.660]   Or is it all dark and terrible?
[01:05:26.660 --> 01:05:28.860]   So it's not about mustache.
[01:05:28.860 --> 01:05:34.860]   I'd take a mustache-twirling villain any day over Mark Zuckerberg because he's...
[01:05:34.860 --> 01:05:35.860]   Wow.
[01:05:35.860 --> 01:05:37.740]   I've given this perspective before.
[01:05:37.740 --> 01:05:41.140]   I think it's very clear and I'm not a psychologist.
[01:05:41.140 --> 01:05:46.500]   I just play one on TV that he's simply is amoral.
[01:05:46.500 --> 01:05:48.980]   He's in the same way that he's literally colorblind.
[01:05:48.980 --> 01:05:51.460]   I think he's blind to moral issues.
[01:05:51.460 --> 01:05:58.460]   I think he just can't tell the difference between right and wrong, but he does want to be successful.
[01:05:58.460 --> 01:06:03.540]   And I think the manifesto that he laid out in this blog post makes it very, very clear
[01:06:03.540 --> 01:06:10.380]   in this sort of like wishy-washy kind of a way that he wants to be WeChat.
[01:06:10.380 --> 01:06:13.700]   WeChat is so dominant in China.
[01:06:13.700 --> 01:06:19.500]   Please, everybody, read up on what it's like to try to live without WeChat in China.
[01:06:19.500 --> 01:06:21.220]   You can't get by.
[01:06:21.220 --> 01:06:26.900]   One point, 1.1 billion people in China use WeChat.
[01:06:26.900 --> 01:06:30.340]   Everybody uses WeChat and that's what he clearly laid out that he wants to do.
[01:06:30.340 --> 01:06:34.980]   He wants these encrypted networks that are private to actually be the way you pay for
[01:06:34.980 --> 01:06:35.980]   everything.
[01:06:35.980 --> 01:06:37.980]   The primary form of communication.
[01:06:37.980 --> 01:06:38.980]   Yeah.
[01:06:38.980 --> 01:06:39.980]   It's your everything.
[01:06:39.980 --> 01:06:41.540]   He wants to be bigger than the internet.
[01:06:41.540 --> 01:06:44.820]   He wants to perfectly control something that's bigger than the internet.
[01:06:44.820 --> 01:06:46.660]   It's not a one-to-one comparison.
[01:06:46.660 --> 01:06:49.940]   China also controls what can exist in China.
[01:06:49.940 --> 01:06:50.940]   There's no competition.
[01:06:50.940 --> 01:06:53.820]   WeChat is so big because it's the only thing there is.
[01:06:53.820 --> 01:06:54.820]   Right.
[01:06:54.820 --> 01:06:55.820]   I don't think it's...
[01:06:55.820 --> 01:06:57.460]   There'd be a lot of competition in the US.
[01:06:57.460 --> 01:06:58.460]   But the...
[01:06:58.460 --> 01:06:59.460]   Including Apple's messages.
[01:06:59.460 --> 01:07:03.220]   There would be a competition, but the good old fashioned network of facts is the very
[01:07:03.220 --> 01:07:06.060]   thing that makes WeChat untouchable.
[01:07:06.060 --> 01:07:10.180]   It makes the WeChat absolutely indispensable and he wants to be that indispensable.
[01:07:10.180 --> 01:07:12.500]   Is it possible this is a jiu-jitsu move?
[01:07:12.500 --> 01:07:18.660]   I think that's kind of what you guys are saying, which is Mark painted into a corner has decided
[01:07:18.660 --> 01:07:24.980]   to use the energy directed at him and redirect it into something that...
[01:07:24.980 --> 01:07:27.180]   And Ben Thompson has some good things to say about this.
[01:07:27.180 --> 01:07:32.620]   He's saying this is both a good move for Facebook and a good move for us.
[01:07:32.620 --> 01:07:36.860]   He says Facebook's getting its privacy cake and eating it too.
[01:07:36.860 --> 01:07:40.500]   He says stop expecting companies to act against their interest.
[01:07:40.500 --> 01:07:43.420]   Facebook isn't killing their core business.
[01:07:43.420 --> 01:07:47.700]   They're doing something that benefits it but is not inherently bad for end users.
[01:07:47.700 --> 01:07:53.180]   It's reasonable that a company can be instituting genuinely user friendly changes like end-to-end
[01:07:53.180 --> 01:07:58.180]   encryption even as it furthers its own self interests.
[01:07:58.180 --> 01:08:03.820]   And then Scott Galloway, who's been a very strong critic of Facebook since he wrote his
[01:08:03.820 --> 01:08:11.180]   book The Four, he says spoiler alert, Zuck doesn't give a fart about your privacy.
[01:08:11.180 --> 01:08:13.500]   Never has, never will.
[01:08:13.500 --> 01:08:17.060]   When Rohingya Muslims are attacked and a woman's right to choose is at risk because of a Supreme
[01:08:17.060 --> 01:08:21.540]   Court stacked by an illegitimate president elected by Russians who weaponized the big
[01:08:21.540 --> 01:08:27.740]   blue button, it's clear Zuck is pretty effing far from a town called privacy.
[01:08:27.740 --> 01:08:32.300]   Well written, Scott, maybe a little bit invective.
[01:08:32.300 --> 01:08:33.620]   So it's a juditsu.
[01:08:33.620 --> 01:08:38.620]   So look, I wanted to give, I want and still want to give the guy the benefit of the doubt.
[01:08:38.620 --> 01:08:42.340]   There's no harm to saying, okay, Mark, put up or shut up.
[01:08:42.340 --> 01:08:43.340]   You got a good idea.
[01:08:43.340 --> 01:08:44.820]   We like the idea.
[01:08:44.820 --> 01:08:45.860]   Let's see you do it.
[01:08:45.860 --> 01:08:49.500]   And then if he doesn't do it, calling him on the carpet, there's no harm in that.
[01:08:49.500 --> 01:08:53.900]   But he's a juditsu move in the sense that he's got these guys coming at him.
[01:08:53.900 --> 01:08:59.500]   He goes, honey, he turns all that energy into instead of breaking up Facebook or putting
[01:08:59.500 --> 01:09:03.380]   him out of business into, oh, it's the new Facebook.
[01:09:03.380 --> 01:09:05.900]   It doesn't matter if he does what he said he would do in that thing.
[01:09:05.900 --> 01:09:10.380]   What he didn't say anything about are the issues that we're all concerned about.
[01:09:10.380 --> 01:09:12.460]   He didn't say anything about the tracking.
[01:09:12.460 --> 01:09:15.340]   He didn't say anything about the shadow profiles.
[01:09:15.340 --> 01:09:19.580]   It's not like he let us kind of project on it that it would be safer.
[01:09:19.580 --> 01:09:24.780]   He didn't say, you know, he took these side issues that people aren't really that concerned
[01:09:24.780 --> 01:09:27.580]   about and he said, oh, this is going to be the big pivot.
[01:09:27.580 --> 01:09:29.780]   In fact, like, why did you get off Facebook?
[01:09:29.780 --> 01:09:31.740]   It's not because you didn't have any encryption.
[01:09:31.740 --> 01:09:35.460]   No, it's because I didn't trust them with my data.
[01:09:35.460 --> 01:09:36.460]   Exactly.
[01:09:36.460 --> 01:09:40.340]   And I think this blog post is yet another reason to not trust them.
[01:09:40.340 --> 01:09:44.820]   It's dripping with a slide of hand.
[01:09:44.820 --> 01:09:51.620]   He's trying to distract everybody from all these stories that are out.
[01:09:51.620 --> 01:09:56.460]   Search for Facebook on Google News and look at the last month of scandals that have emerged
[01:09:56.460 --> 01:10:01.420]   on Google News and see how many of those scandals he even hinted at in the blog.
[01:10:01.420 --> 01:10:02.420]   He had zero.
[01:10:02.420 --> 01:10:07.260]   He had to come to Jesus' moment and said, oh, my God, I got to fix this.
[01:10:07.260 --> 01:10:09.860]   This is a P.I.L. move pure and simple.
[01:10:09.860 --> 01:10:10.860]   So I think-
[01:10:10.860 --> 01:10:14.260]   And I think that this move is ultimately beneficial because the crisis of moderation
[01:10:14.260 --> 01:10:16.860]   that Facebook has been facing for so long.
[01:10:16.860 --> 01:10:20.300]   This solves that way because they don't have to have any more-
[01:10:20.300 --> 01:10:21.300]   Less than most of them.
[01:10:21.300 --> 01:10:23.780]   ... of their paid moderators.
[01:10:23.780 --> 01:10:24.780]   It's encrypted.
[01:10:24.780 --> 01:10:30.540]   And perhaps in the case of right now, I believe Australia recently passed laws saying that
[01:10:30.540 --> 01:10:34.340]   apps like WhatsApp and things like that are going to have to build back doors in their
[01:10:34.340 --> 01:10:36.340]   encryption for law enforcement to get in.
[01:10:36.340 --> 01:10:39.420]   India is planning on passing a similar law.
[01:10:39.420 --> 01:10:43.020]   And then, okay, law enforcement can get in, but Facebook's hands are completely clean.
[01:10:43.020 --> 01:10:46.980]   They don't have to have any more Casey Newton articles about how poorly they're treating
[01:10:46.980 --> 01:10:50.860]   their moderators that have to look at pictures of dead people because that's on their issue
[01:10:50.860 --> 01:10:51.860]   anymore.
[01:10:51.860 --> 01:10:56.180]   It lets them off the hook even with the Rohingya because, well, I can't help it if me and Mar
[01:10:56.180 --> 01:10:57.660]   wants to send this.
[01:10:57.660 --> 01:10:58.660]   We can't see it.
[01:10:58.660 --> 01:10:59.660]   We don't have to moderate it because we can't.
[01:10:59.660 --> 01:11:04.940]   He's trying to get credit for the idea that they won't be able to read your messages, your
[01:11:04.940 --> 01:11:06.460]   private messages.
[01:11:06.460 --> 01:11:09.220]   But what he's not saying is like, but we will have your phone number.
[01:11:09.220 --> 01:11:10.780]   We will know who you're talking to.
[01:11:10.780 --> 01:11:11.900]   We'll know when you're talking to them.
[01:11:11.900 --> 01:11:15.260]   We know what you buy, how much you spent, who you're hanging out with, everywhere you
[01:11:15.260 --> 01:11:16.980]   go 24/7.
[01:11:16.980 --> 01:11:21.820]   And we're going to sell that to advertisers and monetize the crap out of all of this stuff.
[01:11:21.820 --> 01:11:25.180]   He's trying to get credit for essentially a coup.
[01:11:25.180 --> 01:11:27.700]   He's trying to really take over the internet.
[01:11:27.700 --> 01:11:31.580]   Right now, the internet, you use this service for paying for things and that service for
[01:11:31.580 --> 01:11:32.580]   that.
[01:11:32.580 --> 01:11:36.580]   We have a decentralized still, more or less, internet in terms of the full breadth of
[01:11:36.580 --> 01:11:37.580]   services.
[01:11:37.580 --> 01:11:38.580]   He wants to be the sole source of information.
[01:11:38.580 --> 01:11:40.460]   But he's saying, trust me, let me run it.
[01:11:40.460 --> 01:11:42.620]   I can get the trains to run on time.
[01:11:42.620 --> 01:11:48.780]   But everything you're saying, he wants to do, he could do it with an open public Facebook.
[01:11:48.780 --> 01:11:51.180]   No, no, there's too much criticism in that.
[01:11:51.180 --> 01:11:52.180]   Exactly.
[01:11:52.180 --> 01:11:53.180]   Right.
[01:11:53.180 --> 01:11:54.180]   Sure, sure.
[01:11:54.180 --> 01:12:01.580]   But if there's criticism of the things that he wants to do, there's still got to be criticism
[01:12:01.580 --> 01:12:08.700]   when he tries to become WeChat in three years with an end-to-end encrypted private messaging
[01:12:08.700 --> 01:12:12.980]   and hopefully parts of it will be too late.
[01:12:12.980 --> 01:12:17.780]   But if it has different names, you probably won't realize that it's Facebook until they're
[01:12:17.780 --> 01:12:19.700]   already using it for all of their services.
[01:12:19.700 --> 01:12:23.100]   I mean, the number of people who don't realize that Instagram is Facebook is already hard
[01:12:23.100 --> 01:12:24.100]   too high.
[01:12:24.100 --> 01:12:28.780]   He's bleeding users and he wants to stop the bleeding while he rearranges everything
[01:12:28.780 --> 01:12:33.060]   and makes it so that it's impossible for you to get off Facebook.
[01:12:33.060 --> 01:12:34.140]   And he already got Leo.
[01:12:34.140 --> 01:12:35.140]   So he's succeeding.
[01:12:35.140 --> 01:12:37.140]   No, he didn't get me.
[01:12:37.140 --> 01:12:40.340]   I want to encourage him.
[01:12:40.340 --> 01:12:42.420]   I gave him a pat on the head.
[01:12:42.420 --> 01:12:44.820]   That's all I did saying that's right, Mark.
[01:12:44.820 --> 01:12:45.820]   Good idea.
[01:12:45.820 --> 01:12:46.820]   Keep up the good work.
[01:12:46.820 --> 01:12:48.380]   Come back and let's see it happen.
[01:12:48.380 --> 01:12:50.220]   And if it doesn't happen, well, I'll just leave.
[01:12:50.220 --> 01:12:52.580]   I'm not giving him more data.
[01:12:52.580 --> 01:12:55.220]   I can't believe I am defending Facebook.
[01:12:55.220 --> 01:12:58.700]   I can't believe I'm doing that.
[01:12:58.700 --> 01:13:04.860]   But don't we agree that end-to-end encryption at the very least, end-to-end encryption is
[01:13:04.860 --> 01:13:05.860]   a good thing?
[01:13:05.860 --> 01:13:06.860]   Yeah.
[01:13:06.860 --> 01:13:07.860]   Right.
[01:13:07.860 --> 01:13:10.060]   We've been asking for it for everything.
[01:13:10.060 --> 01:13:13.380]   And he wants full credit for this thing that will have three effects.
[01:13:13.380 --> 01:13:17.740]   It'll give us private communication, which is the good thing that you're referring to.
[01:13:17.740 --> 01:13:21.180]   Number two, it'll make his company unbreakupable.
[01:13:21.180 --> 01:13:25.500]   And number three, it'll allow him to wash his hands of all the child pornography and terrorism
[01:13:25.500 --> 01:13:30.740]   that's going on in his network while he runs off with another 400 billion dollars.
[01:13:30.740 --> 01:13:32.620]   We can't have it both ways.
[01:13:32.620 --> 01:13:34.300]   Either we want end-to-end encryption.
[01:13:34.300 --> 01:13:36.780]   And I understand this is a small portion of the whole discussion.
[01:13:36.780 --> 01:13:37.780]   But we already have it.
[01:13:37.780 --> 01:13:38.780]   Patrick, we have it.
[01:13:38.780 --> 01:13:39.780]   We don't need more than we have it.
[01:13:39.780 --> 01:13:41.060]   You have end-to-end encryption.
[01:13:41.060 --> 01:13:42.060]   Right.
[01:13:42.060 --> 01:13:43.420]   Yeah, but not on Facebook.
[01:13:43.420 --> 01:13:52.460]   We want what we're saying is the lack of end-to-end encryption is damaging to our privacy.
[01:13:52.460 --> 01:13:54.540]   We should have end-to-end encryption everywhere.
[01:13:54.540 --> 01:13:55.540]   Yes.
[01:13:55.540 --> 01:14:01.580]   But between lots and lots of companies inter-operating with open standards for end-to-end encryption,
[01:14:01.580 --> 01:14:07.380]   not one guy controlling everything you know and knowing everything everyone does.
[01:14:07.380 --> 01:14:08.380]   That's the problem.
[01:14:08.380 --> 01:14:13.740]   And having both your private messages and a social network having this interoperability
[01:14:13.740 --> 01:14:19.500]   to where some fake news that you get in a group WhatsApp message can be shared under
[01:14:19.500 --> 01:14:24.220]   your now private-ended encrypted Facebook group is 20,000 other people and then spread
[01:14:24.220 --> 01:14:30.140]   from there to your Instagram chat that has like 100 other friends all without being able
[01:14:30.140 --> 01:14:31.460]   to track it or see it.
[01:14:31.460 --> 01:14:37.860]   I think having this sort of giant walled garden will just make things speed up on a
[01:14:37.860 --> 01:14:44.180]   level that we are unable to comprehend and would be unable to even visualize if all of
[01:14:44.180 --> 01:14:49.060]   it was completely encrypted and we were stuck inside that system.
[01:14:49.060 --> 01:14:50.940]   So we don't want it to be encrypted.
[01:14:50.940 --> 01:14:51.940]   We want everything to be encrypted.
[01:14:51.940 --> 01:14:53.220]   I think you want your private messages.
[01:14:53.220 --> 01:14:59.020]   I think we want things to be encrypted but in their own separate spheres to where not
[01:14:59.020 --> 01:15:01.580]   just one person owns the entire pot.
[01:15:01.580 --> 01:15:04.180]   That's I think what we should all want.
[01:15:04.180 --> 01:15:09.980]   So now it's going to be an interesting conversation about what Senator Warren has.
[01:15:09.980 --> 01:15:10.980]   That's next.
[01:15:10.980 --> 01:15:14.060]   But before we do that I just want to delete my Facebook account here.
[01:15:14.060 --> 01:15:15.060]   Hold on a second.
[01:15:15.060 --> 01:15:17.140]   He's literally doing it.
[01:15:17.140 --> 01:15:19.900]   You convinced me.
[01:15:19.900 --> 01:15:22.860]   Why should I, why shouldn't enable this guy?
[01:15:22.860 --> 01:15:23.900]   You want to watch me do it?
[01:15:23.900 --> 01:15:25.620]   You don't believe it?
[01:15:25.620 --> 01:15:27.220]   I was literally.
[01:15:27.220 --> 01:15:30.820]   So it would have deleted everything on March 16th.
[01:15:30.820 --> 01:15:33.820]   That was literally 10 days away from it.
[01:15:33.820 --> 01:15:34.820]   Oh, yeah.
[01:15:34.820 --> 01:15:35.820]   Everything.
[01:15:35.820 --> 01:15:38.220]   And I thought I want to give him a chance.
[01:15:38.220 --> 01:15:39.220]   I want to give him.
[01:15:39.220 --> 01:15:40.220]   Is that a little wrong?
[01:15:40.220 --> 01:15:41.220]   That's a little wrong.
[01:15:41.220 --> 01:15:42.220]   Kick back in your head.
[01:15:42.220 --> 01:15:44.180]   I just want to give him a chance.
[01:15:44.180 --> 01:15:45.180]   Leave Brittany alone.
[01:15:45.180 --> 01:15:49.700]   Oh, I guess I'm just a fool.
[01:15:49.700 --> 01:15:53.300]   I'm just a you're just a very kind person.
[01:15:53.300 --> 01:15:54.300]   That's the problem.
[01:15:54.300 --> 01:15:55.300]   Fool.
[01:15:55.300 --> 01:15:56.540]   You took me.
[01:15:56.540 --> 01:15:58.300]   Fool me once Mark Zuckerberg.
[01:15:58.300 --> 01:15:59.460]   Shame on me.
[01:15:59.460 --> 01:16:02.900]   Fool me 3,482 times Mark Zuckerberg.
[01:16:02.900 --> 01:16:05.100]   Shame on you.
[01:16:05.100 --> 01:16:07.660]   Apparently they're calling.
[01:16:07.660 --> 01:16:09.780]   I still have a Facebook account.
[01:16:09.780 --> 01:16:10.780]   I'll ask.
[01:16:10.780 --> 01:16:12.660]   He says we're calling me.
[01:16:12.660 --> 01:16:13.860]   Don't call me Facebook.
[01:16:13.860 --> 01:16:14.860]   Go away.
[01:16:14.860 --> 01:16:16.940]   Mike, do you have a Facebook account?
[01:16:16.940 --> 01:16:17.940]   I do.
[01:16:17.940 --> 01:16:20.860]   And I've given myself six months to quit.
[01:16:20.860 --> 01:16:22.420]   So I'm quitting on 4th of July.
[01:16:22.420 --> 01:16:24.180]   It's a declaration of independence from Facebook.
[01:16:24.180 --> 01:16:25.180]   Are you really?
[01:16:25.180 --> 01:16:26.180]   Yeah.
[01:16:26.180 --> 01:16:30.620]   Every day I'm going to try to convince everyone who follows me about my point of view about
[01:16:30.620 --> 01:16:31.620]   Facebook.
[01:16:31.620 --> 01:16:33.100]   So I'm like an insurgent on Facebook.
[01:16:33.100 --> 01:16:34.100]   I have to have it for work.
[01:16:34.100 --> 01:16:35.100]   I use my--
[01:16:35.100 --> 01:16:36.100]   Oh, no.
[01:16:36.100 --> 01:16:39.780]   You guys, you talked me into this and you're not giving rid of your accounts.
[01:16:39.780 --> 01:16:45.180]   I mean, I understand it's mad that I have to have it for being groups that I use for
[01:16:45.180 --> 01:16:49.140]   journalism and report on and being able to like search up trends that I write.
[01:16:49.140 --> 01:16:50.140]   Of course you have.
[01:16:50.140 --> 01:16:52.140]   There's already too much necessity with Facebook.
[01:16:52.140 --> 01:16:53.140]   I just accept that.
[01:16:53.140 --> 01:16:54.140]   Yeah.
[01:16:54.140 --> 01:16:55.140]   Yeah.
[01:16:55.140 --> 01:16:56.820]   I know everything about me.
[01:16:56.820 --> 01:16:57.820]   Yeah.
[01:16:57.820 --> 01:16:59.180]   I mean, I'm not taking anything.
[01:16:59.180 --> 01:17:04.260]   It's more for-- you know, the real-- the most important one was my wife wanted to have-- it
[01:17:04.260 --> 01:17:08.260]   says she's married, but I'm not on Facebook doesn't say who she's married to.
[01:17:08.260 --> 01:17:09.260]   Some guy.
[01:17:09.260 --> 01:17:10.260]   Some guy.
[01:17:10.260 --> 01:17:11.260]   It's complicated.
[01:17:11.260 --> 01:17:15.260]   And she wanted, you know, that she'd be married to me.
[01:17:15.260 --> 01:17:16.260]   Okay.
[01:17:16.260 --> 01:17:17.660]   So reason for leaving.
[01:17:17.660 --> 01:17:19.940]   I have a privacy concern.
[01:17:19.940 --> 01:17:22.420]   Why they really don't want you to leave?
[01:17:22.420 --> 01:17:23.420]   Give feedback.
[01:17:23.420 --> 01:17:24.420]   Let us know.
[01:17:24.420 --> 01:17:25.420]   No, no, no, no.
[01:17:25.420 --> 01:17:28.420]   We can always control the information that you can--
[01:17:28.420 --> 01:17:30.420]   We can always do it.
[01:17:30.420 --> 01:17:31.420]   Deactivating.
[01:17:31.420 --> 01:17:32.420]   No, I don't want to deactivate.
[01:17:32.420 --> 01:17:33.420]   I want to delete it.
[01:17:33.420 --> 01:17:34.420]   Okay.
[01:17:34.420 --> 01:17:35.420]   Deactivate.
[01:17:35.420 --> 01:17:37.340]   Deactivating your account-- watch this, by the way, because pretty soon--
[01:17:37.340 --> 01:17:39.140]   It doesn't deactivate messenger though.
[01:17:39.140 --> 01:17:40.140]   You need to deactivate.
[01:17:40.140 --> 01:17:41.140]   Yeah, you have to deactivate.
[01:17:41.140 --> 01:17:43.100]   No, but I thought I could delete this.
[01:17:43.100 --> 01:17:44.100]   How do I delete?
[01:17:44.100 --> 01:17:45.500]   Let me go back and delete it.
[01:17:45.500 --> 01:17:46.500]   Oh, look.
[01:17:46.500 --> 01:17:47.500]   I just reactivated it.
[01:17:47.500 --> 01:17:49.500]   What the hell?
[01:17:49.500 --> 01:17:50.500]   I didn't even click anything.
[01:17:50.500 --> 01:17:54.140]   Isn't the conventional wisdom that you shouldn't delete it because then somebody else
[01:17:54.140 --> 01:17:56.700]   can pose as you easily?
[01:17:56.700 --> 01:17:58.420]   So if you see me on Facebook--
[01:17:58.420 --> 01:17:59.860]   Yeah, it's not me.
[01:17:59.860 --> 01:18:00.860]   It's not me.
[01:18:00.860 --> 01:18:02.620]   Oh, here it is.
[01:18:02.620 --> 01:18:05.660]   Permanently delete your Facebook account and information.
[01:18:05.660 --> 01:18:07.060]   To keep message, deactivate.
[01:18:07.060 --> 01:18:08.060]   Okay.
[01:18:08.060 --> 01:18:09.060]   No, I don't want to--
[01:18:09.060 --> 01:18:10.060]   You want to download your account?
[01:18:10.060 --> 01:18:11.060]   No, I don't want any of that crap.
[01:18:11.060 --> 01:18:12.940]   I don't want my password here.
[01:18:12.940 --> 01:18:13.940]   We'll just put that in.
[01:18:13.940 --> 01:18:15.740]   Thank goodness I have LastPass.
[01:18:15.740 --> 01:18:17.980]   I don't have to-- I don't have to--
[01:18:17.980 --> 01:18:18.980]   Make that?
[01:18:18.980 --> 01:18:19.980]   Oh, go away.
[01:18:19.980 --> 01:18:21.140]   I don't care.
[01:18:21.140 --> 01:18:24.060]   Just put the password in there, LastPass.
[01:18:24.060 --> 01:18:26.340]   Anyway, I shouldn't be doing this on your precious time.
[01:18:26.340 --> 01:18:27.900]   I apologize.
[01:18:27.900 --> 01:18:28.900]   I have--
[01:18:28.900 --> 01:18:31.140]   I'm finding this very entertaining, personally.
[01:18:31.140 --> 01:18:32.140]   Yeah.
[01:18:32.140 --> 01:18:33.140]   Love to watch.
[01:18:33.140 --> 01:18:34.140]   Love to watch.
[01:18:34.140 --> 01:18:36.140]   Yeah, if you do anything you wish you could do.
[01:18:36.140 --> 01:18:38.220]   But you can't because it's your job.
[01:18:38.220 --> 01:18:40.500]   You're permanently going to delete your account once you submit.
[01:18:40.500 --> 01:18:42.100]   You have 30 days.
[01:18:42.100 --> 01:18:43.100]   That's the problem.
[01:18:43.100 --> 01:18:46.700]   They give you that 30 days so that then Mark can put another post up and I could say,
[01:18:46.700 --> 01:18:47.700]   "Good.
[01:18:47.700 --> 01:18:52.140]   It's scheduled for permanent--" Did I do anything?
[01:18:52.140 --> 01:18:53.140]   No.
[01:18:53.140 --> 01:18:54.140]   Oh, OK.
[01:18:54.140 --> 01:18:55.140]   Cancelled confirmedly.
[01:18:55.140 --> 01:18:58.420]   He used to show me Mike Elgin's picture and say, "Mike's going to miss you."
[01:18:58.420 --> 01:18:59.420]   "Mike's going to miss you."
[01:18:59.420 --> 01:19:00.420]   It did.
[01:19:00.420 --> 01:19:01.980]   It used to say this book.
[01:19:01.980 --> 01:19:02.980]   If you want to cancel the relation--
[01:19:02.980 --> 01:19:05.300]   It's a picture of Mike with tears in his eyes.
[01:19:05.300 --> 01:19:06.300]   OK.
[01:19:06.300 --> 01:19:07.300]   Log out.
[01:19:07.300 --> 01:19:08.780]   I am no longer there.
[01:19:08.780 --> 01:19:11.180]   If you see my name on Facebook, it's somebody else.
[01:19:11.180 --> 01:19:13.980]   I long ago deleted my Instagram.
[01:19:13.980 --> 01:19:15.780]   Your profile-- congratulations, Leo.
[01:19:15.780 --> 01:19:17.580]   Your profile is now a shadow profile.
[01:19:17.580 --> 01:19:18.580]   You know, the funny thing--
[01:19:18.580 --> 01:19:19.580]   Right.
[01:19:19.580 --> 01:19:22.940]   Following me everywhere, but silently without my knowledge.
[01:19:22.940 --> 01:19:27.060]   I actually put Facebook on my phone and Twitter too.
[01:19:27.060 --> 01:19:30.740]   And then last night I was looking at it and said, "This is crap," and I deleted it anyway
[01:19:30.740 --> 01:19:32.860]   because I don't want to see it.
[01:19:32.860 --> 01:19:35.140]   I just wanted to give Mark a little signal.
[01:19:35.140 --> 01:19:37.140]   But Mark, I'm onto you.
[01:19:37.140 --> 01:19:39.180]   You have this little son of a gun.
[01:19:39.180 --> 01:19:41.300]   You thought you fooled me, didn't you?
[01:19:41.300 --> 01:19:45.780]   My show today brought to you by WordPress.
[01:19:45.780 --> 01:19:51.660]   If you are on the internet, even if you have a Facebook account, you really need to have
[01:19:51.660 --> 01:19:52.660]   a website.
[01:19:52.660 --> 01:19:58.740]   You need to have a place that you own that you call your own that you could put the best
[01:19:58.740 --> 01:19:59.740]   things about.
[01:19:59.740 --> 01:20:04.540]   In a way, I think the web is really the secret, the antidote to Facebook, the free, the open
[01:20:04.540 --> 01:20:05.620]   web.
[01:20:05.620 --> 01:20:09.180]   And where I hang my hat, WordPress.com.
[01:20:09.180 --> 01:20:12.100]   My site, LeoLaport.com is based on WordPress.com.
[01:20:12.100 --> 01:20:16.580]   In fact, I've been on WordPress.com subscriber for 12 years.
[01:20:16.580 --> 01:20:20.460]   I actually jumped on WordPress the minute it came out when Matt Mullenweig wrote it the
[01:20:20.460 --> 01:20:21.460]   first time.
[01:20:21.460 --> 01:20:24.020]   I was looking for a new blogging, a better blogging platform.
[01:20:24.020 --> 01:20:25.020]   WordPress is it.
[01:20:25.020 --> 01:20:26.580]   In fact, it's so successful.
[01:20:26.580 --> 01:20:29.900]   One third of all the internet worldwide runs on WordPress.
[01:20:29.900 --> 01:20:32.540]   One third.
[01:20:32.540 --> 01:20:33.860]   WordPress.com makes it easy.
[01:20:33.860 --> 01:20:35.660]   I was hosting my own doing all the work.
[01:20:35.660 --> 01:20:39.260]   I was realizing I'm paying more than I would for a WordPress site and doing 10 times the
[01:20:39.260 --> 01:20:40.260]   work.
[01:20:40.260 --> 01:20:42.860]   So I moved to WordPress.com.
[01:20:42.860 --> 01:20:46.300]   It's got great site building tools that let you make a unique site that's your own.
[01:20:46.300 --> 01:20:47.780]   You don't have to be a web expert.
[01:20:47.780 --> 01:20:49.420]   No, you just have to put content up there.
[01:20:49.420 --> 01:20:51.900]   There's a theme and there's thousands of them.
[01:20:51.900 --> 01:20:55.980]   If you have any questions, there's great support from real experts, not just some customer
[01:20:55.980 --> 01:21:00.100]   service rep, but real experts 24/7.
[01:21:00.100 --> 01:21:03.460]   WordPress.com lets anyone pursue whatever it is they love by launching a site that's
[01:21:03.460 --> 01:21:06.500]   free to start with room to grow.
[01:21:06.500 --> 01:21:12.780]   You can upload anything, pictures, images, video, text.
[01:21:12.780 --> 01:21:14.660]   It's all yours and you can download it at any time.
[01:21:14.660 --> 01:21:15.660]   It's your site.
[01:21:15.660 --> 01:21:16.660]   You own it.
[01:21:16.660 --> 01:21:18.380]   That's so important.
[01:21:18.380 --> 01:21:21.820]   If you're a business and you don't have a website, I don't even know how you can do
[01:21:21.820 --> 01:21:23.340]   business that way.
[01:21:23.340 --> 01:21:28.500]   No two week trials, no hidden fees, WordPress users own their own content forever and it's
[01:21:28.500 --> 01:21:29.700]   built to grow with you.
[01:21:29.700 --> 01:21:34.860]   In fact, as I've grown, I've went to the business plan and I just love it.
[01:21:34.860 --> 01:21:37.620]   Great customer support team.
[01:21:37.620 --> 01:21:40.900]   WordPress is so powerful and flexible that many of the biggest companies on earth use
[01:21:40.900 --> 01:21:46.260]   it for their websites, fortune.com, courts.com.
[01:21:46.260 --> 01:21:50.940]   These are people who use WordPress.com every day to turn their dreams into reality.
[01:21:50.940 --> 01:21:56.980]   Build your presence on the net and own it at WordPress.com/twit.
[01:21:56.980 --> 01:22:02.340]   15% on if any new plan purchase, WordPress.com/twit.
[01:22:02.340 --> 01:22:08.580]   I have to say that's what I do when I have the urge to post something on Facebook.
[01:22:08.580 --> 01:22:09.580]   I want to post it publicly.
[01:22:09.580 --> 01:22:11.060]   I just post it on my blog.
[01:22:11.060 --> 01:22:13.900]   That's where people, if you want to know what I'm up to, that's where I'll post my
[01:22:13.900 --> 01:22:14.900]   pictures.
[01:22:14.900 --> 01:22:15.900]   We're going to Hawaii in a month.
[01:22:15.900 --> 01:22:16.900]   That's where I'll post a picture.
[01:22:16.900 --> 01:22:19.500]   I think that's a better place to do it anyway.
[01:22:19.500 --> 01:22:20.500]   WordPress.com/twit.
[01:22:20.500 --> 01:22:24.100]   33% of the net runs on WordPress.
[01:22:24.100 --> 01:22:25.100]   Find out why.
[01:22:25.100 --> 01:22:27.940]   WordPress.com/twit.
[01:22:27.940 --> 01:22:28.940]   I love this story.
[01:22:28.940 --> 01:22:33.980]   Nelly Bowles writing in the New York Times style section because of course no woman could
[01:22:33.980 --> 01:22:36.820]   write for the news section.
[01:22:36.820 --> 01:22:38.900]   Same thing with the cut in New York.
[01:22:38.900 --> 01:22:39.900]   Right?
[01:22:39.900 --> 01:22:43.620]   Rebecca Tradester is always an incredible politics writer, always in the cut.
[01:22:43.620 --> 01:22:44.620]   The cut is great.
[01:22:44.620 --> 01:22:46.340]   How does it look fantastic?
[01:22:46.340 --> 01:22:47.340]   Yeah.
[01:22:47.340 --> 01:22:48.500]   I'm just going to read that.
[01:22:48.500 --> 01:22:49.980]   That's not the ghetto.
[01:22:49.980 --> 01:22:51.980]   That's downtown.
[01:22:51.980 --> 01:22:58.900]   Anyway, thousands of millionaires are about to eat San Francisco alive because you're going
[01:22:58.900 --> 01:23:05.740]   to see this year probably Uber, Lyft, Airbnb and Pinterest all go public.
[01:23:05.740 --> 01:23:11.220]   She estimates they estimate about 10,000 new millionaires in the seven square mile district
[01:23:11.220 --> 01:23:12.580]   that is San Francisco.
[01:23:12.580 --> 01:23:13.580]   That's incredible.
[01:23:13.580 --> 01:23:14.980]   10,000.
[01:23:14.980 --> 01:23:21.740]   And already real estate developers are ruling.
[01:23:21.740 --> 01:23:26.740]   She goes to a presentation by a real estate specialist saying, "Yes, the crowd, are we
[01:23:26.740 --> 01:23:30.980]   going to see a one bedroom condo that's worth less than a million dollars in five years?
[01:23:30.980 --> 01:23:31.980]   No.
[01:23:31.980 --> 01:23:35.340]   Are we going to see single family homes selling for one to three million dollars?"
[01:23:35.340 --> 01:23:38.020]   Yes.
[01:23:38.020 --> 01:23:42.340]   The energy rose as he revealed more data about new millionaires and just how few new units
[01:23:42.340 --> 01:23:43.940]   have been built for them.
[01:23:43.940 --> 01:23:48.780]   San Francisco's single family home sale prices could climb to an average of five million
[01:23:48.780 --> 01:23:50.020]   dollars.
[01:23:50.020 --> 01:23:51.020]   All cash.
[01:23:51.020 --> 01:23:55.100]   "It's just going to be astounding," he said.
[01:23:55.100 --> 01:24:00.380]   And it makes me so sad for my little city by the bay, which used to be a cultural mecca,
[01:24:00.380 --> 01:24:02.140]   a place of diversity.
[01:24:02.140 --> 01:24:03.140]   It was interesting.
[01:24:03.140 --> 01:24:05.620]   Now the diversity is either the very rich or the homeless.
[01:24:05.620 --> 01:24:06.980]   What about what happened to Hope?
[01:24:06.980 --> 01:24:08.340]   I thought we were going to have Hope on this.
[01:24:08.340 --> 01:24:09.340]   No Hope.
[01:24:09.340 --> 01:24:10.340]   There's no Hope.
[01:24:10.340 --> 01:24:11.340]   Why don't we text the crap out of this?
[01:24:11.340 --> 01:24:14.060]   We'll have to text the crap out of these new millionaires and how's the homeless?
[01:24:14.060 --> 01:24:15.060]   How about that?
[01:24:15.060 --> 01:24:17.900]   Didn't Seattle, what Seattle was going to do that?
[01:24:17.900 --> 01:24:19.380]   And they decided on it.
[01:24:19.380 --> 01:24:24.020]   They were going to build a park that had food growing and I think it was controversial
[01:24:24.020 --> 01:24:25.020]   because in America.
[01:24:25.020 --> 01:24:27.020]   Seattle was going to put a head tax on the employees.
[01:24:27.020 --> 01:24:28.020]   Right.
[01:24:28.020 --> 01:24:29.020]   That's right.
[01:24:29.020 --> 01:24:30.020]   The Amazon had it on the city.
[01:24:30.020 --> 01:24:32.940]   The council approved it and then they chickened up.
[01:24:32.940 --> 01:24:34.700]   You think Amazon would want something like that?
[01:24:34.700 --> 01:24:35.700]   San Francisco tried to.
[01:24:35.700 --> 01:24:37.300]   So it's a factory employees would have a place to sleep.
[01:24:37.300 --> 01:24:41.820]   San Francisco tried to tax the large tech giants just a little bit in order to have
[01:24:41.820 --> 01:24:47.260]   that tax go to the homeless in the city and Twitter and a bunch of other tech companies
[01:24:47.260 --> 01:24:49.420]   came out in full force against it.
[01:24:49.420 --> 01:24:56.300]   It was on the ballot and you had all these big rich companies say, oh you can't do that.
[01:24:56.300 --> 01:24:57.300]   Tax us?
[01:24:57.300 --> 01:25:01.260]   You mean the companies that control the secret algorithms that control what everybody reads?
[01:25:01.260 --> 01:25:02.980]   Those companies were against it.
[01:25:02.980 --> 01:25:04.900]   That's not a problem.
[01:25:04.900 --> 01:25:05.900]   At least 10,000.
[01:25:05.900 --> 01:25:08.260]   There's a million errors and it's just it's sad.
[01:25:08.260 --> 01:25:11.700]   I mean San Francisco is just already it's kind of unrecognizable when I go there.
[01:25:11.700 --> 01:25:13.420]   It's not the city that I used to live.
[01:25:13.420 --> 01:25:15.140]   They should come to Paris.
[01:25:15.140 --> 01:25:20.860]   Paris is much better and much more fun than San Francisco is going to be once they are
[01:25:20.860 --> 01:25:21.860]   all millionaires.
[01:25:21.860 --> 01:25:23.780]   That did pass though.
[01:25:23.780 --> 01:25:25.220]   Oh Carson's.
[01:25:25.220 --> 01:25:26.220]   C.
[01:25:26.220 --> 01:25:27.220]   Past.
[01:25:27.220 --> 01:25:28.220]   We won with 60%.
[01:25:28.220 --> 01:25:31.580]   I knew they put a lot of money against it.
[01:25:31.580 --> 01:25:36.180]   I know Jack did a long Twitter thread again about why he was against Grapsey.
[01:25:36.180 --> 01:25:41.140]   That's a picture Mark Benny off of Salesforce who supported it by the way to his credit.
[01:25:41.140 --> 01:25:46.620]   So it did pass $300 million a year and that but that's all going to go to the homeless.
[01:25:46.620 --> 01:25:48.940]   They're going to have a pretty nice homeless shelter downtown.
[01:25:48.940 --> 01:25:52.780]   Yeah, they're going to build a palace for the homeless.
[01:25:52.780 --> 01:25:57.100]   If you've been to San Francisco lately, it's actually it's it's difficult to go there.
[01:25:57.100 --> 01:25:59.580]   The RSA party.
[01:25:59.580 --> 01:26:02.100]   When I left, I walked to Caltrain.
[01:26:02.100 --> 01:26:03.100]   There's tents.
[01:26:03.100 --> 01:26:04.100]   It was unbelievable.
[01:26:04.100 --> 01:26:06.180]   There's porta potties because they're pooping in the streets.
[01:26:06.180 --> 01:26:07.180]   It was incredible.
[01:26:07.180 --> 01:26:09.300]   It's it's so good.
[01:26:09.300 --> 01:26:10.300]   There's a huge.
[01:26:10.300 --> 01:26:11.300]   Also, yeah.
[01:26:11.300 --> 01:26:15.500]   Yeah, it's a I mean, one of the main reasons though also when I took this job at Wired,
[01:26:15.500 --> 01:26:18.020]   I could have gone to San Francisco to state here in New York and I was like, there's
[01:26:18.020 --> 01:26:24.620]   no way that I can afford to live in San Francisco or anywhere remotely close to it.
[01:26:24.620 --> 01:26:28.780]   I mean, not that New York is inexpensive, but it's just going to get worse.
[01:26:28.780 --> 01:26:29.780]   It's saying something.
[01:26:29.780 --> 01:26:32.620]   It's less expensive to stay in Manhattan.
[01:26:32.620 --> 01:26:33.620]   Right.
[01:26:33.620 --> 01:26:34.620]   That is.
[01:26:34.620 --> 01:26:38.020]   Everybody all of my coworkers, I know they like take the train for like an hour or two
[01:26:38.020 --> 01:26:39.500]   to get into the office.
[01:26:39.500 --> 01:26:40.500]   Yeah.
[01:26:40.500 --> 01:26:41.500]   Yeah.
[01:26:41.500 --> 01:26:45.380]   But this was part of that art in Ellie's article, which is that the hipster bros who
[01:26:45.380 --> 01:26:47.300]   have the money, they want to be where the action is.
[01:26:47.300 --> 01:26:48.300]   Yeah.
[01:26:48.300 --> 01:26:49.620]   They don't want to live out of town.
[01:26:49.620 --> 01:26:52.940]   Not moving to Mill Valley.
[01:26:52.940 --> 01:26:53.940]   Let's talk.
[01:26:53.940 --> 01:26:56.380]   We're going to get to we're going to get to Elizabeth Warren, but I wanted to get a few
[01:26:56.380 --> 01:26:58.220]   other stories in there.
[01:26:58.220 --> 01:27:03.940]   You are talking in your Elgin.com blog post, Mike, about Apple self-driving car.
[01:27:03.940 --> 01:27:07.020]   The news has been mixed about that.
[01:27:07.020 --> 01:27:11.460]   Apple's laying off 200 engineers from their self-driving car enterprise.
[01:27:11.460 --> 01:27:12.460]   Yes.
[01:27:12.460 --> 01:27:16.780]   They're moving many others to other parts of the company.
[01:27:16.780 --> 01:27:17.780]   What is Apple?
[01:27:17.780 --> 01:27:22.100]   Are they, we'd heard that they were at first going to build a car, then they had changed
[01:27:22.100 --> 01:27:24.860]   their plans and said, now we're going to sell services.
[01:27:24.860 --> 01:27:28.180]   But I've also quoted Elon Musk who said, you know, you really want to build a self-driving
[01:27:28.180 --> 01:27:29.180]   car.
[01:27:29.180 --> 01:27:31.340]   You have to have both the data and the hardware.
[01:27:31.340 --> 01:27:32.740]   And that's Apple's way, anyway.
[01:27:32.740 --> 01:27:33.740]   Yeah.
[01:27:33.740 --> 01:27:34.740]   To control and profit from every voice.
[01:27:34.740 --> 01:27:35.740]   Steve always.
[01:27:35.740 --> 01:27:36.740]   Steve Jobs always.
[01:27:36.740 --> 01:27:39.540]   Well, Steve put it a little differently than that, but he said, if you want to control
[01:27:39.540 --> 01:27:41.940]   the platform, you have to make the hardware and the software.
[01:27:41.940 --> 01:27:42.940]   Yeah.
[01:27:42.940 --> 01:27:43.940]   He talked about cars and trucks.
[01:27:43.940 --> 01:27:45.100]   He literally meant cars and trucks.
[01:27:45.100 --> 01:27:49.860]   No, I basically what I do is I bust 10 myths around the Apple car.
[01:27:49.860 --> 01:27:51.260]   There's a lot of myths going around.
[01:27:51.260 --> 01:27:53.060]   The first one is the one you mentioned with the layoffs.
[01:27:53.060 --> 01:27:54.660]   They're like, oh, they're re-
[01:27:54.660 --> 01:27:55.660]   It's over.
[01:27:55.660 --> 01:27:56.660]   Yeah, it's over.
[01:27:56.660 --> 01:28:03.140]   And we're at 3.8% based on our best information of the people working on Titan, the self-driving
[01:28:03.140 --> 01:28:05.700]   car project at Apple, 3.8%.
[01:28:05.700 --> 01:28:08.980]   When Tesla lays off 9% of their workforce, people don't go, I guess they're pivoting
[01:28:08.980 --> 01:28:10.900]   away from cars.
[01:28:10.900 --> 01:28:11.900]   That's amazing.
[01:28:11.900 --> 01:28:12.900]   That's only a few percent.
[01:28:12.900 --> 01:28:14.820]   Yeah, they have 5,000 people with an Apple.
[01:28:14.820 --> 01:28:15.820]   And what kind of stuff?
[01:28:15.820 --> 01:28:16.740]   Best information working on it.
[01:28:16.740 --> 01:28:19.540]   Not all of them are full time, but they have a lot of different things.
[01:28:19.540 --> 01:28:23.620]   The AI people are working on AI and also self-driving car AI.
[01:28:23.620 --> 01:28:24.620]   It's related.
[01:28:24.620 --> 01:28:25.620]   Harder design people.
[01:28:25.620 --> 01:28:29.580]   So the way, and so I talk about lots and lots of things, people say, well, they're not going
[01:28:29.580 --> 01:28:30.580]   to manufacture cars.
[01:28:30.580 --> 01:28:31.580]   Well, you know what?
[01:28:31.580 --> 01:28:32.580]   Guess what?
[01:28:32.580 --> 01:28:33.580]   They don't manufacture phones either.
[01:28:33.580 --> 01:28:34.580]   They use a contract manufacturer.
[01:28:34.580 --> 01:28:36.380]   There are in fact, there's one in Europe that builds a current-
[01:28:36.380 --> 01:28:37.540]   It's in Austria.
[01:28:37.540 --> 01:28:43.540]   And they have people, four years ago, there was reports that about a dozen engineers
[01:28:43.540 --> 01:28:47.700]   from Magna Steyer, I think it's called in Austria, were working in their secret Sunny
[01:28:47.700 --> 01:28:48.700]  ville facility.
[01:28:48.700 --> 01:28:50.500]   That's four years ago.
[01:28:50.500 --> 01:28:54.300]   So there's no indication that they have stopped working with Magna Steyer.
[01:28:54.300 --> 01:28:57.420]   They will do a contract manufacturing vehicle.
[01:28:57.420 --> 01:29:01.980]   And there's also a report coming out of Germany this week that they are not building a car,
[01:29:01.980 --> 01:29:03.900]   they're building a van.
[01:29:03.900 --> 01:29:06.140]   And that Apple is very focused on the interior.
[01:29:06.140 --> 01:29:08.340]   It's a living room.
[01:29:08.340 --> 01:29:09.420]   A living room, right?
[01:29:09.420 --> 01:29:13.820]   A content consumption experience on wheels.
[01:29:13.820 --> 01:29:15.660]   This is the vision I think they're going to have.
[01:29:15.660 --> 01:29:20.700]   And here's a little bit of tidbit I love because it was in black and white and almost
[01:29:20.700 --> 01:29:23.300]   everybody really missed it.
[01:29:23.300 --> 01:29:27.420]   Ken Cook said in an interview, I think last year, or within the last year and a half or
[01:29:27.420 --> 01:29:32.300]   so, that Apple is looking at launching a ride service.
[01:29:32.300 --> 01:29:35.860]   He essentially hinted strongly that they were looking at that as a thing.
[01:29:35.860 --> 01:29:36.860]   And I think it makes a lot of sense.
[01:29:36.860 --> 01:29:42.860]   If you think about a self-driving car built and designed by Apple, or designed by Apple
[01:29:42.860 --> 01:29:47.060]   with the whole Apple content consumption experience, Apple virtual reality that's coming in the
[01:29:47.060 --> 01:29:51.900]   future, Apple augmented reality that's coming in the future, Apple music, Apple this, Apple
[01:29:51.900 --> 01:29:52.900]   that.
[01:29:52.900 --> 01:29:53.900]   It's an Apple living room.
[01:29:53.900 --> 01:29:55.900]   It's an Apple store on wheels.
[01:29:55.900 --> 01:29:56.900]   On wheels.
[01:29:56.900 --> 01:29:57.900]   Yeah.
[01:29:57.900 --> 01:30:01.620]   And so I actually have some secret video from the Waymo project I'd like to show you.
[01:30:01.620 --> 01:30:06.740]   This is Apple's vision for the self-driving car of the future.
[01:30:06.740 --> 01:30:09.780]   We're all going to be living in these chairs.
[01:30:09.780 --> 01:30:10.780]   Yeah.
[01:30:10.780 --> 01:30:11.780]   And that's it.
[01:30:11.780 --> 01:30:12.780]   Exactly.
[01:30:12.780 --> 01:30:13.780]   That's it.
[01:30:13.780 --> 01:30:16.540]   And it's all Apple all the time.
[01:30:16.540 --> 01:30:18.660]   Actually, it was a documentary.
[01:30:18.660 --> 01:30:19.660]   Wally was a documentary.
[01:30:19.660 --> 01:30:22.740]   And now I'm going to get taken down by Disney, so I'm going to stop.
[01:30:22.740 --> 01:30:26.900]   Anyway, the main point of this article is to bust the myths.
[01:30:26.900 --> 01:30:30.140]   There's things we know, things we don't know, but there's a lot of misconceptions out there
[01:30:30.140 --> 01:30:31.140]   and I wanted to clear them.
[01:30:31.140 --> 01:30:34.700]   You did point out that the number of dis...
[01:30:34.700 --> 01:30:36.540]   I guess Apple's...
[01:30:36.540 --> 01:30:39.140]   California's DMV report came out on self-driving vehicles.
[01:30:39.140 --> 01:30:45.340]   The number of disengagements for Apple was so huge, disengaged, which means a driver took
[01:30:45.340 --> 01:30:47.740]   over once every 1.1 miles.
[01:30:47.740 --> 01:30:48.740]   Right.
[01:30:48.740 --> 01:30:53.300]   Way higher than well Waymo's, which drove for 11,000.
[01:30:53.300 --> 01:30:54.300]   Waymo's amazing.
[01:30:54.300 --> 01:30:55.300]   Yeah.
[01:30:55.300 --> 01:30:56.300]   Waymo's amazing.
[01:30:56.300 --> 01:31:00.860]   So all the 28 car companies that have been given approval by the California DMV to test
[01:31:00.860 --> 01:31:05.700]   self-driving cars in California, they require all this data and they make it public.
[01:31:05.700 --> 01:31:08.420]   So Waymo is way ahead of the pack in terms of disengagements.
[01:31:08.420 --> 01:31:09.420]   California's...
[01:31:09.420 --> 01:31:10.420]   Apple's the bottom.
[01:31:10.420 --> 01:31:11.420]   Apple's the second.
[01:31:11.420 --> 01:31:12.420]   Apple's the second to the bottom.
[01:31:12.420 --> 01:31:14.820]   Uber is like every half a mile or every 24 miles.
[01:31:14.820 --> 01:31:16.460]   They're disengaging.
[01:31:16.460 --> 01:31:18.820]   What we don't know is why anybody's disengaging.
[01:31:18.820 --> 01:31:22.620]   Apple, in a letter to the DMV said that they are very conservative on disengagements.
[01:31:22.620 --> 01:31:24.540]   So we don't know why they're disengaging.
[01:31:24.540 --> 01:31:28.700]   They probably just have this policy that it's like we are not going to have an accident.
[01:31:28.700 --> 01:31:30.540]   Like no matter what, we don't have an accident.
[01:31:30.540 --> 01:31:31.540]   That's job one.
[01:31:31.540 --> 01:31:33.660]   Take over if you have the slightest doubt.
[01:31:33.660 --> 01:31:34.660]   That'd be my guess.
[01:31:34.660 --> 01:31:35.660]   Yeah.
[01:31:35.660 --> 01:31:40.420]   The other thing is that Apple's disengagements have improved by a couple of orders of magnitude
[01:31:40.420 --> 01:31:41.580]   from the previous year.
[01:31:41.580 --> 01:31:45.740]   From 2017 to 2018, they've gotten way, way better.
[01:31:45.740 --> 01:31:51.220]   But that's another distraction because basically Apple's not trying to beat Waymo to market
[01:31:51.220 --> 01:31:53.060]   and they will not beat Waymo to market.
[01:31:53.060 --> 01:31:57.020]   Apple's not going to go anywhere near self-driving cars until they're ubiquitous.
[01:31:57.020 --> 01:32:02.020]   I have to point out though that there's no indication that Apple might even productize
[01:32:02.020 --> 01:32:03.020]   this.
[01:32:03.020 --> 01:32:07.380]   They have so much money having 1200 full-time engineers working on something that they
[01:32:07.380 --> 01:32:08.380]   never release.
[01:32:08.380 --> 01:32:09.380]   Right.
[01:32:09.380 --> 01:32:10.380]   No big deal.
[01:32:10.380 --> 01:32:13.300]   Here's how to reverse engineer Apple's thinking on this.
[01:32:13.300 --> 01:32:19.220]   Thinking Apple does is either optimize for content consumption or content creation.
[01:32:19.220 --> 01:32:21.460]   Their trucks are for content creation.
[01:32:21.460 --> 01:32:26.500]   They have big expensive computers for people who make movies and things like that.
[01:32:26.500 --> 01:32:31.860]   And then the iPhones and all the other products are for content consumption and communication.
[01:32:31.860 --> 01:32:34.940]   In the future, self-driving cars, we're going to spend lots and lots of time.
[01:32:34.940 --> 01:32:37.500]   I'm talking 20 years from now, 30 years from now.
[01:32:37.500 --> 01:32:39.820]   We're going to spend a third of our lives in self-driving cars.
[01:32:39.820 --> 01:32:41.620]   We're going to have hotel rooms on wheels.
[01:32:41.620 --> 01:32:45.780]   We wake up in a different city that you want to bed in, stuff like that.
[01:32:45.780 --> 01:32:50.420]   Apple can either let other companies control the profits from this content consumption
[01:32:50.420 --> 01:32:53.900]   experience or they can control it themselves.
[01:32:53.900 --> 01:32:59.220]   As Apple executives have actually said, and I quote, "A car is the ultimate mobile device."
[01:32:59.220 --> 01:33:01.300]   It's an inside-out iPhone on wheels.
[01:33:01.300 --> 01:33:04.020]   It's the way they're probably looking at it.
[01:33:04.020 --> 01:33:05.020]   Right.
[01:33:05.020 --> 01:33:10.220]   When the car is driving you around, there's nothing to do except play video games, watch
[01:33:10.220 --> 01:33:11.220]   movies.
[01:33:11.220 --> 01:33:13.780]   Other big tech companies have been looking at this.
[01:33:13.780 --> 01:33:16.140]   What do we put ads all over it?
[01:33:16.140 --> 01:33:17.620]   You don't need to look outside.
[01:33:17.620 --> 01:33:18.620]   Right.
[01:33:18.620 --> 01:33:22.340]   And Apple, and so I think it's not even an individual car.
[01:33:22.340 --> 01:33:24.460]   Maybe it's a transport vehicle.
[01:33:24.460 --> 01:33:25.740]   I think it's lots of things.
[01:33:25.740 --> 01:33:29.300]   The way I look at it is that a self-driving car is a sandwich.
[01:33:29.300 --> 01:33:32.140]   It might just come in like an airport or it might just pick you up.
[01:33:32.140 --> 01:33:33.780]   It could be lots of things.
[01:33:33.780 --> 01:33:35.380]   A self-driving car is a sandwich.
[01:33:35.380 --> 01:33:40.740]   The bottom chassis is batteries with an electric motor on each of the wheels.
[01:33:40.740 --> 01:33:41.740]   It's commoditizable.
[01:33:41.740 --> 01:33:42.740]   That's done.
[01:33:42.740 --> 01:33:43.740]   If you use that, it'll be nothing.
[01:33:43.740 --> 01:33:44.740]   It's cheap, et cetera.
[01:33:44.740 --> 01:33:45.740]   Everybody's doing it.
[01:33:45.740 --> 01:33:51.220]   The top slice of bread is the self-driving car AI that enables you to navigate and stuff
[01:33:51.220 --> 01:33:52.300]   like that.
[01:33:52.300 --> 01:33:54.180]   What goes between that can be anything.
[01:33:54.180 --> 01:33:55.180]   It almost doesn't matter.
[01:33:55.180 --> 01:33:57.260]   You'd be able to plug and play modules.
[01:33:57.260 --> 01:33:59.260]   You have a bedroom, a game room, a this or that.
[01:33:59.260 --> 01:34:00.900]   It doesn't matter.
[01:34:00.900 --> 01:34:03.340]   The point is that Apple is...
[01:34:03.340 --> 01:34:07.260]   The point is that there's going to be a lot of content in consumed in these vehicles because
[01:34:07.260 --> 01:34:09.340]   there's nothing else to do.
[01:34:09.340 --> 01:34:15.660]   The other question you have to ask yourself is Apple's been on this trajectory of approaching
[01:34:15.660 --> 01:34:22.140]   and then declining from and then re-approaching a trillion dollar valuation as a company.
[01:34:22.140 --> 01:34:24.420]   Are they just going to give up and lay down and go to sleep?
[01:34:24.420 --> 01:34:26.220]   Are they going to try to keep growing?
[01:34:26.220 --> 01:34:31.980]   What consumer product do people spend thousands and thousands of dollars on besides iPhones
[01:34:31.980 --> 01:34:33.500]   and stuff like that?
[01:34:33.500 --> 01:34:34.500]   Cars.
[01:34:34.500 --> 01:34:41.700]   I have a picture shot in Cupertino through the trees of Apple's new living room vehicle.
[01:34:41.700 --> 01:34:43.900]   It looks just like...
[01:34:43.900 --> 01:34:45.340]   Is that inflatable?
[01:34:45.340 --> 01:34:46.340]   This is sleeper.
[01:34:46.340 --> 01:34:50.220]   I'm desperately trying to get the podcast to take it down.
[01:34:50.220 --> 01:34:51.980]   That's all I can do.
[01:34:51.980 --> 01:34:52.980]   All right.
[01:34:52.980 --> 01:34:53.980]   Let's...
[01:34:53.980 --> 01:34:54.980]   You've got to stir up that controversy.
[01:34:54.980 --> 01:34:56.980]   You can be the next Laura Loomer.
[01:34:56.980 --> 01:34:57.980]   Stirring it up.
[01:34:57.980 --> 01:34:58.980]   Turn it up.
[01:34:58.980 --> 01:35:01.060]   Train yourself to Disney's front door.
[01:35:01.060 --> 01:35:02.620]   All right.
[01:35:02.620 --> 01:35:03.460]   Let's take a break.
[01:35:03.460 --> 01:35:13.060]   I want to talk about Elizabeth Warren, how we can break up big tech and see if this is
[01:35:13.060 --> 01:35:17.420]   at all a non-starter or if this is at all reasonable.
[01:35:17.420 --> 01:35:18.420]   Some people think it's a great...
[01:35:18.420 --> 01:35:19.420]   It's got Galloway.
[01:35:19.420 --> 01:35:20.420]   This is it.
[01:35:20.420 --> 01:35:22.900]   Breaking up is hard to do according to Neil Sadaka.
[01:35:22.900 --> 01:35:23.900]   We know that.
[01:35:23.900 --> 01:35:30.100]   But first, let's take a look at a little movie we made about the week just gone by on
[01:35:30.100 --> 01:35:31.100]   Twitter.
[01:35:31.100 --> 01:35:33.620]   Previously, on Twitter.
[01:35:33.620 --> 01:35:36.020]   We have a special guest in the studio.
[01:35:36.020 --> 01:35:37.020]   I'm so excited.
[01:35:37.020 --> 01:35:39.100]   The roady Maddock is here.
[01:35:39.100 --> 01:35:40.100]   I see it.
[01:35:40.100 --> 01:35:41.100]   I see it.
[01:35:41.100 --> 01:35:42.100]   Now quick.
[01:35:42.100 --> 01:35:43.100]   Before it's done, cool song.
[01:35:43.100 --> 01:35:48.100]   We're going to pop it in this terrible express of that.
[01:35:48.100 --> 01:35:49.100]   Wait.
[01:35:49.100 --> 01:35:50.100]   Okay.
[01:35:50.100 --> 01:35:51.100]   Quick.
[01:35:51.100 --> 01:35:53.100]   Even to the couriers.
[01:35:53.100 --> 01:35:54.100]   Okay.
[01:35:54.100 --> 01:35:57.220]   You'll be getting that tomorrow morning.
[01:35:57.220 --> 01:35:58.940]   You can't get any fresher than that.
[01:35:58.940 --> 01:35:59.940]   I can't wait.
[01:35:59.940 --> 01:36:00.940]   I can't wait.
[01:36:00.940 --> 01:36:01.940]   Security now.
[01:36:01.940 --> 01:36:07.860]   We have a picture of 19-year-old Santiago Lopez.
[01:36:07.860 --> 01:36:16.100]   He is the first bug bounty hunter millionaire just from finding and reporting security vulnerabilities
[01:36:16.100 --> 01:36:19.900]   through Hacker One's bug bounty program.
[01:36:19.900 --> 01:36:23.980]   I think what we're seeing is we're seeing a C change here.
[01:36:23.980 --> 01:36:26.020]   Hacker powered security.
[01:36:26.020 --> 01:36:29.980]   You've got skills with a Z.
[01:36:29.980 --> 01:36:32.300]   I think you ought to consider it.
[01:36:32.300 --> 01:36:33.300]   Triangulation.
[01:36:33.300 --> 01:36:39.620]   What happens when you give up Google, Facebook, Microsoft, Apple and Amazon?
[01:36:39.620 --> 01:36:45.820]   I had a close friend who had her baby the week I was blocking Facebook and I didn't find
[01:36:45.820 --> 01:36:47.620]   out about it until later.
[01:36:47.620 --> 01:36:51.700]   And so I called her and I said, "Hey, I didn't realize that you gave birth."
[01:36:51.700 --> 01:36:54.940]   And she said, "Well, you know, if I post something to Facebook, I just assume that everybody
[01:36:54.940 --> 01:36:55.940]   I know sees it."
[01:36:55.940 --> 01:36:56.940]   Wait.
[01:36:56.940 --> 01:36:57.940]   That's right.
[01:36:57.940 --> 01:36:58.940]   Why didn't I get your mass text?
[01:36:58.940 --> 01:36:59.940]   I'm in your context.
[01:36:59.940 --> 01:37:00.940]   Very exciting.
[01:37:00.940 --> 01:37:01.940]   Very exciting.
[01:37:01.940 --> 01:37:02.940]   This is yours, Jeff.
[01:37:02.940 --> 01:37:04.100]   Let's catch your name right now.
[01:37:04.100 --> 01:37:05.100]   Oh, it's beautiful.
[01:37:05.100 --> 01:37:07.820]   I think I see the face of Jesus in it.
[01:37:07.820 --> 01:37:08.820]   I think so.
[01:37:08.820 --> 01:37:10.740]   Who's going to say Mary or Jesus?
[01:37:10.740 --> 01:37:12.940]   Oh, Jeff, you got tongs.
[01:37:12.940 --> 01:37:14.700]   You got the tongs.
[01:37:14.700 --> 01:37:15.700]   Wow.
[01:37:15.700 --> 01:37:16.700]   You went up.
[01:37:16.700 --> 01:37:17.700]   All right.
[01:37:17.700 --> 01:37:18.700]   Nice.
[01:37:18.700 --> 01:37:19.700]   Okay.
[01:37:19.700 --> 01:37:20.700]   There it is.
[01:37:20.700 --> 01:37:21.700]   Going there.
[01:37:21.700 --> 01:37:22.700]   They're going to the courier.
[01:37:22.700 --> 01:37:23.700]   I think we made FedEx.
[01:37:23.700 --> 01:37:27.580]   Still no word if those rotis have arrived.
[01:37:27.580 --> 01:37:30.220]   Do we still have the roti-matic?
[01:37:30.220 --> 01:37:32.860]   Should we make rotis for our entire studio?
[01:37:32.860 --> 01:37:33.860]   Absolutely.
[01:37:33.860 --> 01:37:34.860]   Absolutely.
[01:37:34.860 --> 01:37:35.860]   Get right on that.
[01:37:35.860 --> 01:37:46.380]   It is a thousand dollar machine that cranks out flatbreads, you know, Indian style pancakes
[01:37:46.380 --> 01:37:47.660]   at the rate of what is it?
[01:37:47.660 --> 01:37:48.660]   One minute.
[01:37:48.660 --> 01:37:49.660]   One minute.
[01:37:49.660 --> 01:37:50.660]   Pancake a minute.
[01:37:50.660 --> 01:37:51.820]   I could keep up with that easily.
[01:37:51.820 --> 01:37:52.820]   Yeah.
[01:37:52.820 --> 01:37:55.020]   I picked up a minute to give up carbs.
[01:37:55.020 --> 01:37:57.500]   I can tell you.
[01:37:57.500 --> 01:37:59.420]   Our show today brought to you by Atlassian.
[01:37:59.420 --> 01:38:00.420]   We are in Atlassian house.
[01:38:00.420 --> 01:38:03.100]   When there's a technical issue, we put it in Jira.
[01:38:03.100 --> 01:38:06.140]   Jira is where everything goes.
[01:38:06.140 --> 01:38:07.300]   You know who's responsible.
[01:38:07.300 --> 01:38:10.060]   You know what stage it's in, what's going on with it.
[01:38:10.060 --> 01:38:14.020]   At the same time as they're using Jira, they will also put it in confluence.
[01:38:14.020 --> 01:38:15.380]   They'll document the fix.
[01:38:15.380 --> 01:38:17.420]   They'll document the workflow.
[01:38:17.420 --> 01:38:20.180]   We couldn't live without Atlassian.
[01:38:20.180 --> 01:38:25.780]   Atlassian is a collaboration software company that empowers IT teams like ours and all over
[01:38:25.780 --> 01:38:26.780]   the world.
[01:38:26.780 --> 01:38:27.940]   It is a big deal.
[01:38:27.940 --> 01:38:34.060]   If you are an IT team, you know that in this cloud-based world, it's you that has to plan
[01:38:34.060 --> 01:38:35.420]   and execute faster than ever.
[01:38:35.420 --> 01:38:36.820]   The burden is on you.
[01:38:36.820 --> 01:38:42.460]   Incidents require open, agile, smart coordination between ops and software development teams.
[01:38:42.460 --> 01:38:46.980]   The expectations are high, the stakes are high, and it's IT that's right smack dab at
[01:38:46.980 --> 01:38:47.980]   the center.
[01:38:47.980 --> 01:38:52.180]   Falling short inside of business critical workflows, that's just not an option.
[01:38:52.180 --> 01:38:55.780]   That's why so many teams like ours use Atlassian.
[01:38:55.780 --> 01:39:01.100]   The company behind Jira, their software tools are designed to manage complex, challenging
[01:39:01.100 --> 01:39:05.100]   situations like that and keep the collaboration flowing.
[01:39:05.100 --> 01:39:09.300]   By the way, I think sometimes people think Agile is just for developers know Atlassian
[01:39:09.300 --> 01:39:14.860]   offers an affordable, reliable suite of tools for teams of all sizes, from DevOps to Agile
[01:39:14.860 --> 01:39:18.700]   IT apps to ops to ITSM, whatever's next.
[01:39:18.700 --> 01:39:24.140]   The technology backbone to help IT organizations plan, service and support that kind of change
[01:39:24.140 --> 01:39:25.580]   it propels business.
[01:39:25.580 --> 01:39:26.580]   I mentioned Jira.
[01:39:26.580 --> 01:39:27.580]   I mentioned Confluence.
[01:39:27.580 --> 01:39:28.580]   There's Bitbucket.
[01:39:28.580 --> 01:39:34.500]   If you have software code base with ops, genie and status page, you can help helps you
[01:39:34.500 --> 01:39:39.580]   detect incidents, coordinate response efforts, keep stakeholders and customers up to date.
[01:39:39.580 --> 01:39:41.460]   All of that's so important.
[01:39:41.460 --> 01:39:42.660]   They have Trello now.
[01:39:42.660 --> 01:39:46.300]   I tell you, they are an amazing company.
[01:39:46.300 --> 01:39:49.380]   It all integrates seamlessly with Confluence and Jira.
[01:39:49.380 --> 01:39:50.380]   You can document it.
[01:39:50.380 --> 01:39:53.580]   You can keep everybody up to date and you don't have to bounce from platform to platform
[01:39:53.580 --> 01:39:54.580]   to get the job done.
[01:39:54.580 --> 01:39:58.980]   I think that's really important because it's so important that we get this documentation.
[01:39:58.980 --> 01:40:02.660]   I want to make it as easy as possible for our engineering and IT team.
[01:40:02.660 --> 01:40:08.340]   Like all of Atlassian's products, the tools for your team are easy and free to try.
[01:40:08.340 --> 01:40:12.340]   All you have to do is go to Atlassian.com/IT.
[01:40:12.340 --> 01:40:13.340]   Try it.
[01:40:13.340 --> 01:40:15.860]   Find out which tools are best for you.
[01:40:15.860 --> 01:40:21.700]   Try Atlassian today to see what IT can be at Atlassian.com/IT.
[01:40:21.700 --> 01:40:27.620]   We thank them so much for their support.
[01:40:27.620 --> 01:40:28.940]   What is it the Heinlein said?
[01:40:28.940 --> 01:40:30.780]   The roads must roll.
[01:40:30.780 --> 01:40:32.980]   The twit must flow.
[01:40:32.980 --> 01:40:37.940]   It doesn't sound right at all.
[01:40:37.940 --> 01:40:39.820]   The roti must roll.
[01:40:39.820 --> 01:40:41.340]   We're firing up the rhodomatic.
[01:40:41.340 --> 01:40:42.340]   There's a little warm-up time.
[01:40:42.340 --> 01:40:49.020]   But then one, two, three, four, five, six, it's going to take us ten minutes to feed the
[01:40:49.020 --> 01:40:50.820]   entire audience and staff.
[01:40:50.820 --> 01:40:51.820]   Incredible.
[01:40:51.820 --> 01:40:52.820]   Incredible.
[01:40:52.820 --> 01:40:54.820]   They don't look that enthused.
[01:40:54.820 --> 01:40:55.820]   Yeah.
[01:40:55.820 --> 01:40:57.540]   Dry piece of bread.
[01:40:57.540 --> 01:40:58.540]   That sounds great.
[01:40:58.540 --> 01:41:00.620]   Definitely worth $1,000.
[01:41:00.620 --> 01:41:01.620]   Definitely.
[01:41:01.620 --> 01:41:03.740]   It's only the beginning.
[01:41:03.740 --> 01:41:08.900]   In the future, the machines will turn out an entire Indian meal starting with the rhodian
[01:41:08.900 --> 01:41:09.900]   mix.
[01:41:09.900 --> 01:41:11.020]   I hope it doesn't turn out an entire Indian.
[01:41:11.020 --> 01:41:14.620]   That would be very strange if they can cook.
[01:41:14.620 --> 01:41:17.820]   I'm getting punchy.
[01:41:17.820 --> 01:41:18.820]   All right.
[01:41:18.820 --> 01:41:23.140]   There are how many people running for president and the Democratic Party.
[01:41:23.140 --> 01:41:24.140]   It seems like 150.
[01:41:24.140 --> 01:41:25.660]   It's quite a large number.
[01:41:25.660 --> 01:41:28.500]   There are some Republicans who have announced as well.
[01:41:28.500 --> 01:41:34.140]   Elizabeth Warren, one of the front runners, certainly she has the name recognition, wrote
[01:41:34.140 --> 01:41:36.500]   a post on Medium.
[01:41:36.500 --> 01:41:38.860]   It says Team Warren.
[01:41:38.860 --> 01:41:40.060]   It's by Elizabeth Warren.
[01:41:40.060 --> 01:41:44.460]   Here's how we can break up big tech.
[01:41:44.460 --> 01:41:47.900]   25 years ago, Facebook, Google and Amazon didn't exist.
[01:41:47.900 --> 01:41:52.260]   Now they're among the most valuable and well-known companies in the world.
[01:41:52.260 --> 01:41:57.300]   It's a great story, but also one that highlights why the government must break up monopolies
[01:41:57.300 --> 01:42:00.300]   and promote competitive markets.
[01:42:00.300 --> 01:42:04.780]   Aren't we glad she writes that we now have the option of using Google instead of being
[01:42:04.780 --> 01:42:06.500]   stuck with Bing?
[01:42:06.500 --> 01:42:08.100]   Yes.
[01:42:08.100 --> 01:42:12.060]   Today's big tech companies have too much power, too much power over our economy, our society,
[01:42:12.060 --> 01:42:14.500]   our democracy, and then the price process.
[01:42:14.500 --> 01:42:16.820]   I think this is maybe her most important point.
[01:42:16.820 --> 01:42:21.260]   They've hurt small businesses and stifled innovation.
[01:42:21.260 --> 01:42:26.700]   She says her administration will make big structural changes to the tech sector to promote
[01:42:26.700 --> 01:42:31.980]   competition, including breaking up Amazon, Facebook and Google and in a conversation with
[01:42:31.980 --> 01:42:40.020]   Neil Eipatel later this week, she said, "I'm going to put Apple in there as well."
[01:42:40.020 --> 01:42:42.540]   You can read the arguments.
[01:42:42.540 --> 01:42:49.540]   I think a lot of people will have a visceral reaction to this.
[01:42:49.540 --> 01:42:52.500]   I underlined an important part of this as did John Betell.
[01:42:52.500 --> 01:42:56.180]   These companies would be prohibited from owning, and this is something I've actually always
[01:42:56.180 --> 01:43:00.860]   complained about with Google, owning both the platform utility and any participants on
[01:43:00.860 --> 01:43:01.860]   that platform.
[01:43:01.860 --> 01:43:07.220]   They bothered me that YouTube was owned by Google and that YouTube results always showed
[01:43:07.220 --> 01:43:08.220]   up very high.
[01:43:08.220 --> 01:43:11.940]   There's even a bar of YouTube results on Google searches.
[01:43:11.940 --> 01:43:15.740]   Platform utility she writes would be required to meet a standard of fair, reasonable, and
[01:43:15.740 --> 01:43:18.380]   non-discriminatory dealing with users.
[01:43:18.380 --> 01:43:20.940]   That's a little different.
[01:43:20.940 --> 01:43:25.300]   That's a patent dogma.
[01:43:25.300 --> 01:43:28.660]   Platform utilities would not be allowed to transfer or share data with third parties.
[01:43:28.660 --> 01:43:30.380]   I like that.
[01:43:30.380 --> 01:43:34.380]   Let's start with you, Paris.
[01:43:34.380 --> 01:43:37.180]   Regardless of your political bent, is this viable?
[01:43:37.180 --> 01:43:38.980]   Is this doable?
[01:43:38.980 --> 01:43:42.940]   I think that this is viable and I think it's incredibly necessary, especially I think
[01:43:42.940 --> 01:43:47.380]   we're coming from a platform in e-commerce perspective.
[01:43:47.380 --> 01:43:52.900]   I'm sure people think about Amazon as an e-commerce company and really Amazon is so
[01:43:52.900 --> 01:43:53.900]   much more than that.
[01:43:53.900 --> 01:43:59.100]   I don't think most people realize the breadth of Amazon as a company and the things that
[01:43:59.100 --> 01:44:00.100]   it touches.
[01:44:00.100 --> 01:44:04.260]   I suppose if we're going to just look from the e-commerce niche, Amazon is a great example
[01:44:04.260 --> 01:44:09.740]   of why this is necessary in the fact that if you go search something on Amazon and probably
[01:44:09.740 --> 01:44:15.020]   something in the first three top results is going to be a product from Amazon, either
[01:44:15.020 --> 01:44:16.940]   an Amazon basics.
[01:44:16.940 --> 01:44:22.460]   Let's say we search for charging cables for your iPhone.
[01:44:22.460 --> 01:44:27.980]   You're probably going to have an Amazon basics cable pop up or if not that, Amazon has hundreds
[01:44:27.980 --> 01:44:32.540]   of private label brands, something that doesn't seem like it's being sold by Amazon but is
[01:44:32.540 --> 01:44:35.860]   manufactured, shipped and fulfilled by Amazon.
[01:44:35.860 --> 01:44:41.780]   How the company does this is since it owns the platform, it realizes, "Hey, a lot of people
[01:44:41.780 --> 01:44:45.860]   are looking for iPhone chargers or dog hats or whatever.
[01:44:45.860 --> 01:44:47.020]   We don't sell dog hats.
[01:44:47.020 --> 01:44:52.620]   We're going to make an Amazon label dog hat so that we get both the, in addition to the
[01:44:52.620 --> 01:44:56.140]   commission, we'd normally make off a third party dog hat being bought.
[01:44:56.140 --> 01:44:58.500]   We get the entire price of it.
[01:44:58.500 --> 01:45:00.900]   We get the entire revenue from that.
[01:45:00.900 --> 01:45:09.580]   Amazon has the power to direct consumers towards its goods and to sink its competitors down
[01:45:09.580 --> 01:45:13.980]   in the search page to page two, which means no one will see it, much less if it was at
[01:45:13.980 --> 01:45:16.820]   page 15.
[01:45:16.820 --> 01:45:23.780]   This sort of power is something that has serious consequences for small businesses and innovators
[01:45:23.780 --> 01:45:31.020]   because why would you, if you're an entrepreneur or a small business, why would you invest
[01:45:31.020 --> 01:45:36.020]   resources into trying to figure out the next hot product that people are going to be buying
[01:45:36.020 --> 01:45:39.420]   online because you're going to have to go through Amazon and the minute your product
[01:45:39.420 --> 01:45:46.460]   ends up succeeding, Amazon is probably going to copy it and then push you back to the second
[01:45:46.460 --> 01:45:51.980]   or third page or push you down to search result five and you won't be making any money.
[01:45:51.980 --> 01:45:56.420]   He talks about the predatory practices Amazon will use as with diapers.com.
[01:45:56.420 --> 01:46:01.700]   A company comes along, I think it was a former Amazon employee, he said, "Ah, I know, I'll
[01:46:01.700 --> 01:46:03.460]   just take, I'll focus on diapers."
[01:46:03.460 --> 01:46:08.420]   Amazon immediately undercuts him, kills his business and then buys it.
[01:46:08.420 --> 01:46:15.460]   And Amazon's done with hundreds of companies I recently, me and my colleague, Louise Mazzaki,
[01:46:15.460 --> 01:46:19.980]   is at the end of last year, we tried to put together a list of all the different companies
[01:46:19.980 --> 01:46:24.820]   that Amazon owned and it was one of the hardest things that we've ever done because it's
[01:46:24.820 --> 01:46:30.580]   absolutely unreal, the hundreds and hundreds of companies that are Amazon.
[01:46:30.580 --> 01:46:38.400]   And anytime something comes up that is a competitor towards it, it purchases it in India, in Saudi
[01:46:38.400 --> 01:46:43.180]   Arabia and other places Amazon has bought the Amazon equivalents.
[01:46:43.180 --> 01:46:50.140]   And most recently, India passed one of the strictest e-commerce regulations aimed at
[01:46:50.140 --> 01:46:55.980]   breaking up the monopolies of companies like Amazon or Walmart when it comes to e-commerce.
[01:46:55.980 --> 01:47:00.420]   And even that has only had mixed effects on the company.
[01:47:00.420 --> 01:47:06.100]   It's required Amazon to reduce its stakes, how much it owns of these third party entities
[01:47:06.100 --> 01:47:07.660]   that it sells on its site.
[01:47:07.660 --> 01:47:12.140]   But still Amazon has so much of a market share that it's able to get around even some of
[01:47:12.140 --> 01:47:13.140]   the strictest regulations.
[01:47:13.140 --> 01:47:14.140]   So it's kind of a...
[01:47:14.140 --> 01:47:15.140]   Right.
[01:47:15.140 --> 01:47:18.900]   And the algorithmic, you know, Leo downplayed what they did.
[01:47:18.900 --> 01:47:20.980]   Undercut pricing sounds like, oh, they have competitive pricing.
[01:47:20.980 --> 01:47:21.980]   That's a good thing.
[01:47:21.980 --> 01:47:22.980]   No, no, no, no.
[01:47:22.980 --> 01:47:27.500]   No, they were using really sophisticated algorithms to, in real time, undercut the price of literally
[01:47:27.500 --> 01:47:32.500]   every product on diaper.com to always be lower no matter what, no matter how much money they
[01:47:32.500 --> 01:47:35.940]   don't care about losing money, they're making money in other places.
[01:47:35.940 --> 01:47:38.620]   And it's like literally they could just drive any company out of business.
[01:47:38.620 --> 01:47:42.180]   So it's the last monopoly, a use of monopoly.
[01:47:42.180 --> 01:47:46.460]   But on steroids, because it's all algorithmic and, you know, now they have AI that he says,
[01:47:46.460 --> 01:47:52.820]   yeah, because Amazon makes almost all of its profits from AWS and it has a total stronghold
[01:47:52.820 --> 01:47:57.940]   on the cloud services market, it can sell everything on Amazon and generally does for
[01:47:57.940 --> 01:48:02.780]   a loss if it wanted to and still be able to make a bunch of profit.
[01:48:02.780 --> 01:48:07.700]   She says we would spin off Amazon's marketplace, Google's Ad Exchange, Google Search, they
[01:48:07.700 --> 01:48:11.860]   would be called platform utilities, Amazon marketplace and basic Google's Ad Exchange
[01:48:11.860 --> 01:48:14.500]   and Businesses and the exchange would be split apart.
[01:48:14.500 --> 01:48:16.700]   Google Search would have to be spun off.
[01:48:16.700 --> 01:48:20.780]   She would take, she would split off Zappos and Whole Foods from Amazon.
[01:48:20.780 --> 01:48:25.460]   She would unwind the Facebook acquisition of WhatsApp and Instagram.
[01:48:25.460 --> 01:48:31.260]   She would take away Google's Waze, Nest and DoubleClick, which is their ad platform.
[01:48:31.260 --> 01:48:35.140]   She says unwinding these mergers will promote healthy competition in the market.
[01:48:35.140 --> 01:48:38.740]   People put pressure on big tech companies to be more responsive to user concerns about
[01:48:38.740 --> 01:48:39.740]   privacy.
[01:48:39.740 --> 01:48:45.860]   I have to say my first reaction was, oh hell no, because it feels like you're, I think
[01:48:45.860 --> 01:48:51.180]   we have this in this country sometimes, you're punishing them for being too successful.
[01:48:51.180 --> 01:48:52.500]   Saying, is that what went wrong?
[01:48:52.500 --> 01:48:56.340]   The tree got too big, but I have to say the arguments you just gave, Paris are a really
[01:48:56.340 --> 01:49:01.780]   perfect example of why it's not good for society if a company owns too much and gets too big.
[01:49:01.780 --> 01:49:07.980]   But it's worse than that because as Paris was alluding, the problem is that our laws
[01:49:07.980 --> 01:49:14.620]   are based on a world where, okay, so there's a company and you buy products from them and
[01:49:14.620 --> 01:49:17.580]   if they get too big and then you can break them up.
[01:49:17.580 --> 01:49:21.100]   It's a one-to-one relationship between the customer and the company.
[01:49:21.100 --> 01:49:28.420]   In this case, there's no pressure that the public can put on Amazon when they don't even
[01:49:28.420 --> 01:49:32.660]   know that the companies they're buying from are Amazon, when they don't understand that
[01:49:32.660 --> 01:49:38.060]   the profits they make from AWS are enabling them to lose money on all kinds of markets
[01:49:38.060 --> 01:49:42.140]   until they crush it, in which case, at which point in time they raise prices.
[01:49:42.140 --> 01:49:48.900]   There was a study done where they did this in certain narrow academic markets for books
[01:49:48.900 --> 01:49:55.700]   where they basically undercut these books and to the point, the publishers that they
[01:49:55.700 --> 01:49:59.340]   were competing with to the point where the publishers went out of business and as soon
[01:49:59.340 --> 01:50:02.580]   as the publishers went out of business, they quadrupled their prices.
[01:50:02.580 --> 01:50:04.380]   That's the perfect example.
[01:50:04.380 --> 01:50:07.220]   Even if they don't do it, they have the power to do it and should they have the power to
[01:50:07.220 --> 01:50:08.460]   do it and that's problematic.
[01:50:08.460 --> 01:50:13.180]   She also says, "My proposals won't solve every problem we have with our big tech companies.
[01:50:13.180 --> 01:50:15.020]   We must give people more control."
[01:50:15.020 --> 01:50:19.740]   This is what we were talking about earlier about how their personal information is collected,
[01:50:19.740 --> 01:50:24.580]   shared and sold and do it in a way that doesn't lock in massive competitive advantages for
[01:50:24.580 --> 01:50:28.500]   the companies that already have a ton of R data.
[01:50:28.500 --> 01:50:32.020]   Let's ask socialist Europe what it thinks.
[01:50:32.020 --> 01:50:41.500]   Honestly, I'm very surprised, first of all, that she would make this essentially her platform.
[01:50:41.500 --> 01:50:46.740]   I did think the US was ready to consider this idea.
[01:50:46.740 --> 01:50:51.620]   I'm also very surprised that you all seem to be in favor of it.
[01:50:51.620 --> 01:50:53.980]   That's another thing I wasn't expecting.
[01:50:53.980 --> 01:51:03.460]   But overall, I'm not sure how doable it is, but I think it almost doesn't matter.
[01:51:03.460 --> 01:51:09.700]   The key takeaway I have from this is that this is now in the conversation.
[01:51:09.700 --> 01:51:18.620]   This is a concern for the American public, for the American political scene.
[01:51:18.620 --> 01:51:23.940]   Even if it doesn't happen, even if she doesn't become the democratic nominee, even if it
[01:51:23.940 --> 01:51:37.100]   changes things when she actually gets into office, it's putting it in the public consciousness
[01:51:37.100 --> 01:51:43.460]   in a way that I think until six months ago would have been unimaginable, maybe going
[01:51:43.460 --> 01:51:44.740]   back a year.
[01:51:44.740 --> 01:51:50.460]   Until she actually put it in that medium post, I don't think people would have think was
[01:51:50.460 --> 01:51:51.460]   possible.
[01:51:51.460 --> 01:51:53.860]   Creating that conversation.
[01:51:53.860 --> 01:51:54.860]   It's a great point.
[01:51:54.860 --> 01:51:59.540]   So many Overton windows are being shattered in American politics.
[01:51:59.540 --> 01:52:06.260]   Overton window is the range of topics that is socially acceptable to even raise and question.
[01:52:06.260 --> 01:52:10.740]   A few years ago, you couldn't even suggest something like this, but now everybody's taking
[01:52:10.740 --> 01:52:12.180]   it seriously.
[01:52:12.180 --> 01:52:16.780]   The chances that Elizabeth Warren will become president in 2020, I don't know what the
[01:52:16.780 --> 01:52:20.700]   chances are, but it almost doesn't matter because they're building a democratic party
[01:52:20.700 --> 01:52:21.700]   platform.
[01:52:21.700 --> 01:52:24.100]   So even even the mind end up on the platform.
[01:52:24.100 --> 01:52:25.100]   Exactly.
[01:52:25.100 --> 01:52:26.100]   Does it help them or does it hurt them?
[01:52:26.100 --> 01:52:30.780]   I think it helps them because I think America in the majority supports an idea.
[01:52:30.780 --> 01:52:33.500]   I think that's probably true.
[01:52:33.500 --> 01:52:42.460]   What Americans are not thinking a lot about on the other hand, just to play devil's advocacy,
[01:52:42.460 --> 01:52:46.180]   I mean, personally, I agree with Patrick in the sense that I don't care.
[01:52:46.180 --> 01:52:51.140]   If they break up Facebook and some of our other Google and some of our beloved companies,
[01:52:51.140 --> 01:52:56.100]   Apple, et cetera, a lot of people's instinct, instinctive reaction to say, I love the products.
[01:52:56.100 --> 01:52:57.100]   I love this company.
[01:52:57.100 --> 01:52:58.940]   I don't want them to be harmed.
[01:52:58.940 --> 01:53:02.540]   But if there were three apples, that wouldn't be terrible.
[01:53:02.540 --> 01:53:05.740]   And all the shareholders would now be the owners of three.
[01:53:05.740 --> 01:53:07.900]   Actually, could you create more?
[01:53:07.900 --> 01:53:08.900]   Absolutely.
[01:53:08.900 --> 01:53:12.100]   I mean, Alphabet did it voluntarily, sort of.
[01:53:12.100 --> 01:53:16.420]   But the larger implication is that these companies are global giants.
[01:53:16.420 --> 01:53:21.940]   I mean, Facebook, Google, Amazon's becoming a global giant, Apple's obviously a global
[01:53:21.940 --> 01:53:25.180]   giant, somebody's going to be a global giant.
[01:53:25.180 --> 01:53:29.940]   And if we dismantle the American global giants, then the Chinese global giants are going to
[01:53:29.940 --> 01:53:31.660]   become the new global giants.
[01:53:31.660 --> 01:53:33.740]   And we've got to think about whether we want that.
[01:53:33.740 --> 01:53:39.580]   And I wish Europe would step up in terms of there's so much technology in Europe, but
[01:53:39.580 --> 01:53:45.020]   the funding and other cultural aspects of the startup culture aren't happening.
[01:53:45.020 --> 01:53:47.540]   So where's the French Google?
[01:53:47.540 --> 01:53:49.500]   Where's the German Facebook?
[01:53:49.500 --> 01:53:50.500]   Why isn't there?
[01:53:50.500 --> 01:53:54.300]   I mean, there is a French search.
[01:53:54.300 --> 01:53:57.260]   We ask ourselves that question all the time.
[01:53:57.260 --> 01:54:01.300]   I think there is this, I have no idea what I'm talking about.
[01:54:01.300 --> 01:54:07.860]   But I think there is a lot of market size that is problematic.
[01:54:07.860 --> 01:54:14.100]   In Europe, even though we try to create a single market and we have in many ways, the
[01:54:14.100 --> 01:54:15.980]   language barrier is one thing.
[01:54:15.980 --> 01:54:25.220]   Then even with the harmonization of laws, there are still variations with different
[01:54:25.220 --> 01:54:27.300]   parts of the EU.
[01:54:27.300 --> 01:54:32.780]   In the US and in China, you can start your business and immediately have access to what
[01:54:32.780 --> 01:54:33.780]   is it?
[01:54:33.780 --> 01:54:35.980]   250 million customers.
[01:54:35.980 --> 01:54:37.820]   It's a little bit more complicated for us.
[01:54:37.820 --> 01:54:39.300]   So I think that plays into it.
[01:54:39.300 --> 01:54:49.620]   I also think as much as it pains me to say it, our tax regimen or however you want to
[01:54:49.620 --> 01:54:55.500]   call it is maybe a little bit less friendly to aggressive entrepreneurship.
[01:54:55.500 --> 01:54:58.020]   That's possible.
[01:54:58.020 --> 01:55:08.580]   But we have now lived in a world where we have, as we call them in France, the Gaffam, Google
[01:55:08.580 --> 01:55:12.660]   Amazon, Facebook, Apple and Microsoft, are ruling the world.
[01:55:12.660 --> 01:55:13.820]   We know what it looks like.
[01:55:13.820 --> 01:55:15.340]   We know what the positive things are.
[01:55:15.340 --> 01:55:18.780]   We know what the negative things are.
[01:55:18.780 --> 01:55:25.620]   I think it would necessarily be a horrible thing to try out.
[01:55:25.620 --> 01:55:28.660]   Try breaking them down and seeing what happens.
[01:55:28.660 --> 01:55:30.820]   Maybe it would open up.
[01:55:30.820 --> 01:55:37.980]   We were a little bit slow in Europe and in other countries to get on the internet train.
[01:55:37.980 --> 01:55:45.340]   Maybe it was too late when the things we realized and the companies were already there and choking
[01:55:45.340 --> 01:55:50.780]   everyone, the competition out of everyone else.
[01:55:50.780 --> 01:55:55.380]   Maybe that could reignite a little bit of competition in other countries as well.
[01:55:55.380 --> 01:55:58.780]   Honestly, I don't know what would happen.
[01:55:58.780 --> 01:56:05.500]   But I think we know where we are now and there are some, I could be convinced that we should
[01:56:05.500 --> 01:56:07.740]   try it out, I guess.
[01:56:07.740 --> 01:56:14.660]   I wonder though, if we're just turning America into Europe, is that?
[01:56:14.660 --> 01:56:15.660]   Sorry.
[01:56:15.660 --> 01:56:24.620]   I'm jumping on this because I know that there's this fear of Europe and the way things function
[01:56:24.620 --> 01:56:33.100]   here and people call socialism, which actually on the Phileus Club, another show I do sold
[01:56:33.100 --> 01:56:38.300]   from Venezuela, said socialism doesn't really mean anything anymore because it encompasses
[01:56:38.300 --> 01:56:45.620]   everything from Cuba to Sweden.
[01:56:45.620 --> 01:56:47.380]   Socialism doesn't mean anything.
[01:56:47.380 --> 01:56:50.900]   When you're talking about Europe, you're really talking about socialism in Europe or
[01:56:50.900 --> 01:56:51.900]   social democracy.
[01:56:51.900 --> 01:56:53.620]   It's still the open market.
[01:56:53.620 --> 01:56:57.580]   You still have like, it's essentially California more or less.
[01:56:57.580 --> 01:57:01.060]   You're talking about higher taxes and safety nets.
[01:57:01.060 --> 01:57:02.060]   Yes.
[01:57:02.060 --> 01:57:04.060]   It's a tax socialism.
[01:57:04.060 --> 01:57:05.620]   It doesn't say socialism.
[01:57:05.620 --> 01:57:08.100]   Technically, government ownership of major industry.
[01:57:08.100 --> 01:57:10.740]   Which is why it doesn't mean anything.
[01:57:10.740 --> 01:57:14.820]   Some of the Scandinavian countries that are constantly being called socialist are super
[01:57:14.820 --> 01:57:15.820]   capitalistic.
[01:57:15.820 --> 01:57:18.020]   But you have super high taxes and there's a safety net.
[01:57:18.020 --> 01:57:23.580]   What I meant by that though is the kind of anti-entrepreneurial climate and what you left
[01:57:23.580 --> 01:57:27.340]   out of something Le Guilleur has always bemoaned of French entrepreneur who lives in the US
[01:57:27.340 --> 01:57:34.940]   is just the lack of venture funding economy and culture in Europe means it's hard to
[01:57:34.940 --> 01:57:38.020]   get a startup because it's hard to raise the money.
[01:57:38.020 --> 01:57:43.180]   Also, somewhat of a culture that fears failure in a way that supposedly Silicon Valley does
[01:57:43.180 --> 01:57:44.180]   not.
[01:57:44.180 --> 01:57:45.180]   To an extent.
[01:57:45.180 --> 01:57:46.180]   To an extent.
[01:57:46.180 --> 01:57:50.740]   But what my point was not so much that it's just that let's not, here's what I think
[01:57:50.740 --> 01:57:56.900]   the risk of what Warren is proposing is that we will create an environment much like Europe
[01:57:56.900 --> 01:58:02.340]   where it's harder to create a giant, we discourage it.
[01:58:02.340 --> 01:58:07.020]   But then there are countries who don't discourage it like China and all of a sudden Alibaba
[01:58:07.020 --> 01:58:09.060]   dominates world commerce.
[01:58:09.060 --> 01:58:15.260]   And all of a sudden, Baidu becomes the world's search engine slash advertising engine because
[01:58:15.260 --> 01:58:19.420]   they don't stop their capitalistic enterprises.
[01:58:19.420 --> 01:58:22.260]   Oddly enough, even though they're a communist country.
[01:58:22.260 --> 01:58:27.020]   I mean, isn't that a risk that we could, and of course in a lot of very wealthy people
[01:58:27.020 --> 01:58:30.780]   will say, and also disincent us to create big successful companies?
[01:58:30.780 --> 01:58:33.780]   Because we know you're just going to take it away from us if we get too big.
[01:58:33.780 --> 01:58:36.140]   I mean, I suppose there's a risk.
[01:58:36.140 --> 01:58:37.140]   Go ahead, Paris.
[01:58:37.140 --> 01:58:38.140]   Oh, continue.
[01:58:38.140 --> 01:58:45.620]   I suppose it is a risk, but there is these arguments were also made when the breakup of
[01:58:45.620 --> 01:58:52.660]   standard oil was under consideration, which of course did set off a large chain reaction
[01:58:52.660 --> 01:59:00.860]   of increasing antitrust legislation and anti-company breaking up decisions from the Supreme Court,
[01:59:00.860 --> 01:59:05.780]   which eventually created the backlash of deregulation that led to these tech giants.
[01:59:05.780 --> 01:59:11.540]   And from you guys haven't or listeners haven't listened to it, Planet Money NPR's podcast
[01:59:11.540 --> 01:59:17.780]   did a really great three part podcast special on antitrust that goes from standard oil to
[01:59:17.780 --> 01:59:19.940]   the backlash of the tech giants of today.
[01:59:19.940 --> 01:59:22.420]   That is so fantastic.
[01:59:22.420 --> 01:59:28.820]   And it covers all this in depth, which is really aptly timed for Elizabeth Warren announcement.
[01:59:28.820 --> 01:59:35.740]   But I think that we're at a point where current antitrust legislation and the mindset in among
[01:59:35.740 --> 01:59:43.740]   these regulators is less about actively kind of policing these kind of collections of power
[01:59:43.740 --> 01:59:47.380]   that previously we would have thought of as needing regulation.
[01:59:47.380 --> 01:59:55.580]   And it's more about is there any physical sign that this is negatively impacting consumers
[01:59:55.580 --> 02:00:00.100]   in a way like, oh, can we look at it and see we're getting worse prices on goods that
[02:00:00.100 --> 02:00:01.580]   we buy because Amazon exists?
[02:00:01.580 --> 02:00:06.500]   That doesn't take into account the kind of new reality where these things are not as
[02:00:06.500 --> 02:00:09.140]   easily, they're not as transparent.
[02:00:09.140 --> 02:00:15.300]   We can't see what competition would be like if we didn't have Amazon because Amazon is
[02:00:15.300 --> 02:00:16.300]   the reality.
[02:00:16.300 --> 02:00:22.940]   And I guess in the same regards to search engines and Google or Facebook and Microsoft, it's
[02:00:22.940 --> 02:00:27.340]   kind of just created a bubble that we live in where there's really no argument otherwise.
[02:00:27.340 --> 02:00:32.860]   Yeah, I think there's this conversation.
[02:00:32.860 --> 02:00:36.980]   I mean, Paris seems the most convinced that maybe it would be beneficial to break them
[02:00:36.980 --> 02:00:38.500]   up.
[02:00:38.500 --> 02:00:44.940]   I think Mike and I are maybe on the fence, maybe you too, Leo.
[02:00:44.940 --> 02:00:50.620]   But I think this conversation is a conversation that can happen.
[02:00:50.620 --> 02:00:55.900]   Most people that would say, oh, this would be absolutely terrible.
[02:00:55.900 --> 02:01:02.300]   And this, this is this party saying this or that party is not looking at the situation
[02:01:02.300 --> 02:01:03.300]   as it is.
[02:01:03.300 --> 02:01:10.060]   There are big companies and then there are companies that are literally, we have a saying
[02:01:10.060 --> 02:01:14.980]   in French, they're doing the rain and nice weather.
[02:01:14.980 --> 02:01:17.660]   Like basically they're controlling the world.
[02:01:17.660 --> 02:01:19.980]   They are not just big companies.
[02:01:19.980 --> 02:01:26.660]   They are gigantic and they have influences in every aspect of the economy, our lives,
[02:01:26.660 --> 02:01:29.060]   the political life, everything.
[02:01:29.060 --> 02:01:34.060]   And I think if you look at this and don't even stop to think about that question, should
[02:01:34.060 --> 02:01:41.140]   we break them up, then your reasoning is not motivated by a cold look at the situation.
[02:01:41.140 --> 02:01:45.580]   It might be motivated by some political dogma.
[02:01:45.580 --> 02:01:53.660]   The conversation is and the question are valid to ask and to discuss.
[02:01:53.660 --> 02:01:58.500]   Whether or not the answer is absolutely yes or absolutely no, I don't know, but we're
[02:01:58.500 --> 02:02:03.260]   in a situation where this is something that should be discussed.
[02:02:03.260 --> 02:02:04.260]   And Patrick is right.
[02:02:04.260 --> 02:02:05.260]   I am on the fence.
[02:02:05.260 --> 02:02:09.700]   I'm both against it and in favor of it and I'm not really, it's a complicated issue.
[02:02:09.700 --> 02:02:13.740]   But let me put it on a tin foil hat for a second and just ask a rhetorical question.
[02:02:13.740 --> 02:02:19.500]   Let's say we are in 2020, we have a Republican who's dead set against breaking up the social
[02:02:19.500 --> 02:02:21.460]   networks.
[02:02:21.460 --> 02:02:26.460]   And we have a Democratic candidate who says, when I'm president, I am going to break them
[02:02:26.460 --> 02:02:28.460]   up.
[02:02:28.460 --> 02:02:32.100]   What would it take for Facebook to tweak their algorithm and make sure the Republican was
[02:02:32.100 --> 02:02:33.100]   elected?
[02:02:33.100 --> 02:02:34.100]   Oh Lord.
[02:02:34.100 --> 02:02:35.100]   Yeah.
[02:02:35.100 --> 02:02:37.100]   And would we know just funnel millions of dollars into that candidate.
[02:02:37.100 --> 02:02:38.100]   Yeah.
[02:02:38.100 --> 02:02:40.460]   Pretty much Elizabeth Warren just guaranteed no checks from Google Facebook.
[02:02:40.460 --> 02:02:45.700]   They actually had a town hall within Facebook before the 2016 election and a lot of Facebook
[02:02:45.700 --> 02:02:49.060]   employees were like, we can't let Trump become president.
[02:02:49.060 --> 02:02:50.060]   Let's fix this.
[02:02:50.060 --> 02:02:54.260]   We have the power to just like have the other person be president and they thought about
[02:02:54.260 --> 02:02:56.620]   it and they discussed it and they decided no.
[02:02:56.620 --> 02:02:57.620]   That's terrible.
[02:02:57.620 --> 02:03:00.540]   So it's like, you know, that's the best argument for breaking them up.
[02:03:00.540 --> 02:03:01.540]   Yeah.
[02:03:01.540 --> 02:03:02.540]   That's too much.
[02:03:02.540 --> 02:03:04.020]   And it's also an argument that it might be too late.
[02:03:04.020 --> 02:03:07.420]   Yeah, right.
[02:03:07.420 --> 02:03:13.380]   You know, my only concern is actually the political concern, whether it's too fast, too
[02:03:13.380 --> 02:03:15.780]   far for the American people.
[02:03:15.780 --> 02:03:20.780]   And you know, I feel like the Democrats are emboldened, progressives are emboldened
[02:03:20.780 --> 02:03:26.460]   by Trump's presidency and hoping that a reaction, there'll be such a reaction against Trump
[02:03:26.460 --> 02:03:31.620]   that they can finally get through a bunch of progressive legislation that's been stalled
[02:03:31.620 --> 02:03:32.620]   for decades.
[02:03:32.620 --> 02:03:33.620]   I think that's right.
[02:03:33.620 --> 02:03:34.620]   I think that's right.
[02:03:34.620 --> 02:03:35.620]   I think that's right.
[02:03:35.620 --> 02:03:37.700]   It might actually be the wrong thing to do.
[02:03:37.700 --> 02:03:39.500]   And I just don't know.
[02:03:39.500 --> 02:03:45.300]   I think that there's a possibility that this could be a viable platform for a conservative
[02:03:45.300 --> 02:03:51.700]   candidate as well, given the current generally conservative backed like moral crisis over
[02:03:51.700 --> 02:03:53.340]   the power of tech giants.
[02:03:53.340 --> 02:03:59.660]   I was, I have a feed on my silly 27 column tweet deck thing of people on kind of the
[02:03:59.660 --> 02:04:01.780]   right wing conspiracy watching world.
[02:04:01.780 --> 02:04:04.100]   And a lot of them were at CPAC.
[02:04:04.100 --> 02:04:07.580]   And we're talking about, I don't know if you saw there was one CPAC panel that was called
[02:04:07.580 --> 02:04:10.580]   like blocked a conversation on center.
[02:04:10.580 --> 02:04:14.900]   This panel has been blocked by Facebook or something like that, a conversation about
[02:04:14.900 --> 02:04:16.140]   censorship.
[02:04:16.140 --> 02:04:23.420]   And this outrage is no more present than it is in the, in these conservative circles when
[02:04:23.420 --> 02:04:24.940]   it comes to the power of big tech.
[02:04:24.940 --> 02:04:26.820]   This is the largest bogeyman.
[02:04:26.820 --> 02:04:30.460]   And I think as it should be across both sides of the aisle.
[02:04:30.460 --> 02:04:37.020]   This idea of regulation and an overbearing government as it faces corporations is kind
[02:04:37.020 --> 02:04:38.940]   of a 20th century argument too.
[02:04:38.940 --> 02:04:41.940]   What's actually happening in real life, whether we like it or not.
[02:04:41.940 --> 02:04:46.740]   And regardless of which side of the political spectrum anyone is on, there's a huge balance
[02:04:46.740 --> 02:04:52.780]   of power being shifted from governments and the public to corporations and a bunch of
[02:04:52.780 --> 02:04:55.740]   billionaires who individually have an wheeled enormous power.
[02:04:55.740 --> 02:04:59.100]   Jeff Bezos has the Washington Post and a space program.
[02:04:59.100 --> 02:05:03.780]   And the individuals have more power now than we ever even imagined.
[02:05:03.780 --> 02:05:05.420]   And it's just going to continue and continue.
[02:05:05.420 --> 02:05:10.420]   So I think this is one of the first examples of a clumsy attempt to deal with the fact that
[02:05:10.420 --> 02:05:14.340]   corporations are becoming more powerful than government.
[02:05:14.340 --> 02:05:19.860]   And I think from a big picture perspective, we have to deal with the really larger issue.
[02:05:19.860 --> 02:05:21.700]   It's not just tech companies.
[02:05:21.700 --> 02:05:26.380]   It's corporations in general running the government and having more power than the government.
[02:05:26.380 --> 02:05:31.940]   And what does that mean for the power of the people if we believe in democracy?
[02:05:31.940 --> 02:05:34.020]   It is challenging.
[02:05:34.020 --> 02:05:41.580]   And as a tech lover and a tech journalist, my first reaction was horror.
[02:05:41.580 --> 02:05:45.900]   But on the other hand, there might be the only reasonable way out of what is clearly
[02:05:45.900 --> 02:05:48.460]   a problem of buying we've gotten ourselves into.
[02:05:48.460 --> 02:05:52.380]   And I think that that's one of the reasons Mark Zuckerberg wrote his blog post.
[02:05:52.380 --> 02:05:56.100]   But you're right, they have other levers they can pull that are much more devious
[02:05:56.100 --> 02:05:59.340]   nefarious and scary.
[02:05:59.340 --> 02:06:04.500]   Patrick Bejaw from Frenchspin.com.
[02:06:04.500 --> 02:06:05.500]   It's great to have you.
[02:06:05.500 --> 02:06:08.020]   We're not wrapping up quite yet, but we're almost almost done.
[02:06:08.020 --> 02:06:09.020]   Don't worry.
[02:06:09.020 --> 02:06:10.820]   Your long nightmares almost over.
[02:06:10.820 --> 02:06:12.260]   And I wish I could send you a roti.
[02:06:12.260 --> 02:06:18.620]   Our audience is eating these dry pieces of flatbread that we've printed practically on
[02:06:18.620 --> 02:06:19.620]   a three-inch credit.
[02:06:19.620 --> 02:06:21.380]   No, they're gamely forcing them down.
[02:06:21.380 --> 02:06:23.300]   Gamely forcing them down.
[02:06:23.300 --> 02:06:27.140]   We will be giving you beverages soon.
[02:06:27.140 --> 02:06:29.620]   But we could have charged you with that.
[02:06:29.620 --> 02:06:31.620]   Also 3D printed.
[02:06:31.620 --> 02:06:33.060]   Paris Martenau from Wired.
[02:06:33.060 --> 02:06:34.340]   So great to have you.
[02:06:34.340 --> 02:06:35.340]   Mike Elgin.
[02:06:35.340 --> 02:06:36.340]   Great to be here.
[02:06:36.340 --> 02:06:38.700]   Parapatetic digital nomad.
[02:06:38.700 --> 02:06:40.180]   Great to have you.
[02:06:40.180 --> 02:06:42.580]   Our show today brought to you by, and I'll give you all a chance.
[02:06:42.580 --> 02:06:43.580]   Think about what you want to plug.
[02:06:43.580 --> 02:06:44.860]   I'll give you all a chance to do that in a minute.
[02:06:44.860 --> 02:06:51.300]   But first, a word from FreshBooks, a company that changed my outlook on life about 10 years
[02:06:51.300 --> 02:06:52.300]   ago.
[02:06:52.300 --> 02:06:55.420]   I was spending invoices out because I was doing a lot of freelance work and I just hated it.
[02:06:55.420 --> 02:06:57.060]   I just hated it.
[02:06:57.060 --> 02:06:59.420]   Along comes this brand new startup and it was so cool.
[02:06:59.420 --> 02:07:01.100]   They made it so easy to do invoices.
[02:07:01.100 --> 02:07:05.740]   And in the process of doing invoices, do my cloud accounting.
[02:07:05.740 --> 02:07:06.740]   Do all my bookkeeping.
[02:07:06.740 --> 02:07:08.220]   It was awesome.
[02:07:08.220 --> 02:07:14.060]   FreshBooks is the all-in-one cloud accounting solution helping small business owners succeed.
[02:07:14.060 --> 02:07:15.740]   You won't hardly do any accounting.
[02:07:15.740 --> 02:07:18.260]   You'll do more of what you love.
[02:07:18.260 --> 02:07:22.100]   All you have to do is use FreshBooks to make those invoices.
[02:07:22.100 --> 02:07:24.940]   Just by the way, they get you paid as much as twice as fast.
[02:07:24.940 --> 02:07:26.020]   That's the average.
[02:07:26.020 --> 02:07:31.340]   Just because you're able to suddenly take online payments right through the invoice.
[02:07:31.340 --> 02:07:32.620]   Your clients love that.
[02:07:32.620 --> 02:07:34.700]   You'll love that.
[02:07:34.700 --> 02:07:38.380]   Clients will compliment you on the professionalism of your invoices.
[02:07:38.380 --> 02:07:43.940]   And then in the process of doing the invoicing and putting your expenses in through the FreshBooks
[02:07:43.940 --> 02:07:50.860]   app in the invoice or into the FreshBooks database, logging your hours with the time
[02:07:50.860 --> 02:07:51.860]   tracking.
[02:07:51.860 --> 02:07:53.380]   You'll get all the accounting reports.
[02:07:53.380 --> 02:07:57.940]   You'll get accounts receivable, accounts payable, expenses.
[02:07:57.940 --> 02:08:01.460]   You'll know for the first time I left for a lot of us, it was the first time I knew,
[02:08:01.460 --> 02:08:02.940]   whether I was making money or not.
[02:08:02.940 --> 02:08:05.780]   It's kind of a nice feeling when you look at your profit statement.
[02:08:05.780 --> 02:08:09.700]   All of that done automatically by FreshBooks.
[02:08:09.700 --> 02:08:14.540]   Automated recurring invoices, log every hour with time tracking, easy to understand reports,
[02:08:14.540 --> 02:08:19.700]   easily capture expenses, categorize those automatically to make filing taxes a breeze.
[02:08:19.700 --> 02:08:26.020]   When April 15th comes around, FreshBooks is your accountant will love you for the reports
[02:08:26.020 --> 02:08:27.620]   that you can generate from FreshBooks.
[02:08:27.620 --> 02:08:29.180]   It makes it so easy.
[02:08:29.180 --> 02:08:31.860]   With the FreshBooks mobile app, you can run your business from everywhere.
[02:08:31.860 --> 02:08:34.900]   Capture expenses with the camera, send invoices.
[02:08:34.900 --> 02:08:38.380]   Know the moment you get paid off from the palm of your hand.
[02:08:38.380 --> 02:08:40.340]   And it works with everything you're already using.
[02:08:40.340 --> 02:08:44.220]   Gusto G Suite, Funbox, Stripe, Bench On and On and Expensify.
[02:08:44.220 --> 02:08:48.940]   Whatever your apps you're using to keep track of your business, FreshBooks will integrate
[02:08:48.940 --> 02:08:51.020]   it and make it easy.
[02:08:51.020 --> 02:08:54.100]   And they're always adding new features, which I love too.
[02:08:54.100 --> 02:08:55.100]   Here's the deal.
[02:08:55.100 --> 02:08:56.100]   Don't wait another day.
[02:08:56.100 --> 02:08:59.300]   Boost your productivity and try FreshBooks now.
[02:08:59.300 --> 02:09:03.660]   Visit freshbooks.com/twit and you can try it free for 30 days.
[02:09:03.660 --> 02:09:08.060]   That's, I mean, by then you'll know, believe me, what a great deal FreshBooks is.
[02:09:08.060 --> 02:09:10.940]   Enter the words this week in tech and how did you hear about a section?
[02:09:10.940 --> 02:09:13.940]   If you would, that way they'll know you heard it here this week in tech.
[02:09:13.940 --> 02:09:20.740]   FreshBooks.com/twit, your 30-day trial awaits and we thank FreshBooks so much for supporting
[02:09:20.740 --> 02:09:30.060]   me back in the day and our podcast, all these years, freshbooks.com/twit.
[02:09:30.060 --> 02:09:36.700]   House Democrats plan to put out legislation to reinstate net neutrality.
[02:09:36.700 --> 02:09:40.820]   It probably doesn't have a chance in hell, but Patrick told me not to say that.
[02:09:40.820 --> 02:09:42.900]   Well, that's different.
[02:09:42.900 --> 02:09:47.180]   It wouldn't pass because politically it would get me voted.
[02:09:47.180 --> 02:09:50.980]   Yeah, it has to get signed by the president and et cetera.
[02:09:50.980 --> 02:09:51.980]   But it would be nice.
[02:09:51.980 --> 02:09:54.940]   They said it actually did vote and made a reinstate net neutrality rules.
[02:09:54.940 --> 02:09:58.260]   So it's possible there are enough votes there.
[02:09:58.260 --> 02:10:01.900]   What we need above all is to have the rules not change every time there's a new president.
[02:10:01.900 --> 02:10:02.900]   Yeah.
[02:10:02.900 --> 02:10:04.540]   It'd be really nice to set them in stone.
[02:10:04.540 --> 02:10:07.900]   And Congress really can't decide on this because Congress tells the FCC what to do.
[02:10:07.900 --> 02:10:12.020]   The FCC's mandate comes from Congress almost always when these things happen.
[02:10:12.020 --> 02:10:16.180]   And the FCC says, "Well, if you want this, tell Congress.
[02:10:16.180 --> 02:10:20.820]   Get them to set the rules and then we can go ahead and enforce them."
[02:10:20.820 --> 02:10:24.460]   So I just want to let you know, write your member of Congress because I'm sure you all
[02:10:24.460 --> 02:10:28.020]   agree net neutrality is a good thing.
[02:10:28.020 --> 02:10:33.460]   Huawei, a little pissed over the US government's ban on Huawei equipment and the 5G networks
[02:10:33.460 --> 02:10:37.660]   they're suing.
[02:10:37.660 --> 02:10:39.900]   They had a press conference in Shenzhen, China.
[02:10:39.900 --> 02:10:45.540]   The lawsuit is being brought in where you might ask the Eastern District of Texas.
[02:10:45.540 --> 02:10:48.820]   Isn't that where all the patent trolls go?
[02:10:48.820 --> 02:10:51.580]   Yeah, it also is where Huawei's US headquarters is loaded.
[02:10:51.580 --> 02:10:54.580]   And that's where Apple moved their Apple Store away from to punish them.
[02:10:54.580 --> 02:10:58.180]   Apple moved both its Apple stores away from the Eastern District so that they wouldn't
[02:10:58.180 --> 02:10:59.900]   have any presence there.
[02:10:59.900 --> 02:11:00.900]   Yeah.
[02:11:00.900 --> 02:11:01.900]   Yeah.
[02:11:01.900 --> 02:11:02.900]   Not to punish them, but so just so they're not.
[02:11:02.900 --> 02:11:03.900]   Oh, just so they're not.
[02:11:03.900 --> 02:11:04.900]   It doesn't cover.
[02:11:04.900 --> 02:11:05.900]   Would you like a Rodey mic?
[02:11:05.900 --> 02:11:06.900]   Sure.
[02:11:06.900 --> 02:11:07.900]   I would love one.
[02:11:07.900 --> 02:11:08.900]   Thank you.
[02:11:08.900 --> 02:11:09.900]   I'd like to mail you a Rodey.
[02:11:09.900 --> 02:11:14.980]   Yeah, I'll keep an eye on my actual box for some erotic Rodey.
[02:11:14.980 --> 02:11:15.980]   They are perfect.
[02:11:15.980 --> 02:11:18.820]   Each and every one, a perfect example of what a Rodey could be.
[02:11:18.820 --> 02:11:20.620]   Do you have anything besides Mexican food?
[02:11:20.620 --> 02:11:21.620]   Oh, I'm sorry.
[02:11:21.620 --> 02:11:22.620]   That was three of those.
[02:11:22.620 --> 02:11:23.620]   Not a tortilla, although it will make tortillas.
[02:11:23.620 --> 02:11:24.620]   It will make pizzas.
[02:11:24.620 --> 02:11:25.940]   It will make any kind of flatbread.
[02:11:25.940 --> 02:11:26.940]   It turns out-
[02:11:26.940 --> 02:11:27.940]   No, thanks.
[02:11:27.940 --> 02:11:28.940]   I am.
[02:11:28.940 --> 02:11:30.540]   I literally am off-carbohydrate.
[02:11:30.540 --> 02:11:35.620]   It turns out that every culture has its own flatbread, I believe.
[02:11:35.620 --> 02:11:37.180]   The perfection?
[02:11:37.180 --> 02:11:38.180]   It's the perfect food.
[02:11:38.180 --> 02:11:39.180]   So how is-
[02:11:39.180 --> 02:11:40.180]   Yes.
[02:11:40.180 --> 02:11:41.180]   Sorry.
[02:11:41.180 --> 02:11:42.980]   I was getting back to Huawei.
[02:11:42.980 --> 02:11:43.980]   I apologize.
[02:11:43.980 --> 02:11:44.980]   Oh, okay.
[02:11:44.980 --> 02:11:45.980]   Go ahead.
[02:11:45.980 --> 02:11:46.980]   You want to talk about tech?
[02:11:46.980 --> 02:11:47.980]   How news?
[02:11:47.980 --> 02:11:53.940]   No, it's just a little dissection because I have a show to record in a couple of days
[02:11:53.940 --> 02:11:57.700]   and I have no idea what Huawei is suing the US government for.
[02:11:57.700 --> 02:12:03.500]   I mean, I know why they're pissed, but what argument are they bringing forth?
[02:12:03.500 --> 02:12:05.860]   If you could write my show for me, that would be great.
[02:12:05.860 --> 02:12:12.420]   I will tell you exactly what Huawei Deputy Chairman Guo Ping said that no evidence had
[02:12:12.420 --> 02:12:17.180]   been presented for its ban on Huawei products, and thus it was unconstitutional.
[02:12:17.180 --> 02:12:22.140]   In other words, they just said, "Look, we don't think it's safe so you can't use it."
[02:12:22.140 --> 02:12:27.620]   The ban prevents us from serving our US customers, says Huawei damages our reputation, true,
[02:12:27.620 --> 02:12:31.940]   and deprives us of an opportunity to serve customers outside the United States, it violates
[02:12:31.940 --> 02:12:36.620]   separation of power principles, breaks US legal traditions, and goes against the very
[02:12:36.620 --> 02:12:39.020]   nature of the US Constitution.
[02:12:39.020 --> 02:12:41.580]   I guess they have a point.
[02:12:41.580 --> 02:12:47.900]   The funny thing is, of course, the origin country of Huawei doesn't play by those rules,
[02:12:47.900 --> 02:12:52.060]   but I hear that Guo Ping also stands during the National Anthem.
[02:12:52.060 --> 02:12:54.700]   I'm told with good authority.
[02:12:54.700 --> 02:12:57.940]   So if I may, I have a prepared statement about Huawei.
[02:12:57.940 --> 02:13:00.140]   Thank you.
[02:13:00.140 --> 02:13:03.220]   There's a lot of conversation about how it's unfair and how there's no evidence and all
[02:13:03.220 --> 02:13:06.100]   everything they say is complete BS, and here's why.
[02:13:06.100 --> 02:13:07.620]   They say, "Oh, we wouldn't do such a thing.
[02:13:07.620 --> 02:13:08.780]   We haven't done such a thing."
[02:13:08.780 --> 02:13:09.780]   It doesn't matter.
[02:13:09.780 --> 02:13:13.980]   The Chinese Communist Party, the Chinese government wants to take control of whatever
[02:13:13.980 --> 02:13:16.620]   they're doing with their 5G networks.
[02:13:16.620 --> 02:13:17.980]   They will, and they can.
[02:13:17.980 --> 02:13:25.140]   This is a country that builds up the islands in order to steal territorial waters.
[02:13:25.140 --> 02:13:32.420]   We all know that routers and network equipment like 5G, whatever they call them.
[02:13:32.420 --> 02:13:33.420]   Switches and routers?
[02:13:33.420 --> 02:13:34.420]   Thank you.
[02:13:34.420 --> 02:13:36.540]   These things are constantly being software updated.
[02:13:36.540 --> 02:13:39.540]   Those software updates can have any sort of payload.
[02:13:39.540 --> 02:13:40.540]   That's right.
[02:13:40.540 --> 02:13:44.220]   If those are coming from Beijing and the Chinese government were in a conflict with them in
[02:13:44.220 --> 02:13:48.460]   the future, they could just have access to all internet traffic.
[02:13:48.460 --> 02:13:49.700]   They could shut anything down.
[02:13:49.700 --> 02:13:52.220]   They could do any of these things.
[02:13:52.220 --> 02:13:57.980]   I personally support the US government on this score simply because I don't trust the Chinese
[02:13:57.980 --> 02:13:58.980]   government.
[02:13:58.980 --> 02:14:04.100]   I think they're a little too eager to own all the 5G equipment in the future.
[02:14:04.100 --> 02:14:08.660]   That's just such a choke point on the whole world's information infrastructure.
[02:14:08.660 --> 02:14:11.580]   I just don't like them having that kind of access.
[02:14:11.580 --> 02:14:14.220]   This is reasonable risk assessment.
[02:14:14.220 --> 02:14:20.500]   It seems like that could be a strong argument in the lawsuit.
[02:14:20.500 --> 02:14:26.340]   That seems like an actual argument that could be heard.
[02:14:26.340 --> 02:14:28.260]   We shall see.
[02:14:28.260 --> 02:14:29.660]   Yeah.
[02:14:29.660 --> 02:14:34.260]   I mean, there is a dearth of evidence that Huawei is doing anything now, but as you
[02:14:34.260 --> 02:14:38.260]   point out, that doesn't have to be because they would have to do.
[02:14:38.260 --> 02:14:42.700]   Speaking of monopoly, Amazon is teaming up with the Yankees, Sinclair Broadcasting and
[02:14:42.700 --> 02:14:48.460]   others to buy the Yankees sports network from 20th century Fox.
[02:14:48.460 --> 02:14:52.600]   In fact, somebody has said, and I think it's probably true, I think it was on Macbreak
[02:14:52.600 --> 02:14:53.600]   Weekly.
[02:14:53.600 --> 02:14:58.100]   It was Alex Lindsey who said, "You ain't seen nothing yet when the NFL Major League Baseball
[02:14:58.100 --> 02:15:00.700]   and NBA contracts run out.
[02:15:00.700 --> 02:15:07.780]   Broadcasters are going to face outsized bids from Netflix, Amazon, Google and others."
[02:15:07.780 --> 02:15:08.780]   Facebook.
[02:15:08.780 --> 02:15:09.780]   Yes.
[02:15:09.780 --> 02:15:10.780]   Facebook.
[02:15:10.780 --> 02:15:16.540]   That, "Goodbye television rights, they're all going to go to tech companies."
[02:15:16.540 --> 02:15:20.460]   NBC, CBS, ESPN, they just can't compete.
[02:15:20.460 --> 02:15:21.460]   I'm finding that.
[02:15:21.460 --> 02:15:22.460]   They don't have the cash.
[02:15:22.460 --> 02:15:24.900]   It's slightly cheaper for these companies to simply buy the TV networks.
[02:15:24.900 --> 02:15:25.900]   You know what?
[02:15:25.900 --> 02:15:26.900]   Just do that.
[02:15:26.900 --> 02:15:27.900]   You just do that.
[02:15:27.900 --> 02:15:28.900]   Just do that.
[02:15:28.900 --> 02:15:30.420]   Apple personally could buy Hollywood.
[02:15:30.420 --> 02:15:31.420]   Yes, right.
[02:15:31.420 --> 02:15:35.740]   They have more money than Hollywood's worth.
[02:15:35.740 --> 02:15:36.900]   Is Elon in trouble again?
[02:15:36.900 --> 02:15:37.900]   I don't know.
[02:15:37.900 --> 02:15:43.140]   You know, I feel bad for Elon because your SpaceX did this great thing with the Dragon
[02:15:43.140 --> 02:15:46.460]   Crew rocket, they successfully got it to the space station.
[02:15:46.460 --> 02:15:47.900]   It's going to be coming down.
[02:15:47.900 --> 02:15:48.900]   That should have been the headline.
[02:15:48.900 --> 02:15:52.300]   Instead, it's Elon getting fined by the SEC again.
[02:15:52.300 --> 02:15:59.500]   Also, he's being investigated because he has government contracts and he's smoking weed.
[02:15:59.500 --> 02:16:03.620]   Look, writes Crystal Match at Bloomberg.
[02:16:03.620 --> 02:16:06.140]   Just quit tweeting, "Okay?
[02:16:06.140 --> 02:16:09.940]   Investors sue Tesla and Musk again saying his review."
[02:16:09.940 --> 02:16:15.660]   The funniest part of this is that I think, what was it, in Jack's Twitter thread or something?
[02:16:15.660 --> 02:16:18.060]   Maybe it was the one that he did with Kara Swisher.
[02:16:18.060 --> 02:16:19.060]   Maybe it was a different interview.
[02:16:19.060 --> 02:16:22.620]   Somebody asked him, "Who's your ideal of the best Twitter user?"
[02:16:22.620 --> 02:16:24.460]   He said, "Elon Musk."
[02:16:24.460 --> 02:16:28.300]   "Elon Musk is the prime ideal of a good Twitter user."
[02:16:28.300 --> 02:16:30.380]   I'm like, "What are you thinking about your platform, Jack?"
[02:16:30.380 --> 02:16:33.300]   I mean, I guess he could phrase a lot of headline.
[02:16:33.300 --> 02:16:34.300]   Is this for Jack?
[02:16:34.300 --> 02:16:35.460]   Is it good for anyone else?
[02:16:35.460 --> 02:16:37.500]   It's not good for Elon.
[02:16:37.500 --> 02:16:40.820]   Not good for Tesla, not good for us and our sanity.
[02:16:40.820 --> 02:16:46.820]   The lawsuit, which is from the laborers district council and contractors, Pension Fund of
[02:16:46.820 --> 02:16:56.660]   Ohio, wants to join Elon to permanently block Musk's unchecked use of Twitter.
[02:16:56.660 --> 02:16:58.980]   To ban him from Twitter.
[02:16:58.980 --> 02:17:03.540]   Yari has paid $40 million in fines for tweets.
[02:17:03.540 --> 02:17:08.580]   All I want is an interview with the attorney appointed to be his Twitter sitter.
[02:17:08.580 --> 02:17:12.620]   A look into that person's life has got to be a hellish.
[02:17:12.620 --> 02:17:13.620]   Yeah.
[02:17:13.620 --> 02:17:17.540]   The SEC asked a judge to find him in contempt for violating the settlement by failing to
[02:17:17.540 --> 02:17:21.820]   clear a February tweet with the attorney appointed to be his Twitter sitter.
[02:17:21.820 --> 02:17:27.300]   What does this guy do?
[02:17:27.300 --> 02:17:28.740]   You know what's ironic?
[02:17:28.740 --> 02:17:32.980]   Elon has a Twitter sitter, but nobody can stop the president from tweeting.
[02:17:32.980 --> 02:17:33.980]   Right.
[02:17:33.980 --> 02:17:34.980]   Nobody.
[02:17:34.980 --> 02:17:36.380]   Maybe he needs a Twitter sitter.
[02:17:36.380 --> 02:17:40.020]   Well, those are different conversation.
[02:17:40.020 --> 02:17:41.020]   They are.
[02:17:41.020 --> 02:17:44.740]   But I think the quote you're talking about about Elon Musk came from Sam Harris, if I'm
[02:17:44.740 --> 02:17:45.740]   not mistaken.
[02:17:45.740 --> 02:17:50.860]   And they also talked about Trump's tweeting and how he violates terms of service, etc.
[02:17:50.860 --> 02:17:54.100]   And the argument was that, "Well, we take into account newsworthiness.
[02:17:54.100 --> 02:17:58.420]   Everything the president of the United States says in public is newsworthy and therefore
[02:17:58.420 --> 02:17:59.420]   that promise."
[02:17:59.420 --> 02:18:01.380]   Well, and it should.
[02:18:01.380 --> 02:18:02.380]   Honestly.
[02:18:02.380 --> 02:18:09.700]   If you want to talk about weaseling out of something, their responsibility.
[02:18:09.700 --> 02:18:10.700]   Yes, sure.
[02:18:10.700 --> 02:18:12.060]   It is newsworthiness.
[02:18:12.060 --> 02:18:19.300]   But the reality is you can't get away with banning the president of the United States
[02:18:19.300 --> 02:18:20.300]   from Twitter.
[02:18:20.300 --> 02:18:21.300]   That's the problem.
[02:18:21.300 --> 02:18:22.300]   It's not about starting.
[02:18:22.300 --> 02:18:23.300]   It's not about starting.
[02:18:23.300 --> 02:18:24.620]   Everybody, critics want that to happen.
[02:18:24.620 --> 02:18:27.620]   But yeah, that would be all you have to say is he's the president.
[02:18:27.620 --> 02:18:28.620]   Yeah.
[02:18:28.620 --> 02:18:33.900]   Besides, if you're, for critics of Trump, all that stuff he says on Twitter, that's all
[02:18:33.900 --> 02:18:35.220]   going to end up in the indictments.
[02:18:35.220 --> 02:18:38.340]   I mean, half the material in the cases against it.
[02:18:38.340 --> 02:18:43.060]   Yeah, honestly, the Twitter shitter should come from to pro-zone people.
[02:18:43.060 --> 02:18:44.060]   Exactly.
[02:18:44.060 --> 02:18:46.620]   Because he's, well, anyway.
[02:18:46.620 --> 02:18:48.260]   Let's not get political.
[02:18:48.260 --> 02:18:49.500]   I think we can wrap this up.
[02:18:49.500 --> 02:18:53.180]   You guys are a great panel and I brought the biggest stories, I think, in some respects
[02:18:53.180 --> 02:18:58.820]   of the year, and you handled them with a plumb and intelligence, and I always count on
[02:18:58.820 --> 02:18:59.820]   that.
[02:18:59.820 --> 02:19:03.540]   It's so great to have you, Paris Martyno, is a staff writer at Wired.
[02:19:03.540 --> 02:19:06.820]   Her byline is always worth reading at Wired.com.
[02:19:06.820 --> 02:19:09.940]   I paid for my subscription just for you, Paris.
[02:19:09.940 --> 02:19:10.940]   Oh, thanks.
[02:19:10.940 --> 02:19:11.940]   Yes.
[02:19:11.940 --> 02:19:12.940]   Glad that I can keep having a dress.
[02:19:12.940 --> 02:19:13.940]   Yes.
[02:19:13.940 --> 02:19:14.940]   Glad to support you.
[02:19:14.940 --> 02:19:15.940]   Anything you want to plug?
[02:19:15.940 --> 02:19:16.940]   You're doing a podcast?
[02:19:16.940 --> 02:19:17.940]   Anything you want to tell us about?
[02:19:17.940 --> 02:19:18.940]   Yeah.
[02:19:18.940 --> 02:19:21.700]   I mean, I think the thing I want to plug is probably my Twitter handle at Paris Martyn.
[02:19:21.700 --> 02:19:23.220]   It was just on the screen.
[02:19:23.220 --> 02:19:26.620]   I've been tweeting a little bit less than usual, as of late, mostly because I've been
[02:19:26.620 --> 02:19:30.620]   working on this big investigation for the past two months that I can't exactly say too
[02:19:30.620 --> 02:19:35.300]   much about, except for that you'll probably hear about it when it comes out, and it will
[02:19:35.300 --> 02:19:39.500]   hopefully be next week or this week, and I'll tweet about it.
[02:19:39.500 --> 02:19:44.500]   So follow me there and we can talk about it more when that's online.
[02:19:44.500 --> 02:19:49.220]   It's, you know, I am grateful to Wired, and now it makes me happy that I paid for the subscription
[02:19:49.220 --> 02:19:53.700]   that they're willing to put the money into assigning people to something that's going
[02:19:53.700 --> 02:19:55.060]   to take months to develop.
[02:19:55.060 --> 02:20:01.540]   I think that's the kind of news gathering we need from the big news gathering organizations.
[02:20:01.540 --> 02:20:04.380]   I'm glad to see that Wired has that resolve and the...
[02:20:04.380 --> 02:20:08.300]   Yeah, it's been really wonderful, especially because I feel like there are very few places
[02:20:08.300 --> 02:20:13.940]   in tech journalism/journalism in general, where people have the time to actually look
[02:20:13.940 --> 02:20:17.700]   into stories and give them the attention that they deserve.
[02:20:17.700 --> 02:20:20.740]   So next week, you think?
[02:20:20.740 --> 02:20:26.940]   I really, if all of my hopes, it must something catastrophic happens hopefully next week.
[02:20:26.940 --> 02:20:28.620]   The last couple stages.
[02:20:28.620 --> 02:20:36.460]   P-A-R-I-S-M-A-R-T-I-N-E-A-U on the Twitter.
[02:20:36.460 --> 02:20:39.860]   This will be very interesting.
[02:20:39.860 --> 02:20:41.860]   We'll talk soon, hopefully.
[02:20:41.860 --> 02:20:44.260]   Patrick Bejaw has a few podcasts of his own.
[02:20:44.260 --> 02:20:46.220]   Some of them are in English.
[02:20:46.220 --> 02:20:48.440]   A different stream.com.
[02:20:48.440 --> 02:20:55.180]   Yeah, so I guess, well, if you speak French, first of all, or if you want to learn, why
[02:20:55.180 --> 02:21:00.620]   don't you listen to a podcast on a subject matter you already are familiar with and listen
[02:21:00.620 --> 02:21:05.660]   to Le Chante Wutetc, which is on frenchspin.fr.
[02:21:05.660 --> 02:21:09.060]   You can find it there and we talk about tech every week.
[02:21:09.060 --> 02:21:11.020]   But if you speak English, I have a couple of shows.
[02:21:11.020 --> 02:21:15.500]   Pixels is if you're a gamer, go check out Pixels, Reefun Show.
[02:21:15.500 --> 02:21:22.220]   And if you enjoy talking people from different backgrounds, different cultures, the Phileas
[02:21:22.220 --> 02:21:27.780]   Club, go to frenchspin.com for the spelling, is a show where I get people from different
[02:21:27.780 --> 02:21:34.620]   countries, different cultures, as I said, to sit together every month and different people
[02:21:34.620 --> 02:21:35.860]   every time.
[02:21:35.860 --> 02:21:41.460]   And we talk about the state of the world and sometimes it's depressing and we try to have
[02:21:41.460 --> 02:21:42.460]   fun anyway.
[02:21:42.460 --> 02:21:50.340]   We don't always manage, but we really try to have people from all sides of discussions.
[02:21:50.340 --> 02:21:56.300]   And that includes people with whom I disagree vehemently very often, but I still listen to
[02:21:56.300 --> 02:21:57.300]   and respect.
[02:21:57.300 --> 02:21:58.300]   Yeah.
[02:21:58.300 --> 02:22:00.780]   You're really doing great stuff, I have to say.
[02:22:00.780 --> 02:22:04.100]   One of the best podcast networks out there, frenchspin.com and for the French-
[02:22:04.100 --> 02:22:05.100]   Thank you.
[02:22:05.100 --> 02:22:07.260]   I'm a microphone, frenchspin.fr.
[02:22:07.260 --> 02:22:12.540]   And I'm my French little rusty, but I think you would translate little Honde voutech as
[02:22:12.540 --> 02:22:15.740]   a hot date with tech.
[02:22:15.740 --> 02:22:17.460]   Is that right?
[02:22:17.460 --> 02:22:18.460]   Exactly.
[02:22:18.460 --> 02:22:19.460]   Exactly.
[02:22:19.460 --> 02:22:20.460]   That's absolutely what it is.
[02:22:20.460 --> 02:22:21.460]   Tech hot date.
[02:22:21.460 --> 02:22:23.220]   That's also you describe this weekend.
[02:22:23.220 --> 02:22:26.020]   It is a hot day every Sunday.
[02:22:26.020 --> 02:22:28.980]   Mike Elgin, thank you for being on this date.
[02:22:28.980 --> 02:22:29.980]   Thank you.
[02:22:29.980 --> 02:22:33.260]   Don't forget gastronomad.net and the upcoming events.
[02:22:33.260 --> 02:22:34.260]   Right.
[02:22:34.260 --> 02:22:35.260]   Still some time to sign up.
[02:22:35.260 --> 02:22:37.740]   Joining us in Mexico and Morocco, can I plug one other thing?
[02:22:37.740 --> 02:22:38.740]   Yeah.
[02:22:38.740 --> 02:22:40.380]   So my son Kevin Elgin is in the house.
[02:22:40.380 --> 02:22:41.380]   I see Kevin.
[02:22:41.380 --> 02:22:42.380]   He's the smart one in the family.
[02:22:42.380 --> 02:22:43.380]   Love it when Kevin shows that.
[02:22:43.380 --> 02:22:44.380]   He's an entrepreneur.
[02:22:44.380 --> 02:22:45.380]   Yeah.
[02:22:45.380 --> 02:22:49.020]   And he's creating a revolution in technology education for kids.
[02:22:49.020 --> 02:22:54.060]   You've got a smart speaker that doesn't track kids, that they build themselves physically.
[02:22:54.060 --> 02:22:55.540]   It's a cardboard thing.
[02:22:55.540 --> 02:22:58.060]   And then they teach it to talk.
[02:22:58.060 --> 02:22:59.060]   It demystifies AI.
[02:22:59.060 --> 02:23:01.220]   Oh, that's great.
[02:23:01.220 --> 02:23:06.140]   It teaches social skills because they have to understand what is clear speech and so on.
[02:23:06.140 --> 02:23:07.140]   It's a brilliant product.
[02:23:07.140 --> 02:23:09.340]   Go to HelloChatterbox.com.
[02:23:09.340 --> 02:23:10.340]   Sign up for his newsletter.
[02:23:10.340 --> 02:23:12.340]   He's got a Kickstarter coming up pretty soon.
[02:23:12.340 --> 02:23:14.180]   And the list will keep you informed about the newsletter.
[02:23:14.180 --> 02:23:19.460]   So I want to plug that because this is really important for the future of the world.
[02:23:19.460 --> 02:23:21.540]   We got to educate kids about technology.
[02:23:21.540 --> 02:23:23.300]   And this is the first generation.
[02:23:23.300 --> 02:23:27.700]   23% of American households now have a smart speaker in the house.
[02:23:27.700 --> 02:23:32.020]   Kids are learning that there's this AI presence and they're being taught to respect it, which
[02:23:32.020 --> 02:23:33.020]   they shouldn't.
[02:23:33.020 --> 02:23:35.460]   They're being taught to obey it, which they shouldn't.
[02:23:35.460 --> 02:23:39.580]   His technology will teach them that it's just an appliance that they control and it's a
[02:23:39.580 --> 02:23:40.580]   very healthy thing.
[02:23:40.580 --> 02:23:43.780]   So anyway, we'll try to talk about tech on the side.
[02:23:43.780 --> 02:23:44.780]   This is great.
[02:23:44.780 --> 02:23:48.060]   With a minute the Kickstarter starts, let me know and we'll make sure to give you lots
[02:23:48.060 --> 02:23:49.060]   of books.
[02:23:49.060 --> 02:23:50.060]   Great.
[02:23:50.060 --> 02:23:52.060]   And we'll be one of the first to buy it and build it.
[02:23:52.060 --> 02:23:54.380]   And every kid who does it absolutely loves it.
[02:23:54.380 --> 02:23:57.300]   And it's like they get super engaged in building something.
[02:23:57.300 --> 02:23:58.300]   It's wonderful.
[02:23:58.300 --> 02:23:59.300]   This is perfect for you.
[02:23:59.300 --> 02:24:00.300]   He needs to deliver to Europe.
[02:24:00.300 --> 02:24:02.700]   Tell your son he needs to deliver to you.
[02:24:02.700 --> 02:24:04.100]   I have a one-year-old.
[02:24:04.100 --> 02:24:07.300]   Yeah, he says they're going to do it.
[02:24:07.300 --> 02:24:09.300]   Yep, they're going to do it.
[02:24:09.300 --> 02:24:10.300]   Okay, cool.
[02:24:10.300 --> 02:24:11.300]   Yeah.
[02:24:11.300 --> 02:24:12.300]   This is great.
[02:24:12.300 --> 02:24:14.580]   We will absolutely, I'm going to do this with our 16-year-old because it doesn't listen
[02:24:14.580 --> 02:24:16.660]   until they press a button so it's not always listening.
[02:24:16.660 --> 02:24:17.660]   Oh, even better.
[02:24:17.660 --> 02:24:19.260]   It's got a big yellow button on the top.
[02:24:19.260 --> 02:24:21.260]   I like it.
[02:24:21.260 --> 02:24:28.260]   That's a great thing.
[02:24:28.260 --> 02:24:29.260]   I can't wait.
[02:24:29.260 --> 02:24:30.260]   That's really brilliant.
[02:24:30.260 --> 02:24:31.260]   Oh, so cool.
[02:24:31.260 --> 02:24:33.260]   Is that a Raspberry Pi in there?
[02:24:33.260 --> 02:24:34.260]   Raspberry Pi?
[02:24:34.260 --> 02:24:35.260]   Nice.
[02:24:35.260 --> 02:24:36.260]   So cool.
[02:24:36.260 --> 02:24:38.260]   So they're going to learn Python.
[02:24:38.260 --> 02:24:41.260]   Oh, they do Blockly.
[02:24:41.260 --> 02:24:42.260]   There you go.
[02:24:42.260 --> 02:24:43.260]   Yeah, yeah.
[02:24:43.260 --> 02:24:45.260]   All the parts through the recyclable or reusable.
[02:24:45.260 --> 02:24:50.740]   So schools that use this can take apart the cardboard part and then they reuse the electronics
[02:24:50.740 --> 02:24:54.740]   and it costs the schools a few bucks per student for this.
[02:24:54.740 --> 02:24:55.740]   Nice.
[02:24:55.740 --> 02:24:56.740]   Yeah.
[02:24:56.740 --> 02:24:59.340]   And the computer of the future, if we want to prepare kids for the future, the future
[02:24:59.340 --> 02:25:01.300]   is voice-driven AI.
[02:25:01.300 --> 02:25:03.100]   Yeah, that's the future.
[02:25:03.100 --> 02:25:05.940]   But I think you're absolutely right.
[02:25:05.940 --> 02:25:11.340]   I hear articles about parents who are teaching their kids to say, "Please and thank you to
[02:25:11.340 --> 02:25:13.140]   Amazon Echo."
[02:25:13.140 --> 02:25:16.340]   And it's like saying, "Teach your kids to say, 'Please and thank you to the microwave
[02:25:16.340 --> 02:25:17.340]   constantly.'"
[02:25:17.340 --> 02:25:18.340]   Exactly.
[02:25:18.340 --> 02:25:19.340]   It makes no sense.
[02:25:19.340 --> 02:25:20.340]   Exactly.
[02:25:20.340 --> 02:25:21.340]   That's good.
[02:25:21.340 --> 02:25:22.340]   Yeah.
[02:25:22.340 --> 02:25:24.460]   Thank you, everybody, for being here with a great studio audience.
[02:25:24.460 --> 02:25:29.420]   If you can't always promise something as delicious as piping-hop Rodey, this is amazing.
[02:25:29.420 --> 02:25:30.420]   No, it's not.
[02:25:30.420 --> 02:25:31.420]   It's car-tasting.
[02:25:31.420 --> 02:25:32.420]   No, it's...
[02:25:32.420 --> 02:25:33.420]   Is it good?
[02:25:33.420 --> 02:25:34.980]   It would be nice to have some Indian food or something.
[02:25:34.980 --> 02:25:35.980]   Something puts it in the audit.
[02:25:35.980 --> 02:25:36.980]   Yeah, yeah, yeah.
[02:25:36.980 --> 02:25:38.940]   But if you would like to be here, you never know.
[02:25:38.940 --> 02:25:40.260]   You might get some Rodey.
[02:25:40.260 --> 02:25:44.300]   All you have to do is email tickets@twit.tv.
[02:25:44.300 --> 02:25:48.620]   We'll send you directions, information, if you're in the Petaluma area any Sunday or
[02:25:48.620 --> 02:25:52.380]   actually most days of the week, because we have a lot of shows all week long, just email
[02:25:52.380 --> 02:25:53.380]   tickets@twit.tv.
[02:25:53.380 --> 02:25:54.740]   We'd love to see you.
[02:25:54.740 --> 02:25:58.860]   You can also kind of participate live with a live stream at twit.tv/live.
[02:25:58.860 --> 02:26:01.140]   We've got audio and video there.
[02:26:01.140 --> 02:26:08.900]   And a wonderful group in our chat room chatting along with us as we do the shows, IRC.twit.tv.
[02:26:08.900 --> 02:26:10.300]   Most people though listen on demand.
[02:26:10.300 --> 02:26:12.220]   That's the whole point, right?
[02:26:12.220 --> 02:26:13.620]   Listen to the show when it works for you.
[02:26:13.620 --> 02:26:16.100]   A lot of people like to get it for their Monday commute.
[02:26:16.100 --> 02:26:17.100]   That's easy enough.
[02:26:17.100 --> 02:26:20.100]   You can also click on the link in the description below.
[02:26:20.100 --> 02:26:24.100]   And you can also click on the link in the description below.
[02:26:24.100 --> 02:26:27.100]   And you can also click on the link in the description below.
[02:26:27.100 --> 02:26:30.100]   And you can also click on the link in the description below.
[02:26:30.100 --> 02:26:33.100]   And you can also click on the link in the description below.
[02:26:33.100 --> 02:26:36.100]   And you can also click on the link in the description below.
[02:26:36.100 --> 02:26:39.100]   And you can also click on the link in the description below.
[02:26:39.100 --> 02:26:42.100]   And you can also click on the link in the description below.
[02:26:42.100 --> 02:26:45.100]   And you can also click on the link in the description below.
[02:26:45.100 --> 02:26:48.100]   And you can also click on the link in the description below.
[02:26:48.100 --> 02:26:50.100]   And you can also click on the link in the description below.
[02:26:50.100 --> 02:26:52.100]   And you can also click on the link in the description below.
[02:26:52.100 --> 02:26:55.100]   And you can also click on the link in the description below.
[02:26:55.100 --> 02:26:58.100]   And you can also click on the link in the description below.
[02:26:58.100 --> 02:27:01.100]   And you can also click on the link in the description below.

