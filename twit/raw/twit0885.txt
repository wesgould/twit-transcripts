;FFMETADATA1
title=St Jeff's Memorial Hospital
artist=Megan Morrone, Roberto Baldwin, Ashley Esqueda, Jason Howell
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2022-07-24
track=885
language=English
genre=Podcast
comment=Amazon Buys One Medical, Google Glass AR, Netflix Ad-Supported		
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:01.520]   It's time for Twit.
[00:00:01.520 --> 00:00:04.120]   This week in Tech, I'm Jason Howell, filling in for Leo LaPorte.
[00:00:04.120 --> 00:00:09.320]   Today we've got some awesome guests joining me today is Ashley Aschetha, Roberto Baldwin,
[00:00:09.320 --> 00:00:13.520]   and Megan Moroni, where you have so much fun, so much news to discuss.
[00:00:13.520 --> 00:00:16.320]   Amazon buying one medical.
[00:00:16.320 --> 00:00:19.160]   What might prime healthcare actually look like?
[00:00:19.160 --> 00:00:20.720]   We take some guesses.
[00:00:20.720 --> 00:00:23.480]   Also Snap and Twitter earnings lagging.
[00:00:23.480 --> 00:00:28.560]   That's largely thanks to a diminishing ad spend market.
[00:00:28.560 --> 00:00:29.880]   What does it mean for big tech?
[00:00:29.880 --> 00:00:30.880]   What's coming up?
[00:00:30.880 --> 00:00:32.560]   Subscriptions for in-car features?
[00:00:32.560 --> 00:00:33.560]   Hot or not?
[00:00:33.560 --> 00:00:36.240]   I think not, but we've got a nice discussion there.
[00:00:36.240 --> 00:00:41.440]   How Netflix's identity, which is binging content, is actually biting its butt.
[00:00:41.440 --> 00:00:47.880]   Plus so much more coming up next on This Week in Tech.
[00:00:47.880 --> 00:00:48.880]   Podcasts you love.
[00:00:48.880 --> 00:00:51.880]   From people you trust.
[00:00:51.880 --> 00:00:54.880]   This is Twit.
[00:00:54.880 --> 00:01:08.600]   This week in Tech, episode 885, recorded Sunday, July 24th, 2022.
[00:01:08.600 --> 00:01:11.200]   St. Jeff's Memorial Hospital.
[00:01:11.200 --> 00:01:14.520]   This episode of This Week in Tech is brought to you by Zip Recruiter.
[00:01:14.520 --> 00:01:17.360]   Certain people make my life easier by helping me out.
[00:01:17.360 --> 00:01:21.920]   And Zip Recruiter makes hiring easier because they do the work for you.
[00:01:21.920 --> 00:01:22.920]   How?
[00:01:22.920 --> 00:01:27.720]   Zip Recruiter's technology finds great candidates and you can invite them to apply.
[00:01:27.720 --> 00:01:32.760]   Go to ziprecruiter.com/twit to try it for free.
[00:01:32.760 --> 00:01:33.760]   And Buy Audible.
[00:01:33.760 --> 00:01:37.720]   Audible lets you enjoy all of your audio entertainment in one app.
[00:01:37.720 --> 00:01:42.480]   Let Audible help you discover new ways to laugh, be inspired, or be entertained.
[00:01:42.480 --> 00:01:44.720]   New members can try it free for 30 days.
[00:01:44.720 --> 00:01:51.040]   Visit audible.com/twit or text Twit to 500-500.
[00:01:51.040 --> 00:01:52.800]   And Buy Stamps.com.
[00:01:52.800 --> 00:01:58.360]   Stop wasting time and start saving money when you use Stamps.com to mail and ship.
[00:01:58.360 --> 00:02:02.200]   Sign up at Stamps.com, click the microphone at the top of the page and enter code Twit
[00:02:02.200 --> 00:02:09.040]   for a special offer that includes a four-week trial plus free postage and a digital scale.
[00:02:09.040 --> 00:02:10.560]   And Buy Express VPN.
[00:02:10.560 --> 00:02:14.440]   If you don't like big tech tracking you and selling your personal data for profit, it's
[00:02:14.440 --> 00:02:16.000]   time to fight back.
[00:02:16.000 --> 00:02:27.880]   Get three extra months free with a one-year package by going to expressvpn.com/twit.
[00:02:27.880 --> 00:02:32.560]   It's time for Twit this week in tech and you can already tell it's a different kind of
[00:02:32.560 --> 00:02:37.560]   Twit because I'm your host today, Jason Howell filling in for Leo LaPorte who will be returning
[00:02:37.560 --> 00:02:40.920]   soon but not today.
[00:02:40.920 --> 00:02:46.960]   And what can I say on all the weeks like no matter what with Twit, you're guaranteed
[00:02:46.960 --> 00:02:49.760]   to end up on a panel of amazing people.
[00:02:49.760 --> 00:02:54.560]   But I've got three of my favorite internet people on with me today starting with Ashley
[00:02:54.560 --> 00:02:58.600]   Asquetha writer, host, internet rock on tour.
[00:02:58.600 --> 00:03:00.600]   How are you doing Ashley?
[00:03:00.600 --> 00:03:05.640]   I'm good, gainfully unemployed, working on stuff projects.
[00:03:05.640 --> 00:03:06.640]   I'm great.
[00:03:06.640 --> 00:03:07.640]   Things are good.
[00:03:07.640 --> 00:03:08.640]   Things are weird.
[00:03:08.640 --> 00:03:09.640]   Things are good.
[00:03:09.640 --> 00:03:10.640]   I like it.
[00:03:10.640 --> 00:03:14.280]   That sounds like the last couple of years in a nutshell, things are weird at least.
[00:03:14.280 --> 00:03:18.480]   I don't know if people would test with a good part maybe.
[00:03:18.480 --> 00:03:22.760]   Yeah, I might have to just like, I may have to throw a flag there but weird.
[00:03:22.760 --> 00:03:23.760]   Yeah, for sure.
[00:03:23.760 --> 00:03:24.760]   Fair.
[00:03:24.760 --> 00:03:25.760]   Fair enough.
[00:03:25.760 --> 00:03:26.760]   Well, it's great to have you here Ashley.
[00:03:26.760 --> 00:03:30.480]   It's been a while and really appreciate you joining us on this week in tech.
[00:03:30.480 --> 00:03:33.840]   Also joining us another person who has not been on the show.
[00:03:33.840 --> 00:03:36.800]   Actually I think everybody that's on the show has been on in quite a while.
[00:03:36.800 --> 00:03:39.120]   Roberto Baldwin is here.
[00:03:39.120 --> 00:03:43.320]   A co-host, Will Bering's podcast in Man about Town.
[00:03:43.320 --> 00:03:46.080]   Man about Town.
[00:03:46.080 --> 00:03:48.160]   I do things around town.
[00:03:48.160 --> 00:03:50.120]   Sometimes people pay me for those things.
[00:03:50.120 --> 00:03:51.120]   Wow.
[00:03:51.120 --> 00:03:52.120]   That's awesome.
[00:03:52.120 --> 00:03:54.120]   Hey, I heard that you did something around town last night.
[00:03:54.120 --> 00:03:55.400]   You had a show, right?
[00:03:55.400 --> 00:03:58.120]   Oh yeah, Friday night we had a show at the Rich Show.
[00:03:58.120 --> 00:03:59.120]   Oh, that was Friday.
[00:03:59.120 --> 00:04:00.120]   Sorry.
[00:04:00.120 --> 00:04:02.400]   Two of my like 17 bands had a show that night.
[00:04:02.400 --> 00:04:03.400]   So it was a good time.
[00:04:03.400 --> 00:04:04.840]   So if you were there, hi.
[00:04:04.840 --> 00:04:07.200]   If you weren't, I don't know, go there next time I guess.
[00:04:07.200 --> 00:04:08.200]   Right.
[00:04:08.200 --> 00:04:09.200]   There will be more.
[00:04:09.200 --> 00:04:10.200]   There will be more.
[00:04:10.200 --> 00:04:11.720]   One of these days I'm going to make it to one of your shows.
[00:04:11.720 --> 00:04:12.720]   Love it.
[00:04:12.720 --> 00:04:13.720]   That's awesome.
[00:04:13.720 --> 00:04:14.720]   Welcome back, Roberto.
[00:04:14.720 --> 00:04:15.720]   It's good to see you.
[00:04:15.720 --> 00:04:20.320]   And then also joining us, someone who folks who are familiar with the Twit Network are
[00:04:20.320 --> 00:04:21.320]   very familiar with.
[00:04:21.320 --> 00:04:25.720]   Haven't seen it a while on this network on this show, especially Megan Maroney.
[00:04:25.720 --> 00:04:27.840]   Welcome back, Megan.
[00:04:27.840 --> 00:04:28.840]   Thank you.
[00:04:28.840 --> 00:04:31.080]   I am so excited to be here.
[00:04:31.080 --> 00:04:32.720]   Forgive me if I faint.
[00:04:32.720 --> 00:04:34.560]   I got my second booster today.
[00:04:34.560 --> 00:04:37.440]   I got the Band-Aid and everything.
[00:04:37.440 --> 00:04:40.880]   So yeah, I feel great.
[00:04:40.880 --> 00:04:41.880]   Good.
[00:04:41.880 --> 00:04:44.040]   Well, you look great.
[00:04:44.040 --> 00:04:49.000]   And it's great to have you on for now until that booster kicks in and just give us a
[00:04:49.000 --> 00:04:50.000]   heads up, I guess.
[00:04:50.000 --> 00:04:51.800]   If you start getting dizzy or whatever, I don't.
[00:04:51.800 --> 00:04:53.120]   Yeah, just give us a heads up.
[00:04:53.120 --> 00:04:58.600]   Editor at Pro Call, of course, just so people know what you're up to now.
[00:04:58.600 --> 00:05:01.640]   But it is so good to see the three of you.
[00:05:01.640 --> 00:05:02.760]   This is going to be a lot of fun.
[00:05:02.760 --> 00:05:05.440]   We've got the keys to the sports car this week.
[00:05:05.440 --> 00:05:08.280]   So where should we drive first?
[00:05:08.280 --> 00:05:10.480]   We got a dock full of news.
[00:05:10.480 --> 00:05:14.160]   And I really do not want to start with Elon Musk.
[00:05:14.160 --> 00:05:17.480]   So I don't even know why I said that out loud because it almost makes it happen when you
[00:05:17.480 --> 00:05:18.480]   do that.
[00:05:18.480 --> 00:05:19.880]   It's going to say now I feel like we have to.
[00:05:19.880 --> 00:05:25.240]   I feel like you drove us right off the freeway into downtown.
[00:05:25.240 --> 00:05:27.600]   It's like everybody's got a knee gone wrong.
[00:05:27.600 --> 00:05:29.520]   It's like don't stare at the sun.
[00:05:29.520 --> 00:05:30.520]   Don't look at the sun.
[00:05:30.520 --> 00:05:31.520]   And then I looked at the sun.
[00:05:31.520 --> 00:05:33.080]   This is exactly what I did.
[00:05:33.080 --> 00:05:34.080]   Fine.
[00:05:34.080 --> 00:05:35.080]   Real quick.
[00:05:35.080 --> 00:05:36.880]   We're a recurring segment on Twitch.
[00:05:36.880 --> 00:05:38.560]   Just Elon did something.
[00:05:38.560 --> 00:05:41.960]   And then you just talk about it because it just seems like a guarantee every week.
[00:05:41.960 --> 00:05:44.680]   There's something going on with Elon Musk.
[00:05:44.680 --> 00:05:46.120]   It's a six sided die.
[00:05:46.120 --> 00:05:48.320]   And when you roll it, five of them say Musk.
[00:05:48.320 --> 00:05:51.200]   And the other one is like a random story.
[00:05:51.200 --> 00:05:52.200]   Yeah.
[00:05:52.200 --> 00:05:54.520]   So what is the thing that Elon Musk did this time?
[00:05:54.520 --> 00:05:57.560]   Well, I guess this has to do with his trial, right?
[00:05:57.560 --> 00:06:00.080]   There's this trial.
[00:06:00.080 --> 00:06:03.880]   And between Twitter and Elon Musk.
[00:06:03.880 --> 00:06:05.760]   Musk was pushing for it to go to next year.
[00:06:05.760 --> 00:06:07.440]   But that's not happening.
[00:06:07.440 --> 00:06:09.480]   Apparently Twitter was pushing for it to happen soon.
[00:06:09.480 --> 00:06:12.080]   They want to get this done.
[00:06:12.080 --> 00:06:19.280]   Reap whatever reward slash benefit they can from this really just messy, ugly situation.
[00:06:19.280 --> 00:06:22.080]   And apparently it's going to be expedited five day trial.
[00:06:22.080 --> 00:06:25.200]   It's going to happen in October.
[00:06:25.200 --> 00:06:26.880]   So we aren't going to have to wait long.
[00:06:26.880 --> 00:06:28.840]   I kind of felt like we're going to wait a lot longer.
[00:06:28.840 --> 00:06:32.400]   And this whole Musk thing was going to continue out forever and ever.
[00:06:32.400 --> 00:06:34.520]   But I suppose this is good news.
[00:06:34.520 --> 00:06:35.840]   What do you all think?
[00:06:35.840 --> 00:06:40.520]   Well, that Delaware court of chance re like they don't they don't tend to mess around.
[00:06:40.520 --> 00:06:44.480]   This is like a very no nonsense court.
[00:06:44.480 --> 00:06:51.240]   And yeah, it ended up I think the five days is actually one party wanted a shorter trial.
[00:06:51.240 --> 00:06:52.800]   The other wanted a longer one.
[00:06:52.800 --> 00:06:57.480]   And then of course, like Elon Musk said, my legal team needs more time to prepare.
[00:06:57.480 --> 00:07:00.280]   We have to push this until next year.
[00:07:00.280 --> 00:07:02.920]   Three, Nope, nope, we're going to do this in October.
[00:07:02.920 --> 00:07:04.480]   It's going to be five days and that's it.
[00:07:04.480 --> 00:07:09.520]   So I think, you know, Twitter just wants to put all this to bed, whatever, you know, come
[00:07:09.520 --> 00:07:11.800]   what may they would like to move past this.
[00:07:11.800 --> 00:07:16.960]   And so I think that, you know, this is a real big win for Twitter to not have to kind
[00:07:16.960 --> 00:07:21.200]   of drag this out even longer than it needs to be.
[00:07:21.200 --> 00:07:23.320]   It's it's on for you and to want to delay something.
[00:07:23.320 --> 00:07:26.960]   I've never that doesn't seem like it's in his personality at all.
[00:07:26.960 --> 00:07:30.600]   I don't know.
[00:07:30.600 --> 00:07:33.880]   The filing itself is funny because it's sort of designed for Twitter.
[00:07:33.880 --> 00:07:38.520]   Like it's in, you know, it has the little poop emoji that he tweeted in it.
[00:07:38.520 --> 00:07:44.320]   It's like little pieces that it's almost like they did it just like perfect for their platform.
[00:07:44.320 --> 00:07:45.600]   Like this is how it's going to play out.
[00:07:45.600 --> 00:07:47.000]   This is the speed it, which is going to play out.
[00:07:47.000 --> 00:07:52.600]   If you read it, it's just like little tweets basically in the filing, which is amazing.
[00:07:52.600 --> 00:07:54.920]   It's like a little performance art.
[00:07:54.920 --> 00:08:01.040]   The entire trial is expected to be rolled out in 140 characters per, you know, size.
[00:08:01.040 --> 00:08:02.880]   So I think you're absolutely right.
[00:08:02.880 --> 00:08:05.640]   I don't know how they're going to do it.
[00:08:05.640 --> 00:08:06.640]   280 now.
[00:08:06.640 --> 00:08:07.640]   Is it 280 now?
[00:08:07.640 --> 00:08:08.640]   Let's let it.
[00:08:08.640 --> 00:08:09.640]   Let's let it.
[00:08:09.640 --> 00:08:10.640]   That's true.
[00:08:10.640 --> 00:08:11.640]   They have expanded on that.
[00:08:11.640 --> 00:08:12.640]   It's expanded.
[00:08:12.640 --> 00:08:13.640]   The tweets have been expanded.
[00:08:13.640 --> 00:08:14.640]   Classic Twitter.
[00:08:14.640 --> 00:08:15.640]   It's going to be one long thread, one long thread.
[00:08:15.640 --> 00:08:17.640]   And the lawyers are not allowed to edit anything.
[00:08:17.640 --> 00:08:19.640]   They're not and I know what it is.
[00:08:19.640 --> 00:08:20.640]   Sorry.
[00:08:20.640 --> 00:08:21.640]   Sorry.
[00:08:21.640 --> 00:08:24.080]   There will be not a single edit made.
[00:08:24.080 --> 00:08:25.080]   No ends.
[00:08:25.080 --> 00:08:28.480]   Unless they subscribe to Twitter blue, in which case you can undo an argument.
[00:08:28.480 --> 00:08:29.480]   There you go.
[00:08:29.480 --> 00:08:30.480]   Really?
[00:08:30.480 --> 00:08:33.880]   Are you all using Twitter blue these days?
[00:08:33.880 --> 00:08:39.280]   I signed up for it initially and then after like a couple of weeks, like I think my credit
[00:08:39.280 --> 00:08:41.960]   card, like I had to replace my credit card, there was fraud or something like that and
[00:08:41.960 --> 00:08:43.200]   I just never updated it.
[00:08:43.200 --> 00:08:44.840]   So apparently I'm not missing it that much.
[00:08:44.840 --> 00:08:47.280]   But what about y'all?
[00:08:47.280 --> 00:08:48.280]   I do.
[00:08:48.280 --> 00:08:49.280]   For sure.
[00:08:49.280 --> 00:08:50.280]   Not enough.
[00:08:50.280 --> 00:08:51.280]   Yeah.
[00:08:51.280 --> 00:08:52.280]   I do still.
[00:08:52.280 --> 00:08:56.200]   I do so much that I feel like I like some of the features it has.
[00:08:56.200 --> 00:08:57.600]   So it's like helpful for me.
[00:08:57.600 --> 00:08:59.880]   But the undo is really nice.
[00:08:59.880 --> 00:09:04.800]   Like the end of it's like, Hey, if you want to undo this in like 10 seconds, then like
[00:09:04.800 --> 00:09:09.280]   here's your chance because it'll give me that one last like proofreading, which that's
[00:09:09.280 --> 00:09:11.280]   always when I catch it right after I post.
[00:09:11.280 --> 00:09:14.280]   So once I hit that tweet button and it's like, Oh, there's my typo.
[00:09:14.280 --> 00:09:15.280]   Undo that.
[00:09:15.280 --> 00:09:16.280]   Like let's just start over.
[00:09:16.280 --> 00:09:17.280]   So that's helpful.
[00:09:17.280 --> 00:09:18.280]   I like that.
[00:09:18.280 --> 00:09:19.280]   That's a nice feature.
[00:09:19.280 --> 00:09:21.280]   I actually do appreciate that feature.
[00:09:21.280 --> 00:09:22.280]   Yeah.
[00:09:22.280 --> 00:09:24.080]   Yeah, that was the only feature I used.
[00:09:24.080 --> 00:09:27.080]   And for $5 a month, I felt like it was worth it.
[00:09:27.080 --> 00:09:31.040]   But I also felt like it kind of trained me a little bit to take that extra look.
[00:09:31.040 --> 00:09:33.920]   So I don't know, you know, you form a habit in like 30 days.
[00:09:33.920 --> 00:09:42.200]   So like now I do feel like I, yeah, I, I think a little bit more and I do that last proofread
[00:09:42.200 --> 00:09:46.320]   before I tweet, but in the, the no ads thing never really worked for me.
[00:09:46.320 --> 00:09:51.920]   Like I would always click and get at, you know, like saying I'm supposed to be able to see
[00:09:51.920 --> 00:09:54.440]   content with no ads or maybe see it without a subscription.
[00:09:54.440 --> 00:09:55.440]   I don't know.
[00:09:55.440 --> 00:09:56.440]   That was.
[00:09:56.440 --> 00:09:57.440]   Yeah.
[00:09:57.440 --> 00:10:00.680]   It's the thing is very weird because it's like for LA times, like if I click on an LA times
[00:10:00.680 --> 00:10:03.520]   article, it says you need a subscription.
[00:10:03.520 --> 00:10:08.000]   And I guess if I have a subscription, that would be a thing I wouldn't see other ads
[00:10:08.000 --> 00:10:09.000]   on.
[00:10:09.000 --> 00:10:10.000]   It's very odd.
[00:10:10.000 --> 00:10:12.120]   And it doesn't work and it's weird and bad.
[00:10:12.120 --> 00:10:15.120]   And I don't like, I don't like how it's set up.
[00:10:15.120 --> 00:10:17.840]   It should just be here are the partnerships we have.
[00:10:17.840 --> 00:10:22.600]   If you click on an article in the Twitter app, we will open it in our proprietary browser
[00:10:22.600 --> 00:10:26.920]   and you can read it like in a reader mode or something like that with no ads and that's
[00:10:26.920 --> 00:10:27.920]   it.
[00:10:27.920 --> 00:10:30.000]   Like that should be how it works.
[00:10:30.000 --> 00:10:33.520]   But unfortunately that is not the case and it is very annoying.
[00:10:33.520 --> 00:10:34.520]   Yeah.
[00:10:34.520 --> 00:10:36.440]   And it's not hard to do that.
[00:10:36.440 --> 00:10:37.440]   But go ahead.
[00:10:37.440 --> 00:10:38.920]   No, it's not.
[00:10:38.920 --> 00:10:39.920]   Yeah.
[00:10:39.920 --> 00:10:42.280]   I thought about signing up and then I thought I don't care enough.
[00:10:42.280 --> 00:10:43.280]   I tweet.
[00:10:43.280 --> 00:10:44.280]   Oh my God.
[00:10:44.280 --> 00:10:45.280]   It's not so much.
[00:10:45.280 --> 00:10:49.120]   And they're all full of typos and I'm like, you know, I've gone this far.
[00:10:49.120 --> 00:10:52.120]   Why why why mess with the brand?
[00:10:52.120 --> 00:10:53.560]   Why mess with the brand?
[00:10:53.560 --> 00:10:54.560]   That's my brand.
[00:10:54.560 --> 00:10:55.560]   Exactly.
[00:10:55.560 --> 00:10:56.560]   Like why mess with it?
[00:10:56.560 --> 00:10:57.560]   Just let it go.
[00:10:57.560 --> 00:11:02.840]   If there are if there are five tweets happen and none of them have typos, people are just
[00:11:02.840 --> 00:11:04.200]   going to assume I've been kidnapped.
[00:11:04.200 --> 00:11:07.240]   So or how to understand or both.
[00:11:07.240 --> 00:11:11.200]   It's a good feel safe that you've inadvertently created for yourself.
[00:11:11.200 --> 00:11:12.200]   I like them.
[00:11:12.200 --> 00:11:13.200]   Yeah.
[00:11:13.200 --> 00:11:14.200]   It's my security.
[00:11:14.200 --> 00:11:16.200]   I'm going to say info sec.
[00:11:16.200 --> 00:11:17.200]   Very nice.
[00:11:17.200 --> 00:11:20.440]   Apparently we don't care about Musk because we're just talking about Twitter.
[00:11:20.440 --> 00:11:21.440]   It has nothing to do with Elon Musk.
[00:11:21.440 --> 00:11:22.440]   And you know what?
[00:11:22.440 --> 00:11:24.720]   That's just the way it deserves to be.
[00:11:24.720 --> 00:11:25.720]   That actually makes a lot of sense.
[00:11:25.720 --> 00:11:27.360]   There's so many other things he did this week too.
[00:11:27.360 --> 00:11:31.400]   Like today, yesterday, they before it just nonstop.
[00:11:31.400 --> 00:11:34.680]   He's just so much of it is just so tabloidy though.
[00:11:34.680 --> 00:11:38.280]   So I end up tuning out because it just feels like noise more than anything.
[00:11:38.280 --> 00:11:39.840]   You know, so much.
[00:11:39.840 --> 00:11:43.160]   I did almost get canceled on Twitter this week.
[00:11:43.160 --> 00:11:44.160]   Shall we talk about that?
[00:11:44.160 --> 00:11:45.160]   I love you.
[00:11:45.160 --> 00:11:46.160]   Do you tell?
[00:11:46.160 --> 00:11:47.160]   Yeah.
[00:11:47.160 --> 00:11:48.360]   Nobody can't look in.
[00:11:48.360 --> 00:11:52.880]   So I got home from work and my three teenagers were at the dinner table and I was like, did
[00:11:52.880 --> 00:11:56.680]   you see the pictures of Elon Musk without a shirt on?
[00:11:56.680 --> 00:12:03.000]   And my daughter said, Mom, you cannot body shame anyone, including billionaires.
[00:12:03.000 --> 00:12:04.000]   She's 19.
[00:12:04.000 --> 00:12:04.840]   It's smarter than me.
[00:12:04.840 --> 00:12:06.600]   And so I tweeted that.
[00:12:06.600 --> 00:12:11.920]   And I said, I thought she was wrong, which, you know, if you know me, I was joking.
[00:12:11.920 --> 00:12:13.680]   I'm not a body shamer.
[00:12:13.680 --> 00:12:17.920]   But then someone retweeted it and there was a whole big thing about like, if you body
[00:12:17.920 --> 00:12:23.000]   shame a billionaire, anyone with a similar body will feel like now they know, you know,
[00:12:23.000 --> 00:12:24.000]   what you think about them.
[00:12:24.000 --> 00:12:25.960]   It was a big learning moment.
[00:12:25.960 --> 00:12:30.200]   But it was one of those moments where I was like, Oh yeah, I guess everyone who follows
[00:12:30.200 --> 00:12:35.920]   me and follows the people who are going to retweet me don't really know when I'm joking.
[00:12:35.920 --> 00:12:36.920]   Right.
[00:12:36.920 --> 00:12:37.920]   So yeah.
[00:12:37.920 --> 00:12:39.120]   And then somebody retweeted today.
[00:12:39.120 --> 00:12:41.040]   And like, yeah, don't body shame the rich.
[00:12:41.040 --> 00:12:43.000]   Just eat the rich, which I thought was good.
[00:12:43.000 --> 00:12:44.000]   That's a good.
[00:12:44.000 --> 00:12:45.000]   Yeah.
[00:12:45.000 --> 00:12:48.760]   If you're going to eat the rich, you shouldn't be body shacking them.
[00:12:48.760 --> 00:12:51.760]   If anything wrong with eating the rich, right.
[00:12:51.760 --> 00:12:54.600]   Nothing wrong with eating the rich or taxing them for.
[00:12:54.600 --> 00:12:58.800]   There are just so many other ways to like poke fun at them.
[00:12:58.800 --> 00:12:59.800]   Yeah.
[00:12:59.800 --> 00:13:00.800]   He's a lot.
[00:13:00.800 --> 00:13:04.720]   It's like a lot is like, did you see his Eldred Ring build?
[00:13:04.720 --> 00:13:05.720]   It's garbage.
[00:13:05.720 --> 00:13:06.720]   Like that's that's there.
[00:13:06.720 --> 00:13:09.720]   I'm trying to get before.
[00:13:09.720 --> 00:13:12.600]   I'll be careful with that one.
[00:13:12.600 --> 00:13:15.960]   I will throw the word made and list around with out remorse.
[00:13:15.960 --> 00:13:19.440]   I have that's my favorite insult for people now.
[00:13:19.440 --> 00:13:24.720]   It's just that's part of my permanent lexicon just made and less behavior.
[00:13:24.720 --> 00:13:33.920]   Well, let's move on from Elon Musk to to just Twitter and snap.
[00:13:33.920 --> 00:13:38.560]   The only reason I'm going here is because I'm seeing kind of like a thing happening.
[00:13:38.560 --> 00:13:41.000]   I think this is kind of interesting to talk about.
[00:13:41.000 --> 00:13:47.200]   Snap had its weakest quarterly earnings report ever.
[00:13:47.200 --> 00:13:48.200]   It's growth.
[00:13:48.200 --> 00:13:51.280]   The slowest growth in history as a public company.
[00:13:51.280 --> 00:13:56.400]   And of course, the economy right now, everything's in flux, everything's upside down.
[00:13:56.400 --> 00:14:00.280]   It feels like, especially the last six months, things have changed a lot and a very short
[00:14:00.280 --> 00:14:02.000]   amount of time.
[00:14:02.000 --> 00:14:07.480]   And so what they're seeing because they rely so heavily on the ad spend is that that money
[00:14:07.480 --> 00:14:11.520]   is just being being removed, right?
[00:14:11.520 --> 00:14:18.320]   Not to mention Apple's privacy policy changes, which have had a dramatic effect on snap.
[00:14:18.320 --> 00:14:23.680]   This is of course the changes that allowed iOS users to opt out of ad tracking.
[00:14:23.680 --> 00:14:27.520]   So that's making things more difficult for a company, a poor company like snap.
[00:14:27.520 --> 00:14:29.040]   Shares dropped 25% on the news.
[00:14:29.040 --> 00:14:33.840]   Then you got Twitter, which reported lower than expected earnings for the quarter.
[00:14:33.840 --> 00:14:37.000]   Their ad revenue actually only grew 2% year over year.
[00:14:37.000 --> 00:14:41.720]   That's compared to 23% growth last year.
[00:14:41.720 --> 00:14:47.560]   And so a lot of what I was reading about this has to do with the ad spend slowdown that's
[00:14:47.560 --> 00:14:48.560]   happening right now.
[00:14:48.560 --> 00:14:53.440]   The economy, of course, with Twitter, you've got the shirtless Elon that we're just talking
[00:14:53.440 --> 00:14:54.440]   about.
[00:14:54.440 --> 00:15:00.720]   There's probably a lot of blame that can be placed on him as far as that's concerned.
[00:15:00.720 --> 00:15:06.280]   And actually Twitter's spent out of pocket a good amount of money just on that alone,
[00:15:06.280 --> 00:15:09.360]   $33 million between April and June.
[00:15:09.360 --> 00:15:14.840]   But setting all that aside, we're in this time of economic uncertainty.
[00:15:14.840 --> 00:15:21.280]   Apple's privacy move is compounding the pain that's felt by tech companies who are just
[00:15:21.280 --> 00:15:27.080]   really their business is totally reliant on ad spending and data tracking and all this
[00:15:27.080 --> 00:15:28.080]   crazy stuff.
[00:15:28.080 --> 00:15:32.440]   It just seems like Twitter and snap are a couple of examples.
[00:15:32.440 --> 00:15:37.440]   And I feel like we're going to be cascading effect as we move forward further into this
[00:15:37.440 --> 00:15:38.440]   year.
[00:15:38.440 --> 00:15:40.960]   We're going to see a lot more companies feeling the effects of this.
[00:15:40.960 --> 00:15:43.720]   >> It's just not where people are.
[00:15:43.720 --> 00:15:45.720]   >> I mean, Twitter is its own thing.
[00:15:45.720 --> 00:15:49.440]   I mean, I think Twitter has always, like they've always struggled, right?
[00:15:49.440 --> 00:15:56.120]   To turn a profit to make Twitter to really blow out Twitter into something similar to
[00:15:56.120 --> 00:15:58.120]   a Facebook.
[00:15:58.120 --> 00:16:02.880]   I think Twitter is a weird kind of outlier in its own way.
[00:16:02.880 --> 00:16:04.440]   But that's not where anybody is.
[00:16:04.440 --> 00:16:09.320]   And so it's like Snapchat is competing with Instagram and TikTok.
[00:16:09.320 --> 00:16:17.760]   And the thing is there was a point where there was a mix of younger and older people on Snapchat.
[00:16:17.760 --> 00:16:22.080]   And now it's the younger people have broken off for TikTok and the older people have
[00:16:22.080 --> 00:16:23.360]   broken off for reals.
[00:16:23.360 --> 00:16:24.760]   They're over on Instagram.
[00:16:24.760 --> 00:16:26.920]   And so there's just nobody there.
[00:16:26.920 --> 00:16:33.400]   It's not in use the same way that Instagram is being used and that TikTok is being used.
[00:16:33.400 --> 00:16:39.640]   And so it's just, I don't know anybody who uses Snapchat as their main mode of conversation
[00:16:39.640 --> 00:16:40.640]   with anybody anymore.
[00:16:40.640 --> 00:16:43.160]   I mean, used to, but not anymore.
[00:16:43.160 --> 00:16:47.160]   And I think that's sort of the struggle that they're going to have is they're going to find
[00:16:47.160 --> 00:16:53.040]   it very difficult because all of the, you know, millennials and older are on Facebook and
[00:16:53.040 --> 00:16:58.160]   Instagram and all of the Gen Z is all the Gen Z kids are on TikTok now.
[00:16:58.160 --> 00:17:00.760]   And so they've all broken off from Snapchat and they're like, bye.
[00:17:00.760 --> 00:17:02.840]   Like we're, this is much more interesting to us.
[00:17:02.840 --> 00:17:08.320]   And also you have apps like Be Real, which a lot of influencers who are, you know, in
[00:17:08.320 --> 00:17:12.160]   that younger demographic, they're also breaking off to apps like that.
[00:17:12.160 --> 00:17:17.400]   So it's just, it's a scenario where like Snapchat is like not in a great place.
[00:17:17.400 --> 00:17:22.520]   And I don't know what they can do to bring people back.
[00:17:22.520 --> 00:17:25.920]   Release more spectacles, release more of self-edrones.
[00:17:25.920 --> 00:17:27.920]   Oh, spectacles.
[00:17:27.920 --> 00:17:32.400]   I don't think I've opened Snapchat in about four years.
[00:17:32.400 --> 00:17:37.120]   So yeah, there was a point where like, hey, we're all on Snapchat, but we were all on,
[00:17:37.120 --> 00:17:38.800]   you know, my space at some point.
[00:17:38.800 --> 00:17:40.360]   We were all on Friendster at some point.
[00:17:40.360 --> 00:17:41.360]   We were all on Facebook.
[00:17:41.360 --> 00:17:43.360]   We were all on Facebook at some point, that thing.
[00:17:43.360 --> 00:17:44.520]   Yeah, we were all on Facebook.
[00:17:44.520 --> 00:17:48.240]   And I mean, mostly I just get on Facebook to yell about Facebook about how angry I am
[00:17:48.240 --> 00:17:49.240]   with it.
[00:17:49.240 --> 00:17:52.400]   And then I mean, and mostly I'm on Facebook because of the bands because that's where
[00:17:52.400 --> 00:17:55.680]   everyone says, hey, go see a show here on Facebook.
[00:17:55.680 --> 00:18:00.240]   But even for that, it's become completely unusable.
[00:18:00.240 --> 00:18:04.920]   It's just, Facebook is really good at selling ads and that's about it.
[00:18:04.920 --> 00:18:09.840]   Snapchat is really good at just, I don't know, sticking around longer than I anticipated,
[00:18:09.840 --> 00:18:10.840]   really.
[00:18:10.840 --> 00:18:14.360]   Snapchat is really good at not going away other than that.
[00:18:14.360 --> 00:18:15.400]   It's like, well, what is it?
[00:18:15.400 --> 00:18:18.480]   Every generation, it's like even, it's not even every generation.
[00:18:18.480 --> 00:18:24.360]   It's just every so often you're going to have this churn where it's like, oh, because no
[00:18:24.360 --> 00:18:29.160]   younger generation wants to use the social media platform that the older generations
[00:18:29.160 --> 00:18:30.160]   have used.
[00:18:30.160 --> 00:18:31.160]   They want their own thing.
[00:18:31.160 --> 00:18:32.160]   And I get that.
[00:18:32.160 --> 00:18:33.160]   I totally understand that.
[00:18:33.160 --> 00:18:34.160]   I respect it.
[00:18:34.160 --> 00:18:35.160]   Like, that's what it is.
[00:18:35.160 --> 00:18:36.840]   Gen X was big on my space.
[00:18:36.840 --> 00:18:41.560]   Like, then it was boomers with Facebook.
[00:18:41.560 --> 00:18:44.560]   Now they're like, but it wasn't that way at the beginning.
[00:18:44.560 --> 00:18:47.800]   And then it was like, oh, well, now we have MySpace, so like, buy and they left all the
[00:18:47.800 --> 00:18:49.400]   boomers on Facebook.
[00:18:49.400 --> 00:18:55.120]   Then it became, oh, well, here's Twitter, here's Snapchat, here's Instagram for a long
[00:18:55.120 --> 00:18:59.080]   time was like very before it got bought by Facebook.
[00:18:59.080 --> 00:19:04.600]   Like, they're just like every single kind of like group that comes up and starts using
[00:19:04.600 --> 00:19:05.600]   social media.
[00:19:05.600 --> 00:19:06.600]   They want their own thing.
[00:19:06.600 --> 00:19:07.600]   They want their own thing.
[00:19:07.600 --> 00:19:08.920]   They want to feel ownership of it.
[00:19:08.920 --> 00:19:13.120]   They want to feel like it's their community, their age group, their demo, because that's
[00:19:13.120 --> 00:19:14.280]   like, that's what they want.
[00:19:14.280 --> 00:19:17.360]   They want to interact with people who are like them.
[00:19:17.360 --> 00:19:20.680]   And so it's very hard.
[00:19:20.680 --> 00:19:26.200]   I am surprised most of these companies have survived as long as they have, just because,
[00:19:26.200 --> 00:19:30.160]   you know, I guess now it's like, if you look at the demographic use of each one of them,
[00:19:30.160 --> 00:19:33.480]   like, it skews heavily towards one column, right?
[00:19:33.480 --> 00:19:38.360]   And I think, you know, TikTok in particular is like, it's just exploding right now with
[00:19:38.360 --> 00:19:40.400]   users because that's where everyone is.
[00:19:40.400 --> 00:19:42.880]   And that's where all the trends and the memes are coming from.
[00:19:42.880 --> 00:19:44.520]   Like, that's the thing.
[00:19:44.520 --> 00:19:48.920]   Yeah, and the stuff is happening on TikTok is ending up on other platforms as well.
[00:19:48.920 --> 00:19:50.920]   It's like, just getting reposted, regurgitated.
[00:19:50.920 --> 00:19:51.920]   Yes.
[00:19:51.920 --> 00:19:56.040]   It's all, and people go, oh, well, why am I using this when I should just be over here?
[00:19:56.040 --> 00:19:57.040]   And then I could see it first.
[00:19:57.040 --> 00:19:58.040]   Yeah, be at the source.
[00:19:58.040 --> 00:19:59.040]   And everybody just starts migrating.
[00:19:59.040 --> 00:20:00.040]   Yeah.
[00:20:00.040 --> 00:20:01.040]   Instagram.
[00:20:01.040 --> 00:20:02.040]   So I can see what TikToks I haven't seen yet.
[00:20:02.040 --> 00:20:03.040]   Exactly.
[00:20:03.040 --> 00:20:04.840]   Oh, this one didn't show up in the algorithm.
[00:20:04.840 --> 00:20:06.920]   I'll go over to Instagram and watch it there.
[00:20:06.920 --> 00:20:07.920]   Yeah.
[00:20:07.920 --> 00:20:14.000]   When my kids borrow my phone because apparently they know my password, yeah, they're ending
[00:20:14.000 --> 00:20:19.080]   up on YouTube watching the TikToks that are there, you know, that's, and actually, yeah,
[00:20:19.080 --> 00:20:21.400]   and actually, so this was a surprise.
[00:20:21.400 --> 00:20:23.440]   Totally tying it with what we're talking about.
[00:20:23.440 --> 00:20:28.920]   I was away with my family on a swim meet, for a swim meet for my daughter.
[00:20:28.920 --> 00:20:32.040]   And while she was there, you know, she was with a couple of friends and she had my phone
[00:20:32.040 --> 00:20:33.040]   at one point.
[00:20:33.040 --> 00:20:37.120]   And then when I got my phone back, Snapchat was installed and some of her friends from
[00:20:37.120 --> 00:20:38.440]   the swim meet were friended.
[00:20:38.440 --> 00:20:45.400]   So apparently some people are using Snapchat and, you know, younger kids, apparently have
[00:20:45.400 --> 00:20:47.400]   Snapchat and use it regularly.
[00:20:47.400 --> 00:20:51.240]   So I think it's, it's what your friends have and it's what your parents don't want you
[00:20:51.240 --> 00:20:52.240]   have.
[00:20:52.240 --> 00:20:53.240]   Like Snapchat was the big thing.
[00:20:53.240 --> 00:20:55.400]   Nobody's parents because, oh, things just disappear.
[00:20:55.400 --> 00:20:58.840]   Like, which actually turns out to be pretty good for kids when things disappear.
[00:20:58.840 --> 00:20:59.840]   Totally.
[00:20:59.840 --> 00:21:00.840]   Totally.
[00:21:00.840 --> 00:21:01.840]   100%.
[00:21:01.840 --> 00:21:02.840]   Yeah.
[00:21:02.840 --> 00:21:06.680]   So I think, I mean, my kids use it and I will use it sometimes because they, you know,
[00:21:06.680 --> 00:21:10.440]   we all like, I like to see their bitmojis, especially when my daughter went to college
[00:21:10.440 --> 00:21:14.080]   so I could see like she was all the way in New York and, but that's really the only way
[00:21:14.080 --> 00:21:15.080]   that I used it.
[00:21:15.080 --> 00:21:20.240]   But all of these companies are dependent on advertising dollars and those are right now
[00:21:20.240 --> 00:21:21.240]   in the toilet.
[00:21:21.240 --> 00:21:24.280]   So like, that's the other thing that is affecting all of these.
[00:21:24.280 --> 00:21:29.280]   And if they were, if you already like, Snapchat lasted this long for whatever reason, but
[00:21:29.280 --> 00:21:34.560]   it might be like the change that Apple made with tracking like might be the final, you
[00:21:34.560 --> 00:21:38.160]   know, kick in the pants, tossing them off the edge because they can't, you know, they
[00:21:38.160 --> 00:21:42.080]   really can't make money right now because it's the, it's the changes to Apple.
[00:21:42.080 --> 00:21:43.240]   It's the war Ukraine.
[00:21:43.240 --> 00:21:46.880]   It's just the general like macro environment.
[00:21:46.880 --> 00:21:48.160]   You know, it's, it's all these things.
[00:21:48.160 --> 00:21:50.080]   And if you were already not doing that, great.
[00:21:50.080 --> 00:21:53.880]   Or, you know, if you were, if you were a Twitter where someone was like tweeting about
[00:21:53.880 --> 00:21:57.920]   how terrible you are platform was and also I'd like to buy it maybe.
[00:21:57.920 --> 00:22:01.920]   Um, then you're not.
[00:22:01.920 --> 00:22:03.280]   Hypothetically speaking.
[00:22:03.280 --> 00:22:04.700]   Hypothetically speaking.
[00:22:04.700 --> 00:22:05.700]   Yeah.
[00:22:05.700 --> 00:22:06.700]   Right.
[00:22:06.700 --> 00:22:07.700]   Yeah.
[00:22:07.700 --> 00:22:09.700]   So like that's what I think they're all suffering right now.
[00:22:09.700 --> 00:22:12.360]   Anyone dependent on advertising is suffering.
[00:22:12.360 --> 00:22:14.240]   Yeah, for sure.
[00:22:14.240 --> 00:22:18.400]   Um, there's two different directions we could go right now.
[00:22:18.400 --> 00:22:22.600]   Uh, so I'm going to go to boring one just real quick and then we, and then after that,
[00:22:22.600 --> 00:22:25.280]   I have to take a break and then we're going to talk about be real because you mentioned
[00:22:25.280 --> 00:22:26.280]   be real.
[00:22:26.280 --> 00:22:28.280]   I want to talk about that because I think it's super interesting.
[00:22:28.280 --> 00:22:31.360]   Before we go there, I think this ties in with what you're talking about Megan, which
[00:22:31.360 --> 00:22:38.760]   is this, uh, American data privacy and protection act that is, uh, basically a new draft, uh,
[00:22:38.760 --> 00:22:40.520]   going through Washington DC right now.
[00:22:40.520 --> 00:22:44.520]   If there was a, there was an original draft in June, many revisions since, and this is
[00:22:44.520 --> 00:22:47.160]   focusing on data minimizations.
[00:22:47.160 --> 00:22:49.520]   So it ties in this whole ad tracking thing.
[00:22:49.520 --> 00:22:54.600]   Like what is a, what does a future of big tech look like if the mechanisms that they're
[00:22:54.600 --> 00:22:59.240]   used to rely on in order to stay in business and do what they've done for so many years
[00:22:59.240 --> 00:23:01.440]   is the rules are completely changed.
[00:23:01.440 --> 00:23:08.200]   And apparently, uh, this, this draft spells out 17 permitted purposes for data collection
[00:23:08.200 --> 00:23:14.000]   and the use of the users, uh, things like authentication, things like fraud prevention,
[00:23:14.000 --> 00:23:16.840]   uh, transactional data, that sort of stuff.
[00:23:16.840 --> 00:23:20.520]   Anything outside of those 17 purposes would be prohibited.
[00:23:20.520 --> 00:23:25.720]   So in essence, you can't collect data that you don't actually need.
[00:23:25.720 --> 00:23:28.960]   And these are the categories that you might actually need data for and if they aren't
[00:23:28.960 --> 00:23:30.760]   those categories, then you can't.
[00:23:30.760 --> 00:23:35.720]   And I think it would be interesting if this is a bipartisan bill that you're, uh, that's,
[00:23:35.720 --> 00:23:37.200]   that's taking shape right now.
[00:23:37.200 --> 00:23:42.960]   And it happens the impacts that this has for, uh, the tech companies that really rely on
[00:23:42.960 --> 00:23:43.960]   this.
[00:23:43.960 --> 00:23:49.120]   One, one thing that it points out is a target advertising, targeted advertising.
[00:23:49.120 --> 00:23:54.760]   Um, and actually people who are really, you know, advocating for privacy, say this is kind
[00:23:54.760 --> 00:23:58.520]   of one of the disappointing parts of this bill, it would impose limits on this.
[00:23:58.520 --> 00:24:04.640]   Um, but only some, not all, like I think data privacy, like maximalists would say, get rid
[00:24:04.640 --> 00:24:07.200]   of, you know, targeted advertising entirely.
[00:24:07.200 --> 00:24:11.320]   And of course, like, like I'd be amazed if they actually went in that direction, but instead
[00:24:11.320 --> 00:24:13.120]   they're saying, no, you can't do this to minors.
[00:24:13.120 --> 00:24:18.120]   Uh, you can't have targeted advertising based on sensitive data, like health, uh, geolocation,
[00:24:18.120 --> 00:24:19.920]   private communication, that sort of stuff.
[00:24:19.920 --> 00:24:24.420]   Um, and no following people around on the internet tracking everything they do, like
[00:24:24.420 --> 00:24:29.120]   dropping, you know, some sort of tracking mechanism that then shows that when I go over
[00:24:29.120 --> 00:24:31.760]   to this side, I buy this thing and how it all ties into place.
[00:24:31.760 --> 00:24:37.120]   And I don't know, I'm curious to see how if this happens the way it's described, it's
[00:24:37.120 --> 00:24:41.520]   going to impact the business model of so many of these companies that are just making money
[00:24:41.520 --> 00:24:45.400]   hand over fist over fist, the way things have been.
[00:24:45.400 --> 00:24:53.880]   I mean, Facebook and Google have been just reaping the benefits of our lives for deck
[00:24:53.880 --> 00:24:54.880]   over a deck.
[00:24:54.880 --> 00:24:56.120]   Oh my God, so long.
[00:24:56.120 --> 00:24:57.120]   Yeah.
[00:24:57.120 --> 00:24:58.120]   Yeah.
[00:24:58.120 --> 00:25:03.600]   But yeah, and at some point somebody had to say, because, you know, privacy advocates
[00:25:03.600 --> 00:25:07.680]   and tech reporters and a lot of people have been saying, this is too much.
[00:25:07.680 --> 00:25:09.880]   You know too much about us.
[00:25:09.880 --> 00:25:15.240]   You don't get to know every single little bitty thing that's happening in my life because
[00:25:15.240 --> 00:25:19.160]   I searched for something that I thought was private and now you're using it to serve me
[00:25:19.160 --> 00:25:24.440]   ads because you think I'm pregnant or to serve me ads because you think I enjoy, you
[00:25:24.440 --> 00:25:28.640]   know, going to Thailand or that, you know, just weird little things that you're searching
[00:25:28.640 --> 00:25:31.960]   all the time or you're doing or where you're at.
[00:25:31.960 --> 00:25:32.960]   It's too much.
[00:25:32.960 --> 00:25:40.120]   And if you can bring that at least squelch it a bit, I think it helps for individuals.
[00:25:40.120 --> 00:25:41.120]   And it helps.
[00:25:41.120 --> 00:25:45.120]   I mean, the industry as a whole, they just need to figure it out.
[00:25:45.120 --> 00:25:46.440]   They're supposed to be smart people.
[00:25:46.440 --> 00:25:48.520]   If they can't figure it out, then I don't know what to tell them.
[00:25:48.520 --> 00:25:53.120]   That's the thing is they've been, you know, decades of how smart they are and how they're
[00:25:53.120 --> 00:25:54.120]   going to change the world.
[00:25:54.120 --> 00:25:57.360]   And anytime there's any little roadblock, they all freak out like, we don't know how
[00:25:57.360 --> 00:25:58.360]   this is going to work.
[00:25:58.360 --> 00:26:00.920]   I'm like, I thought you were, you were the smart ones.
[00:26:00.920 --> 00:26:02.960]   That's what you keep telling us at least.
[00:26:02.960 --> 00:26:03.960]   Figure it out.
[00:26:03.960 --> 00:26:08.560]   Tens of thousands of people in that department who's expressed job is to figure this out.
[00:26:08.560 --> 00:26:10.120]   So why, why aren't you?
[00:26:10.120 --> 00:26:11.120]   Yeah.
[00:26:11.120 --> 00:26:14.920]   You have billions of dollars and you're upset because Apple won't let people track people.
[00:26:14.920 --> 00:26:17.440]   So figure it out.
[00:26:17.440 --> 00:26:19.160]   You know, you have tens of billions of dollars.
[00:26:19.160 --> 00:26:20.520]   I don't know what to tell you.
[00:26:20.520 --> 00:26:24.920]   I don't feel bad for you and I don't feel bad for your horrible, horrible business practices.
[00:26:24.920 --> 00:26:25.920]   Hey, man.
[00:26:25.920 --> 00:26:26.920]   Hey for journalism.
[00:26:26.920 --> 00:26:27.920]   Yeah, paper journalism.
[00:26:27.920 --> 00:26:36.440]   We've been building everything on the backs of journalists, but we're not going to, but
[00:26:36.440 --> 00:26:40.400]   we've been stealing, you know, all the ad goes, all the ad dollars go to Facebook and
[00:26:40.400 --> 00:26:42.640]   Google because we keep someone gets on.
[00:26:42.640 --> 00:26:48.080]   Yeah, it sits on, you know, people sit on Facebook all day and that's what the ad advertisers
[00:26:48.080 --> 00:26:49.080]   want.
[00:26:49.080 --> 00:26:52.440]   They don't want the, oh, someone went to a site and they read an article for 30 seconds.
[00:26:52.440 --> 00:26:54.080]   They probably didn't see our ad.
[00:26:54.080 --> 00:26:58.080]   Meanwhile over on Facebook, someone was on this site for two hours and our ad was right
[00:26:58.080 --> 00:27:02.480]   there while they scrolled up and down and gotten a fight with their cousin about whoever
[00:27:02.480 --> 00:27:07.880]   was running for office in some small, like school district that no one knows anything
[00:27:07.880 --> 00:27:12.280]   about other than someone made a big fuss about their stupid, stupid ideas.
[00:27:12.280 --> 00:27:15.480]   Tell us how you really feel.
[00:27:15.480 --> 00:27:16.480]   Like it.
[00:27:16.480 --> 00:27:18.680]   Oh, man, don't even get me started on ad.
[00:27:18.680 --> 00:27:23.080]   I'm raining myself in for the dogs.
[00:27:23.080 --> 00:27:24.880]   I don't want to disturb the dogs.
[00:27:24.880 --> 00:27:25.880]   Yeah, I understand.
[00:27:25.880 --> 00:27:27.120]   It's all about the dogs.
[00:27:27.120 --> 00:27:28.120]   Get it.
[00:27:28.120 --> 00:27:30.320]   They get really upset when you talk about privacy law.
[00:27:30.320 --> 00:27:33.560]   They're like, why don't tell them about us.
[00:27:33.560 --> 00:27:34.560]   Don't give them our real name.
[00:27:34.560 --> 00:27:36.960]   I'm like, Oh, I've talked to my dogs.
[00:27:36.960 --> 00:27:40.400]   I'm a horrible dog.
[00:27:40.400 --> 00:27:42.400]   Don't do it.
[00:27:42.400 --> 00:27:44.400]   Don't do it.
[00:27:44.400 --> 00:27:45.400]   Don't do it.
[00:27:45.400 --> 00:27:46.400]   Don't do it.
[00:27:46.400 --> 00:27:51.240]   All right, let's, uh, let's take a break and we'll thank the sponsor of this episode
[00:27:51.240 --> 00:27:52.840]   of this week in tech.
[00:27:52.840 --> 00:27:56.400]   And then when we come back, let's talk a little bit about be real because I've been
[00:27:56.400 --> 00:28:01.320]   using it lately and I'm curious to know all of your thoughts on it and we'll dive into
[00:28:01.320 --> 00:28:02.320]   that.
[00:28:02.320 --> 00:28:06.400]   But first, this episode of this week in tech is brought to you by zipper cruder.
[00:28:06.400 --> 00:28:09.000]   Different people just make life so much easier.
[00:28:09.000 --> 00:28:10.000]   Wouldn't you agree?
[00:28:10.000 --> 00:28:13.080]   You don't know what you would do without them, right?
[00:28:13.080 --> 00:28:14.080]   Maybe it's your partner.
[00:28:14.080 --> 00:28:16.000]   Maybe it's your friend.
[00:28:16.000 --> 00:28:17.480]   Maybe it's your personal assistant.
[00:28:17.480 --> 00:28:19.280]   They all make your life so much easier.
[00:28:19.280 --> 00:28:21.520]   It's nice to have someone on your side, right?
[00:28:21.520 --> 00:28:26.720]   It's like if you need to grow your business, zipper cruder is there making hiring so much
[00:28:26.720 --> 00:28:29.360]   easier because they actually do the work for you.
[00:28:29.360 --> 00:28:31.000]   So they're kind of your friend in hiring.
[00:28:31.000 --> 00:28:32.440]   Think of them that way.
[00:28:32.440 --> 00:28:37.200]   And now you can try it for free at zippercruder.com/twit.
[00:28:37.200 --> 00:28:41.760]   Zipper cruder's technology actually finds the right candidates for your job.
[00:28:41.760 --> 00:28:46.840]   And then you can invite your top choices to apply and four out of five employers who
[00:28:46.840 --> 00:28:50.200]   post on zipper cruder actually amazing success.
[00:28:50.200 --> 00:28:53.840]   They get a quality candidate within the first day.
[00:28:53.840 --> 00:28:56.880]   Talk about not having to wait around for those results, right?
[00:28:56.880 --> 00:29:00.400]   No wonder zipper cruder is the number one rated hiring site.
[00:29:00.400 --> 00:29:04.640]   It's based on G2 ratings as of January 1st, 2022.
[00:29:04.640 --> 00:29:05.640]   ZipRecruiter is awesome.
[00:29:05.640 --> 00:29:09.440]   We've used zipper cruder for twit for hiring.
[00:29:09.440 --> 00:29:11.200]   And I mean, we're not alone.
[00:29:11.200 --> 00:29:12.560]   Everybody knows zipper cruder.
[00:29:12.560 --> 00:29:13.640]   You got to check it out yourself.
[00:29:13.640 --> 00:29:20.360]   The hardest thing you have to do is to remember our special URL to try zipper cruder for free.
[00:29:20.360 --> 00:29:22.560]   And that is ziprecruiter.com/twit.
[00:29:22.560 --> 00:29:24.120]   Again, that's zippercruder.com/twit.
[00:29:24.120 --> 00:29:29.400]   Again, that's zippercruder.com/twit.
[00:29:29.400 --> 00:29:30.400]   Check it out.
[00:29:30.400 --> 00:29:33.720]   You're going to be really happy at the time that it saves you to find qualified candidate
[00:29:33.720 --> 00:29:34.720]   for your position.
[00:29:34.720 --> 00:29:35.720]   That's zippercruder.com/twit.
[00:29:35.720 --> 00:29:40.560]   We thank the zipper cruder for their support of this weekend tech.
[00:29:40.560 --> 00:29:42.000]   All right.
[00:29:42.000 --> 00:29:45.360]   So yeah, so be real.
[00:29:45.360 --> 00:29:48.800]   Are we all using be real at this point?
[00:29:48.800 --> 00:29:52.680]   I guess show of audible hands as well as raising hands.
[00:29:52.680 --> 00:29:55.920]   But I've been on be real for probably now like a month and a half.
[00:29:55.920 --> 00:29:57.080]   And I'm really enjoying it.
[00:29:57.080 --> 00:29:58.080]   What about you all?
[00:29:58.080 --> 00:30:01.000]   Megan, I know you're on be real.
[00:30:01.000 --> 00:30:03.400]   Yeah, you're on be real.
[00:30:03.400 --> 00:30:04.400]   I am.
[00:30:04.400 --> 00:30:05.800]   Yeah, we should be be real friends.
[00:30:05.800 --> 00:30:11.520]   I have I started being on be real through my daughter, who she was like, you have to
[00:30:11.520 --> 00:30:12.520]   get on this.
[00:30:12.520 --> 00:30:13.520]   This was I don't know.
[00:30:13.520 --> 00:30:16.200]   It was like right when she like last summer.
[00:30:16.200 --> 00:30:17.480]   I don't remember when it was.
[00:30:17.480 --> 00:30:22.200]   And then then it was just my kids for a really long time.
[00:30:22.200 --> 00:30:27.920]   And then it became now it's my kids, several of their friends who requested me.
[00:30:27.920 --> 00:30:31.320]   And so I felt like that was fair to accept their request.
[00:30:31.320 --> 00:30:39.600]   And then four former coworkers, Jason, Tom Merritt, Mike Elgin and Willa Remus from Washington
[00:30:39.600 --> 00:30:40.600]   Post.
[00:30:40.600 --> 00:30:44.920]   So it's like four guy tech journalists and a bunch of 17 and 19 year olds.
[00:30:44.920 --> 00:30:46.920]   That's why I follow.
[00:30:46.920 --> 00:30:52.280]   Yeah, I've noticed in my in my short amount of time with Be Real that it is not about
[00:30:52.280 --> 00:30:55.680]   amassing like collecting friends, you know what I mean?
[00:30:55.680 --> 00:30:59.160]   Like a lot of services like when I started Facebook, it was all about like, I don't I
[00:30:59.160 --> 00:31:00.800]   knew you for for two minutes.
[00:31:00.800 --> 00:31:01.800]   Sure.
[00:31:01.800 --> 00:31:02.800]   You're my friend.
[00:31:02.800 --> 00:31:06.240]   And it was about getting that number high, you know, high as high as possible back in
[00:31:06.240 --> 00:31:08.400]   you know, 2008 or whatever it was.
[00:31:08.400 --> 00:31:12.600]   Be real seems to be a lot more a lot more controlled, I suppose.
[00:31:12.600 --> 00:31:14.400]   What about you, Ashley, Roberto?
[00:31:14.400 --> 00:31:15.880]   Have you used this at all?
[00:31:15.880 --> 00:31:17.680]   Yeah, I love it.
[00:31:17.680 --> 00:31:22.640]   I just like the idea of it, which is that for those of you who like have not used to be
[00:31:22.640 --> 00:31:23.920]   real if you're listening to this.
[00:31:23.920 --> 00:31:31.560]   So it's an app that is, I would say it could like Jason, it's a controlled social media.
[00:31:31.560 --> 00:31:37.400]   So it's not just posting publicly whenever you feel like it.
[00:31:37.400 --> 00:31:39.080]   You know, you got it.
[00:31:39.080 --> 00:31:43.560]   Basically the app flags you and says you got two minutes to post.
[00:31:43.560 --> 00:31:44.640]   Like this is the time.
[00:31:44.640 --> 00:31:49.760]   You get a two, everybody gets the same two minute window to take a picture of what you're
[00:31:49.760 --> 00:31:52.280]   currently doing, which is why it's called be real.
[00:31:52.280 --> 00:31:57.400]   It's just like no filters, no, there's nothing, no AR, nothing like that.
[00:31:57.400 --> 00:31:59.480]   Just very straightforward.
[00:31:59.480 --> 00:32:03.000]   Takes a picture with your front facing camera and your rear facing camera.
[00:32:03.000 --> 00:32:05.960]   And that's what gets posted to your profile.
[00:32:05.960 --> 00:32:07.720]   And there are rules that it has.
[00:32:07.720 --> 00:32:14.200]   So if you post late, other people will not, you won't be able to see other people's photos.
[00:32:14.200 --> 00:32:16.680]   They're pictures for the day.
[00:32:16.680 --> 00:32:24.480]   If you delete, if you want to delete a be real, you can only delete a picture and you're not
[00:32:24.480 --> 00:32:27.040]   allowed to delete the next day's picture.
[00:32:27.040 --> 00:32:28.760]   Like the next one that you post.
[00:32:28.760 --> 00:32:30.040]   They won't let you delete it.
[00:32:30.040 --> 00:32:34.160]   Like it'll say you can't, so we'll let you delete this one, but you can't delete the
[00:32:34.160 --> 00:32:35.160]   next one.
[00:32:35.160 --> 00:32:36.520]   Like so whatever that is.
[00:32:36.520 --> 00:32:42.080]   And it says, and there are things where you can say there was a bug or I can't see anything
[00:32:42.080 --> 00:32:43.720]   or what have you.
[00:32:43.720 --> 00:32:55.360]   But it's really interesting that, so it feels like be real is the antithesis of what most
[00:32:55.360 --> 00:32:59.000]   people think social media is for at this point.
[00:32:59.000 --> 00:33:05.920]   Which I think is what is so appealing about it to a lot of Gen Z kids.
[00:33:05.920 --> 00:33:06.920]   I read it.
[00:33:06.920 --> 00:33:10.880]   This is like a weird kind of, I promise I'm coming back to be real at this point.
[00:33:10.880 --> 00:33:15.560]   I read a really interesting ask Reddit the other day and someone said, I just don't understand
[00:33:15.560 --> 00:33:17.400]   Gen Z humor.
[00:33:17.400 --> 00:33:23.320]   Here's some examples and they listed some examples and it's like Gen X humor is like
[00:33:23.320 --> 00:33:27.160]   very kind of South Parky, sort of nihilistic.
[00:33:27.160 --> 00:33:32.160]   Then you get into millennial stuff where it's like this existential crisis humor.
[00:33:32.160 --> 00:33:35.760]   And then you get into Gen Z and it's just like, it's insane.
[00:33:35.760 --> 00:33:38.080]   You don't know what it even is half the time.
[00:33:38.080 --> 00:33:41.880]   And everybody's just kind of like weirdly in on a joke because it's just a vibe.
[00:33:41.880 --> 00:33:43.440]   Like the memes are vibes.
[00:33:43.440 --> 00:33:47.760]   Like they're not really, they're not at all like they don't make sense a lot of the time
[00:33:47.760 --> 00:33:48.760]   but it's a vibe.
[00:33:48.760 --> 00:33:51.680]   And like I get it, I understand that and that's cool.
[00:33:51.680 --> 00:33:53.480]   Like I love it.
[00:33:53.480 --> 00:34:00.120]   But someone had responded to that ask Reddit and they said, it's really interesting because
[00:34:00.120 --> 00:34:07.200]   Gen Z's meme humor specifically is it moves so quickly.
[00:34:07.200 --> 00:34:14.480]   Their version of the internet moves so fast and evolves so quickly that a millennial or
[00:34:14.480 --> 00:34:20.760]   a Gen X or a boomer or whatever would have you might post something and that meme could
[00:34:20.760 --> 00:34:23.640]   live for weeks or months.
[00:34:23.640 --> 00:34:26.640]   And in the early times of the internet, a meme would live for a year.
[00:34:26.640 --> 00:34:29.520]   Like it's just like, we all are familiar with the meme.
[00:34:29.520 --> 00:34:31.480]   I can has cheeseburger.
[00:34:31.480 --> 00:34:34.120]   Like that is an iconic long time meme.
[00:34:34.120 --> 00:34:39.960]   That doesn't exist for Gen Z. It's just like, you're living in the moment from moment to
[00:34:39.960 --> 00:34:47.040]   moment meme to meme and it gets remixed and regurgitated and redone and just transformed
[00:34:47.040 --> 00:34:52.120]   so many times in the span of 24 hours that it just becomes chaos.
[00:34:52.120 --> 00:34:53.760]   Like it's chaotic.
[00:34:53.760 --> 00:34:54.960]   But it's a vibe.
[00:34:54.960 --> 00:34:57.800]   Again, it's funny because it's a vibe.
[00:34:57.800 --> 00:35:03.680]   And so I thought that was so fascinating and be real to me seems like it is working
[00:35:03.680 --> 00:35:05.720]   very hard against that.
[00:35:05.720 --> 00:35:09.320]   And it's just like, no, this is just like show people what you're doing right in this moment.
[00:35:09.320 --> 00:35:11.400]   It's the same to everybody shares the same two minutes.
[00:35:11.400 --> 00:35:16.520]   So it's really a little snapshot of like what's going on in time right now at your phone.
[00:35:16.520 --> 00:35:17.520]   There you go.
[00:35:17.520 --> 00:35:18.520]   That's it.
[00:35:18.520 --> 00:35:23.080]   It's like very simple, very straightforward and it has, it's got bumpers on it, right?
[00:35:23.080 --> 00:35:27.880]   It's got guardrails on it to keep you from gaming the system the way so many other social
[00:35:27.880 --> 00:35:33.640]   media platforms have been gamed by both influencers, advertisers, everything in between.
[00:35:33.640 --> 00:35:35.680]   It's just super fascinating.
[00:35:35.680 --> 00:35:38.520]   I find be real like the so, so, so fascinating.
[00:35:38.520 --> 00:35:40.600]   It's very interesting to me.
[00:35:40.600 --> 00:35:45.640]   It gives me flashbacks to early Twitter, to be honest.
[00:35:45.640 --> 00:35:46.640]   Like early early Twitter.
[00:35:46.640 --> 00:35:47.640]   Yeah.
[00:35:47.640 --> 00:35:51.240]   I just, just in the sense that when, when Twitter first came out, it was kind of like,
[00:35:51.240 --> 00:35:52.640]   what do we even use this for?
[00:35:52.640 --> 00:35:54.760]   You mean we're just supposed to share what we're doing right now?
[00:35:54.760 --> 00:35:56.080]   I guess I'm eating a sandwich.
[00:35:56.080 --> 00:35:58.960]   Well, does anyone really want to know that I'm eating a sandwich?
[00:35:58.960 --> 00:36:00.200]   Half the time would be real.
[00:36:00.200 --> 00:36:03.600]   What you end up getting or at least what I end up getting in my feed is people.
[00:36:03.600 --> 00:36:05.600]   Sitting in front of their computers, right?
[00:36:05.600 --> 00:36:09.880]   They end up seeing like a screen with whatever they're working on, then a shot of them sitting
[00:36:09.880 --> 00:36:12.040]   at their computer, which isn't the most exciting thing.
[00:36:12.040 --> 00:36:16.120]   I realize, hey, join the social network where all you see is what people are, you know,
[00:36:16.120 --> 00:36:19.240]   that they're working at their computers just like you.
[00:36:19.240 --> 00:36:24.720]   But I think what's interesting or appealing to me about it is that because of the guardrails
[00:36:24.720 --> 00:36:29.960]   that you were talking about, Ashley, because of kind of the rules of play, so to speak,
[00:36:29.960 --> 00:36:35.800]   find this idea that you can't, like there's no easy way for you to go all Instagram and
[00:36:35.800 --> 00:36:40.200]   show your luxurious yacht because you just happen to be standing in front of one with
[00:36:40.200 --> 00:36:42.200]   the two minutes that it happens or whatever.
[00:36:42.200 --> 00:36:46.920]   There's no painting your life to be anything, hopefully, other than what it actually is.
[00:36:46.920 --> 00:36:52.680]   And it's kind of the blandness of life ends up being the appealing factor of be real for
[00:36:52.680 --> 00:36:53.680]   me.
[00:36:53.680 --> 00:36:57.280]   It's kind of like confirmation that like, oh yeah, my life can be pretty boring too.
[00:36:57.280 --> 00:36:58.280]   Nice.
[00:36:58.280 --> 00:37:01.840]   You're not always seeing just the really great stuff that someone's doing.
[00:37:01.840 --> 00:37:03.840]   You're seeing kind of the boring stuff that they're doing.
[00:37:03.840 --> 00:37:07.640]   And that's cool too, because that's what being a human is all about.
[00:37:07.640 --> 00:37:12.080]   So there's a very funny tweet about it that says, I can't believe we're all so fake.
[00:37:12.080 --> 00:37:14.320]   This is from Connor, Connor, Franta.
[00:37:14.320 --> 00:37:16.160]   He says, I can't believe we're also fake.
[00:37:16.160 --> 00:37:19.080]   They're now making social media apps that force us to be ourselves.
[00:37:19.080 --> 00:37:20.080]   That's hilarious.
[00:37:20.080 --> 00:37:21.080]   It's like, yeah.
[00:37:21.080 --> 00:37:24.080]   Yeah, that's a pretty spot on Roberto.
[00:37:24.080 --> 00:37:26.640]   What were you going to say?
[00:37:26.640 --> 00:37:31.680]   I just like that there's now a social media that'll just chronicle late stage capitalism
[00:37:31.680 --> 00:37:35.040]   of just sitting in front of our computers with the existential dread in our eyes.
[00:37:35.040 --> 00:37:37.960]   How are things going?
[00:37:37.960 --> 00:37:42.680]   Well, you know, staring at this box again.
[00:37:42.680 --> 00:37:45.960]   I also just literally signed up for it like two seconds ago.
[00:37:45.960 --> 00:37:48.240]   I'm like, yeah, that sounds fine, whatever.
[00:37:48.240 --> 00:37:50.480]   I need a fifth tech reporter guy.
[00:37:50.480 --> 00:37:52.880]   So yeah, it's the same name.
[00:37:52.880 --> 00:37:57.400]   The RNGWIS, go ahead.
[00:37:57.400 --> 00:37:58.400]   Okay.
[00:37:58.400 --> 00:38:00.600]   So the fatal flaw would be real.
[00:38:00.600 --> 00:38:02.720]   And I don't know why they didn't think of this.
[00:38:02.720 --> 00:38:07.680]   It seems quite obvious is that the app is terrible.
[00:38:07.680 --> 00:38:09.960]   And some people think that's like very unique.
[00:38:09.960 --> 00:38:16.720]   But the reason why it almost never works because everyone is using it at the exact same time.
[00:38:16.720 --> 00:38:18.720]   And like that is inherent in what you do.
[00:38:18.720 --> 00:38:21.120]   Like everybody opens it up and takes the picture.
[00:38:21.120 --> 00:38:26.400]   And then so it's like, well, didn't you know that like as you scaled, as you got more users?
[00:38:26.400 --> 00:38:27.400]   Oh boy.
[00:38:27.400 --> 00:38:28.400]   Yeah, good.
[00:38:28.400 --> 00:38:30.680]   So the data spike is very bad.
[00:38:30.680 --> 00:38:34.000]   So it starts at the same time every day.
[00:38:34.000 --> 00:38:36.760]   Everybody gets same time for everyone.
[00:38:36.760 --> 00:38:43.560]   But you can change your time zone like to European time zone or like US time zone, but
[00:38:43.560 --> 00:38:45.720]   not like you at little US time zones.
[00:38:45.720 --> 00:38:48.760]   But you can be on a different time zone, but it's basically the same time every day.
[00:38:48.760 --> 00:38:54.880]   And what has happened is like I've been using it as like, I don't really do it every, you
[00:38:54.880 --> 00:38:57.840]   know, every time like, but you can do it at any time in the day.
[00:38:57.840 --> 00:38:59.400]   It just shows that you've done it late.
[00:38:59.400 --> 00:39:01.120]   And then after you do it, you can see everyone's photos.
[00:39:01.120 --> 00:39:04.760]   So like I haven't done mine today and I'm definitely going to do it of you four to have
[00:39:04.760 --> 00:39:08.920]   like a very meta be real situation when you least expect it.
[00:39:08.920 --> 00:39:09.920]   But that's the thing.
[00:39:09.920 --> 00:39:11.600]   It's like it doesn't really.
[00:39:11.600 --> 00:39:15.960]   But I do still love it for all the reasons that we've discussed.
[00:39:15.960 --> 00:39:19.400]   The other thing that I don't know if you know this is that you can take, you can retake
[00:39:19.400 --> 00:39:22.680]   the picture if you don't like what you look like, but it will notify.
[00:39:22.680 --> 00:39:25.560]   It doesn't notify, but you can see, can look at people's be real.
[00:39:25.560 --> 00:39:31.320]   And like if, you know, if I see that Jason had like this lovely picture of his steel cut
[00:39:31.320 --> 00:39:36.280]   oats and blueberries and his smiling morning face, I can see like how many times did he
[00:39:36.280 --> 00:39:37.280]   take that picture.
[00:39:37.280 --> 00:39:42.760]   So it'll say like that you like took it, you know, until you had the exact right angle.
[00:39:42.760 --> 00:39:46.240]   So I didn't know that it had that feature.
[00:39:46.240 --> 00:39:47.240]   Oh, yeah.
[00:39:47.240 --> 00:39:50.240]   I know you took that shot five times with my own.
[00:39:50.240 --> 00:39:52.480]   It is a screenshot too.
[00:39:52.480 --> 00:39:55.720]   If you screenshot, it'll not say this is a screenshot.
[00:39:55.720 --> 00:39:56.720]   Yeah.
[00:39:56.720 --> 00:39:57.720]   It's a snitch.
[00:39:57.720 --> 00:39:58.720]   Yeah.
[00:39:58.720 --> 00:39:59.720]   I travel like a Europe.
[00:39:59.720 --> 00:40:07.440]   So is it so is it based on the phone's time zone or is the app have its own time zone
[00:40:07.440 --> 00:40:08.640]   from where you set it up?
[00:40:08.640 --> 00:40:10.960]   Because I travel to Europe a lot.
[00:40:10.960 --> 00:40:15.360]   And so will it will it correct as I get over there?
[00:40:15.360 --> 00:40:17.360]   I think it's only I think.
[00:40:17.360 --> 00:40:18.360]   Yeah.
[00:40:18.360 --> 00:40:21.760]   Yeah, I think it's we'll find out and I'm going to be real right now.
[00:40:21.760 --> 00:40:22.760]   Okay.
[00:40:22.760 --> 00:40:23.760]   Oh, yeah.
[00:40:23.760 --> 00:40:24.760]   Be real.
[00:40:24.760 --> 00:40:30.080]   I'm just going to look dead inside.
[00:40:30.080 --> 00:40:31.880]   Something like be real though.
[00:40:31.880 --> 00:40:36.520]   It's hard to see at this stage like like it's it's got activity.
[00:40:36.520 --> 00:40:43.120]   It's got movement obviously the younger generation users a lot a lot of like kids using it.
[00:40:43.120 --> 00:40:44.720]   I don't want to call them kids.
[00:40:44.720 --> 00:40:46.480]   A lot of younger people using them.
[00:40:46.480 --> 00:40:48.680]   This is what happens when you get your mid 40s.
[00:40:48.680 --> 00:40:49.680]   Kids.
[00:40:49.680 --> 00:40:50.680]   I start calling the kids.
[00:40:50.680 --> 00:40:52.880]   I know I get off my lawn for kids.
[00:40:52.880 --> 00:40:55.320]   But there's a lot of movement right now.
[00:40:55.320 --> 00:40:59.680]   Part of me wonders if an app like be real has a short lifespan, right?
[00:40:59.680 --> 00:41:02.400]   Like that is interesting right right now.
[00:41:02.400 --> 00:41:05.600]   But like what does it have the ability to grow into over time?
[00:41:05.600 --> 00:41:10.960]   It's kind of built around these really like like we were talking about these these hard
[00:41:10.960 --> 00:41:12.560]   and fast rules.
[00:41:12.560 --> 00:41:14.560]   Like these companies.
[00:41:14.560 --> 00:41:17.840]   I predict Facebook ultimately want to broaden out and become something more.
[00:41:17.840 --> 00:41:19.600]   How do you do that when you've got these rules?
[00:41:19.600 --> 00:41:21.040]   Facebook will just copy this.
[00:41:21.040 --> 00:41:25.840]   It'll just be a feature of copies where it's like it'll be like a check in feature, but
[00:41:25.840 --> 00:41:31.480]   it'll just be like, Hey, like here's this fun little, you know, sub menu on Instagram
[00:41:31.480 --> 00:41:34.320]   reels or whatever or on Instagram where you can just choose it.
[00:41:34.320 --> 00:41:37.960]   And then it's like, Oh, if you'd like to be notified every day to just like snap a picture,
[00:41:37.960 --> 00:41:40.360]   we'll take one of the front and back of your camera or whatever.
[00:41:40.360 --> 00:41:41.360]   They'll just copy it.
[00:41:41.360 --> 00:41:42.360]   Yeah.
[00:41:42.360 --> 00:41:43.360]   You're right.
[00:41:43.360 --> 00:41:44.360]   That's what that's what usually happens.
[00:41:44.360 --> 00:41:45.720]   You think the front back.
[00:41:45.720 --> 00:41:47.720]   People are angry.
[00:41:47.720 --> 00:41:48.720]   Remember front back?
[00:41:48.720 --> 00:41:50.720]   The app that took a picture of the front and the back.
[00:41:50.720 --> 00:41:51.720]   Remember them?
[00:41:51.720 --> 00:41:52.720]   You think they're like, Oh, come on.
[00:41:52.720 --> 00:41:53.720]   Pressing piece from back.
[00:41:53.720 --> 00:41:54.720]   Poor one out for front back.
[00:41:54.720 --> 00:41:56.720]   Or went out or path or.
[00:41:56.720 --> 00:41:57.720]   All right.
[00:41:57.720 --> 00:41:58.720]   P.
[00:41:58.720 --> 00:41:59.720]   Path.
[00:41:59.720 --> 00:42:00.720]   Yeah.
[00:42:00.720 --> 00:42:01.720]   Yeah.
[00:42:01.720 --> 00:42:02.720]   Oh, I forgot about peach.
[00:42:02.720 --> 00:42:03.720]   Yeah.
[00:42:03.720 --> 00:42:04.720]   I have.
[00:42:04.720 --> 00:42:05.720]   Yeah.
[00:42:05.720 --> 00:42:06.720]   I just signed up for all these things.
[00:42:06.720 --> 00:42:11.560]   So I keep my screen name and I was like, but I'm on be real now.
[00:42:11.560 --> 00:42:12.560]   This is the one that's going to stick.
[00:42:12.560 --> 00:42:13.560]   Yeah.
[00:42:13.560 --> 00:42:17.440]   This is the one you're ready to stick around for at least six months.
[00:42:17.440 --> 00:42:19.200]   I wrote the next Facebook.
[00:42:19.200 --> 00:42:20.440]   You just wait and see.
[00:42:20.440 --> 00:42:22.880]   Megan's daughter told her about it a year ago.
[00:42:22.880 --> 00:42:23.880]   So it's been around.
[00:42:23.880 --> 00:42:24.880]   Yeah, exactly.
[00:42:24.880 --> 00:42:25.880]   It's been chilling.
[00:42:25.880 --> 00:42:26.880]   Yeah.
[00:42:26.880 --> 00:42:30.040]   And imagine the data that they can collect.
[00:42:30.040 --> 00:42:31.040]   That's the other thing.
[00:42:31.040 --> 00:42:35.600]   It's like, if it really is us just doing our regular normal things, you know, because
[00:42:35.600 --> 00:42:40.160]   if you were like, if you're constantly posting on Instagram about like the one time you
[00:42:40.160 --> 00:42:44.760]   got to, you saved enough money to go to Hawaii for the year for me, like you're not, like
[00:42:44.760 --> 00:42:46.920]   that's not going to be that targeted advertising, right?
[00:42:46.920 --> 00:42:50.800]   But if it's like everything you're doing on a normal day, everything that's in your
[00:42:50.800 --> 00:42:56.000]   background, like, I mean, obviously they have a privacy policy in place and they're not
[00:42:56.000 --> 00:42:58.480]   like grabbing all that stuff yet.
[00:42:58.480 --> 00:43:03.320]   But it is a pretty interesting trove of data, just like what you're actually doing in your
[00:43:03.320 --> 00:43:04.320]   regular life.
[00:43:04.320 --> 00:43:05.320]   Mm hmm.
[00:43:05.320 --> 00:43:07.720]   Uh, got to go there.
[00:43:07.720 --> 00:43:11.960]   See, I was just mindlessly posting what I, what I'm doing at a random time.
[00:43:11.960 --> 00:43:16.000]   And now I got to think about exactly how all that image right stuff is being analyzed.
[00:43:16.000 --> 00:43:17.000]   Yeah.
[00:43:17.000 --> 00:43:18.840]   Are you getting a lot of ads for steel cut?
[00:43:18.840 --> 00:43:19.840]   Yes.
[00:43:19.840 --> 00:43:20.840]   Yes.
[00:43:20.840 --> 00:43:21.840]   Yes.
[00:43:21.840 --> 00:43:22.840]   I am.
[00:43:22.840 --> 00:43:25.440]   No, I don't, yeah, and I don't even think there's like, there's not even any ads in the app at
[00:43:25.440 --> 00:43:26.440]   this point.
[00:43:26.440 --> 00:43:27.440]   So that's not.
[00:43:27.440 --> 00:43:29.440]   So, yeah, cool companies will use it to sell the antidepressants.
[00:43:29.440 --> 00:43:31.480]   Everyone's just like, oh God, we know.
[00:43:31.480 --> 00:43:33.520]   Everyone's just like sad or at their desk.
[00:43:33.520 --> 00:43:34.680]   The privacy, yeah.
[00:43:34.680 --> 00:43:37.880]   Let's get those people some pros back.
[00:43:37.880 --> 00:43:38.880]   Who knows?
[00:43:38.880 --> 00:43:42.960]   Maybe Amazon will buy be real and then, uh, everything.
[00:43:42.960 --> 00:43:44.680]   Yeah, they buy everything.
[00:43:44.680 --> 00:43:51.280]   In fact, apparently Amazon is getting further and further into the, it's, it's ambitions
[00:43:51.280 --> 00:43:55.360]   of kind of revitalizing the, uh, the health industry.
[00:43:55.360 --> 00:43:59.920]   They announced, uh, it's intent to buy one medical, which is a San Francisco chain of
[00:43:59.920 --> 00:44:02.520]   primary healthcare clinics.
[00:44:02.520 --> 00:44:08.040]   Um, although one medical from what I understand, I wasn't super familiar with this before kind
[00:44:08.040 --> 00:44:10.440]   of hearing about this news and reading up a little bit about it.
[00:44:10.440 --> 00:44:12.320]   Uh, it's like technologically powered.
[00:44:12.320 --> 00:44:14.560]   So it's not just like primary healthcare clinics.
[00:44:14.560 --> 00:44:18.480]   It's, it's got a technical or technological kind of backbone to it.
[00:44:18.480 --> 00:44:23.560]   Uh, kind of like a self service sort of approach to primary care and telehealth.
[00:44:23.560 --> 00:44:24.760]   Is this like forward?
[00:44:24.760 --> 00:44:28.680]   There's like a series of, there's like a chain of medical offices that they, they have like
[00:44:28.680 --> 00:44:31.880]   very high tech sort of experience when you go in.
[00:44:31.880 --> 00:44:35.280]   Um, I would, I think it, I think it's similar to this.
[00:44:35.280 --> 00:44:42.240]   It's like, um, there's a real heavy focus on like, oh, you know, forward, I guess forward
[00:44:42.240 --> 00:44:44.960]   trajectory technology and like medicine.
[00:44:44.960 --> 00:44:45.960]   Okay.
[00:44:45.960 --> 00:44:46.960]   Yeah.
[00:44:46.960 --> 00:44:48.960]   So it's like a digital services.
[00:44:48.960 --> 00:44:49.960]   Right.
[00:44:49.960 --> 00:44:55.040]   Um, one medical was like aimed at, um, probably like millennials and people like, so it was
[00:44:55.040 --> 00:44:57.240]   an addition to health insurance.
[00:44:57.240 --> 00:45:01.600]   So when I worked at medium, um, we had, this is a benefit, like it was an extra benefit.
[00:45:01.600 --> 00:45:04.680]   Um, in addition to medical insurance, it was just easier and faster.
[00:45:04.680 --> 00:45:08.880]   They got in a little bit of trouble because I think like right when vaccines came out,
[00:45:08.880 --> 00:45:13.080]   they like sort of offered to have people who had one medical skip the line.
[00:45:13.080 --> 00:45:14.080]   Oh, yeah.
[00:45:14.080 --> 00:45:15.080]   Um, like, and so.
[00:45:15.080 --> 00:45:18.680]   Yeah, they're, um, yeah.
[00:45:18.680 --> 00:45:22.480]   So it's like they're, they're just like a disruptor, you know, like, um, you know, Uber
[00:45:22.480 --> 00:45:25.400]   and taxis or Airbnb and hotels.
[00:45:25.400 --> 00:45:26.400]   That's their thing.
[00:45:26.400 --> 00:45:27.400]   Like, right.
[00:45:27.400 --> 00:45:28.400]   Right.
[00:45:28.400 --> 00:45:29.400]   Right.
[00:45:29.400 --> 00:45:34.920]   So Amazon's $3.9 billion all cash deal, uh, to acquire.
[00:45:34.920 --> 00:45:39.120]   And of course everyone jumps to, you know, the obvious place, which is, okay, do we trust
[00:45:39.120 --> 00:45:45.080]   Amazon to be that hands on with, uh, with our medical information?
[00:45:45.080 --> 00:45:48.920]   If you happen to be with, you know, one medical, saw a lot of, saw a lot of people online
[00:45:48.920 --> 00:45:50.840]   who were like, oh, seriously, like I'm out.
[00:45:50.840 --> 00:45:54.600]   If, if Amazon's in, I'm out, I'm not comfortable with that.
[00:45:54.600 --> 00:46:01.000]   Um, so yeah, I mean, that's, that's, I mean, undeniably that's an easy place to go.
[00:46:01.000 --> 00:46:05.280]   Amazon, this isn't Amazon's only foray into this as either, you know, they bought pill
[00:46:05.280 --> 00:46:07.640]   pack however many years ago.
[00:46:07.640 --> 00:46:12.840]   And that's the kind of like the automated kind of mail order, uh, pill delivery service
[00:46:12.840 --> 00:46:13.960]   for medication.
[00:46:13.960 --> 00:46:17.960]   Of course, Whole Foods, which, you know, isn't healthcare, but it is healthy living.
[00:46:17.960 --> 00:46:22.120]   So Amazon kind of has this whole thing going on right now, but does this concern any of
[00:46:22.120 --> 00:46:28.680]   you as far as Amazon being the puppet master in control of this healthcare, uh, wing, so
[00:46:28.680 --> 00:46:29.680]   to speak?
[00:46:29.680 --> 00:46:32.240]   I mean, obviously going to use your company.
[00:46:32.240 --> 00:46:33.240]   Yeah.
[00:46:33.240 --> 00:46:35.000]   Anytime any company says like, we're not going to do that.
[00:46:35.000 --> 00:46:36.000]   And then they do that.
[00:46:36.000 --> 00:46:37.000]   And they do.
[00:46:37.000 --> 00:46:42.220]   Oh, and then they get sort of slapped by the government and they get like a $30,000 fine
[00:46:42.220 --> 00:46:46.320]   or something, which is essentially like the executive lunch budget for the day.
[00:46:46.320 --> 00:46:52.480]   Yeah, it's, it's always concerning when, when any of these big companies continue to consolidate,
[00:46:52.480 --> 00:46:56.360]   uh, more ways to get your data, especially when it comes to healthcare.
[00:46:56.360 --> 00:47:00.160]   That's, that's, I don't know, I don't know if I would have.
[00:47:00.160 --> 00:47:01.160]   It's really prickly.
[00:47:01.160 --> 00:47:02.160]   It's really prickly.
[00:47:02.160 --> 00:47:05.800]   It's like just a real thorny kind of place to be in.
[00:47:05.800 --> 00:47:12.520]   Because the thing is, is, you know, technically they would have to keep that information private,
[00:47:12.520 --> 00:47:17.880]   but also, you know, there's the argument that can be made where it's like, Oh, we, and we,
[00:47:17.880 --> 00:47:19.800]   it's the data is anonymous.
[00:47:19.800 --> 00:47:26.040]   And we, we make sure that it's anonymous before it's used by Amazon Prime or like, you know,
[00:47:26.040 --> 00:47:29.320]   but the thing is, is like, it's going to know it's you, right?
[00:47:29.320 --> 00:47:34.440]   Like if you're going to a one medical facility, your phone is there, your geolocation.
[00:47:34.440 --> 00:47:38.680]   If you have any location services on it and you have the Amazon Amazon, I mean, it's
[00:47:38.680 --> 00:47:42.960]   just, there's a lot of kind of, there's going to be a lot of coincidences with your data.
[00:47:42.960 --> 00:47:43.960]   Right?
[00:47:43.960 --> 00:47:49.040]   It's just going to be, it's, oh, it's what a coincidence you, you got diagnosed with diabetes.
[00:47:49.040 --> 00:47:51.360]   And now Amazon is going to recommend to you.
[00:47:51.360 --> 00:47:54.880]   Like here's all these sponsored, um, you know, insulin pumps that we could recommend
[00:47:54.880 --> 00:47:55.880]   to you.
[00:47:55.880 --> 00:47:58.600]   And you can use your FSA and like all this other, you know, all this other stuff.
[00:47:58.600 --> 00:48:07.360]   So I feel it always makes me feel icky when like a big tech company buys a company that's
[00:48:07.360 --> 00:48:10.240]   in a completely different services vertical.
[00:48:10.240 --> 00:48:13.560]   It's just a little, it's a little weird and it's got just me out a little bit.
[00:48:13.560 --> 00:48:17.720]   I mean, I'm not going to, I hate saying this was like, I'm not going to stop using Amazon.
[00:48:17.720 --> 00:48:20.280]   Like I need that convenience in a lot of ways.
[00:48:20.280 --> 00:48:21.720]   Like, and there's a lot of things that I need.
[00:48:21.720 --> 00:48:23.040]   I got my hypocrite.
[00:48:23.040 --> 00:48:24.040]   I fully admit it.
[00:48:24.040 --> 00:48:28.040]   But also it's just like, yeah, that, that kind of thing is like, I don't know that I
[00:48:28.040 --> 00:48:29.720]   could, I don't know that I could do it.
[00:48:29.720 --> 00:48:33.480]   I don't know that I could give my health data to a company like Amazon.
[00:48:33.480 --> 00:48:36.040]   But then it's like, how much do they already know about you?
[00:48:36.040 --> 00:48:37.040]   Right?
[00:48:37.040 --> 00:48:40.680]   Like, because if you are a diabetic, let's say you buy a, you buy some supplies on Amazon,
[00:48:40.680 --> 00:48:45.240]   they probably know, they probably have an idea that you are someone in your household,
[00:48:45.240 --> 00:48:46.600]   has a certain health condition.
[00:48:46.600 --> 00:48:51.200]   So, or is in a bucket of cat, you know, a bucket that includes a myriad of health conditions
[00:48:51.200 --> 00:48:55.800]   that have similar symptoms or similar care, you know, care instructions.
[00:48:55.800 --> 00:48:58.840]   So it's a tough one.
[00:48:58.840 --> 00:48:59.840]   It's a tough one.
[00:48:59.840 --> 00:49:06.040]   Well, and if they do know that about you, what exactly are they doing with that information,
[00:49:06.040 --> 00:49:07.720]   if they know that about you, right?
[00:49:07.720 --> 00:49:09.920]   Like, it's not like they're selling, it's Amazon.
[00:49:09.920 --> 00:49:15.600]   So, their business is not selling that information that we know of to someone else.
[00:49:15.600 --> 00:49:21.720]   But it is about like their myriad, yeah, myriad ways that all of their services tie
[00:49:21.720 --> 00:49:22.720]   into each other.
[00:49:22.720 --> 00:49:26.160]   You can almost imagine, you know, going to the front desk after, you know, getting a
[00:49:26.160 --> 00:49:31.440]   health checkup and the like, do you have the, you know, the Amazon Prime app and you scan
[00:49:31.440 --> 00:49:34.600]   the QR code and you get like a discount on the way out or something like that, you know?
[00:49:34.600 --> 00:49:37.880]   I know if you have time, you'll get a discount on for your prescription.
[00:49:37.880 --> 00:49:38.880]   That's going to be the thing, right?
[00:49:38.880 --> 00:49:43.920]   It's like you're going to get some discount on your prescription or you walk into a whole
[00:49:43.920 --> 00:49:49.160]   foods or an Amazon fresh and it pings you and says, hey, like, you have high cholesterol.
[00:49:49.160 --> 00:49:52.560]   You should try these foods or, you know, sponsor foods or whatever.
[00:49:52.560 --> 00:49:57.520]   Like, I can see that very easily happening, you know, where it's like, oh, hey, like, you
[00:49:57.520 --> 00:50:02.240]   are, you, you, your doctor does you have keto, like, you're some keto friendly food options,
[00:50:02.240 --> 00:50:03.520]   you know, things like that.
[00:50:03.520 --> 00:50:07.120]   I can see that happening because you're shopping data.
[00:50:07.120 --> 00:50:13.240]   If you're using Amazon already is that data is already being like sorted out in that way.
[00:50:13.240 --> 00:50:15.960]   They know that stuff about you.
[00:50:15.960 --> 00:50:19.720]   And there's also the concern that people in the household share an Amazon account.
[00:50:19.720 --> 00:50:22.440]   No one has an individual, you know, there's not like five people in the house who all
[00:50:22.440 --> 00:50:24.480]   have their individual Amazon account.
[00:50:24.480 --> 00:50:27.160]   The entire family uses one Amazon account.
[00:50:27.160 --> 00:50:30.040]   But if someone goes to the doctor and they're diagnosed with something that they don't want
[00:50:30.040 --> 00:50:34.640]   the rest of the house to know about whether it's their parents or their spouse or their
[00:50:34.640 --> 00:50:41.520]   partner or whoever, the last thing that person wants is for someone else in the family to
[00:50:41.520 --> 00:50:46.680]   hop on Amazon and find this, like, you know, be, oh, you have hemorrhoids or something,
[00:50:46.680 --> 00:50:47.920]   you know, it's just something that's.
[00:50:47.920 --> 00:50:49.680]   Here's your preparation.
[00:50:49.680 --> 00:50:54.920]   Here's your preparation age or something worse, you know, there's the pregnancies or, you
[00:50:54.920 --> 00:50:59.280]   know, cancers or, you know, there's a lot of things that people, you know, you know,
[00:50:59.280 --> 00:51:00.840]   we don't know how people's lives are.
[00:51:00.840 --> 00:51:02.720]   We don't know like what kind of relationships they're in.
[00:51:02.720 --> 00:51:04.800]   A lot of relationships are extremely abusive.
[00:51:04.800 --> 00:51:11.440]   If you have, if you are pregnant and your abusive partner finds out via just logging on
[00:51:11.440 --> 00:51:15.000]   the Amazon when you were about to go, you know, to have some, you know, take care of
[00:51:15.000 --> 00:51:18.040]   the pregnancy because you do not want to have a child with this horrible person.
[00:51:18.040 --> 00:51:21.960]   Well, now you've just created this whole huge mess for this, for this individual because
[00:51:21.960 --> 00:51:25.440]   you decided you wanted to share data to help people buy stuff.
[00:51:25.440 --> 00:51:26.440]   Yeah.
[00:51:26.440 --> 00:51:31.400]   And to piggyback on that, I mean, with the Dobbs decision and Roe v. Wade, you know,
[00:51:31.400 --> 00:51:35.640]   now that data, that information becomes like more important than ever.
[00:51:35.640 --> 00:51:41.280]   And we all know Amazon hasn't been the greatest at resisting subpoenas from law enforcement
[00:51:41.280 --> 00:51:44.960]   with the Ring Doorbells and other home devices, smart home devices they have.
[00:51:44.960 --> 00:51:50.960]   So yeah, this is like, it's a real kind of, it's a real touchy thing.
[00:51:50.960 --> 00:51:54.880]   I mean, I just people's health data is just like one of the most, it's like health finances.
[00:51:54.880 --> 00:51:59.480]   I mean, there's like some buckets of data that are just really sensitive.
[00:51:59.480 --> 00:52:06.560]   So I mean, they're really, I think I would hope that regulators would make sure that
[00:52:06.560 --> 00:52:08.520]   they, you know, really kind of locked it down.
[00:52:08.520 --> 00:52:11.840]   But again, like you said, Roberto, it's like, you know, they'll just be like, oh, well,
[00:52:11.840 --> 00:52:12.840]   we did it.
[00:52:12.840 --> 00:52:13.840]   And like, oops.
[00:52:13.840 --> 00:52:16.360]   We were handling the data this whole time.
[00:52:16.360 --> 00:52:19.880]   And it's just like, you know, these, if we see this over and over and over again, it's
[00:52:19.880 --> 00:52:22.360]   just it's a it's a pattern.
[00:52:22.360 --> 00:52:24.320]   It's a pattern of behavior.
[00:52:24.320 --> 00:52:27.120]   It's not a thing that's like, oh, well, they made a one mistake.
[00:52:27.120 --> 00:52:28.400]   Like they messed up this time.
[00:52:28.400 --> 00:52:32.320]   And it's like, no, this is, this is pretty regular across so much of the industry.
[00:52:32.320 --> 00:52:33.320]   Right.
[00:52:33.320 --> 00:52:34.320]   Right.
[00:52:34.320 --> 00:52:39.600]   Well, Amazon in buying one medical definitely signals at least their understanding that
[00:52:39.600 --> 00:52:44.280]   they, you know, that they are going to be placed under a lot of scrutiny, a lot of regulatory
[00:52:44.280 --> 00:52:47.080]   oversight as a result of this.
[00:52:47.080 --> 00:52:50.320]   But you know, how much impact is that actually going to have the other thing that
[00:52:50.320 --> 00:52:55.440]   you know, we talked about the story briefly on techniques weekly, me and Micah Sergeant
[00:52:55.440 --> 00:52:57.080]   on Thursday.
[00:52:57.080 --> 00:52:59.880]   And one of the things that we ended up talking about is like, you know, we live in a country
[00:52:59.880 --> 00:53:05.360]   where healthcare is just so, so filled with with holes.
[00:53:05.360 --> 00:53:10.520]   Like it's just a it's a horrible situation here for healthcare for a large, you know,
[00:53:10.520 --> 00:53:14.320]   swath of the population compared to other countries where healthcare is paid for for
[00:53:14.320 --> 00:53:15.320]   everyone.
[00:53:15.320 --> 00:53:17.240]   And you know, here you have to pay through your teeth.
[00:53:17.240 --> 00:53:24.040]   It's something like an Amazon buy of a primary care health, you know, business like this
[00:53:24.040 --> 00:53:29.240]   is able to offer healthcare that enables people who couldn't have afforded it prior
[00:53:29.240 --> 00:53:31.440]   to now suddenly afford it.
[00:53:31.440 --> 00:53:36.280]   And you know, obviously there is the caveat of, okay, yeah, but the data, you know, complications
[00:53:36.280 --> 00:53:37.560]   around that and everything.
[00:53:37.560 --> 00:53:40.160]   But that's also that that is a benefit, right?
[00:53:40.160 --> 00:53:45.680]   Like being able to enable people who couldn't have afforded healthcare before to suddenly
[00:53:45.680 --> 00:53:49.040]   do that in a country where it's just a broken system.
[00:53:49.040 --> 00:53:50.640]   At least there's something there.
[00:53:50.640 --> 00:53:53.080]   But who knows if that's what we're even going to see from Amazon.
[00:53:53.080 --> 00:54:00.120]   I'm just kind of reading the tea leaves from, you know, kind of the prime ethos as it were.
[00:54:00.120 --> 00:54:02.120]   Amazon prime comes with dental.
[00:54:02.120 --> 00:54:03.120]   Yeah.
[00:54:03.120 --> 00:54:09.640]   One tooth for free and one free tooth for every two hundred dollars I spend.
[00:54:09.640 --> 00:54:12.880]   I'm like, oh, I spy.
[00:54:12.880 --> 00:54:19.520]   If you have prime, they'll upgrade your crown from from metal to just porcelain.
[00:54:19.520 --> 00:54:22.280]   That'll be so nice prime porcelain.
[00:54:22.280 --> 00:54:25.320]   Prime porcelain.
[00:54:25.320 --> 00:54:28.920]   I would rather not have Jeff Bezos solve our healthcare crisis.
[00:54:28.920 --> 00:54:29.920]   Yeah, I know.
[00:54:29.920 --> 00:54:30.920]   Right.
[00:54:30.920 --> 00:54:31.920]   Totally.
[00:54:31.920 --> 00:54:34.720]   That's really what it boils down to, right?
[00:54:34.720 --> 00:54:38.880]   And he's not building super yachts or buying places with 50 something toilets.
[00:54:38.880 --> 00:54:41.440]   He's like, you know what I should fix?
[00:54:41.440 --> 00:54:42.440]   Healthcare.
[00:54:42.440 --> 00:54:50.440]   Well, but Megan, allow me to to release that kind of that tension that you have around
[00:54:50.440 --> 00:54:51.800]   Bezos because it's not Bezos.
[00:54:51.800 --> 00:54:52.800]   It's jassy.
[00:54:52.800 --> 00:54:53.800]   So do you trust?
[00:54:53.800 --> 00:54:54.800]   Oh, that's true.
[00:54:54.800 --> 00:54:55.800]   True.
[00:54:55.800 --> 00:54:56.800]   You're right.
[00:54:56.800 --> 00:54:57.800]   You can trust jassy.
[00:54:57.800 --> 00:54:58.800]   Yeah.
[00:54:58.800 --> 00:54:59.800]   We're healthcare.
[00:54:59.800 --> 00:55:00.800]   It's like new Coke.
[00:55:00.800 --> 00:55:01.800]   Yeah.
[00:55:01.800 --> 00:55:02.800]   I feel like better.
[00:55:02.800 --> 00:55:09.160]   I feel like it was so little about jassy, not that I know a ton about Bezos, but I feel
[00:55:09.160 --> 00:55:10.760]   like I do compared to jassy.
[00:55:10.760 --> 00:55:11.760]   I don't know.
[00:55:11.760 --> 00:55:12.760]   Do I want to be out?
[00:55:12.760 --> 00:55:13.760]   Yeah.
[00:55:13.760 --> 00:55:17.320]   I don't want to know anything about billionaires or super rich people anymore.
[00:55:17.320 --> 00:55:19.800]   Like I'm just like, I don't want to hear about you.
[00:55:19.800 --> 00:55:21.360]   Just, just go.
[00:55:21.360 --> 00:55:22.600]   You have so much money.
[00:55:22.600 --> 00:55:26.600]   Just please leave the internet and go and just do whatever with your money.
[00:55:26.600 --> 00:55:27.920]   Good, better and different.
[00:55:27.920 --> 00:55:29.160]   Just leave us all alone.
[00:55:29.160 --> 00:55:32.960]   We're all just trying to enjoy being online until it ends.
[00:55:32.960 --> 00:55:37.000]   Until the collapsed society, can you just go away?
[00:55:37.000 --> 00:55:38.000]   It ends.
[00:55:38.000 --> 00:55:39.800]   And then that's it.
[00:55:39.800 --> 00:55:44.960]   Like right before society collapses, just give us your location so we can go to your
[00:55:44.960 --> 00:55:49.560]   boats and your houses and we can eat all your food because you're one person.
[00:55:49.560 --> 00:55:50.560]   All need just a very young from water worlds.
[00:55:50.560 --> 00:55:52.360]   When that happens, like that's our mathematics.
[00:55:52.360 --> 00:55:56.680]   Like I'll need some crawlers and desert crawler that's like 50 bedrooms.
[00:55:56.680 --> 00:55:58.280]   Fine, whatever, a sand crawler.
[00:55:58.280 --> 00:55:59.600]   I need a jaw with sand crawler.
[00:55:59.600 --> 00:56:00.600]   That's what I need.
[00:56:00.600 --> 00:56:03.800]   But yeah, until then, just please, just billionaires.
[00:56:03.800 --> 00:56:05.680]   If you're listening, stay out.
[00:56:05.680 --> 00:56:07.000]   Just get off the internet, please.
[00:56:07.000 --> 00:56:08.360]   Just don't, don't be on the internet.
[00:56:08.360 --> 00:56:10.280]   I'm begging you.
[00:56:10.280 --> 00:56:11.280]   Hands off be real.
[00:56:11.280 --> 00:56:12.280]   Okay.
[00:56:12.280 --> 00:56:13.280]   Seriously.
[00:56:13.280 --> 00:56:14.280]   Oh no.
[00:56:14.280 --> 00:56:17.880]   Oh, you just ruined be real for me.
[00:56:17.880 --> 00:56:19.680]   Just the anticipation.
[00:56:19.680 --> 00:56:22.120]   Just the anticipation.
[00:56:22.120 --> 00:56:23.120]   Just you wait.
[00:56:23.120 --> 00:56:24.800]   It's going to happen.
[00:56:24.800 --> 00:56:25.800]   Maybe.
[00:56:25.800 --> 00:56:27.400]   Oh, well, it was a good 30 seconds.
[00:56:27.400 --> 00:56:28.400]   Help, please.
[00:56:28.400 --> 00:56:29.600]   It was a good, you had a good run.
[00:56:29.600 --> 00:56:30.600]   You had a good run.
[00:56:30.600 --> 00:56:35.200]   Let's take a break and thank the sponsor of this episode of This Week in Tech.
[00:56:35.200 --> 00:56:38.920]   And then we'll get back and we got plenty more news to walk through.
[00:56:38.920 --> 00:56:40.160]   So we'll get back to that in a second.
[00:56:40.160 --> 00:56:44.520]   But first, this episode of This Week in Tech is brought to you by Audible.
[00:56:44.520 --> 00:56:47.200]   And you know, man, how many years have I been with Audible?
[00:56:47.200 --> 00:56:48.200]   Not as long as Leo.
[00:56:48.200 --> 00:56:52.080]   Leo, when he starts rattling off his stats, I'm always like, man, you.
[00:56:52.080 --> 00:56:55.960]   You could probably listen for like a hundred years, the amount of hours that you have in
[00:56:55.960 --> 00:56:56.960]   your Audible library.
[00:56:56.960 --> 00:56:57.960]   I don't know.
[00:56:57.960 --> 00:57:01.720]   But I have a lot, not quite that much, but it's awesome.
[00:57:01.720 --> 00:57:06.080]   Like all of my spare time filled listening to audiobooks.
[00:57:06.080 --> 00:57:07.640]   I love it.
[00:57:07.640 --> 00:57:10.320]   And you know, our schedules, they're busy.
[00:57:10.320 --> 00:57:11.320]   We're always on the go.
[00:57:11.320 --> 00:57:12.880]   I feel like I'm always on the go.
[00:57:12.880 --> 00:57:16.040]   I don't have a ton of times to do the things that I want to do.
[00:57:16.040 --> 00:57:19.160]   But you know, I can find the time.
[00:57:19.160 --> 00:57:22.040]   If I'm walking my dog, I can find time to listen to an audiobook.
[00:57:22.040 --> 00:57:24.360]   That's why I love Audible.
[00:57:24.360 --> 00:57:28.920]   Audible offers an incredible selection of audiobooks across every genre.
[00:57:28.920 --> 00:57:33.200]   And you go on there, you search for any author, any genre.
[00:57:33.200 --> 00:57:36.080]   You're going to find so many options.
[00:57:36.080 --> 00:57:40.240]   And I'll present it in a way where you can really kind of get to the root of, you know,
[00:57:40.240 --> 00:57:44.320]   the suggestions and the reviews and everything to really kind of figure out exactly what
[00:57:44.320 --> 00:57:46.600]   you want to spend your time listening to.
[00:57:46.600 --> 00:57:52.920]   Bestsellers, new releases, celebrity memoirs, mysteries, thrillers, motivation, a lot of
[00:57:52.920 --> 00:57:57.000]   really good self-help, wellness, business, everything, you name it.
[00:57:57.000 --> 00:58:02.480]   You're going to discover exclusive Audible originals from top celebrities, renowned experts,
[00:58:02.480 --> 00:58:05.360]   of course, and exciting new voices and audio.
[00:58:05.360 --> 00:58:09.080]   As an Audible member, you can choose one title a month.
[00:58:09.080 --> 00:58:12.360]   And that's to keep, you get to keep that from their entire catalog.
[00:58:12.360 --> 00:58:16.560]   You choose one a month, it's yours, including the latest bestsellers and new releases.
[00:58:16.560 --> 00:58:22.080]   And then all Audible members actually get access also to a growing selection of audiobooks,
[00:58:22.080 --> 00:58:26.880]   Audible originals and podcasts that are included with your membership.
[00:58:26.880 --> 00:58:33.400]   So you can listen to all you want and more are getting added every single month.
[00:58:33.400 --> 00:58:36.080]   And you can listen to the Audible app anytime, anywhere.
[00:58:36.080 --> 00:58:37.440]   I have it on my phone.
[00:58:37.440 --> 00:58:40.480]   It's always, you know, up and ready to go.
[00:58:40.480 --> 00:58:45.920]   I've got my audio book downloaded so that when I'm on the plane and I don't have connectivity,
[00:58:45.920 --> 00:58:48.520]   let's say my audio book is there waiting for me.
[00:58:48.520 --> 00:58:53.880]   So when you're traveling, you're working out, walking, doing chores, big time into that,
[00:58:53.880 --> 00:58:55.520]   you decide.
[00:58:55.520 --> 00:59:00.560]   One audiobook that I have been actually listening to a second time, I listened to this audiobook
[00:59:00.560 --> 00:59:08.200]   called Untangled by Lisa D'Amour guiding teenage girls through the seven transitions into adulthood
[00:59:08.200 --> 00:59:14.320]   because I have a daughter who is almost a teenager.
[00:59:14.320 --> 00:59:18.000]   And let me tell you, life's starting to get a little crazy around here.
[00:59:18.000 --> 00:59:25.080]   So I'm trying to do my best to be informed, to understand where she is at and to be able
[00:59:25.080 --> 00:59:28.400]   to sister and help her in any way that I possibly can.
[00:59:28.400 --> 00:59:30.680]   And this audiobook is just fantastic.
[00:59:30.680 --> 00:59:33.240]   Like I said, this is my second time listening to it.
[00:59:33.240 --> 00:59:35.560]   It's untangled by Lisa D'Amour.
[00:59:35.560 --> 00:59:41.200]   She is just an amazing author on this topic and I've learned so much through listening to
[00:59:41.200 --> 00:59:42.200]   it.
[00:59:42.200 --> 00:59:43.200]   So and that's just one example.
[00:59:43.200 --> 00:59:44.200]   Right?
[00:59:44.200 --> 00:59:47.440]   So a lot of Twit fans, big into sci-fi.
[00:59:47.440 --> 00:59:53.920]   You're going to find tons of sci-fi on Audible and everything else under the sun.
[00:59:53.920 --> 00:59:58.600]   So let Audible help you discover new ways to laugh, to be inspired, to be entertained.
[00:59:58.600 --> 01:00:01.240]   New members can try it free for 30 days.
[01:00:01.240 --> 01:00:06.440]   Visit Audible.com/Twit or text Twit to 500-500.
[01:00:06.440 --> 01:00:14.160]   That's Audible.com/Twit or text Twit to 500-500 to try Audible free for 30 days.
[01:00:14.160 --> 01:00:15.320]   And you're going to love it.
[01:00:15.320 --> 01:00:18.240]   I mean, you're already listening to podcasts.
[01:00:18.240 --> 01:00:23.000]   You're already used to consuming information through your ears while you're doing other
[01:00:23.000 --> 01:00:24.520]   things, right?
[01:00:24.520 --> 01:00:27.560]   This is a way to allow you to keep reading.
[01:00:27.560 --> 01:00:29.320]   But with your ears, it's awesome.
[01:00:29.320 --> 01:00:36.280]   Audible.com/Twit and we thank Audible for their support of This Week in Tech.
[01:00:36.280 --> 01:00:38.440]   All right.
[01:00:38.440 --> 01:00:40.440]   Did anyone get their invites for Dolly?
[01:00:40.440 --> 01:00:41.440]   Dolly too?
[01:00:41.440 --> 01:00:45.560]   Now that things are expanding out, anybody use this?
[01:00:45.560 --> 01:00:47.960]   I still want mine, but I haven't gotten it yet.
[01:00:47.960 --> 01:00:50.080]   Yeah, I want mine too.
[01:00:50.080 --> 01:00:51.360]   Send our invites.
[01:00:51.360 --> 01:00:53.120]   I'm on the wait list.
[01:00:53.120 --> 01:01:00.280]   I'm ready to type in my crazy prompts and get wild AI art.
[01:01:00.280 --> 01:01:02.280]   I need it.
[01:01:02.280 --> 01:01:04.200]   I need to.
[01:01:04.200 --> 01:01:05.280]   This is so cool.
[01:01:05.280 --> 01:01:12.840]   I love any and almost all examples of how artificial intelligence is intersecting with
[01:01:12.840 --> 01:01:15.080]   kind of the creative arts.
[01:01:15.080 --> 01:01:23.040]   There's some things about AI that's kind of frightening to me in certain ways, you know,
[01:01:23.040 --> 01:01:27.520]   behind the scenes of the tech companies and what they're doing and how AI is making decisions
[01:01:27.520 --> 01:01:32.240]   that's promoting hate or those are the things that I don't like AI for, right?
[01:01:32.240 --> 01:01:38.520]   There's a lot to be worked on, but I'm fascinated by this idea that AI is powering this like
[01:01:38.520 --> 01:01:47.600]   new generation of apps and services that can create art, be it music, be it visual art,
[01:01:47.600 --> 01:01:51.600]   that right now let's say that it's not perfect.
[01:01:51.600 --> 01:01:57.240]   It's not always that I could look at an image and say, oh, yeah, that's a human made that.
[01:01:57.240 --> 01:02:00.600]   And then actually it was a computer like it's not always that way.
[01:02:00.600 --> 01:02:05.680]   But it's happening more often now than it was when they started doing this sort of thing.
[01:02:05.680 --> 01:02:09.440]   And I feel like that's only going to continue to improve and Dolly too.
[01:02:09.440 --> 01:02:13.760]   I mean, everything that, you know, all the examples that you see from Dolly are just,
[01:02:13.760 --> 01:02:15.320]   I don't know, it's mind blowing.
[01:02:15.320 --> 01:02:20.080]   I just want like French fries French fries dressed up as Dolly Parton.
[01:02:20.080 --> 01:02:21.640]   Like these are the things that I need.
[01:02:21.640 --> 01:02:23.120]   I don't you want that.
[01:02:23.120 --> 01:02:25.760]   I could like why?
[01:02:25.760 --> 01:02:27.560]   Where's my invite?
[01:02:27.560 --> 01:02:28.720]   World needs that.
[01:02:28.720 --> 01:02:31.120]   I'm not going to learn how to draw immediately.
[01:02:31.120 --> 01:02:33.760]   And I never learn how to draw.
[01:02:33.760 --> 01:02:40.040]   I need AI to help me realize my, realize my creative visions.
[01:02:40.040 --> 01:02:46.120]   Yes, because, because you don't actually have to have the creative, like the creative follow
[01:02:46.120 --> 01:02:48.160]   through on what it actually looks like.
[01:02:48.160 --> 01:02:51.080]   All you got to do is come up with a couple of words and let the computer draw it for
[01:02:51.080 --> 01:02:52.080]   you.
[01:02:52.080 --> 01:02:54.000]   I mean, who wouldn't love that?
[01:02:54.000 --> 01:02:58.200]   Somebody, somebody said that the other day, if you're really good at Googling, you'll be
[01:02:58.200 --> 01:03:02.240]   really good at Dolly because I can know how to type in the right keywords.
[01:03:02.240 --> 01:03:04.240]   And that made so much sense to me.
[01:03:04.240 --> 01:03:07.360]   It was just such a good explanation of like, yes, that's it.
[01:03:07.360 --> 01:03:09.080]   That's a great explanation.
[01:03:09.080 --> 01:03:10.080]   Great analogy.
[01:03:10.080 --> 01:03:11.080]   Thank you.
[01:03:11.080 --> 01:03:12.080]   Like that's exactly right.
[01:03:12.080 --> 01:03:17.800]   It is, if you are really good at finding things on Google using keywords, you can be
[01:03:17.800 --> 01:03:20.280]   good at art on Dolly too.
[01:03:20.280 --> 01:03:24.080]   Like that's, I think that's really a great way to explain it.
[01:03:24.080 --> 01:03:25.580]   Mm hmm.
[01:03:25.580 --> 01:03:28.740]   That's a fun artistic parlor trick is what the AI is right now.
[01:03:28.740 --> 01:03:29.740]   Yeah.
[01:03:29.740 --> 01:03:31.140]   It's like, hey, I made a funny thing.
[01:03:31.140 --> 01:03:35.060]   It's more, it's, it's really for, hey, look at this weird thing I thought up.
[01:03:35.060 --> 01:03:39.900]   And then it made it and now it's on Twitter or Instagram or TikTok or be, I guess not
[01:03:39.900 --> 01:03:40.900]   be real.
[01:03:40.900 --> 01:03:41.900]   Let's take a picture of another phone.
[01:03:41.900 --> 01:03:44.140]   Unless you're sitting in front of it right now.
[01:03:44.140 --> 01:03:46.540]   And then it'll tell on you, it'll flag you for that.
[01:03:46.540 --> 01:03:48.940]   It's like, hey, what are you doing?
[01:03:48.940 --> 01:03:51.100]   I'm gonna like this.
[01:03:51.100 --> 01:03:52.100]   Like this.
[01:03:52.100 --> 01:03:57.540]   Yeah, every time I hear the AI generated music, I'm always like, oh my God.
[01:03:57.540 --> 01:03:58.540]   Yeah, yeah, yeah.
[01:03:58.540 --> 01:04:00.780]   It's always got a ways to go for sure.
[01:04:00.780 --> 01:04:06.700]   So yeah, I think it's the, you know, the artwork, the drawings, I think are a bit better.
[01:04:06.700 --> 01:04:10.300]   But it's, it's always fun to see the monstrosity that it creates.
[01:04:10.300 --> 01:04:12.740]   It's the monstrosity that makes it fun.
[01:04:12.740 --> 01:04:16.900]   It's the, the, the, the merging together of two horror.
[01:04:16.900 --> 01:04:19.300]   It's like, it's like artistic chamira.
[01:04:19.300 --> 01:04:20.300]   It's just like, yeah.
[01:04:20.300 --> 01:04:21.300]   Yeah.
[01:04:21.300 --> 01:04:22.300]   There's a certain chaos to it.
[01:04:22.300 --> 01:04:23.300]   It's a feeling.
[01:04:23.300 --> 01:04:24.300]   It's a Frankenstein factor.
[01:04:24.300 --> 01:04:25.300]   There's a Frankenstein factor happening.
[01:04:25.300 --> 01:04:27.100]   Or I guess Frankenstein's monster.
[01:04:27.100 --> 01:04:28.100]   It's a Frankenstein monster.
[01:04:28.100 --> 01:04:30.020]   Oh, you don't want, yeah.
[01:04:30.020 --> 01:04:32.300]   You don't want those Mary Shelley people after you.
[01:04:32.300 --> 01:04:33.300]   Nope, I don't.
[01:04:33.300 --> 01:04:36.300]   Mary Shelley stands are very serious people.
[01:04:36.300 --> 01:04:40.180]   The Shelley nation will come down hard on you.
[01:04:40.180 --> 01:04:43.260]   Shelley stands are not messing around everybody.
[01:04:43.260 --> 01:04:44.660]   They don't mess around.
[01:04:44.660 --> 01:04:45.660]   No, no.
[01:04:45.660 --> 01:04:46.660]   That was...
[01:04:46.660 --> 01:04:50.420]   The uncanny valley part of it is still interesting because it's like what you said, Jason.
[01:04:50.420 --> 01:04:56.740]   Like it's, it's easy to like to look at something and think like, oh, like I am surprised that
[01:04:56.740 --> 01:04:59.540]   an AI made that or, you know, that that wasn't made by a person.
[01:04:59.540 --> 01:05:01.580]   The art, like I'm surprised the art itself.
[01:05:01.580 --> 01:05:06.620]   But then there's just something slightly off and it's disturbing.
[01:05:06.620 --> 01:05:14.940]   I had so some, a former coworker has access and just tweeted like, tell me something to
[01:05:14.940 --> 01:05:15.940]   Dolly.
[01:05:15.940 --> 01:05:17.540]   And I said, this was when my internet wasn't working.
[01:05:17.540 --> 01:05:22.620]   And I thought it was because a squirrel had eaten through the cables and the ground somewhere.
[01:05:22.620 --> 01:05:24.660]   And so I was like, squirrel eating my internet.
[01:05:24.660 --> 01:05:29.060]   And it's like a squirrel like eating like a laptop.
[01:05:29.060 --> 01:05:35.620]   And it's just like, okay, well, yeah, like internet equals laptop.
[01:05:35.620 --> 01:05:38.500]   And it's just like, it was just disturbing enough.
[01:05:38.500 --> 01:05:39.500]   But yeah.
[01:05:39.500 --> 01:05:42.820]   It's going to be great for horror movies.
[01:05:42.820 --> 01:05:47.500]   Like if you're making a low budget horror movie and you're like, oh, I need, you know,
[01:05:47.500 --> 01:05:54.140]   a lamb eating a lion while like wearing, you know, a Dr. Pepper hat.
[01:05:54.140 --> 01:05:57.620]   Like that's like, that's a piece of art they're going to put in the background of a horror
[01:05:57.620 --> 01:06:00.780]   movie and the people are going to walk in and like, what is this?
[01:06:00.780 --> 01:06:03.580]   That's, that's what Dolly is going to be really great for.
[01:06:03.580 --> 01:06:09.140]   I mean, I think you're, you're touching on one thing that actually Dolly will be really
[01:06:09.140 --> 01:06:15.660]   good for is, is generating ideas for actual designer, like designers to work for.
[01:06:15.660 --> 01:06:17.660]   Really concept art.
[01:06:17.660 --> 01:06:18.660]   Yeah, totally.
[01:06:18.660 --> 01:06:21.100]   It's like, pieces of concept art could be really cool.
[01:06:21.100 --> 01:06:22.100]   Yeah.
[01:06:22.100 --> 01:06:23.100]   Someone gives you that prompt.
[01:06:23.100 --> 01:06:26.900]   They're like, well, we're looking for is, you know, and then exactly what you said, Roberto,
[01:06:26.900 --> 01:06:28.700]   I can't, I can't recite it word for word.
[01:06:28.700 --> 01:06:30.820]   But what we're looking for is that.
[01:06:30.820 --> 01:06:33.620]   And as a designer, like I'm not a visual arts designer.
[01:06:33.620 --> 01:06:36.140]   So I don't know how the, how the mind works in that regard.
[01:06:36.140 --> 01:06:40.980]   But I have to imagine that certain concepts come to you or, or, you know, or you want
[01:06:40.980 --> 01:06:44.580]   to pursue, but you have no idea where to begin.
[01:06:44.580 --> 01:06:49.060]   And, you know, if Dolly gives you three or nine different ideas, boom, boom, boom, boom,
[01:06:49.060 --> 01:06:50.060]   there you go.
[01:06:50.060 --> 01:06:51.060]   Maybe that's the foundation.
[01:06:51.060 --> 01:06:55.020]   Oh, you know, I didn't think to put the pancake on her head like that.
[01:06:55.020 --> 01:06:56.740]   That's interesting, you know, or whatever.
[01:06:56.740 --> 01:07:01.220]   It could also be interesting if you're an artist to like run it through, like, so you
[01:07:01.220 --> 01:07:03.180]   have a kind of base thing.
[01:07:03.180 --> 01:07:08.260]   So let's say you have a, you know, possessed bear or what have you, let's, we'll stick
[01:07:08.260 --> 01:07:09.860]   with the horror movie stuff.
[01:07:09.860 --> 01:07:14.940]   You have possessed bear, but you're not really sure if you want it to be like gangreness or
[01:07:14.940 --> 01:07:17.820]   if you want it to kind of be like less gory.
[01:07:17.820 --> 01:07:21.100]   And so you could run it through something like Dolly to sort of like give you different
[01:07:21.100 --> 01:07:27.020]   options without having to draw out, you know, do a draw over and then render it yourself,
[01:07:27.020 --> 01:07:28.020]   right?
[01:07:28.020 --> 01:07:30.620]   Like it could be something used for kind of that where it's like, I just want to see
[01:07:30.620 --> 01:07:35.940]   the different iterations of this that I have ideas for and get it spit it out very quickly
[01:07:35.940 --> 01:07:37.740]   and then decide what I want to go forward with.
[01:07:37.740 --> 01:07:42.220]   And then then you go and, you know, as an artist, you would, you would go ahead and do the actual
[01:07:42.220 --> 01:07:44.460]   concept art yourself.
[01:07:44.460 --> 01:07:49.460]   As a former designer, what we typically do is you just draw a lot.
[01:07:49.460 --> 01:07:53.020]   You'd make a lot of bunch of little squares on a piece of paper and you just start like
[01:07:53.020 --> 01:07:59.060]   doodling a ton of little ideas of like what you think, like the design should be or what
[01:07:59.060 --> 01:08:01.380]   the concept should be or what art should be.
[01:08:01.380 --> 01:08:03.300]   And then from there, you're like, Oh, okay.
[01:08:03.300 --> 01:08:06.300]   So I like this bear and I like it with a bloody face.
[01:08:06.300 --> 01:08:09.140]   And you know what, what if like, and sometimes you want reference art.
[01:08:09.140 --> 01:08:13.140]   So Dolly would be actually might be pretty good for reference art because you're like,
[01:08:13.140 --> 01:08:17.060]   okay, I need a picture of a bear eating a cow.
[01:08:17.060 --> 01:08:19.820]   Now finding that photo out in the world is going to be difficult.
[01:08:19.820 --> 01:08:23.140]   So you'll, what you'll typically do is find a picture of a bear and find a picture of
[01:08:23.140 --> 01:08:27.180]   a cow and then maybe a picture of a bear eating like something else and then you sort of merge
[01:08:27.180 --> 01:08:29.020]   those together as you're drawing.
[01:08:29.020 --> 01:08:32.860]   If you could tell Dolly to like, Hey, show me a bear eating a cow.
[01:08:32.860 --> 01:08:38.060]   That might help you when you're coming because you take those like 12 15 60 pieces of thumbnail
[01:08:38.060 --> 01:08:41.980]   art and then you narrow it down to like the five or six good ideas.
[01:08:41.980 --> 01:08:44.380]   And now you want something that looks a little bit better.
[01:08:44.380 --> 01:08:46.980]   So you can sort of, you know, sketch it out.
[01:08:46.980 --> 01:08:50.780]   And if you need some reference of a buried in a cow in this instance, then you might
[01:08:50.780 --> 01:08:53.180]   be able to do that with Dolly, which will help, which is helpful.
[01:08:53.180 --> 01:08:54.180]   Yeah.
[01:08:54.180 --> 01:09:02.020]   Yeah, it's making me think using Dolly as like a way to what is the word?
[01:09:02.020 --> 01:09:04.980]   It's escaping me right now when you're, when you're making a movie and you got to do all
[01:09:04.980 --> 01:09:08.900]   the different little images of the different storyboarding storyboarding.
[01:09:08.900 --> 01:09:09.900]   Thank you.
[01:09:09.900 --> 01:09:10.900]   Yeah.
[01:09:10.900 --> 01:09:14.260]   Using Dolly is like a storyboarding tool would actually be.
[01:09:14.260 --> 01:09:15.260]   Oh, yeah.
[01:09:15.260 --> 01:09:16.700]   It would be horrible for that.
[01:09:16.700 --> 01:09:18.900]   Actually, it would be horrible for storyboard.
[01:09:18.900 --> 01:09:20.900]   Because you need control control.
[01:09:20.900 --> 01:09:22.340]   You need the control.
[01:09:22.340 --> 01:09:23.340]   You need the control.
[01:09:23.340 --> 01:09:24.340]   Yeah.
[01:09:24.340 --> 01:09:25.340]   Yeah.
[01:09:25.340 --> 01:09:30.020]   I was just thinking if somebody did storyboard a fictional, like a totally out off the cuff,
[01:09:30.020 --> 01:09:31.980]   like you could do a short story with this.
[01:09:31.980 --> 01:09:35.740]   storyboard something with Dolly and all the randomness that it gives you and then try
[01:09:35.740 --> 01:09:38.940]   and make a film out of what it gives you.
[01:09:38.940 --> 01:09:41.860]   You probably get some headlines at least.
[01:09:41.860 --> 01:09:42.860]   So there's an idea for you.
[01:09:42.860 --> 01:09:43.860]   That's going to be expensive.
[01:09:43.860 --> 01:09:44.860]   I don't know what you come up with.
[01:09:44.860 --> 01:09:45.860]   That's going to be expensive.
[01:09:45.860 --> 01:09:46.860]   Yeah.
[01:09:46.860 --> 01:09:47.860]   So I'm being expensive as well.
[01:09:47.860 --> 01:09:52.340]   It's going to be like, oh, now I got to go buy this and do this effect.
[01:09:52.340 --> 01:09:54.140]   Oh, this was a bad idea.
[01:09:54.140 --> 01:09:55.820]   This is horrible.
[01:09:55.820 --> 01:09:57.460]   This is horrible.
[01:09:57.460 --> 01:10:00.820]   One thing that's interesting about getting access to Dolly though is that you get full
[01:10:00.820 --> 01:10:01.820]   usage right.
[01:10:01.820 --> 01:10:04.860]   So commercialization, reprint, you could sell it.
[01:10:04.860 --> 01:10:05.860]   Merchandise rights.
[01:10:05.860 --> 01:10:10.700]   I just think it's interesting that you could use their platform to create something that
[01:10:10.700 --> 01:10:11.860]   you aren't actually creating.
[01:10:11.860 --> 01:10:17.420]   The system is for you, but it becomes an original piece that sits on its own and that
[01:10:17.420 --> 01:10:19.420]   you can then sell.
[01:10:19.420 --> 01:10:24.380]   I see many people going to this site and just making tons and tons of stuff, filling Etsy
[01:10:24.380 --> 01:10:27.420]   with all of this crazy merchandise and everything.
[01:10:27.420 --> 01:10:28.420]   I don't know.
[01:10:28.420 --> 01:10:31.580]   So you on the copyright to the item, I want you to create it.
[01:10:31.580 --> 01:10:32.580]   You own the copyright.
[01:10:32.580 --> 01:10:36.660]   If I created a piece of artwork, I immediately own the copyright to that artwork unless I'm
[01:10:36.660 --> 01:10:38.340]   stealing it from somebody.
[01:10:38.340 --> 01:10:42.260]   So if I go to Dolly and I create something, which was my words and it gives me a picture,
[01:10:42.260 --> 01:10:47.220]   I now own the copyright or they're giving me rights to use that image to...
[01:10:47.220 --> 01:10:48.220]   Usage rights.
[01:10:48.220 --> 01:10:49.220]   Yeah.
[01:10:49.220 --> 01:10:50.220]   But it's okay.
[01:10:50.220 --> 01:10:54.140]   So what I read usage rights including commercialization.
[01:10:54.140 --> 01:10:56.020]   So how do those two different?
[01:10:56.020 --> 01:10:57.020]   But they can use it too.
[01:10:57.020 --> 01:10:59.020]   So you don't have your own rights.
[01:10:59.020 --> 01:11:00.020]   Yeah.
[01:11:00.020 --> 01:11:06.020]   So they own the copyright likely, but they give you usage rights.
[01:11:06.020 --> 01:11:10.340]   So yeah, if they see that you've taken something and you're making a mug and you're making
[01:11:10.340 --> 01:11:15.660]   $200,000 a year with your bare eating a cow mug, Dolly can be like, "You know what?
[01:11:15.660 --> 01:11:17.140]   We'll have a cow mug."
[01:11:17.140 --> 01:11:20.860]   Maybe we'll make some tumblers with a bare eating account.
[01:11:20.860 --> 01:11:22.860]   We're selling that mug too.
[01:11:22.860 --> 01:11:26.500]   Yeah, we'll sell that mug too.
[01:11:26.500 --> 01:11:29.340]   I'm sorry for putting the image with the bare eating account.
[01:11:29.340 --> 01:11:35.500]   It'll be interesting to see if they have some type of annual subscription model for people
[01:11:35.500 --> 01:11:42.620]   who want to just own exclusive rights to their own generated images.
[01:11:42.620 --> 01:11:47.380]   There's some interesting legal gray area there where it's like, yes, it's transformative,
[01:11:47.380 --> 01:11:53.500]   but also technically I would be the creator of it because I use the keywords to generate
[01:11:53.500 --> 01:11:54.860]   the images.
[01:11:54.860 --> 01:11:58.460]   So I'm very curious how all that sort of shakes out.
[01:11:58.460 --> 01:11:59.460]   Right.
[01:11:59.460 --> 01:12:00.460]   Yeah.
[01:12:00.460 --> 01:12:04.620]   But I wonder if it'll be something like creative cloud or, you know, shutter stock or whatever,
[01:12:04.620 --> 01:12:12.620]   where it's like you're basically paying to license your own AI generated phrases or whatever.
[01:12:12.620 --> 01:12:16.820]   And it's like, okay, well, if you pay this fee, if you're a professional, here's the fee
[01:12:16.820 --> 01:12:17.820]   you can pay.
[01:12:17.820 --> 01:12:22.220]   You can either pay per image like they do on stock photo websites.
[01:12:22.220 --> 01:12:27.060]   You can say, oh, I want to license this for $100 or whatever.
[01:12:27.060 --> 01:12:31.980]   And maybe they change the pricing based on like what's popular in SEO at the time, like
[01:12:31.980 --> 01:12:33.380]   what are people searching for?
[01:12:33.380 --> 01:12:34.780]   What's like really hot right now?
[01:12:34.780 --> 01:12:36.500]   That's a thing that costs more money.
[01:12:36.500 --> 01:12:40.820]   And then, you know, things that are less searched for costs less money to license out.
[01:12:40.820 --> 01:12:45.980]   So I'll be very curious to see how they end up trying to monetize Dolly too.
[01:12:45.980 --> 01:12:47.940]   And I'm sure that's coming.
[01:12:47.940 --> 01:12:53.500]   But I have a feeling maybe they will ask artists for like an annual subscription fee for unlimited
[01:12:53.500 --> 01:12:56.340]   licensing of, you know, however many images.
[01:12:56.340 --> 01:13:02.060]   I mean, they've started monetizing it actually with this announcement.
[01:13:02.060 --> 01:13:04.260]   It's so it's a credit based system.
[01:13:04.260 --> 01:13:09.100]   So basically, if you are a free user from the beginning, you get 50 credits for the first
[01:13:09.100 --> 01:13:10.540]   month free.
[01:13:10.540 --> 01:13:12.940]   And then every month thereafter, you get 15 credits.
[01:13:12.940 --> 01:13:17.700]   So that's 15 text prompts that you get for free every month, right that you could use.
[01:13:17.700 --> 01:13:21.700]   You can purchase additional credits at $15 for 115 credits.
[01:13:21.700 --> 01:13:23.540]   So 15 bucks, you get a hundred and 15 bucks.
[01:13:23.540 --> 01:13:27.220]   Similar to the stock photo system, like very kind of similar to that.
[01:13:27.220 --> 01:13:28.220]   That's interesting.
[01:13:28.220 --> 01:13:32.460]   I wonder if they'll offer a professional option where it's just an annual subscription fee.
[01:13:32.460 --> 01:13:37.300]   Yeah, at some point, I wouldn't be surprised because I, and this is, I think one of the
[01:13:37.300 --> 01:13:42.300]   things that this is going to be used for a lot is, you know, people who are writing their
[01:13:42.300 --> 01:13:46.860]   own content for their site, you know, would normally go to if they needed an image, go
[01:13:46.860 --> 01:13:52.820]   to a stock photo thing and try and find the thing that closely closest matches what they're
[01:13:52.820 --> 01:13:53.820]   writing about.
[01:13:53.820 --> 01:13:54.820]   But that's not always possible.
[01:13:54.820 --> 01:13:58.500]   So you end up picking from what you have, at least with Dolly, you can say, this is exactly
[01:13:58.500 --> 01:14:00.020]   what I need.
[01:14:00.020 --> 01:14:06.940]   The challenge will be how quickly can you get to that image that you're willing to accept,
[01:14:06.940 --> 01:14:07.940]   right?
[01:14:07.940 --> 01:14:12.940]   Because I mean, even though you have 15 tries, 15 credits, I mean, on the system that I use,
[01:14:12.940 --> 01:14:16.820]   which I can't, what was it called, the Dolly mini, whatever that was from like a month
[01:14:16.820 --> 01:14:21.740]   ago, where all the faces looked like they were like toxic Avenger.
[01:14:21.740 --> 01:14:22.740]   Yeah.
[01:14:22.740 --> 01:14:23.740]   Yeah.
[01:14:23.740 --> 01:14:28.820]   On that system, you know, you put in a prompt and you weren't always guaranteed that the
[01:14:28.820 --> 01:14:31.020]   result of that prompt was going to be great.
[01:14:31.020 --> 01:14:34.060]   You know, you might have to do it two or three times to find the one that you're like, all
[01:14:34.060 --> 01:14:36.140]   right, that's, that's a winner right there.
[01:14:36.140 --> 01:14:40.140]   So, you know, people are going to be burning through credits probably just to find the thing
[01:14:40.140 --> 01:14:44.500]   that they actually want to use in the end, but, but I think it'll be really useful for
[01:14:44.500 --> 01:14:45.500]   that.
[01:14:45.500 --> 01:14:48.940]   So, I don't know, time will tell.
[01:14:48.940 --> 01:14:52.660]   We'll certainly find out.
[01:14:52.660 --> 01:14:53.660]   Let's see here.
[01:14:53.660 --> 01:15:00.180]   Should we talk about a selling, I mean, speaking of subscriptions, BMWs heated seat subscriptions,
[01:15:00.180 --> 01:15:04.620]   which apparently, and you know, when I saw this headline was like, are you kidding me?
[01:15:04.620 --> 01:15:06.700]   Apparently BMW has been doing this since 2020.
[01:15:06.700 --> 01:15:13.820]   So this is not the first example of a subscription model in vehicle sale, you know, features,
[01:15:13.820 --> 01:15:14.820]   as it were.
[01:15:14.820 --> 01:15:20.740]   Roberto, you're probably the best one on the panel to talk about this a little bit.
[01:15:20.740 --> 01:15:25.940]   What do you think about a subscription model coming to the inside of a vehicle?
[01:15:25.940 --> 01:15:27.740]   What do you think about that?
[01:15:27.740 --> 01:15:31.500]   Well, I mean, we, we, people, automakers have been talking about subscription models for
[01:15:31.500 --> 01:15:35.700]   a long time because they're trying to figure out how to make more money from vehicles.
[01:15:35.700 --> 01:15:39.460]   Because right now, like a truck in an SUV, those are just cash cows for the automotive
[01:15:39.460 --> 01:15:46.540]   industry, like the gas powered ones, as we move to EVs, that's the margins are much lower,
[01:15:46.540 --> 01:15:50.580]   just because trucks and SUVs, they don't have all the same regulatory issues.
[01:15:50.580 --> 01:15:52.620]   They can charge more, they make more money.
[01:15:52.620 --> 01:15:54.980]   It's, again, the margins are created.
[01:15:54.980 --> 01:15:57.820]   So they're trying to figure out like, well, how can we make money?
[01:15:57.820 --> 01:15:59.420]   Can we make money from subscriptions?
[01:15:59.420 --> 01:16:02.420]   Because most people have become accustomed to subscriptions.
[01:16:02.420 --> 01:16:03.420]   We have Netflix.
[01:16:03.420 --> 01:16:04.900]   We have Spotify.
[01:16:04.900 --> 01:16:14.100]   And for a little, for a few years, BMW offered car play as a subscription, which I mean,
[01:16:14.100 --> 01:16:18.100]   and the automotive press and owners just hammered them forever.
[01:16:18.100 --> 01:16:20.460]   And this is in the, in the United States for this.
[01:16:20.460 --> 01:16:25.460]   And they finally just relented and said, fine, you're buying a BMW, you pay this much for
[01:16:25.460 --> 01:16:29.820]   car play and you just get car play in your vehicle, which everyone's like, yay, because
[01:16:29.820 --> 01:16:32.340]   you know, cars are expensive.
[01:16:32.340 --> 01:16:36.100]   But that doesn't stop automakers from figuring out how to do it.
[01:16:36.100 --> 01:16:40.060]   Still hearing United States, but also in other markets where they might be a bit more
[01:16:40.060 --> 01:16:41.740]   open to a subscription service.
[01:16:41.740 --> 01:16:46.660]   Like the, I believe the heated seats is in South Korea.
[01:16:46.660 --> 01:16:49.860]   It's not even here in the United States, but all the headlines were like, oh, BMW,
[01:16:49.860 --> 01:16:52.460]   BMW, well, that's not here.
[01:16:52.460 --> 01:16:55.220]   And you know, but a lot of the US press, well, there you go.
[01:16:55.220 --> 01:17:00.300]   See, Jonathan Adelene knows, you know, all the press here is like, oh, it's a, it's a
[01:17:00.300 --> 01:17:05.220]   fun, you know, easy click for people to get angry at something because anger sells.
[01:17:05.220 --> 01:17:09.220]   That's that we've all learned that we've learned out through social media is that if
[01:17:09.220 --> 01:17:13.260]   you have something that's going to make people angry and click, boom, that's how you're going
[01:17:13.260 --> 01:17:17.380]   to get the, that's how you're going to get all the page views, which, with ad sales the
[01:17:17.380 --> 01:17:18.380]   way they are.
[01:17:18.380 --> 01:17:20.740]   I don't know how well that's, that's working out for us anymore.
[01:17:20.740 --> 01:17:29.860]   But, you know, you know, Tesla is going to make a FSD a subscription.
[01:17:29.860 --> 01:17:34.740]   So there are all these subscriptions and there's, I can see where you, if there's a feature
[01:17:34.740 --> 01:17:42.100]   that you don't use all the time, let's say, like GM's Super Cruise, which is a hands-free
[01:17:42.100 --> 01:17:43.620]   driver's assistance system.
[01:17:43.620 --> 01:17:46.900]   It's not, it's not, it's not automated driving.
[01:17:46.900 --> 01:17:49.420]   It's not, you know, don't, that's not a thing you can buy.
[01:17:49.420 --> 01:17:52.060]   Don't think that's, but it's a hands-free system.
[01:17:52.060 --> 01:17:55.500]   You don't need that, let's say 99% of your life.
[01:17:55.500 --> 01:17:58.300]   And then one day you and your family are going to go on this long trip.
[01:17:58.300 --> 01:18:01.100]   You're going to be on the interstate for hours and hours and hours.
[01:18:01.100 --> 01:18:04.620]   And you're like, you know what, what if I just subscribe to this for one month?
[01:18:04.620 --> 01:18:10.460]   So for this trip, we have Super Cruise, his hands-free driver's assistance.
[01:18:10.460 --> 01:18:14.460]   And so during that, you know, eight hour drive to, you know, your grandmother's house
[01:18:14.460 --> 01:18:18.940]   or whatever or Wally World and that, you know, eight hour drive back, you have this
[01:18:18.940 --> 01:18:22.100]   extra driver's assistance system.
[01:18:22.100 --> 01:18:25.820]   For that I can see it, but for things like, you know, features in the vehicle, like heated
[01:18:25.820 --> 01:18:32.340]   seats or radio stations or, you know, the infotainment stuff, that's, that's, that's
[01:18:32.340 --> 01:18:35.500]   really nickel and diamond people who are buying cars.
[01:18:35.500 --> 01:18:39.060]   And cars are already expensive regardless of whether or not you're buying a gas car or
[01:18:39.060 --> 01:18:41.060]   you're buying an EV.
[01:18:41.060 --> 01:18:47.260]   I mean, the median price is over, it's in the 40s, 40, 45, 40 something thousand dollars.
[01:18:47.260 --> 01:18:48.580]   That's so much money.
[01:18:48.580 --> 01:18:50.620]   I can't afford a $40,000 car.
[01:18:50.620 --> 01:18:51.620]   I don't know.
[01:18:51.620 --> 01:18:55.340]   People are getting five year loans and now there's all the defaults coming, you know, 23%
[01:18:55.340 --> 01:19:04.180]   of vehicles that are financed in Washington DC are in default.
[01:19:04.180 --> 01:19:07.060]   It's, yeah, it's a crazy, crazy world.
[01:19:07.060 --> 01:19:10.540]   And the automakers are trying to figure out how to continue to make money in this new
[01:19:10.540 --> 01:19:15.860]   EV world, but it's, it's, you know, they have to tread lightly because, you know, again,
[01:19:15.860 --> 01:19:21.980]   BMW for years got hammered for charging subscriptions for, for, for car play, which is, which is
[01:19:21.980 --> 01:19:26.260]   so it just, it was just ridiculous is what it was.
[01:19:26.260 --> 01:19:30.420]   There's kind of a disconnect for me too.
[01:19:30.420 --> 01:19:35.500]   In the, and I don't know if it's semantics or what, but I, you know, I can buy a car.
[01:19:35.500 --> 01:19:37.140]   I can choose to pay for an option.
[01:19:37.140 --> 01:19:38.140]   Right.
[01:19:38.140 --> 01:19:41.420]   When I buy a car, so I buy a, then that's kind of the model that like I'm used to.
[01:19:41.420 --> 01:19:42.420]   I buy a car.
[01:19:42.420 --> 01:19:44.140]   Do you, do you want the upgrade to the blah, blah, blah?
[01:19:44.140 --> 01:19:45.140]   Yeah, sure.
[01:19:45.140 --> 01:19:46.940]   I'll get the upgrade or no, I don't want that.
[01:19:46.940 --> 01:19:51.700]   You know, and if I don't want it, it's not in there, but this is kind of like, yeah, we
[01:19:51.700 --> 01:19:52.900]   put that in there.
[01:19:52.900 --> 01:19:55.820]   We're just not letting you have it until you pay us a little bit more.
[01:19:55.820 --> 01:19:56.900]   And I don't know.
[01:19:56.900 --> 01:20:00.020]   I don't know why the disconnects doesn't work for me there.
[01:20:00.020 --> 01:20:03.900]   Like it's kind of the same thing, but it's kind of different, you know, like it's already
[01:20:03.900 --> 01:20:10.020]   where, what's happening is this happens with, with Teslas is Teslas are built with all the
[01:20:10.020 --> 01:20:15.900]   hardware for FSD or the FSD beta is full self driving, which isn't actually full self driving,
[01:20:15.900 --> 01:20:18.580]   but all the hardware is already built into the vehicle.
[01:20:18.580 --> 01:20:24.500]   So if you don't buy FSD, Tesla that reduces their margins on the sale of that vehicle.
[01:20:24.500 --> 01:20:27.420]   So they're always pushing you like, Hey, you want to do this, you want to do this, you
[01:20:27.420 --> 01:20:28.420]   want to do this.
[01:20:28.420 --> 01:20:31.980]   And so much of what is coming out in vehicles now is software based.
[01:20:31.980 --> 01:20:34.380]   So the software, the hardware is already built into the vehicles.
[01:20:34.380 --> 01:20:40.340]   It's, you know, if you can reduce the amount of trim levels or that you're building, that
[01:20:40.340 --> 01:20:41.740]   makes it easier to build cars.
[01:20:41.740 --> 01:20:45.260]   If you're building just two trim levels and they have one has all the hardware for, and
[01:20:45.260 --> 01:20:48.460]   all the software for this and one has all the, all the hardware and all the software for
[01:20:48.460 --> 01:20:50.100]   this trim level.
[01:20:50.100 --> 01:20:51.340]   And you just push them through.
[01:20:51.340 --> 01:20:55.860]   And then there are features that you can either add when you add, when you buy it or
[01:20:55.860 --> 01:21:00.340]   add later on, that's, you know, that's extra money for them because they've already built
[01:21:00.340 --> 01:21:01.340]   it in.
[01:21:01.340 --> 01:21:04.980]   It's easier just to bake it in, especially when it comes to software into the vehicle
[01:21:04.980 --> 01:21:06.580]   as opposed to like piecemeal it.
[01:21:06.580 --> 01:21:10.100]   Oh, this person wants this person wants that this person wants this.
[01:21:10.100 --> 01:21:11.540]   So that's where it's changing.
[01:21:11.540 --> 01:21:15.260]   And you know, vehicles are now evolving because of over the air updates.
[01:21:15.260 --> 01:21:20.420]   You can buy a car now that in three months, six months, especially if it's an EV, it might
[01:21:20.420 --> 01:21:25.420]   have better range because they figured out, you know, what, you know, with all the driving
[01:21:25.420 --> 01:21:28.980]   that people are doing with the vehicles, they're like, oh, you know, if we adjust this in the
[01:21:28.980 --> 01:21:34.260]   acceleration or if we adjust this with the way that the, it's charging and discharging,
[01:21:34.260 --> 01:21:36.380]   we can give people an extra five miles.
[01:21:36.380 --> 01:21:37.660]   And so that's great.
[01:21:37.660 --> 01:21:39.900]   But it also opened again, it opens up for this idea.
[01:21:39.900 --> 01:21:45.220]   Like, well, if you want this feature, we'll charge you a subscription, but you can also
[01:21:45.220 --> 01:21:47.900]   like go out and buy a car and be like, you know, I don't want this.
[01:21:47.900 --> 01:21:50.580]   And then later on, change your mind, which you can't do with, you know, you couldn't
[01:21:50.580 --> 01:21:52.060]   do traditionally with cars.
[01:21:52.060 --> 01:21:54.060]   So it's, it's sort of give and take.
[01:21:54.060 --> 01:21:57.700]   And for, for every good thing, there's always going to be something where like, oh my God,
[01:21:57.700 --> 01:21:58.700]   really?
[01:21:58.700 --> 01:22:03.700]   I mean, I've got three, I like in my, so in my Tesla app, right there, I've got three
[01:22:03.700 --> 01:22:04.700]   available.
[01:22:04.700 --> 01:22:06.500]   I've got acceleration boost.
[01:22:06.500 --> 01:22:09.900]   I can get a hands autopilot, which I didn't have an option for before.
[01:22:09.900 --> 01:22:13.420]   That's a new one that they, they used to have and then they didn't have it.
[01:22:13.420 --> 01:22:15.460]   And now that apparently they have it again.
[01:22:15.460 --> 01:22:17.020]   And then full self driving.
[01:22:17.020 --> 01:22:19.780]   So it's a, sorry, it's my, my poor cameras.
[01:22:19.780 --> 01:22:20.780]   Very sad.
[01:22:20.780 --> 01:22:24.540]   But yeah, and then, and then you have a subscription stuff where it's like, you know, hey, here's
[01:22:24.540 --> 01:22:28.820]   your $200 a month or whatever, if you want to just subscribe.
[01:22:28.820 --> 01:22:33.460]   So that's a, yeah, and they're constantly like, I'll get a little notification or whatever
[01:22:33.460 --> 01:22:39.180]   from my Tesla app and it'll be like, Hey, friend, how are you feeling about a.
[01:22:39.180 --> 01:22:43.100]   Just take a look at these upgrades that we might have for you.
[01:22:43.100 --> 01:22:47.620]   Like just, just look, we're no pressure, no pressure, but also if you want to drive your
[01:22:47.620 --> 01:22:51.100]   car a little bit faster, we could do that for you for $2,000 for the low, low price
[01:22:51.100 --> 01:22:52.460]   of two grand.
[01:22:52.460 --> 01:22:56.500]   And so yeah, they, they really, like, I will say it's not annoying.
[01:22:56.500 --> 01:23:04.100]   I don't have like constant, it's not constant in app advertising from my car manufacturer.
[01:23:04.100 --> 01:23:05.100]   Thank God.
[01:23:05.100 --> 01:23:06.100]   That would drive me crazy.
[01:23:06.100 --> 01:23:11.100]   But, um, but it is, but it is there every now and again, I get a little, little notification.
[01:23:11.100 --> 01:23:13.380]   That's like, Hey, you should, you should check the upgrade section.
[01:23:13.380 --> 01:23:14.380]   There's some new stuff in there.
[01:23:14.380 --> 01:23:19.500]   Like, or, or I don't know if you forgot, but you didn't buy full self driving and you
[01:23:19.500 --> 01:23:20.980]   might want to check that out now.
[01:23:20.980 --> 01:23:22.980]   Maybe it's maybe now you're interested in it.
[01:23:22.980 --> 01:23:27.900]   And so they just sort of like remind you that it exists every, every now and again.
[01:23:27.900 --> 01:23:34.740]   So that's, um, yeah, it's, it is very interesting how cars, especially EVs are just becoming
[01:23:34.740 --> 01:23:39.580]   so much more software based, which I know drives my dad crazy because he has a, he has
[01:23:39.580 --> 01:23:43.880]   an Ionic and they did a software update and it changed like the entire UI very similarly
[01:23:43.880 --> 01:23:48.340]   to how Tesla changes UI like a year and a half ago, a couple of years ago.
[01:23:48.340 --> 01:23:52.260]   And, um, and he, he was like, Oh, I have to relearn where everything is, it's driving
[01:23:52.260 --> 01:23:53.260]   me crazy.
[01:23:53.260 --> 01:23:54.460]   Like, he's, and he's just mad.
[01:23:54.460 --> 01:23:56.300]   Like he's furious about it.
[01:23:56.300 --> 01:23:57.300]   He's in his early 60s.
[01:23:57.300 --> 01:23:58.300]   He's just so mad about it.
[01:23:58.300 --> 01:24:00.220]   He's just like, Oh, I had to read, I had to look for everything.
[01:24:00.220 --> 01:24:01.380]   I didn't know where anything was.
[01:24:01.380 --> 01:24:04.620]   And, you know, it's just, yeah, that, that is frustrating.
[01:24:04.620 --> 01:24:08.580]   It's like, you know, you really have like all of your dials and everything else, you know,
[01:24:08.580 --> 01:24:10.340]   your, your screen dials, whatever.
[01:24:10.340 --> 01:24:13.700]   I don't have any dials on my car except for the two little wheels.
[01:24:13.700 --> 01:24:17.060]   But, um, but yeah, and then it's, you know, you use your screen and, and then all of a
[01:24:17.060 --> 01:24:18.420]   sudden everything's different.
[01:24:18.420 --> 01:24:23.180]   Some stuff that you use kind of one touch is now buried under two or three sub menus.
[01:24:23.180 --> 01:24:25.580]   There's like, I mean, it's a whole, is a whole ordeal.
[01:24:25.580 --> 01:24:28.140]   And I know it actually like is better.
[01:24:28.140 --> 01:24:32.780]   Like I know that that UI is more efficient in a lot of ways, but it's just, I'm so used
[01:24:32.780 --> 01:24:36.060]   to the previous one that it, you kind of grade against it.
[01:24:36.060 --> 01:24:40.020]   You're sort of begrudging on, uh, get having to learn this new UI.
[01:24:40.020 --> 01:24:42.940]   So I'm sure they'll change it again and they'll do a big revamp of it.
[01:24:42.940 --> 01:24:46.460]   It's someday, but, um, but yeah, it's like very annoying for a lot of people who are
[01:24:46.460 --> 01:24:51.060]   just used to traditional cars or you have just gauges and dials and like that's it.
[01:24:51.060 --> 01:24:52.060]   And it's, oh, okay.
[01:24:52.060 --> 01:24:55.460]   Well, and then you got your screen that has sort of your, your phone apps or whatever
[01:24:55.460 --> 01:24:59.300]   on it, your infotainment, but everything else is just right in front of you and it's always
[01:24:59.300 --> 01:25:00.940]   there and it's never going to change.
[01:25:00.940 --> 01:25:05.420]   So it's very, uh, very difficult for a lot of folks who are not used to that to like start
[01:25:05.420 --> 01:25:06.420]   getting used to that.
[01:25:06.420 --> 01:25:07.420]   Yeah.
[01:25:07.420 --> 01:25:10.900]   It's a big thing about muscle memory and how we, you know, after you've driven a car for
[01:25:10.900 --> 01:25:12.900]   a long time, you know where the volume control is.
[01:25:12.900 --> 01:25:14.180]   You know where the climate control is.
[01:25:14.180 --> 01:25:17.380]   You know where this is, and even with, if you have an infotainment screen, you know where
[01:25:17.380 --> 01:25:21.420]   things are because you've been using it, like, you know, your dad got used to the way the
[01:25:21.420 --> 01:25:23.040]   ionic was laid out.
[01:25:23.040 --> 01:25:25.740]   And then they're like, oh, you know what?
[01:25:25.740 --> 01:25:27.500]   We're just going to change it.
[01:25:27.500 --> 01:25:30.460]   And again, maybe they change it for the better, but maybe they change it for the worse.
[01:25:30.460 --> 01:25:35.040]   I mean, again, it's, you know, building a UI for a vehicle that's flying down the road
[01:25:35.040 --> 01:25:37.060]   to 70 miles an hour is difficult.
[01:25:37.060 --> 01:25:41.120]   Um, but you know, when you change that muscle memory, now it's like getting into a rental
[01:25:41.120 --> 01:25:42.120]   car.
[01:25:42.120 --> 01:25:43.120]   You're like, well, where is everything?
[01:25:43.120 --> 01:25:44.120]   You know, yeah.
[01:25:44.120 --> 01:25:45.820]   And that is literally my life.
[01:25:45.820 --> 01:25:51.560]   Every week I get a new car and every week I'm like, oh, okay.
[01:25:51.560 --> 01:25:52.960]   How do I turn on the wipers?
[01:25:52.960 --> 01:25:58.340]   Like I'm flashing lights at people or I'm a professional automotive journalist and I'm
[01:25:58.340 --> 01:26:01.580]   just flashing high beams at people all the time trying to figure out how to turn out
[01:26:01.580 --> 01:26:06.740]   the, the, the windshield wipers on because sometimes people are like, oh, it's right here,
[01:26:06.740 --> 01:26:08.040]   but you don't pull it to do this.
[01:26:08.040 --> 01:26:11.280]   You do, you know, you do this or it's way over here in the infotainment system, which
[01:26:11.280 --> 01:26:15.100]   is just, oh, don't even get me started in windshield wipers and infotainment.
[01:26:15.100 --> 01:26:19.240]   But yeah, yeah, it's, it's again, there's, there's, there's a, there's a good and the
[01:26:19.240 --> 01:26:24.600]   bad of the whole like, you know, the tech, the, the rise of tech and vehicles.
[01:26:24.600 --> 01:26:27.620]   And for the most part, it's good, but there are, there are some things that are just,
[01:26:27.620 --> 01:26:29.720]   just painfully frustrating.
[01:26:29.720 --> 01:26:32.880]   There's something that concerns me though about tech in vehicles.
[01:26:32.880 --> 01:26:37.160]   And I don't know if this is just outdated thinking or what, but I have a neighbor who
[01:26:37.160 --> 01:26:44.040]   has a Tesla Model X got it very early on and we've had the opportunity to, you know,
[01:26:44.040 --> 01:26:45.560]   drive it, borrow it.
[01:26:45.560 --> 01:26:50.320]   It's a long story, but we trade trailers for Teslas sometimes and they need to, you
[01:26:50.320 --> 01:26:53.200]   know, pull their trailer, they borrow our sequoia and we get their Tesla.
[01:26:53.200 --> 01:26:55.360]   So it's kind of a, kind of a sweet deal.
[01:26:55.360 --> 01:27:01.000]   Anyways, my point is anytime I'm in his vehicle, which at this point, if I had to guess probably
[01:27:01.000 --> 01:27:07.120]   like six years old, let's say somewhere around there, the, the in, in dash system,
[01:27:07.120 --> 01:27:10.040]   is like crazy laggy.
[01:27:10.040 --> 01:27:16.760]   Like every time you do anything, it just makes me think like, as we kind of pursue further
[01:27:16.760 --> 01:27:23.840]   this, this world filled with, you know, vehicles who are half computer, half vehicle, and more
[01:27:23.840 --> 01:27:28.880]   and more of that technology is, is infused inside of the vehicle.
[01:27:28.880 --> 01:27:33.160]   Will we run into what we run into now with our desktop computers and our laptops, which
[01:27:33.160 --> 01:27:37.960]   is that a, you know, six to eight years, some, somewhere down the line, this, this thing
[01:27:37.960 --> 01:27:44.000]   that was once very, very capable is canelica sure can do it, but it's just a lot slower
[01:27:44.000 --> 01:27:46.600]   and like, what is it going to be in 20 years?
[01:27:46.600 --> 01:27:47.600]   I see.
[01:27:47.600 --> 01:27:48.600]   I got like, I disagree with this.
[01:27:48.600 --> 01:27:53.640]   This is the same thing as having like, you know, a transmission replaced.
[01:27:53.640 --> 01:27:55.560]   You're just going to go and get your computer chip upgraded.
[01:27:55.560 --> 01:27:57.360]   Just swap out the chip.
[01:27:57.360 --> 01:28:01.720]   Just see, it'll cost, it'll cost you a arm and a leg, but you'll just be able to swap
[01:28:01.720 --> 01:28:03.280]   the chip, get it upgraded.
[01:28:03.280 --> 01:28:07.800]   That's actually quite, quite difficult because there's, there's, there's so integrated with
[01:28:07.800 --> 01:28:08.800]   the entire system.
[01:28:08.800 --> 01:28:12.880]   So it's, it's less likely they're going to do that and it's, it's, I mean, it's,
[01:28:12.880 --> 01:28:18.120]   I mean, it's, it's the most part, those vehicles are, you know, they're more and more the automakers
[01:28:18.120 --> 01:28:23.720]   are using, you know, quicker and quicker GPUs from, and mostly it's Nvidia, to be honest.
[01:28:23.720 --> 01:28:28.920]   I mean, video has built a whole new, a whole new headquarters just from all the money they're
[01:28:28.920 --> 01:28:30.280]   making from automakers.
[01:28:30.280 --> 01:28:34.920]   And I think for the, you know, automakers are, are they realized that these infotainment
[01:28:34.920 --> 01:28:40.020]   systems need to be quick day one and, you know, 15 years later.
[01:28:40.020 --> 01:28:45.080]   So at some point, your vehicle will still get upgrades, but at that point, they're just
[01:28:45.080 --> 01:28:46.080]   fixes.
[01:28:46.080 --> 01:28:49.480]   You're not getting new, you're not getting like old iPhones.
[01:28:49.480 --> 01:28:50.880]   Yeah, like an old iPhone.
[01:28:50.880 --> 01:28:54.880]   So say you're not compatible with the newest software upgrade, like you're going to stay
[01:28:54.880 --> 01:28:57.080]   at this version or whatever.
[01:28:57.080 --> 01:28:58.080]   Yeah.
[01:28:58.080 --> 01:29:01.520]   It's just way more than what a traditional car.
[01:29:01.520 --> 01:29:07.320]   It does feel like at some point, we may get to a place where we could upgrade the way
[01:29:07.320 --> 01:29:13.000]   we do a computer, but I don't think that that is close by, like under, by any means, but
[01:29:13.000 --> 01:29:17.240]   I do think that that would be like, because that's just more money, right?
[01:29:17.240 --> 01:29:21.200]   That, that a car company could get out of you if you were not planning on buying a new
[01:29:21.200 --> 01:29:23.920]   car every, you know, eight to 10 years.
[01:29:23.920 --> 01:29:26.520]   They'll just, what you already do with Tesla.
[01:29:26.520 --> 01:29:27.520]   Yeah, that's true.
[01:29:27.520 --> 01:29:33.200]   Yeah, it's, you know, it's, it's, especially the early days of last like 10 years, you know,
[01:29:33.200 --> 01:29:38.360]   you've had what people want versus what the automakers could deliver.
[01:29:38.360 --> 01:29:41.840]   And Tesla had the same problem when it comes to the speed of their, their infotainment system.
[01:29:41.840 --> 01:29:45.640]   You have laggies, you have, you have screens that just turn off, you have screens that
[01:29:45.640 --> 01:29:50.960]   are half dead, you know, automakers would put in features or they would have code that
[01:29:50.960 --> 01:29:54.600]   just wasn't, you know, optimized for the, for the hardware.
[01:29:54.600 --> 01:29:58.640]   So you have, you know, you have screens that are, you know, you end up with this latency
[01:29:58.640 --> 01:30:01.120]   issue and it's software is really difficult.
[01:30:01.120 --> 01:30:02.120]   Just ask Volkswagen.
[01:30:02.120 --> 01:30:07.160]   They, they released the ID three and the ID four and both of those, the hardware was fine.
[01:30:07.160 --> 01:30:12.200]   The software just wasn't up, wasn't ready and they released these vehicles and people
[01:30:12.200 --> 01:30:16.920]   had these cars for a year before Volkswagen updated them so that the infotainment system
[01:30:16.920 --> 01:30:18.960]   wasn't just a laggy mess.
[01:30:18.960 --> 01:30:24.280]   Like that was really the number one, like, issue with that vehicle was that the software
[01:30:24.280 --> 01:30:25.960]   wasn't ready for the infotainment system.
[01:30:25.960 --> 01:30:28.640]   So you're telling people like, Hey, you can buy this car.
[01:30:28.640 --> 01:30:29.640]   Sure.
[01:30:29.640 --> 01:30:34.280]   But when you do this, expect the screen to wait and then move, expect that to happen
[01:30:34.280 --> 01:30:36.000]   because the software is not ready yet.
[01:30:36.000 --> 01:30:37.960]   And now, you know, they've upgraded it.
[01:30:37.960 --> 01:30:43.160]   But I mean, how embarrassing is that for one of the world's largest automakers in the
[01:30:43.160 --> 01:30:48.520]   world they make the, they, they, Lamborghini, Audi, see out.
[01:30:48.520 --> 01:30:54.720]   I mean, they own a ton of, of, of companies and they, that's how hard software is is that
[01:30:54.720 --> 01:31:01.640]   this company couldn't get their first real big, like, you know, the real big current
[01:31:01.640 --> 01:31:05.400]   generation EV onto the road with infotainment that wasn't laggy.
[01:31:05.400 --> 01:31:06.960]   It's, yeah, it's, it's, yeah.
[01:31:06.960 --> 01:31:08.400]   Megan, what were you saying?
[01:31:08.400 --> 01:31:09.800]   Like you were asking about Tesla.
[01:31:09.800 --> 01:31:10.800]   Yeah.
[01:31:10.800 --> 01:31:13.280]   Like, I mean, isn't that similar to how you upgrade a computer?
[01:31:13.280 --> 01:31:17.160]   Like you just upgraded, like, you know, processing the button and you upgraded.
[01:31:17.160 --> 01:31:18.160]   Is that what you were talking about?
[01:31:18.160 --> 01:31:22.840]   Oh, I mean, like switching out the actual chip, like, so getting, you know, which is
[01:31:22.840 --> 01:31:23.840]   a, yeah, the hardware.
[01:31:23.840 --> 01:31:29.600]   I know that there were some hardware updates like for some of the older, was it the Model
[01:31:29.600 --> 01:31:34.600]   S's Roberto, where it was like the model S is who had paid for full self driving, but
[01:31:34.600 --> 01:31:36.560]   had not, they did not have the capacity.
[01:31:36.560 --> 01:31:39.360]   So then there was, that was like, they will.
[01:31:39.360 --> 01:31:40.360]   Okay.
[01:31:40.360 --> 01:31:41.360]   Cool.
[01:31:41.360 --> 01:31:45.160]   But we also, you're really old Teslas, like, don't actually, they can't actually run this.
[01:31:45.160 --> 01:31:47.600]   So we need to upgrade some of your stuff.
[01:31:47.600 --> 01:31:51.480]   There was like a whole, I don't like, maybe I'm misremembering some of the specifics here.
[01:31:51.480 --> 01:31:54.920]   There was a, there was a whole upgrade you could do in order to, it was a hard, it was
[01:31:54.920 --> 01:31:55.920]   a hard, it was a hardware package.
[01:31:55.920 --> 01:31:56.920]   It was a hardware thing.
[01:31:56.920 --> 01:32:00.360]   It was like $1,500 or $1,800 or $2,400.
[01:32:00.360 --> 01:32:04.520]   People were so mad because they were like, I already paid $10,000 for full self driving
[01:32:04.520 --> 01:32:07.160]   and now you're going to ask me for another $1,500.
[01:32:07.160 --> 01:32:08.160]   Yeah.
[01:32:08.160 --> 01:32:12.480]   It's, it's, and that's where it gets really weird because you're selling thing.
[01:32:12.480 --> 01:32:16.120]   And in Tesla does this a lot where they're selling future, they're selling something for
[01:32:16.120 --> 01:32:18.480]   the future as opposed to something that you're buying now.
[01:32:18.480 --> 01:32:23.120]   So you, when you buy FSD and then the prices keeps going up, which is, you know, they just
[01:32:23.120 --> 01:32:25.800]   need money is essentially what they need.
[01:32:25.800 --> 01:32:29.680]   That's why the price continues to go up because most things when, as technology gets better,
[01:32:29.680 --> 01:32:33.640]   the price goes down, but for FSD, it's like the other direction or you're just like, all
[01:32:33.640 --> 01:32:34.960]   right, fine, whatever.
[01:32:34.960 --> 01:32:38.200]   But yeah, you're paying for a future product.
[01:32:38.200 --> 01:32:43.920]   You're not paying for something that's really, that's really usable as a, what it's supposed
[01:32:43.920 --> 01:32:44.920]   to do right now.
[01:32:44.920 --> 01:32:48.240]   You're paying for, it's like, you're paying to be a beta tester.
[01:32:48.240 --> 01:32:49.240]   You're paying to be a beta tester.
[01:32:49.240 --> 01:32:50.240]   Yeah.
[01:32:50.240 --> 01:32:51.320]   Like, look, if you want to do that, that's fine.
[01:32:51.320 --> 01:32:52.320]   I didn't.
[01:32:52.320 --> 01:32:59.160]   I just would, I wanted, I just wanted a car and I liked, I liked my model three a lot.
[01:32:59.160 --> 01:33:03.920]   And I just didn't want to fold my very giant toddler in half to put him in the backseat.
[01:33:03.920 --> 01:33:06.560]   So I decided to get a model Y.
[01:33:06.560 --> 01:33:11.800]   But yeah, it's just, we don't, we don't even have the infrastructure really support full
[01:33:11.800 --> 01:33:12.800]   self driving.
[01:33:12.800 --> 01:33:16.600]   Like in California, our roads are bonkers.
[01:33:16.600 --> 01:33:18.920]   Like I don't, has anybody, like we have bottles everywhere.
[01:33:18.920 --> 01:33:20.880]   It's just, I don't know.
[01:33:20.880 --> 01:33:25.760]   I don't, I'm not, I feel like our state is not necessarily even the cars.
[01:33:25.760 --> 01:33:29.680]   It's just, there are so many variables on side roads that I'm just like, nah, nah, I'm
[01:33:29.680 --> 01:33:30.680]   good.
[01:33:30.680 --> 01:33:32.920]   I think I'll just, well, that's, that's the thing is it is the cars.
[01:33:32.920 --> 01:33:34.400]   It is the cars.
[01:33:34.400 --> 01:33:38.440]   The cars have to understand all these edge cases and everyone thought they could do it
[01:33:38.440 --> 01:33:39.680]   five years ago.
[01:33:39.680 --> 01:33:44.360]   And then they got 90% there and then they realized, oh no, this is really hard.
[01:33:44.360 --> 01:33:45.960]   This is really, really, really hard.
[01:33:45.960 --> 01:33:48.000]   It's like almost infinite edge cases.
[01:33:48.000 --> 01:33:49.920]   It's just, it's so difficult.
[01:33:49.920 --> 01:33:51.400]   It's a really hard problem to solve.
[01:33:51.400 --> 01:33:56.160]   And that's why we consistently have this like, oh, we're five years away from full self driving.
[01:33:56.160 --> 01:33:59.600]   We're 10 years away from a like true AI passing the Turing test.
[01:33:59.600 --> 01:34:03.840]   It's just like you get to that point and then you realize there's so much more that
[01:34:03.840 --> 01:34:07.800]   you didn't realize or know before that now you have to account for and factor in for
[01:34:07.800 --> 01:34:09.760]   and then, and then program for.
[01:34:09.760 --> 01:34:11.640]   And so it's just keeps getting pushed out little by little.
[01:34:11.640 --> 01:34:17.320]   I mean, we've been, I feel like humans have been saying, oh, we're going to have robots
[01:34:17.320 --> 01:34:20.280]   that are sent, you know, sentient AI since like the 50s.
[01:34:20.280 --> 01:34:24.040]   They're like, oh, in 20 years, we'll have robots that's always like all stuff.
[01:34:24.040 --> 01:34:25.040]   Yeah.
[01:34:25.040 --> 01:34:26.040]   It's always 20 years away.
[01:34:26.040 --> 01:34:29.120]   And so, you know, maybe someday we'll close that gap, but for right now it feels like it's
[01:34:29.120 --> 01:34:31.920]   still kind of in a similar, similar space.
[01:34:31.920 --> 01:34:32.920]   Yeah.
[01:34:32.920 --> 01:34:37.240]   Broad strokes are a little bit easier than the fine details.
[01:34:37.240 --> 01:34:41.840]   Once you get to the fine detail point, there's just a myriad of problems in there to solve.
[01:34:41.840 --> 01:34:42.840]   Yeah.
[01:34:42.840 --> 01:34:43.840]   It's just hard.
[01:34:43.840 --> 01:34:44.840]   It's a hard problem.
[01:34:44.840 --> 01:34:45.840]   It's like the daily space.
[01:34:45.840 --> 01:34:46.840]   Yes.
[01:34:46.840 --> 01:34:47.840]   Yeah.
[01:34:47.840 --> 01:34:51.320]   It's like we've, we've just barely got them to make bears that can eat cows.
[01:34:51.320 --> 01:34:57.160]   Like we, let's say AI is good for making bears that eat cows, serving you ads and the
[01:34:57.160 --> 01:35:04.160]   crap is really about it.
[01:35:04.160 --> 01:35:06.400]   Remember, we were all supposed to lose our jobs as writers because AI was going to write
[01:35:06.400 --> 01:35:10.240]   all of our articles and then they did it and they're like, oh yeah, this is hilarious,
[01:35:10.240 --> 01:35:13.840]   but it's completely not usable.
[01:35:13.840 --> 01:35:14.840]   Not yet.
[01:35:14.840 --> 01:35:15.840]   Yeah.
[01:35:15.840 --> 01:35:17.720]   That's what they keep saying.
[01:35:17.720 --> 01:35:18.880]   Everything's not yet.
[01:35:18.880 --> 01:35:20.240]   And at some point you're like, you know what?
[01:35:20.240 --> 01:35:22.480]   It's just easier just to have a human right.
[01:35:22.480 --> 01:35:23.480]   Yep.
[01:35:23.480 --> 01:35:24.480]   It's easier.
[01:35:24.480 --> 01:35:26.400]   You mean drive a car.
[01:35:26.400 --> 01:35:28.840]   It's just easier to let a human draw a picture.
[01:35:28.840 --> 01:35:29.840]   Yeah.
[01:35:29.840 --> 01:35:31.760]   They all appreciate having jobs.
[01:35:31.760 --> 01:35:32.760]   So that's good too.
[01:35:32.760 --> 01:35:33.760]   Yeah.
[01:35:33.760 --> 01:35:34.760]   Yeah.
[01:35:34.760 --> 01:35:35.760]   All right.
[01:35:35.760 --> 01:35:36.760]   Let's take a break.
[01:35:36.760 --> 01:35:38.520]   This is so much fun.
[01:35:38.520 --> 01:35:44.400]   Love doing this show with the three of you, Ashley, Esquetha, Roberto Baldwin, Megan Moroni.
[01:35:44.400 --> 01:35:48.480]   I just, I completely lucked out with having you three on the show today.
[01:35:48.480 --> 01:35:49.480]   So thank you.
[01:35:49.480 --> 01:35:52.440]   This episode is brought to you by stamps.com.
[01:35:52.440 --> 01:35:57.800]   When you're running a small business, you already know every second counts, right?
[01:35:57.800 --> 01:36:00.680]   You can't afford to waste a single moment.
[01:36:00.680 --> 01:36:02.800]   Business just moves too fast.
[01:36:02.800 --> 01:36:06.720]   So why are you still taking time out of your day to go to the post office when you could
[01:36:06.720 --> 01:36:09.160]   be using stamps.com instead?
[01:36:09.160 --> 01:36:10.600]   Literally it's going to save you a trip.
[01:36:10.600 --> 01:36:12.480]   It's going to save you many trips.
[01:36:12.480 --> 01:36:17.440]   Stamps.com makes mailing and shipping quick, easy and cost effective.
[01:36:17.440 --> 01:36:20.760]   And not only that, we, you know, we put our money where our mouth is.
[01:36:20.760 --> 01:36:27.760]   We use stamps here at Twitch and stamps.com has been a partner of this show since 2012.
[01:36:27.760 --> 01:36:30.160]   And we've been talking about them since then as well.
[01:36:30.160 --> 01:36:32.840]   So if you haven't tried them yet, what are you waiting for?
[01:36:32.840 --> 01:36:36.000]   Literally, we rely on stamps.com.
[01:36:36.000 --> 01:36:37.400]   Stamps.com saves you time.
[01:36:37.400 --> 01:36:39.400]   It saves you money and stress.
[01:36:39.400 --> 01:36:45.320]   For more than 20 years, stamps.com has been indispensable for over 1 million businesses.
[01:36:45.320 --> 01:36:50.480]   And stamps.com gives you access to all the post office and UPS shipping services that
[01:36:50.480 --> 01:36:52.600]   you need right from your computer.
[01:36:52.600 --> 01:36:55.280]   So it's just a heck of a lot more convenient.
[01:36:55.280 --> 01:36:58.080]   And it's good for your pocketbook as well.
[01:36:58.080 --> 01:36:59.080]   You get discounts.
[01:36:59.080 --> 01:37:06.360]   You can't find anywhere else like up to 30% off USPS rates and 86% off UPS.
[01:37:06.360 --> 01:37:07.360]   How about that?
[01:37:07.360 --> 01:37:11.440]   Streamline your shipping process with stamps.com's easy to use software.
[01:37:11.440 --> 01:37:12.800]   Their software is awesome.
[01:37:12.800 --> 01:37:16.080]   All you need is your regular computer and a printer.
[01:37:16.080 --> 01:37:19.120]   Other than that, no special supplies or equipment needed.
[01:37:19.120 --> 01:37:20.480]   You're up and running in minutes.
[01:37:20.480 --> 01:37:25.720]   You're printing official postage for any letter, any package, anywhere you want to send it.
[01:37:25.720 --> 01:37:27.240]   All done just easily.
[01:37:27.240 --> 01:37:32.720]   It seamlessly works with Shopify, Amazon, Etsy, eBay and more.
[01:37:32.720 --> 01:37:39.120]   If you're running an Etsy shop or you're sending someone selling something on eBay, instead
[01:37:39.120 --> 01:37:44.200]   of sending them that package with the Sharpie and their name scribbled in, hopefully it's
[01:37:44.200 --> 01:37:48.120]   legible enough or whatever, they receive it and they go, "Okay.
[01:37:48.120 --> 01:37:53.640]   I'm really hoping I find inside what I expect to find."
[01:37:53.640 --> 01:37:55.880]   There's a professionalism that is presented.
[01:37:55.880 --> 01:38:00.120]   When you use stamps.com for your postage instead, things look professional.
[01:38:00.120 --> 01:38:01.720]   You look like a legit business.
[01:38:01.720 --> 01:38:02.720]   That's the point.
[01:38:02.720 --> 01:38:07.160]   So whether you're an office sending invoices, whether you're an Etsy shop, like I said,
[01:38:07.160 --> 01:38:11.600]   sending your products or a warehouse shipping out orders, stamps.com is your mailing and
[01:38:11.600 --> 01:38:13.160]   shipping solution.
[01:38:13.160 --> 01:38:15.240]   You really should check them out.
[01:38:15.240 --> 01:38:21.440]   Stop wasting time, start saving money when you use stamps.com to mail and ship.
[01:38:21.440 --> 01:38:26.960]   Sign up with promo code TWIT for a special offer that includes a four-week trial plus
[01:38:26.960 --> 01:38:31.880]   free postage and you get a digital scale as well, super handy.
[01:38:31.880 --> 01:38:34.040]   No long-term commitments or contracts.
[01:38:34.040 --> 01:38:37.720]   Just go to stamps.com and then on the page, you'll see a microphone.
[01:38:37.720 --> 01:38:38.720]   Click that.
[01:38:38.720 --> 01:38:44.320]   That's at the top of the page and enter code TWIT, TWIT, and you will be happy that you
[01:38:44.320 --> 01:38:45.880]   did.
[01:38:45.880 --> 01:38:47.280]   We love stamps.com.
[01:38:47.280 --> 01:38:50.000]   You got to check them out and you'll see you'll love them as well.
[01:38:50.000 --> 01:38:52.200]   Stamps.com.
[01:38:52.200 --> 01:38:53.560]   Click that microphone.
[01:38:53.560 --> 01:39:00.920]   Enter code TWIT and we thank stamps.com for their support of This Week in Tech.
[01:39:00.920 --> 01:39:05.400]   Any stories jumping out for you, for any one of you that you're like, "You know what?
[01:39:05.400 --> 01:39:08.600]   We have to, before this show is over, we have to talk about this one thing.
[01:39:08.600 --> 01:39:10.720]   I'm open to anything at this point.
[01:39:10.720 --> 01:39:11.720]   What you got?"
[01:39:11.720 --> 01:39:19.880]   I just put a story in there that one of my reporters at Protocol Road, it's a little
[01:39:19.880 --> 01:39:20.880]   push.
[01:39:20.880 --> 01:39:24.880]   Lizzie Lawrence wrote about an email program called Gated.
[01:39:24.880 --> 01:39:31.520]   I don't know if you've heard of it, but how it works is if someone wants to email you,
[01:39:31.520 --> 01:39:35.480]   they have to donate to charity in order to get into your inbox.
[01:39:35.480 --> 01:39:41.040]   The idea is to shift the onus because at this point, spammers can spam us.
[01:39:41.040 --> 01:39:44.320]   They can send us email.
[01:39:44.320 --> 01:39:46.240]   We have to go through and delete it.
[01:39:46.240 --> 01:39:49.120]   Sometimes our spam filter works.
[01:39:49.120 --> 01:39:50.120]   Sometimes it doesn't.
[01:39:50.120 --> 01:39:53.800]   But basically, the onus is on us, not on the spammer.
[01:39:53.800 --> 01:40:00.840]   This is a new program that would be, if you really want access to me, you have to pay.
[01:40:00.840 --> 01:40:04.360]   She interviewed a couple of experts on how they felt about that.
[01:40:04.360 --> 01:40:14.640]   It seems a little bit elitist and a little bit like the idea around Calendly.
[01:40:14.640 --> 01:40:17.920]   There was a little bit of an uproar because it's like, "Oh, well, if you want access
[01:40:17.920 --> 01:40:21.120]   to me, you have to do this."
[01:40:21.120 --> 01:40:22.880]   It didn't have money.
[01:40:22.880 --> 01:40:27.840]   I thought it was an interesting thing to discuss because I am not as annoyed by spam
[01:40:27.840 --> 01:40:29.200]   as I used to be.
[01:40:29.200 --> 01:40:31.640]   It's just sort of a delete, delete, delete.
[01:40:31.640 --> 01:40:32.640]   I know what I'm going to do.
[01:40:32.640 --> 01:40:33.640]   I'm not.
[01:40:33.640 --> 01:40:38.760]   I don't know that I would use this, but curious if either of any of you would.
[01:40:38.760 --> 01:40:40.160]   Can you whitelist people?
[01:40:40.160 --> 01:40:45.160]   If I want a whitelist, my mom doesn't have to get a quarter every time to shoot.
[01:40:45.160 --> 01:40:48.600]   You can actually whitelist anyone.
[01:40:48.600 --> 01:40:50.600]   Your mom has to pay extra.
[01:40:50.600 --> 01:40:53.840]   Can you actually force someone to pay extra?
[01:40:53.840 --> 01:40:54.840]   That's my question.
[01:40:54.840 --> 01:40:56.600]   That's my fault.
[01:40:56.600 --> 01:41:02.600]   Also, where is the version of Gated where people have to just directly pay?
[01:41:02.600 --> 01:41:03.600]   Me.
[01:41:03.600 --> 01:41:07.160]   It goes right into my cell and it's a quarter.
[01:41:07.160 --> 01:41:09.640]   Every time someone wants to email me, I just get a quarter.
[01:41:09.640 --> 01:41:14.360]   Just please email me and pay for the privilege of being in my inbox.
[01:41:14.360 --> 01:41:16.480]   I'll deal with it whenever spares, whatever.
[01:41:16.480 --> 01:41:17.480]   Fine.
[01:41:17.480 --> 01:41:19.320]   Just directly to just cut me a check.
[01:41:19.320 --> 01:41:20.320]   That's the charity I need.
[01:41:20.320 --> 01:41:25.200]   Which I'll just come to after nice and he was like...
[01:41:25.200 --> 01:41:28.880]   The AE foundation, they're like, "What's this for?"
[01:41:28.880 --> 01:41:31.760]   "It'll go to a good cause."
[01:41:31.760 --> 01:41:34.520]   Very small, it goes to a good cause.
[01:41:34.520 --> 01:41:39.440]   Some very thin dogs that are very needy, that have a lot of food needs.
[01:41:39.440 --> 01:41:41.200]   I'm not going to say that.
[01:41:41.200 --> 01:41:42.200]   I'm going to say that.
[01:41:42.200 --> 01:41:43.200]   They're thin by default.
[01:41:43.200 --> 01:41:45.200]   So let's tell them they are.
[01:41:45.200 --> 01:41:46.200]   They were born that way.
[01:41:46.200 --> 01:41:47.200]   But it's your time.
[01:41:47.200 --> 01:41:48.200]   It's your time.
[01:41:48.200 --> 01:41:49.200]   It's my time.
[01:41:49.200 --> 01:41:50.200]   It should be.
[01:41:50.200 --> 01:41:51.200]   Yeah.
[01:41:51.200 --> 01:41:55.040]   She talked to Esther Dyson who was like, "Invest in email programs like this before."
[01:41:55.040 --> 01:41:59.080]   And said, "You should not feel bad about asking people to pay for your time."
[01:41:59.080 --> 01:42:03.640]   It's like being, you know, asking to be paid to write for free or do anything for free.
[01:42:03.640 --> 01:42:04.640]   Yeah, there should be.
[01:42:04.640 --> 01:42:06.360]   Pay me a quarter to read your email.
[01:42:06.360 --> 01:42:07.360]   That's what I...
[01:42:07.360 --> 01:42:08.360]   There you go.
[01:42:08.360 --> 01:42:09.360]   Ten cents, whatever.
[01:42:09.360 --> 01:42:10.880]   Whatever it is, just do that.
[01:42:10.880 --> 01:42:13.000]   That's what I'm all about that system.
[01:42:13.000 --> 01:42:15.560]   Just deposit it right into my bank account.
[01:42:15.560 --> 01:42:16.960]   That seems good.
[01:42:16.960 --> 01:42:21.680]   If you wanted to mail me back in the 90s or the 80s, you had to put a dime.
[01:42:21.680 --> 01:42:23.280]   You had to buy a stamp.
[01:42:23.280 --> 01:42:24.280]   So...
[01:42:24.280 --> 01:42:25.280]   Yeah.
[01:42:25.280 --> 01:42:26.280]   This is like your stamp.
[01:42:26.280 --> 01:42:27.280]   This is like your stamp for email.
[01:42:27.280 --> 01:42:28.280]   Yeah.
[01:42:28.280 --> 01:42:29.280]   But a cup...
[01:42:29.280 --> 01:42:30.800]   But capitalism gets it.
[01:42:30.800 --> 01:42:32.280]   Not the government.
[01:42:32.280 --> 01:42:33.600]   Right, right.
[01:42:33.600 --> 01:42:38.240]   Well, the tagline for the service is "Noise canceling headphones for email."
[01:42:38.240 --> 01:42:43.240]   I like that because I could do with a little noise canceling on my email as well.
[01:42:43.240 --> 01:42:44.240]   Yeah.
[01:42:44.240 --> 01:42:45.680]   I mean, same with you, Megan.
[01:42:45.680 --> 01:42:51.240]   When it comes to spam in my inbox, I guess, we've been living with spam for however many
[01:42:51.240 --> 01:42:55.640]   years at this point, you know, 20 plus years.
[01:42:55.640 --> 01:42:56.880]   At this point, I just like...
[01:42:56.880 --> 01:42:58.280]   I don't even really think about it.
[01:42:58.280 --> 01:43:01.360]   I just kind of like batch delete and move on.
[01:43:01.360 --> 01:43:02.360]   It's...
[01:43:02.360 --> 01:43:03.360]   I don't know.
[01:43:03.360 --> 01:43:07.400]   I realize I probably shouldn't have to do that, but I mean, it's not that difficult
[01:43:07.400 --> 01:43:08.400]   either.
[01:43:08.400 --> 01:43:09.400]   So...
[01:43:09.400 --> 01:43:12.520]   Yeah, I don't know that I would use this.
[01:43:12.520 --> 01:43:17.120]   I'd be curious to see what kind of impact it would have on people who I actually want
[01:43:17.120 --> 01:43:18.120]   to hear from.
[01:43:18.120 --> 01:43:22.320]   But I guess you can set that all up so it probably wouldn't impact them very much.
[01:43:22.320 --> 01:43:26.280]   I'd like it more for phone calls and texts because that's what's really annoying because
[01:43:26.280 --> 01:43:29.360]   they're like, "Oh, a text and I'll go and I'll look at that because I'm assuming it's from
[01:43:29.360 --> 01:43:30.880]   someone I know."
[01:43:30.880 --> 01:43:32.880]   And it's instead like, "Oh, Viagra."
[01:43:32.880 --> 01:43:33.880]   Oh, wow.
[01:43:33.880 --> 01:43:34.880]   From Germany.
[01:43:34.880 --> 01:43:35.880]   Let's see where they're from.
[01:43:35.880 --> 01:43:37.880]   That looks European Viagra.
[01:43:37.880 --> 01:43:45.120]   I want $10 every time someone robo calls me about my cars extended warranty.
[01:43:45.120 --> 01:43:46.120]   That's just...
[01:43:46.120 --> 01:43:47.120]   Oh, yeah.
[01:43:47.120 --> 01:43:49.400]   Fast track me to $10 per phone call.
[01:43:49.400 --> 01:43:51.000]   Thank you.
[01:43:51.000 --> 01:43:52.000]   That's what I need.
[01:43:52.000 --> 01:43:53.000]   We should all get it.
[01:43:53.000 --> 01:43:56.400]   We all deserve it for putting up with these old cars for so long.
[01:43:56.400 --> 01:44:02.040]   We have earned that money for answering these ridiculous calls about our cars extended
[01:44:02.040 --> 01:44:03.040]   warranty.
[01:44:03.040 --> 01:44:05.680]   Well, touching away you just mentioned.
[01:44:05.680 --> 01:44:07.280]   That's super interesting, Megan.
[01:44:07.280 --> 01:44:08.280]   That's like really interesting.
[01:44:08.280 --> 01:44:09.520]   I've never heard of that before.
[01:44:09.520 --> 01:44:15.840]   Yeah, Ashley, just so you know that is actually the number one complaint by consumers.
[01:44:15.840 --> 01:44:21.360]   And there is action in the FCC to somehow stop these robo calls.
[01:44:21.360 --> 01:44:22.360]   Somehow.
[01:44:22.360 --> 01:44:24.080]   For these warranties.
[01:44:24.080 --> 01:44:27.160]   Yeah, the warranty scam as they write it.
[01:44:27.160 --> 01:44:28.160]   Infuriating.
[01:44:28.160 --> 01:44:30.040]   Also, how many people...
[01:44:30.040 --> 01:44:31.040]   How many people...
[01:44:31.040 --> 01:44:32.040]   Yeah, see how's...
[01:44:32.040 --> 01:44:33.040]   Oh, no, Roberta.
[01:44:33.040 --> 01:44:36.720]   I'm like, "How many people are they actually sweeping up in this dragnet?"
[01:44:36.720 --> 01:44:38.040]   Because that's my question.
[01:44:38.040 --> 01:44:39.920]   Because I'm like, "Whoopsed.
[01:44:39.920 --> 01:44:40.920]   Hoopsed."
[01:44:40.920 --> 01:44:45.120]   Among us is out there going, "You know what?
[01:44:45.120 --> 01:44:46.720]   I need an accept..."
[01:44:46.720 --> 01:44:47.960]   You're so right.
[01:44:47.960 --> 01:44:50.640]   I had not thought about my cars extended warranty.
[01:44:50.640 --> 01:44:52.160]   And it is coming to a net.
[01:44:52.160 --> 01:44:53.800]   Like, who is that?
[01:44:53.800 --> 01:44:59.720]   Because not even my grandpa who is in his 80s is like, "Oh, my car's extended warranty.
[01:44:59.720 --> 01:45:00.720]   Of course."
[01:45:00.720 --> 01:45:02.720]   Like, he's like, "No, this is clearly ridiculous."
[01:45:02.720 --> 01:45:06.200]   Like, how many people could possibly be falling for this every year?
[01:45:06.200 --> 01:45:07.200]   I don't know.
[01:45:07.200 --> 01:45:09.200]   How is it so lucrative?
[01:45:09.200 --> 01:45:11.400]   Why is it so prevalent?
[01:45:11.400 --> 01:45:12.920]   The numbers game, right?
[01:45:12.920 --> 01:45:18.680]   Like, if you get that number of tries high enough, you're going to find that tiny little
[01:45:18.680 --> 01:45:21.280]   percentage of people that will fall for it.
[01:45:21.280 --> 01:45:22.280]   I guess.
[01:45:22.280 --> 01:45:23.280]   You don't know.
[01:45:23.280 --> 01:45:26.280]   It's a thing who just haven't answered the phone in two years and then one day they
[01:45:26.280 --> 01:45:28.080]   answer the phone, they're like, "Hello?"
[01:45:28.080 --> 01:45:29.080]   Oh, my God.
[01:45:29.080 --> 01:45:30.080]   They have been.
[01:45:30.080 --> 01:45:31.080]   They have been.
[01:45:31.080 --> 01:45:33.880]   And now they're like, "You know, you've convinced me.
[01:45:33.880 --> 01:45:36.480]   It's taken a while, but I've decided you're right."
[01:45:36.480 --> 01:45:37.480]   Finally, it's expired.
[01:45:37.480 --> 01:45:38.480]   This is the time.
[01:45:38.480 --> 01:45:39.480]   You know.
[01:45:39.480 --> 01:45:40.480]   It's about to expire.
[01:45:40.480 --> 01:45:41.480]   Finally.
[01:45:41.480 --> 01:45:42.480]   Right?
[01:45:42.480 --> 01:45:43.480]   I will.
[01:45:43.480 --> 01:45:44.480]   Yeah.
[01:45:44.480 --> 01:45:45.480]   It's so bizarre.
[01:45:45.480 --> 01:45:46.480]   I just, yeah, I don't...
[01:45:46.480 --> 01:45:47.880]   I have a hard time wrapping my brain around that one.
[01:45:47.880 --> 01:45:48.880]   I don't know.
[01:45:48.880 --> 01:45:49.880]   Yeah.
[01:45:49.880 --> 01:45:50.880]   Yeah.
[01:45:50.880 --> 01:45:51.880]   That is interesting, though.
[01:45:51.880 --> 01:45:54.680]   What about Netflix?
[01:45:54.680 --> 01:45:57.600]   How is Netflix doing?
[01:45:57.600 --> 01:45:58.880]   What's the pulse on Netflix?
[01:45:58.880 --> 01:46:04.000]   This was the second quarter, consecutive quarter of losses.
[01:46:04.000 --> 01:46:05.000]   Not doing good.
[01:46:05.000 --> 01:46:08.520]   They lost 970,000 paid subscribers for the quarter.
[01:46:08.520 --> 01:46:10.280]   They expected to lose 2 million.
[01:46:10.280 --> 01:46:15.080]   So, you know, they didn't lose as much as they thought they were going to, but still
[01:46:15.080 --> 01:46:17.840]   not good at all.
[01:46:17.840 --> 01:46:20.880]   Is anyone here worried about Netflix?
[01:46:20.880 --> 01:46:24.120]   Or is this just kind of like, had to imagine it was going to happen eventually.
[01:46:24.120 --> 01:46:26.040]   Netflix is going to weather this storm.
[01:46:26.040 --> 01:46:27.480]   What do y'all think?
[01:46:27.480 --> 01:46:32.040]   How many people would cancel like a TV station if they could in their regular cable?
[01:46:32.040 --> 01:46:35.120]   Like if they were just like, "Oh, if I never have to see...
[01:46:35.120 --> 01:46:36.120]   I don't know, ESP.
[01:46:36.120 --> 01:46:37.120]   I don't care about it."
[01:46:37.120 --> 01:46:38.120]   The Golf Channel.
[01:46:38.120 --> 01:46:39.120]   Yeah, the Golf Channel.
[01:46:39.120 --> 01:46:40.120]   I don't...
[01:46:40.120 --> 01:46:41.640]   Personally, I don't care about sports.
[01:46:41.640 --> 01:46:45.120]   So any sports channel, if they could like get rid of it when I had cable, I would have
[01:46:45.120 --> 01:46:46.360]   been happy.
[01:46:46.360 --> 01:46:47.360]   But you can't.
[01:46:47.360 --> 01:46:48.360]   That's the...
[01:46:48.360 --> 01:46:53.680]   I mean, that's the great thing for us as consumers with streaming services is that,
[01:46:53.680 --> 01:46:54.680]   "You know what?
[01:46:54.680 --> 01:46:56.880]   I've watched everything I want on Paramount Plus.
[01:46:56.880 --> 01:46:57.880]   Unsubscribe.
[01:46:57.880 --> 01:47:00.840]   You can't do that on TV because everything's bundled and there's carriage fees.
[01:47:00.840 --> 01:47:02.800]   And I'm like, "I'm blah, blah, blah."
[01:47:02.800 --> 01:47:07.080]   So, you know, I think because of that, people were like, "Okay, I've watched all the things
[01:47:07.080 --> 01:47:08.680]   I want to watch on Netflix.
[01:47:08.680 --> 01:47:12.240]   I'm going to unsubscribe until something cool comes back."
[01:47:12.240 --> 01:47:13.240]   And I know people who do that.
[01:47:13.240 --> 01:47:15.280]   I mean, I've done that with show time.
[01:47:15.280 --> 01:47:17.280]   I've done it with epics.
[01:47:17.280 --> 01:47:18.280]   I've done it.
[01:47:18.280 --> 01:47:20.160]   Yeah, I just like, "Okay, I'm done with this show.
[01:47:20.160 --> 01:47:21.160]   I'm done with...
[01:47:21.160 --> 01:47:24.320]   I watched the show I wanted to watch and now I'm going to unsubscribe and then I'll come
[01:47:24.320 --> 01:47:25.320]   back later."
[01:47:25.320 --> 01:47:26.320]   I think that's...
[01:47:26.320 --> 01:47:27.320]   I mean, that's just the new reality.
[01:47:27.320 --> 01:47:32.200]   I mean, it's tough for Netflix because you know, they're the big people on the big dog,
[01:47:32.200 --> 01:47:33.200]   big...
[01:47:33.200 --> 01:47:34.560]   I don't know whatever you call them on the block.
[01:47:34.560 --> 01:47:40.080]   So their changes is going to be way larger than anyone else.
[01:47:40.080 --> 01:47:50.560]   I think Netflix really believed for a long time in the binge model and that it would keep...
[01:47:50.560 --> 01:47:56.360]   If they just turned out as much content as possible, they're spending billions of dollars
[01:47:56.360 --> 01:47:58.400]   on content every year.
[01:47:58.400 --> 01:48:03.680]   And it's like, if they just kept churning out content, then people would stay on Netflix
[01:48:03.680 --> 01:48:05.520]   to watch something, right?
[01:48:05.520 --> 01:48:08.080]   There would always be something for them to binge watch.
[01:48:08.080 --> 01:48:16.680]   But now we have such an embarrassment of riches in terms of streaming services and high quality
[01:48:16.680 --> 01:48:19.480]   programming across all of them pretty much.
[01:48:19.480 --> 01:48:24.080]   Like I think I could tell you the name of a prestige show on just about any of the top
[01:48:24.080 --> 01:48:27.280]   20 streaming services.
[01:48:27.280 --> 01:48:35.600]   I think Netflix is realizing they are unable to capture the zeitgeist the way that they
[01:48:35.600 --> 01:48:42.400]   used to when they were saying, "They were like the big dog on the street."
[01:48:42.400 --> 01:48:44.880]   And they're not able to capture the zeitgeist anymore because...
[01:48:44.880 --> 01:48:47.040]   So here's a great example.
[01:48:47.040 --> 01:48:49.600]   Stranger things.
[01:48:49.600 --> 01:48:52.240]   Literally came and went in my social feeds.
[01:48:52.240 --> 01:48:53.720]   It just came and went.
[01:48:53.720 --> 01:48:56.760]   People binge watched it for about two weeks and then it was gone.
[01:48:56.760 --> 01:49:01.000]   And then it came back and people talked about it for another few days because it was only
[01:49:01.000 --> 01:49:03.840]   two really big episodes and that was it.
[01:49:03.840 --> 01:49:09.800]   And I still see some Eddie Munson memes and some other running up that Hill memes and stuff
[01:49:09.800 --> 01:49:12.240]   like that offshoot memes from it.
[01:49:12.240 --> 01:49:17.200]   But really it's not a water cooler moment anymore.
[01:49:17.200 --> 01:49:23.600]   And you can't make that anymore with a binge model because people are either spoiled so
[01:49:23.600 --> 01:49:25.960]   early that they don't bother.
[01:49:25.960 --> 01:49:28.920]   They'll say, "Oh, just watch it on my own time now that I've been spoiled."
[01:49:28.920 --> 01:49:32.920]   Or they watch it immediately, talk about it immediately and then they're on to the next.
[01:49:32.920 --> 01:49:37.240]   And so this has kind of created a problem with Netflix because like you were saying,
[01:49:37.240 --> 01:49:40.920]   Roberto, you can't just like you binge something and you say, "Okay, I'm good.
[01:49:40.920 --> 01:49:42.080]   I don't need this right now.
[01:49:42.080 --> 01:49:43.800]   I'll wait until Stranger Things."
[01:49:43.800 --> 01:49:46.640]   Like the thing that I care about comes back, Squid Game.
[01:49:46.640 --> 01:49:49.280]   I'll just get rid of it for now.
[01:49:49.280 --> 01:49:57.360]   And companies like Disney are being very methodical about capturing the zeitgeist, making water
[01:49:57.360 --> 01:49:58.440]   cooler moments.
[01:49:58.440 --> 01:50:02.760]   So they're releasing, if you look at their release schedule, it's literally like,
[01:50:02.760 --> 01:50:07.480]   Star Wars, Marvel Show, Star Wars, Marvel Show.
[01:50:07.480 --> 01:50:09.840]   It's just like one after the other after the other.
[01:50:09.840 --> 01:50:15.160]   But they're all just week by week by week so that people can have time to catch the episode,
[01:50:15.160 --> 01:50:16.880]   digest, talk about it.
[01:50:16.880 --> 01:50:19.200]   Then you've got a fresh episode to talk about.
[01:50:19.200 --> 01:50:24.760]   And they've done a much better job of capturing that feeling, that zeitgeist of having water
[01:50:24.760 --> 01:50:27.400]   cooler moments to discuss every single week.
[01:50:27.400 --> 01:50:32.720]   And I think HBO Max did this really well with shows like Game of Thrones and AMC, which
[01:50:32.720 --> 01:50:35.240]   is really good with Breaking Bad and Better Call Saul.
[01:50:35.240 --> 01:50:39.480]   They're still having these moments where it's like the gated release schedule works for
[01:50:39.480 --> 01:50:40.480]   a reason.
[01:50:40.480 --> 01:50:42.480]   It keeps people talking about your show.
[01:50:42.480 --> 01:50:49.120]   And in a world where there is so much white noise, Netflix is learning that it can't just
[01:50:49.120 --> 01:50:54.360]   rest on its laurels and say, "Oh, we're just going to put out so much content that you're
[01:50:54.360 --> 01:50:58.560]   just going to be a subscriber because this is a great default service to have."
[01:50:58.560 --> 01:51:00.960]   Like a lot of people are realizing that's just not the case.
[01:51:00.960 --> 01:51:04.000]   Yeah, I mean, I watched The Boys.
[01:51:04.000 --> 01:51:05.000]   I like that show.
[01:51:05.000 --> 01:51:07.800]   It was bad horrible people who are superheroes.
[01:51:07.800 --> 01:51:09.400]   But it was released every week.
[01:51:09.400 --> 01:51:10.400]   And I'm like, "No, that's fine.
[01:51:10.400 --> 01:51:11.400]   I'm fine with that."
[01:51:11.400 --> 01:51:15.000]   And if I missed it one week, it's not like the olden days where we didn't have T-vone
[01:51:15.000 --> 01:51:16.720]   and are like, "Well, I guess I don't know what happens."
[01:51:16.720 --> 01:51:18.720]   But you can like, you know, we watch it.
[01:51:18.720 --> 01:51:22.240]   Me and my wife will sit and watch it on Friday or Saturday or Sunday and we're like, "Oh,
[01:51:22.240 --> 01:51:23.240]   okay, cool."
[01:51:23.240 --> 01:51:26.600]   And then we'll go on, we'll binge watch whatever random thing has already been out for six
[01:51:26.600 --> 01:51:27.600]   months.
[01:51:27.600 --> 01:51:29.600]   And then, "Oh, hey, then there's a new episode of The Boys."
[01:51:29.600 --> 01:51:34.920]   It's something, it's appointment television, which sort of went away with Netflix.
[01:51:34.920 --> 01:51:37.080]   And now everyone else is doing it but Netflix.
[01:51:37.080 --> 01:51:41.160]   And they think they really need to figure out how to do that, even if they dropped like
[01:51:41.160 --> 01:51:46.520]   three episodes, like the first three drop and then just sort of like, you know, keep
[01:51:46.520 --> 01:51:47.520]   us around.
[01:51:47.520 --> 01:51:48.520]   Yeah.
[01:51:48.520 --> 01:51:51.760]   It's kind of their identity is the binge model, right?
[01:51:51.760 --> 01:51:52.760]   The binge model, right?
[01:51:52.760 --> 01:51:56.720]   Like they really leaned into the binge model as a huge part of their identity.
[01:51:56.720 --> 01:52:02.720]   And I think what's kind of interesting right now, hearing both of you talk about kind of
[01:52:02.720 --> 01:52:10.920]   weekly, you know, release schedules on shows is that no one, at least, and I totally agree,
[01:52:10.920 --> 01:52:15.520]   but the two of you talking about it, no one's disappointed when it's a weekly release.
[01:52:15.520 --> 01:52:17.920]   Like, I'm fine if I don't have the binge.
[01:52:17.920 --> 01:52:18.920]   It's fine.
[01:52:18.920 --> 01:52:23.440]   Like, of course, there's like, there's the desire within me that if I have a full season,
[01:52:23.440 --> 01:52:28.280]   I will binge if it's there, but if it's not there and I have to come back next week,
[01:52:28.280 --> 01:52:29.280]   I'm not disappointed.
[01:52:29.280 --> 01:52:33.800]   I actually really end up enjoying those shows a little bit more kind of because of exactly
[01:52:33.800 --> 01:52:34.800]   what you're talking about.
[01:52:34.800 --> 01:52:40.920]   So if that was Netflix's kind of, you know, model that it really painted its business
[01:52:40.920 --> 01:52:46.320]   around, it's kind of something that I think maybe people are, you know, realizing, oh,
[01:52:46.320 --> 01:52:48.760]   well, you know, it's nice to have that, but it's not a necessary.
[01:52:48.760 --> 01:52:50.800]   It's not a have to have.
[01:52:50.800 --> 01:52:54.160]   And there's something appealing about that staggered release to it.
[01:52:54.160 --> 01:52:55.160]   I don't know.
[01:52:55.160 --> 01:52:58.920]   I end up, yeah, I just end up appreciating the show more because you have the time to
[01:52:58.920 --> 01:52:59.920]   digest it.
[01:52:59.920 --> 01:53:03.040]   You have the time to talk about it and share and all that kind of stuff.
[01:53:03.040 --> 01:53:04.040]   Yeah.
[01:53:04.040 --> 01:53:05.040]   What's fun.
[01:53:05.040 --> 01:53:12.520]   I think also the last two years are everyone was home all the time.
[01:53:12.520 --> 01:53:16.160]   So it's like there's all these companies and Netflix is just one of many like pandemic
[01:53:16.160 --> 01:53:19.960]   darling companies that really like all we did was watch Netflix.
[01:53:19.960 --> 01:53:22.760]   All we wanted to do was binge like we didn't do anything for the last two years.
[01:53:22.760 --> 01:53:23.960]   And now we're not anymore now.
[01:53:23.960 --> 01:53:25.920]   We're out in the world.
[01:53:25.920 --> 01:53:31.120]   And so like binging just doesn't like, you know, doesn't compare to actually being able
[01:53:31.120 --> 01:53:36.840]   to like go to a restaurant and go to a bar, go on vacation, like go outside, be with a
[01:53:36.840 --> 01:53:41.120]   group of people like all those things that we, you know, stop doing for two years we're
[01:53:41.120 --> 01:53:42.760]   doing now again.
[01:53:42.760 --> 01:53:43.760]   Yeah.
[01:53:43.760 --> 01:53:44.760]   Yeah.
[01:53:44.760 --> 01:53:48.760]   It's interesting because I remember when the binge started with Netflix, like that was
[01:53:48.760 --> 01:53:50.800]   like, I'm like, this is how we're going to do it forever.
[01:53:50.800 --> 01:53:53.520]   And I was all about like, oh, you have to wait every week.
[01:53:53.520 --> 01:53:54.920]   I wish I could binge things.
[01:53:54.920 --> 01:53:59.360]   But as time goes on, and I think this like people just in general, like, you know what,
[01:53:59.360 --> 01:54:04.200]   there's so much I can't, I just can't absorb everything so quickly.
[01:54:04.200 --> 01:54:06.440]   Just let me give me a week.
[01:54:06.440 --> 01:54:08.200]   Just, you know, some shows are like, okay, fine.
[01:54:08.200 --> 01:54:09.200]   I'll binge watch it.
[01:54:09.200 --> 01:54:11.600]   But for the most moment, like just let me breathe.
[01:54:11.600 --> 01:54:12.600]   Let me breathe.
[01:54:12.600 --> 01:54:16.800]   And, you know, when you think about like old shows at the, you know, the appointment television,
[01:54:16.800 --> 01:54:21.680]   you know, the, the, the Twin Peaks or Seinfeld or all these things where you had a nice week
[01:54:21.680 --> 01:54:26.680]   to sort of breathe on these, these television shows and sort of like get in.
[01:54:26.680 --> 01:54:27.680]   Okay.
[01:54:27.680 --> 01:54:28.680]   What, what, what does this mean?
[01:54:28.680 --> 01:54:29.680]   What does this mean?
[01:54:29.680 --> 01:54:33.480]   Where's the supposed where if it's just all at once everyone's staggered, it's all over
[01:54:33.480 --> 01:54:34.480]   the place.
[01:54:34.480 --> 01:54:37.520]   It's hard to sort of talk about it because you don't want to ruin it for somebody else.
[01:54:37.520 --> 01:54:43.560]   Because yeah, it's, I think, I think as society, we were like, you know what, just give, give
[01:54:43.560 --> 01:54:44.560]   us a minute.
[01:54:44.560 --> 01:54:45.560]   Just a minute.
[01:54:45.560 --> 01:54:46.560]   Yeah.
[01:54:46.560 --> 01:54:48.560]   And the early days it worked.
[01:54:48.560 --> 01:54:53.680]   It worked because there wasn't the level of content we have for streaming just wasn't
[01:54:53.680 --> 01:54:56.640]   there in the early days of like Netflix.
[01:54:56.640 --> 01:54:58.680]   And so, or streaming on Netflix.
[01:54:58.680 --> 01:55:01.240]   And now it's everybody's streaming.
[01:55:01.240 --> 01:55:07.280]   You can't, you know, you, you would watch Disney stuff on the Disney channel or you'd
[01:55:07.280 --> 01:55:12.000]   watch it on ABC or you, you know, and now it's like this is all, they're all on a level
[01:55:12.000 --> 01:55:13.080]   playing field.
[01:55:13.080 --> 01:55:21.080]   And so this idea of having, you know, a binge model, it's really hard because like you said,
[01:55:21.080 --> 01:55:25.480]   when you want to talk about it with people, you want to capture that moment, that water
[01:55:25.480 --> 01:55:29.080]   cooler moment, it's, it's, you don't know what episode someone else is on.
[01:55:29.080 --> 01:55:30.960]   You don't want to spoil it for them.
[01:55:30.960 --> 01:55:33.240]   Maybe you're farther ahead than all of your other friends.
[01:55:33.240 --> 01:55:35.760]   Maybe you're the farthest behind.
[01:55:35.760 --> 01:55:37.920]   It's just, and it depends on any given week, right?
[01:55:37.920 --> 01:55:41.660]   Like maybe you just had a really busy week and then all of a sudden, oh, here's stranger
[01:55:41.660 --> 01:55:42.660]   things.
[01:55:42.660 --> 01:55:44.560]   Last two episodes of it of the fourth season.
[01:55:44.560 --> 01:55:45.560]   Okay.
[01:55:45.560 --> 01:55:47.840]   Here's, you know, season four, part two.
[01:55:47.840 --> 01:55:49.520]   And you can't get to it that weekend.
[01:55:49.520 --> 01:55:53.040]   And it's just like, okay, well, I guess all my friends are done talking about it.
[01:55:53.040 --> 01:55:55.640]   So I will just watch it whenever I watch it.
[01:55:55.640 --> 01:56:00.640]   Like I'll like, you know, there's always that moment where it just that model doesn't quite
[01:56:00.640 --> 01:56:03.680]   work anymore because there is so much out there.
[01:56:03.680 --> 01:56:04.960]   It just doesn't work.
[01:56:04.960 --> 01:56:13.340]   And I'm somebody, I remember someone in the industry was excoriated in comments in people
[01:56:13.340 --> 01:56:21.340]   are just dunking on this, this kind of media consultant or media analyst who said, I predict
[01:56:21.340 --> 01:56:24.460]   Netflix will have ads on it at some point.
[01:56:24.460 --> 01:56:28.300]   Like and people, this was probably eight, this price eight years ago.
[01:56:28.300 --> 01:56:31.880]   And people are just like, Oh, that is the most ridiculous thing I've ever heard of.
[01:56:31.880 --> 01:56:32.960]   This is the new model.
[01:56:32.960 --> 01:56:34.600]   It's going to be, you know, no ads this that.
[01:56:34.600 --> 01:56:35.760]   Any other thing.
[01:56:35.760 --> 01:56:38.680]   And now that person looks like no Stardomis.
[01:56:38.680 --> 01:56:43.840]   So I, you know, they, they're certainly feeling pretty smug about themselves right now because
[01:56:43.840 --> 01:56:47.680]   Netflix is like, Oh, I think we might have to add ads, which have like kind of a base.
[01:56:47.680 --> 01:56:50.280]   Same thing as Hulu where you have like ads, no ads, right.
[01:56:50.280 --> 01:56:52.200]   But it's like Netflix is going to have to pivot.
[01:56:52.200 --> 01:56:59.360]   They have to, they have to change in some capacity either to continue to keep up that, that revenue
[01:56:59.360 --> 01:57:04.480]   stream and continue to make as much content as they do, which they, they really do.
[01:57:04.480 --> 01:57:10.920]   I think if I'm not mistaken, they are the number one spender when it comes to original
[01:57:10.920 --> 01:57:12.800]   content of all the streamers.
[01:57:12.800 --> 01:57:15.480]   And that like, that is a big deal.
[01:57:15.480 --> 01:57:16.880]   The fact that they spend the most.
[01:57:16.880 --> 01:57:21.880]   And I, if it, if it isn't today, it was for a long time that they were the number one
[01:57:21.880 --> 01:57:23.640]   spender in terms of original content.
[01:57:23.640 --> 01:57:28.920]   And so for them to keep up that amount of spending to make as much as they do to license
[01:57:28.920 --> 01:57:34.160]   as much as they do, it will be very interesting to see how the ads versus subscribers.
[01:57:34.160 --> 01:57:36.160]   Stuff shakes out for them.
[01:57:36.160 --> 01:57:39.040]   Cause we have so many things to pay for.
[01:57:39.040 --> 01:57:40.720]   There's so many streaming services.
[01:57:40.720 --> 01:57:44.240]   And I know that they've already called, they shut down, I believe they shut down the
[01:57:44.240 --> 01:57:48.000]   Netflix animation, which a lot of my friends are in animation and, you know, they have
[01:57:48.000 --> 01:57:51.720]   friends who lost their, you know, they lost their jobs because Netflix is like, you know
[01:57:51.720 --> 01:57:52.720]   what?
[01:57:52.720 --> 01:57:56.880]   Let's not make all of our own animation or at least let's cut back on it.
[01:57:56.880 --> 01:58:01.320]   And so you're just like, Oh, oh, oh, oh, so it's not just the gravy train that we thought
[01:58:01.320 --> 01:58:03.160]   it was going to be forever and ever.
[01:58:03.160 --> 01:58:08.920]   And they got to figure out how to, how to, to, to adjust their, just their, their business
[01:58:08.920 --> 01:58:11.160]   for a sort of changing world.
[01:58:11.160 --> 01:58:12.440]   Yeah, they did.
[01:58:12.440 --> 01:58:17.160]   They laid off all of the people who are working on like all the shows.
[01:58:17.160 --> 01:58:22.200]   They had this like huge diversity push like real and like black creators and LGBTQ plus
[01:58:22.200 --> 01:58:27.560]   creators and they like just laid all of them off to like it was just like, Oh, the editorial.
[01:58:27.560 --> 01:58:28.560]   Yeah.
[01:58:28.560 --> 01:58:35.760]   Yeah, to do with houses. Yeah, like left their jobs and so yeah.
[01:58:35.760 --> 01:58:41.560]   And then these are like creatives that they had, they had literally like, I mean, they
[01:58:41.560 --> 01:58:46.200]   have gone out of their way to get a lot of these really high profile people to come
[01:58:46.200 --> 01:58:49.640]   right for like their editorial arm and all this stuff.
[01:58:49.640 --> 01:58:53.280]   And then it was like six months, like the turnaround was so fast and they were just
[01:58:53.280 --> 01:58:56.120]   like, Oh, sorry, you like left your whole entire life.
[01:58:56.120 --> 01:58:58.480]   Like, I'm never going to shut this down now.
[01:58:58.480 --> 01:59:00.440]   So it's just, yeah, it's really volatile.
[01:59:00.440 --> 01:59:06.720]   Like the spaces, I think Netflix is, it definitely is struggling under its own weight right now.
[01:59:06.720 --> 01:59:09.240]   And I think it has to figure something out quickly.
[01:59:09.240 --> 01:59:12.560]   Yeah, I think you're right.
[01:59:12.560 --> 01:59:16.320]   I do appreciate the flexibility though of the streaming services like you were talking
[01:59:16.320 --> 01:59:17.320]   about earlier.
[01:59:17.320 --> 01:59:21.880]   And the example that I always come around to is the Olympics, right?
[01:59:21.880 --> 01:59:26.600]   Like I don't, I don't have an ongoing subscription to any sort of live TV, anything.
[01:59:26.600 --> 01:59:30.960]   But YouTube TV, you know, I will drop into that for the Olympics for just that month.
[01:59:30.960 --> 01:59:35.960]   The fact that I could do that whereas however many years ago when we actually had like direct
[01:59:35.960 --> 01:59:39.600]   TV for years, I mean, there was no such thing as dropping in and out.
[01:59:39.600 --> 01:59:41.000]   It was so complicated.
[01:59:41.000 --> 01:59:44.400]   So that's what you got for consumers now.
[01:59:44.400 --> 01:59:51.400]   And YouTube and Hulu, both YouTube and Hulu, both like made it okay to pay for subscription
[01:59:51.400 --> 01:59:53.120]   and also have ads like that.
[01:59:53.120 --> 01:59:54.280]   Like that was unheard of.
[01:59:54.280 --> 01:59:55.280]   That's true.
[01:59:55.280 --> 01:59:58.920]   And for a really long time, like Netflix was like, well, you just know ads subscription.
[01:59:58.920 --> 02:00:04.200]   And you know, unless you're part of a big giant other company like HBO or Disney, you
[02:00:04.200 --> 02:00:07.480]   know, it's like, why not do both?
[02:00:07.480 --> 02:00:11.440]   We will regularly watch Roku, the Roku channel because I have like weird 80s movies my wife
[02:00:11.440 --> 02:00:12.440]   will put on.
[02:00:12.440 --> 02:00:14.400]   And they'll have ads and they're like, man, whatever ads.
[02:00:14.400 --> 02:00:17.600]   I'm a big Pluto TV person for like background TV.
[02:00:17.600 --> 02:00:21.600]   You can put on, you know, the Kung Fu channel or you can put on drag race.
[02:00:21.600 --> 02:00:26.000]   There's a whole channel dedicated to RuPaul's drag race that just plays, it's just a shuffle
[02:00:26.000 --> 02:00:32.480]   on every, you know, every season that has existed since like, I think season 12 and back.
[02:00:32.480 --> 02:00:33.480]   And it's great.
[02:00:33.480 --> 02:00:34.480]   It's great.
[02:00:34.480 --> 02:00:37.520]   You just throw it on and you send the background and you can have, you know, whatever you want,
[02:00:37.520 --> 02:00:39.280]   whatever tickles your fancy and it's free.
[02:00:39.280 --> 02:00:40.720]   Pluto TV is all free and everything.
[02:00:40.720 --> 02:00:41.720]   It's pretty cool.
[02:00:41.720 --> 02:00:44.960]   It is the same three ads over and over again though.
[02:00:44.960 --> 02:00:45.960]   Yeah.
[02:00:45.960 --> 02:00:50.160]   It's not like, it's not like every station break is like three different ads.
[02:00:50.160 --> 02:00:55.160]   No, it's the same three ads over and over and over and over.
[02:00:55.160 --> 02:01:00.360]   This is where privacy laws need to like do me wrong a little bit, do me a little dirty
[02:01:00.360 --> 02:01:02.360]   and be like, I know what you're interested in.
[02:01:02.360 --> 02:01:03.560]   And so here's some ads about it.
[02:01:03.560 --> 02:01:07.240]   Cause like, man, I just really want to see like a toy cool toy commercial and there's
[02:01:07.240 --> 02:01:09.360]   just not like, I don't see that anymore.
[02:01:09.360 --> 02:01:12.880]   It's just all like, you know, hey, are you interested in NFTs?
[02:01:12.880 --> 02:01:15.320]   And it's just like, yeah, like I don't like this.
[02:01:15.320 --> 02:01:20.240]   No, like, hey, try, try some new medication.
[02:01:20.240 --> 02:01:24.720]   Like it's always just the same prescription ad like four times like throughout this, you
[02:01:24.720 --> 02:01:27.840]   know, whatever the show is like, but the Marvelous Mrs. Maisel.
[02:01:27.840 --> 02:01:29.480]   It's just like, Hey, here's this new prescription.
[02:01:29.480 --> 02:01:33.040]   You should try if you have heartburn and it's just like, so boring.
[02:01:33.040 --> 02:01:35.240]   Why can't the ads be good?
[02:01:35.240 --> 02:01:36.240]   Yeah.
[02:01:36.240 --> 02:01:42.920]   We, well, you know, they need to have like a classic ads channel that just gets inserted
[02:01:42.920 --> 02:01:43.920]   in there.
[02:01:43.920 --> 02:01:46.120]   You know, it keeps things interesting and you can watch.
[02:01:46.120 --> 02:01:50.040]   Like new ad, new ad.
[02:01:50.040 --> 02:01:51.040]   Class transformers ad.
[02:01:51.040 --> 02:01:52.040]   Classic.
[02:01:52.040 --> 02:01:53.040]   Yeah.
[02:01:53.040 --> 02:01:54.040]   New ads.
[02:01:54.040 --> 02:01:55.040]   Just class ads.
[02:01:55.040 --> 02:01:57.040]   50s to the 90s.
[02:01:57.040 --> 02:01:58.800]   Just that would be really fun.
[02:01:58.800 --> 02:01:59.800]   There you go.
[02:01:59.800 --> 02:02:06.040]   I just put it in like a sandwich and radio DJs, right?
[02:02:06.040 --> 02:02:10.000]   Where it's like you have the, you know, you got the two, two things that are new and fresh,
[02:02:10.000 --> 02:02:12.680]   things you want to sell and you have like that classic, you have a classic ad and they're
[02:02:12.680 --> 02:02:14.600]   like, Oh, hey, I remember this and you're watching.
[02:02:14.600 --> 02:02:16.000]   See you're actually paying attention.
[02:02:16.000 --> 02:02:17.000]   Yeah.
[02:02:17.000 --> 02:02:18.000]   Yes.
[02:02:18.000 --> 02:02:19.000]   Yes.
[02:02:19.000 --> 02:02:22.440]   Well, speaking of ads, let's take a break.
[02:02:22.440 --> 02:02:24.680]   And I don't have a classic ad to play for you right now.
[02:02:24.680 --> 02:02:28.840]   I do have, well, I guess it's classic if you've been listening to this weekend tech for a
[02:02:28.840 --> 02:02:33.240]   number of years because this episode of this week tech is brought to you by Express VPN.
[02:02:33.240 --> 02:02:34.560]   They've been with us for a while.
[02:02:34.560 --> 02:02:39.840]   So let's consider them a classic profiling surveillance data harvesting.
[02:02:39.840 --> 02:02:44.240]   There are a lot of things not to like about tech giants, right?
[02:02:44.240 --> 02:02:46.800]   And we talk about these things on the network all the time.
[02:02:46.800 --> 02:02:52.920]   But what can you actually do about it when you rely on so many of their products?
[02:02:52.920 --> 02:02:56.200]   We don't all have $44 billion to go buying up Twitter.
[02:02:56.200 --> 02:03:00.360]   But the good news is you don't need to be a billionaire to take a stand.
[02:03:00.360 --> 02:03:02.480]   That's why I use Express VPN.
[02:03:02.480 --> 02:03:06.920]   I use it on all my devices for less than seven bucks a month.
[02:03:06.920 --> 02:03:13.680]   You can join me and actually resist fight back against big tech by using Express VPN,
[02:03:13.680 --> 02:03:18.920]   not to mention just fight back at protecting your data all around, not just from big tech.
[02:03:18.920 --> 02:03:21.280]   You want to have good control over your data.
[02:03:21.280 --> 02:03:24.400]   That's really why I use Express VPN.
[02:03:24.400 --> 02:03:29.560]   And especially if I go traveling anywhere, you better believe I've got Express VPN running
[02:03:29.560 --> 02:03:30.560]   on my smartphone.
[02:03:30.560 --> 02:03:38.240]   If I'm in that, be often used, example is in that coffee shop, but you've got free Wi-Fi
[02:03:38.240 --> 02:03:41.200]   all over the map at this point, not just coffee shops.
[02:03:41.200 --> 02:03:46.320]   And if you're using that free Wi-Fi, probably a pretty good idea to activate Express VPN.
[02:03:46.320 --> 02:03:48.080]   That's certainly what I do.
[02:03:48.080 --> 02:03:49.960]   How do you think big tech companies make all their money?
[02:03:49.960 --> 02:03:55.120]   They do it by tracking your searches, your video history, and everything you click on.
[02:03:55.120 --> 02:03:58.880]   And then they're selling your personal data as a result.
[02:03:58.880 --> 02:04:05.560]   All Express VPN helps you anonymize much of your online presence by hiding your IP address.
[02:04:05.560 --> 02:04:11.680]   Which as you know, is a unique identifier that really identifies your specific device.
[02:04:11.680 --> 02:04:15.760]   And that allows big tech to match your activity back to you.
[02:04:15.760 --> 02:04:19.600]   You know what that best part is, how easy it is to use Express VPN.
[02:04:19.600 --> 02:04:21.760]   The app is just super easy.
[02:04:21.760 --> 02:04:26.120]   I just tap one button on my phone or my computer to turn it on.
[02:04:26.120 --> 02:04:29.000]   And that's all it takes to keep people out of the business.
[02:04:29.000 --> 02:04:33.880]   And actually, I should also mention on Android, especially, you don't need to use the app.
[02:04:33.880 --> 02:04:37.400]   Android has a little quick settings area that when you have the app installed and have it
[02:04:37.400 --> 02:04:41.720]   all set up, I just go into my quick settings and I tap on connect to VPN.
[02:04:41.720 --> 02:04:44.760]   There's one there for Express VPN and it's going.
[02:04:44.760 --> 02:04:46.080]   I didn't even need to launch the app.
[02:04:46.080 --> 02:04:47.240]   It's that easy.
[02:04:47.240 --> 02:04:51.000]   If you don't like big tech tracking you and selling your personal data for profit, it's
[02:04:51.000 --> 02:04:55.240]   time to fight back, visit expressvpn.com/twit.
[02:04:55.240 --> 02:05:00.960]   Do that right now and you will get three months of Express VPN for free.
[02:05:00.960 --> 02:05:01.960]   That's right, for free.
[02:05:01.960 --> 02:05:04.160]   That's expressvpn.com/twit.
[02:05:04.160 --> 02:05:05.160]   Check it out.
[02:05:05.160 --> 02:05:06.160]   Awesome VPN.
[02:05:06.160 --> 02:05:07.160]   It doesn't slow anything down either.
[02:05:07.160 --> 02:05:11.000]   That's like a common complaint about VPN is like when I use VPN, everything slows to a
[02:05:11.000 --> 02:05:12.000]   crawl.
[02:05:12.000 --> 02:05:13.160]   You don't get that with Express VPN.
[02:05:13.160 --> 02:05:14.680]   I certainly don't.
[02:05:14.680 --> 02:05:21.840]   Expressvpn.com/twit and we thank them for their support of this week in tech.
[02:05:21.840 --> 02:05:26.400]   All right, before we get to the last stories of the show, let's take a look back at the
[02:05:26.400 --> 02:05:28.240]   previous week on Twit.
[02:05:28.240 --> 02:05:35.600]   I wanted to share a bit of an oops moment, if you will, in the world of photography.
[02:05:35.600 --> 02:05:43.280]   Well, that got cut short because I ended up stepping in a yellow jacket nest and got stung
[02:05:43.280 --> 02:05:45.680]   in the home a handful of times.
[02:05:45.680 --> 02:05:47.320]   They still out here.
[02:05:47.320 --> 02:05:50.600]   And I got a first safety.
[02:05:50.600 --> 02:05:54.720]   Previously on Twit, Windows Weekly.
[02:05:54.720 --> 02:05:59.000]   It's actually found out from multiple sources at this point that Microsoft is moving away
[02:05:59.000 --> 02:06:04.280]   from its annual sort of major release of Windows and is moving to a major release every
[02:06:04.280 --> 02:06:06.800]   three years with feature jobs in between.
[02:06:06.800 --> 02:06:09.400]   Now they call it the feature jobs moments.
[02:06:09.400 --> 02:06:10.600]   Macbreak Weekly.
[02:06:10.600 --> 02:06:15.960]   You forget if you've been living on an M1 MacBook Air for a while, how slow in comparison
[02:06:15.960 --> 02:06:18.200]   those Intel MacBook Airs were.
[02:06:18.200 --> 02:06:19.840]   M2 is faster than M1.
[02:06:19.840 --> 02:06:21.000]   There's no doubt about it.
[02:06:21.000 --> 02:06:25.000]   And having MagSafe come back, having that extra port now.
[02:06:25.000 --> 02:06:26.240]   This week in Google.
[02:06:26.240 --> 02:06:31.720]   At Google I/O, if you remember, Google was talking about kind of the next iteration of
[02:06:31.720 --> 02:06:35.000]   AR glasses that Google is working on.
[02:06:35.000 --> 02:06:36.280]   I'm going to put it out at some point.
[02:06:36.280 --> 02:06:39.040]   But apparently they're going to start beta testing these suckers.
[02:06:39.040 --> 02:06:44.480]   I think next month starting in August because they learned the lesson with glass that if
[02:06:44.480 --> 02:06:48.640]   you give it to just everyday ordinary schmucks like me, we're going to end up making fun
[02:06:48.640 --> 02:06:50.360]   of it and it's not really going to work.
[02:06:50.360 --> 02:06:56.360]   So they realized that the real use of it was for tradespeople and doctors and so on and
[02:06:56.360 --> 02:06:57.360]   so forth.
[02:06:57.360 --> 02:07:02.280]   Mr. Jarvis is someone that has their own theme song, "You're a not a neighbor day person,
[02:07:02.280 --> 02:07:03.280]   my man."
[02:07:03.280 --> 02:07:04.280]   Twit.
[02:07:04.280 --> 02:07:05.280]   I wasn't.
[02:07:05.280 --> 02:07:09.360]   Definitely not a schmuck.
[02:07:09.360 --> 02:07:15.080]   What y'all think about Google's AR glasses, they're going to be beta testing these.
[02:07:15.080 --> 02:07:20.440]   So it's possible, I mean, not to the degree that they did with Google Glass, of course,
[02:07:20.440 --> 02:07:27.440]   but it's possible that you might encounter someone wearing Google's translating AR glasses.
[02:07:27.440 --> 02:07:28.440]   That's kind of a neat feature.
[02:07:28.440 --> 02:07:29.440]   I don't know.
[02:07:29.440 --> 02:07:31.440]   Are you guys interested?
[02:07:31.440 --> 02:07:32.440]   Crickets.
[02:07:32.440 --> 02:07:39.000]   I made a big stink about Google Glass once on the show and then someone was kind of mad
[02:07:39.000 --> 02:07:40.880]   at me about it and then I pointed it to things.
[02:07:40.880 --> 02:07:43.120]   I'm like, "Wrong, you're wrong, I'm right."
[02:07:43.120 --> 02:07:44.360]   But I was very nice about it.
[02:07:44.360 --> 02:07:49.840]   So we Google Glass, they oversold what that thing was going to be.
[02:07:49.840 --> 02:07:54.400]   And then it came out and everyone bought it and then everyone's like, "Oh, this is dumb.
[02:07:54.400 --> 02:07:57.080]   Everyone's doing this the whole time."
[02:07:57.080 --> 02:07:59.080]   Just half rolling their eyes.
[02:07:59.080 --> 02:08:00.080]   Yeah.
[02:08:00.080 --> 02:08:01.080]   Yeah.
[02:08:01.080 --> 02:08:02.080]   I don't know.
[02:08:02.080 --> 02:08:03.080]   Do I need AR glasses?
[02:08:03.080 --> 02:08:04.680]   Do I need glasses just to translate?
[02:08:04.680 --> 02:08:08.360]   I travel to other countries a lot.
[02:08:08.360 --> 02:08:12.520]   That's part of my job is to leave America pretty often.
[02:08:12.520 --> 02:08:14.040]   And I'm doing okay.
[02:08:14.040 --> 02:08:18.080]   I don't need AR glasses.
[02:08:18.080 --> 02:08:21.120]   I feel like I would rent them for a vacation.
[02:08:21.120 --> 02:08:22.120]   There you go.
[02:08:22.120 --> 02:08:23.120]   Yeah.
[02:08:23.120 --> 02:08:24.120]   There you go.
[02:08:24.120 --> 02:08:27.480]   Like renting seems like a vacation rental.
[02:08:27.480 --> 02:08:28.480]   Yeah.
[02:08:28.480 --> 02:08:33.200]   Like you go to Japan and it's part of your Airbnb because when I went to Taipei, I'm like,
[02:08:33.200 --> 02:08:34.200]   "I don't know.
[02:08:34.200 --> 02:08:35.200]   There's nothing.
[02:08:35.200 --> 02:08:37.000]   I have no frame of reference for what's going on."
[02:08:37.000 --> 02:08:38.000]   Right.
[02:08:38.000 --> 02:08:39.000]   Right.
[02:08:39.000 --> 02:08:40.000]   Where's Europe?
[02:08:40.000 --> 02:08:41.000]   I'm like, "Okay.
[02:08:41.000 --> 02:08:42.000]   I kind of figure it out."
[02:08:42.000 --> 02:08:48.040]   For Latin-based languages for me, I'm able to maybe suss out some stuff and I can kind
[02:08:48.040 --> 02:08:50.560]   of find my way around it over time.
[02:08:50.560 --> 02:08:54.760]   But then yeah, if I was going to a country where I just had no frame of reference for
[02:08:54.760 --> 02:08:57.800]   the language, then having that would be nice.
[02:08:57.800 --> 02:09:03.640]   But yeah, this is the thing where it's like, "I feel like if I was going to stay at a hotel,
[02:09:03.640 --> 02:09:06.080]   maybe I could add it on to my stay."
[02:09:06.080 --> 02:09:08.960]   Or if I was staying at an Airbnb, it would be a very nice perk.
[02:09:08.960 --> 02:09:10.200]   Or it's like, "Okay."
[02:09:10.200 --> 02:09:12.560]   And you have the option to use Google AR glasses.
[02:09:12.560 --> 02:09:14.760]   They can translate for you live while you're here.
[02:09:14.760 --> 02:09:16.960]   Please just make sure that you take care of them.
[02:09:16.960 --> 02:09:19.640]   And if you break them, you have to buy them or whatever.
[02:09:19.640 --> 02:09:21.320]   And then that's it.
[02:09:21.320 --> 02:09:24.960]   Like you're using them and then you're responsible for them and then you put them back and then
[02:09:24.960 --> 02:09:25.960]   you leave.
[02:09:25.960 --> 02:09:30.440]   And it's like, that to me seems like the better sort of way to do it.
[02:09:30.440 --> 02:09:35.360]   Or if you're going to a business conference and you're going to a foreign country where
[02:09:35.360 --> 02:09:45.480]   you can't read the language, then your company provides you with Google AR glasses to go
[02:09:45.480 --> 02:09:46.480]   for the conference.
[02:09:46.480 --> 02:09:49.320]   But again, it's a weird rental thing.
[02:09:49.320 --> 02:09:55.400]   It feels like it would be a thing that would be owned and loaned out to use for a specific
[02:09:55.400 --> 02:09:56.400]   use case.
[02:09:56.400 --> 02:09:58.240]   I don't know that I would use it every day.
[02:09:58.240 --> 02:10:00.760]   Yeah, it's like how often you use Google Translate.
[02:10:00.760 --> 02:10:06.640]   I've used it in Korea and in Taipei and then maybe a few times in Germany.
[02:10:06.640 --> 02:10:07.640]   That's it.
[02:10:07.640 --> 02:10:08.640]   Yeah.
[02:10:08.640 --> 02:10:13.920]   I mean, I do wonder if these glasses, I mean, they can't just be translating glasses.
[02:10:13.920 --> 02:10:15.520]   Like that's the only thing they do.
[02:10:15.520 --> 02:10:18.840]   And if that is, that's a very specialized thing.
[02:10:18.840 --> 02:10:20.720]   Very, very limited, right?
[02:10:20.720 --> 02:10:25.960]   But if they are kind of broad strokes, AR glasses, translation is one thing.
[02:10:25.960 --> 02:10:27.280]   What are those other things?
[02:10:27.280 --> 02:10:28.280]   What is the killer app?
[02:10:28.280 --> 02:10:32.520]   Because that's really cool, but that's a short term kind of drop in sort of thing.
[02:10:32.520 --> 02:10:36.120]   I only need this a handful of times and I need it in very specific situations.
[02:10:36.120 --> 02:10:40.200]   But yeah, I wonder if there would be more functionality.
[02:10:40.200 --> 02:10:46.280]   Yeah, I'd love to be able to get around without looking at my phone, like walking.
[02:10:46.280 --> 02:10:47.280]   Yeah.
[02:10:47.280 --> 02:10:50.000]   But again, like, is that you feel like that's like a tourist thing, right?
[02:10:50.000 --> 02:10:53.480]   Where it's like your, it would be a place that you're unfamiliar with.
[02:10:53.480 --> 02:10:56.480]   A language you're unfamiliar with, something you're unfamiliar with.
[02:10:56.480 --> 02:10:57.480]   You would want to use it.
[02:10:57.480 --> 02:11:00.960]   So it would be by definition, a temporary use case.
[02:11:00.960 --> 02:11:03.680]   It would be in her long term use case.
[02:11:03.680 --> 02:11:04.680]   Yeah.
[02:11:04.680 --> 02:11:06.280]   I'm very mad at direction.
[02:11:06.280 --> 02:11:09.360]   So I would use it all the time walking around my neighborhood.
[02:11:09.360 --> 02:11:10.360]   Well, there you go.
[02:11:10.360 --> 02:11:11.360]   I feel like my husband went to.
[02:11:11.360 --> 02:11:13.400]   Yeah, he's obviously he would get lost.
[02:11:13.400 --> 02:11:15.200]   He would get lost in a wet paper bag.
[02:11:15.200 --> 02:11:16.200]   Like he's terrible.
[02:11:16.200 --> 02:11:17.760]   He has no sense of direction.
[02:11:17.760 --> 02:11:18.760]   No, he knows it.
[02:11:18.760 --> 02:11:19.760]   He'll admit it to you.
[02:11:19.760 --> 02:11:20.760]   He would be great for it.
[02:11:20.760 --> 02:11:21.760]   The mall.
[02:11:21.760 --> 02:11:22.760]   Yeah.
[02:11:22.760 --> 02:11:23.760]   I can never find anything in the mall.
[02:11:23.760 --> 02:11:24.760]   Let's go to the mall.
[02:11:24.760 --> 02:11:25.760]   Yeah.
[02:11:25.760 --> 02:11:26.760]   Go to the mall.
[02:11:26.760 --> 02:11:27.760]   You put your guru.
[02:11:27.760 --> 02:11:28.760]   That's that.
[02:11:28.760 --> 02:11:29.760]   I'm going to find Aunt Annie to get myself a pretzel.
[02:11:29.760 --> 02:11:31.760]   I'm not going to walk for 30 minutes.
[02:11:31.760 --> 02:11:38.160]   If I just had a pair of Google AR glasses that only directed me to the nearest hot pretzel,
[02:11:38.160 --> 02:11:39.520]   I would pay for that actually.
[02:11:39.520 --> 02:11:41.520]   The hot pretzel app.
[02:11:41.520 --> 02:11:42.520]   That's all I wanted.
[02:11:42.520 --> 02:11:44.160]   The hot pretzel is only.
[02:11:44.160 --> 02:11:45.160]   Yeah.
[02:11:45.160 --> 02:11:46.160]   Hot pretzels only.
[02:11:46.160 --> 02:11:47.800]   This is how I'm going to set it to that setting.
[02:11:47.800 --> 02:11:52.440]   Just please do not show me anything but where I can find a hot pretzel with cheese.
[02:11:52.440 --> 02:11:53.440]   That's what I want.
[02:11:53.440 --> 02:11:54.440]   Don't do esta wetsls.
[02:11:54.440 --> 02:11:55.440]   That's all I care.
[02:11:55.440 --> 02:11:59.080]   Wetsls pretzels or Antians.
[02:11:59.080 --> 02:12:00.080]   That's it.
[02:12:00.080 --> 02:12:01.080]   That's all I want.
[02:12:01.080 --> 02:12:02.640]   Just show me where the kiosks are.
[02:12:02.640 --> 02:12:08.000]   So you're wearing these at the mall and sure it tells you how to get to the pretzel.
[02:12:08.000 --> 02:12:13.440]   But on the way you look over in that clothing store, you look over in the clothing store
[02:12:13.440 --> 02:12:18.640]   and there's a little call out that's pointing to a rack with a whole series of pants there.
[02:12:18.640 --> 02:12:23.040]   It says 50 percent or 50 percent off while supplies last or whatever.
[02:12:23.040 --> 02:12:25.400]   Would you be open to that kind of AR?
[02:12:25.400 --> 02:12:27.240]   No, because that's an ad.
[02:12:27.240 --> 02:12:32.240]   But what I would be interested in is if I were, let's say, out of Macy's and I was looking
[02:12:32.240 --> 02:12:38.320]   at a designer handbag and I looked at it and AR was able to scan it and say, "Hey, this
[02:12:38.320 --> 02:12:44.880]   bag is available for 50 percent off on this website or the designer's website or examples
[02:12:44.880 --> 02:12:48.160]   or whatever, that I'm interested in.
[02:12:48.160 --> 02:12:49.680]   That I'm very interested in.
[02:12:49.680 --> 02:12:54.080]   Show me how to get the best deal on something while I'm actively looking at it because I
[02:12:54.080 --> 02:12:56.120]   do that already.
[02:12:56.120 --> 02:12:59.680]   You price compare when you're at a big box retail store.
[02:12:59.680 --> 02:13:01.840]   You look at something, go, "Can I get this cheaper somewhere else?
[02:13:01.840 --> 02:13:02.840]   Let me just double check."
[02:13:02.840 --> 02:13:04.120]   And you check on your phone.
[02:13:04.120 --> 02:13:08.680]   If I could get that information quickly without having to type in a bunch of stuff, it just
[02:13:08.680 --> 02:13:11.560]   scans the item and says, "I know what this is.
[02:13:11.560 --> 02:13:16.840]   This is an iPad from 2020 or whatever."
[02:13:16.840 --> 02:13:18.600]   And here's where you can find it cheaper.
[02:13:18.600 --> 02:13:19.600]   Like, great.
[02:13:19.600 --> 02:13:20.600]   That I'm into.
[02:13:20.600 --> 02:13:22.600]   Can you do that with Google Lens now?
[02:13:22.600 --> 02:13:24.880]   That's a great question.
[02:13:24.880 --> 02:13:26.440]   You can get it with Amazon.
[02:13:26.440 --> 02:13:28.680]   I know if you take a picture.
[02:13:28.680 --> 02:13:29.680]   Yeah.
[02:13:29.680 --> 02:13:34.720]   But I mean just that live parsing of it where it's like there's no real process to it.
[02:13:34.720 --> 02:13:40.400]   If it's just wearing the glasses and it tells me, "Oh, hey, I see that this says it's $2.99,
[02:13:40.400 --> 02:13:43.840]   but you can actually get it for $99 over here.
[02:13:43.840 --> 02:13:48.720]   You know, for this camera lens or whatever, it's $1,000 here and it's half price over
[02:13:48.720 --> 02:13:49.720]   at B&H.
[02:13:49.720 --> 02:13:51.680]   Like, I need to know that information.
[02:13:51.680 --> 02:13:54.200]   Like, that's very helpful to me.
[02:13:54.200 --> 02:13:58.400]   It's waiting for your hot word that is something along the lines of, "Ooh, I like this."
[02:13:58.400 --> 02:13:59.400]   And then it's like, "Bloop!
[02:13:59.400 --> 02:14:00.400]   Okay, let's get to work."
[02:14:00.400 --> 02:14:01.400]   Yeah.
[02:14:01.400 --> 02:14:02.400]   Yeah.
[02:14:02.400 --> 02:14:03.560]   Help me with my help.
[02:14:03.560 --> 02:14:05.000]   Help me impulse buy.
[02:14:05.000 --> 02:14:07.720]   Like, help me with my anxiety spending.
[02:14:07.720 --> 02:14:08.720]   That's what I need.
[02:14:08.720 --> 02:14:11.960]   AR is for anxiety reality.
[02:14:11.960 --> 02:14:12.960]   That's what I need.
[02:14:12.960 --> 02:14:16.160]   I need anxiety reality to help me spend money.
[02:14:16.160 --> 02:14:19.320]   I feel like AR is more anxiety inducing than it is really believing.
[02:14:19.320 --> 02:14:20.320]   Anxious reality, yeah.
[02:14:20.320 --> 02:14:21.920]   It's not augmented.
[02:14:21.920 --> 02:14:22.920]   It's anxious.
[02:14:22.920 --> 02:14:24.680]   It's an anxious reality.
[02:14:24.680 --> 02:14:25.920]   Anxiety ridden.
[02:14:25.920 --> 02:14:26.920]   Yeah.
[02:14:26.920 --> 02:14:27.920]   Yeah.
[02:14:27.920 --> 02:14:33.920]   Maybe AR would be helpful if you were looking for, I don't know how to tie it into the story,
[02:14:33.920 --> 02:14:36.680]   prototypes of an original Apple One being auctioned.
[02:14:36.680 --> 02:14:37.680]   Good try, Jason.
[02:14:37.680 --> 02:14:38.680]   Good try.
[02:14:38.680 --> 02:14:39.680]   Yeah, I tried.
[02:14:39.680 --> 02:14:42.160]   I didn't get those expert transitions in, but not quite.
[02:14:42.160 --> 02:14:43.560]   Good try, you can try.
[02:14:43.560 --> 02:14:51.160]   Apparently though, the original prototype of the Apple One, Steve Jobs' original Apple
[02:14:51.160 --> 02:14:54.520]   computer A prototype, is being auctioned right now.
[02:14:54.520 --> 02:15:00.960]   And I think last I checked it was around $305,000 if you wanted to get it.
[02:15:00.960 --> 02:15:02.560]   So yeah, still $305,000.
[02:15:02.560 --> 02:15:03.920]   See, it's not moving.
[02:15:03.920 --> 02:15:06.480]   You got until August 18th, if you want to get that.
[02:15:06.480 --> 02:15:07.480]   Let's pull our money.
[02:15:07.480 --> 02:15:08.480]   Something.
[02:15:08.480 --> 02:15:10.480]   $125, what do you guys got?
[02:15:10.480 --> 02:15:15.480]   An Apple One in this economy?
[02:15:15.480 --> 02:15:16.480]   No.
[02:15:16.480 --> 02:15:17.480]   No.
[02:15:17.480 --> 02:15:19.480]   Can't it run?
[02:15:19.480 --> 02:15:22.480]   Can't it run do?
[02:15:22.480 --> 02:15:24.480]   That's the question you've got to ask yourself.
[02:15:24.480 --> 02:15:26.720]   It doesn't run do to me if you get a discount.
[02:15:26.720 --> 02:15:28.520]   You should get a discount.
[02:15:28.520 --> 02:15:29.520]   Probably not.
[02:15:29.520 --> 02:15:33.760]   No, no one's giving anybody a discount on that.
[02:15:33.760 --> 02:15:35.360]   And also, yeah, probably not.
[02:15:35.360 --> 02:15:36.440]   It probably cannot renew.
[02:15:36.440 --> 02:15:37.440]   But you know what?
[02:15:37.440 --> 02:15:38.440]   Stranger things have happened.
[02:15:38.440 --> 02:15:41.320]   I love when people put doom on things like pregnancy tests.
[02:15:41.320 --> 02:15:44.680]   It's like the coolest thing in the world.
[02:15:44.680 --> 02:15:46.760]   I haven't seen that one.
[02:15:46.760 --> 02:15:47.760]   Sorry, yeah.
[02:15:47.760 --> 02:15:53.440]   The things people have run doom on is it's actually just like legendary status at this
[02:15:53.440 --> 02:15:54.440]   point.
[02:15:54.440 --> 02:15:58.000]   People have worked very hard to make doom run on just about anything.
[02:15:58.000 --> 02:16:02.640]   If it has a tiny screen, even the tiniest of screens, you can make doom run on it.
[02:16:02.640 --> 02:16:06.000]   Also thanks the question why a pregnancy test has a tiny screen.
[02:16:06.000 --> 02:16:07.920]   Like it's just a yes and a no, right?
[02:16:07.920 --> 02:16:08.920]   No.
[02:16:08.920 --> 02:16:10.920]   Everything needs an app now.
[02:16:10.920 --> 02:16:12.920]   Got to have the words.
[02:16:12.920 --> 02:16:15.240]   It can't just be two lines.
[02:16:15.240 --> 02:16:16.240]   That's confusing.
[02:16:16.240 --> 02:16:19.000]   It's got to be like a plus of a minute.
[02:16:19.000 --> 02:16:20.000]   Yeah, no.
[02:16:20.000 --> 02:16:21.800]   It's really just one thing.
[02:16:21.800 --> 02:16:23.680]   But these people are like, is that a positive?
[02:16:23.680 --> 02:16:25.600]   Does that mean like, oh, what great news?
[02:16:25.600 --> 02:16:26.600]   You're not pregnant.
[02:16:26.600 --> 02:16:27.600]   Like that's positive.
[02:16:27.600 --> 02:16:29.240]   Like it's positive news or positive news.
[02:16:29.240 --> 02:16:30.240]   You are pregnant.
[02:16:30.240 --> 02:16:31.240]   Like it's confusing.
[02:16:31.240 --> 02:16:32.240]   People get confused.
[02:16:32.240 --> 02:16:33.240]   Yeah.
[02:16:33.240 --> 02:16:34.720]   Like the COVID test, it's like positive.
[02:16:34.720 --> 02:16:35.720]   It's not positive.
[02:16:35.720 --> 02:16:36.720]   Yeah.
[02:16:36.720 --> 02:16:37.720]   Oh, wow.
[02:16:37.720 --> 02:16:38.720]   This is the episode of The Office.
[02:16:38.720 --> 02:16:39.720]   I'm sure it is.
[02:16:39.720 --> 02:16:40.720]   Yeah.
[02:16:40.720 --> 02:16:41.720]   I'm sure it is.
[02:16:41.720 --> 02:16:42.720]   Michael, it's positive.
[02:16:42.720 --> 02:16:43.720]   It's negative.
[02:16:43.720 --> 02:16:45.720]   And he's like, oh, no, no, no, negative is good.
[02:16:45.720 --> 02:16:47.720]   He's like, good thing.
[02:16:47.720 --> 02:16:48.720]   Yeah.
[02:16:48.720 --> 02:16:49.720]   Sorry.
[02:16:49.720 --> 02:16:54.960]   I went down the doom on a pregnancy test rabbit hole and found an article on Popular
[02:16:54.960 --> 02:16:56.320]   Mechanics that kind of showed it off.
[02:16:56.320 --> 02:16:58.840]   I put the link in the chat room if anyone wants to check it out.
[02:16:58.840 --> 02:17:02.160]   But that's impressive, even though it's pretty low res.
[02:17:02.160 --> 02:17:04.960]   But you know, technically it works.
[02:17:04.960 --> 02:17:05.960]   Still doom.
[02:17:05.960 --> 02:17:06.960]   It works.
[02:17:06.960 --> 02:17:07.960]   And that's what matters.
[02:17:07.960 --> 02:17:08.960]   That's what matters.
[02:17:08.960 --> 02:17:09.960]   That's what matters.
[02:17:09.960 --> 02:17:15.960]   You are technically correct, which is the best kind of correct.
[02:17:15.960 --> 02:17:20.160]   Well, speaking of doom, I mean, there aren't a whole lot of opportunities to talk about
[02:17:20.160 --> 02:17:21.160]   doom.
[02:17:21.160 --> 02:17:24.200]   Co-creator John Romero apparently working on a new first person shooter.
[02:17:24.200 --> 02:17:30.520]   So if you would like doom, I mean, this isn't the first time that they've made some sort
[02:17:30.520 --> 02:17:31.520]   of a follow up.
[02:17:31.520 --> 02:17:32.520]   So I don't know.
[02:17:32.520 --> 02:17:33.600]   I'm not much of a gamer anymore.
[02:17:33.600 --> 02:17:34.600]   Is this news?
[02:17:34.600 --> 02:17:36.600]   I don't care.
[02:17:36.600 --> 02:17:44.000]   I mean, you know, it's always exciting when somebody who's sort of an icon in games is
[02:17:44.000 --> 02:17:46.360]   doing something new.
[02:17:46.360 --> 02:17:47.360]   That's nice.
[02:17:47.360 --> 02:17:50.400]   But they've got a major publisher, obviously.
[02:17:50.400 --> 02:17:53.000]   I mean, there's a lot of cache there, his name, John Romero.
[02:17:53.000 --> 02:17:56.160]   It's like, oh, yeah, hey, I help make doom.
[02:17:56.160 --> 02:17:57.320]   Like that's kind of a big deal.
[02:17:57.320 --> 02:18:02.160]   So seems like it seems like it'd be pretty easy to find a publisher, which barely that's
[02:18:02.160 --> 02:18:03.160]   the case.
[02:18:03.160 --> 02:18:08.560]   But yeah, they've published other stuff before they had a strategy game.
[02:18:08.560 --> 02:18:13.320]   And I think they talked about this shooter is going to be powered by Unreal Engine.
[02:18:13.320 --> 02:18:16.520]   So it'll be the newest UE5.
[02:18:16.520 --> 02:18:21.520]   So this will be like, you know, a whole, it's going to be a whole thing, I'm sure.
[02:18:21.520 --> 02:18:25.920]   I mean, I'm all about a new single player, shooting man.
[02:18:25.920 --> 02:18:27.880]   The new dooms are so good.
[02:18:27.880 --> 02:18:29.760]   I mean, outrageously good.
[02:18:29.760 --> 02:18:35.440]   If you have not played, if you are a fan of original Doom and you have not played the
[02:18:35.440 --> 02:18:41.440]   new ones, the 2016 Doom, the ones that Bethesda and the ones that they're making, incredible.
[02:18:41.440 --> 02:18:42.440]   So good.
[02:18:42.440 --> 02:18:43.440]   The pacing is so good.
[02:18:43.440 --> 02:18:45.800]   The man, the power fantasy is so good.
[02:18:45.800 --> 02:18:47.480]   The graphics are amazing.
[02:18:47.480 --> 02:18:48.480]   The music is incredible.
[02:18:48.480 --> 02:18:53.760]   It's just like just the way that game just keeps you moving forward and you have so much
[02:18:53.760 --> 02:18:54.760]   fun playing.
[02:18:54.760 --> 02:18:55.760]   It's just great.
[02:18:55.760 --> 02:18:56.760]   It's so, so good.
[02:18:56.760 --> 02:18:57.760]   I can't recommend it enough.
[02:18:57.760 --> 02:18:58.760]   Nice.
[02:18:58.760 --> 02:19:00.520]   I'll have to look into that.
[02:19:00.520 --> 02:19:04.560]   So along the game tip though, Discord coming to Xbox.
[02:19:04.560 --> 02:19:08.160]   Like this, again, I put this in here thinking like, well, that sounds significant because
[02:19:08.160 --> 02:19:10.800]   I know, you know, there's a lot of crossover there.
[02:19:10.800 --> 02:19:16.960]   I'm kind of surprised that Discord wasn't on Xbox prior to this, but apparently that's
[02:19:16.960 --> 02:19:17.960]   the case.
[02:19:17.960 --> 02:19:23.960]   I just don't have to hook a keyboard to my Xbox now.
[02:19:23.960 --> 02:19:26.600]   So now you could just do a Discord call.
[02:19:26.600 --> 02:19:27.600]   It's a call.
[02:19:27.600 --> 02:19:28.600]   It's a voice call.
[02:19:28.600 --> 02:19:29.600]   You're saying voice calls.
[02:19:29.600 --> 02:19:30.600]   I could do that.
[02:19:30.600 --> 02:19:31.600]   I guess.
[02:19:31.600 --> 02:19:34.160]   Here's the problem.
[02:19:34.160 --> 02:19:37.240]   So I love my series.
[02:19:37.240 --> 02:19:38.240]   It's great.
[02:19:38.240 --> 02:19:39.240]   I love Game Pass.
[02:19:39.240 --> 02:19:41.640]   It's an incredible like value for what it is.
[02:19:41.640 --> 02:19:45.600]   This $15 subscription, you get access to so many games.
[02:19:45.600 --> 02:19:50.480]   One, setting up this whole thing is a process and a half.
[02:19:50.480 --> 02:19:52.520]   Like you've got to connect.
[02:19:52.520 --> 02:19:54.200]   You've got to get the mobile app.
[02:19:54.200 --> 02:19:57.040]   And you have to transfer Discord.
[02:19:57.040 --> 02:20:01.640]   You have to use your phone to transfer Discord calls to the Xbox.
[02:20:01.640 --> 02:20:05.680]   You have to connect the Xbox account to your Discord account.
[02:20:05.680 --> 02:20:07.000]   It's very convoluted.
[02:20:07.000 --> 02:20:09.480]   There's a lot going on here.
[02:20:09.480 --> 02:20:14.080]   A lot of gamers use Discord though, so this may prove to be very useful.
[02:20:14.080 --> 02:20:22.720]   And the other thing that I should mention is I have a PS5 and an Xbox series S.
[02:20:22.720 --> 02:20:26.280]   And my best friend and I play video games on both.
[02:20:26.280 --> 02:20:27.720]   We play co-op games on both.
[02:20:27.720 --> 02:20:29.800]   We play on the Switch as well.
[02:20:29.800 --> 02:20:35.920]   And in order of ease of use, PS5 like blows the other two out of the water in terms of
[02:20:35.920 --> 02:20:37.480]   just joining a voice chat.
[02:20:37.480 --> 02:20:38.880]   It's like very simple.
[02:20:38.880 --> 02:20:43.040]   You literally just click on your friend's name and it says join voice chat and you just
[02:20:43.040 --> 02:20:44.040]   join.
[02:20:44.040 --> 02:20:45.040]   That's it.
[02:20:45.040 --> 02:20:48.640]   And on Xbox, it's like more complicated, but it's at least on device.
[02:20:48.640 --> 02:20:53.440]   And then on the Switch, it's like you have to do it through an app that connects to a
[02:20:53.440 --> 02:20:56.280]   specific game that you might be playing at that time.
[02:20:56.280 --> 02:20:57.760]   It's just not even worth it.
[02:20:57.760 --> 02:21:04.880]   So in that regard that it's a little bit more complicated and not as easy to join a voice
[02:21:04.880 --> 02:21:08.560]   chat on Xbox's dashboard.
[02:21:08.560 --> 02:21:10.040]   This is a good thing.
[02:21:10.040 --> 02:21:11.040]   This will be a good thing.
[02:21:11.040 --> 02:21:15.560]   And I think a lot of gamers who are really into Discord and use it very heavily will find
[02:21:15.560 --> 02:21:19.320]   this like a minor inconvenience to connect your accounts and get everything set up.
[02:21:19.320 --> 02:21:22.520]   And then we'll be very happy with it going forward.
[02:21:22.520 --> 02:21:23.760]   Yeah, finally.
[02:21:23.760 --> 02:21:24.760]   Yeah.
[02:21:24.760 --> 02:21:25.760]   Yeah.
[02:21:25.760 --> 02:21:28.360]   But this kind of stuff should just be done across all consoles.
[02:21:28.360 --> 02:21:34.080]   You should just be able to plug into your Discord, plug into, we used to have back in
[02:21:34.080 --> 02:21:37.640]   the day when I was rating and wrath of the Lich King, we should have team speak as just
[02:21:37.640 --> 02:21:39.400]   now new stuff.
[02:21:39.400 --> 02:21:42.960]   But you should be able to plug into all these voice chat apps and just be able to talk to
[02:21:42.960 --> 02:21:46.040]   people and it's just easy, shouldn't make it difficult.
[02:21:46.040 --> 02:21:51.920]   The whole point of gaming in so many aspects at this point are, you know, even when you're
[02:21:51.920 --> 02:21:55.280]   playing a single player game, you can be in voice chat talking to your friends like you're
[02:21:55.280 --> 02:21:56.280]   hanging out with them.
[02:21:56.280 --> 02:21:57.280]   It's very social experience.
[02:21:57.280 --> 02:22:00.080]   So to make it difficult doesn't make sense now.
[02:22:00.080 --> 02:22:03.680]   So maybe if they streamline this process, that would be great.
[02:22:03.680 --> 02:22:06.160]   But for now it's still a good thing.
[02:22:06.160 --> 02:22:07.160]   Yeah.
[02:22:07.160 --> 02:22:09.000]   Yeah, that was kind of part of the reason why I put it in there.
[02:22:09.000 --> 02:22:11.040]   I was just really surprised that it hadn't happened before.
[02:22:11.040 --> 02:22:12.040]   So that's good.
[02:22:12.040 --> 02:22:19.840]   And then finally about to wrap things up, but finally, Meta, that's Meta, the installation
[02:22:19.840 --> 02:22:26.440]   art company that you can find at Meta.is is apparently suing Meta, the Facebook company
[02:22:26.440 --> 02:22:28.440]   for trademark violation.
[02:22:28.440 --> 02:22:31.200]   Meta.is has been around for about 12 years.
[02:22:31.200 --> 02:22:33.680]   They hold a valid trademark for the name.
[02:22:33.680 --> 02:22:37.120]   And actually their business has to do with Malta.
[02:22:37.120 --> 02:22:41.640]   And this is from their site, multi-sensory live experiences that ignite the human spirit
[02:22:41.640 --> 02:22:44.800]   with technology, design, music, and storytelling.
[02:22:44.800 --> 02:22:49.600]   So I don't know if that's a perfect overlay over the top of the metaverse ambitions that
[02:22:49.600 --> 02:22:54.560]   Facebook has, but they've been trying to negotiate with Meta for about eight months now saying,
[02:22:54.560 --> 02:23:00.800]   hey, you guys are embroiled in all of these privacy scandals and now our name is tarnished.
[02:23:00.800 --> 02:23:03.520]   And it's impossible to share the name of the company.
[02:23:03.520 --> 02:23:05.120]   So they're suing Meta.
[02:23:05.120 --> 02:23:06.120]   Probably.
[02:23:06.120 --> 02:23:09.080]   I can't imagine it's going to amount to very much.
[02:23:09.080 --> 02:23:15.280]   But I feel bad for them because that's quite a, you know, they have all that background.
[02:23:15.280 --> 02:23:19.640]   The 12 years of building up their own name and reputation only to have Facebook come
[02:23:19.640 --> 02:23:21.480]   along and buy the name and.
[02:23:21.480 --> 02:23:22.840]   Arne-ish it.
[02:23:22.840 --> 02:23:23.840]   Yay.
[02:23:23.840 --> 02:23:24.840]   Tarnish it.
[02:23:24.840 --> 02:23:26.600]   You have tarnished our good name.
[02:23:26.600 --> 02:23:27.600]   Yeah.
[02:23:27.600 --> 02:23:28.600]   Harnessed.
[02:23:28.600 --> 02:23:30.360]   It's like the Mark Zuckerberg Journal Hospital.
[02:23:30.360 --> 02:23:34.040]   People were concerned about going to the Mark Zuckerberg Hospital because they were afraid
[02:23:34.040 --> 02:23:35.600]   in San Francisco.
[02:23:35.600 --> 02:23:38.920]   They were afraid that their data would be sold to Facebook.
[02:23:38.920 --> 02:23:40.800]   That's not tarnished.
[02:23:40.800 --> 02:23:42.320]   That's not tarnished.
[02:23:42.320 --> 02:23:47.560]   When your name, when your name is, is that tarnished?
[02:23:47.560 --> 02:23:49.960]   Maybe you shouldn't put it on things, especially with healthcare.
[02:23:49.960 --> 02:23:50.960]   Yeah.
[02:23:50.960 --> 02:23:53.320]   Amazon's not going to call it the Jeff Bezos Hospital.
[02:23:53.320 --> 02:23:54.320]   Exactly.
[02:23:54.320 --> 02:23:55.320]   No, that's true.
[02:23:55.320 --> 02:23:57.040]   Not that we know anyways.
[02:23:57.040 --> 02:23:58.040]   Probably not.
[02:23:58.040 --> 02:23:59.040]   I mean, yeah, so far.
[02:23:59.040 --> 02:24:00.040]   Yeah.
[02:24:00.040 --> 02:24:01.280]   He's probably got his own hospital.
[02:24:01.280 --> 02:24:03.280]   It's just for him.
[02:24:03.280 --> 02:24:04.480]   Forty rooms.
[02:24:04.480 --> 02:24:05.480]   Yeah.
[02:24:05.480 --> 02:24:07.800]   It's like Barbara Streisand has a mall.
[02:24:07.800 --> 02:24:11.400]   You know Barbara Streisand has a mall under her house.
[02:24:11.400 --> 02:24:12.400]   It's like a mall.
[02:24:12.400 --> 02:24:13.400]   Wow.
[02:24:13.400 --> 02:24:14.400]   Wow.
[02:24:14.400 --> 02:24:16.360]   Does it have a Wetzel's pretzels?
[02:24:16.360 --> 02:24:17.840]   You know what?
[02:24:17.840 --> 02:24:18.840]   That wouldn't surprise me.
[02:24:18.840 --> 02:24:20.840]   If it doesn't, what's the point?
[02:24:20.840 --> 02:24:21.840]   Yeah, it's true.
[02:24:21.840 --> 02:24:26.880]   But also, interestingly enough, I think about that when I think about even more rich people.
[02:24:26.880 --> 02:24:28.840]   Yeah, he probably does have his own hospital.
[02:24:28.840 --> 02:24:33.080]   He probably just has a doctor on call all the time.
[02:24:33.080 --> 02:24:34.080]   Oh, yeah.
[02:24:34.080 --> 02:24:36.080]   You know, just on retainer.
[02:24:36.080 --> 02:24:41.640]   Just pays him just a column and be like, "Hey, I got this weird like, Bunyan.
[02:24:41.640 --> 02:24:43.520]   I needed, can you just look at it?"
[02:24:43.520 --> 02:24:44.520]   Just like text him.
[02:24:44.520 --> 02:24:46.720]   He's like, "Hey, I was lifting weights the other day.
[02:24:46.720 --> 02:24:50.000]   I think I strained my bicep help."
[02:24:50.000 --> 02:24:54.160]   It's just, you know, he's just got some doctor on call all the time.
[02:24:54.160 --> 02:24:55.640]   He has multiple hospitals.
[02:24:55.640 --> 02:24:57.600]   One is on his yacht.
[02:24:57.600 --> 02:24:59.160]   It's a traveling hospital that follows.
[02:24:59.160 --> 02:25:00.160]   Oh, yeah.
[02:25:00.160 --> 02:25:01.720]   Floating hospital, totally.
[02:25:01.720 --> 02:25:02.720]   Yeah.
[02:25:02.720 --> 02:25:03.720]   More than one yacht.
[02:25:03.720 --> 02:25:05.720]   Which he has a hospital on an yacht.
[02:25:05.720 --> 02:25:09.760]   And therefore, which therefore, yes, he has more than one hospital.
[02:25:09.760 --> 02:25:10.760]   Yeah.
[02:25:10.760 --> 02:25:13.760]   We can just extrapolate the data.
[02:25:13.760 --> 02:25:21.520]   The Bezos healthcare system is far more than advanced than one medical.
[02:25:21.520 --> 02:25:23.320]   Yeah, well, maybe that's it.
[02:25:23.320 --> 02:25:24.320]   We have to look forward to it.
[02:25:24.320 --> 02:25:26.800]   100% he has called it St. Jeff's.
[02:25:26.800 --> 02:25:27.800]   Like it's St. Jeff's.
[02:25:27.800 --> 02:25:28.800]   Oh, yeah.
[02:25:28.800 --> 02:25:29.800]   Oh, my.
[02:25:29.800 --> 02:25:30.800]   Oh, my.
[02:25:30.800 --> 02:25:31.800]   Just memorial.
[02:25:31.800 --> 02:25:36.560]   Oh, that's got to be the name he's like, annoying today with the St. Jeff's memorial hospital.
[02:25:36.560 --> 02:25:37.560]   St. Jeff's.
[02:25:37.560 --> 02:25:39.120]   We're trying to make that happen.
[02:25:39.120 --> 02:25:40.120]   Bezos.
[02:25:40.120 --> 02:25:41.520]   We're trying to make that happen.
[02:25:41.520 --> 02:25:45.960]   I just want you to know, Jeff Bezos, if you are in fact going to name your weird, like,
[02:25:45.960 --> 02:25:49.200]   one medical stuff, St. Jeff's, you owe me so much money.
[02:25:49.200 --> 02:25:54.440]   You have to cut me a massive check.
[02:25:54.440 --> 02:26:00.760]   Oh, and all he has to do to get in touch with you is go to ashleyascheth.com.
[02:26:00.760 --> 02:26:01.760]   Because why?
[02:26:01.760 --> 02:26:02.920]   Because you are awesome, Ashley.
[02:26:02.920 --> 02:26:06.760]   Thank you so much for hopping on this episode of this week in tech this week.
[02:26:06.760 --> 02:26:08.080]   It's been a lot of fun.
[02:26:08.080 --> 02:26:09.440]   It has been a lot of fun.
[02:26:09.440 --> 02:26:10.840]   Can I plug my book?
[02:26:10.840 --> 02:26:11.840]   Absolutely.
[02:26:11.840 --> 02:26:12.840]   Please do.
[02:26:12.840 --> 02:26:13.840]   This is your opportunity.
[02:26:13.840 --> 02:26:14.840]   What you got?
[02:26:14.840 --> 02:26:17.040]   It's like the one thing that I've, it's the one thing I'm doing right now.
[02:26:17.040 --> 02:26:24.320]   So I am, I'm excited to tell people I'm writing the art of psychonauts to with I am 8 bit.
[02:26:24.320 --> 02:26:30.600]   So if you go to I am 8 bit.com, there is, well, first of all, they have a ton of really
[02:26:30.600 --> 02:26:33.920]   awesome psychonauts to, they have a collection.
[02:26:33.920 --> 02:26:38.840]   So they have a physical collectors edition that they're going to release later this year.
[02:26:38.840 --> 02:26:45.640]   And yeah, it's going to be this gorgeous, like well laid out art book.
[02:26:45.640 --> 02:26:50.120]   You can see there's the, that's our, that's our, it's not final, but this mock cover that
[02:26:50.120 --> 02:26:52.280]   we have is absolutely beautiful.
[02:26:52.280 --> 02:26:58.120]   We are working with lost in cult who makes a prestigious, very high quality gaming journal.
[02:26:58.120 --> 02:26:59.400]   It's not even really a magazine.
[02:26:59.400 --> 02:27:00.680]   It's sort of a collector's item.
[02:27:00.680 --> 02:27:03.480]   They're going to be doing the book design.
[02:27:03.480 --> 02:27:09.400]   And I have been drowning in beautiful concept art and interviewing a lot of the developers
[02:27:09.400 --> 02:27:12.280]   at Double Fine about their work on psychonauts to.
[02:27:12.280 --> 02:27:17.480]   And, and so if you are a fan of the game, you can pre-order it and it will be out as soon
[02:27:17.480 --> 02:27:19.480]   as I'm done writing it, which who knows when that will be.
[02:27:19.480 --> 02:27:21.680]   No, it's supposed to be out of quarter one of next year.
[02:27:21.680 --> 02:27:26.440]   So please make me look good and pre-order, pre-order this book that I'm writing that
[02:27:26.440 --> 02:27:28.840]   I am so excited to be involved with.
[02:27:28.840 --> 02:27:31.240]   I'm really so, so, so excited about it.
[02:27:31.240 --> 02:27:33.640]   Yeah, that looks really cool.
[02:27:33.640 --> 02:27:36.760]   That's some pretty catching artwork there as well.
[02:27:36.760 --> 02:27:38.200]   Yeah, gorgeous, gorgeous stuff.
[02:27:38.200 --> 02:27:39.560]   Yeah, beautiful.
[02:27:39.560 --> 02:27:40.040]   Right on.
[02:27:40.040 --> 02:27:41.000]   Congratulations.
[02:27:41.000 --> 02:27:42.840]   That's a accomplishment.
[02:27:42.840 --> 02:27:46.040]   I was very excited when they asked me if I wanted to be the person to write it.
[02:27:46.040 --> 02:27:48.040]   That's amazing.
[02:27:48.040 --> 02:27:53.000]   Well, Ashley, we will be following and we will definitely you will, you will be hearing from me
[02:27:53.000 --> 02:27:57.160]   as the person who books this show since the end of the future to bring you back.
[02:27:57.160 --> 02:28:00.120]   And then of course, as you get closer to the release of that,
[02:28:00.120 --> 02:28:04.680]   get in touch, we would love to bring you back and give you the chance to, to plug it.
[02:28:04.680 --> 02:28:06.120]   So, Ashley.
[02:28:06.120 --> 02:28:06.680]   Show it off.
[02:28:06.680 --> 02:28:07.240]   Show it off.
[02:28:07.240 --> 02:28:07.720]   That's right.
[02:28:07.720 --> 02:28:08.680]   Thanks for having me.
[02:28:08.680 --> 02:28:09.160]   Yeah.
[02:28:09.160 --> 02:28:14.440]   And Roberto Baldwin, thank you so much, man, for hopping on today and, and bringing the man
[02:28:14.440 --> 02:28:16.680]   about town to this panel today.
[02:28:16.680 --> 02:28:17.720]   What do you want to leave people with?
[02:28:17.720 --> 02:28:18.760]   Man about town.
[02:28:18.760 --> 02:28:20.280]   I don't know.
[02:28:21.880 --> 02:28:23.560]   I write a bunch of stuff for a bunch of people.
[02:28:23.560 --> 02:28:25.080]   Oh, wait, you know what?
[02:28:25.080 --> 02:28:29.160]   I have a, if you're in the Bay Area and if you like the talking heads and Divo,
[02:28:29.160 --> 02:28:34.840]   this hasn't even been announced yet, but at September 10th, two bands, two of my band,
[02:28:34.840 --> 02:28:35.560]   I have so many.
[02:28:35.560 --> 02:28:38.280]   Anyway, we're doing a Divo and a talking head show.
[02:28:38.280 --> 02:28:41.160]   It's September 10th at Rickshaw Stop at San Francisco.
[02:28:41.160 --> 02:28:41.480]   Nice.
[02:28:41.480 --> 02:28:44.440]   And I don't think there's anything else.
[02:28:44.440 --> 02:28:45.640]   I, I don't know.
[02:28:45.640 --> 02:28:47.800]   Be nice to be your friends.
[02:28:47.800 --> 02:28:49.480]   I guess that's my big plug for the day.
[02:28:49.480 --> 02:28:50.760]   There you go.
[02:28:51.320 --> 02:28:53.400]   And, and to your pets as well.
[02:28:53.400 --> 02:28:55.960]   And to your pet, especially, I mean, who is it nice to their pets?
[02:28:55.960 --> 02:28:56.440]   Come on.
[02:28:56.440 --> 02:29:00.360]   Some people need a reminder probably.
[02:29:00.360 --> 02:29:01.400]   Some people have a problem.
[02:29:01.400 --> 02:29:04.840]   The dogs are circling me like sharks because they want to go outside.
[02:29:04.840 --> 02:29:10.840]   They can feel the show coming to an end.
[02:29:10.840 --> 02:29:11.960]   Yes, they can feel it.
[02:29:11.960 --> 02:29:12.600]   It's in the air.
[02:29:12.600 --> 02:29:13.880]   Yeah, it's a pleasure.
[02:29:13.880 --> 02:29:15.560]   It's a lot of fun hanging out with you today.
[02:29:15.560 --> 02:29:21.160]   And of course, Megan Moroni, I have missed podcasting with you.
[02:29:21.160 --> 02:29:23.320]   It's so good to have you on the show today, Megan.
[02:29:23.320 --> 02:29:24.200]   Thank you for hopping on.
[02:29:24.200 --> 02:29:26.040]   It's good to be here.
[02:29:26.040 --> 02:29:29.160]   We should go to celebrate your birthday to Robbie's show,
[02:29:29.160 --> 02:29:30.680]   which is the day before your birthday.
[02:29:30.680 --> 02:29:32.280]   Good memory.
[02:29:32.280 --> 02:29:34.040]   There you go.
[02:29:34.040 --> 02:29:35.000]   Wow.
[02:29:35.000 --> 02:29:37.240]   Thank you for remembering that.
[02:29:37.240 --> 02:29:38.760]   But you're welcome.
[02:29:38.760 --> 02:29:40.600]   You know my birthday.
[02:29:40.600 --> 02:29:43.000]   What were you on the spot?
[02:29:43.000 --> 02:29:44.520]   Yeah, I'll tell you off.
[02:29:44.520 --> 02:29:45.720]   I'll tell you in a second.
[02:29:45.720 --> 02:29:47.320]   Tell us what you're working on, Megan.
[02:29:47.320 --> 02:29:48.760]   Okay.
[02:29:50.120 --> 02:29:51.400]   I am.
[02:29:51.400 --> 02:29:55.160]   So I cover the workplace at Protocol.
[02:29:55.160 --> 02:30:01.960]   Protocol is a part of Politico and we cover power and politics and tech.
[02:30:01.960 --> 02:30:08.600]   So just how technology works as a force of power right now.
[02:30:08.600 --> 02:30:10.920]   And so covering the workplace,
[02:30:10.920 --> 02:30:13.640]   I'm talking about back to work, remote work, hybrid work,
[02:30:14.600 --> 02:30:20.840]   labor, organizing, DEI, everything that involves working.
[02:30:20.840 --> 02:30:24.120]   So you can check that out at protocol.com.
[02:30:24.120 --> 02:30:26.920]   And I do weekly newsletter about the workplace.
[02:30:26.920 --> 02:30:27.800]   So sign up for that.
[02:30:27.800 --> 02:30:32.200]   And then you can get me in your inbox, me and my team,
[02:30:32.200 --> 02:30:33.400]   Tuesday, Thursday, Sunday.
[02:30:33.400 --> 02:30:36.200]   So yeah, that's what I'm doing.
[02:30:36.200 --> 02:30:40.920]   Right on, but not on March 15th on that day.
[02:30:40.920 --> 02:30:44.200]   You're celebrating your birthday.
[02:30:45.000 --> 02:30:45.480]   Yes.
[02:30:45.480 --> 02:30:45.960]   See?
[02:30:45.960 --> 02:30:46.440]   Yes.
[02:30:46.440 --> 02:30:46.760]   See?
[02:30:46.760 --> 02:30:47.400]   Yeah.
[02:30:47.400 --> 02:30:48.600]   I got there eventually.
[02:30:48.600 --> 02:30:50.120]   There you go.
[02:30:50.120 --> 02:30:50.920]   I'm embarrassed.
[02:30:50.920 --> 02:30:51.880]   All right.
[02:30:51.880 --> 02:30:52.760]   Thank you, Megan.
[02:30:52.760 --> 02:30:54.120]   Always a pleasure.
[02:30:54.120 --> 02:30:55.320]   So great to see you today.
[02:30:55.320 --> 02:30:56.360]   Appreciate it.
[02:30:56.360 --> 02:30:56.840]   Thank you.
[02:30:56.840 --> 02:31:01.160]   And me, well, you can find me all over the Twitch network
[02:31:01.160 --> 02:31:04.920]   as evidenced by this very show, sitting in for Leo.
[02:31:04.920 --> 02:31:06.920]   Leo should be back next week.
[02:31:06.920 --> 02:31:07.960]   So look forward to that.
[02:31:07.960 --> 02:31:11.560]   But you can find me at Jason Howell on Twitter,
[02:31:11.560 --> 02:31:12.600]   doing all about Android,
[02:31:12.600 --> 02:31:15.480]   Twitch.tv/aa every Tuesday,
[02:31:15.480 --> 02:31:18.280]   doing tech news weekly with Mike Asarj and every Thursday.
[02:31:18.280 --> 02:31:19.560]   That's an interviews show.
[02:31:19.560 --> 02:31:20.440]   We have a lot of fun with that.
[02:31:20.440 --> 02:31:22.760]   Twitter.tv/tnw.
[02:31:22.760 --> 02:31:23.640]   So check that out.
[02:31:23.640 --> 02:31:27.080]   Let's see here, club Twitch.
[02:31:27.080 --> 02:31:28.440]   Should we talk a little bit about this?
[02:31:28.440 --> 02:31:30.760]   Twitter.tv/clubtwit.
[02:31:30.760 --> 02:31:32.120]   You may or may not have heard,
[02:31:32.120 --> 02:31:36.040]   but we have a subscription ad-free tier service
[02:31:36.040 --> 02:31:38.200]   for all of our shows, no ads.
[02:31:38.200 --> 02:31:40.040]   If you go to Twitter.tv/clubtwit,
[02:31:40.040 --> 02:31:41.400]   you can see all about it.
[02:31:41.400 --> 02:31:42.840]   You get all of our shows with no ads.
[02:31:42.840 --> 02:31:47.160]   You also get exclusive Twitch Plus podcast feed content.
[02:31:47.160 --> 02:31:50.360]   So a lot of some of the behind-the-scenes stuff that we do
[02:31:50.360 --> 02:31:52.200]   before and after shows gets put in there.
[02:31:52.200 --> 02:31:57.160]   Aunt Pruitt, of course, community manager of club Twitch is just,
[02:31:57.160 --> 02:32:00.120]   he's, there's a book club that he and Stacy do.
[02:32:00.120 --> 02:32:05.000]   There's all sorts of awesome stuff happening just in the club as well.
[02:32:05.000 --> 02:32:06.680]   So Twitch.tv/clubtwit,
[02:32:06.680 --> 02:32:09.320]   get that as well as access to the members only Discord channel,
[02:32:09.320 --> 02:32:13.240]   seven bucks a month, or you can pay for the entire year for $84 for,
[02:32:13.240 --> 02:32:14.920]   for the year.
[02:32:14.920 --> 02:32:17.000]   So do check that out.
[02:32:17.000 --> 02:32:19.320]   And we think you will love what you find there.
[02:32:19.320 --> 02:32:23.480]   As for this show, Twitch.tv/twit is pretty easy.
[02:32:23.480 --> 02:32:23.880]   Go there.
[02:32:23.880 --> 02:32:26.680]   You'll find all the information you need to know about this week in tech.
[02:32:26.680 --> 02:32:34.680]   We do this show every Sunday, 5 15 pm Eastern, 2 15 pm Pacific, 21 15 UTC.
[02:32:34.680 --> 02:32:38.040]   So if you happen to be around a computer and you want to watch live,
[02:32:38.040 --> 02:32:38.840]   you can certainly do that.
[02:32:38.840 --> 02:32:40.200]   Twitch.tv/live.
[02:32:40.200 --> 02:32:44.120]   But I would say subscribe in your podcast of choice,
[02:32:44.120 --> 02:32:45.560]   all that information on the site,
[02:32:45.560 --> 02:32:47.720]   and then you'll get the episode like magic.
[02:32:47.720 --> 02:32:48.920]   You won't even have to think about it.
[02:32:48.920 --> 02:32:51.960]   It'll be there waiting for you as soon as it's ready.
[02:32:51.960 --> 02:32:55.880]   Thank you so much for the opportunity to sit in for Leo today.
[02:32:55.880 --> 02:32:57.640]   I've just had such a blast doing this,
[02:32:57.640 --> 02:32:59.560]   and I can kind of check that off my list,
[02:32:59.560 --> 02:33:01.000]   hosted on episode of Twitch.
[02:33:01.000 --> 02:33:04.440]   And thanks to everyone out there for watching, listening.
[02:33:04.440 --> 02:33:05.880]   Another Twitch is in the can.
[02:33:05.880 --> 02:33:06.600]   We'll see you later.
[02:33:06.600 --> 02:33:18.040]   [music]

