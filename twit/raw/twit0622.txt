;FFMETADATA1
title=Running for Human
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=622
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:03.960]   It's time for Twit this weekend Tech Great Show ahead for you Brianna Wu,
[00:00:03.960 --> 00:00:08.720]   Barretunde Thurston, Larry Magad. Oh my goodness we're gonna talk about the new
[00:00:08.720 --> 00:00:13.560]   Model 3. It came out on Friday. Will the iPhone not have a fingerprint reader?
[00:00:13.560 --> 00:00:18.440]   That's what the rumors are saying and I'm gonna show you my favorite gadget.
[00:00:18.440 --> 00:00:24.040]   Brianna says it's ugly but I love it. It's all coming up next on Twit.
[00:00:25.240 --> 00:00:30.760]   Netcast you love from people you trust.
[00:00:30.760 --> 00:00:41.560]   This is Twit. Bandwidth for this weekend Tech is provided by CashFly at CACHEFLY.com.
[00:00:41.560 --> 00:00:53.720]   This is Twit this weekend Tech, episode 622 recorded Sunday July 9th 2017.
[00:00:53.720 --> 00:00:59.800]   Running for human. This weekend Tech is brought to you by LegalZoom. LegalZoom
[00:00:59.800 --> 00:01:04.480]   helps more than a million people with DBAs, LLCs, incorporation and more.
[00:01:04.480 --> 00:01:09.040]   Visit LegalZoom.com and enter Twit at the checkout for special savings.
[00:01:09.040 --> 00:01:14.880]   And by Casper, an online retailer, premium mattresses for a fraction of the price
[00:01:14.880 --> 00:01:19.200]   because everyone deserves a great night's sleep. Get $50 off any mattress
[00:01:19.200 --> 00:01:24.360]   purchased by visiting Casper.com/Twit and entering the promo code TWIT.
[00:01:24.360 --> 00:01:29.360]   And by Rocket Mortgage from Quick and Loans. Home plays a big role in your life.
[00:01:29.360 --> 00:01:33.200]   That's why Quick and Loans created Rocket Mortgage. It lets you apply simply and
[00:01:33.200 --> 00:01:37.600]   understand the entire mortgage process fully so you can be completely confident
[00:01:37.600 --> 00:01:43.440]   so you're getting the right mortgage for you. Get started at Rocket Mortgage.com/Twit2.
[00:01:43.440 --> 00:01:47.560]   And by Tracker, a coin-sized tracking device that pairs with your smartphone
[00:01:47.560 --> 00:01:52.120]   and keeps you from losing your most valued possessions. Visit the Tracker.com right now
[00:01:52.120 --> 00:01:55.760]   and enter the promo code TWIT to save 20% off any order.
[00:01:55.760 --> 00:02:01.640]   It's time for Twit. This week at Tech, the show we get together with some of the best
[00:02:01.640 --> 00:02:06.040]   minds in technology, journalism and talk about what's going on.
[00:02:06.040 --> 00:02:11.600]   Today we'll start with Larry Magad, CBS Radio News. Connects safely.org.
[00:02:11.600 --> 00:02:14.400]   Safekids.com. Nice to see you. He's looking up his test.
[00:02:14.400 --> 00:02:16.600]   Oh, I got it. Got a camera? Got a camera?
[00:02:16.600 --> 00:02:19.560]   Look at his test. He's got his Tesla order number. I found him.
[00:02:19.560 --> 00:02:21.360]   Don't show your VIN. That's apparently it.
[00:02:21.360 --> 00:02:22.520]   Am I VIN showing?
[00:02:22.520 --> 00:02:23.240]   I don't mind.
[00:02:23.240 --> 00:02:24.960]   Have you shown your VIN.
[00:02:24.960 --> 00:02:26.280]   That's the FCE.
[00:02:26.280 --> 00:02:26.920]   Shocking.
[00:02:26.920 --> 00:02:29.720]   Thank you. Your reservation is confirmed. It doesn't tell me my VIN.
[00:02:29.720 --> 00:02:30.720]   It doesn't tell you that.
[00:02:30.720 --> 00:02:33.560]   No, once you get your VIN, that means you're actually ready to start making it.
[00:02:33.560 --> 00:02:35.560]   I was really nervous because until I'm in.
[00:02:35.560 --> 00:02:39.000]   So I had to look at the email came from Tesla Motors.com.
[00:02:39.000 --> 00:02:40.920]   That used to be Tesla.com.
[00:02:40.920 --> 00:02:42.760]   So I was looking for the wrong email.
[00:02:42.760 --> 00:02:44.600]   Well, glad you found it.
[00:02:44.600 --> 00:02:46.000]   Oh, I thought you. We thought he dreamed it.
[00:02:46.000 --> 00:02:48.560]   I thought I'd be driving my Pinto for the rest of my life.
[00:02:48.560 --> 00:02:53.720]   Also with us running for Congress in the Massachusetts 9th district, right?
[00:02:53.720 --> 00:02:55.480]   Brianna Wu. 8th district.
[00:02:55.480 --> 00:02:57.120]   Yeah. That's it. That's it.
[00:02:57.120 --> 00:02:59.920]   Brianna Wu at brianowoo2018.com.
[00:02:59.920 --> 00:03:01.920]   She's, of course, a game developer, SpaceCatGal.
[00:03:01.920 --> 00:03:05.840]   And I did not know this, but a former life and investigative reporter.
[00:03:05.840 --> 00:03:07.760]   Good for you. That's why I did. That's why I did.
[00:03:07.760 --> 00:03:12.400]   I had to tell you, your listeners and your viewers on this show are freaking amazing.
[00:03:12.400 --> 00:03:15.120]   Every time I come on, they are just amazing.
[00:03:15.120 --> 00:03:18.320]   Like some of the smartest conversations I have after I leave.
[00:03:18.320 --> 00:03:19.760]   It's just amazing.
[00:03:19.760 --> 00:03:23.520]   I have this philosophy of you treat your audience as intelligent,
[00:03:23.520 --> 00:03:25.360]   which television is famous for not doing.
[00:03:25.360 --> 00:03:26.560]   Yes, that's true.
[00:03:26.560 --> 00:03:28.080]   That you get an intelligent audience.
[00:03:28.080 --> 00:03:30.400]   I don't know why. It's crazy, crazy talk.
[00:03:30.400 --> 00:03:35.280]   Anyway, wonderful. And then, but part of the way I do that is have people like you Brianna on.
[00:03:35.280 --> 00:03:36.560]   So thank you for being here.
[00:03:36.560 --> 00:03:41.200]   And speaking of smarty pants, here's Mr. Baratunde Thurston.
[00:03:41.200 --> 00:03:42.880]   Futures. Hey.
[00:03:42.880 --> 00:03:43.720]   Comedian.
[00:03:43.720 --> 00:03:48.240]   Activist. Notice we put the Harvard comma in your lower third, just for you.
[00:03:48.240 --> 00:03:50.080]   I'm a fan of that.
[00:03:50.080 --> 00:03:54.000]   I was taught to type that way well before you even heard of Harvard.
[00:03:54.000 --> 00:03:56.880]   And people who do it another way, I trust them less.
[00:03:56.880 --> 00:03:57.440]   Well, it's funny.
[00:03:57.440 --> 00:03:59.600]   It's people who go to Oxford called the Oxford comma.
[00:03:59.600 --> 00:04:01.600]   So there's apparently some dispute over the.
[00:04:01.600 --> 00:04:04.480]   It's the elitist comma regardless of which side of the poem.
[00:04:04.480 --> 00:04:08.080]   Well, maybe since you are a Harvard man, you could help me with this.
[00:04:08.080 --> 00:04:10.720]   Should you use a Harvard comma before an ampersand?
[00:04:12.560 --> 00:04:14.000]   Oh, I think yeah, you should.
[00:04:14.000 --> 00:04:14.400]   You should.
[00:04:14.400 --> 00:04:14.960]   Okay.
[00:04:14.960 --> 00:04:15.520]   Okay.
[00:04:15.520 --> 00:04:16.560]   Just checking.
[00:04:16.560 --> 00:04:18.800]   See, he earned that degree.
[00:04:18.800 --> 00:04:19.920]   Baratunde's been so new.
[00:04:19.920 --> 00:04:21.440]   We're going to talk about that in just a little bit,
[00:04:21.440 --> 00:04:25.440]   but we're glad to have all three of you here to talk about the week's tech news.
[00:04:25.440 --> 00:04:27.840]   And I guess that was one big story in our audience,
[00:04:27.840 --> 00:04:33.600]   our studio audience reminded me that on Friday, Elon Musk tweeted the first number one.
[00:04:33.600 --> 00:04:38.240]   Model three off the assembly line, which is a big deal.
[00:04:38.240 --> 00:04:40.560]   This is the first relatively affordable Tesla.
[00:04:41.760 --> 00:04:45.840]   Although you know, you're going to have to pay an extra $5,000 for the software.
[00:04:45.840 --> 00:04:48.400]   You don't get autopilot.
[00:04:48.400 --> 00:04:49.680]   You had to pay for that too.
[00:04:49.680 --> 00:04:50.080]   And you're.
[00:04:50.080 --> 00:04:51.680]   Yeah, you do crazy.
[00:04:51.680 --> 00:04:52.720]   I'll tell you what he and does.
[00:04:52.720 --> 00:04:53.840]   It's really interesting.
[00:04:53.840 --> 00:04:59.040]   He's actually and he's have to be to do this, but I will give him full marks for being,
[00:04:59.040 --> 00:05:06.160]   you know, the amazing visionary.
[00:05:06.160 --> 00:05:08.480]   I want to call him the Tony Stark of our generation.
[00:05:08.480 --> 00:05:09.200]   I think that's fair.
[00:05:09.200 --> 00:05:10.560]   I think that's fair.
[00:05:10.560 --> 00:05:11.440]   He's iron man.
[00:05:11.440 --> 00:05:11.760]   Yeah.
[00:05:11.760 --> 00:05:15.760]   But he's also, and I think you have to be a brilliant marketer.
[00:05:15.760 --> 00:05:19.760]   So a lot of the features you'll find on your new car, Larry.
[00:05:19.760 --> 00:05:26.480]   First of all, cost money, but also what the truth is, a Tesla is really just electric go-kart.
[00:05:26.480 --> 00:05:30.560]   And then they put on it this stuff that makes you want it bad.
[00:05:30.560 --> 00:05:34.000]   Like the bio weapon defense mode.
[00:05:34.000 --> 00:05:35.120]   Wait, what?
[00:05:35.120 --> 00:05:37.600]   Why are you serious?
[00:05:37.600 --> 00:05:39.840]   Model X has a bio weapon defense mode.
[00:05:39.840 --> 00:05:43.120]   It even has the bio hazard, you know, that weird logo on it.
[00:05:43.120 --> 00:05:47.600]   And it costs money because it's like some super filter or something.
[00:05:47.600 --> 00:05:49.760]   It's just, it's probably just a HEPA filter, right?
[00:05:49.760 --> 00:05:51.120]   But Elon's brilliant.
[00:05:51.120 --> 00:05:56.160]   He calls it the bio weapon defense mode and puts a bio weapon logo on it.
[00:05:56.160 --> 00:05:58.000]   And you pay thousands more for it.
[00:05:58.000 --> 00:05:58.960]   Because what is it?
[00:05:58.960 --> 00:05:59.520]   And how are you?
[00:05:59.520 --> 00:06:01.280]   What are you protected from?
[00:06:01.280 --> 00:06:02.400]   Well, bio weapons.
[00:06:04.400 --> 00:06:07.440]   If the screen says anthrax ahead, I will be ready.
[00:06:07.440 --> 00:06:09.120]   I could have used that car at Berkeley.
[00:06:09.120 --> 00:06:10.800]   Yeah, actually.
[00:06:10.800 --> 00:06:12.320]   Yeah, that's right.
[00:06:12.320 --> 00:06:14.400]   Tier gas and the light.
[00:06:14.400 --> 00:06:17.040]   And so my autopilot is going to cost me five grand, right?
[00:06:17.040 --> 00:06:19.120]   Yeah, so they tell the autopilot.
[00:06:19.120 --> 00:06:19.600]   Yeah.
[00:06:19.600 --> 00:06:22.720]   But you do have to, to be fair, you are paying for not just software,
[00:06:22.720 --> 00:06:23.600]   but additional hardware.
[00:06:23.600 --> 00:06:25.680]   You have to have radar and lighter.
[00:06:25.680 --> 00:06:27.040]   You mean there's hardware, is in it?
[00:06:27.040 --> 00:06:30.400]   I thought that the car was hardware equipped all the way up to autonomy.
[00:06:30.400 --> 00:06:30.960]   Oh, maybe.
[00:06:30.960 --> 00:06:31.600]   I don't know.
[00:06:31.600 --> 00:06:33.200]   They say every Tesla is being built.
[00:06:33.200 --> 00:06:33.680]   Is that true?
[00:06:33.680 --> 00:06:35.440]   And the hardware for autonomous driving.
[00:06:35.440 --> 00:06:35.440]   OK.
[00:06:35.440 --> 00:06:36.480]   They're all going to have a lot of--
[00:06:36.480 --> 00:06:37.280]   Yeah, they have hardware.
[00:06:37.280 --> 00:06:38.560]   What they call hardware platform.
[00:06:38.560 --> 00:06:40.000]   You're unlocking the hardware.
[00:06:40.000 --> 00:06:41.920]   Oh, that does seem a little expensive.
[00:06:41.920 --> 00:06:44.400]   So you're paying to unlock the hardware that's already there.
[00:06:44.400 --> 00:06:46.400]   So the car is a platform.
[00:06:46.400 --> 00:06:49.440]   And then you get to pay to access its features.
[00:06:49.440 --> 00:06:51.840]   That's my-- that's exactly-- you said it better than I do.
[00:06:51.840 --> 00:06:52.960]   But that's exactly what I was saying.
[00:06:52.960 --> 00:06:54.400]   So can I get a third party app?
[00:06:54.400 --> 00:06:55.360]   Can I get a third party?
[00:06:55.360 --> 00:06:56.000]   No, no.
[00:06:56.000 --> 00:06:57.440]   Can you make it up BMW?
[00:06:57.440 --> 00:07:02.880]   Although we've learned from hackers who have hacked the Tesla,
[00:07:02.880 --> 00:07:04.640]   that it is running Ubuntu Linux.
[00:07:04.640 --> 00:07:05.200]   Wow.
[00:07:05.200 --> 00:07:05.840]   Huh.
[00:07:05.840 --> 00:07:06.000]   Yeah.
[00:07:06.000 --> 00:07:06.880]   That's interesting.
[00:07:06.880 --> 00:07:07.520]   Yeah.
[00:07:07.520 --> 00:07:08.080]   I don't know.
[00:07:08.080 --> 00:07:11.280]   Yeah, I have friends of mine that have worked for Tesla before.
[00:07:11.280 --> 00:07:13.520]   And what I hear about the culture there
[00:07:13.520 --> 00:07:17.440]   is it's really great when Elon can concentrate on your area
[00:07:17.440 --> 00:07:18.560]   of the company.
[00:07:18.560 --> 00:07:20.720]   And then it's just like radio silence
[00:07:20.720 --> 00:07:22.560]   if he's concentrating on something else.
[00:07:22.560 --> 00:07:23.760]   So I don't know.
[00:07:23.760 --> 00:07:27.360]   But I think because the Model 3 so much of the future of Tesla
[00:07:27.360 --> 00:07:29.440]   is, you know, it's riding on this car.
[00:07:30.240 --> 00:07:33.840]   I just-- I knew it was going to be big when people--
[00:07:33.840 --> 00:07:36.160]   I knew that, you know, weren't millionaires,
[00:07:36.160 --> 00:07:39.360]   like people that just do reasonably well in their career
[00:07:39.360 --> 00:07:41.280]   when they were lining up to buy this car.
[00:07:41.280 --> 00:07:43.040]   So I think it's going to be a smash success.
[00:07:43.040 --> 00:07:46.720]   As since you brought up this,
[00:07:46.720 --> 00:07:48.640]   that you had a friend work there,
[00:07:48.640 --> 00:07:50.960]   there have been claims that Tesla too
[00:07:50.960 --> 00:07:54.720]   has this endemic harassment problem.
[00:07:54.720 --> 00:07:56.960]   It seems to be very common in Silicon Valley.
[00:07:56.960 --> 00:07:57.440]   Yeah.
[00:07:57.440 --> 00:07:59.440]   Yeah.
[00:07:59.440 --> 00:08:02.240]   Did your friend talk about it or know about any of this?
[00:08:02.240 --> 00:08:06.240]   You know, she really does not mention anything about it,
[00:08:06.240 --> 00:08:08.960]   but she also left it a few years ago.
[00:08:08.960 --> 00:08:12.080]   You know, I'll ask her next time we hang out, but no.
[00:08:12.080 --> 00:08:13.440]   Yeah, I have a question for you.
[00:08:13.440 --> 00:08:16.080]   So I have a friend who has mentioned the New York Times
[00:08:16.080 --> 00:08:18.800]   article as one of the people who had sexually harassed.
[00:08:18.800 --> 00:08:19.760]   So if I run into--
[00:08:19.760 --> 00:08:19.840]   OK.
[00:08:19.840 --> 00:08:21.680]   What do I say to him?
[00:08:21.680 --> 00:08:22.080]   Do I--
[00:08:22.080 --> 00:08:23.680]   Are you talking about Mark Cannon?
[00:08:23.680 --> 00:08:24.720]   I'm not going to name names.
[00:08:24.720 --> 00:08:24.800]   Yeah.
[00:08:24.800 --> 00:08:25.440]   Well, it's--
[00:08:25.440 --> 00:08:25.920]   [LAUGHTER]
[00:08:25.920 --> 00:08:27.760]   So same problem.
[00:08:27.760 --> 00:08:28.240]   Yeah.
[00:08:28.240 --> 00:08:28.720]   Yeah.
[00:08:28.720 --> 00:08:29.680]   And Mark is--
[00:08:29.680 --> 00:08:32.560]   So the people-- we talked about this last week, of course.
[00:08:32.560 --> 00:08:35.440]   In fact, we had Katie Benner, the author of the Times article on, briefly.
[00:08:35.440 --> 00:08:36.400]   Wow.
[00:08:36.400 --> 00:08:36.960]   She's great.
[00:08:36.960 --> 00:08:37.520]   She's great.
[00:08:37.520 --> 00:08:39.040]   Yeah, I think you see him in a party show.
[00:08:39.040 --> 00:08:40.880]   Credit to Reed Albergotti at the information.
[00:08:40.880 --> 00:08:44.720]   Actually, credit going back to Susan Fowler, the blogger who--
[00:08:44.720 --> 00:08:46.400]   Yeah, he was holding open.
[00:08:46.400 --> 00:08:46.960]   Yeah, he was holding open.
[00:08:46.960 --> 00:08:53.520]   And it's clear that harassment is pervasive throughout the world.
[00:08:55.520 --> 00:08:56.880]   Wherever men go.
[00:08:56.880 --> 00:08:59.440]   Wherever men go, there goes harassment.
[00:08:59.440 --> 00:09:01.200]   And we all need to do better.
[00:09:01.200 --> 00:09:05.280]   And so I don't think Silicon Valley's unique in this respect.
[00:09:05.280 --> 00:09:11.360]   What's surprising is that you expect better of the people we all know who are--
[00:09:11.360 --> 00:09:11.360]   Yeah.
[00:09:11.360 --> 00:09:17.120]   You know, kind of at least pay lip service to kind of forward progressive thinking.
[00:09:17.120 --> 00:09:19.440]   And so they--
[00:09:19.440 --> 00:09:24.000]   Now, of course, Dave McClure of 500 Startups after this article immediately
[00:09:24.000 --> 00:09:25.040]   played Mea Culpa.
[00:09:25.040 --> 00:09:25.680]   Right.
[00:09:25.680 --> 00:09:31.360]   Said I'm a creep, literally in his medium post, and has stepped down.
[00:09:31.360 --> 00:09:31.840]   I'm a creep.
[00:09:31.840 --> 00:09:32.720]   I'm sorry.
[00:09:32.720 --> 00:09:35.360]   Some said that his apology didn't go far enough.
[00:09:35.360 --> 00:09:35.760]   I don't know.
[00:09:35.760 --> 00:09:37.920]   At least he acknowledged it.
[00:09:37.920 --> 00:09:43.680]   Chris Saka, who was also named, has not yet copped to it.
[00:09:43.680 --> 00:09:45.200]   And but Mark Cantor, most of all--
[00:09:45.200 --> 00:09:46.160]   Sort of, yeah.
[00:09:46.160 --> 00:09:46.800]   Sort of did.
[00:09:46.800 --> 00:09:46.960]   Yeah.
[00:09:46.960 --> 00:09:49.040]   I have more work to do, which is about as--
[00:09:49.040 --> 00:09:50.160]   We all have more work to do.
[00:09:50.160 --> 00:09:50.400]   Yeah.
[00:09:50.400 --> 00:09:50.880]   Who doesn't?
[00:09:50.880 --> 00:09:53.440]   Just like a Tesla.
[00:09:54.080 --> 00:09:54.640]   Exactly.
[00:09:54.640 --> 00:09:56.640]   We all need more firmware updates.
[00:09:56.640 --> 00:09:57.200]   But Mark, can I--
[00:09:57.200 --> 00:09:59.120]   I like Mark.
[00:09:59.120 --> 00:10:00.400]   I know Mark.
[00:10:00.400 --> 00:10:00.560]   Yeah.
[00:10:00.560 --> 00:10:03.280]   He is denied it again and again.
[00:10:03.280 --> 00:10:04.640]   Maybe rightly so.
[00:10:04.640 --> 00:10:05.840]   I don't know what the--
[00:10:05.840 --> 00:10:06.320]   I don't know.
[00:10:06.320 --> 00:10:07.680]   We don't know.
[00:10:07.680 --> 00:10:09.760]   I think I would say this.
[00:10:09.760 --> 00:10:14.320]   Like, if it were my friend, something I realized is for me is a white person.
[00:10:14.320 --> 00:10:20.240]   When I see people that may not be doing their part for people of color,
[00:10:20.240 --> 00:10:25.600]   I have a responsibility to speak up because there's just less risk for me as a white person.
[00:10:25.600 --> 00:10:31.360]   So I think if you're a dude in tech, I would personally appreciate if you would like
[00:10:31.360 --> 00:10:34.320]   speak up and pull your friends aside and talk to them about this.
[00:10:34.320 --> 00:10:36.240]   But if you run it, I see it.
[00:10:36.240 --> 00:10:38.240]   When I see somebody acting out, I hope so.
[00:10:38.240 --> 00:10:38.720]   I would do it.
[00:10:38.720 --> 00:10:39.040]   Sure.
[00:10:39.040 --> 00:10:40.000]   I don't know if I need to go--
[00:10:40.000 --> 00:10:41.600]   It's hard because you're not going to--
[00:10:41.600 --> 00:10:42.240]   Right.
[00:10:42.240 --> 00:10:45.040]   You're not going to see it the same way that we are.
[00:10:45.040 --> 00:10:46.960]   It's such a tough--
[00:10:46.960 --> 00:10:48.560]   It's so tough.
[00:10:48.560 --> 00:10:55.600]   And I think one thing I would like it to see is more of a culture where people can make mistakes
[00:10:55.600 --> 00:10:57.360]   and have a second chance.
[00:10:57.360 --> 00:11:03.440]   I mean, I know for me, I would hope today in 2017, I'm a better ally to groups I'm not a part of
[00:11:03.440 --> 00:11:05.280]   than I was in 2010.
[00:11:05.280 --> 00:11:10.880]   So I think all of us are kind of waking up and realizing things need to change.
[00:11:10.880 --> 00:11:14.800]   And if someone comes forward and says, "I made a mistake.
[00:11:14.800 --> 00:11:15.760]   I need to do better."
[00:11:16.320 --> 00:11:21.040]   My strongest inclination is to give them the benefit of the doubt that they want to change.
[00:11:21.040 --> 00:11:22.320]   Give them a second chance.
[00:11:22.320 --> 00:11:26.400]   Maybe not a third chance, but give everybody a chance to make their mistakes right.
[00:11:26.400 --> 00:11:28.800]   And I would add on to that.
[00:11:28.800 --> 00:11:31.520]   I mean, I think also give them that nudge.
[00:11:31.520 --> 00:11:36.640]   Part of why people were upset with Dave was the--
[00:11:36.640 --> 00:11:37.520]   There's this--
[00:11:37.520 --> 00:11:39.600]   Christina Yeoh wrote about it.
[00:11:39.600 --> 00:11:43.680]   I think it's in our show notes about these levels of inappropriateness.
[00:11:43.680 --> 00:11:51.680]   And when male sexual aggression, all scales of it get lumped under inappropriate anything from
[00:11:51.680 --> 00:11:59.040]   aggressive language to physical, aggressive pursuit that is unsolicited and even
[00:11:59.040 --> 00:12:03.520]   resisted, all of those aren't equally inappropriate.
[00:12:03.520 --> 00:12:09.040]   So we need a better language and a better scale and better reporting mechanisms within
[00:12:09.040 --> 00:12:11.840]   any organization, whether it's a nonprofit or a company.
[00:12:11.840 --> 00:12:14.320]   And then the last thing I would say, I mean, Brianna brought it up.
[00:12:14.320 --> 00:12:19.680]   It's always useful to flip the switch, but I will second her notion about
[00:12:19.680 --> 00:12:25.120]   I will see racism way more easily every time because everything's racist.
[00:12:25.120 --> 00:12:33.200]   But also, there's a handoff in the battle for justice on the racial side where you're just like,
[00:12:33.200 --> 00:12:38.320]   "Okay, white people, you have things to do to help move this forward that I will never be able to do."
[00:12:38.320 --> 00:12:45.040]   And I think as men, there are layers to the sexism in our society that if men aren't talking to other
[00:12:45.040 --> 00:12:49.920]   men about it, it just won't move as quickly and as deeply as it needs to.
[00:12:49.920 --> 00:12:53.920]   So we need to have some uncomfortable conversations as men with other men
[00:12:53.920 --> 00:12:58.640]   about the culture we've been brought up in and about challenging each other, our language, our
[00:12:58.640 --> 00:13:04.400]   behavior. And in the aftermath of an incident like this, for those of us who have access to
[00:13:04.400 --> 00:13:09.600]   them and named, and especially the ones not named, bringing it up before there's even further
[00:13:09.600 --> 00:13:13.200]   incidents to be repeated on top of that. That's how hard work to do.
[00:13:13.200 --> 00:13:17.520]   The range of inappropriate material. You remember a couple weeks ago, some media outlet made a big
[00:13:17.520 --> 00:13:21.520]   deal about the fact that Donald Trump had an Irish female reporter in his office and the Oval
[00:13:21.520 --> 00:13:26.640]   Office, and he kind of flirted with her. He said something, "Oh, nice smile." And on the range of
[00:13:26.640 --> 00:13:31.440]   the scale of the things that Donald Trump has done in terms of harassing them, that's way on
[00:13:31.440 --> 00:13:34.960]   the innocent side, in my opinion. Yet they made a big deal about them thinking,
[00:13:34.960 --> 00:13:38.880]   "Wait a minute, let's remember back to grab your, can you say the P word on the..."
[00:13:38.880 --> 00:13:43.600]   I don't think you need to. Everybody knows.
[00:13:43.600 --> 00:13:46.400]   I think we need to put everything in context, what I'm saying.
[00:13:46.400 --> 00:13:51.840]   I would push back on you just a little bit on that. Put yourself in that woman's shoes.
[00:13:51.840 --> 00:13:57.840]   She's worked her entire career. If you are a woman journalist, like talk to your friends that
[00:13:57.840 --> 00:14:02.800]   work that, they're constantly faced with being treated as sex objects and not professionals.
[00:14:02.800 --> 00:14:08.720]   And here she is in a really big moment of her career. And she's being kind of treated as a sex
[00:14:08.720 --> 00:14:14.400]   object and not a professional. So I understand what you're saying about the seriousness of that.
[00:14:14.400 --> 00:14:18.720]   But I do think we need a culture where men kind of are aware of that.
[00:14:18.720 --> 00:14:19.440]   I agree.
[00:14:19.440 --> 00:14:22.240]   Because I'm sure it was very professionally embarrassing for her.
[00:14:22.240 --> 00:14:24.000]   Yeah, that's part of the problem, isn't it?
[00:14:24.000 --> 00:14:29.600]   I would not as aware as we maybe ought to be of how things that sound,
[00:14:29.600 --> 00:14:34.720]   you know, I think many people, many guys would say, "Oh, but that's just saying something nice."
[00:14:34.720 --> 00:14:42.320]   How is that? And we need to get more aware of how that can be patronizing and problematic.
[00:14:42.320 --> 00:14:43.840]   And there's a huge...
[00:14:43.840 --> 00:14:51.840]   We're definitely not. We all grew up in the same perverse stew with all the biases baked in.
[00:14:51.840 --> 00:14:56.560]   And I think what's fascinating about what's happening now is that, like we are having this
[00:14:56.560 --> 00:15:04.320]   conversation, there is clearly a wave and it's not just men's behavior that is less acceptable.
[00:15:04.320 --> 00:15:10.800]   It's women feeling increasingly comfortable stepping up. I mean, this would not have happened
[00:15:10.800 --> 00:15:16.960]   to this degree in the 50s, in the 70s, in the 90s, or even in the earlier part of the 2000s.
[00:15:16.960 --> 00:15:20.960]   And so you can have a Susan Fowler and a Christine Yeoh and a Sarah Kunst.
[00:15:20.960 --> 00:15:27.440]   And these are out on personal websites in the New York Times, on blogs, on video.
[00:15:27.440 --> 00:15:31.840]   So there's something, you know, the culture is shifting. We all have to kind of catch up and
[00:15:31.840 --> 00:15:36.560]   stay relevant. And I think for this show and shows like it, like if you're in technology,
[00:15:36.560 --> 00:15:41.040]   you're really proud of being on the cutting edge. You're an early adopter. I think that
[00:15:41.040 --> 00:15:47.520]   early adoption extends past the latest operating system and the latest Tesla model to like the
[00:15:47.520 --> 00:15:53.360]   latest, you know, social interaction firmware and the latest sort of human rights operating system
[00:15:53.360 --> 00:15:59.360]   and the latest like inter-human respect protocols that we are now being like, oh, we have to update
[00:15:59.360 --> 00:16:04.320]   all of our stuff as well, kind of our meatware. I'm not just ourselves there.
[00:16:04.320 --> 00:16:11.200]   If I could add one more thing to this, I think it is so easy to go after someone on Twitter and
[00:16:11.200 --> 00:16:16.480]   blast them and attack them. And I do think holding people accountable is very useful.
[00:16:16.480 --> 00:16:21.840]   This something I try to do is rather than attacking other people on this subject,
[00:16:21.840 --> 00:16:26.880]   I try to ask myself, what do I need to do better? Because it's so much easier to change
[00:16:26.880 --> 00:16:32.400]   yourself than other people. So like the last game my studio put out, we had no characters that
[00:16:32.400 --> 00:16:38.000]   were people of color. And we had a very small staff of five people, but none of those were
[00:16:38.000 --> 00:16:44.480]   people of color that were on our engineering team. And for me as a leader, I have to hold myself
[00:16:44.480 --> 00:16:49.680]   accountable and know the going forward. I need to make different hiring decisions. So I just,
[00:16:49.680 --> 00:16:55.120]   I wish all of us would take more of a look at ourselves about what we need to change rather than
[00:16:55.120 --> 00:17:00.960]   constantly directing it towards others. Because I just think it leads to this. It just leads to
[00:17:00.960 --> 00:17:04.960]   everybody attacking everybody all the time. Well, it's also interesting to think that Silicon
[00:17:04.960 --> 00:17:10.480]   Valley, which thinks of itself as a very progressive area, really has a lot of work to do and it
[00:17:10.480 --> 00:17:14.880]   cannot put itself in a superior position vis-a-vis the rest of the country. But we can't sit here
[00:17:14.880 --> 00:17:21.040]   and complain about how people are acting in the interland. In fact, if there is a right side of
[00:17:21.040 --> 00:17:26.320]   this, that is it. Because we really, I shouldn't say we, I don't know if I include myself in this,
[00:17:26.320 --> 00:17:29.120]   but Silicon Valley definitely thinks it's better than everybody else. It does.
[00:17:29.120 --> 00:17:35.600]   Right? And it thinks it's more diverse. And it also thinks it's more diverse. And yes,
[00:17:35.600 --> 00:17:41.280]   it's true. You can see people of different ethnicities around. But if you actually look at the power
[00:17:41.280 --> 00:17:46.880]   structure of Silicon Valley, it's pretty underverse. It's really good to remember that. Because I think
[00:17:46.880 --> 00:17:53.360]   technologists, particularly in Silicon Valley, we think we're smarter than everybody else.
[00:17:53.360 --> 00:17:59.120]   We're more sensitive, we're more enlightened. And it's probably a very good message that,
[00:17:59.120 --> 00:18:02.560]   oh, we're just as flawed as everybody else. Maybe more so. Who knows?
[00:18:02.560 --> 00:18:06.160]   Well, also the Silicon Valley is made of people. It's made of oil and green.
[00:18:06.160 --> 00:18:10.720]   Yeah. But there's a lesson there. And the lesson is, because I think technologists,
[00:18:10.720 --> 00:18:16.400]   technocrats are eyeing public office. I think we've talked about this before with Mark Zuckerberg.
[00:18:16.400 --> 00:18:21.440]   And I know Jason Calicanos wants to run for mayor of Sionna Wuzku. I heard about this woman
[00:18:21.440 --> 00:18:26.880]   named Brianna Wu, who wants to be a congressperson. And now I don't think of this as you, Brianna,
[00:18:26.880 --> 00:18:33.440]   actually. But I think that people like Zuckerberg think that they, because they are technologists
[00:18:33.440 --> 00:18:40.080]   and entrepreneurs and they're so vastly successful, would bring a skill set to politics that doesn't
[00:18:40.080 --> 00:18:43.120]   exist right now. So when's the last time you've done? It's very dismissive, right? Oh, well,
[00:18:43.120 --> 00:18:46.800]   I know better. I can do a better job. When's the last time a billionaire ran for president and
[00:18:46.800 --> 00:18:52.880]   how did that work out? I don't think he's a billionaire. But somebody claims to be who thinks
[00:18:52.880 --> 00:18:58.400]   he's very smart because he thinks he ran a successful business. And he thinks that the skill set in
[00:18:58.400 --> 00:19:02.960]   running his real estate empire somehow applies to America. Well, this is Mark Zuckerberg's
[00:19:02.960 --> 00:19:07.280]   different than him, but not necessarily any more qualified in some ways. Yeah.
[00:19:07.280 --> 00:19:12.400]   Yeah. It's a completely different skill set. Like, if I'm running a business and I get 5%
[00:19:12.400 --> 00:19:18.000]   margin, I'm going to be a multi-millionaire. If you're running for office, you have to get 51%
[00:19:18.000 --> 00:19:23.440]   of the vote. And it's just a completely different game. And I completely agree with the layout. I am
[00:19:23.440 --> 00:19:28.480]   among those that are terrified of the idea of him running for office. I think it's a massive
[00:19:28.480 --> 00:19:33.040]   conflict of interest. And I think I can think of very few people that would be worse in that role.
[00:19:33.040 --> 00:19:37.040]   Is it a conflict of interest because he could use the vast power of Facebook to
[00:19:37.040 --> 00:19:43.680]   promote his candidacy? Is that the wrong? Absolutely. Or he has such a massive control over news.
[00:19:43.680 --> 00:19:48.400]   I mean, there was a bond movie about this very subject, you know? Is it a bond villain?
[00:19:48.400 --> 00:19:54.160]   Oh, yeah. I think he could be. He could be. Yeah. Does he have a volcano anywhere? We need to know.
[00:19:54.160 --> 00:20:00.800]   I'll lend him my Dr. Evil chair if he wants to. She did that. Oh, why? He probably, you know what?
[00:20:00.800 --> 00:20:10.880]   He does. And he's building a fence around it. Yeah. But you also understand why he would think
[00:20:10.880 --> 00:20:17.200]   he'd be better at this job. But this is a common misconception. For instance, you very often hear,
[00:20:17.200 --> 00:20:21.600]   well, I have to balance my checkbook. Why can't why can't the government balance his checkbook?
[00:20:21.600 --> 00:20:26.480]   It's just kind of a fundamental misunderstanding of how government works, right? Yeah. I mean,
[00:20:26.480 --> 00:20:31.280]   my rate of him, you know, kind of moving more into the political realm is more like him trying to
[00:20:31.280 --> 00:20:38.720]   rehabilitate his image. And you know, there's very much a trend of when you know, the one percent of
[00:20:38.720 --> 00:20:46.240]   the one percent amass a certain amount of money, they take great pains to like rise their standing
[00:20:46.240 --> 00:20:53.280]   in public opinion. You saw this in the age of Pinkerton. So I think that I just read it as him
[00:20:53.280 --> 00:20:59.440]   trying to raise his profile to be seen as a nice guy. So Facebook can accomplish more political goals.
[00:20:59.440 --> 00:21:03.360]   That's interesting. Yeah. He's not running for president. Mark Zuckerberg is running for human.
[00:21:04.000 --> 00:21:10.160]   And he just wants us to all think of him as like, I'm a human just like you. I just bring my security
[00:21:10.160 --> 00:21:15.440]   detail and a group of people on laptops and pre-announced my arrival into a small bit western town
[00:21:15.440 --> 00:21:20.800]   and then pulls myself on a family just like humans do. That's human, right? It's kind of like a droid.
[00:21:20.800 --> 00:21:26.160]   Yeah. It's very much like data. Say, no, I am human. I think we're being a little unfair. Okay.
[00:21:26.160 --> 00:21:31.040]   Of course we are. There's humor and unfair. Yeah. You're a comedian. You can get away with it.
[00:21:32.640 --> 00:21:38.480]   But I mean, to be, I'll try to be fair. There is, I read someone's account and I don't remember
[00:21:38.480 --> 00:21:44.000]   who's it was unfortunately that his movements, suspicious, furtive movements about the
[00:21:44.000 --> 00:21:48.800]   heartland in swing states was less about him running for president than it was about trying to
[00:21:48.800 --> 00:21:56.560]   kind of reconnect with the user and reconnect with the people and having been blindsided by
[00:21:56.560 --> 00:22:01.840]   the election results and knowing that his platform played a result in spreading some of the
[00:22:01.840 --> 00:22:07.040]   misinformation and propaganda around that. He wanted to kind of get back out there and see
[00:22:07.040 --> 00:22:13.040]   what's really going on. And he certainly wants his platform to be in the middle of every possible
[00:22:13.040 --> 00:22:17.120]   well, the problem is that we have whether it's you and your family, you and your
[00:22:17.120 --> 00:22:23.120]   politician, you and your neighbor like Facebook wants to be that that human to human
[00:22:23.120 --> 00:22:27.600]   interface that we cannot connect without. But if you think about, he lives in a bubble
[00:22:27.600 --> 00:22:31.040]   inside of a bubble. I mean, he's living in Silicon Valley. That's a bubble enough. He's
[00:22:31.040 --> 00:22:35.840]   living at Facebook. That's a bubble and the CEO and a multi billionaire, he's got, you know,
[00:22:35.840 --> 00:22:40.800]   he's even more of a bubble. Got a financial problem. Anything that any of these guys can do to actually
[00:22:40.800 --> 00:22:45.520]   find out about the real world is probably extremely useful. So I actually give him credit for that.
[00:22:45.520 --> 00:22:49.840]   That's not, I don't know if it's related, but Mark, did you hear the story about Mark Zuckerberg
[00:22:49.840 --> 00:22:54.960]   and his security detail in San Francisco? This is film material in Ross writing in the San Francisco
[00:22:54.960 --> 00:22:59.520]   Chronicle. Apparently there's a transient who's been harassing Zuckerberg security detail.
[00:22:59.520 --> 00:23:03.920]   And he's been doing it over and over again. Yeah, you know, a little bit about harassment,
[00:23:03.920 --> 00:23:11.280]   I know, Brianna. Yeah. And on June 14, he was arrested for driving his car towards the protective
[00:23:11.280 --> 00:23:21.200]   Zuckerberg has 16 former Oakland cops surrounding his his home in Dolores in the Dolores part of
[00:23:21.200 --> 00:23:27.760]   Dolores Heights neighborhood. And he drove the car towards him and swerved off at the last minute.
[00:23:27.760 --> 00:23:32.800]   And he's been jailed before, but they won't let the security detail testify according to
[00:23:32.800 --> 00:23:37.280]   material in Ross who are well known investigative journalists at San Francisco, because their former
[00:23:37.280 --> 00:23:43.360]   Oakland cops with troubled records. And they're afraid of putting them on the stand. Wow.
[00:23:43.360 --> 00:23:47.680]   I don't know. There's nothing to say there. I just, yeah, I don't know anything about that.
[00:23:47.680 --> 00:23:52.400]   Yeah, I never hear. It's a weird story and it's not really a tech story. So
[00:23:52.400 --> 00:23:56.400]   since we're talking about anything we're talking about today, but yeah, directly a tech story.
[00:23:56.400 --> 00:24:02.560]   Apparently Facebook is considering a $1 billion or sorry, Â£1 billion
[00:24:02.560 --> 00:24:13.440]   pound offer to buy what a soccer team taught them really?
[00:24:13.440 --> 00:24:20.080]   Soccer football club football club. That's strange. This is coming from the sun. So consider the
[00:24:20.080 --> 00:24:28.160]   source, but strange Zuckerberg wants to buy a soccer. No, it's probably Zuckerberg. Oh my God.
[00:24:28.160 --> 00:24:32.400]   Oh, okay. That makes more sense. Last season's Premier League runners up according to the Sunday
[00:24:32.400 --> 00:24:38.080]   Times. Oh my gosh. Womber owns a basketball team. So why not? You know, when you have that much
[00:24:38.080 --> 00:24:43.520]   money, it's like me saying, let's go down to the corner and get a pizza. Exactly. Yeah. Today,
[00:24:43.520 --> 00:24:49.200]   I'd like a soccer club. You know, any we could buy? All right, let's take a break. We'll talk.
[00:24:49.200 --> 00:24:53.520]   There's lots more to talk about, including, remember we were talking about the Nokia 33
[00:24:53.520 --> 00:24:59.600]   10 phone, really lovely phone. Quinn, a tech crunch. You can now buy a very special edition
[00:24:59.600 --> 00:25:03.200]   commemorating President Trump's meeting with Vladimir Putin.
[00:25:03.920 --> 00:25:11.440]   What? The phone did you a bit out of the. I think that's lovely. I think that's lovely.
[00:25:11.440 --> 00:25:13.840]   It's called the caviar. Guys, I got my credit card.
[00:25:13.840 --> 00:25:20.720]   This is amazing. It's a it's a $2,500. And then of course, the 33 10 is the
[00:25:20.720 --> 00:25:27.280]   the Nokia phone that brings back that great candy bar style and design. 149,000 rubles.
[00:25:27.280 --> 00:25:32.240]   What does that come to in dollars? 2,500. Oh, that's a 20,000. I yeah.
[00:25:32.240 --> 00:25:36.000]   I'm a little loaded. Look at that. Isn't that that's pretty? That's disgusting.
[00:25:36.000 --> 00:25:42.960]   I tell you that's that's that will be valuable someday.
[00:25:42.960 --> 00:25:50.640]   For the people who are listening on on tape delay, we were we were just assaulted visually by the
[00:25:50.640 --> 00:25:59.920]   image of a candy bar phone with a fake wood paneled skin and gold commemorative coin embossed with
[00:25:59.920 --> 00:26:04.560]   two tyrannical desperate profiles of whatever Putin and Donald Trump,
[00:26:04.560 --> 00:26:10.800]   the G20, Germany, 2017, that's the caviar phone. If you want to make your day a little worse or a
[00:26:10.800 --> 00:26:15.680]   little more ridiculous, you should Google it and and see what I was just forced to see without
[00:26:15.680 --> 00:26:20.640]   opting into the experience that this is this is tremendous. This is horrible.
[00:26:20.640 --> 00:26:26.800]   And I've just been handed this by by John Slanina, who is of course an expert on Pink Floyd. He's
[00:26:26.800 --> 00:26:33.840]   our Pink Floyd archivist here at the Twit Studios. The lyrics of money go and I you know, I never
[00:26:33.840 --> 00:26:40.160]   listen to lyrics, but you know, boom, boom, boom, boom, boom, money get away, get a good job with
[00:26:40.160 --> 00:26:44.560]   more pain. You're okay. Money. It's a gas grab that cash with both hands and make a stash.
[00:26:44.560 --> 00:26:50.720]   New car caviar. There's the phone four star daydream. Think I'll buy me a football team.
[00:26:50.720 --> 00:26:53.840]   So we now know where Mark Zuckerberg.
[00:26:53.840 --> 00:26:58.560]   So they're just playing out the song. All right. It was written as they say.
[00:26:58.560 --> 00:27:00.560]   Get the phone. Get the team you're done.
[00:27:00.560 --> 00:27:06.640]   Yeah, we were talking for the show about career ending mistakes. I'm just imagining if I bought
[00:27:06.640 --> 00:27:11.440]   one of these and like people saw me with it. I desperately wanted to see like this.
[00:27:11.440 --> 00:27:12.000]   They didn't even see like this. They didn't even see like this.
[00:27:12.000 --> 00:27:14.560]   You did it ironically. And that this was like a.
[00:27:14.560 --> 00:27:18.640]   I would love to whip this phone out of my next meeting and say, wait, am I going to take a call?
[00:27:19.120 --> 00:27:24.400]   Pooty. Here's the benefit of this phone. It doesn't look like you can tweet with it.
[00:27:24.400 --> 00:27:27.360]   So maybe this is the phone the president should give that to the Donald Trump.
[00:27:27.360 --> 00:27:30.480]   Oh, yeah. It's just got a number pad. There's no keyboard.
[00:27:30.480 --> 00:27:34.640]   Yeah. No, the 33. As I remember the 3310 does have internet, but yeah,
[00:27:34.640 --> 00:27:38.160]   you'd have to type your tweets on the number pad. He'd have to do T9 tweeting.
[00:27:38.160 --> 00:27:43.520]   That's a bot someone should create Trump's T9 tweets.
[00:27:45.760 --> 00:27:50.640]   It might explain Ko-fi-fi. I don't know. All right. Let's take a break. We'll come back with more.
[00:27:50.640 --> 00:27:54.320]   I want to talk about Barrett with Baratunde is up to a medium because that's starting soon.
[00:27:54.320 --> 00:27:56.880]   And I think that's something you're going to be interested in. And then of course,
[00:27:56.880 --> 00:28:00.480]   we'll do a little we'll make it phone time. We'll do a fundraising for Brianna Wu.
[00:28:00.480 --> 00:28:06.480]   We'll see what we can. Yeah. Yeah. Phone time. That's what they call it. Phone time when you call
[00:28:06.480 --> 00:28:11.680]   to make call time. Call time. You get like you get lists of people they've traditionally
[00:28:11.680 --> 00:28:18.800]   donated to Democrats before, and you go through a new column. And it is terrible because I hate
[00:28:18.800 --> 00:28:23.520]   like anyway, it works in technology. I hate talking on the phone. So yeah, I've clearly
[00:28:23.520 --> 00:28:29.200]   made a big career mistake doing this. It's what you do though. That's the problem with all of this.
[00:28:29.200 --> 00:28:34.000]   And that's really, I think one of the things that's wrong with politics in this country is that
[00:28:34.000 --> 00:28:41.200]   your job now is fundraising. I agree. I completely agree. Yeah. He has a song which
[00:28:41.760 --> 00:28:46.320]   he sang for Terry Gross, these sings during call time.
[00:28:46.320 --> 00:28:54.160]   Al Franken does, Senator Al Franken does, the lyrics. I'll have to find it. Let's see if we
[00:28:54.160 --> 00:29:00.480]   can find it. It was on Fresh Air. And he sang it. And it's actually, it's actually pretty funny.
[00:29:00.480 --> 00:29:05.840]   Our show today brought to you by Legal Zoom. Legal Zoom is not a law firm, but it's actually
[00:29:05.840 --> 00:29:13.040]   something kind of better. When I wanted to start Twit, low these many years ago, I called my friend,
[00:29:13.040 --> 00:29:18.640]   Kevin Rose, who started a few businesses. I said, what do I do? He said, you want to make an LLC,
[00:29:18.640 --> 00:29:22.480]   and you want to go to Legal Zoom, and it's cheap, and it's easy. And then you'll be protected. We
[00:29:22.480 --> 00:29:30.240]   are still a Legal Zoom LLC. Legal Zoom lets you do the legal work you need to build a business,
[00:29:30.240 --> 00:29:36.480]   to protect your family with a will. A lot of the stuff you can do yourself online at LegalZoom.com.
[00:29:36.480 --> 00:29:43.120]   It's really important. I'm really learning this that you've got to cross the teas and dot the
[00:29:43.120 --> 00:29:48.560]   eyes. One little slip up on a contractor, a misunderstanding, can set you back. Legal Zoom
[00:29:48.560 --> 00:29:55.040]   is the way to start your business, but it goes well beyond business formation. They have a network
[00:29:55.040 --> 00:30:01.360]   of independent attorneys who can help you answer those day-to-day legal questions at a fixed rate,
[00:30:01.360 --> 00:30:08.720]   no more $350 an hour bills. You know what you're paying. My lawyer is $450. I have a cheap lawyer.
[00:30:08.720 --> 00:30:15.040]   I have a very cheap deal. Let's face it, things like trademarks and employment law and lease
[00:30:15.040 --> 00:30:18.880]   agreements can get very complicated. Don't waste your valuable time trying to wrap your head around
[00:30:18.880 --> 00:30:23.280]   all the fine print. Use Legal Zoom and focus on your business. That's why you got in business,
[00:30:23.280 --> 00:30:27.920]   to do the thing you love. You can get legal help without being billed by the hour. Legal Zoom is
[00:30:27.920 --> 00:30:34.080]   not a law firm, but they will help connect you with attorneys in almost every state. Go to legalzoom.com
[00:30:34.080 --> 00:30:41.040]   today. If you use the offer code TWIT in the referral box, you'll get additional savings. Legalzoom.com.
[00:30:41.040 --> 00:30:49.280]   Forever grateful Legal Zoom. We did our trademarks through them. It's a really great way. I think
[00:30:49.280 --> 00:30:54.880]   Lisa did her will. It's nice when you get your will. They send you this box of materials. It makes
[00:30:54.880 --> 00:31:00.800]   it very easy to do. Legal Zoom. I'm about 90% sure we set up our game studio through them too,
[00:31:00.800 --> 00:31:05.040]   because it's like you said, the LLC stuff. It's all standard. It's so easy. You just pay a few
[00:31:05.040 --> 00:31:11.120]   dollars. It's very easy. I had a question at the time they didn't have this referral service,
[00:31:11.120 --> 00:31:14.800]   which is great, so you could ask questions, because I wasn't sure what state to do it in.
[00:31:15.520 --> 00:31:18.320]   Did you have to deal with this, Brianna? Do you remember? I wasn't sure. Should I
[00:31:18.320 --> 00:31:23.040]   incorporate in California? I ended up doing Delaware, because somebody told me Delaware.
[00:31:23.040 --> 00:31:28.240]   Because it's the cheapest. It is the cheapest because you still pay business taxes in California,
[00:31:28.240 --> 00:31:33.600]   so it doesn't save me any money. No, I don't know why I did it, but I did. I think I know why.
[00:31:33.600 --> 00:31:38.320]   Somebody said, "Oh, if you're ever going to go out and look for adventure funding,
[00:31:38.320 --> 00:31:41.840]   they like it if you're in Delaware." I did my nonprofit network because I was able to get it
[00:31:41.840 --> 00:31:45.760]   instantly. I mean, I was like, "incorporate it in a second." Wow, I'm a corporation.
[00:31:45.760 --> 00:31:54.560]   Right away. It's awesome. I'll tell you. All right, let's move on. Let's talk about some tech.
[00:31:54.560 --> 00:32:00.880]   Rumors? Should we talk about rumors? Apple's rumored that they're not going to do a fingerprint
[00:32:00.880 --> 00:32:06.400]   reader on the next iPhone. This comes not just from Ming-Chi Kuo, famous Apple rumor-monger. He's
[00:32:06.400 --> 00:32:12.480]   actually an analyst for KGI Securities and is in deep touch with the supply chain in China.
[00:32:12.480 --> 00:32:19.600]   He said, "Because you're going to do an edge-to-edge OLED screen, at least on the top of the line
[00:32:19.600 --> 00:32:27.600]   iPhone, they're not going to do a fingerprint reader on it. They were rumors they were going to
[00:32:27.600 --> 00:32:34.240]   try to do it through the screen. Apparently, according to, by the way, not just Ming-Chi Kuo,
[00:32:34.240 --> 00:32:39.840]   now we've got Mark Gurman, who's the king of Apple rumors, saying it as well on his Bloomberg
[00:32:39.840 --> 00:32:43.280]   technology reporting. They're going to do face-requing-
[00:32:43.280 --> 00:32:45.120]   Right. Faith in iris. Faith in iris.
[00:32:45.120 --> 00:32:49.440]   And iris-scounding. Now, Louis, almost instantaneously, left in a second.
[00:32:49.440 --> 00:32:55.920]   So I have a lot of developer questions about this subject. So if you watch the WWDC this year,
[00:32:55.920 --> 00:33:02.240]   the stay of the union, with ARKit, they premiered a lot of stuff by all used depth sensors,
[00:33:02.240 --> 00:33:09.040]   which only exists on the iPhone Plus. And a lot of the tricks that they used were only on those
[00:33:09.040 --> 00:33:16.080]   phones with those depth sensors. So I can see them doing this, but it just seems like TouchID took
[00:33:16.080 --> 00:33:22.480]   so long to get over onto the Mac for Apple Pay. And then if you're, I just think they're going to
[00:33:22.480 --> 00:33:27.440]   have to get that depth sensor technology in there for faces, because it's so vulnerable to holding
[00:33:27.440 --> 00:33:32.560]   like a picture up to the camera. And that's what Microsoft does with, Microsoft's hello.
[00:33:32.560 --> 00:33:38.560]   This is a hello. This is the Surface Studio. When I log in, I can do it with a face. It does a very
[00:33:38.560 --> 00:33:44.960]   good job. But because they're using not just two-dimensional measurements, but also 3D sensing,
[00:33:44.960 --> 00:33:50.160]   this is very much like a Kinect camera in here. There's two cameras. It's supposedly
[00:33:50.160 --> 00:33:54.480]   more reliable and it won't be fooled by things like a picture of-
[00:33:54.480 --> 00:33:55.120]   Right. Right.
[00:33:55.120 --> 00:34:00.560]   But what if you need to unlock your phone in the dark?
[00:34:00.560 --> 00:34:04.480]   Oh, that's a good question. Wow, that's a very good question.
[00:34:04.480 --> 00:34:07.360]   Well, I guess you'd use you'll have to use the password.
[00:34:07.360 --> 00:34:10.160]   I find it the old fashioned way.
[00:34:10.160 --> 00:34:13.920]   On this, you'll look back at hello. It doesn't work a lot of the time. I finally turned it off.
[00:34:13.920 --> 00:34:16.560]   It requires some special words. Well, it depends on the depth sensing technology.
[00:34:16.560 --> 00:34:18.240]   Not the hardware, but not good enough.
[00:34:18.240 --> 00:34:21.760]   I, all the Microsoft stuff I've used is pretty good. It's pretty quick.
[00:34:21.760 --> 00:34:24.400]   So I just type in my pin.
[00:34:24.400 --> 00:34:25.600]   You wear glasses though.
[00:34:25.600 --> 00:34:26.560]   I think that's it.
[00:34:26.560 --> 00:34:30.720]   So train it with both with and without glasses. And it's possible to over train.
[00:34:30.720 --> 00:34:32.240]   So you're saying the computers don't make passes and
[00:34:32.240 --> 00:34:32.960]   boys do wear glasses?
[00:34:32.960 --> 00:34:34.000]   No, not you anyway.
[00:34:34.000 --> 00:34:38.400]   You're the hot tech journalist in glasses.
[00:34:38.400 --> 00:34:41.120]   Have you let your hair down, Larry?
[00:34:41.120 --> 00:34:44.160]   By Larry, you're beautiful.
[00:34:44.160 --> 00:34:46.400]   So anyway-
[00:34:46.400 --> 00:34:50.080]   Is this supposed to be more secure than what Samsung did with face recognition?
[00:34:50.080 --> 00:34:50.160]   Yes.
[00:34:50.160 --> 00:34:51.760]   Because I know you could fool that.
[00:34:51.760 --> 00:34:55.360]   And then the iris can I met some people who fooled it.
[00:34:55.360 --> 00:34:57.840]   They just printed out a picture of your eye.
[00:34:57.840 --> 00:35:03.920]   Yeah, they put it on a ball, like taped it to a golf ball, held that up,
[00:35:03.920 --> 00:35:05.360]   and then boom, unlocked the phone.
[00:35:05.360 --> 00:35:07.760]   Why can't they make you blink or something?
[00:35:07.760 --> 00:35:09.840]   I mean, I've seen some technology where you have to blink.
[00:35:09.840 --> 00:35:12.960]   You have to do something to show you're a moving object.
[00:35:12.960 --> 00:35:14.800]   Sometimes some of this software does this.
[00:35:14.800 --> 00:35:18.000]   It was the KS computer club that did that, Bertone.
[00:35:18.000 --> 00:35:24.000]   In fact, there's a great video of them doing this crack.
[00:35:24.000 --> 00:35:28.720]   They took a picture of a guy and not even that much of a close up picture
[00:35:28.720 --> 00:35:32.960]   with a simple point and shoot camera and we're able to use that picture
[00:35:32.960 --> 00:35:38.240]   from a distance to create a, as you say, an image of his iris,
[00:35:38.240 --> 00:35:42.720]   which they then bent around something and it fooled the Samsung.
[00:35:42.720 --> 00:35:43.360]   Anything.
[00:35:43.360 --> 00:35:47.840]   So you always think of iris scanning as being the best way to do this.
[00:35:47.840 --> 00:35:48.640]   Right.
[00:35:48.640 --> 00:35:51.600]   I don't know. I think this would be a bit of a shock,
[00:35:51.600 --> 00:35:54.240]   but again, Apple's not afraid of that kind of thing.
[00:35:54.240 --> 00:35:56.960]   Remember, Apple did the same thing with the headphone jack.
[00:35:56.960 --> 00:35:57.520]   Right.
[00:35:57.520 --> 00:35:58.960]   Didn't we all a year ago say,
[00:35:58.960 --> 00:36:00.560]   they'll never get rid of the headphone jack.
[00:36:00.560 --> 00:36:03.920]   They also got rid of the floppy disk before anybody else did.
[00:36:03.920 --> 00:36:04.720]   Yeah.
[00:36:04.720 --> 00:36:09.280]   I mean, I think the security fact is there's no method of authentication
[00:36:09.280 --> 00:36:13.040]   that's 100% secure, not password, not a fingerprint, not anything.
[00:36:13.040 --> 00:36:15.520]   I mean, so this is going to be just as fallible.
[00:36:15.520 --> 00:36:19.760]   And I think it just, yeah, this is why Apple requires you periodically
[00:36:19.760 --> 00:36:23.360]   to enter in your real password when you're doing things like changing the system
[00:36:23.360 --> 00:36:25.440]   or anything really critical.
[00:36:25.440 --> 00:36:29.520]   So, you know, I don't have any huge objection to it.
[00:36:29.520 --> 00:36:34.080]   It just seems a little shocking given, you know, all the work they've done
[00:36:34.080 --> 00:36:35.840]   to get Apple pay up to a standard.
[00:36:35.840 --> 00:36:41.280]   I mean, if Apple pay and secure enclave are going to work with facial recognition,
[00:36:41.280 --> 00:36:41.920]   that's great.
[00:36:42.720 --> 00:36:45.760]   I just, I think they'd have to, for the dark problem,
[00:36:45.760 --> 00:36:50.080]   I think they'd have to have something like the connect sensor in there,
[00:36:50.080 --> 00:36:53.760]   you know, which it can sense in the dark because it's shooting out IR beams.
[00:36:53.760 --> 00:36:54.960]   So I don't know.
[00:36:54.960 --> 00:36:55.920]   It's going to be tough to solve.
[00:36:55.920 --> 00:36:57.600]   Yeah.
[00:36:57.600 --> 00:37:02.160]   I think if there's, you know, this is connected to another story that was in the rundown,
[00:37:02.160 --> 00:37:06.800]   but if this were Google doing this, that'd be more freaked out or Facebook
[00:37:06.800 --> 00:37:13.440]   because they like to capture as much media information, biometric data as possible,
[00:37:13.440 --> 00:37:15.760]   and hoard it and store it and sell it.
[00:37:15.760 --> 00:37:17.600]   But Apple doesn't have that business.
[00:37:17.600 --> 00:37:21.520]   So I think if there is a company that's going to be like taking 3D scans of my face,
[00:37:21.520 --> 00:37:26.960]   and I had to choose, is it Amazon, Apple, Facebook, or Google,
[00:37:26.960 --> 00:37:30.800]   I would choose the least of the four evils with respect to privacy,
[00:37:30.800 --> 00:37:32.320]   which I think is Apple in this case.
[00:37:32.320 --> 00:37:37.440]   I hear, so there's always this impression that Apple protects your privacy better.
[00:37:37.440 --> 00:37:41.360]   But I also hear again and again, and even security experts saying,
[00:37:41.360 --> 00:37:43.280]   oh, I would never use an Android phone.
[00:37:43.280 --> 00:37:45.040]   If you want to be secure, use an iPhone.
[00:37:45.040 --> 00:37:46.480]   Do you all agree with that?
[00:37:46.480 --> 00:37:47.040]   I don't agree.
[00:37:47.040 --> 00:37:47.440]   I hear it.
[00:37:47.440 --> 00:37:47.680]   Yeah.
[00:37:47.680 --> 00:37:48.240]   I don't agree.
[00:37:48.240 --> 00:37:49.200]   You don't agree.
[00:37:49.200 --> 00:37:53.600]   I mean, look, I think everything has a risk and androids have risks.
[00:37:53.600 --> 00:38:00.000]   And there are probably somewhat more risks on Android than they're on iOS, but I don't know.
[00:38:00.000 --> 00:38:02.320]   It's the risk I guess I'm going to take because I use an Android phone.
[00:38:02.320 --> 00:38:05.200]   And no one would say that I do too.
[00:38:05.200 --> 00:38:11.920]   No one would say that iOS is flawless or without malware or hacking.
[00:38:11.920 --> 00:38:15.760]   And I also am not convinced that Apple,
[00:38:15.760 --> 00:38:21.360]   I agree that Apple with you bear today, Apple is not collecting information in the same way,
[00:38:21.360 --> 00:38:24.160]   because Google after all makes its money through advertising,
[00:38:24.160 --> 00:38:26.160]   Apple makes its money through selling hardware.
[00:38:26.160 --> 00:38:27.680]   So their business models are different.
[00:38:27.680 --> 00:38:30.880]   No, no, Apple makes its money through selling a way of life.
[00:38:30.880 --> 00:38:31.280]   A dream.
[00:38:31.280 --> 00:38:34.320]   The dream of a better you.
[00:38:34.320 --> 00:38:35.520]   That's how Apple makes it.
[00:38:35.520 --> 00:38:37.200]   Yeah, well, that's to be strictly honest.
[00:38:37.200 --> 00:38:38.160]   That's exactly right.
[00:38:38.160 --> 00:38:39.840]   Well, are we talking security or privacy?
[00:38:39.840 --> 00:38:40.560]   I mean, the one--
[00:38:40.560 --> 00:38:41.920]   Well, there's two issues.
[00:38:41.920 --> 00:38:42.880]   I brought up books.
[00:38:42.880 --> 00:38:44.080]   Well, and they're both issues.
[00:38:44.080 --> 00:38:48.720]   One thing is that the Apple store is a little better at vetting apps in the Google store.
[00:38:48.720 --> 00:38:54.160]   If so, you're more likely to get an insecure app coming onto the Android platform than the iOS.
[00:38:54.160 --> 00:38:54.720]   That's true.
[00:38:54.720 --> 00:38:56.080]   And then the privacy issue is--
[00:38:56.080 --> 00:38:59.440]   Again, I'll raise that point that it's not free of--
[00:38:59.440 --> 00:38:59.920]   Absolutely not.
[00:38:59.920 --> 00:39:01.040]   --all issues apps on the iOS.
[00:39:01.040 --> 00:39:01.680]   Yeah.
[00:39:01.680 --> 00:39:04.160]   Some get through all the time we hear stories of them getting.
[00:39:04.160 --> 00:39:06.160]   No, at the end of the day, sort of like Briana was talking about,
[00:39:06.160 --> 00:39:08.560]   there's no perfect security.
[00:39:08.560 --> 00:39:11.840]   At the end of the day, we're all responsible for our own security.
[00:39:11.840 --> 00:39:17.200]   I mean, making sure you vet the apps you use, making sure you don't download rogue apps.
[00:39:17.200 --> 00:39:20.160]   How many times have you looked for an app and you type in the name of a product
[00:39:20.160 --> 00:39:24.160]   and you get another company's app that comes up in the search,
[00:39:24.160 --> 00:39:29.600]   and if you blindly install it and accept it, you could very well have a rogue app,
[00:39:29.600 --> 00:39:32.800]   simply because you were just not quite careful enough of what you downloaded.
[00:39:32.800 --> 00:39:35.520]   So we're still responsible for any data.
[00:39:35.520 --> 00:39:35.920]   Yeah, I hear--
[00:39:35.920 --> 00:39:38.560]   See, I want to do a legal solution on that.
[00:39:38.560 --> 00:39:42.560]   I think we've got to have a consumer bill of rights when it comes to privacy.
[00:39:42.560 --> 00:39:48.160]   Like, we are clearly having companies that have predatory practices that just take advantage
[00:39:48.160 --> 00:39:49.360]   of normal people.
[00:39:49.360 --> 00:39:54.480]   You know, as far as the question, iPhone or Android, I think both are fine operating systems with
[00:39:54.480 --> 00:39:58.400]   fine security architecture. To me, it's the update issue.
[00:39:58.400 --> 00:40:03.280]   You know, Android just does not update their operating system frequently enough for me to
[00:40:03.280 --> 00:40:04.080]   have confidence.
[00:40:04.080 --> 00:40:05.600]   Well, the hands to make this don't.
[00:40:05.600 --> 00:40:07.360]   I mean, I have a pixel phone.
[00:40:07.360 --> 00:40:09.120]   Mine's up to date because it's a Google phone.
[00:40:09.120 --> 00:40:14.480]   And I have the Nexus 6P for my second phone, and you know, I use that, so it's pretty solid.
[00:40:14.480 --> 00:40:15.120]   But it's just--
[00:40:15.120 --> 00:40:17.520]   So security, if you can afford it basically.
[00:40:17.520 --> 00:40:18.560]   The trust of the Google Playphone?
[00:40:18.560 --> 00:40:18.960]   Yeah.
[00:40:18.960 --> 00:40:23.600]   Yeah, basically. You know, and for me, like I look at John Podesta, who basically,
[00:40:23.600 --> 00:40:26.080]   you know, caused a lot of problems by clicking links.
[00:40:26.080 --> 00:40:28.560]   So I'm very, very cognizant of that, right?
[00:40:28.560 --> 00:40:34.640]   But I think ultimately the answers we've got to, you know, I think we've got to pass
[00:40:34.640 --> 00:40:37.680]   new protections for consumers. You know, we make sure our drugs are safe.
[00:40:37.680 --> 00:40:40.800]   We make sure our roads are safe. We make sure our buildings are safe.
[00:40:40.800 --> 00:40:45.280]   I think we need to start looking and making sure like your software can't just suck up massive
[00:40:45.280 --> 00:40:46.960]   nuts and nuts and information about you.
[00:40:46.960 --> 00:40:50.800]   The technologist who wants to be a legislator, how do you,
[00:40:50.800 --> 00:40:53.040]   Ms. legislator, keep up with the technology?
[00:40:53.040 --> 00:40:56.880]   Because Congress isn't particularly good at keeping up with technology.
[00:40:56.880 --> 00:40:57.280]   And it's just--
[00:40:57.280 --> 00:40:58.400]   Because it's slow updates.
[00:40:58.400 --> 00:40:58.880]   --because it's slow updates.
[00:40:58.880 --> 00:40:58.880]   Yeah.
[00:40:58.880 --> 00:41:02.880]   That are kind of, you know, agnostic when it comes to technology,
[00:41:02.880 --> 00:41:06.720]   so that you don't wind up putting the technologist into a box.
[00:41:06.720 --> 00:41:08.560]   That's a great question.
[00:41:08.560 --> 00:41:15.200]   Yeah, the way I want to do it is I want to say, if you're holding massive amounts of data,
[00:41:15.760 --> 00:41:21.280]   you're liable for keeping that data safe. Now, that doesn't mean you can't ever be hacked.
[00:41:21.280 --> 00:41:25.760]   It means if you're not following the best practices of information security,
[00:41:25.760 --> 00:41:27.840]   then, you know, you could very well end up--
[00:41:27.840 --> 00:41:31.920]   Because Congress could say that, but you can't tell them how to make it safe because Congress is--
[00:41:31.920 --> 00:41:36.400]   No, I think we've got to-- I think we've got to make external boards that look at that and update it.
[00:41:36.400 --> 00:41:42.160]   Yeah, the-- we just had a political operation that let out a huge database of voter information
[00:41:42.160 --> 00:41:46.480]   out there. They threw it on a server in plain text without encryption and without even a
[00:41:46.480 --> 00:41:52.560]   password. That is massively reckless. They should end up in court. You know, someone that just makes
[00:41:52.560 --> 00:41:58.160]   happens to get hacked when they're following best practices, you're good. But I think until
[00:41:58.160 --> 00:42:03.040]   there's a legal consequence for this, it's expensive to do information security right.
[00:42:03.040 --> 00:42:05.280]   So that's two different things. So there's--
[00:42:05.280 --> 00:42:05.840]   Yeah.
[00:42:05.840 --> 00:42:11.760]   --and I agree with you, there should be legal consequences for not doing it right.
[00:42:11.760 --> 00:42:16.240]   And letting stuff out. But I think I also agree with Larry, I wouldn't want
[00:42:16.240 --> 00:42:24.400]   government to pro-scribe how to do it right or even to say, well, you have to do it right. I think
[00:42:24.400 --> 00:42:29.600]   what strikes me that what Congress should do is make penalties for doing it wrong.
[00:42:29.600 --> 00:42:31.120]   Yeah.
[00:42:31.120 --> 00:42:34.000]   Isn't that seem-- do you understand the distinction I'm making?
[00:42:34.000 --> 00:42:37.440]   As a non-legislator, can I weigh in with some BS?
[00:42:37.440 --> 00:42:37.840]   Go ahead.
[00:42:37.840 --> 00:42:38.000]   Yeah.
[00:42:38.880 --> 00:42:44.640]   Totally uninformed but theoretically possible. We don't-- I think I-- the way the lines are being
[00:42:44.640 --> 00:42:51.280]   drawn, I like, I would also add that there needs to be some regulatory or legislative-- basically,
[00:42:51.280 --> 00:42:58.800]   the people need to say, what belongs to whom? I think one of the biggest problems with privacy
[00:42:58.800 --> 00:43:04.000]   and security around our private information is that it is not seen as our information,
[00:43:04.000 --> 00:43:08.720]   that this is now intellectual property of Facebook, intellectual property of Google,
[00:43:08.720 --> 00:43:13.760]   and my browser history, my search history, my location history, my message history,
[00:43:13.760 --> 00:43:18.960]   doesn't belong to me. And it can be shut off at any moment, even though there's a huge chunk of
[00:43:18.960 --> 00:43:24.880]   my identity and my own value tied up in these services. I don't have any recourse if they lose it.
[00:43:24.880 --> 00:43:31.040]   So the property line seems to me is drawn in the wrong place, whereas if we were talking about
[00:43:31.040 --> 00:43:38.000]   my clothes that I purchased and owned or my home that I'm legally leasing, if someone damaged it
[00:43:38.000 --> 00:43:42.560]   or caused it to be damaged through reckless endangerment, they would have some sort of liability. But their
[00:43:42.560 --> 00:43:45.840]   view of me is considered to be theirs as opposed to me.
[00:43:45.840 --> 00:43:51.440]   Yeah, I completely agree with that. Though I think that's a very tricky,
[00:43:51.440 --> 00:43:56.160]   legal question to solve. What I want to do is I want to put an external board. Like,
[00:43:56.160 --> 00:44:02.640]   if you look at standards like, you know, H.264, right, that standard is decided by some engineers
[00:44:02.640 --> 00:44:07.680]   on a board that look at it and make decisions. I think with that same way, if we can get people
[00:44:07.680 --> 00:44:14.240]   that aren't politicians, so it's not politicized to be making a set of best standards the same way,
[00:44:14.240 --> 00:44:18.320]   you know, electrical engineers come through and update the electrical code for the building
[00:44:18.320 --> 00:44:23.680]   we're all sitting in. I think that's the way to do it. So keep it with experts and don't keep it
[00:44:23.680 --> 00:44:30.880]   in politicians hands. We used to have something like that in Congress. They fired them all.
[00:44:30.880 --> 00:44:36.320]   The Office of Technology Assessment was designed to be exactly what you described. So it's part
[00:44:36.320 --> 00:44:40.080]   of your platform to bring that back. Yeah, absolutely. Absolutely.
[00:44:40.080 --> 00:44:43.920]   You got my elixir. You got my illegitimate vote here, New York.
[00:44:43.920 --> 00:44:47.040]   Yeah, I'm going to vote twice for you. That's how much I like it. Okay.
[00:44:47.040 --> 00:44:50.080]   Okay. I'm going to be at that commission on you.
[00:44:50.080 --> 00:44:56.160]   Yeah. No, I actually have some, you know, we have some selfish reasons. We want,
[00:44:56.160 --> 00:45:00.800]   we want to have a pipeline into Congress with you, Verrana. So please get elected.
[00:45:00.800 --> 00:45:04.400]   I will take your call anytime you please get a little.
[00:45:04.400 --> 00:45:10.720]   Absolutely. No, I think that that this is actually for everybody in the US and any country watching
[00:45:10.720 --> 00:45:17.040]   this. I think it is a really, as if you're watching this, you're a technology enthusiast,
[00:45:17.040 --> 00:45:21.600]   probably techno literate. This is an important thing for us to be aware of. We need to have
[00:45:21.600 --> 00:45:25.440]   people in government who understand this and need to support you.
[00:45:25.440 --> 00:45:28.800]   You also bring up an important point when you say any country. So as you know, Leo, I run
[00:45:28.800 --> 00:45:32.880]   Connect safely and work in the internet safety field. And one of the complexities of that,
[00:45:32.880 --> 00:45:35.920]   if you get a Facebook and a Google, they're based here in the United States,
[00:45:35.920 --> 00:45:41.680]   they have hundreds of millions of customers all over the world. And to create a regulatory
[00:45:41.680 --> 00:45:48.320]   environment in a global marketplace is incredibly difficult. And again, I'm not suggesting government
[00:45:48.320 --> 00:45:52.400]   has no role. I agree government has a role to regulate. But when you start regulating,
[00:45:52.400 --> 00:45:58.160]   for example, right now the Europeans are doing this data regulation policy,
[00:45:58.160 --> 00:46:02.960]   which is going to have a huge impact on Silicon Valley, even though these companies are located
[00:46:02.960 --> 00:46:07.520]   thousands of miles away from Europe. So whether you're the US or any other government,
[00:46:07.520 --> 00:46:11.520]   you have to really think through how your regulations are going to affect things.
[00:46:11.520 --> 00:46:16.160]   And how do these companies deal with these multiple different jurisdictions, states,
[00:46:16.160 --> 00:46:21.760]   countries, it's complicated. I'm just saying that it's not as easy, I think, as regulating
[00:46:21.760 --> 00:46:27.520]   electrical panels. Yeah. No. And I think if you asked Zuckerberg in his heart of hearts,
[00:46:27.520 --> 00:46:31.440]   like if you could get him to take some kind of controlled substance and be super honest,
[00:46:31.440 --> 00:46:38.880]   he would want Facebook to be that global government. Because it actually has more constituents,
[00:46:38.880 --> 00:46:47.680]   more citizens than any nationally bound, you know, city, city, state or nation state than we have.
[00:46:47.680 --> 00:46:53.680]   And who better to be able to understand global implications and consequences than a global
[00:46:53.680 --> 00:46:59.040]   platform like that. So I think if you are the biggest, baddest, most well armed and well funded
[00:46:59.040 --> 00:47:05.600]   government, I'm of course, speaking of Canada now, then you still don't hold a candle to the
[00:47:05.600 --> 00:47:12.640]   reach the influence and the kind of the sheer connectivity of a pseudo government like Facebook,
[00:47:12.640 --> 00:47:15.840]   could be that could flip a switch. There could be an update to Facebook. And now we got a Facebook
[00:47:15.840 --> 00:47:21.120]   government, you know, frightening thought. Every science fiction novel I know of, including
[00:47:21.120 --> 00:47:26.640]   neuromancer talks about corporate governance and that the multinationals are ultimately going to
[00:47:26.640 --> 00:47:30.400]   be rules of world. I don't, that science fiction. We have to wait till Zuckerberg had the fun
[00:47:30.400 --> 00:47:34.480]   in law who he could put in charge of things. You don't have to stretch too hard to imagine,
[00:47:34.480 --> 00:47:40.560]   though, that these, I mean, look, it's really good. That minus the nuclear weapons, Facebook
[00:47:40.560 --> 00:47:46.960]   is in many ways, an international power. It is. Yeah. Yeah. Of course, nuclear weapons make
[00:47:46.960 --> 00:47:50.640]   a big difference. Having tanks does make a big difference. I don't anticipate Facebook.
[00:47:50.640 --> 00:47:57.120]   But you know, in some ways, I almost feel like, you know, tanks and weapons are a less relevant,
[00:47:57.120 --> 00:48:03.040]   you know, way to influence things today, like economic warfare, cyber warfare, you know,
[00:48:03.040 --> 00:48:08.480]   information warfare, all of this stuff is all the more relevant. So, you know, something I feel
[00:48:08.480 --> 00:48:12.960]   really strongly about is I think that when we think about serving our country, we think about
[00:48:12.960 --> 00:48:18.960]   somebody in a uniform with a gun. And that's a fine thing to do, but it's not the only way to
[00:48:18.960 --> 00:48:24.960]   solve problems. And I do think that we need people that care about technology, that understand
[00:48:24.960 --> 00:48:30.720]   technology to step up and help improve this policy. Maybe that's run for office yourself.
[00:48:30.720 --> 00:48:35.760]   Maybe it's donate to a candidate that gets it. But we are the ones that understand this stuff.
[00:48:35.760 --> 00:48:41.920]   And clearly, our current leadership just doesn't. That's, I was very saddened by, and I'm sure you
[00:48:41.920 --> 00:48:50.400]   all read the, I think it was a medium post by, I'm trying to find it now, the guy who was working in
[00:48:50.400 --> 00:48:55.920]   our, was it J18? What was it called? The government? Do you know what I'm talking about?
[00:48:55.920 --> 00:49:00.320]   The government organization designed a streamlined government who's finally decided to resign.
[00:49:00.320 --> 00:49:04.560]   Oh, 18F. 18F. Yeah. It's part of the US Digital Service.
[00:49:04.560 --> 00:49:09.760]   But I didn't see about this resignation. And I loved what those folks were doing under
[00:49:10.480 --> 00:49:14.080]   Obama, for sure. And there's still good people deployed in all the agencies doing
[00:49:14.080 --> 00:49:18.480]   good work to make government more effective. But I'm talking about who resigned.
[00:49:18.480 --> 00:49:22.400]   No, no, no, no, Koonen, who was the, he was the,
[00:49:22.400 --> 00:49:28.720]   infrastructure, infrastructure director. You knew this. Yeah. And he had written a blog post in
[00:49:28.720 --> 00:49:34.720]   November, right after the election, why I'm staying at 18F. He brought a blog post this week,
[00:49:35.440 --> 00:49:42.960]   why I'm not staying at 18F. Oh, wow. Yeah. What happened between election and inauguration
[00:49:42.960 --> 00:49:52.640]   day, he said the people with it, with the matches are inside the house. Yeah. Oh, no. And he was,
[00:49:52.640 --> 00:50:01.760]   I think it's a, it's a sad and scary post because he feels like, in particular,
[00:50:03.280 --> 00:50:08.720]   that the issue is not merely that President Trump is unfit, but that he is asking for the
[00:50:08.720 --> 00:50:16.080]   personal loyalty, personal loyalty to him, of people in government. Yes. And he says that this is,
[00:50:16.080 --> 00:50:22.160]   this is a significant issue. And I gather that he feels like
[00:50:22.160 --> 00:50:30.800]   it's not going well at 18, 18F. And that, yeah, giving positions of power to people based on
[00:50:30.800 --> 00:50:36.560]   favoritism or nepotism or how easily they can be controlled from above as dangerous norm for our
[00:50:36.560 --> 00:50:43.440]   democracy. The White House is complete disregard of merit and Trump's fetish with personal loyalty
[00:50:43.440 --> 00:50:51.840]   is becoming systemic and is getting worse. And so he feels like it's just, so this is the thing
[00:50:51.840 --> 00:50:56.560]   that really scares me. You don't want to chase the smart people, the effective people out.
[00:50:57.760 --> 00:51:02.480]   Yeah. And, and Noah, it was one of the smart, effective people. The head of the ethics
[00:51:02.480 --> 00:51:06.400]   of the office just resigned this week as well. I mean, yeah. And the thing is, the timing is
[00:51:06.400 --> 00:51:12.560]   extremely bad because we are more than ever, and I really am concerned about this, faced with
[00:51:12.560 --> 00:51:18.960]   cyber warfare from other national governments, other countries, nation states.
[00:51:18.960 --> 00:51:26.000]   In an unprecedented way, we are seeing hacking, we're seeing attacks, we're seeing probing of,
[00:51:26.000 --> 00:51:32.320]   of the power grid of nuclear facilities. This is widespread. Everybody knows it. Everybody knows
[00:51:32.320 --> 00:51:41.120]   it's happening. And yet, and so now more than ever, we need a plan as a country and a way forward
[00:51:41.120 --> 00:51:46.080]   to this. And I feel like, can I tell you, can I tell you a story that isn't being covered at all?
[00:51:46.080 --> 00:51:50.560]   Yeah. Here in Boston, we have Merck, which is one of the biggest pharmaceutical giants in the
[00:51:50.560 --> 00:51:56.880]   entire planet. Merck, this is a really, really important company. They've been shut down since
[00:51:56.880 --> 00:52:02.560]   June here in Boston. They're a huge facility here, one of the biggest employers in Massachusetts,
[00:52:02.560 --> 00:52:08.400]   because they were hit by ransomware attack. And every single employee there is just on paid vacation.
[00:52:08.400 --> 00:52:16.800]   And you can drive to their parking lot and nobody's there. This is such an unbelievably huge issue.
[00:52:16.800 --> 00:52:22.240]   And the committee, I hope to serve on is the Science and Technology Subcommittee.
[00:52:22.240 --> 00:52:27.440]   As best as I can tell, they have no plans for this. They are not addressing this in a realistic
[00:52:27.440 --> 00:52:33.920]   way. And it's just like you said, it's utterly terrifying. Here in Boston, we have two nuclear
[00:52:33.920 --> 00:52:40.720]   power plants that are in the kill range of Boston. So when I read stories in The New York Times and
[00:52:40.720 --> 00:52:46.880]   The Washington Post about these plants being under attack, that is a 10 out of 10 crisis,
[00:52:46.880 --> 00:52:53.200]   as far as I'm concerned. And it is so frustrating to me that people in both parties have gotten to a
[00:52:53.200 --> 00:52:58.720]   point where we're more interested in screaming at each other than keeping the American people safe.
[00:52:58.720 --> 00:53:01.600]   And this has to be addressed. There are no other options.
[00:53:01.600 --> 00:53:05.760]   You think about it, if a guy with a six-shooter walks into a savings and loan office with his
[00:53:05.760 --> 00:53:10.800]   gun and holds up a bank robbery, that's a huge deal. That's a federal offense. The FBI gets
[00:53:10.800 --> 00:53:15.200]   involved. And you're telling me that an entire company has been shut down. What if somebody got
[00:53:15.200 --> 00:53:20.400]   in there with guns and shut it down? I mean, this is a very frightening thought that you can
[00:53:20.400 --> 00:53:25.520]   remotely shut down a company the size of Merck without even having to come to this country,
[00:53:25.520 --> 00:53:31.440]   let alone show up in their parking lot. Yeah, the other side of that beautiful,
[00:53:31.440 --> 00:53:36.160]   distributed network that we built of all the other networks called the internet. It's like the
[00:53:36.160 --> 00:53:41.520]   the other edge of the sword is starting to be felt, whether it's propaganda, disinfo,
[00:53:41.520 --> 00:53:47.200]   or cyber attacks. There's something finally worth attacking. We multi-billion dollar companies
[00:53:47.200 --> 00:53:51.520]   depend on this connectivity in a way they didn't back when it was like a DARPA project.
[00:53:51.520 --> 00:53:57.840]   Here's a tweet, a picture from DLA Piper, which is a big multinational law firm in Washington, DC.
[00:53:57.840 --> 00:54:03.840]   Attention DLA employees is on a whiteboard as you walk in the door. All network services are down.
[00:54:03.840 --> 00:54:09.200]   Do not underline. Turn on your computers. Please remove all laptops from docking stations and
[00:54:09.200 --> 00:54:16.240]   keep turned off no exceptions. You can imagine the IT department in these companies facing Petra,
[00:54:16.240 --> 00:54:21.840]   which is what brought down Merck and apparently brought down DLA Piper and just watching it spread
[00:54:21.840 --> 00:54:25.440]   through their network. And what I love is the use of whiteboard, you know, with basically,
[00:54:25.440 --> 00:54:28.960]   you know, technology that was essentially right. That's the only thing I can use right?
[00:54:28.960 --> 00:54:37.280]   Whiteboard. So you can't even print it. This is like Mr. Robot playing out in real life.
[00:54:37.280 --> 00:54:43.520]   Well, and that's really what scares me now. It's believed that Petra, at least the experts and
[00:54:43.520 --> 00:54:50.400]   security experts who I've read about say that Petra is probably Russian, but WannaCry,
[00:54:50.400 --> 00:54:56.160]   the same experts believe came out of North Korea. Two states alone with significant hacking capabilities,
[00:54:56.160 --> 00:55:02.480]   not much love for the United States. Great interest in disrupting the US are attacking us
[00:55:02.480 --> 00:55:09.120]   right now, actively attacking us and have been for months. And we have no coherent plan. We have
[00:55:09.120 --> 00:55:14.720]   Rudolph Giuliani. It's the same. I mean, it's funny. It's not funny at all, actually, but the
[00:55:15.520 --> 00:55:21.680]   level of disruption that a lot of us celebrated, you know, that shook the core of the music industry
[00:55:21.680 --> 00:55:27.360]   or the media industry writ large is also, you know, affecting finance is affecting security.
[00:55:27.360 --> 00:55:31.600]   And it just, I don't know, just for Briana being one, especially, I'm just thinking more about
[00:55:31.600 --> 00:55:36.320]   politics than even I normally do, but it resorts to the list. This is a great, this is a way if
[00:55:36.320 --> 00:55:41.760]   you are North Korea, you're a laughing stock. And now that you get respect, your Russia,
[00:55:41.760 --> 00:55:47.440]   your economy is one 20th or something the size it used to be size of Italy. You're not great.
[00:55:47.440 --> 00:55:52.800]   You're you have a lot of people. You have a huge landmass. But the way that you force yourself
[00:55:52.800 --> 00:55:59.200]   back to a seat at the table is through this. This is like, this is a power up in a video game.
[00:55:59.200 --> 00:56:03.280]   You've like unlocked this great level up. I'm gonna propose something.
[00:56:03.280 --> 00:56:10.880]   It's the new nuke is a cyber weapon. This is so we saw it in the 80s and 90s and 2000s
[00:56:10.880 --> 00:56:15.680]   that short term thinking for privately held companies and publicly held companies became
[00:56:15.680 --> 00:56:21.200]   the mode. You want to have great quarterly results. And as a result, you do no planning for the future.
[00:56:21.200 --> 00:56:28.720]   And this mindset I were proposed has also entered a last government that they that every person
[00:56:28.720 --> 00:56:35.920]   in Congress is concerned about the primary and getting through the primary and then ultimately
[00:56:35.920 --> 00:56:40.560]   getting through the election. And not so what's going to happen in the next year and a half,
[00:56:40.560 --> 00:56:44.240]   not what's going to happen in the next five years or 10 years or the long term
[00:56:44.240 --> 00:56:51.280]   stability of the country. And I think that this just in the same way this killed the financial markets
[00:56:51.280 --> 00:56:57.120]   and it really became a problem in the in the in the economy is about to become a massive
[00:56:57.120 --> 00:56:59.920]   problem in government. And it's a huge problem with the healthcare industry, right? You've got
[00:56:59.920 --> 00:57:05.440]   this whole industry that has no idea what their future is because one party has one plan,
[00:57:05.440 --> 00:57:09.840]   another party wants to completely repeal that plan. And even if the Republicans are successful
[00:57:09.840 --> 00:57:14.720]   in doing that, eventually the Democrats are going to come back in and reinstate some kind of other
[00:57:14.720 --> 00:57:20.720]   plan. And how do you run an industry without without any any level of long term planning,
[00:57:20.720 --> 00:57:25.600]   knowing that every four years it's going to flip around. Well, so here's yeah, sorry, go ahead,
[00:57:25.600 --> 00:57:30.640]   Brianna. No, no, no, I was going to say, I think that's the beauty of the plan I was talking on
[00:57:30.640 --> 00:57:38.000]   earlier of making it, you making creating legal consequences if these safeguards aren't in place
[00:57:38.000 --> 00:57:44.000]   because clearly, because of the financial motive, you're not going to spend that money. Like it
[00:57:44.000 --> 00:57:49.040]   talked to engineers, engineers will tell you they asked to improve security at their, you know,
[00:57:49.040 --> 00:57:53.280]   offices and their bosses don't want to spend the money. We have to create an environment
[00:57:53.280 --> 00:57:58.080]   when it's worth that in the private industry for them to keep that safe. And I want Americans to
[00:57:58.080 --> 00:58:03.440]   lead the world in information security. But go over to the military side. I was talking to a
[00:58:03.440 --> 00:58:09.600]   military engineer just last week. You know, there's a six mile set of power cables here in the United
[00:58:09.600 --> 00:58:14.800]   States. If that were taken down, power to a good part of the United States would just vanish.
[00:58:14.800 --> 00:58:19.520]   And that could be taken down with the cyber attack. It happened a few years ago, the East Coast
[00:58:19.520 --> 00:58:23.920]   grid got taken down. Well, and more is concerning. It looks like the Russians have been testing
[00:58:23.920 --> 00:58:29.440]   technologies to do this in the Ukraine to do this. And also targeting socially,
[00:58:29.440 --> 00:58:34.320]   the engineers, the safety engineers that control the systems, like going after them socially to
[00:58:34.320 --> 00:58:40.560]   try to blackmail them, which is another kind of cyberwarefare. So we've got to, we have to create
[00:58:40.560 --> 00:58:45.520]   incentives for private industry to do the right thing. But on the government side, what really
[00:58:45.520 --> 00:58:52.640]   concerns me is the more I ask questions about how is this code reviewed for X or Y system,
[00:58:52.640 --> 00:58:57.600]   there's not a great answer there. So we've got to mandate, if you're not going to use open source
[00:58:57.600 --> 00:59:02.240]   technology, that you do undergo code review. So we can make sure these systems are working.
[00:59:02.240 --> 00:59:05.760]   Because the answer is right now, we just don't know, which is why we're wildly vulnerable.
[00:59:05.760 --> 00:59:09.760]   We have a CTO to make it Smith get replaced. No one knows what's going on.
[00:59:09.760 --> 00:59:14.720]   I'm pretty sure Jared Kushner is taking all the positions.
[00:59:14.720 --> 00:59:21.680]   It's a super, super intelligent, but it may get actually knew something about technology.
[00:59:21.680 --> 00:59:27.120]   Yeah. So I'm trying to remember, but I think it was Xi Jinping, the
[00:59:27.120 --> 00:59:32.560]   general secretary of the Communist Party in China, in other words, the guy in charge in China,
[00:59:32.560 --> 00:59:38.880]   who said specifically, one of the reasons we're succeeding is because we have a long-term plan.
[00:59:38.880 --> 00:59:45.280]   And the US is failing is because they've been not planning for the future. They've been planning for
[00:59:45.280 --> 00:59:50.880]   short-term goals. And that is no way to run a country. You can maybe get away with it
[00:59:50.880 --> 00:59:54.960]   running a company that way. But I don't know if you can run a country that way.
[00:59:54.960 --> 00:59:57.280]   I don't even think you can run a company that way. That for long.
[00:59:57.280 --> 01:00:02.160]   That's kind of in the definition of short-term, because it doesn't work for the long term.
[01:00:02.160 --> 01:00:03.600]   Yeah. I'm going to try to find this.
[01:00:03.600 --> 01:00:07.680]   People's lives are at stake. I mean, when you think about, again, not to overdo the
[01:00:07.680 --> 01:00:12.880]   insurance thing, but if you're planning your life, you want some assurances that this insurance
[01:00:12.880 --> 01:00:17.600]   policy that you're paying for is going to be there for you two years, three years, four years down
[01:00:17.600 --> 01:00:21.600]   the road. And that Medicare is going to be there for you if you're planning on having Medicare.
[01:00:21.600 --> 01:00:25.200]   I don't know how anybody in America has any kind of long-term sense of
[01:00:25.200 --> 01:00:29.840]   assurity, given the fact that we have no idea what's going to be happening year to year.
[01:00:29.840 --> 01:00:35.920]   It's something we've built in. Unfortunately, we built into our economic system
[01:00:35.920 --> 01:00:43.040]   with quarterly reports and stock market results. And now we apparently built that into our government
[01:00:43.040 --> 01:00:49.600]   system with the way the elections work and funding works. And now I'm very worried that this is...
[01:00:49.600 --> 01:00:54.080]   Well, yeah, we got to get more optimistic, guys. I'm feeling really pumped up.
[01:00:54.080 --> 01:00:59.440]   It's your fault. Here's what I'm going to do. I'm going to remind us that our
[01:00:59.440 --> 01:01:05.280]   former government in this nation at least is distributed. We have 50 states. We have 50 laboratories
[01:01:05.280 --> 01:01:10.320]   that you can say broad things about the health insurance market, but it's different in every
[01:01:10.320 --> 01:01:15.200]   state. California's outcomes are very different from Texas. And when it comes to cybersecurity,
[01:01:15.200 --> 01:01:19.120]   it's not... The government's never going to do it all anyway, especially because the internet's
[01:01:19.120 --> 01:01:23.440]   not a government tool. It's not like the interstate highway system, which is kind of managed by
[01:01:23.440 --> 01:01:27.920]   government. We have personal responsibility. The companies in the platforms have major
[01:01:27.920 --> 01:01:33.440]   responsibility. Brianna's going to get in there. We're going to clone her. We'll have AI Congress
[01:01:33.440 --> 01:01:39.520]   powered by Brianna Wu. She's going to seed the initial kernel for the new artificial intelligence
[01:01:39.520 --> 01:01:44.240]   Congress to get the good laws. But in the meantime, Massachusetts will be a little better.
[01:01:44.240 --> 01:01:48.240]   And I just... Yeah, we'll do it. We have to do it because we don't have another choice.
[01:01:48.240 --> 01:01:53.600]   And we can't just be sad and depressed about it. I just have refused to make this progress.
[01:01:53.600 --> 01:01:57.840]   And it's why people should be running for school board and city council and dogcatcher,
[01:01:57.840 --> 01:02:01.600]   whatever other positions are available in their community, and not just worrying about the
[01:02:01.600 --> 01:02:07.040]   president or even Congress. I mean, we... And look, and there will be... Whether the government
[01:02:07.040 --> 01:02:13.280]   does quote-unquote the right thing or not, some kind of... There will eventually be a catastrophic
[01:02:13.280 --> 01:02:19.600]   loss on the financial front by a company. And then all these prices will get paid. And it'll be on
[01:02:19.600 --> 01:02:24.400]   the backs of all these incremental failures, loss of credit card data, loss of security card.
[01:02:24.400 --> 01:02:28.080]   You didn't hash your passwords. We lost this database. And then some major things
[01:02:28.080 --> 01:02:32.960]   going to happen in the form of death, most likely, or serious property damage or something.
[01:02:32.960 --> 01:02:36.960]   And folks are going to be like, "Oh, we could have... When it comes out that you could have done
[01:02:36.960 --> 01:02:41.280]   something that you didn't do, and there was this marginal cost that you wouldn't expend,
[01:02:41.280 --> 01:02:46.720]   that will be the market incentive, sadly, that will get... This is supposed to be optimistic.
[01:02:46.720 --> 01:02:51.520]   I thought you were going to be... Well, it's going to take a chance to feed, but it's not real.
[01:02:51.520 --> 01:02:57.440]   It's a lot. I have a feeling what we're hearing is the beginning of Baratunde's
[01:02:57.440 --> 01:03:05.280]   his launch for his exclusive column in Medium. It's called Active Citizenship. When is that going to
[01:03:05.280 --> 01:03:11.200]   start? It started. June was my first month. I started with a double-header piece about why
[01:03:11.200 --> 01:03:17.200]   everyone should go to jail, preferably as a visitor, not as an enrollee or a detainee.
[01:03:17.200 --> 01:03:23.120]   And this was specific to Rikers Island Jail in New York City, but there's general takeaways to be
[01:03:23.120 --> 01:03:29.280]   applied to any prison or jail anywhere in the world, things being done in our name,
[01:03:29.280 --> 01:03:36.720]   kind of in shadows that we silently cosign on. But I also did a huge data detox a few months back,
[01:03:36.720 --> 01:03:44.480]   and I've been sitting on that and the things I learned trying to have better data hygiene and
[01:03:44.480 --> 01:03:50.320]   privacy hygiene. Super difficult, super challenging, like asking individual users to just be better.
[01:03:50.320 --> 01:03:55.280]   It's kind of like saying, "Just say no." It's not the most effective thing for most people.
[01:03:55.280 --> 01:03:59.200]   So yeah, I'll be writing about citizenship in all its forms, some digital, some
[01:03:59.200 --> 01:04:05.200]   IRL, and some hybrid in between, but it's kicked off. I'll be running it at least through the end of
[01:04:05.200 --> 01:04:12.640]   the year. And it is part of something pretty cool, which is the new paid... Don't show my credit card
[01:04:12.640 --> 01:04:19.040]   number. Thank you. Too late. That's okay. I'll be canceling that credit card now, but I was just
[01:04:19.040 --> 01:04:27.760]   about to pay for the new paid version of Medium, which is pretty exciting. So you remember,
[01:04:27.760 --> 01:04:32.800]   Evan Williams said, "We're going to reinvent Medium. We're not going to have ads on anymore.
[01:04:32.800 --> 01:04:39.200]   We're going to have memberships $5 a month." And I did just pay, and I encourage others to do so,
[01:04:39.200 --> 01:04:46.000]   so that you can see... So your stuff is available only as a member exclusive. I think that's smart.
[01:04:46.000 --> 01:04:51.120]   Well, yeah. I think that's smart. It's a new model. A smart, not a view, smart of
[01:04:51.120 --> 01:04:55.840]   Williams and Medium, because I'll tell you what, I will pay $5 a month just to read you.
[01:04:55.840 --> 01:05:01.200]   Oh, thanks, Leo. Absolutely. No, it's a worthy experiment on their part, and I'm glad that they're
[01:05:01.200 --> 01:05:05.840]   actually putting money and sort of decisions where their mouths have been. We've seen...
[01:05:05.840 --> 01:05:12.880]   The ad model dominates every form of media right now, and so it's good for them, I think,
[01:05:12.880 --> 01:05:19.920]   to at least try something else, because the incentives that online ads create in terms of
[01:05:19.920 --> 01:05:26.480]   clickbait and headline writing and fake news, all the stuff we've seen is pretty clear. So what
[01:05:26.480 --> 01:05:33.360]   would happen if you tried this radical notion of directly paying for access to information?
[01:05:33.360 --> 01:05:36.880]   One of the things that everything should go that way, but it's... One of the things that love
[01:05:36.880 --> 01:05:42.240]   about new media is how we're trying all sorts of different ways, figuring out new ways of making
[01:05:42.240 --> 01:05:48.800]   this work, because journalism is important. Voices disparate are important. Your voice is
[01:05:48.800 --> 01:05:53.120]   important, baritone. So I think it is important we figure out ways to make this work. Now, if I
[01:05:53.120 --> 01:05:59.040]   can just figure out a way to cancel my credit card while I'm doing this show, I'll be fine.
[01:05:59.040 --> 01:06:05.840]   Oh, no. That's great. Go ahead. Can I tell you something about media before we move on?
[01:06:06.640 --> 01:06:12.720]   I think it's really important to recognize companies that do good things, and their
[01:06:12.720 --> 01:06:17.520]   companies, like women in tech talk, don't go work there, stay away from these people.
[01:06:17.520 --> 01:06:24.000]   Medium is consistently, I hear good things from that company, from people that work there,
[01:06:24.000 --> 01:06:31.200]   and I love it that they sponsor networking events for women during WWDC every single year. They
[01:06:31.200 --> 01:06:35.760]   didn't do it this year for some reason, but previous years has been some of the best networking I've
[01:06:35.760 --> 01:06:41.680]   done. And I just, everyone I've ever talked to at that company is awesome. So that is the
[01:06:41.680 --> 01:06:45.680]   company that would feel very comfortable about giving $5 a month to.
[01:06:45.680 --> 01:06:49.120]   You know, we need this. This is good. We need to do this more often. We talk enough about
[01:06:49.120 --> 01:06:53.840]   companies that are badly run in sexist and harassment. Let's honor companies that are well run,
[01:06:53.840 --> 01:07:00.960]   treat their employees well. That is great. I like that, Brianna. Again, you've broken new ground.
[01:07:00.960 --> 01:07:04.960]   I think that's a really good idea. If we find a company that internally is well run,
[01:07:04.960 --> 01:07:12.160]   that its employees are treated with dignity, that it hires a diverse workforce, let everybody know.
[01:07:12.160 --> 01:07:19.200]   And let's patronize those companies. And Oscars for decency. I like it. I like it.
[01:07:19.200 --> 01:07:23.680]   I'll tell you one company I think runs that way. I think pretty well runs that way.
[01:07:23.680 --> 01:07:29.520]   By the way, it just pisses me off because I complain all the time about how when you enter
[01:07:29.520 --> 01:07:32.720]   passwords and credit card numbers, they just show the dots and you can never know if you've
[01:07:32.720 --> 01:07:37.920]   done it right. Medium must have listened. So they showed my credit card number in its entirety.
[01:07:37.920 --> 01:07:49.120]   Why did you use dots? Don't I actually? The one time one time. Why would why would you use
[01:07:49.120 --> 01:07:54.960]   dots? Who's looking when you're typing in your credit? No one's looking. Everyone was looking.
[01:07:54.960 --> 01:08:02.000]   Our show is brought to you today by Casper Mattress is my mattress. The best way. Yeah, right?
[01:08:02.000 --> 01:08:07.600]   Yeah, there's a company that has really done something to change the way you buy a mattress.
[01:08:07.600 --> 01:08:12.800]   Now I know a lot of you think that you can't buy a mattress unless you lie on it. And I agree.
[01:08:12.800 --> 01:08:16.480]   I think ideally you would sleep on it, but you can't do that in the mattress showroom. You can
[01:08:16.480 --> 01:08:21.120]   lie there. They put a little thing down for your feet, a little piece of paper on the pillow,
[01:08:21.120 --> 01:08:25.680]   and then the salesperson stares at you while you go, "Hmm, and you try to get comfortable."
[01:08:25.680 --> 01:08:31.200]   It's not a good way to test a mattress. Casper has a better way. You buy direct from Casper.
[01:08:31.920 --> 01:08:38.320]   They're mattress, by the way, designed by a team of 20 engineers. They have half a million sleepers
[01:08:38.320 --> 01:08:44.480]   who have really perfected it. And here's the best part. You get 100 days to sleep on it.
[01:08:44.480 --> 01:08:48.400]   If at any time in the first 100 days you say, "Yeah, it's not for me." They will come. They will
[01:08:48.400 --> 01:08:56.000]   pick it up. They will get rid of it and no cost to you. They'll refund every penny. Casper
[01:08:56.880 --> 01:09:02.720]   has spent much money on designing a perfect mattress. People don't think about the science
[01:09:02.720 --> 01:09:06.880]   behind mattresses. But I get, it's in the middle of the night, about four o'clock when you wake up
[01:09:06.880 --> 01:09:12.160]   and there's a lump pressing into you from the mattress spring or the sprung or whatever,
[01:09:12.160 --> 01:09:17.600]   the tufting. You might start thinking, "Eh, they ought to spend more time thinking about a mattress."
[01:09:17.600 --> 01:09:23.680]   The Casper team is a bunch of engineering nerds. They have really dug as far as you can into the
[01:09:23.680 --> 01:09:28.640]   science of sleep and how to deliver it. I'll give you an example, especially on these hot summer
[01:09:28.640 --> 01:09:34.160]   nights. A cool mattress is a comfortable mattress. You don't want a mattress that's hot. You want a
[01:09:34.160 --> 01:09:39.440]   mattress that breathes. The Casper mattress is the most comfortable mattress I've ever slept on.
[01:09:39.440 --> 01:09:45.600]   Temperature alone, it's got a breathable open cell layer for all night comfort. It's also got
[01:09:45.600 --> 01:09:52.960]   supportive memory foam that relieves pressure on your hips and other pointy bits, but still supports
[01:09:52.960 --> 01:09:56.800]   you so your back doesn't hurt in the morning. I don't know how they do it. It's magical. Fast
[01:09:56.800 --> 01:10:02.800]   company named Casper, the most innovative brand of 2017. If I had that mattress, I got a sleep
[01:10:02.800 --> 01:10:08.320]   score last night of 78. You need a better sleep score. You need a better sleep score.
[01:10:08.320 --> 01:10:12.640]   Come on, have created this app and this device, you stick under any mattress including Casper.
[01:10:12.640 --> 01:10:17.840]   It analyzes my sleep. Last night, I only got a 78. That's pathetic, Larry.
[01:10:17.840 --> 01:10:22.960]   I have a Casper sent to you. It comes in a very compact box. I can put my sensor under there.
[01:10:22.960 --> 01:10:26.960]   If my sleep score goes up to 90. You'll know. You've got the metrics.
[01:10:26.960 --> 01:10:31.120]   Free, by the way, it's the kind of thing they did. They really did test it. Free shipping,
[01:10:31.120 --> 01:10:35.920]   free returns, not only in the US and Canada, but they've just added the UK. I know I'm
[01:10:35.920 --> 01:10:40.560]   many listeners in Great Britain in the UK who were saying, "Oh, I want a Casper." But it's annoying.
[01:10:40.560 --> 01:10:44.960]   You do these ads. I can't buy one. Now you can buy one. Considering we spend a third of our
[01:10:44.960 --> 01:10:49.280]   lives on a mattress, you've got to get a better night. 7-hour, then 41 minutes.
[01:10:49.280 --> 01:10:57.360]   Get a better sleep score right now with Casper. I have the Casper bed for my dog Rocket.
[01:10:57.360 --> 01:11:03.120]   They do. They have dog beds. They do. I always see what my dog says.
[01:11:03.120 --> 01:11:09.280]   Sleep score is. Actually dogs and cats have a very high sleep score. I want to buy it.
[01:11:11.280 --> 01:11:16.160]   All they do, that they're profession. I have a Casper mattress as well.
[01:11:16.160 --> 01:11:23.040]   To segue us into another story in the lineup. Hold on. Let me finish this at the end.
[01:11:23.040 --> 01:11:28.080]   Oh, you're not done. I'm sorry. I'm not done. I just got to give out the address Casper.com/twit.
[01:11:28.080 --> 01:11:32.080]   And a reminder that if you use the promo code "twit," you get $50 towards any mattress purchase.
[01:11:32.080 --> 01:11:36.560]   Casper, I know it felt like I'd done the ad, but I wasn't quite done. Casper.com/twit
[01:11:36.560 --> 01:11:40.960]   used the promo code. Some terms and conditions apply. You can read it bad. Look at that.
[01:11:40.960 --> 01:11:46.560]   What is the? I love the numbers on the front page. You got to Casper.com/twit.
[01:11:46.560 --> 01:11:52.320]   They're counting up dreams, nights, sheep counted. Go ahead, Veritani. What's the segue?
[01:11:52.320 --> 01:11:59.680]   This tribe before you buy model of e-commerce, Amazon is also pushing more aggressively to
[01:11:59.680 --> 01:12:03.360]   with their Amazon wardrobe. Did you see that? I thought that was very interesting.
[01:12:03.360 --> 01:12:06.320]   All these other companies that are sort of, they don't even charge you until you.
[01:12:06.800 --> 01:12:12.320]   So the basic idea being you get, whether it's for children's clothes or men's fashion or women's
[01:12:12.320 --> 01:12:18.160]   fashion, you get a box of clothes and you can try on a bunch of them and send them back.
[01:12:18.160 --> 01:12:24.000]   And then you get charged based on what you keep rather than the sort of assumption that you
[01:12:24.000 --> 01:12:26.800]   probably won't return. So you're overpaying for things you don't actually use.
[01:12:26.800 --> 01:12:30.080]   So there are other companies that do this, but Amazon is doing something interesting.
[01:12:30.080 --> 01:12:32.480]   The more you buy, the less you pay. Yeah, you get a discount.
[01:12:32.480 --> 01:12:36.080]   So that's smart. Plus they're Amazon. Now I have to tell you this jacket that I'm wearing,
[01:12:36.080 --> 01:12:39.600]   I got in a box. I got it from a bomb fell, which is one of the companies. They were a sponsor,
[01:12:39.600 --> 01:12:44.960]   one of the companies that does this. I love this jacket. And I love that method,
[01:12:44.960 --> 01:12:48.640]   because I don't want to go shop. I hate to shop for clothing. I don't mind shopping for
[01:12:48.640 --> 01:12:54.560]   computers, memory chips. I'll shop at any hardware store in the country as long as you want. But
[01:12:54.560 --> 01:13:00.640]   they have, I was shopping with my wife the other day. In stores where women buy clothes,
[01:13:00.640 --> 01:13:05.520]   they have a chair. They have the husband chair. Am I wrong? You do?
[01:13:05.520 --> 01:13:17.040]   Yeah. And there's actually an Instagram account that is features men sleeping in those chairs.
[01:13:17.040 --> 01:13:25.440]   Is that balls looking bored, looking depressed, looking tired. So yeah,
[01:13:25.440 --> 01:13:28.960]   do yourself a favor. I don't understand why you would bring your husband along on that trip.
[01:13:28.960 --> 01:13:33.520]   I would never do that. I would never do that. I've never buy clothes in a store.
[01:13:33.520 --> 01:13:40.000]   It's part of it. I have an odd inseam. It's 29, and it's impossible to find 29.
[01:13:40.000 --> 01:13:44.960]   The only even numbers in stores. Plus when I go to Costco, they only have extra large,
[01:13:44.960 --> 01:13:49.440]   because they sell food in extra large containers. So they'll close an extra large as well.
[01:13:49.440 --> 01:13:55.200]   And so it's so much easier to buy it online. Here's the, it's Instagram. It's miserable men.
[01:13:55.200 --> 01:14:02.320]   Miserable underscore men. And it's just, it's just pictures of guys like waiting,
[01:14:02.320 --> 01:14:09.360]   waiting for their wives. Just, just how, this is how common this is. You can do a whole Instagram
[01:14:09.360 --> 01:14:17.360]   feed of men waiting for their, their, their gals. Oh God. I'm so tired. I'm so bored.
[01:14:17.360 --> 01:14:22.560]   Oh no. The worst thing is that women are getting these great clothes. These men look horrible.
[01:14:22.560 --> 01:14:27.520]   Well, that's like, yeah, what's stopping you from living a better life?
[01:14:27.520 --> 01:14:33.280]   By the way, look at this guy. Not only is he relaxing, his belt is unbuckled.
[01:14:33.280 --> 01:14:37.440]   I don't think his fly is down. I don't think we can blame that on his wife's shop.
[01:14:37.440 --> 01:14:41.520]   That might be another, another matter entirely. So to get back to your point,
[01:14:41.520 --> 01:14:46.240]   Barrington, I think Amazon really, it's Amazon is about to eat the world in commerce, don't you think?
[01:14:46.240 --> 01:14:50.720]   They would love for every dollar you spend to pass through them, it seems.
[01:14:50.720 --> 01:14:54.640]   That's, that's what Ben Thompson said in Stratecary that Amazon,
[01:14:54.640 --> 01:14:59.200]   ostensibly Amazon's emission statement is to be the most customer-centric company in the world.
[01:14:59.200 --> 01:15:04.880]   Ben said, no, their, their, their, their mission statement is to get a piece of every economic
[01:15:04.880 --> 01:15:10.960]   transaction that occurs. Yeah. Yeah. And they make it so easy. They make it easy. I just got the,
[01:15:10.960 --> 01:15:17.200]   by the way, I am now convinced the best gadget of the year, the Echo Show.
[01:15:17.200 --> 01:15:20.480]   Oh, I hadn't gotten that yet. Is that the, is that the camera?
[01:15:20.480 --> 01:15:24.320]   No, that's not, that's the look. That's the one that ties into this Amazon prime wardrobe where
[01:15:24.320 --> 01:15:28.720]   it takes a picture of your clothes. And by the way, that's brilliant marketing. Yeah.
[01:15:28.720 --> 01:15:31.280]   What's the Echo Show? The Echo Show is the one with a screen.
[01:15:31.280 --> 01:15:36.160]   Oh, right. It's a screen camera, microphone. It's just, it's a regular Echo.
[01:15:36.160 --> 01:15:40.960]   It's a tablet, basically. But adding the screen, you can make video calls. My mom and I, we've been,
[01:15:40.960 --> 01:15:46.160]   I've been dropping in on my mom and that's really fun. You never know what you're going to see.
[01:15:48.560 --> 01:15:52.640]   No, no, she loves it. In fact, I woke her up from her nap the other day. I said, "Mom,
[01:15:52.640 --> 01:15:58.560]   mom," because you say drop in on mom's show or whatever you've named it. And then it makes a
[01:15:58.560 --> 01:16:04.080]   little bleep on her show and then you can talk to her. Mom? So yeah, she doesn't know she has to
[01:16:04.080 --> 01:16:09.440]   accept the calls. No, you don't have to. Yes, you can turn that feature off. She's decided to let
[01:16:09.440 --> 01:16:14.880]   me do scary. Yeah. But you don't have to have that turned off. One of my friends, so I, I had an
[01:16:14.880 --> 01:16:20.480]   Echo in my home. My girlfriend didn't like to visit when that thing was around. That's a reason
[01:16:20.480 --> 01:16:24.480]   to get rid of it. For some reason, didn't like the idea of a constantly listening microphone just
[01:16:24.480 --> 01:16:30.800]   on the table, under the TV. So it's in, it's at, it's at an office that I use. And a friend of mine
[01:16:30.800 --> 01:16:36.480]   called me just in the middle of the day. And the Echo was like, "You got a call." And so then I rang
[01:16:36.480 --> 01:16:41.280]   him. It's just, it's very strange. We've gotten so used to managing our communications, right? We
[01:16:41.280 --> 01:16:47.040]   want to, if someone calls, like they must be an emergency or someone died or there's been an attack,
[01:16:47.040 --> 01:16:52.640]   you text and you set these things up. So to just have a device that's not even a phone ring,
[01:16:52.640 --> 01:16:57.840]   and there's another person and they're in their living room and you're in your like conference
[01:16:57.840 --> 01:17:01.760]   room or living room, it's this, I don't know, it's kind of beautiful, kind of weird. I haven't
[01:17:01.760 --> 01:17:08.240]   decided how much the, am I creeped out by or am I kind of thrilled by the seren, the, the sort of
[01:17:08.240 --> 01:17:12.720]   spontaneity of just like, "Hey, let's ring up Zane in his living room." And he's like,
[01:17:12.720 --> 01:17:16.880]   dealing, his kids are running around, his parents in law are popping over and he's like,
[01:17:16.880 --> 01:17:21.200]   "Now is not a good time." I'm like, "You answered your echo, dude." So I don't know. Does the look
[01:17:21.200 --> 01:17:26.800]   have the same interruption but just with pictures? The show has the same, it's even worse because
[01:17:26.800 --> 01:17:31.840]   you have to pick up, it just starts. He gets to say who we can let have that happen. But,
[01:17:32.400 --> 01:17:39.920]   you know, because it's an intercom. So it's, but for anywhere in the world. For any other echo in the
[01:17:39.920 --> 01:17:48.080]   world. I can't wait. Drop in on Barretunde. That's the same. Barretunde, this is your conscience
[01:17:48.080 --> 01:17:53.520]   speaking. I could see that being a lot of, it's like the new party line, you could link up a,
[01:17:53.520 --> 01:17:58.960]   can you do more than, is it just one to one or can you build like a bridge and have four? Oh, yeah,
[01:17:58.960 --> 01:18:04.240]   that would be fun. No, as far as I know. Could you do house parties? Would that be cool?
[01:18:04.240 --> 01:18:08.560]   Listening parties or like virtual family reunions? Wouldn't that be cool? That's a great idea.
[01:18:08.560 --> 01:18:15.040]   My kids would kill me if I gave them one of these. My son did. Okay. So Michael has,
[01:18:15.040 --> 01:18:20.320]   I, so because of this, I put it, I replaced a black cylinder with this new echo show. So I put
[01:18:20.320 --> 01:18:26.480]   the black cylinder in Michael's room. And now I can, I can say to my echo, drop in on Michael.
[01:18:27.200 --> 01:18:30.960]   And then I said, Michael, wake up. Oh, did that once. It's now muted.
[01:18:30.960 --> 01:18:38.400]   That's right. I have to ask though. I mean, the looks of it though, it looks like something
[01:18:38.400 --> 01:18:44.400]   that was designed on a PlayStation one. It's that polygonal and blocky. I mean, I like it.
[01:18:44.400 --> 01:18:47.760]   A lot of people think it's ugly and I love it. It fits right on my desk.
[01:18:47.760 --> 01:18:54.240]   I can, I can do things like show my front door, show my backyard because it's got a screen now.
[01:18:55.360 --> 01:19:00.400]   Video calls, 230 bucks is one of the negatives. Get the white one. Then it doesn't look, I don't
[01:19:00.400 --> 01:19:04.480]   know. Here comes, here it comes. We're bringing it in. It's unplugged. So it won't do anything.
[01:19:04.480 --> 01:19:10.160]   We got it. It's kind of ugly. I don't know. It's like a router. So to see your backyard,
[01:19:10.160 --> 01:19:14.080]   you have to have a camera in your backyard. My mom wasn't sure about that. She said,
[01:19:14.080 --> 01:19:18.480]   Oh, can I see my backyard with this? I said, do you have a camera in your backyard? She said,
[01:19:18.480 --> 01:19:23.760]   no. I said, well, no, you need a camera. There has to be a Amazon camera. No, it could be any,
[01:19:23.760 --> 01:19:28.640]   so it works with Nest. It works with Ring. I can see the Ring video doorbell on my front door.
[01:19:28.640 --> 01:19:32.800]   I can see the Nest cameras in the house. Actually, that was another thing. My wife did Fido, the
[01:19:32.800 --> 01:19:39.040]   Nest. I had a Nest IQ cameras all over the house. And she said, no more IQ, no cameras in the house.
[01:19:39.040 --> 01:19:43.360]   So it's behind me. It's right over here. We put, oh no, up there. We put it back in my
[01:19:43.360 --> 01:19:47.280]   dog right now. I can, I can go call my dog. Yeah. So you can do it on your phone, right? Well,
[01:19:47.280 --> 01:19:51.840]   now you have this device. I just think it's like, this is going to replace the desk phone in offices
[01:19:51.840 --> 01:19:56.160]   all over the country. And so I don't think that that's, do you think that's horrible that you
[01:19:56.160 --> 01:19:59.840]   wouldn't want that on your desk? It's just, I think it looks a lot better in white. It looks a lot
[01:19:59.840 --> 01:20:02.880]   better in white. Yeah, don't get the black one. I would consider that. You can't call a landline
[01:20:02.880 --> 01:20:06.640]   or a cell phone. You have to call another act. No, although I have to think they're working on
[01:20:06.640 --> 01:20:09.760]   that because Google isn't going to do that. Google's going to do that. And it's just IP,
[01:20:09.760 --> 01:20:13.840]   everything's IP now anyway. So it shouldn't matter. Our friend Mike Elgin, who'll be on the show
[01:20:13.840 --> 01:20:18.400]   next week wrote a really good article in which he said, just in the same way that the cable
[01:20:18.400 --> 01:20:23.040]   companies are going from being television companies to internet companies, that's going to happen to
[01:20:23.040 --> 01:20:29.040]   the phone companies too. It's all about data. Why do you need a phone company? It's just data.
[01:20:29.040 --> 01:20:32.160]   Yeah, it's just data company. So phone companies, just like cable companies,
[01:20:32.160 --> 01:20:36.080]   had to face this reality that we're now going to become an internet service provider. That's our
[01:20:36.080 --> 01:20:45.120]   new business. Well, AT&T. AT&T Verizon, Sprint and T-Mobile. That's ultimately all they'll be is data
[01:20:45.120 --> 01:20:49.120]   companies. I'm sure they're thinking that with 5G and so forth. Remember when you used to have to
[01:20:49.120 --> 01:20:53.600]   pay for phone calls on your cell phone you paid by the minute? They give away phones, they give away
[01:20:53.600 --> 01:20:57.280]   text. They charge for data. Right. It's all about the data. It's all about the data.
[01:20:57.280 --> 01:21:04.080]   As you point out, Bert, how is this or Google Home, how is it different from a phone? It's not.
[01:21:04.080 --> 01:21:10.720]   It's all data. Yeah, it's a connected IP device. You can do anything you want on that connection.
[01:21:10.720 --> 01:21:17.040]   And better, frankly. Except out of the caviar phone still wins out in my book.
[01:21:17.040 --> 01:21:23.920]   There's a good reason how to phone caviar phone. I love you. I love you. You have the phone calls
[01:21:23.920 --> 01:21:31.360]   you. Yeah. Yeah. Echo calls you. If only you could actually hear what the two of them said to
[01:21:31.360 --> 01:21:35.760]   each other on that phone. Right. If you could actually get a read out or how you could do that.
[01:21:35.760 --> 01:21:40.880]   I don't know. Amazon Prime is on pace to become more popular than cable TV. What a surprise.
[01:21:40.880 --> 01:21:47.440]   You know, their video is getting better and better. I actually am finding myself watching
[01:21:47.440 --> 01:21:54.960]   Prime video more than I used to. Here's the graph. This is for recode. This is the top bar
[01:21:54.960 --> 01:22:02.320]   pay TV households, which was flat until 2014. And then oddly started to plummet as people started
[01:22:02.320 --> 01:22:07.360]   to cut the cable, cut the cord. Here is Amazon Prime households. Now this is an estimate because
[01:22:07.360 --> 01:22:14.240]   Amazon doesn't give the number. But it's just a matter of maybe a year before those two lines
[01:22:14.240 --> 01:22:20.400]   crosses. When we think about what? Think about the dollars behind each of those curves. So the
[01:22:20.400 --> 01:22:26.240]   cable household is paying, I don't know, an average of 120 a month or something, maybe for cable.
[01:22:26.720 --> 01:22:32.800]   And the opportunity to extract more money from them is limited by just what that cable company
[01:22:32.800 --> 01:22:38.080]   offers. Maybe an occasional pay per view fight. Maybe you get someone upgrade their package.
[01:22:38.080 --> 01:22:44.560]   Maybe you add phone service or internet service. But they're the step functions. There's not a lot of
[01:22:44.560 --> 01:22:50.160]   micro purchasing or incremental kind of revenue being added. Whereas Amazon Prime, which is what
[01:22:50.160 --> 01:22:56.640]   a hundred bucks a year. And then the purpose of Prime is to get you to spend more dollars. The
[01:22:56.640 --> 01:23:04.240]   more you get out of that. The return on that hundred is way higher to Amazon than a return
[01:23:04.240 --> 01:23:10.160]   on the hundred that goes to a Comcast or a charter or whoever. And they're already winning.
[01:23:10.160 --> 01:23:14.720]   And if you just think about how much money they're sucking out of the houses that are Prime members
[01:23:14.720 --> 01:23:19.600]   versus how much money a cable company is sucking out of houses who are subscribers to the MSL.
[01:23:19.600 --> 01:23:24.400]   And this ties back to the echo because the echo really is just a device for ordering stuff on Amazon.
[01:23:24.400 --> 01:23:28.320]   Prime, real estate. These are Trojan horses, Prime is a Trojan horse that take your money.
[01:23:28.320 --> 01:23:35.440]   Interesting because Jeff Bezos has trained millions of people to say the word ALEXA hundreds of times
[01:23:35.440 --> 01:23:41.680]   or dozens of times a day. That's a brand. That is a brand. No, I won't say it. Every echo.
[01:23:41.680 --> 01:23:47.440]   I say echo all the time because I don't want to say the A word. But think about that. That
[01:23:47.440 --> 01:23:52.480]   is a powerful brand name he's created just by repetition. I don't I imagine they'll use that
[01:23:52.480 --> 01:23:59.120]   in some interesting way. This guy it's hard to imagine. I mean this guy is you know another another
[01:23:59.120 --> 01:24:07.440]   Tony Stark. Yeah. And just to be clear with with that Prime numbers and I want to so you pay 99
[01:24:07.440 --> 01:24:12.160]   for Prime you get like expedited shipping on other stuff you buy from Amazon. You also get
[01:24:12.160 --> 01:24:19.040]   their video service and music. You also get music. You get books. Maybe storage now I think it's
[01:24:19.040 --> 01:24:24.640]   thrown in actually for Prime users. Photo storage unlimited. And you get discounts on all kinds of
[01:24:24.640 --> 01:24:32.480]   other stuff in Amazon. So it's not like a video versus video service. It's like how do I take your
[01:24:32.480 --> 01:24:36.160]   money versus how do I take your money. What you do is you get in the habit of using Amazon for
[01:24:36.160 --> 01:24:41.280]   every purchase and not even shopping around. Right. Which makes them the one company. Right. The one
[01:24:41.280 --> 01:24:48.320]   retailer to rule them all. I did analysis. So one year I had to pay sales tax back before Amazon
[01:24:48.320 --> 01:24:53.360]   charged California sales tax. I had to actually estimate how much I had spent on Amazon. So I went
[01:24:53.360 --> 01:24:58.800]   online. I looked for years of orders and I was shocked at how much money I had spent that year.
[01:24:58.800 --> 01:25:02.640]   And there's no way there's no merchant in the world except maybe the Toyota dealer that I bought
[01:25:02.640 --> 01:25:07.760]   my car from. And then the other few years right that I spent anywhere near that amount of money.
[01:25:08.400 --> 01:25:12.640]   You know, one company. It's incredible. Get ready. You want some more numbers?
[01:25:12.640 --> 01:25:16.560]   Here's some more numbers. Go ahead. Yeah. No, yeah. I was just going to say like,
[01:25:16.560 --> 01:25:22.000]   don't you think though, Amazon, like I have cut the cord on everything. I don't own a phone like
[01:25:22.000 --> 01:25:28.960]   a traditional phone. Don't you think Amazon as far as their video service is the worst out there
[01:25:28.960 --> 01:25:33.680]   of any of them? Because there's now where's town? You don't. I mean, like I love show tour.
[01:25:33.680 --> 01:25:38.240]   I think that's really worth the money. Yeah. Go ahead. Quality or content. Where's town?
[01:25:38.240 --> 01:25:43.760]   Yeah. The quality of the original content. Like they had an exclusive deal to get 24 on there.
[01:25:43.760 --> 01:25:49.200]   And I really like that. But it's like, I just if I weren't already subscribing to it because of
[01:25:49.200 --> 01:25:54.000]   free shipping and stuff like that, I just I would never do it because I don't think the original
[01:25:54.000 --> 01:25:58.640]   content is there. I think this is the winner in original content. But I have to say, there are
[01:25:58.640 --> 01:26:04.320]   some really good show. I mean, transparent. Yeah, transparent is probably their break for in my
[01:26:04.320 --> 01:26:10.480]   own video usage. Transparent is kind of why I get excited about Amazon. I feel like they also had
[01:26:10.480 --> 01:26:16.640]   the man in the high castle. Yeah, that was okay. That's all. And then I use them for they let you
[01:26:16.640 --> 01:26:23.360]   add on stars. And I'm in love with the show called power. And I go to them for that. And then occasionally,
[01:26:23.360 --> 01:26:29.200]   I'll just see what they have that comes with Prime. So I don't have to pay for it on another.
[01:26:29.200 --> 01:26:35.440]   But you're right. A lot of the lot of the TV shows are not quite up to the Netflix or HBO standard.
[01:26:35.440 --> 01:26:42.880]   I know. I just been watching. I love Dick. Yeah, I don't know. I'm not sure that's I'm not sure
[01:26:42.880 --> 01:26:48.640]   that's for me. But you know what? The other thing Amazon's doing is is movies. And remember,
[01:26:48.640 --> 01:26:52.480]   they Manchester by the sea, they they put up the money for that. I think they've got a.
[01:26:52.480 --> 01:26:55.440]   Oh, right. A couple of new movies. That's kind of interesting.
[01:26:55.440 --> 01:27:01.920]   I don't know. I actually think that Amazon has got some pretty decent programming,
[01:27:01.920 --> 01:27:05.680]   not everything. But I think they've got some good. I loved alpha alpha house when it was on the
[01:27:05.680 --> 01:27:11.120]   year that was. Oh, yeah. That was John. You have to watch that before you go to Washington.
[01:27:11.120 --> 01:27:14.800]   Yeah. Yeah. Where are you going to share a house with John Goodman when you move up there,
[01:27:14.800 --> 01:27:20.640]   bro? Everybody. Everybody. That'd be great. That'd be great. Oh my God.
[01:27:20.640 --> 01:27:23.760]   Apparently, I didn't know this, but I learned that from the show that a lot of members of
[01:27:23.760 --> 01:27:27.280]   Congress can't have don't want to buy houses in Washington or can't afford to rent them a
[01:27:27.280 --> 01:27:32.000]   Chuck Schumer. So they all live together. And there was a liberal house. There was a
[01:27:32.000 --> 01:27:35.680]   Democrat. Yeah. Chuck Schumer had to have to live in a house with this guy. But the funny thing
[01:27:35.680 --> 01:27:38.720]   about the show is it's a Republican house, right? Right. And the show they're a whole
[01:27:38.720 --> 01:27:42.400]   good house. Yeah. All conservatives. Yeah. That sounds like a great reality show.
[01:27:42.400 --> 01:27:46.960]   No, it's very funny. It does. Yeah. They could. They could. You can watch Michael Moore's Where to
[01:27:46.960 --> 01:27:53.520]   Invade Next on Amazon Prime. There's a lot of free movies and stuff. It's not Netflix.
[01:27:53.520 --> 01:27:57.200]   But that doesn't have to be. That's a small portion of what Amazon Prime is about. I mean,
[01:27:57.200 --> 01:28:00.960]   really, mostly it's about two day free shipping. Exactly. Yeah. Anyway, I was going to give you
[01:28:00.960 --> 01:28:07.600]   some numbers at Amazon Prime. So as you might predict, Amazon Prime doesn't do all that well in
[01:28:07.600 --> 01:28:14.080]   lower income people. It's the lowest among households that make less than 41,000 a year. But in
[01:28:14.080 --> 01:28:19.120]   households, it makes more than 112,000 a year. Presumably very valuable households to Amazon.
[01:28:19.120 --> 01:28:28.400]   82% are Amazon Prime. That's incredible. That's incredible. 82%. Wow. It's like, it's how you know
[01:28:28.400 --> 01:28:32.880]   you have money. Yeah. Well, you don't have Prime, obviously.
[01:28:32.880 --> 01:28:40.640]   But what that shows you, if you're thinking about Amazon's business, and I know Jeff Bezos
[01:28:40.640 --> 01:28:44.960]   doesn't spend a waking moment not thinking about the business, is there all the growth is going to
[01:28:44.960 --> 01:28:50.320]   happen at the other end? And isn't it, isn't Amazon now in a war versus Walmart? Walmart. Yeah.
[01:28:50.320 --> 01:28:55.600]   They bought you. Yeah. Walmart. Yeah. Walmart bought you. Yeah. Yeah. Yeah. Yeah. Yeah. Somebody had to.
[01:28:55.600 --> 01:28:59.280]   Amazon bought Whole Foods. That'll tell you. Exactly.
[01:28:59.280 --> 01:29:07.120]   But so this article is presuming that at some point Amazon's going to reach out in some way
[01:29:08.320 --> 01:29:13.280]   too, because there's no growth. There's very little growth possible in the in the upper income.
[01:29:13.280 --> 01:29:19.280]   Well, there will be after they get their tax cuts. A lot more of us than the one presents.
[01:29:19.280 --> 01:29:26.240]   Anyway, I thought that it's clearly a success. Amazon is on a tear. Are they going to lower the
[01:29:26.240 --> 01:29:33.360]   price of that Whole Foods? That would be great. Look at that. There you go. NPR, Amazon lowers
[01:29:33.360 --> 01:29:37.920]   prime membership rate for low income customers. Right. I think so. They're already doing it.
[01:29:37.920 --> 01:29:40.320]   How do you prove your low income? What are they?
[01:29:40.320 --> 01:29:48.320]   So I have to give Amazon my tax returns every year. Really? I don't know. Prime Day. Prime Day.
[01:29:48.320 --> 01:29:54.480]   Are you excited? Prime Day is receiving government assistance. Prime Day starts tomorrow at 6 p.m.
[01:29:54.480 --> 01:29:59.360]   Civic. Yeah. I don't, I have never participated in Prime Day. This is the third one. But this is
[01:29:59.360 --> 01:30:04.160]   again brilliant. Is this like their own Black Friday? Yeah. Yeah. Yeah. Yeah.
[01:30:04.160 --> 01:30:10.000]   And be careful, by the way, there are a lot of deals that are not great on Prime Day. I actually
[01:30:10.000 --> 01:30:16.080]   look last year and I chop critically when you're doing it. If you do it. You know, it does a really
[01:30:16.080 --> 01:30:22.000]   good roundup is Jackie over at Wirecutter, which was just a fire by the Times. They always kind of
[01:30:22.000 --> 01:30:27.520]   suck out and find out the ones that are good. So that's where I go by. Here you go. Amazon Prime
[01:30:27.520 --> 01:30:34.960]   Day 2017. What to expect and how to find the best deals? Adam Burakowski writing this one
[01:30:34.960 --> 01:30:40.080]   for the Wirecutter. I literally spent time on that site. This is one of my favorite sites on the
[01:30:40.080 --> 01:30:46.800]   internet and they have a home section now. And I think I just read everything. I just like I skimmed
[01:30:46.800 --> 01:30:53.760]   over. Maybe I need emergency solar powered flashlights with the FMF radios. There's choices and they
[01:30:53.760 --> 01:30:58.640]   write so well about it that it made me like respect. I should probably consider one of those things.
[01:30:58.640 --> 01:31:03.440]   So the Wirecutters, my new kind of inter-diction. I learned a lesson about discount shopping. I
[01:31:03.440 --> 01:31:07.440]   have never actually gone to the Goodwill in Palo Alto. I go there all the time to donate, but this
[01:31:07.440 --> 01:31:11.680]   time I actually went shopping there. And it turned out that there were several items I looked at
[01:31:11.680 --> 01:31:16.880]   and I went online to check them. New versions of them were cheaper on Amazon than the used ones
[01:31:16.880 --> 01:31:22.960]   where I'd good will. Tell the have to be a critical shopper. Here's the tally from Wirecutter from
[01:31:22.960 --> 01:31:35.600]   last year's Prime Day. Of 7,950 deals, only 64 were good deals. So basically it's a big lie.
[01:31:35.600 --> 01:31:42.720]   It's a lie. Like percentage wise speaking, it rounds up to a 100% BS. Prime Day is 100%.
[01:31:42.720 --> 01:31:46.320]   It's like shopping at Costco. You assume everything is cheap, but it isn't. You have to look.
[01:31:46.320 --> 01:31:49.920]   Right. Yeah. Well, that's what our economy is built on, folks. Okay, great.
[01:31:49.920 --> 01:31:55.760]   Wise, wise and more lies. All right, let's take a break. Baratunde Thurston is here. It's always
[01:31:55.760 --> 01:32:03.760]   great to have you look for his new regular column on medium. You could just use my credit card number
[01:32:03.760 --> 01:32:11.520]   sign up. Thank you for the subsidy. Thank you. Yeah. The first 100 people use my credit card number
[01:32:11.520 --> 01:32:20.000]   you're in and the rest of you will. You snooze, you lose. That's Brianna Wu. I, you know what,
[01:32:20.000 --> 01:32:24.240]   I should give you a little contribution too. Let's just pretend this is one of your phone
[01:32:24.240 --> 01:32:30.000]   days and we should, can I contribute at Brianna Wu 2018.com? Because I sure like to.
[01:32:30.000 --> 01:32:35.760]   You can go to support Brianna.com and it's all right there. And yeah, I super appreciate it.
[01:32:35.760 --> 01:32:40.560]   The thing is it's not enough to tweet about this. It's not enough to Facebook about it.
[01:32:40.560 --> 01:32:44.960]   We've got to take action. So pick one of three things, like either run for office,
[01:32:44.960 --> 01:32:50.800]   either donate time to somebody that's doing things you like or donate money to somebody that's doing
[01:32:50.800 --> 01:32:55.920]   things you like. We can't just talk about this. We've got to take action. And you do not have to
[01:32:55.920 --> 01:33:01.920]   be a resident of the Massachusetts 8th district to donate to the campaign. But unless you have to
[01:33:01.920 --> 01:33:10.480]   vote for Brianna, when is, when is the primary? It's next year. They haven't had it set yet because
[01:33:10.480 --> 01:33:15.360]   a guy I'm going running against doesn't usually have challengers. He's just automatically voted in.
[01:33:15.360 --> 01:33:21.520]   So what we need to have a primary. What? He's got the auto update feature on. Yeah.
[01:33:22.240 --> 01:33:25.680]   Audio elects are millions of people coming down from Canada to vote for you.
[01:33:25.680 --> 01:33:32.240]   Is that going to happen? I can't adore. Yeah. Now, Brianna is not encouraging that.
[01:33:32.240 --> 01:33:38.080]   No, I know. But you may donate. No, I would appreciate that. I promise you, like I am going to,
[01:33:38.080 --> 01:33:45.040]   I will have the EFF on speed dial. Like I will really turn a lot of these policies around. And
[01:33:45.040 --> 01:33:51.520]   just something I have to tell people, this isn't like a boil the ocean solution. There are only eight
[01:33:51.520 --> 01:33:55.440]   people to control the votes in the science and technology subcommittee.
[01:33:55.440 --> 01:34:00.320]   Getting eight people that know what they're talking about is not an insurmountable goal.
[01:34:00.320 --> 01:34:05.920]   So, you know, if your congressperson sucks, like consider running for office yourself and serve
[01:34:05.920 --> 01:34:10.960]   on that committee with me, it'll be great. We'll have a good time. And I see that this donation
[01:34:10.960 --> 01:34:17.520]   page has something called fast action. This is, is this something that let's makes it easy for you to
[01:34:18.640 --> 01:34:23.520]   participate and donate to other members of congress or? I would assume so.
[01:34:23.520 --> 01:34:27.280]   Oh, you don't know. It's going to link to other lists. Yeah, I've never donated to myself through
[01:34:27.280 --> 01:34:33.440]   that. So that would be dumb. Maybe you should. Yeah. Maybe I should. You got to walk yourself
[01:34:33.440 --> 01:34:38.400]   through the user path, you know? Yeah. That's right. That's right. Just a buck. That's all it takes.
[01:34:38.400 --> 01:34:44.240]   Also, Larry Maggot is here. And Larry is, of course, at his own website, Larry Maggot.
[01:34:44.240 --> 01:34:45.840]   Well, Larrythworld.com. Larry's world.com.
[01:34:45.840 --> 01:34:52.560]   And then connect safely and .org and safekids.com. Well, you got something coming up. Why don't you
[01:34:52.560 --> 01:34:56.960]   use your chance to plug that? Oh, well, it's not always coming. I mean, the... Well, you said you
[01:34:56.960 --> 01:35:02.320]   wanted to mention something. Well, you know, I just... So we've all heard about Donald Trump's
[01:35:02.320 --> 01:35:07.680]   cyberbullying. Everybody here has heard about... I'm looking at my... If you're there, yes.
[01:35:07.680 --> 01:35:12.080]   If you're me, yes, yes. Yeah. And, you know, and the fact that I think that whatever you think of
[01:35:12.080 --> 01:35:15.360]   Donald Trump, but I bet you there are people in our audience who like him. A great many.
[01:35:15.360 --> 01:35:18.720]   For his policies. Yeah. And that's a legitimate thing to be.
[01:35:18.720 --> 01:35:22.000]   But that doesn't mean you have to support his behavior. And so the point of this article and
[01:35:22.000 --> 01:35:28.640]   podcast is to examine what happened if you are a Trump supporter. You admire his policies, but you
[01:35:28.640 --> 01:35:33.520]   do not admire his the way in which he treats women, the way in which he demeaned his opponents
[01:35:33.520 --> 01:35:37.840]   during the campaign. How do you talk to your children? How do you explain that the most powerful
[01:35:37.840 --> 01:35:43.120]   person in the world who our family may have voted for is acting badly and we don't want you to
[01:35:43.120 --> 01:35:47.840]   act that way? So I sort of explored that with some of the leading experts on cyberbullying in the
[01:35:47.840 --> 01:35:52.400]   world. People like Hadi Agudstin, who's the head of the cyberbullying, international bullying
[01:35:52.400 --> 01:35:57.040]   prevention association. And Justin Patchin, who runs the cyberbullying research center,
[01:35:57.040 --> 01:36:03.040]   and Rosalind Wyzman, who wrote the book that was the basis for the movie Mean Girls. And really
[01:36:03.040 --> 01:36:08.720]   exploring how you talk to your children. And it's kind of a fascinating set of advice that shows up
[01:36:08.720 --> 01:36:16.080]   in both the column and in the podcast that you can separate out his behavior from his policies.
[01:36:16.080 --> 01:36:20.160]   And I mean, I know a lot of people don't agree with his policies and that's fine too. And I also
[01:36:20.160 --> 01:36:26.640]   make the point that liberals have to be careful not to fall into the same trap. So I was a guest
[01:36:26.640 --> 01:36:33.040]   that's many of my Facebook friends made fun of Chris Christie last week for being on the beach.
[01:36:33.040 --> 01:36:37.440]   And they were absolutely right to criticize the fact that he was on a public beach that was closed
[01:36:37.440 --> 01:36:42.240]   to the rest of the state. But then they started with fat shaming and fat jokes. And I think that
[01:36:42.240 --> 01:36:47.760]   that is very annoying. You can criticize Christie. You can criticize Trump. You can criticize anybody
[01:36:47.760 --> 01:36:53.200]   but stick to the issues and not start demeaning them as human beings and their physical characteristics.
[01:36:53.200 --> 01:36:58.560]   So that's kind of some of the things that I think we need a more civil society regardless of
[01:36:58.560 --> 01:37:03.920]   the political realm which probably needs to be shaken up as well. But I say, Brianna, when you
[01:37:03.920 --> 01:37:07.760]   get to Congress, treat everybody nicely, even your opponents. There were some.
[01:37:07.760 --> 01:37:14.480]   I try to. One of the beautiful things about running is I talk to Trump supporters every single day
[01:37:14.480 --> 01:37:21.360]   when I do campaign events. And it's really, you see them as people, right? You hear about why
[01:37:21.360 --> 01:37:26.880]   they voted that way and I don't agree with it. But there's a real economic desperation there
[01:37:26.880 --> 01:37:33.200]   that I understand. So I think you're that on and it makes me really uncomfortable when even,
[01:37:33.200 --> 01:37:38.560]   you know, I'm a feminist when feminists start attacking men for their physical characteristics.
[01:37:38.560 --> 01:37:43.680]   I'm deeply uncomfortable with that. So I completely agree with everything you said.
[01:37:43.680 --> 01:37:48.720]   There are some fine, Chris Christie memes out there that don't entirely.
[01:37:48.720 --> 01:37:52.480]   That's one. Yeah.
[01:37:52.480 --> 01:37:55.840]   It's led you to criticize. You know, that's one.
[01:37:55.840 --> 01:38:00.400]   So a couple of quick notes Brianna, I just gave you some money. Please pay it wisely.
[01:38:00.400 --> 01:38:01.760]   Oh, thank you. Thank you.
[01:38:01.760 --> 01:38:07.840]   And Larry, you have experts on cyberbullying on when can we expect Melania Trump to join you?
[01:38:07.840 --> 01:38:09.920]   I said here a letter. So I wrote a column.
[01:38:09.920 --> 01:38:16.720]   That is her. I read her a column right after the inauguration saying help and I gave her some
[01:38:16.720 --> 01:38:22.000]   advice. And then I mailed her a copy of Cadet Safele's parents guide to cyberbullying.
[01:38:22.000 --> 01:38:26.160]   We don't have a spouses guide to cyberbullying, but we have a parents guide and she's a parent.
[01:38:26.160 --> 01:38:28.400]   And you know, she never got back to me, not even a force.
[01:38:28.400 --> 01:38:29.040]   He's busy.
[01:38:29.040 --> 01:38:32.960]   So she just responded. Yeah, she's probably very busy, you know,
[01:38:32.960 --> 01:38:34.640]   got implementing her own policy.
[01:38:34.640 --> 01:38:36.720]   She needs some advice. I'm happy to give it to her.
[01:38:36.720 --> 01:38:37.360]   So that's great.
[01:38:37.360 --> 01:38:42.400]   Amazing. Let's take a break. I showed you today, brought to you by those good folks at
[01:38:42.400 --> 01:38:49.520]   rockets mortgage. Rocket mortgages was created by quick and loans, one of the foremost high tech
[01:38:49.520 --> 01:38:54.240]   companies in America and the very and one of the biggest mortgage loaners.
[01:38:54.240 --> 01:39:00.400]   They realized that the mortgage loan process wasn't exactly keeping up with the times.
[01:39:00.400 --> 01:39:04.640]   It was dated. It wasn't exactly client focused.
[01:39:04.640 --> 01:39:10.400]   So the technological revolution has come to getting your next home loan or your next
[01:39:10.400 --> 01:39:14.880]   refi and it's thanks to quick and loans and something they call rocket mortgage. Rocket
[01:39:14.880 --> 01:39:20.640]   mortgage is an entirely online mortgage approval process. You don't need to go into a bank.
[01:39:20.640 --> 01:39:27.040]   You don't need to gather documents from the basement of the attic. You don't need all of
[01:39:27.040 --> 01:39:32.080]   this can be done on your phone, on your tablet, on your computer, giving you all the information
[01:39:32.080 --> 01:39:36.240]   you need about your loan, all the details. So you can get confident that you're getting the right
[01:39:36.240 --> 01:39:41.680]   mortgage for you and you could choose your term, choose your rate. And it makes it really easy
[01:39:41.680 --> 01:39:46.320]   because they have all these trusted partners, which makes it possible to share your financial
[01:39:46.320 --> 01:39:52.160]   information without getting up and going through the paperwork. You can do it all with the touch
[01:39:52.160 --> 01:39:56.640]   of a button. So whether you're buying your first home or your tenth, whether you're refying your
[01:39:56.640 --> 01:40:01.840]   existing home rocket mortgage, can do it for you. And because it's all online, they do it for you
[01:40:01.840 --> 01:40:07.600]   fast. Last mortgage took a couple of months for me when we bought our house almost four years ago.
[01:40:07.600 --> 01:40:13.280]   In fact, we went on vacation. We applied for the loan. We thought, well, we can't possibly still
[01:40:13.280 --> 01:40:18.000]   be doing this in a month. We almost lost the house because the seller said, what's going on?
[01:40:18.000 --> 01:40:23.360]   And they said, and we were faxing stuff from vacation, not this way. You'll get your loan
[01:40:23.360 --> 01:40:27.680]   not in months, not in days, not in minutes, not in weeks, but in minutes right away.
[01:40:28.640 --> 01:40:32.720]   Based on your income assets and credits, they're going to analyze all the options like that and
[01:40:32.720 --> 01:40:37.760]   get the right loan for you. Rocket mortgage from quick and loans apply simply. Understand fully
[01:40:37.760 --> 01:40:43.760]   mortgage confidently. Please go to rocket mortgage dot com slash twit to that's rocket mortgage dot
[01:40:43.760 --> 01:40:48.160]   com twit and the number two. That way they'll know you heard it here. Equal housing lender licensed
[01:40:48.160 --> 01:40:53.440]   in all 50 states and MLS consumer access dot org number 30 30. And we thank rocket mortgage and
[01:40:53.440 --> 01:41:02.320]   quick and loans for supporting this week in tech. I love this panel. I think you guys
[01:41:02.320 --> 01:41:09.600]   move in and we'll just we'll just stay here for the whole next five years or whatever.
[01:41:09.600 --> 01:41:13.520]   No, because Brianna, you probably, you know, we won't be able to have you on it. Well,
[01:41:13.520 --> 01:41:16.240]   man, I think we could have you on when you're a member of Congress. Why not?
[01:41:16.240 --> 01:41:22.320]   Yeah, there's no law against it. So you never had an elected official on twit, Leo.
[01:41:22.320 --> 01:41:28.000]   Yeah, we have from time to time. There was a guy running for Lieutenant Governor of California
[01:41:28.000 --> 01:41:35.680]   didn't realize to it was just this podcast thing who stopped by and time we get people confused about,
[01:41:35.680 --> 01:41:41.040]   you know, whether they can use this to garner votes. But yeah, I and I have to say,
[01:41:41.040 --> 01:41:46.960]   I think it's important to get politicians on talking to audiences that are interested in
[01:41:47.520 --> 01:41:52.080]   technology. Absolutely. Just unleash unleash the chatroom on them. I don't
[01:41:52.080 --> 01:41:55.360]   be a great education. You know, the funny thing is, so I'm going to check right. I've been a
[01:41:55.360 --> 01:41:59.760]   tech writer, as you know, Leo, for more than 30 years. And when I first started, I remember
[01:41:59.760 --> 01:42:02.800]   telling somebody I've got good news and bad news is what's the good news? Good news. I just got
[01:42:02.800 --> 01:42:07.840]   a column in the LA Times back when newspapers, well, really mattered. And they matter again.
[01:42:07.840 --> 01:42:12.480]   Yeah. Yeah. It was the bad news that I got to write about computers. And it has become so much
[01:42:12.480 --> 01:42:18.720]   fun the last few years now that technology and policy are so connected that we're no longer
[01:42:18.720 --> 01:42:23.040]   just talking about gadgets. We're talking about things that really, I'm not the gadgets don't matter,
[01:42:23.040 --> 01:42:26.960]   but we're talking about things that really matter to people. And that's why I think,
[01:42:26.960 --> 01:42:33.040]   Brianna, your candidacy is so important. The fact that there really is a nexus between
[01:42:33.040 --> 01:42:38.480]   technology and how our lives are going to go forward. And it's a time for government to pay
[01:42:38.480 --> 01:42:45.760]   attention to it. And it's just so, I don't know, it's amazing to me how much time we spent today
[01:42:45.760 --> 01:42:52.880]   talking about policy and how much I wind up writing about it. Yeah, no, it's great. I just want to say
[01:42:52.880 --> 01:42:59.520]   I can 100% endorse any politician coming on this show. I've had actually, your listeners have reached
[01:42:59.520 --> 01:43:06.240]   out to me about various levels of policy. And I've been able to like show them legislation we're
[01:43:06.240 --> 01:43:11.280]   thinking about. And they've given input on it because of their expertise in cyber security or
[01:43:11.280 --> 01:43:17.280]   different areas. It's gotten to be better because of that. I mean, you have an amazing audience. So
[01:43:17.280 --> 01:43:21.280]   it's for me as a politician, it's well worth my time to come here. That's encouraging to me.
[01:43:21.280 --> 01:43:28.640]   Because I think there was for a while in amongst tech fans, this kind of, it was kind of fashionable
[01:43:28.640 --> 01:43:33.840]   to say, Oh, government doesn't work, forget it, they'll never understand. They're just dummies.
[01:43:34.640 --> 01:43:37.840]   I'm not going to vote. I'm not going to participate because it's meaningless.
[01:43:37.840 --> 01:43:43.520]   And that makes me sad because I tell you what, if you don't, then you don't get to complain.
[01:43:43.520 --> 01:43:50.240]   So I'm really glad to hear that people who watch this show are contacting you and are getting involved.
[01:43:50.240 --> 01:43:54.560]   Although I'm not getting any help from some readers and listeners who get angry at me when I get into
[01:43:54.560 --> 01:43:58.560]   political. You get that too. And I know that's fine. I understand that.
[01:44:00.480 --> 01:44:04.160]   You know, I think sometimes talking about these hot button topics, you're going to get that.
[01:44:04.160 --> 01:44:08.800]   Yeah. And I think that shouldn't deter us from talking about them. Not to the exclusion of the
[01:44:08.800 --> 01:44:15.920]   Samsung Note 7 returning or the Bixby button. Anybody want to talk about a gadget? Any gadget?
[01:44:15.920 --> 01:44:20.160]   I'll take any. Actually, let's as long as we're talking, we should talk about July 12th,
[01:44:20.160 --> 01:44:27.280]   which is a day of protest. A day that you live in infamy. We've done this before, right?
[01:44:27.280 --> 01:44:31.920]   Bertuna, you've been involved in previous boycotts and internet activism.
[01:44:31.920 --> 01:44:37.200]   Put this black badge on your site. It's a black arm band for internet thing.
[01:44:37.200 --> 01:44:44.160]   This is about net neutrality. And we have a new FCC commissioner, Ajit Pai, who is against some
[01:44:44.160 --> 01:44:51.440]   of the rules established back in 2015 that would make sure that the internet remained a relatively
[01:44:51.440 --> 01:44:57.280]   fair place as far as treating a bit like a bit like a bit. So the FCC doesn't have to listen to
[01:44:57.280 --> 01:45:02.880]   anybody. They have the votes to go which way the commissioner wants, but a strong public showing
[01:45:02.880 --> 01:45:11.520]   by people and many companies have signed on, including Google and Facebook, to say we prefer
[01:45:11.520 --> 01:45:17.200]   a fair internet to one that can be totally bought and sold to the extent that you have
[01:45:17.920 --> 01:45:24.720]   preferential treatment, priority access, and create this minimum two-tiered internet of the fast lane
[01:45:24.720 --> 01:45:32.160]   and then the crap lane. So, yeah. So can we go to this well too often? Because remember we did
[01:45:32.160 --> 01:45:38.560]   this a couple of years ago for SOPA. There was internet freedom day. It seems like we've done
[01:45:38.560 --> 01:45:45.440]   this a few times. It's been successful. In fact, the whole issue of net neutrality probably wouldn't
[01:45:45.440 --> 01:45:53.360]   even exist if the previous chairman of the FCC, Tom Wheeler, hadn't been slammed by millions of
[01:45:53.360 --> 01:46:00.560]   comments telling him he should use title two and assert the right of the FCC to enforce net neutrality.
[01:46:00.560 --> 01:46:07.040]   That's what's at stake today. It's a reversal of that existing FCC policy to support net neutrality.
[01:46:07.040 --> 01:46:12.160]   And the comments begin once again. Now, there was the history of this is a little checker.
[01:46:13.360 --> 01:46:18.880]   Remember, they opened for comments and then it was slammed by people commenting and then they said,
[01:46:18.880 --> 01:46:23.760]   oh, this is a DDoS attack and they shut the comments down, never offering the FCC. I never
[01:46:23.760 --> 01:46:27.680]   offered any evidence that it was in fact a DDoS attack. The DDoS was a lot of people having an
[01:46:27.680 --> 01:46:32.400]   opinion about it. Didn't John Oliver have something to do with this? John Oliver created a website,
[01:46:32.400 --> 01:46:40.000]   something the FCC, screw the FCC, F the FCC, something like that. So, I guess
[01:46:42.480 --> 01:46:47.920]   July 12 is the Internet wide day of action to save net neutrality. A lot of companies,
[01:46:47.920 --> 01:46:53.280]   even Netflix, which for a while said, oh, we don't need to net neutrality anymore. We already won.
[01:46:53.280 --> 01:46:58.240]   One thing is interesting is I actually interviewed Evan Greer, who's kind of the
[01:46:58.240 --> 01:47:03.440]   spokesperson for this campaign. And she was saying that a lot of companies are not going to go dark.
[01:47:03.440 --> 01:47:07.200]   They're just going to encourage you to take some action. Yeah, we on the soap.
[01:47:07.200 --> 01:47:11.760]   Soap a day we thought about going dark, Reddit went dark. A lot of sites went dark.
[01:47:11.760 --> 01:47:18.640]   We went black and white because monochrome. And I think that that was my decision to do that
[01:47:18.640 --> 01:47:23.200]   was more because I felt we needed to cover the day. And we needed to talk about it on that day.
[01:47:23.200 --> 01:47:26.880]   But if you tuned in and you saw a black and white video, I think it would remind you that
[01:47:26.880 --> 01:47:32.400]   something was going on. I don't know what we're going to do on July 12, I guess. Maybe we'll do
[01:47:32.400 --> 01:47:38.800]   that again. Well, I like the idea of giving people a tool to weigh in, donate, or do some action
[01:47:38.800 --> 01:47:41.600]   as opposed to simply going dark. I think that's a clever tactic.
[01:47:41.600 --> 01:47:46.880]   Yeah. And I think we're in a season of heightened political action. If there's a case,
[01:47:46.880 --> 01:47:56.320]   a new twist to be made on this case, someone who is hyper-politically active with this group,
[01:47:56.320 --> 01:48:02.480]   trying to get their name, Media Mobilizing Project, said, "Freedom of speech doesn't mean
[01:48:02.480 --> 01:48:08.080]   much without the freedom to be heard." And I think if you look at anything from all sides
[01:48:08.080 --> 01:48:16.000]   left or right, the Tea Party, Occupy, Black Lives Matter, Women's March, Truth March, Science March,
[01:48:16.000 --> 01:48:20.480]   other abstract ideas that apparently need defending in these current times, March,
[01:48:20.480 --> 01:48:26.160]   that those new ways of organizing and distributing power essentially is because we all have a right
[01:48:26.160 --> 01:48:31.360]   to connect to each other. And we're not relegated to a crap lane on the internet. So if you care
[01:48:31.360 --> 01:48:36.480]   about any of those things, in addition to just a more sound technical infrastructure,
[01:48:37.200 --> 01:48:40.720]   you should be in support of Net Neutrality. Well, you know what? I don't understand. Maybe somebody
[01:48:40.720 --> 01:48:44.720]   in the chat room could help me out. I don't understand who benefits from dropping network
[01:48:44.720 --> 01:48:50.320]   neutrality other than the big internet service providers. I mean, usually... Is there anybody...
[01:48:50.320 --> 01:48:55.840]   Well, and this is interesting because there's a case to be made, right, where if from a cost savings
[01:48:55.840 --> 01:48:59.520]   perspective, and we've been spent a lot of time talking about Amazon deals and how the
[01:48:59.520 --> 01:49:07.840]   not really deals. But if you get a cell phone and it has an allowance of two gigabytes a month of data,
[01:49:07.840 --> 01:49:14.800]   but YouTube is thrown in for free or that provider's preferred music plan is thrown in for free,
[01:49:14.800 --> 01:49:20.240]   you could argue that consumers benefit. And I think that's the twisted way of painting this
[01:49:20.240 --> 01:49:26.320]   picture is that by determining winners and losers at this high corporate level, you can offer that
[01:49:26.320 --> 01:49:30.560]   for free, but it's at a great disservice to the potential. They're doing that in a new voice,
[01:49:30.560 --> 01:49:35.840]   a new platform. All right. Because I think there are a counter argument against Net Neutrality.
[01:49:35.840 --> 01:49:41.280]   There are legitimate. I have to say this, there are legitimate people,
[01:49:41.280 --> 01:49:47.040]   intelligent people who are in favor of dropping title two regulation for a variety of reasons.
[01:49:47.040 --> 01:49:51.520]   There are intelligent people who say the government, including the FCC, should in no way
[01:49:53.680 --> 01:50:00.480]   govern the internet. And I have to agree with that, but I would point out that that's not what
[01:50:00.480 --> 01:50:04.560]   we're asking the FCC to do. We're not asking them to regulate the internet. We're asking them to
[01:50:04.560 --> 01:50:11.520]   regulate companies that bring the internet to millions of consumers who have already shown
[01:50:11.520 --> 01:50:16.320]   that they would like to choose winners and losers on the internet. And what we're trying to say is
[01:50:16.320 --> 01:50:20.560]   I think it's appropriate for government to regulate that. And it's practically an
[01:50:20.560 --> 01:50:26.480]   op-le, but to do op-le at best. Well, thanks to the FCC. I got to point out that that's part
[01:50:26.480 --> 01:50:32.880]   of what the FCC did. The history of government intervention in the internet is not all kittens
[01:50:32.880 --> 01:50:41.360]   and puppies. I just, I don't want, as somebody who makes his living, bringing content over the
[01:50:41.360 --> 01:50:47.760]   internet to people, it's really important to me that Comcast not come to you and say,
[01:50:48.320 --> 01:50:54.560]   hey, Twitt's going to cost you, but Netflix is not. So, which would you like to watch tonight?
[01:50:54.560 --> 01:50:57.520]   I don't think they should get to choose winners and losers.
[01:50:57.520 --> 01:51:03.600]   Now, it's up to Congress. I think this is one of these, I think this is one of these great issues
[01:51:03.600 --> 01:51:08.960]   that it's not really a partisan issue. I mean, I know a lot of libertarians that feel just as
[01:51:08.960 --> 01:51:14.560]   strongly about net neutrality as I do. And, you know, one of the things I think is just so interesting
[01:51:14.560 --> 01:51:21.680]   is engineers I talk to that work in tech, we all understand the dangers that are here for, you know,
[01:51:21.680 --> 01:51:30.000]   free dispersal of information. So, I think the only, I think there are some fringe people that
[01:51:30.000 --> 01:51:35.040]   have a different opinion. But I think generally speaking, the people advocating for this are the
[01:51:35.040 --> 01:51:42.160]   big telecom companies, which have huge lobbying firms in Washington, D.C. You know, Al Franken,
[01:51:42.160 --> 01:51:47.120]   his last book, we were talking about that earlier, Leo. You know, he talks about working with Comcast
[01:51:47.120 --> 01:51:52.560]   and how they came and testified before Congress with the NBC Universal Deal and completely
[01:51:52.560 --> 01:51:57.840]   renamed on what they said they were going to do. So, you know, I just think there's every single
[01:51:57.840 --> 01:52:03.120]   reason to be skeptical that these giant telecom companies are going to, you know, treat this correctly.
[01:52:03.120 --> 01:52:05.440]   So, I'm 100% in favor of it.
[01:52:06.720 --> 01:52:11.360]   I guess I have to, I should have booked somebody who is against net neutrality.
[01:52:11.360 --> 01:52:19.440]   Because I'm not doing a very good job arguing the case. But I don't, I think there are legitimate
[01:52:19.440 --> 01:52:24.880]   intelligent people who were in favor of at least of at least of overturning these FCCs.
[01:52:24.880 --> 01:52:27.840]   Well, I mean, one argument is that in April, don't fix it. I mean,
[01:52:27.840 --> 01:52:32.080]   net neutrality wasn't on the books until, you know, about a year ago and this.
[01:52:32.080 --> 01:52:36.080]   Not even that one. I don't think it really, I mean, when did it become?
[01:52:36.080 --> 01:52:40.800]   Relatively. I think it took into effect this actually January. But the point is that we had no
[01:52:40.800 --> 01:52:50.240]   net neutrality codified by Congress and the FCC and things weren't horrible. But I see even
[01:52:50.240 --> 01:52:57.120]   with net neutrality, I'm seeing all these AT&T deals with what do they call their direct TV.
[01:52:57.120 --> 01:53:02.800]   I'm seeing T-Mobile and there's their deals going on anyway, despite net neutrality. So,
[01:53:03.440 --> 01:53:08.320]   you may actually still get your free Netflix given the current. I'm not exactly sure how they do it.
[01:53:08.320 --> 01:53:13.680]   But there are ways around net neutrality even under the current FCC rule.
[01:53:13.680 --> 01:53:19.120]   Jawbone shutting down.
[01:53:19.120 --> 01:53:26.640]   I thought this was a great company. They started by making Bluetooth speakers. They pretty much
[01:53:26.640 --> 01:53:31.040]   created that category. They remember the jam box. What a great Bluetooth speaker that was. That
[01:53:31.040 --> 01:53:37.120]   was a huge hit. But they were, of course, immediately faced competition from China and elsewhere.
[01:53:37.120 --> 01:53:41.600]   And they really couldn't in any way own the Bluetooth speaker market. So, they looked for a new,
[01:53:41.600 --> 01:53:47.280]   for you know, green fields they could try to own. And they went to the fitness device. Remember,
[01:53:47.280 --> 01:53:54.560]   they created, was it the up the jawbone up the up band had some problems. One of them had a nickel
[01:53:54.560 --> 01:54:02.800]   in it, which cost allergies and they had to recall all of them. And so, they were at one point
[01:54:02.800 --> 01:54:10.320]   valued as high as $3 billion. They've thrown in the towel. They're liquidating their assets.
[01:54:10.320 --> 01:54:15.680]   And its founder, Joseon Raman, is starting a new company called Jawbone Health Hub, which
[01:54:15.680 --> 01:54:19.920]   will work on medical software and hardware. I don't know if he'll have a consumer facing
[01:54:22.080 --> 01:54:30.560]   product or not. And they have raised money. But, you know, they have litigation going on with Fitbit.
[01:54:30.560 --> 01:54:36.320]   That will be taken over by I think some people bought the remaining assets of Jawbone.
[01:54:36.320 --> 01:54:44.000]   I think they've always reminded me a lot of Palm. Palm had such a strong early product in
[01:54:44.000 --> 01:54:48.800]   that category. But as time went on, they were just unable to innovate. They're unable to bring
[01:54:48.800 --> 01:54:55.360]   it to the next level. And I own their early products just like everyone else did. But I think the
[01:54:55.360 --> 01:55:00.560]   B-TEX headphones, those came out. They're really great, very easy to use. They're stylish.
[01:55:00.560 --> 01:55:04.560]   That's right. Before they did the speaker, they did Jawbone Bluetooth. You're right.
[01:55:04.560 --> 01:55:09.120]   Bluetooth headsets. Yeah, absolutely. And I just think they never innovated.
[01:55:09.120 --> 01:55:14.160]   Yeah. Well, it just became, I think this is going to be a problem for a lot of companies that
[01:55:14.800 --> 01:55:18.640]   you can't enter a market, create a market, and then hold that market.
[01:55:18.640 --> 01:55:24.240]   Because Chinese cloners and others will come along. Unless you have some secret sauce,
[01:55:24.240 --> 01:55:29.600]   they're going to face terrific competition. How's Tivo doing? I mean, that was an example.
[01:55:29.600 --> 01:55:33.120]   They owned the market of digital recorders for a while. Right. Now, they're commodities and
[01:55:33.120 --> 01:55:39.680]   every cable operator offers one. And these are companies, they say, about pioneers having arrows
[01:55:39.680 --> 01:55:45.280]   in their back. You have to give them credit. We owe them a debt of gratitude for having been
[01:55:45.280 --> 01:55:50.480]   pioneers. But at the end of the day, it's a competitive landscape. And they just don't own
[01:55:50.480 --> 01:55:57.120]   their market. One way you protect that, of course, was patents. And there's a big battle going on
[01:55:57.120 --> 01:56:04.240]   right now between Apple and Qualcomm. And the more I learned about this, the more I'm kind of on the
[01:56:04.240 --> 01:56:12.160]   side of Qualcomm, believe it or not. Really? Yeah. So here's, here's, and you can argue,
[01:56:12.160 --> 01:56:16.000]   tell me, tell me why I'm wrong here. Kind of my starting to think this way.
[01:56:16.000 --> 01:56:23.920]   Qualcomm did create a huge number of innovations. They invented CDMA. They made CDMA radios. That's
[01:56:23.920 --> 01:56:28.160]   where they made their big bucks. Of course, CDMA is being phased out now. But nevertheless,
[01:56:28.160 --> 01:56:36.240]   anybody who makes a cell phone must license technology from Qualcomm. You just have to.
[01:56:36.240 --> 01:56:41.280]   They own so many patents in that area. And rightly, they're not a patent role. They invented so many
[01:56:41.280 --> 01:56:48.080]   technologies that are using cell phones. Apple was paying them a lot of money. I'm told it was,
[01:56:48.080 --> 01:56:54.080]   it ended up being a few dollars per handset. That's what Samsung pays and others. But at some point,
[01:56:54.080 --> 01:57:00.640]   Apple decided, we don't want to pay anymore. And so they're suing Qualcomm for a billion dollars
[01:57:00.640 --> 01:57:06.400]   and stopped paying the license fees. Qualcomm has countersuits saying we want our license fees.
[01:57:06.400 --> 01:57:14.800]   I'm, you know, and maybe, you know, this is, of course, patent law and so forth is complicated.
[01:57:14.800 --> 01:57:20.960]   But there is a lot of, here's Qualcomm. There's a little poster infographic that Qualcomm made
[01:57:20.960 --> 01:57:29.760]   on some of the patents. And what Qualcomm's latest blow in this is to go to the ITC, the U.S.
[01:57:29.760 --> 01:57:36.720]   International Trade Commission, and say, Apple, we want you to rule that Apple cannot import any
[01:57:36.720 --> 01:57:42.560]   iPhones using the Intel chips. Apple last year in the iPhone 7 replaced the Qualcomm chip in some
[01:57:42.560 --> 01:57:46.720]   of their phones, not all of them with Intel radios. The Intel radios didn't for LTE. They
[01:57:46.720 --> 01:57:51.920]   didn't work as well. And Apple, this is another thing Qualcomm's suing over. Apple slowed down
[01:57:51.920 --> 01:57:56.640]   the Qualcomm radios because they wanted them to be the same. They wanted every iPhone to be the
[01:57:56.640 --> 01:58:01.360]   same. So I have an Intel radio on my iPhone because I got it from T-Mobile. I think it was
[01:58:01.360 --> 01:58:09.360]   at AT&T T-Mobile have the Intel chips because they're their GSM. And Apple slowed down the
[01:58:09.360 --> 01:58:14.960]   Verizon and Sprint phone so that they would all be equally slow, which Qualcomm was mad about.
[01:58:14.960 --> 01:58:22.480]   Our technology is better, but Apple's making it limp. And so they've asked the ITC to block
[01:58:22.480 --> 01:58:28.560]   to ban all Intel-based iPhones from the United States. It seems like part of the...
[01:58:28.560 --> 01:58:30.160]   Go ahead, Brianna.
[01:58:30.160 --> 01:58:38.560]   Yeah, my husband, he is head of IP for major company on the Nasdaq. So we talk about
[01:58:38.560 --> 01:58:44.720]   intellectual property a lot in our house. I definitely agree with you that Qualcomm
[01:58:44.720 --> 01:58:49.200]   has an awesome case here. And they did invent the core technology there.
[01:58:49.200 --> 01:58:56.320]   But the way that this was negotiated originally with the iPhone, it's not that they're paying a
[01:58:56.320 --> 01:59:03.040]   standard fee for these core technologies. It's that they're getting a certain percentage of
[01:59:03.040 --> 01:59:09.280]   every single iPhone sale period. And Apple isn't saying we don't want to pay anything for your
[01:59:09.280 --> 01:59:15.040]   patents. They are saying we want to bring you back to the table and pay you a more standard fee.
[01:59:15.040 --> 01:59:21.840]   Something we talk about a lot in intellectual property is a reasonable licensing rate for
[01:59:21.840 --> 01:59:28.480]   core technologies like CDMA. So I think that this is one of the situations where I think both
[01:59:28.480 --> 01:59:35.440]   people are right. Qualcomm did a lot of innovation there. But the reason people buy iPhones today,
[01:59:35.440 --> 01:59:39.840]   or at least this is Apple's argument, has more to do with the screen technology,
[01:59:39.840 --> 01:59:47.760]   the responsiveness of it, touch ID, the camera, those core features. And Apple's argument is
[01:59:47.760 --> 01:59:54.000]   that CDMA technology inside of it, the speed of it, that's not why people are buying phones.
[01:59:54.000 --> 01:59:56.400]   So I think that's a believable argument.
[01:59:56.400 --> 02:00:00.240]   If there's a counter argument, if they're not buying phones for that, take that out of your phone
[02:00:00.240 --> 02:00:02.480]   and see if they buy your phone. Exactly.
[02:00:02.480 --> 02:00:05.120]   Right. Yeah. Right. Right.
[02:00:05.120 --> 02:00:10.400]   You may say they're not buying the phones because of that. But if you take it out,
[02:00:10.400 --> 02:00:14.400]   they ain't buying the phone, that sounds to me like those are critical technologies.
[02:00:14.400 --> 02:00:19.600]   Sure. And that's, I'm not saying I believe that I'm saying that's Apple's argument. I would say
[02:00:19.600 --> 02:00:29.280]   this for core technologies, I do think we need to make sure that people don't like set the fees
[02:00:29.280 --> 02:00:35.040]   so high that consumers end up paying unreasonable fees to basically pay for these patents.
[02:00:35.040 --> 02:00:38.800]   So we need reasonable licensing rates for core technologies.
[02:00:38.800 --> 02:00:41.120]   Yeah. Isn't that, isn't it,
[02:00:41.120 --> 02:00:46.640]   "Fran, fair, and reasonable," I can't remember what Fran stands for, but I don't know how many of
[02:00:46.640 --> 02:00:52.400]   these are Fran patents. At least six Qualcomm asserts are not Fran, they're not essential,
[02:00:52.400 --> 02:00:58.320]   but Apple uses them. And as a result, Apple should pay for them if you're going to use them pay for them.
[02:00:59.200 --> 02:01:04.640]   I don't know. I don't know. The problem is that Apple doesn't want to pay a percentage of these
[02:01:04.640 --> 02:01:09.040]   phone sales. There are too much cash that's going on as a percentage. They could just lower the price
[02:01:09.040 --> 02:01:14.160]   of the iPhone and effectively pay Qualcomm less money. We would all be happier.
[02:01:15.120 --> 02:01:20.320]   But I don't want to be one sensitive or Apple phone buyer to pay whatever Apple charges.
[02:01:20.320 --> 02:01:27.280]   Just think, trying to think outside the box here and help out out and help resolve this.
[02:01:27.280 --> 02:01:33.760]   I'm a mediator in this corporate financial ledger battle. Let's bring that.
[02:01:33.760 --> 02:01:41.440]   Peace in our time. I think it's about time. Anyway, yeah, so good. I think obviously we need
[02:01:41.440 --> 02:01:47.520]   to have more of a conversation about this. I feel like, I mean, look, Qualcomm's taken the
[02:01:47.520 --> 02:01:51.440]   nuclear option. If you ban, I have the iPhones that come into the country, that's going to be a big
[02:01:51.440 --> 02:01:55.520]   issue. And it's not going to make Qualcomm any friends among the public either.
[02:01:55.520 --> 02:02:01.920]   So when they probably, yeah, they're attached to a gravy train. The iPhone is a runaway hit.
[02:02:01.920 --> 02:02:06.480]   They want to keep that as high as possible. Like they want as much money as possible. Apple
[02:02:06.480 --> 02:02:11.600]   wants to pay as little as possible. And like all sound business people, they're taking it to court.
[02:02:11.600 --> 02:02:14.640]   That's just what you do. Let's just take it. Just business.
[02:02:14.640 --> 02:02:19.600]   And let's take a little break and we're going to wrap things up because we're on the two hour
[02:02:19.600 --> 02:02:27.360]   mark. And you know, it's funny. I mean, this show is getting longer. But bladders aren't getting
[02:02:27.360 --> 02:02:31.840]   any bigger. So I think it really, really probably be a good time to take a little break right here.
[02:02:31.840 --> 02:02:38.000]   And anybody who wants to run off can, while we talk a little bit about the tracker,
[02:02:38.000 --> 02:02:42.240]   a coin size tracking device that I love. I just got the new tracker. You have one.
[02:02:42.240 --> 02:02:48.160]   You're putting it on my wife's got my keys. It pairs to your phone. This was, I think,
[02:02:48.160 --> 02:02:52.080]   the first Bluetooth tracking device, they big kick starter. Remember, they've gotten so much
[02:02:52.080 --> 02:02:55.520]   better that we saw that we saw the tracker Bravo come out. I think it was last year about
[02:02:55.520 --> 02:03:01.520]   the size of a quarter weighs less anodized aluminum, replaceable battery. We just got the new tracker
[02:03:01.520 --> 02:03:06.240]   pixels. John, would you bring me my keys? My keys is on my desk because I got the tracker pixel
[02:03:06.240 --> 02:03:10.560]   attached to it. It's as awesome because the pixel has, it's first of all, the lightest
[02:03:10.560 --> 02:03:15.760]   Bluetooth tracking device in the markets, even smaller, even lighter. And I love this. They put
[02:03:15.760 --> 02:03:21.600]   LEDs on it. So, you know, a lot of times when you lose the keys, it's because they're under the
[02:03:21.600 --> 02:03:27.440]   sofa or they're in a cushion. Now you can get the LEDs to light up and it makes it even easier to
[02:03:27.440 --> 02:03:32.480]   find. Look how little this tracker pixel is. It's tiny, teeny, weeny. And like all the
[02:03:32.480 --> 02:03:36.160]   trackers, it has a button on it so you can press the button and that will call your phone. They've
[02:03:36.160 --> 02:03:40.560]   got two-way separation alerts. So if you leave your phone behind, the tracker screams at you.
[02:03:40.560 --> 02:03:45.360]   But if you leave the tracker behind, the phone will let you know. The tracker app on your phone
[02:03:45.360 --> 02:03:50.400]   shows where your trackers are. You can have up to 10 trackers paired to a phone. And
[02:03:50.400 --> 02:03:54.880]   now you can have trackers paired to multiple phones. So that means everybody in the family can
[02:03:54.880 --> 02:04:00.560]   help you look for your keys. If you misplace an item that has a tracker pixel attached,
[02:04:00.560 --> 02:04:06.800]   you just trigger the pixel and a 90 decibel alert and powerful LED lights will light up.
[02:04:06.800 --> 02:04:11.120]   And you will find that device. So my tracker is somewhere near the Mystic Theater.
[02:04:11.120 --> 02:04:16.800]   That's just nearby. The Mystic is where the old place was. You better tell your wife we move.
[02:04:16.800 --> 02:04:24.720]   So the tracker is great, but it also has one feature that no other tracking device has
[02:04:24.720 --> 02:04:30.160]   the global GPS network. So if the problem is if your wife left those keys at the Mystic and
[02:04:30.160 --> 02:04:34.960]   drove off, there'd be no tracker, no phone tracking those keys. But here's the beauty part. Somebody
[02:04:34.960 --> 02:04:38.800]   walks by that theater who's got the tracker and there's four and a half million tracker customers
[02:04:38.800 --> 02:04:44.960]   out there. Their phone will see your tracker and ping your phone. That explains why even though
[02:04:44.960 --> 02:04:49.120]   my tracker is connected to my phone, but it's still tracking. That's how you know, because if somebody
[02:04:49.120 --> 02:04:53.520]   else saw it, that is so sweet. This is kind of brilliant. Yeah, four and a half million
[02:04:53.520 --> 02:04:57.520]   trackers out there. Look at the map. They're all over the world. Okay, don't lose your keys in
[02:04:57.520 --> 02:05:03.680]   Siberia or Greenland. But other than that, you're covered. Actually, there's even a few in Greenland,
[02:05:03.680 --> 02:05:09.680]   I see. I have to tell you, I love trackers so much and I've used some of the ones from other
[02:05:09.680 --> 02:05:15.680]   competitors. And what I hate about them is it's so bad for the environment because you spend like
[02:05:15.680 --> 02:05:21.520]   $100 on four of them. You have to throw them out when the bag goes by. You have to throw it out.
[02:05:21.520 --> 02:05:29.680]   It's so ridiculous because the competitive product is okay, but it's so expensive because if you
[02:05:29.680 --> 02:05:34.720]   have a lot of these, you're going to end up paying like $200 a year for it. So all the trackers,
[02:05:34.720 --> 02:05:39.760]   you can open them up. Even this new one, you can open it up, put in a new battery. So it's good
[02:05:39.760 --> 02:05:44.720]   to go. And you're right, Brianna. That is a really big differentiator and I really like that
[02:05:44.720 --> 02:05:52.800]   about tracker. Save the environment and your keys at the same time. We got a good deal for you.
[02:05:52.800 --> 02:05:58.320]   If you go to the tracker.com and use a promo code TWIT, load up your shopping basket and then
[02:05:58.320 --> 02:06:03.600]   that promo code will take 20% off any order. Th e t r actually the website is harder to find
[02:06:03.600 --> 02:06:09.520]   than your keys. Th e t r a c k r dot com. You know, we're going to wall it. It's going to
[02:06:09.520 --> 02:06:14.960]   tracker embedded in the wallet. Yeah, it's great. We should still put a tracker in your wallet,
[02:06:14.960 --> 02:06:18.880]   but it's going to actually be embedded. Yeah, that would even be better. Yeah. The tracker.com.
[02:06:18.880 --> 02:06:22.880]   Don't forget that promo code TWIT. You'll save 20%. And I love this new tracker pixel. It's so
[02:06:22.880 --> 02:06:31.520]   cool. We have had so much fun. You guys are just dying. I made it light up. I forgot to do that.
[02:06:31.520 --> 02:06:36.640]   You can also ping your phone from your tracker. Yeah. Right. You guys are so great.
[02:06:36.640 --> 02:06:39.680]   Barry Tunde Thurston. Always a pleasure to have you on the show.
[02:06:39.680 --> 02:06:46.400]   You're muted right now. So am I? Oh, no, you're okay. You just came back. Okay. Okay.
[02:06:46.400 --> 02:06:53.680]   It would be hard for me to be here without my old TWIT compatriot, Nick Bilton. And so during
[02:06:53.680 --> 02:06:58.400]   the break, Nick actually sent me a message. He says hello to everyone. And I would be a
[02:06:58.400 --> 02:07:03.920]   bad friend if I didn't tell you his book, American Kingpin is great. So I'll use the balance of my
[02:07:03.920 --> 02:07:09.360]   time to promote Nick, tell you to give money to Brianna and check out connect safely.org.
[02:07:09.360 --> 02:07:13.760]   What a guy. Anybody's ever plugged everybody else.
[02:07:13.760 --> 02:07:22.240]   American Kingpin is the story behind the Silk Road and how they caught how the FBI caught Ross
[02:07:22.240 --> 02:07:29.040]   Albrecht. And it is Nick is a great writer. His Twitter book was incredible. But this one,
[02:07:29.920 --> 02:07:34.960]   you can't put it down. We got Nick coming on triangulation in the next couple of weeks, I think. We had him
[02:07:34.960 --> 02:07:38.560]   scheduled and he couldn't do it, but we've rescheduled and he will be on the next couple of weeks to
[02:07:38.560 --> 02:07:43.280]   join us and talk about his new book. Yeah. Nick's a great book. I bought that book after I came on
[02:07:43.280 --> 02:07:49.360]   last time and I swear this is true. The next day I sat down and I had meetings and I just read the
[02:07:49.360 --> 02:07:54.080]   book straight through it because it was that addictive. I've read it four times. What? Wow.
[02:07:54.080 --> 02:08:01.040]   This is is really is a competition for the best plug. Is that what's going on?
[02:08:01.040 --> 02:08:07.760]   I love this book. I love this book. It would be a fine work of fiction and the fact that it's all
[02:08:07.760 --> 02:08:13.440]   true makes it just an amazing work of journalism. It's stunning. I think you should put that on the
[02:08:13.440 --> 02:08:20.960]   back, Nick, an amazing work for Brianna. Brianna, good luck with your campaign. We're going to have
[02:08:20.960 --> 02:08:26.080]   you on many more times before the primary, but I still want to make sure everybody knows to support
[02:08:26.080 --> 02:08:35.040]   Brianna Wu, support Brianna.com and to visit visit her website Brianna Wu 2018. We clearly need
[02:08:35.040 --> 02:08:40.880]   somebody like you in Congress and you know what? Your message is important. Get involved, run,
[02:08:40.880 --> 02:08:47.360]   vote, participate because if we don't, then we have no reason to complain.
[02:08:48.560 --> 02:08:52.960]   Absolutely. You know, and unlike other politicians, if you send a tweet to me,
[02:08:52.960 --> 02:08:57.200]   I'll actually talk to you. It won't be one of my staff. You can actually talk to me.
[02:08:57.200 --> 02:09:01.280]   Tell us about this American flag behind you. That's very cool. I really like that.
[02:09:01.280 --> 02:09:06.800]   You know, I got it from, I honestly got it from Amazon and I was looking for a backdrop,
[02:09:06.800 --> 02:09:14.000]   something that just wasn't generic American flag and I just loved it. I thought it symbolized
[02:09:14.000 --> 02:09:19.760]   like where we kind of are as a country and yeah. Well, it's on Amazon folks.
[02:09:19.760 --> 02:09:26.800]   Be buying it already. What is it, right? Yeah. Of course, we always want to thank Larry
[02:09:26.800 --> 02:09:30.960]   Maggett for making the trip here. You see him on CBS radio. You visit his website Larry's World
[02:09:30.960 --> 02:09:36.320]   and don't forget connect safely.org and great articles. There are lots of information and I've
[02:09:36.320 --> 02:09:40.400]   used the, I don't know if it's safe for kids or connect safely. You have the internet contract,
[02:09:40.400 --> 02:09:46.240]   but that's a, yeah, that's unsafe kids.com safe kids.com. That is a really useful tool for any parent
[02:09:46.240 --> 02:09:50.000]   who has kids that are starting to venture out onto the internet, especially I think teens and
[02:09:50.000 --> 02:09:53.760]   preteens. Yeah. One of the things that I think makes us a little different from some of the
[02:09:53.760 --> 02:09:58.800]   internet safety groups is we really respect kids, respect their rights, but sometimes we all need
[02:09:58.800 --> 02:10:02.960]   a little help and respect the internet and respect the internet. Absolutely. Also freedom of speech.
[02:10:02.960 --> 02:10:08.080]   Yeah. You know, we can protect our children without having to sanitize the internet. The
[02:10:08.080 --> 02:10:12.320]   internet can still be there for everybody. Yeah. Well done. It's a great site. Thank you.
[02:10:12.320 --> 02:10:15.440]   Thank you everybody for joining us. We had a great studio audience. You guys,
[02:10:15.440 --> 02:10:18.560]   thank you for being here. I really appreciate it. It makes a lot of more fun for us to
[02:10:18.560 --> 02:10:25.360]   to know that there's actually six people listening. If you want to be in the studio
[02:10:25.360 --> 02:10:30.160]   audience, we love having an open studio. All you have to do is email tickets@twit.tv and we'll
[02:10:30.160 --> 02:10:34.160]   arrange. Well, first of all, we'll send you directions to our hidden location and then we'll
[02:10:34.160 --> 02:10:38.960]   arrange a chair so that you have somewhere to sit. If you can't be here in person, you can always
[02:10:38.960 --> 02:10:46.640]   watch live. We stream everything we do at our website, twit.tv/live or youtube.com/twit or
[02:10:46.640 --> 02:10:52.320]   ustream.com/twit or twitch.tv/twit. If you want to watch live, I encourage you to join us in the
[02:10:52.320 --> 02:10:58.000]   chat room to twit.irc.twit.tv. The chat room is always full of great and interesting people
[02:10:58.640 --> 02:11:05.840]   who keep us honest and offer often opposing viewpoints, which we welcome. IRC.twit.tv.
[02:11:05.840 --> 02:11:11.840]   Now, most of you don't participate live because you've got a life. So for those of you with lives,
[02:11:11.840 --> 02:11:17.280]   just remember, Twit.tv, the website, has downloadable on-demand versions of everything we do, including
[02:11:17.280 --> 02:11:23.040]   this show, audio and video. And of course, you probably have a program or an app that you use to
[02:11:23.040 --> 02:11:29.440]   get podcasts. Use that and subscribe because you want to get every single episode.
[02:11:29.440 --> 02:11:34.960]   Thank you so much for being here and we'll see you next time. Next Sunday,
[02:11:34.960 --> 02:11:42.560]   what time is it? It's 3 p.m. Eastern, 3 p.m. Pacific, 6 p.m. Eastern, 2200 UTC. I did the math in my head,
[02:11:42.560 --> 02:11:48.160]   all by myself. Thanks for joining us. We'll see you next time. Another Twit is in the can. Bye-bye.
[02:11:48.160 --> 02:11:50.720]   Are you still naming me? Are you still naming me?
[02:11:50.720 --> 02:11:51.200]   Yeah!
[02:11:52.080 --> 02:11:53.280]   Where's the key to it?
[02:11:53.280 --> 02:11:59.680]   Do the Twit. Alright. Do the Twit, baby. Do the Twit. Alright. Do the Twit.

