;FFMETADATA1
title=The Rods Go Down!
artist=Leo Laporte, Allyn Malventano, Louis Maresca, Sam Abuelsamid
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2022-03-28
track=868
language=English
genre=Podcast
comment=Kaspersky on Security Risk List, Lapsus$ hackers caught, EU's messaging law
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:04.000]   It's time for Twet this weekend tech. We have such a geeky and great panel for you.
[00:00:04.000 --> 00:00:11.000]   Sam Ebbels, Sam-Eddar, car guy is here. Alan Melvantano, the former Submariner. He now works at Intel.
[00:00:11.000 --> 00:00:16.000]   He's also an expert hacker. And all the way from this weekend in a price tech.
[00:00:16.000 --> 00:00:23.000]   Lou MM stops by lots to talk about. Kasperski, the first Russian company on the no-buy list.
[00:00:23.000 --> 00:00:29.000]   The threat of Russian cyber attacks. Lou and Alan will weigh in on why Russia hasn't attacked yet.
[00:00:29.000 --> 00:00:35.000]   And it turns out it was a teenager in his mom's basement who hacked all those companies.
[00:00:35.000 --> 00:00:39.000]   It's all coming up next on Twet.
[00:00:39.000 --> 00:00:41.000]   Podcasts you love.
[00:00:41.000 --> 00:00:44.000]   From people you trust.
[00:00:44.000 --> 00:00:47.000]   This is Twet.
[00:00:54.000 --> 00:01:03.000]   This is Twet. This week at Tech, Episode 868, recorded Sunday, March 27th, 2022.
[00:01:03.000 --> 00:01:05.000]   The rods go down.
[00:01:05.000 --> 00:01:12.000]   This week at Tech is brought to you by Grammarly. Get through those emails and your work quicker
[00:01:12.000 --> 00:01:18.000]   by keeping it concise, confident and effective with Grammarly. Go to Grammarly.com/Twet
[00:01:18.000 --> 00:01:22.000]   to sign up for a free account. And when you're ready to upgrade to Grammarly Premium,
[00:01:22.000 --> 00:01:25.000]   you'll get 20% off.
[00:01:25.000 --> 00:01:27.000]   And by Streak.
[00:01:27.000 --> 00:01:30.000]   Streak makes it so easy to run your business through Gmail.
[00:01:30.000 --> 00:01:33.000]   And when you try it, you're going to love it.
[00:01:33.000 --> 00:01:36.000]   It only takes 30 seconds to get started right now for a limited time.
[00:01:36.000 --> 00:01:38.000]   Save 20% on the Pro plan.
[00:01:38.000 --> 00:01:41.000]   Streak.com/Twet.
[00:01:41.000 --> 00:01:43.000]   And by Noom.
[00:01:43.000 --> 00:01:50.000]   Unlike other programs, Noom Weight uses a psychology-based approach to help people better understand their relationship with food.
[00:01:50.000 --> 00:01:55.000]   And gives you the skills and knowledge you need to build long-lasting positive habits.
[00:01:55.000 --> 00:02:01.000]   It works for me. Sign up for your trial at Noom.com/Twet.
[00:02:01.000 --> 00:02:09.000]   And by the new and recently updated TriCaster 2 Elite by NewTech, the most complete live production system on the planet.
[00:02:09.000 --> 00:02:17.000]   There's a TriCaster for every production, including yours. Visit go.NewTech.com/Twet-TV
[00:02:17.000 --> 00:02:22.000]   or you'll find an interactive guide to help you choose which TriCaster is right for you.
[00:02:22.000 --> 00:02:27.000]   [music]
[00:02:27.000 --> 00:02:33.000]   It's time for Twet this week in Tech. The show will cover the week's tech news, some fun news this week.
[00:02:33.000 --> 00:02:40.000]   Fortunately, we've got a great panel. Sam Ables. Sam is here. He was on his way to San Diego this morning during the radio show, but we got him.
[00:02:40.000 --> 00:02:46.000]   Wheelbearrings.media is his podcast, Wheelbearrings podcast. He's a principal researcher at Guide House Insights.
[00:02:46.000 --> 00:02:51.000]   And of course, automotive technology expert. What are you doing in San Diego today?
[00:02:51.000 --> 00:02:59.000]   I am here to drive the new Toyota BZ4X, their first purpose-built electric vehicle that's launching this spring.
[00:02:59.000 --> 00:03:04.000]   Boy, we talk about electric vehicles all the time now in the radio show.
[00:03:04.000 --> 00:03:08.000]   It is there just taking off. Everybody's got one more coming out all the time.
[00:03:08.000 --> 00:03:13.000]   We're holding on wheel bearings every week. It's more EVs to talk about.
[00:03:13.000 --> 00:03:22.000]   It's great. Also joining us, it's great to see him from this week in Enterprise Tech, the host, Lou Mareska.
[00:03:22.000 --> 00:03:26.000]   Good to see you, Lou. How many children do you have now?
[00:03:26.000 --> 00:03:27.000]   [laughter]
[00:03:27.000 --> 00:03:31.000]   Every time I have to check in, I still only have five children, but I have five.
[00:03:31.000 --> 00:03:32.000]   This is the only five.
[00:03:32.000 --> 00:03:39.000]   Are you to deserve an award? I only had two, and I could barely keep up. Five is amazing. I'm very impressed.
[00:03:39.000 --> 00:03:45.000]   Lou, of course, is an employee of Microsoft, but his opinions are his own, and he does not reflect Microsoft.
[00:03:45.000 --> 00:03:49.000]   You can recuse yourself on any story that you feel is inappropriate.
[00:03:49.000 --> 00:03:52.000]   We always love having Lou on.
[00:03:52.000 --> 00:03:55.000]   And boy, welcome back to our microphone. It's been a long time.
[00:03:55.000 --> 00:03:59.000]   You may remember Alan Malvin Tonna from this week in Computer Hardware.
[00:03:59.000 --> 00:04:07.000]   He was a PC perspective, a storage expert. He was my source for all things SSD for so many.
[00:04:07.000 --> 00:04:10.000]   He was. Still are. He still are.
[00:04:10.000 --> 00:04:14.000]   Former Submariner Submariner from the, you were a Navy guy, right?
[00:04:14.000 --> 00:04:15.000]   Yep.
[00:04:15.000 --> 00:04:17.000]   And retired.
[00:04:17.000 --> 00:04:20.000]   USN-R-E-T.
[00:04:20.000 --> 00:04:23.000]   And he currently is working at Intel.
[00:04:23.000 --> 00:04:26.000]   You filed Ryan Shroud over there from PC perspective.
[00:04:26.000 --> 00:04:33.000]   He's a storage technical analyst. And just like Lou, Alan's thoughts are his own.
[00:04:33.000 --> 00:04:38.000]   He does not speak for Intel, but I'm glad they let you be on the show. That's great.
[00:04:38.000 --> 00:04:41.000]   Yeah, yeah. I mean, I can talk about storage stuff just, you know, not here to sell.
[00:04:41.000 --> 00:04:43.000]   I'm not here to sell anything.
[00:04:43.000 --> 00:04:46.000]   Optane, obtain, obtain. That's all I can say. Over and over.
[00:04:46.000 --> 00:04:50.000]   Listen, I'm personally a sucker for some optane. I'm a sucker for some optane.
[00:04:50.000 --> 00:04:51.000]   Yeah, yeah.
[00:04:51.000 --> 00:04:55.000]   That's that's that when they announced the its tri X.
[00:04:55.000 --> 00:04:59.000]   Was that the original name of the three cross point cross point? That's right.
[00:04:59.000 --> 00:05:06.000]   It was three three D RAM. And I remember when they announced it, I we thought this is going to transform.
[00:05:06.000 --> 00:05:11.000]   In other words, it's it's basically an SSC. It's fast enough to act as RAM.
[00:05:11.000 --> 00:05:15.000]   Or is it a RAM that's not involved enough to act as an SSD?
[00:05:15.000 --> 00:05:16.000]   I don't know. It's one of the.
[00:05:16.000 --> 00:05:20.000]   It's in the middle between it's between NAND and RAM, right?
[00:05:20.000 --> 00:05:22.000]   Yeah. Performance wise. It's very cool.
[00:05:22.000 --> 00:05:25.000]   But yeah, it is persistent, right? So the power goes off. All the stuff's still there.
[00:05:25.000 --> 00:05:26.000]   That's pretty cool.
[00:05:26.000 --> 00:05:30.000]   Very, very nice. And I see you have a bobble head.
[00:05:30.000 --> 00:05:32.000]   Which is me.
[00:05:32.000 --> 00:05:34.000]   No, you don't. Oh, you have that.
[00:05:34.000 --> 00:05:35.000]   Oh, I have the coaster.
[00:05:35.000 --> 00:05:37.000]   Lou has the bobble head. You have the coaster.
[00:05:37.000 --> 00:05:39.000]   Lou has the bobble head. Yeah.
[00:05:39.000 --> 00:05:47.000]   I'm just glad because apparently the bobble heads have been making it to places other than,
[00:05:47.000 --> 00:05:55.000]   I don't know, places that we would like. Here is an image of this is a live in Palm Desert.
[00:05:55.000 --> 00:06:02.000]   Photographer thrift store junkie can't believe what I found in a thrift store.
[00:06:02.000 --> 00:06:07.000]   The Leo bobble head. But you know, it is in pristine condition.
[00:06:07.000 --> 00:06:12.000]   So worth a lot of money. I made a mistake. I should have made NFTs, not bobble heads.
[00:06:12.000 --> 00:06:13.000]   There was my mistake.
[00:06:13.000 --> 00:06:18.000]   All right, let's start with the hacking.
[00:06:18.000 --> 00:06:23.000]   Because you're here, Alan, tell me what your hacking credentials are.
[00:06:23.000 --> 00:06:28.000]   Yeah, so I don't know. I think it was the last one I was on or the one before.
[00:06:28.000 --> 00:06:31.000]   We discovered that you had a deep dark secret.
[00:06:31.000 --> 00:06:36.000]   Leo discovered it might be one of the best spittechs Leo ever did on a twit.
[00:06:36.000 --> 00:06:38.000]   Because I caught him right when he was drinking.
[00:06:38.000 --> 00:06:41.000]   Oh, yeah, did you know I was in the NSA there, buddy.
[00:06:41.000 --> 00:06:42.000]   Thanks.
[00:06:42.000 --> 00:06:44.000]   Yeah, but I didn't do.
[00:06:44.000 --> 00:06:47.000]   Was that pre-navy or was that part of your naval service?
[00:06:47.000 --> 00:06:48.000]   Part of?
[00:06:48.000 --> 00:06:49.000]   Part of related.
[00:06:49.000 --> 00:06:50.000]   Okay.
[00:06:50.000 --> 00:06:56.000]   Yeah, yeah, because there's NSA commands that are joint service commands where you'll have all the other branches of the military.
[00:06:56.000 --> 00:06:59.000]   They'll come and they'll join some civilian folk that work, you know,
[00:06:59.000 --> 00:07:01.000]   that work alongside the civilians that work at the NSA.
[00:07:01.000 --> 00:07:02.000]   Wow.
[00:07:02.000 --> 00:07:03.000]   Wow.
[00:07:03.000 --> 00:07:05.000]   So my job there was, well,
[00:07:05.000 --> 00:07:06.000]   You were an analyst.
[00:07:06.000 --> 00:07:07.000]   I did the NSA job.
[00:07:07.000 --> 00:07:11.000]   I was in Virginia and I was doing network defense there.
[00:07:11.000 --> 00:07:12.000]   Oh, wow.
[00:07:12.000 --> 00:07:15.000]   Well, that wasn't NSA, but that was still network related and like hacking related.
[00:07:15.000 --> 00:07:16.000]   Wow.
[00:07:16.000 --> 00:07:22.000]   But then the NSA side, they do some more offensive, I will say things, of course.
[00:07:22.000 --> 00:07:26.000]   But when I was there, I reverse engineered malware.
[00:07:26.000 --> 00:07:27.000]   So we're kind of.
[00:07:27.000 --> 00:07:33.000]   We've been talking, I mean, look at, we talk about, you know, security all the time, not just in security now.
[00:07:33.000 --> 00:07:39.000]   It's a common subject, but it's really become a hot topic since the Russian invasion of Ukraine.
[00:07:39.000 --> 00:07:42.000]   Because, and there's a lot of speculation about this.
[00:07:42.000 --> 00:07:47.000]   I think many of us thought Russia would use their cyber warfare capabilities.
[00:07:47.000 --> 00:07:51.000]   Initially against Ukraine, there were some at the beginning of the invasion.
[00:07:51.000 --> 00:07:59.000]   They shut some things down, which came right back online, including the financial system and some satellite reconnaissance systems.
[00:07:59.000 --> 00:08:06.000]   But then we've also been worried a little bit about cyber warfare attacks in retaliation for sanctions against the West,
[00:08:06.000 --> 00:08:07.000]   especially in the US.
[00:08:07.000 --> 00:08:09.000]   None of this really has panned out.
[00:08:09.000 --> 00:08:11.000]   What is your sense of it, Alan?
[00:08:11.000 --> 00:08:12.000]   Is it?
[00:08:12.000 --> 00:08:14.000]   I have a theory.
[00:08:14.000 --> 00:08:15.000]   Yeah.
[00:08:15.000 --> 00:08:20.000]   So part of the job that I was doing when I was there was reverse engineering malware.
[00:08:20.000 --> 00:08:22.000]   Well, where do we get the malware?
[00:08:22.000 --> 00:08:26.000]   We get it when one country A attacks country B.
[00:08:26.000 --> 00:08:27.000]   And then we see it.
[00:08:27.000 --> 00:08:28.000]   And then what do we do?
[00:08:28.000 --> 00:08:31.000]   We pick it apart and we figure out how to defend against it.
[00:08:31.000 --> 00:08:32.000]   Right?
[00:08:32.000 --> 00:08:40.000]   By the way, protect us being the United States from those other foreign countries who might happen to be fighting amongst themselves at the time.
[00:08:40.000 --> 00:08:41.000]   Right?
[00:08:41.000 --> 00:08:45.000]   But then we can warn from that and protect ourselves using that information.
[00:08:45.000 --> 00:08:46.000]   Right?
[00:08:46.000 --> 00:08:54.000]   So I have a suspicion that either Russia just didn't have, you know, they're not up to snuff on their hacking ability.
[00:08:54.000 --> 00:08:57.000]   Maybe it's sort of in line with their, you know, other abilities.
[00:08:57.000 --> 00:08:58.000]   The military capability.
[00:08:58.000 --> 00:09:01.000]   It seems like they haven't been panning out that well.
[00:09:01.000 --> 00:09:02.000]   That's option A.
[00:09:02.000 --> 00:09:04.000]   Option B is they don't want to play their hand.
[00:09:04.000 --> 00:09:05.000]   Right?
[00:09:05.000 --> 00:09:16.000]   If they do have those exploits that they know that people can't yet defend against, why would you lay them all on the table, you know, against Ukraine when everybody else is going to be listening, so to speak.
[00:09:16.000 --> 00:09:17.000]   Right?
[00:09:17.000 --> 00:09:20.000]   They all have their ways of trying to catch that stuff coming across the wire.
[00:09:20.000 --> 00:09:27.000]   So that would then make, you know, subsequent attacks against anybody else, Russia wanted to go after harder.
[00:09:27.000 --> 00:09:28.000]   Right?
[00:09:28.000 --> 00:09:32.000]   Because everybody, the cats out of the bag, once they try to do, once they try to use those exploits.
[00:09:32.000 --> 00:09:41.000]   That's why those NSO group exploits are so, are millions of dollars because once the nation state uses it, the risk is now the cats out of the bag and will be defended against.
[00:09:41.000 --> 00:09:42.000]   So uses...
[00:09:42.000 --> 00:09:43.000]   Right?
[00:09:43.000 --> 00:09:44.000]   They don't last that long though.
[00:09:44.000 --> 00:09:45.000]   They don't last that long.
[00:09:45.000 --> 00:09:46.000]   No.
[00:09:46.000 --> 00:09:47.000]   These types of exploits.
[00:09:47.000 --> 00:09:48.000]   Yourities are in and out most of the time.
[00:09:48.000 --> 00:09:55.000]   So I don't, like, sitting on them for too long is going to be, you know, they'll end up being plugged and then they'll have to go and do a whole bunch of other work to figure out another exploit.
[00:09:55.000 --> 00:10:03.000]   So I think, you know, I kind of think that I feel like this whole thing, you know, now it's by the current administration around this.
[00:10:03.000 --> 00:10:10.000]   Yeah, Biden actually gave a speech warning last week saying, "I've previously warned about the potential that Russia conduct malicious cyber activity.
[00:10:10.000 --> 00:10:12.000]   It's part of Russia's playbook.
[00:10:12.000 --> 00:10:14.000]   Today I'm reiterating those warnings.
[00:10:14.000 --> 00:10:23.000]   This was a week ago Monday based on a, this is the important line, evolving intelligence that the Russian government is exploring options for potential cyber attacks.
[00:10:23.000 --> 00:10:27.000]   If you go to the CSA page, big sign on the front page.
[00:10:27.000 --> 00:10:30.000]   This is the Cybersecurity Infrastructure Security Agency.
[00:10:30.000 --> 00:10:32.000]   It says, "Shields up.
[00:10:32.000 --> 00:10:35.000]   They want everybody to protect themselves."
[00:10:35.000 --> 00:10:36.000]   So it's your...
[00:10:36.000 --> 00:10:37.000]   So what is it?
[00:10:37.000 --> 00:10:38.000]   So, what do you think?
[00:10:38.000 --> 00:10:42.000]   Do you agree with Alan that the Russians are reluctant to use these because they don't want to waste them?
[00:10:42.000 --> 00:10:52.000]   You know, I think that they're either reluctant or they're holding back, but I do think that, you know, obviously when there's a war going on, obviously this country's like Russia, like China,
[00:10:52.000 --> 00:10:59.000]   will go and do exploits and do hacking and cyber threats around the world just to pull the eyes off of their war.
[00:10:59.000 --> 00:11:01.000]   And I feel like they're going to start doing this no matter what.
[00:11:01.000 --> 00:11:02.000]   That's a distraction.
[00:11:02.000 --> 00:11:03.000]   That's a distraction.
[00:11:03.000 --> 00:11:12.000]   And I feel like organizations, if they're not aware of this, of this threat already, and haven't taken the steps, even before the president's warning, you're already asking, you're already kind of in a world of hurt.
[00:11:12.000 --> 00:11:18.000]   So I think, you know, I think the, it's nice that the administration puts something out there and said, "Hey, there's a threat."
[00:11:18.000 --> 00:11:22.000]   I think it's kind of a little bit kind of like propaganda, sort of speaking.
[00:11:22.000 --> 00:11:22.000]   Yeah.
[00:11:22.000 --> 00:11:23.000]   Owners, almost.
[00:11:23.000 --> 00:11:26.000]   It seems a risky thing to do because it's going to scare people.
[00:11:26.000 --> 00:11:27.000]   I get calls now on the radio show.
[00:11:27.000 --> 00:11:29.000]   What are they going to attack?
[00:11:29.000 --> 00:11:30.000]   Right, yeah.
[00:11:30.000 --> 00:11:31.000]   And I mean, certainly we're vulnerable.
[00:11:31.000 --> 00:11:38.000]   Our electric grid is very heterogeneous, which means, you know, there's no one central authority.
[00:11:38.000 --> 00:11:39.000]   There's no one governing.
[00:11:39.000 --> 00:11:41.000]   It's been, in fact, often this privately owned.
[00:11:41.000 --> 00:11:43.000]   We know it's porous.
[00:11:43.000 --> 00:11:46.000]   We've seen malware and a lot of electrical grid installations.
[00:11:46.000 --> 00:11:49.000]   Our financial institutions are entirely computerized.
[00:11:49.000 --> 00:11:50.000]   Hit them.
[00:11:50.000 --> 00:11:52.000]   That could be devastating.
[00:11:52.000 --> 00:11:53.000]   Forget sanctions.
[00:11:53.000 --> 00:11:55.000]   Bring down the financial system.
[00:11:55.000 --> 00:11:59.000]   Our food network is very vulnerable.
[00:11:59.000 --> 00:12:08.000]   Not only electric, you know, completely electrified, electronicized, but there's only five days worth of food at any given time in the supply chain.
[00:12:08.000 --> 00:12:09.000]   That's just three.
[00:12:09.000 --> 00:12:10.000]   We saw what happened.
[00:12:10.000 --> 00:12:15.000]   We saw what happened in, was it last year or 2020 when they attacked,
[00:12:15.000 --> 00:12:20.000]   a company, a gasoline distribution pipeline, colonial pipeline.
[00:12:20.000 --> 00:12:21.000]   Yeah, colonial pipeline.
[00:12:21.000 --> 00:12:24.000]   And they didn't actually take down the pipeline system.
[00:12:24.000 --> 00:12:25.000]   Right.
[00:12:25.000 --> 00:12:26.000]   The building system.
[00:12:26.000 --> 00:12:27.000]   Yeah.
[00:12:27.000 --> 00:12:28.000]   Yeah.
[00:12:28.000 --> 00:12:32.000]   That was a dark side, which was, in fact, a Russian malware operation.
[00:12:32.000 --> 00:12:37.000]   In fact, I know CISA estimates about 75% of all ransomware comes out of Russia.
[00:12:37.000 --> 00:12:41.000]   Whether it's the Russian government or independent operate.
[00:12:41.000 --> 00:12:44.000]   My sense is, I don't know, Alan, what you think, but my sense is it's independent operation.
[00:12:44.000 --> 00:12:51.000]   It's independent operators who are tolerated, if not sanctioned, by the Russian government because of their useful attacks.
[00:12:51.000 --> 00:12:56.000]   It's, as far as attack vectors, it's always like the silliest thing.
[00:12:56.000 --> 00:13:01.000]   Like that example that was just given about, you know, like they got into their IT network and they messed up their billing, right?
[00:13:01.000 --> 00:13:03.000]   It's always the, you always get into the weirdest.
[00:13:03.000 --> 00:13:04.000]   Oh, and how did they get into?
[00:13:04.000 --> 00:13:05.000]   The expecting place.
[00:13:05.000 --> 00:13:06.000]   They got in through.
[00:13:06.000 --> 00:13:07.000]   Yeah.
[00:13:07.000 --> 00:13:08.000]   What was it?
[00:13:08.000 --> 00:13:10.000]   It was a reused, it was a password.
[00:13:10.000 --> 00:13:15.000]   It was a conventional stuffing attack on a password for somebody who didn't work there anymore.
[00:13:15.000 --> 00:13:16.000]   Right.
[00:13:16.000 --> 00:13:20.000]   Who had a VPN access, had used a reused password left.
[00:13:20.000 --> 00:13:22.000]   They never deactivated the account.
[00:13:22.000 --> 00:13:24.000]   It was just sitting there.
[00:13:24.000 --> 00:13:25.000]   Right.
[00:13:25.000 --> 00:13:35.000]   And now with so many people working from home and also using VPNs for work, potentially on that same system that they might be using for personal stuff when they're not on the clock and they've, you know, shut off the VPN, right?
[00:13:35.000 --> 00:13:36.000]   You're off the VPN.
[00:13:36.000 --> 00:13:41.000]   You're not under the umbrella of the corporations network and their firewalls and whatnot.
[00:13:41.000 --> 00:13:42.000]   You're under your own router.
[00:13:42.000 --> 00:13:45.000]   You potentially get exploited there.
[00:13:45.000 --> 00:13:48.000]   Not even be a prior employee, potentially a current employee, right?
[00:13:48.000 --> 00:13:54.000]   Like your personal or your work machine, you can potentially get hacked, you know, when you're not on the clock and then you get on the VPN.
[00:13:54.000 --> 00:14:01.000]   And now if you, if your AV had not picked that up yet, now you have a vector into, you know, potentially into the work system, right?
[00:14:01.000 --> 00:14:06.000]   But that applies across all sorts of industry, right?
[00:14:06.000 --> 00:14:14.000]   Not just Intel or Microsoft or any other kind of those kinds of companies, but like any, any other company where you have some remote workers.
[00:14:14.000 --> 00:14:18.000]   Why do you even imply to the NSA?
[00:14:18.000 --> 00:14:21.000]   Those guys don't do like work from home VPN.
[00:14:21.000 --> 00:14:25.000]   No, yeah, not like the NSA contractor.
[00:14:25.000 --> 00:14:26.000]   Do you remember this?
[00:14:26.000 --> 00:14:28.000]   Take something home on a thumb drive.
[00:14:28.000 --> 00:14:35.000]   He was running at a malware, any malware program called Kaspersky on his home system.
[00:14:35.000 --> 00:14:47.000]   It detected the malware, which was an NSA exploit and uploaded it to Russian servers, where from which it was apparently exfiltrated somehow.
[00:14:47.000 --> 00:14:52.000]   We don't know how, maybe the FSU and released.
[00:14:52.000 --> 00:14:59.000]   Yeah, that would never, could never happen.
[00:14:59.000 --> 00:15:09.000]   I will say this, like despite the fact that Kaspersky is of course like Russian affiliated, like they have a history of being a reasonably good reputation as far as anti-virus.
[00:15:09.000 --> 00:15:10.000]   Not anymore.
[00:15:10.000 --> 00:15:11.000]   Not anymore.
[00:15:11.000 --> 00:15:12.000]   I agree.
[00:15:12.000 --> 00:15:14.000]   In fact, Dvorak used to swear by it.
[00:15:14.000 --> 00:15:15.000]   He said that's the only one I'll use.
[00:15:15.000 --> 00:15:20.000]   But I know, knowing Dvorak, that that was probably because he'd had drinks with Eugene.
[00:15:20.000 --> 00:15:25.000]   In fact, Eugene Kaspersky was a well-liked, beloved guy.
[00:15:25.000 --> 00:15:26.000]   He'd go to Davos.
[00:15:26.000 --> 00:15:27.000]   He'd go to conferences.
[00:15:27.000 --> 00:15:28.000]   He'd buy drinks for journalists.
[00:15:28.000 --> 00:15:34.000]   And I can't tell you how many times over the last five years, I've asked the question, well, should we still be using Kaspersky?
[00:15:34.000 --> 00:15:36.000]   And people say, oh, no, no, Eugene's cool.
[00:15:36.000 --> 00:15:37.000]   He's cool.
[00:15:37.000 --> 00:15:49.000]   It would never, well, maybe his golden aura has worn off because this week the FCC added Kaspersky's anti-virus to its restricted,
[00:15:49.000 --> 00:15:50.000]   restricted list.
[00:15:50.000 --> 00:15:57.000]   The first time anybody but China has been put on this list, the first Russian company on the security risk list.
[00:15:57.000 --> 00:16:05.000]   Well, the thing is, even if Eugene Kaspersky is a good guy and didn't do anything wrong, it's a big company.
[00:16:05.000 --> 00:16:07.000]   He's probably got thousands of employees.
[00:16:07.000 --> 00:16:13.000]   Well, and he's in Russia where there's a law that says if the FSU wants your data, they get it.
[00:16:13.000 --> 00:16:15.000]   It's kind of like China, right?
[00:16:15.000 --> 00:16:19.000]   Kaspersky said they were disappointed with the FCC's action.
[00:16:19.000 --> 00:16:26.000]   By the way, they call themselves the world's largest privately owned security company.
[00:16:26.000 --> 00:16:31.000]   They have 400 million users globally, quarter of a million companies.
[00:16:31.000 --> 00:16:36.000]   They said they were disappointed saying, quote, it was a response to the geopolitical climate.
[00:16:36.000 --> 00:16:37.000]   Well, duh.
[00:16:37.000 --> 00:16:43.000]   Rather than a comprehensive evaluation of the integrity of Kaspersky's products and services.
[00:16:43.000 --> 00:16:45.000]   But Kaspersky's always said that.
[00:16:45.000 --> 00:16:51.000]   US government banned them in 2017 after the NSA breach.
[00:16:51.000 --> 00:17:01.000]   And now the FCC says, which means that no federal agency can or anybody's using federal money can buy a copy of Kaspersky.
[00:17:01.000 --> 00:17:02.000]   What do you think, Alan?
[00:17:02.000 --> 00:17:05.000]   Do you have an opinion on Eugene and the company?
[00:17:05.000 --> 00:17:10.000]   I mean, there's no way to know for sure what level of influence there is, right?
[00:17:10.000 --> 00:17:13.000]   Which seems to be what has led to those decisions.
[00:17:13.000 --> 00:17:18.000]   So it's just, you know, but we just can't condone it to this degree where we want, you know,
[00:17:18.000 --> 00:17:22.000]   or we're recommending our government employees to go and use this antivirus.
[00:17:22.000 --> 00:17:24.000]   If you're going to use one, just don't use that one.
[00:17:24.000 --> 00:17:32.000]   You know, regardless of how good it was, there are still ways, like, if you wanted your file to be scanned by that particular tool,
[00:17:32.000 --> 00:17:37.000]   there's still places online where you can submit a file for analysis and it'll scan it.
[00:17:37.000 --> 00:17:40.000]   It'll bounce it across, you know, 20 different AVs and give you a result.
[00:17:40.000 --> 00:17:42.000]   I think it's a virus total is one of them.
[00:17:42.000 --> 00:17:46.000]   If they're still up, you know, there's ways to get them scanned.
[00:17:46.000 --> 00:17:56.000]   But like, you know, those folks are doing it in such a way that whatever does get scanned by any of those tools is a system that is not going to then talk back to any of those companies.
[00:17:56.000 --> 00:17:57.000]   They sort of isolate it.
[00:17:57.000 --> 00:17:58.000]   Yeah.
[00:17:58.000 --> 00:17:59.000]   Right.
[00:17:59.000 --> 00:18:03.000]   So it's just it's only it's only in and not out sort of a sort of a box.
[00:18:03.000 --> 00:18:04.000]   Right.
[00:18:04.000 --> 00:18:07.000]   And there are plenty of antiviruses.
[00:18:07.000 --> 00:18:11.000]   So, you know, why take a chance, I guess, although Kaspersky is very good.
[00:18:11.000 --> 00:18:14.000]   I mean, it is a very good antivirus.
[00:18:14.000 --> 00:18:15.000]   Yeah.
[00:18:15.000 --> 00:18:16.000]   I don't know.
[00:18:16.000 --> 00:18:20.000]   It's just that, you know, it's just, are they talking, you know, to what degree are they talking back to their government?
[00:18:20.000 --> 00:18:21.000]   Right.
[00:18:21.000 --> 00:18:22.000]   Right.
[00:18:22.000 --> 00:18:23.000]   That's that's the question mark.
[00:18:23.000 --> 00:18:24.000]   FCC.
[00:18:24.000 --> 00:18:25.000]   Yeah.
[00:18:25.000 --> 00:18:26.000]   Well, and that's the thing.
[00:18:26.000 --> 00:18:28.000]   They're not going to tell you why they say this.
[00:18:28.000 --> 00:18:32.000]   It could just be the political climate, I guess.
[00:18:32.000 --> 00:18:34.000]   I would hope they'd have a technical reason.
[00:18:34.000 --> 00:18:44.000]   They say they're relying on findings from DHS and the Committee for Assessment of Foreign Participation in the United States telecommunications service sector.
[00:18:44.000 --> 00:18:46.000]   CAF butts.
[00:18:46.000 --> 00:18:48.000]   [laughter]
[00:18:48.000 --> 00:18:53.000]   I mean, this could legitimately just be down to potential risk and not actual risk.
[00:18:53.000 --> 00:18:58.000]   Like there might not there might not be a shred of like direct evidence that Kaspersky has done whatever.
[00:18:58.000 --> 00:18:59.000]   Right.
[00:18:59.000 --> 00:19:00.000]   Right.
[00:19:00.000 --> 00:19:02.000]   But the potential is there.
[00:19:02.000 --> 00:19:03.000]   Right.
[00:19:03.000 --> 00:19:04.000]   There's nothing to say that tomorrow that couldn't happen.
[00:19:04.000 --> 00:19:09.000]   And you don't want a bunch of government employees all having it on their system and then have to do that damage control and say,
[00:19:09.000 --> 00:19:11.000]   "Oh, everybody, quick.
[00:19:11.000 --> 00:19:16.000]   Uninstall your Kaspersky right away because now somebody flipped a switch and, you know,
[00:19:16.000 --> 00:19:19.000]   it is now has some attack vector via that tool."
[00:19:19.000 --> 00:19:20.000]   Right.
[00:19:20.000 --> 00:19:26.000]   Because that's the worst thing for an exploit style attack vector is the antivirus tool itself.
[00:19:26.000 --> 00:19:27.000]   Right.
[00:19:27.000 --> 00:19:28.000]   That's the one thing you're trusting on your system.
[00:19:28.000 --> 00:19:30.000]   You don't want that to be the thing attacking you.
[00:19:30.000 --> 00:19:33.000]   I honestly, and we have, you know, we use an antivirus here.
[00:19:33.000 --> 00:19:38.000]   We use ESET on our editors computers because they are compelled to use Windows 8.
[00:19:38.000 --> 00:19:39.000]   [laughter]
[00:19:39.000 --> 00:19:42.000]   Did we, we rebuilt, we got new Dell workstations.
[00:19:42.000 --> 00:19:45.000]   Did we put Windows 9 on there?
[00:19:45.000 --> 00:19:46.000]   No.
[00:19:46.000 --> 00:19:47.000]   We put 10 on.
[00:19:47.000 --> 00:19:48.000]   Okay.
[00:19:48.000 --> 00:19:50.000]   We're putting 10 on.
[00:19:50.000 --> 00:19:54.000]   But, you know, that's very common in a business where you don't, if you've got a stable system,
[00:19:54.000 --> 00:19:56.000]   you don't want a willing nail.
[00:19:56.000 --> 00:19:57.000]   You say, "Oh, you got an upgrade."
[00:19:57.000 --> 00:20:02.000]   That's normal for normal users, but you don't just want to say willing, "Oh, great."
[00:20:02.000 --> 00:20:05.000]   But at the same time, we run ESET just to be sure.
[00:20:05.000 --> 00:20:11.000]   But normally, I will tell normal people on the radio show, "Don't, you don't need an antivirus."
[00:20:11.000 --> 00:20:13.000]   Microsoft has a very good antivirus.
[00:20:13.000 --> 00:20:19.000]   Anything you, anything you put on your system has the potential for making your system more vulnerable,
[00:20:19.000 --> 00:20:23.000]   less reliable, slow down your CPU and all that stuff.
[00:20:23.000 --> 00:20:30.000]   So don't install anything unnecessary and an antivirus is, do you agree, Alan, for most people unnecessary?
[00:20:30.000 --> 00:20:35.000]   To install an additional antivirus, an addition, or a long side defender?
[00:20:35.000 --> 00:20:36.000]   I personally just use Defender.
[00:20:36.000 --> 00:20:37.000]   Yeah, Defender's fine.
[00:20:37.000 --> 00:20:40.000]   And I don't run one on a Mac.
[00:20:40.000 --> 00:20:44.000]   I think Apple's protections, they're not, they're not really an antivirus, but Apple's protection is sufficient.
[00:20:44.000 --> 00:20:47.000]   But to be honest, I don't run it on Linux either.
[00:20:47.000 --> 00:20:52.000]   I just don't want to put another program on there with deep hooks into the kernel
[00:20:52.000 --> 00:20:54.000]   that could not be reliable.
[00:20:54.000 --> 00:21:03.000]   So the key is to having an OS, running an OS like Linux, which also applies to what's most likely on your home router as well.
[00:21:03.000 --> 00:21:04.000]   Right.
[00:21:04.000 --> 00:21:05.000]   Right.
[00:21:05.000 --> 00:21:06.000]   Most of those are forms of Linux.
[00:21:06.000 --> 00:21:07.000]   And your phone, if you're an antivirus.
[00:21:07.000 --> 00:21:08.000]   Yeah.
[00:21:08.000 --> 00:21:14.000]   I sort of envision, like, nobody's really taken this to heart yet, but I envision this as, remember those pictures back from World War II
[00:21:14.000 --> 00:21:17.000]   where everybody had to sort of chip in and, like, you got victory going.
[00:21:17.000 --> 00:21:21.000]   Make an ammo and, you know, everybody's doing their part to whatever piece of the effort that they can do.
[00:21:21.000 --> 00:21:22.000]   Right.
[00:21:22.000 --> 00:21:29.000]   What I think people really should be doing now, which I don't think enough people are paying attention to is there's an awful lot of people
[00:21:29.000 --> 00:21:32.000]   with routers with multiple year old firmware on them.
[00:21:32.000 --> 00:21:33.000]   Right.
[00:21:33.000 --> 00:21:39.000]   Like, it's just something that nobody thinks of, if it's not something that automatically updates on its own.
[00:21:39.000 --> 00:21:44.000]   And there is basically a Linux machine sitting at the gateway to your house, right?
[00:21:44.000 --> 00:21:46.000]   The way into your house.
[00:21:46.000 --> 00:21:51.000]   And there have been exploits over the past years, and those apply to those routers as well.
[00:21:51.000 --> 00:21:53.000]   There's ways in potentially.
[00:21:53.000 --> 00:21:58.000]   So, yeah, people, like, you want to chip in on your war effort sort of thing.
[00:21:58.000 --> 00:22:01.000]   Update the things in your homes.
[00:22:01.000 --> 00:22:06.000]   And if you're a guy helping out at a small business or whatever, like, make sure the routers update.
[00:22:06.000 --> 00:22:13.000]   That's probably the easiest thing you could do to, you know, stave off potential ways in from anybody.
[00:22:13.000 --> 00:22:14.000]   Not just Russia.
[00:22:14.000 --> 00:22:16.000]   But like, you know, anybody.
[00:22:16.000 --> 00:22:17.000]   That's what shields up is.
[00:22:17.000 --> 00:22:20.000]   It's not just for big businesses for all of us.
[00:22:20.000 --> 00:22:21.000]   I've seen this on Twitter too.
[00:22:21.000 --> 00:22:23.000]   Do you want to do your part in the war effort?
[00:22:23.000 --> 00:22:25.000]   That's your freaking software.
[00:22:25.000 --> 00:22:26.000]   Yeah.
[00:22:26.000 --> 00:22:27.000]   Yeah.
[00:22:27.000 --> 00:22:35.000]   It's true because if you ever, Steve was talking on Tuesday about micro tick routers, which have firmware updates, but people never update them.
[00:22:35.000 --> 00:22:42.000]   And so there's this vast hole that can be co-opted and used for DDoS attacks without your knowledge.
[00:22:42.000 --> 00:22:46.000]   If you apply the update, you'd, the vulnerabilities be gone.
[00:22:46.000 --> 00:22:47.000]   So, do it.
[00:22:47.000 --> 00:22:48.000]   Right.
[00:22:48.000 --> 00:22:56.000]   And that's, and that's the kind of thing that it doesn't necessarily need to be a zero day for something that a country like Russia may have something that they could pull the fire on.
[00:22:56.000 --> 00:22:57.000]   They don't mind exposing that.
[00:22:57.000 --> 00:22:59.000]   It's a well-known exploit.
[00:22:59.000 --> 00:23:00.000]   Been around for years.
[00:23:00.000 --> 00:23:01.000]   Well, no, it's not that.
[00:23:01.000 --> 00:23:11.000]   It's that if they have X number of systems in the US that they own, right, effectively, they're not going to, yeah, they've been in effect about new things.
[00:23:11.000 --> 00:23:16.000]   And in effect about net, they're not going to flip the switch on that until it's something that's really juicy that they want to do.
[00:23:16.000 --> 00:23:17.000]   They're not just going to do it well and nearly.
[00:23:17.000 --> 00:23:31.000]   They're not going to send US botnet machines trying to attack Ukraine right now because the US people would figure out what those were in the meantime and have weeks, you know, to get those machines offline or, you know, attention would be drawn to it at that point.
[00:23:31.000 --> 00:23:32.000]   Right.
[00:23:32.000 --> 00:23:33.000]   And people would fix it.
[00:23:33.000 --> 00:23:34.000]   And you wouldn't want that.
[00:23:34.000 --> 00:23:35.000]   Right.
[00:23:35.000 --> 00:23:45.000]   So that's the kind of thing you need to make sure when it's dormant and not being used yet, but potentially could be used, update the dang devices and, you know, shut those security holes last year.
[00:23:45.000 --> 00:23:50.000]   The FBI was a strangest bullet and sent in a bullet and say, reboot your routers to everybody.
[00:23:50.000 --> 00:23:51.000]   Yep.
[00:23:51.000 --> 00:23:57.000]   Reboot your routers because these in this particular, the Mallee we're talking about wasn't persistent.
[00:23:57.000 --> 00:23:59.000]   It was sat in memory.
[00:23:59.000 --> 00:24:01.000]   So if you just rebooted your router.
[00:24:01.000 --> 00:24:08.000]   This was 2018 May 2018 FBI's urgent request reboot your router to stop Russia linked malware.
[00:24:08.000 --> 00:24:11.000]   And it would go away.
[00:24:11.000 --> 00:24:12.000]   Yeah.
[00:24:12.000 --> 00:24:20.000]   And it was probably a matter of it couldn't get back in because they had, you know, taken over whatever that DNS entry was or whatever something that had to do or that IP address.
[00:24:20.000 --> 00:24:21.000]   Right.
[00:24:21.000 --> 00:24:22.000]   Usually it's whatever that vector is.
[00:24:22.000 --> 00:24:26.000]   They'll figure out some other way to sort of cut it off at the head elsewhere.
[00:24:26.000 --> 00:24:27.000]   Right.
[00:24:27.000 --> 00:24:31.000]   And yeah, just protection in that case could just be a matter of rebooting the router.
[00:24:31.000 --> 00:24:35.000]   I'm sure there was also something where you should update your firmware also.
[00:24:35.000 --> 00:24:36.000]   Yeah.
[00:24:36.000 --> 00:24:37.000]   You might just so you don't get reinfected.
[00:24:37.000 --> 00:24:38.000]   Yes, exactly.
[00:24:38.000 --> 00:24:47.000]   But at the time, the FBI said Russia has a botnet of hundreds of thousands of U.S. routers.
[00:24:47.000 --> 00:24:55.000]   And when they say Russia, they're talking about fancy bear, which is, you know, apt apt apt 28 is another name.
[00:24:55.000 --> 00:25:02.000]   They always have these strange names, which is a Russian group run by the GRU Russian military intelligence.
[00:25:02.000 --> 00:25:07.000]   And they said they had a global network of hundreds of thousands of routers under control.
[00:25:07.000 --> 00:25:09.000]   FBI said, please reboot.
[00:25:09.000 --> 00:25:10.000]   Wow.
[00:25:10.000 --> 00:25:12.000]   So update your router, kids.
[00:25:12.000 --> 00:25:13.000]   That's a good thing.
[00:25:13.000 --> 00:25:14.000]   Yeah.
[00:25:14.000 --> 00:25:15.000]   Well, question for you.
[00:25:15.000 --> 00:25:21.000]   I mean, you know, I have, I use a Nest Wi-Fi mesh system at home, which updates itself.
[00:25:21.000 --> 00:25:26.000]   And I know I think most mesh systems are Euro and so on, update themselves.
[00:25:26.000 --> 00:25:34.000]   But do most other mainstream routers today, the ones made today, do they, are they now being set up to automatically update their firmware?
[00:25:34.000 --> 00:25:39.000]   Because I know in the past, updating the firmware on a router was a real pain.
[00:25:39.000 --> 00:25:46.000]   And for an average person to do that, you know, I mean, they're more likely to brick it than successfully update.
[00:25:46.000 --> 00:25:47.000]   That's true.
[00:25:47.000 --> 00:25:48.000]   Right.
[00:25:48.000 --> 00:25:55.000]   And many of them, like, I think a lot of the Asus routers, they have the capability to do automatic updates, but I'm not sure that it's the default.
[00:25:55.000 --> 00:25:56.000]   Right.
[00:25:56.000 --> 00:25:57.000]   So you have to go in there.
[00:25:57.000 --> 00:26:06.000]   The real problem is the cheap $54 Linksys routers or micro tick routers, TP-Link routers, where they didn't put that capability.
[00:26:06.000 --> 00:26:07.000]   You're right.
[00:26:07.000 --> 00:26:09.000]   That's a, but that's an expensive router.
[00:26:09.000 --> 00:26:12.000]   One of the reasons I recommend it is because it auto updates.
[00:26:12.000 --> 00:26:21.000]   In fact, there was a flaw that was exposed, it wasn't a zero day, but was reported in the Euro router two years ago.
[00:26:21.000 --> 00:26:28.000]   And by the time it was reported and we were able to tell people about it, we also were able to say, "Don't worry because Euro has pushed out an update that everybody has gotten.
[00:26:28.000 --> 00:26:29.000]   Everybody has."
[00:26:29.000 --> 00:26:33.000]   So, yeah, auto update is a big deal.
[00:26:33.000 --> 00:26:35.000]   I feel like we should require stuff like that.
[00:26:35.000 --> 00:26:41.000]   I mean, if we're going to take this security seriously, it should be kind of a requirement that all IoT devices are going to be able to do.
[00:26:41.000 --> 00:26:44.000]   All IoT devices have auto update facilities.
[00:26:44.000 --> 00:26:49.000]   There is a flip side to that and that is sometimes updates are known to break things.
[00:26:49.000 --> 00:26:50.000]   Right.
[00:26:50.000 --> 00:26:58.000]   So there's some, you know, for the sake of, you know, I knew I was about to be on your show today, do I want my router auto up-playing in this moment?
[00:26:58.000 --> 00:26:59.000]   Right.
[00:26:59.000 --> 00:27:04.000]   Like there's some, you have to have some sort of limitations in place sometimes depending on your, your uptime requirements.
[00:27:04.000 --> 00:27:12.000]   Also hard to convince people if it's not going to affect them, like they're not going to get, they're just being used as a DDoS router.
[00:27:12.000 --> 00:27:15.000]   It's not going to affect your personal security.
[00:27:15.000 --> 00:27:16.000]   It's harder to convince people.
[00:27:16.000 --> 00:27:17.000]   Right.
[00:27:17.000 --> 00:27:18.000]   They need to fix that.
[00:27:18.000 --> 00:27:19.000]   I want to take a little break.
[00:27:19.000 --> 00:27:22.000]   When we come back, I want to talk about LAPSUS.
[00:27:22.000 --> 00:27:33.000]   This was the hacking group that broke into Octa, broke into Microsoft, stole source code, apparently in Vidia.
[00:27:33.000 --> 00:27:39.000]   Samsung, the list of long lists, LAPSUS dollar sign.
[00:27:39.000 --> 00:27:43.000]   Wonder what they're, well, huh?
[00:27:43.000 --> 00:27:48.000]   And the great story about the guy behind it.
[00:27:48.000 --> 00:27:52.000]   I'll give you a hint, not a Russian.
[00:27:52.000 --> 00:27:56.000]   But first a word from our sponsor and actually I want to give these guys a huge plug.
[00:27:56.000 --> 00:28:01.000]   Not only do I believe in this product and use this product and Lisa uses this product.
[00:28:01.000 --> 00:28:03.000]   We talk about it all the time, Grammarly.
[00:28:03.000 --> 00:28:10.000]   But this is one of the big Ukraine companies that is struggling during this war.
[00:28:10.000 --> 00:28:12.000]   They do, I love Grammarly for many reasons.
[00:28:12.000 --> 00:28:16.000]   They're also written in LISP, which I really, really like.
[00:28:16.000 --> 00:28:17.000]   Really it's a writing tool.
[00:28:17.000 --> 00:28:20.000]   For instance, Lisa's spelling's great.
[00:28:20.000 --> 00:28:22.000]   Her grammar's pretty good.
[00:28:22.000 --> 00:28:30.000]   But what Grammarly does, and this is very useful, is as she's writing emails to employees, it'll sometimes say, you know, that's a little brusque.
[00:28:30.000 --> 00:28:33.000]   Maybe you'd like to soften it a little bit.
[00:28:33.000 --> 00:28:34.000]   And she always laughs.
[00:28:34.000 --> 00:28:39.000]   She says, well, yeah, I mean, I'm just very straightforward, but she'll add a little please and thank you.
[00:28:39.000 --> 00:28:41.000]   And thank you, Grammarly, for doing that.
[00:28:41.000 --> 00:28:45.000]   Grammarly has a free version and a premium version.
[00:28:45.000 --> 00:28:49.000]   You can even use it on the website, which is really cool.
[00:28:49.000 --> 00:28:51.000]   The thing I'm talking about is the tone detector.
[00:28:51.000 --> 00:28:53.000]   That's free.
[00:28:53.000 --> 00:28:59.000]   It helps you say what you mean in the appropriate tone and never, uh, never,
[00:28:59.000 --> 00:29:00.000]   never misinterpreted.
[00:29:00.000 --> 00:29:08.000]   Nowadays, as we use a lot of texts, especially emails to communicate, it's very easy to miss the tone in email.
[00:29:08.000 --> 00:29:15.000]   So it's really important when you're writing your emails that you express it in, in a way that is not going to raise somebody's
[00:29:15.000 --> 00:29:17.000]   hackles on the other end.
[00:29:17.000 --> 00:29:18.000]   They have premium tone adjustments.
[00:29:18.000 --> 00:29:19.000]   They go even further.
[00:29:19.000 --> 00:29:24.000]   This is what Lisa uses to help ensure you're being clear and assertive in your emails.
[00:29:24.000 --> 00:29:25.000]   Persuasive.
[00:29:25.000 --> 00:29:29.000]   They help you be persuasive with a confident and polished tone.
[00:29:29.000 --> 00:29:32.000]   They'll suggest more decisive phrases and word choices.
[00:29:32.000 --> 00:29:33.000]   I really love that.
[00:29:33.000 --> 00:29:40.000]   Grammarly also has a premium feature called full sentence rewrite that will take a sentence that's maybe a little run on
[00:29:40.000 --> 00:29:41.000]   and a little convoluted.
[00:29:41.000 --> 00:29:43.000]   And I'm always impressed.
[00:29:43.000 --> 00:29:44.000]   Come back with a sentence.
[00:29:44.000 --> 00:29:47.000]   If you send it this way, it'd be much clearer and it's true.
[00:29:47.000 --> 00:29:50.000]   Rewriting those hard to read sentences.
[00:29:50.000 --> 00:29:57.000]   They also have clarity suggestions in the premium version that simplify sentences and get your point across faster by
[00:29:57.000 --> 00:30:01.000]   cutting unnecessary words and jargon to make your sentences easy to follow.
[00:30:01.000 --> 00:30:03.000]   I wish everybody in business used this.
[00:30:03.000 --> 00:30:06.000]   The business jargon drives me nuts.
[00:30:06.000 --> 00:30:08.000]   And you use it because everybody uses it.
[00:30:08.000 --> 00:30:09.000]   It's unconscious.
[00:30:09.000 --> 00:30:11.000]   It's nice though to get a little nudge.
[00:30:11.000 --> 00:30:12.000]   And you know what?
[00:30:12.000 --> 00:30:13.000]   It's not a human.
[00:30:13.000 --> 00:30:18.000]   It's just on your computer, a little nudge saying, you know, you shouldn't really say, run this up the flagpole to see
[00:30:18.000 --> 00:30:19.000]   who salutes.
[00:30:19.000 --> 00:30:25.000]   You might want to try another way of saying that and even gives you one click replacement that you can just, it saves
[00:30:25.000 --> 00:30:26.000]   your time.
[00:30:26.000 --> 00:30:27.000]   It's free to use.
[00:30:27.000 --> 00:30:30.000]   You download it, integrate it into your daily life.
[00:30:30.000 --> 00:30:36.000]   It works wherever you are in Gmail, for instance, to help you work more efficiently on any of your projects.
[00:30:36.000 --> 00:30:42.000]   I just think it's a great solution and I really want to support these guys because as a Ukraine based company,
[00:30:42.000 --> 00:30:46.000]   I bet you they would love a little extra love from our audience.
[00:30:46.000 --> 00:30:56.000]   So go to Grammarly, G-R-A-M-M-A-R-L-Y, Grammarly.com/twit, sign up for that free account, get through those emails
[00:30:56.000 --> 00:31:02.000]   and your work quicker by keeping it concise, confident, and effective with Grammarly.
[00:31:02.000 --> 00:31:06.000]   Go to Grammarly.com/twit to sign up for a free account.
[00:31:06.000 --> 00:31:10.000]   And when you're ready to upgrade to Grammarly Premium, you'll get 20% off.
[00:31:10.000 --> 00:31:12.000]   I think Grammarly is a great choice.
[00:31:12.000 --> 00:31:15.000]   At least get the free version and show them.
[00:31:15.000 --> 00:31:16.000]   We care.
[00:31:16.000 --> 00:31:18.000]   Grammarly.com/twit.
[00:31:18.000 --> 00:31:22.000]   Make sure you do that though so you can get 20% off if you decide to buy.
[00:31:22.000 --> 00:31:23.000]   I'm a big fan.
[00:31:23.000 --> 00:31:25.000]   We use Grammarly throughout the...
[00:31:25.000 --> 00:31:35.000]   I think we have accounts for everybody in the business because nobody needs to suffer from incomplete or unclear emails.
[00:31:35.000 --> 00:31:38.000]   Grammarly.com/twit.
[00:31:38.000 --> 00:31:41.000]   Thank you Grammarly for your support and we support you.
[00:31:41.000 --> 00:31:43.000]   We really do.
[00:31:43.000 --> 00:31:45.000]   We've been using it for years here.
[00:31:45.000 --> 00:31:46.000]   Isn't it great?
[00:31:46.000 --> 00:31:47.000]   Momma.
[00:31:47.000 --> 00:31:50.000]   You know, I first, because I like to think...
[00:31:50.000 --> 00:31:52.000]   I've written a few books.
[00:31:52.000 --> 00:31:54.000]   I like to think I'm a good writer.
[00:31:54.000 --> 00:31:59.000]   Even if you even I go, "Yeah, you're right Grammarly.
[00:31:59.000 --> 00:32:00.000]   Yeah, you're right."
[00:32:00.000 --> 00:32:01.000]   Okay.
[00:32:01.000 --> 00:32:02.000]   Okay.
[00:32:02.000 --> 00:32:03.000]   Lapsas.
[00:32:03.000 --> 00:32:05.000]   We actually talked about this last week.
[00:32:05.000 --> 00:32:10.000]   Bloomberg had a scoop that in fact Lapsas was not a Russian hacking group.
[00:32:10.000 --> 00:32:14.000]   But a 16 year old in England.
[00:32:14.000 --> 00:32:19.000]   Multi-millionaire cyber criminal in his mom's basement.
[00:32:19.000 --> 00:32:21.000]   He lives at home.
[00:32:21.000 --> 00:32:27.000]   He allegedly has amassed a $14 million fortune.
[00:32:27.000 --> 00:32:30.000]   Now you don't want to piss off your fellow hackers.
[00:32:30.000 --> 00:32:33.000]   Apparently he's been named by rival hackers and researchers.
[00:32:33.000 --> 00:32:39.000]   The city of London police say they've arrested seven teenagers in relation to the Lapsas hacking.
[00:32:39.000 --> 00:32:43.000]   But they won't say if he's one of them.
[00:32:43.000 --> 00:32:50.000]   The boy's father told the BBC, "We're concerned and we're trying to keep them away from computers."
[00:32:50.000 --> 00:32:55.000]   You know, there's a tough conversation with your son.
[00:32:55.000 --> 00:33:01.000]   Son, do you have 10 million pounds in a bank account we don't know about?
[00:33:01.000 --> 00:33:03.000]   Lapsas has been really good.
[00:33:03.000 --> 00:33:08.000]   I mean, Lou, I know you know they got the Microsofts.
[00:33:08.000 --> 00:33:11.000]   Holy grail, they got the source code.
[00:33:11.000 --> 00:33:13.000]   Although this happens freely.
[00:33:13.000 --> 00:33:16.000]   I don't think Microsoft really cares that much if you get the source code.
[00:33:16.000 --> 00:33:18.000]   I mean, they obviously it's a trade secret and stuff.
[00:33:18.000 --> 00:33:22.000]   But nobody's going to rebuild Windows 10 from the source code.
[00:33:22.000 --> 00:33:23.000]   Yeah, I mean, you don't really.
[00:33:23.000 --> 00:33:25.000]   I mean, we honestly don't know what source code they got.
[00:33:25.000 --> 00:33:27.000]   I've said something about Bing and some other things.
[00:33:27.000 --> 00:33:31.000]   And we don't know if they got old legacy code that's been sitting there for a while.
[00:33:31.000 --> 00:33:33.000]   We don't know if they got just parts of the code.
[00:33:33.000 --> 00:33:34.000]   We have no idea.
[00:33:34.000 --> 00:33:37.000]   And I think, like you said, security is not necessarily
[00:33:37.000 --> 00:33:38.000]   about the source code.
[00:33:38.000 --> 00:33:39.000]   Go look at open source, right?
[00:33:39.000 --> 00:33:43.000]   There's lots of open source applications out there that are highly secure and the source
[00:33:43.000 --> 00:33:44.000]   is open, right?
[00:33:44.000 --> 00:33:45.000]   Right.
[00:33:45.000 --> 00:33:47.000]   Cortana being the other hand, Windows, that thing.
[00:33:47.000 --> 00:33:52.000]   If you have a source code, wouldn't it be potentially possible to find some vulnerabilities
[00:33:52.000 --> 00:33:53.000]   that others haven't found here?
[00:33:53.000 --> 00:33:55.000]   I think it's most likely who's looking at it, right?
[00:33:55.000 --> 00:33:56.000]   I'm looking for...
[00:33:56.000 --> 00:33:58.000]   I look at it because I like to read the profanities in the comments.
[00:33:58.000 --> 00:34:01.000]   I hope they got the comments, too.
[00:34:01.000 --> 00:34:06.000]   Or you see comments sometimes when you look at source code or somebody says, "I have no
[00:34:06.000 --> 00:34:07.000]   idea why this works."
[00:34:07.000 --> 00:34:08.000]   But leave it in.
[00:34:08.000 --> 00:34:11.000]   We got smart a long time ago.
[00:34:11.000 --> 00:34:14.000]   We have code scanners now that pull the comments out.
[00:34:14.000 --> 00:34:15.000]   Oh, do they?
[00:34:15.000 --> 00:34:16.000]   Oh, yeah.
[00:34:16.000 --> 00:34:17.000]   One of the reasons...
[00:34:17.000 --> 00:34:20.000]   I mean, honestly, I think Microsoft could easily, in fact, they've talked about this release
[00:34:20.000 --> 00:34:21.000]   source code.
[00:34:21.000 --> 00:34:23.000]   But one of the big reasons they don't is they...
[00:34:23.000 --> 00:34:27.000]   Some of the source code is patent and combered, not just by Microsoft, but by third parties.
[00:34:27.000 --> 00:34:30.000]   So you can't just willily nilly say, "Here's the source code."
[00:34:30.000 --> 00:34:34.000]   You don't have the right to release the source code for some of this stuff.
[00:34:34.000 --> 00:34:35.000]   Right.
[00:34:35.000 --> 00:34:40.000]   And as I said, even if you got the full thing, nobody's going to build Windows.
[00:34:40.000 --> 00:34:44.000]   If you had all the source code, could you build it?
[00:34:44.000 --> 00:34:50.000]   I mean, they call that building the world when Microsoft, they basically call it building
[00:34:50.000 --> 00:34:51.000]   the world.
[00:34:51.000 --> 00:34:54.000]   You have to have pretty beefy machines and it takes a really long time.
[00:34:54.000 --> 00:34:57.000]   And I can guarantee you probably would never get all the source code in the right spot
[00:34:57.000 --> 00:34:59.000]   and be able to build everything at once.
[00:34:59.000 --> 00:35:00.000]   You wouldn't be able to.
[00:35:00.000 --> 00:35:01.000]   No.
[00:35:01.000 --> 00:35:04.000]   So I think it's more what you said, Sam.
[00:35:04.000 --> 00:35:06.000]   There are people like me who are just code tourists.
[00:35:06.000 --> 00:35:08.000]   I love looking at that stuff.
[00:35:08.000 --> 00:35:12.280]   One of my favorite books was the source code for the original Unix that was released early
[00:35:12.280 --> 00:35:13.280]   on.
[00:35:13.280 --> 00:35:14.280]   It's fascinating.
[00:35:14.280 --> 00:35:18.280]   But so there's code tourists, but mostly I think it's probably bad guys looking for
[00:35:18.280 --> 00:35:20.280]   holes from a state.
[00:35:20.280 --> 00:35:26.080]   Or maybe someone just wants to compile it to run on their Raspberry Pi.
[00:35:26.080 --> 00:35:31.880]   The teenager who, by the way, they say on the spectrum, he's autistic, uses the online
[00:35:31.880 --> 00:35:35.720]   handle white or breach base.
[00:35:35.720 --> 00:35:42.120]   The boy told the father of the boy told the BBC, I'd never heard about any of this until
[00:35:42.120 --> 00:35:43.120]   recently.
[00:35:43.120 --> 00:35:46.920]   He's never talked about any hacking, but he is very good on computers and spends a lot
[00:35:46.920 --> 00:35:48.320]   of time on the computer.
[00:35:48.320 --> 00:35:51.440]   I always thought he was playing games.
[00:35:51.440 --> 00:35:52.440]   Under understatement.
[00:35:52.440 --> 00:35:54.200]   Very good on computers.
[00:35:54.200 --> 00:35:58.400]   Seven, the city of London, please say seven people between the ages of 16 and 21 have been
[00:35:58.400 --> 00:35:59.400]   arrested.
[00:35:59.400 --> 00:36:02.320]   They've all been released under investigation.
[00:36:02.320 --> 00:36:05.160]   If he's underage, they can't do a whole lot.
[00:36:05.160 --> 00:36:07.800]   In fact, they can't name him.
[00:36:07.800 --> 00:36:10.640]   He tends to special educational school in Oxford.
[00:36:10.640 --> 00:36:14.040]   His dad said, "We're going to try to stop him from going on computers."
[00:36:14.040 --> 00:36:18.920]   The BBC has also spoken to the boy's mother, who did not want to comment.
[00:36:18.920 --> 00:36:23.080]   He was doxxed on a hacker site after falling out with business partners.
[00:36:23.080 --> 00:36:24.080]   Wow.
[00:36:24.080 --> 00:36:25.240]   That is impressive.
[00:36:25.240 --> 00:36:29.800]   Just the age range of several of them.
[00:36:29.800 --> 00:36:35.320]   For some of the stuff to really wrap your head around it, it takes a few years to get
[00:36:35.320 --> 00:36:40.680]   well-versed enough in all of the aspects of that arena.
[00:36:40.680 --> 00:36:45.480]   Unless you're doing the script kitty style thing, where you just come across some exploits
[00:36:45.480 --> 00:36:48.080]   and try to use them.
[00:36:48.080 --> 00:36:50.600]   The learning is not very much for that, but these guys...
[00:36:50.600 --> 00:36:52.760]   He doesn't sound like a script.
[00:36:52.760 --> 00:36:53.760]   Exactly.
[00:36:53.760 --> 00:36:57.080]   They would have had to come up with some stuff to be this effective.
[00:36:57.080 --> 00:37:00.360]   That's pretty impressive, given the ages, especially.
[00:37:00.360 --> 00:37:08.200]   The Chief Research Officer at Unit 221B, which is a cybersecurity investigation company,
[00:37:08.200 --> 00:37:09.200]   said we've had his name...
[00:37:09.200 --> 00:37:10.200]   It's a Baker Street.
[00:37:10.200 --> 00:37:11.200]   221B.
[00:37:11.200 --> 00:37:12.200]   Oh, I get it.
[00:37:12.200 --> 00:37:13.200]   It's a spherical.
[00:37:13.200 --> 00:37:14.200]   It's a journal.
[00:37:14.200 --> 00:37:16.760]   It's like Holmes reference.
[00:37:16.760 --> 00:37:18.680]   I didn't pick up on that.
[00:37:18.680 --> 00:37:23.680]   They said we've had his name since the middle of last year, and we identified him before
[00:37:23.680 --> 00:37:25.760]   his doxing.
[00:37:25.760 --> 00:37:31.200]   They've been working with a security company Palo Alto, and they watched him on his exploits
[00:37:31.200 --> 00:37:36.200]   throughout 2021, periodically sending law enforcement a heads up about the latest crimes.
[00:37:36.200 --> 00:37:38.480]   I don't know why they didn't stop him.
[00:37:38.480 --> 00:37:40.160]   Why would you not stop him?
[00:37:40.160 --> 00:37:43.680]   You want to roll up the whole evidence?
[00:37:43.680 --> 00:37:44.680]   Yeah.
[00:37:44.680 --> 00:37:45.680]   Yeah.
[00:37:45.680 --> 00:37:51.480]   You might not have done something egregious enough to warrant knocking on their door or
[00:37:51.480 --> 00:37:52.480]   something.
[00:37:52.480 --> 00:37:53.480]   They have it.
[00:37:53.480 --> 00:37:58.800]   So has Microsoft or Nvidia or Intel given this kid a job offer yet?
[00:37:58.800 --> 00:38:00.320]   You know that's next.
[00:38:00.320 --> 00:38:02.120]   You know that's next.
[00:38:02.120 --> 00:38:05.840]   The fact that he didn't have such good, upset means he was just...
[00:38:05.840 --> 00:38:11.880]   As with a lot of kids who hack, this was fun for him, although he didn't accumulate
[00:38:11.880 --> 00:38:12.880]   $14 million.
[00:38:12.880 --> 00:38:17.160]   That sounds like fun to me.
[00:38:17.160 --> 00:38:19.360]   The maturity was not that high with this group.
[00:38:19.360 --> 00:38:21.560]   I mean, they glowed a bunch.
[00:38:21.560 --> 00:38:22.560]   Yeah.
[00:38:22.560 --> 00:38:24.200]   I mean, they were gloating a bunch about it.
[00:38:24.200 --> 00:38:25.200]   Yeah.
[00:38:25.200 --> 00:38:26.200]   Everywhere, right.
[00:38:26.200 --> 00:38:27.200]   It's interesting.
[00:38:27.200 --> 00:38:31.960]   The kids could be that sophisticated, that skilled, not a nation state hacker, just some
[00:38:31.960 --> 00:38:35.360]   kids in their basement, their mom's basement.
[00:38:35.360 --> 00:38:37.600]   They hacked almost everybody.
[00:38:37.600 --> 00:38:40.200]   Samsung got hacked and Nvidia got hacked.
[00:38:40.200 --> 00:38:41.640]   Microsoft.
[00:38:41.640 --> 00:38:45.200]   The one that concerns people the most is Okta.
[00:38:45.200 --> 00:38:47.280]   Why is that an issue?
[00:38:47.280 --> 00:38:48.640]   Lou?
[00:38:48.640 --> 00:38:55.960]   So Okta, they have this thing called the warehouse workforce identity solutions layer, which
[00:38:55.960 --> 00:39:03.120]   is basically a bunch of organizations store their keys to the kingdom on their network.
[00:39:03.120 --> 00:39:08.600]   And so if that type of data was exfiltrated, that means that all of those organizations
[00:39:08.600 --> 00:39:10.360]   are not open to attacks.
[00:39:10.360 --> 00:39:12.480]   And so I think that's why Okta was such a big thing.
[00:39:12.480 --> 00:39:13.960]   Because they're an identity provider.
[00:39:13.960 --> 00:39:18.560]   They're basically the first line of defense for most organizations.
[00:39:18.560 --> 00:39:23.000]   Obviously, if you've been able to do things like MFA and other things, you're in better
[00:39:23.000 --> 00:39:24.000]   shape.
[00:39:24.000 --> 00:39:28.760]   But in the same sense, these types of keys allow for services to talk to things, right?
[00:39:28.760 --> 00:39:33.600]   So you can have special certificates and keys that can have services to talk to your data
[00:39:33.600 --> 00:39:35.000]   and so on and so forth.
[00:39:35.000 --> 00:39:36.240]   So Okta manages all that.
[00:39:36.240 --> 00:39:38.360]   So people will worry about that.
[00:39:38.360 --> 00:39:43.120]   It looks like they said, "Hey, this wasn't affected at all."
[00:39:43.120 --> 00:39:44.400]   So don't worry.
[00:39:44.400 --> 00:39:46.200]   But again, it could have been.
[00:39:46.200 --> 00:39:47.200]   Yeah.
[00:39:47.200 --> 00:39:52.240]   According to Hawkeda's chief security officer, David Bradbury, the hackers had accessed,
[00:39:52.240 --> 00:39:53.760]   this is just what you were talking about, Alan.
[00:39:53.760 --> 00:40:00.000]   The computer of a customer support engineer working for the subprocessor over a five-day
[00:40:00.000 --> 00:40:05.800]   period back in January, the attack had been, quote, "analogist to walking away from your
[00:40:05.800 --> 00:40:11.680]   computer at a coffee shop whereby a stranger has, virtually in this case, sat down at
[00:40:11.680 --> 00:40:13.320]   your machine and is using the master keyboard.
[00:40:13.320 --> 00:40:15.400]   It was contained quickly.
[00:40:15.400 --> 00:40:20.320]   The guy did not have so-called god-like access.
[00:40:20.320 --> 00:40:23.480]   So Okta itself not breached.
[00:40:23.480 --> 00:40:30.400]   However, worst case, they said 366 clients were affected.
[00:40:30.400 --> 00:40:31.400]   Yeah.
[00:40:31.400 --> 00:40:34.800]   I mean, thinking about it, it could be purely coincidence that it just happened to be that
[00:40:34.800 --> 00:40:35.800]   person.
[00:40:35.800 --> 00:40:36.800]   Yeah.
[00:40:36.800 --> 00:40:37.800]   Right.
[00:40:37.800 --> 00:40:40.240]   You would hope that the people with the higher access would have better safeguards in place.
[00:40:40.240 --> 00:40:45.040]   But that's what I was just saying before, where it's always the silliest thing where
[00:40:45.040 --> 00:40:49.320]   you don't expect a particular kind of exploit.
[00:40:49.320 --> 00:40:54.560]   I mean, heck, there was the closest that my network here ever came to be in compromise
[00:40:54.560 --> 00:40:57.960]   was I was about to get out from my computer and my mouse moved.
[00:40:57.960 --> 00:40:58.960]   Yeah.
[00:40:58.960 --> 00:40:59.960]   Right?
[00:40:59.960 --> 00:41:00.960]   Not a good thing.
[00:41:00.960 --> 00:41:04.880]   Yeah, yeah, I just heard a noose, so there was already a fine thing going just for me
[00:41:04.880 --> 00:41:07.120]   talking about it, right?
[00:41:07.120 --> 00:41:10.800]   And I was already standing up, so I just casually walked right around to the back of
[00:41:10.800 --> 00:41:15.960]   my computer and yanked out the network cable because I was like, "Okay, what's going on
[00:41:15.960 --> 00:41:16.960]   here?"
[00:41:16.960 --> 00:41:21.840]   Yeah, and that computer did not go back on my network until everything was completely
[00:41:21.840 --> 00:41:22.840]   wiped.
[00:41:22.840 --> 00:41:24.760]   Did you have a remote access Trojan on there?
[00:41:24.760 --> 00:41:26.080]   Did you find it?
[00:41:26.080 --> 00:41:27.080]   Yeah.
[00:41:27.080 --> 00:41:28.080]   Yeah.
[00:41:28.080 --> 00:41:29.080]   It was a rat.
[00:41:29.080 --> 00:41:30.680]   I don't know how it got on there, and it wasn't anywhere else on my network.
[00:41:30.680 --> 00:41:31.680]   Wow.
[00:41:31.680 --> 00:41:32.680]   But if you can get one, just...
[00:41:32.680 --> 00:41:33.680]   But, you know, right?
[00:41:33.680 --> 00:41:34.680]   Yeah.
[00:41:34.680 --> 00:41:37.440]   And actually, Microsoft or Intel is probably a target.
[00:41:37.440 --> 00:41:39.440]   People are trying all the time, you know, with...
[00:41:39.440 --> 00:41:40.440]   Oh, this was...
[00:41:40.440 --> 00:41:44.440]   I was like, nobody random guy at PC Per, you know, that wasn't...
[00:41:44.440 --> 00:41:46.360]   You know, this was years ago.
[00:41:46.360 --> 00:41:49.480]   There is bragging rights and hacking Alan Tonto's computer.
[00:41:49.480 --> 00:41:50.480]   I guess.
[00:41:50.480 --> 00:41:53.560]   Well, they got to move my mouse for about six seconds.
[00:41:53.560 --> 00:41:54.560]   Congratulations.
[00:41:54.560 --> 00:41:55.560]   Okay, a little tip.
[00:41:55.560 --> 00:41:56.560]   Good job.
[00:41:56.560 --> 00:41:59.880]   If you're living in your mom's basement, do not move the mouse, okay?
[00:41:59.880 --> 00:42:04.280]   You can give a whiz also, yes.
[00:42:04.280 --> 00:42:06.880]   Stay away from the mouse.
[00:42:06.880 --> 00:42:07.880]   That's hysterical.
[00:42:07.880 --> 00:42:08.880]   That's hysterical.
[00:42:08.880 --> 00:42:11.480]   Most of these organizations, Leo, they implement...
[00:42:11.480 --> 00:42:14.920]   I mean, we talked about this on the show all the time, is Zero Trust, where, like, even
[00:42:14.920 --> 00:42:20.040]   if this support person had any access to anything, the next time they accessed something
[00:42:20.040 --> 00:42:24.440]   that had specific customer data on it or particular customer data, they should have
[00:42:24.440 --> 00:42:25.440]   popped up another thing.
[00:42:25.440 --> 00:42:28.920]   Hey, make sure your identity is identified or, you know, that kind of thing.
[00:42:28.920 --> 00:42:33.720]   So I can't imagine Octa doesn't have these systems in place, which is why I'm pretty
[00:42:33.720 --> 00:42:35.160]   sure they got nothing.
[00:42:35.160 --> 00:42:36.160]   Right.
[00:42:36.160 --> 00:42:42.120]   Yeah, one hopes, you know, especially a company like Octa or Duo, which they're there to be
[00:42:42.120 --> 00:42:47.400]   an added layer of security to companies that are relying on them, would have themselves
[00:42:47.400 --> 00:42:52.400]   very good security practices.
[00:42:52.400 --> 00:42:53.800]   One would hope.
[00:42:53.800 --> 00:42:58.680]   We've seen situations where that's not the case.
[00:42:58.680 --> 00:43:04.120]   I think, you know, one part, one problem here, though, is you've got all of these different
[00:43:04.120 --> 00:43:09.200]   companies that are being breached in different ways.
[00:43:09.200 --> 00:43:14.840]   And, you know, modern systems are really complex and often include components from a lot of
[00:43:14.840 --> 00:43:15.840]   different vendors.
[00:43:15.840 --> 00:43:20.000]   You know, you may have, you know, you can have some stuff from Octa, some stuff from Microsoft,
[00:43:20.000 --> 00:43:23.160]   maybe some Nvidia stuff somewhere in the stack.
[00:43:23.160 --> 00:43:28.200]   And you know, if you start finding holes in different parts of it, you know, I think
[00:43:28.200 --> 00:43:33.600]   you talked earlier, you know, about kind of, you know, finding, you know, that, you know,
[00:43:33.600 --> 00:43:39.520]   starting off with, you know, an unused VPN account, you know, and then finding your, you
[00:43:39.520 --> 00:43:44.320]   know, kind of just kind of worming your way through the system through all these different
[00:43:44.320 --> 00:43:45.320]   things.
[00:43:45.320 --> 00:43:46.320]   That's the fun of it.
[00:43:46.320 --> 00:43:50.520]   If you've managed to get into all these different things, you can start to make connections
[00:43:50.520 --> 00:43:51.520]   between them.
[00:43:51.520 --> 00:43:54.920]   I can totally see the pleasure and thrill of that.
[00:43:54.920 --> 00:43:55.920]   Right.
[00:43:55.920 --> 00:43:59.000]   It's like an adventure game I got in here.
[00:43:59.000 --> 00:44:00.160]   Let's see what else I can do.
[00:44:00.160 --> 00:44:04.600]   And I don't think a lot of times, especially these people, these teenagers, you know, younger
[00:44:04.600 --> 00:44:07.640]   people, they're not connecting the dots.
[00:44:07.640 --> 00:44:08.640]   It's just fun for them.
[00:44:08.640 --> 00:44:15.160]   I, you know, I talked to Mitnick and Adrian Lamo and many others who are very skilled guys,
[00:44:15.160 --> 00:44:17.600]   Kevin Polson, it was fun for them.
[00:44:17.600 --> 00:44:20.440]   Even Wozniak used to do this as a kid.
[00:44:20.440 --> 00:44:22.280]   And it was an adventure, right?
[00:44:22.280 --> 00:44:26.320]   But if it, you know, it might, it might be fun for these guys, but if they start releasing
[00:44:26.320 --> 00:44:30.280]   this code or putting it, you know, somewhere in a GitHub repository or wherever it might
[00:44:30.280 --> 00:44:36.120]   be, you know, somebody else who wants to do something more nefarious with it could take
[00:44:36.120 --> 00:44:39.040]   that and then start, you know, connecting the dots.
[00:44:39.040 --> 00:44:40.040]   Oh, absolutely.
[00:44:40.040 --> 00:44:41.040]   That's not saying real rest.
[00:44:41.040 --> 00:44:42.920]   I've been saying it's a good thing.
[00:44:42.920 --> 00:44:47.320]   But on the other hand, I am saying it's probably be great to find an outlet for people like
[00:44:47.320 --> 00:44:53.360]   that with skills like that, that's just as fun because it's, that's those are good skills
[00:44:53.360 --> 00:44:54.360]   as a value.
[00:44:54.360 --> 00:44:58.080]   How did you become a heads, how did you become a professional hacker, Alan?
[00:44:58.080 --> 00:45:01.040]   Well, I was.
[00:45:01.040 --> 00:45:02.040]   I wasn't.
[00:45:02.040 --> 00:45:03.040]   We studied school.
[00:45:03.040 --> 00:45:05.080]   Did just the Navy teach you?
[00:45:05.080 --> 00:45:06.320]   Where did you learn that?
[00:45:06.320 --> 00:45:07.320]   Okay.
[00:45:07.320 --> 00:45:12.480]   So, when, so I was running reactors on subs and then I transitioned over to do the network
[00:45:12.480 --> 00:45:16.440]   stuff that they don't necessarily teach you how to be a hacker right away.
[00:45:16.440 --> 00:45:19.520]   You know, you have to sort of move into the positions where you would have to do more
[00:45:19.520 --> 00:45:22.600]   and more of that sort of thing and then sort of get trained along the way.
[00:45:22.600 --> 00:45:27.440]   But just in order to make that first step and be in that, that rating, which is like
[00:45:27.440 --> 00:45:34.600]   a job description in the, the Navy to do the network jobs in general, there was a school,
[00:45:34.600 --> 00:45:39.360]   like a, you know, a couple of months school with the final exam was actually, here's these
[00:45:39.360 --> 00:45:44.320]   few sheets of paper of network traffic that you happen to have sniffed come across a network,
[00:45:44.320 --> 00:45:47.080]   raw out the diagram of all the systems on the network.
[00:45:47.080 --> 00:45:48.080]   That's right.
[00:45:48.080 --> 00:45:49.080]   Yeah.
[00:45:49.080 --> 00:45:51.560]   And so, and that's where you were talking about earlier where it's like there, for some
[00:45:51.560 --> 00:45:52.560]   people this is fun.
[00:45:52.560 --> 00:45:55.880]   And I mean, that final exam, even though it was arduous and took me a few hours to do,
[00:45:55.880 --> 00:45:58.840]   but it was, you know, it was a pain, but it was kind and interesting.
[00:45:58.840 --> 00:45:59.840]   Yeah.
[00:45:59.840 --> 00:46:00.840]   Yeah.
[00:46:00.840 --> 00:46:01.840]   Yeah.
[00:46:01.840 --> 00:46:04.000]   It's, you know, I took, I took just this, you know, some network traffic of somebody that
[00:46:04.000 --> 00:46:08.360]   was like, you know, outputting a config of a router and I turned it into an entire network
[00:46:08.360 --> 00:46:14.280]   diagram, you know, just from some lines of, you know, addresses and whatnot.
[00:46:14.280 --> 00:46:18.800]   But that's not, you know, that's mostly for defense or just understanding networking,
[00:46:18.800 --> 00:46:19.800]   right?
[00:46:19.800 --> 00:46:22.800]   That's sort of baseline fundamentals, which you would then build if you went and worked
[00:46:22.800 --> 00:46:26.160]   somewhere where they were doing more hacking style things, then you would have to go to
[00:46:26.160 --> 00:46:28.880]   more schools and build up your, your knowledge more, right?
[00:46:28.880 --> 00:46:32.360]   All the schools that I went to were more along the lines of reverse engineering and
[00:46:32.360 --> 00:46:34.600]   like defense, things like that.
[00:46:34.600 --> 00:46:39.240]   But we did have red team, like people in the building, they call them red teams.
[00:46:39.240 --> 00:46:41.240]   And that's a, that's not just in the military.
[00:46:41.240 --> 00:46:42.240]   I mean, there's civilian.
[00:46:42.240 --> 00:46:43.240]   Oh, yeah.
[00:46:43.240 --> 00:46:44.440]   Companies that do red teaming.
[00:46:44.440 --> 00:46:48.120]   And that's the kind of thing where those, where those kids would do great at, right?
[00:46:48.120 --> 00:46:49.880]   Like go work there.
[00:46:49.880 --> 00:46:52.600]   You could potentially make a heck of a lot of money.
[00:46:52.600 --> 00:46:57.760]   You know, not maybe not the exploit of levels of money that those kids were making, sort
[00:46:57.760 --> 00:47:01.480]   of blackmailing people, but 14 millions, a little more than any of these.
[00:47:01.480 --> 00:47:02.480]   Yeah.
[00:47:02.480 --> 00:47:05.720]   You could certainly make an a good, honest living.
[00:47:05.720 --> 00:47:10.080]   If you have a sharp skill set doing that type of, that type of exploit work, and in
[00:47:10.080 --> 00:47:14.320]   those cases, you would be doing it legally with the permission of the companies who you're
[00:47:14.320 --> 00:47:19.000]   contracting with, you know, where they basically say, look, we want you to attack us.
[00:47:19.000 --> 00:47:22.240]   You know, here's the, where's the window of time where you're allowed to do it.
[00:47:22.240 --> 00:47:25.480]   Here's the boundaries where, you know, we don't want you to like shut all of our servers
[00:47:25.480 --> 00:47:27.760]   off, please, you know, that kind of the thing.
[00:47:27.760 --> 00:47:34.360]   The early guys were into the system that they were looking at was the phone company.
[00:47:34.360 --> 00:47:40.560]   The, the, you know, Mabel was a fascinating kind of network problem, kind of like that
[00:47:40.560 --> 00:47:44.120]   piece of paper problem you were given, where they were trying to figure out how it works.
[00:47:44.120 --> 00:47:48.640]   And I remember John Draper, better known as Captain Crunch, telling me that they used
[00:47:48.640 --> 00:47:52.920]   to dumpster dive behind the phone company looking for manuals.
[00:47:52.920 --> 00:47:56.280]   And when they found the manuals, they would, they would pour through them.
[00:47:56.280 --> 00:48:00.160]   I mean, stuff that you and I would look at and go, good Lord, who cares?
[00:48:00.160 --> 00:48:02.040]   And they would pour through them.
[00:48:02.040 --> 00:48:07.960]   He's the guy who figured out that a 2600 Hertz tone would trigger the switching equipment
[00:48:07.960 --> 00:48:12.240]   to give you access to long distance phone calls for free.
[00:48:12.240 --> 00:48:15.280]   That's why it was named Captain Crunch, because it turned out that was exactly the tone that
[00:48:15.280 --> 00:48:20.360]   the Crunch whistle came in a box of cereal put out.
[00:48:20.360 --> 00:48:26.680]   But they had that same kind of mindset where somehow they were fascinated by complex systems
[00:48:26.680 --> 00:48:29.200]   and deducing how they worked.
[00:48:29.200 --> 00:48:30.200]   Right.
[00:48:30.200 --> 00:48:33.680]   Yeah, there's, there's some, there's a certain subset of folks that just have a really high
[00:48:33.680 --> 00:48:35.080]   aptitude for that sort of thing.
[00:48:35.080 --> 00:48:36.080]   Yeah.
[00:48:36.080 --> 00:48:37.360]   And some people just, just kind of love it.
[00:48:37.360 --> 00:48:38.360]   Yeah.
[00:48:38.360 --> 00:48:39.560]   You know, just, it's a challenge, right?
[00:48:39.560 --> 00:48:44.220]   Like, I had to learn an awful lot of layers of knowledge to understand all the stuff for
[00:48:44.220 --> 00:48:46.680]   reactor theory to run reactors on submarines.
[00:48:46.680 --> 00:48:47.680]   Yeah.
[00:48:47.680 --> 00:48:48.680]   Right.
[00:48:48.680 --> 00:48:49.680]   Yeah.
[00:48:49.680 --> 00:48:50.680]   And then they did an awful series.
[00:48:50.680 --> 00:48:51.680]   Yeah.
[00:48:51.680 --> 00:48:55.400]   They sort of touch on like all the complexities of how did this reactor melt down and we're
[00:48:55.400 --> 00:48:56.760]   all the things that led into it, right?
[00:48:56.760 --> 00:48:59.680]   And that was, you know, that was like a half hour discussion that they did at the end of
[00:48:59.680 --> 00:49:00.680]   that series.
[00:49:00.680 --> 00:49:02.000]   And that was a super oversight.
[00:49:02.000 --> 00:49:03.000]   I love that.
[00:49:03.000 --> 00:49:04.000]   Did you love that though?
[00:49:04.000 --> 00:49:05.000]   Wasn't that a good?
[00:49:05.000 --> 00:49:06.560]   It was, it was excellent.
[00:49:06.560 --> 00:49:07.560]   Yeah.
[00:49:07.560 --> 00:49:09.600]   It was, they, you know, those are all the exact principle.
[00:49:09.600 --> 00:49:10.600]   Everything was correct.
[00:49:10.600 --> 00:49:11.600]   Right.
[00:49:11.600 --> 00:49:12.600]   That's exactly how all that stuff works.
[00:49:12.600 --> 00:49:16.120]   Xenon is a thing that tries to shut the reactor off and all that, all those things are, you
[00:49:16.120 --> 00:49:22.400]   know, they pronounced it the way Russians pronounce it and Xenon, which threw me off.
[00:49:22.400 --> 00:49:26.000]   But yeah, I mean, all that stuff and there's just a certain type of, you know, people with
[00:49:26.000 --> 00:49:31.920]   a certain type of mentality who just really enjoy the, you know, technical something that,
[00:49:31.920 --> 00:49:33.720]   you know, something that has technical manuals, right?
[00:49:33.720 --> 00:49:39.160]   The reactor plants on the sub had just, you know, entire cabinets full of books, right?
[00:49:39.160 --> 00:49:41.720]   For you to study and learn all parts of those systems, right?
[00:49:41.720 --> 00:49:45.920]   So imagine you have this black box of a system like the Malbel thing and you're like, well,
[00:49:45.920 --> 00:49:47.800]   I want to really know how this works, right?
[00:49:47.800 --> 00:49:49.720]   Again, it would be great if they worked there.
[00:49:49.720 --> 00:49:53.080]   They, I'm sure they would be amazing employees and probably do great things for their company,
[00:49:53.080 --> 00:49:57.120]   but from the outside in, you just dumpster dive the manuals and try to learn how the
[00:49:57.120 --> 00:50:00.640]   system works and then figure out ways to, you know, do creative things with it.
[00:50:00.640 --> 00:50:03.960]   There was a great game I played on the Atari.
[00:50:03.960 --> 00:50:06.160]   I think it was called Scram.
[00:50:06.160 --> 00:50:11.920]   It was a classic simulator game where you had, you had to Scram a reactor before it melted
[00:50:11.920 --> 00:50:12.920]   down.
[00:50:12.920 --> 00:50:16.520]   And I'm sure, I mean, it was primitive even compared to the description of how a reactor
[00:50:16.520 --> 00:50:17.520]   works in Chernobyl.
[00:50:17.520 --> 00:50:22.120]   And I don't, I don't think we had any xenon in there, but it was really fun to try to
[00:50:22.120 --> 00:50:27.720]   keep the reactor running without boiling off the liquid or it was really cool.
[00:50:27.720 --> 00:50:28.720]   Yeah.
[00:50:28.720 --> 00:50:29.720]   Yeah.
[00:50:29.720 --> 00:50:32.720]   But I never, I don't think I had that because when I first met you, Alan, you were, you
[00:50:32.720 --> 00:50:39.880]   were talking about, you know, the, the controllers in these SST drives and the variations that
[00:50:39.880 --> 00:50:45.000]   I think even I saw that even then, that kind of fascination with complex systems and how
[00:50:45.000 --> 00:50:47.200]   they work and how they interact.
[00:50:47.200 --> 00:50:50.200]   And that was very much the same sort of thing, right?
[00:50:50.200 --> 00:50:53.640]   Outside looking in, this is a black box.
[00:50:53.640 --> 00:50:55.720]   It's misbehaving in some way.
[00:50:55.720 --> 00:51:00.960]   How do I find out just by poking at it with, you know, asking it to do different types of
[00:51:00.960 --> 00:51:05.640]   requests and then does the performance go up or down after I've done those, right?
[00:51:05.640 --> 00:51:06.840]   That's the same, same sort of thing, right?
[00:51:06.840 --> 00:51:08.320]   You're poking at it with a stick.
[00:51:08.320 --> 00:51:11.000]   See what makes the thing tech, right?
[00:51:11.000 --> 00:51:17.040]   You can, by the way, if you want to play Scram, Chris Crawford's classic game from 1980,
[00:51:17.040 --> 00:51:18.040]   it's on.
[00:51:18.040 --> 00:51:22.440]   Thank you, Brewster Kale Internet Archive.
[00:51:22.440 --> 00:51:24.760]   You know, you know what's, you know what's amazing about this?
[00:51:24.760 --> 00:51:27.480]   Somehow I have never, I did not know that this existed, Leo.
[00:51:27.480 --> 00:51:32.240]   Oh, this is, was it, I was playing in Atari 800.
[00:51:32.240 --> 00:51:33.520]   I had no idea.
[00:51:33.520 --> 00:51:38.760]   And I didn't, you know, thank you to the chat room for finding it for me, building a nuclear
[00:51:38.760 --> 00:51:39.760]   power plant.
[00:51:39.760 --> 00:51:42.520]   And then you have to, you have to keep it running.
[00:51:42.520 --> 00:51:45.360]   Alan, it might have, might have saved you some study time.
[00:51:45.360 --> 00:51:49.800]   It looks like they've just built it randomly.
[00:51:49.800 --> 00:51:53.640]   Chris was kind of a genius game simulator, waiting for NRC license.
[00:51:53.640 --> 00:51:54.960]   I guess you have to get your license.
[00:51:54.960 --> 00:51:55.960]   Oh, there we go.
[00:51:55.960 --> 00:51:56.960]   Oh, there we go.
[00:51:56.960 --> 00:51:57.960]   There we go.
[00:51:57.960 --> 00:51:58.960]   Thank you.
[00:51:58.960 --> 00:51:59.960]   We've got our license.
[00:51:59.960 --> 00:52:01.320]   Now you've got the pressure, the temperature, the workers.
[00:52:01.320 --> 00:52:02.320]   Yeah.
[00:52:02.320 --> 00:52:04.400]   How many megawatt hours you're putting out?
[00:52:04.400 --> 00:52:05.400]   Yeah.
[00:52:05.400 --> 00:52:08.320]   I'm sure it's much simplified, but still, it was a fun game.
[00:52:08.320 --> 00:52:10.560]   Yeah, I mean, that's, that's definitely a reactor.
[00:52:10.560 --> 00:52:11.960]   That's doing some stuff.
[00:52:11.960 --> 00:52:17.360]   You know, I've always wanted to ask somebody who ran a nuclear reactor, how accurate this
[00:52:17.360 --> 00:52:18.360]   was.
[00:52:18.360 --> 00:52:22.400]   I mean, it's got, it's got loops and stuff and there's a huge danger.
[00:52:22.400 --> 00:52:24.040]   And yeah, those are the rods.
[00:52:24.040 --> 00:52:27.520]   See, there's the rods and I can, I can lower them or I can raise them.
[00:52:27.520 --> 00:52:28.520]   Yeah.
[00:52:28.520 --> 00:52:30.520]   Well, I don't understand if they call it Scram.
[00:52:30.520 --> 00:52:34.040]   Isn't the, is it to not call it to make it so you had to scram the reactor?
[00:52:34.040 --> 00:52:35.040]   Like you got to keep it running?
[00:52:35.040 --> 00:52:36.040]   Scram is.
[00:52:36.040 --> 00:52:37.320]   Yeah, that's, I think that's what it is.
[00:52:37.320 --> 00:52:41.600]   I think it starts to overheat and you have to kind of manage the rods and so forth.
[00:52:41.600 --> 00:52:42.600]   Yeah.
[00:52:42.600 --> 00:52:43.600]   Scram, the goal is to scram.
[00:52:43.600 --> 00:52:46.000]   You would just hit scram and then the game would, like I won.
[00:52:46.000 --> 00:52:47.000]   Scram is what?
[00:52:47.000 --> 00:52:49.600]   Pulling the rods completely out so that they reaction it.
[00:52:49.600 --> 00:52:51.600]   No, no, no.
[00:52:51.600 --> 00:52:53.880]   In, in rods go in.
[00:52:53.880 --> 00:52:54.880]   Yes.
[00:52:54.880 --> 00:52:56.960]   Rods go in, but doesn't that increase the reaction?
[00:52:56.960 --> 00:52:59.600]   No, the, well, okay.
[00:52:59.600 --> 00:53:02.120]   The rods don't let this guy run it.
[00:53:02.120 --> 00:53:05.920]   But I thought I was supposed to take them out.
[00:53:05.920 --> 00:53:06.920]   Okay.
[00:53:06.920 --> 00:53:07.920]   Okay.
[00:53:07.920 --> 00:53:10.680]   The control rods are not the fuel rod.
[00:53:10.680 --> 00:53:11.680]   The control rod.
[00:53:11.680 --> 00:53:12.920]   Slow the reaction down.
[00:53:12.920 --> 00:53:13.920]   I got it.
[00:53:13.920 --> 00:53:14.920]   I absorb new trons.
[00:53:14.920 --> 00:53:15.920]   I mean, a half-nium.
[00:53:15.920 --> 00:53:17.680]   They get in the way of the chain reaction.
[00:53:17.680 --> 00:53:18.680]   I get it.
[00:53:18.680 --> 00:53:19.680]   I remember now.
[00:53:19.680 --> 00:53:20.680]   Yes.
[00:53:20.680 --> 00:53:21.680]   Yes.
[00:53:21.680 --> 00:53:22.680]   Yes.
[00:53:22.680 --> 00:53:24.120]   Remember that when you're, you know, when you happen to be touring a reactor plant and
[00:53:24.120 --> 00:53:27.200]   everybody dies and you have to be the guy to save the day.
[00:53:27.200 --> 00:53:28.200]   The rods go in.
[00:53:28.200 --> 00:53:29.200]   In.
[00:53:29.200 --> 00:53:30.200]   Go out.
[00:53:30.200 --> 00:53:31.200]   The control rods.
[00:53:31.200 --> 00:53:32.200]   Okay.
[00:53:32.200 --> 00:53:33.200]   Got it.
[00:53:33.200 --> 00:53:34.200]   Okay.
[00:53:34.200 --> 00:53:41.840]   Let's by the way, if Leo's running the reactor, it's time to scram.
[00:53:41.840 --> 00:53:42.840]   Yeah.
[00:53:42.840 --> 00:53:43.840]   Exactly.
[00:53:43.840 --> 00:53:46.280]   Now we know get the hell out quick.
[00:53:46.280 --> 00:53:50.320]   I don't know if you can run far enough or fast enough.
[00:53:50.320 --> 00:53:51.320]   Let's take a little break.
[00:53:51.320 --> 00:53:56.920]   I want to talk about the EU preliminary law, provisional law that Apple is not going to
[00:53:56.920 --> 00:53:59.100]   like that one cotton picking bit.
[00:53:59.100 --> 00:54:02.640]   Alan Amalventano, our submariner is here.
[00:54:02.640 --> 00:54:05.840]   He is a technical analyst at Intel.
[00:54:05.840 --> 00:54:06.840]   And I have to apologize.
[00:54:06.840 --> 00:54:08.480]   You know, we used to have you on all the time.
[00:54:08.480 --> 00:54:11.800]   As soon as you went to Intel, I thought, well, I can't have him on any more.
[00:54:11.800 --> 00:54:16.800]   But thank you for it to Intel for letting you join us and save us from nuclear meltdown.
[00:54:16.800 --> 00:54:17.800]   We appreciate it.
[00:54:17.800 --> 00:54:20.240]   Honestly, most of it was just, I was just busy.
[00:54:20.240 --> 00:54:21.720]   Well, we're glad you're here.
[00:54:21.720 --> 00:54:22.720]   We're with storage.
[00:54:22.720 --> 00:54:23.720]   Thanks.
[00:54:23.720 --> 00:54:24.720]   Glad you're here.
[00:54:24.720 --> 00:54:26.440]   Also with Sam Abul's Samad, he's my car guy.
[00:54:26.440 --> 00:54:30.500]   He's every week on the tech guy radio show.
[00:54:30.500 --> 00:54:33.620]   He has his own podcast called Wheel bearings, Wheel bearings.media.
[00:54:33.620 --> 00:54:37.620]   He is an expert on all things car, principal researcher at Guide House Insights.
[00:54:37.620 --> 00:54:38.620]   Great to have you Sam.
[00:54:38.620 --> 00:54:40.420]   You're in San Diego.
[00:54:40.420 --> 00:54:43.140]   Yeah, actually in Encinitas right now.
[00:54:43.140 --> 00:54:44.140]   Oh, nice.
[00:54:44.140 --> 00:54:45.140]   Love that area.
[00:54:45.140 --> 00:54:46.140]   Yeah.
[00:54:46.140 --> 00:54:50.380]   We'll have a good time also with us from his new home on the East Coast.
[00:54:50.380 --> 00:54:51.380]   You relocated.
[00:54:51.380 --> 00:54:52.380]   Lou Maresca.
[00:54:52.380 --> 00:54:53.380]   I did.
[00:54:53.380 --> 00:54:54.380]   Did you take the kids with you?
[00:54:54.380 --> 00:54:55.380]   I did.
[00:54:55.380 --> 00:54:58.000]   I did take the kids with them, unfortunately.
[00:54:58.000 --> 00:55:01.040]   But yeah, no, you have the sweetest boys.
[00:55:01.040 --> 00:55:02.040]   Are they?
[00:55:02.040 --> 00:55:03.040]   They solve it.
[00:55:03.040 --> 00:55:04.040]   It's fine boys.
[00:55:04.040 --> 00:55:05.040]   Yeah.
[00:55:05.040 --> 00:55:06.040]   Wow.
[00:55:06.040 --> 00:55:07.040]   That keep me real busy.
[00:55:07.040 --> 00:55:08.040]   Wow.
[00:55:08.040 --> 00:55:09.040]   Are you going to keep trying to help you have a girl?
[00:55:09.040 --> 00:55:10.040]   Is that what's going on?
[00:55:10.040 --> 00:55:11.040]   I think we're not going to do that.
[00:55:11.040 --> 00:55:17.680]   And I know you were there were some health issues with some of them, but everybody's doing
[00:55:17.680 --> 00:55:18.680]   well.
[00:55:18.680 --> 00:55:19.680]   Everybody's healthy.
[00:55:19.680 --> 00:55:20.680]   Yes, they are all men didn't.
[00:55:20.680 --> 00:55:21.680]   We're doing well.
[00:55:21.680 --> 00:55:22.680]   Yeah, we're looking forward to summer.
[00:55:22.680 --> 00:55:23.680]   Oh, yeah.
[00:55:23.680 --> 00:55:24.680]   I bet you're on.
[00:55:24.680 --> 00:55:25.680]   Please.
[00:55:25.680 --> 00:55:29.180]   Dad, you did you know about winter?
[00:55:29.180 --> 00:55:30.620]   Are you from the East Coast originally?
[00:55:30.620 --> 00:55:31.620]   Oh, yeah.
[00:55:31.620 --> 00:55:33.020]   I grew up in New York and Massachusetts.
[00:55:33.020 --> 00:55:34.020]   Oh, okay.
[00:55:34.020 --> 00:55:35.020]   Absolutely.
[00:55:35.020 --> 00:55:36.020]   Yeah.
[00:55:36.020 --> 00:55:39.620]   Because I always wonder why somebody would willingly move to Rhode Island.
[00:55:39.620 --> 00:55:41.820]   But I grew up there.
[00:55:41.820 --> 00:55:45.780]   But as soon as I found California, why would you leave California?
[00:55:45.780 --> 00:55:49.940]   But my mom lives just literally like around the corner from you.
[00:55:49.940 --> 00:55:53.180]   So yeah, she does come out and visit some beautiful place.
[00:55:53.180 --> 00:55:54.180]   Yeah, there's beaches.
[00:55:54.180 --> 00:55:56.000]   There's just lots of great stuff here.
[00:55:56.000 --> 00:55:57.000]   It's actually, I love it.
[00:55:57.000 --> 00:56:00.440]   And I do kind of miss that great feeling of fall.
[00:56:00.440 --> 00:56:03.920]   And then of course now is a great time of year because you've been suffering all winter
[00:56:03.920 --> 00:56:05.280]   and the sun starts to shine.
[00:56:05.280 --> 00:56:10.440]   The birds because Robin Redbreast comes out and spring is here.
[00:56:10.440 --> 00:56:18.400]   Great to have all three of you are show today brought to you by streak, not scram, streak
[00:56:18.400 --> 00:56:26.000]   is actually a CRM for Gmail, a customer relationship management tool that you need.
[00:56:26.000 --> 00:56:29.760]   You will love if you use Gmail and business as we do.
[00:56:29.760 --> 00:56:32.920]   We use Google's workspace.
[00:56:32.920 --> 00:56:37.040]   You know, I mean, it's a great tool for business, but there are some things maybe you could
[00:56:37.040 --> 00:56:38.800]   have a little help with.
[00:56:38.800 --> 00:56:43.400]   Streak has been awarded Google's technology partner of the year.
[00:56:43.400 --> 00:56:50.000]   750,000 users, entrepreneurs, small business owners, founders love the idea that you don't
[00:56:50.000 --> 00:56:54.560]   have to leave Gmail to get to your customer information and email.
[00:56:54.560 --> 00:56:55.720]   It's all in one place.
[00:56:55.720 --> 00:56:56.720]   You save time.
[00:56:56.720 --> 00:57:02.480]   You get more responses by tracking emails, sending email merges with automated follow ups.
[00:57:02.480 --> 00:57:08.040]   You ever remember the days of doing a mail merge with, I don't know, Microsoft Word?
[00:57:08.040 --> 00:57:09.480]   Hey, it's a lot easier.
[00:57:09.480 --> 00:57:12.240]   Let me tell you with this, you never have to leave your inbox.
[00:57:12.240 --> 00:57:15.160]   It takes 30 seconds to get started.
[00:57:15.160 --> 00:57:16.840]   Send out your mailings.
[00:57:16.840 --> 00:57:18.880]   Keep track of your customers.
[00:57:18.880 --> 00:57:21.440]   All you have to do is add streaks extension to your browser.
[00:57:21.440 --> 00:57:24.280]   You're ready to go.
[00:57:24.280 --> 00:57:28.640]   Keeping track of your customers is I think the most, you know, just the best way to serve
[00:57:28.640 --> 00:57:32.120]   them so that when you're in contact with them, you know the story, you know the history,
[00:57:32.120 --> 00:57:33.560]   you know them.
[00:57:33.560 --> 00:57:38.800]   It is huge and streak will let you do it so easily, so transparently.
[00:57:38.800 --> 00:57:43.120]   It's easy to run your business and all within Gmail and when you try it, you're going to
[00:57:43.120 --> 00:57:44.120]   love it.
[00:57:44.120 --> 00:57:45.120]   Get started right now.
[00:57:45.120 --> 00:57:48.120]   It shouldn't take you to maybe less than a minute before this ad is over.
[00:57:48.120 --> 00:57:54.000]   In fact, if you go to streak.com/twit and right now for a limited time, 20% off the
[00:57:54.000 --> 00:57:55.760]   pro plan.
[00:57:55.760 --> 00:58:02.480]   S-T-R-E-A-K streak.com/twit 20% off the pro plan.
[00:58:02.480 --> 00:58:09.880]   If you're managing customers, support tickets, if you're doing job searches, buyers and sellers,
[00:58:09.880 --> 00:58:10.880]   there's nothing like it.
[00:58:10.880 --> 00:58:19.200]   Strick.com/twit and we thank you so much for supporting our show.
[00:58:19.200 --> 00:58:24.320]   Not yet a law in the EU, but boy, I think Apple and Google both lobbied hard against
[00:58:24.320 --> 00:58:31.320]   this.
[00:58:31.320 --> 00:58:34.320]   A law that would force Apple and I guess Google, anybody who has a store, you have to be a company
[00:58:34.320 --> 00:58:42.000]   with more than 75 billion euros value annual sales of 7.5 billion and 45 million monthly
[00:58:42.000 --> 00:58:43.000]   users.
[00:58:43.000 --> 00:58:46.160]   I think Google and Apple both qualify.
[00:58:46.160 --> 00:58:50.560]   Then you have to offer third party payment options in your stead of your stores.
[00:58:50.560 --> 00:58:53.080]   This is something Epic sued Apple over and lost.
[00:58:53.080 --> 00:58:55.080]   That's on appeal right now.
[00:58:55.080 --> 00:59:02.920]   Saying we don't want to pay 30% to Apple, and I think even more important to me.
[00:59:02.920 --> 00:59:04.840]   I don't care so much about that.
[00:59:04.840 --> 00:59:09.160]   That's something maybe developers who don't want to give Apple 30% companies like Netflix
[00:59:09.160 --> 00:59:12.320]   and Amazon and Epic might not like.
[00:59:12.320 --> 00:59:16.480]   But I think the thing that is more important to me and actually I think would be a big improvement
[00:59:16.480 --> 00:59:23.560]   in interoperability with Apple's messages.
[00:59:23.560 --> 00:59:29.080]   Apple would have to open up, I'm quoting here, and interoperate with smaller messaging platforms
[00:59:29.080 --> 00:59:31.800]   if they so request.
[00:59:31.800 --> 00:59:35.560]   Users with smaller big platforms would then be able to exchange messages, send files,
[00:59:35.560 --> 00:59:41.720]   or make video calls across messaging apps, giving them more choice.
[00:59:41.720 --> 00:59:43.720]   I think it's really the crown jewels for Apple.
[00:59:43.720 --> 00:59:52.480]   In fact, we saw in the Epic versus Apple Discovery emails from Apple CEO Tim Cook, Scott Forestall,
[00:59:52.480 --> 00:59:57.080]   Eddie Q and others saying we don't make messages on Android.
[00:59:57.080 --> 01:00:01.400]   That's the only reason parents are buying Apple phones for their kids so they can be
[01:00:01.400 --> 01:00:04.200]   green bubbles.
[01:00:04.200 --> 01:00:09.800]   Apple would also have to allow users to uninstall Safari and other stock apps.
[01:00:09.800 --> 01:00:10.800]   This would be a good one too.
[01:00:10.800 --> 01:00:13.400]   I'll place them with third party alternatives if they so wish.
[01:00:13.400 --> 01:00:16.800]   Although iPhones lately have allowed you to use a third party browser instead of the default
[01:00:16.800 --> 01:00:17.800]   Safari.
[01:00:17.800 --> 01:00:18.800]   Well, hold on.
[01:00:18.800 --> 01:00:19.800]   So WebKit though.
[01:00:19.800 --> 01:00:27.760]   Oh, when you use any third party Web browser on Apple devices, you may be using their sort
[01:00:27.760 --> 01:00:32.440]   of shell of a browser, but the actual thing doing the rendering, accessing the Web pages
[01:00:32.440 --> 01:00:33.720]   is still WebKit.
[01:00:33.720 --> 01:00:38.600]   This is a perfect example of, I'll take this position.
[01:00:38.600 --> 01:00:42.800]   My government maybe shouldn't weigh in on these technical issues.
[01:00:42.800 --> 01:00:49.120]   I think the EU legislators say, "Well, you just make them uninstall Safari.
[01:00:49.120 --> 01:00:50.560]   Make that an option.
[01:00:50.560 --> 01:00:51.560]   Don't understand.
[01:00:51.560 --> 01:00:53.800]   That's not a solution."
[01:00:53.800 --> 01:00:57.600]   You'd have to say, "Oh, you can use some other rendering engine."
[01:00:57.600 --> 01:00:59.160]   Chromium or whatever.
[01:00:59.160 --> 01:01:00.160]   Yeah.
[01:01:00.160 --> 01:01:01.160]   Yeah.
[01:01:01.160 --> 01:01:06.360]   Which now there may be some downsides or maybe Apple doing some power efficiency, tostles,
[01:01:06.360 --> 01:01:11.680]   stuff with WebKit that makes a better experience on an iOS device regardless of which browser
[01:01:11.680 --> 01:01:13.680]   you're using with it.
[01:01:13.680 --> 01:01:14.680]   Fine.
[01:01:14.680 --> 01:01:15.680]   But I don't know.
[01:01:15.680 --> 01:01:21.480]   I really, my personal belief is that if I put Chrome on an iPhone, it should be Chrome.
[01:01:21.480 --> 01:01:22.480]   Right?
[01:01:22.480 --> 01:01:23.480]   I agree.
[01:01:23.480 --> 01:01:24.480]   And in case of iPhone, it's not.
[01:01:24.480 --> 01:01:27.040]   It's WebKit with a Chrome Chrome on top.
[01:01:27.040 --> 01:01:28.040]   Right.
[01:01:28.040 --> 01:01:29.040]   Right.
[01:01:29.040 --> 01:01:30.040]   Right.
[01:01:30.040 --> 01:01:33.720]   Gatekeepers, again, Apple, Google, companies, I guess Facebook would qualify.
[01:01:33.720 --> 01:01:36.720]   Although Facebook value keeps going down there.
[01:01:36.720 --> 01:01:38.800]   They'll be low enough.
[01:01:38.800 --> 01:01:40.640]   They don't have to worry about this.
[01:01:40.640 --> 01:01:45.040]   We'll have to make it as easy to unsubscribe from services as subscribe.
[01:01:45.040 --> 01:01:47.880]   Yeah.
[01:01:47.880 --> 01:01:53.400]   For the most important software, for instance, web browsers not require this software by
[01:01:53.400 --> 01:01:57.640]   default upon installation of the operating system, ensure interoperability of messaging
[01:01:57.640 --> 01:01:59.480]   services, basic functionalities.
[01:01:59.480 --> 01:02:00.800]   I think that would be...
[01:02:00.800 --> 01:02:04.000]   It doesn't mean that Apple would have to make messages for Android, however.
[01:02:04.000 --> 01:02:05.000]   It just means...
[01:02:05.000 --> 01:02:07.000]   I don't think I think this one might be...
[01:02:07.000 --> 01:02:13.160]   No, but if Google wanted to make their messaging app work with Apple messages, then they would
[01:02:13.160 --> 01:02:15.160]   have to allow that.
[01:02:15.160 --> 01:02:16.160]   Oh.
[01:02:16.160 --> 01:02:17.160]   Yeah.
[01:02:17.160 --> 01:02:18.160]   Apple can make it...
[01:02:18.160 --> 01:02:20.880]   Or anybody can make an Android app.
[01:02:20.880 --> 01:02:21.880]   Oh.
[01:02:21.880 --> 01:02:22.880]   Yeah.
[01:02:22.880 --> 01:02:23.880]   That's interesting.
[01:02:23.880 --> 01:02:24.880]   Allow it to develop...
[01:02:24.880 --> 01:02:29.960]   It's not going to require Apple to make an Android messages app, but anybody else could
[01:02:29.960 --> 01:02:32.200]   do it and tie into it.
[01:02:32.200 --> 01:02:33.200]   Right.
[01:02:33.200 --> 01:02:34.200]   Tie into their platform.
[01:02:34.200 --> 01:02:35.200]   Right.
[01:02:35.200 --> 01:02:36.200]   So they just have to provide the APIs.
[01:02:36.200 --> 01:02:37.200]   I like that.
[01:02:37.200 --> 01:02:42.680]   Right now you have to jump through hoops to get Apple messages on an Android device.
[01:02:42.680 --> 01:02:46.400]   I like it right up until the point where I start getting spammed by the random person
[01:02:46.400 --> 01:02:49.280]   that has an app that has access to their network.
[01:02:49.280 --> 01:02:50.280]   Oh.
[01:02:50.280 --> 01:02:51.280]   Good point.
[01:02:51.280 --> 01:02:52.280]   Yeah.
[01:02:52.280 --> 01:02:55.800]   And you know, I'll channel Alex Lindsey on Macbreak Weekly because he's dead set against
[01:02:55.800 --> 01:02:57.200]   any of these changes.
[01:02:57.200 --> 01:03:05.760]   And I think he has a point that the way Apple does it admittedly to Apple's benefit, it's
[01:03:05.760 --> 01:03:11.840]   lock-in, it's proprietary, it's a silo, but the way they do it also makes it easier and
[01:03:11.840 --> 01:03:14.840]   cleaner for users.
[01:03:14.840 --> 01:03:17.840]   And that's a good point.
[01:03:17.840 --> 01:03:18.840]   That's a good point.
[01:03:18.840 --> 01:03:19.840]   You know, but...
[01:03:19.840 --> 01:03:20.840]   More security.
[01:03:20.840 --> 01:03:22.880]   I think users should have the right to...
[01:03:22.880 --> 01:03:26.280]   If they want to make their life messy, they should be able to do it.
[01:03:26.280 --> 01:03:28.600]   You should have the right to be less secure.
[01:03:28.600 --> 01:03:29.600]   Yeah.
[01:03:29.600 --> 01:03:30.600]   Yeah.
[01:03:30.600 --> 01:03:35.800]   You shouldn't be locked into a particular means of doing something.
[01:03:35.800 --> 01:03:40.600]   If you want to take that risk, you should be allowed to do that.
[01:03:40.600 --> 01:03:44.880]   There's nothing stopping people from using things like WhatsApp and Telegram though.
[01:03:44.880 --> 01:03:49.120]   I think that's the big problem with all I have with all of this is that they're not going
[01:03:49.120 --> 01:03:50.320]   to go stop these.
[01:03:50.320 --> 01:03:54.320]   They're not going to make them be interoperable, which means then people are just going to
[01:03:54.320 --> 01:03:55.320]   move to those.
[01:03:55.320 --> 01:03:59.480]   I just don't understand this line of thinking unfortunately.
[01:03:59.480 --> 01:04:04.520]   The problem with that, and particularly for messaging apps, probably more so than anything
[01:04:04.520 --> 01:04:08.480]   else, is you really are...
[01:04:08.480 --> 01:04:13.800]   That is probably the one place where the network effect is the biggest factor.
[01:04:13.800 --> 01:04:21.840]   You can switch from Apple messages to WhatsApp or anything else or Signal or whatever you
[01:04:21.840 --> 01:04:23.000]   want.
[01:04:23.000 --> 01:04:29.120]   But if you can't get all the people you communicate with to come over as well, then it's useless
[01:04:29.120 --> 01:04:31.120]   to you.
[01:04:31.120 --> 01:04:37.760]   You should have the ability to go from WhatsApp or Signal or Telegram to Apple messages or
[01:04:37.760 --> 01:04:42.720]   to WhatsApp or to go back and forth between any of these from any of these.
[01:04:42.720 --> 01:04:47.760]   It should be a many to many relationship, not a one to one relationship.
[01:04:47.760 --> 01:04:51.400]   It's shocking how high a percentage of folks will just use the default thing.
[01:04:51.400 --> 01:04:52.400]   Whatever is there.
[01:04:52.400 --> 01:04:54.000]   What came on the phone?
[01:04:54.000 --> 01:04:55.000]   Yes.
[01:04:55.000 --> 01:04:56.000]   Right.
[01:04:56.000 --> 01:04:59.920]   Many people in that group don't even realize that they can install extra apps.
[01:04:59.920 --> 01:05:02.080]   They're like, "Oh, I could put WhatsApp on there."
[01:05:02.080 --> 01:05:03.080]   Oh, okay.
[01:05:03.080 --> 01:05:04.080]   Yeah, that's right.
[01:05:04.080 --> 01:05:07.760]   They don't understand the difference between the green and the blue on iMessage, right?
[01:05:07.760 --> 01:05:10.840]   They just know that a lot of those bluebies in there.
[01:05:10.840 --> 01:05:12.960]   But you know what, it is a strong lock yet.
[01:05:12.960 --> 01:05:14.120]   I mentioned this story before.
[01:05:14.120 --> 01:05:18.000]   My son, I asked my son who was in a fraternity at CU Boulder a couple of years ago.
[01:05:18.000 --> 01:05:20.160]   I said, "How many kids have Android?
[01:05:20.160 --> 01:05:21.160]   How many iPhones?"
[01:05:21.160 --> 01:05:23.480]   He's only one kid with Android.
[01:05:23.480 --> 01:05:25.400]   And he's the blue bubble.
[01:05:25.400 --> 01:05:28.680]   He's left out of all of our group conversations.
[01:05:28.680 --> 01:05:32.440]   There's huge pressure as a result to be an iPhone user.
[01:05:32.440 --> 01:05:34.800]   Apple knows that.
[01:05:34.800 --> 01:05:40.920]   And also to some degree, I kind of want there to be more interoperability just to try to
[01:05:40.920 --> 01:05:46.120]   redo, not that I want everybody to end up settling on iMessage necessarily, but I remember
[01:05:46.120 --> 01:05:51.640]   way back in the day when you had to use like, iTrillion or not iMessage trillion for iCQ
[01:05:51.640 --> 01:05:54.240]   and like MSN and our pigeon, right?
[01:05:54.240 --> 01:05:59.400]   Where you had to use, well, and I still remember my stupid iCQ number even right now.
[01:05:59.400 --> 01:06:00.400]   I don't know why.
[01:06:00.400 --> 01:06:01.400]   It's crazy.
[01:06:01.400 --> 01:06:02.400]   What's your iCQ number?
[01:06:02.400 --> 01:06:03.400]   Go ahead, tell me.
[01:06:03.400 --> 01:06:04.400]   169-6682.
[01:06:04.400 --> 01:06:06.440]   You guys remember your iCQ numbers?
[01:06:06.440 --> 01:06:10.000]   See, it doesn't matter if somebody spams me because I haven't logged into that.
[01:06:10.000 --> 01:06:11.000]   It like 10 years.
[01:06:11.000 --> 01:06:12.000]   Probably you saw that again.
[01:06:12.000 --> 01:06:13.960]   Lou, do you remember your iCQ number?
[01:06:13.960 --> 01:06:14.960]   I do 1414.
[01:06:14.960 --> 01:06:15.960]   Oh my God.
[01:06:15.960 --> 01:06:16.960]   Do you remember your iCQ?
[01:06:16.960 --> 01:06:19.600]   That's a nice one.
[01:06:19.600 --> 01:06:23.960]   I never used iCQ and I wish I could remember my iCQ number.
[01:06:23.960 --> 01:06:24.960]   I know my iCQ number.
[01:06:24.960 --> 01:06:28.440]   I'm sure I had an iCQ number, but I don't remember.
[01:06:28.440 --> 01:06:30.440]   CompuCerve 75106, 3135.
[01:06:30.440 --> 01:06:31.440]   Yeah.
[01:06:31.440 --> 01:06:35.920]   But we used to use those apps that would tie all those together because there were so
[01:06:35.920 --> 01:06:37.080]   many dang different things.
[01:06:37.080 --> 01:06:38.080]   Oh, so annoying.
[01:06:38.080 --> 01:06:39.080]   In the butt, right?
[01:06:39.080 --> 01:06:40.080]   Yeah.
[01:06:40.080 --> 01:06:41.880]   And nowadays it's sort of the same thing.
[01:06:41.880 --> 01:06:44.120]   I have family overseas to talk to them.
[01:06:44.120 --> 01:06:47.360]   Well, I got to use WhatsApp or I got to use whatever the other thing that they use over
[01:06:47.360 --> 01:06:48.360]   there.
[01:06:48.360 --> 01:06:50.600]   You have to have all the apps, basically.
[01:06:50.600 --> 01:06:52.920]   Because this guy uses message or this guy uses WhatsApp.
[01:06:52.920 --> 01:06:54.160]   He uses Telegram.
[01:06:54.160 --> 01:06:58.000]   I wish I could use signal for everything.
[01:06:58.000 --> 01:07:01.920]   If signal didn't tie to a phone number, I would use signal for everything.
[01:07:01.920 --> 01:07:05.960]   And I would just say, you know, everybody has to signal me, but you can't because you
[01:07:05.960 --> 01:07:07.560]   just one per phone.
[01:07:07.560 --> 01:07:08.560]   Yeah.
[01:07:08.560 --> 01:07:11.120]   And there's always going to be somebody that's not using that.
[01:07:11.120 --> 01:07:12.560]   And then they use another thing.
[01:07:12.560 --> 01:07:15.160]   And I mean, this is the beauty of email.
[01:07:15.160 --> 01:07:18.480]   This is why email works so well because it didn't matter what system.
[01:07:18.480 --> 01:07:23.720]   I mean, at least once we got past MCI mail, you could use whatever mail app you wanted
[01:07:23.720 --> 01:07:25.400]   and it still went through.
[01:07:25.400 --> 01:07:27.440]   So how come we were able to solve it with email?
[01:07:27.440 --> 01:07:32.160]   But we went in the exact opposite direction with messaging.
[01:07:32.160 --> 01:07:33.160]   What happens?
[01:07:33.160 --> 01:07:34.160]   Standards.
[01:07:34.160 --> 01:07:35.160]   It's a protocol.
[01:07:35.160 --> 01:07:36.160]   I mean, email is a protocol.
[01:07:36.160 --> 01:07:37.160]   Lack of standards.
[01:07:37.160 --> 01:07:38.160]   You develop a protocol.
[01:07:38.160 --> 01:07:42.520]   It's more agnostic versus these specific platforms that are tied down.
[01:07:42.520 --> 01:07:47.360]   And because it used to be if you had the source, you couldn't talk to people on CompuServe.
[01:07:47.360 --> 01:07:52.520]   And if you had MCI mail or genie, these were all, they were not interoperable.
[01:07:52.520 --> 01:07:53.960]   These were like it is today.
[01:07:53.960 --> 01:07:56.080]   They were siloed.
[01:07:56.080 --> 01:07:59.360]   The difference was you had to have a paid account with those.
[01:07:59.360 --> 01:08:05.480]   So if I were an MCI mail account, I bet I could remember my MCI mail number, but you
[01:08:05.480 --> 01:08:08.240]   couldn't email me from any of the other services.
[01:08:08.240 --> 01:08:11.440]   So if you didn't have MCI mail, you literally could not email me.
[01:08:11.440 --> 01:08:14.360]   That was a bad situation.
[01:08:14.360 --> 01:08:16.960]   And the internet mail solved all that.
[01:08:16.960 --> 01:08:19.400]   And eventually everybody kind of conceded.
[01:08:19.400 --> 01:08:23.320]   Today you've got companies that say, no, no, no, this is my business model.
[01:08:23.320 --> 01:08:29.560]   I'm not going to let iMessage interoperate with anything else or Facebook messenger.
[01:08:29.560 --> 01:08:34.920]   So in that respect, I think the EU is not wrong.
[01:08:34.920 --> 01:08:35.920]   It would be nice.
[01:08:35.920 --> 01:08:37.960]   I don't know if you can have a legislative solution.
[01:08:37.960 --> 01:08:44.840]   By the way, if I think the key to a legislative solution is it needs to be technology agnostic.
[01:08:44.840 --> 01:08:49.520]   The regulations can't specify that you have to do it a particular way.
[01:08:49.520 --> 01:08:53.280]   You have to specify what is the end result that you want.
[01:08:53.280 --> 01:08:58.600]   You want any messaging system to be able to talk to any other messaging system.
[01:08:58.600 --> 01:09:04.240]   It needs to be results oriented, not specifying a particular technology solution.
[01:09:04.240 --> 01:09:06.960]   And if you do that, then...
[01:09:06.960 --> 01:09:10.000]   Well they're not saying you have to use XMPP.
[01:09:10.000 --> 01:09:11.080]   They're not going that far.
[01:09:11.080 --> 01:09:13.760]   They're just saying you have to be interoperable.
[01:09:13.760 --> 01:09:14.760]   Yeah.
[01:09:14.760 --> 01:09:15.760]   They're kind of targeting them.
[01:09:15.760 --> 01:09:17.000]   They're kind of targeting the big ones.
[01:09:17.000 --> 01:09:20.120]   They're saying that you have to make certain amount before we start targeting them.
[01:09:20.120 --> 01:09:21.120]   Oh yeah, absolutely.
[01:09:21.120 --> 01:09:23.760]   So they're kind of targeting those specific applications.
[01:09:23.760 --> 01:09:26.040]   Well, it's kind of a form of antitrust.
[01:09:26.040 --> 01:09:33.640]   And the EU's view of antitrust is very different than our view of antitrust in the United States.
[01:09:33.640 --> 01:09:38.200]   Although I have to say it's going in this direction as well in the US.
[01:09:38.200 --> 01:09:41.480]   By the way, this is not a light fine.
[01:09:41.480 --> 01:09:45.120]   Again, this is provisional.
[01:09:45.120 --> 01:09:49.720]   As I remember, it's a complicated system, but every country has to ratify it before it's
[01:09:49.720 --> 01:09:52.440]   the rule of that country.
[01:09:52.440 --> 01:09:57.200]   If the gatekeeper violates the rules laid down on the legislation, the EU says the fine
[01:09:57.200 --> 01:10:01.480]   can be up to 10% of its worldwide revenue.
[01:10:01.480 --> 01:10:02.480]   Billions.
[01:10:02.480 --> 01:10:08.360]   This is not that slap on the wrist, 5 million euros that the Irish state authorities charging
[01:10:08.360 --> 01:10:16.680]   Apple every week for repeat offense up to 20% of worldwide revenue.
[01:10:16.680 --> 01:10:18.480]   Yikes.
[01:10:18.480 --> 01:10:27.280]   So I guess the overarching question for the three of you is, should legislative bodies
[01:10:27.280 --> 01:10:30.720]   do this kind of thing or not?
[01:10:30.720 --> 01:10:34.640]   Are they the right people to do this, Lou?
[01:10:34.640 --> 01:10:35.640]   I don't think so.
[01:10:35.640 --> 01:10:38.160]   I'm probably the odd man out here.
[01:10:38.160 --> 01:10:42.480]   I just think that maybe it's the way they're going about it is just wrong for me.
[01:10:42.480 --> 01:10:48.280]   I think that they're targeting specific large companies and technology that they make in
[01:10:48.280 --> 01:10:49.280]   order to do this.
[01:10:49.280 --> 01:10:52.240]   When in fact, I think that's almost anti-competitive.
[01:10:52.240 --> 01:10:56.720]   So I'm just my personal opinion there.
[01:10:56.720 --> 01:10:59.400]   What do you think, Alan?
[01:10:59.400 --> 01:11:02.000]   I see both sides of it.
[01:11:02.000 --> 01:11:03.000]   I know.
[01:11:03.000 --> 01:11:04.000]   It's hard for me to say it one way or the other.
[01:11:04.000 --> 01:11:07.960]   I get where Lou's coming from, but I also feel like, okay, if they don't do it, who
[01:11:07.960 --> 01:11:10.160]   will and how will they, right?
[01:11:10.160 --> 01:11:14.680]   It has to be somebody big enough to actually have an impact if it's ever going to happen,
[01:11:14.680 --> 01:11:17.800]   not necessarily that I support how they're doing how they're going about it.
[01:11:17.800 --> 01:11:20.440]   So that begs the second question, does this need to happen?
[01:11:20.440 --> 01:11:23.560]   Is this something we need or can we just go on the way it is?
[01:11:23.560 --> 01:11:27.240]   Again, there's two sides, right?
[01:11:27.240 --> 01:11:31.240]   Yeah, there are definitely pros and cons to doing it.
[01:11:31.240 --> 01:11:36.760]   The only mechanism we as a society have for this kind of thing is government.
[01:11:36.760 --> 01:11:41.960]   That's the whole, that's in theory, maybe not in practice, but the theory is that society's
[01:11:41.960 --> 01:11:47.920]   voice saying, no, no, companies, big tech companies, I know you're there to make a profit.
[01:11:47.920 --> 01:11:48.920]   That's your mantra.
[01:11:48.920 --> 01:11:49.920]   That's what you're doing.
[01:11:49.920 --> 01:11:54.520]   But we as a society want you to do something that maybe isn't your best business interests,
[01:11:54.520 --> 01:11:57.040]   which is make your messaging programs interoperable.
[01:11:57.040 --> 01:12:02.080]   And we as a society say, if you want to operate in our society, you need to hear that rule.
[01:12:02.080 --> 01:12:05.240]   In theory, that's the way to do it, and that's the right way to do it.
[01:12:05.240 --> 01:12:10.680]   I think the big issue that comes about from, like take this example right now, and there's
[01:12:10.680 --> 01:12:14.280]   even some other examples that the EU also has done, right?
[01:12:14.280 --> 01:12:18.360]   The EU is pretty aggressive about doing this sort of thing where they want to step in about
[01:12:18.360 --> 01:12:20.920]   some particular technological thing.
[01:12:20.920 --> 01:12:23.880]   My sort of beef with it is the same thing that's making all of us collectively roll
[01:12:23.880 --> 01:12:26.240]   our eyes about the WebKit thing, for example, right?
[01:12:26.240 --> 01:12:31.200]   It's like, well, these guys didn't know the whole story technologically, right?
[01:12:31.200 --> 01:12:36.480]   They didn't have their minds fully wrapped around the issue at hand and how to address
[01:12:36.480 --> 01:12:40.840]   it and all of the little caveats that might come along with it.
[01:12:40.840 --> 01:12:45.480]   So of course, once they make the decision and the requirement comes down, it seems boneheaded
[01:12:45.480 --> 01:12:50.000]   to those who actually understand that it's like, well, you guys didn't make an informed
[01:12:50.000 --> 01:12:51.520]   decision, right?
[01:12:51.520 --> 01:12:56.320]   They made, there was some decision like a year ago or something with respect to, I think
[01:12:56.320 --> 01:13:02.920]   it affected Tesla the most, but it was targeted at, like, if a car has like a some autonomous
[01:13:02.920 --> 01:13:10.400]   type feature, then it can't like turn at this exceeding this number of G-force, right?
[01:13:10.400 --> 01:13:12.080]   That sounds like a good law.
[01:13:12.080 --> 01:13:16.840]   Well, no, no, but it was such a low number that it was like you basically had to make
[01:13:16.840 --> 01:13:18.520]   a slow grandma, right?
[01:13:18.520 --> 01:13:23.040]   So it was like you couldn't even make a turn like a normal, right?
[01:13:23.040 --> 01:13:27.760]   And it was to the point where, yeah, and it was to the point where if you as a regular
[01:13:27.760 --> 01:13:32.280]   person tried to adhere to this restriction, just driving normally, you would have piles
[01:13:32.280 --> 01:13:34.640]   up behind you, right?
[01:13:34.640 --> 01:13:36.680]   Because you're just, it's to the point where it's hazardous.
[01:13:36.680 --> 01:13:38.640]   That's just, they chose a wrong number.
[01:13:38.640 --> 01:13:43.920]   Yes, but again, it's the whole like, you didn't fully think this out, right?
[01:13:43.920 --> 01:13:47.600]   Did nobody sit somebody in a car and yeah, it's like, you know, sit somebody in a car
[01:13:47.600 --> 01:13:49.600]   and do this much of a G-firmency.
[01:13:49.600 --> 01:13:53.920]   In the defense of government, that's part of the process as your proposal law, somebody
[01:13:53.920 --> 01:13:57.320]   points out that's driving like a grandma, you say, all right, what do we make it?
[01:13:57.320 --> 01:13:58.320]   Three Gs.
[01:13:58.320 --> 01:13:59.800]   It's not done.
[01:13:59.800 --> 01:14:01.280]   This is it done in final.
[01:14:01.280 --> 01:14:04.120]   There's a process and it can evolve.
[01:14:04.120 --> 01:14:06.640]   The Constitution has many amendments.
[01:14:06.640 --> 01:14:10.560]   I don't think that that's a strike against it that they chose a bad number.
[01:14:10.560 --> 01:14:15.760]   Well, in a lot of these cases, by the time the number, by the time the information gets
[01:14:15.760 --> 01:14:19.360]   out, like it's already sort of a done deal.
[01:14:19.360 --> 01:14:22.000]   And then it's, you have to have, it's insurmountable.
[01:14:22.000 --> 01:14:24.880]   Then the car manufacturers have to implement it whether or not you're going to change
[01:14:24.880 --> 01:14:25.880]   it down the road.
[01:14:25.880 --> 01:14:26.880]   Right.
[01:14:26.880 --> 01:14:30.560]   And then everybody has to complain about it for weeks or months to finally they meet
[01:14:30.560 --> 01:14:31.560]   them back in the middle.
[01:14:31.560 --> 01:14:34.320]   They should have met them back in the middle before everything was set and stopped.
[01:14:34.320 --> 01:14:38.560]   On the other hand, I don't think Tesla should be able to roll through stuff.
[01:14:38.560 --> 01:14:39.560]   Right.
[01:14:39.560 --> 01:14:40.560]   I agree with you.
[01:14:40.560 --> 01:14:42.960]   I agree with you there.
[01:14:42.960 --> 01:14:50.880]   To defend the regulators a little bit, the regulatory process is not something that happens quickly,
[01:14:50.880 --> 01:14:53.440]   which is both good and bad.
[01:14:53.440 --> 01:14:56.920]   It's a process that often takes years.
[01:14:56.920 --> 01:15:01.920]   And I'm not quite sure exactly which one you're referencing there, Alan.
[01:15:01.920 --> 01:15:09.280]   But generally, they'll put out, and this isn't just for vehicles, it's for everything,
[01:15:09.280 --> 01:15:11.440]   every regulatory process.
[01:15:11.440 --> 01:15:14.240]   They put out a notice proposed rulemaking.
[01:15:14.240 --> 01:15:16.160]   Here's what we're thinking about.
[01:15:16.160 --> 01:15:20.280]   You got 90 days, six months to give us comments.
[01:15:20.280 --> 01:15:21.880]   We'll evaluate that.
[01:15:21.880 --> 01:15:27.000]   And even before they get to that point, they've usually done years of research and analysis
[01:15:27.000 --> 01:15:29.200]   before they even do that NPRM.
[01:15:29.200 --> 01:15:35.040]   And then there's the next stage they go, they iterate through that sometimes several times
[01:15:35.040 --> 01:15:38.240]   before they finally come up with a final regulation.
[01:15:38.240 --> 01:15:39.240]   Yeah.
[01:15:39.240 --> 01:15:40.240]   Of course.
[01:15:40.240 --> 01:15:45.400]   In that case, the fault really lies on the other parties for not paying attention necessarily
[01:15:45.400 --> 01:15:46.320]   because those like the--
[01:15:46.320 --> 01:15:47.320]   Yeah.
[01:15:47.320 --> 01:15:48.320]   Yeah.
[01:15:48.320 --> 01:15:54.440]   And certainly most big companies have people that are keeping an eye on this.
[01:15:54.440 --> 01:16:02.040]   And they do respond and comment on these notices of proposed rulemaking before they ever get
[01:16:02.040 --> 01:16:03.040]   to that stage.
[01:16:03.040 --> 01:16:07.360]   So on the other hand, if you're Elon, you might be tweeting that the National Highway
[01:16:07.360 --> 01:16:11.240]   Transportation Safety Administration are the funniest police.
[01:16:11.240 --> 01:16:12.240]   Yeah.
[01:16:12.240 --> 01:16:16.800]   This is when they told Tesla, you know that thing that makes fart sounds as you drive
[01:16:16.800 --> 01:16:19.600]   down the road, you got to turn that off.
[01:16:19.600 --> 01:16:22.240]   That is not OK.
[01:16:22.240 --> 01:16:24.040]   I know.
[01:16:24.040 --> 01:16:26.920]   They just don't think CEO should be acting like 12-year-olds.
[01:16:26.920 --> 01:16:27.920]   Yeah.
[01:16:27.920 --> 01:16:30.320]   He's had some fun with Nitzi.
[01:16:30.320 --> 01:16:37.080]   Nitzi, I don't-- I don't know where he stands these days.
[01:16:37.080 --> 01:16:38.080]   I'm not--
[01:16:38.080 --> 01:16:40.840]   He doesn't like the N-H-Lators.
[01:16:40.840 --> 01:16:46.440]   Even though none of my cars have that sound maker on them because they're early enough
[01:16:46.440 --> 01:16:47.400]   to not have had it.
[01:16:47.400 --> 01:16:52.840]   And I kind of find that whole thing annoying myself because if I'm coming up on somebody,
[01:16:52.840 --> 01:16:53.840]   I'll tap the horn.
[01:16:53.840 --> 01:16:55.320]   Like, I'll make it obvious that I'm fine.
[01:16:55.320 --> 01:16:57.840]   Well, you do need-- and I don't think he's arguing against this.
[01:16:57.840 --> 01:17:03.320]   And then this is actually a requirement of Nitzi is some sort of sound so that blind
[01:17:03.320 --> 01:17:07.160]   pedestrians and others know that an electric vehicle, which is otherwise much less noisy
[01:17:07.160 --> 01:17:09.360]   than an ice vehicle, is near.
[01:17:09.360 --> 01:17:12.160]   But the key is that the sound has to be a standard.
[01:17:12.160 --> 01:17:17.160]   It has to be a standard sound so that it's understood that that is an acai at vehicle.
[01:17:17.160 --> 01:17:18.160]   Not yes.
[01:17:18.160 --> 01:17:19.160]   That's a major--
[01:17:19.160 --> 01:17:20.160]   Right.
[01:17:20.160 --> 01:17:23.680]   --that's a lot of burritos coming down the road in your direction.
[01:17:23.680 --> 01:17:29.000]   My Mustang Mach-E has a low whining sound when I get below, I think, eight miles an hour.
[01:17:29.000 --> 01:17:30.320]   I don't have a problem with that.
[01:17:30.320 --> 01:17:33.680]   It also has-- and there's a lot of actually Mustang owners who don't like this.
[01:17:33.680 --> 01:17:37.080]   This has a backup beep, like a truck.
[01:17:37.080 --> 01:17:38.080]   Is that same?
[01:17:38.080 --> 01:17:39.720]   Is that-- why?
[01:17:39.720 --> 01:17:40.720]   [LAUGHTER]
[01:17:40.720 --> 01:17:45.720]   That's, again, that's part of the same set of rules that--
[01:17:45.720 --> 01:17:49.040]   Are all cars going to have backup or beeps now?
[01:17:49.040 --> 01:17:53.720]   Well, for not necessarily a beep for the backups, but some sort of sound when they're
[01:17:53.720 --> 01:17:58.480]   backing up for anything that's operating in electric mode below 20 miles.
[01:17:58.480 --> 01:17:59.640]   Oh, it's just because it's electric.
[01:17:59.640 --> 01:18:00.640]   OK.
[01:18:00.640 --> 01:18:01.640]   Yeah.
[01:18:01.640 --> 01:18:02.680]   And it applies to hybrids as well.
[01:18:02.680 --> 01:18:08.200]   So if you're driving a hybrid-- and the Mustang doesn't make a beep when it's backing up,
[01:18:08.200 --> 01:18:09.200]   doesn't it?
[01:18:09.200 --> 01:18:12.680]   Yeah, like a car, like a truck or a forklift.
[01:18:12.680 --> 01:18:16.720]   It must have changed that because the last time I drove it, it didn't do that.
[01:18:16.720 --> 01:18:19.960]   Yeah, I've seen on Reddit a number of owners complain, I don't mind.
[01:18:19.960 --> 01:18:20.960]   It's fine.
[01:18:20.960 --> 01:18:23.960]   I don't want to hit a kid that-- things like that, big camera, I can see what's going
[01:18:23.960 --> 01:18:24.960]   on.
[01:18:24.960 --> 01:18:27.440]   But still, I don't want to hit a kid that's too small to see or whatever.
[01:18:27.440 --> 01:18:28.640]   So that's fine.
[01:18:28.640 --> 01:18:29.600]   Yeah.
[01:18:29.600 --> 01:18:30.600]   That's fine.
[01:18:30.600 --> 01:18:31.600]   No, and that's intentional.
[01:18:31.600 --> 01:18:36.600]   Still, like you said, it's not something on my checklist for cars.
[01:18:36.600 --> 01:18:42.560]   Yeah, it needs to be relatively standardized so that you have-- you start to build up a
[01:18:42.560 --> 01:18:45.240]   community understanding of what a particular sound means.
[01:18:45.240 --> 01:18:46.600]   What it is, yes.
[01:18:46.600 --> 01:18:48.040]   And that beep is a well-known sound.
[01:18:48.040 --> 01:18:49.880]   I mean, it's the same sound trucks make in others.
[01:18:49.880 --> 01:18:50.880]   So it is definitely--
[01:18:50.880 --> 01:18:56.560]   Just like we know that traffic signals, red light, and stop green means go.
[01:18:56.560 --> 01:18:59.520]   Although, dwindles idea in our chat room that they should sound like tie fighters when
[01:18:59.520 --> 01:19:01.880]   they go by isn't a bad idea.
[01:19:01.880 --> 01:19:04.880]   Well, I mean, that's what Formula E race cars sound like.
[01:19:04.880 --> 01:19:06.200]   They sound like tie fighters.
[01:19:06.200 --> 01:19:07.200]   [LAUGHTER]
[01:19:07.200 --> 01:19:08.200]   Then why?
[01:19:08.200 --> 01:19:09.200]   It was great.
[01:19:09.200 --> 01:19:13.440]   I was actually-- earlier, I was watching somebody posted a video.
[01:19:13.440 --> 01:19:20.800]   They were test driving the Porsche Mission R concept, which is also an EV concept for
[01:19:20.800 --> 01:19:22.520]   a future race car.
[01:19:22.520 --> 01:19:24.680]   And it is very similar.
[01:19:24.680 --> 01:19:25.880]   It sounds like a tie fighter.
[01:19:25.880 --> 01:19:30.280]   It's the wine of the electric motors in the gears as it drives around.
[01:19:30.280 --> 01:19:31.280]   Yeah.
[01:19:31.280 --> 01:19:36.440]   The electric hill climb cars are very annoying.
[01:19:36.440 --> 01:19:40.360]   Because that sound is meant for you to really hear it from a long way off because they're
[01:19:40.360 --> 01:19:44.360]   kind of really screaming up a hill and then they'll want someone to not know that they're
[01:19:44.360 --> 01:19:45.840]   coming into those sounds.
[01:19:45.840 --> 01:19:52.000]   Yeah, if you ever listen to those, they've done some Tesla hill climbs or even the Volkswagen
[01:19:52.000 --> 01:19:53.000]   EV.
[01:19:53.000 --> 01:19:54.000]   I forget the name of that car.
[01:19:54.000 --> 01:19:55.000]   The IDR.
[01:19:55.000 --> 01:20:00.760]   When that thing is doing a hill climb event, it is the most obnoxious sounding thing where
[01:20:00.760 --> 01:20:03.200]   you'll watch a video and you kind of have to turn the volume down and you don't get
[01:20:03.200 --> 01:20:08.800]   to hear the cool EV sounds because the sound coming out of the sound maker is so annoying
[01:20:08.800 --> 01:20:09.800]   on the car.
[01:20:09.800 --> 01:20:10.800]   Yeah.
[01:20:10.800 --> 01:20:11.800]   Elon, I get it.
[01:20:11.800 --> 01:20:14.440]   Elon, you don't want to get run over by one another.
[01:20:14.440 --> 01:20:21.200]   Well, last week I was flying home from South by Southwest and I ran into a former colleague
[01:20:21.200 --> 01:20:24.800]   of mine that I used to work with about 10 years ago.
[01:20:24.800 --> 01:20:32.000]   And he used to be in PR at GM and he now works for this company that does sound design.
[01:20:32.000 --> 01:20:38.720]   It's an agency and they work with a lot of different kinds of companies creating sounds
[01:20:38.720 --> 01:20:44.400]   for different things, whether it's the sound of an action or something that can be used
[01:20:44.400 --> 01:20:46.000]   in ads.
[01:20:46.000 --> 01:20:49.240]   They're working with some automakers on sounds for EVs.
[01:20:49.240 --> 01:20:56.440]   BMW hired Hans Zimmer to create the soundtrack for their EVs.
[01:20:56.440 --> 01:21:01.120]   Last week when I was at a Volvo event, they were talking about the sounds, how they do
[01:21:01.120 --> 01:21:02.120]   some of the sounds.
[01:21:02.120 --> 01:21:07.020]   It used to be that when you turned on your turn signal, the turn signal switch was tied
[01:21:07.020 --> 01:21:09.440]   to a mechanical relay.
[01:21:09.440 --> 01:21:11.240]   That's what the clicking sound was of your turn signals.
[01:21:11.240 --> 01:21:15.160]   It was actually a relay switching back and forth.
[01:21:15.160 --> 01:21:17.720]   And now they don't have those relays anymore.
[01:21:17.720 --> 01:21:18.720]   It's all electronic.
[01:21:18.720 --> 01:21:20.880]   So they had to come up with a sound for that.
[01:21:20.880 --> 01:21:23.200]   It still sounds like the relay though, doesn't it?
[01:21:23.200 --> 01:21:25.360]   Well, not in the Volvo.
[01:21:25.360 --> 01:21:28.240]   It's still a click, but it's different.
[01:21:28.240 --> 01:21:34.560]   And they showed us a video of some of their sound designers walking through a forest in
[01:21:34.560 --> 01:21:37.120]   Sweden, reporting various sounds.
[01:21:37.120 --> 01:21:42.760]   And one of the sounds they happened to catch was as the guy stepped on a stick and the
[01:21:42.760 --> 01:21:44.360]   stick snapped.
[01:21:44.360 --> 01:21:45.760]   And he recorded that sound.
[01:21:45.760 --> 01:21:48.360]   And that's actually been a lot of photos.
[01:21:48.360 --> 01:21:49.360]   It's so Vovos.
[01:21:49.360 --> 01:21:56.000]   That when you do the turn signal, that sound is actually the sound of a twig snapping.
[01:21:56.000 --> 01:21:57.200]   That's so Vovos.
[01:21:57.200 --> 01:22:00.720]   I think that probably they made that up after they did it.
[01:22:00.720 --> 01:22:02.520]   But here is a...
[01:22:02.520 --> 01:22:05.840]   No, you think they really did that?
[01:22:05.840 --> 01:22:06.840]   No.
[01:22:06.840 --> 01:22:07.840]   It feels like a kind of retro.
[01:22:07.840 --> 01:22:09.600]   A retro-style design beautiful.
[01:22:09.600 --> 01:22:14.240]   It's basically a modern sort of fully work.
[01:22:14.240 --> 01:22:15.240]   Here is the...
[01:22:15.240 --> 01:22:16.240]   Can we get to the sound?
[01:22:16.240 --> 01:22:17.240]   Hans Zimmer.
[01:22:17.240 --> 01:22:18.240]   Let's just get to the car.
[01:22:18.240 --> 01:22:21.240]   Making the iPhone sound ominous.
[01:22:21.240 --> 01:22:22.240]   Hans.
[01:22:22.240 --> 01:22:28.240]   I think, you know, given that he was in the Bugles, it should be, you know, the iPhone.
[01:22:28.240 --> 01:22:29.240]   Can we get to the sound?
[01:22:29.240 --> 01:22:30.240]   Hans Zimmer.
[01:22:30.240 --> 01:22:31.240]   Let's just get to the car.
[01:22:31.240 --> 01:22:32.240]   Making the iPhone sound ominous.
[01:22:32.240 --> 01:22:33.240]   To the car.
[01:22:33.240 --> 01:22:34.240]   To the car.
[01:22:34.240 --> 01:22:35.240]   To the car.
[01:22:35.240 --> 01:22:36.240]   Hans Zimmer.
[01:22:36.240 --> 01:22:37.240]   Let's just get to the car.
[01:22:37.240 --> 01:22:38.240]   Making the iPhone sound ominous.
[01:22:38.240 --> 01:22:39.240]   To the car.
[01:22:39.240 --> 01:22:40.240]   Hans Zimmer.
[01:22:40.240 --> 01:22:41.240]   To the car.
[01:22:41.240 --> 01:22:42.240]   Hans Zimmer.
[01:22:42.240 --> 01:22:43.240]   I think, you know, he...
[01:22:43.240 --> 01:22:45.240]   To the road this year.
[01:22:45.240 --> 01:22:48.240]   Oh, come on.
[01:22:48.240 --> 01:22:49.240]   I want to hear the sounds.
[01:22:49.240 --> 01:22:52.240]   I had to sit through this whole dumb video.
[01:22:52.240 --> 01:22:53.240]   Alright.
[01:22:53.240 --> 01:22:58.240]   I think if you have a car, having Hans Zimmer design the sounds is not a bad choice.
[01:22:58.240 --> 01:23:02.240]   Elon Musk speaking, we'll do the Elon Musk segment and then we'll move on.
[01:23:02.240 --> 01:23:03.240]   Speaking of...
[01:23:03.240 --> 01:23:07.240]   Speaking of Elon, had a poll.
[01:23:07.240 --> 01:23:13.040]   Given that Twitter serves as the de facto public town square, failing to adhere to free speech
[01:23:13.040 --> 01:23:15.040]   principles fundamentally undermines democracy.
[01:23:15.040 --> 01:23:18.040]   So he asks, "Free speech is essential to functioning democracy.
[01:23:18.040 --> 01:23:21.040]   Do you believe Twitter rigorously adheres to this principle?"
[01:23:21.040 --> 01:23:26.040]   What do you think the results would be if you had a poll like that on Twitter?
[01:23:26.040 --> 01:23:28.040]   You think they'd say, "Oh, no, no, free speech.
[01:23:28.040 --> 01:23:30.040]   Definitely a big part of Twitter."
[01:23:30.040 --> 01:23:31.040]   No, of course not.
[01:23:31.040 --> 01:23:33.040]   70% said no.
[01:23:33.040 --> 01:23:42.040]   So then Elon, being Elon, he smoked another doobie and said, "Is a new platform needed?"
[01:23:42.040 --> 01:23:47.040]   "Is Elon Musk going to create his own Twitter, by the way?"
[01:23:47.040 --> 01:23:52.040]   After the doobie wore out, he tweeted, "See's the memes of production."
[01:23:52.040 --> 01:23:54.040]   So I don't know how serious he's been.
[01:23:54.040 --> 01:23:57.040]   He'll get to this right after he finally launches Proveda.
[01:23:57.040 --> 01:23:58.040]   Yeah.
[01:23:58.040 --> 01:23:59.040]   Oh, that's right.
[01:23:59.040 --> 01:24:00.040]   That was another thing he wanted to do.
[01:24:00.040 --> 01:24:03.040]   Yeah, that was like four or five years ago.
[01:24:03.040 --> 01:24:04.040]   Yeah.
[01:24:04.040 --> 01:24:06.040]   Although he's got the money.
[01:24:06.040 --> 01:24:11.040]   I mean, if anybody were going to launch the next Twitter, it could be Elon Musk.
[01:24:11.040 --> 01:24:12.040]   Yeah.
[01:24:12.040 --> 01:24:14.040]   Would anybody join it?
[01:24:14.040 --> 01:24:15.040]   I don't think so.
[01:24:15.040 --> 01:24:16.040]   "See's the memes of production."
[01:24:16.040 --> 01:24:19.040]   Well, all his fans and his bots will.
[01:24:19.040 --> 01:24:20.040]   Yeah, that's right.
[01:24:20.040 --> 01:24:21.040]   Let's take a little break.
[01:24:21.040 --> 01:24:22.040]   We'll come back with more.
[01:24:22.040 --> 01:24:23.040]   Sam Ebbels, Sam Ebbels.
[01:24:23.040 --> 01:24:24.040]   Great to have you.
[01:24:24.040 --> 01:24:29.040]   Alan Malventano from Intel, not speaking for Intel.
[01:24:29.040 --> 01:24:32.040]   Not speaking for Microsoft, but of Microsoft, Loomareska.
[01:24:32.040 --> 01:24:35.040]   Also host of this week in Enterprise Tech.
[01:24:35.040 --> 01:24:39.040]   I don't know if you've noticed, but my weight goes up and down quite a bit.
[01:24:39.040 --> 01:24:44.040]   I finally found a weight loss program I can live with for a long time.
[01:24:44.040 --> 01:24:46.040]   I am a fan of Noom.
[01:24:46.040 --> 01:24:48.040]   I know you've seen the ads.
[01:24:48.040 --> 01:24:50.040]   Lisa is also a big Noom fan.
[01:24:50.040 --> 01:24:52.040]   I have to say, I am so impressed.
[01:24:52.040 --> 01:24:56.040]   I started Noom a year ago because I'd seen all the ads.
[01:24:56.040 --> 01:25:01.040]   Went through the, there's a question and answer process where they kind of identify your, you
[01:25:01.040 --> 01:25:03.040]   know, relationship to food at the beginning.
[01:25:03.040 --> 01:25:04.040]   Went through that.
[01:25:04.040 --> 01:25:05.040]   Lisa was kind of interested.
[01:25:05.040 --> 01:25:06.040]   She said, "You know what?
[01:25:06.040 --> 01:25:07.040]   I'm going to support you.
[01:25:07.040 --> 01:25:08.040]   She never needed to lose weight.
[01:25:08.040 --> 01:25:09.040]   I'm going to support you.
[01:25:09.040 --> 01:25:10.040]   I'm going to do it with you."
[01:25:10.040 --> 01:25:11.040]   I said, "Thank you.
[01:25:11.040 --> 01:25:12.040]   That's great.
[01:25:12.040 --> 01:25:13.040]   We'll do it together."
[01:25:13.040 --> 01:25:15.040]   It's very helpful when your spouse does it with you.
[01:25:15.040 --> 01:25:17.040]   She's lost like 10 pounds, kept it off.
[01:25:17.040 --> 01:25:18.040]   She looks fantastic.
[01:25:18.040 --> 01:25:20.040]   Still a little yo-yo.
[01:25:20.040 --> 01:25:22.040]   But I love Noom.
[01:25:22.040 --> 01:25:27.040]   Noom weight is all about better health through education.
[01:25:27.040 --> 01:25:32.040]   It's a psychology-based approach that helps you change the way you think about food and
[01:25:32.040 --> 01:25:35.040]   health rather than demanding you change your entire lifestyle.
[01:25:35.040 --> 01:25:39.040]   One of the things Lisa loved and I love is there are no bad foods.
[01:25:39.040 --> 01:25:41.040]   A lot of diets say, "Well, you can't eat that."
[01:25:41.040 --> 01:25:42.040]   Or, "You can't eat that."
[01:25:42.040 --> 01:25:45.040]   Of course, my elephant mind, that's the thing I want.
[01:25:45.040 --> 01:25:46.040]   "Can't eat cupcakes.
[01:25:46.040 --> 01:25:51.040]   I'm going to eat cupcakes and I'm going to eat them in excess."
[01:25:51.040 --> 01:25:54.040]   Noom doesn't restrict what you can eat or you can't eat.
[01:25:54.040 --> 01:25:58.040]   It gives you the knowledge and wisdom you need to make informed choices.
[01:25:58.040 --> 01:26:03.040]   You log what you eat, which by the way, just by itself is very helpful in understanding
[01:26:03.040 --> 01:26:04.040]   what you're doing.
[01:26:04.040 --> 01:26:08.040]   Then they have these lessons in which you learn about your relationship with food.
[01:26:08.040 --> 01:26:09.040]   For instance, I'm a fog eater.
[01:26:09.040 --> 01:26:11.040]   I eat unconsciously.
[01:26:11.040 --> 01:26:16.040]   They gave me a lot of tips that help me be very conscious and mindful as I'm eating.
[01:26:16.040 --> 01:26:17.040]   Lisa and I will do that together.
[01:26:17.040 --> 01:26:20.040]   She said, "Oh, turn off the TV.
[01:26:20.040 --> 01:26:22.040]   Let's put your fork down after your first bite.
[01:26:22.040 --> 01:26:23.040]   Taste it.
[01:26:23.040 --> 01:26:24.040]   It's fun.
[01:26:24.040 --> 01:26:25.040]   I love doing it."
[01:26:25.040 --> 01:26:29.040]   Noom understands building long-term positive habits can be hard.
[01:26:29.040 --> 01:26:31.040]   It is filled with ups and downs.
[01:26:31.040 --> 01:26:34.680]   It's about progress, not about perfection.
[01:26:34.680 --> 01:26:37.760]   Everybody's journey looks different, but I have to say, "Noom works.
[01:26:37.760 --> 01:26:38.760]   I love it.
[01:26:38.760 --> 01:26:39.760]   I feel better.
[01:26:39.760 --> 01:26:41.040]   I've lost weight.
[01:26:41.040 --> 01:26:42.040]   My clothes fit.
[01:26:42.040 --> 01:26:43.160]   Lisa looks great.
[01:26:43.160 --> 01:26:44.160]   It really works.
[01:26:44.160 --> 01:26:47.280]   It affects 75% of users finish the program.
[01:26:47.280 --> 01:26:49.120]   That's unheard of.
[01:26:49.120 --> 01:26:50.960]   It's based in science.
[01:26:50.960 --> 01:26:53.760]   It's not airy, fairy.
[01:26:53.760 --> 01:26:55.840]   It's not made up.
[01:26:55.840 --> 01:26:57.240]   Science is at the heart of everything they do.
[01:26:57.240 --> 01:27:02.600]   They've published 30 peer-reviewed scientific articles that inform users and practitioners
[01:27:02.600 --> 01:27:08.000]   and scientists in the public about how Noom works and about how effective it is.
[01:27:08.000 --> 01:27:09.840]   It's proven.
[01:27:09.840 --> 01:27:13.040]   With Noom taking care of your health is empowering instead of stress-inducing.
[01:27:13.040 --> 01:27:17.040]   I know you've seen the Noom ads and you've seen all the publicity about Noom.
[01:27:17.040 --> 01:27:18.920]   I'm here to tell you it works.
[01:27:18.920 --> 01:27:19.920]   It works for me.
[01:27:19.920 --> 01:27:20.920]   It works for Lisa.
[01:27:20.920 --> 01:27:24.120]   It works for so many people we know.
[01:27:24.120 --> 01:27:25.920]   It's not punitive.
[01:27:25.920 --> 01:27:27.320]   You don't have to fear.
[01:27:27.320 --> 01:27:30.360]   You get a bad day and off day.
[01:27:30.360 --> 01:27:31.600]   You haven't ruined your program.
[01:27:31.600 --> 01:27:33.600]   Noom has to get back on track.
[01:27:33.600 --> 01:27:35.840]   Noom weight fits beautifully into your life.
[01:27:35.840 --> 01:27:37.800]   Five, 10, 15 minutes a day.
[01:27:37.800 --> 01:27:42.040]   However much time you want to spend on the app is up to you.
[01:27:42.040 --> 01:27:43.600]   It is not judgmental.
[01:27:43.600 --> 01:27:45.880]   You get a coach who works with you.
[01:27:45.880 --> 01:27:51.000]   You get a group which is for a lot of people very healthy and helpful to have other people
[01:27:51.000 --> 01:27:52.880]   doing in the same journey.
[01:27:52.880 --> 01:27:54.320]   I think they've really figured this out.
[01:27:54.320 --> 01:27:55.640]   I am a big fan.
[01:27:55.640 --> 01:27:58.160]   Start building better habits today.
[01:27:58.160 --> 01:28:01.160]   Sign up for your trial.
[01:28:01.160 --> 01:28:02.760]   N-O-O-M.
[01:28:02.760 --> 01:28:04.920]   Noom.com/twit.
[01:28:04.920 --> 01:28:06.040]   And I believe in this.
[01:28:06.040 --> 01:28:06.960]   This is so great.
[01:28:06.960 --> 01:28:09.800]   Noom.com/twit.
[01:28:09.800 --> 01:28:10.800]   Start that trial today.
[01:28:10.800 --> 01:28:13.240]   I think you will thank me for it.
[01:28:13.240 --> 01:28:14.240]   I really do.
[01:28:14.240 --> 01:28:16.440]   In fact, I have already talked to many people who have.
[01:28:16.440 --> 01:28:20.120]   It's very exciting.
[01:28:20.120 --> 01:28:21.120]   Let's see.
[01:28:21.120 --> 01:28:23.880]   We're going to move on to our Quick Takes section.
[01:28:23.880 --> 01:28:26.400]   They don't have to be quick.
[01:28:26.400 --> 01:28:28.080]   Nothing we do here is quick.
[01:28:28.080 --> 01:28:34.400]   Roku has updated its OS 11 personalized photo screens over.
[01:28:34.400 --> 01:28:35.560]   Finally, I know.
[01:28:35.560 --> 01:28:38.800]   Although I still think Roku probably, I know.
[01:28:38.800 --> 01:28:39.960]   Who do you like, Alan?
[01:28:39.960 --> 01:28:43.320]   Who has the best software in your opinion?
[01:28:43.320 --> 01:28:44.720]   Was it you who said finally or was it Lou?
[01:28:44.720 --> 01:28:45.720]   I think it was you.
[01:28:45.720 --> 01:28:46.720]   I said finally.
[01:28:46.720 --> 01:28:47.720]   Oh, Lou, what do you like?
[01:28:47.720 --> 01:28:51.240]   You have a family and a bunch of people watching TV.
[01:28:51.240 --> 01:28:52.240]   You have a challenge.
[01:28:52.240 --> 01:28:53.400]   I was a court car a long time ago.
[01:28:53.400 --> 01:28:54.760]   I started out with Roku.
[01:28:54.760 --> 01:28:56.880]   I've had all of them.
[01:28:56.880 --> 01:28:59.600]   I have the ultimate, the ultra's, the expresses.
[01:28:59.600 --> 01:29:02.920]   I just really disappointed over the years on how they've just been really static with
[01:29:02.920 --> 01:29:04.440]   what they've offered.
[01:29:04.440 --> 01:29:07.080]   The performance's abilities changed.
[01:29:07.080 --> 01:29:10.040]   I've turned everything into Apple TV now.
[01:29:10.040 --> 01:29:12.240]   It's three times more expensive.
[01:29:12.240 --> 01:29:14.560]   I like the Shield TVs.
[01:29:14.560 --> 01:29:15.920]   Oh, those shields are great.
[01:29:15.920 --> 01:29:17.480]   You know what's wrong with the Shield?
[01:29:17.480 --> 01:29:18.480]   I had both shields.
[01:29:18.480 --> 01:29:20.480]   I had the new Shield and the old one.
[01:29:20.480 --> 01:29:23.720]   Not the stick, the big box.
[01:29:23.720 --> 01:29:25.040]   They've kept it up to date.
[01:29:25.040 --> 01:29:28.440]   They have a tegrib in there, which means it's got a lot of processing power.
[01:29:28.440 --> 01:29:32.960]   I've been playing the GeForce games now, games on it, and it's got plenty of power for that.
[01:29:32.960 --> 01:29:38.120]   But there's not enough, at least in my nick of the woods, the XFINITY will not let me
[01:29:38.120 --> 01:29:40.320]   run HBO now on it.
[01:29:40.320 --> 01:29:41.480]   Show time anytime.
[01:29:41.480 --> 01:29:43.440]   Oh, the app support doesn't look like it.
[01:29:43.440 --> 01:29:44.440]   The app support is not there.
[01:29:44.440 --> 01:29:48.720]   I wish it were because I would absolutely, it's got the most power anyway.
[01:29:48.720 --> 01:29:51.120]   Isn't that just running Android TV?
[01:29:51.120 --> 01:29:54.200]   You can just get the app straight out of the...
[01:29:54.200 --> 01:29:58.600]   No, but, okay, and this is a really messed up situation.
[01:29:58.600 --> 01:30:01.600]   These channels, none of these channels, want to screw with the cable companies.
[01:30:01.600 --> 01:30:09.280]   Because if HBO or ESPN or anybody weren't on a cable system, they would die on the vine.
[01:30:09.280 --> 01:30:12.880]   We're not yet at the point where cord cutters can support you.
[01:30:12.880 --> 01:30:15.440]   So for most people, people like me, I pay for a cable subscription.
[01:30:15.440 --> 01:30:17.280]   I'm not a cord cutter like you, Lou.
[01:30:17.280 --> 01:30:25.080]   I get HBO now, I guess they call it free because I pay for it through my cable subscription.
[01:30:25.080 --> 01:30:27.200]   But that's on an Apple TV.
[01:30:27.200 --> 01:30:31.920]   They only recently made a deal with Roku and it is not on the shield.
[01:30:31.920 --> 01:30:36.920]   So that's only because XFINITY is my cable writer and they haven't made a deal or some...
[01:30:36.920 --> 01:30:41.920]   I don't know where the buck stops could be HBO, but I think it's knowing XFINITY is almost
[01:30:41.920 --> 01:30:44.520]   certainly them.
[01:30:44.520 --> 01:30:48.000]   So HBO Max, that's what it is, HBO Max.
[01:30:48.000 --> 01:30:49.000]   I can't use it.
[01:30:49.000 --> 01:30:50.960]   I think Showtime anytime doesn't work either.
[01:30:50.960 --> 01:30:53.640]   So it's a limited number of apps I can run, not because they don't run.
[01:30:53.640 --> 01:30:57.040]   They're available on the Android TV app, but because the stupid cable company won't let
[01:30:57.040 --> 01:30:58.040]   me do it.
[01:30:58.040 --> 01:30:59.040]   You just can't use your cable.
[01:30:59.040 --> 01:31:02.080]   Yeah, I could pay 20 bucks extra for it or whatever.
[01:31:02.080 --> 01:31:04.920]   So yeah, you can use the apps.
[01:31:04.920 --> 01:31:08.720]   We use Chromecast with Google TV.
[01:31:08.720 --> 01:31:11.080]   We did Roku back in the old days.
[01:31:11.080 --> 01:31:12.320]   I like that new Chromecast.
[01:31:12.320 --> 01:31:13.320]   Yeah.
[01:31:13.320 --> 01:31:17.360]   And then the new one, I love the interface on there.
[01:31:17.360 --> 01:31:19.520]   It's a nice little remote.
[01:31:19.520 --> 01:31:22.600]   We got them on all our TVs and it works great.
[01:31:22.600 --> 01:31:24.360]   But are you a card cutter?
[01:31:24.360 --> 01:31:25.360]   We haven't had cable.
[01:31:25.360 --> 01:31:27.720]   Yeah, we haven't had cable TV for like six years.
[01:31:27.720 --> 01:31:30.920]   So this is something Comcast taught on a note.
[01:31:30.920 --> 01:31:34.640]   This complaint does not crop up if you're not a cable customer.
[01:31:34.640 --> 01:31:35.640]   Yeah.
[01:31:35.640 --> 01:31:38.440]   So you get another reason to take a cable.
[01:31:38.440 --> 01:31:39.440]   Another reason to take a cable.
[01:31:39.440 --> 01:31:43.240]   Yeah, I pay for YouTube TV, which really gives me everything the cable does.
[01:31:43.240 --> 01:31:44.560]   Does that make you try?
[01:31:44.560 --> 01:31:45.560]   We try the YouTube.
[01:31:45.560 --> 01:31:46.560]   All of us.
[01:31:46.560 --> 01:31:50.920]   Yeah, because if all of us have YouTube TV, does that make us all quasi-cord cutters?
[01:31:50.920 --> 01:31:51.920]   Yeah.
[01:31:51.920 --> 01:31:52.920]   Well, you're dumb.
[01:31:52.920 --> 01:31:59.520]   Yeah, you're dumb if you like me are still paying Comcast for cable and YouTube TV.
[01:31:59.520 --> 01:32:01.360]   That's really dumb.
[01:32:01.360 --> 01:32:08.840]   We tried the YouTube TV trial a couple of years ago and after about three days, we realized,
[01:32:08.840 --> 01:32:12.560]   wait, we have to watch ads and we can't skip them.
[01:32:12.560 --> 01:32:15.440]   It's like this was like after three years of having no cables.
[01:32:15.440 --> 01:32:16.440]   You can skip them?
[01:32:16.440 --> 01:32:17.440]   In fact.
[01:32:17.440 --> 01:32:19.600]   Yeah, well, just, I mean, just the fact that they're there at all.
[01:32:19.600 --> 01:32:20.600]   Right.
[01:32:20.600 --> 01:32:23.080]   You know, was a non-starter and we said, forget that.
[01:32:23.080 --> 01:32:25.200]   Well, it's getting ads because it's not.
[01:32:25.200 --> 01:32:27.200]   It's because it's broadcast.
[01:32:27.200 --> 01:32:28.920]   You're getting the full broadcast.
[01:32:28.920 --> 01:32:32.680]   For instance, right now the Oscars are about an hour off.
[01:32:32.680 --> 01:32:37.520]   I'm got the red carpet and I'm not, I'm recording it on YouTube TV, not on my Tivo.
[01:32:37.520 --> 01:32:39.320]   There's another thing I spent money on.
[01:32:39.320 --> 01:32:40.680]   It's a lifetime.
[01:32:40.680 --> 01:32:43.920]   Subscription to Tivo on my cable.
[01:32:43.920 --> 01:32:47.040]   But I'm doing the YouTube TV because it's very easy to TV art.
[01:32:47.040 --> 01:32:50.000]   In fact, before I left in the morning, I said, get the red carpet and get the Oscars.
[01:32:50.000 --> 01:32:50.920]   It's one button click.
[01:32:50.920 --> 01:32:52.360]   It's great.
[01:32:52.360 --> 01:32:57.720]   And what I'll do is because I'm watching an Apple TV, you can then press the Siri button
[01:32:57.720 --> 01:33:03.320]   and say, skip ahead and you have to know how many minutes this commercial break is and
[01:33:03.320 --> 01:33:07.160]   you'll learn, skip ahead three and a half minutes and it skips right through and goes
[01:33:07.160 --> 01:33:08.320]   to the next thing.
[01:33:08.320 --> 01:33:09.400]   It's great.
[01:33:09.400 --> 01:33:10.880]   So that's the trick.
[01:33:10.880 --> 01:33:13.040]   You have to do it on an Apple TV.
[01:33:13.040 --> 01:33:14.880]   Yeah, it's true.
[01:33:14.880 --> 01:33:15.880]   Yeah.
[01:33:15.880 --> 01:33:18.520]   There's a lot of services out there like Paramount Plaza.
[01:33:18.520 --> 01:33:21.440]   All of them still make you watch, you pay for them and you still watch commercials and
[01:33:21.440 --> 01:33:22.640]   you can't skip them.
[01:33:22.640 --> 01:33:23.640]   Well, yeah.
[01:33:23.640 --> 01:33:24.640]   So I don't mind.
[01:33:24.640 --> 01:33:25.640]   Well, they have different plans though.
[01:33:25.640 --> 01:33:27.720]   You can get the cheaper plans with ads.
[01:33:27.720 --> 01:33:28.720]   Yeah.
[01:33:28.720 --> 01:33:30.040]   And the problem, I don't know if this has gotten better.
[01:33:30.040 --> 01:33:32.640]   I spend way too much money on TV obviously.
[01:33:32.640 --> 01:33:35.040]   So I pay for the Hulu that doesn't have the ads.
[01:33:35.040 --> 01:33:36.680]   But the ads were driving me crazy.
[01:33:36.680 --> 01:33:40.080]   Finacy, one more Captain obvious Expedia ad.
[01:33:40.080 --> 01:33:42.680]   I was going to shoot the TV.
[01:33:42.680 --> 01:33:46.320]   That's the other thing where you'll get the ads, but they'll come in this wave where
[01:33:46.320 --> 01:33:50.440]   you got caught in some back corner of the algorithm where it's just like every ad you
[01:33:50.440 --> 01:33:56.200]   get is going to be this one ad right now for the next like day, right, on all your devices.
[01:33:56.200 --> 01:33:57.200]   That's the same ad.
[01:33:57.200 --> 01:33:58.200]   It's just crazy.
[01:33:58.200 --> 01:34:03.440]   All I've done is convinced me to spend an extra five bucks a month and not have the ads.
[01:34:03.440 --> 01:34:07.560]   We're in a bad, the other is a bad time where it's kind of a transitional period and nothing
[01:34:07.560 --> 01:34:09.560]   works quite right.
[01:34:09.560 --> 01:34:16.840]   And the other key to using streaming services is to not be shy about canceling them.
[01:34:16.840 --> 01:34:20.400]   If there's something you're not watching, if there's a service, there's nothing on your
[01:34:20.400 --> 01:34:21.400]   watching right now.
[01:34:21.400 --> 01:34:22.400]   Yes.
[01:34:22.400 --> 01:34:23.400]   Just cancel them.
[01:34:23.400 --> 01:34:24.400]   And it's so easy to do now.
[01:34:24.400 --> 01:34:29.640]   I can go in and I can cancel stars or we just canceled Hulu a couple of months ago.
[01:34:29.640 --> 01:34:31.800]   And we'll bring it back in a few months.
[01:34:31.800 --> 01:34:33.880]   When there's stuff we want to see again.
[01:34:33.880 --> 01:34:37.800]   And we just stuff gets on and gets turned on and off.
[01:34:37.800 --> 01:34:43.920]   And so the whole bill, the total bill stays fairly manageable.
[01:34:43.920 --> 01:34:53.520]   Speaking of Google TV, the Apple TV app on your shield or on your Google TV no longer
[01:34:53.520 --> 01:34:56.440]   lets you buy or rent movies from Apple TV.
[01:34:56.440 --> 01:34:57.440]   Okay, fine.
[01:34:57.440 --> 01:35:02.440]   And they don't, they like others don't want to pay Google the 30% vig.
[01:35:02.440 --> 01:35:03.440]   Oh, funny.
[01:35:03.440 --> 01:35:04.880]   What even worse?
[01:35:04.880 --> 01:35:13.280]   They have a button on there, which they prevent, by the way, on the Apple devices that has
[01:35:13.280 --> 01:35:18.440]   a how to watch button that says, oh, you can't buy on this, but you can always go to the
[01:35:18.440 --> 01:35:20.880]   website and buy it or use it.
[01:35:20.880 --> 01:35:23.360]   And that's exactly against Apple's own rules.
[01:35:23.360 --> 01:35:24.360]   Talk about hypocrites.
[01:35:24.360 --> 01:35:27.280]   Yeah, that's the thing they don't want anybody else to do and they're doing it.
[01:35:27.280 --> 01:35:28.280]   Oh, great.
[01:35:28.280 --> 01:35:36.320]   Anyway, I shouldn't get up in arms about this.
[01:35:36.320 --> 01:35:37.320]   It's just funny.
[01:35:37.320 --> 01:35:39.160]   It just cracks me in.
[01:35:39.160 --> 01:35:43.840]   Finally, the I fix it tear down of the new Max is out in the new display.
[01:35:43.840 --> 01:35:46.080]   Boy, these are beautifully built.
[01:35:46.080 --> 01:35:47.080]   I don't know.
[01:35:47.080 --> 01:35:49.160]   They're not Intel boxes, Alan.
[01:35:49.160 --> 01:35:50.160]   Okay.
[01:35:50.160 --> 01:35:52.480]   But as an engineer, you've got a.
[01:35:52.480 --> 01:35:55.520]   Hey, I appreciate a well, well built piece of heart.
[01:35:55.520 --> 01:35:56.520]   Beautiful.
[01:35:56.520 --> 01:35:57.520]   Beautiful piece of hardware.
[01:35:57.520 --> 01:35:59.840]   That's a big honking chip.
[01:35:59.840 --> 01:36:01.000]   Oh, yeah.
[01:36:01.000 --> 01:36:02.680]   There's the pictures of the chip are hysterical.
[01:36:02.680 --> 01:36:08.160]   It's I mean, it's the ultra is like as big as a match box or something.
[01:36:08.160 --> 01:36:13.640]   Well, have we seen a picture of the chip without the the spreader on it?
[01:36:13.640 --> 01:36:14.640]   Yes, it's spreader.
[01:36:14.640 --> 01:36:15.640]   So the actual dot.
[01:36:15.640 --> 01:36:17.720]   Yeah, let me show you how big is that actually?
[01:36:17.720 --> 01:36:18.720]   It's big.
[01:36:18.720 --> 01:36:23.240]   As I said on one show, it's as big as your middle finger, which is the message Apple's
[01:36:23.240 --> 01:36:24.240]   sending to Intel.
[01:36:24.240 --> 01:36:26.240]   No, I'm sorry.
[01:36:26.240 --> 01:36:29.320]   I shouldn't say that out loud.
[01:36:29.320 --> 01:36:31.360]   Max Tech was the first to do a tear down.
[01:36:31.360 --> 01:36:38.560]   And let me jump ahead in his video because I was impressed because he was he was going
[01:36:38.560 --> 01:36:43.760]   to have to put it back again, which is I know the first the first ones I saw, you know,
[01:36:43.760 --> 01:36:48.600]   was just the the package, you know, with a next to a rising that was like three times
[01:36:48.600 --> 01:36:49.960]   the size of a rising seven.
[01:36:49.960 --> 01:36:52.640]   Well, that's as far as he yeah, he that's as far as he's gotten.
[01:36:52.640 --> 01:36:55.600]   So here he is taking the heat spreader off.
[01:36:55.600 --> 01:36:56.600]   Here's the die.
[01:36:56.600 --> 01:36:59.600]   And there you see the thermal paste on that.
[01:36:59.600 --> 01:37:02.400]   He's going to actually rub off the thermal paste.
[01:37:02.400 --> 01:37:03.840]   Oh, yes, there it is.
[01:37:03.840 --> 01:37:04.840]   There it is.
[01:37:04.840 --> 01:37:10.120]   So that where that where that is that that same footprint on that footprint.
[01:37:10.120 --> 01:37:14.320]   That's yeah, because that's where the thermal paste is the rest of this dive.
[01:37:14.320 --> 01:37:21.680]   The chip is filled with ram and the, you know, the pro res playback stuff and the AI stuff
[01:37:21.680 --> 01:37:23.040]   and all of that stuff.
[01:37:23.040 --> 01:37:25.280]   But he does later put a rise in next to it.
[01:37:25.280 --> 01:37:27.360]   Let me see if I can get to that part of the video.
[01:37:27.360 --> 01:37:28.360]   They run pretty cool.
[01:37:28.360 --> 01:37:30.360]   So probably why there's a small.
[01:37:30.360 --> 01:37:32.200]   The heat spreader so small.
[01:37:32.200 --> 01:37:36.920]   Well, there's one on the top and the bottom, which is kind of interesting.
[01:37:36.920 --> 01:37:40.320]   These I don't think they're trying to run quite as cool because I think they really want
[01:37:40.320 --> 01:37:44.680]   to maximize the the output of these things.
[01:37:44.680 --> 01:37:47.480]   So they the fan is always on on this.
[01:37:47.480 --> 01:37:49.360]   It never I ran a process.
[01:37:49.360 --> 01:37:51.080]   It was very CPU intensive.
[01:37:51.080 --> 01:37:53.000]   I pegged the CPUs all.
[01:37:53.000 --> 01:37:54.000]   Let's see.
[01:37:54.000 --> 01:37:55.000]   This is the max studio.
[01:37:55.000 --> 01:37:56.000]   There it is.
[01:37:56.000 --> 01:37:57.000]   It's the rise in next to it.
[01:37:57.000 --> 01:37:58.000]   I have the ultra at home.
[01:37:58.000 --> 01:37:59.000]   Lisa has the ultra.
[01:37:59.000 --> 01:38:03.800]   I pegged the CPUs for a long period of time as a photogrammetry project.
[01:38:03.800 --> 01:38:08.200]   Alex Lindsey gave me and it never even got appreciably warm.
[01:38:08.200 --> 01:38:11.640]   The air coming out the back was no warmer and it and the fans didn't ramp up or down.
[01:38:11.640 --> 01:38:14.200]   They're just on nonstop and the thermals were very good.
[01:38:14.200 --> 01:38:15.920]   I was looking at the temperatures.
[01:38:15.920 --> 01:38:16.920]   Thermals are very good.
[01:38:16.920 --> 01:38:18.160]   How noticeable is the fan blowing?
[01:38:18.160 --> 01:38:19.560]   They don't hear it at all.
[01:38:19.560 --> 01:38:20.560]   It's just.
[01:38:20.560 --> 01:38:21.560]   You turn it on.
[01:38:21.560 --> 01:38:26.400]   It's a it's this weird thrusters and I think they're very big and they move a lot of air.
[01:38:26.400 --> 01:38:27.400]   So I don't think you hear them.
[01:38:27.400 --> 01:38:28.400]   Yeah.
[01:38:28.400 --> 01:38:29.400]   It's like a light white noise sound.
[01:38:29.400 --> 01:38:30.400]   Yeah.
[01:38:30.400 --> 01:38:31.400]   Not even that.
[01:38:31.400 --> 01:38:32.400]   You have to put your ear next to it.
[01:38:32.400 --> 01:38:33.400]   Right.
[01:38:33.400 --> 01:38:40.680]   But I have to say I compared it processor wise on this photogrammetry project to the same
[01:38:40.680 --> 01:38:47.760]   project running on a PC running Linux with a radion or an NVIDIA GTX 3080 and it was
[01:38:47.760 --> 01:38:50.520]   much faster.
[01:38:50.520 --> 01:38:53.960]   Was it was it accelerated by?
[01:38:53.960 --> 01:38:58.840]   Well, I think the software it's called Metashape, which they write for Windows Mac and Linux.
[01:38:58.840 --> 01:39:01.920]   I was running on a Linux machine.
[01:39:01.920 --> 01:39:04.280]   I don't know how well tuned it is for the M1.
[01:39:04.280 --> 01:39:08.080]   It was M1 software, but I don't know how well tuned it is for the GPUs and the M1.
[01:39:08.080 --> 01:39:09.720]   So these are system GPUs.
[01:39:09.720 --> 01:39:12.400]   They're on that chip and I don't know.
[01:39:12.400 --> 01:39:14.400]   It didn't look like it was using the GPUs as much.
[01:39:14.400 --> 01:39:17.440]   On the other hand on the PC it was pegging the 3080.
[01:39:17.440 --> 01:39:18.680]   It was really using the GPU.
[01:39:18.680 --> 01:39:24.280]   And the GPU bound stuff was like three or four times faster.
[01:39:24.280 --> 01:39:25.440]   But that's important.
[01:39:25.440 --> 01:39:33.000]   What it means is that just going out and buying the Ultra doesn't guarantee you a faster process.
[01:39:33.000 --> 01:39:35.520]   You need to have software that's tuned for it.
[01:39:35.520 --> 01:39:41.720]   And in fact, Apple shows the graph at 200 watts, how oh, we're just as good as the 3090
[01:39:41.720 --> 01:39:42.720]   at 200 watts.
[01:39:42.720 --> 01:39:47.640]   What they don't mention is the 3090 can go to 400 watts and will in fact outpass the
[01:39:47.640 --> 01:39:48.640]   Ultra.
[01:39:48.640 --> 01:39:53.960]   If heat and power are not a concern, which they're not on a desktop, then you don't
[01:39:53.960 --> 01:39:57.080]   have the fastest chip on the block.
[01:39:57.080 --> 01:40:00.640]   And Apple really obfuscates that, I think.
[01:40:00.640 --> 01:40:04.200]   So I'm happy to have these, but I think you really need to know what you're...
[01:40:04.200 --> 01:40:06.720]   First of all, you don't need one of these unless you're using something that's going
[01:40:06.720 --> 01:40:12.640]   to use all these CPUs, which is nothing, just a handful of things.
[01:40:12.640 --> 01:40:18.080]   And secondly, you need to use a tool that is tuned and the hardware that is tuned for
[01:40:18.080 --> 01:40:19.080]   the job you're doing.
[01:40:19.080 --> 01:40:21.320]   And it's not obviously the Apple always.
[01:40:21.320 --> 01:40:23.920]   Well, I mean, that's been the case for a long time though, right?
[01:40:23.920 --> 01:40:25.840]   Like you buy the Apple, you're buying the thing.
[01:40:25.840 --> 01:40:28.960]   As it comes, chances are you're not really going to upgrade it after the fact, right?
[01:40:28.960 --> 01:40:29.960]   Those are founds.
[01:40:29.960 --> 01:40:31.200]   Oh, these are not upgradeable at all.
[01:40:31.200 --> 01:40:32.200]   Right.
[01:40:32.200 --> 01:40:36.160]   Those are just the bounds that you sort of buy into if you go that route, you know, if
[01:40:36.160 --> 01:40:37.920]   that's your cup of tea, then fine.
[01:40:37.920 --> 01:40:43.680]   But you know, the flip side of that is PC enthusiast style folks who just want to build
[01:40:43.680 --> 01:40:46.040]   the fire breathing rig to do whatever.
[01:40:46.040 --> 01:40:47.040]   You can do it.
[01:40:47.040 --> 01:40:48.040]   That's right.
[01:40:48.040 --> 01:40:49.040]   They want to build an Uggum, right?
[01:40:49.040 --> 01:40:50.680]   You're never going to do an Uggum with an iMac.
[01:40:50.680 --> 01:40:51.680]   No.
[01:40:51.680 --> 01:40:52.680]   Right.
[01:40:52.680 --> 01:40:55.920]   First of all, because none of the games you want to run will run on the iMac.
[01:40:55.920 --> 01:40:57.480]   Well, sure.
[01:40:57.480 --> 01:41:02.760]   But even if they did, I have, I think the Uggum number, I don't know, two or three, one
[01:41:02.760 --> 01:41:05.080]   of the heat types, one of the water blocks is on my shelf.
[01:41:05.080 --> 01:41:06.600]   The ultimate gaming machine.
[01:41:06.600 --> 01:41:10.040]   You know that if Colleen gave it to you, it's the Rids, like the one we built.
[01:41:10.040 --> 01:41:11.040]   I think it's the water.
[01:41:11.040 --> 01:41:12.040]   The water.
[01:41:12.040 --> 01:41:13.040]   Cool.
[01:41:13.040 --> 01:41:14.040]   Something.
[01:41:14.040 --> 01:41:15.040]   Yeah, it was like the triple water cold.
[01:41:15.040 --> 01:41:16.520]   It's like, so she has one of them.
[01:41:16.520 --> 01:41:18.960]   Patrick Norton has the other one and I have the third one.
[01:41:18.960 --> 01:41:19.960]   Oh, no, kid.
[01:41:19.960 --> 01:41:20.960]   Yeah.
[01:41:20.960 --> 01:41:23.800]   We're, we're, we're, we're, we're, we're Uggum bros.
[01:41:23.800 --> 01:41:24.800]   I guess.
[01:41:24.800 --> 01:41:29.280]   I'm glad to know the ultimate gaming machine survived, at least in pieces somewhere in
[01:41:29.280 --> 01:41:30.280]   pieces.
[01:41:30.280 --> 01:41:32.680]   It's far from ultimate these days, obviously.
[01:41:32.680 --> 01:41:38.120]   Oh, yeah, that was like a GTX 280 water block or something.
[01:41:38.120 --> 01:41:39.120]   Yeah.
[01:41:39.120 --> 01:41:40.120]   Yeah.
[01:41:40.120 --> 01:41:41.120]   We've built those over the years.
[01:41:41.120 --> 01:41:43.280]   The first one we built was at tech TV.
[01:41:43.280 --> 01:41:48.960]   We built that one with Colleen in the mid 2000s and then we built another one when we started
[01:41:48.960 --> 01:41:51.080]   the new screensavers brought it back.
[01:41:51.080 --> 01:41:54.680]   It was all like, I can, I can wear it was like, Oh, and what do we use?
[01:41:54.680 --> 01:41:56.520]   Oh, you got to use Vosseraptors.
[01:41:56.520 --> 01:41:57.680]   Oh, I remember.
[01:41:57.680 --> 01:41:58.680]   I remember.
[01:41:58.680 --> 01:42:03.880]   And then I think the one we built on tech TV was, um, what was the company with?
[01:42:03.880 --> 01:42:07.040]   And then they had the two cards and you could have a connector between the two cards and
[01:42:07.040 --> 01:42:11.160]   Oh, well, that was, I mean, that was, you talking on the graphics cards?
[01:42:11.160 --> 01:42:12.160]   Yeah.
[01:42:12.160 --> 01:42:13.160]   What was the name of the line?
[01:42:13.160 --> 01:42:14.160]   And V link.
[01:42:14.160 --> 01:42:15.160]   SLI.
[01:42:15.160 --> 01:42:16.160]   Yeah.
[01:42:16.160 --> 01:42:17.160]   Yeah.
[01:42:17.160 --> 01:42:19.280]   But really SLI was like maybe even before.
[01:42:19.280 --> 01:42:20.840]   What was the name of that company that used to be?
[01:42:20.840 --> 01:42:22.640]   It was, what do you mean?
[01:42:22.640 --> 01:42:23.640]   That was Nvidia Nvidia.
[01:42:23.640 --> 01:42:25.640]   No, no, this is pre Nvidia.
[01:42:25.640 --> 01:42:26.640]   It was.
[01:42:26.640 --> 01:42:28.640]   Oh, oh, oh, uh, 3D effects.
[01:42:28.640 --> 01:42:29.640]   3D FX.
[01:42:29.640 --> 01:42:30.640]   Thank you.
[01:42:30.640 --> 01:42:34.240]   And you could, and you could parallelize the cards in some weird way.
[01:42:34.240 --> 01:42:35.240]   Yeah.
[01:42:35.240 --> 01:42:39.920]   You can have a pair of like Voodoo, I don't know what, like 2000s at the time or something.
[01:42:39.920 --> 01:42:40.920]   Man, that was.
[01:42:40.920 --> 01:42:41.920]   Yeah.
[01:42:41.920 --> 01:42:42.920]   Voodoo.
[01:42:42.920 --> 01:42:43.920]   That was it.
[01:42:43.920 --> 01:42:44.920]   Voodoo.
[01:42:44.920 --> 01:42:45.920]   Voodoo.
[01:42:45.920 --> 01:42:46.920]   It was.
[01:42:46.920 --> 01:42:47.920]   Which Nvidia, which Nvidia later acquired, right?
[01:42:47.920 --> 01:42:51.760]   That's their, that's how SLI came about, but it was pre SLI.
[01:42:51.760 --> 01:42:53.240]   Yeah.
[01:42:53.240 --> 01:42:55.440]   Any of you play any of the virtualized things?
[01:42:55.440 --> 01:42:57.640]   Are you a game pass user Alan?
[01:42:57.640 --> 01:42:59.400]   Oh, not Alan.
[01:42:59.400 --> 01:43:00.400]   Lou.
[01:43:00.400 --> 01:43:01.400]   Lou, thank you.
[01:43:01.400 --> 01:43:02.400]   Yes.
[01:43:02.400 --> 01:43:03.400]   A guy over there.
[01:43:03.400 --> 01:43:04.400]   Yes.
[01:43:04.400 --> 01:43:05.840]   My brain is fried.
[01:43:05.840 --> 01:43:06.840]   Sorry, Lou.
[01:43:06.840 --> 01:43:10.000]   I know who you are.
[01:43:10.000 --> 01:43:13.760]   So you use the game that was, is that old ex, old ex cloud.
[01:43:13.760 --> 01:43:15.840]   Now it's called game pass, right?
[01:43:15.840 --> 01:43:16.840]   Right.
[01:43:16.840 --> 01:43:17.840]   It's right correctly.
[01:43:17.840 --> 01:43:18.840]   Yeah.
[01:43:18.840 --> 01:43:19.840]   Game pass is nice.
[01:43:19.840 --> 01:43:22.600]   By the way, that's why I can't remember names because my brain is filled with crap
[01:43:22.600 --> 01:43:23.600]   like that.
[01:43:23.600 --> 01:43:24.600]   It used to be ex cloud.
[01:43:24.600 --> 01:43:25.600]   No, it's game pass.
[01:43:25.600 --> 01:43:28.880]   Well, there's actually ex cloud, a game pass and ex cloud, two different things.
[01:43:28.880 --> 01:43:33.080]   Like ex cloud is you can, you can remotely play from like a mobile phone on their, on
[01:43:33.080 --> 01:43:37.720]   their servers and game pass is just, they give you like a, like a barrage of games that
[01:43:37.720 --> 01:43:39.920]   you can choose from and install for free as part of game pass.
[01:43:39.920 --> 01:43:43.600]   But what do they call ex cloud now then?
[01:43:43.600 --> 01:43:44.600]   I don't know.
[01:43:44.600 --> 01:43:48.240]   I think it's the game pass cloud gaming game pass cloud gaming or something.
[01:43:48.240 --> 01:43:49.840]   They don't call it ex cloud anymore.
[01:43:49.840 --> 01:43:51.840]   That was a code name.
[01:43:51.840 --> 01:43:54.080]   Anyway, so is it as good?
[01:43:54.080 --> 01:43:59.080]   Do I need a 30 80 or 90 or can I just play on Microsoft's GPUs?
[01:43:59.080 --> 01:44:01.320]   Well, there's, I mean, it all depends.
[01:44:01.320 --> 01:44:04.880]   Like if you're playing, you know, first person shooter games is not, it's probably not going
[01:44:04.880 --> 01:44:08.400]   to be super great because of latency is anytime it's going to be a problem with that.
[01:44:08.400 --> 01:44:12.560]   But if you're playing like, you know, Minecraft or something like that, it's great from Minecraft.
[01:44:12.560 --> 01:44:13.560]   Yeah.
[01:44:13.560 --> 01:44:14.560]   Yeah.
[01:44:14.560 --> 01:44:16.240]   I can play Minecraft on a Raspberry Pi.
[01:44:16.240 --> 01:44:19.400]   I don't really need to say for that.
[01:44:19.400 --> 01:44:20.400]   Okay.
[01:44:20.400 --> 01:44:21.400]   Yeah.
[01:44:21.400 --> 01:44:25.400]   We had high hopes for all of these streaming services because not for gaming so much.
[01:44:25.400 --> 01:44:30.400]   I was really, I really thought that this was what Google Microsoft and Vidya and others
[01:44:30.400 --> 01:44:35.920]   were doing to test out the ability to stream software and ultimately was to stream an entire
[01:44:35.920 --> 01:44:40.400]   computer operating system that that was the real.
[01:44:40.400 --> 01:44:44.000]   That's fine except that latency issue just like Lu said.
[01:44:44.000 --> 01:44:45.000]   Really?
[01:44:45.000 --> 01:44:50.080]   That's the problem is that while there's no air on the bottom of my spreadsheet.
[01:44:50.080 --> 01:44:56.400]   Well, you do if you move the mouse and it takes 20 milliseconds or 50 milliseconds for the
[01:44:56.400 --> 01:44:57.560]   mouse to move on your screen.
[01:44:57.560 --> 01:45:00.960]   Or I'm typing in the letter show up a second later.
[01:45:00.960 --> 01:45:01.960]   That's no good.
[01:45:01.960 --> 01:45:02.960]   You're right.
[01:45:02.960 --> 01:45:03.960]   Right.
[01:45:03.960 --> 01:45:07.520]   See, and that's, you know, and in some cases that's an awful, depending on how it's optimized,
[01:45:07.520 --> 01:45:10.600]   but in some cases, there's an awful lot of bandwidth that you would need to go back and
[01:45:10.600 --> 01:45:14.680]   forth to redraw whatever the thing is just to, just for something where locally on the
[01:45:14.680 --> 01:45:16.720]   system, it would barely use any resources at all.
[01:45:16.720 --> 01:45:17.720]   You're right.
[01:45:17.720 --> 01:45:18.720]   Yeah.
[01:45:18.720 --> 01:45:22.160]   Because it's actually less efficient to stream it versus just have it locally.
[01:45:22.160 --> 01:45:27.560]   Microsoft does have Windows streaming Windows solution, right?
[01:45:27.560 --> 01:45:29.760]   Sorry, Windows 365.
[01:45:29.760 --> 01:45:32.680]   No, no, no.
[01:45:32.680 --> 01:45:33.680]   You run their server.
[01:45:33.680 --> 01:45:34.680]   I can't remember what they call it.
[01:45:34.680 --> 01:45:35.680]   The virtual desktop.
[01:45:35.680 --> 01:45:36.680]   Yeah.
[01:45:36.680 --> 01:45:37.680]   Yep.
[01:45:37.680 --> 01:45:38.680]   Yep.
[01:45:38.680 --> 01:45:39.680]   BDI.
[01:45:39.680 --> 01:45:40.680]   Yeah.
[01:45:40.680 --> 01:45:41.680]   I think they have, they've had that for a while.
[01:45:41.680 --> 01:45:42.680]   In fact, a lot of companies use this just to make things more secure.
[01:45:42.680 --> 01:45:47.120]   So like if you have your home machine, your remote worker, you use it as you kind of
[01:45:47.120 --> 01:45:52.280]   jump box into it and those machines are highly patched and they're highly regulated.
[01:45:52.280 --> 01:45:53.560]   That's why I thought it would take off.
[01:45:53.560 --> 01:45:59.320]   The business would want this because they could buy cheap hardware, run Windows virtualized.
[01:45:59.320 --> 01:46:04.000]   They wouldn't have to worry about the IT burden of keeping it up to date, keeping it patched,
[01:46:04.000 --> 01:46:05.000]   all that stuff.
[01:46:05.000 --> 01:46:07.520]   I think I thought that would be a great solution.
[01:46:07.520 --> 01:46:09.400]   Azure virtual desktop.
[01:46:09.400 --> 01:46:11.600]   It's expensive though.
[01:46:11.600 --> 01:46:14.400]   It's more than a PC would be, I think.
[01:46:14.400 --> 01:46:16.320]   So it depends.
[01:46:16.320 --> 01:46:19.120]   It depends how many laces you're buying.
[01:46:19.120 --> 01:46:20.120]   Right.
[01:46:20.120 --> 01:46:21.600]   But you know, I love the idea.
[01:46:21.600 --> 01:46:25.720]   I mean, it really solves so many security issues.
[01:46:25.720 --> 01:46:29.600]   As, I mean, as much as you trust Microsoft, I guess, but who doesn't trust it?
[01:46:29.600 --> 01:46:34.760]   Is that using the same sort of like trick where just the, what was the old school version
[01:46:34.760 --> 01:46:38.480]   where you could just do the equivalent of like VNC locally on your network?
[01:46:38.480 --> 01:46:40.480]   That was just remote desktop, right?
[01:46:40.480 --> 01:46:45.040]   Like it, yeah, you're just remoting into a machine basically that's part of a virtual,
[01:46:45.040 --> 01:46:46.480]   you know, skis server.
[01:46:46.480 --> 01:46:48.080]   And then they just, yeah, exactly.
[01:46:48.080 --> 01:46:53.000]   What I really like about those technologies is that they are effectively like just sending
[01:46:53.000 --> 01:46:54.920]   the draw calls across the network.
[01:46:54.920 --> 01:46:55.920]   It's just vector-based.
[01:46:55.920 --> 01:46:58.280]   It's not, well, it's not just vector.
[01:46:58.280 --> 01:47:01.560]   It's literally like, you know, draw a window here and do this.
[01:47:01.560 --> 01:47:02.560]   Right.
[01:47:02.560 --> 01:47:03.560]   It's not just like changes.
[01:47:03.560 --> 01:47:05.120]   It's actually even deeper than that.
[01:47:05.120 --> 01:47:08.520]   So the local processor is actually drawing.
[01:47:08.520 --> 01:47:09.520]   It's not a video.
[01:47:09.520 --> 01:47:10.520]   It's not a movie stream.
[01:47:10.520 --> 01:47:11.520]   It's a stream of fans.
[01:47:11.520 --> 01:47:12.520]   Yeah, that's right.
[01:47:12.520 --> 01:47:13.520]   Exactly.
[01:47:13.520 --> 01:47:17.960]   You know, when you get that first of all, it's super efficient and you can do lots with
[01:47:17.960 --> 01:47:19.720]   very little bandwidth in those cases, right?
[01:47:19.720 --> 01:47:21.640]   But also it's very effective.
[01:47:21.640 --> 01:47:25.760]   You don't get like, you know, oh, compression artifacts or things like that on the screen.
[01:47:25.760 --> 01:47:26.760]   Right.
[01:47:26.760 --> 01:47:27.760]   Wouldn't really happen as much, right?
[01:47:27.760 --> 01:47:28.760]   Right.
[01:47:28.760 --> 01:47:31.600]   Because it's actually drawing the flonsal locally and doing things like that.
[01:47:31.600 --> 01:47:33.760]   It's clients that we're computing back again.
[01:47:33.760 --> 01:47:38.160]   Well, it's the way Google Maps and services like that work as well.
[01:47:38.160 --> 01:47:39.160]   Yeah.
[01:47:39.160 --> 01:47:40.160]   You know, and stream commands.
[01:47:40.160 --> 01:47:41.160]   Not video.
[01:47:41.160 --> 01:47:42.160]   Yeah.
[01:47:42.160 --> 01:47:43.760]   It's a map of tiles down.
[01:47:43.760 --> 01:47:46.880]   Now it just sends the vector commands and tells you what to draw.
[01:47:46.880 --> 01:47:47.880]   Oh, you know, that's interesting.
[01:47:47.880 --> 01:47:51.080]   Because I remember in the old days of maps, you would see tiles load.
[01:47:51.080 --> 01:47:52.800]   You don't see that anymore, do you?
[01:47:52.800 --> 01:47:53.800]   You're absolutely right.
[01:47:53.800 --> 01:47:55.560]   What happens is it slowly builds.
[01:47:55.560 --> 01:47:59.680]   It adds the places of interest in the street slowly.
[01:47:59.680 --> 01:48:00.680]   You see it all building.
[01:48:00.680 --> 01:48:01.680]   I didn't realize that.
[01:48:01.680 --> 01:48:03.560]   So it's actually gets it in commands down.
[01:48:03.560 --> 01:48:05.320]   Draw this here, draw that there.
[01:48:05.320 --> 01:48:06.320]   That kind of thing.
[01:48:06.320 --> 01:48:07.320]   Yup.
[01:48:07.320 --> 01:48:08.320]   That's interesting.
[01:48:08.320 --> 01:48:10.040]   Do you follow Alan?
[01:48:10.040 --> 01:48:12.920]   Do you follow the Nvidia's?
[01:48:12.920 --> 01:48:14.560]   I know you do, Sam.
[01:48:14.560 --> 01:48:15.560]   In fact, we...
[01:48:15.560 --> 01:48:16.560]   Hack stuff?
[01:48:16.560 --> 01:48:17.560]   Yeah.
[01:48:17.560 --> 01:48:18.560]   Yeah.
[01:48:18.560 --> 01:48:19.560]   Was it GTC?
[01:48:19.560 --> 01:48:20.560]   What do they call it?
[01:48:20.560 --> 01:48:21.560]   GTC.
[01:48:21.560 --> 01:48:22.560]   GTC.
[01:48:22.560 --> 01:48:23.560]   Oh, the GTC conference.
[01:48:23.560 --> 01:48:24.560]   Yeah.
[01:48:24.560 --> 01:48:25.560]   That was this week.
[01:48:25.560 --> 01:48:28.640]   Last year, Sam and I streamed it and I decided not to this year.
[01:48:28.640 --> 01:48:33.400]   Sam, did I miss anything huge?
[01:48:33.400 --> 01:48:34.400]   Not especially.
[01:48:34.400 --> 01:48:36.680]   I mean, there was some interesting stuff.
[01:48:36.680 --> 01:48:44.200]   Last year, Jensen first talked about the Grace CPU, an ARM-based CPU for servers.
[01:48:44.200 --> 01:48:49.360]   And this year, they flushed that out and they showed what they call the Grace CPU Superchip,
[01:48:49.360 --> 01:48:55.000]   which is actually two of these combined together for 144 CPU cores.
[01:48:55.000 --> 01:48:56.000]   Wow.
[01:48:56.000 --> 01:49:02.840]   And a terabyte per second of memory bandwidth, the built-in memory.
[01:49:02.840 --> 01:49:07.280]   But they also announced a new GPU architecture they call Hopper.
[01:49:07.280 --> 01:49:08.280]   Right.
[01:49:08.280 --> 01:49:11.920]   And that goes along with the Grace and Hopper design.
[01:49:11.920 --> 01:49:12.920]   That's the last name.
[01:49:12.920 --> 01:49:13.920]   Oh, I get it.
[01:49:13.920 --> 01:49:14.920]   Yeah.
[01:49:14.920 --> 01:49:16.160]   They're designed to work together.
[01:49:16.160 --> 01:49:18.400]   Hopper's the GPU, Grace is the CPU.
[01:49:18.400 --> 01:49:21.400]   I will point out a naval person.
[01:49:21.400 --> 01:49:23.200]   A naval command?
[01:49:23.200 --> 01:49:24.360]   Commodore or commander?
[01:49:24.360 --> 01:49:25.360]   I can't remember.
[01:49:25.360 --> 01:49:26.360]   Yes.
[01:49:26.360 --> 01:49:27.360]   Yeah.
[01:49:27.360 --> 01:49:29.720]   Next, it's going to be Coball all over again.
[01:49:29.720 --> 01:49:30.720]   I'm excited.
[01:49:30.720 --> 01:49:32.800]   So there was actually some other stuff.
[01:49:32.800 --> 01:49:34.840]   Except a little right at itself in AI.
[01:49:34.840 --> 01:49:35.840]   Thank God.
[01:49:35.840 --> 01:49:39.040]   Anything is better than what we had.
[01:49:39.040 --> 01:49:41.800]   There was some other stuff that peaked my interest from what else.
[01:49:41.800 --> 01:49:42.800]   Yes.
[01:49:42.800 --> 01:49:43.800]   It wasn't just Nvidia.
[01:49:43.800 --> 01:49:45.640]   It was actually coming from Microsoft.
[01:49:45.640 --> 01:49:47.560]   So, you know, Lou doesn't have to say it.
[01:49:47.560 --> 01:49:49.280]   I will gladly promote it for him.
[01:49:49.280 --> 01:49:51.440]   And that's direct storage.
[01:49:51.440 --> 01:49:53.600]   Oh, huge.
[01:49:53.600 --> 01:49:58.560]   Originally on the Xbox, the idea of fast storage.
[01:49:58.560 --> 01:50:00.120]   It's different about direct storage, Alan.
[01:50:00.120 --> 01:50:01.880]   You're a storage expert.
[01:50:01.880 --> 01:50:06.080]   So to distill it down, and again, it's not fully baked yet.
[01:50:06.080 --> 01:50:10.480]   For example, they don't have the graphics decompression piece in or the pass the data
[01:50:10.480 --> 01:50:12.880]   directly to the GPU piece in yet.
[01:50:12.880 --> 01:50:13.880]   But they have an API.
[01:50:13.880 --> 01:50:15.680]   And that's all that we need.
[01:50:15.680 --> 01:50:16.680]   There's an API.
[01:50:16.680 --> 01:50:22.240]   They don't have that other API, but there's the API to get the stuff off of the SSD quickly.
[01:50:22.240 --> 01:50:28.520]   And to bypass some portions of the what's historically a very long stack of code that
[01:50:28.520 --> 01:50:31.400]   a request to an SSD normally has to go through.
[01:50:31.400 --> 01:50:34.280]   So the idea is that, hey, I'm doing these types of things.
[01:50:34.280 --> 01:50:37.000]   I don't need to worry about X, Y, and Z in the process.
[01:50:37.000 --> 01:50:43.000]   I can sort of optimize this code path so that I'm using less CPU resources just to request
[01:50:43.000 --> 01:50:46.640]   something from the SSD, just to do a request.
[01:50:46.640 --> 01:50:50.720]   And then there's some other things in there in terms of batching.
[01:50:50.720 --> 01:50:56.560]   So they're trying to, and part of this is actually wouldn't be necessary if not for
[01:50:56.560 --> 01:51:03.160]   game developers just generally speaking, not necessarily optimizing around SSD, just the
[01:51:03.160 --> 01:51:06.000]   fact that you have fast storage, right?
[01:51:06.000 --> 01:51:10.120]   Many of the games that exist, the game engines that exist today, when they load things, they're
[01:51:10.120 --> 01:51:13.800]   doing it, you know, not optimally.
[01:51:13.800 --> 01:51:18.440]   You could get much better speeds out of a SSD if you requested things in a slightly
[01:51:18.440 --> 01:51:19.560]   different way.
[01:51:19.560 --> 01:51:24.960]   And so part of the direct storage API is encouraging this thing called batching, which is where
[01:51:24.960 --> 01:51:30.960]   don't just ask for 4K 10,000 times in a row, you know, 4 kilobytes of information over
[01:51:30.960 --> 01:51:33.360]   and over again, you know, you should do larger requests.
[01:51:33.360 --> 01:51:35.680]   You should do them in batches, right?
[01:51:35.680 --> 01:51:40.160]   Ask for, hey, I need this 1 gigabyte of data from this file.
[01:51:40.160 --> 01:51:44.280]   And so the idea with direct storage is you just make that request as the game engine,
[01:51:44.280 --> 01:51:47.840]   and then direct storage takes care of all the smaller requests, but it's able to do
[01:51:47.840 --> 01:51:53.120]   them in a much more optimized way that the SSD is going to go closer to its full speed,
[01:51:53.120 --> 01:51:54.120]   right?
[01:51:54.120 --> 01:51:57.600]   So what we're acting is if they were spinning hard drives that you couldn't, you'd have
[01:51:57.600 --> 01:52:03.320]   to wait the drive came around so you had these block sizes and you'd load it by block.
[01:52:03.320 --> 01:52:08.480]   It wasn't necessarily that bad, but it was just suboptimal, right?
[01:52:08.480 --> 01:52:11.480]   So it was only, it was only asking for one thing at a time.
[01:52:11.480 --> 01:52:16.560]   It's random access can do a big chunk at once, is that?
[01:52:16.560 --> 01:52:22.320]   Well, for SSDs, especially for NAND, right, Optane less so has this issue, but for NAND
[01:52:22.320 --> 01:52:27.960]   in particular, you can't really get, you know, you have a Gen 4 super fancy, you know,
[01:52:27.960 --> 01:52:30.720]   fire breathing SSD like top of the line right now.
[01:52:30.720 --> 01:52:33.800]   And it's supposed to go 7 gig per second in a straight line.
[01:52:33.800 --> 01:52:34.800]   Wow.
[01:52:34.800 --> 01:52:35.800]   Sequential through foot, right?
[01:52:35.800 --> 01:52:39.200]   And we're about to move, we're about to move to 14 when we do Gen 5 SSDs when those
[01:52:39.200 --> 01:52:40.760]   start coming out.
[01:52:40.760 --> 01:52:46.160]   But because it's NAND and each request has a certain turnaround time, you can't actually
[01:52:46.160 --> 01:52:50.160]   hit that 7 gig per second if you only ask for one little thing at a time.
[01:52:50.160 --> 01:52:51.160]   Right.
[01:52:51.160 --> 01:52:53.280]   So there is that turnaround time.
[01:52:53.280 --> 01:52:54.560]   So yeah, there is a turnaround time.
[01:52:54.560 --> 01:53:02.080]   So if you ask the SSD, say, hey, I need, you know, give me 128 of these 32K kilobyte
[01:53:02.080 --> 01:53:04.560]   chunks at once, right?
[01:53:04.560 --> 01:53:08.040]   You'll still have that turnaround time, but once the time is up, you'll start getting
[01:53:08.040 --> 01:53:11.080]   a fire hose of all of those requests will start coming in, right?
[01:53:11.080 --> 01:53:16.240]   And overall, you'll get much closer to that 7 gig per second that you could get theoretically
[01:53:16.240 --> 01:53:17.320]   from that thing, right?
[01:53:17.320 --> 01:53:19.320]   So this is a matter of how do you ask for the data?
[01:53:19.320 --> 01:53:27.080]   This was G D as in developers conference as opposed to G T, which is the NVIDIA conference.
[01:53:27.080 --> 01:53:28.840]   I understand the confusion.
[01:53:28.840 --> 01:53:29.840]   Oh, right.
[01:53:29.840 --> 01:53:30.840]   But they both happen.
[01:53:30.840 --> 01:53:31.840]   Sorry.
[01:53:31.840 --> 01:53:32.840]   They both happen.
[01:53:32.840 --> 01:53:33.840]   And this is actually a huge deal.
[01:53:33.840 --> 01:53:37.880]   Although ours, Technik and Rook Cunningham writing said that some of the improvements that
[01:53:37.880 --> 01:53:43.480]   you might expect were slowed down in the real world because of CPU bottlenecks.
[01:53:43.480 --> 01:53:49.200]   Yes, that's the other piece of this, which is all of those requests as they're going
[01:53:49.200 --> 01:53:50.760]   to the SSD.
[01:53:50.760 --> 01:53:54.800]   There is a slightly different code path that you can take through the operating system,
[01:53:54.800 --> 01:53:55.800]   right?
[01:53:55.800 --> 01:53:59.440]   Because realize operating systems have various layers of obfuscation to get to the storage,
[01:53:59.440 --> 01:54:00.440]   right?
[01:54:00.440 --> 01:54:04.840]   For example, me doing my SSD testing, I know that I can only get so many requests per
[01:54:04.840 --> 01:54:12.320]   second from an SSD with like one thread, just like one application thread running on a CPU,
[01:54:12.320 --> 01:54:13.320]   right?
[01:54:13.320 --> 01:54:14.400]   There is a top end of that.
[01:54:14.400 --> 01:54:20.640]   And that top end is based on the CPU pegs because it's repeatedly running this code for each
[01:54:20.640 --> 01:54:21.640]   request.
[01:54:21.640 --> 01:54:23.160]   It has to go through the kernel and go through all the different--
[01:54:23.160 --> 01:54:26.080]   The hardware abstraction layer and all of that.
[01:54:26.080 --> 01:54:27.720]   Yeah, it has to go through all those layers.
[01:54:27.720 --> 01:54:35.720]   Well, there is a more direct path that can be taken by using the direct storage API, which
[01:54:35.720 --> 01:54:38.640]   bypasses some of those layers, right?
[01:54:38.640 --> 01:54:41.480]   Because again, the context is that you're not doing regular computer stuff.
[01:54:41.480 --> 01:54:45.160]   You're actually just loading game textures and data and whatnot.
[01:54:45.160 --> 01:54:50.360]   You don't have to do all of the other things you would normally do for a generic multi-purpose
[01:54:50.360 --> 01:54:53.160]   IO request to disk, right?
[01:54:53.160 --> 01:54:55.680]   You don't need to update the last time the file was accessed.
[01:54:55.680 --> 01:54:58.960]   You don't need to do all these other things every time you do one of those requests.
[01:54:58.960 --> 01:55:03.600]   So right now it's in gaming, particularly on the Xbox Series X.
[01:55:03.600 --> 01:55:08.560]   But once it comes to Windows, would you notice a difference in improvement in performance?
[01:55:08.560 --> 01:55:12.720]   I mean, a lot of what we do in Windows isn't loading giant textures.
[01:55:12.720 --> 01:55:14.600]   It's small chunks.
[01:55:14.600 --> 01:55:17.520]   Yeah, so it's going to have bounds.
[01:55:17.520 --> 01:55:21.120]   First of all, the thing has to call the API, right?
[01:55:21.120 --> 01:55:26.960]   So the game developers will have to update their code, their game engines, to use this,
[01:55:26.960 --> 01:55:28.640]   right?
[01:55:28.640 --> 01:55:32.440]   And then once they're using it, it may not necessarily be used for every single point
[01:55:32.440 --> 01:55:33.440]   of the game.
[01:55:33.440 --> 01:55:37.800]   So in other words, if you launch the game, it might launch more like a regular application
[01:55:37.800 --> 01:55:39.640]   with regular API calls.
[01:55:39.640 --> 01:55:42.400]   And then maybe it's not until you're in the game that it's actually using the direct
[01:55:42.400 --> 01:55:46.520]   storage stuff to just sort of transition between levels faster.
[01:55:46.520 --> 01:55:50.080]   That would be the gist of that.
[01:55:50.080 --> 01:55:54.480]   And the reason for making it more CPU efficient for all those requests is that that leaves
[01:55:54.480 --> 01:55:58.680]   more CPU horsepower available for the game to run, right?
[01:55:58.680 --> 01:56:01.240]   You're making the storage piece more efficient.
[01:56:01.240 --> 01:56:10.200]   So then the game developers will, at least in theory, be able to move more towards the
[01:56:10.200 --> 01:56:11.800]   same sort of thing that the Xbox is doing, right?
[01:56:11.800 --> 01:56:17.480]   Where you have seamless transitions between what would have been a loading scene in a
[01:56:17.480 --> 01:56:18.480]   game, right?
[01:56:18.480 --> 01:56:23.240]   It just turns into you just go right into the next thing because it's able to load all
[01:56:23.240 --> 01:56:28.280]   of that stuff faster and more efficiently in the background and not impact the performance
[01:56:28.280 --> 01:56:29.280]   of the game.
[01:56:29.280 --> 01:56:30.280]   Yep.
[01:56:30.280 --> 01:56:32.000]   Let me add to what Alan's saying to it.
[01:56:32.000 --> 01:56:33.520]   It actually has a cascading effect too.
[01:56:33.520 --> 01:56:38.000]   So think about a device like, let's say, a hollow lens that needs to be able to produce
[01:56:38.000 --> 01:56:39.320]   graphics quickly on.
[01:56:39.320 --> 01:56:45.040]   If it can bypass the CPU, it actually will run at a lower amount of power usage, which
[01:56:45.040 --> 01:56:49.680]   means that device will be able to implement these features better and be able to be more
[01:56:49.680 --> 01:56:50.680]   power efficient.
[01:56:50.680 --> 01:56:53.440]   So I think there's a lot of advantages to doing this.
[01:56:53.440 --> 01:56:54.440]   Right.
[01:56:54.440 --> 01:56:59.640]   And that's the other piece that's not fully baked or at least it's not in Windows 11 yet.
[01:56:59.640 --> 01:57:06.720]   And that is, don't only read it from the storage faster and more efficiently, but also the
[01:57:06.720 --> 01:57:13.000]   CPU doesn't need these textures just to go directly to the GPU and let the GPU decompress
[01:57:13.000 --> 01:57:14.280]   it or do whatever it needs to do.
[01:57:14.280 --> 01:57:19.480]   So then potentially the CPU, yes, it's kind of still in the middle, but it's not really
[01:57:19.480 --> 01:57:21.080]   doing stuff in the middle anymore.
[01:57:21.080 --> 01:57:24.400]   You're literally just going right from the SSD to the to the GPU or at least with as
[01:57:24.400 --> 01:57:28.320]   little CPU overhead as possible.
[01:57:28.320 --> 01:57:33.600]   I knew when we had Allen and Lou and Sam on it would get pretty geeky, but I had no idea.
[01:57:33.600 --> 01:57:34.600]   Sorry.
[01:57:34.600 --> 01:57:36.840]   No, I love it.
[01:57:36.840 --> 01:57:37.840]   Are you kidding?
[01:57:37.840 --> 01:57:39.040]   Let's take a little break.
[01:57:39.040 --> 01:57:41.600]   I got a, I got a, I need to, I need to think.
[01:57:41.600 --> 01:57:42.600]   I need to digest.
[01:57:42.600 --> 01:57:49.440]   Hey, while we're doing that though, let me talk a little bit about our newest toy here
[01:57:49.440 --> 01:57:54.600]   in the studio, our TriCaster to elite from New Tech.
[01:57:54.600 --> 01:57:59.880]   You know that when I first started to it back in 2005, I was looking for a switching solution
[01:57:59.880 --> 01:58:06.080]   that would let us have multiple cameras to kind of do like a TV style production, but
[01:58:06.080 --> 01:58:07.080]   without the big cost.
[01:58:07.080 --> 01:58:10.480]   And we chose New Tech because I talked to everybody.
[01:58:10.480 --> 01:58:12.560]   Everybody agreed the TriCaster was the way to go.
[01:58:12.560 --> 01:58:17.240]   Of course it's been 15 years, 17 actually.
[01:58:17.240 --> 01:58:20.600]   And the TriCaster has gotten better and better and better.
[01:58:20.600 --> 01:58:22.200]   And now thank you, New Tech.
[01:58:22.200 --> 01:58:27.960]   You've got the TriCaster to elite, the most complete live production system on the planet.
[01:58:27.960 --> 01:58:33.120]   And I will be honest, we use a fraction of the capabilities, but sure is fun for us to
[01:58:33.120 --> 01:58:34.120]   play with.
[01:58:34.120 --> 01:58:36.600]   New Tech has a full line of TriCasters.
[01:58:36.600 --> 01:58:39.840]   You don't have to select the top of the line like we do.
[01:58:39.840 --> 01:58:41.760]   There's some very affordable choices too.
[01:58:41.760 --> 01:58:48.960]   Churches, colleges, broadcasters, podcasters all love New Tech because it gives you solutions
[01:58:48.960 --> 01:58:53.960]   you can afford that give you capabilities you could only dream of.
[01:58:53.960 --> 01:58:58.880]   The way we use it is of course is a live video production system, but New Tech can do so
[01:58:58.880 --> 01:58:59.880]   much more.
[01:58:59.880 --> 01:59:03.880]   It could be an entire digital media solution creating content for the internet, mobile
[01:59:03.880 --> 01:59:05.720]   and television distribution.
[01:59:05.720 --> 01:59:11.280]   There really is a great time for that because of local sports, local TV stations, national
[01:59:11.280 --> 01:59:14.400]   stations who want to create streaming solutions.
[01:59:14.400 --> 01:59:18.680]   Late in last year, New Tech unleashed an updated version of the TriCaster to elite.
[01:59:18.680 --> 01:59:22.360]   This is what we're using today with so many new features.
[01:59:22.360 --> 01:59:23.920]   Really exciting.
[01:59:23.920 --> 01:59:28.320]   The live call connect feature supports Facebook, messenger, WhatsApp and FaceTime.
[01:59:28.320 --> 01:59:31.160]   That can be an input to any production.
[01:59:31.160 --> 01:59:34.800]   Selectable audio and video return enables TriCaster to elite operators to view an audio
[01:59:34.800 --> 01:59:39.560]   return like any other output allowing greater flexibility.
[01:59:39.560 --> 01:59:44.400]   There's a new, have we ever used this John neural voice isolation tool which takes the
[01:59:44.400 --> 01:59:51.640]   audio, uses AI and can cancel or reduce background noise automatically detect voices.
[01:59:51.640 --> 01:59:56.200]   Incredible especially if you're doing a show with a noisy environment, a race track or
[01:59:56.200 --> 02:00:02.280]   a conference or a worship service, you can really clean up the audio.
[02:00:02.280 --> 02:00:06.480]   You get so much power and flexibility and simplicity as always with all of New Tech's
[02:00:06.480 --> 02:00:07.480]   products.
[02:00:07.480 --> 02:00:10.560]   You've got variable support in macros.
[02:00:10.560 --> 02:00:13.360]   We use macros a lot John's always writing new macros for us.
[02:00:13.360 --> 02:00:19.320]   The dynamic and powerful tool that allows operators to nest macros now, deliver complex
[02:00:19.320 --> 02:00:23.120]   productions more easily and that's mostly how John uses a macros to make it easier for
[02:00:23.120 --> 02:00:27.760]   me in my studio so I can press a button.
[02:00:27.760 --> 02:00:29.000]   It'll take care of it.
[02:00:29.000 --> 02:00:30.000]   That's awesome.
[02:00:30.000 --> 02:00:35.120]   I'm doing all my own switching when I'm in my office but it's mostly thanks to macros
[02:00:35.120 --> 02:00:36.520]   from TriCaster.
[02:00:36.520 --> 02:00:43.280]   TriCaster to elite supports encoding of three channels and anything from HD to UHD simultaneously
[02:00:43.280 --> 02:00:47.360]   they've brought live panel builder into the TriCaster.
[02:00:47.360 --> 02:00:50.040]   This is always a nice post production tool.
[02:00:50.040 --> 02:00:55.120]   Now you can create bespoke user interfaces, customize each preset within the user interface
[02:00:55.120 --> 02:00:59.640]   making your distributed workflow simpler, more cohesive, never compromising on quality.
[02:00:59.640 --> 02:01:01.080]   I can go on and on.
[02:01:01.080 --> 02:01:06.280]   I can rapcidize for hours and I'm not even the primary user.
[02:01:06.280 --> 02:01:09.160]   Our team loves our TriCaster.
[02:01:09.160 --> 02:01:11.400]   We especially love NDI.
[02:01:11.400 --> 02:01:19.200]   The network distributed interface, we have an NDI camera, point zoom, pan tilt zoom camera
[02:01:19.200 --> 02:01:26.360]   above me, that NDI means it doesn't have to have an HDMI connector or an SDI connector.
[02:01:26.360 --> 02:01:31.520]   This camera is controlled by John on the control surface and the only thing plugged into it
[02:01:31.520 --> 02:01:33.200]   is a network cable.
[02:01:33.200 --> 02:01:34.800]   Is it POE as well John?
[02:01:34.800 --> 02:01:35.800]   Yeah.
[02:01:35.800 --> 02:01:37.160]   So we don't even have a power cable.
[02:01:37.160 --> 02:01:39.120]   The whole thing is controlled by a network cable.
[02:01:39.120 --> 02:01:41.960]   The video goes over the network into the TriCaster.
[02:01:41.960 --> 02:01:43.880]   That's awesome.
[02:01:43.880 --> 02:01:45.200]   That's awesome.
[02:01:45.200 --> 02:01:51.360]   The NDI Genlock tool, let's TriCaster 2 Elite customers match outputs to a common sync pulse
[02:01:51.360 --> 02:01:57.280]   so you know everything synced up exactly when to send a frame of video, incredible accuracy
[02:01:57.280 --> 02:02:00.000]   especially needed for a remote workflow.
[02:02:00.000 --> 02:02:02.680]   You can send an alpha channel through one of the mix outs.
[02:02:02.680 --> 02:02:04.880]   You can bring post production closer to live.
[02:02:04.880 --> 02:02:09.840]   This can use the keying on the TriCaster to feed graphics or real time 3D creation tools.
[02:02:09.840 --> 02:02:15.320]   We don't use the keying but boy the TriCaster's key is better every single time.
[02:02:15.320 --> 02:02:17.440]   It's mind boggling.
[02:02:17.440 --> 02:02:22.200]   Since its arrival in 2020, TriCaster 2 Elite has offered an incredibly powerful live production
[02:02:22.200 --> 02:02:23.200]   system.
[02:02:23.200 --> 02:02:27.960]   These very latest updates put even more power in the hands of storytellers.
[02:02:27.960 --> 02:02:29.920]   We only scratch the surface.
[02:02:29.920 --> 02:02:33.480]   Take a look at the TriCaster and see what you can do with it.
[02:02:33.480 --> 02:02:36.560]   It's literally better than broadcast.
[02:02:36.560 --> 02:02:41.600]   It makes me feel really good about choosing TriCaster all those years ago.
[02:02:41.600 --> 02:02:48.040]   The TriCaster 1 Pro, another great choice for producers, content creators, publishers.
[02:02:48.040 --> 02:02:50.240]   It's got great future ready capabilities.
[02:02:50.240 --> 02:02:54.280]   It's a streamlined live video production system with LiveCall Connect.
[02:02:54.280 --> 02:02:58.600]   4K UHD switching, live streaming, recording.
[02:02:58.600 --> 02:03:01.560]   That's just really impressive what they've done.
[02:03:01.560 --> 02:03:03.680]   Take a look at the TriCaster family.
[02:03:03.680 --> 02:03:05.280]   Start by pushing that start button.
[02:03:05.280 --> 02:03:14.920]   Find out which TriCaster is right for you at go.newtech.com/twit-tv.
[02:03:14.920 --> 02:03:23.240]   Get that go.newtech.com/twit-tv.
[02:03:23.240 --> 02:03:26.600]   You'll find an easy to use interactive guide that will give you that advice when you hit
[02:03:26.600 --> 02:03:28.800]   that start button on which TriCaster is right for you.
[02:03:28.800 --> 02:03:32.640]   But you know what, just go because it's fun to browse and dream and think about all the
[02:03:32.640 --> 02:03:34.120]   things you can do with TriCaster.
[02:03:34.120 --> 02:03:39.880]   Every time I look at what we can do, I'm thinking, "Why aren't I in Mount Rushmore right now?"
[02:03:39.880 --> 02:03:43.200]   There's so many things we could do with that.
[02:03:43.200 --> 02:03:44.880]   It's just so cool.
[02:03:44.880 --> 02:03:46.360]   I know John is always excited.
[02:03:46.360 --> 02:03:48.600]   We got a new control surface to go with it, right?
[02:03:48.600 --> 02:03:49.600]   We just...
[02:03:49.600 --> 02:03:51.760]   It was a big upgrade for us.
[02:03:51.760 --> 02:03:55.120]   Go.newtech.com/twit-tv.
[02:03:55.120 --> 02:03:57.680]   Please go to that address so they know you saw it here.
[02:03:57.680 --> 02:04:02.360]   We want them to know how much we appreciate everything they do for us at newtech.
[02:04:02.360 --> 02:04:06.560]   The TriCaster 1 Pro and the new TriCaster 2 Elite.
[02:04:06.560 --> 02:04:08.300]   Very good stuff.
[02:04:08.300 --> 02:04:11.720]   I have a request on behalf of the listeners.
[02:04:11.720 --> 02:04:12.720]   Yes.
[02:04:12.720 --> 02:04:17.040]   Don't enable the noise cancellation on your mic because then we can't hear John laughing
[02:04:17.040 --> 02:04:19.200]   in the background.
[02:04:19.200 --> 02:04:21.920]   The AI would strip John out.
[02:04:21.920 --> 02:04:24.680]   You probably can hear right now John going, "Hm, whoa, whoa, whoa, whoa, whoa, whoa, whoa,
[02:04:24.680 --> 02:04:25.680]   whoa, whoa, whoa."
[02:04:25.680 --> 02:04:26.680]   But all the things he can do with it.
[02:04:26.680 --> 02:04:28.400]   I'll give you one more button to press John.
[02:04:28.400 --> 02:04:30.080]   We had a fun week this week on Twit.
[02:04:30.080 --> 02:04:32.360]   We made a little promo watch.
[02:04:32.360 --> 02:04:33.720]   I use Instagram less and less.
[02:04:33.720 --> 02:04:37.960]   In fact, I just saw a story that they want to become a shopping mall.
[02:04:37.960 --> 02:04:40.200]   People buy a lot of that crap.
[02:04:40.200 --> 02:04:41.200]   Oh, geez.
[02:04:41.200 --> 02:04:44.800]   Why do you think I'm sitting on a stick?
[02:04:44.800 --> 02:04:47.600]   You think I would have bought this in a store?
[02:04:47.600 --> 02:04:49.240]   Oh, that's perfect.
[02:04:49.240 --> 02:04:52.360]   I need a chair with a little tiny seat.
[02:04:52.360 --> 02:04:54.160]   He's been squirming all day.
[02:04:54.160 --> 02:04:55.160]   When did you get this?
[02:04:55.160 --> 02:04:56.160]   Middle of the night.
[02:04:56.160 --> 02:04:59.240]   Pre-prepared on Twit.
[02:04:59.240 --> 02:05:00.240]   All about Android.
[02:05:00.240 --> 02:05:01.240]   Guess what?
[02:05:01.240 --> 02:05:03.520]   Google I/O is going to be around for 2022.
[02:05:03.520 --> 02:05:04.520]   And guess what?
[02:05:04.520 --> 02:05:05.520]   It's going to be at Sheryline Amphitheater.
[02:05:05.520 --> 02:05:08.320]   I'll get to go to Shoreline in party at Kefwoon.
[02:05:08.320 --> 02:05:13.520]   No, I want Justin Kefwoon in a Shoreline party because it is a virtual event.
[02:05:13.520 --> 02:05:14.640]   The tech guy.
[02:05:14.640 --> 02:05:17.920]   They make the world's smallest view master.
[02:05:17.920 --> 02:05:22.160]   They make the world's smallest light bright.
[02:05:22.160 --> 02:05:27.160]   Now they are making the world's smallest Atari 26.
[02:05:27.160 --> 02:05:28.880]   Oh, that's so cute.
[02:05:28.880 --> 02:05:29.880]   Wait a minute.
[02:05:29.880 --> 02:05:31.120]   Working.
[02:05:31.120 --> 02:05:32.320]   Mac Break Weekly.
[02:05:32.320 --> 02:05:34.880]   Apple is fined for the ninth time.
[02:05:34.880 --> 02:05:36.360]   There's only one more week.
[02:05:36.360 --> 02:05:40.840]   And then this will all be over Apple by the Dutch regulators.
[02:05:40.840 --> 02:05:42.840]   It's five million euros every week.
[02:05:42.840 --> 02:05:45.000]   But the Apple just saw it as a-- well, that'll cost $50 million.
[02:05:45.000 --> 02:05:46.520]   And then they went back to what they were doing.
[02:05:46.520 --> 02:05:47.200]   They were like--
[02:05:47.200 --> 02:05:49.160]   Yeah, like Tim Cook has a stack of singles.
[02:05:49.160 --> 02:05:51.240]   And he's just counting off singles every week.
[02:05:51.240 --> 02:05:52.680]   Make a rain, Tim.
[02:05:52.680 --> 02:05:53.520]   Make a rain.
[02:05:53.520 --> 02:05:54.320]   Twit.
[02:05:54.320 --> 02:05:56.680]   Take it to the bank.
[02:05:56.680 --> 02:05:57.520]   Oh, don't mind me.
[02:05:57.520 --> 02:06:04.360]   I'm just playing centipede on my little tiny thing.
[02:06:04.360 --> 02:06:05.160]   I need one of those.
[02:06:05.160 --> 02:06:06.240]   It's so cute.
[02:06:06.240 --> 02:06:08.840]   Look, it's a little 2600.
[02:06:08.840 --> 02:06:10.560]   And then you get a little joystick.
[02:06:10.560 --> 02:06:13.040]   It's totally playable, though.
[02:06:13.040 --> 02:06:15.160]   And there's the reset button.
[02:06:15.160 --> 02:06:16.360]   It even makes the sound.
[02:06:16.360 --> 02:06:18.640]   Look, where do you get those?
[02:06:18.640 --> 02:06:19.800]   Target.
[02:06:19.800 --> 02:06:20.800]   Walmart.
[02:06:20.800 --> 02:06:24.920]   You know, Micah and I did this yesterday with Dick.
[02:06:24.920 --> 02:06:26.280]   And oh, look at this.
[02:06:26.280 --> 02:06:29.640]   This is the first game, first video game I ever played, Pong.
[02:06:29.640 --> 02:06:34.000]   I remember getting a stack of quarters and a white Russian
[02:06:34.000 --> 02:06:38.720]   and sitting down to play this game in a bar.
[02:06:38.720 --> 02:06:43.840]   I didn't come out five white Russians and eight hours later.
[02:06:43.840 --> 02:06:45.400]   Because I was so entranced by the idea
[02:06:45.400 --> 02:06:48.480]   that you could play a thing, a video game on a computer.
[02:06:48.480 --> 02:06:51.200]   Now, now I have it on something the size of a--
[02:06:51.200 --> 02:06:53.000]   I don't know.
[02:06:53.000 --> 02:06:54.520]   The size of a--
[02:06:54.520 --> 02:06:55.800]   something a cube.
[02:06:55.800 --> 02:06:56.480]   It's so cute.
[02:06:56.480 --> 02:06:59.000]   Look, the TV comes out and has got little legs.
[02:06:59.000 --> 02:06:59.560]   This thing is--
[02:06:59.560 --> 02:07:00.440]   Oh, it's a health?
[02:07:00.440 --> 02:07:01.720]   20 bucks.
[02:07:01.720 --> 02:07:02.640]   The air cool.
[02:07:02.640 --> 02:07:03.920]   It's a miracle.
[02:07:03.920 --> 02:07:04.760]   It's already 20--
[02:07:04.760 --> 02:07:05.320]   20 bucks.
[02:07:05.320 --> 02:07:06.400]   You're gonna get one of those.
[02:07:06.400 --> 02:07:07.040]   Yeah.
[02:07:07.040 --> 02:07:09.800]   That was the first console I owned.
[02:07:09.800 --> 02:07:11.360]   Me too.
[02:07:11.360 --> 02:07:11.720]   Me too.
[02:07:11.720 --> 02:07:12.800]   I've told the story many times.
[02:07:12.800 --> 02:07:14.120]   I apologize if you've heard it before,
[02:07:14.120 --> 02:07:17.240]   but I spent so much money and time at Chuck E. Cheese
[02:07:17.240 --> 02:07:20.120]   Pizza Time Theater playing asteroids and battle zone
[02:07:20.120 --> 02:07:20.480]   and all that.
[02:07:20.480 --> 02:07:21.280]   I finally said, you know what?
[02:07:21.280 --> 02:07:23.280]   I should really get the 2600.
[02:07:23.280 --> 02:07:23.840]   And I did.
[02:07:23.840 --> 02:07:25.360]   And that's actually how I got into computers.
[02:07:25.360 --> 02:07:26.160]   Because then I said, well, what?
[02:07:26.160 --> 02:07:27.840]   I really need a Atari 400.
[02:07:27.840 --> 02:07:30.360]   Then I said, when I really need a Atari 800--
[02:07:30.360 --> 02:07:33.040]   and, well, you know, how it goes.
[02:07:33.040 --> 02:07:35.120]   But now I have a 2,600.
[02:07:35.120 --> 02:07:36.800]   Look, it's so cute.
[02:07:36.800 --> 02:07:38.280]   It's so cute.
[02:07:38.280 --> 02:07:40.160]   It must have licensed it, right?
[02:07:40.160 --> 02:07:42.080]   It's exactly like it.
[02:07:42.080 --> 02:07:43.960]   I'm just surprised they got Paul.
[02:07:43.960 --> 02:07:44.920]   Oh, I know.
[02:07:44.920 --> 02:07:46.560]   That was that a Atari game.
[02:07:46.560 --> 02:07:47.640]   I don't think so originally.
[02:07:47.640 --> 02:07:49.160]   It was Namco or somebody.
[02:07:49.160 --> 02:07:50.760]   They have Pac-Manz on there.
[02:07:50.760 --> 02:07:52.360]   That's the game.
[02:07:52.360 --> 02:07:54.480]   The Pong Arcade game is the one that--
[02:07:54.480 --> 02:07:57.160]   that's the only one that gives the main project
[02:07:57.160 --> 02:07:58.120]   a really hard time.
[02:07:58.120 --> 02:07:58.720]   Oh, really?
[02:07:58.720 --> 02:07:59.960]   They sue them?
[02:07:59.960 --> 02:08:03.920]   Well, they just don't want that out there, I guess.
[02:08:03.920 --> 02:08:05.240]   I mean, people don't get it, of course.
[02:08:05.240 --> 02:08:09.280]   You could write it in Python at an hour.
[02:08:09.280 --> 02:08:12.280]   I mean, it's the simplest game ever.
[02:08:12.280 --> 02:08:13.720]   Yeah.
[02:08:13.720 --> 02:08:14.680]   It's funny.
[02:08:14.680 --> 02:08:15.640]   Who owns Pong?
[02:08:15.640 --> 02:08:16.640]   Is it Chatham?
[02:08:16.640 --> 02:08:17.800]   Do you know who owns Pong?
[02:08:17.800 --> 02:08:19.760]   I wonder why they're so tough on it.
[02:08:19.760 --> 02:08:20.800]   It is historic.
[02:08:20.800 --> 02:08:21.640]   I mean, in that respect.
[02:08:21.640 --> 02:08:22.160]   It is.
[02:08:22.160 --> 02:08:23.000]   I think that's what it is.
[02:08:23.000 --> 02:08:24.800]   They're going for the historic value of, hey,
[02:08:24.800 --> 02:08:26.240]   this is the first game.
[02:08:26.240 --> 02:08:27.400]   Well, as I mentioned--
[02:08:27.400 --> 02:08:29.680]   But if you're not getting any revenue from it, why do you care?
[02:08:29.680 --> 02:08:30.440]   Right.
[02:08:30.440 --> 02:08:31.920]   Right, yeah.
[02:08:31.920 --> 02:08:34.040]   As I mentioned earlier, just go to Internet Archive.
[02:08:34.040 --> 02:08:35.200]   You could play all these games.
[02:08:35.200 --> 02:08:37.560]   You could play Scram.
[02:08:37.560 --> 02:08:40.520]   The rods go in and the reactor slows down.
[02:08:40.520 --> 02:08:41.440]   Is that right?
[02:08:41.440 --> 02:08:41.920]   Yes.
[02:08:41.920 --> 02:08:42.920]   OK.
[02:08:42.920 --> 02:08:44.320]   Good to know for when you play that later.
[02:08:44.320 --> 02:08:46.800]   OK.
[02:08:46.800 --> 02:08:49.120]   Chris Crawford was an amazing guy.
[02:08:49.120 --> 02:08:53.200]   He was like the king of simulations on the old Atari.
[02:08:53.200 --> 02:08:53.720]   Let's see.
[02:08:53.720 --> 02:08:57.320]   YouTube's buying more TV shows, 4,000 free episodes of TV.
[02:08:57.320 --> 02:09:00.280]   Amazon's buying the old MGM catalog
[02:09:00.280 --> 02:09:02.160]   with a bunch of crappy TV shows.
[02:09:02.160 --> 02:09:03.600]   Obviously, catalog is it.
[02:09:03.600 --> 02:09:06.280]   I think streaming is-- we were just talking about this.
[02:09:06.280 --> 02:09:07.880]   This is where the big battle where
[02:09:07.880 --> 02:09:10.880]   you all is about to begin with these big companies.
[02:09:10.880 --> 02:09:14.480]   Trying very hard to get your dollar.
[02:09:14.480 --> 02:09:18.680]   Unimpressed.
[02:09:18.680 --> 02:09:22.200]   I'd say that because I watch Disney just pull and suck
[02:09:22.200 --> 02:09:23.720]   everything back into their service.
[02:09:23.720 --> 02:09:25.040]   And it just drives me to--
[02:09:25.040 --> 02:09:26.520]   Yeah.
[02:09:26.520 --> 02:09:30.240]   I'm very selective about who gets my dollars from that stuff.
[02:09:30.240 --> 02:09:31.000]   Yeah, I don't blame you.
[02:09:31.000 --> 02:09:36.280]   You said, I regularly shut off services, cancel them,
[02:09:36.280 --> 02:09:38.320]   and then bring them back when there's something out there
[02:09:38.320 --> 02:09:39.640]   that I actually want to watch.
[02:09:39.640 --> 02:09:40.280]   Yeah.
[02:09:40.280 --> 02:09:41.040]   That's a good idea.
[02:09:41.040 --> 02:09:45.360]   Honda is retiring as a mo.
[02:09:45.360 --> 02:09:47.800]   The first robot-- 20 years.
[02:09:47.800 --> 02:09:50.240]   I didn't realize a robot had been around that long.
[02:09:50.240 --> 02:09:55.520]   The first humanoid robot debuted in 2000.
[02:09:55.520 --> 02:09:56.600]   It could walk.
[02:09:56.600 --> 02:09:58.520]   It could dance.
[02:09:58.520 --> 02:10:03.040]   They haven't upgraded it in 11 years.
[02:10:03.040 --> 02:10:04.280]   But that's it for asthma.
[02:10:04.280 --> 02:10:07.200]   If you have one, if you bought one, I don't know.
[02:10:07.200 --> 02:10:08.800]   I don't think they ever sold them.
[02:10:08.800 --> 02:10:10.040]   Oh, OK.
[02:10:10.040 --> 02:10:13.680]   I actually did meet Asimo in Japan.
[02:10:13.680 --> 02:10:18.440]   Yeah, back in 2009, I was there on a--
[02:10:18.440 --> 02:10:22.440]   Honda brought some media over for the Tokyo Motor Show.
[02:10:22.440 --> 02:10:24.320]   And we went to Honda headquarters,
[02:10:24.320 --> 02:10:30.160]   and we got to meet Asimo and see a demo in shake hands
[02:10:30.160 --> 02:10:32.160]   with them and everything.
[02:10:32.160 --> 02:10:36.600]   Well, I hope you memorize that because they're going to--
[02:10:36.600 --> 02:10:38.000]   I've got a photo of it somewhere.
[02:10:38.000 --> 02:10:39.440]   Retire in Asimo.
[02:10:39.440 --> 02:10:43.280]   Yeah, he was still performing in a science museum,
[02:10:43.280 --> 02:10:45.680]   the National Museum of Emerging Science and Innovation
[02:10:45.680 --> 02:10:49.160]   in Tokyo, as well as the Honda Asimo showroom.
[02:10:49.160 --> 02:10:54.920]   But last performance is coming up.
[02:10:54.920 --> 02:10:58.120]   It's been a good 20 years, Asimo.
[02:10:58.120 --> 02:11:00.320]   The inventor of the GIF--
[02:11:00.320 --> 02:11:05.720]   and I'm going to say GIF from now on as past Steve Wilhite--
[02:11:05.720 --> 02:11:08.680]   he invented the GIF on CompuServe.
[02:11:08.680 --> 02:11:12.040]   We were just talking about that in the 1980s
[02:11:12.040 --> 02:11:14.760]   and spent the rest of his life trying to convince people
[02:11:14.760 --> 02:11:19.760]   that it's GIF, not GIF.
[02:11:19.760 --> 02:11:26.120]   In fact, when he won the Webby Award about 10 years ago,
[02:11:26.120 --> 02:11:29.720]   he-- very famously, his acceptance speech,
[02:11:29.720 --> 02:11:31.320]   you know, you only get five letters.
[02:11:31.320 --> 02:11:32.320]   Here, I'll play it for you.
[02:11:35.080 --> 02:11:40.560]   Was its pronounced GIF.
[02:11:40.560 --> 02:11:42.760]   And the crowd goes wild.
[02:11:42.760 --> 02:11:44.160]   Not GIF.
[02:11:44.160 --> 02:11:46.040]   Not GIF.
[02:11:46.040 --> 02:11:46.800]   I can never remember.
[02:11:46.800 --> 02:11:48.480]   Hey, you invented you get to name it.
[02:11:48.480 --> 02:11:50.560]   Is that true, though, really?
[02:11:50.560 --> 02:11:51.200]   I mean--
[02:11:51.200 --> 02:11:51.960]   Works for me.
[02:11:51.960 --> 02:11:52.440]   I should.
[02:11:52.440 --> 02:11:53.440]   I guess.
[02:11:53.440 --> 02:11:54.080]   Yeah.
[02:11:54.080 --> 02:11:56.880]   I never really wanted to call it GIF,
[02:11:56.880 --> 02:11:59.480]   because that made me think of peanut butter.
[02:11:59.480 --> 02:12:03.200]   In fact, remember when GIF peanut butter set out?
[02:12:03.200 --> 02:12:04.120]   Peanut butter jar?
[02:12:04.120 --> 02:12:06.880]   We probably still have it somewhere.
[02:12:06.880 --> 02:12:11.920]   With a label that said it's pronounced GIF, weird GIF.
[02:12:11.920 --> 02:12:16.280]   So there's a little tension between them.
[02:12:16.280 --> 02:12:20.160]   Also passed away, speaking of vintage computers,
[02:12:20.160 --> 02:12:23.600]   the former CEO of Tandy Corporation
[02:12:23.600 --> 02:12:27.680]   who pushed out the original TRS 80.
[02:12:27.680 --> 02:12:30.120]   A lot of people got their first taste
[02:12:30.120 --> 02:12:36.040]   of a personal computer in the $600 TRS 80 in 1978.
[02:12:36.040 --> 02:12:39.000]   I think it came out '77.
[02:12:39.000 --> 02:12:42.680]   And it was John Roach, who was the CEO at the time.
[02:12:42.680 --> 02:12:46.040]   They shipped-- he says--
[02:12:46.040 --> 02:12:47.800]   The Apple one had been introduced the year before.
[02:12:47.800 --> 02:12:49.880]   Commodore and other companies are marketing their own home
[02:12:49.880 --> 02:12:50.840]   computers.
[02:12:50.840 --> 02:12:55.120]   But the TRS 80 became, for a time, the most popular computer
[02:12:55.120 --> 02:12:57.320]   on the market.
[02:12:57.320 --> 02:13:01.120]   Mr. Roach said that Charles Tandy blew a little smoke
[02:13:01.120 --> 02:13:03.080]   and said, build a thousand.
[02:13:03.080 --> 02:13:05.360]   And if we can't sell them, we'll use them in the store
[02:13:05.360 --> 02:13:09.480]   for something, the battery glove or something.
[02:13:09.480 --> 02:13:12.200]   We were finally able to ship some machines in September,
[02:13:12.200 --> 02:13:13.640]   shipped 5,000 that year.
[02:13:13.640 --> 02:13:15.760]   That was all we could make.
[02:13:15.760 --> 02:13:17.920]   Our competitors shipped none.
[02:13:17.920 --> 02:13:22.240]   $600, which in 1978 was a lot more--
[02:13:22.240 --> 02:13:23.680]   dollar was worth something.
[02:13:23.680 --> 02:13:27.120]   But it was still a lot cheaper than anything else out there.
[02:13:27.120 --> 02:13:32.160]   So John Roach passed away at the age of 83, Stephen Wilhite
[02:13:32.160 --> 02:13:35.200]   at the age of 84, a couple of the pioneers
[02:13:35.200 --> 02:13:38.520]   of the computer industry.
[02:13:38.520 --> 02:13:41.600]   Ladies and gentlemen, boys and girls, children of all ages,
[02:13:41.600 --> 02:13:42.840]   this has been a lot of fun.
[02:13:42.840 --> 02:13:44.880]   We had some geeky times.
[02:13:44.880 --> 02:13:46.640]   Thank you so much for being here.
[02:13:46.640 --> 02:13:50.000]   I want to remind you that Lou is a regular.
[02:13:50.000 --> 02:13:52.640]   He's the host of this week on Enterprise Tech.
[02:13:52.640 --> 02:13:56.000]   Every Friday, around noon, you can watch it live,
[02:13:56.000 --> 02:13:59.240]   noon Pacific, 3 p.m. Eastern time.
[02:13:59.240 --> 02:14:02.600]   [NON-ENGLISH SPEECH]
[02:14:02.600 --> 02:14:03.920]   It's-- I can't do the math.
[02:14:03.920 --> 02:14:06.640]   20,000 UTC, I believe.
[02:14:06.640 --> 02:14:07.520]   No, seven.
[02:14:07.520 --> 02:14:09.880]   It's 1900 from T.C.
[02:14:09.880 --> 02:14:10.800]   I think so.
[02:14:10.800 --> 02:14:13.200]   Come on by, watch it live, or subscribe
[02:14:13.200 --> 02:14:14.600]   at twit.tv/twiet.
[02:14:14.600 --> 02:14:15.800]   Thank you, Lou.
[02:14:15.800 --> 02:14:16.400]   Thank you, Lou.
[02:14:16.400 --> 02:14:18.280]   Everything going well.
[02:14:18.280 --> 02:14:18.760]   Yeah.
[02:14:18.760 --> 02:14:19.280]   Good.
[02:14:19.280 --> 02:14:20.120]   I'm going to blast.
[02:14:20.120 --> 02:14:21.320]   Having a good time.
[02:14:21.320 --> 02:14:23.000]   We're doing remote work and enjoying it.
[02:14:23.000 --> 02:14:25.400]   We've told you were working remotely on Mac Microsoft.
[02:14:25.400 --> 02:14:30.240]   Yeah, my whole work is over in Redmond.
[02:14:30.240 --> 02:14:33.640]   So I know Microsoft's bringing people back into the office.
[02:14:33.640 --> 02:14:35.440]   You can stay remote, though.
[02:14:35.440 --> 02:14:36.880]   I am 100% remote.
[02:14:36.880 --> 02:14:37.960]   Nice.
[02:14:37.960 --> 02:14:41.080]   Well, we love you, and we really love the work you do.
[02:14:41.080 --> 02:14:43.160]   So thank you for being here for us.
[02:14:43.160 --> 02:14:43.680]   Thank you.
[02:14:43.680 --> 02:14:44.440]   I'm doing it.
[02:14:44.440 --> 02:14:46.040]   I don't like to make you work on a Sunday,
[02:14:46.040 --> 02:14:48.640]   but every once in a while, just to reconnect.
[02:14:48.640 --> 02:14:49.200]   That's great to see you.
[02:14:49.200 --> 02:14:50.200]   No, I'm a blast.
[02:14:50.200 --> 02:14:51.400]   I'm-- thank you for having me.
[02:14:51.400 --> 02:14:53.520]   So glad to reconnect with Alan Malvin-Tano.
[02:14:53.520 --> 02:14:56.840]   Long time friend, host of this week in computer hardware
[02:14:56.840 --> 02:14:59.600]   for many years until he went off and joined the enemy
[02:14:59.600 --> 02:15:00.720]   at Intel.
[02:15:00.720 --> 02:15:01.920]   Storage technical analyst.
[02:15:01.920 --> 02:15:02.520]   Enemy.
[02:15:02.520 --> 02:15:05.200]   No, they're the good guys.
[02:15:05.200 --> 02:15:06.840]   How is it at Intel these days?
[02:15:06.840 --> 02:15:07.920]   Are-- is there--
[02:15:07.920 --> 02:15:10.240]   invigorated?
[02:15:10.240 --> 02:15:13.520]   Yeah, you know, there's plenty of storage stuff for me
[02:15:13.520 --> 02:15:15.800]   to try to get people to fix and make better.
[02:15:15.800 --> 02:15:17.240]   Mr. Optane.
[02:15:17.240 --> 02:15:19.920]   Also, I think Gelsinger, Pat Gelsinger
[02:15:19.920 --> 02:15:22.160]   has been a really exciting CEO.
[02:15:22.160 --> 02:15:25.320]   And his vision for Intel is both a design company
[02:15:25.320 --> 02:15:27.360]   and a foundry is really interesting.
[02:15:27.360 --> 02:15:31.240]   I know it's a gutsy move, but we wish him--
[02:15:31.240 --> 02:15:34.200]   wish you guys absolutely the best we need Intel.
[02:15:34.200 --> 02:15:35.440]   Intel's very important.
[02:15:35.440 --> 02:15:35.960]   And--
[02:15:35.960 --> 02:15:39.080]   Yeah, the level of enthusiasm is kind of like just, you know,
[02:15:39.080 --> 02:15:40.600]   collectively, higher lately.
[02:15:40.600 --> 02:15:42.560]   Yeah, I think Pat's a great, great guy.
[02:15:42.560 --> 02:15:44.320]   I mean, here's a chip designer, right?
[02:15:44.320 --> 02:15:46.240]   He should be who's running Intel, I think.
[02:15:46.240 --> 02:15:46.800]   Yeah.
[02:15:46.800 --> 02:15:48.040]   Great to have you on, Alan.
[02:15:48.040 --> 02:15:51.880]   Are you-- any podcasts you're doing, anything you want to plug?
[02:15:51.880 --> 02:15:54.560]   No, I don't really do much of anything--
[02:15:54.560 --> 02:15:56.160]   We're lucky to get you.
[02:15:56.160 --> 02:15:57.280]   Well, yeah, yeah, yeah.
[02:15:57.280 --> 02:16:00.080]   But, you know, I mean, heck, I can go over to Lou or Sam
[02:16:00.080 --> 02:16:02.280]   to talk storage for cars.
[02:16:02.280 --> 02:16:03.600]   Gekkiki, man.
[02:16:03.600 --> 02:16:05.280]   Oh, yeah, you're a big car guy, too.
[02:16:05.280 --> 02:16:07.240]   We didn't even get to some of the car stories.
[02:16:07.240 --> 02:16:09.920]   There's a lot of car news as well.
[02:16:09.920 --> 02:16:13.600]   Yeah, I may or may not have root access to my Tesla.
[02:16:13.600 --> 02:16:16.040]   Ooh.
[02:16:16.040 --> 02:16:17.800]   How interesting.
[02:16:17.800 --> 02:16:18.800]   You know, come on.
[02:16:18.800 --> 02:16:23.120]   You SSH into your-- yeah, Mercedes.
[02:16:23.120 --> 02:16:24.640]   I love it.
[02:16:24.640 --> 02:16:25.640]   Mercedes.
[02:16:25.640 --> 02:16:26.120]   What'd I say?
[02:16:26.120 --> 02:16:26.800]   I mean, Tesla.
[02:16:26.800 --> 02:16:28.800]   Yeah, yeah, yeah.
[02:16:28.800 --> 02:16:33.120]   Can you sideload programs into it?
[02:16:33.120 --> 02:16:34.800]   I saw somebody put--
[02:16:34.800 --> 02:16:37.280]   It's basically a bun-touleo.
[02:16:37.280 --> 02:16:37.960]   It's a bun-tou.
[02:16:37.960 --> 02:16:39.440]   Once you're in there, you can do whatever you--
[02:16:39.440 --> 02:16:40.400]   Wow.
[02:16:40.400 --> 02:16:43.280]   So you can pseudo-up data.
[02:16:43.280 --> 02:16:44.480]   Well, you have to be creative.
[02:16:44.480 --> 02:16:48.640]   Thank you for being here, Alan.
[02:16:48.640 --> 02:16:52.400]   Samable, Sam-ed, of course, a regular on the Tech Guy Show.
[02:16:52.400 --> 02:16:54.520]   His wheel bearings is a fantastic podcast
[02:16:54.520 --> 02:16:58.000]   to do with Nicole and Robbie, two of my other favorites.
[02:16:58.000 --> 02:17:01.480]   It's a great show if you're into cars, wheelbearrings.media,
[02:17:01.480 --> 02:17:03.880]   principal researcher at Guide House Insights.
[02:17:03.880 --> 02:17:06.320]   Anything else you want to plug?
[02:17:06.320 --> 02:17:06.960]   Let's see.
[02:17:06.960 --> 02:17:08.440]   There's also the other podcast that I'm
[02:17:08.440 --> 02:17:11.000]   doing with my colleagues on the transportation team
[02:17:11.000 --> 02:17:13.960]   at Guide House called Guide House Transportation Insights.
[02:17:13.960 --> 02:17:14.440]   Nice.
[02:17:14.440 --> 02:17:16.920]   You can find out in all the usual places.
[02:17:16.920 --> 02:17:18.560]   Just search for that.
[02:17:18.560 --> 02:17:20.000]   What else?
[02:17:20.000 --> 02:17:24.200]   Oh, speaking of software-defined vehicles,
[02:17:24.200 --> 02:17:28.120]   we're going to be doing a webinar on April 12th.
[02:17:28.120 --> 02:17:32.640]   We're going to have an executive from Aurora Labs,
[02:17:32.640 --> 02:17:34.840]   which is a company doing some really interesting stuff
[02:17:34.840 --> 02:17:37.200]   with vehicle software tools.
[02:17:37.200 --> 02:17:41.760]   Scott Miller, who is the VP of software at General Motors.
[02:17:41.760 --> 02:17:46.760]   And I'm trying to remember somebody, a VP from NVIDIA,
[02:17:46.760 --> 02:17:51.320]   who I'm sorry, but I cannot remember his name right now.
[02:17:51.320 --> 02:17:55.040]   But so of GM, NVIDIA, and Aurora Labs
[02:17:55.040 --> 02:17:58.920]   talking for an hour about software-defined vehicles
[02:17:58.920 --> 02:18:00.040]   on April 12th.
[02:18:00.040 --> 02:18:03.720]   And if you look just look for Guide House Insights webinars,
[02:18:03.720 --> 02:18:05.760]   you can find the registration page for that.
[02:18:05.760 --> 02:18:07.280]   Nice.
[02:18:07.280 --> 02:18:08.520]   Very cool.
[02:18:08.520 --> 02:18:09.640]   Thank you, gentlemen.
[02:18:09.640 --> 02:18:10.440]   A great show.
[02:18:10.440 --> 02:18:11.120]   Well done.
[02:18:11.120 --> 02:18:12.440]   Bravo.
[02:18:12.440 --> 02:18:15.760]   And I bet you're all glad you were here to watch or listen to it.
[02:18:15.760 --> 02:18:18.280]   We can-- we do it live, so you can watch and listen live
[02:18:18.280 --> 02:18:20.640]   at live.twit.tv.
[02:18:20.640 --> 02:18:23.760]   It's every Sunday, around 230 Pacific, 530 Eastern,
[02:18:23.760 --> 02:18:25.720]   2130 UTC.
[02:18:25.720 --> 02:18:29.440]   If you want to watch live, just head over to that website.
[02:18:29.440 --> 02:18:32.120]   You can choose from a live audio or video stream.
[02:18:32.120 --> 02:18:33.960]   Now, if you're watching live, you should probably chat live
[02:18:33.960 --> 02:18:34.760]   with us.
[02:18:34.760 --> 02:18:39.080]   It's always fun in the IRC, IRC.twit.tv.
[02:18:39.080 --> 02:18:40.120]   And of course, the club members,
[02:18:40.120 --> 02:18:43.200]   they get to chat in the fabulous Discord, which
[02:18:43.200 --> 02:18:47.440]   is kind of rapidly becoming my favorite online community,
[02:18:47.440 --> 02:18:49.880]   not just chat rooms for every show that we do,
[02:18:49.880 --> 02:18:52.120]   but for every subject, a geek could be interested in,
[02:18:52.120 --> 02:18:56.840]   including automotive tech, beer, wine, cocktails, crypto,
[02:18:56.840 --> 02:18:59.640]   gaming, hacking, and a whole lot more.
[02:18:59.640 --> 02:19:01.320]   That's just one of the benefits of club
[02:19:01.320 --> 02:19:02.400]   $2.07 a month.
[02:19:02.400 --> 02:19:04.000]   Gets you access to the Discord.
[02:19:04.000 --> 02:19:08.880]   You get ad-free versions of all the shows we do
[02:19:08.880 --> 02:19:12.840]   with your own special feed and a Twit+ feed where stuff that
[02:19:12.840 --> 02:19:15.000]   doesn't make it into the podcast appears,
[02:19:15.000 --> 02:19:19.200]   including our untitled Linux show, The Giz Fizz, Stacey's Book
[02:19:19.200 --> 02:19:22.400]   Club, which is, I think, coming up on the 20--
[02:19:22.400 --> 02:19:24.560]   oh, it was last week.
[02:19:24.560 --> 02:19:25.320]   It's over.
[02:19:25.320 --> 02:19:28.800]   But you know what is coming up is Paul The Rots
[02:19:28.800 --> 02:19:31.840]   after hours conversation.
[02:19:31.840 --> 02:19:34.480]   Thanks to Ant Pruitt, that's coming up March 31,
[02:19:34.480 --> 02:19:36.240]   about four days.
[02:19:36.240 --> 02:19:37.360]   Again, $7 a month.
[02:19:37.360 --> 02:19:38.520]   I think there's a lot of benefit.
[02:19:38.520 --> 02:19:41.320]   And it sure helps us keep the lights on.
[02:19:41.320 --> 02:19:45.040]   Go to twit.tv/clubtwit to find out more.
[02:19:45.040 --> 02:19:46.480]   There's a corporate membership as well.
[02:19:46.480 --> 02:19:48.480]   Thank you very much for your support.
[02:19:48.480 --> 02:19:50.160]   After the fact, all the shows we do
[02:19:50.160 --> 02:19:52.680]   are available at the website, twit.tv.
[02:19:52.680 --> 02:19:55.440]   Also on YouTube, every show has its dedicated channel,
[02:19:55.440 --> 02:19:56.880]   and it does Twit.
[02:19:56.880 --> 02:19:59.760]   And you can also subscribe in your favorite podcast player.
[02:19:59.760 --> 02:20:01.040]   That's probably the easiest way to do it.
[02:20:01.040 --> 02:20:03.480]   So you get it automatically, ready for your Monday morning
[02:20:03.480 --> 02:20:04.520]   commute.
[02:20:04.520 --> 02:20:09.560]   And if your podcast player has reviews, please do us a solid
[02:20:09.560 --> 02:20:13.360]   and leave a five star review so that everybody knows about this.
[02:20:13.360 --> 02:20:17.440]   Probably the longest running tech show in the world.
[02:20:17.440 --> 02:20:18.800]   Thank you for joining us.
[02:20:18.800 --> 02:20:19.680]   We'll see you next time.
[02:20:19.680 --> 02:20:20.400]   Another Twit.
[02:20:20.400 --> 02:20:21.320]   This is amazing.
[02:20:21.320 --> 02:20:21.920]   Bye bye.
[02:20:21.920 --> 02:20:22.920]   I'm running.
[02:20:22.920 --> 02:20:24.920]   [MUSIC PLAYING]
[02:20:24.920 --> 02:20:25.920]   Do it the Twit.
[02:20:25.920 --> 02:20:26.920]   All right.
[02:20:26.920 --> 02:20:28.920]   Do it the Twit, baby.
[02:20:28.920 --> 02:20:29.920]   Do it the Twit.
[02:20:29.920 --> 02:20:30.920]   All right.
[02:20:30.920 --> 02:20:32.920]   Do it the Twit, baby.

