;FFMETADATA1
title=Millsplain It to Me
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=702
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.760]   It's time for Twit this week in Tech Micah Sergeant.
[00:00:02.760 --> 00:00:07.840]   He's our token millennial, joins Sebastian Peake, the newest host of this week in Computer
[00:00:07.840 --> 00:00:11.520]   Hardware and IBM developer relations guy Wesley Faulkner.
[00:00:11.520 --> 00:00:17.240]   We're going to talk about all the hot new products from CES, including a new ray tracing
[00:00:17.240 --> 00:00:25.400]   video card from NVIDIA, the hot new AMD processors rumored to be five gigahertz and data privacy.
[00:00:25.400 --> 00:00:27.600]   Tim Cook has thrown down the gauntlet.
[00:00:27.600 --> 00:00:29.520]   It's all coming up next on Twit.
[00:00:30.520 --> 00:00:34.440]   Netcast you love.
[00:00:34.440 --> 00:00:39.640]   From people you trust.
[00:00:39.640 --> 00:00:49.880]   This is Twit.
[00:00:49.880 --> 00:00:57.320]   This is Twit this week in Tech, Episode 702 recorded Sunday January 20th 2019.
[00:00:57.320 --> 00:00:59.320]   He'll explain it to me.
[00:00:59.320 --> 00:01:03.800]   This week in Tech is brought to you by Aura Ring, the most accurate sleep and activity
[00:01:03.800 --> 00:01:04.800]   tracker ever.
[00:01:04.800 --> 00:01:05.800]   I love my Aura.
[00:01:05.800 --> 00:01:11.120]   Visit auraring.com and use the code TWIT for $50 off your purchase.
[00:01:11.120 --> 00:01:15.760]   And by ZipRecruiter, hire qualified candidates the smart way and take your business to the
[00:01:15.760 --> 00:01:17.520]   next level in 2019.
[00:01:17.520 --> 00:01:22.200]   Try ZipRecruiter free at zipprecruiter.com/twit.
[00:01:22.200 --> 00:01:27.320]   And by ExpressVPN, protect your online activity today.
[00:01:27.320 --> 00:01:33.720]   For an extra three months free with a year package, go to expressvpn.com/twit and by
[00:01:33.720 --> 00:01:35.280]   Atlassian.
[00:01:35.280 --> 00:01:40.080]   Atlassian Software powers the full spectrum of collaboration between IT teams and the rest
[00:01:40.080 --> 00:01:41.640]   of your organization.
[00:01:41.640 --> 00:01:47.320]   Visit Atlassian.com to find out which Atlassian tools are right for your team and give their
[00:01:47.320 --> 00:01:52.120]   products a try for free.
[00:01:52.120 --> 00:01:56.240]   It's time for TWIT this week in Tech, the show we cover the week's Tech news with the best
[00:01:56.240 --> 00:02:01.040]   tech journalists we can find at short notice during an NFL playoff season.
[00:02:01.040 --> 00:02:02.360]   I'm just kidding.
[00:02:02.360 --> 00:02:03.880]   I'm just teasing you.
[00:02:03.880 --> 00:02:05.640]   Wesley Faulkner is here from IBM.
[00:02:05.640 --> 00:02:07.800]   He's a developer, he's an IBM.
[00:02:07.800 --> 00:02:08.800]   Hey Wesley.
[00:02:08.800 --> 00:02:09.800]   Good to see you.
[00:02:09.800 --> 00:02:10.800]   Good to see you.
[00:02:10.800 --> 00:02:15.200]   We'll be seeing you, I think, in Austin in a couple of months at Southby.
[00:02:15.200 --> 00:02:17.240]   That'll be a lot of fun.
[00:02:17.240 --> 00:02:18.640]   Wesley is in Austin.
[00:02:18.640 --> 00:02:23.560]   He's developed relations at IBM many years at AMD before that and that may be relevant
[00:02:23.560 --> 00:02:28.560]   because also with us, I think for his first time on TWIT, Sebastian Peake, the editor in
[00:02:28.560 --> 00:02:34.280]   chief at PC perspective and our new host on this week in Computer Hardware with Patrick
[00:02:34.280 --> 00:02:35.280]   Norton.
[00:02:35.280 --> 00:02:36.280]   Hey Sebastian.
[00:02:36.280 --> 00:02:38.480]   Hey, I'm the homegrown talent on the show.
[00:02:38.480 --> 00:02:39.480]   Homegrown.
[00:02:39.480 --> 00:02:41.600]   You came and brought him up from the farm league.
[00:02:41.600 --> 00:02:42.600]   Yeah.
[00:02:42.600 --> 00:02:43.600]   Yeah.
[00:02:43.600 --> 00:02:46.960]   He used to be a shortstop for the Mississippi Blues.
[00:02:46.960 --> 00:02:48.040]   No, it's great to have you.
[00:02:48.040 --> 00:02:49.040]   Thank you for joining us, Sebastian.
[00:02:49.040 --> 00:02:50.360]   Thank you for having me.
[00:02:50.360 --> 00:02:54.080]   And thank you for being willing to take on Twitch.
[00:02:54.080 --> 00:02:57.800]   We went through two hosts in a very brief period of time because we're not going to try
[00:02:57.800 --> 00:03:01.960]   out who started the show with me way back when got a job at Intel.
[00:03:01.960 --> 00:03:06.680]   So we put Alan Melvantano in his place and then Alan got a job like three weeks later
[00:03:06.680 --> 00:03:07.680]   Intel.
[00:03:07.680 --> 00:03:12.520]   So I think Ryan was scooped up Alan, but we could say this job is going to be my spring
[00:03:12.520 --> 00:03:14.240]   board to that Intel position.
[00:03:14.240 --> 00:03:15.480]   I'm always lost.
[00:03:15.480 --> 00:03:18.040]   Spring board to Intel.
[00:03:18.040 --> 00:03:24.200]   Also, it's great to have Mike Asargent Chihuahua coffee.
[00:03:24.200 --> 00:03:25.440]   Chihuahua Doc coffee.
[00:03:25.440 --> 00:03:26.520]   That's that's the site.
[00:03:26.520 --> 00:03:27.520]   That's the site.
[00:03:27.520 --> 00:03:28.520]   Yeah.
[00:03:28.520 --> 00:03:33.400]   You know, anytime you don't have other journalists to hop on because of football, I'm happy to
[00:03:33.400 --> 00:03:34.400]   be here for you.
[00:03:34.400 --> 00:03:35.480]   You couldn't care less.
[00:03:35.480 --> 00:03:38.280]   I could not care less, but you know what?
[00:03:38.280 --> 00:03:40.480]   I appreciate it that some people do and I understand.
[00:03:40.480 --> 00:03:42.080]   We couldn't get you on during the Golden Globe.
[00:03:42.080 --> 00:03:44.080]   So that was it was.
[00:03:44.080 --> 00:03:45.960]   I don't care about anything.
[00:03:45.960 --> 00:03:46.960]   Nothing.
[00:03:46.960 --> 00:03:48.960]   I don't care about anything on TV.
[00:03:48.960 --> 00:03:50.480]   He says, no, we love having all three of you on.
[00:03:50.480 --> 00:03:51.840]   It's great to have you.
[00:03:51.840 --> 00:03:54.280]   I don't know what's going on in football either.
[00:03:54.280 --> 00:03:55.680]   And I'm happy about that.
[00:03:55.680 --> 00:03:59.280]   And most of the people who listen to the show already know what happened.
[00:03:59.280 --> 00:04:01.680]   So there you go.
[00:04:01.680 --> 00:04:05.560]   We were talking actually, I want to say there was a little inside baseball going on between
[00:04:05.560 --> 00:04:13.040]   Sebastian and Wesley about the rumors that AMD, where Wesley used to work, but you don't
[00:04:13.040 --> 00:04:14.040]   have any.
[00:04:14.040 --> 00:04:18.240]   Do you have any insight information there?
[00:04:18.240 --> 00:04:19.240]   No.
[00:04:19.240 --> 00:04:24.520]   There was a rumor that they were going to do a five gigahertz rise in.
[00:04:24.520 --> 00:04:27.520]   And Sebastian, you said maybe, huh?
[00:04:27.520 --> 00:04:31.480]   Well, yeah, there were rumors that were reported by numerous outlets.
[00:04:31.480 --> 00:04:38.760]   I think the original report came out of the adored TV YouTube video.
[00:04:38.760 --> 00:04:43.480]   No, well, I don't press YouTube videos for nothing.
[00:04:43.480 --> 00:04:47.120]   Essentially, he claimed that when rise in 3000 was going to be announced and that was
[00:04:47.120 --> 00:04:51.600]   widely rumored to be the big announcement, AMD was going to have a CES that it was going
[00:04:51.600 --> 00:04:55.960]   to be like more cores, like all the way up to a 16 core desktop art.
[00:04:55.960 --> 00:05:03.080]   They were talking about arts with five gigahertz, boosts, clock speeds.
[00:05:03.080 --> 00:05:12.160]   And then when Lisa actually came out and sort of preannounced the next version of Bryson,
[00:05:12.160 --> 00:05:15.080]   she did not give specific shit, said we do not have final clocks.
[00:05:15.080 --> 00:05:21.280]   And even on the on stage benchmarking with Cenabench that their presentation, they were
[00:05:21.280 --> 00:05:25.120]   not revealing what clocks their prototype was actually running at.
[00:05:25.120 --> 00:05:26.920]   So that's all under wraps.
[00:05:26.920 --> 00:05:31.280]   I would not be surprised at all if they do have a part that can hit close to those numbers
[00:05:31.280 --> 00:05:34.400]   or those numbers on single core boosts.
[00:05:34.400 --> 00:05:37.480]   But I would be very surprised if they had something that came out at like eight cores,
[00:05:37.480 --> 00:05:38.480]   16 threads.
[00:05:38.480 --> 00:05:39.480]   That would be pretty.
[00:05:39.480 --> 00:05:41.480]   You could use that to heat a house.
[00:05:41.480 --> 00:05:43.400]   That would be so hot.
[00:05:43.400 --> 00:05:49.720]   Yeah, I mean, yeah, they're not as warm as maybe the previous generation AMD stuff we're
[00:05:49.720 --> 00:05:50.960]   used to.
[00:05:50.960 --> 00:05:55.360]   But yeah, I think if you're pushing five gigahertz regardless on that many cores, you're going
[00:05:55.360 --> 00:05:56.800]   to be generating some key.
[00:05:56.800 --> 00:05:57.800]   Yeah.
[00:05:57.800 --> 00:06:00.760]   And the past I've rooted for AMD for years, I rooted for AMD because they were keeping
[00:06:00.760 --> 00:06:01.760]   it in tell.
[00:06:01.760 --> 00:06:05.080]   Honest, Intel really didn't have any competition for a long time.
[00:06:05.080 --> 00:06:10.520]   And all of a sudden AMD, maybe this was maybe as much as 15, 20 years ago, came along and
[00:06:10.520 --> 00:06:12.280]   really stuck it to them.
[00:06:12.280 --> 00:06:14.280]   So I was really rooting from them at this point.
[00:06:14.280 --> 00:06:16.400]   I'm starting to feel bad for Intel.
[00:06:16.400 --> 00:06:21.040]   I don't know if I don't feel bad for Intel.
[00:06:21.040 --> 00:06:22.680]   They seem to be doing pretty well.
[00:06:22.680 --> 00:06:23.680]   Okay.
[00:06:23.680 --> 00:06:26.840]   It feels like they've fumbled the future a little bit.
[00:06:26.840 --> 00:06:30.720]   But they have an airbank.
[00:06:30.720 --> 00:06:31.720]   They have.
[00:06:31.720 --> 00:06:32.720]   It's like IBM.
[00:06:32.720 --> 00:06:33.720]   They got patents.
[00:06:33.720 --> 00:06:34.720]   They got money.
[00:06:34.720 --> 00:06:36.840]   It's not like, no, nobody's going broke.
[00:06:36.840 --> 00:06:44.520]   But at the same time, Brian Crazinich kind of manages to not ever create a mobile part.
[00:06:44.520 --> 00:06:47.480]   They never get down to 10 nano meters.
[00:06:47.480 --> 00:06:49.440]   They five gigahertz.
[00:06:49.440 --> 00:06:52.760]   What are you crazy?
[00:06:52.760 --> 00:06:55.800]   And I started to feel sorry for him to be honest with you.
[00:06:55.800 --> 00:07:03.720]   And I think it's important that we have numerous people competing hard against one another.
[00:07:03.720 --> 00:07:07.240]   So you think that x86 has legs.
[00:07:07.240 --> 00:07:09.720]   It's not going to be an arm world going forward.
[00:07:09.720 --> 00:07:14.360]   I think Intel's greatest strength or was his greatest strength, his turn into their greatest
[00:07:14.360 --> 00:07:15.360]   weakness.
[00:07:15.360 --> 00:07:18.440]   They used to say, you're not a real chip company unless you have fabs.
[00:07:18.440 --> 00:07:21.440]   And they're having problems tooling up their own fabs.
[00:07:21.440 --> 00:07:27.360]   The good thing with AMD, which is good and bad, they spun off their fabs into global
[00:07:27.360 --> 00:07:28.360]   foundries.
[00:07:28.360 --> 00:07:32.160]   And that also allowed them to flex to other manufacturers.
[00:07:32.160 --> 00:07:33.600]   IBM was one of them.
[00:07:33.600 --> 00:07:39.880]   And then I can't think of the other one that they went with in order to be able to get
[00:07:39.880 --> 00:07:43.520]   go where they were able to get the dice rings, what they needed.
[00:07:43.520 --> 00:07:48.520]   But now, since Intel does their own fab, they have to spend that money, their own research.
[00:07:48.520 --> 00:07:54.560]   And they don't have access to the same amount of patents as an IBM does.
[00:07:54.560 --> 00:07:58.520]   And so that's probably what's loaned them down is just being able to figure out how
[00:07:58.520 --> 00:08:03.240]   to get it smaller, not in the design, but actually in the manufacturing.
[00:08:03.240 --> 00:08:05.400]   There's also a leadership crisis crisis.
[00:08:05.400 --> 00:08:12.120]   So the percentage left under a cloud, the story was because he had an affair with an
[00:08:12.120 --> 00:08:13.120]   associate.
[00:08:13.120 --> 00:08:19.720]   Honestly, it really had to be because the company was not going in the right direction.
[00:08:19.720 --> 00:08:20.720]   Allegedly.
[00:08:20.720 --> 00:08:22.120]   And I heard it was consensual.
[00:08:22.120 --> 00:08:26.000]   So, yeah, I mean, you could easily overlook what happened.
[00:08:26.000 --> 00:08:28.400]   It wasn't like he used his position of power.
[00:08:28.400 --> 00:08:33.040]   You know, but it was a convenient pretext for getting rid of crescendage.
[00:08:33.040 --> 00:08:34.920]   I will give somebody five points.
[00:08:34.920 --> 00:08:35.920]   I know you guys know.
[00:08:35.920 --> 00:08:36.920]   So don't say anything.
[00:08:36.920 --> 00:08:40.440]   If you could tell me, who's the CEO right now of Intel?
[00:08:40.440 --> 00:08:41.440]   Anybody.
[00:08:41.440 --> 00:08:42.920]   They're looking at each other.
[00:08:42.920 --> 00:08:46.520]   No one it's their CFO, Bob Swan, but he's temporary, right?
[00:08:46.520 --> 00:08:47.520]   And now we're waiting.
[00:08:47.520 --> 00:08:48.680]   He doesn't want it.
[00:08:48.680 --> 00:08:49.880]   He doesn't want it.
[00:08:49.880 --> 00:08:54.160]   So who's going to take over at Intel?
[00:08:54.160 --> 00:08:56.000]   And does it matter?
[00:08:56.000 --> 00:09:02.080]   By the way, Lisa Sue, you were talking about the CEO at AMD, is considered one of the candidates.
[00:09:02.080 --> 00:09:03.320]   Oh, yeah.
[00:09:03.320 --> 00:09:04.920]   The rumor is that they really want her.
[00:09:04.920 --> 00:09:08.080]   It would be quite a coup if they were to take her away.
[00:09:08.080 --> 00:09:17.600]   But I feel like she has risen very, very fast, seemingly the top of--
[00:09:17.600 --> 00:09:23.240]   she is one of the most celebrated CEOs certainly in Silicon Valley now, if not the nation.
[00:09:23.240 --> 00:09:24.760]   Isn't that interesting?
[00:09:24.760 --> 00:09:32.160]   And then there are a lot of candidates from other companies, Apple's senior vice president
[00:09:32.160 --> 00:09:33.160]   for hardware.
[00:09:33.160 --> 00:09:37.480]   Johnny, is it Shruji or Shruji?
[00:09:37.480 --> 00:09:42.320]   I'm not familiar with his work, but he was at Intel for a long time, for 15 years.
[00:09:42.320 --> 00:09:46.240]   He's also one of Apple's, apparently, according to the street, one of Apple's highest paid
[00:09:46.240 --> 00:09:47.400]   executives.
[00:09:47.400 --> 00:09:52.360]   And if you're thinking Apple and I pay, that's pretty good money.
[00:09:52.360 --> 00:10:00.840]   Somebody from within maybe Intel's own ranks, or perhaps former COO of Google Cloud, Diane
[00:10:00.840 --> 00:10:01.840]   Bryant.
[00:10:01.840 --> 00:10:02.840]   Hmm.
[00:10:02.840 --> 00:10:07.840]   I just feel like it was hard for him to ever come back.
[00:10:07.840 --> 00:10:13.560]   There are a percentage after that ill timed, we shall say, stock sale.
[00:10:13.560 --> 00:10:14.560]   Yeah.
[00:10:14.560 --> 00:10:15.560]   That was another problem, right?
[00:10:15.560 --> 00:10:16.560]   Yeah.
[00:10:16.560 --> 00:10:17.560]   Yeah.
[00:10:17.560 --> 00:10:18.560]   The optics were not good.
[00:10:18.560 --> 00:10:23.120]   So you say, I don't need to root for him, but I am rooting for Intel because we want--
[00:10:23.120 --> 00:10:24.280]   and I'm rooting for AMD.
[00:10:24.280 --> 00:10:29.000]   We want strong competitive companies, and we know ARM is doing all right.
[00:10:29.000 --> 00:10:30.640]   The various ARM fabs.
[00:10:30.640 --> 00:10:31.640]   Yeah.
[00:10:31.640 --> 00:10:34.240]   Keep in mind, AMD has an ARM license too.
[00:10:34.240 --> 00:10:36.120]   Ah, interesting.
[00:10:36.120 --> 00:10:37.120]   Interesting.
[00:10:37.120 --> 00:10:38.120]   All right.
[00:10:38.120 --> 00:10:42.920]   I thought I'd just bring that up because we got the hardware guys in house.
[00:10:42.920 --> 00:10:44.760]   But, Micah, we'll get something for you too.
[00:10:44.760 --> 00:10:45.760]   Don't worry.
[00:10:45.760 --> 00:10:46.760]   Hey, it's all right.
[00:10:46.760 --> 00:10:47.760]   I'm here.
[00:10:47.760 --> 00:10:48.760]   I'm learning.
[00:10:48.760 --> 00:10:49.760]   I'm learning.
[00:10:49.760 --> 00:10:52.920]   Actually, I mean, one of the big shoes that we're going to find out in the next couple
[00:10:52.920 --> 00:10:57.800]   of years is going to drop is whether Apple stops buying Intel chips and starts making
[00:10:57.800 --> 00:10:58.800]   its own.
[00:10:58.800 --> 00:11:02.880]   Intel got a windfall because Apple-- we found this out, by the way, finally, in testimony
[00:11:02.880 --> 00:11:08.480]   during the Qualcomm lawsuit that Apple couldn't buy Qualcomm chips for its next generation
[00:11:08.480 --> 00:11:09.480]   iPhones.
[00:11:09.480 --> 00:11:15.240]   They were forced to go to Intel and say, can you double your production because we need
[00:11:15.240 --> 00:11:16.240]   your chips?
[00:11:16.240 --> 00:11:21.040]   We can't buy Qualcomm chips for-- was it the 10 or was it the 10s for the new generation
[00:11:21.040 --> 00:11:22.040]   iPhones?
[00:11:22.040 --> 00:11:23.040]   The new ones.
[00:11:23.040 --> 00:11:24.040]   The 10s.
[00:11:24.040 --> 00:11:25.040]   The 10s.
[00:11:25.040 --> 00:11:26.240]   There's testimony by Qualcomm on Friday.
[00:11:26.240 --> 00:11:27.240]   I don't know if you saw this.
[00:11:27.240 --> 00:11:28.240]   Oh, I didn't see it.
[00:11:28.240 --> 00:11:32.600]   They directly disputed saying, we never stop selling.
[00:11:32.600 --> 00:11:37.320]   And they pointed to their dispute with Samsung and said that when we-- there were two years
[00:11:37.320 --> 00:11:40.840]   in dispute for licensing, and we still sold to them.
[00:11:40.840 --> 00:11:45.760]   So it's conflicting testimony to say whether or not did they actually say they won't sell
[00:11:45.760 --> 00:11:49.000]   it or did they continue to try to sell it?
[00:11:49.000 --> 00:11:51.640]   And Apple said, well, we won't buy it unless these are our terms.
[00:11:51.640 --> 00:11:53.600]   It was Apple's COO.
[00:11:53.600 --> 00:11:57.400]   On the witness stand, sworn in.
[00:11:57.400 --> 00:11:59.120]   So that would be perjury.
[00:11:59.120 --> 00:12:02.440]   Jeff Williams, who said no, they wouldn't sell it to us.
[00:12:02.440 --> 00:12:11.400]   Bloomberg has acquired some leaked emails in this regard.
[00:12:11.400 --> 00:12:13.440]   I'm not sure what to make of it.
[00:12:13.440 --> 00:12:15.080]   Let me go to the reveal.
[00:12:15.080 --> 00:12:17.520]   New reason Apple and Qualcomm parted ways.
[00:12:17.520 --> 00:12:22.400]   This came out a couple of days ago.
[00:12:22.400 --> 00:12:23.880]   This is part of the FTC.
[00:12:23.880 --> 00:12:26.960]   It's not actually Apple's fight with Qualcomm.
[00:12:26.960 --> 00:12:35.320]   This is the FTC trial against Qualcomm for not licensing their technology at a fair and
[00:12:35.320 --> 00:12:39.960]   reasonable price.
[00:12:39.960 --> 00:12:45.440]   And my wildest imagination, wrote Jeff Williams, of some evil intention of Apple, I have trouble
[00:12:45.440 --> 00:12:49.520]   coming up with a real scenario where anything of significant value could be leaked based
[00:12:49.520 --> 00:12:53.720]   on this code.
[00:12:53.720 --> 00:12:58.600]   I just hope the licensing dispute doesn't cloud good judgment in the team on a massive
[00:12:58.600 --> 00:12:59.680]   business opportunity.
[00:12:59.680 --> 00:13:03.200]   This is $2 billion of chips from Qualcomm.
[00:13:03.200 --> 00:13:06.720]   I was hoping to keep some decent quantity of business flowing with hopes the licensing
[00:13:06.720 --> 00:13:07.720]   stuff will get solved.
[00:13:07.720 --> 00:13:13.360]   Apparently, Qualcomm was concerned that Apple would leak technology information.
[00:13:13.360 --> 00:13:19.760]   I think they have actually accused Apple of doing that and giving information to Intel
[00:13:19.760 --> 00:13:27.280]   to allow them to build the modems for the phone and avoid the $7.50 per device.
[00:13:27.280 --> 00:13:30.120]   It doesn't speak at Qualcomm was charging.
[00:13:30.120 --> 00:13:36.520]   It does say in the emails that Qualcomm offered to provide the software access Apple needed
[00:13:36.520 --> 00:13:41.320]   in return for a commitment from Apple to use Qualcomm chips and at least 50% of iPhones
[00:13:41.320 --> 00:13:44.840]   over two years.
[00:13:44.840 --> 00:13:49.240]   Maybe Jeff's story did need a little bit of additional information.
[00:13:49.240 --> 00:13:52.320]   It wasn't completely the Qualcomm's fault.
[00:13:52.320 --> 00:13:54.760]   Does it mean there's a seems 750 seems very petty?
[00:13:54.760 --> 00:13:58.320]   I just pay it Apple.
[00:13:58.320 --> 00:13:59.320]   That's what they're asking.
[00:13:59.320 --> 00:14:02.560]   Qualcomm says we want $7.50 per iPhone.
[00:14:02.560 --> 00:14:03.560]   I'm not clear about this.
[00:14:03.560 --> 00:14:08.360]   Maybe Micah knows because I know Renee has said that's not merely the 750, but it's that
[00:14:08.360 --> 00:14:14.560]   Qualcomm's demanding a percentage of revenue rather than a flat fee for licensing this
[00:14:14.560 --> 00:14:15.560]   stuff.
[00:14:15.560 --> 00:14:18.960]   That's capped at $400 of device.
[00:14:18.960 --> 00:14:21.920]   It's $400 per device is the cap of the revenue of the phone.
[00:14:21.920 --> 00:14:25.360]   Still, you can understand why Apple might say, "Well, dudes."
[00:14:25.360 --> 00:14:27.520]   You're just one part of the pie here.
[00:14:27.520 --> 00:14:30.280]   Yeah, you want a percentage of our total revenue?
[00:14:30.280 --> 00:14:38.320]   No, we'll license it, but somebody asked for 5% of my revenue to play music or something.
[00:14:38.320 --> 00:14:42.640]   I'd say, "No, no, I'll give you a flat fee, but I'm not going to tie it to how much I make."
[00:14:42.640 --> 00:14:45.120]   But it's kind of core to the technology of what you're trying to do.
[00:14:45.120 --> 00:14:49.800]   What if there are 25% fee of you being able to stream on the internet?
[00:14:49.800 --> 00:14:54.240]   You'd be like, "Okay, that sounds reasonable."
[00:14:54.240 --> 00:14:59.840]   It's a fascinating back and forth, although it just feels like it was going on for decades.
[00:14:59.840 --> 00:15:00.840]   That's what I was going to say.
[00:15:00.840 --> 00:15:06.880]   I can remember reporting on this years and years ago, and it's just ongoing, and there's
[00:15:06.880 --> 00:15:09.920]   like, "Is anyone actually getting any money out of it?
[00:15:09.920 --> 00:15:13.320]   I understand wanting to step away from Qualcomm."
[00:15:13.320 --> 00:15:14.320]   Yeah.
[00:15:14.320 --> 00:15:15.880]   Lawyer's win.
[00:15:15.880 --> 00:15:17.840]   Apple finally gave up.
[00:15:17.840 --> 00:15:24.560]   I think the Apple Samsung battle was really started by Steve Jobs, and I think Apple finally
[00:15:24.560 --> 00:15:26.480]   said, "All right, that's enough."
[00:15:26.480 --> 00:15:27.480]   No.
[00:15:27.480 --> 00:15:28.480]   That's chill.
[00:15:28.480 --> 00:15:30.480]   That's just chill.
[00:15:30.480 --> 00:15:34.600]   I suppose at some point, adults will prevail in this Qualcomm battle.
[00:15:34.600 --> 00:15:35.600]   Maybe not.
[00:15:35.600 --> 00:15:36.600]   I don't know.
[00:15:36.600 --> 00:15:40.720]   Apple has lost a few, but the FTC inquiry has really helped them, I think.
[00:15:40.720 --> 00:15:47.200]   Meanwhile, Tim Cook writes an editorial in Time magazine doubling down on Apple's best
[00:15:47.200 --> 00:15:51.400]   marketing, I think, best marketing pitch, privacy.
[00:15:51.400 --> 00:15:56.280]   He says, "You deserve privacy online, and here's how you could actually get it.
[00:15:56.280 --> 00:15:57.920]   The problem is solvable.
[00:15:57.920 --> 00:16:00.720]   It's not too big, too challenging, or too late."
[00:16:00.720 --> 00:16:09.120]   He calls on Congress to do a few things, and I really like his three proposals here.
[00:16:09.120 --> 00:16:13.720]   First, the right to have personal data minimized.
[00:16:13.720 --> 00:16:15.920]   Some of this is in GDPR.
[00:16:15.920 --> 00:16:16.920]   The company-
[00:16:16.920 --> 00:16:17.920]   Yeah.
[00:16:17.920 --> 00:16:23.520]   Some of this is stuff that not he, but Apple and others that actually put forth.
[00:16:23.520 --> 00:16:31.960]   His pitch in this article is about this really good clearinghouse where the data brokers that
[00:16:31.960 --> 00:16:35.920]   collect our information, buyer information from other companies, and then sell it to
[00:16:35.920 --> 00:16:39.840]   other companies, those middle men.
[00:16:39.840 --> 00:16:44.440]   It's about being able to get access to them and know what they have on us and be able
[00:16:44.440 --> 00:16:49.120]   to change, delete, or adjust that information as we see fit.
[00:16:49.120 --> 00:16:54.160]   I like how he piggybacked off of the idea of the thing that's already in the works that
[00:16:54.160 --> 00:16:56.960]   these different companies are working on to say.
[00:16:56.960 --> 00:17:02.400]   Also, what really we need to be doing is talking about these companies that are buying data
[00:17:02.400 --> 00:17:03.560]   of ours.
[00:17:03.560 --> 00:17:05.160]   We don't really know that.
[00:17:05.160 --> 00:17:10.800]   People are going to them and buying those packages of data to be able to understand what
[00:17:10.800 --> 00:17:11.800]   their consumers want.
[00:17:11.800 --> 00:17:16.640]   Well, after all, wasn't that what AT&T Sprint and T-Mobile were accused of doing, is selling
[00:17:16.640 --> 00:17:22.840]   location data to brokers who then would sell it on to other people.
[00:17:22.840 --> 00:17:24.400]   That's even worse.
[00:17:24.400 --> 00:17:26.960]   That's like, "Well, anybody who wants location data."
[00:17:26.960 --> 00:17:29.960]   He wants Congress to pass.
[00:17:29.960 --> 00:17:32.760]   I'm curious about all three of you think of this.
[00:17:32.760 --> 00:17:33.760]   Here's his proposal.
[00:17:33.760 --> 00:17:34.760]   This is Tim Cook again.
[00:17:34.760 --> 00:17:40.720]   "Congress to pass comprehensive federal privacy legislation for principles," as I mentioned,
[00:17:40.720 --> 00:17:42.720]   "the right to have personal data minimized."
[00:17:42.720 --> 00:17:48.560]   "Second, the right to knowledge," "to know what data is being collected and why."
[00:17:48.560 --> 00:17:50.160]   This all seems completely reasonable, by the way.
[00:17:50.160 --> 00:17:51.760]   "Third, the right to access."
[00:17:51.760 --> 00:17:55.360]   It should be easy for you to access, correct, and delete."
[00:17:55.360 --> 00:17:57.760]   That's an important word, your personal data.
[00:17:57.760 --> 00:18:03.200]   Finally, the right to data security, keep my data safe.
[00:18:03.200 --> 00:18:08.040]   All you have to do, you look no farther than Equifax to realize how important that is.
[00:18:08.040 --> 00:18:11.960]   If you've got my data, you better darn well, keep it safe.
[00:18:11.960 --> 00:18:16.240]   I think some of this is not really helpful unless it makes it easy.
[00:18:16.240 --> 00:18:20.080]   A lot of the disclosure happens in a lot of legal use and things you click off when
[00:18:20.080 --> 00:18:22.200]   you sign something.
[00:18:22.200 --> 00:18:29.000]   If there's not an easy way of getting to it, like Facebook says that you can control ads,
[00:18:29.000 --> 00:18:37.400]   you can turn off preferences, but you have to dig through how many settings to find it.
[00:18:37.400 --> 00:18:43.680]   All of this sounds well and good, but if there's no standard in terms of this is how
[00:18:43.680 --> 00:18:49.840]   you present it and this is how you find it and everybody does it, then it's almost impossible
[00:18:49.840 --> 00:18:50.840]   to manage.
[00:18:50.840 --> 00:18:57.960]   It would be nice if it was like a credit report where you're saying, "Tell me who all has
[00:18:57.960 --> 00:18:58.960]   my information."
[00:18:58.960 --> 00:19:01.960]   You get a big report and then you can say, "You can go to them saying, "That's wrong,
[00:19:01.960 --> 00:19:03.360]   that's right, that's wrong, that's right."
[00:19:03.360 --> 00:19:08.440]   There needs to be some aggregator where you can go to one place and get it from all these
[00:19:08.440 --> 00:19:09.640]   different sites.
[00:19:09.640 --> 00:19:14.000]   But if you have to say, "What did I sign up for?
[00:19:14.000 --> 00:19:15.360]   Who has that information?"
[00:19:15.360 --> 00:19:19.480]   Then you have to do the investigative work yourself to figure out who has it.
[00:19:19.480 --> 00:19:25.720]   One's in a house with every single thing, every app on your phone.
[00:19:25.720 --> 00:19:26.720]   That's that.
[00:19:26.720 --> 00:19:32.600]   That's why we believe the Federal Trade Commission should establish a data broker clearing house,
[00:19:32.600 --> 00:19:37.240]   requiring all data brokers to register, enabling consumers to track the transactions that have
[00:19:37.240 --> 00:19:41.520]   bundled and sold their data from place to place and giving users the power to delete
[00:19:41.520 --> 00:19:45.560]   their data on demand freely, easily and online once and for all.
[00:19:45.560 --> 00:19:51.640]   I do see that as the credit report, the ability to go and say, "Okay, I know that when I was
[00:19:51.640 --> 00:19:56.800]   on Instagram and I clicked on these, I liked these things, then Instagram had that information
[00:19:56.800 --> 00:20:01.880]   and maybe that information then got sold to this third party that then sold that information
[00:20:01.880 --> 00:20:05.760]   to someone else and it goes all over the place to be able to pull that in and collect, I think,
[00:20:05.760 --> 00:20:06.760]   is great."
[00:20:06.760 --> 00:20:11.920]   One of the things that I see in the chat room and when I talked about this before, the concern
[00:20:11.920 --> 00:20:19.400]   that, "Okay, if all of my data is in one place and it's a site that's built by the government,
[00:20:19.400 --> 00:20:23.400]   let's talk about privacy and security there because if you've got one place where someone
[00:20:23.400 --> 00:20:28.680]   can attack and get into, they've suddenly got all of my information from all of these
[00:20:28.680 --> 00:20:34.240]   different apps and services that I use, that's a little concerning.
[00:20:34.240 --> 00:20:35.760]   That part kind of worries me.
[00:20:35.760 --> 00:20:42.360]   I don't know who should be in charge of holding on to all of that data for me and actually
[00:20:42.360 --> 00:20:43.360]   keeping it safe."
[00:20:43.360 --> 00:20:48.640]   Well, and then there's a fight between federal and states.
[00:20:48.640 --> 00:20:54.520]   I think Tim Cook's calling for a federal law, but state of California has a very aggressive
[00:20:54.520 --> 00:20:55.520]   privacy law.
[00:20:55.520 --> 00:21:02.120]   Marco Rubio, Florida, has proposed a bill poorly named the America Data Dissemination
[00:21:02.120 --> 00:21:03.120]   Act.
[00:21:03.120 --> 00:21:13.680]   I could say what that sounds like, but it establishes a process for creating rules instead of issuing
[00:21:13.680 --> 00:21:19.920]   specific rules right away and allows 27 months for Congress or the FTC to write the rules
[00:21:19.920 --> 00:21:24.920]   and it would supersede any state law.
[00:21:24.920 --> 00:21:25.920]   Now I don't think that's a bad thing.
[00:21:25.920 --> 00:21:26.920]   I don't understand.
[00:21:26.920 --> 00:21:27.920]   I don't understand.
[00:21:27.920 --> 00:21:31.280]   A patchwork of laws is probably hard for any one company to adhere to.
[00:21:31.280 --> 00:21:38.000]   So a federal law, if it's the right law, would be probably the right way to do this.
[00:21:38.000 --> 00:21:40.320]   So is this like, oh boy, good.
[00:21:40.320 --> 00:21:45.440]   No, I was just going to say, is this him saying, "Oh dear, I see that we're about to
[00:21:45.440 --> 00:21:50.000]   start working on making these rules and we need more time so we should have 27 months
[00:21:50.000 --> 00:21:51.000]   at least."
[00:21:51.000 --> 00:21:54.920]   I'm confused with this law as opposed to fix.
[00:21:54.920 --> 00:22:05.840]   Well, and the public knowledge said the bill is based on the Privacy Act of 1974, which
[00:22:05.840 --> 00:22:10.880]   applied to federal agencies, but Rubio proposes the same rules prior to the private sector.
[00:22:10.880 --> 00:22:16.760]   But it's really more a transparency in data accuracy law than a privacy law.
[00:22:16.760 --> 00:22:23.400]   So there is some concern that this is a sneaky attempt to override state privacy laws and
[00:22:23.400 --> 00:22:26.280]   then do nothing at the federal level.
[00:22:26.280 --> 00:22:28.040]   Oh my Lord.
[00:22:28.040 --> 00:22:29.040]   Okay.
[00:22:29.040 --> 00:22:34.640]   I really like West's idea of a report where everything has to be registered and all accesses
[00:22:34.640 --> 00:22:40.680]   are something that users can themselves access and see exactly where your information is
[00:22:40.680 --> 00:22:41.680]   going.
[00:22:41.680 --> 00:22:45.560]   But I think another thing that we have to have, if there were to be some sort of sweeping
[00:22:45.560 --> 00:22:51.320]   legislation that at a federal level laid down some rules, one of them is how the data
[00:22:51.320 --> 00:22:58.240]   is actually handled because as we've seen with, I think this week, yet another data
[00:22:58.240 --> 00:23:00.000]   breach or at least one that was exposed.
[00:23:00.000 --> 00:23:01.000]   Oh yeah.
[00:23:01.000 --> 00:23:02.560]   Let's talk about that one.
[00:23:02.560 --> 00:23:03.560]   How is your data stored?
[00:23:03.560 --> 00:23:07.600]   Well, unfortunately far too many times in my life, it turns out my data was stored in
[00:23:07.600 --> 00:23:08.600]   plain text.
[00:23:08.600 --> 00:23:09.600]   Yeah.
[00:23:09.600 --> 00:23:12.360]   It'll help me very much.
[00:23:12.360 --> 00:23:19.280]   So Troy Hunt on Wednesday published a post on Have I Been Pwned, his great site about
[00:23:19.280 --> 00:23:29.000]   collection number one, which contains 773 million in the clear, unique email addresses,
[00:23:29.000 --> 00:23:32.200]   21 million unique passwords.
[00:23:32.200 --> 00:23:35.360]   It, you know, it was a big deal.
[00:23:35.360 --> 00:23:42.080]   But I love Brian Krebs because his first thing he does is he, he actually hunts down the
[00:23:42.080 --> 00:23:44.360]   guy who posted this.
[00:23:44.360 --> 00:23:49.840]   He apparently has a telegram account, his username, Sanixer, and he contacted and find
[00:23:49.840 --> 00:23:54.440]   out more about collection one, which by the way is available for the low, low price of
[00:23:54.440 --> 00:24:05.680]   $45, $45, which Brian points out is just 0.00002 cents per password.
[00:24:05.680 --> 00:24:08.200]   And Sanixer says, Oh, you don't want collection one.
[00:24:08.200 --> 00:24:10.200]   That's two or three years old.
[00:24:10.200 --> 00:24:16.320]   I've got much, much more recent stuff.
[00:24:16.320 --> 00:24:21.440]   And I hope that all of this stuff will eventually make it into Have I Been Pwned.
[00:24:21.440 --> 00:24:25.920]   If you go to HaveIbeenpwn.com, which everybody probably should do at this point, not do the
[00:24:25.920 --> 00:24:30.960]   front page, which is enter your email address, forget it, you know your email address compromised.
[00:24:30.960 --> 00:24:32.640]   That's not the problem.
[00:24:32.640 --> 00:24:40.000]   Click the tab at the top that says passwords and enter in some passwords.
[00:24:40.000 --> 00:24:41.520]   That's an eye opener.
[00:24:41.520 --> 00:24:46.080]   These are passwords that are in the clear in collection number one.
[00:24:46.080 --> 00:24:47.080]   Go ahead.
[00:24:47.080 --> 00:24:48.080]   Let's see.
[00:24:48.080 --> 00:24:49.080]   This is a Karsten.
[00:24:49.080 --> 00:24:53.120]   Oh, Karsten, that password's been seen 60,000 times before.
[00:24:53.120 --> 00:24:55.520]   Would you enter monkey one, two, three?
[00:24:55.520 --> 00:25:00.520]   Um, wait, or is that your password?
[00:25:00.520 --> 00:25:03.440]   So I entered the, yeah, okay.
[00:25:03.440 --> 00:25:07.520]   But I entered the password that I use on low security sites all the time.
[00:25:07.520 --> 00:25:09.080]   Totally pwned.
[00:25:09.080 --> 00:25:12.440]   So that's the one everybody should be going to.
[00:25:12.440 --> 00:25:18.240]   And it does not include Sanixer's complete collection, just collection one, which is
[00:25:18.240 --> 00:25:20.280]   big enough.
[00:25:20.280 --> 00:25:23.680]   So honestly, those passwords are no good anymore.
[00:25:23.680 --> 00:25:27.720]   The bottom line in Krebs points this out is turn on two factor every single place you
[00:25:27.720 --> 00:25:31.640]   can never, ever reuse passwords.
[00:25:31.640 --> 00:25:33.160]   And if you password has not been pwned.
[00:25:33.160 --> 00:25:34.160]   Oh, good news.
[00:25:34.160 --> 00:25:35.160]   Yeah.
[00:25:35.160 --> 00:25:39.000]   The first, what I would do is go there and enter your email password because that's the,
[00:25:39.000 --> 00:25:40.000]   that's the keys to the kingdom.
[00:25:40.000 --> 00:25:43.200]   Because if somebody can get into your email account, first of all, turn on two factor.
[00:25:43.200 --> 00:25:46.720]   If you're not, and if you're using an email provider that doesn't offer two factor, get
[00:25:46.720 --> 00:25:47.720]   the hell out.
[00:25:47.720 --> 00:25:48.720]   Yeah.
[00:25:48.720 --> 00:25:49.720]   What are you doing?
[00:25:49.720 --> 00:25:50.720]   What are you crazy?
[00:25:50.720 --> 00:25:51.960]   I don't think you're using Yahoo get out of there.
[00:25:51.960 --> 00:25:52.960]   I'm just going to say it.
[00:25:52.960 --> 00:25:55.880]   They do have two factor, but yeah, I know, but don't.
[00:25:55.880 --> 00:25:56.880]   Yeah.
[00:25:56.880 --> 00:26:00.640]   I'm going to call on the radio show today from a very nice woman who said, I just thought
[00:26:00.640 --> 00:26:04.720]   I hadn't done it in months, check my online brokerage.
[00:26:04.720 --> 00:26:08.160]   So I called them and they said, Oh, you changed your, I couldn't log in.
[00:26:08.160 --> 00:26:09.160]   So I called them.
[00:26:09.160 --> 00:26:10.520]   They said, you changed your password yesterday.
[00:26:10.520 --> 00:26:16.040]   And we just got all the paperwork to, to sell all your stocks and send a check.
[00:26:16.040 --> 00:26:18.800]   And she said, no, that wasn't me.
[00:26:18.800 --> 00:26:20.760]   And this is how horrible was.
[00:26:20.760 --> 00:26:25.000]   She said the fraud division of this online broker got involved.
[00:26:25.000 --> 00:26:26.360]   And they said, yeah, we listened to the call.
[00:26:26.360 --> 00:26:28.960]   It was a man pretending to be a woman.
[00:26:28.960 --> 00:26:31.160]   Hi, this is Mara.
[00:26:31.160 --> 00:26:33.480]   What in the world?
[00:26:33.480 --> 00:26:37.040]   And they had her address.
[00:26:37.040 --> 00:26:39.480]   They had her phone number.
[00:26:39.480 --> 00:26:43.760]   And in order to verify the identity, as many do, they, the, the stock brokerage used
[00:26:43.760 --> 00:26:46.520]   for credit report to say, well, did you ever get a loan for this?
[00:26:46.520 --> 00:26:49.240]   Did you ever, you know, where did you live of these three addresses?
[00:26:49.240 --> 00:26:50.240]   You know how they do that.
[00:26:50.240 --> 00:26:51.240]   Yeah.
[00:26:51.240 --> 00:26:53.960]   And the hacker knew it all because obviously.
[00:26:53.960 --> 00:26:55.680]   So Mara said, how did they get that?
[00:26:55.680 --> 00:26:59.320]   And I said, well, probably from Equifax.
[00:26:59.320 --> 00:27:00.320]   But who knows, right?
[00:27:00.320 --> 00:27:02.800]   If they, and they, and at this point they probably have your social, maybe they got
[00:27:02.800 --> 00:27:04.400]   a from Mary on.
[00:27:04.400 --> 00:27:09.640]   They, and they had enough information about her to poses her to say, sell all my stocks
[00:27:09.640 --> 00:27:10.840]   and send me a check.
[00:27:10.840 --> 00:27:15.360]   Oh, and, yeah, it's lucky she caught it.
[00:27:15.360 --> 00:27:16.360]   Lucky she caught it.
[00:27:16.360 --> 00:27:20.560]   So, but the fact that they, they, they, they, the fraud department said, yeah, I was a guy
[00:27:20.560 --> 00:27:22.600]   pretending to be a woman.
[00:27:22.600 --> 00:27:25.000]   And that the customer service rep said, yeah, yeah, fine.
[00:27:25.000 --> 00:27:29.480]   Okay, here's, here's your, tell us where to send your money.
[00:27:29.480 --> 00:27:31.040]   So that's why these breaches are important.
[00:27:31.040 --> 00:27:32.600]   And that's why you got to turn on two factor.
[00:27:32.600 --> 00:27:36.280]   You should check your email password, especially because if they get your email, they can you
[00:27:36.280 --> 00:27:39.920]   go to every other site say, I forgot my password, send me a reset.
[00:27:39.920 --> 00:27:40.920]   And you're dead.
[00:27:40.920 --> 00:27:45.800]   Do you remember at the beginning of the internet, there used to be like a shield at the bottom
[00:27:45.800 --> 00:27:46.800]   that's secure?
[00:27:46.800 --> 00:27:47.800]   Yeah, secure.
[00:27:47.800 --> 00:27:48.800]   And do that on some sites.
[00:27:48.800 --> 00:27:53.400]   Like when you go by fruit and it's organic, it's certified by some third party.
[00:27:53.400 --> 00:27:58.200]   I think the internet needs to come up with a list of things you should have, like with
[00:27:58.200 --> 00:28:03.520]   the kind of SSL certificate, the type of two factor authentication that your site supports.
[00:28:03.520 --> 00:28:08.520]   You know, whether it's SMS or through an authentication app or something like that, come up with some
[00:28:08.520 --> 00:28:10.320]   sort of seal.
[00:28:10.320 --> 00:28:17.360]   And so I know when I go to eBay or I go to Gmail that if it has the seal that it checks
[00:28:17.360 --> 00:28:20.880]   all those boxes and I would have to think about this less.
[00:28:20.880 --> 00:28:22.400]   Nothing like that exists though, right?
[00:28:22.400 --> 00:28:26.320]   I mean, there's a Norton, but I don't trust, you know, yeah, I don't try.
[00:28:26.320 --> 00:28:27.920]   Yeah, I see one of those seals at the bottom.
[00:28:27.920 --> 00:28:32.440]   I'm like, Nope, I don't even like all that happened is the company paid this company at
[00:28:32.440 --> 00:28:33.440]   one point.
[00:28:33.440 --> 00:28:36.800]   Maybe they did an assay, a security assay, maybe not.
[00:28:36.800 --> 00:28:38.240]   You like right click on it.
[00:28:38.240 --> 00:28:39.560]   Oh, this is just a PNG.
[00:28:39.560 --> 00:28:41.400]   They loaded into the stupid side.
[00:28:41.400 --> 00:28:44.920]   Yeah, you know, you need to like, you know, work on that or something.
[00:28:44.920 --> 00:28:45.920]   We need something.
[00:28:45.920 --> 00:28:50.520]   And, you know, if it's government, I don't know, I think it has to be at some point.
[00:28:50.520 --> 00:28:55.940]   Here is a Democratic bill Ron Wyden has put forward, which proposes significant jail
[00:28:55.940 --> 00:28:59.320]   time for somebody who allows your data to be leaked.
[00:28:59.320 --> 00:29:01.480]   I think that's a good idea.
[00:29:01.480 --> 00:29:02.480]   Let's get to the future.
[00:29:02.480 --> 00:29:04.120]   I think it's going to be harder penalties.
[00:29:04.120 --> 00:29:05.120]   Absolutely.
[00:29:05.120 --> 00:29:09.920]   Because that's when it comes to the protection, that's the one thing that I think will either
[00:29:09.920 --> 00:29:15.880]   a whole heck of a lot of money that you got to pay or jail time for folks who are, you
[00:29:15.880 --> 00:29:20.880]   know, legitimately negligent in whatever aspect to result in this.
[00:29:20.880 --> 00:29:25.840]   Because I saw like they're working on potentially charging Facebook a whole heck of a lot of
[00:29:25.840 --> 00:29:27.600]   money or thinking about it.
[00:29:27.600 --> 00:29:29.520]   I can't remember what that posted said.
[00:29:29.520 --> 00:29:34.400]   But yeah, I think money talks as they say.
[00:29:34.400 --> 00:29:38.680]   What about on mandating like in the top corner, they have to say how many breaches they've
[00:29:38.680 --> 00:29:40.040]   had in the last 30 days?
[00:29:40.040 --> 00:29:41.040]   Go site.
[00:29:41.040 --> 00:29:45.800]   Well, GDPR requires that you reveal breaches within 72 hours.
[00:29:45.800 --> 00:29:46.800]   That's a big.
[00:29:46.800 --> 00:29:48.720]   So I was doing a little research.
[00:29:48.720 --> 00:29:56.040]   I wonder what Equifax, what were the big fines and penalties Equifax had to pay for that breach,
[00:29:56.040 --> 00:29:58.680]   which probably cost Mara.
[00:29:58.680 --> 00:30:02.280]   They reached an agreement with the New York State Department of Financial Services and
[00:30:02.280 --> 00:30:05.280]   seven other state banking regulators.
[00:30:05.280 --> 00:30:09.920]   The order does not impose any fines or monetary penalties.
[00:30:09.920 --> 00:30:14.960]   They just they agreed to implement stronger data security measures.
[00:30:14.960 --> 00:30:18.840]   And this is just states that have no federal states.
[00:30:18.840 --> 00:30:19.840]   Not even all states.
[00:30:19.840 --> 00:30:20.840]   There's no.
[00:30:20.840 --> 00:30:25.880]   I would have required to make sure they hire someone who has experienced data security.
[00:30:25.880 --> 00:30:32.600]   The really, yeah, I mean, as far as I can tell, Equifax made money on this by selling monitoring
[00:30:32.600 --> 00:30:35.160]   services to the poor people who'd been hacked.
[00:30:35.160 --> 00:30:36.400]   That's not that terrible.
[00:30:36.400 --> 00:30:38.160]   That's really what happened.
[00:30:38.160 --> 00:30:40.000]   They made money.
[00:30:40.000 --> 00:30:44.160]   I don't think there's any severe penalty that I can find anywhere.
[00:30:44.160 --> 00:30:49.040]   The DOJ and SEC have charged former Equifax executives for insider trading.
[00:30:49.040 --> 00:30:53.200]   Remember, there was a big stock sale right before the breach was revealed.
[00:30:53.200 --> 00:30:55.000]   So maybe somebody's going to go down on that.
[00:30:55.000 --> 00:30:56.000]   It does face.
[00:30:56.000 --> 00:30:57.000]   That was just foolish too.
[00:30:57.000 --> 00:30:58.000]   Why would you?
[00:30:58.000 --> 00:30:59.560]   Why even try to do that?
[00:30:59.560 --> 00:31:01.840]   That was so stupid.
[00:31:01.840 --> 00:31:09.440]   They continue to be under investigation by the FTC and they face a lot of civil lawsuits.
[00:31:09.440 --> 00:31:12.040]   I think maybe that in the long run, that's what's going to happen.
[00:31:12.040 --> 00:31:14.640]   Maybe is that some civil lawsuits will cost them.
[00:31:14.640 --> 00:31:20.200]   But right now, Equifax is sitting pretty and and and I don't see anything going on with
[00:31:20.200 --> 00:31:21.200]   Marriott.
[00:31:21.200 --> 00:31:22.800]   I don't see anything going on with Target.
[00:31:22.800 --> 00:31:23.800]   I don't see anything going on.
[00:31:23.800 --> 00:31:28.760]   I mean, Yahoo, three billion records, three billion.
[00:31:28.760 --> 00:31:34.320]   Well, Leo, they have made a commitment to privacy.
[00:31:34.320 --> 00:31:36.520]   We're committed to your prime, I think.
[00:31:36.520 --> 00:31:38.520]   We're going to rename it.
[00:31:38.520 --> 00:31:39.520]   We're going to rename it.
[00:31:39.520 --> 00:31:40.960]   It's what we're going to do.
[00:31:40.960 --> 00:31:42.920]   It's going to be we're not going to call it oath.
[00:31:42.920 --> 00:31:45.160]   We're going to call it Verizon media.
[00:31:45.160 --> 00:31:46.160]   Okay.
[00:31:46.160 --> 00:31:47.160]   Thank you.
[00:31:47.160 --> 00:31:54.520]   I was part of the OPMI breach because I had, well, I applied for secret clearance because
[00:31:54.520 --> 00:31:56.080]   I used to work for Dell.
[00:31:56.080 --> 00:31:57.840]   And so I need to get on military bases.
[00:31:57.840 --> 00:32:01.280]   So that's the office of personnel management, the US government.
[00:32:01.280 --> 00:32:02.280]   Yeah.
[00:32:02.280 --> 00:32:09.800]   And so my FBI file, when you go through security clearance, they ask for some extremely sensitive
[00:32:09.800 --> 00:32:10.800]   information.
[00:32:10.800 --> 00:32:11.800]   Yeah.
[00:32:11.800 --> 00:32:14.600]   Basically, they want to know if anyone could blackmail you, what can they blackmail you
[00:32:14.600 --> 00:32:15.600]   with?
[00:32:15.600 --> 00:32:16.600]   Right.
[00:32:16.600 --> 00:32:17.600]   And you have to like list all of that.
[00:32:17.600 --> 00:32:18.680]   And then they got breached.
[00:32:18.680 --> 00:32:23.760]   And then all I got was the letter and the mail saying, Hey, you're still got stolen.
[00:32:23.760 --> 00:32:25.640]   Look out for those blackmail letters, Wesley.
[00:32:25.640 --> 00:32:26.640]   Yeah.
[00:32:26.640 --> 00:32:33.080]   That's the part that makes me worried about this online clearing house idea because I think
[00:32:33.080 --> 00:32:34.080]   that it's a good idea.
[00:32:34.080 --> 00:32:39.960]   They don't trust anybody to have that information on me because no one's done a good enough
[00:32:39.960 --> 00:32:40.960]   job with that.
[00:32:40.960 --> 00:32:43.920]   You know, there is good news about the OPMI breach.
[00:32:43.920 --> 00:32:45.600]   Wesley, you'll be glad to know that's this.
[00:32:45.600 --> 00:32:47.560]   It turns out it probably wasn't a bad guy.
[00:32:47.560 --> 00:32:50.720]   It was China.
[00:32:50.720 --> 00:32:55.000]   And they're not because that data like the Yahoo day has never emerged in public, you
[00:32:55.000 --> 00:32:57.520]   know, on the dark web or on for sale anywhere.
[00:32:57.520 --> 00:33:02.080]   And it really was probably just China trying to, you know, figure out who they can sub
[00:33:02.080 --> 00:33:05.640]   born where, you know, they have my Marriott data data.
[00:33:05.640 --> 00:33:06.640]   And they have that.
[00:33:06.640 --> 00:33:07.640]   Oh, yeah.
[00:33:07.640 --> 00:33:08.640]   China's got the whole thing.
[00:33:08.640 --> 00:33:13.320]   They got a great picture of who is Wesley Faulkner.
[00:33:13.320 --> 00:33:17.360]   You know, if I were you, I'd buy some lightweight here and you'd have a complete set.
[00:33:17.360 --> 00:33:19.560]   You'd have you collect all.
[00:33:19.560 --> 00:33:26.560]   No, but you can do it.
[00:33:26.560 --> 00:33:28.560]   If you're listening right now, send me a coupon.
[00:33:28.560 --> 00:33:29.560]   Send me a coupon discount.
[00:33:29.560 --> 00:33:30.560]   I'll buy a Huawei phone.
[00:33:30.560 --> 00:33:34.360]   No, seriously, in a way, this is what's really sad.
[00:33:34.360 --> 00:33:40.640]   It's better to be breached by a state actor than have your stuff sold on the dark web,
[00:33:40.640 --> 00:33:41.640]   right?
[00:33:41.640 --> 00:33:44.600]   You know, what's best is none of that to happen though.
[00:33:44.600 --> 00:33:45.600]   Oh, that.
[00:33:45.600 --> 00:33:47.400]   Well, yeah, that one's balanced.
[00:33:47.400 --> 00:33:50.000]   What I mean, what, what dream on Mike?
[00:33:50.000 --> 00:33:54.880]   Maybe we should ask like when you're getting to know someone new, you just say, so if you
[00:33:54.880 --> 00:33:57.840]   had to have your data stolen by a country, what country would you choose?
[00:33:57.840 --> 00:34:01.200]   Oh, you can learn a lot about a person from that.
[00:34:01.200 --> 00:34:02.440]   I trust China.
[00:34:02.440 --> 00:34:03.440]   I trust.
[00:34:03.440 --> 00:34:04.440]   Okay.
[00:34:04.440 --> 00:34:05.440]   I trust Mark Zuckerberg.
[00:34:05.440 --> 00:34:06.440]   Okay.
[00:34:06.440 --> 00:34:10.280]   There's a there's a question asked on a first date.
[00:34:10.280 --> 00:34:11.280]   Who do you trust more?
[00:34:11.280 --> 00:34:13.720]   China or Zuckerberg?
[00:34:13.720 --> 00:34:14.720]   Sink hard.
[00:34:14.720 --> 00:34:17.320]   You just look at him dead.
[00:34:17.320 --> 00:34:18.320]   Right?
[00:34:18.320 --> 00:34:20.000]   Sink really hard about it.
[00:34:20.000 --> 00:34:21.000]   Hard.
[00:34:21.000 --> 00:34:24.800]   All right, let's take a little break.
[00:34:24.800 --> 00:34:25.800]   I don't know.
[00:34:25.800 --> 00:34:27.480]   I didn't mean to start with such bad news.
[00:34:27.480 --> 00:34:29.880]   Let's we'll find some happy, go lucky.
[00:34:29.880 --> 00:34:32.720]   Actually, did you go to CES Sebastian?
[00:34:32.720 --> 00:34:33.720]   I did.
[00:34:33.720 --> 00:34:39.960]   I was actually there only for three days, but you say I did go three days felt like a lifetime.
[00:34:39.960 --> 00:34:43.120]   It was nice to sneak out early though when everybody else had to stay that extra day
[00:34:43.120 --> 00:34:45.120]   or two and I'm like, sorry guys.
[00:34:45.120 --> 00:34:46.120]   Got to get on the plane.
[00:34:46.120 --> 00:34:47.120]   Yeah.
[00:34:47.120 --> 00:34:48.120]   Bye bye.
[00:34:48.120 --> 00:34:51.400]   I always like to stay a little Sunday because Sunday is fun because all the geeks are going
[00:34:51.400 --> 00:34:54.360]   home and all the gamblers are coming in.
[00:34:54.360 --> 00:34:55.840]   Yes.
[00:34:55.840 --> 00:35:00.840]   It's always fun to fly out of Vegas at the end of the week to watch the broke people
[00:35:00.840 --> 00:35:04.960]   leave and the fresh suckers, I cast coming in.
[00:35:04.960 --> 00:35:06.120]   It's always fun.
[00:35:06.120 --> 00:35:10.360]   And it's fun on Sunday if you take a cab to the airport to McCarran because at this
[00:35:10.360 --> 00:35:13.520]   happened to be the other last time I was in Vegas, the cab he said, see that guy?
[00:35:13.520 --> 00:35:16.280]   He's like walking to the airport, rolling his luggage behind him.
[00:35:16.280 --> 00:35:17.960]   He lost everything but his plane ticket.
[00:35:17.960 --> 00:35:21.840]   He can't even afford cab fare to the airport.
[00:35:21.840 --> 00:35:23.320]   He's walking.
[00:35:23.320 --> 00:35:26.760]   And apparently that's you see a lot of that.
[00:35:26.760 --> 00:35:27.760]   Little tip kids.
[00:35:27.760 --> 00:35:30.000]   Maybe it's better.
[00:35:30.000 --> 00:35:31.480]   Put some cab fare in your shoe.
[00:35:31.480 --> 00:35:32.480]   You never know.
[00:35:32.480 --> 00:35:35.360]   Are you sure you said it was supposed to get more uplifting?
[00:35:35.360 --> 00:35:36.360]   I know.
[00:35:36.360 --> 00:35:37.360]   I'm sorry.
[00:35:37.360 --> 00:35:38.360]   I'm sorry.
[00:35:38.360 --> 00:35:40.360]   I'm sorry.
[00:35:40.360 --> 00:35:43.640]   Our show today, oh, I'm happy to tell you about my Aura ring.
[00:35:43.640 --> 00:35:47.680]   Some of you have noticed I wear this ring and I've been wearing this for some time.
[00:35:47.680 --> 00:35:49.480]   Kevin Rose was the first to tell me about it.
[00:35:49.480 --> 00:35:51.680]   Way back when he was on triangulation.
[00:35:51.680 --> 00:35:53.000]   He's an advisor to this company.
[00:35:53.000 --> 00:35:54.800]   It's a finished company.
[00:35:54.800 --> 00:35:58.280]   And he said, I'll hook you up with Harpreet and he'll get you what he did.
[00:35:58.280 --> 00:36:00.160]   I've been wearing it ever since.
[00:36:00.160 --> 00:36:02.520]   This beats, you know, I have an Apple watch.
[00:36:02.520 --> 00:36:03.920]   I have a fit with this beats.
[00:36:03.920 --> 00:36:09.760]   Any other tracker fitness or health or sleep tracker on the market, it is awesome.
[00:36:09.760 --> 00:36:14.800]   ORA is O-U-R-A or a ring.com.
[00:36:14.800 --> 00:36:16.200]   Let me show you what it does.
[00:36:16.200 --> 00:36:18.840]   It is of course an activity tracker.
[00:36:18.840 --> 00:36:22.640]   You know, it shows you how much exercise you've got, you know, and how many calories
[00:36:22.640 --> 00:36:23.640]   you've used.
[00:36:23.640 --> 00:36:26.440]   It ties in if you use an iPhone with Apple Health, which is great.
[00:36:26.440 --> 00:36:29.480]   So you can get more information from Apple Health.
[00:36:29.480 --> 00:36:31.720]   So it shows you I wrote for 30 minutes yesterday.
[00:36:31.720 --> 00:36:32.720]   How many calories?
[00:36:32.720 --> 00:36:34.840]   I wrote for Apple Health.
[00:36:34.840 --> 00:36:36.160]   How much walking I did.
[00:36:36.160 --> 00:36:37.320]   How many calories I've burned.
[00:36:37.320 --> 00:36:38.320]   Here's my sleep score.
[00:36:38.320 --> 00:36:39.600]   This is fascinating.
[00:36:39.600 --> 00:36:41.880]   So the ring inside it has an accelerometer.
[00:36:41.880 --> 00:36:44.160]   That's how it measures footsteps and movement.
[00:36:44.160 --> 00:36:49.600]   But it also has an infrared optical pulse measure that's more accurate than on your
[00:36:49.600 --> 00:36:51.600]   wrist because it's on your finger.
[00:36:51.600 --> 00:36:57.560]   3D accelerometer, gyroscope and a temperature sensor.
[00:36:57.560 --> 00:36:59.760]   It is really great.
[00:36:59.760 --> 00:37:03.080]   This is my sleep score from last night, 66.
[00:37:03.080 --> 00:37:04.080]   What?
[00:37:04.080 --> 00:37:06.360]   Not good.
[00:37:06.360 --> 00:37:11.520]   I can tap on it and I can learn more about how much awake time, how much rem time, how
[00:37:11.520 --> 00:37:15.320]   much was light sleep, how much was deep sleep, how fast I went to sleep.
[00:37:15.320 --> 00:37:16.680]   It only took me 26 minutes.
[00:37:16.680 --> 00:37:18.760]   That's actually a long time to fall asleep.
[00:37:18.760 --> 00:37:22.320]   But I only had 6% deep sleep, 22 minutes.
[00:37:22.320 --> 00:37:27.840]   An hour or three quarters of dreaming, it says, "Pay attention because your restfulness
[00:37:27.840 --> 00:37:29.560]   was bad."
[00:37:29.560 --> 00:37:33.960]   And so it gives you advice about optimizing your sleep environment, your temperature of
[00:37:33.960 --> 00:37:37.080]   void spicy meals, get regular activity.
[00:37:37.080 --> 00:37:40.160]   It will give you information that's really useful.
[00:37:40.160 --> 00:37:41.680]   Here's my resting heart rate.
[00:37:41.680 --> 00:37:46.960]   This is the other thing I really like is the temperature information is fascinating.
[00:37:46.960 --> 00:37:54.400]   Did you know that right before you get sick, your temperature is going to go up slightly?
[00:37:54.400 --> 00:37:58.160]   And here's a 30-day measurement of my temperature.
[00:37:58.160 --> 00:38:01.680]   So you can see if it's going up, maybe you're about to get sick or maybe you drank too much
[00:38:01.680 --> 00:38:02.720]   last night.
[00:38:02.720 --> 00:38:07.640]   The other thing that's fascinating is something called heart rate variability.
[00:38:07.640 --> 00:38:12.280]   It turns out that higher is better when it comes to heart rate variability.
[00:38:12.280 --> 00:38:14.280]   That's the amount of time in between beats.
[00:38:14.280 --> 00:38:17.520]   It should be less consistent, not more consistent.
[00:38:17.520 --> 00:38:20.040]   And it can range from below 20 to over 100.
[00:38:20.040 --> 00:38:21.560]   100 is great.
[00:38:21.560 --> 00:38:24.880]   And so you'll see, in fact, if I look at my monthly, look at this.
[00:38:24.880 --> 00:38:28.360]   My heart rate variability plummeted in November and December.
[00:38:28.360 --> 00:38:29.920]   It's coming back up.
[00:38:29.920 --> 00:38:35.240]   That will show you readiness, the ability to work out your fitness level.
[00:38:35.240 --> 00:38:36.400]   Maybe you're over training.
[00:38:36.400 --> 00:38:38.120]   Maybe you're under stress.
[00:38:38.120 --> 00:38:43.200]   They have lots of information in the app that tells you what it means.
[00:38:43.200 --> 00:38:49.280]   There has been never been a better device as far as I'm concerned for giving you information.
[00:38:49.280 --> 00:38:50.400]   That's all the good news.
[00:38:50.400 --> 00:38:52.320]   There is bad news.
[00:38:52.320 --> 00:38:54.360]   They're sold out through April.
[00:38:54.360 --> 00:38:56.080]   I hate to do this to you.
[00:38:56.080 --> 00:39:00.320]   But this has proven so popular that they can't keep them in stock.
[00:39:00.320 --> 00:39:04.040]   By the way, the other thing I recommend, read the privacy policy.
[00:39:04.040 --> 00:39:05.880]   It is a Finnish company.
[00:39:05.880 --> 00:39:09.880]   Your data is highly protected, anonymized.
[00:39:09.880 --> 00:39:12.400]   It is completely secure.
[00:39:12.400 --> 00:39:17.560]   So this is one smart fitness tracker that you can use without worrying.
[00:39:17.560 --> 00:39:21.600]   The daily feedback really is great to help you understand your body, improve your health,
[00:39:21.600 --> 00:39:22.600]   to reach your goals.
[00:39:22.600 --> 00:39:23.600]   It's very light.
[00:39:23.600 --> 00:39:27.680]   It's very titanium with a diamond hard carbon coating.
[00:39:27.680 --> 00:39:31.240]   So light is strong and is non-allergenic.
[00:39:31.240 --> 00:39:33.520]   You don't have to worry about it.
[00:39:33.520 --> 00:39:35.080]   It fits on.
[00:39:35.080 --> 00:39:36.080]   They have a size.
[00:39:36.080 --> 00:39:37.480]   In fact, you can get the size or kit.
[00:39:37.480 --> 00:39:40.680]   In fact, might do that now so you get ready.
[00:39:40.680 --> 00:39:45.160]   It comes in eight different sizes and a variety of looks.
[00:39:45.160 --> 00:39:47.320]   I could show you a couple here.
[00:39:47.320 --> 00:39:48.800]   The one I'm wearing is $2.99.
[00:39:48.800 --> 00:39:53.960]   They also have a shiny silver.
[00:39:53.960 --> 00:39:57.200]   There's actually I'm wearing the Stealth, which is $3.99.
[00:39:57.200 --> 00:39:59.640]   You can get heritage or balance, depending.
[00:39:59.640 --> 00:40:01.360]   Those are different shapes.
[00:40:01.360 --> 00:40:03.240]   Now, I'll give you a few more stats.
[00:40:03.240 --> 00:40:04.760]   The battery lasts up to a week.
[00:40:04.760 --> 00:40:06.440]   You don't have to charge it every day.
[00:40:06.440 --> 00:40:08.760]   What I do is I put it when I'm taking a shower.
[00:40:08.760 --> 00:40:10.320]   I knew, by the way, it completely waterproof.
[00:40:10.320 --> 00:40:14.400]   I wear it in a shower, the bath, the hot tub everywhere.
[00:40:14.400 --> 00:40:16.560]   It's got a great app for iOS or Android.
[00:40:16.560 --> 00:40:20.200]   They were updating it all the time with more information.
[00:40:20.200 --> 00:40:22.480]   It will sync to your mobile device using Bluetooth LE,
[00:40:22.480 --> 00:40:26.520]   so it's very easy, very fast, transparent, simple thing to do.
[00:40:26.520 --> 00:40:29.480]   You don't have to pair it or anything like that.
[00:40:29.480 --> 00:40:31.600]   Track your sleep, make the most of your day,
[00:40:31.600 --> 00:40:34.640]   get great insights into how you're feeling,
[00:40:34.640 --> 00:40:36.440]   what your health situation is.
[00:40:36.440 --> 00:40:37.320]   I'm proud of myself.
[00:40:37.320 --> 00:40:41.640]   My resting heart rate's down to 56, which is a very good sign.
[00:40:41.640 --> 00:40:45.160]   Aura Ring, o-u-r-a-r-i-n-g.com.
[00:40:45.160 --> 00:40:47.560]   If you order it now, you'll be getting it in April.
[00:40:47.560 --> 00:40:49.440]   And if you use the offer code TWIT at checkout,
[00:40:49.440 --> 00:40:51.200]   you'll get $50 off.
[00:40:51.200 --> 00:40:54.280]   They are, you know, order now and you'll get it in April
[00:40:54.280 --> 00:40:56.120]   and do that because if you wait to April,
[00:40:56.120 --> 00:40:59.600]   it'll be order it now and get it in June or something.
[00:40:59.600 --> 00:41:02.520]   Although, heart rate tells me they're ramping up,
[00:41:02.520 --> 00:41:04.400]   they're getting ready, they know they're going to get
[00:41:04.400 --> 00:41:06.720]   a lot of sales here.
[00:41:06.720 --> 00:41:07.560]   And I think they should.
[00:41:07.560 --> 00:41:09.480]   This is the best fitness device I've used.
[00:41:09.480 --> 00:41:12.080]   Aura Ring.com.
[00:41:12.080 --> 00:41:14.200]   And if you look back, you'll notice I've been wearing this
[00:41:14.200 --> 00:41:15.280]   for at least six months.
[00:41:15.280 --> 00:41:16.600]   I just, I love this thing.
[00:41:16.600 --> 00:41:21.160]   And we thank him for their support of this week in tech.
[00:41:21.160 --> 00:41:22.920]   Michael Sargent is here.
[00:41:22.920 --> 00:41:24.440]   He writes regularly at iMore.
[00:41:24.440 --> 00:41:25.400]   You've seen his stuff there.
[00:41:25.400 --> 00:41:26.680]   You've seen him on our show.
[00:41:26.680 --> 00:41:29.600]   He does podcast too.
[00:41:29.600 --> 00:41:33.000]   And I love the office podcast.
[00:41:33.000 --> 00:41:33.960]   That is fantastic.
[00:41:33.960 --> 00:41:36.080]   Oh, Micah, you're muted.
[00:41:36.080 --> 00:41:37.240]   Oh, that was our fault.
[00:41:37.240 --> 00:41:38.160]   Go ahead.
[00:41:38.160 --> 00:41:39.000]   - Okay.
[00:41:39.000 --> 00:41:39.840]   I was like, wait, no.
[00:41:39.840 --> 00:41:41.200]   - Speak, Micah.
[00:41:41.200 --> 00:41:44.000]   - Yeah, somehow I manage the podcast
[00:41:44.000 --> 00:41:46.320]   about the office I do with Tiffany Arment.
[00:41:46.320 --> 00:41:48.520]   - Oh, that's Marco's wife.
[00:41:48.520 --> 00:41:49.360]   - Yes.
[00:41:49.360 --> 00:41:51.760]   Well, I would say Marco is her husband.
[00:41:51.760 --> 00:41:53.720]   - Much better, much better.
[00:41:53.720 --> 00:41:54.560]   - She's awesome.
[00:41:54.560 --> 00:41:55.400]   - She's awesome.
[00:41:55.400 --> 00:41:57.200]   Marco Arment is a legend, a programming legend.
[00:41:57.200 --> 00:41:58.040]   - Yes.
[00:41:58.040 --> 00:42:00.920]   - But his tumbler, he does overcast the best podcast,
[00:42:00.920 --> 00:42:03.120]   audio podcast app on iOS.
[00:42:03.120 --> 00:42:03.960]   Great guy.
[00:42:03.960 --> 00:42:05.400]   Oh, nice.
[00:42:05.400 --> 00:42:06.520]   And Tiff is great too.
[00:42:06.520 --> 00:42:08.720]   That's somehow I manage.
[00:42:08.720 --> 00:42:11.000]   Have you gotten through all the episodes yet?
[00:42:11.000 --> 00:42:13.880]   - Oh no, we are only on season three.
[00:42:14.880 --> 00:42:17.840]   Yeah, we're still working our way through,
[00:42:17.840 --> 00:42:21.520]   but we are, we're a little bit away from episode 52,
[00:42:21.520 --> 00:42:23.120]   but we're getting there.
[00:42:23.120 --> 00:42:26.320]   We've been almost doing it for a year, which is surprising.
[00:42:26.320 --> 00:42:27.160]   - Yeah.
[00:42:27.160 --> 00:42:28.280]   I learned something from it.
[00:42:28.280 --> 00:42:30.120]   I didn't realize that the early episodes
[00:42:30.120 --> 00:42:32.920]   of the office were very dark.
[00:42:32.920 --> 00:42:33.920]   - Yeah.
[00:42:33.920 --> 00:42:34.920]   Yeah, very dark.
[00:42:34.920 --> 00:42:39.440]   It wasn't until season two, when they decided,
[00:42:39.440 --> 00:42:40.760]   the producers were like,
[00:42:40.760 --> 00:42:44.800]   "We can't make this like the British version of the office,"
[00:42:44.800 --> 00:42:46.520]   which is very dark comedy.
[00:42:46.520 --> 00:42:48.800]   - 'Cause they only did six episodes of something, right?
[00:42:48.800 --> 00:42:49.960]   - Yeah, they only did six episodes.
[00:42:49.960 --> 00:42:51.080]   It didn't do well.
[00:42:51.080 --> 00:42:52.880]   And they wanted to keep it going.
[00:42:52.880 --> 00:42:54.600]   It was like one of the only shows at the time
[00:42:54.600 --> 00:42:57.560]   where they begged NBC,
[00:42:57.560 --> 00:42:59.120]   "Please let us keep making this show."
[00:42:59.120 --> 00:43:01.680]   They said they would, and then it took off.
[00:43:01.680 --> 00:43:02.800]   - One of the greatest comedies,
[00:43:02.800 --> 00:43:04.880]   if not the greatest comedy of all time, I think.
[00:43:04.880 --> 00:43:05.960]   Just great show.
[00:43:05.960 --> 00:43:06.800]   - Amen.
[00:43:06.800 --> 00:43:08.080]   - Also with this Wesley Faulkner,
[00:43:08.080 --> 00:43:10.720]   he is currently a developer relations at IBM
[00:43:10.720 --> 00:43:13.880]   Wesley 83 on the Twitter.
[00:43:13.880 --> 00:43:17.080]   That is either your high school football number,
[00:43:17.080 --> 00:43:19.840]   your birth date,
[00:43:19.840 --> 00:43:22.240]   or the number of beers you can drink
[00:43:22.240 --> 00:43:23.160]   before you fall over.
[00:43:23.160 --> 00:43:24.480]   I don't know which.
[00:43:24.480 --> 00:43:25.560]   (laughing)
[00:43:25.560 --> 00:43:28.160]   - That's a, maybe how many times
[00:43:28.160 --> 00:43:29.480]   my password's been breached.
[00:43:29.480 --> 00:43:30.760]   (laughing)
[00:43:30.760 --> 00:43:32.880]   I always, I just assume when I see a number
[00:43:32.880 --> 00:43:36.800]   in a handle that's a birth year.
[00:43:36.800 --> 00:43:37.640]   - It's not.
[00:43:37.640 --> 00:43:38.800]   - But it can't be for you.
[00:43:38.800 --> 00:43:41.360]   - Yeah, but it's, it's, it's, it's, well,
[00:43:41.360 --> 00:43:42.960]   I'll tell you next time it's.
[00:43:42.960 --> 00:43:45.280]   - You don't have to tell us what it is, that's okay.
[00:43:45.280 --> 00:43:46.120]   That's okay.
[00:43:46.120 --> 00:43:47.240]   - Yeah.
[00:43:47.240 --> 00:43:48.920]   - 82 was taken, probably.
[00:43:48.920 --> 00:43:50.400]   - Yeah. - Yeah.
[00:43:50.400 --> 00:43:51.240]   - Also here.
[00:43:51.240 --> 00:43:52.240]   - 84 is just way too much.
[00:43:52.240 --> 00:43:53.600]   (laughing)
[00:43:53.600 --> 00:43:56.360]   - Also here, and we're thrilled to have them,
[00:43:56.360 --> 00:43:58.440]   our brand new host of this week in computer hardware
[00:43:58.440 --> 00:44:00.280]   with Patrick Norton Sebastian Peek,
[00:44:00.280 --> 00:44:01.360]   editor in chief. - Thank you.
[00:44:01.360 --> 00:44:04.520]   - Of PC perspective.
[00:44:04.520 --> 00:44:07.040]   - I feel kind of like one of those,
[00:44:07.040 --> 00:44:08.600]   you know when you watch a Fox sporting event,
[00:44:08.600 --> 00:44:10.000]   like the World Series, and then they look out
[00:44:10.000 --> 00:44:11.320]   into the crowd, like Joe Bucks like,
[00:44:11.320 --> 00:44:12.920]   oh look who happens to be here.
[00:44:12.920 --> 00:44:15.120]   And they have like one of their box celebrities
[00:44:15.120 --> 00:44:16.800]   just happens to be watching the game.
[00:44:16.800 --> 00:44:17.640]   That's me.
[00:44:17.640 --> 00:44:19.360]   - Sort of.
[00:44:19.360 --> 00:44:20.360]   - Yeah.
[00:44:20.360 --> 00:44:24.000]   It's like you're, you're Mr. Carter,
[00:44:24.000 --> 00:44:26.720]   you're Gabe Kaplan out in the, at the stands.
[00:44:26.720 --> 00:44:28.480]   - Hey, it's Gabe Kaplan.
[00:44:28.480 --> 00:44:31.480]   Hey everybody, watch Mr. Carter, Sunday's at three.
[00:44:31.480 --> 00:44:33.280]   (laughing)
[00:44:33.280 --> 00:44:34.360]   - Welcome back, Carter.
[00:44:35.560 --> 00:44:40.560]   Amazon's Echo got a professional, professional voice.
[00:44:40.560 --> 00:44:42.400]   Have you heard it yet?
[00:44:42.400 --> 00:44:44.000]   - I listened to it, it sounds weird.
[00:44:44.000 --> 00:44:45.600]   - Yeah, I don't like it.
[00:44:45.600 --> 00:44:49.800]   It emphasizes some words, and it just doesn't sound right.
[00:44:49.800 --> 00:44:50.640]   - Yeah.
[00:44:50.640 --> 00:44:54.440]   Yeah, it's not, it's not, it's crazy.
[00:44:54.440 --> 00:44:55.280]   - It's crazy.
[00:44:55.280 --> 00:44:58.120]   - And you know, we're on the flash briefing.
[00:44:58.120 --> 00:45:00.480]   I encourage you if you're gonna use Amazon's flash briefing,
[00:45:00.480 --> 00:45:02.880]   which I use every morning, I love it,
[00:45:02.880 --> 00:45:04.480]   to use stuff that's prerecorded,
[00:45:04.480 --> 00:45:05.440]   not stuff that it reads.
[00:45:05.440 --> 00:45:08.080]   So like when I do tech meme, it reads headlines,
[00:45:08.080 --> 00:45:10.720]   and this is what it sounds like.
[00:45:10.720 --> 00:45:14.040]   - Royal Brides personalized wedding touches strike a chord,
[00:45:14.040 --> 00:45:16.160]   with two blockbuster British royal weddings
[00:45:16.160 --> 00:45:17.960]   this year in and in and during fashion.
[00:45:17.960 --> 00:45:18.880]   - N-no, no, no, no.
[00:45:18.880 --> 00:45:19.720]   - Royal wedding?
[00:45:19.720 --> 00:45:20.880]   - Royal wedding.
[00:45:20.880 --> 00:45:24.560]   - Yeah, so that's, that's Echo, that's her voice, right?
[00:45:24.560 --> 00:45:29.560]   Here is supposedly how much better it will sound.
[00:45:29.560 --> 00:45:33.680]   - Nick Jonas, Nicholas Jerry Jonas is an American singer,
[00:45:33.680 --> 00:45:36.840]   songwriter, actor, and record producer.
[00:45:36.840 --> 00:45:38.760]   - Oh, that's supposed to be the flab version.
[00:45:38.760 --> 00:45:40.320]   - Oh, is there one that's-
[00:45:40.320 --> 00:45:42.760]   - The one with the app fastest.
[00:45:42.760 --> 00:45:45.400]   - Oh, here's the, here's the newscaster boy, are you ready?
[00:45:45.400 --> 00:45:46.240]   - Yeah.
[00:45:46.240 --> 00:45:47.240]   - Ready, that's the flat one.
[00:45:47.240 --> 00:45:48.120]   Here's the newscast.
[00:45:48.120 --> 00:45:51.960]   - Royal Brides personalized wedding touches strike a chord,
[00:45:51.960 --> 00:45:54.520]   with two blockbuster British royal weddings this year,
[00:45:54.520 --> 00:45:55.520]   and in and during fashionation,
[00:45:55.520 --> 00:45:58.120]   - I will talk like this on the show from now on,
[00:45:58.120 --> 00:46:01.960]   'cause I think people are used to how Amazon's Echo talks.
[00:46:01.960 --> 00:46:04.320]   While Royal wedding fashion will have an influence on-
[00:46:04.320 --> 00:46:07.640]   - Yeah, I don't think that's how newscasters talk either.
[00:46:07.640 --> 00:46:08.480]   - No.
[00:46:08.480 --> 00:46:09.720]   - Yeah, it's weird.
[00:46:09.720 --> 00:46:11.800]   - Is Google just own this space?
[00:46:11.800 --> 00:46:14.480]   I mean, Google duplex really sounds like a person.
[00:46:14.480 --> 00:46:16.560]   - I've been having so much,
[00:46:16.560 --> 00:46:20.240]   I got my Google Home out recently,
[00:46:20.240 --> 00:46:23.480]   because Google did a very, very, very good job.
[00:46:23.480 --> 00:46:27.160]   I like one of these recent tests for how intelligent
[00:46:27.160 --> 00:46:28.880]   each of the virtual assistants is.
[00:46:28.880 --> 00:46:31.400]   And so I thought, okay, I'm gonna plot my Google Home again,
[00:46:31.400 --> 00:46:33.760]   because the Google Assistant had done such a good job,
[00:46:33.760 --> 00:46:35.120]   and I wanted to just play around with it.
[00:46:35.120 --> 00:46:39.440]   And I forgot that they had added like six different voices
[00:46:39.440 --> 00:46:41.960]   that are named just colors, different colors,
[00:46:41.960 --> 00:46:44.120]   and each of them sounds incredible.
[00:46:44.120 --> 00:46:47.120]   - Yeah, they kinda own this, don't they?
[00:46:47.120 --> 00:46:48.920]   - Yeah, they're way ahead,
[00:46:48.920 --> 00:46:50.880]   especially since they've had Google Voice,
[00:46:50.880 --> 00:46:52.880]   which was what, Grand Central?
[00:46:52.880 --> 00:46:55.920]   - Yeah, they've been listening to, they have so.
[00:46:55.920 --> 00:46:56.800]   - They've been listening to,
[00:46:56.800 --> 00:46:58.360]   they know what we sound like.
[00:46:58.360 --> 00:47:00.260]   I want the Wesley Faulkner voice.
[00:47:01.100 --> 00:47:02.140]   (laughs)
[00:47:02.140 --> 00:47:04.420]   - Didn't they demo at Google I/O?
[00:47:04.420 --> 00:47:06.380]   - John Legend?
[00:47:06.380 --> 00:47:08.260]   - Yeah, that's right, it was John Legend's voice.
[00:47:08.260 --> 00:47:09.620]   - Yeah, that would be great.
[00:47:09.620 --> 00:47:11.860]   - I should prefer Matthew McConaughey.
[00:47:11.860 --> 00:47:12.700]   - All right, all right.
[00:47:12.700 --> 00:47:13.540]   - Waking up, all right.
[00:47:13.540 --> 00:47:14.900]   - Wouldn't they give you that right?
[00:47:14.900 --> 00:47:17.540]   - Yeah, I'd be like, oh no, not again.
[00:47:17.540 --> 00:47:20.220]   - Tom, Tom, remember Tom, Tom used to have celebrity voices
[00:47:20.220 --> 00:47:24.260]   in its GPS when you, and I tried Dennis Hopper briefly.
[00:47:24.260 --> 00:47:25.340]   (laughs)
[00:47:25.340 --> 00:47:26.340]   - And they had glattoes,
[00:47:26.340 --> 00:47:27.460]   which would tell you the wrong direction.
[00:47:27.460 --> 00:47:28.460]   - Glattoes would give you the light,
[00:47:28.460 --> 00:47:31.420]   and say turn right when he was supposed to turn left.
[00:47:31.420 --> 00:47:34.140]   Dennis Hopper was so stoned out, it was just,
[00:47:34.140 --> 00:47:36.700]   oh man, here we are.
[00:47:36.700 --> 00:47:39.220]   Why would anybody wanna go here?
[00:47:39.220 --> 00:47:44.220]   It was just weird, but I kind of enjoyed that, I don't know.
[00:47:44.220 --> 00:47:48.460]   All right, anyway, Google seems to be winning in that regard.
[00:47:48.460 --> 00:47:52.340]   - Are you like that it can whisper though, the echo?
[00:47:52.340 --> 00:47:53.180]   - Whisper.
[00:47:53.180 --> 00:47:56.540]   - Yeah, I think if you whisper to it, then it will whisper back.
[00:47:56.540 --> 00:47:59.620]   - Yeah, I got a nice first time you whisper it says,
[00:47:59.620 --> 00:48:02.820]   - I think you're talking in whisper mode, are you?
[00:48:02.820 --> 00:48:03.820]   - Yes.
[00:48:03.820 --> 00:48:04.900]   - Okay.
[00:48:04.900 --> 00:48:05.740]   - Oh whisper.
[00:48:05.740 --> 00:48:10.740]   - Google announced that they're buying
[00:48:10.740 --> 00:48:14.340]   fossil smartwatch tech.
[00:48:14.340 --> 00:48:17.860]   This almost felt like an admission of failure to me.
[00:48:17.860 --> 00:48:19.900]   - Sounds like Motorola.
[00:48:19.900 --> 00:48:22.460]   - Yeah, or HTC, that's what they've been doing, isn't it?
[00:48:22.460 --> 00:48:25.020]   They've been, so they did kind of an HTC with fossil.
[00:48:25.020 --> 00:48:26.820]   Fossil still is gonna make smart watches,
[00:48:26.820 --> 00:48:28.620]   they still have a hundred people working there,
[00:48:28.620 --> 00:48:33.220]   but Google spent $40 million to get smartwatch technology
[00:48:33.220 --> 00:48:35.380]   currently under development
[00:48:35.380 --> 00:48:40.100]   and transfer a number of fossil employees to Google,
[00:48:40.100 --> 00:48:42.380]   number unknown.
[00:48:42.380 --> 00:48:44.220]   Fossil said, we're still gonna do smartwatches,
[00:48:44.220 --> 00:48:45.700]   we still have a big team working on it,
[00:48:45.700 --> 00:48:47.900]   but what is Fossil doing that Android is not,
[00:48:47.900 --> 00:48:49.860]   and Redware is not doing?
[00:48:49.860 --> 00:48:52.140]   - They just wanna make sure someone keeps making those watches.
[00:48:52.140 --> 00:48:53.300]   - Oh maybe that's it.
[00:48:53.300 --> 00:48:55.340]   - Here, here, it would be a shame
[00:48:55.340 --> 00:48:57.340]   if you were to stop making watches.
[00:48:57.340 --> 00:49:00.620]   - You need to work on making, like revving the processors
[00:49:00.620 --> 00:49:02.540]   'cause that's what's holding them back.
[00:49:02.540 --> 00:49:03.380]   - That's right.
[00:49:03.380 --> 00:49:06.860]   - They're underpowered and they're taking too much power.
[00:49:06.860 --> 00:49:11.300]   And doesn't seem like ARM is really caring all that much.
[00:49:11.300 --> 00:49:12.900]   You're like, "Ah, there's another processor
[00:49:12.900 --> 00:49:13.740]   "that's a couple years old."
[00:49:13.740 --> 00:49:14.580]   - They're ancient.
[00:49:14.580 --> 00:49:15.900]   - Yeah.
[00:49:15.900 --> 00:49:19.140]   - So and Apple's just leaps and bounds, you know,
[00:49:19.140 --> 00:49:21.380]   head 'cause they're designing their own silicon,
[00:49:21.380 --> 00:49:23.420]   they're doing a great job with it.
[00:49:23.420 --> 00:49:26.660]   I would like to have a great Android Wear.
[00:49:26.660 --> 00:49:29.700]   Anyway, this would bolster a long-standing rumor
[00:49:29.700 --> 00:49:33.500]   that Google might get into the Pixel Watch.
[00:49:33.500 --> 00:49:34.340]   - Oh yeah.
[00:49:34.340 --> 00:49:35.180]   - Oh yeah.
[00:49:35.180 --> 00:49:36.260]   - Will it take photos?
[00:49:36.260 --> 00:49:39.980]   - Why do you want your watch to take photos?
[00:49:39.980 --> 00:49:41.860]   - I don't wanna take photos of just no pixels.
[00:49:41.860 --> 00:49:45.340]   Pixel is so well known for being a good camera phone.
[00:49:45.340 --> 00:49:48.460]   I thought if you're gonna tag that brand onto a smartwatch,
[00:49:48.460 --> 00:49:49.860]   will this be the first smartwatch
[00:49:49.860 --> 00:49:52.540]   that you can hold up and take a photo
[00:49:52.540 --> 00:49:54.700]   with this tiny little lens on the end of it?
[00:49:54.700 --> 00:49:56.340]   - I had a watch like that.
[00:49:56.340 --> 00:49:59.300]   It was a thick band and had a little lens right here,
[00:49:59.300 --> 00:50:01.900]   but it's very hard to get a decent picture.
[00:50:01.900 --> 00:50:03.780]   - Holding it on a wrist like that.
[00:50:03.780 --> 00:50:05.500]   It's not easy.
[00:50:05.500 --> 00:50:06.340]   - It's gotta be on the top.
[00:50:06.340 --> 00:50:07.180]   - You're like, "Are you flexing?
[00:50:07.180 --> 00:50:08.020]   "What's the deal?"
[00:50:08.020 --> 00:50:09.780]   - Nothing.
[00:50:09.780 --> 00:50:12.260]   If my wearable doesn't let me take selfies.
[00:50:12.260 --> 00:50:13.100]   - I'm out.
[00:50:13.100 --> 00:50:14.220]   (laughing)
[00:50:14.220 --> 00:50:15.260]   - I guess selfies, yeah.
[00:50:15.260 --> 00:50:16.300]   That makes more sense.
[00:50:16.300 --> 00:50:17.580]   - Yeah.
[00:50:17.580 --> 00:50:18.420]   - What time is it?
[00:50:18.420 --> 00:50:19.820]   - Just like, "Am I looking at my watch?
[00:50:19.820 --> 00:50:21.220]   "Am I taking a picture right now?"
[00:50:21.220 --> 00:50:22.540]   - Oh, you don't know, do ya?
[00:50:22.540 --> 00:50:23.380]   - Yeah.
[00:50:23.380 --> 00:50:24.220]   - You wouldn't know.
[00:50:24.220 --> 00:50:26.540]   - I already around people without smartwatch
[00:50:26.540 --> 00:50:29.260]   that don't use smartwatches or aren't used to them,
[00:50:29.260 --> 00:50:30.100]   I have to go,
[00:50:30.100 --> 00:50:31.580]   I promise I'm not looking at my watch
[00:50:31.580 --> 00:50:34.620]   because I wanna go away from you right now.
[00:50:34.620 --> 00:50:36.580]   'Cause I've had too many people.
[00:50:36.580 --> 00:50:37.500]   Are you in a hurry?
[00:50:37.500 --> 00:50:39.660]   Is this, are you busy right now?
[00:50:39.660 --> 00:50:40.580]   No, no, no, I promise.
[00:50:40.580 --> 00:50:42.500]   It's just my watch tapped me.
[00:50:42.500 --> 00:50:46.140]   - This was initially a selling point in the Apple watches.
[00:50:46.140 --> 00:50:47.220]   Oh, you don't have to look at your phone.
[00:50:47.220 --> 00:50:48.340]   You just look at your watch
[00:50:48.340 --> 00:50:50.420]   and then people think you're really bored.
[00:50:50.420 --> 00:50:52.100]   - Yeah, I like you're being rude.
[00:50:52.100 --> 00:50:52.940]   - It's worse.
[00:50:52.940 --> 00:50:55.180]   - Marginally less rude than looking at your phone,
[00:50:55.180 --> 00:50:56.980]   but only a little bit.
[00:50:56.980 --> 00:51:00.020]   It's a surreptitious, yeah, so you have to kinda like,
[00:51:00.020 --> 00:51:03.060]   surreptitiously look, what are you looking at?
[00:51:03.060 --> 00:51:05.740]   - My waist.
[00:51:05.740 --> 00:51:07.820]   - My waist, I'm looking at my belt.
[00:51:07.820 --> 00:51:10.500]   - Yeah.
[00:51:10.500 --> 00:51:13.260]   - Do you think it's gonna last smartwatches?
[00:51:13.260 --> 00:51:14.780]   I mean,
[00:51:14.780 --> 00:51:16.300]   - I don't know, do you,
[00:51:16.300 --> 00:51:17.740]   is it just a fad like VR?
[00:51:17.740 --> 00:51:19.980]   - Do you not wear a smartwatch, Wesley?
[00:51:19.980 --> 00:51:23.660]   - I do, I have this cheap one.
[00:51:23.660 --> 00:51:25.820]   - Oh, no, that's the, which one is that?
[00:51:25.820 --> 00:51:27.020]   Is that the Pebble?
[00:51:27.020 --> 00:51:30.580]   - The, it's the Amaze Fit.
[00:51:30.580 --> 00:51:32.380]   - You have an off brand smartwatch.
[00:51:32.380 --> 00:51:33.700]   No, what if you don't like them?
[00:51:33.700 --> 00:51:35.300]   - It's 60 bucks.
[00:51:35.300 --> 00:51:37.220]   I got it at a gas station.
[00:51:37.220 --> 00:51:38.780]   It was 60 bucks.
[00:51:38.780 --> 00:51:41.060]   - Yeah, it's because there,
[00:51:41.060 --> 00:51:42.780]   I do have a Pixel phone.
[00:51:42.780 --> 00:51:47.780]   There's nothing that, this battery lasts 30 days is why I wear it.
[00:51:47.780 --> 00:51:48.620]   - Oh, yeah.
[00:51:48.620 --> 00:51:52.780]   - And so I do my sleep tracking and all that stuff on it.
[00:51:52.780 --> 00:51:56.220]   But it's, it gives like basic notifications.
[00:51:56.220 --> 00:51:57.420]   I did have a Pebble.
[00:51:57.420 --> 00:52:00.460]   I was one of the Kickstarter backers of Pebble.
[00:52:00.460 --> 00:52:03.860]   And there's nothing like it that has the functionality.
[00:52:03.860 --> 00:52:05.820]   That, that thing was amazing.
[00:52:05.820 --> 00:52:09.260]   If they made an updated Pebble, I would buy it tomorrow.
[00:52:09.260 --> 00:52:10.100]   - Yeah.
[00:52:10.100 --> 00:52:11.500]   - But unfortunately they folded.
[00:52:11.500 --> 00:52:12.340]   - Yeah.
[00:52:12.340 --> 00:52:13.420]   - I have mine in my drawer next to me.
[00:52:13.420 --> 00:52:14.860]   I was a backer of that too.
[00:52:14.860 --> 00:52:15.780]   - Me too, I've been into it.
[00:52:15.780 --> 00:52:16.620]   - Yeah.
[00:52:16.620 --> 00:52:18.540]   Was it, you could reply to text message.
[00:52:18.540 --> 00:52:21.100]   You could just, you could, you can dismiss calls.
[00:52:21.100 --> 00:52:22.900]   You can send a voicemail.
[00:52:22.900 --> 00:52:24.460]   You could do it so much with that.
[00:52:24.460 --> 00:52:27.380]   And it also would last like a week on E.
[00:52:27.380 --> 00:52:28.380]   Sorry.
[00:52:28.380 --> 00:52:29.220]   Nostalgia.
[00:52:29.220 --> 00:52:32.180]   - You need to, you need to enter Apple's
[00:52:32.180 --> 00:52:35.020]   soothing wall to carton, Wesley.
[00:52:35.020 --> 00:52:37.020]   Join us one of us.
[00:52:37.020 --> 00:52:37.860]   (laughing)
[00:52:37.860 --> 00:52:38.940]   One of us.
[00:52:39.780 --> 00:52:42.060]   - 'Cause the Apple Watch is really the only wearable wrist
[00:52:42.060 --> 00:52:44.020]   wearable anyway that's worth it.
[00:52:44.020 --> 00:52:46.140]   - I love it for the heart stuff though.
[00:52:46.140 --> 00:52:48.780]   I mean, and that's sort of what,
[00:52:48.780 --> 00:52:51.500]   'cause I was on a, what, Series 3,
[00:52:51.500 --> 00:52:54.020]   and was gonna be finding content with that
[00:52:54.020 --> 00:52:55.780]   until I found out about the stuff that was available
[00:52:55.780 --> 00:53:00.140]   on the Series 4, because I did have some heart issues,
[00:53:00.140 --> 00:53:01.500]   I guess that have been last year.
[00:53:01.500 --> 00:53:02.940]   - Oh.
[00:53:02.940 --> 00:53:04.740]   - Yeah, I ended up in the ER a couple times
[00:53:04.740 --> 00:53:05.560]   with some heart stuff.
[00:53:05.560 --> 00:53:08.980]   And so when I found out that Apple is going to be making
[00:53:08.980 --> 00:53:10.420]   a watch that had ECG, I was like,
[00:53:10.420 --> 00:53:12.020]   I just upgraded to the Series 3,
[00:53:12.020 --> 00:53:13.860]   but this one, I wanna get this one,
[00:53:13.860 --> 00:53:16.300]   and I can use that and my doctor can see that
[00:53:16.300 --> 00:53:17.740]   and make sure I don't have, you know,
[00:53:17.740 --> 00:53:18.580]   a Rizmea's going on for one.
[00:53:18.580 --> 00:53:20.180]   - You can't get the Alive Core 4,
[00:53:20.180 --> 00:53:25.100]   if you have a Rizmea, or a arterial fibrillation,
[00:53:25.100 --> 00:53:27.060]   the Alive Core's 99 bucks, it will work
[00:53:27.060 --> 00:53:28.780]   with any smartphone.
[00:53:28.780 --> 00:53:30.100]   That was-- - The Bluetooth connected.
[00:53:30.100 --> 00:53:33.100]   - Yeah, that was Vic Gundotra left,
[00:53:33.100 --> 00:53:37.740]   after the debacle that was Google+, left Google CEO,
[00:53:37.740 --> 00:53:39.780]   he's just recently stepped down as CEO,
[00:53:39.780 --> 00:53:42.940]   he's gonna go on the board, chairman of the board, I guess.
[00:53:42.940 --> 00:53:47.860]   But he said, thanks to Apple and the ECG watch,
[00:53:47.860 --> 00:53:49.060]   our sales went through the roof
[00:53:49.060 --> 00:53:51.460]   because people found out that you could do that.
[00:53:51.460 --> 00:53:52.940]   And Alive Core's only 99 bucks,
[00:53:52.940 --> 00:53:55.260]   you don't have to have a special watch.
[00:53:55.260 --> 00:53:56.500]   - Really good hardware too,
[00:53:56.500 --> 00:54:00.740]   like it's a high quality product that is helpful for,
[00:54:00.740 --> 00:54:03.300]   again, for folks who otherwise you have to wear
[00:54:03.300 --> 00:54:06.740]   one of those really ridiculous leads,
[00:54:06.740 --> 00:54:10.500]   like multi-lead thing that's called a holster.
[00:54:10.500 --> 00:54:12.700]   And I don't know, a halter monitor, that's it.
[00:54:12.700 --> 00:54:14.860]   And it's just this big bulky thing
[00:54:14.860 --> 00:54:16.660]   that you gotta make sure the batteries are in it,
[00:54:16.660 --> 00:54:18.580]   and it's much different from being able
[00:54:18.580 --> 00:54:21.500]   to have this tiny little wafer you can touch your fingers to
[00:54:21.500 --> 00:54:23.500]   and make sure your AOK heart was.
[00:54:23.500 --> 00:54:24.980]   - Are you OK now?
[00:54:24.980 --> 00:54:26.860]   - Yes, yes, yes.
[00:54:26.860 --> 00:54:28.860]   Thank goodness, 'cause they were like,
[00:54:28.860 --> 00:54:32.860]   yeah, we might have to go in and do no-deblation.
[00:54:32.860 --> 00:54:34.300]   So it's gonna have to have heart surgery,
[00:54:34.300 --> 00:54:36.700]   and then they found out that it was,
[00:54:36.700 --> 00:54:39.180]   the heart stuff was caused by something totally unrelated,
[00:54:39.180 --> 00:54:41.060]   so it wasn't like bad stuff.
[00:54:41.060 --> 00:54:43.380]   My heart anatomy was AOK, so.
[00:54:43.380 --> 00:54:45.060]   - Did you have a broken heart?
[00:54:45.060 --> 00:54:46.500]   - I had a broken heart.
[00:54:46.500 --> 00:54:47.460]   (laughs)
[00:54:47.460 --> 00:54:49.460]   It was food allergies actually, that it was-
[00:54:49.460 --> 00:54:51.460]   - Oh, wow. - You're kidding.
[00:54:51.460 --> 00:54:52.700]   - Wow. - Wow.
[00:54:52.700 --> 00:54:54.740]   - It was a whole deal.
[00:54:54.740 --> 00:54:56.620]   - I wish I were allergic to food.
[00:54:56.620 --> 00:54:58.860]   (both laugh)
[00:54:58.860 --> 00:55:00.460]   - Bear in mind, says she's allergic to pizza
[00:55:00.460 --> 00:55:01.460]   and makes her butt swell up.
[00:55:01.460 --> 00:55:02.780]   - Oh, God, yes, right.
[00:55:02.780 --> 00:55:04.820]   That's exactly my problem.
[00:55:04.820 --> 00:55:06.980]   I swell up whenever I eat.
[00:55:06.980 --> 00:55:10.660]   So to your point earlier, Wesley,
[00:55:10.660 --> 00:55:12.740]   you're talking about Facebook users
[00:55:12.740 --> 00:55:16.220]   and generally whether users even know
[00:55:16.220 --> 00:55:17.460]   that data's being collected.
[00:55:17.460 --> 00:55:20.300]   Pew, the Research Center, they do good stuff.
[00:55:20.300 --> 00:55:23.780]   Recently did a survey of Facebook users,
[00:55:23.780 --> 00:55:25.300]   this is the most depressing.
[00:55:25.300 --> 00:55:27.740]   They found three quarters of Facebook users,
[00:55:27.740 --> 00:55:32.100]   74%, didn't even know that Facebook maintains
[00:55:32.100 --> 00:55:34.820]   a list of their interests and traits
[00:55:34.820 --> 00:55:37.020]   to target them with ads.
[00:55:37.020 --> 00:55:41.060]   They didn't even know that, three quarters.
[00:55:41.060 --> 00:55:42.940]   And then researchers said,
[00:55:42.940 --> 00:55:46.620]   well, go look at your Facebook ad preferences page.
[00:55:46.620 --> 00:55:51.460]   And then 51% said, well, I'm uncomfortable with that.
[00:55:51.460 --> 00:55:54.260]   And a quarter said, you know what?
[00:55:54.260 --> 00:55:56.740]   The ad preferences page is wrong about me.
[00:55:56.740 --> 00:55:58.140]   Well, that's not a surprise.
[00:55:58.140 --> 00:56:01.300]   88% of the people they polled,
[00:56:01.300 --> 00:56:05.820]   and they polled 963 Facebook users aged 18 and older,
[00:56:05.820 --> 00:56:11.740]   88% had at least something on that ad preferences page
[00:56:11.740 --> 00:56:13.140]   that had been generated for them.
[00:56:13.140 --> 00:56:13.980]   But this is--
[00:56:13.980 --> 00:56:17.100]   - I would love to see this study paired
[00:56:17.100 --> 00:56:21.060]   with the other one saying how much will you pay
[00:56:21.060 --> 00:56:23.340]   to get dumped your Facebook
[00:56:23.340 --> 00:56:25.060]   and see if that number fluctuates,
[00:56:25.060 --> 00:56:27.220]   like if it goes up or down after they--
[00:56:27.220 --> 00:56:29.340]   - Now that you know they're spying on you how much.
[00:56:29.340 --> 00:56:31.180]   - Guys, it wasn't even $1,000.
[00:56:31.180 --> 00:56:34.060]   People would, you'd have to pay me $1,000
[00:56:34.060 --> 00:56:35.540]   to give up my Facebook.
[00:56:35.540 --> 00:56:37.580]   - They wouldn't be able to stay away.
[00:56:37.580 --> 00:56:39.900]   Maybe they'd take the $1,000,
[00:56:39.900 --> 00:56:42.540]   but they'd be getting back in on the sly.
[00:56:42.540 --> 00:56:43.380]   (laughing)
[00:56:43.380 --> 00:56:44.380]   - Addiction.
[00:56:44.380 --> 00:56:47.220]   - I've been getting in on the sly, I admit it.
[00:56:47.220 --> 00:56:49.060]   - They'd make another, like a ghost account,
[00:56:49.060 --> 00:56:51.460]   and then they go in and they'd spy on people's--
[00:56:51.460 --> 00:56:53.420]   - No, I deactivated my Facebook account,
[00:56:53.420 --> 00:56:54.820]   and it feels really good.
[00:56:54.820 --> 00:56:56.060]   I've been-- - I deleted it.
[00:56:56.060 --> 00:56:58.500]   I, they've give you an ability to do that,
[00:56:58.500 --> 00:57:01.340]   and I have to wait 30, 31 days or something like that,
[00:57:01.340 --> 00:57:04.420]   and mine was just deleted full on--
[00:57:04.420 --> 00:57:05.540]   - Guys.
[00:57:05.540 --> 00:57:06.700]   - A couple days ago.
[00:57:06.700 --> 00:57:07.980]   - See, I've been debating that.
[00:57:07.980 --> 00:57:10.700]   - It's deactivated, but then how am I gonna use
[00:57:10.700 --> 00:57:12.040]   my Facebook portals?
[00:57:12.040 --> 00:57:17.260]   - Oh no, you just make a dummy account, I guess.
[00:57:17.260 --> 00:57:20.180]   - No, I debated, I don't want somebody to steal my name,
[00:57:20.180 --> 00:57:23.220]   but I guess really, if you, if I'm very public
[00:57:23.220 --> 00:57:26.060]   about not having a Facebook account, that's that, right?
[00:57:26.060 --> 00:57:26.900]   - Yeah.
[00:57:26.900 --> 00:57:29.140]   - I'm gonna delete my Instagram account.
[00:57:29.140 --> 00:57:31.580]   - Oh, see, I kept that, and that makes me a bad person.
[00:57:31.580 --> 00:57:32.420]   - No.
[00:57:32.420 --> 00:57:33.260]   - 'Cause I got rid of Facebook,
[00:57:33.260 --> 00:57:34.420]   but that people are like, you know,
[00:57:34.420 --> 00:57:36.660]   that's the point, you're not really off Facebook.
[00:57:36.660 --> 00:57:38.540]   - Yeah, that's okay, I'm gonna just use
[00:57:38.540 --> 00:57:39.860]   WhatsApp from now on.
[00:57:39.860 --> 00:57:44.740]   - Oh, question about the portal while you're talking about it.
[00:57:44.740 --> 00:57:45.580]   - Yeah, you want--
[00:57:45.580 --> 00:57:46.900]   - So I know that you can only have what,
[00:57:46.900 --> 00:57:49.900]   5,000 Facebook friends, that's the top cap.
[00:57:49.900 --> 00:57:50.860]   - That's right.
[00:57:50.860 --> 00:57:53.180]   - So if you have a portal and you wanna add someone,
[00:57:53.180 --> 00:57:55.580]   you're at your 5,000 number, can you?
[00:57:55.580 --> 00:57:58.100]   Do you really want 5,000 people?
[00:57:58.100 --> 00:58:00.220]   - Just, I mean, your portal directory?
[00:58:00.220 --> 00:58:01.660]   - Let's say you wanted to use it for,
[00:58:01.660 --> 00:58:03.700]   let's say, this show or whatever.
[00:58:03.700 --> 00:58:04.820]   - So the way portal works--
[00:58:04.820 --> 00:58:06.020]   - It's like, get one of your call in or something.
[00:58:06.020 --> 00:58:08.900]   - The way portal works is really tied to Messenger.
[00:58:08.900 --> 00:58:10.780]   So I don't think there's any limit to the number of people
[00:58:10.780 --> 00:58:13.540]   you can use Messenger to contact.
[00:58:13.540 --> 00:58:14.380]   - Oh, okay.
[00:58:14.380 --> 00:58:17.260]   - So as long as somebody has a Facebook Messenger account,
[00:58:17.260 --> 00:58:19.020]   and who doesn't?
[00:58:19.020 --> 00:58:22.260]   - By the way, you still have a Facebook Messenger account,
[00:58:22.260 --> 00:58:23.940]   Micah, 'cause you can delete your Facebook,
[00:58:23.940 --> 00:58:26.940]   but it does not delete your Messenger account.
[00:58:26.940 --> 00:58:27.980]   - Did you know that? - Okay.
[00:58:27.980 --> 00:58:28.820]   - Yeah. - Okay.
[00:58:28.820 --> 00:58:31.020]   - See, people don't even know that.
[00:58:31.020 --> 00:58:33.740]   - How do I, where do you go to delete that?
[00:58:33.740 --> 00:58:35.300]   - I don't know.
[00:58:35.300 --> 00:58:36.140]   - Now how much would you--
[00:58:36.140 --> 00:58:37.140]   - I got a write an article done.
[00:58:37.140 --> 00:58:37.980]   Micah is how to delete this.
[00:58:37.980 --> 00:58:41.700]   - I stupidly bought two portals, the big ones.
[00:58:41.700 --> 00:58:44.500]   Not only did I get portals, but I got the 17 inch ones.
[00:58:44.500 --> 00:58:46.500]   They're great, they're really cool,
[00:58:46.500 --> 00:58:48.780]   but you have to have a Facebook Messenger account to use it.
[00:58:48.780 --> 00:58:49.980]   I just don't wanna do it.
[00:58:51.580 --> 00:58:55.060]   - Now how is that different from a good screen in a webcam?
[00:58:55.060 --> 00:58:57.420]   - It's kinda purpose built.
[00:58:57.420 --> 00:58:58.420]   - Okay.
[00:58:58.420 --> 00:59:01.780]   - Like I would like, I was gonna give it to my mom.
[00:59:01.780 --> 00:59:03.100]   So it makes it very easy for her.
[00:59:03.100 --> 00:59:05.420]   There's a big button that says, "Talk to Leia,"
[00:59:05.420 --> 00:59:08.380]   or I can call her and I'll peer on her screen.
[00:59:08.380 --> 00:59:09.780]   It's just easy.
[00:59:09.780 --> 00:59:10.740]   - Okay.
[00:59:10.740 --> 00:59:12.020]   - That's the main reason.
[00:59:12.020 --> 00:59:14.020]   I tried to return it, they wouldn't let me.
[00:59:14.020 --> 00:59:16.820]   - They wouldn't let you.
[00:59:16.820 --> 00:59:18.980]   - They said there's 30 day return policy,
[00:59:18.980 --> 00:59:20.580]   so I thought, "Well, I'll buy this, I'll review it,
[00:59:20.580 --> 00:59:21.420]   "and I'll give it back."
[00:59:21.420 --> 00:59:23.340]   And I said, "I'm gonna know that, like in two weeks,
[00:59:23.340 --> 00:59:25.180]   "saying I wanna send it back."
[00:59:25.180 --> 00:59:26.580]   They said, "Oh, well, you can return it,
[00:59:26.580 --> 00:59:28.660]   "but first you have to tell us why."
[00:59:28.660 --> 00:59:30.500]   And we need to copy the invoice.
[00:59:30.500 --> 00:59:32.940]   So I said, "I don't want it 'cause I don't want you
[00:59:32.940 --> 00:59:35.500]   "spying on me and here's my invoice."
[00:59:35.500 --> 00:59:37.420]   And then I never heard from them again.
[00:59:37.420 --> 00:59:38.260]   - Wow.
[00:59:38.260 --> 00:59:41.980]   So basically that's, I think legally,
[00:59:41.980 --> 00:59:44.180]   that's them saying they are spying on you, right?
[00:59:44.180 --> 00:59:48.860]   - Yeah, it's like, "Oh, well, never pay no attention."
[00:59:48.860 --> 00:59:51.060]   - Yeah, just forget about this, please.
[00:59:51.060 --> 00:59:52.620]   - The Facebook portal went, "Uh-uh."
[00:59:52.620 --> 00:59:56.060]   - You're stuck with me, Leo.
[00:59:56.060 --> 01:00:00.460]   - Now, Jeff Jarvis got very upset
[01:00:00.460 --> 01:00:02.060]   in a way that one would not expect
[01:00:02.060 --> 01:00:04.540]   over this article from Wired Magazine, Kato Kneel,
[01:00:04.540 --> 01:00:06.700]   and it's not, I should point out it's an opinion piece,
[01:00:06.700 --> 01:00:07.940]   not an article.
[01:00:07.940 --> 01:00:12.860]   Facebook's 10 year challenge is just a harmless meme, right?
[01:00:12.860 --> 01:00:14.900]   She posited, "Well, we know, no,
[01:00:14.900 --> 01:00:17.900]   "but what if Facebook was just trying to collect data
[01:00:17.900 --> 01:00:21.300]   "about how people age over 10 years?"
[01:00:21.300 --> 01:00:25.900]   And it's more of a what if piece it made,
[01:00:25.900 --> 01:00:26.980]   Jeff went ballistic.
[01:00:26.980 --> 01:00:30.500]   He said, "This is exactly what's wrong with journalism today.
[01:00:30.500 --> 01:00:33.180]   "This is not, you know, this is gonna,
[01:00:33.180 --> 01:00:35.660]   "people are gonna, this is gonna bring government regulation
[01:00:35.660 --> 01:00:37.300]   "down on their heads.
[01:00:37.300 --> 01:00:39.180]   "This is inappropriate."
[01:00:39.180 --> 01:00:41.860]   - I don't know, I don't think it's that far-fetched.
[01:00:41.860 --> 01:00:43.500]   Maybe they are collecting that kind of data.
[01:00:43.500 --> 01:00:45.060]   Of course they are.
[01:00:45.060 --> 01:00:46.500]   - I'm of two minds of this.
[01:00:46.500 --> 01:00:48.060]   - Okay.
[01:00:48.060 --> 01:00:51.900]   - First of all, from the technical point of view,
[01:00:51.900 --> 01:00:55.620]   there's a lot easier way of doing this.
[01:00:55.620 --> 01:00:59.740]   So I doubt that this is something that Facebook is doing.
[01:00:59.740 --> 01:01:00.820]   - Facebook, by the way, says,
[01:01:00.820 --> 01:01:03.180]   "We have nothing, this is a user-generated meme.
[01:01:03.180 --> 01:01:04.020]   "We know, I made it do it."
[01:01:04.020 --> 01:01:05.180]   - Yeah, this is not a method they would use
[01:01:05.180 --> 01:01:06.460]   to get this information.
[01:01:06.460 --> 01:01:11.780]   On the other hand, in terms of going back to the article,
[01:01:11.780 --> 01:01:13.900]   we just talked about how many people know
[01:01:15.140 --> 01:01:16.900]   what Facebook is collecting on you.
[01:01:16.900 --> 01:01:21.900]   I think this is something that gets into the public space easier.
[01:01:21.900 --> 01:01:26.460]   Then the audience is not the technical audience,
[01:01:26.460 --> 01:01:28.380]   the audience is the people who don't know
[01:01:28.380 --> 01:01:30.380]   that this stuff is even possible,
[01:01:30.380 --> 01:01:32.020]   that they were like, "Huh."
[01:01:32.020 --> 01:01:36.220]   And maybe it'll add just enough skepticism for them to,
[01:01:36.220 --> 01:01:39.980]   say, "Oh, what's my, whatever, the porn-styrene name,
[01:01:39.980 --> 01:01:41.220]   "the city you grew up on,
[01:01:41.220 --> 01:01:42.580]   "I mean, the street you grew up on,
[01:01:42.580 --> 01:01:44.660]   "and then your last name, that's your porn-star name,
[01:01:44.660 --> 01:01:45.900]   "or whatever, I brought that one."
[01:01:45.900 --> 01:01:48.100]   I brought that one up to Jeff,
[01:01:48.100 --> 01:01:50.460]   that Cambridge Analytica did pretty good
[01:01:50.460 --> 01:01:51.860]   using those Facebook quizzes
[01:01:51.860 --> 01:01:54.300]   to gather information about people.
[01:01:54.300 --> 01:01:56.420]   - And so there's just, maybe people like,
[01:01:56.420 --> 01:01:58.540]   "I shouldn't submit this information, I shouldn't do this."
[01:01:58.540 --> 01:02:02.340]   And I want people to pause just to lamin' people,
[01:02:02.340 --> 01:02:03.660]   and just so they can understand,
[01:02:03.660 --> 01:02:05.860]   "I shouldn't volunteer this information,"
[01:02:05.860 --> 01:02:09.860]   or use it ironically, which is great.
[01:02:09.860 --> 01:02:13.460]   But don't, so from a technical standpoint,
[01:02:13.460 --> 01:02:16.140]   there's a lot easier way of doing this,
[01:02:16.140 --> 01:02:18.740]   especially understanding how machine learning works.
[01:02:18.740 --> 01:02:23.980]   But, and it's also not a dirty dataset.
[01:02:23.980 --> 01:02:26.220]   There's ways of cleaning it to make sure
[01:02:26.220 --> 01:02:29.660]   that you get good data in order to train your model.
[01:02:29.660 --> 01:02:31.980]   But in terms of age progression,
[01:02:31.980 --> 01:02:33.340]   that's really not really useful
[01:02:33.340 --> 01:02:35.860]   for a whole bunch of applications.
[01:02:35.860 --> 01:02:39.580]   But facial recognition and training it to say,
[01:02:39.580 --> 01:02:41.340]   "This is a different twin time,"
[01:02:41.340 --> 01:02:43.540]   and just making sure that they've,
[01:02:43.540 --> 01:02:45.780]   no, this increased the accuracy rate
[01:02:45.780 --> 01:02:49.100]   of predicting the right person, that's something else.
[01:02:49.100 --> 01:02:51.900]   But, I think this is a great article
[01:02:51.900 --> 01:02:55.020]   in terms of it's getting tons of attention
[01:02:55.020 --> 01:02:57.100]   from people who participated,
[01:02:57.100 --> 01:03:00.020]   who might not know that this stuff is possible.
[01:03:00.020 --> 01:03:01.140]   - That's, that's--
[01:03:01.140 --> 01:03:02.260]   - I like that.
[01:03:02.260 --> 01:03:03.100]   - Yeah.
[01:03:03.100 --> 01:03:05.060]   - I like that second, that second mind that you had there.
[01:03:05.060 --> 01:03:07.180]   I think, you know, one of the things,
[01:03:07.180 --> 01:03:10.180]   'cause I saw a bunch of different people talking about that
[01:03:10.180 --> 01:03:13.140]   after this 10 year challenge happened or whatever.
[01:03:13.140 --> 01:03:16.620]   And, at first I was sort of like, this, that silly,
[01:03:16.620 --> 01:03:19.100]   and I could understand sort of the griping about that.
[01:03:19.100 --> 01:03:22.620]   But I think, certainly in the idea that
[01:03:22.620 --> 01:03:24.900]   if there was like a data scientist out there
[01:03:24.900 --> 01:03:27.100]   who wanted to try and figure out
[01:03:27.100 --> 01:03:30.580]   if they could, you know, correctly predict how someone aged
[01:03:30.580 --> 01:03:33.740]   over time, then they could like search the hashtag
[01:03:33.740 --> 01:03:36.940]   that exists or search for those Facebook posts that exist.
[01:03:36.940 --> 01:03:41.020]   But, I mean, if you're on Facebook
[01:03:41.020 --> 01:03:44.420]   and you have been on Facebook for a while
[01:03:44.420 --> 01:03:46.660]   and uploading photos of yourself from, you know,
[01:03:46.660 --> 01:03:50.420]   high school into college and on,
[01:03:50.420 --> 01:03:54.340]   then there's the whole history of how you age
[01:03:54.340 --> 01:03:57.180]   in a better way than just between two,
[01:03:57.180 --> 01:03:59.100]   between 10 year periods.
[01:03:59.100 --> 01:04:01.900]   And so it's sort of already there, I guess.
[01:04:01.900 --> 01:04:02.980]   Not that that, you know what I mean?
[01:04:02.980 --> 01:04:06.180]   Like that doesn't make the idea that we should be concerned
[01:04:06.180 --> 01:04:07.380]   about privacy any less.
[01:04:07.380 --> 01:04:08.580]   We absolutely should be.
[01:04:08.580 --> 01:04:12.300]   But I guess we could just, we could literally say this
[01:04:12.300 --> 01:04:14.420]   about anything that we put on the internet.
[01:04:14.420 --> 01:04:19.420]   It's like, oh, Twitter was just made to collect our,
[01:04:19.420 --> 01:04:20.980]   how our minds are thinking at the time
[01:04:20.980 --> 01:04:23.220]   so that it can better sell to us.
[01:04:23.220 --> 01:04:25.380]   It's all sort of doing that always.
[01:04:25.380 --> 01:04:27.900]   So I don't know how this is that much different
[01:04:27.900 --> 01:04:29.620]   from something else.
[01:04:29.620 --> 01:04:31.620]   - It's as bad as the Tide Pod Challenge
[01:04:31.620 --> 01:04:33.940]   or the Bird Box Challenge.
[01:04:33.940 --> 01:04:35.940]   - Oh my Lord.
[01:04:35.940 --> 01:04:38.100]   So Netflix actually had to tweet,
[01:04:38.100 --> 01:04:39.540]   can't believe I have to say this,
[01:04:39.540 --> 01:04:42.100]   but please do not hurt yourself
[01:04:42.100 --> 01:04:43.500]   with this Bird Box Challenge.
[01:04:43.500 --> 01:04:44.740]   It's the movie with Sandra Bullock
[01:04:44.740 --> 01:04:47.500]   where you have to keep yourself blindfolded.
[01:04:47.500 --> 01:04:48.340]   So people are like.
[01:04:48.340 --> 01:04:49.380]   - I'm fine with people hurting themselves.
[01:04:49.380 --> 01:04:50.940]   I just don't want them to hurt other people.
[01:04:50.940 --> 01:04:52.180]   - Yeah, that's a good point.
[01:04:52.180 --> 01:04:54.060]   If it's, what's his name?
[01:04:54.060 --> 01:04:56.940]   Who is the, the YouTuber who did the first one,
[01:04:56.940 --> 01:04:59.140]   he walked into the street and drove around like,
[01:04:59.140 --> 01:05:01.180]   you know, the guy, what's his name I can't remember?
[01:05:01.180 --> 01:05:02.300]   - Oh yeah, the, yeah.
[01:05:02.300 --> 01:05:03.860]   - Blanked his name out, the brothers.
[01:05:03.860 --> 01:05:04.860]   - Yeah, same.
[01:05:04.860 --> 01:05:05.700]   Oh, golly.
[01:05:05.700 --> 01:05:06.540]   - Oh, it's good.
[01:05:06.540 --> 01:05:07.380]   - Really famous.
[01:05:07.380 --> 01:05:10.060]   - Don't occupy any space of your brain with this guy's name.
[01:05:10.060 --> 01:05:11.860]   Anyway, apparently other people have tried to drive
[01:05:11.860 --> 01:05:13.660]   driving with blindfolds on.
[01:05:13.660 --> 01:05:15.220]   Don't do that.
[01:05:15.220 --> 01:05:17.380]   Netflix says, "We don't know how this started
[01:05:17.380 --> 01:05:19.620]   "and we appreciate the love,
[01:05:19.620 --> 01:05:22.060]   "but boy and girl who I guess are on Bird Box
[01:05:22.060 --> 01:05:23.580]   "have just one wish for 2019
[01:05:23.580 --> 01:05:26.500]   "is that you do not end up in the hospital due to memes."
[01:05:26.500 --> 01:05:29.540]   Yeah, this seems fair.
[01:05:29.540 --> 01:05:32.140]   - I just don't know why this has to be said.
[01:05:32.140 --> 01:05:35.220]   And I, so I guess a question here is like,
[01:05:35.220 --> 01:05:38.380]   do you think that, I'm trying to think of a time
[01:05:38.380 --> 01:05:40.820]   before we sort of had these social networks?
[01:05:40.820 --> 01:05:44.380]   And I don't know, you put in like a VHS tape
[01:05:44.380 --> 01:05:48.420]   and watched some movie back in the day
[01:05:48.420 --> 01:05:51.060]   and something in the movie,
[01:05:51.060 --> 01:05:53.500]   I'm trying to think of something like--
[01:05:53.500 --> 01:05:55.260]   - Nothing like this ever happened, trust me,
[01:05:55.260 --> 01:05:56.100]   I'm an old man.
[01:05:56.100 --> 01:05:56.940]   - That's what I'm wondering.
[01:05:56.940 --> 01:05:58.300]   - None of this, you know what?
[01:05:58.300 --> 01:06:01.780]   This is a form of insanity that is new to the world
[01:06:01.780 --> 01:06:03.260]   and it's because of social media.
[01:06:03.260 --> 01:06:04.100]   And it's why I'm not--
[01:06:04.100 --> 01:06:06.580]   - I'm not on Twitter, Instagram or Facebook.
[01:06:06.580 --> 01:06:09.620]   It's why Elon Musk has to stop tweeting.
[01:06:09.620 --> 01:06:12.660]   It's why the president has to stop tweeting.
[01:06:12.660 --> 01:06:14.620]   It makes people nuts.
[01:06:14.620 --> 01:06:16.900]   - You never went into a dark bathroom
[01:06:16.900 --> 01:06:19.220]   and said like Bloody Mary, Bloody Mary,
[01:06:19.220 --> 01:06:20.340]   Bloody Mary, Bloody Mary three times.
[01:06:20.340 --> 01:06:21.780]   - Yeah, but that was harmless.
[01:06:21.780 --> 01:06:23.780]   - Yeah, some of us is harmless, but--
[01:06:23.780 --> 01:06:25.420]   - Okay, okay, maybe you're right.
[01:06:25.420 --> 01:06:27.420]   - I'm just trying to think of those things that happened.
[01:06:27.420 --> 01:06:29.820]   - It just didn't get put out there, you know?
[01:06:29.820 --> 01:06:31.740]   Like, no, it wasn't recorded anywhere.
[01:06:31.740 --> 01:06:33.300]   But I do, I think that there is something
[01:06:33.300 --> 01:06:35.860]   in what you're saying, Leo, because we know
[01:06:35.860 --> 01:06:39.180]   that our dopaminurgical systems are affected by likes
[01:06:39.180 --> 01:06:41.620]   and retweets and replies and things like that.
[01:06:41.620 --> 01:06:43.460]   - And even people did do Bloody Mary, Bloody Mary.
[01:06:43.460 --> 01:06:46.420]   It wasn't like a sweep the nation.
[01:06:46.420 --> 01:06:47.260]   - That's right.
[01:06:47.260 --> 01:06:48.100]   - That's right.
[01:06:48.100 --> 01:06:49.900]   - You can't get rid of stupid people.
[01:06:49.900 --> 01:06:52.820]   I'm like these become more popular like the Titan.
[01:06:52.820 --> 01:06:53.860]   - It's the Darwin Awards.
[01:06:53.860 --> 01:06:55.700]   We are getting rid of stupid people.
[01:06:55.700 --> 01:06:56.540]   (laughing)
[01:06:56.540 --> 01:06:57.380]   - You think you're just starting to like--
[01:06:57.380 --> 01:06:58.220]   - Just starting to like--
[01:06:58.220 --> 01:06:59.540]   - Like a certain-- - Logan Paul.
[01:06:59.540 --> 01:07:00.700]   Oh no, it came to me.
[01:07:00.700 --> 01:07:01.540]   Logan Paul.
[01:07:02.740 --> 01:07:03.580]   - I'm sorry.
[01:07:03.580 --> 01:07:04.900]   - Oh no, no.
[01:07:04.900 --> 01:07:06.260]   - Put it out of your mind again.
[01:07:06.260 --> 01:07:07.700]   (laughing)
[01:07:07.700 --> 01:07:10.900]   - Here is, here is, as long as we're talking stupid people,
[01:07:10.900 --> 01:07:16.180]   in the fake New Year, a native ads are muttering,
[01:07:16.180 --> 01:07:17.860]   muddying the waters.
[01:07:17.860 --> 01:07:21.500]   This is from Boston University Research.
[01:07:21.500 --> 01:07:24.740]   An online experiment found that less than one in 10 people
[01:07:24.740 --> 01:07:28.540]   can tell sponsored content from an article.
[01:07:30.100 --> 01:07:34.340]   Now, that's to me, this is really depressing
[01:07:34.340 --> 01:07:39.340]   because this is from a study done by Boston University School
[01:07:39.340 --> 01:07:43.300]   of Communication Assistant Professor of Advertising.
[01:07:43.300 --> 01:07:47.060]   Her online survey devolved to participants.
[01:07:47.060 --> 01:07:48.540]   They were viewing advertisements,
[01:07:48.540 --> 01:07:50.860]   but many of the people 90% thought
[01:07:50.860 --> 01:07:52.140]   they'd been looking at an article,
[01:07:52.140 --> 01:07:54.620]   even though they were told ahead of time.
[01:07:54.620 --> 01:07:55.460]   (laughing)
[01:07:55.460 --> 01:07:56.900]   They were told ahead of time.
[01:07:58.380 --> 01:08:03.380]   The 738 nationally representative sample of US adults
[01:08:03.380 --> 01:08:07.020]   doesn't surprise me, I guess,
[01:08:07.020 --> 01:08:07.900]   but it is depressing.
[01:08:07.900 --> 01:08:09.580]   Native advertising, if you don't know,
[01:08:09.580 --> 01:08:11.260]   is, and you see it everywhere now,
[01:08:11.260 --> 01:08:13.460]   is something that somebody paid for.
[01:08:13.460 --> 01:08:17.380]   It looks like an article in a newspaper or a magazine
[01:08:17.380 --> 01:08:18.220]   or a website.
[01:08:18.220 --> 01:08:20.020]   It looks like a real article, but it's not.
[01:08:20.020 --> 01:08:25.020]   It's paid content that cleverly mentions, you know,
[01:08:25.700 --> 01:08:30.700]   the drug or the car or whatever it is they're trying to advertise.
[01:08:30.700 --> 01:08:32.460]   And then she divulges to the class,
[01:08:32.460 --> 01:08:35.700]   by the way, this class was a paid advertisement for Seattle.
[01:08:35.700 --> 01:08:37.740]   (laughing)
[01:08:37.740 --> 01:08:39.820]   You've been wondering why I'm sitting in a hot tub
[01:08:39.820 --> 01:08:41.260]   in the woods, well.
[01:08:41.260 --> 01:08:44.820]   It's the same with outbrain or all the links
[01:08:44.820 --> 01:08:45.660]   on the bottom of the-- Oh, the tubula
[01:08:45.660 --> 01:08:46.620]   and outbrain crap.
[01:08:46.620 --> 01:08:47.460]   Yes.
[01:08:47.460 --> 01:08:48.980]   You know, I fall for it every time.
[01:08:48.980 --> 01:08:52.500]   'Cause it's always really good link bait,
[01:08:52.500 --> 01:08:55.460]   like you won't believe what this celebrity
[01:08:55.460 --> 01:08:57.780]   looks like 20 years later.
[01:08:57.780 --> 01:08:59.340]   And I have 20 now-- And it looks like
[01:08:59.340 --> 01:09:01.180]   all of you still haven't seen the answer.
[01:09:01.180 --> 01:09:04.300]   It's a slideshow that goes and goes and goes.
[01:09:04.300 --> 01:09:05.140]   Never find the thing.
[01:09:05.140 --> 01:09:08.020]   I wonder if, you know, in college,
[01:09:08.020 --> 01:09:11.020]   I can remember taking a media class
[01:09:11.020 --> 01:09:12.620]   and it was just like one of the electives
[01:09:12.620 --> 01:09:13.540]   that was available.
[01:09:13.540 --> 01:09:15.460]   And I learned a whole heck of a lot in that class
[01:09:15.460 --> 01:09:17.540]   about media literacy in general.
[01:09:17.540 --> 01:09:21.340]   And in high school, you have to take certain,
[01:09:21.340 --> 01:09:22.660]   depending on the state that you're in,
[01:09:22.660 --> 01:09:25.740]   you have to take certain classes to satisfy
[01:09:25.740 --> 01:09:28.100]   the requirements for the state of your education.
[01:09:28.100 --> 01:09:32.340]   And I really do feel like, as part of a public education,
[01:09:32.340 --> 01:09:34.700]   at this point, media literacy should be--
[01:09:34.700 --> 01:09:35.700]   Yeah, I agree.
[01:09:35.700 --> 01:09:38.100]   And, you know, in the scope of things.
[01:09:38.100 --> 01:09:41.340]   There's a very good point.
[01:09:41.340 --> 01:09:42.260]   Let's take a break about it.
[01:09:42.260 --> 01:09:43.860]   The combination of the two stats,
[01:09:43.860 --> 01:09:46.660]   74% of Facebook users don't know
[01:09:46.660 --> 01:09:49.060]   that they're being targeted based on their own behavior.
[01:09:49.060 --> 01:09:51.580]   And then 90% of people can't recognize
[01:09:51.580 --> 01:09:54.780]   that they add from actual news.
[01:09:54.780 --> 01:09:56.060]   But Facebook is just rubbing their hands
[01:09:56.060 --> 01:09:56.900]   'cause they're like, "Yes."
[01:09:56.900 --> 01:09:58.700]   Yes, the opportunity!
[01:09:58.700 --> 01:10:00.020]   Step three, profit.
[01:10:00.020 --> 01:10:04.020]   Yeah, you know, you can't fix stupid.
[01:10:04.020 --> 01:10:07.780]   Nobody who watches our shows
[01:10:07.780 --> 01:10:12.180]   would have any trouble distinguishing between
[01:10:12.180 --> 01:10:13.540]   distincting.
[01:10:13.540 --> 01:10:16.620]   I didn't know the word, but I like distinguishing
[01:10:16.620 --> 01:10:19.300]   between advertising and content.
[01:10:19.300 --> 01:10:20.180]   Would you know?
[01:10:20.180 --> 01:10:22.220]   You would know the difference.
[01:10:22.220 --> 01:10:24.420]   By the way, we had a great week this week on Twitch.
[01:10:24.420 --> 01:10:26.820]   And we've made a fascinating mini movie
[01:10:26.820 --> 01:10:29.220]   for your enjoyment watch.
[01:10:29.220 --> 01:10:31.300]   Previously on Twitch.
[01:10:31.300 --> 01:10:34.020]   Getting to the news, there's nothing to see here.
[01:10:34.020 --> 01:10:36.260]   No, actually, wait a minute.
[01:10:36.260 --> 01:10:37.420]   There's someone sitting in between us.
[01:10:37.420 --> 01:10:39.380]   There was no empty desk, so they'd like to sit here.
[01:10:39.380 --> 01:10:40.220]   I'm like, all right.
[01:10:40.220 --> 01:10:42.260]   Yeah, we figured we couldn't find an office
[01:10:42.260 --> 01:10:43.100]   for you to work in.
[01:10:43.100 --> 01:10:45.100]   So if you don't mind working between us,
[01:10:45.100 --> 01:10:46.380]   Father Robert Balisaire.
[01:10:46.380 --> 01:10:47.660]   It's the best place to be, really.
[01:10:47.660 --> 01:10:49.900]   And we'll just do the show and pretend you're not here.
[01:10:49.900 --> 01:10:51.540]   Yeah, it's Lady Berkard.
[01:10:51.540 --> 01:10:52.540]   Grab me a sandwich.
[01:10:52.540 --> 01:10:53.540]   (laughing)
[01:10:53.540 --> 01:10:54.820]   Get down with that.
[01:10:54.820 --> 01:10:55.820]   Windows Weekly.
[01:10:55.820 --> 01:10:58.260]   The death of Windows 7.
[01:10:58.260 --> 01:11:00.580]   January 14th, 2020.
[01:11:00.580 --> 01:11:04.140]   That's the last, that's the first patch Tuesday of January.
[01:11:04.140 --> 01:11:06.420]   And the last time that they're gonna issue
[01:11:06.420 --> 01:11:10.140]   for everyone free security updates to Windows 7.
[01:11:10.140 --> 01:11:12.860]   After that, Windows 7 will be like XP and Orphan.
[01:11:12.860 --> 01:11:17.580]   This week in computer hardware, Cortana and Search.
[01:11:17.580 --> 01:11:19.340]   Yeah, they needed some space.
[01:11:19.340 --> 01:11:21.540]   It's just not working out.
[01:11:21.540 --> 01:11:23.460]   I saw Mary Jo Foley tweet about this
[01:11:23.460 --> 01:11:25.620]   so I went to the Microsoft blogs.
[01:11:25.620 --> 01:11:28.580]   This is the actual graphic that Microsoft published
[01:11:28.580 --> 01:11:30.820]   to show you separation of Search.
[01:11:30.820 --> 01:11:31.660]   Really?
[01:11:31.660 --> 01:11:32.500]   Cortana.
[01:11:32.500 --> 01:11:35.300]   What looks like Microsoft paints
[01:11:35.300 --> 01:11:37.820]   and yellow text and arrows that were drawn by hand.
[01:11:37.820 --> 01:11:39.340]   We know we use this pack.
[01:11:39.340 --> 01:11:40.740]   Just like you like it.
[01:11:40.740 --> 01:11:45.700]   And ladies and gentlemen, thank you, Berk,
[01:11:45.700 --> 01:11:46.540]   for the Cupcake.
[01:11:46.540 --> 01:11:48.580]   Our 500th episode is,
[01:11:48.580 --> 01:11:49.940]   "Burt gonna eat the cupcake,
[01:11:49.940 --> 01:11:51.220]   "it's Kevin gonna eat the cupcake,
[01:11:51.220 --> 01:11:53.060]   "or will like Leo eat the cupcake."
[01:11:53.060 --> 01:11:55.860]   I'll eat it and I won't blow the candle out.
[01:11:55.860 --> 01:11:56.700]   Ow!
[01:11:56.700 --> 01:11:58.380]   Hope everybody made a wish.
[01:11:58.380 --> 01:12:01.100]   Happy 500th and we're so glad Sebastian Peake
[01:12:01.100 --> 01:12:03.740]   is now part of this week in computer hardware.
[01:12:03.740 --> 01:12:04.580]   It's great.
[01:12:04.580 --> 01:12:06.140]   But I didn't get to eat the cupcake.
[01:12:06.140 --> 01:12:09.100]   Sebastian, do you have over your right shoulder,
[01:12:09.100 --> 01:12:12.540]   like 20 hard drives, all connected up to one computer?
[01:12:12.540 --> 01:12:14.780]   I wish, I wish they were hard drives.
[01:12:14.780 --> 01:12:15.620]   What is that?
[01:12:15.620 --> 01:12:16.460]   What's the correct?
[01:12:16.460 --> 01:12:18.100]   Graphics cards.
[01:12:18.100 --> 01:12:19.580]   Oh, that's even crazier.
[01:12:19.580 --> 01:12:21.220]   Are you testing graphics cards?
[01:12:21.220 --> 01:12:22.740]   Yes, I've been testing graphics cards.
[01:12:22.740 --> 01:12:24.100]   Yikes.
[01:12:24.100 --> 01:12:25.980]   Do you enjoy doing that?
[01:12:25.980 --> 01:12:28.220]   I mean, at first, yes.
[01:12:28.220 --> 01:12:30.500]   And then by the time you get done,
[01:12:30.500 --> 01:12:33.420]   like going through 10 games, three runs each,
[01:12:33.420 --> 01:12:34.820]   at three different resolutions,
[01:12:34.820 --> 01:12:36.860]   and then overclocking, you're like, okay, no,
[01:12:36.860 --> 01:12:40.900]   I'd be okay if I never saw them in the graphics card again.
[01:12:40.900 --> 01:12:42.700]   I just-- And they're more on the way.
[01:12:42.700 --> 01:12:43.660]   Isn't there, didn't they,
[01:12:43.660 --> 01:12:44.660]   that I have to announce, have you tried
[01:12:44.660 --> 01:12:47.420]   their new ray tracing card from, is it in?
[01:12:47.420 --> 01:12:49.460]   Yeah, the RTX cards.
[01:12:49.460 --> 01:12:53.100]   I've just finished the review on this 2060,
[01:12:53.100 --> 01:12:54.180]   right when I got to CES,
[01:12:54.180 --> 01:12:55.580]   I was actually publishing that.
[01:12:55.580 --> 01:12:56.420]   What do you think?
[01:12:56.420 --> 01:12:58.540]   And it's beautiful.
[01:12:58.540 --> 01:13:03.540]   I mean, what I'm waiting for is what Nvidia calls DLSS.
[01:13:03.540 --> 01:13:06.140]   'Cause you can do hardware ray tracing,
[01:13:06.140 --> 01:13:08.260]   they have these tensor cores for ray tracing.
[01:13:08.260 --> 01:13:10.340]   And right now they have the only hardware
[01:13:10.340 --> 01:13:13.140]   that can do that with these RTX series cards.
[01:13:13.140 --> 01:13:17.380]   But they have this deep learning super sampling
[01:13:17.380 --> 01:13:24.380]   technology that uses AI to kind of draw the frame
[01:13:24.380 --> 01:13:29.180]   that you're viewing,
[01:13:29.180 --> 01:13:33.740]   and it supposes significantly less overhead to your hardware.
[01:13:33.740 --> 01:13:38.220]   So the potential is to be able to do higher frame rates
[01:13:38.220 --> 01:13:40.420]   with the same kind of beautiful,
[01:13:40.420 --> 01:13:42.780]   like lighting effects you get from ray tracing,
[01:13:42.780 --> 01:13:46.620]   using deep learning, using these cards and other cards.
[01:13:46.620 --> 01:13:51.300]   So we saw a demo of that at CES, actually Nvidia had RTX cards
[01:13:51.300 --> 01:13:55.500]   running the new 3D Mark port royal demo.
[01:13:55.500 --> 01:13:57.740]   That's gonna be the standard demo, at least for a while,
[01:13:57.740 --> 01:14:00.460]   that allows you to actually test ray tracing,
[01:14:00.460 --> 01:14:02.740]   which we didn't even get until January 8.
[01:14:02.740 --> 01:14:05.860]   So I was at CES watching it for the first time,
[01:14:05.860 --> 01:14:07.900]   'cause I didn't have a preview copy.
[01:14:07.900 --> 01:14:11.740]   And right next to it was a free release copy
[01:14:11.740 --> 01:14:14.140]   of the same benchmark running DLSS,
[01:14:14.140 --> 01:14:15.740]   and it was running at a much higher frame rate.
[01:14:15.740 --> 01:14:17.380]   And look just as good.
[01:14:17.380 --> 01:14:19.980]   So it actually looks slightly better,
[01:14:19.980 --> 01:14:22.820]   because they were able to do things like,
[01:14:22.820 --> 01:14:26.420]   they can train it to identify the edges of objects.
[01:14:26.420 --> 01:14:29.380]   So the edges were really sharp.
[01:14:29.380 --> 01:14:32.460]   And then if you looked at just regular ray tracing
[01:14:32.460 --> 01:14:35.220]   with standard temporal anti-aliasing,
[01:14:35.220 --> 01:14:37.660]   it kind of makes the whole screen look a little bit soft,
[01:14:37.660 --> 01:14:39.180]   a little bit blurred.
[01:14:39.180 --> 01:14:41.740]   So the DLSS version was much sharper,
[01:14:41.740 --> 01:14:43.900]   and was running at a high frame rate.
[01:14:43.900 --> 01:14:46.260]   So that's really exciting.
[01:14:46.260 --> 01:14:48.540]   - I understand ray tracing.
[01:14:48.540 --> 01:14:51.180]   And in the past, it generates a great result,
[01:14:51.180 --> 01:14:53.900]   but it's so compute intensive.
[01:14:53.900 --> 01:14:57.700]   It literally imagines from a light source,
[01:14:57.700 --> 01:14:59.900]   it traces the ray of light,
[01:14:59.900 --> 01:15:02.460]   and imagines at each point what that's gonna look like,
[01:15:02.460 --> 01:15:04.420]   and you can imagine how long that takes.
[01:15:04.420 --> 01:15:06.980]   But they're doing it in real time.
[01:15:06.980 --> 01:15:08.460]   - Yeah, that's the amazing thing.
[01:15:08.460 --> 01:15:09.820]   It's thick about just a few years ago,
[01:15:09.820 --> 01:15:11.940]   when they would be running like rendering farms
[01:15:11.940 --> 01:15:15.860]   at movie studio to do five seconds of film.
[01:15:15.860 --> 01:15:17.860]   And now you can do it in real time
[01:15:17.860 --> 01:15:19.420]   because they have dedicated hardware for them.
[01:15:19.420 --> 01:15:21.340]   - Will there be games that use this?
[01:15:21.340 --> 01:15:22.140]   - Yeah, there already are.
[01:15:22.140 --> 01:15:24.900]   Battlefield 5 is the poster child right now for ray tracing,
[01:15:24.900 --> 01:15:26.860]   'cause you can enable it.
[01:15:26.860 --> 01:15:29.860]   And it does look amazing.
[01:15:29.860 --> 01:15:33.260]   Like the parts of it that keep on,
[01:15:33.260 --> 01:15:36.300]   are that are shown as being very obvious examples of it,
[01:15:36.300 --> 01:15:39.620]   are always things like water reflections,
[01:15:39.620 --> 01:15:42.100]   light reflections on Chinese surfaces like Chrome,
[01:15:42.100 --> 01:15:44.260]   or like the side of a car when there's an explosion,
[01:15:44.260 --> 01:15:48.900]   then you can see exactly how the lighting would really fall.
[01:15:48.900 --> 01:15:50.140]   And it's very convincing,
[01:15:50.140 --> 01:15:51.300]   especially when you look at it side by side
[01:15:51.300 --> 01:15:53.460]   with standard lighting techniques
[01:15:53.460 --> 01:15:56.660]   that have been used in games for many years, but.
[01:15:56.660 --> 01:15:58.900]   It is extremely-- - So the 2080
[01:15:58.900 --> 01:16:03.900]   and the 2080 titanium do support ray tracing and DLSS.
[01:16:03.900 --> 01:16:09.180]   - Yes, and actually even this little 2060 behind me,
[01:16:09.180 --> 01:16:10.300]   even that does. - Wow.
[01:16:10.300 --> 01:16:14.420]   - And that's sort of their high mid-range card.
[01:16:14.420 --> 01:16:17.900]   So it has the hardware capability of supporting ray tracing,
[01:16:17.900 --> 01:16:20.300]   but for the 2060 especially,
[01:16:20.300 --> 01:16:23.780]   it's gonna be like a DLSS story,
[01:16:23.780 --> 01:16:24.620]   where there's a ray tracing.
[01:16:24.620 --> 01:16:27.220]   - Deep learning DL, super sampling.
[01:16:27.220 --> 01:16:28.060]   - Yes.
[01:16:28.060 --> 01:16:30.100]   - Is this-- - And they haven't gone into
[01:16:30.100 --> 01:16:32.740]   great detail about what exactly--
[01:16:32.740 --> 01:16:36.900]   - You throw AI in and then everything's better kind of thing.
[01:16:36.900 --> 01:16:39.580]   - Why do they call it DLSS with blockchain?
[01:16:39.580 --> 01:16:43.380]   Or is this actually really using deep learning
[01:16:43.380 --> 01:16:44.580]   to do a better job?
[01:16:44.580 --> 01:16:46.700]   And how is it using deep learning?
[01:16:46.700 --> 01:16:50.100]   - Yeah, they haven't told us exactly how it works,
[01:16:50.100 --> 01:16:52.700]   but, and it's kind of their own proprietary thing,
[01:16:52.700 --> 01:16:54.940]   obviously, but-- - They say it leverages
[01:16:54.940 --> 01:16:56.740]   a deep neural network to extract
[01:16:56.740 --> 01:17:00.340]   multi-dimensional features of the rendered scene
[01:17:00.340 --> 01:17:02.420]   and a 10-legently combined details
[01:17:02.420 --> 01:17:06.380]   from multiple frames to construct a high quality final image.
[01:17:06.380 --> 01:17:08.300]   - I think if you read between the lines,
[01:17:08.300 --> 01:17:12.660]   what they're saying is it enables you to actually,
[01:17:12.660 --> 01:17:15.660]   in hardware, render at a lower resolution
[01:17:15.660 --> 01:17:19.180]   and then leverage this to display it at the higher resolution,
[01:17:19.180 --> 01:17:22.780]   which is why suddenly the frame count like goes way up,
[01:17:22.780 --> 01:17:24.980]   your actual frame rate goes way up.
[01:17:24.980 --> 01:17:27.980]   I think in hardware, you're probably at like half resolution.
[01:17:27.980 --> 01:17:30.460]   - You know what the analog is of this.
[01:17:30.460 --> 01:17:33.420]   TVs are gonna start doing this with up sampling.
[01:17:33.420 --> 01:17:37.020]   So in the past, when you up sampled from, you know,
[01:17:37.020 --> 01:17:40.860]   24 frames to 60 frames, you had to imagine,
[01:17:40.860 --> 01:17:43.660]   you interpolated what was the missing frames
[01:17:43.660 --> 01:17:46.420]   and usually that was just duplicating previous frames.
[01:17:46.420 --> 01:17:49.260]   But I heard about this, the CAS,
[01:17:49.260 --> 01:17:50.980]   Scott Wilkinson told us about this,
[01:17:50.980 --> 01:17:54.340]   they're starting to use neural networks to actually try to,
[01:17:54.340 --> 01:17:58.020]   by training it with high definition material,
[01:17:58.020 --> 01:18:00.380]   so it can learn what should be in between those frames
[01:18:00.380 --> 01:18:02.020]   when you up sample.
[01:18:02.020 --> 01:18:03.340]   - Sounds kinda cool.
[01:18:03.340 --> 01:18:04.180]   - Yeah.
[01:18:04.180 --> 01:18:09.180]   - Although I do, I still can't watch a 60 frames per second film.
[01:18:09.180 --> 01:18:14.780]   And I remember there was this scary, supposedly scary movie.
[01:18:14.780 --> 01:18:16.860]   It was like the horror movie that was really popular
[01:18:16.860 --> 01:18:19.060]   for a while, it was It Follows.
[01:18:19.060 --> 01:18:22.580]   And I sat down and was excited to watch this film
[01:18:22.580 --> 01:18:24.540]   with some friends and I just spent pretty much
[01:18:24.540 --> 01:18:27.700]   the whole time griping about how it was in 60 frames per second
[01:18:27.700 --> 01:18:30.620]   and how that just made me think of it as like, I don't know,
[01:18:30.620 --> 01:18:33.900]   TBS television show and the scary movie
[01:18:33.900 --> 01:18:35.220]   didn't end up being that scary anyway,
[01:18:35.220 --> 01:18:37.980]   but like I don't want to take 24
[01:18:37.980 --> 01:18:39.580]   and make it 60 frames per second
[01:18:39.580 --> 01:18:42.420]   because it just pulls me out of,
[01:18:42.420 --> 01:18:43.260]   there's some of the--
[01:18:43.260 --> 01:18:45.780]   - Peter Jackson's a fan of this high frame rate stuff.
[01:18:45.780 --> 01:18:47.660]   And remember people complaining about The Hobbit,
[01:18:47.660 --> 01:18:48.500]   which was a--
[01:18:48.500 --> 01:18:49.340]   - I do.
[01:18:49.340 --> 01:18:50.180]   - 'Cause it was one of them.
[01:18:50.180 --> 01:18:52.180]   - Gandalf staff looked like, you know,
[01:18:52.180 --> 01:18:55.380]   it was made out of plastic from Staffs R Us.
[01:18:55.380 --> 01:18:57.660]   - Exactly, it came from Staffs R Us.
[01:18:57.660 --> 01:18:59.900]   And I boycotted that place.
[01:18:59.900 --> 01:19:01.900]   Like don't like them. - Yeah, don't like them.
[01:19:01.900 --> 01:19:02.780]   - Yeah.
[01:19:02.780 --> 01:19:07.340]   - So the DLSS basically replaces anti-aliasing
[01:19:07.340 --> 01:19:10.340]   in the same way, okay, correct me if I'm completely nuts
[01:19:10.340 --> 01:19:13.580]   best, but the same way that upscaling can be done better
[01:19:13.580 --> 01:19:16.260]   by training it, you could do anti-aliasing better
[01:19:16.260 --> 01:19:21.060]   by training a neural network to imagine what's in those jaggies.
[01:19:21.060 --> 01:19:21.980]   - That's the dream.
[01:19:21.980 --> 01:19:24.300]   And actually thinking about TV technology,
[01:19:24.300 --> 01:19:26.180]   does this mean that we can use deep learning
[01:19:26.180 --> 01:19:31.020]   to finally eliminate these sort of terrible soap opera effect?
[01:19:31.020 --> 01:19:33.220]   Like when I-- - Yes, that's the point.
[01:19:33.220 --> 01:19:34.060]   Yes.
[01:19:34.060 --> 01:19:35.420]   - That's the war-- - That's moving enabled.
[01:19:35.420 --> 01:19:36.260]   - Oh.
[01:19:36.260 --> 01:19:39.220]   - It, depending on the TV, some of them do an okay job.
[01:19:39.220 --> 01:19:43.340]   And some of them is just weird warbly motion and just--
[01:19:43.340 --> 01:19:44.540]   - I notice it right away.
[01:19:44.540 --> 01:19:46.460]   If you're seeing a movie and it looks like it was shot
[01:19:46.460 --> 01:19:49.540]   on video, you know, like a soap opera,
[01:19:49.540 --> 01:19:52.100]   you know, I personally notice it immediately.
[01:19:52.100 --> 01:19:54.140]   I know lots of people though, they don't.
[01:19:54.140 --> 01:19:55.460]   I'll go into people's houses.
[01:19:55.460 --> 01:19:57.780]   In fact, over the holidays, a bit quite a few of you
[01:19:57.780 --> 01:20:01.420]   went in mom and dad's house and turned it off.
[01:20:01.420 --> 01:20:02.980]   - Get rid of that motion smoothing,
[01:20:02.980 --> 01:20:04.940]   that weird up sampling nonsense.
[01:20:04.940 --> 01:20:06.260]   - Look, I do whatever comes-- - I do whatever
[01:20:06.260 --> 01:20:07.620]   it comes through, sells me to do.
[01:20:07.620 --> 01:20:08.700]   - Yeah.
[01:20:08.700 --> 01:20:09.540]   Exactly.
[01:20:09.540 --> 01:20:10.380]   - What did he say?
[01:20:10.380 --> 01:20:11.500]   Turn it off, right?
[01:20:11.500 --> 01:20:13.420]   - Yeah, he had that little essay.
[01:20:13.420 --> 01:20:14.660]   I kept on waiting for the punchline, like,
[01:20:14.660 --> 01:20:15.500]   what is he plugging?
[01:20:15.500 --> 01:20:17.380]   Like, no, it's really just a essay.
[01:20:17.380 --> 01:20:18.860]   - Where's the Scientology in this?
[01:20:18.860 --> 01:20:19.700]   Where?
[01:20:19.700 --> 01:20:20.540]   (laughing)
[01:20:20.540 --> 01:20:21.540]   All right.
[01:20:21.540 --> 01:20:23.740]   - Wait, Sebastian, for the DLSS,
[01:20:23.740 --> 01:20:25.180]   who does the training model?
[01:20:25.180 --> 01:20:28.300]   Is that done by NVIDIA or the game provider has to--
[01:20:28.300 --> 01:20:29.740]   - That's a good question.
[01:20:29.740 --> 01:20:30.580]   - That is a good question.
[01:20:30.580 --> 01:20:31.420]   - I don't know.
[01:20:31.420 --> 01:20:32.420]   - I don't know.
[01:20:32.420 --> 01:20:34.860]   I would assume that they had worked on it internally.
[01:20:34.860 --> 01:20:37.180]   They didn't say anything about being developer level.
[01:20:37.180 --> 01:20:39.220]   However, I think that makes more sense
[01:20:39.220 --> 01:20:42.180]   because certain games like Shadow of the Tomb Raider,
[01:20:42.180 --> 01:20:45.940]   that's a, like, coming, but it hasn't been released yet,
[01:20:45.940 --> 01:20:47.780]   yet NVIDIA was showing like,
[01:20:47.780 --> 01:20:50.460]   they've probably partnered with 3DMark
[01:20:50.460 --> 01:20:53.860]   to have this port royal demo with the option enabled.
[01:20:53.860 --> 01:20:57.340]   So at this point, I'm sure it is just a matter of actually,
[01:20:57.340 --> 01:20:59.340]   like, having teams work on this,
[01:20:59.340 --> 01:21:00.580]   implement it within games,
[01:21:00.580 --> 01:21:03.980]   and that would probably fall on the game developer, I imagine.
[01:21:03.980 --> 01:21:05.860]   - Yeah, but I'm guessing some game developers
[01:21:05.860 --> 01:21:07.260]   won't have access to the farms
[01:21:07.260 --> 01:21:08.740]   in order to do the training model,
[01:21:08.740 --> 01:21:11.260]   'cause that's the training part is the intensive part.
[01:21:11.260 --> 01:21:14.700]   Once it's trained, you can deploy it on lower hardware.
[01:21:14.700 --> 01:21:17.700]   And so I'm guessing NVIDIA has a farm
[01:21:17.700 --> 01:21:20.980]   that they then rent out to the game developers
[01:21:20.980 --> 01:21:22.060]   for them to train their models
[01:21:22.060 --> 01:21:24.180]   so they can work better on their cards.
[01:21:24.180 --> 01:21:27.420]   So that sounds like another source of revenue for them.
[01:21:27.420 --> 01:21:29.780]   - Yeah, I wonder if it's part of, like,
[01:21:29.780 --> 01:21:31.140]   game works going forward.
[01:21:31.140 --> 01:21:32.500]   This is one of those things where you can sort of buy
[01:21:32.500 --> 01:21:34.860]   into their ecology and say,
[01:21:34.860 --> 01:21:37.180]   I want to use like their hair effects and this and this,
[01:21:37.180 --> 01:21:40.260]   and also implement DLSS in my game.
[01:21:40.260 --> 01:21:41.260]   - You know where this, you know,
[01:21:41.260 --> 01:21:44.420]   it might be driving this is server-side gaming,
[01:21:44.420 --> 01:21:45.540]   because the whole point,
[01:21:45.540 --> 01:21:47.460]   or one of the points of DLSS is you,
[01:21:47.460 --> 01:21:49.500]   you render, and the reason is faster frame rate,
[01:21:49.500 --> 01:21:52.460]   you render a lower quality, faster frame rate image,
[01:21:52.460 --> 01:21:57.260]   and then clean it up with DLSS to make it look spectacular.
[01:21:57.260 --> 01:21:58.460]   That's exactly what you'd want.
[01:21:58.460 --> 01:22:00.100]   If you were doing gaming on the server side,
[01:22:00.100 --> 01:22:02.380]   you'd want low latency, low quality images
[01:22:02.380 --> 01:22:05.340]   that you send to the playing device,
[01:22:05.340 --> 01:22:08.260]   but then if the playing device had the ability to clean it up,
[01:22:08.260 --> 01:22:11.260]   that would be the best of both worlds, right?
[01:22:11.260 --> 01:22:14.180]   You get great optics and low latency.
[01:22:14.180 --> 01:22:15.980]   I don't know, I'm making this up, I don't know.
[01:22:15.980 --> 01:22:19.540]   - It shows you how much money there is in gaming though,
[01:22:19.540 --> 01:22:23.900]   that this is, all this fancy technology is for gaming.
[01:22:23.900 --> 01:22:27.700]   - It'll also be lock in and harder to port.
[01:22:27.700 --> 01:22:30.240]   - Oh, who cares?
[01:22:30.240 --> 01:22:34.060]   That's, video doesn't they want everybody
[01:22:34.060 --> 01:22:35.700]   just to use Nvidia cards?
[01:22:35.700 --> 01:22:36.820]   - AMD will care.
[01:22:36.820 --> 01:22:38.940]   - Yeah, that's the only radion cares.
[01:22:38.940 --> 01:22:40.420]   - Yeah, we know it.
[01:22:40.420 --> 01:22:42.340]   - This is all those talking for Nvidia, right?
[01:22:42.340 --> 01:22:43.740]   But everybody, every card does this,
[01:22:43.740 --> 01:22:45.460]   every company does this.
[01:22:45.460 --> 01:22:47.140]   How many games you buy this?
[01:22:47.140 --> 01:22:48.740]   It works better with radion.
[01:22:48.740 --> 01:22:52.700]   - Yeah, there are fewer of those, for sure.
[01:22:52.700 --> 01:22:53.540]   - Are they?
[01:22:53.540 --> 01:22:54.380]   - Yeah.
[01:22:54.380 --> 01:22:55.380]   - But there are quite a few more.
[01:22:55.380 --> 01:22:57.020]   I know that was one of those things in our industry
[01:22:57.020 --> 01:23:00.340]   where it's been a lot of controversy about sort of game works
[01:23:00.340 --> 01:23:04.140]   and how Nvidia had an advantage there
[01:23:04.140 --> 01:23:06.460]   and that so many games, especially in game benchmarks
[01:23:06.460 --> 01:23:08.300]   when we, you know, new graphics cards come out,
[01:23:08.300 --> 01:23:09.780]   we run benchmarks, we release results,
[01:23:09.780 --> 01:23:11.620]   and then people point to them and say, yeah,
[01:23:11.620 --> 01:23:14.260]   but Nvidia was helping them
[01:23:14.260 --> 01:23:17.460]   and they were helping develop this game
[01:23:17.460 --> 01:23:18.980]   and there's an advantage on the Nvidia hardware
[01:23:18.980 --> 01:23:20.420]   because of game work, so.
[01:23:20.420 --> 01:23:23.060]   - Snow accident that Nvidia makes the shield, is it?
[01:23:23.060 --> 01:23:27.380]   And in fact, offers a streaming gaming service over it.
[01:23:27.380 --> 01:23:30.100]   Out of sync explains it.
[01:23:30.100 --> 01:23:35.100]   DLSS is pre-computed for each game by Nvidia
[01:23:35.100 --> 01:23:37.580]   and distributed through driver updates.
[01:23:37.580 --> 01:23:38.860]   So they're doing the work.
[01:23:38.860 --> 01:23:43.380]   You know what you do--
[01:23:43.380 --> 01:23:44.220]   - Can't imagine.
[01:23:44.220 --> 01:23:47.500]   - You run at very high, you run at a very high quality
[01:23:47.500 --> 01:23:48.860]   and you run at a very low quality
[01:23:48.860 --> 01:23:52.740]   and then you train the neural network.
[01:23:52.740 --> 01:23:55.180]   This is where you're going from this point.
[01:23:55.180 --> 01:23:56.500]   - It's the 10 year challenge.
[01:23:56.500 --> 01:23:57.340]   - Ah!
[01:23:57.340 --> 01:23:58.180]   - It's the 10 year challenge.
[01:23:58.180 --> 01:23:59.020]   - That's right.
[01:23:59.020 --> 01:24:01.060]   - The show, 1997 game and a 2007 game.
[01:24:01.060 --> 01:24:02.620]   Look like that.
[01:24:02.620 --> 01:24:05.100]   - I want Minecraft to look like that.
[01:24:05.100 --> 01:24:07.300]   Our show today brought to you by Zip Recruiter.
[01:24:07.300 --> 01:24:09.340]   We love Zip Recruiter.
[01:24:09.340 --> 01:24:10.980]   We've posted jobs on Zip Recruiter.
[01:24:10.980 --> 01:24:12.460]   We've got a job right now, I won't say.
[01:24:12.460 --> 01:24:14.780]   Actually, I shouldn't say, never mind.
[01:24:14.780 --> 01:24:15.780]   It's not your job, John.
[01:24:15.780 --> 01:24:17.340]   It's not your job, Kirsten.
[01:24:17.340 --> 01:24:18.940]   (laughing)
[01:24:18.940 --> 01:24:19.780]   Not my job.
[01:24:19.780 --> 01:24:21.100]   It might be my job.
[01:24:21.100 --> 01:24:21.940]   Posted on Zip Recruiter,
[01:24:21.940 --> 01:24:23.660]   Zip Recruiter is the best way to hire
[01:24:23.660 --> 01:24:25.660]   qualified candidates fast.
[01:24:25.660 --> 01:24:27.220]   You know what's smart?
[01:24:27.220 --> 01:24:28.180]   I'll tell you what's smart.
[01:24:28.180 --> 01:24:30.700]   Kickin' off 2019 by planning out
[01:24:30.700 --> 01:24:33.180]   which roles your business needs to hire for.
[01:24:33.180 --> 01:24:34.100]   You know what else is smart?
[01:24:34.100 --> 01:24:35.700]   Starting the New Year off strong by going
[01:24:35.700 --> 01:24:39.940]   to ziprecruiter.com/twit to get those people.
[01:24:39.940 --> 01:24:43.100]   See, Zip Recruiter is completely different
[01:24:43.100 --> 01:24:44.500]   from those other job sites.
[01:24:44.500 --> 01:24:45.740]   Of course, we've always mentioned the fact
[01:24:45.740 --> 01:24:47.020]   you post one son's Zip Recruiter,
[01:24:47.020 --> 01:24:49.100]   it goes to 100 plus job sites.
[01:24:49.100 --> 01:24:51.900]   With one click, gets your job out to the maximum people.
[01:24:51.900 --> 01:24:53.340]   But the other thing Zip Recruiter does,
[01:24:53.340 --> 01:24:55.780]   they find qualified candidates for you.
[01:24:55.780 --> 01:24:58.140]   They're powerful matching technology,
[01:24:58.140 --> 01:25:00.700]   scans thousands of resumes to identify people
[01:25:00.700 --> 01:25:02.460]   with the right skills, education,
[01:25:02.460 --> 01:25:05.580]   and experience and actively invites them
[01:25:05.580 --> 01:25:07.460]   to apply to your job.
[01:25:07.460 --> 01:25:09.140]   You get qualified candidates fast.
[01:25:09.140 --> 01:25:10.060]   It just works.
[01:25:10.060 --> 01:25:13.100]   It's number one rated by employers in the US
[01:25:13.100 --> 01:25:15.980]   from among all the hiring sites on TrustPilot,
[01:25:15.980 --> 01:25:17.220]   over a thousand reviews.
[01:25:17.220 --> 01:25:19.900]   We use it, we use it, and we continue to use it
[01:25:19.900 --> 01:25:22.860]   'cause it's a great way to find the best people.
[01:25:22.860 --> 01:25:24.620]   Figure out who you need to hire
[01:25:24.620 --> 01:25:26.860]   to take your business to the next level in 2019.
[01:25:26.860 --> 01:25:27.940]   And right now,
[01:25:27.940 --> 01:25:31.300]   Twit listeners can try Zip Recruiter free
[01:25:31.300 --> 01:25:35.340]   at our exclusive web address, ziprecruiter.com/twit.
[01:25:35.340 --> 01:25:36.980]   Ziprecruiter.com/twit.
[01:25:36.980 --> 01:25:41.980]   Ziprecruiter.com/twit, the smartest way to hire.
[01:25:41.980 --> 01:25:46.740]   I didn't expect to talk about the 2080 and all of this,
[01:25:46.740 --> 01:25:47.740]   but I'm glad we did.
[01:25:47.740 --> 01:25:50.100]   This is really interesting stuff.
[01:25:50.100 --> 01:25:52.300]   Good review on PC per,
[01:25:52.300 --> 01:25:54.300]   benchmarks and all,
[01:25:54.300 --> 01:25:57.260]   talking about what these new cards do.
[01:25:57.260 --> 01:25:58.660]   And they're only,
[01:25:58.660 --> 01:26:01.220]   oh, I don't know, a couple of thousand bucks.
[01:26:01.220 --> 01:26:04.860]   How much would it cost me to get a 2080?
[01:26:04.860 --> 01:26:06.300]   - A 2080 is $699.
[01:26:06.300 --> 01:26:08.020]   - Oh, some of the cards out there,
[01:26:08.020 --> 01:26:10.300]   like on Newegg or a little bit more.
[01:26:10.300 --> 01:26:12.220]   But I was actually seeing two last night
[01:26:12.220 --> 01:26:14.340]   that we're selling for that 699 retail.
[01:26:14.340 --> 01:26:16.900]   That's the MSRP if I direct from Nvidia.
[01:26:16.900 --> 01:26:18.860]   - So I didn't think Nvidia made cards.
[01:26:18.860 --> 01:26:21.180]   I thought they were like armed fabulous,
[01:26:21.180 --> 01:26:23.580]   but they are now making cards.
[01:26:23.580 --> 01:26:25.300]   - Yeah, I don't know if they're making them.
[01:26:25.300 --> 01:26:26.140]   They do sell them.
[01:26:26.140 --> 01:26:29.740]   They have their own founders edition is what they call it.
[01:26:29.740 --> 01:26:32.020]   And so the card behind me is a founders edition.
[01:26:32.020 --> 01:26:34.020]   That's their new cooler design.
[01:26:34.020 --> 01:26:37.100]   And actually interestingly, AMD is starting
[01:26:37.100 --> 01:26:37.940]   to sell their own cards.
[01:26:37.940 --> 01:26:42.300]   This new Radeon Vegas 7 that they have coming out
[01:26:42.300 --> 01:26:45.420]   is going to be sold on AMD.com
[01:26:45.420 --> 01:26:46.740]   with their own reference design.
[01:26:46.740 --> 01:26:47.580]   So.
[01:26:47.580 --> 01:26:50.740]   - Is there any reason to buy it from them instead of,
[01:26:50.740 --> 01:26:52.420]   I don't know, you know,
[01:26:52.420 --> 01:26:55.580]   somebody else?
[01:26:55.580 --> 01:26:56.420]   - Anyone else?
[01:26:56.420 --> 01:26:59.940]   Yeah, well, I think the reason would be just.
[01:26:59.940 --> 01:27:01.220]   - I was thinking gigabytes, I guess.
[01:27:01.220 --> 01:27:02.180]   - Price.
[01:27:02.180 --> 01:27:04.380]   - I mean, when companies sell directly,
[01:27:04.380 --> 01:27:08.740]   like during last year, during the mining craze,
[01:27:08.740 --> 01:27:12.260]   when you could not find a graphics card if you wanted it.
[01:27:12.260 --> 01:27:14.820]   And when they would show up at retail,
[01:27:14.820 --> 01:27:17.420]   you were seeing crazy prices of $1,000 or more,
[01:27:17.420 --> 01:27:20.420]   like a 1080 from Nvidia.
[01:27:20.420 --> 01:27:22.940]   And then you'd go to Nvidia.com
[01:27:22.940 --> 01:27:24.660]   and they would, for brief windows of time,
[01:27:24.660 --> 01:27:27.220]   have them in stock and you were buying them at just MSRP.
[01:27:27.220 --> 01:27:30.660]   So for things like that, especially if you like,
[01:27:30.660 --> 01:27:32.220]   just the stock reference design,
[01:27:32.220 --> 01:27:34.300]   in the past reference designs for graphics cards,
[01:27:34.300 --> 01:27:36.940]   were pretty bad, very loud,
[01:27:36.940 --> 01:27:39.180]   blower style coolers and things.
[01:27:39.180 --> 01:27:40.340]   They've gotten pretty advanced,
[01:27:40.340 --> 01:27:42.740]   like AMD is showing a three fan,
[01:27:42.740 --> 01:27:46.220]   very kind of nice modern looking cooler.
[01:27:46.220 --> 01:27:48.780]   Nvidia has these nice dual fan coolers that are very quiet.
[01:27:48.780 --> 01:27:52.380]   So if you like the look of these things,
[01:27:52.380 --> 01:27:54.940]   then there's one reason, just aesthetics alone.
[01:27:58.140 --> 01:28:00.700]   Nolan Bush, now we've had him on triangulation.
[01:28:00.700 --> 01:28:02.300]   He drew it, I wonder if we saved that.
[01:28:02.300 --> 01:28:06.100]   He drew a pong on our back wall in the old studio.
[01:28:06.100 --> 01:28:07.660]   I hope somebody saved that.
[01:28:07.660 --> 01:28:11.980]   Now he's making games for the Amazon Echo,
[01:28:11.980 --> 01:28:15.660]   voice activated games.
[01:28:15.660 --> 01:28:20.140]   Mm, hmm.
[01:28:20.140 --> 01:28:21.620]   (laughing)
[01:28:21.620 --> 01:28:23.860]   - The thing is the newscaster voice that we've heard
[01:28:23.860 --> 01:28:28.860]   does not give me faith about games from the Amazon Echo.
[01:28:28.860 --> 01:28:35.620]   Although I saw Ry Chris on Twitter's CNET person
[01:28:35.620 --> 01:28:39.780]   and he does a lot of smart home stuff.
[01:28:39.780 --> 01:28:41.940]   And he, I think he was at this conference
[01:28:41.940 --> 01:28:44.980]   or this meetup or whatever it was.
[01:28:44.980 --> 01:28:47.580]   And I saw some of the stuff coming out of it.
[01:28:47.580 --> 01:28:50.180]   And it did sound interesting.
[01:28:50.180 --> 01:28:51.860]   Some of the things that are being worked on there
[01:28:51.860 --> 01:28:54.780]   and potentially like what the Amazon Echo could do
[01:28:54.780 --> 01:28:57.900]   in the future because I don't know.
[01:28:57.900 --> 01:28:59.660]   There are a lot of people with these devices.
[01:28:59.660 --> 01:29:03.700]   And when we give more features and more fun things
[01:29:03.700 --> 01:29:05.260]   that we can do with them, I think that it helps
[01:29:05.260 --> 01:29:08.060]   the sort of smart speaker market overall.
[01:29:08.060 --> 01:29:10.740]   And it gets people used to having these devices
[01:29:10.740 --> 01:29:14.220]   in their home, which only results in more companies
[01:29:14.220 --> 01:29:16.140]   paying attention to them, which means that I get
[01:29:16.140 --> 01:29:18.020]   to buy new fun smart home tech.
[01:29:18.020 --> 01:29:20.840]   So like it's a good thing all around.
[01:29:20.840 --> 01:29:24.720]   Even if it's just so that kids can play, I don't know,
[01:29:24.720 --> 01:29:29.780]   with a Candyland board games with the Amazon Echo.
[01:29:29.780 --> 01:29:32.540]   - I played Jeopardy and you could play 20 questions.
[01:29:32.540 --> 01:29:34.920]   This sounds, I think there's potential here.
[01:29:34.920 --> 01:29:36.180]   If you really knew what you were doing
[01:29:36.180 --> 01:29:38.900]   and you really thought about the challenges
[01:29:38.900 --> 01:29:40.340]   of a voice assistant.
[01:29:40.340 --> 01:29:43.040]   So the first game that's just gonna come out in March
[01:29:43.040 --> 01:29:47.020]   is called St. Noir.
[01:29:47.020 --> 01:29:50.560]   It's a voice activated murder mystery game.
[01:29:50.560 --> 01:29:52.380]   The challenge is you to solve a murder
[01:29:52.380 --> 01:29:55.280]   by interviewing a full cast of characters.
[01:29:55.280 --> 01:29:58.820]   That sounds kind of interesting, doesn't it?
[01:29:58.820 --> 01:30:01.500]   - The murder is Bruce Wayne's parents, I think.
[01:30:01.500 --> 01:30:02.660]   - Oh, is it?
[01:30:02.660 --> 01:30:03.500]   - Yeah.
[01:30:03.500 --> 01:30:04.780]   - Oh, you're big serial guy.
[01:30:04.780 --> 01:30:07.620]   - No, no, no, there was an earlier game
[01:30:07.620 --> 01:30:09.220]   called the Wayne Investigation,
[01:30:09.220 --> 01:30:10.820]   which was a Batman themed adventure
[01:30:10.820 --> 01:30:13.700]   to let you investigate the murder of Bruce Wayne's parents.
[01:30:13.700 --> 01:30:15.540]   That's already out.
[01:30:15.540 --> 01:30:17.900]   There are Amazon Echo Interactive Toys.
[01:30:17.900 --> 01:30:20.460]   There's an Echo Escape Room Challenge
[01:30:20.460 --> 01:30:22.600]   from Stoked Skills.
[01:30:22.600 --> 01:30:26.960]   My problem is you feel stuck.
[01:30:26.960 --> 01:30:27.800]   - Yeah.
[01:30:27.800 --> 01:30:29.520]   - Like you gotta keep interacting,
[01:30:29.520 --> 01:30:32.040]   but you can't put it down and come back to it.
[01:30:32.040 --> 01:30:33.260]   - Yeah, and also, I don't know,
[01:30:33.260 --> 01:30:36.280]   one of the, I am a little weirded out sometimes
[01:30:36.280 --> 01:30:37.800]   whenever companies are just like,
[01:30:37.800 --> 01:30:40.340]   "Let's throw our product into this experience
[01:30:40.340 --> 01:30:42.280]   "that already exists and it doesn't make sense
[01:30:42.280 --> 01:30:43.400]   "other than to just do it."
[01:30:43.400 --> 01:30:44.520]   - They have to reinvent.
[01:30:44.520 --> 01:30:46.040]   They really have to think of something to do.
[01:30:46.040 --> 01:30:49.040]   - Yeah, because the fun thing about a murder mystery game,
[01:30:49.040 --> 01:30:50.280]   if you're going all out,
[01:30:50.280 --> 01:30:52.320]   it's one of those dinner party things
[01:30:52.320 --> 01:30:53.520]   where everybody dresses up
[01:30:53.520 --> 01:30:55.520]   and everybody has a little character card.
[01:30:55.520 --> 01:30:57.600]   And you're interacting with human beings.
[01:30:57.600 --> 01:30:59.760]   So why would we have just four people
[01:30:59.760 --> 01:31:00.920]   sitting around a board game
[01:31:00.920 --> 01:31:02.520]   and we're all just talking to the Echo
[01:31:02.520 --> 01:31:04.200]   instead of talking to each other?
[01:31:04.200 --> 01:31:06.400]   That kind of takes the fun out
[01:31:06.400 --> 01:31:09.200]   of what a murder mystery game usually is.
[01:31:09.200 --> 01:31:10.040]   - How about this?
[01:31:10.040 --> 01:31:12.160]   So it is a board, no, I'm looking at it.
[01:31:12.160 --> 01:31:14.760]   You buy for 40 bucks, you have to buy the board game,
[01:31:14.760 --> 01:31:16.560]   which is kind of like clue, right?
[01:31:17.720 --> 01:31:22.360]   And then the Echo is a kind of companion
[01:31:22.360 --> 01:31:24.360]   to solving this mystery.
[01:31:24.360 --> 01:31:26.680]   - So this is like a VHS game for a movie.
[01:31:26.680 --> 01:31:28.160]   - Yes, yes.
[01:31:28.160 --> 01:31:29.360]   - Is it replayable?
[01:31:29.360 --> 01:31:32.880]   - Should be, why wouldn't it be?
[01:31:32.880 --> 01:31:34.800]   A VHS shamed has been 40 bucks.
[01:31:34.800 --> 01:31:35.880]   - Exactly.
[01:31:35.880 --> 01:31:37.840]   - And you could play it once.
[01:31:37.840 --> 01:31:40.800]   - I guess they changed the murder every time or something.
[01:31:40.800 --> 01:31:43.240]   - They got five games release,
[01:31:43.240 --> 01:31:45.560]   six games total scheduled for release this year.
[01:31:46.760 --> 01:31:49.320]   - There is also a drinking game.
[01:31:49.320 --> 01:31:50.640]   - Oh.
[01:31:50.640 --> 01:31:53.280]   - Those are like, it doesn't inherently become fun, right?
[01:31:53.280 --> 01:31:54.760]   - I can't play into that.
[01:31:54.760 --> 01:31:55.600]   - Echo?
[01:31:55.600 --> 01:31:57.640]   - Hurry.
[01:31:57.640 --> 01:31:58.480]   - This is fun.
[01:31:58.480 --> 01:31:59.560]   - This is fun.
[01:31:59.560 --> 01:32:02.560]   - What's your name again, Siri?
[01:32:02.560 --> 01:32:03.400]   Oh no.
[01:32:03.400 --> 01:32:04.520]   - Ah, sorry.
[01:32:04.520 --> 01:32:07.960]   - Does this mean that we could get like a chat roulette
[01:32:07.960 --> 01:32:09.720]   for as far as fingers?
[01:32:09.720 --> 01:32:10.560]   - Wouldn't that be interesting?
[01:32:10.560 --> 01:32:11.400]   - Oh God.
[01:32:11.400 --> 01:32:14.400]   - But we're actually not a chat roulette.
[01:32:14.400 --> 01:32:17.400]   - Is that still a deal to do that?
[01:32:17.400 --> 01:32:22.640]   - You know, it may be I'm weird, but I've heard.
[01:32:22.640 --> 01:32:23.480]   - We know that.
[01:32:23.480 --> 01:32:26.640]   - Can do, you know, like voice gaming,
[01:32:26.640 --> 01:32:29.200]   I'm thinking tech space adventures, think about it.
[01:32:29.200 --> 01:32:30.040]   - Yes.
[01:32:30.040 --> 01:32:31.320]   - So to be a dungeon master.
[01:32:31.320 --> 01:32:33.120]   - Proceed, I'm in the bathroom brushing my teeth.
[01:32:33.120 --> 01:32:34.280]   Proceed North.
[01:32:34.280 --> 01:32:35.440]   - You cannot go North.
[01:32:35.440 --> 01:32:36.280]   - All right, ease.
[01:32:36.280 --> 01:32:37.120]   - I love it.
[01:32:37.120 --> 01:32:38.800]   - You encountered the locked door.
[01:32:38.800 --> 01:32:39.960]   - Sebastian, you could write this.
[01:32:39.960 --> 01:32:41.360]   It's not hard to write these.
[01:32:41.360 --> 01:32:44.120]   - There are a couple of those that are like that.
[01:32:44.120 --> 01:32:45.480]   - Yeah, I talked with Megan Rowan,
[01:32:45.480 --> 01:32:47.200]   I think on iOS today.
[01:32:47.200 --> 01:32:48.880]   - "Bandersonic" is the Netflix movie.
[01:32:48.880 --> 01:32:50.760]   Is that what's, I haven't watched it yet,
[01:32:50.760 --> 01:32:53.080]   'cause I'm again, I'm afraid of getting trapped.
[01:32:53.080 --> 01:32:57.240]   - But see in the movies about a choose your own adventure game.
[01:32:57.240 --> 01:33:01.720]   So it would be just like watching a game about a game about it.
[01:33:01.720 --> 01:33:03.400]   - Chat roulette is definitely still a sight.
[01:33:03.400 --> 01:33:04.280]   I didn't realize.
[01:33:04.280 --> 01:33:06.000]   - You just went to chat roulette.
[01:33:06.000 --> 01:33:08.600]   - I did, I guess I was curious.
[01:33:08.600 --> 01:33:13.000]   But so there are a few games I talked to Megan Moroney
[01:33:13.000 --> 01:33:14.200]   before, I think it was in iOS today
[01:33:14.200 --> 01:33:18.560]   about some of the games that are on the Echo.
[01:33:18.560 --> 01:33:20.680]   And there actually are some interesting ones
[01:33:20.680 --> 01:33:24.800]   and pretty good ones that are essentially text-based adventures
[01:33:24.800 --> 01:33:28.400]   where you're sort of, you know, given the option to say,
[01:33:28.400 --> 01:33:29.720]   "Oh, I wanna do this, I wanna do that."
[01:33:29.720 --> 01:33:32.360]   But they're not, I think if it's built, you know,
[01:33:32.360 --> 01:33:34.400]   sort of from Amazon's perspective,
[01:33:34.400 --> 01:33:37.040]   knowing what technologies they have available,
[01:33:37.040 --> 01:33:38.000]   it's gonna be better.
[01:33:38.000 --> 01:33:41.800]   So I wouldn't be, you know, completely against
[01:33:41.800 --> 01:33:42.840]   trying something like this.
[01:33:42.840 --> 01:33:46.000]   I just don't wanna make something less fun
[01:33:46.000 --> 01:33:47.440]   by adding an Echo to it.
[01:33:47.440 --> 01:33:49.200]   Like you said, feeling trapped, I think that was a really good--
[01:33:49.200 --> 01:33:51.440]   - But today's generation is not gonna play Zork.
[01:33:51.440 --> 01:33:53.880]   They're not gonna sit at a command line and type commands.
[01:33:53.880 --> 01:33:58.080]   But I could totally see them saying Echo had Norse
[01:33:58.080 --> 01:33:59.440]   and then hearing a description.
[01:33:59.440 --> 01:34:00.720]   That sounds like fun, actually.
[01:34:00.720 --> 01:34:03.000]   - It's definitely like a time though,
[01:34:03.000 --> 01:34:05.920]   like 15 minutes, 20 minutes, but three hour game.
[01:34:05.920 --> 01:34:07.480]   - Yeah. - I don't think so.
[01:34:07.480 --> 01:34:09.720]   - Well, you should be able to stop and pick it up.
[01:34:09.720 --> 01:34:10.560]   - Yeah.
[01:34:11.920 --> 01:34:13.400]   - Zork was a lot of fun.
[01:34:13.400 --> 01:34:18.160]   You'd have to figure out how to pronounce XYZY and Plug.
[01:34:18.160 --> 01:34:21.920]   - That would be fun. - You just did?
[01:34:21.920 --> 01:34:24.040]   - Oh, that's how you pronounce it.
[01:34:24.040 --> 01:34:27.680]   That's how you pronounce it.
[01:34:27.680 --> 01:34:30.680]   - So when the chat said Echo, go north,
[01:34:30.680 --> 01:34:32.280]   order a case of toilet paper.
[01:34:32.280 --> 01:34:33.520]   (laughing)
[01:34:33.520 --> 01:34:34.360]   - From Amazon.
[01:34:34.360 --> 01:34:37.320]   - You can do it all!
[01:34:37.320 --> 01:34:38.840]   Shop.
[01:34:38.840 --> 01:34:40.080]   - Yeah, you pause in the middle of your
[01:34:40.080 --> 01:34:41.320]   choose your own adventure game.
[01:34:41.320 --> 01:34:43.360]   You just wanna get some new dog treats
[01:34:43.360 --> 01:34:45.200]   and then it's like, oh no, sorry,
[01:34:45.200 --> 01:34:46.960]   that is not a command in this game.
[01:34:46.960 --> 01:34:50.600]   - So I bet there would be like interstitial advertising,
[01:34:50.600 --> 01:34:52.360]   like right in the middle of your game.
[01:34:52.360 --> 01:34:55.120]   So sudden, you know, I'm going east
[01:34:55.120 --> 01:34:59.120]   and also on sale this week on amazon.com.
[01:34:59.120 --> 01:35:01.280]   - Have you seen the new man in the high tower
[01:35:01.280 --> 01:35:03.840]   or is it Castle, whatever the show?
[01:35:03.840 --> 01:35:05.680]   - No, it's a good? - Yeah.
[01:35:05.680 --> 01:35:07.280]   - Oh, you're saying that's the end.
[01:35:07.280 --> 01:35:08.920]   See, you're such a good-- - That's how she writes.
[01:35:08.920 --> 01:35:11.600]   - I can't tell the difference between content.
[01:35:11.600 --> 01:35:14.480]   - 90% of podcasts, those can't tell a different screen.
[01:35:14.480 --> 01:35:15.480]   (laughing)
[01:35:15.480 --> 01:35:18.080]   - An ad. - At least 25%.
[01:35:18.080 --> 01:35:19.080]   - And they're gonna use your voice
[01:35:19.080 --> 01:35:21.440]   for these games for training.
[01:35:21.440 --> 01:35:22.680]   - Yeah, of course they are.
[01:35:22.680 --> 01:35:25.040]   - That's the thing why the 10 year challenge thing,
[01:35:25.040 --> 01:35:26.360]   even if Facebook's not doing that,
[01:35:26.360 --> 01:35:29.160]   every bit of data you give any of these companies
[01:35:29.160 --> 01:35:31.740]   is grist for the mill, they use it all.
[01:35:31.740 --> 01:35:35.400]   I'm sorry, go ahead, I didn't mean to cut you off, Micah.
[01:35:35.400 --> 01:35:37.160]   - I was doing another, I said,
[01:35:37.160 --> 01:35:38.920]   have you seen the new Zippra cruder website?
[01:35:38.920 --> 01:35:40.920]   - No, I haven't, where is it?
[01:35:40.920 --> 01:35:42.600]   Oh, I'm sorry.
[01:35:42.600 --> 01:35:45.280]   I get sucked in by that stuff.
[01:35:45.280 --> 01:35:47.320]   - You know, YouTube does that when you play a video,
[01:35:47.320 --> 01:35:49.080]   sometimes you get a survey instead of an ad
[01:35:49.080 --> 01:35:51.720]   and says, have you seen advertisements for XYZ
[01:35:51.720 --> 01:35:53.320]   or whatever the show's thinking?
[01:35:53.320 --> 01:35:55.280]   See how effective they're online advertising?
[01:35:55.280 --> 01:35:57.000]   - They have to be really careful with that.
[01:35:57.000 --> 01:36:00.640]   They really is a fine line between annoying
[01:36:00.640 --> 01:36:03.320]   and something you could tolerate.
[01:36:03.320 --> 01:36:06.200]   - Yeah, but since Amazon is getting
[01:36:06.200 --> 01:36:08.160]   into the ad business where a lot more
[01:36:08.160 --> 01:36:10.360]   of the revenue is from ads,
[01:36:10.360 --> 01:36:12.720]   I wouldn't be surprised if they did something like this.
[01:36:12.720 --> 01:36:18.720]   - Here's an alert from Microsoft.
[01:36:18.720 --> 01:36:20.920]   If you're still using Windows 10 mobile,
[01:36:20.920 --> 01:36:24.280]   you should switch immediately to iPhone or Android.
[01:36:24.280 --> 01:36:26.320]   - Yeah. - I'm sorry.
[01:36:26.320 --> 01:36:29.120]   Somebody apparently is, Microsoft says,
[01:36:29.120 --> 01:36:30.600]   they're gonna kill off support.
[01:36:30.600 --> 01:36:35.880]   December of 2019, oh, well, you got some time.
[01:36:35.880 --> 01:36:38.240]   - Yeah, this, you know, maybe something will happen.
[01:36:38.240 --> 01:36:40.920]   It'll come back before December.
[01:36:40.920 --> 01:36:42.960]   - Wow. - We get popular again.
[01:36:42.960 --> 01:36:43.800]   - That's kind of sad.
[01:36:43.800 --> 01:36:46.520]   Windows Phone actually was really, I thought,
[01:36:46.520 --> 01:36:51.520]   innovative clever and it's a shame that it didn't succeed.
[01:36:51.520 --> 01:36:55.880]   But so Paul Thorett caught this one.
[01:36:55.880 --> 01:37:02.520]   A change to the, of course, the headline
[01:37:02.520 --> 01:37:04.400]   in typical Thorett style,
[01:37:04.400 --> 01:37:07.320]   Windows 10 mobile is dead dead.
[01:37:07.320 --> 01:37:09.600]   And then I don't know what this picture means.
[01:37:09.600 --> 01:37:14.520]   - Those are several different memes all together
[01:37:14.520 --> 01:37:16.680]   and one and they're used, those are like shocked memes.
[01:37:16.680 --> 01:37:18.000]   So they're all like, what?
[01:37:18.000 --> 01:37:19.440]   - What? - Oh, I get it.
[01:37:19.440 --> 01:37:20.600]   I get it.
[01:37:20.600 --> 01:37:24.400]   So Pikachu and Care Bear and the girl and the monkey.
[01:37:24.400 --> 01:37:26.320]   - I think that's Jerry, the mouse.
[01:37:26.320 --> 01:37:27.680]   - Jerry, the mouse?
[01:37:27.680 --> 01:37:29.440]   Oh, I've Tom and Jerry.
[01:37:29.440 --> 01:37:31.880]   - Yeah. - Boy, he has a drinking
[01:37:31.880 --> 01:37:32.720]   problem or something.
[01:37:32.720 --> 01:37:34.680]   - He was playing that echo game.
[01:37:34.680 --> 01:37:36.040]   - Yeah, hey, I'm Jerry.
[01:37:36.040 --> 01:37:36.880]   You should be Jerry.
[01:37:36.880 --> 01:37:39.760]   You remember me with Tom?
[01:37:39.760 --> 01:37:43.000]   - That guy, he's the one who's the fake shock.
[01:37:43.000 --> 01:37:44.000]   - That was Jerry.
[01:37:44.000 --> 01:37:48.120]   And the girl is, that's famous too.
[01:37:48.120 --> 01:37:50.480]   Oh, this is like the X factor, I get it, I get it.
[01:37:50.480 --> 01:37:52.720]   - Yeah, and they're all kind of like fake shocked.
[01:37:52.720 --> 01:37:54.840]   So it's like, you shouldn't be shocked by this,
[01:37:54.840 --> 01:37:56.920]   but you are, those are the different memes there.
[01:37:56.920 --> 01:37:59.560]   - This is why we need millennials around to explain stuff.
[01:37:59.560 --> 01:38:00.720]   - This is why you can't replace me
[01:38:00.720 --> 01:38:01.720]   at the ZipperKruder host.
[01:38:01.720 --> 01:38:02.920]   - I need you.
[01:38:02.920 --> 01:38:03.760]   - Yes.
[01:38:03.760 --> 01:38:05.200]   - That's like when I hear like a celebrity die
[01:38:05.200 --> 01:38:06.600]   and we're like, they were still alive.
[01:38:06.600 --> 01:38:08.240]   (laughing)
[01:38:08.240 --> 01:38:10.120]   - Someday that'll be me, Wesley.
[01:38:10.120 --> 01:38:13.160]   - Leah was still alive?
[01:38:13.160 --> 01:38:14.000]   - Yeah.
[01:38:14.000 --> 01:38:14.840]   - Someday.
[01:38:14.840 --> 01:38:19.320]   I don't know, now you heard the warning
[01:38:19.320 --> 01:38:24.040]   and we did see you and Sebastian, you and Patrick
[01:38:24.040 --> 01:38:28.760]   talking about Cortana giving up as well.
[01:38:28.760 --> 01:38:29.600]   - Yeah.
[01:38:29.600 --> 01:38:32.520]   - You know, I was one of those people who jumped on
[01:38:32.520 --> 01:38:35.000]   Windows Phone, when the really nice Lumia phones
[01:38:35.000 --> 01:38:38.360]   started coming out and I think it was a Lumia 900,
[01:38:38.360 --> 01:38:41.480]   I bought one of those, I jumped off iOS
[01:38:41.480 --> 01:38:46.480]   and went to Windows Mobile and it was okay at first
[01:38:46.480 --> 01:38:49.320]   and there was the promise of all these apps
[01:38:49.320 --> 01:38:50.840]   that were gonna be coming like, okay,
[01:38:50.840 --> 01:38:52.760]   I'm gonna be getting eBay, I'm gonna be getting this,
[01:38:52.760 --> 01:38:55.320]   I'm gonna be getting that and I'll have everything I need.
[01:38:55.320 --> 01:38:58.000]   And then one of the areas that never really came
[01:38:58.000 --> 01:39:01.480]   was like chat app support, back when HipChat was still
[01:39:01.480 --> 01:39:04.320]   more widely used before Slack kinda took over
[01:39:04.320 --> 01:39:06.640]   and I was waiting for like that kind of support
[01:39:06.640 --> 01:39:09.120]   which never came and then eBay was released
[01:39:09.120 --> 01:39:11.280]   but then never updated it and then like six or eight
[01:39:11.280 --> 01:39:13.320]   months later, so it wasn't updated.
[01:39:13.320 --> 01:39:15.760]   And I finally just left, like I love the interface,
[01:39:15.760 --> 01:39:18.840]   I loved the tiles, like I could organize it
[01:39:18.840 --> 01:39:21.320]   exactly how it seemed to make the most sense to me
[01:39:21.320 --> 01:39:24.280]   for like one-handed use, having like the size
[01:39:24.280 --> 01:39:25.680]   and the location of the tiles wherever I wanted
[01:39:25.680 --> 01:39:28.720]   on the screen, which you couldn't do with Android or iOS
[01:39:28.720 --> 01:39:32.000]   and there wasn't good app support,
[01:39:32.000 --> 01:39:33.760]   there never was good app support
[01:39:33.760 --> 01:39:36.840]   and Microsoft was paying developers to make
[01:39:36.840 --> 01:39:40.480]   these keystone apps like Instagram and--
[01:39:40.480 --> 01:39:42.560]   - They extended pay people, they had to pay them.
[01:39:42.560 --> 01:39:44.800]   - And then they weren't paying them to keep them updated
[01:39:44.800 --> 01:39:46.640]   like, okay, we made the app, here it is
[01:39:46.640 --> 01:39:48.480]   and then they would just sit there for a year
[01:39:48.480 --> 01:39:51.360]   without an update, without feature updates.
[01:39:51.360 --> 01:39:54.520]   So it's sad but it's--
[01:39:54.520 --> 01:39:56.320]   - It makes perfect sense to me,
[01:39:56.320 --> 01:39:58.960]   'cause they just, if they'd had the app support,
[01:39:58.960 --> 01:40:02.440]   at some point a mobile phone is just a platform for apps
[01:40:02.440 --> 01:40:06.680]   and I can go between iOS and Android seamlessly
[01:40:06.680 --> 01:40:08.760]   for the most part, I mean there's the whole
[01:40:08.760 --> 01:40:11.640]   iMessage thing but as far as apps go,
[01:40:11.640 --> 01:40:13.960]   they're basically a parody at this point,
[01:40:13.960 --> 01:40:17.480]   a lot of the major apps are just about the same
[01:40:17.480 --> 01:40:22.080]   on either platform but we have platforms that really did
[01:40:22.080 --> 01:40:26.800]   a lot with UI, actual usability, user experience,
[01:40:26.800 --> 01:40:31.440]   like Palm and Windows Phone
[01:40:31.440 --> 01:40:34.560]   and now we have elements of Palm at least live on
[01:40:34.560 --> 01:40:38.480]   with the iPhone 10 where you have the gesture based
[01:40:38.480 --> 01:40:40.040]   interface and sliding up from the bottom,
[01:40:40.040 --> 01:40:41.480]   that's all stuff we saw with the Palm 3G.
[01:40:41.480 --> 01:40:42.320]   - That's true isn't it?
[01:40:42.320 --> 01:40:44.560]   Yeah, it's one of the reasons I like the Pre so much.
[01:40:44.560 --> 01:40:46.440]   I like the Prewiz. - Yeah, the Prewiz.
[01:40:46.440 --> 01:40:48.680]   - Yeah, the Prewiz. - But--
[01:40:48.680 --> 01:40:51.480]   - Although doesn't it live on in some teavs,
[01:40:51.480 --> 01:40:52.920]   who is it, LG, the bottom of the Palm?
[01:40:52.920 --> 01:40:55.680]   - LG has WebOS supposedly.
[01:40:55.680 --> 01:40:59.080]   It has like these cards at the bottom of the screen
[01:40:59.080 --> 01:41:01.080]   like a flip up but it's not the same.
[01:41:01.080 --> 01:41:02.080]   You need touch.
[01:41:02.080 --> 01:41:07.560]   - I gotta say as the old social media manager
[01:41:07.560 --> 01:41:10.400]   for HipChat, you guys were extremely vocal
[01:41:10.400 --> 01:41:13.800]   in terms of your demand for Windows 10 apps,
[01:41:13.800 --> 01:41:15.440]   sorry, Windows mobile apps.
[01:41:15.440 --> 01:41:17.440]   - Yeah, I probably want to vote people.
[01:41:17.440 --> 01:41:20.080]   - I used to get tweets on that every single day,
[01:41:20.080 --> 01:41:22.000]   when's the app coming, when's the app coming?
[01:41:22.000 --> 01:41:24.680]   - Did HipChat not have a Windows phone app?
[01:41:24.680 --> 01:41:27.280]   - We eventually made a beta something port
[01:41:27.280 --> 01:41:28.840]   or something like that. - Was it hard?
[01:41:28.840 --> 01:41:29.880]   Why didn't you?
[01:41:29.880 --> 01:41:34.440]   - The market share wasn't there.
[01:41:34.440 --> 01:41:36.320]   Even though the people were vocal,
[01:41:36.320 --> 01:41:39.640]   they just didn't care about it to even make something
[01:41:39.640 --> 01:41:43.440]   that was possible. - That's a common problem.
[01:41:43.440 --> 01:41:45.920]   People fall for the vocal minority,
[01:41:45.920 --> 01:41:49.040]   but it's 10 people just making a lot of noise,
[01:41:49.040 --> 01:41:50.160]   especially with social media,
[01:41:50.160 --> 01:41:53.000]   you can really amplify 10 people now.
[01:41:53.000 --> 01:41:56.040]   And it'd be easy to be fooled by that.
[01:41:56.040 --> 01:41:59.360]   - Amplify 10 people to do the TidePod challenge.
[01:41:59.360 --> 01:42:00.440]   - Oh God.
[01:42:00.440 --> 01:42:03.400]   Are you sad about HipChat kind of going away,
[01:42:03.400 --> 01:42:05.840]   being sucked up and absorbed by Slack?
[01:42:05.840 --> 01:42:08.680]   - In a way, yes, but you know,
[01:42:08.680 --> 01:42:10.680]   they just wrote out a new logo.
[01:42:10.680 --> 01:42:12.360]   And with that announcement,
[01:42:12.360 --> 01:42:15.440]   they pledge a simpler UI.
[01:42:15.440 --> 01:42:19.000]   - Everybody's so unhappy with the new Slack icon.
[01:42:19.160 --> 01:42:20.760]   - I was hoping we were gonna talk about that.
[01:42:20.760 --> 01:42:22.080]   - That's like people were so bad.
[01:42:22.080 --> 01:42:23.280]   We should mention Slack's a sponsor.
[01:42:23.280 --> 01:42:25.240]   HipChat was a sponsor, Atlassian's a sponsor.
[01:42:25.240 --> 01:42:26.600]   You're all sponsors.
[01:42:26.600 --> 01:42:29.520]   But you know, this new, I don't know,
[01:42:29.520 --> 01:42:30.760]   can you see this new,
[01:42:30.760 --> 01:42:33.860]   it's like people are upset about the icon.
[01:42:33.860 --> 01:42:36.040]   Like that's-- - That's 'cause humans
[01:42:36.040 --> 01:42:38.760]   don't like change and everyone says they love change
[01:42:38.760 --> 01:42:40.840]   and I like it when things are dynamic and things change,
[01:42:40.840 --> 01:42:44.200]   but nobody really, like it's not at our base in states
[01:42:44.200 --> 01:42:47.240]   to enjoy change. - It's just an icon.
[01:42:47.240 --> 01:42:48.880]   - Right. - Although having said that,
[01:42:48.880 --> 01:42:49.840]   why change it?
[01:42:49.840 --> 01:42:52.520]   - Oh, apparently they're about to go--
[01:42:52.520 --> 01:42:53.360]   - Well, apparently they're about to go--
[01:42:53.360 --> 01:42:55.840]   - We said the new commitment to everything and yeah.
[01:42:55.840 --> 01:42:58.520]   - They're going public and they're like,
[01:42:58.520 --> 01:42:59.760]   I guess freshening it up.
[01:42:59.760 --> 01:43:01.800]   I don't know why you wouldn't want that.
[01:43:01.800 --> 01:43:05.320]   Like why wouldn't you go with what people know?
[01:43:05.320 --> 01:43:06.160]   If you already had the brand, I didn't--
[01:43:06.160 --> 01:43:08.440]   - It looks like Smurfs sweat.
[01:43:08.440 --> 01:43:10.240]   - Well, so it was a legitimate, you know,
[01:43:10.240 --> 01:43:13.040]   the reasoning behind it was especially because
[01:43:13.040 --> 01:43:14.760]   of the way that the logo was set up.
[01:43:14.760 --> 01:43:17.080]   But I think they said that I had like 16 different colors
[01:43:17.080 --> 01:43:19.720]   in it because of the overlaying bands.
[01:43:19.720 --> 01:43:23.560]   And then also there was no complete and like,
[01:43:23.560 --> 01:43:25.360]   they didn't have a place where you could go and say,
[01:43:25.360 --> 01:43:27.800]   okay, this is exactly what I'm supposed to do with the logo.
[01:43:27.800 --> 01:43:28.880]   And this is how it's set up.
[01:43:28.880 --> 01:43:32.000]   And so depending on who was putting the logo where
[01:43:32.000 --> 01:43:34.600]   and what, it all looked very different.
[01:43:34.600 --> 01:43:36.800]   And so they were trying to sort of bring things in
[01:43:36.800 --> 01:43:39.760]   and make a standard design. - That is true.
[01:43:39.760 --> 01:43:40.600]   - Yeah. - And pull it in
[01:43:40.600 --> 01:43:41.440]   and make it easier.
[01:43:41.440 --> 01:43:42.440]   So like I understand that,
[01:43:42.440 --> 01:43:44.240]   and yeah, with it going public, that makes sense.
[01:43:44.240 --> 01:43:47.480]   - That's a challenge with the Twit logo.
[01:43:47.480 --> 01:43:49.840]   I had good advice, thank you, from designers who said,
[01:43:49.840 --> 01:43:51.760]   now you make sure it looks good in all sizes
[01:43:51.760 --> 01:43:54.720]   that you could stitch it on a hat, you know,
[01:43:54.720 --> 01:43:55.920]   that you could put it on a T-shirt.
[01:43:55.920 --> 01:43:58.040]   Those are things you really, and I bet you slack,
[01:43:58.040 --> 01:44:00.480]   they just said, oh, this is pretty, which it was,
[01:44:00.480 --> 01:44:01.480]   but they weren't thinking about--
[01:44:01.480 --> 01:44:03.240]   - And it was before it was public.
[01:44:03.240 --> 01:44:05.560]   I mean, like it was, they made it before
[01:44:05.560 --> 01:44:07.920]   the app was finished, I think they said.
[01:44:07.920 --> 01:44:10.880]   So the logo was sort of put together just on a whim
[01:44:10.880 --> 01:44:12.400]   and it sort of came second.
[01:44:12.400 --> 01:44:15.200]   But yeah, so like I understand the change,
[01:44:15.200 --> 01:44:19.480]   but anytime, I remember whenever the Twitter changed
[01:44:19.480 --> 01:44:23.480]   from a star to a heart, or when the typeface changes
[01:44:23.480 --> 01:44:25.200]   in an app or what have you.
[01:44:25.200 --> 01:44:27.600]   Yeah, it's just like, we don't like that change
[01:44:27.600 --> 01:44:29.400]   'cause we're used to what it was before.
[01:44:29.400 --> 01:44:31.480]   There are some legitimate critiques of it,
[01:44:31.480 --> 01:44:32.880]   and I understood those, but yeah,
[01:44:32.880 --> 01:44:35.520]   the rage always seems to come forth and it's kind of funny.
[01:44:35.520 --> 01:44:37.240]   - Yeah, but they're gonna be like,
[01:44:37.240 --> 01:44:39.760]   totally hold my beer when they change the app,
[01:44:39.760 --> 01:44:41.400]   because if you're mad about their logo,
[01:44:41.400 --> 01:44:42.960]   they're gonna be changing their interface.
[01:44:42.960 --> 01:44:45.640]   And it's apparent that Microsoft Teams
[01:44:45.640 --> 01:44:48.880]   is really starting to get market share.
[01:44:48.880 --> 01:44:51.720]   And so they are gonna try to reposition their app
[01:44:51.720 --> 01:44:54.840]   to be simpler, easier to navigate and to more people.
[01:44:54.840 --> 01:44:56.360]   - So they feel challenged by Teams.
[01:44:56.360 --> 01:45:01.360]   Now Teams does have some features that missing that Slack has,
[01:45:01.360 --> 01:45:04.800]   but apparently the adoption on Teams has been phenomenal
[01:45:04.800 --> 01:45:06.080]   'cause it's free.
[01:45:06.080 --> 01:45:07.680]   - Yeah. - And Slack has a free tier,
[01:45:07.680 --> 01:45:10.080]   but, and you think it's simpler?
[01:45:10.080 --> 01:45:11.240]   - Yeah, it's easier to use.
[01:45:11.240 --> 01:45:13.840]   It's just, because it is limited in features,
[01:45:13.840 --> 01:45:15.440]   I guess that's why.
[01:45:15.440 --> 01:45:18.600]   It feels like Slack's been built by committee
[01:45:18.600 --> 01:45:21.240]   from their users, which is a good thing in terms of adoption,
[01:45:21.240 --> 01:45:23.920]   but now that they're going to the masses,
[01:45:23.920 --> 01:45:26.840]   they're like people are being confused by the interface
[01:45:26.840 --> 01:45:28.200]   and don't know how to use it,
[01:45:28.200 --> 01:45:29.680]   because they haven't been there from the beginning.
[01:45:29.680 --> 01:45:31.480]   It's like if you picked up an iPhone today
[01:45:31.480 --> 01:45:34.200]   as opposed to an iPhone from when they first came out,
[01:45:34.200 --> 01:45:36.960]   and you follow them through all their iterations,
[01:45:36.960 --> 01:45:39.720]   you kind of get graduated from one level to the next.
[01:45:39.720 --> 01:45:42.440]   And so it makes sense as they add more features,
[01:45:42.440 --> 01:45:45.320]   but once you're trying to be introduced to a new audience,
[01:45:45.320 --> 01:45:47.120]   it seems like there's a lot there.
[01:45:47.120 --> 01:45:48.480]   So it's that equivalent.
[01:45:48.480 --> 01:45:49.600]   - What does IBM use?
[01:45:49.600 --> 01:45:51.140]   Don't say lotus notes.
[01:45:51.140 --> 01:45:55.680]   - So we have same time, which is built in-house.
[01:45:55.680 --> 01:45:57.480]   - It's in in-house app, okay.
[01:45:57.480 --> 01:46:01.600]   - But it just got sold off to another company, I believe.
[01:46:01.600 --> 01:46:03.160]   But we also use Slack.
[01:46:03.160 --> 01:46:04.160]   - I love Slack.
[01:46:04.160 --> 01:46:06.980]   We looked at, so when HipChat went away,
[01:46:06.980 --> 01:46:10.880]   we looked at Teams, we looked at a bunch of stuff.
[01:46:10.880 --> 01:46:14.900]   We looked at Matrix Riot, which is an open source.
[01:46:14.900 --> 01:46:17.540]   You run your own Matrix server and Riot's the client.
[01:46:17.540 --> 01:46:21.460]   We looked at Slack, and everybody really wanted to use Slack.
[01:46:21.460 --> 01:46:25.460]   I mean, what Slack has going for it is people love it.
[01:46:25.460 --> 01:46:26.300]   - Yeah.
[01:46:26.300 --> 01:46:28.260]   - Even in like personal aspects,
[01:46:28.260 --> 01:46:33.020]   it's not just for Teams that are companies working on things.
[01:46:33.020 --> 01:46:35.780]   The plenty of people have created Slack's just
[01:46:35.780 --> 01:46:38.500]   to hang out with their friends from all over.
[01:46:38.500 --> 01:46:40.400]   - Interesting.
[01:46:40.400 --> 01:46:42.740]   So Teams is gonna be a threat.
[01:46:42.740 --> 01:46:46.020]   And now you know something, Wesley, about the redesign
[01:46:46.020 --> 01:46:47.940]   that I didn't know about or is just-
[01:46:47.940 --> 01:46:50.580]   - It was in their announcement about the logo.
[01:46:50.580 --> 01:46:52.420]   They're talking about they're gonna be changing their interface.
[01:46:52.420 --> 01:46:53.580]   - Interesting.
[01:46:53.580 --> 01:46:55.620]   Snapchat, you do that at your peril.
[01:46:55.620 --> 01:46:58.420]   Remember Snapchat, I think really took a hit
[01:46:58.420 --> 01:46:59.260]   from the redesign.
[01:46:59.260 --> 01:47:00.100]   People hate it.
[01:47:00.100 --> 01:47:00.940]   - Yeah, I think that was especially
[01:47:00.940 --> 01:47:03.740]   'cause celebrities got involved and said,
[01:47:03.740 --> 01:47:05.140]   "Oh, I hate the way that it looks now
[01:47:05.140 --> 01:47:06.700]   "and I'm not using it ever again."
[01:47:06.700 --> 01:47:07.540]   - Is that Courtney?
[01:47:07.540 --> 01:47:09.500]   - That Kardashian.
[01:47:09.500 --> 01:47:10.340]   - I was thinking of-
[01:47:10.340 --> 01:47:11.740]   - Chloe.
[01:47:11.740 --> 01:47:12.900]   - I was thinking of, I think,
[01:47:12.900 --> 01:47:14.780]   didn't Rihanna say no to-
[01:47:14.780 --> 01:47:15.860]   - Rihanna, well, they're-
[01:47:15.860 --> 01:47:17.180]   - No, Rihanna, Rihanna.
[01:47:17.180 --> 01:47:18.020]   - Rihanna.
[01:47:18.020 --> 01:47:19.460]   (laughing)
[01:47:19.460 --> 01:47:21.180]   - Rihanna, I don't know that.
[01:47:21.180 --> 01:47:24.940]   - Someone in the chat room said you're Mille'splaining,
[01:47:24.940 --> 01:47:27.140]   you're Millennium'splaining to me.
[01:47:27.140 --> 01:47:29.220]   I need to be Mille'splaining.
[01:47:29.220 --> 01:47:30.060]   - Mille'splaining.
[01:47:30.060 --> 01:47:30.900]   - Mille'splaining.
[01:47:30.900 --> 01:47:31.740]   - Mille'splaining.
[01:47:31.740 --> 01:47:33.100]   - I can't remember who it was, but perhaps one
[01:47:33.100 --> 01:47:34.740]   of the Kardashians did, I have no idea.
[01:47:34.740 --> 01:47:38.260]   But whenever the celebrities hop on that and say,
[01:47:38.260 --> 01:47:40.180]   "Oh, I don't like this thing,"
[01:47:40.180 --> 01:47:43.020]   then there are people who follow and suit.
[01:47:43.020 --> 01:47:46.740]   And the fact is Snapchat has never made any sense ever.
[01:47:46.740 --> 01:47:49.620]   So I don't like them changing the way that the app
[01:47:49.620 --> 01:47:50.860]   was set up, it's just like, "Oh, well,
[01:47:50.860 --> 01:47:52.820]   "this is just another thing that I don't understand how to-"
[01:47:52.820 --> 01:47:54.260]   - I thought it was an intentional feature
[01:47:54.260 --> 01:47:58.140]   that they figured the best way to go viral with an app
[01:47:58.140 --> 01:48:00.500]   is to make it completely opaque on how to use it.
[01:48:00.500 --> 01:48:02.820]   But the one kid who figured out how to use it
[01:48:02.820 --> 01:48:03.900]   would get all this status
[01:48:03.900 --> 01:48:05.500]   by showing all his friends,
[01:48:05.500 --> 01:48:07.860]   and then they'd get status by showing their friends
[01:48:07.860 --> 01:48:09.180]   and it would make it go viral.
[01:48:09.180 --> 01:48:12.180]   I thought it was like a brilliant marketing ploy.
[01:48:12.180 --> 01:48:14.900]   But maybe not. - That's clever.
[01:48:14.900 --> 01:48:21.220]   I know that whenever, 'cause like the,
[01:48:21.220 --> 01:48:23.300]   when I started working at iMoor,
[01:48:23.300 --> 01:48:25.140]   the way that I got that job was actually writing
[01:48:25.140 --> 01:48:27.300]   this huge guide on Snapchat.
[01:48:27.300 --> 01:48:29.220]   - You Mille and Blaine Snapchat.
[01:48:29.220 --> 01:48:30.060]   - I had to.
[01:48:30.060 --> 01:48:32.620]   - I had to, I had to Mille explain it to myself though,
[01:48:32.620 --> 01:48:34.540]   'cause I hadn't really used the app before.
[01:48:34.540 --> 01:48:36.660]   And so I asked some of my friends
[01:48:36.660 --> 01:48:37.940]   who were regular Snapchat users,
[01:48:37.940 --> 01:48:39.580]   like, "Hey, am I forgetting anything?"
[01:48:39.580 --> 01:48:41.700]   And they're like, "Yeah, they're like all of these other things."
[01:48:41.700 --> 01:48:42.820]   - There's all this stuff.
[01:48:42.820 --> 01:48:44.980]   - Gestures, I'm like, "What the heck?"
[01:48:44.980 --> 01:48:45.820]   - Yeah.
[01:48:45.820 --> 01:48:48.900]   So the old Slack logo,
[01:48:48.900 --> 01:48:50.660]   and now I'm kind of obsessed by this,
[01:48:50.660 --> 01:48:52.260]   looked like the hashtag.
[01:48:52.260 --> 01:48:54.300]   It was like a number sign.
[01:48:54.300 --> 01:48:56.940]   And now it looks like, I'm telling you, Smurf Sweat,
[01:48:56.940 --> 01:48:58.860]   it looks like, I don't know what's going on.
[01:48:58.860 --> 01:49:02.580]   It's, I can't, but again,
[01:49:02.580 --> 01:49:03.940]   it's just a logo, guys.
[01:49:03.940 --> 01:49:06.220]   I don't, I don't really,
[01:49:06.220 --> 01:49:09.820]   but I understand why people get upset when change happens.
[01:49:09.820 --> 01:49:11.820]   So it'll be interesting to watch,
[01:49:11.820 --> 01:49:14.020]   "Oh, here's their original,
[01:49:14.020 --> 01:49:16.460]   "this is the problem that you were talking about."
[01:49:16.460 --> 01:49:17.540]   It just looks different.
[01:49:17.540 --> 01:49:18.380]   - Like, partially true.
[01:49:18.380 --> 01:49:20.740]   - And nobody can reproduce it.
[01:49:20.740 --> 01:49:22.980]   That is a good point, yeah.
[01:49:22.980 --> 01:49:24.020]   Yeah.
[01:49:24.020 --> 01:49:25.580]   Okay, that makes sense.
[01:49:25.580 --> 01:49:28.620]   - And how say those images there,
[01:49:28.620 --> 01:49:31.220]   like what different people as in the team have done,
[01:49:31.220 --> 01:49:33.740]   and you go, what you can go in.
[01:49:33.740 --> 01:49:35.220]   - But see, here's the interesting thing.
[01:49:35.220 --> 01:49:36.660]   I didn't read this blog post.
[01:49:36.660 --> 01:49:38.660]   I just saw, all one day I woke up
[01:49:38.660 --> 01:49:40.700]   and my phone looked different.
[01:49:40.700 --> 01:49:42.820]   And that's all, I didn't, I didn't,
[01:49:42.820 --> 01:49:44.220]   you can write this, but nobody's,
[01:49:44.220 --> 01:49:47.540]   I mean, you have to somehow mill-spline it to everybody.
[01:49:47.540 --> 01:49:48.620]   (laughing)
[01:49:48.620 --> 01:49:50.420]   I love this new term.
[01:49:50.420 --> 01:49:52.780]   By the way, at the end of the blog post, TLDR,
[01:49:52.780 --> 01:49:54.140]   we changed the logo.
[01:49:54.140 --> 01:49:56.400]   (laughing)
[01:49:56.400 --> 01:50:00.860]   But TLDRs go, the top kids just saying,
[01:50:00.860 --> 01:50:03.260]   - They didn't have a bill to explain it.
[01:50:03.260 --> 01:50:05.340]   - They didn't have a bill to explain it.
[01:50:05.340 --> 01:50:07.900]   That is, Micah Sargent, we're gonna get you to reboot,
[01:50:07.900 --> 01:50:10.780]   Micah, you're, I don't know what happens to your internet.
[01:50:10.780 --> 01:50:12.220]   Maybe your neighbors are watching
[01:50:12.220 --> 01:50:14.980]   a Bander Snatch or something, I don't know.
[01:50:14.980 --> 01:50:17.260]   There's something, oh, it's like, oh,
[01:50:17.260 --> 01:50:19.660]   it's degrading fast.
[01:50:19.660 --> 01:50:22.660]   Micah is at chihuahua.coffee.
[01:50:22.660 --> 01:50:23.980]   And we love having him on the show,
[01:50:23.980 --> 01:50:25.220]   whenever we can get him.
[01:50:25.220 --> 01:50:26.980]   Sebastian Peake is our newest player.
[01:50:26.980 --> 01:50:29.100]   He's the host of, this week in Computer Hardware
[01:50:29.100 --> 01:50:32.860]   with Patrick Norton, EIC, Editor-in-Chief at PC Perspective.
[01:50:32.860 --> 01:50:35.620]   Thrilled to have you, thank you for joining us, Sebastian.
[01:50:35.620 --> 01:50:36.620]   - Thank you, glad to be here.
[01:50:36.620 --> 01:50:39.940]   - And from Austin, Texas, he works at IBM
[01:50:39.940 --> 01:50:41.060]   and Developer Relations.
[01:50:41.060 --> 01:50:43.860]   This is good, this is, it's like the dating game.
[01:50:43.860 --> 01:50:46.060]   I'm introducing Bachelor Number Three,
[01:50:46.060 --> 01:50:49.260]   coming to us from Austin, Texas, Wesley Faulkner.
[01:50:49.260 --> 01:50:51.340]   (laughing)
[01:50:51.340 --> 01:50:52.900]   I show that they brought to you by
[01:50:52.900 --> 01:50:55.340]   my new favorite VPN, ExpressVPN.
[01:50:55.340 --> 01:50:56.980]   I know a lot of you are in a quest
[01:50:56.980 --> 01:50:59.060]   to find a virtual private network,
[01:50:59.060 --> 01:51:03.660]   a way to surf securely, safely, privately,
[01:51:03.660 --> 01:51:05.380]   whether you're in an open Wi-Fi access spot,
[01:51:05.380 --> 01:51:07.740]   even from home, 'cause you know your ISP's
[01:51:07.740 --> 01:51:11.140]   looking over your shoulder, ExpressVPN is the best.
[01:51:11.140 --> 01:51:14.780]   It's secure, it protects you and your data.
[01:51:14.780 --> 01:51:18.100]   They have the very best privacy policy I've ever seen.
[01:51:18.100 --> 01:51:19.940]   No logging, they don't pay,
[01:51:19.940 --> 01:51:21.300]   you know, they don't track in any way,
[01:51:21.300 --> 01:51:23.340]   they don't record your history.
[01:51:23.340 --> 01:51:26.420]   You, now you are being tracked by social media sites,
[01:51:26.420 --> 01:51:28.620]   by marketing companies, by your mobile provider,
[01:51:28.620 --> 01:51:29.980]   by your internet provider,
[01:51:29.980 --> 01:51:33.340]   and by the hacker sitting next to you at the coffee shop.
[01:51:33.340 --> 01:51:35.580]   So, take back your privacy and security
[01:51:35.580 --> 01:51:36.780]   with ExpressVPN.
[01:51:36.780 --> 01:51:39.500]   It couldn't be easier, they've got apps for every platform.
[01:51:39.500 --> 01:51:41.780]   One click turns on the VPN.
[01:51:41.780 --> 01:51:43.700]   I think one of the best things about ExpressVPN
[01:51:43.700 --> 01:51:44.540]   is their speed.
[01:51:44.540 --> 01:51:47.620]   They have servers all over the world,
[01:51:47.620 --> 01:51:49.860]   and they're very fast servers.
[01:51:49.860 --> 01:51:52.020]   So they're fast enough to watch streaming video,
[01:51:52.020 --> 01:51:54.300]   they're fast enough to do everything you do,
[01:51:54.300 --> 01:51:57.780]   you're not gonna pay that VPN penalty.
[01:51:57.780 --> 01:51:59.420]   I really appreciate that.
[01:51:59.420 --> 01:52:02.020]   ExpressVPN secures and anonymizes your browsing
[01:52:02.020 --> 01:52:03.140]   by encrypting your data,
[01:52:03.140 --> 01:52:05.740]   hiding your public IP address.
[01:52:05.740 --> 01:52:08.420]   You could surf safely on public Wi-Fi.
[01:52:08.420 --> 01:52:11.380]   It tech radar rated it number one.
[01:52:11.380 --> 01:52:12.780]   And by the way, if at any time,
[01:52:12.780 --> 01:52:14.340]   you know, you got 30 days, you don't like it,
[01:52:14.340 --> 01:52:15.500]   you're money back.
[01:52:15.500 --> 01:52:17.140]   30 day money back, guarantee.
[01:52:17.140 --> 01:52:18.380]   Less than seven bucks a month.
[01:52:18.380 --> 01:52:19.620]   That's very affordable,
[01:52:19.620 --> 01:52:21.220]   and they make enough money
[01:52:21.220 --> 01:52:22.940]   so they don't have to do anything bad.
[01:52:22.940 --> 01:52:25.260]   They protect you,
[01:52:25.260 --> 01:52:29.060]   they will not inject content into your VPN stream
[01:52:29.060 --> 01:52:30.060]   or anything like that.
[01:52:30.060 --> 01:52:31.820]   Protect your online activity today.
[01:52:31.820 --> 01:52:33.900]   Find out you can get three extra months free.
[01:52:33.900 --> 01:52:36.420]   This makes it even more affordable with a one year package.
[01:52:36.420 --> 01:52:39.420]   If you go to expressvpn.com/twit.
[01:52:39.420 --> 01:52:40.940]   This is VPN done right.
[01:52:40.940 --> 01:52:44.140]   Expressvpn.com/twit.
[01:52:44.140 --> 01:52:46.460]   Get three extra months with your one year subscription.
[01:52:46.460 --> 01:52:51.460]   Expressvpn.com/twit.
[01:52:51.460 --> 01:52:56.460]   Did you see this Japanese hotel?
[01:52:56.460 --> 01:53:00.580]   That tried to replace its staff with robots?
[01:53:00.580 --> 01:53:05.100]   Robot hotel, oops, let's close this box,
[01:53:05.100 --> 01:53:07.660]   asking me to pay for the Wall Street Journal.
[01:53:07.660 --> 01:53:11.500]   Which I do, Robot Hotel loses love for robots.
[01:53:11.500 --> 01:53:14.380]   The robot revolution will have to wait
[01:53:14.380 --> 01:53:17.460]   at the Henna Hotel in Japan.
[01:53:17.460 --> 01:53:19.700]   They're laying off the droids
[01:53:19.700 --> 01:53:24.700]   because turns out the robots aren't the best at hospitality.
[01:53:24.700 --> 01:53:27.660]   Are their robots dinosaurs?
[01:53:27.660 --> 01:53:30.020]   Why is there a dinosaur at the top?
[01:53:30.020 --> 01:53:31.860]   That's a great question.
[01:53:31.860 --> 01:53:34.340]   No one knows, I don't know.
[01:53:34.340 --> 01:53:35.300]   I don't know.
[01:53:35.300 --> 01:53:37.260]   I saw that could be part of the private counter.
[01:53:37.260 --> 01:53:39.340]   If the robots look like that, yes.
[01:53:39.340 --> 01:53:40.180]   Yeah.
[01:53:40.180 --> 01:53:42.500]   Or robots or Raptors.
[01:53:42.500 --> 01:53:46.220]   The hotel has fired half of the 243 robots
[01:53:46.220 --> 01:53:48.940]   because they create work rather than reducing it.
[01:53:48.940 --> 01:53:50.940]   One staff member said, "It's easier now
[01:53:50.940 --> 01:53:52.820]   that we're not being frequently called by guests
[01:53:52.820 --> 01:53:55.340]   to help with problems with the robots."
[01:53:55.340 --> 01:53:57.340]   You imagine, this robot stuck in my room
[01:53:57.340 --> 01:53:58.340]   and I can't get it to leave.
[01:53:58.340 --> 01:53:59.860]   It's a rhythmic fellow!
[01:53:59.860 --> 01:54:06.100]   Maybe they should get Nell Bushnell to get his--
[01:54:06.100 --> 01:54:06.940]   Chuckie cheese!
[01:54:06.940 --> 01:54:08.260]   His robots, his room of Chuckie cheese.
[01:54:08.260 --> 01:54:09.100]   Oh, oh!
[01:54:09.100 --> 01:54:11.260]   Welcome to War Hotel.
[01:54:11.260 --> 01:54:17.460]   Did you see Sebastian, a bunch of hospitality robots at CES
[01:54:17.460 --> 01:54:21.660]   because according to this article in the journal, there were--
[01:54:21.660 --> 01:54:25.100]   I was mired in meetings from hotel to hotel.
[01:54:25.100 --> 01:54:27.580]   And they were with real people, not robots.
[01:54:27.580 --> 01:54:29.540]   They were-- I think they were real.
[01:54:29.540 --> 01:54:31.580]   I mean, I could have been fooled.
[01:54:31.580 --> 01:54:33.500]   Did you speak to any masters?
[01:54:33.500 --> 01:54:34.260]   There are no--
[01:54:34.260 --> 01:54:35.260]   No, there were no--
[01:54:35.260 --> 01:54:38.420]   Here's a robot, which the Wall Street Journal points out
[01:54:38.420 --> 01:54:40.860]   was an operational sitting at a player piano
[01:54:40.860 --> 01:54:45.020]   in the lobby of the Cessibo Hotel.
[01:54:45.020 --> 01:54:46.020]   There's a hotel--
[01:54:46.020 --> 01:54:48.140]   Thank you, Montaup.
[01:54:48.140 --> 01:54:49.500]   Looks like a Roomba.
[01:54:49.500 --> 01:54:50.340]   Yeah.
[01:54:50.340 --> 01:54:52.620]   It is, it's a Roomba attached to a body.
[01:54:52.620 --> 01:54:57.500]   There's a hotel apparently called Strange Hotel.
[01:54:57.500 --> 01:55:00.660]   There's the Space Egg Robot Hotel Porter,
[01:55:00.660 --> 01:55:04.180]   introduced by Ali Baba.
[01:55:04.180 --> 01:55:06.940]   The Strange Hotel attempted to--
[01:55:06.940 --> 01:55:09.460]   Sorry, I got some serious--
[01:55:09.460 --> 01:55:11.060]   what native marketing right there.
[01:55:11.060 --> 01:55:12.060]   Yeah.
[01:55:12.060 --> 01:55:15.420]   Space Egg Robot Hotel Porter.
[01:55:15.420 --> 01:55:18.380]   Strange hotels attempt to add more and more contraptions fizzled.
[01:55:18.380 --> 01:55:20.780]   One goal was to overcome labor shortages
[01:55:20.780 --> 01:55:23.700]   by using machines for tasks like luggage storage
[01:55:23.700 --> 01:55:26.500]   to mixing cocktails to cleaning.
[01:55:26.500 --> 01:55:28.980]   The hotel is next to a theme park in a rural area
[01:55:28.980 --> 01:55:32.300]   with a severe shortage of workers.
[01:55:32.300 --> 01:55:34.580]   They aim to lure foreign tourists by tapping
[01:55:34.580 --> 01:55:37.100]   into the image of Japan, the country
[01:55:37.100 --> 01:55:39.940]   that has produced smart toilets and hologram girlfriends
[01:55:39.940 --> 01:55:43.820]   as a technologically advanced nation.
[01:55:43.820 --> 01:55:45.380]   Have you seen that Russian robot?
[01:55:45.380 --> 01:55:45.880]   No.
[01:55:45.880 --> 01:55:47.020]   They should have used that one.
[01:55:47.020 --> 01:55:48.020]   What does it do?
[01:55:48.020 --> 01:55:49.940]   So they--
[01:55:49.940 --> 01:55:52.540]   So the Russia said that there was a most advanced robot
[01:55:52.540 --> 01:55:53.820]   that they've ever created.
[01:55:53.820 --> 01:55:56.180]   And they submitted it to some sort of contest.
[01:55:56.180 --> 01:55:58.780]   It was a man in a suit.
[01:55:58.780 --> 01:56:00.220]   Oh, that's hilarious.
[01:56:00.220 --> 01:56:01.580]   He's very advanced.
[01:56:01.580 --> 01:56:04.180]   Advanced high-tech robot.
[01:56:04.180 --> 01:56:04.820]   Here he is.
[01:56:04.820 --> 01:56:06.940]   Look how realistic he looks.
[01:56:06.940 --> 01:56:09.020]   He speaks many languages.
[01:56:09.020 --> 01:56:09.940]   He can walk.
[01:56:09.940 --> 01:56:12.860]   It's clearly a man in a suit.
[01:56:12.860 --> 01:56:16.020]   It's not even a very good costume.
[01:56:16.020 --> 01:56:19.740]   And they were trying to play it off as if it wasn't a man.
[01:56:19.740 --> 01:56:20.620]   That wasn't just--
[01:56:20.620 --> 01:56:23.340]   This wasn't trying to be a real robot.
[01:56:23.340 --> 01:56:24.420]   Wow.
[01:56:24.420 --> 01:56:26.900]   I've seen better cosplay at a comic con.
[01:56:26.900 --> 01:56:28.020]   This is terrible.
[01:56:28.020 --> 01:56:31.500]   Oh, man.
[01:56:31.500 --> 01:56:32.020]   Oh, man.
[01:56:32.020 --> 01:56:33.700]   He's fixed by this video right now.
[01:56:33.700 --> 01:56:37.420]   This kind of breaks my heart a little bit.
[01:56:37.420 --> 01:56:40.260]   It's almost-- it's a stereotype of Russia.
[01:56:40.260 --> 01:56:41.740]   Yeah, we invented TV.
[01:56:41.740 --> 01:56:43.460]   We invented the space travel.
[01:56:43.460 --> 01:56:45.420]   We invented robots.
[01:56:45.420 --> 01:56:46.620]   He's man in suits.
[01:56:46.620 --> 01:56:58.220]   Disney lost a billion dollars in streaming last year,
[01:56:58.220 --> 01:56:59.780]   partly because of Hulu.
[01:56:59.780 --> 01:57:05.460]   They have ownership in Hulu and something called BAM tech.
[01:57:05.460 --> 01:57:07.220]   BAM tech.
[01:57:07.220 --> 01:57:09.140]   They are planning on launching a streaming service
[01:57:09.140 --> 01:57:09.780]   later this year.
[01:57:09.780 --> 01:57:11.900]   But maybe-- I don't know--
[01:57:11.900 --> 01:57:15.620]   Hulu was a primary contributor to a $580 million loss
[01:57:15.620 --> 01:57:18.700]   in investments in the fiscal year that ended September 30th.
[01:57:18.700 --> 01:57:23.100]   Another $469 million in their direct consumer segment.
[01:57:23.100 --> 01:57:27.420]   BAM tech is the streaming technology that powers ESPN+
[01:57:27.420 --> 01:57:27.980]   among others.
[01:57:27.980 --> 01:57:29.420]   OK.
[01:57:29.420 --> 01:57:29.900]   Disney.
[01:57:29.900 --> 01:57:32.620]   Disney shouldn't have spent so much money on Lucasfilm.
[01:57:32.620 --> 01:57:33.660]   No.
[01:57:33.660 --> 01:57:35.620]   No, that was a good thing.
[01:57:35.620 --> 01:57:35.820]   That was--
[01:57:35.820 --> 01:57:36.740]   Look at where it got.
[01:57:36.740 --> 01:57:38.740]   Now, what I saw-- and I didn't read it
[01:57:38.740 --> 01:57:40.540]   because I don't follow this stuff.
[01:57:40.540 --> 01:57:43.820]   The article today that said the Star Wars franchises
[01:57:43.820 --> 01:57:44.300]   in trouble.
[01:57:44.300 --> 01:57:47.260]   Do we know what that means?
[01:57:47.260 --> 01:57:49.900]   Well, they just canceled another project.
[01:57:49.900 --> 01:57:53.900]   There was an open world game, I believe, that-- yeah.
[01:57:53.900 --> 01:57:58.980]   Solo Lost was the first Star Wars movie ever to lose money.
[01:57:58.980 --> 01:58:01.100]   This is from-- I don't read this regularly,
[01:58:01.100 --> 01:58:05.140]   but cosmic book news.
[01:58:05.140 --> 01:58:08.860]   Star Wars and Marvel Comics sales drop.
[01:58:08.860 --> 01:58:10.140]   Aquaman did all right.
[01:58:10.140 --> 01:58:14.380]   Trouble in paradise.
[01:58:14.380 --> 01:58:15.300]   So maybe they shouldn't have bought it.
[01:58:15.300 --> 01:58:16.500]   This is the problem.
[01:58:16.500 --> 01:58:17.460]   What's that?
[01:58:17.460 --> 01:58:21.820]   EA has made two games for Star Wars in the past.
[01:58:21.820 --> 01:58:23.420]   Terrible games.
[01:58:23.420 --> 01:58:26.780]   They had a 10-year license, and they've made two games.
[01:58:26.780 --> 01:58:28.020]   Oh, wow.
[01:58:28.020 --> 01:58:32.700]   10 years, two games, not a very good rate show.
[01:58:32.700 --> 01:58:33.260]   Who was it?
[01:58:33.260 --> 01:58:35.340]   Was it Netflix that said their number one competitor
[01:58:35.340 --> 01:58:36.940]   is not any of these guys?
[01:58:36.940 --> 01:58:37.900]   It's--
[01:58:37.900 --> 01:58:38.420]   Fortnite.
[01:58:38.420 --> 01:58:41.300]   Fortnite.
[01:58:41.300 --> 01:58:43.540]   The kids, they don't watch TV like they used to.
[01:58:43.540 --> 01:58:44.740]   They're playing Fortnite.
[01:58:44.740 --> 01:58:50.260]   So Twitch-- why do they say Fortnite instead of Twitch?
[01:58:50.260 --> 01:58:53.700]   Is it because they stream out other places than just on Twitch?
[01:58:53.700 --> 01:58:54.700]   Well, that's interesting.
[01:58:54.700 --> 01:58:58.180]   You think people are watching Fortnite not playing Fortnite?
[01:58:58.180 --> 01:58:59.500]   Oh, is that what they mean?
[01:58:59.500 --> 01:59:01.140]   I didn't know what Netflix meant by that.
[01:59:01.140 --> 01:59:06.060]   Because I don't know if they meant like streaming competitor
[01:59:06.060 --> 01:59:09.420]   as in watching Fortnite versus--
[01:59:09.420 --> 01:59:14.740]   People only have a certain amount of screen time.
[01:59:14.740 --> 01:59:20.860]   Netflix says, "Fortnite is a bigger rival than HBO."
[01:59:20.860 --> 01:59:22.980]   The online shooter accounts for an enormous amount
[01:59:22.980 --> 01:59:24.060]   of consumer's screen time.
[01:59:24.060 --> 01:59:26.780]   I bet you you're right that some of that's Twitch watching
[01:59:26.780 --> 01:59:27.940]   people play.
[01:59:27.940 --> 01:59:30.060]   This is a shareholder letter that Netflix sent out
[01:59:30.060 --> 01:59:31.660]   on Thursday.
[01:59:31.660 --> 01:59:34.620]   Quote, "We earn consumer screen time, both mobile and television,
[01:59:34.620 --> 01:59:37.300]   away from a very broad set of competitors we compete with
[01:59:37.300 --> 01:59:41.540]   and lose to Fortnite more than HBO.
[01:59:41.540 --> 01:59:43.940]   There are thousands of competitors in this highly fragmented
[01:59:43.940 --> 01:59:47.100]   market vying to entertain consumers."
[01:59:47.100 --> 01:59:49.700]   There's a big price difference between HBO and Fortnite.
[01:59:49.700 --> 01:59:51.060]   Yeah, Fortnite's free.
[01:59:51.060 --> 01:59:52.620]   Yeah.
[01:59:52.620 --> 01:59:55.420]   Unless you want that dance move.
[01:59:55.420 --> 01:59:56.860]   The floss.
[01:59:56.860 --> 01:59:57.700]   I bet-- wait a minute.
[01:59:57.700 --> 01:59:59.700]   Mill's playing the floss to me because I bet you--
[01:59:59.700 --> 02:00:01.140]   can you do it?
[02:00:01.140 --> 02:00:02.140]   Yes, yes.
[02:00:02.140 --> 02:00:02.940]   Let's see.
[02:00:02.940 --> 02:00:03.460]   Stand up.
[02:00:03.460 --> 02:00:04.260]   I'm not going to do that.
[02:00:04.260 --> 02:00:04.780]   Floss.
[02:00:04.780 --> 02:00:06.700]   Show me how to do it.
[02:00:06.700 --> 02:00:08.100]   Oh, my lord.
[02:00:08.100 --> 02:00:08.900]   No, no, no, no.
[02:00:08.900 --> 02:00:09.940]   OK.
[02:00:09.940 --> 02:00:11.380]   Both hands.
[02:00:11.380 --> 02:00:12.900]   Take them out.
[02:00:12.900 --> 02:00:15.700]   And then we stick our hip to the other side.
[02:00:15.700 --> 02:00:18.940]   And then you floss it through.
[02:00:18.940 --> 02:00:22.060]   And then you switch.
[02:00:22.060 --> 02:00:24.220]   And then you floss it through.
[02:00:24.220 --> 02:00:26.380]   Do it fast, though, because when you do it--
[02:00:26.380 --> 02:00:27.020]   Yes.
[02:00:27.020 --> 02:00:28.580]   Then you do it super fast, and that's
[02:00:28.580 --> 02:00:29.740]   whenever it looks cool.
[02:00:29.740 --> 02:00:32.300]   And it's fun.
[02:00:32.300 --> 02:00:35.140]   But that's the trick, by the way, which was explained to me
[02:00:35.140 --> 02:00:37.900]   by another millennial I know, because I know too.
[02:00:37.900 --> 02:00:41.780]   And the key is that the hips go opposite of the hands.
[02:00:41.780 --> 02:00:42.300]   Yes.
[02:00:42.300 --> 02:00:45.100]   See, my temte-- I would tend to do it in the same way, but they--
[02:00:45.100 --> 02:00:46.460]   Were you going like one way and the other?
[02:00:46.460 --> 02:00:48.060]   That doesn't look right.
[02:00:48.060 --> 02:00:48.500]   Yeah.
[02:00:48.500 --> 02:00:51.580]   So that's what makes it sort of look
[02:00:51.580 --> 02:00:52.620]   like an optical illusion.
[02:00:52.620 --> 02:00:56.980]   But with Fortnite, Netflix could only
[02:00:56.980 --> 02:00:59.100]   say that Fortnite was a competitor in terms
[02:00:59.100 --> 02:01:03.100]   of playing the game if they were talking about Bandersnatch.
[02:01:03.100 --> 02:01:03.620]   You know what I mean?
[02:01:03.620 --> 02:01:05.340]   Like they haven't made games before.
[02:01:05.340 --> 02:01:09.300]   So I do feel like it's got to be about streaming there more
[02:01:09.300 --> 02:01:10.980]   than anything.
[02:01:10.980 --> 02:01:13.940]   So we've got millennials, sure.
[02:01:13.940 --> 02:01:15.660]   But now we've got that next generation.
[02:01:15.660 --> 02:01:16.180]   Yes.
[02:01:16.180 --> 02:01:17.340]   We call it post-millennials and all that.
[02:01:17.340 --> 02:01:19.940]   So my siblings, my younger brother,
[02:01:19.940 --> 02:01:22.420]   is a Twitch streamer of Fortnite.
[02:01:22.420 --> 02:01:23.780]   And does that sort of--
[02:01:23.780 --> 02:01:24.340]   For a living.
[02:01:24.340 --> 02:01:25.860]   For a living.
[02:01:25.860 --> 02:01:26.380]   Yeah.
[02:01:26.380 --> 02:01:26.880]   Right.
[02:01:26.880 --> 02:01:27.620]   Yeah.
[02:01:27.620 --> 02:01:30.340]   His rent and stuff is paid by playing that game, which
[02:01:30.340 --> 02:01:31.700]   I have no idea how any of it works.
[02:01:31.700 --> 02:01:35.860]   But my sister-- I guess we say our sister,
[02:01:35.860 --> 02:01:39.100]   most of the television that she watches
[02:01:39.100 --> 02:01:43.300]   is actually my-- our younger brother playing Fortnite.
[02:01:43.300 --> 02:01:47.540]   So apparently people do spend their free hours of screen time
[02:01:47.540 --> 02:01:49.140]   just watching people play video games.
[02:01:49.140 --> 02:01:50.860]   I despair for our future.
[02:01:50.860 --> 02:01:51.940]   Why not YouTube, though?
[02:01:51.940 --> 02:01:55.140]   I would think YouTube is a natural competitor.
[02:01:55.140 --> 02:01:56.820]   That's because you're old.
[02:01:56.820 --> 02:01:57.820]   So--
[02:01:57.820 --> 02:01:59.020]   True.
[02:01:59.020 --> 02:02:01.220]   But see, they do stream on YouTube, too, don't they?
[02:02:01.220 --> 02:02:03.300]   I mean, can't you watch YouTube forever?
[02:02:03.300 --> 02:02:06.860]   Gen Z watches their brother playing Fortnite.
[02:02:06.860 --> 02:02:08.940]   That's what it is.
[02:02:08.940 --> 02:02:11.980]   I think even YouTube is going to face a challenge
[02:02:11.980 --> 02:02:16.180]   with this younger generation, these 13-year-olds.
[02:02:16.180 --> 02:02:19.300]   Well, now they've got TikTok, right?
[02:02:19.300 --> 02:02:20.500]   But that'll last two years.
[02:02:20.500 --> 02:02:20.980]   And that's what it is.
[02:02:20.980 --> 02:02:21.300]   That's what it is.
[02:02:21.300 --> 02:02:22.900]   Something else.
[02:02:22.900 --> 02:02:25.940]   Yeah, TikTok, by the way, is owned by a Chinese company.
[02:02:25.940 --> 02:02:28.100]   So if you were to have privacy--
[02:02:28.100 --> 02:02:30.140]   So I got Wesley's information, and then everyone
[02:02:30.140 --> 02:02:33.540]   who's uploading videos to TikTok.
[02:02:33.540 --> 02:02:35.020]   Are you seeing a lot of ads for TikTok
[02:02:35.020 --> 02:02:36.260]   in your streams, Wesley?
[02:02:36.260 --> 02:02:37.260]   Oh, yeah.
[02:02:37.260 --> 02:02:42.940]   Tense doesn't-- they're backed by a huge, huge chunk of money.
[02:02:42.940 --> 02:02:44.980]   They're part of the Vision Fund, so--
[02:02:44.980 --> 02:02:46.340]   That's-- they got some money.
[02:02:46.340 --> 02:02:47.260]   Yeah.
[02:02:47.260 --> 02:02:48.060]   So--
[02:02:48.060 --> 02:02:52.260]   That suns, Masayoshi suns, multi-billion dollar.
[02:02:52.260 --> 02:02:55.620]   But by the way, it's about 50% Saudi Arabia.
[02:02:55.620 --> 02:02:57.900]   So--
[02:02:57.900 --> 02:02:58.980]   Yep.
[02:02:58.980 --> 02:03:05.540]   A poker playing robot is going to work for the Pentagon.
[02:03:05.540 --> 02:03:05.980]   You may be--
[02:03:05.980 --> 02:03:07.140]   Me too, actually.
[02:03:07.140 --> 02:03:08.140]   Are you two?
[02:03:08.140 --> 02:03:10.100]   Yeah, it's either the Intel or the Pentagon.
[02:03:10.100 --> 02:03:12.620]   In 2017, you may remember Libratas,
[02:03:12.620 --> 02:03:14.460]   which was a poker playing robot that
[02:03:14.460 --> 02:03:17.900]   defeated four of the best human players at no limit,
[02:03:17.900 --> 02:03:20.300]   Texan Haldum.
[02:03:20.300 --> 02:03:22.220]   Libratas, which is Latin for Balanced,
[02:03:22.220 --> 02:03:25.260]   was created by researchers from Carnegie Mellon
[02:03:25.260 --> 02:03:27.860]   to test ideas for automated decision making based
[02:03:27.860 --> 02:03:30.900]   on game theory.
[02:03:30.900 --> 02:03:32.900]   After he beat the poker players,
[02:03:32.900 --> 02:03:34.300]   the professor who led the project
[02:03:34.300 --> 02:03:38.100]   founded a startup called Strategy Robot.
[02:03:38.100 --> 02:03:40.900]   Late in August, the company received a two year contract
[02:03:40.900 --> 02:03:46.140]   of $10 million from the army.
[02:03:46.140 --> 02:03:50.180]   I don't think it'll be playing poker, but who knows?
[02:03:50.180 --> 02:03:51.540]   Strategy at what, though?
[02:03:51.540 --> 02:03:52.380]   Maybe Fortnite.
[02:03:52.380 --> 02:03:55.140]   Is this computer going to be in charge of human lives?
[02:03:55.140 --> 02:03:57.660]   Saying you go over here, you do this?
[02:03:57.660 --> 02:03:58.620]   Strategy Robot--
[02:03:58.620 --> 02:03:59.140]   That's scary.
[02:03:59.140 --> 02:03:59.980]   --is according to Wired.
[02:03:59.980 --> 02:04:03.460]   Isn't the Pentagon's only new foray into AI-enhanced game
[02:04:03.460 --> 02:04:06.500]   theory, AI-enhanced game?
[02:04:06.500 --> 02:04:09.380]   They've got so much money in the military
[02:04:09.380 --> 02:04:12.180]   that they can afford to do a lot of blue sky.
[02:04:12.180 --> 02:04:13.820]   Try everything.
[02:04:13.820 --> 02:04:16.100]   Like the men who stare at goats, right?
[02:04:16.100 --> 02:04:17.180]   Just try it.
[02:04:17.180 --> 02:04:19.460]   Maybe it'll work.
[02:04:19.460 --> 02:04:21.620]   Michael Wellman, a professor at the University of Michigan,
[02:04:21.620 --> 02:04:24.100]   says his group's working on applying computational game
[02:04:24.100 --> 02:04:28.020]   theory to cybersecurity under the eegis of the army.
[02:04:28.020 --> 02:04:32.580]   The breakthrough of poker rules--
[02:04:32.580 --> 02:04:33.940]   You don't know all the rules, though.
[02:04:33.940 --> 02:04:35.780]   That's going to be hard.
[02:04:35.780 --> 02:04:37.340]   I don't see how you put that in.
[02:04:37.340 --> 02:04:40.500]   The only way to win the game is not to play.
[02:04:40.500 --> 02:04:45.260]   Four games.
[02:04:45.260 --> 02:04:45.740]   Thank you.
[02:04:45.740 --> 02:04:46.580]   For those who don't know that.
[02:04:46.580 --> 02:04:48.140]   Name check.
[02:04:48.140 --> 02:04:50.180]   Quick name check.
[02:04:50.180 --> 02:04:51.980]   I didn't know.
[02:04:51.980 --> 02:04:54.180]   What?
[02:04:54.180 --> 02:04:57.420]   That's actually segwaying us to this fast company article
[02:04:57.420 --> 02:05:02.660]   about the Vision Fund and Masayoshi Sun.
[02:05:02.660 --> 02:05:05.580]   It says, are you ready to live in Masa World?
[02:05:05.580 --> 02:05:07.500]   Oh, dear.
[02:05:07.500 --> 02:05:13.540]   I used to work for a son, San, when he owned Zif Davis.
[02:05:13.540 --> 02:05:15.300]   Briefly.
[02:05:15.300 --> 02:05:17.540]   This article was extremely scary.
[02:05:17.540 --> 02:05:19.700]   So tell us about it, Wesley.
[02:05:19.700 --> 02:05:22.140]   Well, it's just--
[02:05:22.140 --> 02:05:23.820]   he has a ton of money and money.
[02:05:23.820 --> 02:05:25.700]   100 billion dollars.
[02:05:25.700 --> 02:05:28.140]   But his power comes from the fact
[02:05:28.140 --> 02:05:31.820]   that he has money and influence.
[02:05:31.820 --> 02:05:36.420]   He has deep connections with world leaders,
[02:05:36.420 --> 02:05:40.940]   all these pivotal companies that he is under his umbrella.
[02:05:40.940 --> 02:05:45.860]   They make them work together, so they are a family, they call it.
[02:05:45.860 --> 02:05:51.340]   So they're in the umbrella, so they become interdependent
[02:05:51.340 --> 02:05:52.580]   on themselves.
[02:05:52.580 --> 02:05:54.060]   And so it builds on itself.
[02:05:54.060 --> 02:05:58.740]   So he's trying to build the future that he wants from--
[02:05:58.740 --> 02:06:01.860]   and he's adding the pieces as he goes.
[02:06:01.860 --> 02:06:05.140]   And so going back to TikTok, you're saying, oh, that'll be done.
[02:06:05.140 --> 02:06:07.180]   No, they will find a way to support each other
[02:06:07.180 --> 02:06:08.540]   so they can keep going.
[02:06:08.540 --> 02:06:11.540]   And so even if you think that it's something you don't want,
[02:06:11.540 --> 02:06:14.380]   they will make it happen.
[02:06:14.380 --> 02:06:21.220]   Sun believes that robots will make us healthier and happier.
[02:06:21.220 --> 02:06:24.540]   He has long told people, I have a 300-year plan.
[02:06:24.540 --> 02:06:31.180]   I guess job one would be to live 300 years.
[02:06:31.180 --> 02:06:33.580]   Yeah, I'm going what?
[02:06:33.580 --> 02:06:38.900]   Well, but that's actually not unusual for a Japanese industrialist.
[02:06:38.900 --> 02:06:42.860]   They do think more long-term, right?
[02:06:42.860 --> 02:06:46.260]   It sounds like Sun is one of the believers--
[02:06:46.260 --> 02:06:49.260]   the true believers who thinks technology is the only way
[02:06:49.260 --> 02:06:51.340]   to save the world at this point.
[02:06:51.340 --> 02:06:56.660]   The scary thing about it is that he hires people who think like him,
[02:06:56.660 --> 02:07:00.540]   which means that I'm using this wrong,
[02:07:00.540 --> 02:07:04.620]   but neurodiversity or diversity of thought
[02:07:04.620 --> 02:07:11.260]   is probably something that's not the best.
[02:07:11.260 --> 02:07:14.300]   So in terms of vetting, it could be--
[02:07:14.300 --> 02:07:17.380]   like, for instance, WeWork is one of the companies listed.
[02:07:17.380 --> 02:07:21.860]   And it was recently released that the president of WeWork
[02:07:21.860 --> 02:07:26.580]   apparently owned a lot of the properties that WeWork was renting
[02:07:26.580 --> 02:07:28.380]   in order to have their offices.
[02:07:28.380 --> 02:07:32.460]   And so an environment like that--
[02:07:32.460 --> 02:07:33.780]   Talk about double dipping.
[02:07:33.780 --> 02:07:35.860]   I mean, he's the landlord.
[02:07:35.860 --> 02:07:40.900]   WeWork's CEO is also WeWork's landlord.
[02:07:40.900 --> 02:07:41.400]   Yeah.
[02:07:41.400 --> 02:07:42.380]   That doesn't sound right.
[02:07:42.380 --> 02:07:46.940]   So if WeWork is losing money because they don't get enough people
[02:07:46.940 --> 02:07:49.940]   to pay for people looking-- it's fine.
[02:07:49.940 --> 02:07:51.540]   He's still himself--
[02:07:51.540 --> 02:07:52.580]   He still makes money.
[02:07:52.580 --> 02:07:53.020]   Yeah.
[02:07:53.020 --> 02:07:54.940]   This is really the key.
[02:07:54.940 --> 02:07:58.140]   You've got to think like a spider.
[02:07:58.140 --> 02:08:00.860]   So this Fast Company article is good.
[02:08:00.860 --> 02:08:03.980]   I think graphics for each of his categories--
[02:08:03.980 --> 02:08:06.420]   obsession number one is, as you said, real estate.
[02:08:06.420 --> 02:08:08.980]   Sun believes there's an opportunity to consolidate
[02:08:08.980 --> 02:08:13.020]   and automate the fractured world of real estate.
[02:08:13.020 --> 02:08:16.540]   So $20 billion in WeWork, for instance.
[02:08:16.540 --> 02:08:19.860]   Although, I think he lowered that recently.
[02:08:19.860 --> 02:08:22.060]   Obsession number two, mobility, transportation
[02:08:22.060 --> 02:08:25.340]   is moving from something individual zone to a service
[02:08:25.340 --> 02:08:27.140]   they rent on demand via technology.
[02:08:27.140 --> 02:08:29.660]   We're clearly seeing that move.
[02:08:29.660 --> 02:08:31.460]   So these are some of his investments.
[02:08:31.460 --> 02:08:34.780]   Uber, Grab, DD-Chuxing, which is the Chinese.
[02:08:34.780 --> 02:08:36.460]   DD is the Chinese Uber.
[02:08:36.460 --> 02:08:37.740]   GM Cruise.
[02:08:37.740 --> 02:08:39.740]   That's their self-driving vehicles.
[02:08:39.740 --> 02:08:42.420]   Ola, which is the Uber of India.
[02:08:42.420 --> 02:08:48.100]   Manbang Group, which despite its name, is about truck hailing.
[02:08:48.100 --> 02:08:49.860]   It probably means something different wherever
[02:08:49.860 --> 02:08:51.380]   Manbang is.
[02:08:51.380 --> 02:08:55.420]   Get around peer-to-peer car sharing, park jockey,
[02:08:55.420 --> 02:08:56.420]   parking reservations.
[02:08:56.420 --> 02:08:57.660]   You're going to have a problem with language,
[02:08:57.660 --> 02:08:59.980]   I think, is going to be a problem because things mean
[02:08:59.980 --> 02:09:02.380]   different things in different countries.
[02:09:02.380 --> 02:09:04.980]   Other obsessions?
[02:09:04.980 --> 02:09:05.460]   Let's see.
[02:09:05.460 --> 02:09:06.420]   What else?
[02:09:06.420 --> 02:09:07.580]   Maybe that's it.
[02:09:07.580 --> 02:09:08.420]   Oh no, here it is.
[02:09:08.420 --> 02:09:10.460]   Number three, commerce.
[02:09:10.460 --> 02:09:12.820]   He online purchases of goods and services
[02:09:12.820 --> 02:09:15.340]   will flourish in AI-powered world.
[02:09:15.340 --> 02:09:16.420]   Maybe not.
[02:09:16.420 --> 02:09:19.220]   Maybe all the people he disenfranchises won't have any
[02:09:19.220 --> 02:09:22.460]   money to spend on Flipkart brandless Zoom, pizza,
[02:09:22.460 --> 02:09:25.700]   Alibaba, food, delivery, and on and on.
[02:09:25.700 --> 02:09:27.060]   Right?
[02:09:27.060 --> 02:09:29.220]   What happens when nobody has a job?
[02:09:29.220 --> 02:09:33.580]   Well, that's whenever-- what?
[02:09:33.580 --> 02:09:36.900]   That's when we start to have universal basic income.
[02:09:36.900 --> 02:09:39.340]   Yeah, this is what bothers me about universal basic income.
[02:09:39.340 --> 02:09:41.300]   It's people like SunSider saying,
[02:09:41.300 --> 02:09:43.100]   shoot, we're going to run out of customers.
[02:09:43.100 --> 02:09:46.140]   Why don't we just give them a little bit of the money back?
[02:09:46.140 --> 02:09:48.300]   You owe me a soul to try to come.
[02:09:48.300 --> 02:09:51.940]   But in store, we'll give them 10%.
[02:09:51.940 --> 02:09:56.060]   We'll keep 90% everybody happy.
[02:09:56.060 --> 02:09:57.900]   Well, a good article.
[02:09:57.900 --> 02:09:59.620]   Highly recommended.
[02:09:59.620 --> 02:10:01.060]   It's a long read, though.
[02:10:01.060 --> 02:10:03.500]   See, if he hasn't invested in Fortnite, though,
[02:10:03.500 --> 02:10:05.940]   then he's not going to win.
[02:10:05.940 --> 02:10:07.820]   Tim Sweeney's got a future, man.
[02:10:07.820 --> 02:10:09.900]   Forget SunSider.
[02:10:09.900 --> 02:10:11.260]   It's all about Tim Sweeney.
[02:10:11.260 --> 02:10:13.460]   He's got the money now.
[02:10:13.460 --> 02:10:14.460]   That's what I like.
[02:10:14.460 --> 02:10:17.700]   Frankly, that's what I like about this space is you really can't--
[02:10:17.700 --> 02:10:22.300]   you can be a big thinker like SunSider, Jeff Bezos.
[02:10:22.300 --> 02:10:24.460]   But you can't really predict what's going to happen.
[02:10:24.460 --> 02:10:25.620]   You don't know.
[02:10:25.620 --> 02:10:28.580]   Yeah, Fortnite could just be this year's Pokemon Go
[02:10:28.580 --> 02:10:30.140]   and looking what happened to their--
[02:10:30.140 --> 02:10:31.820]   Nothing happened to Pokemon Go.
[02:10:31.820 --> 02:10:33.940]   It's still a blast.
[02:10:33.940 --> 02:10:35.580]   That was offensive.
[02:10:35.580 --> 02:10:37.420]   Now I'm offended.
[02:10:37.420 --> 02:10:42.260]   Will you mill explain to him why Pokemon Go is still relevant
[02:10:42.260 --> 02:10:42.740]   in this day?
[02:10:42.740 --> 02:10:45.220]   Get your Pokeball out, and we'll talk about it.
[02:10:45.220 --> 02:10:46.980]   Yeah, I have a Pokeball some.
[02:10:46.980 --> 02:10:49.140]   I've been playing it under the table the whole time.
[02:10:49.140 --> 02:10:52.420]   So to me, I'm really actually thinking that the big thing--
[02:10:52.420 --> 02:10:53.500]   we ain't seen nothing yet.
[02:10:53.500 --> 02:10:55.740]   Pokemon Go came out July 2016.
[02:10:55.740 --> 02:10:57.900]   Remember, in the first six months,
[02:10:57.900 --> 02:11:02.300]   you'd see like, hordes of people appear out of nowhere
[02:11:02.300 --> 02:11:05.020]   because they're all catching some imaginary augmented
[02:11:05.020 --> 02:11:08.620]   reality thing that no one except them can see.
[02:11:08.620 --> 02:11:11.380]   We were in San Diego that summer,
[02:11:11.380 --> 02:11:14.940]   and there's people on the median strip,
[02:11:14.940 --> 02:11:17.620]   the lawn in between the two roads.
[02:11:17.620 --> 02:11:20.700]   There's like 1,000-- it looks like Woodstock.
[02:11:20.700 --> 02:11:24.020]   And we're going by and we go, oh, there's two gyms there.
[02:11:24.020 --> 02:11:25.940]   They're playing Pokemon Go.
[02:11:25.940 --> 02:11:27.100]   That ain't nothing.
[02:11:27.100 --> 02:11:27.500]   Get ready.
[02:11:27.500 --> 02:11:28.980]   You heard it here first.
[02:11:28.980 --> 02:11:31.380]   Sometimes this year Warner Brothers and Niantic,
[02:11:31.380 --> 02:11:32.900]   the creators of Pokemon Go, are going
[02:11:32.900 --> 02:11:35.100]   to release the Harry Potter game.
[02:11:35.100 --> 02:11:37.740]   Yeah, that's going to get people.
[02:11:37.740 --> 02:11:40.420]   If you think Pokemon Go was crazy,
[02:11:40.420 --> 02:11:42.780]   because what is the number of people who are Harry Potter
[02:11:42.780 --> 02:11:46.220]   fans compared to the number of Pokemon fans?
[02:11:46.220 --> 02:11:46.580]   I'm going to--
[02:11:46.580 --> 02:11:47.540]   I'm going to look that up.
[02:11:47.540 --> 02:11:48.540]   I'll ask Cortana.
[02:11:48.540 --> 02:11:51.900]   Ask Cortana, she'll prefer you to--
[02:11:51.900 --> 02:11:56.420]   but no, I honestly think that that's going to be a phenomenon.
[02:11:56.420 --> 02:11:59.540]   We don't yet know how crazy that'll be.
[02:11:59.540 --> 02:12:00.060]   Yeah.
[02:12:00.060 --> 02:12:04.260]   You do the-- with the Bird Box Challenge with the Pokemon.
[02:12:04.260 --> 02:12:04.780]   I do.
[02:12:04.780 --> 02:12:06.260]   Just put on a blindfold.
[02:12:06.260 --> 02:12:08.100]   Findfold and try to find Pokemon.
[02:12:08.100 --> 02:12:08.620]   Catch them.
[02:12:08.620 --> 02:12:12.260]   Oh, they're there somewhere.
[02:12:12.260 --> 02:12:13.700]   You now know when you go down the street,
[02:12:13.700 --> 02:12:15.340]   because everybody now in Pokemon Go
[02:12:15.340 --> 02:12:16.180]   is throwing curveballs.
[02:12:16.180 --> 02:12:16.660]   You could tell.
[02:12:16.660 --> 02:12:17.100]   It used to be.
[02:12:17.100 --> 02:12:19.500]   You couldn't be sure because people are just tapping their phones.
[02:12:19.500 --> 02:12:22.220]   But everybody's doing this, just so you know Sebastian.
[02:12:22.220 --> 02:12:24.180]   If you see somebody spinning their finger
[02:12:24.180 --> 02:12:26.340]   and then going like that on their phone--
[02:12:26.340 --> 02:12:26.700]   OK.
[02:12:26.700 --> 02:12:27.340]   --they're playing Pokemon.
[02:12:27.340 --> 02:12:28.180]   While driving.
[02:12:28.180 --> 02:12:29.980]   While driving.
[02:12:29.980 --> 02:12:33.260]   I would ever do that.
[02:12:33.260 --> 02:12:34.100]   Much.
[02:12:34.100 --> 02:12:38.220]   Our show today brought to you by Atlassian.
[02:12:38.220 --> 02:12:41.380]   Speaking-- we were just talking about HipChat.
[02:12:41.380 --> 02:12:45.900]   And by the way, did you see Atlassian's quarterly results
[02:12:45.900 --> 02:12:46.940]   of their stock price?
[02:12:46.940 --> 02:12:49.100]   They're going through the roof.
[02:12:49.100 --> 02:12:52.820]   I'm not surprised Atlassian is the collaboration software
[02:12:52.820 --> 02:12:56.780]   company that empowers teams all around the world.
[02:12:56.780 --> 02:13:01.220]   We use their tools like crazy.
[02:13:01.220 --> 02:13:04.100]   If you're in agile development, of course you know about Jira.
[02:13:04.100 --> 02:13:05.620]   Jira's kind of the backbone.
[02:13:05.620 --> 02:13:09.620]   But then there's Bitbucket for code, building, and shipping.
[02:13:09.620 --> 02:13:12.260]   We use Confluence to document our systems.
[02:13:12.260 --> 02:13:14.100]   That's for collaboration.
[02:13:14.100 --> 02:13:16.500]   Jira Service Desk, SourceTree.
[02:13:16.500 --> 02:13:17.580]   They acquired Trello.
[02:13:17.580 --> 02:13:20.460]   Everybody loves Trello for project management.
[02:13:20.460 --> 02:13:22.100]   Then of course you have for ops.
[02:13:22.100 --> 02:13:25.780]   You've got Jira Ops, Ops Genie Status Page.
[02:13:25.780 --> 02:13:29.700]   They're putting together an incredible lineup.
[02:13:29.700 --> 02:13:32.580]   Their software tools are designed to manage complex collaboration.
[02:13:32.580 --> 02:13:34.940]   And by the way, not just for developers.
[02:13:34.940 --> 02:13:37.580]   Atlassian offers an affordable, reliable suite
[02:13:37.580 --> 02:13:41.300]   of tools that all interoperates for teams of any size.
[02:13:41.300 --> 02:13:45.220]   From DevOps to Agile, from IT apps to ops to ITSM
[02:13:45.220 --> 02:13:46.820]   and whatever is next.
[02:13:46.820 --> 02:13:51.300]   They're there with the tools you need to solve problems,
[02:13:51.300 --> 02:13:55.140]   to respond, coordinate efforts, to organize.
[02:13:55.140 --> 02:13:57.540]   Actually the bottom line to communicate.
[02:13:57.540 --> 02:14:00.500]   Your team can choose the tools that are right for your current framework,
[02:14:00.500 --> 02:14:02.820]   trusting that as you grow, they will grow with you.
[02:14:02.820 --> 02:14:05.540]   And of course it all integrates seamlessly with Jira and Confluence.
[02:14:05.540 --> 02:14:08.900]   That keeps you moving fast, keeps you from bouncing around
[02:14:08.900 --> 02:14:09.900]   from platform to platform.
[02:14:09.900 --> 02:14:11.060]   It's all in there.
[02:14:11.060 --> 02:14:11.660]   It's all working.
[02:14:11.660 --> 02:14:13.420]   Look at the companies that use Atlassian.
[02:14:13.420 --> 02:14:16.100]   We use it like crazy.
[02:14:16.100 --> 02:14:17.780]   Really great stuff.
[02:14:17.780 --> 02:14:19.900]   The tools for your IT team are easy.
[02:14:19.900 --> 02:14:23.420]   And by the way, free to try when you go to Atlassian.com.
[02:14:23.420 --> 02:14:28.500]   Atlassin.com.
[02:14:28.500 --> 02:14:31.180]   Atlassian's knocking it out of the park.
[02:14:31.180 --> 02:14:32.940]   And we're really glad to be partnering with them
[02:14:32.940 --> 02:14:35.260]   and to use their tools every single day.
[02:14:35.260 --> 02:14:38.860]   AtlassianforIT.com.
[02:14:38.860 --> 02:14:43.620]   Only sure IT team at Atlassian's Stellar collaboration software tools.
[02:14:43.620 --> 02:14:46.380]   When you worked at HipChat, were you working for Atlassian?
[02:14:46.380 --> 02:14:46.900]   Atlassian?
[02:14:46.900 --> 02:14:47.820]   Yes.
[02:14:47.820 --> 02:14:48.340]   Yes.
[02:14:48.340 --> 02:14:49.860]   I was their social media manager for--
[02:14:49.860 --> 02:14:50.860]   Nice.
[02:14:50.860 --> 02:14:52.020]   You got to--
[02:14:52.020 --> 02:14:53.140]   I don't know what it was like.
[02:14:53.140 --> 02:14:54.460]   Was it good working there?
[02:14:54.460 --> 02:14:59.500]   Because I really admire that company so much.
[02:14:59.500 --> 02:15:01.500]   You can be honest.
[02:15:01.500 --> 02:15:02.460]   It was the best.
[02:15:02.460 --> 02:15:05.900]   It was really-- it's an amazing company.
[02:15:05.900 --> 02:15:07.500]   The people were great.
[02:15:07.500 --> 02:15:10.700]   The talent is unmatched.
[02:15:10.700 --> 02:15:11.780]   And you must be proud of them.
[02:15:11.780 --> 02:15:15.020]   They posted a billion in revenue for the first time.
[02:15:15.020 --> 02:15:18.300]   And their stock went up 9%.
[02:15:18.300 --> 02:15:18.940]   That's the thing.
[02:15:18.940 --> 02:15:21.980]   Their trajectory, they outperform every single day.
[02:15:21.980 --> 02:15:22.980]   It's a single quarter.
[02:15:22.980 --> 02:15:23.980]   Nice.
[02:15:23.980 --> 02:15:27.700]   If you just look at their estimates and their growth is unmatched.
[02:15:27.700 --> 02:15:29.940]   They're a really great company.
[02:15:29.940 --> 02:15:30.940]   Did you--
[02:15:30.940 --> 02:15:31.940]   They were an interesting thing.
[02:15:31.940 --> 02:15:32.940]   But you worked at Atlassian.
[02:15:32.940 --> 02:15:34.940]   You didn't go down to Australia.
[02:15:34.940 --> 02:15:35.940]   No.
[02:15:35.940 --> 02:15:38.460]   Well, no.
[02:15:38.460 --> 02:15:40.180]   Because of my role, there was no need for me to go.
[02:15:40.180 --> 02:15:41.660]   Your social would be anywhere.
[02:15:41.660 --> 02:15:42.660]   Yeah.
[02:15:42.660 --> 02:15:44.580]   I did go to San Francisco a few times.
[02:15:44.580 --> 02:15:47.340]   But several people go to Australia.
[02:15:47.340 --> 02:15:50.100]   We had several Australians, of course, come in and work.
[02:15:50.100 --> 02:15:53.540]   So yeah, it's a great story.
[02:15:53.540 --> 02:15:54.900]   It's a great company.
[02:15:54.900 --> 02:15:58.180]   Of course, they definitely eat their own dog food.
[02:15:58.180 --> 02:16:03.460]   So they work on the same products
[02:16:03.460 --> 02:16:04.820]   that they try to bring to market.
[02:16:04.820 --> 02:16:08.900]   And we had the most advanced versions of everything.
[02:16:08.900 --> 02:16:13.940]   And we once a month had these things called--
[02:16:13.940 --> 02:16:15.740]   well, these hacker challenges, where
[02:16:15.740 --> 02:16:19.540]   you build your own product from their tools.
[02:16:19.540 --> 02:16:21.620]   And then you incorporate it.
[02:16:21.620 --> 02:16:24.300]   And then if it works, you deploy it.
[02:16:24.300 --> 02:16:26.060]   And people start using it in-house.
[02:16:26.060 --> 02:16:26.560]   Nice.
[02:16:26.560 --> 02:16:27.780]   And if it becomes successful enough,
[02:16:27.780 --> 02:16:30.220]   it will roll out into a feature for everyone else.
[02:16:30.220 --> 02:16:31.220]   And they did that all the time.
[02:16:31.220 --> 02:16:32.460]   And it was so much fun.
[02:16:32.460 --> 02:16:33.220]   They're agile.
[02:16:33.220 --> 02:16:34.460]   What a surprise.
[02:16:34.460 --> 02:16:36.460]   Yeah.
[02:16:36.460 --> 02:16:38.380]   So this was a big mistake.
[02:16:38.380 --> 02:16:40.780]   The scooter company Bird.
[02:16:40.780 --> 02:16:41.980]   Apparently, I didn't know this.
[02:16:41.980 --> 02:16:47.700]   There are bird scooters piling up in city impound lots
[02:16:47.700 --> 02:16:51.820]   because they get abandoned and the city impounds them.
[02:16:51.820 --> 02:16:53.620]   And then people buy them.
[02:16:53.620 --> 02:16:57.500]   And it turns out with a $30 conversion kit from China,
[02:16:57.500 --> 02:17:01.300]   you just take the bird board out and it depersonalizes it.
[02:17:01.300 --> 02:17:06.140]   Turns it into a scooter untethered from the bird infrastructure.
[02:17:06.140 --> 02:17:11.060]   Corey Doctorow had the nerve to tell people that.
[02:17:11.060 --> 02:17:14.460]   And bird sent us-- and I'm quoting Corey here--
[02:17:14.460 --> 02:17:17.820]   "a legal threat of sub absurdity."
[02:17:17.820 --> 02:17:21.140]   We were publishing it in full along with a scorching response
[02:17:21.140 --> 02:17:23.660]   from the Electronic Frontier Foundation
[02:17:23.660 --> 02:17:28.780]   as a kind of celebration of truly world-class legal foolishness.
[02:17:28.780 --> 02:17:31.980]   They attempted to use 1201 of the digital millennium copyright.
[02:17:31.980 --> 02:17:36.500]   That section says, you can't disseminate circumvention tools.
[02:17:36.500 --> 02:17:40.020]   But of course, Corey didn't disseminate circumvention tools.
[02:17:40.020 --> 02:17:42.940]   He wrote a story about people doing that.
[02:17:42.940 --> 02:17:43.860]   No, not even.
[02:17:43.860 --> 02:17:46.060]   They're not-- they were just replacing the board.
[02:17:46.060 --> 02:17:47.660]   Yes, it's not circumventing.
[02:17:47.660 --> 02:17:48.460]   Yeah.
[02:17:48.460 --> 02:17:50.140]   You're taking the board out.
[02:17:50.140 --> 02:17:52.220]   You don't have to beg-- you don't have to figure it out.
[02:17:52.220 --> 02:17:55.140]   You just take out the board.
[02:17:55.140 --> 02:17:56.500]   Oh, heaven for fen.
[02:17:56.500 --> 02:17:59.620]   So somebody at Bird's probably--
[02:17:59.620 --> 02:18:02.100]   or Bird's law firm is probably going, oh crap.
[02:18:02.100 --> 02:18:02.620]   Because--
[02:18:02.620 --> 02:18:04.540]   There's a zip recruiter.
[02:18:04.540 --> 02:18:07.420]   Yes, there's a zip recruiter at that firm.
[02:18:07.420 --> 02:18:11.060]   As it turns out, Corey Doctorow is one of the chief
[02:18:11.060 --> 02:18:13.260]   campaigners against section 1201.
[02:18:13.260 --> 02:18:16.340]   And he's famous for it.
[02:18:16.340 --> 02:18:18.740]   And he isn't going to back down.
[02:18:18.740 --> 02:18:23.860]   He says, I've pledged myself to killing section 1201 of the DMCA.
[02:18:23.860 --> 02:18:26.540]   He has a project called Apollo 1201,
[02:18:26.540 --> 02:18:30.540]   a mission to eradicate DRM in our lifetime.
[02:18:30.540 --> 02:18:35.260]   This is the guy you sent the 1201 season to assist to.
[02:18:35.260 --> 02:18:38.540]   It's like pouring gasoline on the fire.
[02:18:38.540 --> 02:18:42.180]   Anyway, we're hoping we can get Corey with us down in South
[02:18:42.180 --> 02:18:42.680]   Hawaii.
[02:18:42.680 --> 02:18:44.740]   He's going to be at South by Southwest.
[02:18:44.740 --> 02:18:45.900]   Do you know Corey West?
[02:18:45.900 --> 02:18:47.020]   He is so much fun.
[02:18:47.020 --> 02:18:48.020]   I have not met him.
[02:18:48.020 --> 02:18:48.860]   One of the smartest--
[02:18:48.860 --> 02:18:49.300]   I would love the honor.
[02:18:49.300 --> 02:18:50.060]   It's scary.
[02:18:50.060 --> 02:18:51.740]   He's one of the smartest guys I ever met.
[02:18:51.740 --> 02:18:54.860]   And so I'm running to keep up with his intellect.
[02:18:54.860 --> 02:18:55.220]   It's--
[02:18:55.220 --> 02:18:56.940]   You ran for president?
[02:18:56.940 --> 02:18:58.380]   No, that was Larry Lessig.
[02:18:58.380 --> 02:18:59.380]   Oh, Larry Lessig.
[02:18:59.380 --> 02:19:00.380]   Oh, yeah.
[02:19:00.380 --> 02:19:04.300]   Another stalwart in the fight against DRM.
[02:19:04.300 --> 02:19:06.060]   Larry finally decided, we're never
[02:19:06.060 --> 02:19:08.220]   going to get rid of copy protection.
[02:19:08.220 --> 02:19:11.140]   We're never going to get rid of crazy copyright
[02:19:11.140 --> 02:19:13.060]   and intellectual property protection
[02:19:13.060 --> 02:19:17.220]   until we get rid of this massive corporate money
[02:19:17.220 --> 02:19:19.420]   pouring into politics.
[02:19:19.420 --> 02:19:21.340]   So this is back in 2016.
[02:19:21.340 --> 02:19:23.420]   Larry Lessig, who is a professor of law at Harvard,
[02:19:23.420 --> 02:19:26.580]   created Creative Commons, said, look, here's what I'm going to do.
[02:19:26.580 --> 02:19:31.620]   I'm going to run for president on one platform only
[02:19:31.620 --> 02:19:34.420]   to completely eliminate corporate donations,
[02:19:34.420 --> 02:19:38.500]   to complete campaign financing redesign
[02:19:38.500 --> 02:19:41.100]   so that it's public financing.
[02:19:41.100 --> 02:19:43.540]   There's no corporate money in it at all.
[02:19:43.540 --> 02:19:48.180]   So when you elect me, on day one, I will do that.
[02:19:48.180 --> 02:19:49.380]   On day two, I'll resign.
[02:19:49.380 --> 02:19:50.620]   I'll have a really good vice president.
[02:19:50.620 --> 02:19:52.420]   He'll take over.
[02:19:52.420 --> 02:19:54.340]   Needless to say, Corey didn't even stand a chance.
[02:19:54.340 --> 02:19:57.900]   But I thought a brilliant plan.
[02:19:57.900 --> 02:20:00.380]   Brilliant plan.
[02:20:00.380 --> 02:20:02.420]   Here is the last story.
[02:20:02.420 --> 02:20:03.660]   We're going to let you all go home.
[02:20:03.660 --> 02:20:06.300]   But it's a beautiful story.
[02:20:06.300 --> 02:20:08.500]   Cremona, Italy.
[02:20:08.500 --> 02:20:12.380]   This is where the Strata various violin
[02:20:12.380 --> 02:20:19.900]   was created in the 1700s by Antonio Strada Vari.
[02:20:19.900 --> 02:20:23.300]   They-- these violins, which are in this museum,
[02:20:23.300 --> 02:20:26.900]   are dying, not just Strata variouses,
[02:20:26.900 --> 02:20:33.260]   but other classics by Amati and Guanieri del Jesu.
[02:20:33.260 --> 02:20:36.140]   They were-- you know, age.
[02:20:36.140 --> 02:20:38.180]   We're going to lose them.
[02:20:38.180 --> 02:20:40.220]   So somebody had a brilliant idea.
[02:20:40.220 --> 02:20:42.700]   Let's digitize the sound.
[02:20:42.700 --> 02:20:48.860]   So the curator of Cremona's Museum of Violins,
[02:20:48.860 --> 02:20:58.460]   the Museo del Villolino, has taken over the auditorium
[02:20:58.460 --> 02:21:03.380]   is bringing in world class musicians to play these violins.
[02:21:03.380 --> 02:21:05.540]   But they found out there's a little problem every time.
[02:21:05.540 --> 02:21:08.580]   They're cobblestone streets all around this museum.
[02:21:08.580 --> 02:21:10.580]   Every time a truck goes by, there's
[02:21:10.580 --> 02:21:14.060]   a rumble that gets picked up by the microphones.
[02:21:14.060 --> 02:21:20.340]   Fortunately, the mayor of Cremona is a trustee of the museum.
[02:21:20.340 --> 02:21:23.620]   He decreed silence in the city.
[02:21:23.620 --> 02:21:27.540]   They have roped off the entire area of the museum.
[02:21:27.540 --> 02:21:30.180]   And they have told everybody in Cremona,
[02:21:30.180 --> 02:21:34.340]   you need to be quiet during the recordings
[02:21:34.340 --> 02:21:38.540]   so that it'll take a long time.
[02:21:38.540 --> 02:21:41.980]   Four musicians playing two violins of viola and a cello.
[02:21:41.980 --> 02:21:44.500]   They work through scales, arpeggios.
[02:21:44.500 --> 02:21:45.460]   They pluck the strings.
[02:21:45.460 --> 02:21:47.140]   They bow the strings.
[02:21:47.140 --> 02:21:51.060]   32 ultra sensitive microphones set up in the museum's auditorium
[02:21:51.060 --> 02:21:53.580]   will capture the sounds.
[02:21:53.580 --> 02:21:55.380]   They'll have to play hundreds of thousands
[02:21:55.380 --> 02:21:58.780]   of individual notes and transitions for eight hours a day,
[02:21:58.780 --> 02:22:01.100]   six days a week, for more than a month.
[02:22:01.100 --> 02:22:03.580]   But when it's done, these will all be digitized.
[02:22:03.580 --> 02:22:08.740]   And you will be able to buy stratovariest samples
[02:22:08.740 --> 02:22:11.340]   that will capture the sound of these violins, these violins
[02:22:11.340 --> 02:22:18.580]   that are losing their tone with age.
[02:22:18.580 --> 02:22:20.340]   And they'll be preserved forever.
[02:22:20.340 --> 02:22:20.980]   Isn't that great?
[02:22:20.980 --> 02:22:22.660]   This is the auditorium.
[02:22:22.660 --> 02:22:26.100]   You basically rebuild a whole song with the sounds
[02:22:26.100 --> 02:22:27.100]   that are being made.
[02:22:27.100 --> 02:22:29.700]   You'll have every note, every tone, every transition.
[02:22:29.700 --> 02:22:31.220]   Starting in January 7th, police
[02:22:31.220 --> 02:22:33.060]   cordoned off the streets around the auditorium.
[02:22:33.060 --> 02:22:35.420]   The auditorium's ventilation and elevators return off.
[02:22:35.420 --> 02:22:39.300]   Every light bulb was unscrewed to eliminate the buzzing sound.
[02:22:39.300 --> 02:22:43.820]   I think it's fantastic.
[02:22:43.820 --> 02:22:44.140]   I just had--
[02:22:44.140 --> 02:22:46.140]   Some day-- sorry.
[02:22:46.140 --> 02:22:47.980]   Some day my son who's three--
[02:22:47.980 --> 02:22:48.980]   We'll be able to hear this.
[02:22:48.980 --> 02:22:51.140]   I will buy a Roland keyboard.
[02:22:51.140 --> 02:22:51.620]   That's right.
[02:22:51.620 --> 02:22:52.700]   I'll just like, oh, yeah.
[02:22:52.700 --> 02:22:55.300]   I'll just-- yeah, it's a stratovariest voice there.
[02:22:55.300 --> 02:22:56.860]   It sounds pretty good.
[02:22:56.860 --> 02:22:57.380]   And then a bit--
[02:22:57.380 --> 02:22:59.620]   He won't have any idea of what actually went into sampling.
[02:22:59.620 --> 02:23:00.140]   Yeah.
[02:23:00.140 --> 02:23:01.140]   Isn't that a great story?
[02:23:01.140 --> 02:23:01.620]   That's amazing.
[02:23:01.620 --> 02:23:04.340]   See, I told you we'd end on a happy note.
[02:23:04.340 --> 02:23:05.620]   C-sharp.
[02:23:05.620 --> 02:23:07.700]   That's a New York Times article, which is a great-- really
[02:23:07.700 --> 02:23:08.900]   did a really nice job of this.
[02:23:08.900 --> 02:23:10.820]   It's a really fascinating article.
[02:23:10.820 --> 02:23:12.420]   Hey, I had so much fun.
[02:23:12.420 --> 02:23:14.020]   Thank you all for being here.
[02:23:14.020 --> 02:23:18.580]   Wesley Faulkner, he's developer relations guy at IBM.
[02:23:18.580 --> 02:23:19.980]   Anything you want to plug, Wesley?
[02:23:19.980 --> 02:23:22.700]   Anything you up to these days?
[02:23:22.700 --> 02:23:25.580]   Well, if you're a developer and you're watching this show,
[02:23:25.580 --> 02:23:26.300]   get in touch with me.
[02:23:26.300 --> 02:23:28.540]   Send me a message on Twitter.
[02:23:28.540 --> 02:23:30.180]   And we'll connect.
[02:23:30.180 --> 02:23:37.660]   I am trying to figure out who would be good to add to my own work
[02:23:37.660 --> 02:23:40.380]   network in terms of figuring of--
[02:23:40.380 --> 02:23:41.900]   we have speaking opportunities.
[02:23:41.900 --> 02:23:44.940]   We have round tables.
[02:23:44.940 --> 02:23:48.740]   We have different things where, as a company,
[02:23:48.740 --> 02:23:52.820]   we need experts to give their opinion on or possibly fly you
[02:23:52.820 --> 02:23:53.900]   to.
[02:23:53.900 --> 02:23:57.060]   And so I'm trying to increase my network of developers.
[02:23:57.060 --> 02:24:00.460]   So if you're a developer on machine learning,
[02:24:00.460 --> 02:24:07.460]   any type of R, Python, scientific research, data mining,
[02:24:07.460 --> 02:24:10.820]   anything that's related to computers that you type on
[02:24:10.820 --> 02:24:13.780]   and make a program, send me a message on Twitter,
[02:24:13.780 --> 02:24:15.660]   and let's connect.
[02:24:15.660 --> 02:24:17.460]   You cannot steal Sebastian Peak.
[02:24:17.460 --> 02:24:20.100]   That's all I'm going to say.
[02:24:20.100 --> 02:24:21.340]   Sebastian, you're stuck at PC--
[02:24:21.340 --> 02:24:24.140]   I work for IBM, not Intel.
[02:24:24.140 --> 02:24:26.900]   There's a difference.
[02:24:26.900 --> 02:24:28.820]   He's editor-in-chief at PCpert.com.
[02:24:28.820 --> 02:24:31.580]   And I am grateful to have him as our new host of this week
[02:24:31.580 --> 02:24:33.780]   in computer hardware with Patrick Norton.
[02:24:33.780 --> 02:24:35.020]   Sebastian, it was great to have you.
[02:24:35.020 --> 02:24:36.020]   Anything you want to plug?
[02:24:36.020 --> 02:24:39.060]   I'm looking forward to reading that roundup of the new cards
[02:24:39.060 --> 02:24:39.700]   from NVIDIA.
[02:24:39.700 --> 02:24:41.820]   That should be very interesting.
[02:24:41.820 --> 02:24:42.740]   Yeah.
[02:24:42.740 --> 02:24:45.300]   Well, just the website PCpert.com.
[02:24:45.300 --> 02:24:46.820]   And there's a review.
[02:24:46.820 --> 02:24:49.500]   I already have a preliminary review of the RTX 2060,
[02:24:49.500 --> 02:24:51.060]   their new lower cost card that still
[02:24:51.060 --> 02:24:52.500]   has retracing capabilities.
[02:24:52.500 --> 02:24:53.900]   I'll be adding to that.
[02:24:53.900 --> 02:24:55.060]   Like my plans in the coming weeks
[02:24:55.060 --> 02:24:59.540]   are to add the DLSS story as that becomes available to add more
[02:24:59.540 --> 02:25:03.460]   of like as the board partners like ASIS and MSIE/VGA
[02:25:03.460 --> 02:25:05.140]   release their versions and what they can do,
[02:25:05.140 --> 02:25:07.100]   some of them are overclocked out of the box, that kind of stuff.
[02:25:07.100 --> 02:25:10.300]   So just check out the website PCpert.com.
[02:25:10.300 --> 02:25:12.220]   And you can follow me on Twitter if you want to.
[02:25:12.220 --> 02:25:13.180]   Add Sebastian Peak.
[02:25:13.180 --> 02:25:17.340]   But how much would a 460 set me back?
[02:25:17.340 --> 02:25:19.180]   Uh, 349.
[02:25:19.180 --> 02:25:20.900]   That's not too bad.
[02:25:20.900 --> 02:25:21.220]   No.
[02:25:21.220 --> 02:25:24.900]   And it's really not the mid-range card people were expecting.
[02:25:24.900 --> 02:25:26.260]   Like, oh, like 1080p gaming.
[02:25:26.260 --> 02:25:30.300]   Like, no, this actually is like 1440 gaming or like ultra-wide
[02:25:30.300 --> 02:25:31.780]   1080 gaming.
[02:25:31.780 --> 02:25:35.900]   So it's really kind of a step between the mid-range
[02:25:35.900 --> 02:25:38.580]   and the high end and 349 is pretty much exactly where
[02:25:38.580 --> 02:25:39.060]   it should be.
[02:25:39.060 --> 02:25:42.260]   They were very fair with pricing this time.
[02:25:42.260 --> 02:25:43.740]   That's-- I might--
[02:25:43.740 --> 02:25:45.900]   I just bought a video card for a server machine.
[02:25:45.900 --> 02:25:48.100]   I guess I don't really need anything fancy in a server machine.
[02:25:48.100 --> 02:25:52.420]   But it'd be nice if I could play, I don't know, Fortnite on it.
[02:25:52.420 --> 02:25:58.340]   Or if the new version of Quake 2 that someone came up with
[02:25:58.340 --> 02:25:59.140]   that uses it.
[02:25:59.140 --> 02:25:59.900]   It's entirely ray-free.
[02:25:59.900 --> 02:26:01.340]   What?
[02:26:01.340 --> 02:26:01.780]   Yeah.
[02:26:01.780 --> 02:26:04.060]   It's called Q2VKPT.
[02:26:04.060 --> 02:26:05.580]   And I could not type that straight.
[02:26:05.580 --> 02:26:07.100]   I could go back and direct it later.
[02:26:07.100 --> 02:26:12.380]   But Quake 2, completely from the ground up, redone with ray-free.
[02:26:12.380 --> 02:26:12.820]   Oh my god.
[02:26:12.820 --> 02:26:14.900]   I loved Quake 2.
[02:26:14.900 --> 02:26:16.700]   And Carmack did an amazing job back in the day
[02:26:16.700 --> 02:26:18.700]   with lighting effects, with what he had.
[02:26:18.700 --> 02:26:20.420]   But now the hardware can do it.
[02:26:20.420 --> 02:26:20.820]   And it looks--
[02:26:20.820 --> 02:26:21.820]   Oh, man.
[02:26:21.820 --> 02:26:23.380]   The videos look amazing.
[02:26:23.380 --> 02:26:24.660]   I haven't installed it yet.
[02:26:24.660 --> 02:26:25.460]   It's all free.
[02:26:25.460 --> 02:26:28.300]   You can actually use the Quake 2 demo.
[02:26:28.300 --> 02:26:30.420]   It only needs some of the basic files.
[02:26:30.420 --> 02:26:33.060]   And then there's this whole new engine that's
[02:26:33.060 --> 02:26:34.340]   been created to run it.
[02:26:34.340 --> 02:26:37.740]   And this has been like going on since the mid to late 2000s.
[02:26:37.740 --> 02:26:40.860]   But they finally have a full half-traced version that
[02:26:40.860 --> 02:26:42.460]   runs on the new RTX card.
[02:26:42.460 --> 02:26:46.420]   Oh, that sounds really interesting.
[02:26:46.420 --> 02:26:49.140]   Now I'm thinking maybe-- I think I bought a 1060.
[02:26:49.140 --> 02:26:51.540]   I should send it back.
[02:26:51.540 --> 02:26:56.460]   Yeah, the 2060 is literally double the performance of the 1060.
[02:26:56.460 --> 02:26:58.300]   Holy cow.
[02:26:58.300 --> 02:26:58.820]   So--
[02:26:58.820 --> 02:27:00.260]   Holy cow.
[02:27:00.260 --> 02:27:01.220]   It's worth it.
[02:27:01.220 --> 02:27:04.260]   If you're still within that return window, get a 2060.
[02:27:04.260 --> 02:27:04.820]   That might be.
[02:27:04.820 --> 02:27:05.540]   I got a new egg.
[02:27:05.540 --> 02:27:07.460]   That means I probably could send it back.
[02:27:07.460 --> 02:27:09.060]   And I know what you were about to say, which is,
[02:27:09.060 --> 02:27:11.340]   don't forget to tune in this week in computer hardware.
[02:27:11.340 --> 02:27:11.940]   It's right.
[02:27:11.940 --> 02:27:13.020]   How could I forget?
[02:27:13.020 --> 02:27:13.860]   How could you forget?
[02:27:13.860 --> 02:27:16.860]   The show that covers me and Patrick just talking.
[02:27:16.860 --> 02:27:19.700]   I try to make sure we talk about projectors as often
[02:27:19.700 --> 02:27:20.620]   as we possibly can.
[02:27:20.620 --> 02:27:21.620]   Why is that?
[02:27:21.620 --> 02:27:24.140]   See, just because we're both like projector nerds.
[02:27:24.140 --> 02:27:25.820]   You're video guys.
[02:27:25.820 --> 02:27:27.100]   I am.
[02:27:27.100 --> 02:27:27.620]   He is.
[02:27:27.620 --> 02:27:29.940]   I have the strange thing about my house
[02:27:29.940 --> 02:27:31.700]   and my wife puts up with me for some reason.
[02:27:31.700 --> 02:27:33.460]   But we have an OLED.
[02:27:33.460 --> 02:27:37.140]   I had to have the B60 led back in 2016.
[02:27:37.140 --> 02:27:38.980]   Yeah, that's what I have.
[02:27:38.980 --> 02:27:44.660]   And then I also have this nice Epson UB5030 projector
[02:27:44.660 --> 02:27:47.100]   and 100-inch screen.
[02:27:47.100 --> 02:27:48.300]   So it's like--
[02:27:48.300 --> 02:27:48.660]   Decisions.
[02:27:48.660 --> 02:27:50.020]   But we can't have both.
[02:27:50.020 --> 02:27:54.980]   And then she was like, well, I had a projector on loan for review.
[02:27:54.980 --> 02:27:55.740]   And I showed it to her.
[02:27:55.740 --> 02:27:57.340]   She's like, oh, this is great.
[02:27:57.340 --> 02:27:58.380]   And she likes sports.
[02:27:58.380 --> 02:27:59.660]   She's actually a big football fan.
[02:27:59.660 --> 02:28:03.580]   So I'm like, you can watch football on the entire wall.
[02:28:03.580 --> 02:28:05.500]   And then I can have my OLED TV.
[02:28:05.500 --> 02:28:06.260]   So she was sold.
[02:28:06.260 --> 02:28:07.420]   So we actually have both.
[02:28:07.420 --> 02:28:09.380]   So the living room was all screens.
[02:28:09.380 --> 02:28:10.780]   Nice.
[02:28:10.780 --> 02:28:16.820]   We borrowed the high-sense dual laser 100-inch short throw
[02:28:16.820 --> 02:28:19.020]   projector for Thanksgiving.
[02:28:19.020 --> 02:28:20.180]   And I haven't given it back yet.
[02:28:20.180 --> 02:28:21.700]   But I have it at home.
[02:28:21.700 --> 02:28:23.780]   It is nice to have a screen that big to watch the--
[02:28:23.780 --> 02:28:26.300]   well, we'll keep it through the Super Bowl for short.
[02:28:26.300 --> 02:28:26.860]   It's really nice.
[02:28:26.860 --> 02:28:28.660]   Ultra short throws and short throws are amazing.
[02:28:28.660 --> 02:28:31.780]   Because the ultra short throw I've had for a little while.
[02:28:31.780 --> 02:28:34.660]   I set it on a table, like a foot and a half away
[02:28:34.660 --> 02:28:36.180]   from the wall and had 100-inch screen.
[02:28:36.180 --> 02:28:39.020]   Yeah, that's exactly it.
[02:28:39.020 --> 02:28:39.940]   It's not even that far.
[02:28:39.940 --> 02:28:41.860]   It's eight inches away from the screen.
[02:28:41.860 --> 02:28:43.740]   We just love this thing.
[02:28:43.740 --> 02:28:45.300]   And the thing--
[02:28:45.300 --> 02:28:48.980]   Scott Wilkinson and Robert Herron came in and calibrated it.
[02:28:48.980 --> 02:28:53.220]   But when I turn it to vivid mode, when I watch the football,
[02:28:53.220 --> 02:28:55.780]   I don't have to green to look like it's fluorescent.
[02:28:55.780 --> 02:28:57.260]   It's better that way.
[02:28:57.260 --> 02:28:57.900]   I don't know why.
[02:28:57.900 --> 02:28:59.180]   I just like it that way.
[02:28:59.180 --> 02:29:00.380]   Well, it's great to have you Sebastian.
[02:29:00.380 --> 02:29:01.700]   Welcome to the team.
[02:29:01.700 --> 02:29:02.220]   Thank you.
[02:29:02.220 --> 02:29:05.500]   And to my Mill Splainer friend.
[02:29:05.500 --> 02:29:07.060]   Where would we be?
[02:29:07.060 --> 02:29:10.740]   I need to register Millsplainer.com or something like that.
[02:29:10.740 --> 02:29:11.700]   We need you.
[02:29:11.700 --> 02:29:12.620]   We need you.
[02:29:12.620 --> 02:29:16.460]   We need somebody to tell us old farts what's going on with the kids
[02:29:16.460 --> 02:29:16.740]   today.
[02:29:16.740 --> 02:29:19.020]   Although, fair warning, you're going
[02:29:19.020 --> 02:29:22.540]   to be replaced by a Genes ear in anything else.
[02:29:22.540 --> 02:29:25.220]   I already am constantly going, wait, what?
[02:29:25.220 --> 02:29:26.940]   I don't know what's going on.
[02:29:26.940 --> 02:29:28.860]   I'm so thankful I have younger siblings
[02:29:28.860 --> 02:29:30.980]   that I can sort of ping for advice.
[02:29:30.980 --> 02:29:33.180]   Why are you putting on blindfold seat typots?
[02:29:33.180 --> 02:29:33.980]   Why is that?
[02:29:33.980 --> 02:29:35.020]   Oh, god.
[02:29:35.020 --> 02:29:36.420]   What is that all about?
[02:29:36.420 --> 02:29:40.300]   Back in my day, we didn't do things like that.
[02:29:40.300 --> 02:29:42.460]   Millsplainer.com.
[02:29:42.460 --> 02:29:43.740]   Ladies and gentlemen, everybody should
[02:29:43.740 --> 02:29:47.140]   go to chihuahua.coffee, which is the best game ever
[02:29:47.140 --> 02:29:48.300]   for a website.
[02:29:48.300 --> 02:29:50.180]   Yeah, I can thank Renee Ritchie for that.
[02:29:50.180 --> 02:29:55.100]   As far as something to plug, check out somehowimanage.biz,
[02:29:55.100 --> 02:29:56.700]   or you can head to JasonSnells.
[02:29:56.700 --> 02:30:01.820]   It's the incomparable.com and look for somehowimanage.
[02:30:01.820 --> 02:30:03.180]   Every time I keep forgetting that I
[02:30:03.180 --> 02:30:06.460]   need to update some of these pages on my site,
[02:30:06.460 --> 02:30:08.580]   and then you lovely people bring them up,
[02:30:08.580 --> 02:30:10.660]   and then I'm like, wow, you could do that.
[02:30:10.660 --> 02:30:12.180]   A little bit of a problem.
[02:30:12.180 --> 02:30:13.420]   Not that I don't know anything about it.
[02:30:13.420 --> 02:30:14.900]   You like to launch shows.
[02:30:14.900 --> 02:30:17.540]   [LAUGHTER]
[02:30:17.540 --> 02:30:18.580]   Yes, yes indeed.
[02:30:18.580 --> 02:30:19.700]   I know a little about that.
[02:30:19.700 --> 02:30:22.300]   But the latest is somehowimanage.biz.
[02:30:22.300 --> 02:30:26.380]   Somehowimanage.biz will take you right to that show.
[02:30:26.380 --> 02:30:27.220]   Love it.
[02:30:27.220 --> 02:30:27.900]   Thank you, Micah.
[02:30:27.900 --> 02:30:29.340]   Great to have you once again.
[02:30:29.340 --> 02:30:30.820]   And thanks to all of you for joining us.
[02:30:30.820 --> 02:30:32.660]   We do tweet every Sunday afternoon,
[02:30:32.660 --> 02:30:34.420]   3 p.m. Pacific, 6 p.m. Eastern time.
[02:30:34.420 --> 02:30:35.380]   You can stop by.
[02:30:35.380 --> 02:30:37.740]   And in the studio, we had a nice studio audience.
[02:30:37.740 --> 02:30:39.180]   They thank you guys for joining us.
[02:30:39.180 --> 02:30:41.700]   All you have to do is email tickets at twitter.tv.
[02:30:41.700 --> 02:30:42.900]   We'll put a chair out for you.
[02:30:42.900 --> 02:30:48.340]   You can also watch our live stream, twit.tv/live.
[02:30:48.340 --> 02:30:50.460]   We stream video and audio of everything we do,
[02:30:50.460 --> 02:30:52.100]   so you can join us at any time.
[02:30:52.100 --> 02:30:55.220]   If you do that, though, join the kids who are watching
[02:30:55.220 --> 02:30:56.620]   in the back of the class.
[02:30:56.620 --> 02:31:01.940]   They're all hanging out on the chatroom at irc.twit.tv.
[02:31:01.940 --> 02:31:03.660]   On-demand versions of everything we do also
[02:31:03.660 --> 02:31:05.940]   available on the website, twit.tv.
[02:31:05.940 --> 02:31:07.940]   Or wherever you get your favorite podcasts,
[02:31:07.940 --> 02:31:08.900]   just subscribe that way.
[02:31:08.900 --> 02:31:13.500]   You'll get every episode the minute it's done.
[02:31:13.500 --> 02:31:15.820]   Twit.tv.
[02:31:15.820 --> 02:31:16.980]   Thank you all for being here.
[02:31:16.980 --> 02:31:18.100]   We'll see you next time.
[02:31:18.100 --> 02:31:19.100]   Another twit.
[02:31:19.100 --> 02:31:20.660]   [MUSIC PLAYING]
[02:31:20.660 --> 02:31:22.660]   Bye.
[02:31:22.660 --> 02:31:24.660]   [MUSIC PLAYING]
[02:31:24.660 --> 02:31:26.660]   [MUSIC PLAYING]
[02:31:26.660 --> 02:31:29.660]   Do it the Twitter. All right. Do it the Twitter.

