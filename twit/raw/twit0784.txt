;FFMETADATA1
title=Karsten Has Pictures
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=784
genre=Podcast
comment=https://twit.tv/twit
copyright=These podcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:04.320]   It's time for Twent this week in Tech. What a show we've got for you. Amy Webb is here.
[00:00:04.320 --> 00:00:08.800]   Mike Masnick from Tech Dirt. My buddy Ian Thompson from the Register.
[00:00:08.800 --> 00:00:14.800]   Fortnite booted off the App Store. Why? What's happening? And will that lawsuit
[00:00:14.800 --> 00:00:19.760]   have any chance of success? Uber and Lyft say we're out of here.
[00:00:19.760 --> 00:00:26.560]   And the conflict with China. It's more than just TikTok. Amy Webb explains. It's all coming up next
[00:00:26.560 --> 00:00:31.520]   on Twent. This week at Tech comes to you from Twent's LastPass Studios.
[00:00:31.520 --> 00:00:35.840]   Securing every access point in your company doesn't have to be a challenge. LastPass
[00:00:35.840 --> 00:00:41.280]   unifies access and authentication to make securing your employees simple and secure.
[00:00:41.280 --> 00:00:46.000]   Even when they're working remotely, check out lastpass.com/twent to learn more.
[00:00:46.000 --> 00:00:48.640]   [Music]
[00:00:48.640 --> 00:00:54.480]   Podcasts you love. From people you trust. This is Twent.
[00:00:54.480 --> 00:01:09.120]   This is Twent this week in Tech. Episode 784 recorded Sunday August 16th, 2020.
[00:01:09.680 --> 00:01:14.480]   Carsten has pictures. This week, Attack is brought to you by
[00:01:14.480 --> 00:01:21.040]   Worldwide Technology. WWT's Advanced Technology Center is like no other testing and research lab.
[00:01:21.040 --> 00:01:26.160]   With more than half a billion dollars of equipment, including solutions from key partners like HPE
[00:01:26.160 --> 00:01:34.640]   and Intel and its virtual so you can access it 24/7. To learn more about WWT, the ATC, and become a
[00:01:34.640 --> 00:01:44.480]   member of their growing community, go to www.wt.com/twent. And by Wasabi Hot Cloud Storage.
[00:01:44.480 --> 00:01:50.080]   Thinking about moving your data storage to the cloud, Wasabi is enterprise class cloud storage
[00:01:50.080 --> 00:01:55.920]   at one-fifth of price of Amazon S3 and faster than the competition with no fees for egress or
[00:01:55.920 --> 00:02:02.560]   API requests and no complex storage tiers. Start a free trial at wasabi.com and enter the code
[00:02:02.560 --> 00:02:10.160]   Twent. And by LastPass. Allow your remote workforce the ability to do their best work without jumping
[00:02:10.160 --> 00:02:16.880]   through hoops. Ensure your business is security with LastPass. Visit LastPass.com/twent to find
[00:02:16.880 --> 00:02:24.320]   out how they can help you. And by ExpressVPN. ExpressVPN is ridiculously fast. You can stream
[00:02:24.320 --> 00:02:30.160]   everything in HD quality with zero buffering. For three extra months free with a one-year package,
[00:02:30.160 --> 00:02:33.280]   go to expressvpn.com/twent.
[00:02:33.280 --> 00:02:44.640]   It's time for Twent this week in Tech. The show we get together with strangely dressed
[00:02:44.640 --> 00:02:51.280]   tech journalists and talk about what's been happening this week. Apparently this week we are
[00:02:51.280 --> 00:02:56.720]   all characters from Fortnite. I'm not sure exactly what is going on. Ian Thompson is here.
[00:02:56.720 --> 00:03:01.120]   Unaccountably his hair and mustache and even eyebrows are now slightly green.
[00:03:01.120 --> 00:03:08.720]   Yes indeed. Customers are a very persuasive person in that regards but my wife is refusing
[00:03:08.720 --> 00:03:13.760]   to kiss me until I shower. I swear to God, Carson won't last long. He has pictures or something.
[00:03:13.760 --> 00:03:18.880]   He's able to convince you. Never let this guy go into politics. He's just waiting to do something
[00:03:18.880 --> 00:03:25.600]   insane. Also with us from the future today Institute, our favorite futurist, the only one I know,
[00:03:25.600 --> 00:03:32.960]   Amy Webb, who is living in the future today. That is a good look, Amy. Thank you.
[00:03:32.960 --> 00:03:43.200]   A purplish, pinkish wig, strange future glasses. It's very, very kind that Amy predicts we'll all
[00:03:43.200 --> 00:03:48.880]   be wearing in the next decade or so. There's certainly augmented reality going on in those
[00:03:48.880 --> 00:03:53.600]   glasses I can tell. I can tell. Yes, and I printed a necklace just for a second.
[00:03:53.600 --> 00:04:01.520]   Ooh, a Tesseratz necklace. That's cool. Excellent. So do you do the 3D printing thing? Obviously,
[00:04:01.520 --> 00:04:07.840]   you do. I don't know. I can take it or leave it. We do 3D print part replacement parts for things
[00:04:07.840 --> 00:04:13.600]   and my daughter prototype stuff but it's more of a toy, really. Yes. Somebody called the radio
[00:04:13.600 --> 00:04:17.520]   show and said, "I want to get my mother in law. She's really into cookies. She wants a 3D printed
[00:04:17.520 --> 00:04:25.360]   print cookie cutters." And I said, "Just go to Target. Don't, don't." I mean, I can't think of a design.
[00:04:25.360 --> 00:04:31.360]   Yeah, that I wouldn't do. We did try to extrude chocolate that I would not attempt to do.
[00:04:31.360 --> 00:04:38.080]   It seems like these 3D printers are more work than they're really fun.
[00:04:38.080 --> 00:04:43.040]   They are. And especially if you're trying, if you don't have any background in CAD,
[00:04:43.040 --> 00:04:46.720]   trying to get a design. Oh, it's crazy. Yeah. You know, put into the right format.
[00:04:46.720 --> 00:04:52.320]   And then you got to calibrate it. And the first one always looks like the first pancake literally.
[00:04:52.320 --> 00:04:56.960]   And then it's just... And honestly, like, I don't... Yes, it's fun to play with. It also,
[00:04:56.960 --> 00:05:02.240]   it's a lot of plastic. And at some point, that stuff is going to get thrown out and I don't love
[00:05:02.240 --> 00:05:08.480]   the idea of contributing additional plastic, you know, into the garbage. Yeah. Good. Yeah. All
[00:05:08.480 --> 00:05:18.160]   that PLA. I'm dressed, apparently, it's a toss-up between Eddie Munster and Uncle Fester. I don't
[00:05:18.160 --> 00:05:24.960]   know which I am mixing the memes on that one. And also, we're thrilled to have from Tech Dirt,
[00:05:24.960 --> 00:05:30.960]   the return of Mike Masnick, who is now regretting probably, is agreeing to appear on the show today.
[00:05:30.960 --> 00:05:32.640]   He's living in his blue room. Oh, it's wonderful.
[00:05:32.640 --> 00:05:37.680]   [Singing]
[00:05:37.680 --> 00:05:40.800]   Actually, the reason we're here armed... Whoa!
[00:05:40.800 --> 00:05:48.640]   I didn't know the gun was loaded. The reason we're here armed... A lot of Americans say that.
[00:05:48.640 --> 00:05:59.360]   Yeah. Whoa! Is because you can't play Fortnite on iOS anymore or Android. It's hard to hit the
[00:05:59.360 --> 00:06:04.640]   camera. Let me just see if I can really... Yeah, we'll get there.
[00:06:04.640 --> 00:06:22.080]   Fortnite clearly was itching for a fight and decided to take this time to modify the
[00:06:22.080 --> 00:06:30.640]   in-app purchases on its app, both on iOS and Android, in order to get pulled down on both.
[00:06:30.640 --> 00:06:41.360]   At which point, they released a video that, oddly, they had just ready to hand, called 1980 Fortnite
[00:06:41.360 --> 00:06:51.600]   that may remind you a little bit of a video that we saw in 1984, people sitting watching a giant
[00:06:51.600 --> 00:06:57.680]   screen, a young woman with... Well, it's not a sledgehammer, actually. It's a unicorn hobby horse.
[00:06:57.680 --> 00:07:05.440]   And she's running away from the police. She arrives and tosses it through the screen,
[00:07:05.440 --> 00:07:16.240]   which smashes. And then Epic Games has defied the app store monopoly in retaliation. Apple is
[00:07:16.240 --> 00:07:24.880]   blocking Fortnite from 1 billion devices. Join the fight to stop 2020 from being 1984 hashtag
[00:07:24.880 --> 00:07:33.120]   free Fortnite. They were ready. They also went to court, saw an injunction. They did the same thing
[00:07:33.120 --> 00:07:36.720]   to Google. They didn't have a video ready for Google. I don't know. Maybe they thought Google
[00:07:36.720 --> 00:07:41.680]   wouldn't pay its attention. You may remember that Tim Sweeney of Epic didn't put Fortnite on the
[00:07:41.680 --> 00:07:45.440]   Google Play Store at first, saying you should sideload it because we don't want to pay the 30%.
[00:07:46.240 --> 00:07:55.200]   Eventually they gave in. Mike, is there legal merit in what Epic is doing? Will they prevail in
[00:07:55.200 --> 00:08:05.680]   court? Or can they? It's a big hill to climb. That doesn't mean that they won't win. They might.
[00:08:05.680 --> 00:08:12.560]   But if I were taking odds on whether or not Epic would prevail, I would say they are unlikely to
[00:08:12.560 --> 00:08:18.720]   prevail. Though I was impressed. Not only did they have that 1984 video, they actually referenced 1984
[00:08:18.720 --> 00:08:25.360]   in the complaint so that they're marketing legal team. It's a 60 page complaint. I don't think
[00:08:25.360 --> 00:08:30.160]   they wrote that overnight. No. No, no, no, they had but it's impressive not only did they have
[00:08:30.160 --> 00:08:34.160]   it ready, but that they had worked out with the marketing. Yes. This whole framing. Well, wait,
[00:08:34.160 --> 00:08:38.960]   that's not though. I think that's part of it. In a way that I think if I'm the judge,
[00:08:39.920 --> 00:08:45.920]   that's going to taint this a little bit because it's so clear that they set this whole thing up,
[00:08:45.920 --> 00:08:54.560]   that they prepared for months for this moment. I mean, part of the thing that's interesting
[00:08:54.560 --> 00:08:59.520]   about it, I guess, is that if you look at it from Apple's perspective, they were going to be in
[00:08:59.520 --> 00:09:04.240]   trouble no matter which decision they made. If they let Fortnite get away with this,
[00:09:04.240 --> 00:09:09.520]   then everybody else would be complaining that, oh, they're giving special treatment to Fortnite.
[00:09:09.520 --> 00:09:12.800]   And then of course, when they say, well, Fortnite is violating the rules, so therefore, we're going
[00:09:12.800 --> 00:09:18.320]   to hold them from the store, then they have all these other issues. So no matter which way it was
[00:09:18.320 --> 00:09:25.760]   going to go, like Apple didn't have any good choices. And I guess Google was picking sides and
[00:09:25.760 --> 00:09:29.840]   decided they were going to realizing that if Apple loses, they're going to be in trouble too.
[00:09:29.840 --> 00:09:35.920]   Yeah, Apple, of course, is already under the gun in the EU over
[00:09:35.920 --> 00:09:42.000]   App Store monopoly. In the United States, Tim Cook was brought up in front of Congress,
[00:09:42.000 --> 00:09:45.440]   along with three other executives, as you know, a couple of weeks ago. And that was,
[00:09:45.440 --> 00:09:51.600]   you know, one of the issues that Congress was interested in, the antitrust subcommittee
[00:09:51.600 --> 00:09:57.040]   will have a report probably not till the end of the year early next year about this. But there's
[00:09:57.040 --> 00:10:04.400]   some concern the FTC is looking into it that maybe Apple is monopolistic. On the other hand,
[00:10:04.400 --> 00:10:10.800]   I'll give this argument so you guys don't have to. A lot of people, I know, say, hey, Apple,
[00:10:10.800 --> 00:10:17.520]   it's as if Apple built a great mall. And forever 21 moved in and said, well, but we don't want to
[00:10:17.520 --> 00:10:23.600]   pay you any rent. We just want to be in your mall. They're free loading, Epic's free loading,
[00:10:24.240 --> 00:10:28.560]   on what Apple has built with its platform and its store. Do you agree, Amy? Is that
[00:10:28.560 --> 00:10:34.320]   seem reasonable? Yeah, so this is there's a there's a couple of things happening here. One,
[00:10:34.320 --> 00:10:41.680]   we don't have a clear definition for what the future of distribution would look like. So,
[00:10:41.680 --> 00:10:48.000]   what's interesting about, I think it's interesting that Epic is trying to initiate an antitrust
[00:10:48.000 --> 00:10:53.520]   battle because the the hearing that happened a week ago or two weeks ago,
[00:10:53.520 --> 00:11:02.000]   reflects lawmakers sort of scrambling to first of all group together companies that really are
[00:11:02.000 --> 00:11:07.680]   doing disparate things. And second of all, using policy that was written in 1890. So,
[00:11:07.680 --> 00:11:14.320]   the Sherman Act has written- I know about App Stores. Right, but this is important because
[00:11:14.320 --> 00:11:20.400]   there's very little substantive analogy to make about the means for distribution
[00:11:20.400 --> 00:11:30.720]   in a digital setting and the railroad system. So, that being said, this is an interesting,
[00:11:30.720 --> 00:11:35.680]   this could be an interesting and possible possibly the only way to really crack,
[00:11:35.680 --> 00:11:41.520]   crack through. And that's because this is a limited circumstance. So, Apple charging 30%,
[00:11:42.640 --> 00:11:48.080]   if you look at other industries, that percentage of rev share is higher than what you would see
[00:11:48.080 --> 00:11:55.360]   elsewhere. It's not though higher than on the consoles, Sony, Microsoft and Nintendo
[00:11:55.360 --> 00:12:01.440]   charge the same 30% fee and have the same control. This all dates back to the days when
[00:12:01.440 --> 00:12:08.320]   Atari Nintendo were swamped by crappy games and they learned very early on, we got to keep
[00:12:08.320 --> 00:12:13.760]   type control over what's on our console. Fortnite doesn't seem to mind that 30%.
[00:12:13.760 --> 00:12:19.040]   It's the data on the other end. So, the key difference here is that when you've got a console
[00:12:19.040 --> 00:12:26.080]   game with heavy DRM protections, you're talking about a limited use case. Now,
[00:12:26.080 --> 00:12:34.640]   with a game being on a different type of device, one that hinges on the Play Store and Apple Store,
[00:12:35.440 --> 00:12:41.920]   there's a wealth of other data there. And so, I think if they were, it really depends,
[00:12:41.920 --> 00:12:47.360]   if they try to define antitrust very narrowly, I think they have a shot. I think it could be more
[00:12:47.360 --> 00:12:53.440]   compelling for them to talk about the future of all of this data that's being generated.
[00:12:53.440 --> 00:13:02.160]   And the fact that that in and of itself is also, you know, but that has value. And they can't easily
[00:13:02.160 --> 00:13:09.520]   act those data in addition to having to pay the fees. And you can't, you know, there is no other
[00:13:09.520 --> 00:13:14.560]   way to play Fortnite. You either have to jailbreak and I guess somehow... That's true on Google,
[00:13:14.560 --> 00:13:19.520]   you could sideload, but there's nothing you can do on Apple. Right. So, I think Google had... I don't
[00:13:19.520 --> 00:13:25.440]   think I have a strong of a case against Google, but the reality is that Google, you know, Facebook,
[00:13:25.440 --> 00:13:32.000]   Amazon and Apple are all facing some flavor of antitrust. And the blanket application,
[00:13:32.000 --> 00:13:36.960]   we already know, doesn't apply. So, what's interesting here is Epic could force the hand of Apple and
[00:13:36.960 --> 00:13:43.920]   start to change parts of the industry. What is the... So, Apple's response to this, by the way,
[00:13:43.920 --> 00:13:53.200]   let me paraphrase it is, this is disingenuous of Epic. They've had apps on our App Store for 10 years,
[00:13:53.200 --> 00:13:58.800]   they've benefited from their presence on the App Store for 10 years. Now, Apple says Epic's
[00:13:58.800 --> 00:14:03.360]   business interests lead it to push for a special arrangement that would be unfair to other
[00:14:03.360 --> 00:14:09.600]   developers. Whose reputation is more at risk here? Epic's or Apple's? Ian?
[00:14:09.600 --> 00:14:15.840]   Honestly, I think this is a really interesting case because, I mean, let's face it, you don't
[00:14:15.840 --> 00:14:20.240]   get Fortnite because it's on the Apple Store, you get Fortnite because it's a really good game.
[00:14:21.280 --> 00:14:27.040]   And Apple has said they run a closed ecosystem. If you want apps on our phones or on our hardware,
[00:14:27.040 --> 00:14:31.280]   you have to go through us. And that seems blatantly anti-compestive. I've missed
[00:14:31.280 --> 00:14:36.720]   on a foreigner over here, but even so. What is that happening? He didn't do with anything.
[00:14:36.720 --> 00:14:42.800]   Well, I mean, not knowing quite how... Oh, what are antitrust laws? They're different.
[00:14:42.800 --> 00:14:46.640]   I've been told, and Mike's probably more an expert of on this than I am, but they're different in the
[00:14:47.440 --> 00:14:52.240]   EU than they are in the United States. Oh, very much so. Yeah. You would not get away with this
[00:14:52.240 --> 00:14:59.040]   in the EU, but I mean, US regulators are very much the sort of, "Oh, well, do whatever you like,
[00:14:59.040 --> 00:15:04.080]   and we'll issue a minor find." Honestly, I'm with Epic on this one. And yes, Apple
[00:15:04.080 --> 00:15:09.920]   slept walked into this. They walked right into an ambush. They had the Epic had the trailer
[00:15:09.920 --> 00:15:16.160]   ready to go. They had the lawsuits ready to go. This was done around about the time that Apple was
[00:15:16.160 --> 00:15:20.320]   facing antitrust talks in Congress. This was a hit job.
[00:15:20.320 --> 00:15:27.040]   Although, if I'm a if I'm a Fortnite player, I might be pissed off on the one hand because
[00:15:27.040 --> 00:15:34.000]   we know Tim Sweeney personally made $7 billion last year from Fortnite. The Epic made even more.
[00:15:34.000 --> 00:15:38.320]   So it's not like they're hurting, giving Apple their 30% hasn't hurt them.
[00:15:38.320 --> 00:15:45.600]   It's the principle of the thing, surely. I mean, yes. Okay. Apple says, if you want to run software
[00:15:45.600 --> 00:15:50.480]   on our phones, you have to give us 30%. That seems to me to be anti-competitive.
[00:15:50.480 --> 00:15:56.880]   Apple is not the percentage. It's not the percentage. It's the fact that there aren't others in the
[00:15:56.880 --> 00:16:03.120]   market where you can easily, if it's the case that most people have one of two operating systems
[00:16:03.120 --> 00:16:09.920]   and the preponderance of young people who play Fortnite are on iOS, then it would follow that
[00:16:09.920 --> 00:16:14.000]   you can't play the game reasonably in any other way because Apple has minimized the market and
[00:16:14.000 --> 00:16:17.600]   and collapsed whatever competition there might have been.
[00:16:17.600 --> 00:16:22.880]   By the way, we should mention, I don't know how this will impact it, but Tencent has a
[00:16:22.880 --> 00:16:29.200]   significant ownership stake in this. So, all significant ownership and everything.
[00:16:29.200 --> 00:16:36.400]   And everybody, yeah, pretty much everybody. So, but it, somebody wrote, I think in
[00:16:36.400 --> 00:16:42.240]   ARIS Technica, they wrote, there's also a risk to Apple here because they're going to miss out
[00:16:42.240 --> 00:16:46.640]   on a hold, if this continues on a whole generation of young gamers who will not,
[00:16:46.640 --> 00:16:50.480]   but where are they going to go? Are they going to go to Google? I mean, and
[00:16:50.480 --> 00:16:55.200]   or maybe they'll just go to a console. I don't really know.
[00:16:55.200 --> 00:17:02.000]   It reminds me of Sony. Remember when Sony went through the DRM challenges and pissed off
[00:17:02.000 --> 00:17:07.200]   everybody? Yes. The root case scenario. People still hold that against Sony. I still talk to
[00:17:07.200 --> 00:17:11.200]   people all the time. See, I'll never own anything Sony. Right. So, you know, Apple's in the process
[00:17:11.200 --> 00:17:15.280]   of trying to launch its own system. Google is still trying to get its system, cloud-based
[00:17:15.280 --> 00:17:19.760]   gaming system off the ground. You know, there are, there's a lot of nuance here that just the
[00:17:19.760 --> 00:17:24.080]   average person playing Fortnite either doesn't care or doesn't know anything about. Most people
[00:17:24.080 --> 00:17:30.160]   have never heard of Tencent. So, I think that Apple has a lot to lose here in terms of, again,
[00:17:30.160 --> 00:17:32.960]   you know, I think- So, the backlash will hit Apple more than it would hit.
[00:17:32.960 --> 00:17:38.800]   I think from a long-term strategic vantage point, this is potentially, you know, challenge, it's bad
[00:17:38.800 --> 00:17:43.680]   for Apple. Mike? But it certainly could go against Epic, too. I mean, it kind of depends on how
[00:17:43.680 --> 00:17:48.400]   people, how all this shakes out. And there's certainly been some anger about Epic and the way
[00:17:48.400 --> 00:17:53.680]   that they've done certain things. I don't think, versus the Google Boycat worked so well for them.
[00:17:53.680 --> 00:18:00.800]   Yeah. I think there are a lot of things where, you know, Epic sort of made the first move here.
[00:18:00.800 --> 00:18:04.880]   And I think a lot of people will see that and say, like, yeah, this is obviously just sort of a
[00:18:04.880 --> 00:18:10.640]   negotiating tactic. And as part of that negotiating tactic, they push things and effectively got
[00:18:10.640 --> 00:18:15.440]   themselves banned from the App Store. Is that Apple's fault or is that, is that Apple's fault?
[00:18:15.440 --> 00:18:21.120]   I think people can come down on either side, but I'm not so sure that I would be positive that Apple
[00:18:21.120 --> 00:18:24.960]   is the one that most people would blame. I think a lot of people might start blaming Epic for,
[00:18:24.960 --> 00:18:30.960]   you know, they made a ton of money doing it this way for a long, long time. And suddenly,
[00:18:30.960 --> 00:18:35.920]   they want a better deal. And, you know, Epic, Epic has pissed off a lot of people.
[00:18:35.920 --> 00:18:38.000]   It doesn't look like it looks greedy. Yeah.
[00:18:38.000 --> 00:18:42.640]   Yeah. By the way, they said that they wouldn't, they wouldn't take a penny from this settlement.
[00:18:42.640 --> 00:18:47.120]   They're not seeking damages. They just want Apple to change its policies. Now, I should point out,
[00:18:47.120 --> 00:18:52.560]   the, my opinion, the company that has a much stronger case is Microsoft here.
[00:18:52.560 --> 00:18:57.920]   Apple also is not going to allow the X cloud service, Microsoft streaming game service,
[00:18:57.920 --> 00:19:03.840]   on iOS. And I think Microsoft can make a very strong case. We're no different than Netflix.
[00:19:03.840 --> 00:19:08.480]   You allow Netflix. It's a streaming game, not a streaming movie. It's interactive. But otherwise,
[00:19:08.480 --> 00:19:13.280]   it we're pretty much the Netflix of gaming. And you're not going to allow us on here because you
[00:19:13.280 --> 00:19:20.000]   say you can't vet the individual games. That makes very little sense. I think Microsoft would have a
[00:19:20.000 --> 00:19:24.000]   stronger case that, that Apple's doing this in their own economic interest, that they don't want
[00:19:24.000 --> 00:19:30.320]   you to play Stadia, the Google games or X cloud, the Microsoft games, or GeForce now or any of the
[00:19:30.320 --> 00:19:36.800]   other streaming services, they want you to play Apple Arcade. And I think that's a very interesting
[00:19:36.800 --> 00:19:42.160]   economic argument. Interestingly, Microsoft is, at least to this point, is not pursuing this in
[00:19:42.160 --> 00:19:47.440]   court. I think Microsoft's going to let the court of public opinion be Apple on this one. And I
[00:19:47.440 --> 00:19:51.600]   think maybe they will come out better than, than Epic has got to come out on this.
[00:19:52.240 --> 00:19:56.320]   Well, I mean, who would have thought Apple would be monopolistic in its business practices?
[00:19:56.320 --> 00:19:59.840]   Oh, I know. Never would have. Then again, Microsoft pointing the finger is.
[00:19:59.840 --> 00:20:07.280]   I'm going to put on my purple wig here and say, oh, I already have it on. I'm going to say,
[00:20:07.280 --> 00:20:12.880]   there is a case to be made. Maybe you guys can shoot this down. I'm not making this case,
[00:20:12.880 --> 00:20:18.400]   but I've heard this made many, many times Apple created all this value. They created the iPhone.
[00:20:18.400 --> 00:20:23.120]   They created the App Store. They created an ecosystem people wanted to participate in.
[00:20:23.120 --> 00:20:27.920]   And for most developers, Apple's doing a great service. They're providing
[00:20:27.920 --> 00:20:33.840]   a marketplace. They're providing storefront. They're providing bandwidth. It's much easier for
[00:20:33.840 --> 00:20:38.960]   the developer. If you, if you went to Ingram, micro to distribute your game in the old days,
[00:20:38.960 --> 00:20:45.040]   they took a hell of a lot more than 30%. So Apple's 30% is a small amount for distributing
[00:20:45.840 --> 00:20:52.800]   a program. If you compare it to the old days when you had software in boxes, this is a preferable
[00:20:52.800 --> 00:20:57.280]   system. And some developers do think it's preferable. Mike?
[00:20:57.280 --> 00:21:04.000]   I would say even if you go back to early phones, if you go back to pre-iPhone days,
[00:21:04.000 --> 00:21:09.680]   when you had Verizon and AT&T that they had total control over their phones, and in order to get
[00:21:09.680 --> 00:21:13.600]   even, you didn't have a marketplace even. If you wanted to get an app onto the phone,
[00:21:13.600 --> 00:21:20.640]   you had to negotiate some sort of deal with Verizon or AT&T or whoever, and they would take a huge
[00:21:20.640 --> 00:21:25.680]   chunk of cash upfront. You had all these phone app developers who were raising a bunch of venture
[00:21:25.680 --> 00:21:34.080]   capital just to hand it off to the telcos. The iPhone, Apple App Store setup is much more
[00:21:34.080 --> 00:21:38.560]   preferable. It's why we have a mobile ecosystem today in the first place. So I actually think that
[00:21:38.560 --> 00:21:43.440]   argument makes a lot of sense. The question then is to get back to what Amy was saying is,
[00:21:43.680 --> 00:21:50.640]   how do you define this market from an antitrust perspective? Is it monopolistic? Is it anti-competitive?
[00:21:50.640 --> 00:21:56.480]   Well, that again sort of depends on what do you consider this marketplace to be. But you do have
[00:21:56.480 --> 00:22:02.240]   to admit that Apple created this whole entire space in the first place, and that's not nothing.
[00:22:02.240 --> 00:22:10.240]   Yeah. So how does this get resolved? I don't think we want to let this go through the courts.
[00:22:11.120 --> 00:22:17.040]   What could Apple do to make people happy? Amy, do you have any thoughts about?
[00:22:17.040 --> 00:22:20.720]   I mean, part of the problem is we've never, as you point out, we've never seen anything like this
[00:22:20.720 --> 00:22:25.760]   before. So there's no precedent. Our current antitrust laws are completely unrelated to what's
[00:22:25.760 --> 00:22:30.720]   going on here. So is there a compromise Apple could come up with that would make everybody happy?
[00:22:30.720 --> 00:22:38.480]   Right. So all of the big tech companies, Apple included, have government relations departments,
[00:22:38.480 --> 00:22:44.160]   whose job it is to meet with and help write policy. They all have corporate foreign policy departments
[00:22:44.160 --> 00:22:53.280]   now. I think when I remember first starting to hear grumblings about the 30% and Apple booting
[00:22:53.280 --> 00:23:01.840]   developers out of the store, I think what happened was there's just a lack of transparency.
[00:23:01.840 --> 00:23:06.720]   And I think with a lot of these companies, you're not divulging IP. I don't think you're giving
[00:23:06.720 --> 00:23:12.960]   TJ or a competitive advantage by simply saying, in a very transparent way, this is our roadmap.
[00:23:12.960 --> 00:23:17.120]   This is what's happening. Here's why we're doing it. I think the problem is none of that
[00:23:17.120 --> 00:23:22.960]   communication happened. And people are pretty, and all of this is also happening, let's not
[00:23:22.960 --> 00:23:30.160]   forget, during an incredibly volatile time when people are having a hard time just confronting this
[00:23:30.160 --> 00:23:38.560]   uncertainty because of the virus and crazy weather events this time of year, and all of the social
[00:23:38.560 --> 00:23:45.200]   injustice protests that are happening. So from a regulatory perspective, at this point, we'll have
[00:23:45.200 --> 00:23:49.120]   to see if a judge picks up the suit. We'll have to see if Congress does anything.
[00:23:49.120 --> 00:23:57.440]   Whatever direction it winds up going in, it'll be several months, if not years before, the whole
[00:23:57.440 --> 00:24:05.120]   thing gets sorted out. But in the court of public opinion, Apple would do itself well at this point
[00:24:05.120 --> 00:24:11.520]   by opening up that line of communication a little bit better and talking about its plans for the
[00:24:11.520 --> 00:24:18.800]   future. Steve Jobs used to do that really well. You saw the future when he took the stage and
[00:24:18.800 --> 00:24:24.720]   they unveiled a new product. But when there weren't big press conferences or events happening,
[00:24:24.720 --> 00:24:32.880]   he was constantly talking about his vision for the future. I think a lot of this felt like it
[00:24:32.880 --> 00:24:37.760]   came out of nowhere, and that Apple was suddenly trying to be super greedy. It's a business,
[00:24:37.760 --> 00:24:43.200]   and this is what in business school we call network value, or I'm sorry, a value network, right?
[00:24:43.200 --> 00:24:48.160]   So the whole thing falls apart unless everybody's contributing and earning value and creating value
[00:24:48.160 --> 00:24:51.280]   and making money. Well, there's another phrase they use in business school, rent seeking.
[00:24:52.000 --> 00:24:57.280]   And I think from Tim Sweeney's point of view, from Epic's point of view, is you want a piece of
[00:24:57.280 --> 00:25:05.840]   our action for doing nothing, right? And so that's rent seeking. So this is, I think, here's, I
[00:25:05.840 --> 00:25:10.080]   might take it on as his Apple painted themselves into a corner. When they first started this up,
[00:25:10.080 --> 00:25:13.360]   it made a lot of sense. It was a simple thing. They probably didn't look far enough down the road
[00:25:13.360 --> 00:25:18.160]   to see these problems. They thought about it and they said, look, we're going to give you bandwidth,
[00:25:18.160 --> 00:25:25.040]   we're going to give you a storefront, we're going to give you the option to be in this ecosystem we've
[00:25:25.040 --> 00:25:29.200]   created. We're going to give customers a safe place to go where they don't have to worry about
[00:25:29.200 --> 00:25:32.480]   their kids, they don't have to worry about themselves, they don't have to worry about malware.
[00:25:32.480 --> 00:25:36.960]   The store will be highly curated. It's going to be a win all around. Developers are going to love it.
[00:25:36.960 --> 00:25:42.640]   Users are going to love it. And I think that they were right in the initial thing. But what's
[00:25:42.640 --> 00:25:49.120]   happened is the world has evolved. And now we've got to this position where the lines aren't quite as
[00:25:49.120 --> 00:25:56.720]   clear. X-Class is a really good example. Is it a game store? Is it Netflix? What exactly is it?
[00:25:56.720 --> 00:26:02.640]   And I don't think that Apple's policies encompass the range of activities now that are going on in
[00:26:02.640 --> 00:26:08.720]   the store. I don't think Apple, honestly, I don't think Apple acted out of greed. I think they
[00:26:08.720 --> 00:26:13.520]   acted out of trying to make a good marketplace and have an insensible plan. But they didn't see
[00:26:13.520 --> 00:26:19.200]   far enough down the road as to the problem that was going to crop up here. And now they have
[00:26:19.200 --> 00:26:24.720]   been themselves as a court because you can't give epic a deal because then now that opens the
[00:26:24.720 --> 00:26:30.720]   door for a lot of other people. A lot of small developers have quite rightly criticized the
[00:26:30.720 --> 00:26:36.960]   app store for inconsistent policies, not being clear why stuff was pulled. You want us to make
[00:26:36.960 --> 00:26:42.320]   that blue? That's the problem? There's all sorts of little issues that have been bubbling around in
[00:26:42.320 --> 00:26:48.480]   the app store for years. It's kind of partly because it's too successful. There's too many new apps.
[00:26:48.480 --> 00:26:54.640]   Sorry. Apple obviously doesn't want to have to negotiate individual deals,
[00:26:54.640 --> 00:26:59.600]   individual software companies because that's a massive pain in the arse for them. But in terms of
[00:27:01.040 --> 00:27:09.200]   pure, Apple has said, yes, we've created this app store. We should take 30%. But a lot of the
[00:27:09.200 --> 00:27:15.200]   works for a lot of apps, but a lot of the people who want to buy a specific app couldn't care
[00:27:15.200 --> 00:27:20.560]   less where it comes from. They just want solid code. And for Apple to claim 30% on that seems
[00:27:20.560 --> 00:27:23.120]   problematic, to say the least.
[00:27:24.160 --> 00:27:33.200]   Well, so here's the issue. Leo said this somewhat in passing, but the real challenge here is that
[00:27:33.200 --> 00:27:38.320]   there was no longer term strategic plan. There hasn't been at foresight. I mean, at Fortnite,
[00:27:38.320 --> 00:27:44.480]   there might have been some big picture idea. But Fortnite's had its fair share of IP battles.
[00:27:44.480 --> 00:27:49.840]   So part of the problem is a lot of the planning process gets front loaded. We want to do this.
[00:27:49.840 --> 00:27:56.160]   This is our big strategic plan. And maybe companies go out 18 months, two years, five years, that
[00:27:56.160 --> 00:28:02.160]   feels like this distant future. And what they forget is that the sort of beginning of that plan
[00:28:02.160 --> 00:28:09.840]   gets reset at zero with every new business day. And so if you're not able or willing to recalibrate
[00:28:09.840 --> 00:28:16.240]   and see strategy as something that gets worked on all the time, and foresight as something more
[00:28:16.240 --> 00:28:24.160]   than cool trends, then you're OK. None of these companies that we've talked about,
[00:28:24.160 --> 00:28:31.360]   among all of the other big tech companies, foresight's not part of the product process.
[00:28:31.360 --> 00:28:35.040]   What should happen is you should go from cool idea or hackathon or whatever
[00:28:35.040 --> 00:28:43.200]   to risk modeling next, and also opportunity modeling because there are probably ways to
[00:28:43.200 --> 00:28:47.440]   derive value, a new synergies within the organization that nobody thought of.
[00:28:47.440 --> 00:28:51.600]   And once you get past something that's a rigorous modeling session,
[00:28:51.600 --> 00:28:58.240]   then you go and you build or you mitigate some of that risk and then you build.
[00:28:58.240 --> 00:29:03.360]   What happens is that doesn't happen until way later in the process when everybody's trying to
[00:29:03.360 --> 00:29:08.240]   sort of fix things. Right? Yeah. And that's what you come in and do for companies. You say,
[00:29:08.240 --> 00:29:12.160]   let's let's let's do I can't wear this stupid wig. Let's
[00:29:12.160 --> 00:29:18.320]   nobody's going to take me seriously. Some guy in a purple wig saying this. So
[00:29:18.320 --> 00:29:24.240]   you have my permission. All of you. Well, you can't do anything about it. And you're stuck. Sorry.
[00:29:24.240 --> 00:29:30.240]   I was wearing it out of solidarity, to be honest, but I just I'm sorry. Solidarity only goes so far.
[00:29:32.080 --> 00:29:37.760]   No, I forgot what I was saying. Well, I'll go ahead, Mike. Go ahead.
[00:29:37.760 --> 00:29:43.440]   I'm going to jump in and just say like, you know, I still think to some extent that this is
[00:29:43.440 --> 00:29:47.120]   really just a negotiation, right? You have two giant companies that are affected
[00:29:47.120 --> 00:29:52.880]   negotiating with each other. And I think in the end, you know, it would not surprise me at all.
[00:29:52.880 --> 00:29:58.080]   If Apple effectively caves and says, okay, we're going to cut, you know, epic, a better deal here.
[00:29:58.080 --> 00:30:01.360]   And yes, the fear, the reason they don't want to do this, because they don't want to have to
[00:30:01.360 --> 00:30:05.840]   negotiate with every single developer. But the fact is, not every developer and very,
[00:30:05.840 --> 00:30:10.720]   very few developers are as big or as powerful as epic. And so therefore, they'll probably cut
[00:30:10.720 --> 00:30:14.640]   a favorable deal with epic. And because of that, they'll probably end up having to cut a favorable
[00:30:14.640 --> 00:30:19.520]   deal with, you know, a few other very large players and everybody else will have to suck it up and
[00:30:19.520 --> 00:30:23.760]   take the 30%. They kind of already did this with Amazon, didn't they? In order to get Amazon Prime.
[00:30:23.760 --> 00:30:31.040]   Yeah. And that's part of the problem is they've already done special consideration. If I were
[00:30:31.360 --> 00:30:36.000]   honestly, if I were Apple, I just hold the line and say, sorry, 30%. It's our store.
[00:30:36.000 --> 00:30:41.440]   There's one thing Apple could and probably should have done, and I wish they had done,
[00:30:41.440 --> 00:30:48.480]   that would probably help them in court. The problem right now is that Apple has an iron grip
[00:30:48.480 --> 00:30:53.280]   on what can be run on that phone, because they're the only unlike Google. They're the only one with
[00:30:53.280 --> 00:30:57.200]   the app store. I think Google gets off the hook because Google just says sideload, no big deal.
[00:30:57.200 --> 00:31:02.560]   But Apple, no, no, they have an iron grip. What Apple should be doing, and I wish they would do,
[00:31:02.560 --> 00:31:09.200]   is supporting progressive web apps. That is websites that turn into apps when you bookmark
[00:31:09.200 --> 00:31:14.240]   them on the phone. It's kind of like it back in 2007, except that the technology is much more
[00:31:14.240 --> 00:31:20.400]   advanced, both Google and Microsoft support it very well. And you could easily have, there's a
[00:31:20.400 --> 00:31:24.720]   Twitter mobile app, for instance, that turns into a Twitter app on the iPhone that's indistinguishable
[00:31:24.720 --> 00:31:29.120]   from the native app. You could easily do that. And then Apple could say, but your honor,
[00:31:29.120 --> 00:31:34.880]   there is a way that this could be on it. If they would do this, we're not preventing that.
[00:31:34.880 --> 00:31:42.000]   We just think that our customers want a curated experience in the app store. We think that's
[00:31:42.000 --> 00:31:47.920]   worth something. We think 30%, given the history of distribution deals, is a very fair amount.
[00:31:47.920 --> 00:31:53.200]   It's exactly what consoles charge, and it's not more than we deserve for what we've created.
[00:31:53.920 --> 00:31:58.160]   And there's an alternative. And that's what's lacking right now, as they can't say,
[00:31:58.160 --> 00:32:02.080]   and there's an alternative. Is that going to be a problem for them, Mike?
[00:32:02.080 --> 00:32:08.640]   Yeah, I mean, I think you're right that if they had that ability, one, I think it would be good
[00:32:08.640 --> 00:32:14.240]   for the world and the Internet and mobile devices in general. So I'm all for that.
[00:32:14.240 --> 00:32:19.680]   And yes, it would give them a much better argument in court. I think if they really wanted to
[00:32:21.600 --> 00:32:26.160]   go through the entire litigation process, they have a fairly strong argument, especially with
[00:32:26.160 --> 00:32:31.680]   antitrust laws the way they are right now. But going through that process is extremely expensive
[00:32:31.680 --> 00:32:36.560]   and annoying and distracting in its own way. And so they might not want to do that. But
[00:32:36.560 --> 00:32:41.040]   you know, so I don't know if they need that to win the case. So I don't know if that makes a
[00:32:41.040 --> 00:32:46.000]   difference in terms of how well the case will turn out. But I think in general, that's not a
[00:32:46.000 --> 00:32:52.000]   bad idea. This this actually cases being litigated right now in another case that actually went to
[00:32:52.000 --> 00:32:59.200]   the Supreme Court overstanding not over the case itself. The the app store has been challenged.
[00:32:59.200 --> 00:33:06.160]   And the Supreme Court said that the plaintiffs do have standing. I can't remember if it was a class
[00:33:06.160 --> 00:33:11.920]   action. I actually don't remember the details of this. But there is another lower court that is
[00:33:12.480 --> 00:33:17.680]   actually looking at Apple's monopoly right now. So this is this there's their action on many,
[00:33:17.680 --> 00:33:26.160]   many fronts going on. But if I'm Apple, I hold the line. I say I say Epic will blink Epic. We know
[00:33:26.160 --> 00:33:31.840]   Epic blinked with Google when they released Fortnite as a side load. It did not go well for them. They
[00:33:31.840 --> 00:33:39.120]   gave in. And I think if I'm Google, I don't blink. I just say, Hey, sorry, dudes, that's the rule.
[00:33:39.120 --> 00:33:43.520]   You made a lot of money last year. There were 17 billion, I think.
[00:33:43.520 --> 00:33:49.040]   You have no not a leg to stand on. You're benefiting from what we've created.
[00:33:49.040 --> 00:33:54.960]   I do have to say Apple, I think has a better case in this than Google does,
[00:33:54.960 --> 00:34:02.080]   because Apple really rigorous. Well, yeah, because I think honestly, Apple rigorously checks apps on
[00:34:02.080 --> 00:34:08.400]   its site for malware. They are better miles ahead from Google on that. So really is curated.
[00:34:08.400 --> 00:34:14.880]   That story. Well, yeah, I mean, you're paying for a certain amount of security in the,
[00:34:14.880 --> 00:34:19.760]   you know, an engineer has gone through this and you're unlikely if you download a fast app to get
[00:34:19.760 --> 00:34:23.360]   a route kit installed on your own. You only get a really the best fart apps.
[00:34:23.360 --> 00:34:29.440]   Exactly. Exactly. But when you're dealing with something like Fortnite or I'm showing my age here,
[00:34:29.440 --> 00:34:33.840]   but I mean, imagine if doom had been released, you couldn't have released doom on the Apple on
[00:34:33.840 --> 00:34:38.160]   the App Store, because they would have. Yeah, there are a lot of software models that are not
[00:34:38.160 --> 00:34:43.360]   allowed. There's no demos. Yeah, doom was a three level demo that the new pay for.
[00:34:43.360 --> 00:34:47.680]   I guess you could have done it, but you would have to have an app purchase and Apple would have taken
[00:34:47.680 --> 00:34:55.120]   30%. Exactly. So I mean, it kind of grinds my gears on that point. I think Google is a lot less,
[00:34:55.120 --> 00:35:02.000]   has a lot less of a defendable position on this because their malware checking is just
[00:35:02.000 --> 00:35:08.080]   pathetically bad compared to apples. But I mean, so yeah, if you want to buy from the Apple App Store,
[00:35:08.080 --> 00:35:13.680]   then fine. You get a certain amount of security. But I do find it a little bit
[00:35:13.680 --> 00:35:20.800]   grinding that they can charge 30% on a game which was made popular with and they had nothing to do
[00:35:20.800 --> 00:35:26.240]   with, which has been checked before. And we should point out it's not merely 30%. The game is free.
[00:35:26.240 --> 00:35:33.760]   The 30% isn't for the game. It's for costumes and other downloadable content, which Apple really
[00:35:33.760 --> 00:35:40.640]   had nothing to do with. They're given away the game. So ultimately, our feelings about what's right
[00:35:40.640 --> 00:35:48.560]   and wrong don't matter because the courts are going to look at precedent. Our policymakers are
[00:35:48.560 --> 00:35:54.400]   going to look at what makes sense right now based on how people are feeling about the election and
[00:35:54.400 --> 00:36:02.480]   everything else. And we don't have case law that defines a lot of digital IP yet. The problem is
[00:36:02.480 --> 00:36:10.880]   that you can't preemptively make policy or regulation or case law until an event happens.
[00:36:10.880 --> 00:36:15.920]   Honestly, though, honestly, it's not our feelings. It's the judge's feelings because honestly,
[00:36:15.920 --> 00:36:20.960]   I mean, my first reaction is well, it completely depends on what court gets this case.
[00:36:20.960 --> 00:36:25.600]   Well, they're doing it in Northern District of California, which means a possibility that
[00:36:25.600 --> 00:36:30.000]   Coe's going to be in charge and she knows her stuff. She does. Lucy Coe is very good.
[00:36:30.880 --> 00:36:36.640]   So and she's done a lot of antitrust stuff. So we mentioned that antitrust differs in the US
[00:36:36.640 --> 00:36:45.760]   and the EU. My sense of it is that in the US, it's all about keeping companies competitive. It's to
[00:36:45.760 --> 00:36:53.760]   benefit innovation via allowing other companies to compete. And in the EU, it's a sense of
[00:36:53.760 --> 00:36:56.640]   protecting consumers more. Is that accurate? Is that a fair?
[00:36:58.480 --> 00:37:02.000]   Go ahead. Why don't you do that? Because that really is yours. Your Bailey.
[00:37:02.000 --> 00:37:09.600]   Yeah. I mean, well, there's another case that we might talk about later about what happened
[00:37:09.600 --> 00:37:15.920]   with Qualcomm because that gets into this a little bit. But that was rolled in the Ninth Circuit this
[00:37:15.920 --> 00:37:24.320]   week. But generally speaking, the American form of antitrust law over the last few decades has
[00:37:24.320 --> 00:37:29.760]   actually been to look for consumer harm. And that's been actually where a lot of the debate is
[00:37:29.760 --> 00:37:35.440]   lately is whether or not that's that's appropriate or not. Whereas the EU looks at more of, is this
[00:37:35.440 --> 00:37:42.320]   company too big? And that's been really the dividing line. So a lot of the the the actions in the EU
[00:37:42.320 --> 00:37:46.400]   on antitrust have been, well, this company is too big and it's doing something that we feel is
[00:37:46.400 --> 00:37:52.720]   unfair because of its bigness. And they're too big. Because it's a terrible phrase. Really, they
[00:37:52.720 --> 00:38:00.720]   actually think that a company can be too big. Yes. Not anti competitive, just too bit too successful.
[00:38:00.720 --> 00:38:06.240]   Right. So that's and this is paraphrasing slightly. But that is effectively what they're
[00:38:06.240 --> 00:38:10.000]   saying is that when those companies are too big, then they're leading to things that are,
[00:38:10.000 --> 00:38:14.320]   you know, in effect anti competitive, but they're not necessarily having to show
[00:38:14.320 --> 00:38:19.120]   the anti competitive nature, the anti competitive impact of it. So that's practically when American.
[00:38:20.640 --> 00:38:31.440]   Well, I have a comment on this. If a company gets too big, it becomes anti competitive.
[00:38:31.440 --> 00:38:35.920]   It wants you can dominate a market. I mean, we all know this. Once a company gets to the point
[00:38:35.920 --> 00:38:41.040]   where it can dominate a market because it has that many tendrils out there, there is an argument
[00:38:41.040 --> 00:38:47.360]   to say that companies can get too big. A fission competition relies on allowing smaller competitors
[00:38:47.360 --> 00:38:52.080]   to enter the market. But in the US, it's always been if you're that big, it's only a bad,
[00:38:52.080 --> 00:38:56.640]   it's okay to be big. It's only a bad thing if you use your dominance in one market to
[00:38:56.640 --> 00:39:02.560]   enter another and dominate another market. That's the line you can't cross.
[00:39:02.560 --> 00:39:08.000]   And to harm consumers in that process. Right. So that's part of it.
[00:39:08.000 --> 00:39:12.880]   I think that's reasonable. So that says in the US, it's okay. If you're a wildly successful
[00:39:12.880 --> 00:39:17.120]   company in one area, you just can't use that success to enter other markets.
[00:39:17.120 --> 00:39:21.840]   Well, I mean, it sounds like a cute idea, but that's exactly what Facebook did,
[00:39:21.840 --> 00:39:25.760]   which is why they dominate three quarters of the social media market right now.
[00:39:25.760 --> 00:39:29.840]   As same thing Cisco did in the 90s and noughties, you know,
[00:39:29.840 --> 00:39:36.240]   Apple is going to say, look, we only have at best 50% of the market. How can you say we're too big?
[00:39:36.240 --> 00:39:40.320]   In the United States, a free market, there's a tension and I think,
[00:39:40.320 --> 00:39:47.840]   unresolvable tension, pitting a free market economy against our desire for there to be
[00:39:47.840 --> 00:39:52.160]   sort of infinite competition in the marketplace. Oh, you're right. We believe in the
[00:39:52.160 --> 00:40:00.000]   ratio, Alger rags to riches. That's what we aim for. That's right. And there is not a
[00:40:00.000 --> 00:40:05.520]   I would challenge everybody listening to see if you can think of one industry where,
[00:40:06.800 --> 00:40:14.240]   ultimately, there wasn't consolidation. There is always consolidation within the market for all of,
[00:40:14.240 --> 00:40:18.560]   you know, for many. But I would submit that that's what we should regulate, not the fact that such
[00:40:18.560 --> 00:40:25.200]   as somebody becomes big and successful. Google is dominant in search because they made a great
[00:40:25.200 --> 00:40:29.760]   product and no one else wanted to use the other one. Well, here's another way to think about it.
[00:40:29.760 --> 00:40:34.720]   You know, Amazon, I think of all of the different companies that are under the microscope right now
[00:40:34.720 --> 00:40:41.440]   is going to have it will be the hardest to prove a case against Amazon because there is Amazon.com,
[00:40:41.440 --> 00:40:46.160]   which is an online marketplace where you can buy stuff. There's AWS. There is the
[00:40:46.160 --> 00:40:53.280]   spatial mapping system for coal mines. There is the medical transcription service. I mean,
[00:40:53.280 --> 00:40:59.520]   Amazon has done an incredible job of being very diverse and not dominating any one particular
[00:40:59.520 --> 00:41:05.600]   market. They are not the biggest online retailer, not by far. They don't have market dominance
[00:41:05.600 --> 00:41:13.520]   and logistics. The value of Amazon is not any one individual business unit. It's the connections
[00:41:13.520 --> 00:41:19.520]   between all of them. It's it, you know, having all of these systems work together functions as a
[00:41:19.520 --> 00:41:25.920]   kind of continual level up. So most of the ire is usually directed at Amazon when we're talking
[00:41:25.920 --> 00:41:33.120]   about consolidation and, you know, competition in the United States. The problem is it's going to be
[00:41:33.120 --> 00:41:40.480]   very hard to take them down. So we have to change how we're I think we don't have the right language
[00:41:40.480 --> 00:41:45.440]   yet to really describe what it is that we're after, right? What we're after is, you know,
[00:41:45.440 --> 00:41:51.600]   fair practices and people not being kind of crappy and, you know, companies make, you know,
[00:41:51.600 --> 00:41:57.920]   feeling like we can trust companies and that we don't start sort of with instant skepticism
[00:41:57.920 --> 00:42:04.160]   and that we feel okay using the tools. But, you know, Facebook is an easier case, I think,
[00:42:04.160 --> 00:42:08.960]   Apple and Google are slightly easier. Amazon is a totally different beast and yet that's the
[00:42:08.960 --> 00:42:15.680]   company that everybody is kind of gunning for. Yeah. It's the law. The laws clearly
[00:42:16.560 --> 00:42:25.120]   need to be adapted to the 21st century. And we as a before the laws can be adapted, we as a society
[00:42:25.120 --> 00:42:34.000]   need to have the debate and really think about what is it we want? What is I don't think Americans
[00:42:34.000 --> 00:42:40.480]   want to punish a company for becoming successful. That's kind of an antithetical to the kind of
[00:42:40.480 --> 00:42:45.360]   the magic, the dream. Yes, but they don't want to be, you know, they don't want to be screwed
[00:42:45.360 --> 00:42:50.160]   sideways by them either. I mean, well, I'll put this in more personal terms. I don't think the
[00:42:50.160 --> 00:42:56.000]   billionaires should be allowed to exist. I think the marginal tax bracket should get to 90 or 95%
[00:42:56.000 --> 00:43:02.800]   after your first say 500 million. Hey, word for America in the 1950s, 60s and 70s and pretty
[00:43:02.800 --> 00:43:07.600]   well down. But I think if you propose that today, even though it's very clear that we have people who
[00:43:07.600 --> 00:43:14.880]   have Jeff Bezos, a good example, so much wealth that it's bad for society. But if I,
[00:43:14.880 --> 00:43:18.560]   if somebody, if some candidate proposed that, I think they'd be shut down. I mean, I guess
[00:43:18.560 --> 00:43:25.120]   Elizabeth Warren did. And that was the end of the day. This is tricky because, and I'm, listen,
[00:43:25.120 --> 00:43:31.040]   I'm not trying to defend Amazon, but in the case of Bezos, you've got the money that people say
[00:43:31.040 --> 00:43:36.800]   that you're worth on paper and then you have actual spendable, you know, liquidity. Right. And
[00:43:36.800 --> 00:43:41.600]   the problem is that that our government in the United States is not funding by anywhere,
[00:43:42.160 --> 00:43:48.240]   by any reasonable level, we are not funding basic research and science and technology.
[00:43:48.240 --> 00:43:55.520]   So we sort of offloaded all of this to the private sector. And I find it difficult for us to
[00:43:55.520 --> 00:44:01.360]   to criticize. And again, I'm not defending, certainly not defending past behavior, but like
[00:44:01.360 --> 00:44:08.320]   Elon Musk, you know, Bezos, they're in a way self funding with loopholes and taxes and everything
[00:44:08.320 --> 00:44:14.000]   else. But, you know, they're building the next generation of the technology that will be needed
[00:44:14.000 --> 00:44:19.840]   for space. We can argue about whether or not that's even necessary at this particular moment in time.
[00:44:19.840 --> 00:44:29.840]   But, but if we can't both say there shouldn't be lots, you know, we can't both close the wealth gap,
[00:44:29.840 --> 00:44:37.120]   but while at the same time, not reinvesting in our, the critical infrastructure that is our
[00:44:37.120 --> 00:44:40.960]   intellectual property in the United States. It's so hard to have conversations like this now,
[00:44:40.960 --> 00:44:46.480]   because our government is so far from being effective that this is such a pipe dream.
[00:44:46.480 --> 00:44:53.760]   You know, we were just like testing for COVID. If we have that, please. I mean, I'm sorry. I
[00:44:53.760 --> 00:45:00.720]   find it difficult to sympathize. Jeff Bezos gave an interview in Germany a couple of years ago,
[00:45:00.720 --> 00:45:05.360]   where he was just like, I've got so much money, I'm putting into space and, you know, that's
[00:45:05.360 --> 00:45:10.320]   what I'm going to do. At the meantime, the very people that pack his packages,
[00:45:10.320 --> 00:45:15.680]   make him that money, make him that wealthy are having to piss into bottles,
[00:45:15.680 --> 00:45:22.880]   to avoid going over their quota. This is just insanity. I mean, sorry, just show some respect
[00:45:22.880 --> 00:45:26.960]   the people that make you much. I totally agree. The point that I was actually trying to make,
[00:45:26.960 --> 00:45:34.000]   I agree with you. My point is, if, if we want wealth distribution to be more equal, I think we
[00:45:34.000 --> 00:45:40.720]   must also take, we must also devote significantly more resources into basic
[00:45:40.720 --> 00:45:44.400]   research and development, which we're not doing. I don't know. I would do on that.
[00:45:44.400 --> 00:45:51.200]   I would. If it's in the private sector versus the public sector, I'm not saying the federal
[00:45:51.200 --> 00:45:55.840]   government should do everything, but if most of what we're funneling out is into the private sector,
[00:45:55.840 --> 00:46:02.400]   the private sector is market driven. So that is not the right, you know,
[00:46:02.400 --> 00:46:10.320]   you are motivating people to make choices that are not necessarily in the public's interest.
[00:46:10.320 --> 00:46:14.080]   Right. Oh, no. I mean, this is why government is so good at this stuff. I mean,
[00:46:14.080 --> 00:46:19.360]   no private company would have funded research into TCIP or the internet, because there's no
[00:46:19.360 --> 00:46:25.120]   profit in it. You need the government to do long-term, pure research, and then companies take it and
[00:46:25.120 --> 00:46:30.240]   run with it. But no private company is going to do casting bread across the water's
[00:46:30.240 --> 00:46:35.120]   pure research because they can't justify it to shareholders. That's where government comes in,
[00:46:35.120 --> 00:46:40.800]   surely. I agree. Mike, but in lieu of government, Mike's trying to get a word in the edge,
[00:46:40.800 --> 00:46:45.280]   I want to give Mike a chance just because he's made a blue wig, don't hold it against him.
[00:46:45.280 --> 00:46:49.680]   I'm keeping it on. It's not going away. You are brave.
[00:46:51.440 --> 00:46:56.080]   And I'm sweating of a storm. You can take it off. I'll take it off. You don't have to wear it.
[00:46:56.080 --> 00:47:01.680]   So anyway, to get back to the point that you were saying about the marginal tax rate,
[00:47:01.680 --> 00:47:06.960]   right? So there was just a couple of days ago, I saw that California was proposing to effectively
[00:47:06.960 --> 00:47:12.160]   boost the marginal tax rate on the wealthiest folks here. And there was all this talk of how
[00:47:12.160 --> 00:47:16.960]   all the successful Silicon Valley entrepreneurs are going to move out of California, because
[00:47:17.600 --> 00:47:22.400]   it was going to, I think for the highest earners, was going to push the marginal tax rate up to like
[00:47:22.400 --> 00:47:30.720]   55% or something like that, nowhere near the sort of 90, 95% that was from a few decades back.
[00:47:30.720 --> 00:47:38.000]   And so you have this issue of people will go elsewhere too, if the tax rate is too high.
[00:47:38.000 --> 00:47:42.240]   And I think everybody's correct that there's two separate things to being talked about here.
[00:47:42.240 --> 00:47:49.840]   One is the sort of fundamental basic research, the R of the R and D. And then there's the D side of it.
[00:47:49.840 --> 00:47:56.160]   And we've now moved from a world where there was a ton of money going into R and lessened to D
[00:47:56.160 --> 00:48:02.080]   to a world that now everything is just focused on development. And very little on the fundamental
[00:48:02.080 --> 00:48:05.760]   research. Well, the other side of this finding that balance is important.
[00:48:05.760 --> 00:48:11.760]   Space is a bad example, because we spend so little on space, almost shamefully.
[00:48:11.760 --> 00:48:18.720]   But for instance, the amount of money Bill Gates puts into public health and vaccines
[00:48:18.720 --> 00:48:25.440]   is a tiny fraction of what governments can spend. So you can't expect, you can't put this on the
[00:48:25.440 --> 00:48:30.000]   private sector. They're just not only is it that it's market driven, that there are going to be
[00:48:30.000 --> 00:48:34.160]   development folks, there are all sorts of reasons. But it's also a tiny fraction of the kind of money
[00:48:34.160 --> 00:48:40.560]   government can spend. And I just think that that's abrogating your responsibility to say,
[00:48:40.560 --> 00:48:48.400]   well, let the private sector do it. I know that that's a popular current in American thinking
[00:48:48.400 --> 00:48:52.800]   right now, but I don't think it's a way to go. Well, I mean, the private, sorry, Mike, up to you.
[00:48:52.800 --> 00:48:58.800]   I was going to say, I mean, well, again, getting to the difference between the research and the
[00:48:58.800 --> 00:49:04.800]   development side of it, there's a difference between sort of core level infrastructure and
[00:49:04.800 --> 00:49:08.880]   everything above the infrastructure. And I think that there's a very strong argument for
[00:49:09.520 --> 00:49:14.080]   government funding of the infrastructure that makes everything else possible. And then allowing
[00:49:14.080 --> 00:49:18.960]   there to be tremendous competition and let there be a free market and everything on top of that
[00:49:18.960 --> 00:49:23.200]   infrastructure. That's how the internet should be run, for instance, build the highways,
[00:49:23.200 --> 00:49:29.280]   exactly. Let everybody else build on top of it. And you get competition, you get free enterprise,
[00:49:29.280 --> 00:49:34.240]   but you also get infrastructure that works. Well, this is exactly what the South Koreans did.
[00:49:34.240 --> 00:49:39.760]   This is exactly what the Nordic nations did. They build the infrastructure and let it flow.
[00:49:39.760 --> 00:49:47.040]   Over here, it's private network, which is why Americans get screwed daily on their mobile phone
[00:49:47.040 --> 00:49:53.520]   and their telecoms charges the rest of it, because it's an oligopoly. It's not free market competition.
[00:49:53.520 --> 00:50:00.000]   But yes, the government needs to fund the pure research companies need to develop it from there.
[00:50:00.000 --> 00:50:06.560]   I mean, if you look at most of the major, you know, even SpaceX wouldn't exist without NASA
[00:50:06.560 --> 00:50:09.520]   Yes. Going forward on the way. That's absolutely true.
[00:50:09.520 --> 00:50:17.120]   Government seeds, competition and private companies push forward and it can work
[00:50:17.120 --> 00:50:24.240]   so long as companies don't get greedy. So should Apple give up on this and just say,
[00:50:24.240 --> 00:50:30.400]   okay, here, we'll make Fortnite. We'll give you it. We'll, I just don't see Apple saying, okay,
[00:50:30.400 --> 00:50:36.160]   we'll give you a deal 15%. I don't see that. And why not? And is, and everyone in this dog is
[00:50:36.160 --> 00:50:40.960]   then going to go to Apple and say, yeah, we want special deal as well. You know, the legal
[00:50:40.960 --> 00:50:45.040]   department are going to have some at home. Maybe it's time. Maybe at this point, Apple,
[00:50:45.040 --> 00:50:52.560]   for the last 10 plus years, got to build the platform, use that money. Maybe it's time to say,
[00:50:52.560 --> 00:50:57.920]   you know, 30% is too much now. It should be 15. I don't think it make everybody happy.
[00:50:57.920 --> 00:51:04.560]   Nothing ever does. But no, I mean, it's honestly, they should cut out. They should cut individual
[00:51:04.560 --> 00:51:08.480]   deals for individual companies. There's going to be a massive pain in the backside. But you know,
[00:51:08.480 --> 00:51:15.600]   it's, I don't honestly think with a game as popular as Fortnite, you can say we are adding 30%
[00:51:15.600 --> 00:51:19.440]   to the value of your game just by hosting on our Web Store. Yeah.
[00:51:20.000 --> 00:51:23.040]   All right. Let's take a break. We have lots more to talk about. We got a great team
[00:51:23.040 --> 00:51:27.760]   dressed strangely, but that don't hold it against them. Mike Masnick, a tech dirt
[00:51:27.760 --> 00:51:33.600]   who was recently defunded, much like the Federalist will talk about Google.
[00:51:33.600 --> 00:51:43.360]   It's an interesting conundrum. Yeah. That's great to have you, Mike. Techdirt is a must read
[00:51:43.360 --> 00:51:49.040]   every single morning for me, techdirt.com. And Mike also has his own podcast. We'll talk about
[00:51:49.040 --> 00:51:56.480]   that later. Ian Thompson, another must read the register.com now. No more of that silly.co.uk.
[00:51:56.480 --> 00:52:01.840]   Although. Oh, don't go to UK still works. I like saying that. You know, when I was a kid,
[00:52:01.840 --> 00:52:10.400]   I subscribed to punch the British. The British humor magazine, even though I didn't get any of
[00:52:10.400 --> 00:52:15.200]   the, I mean, I don't even know who Edward Heath was, but I, but it was fun. And I knew I liked
[00:52:15.200 --> 00:52:21.120]   the cartoons of his giant perbuscus. And it, and by the way, it was shipped on a slow boat because
[00:52:21.120 --> 00:52:26.240]   I would get it like two months later. But I liked it because it was kind of quirky and fun.
[00:52:26.240 --> 00:52:30.240]   And so that's why I liked that co.uk. I don't know where I was going.
[00:52:30.240 --> 00:52:34.720]   Yeah, I know. I miss it as well. But unfortunately, from an advertiser's perspective,
[00:52:34.720 --> 00:52:39.120]   when we, when our sales guys were going out there, like, Oh, dot, cut UK, just there's the door.
[00:52:39.120 --> 00:52:42.560]   Yeah. What does that mean? A cooke. It spells cooke. What are you talking?
[00:52:43.760 --> 00:52:49.600]   Believe me, try having a company named Twit. See how far you get.
[00:52:49.600 --> 00:52:52.080]   Yeah. You have the record which justifies.
[00:52:52.080 --> 00:52:58.880]   And then there's the fabulous Amy Webb who is visiting us from the future today.
[00:52:58.880 --> 00:53:04.880]   She is a futurist future today Institute. I feel so guilty. I took my wig off because you're stuck.
[00:53:04.880 --> 00:53:11.200]   And it just doesn't seem right. But I couldn't, I couldn't do it. I just couldn't do it anymore.
[00:53:11.200 --> 00:53:16.400]   But anyway, thank you. That was not as stuck as Ian is. I this is I can take this off when we're done.
[00:53:16.400 --> 00:53:22.560]   You actually though, you look great. I mean, it's a really good look for you. You might consider
[00:53:22.560 --> 00:53:27.600]   this for future presentations. Yes, I think when I go to my meetings at the Pentagon,
[00:53:27.600 --> 00:53:36.160]   everybody will take it seriously. It's not worse than Shingey. No, he is not a futurist.
[00:53:36.160 --> 00:53:44.480]   What is Shingey? That is a I don't know, but he is not a train that there are people who call
[00:53:44.480 --> 00:53:49.040]   themselves futurists. And then there are people who have been trained in the methodology and the
[00:53:49.040 --> 00:53:54.240]   data and everything else. These are different. He calls himself the digital profit. Yes, I know.
[00:53:54.240 --> 00:54:00.000]   Well, I would never call myself that because I do modeling. I don't have an oracle or a magic
[00:54:00.000 --> 00:54:05.600]   ball or whatever. Hi, I'm a digital profit. Nice to meet you.
[00:54:05.600 --> 00:54:11.840]   It's sad. We now have similar hair. Yeah, you know, if Shingey would just die at purple,
[00:54:11.840 --> 00:54:16.880]   I think you two would really be easy. We've got the glasses. That would be so great for me.
[00:54:16.880 --> 00:54:22.560]   It's a great job title. It's like for us at a prison in Google,
[00:54:22.560 --> 00:54:29.040]   her business cards are security princess. And it's just that's just a great job title to have.
[00:54:29.040 --> 00:54:35.200]   Shingey has at times had kind of bluish hair, so it is conceivable.
[00:54:35.200 --> 00:54:45.440]   I was showing me. Thanks, Leo. Really? So glad I did. I was going to say,
[00:54:45.440 --> 00:54:50.880]   you just got to get a call about my look. You, whether or not I should keep this look.
[00:54:50.880 --> 00:54:56.320]   I thought that was your hair. What are you talking about? That was Mike's look. He's blue.
[00:54:56.720 --> 00:54:58.160]   My natural locks. Yeah.
[00:54:58.160 --> 00:54:59.280]   Double D double.
[00:54:59.280 --> 00:55:09.840]   Our show today brought to you by W W T worldwide technology and their advanced technology center,
[00:55:09.840 --> 00:55:18.080]   the ATC in St. Louis. We visited it last March. Seems like an eon ago. It was so cool.
[00:55:18.960 --> 00:55:26.320]   Half billion dollars of equipment from the biggest enterprise companies, hundreds of OEMs,
[00:55:26.320 --> 00:55:32.640]   partners like the tech heavyweights of Hewlett Packard Enterprise, HPE and Intel,
[00:55:32.640 --> 00:55:37.600]   but also the little guys, the disruptors, the emerging companies like Equinix.
[00:55:37.600 --> 00:55:44.240]   It's really kind of amazing to walk down these aisles rack after rack filled with all the best
[00:55:44.240 --> 00:55:49.520]   stuff. What's that? Well, that's cool. What's that? I just, I loved it. What's cool is that the
[00:55:49.520 --> 00:55:54.080]   engineers at W W T if I talked to them and they said, yeah, we got, I said, you got the best job.
[00:55:54.080 --> 00:55:59.680]   Yeah, we get to play with everything, but they use it to create pilots to spin up proofs of concept
[00:55:59.680 --> 00:56:06.080]   to help W W T's enterprise customers understand what's new in technology, what technology they're
[00:56:06.080 --> 00:56:10.320]   going to use, how it integrates with their existing technology. It's pretty impressive.
[00:56:11.040 --> 00:56:16.480]   Companies stay with them for as long as a decade and more because they know they can always go to
[00:56:16.480 --> 00:56:21.680]   W W T to get the answers they need to make sure their business is using the right technology to
[00:56:21.680 --> 00:56:26.640]   get the job done. Their Advanced Technology Center is an incubator for IT innovation. You get
[00:56:26.640 --> 00:56:33.280]   schedulable and on demand labs like HPE's InfoSight Lab, along with hundreds of others,
[00:56:33.280 --> 00:56:38.320]   representing the latest advances in cloud based machine learning to provide global insights into
[00:56:38.320 --> 00:56:45.200]   the status and health of infrastructure in one location and a whole lot more. You can do what a
[00:56:45.200 --> 00:56:50.960]   the W W T engineers do in the ATC yourself. They're setting up these sandboxes, but
[00:56:50.960 --> 00:56:54.800]   this is new. They started this last summer. I love this. They offer their lab as a service,
[00:56:54.800 --> 00:57:01.760]   a dedicated lab space within the ATC where you as a customer can do your own programmatic testing
[00:57:01.760 --> 00:57:06.720]   using anything in this half billion dollar technology ecosystem. And because it's virtual,
[00:57:06.720 --> 00:57:11.200]   you don't have to go to St. Louis to use it. You can use it anywhere in the world 24/7.
[00:57:11.200 --> 00:57:17.840]   This is exactly the same stuff that the W W T engineers are using as they work every day,
[00:57:17.840 --> 00:57:23.360]   beta testing new solutions built on the latest and greatest HPE technologies, building reference
[00:57:23.360 --> 00:57:28.880]   architectures, custom integrations to help their customers. It's really impressive. This is a
[00:57:28.880 --> 00:57:35.360]   company you will want to be with forever because they are going to help you get the job done.
[00:57:35.360 --> 00:57:42.000]   And it all starts by you going to W W T dot com slash twit, taking a look at this incredible ATC
[00:57:42.000 --> 00:57:47.040]   ecosystem. You get articles, case studies, all the tools you need to make a difference in today's
[00:57:47.040 --> 00:57:52.320]   fast moving enterprise technology space, including those great hands on labs.
[00:57:52.320 --> 00:58:00.160]   Learn why organizations across every industry, public and private turn to W W T to guide them
[00:58:00.160 --> 00:58:08.080]   on their digital transformation. W W T dot com slash twit, create that mind W W T account,
[00:58:08.080 --> 00:58:14.560]   get those resources at the ATC. You'll be blown away. It is I learn more and more about this
[00:58:14.560 --> 00:58:21.520]   company all the time. And I'm amazed at all they do. W W T dot com slash twit, worldwide technology,
[00:58:21.520 --> 00:58:28.480]   delivering business and technology outcomes all around the world. Thank you, W W T. So what is
[00:58:28.480 --> 00:58:35.840]   what did happen with Google and you getting it. So this was we talked last time you were on,
[00:58:35.840 --> 00:58:39.920]   in fact, Mike, about the Federalists saying, you know, the story that everybody published that
[00:58:39.920 --> 00:58:45.280]   you debunked that the Federalist was being demonetized by Google. The theory was, oh,
[00:58:45.280 --> 00:58:50.880]   there Google is against conservative thought and they're defunding us. But that's actually
[00:58:50.880 --> 00:58:56.320]   not the case. And now it's happened to you. This is automatic, right?
[00:58:58.080 --> 00:59:03.760]   Yeah. So they have these, you know, systems, these bots that go and are constantly monitoring
[00:59:03.760 --> 00:59:08.560]   different websites that have ads hands on it. And you know, what we had written originally about
[00:59:08.560 --> 00:59:14.240]   the with the Federalist was that we had gotten similar notices, but we got them, you know,
[00:59:14.240 --> 00:59:19.440]   once every month or once every two or three months, we would suddenly get a notice from Google and
[00:59:19.440 --> 00:59:24.480]   was saying, there's a problem on this particular article. And it was usually our comments, something
[00:59:24.480 --> 00:59:28.080]   in our comments that they didn't like and they didn't want their ads to appear next to it.
[00:59:28.080 --> 00:59:31.840]   And that's apparently what they had told the Federalist and the Federalist turned into this big thing
[00:59:31.840 --> 00:59:36.320]   that Google was, you know, against them for their conservative viewpoints. But that's always a
[00:59:36.320 --> 00:59:42.000]   concern for advertisers. I, it's our advertisers too. They don't want to be in an environment that
[00:59:42.000 --> 00:59:46.800]   doesn't reflect well on them. So that's why it's difficult. YouTube's difficult. Twitter's difficult.
[00:59:46.800 --> 00:59:51.200]   And so it makes perfect sense that AdSense would be monitoring the pages that the ads are going
[00:59:51.200 --> 00:59:56.160]   to appear on. And if there's anything controversial, they'll say, okay, well, you're not going to get
[00:59:56.160 --> 01:00:01.440]   an ad until that goes away. Mike, what was it? Well, you know what the content was?
[01:00:01.440 --> 01:00:06.160]   Well, this is the problem. So what happened was two weeks ago, suddenly, instead of getting like
[01:00:06.160 --> 01:00:11.760]   one every two or three months, we started getting like two or three notices every day. And, you know,
[01:00:11.760 --> 01:00:16.240]   you would have to and there would be no information in the notice, you would have to log into the
[01:00:16.240 --> 01:00:20.800]   to the platform. And then it would give you very little information, but it would list out, you know,
[01:00:20.800 --> 01:00:27.040]   it kept changing. So somewhere between 20 and 30 URLs, some, you know, were very, very old.
[01:00:27.040 --> 01:00:31.440]   Some didn't even exist. My favorite one was one that didn't even exist. If you clicked on it,
[01:00:31.440 --> 01:00:39.200]   it would just take you to the front page of TechDirt. What my two favorites were the tag page for
[01:00:39.200 --> 01:00:47.920]   Google was deemed dangerous and derogatory. And so therefore, they could not put ads on that.
[01:00:47.920 --> 01:00:54.320]   And then the second one, which felt somewhat ironic, was that the tag page for content moderation
[01:00:54.320 --> 01:01:02.080]   was also deemed, uh, derogatory. And so then is this kind of some sort of automated,
[01:01:02.080 --> 01:01:06.000]   like the content ID system on YouTube, some sort of automated thing that's just dumb
[01:01:06.000 --> 01:01:11.120]   and looks for keywords. And then there was maybe like an update sent and it just, you know,
[01:01:11.120 --> 01:01:15.680]   bad codes, you get garbage in, you get garbage out. Like it seems like it was that's, that's,
[01:01:15.680 --> 01:01:19.680]   that's what I thought. And I had actually emailed some people at Google and said, hey,
[01:01:19.680 --> 01:01:23.840]   did something go haywire? Because suddenly, you know, now we were getting like two or three of
[01:01:23.840 --> 01:01:28.240]   these messages every day. And the list kept changing. We weren't doing anything. And so like,
[01:01:28.240 --> 01:01:32.080]   you know, URLs that were bad would suddenly disappear from the list and the new ones would
[01:01:32.080 --> 01:01:36.560]   appear and there was no explanation for it. And so I said, you know, did something go haywire? And
[01:01:36.560 --> 01:01:41.120]   they said, Nope, nothing's changed. And you know, the feedback I got was basically like,
[01:01:41.120 --> 01:01:45.440]   we'll pass along your criticism to the teams about how to better communicate. And it's like,
[01:01:45.440 --> 01:01:50.640]   that doesn't help me. And then we just sort of kept getting, you know,
[01:01:50.640 --> 01:01:55.360]   angry or angry messages. Whereas in the past, usually they would just say, you know, we just
[01:01:55.360 --> 01:01:59.200]   won't put ads on this page. And to us, we're like, fine, whatever, we don't get money for that
[01:01:59.200 --> 01:02:04.480]   page. No problem. But now that they started putting these notices that said you must fix it. And
[01:02:04.480 --> 01:02:08.160]   then they told us if we weren't able to fix these things. And again, they weren't very clear as to
[01:02:08.160 --> 01:02:12.880]   what the problem was by the end of August that they were going to cut us off. And then it just
[01:02:12.880 --> 01:02:16.240]   got worse and worse. And we just said, you know, forget it, I don't want to spend all my time
[01:02:16.240 --> 01:02:21.280]   dealing with this. So we pulled all the ads down. And so right now we have no ads on the site other
[01:02:21.280 --> 01:02:26.000]   than, you know, sort of house ads. And we're trying to figure out what we're going to do about it.
[01:02:26.000 --> 01:02:31.280]   But you know, right now we're we're not making advertising revenue. So that's terrible. You
[01:02:31.280 --> 01:02:36.560]   really are defunded. Well, but you're also so you're not earning revenue, but they're not earning
[01:02:36.560 --> 01:02:42.000]   revenue either. So it seems like if this is happening across the board, they don't want this.
[01:02:42.640 --> 01:02:47.440]   There would be somebody within the organization looking around for a broken code is what it
[01:02:47.440 --> 01:02:53.680]   sounds like to me. But again, like the experience, sorry, our experience of Google on this stage,
[01:02:53.680 --> 01:02:59.680]   they're relying totally on automated tools. And it's it's muck up central. It really is. Mike,
[01:02:59.680 --> 01:03:04.720]   sorry, I interrupted. No, that's okay. I mean, you know, the thing is that was my assumption too,
[01:03:04.720 --> 01:03:10.160]   is that they had code that had gone haywire. But we from we haven't heard other sites having the
[01:03:10.160 --> 01:03:16.320]   same sort of, you know, sudden rush of notices. And we've dealt to people at Google. And the
[01:03:16.320 --> 01:03:21.120]   the response that we've gotten is that no, this was this was an accurate thing. And so if you want
[01:03:21.120 --> 01:03:25.920]   to keep having the ads on your site, you have to fix it. And again, like what is what do we think
[01:03:25.920 --> 01:03:31.280]   it's me? Yeah. Yeah. And so like, you know, even in the cases where, you know, in some articles,
[01:03:31.280 --> 01:03:34.960]   some articles like I could figure out like, yeah, sure, they probably don't like these particular
[01:03:34.960 --> 01:03:43.360]   comments. Or, you know, we had some articles about the George Floyd protests that were pretty angry,
[01:03:43.360 --> 01:03:47.440]   because we think that's a situation worth being angry about. And they said that was shocking
[01:03:47.440 --> 01:03:51.600]   content. And so like, okay, that's shocking content. But we're not going to change that just
[01:03:51.600 --> 01:03:55.840]   because Google doesn't like it if they don't want to put ads on that page. Fine. But like, you know,
[01:03:55.840 --> 01:03:59.840]   things like the tag page for Google, what are we supposed to change on that? You know, I'm not
[01:03:59.840 --> 01:04:04.240]   going to be nice to Google just so that Google keeps their ads on the page. If that's the problem,
[01:04:04.240 --> 01:04:08.480]   I think that's a bigger deal of trying to influence our coverage like, hey, that's not cool.
[01:04:08.480 --> 01:04:13.120]   Advertisers do that. You know, we sell our ads direct. We don't go through a service like Google
[01:04:13.120 --> 01:04:19.120]   AdSense. And we've had advertisers, I had an advertiser back in April say, well, we don't want
[01:04:19.120 --> 01:04:25.200]   to be on any content that mentions COVID-19. You're not alone on that. We've had the same
[01:04:25.200 --> 01:04:30.400]   people. So we said, well, no, sorry, stuff that way. Yeah, we won't let advertisers dictate
[01:04:30.400 --> 01:04:34.240]   editorial. I understand though, advertisers are trying to avoid controversy.
[01:04:34.240 --> 01:04:40.080]   So because they're their interest is pure commerce. They just want to sell a product. They don't
[01:04:40.080 --> 01:04:46.640]   want to get people mad at them. So I understand that. But why, for instance, Google suddenly say
[01:04:46.640 --> 01:04:53.280]   that your newsletters, your daily emails are phishing. Yeah, that was the other thing that
[01:04:53.280 --> 01:04:58.160]   the exact same day that this started, all of our daily newsletters, which are just the literally
[01:04:58.160 --> 01:05:04.080]   like a snapshot of the days blog sent out as an email were put into phishing. And so for people
[01:05:04.080 --> 01:05:08.240]   who had G Suite, they were just automatically deleted. And you've got a note saying, we're not
[01:05:08.240 --> 01:05:12.640]   showing you TechDirt's newsletter today because it was a phishing attempt. And for people who just
[01:05:12.640 --> 01:05:17.760]   had Gmail, it was put into spam with big red warning letter, you know, on top saying this is,
[01:05:17.760 --> 01:05:21.840]   this is consistent with a phishing email. We're like, what where's the phishing aspect? We're
[01:05:21.840 --> 01:05:27.920]   not asking anyone to sign in. It's just the, you know, a snapshot of a blog, you know, of all the
[01:05:27.920 --> 01:05:35.840]   stories of the day. And so I was just thinking, I wonder if there's a totally different issue,
[01:05:35.840 --> 01:05:39.200]   which is that you've been blacklisted, like somebody blacklisted the domain,
[01:05:39.200 --> 01:05:44.320]   somebody else who doesn't like either what you're right, or it doesn't like you or.
[01:05:44.320 --> 01:05:50.080]   That's what I'm wondering. Is there community moderation? Are there tools of some kind that's?
[01:05:50.080 --> 01:05:54.800]   I mean, that was some people said that, you know, and people were saying like, maybe people were
[01:05:54.800 --> 01:06:00.240]   even like putting specific comments on the site in order to try and get us demonetized, which is
[01:06:00.240 --> 01:06:05.280]   what's happened before is the comment pages have brought you down. Yeah, which is why a lot of
[01:06:05.280 --> 01:06:12.640]   publications have separate pages for content. There's plenty of tools where you can list or
[01:06:12.640 --> 01:06:20.480]   delist URLs, right? Black Hold them. Yeah. I just wonder if somebody's.
[01:06:20.480 --> 01:06:26.800]   Somebody's out to get you. Never. Or Google has decided that the word dirt should never appear
[01:06:26.800 --> 01:06:33.440]   on a page with advertising. I mean, that's possible. That day will come.
[01:06:33.440 --> 01:06:39.760]   It's possible. I mean, the thing, honestly, what would make this better, though, is if
[01:06:39.760 --> 01:06:43.760]   at least they would explain to us what the deal is, right? I mean, the only information that we get
[01:06:43.760 --> 01:06:48.480]   is, you know, this was deemed dangerous and derogatory, or this was deemed shocking.
[01:06:48.480 --> 01:06:53.760]   And it's like, well, how do we fix that? Right? And it's like, I'm not going to try and figure out
[01:06:53.760 --> 01:06:59.600]   how to make our page on Google, not something that they find derogatory. Like, that's not worth
[01:06:59.600 --> 01:07:05.120]   it in any sense of the word. It's the kind of thing that would make Kafka just sorry.
[01:07:05.120 --> 01:07:07.040]   Yeah, it's very CAF-esque, isn't it? Yeah.
[01:07:07.040 --> 01:07:12.560]   They probably don't know when they don't have a work stream or a unit set up, try to do like a
[01:07:12.560 --> 01:07:18.480]   reverse digital forensic investigation to figure it out. I mean, content moderation is hard at scale.
[01:07:18.480 --> 01:07:23.040]   Yeah. And there's no bigger scale than Google and Facebook, right?
[01:07:23.040 --> 01:07:27.280]   Yeah. Well, I mean, this is the thing, right? I mean, like, one of the articles that early,
[01:07:27.280 --> 01:07:32.000]   like, like last year that we got in trouble for the same thing was the article about,
[01:07:32.000 --> 01:07:36.800]   not that it's hard at scale, that it's impossible to do well at scale. And the funny story was that
[01:07:36.800 --> 01:07:42.320]   we got that one, that article deemed dangerous and derogatory to where we were trying to explain why
[01:07:42.320 --> 01:07:45.120]   these things happen and why we understand why these things happen.
[01:07:45.120 --> 01:07:49.040]   The first rule of content moderation is you don't talk about content moderation.
[01:07:49.040 --> 01:07:55.440]   That seems to be the issue. And it's funny. I mean, I find the whole thing somewhat ironic.
[01:07:55.440 --> 01:08:00.720]   I totally, like, I sympathize with Google being in this position because I recognize they're trying
[01:08:00.720 --> 01:08:07.200]   to keep their advertisers happy. And I would bet that most of the sites where these things pop up
[01:08:07.200 --> 01:08:10.800]   and where people complain, they probably are people who are doing bad things and trying to
[01:08:10.800 --> 01:08:14.640]   gain the system. And so they have these processes in place. It's just that, you know,
[01:08:14.640 --> 01:08:20.560]   we happen to be one of the exceptions now. We got a lot of, I think, we're pretty good actors,
[01:08:20.560 --> 01:08:26.800]   but they don't think so. Very good. Now we're in the market for different advertising solutions.
[01:08:26.800 --> 01:08:33.600]   We are exploring our options as we speak. Yeah. It sounds like it's not a long term solution.
[01:08:33.600 --> 01:08:39.760]   I mean, I know how you feel, Mike, because we're advertising driven the same way and we're still
[01:08:39.760 --> 01:08:45.200]   putting our content out for free. But I don't know. It's scary times over the next few years.
[01:08:45.200 --> 01:08:49.120]   We're going to have to see how this shakes out. But I don't honestly think that giving
[01:08:49.120 --> 01:08:55.520]   a company like Google that much control over your revenue flow, there's no way we can get around
[01:08:55.520 --> 01:09:01.520]   it, but there has to be a better way. Well, yeah, no. And look, I mean, we've been trying to
[01:09:01.520 --> 01:09:06.320]   explore different ways for a long time. And, you know, to be honest, like, you know, AdSense is,
[01:09:06.320 --> 01:09:09.920]   you know, it's not a huge part of our revenue stream because we've been exploring all
[01:09:09.920 --> 01:09:14.880]   different things. And so like losing them sucks, right? I mean, it's still a loss of revenue,
[01:09:14.880 --> 01:09:20.000]   but it is not that is not 100% of our revenue is not even 50% of our revenue. Oh, that's good.
[01:09:20.000 --> 01:09:24.560]   Yeah. But it is still, you know, it is still a certain amount of it that we would prefer that
[01:09:24.560 --> 01:09:30.560]   we had it. It wasn't a big zero. So yeah. Yeah, that's, I mean, we, that's why we spent a lot of money,
[01:09:31.600 --> 01:09:38.480]   millions really building us inside sales because it was we wanted to control our own destiny, you
[01:09:38.480 --> 01:09:45.200]   know, but it's not that's not tenable for a lot of people. Yeah, no, we've tried that. And we
[01:09:45.200 --> 01:09:51.040]   haven't had much luck. Like we're in that, that dangerous spot where we're not quite big enough
[01:09:51.040 --> 01:09:55.120]   to really just have been inside sales. I married somebody who was very good at this.
[01:09:56.960 --> 01:10:02.240]   Choose your spouse wisely is my advice. Lisa is very good at that.
[01:10:02.240 --> 01:10:08.640]   The problem is that this is hits the independence hardest. Yeah, you know, if you're
[01:10:08.640 --> 01:10:16.160]   exactly the voices you want. Speaking. Exactly. It's kind of, it's the outsiders. It's the edge
[01:10:16.160 --> 01:10:20.960]   people, the people that actually break the news rather than, you know, just follow the mainstream.
[01:10:20.960 --> 01:10:27.280]   And that's what makes this really disturbing. I mean, I've, I've re TECTER daily and you do a
[01:10:27.280 --> 01:10:32.240]   great publication there. But yeah, it's going to be interesting to see how this works out. I hope
[01:10:32.240 --> 01:10:37.680]   it works out for the best for all of us. I've always worried for Mike, TECTER, because you don't
[01:10:37.680 --> 01:10:44.240]   pull your punches. And when that guy, the email guy sued you, I thought, Oh crap. But you've
[01:10:44.240 --> 01:10:49.600]   stood it. You stood there and you know, you fought the good fight. So everybody.
[01:10:49.600 --> 01:10:56.960]   Yeah, that guy was at complete wanker and he can sue me. It just says no way that was that was
[01:10:56.960 --> 01:11:05.920]   justified. He won't sue you. He'll sue me. So stop. I don't know this guy. What the
[01:11:05.920 --> 01:11:11.920]   hell color is that mustache? No, no, I'm kidding. I'm just teasing.
[01:11:11.920 --> 01:11:22.720]   Uber and Lyft could have some problems in California this week. A judge ruled no, your employees,
[01:11:22.720 --> 01:11:29.920]   your drivers are not contractors. They are employees. And you have to pay them as such.
[01:11:31.600 --> 01:11:38.000]   Both companies say they may actually suspend all operations in the state. But they are pushing a
[01:11:38.000 --> 01:11:44.400]   referendum ballot this November that would exempt them from AB five. AB five has been a mixed bag.
[01:11:44.400 --> 01:11:50.880]   It was really targeted at these drivers specifically, but it hurt all gig workers, including a lot of
[01:11:50.880 --> 01:11:59.360]   our friends, independent freelance writers who can't work because they're Californians and
[01:12:00.320 --> 01:12:05.120]   companies won't hire them or won't give them work because of this really strict limitations
[01:12:05.120 --> 01:12:10.800]   in California and what constitutes contract work. They're limited on the number of articles
[01:12:10.800 --> 01:12:17.440]   they can write, for instance. I've got to say though, Uber and Lyft statements have been kind of like
[01:12:17.440 --> 01:12:23.040]   nice ride share service you had there, shame if something was going to happen to it. I mean,
[01:12:23.040 --> 01:12:29.440]   they're basically saying we will lock you out unless you do what we say. And that's not how
[01:12:29.440 --> 01:12:34.640]   democracy works. So I can not just doing that. They're trying to change the law in November.
[01:12:34.640 --> 01:12:39.120]   They've got a referendum. They've got a rock 22 going through the law. Yeah. And they're pushing
[01:12:39.120 --> 01:12:45.120]   it to all their customers. I've been getting the ads as well. They've been running a lot of ads.
[01:12:45.120 --> 01:12:51.200]   Have you seen the ads? You know, I'm a mother of four. And I could the only way I can make a living
[01:12:51.200 --> 01:12:57.040]   is by delivering groceries every, you know, third day or whatever. And, you know, it makes you
[01:12:57.040 --> 01:13:03.040]   target the heartstrings. And I don't know how I feel about this. I understand. And the IRS has
[01:13:03.040 --> 01:13:09.920]   always had strict rules about who can be, you know, a lot of companies use contract employees
[01:13:09.920 --> 01:13:17.040]   to avoid paying benefits and other expenses. And they do it in effect as a way to dodge treating
[01:13:17.040 --> 01:13:22.000]   the employee properly. And I understand that's what AB5 is trying to take care of. But at the same
[01:13:22.000 --> 01:13:28.160]   time, I also nowadays we know a lot of gig workers. And it's hard for them. You know,
[01:13:28.160 --> 01:13:31.920]   all you're gainfully employed. But I know a lot of the people we have on these shows
[01:13:31.920 --> 01:13:37.920]   are hurt by this law. So I think this law doesn't think about the long term.
[01:13:37.920 --> 01:13:45.520]   So yes, something needs to be done to provide better services for the people who are contract
[01:13:45.520 --> 01:13:52.800]   workers. But this referendum on Uber and Lyft has very long term consequences for the state of
[01:13:52.800 --> 01:13:59.520]   California. Katie Binley in the Wall Street Journal, the weekend journal has a huge story about tech
[01:13:59.520 --> 01:14:06.320]   migration. And people because of the virus choosing to live somewhere else. And then just, you know,
[01:14:06.320 --> 01:14:09.920]   if you're working from home, you can work from home anywhere. It doesn't have to be California.
[01:14:09.920 --> 01:14:14.000]   But if you're in a situation where you're a contract worker and there's lingering economic
[01:14:14.000 --> 01:14:22.960]   recession and the virus is protracted, California stands, I think, to one of the unintended consequences
[01:14:22.960 --> 01:14:26.720]   of trying to get people better benefits is that you drive revenue out of the state.
[01:14:26.720 --> 01:14:32.400]   So there's a great illustration on that article of a Model 3 Tesla going across the Golden Gate
[01:14:32.400 --> 01:14:40.080]   Bridge, just like the Jodes leaving Oklahoma with all their stuff on the roof.
[01:14:41.280 --> 01:14:48.400]   I agree that something should be done. So the problem with every government is that there's no
[01:14:48.400 --> 01:14:53.920]   planning. There's no long term planning in place. So this addresses an existing problem without
[01:14:53.920 --> 01:14:59.920]   thinking through the next order impacts and how you could wind up, it's all coming from a very
[01:14:59.920 --> 01:15:03.360]   good place, but you could wind up with serious problems on the other side.
[01:15:05.280 --> 01:15:11.760]   Yeah, I think that part of the thing with AB5 was just that it assumes that everyone who is a
[01:15:11.760 --> 01:15:17.040]   contractor or a freelancer or a gig worker wants it to be a full-time job. And I think for those who
[01:15:17.040 --> 01:15:22.000]   actually do want that, then there's benefits there. But for a huge number of those people,
[01:15:22.000 --> 01:15:26.000]   they actually don't want it to be a full-time job. They like the flexibility. They like the
[01:15:26.000 --> 01:15:31.840]   ability to have it be like an additional income or to be able to change things up or to make their
[01:15:31.840 --> 01:15:37.360]   own hours and things like that. And AB5 doesn't take that into account. And certainly in the
[01:15:37.360 --> 01:15:42.640]   journalism space, the number of answers in California, I know a bunch of them certainly,
[01:15:42.640 --> 01:15:48.240]   who are all suffering because of this law. And they're saying, we never want it to be full-time.
[01:15:48.240 --> 01:15:51.920]   I don't want to be tied to a particular publication, which is probably going to go out of business
[01:15:51.920 --> 01:15:59.440]   soon anyways. I want to be able to bounce around. And I think that people say it's very cynical that
[01:15:59.440 --> 01:16:06.560]   Uber and Lyft have been pushing for a third option between freelance contractor and full-time employee.
[01:16:06.560 --> 01:16:11.840]   But when you look at it, it makes sense. There should be something different because it is a
[01:16:11.840 --> 01:16:19.040]   different type of work. And you want there to be some sort of safety net for them in terms of
[01:16:19.040 --> 01:16:26.240]   doing their job, but saying that it has to be a full-time employee or a fully benefited employee
[01:16:26.240 --> 01:16:30.320]   is not necessarily the right answer. So figuring out something in between would be good, but that's
[01:16:30.320 --> 01:16:34.480]   not what the California legislature has done. I talked to a lot of really unhappy Uber and Lyft
[01:16:34.480 --> 01:16:43.920]   drivers, not lately, but before COVID. There weren't a lot of them that were thrilled
[01:16:43.920 --> 01:16:48.320]   with the way they were still doing it. So obviously it's somewhat worked for them.
[01:16:48.320 --> 01:16:53.840]   But do you think Uber and Lyft take advantage of their drivers?
[01:16:55.280 --> 01:17:01.760]   Yes, they do. I'm sorry. Uber and Lyft's business model does not work unless you can pay less than
[01:17:01.760 --> 01:17:06.880]   full-time wages. Their whole model is actually ultimately based on not having drivers at all.
[01:17:06.880 --> 01:17:12.000]   Also, they're a set horrible rental model where they were trying to get people to
[01:17:12.000 --> 01:17:16.320]   upgrade to black cars, but do the financing through them, which was horrible.
[01:17:16.320 --> 01:17:22.000]   Worse than a taxi though, the taxi drivers kind of get a roped few.
[01:17:22.000 --> 01:17:28.480]   Medallion system in New York is part of the reason why Uber was able to grow because that was a
[01:17:28.480 --> 01:17:33.600]   keen lack of planning. They never issued more Medallion as somebody who's in New York and
[01:17:33.600 --> 01:17:39.360]   never limited them. That was intentional. It became absolutely untenable. So just before
[01:17:39.360 --> 01:17:46.480]   the virus, you had 100,000 Uber drivers crowding the streets of the boroughs, many of them in Manhattan.
[01:17:47.920 --> 01:17:53.760]   Also was bad. But the whole thing, again, a lot of our current problems are the result of nobody
[01:17:53.760 --> 01:17:59.920]   thinking that through the next order impacts and having the wherewithal to make short-term
[01:17:59.920 --> 01:18:04.560]   decisions that benefit the longer term versus cause less kind of harm.
[01:18:04.560 --> 01:18:09.920]   We really reward that. Both Lyft and Uber have had huge rewards to the founders.
[01:18:09.920 --> 01:18:16.640]   The thing that I don't fully understand that Uber and Lyft haven't done that I think they
[01:18:16.640 --> 01:18:20.160]   might have been in a better position if they had done is make it a real marketplace,
[01:18:20.160 --> 01:18:25.520]   where it left the drivers effectively set their prices as well and then let Uber and Lyft sort
[01:18:25.520 --> 01:18:32.320]   of match prices based on what customers are looking for and what drivers are willing to accept.
[01:18:32.320 --> 01:18:36.880]   Instead, basically, they're doing everything. Uber and Lyft are setting everything, including
[01:18:36.880 --> 01:18:41.600]   exactly what the price is. Therefore, it's harder to call them a true marketplace. If they had
[01:18:41.600 --> 01:18:45.520]   set it up as a real marketplace, then I think they would have a stronger argument here.
[01:18:45.520 --> 01:18:54.320]   I don't know about Lyft, but I know that Uber subsidizes $0.41 on the dollar for every ride.
[01:18:54.320 --> 01:19:01.680]   It's not exactly a flexible pricing model. They're doing that for a reason,
[01:19:01.680 --> 01:19:07.120]   because they want to dominate the market and once they've got autogopelier, monopoly control,
[01:19:07.120 --> 01:19:13.360]   they can check the price. But their business model doesn't work unless they can pay less than
[01:19:13.360 --> 01:19:20.240]   taxi drive. I'm with you, Amy. The taxi system in the US, and I spoke to a VC and he goes,
[01:19:20.240 --> 01:19:26.160]   "You want to know why Uber really took off an SF because SF taxi drivers are amongst the worst
[01:19:26.160 --> 01:19:32.480]   in the world to screen you over?" I can understand that totally. I'm sorry, if someone's working
[01:19:32.480 --> 01:19:39.200]   60 hours a day for Uber, sorry, 60 hours a week for Uber, they are a full-time employee and they
[01:19:39.200 --> 01:19:44.560]   should be treated as such. Is part of the problem in this country that we don't have
[01:19:44.560 --> 01:19:52.400]   national healthcare? We're seeing right now a huge problem because for most Americans,
[01:19:52.400 --> 01:19:57.200]   their healthcare is tied to their employment. When you're out of work,
[01:19:58.000 --> 01:20:02.560]   you're out of healthcare at the same time. That really is what all of this AB5 is about,
[01:20:02.560 --> 01:20:09.040]   is not paying those benefits to those workers because they're contractors, so I don't have to pay
[01:20:09.040 --> 01:20:18.960]   health. I'm going to say, Amy. I've got to say, as a European, it is shocking,
[01:20:18.960 --> 01:20:23.280]   really shocking quite how bad things were. I had no idea until I moved out here.
[01:20:24.400 --> 01:20:30.880]   You've got student loans, you've got medical insurance. It's basically economic surfdom,
[01:20:30.880 --> 01:20:36.240]   as far as I can see. If you don't have a job, you can't pay off your loans, you can't pay off
[01:20:36.240 --> 01:20:42.080]   your medical care. If you've got a family, this is just killing innovation in this country.
[01:20:42.080 --> 01:20:45.760]   If you've got a family, you're not going to go out alone and make your own startup because you
[01:20:45.760 --> 01:20:54.080]   can't afford the healthcare costs. There is an argument that Microsoft and Apple
[01:20:54.080 --> 01:20:59.120]   kicked off because they were started by kids in their 20s who didn't have families to look after.
[01:20:59.120 --> 01:21:03.680]   But if you've got a family, if you've got a serious medical condition, you can't afford to lose your
[01:21:03.680 --> 01:21:10.800]   job. It's massively harming towards innovation and it's killing America at this point. I'm sorry.
[01:21:10.800 --> 01:21:17.040]   I can't give you. Oh, no, I completely agree with you. My company has several employees.
[01:21:19.920 --> 01:21:27.760]   A couple of years ago, I thought this was insane that if for some reason we part ways,
[01:21:27.760 --> 01:21:33.360]   you know, that their insurance is going to go away. So I tried to convert the entire company
[01:21:33.360 --> 01:21:38.400]   over to a system where we still, we would cover everybody's insurance, the whole thing,
[01:21:38.400 --> 01:21:44.320]   and really good insurance, but that it was in their name. So what I tried to do was buy
[01:21:44.320 --> 01:21:49.680]   everybody their own and we have employees in many different states and also in Canada.
[01:21:49.680 --> 01:21:55.680]   So I tried to buy different policies. It was so onerous and so so that they could keep them.
[01:21:55.680 --> 01:22:05.200]   The whole process was so ridiculously hard that and it wasn't clear whether or not they were going
[01:22:05.200 --> 01:22:09.280]   to get the benefits that I knew we could get through a company plan. I finally just gave up.
[01:22:09.280 --> 01:22:17.760]   We still pay for all of, we cover all of their benefits, but the problem remains that they,
[01:22:17.760 --> 01:22:24.640]   you know, they can't really take all of that with them. And it's expensive. My
[01:22:24.640 --> 01:22:30.880]   per employee insurance rates are very, very expensive. Like those are 1000.
[01:22:30.880 --> 01:22:32.880]   Yeah. Yeah. Yeah. That's very expensive.
[01:22:32.880 --> 01:22:38.400]   We're in the same boat, basically. I mean, we have employees all over and also Canada,
[01:22:38.400 --> 01:22:41.520]   though, Canada is a little bit different because they do have universal health care.
[01:22:41.520 --> 01:22:44.400]   Yeah, that's fine. It's a separate issue.
[01:22:44.400 --> 01:22:51.120]   Yeah. Before employees in the states, it is a challenge. And of course, we do the same thing
[01:22:51.120 --> 01:22:56.960]   where we want to provide them really good healthcare, but it's doing that in a way that is sensible.
[01:22:56.960 --> 01:23:01.680]   I think honestly, it's a parallel to what we were talking about earlier with this idea of like,
[01:23:01.680 --> 01:23:06.400]   you know, infrastructure, right? To me, healthcare, to some extent, is infrastructure, right? If you
[01:23:06.400 --> 01:23:11.760]   can provide a base level of healthcare to everyone, like you need that for everything else that
[01:23:11.760 --> 01:23:15.760]   happens in the economy and everything else that happens in the world, you shouldn't have people
[01:23:15.760 --> 01:23:21.440]   worrying about that in order to do everything else that they need to do to make the economy run.
[01:23:21.440 --> 01:23:27.280]   Two stories. One from our chatroom, Elrich says, my company decided to fire 500 people.
[01:23:27.280 --> 01:23:32.640]   They fired people from the Mountain View, California office instead of the Toronto office,
[01:23:32.640 --> 01:23:38.000]   because the Toronto people were cheaper. They don't have to pay healthcare. And then our friend,
[01:23:38.000 --> 01:23:47.280]   Renee Ritchie, who left I'm more, left his full-time job with, which would have paid benefits,
[01:23:47.280 --> 01:23:51.520]   except he's in Quebec. And he was able to start his own YouTube channel because he didn't have
[01:23:51.520 --> 01:23:56.800]   to worry about that. So there is definitely a burden, an innovation burden.
[01:23:56.800 --> 01:24:02.800]   Well, I mean, we have the same problem with the Raj. I mean, we had a situation before COVID kicked
[01:24:02.800 --> 01:24:11.600]   in where we were looking to expand our journalist headcount. And honestly, it was simple economics.
[01:24:11.600 --> 01:24:17.760]   For the amount of healthcare costs we'd have to pay in the US, we could employ two journalists
[01:24:17.760 --> 01:24:23.600]   in the UK, whether they have a national health care system. So it was just logical. We would
[01:24:23.600 --> 01:24:28.960]   love to hire more US journalists, but given the excess costs that are going on there,
[01:24:28.960 --> 01:24:34.720]   and the fact that health companies have to show like a 5 or 6% growth rate every year, which means
[01:24:34.720 --> 01:24:42.080]   prices get jacked up with the US under the system. That's why this show, there's a Brit and two
[01:24:42.080 --> 01:24:48.000]   aliens because I don't have to pay you guys healthcare at all. That's a joke. We're going to take a
[01:24:48.000 --> 01:24:52.240]   little break, come back with their Microsoft announced a new phone, but it's not a phone, but it's
[01:24:52.240 --> 01:24:56.880]   scored of a phone, but I don't know if it's a phone. And the reaction we're seeing from the tech
[01:24:56.880 --> 01:25:00.640]   blogs is very interesting. We'll talk about that. And a lot more. Amy Webb is here from the
[01:25:00.640 --> 01:25:06.960]   future today Institute, future day Institute.com. Ian Thompson from the register.com. Mike
[01:25:06.960 --> 01:25:11.760]   Masnick from techter.com. Always a pleasure having you guys. We were going to have a little
[01:25:11.760 --> 01:25:21.920]   fortnight fight, but we decided not to get this camera yet. Now I'm out of ammo. I showed you
[01:25:21.920 --> 01:25:29.920]   a little bit of a 3.30 for disnaming. I have to calibrate the sights on this nerf pistol.
[01:25:29.920 --> 01:25:36.160]   You know, when we moved into the brick house many moons ago, I guess almost 10 years ago,
[01:25:36.160 --> 01:25:40.800]   I had this crazy idea because we had this giant 10,000 square foot basement that at the time
[01:25:40.800 --> 01:25:44.960]   was completely empty. We eventually we filled it with crap, but at the time was completely empty.
[01:25:44.960 --> 01:25:49.920]   And I bought like 20 nerf guns. I thought we'd have a great big battle. This is the last one
[01:25:49.920 --> 01:25:56.160]   left. I don't know where they've all gone to our show today brought to you by wasabi hot cloud
[01:25:56.160 --> 01:26:02.800]   storage. I think this is amazing, but I wish more people knew about everybody knows about Amazon
[01:26:02.800 --> 01:26:11.040]   S3. What if I told you there was something that was compatible with the S3 API, but was 80% cheaper.
[01:26:11.040 --> 01:26:16.640]   Didn't didn't charge for egress didn't have all those crazy tears.
[01:26:17.760 --> 01:26:23.840]   That was even faster than S3 provided 11 nines of durability. Wouldn't you be interested?
[01:26:23.840 --> 01:26:28.960]   But everybody talks about Amazon, Google, the clouds got to be micros.
[01:26:28.960 --> 01:26:36.720]   It's wasabi wasabi's disruptive price performance model is putting everything is upending people's
[01:26:36.720 --> 01:26:45.120]   storage plans wasabi is actually less than on Prem storage less than just the annual cost for
[01:26:45.120 --> 01:26:50.080]   maintenance fees on on Prem storage. That's how much you save with the wasabi.
[01:26:50.080 --> 01:26:58.240]   It is a fantastic way. And if you know you're going to be creating a lot of data,
[01:26:58.240 --> 01:27:02.800]   most companies do, you know, we're going to have a terabyte a week or whatever. Wasabi's a great
[01:27:02.800 --> 01:27:07.120]   choice. Just compare that to the cost of on Prem storage. Your boss might say, well, on Prem,
[01:27:07.120 --> 01:27:14.160]   we know it's safe for it secure. No wasabi's 11 nines of durability. They're hosted in premier tier
[01:27:14.160 --> 01:27:19.600]   four data centers that are not only fully secure, but they're fully redundant. They do active
[01:27:19.600 --> 01:27:25.680]   integrity checking all objects stored on wasabi servers are checked for integrity every 90 days.
[01:27:25.680 --> 01:27:31.200]   And because they're on redundant network centers, if there's one bit off, you can restore it and
[01:27:31.200 --> 01:27:36.160]   you never lost a bit. That's how you get 11 nines of durability. It's secure by default.
[01:27:36.160 --> 01:27:40.560]   Everything stored in the wasabi cloud is always encrypted at rest, even if you don't specify it.
[01:27:41.120 --> 01:27:44.880]   Of course, they follow all the industry's best security models and design practices. You've got
[01:27:44.880 --> 01:27:52.240]   access control mechanisms, bucket policies, ACLs. One of my favorite things, and it's great if you're
[01:27:52.240 --> 01:27:57.840]   reading about Garmin and all the people being hit by ransomware, you will love this. Your data in
[01:27:57.840 --> 01:28:03.520]   the cloud is can be immutable. You can say this can't be changed. It cannot be erased. It cannot
[01:28:03.520 --> 01:28:12.960]   be altered either by malware, hackers, fumble-fingered employees. Your data is safe. Wasabi is highly
[01:28:12.960 --> 01:28:20.480]   secure disruptive technology that's turning its industry on its ear. 80% cheaper, six times faster
[01:28:20.480 --> 01:28:26.960]   than Amazon S3. And now there are two ways to go. There's flat fee, very affordable, or
[01:28:27.760 --> 01:28:33.760]   you can pay one time and get reserved capacity storage. This is for companies that know we're
[01:28:33.760 --> 01:28:37.520]   going to be using a certain amount of storage every week, every month, every year. So what you do is
[01:28:37.520 --> 01:28:43.280]   you reserve it with Asabi ahead of time. Just like you would buy storage ahead of time, you're not
[01:28:43.280 --> 01:28:46.720]   going to buy the hard drive the minute you need it. You buy it ahead of time. You reserve the
[01:28:46.720 --> 01:28:52.240]   capacity with Asabi for one, three, or five year increments. The more you reserve, the longer the
[01:28:52.240 --> 01:28:58.480]   term, the more you'll save. You can save a lot. Like I said, it's significantly less than on-prem
[01:28:58.480 --> 01:29:04.080]   storage. It's less than the annual cost of maintenance fees for on-prem storage with
[01:29:04.080 --> 01:29:10.400]   Asabi is just a no-brainer. And if you're a managed service provider and you resell this
[01:29:10.400 --> 01:29:15.200]   stuff, you're going to love it because you can sell it at a lower cost and still make more money.
[01:29:15.200 --> 01:29:20.800]   Everybody wins with Asabi. Calculate the savings for yourself. You can start a free trial right
[01:29:20.800 --> 01:29:25.840]   now for one month. Go to Asabi.com. Click the free trial link under the code TWIT. Play with it,
[01:29:25.840 --> 01:29:30.880]   bang on it, mess with it. I think you'll see really. But since it uses the S3 API, all your
[01:29:30.880 --> 01:29:35.600]   tools already work. Join the movement. Migrate your data to the cloud and do it with confidence.
[01:29:35.600 --> 01:29:42.720]   W-A-S-A-B-I.com. Look, everybody's using more and more storage. Asabi's the place to do it.
[01:29:42.720 --> 01:29:49.280]   Asabi.com, use the offer code TWIT. Hey, before we go on, we had a fun week this week on TWIT.
[01:29:49.280 --> 01:29:54.160]   And I understand a small movie has been made to demonstrate watch.
[01:29:54.160 --> 01:29:58.400]   Steve Wasting is celebrating a birthday.
[01:29:58.400 --> 01:30:00.080]   ♪ Was his god ♪
[01:30:00.080 --> 01:30:02.720]   ♪ Everything he could ever want ♪
[01:30:02.720 --> 01:30:06.480]   ♪ Including honorary doctorate degrees ♪
[01:30:06.480 --> 01:30:10.560]   ♪ Thank you, Jonathan Mann, the song "A Day Man" ♪
[01:30:10.560 --> 01:30:14.080]   Previously on TWIT. All about Android.
[01:30:14.080 --> 01:30:18.720]   You've been considering waiting for the foray to get most of the things right that it really needed
[01:30:18.720 --> 01:30:21.600]   to land. The camera's great. It's felt, it's light.
[01:30:21.600 --> 01:30:23.760]   Windows Weekory. The DUO's here!
[01:30:23.760 --> 01:30:27.200]   Despite the fact that every other form factor they've tried has not succeeded.
[01:30:27.200 --> 01:30:30.160]   They did do it once with the Surface Pro and they clearly want to do it again.
[01:30:30.160 --> 01:30:33.360]   And they're making this bet for some reason on a dual screen device.
[01:30:33.360 --> 01:30:35.920]   Tech News Weekly. Harry McCracken from Fast Company.
[01:30:35.920 --> 01:30:37.840]   He has the new Surface Duo device.
[01:30:37.840 --> 01:30:40.240]   That's quite wide. Like I couldn't put it in my shirt pocket.
[01:30:40.240 --> 01:30:43.040]   And it is really thin. If thinner than other smartphones.
[01:30:43.040 --> 01:30:44.000]   Mac Break Weekly.
[01:30:44.000 --> 01:30:46.880]   This iMac has got way better AMD graphics,
[01:30:46.880 --> 01:30:49.440]   a way better camera. But that nano-texture displayed.
[01:30:49.440 --> 01:30:51.680]   It is the best screen I have ever seen.
[01:30:51.680 --> 01:30:53.920]   But how do you not touch me alone?
[01:30:53.920 --> 01:30:54.880]   I know, right?
[01:30:54.880 --> 01:31:00.720]   Apple says they're not going to allow XCloud or Stadia on iOS.
[01:31:00.720 --> 01:31:04.480]   Here's a moment where the world is really going to like title wave
[01:31:04.480 --> 01:31:05.680]   their opinions on this.
[01:31:05.680 --> 01:31:11.440]   Live update, Epic's Fortnite has been removed from the App Store after they implemented direct
[01:31:11.440 --> 01:31:16.480]   payments. Today, Epic Games took the unfortunate step of violating the App Store
[01:31:16.480 --> 01:31:22.320]   guidelines that are applied equally to every developer and designed to keep the store safe for our users.
[01:31:22.320 --> 01:31:25.200]   If you missed to it this week, you missed a lot.
[01:31:25.200 --> 01:31:26.160]   I know, right?
[01:31:26.160 --> 01:31:33.520]   I am nuts. I am nuts. I admit it. I woke up Wednesday morning.
[01:31:33.520 --> 01:31:38.560]   I saw at 6 a.m. Microsoft selling a new phone. I rushed out,
[01:31:38.560 --> 01:31:44.160]   laid down my $1,400 and bought a Surface Duo.
[01:31:44.880 --> 01:31:48.640]   Then I read all the articles saying, "Oh, this is a terrible idea."
[01:31:48.640 --> 01:31:51.520]   I thought it was a great idea.
[01:31:51.520 --> 01:31:58.240]   Any thoughts? Was I nuts? It looks like a little Monoskeen a notebook.
[01:31:58.240 --> 01:32:02.320]   Two screens. I was going to buy the Galaxy Fold. I thought, "Why fold in half?
[01:32:02.320 --> 01:32:07.120]   Just have a hinge. Two screens. The software works so that you can move stuff.
[01:32:07.120 --> 01:32:09.120]   You have two Android apps running."
[01:32:09.120 --> 01:32:11.600]   The other thing I think it's interesting is for the first time ever,
[01:32:13.040 --> 01:32:18.400]   Microsoft, which normally provides operating systems to OEMs who build hardware.
[01:32:18.400 --> 01:32:22.720]   For the first time ever, Microsoft is an OEM building hardware based on Google's software.
[01:32:22.720 --> 01:32:25.520]   Somebody else's operating system. It's their first Android device.
[01:32:25.520 --> 01:32:30.240]   I think it's very interesting. I think it could be a form factor that could change things.
[01:32:30.240 --> 01:32:31.200]   Am I nuts, Amy?
[01:32:31.200 --> 01:32:38.160]   Well, did you ever play with, I'm sure you did, the Windows phone a billion years ago?
[01:32:38.160 --> 01:32:40.160]   Those were awful, though. Those were terrible.
[01:32:40.160 --> 01:32:47.840]   Well, which Windows phone? No, Windows phone 7 and 8. The new one with the tiles, I like that.
[01:32:47.840 --> 01:32:49.280]   The tiles. I had the tiles.
[01:32:49.280 --> 01:32:50.880]   You're not talking about the old Windows C.
[01:32:50.880 --> 01:32:54.720]   I like that. I thought that was good.
[01:32:54.720 --> 01:33:00.400]   I actually thought that the phone was, and I can't remember which operating system was,
[01:33:00.400 --> 01:33:02.400]   but the hardware was pretty nice.
[01:33:02.400 --> 01:33:03.920]   The Nokia's...
[01:33:03.920 --> 01:33:06.320]   The Nokia cameras are fantastic.
[01:33:06.320 --> 01:33:07.760]   40 megapixel cameras.
[01:33:08.800 --> 01:33:09.680]   It wasn't the phone.
[01:33:09.680 --> 01:33:11.280]   It was great. The operating system was great.
[01:33:11.280 --> 01:33:15.040]   I don't even think the... No, no, I don't even think the... I think Microsoft
[01:33:15.040 --> 01:33:19.280]   did something really interesting. They sat back while Google and Apple went crazy
[01:33:19.280 --> 01:33:23.120]   with mobile and they looked and they looked and they said, "Okay, we could do something better."
[01:33:23.120 --> 01:33:26.800]   They did make something better, but by then they were way in the back...
[01:33:26.800 --> 01:33:31.280]   And Google and Apple were miles ahead of them and it was hopeless.
[01:33:31.280 --> 01:33:35.760]   So full disclosure, I've advised Microsoft on and off for many years.
[01:33:37.280 --> 01:33:44.000]   I continue to think that in a lot of areas, Microsoft has superior code, has superior products.
[01:33:44.000 --> 01:33:50.240]   The problem is making decisions internally and getting it to market.
[01:33:50.240 --> 01:33:54.800]   I mean, where is the value network?
[01:33:54.800 --> 01:33:58.960]   Where is the ecosystem of the developers and the people and the processes and the work streams
[01:33:58.960 --> 01:34:00.240]   and the apps? You know what I mean?
[01:34:00.240 --> 01:34:06.640]   It's just... I think at some point you have to also invest in really developing and getting
[01:34:06.640 --> 01:34:11.680]   it, getting that entire... Let me make the case. Let me pretend that I'm such
[01:34:11.680 --> 01:34:15.520]   in a dollar a panel of penneas and charger devices. Let me make the case.
[01:34:15.520 --> 01:34:22.400]   People... The world is changing clearly, right? The idea of a PC on your desk,
[01:34:22.400 --> 01:34:25.280]   mobile completely blew that out of the water, right?
[01:34:25.280 --> 01:34:28.560]   This is Microsoft's business. In fact, for the first time ever, I was looking at Microsoft's
[01:34:28.560 --> 01:34:31.040]   quarterly... Or actually, it was the yearly results.
[01:34:31.040 --> 01:34:36.080]   And Azure was the biggest money maker. Then there was Windows, then there was Office,
[01:34:36.080 --> 01:34:39.440]   then there was a bunch of other stuff. Those lines have completely crossed.
[01:34:39.440 --> 01:34:44.400]   Microsoft is a cloud company now. And I wonder really how much longer they want.
[01:34:44.400 --> 01:34:50.400]   They care that much about Office and Windows. So what I think is that they're thinking
[01:34:50.400 --> 01:34:54.880]   Nadella comes from the Azure division. They're thinking, "Look, devices aren't going to matter
[01:34:54.880 --> 01:35:00.080]   so much. Nobody's going to say, 'Oh, I have to run Windows. It doesn't matter. I can run a Chromebook.
[01:35:00.080 --> 01:35:04.800]   I can run iPad. I can run anything I want. I just... I need a window to the cloud.
[01:35:04.800 --> 01:35:09.840]   What does matter is form factor. And what Microsoft is desperately trying to figure out is,
[01:35:09.840 --> 01:35:14.240]   what are these thin clients? We know our business is going to be selling
[01:35:14.240 --> 01:35:19.760]   software as a service and operating systems as a service. What are the clients going to be?
[01:35:19.760 --> 01:35:24.320]   And how can we have a part of that market as well? And so it makes sense for me for them to release
[01:35:24.320 --> 01:35:28.960]   something that is a complete... It's not a slab of glass. It's a unique way of looking at it.
[01:35:28.960 --> 01:35:32.960]   It still relies on parts from other places around the world.
[01:35:32.960 --> 01:35:36.560]   Well, that's true. Well, but this could potentially be a challenge going,
[01:35:36.560 --> 01:35:40.880]   well, who's going to make anything nowadays if you do that? If you say that, I'm not going to make
[01:35:40.880 --> 01:35:46.320]   any hard. I can't make a refrigerator. I'm going to say, I'm going to make it in Muncie. Where
[01:35:46.320 --> 01:35:51.600]   am I going to make it? I'm going to make it. I mean, I've got to say, I do kind of like Microsoft's
[01:35:51.600 --> 01:35:58.640]   approach to this and that they've got rid of the whole folding screen business because I still
[01:35:58.640 --> 01:36:02.800]   don't think the technology is there on that. That's clearly bad. I'm doing the dual screen,
[01:36:02.800 --> 01:36:08.560]   I think is going to pay benefits, but it's Microsoft. They're not exactly innovators.
[01:36:08.560 --> 01:36:12.720]   They are developers rather than innovation. Well, that's why I thought this was interesting
[01:36:12.720 --> 01:36:17.760]   because you're right. I wasn't very impressed with any of the surface stuff.
[01:36:17.760 --> 01:36:24.400]   And I'm not a Windows fan. I don't like Windows. But I think this idea of two screens,
[01:36:24.400 --> 01:36:29.680]   it's small enough to put in your pocket, but it opens up to an 80 inch, kind of like a tablet.
[01:36:29.680 --> 01:36:34.400]   It's kind of interesting. If they can get the scrolling between the two to work fine,
[01:36:34.400 --> 01:36:41.440]   it looks pretty good. That would actually work fairly well. I've never yet seen a
[01:36:41.440 --> 01:36:46.400]   foldable screen which would last more than six months to a year. The screens are folding.
[01:36:46.400 --> 01:36:50.960]   The screens are folding. Yeah, no, exactly. This is why they've done the smart thing
[01:36:50.960 --> 01:36:56.080]   by doing two separate screens. Samsung and the rest of them can go for this folding screen,
[01:36:56.080 --> 01:37:04.400]   but I don't honestly think it's going to work. I feel like I saw an HTC phone. I used to live
[01:37:04.400 --> 01:37:10.960]   in Hong Kong and I was going back and forth a bunch. I feel like I saw HTC or somebody else had
[01:37:10.960 --> 01:37:16.320]   a dual screen. So you had to flip the phone around, but it was you double the wheel. LG has a dual
[01:37:16.320 --> 01:37:20.560]   screen. No, you're right. This has been around. In fact, remember when you lived in Japan
[01:37:20.560 --> 01:37:27.680]   and those big weird phones that were really, they had flipped, but they had too... This is not new.
[01:37:27.680 --> 01:37:36.960]   Now, I keep wondering when... I'm surprised we haven't seen more work in scrolling surfaces,
[01:37:36.960 --> 01:37:44.480]   more like an e-ink versus a traditional screen that's now just bigger and too hinged together.
[01:37:46.800 --> 01:37:53.760]   For certain purposes, I think we're headed to an ecosystem where we've got more diversification
[01:37:53.760 --> 01:37:57.600]   of devices for a while, where we've got a lot of experimentation and different types of...
[01:37:57.600 --> 01:38:02.960]   Well, that's one of the things I want to celebrate. Yeah, I mean, the last thing I want to do is buy
[01:38:02.960 --> 01:38:09.760]   another glass slab. Right, that's right. I meant retractable. So like, pick there a pen that you
[01:38:09.760 --> 01:38:15.840]   can retract a screen out of. There's functionality there. It's not as pretty or let's see, but...
[01:38:15.840 --> 01:38:22.000]   This is kind of pretty, I think. Sure, it's pretty. You going to use it? Yeah, I think so.
[01:38:22.000 --> 01:38:29.520]   Even if I just use it as a really, really expensive Kindle, I love the idea that Amazon did the
[01:38:29.520 --> 01:38:35.200]   Kindle software so that you could... The other thing is because it's got a 360 hinge, and so you
[01:38:35.200 --> 01:38:39.360]   could use it like, look at that. Now, wait a minute. Let me just go back and show you this. This is the...
[01:38:39.360 --> 01:38:43.680]   That page full of those books. Yes. That's the Kindle. It's like a little book.
[01:38:44.400 --> 01:38:48.720]   Yeah, that is the Puppies Packet. I mean, you've got the good scrolling system going through,
[01:38:48.720 --> 01:38:54.800]   but honestly, I miss Eink. Eink sucks. Oh, come on.
[01:38:54.800 --> 01:39:02.160]   It sounds like 15 years ago. Right. I have all the latest Kindles. I have the Amazon Oasis and I...
[01:39:02.160 --> 01:39:10.640]   It still sucks. It's flexible though. So don't, don't conflate Eink with the device that Amazon...
[01:39:10.640 --> 01:39:17.440]   Oh, okay. Right. Eink itself is actually pretty slick and it can be cold and bend and quill.
[01:39:17.440 --> 01:39:23.760]   I don't know if I really want to roll up screen in my pot, like a little scroll that I open up.
[01:39:23.760 --> 01:39:28.720]   Like this. I think it was... Right. Don't write now. I have a mobile phone though. Sorry.
[01:39:28.720 --> 01:39:33.440]   I've mentioned the future. So you don't want that now, but imagine a near future in which you are
[01:39:33.440 --> 01:39:39.280]   wearing most of the devices. So you've got sort of dumb smart glasses or some glasses and earpiece.
[01:39:40.000 --> 01:39:45.920]   Right. And that is just sort of the last mile of information and the infrastructure
[01:39:45.920 --> 01:39:53.600]   supporting content. So like a pen that you would sort of... I'm sad. I bought this thing and
[01:39:53.600 --> 01:40:00.400]   everybody said it's dead on arrival and I got talked out of it. But that's okay. Mike, you want
[01:40:00.400 --> 01:40:05.760]   to weigh in at all on this? Do you... I mean, I think I agree with everything that everybody said.
[01:40:05.760 --> 01:40:13.120]   It's a neat design. I can understand the impulse buy if you have $1,400 sitting in your pocket.
[01:40:13.120 --> 01:40:21.280]   But... I make my wife buy these things. I don't know. I just... I don't know that it will get
[01:40:21.280 --> 01:40:27.120]   that much use or that the setup as neat as it looks and as wonderful as that commercial looks,
[01:40:27.120 --> 01:40:33.200]   like how useful is this and how much are you going to turn to this device over existing devices.
[01:40:33.200 --> 01:40:37.840]   And I think Amy's right that there's a lot more like really interesting stuff coming down the
[01:40:37.840 --> 01:40:43.360]   road very soon. So even if this is nice, you know, a few years from now, people are going to...
[01:40:43.360 --> 01:40:49.120]   It's the first. I understand that. And so... Yeah. It's the first. I think, you know, I was
[01:40:49.120 --> 01:40:55.760]   about to buy the new Galaxy Fold. So in that respect, I think I've saved a little bit of money and
[01:40:55.760 --> 01:41:00.960]   and brain cells. I do have an entire cabinet of devices. It seemed really cool when I bought them
[01:41:01.840 --> 01:41:08.320]   no longer any use at all. But seriously, I would love to get access to your
[01:41:08.320 --> 01:41:13.600]   cabinet devices as well. Could you buy everything in this grime? I am just...
[01:41:13.600 --> 01:41:18.720]   What you should do. I'm slowing it. Well, partly it's part of the job, right? So I can write it off.
[01:41:18.720 --> 01:41:25.280]   Mostly nowadays, I don't want to buy... Like I'm not going to buy this Samsung Note,
[01:41:25.280 --> 01:41:30.320]   the new Note 20, which they announced because it's so much like the Note 10, which I already have.
[01:41:30.320 --> 01:41:36.080]   I don't see any reason. But when I do see a new form factor or an attempt to do something
[01:41:36.080 --> 01:41:41.440]   out of the box, I kind of want to try it and get it. And I did think that folding phones
[01:41:41.440 --> 01:41:47.760]   were kind of interesting. I think there's a real problem because it's still not a glass screen.
[01:41:47.760 --> 01:41:54.640]   It's a plastic screen, ultimately. That's not a good experience. What heat would be like if you're
[01:41:54.640 --> 01:42:00.240]   using it for many, many hours in whether that's not chilly, I wonder... Well, I'll find out, won't I?
[01:42:00.240 --> 01:42:08.240]   Because it's hotter in hell right now. We are having a heatwave. Oh, tell me about it. I'm
[01:42:08.240 --> 01:42:13.520]   sizzing my back room at the moment. I've got ice packs around myself. I didn't want to say anything.
[01:42:13.520 --> 01:42:17.840]   Well, I didn't want to say anything. But your blue mustache is turning into blue lip gloss. I didn't
[01:42:17.840 --> 01:42:25.120]   want to say anything. No, I know. I should... That's a green, but no, it's just terrible. It's kind of melting
[01:42:25.120 --> 01:42:31.680]   onto your face. I wasn't going to say anything. But let's take a little break. I thought the duo
[01:42:31.680 --> 01:42:36.560]   would be interesting. We'll find out. It comes out September 10th. It is a little high priced.
[01:42:36.560 --> 01:42:40.800]   And as many people pointed out, it doesn't have any of the attributes of a phone, no NFC.
[01:42:40.800 --> 01:42:47.120]   It has not waterproof. It doesn't have wireless charging. The camera is mediocre at best.
[01:42:48.080 --> 01:42:55.120]   And it's $1,400. So I'm probably just a sucker. But I want to see news. I want to see news. Believe
[01:42:55.120 --> 01:43:00.640]   me, Amy Webb, I will be the first in line to buy augmented reality spectacles when Apple ships those.
[01:43:00.640 --> 01:43:07.440]   You know? My husband's been writing prescriptions for Amazon glasses for the Echo.
[01:43:07.440 --> 01:43:08.000]   Really?
[01:43:08.000 --> 01:43:10.320]   Echo, whatever they're called. Yeah, he's written two scripts.
[01:43:10.320 --> 01:43:10.720]   Really?
[01:43:10.720 --> 01:43:16.880]   He was... Yeah. And every time he's like, "Hey, what are you going to do with these things? What's the
[01:43:16.880 --> 01:43:18.240]   why are you getting them?"
[01:43:18.240 --> 01:43:20.800]   Yeah, these don't seem that interesting because really it's just
[01:43:20.800 --> 01:43:23.680]   Echo and glasses, right?
[01:43:23.680 --> 01:43:30.720]   They're actually... It's a brilliant, brilliant move, I think, by Amazon because there is no camera.
[01:43:30.720 --> 01:43:36.720]   The lenses are not... There's no digital layer. It just allows you to talk to Alexa. But it's a
[01:43:36.720 --> 01:43:46.000]   clever, slow on-ramp to a world in which we are wearing more technology. And especially after what
[01:43:46.000 --> 01:43:52.400]   happened with Google Glass, a pair of glasses that are somewhat impractical, but you can talk to
[01:43:52.400 --> 01:43:57.040]   but don't have any of the creepy factor that people were concerned about with Glass.
[01:43:57.040 --> 01:44:00.560]   Acclimates. It acclimates both...
[01:44:00.560 --> 01:44:05.120]   It's really... All this is is earbuds built in the glasses, though.
[01:44:05.120 --> 01:44:12.480]   Sure. But it's also then getting... So I've worn glasses since I was four. I've got no problem.
[01:44:12.480 --> 01:44:13.440]   Yeah, me too.
[01:44:13.440 --> 01:44:16.640]   More of a problem wearing contacts at this point than glasses.
[01:44:16.640 --> 01:44:22.800]   But if you're not used to wearing glasses, you're asking people to jump through some hurdles.
[01:44:22.800 --> 01:44:26.640]   So I think what Amazon is doing is actually pretty clever.
[01:44:26.640 --> 01:44:32.800]   When are we going to get the glasses that you described on that show First Man,
[01:44:32.800 --> 01:44:38.800]   which I really liked and I'm sorry that that didn't get picked up, but the idea was the first
[01:44:38.800 --> 01:44:44.160]   people going to Mars. And I know you were a consultant for it. In fact, I watched it because I knew
[01:44:44.160 --> 01:44:49.040]   you were a consultant for it. And one of the things I really loved about it was everybody in the show
[01:44:49.040 --> 01:44:54.960]   was wearing what looked like normal spectacles, but they could like you could swipe video from
[01:44:54.960 --> 01:44:59.840]   yours to another person. So people would say, "Hey, watch this." And they would swipe it over.
[01:44:59.840 --> 01:45:04.720]   They would be watching something, you know, you could see their eyes. You didn't know they
[01:45:04.720 --> 01:45:08.640]   were watching something. They kind of went, "And I thought, that's what I want. That's exactly what
[01:45:08.640 --> 01:45:14.000]   I want. I want to augment reality. When am I going to get that?" So that show is set in the year
[01:45:14.000 --> 01:45:22.080]   2031 and we worked on all of the technology that's in the show. You know, everybody, there's so
[01:45:22.080 --> 01:45:29.120]   many patents, there's so much IP, there's so much development in glasses. There's a couple of hurdles.
[01:45:29.120 --> 01:45:35.280]   One is getting enough coverage, wireless coverage to make them work because part of what makes them
[01:45:35.280 --> 01:45:42.640]   work is sort of spatial computing. Two is getting people used to the idea of wearing normal looking
[01:45:42.640 --> 01:45:51.200]   glasses. So, and I think for people who prefer contacts, it's going to be a little bit of a leap
[01:45:51.200 --> 01:45:58.160]   to get them to start wearing glasses again. And then it's getting them made. I don't think you
[01:45:58.160 --> 01:46:02.240]   can underestimate the geopolitical tensions right now between the United States and you
[01:46:02.240 --> 01:46:06.480]   find that. You brought that up before. So, nobody should announce a new product that's not built in
[01:46:06.480 --> 01:46:15.600]   the US? I know that a lot of companies are now trying to create manufacturing plants and
[01:46:15.600 --> 01:46:22.720]   factories to build components in the United States. Whether or not that scales. That's a good thing,
[01:46:22.720 --> 01:46:28.640]   if it works. It's a good thing if it doesn't have a trickle down effect of driving up the prices
[01:46:28.640 --> 01:46:34.160]   on everything. The prices go up. Subsidizes. Right. So, then we have a bigger wealth divide and
[01:46:34.160 --> 01:46:39.520]   technological divide than we have right now, which is not a good thing. But to answer your question
[01:46:39.520 --> 01:46:44.880]   about glasses, we're probably another, what is it 2020? We're probably another decade away, but
[01:46:44.880 --> 01:46:49.920]   it's not like there's going to be a switch that flips and suddenly everybody's got the glasses.
[01:46:49.920 --> 01:46:56.800]   It's a transition. So, we will start to start, you know, it's in that that transition is
[01:46:56.800 --> 01:47:01.920]   probably a little bit protracted now because of the virus. Do you think even though there's a
[01:47:01.920 --> 01:47:09.120]   potential that the administration will change in January and perhaps we'll, I don't know if we'll
[01:47:09.120 --> 01:47:14.480]   warm up to China, but maybe we'll have a more strategic relationship with China. You think there's
[01:47:14.480 --> 01:47:21.200]   still a cause for concern? So, part of the problem in the United States is that there's the old
[01:47:21.200 --> 01:47:30.480]   guard and what its posture was toward China, which was sort of frenemy, which I think in some ways
[01:47:30.480 --> 01:47:35.760]   was good, but also sort of failed to recognize China as a growing diplomatic economic and
[01:47:35.760 --> 01:47:41.280]   militaristic pacing threat. That's what Ben Thompson says too. He says, we're not acknowledging
[01:47:41.840 --> 01:47:46.480]   what China really is after. So, the problem is once you make that acknowledgement,
[01:47:46.480 --> 01:47:54.640]   there is a new set of tensions that are created and it's a little difficult to acknowledge China
[01:47:54.640 --> 01:48:00.560]   as a militaristic pacing threat, which would be a big deal in the United States. And then to say,
[01:48:00.560 --> 01:48:05.760]   we're going to just placate at this point, the sort of the script that the military runs by
[01:48:05.760 --> 01:48:13.680]   doesn't allow for that. Am I hopelessly naive to believe that the best hope for world peace is free
[01:48:13.680 --> 01:48:20.480]   trade, that a country that is a trading partner, even if we don't agree with what they're doing to
[01:48:20.480 --> 01:48:28.240]   the Weijer Muslims, which is horrific, that it's a safer world if we're economically dependent on
[01:48:28.240 --> 01:48:34.400]   each other, than if we have barriers and walls up, is that hopelessly naive? Well, I think that was
[01:48:34.400 --> 01:48:40.880]   the idea. Yeah, that's the old way. As a growing, we're going to see the largest growth of a
[01:48:40.880 --> 01:48:48.640]   of like a middle class ever than ever before seen in human history. So China's biggest problem is
[01:48:48.640 --> 01:48:55.440]   food scarcity. It's making sure all of these people are fed and that as this economic transition
[01:48:55.440 --> 01:49:02.080]   happens, that there's not a huge uprising. So, China's legitimately worried about a lot of things,
[01:49:02.640 --> 01:49:08.240]   but to answer your question, well, they had a massive famine under Mao. There was no uprising,
[01:49:08.240 --> 01:49:16.160]   tens of millions, hundreds of millions of people died due to poor planning and poor policy from
[01:49:16.160 --> 01:49:22.080]   the central government, but it didn't cause a revolution. No, but China's also positioned
[01:49:22.080 --> 01:49:26.560]   differently now. I know we're super far off topic, but China's been quietly moving into emerging
[01:49:26.560 --> 01:49:31.040]   markets. And if you're at all interested in the forefront of mobile Africa's a really good place
[01:49:31.040 --> 01:49:35.840]   to look because they've leaped frog a lot of other places in the world. So you've got all of this
[01:49:35.840 --> 01:49:40.240]   emerging critical infrastructure, all of these new markets, all of this emerging work that's
[01:49:40.240 --> 01:49:48.640]   been happening with China at the helm, with their infrastructure and their technology being used.
[01:49:48.640 --> 01:49:53.840]   And when I started talking five or six years ago about a bifurcation of our digital like a
[01:49:53.840 --> 01:49:58.320]   splinter net, right, a bifurcation of how our digital systems work, everybody was like, well,
[01:49:58.320 --> 01:50:01.920]   who cares? It's just China is just Africa. And now here we are in the air.
[01:50:01.920 --> 01:50:10.640]   Yeah, we got to care. And so if there's a transition, I think what we have is probably a smarter,
[01:50:10.640 --> 01:50:17.600]   quieter approach and hopefully a lot less grandstanding and taunting in a public space,
[01:50:17.600 --> 01:50:23.120]   which is not that's I mean, look, that's clearly unproductive. And you're right, if we thought
[01:50:23.120 --> 01:50:27.680]   this is going to go on for another four years, I would probably want to build a factory in the US
[01:50:27.680 --> 01:50:34.320]   to I understand that. Yeah, but like this is all kind of important because as everybody starts
[01:50:34.320 --> 01:50:38.960]   suddenly now waking up to the idea that there's a company called Tencent, which is
[01:50:38.960 --> 01:50:45.280]   hold that hold that thought. I do want to talk about TikTok and Tencent. There's a new plan with
[01:50:45.280 --> 01:50:50.000]   TikTok, by the way, because it's a new week, new week, new plan. But we'll talk about that. And I
[01:50:50.000 --> 01:50:55.120]   do want to talk about Tencent and what is going on. And then I will mention this because I know
[01:50:55.120 --> 01:50:58.960]   Mike Masnick, you're very interested in what's happening to the Postal Service this week. They're
[01:50:58.960 --> 01:51:05.520]   taking out millions of dollars with the equipment. It's just announced that the house is going to
[01:51:05.520 --> 01:51:11.360]   return to do something about that they're going to cut their summer recess short to consider
[01:51:11.360 --> 01:51:15.280]   legislation to protect the Postal Service. And I know that was something you were interested in
[01:51:15.280 --> 01:51:19.840]   Mike. So I just mentioned that that just broke came across the wire. But let's take a little
[01:51:19.840 --> 01:51:26.560]   break. Got to do it. I'm sorry because I want to talk about the fine people who built this studio,
[01:51:26.560 --> 01:51:32.320]   the LastPass studio. We're here. Thanks to LastPass. They're keeping the lights on. And frankly,
[01:51:32.320 --> 01:51:39.760]   they're keeping our software, our passwords, our users secure. Thank you, LastPass. But now with
[01:51:39.760 --> 01:51:46.400]   this work from home thing, you know, this is our IT already had a big challenge. Now, you got a
[01:51:46.400 --> 01:51:51.600]   remote workforce. LastPass surveyed global IT decision makers, almost all of them. 96% of them
[01:51:51.600 --> 01:51:57.280]   said, yeah, the remote workforce changes everything when it comes to identity and access management.
[01:51:57.280 --> 01:52:02.720]   How can you manage identities, promote goods, security behaviors when your employees are at
[01:52:02.720 --> 01:52:09.760]   home in their gym jams? You can with LastPass. LastPass. Oh, I'm so glad. I'm so relieved.
[01:52:09.760 --> 01:52:16.000]   I've been using LastPass personally for 12 years, but we started using LastPass Enterprise
[01:52:16.000 --> 01:52:21.120]   about five or six years ago. And thank goodness, because with LastPass, our employees can go home,
[01:52:21.120 --> 01:52:25.360]   but we still have the security. They've got the keys to the camera. They've taken them home.
[01:52:25.360 --> 01:52:30.640]   The keys to our bank accounts, our websites, our databases, our quick books, everything.
[01:52:30.640 --> 01:52:37.200]   But we still, we don't give up centralized control. We don't give up an IT dashboard.
[01:52:37.200 --> 01:52:43.440]   Let's just know exactly who's using what, when, and where. And that's so important to securing
[01:52:43.440 --> 01:52:48.000]   our stuff and your stuff, right? Of course, it starts with the password vault. Every employee
[01:52:48.000 --> 01:52:52.000]   gets their own vault for storing every app and web log in. They use, they love this, by the way,
[01:52:52.000 --> 01:52:56.880]   because it's automatic. The first thing I install when I get a new phone, when I get this new duo,
[01:52:56.880 --> 01:53:01.760]   put LastPass on there. And when I add other apps, log into websites, LastPass fills it in. It's
[01:53:01.760 --> 01:53:07.600]   so much easier, so much easier. It's also important because it makes password sharing easier. It's one
[01:53:07.600 --> 01:53:11.920]   thing when you're all in the office together, but password share, you don't want them sending texts
[01:53:11.920 --> 01:53:17.600]   with the log into your bank account. LastPass does it securely right in LastPass,
[01:53:17.600 --> 01:53:24.320]   so your corporate data is safe. You get enforceable policies. We always, for instance, insist that
[01:53:24.320 --> 01:53:29.040]   people use two factor with LastPass. We could turn that on. We have minimum password requirements.
[01:53:29.040 --> 01:53:35.680]   You also get easy user management. We can add and remove users automatically. You can even do it
[01:53:35.680 --> 01:53:39.360]   with the directory integration. So if you're already using LDAP or something like that,
[01:53:39.360 --> 01:53:46.480]   it could just automatically happen. I think LastPass is critical to managing a business that's
[01:53:46.480 --> 01:53:52.480]   distributed. And now all businesses are. When user entities are centrally and securely managed,
[01:53:52.480 --> 01:53:56.720]   a business can ensure the correct employees doing the right thing and has the right access.
[01:53:56.720 --> 01:54:02.720]   That's why you need LastPass. They love it. They'll work more efficiently. When they can access the
[01:54:02.720 --> 01:54:07.840]   data and resources they need easily, you'll love it because LastPass's IAM solutions help
[01:54:07.840 --> 01:54:13.200]   businesses improve the employee experience and safeguard from cyber threats. Let your remote
[01:54:13.200 --> 01:54:19.120]   workforce focus on the work they need to do without compromising your security. Secure your
[01:54:19.120 --> 01:54:29.760]   remote workforce with LastPass, LastPass.com/twit to learn more, LastPass.com/twit to learn more.
[01:54:29.760 --> 01:54:37.600]   So TikTok, the latest is, does this supersede the previous? I'm very confused. There's a new
[01:54:37.600 --> 01:54:44.720]   executive order ordering ByteDance to divest from its US TikTok business within 90 days.
[01:54:44.720 --> 01:54:50.880]   Effectively, I think that extends the deadline from September to 90 days from now, right?
[01:54:50.880 --> 01:54:55.440]   Right. That changes at 45 days. I don't know what preceded it.
[01:54:55.440 --> 01:55:02.880]   The idea was, well, Microsoft will buy it. And then if they don't, then at September 20, it's all over.
[01:55:03.520 --> 01:55:09.600]   That's, I guess, superseded. I don't know. By the order, the new order ByteDance is ordered to
[01:55:09.600 --> 01:55:17.360]   destroy all its copies of data attached to US users and inform CFIUS, the Committee on Foreign
[01:55:17.360 --> 01:55:21.680]   Investment in the United States, when it has done so. Great. Good luck enforcing that.
[01:55:21.680 --> 01:55:24.960]   No, we didn't. It's all gone. It's still needed.
[01:55:24.960 --> 01:55:31.760]   This is just insane. When you look at the amount of data that Google or Facebook apps take,
[01:55:31.760 --> 01:55:39.360]   it's no different from TikTok. I mean, basically Trump has got a piece of ginger up his backside
[01:55:39.360 --> 01:55:43.920]   over the fact that TikTok is full. No, wait a minute. He says, there is, I'm not going to do
[01:55:43.920 --> 01:55:51.600]   the imitation. I can't. There is credible evidence. There is credible evidence that
[01:55:51.600 --> 01:55:56.960]   leads me to believe that ByteDance, get this, quote, "might take action that threatens to
[01:55:56.960 --> 01:56:02.720]   impair the national security of the United States." All right. This is defunding the United States
[01:56:02.720 --> 01:56:08.320]   Postal Service. Yeah, but what could TikTok do to impair our national security? It could stop
[01:56:08.320 --> 01:56:13.040]   kids from dancing. All right. No, wait a minute. Amy says a lot. What could they do?
[01:56:13.040 --> 01:56:19.760]   So, TikTok is... They could throw the election at Joe Biden.
[01:56:19.760 --> 01:56:26.080]   This is not... I would be more worried about the Russians than the Chinese with the upcoming
[01:56:26.080 --> 01:56:31.280]   election. This is a company that has a highly sophisticated approach to...
[01:56:31.280 --> 01:56:40.080]   TikTok is an AI company. It's not a social media network. And again, we sort of failed to
[01:56:40.080 --> 01:56:45.440]   recognize what was happening, the kind of cute memes and the funny dancing videos obscures what's
[01:56:45.440 --> 01:56:51.440]   actually going on behind the scenes. And again, I think if it was a different administration
[01:56:51.440 --> 01:56:56.800]   and the language was a little different, we would be probably paying attention in a different way.
[01:56:56.800 --> 01:57:03.360]   If this was an Obama administration saying... I'd still be mad. I think TikTok is amazing.
[01:57:03.360 --> 01:57:08.640]   So, what is TikTok? That's exactly the point, Leo. TikTok is amazing. It's easy to use.
[01:57:08.640 --> 01:57:14.080]   Grandparents can use it. Instagram is complicated. Snap is very complicated. So,
[01:57:14.080 --> 01:57:20.240]   this is a well-designed... Instagram made a competitor that's unusable. Reels. TikTok is easy.
[01:57:20.240 --> 01:57:23.360]   Anybody can do it. It's fun. And I love watching the videos.
[01:57:23.360 --> 01:57:28.960]   That's right. This is... ByteDance is a Chinese company. And again, this is not about
[01:57:28.960 --> 01:57:35.360]   Sino-mongering or fear-mongering or anything like that. This is specific to this company,
[01:57:35.360 --> 01:57:40.640]   but ByteDance is a company that has helped roll out the Chinese social credits core and a lot of
[01:57:40.640 --> 01:57:49.200]   different parts of the country. And again, if we're talking about algorithmic determinism and
[01:57:49.200 --> 01:57:56.000]   automatic scoring, we have a close friend, who I see almost every week, who is Chinese, who uses
[01:57:56.000 --> 01:58:02.240]   WeChat and the enormous number of... Also to be... Also to be... The social media that you've never
[01:58:02.240 --> 01:58:06.000]   heard of before because you can't get access to it without a Chinese phone number. But
[01:58:06.000 --> 01:58:16.560]   two videos, there's a video of her with two teenagers jumping into a pool. One of the teenagers is a
[01:58:16.560 --> 01:58:24.000]   boy. There's nothing interesting at all. Three people, the video lasted like seven seconds.
[01:58:24.000 --> 01:58:31.280]   Three people, it's a teenage girl, full bathing suit, so nothing salacious. Her and a boy,
[01:58:31.280 --> 01:58:38.640]   he jumps in. Her entire account got locked. And the reason was because he was in the shot without
[01:58:38.640 --> 01:58:44.880]   a shirt on. How else do you go swimming in the United States? But that got locked down.
[01:58:44.880 --> 01:58:50.400]   It was another time that she had a different account and the Chinese national anthem was playing
[01:58:50.400 --> 01:58:55.200]   kind of by accident in the background. And again, she got permanently banned.
[01:58:55.200 --> 01:58:59.760]   But how does that impact our national security? I mean, it's bad for teenage boys without shirts.
[01:58:59.760 --> 01:59:06.960]   So because it's not like they have an army of 15,000 people sort of watching all of these videos.
[01:59:06.960 --> 01:59:07.920]   That's automated, right? Yeah.
[01:59:07.920 --> 01:59:13.600]   They have a very... So, you know, again, I wonder the Google problems that Mike was describing
[01:59:14.480 --> 01:59:23.760]   if Baidu has similar janky issues. My assumption is probably not for many different reasons.
[01:59:23.760 --> 01:59:28.800]   But the point is if the data are domiciled in China, which they are, then they are subject
[01:59:28.800 --> 01:59:36.160]   to the CCP. And at any time, the CCP can say, we'd like to pull files on every single person
[01:59:36.160 --> 01:59:42.160]   who meets these criteria, every single gay person, every single person who has ever posted a video
[01:59:42.160 --> 01:59:45.840]   about, you know, whatever. And you know the information.
[01:59:45.840 --> 01:59:51.760]   Yeah. I mean, sure, the US under the Patriot Act can do exactly the same thing
[01:59:51.760 --> 01:59:55.920]   if they claim national security grounds, not on social, but they can...
[01:59:55.920 --> 02:00:00.400]   So they can go to Facebook and say, hey, Facebook, I want it all. They could do that. Of course they could.
[02:00:00.400 --> 02:00:04.560]   Yeah. They don't even need to go to Facebook, right? There are all these different data
[02:00:04.560 --> 02:00:09.440]   companies that have all those data collected. And it's easy to buy it. Anyone can go buy it.
[02:00:09.440 --> 02:00:14.880]   The US government buys stuff from those companies all the time. So I'm still trying to figure out
[02:00:14.880 --> 02:00:20.080]   how Baiduance is somehow different, other than the fact that it's based in China. Why is this such a
[02:00:20.080 --> 02:00:23.360]   big concern as compared to all of the data that's out there from other...
[02:00:23.360 --> 02:00:29.200]   One thing I've heard that makes a little sense is that algorithmically, they could... I mean,
[02:00:29.200 --> 02:00:36.560]   look, what's going on on Facebook? QAnon wouldn't really exist except Facebook has in effect,
[02:00:36.560 --> 02:00:40.800]   not intentionally, but in effect promoted it. Baiduance could, in theory, use the same
[02:00:40.800 --> 02:00:45.120]   techniques to promote something that was in the Chinese government interest.
[02:00:45.120 --> 02:00:51.840]   Somehow, it could be as a propaganda engine, I guess. But is that what you're talking about,
[02:00:51.840 --> 02:00:57.440]   Amy? Or is there something more nefarious going? I don't know the playbook yet. But
[02:00:58.240 --> 02:01:07.600]   there is a huge difference between a company that has data. I mean, it is difficult to describe
[02:01:07.600 --> 02:01:13.440]   how fast and large... How fast this company has grown. They're the number one social...
[02:01:13.440 --> 02:01:18.960]   They are far more popular than... Can't you say the same things about Facebook?
[02:01:22.160 --> 02:01:28.800]   Sure. I guess the difference is if China came in and either secretly or overtly tried to buy
[02:01:28.800 --> 02:01:34.080]   access to Facebook data, either directly or through a third party, there are channels
[02:01:34.080 --> 02:01:40.240]   to do something about that. There are not existing channels beyond CFIUS. I don't know that the
[02:01:40.240 --> 02:01:45.760]   Patriot Act applies. I mean, I don't know. We're sort of in unchartered territory. And what the end
[02:01:45.760 --> 02:01:51.600]   uses for these data are, I don't know right now. But I don't know what Mark Zuckerberg's doing with
[02:01:51.600 --> 02:01:58.640]   all the data he's got. But I do know that I personally blame him and Facebook for some of the problems
[02:01:58.640 --> 02:02:06.640]   we face in this country right now. Should we ban Mark Zuckerberg? Facebook has a lot of problems,
[02:02:06.640 --> 02:02:17.040]   too. Yeah. This is a very... This headline from 1-0 on Medium is very provocative.
[02:02:17.040 --> 02:02:23.920]   "Jumana Abu Ghazela. An unelected monarch is shaping our public life. His name is Mark Zuckerberg.
[02:02:23.920 --> 02:02:30.080]   The most important election this year has only one voter. And then that picture of Mark with...
[02:02:30.080 --> 02:02:35.680]   I mean, they've already admitted they are saying, "We're not going to censor the...
[02:02:35.680 --> 02:02:40.960]   Is it diamond and silk people?" Because that would cause too much of a PR problem.
[02:02:40.960 --> 02:02:46.000]   Never the fact that they're putting out complete falsehoods, but we're not going to censor it because
[02:02:46.000 --> 02:02:50.960]   it's a PR problem. It does seem like Facebook is becoming like Fox book at the moment.
[02:02:50.960 --> 02:02:57.600]   That's not even that. I'm not even worried about slant or bias. I think it's a weapon.
[02:02:57.600 --> 02:03:03.200]   And I think that people who know how to use it, I think QAnon is a very good example.
[02:03:03.200 --> 02:03:10.080]   I think they've used Facebook particularly, other media as well, but Facebook particularly
[02:03:11.120 --> 02:03:17.760]   to spread a gospel that is very dangerous. And we've looked. The United States has been
[02:03:17.760 --> 02:03:23.120]   rife with conspiracy theories since 1776. I blame King George for that.
[02:03:23.120 --> 02:03:27.520]   Well, obviously you would have been better off if the British were naked.
[02:03:27.520 --> 02:03:32.560]   I mean, you've been doing that many properly. You could have umpires.
[02:03:32.560 --> 02:03:38.560]   You even stock color? I'm reading a wonderful book by Eric Leisen called
[02:03:38.560 --> 02:03:44.000]   "The Splendid and the Vile About the Battle of Britain." And one of the problems that they had
[02:03:44.000 --> 02:03:50.560]   in Britain was the rapid dissemination of false rumors that things like, "Oh yeah, don't go in
[02:03:50.560 --> 02:03:54.000]   the bomb shelters because once they get bombed and everybody dies, they just brick it up and it's
[02:03:54.000 --> 02:04:02.560]   a giant katovk." Or the Germans have built a bomb, a devastating giant bomb they're going to drop
[02:04:02.560 --> 02:04:07.040]   tonight. And these things were right. But what they didn't have is Facebook.
[02:04:07.040 --> 02:04:08.880]   Well, I mean, okay.
[02:04:08.880 --> 02:04:13.920]   This had to go over the fence, but one neighbor telling another, imagine if they'd had Facebook.
[02:04:13.920 --> 02:04:18.720]   My grandfather was a postmaster in the Second World War.
[02:04:18.720 --> 02:04:21.440]   How did he feel about sorting machines?
[02:04:21.440 --> 02:04:23.440]   I'm sorry, go ahead.
[02:04:23.440 --> 02:04:32.160]   Wow, don't get me started on that. But I mean, in 1940, he told the tales of my mum and the
[02:04:32.160 --> 02:04:38.160]   rest of the family. A very well dressed woman came in and said, "I need to send a telegram to
[02:04:38.160 --> 02:04:44.880]   my husband down in Kent saying to get the family treasures buried because the Germans have invaded.
[02:04:44.880 --> 02:04:51.360]   They're already in Kent. They're already in Dover and you need to get stuff out."
[02:04:51.360 --> 02:04:55.680]   And he was in a panic for 12 hours because that was believed it.
[02:04:55.680 --> 02:04:56.640]   People knew. Yeah.
[02:04:57.440 --> 02:05:01.360]   And Facebook is doing, you know, this is the same problem over again.
[02:05:01.360 --> 02:05:02.400]   They're getting at scale.
[02:05:02.400 --> 02:05:07.040]   So, can I offer another?
[02:05:07.040 --> 02:05:07.840]   Please.
[02:05:07.840 --> 02:05:13.680]   Okay. So where are people making their TikTok videos? For the most part, they are making them
[02:05:13.680 --> 02:05:18.720]   in their homes, right? So you've got a company that has best in class computer vision software.
[02:05:18.720 --> 02:05:24.640]   Again, think of TikTok not as a social media company, but as an AI powerhouse.
[02:05:25.200 --> 02:05:31.760]   You've got hundreds of millions of people constantly showing their spaces.
[02:05:31.760 --> 02:05:38.800]   And let's say that China is plotting out war 10 years from now in economic terms.
[02:05:38.800 --> 02:05:45.200]   And in the process, they are learning about how and what types of devices we have and where we
[02:05:45.200 --> 02:05:50.400]   tend to spend our time. You know, China could cripple the United States economy by...
[02:05:50.400 --> 02:05:54.960]   They don't need TikTok to do that. They make everything that they see on the vision.
[02:05:54.960 --> 02:05:57.600]   I don't try to say it.
[02:05:57.600 --> 02:05:58.400]   They already know.
[02:05:58.400 --> 02:06:02.000]   The problem is that we're trying to use past wars.
[02:06:02.000 --> 02:06:06.480]   All they have to say is let's shut down Shenzhen and see how the Americans like it.
[02:06:06.480 --> 02:06:15.200]   It's... I would urge us to not use previous wars or previous experiences.
[02:06:15.200 --> 02:06:18.800]   We think about how things evolve from here.
[02:06:18.800 --> 02:06:24.560]   Now, did the Trump administration botch this whole communication and what they're doing?
[02:06:24.560 --> 02:06:30.960]   Of course they did. It doesn't mean that there's not some validity in thinking through what data
[02:06:30.960 --> 02:06:36.640]   are being scraped. Either implicitly on the back end or what's being shown.
[02:06:36.640 --> 02:06:37.680]   No, I got it.
[02:06:37.680 --> 02:06:38.160]   I got it.
[02:06:38.160 --> 02:06:42.800]   Yeah. So what are they going to do? So it's not... It's obviously not a shooting war.
[02:06:42.800 --> 02:06:48.240]   But what is the kind of economic warfare that China would engage in? What would their goal be?
[02:06:48.240 --> 02:06:52.080]   This is one of the reasons I think I still believe that if we're trading partners,
[02:06:52.080 --> 02:06:57.520]   if they buy our soybeans and we buy our... They make our phones,
[02:06:57.520 --> 02:07:00.240]   they're less likely to want to take us out.
[02:07:00.240 --> 02:07:04.240]   But what would taking us out mean? Would it be economic destroying us economically?
[02:07:04.240 --> 02:07:05.760]   There's no... Why did they do that?
[02:07:05.760 --> 02:07:10.000]   Because part of this has to do with pride. The United States,
[02:07:10.000 --> 02:07:13.120]   you know, having moved outside of the United States for a long time,
[02:07:13.120 --> 02:07:17.840]   you know, a lot of people don't like us. We're kind of shitty to a lot of people in a lot of...
[02:07:17.840 --> 02:07:22.960]   Well, you could ask the same thing. Why would... What is Putin care what happens in the US?
[02:07:22.960 --> 02:07:23.760]   Same thing, right?
[02:07:23.760 --> 02:07:26.000]   So part of this is pride.
[02:07:26.000 --> 02:07:34.720]   Okay, sorry. Seriously, go to China and look at the museums there.
[02:07:34.720 --> 02:07:44.720]   If you go to any Chinese history museum, they will record how the US, UK, Germany, France,
[02:07:44.720 --> 02:07:50.800]   took over a section of their country. What they essentially did was take over Manhattan and say,
[02:07:50.800 --> 02:07:55.360]   "Our rules apply here. We're going to fight wars and sell drugs to your people."
[02:07:55.360 --> 02:07:56.560]   The Boxer Rebellion.
[02:07:56.560 --> 02:07:57.280]   Absolutely.
[02:07:57.280 --> 02:07:58.000]   Understand that.
[02:07:58.000 --> 02:07:58.160]   Yeah.
[02:07:58.160 --> 02:07:59.280]   So they...
[02:07:59.280 --> 02:08:00.240]   But that's history.
[02:08:00.240 --> 02:08:00.960]   Absolutely not.
[02:08:00.960 --> 02:08:01.680]   No.
[02:08:01.680 --> 02:08:05.280]   Are you saying that out of spite they're just going to say, "Oh, we don't...
[02:08:05.280 --> 02:08:09.040]   Let's just... What would they do? They pulled the plug on America?"
[02:08:09.040 --> 02:08:12.160]   It's not out of spite. It's about retribution.
[02:08:12.720 --> 02:08:17.760]   You know, it's basically, you did this to us. How on earth are you going to turn around and say,
[02:08:17.760 --> 02:08:20.320]   "This is bad if we do it to you?"
[02:08:20.320 --> 02:08:22.240]   No, I agree.
[02:08:22.240 --> 02:08:23.920]   But what do they want to do?
[02:08:23.920 --> 02:08:25.280]   So...
[02:08:25.280 --> 02:08:30.320]   Well, the economic argument that I hear made a lot is China doesn't work without the United States.
[02:08:30.320 --> 02:08:36.880]   That's true today. But China... I mean, what happens when you've aligned every emerging economy
[02:08:36.880 --> 02:08:41.600]   on your side, right? Suddenly, you've got a compounding effect.
[02:08:42.240 --> 02:08:48.000]   And you don't need to rely on us as much. And there are plenty of arguments to be made
[02:08:48.000 --> 02:08:53.840]   that would say, "What would a future look like in which the United States is still very strong?
[02:08:53.840 --> 02:08:59.680]   We still have a very good economy, but is beholden to China in much more profound ways than we are
[02:08:59.680 --> 02:09:00.400]   right now."
[02:09:00.400 --> 02:09:06.160]   More than the fact that Tencent owns a minority stake in virtually every company in the...
[02:09:06.160 --> 02:09:09.200]   So, again, how did we get to that place?
[02:09:09.200 --> 02:09:15.280]   Because a year and a half ago, I was meeting with Chinese... I'm sorry, a year and a half ago,
[02:09:15.280 --> 02:09:22.800]   I was in Los Angeles meeting with Japanese government officials and some CEOs of companies
[02:09:22.800 --> 02:09:27.760]   that you know, trying to explain to them why they needed to pay attention to TikTok and why
[02:09:27.760 --> 02:09:31.440]   it's dangerous for China to be caught in a proxy battle between the United States.
[02:09:31.440 --> 02:09:35.280]   They were unaware of what Tencent was, let alone...
[02:09:35.280 --> 02:09:36.720]   Right, as was I.
[02:09:36.720 --> 02:09:40.960]   So, should we ban... So, let's say, I mean, I don't want to get...
[02:09:40.960 --> 02:09:46.560]   Forget the politics of it. Should we ban TikTok? Would that be a good idea?
[02:09:46.560 --> 02:09:53.440]   I don't know that that's feasible. I can tell you that I don't have TikTok on a device and my...
[02:09:53.440 --> 02:10:01.120]   Nobody that I know has TikTok on a device. I enjoy the videos. I watch them using third-party
[02:10:01.120 --> 02:10:05.520]   systems, but there is no way I would install that on anything that I am.
[02:10:05.520 --> 02:10:10.800]   Is it a risk to creators on TikTok only or by what... I never create anything on TikTok,
[02:10:10.800 --> 02:10:12.000]   but I like to look at it.
[02:10:12.000 --> 02:10:18.400]   Do we need the Papa John's founder, who's a total tool in his TikToks?
[02:10:18.400 --> 02:10:19.920]   Well, I don't look at his TikToks.
[02:10:19.920 --> 02:10:21.120]   Hashtag Better Lives.
[02:10:21.120 --> 02:10:21.600]   No.
[02:10:21.600 --> 02:10:22.960]   I don't look at his TikToks.
[02:10:22.960 --> 02:10:30.320]   The thing that gets me about all of this is just the idea that focusing so much on TikTok,
[02:10:30.320 --> 02:10:37.520]   because there's so much already involved in between China and the US,
[02:10:37.520 --> 02:10:45.120]   where when we focus specifically on TikTok and say, they have to divest or they'll be blocked
[02:10:45.120 --> 02:10:51.840]   in the US, that can lead to retaliation by China already. They have lots of other ways that
[02:10:51.840 --> 02:10:57.520]   they can retaliate. I think the focus on TikTok is so misguided as opposed to figuring out a
[02:10:57.520 --> 02:11:03.520]   broader strategy. I agree that there are concerns about China and how it is integrated into the
[02:11:03.520 --> 02:11:09.680]   US economy, but I think focusing so much on TikTok is going to backfire in a really big way.
[02:11:09.680 --> 02:11:15.040]   By the way, that's why we're all wearing weird wigs. It's to distract the Chinese,
[02:11:15.040 --> 02:11:18.000]   and they're going to watch this and say, "Well, don't worry about that. They're nuts."
[02:11:18.000 --> 02:11:22.000]   Oh, I was going to say, I thought you were talking about distracting the facial recognition
[02:11:22.000 --> 02:11:22.480]   algorithms.
[02:11:22.480 --> 02:11:23.040]   Yeah, that too.
[02:11:23.040 --> 02:11:28.720]   I thought that right now, it wouldn't go. Alibaba has a really good system where even if you've got
[02:11:28.720 --> 02:11:30.960]   a sense time and MedV, even if you've got--
[02:11:30.960 --> 02:11:32.240]   Is it working with masks?
[02:11:32.240 --> 02:11:39.040]   It works with a full mask. You could be recognized by, I don't need your face to recognize it.
[02:11:39.040 --> 02:11:42.880]   If I've got a date and posture and voice work--
[02:11:42.880 --> 02:11:43.440]   I should.
[02:11:43.440 --> 02:11:44.960]   --and yeah.
[02:11:44.960 --> 02:11:49.840]   So this is a sensible thing, and the sensible thing would be to put the word out,
[02:11:49.840 --> 02:11:54.960]   get rid of TikTok on your phone. And if you're a TikTok creator, where should they go? What do they do?
[02:11:54.960 --> 02:12:01.120]   Well, this is the challenge. I think the reason that TikTok took off the way it was was in
[02:12:01.120 --> 02:12:06.880]   in opposition to the vitriol on Twitter and Facebook.
[02:12:06.880 --> 02:12:07.440]   Right.
[02:12:07.440 --> 02:12:12.400]   And Snapchat somehow got somewhat uncool. I don't know if it's Snapchat.
[02:12:12.400 --> 02:12:13.840]   TikTok's my happy place.
[02:12:13.840 --> 02:12:15.200]   I just--
[02:12:15.200 --> 02:12:16.800]   So I think that tells us something, right?
[02:12:17.840 --> 02:12:20.880]   The problem is, it's not-- you can't just stand up another network.
[02:12:20.880 --> 02:12:24.080]   What TikTok and ByteDancer are--
[02:12:24.080 --> 02:12:33.200]   they are building unbelievable recognition and automation systems.
[02:12:33.200 --> 02:12:35.600]   And that's what is impressive.
[02:12:35.600 --> 02:12:39.120]   Mike wrote-- actually, it wasn't Mike, it was Carl on a tech chair at a really good
[02:12:39.120 --> 02:12:43.760]   point, but makes your point, Mike. The idea that banning TikTok towards Chinese intelligence
[02:12:43.760 --> 02:12:49.200]   in any way is ridiculous. They've already got hooks into us in a million ways, right?
[02:12:49.200 --> 02:12:50.320]   Yeah.
[02:12:50.320 --> 02:12:54.240]   Well, hang on. I mean, they took the OPM's databases.
[02:12:54.240 --> 02:12:58.240]   They have the security clearances of all the people who agree.
[02:12:58.240 --> 02:13:01.280]   You know, the idea that TikTok is in some way a threat?
[02:13:01.280 --> 02:13:07.280]   Well, you're also assuming that it's just sort of top level people with security clearances.
[02:13:07.280 --> 02:13:12.560]   What happens if you've got the vast majority of people between the ages of
[02:13:13.440 --> 02:13:16.080]   six and 26 today?
[02:13:16.080 --> 02:13:19.520]   What happens 10 years from now?
[02:13:19.520 --> 02:13:20.080]   Again, I think--
[02:13:20.080 --> 02:13:24.880]   But you're not lying that the Chinese government is going to march in the United States and round up
[02:13:24.880 --> 02:13:26.400]   every gay person.
[02:13:26.400 --> 02:13:29.280]   Yeah, I'm not suggesting that.
[02:13:29.280 --> 02:13:31.520]   I wouldn't put it past them, to be honest, but--
[02:13:31.520 --> 02:13:31.920]   Really?
[02:13:31.920 --> 02:13:35.920]   Because that'd be worried if that's the future you're talking about.
[02:13:35.920 --> 02:13:37.360]   Well, honestly--
[02:13:37.360 --> 02:13:38.960]   What if you turn that back on?
[02:13:38.960 --> 02:13:39.520]   Sorry, Amy.
[02:13:39.520 --> 02:13:40.880]   Sorry, you go in.
[02:13:41.760 --> 02:13:42.880]   OK, I mean, I'm sorry.
[02:13:42.880 --> 02:13:45.280]   This is the future we're looking at at the moment.
[02:13:45.280 --> 02:13:50.400]   We have the ability, if you ignore ethics and the rest of it,
[02:13:50.400 --> 02:13:52.560]   to actually, yeah, find every gay person.
[02:13:52.560 --> 02:13:54.880]   Find every-- every out gay person.
[02:13:54.880 --> 02:13:59.120]   Find everyone with uncomfortable political beliefs.
[02:13:59.120 --> 02:14:01.200]   We can do this right now.
[02:14:01.200 --> 02:14:04.560]   It's a question to the society as whether or not we allow that to happen.
[02:14:04.560 --> 02:14:09.200]   And I'm not trusting the Chinese government to not allow that to happen.
[02:14:09.200 --> 02:14:13.280]   And honestly, not really trusting the US or UK governments to do the same either.
[02:14:13.280 --> 02:14:16.880]   Mike, one last thought before I move on.
[02:14:16.880 --> 02:14:22.080]   I mean, I think that there are real concerns about China.
[02:14:22.080 --> 02:14:24.640]   I think focusing it all on TikTok is a mistake.
[02:14:24.640 --> 02:14:24.960]   I agree.
[02:14:24.960 --> 02:14:26.000]   And I think it's a distraction.
[02:14:26.000 --> 02:14:31.040]   And I think that by focusing it on TikTok, we actually give the Chinese an excuse to do
[02:14:31.040 --> 02:14:32.000]   something back.
[02:14:32.000 --> 02:14:33.840]   And I just think it's the wrong approach.
[02:14:33.840 --> 02:14:34.960]   What would you recommend?
[02:14:34.960 --> 02:14:37.360]   Let's all acknowledge Amy's point.
[02:14:38.080 --> 02:14:40.800]   So what do we do?
[02:14:40.800 --> 02:14:43.600]   Do we move every factory back in the United States?
[02:14:43.600 --> 02:14:45.520]   Is that even feasible?
[02:14:45.520 --> 02:14:48.960]   And I think that is also the reverse solution.
[02:14:48.960 --> 02:14:55.520]   I mean, I think that your initial instincts were kind of where I land as well,
[02:14:55.520 --> 02:15:00.160]   which is that the more that we can make sure that China is also reliant on the US,
[02:15:00.160 --> 02:15:05.200]   that we're both reliant on each other, that then we have power and influence over them,
[02:15:06.640 --> 02:15:11.760]   that we prevent those the dystopian situations that we're talking about.
[02:15:11.760 --> 02:15:13.120]   Are there risks there?
[02:15:13.120 --> 02:15:14.160]   Yeah, absolutely.
[02:15:14.160 --> 02:15:20.160]   But I think that the answer can't be to close off and trying to shut them off and sort of
[02:15:20.160 --> 02:15:23.520]   separate out the world and fragment everything.
[02:15:23.520 --> 02:15:26.080]   I don't think that's a real solution either.
[02:15:26.640 --> 02:15:33.280]   Amy, are you a kind of a Kissingerian real politic advocate here?
[02:15:33.280 --> 02:15:40.080]   What kind of policy going forward if you could be in charge?
[02:15:40.080 --> 02:15:41.120]   Would you recommend?
[02:15:41.120 --> 02:15:43.760]   I have a degree in game theory.
[02:15:43.760 --> 02:15:45.920]   Good.
[02:15:45.920 --> 02:15:46.960]   That's very useful.
[02:15:46.960 --> 02:15:55.440]   So I tend to fall back on the belief that the best way forward is one in which
[02:15:56.320 --> 02:16:01.680]   we can't win unless China also wins.
[02:16:01.680 --> 02:16:02.240]   Right.
[02:16:02.240 --> 02:16:02.240]   Right.
[02:16:02.240 --> 02:16:07.920]   So we need to create a situation in which we both lose together, we both win together.
[02:16:07.920 --> 02:16:11.440]   That is much easier said than done.
[02:16:11.440 --> 02:16:14.000]   We need to set up a prisoner's dilemma in effect.
[02:16:14.000 --> 02:16:15.840]   An artificial one.
[02:16:15.840 --> 02:16:20.320]   But it needs to be economic in scope.
[02:16:20.880 --> 02:16:28.000]   And the challenge is that the longer that we wait to develop something like that,
[02:16:28.000 --> 02:16:29.280]   the harder it's going to be.
[02:16:29.280 --> 02:16:36.480]   And China has been in the process of making new alliances around the world at the same time
[02:16:36.480 --> 02:16:40.880]   that we are angering our alliances around the world.
[02:16:40.880 --> 02:16:43.600]   So I think there's a way forward, but it has to be much more,
[02:16:43.600 --> 02:16:45.120]   Mike is right.
[02:16:45.120 --> 02:16:46.800]   This is not just about TikTok.
[02:16:47.680 --> 02:16:51.200]   And we shouldn't die on the mountain that is TikTok.
[02:16:51.200 --> 02:16:53.600]   But Tencent is an issue.
[02:16:53.600 --> 02:16:54.560]   Alibaba is an issue.
[02:16:54.560 --> 02:16:55.520]   Baidu is an issue.
[02:16:55.520 --> 02:16:59.440]   Meg V is an issue that sense time is an issue.
[02:16:59.440 --> 02:17:00.400]   We have a lot of issues.
[02:17:00.400 --> 02:17:05.360]   Microsoft buying TikToks American assets would have no benefit
[02:17:05.360 --> 02:17:08.320]   to anybody, including Microsoft, I think.
[02:17:08.320 --> 02:17:09.680]   Well, I don't know.
[02:17:09.680 --> 02:17:10.160]   I don't know.
[02:17:10.160 --> 02:17:14.400]   It would have a significant benefit to the Trump government the way he sells it.
[02:17:14.400 --> 02:17:14.960]   He's going to get it.
[02:17:14.960 --> 02:17:16.720]   Because he wants a large cut.
[02:17:16.720 --> 02:17:19.440]   When did this happen?
[02:17:19.440 --> 02:17:20.320]   Seriously.
[02:17:20.320 --> 02:17:23.440]   When did the American government say we will own a good thing?
[02:17:23.440 --> 02:17:25.840]   It doesn't go into Mr. Trump's pocket.
[02:17:25.840 --> 02:17:26.960]   It goes to the Treasury.
[02:17:26.960 --> 02:17:29.440]   Which Mike is talking about.
[02:17:29.440 --> 02:17:30.880]   We don't know where that goes after that.
[02:17:30.880 --> 02:17:31.280]   Yeah.
[02:17:31.280 --> 02:17:32.240]   I'm sorry.
[02:17:32.240 --> 02:17:33.920]   This is not free enterprise.
[02:17:33.920 --> 02:17:35.280]   This is just...
[02:17:35.280 --> 02:17:35.440]   Yeah.
[02:17:35.440 --> 02:17:36.800]   That smells.
[02:17:36.800 --> 02:17:41.440]   But I'm really looking forward to the TikTok LinkedIn synergies.
[02:17:41.440 --> 02:17:41.680]   So...
[02:17:41.680 --> 02:17:45.120]   [laughter]
[02:17:45.120 --> 02:17:46.160]   Oh my god.
[02:17:46.160 --> 02:17:47.360]   TikTok resumes.
[02:17:47.360 --> 02:17:48.000]   I would just...
[02:17:48.000 --> 02:17:52.000]   Just like, can't it just like just be done?
[02:17:52.000 --> 02:17:52.400]   You know what?
[02:17:52.400 --> 02:17:53.840]   You've changed my mind though, Amy.
[02:17:53.840 --> 02:17:58.080]   Because I really, until now, said this is silly.
[02:17:58.080 --> 02:17:59.760]   It's just a fun social network.
[02:17:59.760 --> 02:18:01.280]   What are you worried about?
[02:18:01.280 --> 02:18:05.120]   You've convinced me that there's some deeper, darker side to this.
[02:18:05.120 --> 02:18:09.360]   I had no idea 10 cent was involved in the social credit system in China
[02:18:09.360 --> 02:18:11.120]   or that they were an AI company.
[02:18:11.120 --> 02:18:12.320]   Not 10 cent.
[02:18:12.320 --> 02:18:13.200]   I'm sorry.
[02:18:13.200 --> 02:18:14.000]   By dance.
[02:18:14.000 --> 02:18:15.040]   By dance.
[02:18:15.040 --> 02:18:15.600]   By dance.
[02:18:15.600 --> 02:18:16.640]   But by dance.
[02:18:16.640 --> 02:18:17.920]   But yes.
[02:18:17.920 --> 02:18:20.400]   Well, 10 cent is another example of...
[02:18:20.400 --> 02:18:23.680]   That's ostensibly a private company.
[02:18:23.680 --> 02:18:26.240]   It's not a Chinese government entity.
[02:18:26.240 --> 02:18:29.200]   Well, again, there is no truly private company.
[02:18:29.200 --> 02:18:33.120]   But they have 5%, 10% stake.
[02:18:33.120 --> 02:18:34.640]   They have 5% Tesla.
[02:18:34.640 --> 02:18:39.600]   They own big significant stakes in many, many American.
[02:18:39.600 --> 02:18:41.520]   In Reddit, they have 10% of Reddit.
[02:18:41.520 --> 02:18:43.760]   So maybe this kind of...
[02:18:43.760 --> 02:18:46.160]   There's some sort of economic...
[02:18:46.160 --> 02:18:48.240]   I don't know.
[02:18:48.240 --> 02:18:49.520]   It's above my pay grade.
[02:18:49.520 --> 02:18:50.240]   I don't understand it.
[02:18:50.240 --> 02:18:51.120]   I was hoping you might.
[02:18:51.120 --> 02:18:54.160]   And 10 cent has 22 or so billion, 20,
[02:18:54.160 --> 02:18:58.560]   20, somewhere between 20 and 25 billion dollars worth of US assets.
[02:18:58.560 --> 02:19:01.600]   That's not an insignificant, insignificant amount of money.
[02:19:01.600 --> 02:19:01.840]   Yeah.
[02:19:01.840 --> 02:19:03.920]   And see, I love China.
[02:19:03.920 --> 02:19:06.160]   I was a Chinese studies major in college.
[02:19:06.160 --> 02:19:06.960]   I love the culture.
[02:19:06.960 --> 02:19:08.000]   I love the people.
[02:19:08.000 --> 02:19:10.480]   When I've been to China, I've enjoyed every minute of it.
[02:19:10.480 --> 02:19:13.920]   So I am not...
[02:19:13.920 --> 02:19:16.320]   I don't want to be a sign of phobe.
[02:19:16.320 --> 02:19:21.360]   But on the other hand, maybe we have to be realistic about the dangers that they pose.
[02:19:21.360 --> 02:19:24.160]   I also just really quickly want to highlight that
[02:19:24.160 --> 02:19:31.280]   the one terrible outcome of all of this is that Americans become fearful
[02:19:31.280 --> 02:19:34.080]   or antagonistic or racist towards Chinese people.
[02:19:34.080 --> 02:19:35.280]   That's my big fear.
[02:19:35.280 --> 02:19:35.600]   Yeah.
[02:19:35.600 --> 02:19:39.840]   We have to be very, very careful of making sure that the conversation...
[02:19:39.840 --> 02:19:44.240]   And I don't think that people who work at 10 cent have it out for people in the United States.
[02:19:44.240 --> 02:19:48.560]   These are geopolitical problems that have been around since before I was alive.
[02:19:48.560 --> 02:19:50.160]   Right. Absolutely.
[02:19:50.160 --> 02:19:50.720]   Yeah.
[02:19:50.720 --> 02:19:51.200]   Right.
[02:19:51.200 --> 02:19:51.360]   So...
[02:19:51.360 --> 02:19:54.400]   A little break, then a surprise.
[02:19:54.400 --> 02:19:57.440]   No, I'm not going to wear a blue wig.
[02:19:57.440 --> 02:20:02.320]   This week in tech brought to you this week by ExpressVPN.
[02:20:02.320 --> 02:20:05.200]   You know, that's the VPN provider I use and recommend.
[02:20:05.200 --> 02:20:07.680]   Because they protect my privacy.
[02:20:07.680 --> 02:20:09.040]   I know they don't do any logging.
[02:20:09.040 --> 02:20:09.920]   I know they actually...
[02:20:09.920 --> 02:20:10.640]   They've been audited.
[02:20:10.640 --> 02:20:11.760]   They have third party audits.
[02:20:11.760 --> 02:20:17.520]   They use a technology called Trusted Server that prevents them from logging any of my traffic.
[02:20:17.520 --> 02:20:19.760]   So I know I've got privacy there.
[02:20:19.760 --> 02:20:21.440]   But it's also more secure.
[02:20:21.440 --> 02:20:26.080]   And nowadays we're all watching a lot of TV.
[02:20:26.080 --> 02:20:33.760]   It also turns out a great way to get around geographic restrictions on the things you watch on TV.
[02:20:33.760 --> 02:20:35.360]   And this is not illegal.
[02:20:35.360 --> 02:20:36.800]   This is not even immoral.
[02:20:36.800 --> 02:20:41.200]   If you're paying for Netflix, maybe you've watched everything good on Netflix US.
[02:20:41.200 --> 02:20:42.160]   I have.
[02:20:42.160 --> 02:20:46.960]   But now with ExpressVPN, I can unlock thousands of new shows and movies
[02:20:46.960 --> 02:20:49.360]   from streaming libraries all over the globe.
[02:20:49.360 --> 02:20:52.080]   The one thing that's great about ExpressVPN,
[02:20:52.080 --> 02:20:53.040]   it's fast enough to do that.
[02:20:53.040 --> 02:20:56.320]   A lot of VPNs you would never want to watch HD video
[02:20:56.320 --> 02:20:57.280]   because it's just too slow.
[02:20:57.280 --> 02:21:00.240]   I leave ExpressVPN on all the time on my devices
[02:21:00.240 --> 02:21:02.480]   because I don't even notice it's there.
[02:21:03.120 --> 02:21:05.520]   Still can watch HD video, no buffering.
[02:21:05.520 --> 02:21:06.880]   And it's on everything I use.
[02:21:06.880 --> 02:21:12.480]   iOS, Android, Windows, Mac, Linux, even our TVs, our smart devices.
[02:21:12.480 --> 02:21:16.000]   ExpressVPN works with many streaming services.
[02:21:16.000 --> 02:21:17.920]   They're in over 100 countries.
[02:21:17.920 --> 02:21:20.480]   So that means you can go to that country.
[02:21:20.480 --> 02:21:21.920]   For instance, here's what I do.
[02:21:21.920 --> 02:21:23.040]   I fire up Netflix.
[02:21:23.040 --> 02:21:24.720]   I'm a subscriber.
[02:21:24.720 --> 02:21:29.520]   I take ExpressVPN and normally it picks the server nearest you, the fastest server.
[02:21:29.520 --> 02:21:31.200]   But I say, no, no, instead of that,
[02:21:32.080 --> 02:21:33.440]   let's go to London today.
[02:21:33.440 --> 02:21:34.240]   And now I'm watching.
[02:21:34.240 --> 02:21:35.760]   I refresh Netflix suddenly.
[02:21:35.760 --> 02:21:36.880]   I can see Dr. Who.
[02:21:36.880 --> 02:21:39.200]   I can see black.
[02:21:39.200 --> 02:21:40.720]   Yeah, all the black adders I want.
[02:21:40.720 --> 02:21:41.440]   I love black.
[02:21:41.440 --> 02:21:44.320]   I can go to Canada and watch Brooklyn nine, nine,
[02:21:44.320 --> 02:21:46.480]   or Rick and Morty in Netflix, France.
[02:21:46.480 --> 02:21:52.960]   You haven't seen anything until you see in a multi in France.
[02:21:52.960 --> 02:21:54.480]   It's a good stuff.
[02:21:54.480 --> 02:21:56.560]   Fresh Prince of Bel Air in Australia.
[02:21:56.560 --> 02:21:58.240]   Hey, how about that?
[02:21:58.240 --> 02:22:00.160]   Just change a location.
[02:22:00.160 --> 02:22:00.880]   Hit connect.
[02:22:00.880 --> 02:22:01.840]   Refresh the page.
[02:22:02.080 --> 02:22:02.800]   And you can watch it.
[02:22:02.800 --> 02:22:08.160]   ExpressVPN works with Amazon Prime with Netflix with BBC's iPlayer with YouTube.
[02:22:08.160 --> 02:22:09.520]   It's fast.
[02:22:09.520 --> 02:22:10.240]   It's easy.
[02:22:10.240 --> 02:22:14.480]   And if you use my link right now to expressvpn.com/twit,
[02:22:14.480 --> 02:22:16.560]   three extra months free with a one year package,
[02:22:16.560 --> 02:22:21.520]   go to expressvpn.com/twit and get the extra three months as part of that deal.
[02:22:21.520 --> 02:22:27.120]   15 months of the price of 12 expressvpn.com/twit.
[02:22:27.120 --> 02:22:28.160]   See only VPN.
[02:22:28.160 --> 02:22:29.360]   I use the one I recommend.
[02:22:29.360 --> 02:22:31.040]   I've got it on all my devices.
[02:22:31.040 --> 02:22:35.600]   I've got it on my TV to expressvpn.com/twit.
[02:22:35.600 --> 02:22:39.280]   Privacy, security, and Rick and Morty in France.
[02:22:39.280 --> 02:22:40.960]   One more could you ask for?
[02:22:40.960 --> 02:22:43.840]   I mean, honestly, that's all I never want.
[02:22:43.840 --> 02:22:46.320]   So I told you I had a shocker.
[02:22:46.320 --> 02:22:53.200]   President Trump thinks he says he's considering a pardon for Edward Snowden.
[02:22:53.200 --> 02:22:55.920]   What?
[02:22:55.920 --> 02:22:56.320]   Yeah.
[02:22:56.320 --> 02:22:59.520]   Every day I wake up and I it's like chat roulette.
[02:22:59.520 --> 02:23:00.640]   What?
[02:23:00.640 --> 02:23:01.520]   New point?
[02:23:01.520 --> 02:23:05.440]   I don't know what I'm going to get and how blind it I'm going to be once I get there.
[02:23:05.440 --> 02:23:07.120]   What?
[02:23:07.120 --> 02:23:09.600]   President Trump in an interview with the New York Post,
[02:23:09.600 --> 02:23:11.920]   that bastion of journalism and integrity,
[02:23:11.920 --> 02:23:17.200]   said there are a lot of people who think that Snowden's not being treated fairly by
[02:23:17.200 --> 02:23:18.400]   US law enforcement.
[02:23:18.400 --> 02:23:20.640]   I'm going to start looking at it.
[02:23:20.640 --> 02:23:23.840]   This is that is Bedminster.
[02:23:23.840 --> 02:23:26.480]   I mean, this is one of the problems.
[02:23:26.480 --> 02:23:30.320]   Yes, Snowden is not being treated fairly by the US legal system,
[02:23:30.320 --> 02:23:36.640]   but I don't honestly don't think that Donald Trump is going to do anything better about this.
[02:23:36.640 --> 02:23:37.680]   You know, it's so strange.
[02:23:37.680 --> 02:23:41.040]   This is all flipped because he was a hero, right?
[02:23:41.040 --> 02:23:43.360]   He told us what the NSA was up to.
[02:23:43.360 --> 02:23:45.040]   Then he fled to Russia.
[02:23:45.040 --> 02:23:48.640]   And now the same people who lionized him five years ago
[02:23:48.640 --> 02:23:50.560]   are saying, you know what?
[02:23:50.560 --> 02:23:51.920]   I think he's a Russian pawn.
[02:23:51.920 --> 02:23:53.680]   He's a Putin pawn.
[02:23:53.680 --> 02:23:58.320]   Kid, life is too fast for me, slow down.
[02:23:58.320 --> 02:24:00.000]   I mean, I'm going to say Mike.
[02:24:00.000 --> 02:24:00.480]   Go ahead, Mike.
[02:24:00.480 --> 02:24:02.800]   I'm curious on your on your on your view on this.
[02:24:02.800 --> 02:24:02.960]   Yeah.
[02:24:02.960 --> 02:24:09.840]   I got to say, Snowden strikes me as a patriot who, you know, did other things.
[02:24:09.840 --> 02:24:12.400]   That's last year's thinking, Ian.
[02:24:12.400 --> 02:24:20.240]   Yeah, I mean, I think that he was a whistleblower, right?
[02:24:20.240 --> 02:24:24.320]   I mean, he exposed things that the NSA was doing that were bad.
[02:24:24.320 --> 02:24:28.000]   And I think violated the Fourth Amendment and caused a lot of problems.
[02:24:28.000 --> 02:24:31.040]   And I think that the government has treated him very, very badly.
[02:24:31.040 --> 02:24:37.520]   I also will note, by the way, that in 2013, Trump himself issued a tweet where he said
[02:24:37.520 --> 02:24:39.920]   that he thought Snowden should be executed.
[02:24:39.920 --> 02:24:46.320]   So his own view seems to shift over time, depending on what is going on.
[02:24:46.320 --> 02:24:50.000]   And there is a feeling that, you know, like so many things with Trump, when a reporter
[02:24:50.000 --> 02:24:53.520]   asks him a question, he will say, yes, of course, we're looking into that when he doesn't really
[02:24:53.520 --> 02:24:56.480]   have much of an idea of what he's actually talking about.
[02:24:56.480 --> 02:25:01.040]   So I would be surprised if he does anything, but I, you know, that would be like, you know,
[02:25:01.040 --> 02:25:06.000]   one of the rare good things that I think the president would do if he did issue a pardon.
[02:25:06.000 --> 02:25:10.080]   I'm not holding my breath, and I don't think Edward Snowden is holding his breath.
[02:25:10.080 --> 02:25:11.840]   That Trump would actually pardon him either.
[02:25:11.840 --> 02:25:13.520]   And then there's this.
[02:25:13.520 --> 02:25:20.960]   The White House is planning to, with its new defense budget, increase AI and quantum funding by 30%.
[02:25:20.960 --> 02:25:26.000]   Yeah, Palantir is going to make it a big pay to have this.
[02:25:26.000 --> 02:25:28.240]   So wait, there's a, wait, there's a backstory here.
[02:25:28.240 --> 02:25:30.320]   So Michael, we'll just do this.
[02:25:30.320 --> 02:25:31.040]   So, okay.
[02:25:31.040 --> 02:25:38.560]   So Michael just got appointed the head of basically R&D engineering and.
[02:25:38.560 --> 02:25:40.800]   He's the CTO, Michael Kratzios.
[02:25:40.800 --> 02:25:41.360]   I don't know.
[02:25:41.360 --> 02:25:42.960]   He was the CEO.
[02:25:42.960 --> 02:25:43.520]   CTO.
[02:25:43.520 --> 02:25:45.600]   He was the CTO, sorry, CTO.
[02:25:45.600 --> 02:25:49.600]   He is now within DoD.
[02:25:49.600 --> 02:25:51.520]   He's in the Pentagon and has the largest.
[02:25:51.520 --> 02:25:55.840]   He's managing a $60 billion with a B dollar budget.
[02:25:55.840 --> 02:26:03.200]   He was formerly, and as far as I know, has never managed, and we're close to that type of budget,
[02:26:03.200 --> 02:26:09.200]   or been in charge of R&D activities in this way.
[02:26:09.200 --> 02:26:13.360]   Hey, but he does say we're going to be winning.
[02:26:13.360 --> 02:26:14.560]   Okay.
[02:26:14.560 --> 02:26:18.640]   He says, we need to make sure we're winning and leading in the technologies of today.
[02:26:19.600 --> 02:26:20.800]   I agree with that.
[02:26:20.800 --> 02:26:25.040]   But again, he was Peter Thiel's chief of staff, leading into.
[02:26:25.040 --> 02:26:26.000]   Oh, okay.
[02:26:26.000 --> 02:26:26.720]   So I don't.
[02:26:26.720 --> 02:26:27.600]   He's a little young.
[02:26:27.600 --> 02:26:28.960]   He's 33 years old.
[02:26:28.960 --> 02:26:30.080]   33 years old.
[02:26:30.080 --> 02:26:39.120]   You know, this is a big, this is the part of the DoD that makes big bets on big strategic decisions.
[02:26:39.120 --> 02:26:42.320]   I don't know.
[02:26:42.320 --> 02:26:43.760]   I don't know.
[02:26:43.760 --> 02:26:45.280]   I know that he was well liked.
[02:26:45.280 --> 02:26:49.520]   I know that he was well liked among some staffers at the state.
[02:26:49.520 --> 02:26:53.120]   And some staffers at OSTP that I know.
[02:26:53.120 --> 02:27:03.040]   But I am baffled by this appointment and the significant responsibility that he's been given,
[02:27:03.040 --> 02:27:08.560]   which could all be gone in a matter of months if there is a changeover.
[02:27:08.560 --> 02:27:15.280]   But yeah, obviously we should be heavily invested in different types of approaches to
[02:27:15.280 --> 02:27:24.240]   warfare. But the connections now between, you know, between all of the different investments
[02:27:24.240 --> 02:27:30.400]   that Peter Thiel has and some of the relationships that the federal government has had with.
[02:27:30.400 --> 02:27:37.200]   They think this is really just going to be a funnel from the taxpayers right into Peter Thiel's
[02:27:37.200 --> 02:27:37.520]   pocket.
[02:27:37.520 --> 02:27:41.520]   I don't know.
[02:27:41.520 --> 02:27:42.480]   I think so.
[02:27:43.280 --> 02:27:49.840]   The other question is, is it, should we be spending a billion dollars on quantum information science?
[02:27:49.840 --> 02:27:52.720]   Or is this really very blue sky still?
[02:27:52.720 --> 02:27:59.200]   Well, I mean, to get back to what we were talking about earlier, you know, blue sky stuff.
[02:27:59.200 --> 02:27:59.680]   Got to do.
[02:27:59.680 --> 02:28:02.240]   It's the kind of stuff that you hope the government does invest in.
[02:28:02.240 --> 02:28:04.720]   So I'm not so upset about that part of it.
[02:28:04.720 --> 02:28:10.240]   I mean, I think, you know, it's good to see the government investing in pure research.
[02:28:10.240 --> 02:28:12.800]   And this is definitely sort of a pure research area.
[02:28:12.800 --> 02:28:16.800]   Yeah, if we had had this story at 10 years ago, five years ago, we would go,
[02:28:16.800 --> 02:28:19.440]   yeah, yeah, yeah, go, go team.
[02:28:19.440 --> 02:28:22.480]   Now I'm just, I don't know.
[02:28:22.480 --> 02:28:28.480]   But I will say, I will say one thing that I'm skeptical about is that whenever it's framed as a
[02:28:28.480 --> 02:28:35.200]   race, you know, the race to 5G, the race to AI, the race to quantum computing, I think that's all
[02:28:35.200 --> 02:28:39.200]   nonsense. And that's, you know, that's just sort of how we got to do the blue sky.
[02:28:39.760 --> 02:28:46.400]   And yeah, I kind of made fun of an article a couple of weeks ago, where a reporter, I think,
[02:28:46.400 --> 02:28:51.040]   kind of misunderstood where this was after the Chicago announcement that we were going to do
[02:28:51.040 --> 02:28:58.240]   more research into a quantum internet where hackers couldn't hack because when you observe
[02:28:58.240 --> 02:29:05.520]   quantum particles, they, they change. So, so hackers can't hack that, right? And also, there was a
[02:29:05.520 --> 02:29:12.640]   magical, using quantum entanglement, magical way for two machines in different locations to talk
[02:29:12.640 --> 02:29:17.520]   to each other instantaneously, kind of like the Ansible. And I thought, maybe that's a little
[02:29:17.520 --> 02:29:23.120]   premature to announce that, just a little. But maybe we'll have who knows, everyone likes that
[02:29:23.120 --> 02:29:26.960]   headline. I'm the idiot who bought the Microsoft duo. What do I know?
[02:29:26.960 --> 02:29:34.560]   I always like to mention the passing of an unfortunately has become more and more common
[02:29:34.560 --> 02:29:40.800]   of internet pioneers, Russell, Russell Kersch, who invented the pixel. One wouldn't think the
[02:29:40.800 --> 02:29:46.960]   pixel would need to be invented, but yes, it would. Passed away in Portland this week at the age of
[02:29:46.960 --> 02:29:55.040]   91. He was at the National Bureau of Standards as a member of the Standards Eastern Automatic
[02:29:55.040 --> 02:30:02.240]   Computer Team. This is 1951 when they had teams. And he was in charge of handling the US's first
[02:30:02.240 --> 02:30:09.600]   programmable computer. There it is. An image of his infant son, 176 pixels by 176 pixels.
[02:30:09.600 --> 02:30:17.520]   This is in the 50s. He developed a digital image scanner for CAC that went on to capture the first
[02:30:17.520 --> 02:30:23.840]   digital images, including that picture of Walden, his son, would be about my age now.
[02:30:23.840 --> 02:30:30.880]   He invented the pixel. And then he said, you know, we blew it. The square pixels, that was
[02:30:30.880 --> 02:30:36.160]   the logical thing to do. But really, that wasn't the only kind of thing you could do. And it was
[02:30:36.160 --> 02:30:39.680]   something very foolish that everyone in the world has been suffering from ever since.
[02:30:39.680 --> 02:30:45.680]   So he said, you know, we really should have arbitrary shaped pixels, because then you wouldn't have
[02:30:45.680 --> 02:30:52.560]   pixelation. But that's always the way with technology creators. I interviewed Mark Andresen,
[02:30:53.280 --> 02:31:00.400]   God, what in 95? And he got an angry phone call from Tim Berners-Lee saying,
[02:31:00.400 --> 02:31:05.920]   you should not put images into worldwide web links, because that's not what it's for. It's for
[02:31:05.920 --> 02:31:14.480]   documents. Sorry. Sorry. Sorry. It's the same thing with Thomas Edison when he listed the 10
[02:31:14.480 --> 02:31:20.080]   things that the photograph could be used for. Playing music was down at number eight. You know,
[02:31:20.080 --> 02:31:25.040]   people don't get, you know, they don't understand the inventions they create.
[02:31:25.040 --> 02:31:30.320]   R.I.P. Russell A. Kersch, the inventor of the pixel.
[02:31:30.320 --> 02:31:37.440]   Well, that was Francis Allen. Yeah, I talked about that last week, Francis Allen,
[02:31:37.440 --> 02:31:43.200]   who invented parallel compas, you know, optimizing compilers and parallel compilation. It was a big
[02:31:43.200 --> 02:31:48.560]   big big. I didn't get a Turing Award until 2006. Seriously, they couldn't have put amazing
[02:31:48.560 --> 02:31:51.680]   grace in that earlier. But anyway, that's another round.
[02:31:51.680 --> 02:31:57.360]   Before we move off of this, can we just take a moment because these things never get set
[02:31:57.360 --> 02:32:02.480]   enough while everybody's alive? But there's a group of unsung heroes in the middle of the virus,
[02:32:02.480 --> 02:32:07.840]   and that's everybody working in IT who are keeping our systems running and our phones working and
[02:32:07.840 --> 02:32:15.600]   our cameras working. And they are under incredible stress and don't get near the amount of public
[02:32:15.600 --> 02:32:21.440]   adulation that they should. Bless you. If anybody should thank them, it is us. Could Amy look like
[02:32:21.440 --> 02:32:29.120]   that if it weren't for our heroes of IT? Ladies and gentlemen, you have a green screen behind
[02:32:29.120 --> 02:32:33.360]   you? Because it's a really excellent. I don't. This is, I think Skype must have updated.
[02:32:33.360 --> 02:32:39.040]   I don't. This is just, I'm sitting in my office at home, and this is amazing. The green screen
[02:32:39.040 --> 02:32:44.560]   is much better on this than on Zoom. Skype clearly works best with purple wigs.
[02:32:44.560 --> 02:32:51.840]   That's obvious. That's Amy Webb, and you are always a joy to have on the show. And you always
[02:32:51.840 --> 02:32:56.320]   open my mind. I learned something every single time you're on FutureTodayInstitute.com. If you
[02:32:56.320 --> 02:33:01.680]   want to learn about her work helping governments and organizations instead of just throwing stuff
[02:33:01.680 --> 02:33:06.800]   against the wall actually plan for the future. Because she knows what it's going to be.
[02:33:06.800 --> 02:33:11.120]   Thank you. Thank you, Amy. It's always a pleasure to have you on. And I'm going to
[02:33:11.120 --> 02:33:16.800]   get to delete TikTok as soon as it shows over. I'm going to be sad. I was learning some new
[02:33:16.800 --> 02:33:21.400]   dances, but okay, I'm going to delete it. I don't want it to be. But it would be
[02:33:21.400 --> 02:33:25.200]   TikTok on your new Surface Folding Screen thing. Well, that's what I was thinking. It's going to
[02:33:25.200 --> 02:33:31.120]   be the perfect TikTok machine, but I'll have to find something else. I already got rid of Facebook
[02:33:31.120 --> 02:33:35.840]   and Instagram and WhatsApp. I'm not, you know, I don't want to be, I don't want to be a portal
[02:33:36.480 --> 02:33:43.040]   to, I don't know, the future or something. I don't know. They could find, you know what?
[02:33:43.040 --> 02:33:47.360]   I don't care if people know what I'm up to. If you want Chinese government, I'll put a camera
[02:33:47.360 --> 02:33:54.720]   in my house. Oh, wait a minute, too late. That's Ian Thompson. He is dapper as hell
[02:33:54.720 --> 02:34:02.400]   in his greenish mustache in here. And I was in, please apologize to your beautiful wife.
[02:34:03.280 --> 02:34:09.520]   No, no, I have to shower immediately afterwards. But it has been tremendous fun and custom is a
[02:34:09.520 --> 02:34:18.720]   very persuasive person. But no, it's just fun. Ian's at the register.com where he's in charge,
[02:34:18.720 --> 02:34:23.200]   he's a news editor, so he's in charge of all the most important stuff right in the good headlines.
[02:34:23.200 --> 02:34:27.760]   Thank you, Ian. It's great to see you again. And Mike Masnick, we love you and your blue hair.
[02:34:28.480 --> 02:34:33.040]   He's the first blue haired old lady we've ever had on this show. Excellent.
[02:34:33.040 --> 02:34:38.560]   It's real to have you. Techter.com, I hope you can figure out a way around the Google ad
[02:34:38.560 --> 02:34:44.480]   black hole you've fallen into. That sucks. We'll see. We'll see. We'll be experimenting.
[02:34:44.480 --> 02:34:49.760]   Do you allow people to like subscribe or support you? Yeah. Yeah. We have, we have,
[02:34:49.760 --> 02:34:56.560]   at the top of the page, there's a support techter tab and that lists lots of different ways that
[02:34:56.560 --> 02:35:01.920]   you can support. Please do. Yeah. And there's all sorts of ways we try and make it as easy as
[02:35:01.920 --> 02:35:07.920]   possible for people to support us and there's a patreon. And there's of course, those great
[02:35:07.920 --> 02:35:15.520]   tech dirt YouTube takedown masks, which everybody I've got to order some. Lots of great tech
[02:35:15.520 --> 02:35:23.280]   tech dirt merch. Yep, we have lots of different stuff. And so. And of course, tech dirt has a
[02:35:23.280 --> 02:35:31.920]   podcast, which we do it on SoundCloud. Yeah. We have lots of different guests. We have some really
[02:35:31.920 --> 02:35:37.680]   interesting ones coming up. We had just this past week, we had a really interesting, like,
[02:35:37.680 --> 02:35:44.160]   small company that's building exercise equipment, but they actually encourage people to build their
[02:35:44.160 --> 02:35:50.160]   own copies of it. Oh, that's interesting. Yeah. You know, they didn't freak out about people
[02:35:50.160 --> 02:35:53.680]   copying them. Nice. They actually encourage people too. So I thought it was a really interesting
[02:35:53.680 --> 02:35:58.240]   conversation. That's really great. Thank you, Mike. Really appreciate all you do. Keep up the
[02:35:58.240 --> 02:36:03.120]   great work at techter.com. Thank you all for being here. We always have fun doing this show
[02:36:03.120 --> 02:36:08.480]   wigs or not. You don't have to wear one to watch it anyway or listen to it. If you haven't seen
[02:36:08.480 --> 02:36:14.000]   the video, get the video today. It's a little weird. We also have audio available. All of that,
[02:36:14.000 --> 02:36:20.960]   you can get on our website, twit.tv. We're on YouTube. And of course, you can subscribe in your
[02:36:20.960 --> 02:36:26.640]   favorite podcast client. If you want to watch the live version of the show, you can get that,
[02:36:26.640 --> 02:36:34.960]   the live stream, any Sunday at around, it starts around 215 Pacific 515 Eastern. The show usually
[02:36:34.960 --> 02:36:39.360]   gets away under way about half an hour later, but you can watch the pre-show as we get set up
[02:36:39.360 --> 02:36:47.600]   and all that stuff. That behind the scenes stream is a twit.tv/live 215 Pacific 515 Eastern time
[02:36:47.600 --> 02:36:56.240]   2115 UTC of a Sunday evening. Our chatroom is irc.twit.tv. Great people hanging out there as they
[02:36:56.240 --> 02:37:03.600]   watch live. Please take advantage of that. It's a great geek confab. And you can always get the
[02:37:03.600 --> 02:37:09.840]   show on your favorite voice assistant. Just say, "Hey, you play this week in tech podcast." And you'll
[02:37:09.840 --> 02:37:16.000]   get the latest episode or play Twit Live. And often it will play the live stream. Sometimes not.
[02:37:16.000 --> 02:37:22.960]   Sometimes I get a song by Rosemary Clooney. I don't know why. It's just only the artificial
[02:37:22.960 --> 02:37:27.760]   intelligence. That's totally random. I played piano for once. Did you? I accompanied her.
[02:37:28.880 --> 02:37:34.560]   Yeah. Where? When? How? I just dropped that into the show and leave it.
[02:37:34.560 --> 02:37:42.080]   Did you play "Come On On My House? My House? You got to feed me?" She was really struggling,
[02:37:42.080 --> 02:37:49.200]   I think, with alcoholism at that point. I was a sub-in for bands that, when they needed an
[02:37:49.200 --> 02:37:55.040]   extra set of hands. So she forgot the words. She was struggling with Rudolph as a Christmas
[02:37:55.040 --> 02:38:03.120]   show. I loved her. I loved her. I grew up watching her in White Christmas, of course.
[02:38:03.120 --> 02:38:08.480]   And her nephew, George, did pretty well too for himself a little later on.
[02:38:08.480 --> 02:38:13.280]   Thank you. I'm learning stuff about you, Amy, every time.
[02:38:13.280 --> 02:38:19.360]   So you were like a band? You played in a piano in a band?
[02:38:20.320 --> 02:38:28.800]   I dropped out of music school. I had performance. I had gotten recruited when I was a freshman.
[02:38:28.800 --> 02:38:34.800]   So I started off in music school against my wishes and then dropped out. So I have a background.
[02:38:34.800 --> 02:38:39.040]   I'm a terrible musician. To make your mom happy. But you had that mathematical mind because
[02:38:39.040 --> 02:38:46.960]   game theory, wow, that's fun. Yeah. I had a scholarship. So there was that or, I guess,
[02:38:46.960 --> 02:38:51.760]   something else. Working for a living. Yep. Thanks everybody. We'll see you next time.
[02:38:51.760 --> 02:38:54.400]   Another Twit. This is amazing.
[02:38:54.400 --> 02:38:56.400]   See ya.
[02:38:57.400 --> 02:38:58.400]   Do it the twist.
[02:38:58.400 --> 02:38:59.400]   Do it the twist.
[02:38:59.400 --> 02:39:00.400]   Alright.
[02:39:00.400 --> 02:39:02.400]   Do it the twist, baby.
[02:39:02.400 --> 02:39:04.400]   Do it the twist.
[02:39:04.400 --> 02:39:10.120]   it.

