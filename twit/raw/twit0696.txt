;FFMETADATA1
title=I've Got Mark-Level Sign-Off
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=696
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:03.060]   It's time for Twent this week in Tech.
[00:00:03.060 --> 00:00:04.160]   Sam Mibul-Smit is here.
[00:00:04.160 --> 00:00:06.240]   He's senior analyst of Navigant Research,
[00:00:06.240 --> 00:00:09.840]   Rich D'Amourro, KTLA's Rich on Tech Guy,
[00:00:09.840 --> 00:00:12.840]   and from France wearing his yellow jacket,
[00:00:12.840 --> 00:00:16.040]   Patrick Bezia, we're gonna talk about the French riots
[00:00:16.040 --> 00:00:18.380]   and Facebook's role there,
[00:00:18.380 --> 00:00:23.220]   unintentional consequences of Fosta and Cesta
[00:00:23.220 --> 00:00:25.440]   and the Lock-In on Quora,
[00:00:25.440 --> 00:00:27.240]   plus boyfriends of Instagram.
[00:00:27.240 --> 00:00:29.400]   It's all coming up next.
[00:00:29.400 --> 00:00:30.240]   On Twit.
[00:00:30.240 --> 00:00:35.720]   Netcast you love.
[00:00:35.720 --> 00:00:37.200]   From people you trust.
[00:00:37.200 --> 00:00:42.200]   This is Twit.
[00:00:42.200 --> 00:00:50.240]   This is Twit.
[00:00:50.240 --> 00:00:54.200]   This week in Tech, episode 696, recorded Sunday,
[00:00:54.200 --> 00:00:57.000]   December 9th, 2018.
[00:00:57.000 --> 00:00:59.080]   I've got Mark Level sign off.
[00:01:00.040 --> 00:01:03.720]   This week in Tech is brought to you by Robinhood,
[00:01:03.720 --> 00:01:06.360]   an investing app that lets you buy and sell stocks,
[00:01:06.360 --> 00:01:10.560]   ETFs, options, and cryptocurrency commission-free.
[00:01:10.560 --> 00:01:15.320]   Sign up at twit2.robonhood.com and get a free stock
[00:01:15.320 --> 00:01:18.760]   like Apple Forward or Sprint to help build your portfolio.
[00:01:18.760 --> 00:01:20.680]   And buy stamps.com.
[00:01:20.680 --> 00:01:23.480]   Buy and print review, US postage, the instant you need it
[00:01:23.480 --> 00:01:24.720]   right from your desk.
[00:01:24.720 --> 00:01:26.880]   For our special offer, go to stamps.com,
[00:01:26.880 --> 00:01:29.440]   click the microphone, and enter Twit.
[00:01:29.440 --> 00:01:31.160]   And buy Ring.
[00:01:31.160 --> 00:01:33.760]   Ring's alarm security kit is a smarter way
[00:01:33.760 --> 00:01:35.480]   to protect your entire home.
[00:01:35.480 --> 00:01:37.800]   Go to Ring.com/Twit to learn how you can get
[00:01:37.800 --> 00:01:41.080]   home security for only $10 a month.
[00:01:41.080 --> 00:01:44.840]   And buy ExpressVPN.
[00:01:44.840 --> 00:01:47.320]   Protect your online activity today.
[00:01:47.320 --> 00:01:49.440]   For an extra three months free with a one year package,
[00:01:49.440 --> 00:01:52.680]   go to expressvpn.com/twit.
[00:01:55.640 --> 00:01:57.640]   It's time for Twit this week in Tech, the show where you get
[00:01:57.640 --> 00:02:00.400]   together with some of the best tech journalists in the world
[00:02:00.400 --> 00:02:02.680]   and talk about tech knowledge.
[00:02:02.680 --> 00:02:05.720]   You're joining me in studio this week.
[00:02:05.720 --> 00:02:09.120]   Sam Aboule-Samanade, who is senior analyst at the Apple
[00:02:09.120 --> 00:02:12.760]   Book Research, and he is in town with a Jaguar E-Pace
[00:02:12.760 --> 00:02:13.600]   electric-
[00:02:13.600 --> 00:02:14.880]   I-Pace.
[00:02:14.880 --> 00:02:16.200]   I get it wrong every time because-
[00:02:16.200 --> 00:02:17.200]   I know, Jaguar for electric.
[00:02:17.200 --> 00:02:18.960]   Jaguar really messed up that branding.
[00:02:18.960 --> 00:02:19.800]   It's an I-Pace.
[00:02:19.800 --> 00:02:23.000]   Think of it like it's a accompaniment to your iPhone.
[00:02:23.000 --> 00:02:23.600]   Exactly.
[00:02:23.600 --> 00:02:25.840]   And your iMac, your iPace.
[00:02:25.840 --> 00:02:26.680]   Sam, always a pleasure.
[00:02:26.680 --> 00:02:27.680]   Thank you for letting me drive that.
[00:02:27.680 --> 00:02:29.000]   It was a lot of fun.
[00:02:29.000 --> 00:02:29.840]   Pleasure to bring it up.
[00:02:29.840 --> 00:02:30.880]   Yeah.
[00:02:30.880 --> 00:02:32.640]   Please.
[00:02:32.640 --> 00:02:35.200]   You are the reason why Jaguar was willing to let me have
[00:02:35.200 --> 00:02:37.800]   the car this weekend because it's all tied up for North
[00:02:37.800 --> 00:02:39.360]   American car, the year jurors.
[00:02:39.360 --> 00:02:39.960]   Oh, really?
[00:02:39.960 --> 00:02:40.960]   Yeah.
[00:02:40.960 --> 00:02:43.320]   So thanks, Jaguar.
[00:02:43.320 --> 00:02:46.760]   And I'm going to buy five.
[00:02:46.760 --> 00:02:50.120]   Also with us, he's the author of a brand new book,
[00:02:50.120 --> 00:02:53.080]   publisher, too, I think 101 Handy Tech Tips
[00:02:53.080 --> 00:02:56.120]   for the iPhone from KTLA in Los Angeles.
[00:02:56.120 --> 00:02:58.360]   It is rich on tech, rich tomorrow.
[00:02:58.360 --> 00:02:59.680]   Hi, Rich.
[00:02:59.680 --> 00:03:00.200]   Hey, Leo.
[00:03:00.200 --> 00:03:01.080]   Thanks for having me on.
[00:03:01.080 --> 00:03:02.960]   Did this just come out?
[00:03:02.960 --> 00:03:05.520]   This just came out about a week ago now.
[00:03:05.520 --> 00:03:07.160]   So it's on Amazon in paperback.
[00:03:07.160 --> 00:03:09.440]   I did it as an e-book over the summer.
[00:03:09.440 --> 00:03:12.640]   And a lot of folks said, hey, can you make it a paperback?
[00:03:12.640 --> 00:03:13.400]   So I did.
[00:03:13.400 --> 00:03:16.120]   I went back to the drawing board, revised it for iOS 12.
[00:03:16.120 --> 00:03:17.320]   And now it's a paperback.
[00:03:17.320 --> 00:03:21.000]   And I can finally answer all those emails with a link to Amazon.
[00:03:21.000 --> 00:03:22.480]   You just buy my book.
[00:03:22.480 --> 00:03:23.360]   Even better.
[00:03:23.360 --> 00:03:25.120]   It's really-- it's got a lot of illustrations.
[00:03:25.120 --> 00:03:26.080]   It's nicely laid out.
[00:03:26.080 --> 00:03:27.040]   It's really a beautiful book.
[00:03:27.040 --> 00:03:27.520]   Nice and thick.
[00:03:27.520 --> 00:03:28.600]   Lots of information.
[00:03:28.600 --> 00:03:30.760]   Did you know, though, Rich, my very first book, which
[00:03:30.760 --> 00:03:33.440]   was published in March 1995, this book
[00:03:33.440 --> 00:03:36.640]   is 101 Handy Tech Tips for the iPhone.
[00:03:36.640 --> 00:03:41.800]   My very first book was 101 Computer Answers You Need to Know.
[00:03:41.800 --> 00:03:42.760]   Oh, my gosh.
[00:03:42.760 --> 00:03:43.600]   Leo.
[00:03:43.600 --> 00:03:44.360]   That is amazing.
[00:03:44.360 --> 00:03:45.760]   I did not know that.
[00:03:45.760 --> 00:03:47.080]   But we are on the same wavelength here.
[00:03:47.080 --> 00:03:48.760]   Something magical about 101.
[00:03:48.760 --> 00:03:51.440]   Actually, the publisher named it that my art--
[00:03:51.440 --> 00:03:52.760]   Gina Smith, who wrote it with me--
[00:03:52.760 --> 00:03:55.200]   our original title was, how do I get the dog here out
[00:03:55.200 --> 00:03:57.040]   of the disk drive, which I thought was a better--
[00:03:57.040 --> 00:03:58.120]   That would have been a much better title.
[00:03:58.120 --> 00:03:58.640]   I know.
[00:03:58.640 --> 00:03:59.120]   I agree.
[00:03:59.120 --> 00:03:59.600]   Good.
[00:03:59.600 --> 00:04:02.640]   And given how that book sold, I wish I had been to that.
[00:04:02.640 --> 00:04:05.200]   But they changed the name on us, because they're the publisher.
[00:04:05.200 --> 00:04:06.360]   This is the beauty of it.
[00:04:06.360 --> 00:04:08.600]   Nowadays, what does a publisher do besides getting your way?
[00:04:08.600 --> 00:04:09.840]   Nothing.
[00:04:09.840 --> 00:04:11.560]   So do it yourself on Amazon.
[00:04:11.560 --> 00:04:12.520]   Did you use--
[00:04:12.520 --> 00:04:15.480]   Amazon's like Create Space or whatever they call it now?
[00:04:15.480 --> 00:04:15.880]   Yeah.
[00:04:15.880 --> 00:04:18.120]   It's now called like Kindle Direct Publishing.
[00:04:18.120 --> 00:04:19.360]   But they bought Create Space.
[00:04:19.360 --> 00:04:22.240]   I actually want to do another book on how to write a book,
[00:04:22.240 --> 00:04:24.320]   because when I did my first ebook,
[00:04:24.320 --> 00:04:25.680]   I learned everything along the way.
[00:04:25.680 --> 00:04:28.160]   And I thought, oh, I could just convert it to the paperback,
[00:04:28.160 --> 00:04:29.520]   not so fast.
[00:04:29.520 --> 00:04:32.000]   There's a lot that goes into a book that's different when
[00:04:32.000 --> 00:04:34.440]   you do a paperback version versus the ebook
[00:04:34.440 --> 00:04:35.600]   and all the software you use.
[00:04:35.600 --> 00:04:38.800]   So one of these days, I'll do a kind of a story on that.
[00:04:38.800 --> 00:04:40.000]   But it's really fascinating.
[00:04:40.000 --> 00:04:43.120]   But it's amazing what you can do yourself nowadays.
[00:04:43.120 --> 00:04:44.360]   And it's really fun too.
[00:04:44.360 --> 00:04:45.160]   There's no reason.
[00:04:45.160 --> 00:04:46.520]   I call a sake did a book.
[00:04:46.520 --> 00:04:47.680]   That's called Ape.
[00:04:47.680 --> 00:04:48.080]   Yeah.
[00:04:48.080 --> 00:04:49.000]   Yeah.
[00:04:49.000 --> 00:04:52.640]   But it's author, publisher, entrepreneur, ape.
[00:04:52.640 --> 00:04:53.800]   It's all about publishing.
[00:04:53.800 --> 00:04:56.320]   But I think it is focused maybe more on eBooks and Print.
[00:04:56.320 --> 00:04:56.800]   I don't know.
[00:04:56.800 --> 00:05:00.200]   If there are differences, maybe you should write that book,
[00:05:00.200 --> 00:05:01.200]   Rich.
[00:05:01.200 --> 00:05:03.040]   Maybe I should-- well, I mean, it's kind of unique to write
[00:05:03.040 --> 00:05:06.520]   a paperback, because the audience for this book
[00:05:06.520 --> 00:05:07.920]   kind of wants help with their iPhone.
[00:05:07.920 --> 00:05:09.040]   So it's kind of like--
[00:05:09.040 --> 00:05:11.320]   You can sit there with the paperback with your iPhone,
[00:05:11.320 --> 00:05:13.440]   which is a little bit easier than having a tablet--
[00:05:13.440 --> 00:05:14.800]   Oh, I could put your iPhone.
[00:05:14.800 --> 00:05:16.320]   No, this is--
[00:05:16.320 --> 00:05:18.160]   there are certain things you want a printed book for.
[00:05:18.160 --> 00:05:19.720]   This is one of them, absolutely.
[00:05:19.720 --> 00:05:20.680]   And people are printing out.
[00:05:20.680 --> 00:05:21.440]   I offered a PDF--
[00:05:21.440 --> 00:05:21.800]   I should be--
[00:05:21.800 --> 00:05:22.640]   I should be-- can't figure out--
[00:05:22.640 --> 00:05:22.640]   --other one.
[00:05:22.640 --> 00:05:24.080]   --turn on your phone, you know.
[00:05:24.080 --> 00:05:24.840]   Yeah.
[00:05:24.840 --> 00:05:25.960]   I talk about that.
[00:05:25.960 --> 00:05:27.960]   I talk about how to turn it off in the book, actually,
[00:05:27.960 --> 00:05:28.360]   because--
[00:05:28.360 --> 00:05:29.000]   Yeah, people don't know.
[00:05:29.000 --> 00:05:29.480]   --it didn't.
[00:05:29.480 --> 00:05:29.960]   You know?
[00:05:29.960 --> 00:05:30.800]   Yeah.
[00:05:30.800 --> 00:05:30.800]   They think.
[00:05:30.800 --> 00:05:32.640]   And then you call 911 when you try to turn it off.
[00:05:32.640 --> 00:05:34.840]   I mean, it's crazy.
[00:05:34.840 --> 00:05:37.840]   The only phone that calls 911 when you try to turn it off.
[00:05:37.840 --> 00:05:40.240]   101 Handy Tech Tips for the iPhone.
[00:05:40.240 --> 00:05:42.280]   Thank you, Rich, for the copy.
[00:05:42.280 --> 00:05:43.560]   I appreciate it.
[00:05:43.560 --> 00:05:44.080]   You're welcome.
[00:05:44.080 --> 00:05:44.600]   Enjoy.
[00:05:44.600 --> 00:05:45.840]   Nice.
[00:05:45.840 --> 00:05:46.240]   And then also--
[00:05:46.240 --> 00:05:48.120]   If you learn something, let me know.
[00:05:48.120 --> 00:05:49.320]   I will, I'm sure.
[00:05:49.320 --> 00:05:50.080]   I'm always learning.
[00:05:50.080 --> 00:05:52.000]   But that's the thing about doing a radio show, as you know,
[00:05:52.000 --> 00:05:55.160]   because Rich fills in for me when I'm on a town.
[00:05:55.160 --> 00:05:57.440]   By virtue of doing the show, you learn,
[00:05:57.440 --> 00:06:00.080]   because people will inevitably ask you stuff and you go,
[00:06:00.080 --> 00:06:00.600]   I don't know.
[00:06:00.600 --> 00:06:01.360]   Let me look at that.
[00:06:01.360 --> 00:06:02.800]   Let me do some research.
[00:06:02.800 --> 00:06:04.680]   I got to learn that one.
[00:06:04.680 --> 00:06:08.760]   Also here, he's wearing his yellow jacket.
[00:06:08.760 --> 00:06:11.400]   Patrick Bezha.
[00:06:11.400 --> 00:06:13.280]   Yeah, I don't have a car.
[00:06:13.280 --> 00:06:15.120]   I don't have a book.
[00:06:15.120 --> 00:06:18.280]   But I am in Paris and I survived this weekend.
[00:06:18.280 --> 00:06:21.040]   So I feel that qualifies me for something.
[00:06:21.040 --> 00:06:26.400]   They call these protests the Gye-Joon or yellow jacket
[00:06:26.400 --> 00:06:28.520]   protests going on right now.
[00:06:28.520 --> 00:06:30.800]   Hundreds arrests.
[00:06:30.800 --> 00:06:33.200]   Some people have died.
[00:06:33.200 --> 00:06:35.640]   Patrick is with Frenchspin.com.
[00:06:35.640 --> 00:06:39.600]   He's a French podcaster and always a welcome guest
[00:06:39.600 --> 00:06:40.640]   on the show.
[00:06:40.640 --> 00:06:44.360]   I have here in my hand an article in Buzzfeed News
[00:06:44.360 --> 00:06:45.200]   from Ryan Broderick.
[00:06:45.200 --> 00:06:47.440]   The yellow jackets, riots in France
[00:06:47.440 --> 00:06:51.680]   are what happens when Facebook gets involved with local news.
[00:06:51.680 --> 00:06:53.960]   Is that just link bait or is there
[00:06:53.960 --> 00:06:56.080]   some connection to Facebook on this?
[00:06:56.080 --> 00:06:59.480]   I mean, there's definitely unquestionably a connection
[00:06:59.480 --> 00:07:01.440]   to Facebook.
[00:07:01.440 --> 00:07:05.160]   I think the way it's being portrayed throughout the world
[00:07:05.160 --> 00:07:09.440]   is unsurprisingly a lot more dramatic than it actually is.
[00:07:09.440 --> 00:07:10.960]   And I don't want to diminish it.
[00:07:10.960 --> 00:07:12.760]   It was pretty dramatic.
[00:07:12.760 --> 00:07:14.320]   But last weekend, this weekend,
[00:07:14.320 --> 00:07:15.680]   it was a lot less.
[00:07:15.680 --> 00:07:20.080]   And certainly the yellow jackets have been organizing
[00:07:20.080 --> 00:07:20.680]   through Facebook.
[00:07:20.680 --> 00:07:24.960]   That's it's a citizen uprising movement
[00:07:24.960 --> 00:07:29.240]   that is very similar to things like Occupy Wall Street.
[00:07:29.240 --> 00:07:32.600]   They have no leader, no specific list of demands.
[00:07:32.600 --> 00:07:37.960]   And they're unhappy people who by virtue of Facebook groups,
[00:07:37.960 --> 00:07:41.000]   which is another piece of irony because Zuckerberg,
[00:07:41.000 --> 00:07:44.640]   as you remember, in the last couple of years,
[00:07:44.640 --> 00:07:47.680]   has said we're going to de-emphasize the pages
[00:07:47.680 --> 00:07:51.600]   and we're going to re-emphasize the groups
[00:07:51.600 --> 00:07:53.240]   because groups are about communities.
[00:07:53.240 --> 00:07:54.920]   So it's going to make everything better.
[00:07:54.920 --> 00:07:59.960]   And I never quite understood why groups would be better
[00:07:59.960 --> 00:08:01.680]   than pages.
[00:08:01.680 --> 00:08:04.120]   And really, they aren't.
[00:08:04.120 --> 00:08:06.360]   And it's pretty much the same thing.
[00:08:06.360 --> 00:08:09.440]   And so to get back to the question,
[00:08:09.440 --> 00:08:12.320]   there's no question that they organize through Facebook.
[00:08:12.320 --> 00:08:13.760]   It's absolutely certain.
[00:08:13.760 --> 00:08:18.320]   And that's how the movement began and keeps being fueled.
[00:08:18.320 --> 00:08:22.080]   Well, I mean, and that could be a virtue of social media.
[00:08:22.080 --> 00:08:25.320]   I mean, everybody was applauding Twitter
[00:08:25.320 --> 00:08:27.440]   when the Arab Spring happened.
[00:08:27.440 --> 00:08:31.200]   And people used both Facebook and Twitter to organize
[00:08:31.200 --> 00:08:32.760]   and overthrow the governments of Egypt
[00:08:32.760 --> 00:08:34.320]   and other Middle Eastern governments.
[00:08:34.320 --> 00:08:37.240]   I remember one of the protesters in Egypt named his daughter
[00:08:37.240 --> 00:08:40.360]   Facebook because he was so grateful to Facebook.
[00:08:40.360 --> 00:08:41.600]   At that time, everybody was saying,
[00:08:41.600 --> 00:08:43.320]   this is what's great about social media.
[00:08:43.320 --> 00:08:45.600]   And I think in this--
[00:08:45.600 --> 00:08:46.520]   Yeah.
[00:08:46.520 --> 00:08:48.920]   Yeah, and here they're using mostly Facebook,
[00:08:48.920 --> 00:08:55.360]   but I think it's important to separate the issues of violence
[00:08:55.360 --> 00:08:58.080]   that happened during the protests of violence
[00:08:58.080 --> 00:09:01.200]   that was to a level that we don't usually see
[00:09:01.200 --> 00:09:03.840]   even though we always have a little bit of it.
[00:09:03.840 --> 00:09:07.280]   And the fact that they are organizing through Facebook,
[00:09:07.280 --> 00:09:10.880]   it's not inherently bad that they're organizing through Facebook.
[00:09:10.880 --> 00:09:15.600]   It's just a movement that is being given the possibility
[00:09:15.600 --> 00:09:17.520]   of getting together.
[00:09:17.520 --> 00:09:22.920]   And I think most people in France don't--
[00:09:22.920 --> 00:09:26.000]   I mean, everyone respects their right to voice
[00:09:26.000 --> 00:09:27.120]   their discontent.
[00:09:27.120 --> 00:09:30.360]   It's a French national trait.
[00:09:30.360 --> 00:09:30.800]   It is.
[00:09:30.800 --> 00:09:32.640]   You're famous for barricades.
[00:09:32.640 --> 00:09:35.360]   You're famous for strikes.
[00:09:35.360 --> 00:09:36.800]   There's not a time I've been to France
[00:09:36.800 --> 00:09:39.200]   where somebody hasn't been on strike.
[00:09:39.200 --> 00:09:42.840]   Strikes, certainly demonstrations, yes.
[00:09:42.840 --> 00:09:46.440]   The kind of violence we've seen is not--
[00:09:46.440 --> 00:09:47.600]   especially last weekend.
[00:09:47.600 --> 00:09:50.400]   There was one weekend which was really bad.
[00:09:50.400 --> 00:09:53.440]   And that's where all of the images you see come from.
[00:09:53.440 --> 00:09:57.360]   And that is not something we are OK with.
[00:09:57.360 --> 00:10:00.440]   This weekend, the police was better organized
[00:10:00.440 --> 00:10:03.240]   and they stopped a lot of things proactively.
[00:10:03.240 --> 00:10:08.040]   And it was still a little bit bad, but not as bad.
[00:10:08.040 --> 00:10:11.360]   And I think the way we think of it is, of course,
[00:10:11.360 --> 00:10:15.360]   no one likes it when people go and loot stores and all of that.
[00:10:15.360 --> 00:10:19.560]   But every country has something that is bad,
[00:10:19.560 --> 00:10:21.520]   and that people don't like.
[00:10:21.520 --> 00:10:25.080]   But if we have to choose, it's probably something
[00:10:25.080 --> 00:10:28.360]   that is less damaging than things--
[00:10:28.360 --> 00:10:31.360]   I don't want to make it a competition.
[00:10:31.360 --> 00:10:35.160]   But when you have an issue in the US, it's mass shootings.
[00:10:35.160 --> 00:10:37.600]   And this doesn't really happen here.
[00:10:37.600 --> 00:10:41.560]   Even in these situations, we've had a few deaths.
[00:10:41.560 --> 00:10:45.800]   Maybe you can count them on one, maybe two hands.
[00:10:45.800 --> 00:10:48.880]   But those were mostly accidents, all of them
[00:10:48.880 --> 00:10:51.120]   were accidents in these kinds of issues.
[00:10:51.120 --> 00:10:53.040]   It's mostly property damage.
[00:10:53.040 --> 00:10:58.960]   And while we don't want to have to live with what happened last week,
[00:10:58.960 --> 00:11:02.880]   if a few dozen cars burn, I guess that's
[00:11:02.880 --> 00:11:05.960]   the price of being able to demonstrate.
[00:11:05.960 --> 00:11:09.200]   And that's where I would go well.
[00:11:09.200 --> 00:11:10.400]   That's how it works in France.
[00:11:10.400 --> 00:11:13.080]   But it's not as bad as things that people
[00:11:13.080 --> 00:11:16.040]   say that's how it works here in other countries.
[00:11:16.040 --> 00:11:17.760]   I guess that's how I would characterize it.
[00:11:17.760 --> 00:11:22.600]   BuzzFeed compares it to the anti-Muslim riots in Myanmar
[00:11:22.600 --> 00:11:25.000]   and Sri Lanka that were organized on Facebook.
[00:11:25.000 --> 00:11:29.840]   The lynchings and assaults that occurred in Brazil and India,
[00:11:29.840 --> 00:11:32.600]   thanks to WhatsApp.
[00:11:32.600 --> 00:11:37.520]   Clearly, we've had riots in the United States in 1967,
[00:11:37.520 --> 00:11:38.560]   and Watts and other places.
[00:11:38.560 --> 00:11:41.320]   There was no Facebook or Twitter or WhatsApp.
[00:11:41.320 --> 00:11:42.960]   Riots happen.
[00:11:42.960 --> 00:11:46.160]   But can you say that it's, to some degree, social media
[00:11:46.160 --> 00:11:49.840]   has weaponized the ability of organizers?
[00:11:49.840 --> 00:11:54.040]   Or I'll give you the BuzzFeed's timeline.
[00:11:54.040 --> 00:11:57.600]   In January, group collaire or angry groups
[00:11:57.600 --> 00:12:01.080]   started to appear across French Facebook.
[00:12:01.080 --> 00:12:04.680]   And what they do is they organize around De Parme-Mall.
[00:12:04.680 --> 00:12:07.840]   So there are many departments in France.
[00:12:07.840 --> 00:12:09.160]   And each has a number.
[00:12:09.160 --> 00:12:11.440]   And apparently, every person in France
[00:12:11.440 --> 00:12:13.440]   knows their department number.
[00:12:13.440 --> 00:12:15.520]   So these groups were set up very locally.
[00:12:15.520 --> 00:12:17.400]   And this was one thing that Facebook did do,
[00:12:17.400 --> 00:12:19.440]   the change things, as you mentioned, Patrick,
[00:12:19.440 --> 00:12:24.280]   is they prioritize local news on your news feed.
[00:12:24.280 --> 00:12:26.400]   And so these anger groups, because they were organized
[00:12:26.400 --> 00:12:28.920]   by a department, were able to take advantage of that
[00:12:28.920 --> 00:12:33.520]   and show up more often in the news feed.
[00:12:33.520 --> 00:12:37.800]   They also, you could say that memes, even false memes,
[00:12:37.800 --> 00:12:43.680]   and fake news can be promoted by these social networks.
[00:12:43.680 --> 00:12:46.400]   Facebook tweaked its algorithm, local angle groups.
[00:12:46.400 --> 00:12:48.840]   This is BuzzFeed again, spread across French fakes.
[00:12:48.840 --> 00:12:51.000]   Look at a shocking speed.
[00:12:51.000 --> 00:12:52.720]   The groups were able to organize a dozen or so
[00:12:52.720 --> 00:12:55.000]   decent sized protests last winter.
[00:12:55.000 --> 00:12:56.520]   French De Parme-Mall, and they're talking about
[00:12:56.520 --> 00:13:00.600]   the numbering scheme, you'd get anger 24 or anger 87,
[00:13:00.600 --> 00:13:04.160]   the number being the De Parme-Mall.
[00:13:04.160 --> 00:13:06.400]   By spring, the protest movement had more or less died down.
[00:13:06.400 --> 00:13:12.000]   But on May 29th, they talk about this change.org petition
[00:13:12.000 --> 00:13:18.800]   that suddenly went viral and gained at last count 1.8
[00:13:18.800 --> 00:13:23.800]   million signatures.
[00:13:23.800 --> 00:13:27.800]   For people who aren't following it, one thing I did learn
[00:13:27.800 --> 00:13:29.800]   from this article, I think the article is,
[00:13:29.800 --> 00:13:30.800]   I think you're right, Patrick.
[00:13:30.800 --> 00:13:33.800]   You can't blame Facebook for this.
[00:13:33.800 --> 00:13:35.800]   One thing I did learn from the article is that every French
[00:13:35.800 --> 00:13:40.800]   driver is required to carry a yellow safety vest in their car.
[00:13:40.800 --> 00:13:44.800]   So whoever thought this yellow jacket riot up was very smart.
[00:13:44.800 --> 00:13:50.800]   Well, I don't think it was thought that consciously.
[00:13:50.800 --> 00:13:54.800]   It was just something that came up organically, very organically.
[00:13:54.800 --> 00:14:01.800]   And the government has been somewhat unpopular with some
[00:14:01.800 --> 00:14:04.800]   portions of the population for a while.
[00:14:04.800 --> 00:14:08.800]   And it was a lot of mismanagement in communication and in
[00:14:08.800 --> 00:14:10.800]   policy implementations by the government.
[00:14:10.800 --> 00:14:13.800]   So I guess it didn't come out of nowhere.
[00:14:13.800 --> 00:14:18.800]   And it's not like these people would suddenly, if Facebook
[00:14:18.800 --> 00:14:21.800]   didn't exist, it's not like they would have all of a sudden
[00:14:21.800 --> 00:14:22.800]   have been happy about everything.
[00:14:22.800 --> 00:14:23.800]   I guess that's the question.
[00:14:23.800 --> 00:14:27.800]   Did Facebook amp it up?
[00:14:27.800 --> 00:14:29.800]   Was the presence of social networks make it worse?
[00:14:29.800 --> 00:14:34.800]   Yeah, I think what we're seeing, not just in France, but elsewhere,
[00:14:34.800 --> 00:14:40.800]   is that social networks are acting as a catalyst for what's
[00:14:40.800 --> 00:14:41.800]   happening.
[00:14:41.800 --> 00:14:45.800]   I mean, in chemistry, a catalyst doesn't actually participate
[00:14:45.800 --> 00:14:47.800]   actively in the reaction.
[00:14:47.800 --> 00:14:50.800]   You have materials, you put them together, and the presence of
[00:14:50.800 --> 00:14:52.800]   catalysts speeds up the reaction.
[00:14:52.800 --> 00:14:54.800]   I think we're seeing the same kind of thing with social
[00:14:54.800 --> 00:14:57.800]   networks where they are acting as catalysts for things that are
[00:14:57.800 --> 00:14:59.800]   already fomenting.
[00:14:59.800 --> 00:15:04.800]   Without those communications mechanisms, those reactions would
[00:15:04.800 --> 00:15:08.800]   probably still happen, but at a much slower rate and a much
[00:15:08.800 --> 00:15:10.800]   smaller scale.
[00:15:10.800 --> 00:15:12.800]   I don't know how much of it.
[00:15:12.800 --> 00:15:14.800]   Go ahead, Rich, and then...
[00:15:14.800 --> 00:15:17.800]   In the past, you'd have to see this on the news or read about it
[00:15:17.800 --> 00:15:21.800]   or be interested in it and somehow be affected enough to go out
[00:15:21.800 --> 00:15:24.800]   and join these folks and figure out where they are, where they're
[00:15:24.800 --> 00:15:26.800]   going to be, all this stuff.
[00:15:26.800 --> 00:15:28.800]   With Facebook, and especially the changes you're talking about,
[00:15:28.800 --> 00:15:30.800]   where the local news and the groups and stuff is kind of
[00:15:30.800 --> 00:15:34.800]   pushed up more prominent in your news feed, it does kind of
[00:15:34.800 --> 00:15:37.800]   lend itself to helping these things get off the ground a little
[00:15:37.800 --> 00:15:38.800]   bit more.
[00:15:38.800 --> 00:15:40.800]   I never thought I'd say this.
[00:15:40.800 --> 00:15:43.800]   But I feel sorry for Mark Zuckerberg because it seems like
[00:15:43.800 --> 00:15:45.800]   there's no move you can make that's going to make it better.
[00:15:45.800 --> 00:15:47.800]   Moving to local seemed like a good idea.
[00:15:47.800 --> 00:15:48.800]   Turn it off.
[00:15:48.800 --> 00:15:51.800]   Well, if it wasn't Facebook, it'd be Twitter.
[00:15:51.800 --> 00:15:53.800]   If it wasn't Twitter, it'd be WhatsApp.
[00:15:53.800 --> 00:15:55.800]   I mean, we have so many social networks out there.
[00:15:55.800 --> 00:15:59.800]   Not one is the one that everyone uses to do these things.
[00:15:59.800 --> 00:16:02.800]   No matter what country you're in, people are relying on some sort
[00:16:02.800 --> 00:16:04.800]   of social network to get the word out.
[00:16:04.800 --> 00:16:07.800]   And this one just happens to be Facebook and they just have
[00:16:07.800 --> 00:16:11.800]   to make those changes which kind of help this along, I think.
[00:16:11.800 --> 00:16:14.800]   Well, I think part of the problem is the scale of modern
[00:16:14.800 --> 00:16:15.800]   social networks.
[00:16:15.800 --> 00:16:19.800]   They've gotten so big and have so much reach that I think
[00:16:19.800 --> 00:16:21.800]   that's what contributes to this.
[00:16:21.800 --> 00:16:23.800]   But that's what we celebrated the internet for was the look at
[00:16:23.800 --> 00:16:25.800]   Rich used the internet to publish his own book.
[00:16:25.800 --> 00:16:28.800]   He didn't need a publisher, a musician can use the internet
[00:16:28.800 --> 00:16:29.800]   to create an album.
[00:16:29.800 --> 00:16:31.800]   You don't need a record label.
[00:16:31.800 --> 00:16:34.800]   And just in that same way, protesters can organize protests
[00:16:34.800 --> 00:16:35.800]   much more efficiently.
[00:16:35.800 --> 00:16:36.800]   That's the internet.
[00:16:36.800 --> 00:16:40.800]   Well, if you look back to the late 90s and the early 2000s,
[00:16:40.800 --> 00:16:45.800]   we had these blog rings, web blog rings, which were in a way
[00:16:45.800 --> 00:16:47.800]   social networks, but it was connecting people.
[00:16:47.800 --> 00:16:48.800]   But it was much more dispersed.
[00:16:48.800 --> 00:16:50.800]   It was much more dispersed.
[00:16:50.800 --> 00:16:52.800]   And it was much more velocity.
[00:16:52.800 --> 00:16:55.800]   There is a velocity you get nowadays.
[00:16:55.800 --> 00:16:56.800]   Right.
[00:16:56.800 --> 00:16:58.800]   That comes from that scale.
[00:16:58.800 --> 00:17:02.800]   If we didn't have that much scale, so I think having too much
[00:17:02.800 --> 00:17:06.800]   scale in social networks is probably a bad thing for society.
[00:17:06.800 --> 00:17:08.800]   Go ahead, Patrick.
[00:17:08.800 --> 00:17:10.800]   There's certainly some of that.
[00:17:10.800 --> 00:17:14.800]   And the velocity is amplified and the scale helps that.
[00:17:14.800 --> 00:17:20.800]   But I think the main difference that this has enabled with,
[00:17:20.800 --> 00:17:25.800]   you know, the difference with previous significant protests
[00:17:25.800 --> 00:17:29.800]   and movements like this is the fact that there really isn't
[00:17:29.800 --> 00:17:32.800]   a leader to direct any of it.
[00:17:32.800 --> 00:17:34.800]   And it's not like it could never happen without the leader
[00:17:34.800 --> 00:17:37.800]   before, as I mentioned, Occupy Wall Street kind of happened.
[00:17:37.800 --> 00:17:39.800]   I think I don't think the internet was a factor.
[00:17:39.800 --> 00:17:40.800]   It was laterless.
[00:17:40.800 --> 00:17:41.800]   Yeah.
[00:17:41.800 --> 00:17:45.800]   But now it's very difficult to address because there's no leader.
[00:17:45.800 --> 00:17:48.800]   There's no one person saying this is what we want.
[00:17:48.800 --> 00:17:49.800]   This is how we're going to do it.
[00:17:49.800 --> 00:17:52.800]   Like if you needed to see it on TV before, there was one or two or
[00:17:52.800 --> 00:17:55.800]   three people who would say this is what we're going to do.
[00:17:55.800 --> 00:17:59.800]   And this is where we're going to rally, to do that demonstration.
[00:17:59.800 --> 00:18:05.800]   But now it's just an agglomeration of different groups that have
[00:18:05.800 --> 00:18:10.800]   represented kind of the leaders of the pages, but there's dozens.
[00:18:10.800 --> 00:18:15.800]   And I don't think that would have happened in that way without the
[00:18:15.800 --> 00:18:16.800]   social networks.
[00:18:16.800 --> 00:18:20.800]   So the leaderless nature of it, I think is what is enabled by the social
[00:18:20.800 --> 00:18:21.800]   networks.
[00:18:21.800 --> 00:18:26.800]   And it's really important for everybody to spread rumor and
[00:18:26.800 --> 00:18:27.800]   false news.
[00:18:27.800 --> 00:18:30.800]   And again, I'm not sure this is a bad thing.
[00:18:30.800 --> 00:18:34.800]   In the past news organizations had gatekeepers and there were
[00:18:34.800 --> 00:18:37.800]   trusted sources, you know, Lamonde.
[00:18:37.800 --> 00:18:40.800]   If you didn't read it Lamonde, it wasn't real.
[00:18:40.800 --> 00:18:42.800]   That wasn't necessarily a good thing.
[00:18:42.800 --> 00:18:46.800]   I think the loss of gatekeepers has been in many ways a boon on
[00:18:46.800 --> 00:18:47.800]   the internet.
[00:18:47.800 --> 00:18:50.800]   But it also means that, well, people were in one case a fake
[00:18:50.800 --> 00:18:55.800]   news, and I was in a crime asking the Paris prosecutor to use force
[00:18:55.800 --> 00:18:56.800]   was spread everywhere.
[00:18:56.800 --> 00:18:57.800]   It was obviously fake.
[00:18:57.800 --> 00:18:58.800]   It was filled with typos.
[00:18:58.800 --> 00:18:59.800]   But it didn't matter.
[00:18:59.800 --> 00:19:02.800]   And again, it was ballistic because of social networks.
[00:19:02.800 --> 00:19:04.800]   It, yes, that certainly happens.
[00:19:04.800 --> 00:19:07.800]   And fake news is a problem here.
[00:19:07.800 --> 00:19:11.800]   Obviously, as it is in many other places in the world, I will say
[00:19:11.800 --> 00:19:15.800]   while it is a factor, I think we've developed a series of fact
[00:19:15.800 --> 00:19:22.800]   checking organizations coming out of mainstream media.
[00:19:22.800 --> 00:19:25.800]   But one is from AP, one is from Libra Sion.
[00:19:25.800 --> 00:19:30.800]   There are maybe a couple of others that now people have kind of
[00:19:30.800 --> 00:19:31.800]   gotten into the habit.
[00:19:31.800 --> 00:19:35.800]   If you're not, you know, immersed into those groups and we don't
[00:19:35.800 --> 00:19:39.800]   know how many there are, but it's probably a few, maybe a couple
[00:19:39.800 --> 00:19:40.800]   of 300,000 people.
[00:19:40.800 --> 00:19:43.800]   So it's not a huge significant part of the population.
[00:19:43.800 --> 00:19:45.800]   It's not insignificant, but it's not everyone.
[00:19:45.800 --> 00:19:49.800]   And a lot of other people have taken a habit to, before they
[00:19:49.800 --> 00:19:53.800]   believe something that seems a little bit too big, going to those
[00:19:53.800 --> 00:19:57.800]   Twitter accounts or websites and looking at those analysis.
[00:19:57.800 --> 00:20:00.800]   And they go and check stuff and make sure it happens.
[00:20:00.800 --> 00:20:02.800]   And sometimes they say, yes, this actually happened.
[00:20:02.800 --> 00:20:06.800]   There are things like someone who was injured in the demonstration
[00:20:06.800 --> 00:20:08.800]   on Saturday who lost an eye.
[00:20:08.800 --> 00:20:10.800]   And apparently it was confirmed that she did lose an eye.
[00:20:10.800 --> 00:20:15.800]   And that was, you know, kind of displayed in those groups.
[00:20:15.800 --> 00:20:18.800]   But sometimes they say, no, this actually isn't true.
[00:20:18.800 --> 00:20:22.800]   And I think a majority of the people, the population looks at
[00:20:22.800 --> 00:20:26.800]   this before forming their opinion on these things.
[00:20:26.800 --> 00:20:31.800]   So I'm not saying fake news isn't a factor, but it's maybe a
[00:20:31.800 --> 00:20:37.800]   little bit more constrained than it would be somewhere else.
[00:20:37.800 --> 00:20:40.800]   It's really, there's such a close analog between our
[00:20:40.800 --> 00:20:42.800]   presidential election Brexit.
[00:20:42.800 --> 00:20:43.800]   Absolutely.
[00:20:43.800 --> 00:20:48.800]   What's going on now, none of this would happen if people were
[00:20:48.800 --> 00:20:50.800]   genuinely upset, right?
[00:20:50.800 --> 00:20:53.800]   It's not creating these protests out of thin air.
[00:20:53.800 --> 00:20:58.800]   And I think there's absolutely, and that's something that people,
[00:20:58.800 --> 00:21:03.800]   I think like me, who are very interested in those happenings
[00:21:03.800 --> 00:21:06.800]   and who have been in the last few years, knew that there was this
[00:21:06.800 --> 00:21:08.800]   danger in France.
[00:21:08.800 --> 00:21:14.800]   But I've been astounded by how much other people, regular people,
[00:21:14.800 --> 00:21:19.800]   kind of are discovering this and don't even realize that it's
[00:21:19.800 --> 00:21:22.800]   the same movement, people who are unhappy.
[00:21:22.800 --> 00:21:26.800]   And even the president, you know, he was elected by essentially
[00:21:26.800 --> 00:21:27.800]   luck.
[00:21:27.800 --> 00:21:29.800]   He wasn't bad that he was elected also by luck.
[00:21:29.800 --> 00:21:32.800]   And I'm not going to go into the details of this, but he was.
[00:21:32.800 --> 00:21:34.800]   And you're talking about Macron.
[00:21:34.800 --> 00:21:35.800]   Not Trump, right?
[00:21:35.800 --> 00:21:36.800]   Yes, yes.
[00:21:36.800 --> 00:21:37.800]   OK.
[00:21:37.800 --> 00:21:38.800]   Macron.
[00:21:38.800 --> 00:21:39.800]   Good.
[00:21:39.800 --> 00:21:40.800]   It was a whole variation.
[00:21:40.800 --> 00:21:41.800]   Thank you.
[00:21:41.800 --> 00:21:51.800]   And the thing is, he kind of got about this situation and didn't
[00:21:51.800 --> 00:21:57.800]   address the unrest of that class of the population for two years.
[00:21:57.800 --> 00:22:01.800]   He even, he didn't handle things well.
[00:22:01.800 --> 00:22:06.800]   And now I'm kind of hoping that this is a good time for it to
[00:22:06.800 --> 00:22:10.800]   erupt because now we can't ignore it.
[00:22:10.800 --> 00:22:13.800]   Maybe there's a slim chance he can address it.
[00:22:13.800 --> 00:22:16.800]   And if he does, we kind of dodge the election bullet.
[00:22:16.800 --> 00:22:19.800]   If he doesn't, though, I don't know what's going to happen in three
[00:22:19.800 --> 00:22:22.800]   years when we get the next election because there is no one,
[00:22:22.800 --> 00:22:28.800]   no one in the current political scenery that could make for
[00:22:28.800 --> 00:22:31.800]   reasonable accepted candidate.
[00:22:31.800 --> 00:22:33.800]   And that could be very dangerous.
[00:22:33.800 --> 00:22:37.800]   But it's happening now, the unrest that you've seen for Brexit and for
[00:22:37.800 --> 00:22:41.800]   Trump, it's happening now between right in the middle of two elections.
[00:22:41.800 --> 00:22:44.800]   So maybe there's a chance it can be addressed.
[00:22:44.800 --> 00:22:47.800]   So here's my question for all three of you.
[00:22:47.800 --> 00:22:51.800]   It's really on the one hand, easy to say, oh, of course, when something bad
[00:22:51.800 --> 00:22:53.800]   happens, you're going to blame technology.
[00:22:53.800 --> 00:22:55.800]   You're going to have, you know, they'll always be blame the Russians,
[00:22:55.800 --> 00:22:57.800]   blame the blame Google, blame the tech groups.
[00:22:57.800 --> 00:22:59.800]   So there on the one hand, there's that.
[00:22:59.800 --> 00:23:04.800]   On the other hand, I think there is some evidence that these new technologies,
[00:23:04.800 --> 00:23:07.800]   in the same way that the made it possible for Rich to publish his own book
[00:23:07.800 --> 00:23:13.800]   and the, an artist to make their own CD, have also empowered people to protest
[00:23:13.800 --> 00:23:19.800]   and to, uh, election year and to change results, uh, according to their
[00:23:19.800 --> 00:23:20.800]   political positions.
[00:23:20.800 --> 00:23:24.800]   That's what we thought the internet was good for.
[00:23:24.800 --> 00:23:26.800]   There's good, there's going to be bad.
[00:23:26.800 --> 00:23:27.800]   There's tech backlash.
[00:23:27.800 --> 00:23:28.800]   It's happening right now.
[00:23:28.800 --> 00:23:35.800]   Uh, is it legitimate or is this a, is this scapegoating?
[00:23:35.800 --> 00:23:41.800]   And isn't this just the, what we expect, what we, what we celebrated the
[00:23:41.800 --> 00:23:45.800]   internet for, the chance for people to organize, to get together to, to,
[00:23:45.800 --> 00:23:48.800]   to without gatekeepers, express their opinion.
[00:23:48.800 --> 00:23:50.800]   I, I, by the way, I don't have an answer.
[00:23:50.800 --> 00:23:51.800]   I don't know what the answer is.
[00:23:51.800 --> 00:23:53.800]   I debate this all the time.
[00:23:53.800 --> 00:23:55.800]   Rich, do you think about this at all?
[00:23:55.800 --> 00:23:58.800]   You deal with real people on KTLA all the time.
[00:23:58.800 --> 00:23:59.800]   Of course.
[00:23:59.800 --> 00:24:03.800]   I mean, look, the internet has done a million amazing things and for every
[00:24:03.800 --> 00:24:06.800]   amazing thing, there have been bad things.
[00:24:06.800 --> 00:24:08.800]   And that's just the reality of any new technology.
[00:24:08.800 --> 00:24:12.800]   I mean, you have cars that get people around, but they also, uh, injure people
[00:24:12.800 --> 00:24:14.800]   and kill people every day on freeways.
[00:24:14.800 --> 00:24:17.800]   I mean, that's just the reality of anything that we have in our world.
[00:24:17.800 --> 00:24:18.800]   There's good and there's bad.
[00:24:18.800 --> 00:24:22.800]   With the internet, the way I see it is that, of course, it enables,
[00:24:22.800 --> 00:24:27.800]   in enables amazing things that, you know, bring people together and, you know,
[00:24:27.800 --> 00:24:28.800]   whatever.
[00:24:28.800 --> 00:24:31.800]   I mean, the way that we can do this show right now is thanks to the internet.
[00:24:31.800 --> 00:24:32.800]   Yes.
[00:24:32.800 --> 00:24:33.800]   I mean, yes.
[00:24:33.800 --> 00:24:35.800]   You couldn't do this without the internet.
[00:24:35.800 --> 00:24:40.800]   Uh, 10 years ago, you'd need a huge broadcast studio with millions of dollars
[00:24:40.800 --> 00:24:41.800]   of equipment.
[00:24:41.800 --> 00:24:44.800]   And now I can do this, like you said, from my house, do the book.
[00:24:44.800 --> 00:24:48.800]   Um, but on the flip side, you know, the internet enables a lot of people to come
[00:24:48.800 --> 00:24:50.800]   together in ways that we've never imagined.
[00:24:50.800 --> 00:24:54.800]   So with things like protests and stuff, uh, like I said, in the past,
[00:24:54.800 --> 00:24:56.800]   someone might have, you know, going to work.
[00:24:56.800 --> 00:24:58.800]   They don't really hear about it much.
[00:24:58.800 --> 00:25:01.800]   They kind of not really interested, but, you know, now with the internet and
[00:25:01.800 --> 00:25:04.800]   Facebook and all these things in Twitter and you're checking these feeds
[00:25:04.800 --> 00:25:08.800]   constantly, it may seem like something's bigger than it is.
[00:25:08.800 --> 00:25:09.800]   That can happen.
[00:25:09.800 --> 00:25:10.800]   That's a side effect.
[00:25:10.800 --> 00:25:12.800]   Um, something can become bigger than it is.
[00:25:12.800 --> 00:25:16.800]   And I'm not saying these protests are small or they are insignificant.
[00:25:16.800 --> 00:25:20.800]   I'm just saying that people that might be interested a little part in the past
[00:25:20.800 --> 00:25:24.800]   can now be interested a lot more because we have that ability to kind of
[00:25:24.800 --> 00:25:28.800]   follow things more closely, track things more closely, read up on them,
[00:25:28.800 --> 00:25:33.800]   research, and, you know, I think it brings more people into the fold just by the
[00:25:33.800 --> 00:25:34.800]   nature of the internet.
[00:25:34.800 --> 00:25:38.800]   Do we need Sam to do something about it or is this what you'd expect?
[00:25:38.800 --> 00:25:40.800]   And it's going to go up and down.
[00:25:40.800 --> 00:25:41.800]   The pendulum's going to swing.
[00:25:41.800 --> 00:25:45.800]   And eventually, as Patrick said, people will get wise to this and look for
[00:25:45.800 --> 00:25:49.800]   gatekeepers or fact checking sources and get sensible.
[00:25:49.800 --> 00:25:54.800]   I mean, should people be, I fear that we're going to see action of some kind.
[00:25:54.800 --> 00:25:57.800]   It looks pretty clear Congress is going to act in some way.
[00:25:57.800 --> 00:25:58.800]   Yeah.
[00:25:58.800 --> 00:26:02.800]   I think to what Rich said, you know, I think that everything we create, you know,
[00:26:02.800 --> 00:26:06.800]   no matter how benign it might seem, can be used for good or for bad.
[00:26:06.800 --> 00:26:12.800]   You know, I mean, you take a rock, you know, back in, you know, long before
[00:26:12.800 --> 00:26:14.800]   civilization, you know, somebody figured out you can use a rock to create a
[00:26:14.800 --> 00:26:16.800]   rock, you can use a rock to crack open a coconut.
[00:26:16.800 --> 00:26:19.800]   And then they figured out you can use a rock to crack open somebody's head.
[00:26:19.800 --> 00:26:20.800]   Right.
[00:26:20.800 --> 00:26:24.800]   You know, so anything that we build or that we find that we can use as a tool
[00:26:24.800 --> 00:26:27.800]   can be used for positive or negative.
[00:26:27.800 --> 00:26:29.800]   Would you advocate at this point?
[00:26:29.800 --> 00:26:32.800]   Hey, it's just the way it is.
[00:26:32.800 --> 00:26:33.800]   Let it happen.
[00:26:33.800 --> 00:26:34.800]   Or would you advocate regulation?
[00:26:34.800 --> 00:26:39.800]   Do we need to think about the negative consequences and try to mitigate those?
[00:26:39.800 --> 00:26:41.800]   Or is it just or is that a mistake?
[00:26:41.800 --> 00:26:44.800]   No, sometimes people say any regulation of the internet would be a mistake because
[00:26:44.800 --> 00:26:46.800]   there's no way you could really do it right.
[00:26:46.800 --> 00:26:52.800]   I think we'd be foolish to not consider ways that we can mitigate the bad, you know,
[00:26:52.800 --> 00:26:55.800]   again, whether it's the internet or any other technology, we always need to think
[00:26:55.800 --> 00:27:00.800]   about, you know, how can this be used and try to amplify the things that it can
[00:27:00.800 --> 00:27:05.800]   be done that can be used for good and where possible, you know, where we can figure
[00:27:05.800 --> 00:27:09.800]   out how we can, how we can mitigate the bad impacts of it.
[00:27:09.800 --> 00:27:17.800]   And so I think that we do need to take some serious look at how some of this
[00:27:17.800 --> 00:27:22.800]   technology, you know, social networks have grown and evolved over the last 10, 15
[00:27:22.800 --> 00:27:23.800]   years.
[00:27:23.800 --> 00:27:27.800]   And what can we do to mitigate those negative impacts?
[00:27:27.800 --> 00:27:29.800]   Because I think there are things that come up with.
[00:27:29.800 --> 00:27:31.800]   Well, yeah, it was easy.
[00:27:31.800 --> 00:27:32.800]   Yeah.
[00:27:32.800 --> 00:27:33.800]   And who decides?
[00:27:33.800 --> 00:27:35.800]   I mean, that's the other part of this is like who does, I mean, I get it.
[00:27:35.800 --> 00:27:39.800]   There are certain things that we might all agree on that we don't want to see or
[00:27:39.800 --> 00:27:41.800]   we don't want to have on these networks.
[00:27:41.800 --> 00:27:45.800]   But when it comes to everything else, it's like, well, if I want to post the most
[00:27:45.800 --> 00:27:49.800]   crazy story ever that's totally made up, why am I not allowed to do that?
[00:27:49.800 --> 00:27:53.800]   And, you know, that should not be voted by the people, whether they look at it or
[00:27:53.800 --> 00:27:54.800]   not look at it.
[00:27:54.800 --> 00:27:57.800]   And, you know, Facebook says, sorry, you can't have that on there.
[00:27:57.800 --> 00:27:59.800]   It's like, well, what if that's my job?
[00:27:59.800 --> 00:28:03.800]   What if I become the most famous, you know, satirical writer in the world because
[00:28:03.800 --> 00:28:05.800]   of the stuff that I post, as long as it's not harming anyone?
[00:28:05.800 --> 00:28:08.800]   I mean, that's where we get into like, you know, how do you decide?
[00:28:08.800 --> 00:28:11.800]   And if it's a government doing it, I mean, there's some people that don't
[00:28:11.800 --> 00:28:14.800]   want the government doing it or even coming up with those regulations to do it.
[00:28:14.800 --> 00:28:18.800]   And Facebook has tried to do all this stuff and clearly they've failed in a lot of
[00:28:18.800 --> 00:28:19.800]   ways.
[00:28:19.800 --> 00:28:23.800]   I think the fundamental thing that we all need to do, I think everybody needs to
[00:28:23.800 --> 00:28:26.800]   take more responsibility for the information that they take in.
[00:28:26.800 --> 00:28:32.800]   And, you know, I think one of the real failings is not necessarily how the
[00:28:32.800 --> 00:28:39.800]   social networks have evolved, but not really teaching people to think critically
[00:28:39.800 --> 00:28:44.800]   enough about everything, you know, whether it's fake news or anything else.
[00:28:44.800 --> 00:28:46.800]   We don't do enough critical thinking.
[00:28:46.800 --> 00:28:52.800]   And I think ultimately the part of the solution, you know, I don't know all the
[00:28:52.800 --> 00:28:56.800]   answers, but I think part of the solution is to really do, you know,
[00:28:56.800 --> 00:29:01.800]   teach people, especially teach kids more critical thinking to really
[00:29:01.800 --> 00:29:06.800]   analyze what they're taking in and see if it really makes sense or not.
[00:29:06.800 --> 00:29:09.800]   Patrick, you're right in the middle of this right now.
[00:29:09.800 --> 00:29:14.800]   I mean, you know, as much as people in the United States are upset by the
[00:29:14.800 --> 00:29:18.800]   election, people in Britain upset by Brexit, I imagine the people of France are upset.
[00:29:18.800 --> 00:29:19.800]   What's going on?
[00:29:19.800 --> 00:29:21.800]   What's your take on this?
[00:29:21.800 --> 00:29:22.800]   You're right in the middle of it.
[00:29:22.800 --> 00:29:24.800]   So I will say two things.
[00:29:24.800 --> 00:29:29.800]   First, I think I agree with what you were saying earlier, both of you, yes,
[00:29:29.800 --> 00:29:31.800]   technology can be used in good and bad ways.
[00:29:31.800 --> 00:29:34.800]   The difference here, at least for us tech enthusiasts, we thought the
[00:29:34.800 --> 00:29:36.800]   internet was going to be only good.
[00:29:36.800 --> 00:29:38.800]   Yeah, we were clearly misguided.
[00:29:38.800 --> 00:29:39.800]   We were not.
[00:29:39.800 --> 00:29:40.800]   We were not.
[00:29:40.800 --> 00:29:41.800]   We were not.
[00:29:41.800 --> 00:29:42.800]   Naive is a good idea.
[00:29:42.800 --> 00:29:44.800]   And I think that's a little bit of a difference because when you see, you know,
[00:29:44.800 --> 00:29:48.800]   nuclear power, you think, yeah, that probably is going to be turned into a
[00:29:48.800 --> 00:29:51.800]   bomb, but we didn't see this happening for tech.
[00:29:51.800 --> 00:29:53.800]   We thought it was going to be everyone's going to have a voice.
[00:29:53.800 --> 00:29:54.800]   It's going to be wonderful.
[00:29:54.800 --> 00:29:55.800]   It's going to self-regulate.
[00:29:55.800 --> 00:29:56.800]   I was one of the chief leaders.
[00:29:56.800 --> 00:29:57.800]   Yeah, absolutely.
[00:29:57.800 --> 00:29:58.800]   And we all were.
[00:29:58.800 --> 00:30:03.800]   The other thing is I need to take you guys to task a little bit and you,
[00:30:03.800 --> 00:30:07.800]   Leo, and essentially the entirety of America.
[00:30:07.800 --> 00:30:10.800]   That's a small task I've assigned to myself.
[00:30:10.800 --> 00:30:15.800]   But I'm the first player in socialist European socialist that's
[00:30:15.800 --> 00:30:16.800]   the case for a second.
[00:30:16.800 --> 00:30:18.800]   Yes, everybody, open your minds.
[00:30:18.800 --> 00:30:20.800]   Listen to what Patrick has to say.
[00:30:20.800 --> 00:30:25.800]   I think you, on an intellectual level, you sometimes think, as you just did,
[00:30:25.800 --> 00:30:28.800]   Leo, oh, do we need to regulate?
[00:30:28.800 --> 00:30:32.800]   Maybe sometimes we kind of should regulate some things with a light touch.
[00:30:32.800 --> 00:30:39.800]   And then anytime you talk about anything concrete, you then almost instinctively,
[00:30:39.800 --> 00:30:43.800]   I think this is an American trait, kind of go, oh, but we don't want the
[00:30:43.800 --> 00:30:44.800]   government to be involved in anything.
[00:30:44.800 --> 00:30:49.800]   And so you went up with situations where, you know, the, the
[00:30:49.800 --> 00:30:55.800]   capitalistic societies, capitalistic enterprises sometimes need to be regulated.
[00:30:55.800 --> 00:31:01.800]   One example would be the, and I know this is controversial, but the telecom
[00:31:01.800 --> 00:31:05.800]   industry in the US, there is something that isn't working because it's not being
[00:31:05.800 --> 00:31:09.800]   pushed in the right direction for competition, which is the essence of
[00:31:09.800 --> 00:31:11.800]   capitalism to work properly.
[00:31:11.800 --> 00:31:13.800]   So that would be one example.
[00:31:13.800 --> 00:31:17.800]   Another one I use often reference the GDPR.
[00:31:17.800 --> 00:31:25.800]   And whenever someone references that, you immediately go to the admittedly real
[00:31:25.800 --> 00:31:30.800]   inconvenience of having to click all of the banners that you have to click on
[00:31:30.800 --> 00:31:31.800]   when you visit websites in Europe.
[00:31:31.800 --> 00:31:32.800]   And it is annoying.
[00:31:32.800 --> 00:31:33.800]   And it is probably--
[00:31:33.800 --> 00:31:34.800]   Or any website.
[00:31:34.800 --> 00:31:35.800]   This point.
[00:31:35.800 --> 00:31:36.800]   Yeah, it's every website.
[00:31:36.800 --> 00:31:37.800]   Oh, it's everywhere.
[00:31:37.800 --> 00:31:38.800]   Yes.
[00:31:38.800 --> 00:31:39.800]   I agree.
[00:31:39.800 --> 00:31:40.800]   It's very annoying.
[00:31:40.800 --> 00:31:41.800]   It's probably not possible.
[00:31:41.800 --> 00:31:42.800]   I blame you for that, Patrick.
[00:31:42.800 --> 00:31:47.800]   And so you should. But there are also other positive aspects of GDPR.
[00:31:47.800 --> 00:31:49.800]   You know, the fact your data is portable.
[00:31:49.800 --> 00:31:50.800]   You can download it.
[00:31:50.800 --> 00:31:51.800]   You can delete your accounts.
[00:31:51.800 --> 00:31:55.800]   You can-- And this isn't the companies that woke up one day and who thought,
[00:31:55.800 --> 00:31:57.800]   "Oh, we really should do that."
[00:31:57.800 --> 00:31:58.800]   No.
[00:31:58.800 --> 00:32:04.800]   It's the governments that decided this should be addressed in that way.
[00:32:04.800 --> 00:32:09.800]   The right to be forgotten, for example, you probably remember this.
[00:32:09.800 --> 00:32:16.800]   Essentially, France and the EU, I believe, have imposed on Google removing links
[00:32:16.800 --> 00:32:21.800]   from the search engine if someone estimates that they are not--
[00:32:21.800 --> 00:32:25.800]   They shouldn't be appearing anymore because it's old news, old stuff.
[00:32:25.800 --> 00:32:27.800]   They've changed.
[00:32:27.800 --> 00:32:30.800]   And we all thought, me included, that that was going to be, you know,
[00:32:30.800 --> 00:32:31.800]   censoring free speech.
[00:32:31.800 --> 00:32:36.800]   And it was going to have dramatic consequences on the way the Internet works.
[00:32:36.800 --> 00:32:37.800]   Blah, blah, blah.
[00:32:37.800 --> 00:32:39.800]   It's been implemented for a few years now.
[00:32:39.800 --> 00:32:45.800]   And we've seen that by Google's own account, I mean, we haven't seen a giant scandal coming out of it.
[00:32:45.800 --> 00:32:47.800]   It seems to be working reasonably well.
[00:32:47.800 --> 00:32:50.800]   Certainly, there might be some issues here and there.
[00:32:50.800 --> 00:32:56.800]   But wait, if you're Google, you may not agree with that because it's a great cost and effort on Google's part.
[00:32:56.800 --> 00:32:59.800]   And to me, that is a poster child.
[00:32:59.800 --> 00:33:03.800]   The right to be forgotten is the poster child for regulation gone wrong.
[00:33:03.800 --> 00:33:09.800]   In so many ways, it blames Google, the search engine, for content on the Internet.
[00:33:09.800 --> 00:33:12.800]   And it says Google's responsible for purging it, not the original--
[00:33:12.800 --> 00:33:13.800]   Your creator of it.
[00:33:13.800 --> 00:33:14.800]   Your creator of it.
[00:33:14.800 --> 00:33:16.800]   It makes no sense at all.
[00:33:16.800 --> 00:33:20.800]   Yes, you're treating the symptom instead of the cause.
[00:33:20.800 --> 00:33:21.800]   I agree.
[00:33:21.800 --> 00:33:22.800]   But the cause is impossible to treat.
[00:33:22.800 --> 00:33:24.800]   Well, then, you can't treat it.
[00:33:24.800 --> 00:33:25.800]   And sometimes the best thing you can do.
[00:33:25.800 --> 00:33:31.800]   When you have a headache caused by something, first, you might take, you know,
[00:33:31.800 --> 00:33:35.800]   aspirin to treat the headache.
[00:33:35.800 --> 00:33:38.800]   And you don't care that it's just treating the symptoms.
[00:33:38.800 --> 00:33:40.800]   My point is sometimes regulation is necessary.
[00:33:40.800 --> 00:33:46.800]   You have Microsoft now calling for regulation of facial recognition.
[00:33:46.800 --> 00:33:53.800]   Yeah, but I think mostly because these big companies recognize it's coming and they would like to steer it in a direction that's less dangerous to them.
[00:33:53.800 --> 00:33:55.800]   That's what's really happening.
[00:33:55.800 --> 00:33:57.800]   These companies don't want any regulation.
[00:33:57.800 --> 00:34:05.800]   But when Tim Cook says, "Yeah, we need regulation," he's saying, "We need regulation that's weakened steer rather than what might happen if we just let Congress decide."
[00:34:05.800 --> 00:34:07.800]   I think GDPR, you're absolutely right.
[00:34:07.800 --> 00:34:08.800]   There are benefits.
[00:34:08.800 --> 00:34:12.800]   We wouldn't know about the Marriott break-in if it weren't for GDPR.
[00:34:12.800 --> 00:34:13.800]   They would have buried it.
[00:34:13.800 --> 00:34:20.800]   But GDPR has such a severe penalty and such a short time frame for revealing breaches that they had to reveal it.
[00:34:20.800 --> 00:34:23.800]   And I think you could point to a lot of good Dutch I-GPR.
[00:34:23.800 --> 00:34:27.800]   I don't think you could point to any good done by the right to be forgotten.
[00:34:27.800 --> 00:34:35.800]   And the fact that Google has just absorbed the burden of this silently and it doesn't mean that it's not a bad law.
[00:34:35.800 --> 00:34:39.800]   But do you agree that it didn't destroy the internet?
[00:34:39.800 --> 00:34:40.800]   It didn't.
[00:34:40.800 --> 00:34:42.800]   Not yet.
[00:34:42.800 --> 00:34:45.800]   Well, we got to take a break.
[00:34:45.800 --> 00:34:51.800]   I'm going to propose another poster child for a bad law.
[00:34:51.800 --> 00:34:57.800]   And that is Fosta and Cesta, which was signed to law into law in March by President Trump.
[00:34:57.800 --> 00:35:00.800]   It had a great name, Stop Enabling Sex Traffickers Act.
[00:35:00.800 --> 00:35:06.800]   But I think we're starting to see the severe and unintended consequences of this.
[00:35:06.800 --> 00:35:08.800]   And I want to talk about that in a little bit.
[00:35:08.800 --> 00:35:10.800]   But it's the same conversation.
[00:35:10.800 --> 00:35:13.800]   It's whether it's possible to regulate the internet.
[00:35:13.800 --> 00:35:27.800]   It feels to me almost like an impedance mismatch that you have institutions that are designed to move slowly, deliberately, intelligently, to create laws to protect common good.
[00:35:27.800 --> 00:35:34.800]   Versus a business ecosystem that's designed to break things and move fast.
[00:35:34.800 --> 00:35:38.800]   And here's another poster child.
[00:35:38.800 --> 00:35:48.800]   What the DOJ did to Microsoft or in Europe, what the EU did to Microsoft in the antitrust decisions, creating a browser ballot.
[00:35:48.800 --> 00:35:50.800]   I didn't have to put up with that, but you did, Patrick.
[00:35:50.800 --> 00:35:54.800]   Anytime you installed Windows, you had to vote for the browser you wanted to use.
[00:35:54.800 --> 00:35:55.800]   Did nothing.
[00:35:55.800 --> 00:35:58.800]   Accomplished nothing was too little, too late.
[00:35:58.800 --> 00:36:03.800]   So there are some, I think prime examples of why it's very difficult for governments to get this right.
[00:36:03.800 --> 00:36:08.800]   But I could give you another couple, the Windows N that didn't have Windows Media Player.
[00:36:08.800 --> 00:36:09.800]   Yeah.
[00:36:09.800 --> 00:36:13.800]   Which Microsoft sold the same price as the one that did.
[00:36:13.800 --> 00:36:14.800]   Yes, I agree.
[00:36:14.800 --> 00:36:24.800]   The point I was trying to make is sometimes regulation might be necessary, but you all immediately go from maybe to, oh, this is bad.
[00:36:24.800 --> 00:36:25.800]   This is bad.
[00:36:25.800 --> 00:36:26.800]   Oh, no, don't government.
[00:36:26.800 --> 00:36:27.800]   Don't touch it.
[00:36:27.800 --> 00:36:28.800]   No universal Patrick.
[00:36:28.800 --> 00:36:35.800]   There is definitely a strain in the American, you know, kind of psyche against government.
[00:36:35.800 --> 00:36:41.800]   And just the same, as I think it said, that in Europe there's a strain against corporations and a trust of government.
[00:36:41.800 --> 00:36:44.800]   But that is not universal by any means in the United States.
[00:36:44.800 --> 00:36:52.800]   And I think a lot of sensible, sane people at this point in the US and all around the world are saying, well, okay, there are definitely negatives.
[00:36:52.800 --> 00:37:00.800]   This is what I was asking to technology. Is it possible to make a sane law to mitigate those?
[00:37:00.800 --> 00:37:17.800]   Well, pay attention in the next few months when you talk about regulation and see if you don't all in the panel around the table end up on the conclusion that you probably, that you will, you know, you think all of the regulation you're talking about, regulations you're talking about, ended up being bad.
[00:37:17.800 --> 00:37:21.800]   And I think that's a pretty significant.
[00:37:21.800 --> 00:37:26.800]   I'll give you regulations that everybody would agree were good. And Samuel and all about this seat belts.
[00:37:26.800 --> 00:37:32.800]   I mean, the US government has done a great job to take a very dangerous thing and make it a little bit less dangerous driving.
[00:37:32.800 --> 00:37:37.800]   Yeah, I mean, we're managing just progress on automotive safety and emissions and fuel economy over the last 50 years.
[00:37:37.800 --> 00:37:38.800]   Huge air travel.
[00:37:38.800 --> 00:37:41.800]   I mean, air travel regulations in America are amazing.
[00:37:41.800 --> 00:37:43.800]   I was talking about the internet, but...
[00:37:43.800 --> 00:37:44.800]   Well, that's the problem.
[00:37:44.800 --> 00:37:52.800]   Yeah, there are some things you can regulate. You can say we want to have clean, safe drinking water and make that a regulation.
[00:37:52.800 --> 00:37:53.800]   No, we don't need that.
[00:37:53.800 --> 00:37:55.800]   Well, except in Flint, Michigan.
[00:37:55.800 --> 00:37:57.800]   But that's drinking water is so much easier. I mean, it's just...
[00:37:57.800 --> 00:37:58.800]   That's exactly it.
[00:37:58.800 --> 00:38:05.800]   So that's the thing. Drinking water is simple. It's like, it's 50/50. It's either cut or dry. You know, it's like...
[00:38:05.800 --> 00:38:10.800]   It's just there. You know, it's clean. It's clear. It tests for certain things.
[00:38:10.800 --> 00:38:15.800]   Internet, you can apply these same rules that you never have been able to do that. And I think that's why it's so complicated.
[00:38:15.800 --> 00:38:20.800]   And I don't think that in America, we just say, "Oh, government, it's bad just because the government's doing it."
[00:38:20.800 --> 00:38:27.800]   And like Leo said, yes, there are certain people that do believe that. But the nature of the Internet is so complicated.
[00:38:27.800 --> 00:38:33.800]   That no matter anything that you apply to it, almost doesn't work for everything that happens on the Internet.
[00:38:33.800 --> 00:38:35.800]   And that's the trick here.
[00:38:35.800 --> 00:38:37.800]   And it was almost everything that...
[00:38:37.800 --> 00:38:42.800]   I agree with almost everything that Patrick said, although I will take issue with the right to be forgotten.
[00:38:42.800 --> 00:38:44.800]   But everything else, I do agree with you.
[00:38:44.800 --> 00:38:56.800]   I think the fundamental problem here in the U.S. is that we have legislators that fundamentally don't understand the technology.
[00:38:56.800 --> 00:39:02.800]   And they're not in a position to do thoughtful regulation.
[00:39:02.800 --> 00:39:16.800]   All you have to do is look at how they... When they have hearings, they go out there and they are completely clueless when they're talking to somebody like Mark Zuckerberg or any of the other technology people that they bring in.
[00:39:16.800 --> 00:39:22.800]   You've got a bunch of old white guys that... No offense, Leo, but they...
[00:39:22.800 --> 00:39:24.800]   Oh, as an old white guy.
[00:39:24.800 --> 00:39:30.800]   Well, older white guys that just don't even have a clue.
[00:39:30.800 --> 00:39:35.800]   And they couldn't write a decent regulation for this if they tried.
[00:39:35.800 --> 00:39:46.800]   And even when they try to do something simple, that would seem to be more straightforward, they seem to be incapable of doing it in a thoughtful manner, which is something you need to do for regulation.
[00:39:46.800 --> 00:39:50.800]   I think there's an even bigger problem in the United States, which is that we have the best Congress money can run.
[00:39:50.800 --> 00:39:55.800]   And that's what I was going to say now, because there's way too much companies have a lot of money.
[00:39:55.800 --> 00:40:03.800]   It's not just them, but big corporations in general, we have too many really big corporations that have way too much influence on the political system in this country.
[00:40:03.800 --> 00:40:04.800]   That's the real thing.
[00:40:04.800 --> 00:40:06.800]   To me, that's a bigger problem than it led to kids' senators.
[00:40:06.800 --> 00:40:07.800]   You can learn...
[00:40:07.800 --> 00:40:17.800]   You can have staffers that have a bigger staff and they do have smart staff and they're going to be younger members of Congress coming in in January and there's going to be younger senators someday, maybe in 100 years.
[00:40:17.800 --> 00:40:20.800]   But that's not the biggest problem to us.
[00:40:20.800 --> 00:40:21.800]   You know, you've got some young people.
[00:40:21.800 --> 00:40:22.800]   Members of Congress.
[00:40:22.800 --> 00:40:23.800]   I'm not joking about it.
[00:40:23.800 --> 00:40:25.800]   This is a severe issue in the United States.
[00:40:25.800 --> 00:40:26.800]   When you see...
[00:40:26.800 --> 00:40:37.800]   Yeah, I know you want to go to break, but just to keep it very short, this is another thing that you guys do, which you discredit any work of the government by these comments.
[00:40:37.800 --> 00:40:42.800]   I think the hearings of Zuckerberg were not all clueless.
[00:40:42.800 --> 00:40:45.800]   Some of them did ask a genuine question.
[00:40:45.800 --> 00:40:53.800]   Some of them maybe for re-election purposes, but some of them were interesting and significant questions.
[00:40:53.800 --> 00:41:11.800]   The format wasn't adapted to answering them, but that's, by the way, Patrick, that's the tool that was used by these lobbyists and the members of the Senate to make sure that Mark Zuckerberg never really was put into the law.
[00:41:11.800 --> 00:41:16.800]   And this is why Mark is not going to go to the EU because those rules won't apply.
[00:41:16.800 --> 00:41:18.800]   There will be follow-up questions.
[00:41:18.800 --> 00:41:20.800]   There will be tough questions asked.
[00:41:20.800 --> 00:41:31.800]   And so you structurally saw exactly the problem in the US Senate, which is he wasn't going to be asked any tough questions because the rules for the conversation were set in such a way that he couldn't be.
[00:41:31.800 --> 00:41:32.800]   And there was no...
[00:41:32.800 --> 00:41:33.800]   I'll show you five minutes.
[00:41:33.800 --> 00:41:35.800]   You had five minutes and no time for follow-up.
[00:41:35.800 --> 00:41:36.800]   And that's the problem.
[00:41:36.800 --> 00:41:37.800]   That's the influence of money.
[00:41:37.800 --> 00:41:38.800]   It's very subtle.
[00:41:38.800 --> 00:41:43.800]   But that's why Mark isn't going to go to the EU to testify, is he?
[00:41:43.800 --> 00:41:45.800]   Well, I mean, he won't go to the UK.
[00:41:45.800 --> 00:41:55.800]   I'm going to shoot myself in the foot here and say that the EU hearings were even worse because they all asked the questions at once for like half an hour and then he answered whatever he wanted.
[00:41:55.800 --> 00:41:57.800]   Okay, that's not good either.
[00:41:57.800 --> 00:41:59.800]   But at least...
[00:41:59.800 --> 00:42:00.800]   But yeah, right.
[00:42:00.800 --> 00:42:05.800]   It's the UK commissioners he doesn't want to talk to because he knows he will be really called on the carpet for that.
[00:42:05.800 --> 00:42:08.800]   And he is refused consistently to go there.
[00:42:08.800 --> 00:42:10.800]   And it's not because it's such a long flight, I don't think.
[00:42:10.800 --> 00:42:13.800]   I think he could get a good nice, life-flat sleep, life-at sleep.
[00:42:13.800 --> 00:42:14.800]   Yeah.
[00:42:14.800 --> 00:42:15.800]   You see.
[00:42:15.800 --> 00:42:16.800]   Patrick, I'm so glad you're here.
[00:42:16.800 --> 00:42:17.800]   You could not be here on a better week.
[00:42:17.800 --> 00:42:19.800]   And I'm thrilled that you're here.
[00:42:19.800 --> 00:42:23.800]   Patrick podcasts in French and English at Frenchspin.com.
[00:42:23.800 --> 00:42:26.800]   And he's a long time regular on our shows.
[00:42:26.800 --> 00:42:27.800]   We always love having you on.
[00:42:27.800 --> 00:42:28.800]   Thank you, Patrick.
[00:42:28.800 --> 00:42:31.800]   Do you have a red, yellow vest in your car?
[00:42:31.800 --> 00:42:38.800]   Or is it...I hit it for the purposes of this show because I didn't want to read my truth all this.
[00:42:38.800 --> 00:42:42.800]   Patrick has been secretly leading the charge in France here.
[00:42:42.800 --> 00:42:43.800]   Just tell us.
[00:42:43.800 --> 00:42:45.800]   Because you think I'm playing devil's advocate here.
[00:42:45.800 --> 00:42:46.800]   I want to convince you.
[00:42:46.800 --> 00:42:50.800]   We don't actually get any sense of what's really going on in Europe.
[00:42:50.800 --> 00:42:52.800]   That's another flaw in the United States.
[00:42:52.800 --> 00:42:54.800]   What are the protests about?
[00:42:54.800 --> 00:42:56.800]   It's not about gas prices per se, is it?
[00:42:56.800 --> 00:43:00.800]   Well, it's started with that, but it was the straw that broke the camel's back.
[00:43:00.800 --> 00:43:10.800]   Honestly, one of the issues with that citizens, whatever unrest protest uprising, is that we don't know exactly what they want.
[00:43:10.800 --> 00:43:15.800]   And they all profess, they all claim that they don't speak for the entire movement.
[00:43:15.800 --> 00:43:17.800]   This is so much like Occupy Wall Street.
[00:43:17.800 --> 00:43:18.800]   Yes.
[00:43:18.800 --> 00:43:19.800]   It's exactly the same.
[00:43:19.800 --> 00:43:20.800]   What did they want?
[00:43:20.800 --> 00:43:21.800]   I don't know, but they were there.
[00:43:21.800 --> 00:43:23.800]   It's the downside of a decentralized protest.
[00:43:23.800 --> 00:43:24.800]   Right.
[00:43:24.800 --> 00:43:25.800]   In my turn.
[00:43:25.800 --> 00:43:26.800]   It was the solution.
[00:43:26.800 --> 00:43:27.800]   It was the solution.
[00:43:27.800 --> 00:43:28.800]   It was the clear sound bites.
[00:43:28.800 --> 00:43:29.800]   You know what I mean?
[00:43:29.800 --> 00:43:30.800]   We had chance.
[00:43:30.800 --> 00:43:32.800]   Ho, ho, ho, cheap men.
[00:43:32.800 --> 00:43:33.800]   We knew.
[00:43:33.800 --> 00:43:35.800]   Hey, hey, LBJ.
[00:43:35.800 --> 00:43:37.800]   How many kids did you kill today?
[00:43:37.800 --> 00:43:39.800]   That's from my ear.
[00:43:39.800 --> 00:43:40.800]   Wow.
[00:43:40.800 --> 00:43:42.800]   Well, they have slogans.
[00:43:42.800 --> 00:43:44.800]   Just, you know, unrealistic.
[00:43:44.800 --> 00:43:46.800]   They're in French, so we can't.
[00:43:46.800 --> 00:43:48.800]   We don't know what they're saying.
[00:43:48.800 --> 00:43:49.800]   What is the French?
[00:43:49.800 --> 00:43:50.800]   They barely speak English.
[00:43:50.800 --> 00:43:52.800]   What are they chanting in French?
[00:43:52.800 --> 00:43:58.800]   Well, I think the biggest one is Macron de Mecion, which is Macron Resign.
[00:43:58.800 --> 00:44:03.800]   And some of them want a general that was fired to become president.
[00:44:03.800 --> 00:44:07.800]   Some of them want like it's, it's, they're expressing anger.
[00:44:07.800 --> 00:44:10.800]   It's like, you know, because it's the same thing that happened in the United States
[00:44:10.800 --> 00:44:11.800]   in 2016.
[00:44:11.800 --> 00:44:17.800]   It was a generalized anger, a variety of different causes, but it was an uprising of sorts.
[00:44:17.800 --> 00:44:21.800]   And it was people showing their, you know, this, that we don't like the way the world's
[00:44:21.800 --> 00:44:22.800]   gone.
[00:44:22.800 --> 00:44:23.800]   Exactly.
[00:44:23.800 --> 00:44:24.800]   Yeah.
[00:44:24.800 --> 00:44:29.800]   Let's take a little tiny time out also with a Sam Eble cement, who is, of course, my car
[00:44:29.800 --> 00:44:32.800]   guy, senior analyst at Navigant Research.
[00:44:32.800 --> 00:44:34.400]   I feel like you're almost my pimp.
[00:44:34.400 --> 00:44:36.560]   You bring me great cars to drive.
[00:44:36.560 --> 00:44:40.640]   I just drove the Jaguar I-Pays and I really enjoyed driving it, but you've got to bring
[00:44:40.640 --> 00:44:44.800]   me that new Porsche Taycan, because I want to try that.
[00:44:44.800 --> 00:44:47.800]   Or Taycan, as they, as they say, T-A-Y-C-A-N.
[00:44:47.800 --> 00:44:49.800]   As soon as we can get our hands on one.
[00:44:49.800 --> 00:44:50.800]   Yeah.
[00:44:50.800 --> 00:44:51.800]   You can use my name if you want.
[00:44:51.800 --> 00:44:52.800]   Okay.
[00:44:52.800 --> 00:44:54.800]   I know an old white guy, you can say.
[00:44:54.800 --> 00:44:55.800]   All right.
[00:44:55.800 --> 00:44:59.240]   So do they take it from this old white guy?
[00:44:59.240 --> 00:45:01.160]   This is a good time to invest.
[00:45:01.160 --> 00:45:02.260]   You're going to say, what Leo?
[00:45:02.260 --> 00:45:03.260]   Are you kidding?
[00:45:03.260 --> 00:45:04.420]   Yes, it is.
[00:45:04.420 --> 00:45:08.800]   And I'm going to tell you the best way to do it with Robinhood, an investing app that
[00:45:08.800 --> 00:45:15.400]   lets you buy and sell all kinds of investment vehicles, not just stocks, but ETFs.
[00:45:15.400 --> 00:45:17.040]   That's exchange traded funds.
[00:45:17.040 --> 00:45:20.640]   That's a very popular form of equity these days.
[00:45:20.640 --> 00:45:24.280]   Funds, even cryptocurrency.
[00:45:24.280 --> 00:45:27.000]   And the best thing about Robinhood, this is the future of trading.
[00:45:27.000 --> 00:45:27.920]   It's commission-free.
[00:45:27.920 --> 00:45:33.200]   They're trying to make financial services work for everyone, not just the wealthy.
[00:45:33.200 --> 00:45:36.000]   The Robinhood app is awesome.
[00:45:36.000 --> 00:45:40.400]   It's a non-intimidating way for stock market newcomers to invest for the first time with
[00:45:40.400 --> 00:45:42.360]   real confidence.
[00:45:42.360 --> 00:45:44.000]   It's simple, it's intuitive.
[00:45:44.000 --> 00:45:49.560]   The data is presented in a way you can understand clearly and yet it's real hardcore data.
[00:45:49.560 --> 00:45:52.800]   So for the first time you'll go, oh, I get it.
[00:45:52.800 --> 00:45:53.800]   And no commission fees.
[00:45:53.800 --> 00:45:55.080]   I don't even know how they do this.
[00:45:55.080 --> 00:45:59.440]   You know, brokerage typically will charge as much as $10 for every trade that takes a
[00:45:59.440 --> 00:46:02.160]   huge chunk out of your earnings if you make money.
[00:46:02.160 --> 00:46:04.800]   But Robinhood charges no commission fees.
[00:46:04.800 --> 00:46:08.320]   You can, you'd be crazy to use any other platform.
[00:46:08.320 --> 00:46:11.640]   Trade stocks keep 100% of your profits.
[00:46:11.640 --> 00:46:15.040]   In fact, I bet you, I can read your mind right now.
[00:46:15.040 --> 00:46:16.800]   You're saying, well, that can't possibly be.
[00:46:16.800 --> 00:46:19.040]   Yeah, that was true.
[00:46:19.040 --> 00:46:20.760]   I don't know why they do it, but they do.
[00:46:20.760 --> 00:46:22.800]   Robinhood's a good name for them, right?
[00:46:22.800 --> 00:46:24.520]   Easy to understand charts and market data.
[00:46:24.520 --> 00:46:28.720]   You can place a trade with literally four apps, four taps on the smartphone app, four
[00:46:28.720 --> 00:46:29.720]   taps.
[00:46:29.720 --> 00:46:33.160]   It is, it has, it lets you view stock collections.
[00:46:33.160 --> 00:46:38.920]   There's the 100 most popular sectors, for instance, like entertainment, social media,
[00:46:38.920 --> 00:46:42.480]   few analyst ratings of buy hold and sell for every stock.
[00:46:42.480 --> 00:46:47.080]   Learn how to invest as you build your portfolio, discover new stocks, track favorite companies,
[00:46:47.080 --> 00:46:50.720]   get a personalized news fade, customize notifications.
[00:46:50.720 --> 00:46:55.240]   So if the price moves, you'll know immediately, you'll know the, you could write moment to
[00:46:55.240 --> 00:46:56.240]   invest.
[00:46:56.240 --> 00:46:58.600]   I love this.
[00:46:58.600 --> 00:47:04.160]   Just when you sign up, just to throw in a little extra, if you go to Twit2, TwitInTheNumber2.Robinhood.com,
[00:47:04.160 --> 00:47:07.680]   they're going to throw in a free stock.
[00:47:07.680 --> 00:47:09.400]   Help build your portfolio.
[00:47:09.400 --> 00:47:10.720]   I don't know what the stock will be.
[00:47:10.720 --> 00:47:11.720]   It's random.
[00:47:11.720 --> 00:47:13.040]   It could be Apple, it could be Ford, it could be Sprint.
[00:47:13.040 --> 00:47:26.280]   The free stock, just to get your portfolio started, Twit2.Robinhood.com, Twit2.Robinhood.com.
[00:47:26.280 --> 00:47:30.520]   Fosta Cesta, we talked a lot about this when it was passed.
[00:47:30.520 --> 00:47:38.680]   And it's a hard thing to talk about because how could you be against a law that puts sex
[00:47:38.680 --> 00:47:42.120]   trafficking out of business?
[00:47:42.120 --> 00:47:44.720]   That was the whole point of Fosta and Cesta.
[00:47:44.720 --> 00:47:47.880]   The whole idea, in fact, it's in the name.
[00:47:47.880 --> 00:47:51.280]   Stop enabling Sex Traffickers Act.
[00:47:51.280 --> 00:47:54.880]   Allow victims in states to fight online sex trafficking act.
[00:47:54.880 --> 00:47:58.600]   I mean, how could that be wrong?
[00:47:58.600 --> 00:48:01.720]   It was signed into law April 2018.
[00:48:01.720 --> 00:48:08.480]   But even then, we talked about, a number of people talked about unfortunate consequences.
[00:48:08.480 --> 00:48:10.880]   And I think maybe we're starting to see those.
[00:48:10.880 --> 00:48:17.120]   So this week, Tumblr, which was bought from Yahoo by Verizon, is a part of Oath, or is
[00:48:17.120 --> 00:48:18.400]   it its own division now?
[00:48:18.400 --> 00:48:19.400]   I don't know.
[00:48:19.400 --> 00:48:20.960]   Decided that they were going to--
[00:48:20.960 --> 00:48:23.360]   But changing the name back again, something else.
[00:48:23.360 --> 00:48:24.360]   It's not Oath anymore.
[00:48:24.360 --> 00:48:25.360]   I know, I don't know.
[00:48:25.360 --> 00:48:26.360]   It's very confusing.
[00:48:26.360 --> 00:48:30.760]   Decided that they were going to, for the first time ever, block adult content, a better,
[00:48:30.760 --> 00:48:31.760]   more positive.
[00:48:31.760 --> 00:48:35.080]   Tumblr, I'm not against this idea.
[00:48:35.080 --> 00:48:41.880]   But I have to point out that David Carp and Tumblr exist because, I think, of adult content,
[00:48:41.880 --> 00:48:48.760]   a huge percentage, more than double digit percentage, of Tumblr's stuff was adult content.
[00:48:48.760 --> 00:48:54.800]   I can understand why Verizon may not want to be a curator of adult content on the net.
[00:48:54.800 --> 00:49:06.320]   December 17, all porn-related communities on the platform will be eradicated.
[00:49:06.320 --> 00:49:09.840]   Mike Drucker tweets, "Congratulations to Tumblr for taking a stand against the only thing
[00:49:09.840 --> 00:49:13.880]   people still go to Tumblr for.
[00:49:13.880 --> 00:49:16.840]   But we've already seen how hard this is to implement.
[00:49:16.840 --> 00:49:23.320]   There have been filters on Tumblr that have blocked vomiting unicorns, raw chicken, as
[00:49:23.320 --> 00:49:25.240]   adult content.
[00:49:25.240 --> 00:49:31.760]   And even, what was it, a patent for some sort of device, which I guess it looked like some
[00:49:31.760 --> 00:49:32.680]   sort of sex device?
[00:49:32.680 --> 00:49:33.680]   I don't know.
[00:49:33.680 --> 00:49:34.680]   It wasn't.
[00:49:34.680 --> 00:49:35.680]   It's very hard.
[00:49:35.680 --> 00:49:37.200]   Who wants to see raw chicken anyway?
[00:49:37.200 --> 00:49:38.200]   I agree.
[00:49:38.200 --> 00:49:39.200]   Block it all.
[00:49:39.200 --> 00:49:41.000]   Touch the stuff before you cook it.
[00:49:41.000 --> 00:49:43.360]   Block it all.
[00:49:43.360 --> 00:49:48.120]   This is probably the best article about it from, of course, the great guy at Tech Dirt, Mike
[00:49:48.120 --> 00:49:49.880]   Masnick.
[00:49:49.880 --> 00:49:52.760]   He says, "As we've covered for a while now, Foste became law."
[00:49:52.760 --> 00:49:55.760]   And this is an example, by the way, of tech companies saying, "Well, we're going to write
[00:49:55.760 --> 00:49:59.400]   the regulations so that a worse regulation doesn't go into effect."
[00:49:59.400 --> 00:50:02.920]   Facebook did an about face on its position.
[00:50:02.920 --> 00:50:08.160]   Turns out, Charles Sandberg decided it was important to appease Congress on something,
[00:50:08.160 --> 00:50:12.680]   even though Facebook's own policy team said, "No, we can't do that."
[00:50:12.680 --> 00:50:16.280]   Mike says, "As we pointed out at the time, this was Facebook basically selling out the
[00:50:16.280 --> 00:50:22.600]   internet because it eliminated the 230 exemption, the Safe Harbor from the Copyright Act, which
[00:50:22.600 --> 00:50:32.520]   allowed the companies weren't responsible for the, you know, that they could be publishers
[00:50:32.520 --> 00:50:34.760]   without being responsible for all the content that's on there."
[00:50:34.760 --> 00:50:39.680]   Suddenly meant that Facebook was responsible for, Tumblr was responsible for, content
[00:50:39.680 --> 00:50:41.840]   on its site.
[00:50:41.840 --> 00:50:45.640]   Mike says, and I don't think he's wrong, the early indications are that not only will
[00:50:45.640 --> 00:50:51.280]   it not help clean up the mess it's caused, it's leaning in on this new puritanical internet
[00:50:51.280 --> 00:50:52.280]   it wants to create.
[00:50:52.280 --> 00:50:56.440]   Facebook has been sued under Foste, but by someone arguing it's helped facilitate sex
[00:50:56.440 --> 00:50:57.440]   trafficking.
[00:50:57.440 --> 00:51:00.320]   I want to be clear, I'm not in favor of sex trafficking.
[00:51:00.320 --> 00:51:05.280]   That's not what this law is about.
[00:51:05.280 --> 00:51:09.160]   Facebook's put up a whole bunch of new guidelines under the head of sexual solicitation.
[00:51:09.160 --> 00:51:15.120]   For instance, "You can no longer, in Facebook, say what your sexual partner preference is."
[00:51:15.120 --> 00:51:18.480]   That's deemed as sexual solicitation.
[00:51:18.480 --> 00:51:24.480]   "Vague suggestive statements such as looking for a good time tonight, sexualized slang,
[00:51:24.480 --> 00:51:31.880]   using sexual hints such as mentioning sex roles, sex positions, scenarios, preferences."
[00:51:31.880 --> 00:51:35.400]   Sexual, yeah, sexual partner preferences.
[00:51:35.400 --> 00:51:40.520]   It seems like I like men say or I like women say.
[00:51:40.520 --> 00:51:41.520]   That's prohibited.
[00:51:41.520 --> 00:51:43.880]   Sexual orientation, you're sexual identity.
[00:51:43.880 --> 00:51:48.960]   It seems like Facebook, correct me if I'm wrong, but it seems like they're going farther
[00:51:48.960 --> 00:51:55.880]   than what the law reasonably would arguably require.
[00:51:55.880 --> 00:52:00.600]   Mike makes the point that the bill not only has decreased sex trafficking or even sex
[00:52:00.600 --> 00:52:05.000]   ads online, it's just put it underground where it's harder to police.
[00:52:05.000 --> 00:52:12.920]   Even more so, and I'm not a prude, but I'm not soliciting on Facebook for partners either,
[00:52:12.920 --> 00:52:18.680]   but there's a real concern that this is going to lead to widespread censorship online and
[00:52:18.680 --> 00:52:21.440]   that that's what's starting to happen now.
[00:52:21.440 --> 00:52:28.560]   Well, I think you got to go back to since Facebook owns the platform, any platform owner.
[00:52:28.560 --> 00:52:29.560]   They can do whatever they want.
[00:52:29.560 --> 00:52:30.920]   They can censor anything they want.
[00:52:30.920 --> 00:52:31.920]   Mike says this.
[00:52:31.920 --> 00:52:33.160]   Obviously, this is Facebook's platform.
[00:52:33.160 --> 00:52:37.600]   It can make whatever stupid rules it wants, but it's not difficult to see how this is likely
[00:52:37.600 --> 00:52:41.520]   to impact all kinds of perfectly acceptable content on Facebook.
[00:52:41.520 --> 00:52:43.640]   It also seems quite hypocritical.
[00:52:43.640 --> 00:52:47.600]   Mike writes, given that Facebook's early versions were very much about helping college students
[00:52:47.600 --> 00:52:48.600]   hook up.
[00:52:48.600 --> 00:52:52.480]   Well, you know, if people don't like it, there's a solution to that.
[00:52:52.480 --> 00:52:54.520]   You leave Facebook and do something else.
[00:52:54.520 --> 00:52:55.520]   I agree.
[00:52:55.520 --> 00:52:59.320]   As long as Fosta Cesta doesn't make it global.
[00:52:59.320 --> 00:53:03.360]   That's the real problem is that now we have these laws and there's a real concern that
[00:53:03.360 --> 00:53:07.240]   there is a new prudishness and a new censorship that's going to sweep the Internet.
[00:53:07.240 --> 00:53:12.000]   And again, and if that's the case, Patrick Bejaw, who lives in a country where bare breasts
[00:53:12.000 --> 00:53:19.000]   are actually printed on the money, clearly this is a potential problem.
[00:53:19.000 --> 00:53:25.680]   Oh, this is an example of where regulation maybe can be misguided in with all the best
[00:53:25.680 --> 00:53:27.360]   intent.
[00:53:27.360 --> 00:53:35.120]   With all the devilish advocating, I can muster, I won't be able to say that this is a good
[00:53:35.120 --> 00:53:38.680]   law or well written law.
[00:53:38.680 --> 00:53:45.200]   But the bare-breasted thing is actually a constant issue with Facebook and other social
[00:53:45.200 --> 00:53:50.720]   networks because when they decide to take away some piece of content, they do it based
[00:53:50.720 --> 00:53:55.640]   on very often American cultural context and references.
[00:53:55.640 --> 00:54:05.000]   And for us, we have bare-breasted women in ads on the sidewalk to sell.
[00:54:05.000 --> 00:54:06.000]   It's on your money.
[00:54:06.000 --> 00:54:07.000]   It's on the money.
[00:54:07.000 --> 00:54:09.280]   It's like even cosmetic products and stuff like that.
[00:54:09.280 --> 00:54:10.280]   Sure.
[00:54:10.280 --> 00:54:12.320]   Have you ever been to the beach in France?
[00:54:12.320 --> 00:54:13.320]   Exactly.
[00:54:13.320 --> 00:54:14.320]   It's cultural.
[00:54:14.320 --> 00:54:16.520]   It's not considered sexual in France.
[00:54:16.520 --> 00:54:17.520]   No.
[00:54:17.520 --> 00:54:18.520]   No.
[00:54:18.520 --> 00:54:20.920]   Anymore than a bare-breasted man is considered sexual in America.
[00:54:20.920 --> 00:54:21.920]   Well, except for you.
[00:54:21.920 --> 00:54:22.920]   I mean, Sam.
[00:54:22.920 --> 00:54:23.920]   Yeah.
[00:54:23.920 --> 00:54:29.200]   It's certainly not asexual, but it's not a big deal.
[00:54:29.200 --> 00:54:36.600]   But this implementation of the law seems like you can't say, "I'm straight or I'm
[00:54:36.600 --> 00:54:37.600]   gay."
[00:54:37.600 --> 00:54:42.400]   I don't see really how that relates to...
[00:54:42.400 --> 00:54:48.720]   It's certainly a very, very, very, very conservative interpretation of that law.
[00:54:48.720 --> 00:54:53.720]   And I don't see how it can be implemented and acted on, acted upon.
[00:54:53.720 --> 00:54:57.600]   Well, I think Facebook is covering themselves.
[00:54:57.600 --> 00:54:59.000]   They're trying to make this...
[00:54:59.000 --> 00:55:00.000]   Exactly.
[00:55:00.000 --> 00:55:02.000]   They're trying to make this...
[00:55:02.000 --> 00:55:08.480]   Look, they have to come up with what they believe are the standards for their site and
[00:55:08.480 --> 00:55:10.800]   how they want to go, what direction they want to go.
[00:55:10.800 --> 00:55:12.640]   And yes, it's in the spirit of this law.
[00:55:12.640 --> 00:55:16.440]   And of course, the law is designed to do one thing, but Facebook's saying, "Well, here's
[00:55:16.440 --> 00:55:19.240]   the things that we hold true on our site, okay?
[00:55:19.240 --> 00:55:20.520]   We don't want you talking about this.
[00:55:20.520 --> 00:55:22.160]   We don't want you presenting that."
[00:55:22.160 --> 00:55:28.120]   And yes, there's always going to be some gray area where there's an overlap with a group,
[00:55:28.120 --> 00:55:32.600]   these groups and things that might be on there that use this to communicate and talk
[00:55:32.600 --> 00:55:34.920]   and stuff like that and to talk about sexuality.
[00:55:34.920 --> 00:55:41.840]   But I don't think if I posted on my status update looking for a good time tonight, that
[00:55:41.840 --> 00:55:42.840]   would be pulled down immediately.
[00:55:42.840 --> 00:55:43.840]   I mean, I could be wrong.
[00:55:43.840 --> 00:55:44.840]   I would be.
[00:55:44.840 --> 00:55:45.840]   Well, so it will...
[00:55:45.840 --> 00:55:46.840]   I mean, I don't know.
[00:55:46.840 --> 00:55:47.840]   I haven't...
[00:55:47.840 --> 00:55:48.840]   Try it.
[00:55:48.840 --> 00:55:49.840]   I'll try that.
[00:55:49.840 --> 00:55:50.840]   We'll see what happens.
[00:55:50.840 --> 00:55:51.840]   Let me...
[00:55:51.840 --> 00:55:52.840]   I'm not sure if you're going to be able to do it.
[00:55:52.840 --> 00:55:53.840]   No, no, you shouldn't do it.
[00:55:53.840 --> 00:55:54.840]   We'll get somebody in our audience.
[00:55:54.840 --> 00:55:55.840]   But I don't know.
[00:55:55.840 --> 00:56:00.560]   But the reality is, I mean, they want to make it so that if they take something down, they
[00:56:00.560 --> 00:56:03.480]   have the sexual solicitation.
[00:56:03.480 --> 00:56:08.080]   This is under community standards, section three, item 15.
[00:56:08.080 --> 00:56:10.920]   And they're talking about sexual solicitation.
[00:56:10.920 --> 00:56:13.560]   Will that overlap into other things?
[00:56:13.560 --> 00:56:14.560]   Probably.
[00:56:14.560 --> 00:56:16.560]   Well, it was also something about sexual slang.
[00:56:16.560 --> 00:56:17.560]   It was also something about sexual slang.
[00:56:17.560 --> 00:56:18.560]   And it too wasn't?
[00:56:18.560 --> 00:56:19.560]   Yeah, sexual slang.
[00:56:19.560 --> 00:56:20.560]   But again, it's how you're posting it.
[00:56:20.560 --> 00:56:25.360]   They're using this to take down groups that are using this for sexual solicitation and
[00:56:25.360 --> 00:56:26.360]   sex trafficking.
[00:56:26.360 --> 00:56:29.400]   They want to make sure that they're protected because they said, "Hey, look, you can't do
[00:56:29.400 --> 00:56:30.400]   that.
[00:56:30.400 --> 00:56:31.600]   And I don't care if your group has 100,000 people in it.
[00:56:31.600 --> 00:56:34.240]   If you're posting this kind of stuff, we're going to take it down."
[00:56:34.240 --> 00:56:35.760]   They're protecting themselves.
[00:56:35.760 --> 00:56:40.800]   But if me, if I want to post something that's silly or some sort of meme or something that's
[00:56:40.800 --> 00:56:45.040]   sexual in nature, not that I do that, but I don't know.
[00:56:45.040 --> 00:56:46.600]   I mean, yes, it could be taken down.
[00:56:46.600 --> 00:56:47.600]   Will it happen overnight?
[00:56:47.600 --> 00:56:48.600]   Will their computers do it?
[00:56:48.600 --> 00:56:49.600]   Will their machine learning?
[00:56:49.600 --> 00:56:50.600]   Who knows?
[00:56:50.600 --> 00:56:53.680]   But they're protecting themselves because of this law.
[00:56:53.680 --> 00:56:55.000]   And no, it's not going to be perfect.
[00:56:55.000 --> 00:56:59.520]   But again, it's what direction does Facebook want to go in with their platform?
[00:56:59.520 --> 00:57:02.240]   Tumblr decided, like you said, Leo.
[00:57:02.240 --> 00:57:06.520]   Tumblr was sort of known for this in a certain way.
[00:57:06.520 --> 00:57:10.160]   Millions of people knew Tumblr for what it was.
[00:57:10.160 --> 00:57:14.600]   And many more millions knew for the other side of Tumblr, right?
[00:57:14.600 --> 00:57:19.000]   Facebook doesn't want to have the other side, that secret side that an average person doesn't
[00:57:19.000 --> 00:57:20.000]   know.
[00:57:20.000 --> 00:57:24.040]   I've wondered for years why Tumblr didn't do that too because it really, it could be
[00:57:24.040 --> 00:57:25.040]   pretty nasty.
[00:57:25.040 --> 00:57:26.760]   And yet, Tumblr is a great place.
[00:57:26.760 --> 00:57:29.720]   It's kind of the, I call it the live journal for the 21st century.
[00:57:29.720 --> 00:57:32.760]   It's a great place for young people to blog.
[00:57:32.760 --> 00:57:35.040]   I mean, it's a nice platform.
[00:57:35.040 --> 00:57:42.120]   It might have been the pornographic or erotic part of Tumblr might have been first because
[00:57:42.120 --> 00:57:45.240]   of the Apple ban on the app.
[00:57:45.240 --> 00:57:46.240]   It might have--
[00:57:46.240 --> 00:57:47.240]   Oh, it's totally a response to that.
[00:57:47.240 --> 00:57:48.240]   Well, but that's the point.
[00:57:48.240 --> 00:57:52.280]   Because of Fosta Cesta, you're no longer covered by Section 230.
[00:57:52.280 --> 00:57:55.000]   You are liable for the content on your platform.
[00:57:55.000 --> 00:57:58.880]   So everybody, Facebook, Tumblr, but everybody else is going to start looking at this and
[00:57:58.880 --> 00:58:01.800]   saying, are we liable?
[00:58:01.800 --> 00:58:03.800]   And do we need to do something about it?
[00:58:03.800 --> 00:58:10.240]   Well, and to your comment earlier about, you know, does this presage a broader censorship
[00:58:10.240 --> 00:58:12.240]   because of these laws?
[00:58:12.240 --> 00:58:13.240]   Exactly.
[00:58:13.240 --> 00:58:17.560]   You know, is there potential that, you know, perhaps this is a violation of the First Amendment
[00:58:17.560 --> 00:58:21.120]   and could potentially, you know, the whole law could be potentially unconstitutional?
[00:58:21.120 --> 00:58:22.120]   I don't know.
[00:58:22.120 --> 00:58:23.120]   I'm not a lawyer.
[00:58:23.120 --> 00:58:24.520]   Is Facebook protected by the First Amendment?
[00:58:24.520 --> 00:58:25.520]   I mean, is it?
[00:58:25.520 --> 00:58:29.280]   It's a private website that they, you know, it feels like it's a--
[00:58:29.280 --> 00:58:30.840]   No, they're not.
[00:58:30.840 --> 00:58:38.400]   But if the government decides to try to force companies to do something, to go more broadly
[00:58:38.400 --> 00:58:45.280]   with censorship using this law, then perhaps that, you know, that could be seen as a violation
[00:58:45.280 --> 00:58:46.280]   of this.
[00:58:46.280 --> 00:58:49.720]   I know Patrick says that we don't believe the government, but I would say if the government
[00:58:49.720 --> 00:58:54.120]   came up with this, I think that they looked at it and specifically targeted what they
[00:58:54.120 --> 00:58:55.280]   wanted to do with this.
[00:58:55.280 --> 00:58:59.120]   Yes, can I have a chilling effect in other aspects and companies that look, we're out
[00:58:59.120 --> 00:59:00.120]   of this.
[00:59:00.120 --> 00:59:02.080]   We're just not even going to deal with it because it's too much work.
[00:59:02.080 --> 00:59:06.240]   I can see that happening, but that happens in a lot of different-- with a lot of different
[00:59:06.240 --> 00:59:09.480]   laws, you know, gambling and other types of laws where people are like, look, we're
[00:59:09.480 --> 00:59:14.280]   not even going to touch this because it's too delicate of a manner to be involved with,
[00:59:14.280 --> 00:59:15.280]   so we're just-- we're out.
[00:59:15.280 --> 00:59:16.280]   Peace out.
[00:59:16.280 --> 00:59:22.880]   When Fosta Cessna was up and voted upon and we talked a lot about it, it's a tricky thing
[00:59:22.880 --> 00:59:27.280]   because it sounds like if you're saying it as a bad law, you're advocating sex trafficking.
[00:59:27.280 --> 00:59:32.040]   So let me talk-- take the word sex trafficking out of it and talk about what it actually
[00:59:32.040 --> 00:59:33.040]   does.
[00:59:33.040 --> 00:59:39.560]   In the Communications Decency Act, which was passed in 1996 and really was the law that
[00:59:39.560 --> 00:59:46.280]   let the internet happen, created a safe harbor rule in section 230 that said, quote, "No
[00:59:46.280 --> 00:59:52.000]   provider or user of an interactive computer service shall be treated as the publisher
[00:59:52.000 --> 00:59:57.000]   or speaker of any information provided by another information content provider."
[00:59:57.000 --> 00:59:59.880]   In other words, you're not liable.
[00:59:59.880 --> 01:00:01.560]   You're not a publisher.
[01:00:01.560 --> 01:00:05.400]   You're a telecommunications-- you're a platform.
[01:00:05.400 --> 01:00:07.880]   You're a telecommunications utility.
[01:00:07.880 --> 01:00:13.960]   And so by passing this law, basically, it meant all website publishers are now responsible
[01:00:13.960 --> 01:00:18.440]   for whatever contents on their site, even if it's published by a third party, especially
[01:00:18.440 --> 01:00:20.160]   if it's published by a third party.
[01:00:20.160 --> 01:00:27.680]   And the fear was that it would-- and then the hard thing is to advocate for this sounds
[01:00:27.680 --> 01:00:32.960]   like I'm advocating for pornography, but I am advocating for a free and open internet
[01:00:32.960 --> 01:00:39.200]   and there are lots of places people want to be able to go where they can talk about things
[01:00:39.200 --> 01:00:41.800]   freely, including adult topics.
[01:00:41.800 --> 01:00:45.880]   And if that suddenly disappears, remember, some of it is like Craigslist eliminating their
[01:00:45.880 --> 01:00:48.160]   personal big deal, right?
[01:00:48.160 --> 01:00:52.200]   Although if you're a sex worker, that is a big deal because suddenly you're pushed back
[01:00:52.200 --> 01:00:56.640]   underground again.
[01:00:56.640 --> 01:00:59.360]   I think Fosten Cesta was a bad idea.
[01:00:59.360 --> 01:01:04.440]   I think we should keep an eye on this because this is going to be, I think, a rapidly spreading
[01:01:04.440 --> 01:01:05.440]   trend.
[01:01:05.440 --> 01:01:09.120]   And Facebook, Tumblr, it's just the beginning.
[01:01:09.120 --> 01:01:12.440]   So it's going to be bad.
[01:01:12.440 --> 01:01:17.880]   There's a different way of doing this-- well, not specifically about sex trafficking.
[01:01:17.880 --> 01:01:23.760]   If it's OK to veer a little bit off of that topic, but to something that is germane, I
[01:01:23.760 --> 01:01:27.960]   think a lot of the issues we're seeing with these laws is that it's kind of a football
[01:01:27.960 --> 01:01:29.520]   that no one wants to be holding.
[01:01:29.520 --> 01:01:36.360]   The government doesn't want to be the one moderating all of these pieces of content.
[01:01:36.360 --> 01:01:46.200]   And the tech giants don't want to be the ones responsible for deciding what is acceptable
[01:01:46.200 --> 01:01:47.760]   and what isn't.
[01:01:47.760 --> 01:01:52.080]   And the French government actually proposed something and is going to be implementing
[01:01:52.080 --> 01:02:03.040]   something interesting with Facebook in regards to undesirable content and how they remove
[01:02:03.040 --> 01:02:04.280]   it.
[01:02:04.280 --> 01:02:09.600]   So what's going to be happening is that a French entity, a French governmental entity, is
[01:02:09.600 --> 01:02:15.200]   going to have access to the Facebook algorithms for moderation.
[01:02:15.200 --> 01:02:17.520]   And it's going to be a tech-literate entity.
[01:02:17.520 --> 01:02:20.800]   We haven't decided with one yet, but we have a few.
[01:02:20.800 --> 01:02:25.640]   And so they're going to vet their algorithm and the way they mod-- I don't know how much
[01:02:25.640 --> 01:02:26.880]   of it is going to be.
[01:02:26.880 --> 01:02:30.800]   And once they have vetted it, I imagine it's going to be kind of set in stone, but they're
[01:02:30.800 --> 01:02:35.040]   going to say, OK, this we're OK with, you can use it.
[01:02:35.040 --> 01:02:38.040]   And then Facebook is in charge of making it run.
[01:02:38.040 --> 01:02:42.480]   But I think this might be a way that the two could be reconciled.
[01:02:42.480 --> 01:02:43.600]   We'll see how it works out.
[01:02:43.600 --> 01:02:45.080]   But I think the idea is interesting.
[01:02:45.080 --> 01:02:46.080]   I love the--
[01:02:46.080 --> 01:02:51.360]   you're saying independent auditing of the algorithms that are used to do the monitoring?
[01:02:51.360 --> 01:02:52.560]   Well, the--
[01:02:52.560 --> 01:02:55.120]   It's government auditing, actually.
[01:02:55.120 --> 01:02:56.120]   So it's going to have to--
[01:02:56.120 --> 01:02:57.320]   Well, I say independent.
[01:02:57.320 --> 01:03:00.800]   I mean, independent from the companies that are actually running a platform.
[01:03:00.800 --> 01:03:01.320]   Yeah.
[01:03:01.320 --> 01:03:02.160]   We've seen that before.
[01:03:02.160 --> 01:03:08.840]   The US Department of Justice put a person in Microsoft to keep an eye on their anti-trust
[01:03:08.840 --> 01:03:10.160]   moves.
[01:03:10.160 --> 01:03:12.560]   And this is actually a very good idea, I think.
[01:03:12.560 --> 01:03:13.080]   Yeah.
[01:03:13.080 --> 01:03:14.920]   That was a different scenario, though.
[01:03:14.920 --> 01:03:17.920]   I mean, they were looking at the business moves as opposed to looking more--
[01:03:17.920 --> 01:03:21.080]   Well, it takes more technical expertise to do this.
[01:03:21.080 --> 01:03:24.000]   But there are people out there who can do it.
[01:03:24.000 --> 01:03:28.240]   Yeah, I think things like that are actually a really good idea.
[01:03:28.240 --> 01:03:34.400]   Because as another example, it's closer to my particular area of expertise with autonomous
[01:03:34.400 --> 01:03:34.920]   cars.
[01:03:34.920 --> 01:03:37.840]   I think that's something that we need to look at start doing.
[01:03:37.840 --> 01:03:41.840]   With that kind of technology, we need to have experts that can look at this stuff
[01:03:41.840 --> 01:03:44.720]   and figure out to understand what these things are doing.
[01:03:44.720 --> 01:03:48.880]   And I think in general, across the technology sphere, I think that that's actually a good
[01:03:48.880 --> 01:03:53.960]   idea to have this sort of vetting and auditing of these systems.
[01:03:53.960 --> 01:04:00.560]   Because we've seen all kinds of situations over the years where there has been cheating
[01:04:00.560 --> 01:04:02.480]   for one of a better word.
[01:04:02.480 --> 01:04:07.480]   I mean, looking at the Volkswagen diesel case is a perfect example of that.
[01:04:07.480 --> 01:04:10.640]   If somebody had been vetting that software, they could not have done that.
[01:04:10.640 --> 01:04:12.520]   Because that was all done entirely in software.
[01:04:12.520 --> 01:04:21.040]   And any system that's run completely electronically, completely in software can be abused and misused
[01:04:21.040 --> 01:04:25.120]   in these kinds of different kinds of ways.
[01:04:25.120 --> 01:04:26.280]   You're right, though, Patrick.
[01:04:26.280 --> 01:04:31.400]   My first reaction is, oh, my God, we can't let government put its fingers at those gears.
[01:04:31.400 --> 01:04:32.400]   That's a...
[01:04:32.400 --> 01:04:34.400]   See, I told you what you pointed out.
[01:04:34.400 --> 01:04:35.400]   I didn't want to say it.
[01:04:35.400 --> 01:04:36.400]   I didn't want to say it.
[01:04:36.400 --> 01:04:38.920]   I don't want to be...
[01:04:38.920 --> 01:04:44.440]   But I think in this case, it might turn out to be, I'm going to be careful here, but it
[01:04:44.440 --> 01:04:50.080]   might turn out to be an acceptable compromise because you put the responsibility of how the
[01:04:50.080 --> 01:04:53.520]   algorithm runs on the government's vetting.
[01:04:53.520 --> 01:04:59.320]   So it's kind of seeing whether or not it's legally, for the government represents ideally
[01:04:59.320 --> 01:05:00.400]   the will of the people.
[01:05:00.400 --> 01:05:03.880]   So the government is going to say, okay, we think this could work.
[01:05:03.880 --> 01:05:11.280]   And then the actual running of it, which is very labor and computational power and probably
[01:05:11.280 --> 01:05:18.640]   capital intensive, is still on the running of the platform as its day-to-day operation
[01:05:18.640 --> 01:05:24.240]   because the government is not going to start actually approving and moderating each individual
[01:05:24.240 --> 01:05:25.240]   post.
[01:05:25.240 --> 01:05:28.440]   But somebody in the chatroom saying, Addison saying, this is like a health inspector.
[01:05:28.440 --> 01:05:29.440]   Right?
[01:05:29.440 --> 01:05:30.440]   You have a meat factory.
[01:05:30.440 --> 01:05:33.840]   You have health inspectors go in and test the safety of the meat.
[01:05:33.840 --> 01:05:37.440]   That's not an inappropriate role for government to play, I think.
[01:05:37.440 --> 01:05:40.220]   It requires more high tech and more...
[01:05:40.220 --> 01:05:42.000]   It's definitely more complicated, but you're right.
[01:05:42.000 --> 01:05:44.560]   But it's essentially the same role.
[01:05:44.560 --> 01:05:45.560]   Yeah.
[01:05:45.560 --> 01:05:46.560]   I mean, it depends...
[01:05:46.560 --> 01:05:47.560]   Yeah.
[01:05:47.560 --> 01:05:48.560]   I've got a related question.
[01:05:48.560 --> 01:05:49.560]   It makes me...
[01:05:49.560 --> 01:05:51.120]   Just as squirrely as it does you, Rich.
[01:05:51.120 --> 01:05:54.200]   I've got a related question to this.
[01:05:54.200 --> 01:06:00.400]   If these platform providers are liable for stuff that's being published on there now,
[01:06:00.400 --> 01:06:06.040]   what happens, how does FOSTA impact somebody that's running their own blog?
[01:06:06.040 --> 01:06:07.040]   If they've got stuff...
[01:06:07.040 --> 01:06:08.040]   It impacts you.
[01:06:08.040 --> 01:06:09.040]   A self-opted...
[01:06:09.040 --> 01:06:10.040]   You're responsible.
[01:06:10.040 --> 01:06:11.040]   Right.
[01:06:11.040 --> 01:06:12.040]   I'm responsible for what I publish.
[01:06:12.040 --> 01:06:16.080]   No, but if somebody puts a comment on your blog, so listening sex, that's on you, baby.
[01:06:16.080 --> 01:06:20.580]   But let's say I'm running a blog where I have comments turned off and so I'm the only one
[01:06:20.580 --> 01:06:21.580]   posting stuff on there.
[01:06:21.580 --> 01:06:22.580]   I'm the only one contributing.
[01:06:22.580 --> 01:06:23.580]   That's what you're going to get.
[01:06:23.580 --> 01:06:24.580]   Does my hosting provider...
[01:06:24.580 --> 01:06:26.400]   Is my hosting provider liable?
[01:06:26.400 --> 01:06:27.400]   Yes.
[01:06:27.400 --> 01:06:28.400]   Yeah.
[01:06:28.400 --> 01:06:29.400]   Yeah.
[01:06:29.400 --> 01:06:30.400]   Denise Howell...
[01:06:30.400 --> 01:06:31.400]   Yeah, if you're running a staff council...
[01:06:31.400 --> 01:06:32.400]   Yeah.
[01:06:32.400 --> 01:06:33.400]   I mean, but that makes sense.
[01:06:33.400 --> 01:06:34.400]   If you set up a...
[01:06:34.400 --> 01:06:36.320]   I'll let Denise Howell answer.
[01:06:36.320 --> 01:06:37.320]   Yeah.
[01:06:37.320 --> 01:06:38.320]   What's that?
[01:06:38.320 --> 01:06:39.320]   We have a...
[01:06:39.320 --> 01:06:40.880]   Our host of this week in law is in the chatroom.
[01:06:40.880 --> 01:06:45.160]   I'll let Denise give us an actual legal opinion, but go ahead, Rich.
[01:06:45.160 --> 01:06:46.720]   Well, I'm just saying, I mean, if you...
[01:06:46.720 --> 01:06:47.720]   Look, I mean, it makes sense.
[01:06:47.720 --> 01:06:57.000]   If you set up a website, a blog that is to sell sex, then it makes sense that the web
[01:06:57.000 --> 01:07:01.280]   host provider would be able to say, "Hey, no, we're taking you down because we can't
[01:07:01.280 --> 01:07:02.720]   allow that on our platform."
[01:07:02.720 --> 01:07:10.120]   Now, if you do a blog that's just discussion of sex, that's different.
[01:07:10.120 --> 01:07:13.040]   So I think that it goes back to the law.
[01:07:13.040 --> 01:07:14.800]   What is the spirit of the law?
[01:07:14.800 --> 01:07:16.800]   It's to stop sex trafficking, and I get it.
[01:07:16.800 --> 01:07:21.000]   We've talked about how it definitely lingers and goes into other areas.
[01:07:21.000 --> 01:07:26.560]   But the reality is, yeah, your blog provider should be liable for that because they're
[01:07:26.560 --> 01:07:27.720]   providing the service.
[01:07:27.720 --> 01:07:32.120]   That is their business is to provide the web space and the hosting and all that stuff.
[01:07:32.120 --> 01:07:37.480]   And they have to make sure that they're abiding by the law of what you put on there on their
[01:07:37.480 --> 01:07:38.480]   site.
[01:07:38.480 --> 01:07:43.760]   And it gets complicated, but it's pretty cut and dry with the law saying what is allowed
[01:07:43.760 --> 01:07:45.040]   and what's not.
[01:07:45.040 --> 01:07:47.400]   And that's kind of part of it.
[01:07:47.400 --> 01:07:49.320]   I think that's one of the issues, actually.
[01:07:49.320 --> 01:07:52.640]   I'm not sure how cut and dry it is with this law.
[01:07:52.640 --> 01:07:58.040]   I mean, maybe we should read it and leave it to Denise Howell to tell us.
[01:07:58.040 --> 01:07:59.040]   It seems it's kind of...
[01:07:59.040 --> 01:08:01.080]   With all this said, I have not read the law.
[01:08:01.080 --> 01:08:03.960]   So I'm just speaking off the cuff here.
[01:08:03.960 --> 01:08:07.800]   But I would assume it's cut and dry if you're smart.
[01:08:07.800 --> 01:08:10.640]   I think that's another difference with the health...
[01:08:10.640 --> 01:08:17.040]   One of the differences with the health inspector comparison with health regulations, they're
[01:08:17.040 --> 01:08:18.720]   very precise.
[01:08:18.720 --> 01:08:23.440]   And this is one of the thankless job of the government, which is to say, in this situation
[01:08:23.440 --> 01:08:25.640]   you can do this and you have this kind of thing.
[01:08:25.640 --> 01:08:30.120]   And it's a horrible job and I'm very thankful some people are willing to do it, but it's
[01:08:30.120 --> 01:08:31.400]   very precise.
[01:08:31.400 --> 01:08:33.840]   And it specifies exactly what you can and can't do.
[01:08:33.840 --> 01:08:39.760]   I don't think these laws that regulate the internet, they speak in the general principle.
[01:08:39.760 --> 01:08:40.920]   But the law doesn't mean it.
[01:08:40.920 --> 01:08:45.120]   But that's why Facebook is coming up with this laundry lesson.
[01:08:45.120 --> 01:08:48.560]   If you read these things, that's why they're saying, we know the law.
[01:08:48.560 --> 01:08:50.640]   Here's how we're interpreting it for our platform.
[01:08:50.640 --> 01:08:54.160]   And our platform says, you can't say the word buttocks or whatever.
[01:08:54.160 --> 01:08:58.640]   It's like there's different things that they say that they have laid out, so it's very
[01:08:58.640 --> 01:08:59.640]   clear.
[01:08:59.640 --> 01:09:03.200]   So when they shut down a group that has 100,000 people on there that are clearly going to be
[01:09:03.200 --> 01:09:06.240]   mad about this, they say, look, this is what we said in our standards.
[01:09:06.240 --> 01:09:07.240]   We get it.
[01:09:07.240 --> 01:09:11.480]   The law is there for this, but we have our own community standards that we have written
[01:09:11.480 --> 01:09:12.880]   based on this law.
[01:09:12.880 --> 01:09:14.200]   And of course those are going to change.
[01:09:14.200 --> 01:09:16.240]   Of course they're going to evolve as time goes on.
[01:09:16.240 --> 01:09:21.880]   But the law itself sets the standard and all these companies have to decide, they have
[01:09:21.880 --> 01:09:23.040]   to interpret the law.
[01:09:23.040 --> 01:09:27.160]   And it is more complicated than a meat inspector saying, this is grade A, this is grade B, this
[01:09:27.160 --> 01:09:28.560]   is good, this is bad.
[01:09:28.560 --> 01:09:29.840]   It is way more complicated.
[01:09:29.840 --> 01:09:33.000]   And that's why we're having this discussion because I don't think anyone would say that
[01:09:33.000 --> 01:09:36.440]   we don't want health inspectors inside the meatpacking plant.
[01:09:36.440 --> 01:09:40.200]   But there are a lot of people who would say, we don't necessarily want the government
[01:09:40.200 --> 01:09:44.600]   policing all this stuff on these websites and deciding what's allowed and what's not
[01:09:44.600 --> 01:09:46.400]   allowed and what Facebook can have.
[01:09:46.400 --> 01:09:48.920]   And that's why it's so tricky.
[01:09:48.920 --> 01:09:55.920]   And incidentally, as a footnote to your question, Sam, in June, the EFF did file a lawsuit seeking
[01:09:55.920 --> 01:10:00.960]   to have it declared unconstitutional and it was dismissed in September, their lawsuit.
[01:10:00.960 --> 01:10:05.400]   So it is, it's been ruled by at least the lower court is constitutional.
[01:10:05.400 --> 01:10:08.800]   I think, that's a good question.
[01:10:08.800 --> 01:10:10.320]   I don't know.
[01:10:10.320 --> 01:10:19.080]   It seems to me that if that law can be interpreted in such a wide range as Facebook is doing by
[01:10:19.080 --> 01:10:26.920]   implementing those community guidelines, apparently based on the law, it seems the law isn't
[01:10:26.920 --> 01:10:29.480]   precise enough.
[01:10:29.480 --> 01:10:33.800]   It's not like the health regulations.
[01:10:33.800 --> 01:10:35.080]   It's too vague.
[01:10:35.080 --> 01:10:39.120]   I can't imagine that anyone would be okay with a law that says you can't express your
[01:10:39.120 --> 01:10:41.320]   sexual preference on a website.
[01:10:41.320 --> 01:10:42.320]   So this seems like-
[01:10:42.320 --> 01:10:45.560]   Does the law say that or is that what Facebook is saying?
[01:10:45.560 --> 01:10:46.560]   No, exactly.
[01:10:46.560 --> 01:10:48.280]   That's my point.
[01:10:48.280 --> 01:10:53.720]   I'm saying if Facebook can interpret the law in that way and say, well, this is the way
[01:10:53.720 --> 01:10:57.480]   we look at what the law says, I think the law is badly written.
[01:10:57.480 --> 01:10:58.480]   It's why.
[01:10:58.480 --> 01:11:00.000]   But that's Facebook's platform.
[01:11:00.000 --> 01:11:00.920]   That's their prerogative.
[01:11:00.920 --> 01:11:07.840]   If you're a website that is a website dedicated to all things sex, like a blog or something,
[01:11:07.840 --> 01:11:09.800]   you're clearly going to have way different standards.
[01:11:09.800 --> 01:11:13.080]   They're still stopping the sex trafficking, but they're saying, yeah, you could talk
[01:11:13.080 --> 01:11:14.080]   about whatever you want here.
[01:11:14.080 --> 01:11:18.640]   You can post whatever memes you want, whatever pictures you want, whatever thoughts you want.
[01:11:18.640 --> 01:11:22.200]   That's the difference here is that Facebook is saying these are our standards based on
[01:11:22.200 --> 01:11:23.640]   this law.
[01:11:23.640 --> 01:11:25.840]   I believe that they can do that.
[01:11:25.840 --> 01:11:26.840]   Another website-
[01:11:26.840 --> 01:11:27.840]   They can.
[01:11:27.840 --> 01:11:32.200]   The law has what they want to do and the standards that the law sets, but then each
[01:11:32.200 --> 01:11:37.440]   platform sets what they believe their platform stands for and what their members should be
[01:11:37.440 --> 01:11:38.440]   able to do and not be able to do.
[01:11:38.440 --> 01:11:42.000]   There's going to be a wide range what you can do on Facebook versus another website
[01:11:42.000 --> 01:11:45.400]   that's dedicated to all things sex.
[01:11:45.400 --> 01:11:51.080]   Listen, I think that Facebook, of course, they can do whatever they want.
[01:11:51.080 --> 01:11:53.040]   I think that's pretty clear and we've all said it.
[01:11:53.040 --> 01:11:54.360]   We all agree.
[01:11:54.360 --> 01:12:01.640]   But if they're saying this law is compelling us to prevent you from saying what your sexual
[01:12:01.640 --> 01:12:06.520]   preference is when the law is supposedly about preventing sex trafficking, then there's
[01:12:06.520 --> 01:12:07.520]   an issue.
[01:12:07.520 --> 01:12:09.800]   Of course, Facebook can do it.
[01:12:09.800 --> 01:12:11.040]   We all agree.
[01:12:11.040 --> 01:12:17.040]   But if they're doing it because of the law, because of that law specifically, there's
[01:12:17.040 --> 01:12:18.880]   a disconnect there.
[01:12:18.880 --> 01:12:24.440]   If they do it because they want to do it, that's fine.
[01:12:24.440 --> 01:12:27.760]   That sequence of events seems broken to me.
[01:12:27.760 --> 01:12:33.760]   The problem really is the definition of, well, first of all, they take away Facebook's defense
[01:12:33.760 --> 01:12:35.760]   under Section 230.
[01:12:35.760 --> 01:12:42.360]   And then they say, well, you can't do anything that promotes prostitution or consensual or
[01:12:42.360 --> 01:12:45.280]   non-consensual sex.
[01:12:45.280 --> 01:12:47.480]   That's all.
[01:12:47.480 --> 01:12:53.840]   With the intent to promote or facilitate the prostitution of other persons should be
[01:12:53.840 --> 01:12:59.640]   fine under this title, it's so unclear or so vague.
[01:12:59.640 --> 01:13:01.840]   This is really the problem with all this stuff.
[01:13:01.840 --> 01:13:02.840]   Exactly.
[01:13:02.840 --> 01:13:03.840]   It's very difficult.
[01:13:03.840 --> 01:13:10.520]   And having lost their protections going to err on the side of conservatively getting rid
[01:13:10.520 --> 01:13:11.520]   of...
[01:13:11.520 --> 01:13:17.720]   If I say, I like guys and I'm looking for guys on my Facebook page, that can be interpreted
[01:13:17.720 --> 01:13:19.160]   as soliciting.
[01:13:19.160 --> 01:13:20.240]   And that is illegal.
[01:13:20.240 --> 01:13:22.520]   And Facebook's liable.
[01:13:22.520 --> 01:13:25.960]   And Facebook, I think, reasonably says, well, you can't say that anymore because we don't
[01:13:25.960 --> 01:13:28.240]   want to go to jail for 10 years.
[01:13:28.240 --> 01:13:42.880]   So vaguely written law.
[01:13:42.880 --> 01:13:43.880]   Let's take another break.
[01:13:43.880 --> 01:13:50.360]   I've got even more things to debate about, including the fascinating story of how the
[01:13:50.360 --> 01:13:57.600]   UK government got these Facebook memos and how they're going to use them against Facebook.
[01:13:57.600 --> 01:13:59.440]   And we'll talk about shiny stuff.
[01:13:59.440 --> 01:14:00.800]   New phones or something.
[01:14:00.800 --> 01:14:01.800]   The AirPods.
[01:14:01.800 --> 01:14:02.800]   I don't know.
[01:14:02.800 --> 01:14:05.440]   We'll find something cool and exciting because I don't want people to think it's all about
[01:14:05.440 --> 01:14:06.440]   this.
[01:14:06.440 --> 01:14:10.120]   Patrick Bezha, FrenchSpin.com.
[01:14:10.120 --> 01:14:11.120]   Wonderful to have you.
[01:14:11.120 --> 01:14:12.120]   Thanks for coming back.
[01:14:12.120 --> 01:14:14.320]   Rich D'Muro author of a brand new book.
[01:14:14.320 --> 01:14:17.240]   101 handy tech tips for the iPhone.
[01:14:17.240 --> 01:14:18.920]   It's on Amazon, richontech.tv.
[01:14:18.920 --> 01:14:24.000]   I bet you'd like people to go to richontech.tv to buy this because then you get a bigger chunk.
[01:14:24.000 --> 01:14:26.800]   It's all through Amazon.
[01:14:26.800 --> 01:14:28.800]   You could search either way.
[01:14:28.800 --> 01:14:29.800]   But all things have your own beliefs.
[01:14:29.800 --> 01:14:32.320]   Unless I shipped it to you directly, that would be the biggest chunk.
[01:14:32.320 --> 01:14:34.160]   And you don't want to do that.
[01:14:34.160 --> 01:14:35.640]   No dang way.
[01:14:35.640 --> 01:14:37.200]   I'm not getting in the shipping business.
[01:14:37.200 --> 01:14:38.200]   No thanks.
[01:14:38.200 --> 01:14:39.200]   Yes.
[01:14:39.200 --> 01:14:44.880]   And Sam O'Bool-Samid, who does not ship cars but drives them out here for us to look
[01:14:44.880 --> 01:14:45.880]   at.
[01:14:45.880 --> 01:14:47.920]   He is a senior analyst at Navigant Research.
[01:14:47.920 --> 01:14:52.400]   There's a lot of automotive reporting and it's always good to have you, Sam.
[01:14:52.400 --> 01:14:55.320]   Our show today brought to you by Stamps.com.
[01:14:55.320 --> 01:14:58.120]   The busy season of the post office.
[01:14:58.120 --> 01:15:01.800]   I love, I have to say, first of all, I love the post office.
[01:15:01.800 --> 01:15:07.200]   When I was a kid and the mailman coming up the steps meant that something cool was coming
[01:15:07.200 --> 01:15:08.360]   because I didn't get any bills.
[01:15:08.360 --> 01:15:10.160]   Remember, I only got the good stuff as a kid.
[01:15:10.160 --> 01:15:12.560]   Now they bring me bills, but I still love the post office.
[01:15:12.560 --> 01:15:15.120]   I have this warm spot in my heart for the US Postal Service.
[01:15:15.120 --> 01:15:17.600]   What an amazing thing it is.
[01:15:17.600 --> 01:15:21.960]   But this time of year, people going in, they're mailing their Christmas packages, their Christmas
[01:15:21.960 --> 01:15:28.240]   cards, and if you use the post office to do business, it would be nice, wouldn't it,
[01:15:28.240 --> 01:15:30.320]   to be able to do everything you need to do from your desk?
[01:15:30.320 --> 01:15:31.680]   That's what Stamps.com does.
[01:15:31.680 --> 01:15:35.880]   It saves us so much time during the Hector holiday season because you get all the services
[01:15:35.880 --> 01:15:39.640]   of the US Postal Service right at your desktop.
[01:15:39.640 --> 01:15:44.000]   Starts by buying and printing official US postage for any letter, any package, any class of
[01:15:44.000 --> 01:15:47.400]   mail, but it doesn't require any special hardware, no special ink or anything.
[01:15:47.400 --> 01:15:52.160]   You use your computer, your printer, and then the mail carrier comes and picks it up so
[01:15:52.160 --> 01:15:53.840]   you don't have to go to the post office.
[01:15:53.840 --> 01:15:56.960]   Plus, you get deals you can't get at the post office.
[01:15:56.960 --> 01:16:01.120]   Discounts, you can print postage any time, any day.
[01:16:01.120 --> 01:16:03.840]   It's always open at Stamps.com.
[01:16:03.840 --> 01:16:07.760]   You have a beautiful USB scale that will make sure you always print the right amount of
[01:16:07.760 --> 01:16:08.760]   postage every time.
[01:16:08.760 --> 01:16:11.160]   They'll suggest ways to save money.
[01:16:11.160 --> 01:16:17.360]   They'll fill out forms if you do international mailing or you want to do confirmation.
[01:16:17.360 --> 01:16:21.400]   They'll print out all the forms you need and fill them out for you.
[01:16:21.400 --> 01:16:25.120]   They'll take the data for your recipient from your address book.
[01:16:25.120 --> 01:16:28.920]   If you sell an Etsy Amazon eBay, this is absolutely the way to go.
[01:16:28.920 --> 01:16:30.680]   They'll take it right off the webpage.
[01:16:30.680 --> 01:16:33.040]   Your return address is right on there automatically.
[01:16:33.040 --> 01:16:36.160]   Even a logo and you always have exactly the right postage.
[01:16:36.160 --> 01:16:40.400]   You never pay more or worse send something postage due.
[01:16:40.400 --> 01:16:41.400]   You get discounts on postage.
[01:16:41.400 --> 01:16:43.040]   You can't even get at the post office.
[01:16:43.040 --> 01:16:45.720]   It's the best gift you can give yourself this holiday season.
[01:16:45.720 --> 01:16:48.920]   We use Stamps.com at Twit for all of our business mailing.
[01:16:48.920 --> 01:16:49.920]   You should too.
[01:16:49.920 --> 01:16:51.560]   We're going to give you a great deal.
[01:16:51.560 --> 01:16:53.880]   You can enjoy the Stamps.com service with a special offer.
[01:16:53.880 --> 01:17:00.320]   It includes a four week trial plus free postage and a digital scale.
[01:17:00.320 --> 01:17:01.480]   There's no long term commitment.
[01:17:01.480 --> 01:17:03.160]   Go to Stamps.com.
[01:17:03.160 --> 01:17:05.280]   Click the microphone at the top of the homepage.
[01:17:05.280 --> 01:17:11.320]   The promo code is TWIT and you'll get our amazing offer.
[01:17:11.320 --> 01:17:13.000]   Stamps.com.
[01:17:13.000 --> 01:17:14.080]   Click the microphone.
[01:17:14.080 --> 01:17:16.120]   Click the promo code TWIT.
[01:17:16.120 --> 01:17:17.120]   Thank you Stamps.com.
[01:17:17.120 --> 01:17:21.240]   We've been using Stamps.com for more than a decade and they've been a sponsor for that
[01:17:21.240 --> 01:17:22.240]   long.
[01:17:22.240 --> 01:17:23.120]   We're just big fans.
[01:17:23.120 --> 01:17:25.480]   Stamps.com.
[01:17:25.480 --> 01:17:34.360]   The story of how the UK government got these Facebook emails is fascinating.
[01:17:34.360 --> 01:17:42.040]   I guess the emails were handed over in another court case in Discovery to a company called
[01:17:42.040 --> 01:17:44.360]   643.
[01:17:44.360 --> 01:17:47.720]   The founder of the company was in the United States.
[01:17:47.720 --> 01:17:52.160]   Rather is from the United States was in London for a business trip.
[01:17:52.160 --> 01:17:54.280]   The documents were under seal.
[01:17:54.280 --> 01:17:56.400]   It's a California court case.
[01:17:56.400 --> 01:18:04.040]   But I guess police came to his hotel room and they said, "Show us the documents.
[01:18:04.040 --> 01:18:05.200]   Hand them over."
[01:18:05.200 --> 01:18:06.680]   So he did.
[01:18:06.680 --> 01:18:07.680]   He did.
[01:18:07.680 --> 01:18:13.160]   643, Cherry picked these documents from years ago as part of a lawsuit to force Facebook
[01:18:13.160 --> 01:18:16.440]   to share information on friends of the apps users.
[01:18:16.440 --> 01:18:21.400]   The set of documents by design tells only one side of the story of its important context.
[01:18:21.400 --> 01:18:27.920]   But among other things, there's an email from Mark Zuckerberg when asked, "Hey, this
[01:18:27.920 --> 01:18:29.320]   goes back to 2013.
[01:18:29.320 --> 01:18:35.360]   Twitter launched Vine and Vine used a Facebook tool that let Vine users connect to their
[01:18:35.360 --> 01:18:36.360]   Facebook friends."
[01:18:36.360 --> 01:18:42.800]   Somebody sent an email, somebody from Facebook sent an email to Mark saying, "Hey, there's
[01:18:42.800 --> 01:18:44.440]   a competitive threat here."
[01:18:44.440 --> 01:18:48.000]   The engineer said the email said, "We should cut off Vine's access to Facebook data."
[01:18:48.000 --> 01:18:51.160]   Zuckerberg said, "Yeah, go for it."
[01:18:51.160 --> 01:18:54.160]   That's what we call in the business a smoking gun.
[01:18:54.160 --> 01:18:58.480]   It sounds like the old days of windows isn't done until a lotus doesn't run.
[01:18:58.480 --> 01:18:59.880]   That's what we call a smoking gun.
[01:18:59.880 --> 01:19:05.800]   That's what UK legislators want, why they want to see and ask Mark all about this Mark's
[01:19:05.800 --> 01:19:06.800]   terrified.
[01:19:06.800 --> 01:19:09.120]   I don't think he's going.
[01:19:09.120 --> 01:19:14.880]   A lawyer that Bloomberg consulted said, "Refusal of access to Vine data could be seen as,
[01:19:14.880 --> 01:19:18.960]   quote, 'potential refusal to deal with rivals.'"
[01:19:18.960 --> 01:19:23.000]   That's illegal in the UK.
[01:19:23.000 --> 01:19:26.280]   But you would need to show that Facebook is essential to users and it's not clear that
[01:19:26.280 --> 01:19:27.280]   it is.
[01:19:27.280 --> 01:19:32.240]   "Members of Parliament will not hesitate to wield a big stick to enforce competition
[01:19:32.240 --> 01:19:35.400]   rules and taxation," said a UK lawmaker.
[01:19:35.400 --> 01:19:42.360]   A member of the European Parliament, according to one of the documents, Zuckerberg personally
[01:19:42.360 --> 01:19:48.120]   reviewed a list of apps made by strategic competitors that were not allowed to use Facebook's advertising
[01:19:48.120 --> 01:19:53.960]   services or services for applications without, quote, "Mark level signoff."
[01:19:53.960 --> 01:19:58.560]   I like the Mark level signoff.
[01:19:58.560 --> 01:20:01.880]   Facebook says, "No, but it's an out of date policy.
[01:20:01.880 --> 01:20:04.040]   We're going to review it."
[01:20:04.040 --> 01:20:11.000]   643's founder Ted Kramer said, "I didn't mean to do it.
[01:20:11.000 --> 01:20:14.040]   They made me."
[01:20:14.040 --> 01:20:16.320]   What a story.
[01:20:16.320 --> 01:20:18.160]   So we'll see what happens.
[01:20:18.160 --> 01:20:22.800]   Kramer was ordered by a judge a couple of days ago to surrender his laptop to a forensic
[01:20:22.800 --> 01:20:26.880]   expert after admitting he turned over the documents to British lawmakers in violation
[01:20:26.880 --> 01:20:28.960]   of a US court order.
[01:20:28.960 --> 01:20:33.960]   California Superior Court judge Raymond Swope said, "What happened here is unconscionable."
[01:20:33.960 --> 01:20:38.600]   Facebook wants the laptop to be examined in order to determine what happened in the UK,
[01:20:38.600 --> 01:20:41.920]   to what extent the court order was breached and how much of its confidential information
[01:20:41.920 --> 01:20:48.120]   has been divulged to the committee.
[01:20:48.120 --> 01:20:51.320]   I guess the only question I have here is, was he?
[01:20:51.320 --> 01:20:54.680]   Did he have all of those documents in his laptop all the time?
[01:20:54.680 --> 01:20:55.680]   Yes.
[01:20:55.680 --> 01:20:57.480]   That's the weird part.
[01:20:57.480 --> 01:21:01.040]   Well, you know, these things happen.
[01:21:01.040 --> 01:21:02.560]   I thought these were fascinating.
[01:21:02.560 --> 01:21:04.880]   I just love reading every single one of these.
[01:21:04.880 --> 01:21:06.240]   I just saw them on Twitter.
[01:21:06.240 --> 01:21:08.160]   There's like six or seven linked.
[01:21:08.160 --> 01:21:14.480]   It gives you an inside look at the things that you think just sort of happen when these
[01:21:14.480 --> 01:21:18.480]   companies change and evolve their service or their product or they shut off certain
[01:21:18.480 --> 01:21:20.200]   functionality.
[01:21:20.200 --> 01:21:26.680]   It really gives you a look into the fact that none of that stuff happens randomly, like
[01:21:26.680 --> 01:21:34.520]   shutting off the API and it's a fascinating inside look at the mind of Facebook and all
[01:21:34.520 --> 01:21:36.880]   these tech companies.
[01:21:36.880 --> 01:21:42.480]   To me, it just goes to show that they're pushing us down these silos where they want
[01:21:42.480 --> 01:21:47.920]   you to get into their product, get into their system and they just don't want that interoperability
[01:21:47.920 --> 01:21:49.880]   with the other products and the other systems.
[01:21:49.880 --> 01:21:51.520]   It used to be the best example.
[01:21:51.520 --> 01:21:57.440]   I remember back in the day there was this product called Plaxo and you would upload your address
[01:21:57.440 --> 01:21:58.440]   book.
[01:21:58.440 --> 01:22:01.440]   Oh, God, I'm the address book.
[01:22:01.440 --> 01:22:02.440]   Yeah, it would.
[01:22:02.440 --> 01:22:03.440]   What a blight.
[01:22:03.440 --> 01:22:04.440]   Right.
[01:22:04.440 --> 01:22:07.520]   But for a couple of months, everyone would update your address book.
[01:22:07.520 --> 01:22:11.080]   And it was that kind of thing that like it just kind of crossed all boundaries.
[01:22:11.080 --> 01:22:13.160]   You know, like it just worked with everything.
[01:22:13.160 --> 01:22:14.520]   Everything went into it.
[01:22:14.520 --> 01:22:19.120]   And I just feel like Facebook and all these companies, they want you to kind of be in,
[01:22:19.120 --> 01:22:21.360]   but they don't want it to interact with anything else.
[01:22:21.360 --> 01:22:25.200]   And just something as simple as the iPhone right now, it used to be you could have all
[01:22:25.200 --> 01:22:27.520]   your contacts updated.
[01:22:27.520 --> 01:22:32.640]   The photos on your iPhone would kind of take it from the Facebook API, which to me is a
[01:22:32.640 --> 01:22:36.080]   great system because I'm not going to sit there and update pictures of people on my
[01:22:36.080 --> 01:22:37.080]   phone.
[01:22:37.080 --> 01:22:39.560]   So if it can pull it from Facebook, I love it.
[01:22:39.560 --> 01:22:40.560]   I loved it.
[01:22:40.560 --> 01:22:44.560]   And I don't know what the UK law is, but I feel like Facebook should have the right to
[01:22:44.560 --> 01:22:46.160]   say no to people.
[01:22:46.160 --> 01:22:49.720]   If the, you know, the problem is that they were using it selectively.
[01:22:49.720 --> 01:22:52.280]   So if you were a competitor, you can't use the API.
[01:22:52.280 --> 01:22:56.760]   But if you're somebody, they used it in a way to incent people to work with them.
[01:22:56.760 --> 01:23:01.440]   Yeah, we'll let you have some of this information as long as you play good with us.
[01:23:01.440 --> 01:23:07.080]   Yeah, there was something about like, you had to spend like $250,000 on ads to get access
[01:23:07.080 --> 01:23:08.080]   to something.
[01:23:08.080 --> 01:23:11.720]   I mean, it was, I mean, clearly they, they, yeah, they were punishing people that they
[01:23:11.720 --> 01:23:16.840]   didn't want on their platform in ways that the public didn't realize or the average person
[01:23:16.840 --> 01:23:19.440]   or maybe even the companies that were working with them didn't realize.
[01:23:19.440 --> 01:23:20.440]   Okay, what's going on here?
[01:23:20.440 --> 01:23:22.560]   We thought we were all kind of in this together.
[01:23:22.560 --> 01:23:27.240]   And I don't know the law in this matter, but I can understand why as a business person,
[01:23:27.240 --> 01:23:28.240]   you would do that.
[01:23:28.240 --> 01:23:29.880]   Hey, these guys, I don't want them to use our data.
[01:23:29.880 --> 01:23:31.120]   Hey, I want them to use our data.
[01:23:31.120 --> 01:23:32.600]   They're giving us money.
[01:23:32.600 --> 01:23:33.600]   That seems fair.
[01:23:33.600 --> 01:23:35.160]   See, that's annoying for the end user though.
[01:23:35.160 --> 01:23:40.000]   That's where I get annoyed because as the, as the average person, the end user, I don't
[01:23:40.000 --> 01:23:42.840]   want the company that has the biggest checkbook to be able to.
[01:23:42.840 --> 01:23:46.840]   It's kind of like with the Android phones, not so much anymore, but it still happens.
[01:23:46.840 --> 01:23:50.120]   You know, there's like all these apps on there from these random companies.
[01:23:50.120 --> 01:23:54.360]   And it's like, well, they just paid Verizon to load those apps onto the phone when you
[01:23:54.360 --> 01:23:55.360]   buy it.
[01:23:55.360 --> 01:23:58.920]   And you got to sit there and delete all them or sometimes you couldn't delete them.
[01:23:58.920 --> 01:24:02.320]   But it's, you know, as the end user, you don't really necessarily want that.
[01:24:02.320 --> 01:24:06.040]   But I understand, like you said, from a company standpoint, of course, that you got some money
[01:24:06.040 --> 01:24:07.040]   that's working together.
[01:24:07.040 --> 01:24:08.040]   Well, here's the disconnect.
[01:24:08.040 --> 01:24:09.040]   Let's work together.
[01:24:09.040 --> 01:24:11.480]   All the value the company has is value you gave it.
[01:24:11.480 --> 01:24:13.600]   It's the information you gave the company.
[01:24:13.600 --> 01:24:16.920]   And then they're deciding who they should parse it out to and who they shouldn't.
[01:24:16.920 --> 01:24:22.400]   You know, as a company, you know, a company is incentivized to create lock-in.
[01:24:22.400 --> 01:24:27.840]   You know, they want to keep you as a, as a, as a customer, any way that they can.
[01:24:27.840 --> 01:24:31.480]   And you know, every company you look at does that, or at least they try to.
[01:24:31.480 --> 01:24:36.160]   They try to find ways to lock in their customers and, and make the switching costs as high
[01:24:36.160 --> 01:24:41.960]   as they possibly can because it's, it's expensive to, to get customers.
[01:24:41.960 --> 01:24:48.280]   So if you can keep the customers you have, you know, of course for, for us as consumers,
[01:24:48.280 --> 01:24:49.960]   we have a responsibility.
[01:24:49.960 --> 01:24:53.800]   If we don't like the way that companies are treating our treating us and treating our
[01:24:53.800 --> 01:24:58.400]   data, we have a responsibility to not be passive to actually do something.
[01:24:58.400 --> 01:24:59.760]   You're not a Facebook user.
[01:24:59.760 --> 01:25:00.760]   You love Facebook.
[01:25:00.760 --> 01:25:01.760]   Yeah, I love Facebook.
[01:25:01.760 --> 01:25:02.760]   Probably, partly for that reason.
[01:25:02.760 --> 01:25:03.760]   Yeah, exactly.
[01:25:03.760 --> 01:25:04.760]   You know, and for, for a lot of reason.
[01:25:04.760 --> 01:25:08.000]   But Sam, don't you think, don't you think we're seeing this more with companies doing
[01:25:08.000 --> 01:25:11.920]   that where they, I feel like when the internet started, these companies did work.
[01:25:11.920 --> 01:25:12.920]   Together.
[01:25:12.920 --> 01:25:15.120]   And it was like, oh, if you don't want to, if you want to export your data, we have
[01:25:15.120 --> 01:25:17.320]   a data export tool and we have an import tool.
[01:25:17.320 --> 01:25:18.320]   Yeah, absolutely.
[01:25:18.320 --> 01:25:19.920]   And nowadays it's getting so complicated.
[01:25:19.920 --> 01:25:23.680]   Like I went, I remember when I shut down my tumblr and I wanted to like, I was like,
[01:25:23.680 --> 01:25:28.280]   Oh, surely there's a way to import tumblr to whatever, you know.
[01:25:28.280 --> 01:25:29.600]   And it just wasn't there.
[01:25:29.600 --> 01:25:32.200]   Like I couldn't believe I couldn't find a simple tool.
[01:25:32.200 --> 01:25:34.720]   And it turns out that, you know, once you're in, they want you to stay in.
[01:25:34.720 --> 01:25:37.760]   And I can't remember, maybe it wasn't tumblr specifically, but it was, you know, you look
[01:25:37.760 --> 01:25:40.360]   for these little tools that you think are super simple.
[01:25:40.360 --> 01:25:43.880]   I mean, even something like Google Photos, I was thinking about it.
[01:25:43.880 --> 01:25:48.240]   Everyone's so hip on Google Photos, but there will come a day when something else better
[01:25:48.240 --> 01:25:49.760]   comes along.
[01:25:49.760 --> 01:25:53.760]   And it'd be nice if it was like a one-click import from Google Photos.
[01:25:53.760 --> 01:25:54.760]   But guess what?
[01:25:54.760 --> 01:25:55.760]   No way.
[01:25:55.760 --> 01:25:58.720]   You're going to have to go into your back end of Google takeout, you know, wait three
[01:25:58.720 --> 01:26:00.840]   days for them to zip your stuff up.
[01:26:00.840 --> 01:26:02.960]   And then somehow, I mean, no one's going to do that.
[01:26:02.960 --> 01:26:07.120]   That's the bottom line is a, it's, it's there, but it's not necessarily easy.
[01:26:07.120 --> 01:26:10.320]   And I just, I feel like it's a newer thing with the internet, with these companies now.
[01:26:10.320 --> 01:26:11.320]   Totally agree.
[01:26:11.320 --> 01:26:13.320]   Siloing is really bad.
[01:26:13.320 --> 01:26:16.920]   And, you know, and part of the problem is, you know, it's good for business.
[01:26:16.920 --> 01:26:21.680]   Well, as public companies, you know, they're, you know, they, they, in order to keep their
[01:26:21.680 --> 01:26:23.600]   stock price up, they have to show growth.
[01:26:23.600 --> 01:26:24.600]   Right.
[01:26:24.600 --> 01:26:29.240]   And one way to do that is to keep the customers, you know, to keep your customers from leaving.
[01:26:29.240 --> 01:26:33.000]   And you know, so this, the siloing is part of that strategy to,
[01:26:33.000 --> 01:26:34.720]   On the king of it is Apple, right?
[01:26:34.720 --> 01:26:35.720]   Exactly.
[01:26:35.720 --> 01:26:37.040]   I mean, if you, everything works better.
[01:26:37.040 --> 01:26:40.960]   Here's a great article from Andy bio who does waxy links.
[01:26:40.960 --> 01:26:44.840]   And he's one of, he's a internet pioneer, really great guy.
[01:26:44.840 --> 01:26:47.560]   He gives you this example with Quora.
[01:26:47.560 --> 01:26:51.640]   Yesterday says Quora announced a hundred million user accounts were compromised.
[01:26:51.640 --> 01:26:54.880]   You know Quora, that's the site where you could ask a question and people pitch in and
[01:26:54.880 --> 01:26:55.880]   give it the answers.
[01:26:55.880 --> 01:26:58.040]   But what I didn't know is that Quora.
[01:26:58.040 --> 01:26:59.400]   Or something resembling answers.
[01:26:59.400 --> 01:27:00.400]   Yeah.
[01:27:00.400 --> 01:27:01.400]   Some of the answers are good.
[01:27:01.400 --> 01:27:02.400]   Some not.
[01:27:02.400 --> 01:27:07.040]   He says, well, you should never ever use Quora.
[01:27:07.040 --> 01:27:12.920]   And he says part of the reasons is data breach, but really the real reason is that Quora hoards
[01:27:12.920 --> 01:27:13.920]   all this information.
[01:27:13.920 --> 01:27:17.360]   The information, you know, Quora's value comes out of the answers.
[01:27:17.360 --> 01:27:21.960]   We give it just like IMDB was built by our contributions.
[01:27:21.960 --> 01:27:25.800]   Quora's mission, they say on their about page to share and grow the world's knowledge 300
[01:27:25.800 --> 01:27:29.600]   million monthly users, 40 million questions.
[01:27:29.600 --> 01:27:32.720]   They've got a lot of information, but they do everything you can.
[01:27:32.720 --> 01:27:35.160]   They can to make sure you can't get that contributions out.
[01:27:35.160 --> 01:27:40.640]   There's no public API, no backup, no export tool restricted to access to answers without
[01:27:40.640 --> 01:27:41.640]   an account.
[01:27:41.640 --> 01:27:45.160]   They block scrapers, but the worst one, and you could say, Oh, well, all right, that
[01:27:45.160 --> 01:27:46.160]   all makes sense.
[01:27:46.160 --> 01:27:48.480]   They didn't want to, you know, put all the effort in to do all that.
[01:27:48.480 --> 01:27:51.040]   They block the internet archive.
[01:27:51.040 --> 01:27:56.800]   For years, Quora has explicitly forbidden the internet archive from indexing their site.
[01:27:56.800 --> 01:28:01.960]   Quora says, well, people share a lot of sensitive information on Quora.
[01:28:01.960 --> 01:28:05.400]   We want to keep it within Quora so that they can delete it.
[01:28:05.400 --> 01:28:09.320]   It's the right to be forgotten directly on Quora and then there is no other copy elsewhere.
[01:28:09.320 --> 01:28:10.960]   I kind of understand that.
[01:28:10.960 --> 01:28:16.040]   But at the same time, the whole mission of the internet archive is to preserve exactly
[01:28:16.040 --> 01:28:17.040]   this kind of information.
[01:28:17.040 --> 01:28:22.320]   And it is kind of in Quora's business interest to keep it to themselves.
[01:28:22.320 --> 01:28:29.040]   Quora, by the way, you know, the real risk here is Quora's long term prospects are unknown.
[01:28:29.040 --> 01:28:33.880]   They've raised $225 million, four rounds of funding funding.
[01:28:33.880 --> 01:28:35.480]   Do they have any source of revenue?
[01:28:35.480 --> 01:28:37.240]   They have no source of revenue.
[01:28:37.240 --> 01:28:39.240]   One point seven billion dollar valuation.
[01:28:39.240 --> 01:28:40.680]   I mean, yeah, you could pay.
[01:28:40.680 --> 01:28:42.440]   Are there even ads on Quora?
[01:28:42.440 --> 01:28:43.440]   I don't even know.
[01:28:43.440 --> 01:28:48.240]   I feel like they're, yeah, I think maybe they want you to pay so you can see more.
[01:28:48.240 --> 01:28:52.280]   Oh, but but the issue is, I don't know, based based on what I've seen.
[01:28:52.280 --> 01:28:57.520]   I haven't seen anything that would actually entice me to pay the same war of the same.
[01:28:57.520 --> 01:29:00.360]   The issue is all these people put all this information and knowledge in there is some
[01:29:00.360 --> 01:29:02.200]   really good stuff in Quora.
[01:29:02.200 --> 01:29:09.040]   Like there is, for instance, in what is it, Stack Exchange, the really great programmers
[01:29:09.040 --> 01:29:12.440]   site where you can get all the information you'd ever want.
[01:29:12.440 --> 01:29:13.440]   That has an API.
[01:29:13.440 --> 01:29:15.080]   That has a way of exfiltrating the data.
[01:29:15.080 --> 01:29:16.920]   That has a way of sharing that data.
[01:29:16.920 --> 01:29:20.520]   Quora is taking all that data that users contributed in locking in.
[01:29:20.520 --> 01:29:24.200]   It does remind me of IMDB, which didn't have a, they didn't have an API.
[01:29:24.200 --> 01:29:27.480]   They had an interface, but was it, oh no, CDDB.
[01:29:27.480 --> 01:29:29.040]   Do you remember that?
[01:29:29.040 --> 01:29:30.040]   Oh, wow.
[01:29:30.040 --> 01:29:31.040]   Bringing it way back.
[01:29:31.040 --> 01:29:32.040]   Way back.
[01:29:32.040 --> 01:29:33.040]   Old school, man.
[01:29:33.040 --> 01:29:34.240]   That was a great idea, right?
[01:29:34.240 --> 01:29:35.240]   You got a CD.
[01:29:35.240 --> 01:29:37.600]   You'd enter in all the tracks by hand.
[01:29:37.600 --> 01:29:39.800]   It was a great big database.
[01:29:39.800 --> 01:29:44.480]   They got sold and they went private and some big company made money off all the data that
[01:29:44.480 --> 01:29:45.880]   everybody used CDDB.
[01:29:45.880 --> 01:29:47.640]   I think, didn't grace note by CDDB.
[01:29:47.640 --> 01:29:48.640]   Grace note bottom.
[01:29:48.640 --> 01:29:51.160]   But to be fair, I mean, it didn't take me that much.
[01:29:51.160 --> 01:29:55.120]   I used to rip all my CDs and I used to love correcting things and entering.
[01:29:55.120 --> 01:29:56.640]   I mean, I don't feel so bad.
[01:29:56.640 --> 01:30:00.920]   I'm not like waiting for my payment check from grace note, which by the way, my company
[01:30:00.920 --> 01:30:02.440]   used to own actually.
[01:30:02.440 --> 01:30:05.640]   So in a weird way, I think I made money off of that.
[01:30:05.640 --> 01:30:08.080]   Yeah, Tribune Media used to own grace note.
[01:30:08.080 --> 01:30:09.080]   That's funny.
[01:30:09.080 --> 01:30:10.080]   They don't own it anymore.
[01:30:10.080 --> 01:30:11.080]   Sony, oh no, I think.
[01:30:11.080 --> 01:30:12.080]   Yeah.
[01:30:12.080 --> 01:30:13.080]   No, okay.
[01:30:13.080 --> 01:30:14.080]   But this is a point of the point.
[01:30:14.080 --> 01:30:15.080]   Oh no, wait a minute.
[01:30:15.080 --> 01:30:16.080]   Sorry.
[01:30:16.080 --> 01:30:17.080]   What?
[01:30:17.080 --> 01:30:21.880]   And then it was sold to Tribune Media Services.
[01:30:21.880 --> 01:30:23.960]   That's when you got it from Sony.
[01:30:23.960 --> 01:30:25.760]   But then they resold it to Nielsen.
[01:30:25.760 --> 01:30:26.760]   So Nielsen.
[01:30:26.760 --> 01:30:27.760]   Nielsen.
[01:30:27.760 --> 01:30:28.760]   That's a great company.
[01:30:28.760 --> 01:30:31.160]   Don't say anything bad about Nielsen.
[01:30:31.160 --> 01:30:32.160]   We can get in trouble.
[01:30:32.160 --> 01:30:34.320]   Yeah, I got to watch what I say there.
[01:30:34.320 --> 01:30:35.320]   I'll be sure.
[01:30:35.320 --> 01:30:36.320]   Great.
[01:30:36.320 --> 01:30:37.320]   Love ratings.
[01:30:37.320 --> 01:30:38.320]   Love ratings.
[01:30:38.320 --> 01:30:43.040]   But this is why I was surprised when you guys heard of movies anywhere.
[01:30:43.040 --> 01:30:45.520]   It's like the service actually Disney came up with.
[01:30:45.520 --> 01:30:46.520]   Yeah.
[01:30:46.520 --> 01:30:49.480]   So I unlocked your movies from iTunes and Amazon.
[01:30:49.480 --> 01:30:55.640]   This is one of the best examples of internet companies actually doing something really good
[01:30:55.640 --> 01:30:57.080]   for the consumer.
[01:30:57.080 --> 01:30:58.080]   And I get it.
[01:30:58.080 --> 01:31:01.040]   It gets you to buy more movies because before that you're like, "I should go with the digital
[01:31:01.040 --> 01:31:02.040]   edition.
[01:31:02.040 --> 01:31:05.800]   Do I want to spend $20 on something that I can only use on iTunes?"
[01:31:05.800 --> 01:31:06.800]   Now it's like, "Okay, fine.
[01:31:06.800 --> 01:31:08.000]   I can use it on Amazon.
[01:31:08.000 --> 01:31:09.160]   I can use it on my iPad.
[01:31:09.160 --> 01:31:11.320]   I can use it anywhere."
[01:31:11.320 --> 01:31:15.280]   Because if as long as you're using it inside one of these services.
[01:31:15.280 --> 01:31:19.160]   The funny thing is there are movie companies that say you can't be on movies anywhere.
[01:31:19.160 --> 01:31:20.160]   But you can connect.
[01:31:20.160 --> 01:31:22.000]   I have connected on my movies anywhere.
[01:31:22.000 --> 01:31:23.000]   I love this.
[01:31:23.000 --> 01:31:26.600]   iTunes prime video voodoo, "XFINITY NOW."
[01:31:26.600 --> 01:31:28.080]   So this was always an issue.
[01:31:28.080 --> 01:31:31.560]   You buy an on-demand movie from your cable provider.
[01:31:31.560 --> 01:31:33.080]   That's a dumb thing to do.
[01:31:33.080 --> 01:31:34.080]   You'll never...
[01:31:34.080 --> 01:31:35.080]   I guess they...
[01:31:35.080 --> 01:31:36.960]   When you give that cable box back, goodbye.
[01:31:36.960 --> 01:31:37.960]   Goodbye.
[01:31:37.960 --> 01:31:39.800]   Google Play Microsoft and FanDang on now.
[01:31:39.800 --> 01:31:43.360]   And I've got them all connected because now I have a huge database of all the movies
[01:31:43.360 --> 01:31:44.360]   I've ever bought.
[01:31:44.360 --> 01:31:48.440]   Once Disney launches Disney Plus, they're streaming service next year.
[01:31:48.440 --> 01:31:50.440]   Disney movies won't be on here.
[01:31:50.440 --> 01:31:55.400]   Or will movies anywhere become something that's only available to Disney Plus subscribers?
[01:31:55.400 --> 01:31:56.400]   That's the problem.
[01:31:56.400 --> 01:31:57.400]   This is too good to be true.
[01:31:57.400 --> 01:32:00.840]   Or will the companies not like it as much because now Disney...
[01:32:00.840 --> 01:32:03.480]   But the thing that Disney did well is they don't publicize it.
[01:32:03.480 --> 01:32:05.840]   It's their technology number one.
[01:32:05.840 --> 01:32:10.840]   And the only major studio that's not on board right now is Paramount.
[01:32:10.840 --> 01:32:11.840]   They're the only holdout.
[01:32:11.840 --> 01:32:15.760]   So all my movies that I have from Paramount on my iPad don't show up on my Amazon TV.
[01:32:15.760 --> 01:32:16.760]   And I'm like, "What's going on here?"
[01:32:16.760 --> 01:32:19.200]   I go at all the Star Trek movies, but I can't...
[01:32:19.200 --> 01:32:20.480]   They're not in my movies anywhere.
[01:32:20.480 --> 01:32:22.880]   But look, I got 114 movies in here.
[01:32:22.880 --> 01:32:24.840]   How many movies are in your movies anywhere?
[01:32:24.840 --> 01:32:26.920]   I think I've got 84 in mine.
[01:32:26.920 --> 01:32:27.920]   Look at that.
[01:32:27.920 --> 01:32:28.920]   That's really...
[01:32:28.920 --> 01:32:29.920]   But that's pretty good.
[01:32:29.920 --> 01:32:32.840]   But this is my point is this is an example of they didn't necessarily make it where it's
[01:32:32.840 --> 01:32:36.000]   a takeout thing, but they made it work for the average consumer.
[01:32:36.000 --> 01:32:40.260]   My thing was always, you got to kind of pick this silo of where you buy your movie really
[01:32:40.260 --> 01:32:41.260]   makes a difference.
[01:32:41.260 --> 01:32:46.080]   And in 10 years into digital movies, the fact that they sort of changed that and got rid
[01:32:46.080 --> 01:32:48.000]   of that is a really cool thing for us.
[01:32:48.000 --> 01:32:49.000]   Don't judge me.
[01:32:49.000 --> 01:32:50.560]   So much of other companies can take a...
[01:32:50.560 --> 01:32:51.560]   Don't judge me.
[01:32:51.560 --> 01:32:55.320]   I bought the born movies because Lisa wanted me to.
[01:32:55.320 --> 01:32:57.440]   I own all the born movies.
[01:32:57.440 --> 01:33:01.680]   No one would ever judge you for doing what makes your life happy.
[01:33:01.680 --> 01:33:02.680]   Look how many Harry Potter's.
[01:33:02.680 --> 01:33:04.560]   I have them all, baby.
[01:33:04.560 --> 01:33:06.320]   One is out of order.
[01:33:06.320 --> 01:33:07.320]   See, that would really bug me.
[01:33:07.320 --> 01:33:08.400]   Yeah, it is bugging me.
[01:33:08.400 --> 01:33:09.640]   How do I fix that?
[01:33:09.640 --> 01:33:10.640]   Can I drag that?
[01:33:10.640 --> 01:33:11.640]   Oh, man.
[01:33:11.640 --> 01:33:14.980]   Oh, it's recently added.
[01:33:14.980 --> 01:33:19.060]   So let's make it by release date or no A to Z.
[01:33:19.060 --> 01:33:20.060]   What will happen then?
[01:33:20.060 --> 01:33:22.140]   No, then they won't be in order at all.
[01:33:22.140 --> 01:33:25.260]   Oh, release date should work.
[01:33:25.260 --> 01:33:26.260]   That's all.
[01:33:26.260 --> 01:33:27.260]   Oh, there they are.
[01:33:27.260 --> 01:33:28.260]   Oh, no.
[01:33:28.260 --> 01:33:31.700]   It's still two, seven, seven, four, six, five, three, one.
[01:33:31.700 --> 01:33:32.700]   That sounds like...
[01:33:32.700 --> 01:33:33.700]   That makes no sense.
[01:33:33.700 --> 01:33:34.700]   That sounds like what's your name's number?
[01:33:34.700 --> 01:33:35.700]   A bad 1980 stuff.
[01:33:35.700 --> 01:33:39.260]   Two, seven, seven, four, six, five, three, one.
[01:33:39.260 --> 01:33:40.260]   Is that Jenny's number?
[01:33:40.260 --> 01:33:41.260]   Number known as...
[01:33:41.260 --> 01:33:47.940]   Everybody's mad at me because I dissed the born movies.
[01:33:47.940 --> 01:33:50.540]   I guess everybody likes the born movies.
[01:33:50.540 --> 01:33:52.080]   I didn't know people didn't like those.
[01:33:52.080 --> 01:33:53.080]   I thought people generally...
[01:33:53.080 --> 01:33:55.080]   Never entertaining them.
[01:33:55.080 --> 01:33:59.720]   Just tell them you also have the fate and the furious in there.
[01:33:59.720 --> 01:34:00.720]   Everyone will like you.
[01:34:00.720 --> 01:34:01.720]   I got that free.
[01:34:01.720 --> 01:34:02.720]   Yeah, that's great.
[01:34:02.720 --> 01:34:05.000]   Some of these movies in here are free for sure.
[01:34:05.000 --> 01:34:06.360]   I got that free.
[01:34:06.360 --> 01:34:08.000]   It was part of the free deal.
[01:34:08.000 --> 01:34:09.000]   Yeah.
[01:34:09.000 --> 01:34:10.500]   Maybe I did buy Elf.
[01:34:10.500 --> 01:34:11.500]   I don't know.
[01:34:11.500 --> 01:34:12.500]   Enough said.
[01:34:12.500 --> 01:34:13.500]   No, I think I got Elf for free.
[01:34:13.500 --> 01:34:15.000]   Elf was like a Google play.
[01:34:15.000 --> 01:34:16.000]   They gave it away for free.
[01:34:16.000 --> 01:34:17.000]   I think so.
[01:34:17.000 --> 01:34:19.200]   Yeah, and I got big hero five for free and big for free.
[01:34:19.200 --> 01:34:20.200]   Yeah.
[01:34:20.200 --> 01:34:22.460]   But the big Lebasko and the big sleep, I bought that.
[01:34:22.460 --> 01:34:23.460]   Those are all big movies.
[01:34:23.460 --> 01:34:24.460]   That's a good one.
[01:34:24.460 --> 01:34:25.460]   That's a good one.
[01:34:25.460 --> 01:34:28.180]   See if you can organize them by big in the title.
[01:34:28.180 --> 01:34:33.260]   I got all numbers, 2001, 308 miles.
[01:34:33.260 --> 01:34:34.980]   Those are down together.
[01:34:34.980 --> 01:34:41.580]   My favorite is Harry Potter, 2774651.
[01:34:41.580 --> 01:34:42.580]   Don't lose that number.
[01:34:42.580 --> 01:34:46.500]   Our show today brought to you by Ring.
[01:34:46.500 --> 01:34:50.460]   You know, when we travel, I love the fact that I've got a Ring video doorbell and ring
[01:34:50.460 --> 01:34:51.660]   cameras around the house.
[01:34:51.660 --> 01:34:52.660]   It's always fun.
[01:34:52.660 --> 01:34:54.540]   I don't look for bad guys.
[01:34:54.540 --> 01:34:59.700]   We've got a nice safe neighborhood, but I do check on the cats periodically.
[01:34:59.700 --> 01:35:02.380]   Now I've got the Ring alarm system.
[01:35:02.380 --> 01:35:07.020]   This is the way to protect your entire home home security.
[01:35:07.020 --> 01:35:09.540]   $10 a month.
[01:35:09.540 --> 01:35:11.020]   Ring invented the video doorbell.
[01:35:11.020 --> 01:35:12.780]   Jamie Siminoff, you know him.
[01:35:12.780 --> 01:35:14.980]   Awesome guy.
[01:35:14.980 --> 01:35:18.180]   He thought there was another step to take.
[01:35:18.180 --> 01:35:22.780]   Traditional alarm companies, they make their money with high monthly premiums and they
[01:35:22.780 --> 01:35:25.420]   love to tie you up to those long term contracts.
[01:35:25.420 --> 01:35:28.860]   Two years, no, three, try three year contracts.
[01:35:28.860 --> 01:35:30.300]   Ring changed all that.
[01:35:30.300 --> 01:35:32.100]   Ring alarm is an easy to install.
[01:35:32.100 --> 01:35:35.780]   You can do it yourself, which is nice because it means you can also take it down and take
[01:35:35.780 --> 01:35:36.780]   it with you.
[01:35:36.780 --> 01:35:37.780]   So it's great.
[01:35:37.780 --> 01:35:40.620]   If you're planning a move or you're a runner, this is a really nice system.
[01:35:40.620 --> 01:35:43.140]   It doesn't even install or you can do it yourself.
[01:35:43.140 --> 01:35:48.100]   It's affordable, but it's a home security system with no long term contract.
[01:35:48.100 --> 01:35:51.700]   So you build the system that's right for your home, have it up and running in minutes,
[01:35:51.700 --> 01:35:54.060]   add sensors as needed.
[01:35:54.060 --> 01:35:58.500]   The Ring alarm security kit comes with everything you need to protect your home and 24/7 professional
[01:35:58.500 --> 01:36:01.580]   monitoring $10 a month.
[01:36:01.580 --> 01:36:04.340]   It's a third with those other guys charged with no contract.
[01:36:04.340 --> 01:36:06.620]   You get a base station that keeps your alarm system online.
[01:36:06.620 --> 01:36:08.300]   It connects to mobile devices.
[01:36:08.300 --> 01:36:09.300]   That's nice.
[01:36:09.300 --> 01:36:11.860]   So if they cut the phone lines, it works.
[01:36:11.860 --> 01:36:14.780]   You've got a keypad to arm and disarm your alarm system.
[01:36:14.780 --> 01:36:19.220]   A contact sensor, you can put it on a window or a door to know when somebody's coming in.
[01:36:19.220 --> 01:36:21.060]   Motion detectors got to put that in the hall.
[01:36:21.060 --> 01:36:23.780]   So you'll see people walking down the hall.
[01:36:23.780 --> 01:36:27.860]   Range extended to means you can extend the range of the base station throughout the entire
[01:36:27.860 --> 01:36:31.180]   house or even out to outbuildings and places like that.
[01:36:31.180 --> 01:36:34.380]   This really is the best way to protect your in higher home.
[01:36:34.380 --> 01:36:36.940]   The Ring alarm security kit.
[01:36:36.940 --> 01:36:42.860]   Right now you get it at ring.com/twit or visit a retail store if you want to take a look
[01:36:42.860 --> 01:36:44.420]   at it in person.
[01:36:44.420 --> 01:36:46.220]   Go to ring.com/twit.
[01:36:46.220 --> 01:36:53.220]   Learn how home, whole home security can be yours $10 a month.
[01:36:53.220 --> 01:36:56.700]   There's no reason to let the bad guys infiltrate.
[01:36:56.700 --> 01:36:57.700]   And I love it.
[01:36:57.700 --> 01:36:58.780]   They have lots more sensors you can buy.
[01:36:58.780 --> 01:37:01.140]   This is the Ring base unit.
[01:37:01.140 --> 01:37:03.420]   Looks kind of like a Wi-Fi access point.
[01:37:03.420 --> 01:37:05.300]   It's just a little white box.
[01:37:05.300 --> 01:37:06.300]   The keypad.
[01:37:06.300 --> 01:37:07.660]   This is such a great idea.
[01:37:07.660 --> 01:37:09.660]   Jamie's done it again.
[01:37:09.660 --> 01:37:13.420]   Ring.com/twit.
[01:37:13.420 --> 01:37:17.180]   We thank Ring for their support and all the good things they've done.
[01:37:17.180 --> 01:37:22.180]   By the way, this is a Z-Wave Plus unit so you can use it with other Z-Wave devices too.
[01:37:22.180 --> 01:37:23.180]   No tools required.
[01:37:23.180 --> 01:37:26.140]   You don't even need a screwdriver.
[01:37:26.140 --> 01:37:27.540]   Stick them up.
[01:37:27.540 --> 01:37:31.380]   And if you need to move, take them down and set them up again in another place.
[01:37:31.380 --> 01:37:32.460]   Ring.com/twit.
[01:37:32.460 --> 01:37:38.060]   Don't try to put the box back together because let's you open it.
[01:37:38.060 --> 01:37:39.060]   It seems no.
[01:37:39.060 --> 01:37:42.500]   I'm sure I'll be able to do that.
[01:37:42.500 --> 01:37:43.940]   Thank you for reminding me about movies anywhere.
[01:37:43.940 --> 01:37:45.140]   I've completely forgot.
[01:37:45.140 --> 01:37:46.140]   I love that.
[01:37:46.140 --> 01:37:47.780]   That's a great service.
[01:37:47.780 --> 01:37:48.860]   And Plaxo.
[01:37:48.860 --> 01:37:51.220]   Talk about CDDB and Plaxo.
[01:37:51.220 --> 01:37:52.460]   Do you know who started Plaxo?
[01:37:52.460 --> 01:37:54.260]   Sean Parker.
[01:37:54.260 --> 01:37:56.620]   I just read that in a book actually.
[01:37:56.620 --> 01:37:57.620]   I did not know that.
[01:37:57.620 --> 01:37:58.780]   Yeah.
[01:37:58.780 --> 01:37:59.780]   That was the one.
[01:37:59.780 --> 01:38:03.540]   And the reason people hate Plaxo because it sent emails out to everybody you know over
[01:38:03.540 --> 01:38:06.100]   and over again saying join Plaxo.
[01:38:06.100 --> 01:38:07.100]   Then I'll--
[01:38:07.100 --> 01:38:08.100]   So did LinkedIn.
[01:38:08.100 --> 01:38:10.260]   Yeah, remember that?
[01:38:10.260 --> 01:38:15.300]   Plaxo eventually got sold to Comcast and--
[01:38:15.300 --> 01:38:18.980]   It became Comcast's default address book.
[01:38:18.980 --> 01:38:19.980]   Probably.
[01:38:19.980 --> 01:38:20.980]   It did.
[01:38:20.980 --> 01:38:21.980]   Oh, wow.
[01:38:21.980 --> 01:38:22.980]   Shut down into the year last year.
[01:38:22.980 --> 01:38:23.980]   Oh, did it really?
[01:38:23.980 --> 01:38:24.980]   Yeah.
[01:38:24.980 --> 01:38:27.300]   Until December last year.
[01:38:27.300 --> 01:38:28.300]   Plaxo.
[01:38:28.300 --> 01:38:30.300]   The last three people finally got cut off.
[01:38:30.300 --> 01:38:31.300]   Yeah.
[01:38:31.300 --> 01:38:34.580]   But you know, truthfully I use Facebook for that because I used to when I was-- I don't--
[01:38:34.580 --> 01:38:36.220]   my Facebook has Kastiactivated.
[01:38:36.220 --> 01:38:39.540]   But I used to connect my calendar or address book to Facebook.
[01:38:39.540 --> 01:38:41.980]   The only negative was to get all these birthdays in there.
[01:38:41.980 --> 01:38:42.980]   Yeah.
[01:38:42.980 --> 01:38:45.780]   Oh, my computer every day, I've got like four or five birthdays.
[01:38:45.780 --> 01:38:47.140]   I don't even know who these people are.
[01:38:47.140 --> 01:38:48.140]   And it's duplicates.
[01:38:48.140 --> 01:38:51.740]   It's like triple kits because it's like my Facebook, it's Google.
[01:38:51.740 --> 01:38:52.740]   It's all these things.
[01:38:52.740 --> 01:38:55.940]   I feel bad that I'm not wishing 20 people a happy birthday every day.
[01:38:55.940 --> 01:38:56.940]   No.
[01:38:56.940 --> 01:38:58.500]   It makes you feel guilty.
[01:38:58.500 --> 01:39:00.780]   So Google has announced that they are finally killing--
[01:39:00.780 --> 01:39:02.660]   That's the real reason I quit Facebook.
[01:39:02.660 --> 01:39:04.260]   So I wouldn't have to wish anybody a happy birthday.
[01:39:04.260 --> 01:39:05.260]   It's a very good reason.
[01:39:05.260 --> 01:39:09.860]   In fact, I had activated Facebook to buy those portals, which I'm still trying to return
[01:39:09.860 --> 01:39:11.580]   and Facebook doesn't seem to want me to return them.
[01:39:11.580 --> 01:39:15.380]   I can't understand why.
[01:39:15.380 --> 01:39:16.380]   And I had it.
[01:39:16.380 --> 01:39:17.380]   So I had to activate it to buy them.
[01:39:17.380 --> 01:39:19.740]   And then I realized my birthday was coming up and I went, "Oh, God."
[01:39:19.740 --> 01:39:25.420]   I quickly deactivated it before anybody could wish me a happy birthday.
[01:39:25.420 --> 01:39:26.420]   It's a burden.
[01:39:26.420 --> 01:39:27.420]   Yeah.
[01:39:27.420 --> 01:39:30.100]   Because you feel like you have to say something to everyone back.
[01:39:30.100 --> 01:39:31.100]   And I don't--
[01:39:31.100 --> 01:39:32.100]   And when you get to a certain--
[01:39:32.100 --> 01:39:38.180]   And you're wishing people happy birthday is kind of a headache because you don't want
[01:39:38.180 --> 01:39:40.100]   to say the same thing to everyone.
[01:39:40.100 --> 01:39:41.100]   Right.
[01:39:41.100 --> 01:39:42.100]   Because I come up with some creative--
[01:39:42.100 --> 01:39:43.100]   Right.
[01:39:43.100 --> 01:39:44.380]   --happy birthday.
[01:39:44.380 --> 01:39:46.820]   I hope everything is going great.
[01:39:46.820 --> 01:39:48.820]   Another year around the sun.
[01:39:48.820 --> 01:39:52.860]   You don't look a day over 40.
[01:39:52.860 --> 01:39:55.700]   I don't know if you noticed, but there was a point when Facebook would actually, at the
[01:39:55.700 --> 01:40:00.380]   top of your news feed, literally with one tap, you could wish people a happy birthday.
[01:40:00.380 --> 01:40:04.700]   They would populate the status message, the comment on their page.
[01:40:04.700 --> 01:40:09.380]   It would be like 76 of your friends wished your friend Adam a happy birthday.
[01:40:09.380 --> 01:40:10.380]   Would you like to as well?
[01:40:10.380 --> 01:40:12.020]   It would be like three little things.
[01:40:12.020 --> 01:40:14.180]   You could just one tap and wish him a happy birthday.
[01:40:14.180 --> 01:40:15.180]   What happened to that?
[01:40:15.180 --> 01:40:16.180]   I mean, I don't know.
[01:40:16.180 --> 01:40:18.140]   I mean, maybe it's still-- I'm not really on Facebook.
[01:40:18.140 --> 01:40:19.140]   I don't really know.
[01:40:19.140 --> 01:40:20.820]   I mean, maybe they still do that.
[01:40:20.820 --> 01:40:22.380]   We've got three people not on Facebook.
[01:40:22.380 --> 01:40:24.180]   Patrick, do you use Facebook?
[01:40:24.180 --> 01:40:25.660]   Well, I mean, I asked--
[01:40:25.660 --> 01:40:28.860]   I was going to say he's working on it.
[01:40:28.860 --> 01:40:38.700]   No, I am on Facebook, but mostly to manage my page, which in the past year or so has
[01:40:38.700 --> 01:40:40.460]   become entirely useless.
[01:40:40.460 --> 01:40:41.540]   I post stuff on there.
[01:40:41.540 --> 01:40:42.540]   I'm not sure.
[01:40:42.540 --> 01:40:44.940]   It's kind of like-- it's almost like Google+, a year ago.
[01:40:44.940 --> 01:40:45.940]   Yeah.
[01:40:45.940 --> 01:40:46.940]   You posted it to--
[01:40:46.940 --> 01:40:48.580]   It's gone way down.
[01:40:48.580 --> 01:40:49.580]   Yeah.
[01:40:49.580 --> 01:40:50.940]   I have a Facebook page.
[01:40:50.940 --> 01:40:54.060]   And they literally just-- they cut you off of the knees.
[01:40:54.060 --> 01:40:57.420]   And it's just-- it's crazy.
[01:40:57.420 --> 01:40:59.340]   It just makes you not want to post there anymore.
[01:40:59.340 --> 01:41:03.300]   Meanwhile, Instagram, they're artificially boosting everything.
[01:41:03.300 --> 01:41:04.980]   So you're getting a lot of engagement there.
[01:41:04.980 --> 01:41:07.020]   I mean, that's what you're talking about, right?
[01:41:07.020 --> 01:41:08.020]   Patrick?
[01:41:08.020 --> 01:41:09.540]   Yes, Instagram.
[01:41:09.540 --> 01:41:14.180]   And now they even tell you when you post something on your page in the past couple
[01:41:14.180 --> 01:41:20.020]   of days, they started suggesting Instagram pictures to add to your Facebook post, for
[01:41:20.020 --> 01:41:21.980]   some reason.
[01:41:21.980 --> 01:41:23.620]   It's very, very strange.
[01:41:23.620 --> 01:41:29.620]   When I was still on there, we had a page for our podcast, our Wheel Bering Podcast.
[01:41:29.620 --> 01:41:34.740]   And the engagement on there was very low compared to Twitter and other stuff.
[01:41:34.740 --> 01:41:38.700]   And even when I did get a notification of a message, if I wanted to go back and try
[01:41:38.700 --> 01:41:43.420]   and find it, it was nearly impossible to try and find old messages.
[01:41:43.420 --> 01:41:45.020]   The way it was designed was terrible.
[01:41:45.020 --> 01:41:47.300]   So we really didn't lose anything with that.
[01:41:47.300 --> 01:41:48.300]   Yeah.
[01:41:48.300 --> 01:41:53.660]   It's-- and the thing they do, they still encourage you to boost the posts.
[01:41:53.660 --> 01:41:55.860]   Oh, yeah, because they have to spend money.
[01:41:55.860 --> 01:41:57.700]   Like, yes, of course.
[01:41:57.700 --> 01:42:01.740]   But they do it in a very-- well, I don't know if I would call it clever.
[01:42:01.740 --> 01:42:06.180]   But if your post is performing well, they tell you, oh, your post is performing better
[01:42:06.180 --> 01:42:10.220]   than 85% of your posts boost it to get more people.
[01:42:10.220 --> 01:42:17.580]   If it's not, they tell you, hey, other people have boosted posts similar to yours.
[01:42:17.580 --> 01:42:23.540]   And they have reached 13,000 people for a couple of bucks.
[01:42:23.540 --> 01:42:24.540]   Don't you want to do that?
[01:42:24.540 --> 01:42:30.980]   And then when people interact with your post who aren't already fans of your page, they
[01:42:30.980 --> 01:42:37.340]   tell you this many people have interacted with your post and aren't fans of your page.
[01:42:37.340 --> 01:42:41.220]   Make sure they see your next post by inviting them to your page.
[01:42:41.220 --> 01:42:43.580]   And they provide you with the little button.
[01:42:43.580 --> 01:42:46.740]   Like it's-- I don't know what they're doing with pages, but it's--
[01:42:46.740 --> 01:42:50.220]   So I don't think it's working out.
[01:42:50.220 --> 01:42:54.540]   We had Chris Markwad, our photo guy on the radio show today.
[01:42:54.540 --> 01:42:57.660]   And he was in vaying against Instagram.
[01:42:57.660 --> 01:43:02.780]   He said that Instagram has ruined the most beautiful places in the world with location
[01:43:02.780 --> 01:43:03.780]   hashtags.
[01:43:03.780 --> 01:43:06.540]   He's on a campaign to stop.
[01:43:06.540 --> 01:43:09.740]   And in fact, apparently, there are actually locations that are doing this.
[01:43:09.740 --> 01:43:15.060]   In Jackson Hole, Wyoming, they have signs everywhere that say, don't tag this picture.
[01:43:15.060 --> 01:43:17.460]   Don't tell anybody where you got this picture.
[01:43:17.460 --> 01:43:21.980]   It's the exact opposite of what had been going on, where you know, hashtag us.
[01:43:21.980 --> 01:43:26.980]   Because so many-- what's happening is-- and he pointed out this website or other Instagram
[01:43:26.980 --> 01:43:31.140]   feed called Boy Friends of Instagram-- is that you have all of these-- they're mostly
[01:43:31.140 --> 01:43:37.220]   attractive young women, Instagram influencers who are going around to all these places
[01:43:37.220 --> 01:43:42.220]   and taking pictures-- of course, it's the boyfriends taking the picture and ruining
[01:43:42.220 --> 01:43:46.580]   these places for everyone else by hashtagging it.
[01:43:46.580 --> 01:43:51.100]   And then they get overrun with more Instagram influencers.
[01:43:51.100 --> 01:43:55.860]   It seems like the main influence is-- by the way, I love this in the feed.
[01:43:55.860 --> 01:43:59.140]   And it was an Instagram influencer Halloween costume set.
[01:43:59.140 --> 01:44:00.140]   Oh, yeah.
[01:44:00.140 --> 01:44:01.140]   That was a classic.
[01:44:01.140 --> 01:44:02.140]   That was awesome.
[01:44:02.140 --> 01:44:03.740]   That looks like it.
[01:44:03.740 --> 01:44:04.740]   Yeah.
[01:44:04.740 --> 01:44:11.700]   Sport bra, hoodie, sunglasses, a blonde wig with a black baseball cap, leggings.
[01:44:11.700 --> 01:44:12.700]   Yeah.
[01:44:12.700 --> 01:44:13.900]   I would have looked good at that.
[01:44:13.900 --> 01:44:16.060]   I will admit, though, I was guilty of this.
[01:44:16.060 --> 01:44:21.380]   I saw in my feed, one of these influencers who on the way to Vegas or the way back stopped
[01:44:21.380 --> 01:44:23.420]   at this place called like seven magic moments.
[01:44:23.420 --> 01:44:24.900]   And you went there.
[01:44:24.900 --> 01:44:25.900]   And of course, what did I do?
[01:44:25.900 --> 01:44:28.140]   I stopped on the way back just to take a picture.
[01:44:28.140 --> 01:44:30.140]   I was like, well, I could do a picture like hers.
[01:44:30.140 --> 01:44:31.820]   It could look just as cool.
[01:44:31.820 --> 01:44:33.060]   And it was cool.
[01:44:33.060 --> 01:44:36.580]   But the reality is, the only reason I would have ever stopped there is because I saw it
[01:44:36.580 --> 01:44:37.660]   on my Instagram feed.
[01:44:37.660 --> 01:44:43.580]   So I guess it's a good thing for that art installation, but it's a bad thing for your
[01:44:43.580 --> 01:44:44.580]   right.
[01:44:44.580 --> 01:44:46.740]   These people are just-- they see someone's amazing picture in a place.
[01:44:46.740 --> 01:44:48.220]   And they're like, I want to go do that.
[01:44:48.220 --> 01:44:50.300]   I want to have that same exact picture.
[01:44:50.300 --> 01:44:52.060]   That's what happens when I see Leo traveling the world.
[01:44:52.060 --> 01:44:53.980]   I'm like, I think a picture where Leo was.
[01:44:53.980 --> 01:44:55.500]   Well, I got off Instagram, too.
[01:44:55.500 --> 01:44:56.900]   So you're just going to have to-- I don't know.
[01:44:56.900 --> 01:45:04.940]   What do my blog is said when you see that social media has-- I mean, really, the real
[01:45:04.940 --> 01:45:06.620]   problem is the world is overpopulated.
[01:45:06.620 --> 01:45:07.700]   They're just too many people.
[01:45:07.700 --> 01:45:10.340]   But social media has now exacerbated the problem.
[01:45:10.340 --> 01:45:12.780]   Were you going to say something about it?
[01:45:12.780 --> 01:45:14.180]   Everyone's in the same problem.
[01:45:14.180 --> 01:45:15.180]   I'm not saying that one.
[01:45:15.180 --> 01:45:17.620]   It's the problem.
[01:45:17.620 --> 01:45:19.380]   Are you guys using TikTok?
[01:45:19.380 --> 01:45:21.380]   No, that's the hot new thing, right?
[01:45:21.380 --> 01:45:22.380]   Wasn't this musically?
[01:45:22.380 --> 01:45:23.380]   And it got purchased.
[01:45:23.380 --> 01:45:24.380]   Exactly.
[01:45:24.380 --> 01:45:26.620]   So are you a Tiktoker?
[01:45:26.620 --> 01:45:28.500]   Well, I'm a lurker for now.
[01:45:28.500 --> 01:45:30.580]   We'll see if I actually start posting.
[01:45:30.580 --> 01:45:31.860]   I probably don't think so.
[01:45:31.860 --> 01:45:40.340]   But it was the strangest experience to start lurking on TikTok because it's the first
[01:45:40.340 --> 01:45:46.340]   time I have ever felt out of touch with what the young people are doing.
[01:45:46.340 --> 01:45:47.340]   You're all doing.
[01:45:47.340 --> 01:45:48.340]   Yes.
[01:45:48.340 --> 01:45:49.340]   It happens to all of us, Patrick.
[01:45:49.340 --> 01:45:50.740]   It happened to me about 30 years ago.
[01:45:50.740 --> 01:45:53.100]   But it happens to all of us eventually.
[01:45:53.100 --> 01:45:56.820]   But I think, for Snapchat, there was a little bit of it.
[01:45:56.820 --> 01:46:00.180]   But TikTok is kind of its own universe.
[01:46:00.180 --> 01:46:08.340]   And every post, every single post, is kind of a take on a meme that is already making
[01:46:08.340 --> 01:46:10.780]   fun of another meme.
[01:46:10.780 --> 01:46:13.260]   And it has the whole music part to it.
[01:46:13.260 --> 01:46:14.260]   It's very entertaining.
[01:46:14.260 --> 01:46:16.820]   I started enjoying it quite a bit.
[01:46:16.820 --> 01:46:18.740]   But it's kind of an interesting experience.
[01:46:18.740 --> 01:46:21.140]   I would encourage people to check it out.
[01:46:21.140 --> 01:46:28.580]   So originally, musically, you have to download the app and set up an account.
[01:46:28.580 --> 01:46:34.500]   But to have using an app, if you're using an app, you're not making every second of
[01:46:34.500 --> 01:46:35.500]   your life count.
[01:46:35.500 --> 01:46:36.500]   Oh, that's profound.
[01:46:36.500 --> 01:46:38.500]   Let me think about that.
[01:46:38.500 --> 01:46:40.700]   If you're using it, why is that?
[01:46:40.700 --> 01:46:41.940]   Because you should just be living life.
[01:46:41.940 --> 01:46:42.940]   Oh.
[01:46:42.940 --> 01:46:43.940]   Not messing around with some of your stuff.
[01:46:43.940 --> 01:46:50.860]   If you're seeing life through an Instagram filter, not everything looks like that.
[01:46:50.860 --> 01:46:56.220]   This is the TikTok Real Short Award.
[01:46:56.220 --> 01:47:02.140]   So musically, which really started this and ended up merging with them, was lip syncing.
[01:47:02.140 --> 01:47:03.820]   TikTok's not lip syncing, Patrick.
[01:47:03.820 --> 01:47:04.820]   Give us all of it.
[01:47:04.820 --> 01:47:05.820]   There's some of it.
[01:47:05.820 --> 01:47:07.740]   It's a tour of what this is.
[01:47:07.740 --> 01:47:09.180]   There's some lip syncing.
[01:47:09.180 --> 01:47:11.340]   There's a lot of choreography.
[01:47:11.340 --> 01:47:15.100]   And there's a real vine.
[01:47:15.100 --> 01:47:16.100]   It feels like vine.
[01:47:16.100 --> 01:47:17.100]   Real to it.
[01:47:17.100 --> 01:47:18.100]   Yeah.
[01:47:18.100 --> 01:47:19.100]   A little bit.
[01:47:19.100 --> 01:47:20.100]   But it's more creative.
[01:47:20.100 --> 01:47:22.980]   And there is some genuinely interest.
[01:47:22.980 --> 01:47:27.140]   Well, some genuinely interesting stuff in there.
[01:47:27.140 --> 01:47:35.620]   It's probably the most entertaining social network-ish app I've used in the past few
[01:47:35.620 --> 01:47:36.620]   years.
[01:47:36.620 --> 01:47:37.620]   It's entertaining.
[01:47:37.620 --> 01:47:40.100]   I don't know that it's good, but it's entertaining.
[01:47:40.100 --> 01:47:41.100]   Here is, I'll play this.
[01:47:41.100 --> 01:47:42.500]   I don't know what it's going to be like.
[01:47:42.500 --> 01:47:49.020]   This is Anne Lupo's entry for the LA Film Festival and the TikTok Real Short Award.
[01:47:49.020 --> 01:47:50.020]   Why I am a filmmaker.
[01:47:50.020 --> 01:47:51.020]   People.
[01:47:51.020 --> 01:47:53.580]   I just make people laugh.
[01:47:53.580 --> 01:47:56.980]   She's got laser eyes, duericks, skull masks.
[01:47:56.980 --> 01:47:59.980]   I have a film case of multiple personality.
[01:47:59.980 --> 01:48:02.340]   Why did she become a filmmaker?
[01:48:02.340 --> 01:48:03.340]   I have a lot of questions.
[01:48:03.340 --> 01:48:04.340]   Can I go do a scot?
[01:48:04.340 --> 01:48:06.740]   Okay, that doesn't seem like the best one.
[01:48:06.740 --> 01:48:07.740]   It's not?
[01:48:07.740 --> 01:48:08.740]   That's one of the worst.
[01:48:08.740 --> 01:48:09.940]   I'm actually going to download now.
[01:48:09.940 --> 01:48:11.580]   I'm not.
[01:48:11.580 --> 01:48:14.100]   It's making me queasy.
[01:48:14.100 --> 01:48:15.100]   It's weird.
[01:48:15.100 --> 01:48:16.100]   It's weird.
[01:48:16.100 --> 01:48:17.660]   That's not worth the risk.
[01:48:17.660 --> 01:48:18.660]   This is not.
[01:48:18.660 --> 01:48:20.020]   That's because you're old.
[01:48:20.020 --> 01:48:21.820]   I am old, apparently.
[01:48:21.820 --> 01:48:23.260]   All right.
[01:48:23.260 --> 01:48:24.180]   Okay.
[01:48:24.180 --> 01:48:28.940]   There was a point in my life when I used to love to download these.
[01:48:28.940 --> 01:48:31.300]   Anything that was new, new social network, new this.
[01:48:31.300 --> 01:48:32.300]   Me too.
[01:48:32.300 --> 01:48:35.060]   And now it's like, it takes like a year for it.
[01:48:35.060 --> 01:48:39.340]   Even you guys talking about it, I'm still like, nope, not going to sign up for this one.
[01:48:39.340 --> 01:48:40.340]   Isn't that?
[01:48:40.340 --> 01:48:41.340]   That's a sign of maturity.
[01:48:41.340 --> 01:48:42.340]   I did the same.
[01:48:42.340 --> 01:48:46.180]   I would get my name on everything possible just so that I plant my flag.
[01:48:46.180 --> 01:48:47.180]   Reserve your name.
[01:48:47.180 --> 01:48:48.180]   Yep.
[01:48:48.180 --> 01:48:49.180]   Peach.
[01:48:49.180 --> 01:48:50.180]   Peach?
[01:48:50.180 --> 01:48:51.180]   Sure.
[01:48:51.180 --> 01:48:52.180]   Oh, what was that one?
[01:48:52.180 --> 01:48:53.180]   Hello.
[01:48:53.180 --> 01:48:54.180]   What was the social network that was?
[01:48:54.180 --> 01:48:55.180]   Still on hello.
[01:48:55.180 --> 01:48:56.180]   Yeah.
[01:48:56.180 --> 01:48:58.180]   I think I got like rich D. Rich D.
[01:48:58.180 --> 01:49:00.020]   Yeah, for a while, I thought maybe I should get it early.
[01:49:00.020 --> 01:49:01.020]   I get Leo.
[01:49:01.020 --> 01:49:02.020]   Right.
[01:49:02.020 --> 01:49:03.020]   No, you got to be consistent.
[01:49:03.020 --> 01:49:05.620]   It should always be Leo LaPorte everywhere.
[01:49:05.620 --> 01:49:07.780]   I am so glad I don't do this anymore.
[01:49:07.780 --> 01:49:10.780]   I do have an addiction to Pokemon Go, but that's another story entirely.
[01:49:10.780 --> 01:49:12.700]   I can verify that.
[01:49:12.700 --> 01:49:14.420]   I've been playing the game during my life.
[01:49:14.420 --> 01:49:17.060]   Occasionally something will show up, but I want to miss it.
[01:49:17.060 --> 01:49:19.060]   There's good stuff out there.
[01:49:19.060 --> 01:49:22.180]   There's nothing right now.
[01:49:22.180 --> 01:49:23.180]   So Google Messages.
[01:49:23.180 --> 01:49:25.180]   Oh my God.
[01:49:25.180 --> 01:49:28.380]   What a tangled web we weave when we're street.
[01:49:28.380 --> 01:49:30.940]   Practice to create messaging apps.
[01:49:30.940 --> 01:49:34.860]   Allows going away, finally.
[01:49:34.860 --> 01:49:42.180]   Earlier this year, according to the keyword blog, we paused investment in aloe.
[01:49:42.180 --> 01:49:46.740]   And now we're just going to turn it off through March 2019, and then you'll be able
[01:49:46.740 --> 01:49:48.940]   to export all your conversations.
[01:49:48.940 --> 01:49:51.780]   But they've still got duo.
[01:49:51.780 --> 01:49:56.820]   And even though rumors of the contrary, they are not killing Hangouts, although eventually
[01:49:56.820 --> 01:50:03.060]   they're going to move us to Hangouts meet primarily focused on team collaboration for
[01:50:03.060 --> 01:50:05.220]   G Suite customers.
[01:50:05.220 --> 01:50:09.060]   I just use it for Google Fi messaging.
[01:50:09.060 --> 01:50:15.140]   They've got Verizon doing RCS with Android messages, now just messages because it's not
[01:50:15.140 --> 01:50:17.300]   confusing enough.
[01:50:17.300 --> 01:50:21.140]   40 carriers, 175 million people using messages.
[01:50:21.140 --> 01:50:23.300]   Oh, yeah.
[01:50:23.300 --> 01:50:25.780]   That's just the app.
[01:50:25.780 --> 01:50:29.100]   Not RCS, I know, has just turned on on the Pixel 3.
[01:50:29.100 --> 01:50:30.100]   I'm sorry.
[01:50:30.100 --> 01:50:32.340]   You can get through your stuff because I have a lot of thoughts on this.
[01:50:32.340 --> 01:50:33.940]   I'm angry about this.
[01:50:33.940 --> 01:50:36.900]   I'm just angry because here's the thing.
[01:50:36.900 --> 01:50:42.580]   I mean, Leo, like you, obviously I jump back and forth between Android and iOS because
[01:50:42.580 --> 01:50:44.420]   I like to keep up on both of them.
[01:50:44.420 --> 01:50:45.420]   I love Android.
[01:50:45.420 --> 01:50:47.420]   I love what you can do on Android.
[01:50:47.420 --> 01:50:52.220]   The thing that literally kills me about Android, have you ever tried to send a video file or
[01:50:52.220 --> 01:50:53.980]   a picture text to someone?
[01:50:53.980 --> 01:50:55.420]   Like, I mean, it's a joke.
[01:50:55.420 --> 01:50:57.860]   A picture is fine because it's small, but whatever.
[01:50:57.860 --> 01:51:02.060]   But a video to someone or, you know, the fact is when you're gone, Android, it never
[01:51:02.060 --> 01:51:03.140]   goes through.
[01:51:03.140 --> 01:51:04.140]   It's ridiculous.
[01:51:04.140 --> 01:51:09.380]   You feel like you've taken 10 years, 10 steps back in years when you are messaging on an
[01:51:09.380 --> 01:51:10.460]   Android device.
[01:51:10.460 --> 01:51:13.900]   And for a while, I was trying to force everyone to use Facebook Messenger.
[01:51:13.900 --> 01:51:16.140]   No, I can't do that.
[01:51:16.140 --> 01:51:17.140]   I wish we could.
[01:51:17.140 --> 01:51:20.100]   I wish we could say to somebody, just anything, what's app?
[01:51:20.100 --> 01:51:21.460]   I like Telegram for a while.
[01:51:21.460 --> 01:51:23.460]   I really thought that was great.
[01:51:23.460 --> 01:51:25.060]   Let's all just pick one thing.
[01:51:25.060 --> 01:51:26.460]   Let's all just do this.
[01:51:26.460 --> 01:51:27.460]   But everyone uses it.
[01:51:27.460 --> 01:51:28.460]   They've already picked.
[01:51:28.460 --> 01:51:29.460]   It's called iMessage.
[01:51:29.460 --> 01:51:30.460]   But it's not on Android.
[01:51:30.460 --> 01:51:32.300]   I don't use it on the message.
[01:51:32.300 --> 01:51:36.860]   But Apple could own messaging tomorrow if they launched an iMessage for Android.
[01:51:36.860 --> 01:51:37.860]   I agree.
[01:51:37.860 --> 01:51:40.260]   Literally, tomorrow they'd own messaging for all the eternity.
[01:51:40.260 --> 01:51:42.140]   One less incentive to buy an iPhone.
[01:51:42.140 --> 01:51:43.300]   There's that silo thing.
[01:51:43.300 --> 01:51:44.300]   Right?
[01:51:44.300 --> 01:51:45.300]   I get it.
[01:51:45.300 --> 01:51:46.300]   And I understand that.
[01:51:46.300 --> 01:51:50.540]   But the thing about RCS is like, if that does happen in a meaningful way where these carriers
[01:51:50.540 --> 01:51:55.700]   finally turn it on, I mean, I believe that's a huge deal for Android because messaging on
[01:51:55.700 --> 01:51:57.220]   Android is just so bad.
[01:51:57.220 --> 01:51:58.220]   But it's the other flip side is...
[01:51:58.220 --> 01:52:00.700]   It's still fundamentally flawed though because there's no encryption.
[01:52:00.700 --> 01:52:01.700]   Well, okay.
[01:52:01.700 --> 01:52:02.700]   And that's all.
[01:52:02.700 --> 01:52:03.700]   One of the things that people say they like about it.
[01:52:03.700 --> 01:52:05.700]   Most people don't care about encryption.
[01:52:05.700 --> 01:52:06.700]   Most people don't.
[01:52:06.700 --> 01:52:07.700]   Most people care.
[01:52:07.700 --> 01:52:08.700]   They say.
[01:52:08.700 --> 01:52:09.700]   Yeah, they say they care.
[01:52:09.700 --> 01:52:11.780]   Well, I mean, that's real encryption.
[01:52:11.780 --> 01:52:13.780]   But who else uses it?
[01:52:13.780 --> 01:52:14.780]   I don't think my mom...
[01:52:14.780 --> 01:52:16.020]   You use it to talk to yourself and your wife.
[01:52:16.020 --> 01:52:17.020]   Yeah, two people.
[01:52:17.020 --> 01:52:20.940]   Can you imagine my mom sitting there and I'd be like, "Mom, I'm going to get you on Android
[01:52:20.940 --> 01:52:22.260]   and you're going to go to messages."
[01:52:22.260 --> 01:52:25.100]   And she'd be like, "Nope, I've heard it's not encrypted.
[01:52:25.100 --> 01:52:26.100]   I'm not doing it."
[01:52:26.100 --> 01:52:29.820]   I believe you like, "This doesn't look like privacy."
[01:52:29.820 --> 01:52:31.660]   This is what I like about my KTLA.
[01:52:31.660 --> 01:52:34.500]   I talk to the average person that is doing stuff.
[01:52:34.500 --> 01:52:39.380]   And I just, I hear from them and the questions and things and concerns that they have are
[01:52:39.380 --> 01:52:43.020]   very different than what you hear in sort of the tech world.
[01:52:43.020 --> 01:52:47.260]   And so anyway, the point is they just want to be able to send a picture, send a video,
[01:52:47.260 --> 01:52:51.060]   see when people are typing, see when things are delivered, see when they're read.
[01:52:51.060 --> 01:52:54.020]   And I feel like I'm not going to go on about...
[01:52:54.020 --> 01:52:58.340]   I don't believe what Apple did was right with the whole hijacking your phone number and
[01:52:58.340 --> 01:52:59.340]   kind of...
[01:52:59.340 --> 01:53:03.780]   They built a service on top of hijacking your phone number for iMessage, basically.
[01:53:03.780 --> 01:53:05.900]   And if Google ever did that, people would go crazy.
[01:53:05.900 --> 01:53:07.220]   So anyway, I'll leave it at that.
[01:53:07.220 --> 01:53:08.980]   No, I agree with you 100%.
[01:53:08.980 --> 01:53:10.540]   Here's what we all want.
[01:53:10.540 --> 01:53:15.300]   About something we can use on both Android and iOS that works equally well so you don't
[01:53:15.300 --> 01:53:18.980]   have green bubbles and blue bubbles, that silly messages thing.
[01:53:18.980 --> 01:53:20.780]   There needs to be desktop integration.
[01:53:20.780 --> 01:53:24.140]   I need a unified messaging app on every platform I use.
[01:53:24.140 --> 01:53:26.060]   You know what does that?
[01:53:26.060 --> 01:53:27.060]   Email.
[01:53:27.060 --> 01:53:29.260]   No, but you can't...
[01:53:29.260 --> 01:53:33.140]   If you're trying to meet someone out at a restaurant, you're not going to email them
[01:53:33.140 --> 01:53:34.140]   saying, "Hey, I'm standing..."
[01:53:34.140 --> 01:53:35.140]   It's so frustrating.
[01:53:35.140 --> 01:53:36.140]   It's a free table.
[01:53:36.140 --> 01:53:38.820]   A friend of mine, I have his number, he has my number.
[01:53:38.820 --> 01:53:41.100]   I text him, he never text me, it's only email.
[01:53:41.100 --> 01:53:42.940]   He uses email like test messaging.
[01:53:42.940 --> 01:53:45.180]   It's incredibly inconvenient for that exactly.
[01:53:45.180 --> 01:53:49.420]   He doesn't want to deal with the cross message incompatibility.
[01:53:49.420 --> 01:53:50.420]   Cross-platform.
[01:53:50.420 --> 01:53:51.420]   We start a campaign to get...
[01:53:51.420 --> 01:53:53.340]   I mean, I actually really like Telegram.
[01:53:53.340 --> 01:53:56.820]   All right, admittedly, it is not fully encrypted.
[01:53:56.820 --> 01:53:57.580]   It's somewhat encrypted.
[01:53:57.580 --> 01:54:01.180]   It's like sort of encrypted.
[01:54:01.180 --> 01:54:05.140]   It's got great features, it's got nice big stickers, it can do video audio, it's got
[01:54:05.140 --> 01:54:06.140]   group chats.
[01:54:06.140 --> 01:54:10.060]   Can we just get everybody to move to Telegram and just...
[01:54:10.060 --> 01:54:11.060]   You did really well.
[01:54:11.060 --> 01:54:13.060]   Why not do you do a lot of messaging?
[01:54:13.060 --> 01:54:14.060]   Signature.
[01:54:14.060 --> 01:54:17.260]   Yes, I put signal on everything, right?
[01:54:17.260 --> 01:54:20.660]   But nobody ever uses it, so it's like eventually it took it off.
[01:54:20.660 --> 01:54:24.460]   Why not follow Sam and go with signal if you're going to do that?
[01:54:24.460 --> 01:54:27.380]   What do you use in France?
[01:54:27.380 --> 01:54:28.740]   Most people use...
[01:54:28.740 --> 01:54:35.540]   Well, I guess the people who don't use message, I message or I guess messages use WhatsApp.
[01:54:35.540 --> 01:54:37.740]   WhatsApp is very popular in Europe.
[01:54:37.740 --> 01:54:38.740]   Yeah.
[01:54:38.740 --> 01:54:39.740]   Another Facebook.
[01:54:39.740 --> 01:54:41.940]   WhatsApp is the one that's owned by Facebook, right?
[01:54:41.940 --> 01:54:42.940]   Yeah.
[01:54:42.940 --> 01:54:43.940]   Yes.
[01:54:43.940 --> 01:54:44.940]   So there's WhatsApp and then what's the other?
[01:54:44.940 --> 01:54:45.940]   Oh, we chat.
[01:54:45.940 --> 01:54:46.940]   We chat.
[01:54:46.940 --> 01:54:48.340]   When you go to China, everyone uses we chat.
[01:54:48.340 --> 01:54:51.620]   Yes, see, they've solved in Japan, it's lying.
[01:54:51.620 --> 01:54:54.660]   And Viber is popular in some parts of the...
[01:54:54.660 --> 01:54:57.180]   I think he's in Europe.
[01:54:57.180 --> 01:54:58.180]   Why in America?
[01:54:58.180 --> 01:54:59.460]   It's literally just a message.
[01:54:59.460 --> 01:55:01.460]   That's what people think of when they message.
[01:55:01.460 --> 01:55:02.460]   It's just...
[01:55:02.460 --> 01:55:04.260]   It's kind of like become the de facto standard.
[01:55:04.260 --> 01:55:05.860]   Half the people think of it.
[01:55:05.860 --> 01:55:06.860]   Half.
[01:55:06.860 --> 01:55:08.780]   The other half are going, "Why am I a green bubble?
[01:55:08.780 --> 01:55:09.780]   What's the issue?"
[01:55:09.780 --> 01:55:10.780]   Yeah.
[01:55:10.780 --> 01:55:13.100]   So let me ask you a question.
[01:55:13.100 --> 01:55:14.100]   Why...
[01:55:14.100 --> 01:55:15.100]   You're right.
[01:55:15.100 --> 01:55:18.020]   If Apple were to make a message for Android, it'd be over.
[01:55:18.020 --> 01:55:20.660]   Oh, well, they probably should make a Windows version too.
[01:55:20.660 --> 01:55:22.660]   But then it'd be over, right?
[01:55:22.660 --> 01:55:23.820]   They would just own it.
[01:55:23.820 --> 01:55:26.500]   Why don't they do that?
[01:55:26.500 --> 01:55:28.700]   Just to sell iPhones, that's dumb.
[01:55:28.700 --> 01:55:30.900]   To keep you in their system.
[01:55:30.900 --> 01:55:31.900]   It is...
[01:55:31.900 --> 01:55:32.900]   I'm convinced.
[01:55:32.900 --> 01:55:36.700]   Technically, it may be something that their servers can't handle it.
[01:55:36.700 --> 01:55:37.700]   They'd have to expand.
[01:55:37.700 --> 01:55:38.700]   I don't know.
[01:55:38.700 --> 01:55:40.700]   But I think the reality is, when you talk to people...
[01:55:40.700 --> 01:55:41.700]   I'm sure I don't remember.
[01:55:41.700 --> 01:55:45.500]   I'm less than happy to give them to sell them some extra capacity for that.
[01:55:45.500 --> 01:55:46.500]   I'm sure.
[01:55:46.500 --> 01:55:47.500]   And it's just...
[01:55:47.500 --> 01:55:48.500]   Yeah, it's just to turn the dial up.
[01:55:48.500 --> 01:55:49.500]   I wonder if it's not...
[01:55:49.500 --> 01:55:50.500]   I wonder if it's not...
[01:55:50.500 --> 01:55:51.500]   I message in FaceTime.
[01:55:51.500 --> 01:55:56.380]   I mean, it's two things that just keep you glued and to the iPhone.
[01:55:56.380 --> 01:55:57.380]   Cut.
[01:55:57.380 --> 01:55:59.380]   Go ahead, Patrick.
[01:55:59.380 --> 01:56:06.660]   I think a message might not be quite enough to keep people as a feature.
[01:56:06.660 --> 01:56:07.660]   Or maybe it is.
[01:56:07.660 --> 01:56:09.300]   It's definitely very useful.
[01:56:09.300 --> 01:56:14.100]   But I'm wondering how much of it is keeping people not for the functionality, but just
[01:56:14.100 --> 01:56:15.100]   for the status.
[01:56:15.100 --> 01:56:18.340]   Like literally, you were joking about the green and blue bubbles.
[01:56:18.340 --> 01:56:22.620]   When you have a blue bubble, you're part of the people who have a blue bubble.
[01:56:22.620 --> 01:56:23.620]   And that might help you.
[01:56:23.620 --> 01:56:25.020]   No, I don't think so.
[01:56:25.020 --> 01:56:26.020]   No.
[01:56:26.020 --> 01:56:27.020]   No.
[01:56:27.020 --> 01:56:28.020]   I don't care.
[01:56:28.020 --> 01:56:29.020]   If someone texts me on my phone.
[01:56:29.020 --> 01:56:30.020]   It does not...
[01:56:30.020 --> 01:56:31.740]   That's because you're so old.
[01:56:31.740 --> 01:56:37.060]   So my son in the frat, I said, "How many people have Android phones?"
[01:56:37.060 --> 01:56:38.900]   He says, "One guy."
[01:56:38.900 --> 01:56:42.580]   And he's really kind of ostracized because everything we do in the frat, we all have
[01:56:42.580 --> 01:56:45.060]   iPhones, is done on messages.
[01:56:45.060 --> 01:56:49.180]   And because he can't be part of our group, because he's on Android, he's a blue bubble,
[01:56:49.180 --> 01:56:52.060]   he's a green bubble, he doesn't get to go to the parties.
[01:56:52.060 --> 01:56:53.060]   He's left out.
[01:56:53.060 --> 01:56:54.060]   Okay.
[01:56:54.060 --> 01:56:55.060]   Terrible.
[01:56:55.060 --> 01:56:57.700]   But that's because his phone is not platform, you know what I mean?
[01:56:57.700 --> 01:56:59.700]   It's not interoperable with iMessage.
[01:56:59.700 --> 01:57:04.180]   It's not because, look, if his phone, when he was messaging them and all the group functions
[01:57:04.180 --> 01:57:07.660]   worked perfectly and when he was writing, it would show them that, they would have no
[01:57:07.660 --> 01:57:08.660]   problem with that.
[01:57:08.660 --> 01:57:11.460]   Oh yeah, it's not because he's an Android user, but...
[01:57:11.460 --> 01:57:13.380]   It's because it doesn't work.
[01:57:13.380 --> 01:57:14.380]   But it kind of adds to the...
[01:57:14.380 --> 01:57:17.820]   I'm a message to get the same message on every single device that I'm using.
[01:57:17.820 --> 01:57:20.580]   I've got it on my laptop, I get it on my Apple Watch.
[01:57:20.580 --> 01:57:22.220]   I mean, it's crazy how many times I see a message.
[01:57:22.220 --> 01:57:23.780]   And that's how it should be.
[01:57:23.780 --> 01:57:24.780]   And that's how it should be, though.
[01:57:24.780 --> 01:57:25.780]   I mean, that's the problem.
[01:57:25.780 --> 01:57:28.660]   And at Google, both Google and Apple are missing an opportunity.
[01:57:28.660 --> 01:57:31.100]   Now, contrast that to what Microsoft's doing with that.
[01:57:31.100 --> 01:57:32.420]   Actually, let's take a break.
[01:57:32.420 --> 01:57:36.300]   And then I want to talk about this because this is the big story of the week.
[01:57:36.300 --> 01:57:38.100]   And we really didn't talk about it.
[01:57:38.100 --> 01:57:40.900]   This is a complete page turner for Microsoft.
[01:57:40.900 --> 01:57:44.420]   This is a whole new Microsoft unlike anything we've ever seen before.
[01:57:44.420 --> 01:57:46.020]   But I'll get to that in a second.
[01:57:46.020 --> 01:57:49.020]   Our show today brought to you by ExpressVPN.
[01:57:49.020 --> 01:57:50.020]   You are looking for a VPN.
[01:57:50.020 --> 01:57:53.060]   I know you are because you want to protect your privacy online.
[01:57:53.060 --> 01:57:54.740]   You want to secure your data.
[01:57:54.740 --> 01:57:56.580]   You don't want to be tracked.
[01:57:56.580 --> 01:57:59.500]   You want to be able to surf from any country in the world.
[01:57:59.500 --> 01:58:03.500]   So if there's something wonderful in another country that has geographic restrictions,
[01:58:03.500 --> 01:58:06.700]   you want to be able to get it, you need ExpressVPN.
[01:58:06.700 --> 01:58:09.660]   It is literally the best VPN service out there.
[01:58:09.660 --> 01:58:13.420]   Rated number one by tech radar, a 30-day money-back guarantee.
[01:58:13.420 --> 01:58:17.260]   So if you disagree, while you can get your money back, you won't.
[01:58:17.260 --> 01:58:18.260]   You won't.
[01:58:18.260 --> 01:58:19.260]   You'll love ExpressVPN.
[01:58:19.260 --> 01:58:21.540]   Easy to use apps that run seamlessly in the background.
[01:58:21.540 --> 01:58:22.540]   Everywhere.
[01:58:22.540 --> 01:58:24.140]   Your computer, your phone, your tablet.
[01:58:24.140 --> 01:58:25.900]   And click, boom, you're protected.
[01:58:25.900 --> 01:58:30.500]   It secures and anonymizes your internet browsing by encrypting your data, hiding your public
[01:58:30.500 --> 01:58:32.340]   IP address.
[01:58:32.340 --> 01:58:35.780]   And this is why it's so important to choose the right VPN provider.
[01:58:35.780 --> 01:58:39.700]   Remember that now, instead of emerging on the internet from your device, you're emerging
[01:58:39.700 --> 01:58:42.300]   on the internet from an ExpressVPN server.
[01:58:42.300 --> 01:58:47.860]   So you want a VPN service that respects your privacy, doesn't try to make money off of
[01:58:47.860 --> 01:58:49.780]   you by selling your information.
[01:58:49.780 --> 01:58:51.420]   That's ExpressVPN.
[01:58:51.420 --> 01:58:52.940]   No logging.
[01:58:52.940 --> 01:58:58.100]   If you need the privacy policy, you'll see why I recommended less than $7 a month.
[01:58:58.100 --> 01:59:01.860]   If you don't want to be tracked, if you don't want to hand over your online history to your
[01:59:01.860 --> 01:59:08.380]   internet service provider, to data resellers or to some junk VPN provider, get ExpressVPN.
[01:59:08.380 --> 01:59:10.140]   It's fast.
[01:59:10.140 --> 01:59:11.140]   It's private.
[01:59:11.140 --> 01:59:14.020]   No compromises.
[01:59:14.020 --> 01:59:16.540]   And it's by the way, a great deal right now.
[01:59:16.540 --> 01:59:19.780]   You'll get an extra three months free when you buy a one year package.
[01:59:19.780 --> 01:59:22.900]   That's the best deal at expressvpn.com/twit.
[01:59:22.900 --> 01:59:23.900]   ExpressVPN.
[01:59:23.900 --> 01:59:27.100]   Your search is over.
[01:59:27.100 --> 01:59:29.300]   I know people are always asking me, what's the best one?
[01:59:29.300 --> 01:59:30.300]   What's the best one?
[01:59:30.300 --> 01:59:31.300]   It's simple.
[01:59:31.300 --> 01:59:32.300]   ExpressVPN.
[01:59:32.300 --> 01:59:34.500]   ExpressVPN.com/twit.
[01:59:34.500 --> 01:59:38.020]   Three extra months when you sign up for the year package.
[01:59:38.020 --> 01:59:42.660]   ExpressVPN.com/twit.
[01:59:42.660 --> 01:59:44.540]   This blew me away.
[01:59:44.540 --> 01:59:47.860]   We heard the rumors and then Microsoft yet said, yes, it's true.
[01:59:47.860 --> 01:59:55.500]   We are abandoning the edge engine, edge is the browser that comes with Windows 10 because
[01:59:55.500 --> 02:00:00.460]   not because it's not good, not because it's not fast, but because the world works better
[02:00:00.460 --> 02:00:05.820]   when everybody develops for a single platform, we're going to start using Chromium, which
[02:00:05.820 --> 02:00:11.060]   makes edge Chrome compatible, puts Chrome services on all Windows machines.
[02:00:11.060 --> 02:00:16.260]   Not only that, they're going to make a Chromium based Microsoft edge for Mac.
[02:00:16.260 --> 02:00:17.540]   They're going to make it for Windows.
[02:00:17.540 --> 02:00:18.900]   They're going to make it for Android.
[02:00:18.900 --> 02:00:22.380]   They're going to make it for iOS.
[02:00:22.380 --> 02:00:29.220]   This is a shock from a company that hated open source, said Linux was a cancer, wanted
[02:00:29.220 --> 02:00:32.820]   to do everything themselves.
[02:00:32.820 --> 02:00:34.940]   All of a sudden they're going to be using Chromium.
[02:00:34.940 --> 02:00:38.260]   Now I mixed feelings about that because what we don't want, I think it's not good for
[02:00:38.260 --> 02:00:40.860]   the world to have a single browser.
[02:00:40.860 --> 02:00:43.340]   But monocultures are always bad.
[02:00:43.340 --> 02:00:44.900]   They inevitably lead to problems.
[02:00:44.900 --> 02:00:48.340]   But there are also advantages because when you develop a website, you don't have to think
[02:00:48.340 --> 02:00:49.900]   about five different ways.
[02:00:49.900 --> 02:00:52.140]   All the plugins will work.
[02:00:52.140 --> 02:00:54.900]   One of the things they're going to do is contribute to the Chromium project.
[02:00:54.900 --> 02:00:58.020]   They're going to be a good open source contributor.
[02:00:58.020 --> 02:01:03.380]   They're adding ARM based compatibility so that the ARM Windows devices will be able to use
[02:01:03.380 --> 02:01:04.540]   Chrome and Chromium.
[02:01:04.540 --> 02:01:07.460]   You Chrome will get this benefit as well.
[02:01:07.460 --> 02:01:08.460]   There'll still be Safari.
[02:01:08.460 --> 02:01:10.260]   There'll still be Firefox.
[02:01:10.260 --> 02:01:13.460]   I think Microsoft should have gone with Gecko.
[02:01:13.460 --> 02:01:14.460]   That's the Firefox edge.
[02:01:14.460 --> 02:01:16.220]   Firefox engine.
[02:01:16.220 --> 02:01:27.500]   I think it's better for the internet if we have these two or three strong rendering engines,
[02:01:27.500 --> 02:01:33.020]   browser engines rather than just one that's dominant.
[02:01:33.020 --> 02:01:37.700]   Even if you have these multiple companies contributing to it, inevitably something is
[02:01:37.700 --> 02:01:41.700]   going to go wrong in that process.
[02:01:41.700 --> 02:01:48.020]   Everybody's going to find a vulnerability and it's going to cause utter havoc.
[02:01:48.020 --> 02:01:53.580]   Owen Williams, who's a web developer, wrote from other board this move, will fundamentally
[02:01:53.580 --> 02:01:56.220]   change the web.
[02:01:56.220 --> 02:01:59.300]   After more than 20 years of fighting for relevance on the web, Microsoft is planning
[02:01:59.300 --> 02:02:05.060]   to scrap the underlying architecture of its browser in favor of Chromium.
[02:02:05.060 --> 02:02:09.220]   Internet Explorer's legacy is finally dead.
[02:02:09.220 --> 02:02:10.660]   Finally dead.
[02:02:10.660 --> 02:02:14.540]   He also says there's a strategic reason for this because it makes web browsers first-class
[02:02:14.540 --> 02:02:19.860]   citizens and it helps Microsoft be completely cross-platform.
[02:02:19.860 --> 02:02:22.380]   Basically Chromium will be baked into Windows from now on.
[02:02:22.380 --> 02:02:30.380]   That means PWA, Progressive Web Apps will be fully supported on Windows.
[02:02:30.380 --> 02:02:31.380]   They own GitHub.
[02:02:31.380 --> 02:02:37.460]   Remember, GitHub owns Electron, created Electron, which is basically a Chrome browser platform
[02:02:37.460 --> 02:02:40.220]   for apps.
[02:02:40.220 --> 02:02:45.340]   I think this is a very interesting move and I'm really so different from the Microsoft
[02:02:45.340 --> 02:02:47.220]   of a few years ago.
[02:02:47.220 --> 02:02:51.140]   Well, it's a very different company.
[02:02:51.140 --> 02:02:56.980]   You were referencing the open-source's Cancer Command, which of course was made at a very
[02:02:56.980 --> 02:02:59.780]   different time for the company.
[02:02:59.780 --> 02:03:05.940]   I think we're shocked by this announcement because we, once again, we're all old and
[02:03:05.940 --> 02:03:10.060]   for us, Microsoft is not a vampire.
[02:03:10.060 --> 02:03:11.060]   Yeah.
[02:03:11.060 --> 02:03:12.060]   Yeah.
[02:03:12.060 --> 02:03:18.980]   But ever since Satya came along, he has completely transformed as we all discuss in our various
[02:03:18.980 --> 02:03:21.100]   shows very often.
[02:03:21.100 --> 02:03:23.580]   He's transformed the company.
[02:03:23.580 --> 02:03:31.700]   For the new Microsoft, I'm not sure this is such a surprising move.
[02:03:31.700 --> 02:03:39.940]   I'm not sure what benefit the new Microsoft, which is ubiquitous and wants to be the infrastructure
[02:03:39.940 --> 02:03:47.100]   of the Internet's infrastructure, what benefit Edge really gave them, owning their...
[02:03:47.100 --> 02:03:53.220]   Because it's not like they're abandoning their browser branding and model.
[02:03:53.220 --> 02:03:55.140]   It's just using the...
[02:03:55.140 --> 02:03:56.140]   Yeah.
[02:03:56.140 --> 02:03:57.140]   Yeah.
[02:03:57.140 --> 02:04:00.180]   The problem was nobody used Edge.
[02:04:00.180 --> 02:04:06.180]   Everybody used Chrome, like 80% and 11% used Internet Explorer, which is bizarre.
[02:04:06.180 --> 02:04:07.780]   And then Edge was down below that.
[02:04:07.780 --> 02:04:11.820]   So it's also throwing in the towel and saying, "All right.
[02:04:11.820 --> 02:04:12.820]   Yeah."
[02:04:12.820 --> 02:04:16.820]   If you're creating a browser that's third or fourth on the list, you're going to be less
[02:04:16.820 --> 02:04:22.260]   compatible with the global web because people are just not going to check for compatibility.
[02:04:22.260 --> 02:04:24.620]   And that is ultimately a problem.
[02:04:24.620 --> 02:04:26.700]   What's Firefox's market share now?
[02:04:26.700 --> 02:04:28.180]   I don't know.
[02:04:28.180 --> 02:04:30.740]   I don't think it's very high.
[02:04:30.740 --> 02:04:32.700]   Let's check browser market share.
[02:04:32.700 --> 02:04:35.580]   Of course, I'm going to search Google for this.
[02:04:35.580 --> 02:04:36.580]   Yeah, it's...
[02:04:36.580 --> 02:04:37.580]   I mean, it's tough.
[02:04:37.580 --> 02:04:44.420]   One issue is going to be that you can't watch the Apple keynotes on Windows anymore because
[02:04:44.420 --> 02:04:45.660]   it only worked on Edge.
[02:04:45.660 --> 02:04:46.660]   Actually, they fixed...
[02:04:46.660 --> 02:04:48.740]   I think that's being fixed now, but we'll see.
[02:04:48.740 --> 02:04:49.740]   Oh.
[02:04:49.740 --> 02:04:50.740]   Okay.
[02:04:50.740 --> 02:04:51.740]   I hope so.
[02:04:51.740 --> 02:04:52.740]   Do you want to talk?
[02:04:52.740 --> 02:04:53.740]   You can all watch it in iMessages.
[02:04:53.740 --> 02:04:54.740]   Yeah.
[02:04:54.740 --> 02:04:55.740]   Do you want to talk?
[02:04:55.740 --> 02:04:58.100]   And you definitely can't send that to your friends on an Android phone.
[02:04:58.100 --> 02:05:00.500]   You can't send that link.
[02:05:00.500 --> 02:05:06.940]   So here's the graph that's kind of telling.
[02:05:06.940 --> 02:05:10.820]   The blue line at the top, that's Chrome.
[02:05:10.820 --> 02:05:14.260]   Edge is the light blue line at the bottom here.
[02:05:14.260 --> 02:05:16.860]   Firefox is the orange line, a little bit above Edge.
[02:05:16.860 --> 02:05:21.660]   Internet Explorer is the purple line, a little bit above Firefox, but none of them have more
[02:05:21.660 --> 02:05:24.260]   than 15% market share.
[02:05:24.260 --> 02:05:27.300]   Chrome has 63.6% market share.
[02:05:27.300 --> 02:05:29.020]   Internet Explorer 11.
[02:05:29.020 --> 02:05:30.020]   Firefox.
[02:05:30.020 --> 02:05:31.020]   More than Firefox?
[02:05:31.020 --> 02:05:33.380]   Oh, Firefox is only 10%.
[02:05:33.380 --> 02:05:37.380]   But I'm saying that Internet Explorer is higher than that Firefox.
[02:05:37.380 --> 02:05:38.380]   That must just be desktop.
[02:05:38.380 --> 02:05:39.380]   That's desktop.
[02:05:39.380 --> 02:05:40.380]   You want to look at mobile?
[02:05:40.380 --> 02:05:41.380]   Yes, that's just a mobile.
[02:05:41.380 --> 02:05:43.220]   It's all Safari, of course.
[02:05:43.220 --> 02:05:44.220]   Safari?
[02:05:44.220 --> 02:05:45.220]   No.
[02:05:45.220 --> 02:05:46.220]   Safari 26%.
[02:05:46.220 --> 02:05:48.220]   Now this is global.
[02:05:48.220 --> 02:05:49.220]   63% Chrome.
[02:05:49.220 --> 02:05:56.900]   But talk about a disconnect because on iOS devices, obviously Safari, way easier to just
[02:05:56.900 --> 02:05:59.700]   go with the default where links open up.
[02:05:59.700 --> 02:06:06.260]   Why not use WebKit instead of Blink?
[02:06:06.260 --> 02:06:09.940]   By going to Chrome, they're using the Blink, which is a fork of WebKit.
[02:06:09.940 --> 02:06:12.540]   Why not use WebKit instead?
[02:06:12.540 --> 02:06:14.620]   That would have given Leo a heart attack.
[02:06:14.620 --> 02:06:16.540]   It would have been Microsoft's WebKit.
[02:06:16.540 --> 02:06:18.380]   That would have given me a heart attack.
[02:06:18.380 --> 02:06:22.340]   That's one company that's never going to use Chromium or Blink is Apple.
[02:06:22.340 --> 02:06:24.740]   Safari which uses WebKit.
[02:06:24.740 --> 02:06:28.460]   And everything on the iPhone is WebKit because Apple doesn't allow you to do anything besides
[02:06:28.460 --> 02:06:29.460]   WebKit.
[02:06:29.460 --> 02:06:32.500]   So that gives them some significant market share.
[02:06:32.500 --> 02:06:34.420]   Yeah, that may have been interesting if Microsoft has been WebKit.
[02:06:34.420 --> 02:06:40.180]   If they'd gone WebKit, then it would have been essentially using their native, they
[02:06:40.180 --> 02:06:44.900]   could have done an Edge browser for iOS and it would have been using its native rendering
[02:06:44.900 --> 02:06:45.900]   engine.
[02:06:45.900 --> 02:06:46.900]   Yeah.
[02:06:46.900 --> 02:06:52.620]   But they're not in it to balance out the balance of power in the browser market.
[02:06:52.620 --> 02:06:54.980]   I think they want to do it.
[02:06:54.980 --> 02:06:57.540]   But I think why do they want to do it?
[02:06:57.540 --> 02:07:02.940]   For the health of the Web and the Internet, it would have been better to have two strong
[02:07:02.940 --> 02:07:05.740]   competitors rather than one totally dominant one.
[02:07:05.740 --> 02:07:06.740]   Sure.
[02:07:06.740 --> 02:07:07.940]   Yeah, no, I completely agree.
[02:07:07.940 --> 02:07:11.780]   But I think Microsoft's intent here is just, "Okay, we don't want to have to worry about
[02:07:11.780 --> 02:07:12.780]   this anymore.
[02:07:12.780 --> 02:07:14.660]   We're just going to use Chromium.
[02:07:14.660 --> 02:07:15.660]   Everyone does it.
[02:07:15.660 --> 02:07:17.100]   It's going to run fine.
[02:07:17.100 --> 02:07:20.900]   And it's a headache we don't want to deal with now."
[02:07:20.900 --> 02:07:22.420]   Huawei, again in the news.
[02:07:22.420 --> 02:07:25.220]   Why am we been talking about this Huawei thing for a while?
[02:07:25.220 --> 02:07:30.940]   I'm still torn about whether this is a political effort by the United States to discredit China
[02:07:30.940 --> 02:07:33.700]   or whether there really is a security issue.
[02:07:33.700 --> 02:07:38.460]   Huawei's chief financial officer, the daughter of the founder who of course was former Chinese
[02:07:38.460 --> 02:07:43.020]   military arrested in Canada on behalf of the US last weekend.
[02:07:43.020 --> 02:07:48.060]   She was apprehended for allegedly violating US sanctions against Iran while Huawei created
[02:07:48.060 --> 02:07:53.340]   a shell company that did business with Iran pretending to be another company.
[02:07:53.340 --> 02:07:57.260]   It was in fact Huawei.
[02:07:57.260 --> 02:08:02.100]   Now American tech executives have been warned about travel to China because China's hopping
[02:08:02.100 --> 02:08:04.100]   mad.
[02:08:04.100 --> 02:08:07.060]   Huawei makes almost all the 5G gear in the market.
[02:08:07.060 --> 02:08:09.220]   Canada said it had cost more than a billion dollars.
[02:08:09.220 --> 02:08:14.980]   We're tearing out all our Huawei gear.
[02:08:14.980 --> 02:08:17.860]   The security, see this is the problem.
[02:08:17.860 --> 02:08:19.780]   I don't know what the US intelligence community thinks.
[02:08:19.780 --> 02:08:23.100]   I do know what the US administration thinks.
[02:08:23.100 --> 02:08:24.780]   I do know what the Commerce Department thinks.
[02:08:24.780 --> 02:08:29.220]   I know what Congress thinks that Huawei and other Chinese companies are a threat because
[02:08:29.220 --> 02:08:34.900]   they might spy on us industrial espionage using their gear in our networks.
[02:08:34.900 --> 02:08:42.340]   Or worse, should a cyber war erupt to use it to cut us off, to turn off our networks.
[02:08:42.340 --> 02:08:43.340]   Those all seem legit.
[02:08:43.340 --> 02:08:46.940]   I haven't heard from the intelligence community or whether there's a, if that's a real threat
[02:08:46.940 --> 02:08:49.180]   or not.
[02:08:49.180 --> 02:08:54.180]   But don't go to China and don't buy Huawei.
[02:08:54.180 --> 02:08:59.380]   And I'm just not sure if it's a technical issue or a political issue.
[02:08:59.380 --> 02:09:01.860]   And we can't be sure.
[02:09:01.860 --> 02:09:08.540]   It's one of the biggest tech and political questions of these past few years because
[02:09:08.540 --> 02:09:11.620]   the implications are massive.
[02:09:11.620 --> 02:09:15.740]   If it is actually a tech issue and if it isn't.
[02:09:15.740 --> 02:09:22.620]   And I don't know that short of having a suicidal whistleblower, we're ever going to know.
[02:09:22.620 --> 02:09:27.300]   This is, I mean, maybe when the documents are declassified in 50 years.
[02:09:27.300 --> 02:09:38.260]   But it's really hard because you don't want to be swallowing the version that seems implausible.
[02:09:38.260 --> 02:09:40.100]   But both are, that's the problem.
[02:09:40.100 --> 02:09:41.540]   Both are somewhat plausible.
[02:09:41.540 --> 02:09:43.940]   And we can't know.
[02:09:43.940 --> 02:09:47.260]   Huawei makes most of the 5G gear in the, in the world.
[02:09:47.260 --> 02:09:50.420]   They're the number two cell phone manufacturer, smartphone manufacturer in the world after
[02:09:50.420 --> 02:09:52.780]   Samsung.
[02:09:52.780 --> 02:09:55.820]   But they don't sell phones in the US because of the commerce department and they don't
[02:09:55.820 --> 02:10:01.900]   sell networking gear and seems to a lot of countries now because of, because of, I think
[02:10:01.900 --> 02:10:05.860]   a trade war, to be honest, but I just don't know.
[02:10:05.860 --> 02:10:09.460]   According to the next web, if you have a micro tick router, get rid of it.
[02:10:09.460 --> 02:10:15.420]   So as many as 400,000 routers have been hijacked because of a flaw in the micro tick routers
[02:10:15.420 --> 02:10:20.340]   that allows bad guys to put crypto currency mining software in the router.
[02:10:20.340 --> 02:10:23.340]   Okay, admittedly routers are not super fast.
[02:10:23.340 --> 02:10:26.340]   But if you get 415,000 of them, you might make a little bit coin.
[02:10:26.340 --> 02:10:28.180]   I'm a little money on the side.
[02:10:28.180 --> 02:10:30.420]   I've never even heard of micro tech.
[02:10:30.420 --> 02:10:32.060]   Yeah, they're out there.
[02:10:32.060 --> 02:10:36.060]   And unfortunately, the real problem with most routers these days, and this is why I'm telling
[02:10:36.060 --> 02:10:37.820]   everybody, I'm sure you are too rich.
[02:10:37.820 --> 02:10:40.740]   If I were one of the newer mesh routers, even though they're more expensive, they're kept
[02:10:40.740 --> 02:10:41.900]   up to date.
[02:10:41.900 --> 02:10:44.540]   Most routers are woefully insecure.
[02:10:44.540 --> 02:10:47.740]   I got Google Wi-Fi last year.
[02:10:47.740 --> 02:10:49.380]   I really like it.
[02:10:49.380 --> 02:10:50.380]   It's great.
[02:10:50.380 --> 02:10:54.500]   I mean, they're not much better than having three different routers scattered around my
[02:10:54.500 --> 02:10:55.660]   house.
[02:10:55.660 --> 02:10:58.860]   I did back in the day, Leo, you'll like this.
[02:10:58.860 --> 02:11:02.620]   I turned my old Belkin router into an access point.
[02:11:02.620 --> 02:11:06.460]   Like before these mesh networks were, you know, I didn't want to use like a booster.
[02:11:06.460 --> 02:11:08.780]   So I actually hardwired it to my router.
[02:11:08.780 --> 02:11:11.020]   I don't even know how I just followed something on YouTube.
[02:11:11.020 --> 02:11:12.020]   But it was great.
[02:11:12.020 --> 02:11:15.860]   I had like perfect signal in my hold back when I lived in an apartment.
[02:11:15.860 --> 02:11:18.780]   And it's kind of like it was like the forefather of these new systems.
[02:11:18.780 --> 02:11:21.460]   Now this was five years ago, six years ago.
[02:11:21.460 --> 02:11:23.620]   But now with these, the new systems are just amazing.
[02:11:23.620 --> 02:11:27.180]   I mean, I tell people you're getting what you pay for because your internet works in
[02:11:27.180 --> 02:11:28.180]   all the corners.
[02:11:28.180 --> 02:11:31.660]   And but now here's the thing, they're trying to upsell you on these services.
[02:11:31.660 --> 02:11:32.660]   That's like with Skuro.
[02:11:32.660 --> 02:11:34.260]   Yeah, you got to subscribe.
[02:11:34.260 --> 02:11:39.060]   Except that I understand and consumers hate this idea.
[02:11:39.060 --> 02:11:43.620]   But I'm trying to tell them, look, if you're not paying these fees, there's no incentive
[02:11:43.620 --> 02:11:45.820]   for these guys to fix the problems in these routers.
[02:11:45.820 --> 02:11:50.100]   They, right, you know, so it's not a bad thing.
[02:11:50.100 --> 02:11:51.100]   Subscribe.
[02:11:51.100 --> 02:11:52.100]   You get a lot of services.
[02:11:52.100 --> 02:11:53.180]   Euro is an example.
[02:11:53.180 --> 02:11:54.940]   You get one password.
[02:11:54.940 --> 02:11:56.540]   You get a VPN.
[02:11:56.540 --> 02:11:57.540]   You get filters.
[02:11:57.540 --> 02:11:59.660]   You get ad blockers.
[02:11:59.660 --> 02:12:01.060]   You get regular updates.
[02:12:01.060 --> 02:12:02.860]   You get all sorts of features.
[02:12:02.860 --> 02:12:08.620]   It's 99 bucks a year and you're kind of incentivizing them to keep their platform up to date, which
[02:12:08.620 --> 02:12:11.540]   I think is worth the hundred bucks a year.
[02:12:11.540 --> 02:12:15.340]   Yeah, no, it's their service is definitely worth the hundred dollars.
[02:12:15.340 --> 02:12:18.100]   If you add everything up that they give you, it's well worth it.
[02:12:18.100 --> 02:12:19.100]   People are mad.
[02:12:19.100 --> 02:12:21.860]   It's just plume because plume said if you don't pay it, it won't work.
[02:12:21.860 --> 02:12:22.860]   Yeah.
[02:12:22.860 --> 02:12:23.860]   That's a different matter.
[02:12:23.860 --> 02:12:24.860]   That's a different matter.
[02:12:24.860 --> 02:12:26.940]   It's certainly, you know, it costs money to provide.
[02:12:26.940 --> 02:12:32.380]   I mean, you talked about this all over the years on your radio show.
[02:12:32.380 --> 02:12:38.300]   It costs money to provide support and to continue to support a product years after you've shipped
[02:12:38.300 --> 02:12:39.300]   it.
[02:12:39.300 --> 02:12:42.980]   There's a significant cost associated with that with doing the development and validation
[02:12:42.980 --> 02:12:44.820]   of all that.
[02:12:44.820 --> 02:12:46.820]   That's something that we're increasingly seeing.
[02:12:46.820 --> 02:12:51.300]   We're going to see more and more of across all of the electronically driven products that
[02:12:51.300 --> 02:12:55.780]   we have from routers to autonomous vehicles.
[02:12:55.780 --> 02:12:59.700]   Somehow we've got to figure out a way to pay for that and figure out what's the best way
[02:12:59.700 --> 02:13:01.780]   for consumers to pay for that.
[02:13:01.780 --> 02:13:05.500]   You know, the sort of ongoing subscription fee for the product.
[02:13:05.500 --> 02:13:10.100]   Do you build it in upfront, you know, into the cost of the original price of the product
[02:13:10.100 --> 02:13:16.460]   or do you not even sell the product but only provide it as a service?
[02:13:16.460 --> 02:13:17.460]   Two thoughts on that.
[02:13:17.460 --> 02:13:20.860]   Remember when people used to get really mad about having to pay the, there was like a
[02:13:20.860 --> 02:13:24.620]   fee for like updating your maps and your GPS system in your car.
[02:13:24.620 --> 02:13:25.620]   So people get mad about that.
[02:13:25.620 --> 02:13:27.300]   Of course those people were a little bit rages.
[02:13:27.300 --> 02:13:31.700]   You know, it was like $9.00 for updated maps.
[02:13:31.700 --> 02:13:34.860]   Would you pay for a subscription to like a cell phone?
[02:13:34.860 --> 02:13:39.500]   You know, like if you bought an Android phone or even remember when Apple, the first iOS
[02:13:39.500 --> 02:13:43.660]   update or was it an iOS or was it just the, it was just called?
[02:13:43.660 --> 02:13:47.140]   Yeah, they were like before I remember it was even iOS when it was iPhone OS.
[02:13:47.140 --> 02:13:48.140]   The first five bucks.
[02:13:48.140 --> 02:13:49.620]   Yeah, they were charging for it.
[02:13:49.620 --> 02:13:50.620]   Remember that?
[02:13:50.620 --> 02:13:51.620]   I don't remember that.
[02:13:51.620 --> 02:13:55.260]   It was like the first, I think it was the first update they ever did was $5 to update.
[02:13:55.260 --> 02:13:57.980]   No, I think that was actually only on the iPod touch.
[02:13:57.980 --> 02:13:58.980]   The iPod touch, yeah.
[02:13:58.980 --> 02:14:02.860]   She updates for free for the phone, but on the iPod touch, you had to pay for the update.
[02:14:02.860 --> 02:14:03.860]   I don't remember that.
[02:14:03.860 --> 02:14:04.860]   I think it was $10.
[02:14:04.860 --> 02:14:05.860]   John's nodding.
[02:14:05.860 --> 02:14:06.860]   Yeah.
[02:14:06.860 --> 02:14:07.860]   $10.
[02:14:07.860 --> 02:14:10.540]   Well, Apple, it was in a world where we're not old.
[02:14:10.540 --> 02:14:11.540]   What's up?
[02:14:11.540 --> 02:14:12.540]   They're charging you for it.
[02:14:12.540 --> 02:14:14.540]   How much had born back then?
[02:14:14.540 --> 02:14:16.780]   They're charging you in that 12, $1,400 phone.
[02:14:16.780 --> 02:14:17.780]   Yeah, they're charging you.
[02:14:17.780 --> 02:14:21.060]   Your iOS updates were, were you had to pay for them?
[02:14:21.060 --> 02:14:22.060]   Remember that?
[02:14:22.060 --> 02:14:23.060]   That wasn't so long ago.
[02:14:23.060 --> 02:14:24.060]   Yeah.
[02:14:24.060 --> 02:14:25.060]   Back out.
[02:14:25.060 --> 02:14:26.060]   It was 10 was 130 bucks a year.
[02:14:26.060 --> 02:14:28.700]   You guys are all sad and like old timers.
[02:14:28.700 --> 02:14:29.700]   It's been a lot of fun.
[02:14:29.700 --> 02:14:32.820]   I have so many more stories we could cover, but really, we really probably shouldn't go
[02:14:32.820 --> 02:14:36.140]   more than three or four hours on the show because it's just, you know.
[02:14:36.140 --> 02:14:38.820]   We didn't even talk about Waymo One launching.
[02:14:38.820 --> 02:14:46.900]   Waymo One, we got the electric story about Tesla vehicles driving 1.2 million, sorry,
[02:14:46.900 --> 02:14:49.060]   billion miles on autopilot.
[02:14:49.060 --> 02:14:50.060]   Only three people died.
[02:14:50.060 --> 02:14:51.060]   Only three.
[02:14:51.060 --> 02:14:52.060]   Yeah.
[02:14:52.060 --> 02:14:53.060]   It's nothing.
[02:14:53.060 --> 02:14:54.060]   That's a four times safer than humans.
[02:14:54.060 --> 02:14:58.940]   Depends on how you added up and what you're actually comparing it to.
[02:14:58.940 --> 02:15:02.540]   We follow up on the CRISPR story from last week.
[02:15:02.540 --> 02:15:09.940]   The Chinese scientist for reportedly editing those babies' genes has now gone missing.
[02:15:09.940 --> 02:15:12.380]   I don't know whether he's edited out.
[02:15:12.380 --> 02:15:13.620]   He's, I don't know.
[02:15:13.620 --> 02:15:15.580]   Yes, it's just, it's a mystery.
[02:15:15.580 --> 02:15:17.780]   His, his rumors are circulating.
[02:15:17.780 --> 02:15:19.780]   He's been detained by the Chinese government.
[02:15:19.780 --> 02:15:23.660]   Nobody's heard from him since November 28th when he spoke in Hong Kong at the International
[02:15:23.660 --> 02:15:25.260]   Summit on Human Genome Editing.
[02:15:25.260 --> 02:15:29.500]   I thought the rumors were he's on house arrest.
[02:15:29.500 --> 02:15:35.020]   That sounds like, that sounds reasonable because even though it wasn't clear whether
[02:15:35.020 --> 02:15:38.220]   it was illegal to do that in China and everybody assumed, well, if he did it, he must have had
[02:15:38.220 --> 02:15:40.020]   the approval of the Chinese government.
[02:15:40.020 --> 02:15:43.140]   There has been such international uproar over this.
[02:15:43.140 --> 02:15:47.340]   I think the Chinese government thought, it's just, it's just, it's just locking them.
[02:15:47.340 --> 02:15:53.620]   It's just, and meanwhile, China immediately denounced it, I think, the next day.
[02:15:53.620 --> 02:15:56.100]   Yeah, as soon as they saw what people were saying.
[02:15:56.100 --> 02:16:00.300]   Now unless they could slip a spy chip inside those new babies, they don't want anything
[02:16:00.300 --> 02:16:01.300]   to do with it.
[02:16:01.300 --> 02:16:02.300]   Is it a Huawei baby?
[02:16:02.300 --> 02:16:03.300]   It's a Huawei baby.
[02:16:03.300 --> 02:16:04.300]   It's a Huawei baby.
[02:16:04.300 --> 02:16:05.300]   Aah!
[02:16:05.300 --> 02:16:09.220]   China forms a new body to review the ethics risks of video games.
[02:16:09.220 --> 02:16:13.780]   They rejected nine of the initial batch of 20 titles they reviewed.
[02:16:13.780 --> 02:16:19.340]   I don't know which games, but they're worried about video game addiction.
[02:16:19.340 --> 02:16:20.340]   Mm.
[02:16:20.340 --> 02:16:27.180]   They've been, the big, the big story there, or the continuing story was that the two committees
[02:16:27.180 --> 02:16:34.460]   that were reviewing video games were kind of under reworking for months.
[02:16:34.460 --> 02:16:39.620]   So no new video game was approved in the country for months and months.
[02:16:39.620 --> 02:16:43.300]   And that was a concern for the video game developers.
[02:16:43.300 --> 02:16:44.300]   Yeah.
[02:16:44.300 --> 02:16:45.300]   You used to work for Blizzard.
[02:16:45.300 --> 02:16:47.140]   I don't know, is Blizzard in China?
[02:16:47.140 --> 02:16:48.140]   Yeah.
[02:16:48.140 --> 02:16:49.300]   Through partners.
[02:16:49.300 --> 02:16:52.580]   I don't think they had games that came out during that period.
[02:16:52.580 --> 02:16:55.980]   So it was kind of not a big deal for them.
[02:16:55.980 --> 02:17:02.820]   On Thursday, the Australian government passed a law, the assistance and access law requiring
[02:17:02.820 --> 02:17:08.780]   tech companies to help law enforcement agencies break into individuals' encrypted data using
[02:17:08.780 --> 02:17:13.140]   secret warrants the government can even compel a company to serve malware remotely to the
[02:17:13.140 --> 02:17:16.220]   targets device.
[02:17:16.220 --> 02:17:17.220]   This follows us.
[02:17:17.220 --> 02:17:18.620]   So this is the nightmare scenario, right?
[02:17:18.620 --> 02:17:20.620]   But this is the horror one.
[02:17:20.620 --> 02:17:25.820]   From what I understand, essentially the government is saying, you have to provide the data.
[02:17:25.820 --> 02:17:27.020]   We don't care how you do it.
[02:17:27.020 --> 02:17:28.020]   Figure it out.
[02:17:28.020 --> 02:17:29.020]   You have to.
[02:17:29.020 --> 02:17:33.060]   So I don't know, I don't know how what the companies are going to do there.
[02:17:33.060 --> 02:17:36.420]   Are they going to stop doing business in Australia?
[02:17:36.420 --> 02:17:38.420]   What's, what can they do?
[02:17:38.420 --> 02:17:39.420]   Stunning.
[02:17:39.420 --> 02:17:41.380]   I don't know.
[02:17:41.380 --> 02:17:43.580]   We'll find out.
[02:17:43.580 --> 02:17:49.140]   It's, you know, Britain's got a similar law, the investigatory powers law.
[02:17:49.140 --> 02:17:52.060]   Russia has laws against encryption.
[02:17:52.060 --> 02:17:53.580]   I think this is a global phenomenon.
[02:17:53.580 --> 02:17:57.900]   The real question in my mind is how long before the US and France adopt such laws?
[02:17:57.900 --> 02:17:59.980]   I threw France in for you, Patrick.
[02:17:59.980 --> 02:18:01.700]   I appreciate that.
[02:18:01.700 --> 02:18:02.700]   Thank you.
[02:18:02.700 --> 02:18:03.700]   Nobody really cares.
[02:18:03.700 --> 02:18:05.940]   It'll be a new EU directive.
[02:18:05.940 --> 02:18:12.260]   Patrick Bejah, if you want to hear more about all sorts of topics, movies, games, politics,
[02:18:12.260 --> 02:18:15.660]   Frenchspin.com, there's a podcast for you there.
[02:18:15.660 --> 02:18:18.300]   He's now a full time podcaster.
[02:18:18.300 --> 02:18:19.300]   I am.
[02:18:19.300 --> 02:18:22.020]   I've been for a few years, powered by Patreon.
[02:18:22.020 --> 02:18:23.020]   Yay.
[02:18:23.020 --> 02:18:29.100]   Actually, on, on my French tech show, which I would encourage people who speak French
[02:18:29.100 --> 02:18:33.380]   or want to learn French to go check out at Frenchspin.fr.
[02:18:33.380 --> 02:18:35.140]   It's called La Honde du Teque.
[02:18:35.140 --> 02:18:40.500]   And you can enjoy the language with topics you're already familiar with.
[02:18:40.500 --> 02:18:43.540]   I do one on gaming as well, which is called La Honde du Vujour.
[02:18:43.540 --> 02:18:51.540]   And I have one on politics in English at Frenchspin.com, which is the Filiest Club.
[02:18:51.540 --> 02:18:55.740]   We talk about all the happenings from different perspectives because we get people from different
[02:18:55.740 --> 02:18:56.740]   countries.
[02:18:56.740 --> 02:18:58.820]   So I think that's something interesting.
[02:18:58.820 --> 02:19:05.980]   The nice thing about La Honde du Teque is so much of tech is in France as English.
[02:19:05.980 --> 02:19:06.980]   So free.
[02:19:06.980 --> 02:19:14.460]   I'm looking at your show notes, Tumblr, Amazon, pornography, Airbnb, Instagram, Microsoft,
[02:19:14.460 --> 02:19:18.420]   Apple, all a plural and pros on core.
[02:19:18.420 --> 02:19:19.420]   Yes.
[02:19:19.420 --> 02:19:20.420]   Absolutely.
[02:19:20.420 --> 02:19:21.420]   I love it.
[02:19:21.420 --> 02:19:24.820]   The delta to free half those words are English.
[02:19:24.820 --> 02:19:27.300]   Well, delta is also French, but free.
[02:19:27.300 --> 02:19:28.300]   Yes.
[02:19:28.300 --> 02:19:36.940]   It's a company that started the triple play, triple play set up boxes or ISPs.
[02:19:36.940 --> 02:19:42.300]   It actually started in France and I don't know the mid 2000s or the 2000s.
[02:19:42.300 --> 02:19:43.300]   Nice.
[02:19:43.300 --> 02:19:44.300]   Yeah.
[02:19:44.300 --> 02:19:47.260]   And not Patrick on Twitter, of course, it's very easy.
[02:19:47.260 --> 02:19:49.780]   It's Patrick with a knot in front of it.
[02:19:49.780 --> 02:19:51.900]   And you already remember it.
[02:19:51.900 --> 02:19:52.900]   I got to know.
[02:19:52.900 --> 02:19:56.100]   What's the Icy Veins podcast about?
[02:19:56.100 --> 02:20:01.500]   So that Icy Veins is actually a website for Blizzard Games News.
[02:20:01.500 --> 02:20:02.500]   Ah.
[02:20:02.500 --> 02:20:05.180]   I thought it was the horror stuff.
[02:20:05.180 --> 02:20:07.180]   Not far.
[02:20:07.180 --> 02:20:08.180]   No.
[02:20:08.180 --> 02:20:10.140]   Patrick, it's really great to see you.
[02:20:10.140 --> 02:20:11.300]   You can thank you for having me.
[02:20:11.300 --> 02:20:14.540]   Put your yellow vest back on.
[02:20:14.540 --> 02:20:15.540]   We are done here.
[02:20:15.540 --> 02:20:16.980]   It's really nice to have you.
[02:20:16.980 --> 02:20:22.260]   Also, a thrill to have my friend Rich tomorrow back on.
[02:20:22.260 --> 02:20:26.820]   Pick up your book off the floor where I threw it after I realized, oh, my name is not on
[02:20:26.820 --> 02:20:27.820]   it.
[02:20:27.820 --> 02:20:33.220]   101 handy tech tips for the iPhone.
[02:20:33.220 --> 02:20:34.460]   I'm not going to give you a hard time.
[02:20:34.460 --> 02:20:39.660]   But on the back, it says he's also a frequent contributor to KFI Los Angeles and Phil and
[02:20:39.660 --> 02:20:43.540]   host for a nationally syndicated technology radio show.
[02:20:43.540 --> 02:20:45.300]   What show would that be?
[02:20:45.300 --> 02:20:46.740]   You know, it's your show.
[02:20:46.740 --> 02:20:48.860]   I love it.
[02:20:48.860 --> 02:20:49.860]   I don't need the plug.
[02:20:49.860 --> 02:20:51.860]   I will do a new version with your blood on there.
[02:20:51.860 --> 02:20:52.860]   No, no, I'm teasing you.
[02:20:52.860 --> 02:20:53.860]   I'm teasing you.
[02:20:53.860 --> 02:20:57.420]   But if you want a blurb, let me know and I will give you a blurb for it because you
[02:20:57.420 --> 02:21:02.780]   deserve a little credit for doing the hard work of helping people understand how to use
[02:21:02.780 --> 02:21:03.780]   their technology.
[02:21:03.780 --> 02:21:06.140]   I got a text from my father-in-law today.
[02:21:06.140 --> 02:21:11.340]   I gave him a copy last night and he said, let's see where is it on my watch here.
[02:21:11.340 --> 02:21:12.340]   Yeah.
[02:21:12.340 --> 02:21:13.340]   Oh gosh, too many texts.
[02:21:13.340 --> 02:21:17.180]   Anyway, he did say he goes, oh, here he is.
[02:21:17.180 --> 02:21:18.180]   Really love the book.
[02:21:18.180 --> 02:21:21.740]   Just spent time talking to Siri using your tips.
[02:21:21.740 --> 02:21:22.740]   Amazing.
[02:21:22.740 --> 02:21:25.820]   I mean, I love getting the emails from people because even people who thought they knew
[02:21:25.820 --> 02:21:29.940]   everything about the iPhone, they read it and they learn like these little things that
[02:21:29.940 --> 02:21:31.780]   you just don't know the iPhone does.
[02:21:31.780 --> 02:21:32.780]   It's fun.
[02:21:32.780 --> 02:21:33.780]   It's awesome.
[02:21:33.780 --> 02:21:38.300]   It's on Amazon in paperback, also on a Kindle if you want to do it that way.
[02:21:38.300 --> 02:21:40.140]   And I have a podcast too, Leo, by the way.
[02:21:40.140 --> 02:21:41.140]   Rich on tech.
[02:21:41.140 --> 02:21:42.140]   Rich on tech.tv.
[02:21:42.140 --> 02:21:44.140]   Yeah, there it is.
[02:21:44.140 --> 02:21:48.300]   So you can search in iTunes and I'm there.
[02:21:48.300 --> 02:21:53.540]   My words are not as Frenchie or fancy, but...
[02:21:53.540 --> 02:21:54.540]   That's probably a good thing.
[02:21:54.540 --> 02:21:59.700]   You can see them every or many mornings on KTLA's Morning News in Los Angeles and TV stations
[02:21:59.700 --> 02:22:00.700]   nationwide.
[02:22:00.700 --> 02:22:01.700]   Great to see you again, Rich.
[02:22:01.700 --> 02:22:02.700]   Thank you, Leo.
[02:22:02.700 --> 02:22:04.300]   He gets up at like two in the morning.
[02:22:04.300 --> 02:22:06.300]   When do you have to get up to do the morning?
[02:22:06.300 --> 02:22:11.100]   Oh, 3 a.m., 2.55 is my alarm of my phone.
[02:22:11.100 --> 02:22:13.100]   Oh, my God.
[02:22:13.100 --> 02:22:14.100]   Yeah.
[02:22:14.100 --> 02:22:17.220]   Sam Aboule-Somed, it's so great to have you.
[02:22:17.220 --> 02:22:20.260]   I know I mispronounce your name every single time, but you know how to...
[02:22:20.260 --> 02:22:21.260]   This is fine.
[02:22:21.260 --> 02:22:22.260]   It's close.
[02:22:22.260 --> 02:22:23.260]   Right, yeah.
[02:22:23.260 --> 02:22:24.260]   Okay.
[02:22:24.260 --> 02:22:25.260]   He's a senior analyst for Navigant Research.
[02:22:25.260 --> 02:22:29.340]   He is the man who brings me the cars and it's always fun to have you on.
[02:22:29.340 --> 02:22:32.060]   Come back soon and bring that new Porsche with you, will you?
[02:22:32.060 --> 02:22:33.060]   I will try.
[02:22:33.060 --> 02:22:34.060]   I will do my best.
[02:22:34.060 --> 02:22:35.460]   It's always fun to be here with you.
[02:22:35.460 --> 02:22:36.460]   Thank you.
[02:22:36.460 --> 02:22:37.460]   You know, you can...
[02:22:37.460 --> 02:22:38.460]   What's your podcast?
[02:22:38.460 --> 02:22:39.460]   It's called Wheel Bering.
[02:22:39.460 --> 02:22:40.460]   It's at wheelbering.media.
[02:22:40.460 --> 02:22:46.220]   My friend Dan Roth and I have been doing it for a little over two years now.
[02:22:46.220 --> 02:22:51.500]   We talk about the cars that we're driving and about automotive technology and cool stuff
[02:22:51.500 --> 02:22:54.300]   that's going on in the automotive space.
[02:22:54.300 --> 02:22:58.820]   We're going to be recording another one Tuesday night.
[02:22:58.820 --> 02:23:04.300]   You can also find the work that I do for pay at NavigantResearch.com, the research reports
[02:23:04.300 --> 02:23:07.820]   that we write and we do custom research for clients as well.
[02:23:07.820 --> 02:23:14.300]   You can also find my ramblings and Forbes talking about cars and also an automotive engineering
[02:23:14.300 --> 02:23:15.300]   magazine.
[02:23:15.300 --> 02:23:16.300]   How long have you been doing this?
[02:23:16.300 --> 02:23:17.740]   When did you start covering cars?
[02:23:17.740 --> 02:23:21.300]   Well, I've been in the auto industry since 1990.
[02:23:21.300 --> 02:23:22.540]   I graduated in 1990.
[02:23:22.540 --> 02:23:25.180]   I worked for 17 years as an engineer and then...
[02:23:25.180 --> 02:23:26.180]   Where'd you work?
[02:23:26.180 --> 02:23:27.180]   I worked for a couple of different suppliers.
[02:23:27.180 --> 02:23:28.180]   I worked for Delco.
[02:23:28.180 --> 02:23:31.220]   Which was the precursor of Delphi.
[02:23:31.220 --> 02:23:35.460]   Then I worked for Kelsey Hayes through several acquisitions.
[02:23:35.460 --> 02:23:38.660]   By the time I left, it was TRW automotive.
[02:23:38.660 --> 02:23:41.620]   Then I started writing full time in 2007.
[02:23:41.620 --> 02:23:44.100]   Lisa gave you the highest praise.
[02:23:44.100 --> 02:23:46.140]   She said he's a real car guy.
[02:23:46.140 --> 02:23:47.540]   She said, "I listen to Sam.
[02:23:47.540 --> 02:23:48.540]   She's a real car person.
[02:23:48.540 --> 02:23:50.540]   She loves her car."
[02:23:50.540 --> 02:23:56.820]   It used to be said that if you cut their veins and they bleed gasoline, then they're
[02:23:56.820 --> 02:23:58.620]   a real car guy and that's me.
[02:23:58.620 --> 02:24:00.780]   He's a real metal bender.
[02:24:00.780 --> 02:24:01.780]   Yeah.
[02:24:01.780 --> 02:24:02.780]   Thank you, Sam.
[02:24:02.780 --> 02:24:03.780]   I've done that.
[02:24:03.780 --> 02:24:04.780]   Thanks to all of you for joining us.
[02:24:04.780 --> 02:24:05.700]   We do this week in tech every week.
[02:24:05.700 --> 02:24:10.460]   It's really great fun for me to get together with some of my best friends and talk about
[02:24:10.460 --> 02:24:11.900]   the issues that I really care about.
[02:24:11.900 --> 02:24:12.900]   I hope you do too.
[02:24:12.900 --> 02:24:14.060]   I'm sure you do if you're here.
[02:24:14.060 --> 02:24:17.340]   3PM Pacific, 6PM Eastern, 2300 UTC.
[02:24:17.340 --> 02:24:22.420]   You can just go to twit.tv/live and pick a feed, audio or video.
[02:24:22.420 --> 02:24:26.460]   If you are watching or listening live, make sure you go to the chatroom to irc.twit.com.
[02:24:26.460 --> 02:24:30.780]   That's where all the other people watching and listening live.
[02:24:30.780 --> 02:24:31.780]   Hang out.
[02:24:31.780 --> 02:24:33.180]   Chat along with them.
[02:24:33.180 --> 02:24:35.740]   We welcome studio audience members.
[02:24:35.740 --> 02:24:39.940]   We have some visitors today from Minnesota and from Seattle.
[02:24:39.940 --> 02:24:45.220]   Great to have you both and a little dog named Rufus who's been a great, but good boy the
[02:24:45.220 --> 02:24:46.220]   whole time.
[02:24:46.220 --> 02:24:47.220]   Very patient.
[02:24:47.220 --> 02:24:48.220]   Just email tickets@twit.tv.
[02:24:48.220 --> 02:24:54.300]   We'll be glad to put a chair out for you and my bowl of water out for Rufus.
[02:24:54.300 --> 02:24:55.300]   What else?
[02:24:55.300 --> 02:24:59.340]   Oh yeah, you can get on to man versions at the website, twit.tv.
[02:24:59.340 --> 02:25:00.980]   Or probably the best thing to do.
[02:25:00.980 --> 02:25:02.540]   Find your podcast app.
[02:25:02.540 --> 02:25:03.660]   There are many good ones.
[02:25:03.660 --> 02:25:05.660]   We like pocket casts.
[02:25:05.660 --> 02:25:06.780]   The Apple Podcast app.
[02:25:06.780 --> 02:25:08.940]   Google's got a good podcast app now.
[02:25:08.940 --> 02:25:11.380]   Stitcher, slacker and subscribe.
[02:25:11.380 --> 02:25:12.540]   That way you'll get the episode.
[02:25:12.540 --> 02:25:17.780]   The minute it's edited and finished and polished up, hot off the presses delivered right to
[02:25:17.780 --> 02:25:18.860]   your device.
[02:25:18.860 --> 02:25:23.740]   You can also use your voice assistant anytime and just ask for this weekend tech podcast.
[02:25:23.740 --> 02:25:25.100]   You'll get the most recent edition.
[02:25:25.100 --> 02:25:26.100]   It's nice too.
[02:25:26.100 --> 02:25:27.780]   Thanks for being here.
[02:25:27.780 --> 02:25:28.780]   Have a great night.
[02:25:28.780 --> 02:25:30.100]   We'll see you next week.
[02:25:30.100 --> 02:25:31.100]   Another Twit.
[02:25:31.100 --> 02:25:32.100]   It is amazing.
[02:25:32.100 --> 02:25:32.100]   It is amazing.
[02:25:33.100 --> 02:25:36.100]   I'm on the twit.
[02:25:36.100 --> 02:25:37.100]   Do on the twit.
[02:25:37.100 --> 02:25:38.100]   Alright.
[02:25:38.100 --> 02:25:39.100]   Do on the twit, baby.
[02:25:39.100 --> 02:25:40.100]   Do on the twit.
[02:25:40.100 --> 02:25:41.100]   Alright.

