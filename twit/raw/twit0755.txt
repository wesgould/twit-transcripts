;FFMETADATA1
title=Somebody Stole My Tim Tams!
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=755
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.320]   It's time for Twack this weekend tech.
[00:00:02.320 --> 00:00:05.760]   Patrick Bejaw is here from frenchspin.com.
[00:00:05.760 --> 00:00:07.960]   Ian Thompson from The Register, my buddy.
[00:00:07.960 --> 00:00:11.240]   The parapetetic Mike Elgin we're going to talk about.
[00:00:11.240 --> 00:00:13.840]   Jeff Bezos' phone, was it really hacked
[00:00:13.840 --> 00:00:16.720]   by the Saudi Crown Prince?
[00:00:16.720 --> 00:00:20.400]   Apple is pushing back against the EU Common Chargers standards.
[00:00:20.400 --> 00:00:23.360]   One and only one good thing about Brexit.
[00:00:23.360 --> 00:00:27.000]   And where did Alan Turing's OBE medal go?
[00:00:27.000 --> 00:00:29.440]   Turns out it's hidden behind a toilet
[00:00:29.440 --> 00:00:30.600]   in Colorado.
[00:00:30.600 --> 00:00:32.960]   It's all coming up next on Twit.
[00:00:32.960 --> 00:00:36.080]   This weekend tech comes to you from the LastPass studios.
[00:00:36.080 --> 00:00:38.880]   You're focused on security, but are your employees?
[00:00:38.880 --> 00:00:41.400]   LastPass can ensure they are by making access
[00:00:41.400 --> 00:00:42.880]   and authentication seamless.
[00:00:42.880 --> 00:00:47.800]   Visit lasspass.com/twit to learn more.
[00:00:47.800 --> 00:00:52.560]   Podcasts you love from people you trust.
[00:00:52.560 --> 00:00:53.800]   This is Twit.
[00:00:53.800 --> 00:01:00.680]   This is Twit, this weekend tech.
[00:01:00.680 --> 00:01:07.800]   Episode 755, recorded Sunday, January 26, 2020.
[00:01:07.800 --> 00:01:10.800]   Somebody stole my Tim Tams.
[00:01:10.800 --> 00:01:13.800]   This weekend tech is brought to you by LastPass.
[00:01:13.800 --> 00:01:15.800]   LastPass is a personal password manager
[00:01:15.800 --> 00:01:17.800]   and identity solution for businesses
[00:01:17.800 --> 00:01:20.800]   that help secure everywhere you work and live.
[00:01:20.800 --> 00:01:24.800]   One password gets you in and LastPass will take care of the rest.
[00:01:24.800 --> 00:01:28.800]   Visit lasspass.com/twit to learn more.
[00:01:28.800 --> 00:01:31.800]   And by FreshBooks, the number one accounting software
[00:01:31.800 --> 00:01:34.800]   in the cloud for self-employed professionals and their teams
[00:01:34.800 --> 00:01:37.800]   seamlessly create invoices from estimates in a flash.
[00:01:37.800 --> 00:01:42.800]   Try it free for 30 days at freshbooks.com/twit.
[00:01:42.800 --> 00:01:44.800]   And by HealthIQ.
[00:01:44.800 --> 00:01:48.800]   HealthIQ uses science and data to secure lower life insurance rates
[00:01:48.800 --> 00:01:50.800]   for healthy people like you.
[00:01:50.800 --> 00:01:53.800]   To see if you qualify go to healthIQ.com/twit
[00:01:53.800 --> 00:01:55.800]   and take the HealthIQ quiz.
[00:01:55.800 --> 00:01:58.800]   It could save you up to 41% on your life insurance premiums
[00:01:58.800 --> 00:02:00.800]   compared to other providers.
[00:02:00.800 --> 00:02:03.800]   And by CashFly.
[00:02:03.800 --> 00:02:06.800]   Give your users the seamless online experience they want.
[00:02:06.800 --> 00:02:09.800]   Power your site or app with CashFly CDN
[00:02:09.800 --> 00:02:12.800]   and be 30% faster than the competition.
[00:02:12.800 --> 00:02:15.800]   Learn more at twit.cashfly.com.
[00:02:15.800 --> 00:02:22.800]   [music]
[00:02:22.800 --> 00:02:24.800]   Hey everybody welcome.
[00:02:24.800 --> 00:02:28.800]   It's time for Twit the Australia Day edition.
[00:02:28.800 --> 00:02:30.800]   Let me just see if this works.
[00:02:30.800 --> 00:02:32.800]   Ozzy, Ozzy, Ozzy.
[00:02:32.800 --> 00:02:34.800]   It does.
[00:02:34.800 --> 00:02:37.800]   We have a bunch of kids from the Canberra Grammar School
[00:02:37.800 --> 00:02:38.800]   visiting us.
[00:02:38.800 --> 00:02:39.800]   Thank you for the gifts.
[00:02:39.800 --> 00:02:42.800]   Some pictures and little kangaroos.
[00:02:42.800 --> 00:02:46.800]   More importantly Tim Tams, which we are going to share with our panel.
[00:02:46.800 --> 00:02:47.800]   Not you though.
[00:02:47.800 --> 00:02:49.800]   Patrick Bejia, he's in Finland.
[00:02:49.800 --> 00:02:52.800]   The host at Le Ronde vous.
[00:02:52.800 --> 00:02:53.800]   Tech.
[00:02:53.800 --> 00:02:57.800]   I want to turn tech into a French word and I couldn't.
[00:02:57.800 --> 00:02:59.800]   Le Ronde vous tech.
[00:02:59.800 --> 00:03:04.800]   Why is Le Ronde vous avec la zordenatur?
[00:03:04.800 --> 00:03:06.800]   It was too long.
[00:03:06.800 --> 00:03:08.800]   That was the official title.
[00:03:08.800 --> 00:03:12.800]   But then it didn't fit in the RSS feed.
[00:03:12.800 --> 00:03:14.800]   So yes, Le Ronde vous tech.
[00:03:14.800 --> 00:03:18.800]   If you speak French and like tech, what are you even doing if you're not subscribed?
[00:03:18.800 --> 00:03:19.800]   Le Ronde vous tech.
[00:03:19.800 --> 00:03:20.800]   There you go.
[00:03:20.800 --> 00:03:23.800]   And also, I'm really sad because I've never had Tim Tams ever.
[00:03:23.800 --> 00:03:24.800]   Oh, this is so good.
[00:03:24.800 --> 00:03:25.800]   I wish I was there.
[00:03:25.800 --> 00:03:29.800]   What you do is you bite the ends off and they become a straw and then you could sip your tea through it.
[00:03:29.800 --> 00:03:31.800]   It's just fantastic.
[00:03:31.800 --> 00:03:34.800]   So thank you to our friends from the Canberra School.
[00:03:34.800 --> 00:03:35.800]   It's great to have you.
[00:03:35.800 --> 00:03:37.800]   And happy Australia Day.
[00:03:37.800 --> 00:03:39.800]   I didn't realize, but it's Australia Day.
[00:03:39.800 --> 00:03:41.800]   They all have, can you get a shot of them with their flags?
[00:03:41.800 --> 00:03:43.800]   They have a big flag and everything?
[00:03:43.800 --> 00:03:45.800]   Wow.
[00:03:45.800 --> 00:03:46.800]   How are the fires?
[00:03:46.800 --> 00:03:49.800]   Are they calming down a little bit or is it still a crisis?
[00:03:49.800 --> 00:03:51.800]   A little bit better?
[00:03:51.800 --> 00:03:53.800]   Yeah, oh, it's a nightmare.
[00:03:53.800 --> 00:03:55.800]   So, Ken, Canberra.
[00:03:55.800 --> 00:03:56.800]   Canberra.
[00:03:56.800 --> 00:03:58.800]   I'm practicing.
[00:03:58.800 --> 00:04:00.800]   Also joining me, Mike Algin.
[00:04:00.800 --> 00:04:02.800]   He's from God knows where, all over.
[00:04:02.800 --> 00:04:04.800]   It's always nice when you come to the States to have you in studio.
[00:04:04.800 --> 00:04:05.800]   I'm from everywhere.
[00:04:05.800 --> 00:04:09.800]   Yeah, it's great to visit this exotic place called California.
[00:04:09.800 --> 00:04:10.800]   No, great to be here.
[00:04:10.800 --> 00:04:14.800]   And it's great that oddly enough, this county isn't on fire.
[00:04:14.800 --> 00:04:15.800]   So I don't know what's happening.
[00:04:15.800 --> 00:04:19.800]   Well, it's just the rain came, but it'll wail next year.
[00:04:19.800 --> 00:04:20.800]   You were in Mexico City last?
[00:04:20.800 --> 00:04:21.800]   We were in Mexico.
[00:04:21.800 --> 00:04:24.800]   Well, we took a vacation in El Salvador for a couple of weeks over the New Year's.
[00:04:24.800 --> 00:04:25.800]   That's where your wife, Amira, is from.
[00:04:25.800 --> 00:04:26.800]   That's right.
[00:04:26.800 --> 00:04:27.800]   We visited some of her family.
[00:04:27.800 --> 00:04:31.800]   We're going to Mexico in a few weeks.
[00:04:31.800 --> 00:04:35.800]   And then we're going to be gone all year, pretty much traveling all over the place.
[00:04:35.800 --> 00:04:38.800]   To win the Gastronomad thing at Gastronomad.net.
[00:04:38.800 --> 00:04:42.800]   If you click the link that says "experiences," you can see the upcoming experiences.
[00:04:42.800 --> 00:04:44.800]   Provence is next.
[00:04:44.800 --> 00:04:46.800]   The next one, well, Mexico City is next.
[00:04:46.800 --> 00:04:48.800]   That sold out, Morocco sold out.
[00:04:48.800 --> 00:04:52.800]   And Prosecco, we still have some rooms and I recommend that everybody join us in Prosecco
[00:04:52.800 --> 00:04:54.800]   because that's going to be so much fun.
[00:04:54.800 --> 00:04:55.800]   Pretty crazy.
[00:04:55.800 --> 00:04:56.800]   It'll be a well-oiled holiday.
[00:04:56.800 --> 00:04:57.800]   Yes.
[00:04:57.800 --> 00:05:02.800]   But no champagne as Patrick was quick to point out, just Prosecco.
[00:05:02.800 --> 00:05:09.800]   Also with us from just down the road a piece, but he's originally from the UK.
[00:05:09.800 --> 00:05:11.800]   It's Ian Thompson of the Register.co.
[00:05:11.800 --> 00:05:13.800]   We got a great international cast today.
[00:05:13.800 --> 00:05:14.800]   Yep.
[00:05:14.800 --> 00:05:19.800]   You know, the Australian, you've got the Americans on two and then the old world is on two.
[00:05:19.800 --> 00:05:20.800]   The old world.
[00:05:20.800 --> 00:05:22.800]   And we have our Tim Tams and our shapes from the...
[00:05:22.800 --> 00:05:23.800]   And our koala.
[00:05:23.800 --> 00:05:26.800]   The Australia should be a new world as well, right?
[00:05:26.800 --> 00:05:29.800]   I mean, they're all prisoners of her majesty.
[00:05:29.800 --> 00:05:32.800]   Oh, no, no, never say that in Adelaide.
[00:05:32.800 --> 00:05:37.800]   Never say in Canberra, it's just like, there were some earlier ones.
[00:05:37.800 --> 00:05:38.800]   Yes, who were coming?
[00:05:38.800 --> 00:05:39.800]   In the early days.
[00:05:39.800 --> 00:05:40.800]   A lot of people moved down now.
[00:05:40.800 --> 00:05:45.800]   I've got relatives in Sydney in Adelaide who just moved down to the lucky country in the 50s and 60s.
[00:05:45.800 --> 00:05:46.800]   It's so beautiful.
[00:05:46.800 --> 00:05:47.800]   I love Australia.
[00:05:47.800 --> 00:05:48.800]   I do.
[00:05:48.800 --> 00:05:50.800]   But then I love France and actually, Patrick's in Finland.
[00:05:50.800 --> 00:05:54.800]   So this is where we're from all over here.
[00:05:54.800 --> 00:05:59.800]   So welcome to our... are you guys going to have to run out before the show's over?
[00:05:59.800 --> 00:06:05.800]   Last time we had a crew here from Australia, I arranged to have them walk out and discuss.
[00:06:05.800 --> 00:06:06.800]   It was great.
[00:06:06.800 --> 00:06:07.800]   They had to leave a little early.
[00:06:07.800 --> 00:06:09.800]   So I said, "All right, I'm going to say something bad about Australia.
[00:06:09.800 --> 00:06:11.800]   You can just all go, "Ah!" and leave.
[00:06:11.800 --> 00:06:13.800]   So we could do that if you want.
[00:06:13.800 --> 00:06:15.800]   Australia Day.
[00:06:15.800 --> 00:06:17.800]   It should be America Day.
[00:06:17.800 --> 00:06:18.800]   No, that's a hard news.
[00:06:18.800 --> 00:06:19.800]   Ken, you're so annoying.
[00:06:19.800 --> 00:06:20.800]   I hate Ken.
[00:06:20.800 --> 00:06:22.800]   Every day is America Day.
[00:06:22.800 --> 00:06:24.800]   Those drop bears are nuts.
[00:06:24.800 --> 00:06:25.800]   I'll drop roses.
[00:06:25.800 --> 00:06:28.800]   You just smear veg on the top of your head and behind your ears.
[00:06:28.800 --> 00:06:30.800]   Actually, you don't want to hold a koala.
[00:06:30.800 --> 00:06:32.800]   You end up smelling like you're colibtous, right?
[00:06:32.800 --> 00:06:34.800]   They're very fragrant, those koalas.
[00:06:34.800 --> 00:06:36.800]   They're very potent.
[00:06:36.800 --> 00:06:38.800]   Did you see that footage that they...
[00:06:38.800 --> 00:06:39.800]   Yeah, the guy in his head.
[00:06:39.800 --> 00:06:40.800]   No, no.
[00:06:40.800 --> 00:06:45.800]   This was the Scottish reporter who was down and visiting the drop by.
[00:06:45.800 --> 00:06:48.800]   They got it all armoured up and they were...
[00:06:48.800 --> 00:06:49.800]   No, it's kicking off.
[00:06:49.800 --> 00:06:50.800]   It's kicking off.
[00:06:50.800 --> 00:06:51.800]   It's kicking off.
[00:06:51.800 --> 00:06:52.800]   It's kicking off.
[00:06:52.800 --> 00:06:53.800]   Give it back.
[00:06:53.800 --> 00:06:56.800]   It's just like bloody off.
[00:06:56.800 --> 00:06:57.800]   They're cuddly.
[00:06:57.800 --> 00:06:58.800]   They're so sweet.
[00:06:58.800 --> 00:07:00.800]   Australians are the koalas.
[00:07:00.800 --> 00:07:01.800]   I'm sorry.
[00:07:01.800 --> 00:07:02.800]   Everybody.
[00:07:02.800 --> 00:07:03.800]   Everybody.
[00:07:03.800 --> 00:07:05.800]   Gosh, I don't know where to start here.
[00:07:05.800 --> 00:07:13.800]   We're still trying to get back into the swing of things after the holidays and then CES.
[00:07:13.800 --> 00:07:16.800]   Now it just gets a little calmer, a little quieter.
[00:07:16.800 --> 00:07:19.800]   Time for reflection.
[00:07:19.800 --> 00:07:22.800]   Surprisingly, few cases of CES flew this year.
[00:07:22.800 --> 00:07:26.800]   Usually, everyone comes back with conference cough, but I've only seen a couple of cases
[00:07:26.800 --> 00:07:27.800]   around.
[00:07:27.800 --> 00:07:28.800]   Me too.
[00:07:28.800 --> 00:07:32.800]   At Pruitt did get ill, but it was much later, like a week later, so I think it might have
[00:07:32.800 --> 00:07:33.800]   had another provenance.
[00:07:33.800 --> 00:07:36.800]   Well, California's going to go nuts.
[00:07:36.800 --> 00:07:39.800]   Now we've got our first case of the virus in Los Angeles.
[00:07:39.800 --> 00:07:40.800]   Coronavirus is happening.
[00:07:40.800 --> 00:07:41.800]   Yeah.
[00:07:41.800 --> 00:07:42.800]   That's the new...
[00:07:42.800 --> 00:07:43.800]   Every year there has to be one, right?
[00:07:43.800 --> 00:07:45.800]   Something that we're all freaked out about.
[00:07:45.800 --> 00:07:48.800]   I guess because of international travel, and you guys are a perfect example of this,
[00:07:48.800 --> 00:07:51.800]   stuff does spread faster than ever spread before.
[00:07:51.800 --> 00:07:53.800]   Yeah, but they got a British doctor on the Earth.
[00:07:53.800 --> 00:07:57.800]   Honestly, if you look at the death rates of flu on a really cold winter and you update
[00:07:57.800 --> 00:07:59.800]   them day by day, they look just as scary.
[00:07:59.800 --> 00:08:00.800]   So, you know...
[00:08:00.800 --> 00:08:01.800]   Flu is much more serious.
[00:08:01.800 --> 00:08:02.800]   Get your flu shot.
[00:08:02.800 --> 00:08:04.800]   There's no coronavirus shot, right?
[00:08:04.800 --> 00:08:08.800]   Yeah, that's exactly the thing that's freaking the Chinese government out and others is the
[00:08:08.800 --> 00:08:10.800]   fact that we don't know, we don't understand it.
[00:08:10.800 --> 00:08:12.800]   And it could even mutate between now and the time we see it.
[00:08:12.800 --> 00:08:13.800]   It could be airborne.
[00:08:13.800 --> 00:08:14.800]   They have no idea.
[00:08:14.800 --> 00:08:15.800]   How do you get it?
[00:08:15.800 --> 00:08:16.800]   All of that.
[00:08:16.800 --> 00:08:17.800]   Yeah, yeah.
[00:08:17.800 --> 00:08:20.800]   I choose not to be paranoid.
[00:08:20.800 --> 00:08:22.800]   We're just gonna...
[00:08:22.800 --> 00:08:25.800]   I'll get my mask later.
[00:08:25.800 --> 00:08:27.800]   Let's talk about Jeff Bezos.
[00:08:27.800 --> 00:08:33.800]   This is a really interesting story that has developed over the past week.
[00:08:33.800 --> 00:08:40.800]   Of course, you remember last year, Jeff Bezos, who was at the time married, was busted over
[00:08:40.800 --> 00:08:43.800]   his relationship with Lauren Sanchez, his new girlfriend.
[00:08:43.800 --> 00:08:45.800]   He's gotten divorced since.
[00:08:45.800 --> 00:08:52.120]   And you remember probably the national enquirer attempting to blackmail him with pictures and
[00:08:52.120 --> 00:08:55.240]   texts from his romantic liaison.
[00:08:55.240 --> 00:08:56.560]   And he went very public with it.
[00:08:56.560 --> 00:08:59.920]   Went to Medium, published an article saying, "I will not be blackmailed.
[00:08:59.920 --> 00:09:01.520]   Here's what they're doing.
[00:09:01.520 --> 00:09:02.520]   It was great.
[00:09:02.520 --> 00:09:03.520]   I enjoyed it."
[00:09:03.520 --> 00:09:07.000]   And when you're the richest man in the world, you can do that, right?
[00:09:07.000 --> 00:09:08.480]   That talk about privilege.
[00:09:08.480 --> 00:09:09.480]   You can do that.
[00:09:09.480 --> 00:09:13.160]   Oh, well, again, I mean, not only did it give us some great headlines, which, you know,
[00:09:13.160 --> 00:09:15.560]   that's what the red is about, but it just...
[00:09:15.560 --> 00:09:18.080]   It was that just like, "Yeah, okay.
[00:09:18.080 --> 00:09:20.080]   Publish and be damned.
[00:09:20.080 --> 00:09:21.400]   You want to write this?
[00:09:21.400 --> 00:09:22.680]   I'm not gonna submit to blackmail."
[00:09:22.680 --> 00:09:23.880]   Like, a lot of respect.
[00:09:23.880 --> 00:09:24.880]   Good for him.
[00:09:24.880 --> 00:09:25.880]   Yeah, respect.
[00:09:25.880 --> 00:09:32.840]   Then, at the time, the enquirer said, "We got it from Lauren Sanchez's estranged brother
[00:09:32.840 --> 00:09:36.920]   who got access to her phone and then was able to get the stuff off it and send it to the
[00:09:36.920 --> 00:09:38.520]   national enquirer."
[00:09:38.520 --> 00:09:44.720]   Gavin De Becker, well-known security expert, was hired by Bezos to do an investigation.
[00:09:44.720 --> 00:09:46.880]   That seemed to be the result of the investigation.
[00:09:46.880 --> 00:09:51.040]   And then, all of a sudden, new news came out last week.
[00:09:51.040 --> 00:09:56.560]   A security firm that I'm not familiar with, maybe you are...
[00:09:56.560 --> 00:09:57.560]   Was it RTI?
[00:09:57.560 --> 00:09:58.560]   Was that their name?
[00:09:58.560 --> 00:09:59.560]   FTI.
[00:09:59.560 --> 00:10:00.560]   FTI.
[00:10:00.560 --> 00:10:01.560]   FTI.
[00:10:01.560 --> 00:10:08.480]   FTI did an analysis of Bezos' phone and concluded that he was hacked.
[00:10:08.480 --> 00:10:14.040]   By the Crown Prince of Saudi Arabia, Muhammad bin Salman, MBS, he was apparently in a WhatsApp
[00:10:14.040 --> 00:10:16.000]   conversation with MBS.
[00:10:16.000 --> 00:10:23.680]   At some point in the conversation, MBS sent him a file, which, according to this investigation,
[00:10:23.680 --> 00:10:29.560]   then exfiltrated contents of a Jeff's phone to the Saudi prince, and presumably at that
[00:10:29.560 --> 00:10:33.480]   point passed it along to the national enquirer.
[00:10:33.480 --> 00:10:37.720]   The FTI said, "We medium to high confidence on this."
[00:10:37.720 --> 00:10:44.960]   And a number of security experts, including Matthew Green and Alex Stamos, who used to be
[00:10:44.960 --> 00:10:51.000]   at Tech Security CS CISO, Chief Information Security Officer at Facebook, who owns WhatsApp,
[00:10:51.000 --> 00:10:54.320]   and he said, "This is a little suspect this finding."
[00:10:54.320 --> 00:10:56.840]   And he's been very critical of Facebook, so it's not like he's just...
[00:10:56.840 --> 00:10:59.400]   He's not defending his phone in the company.
[00:10:59.400 --> 00:11:07.160]   So for the news-consuming audience at home, I want to clarify this from a news analysis
[00:11:07.160 --> 00:11:08.160]   perspective.
[00:11:08.160 --> 00:11:15.440]   So what we're talking about, all of this noise around this is based on the claims, the unproven
[00:11:15.440 --> 00:11:20.040]   claims of a single person and theoretically his organization.
[00:11:20.040 --> 00:11:22.040]   You mean FTI?
[00:11:22.040 --> 00:11:23.040]   Yes.
[00:11:23.040 --> 00:11:24.040]   So this is one guy?
[00:11:24.040 --> 00:11:28.640]   To be fair, they did finger the Saudis a couple of months ago with the initial investigation,
[00:11:28.640 --> 00:11:30.120]   and that was from Bezos' own crew.
[00:11:30.120 --> 00:11:31.120]   Yes.
[00:11:31.120 --> 00:11:32.120]   But I take you to central point.
[00:11:32.120 --> 00:11:33.120]   Yes.
[00:11:33.120 --> 00:11:35.600]   Furthermore, we know that WhatsApp is vulnerable to precisely the scale of hacking.
[00:11:35.600 --> 00:11:36.600]   We do.
[00:11:36.600 --> 00:11:39.760]   Even an iPhone and Jeff Bezos said, "Myphone 10 is vulnerable."
[00:11:39.760 --> 00:11:41.640]   So this is not impossible.
[00:11:41.640 --> 00:11:44.440]   The way you do a forensic analysis on something like this is you...
[00:11:44.440 --> 00:11:49.440]   First of all, you have to decrypt the loader and all that stuff, which he didn't do.
[00:11:49.440 --> 00:11:50.720]   The best thing to do is to put it out.
[00:11:50.720 --> 00:11:55.080]   And this was the thing that puzzled Stamos and Green.
[00:11:55.080 --> 00:11:56.080]   Why didn't he?
[00:11:56.080 --> 00:11:57.080]   He's...
[00:11:57.080 --> 00:11:58.080]   Right.
[00:11:58.080 --> 00:11:59.080]   He would be on the device.
[00:11:59.080 --> 00:12:00.080]   Why did they not decrypt the bootloader?
[00:12:00.080 --> 00:12:01.080]   That's right.
[00:12:01.080 --> 00:12:02.080]   See if the evidence of the hacking.
[00:12:02.080 --> 00:12:03.080]   That's right.
[00:12:03.080 --> 00:12:08.240]   The massive amount of...so the story goes that he received this file, he opened the video,
[00:12:08.240 --> 00:12:11.440]   and then suddenly his phone just started pumping data out.
[00:12:11.440 --> 00:12:16.080]   The amount of data that was being pumped out supposedly is less than 500k.
[00:12:16.080 --> 00:12:17.080]   Yes.
[00:12:17.080 --> 00:12:18.080]   So I read...
[00:12:18.080 --> 00:12:20.440]   We think 500 megs in one case and 500k in another.
[00:12:20.440 --> 00:12:21.440]   I don't know.
[00:12:21.440 --> 00:12:22.440]   Tiny.
[00:12:22.440 --> 00:12:26.360]   I'd heard the...his baseline data use was 430...
[00:12:26.360 --> 00:12:27.360]   Exactly.
[00:12:27.360 --> 00:12:30.880]   But after the infection, that jumped up to gigabit levels.
[00:12:30.880 --> 00:12:31.880]   I see.
[00:12:31.880 --> 00:12:32.880]   So the baseline...
[00:12:32.880 --> 00:12:33.880]   So the baseline is even lower than...
[00:12:33.880 --> 00:12:38.000]   Which also sounded really dodgy, because if you're using a mobile phone, you're easily
[00:12:38.000 --> 00:12:40.280]   sending out more than 430.
[00:12:40.280 --> 00:12:43.040]   So that would indicate maybe this wasn't his primary phone.
[00:12:43.040 --> 00:12:45.520]   It was a phone he used just for WhatsApp, perhaps?
[00:12:45.520 --> 00:12:46.520]   Yeah.
[00:12:46.520 --> 00:12:47.520]   Well, okay.
[00:12:47.520 --> 00:12:48.520]   I misread that part.
[00:12:48.520 --> 00:12:53.640]   But the fact is that there's something fishy going on around FTI, because they need to go
[00:12:53.640 --> 00:12:58.920]   to Facebook and/or Apple or somebody else who will do a real analysis and find out what
[00:12:58.920 --> 00:12:59.920]   really happened.
[00:12:59.920 --> 00:13:04.520]   What we think we know is that he sent him a file and then his phone started acting funny.
[00:13:04.520 --> 00:13:05.520]   Yeah.
[00:13:05.520 --> 00:13:08.040]   That doesn't necessarily mean that video file.
[00:13:08.040 --> 00:13:11.680]   They found no trace of malware, which doesn't mean there wasn't malware that didn't erase
[00:13:11.680 --> 00:13:12.680]   it.
[00:13:12.680 --> 00:13:13.680]   Lots of malware erases.
[00:13:13.680 --> 00:13:14.680]   Exactly.
[00:13:14.680 --> 00:13:18.000]   But just from a news analysis point of view, this is entirely based on a claim and that
[00:13:18.000 --> 00:13:20.360]   claim is entirely unproven to date.
[00:13:20.360 --> 00:13:21.880]   And I would love to see it proven.
[00:13:21.880 --> 00:13:22.880]   Yeah.
[00:13:22.880 --> 00:13:24.840]   I mean, because security...
[00:13:24.840 --> 00:13:29.640]   In other words, there's circumstantial evidence, but there's no smoking gun at this point.
[00:13:29.640 --> 00:13:36.360]   Facebook's argument is WhatsApp was not backdoor or was not vulnerable to this.
[00:13:36.360 --> 00:13:40.400]   And on the grounds of it, I would say that's probably correct in that if you're going to
[00:13:40.400 --> 00:13:44.760]   bundle simple malware with something and you're the crown prince of Saudi Arabia, that's
[00:13:44.760 --> 00:13:48.680]   kind of you are going to get it through to the richest man in the world because he takes
[00:13:48.680 --> 00:13:49.960]   your phone calls.
[00:13:49.960 --> 00:13:52.280]   So I don't think it's a flaw in WhatsApp itself.
[00:13:52.280 --> 00:13:54.760]   I think possibly the video file, but again, we need more.
[00:13:54.760 --> 00:13:56.760]   We need evidence that this actually happened.
[00:13:56.760 --> 00:14:01.640]   So one possibility that isn't discussed enough is the possibility that there was no hack,
[00:14:01.640 --> 00:14:03.760]   no malware, nothing.
[00:14:03.760 --> 00:14:05.640]   Right?
[00:14:05.640 --> 00:14:06.640]   We have not seen evidence...
[00:14:06.640 --> 00:14:10.640]   Well, the evidence that it's solely down to his power maul's brother feeding this to
[00:14:10.640 --> 00:14:11.640]   the actual law.
[00:14:11.640 --> 00:14:12.640]   And the timing doesn't fit either.
[00:14:12.640 --> 00:14:14.640]   So there's the problem with the timing of this whole thing.
[00:14:14.640 --> 00:14:15.640]   So why...
[00:14:15.640 --> 00:14:16.640]   So...
[00:14:16.640 --> 00:14:21.000]   And Patrick, just chime in if you have anything you'd like to say.
[00:14:21.000 --> 00:14:24.000]   Why would somebody make this up?
[00:14:24.000 --> 00:14:30.000]   Well, one person who has a motive here is the sister of the girlfriend.
[00:14:30.000 --> 00:14:35.200]   I mean, I'm sorry, the brother of the girlfriend who had been accused of leaking information
[00:14:35.200 --> 00:14:36.200]   about their affairs.
[00:14:36.200 --> 00:14:37.760]   But does he know the FTI folks?
[00:14:37.760 --> 00:14:38.760]   Well, I don't know.
[00:14:38.760 --> 00:14:39.760]   I don't know.
[00:14:39.760 --> 00:14:40.760]   He's a TV producer.
[00:14:40.760 --> 00:14:43.680]   I can't see him having that many sort of context.
[00:14:43.680 --> 00:14:47.280]   There is unfortunately a political undercurrent to this as well.
[00:14:47.280 --> 00:14:55.240]   And the nexus is between Saudi Arabia, the president, the national enquirer and Jeff
[00:14:55.240 --> 00:14:56.240]   Bezos.
[00:14:56.240 --> 00:14:57.240]   And the Washington Post.
[00:14:57.240 --> 00:14:58.240]   And the Post.
[00:14:58.240 --> 00:14:59.240]   And the Post.
[00:14:59.240 --> 00:15:00.240]   And to SOGI.
[00:15:00.240 --> 00:15:01.240]   Yeah.
[00:15:01.240 --> 00:15:02.240]   And to SOGI.
[00:15:02.240 --> 00:15:03.240]   And to SOGI.
[00:15:03.240 --> 00:15:04.240]   In particular.
[00:15:04.240 --> 00:15:05.240]   Yeah.
[00:15:05.240 --> 00:15:08.040]   So we know that the president is not a big fan of Bezos or the Washington Post.
[00:15:08.040 --> 00:15:13.040]   We know that Saudi Arabia is implicated in the murder of Khashoggi, a Washington Post.
[00:15:13.040 --> 00:15:14.800]   I think impolm is going a little bit sooner.
[00:15:14.800 --> 00:15:16.040]   Yeah, we pretty much know they did that.
[00:15:16.040 --> 00:15:17.040]   No axles involved.
[00:15:17.040 --> 00:15:18.040]   Yeah.
[00:15:18.040 --> 00:15:24.040]   We know that Saudi Arabia has a close relationship to President Trump because of military weaponry.
[00:15:24.040 --> 00:15:27.040]   Well, Saudi Arabia is also invested in the national enquirer.
[00:15:27.040 --> 00:15:29.960]   They run a very positive Saudi edition of a few of you.
[00:15:29.960 --> 00:15:33.800]   If you start tearing people with that brush, Saudi Arabia has invested in almost every
[00:15:33.800 --> 00:15:35.400]   Silicon Valley startup we talk about.
[00:15:35.400 --> 00:15:36.400]   This is true.
[00:15:36.400 --> 00:15:38.800]   Because their sovereign fund is a very active venture capital fund.
[00:15:38.800 --> 00:15:40.200]   All of whom hate Amazon.
[00:15:40.200 --> 00:15:41.200]   Oh my God.
[00:15:41.200 --> 00:15:45.800]   So I guess if you're looking for motive, there's multiple possibilities.
[00:15:45.800 --> 00:15:47.800]   It's like knives out.
[00:15:47.800 --> 00:15:49.240]   It's like knives out.
[00:15:49.240 --> 00:15:51.760]   Everybody is suspect.
[00:15:51.760 --> 00:15:54.120]   Don't tell me I haven't seen it.
[00:15:54.120 --> 00:15:55.480]   Well, that's so that's interesting.
[00:15:55.480 --> 00:15:57.760]   Do you have a thought about this, Patrick?
[00:15:57.760 --> 00:16:00.600]   Well, the it sounds outlandish.
[00:16:00.600 --> 00:16:01.600]   It's out outrageous.
[00:16:01.600 --> 00:16:04.720]   It sells copies of the newspaper because it's great.
[00:16:04.720 --> 00:16:07.000]   The press conference of Saudi Arabia.
[00:16:07.000 --> 00:16:10.200]   Hack the world's richest man is a great story.
[00:16:10.200 --> 00:16:15.160]   But the thing the thing that is really surprising is that the case you know that you just laid
[00:16:15.160 --> 00:16:21.280]   out, which is the case that everyone is laying out, does make it make sense.
[00:16:21.280 --> 00:16:32.320]   It could actually be a motive for of course the secret service of Saudi Arabia to go to
[00:16:32.320 --> 00:16:37.360]   MBS and tell him, hey, if you want this done, maybe we can do it like this and he might
[00:16:37.360 --> 00:16:38.360]   agree.
[00:16:38.360 --> 00:16:44.640]   It wouldn't seem completely outlandish that that would actually take place.
[00:16:44.640 --> 00:16:52.320]   Which is why this story kind of has legs with all of the caveats we need to apply.
[00:16:52.320 --> 00:16:54.920]   Yeah, it could make sense.
[00:16:54.920 --> 00:16:59.200]   And it's so outlandish that it shouldn't, but it kind of does.
[00:16:59.200 --> 00:17:01.720]   So I guess that's the world we live in.
[00:17:01.720 --> 00:17:06.360]   We live in unfortunately a post fact world where it's very difficult to get to the truth
[00:17:06.360 --> 00:17:11.720]   of anything anymore, which is precisely why we need a real forensic analysis.
[00:17:11.720 --> 00:17:17.400]   The evidence is sitting there on somebody's desk and everybody's speculating and on these
[00:17:17.400 --> 00:17:18.400]   fields.
[00:17:18.400 --> 00:17:19.880]   Why would we care?
[00:17:19.880 --> 00:17:23.240]   Somebody in the chat from saying it's just another, it's just a rich guy being hacked.
[00:17:23.240 --> 00:17:24.240]   Why would we care?
[00:17:24.240 --> 00:17:25.960]   No, wait, no.
[00:17:25.960 --> 00:17:26.960]   What?
[00:17:26.960 --> 00:17:28.480]   No.
[00:17:28.480 --> 00:17:34.760]   This is an attempt to manipulate one of the richest people in the world.
[00:17:34.760 --> 00:17:38.440]   And so that means one of the people who has the most power in the world.
[00:17:38.440 --> 00:17:43.440]   Of course, there more owns a newspaper that is currently at odds with the president of
[00:17:43.440 --> 00:17:45.240]   the United States.
[00:17:45.240 --> 00:17:47.920]   Yes, obviously we care.
[00:17:47.920 --> 00:17:49.480]   This is why it's a big story.
[00:17:49.480 --> 00:17:51.920]   Yeah, I mean, the fact that they were.
[00:17:51.920 --> 00:17:56.280]   Okay, for me, the thing that got this was if this was going to work, then the crown prince
[00:17:56.280 --> 00:17:59.280]   of Saudi Arabia must be sending out malware.
[00:17:59.280 --> 00:18:03.400]   Now we haven't worked out who it's from NSO groups being mentioned, gamma groups being
[00:18:03.400 --> 00:18:09.280]   mentioned as a whole bunch of companies who will cheerfully sell to governments decent
[00:18:09.280 --> 00:18:13.280]   quality malware capable of getting through most mobile phones.
[00:18:13.280 --> 00:18:15.920]   But it's just, yeah, a bloke gets hacked.
[00:18:15.920 --> 00:18:17.480]   But why are they doing this?
[00:18:17.480 --> 00:18:22.040]   And the fact that Bezos went so public with it, you know, he's definitely not going to
[00:18:22.040 --> 00:18:24.040]   lay down and take this one.
[00:18:24.040 --> 00:18:30.880]   So why doesn't Bezos confirm or deny or his team confirm or deny that report?
[00:18:30.880 --> 00:18:35.840]   Well, it's the same old problem that you get with any computer computer intrusion problem
[00:18:35.840 --> 00:18:39.280]   in that there is never any concrete proof.
[00:18:39.280 --> 00:18:42.720]   Yes, this definitely came from, you know, from here or from there.
[00:18:42.720 --> 00:18:47.160]   I'm still hearing people saying with very little proof that, oh, the North Koreans are
[00:18:47.160 --> 00:18:48.240]   responsible for this.
[00:18:48.240 --> 00:18:52.200]   So the minute you hear advanced persistent threat, you know, that's basically an excuse
[00:18:52.200 --> 00:18:55.720]   for a security company saying our code didn't work.
[00:18:55.720 --> 00:18:58.240]   And this is now being applied to the highest echelons of government.
[00:18:58.240 --> 00:19:00.680]   And that's why we should be concerned.
[00:19:00.680 --> 00:19:03.560]   The report, okay, you want to add more conspiracy?
[00:19:03.560 --> 00:19:06.000]   This is just made for conspiracy theories.
[00:19:06.000 --> 00:19:08.800]   FTI consulting is Anthony J. Ferranti.
[00:19:08.800 --> 00:19:14.440]   He's a former FBI investigator who also worked on the hack of the Democratic National Committee
[00:19:14.440 --> 00:19:18.440]   in 2016 by the Russian nation state of Obama.
[00:19:18.440 --> 00:19:20.880]   He investigated on the side of Obama.
[00:19:20.880 --> 00:19:23.920]   He wasn't involved in the hack.
[00:19:23.920 --> 00:19:32.480]   Just to give the facts, according to the report from FTI, they couldn't figure and they couldn't
[00:19:32.480 --> 00:19:40.040]   find any malware, but they were able to find what looked to be a video of telecommunications
[00:19:40.040 --> 00:19:44.760]   video that had been sent to Jeff Bezos with an encrypted downloader.
[00:19:44.760 --> 00:19:49.680]   The file shows an image of the Saudi flag and Swedish flags arrived with an encrypted
[00:19:49.680 --> 00:19:54.240]   downloader.
[00:19:54.240 --> 00:19:59.000]   Decided that it was suspicious only because immediately after receiving within hours of
[00:19:59.000 --> 00:20:05.720]   receiving the encrypted downloader, the amount of data being sent from the phone leaped from
[00:20:05.720 --> 00:20:12.400]   430k, as you mentioned, to 126 megabytes and then maintained an unusually high average
[00:20:12.400 --> 00:20:17.960]   of 100 megabytes of egress of data a day for another month, including many massive and
[00:20:17.960 --> 00:20:21.360]   highly atypical spikes of egress data.
[00:20:21.360 --> 00:20:22.560]   That's why it's circumstantial.
[00:20:22.560 --> 00:20:26.320]   The phone started behaving differently after receiving this video.
[00:20:26.320 --> 00:20:28.560]   We couldn't find anything wrong with the video.
[00:20:28.560 --> 00:20:33.200]   We couldn't find a malware, but there's this evidence that the phone started to do something.
[00:20:33.200 --> 00:20:35.640]   Of course, there's many ways you could explain that.
[00:20:35.640 --> 00:20:37.840]   Maybe Jeff just decided to start using that phone more.
[00:20:37.840 --> 00:20:40.480]   We don't know.
[00:20:40.480 --> 00:20:41.480]   You're right.
[00:20:41.480 --> 00:20:46.480]   That's why Gavin De Becker and Jeff Bezos need to get in on the way.
[00:20:46.480 --> 00:20:52.800]   I'm sure if he started to use the phone more enough to justify this, he would have said,
[00:20:52.800 --> 00:20:53.800]   "No, no, no."
[00:20:53.800 --> 00:20:54.800]   I just started watching porn.
[00:20:54.800 --> 00:21:01.720]   By the way, FTI got the phone because it was given, I presume, given to them.
[00:21:01.720 --> 00:21:05.280]   De Becker is actually a good security guy.
[00:21:05.280 --> 00:21:08.640]   From what I've seen of his past work, he knows what he's talking about, but he's also
[00:21:08.640 --> 00:21:10.600]   paid by Jeff Bezos.
[00:21:10.600 --> 00:21:15.960]   You have to include that into your calculations as to whether or not this is true.
[00:21:15.960 --> 00:21:21.120]   I don't think they'd be making the accusation unless they had some fairly solid claims.
[00:21:21.120 --> 00:21:24.880]   I'm seeing a few people rob Graham at the infra-set.
[00:21:24.880 --> 00:21:26.560]   He's a professional contrarian.
[00:21:26.560 --> 00:21:30.400]   He's coming out against this, but some of the stuff he's coming up with sounds, there
[00:21:30.400 --> 00:21:34.160]   are questions to be raised over this.
[00:21:34.160 --> 00:21:36.120]   There are two black boxes, actually.
[00:21:36.120 --> 00:21:39.640]   One of them is the phone itself and the evidence that it contains that nobody's getting at.
[00:21:39.640 --> 00:21:42.960]   The second one is the palace intrigue of the Saudi government.
[00:21:42.960 --> 00:21:52.040]   We really don't know the idea that the Crown Prince himself, he's a bloodthirsty evil murderer,
[00:21:52.040 --> 00:21:54.240]   but he's not stupid.
[00:21:54.240 --> 00:21:56.200]   For him to directly send malware, so that's far better.
[00:21:56.200 --> 00:21:58.600]   It's been really nice knowing you might appreciate it.
[00:21:58.600 --> 00:21:59.600]   Fatwa!
[00:21:59.600 --> 00:22:04.360]   You don't know if there's other machinations going on.
[00:22:04.360 --> 00:22:05.920]   You don't know if you'd like this phone.
[00:22:05.920 --> 00:22:08.240]   It feels like it's far too complicated for us to untangle.
[00:22:08.240 --> 00:22:10.240]   You see, I, for one, welcome our Saudi overlords.
[00:22:10.240 --> 00:22:13.520]   I'd like to tell you how I could be in great help in the future.
[00:22:13.520 --> 00:22:17.280]   By the way, FTI kind of bungled this because during the initial attempt to collect the
[00:22:17.280 --> 00:22:23.520]   forensic information, FTI determined that Dyson and iTunes backup encryption enabled.
[00:22:23.520 --> 00:22:24.520]   Good.
[00:22:24.520 --> 00:22:25.520]   That's what you should do.
[00:22:25.520 --> 00:22:30.320]   The full analysis of the content would require the encryption password.
[00:22:30.320 --> 00:22:37.040]   Apparently, Bezos or whoever backed it up never gave them that password because then
[00:22:37.040 --> 00:22:41.040]   the investigators, quote, "tested options for bypassing the password encryption.
[00:22:41.040 --> 00:22:42.960]   We don't know of a way to do that."
[00:22:42.960 --> 00:22:49.000]   And ended up resetting all settings on the iPhone X to factory default, thereby removing
[00:22:49.000 --> 00:22:53.440]   any encryption password while preserving the file system and relevant data.
[00:22:53.440 --> 00:22:54.440]   So...
[00:22:54.440 --> 00:22:56.960]   Which itself is a little suspicious, I think.
[00:22:56.960 --> 00:22:57.960]   The whole thing is a mess.
[00:22:57.960 --> 00:22:59.440]   I don't like any of it.
[00:22:59.440 --> 00:23:04.360]   And everybody involved has a hidden agenda or less hidden agenda.
[00:23:04.360 --> 00:23:11.640]   For instance, Bezos might be under pressure from his new girlfriend to exonerate her
[00:23:11.640 --> 00:23:13.360]   brother.
[00:23:13.360 --> 00:23:15.320]   And who the hell knows?
[00:23:15.320 --> 00:23:16.720]   We do care because I don't...
[00:23:16.720 --> 00:23:17.720]   I think this is a...
[00:23:17.720 --> 00:23:18.720]   You're right.
[00:23:18.720 --> 00:23:21.720]   You made a good case, Patrick, for caring, but I don't know if we'll ever know.
[00:23:21.720 --> 00:23:25.960]   This is just one more thing we won't know until they write the book in 20 years.
[00:23:25.960 --> 00:23:29.160]   Well, it kind of reminds me of the whole North Korea hacking so many things.
[00:23:29.160 --> 00:23:31.000]   I'm still deeply suspicious about that.
[00:23:31.000 --> 00:23:32.200]   Who really did that happen?
[00:23:32.200 --> 00:23:33.200]   Yeah, exactly.
[00:23:33.200 --> 00:23:36.360]   With this case, the timing doesn't match up.
[00:23:36.360 --> 00:23:38.520]   Oh, they hacked it to stop the North Korean film.
[00:23:38.520 --> 00:23:42.720]   Well, no, they were active for two weeks before and then seemed to hang on to this.
[00:23:42.720 --> 00:23:45.120]   Yeah, and who really has a motive to do that?
[00:23:45.120 --> 00:23:46.560]   I think Disney comes up.
[00:23:46.560 --> 00:23:47.560]   Well, no, I mean...
[00:23:47.560 --> 00:23:49.560]   Well, no, actually, I've got...
[00:23:49.560 --> 00:23:52.560]   So, wait a minute, you've got the Kingdom and Disney now, Matt.
[00:23:52.560 --> 00:23:53.560]   You're going to be...
[00:23:53.560 --> 00:23:58.360]   You've seen a contest where some knowledge has gone on and they're saying the most likely
[00:23:58.360 --> 00:24:01.520]   scenario that they first thought, well, this is a rival investor who's trying to bring
[00:24:01.520 --> 00:24:06.160]   down this top price because they're aiming to sort of get rid of the board at Sony.
[00:24:06.160 --> 00:24:10.360]   Do you feel like that going forward over the next five years, nothing but chaos will
[00:24:10.360 --> 00:24:14.520]   emerge and we'll completely lose the threat of every...
[00:24:14.520 --> 00:24:17.360]   Five, I think 50.
[00:24:17.360 --> 00:24:23.560]   I just feel like this is the beginning of a post-truth era where anything goes and no
[00:24:23.560 --> 00:24:24.560]   one will know what's going on.
[00:24:24.560 --> 00:24:25.920]   We're in information shock at the moment.
[00:24:25.920 --> 00:24:26.920]   When you think about...
[00:24:26.920 --> 00:24:27.920]   We have too much information.
[00:24:27.920 --> 00:24:32.640]   When you think about to... For all of human history up until the invention of the railways
[00:24:32.640 --> 00:24:37.360]   and the telegraph, the internet was a guy on a horse and that was the fastest way you
[00:24:37.360 --> 00:24:39.760]   could get your data.
[00:24:39.760 --> 00:24:44.640]   And then in the last 200 years, we've just gone from that to just getting it from a
[00:24:44.640 --> 00:24:48.880]   few newspapers to TVs and newspapers and now the internet.
[00:24:48.880 --> 00:24:53.440]   And there is some very interesting psychological research saying that human beings cannot handle
[00:24:53.440 --> 00:24:54.760]   that level of information.
[00:24:54.760 --> 00:24:56.640]   And intuitively, I disagree with that.
[00:24:56.640 --> 00:24:59.080]   I think we need to evolve the way we think about things.
[00:24:59.080 --> 00:25:03.840]   And one of those things is we need to embrace the power of ignorance, Leo.
[00:25:03.840 --> 00:25:04.840]   So what I...
[00:25:04.840 --> 00:25:05.840]   Here's what I mean by that.
[00:25:05.840 --> 00:25:07.120]   What is the power of ignorance?
[00:25:07.120 --> 00:25:10.920]   So people are walking around after reading all these stories and in their minds they're
[00:25:10.920 --> 00:25:15.040]   thinking, "Oh, the Saudi crown pens hacked Bezos and tried to blackmail him."
[00:25:15.040 --> 00:25:16.040]   I think that's what happened.
[00:25:16.040 --> 00:25:17.040]   Yeah.
[00:25:17.040 --> 00:25:21.320]   That's probably what you would conclude given what mainstream reporting has said.
[00:25:21.320 --> 00:25:22.320]   Exactly.
[00:25:22.320 --> 00:25:25.200]   There's no reason to conclude that other than lazy thinking.
[00:25:25.200 --> 00:25:30.560]   What we should be walking around saying is, "These people claimed X.
[00:25:30.560 --> 00:25:32.440]   Somebody else claimed Y.
[00:25:32.440 --> 00:25:36.000]   We don't have the facts to really know which is true, but I know that they claimed this
[00:25:36.000 --> 00:25:37.000]   and they claimed that."
[00:25:37.000 --> 00:25:39.360]   End of story, I am ignorant about what actually happened.
[00:25:39.360 --> 00:25:40.360]   That's what I just did.
[00:25:40.360 --> 00:25:41.360]   That's what we just did.
[00:25:41.360 --> 00:25:43.320]   That is comfortable with the ignorance.
[00:25:43.320 --> 00:25:44.320]   And get comfortable with that.
[00:25:44.320 --> 00:25:46.080]   That's really dangerous though.
[00:25:46.080 --> 00:25:48.800]   And I don't know that there's a way out of it.
[00:25:48.800 --> 00:25:55.040]   But that is the logical conclusion that most reasonable people should get to in most cases
[00:25:55.040 --> 00:25:56.280]   on almost anything.
[00:25:56.280 --> 00:26:00.120]   If you ask me if there's a God, that's my response.
[00:26:00.120 --> 00:26:03.080]   No, but there's lots of conistricting evidence.
[00:26:03.080 --> 00:26:04.480]   I don't know.
[00:26:04.480 --> 00:26:10.600]   Unless you're talking about a couple of topics on which we're pretty certain, like, you know,
[00:26:10.600 --> 00:26:14.120]   the planet round and is a climate change happening.
[00:26:14.120 --> 00:26:15.120]   Yeah.
[00:26:15.120 --> 00:26:16.120]   Right?
[00:26:16.120 --> 00:26:17.120]   Both of those we probably know.
[00:26:17.120 --> 00:26:21.280]   Because I'm doing a little bit of an overexaggeration.
[00:26:21.280 --> 00:26:27.600]   But the problem when you get to that is that way of thinking that you're describing, Mike,
[00:26:27.600 --> 00:26:33.160]   which I think, again, it's very reasonable, is that it's very easy then for anyone to
[00:26:33.160 --> 00:26:36.320]   claim the opposite of what someone else is claiming.
[00:26:36.320 --> 00:26:42.880]   And most people who see arguments that seem reasonable presented to them are going to
[00:26:42.880 --> 00:26:43.880]   go, "I'm excited."
[00:26:43.880 --> 00:26:45.840]   Yes, I don't know.
[00:26:45.840 --> 00:26:48.680]   But how can I sort it out?
[00:26:48.680 --> 00:26:54.960]   But the lunging to a belief about something based on fragmentary information is a cognitive
[00:26:54.960 --> 00:26:55.960]   bias.
[00:26:55.960 --> 00:26:57.600]   It's a flaw in the human software.
[00:26:57.600 --> 00:26:58.600]   Isn't that all?
[00:26:58.600 --> 00:27:00.120]   We do all the time.
[00:27:00.120 --> 00:27:01.120]   Yes.
[00:27:01.120 --> 00:27:02.800]   No, but I should go ahead.
[00:27:02.800 --> 00:27:10.880]   We shouldn't, but, but if you go just one step further, then that's what post-truth makes
[00:27:10.880 --> 00:27:11.880]   happen.
[00:27:11.880 --> 00:27:12.880]   Yeah.
[00:27:12.880 --> 00:27:17.600]   There's so much information, it's so much conflicting quote unquote facts that most
[00:27:17.600 --> 00:27:19.560]   people just, you don't know.
[00:27:19.560 --> 00:27:20.560]   It happens all the time.
[00:27:20.560 --> 00:27:21.560]   Okay.
[00:27:21.560 --> 00:27:23.120]   There's a difference between everywhere else.
[00:27:23.120 --> 00:27:24.120]   There's a difference between...
[00:27:24.120 --> 00:27:26.120]   You can't be sure, so you just don't believe anything.
[00:27:26.120 --> 00:27:27.120]   Right.
[00:27:27.120 --> 00:27:30.960]   But there's a difference between clarifying, being clear in your own mind about what you
[00:27:30.960 --> 00:27:38.080]   know and what you, what somebody is claiming is true and somebody reported is true, and
[00:27:38.080 --> 00:27:40.160]   just having an equivalence about everything.
[00:27:40.160 --> 00:27:47.980]   If Breitbart reports A and the Wall Street Journal reports B, I'm gonna give it to Wall
[00:27:47.980 --> 00:27:49.980]   Street Journal until...
[00:27:49.980 --> 00:27:52.560]   But what you're saying is you should have some buckets.
[00:27:52.560 --> 00:27:54.920]   You shouldn't, there isn't just true or false.
[00:27:54.920 --> 00:27:56.080]   There are more buckets.
[00:27:56.080 --> 00:27:57.080]   Yeah.
[00:27:57.080 --> 00:28:00.280]   With I have some information, I'm leaning this way, I have no information, no one can
[00:28:00.280 --> 00:28:01.280]   know.
[00:28:01.280 --> 00:28:04.200]   I definitely know this is true, I definitely know this is false.
[00:28:04.200 --> 00:28:08.440]   You need more, you need to be more flexible in how you hold things.
[00:28:08.440 --> 00:28:11.240]   You have to cultivate an intuition about the probability of things.
[00:28:11.240 --> 00:28:12.240]   But intuition is not too risky.
[00:28:12.240 --> 00:28:15.080]   If somebody reports something, I think it will last 99%, I'm pretty sure that...
[00:28:15.080 --> 00:28:18.040]   Yeah, but intuition, look, we trusted the New York Times for years, I don't know if that
[00:28:18.040 --> 00:28:19.040]   was...
[00:28:19.040 --> 00:28:21.040]   PC, maybe there's a better situation.
[00:28:21.040 --> 00:28:25.040]   I don't know if you have it in this country, but in the UK when I was growing up, an A-level
[00:28:25.040 --> 00:28:30.280]   course was taken from 16 to 18 year olds called Media Studies, where you focused on the
[00:28:30.280 --> 00:28:36.040]   media, how they're portraying certain things, how that imagery is used, that sort of thing.
[00:28:36.040 --> 00:28:38.440]   And that was tremendously useful.
[00:28:38.440 --> 00:28:43.000]   And before you read any information source, you've got to ask yourself, who wrote it,
[00:28:43.000 --> 00:28:45.960]   why did they write it, who paid for it to be written.
[00:28:45.960 --> 00:28:49.960]   And if only by applying critical thinking to the thing, are we going to get out of this
[00:28:49.960 --> 00:28:50.960]   mess?
[00:28:50.960 --> 00:28:55.080]   Or I just do what Joe Rogan says and leave it at that, because honestly that seems like
[00:28:55.080 --> 00:28:56.080]   the best pass.
[00:28:56.080 --> 00:29:00.080]   Yeah, the hallmark of the wise decisions, Joe Rogan.
[00:29:00.080 --> 00:29:07.680]   The problem is it's really valuable and important for us on a podcast when we're talking about
[00:29:07.680 --> 00:29:14.400]   the tech topic that we really know a lot about, because that's our jobs, to say everything
[00:29:14.400 --> 00:29:15.400]   we're saying.
[00:29:15.400 --> 00:29:16.400]   And that's why we brought it up.
[00:29:16.400 --> 00:29:17.400]   That's exactly what I brought it up.
[00:29:17.400 --> 00:29:22.720]   Because we presumably have the expertise to evaluate these assertions.
[00:29:22.720 --> 00:29:27.840]   And I'm actually, I'm playing a little bit of devil's advocate, because I agree with you.
[00:29:27.840 --> 00:29:33.440]   But even us on this were baffled and we're not sure where to land.
[00:29:33.440 --> 00:29:39.240]   Imagine what regular people, about the myriad of topics, have to, no one has time to actually
[00:29:39.240 --> 00:29:46.560]   go and investigate and think about and decide how they feel about the story where they're
[00:29:46.560 --> 00:29:52.440]   getting, of course, if it's something that is easy to determine, and maybe for some people
[00:29:52.440 --> 00:29:56.520]   it's going to be Breitbart versus someone else.
[00:29:56.520 --> 00:30:03.320]   But there are also many, many different topics that are covered from different sides.
[00:30:03.320 --> 00:30:11.640]   On one media, it's not as the lab situation.
[00:30:11.640 --> 00:30:16.360]   I think a little bit what you're describing, Mike, is the lab situation where the parameters
[00:30:16.360 --> 00:30:17.840]   are ideal.
[00:30:17.840 --> 00:30:23.320]   In real life, people have jobs and food to cook and they don't have time to do it.
[00:30:23.320 --> 00:30:26.040]   And in fact, that's what these people used to go.
[00:30:26.040 --> 00:30:28.200]   I wash my hands of it.
[00:30:28.200 --> 00:30:30.160]   And I'm just going to go make dinner.
[00:30:30.160 --> 00:30:31.160]   But this is one of the many areas.
[00:30:31.160 --> 00:30:33.480]   And this is incredibly dangerous because this is what's happening.
[00:30:33.480 --> 00:30:34.480]   That's what's happening.
[00:30:34.480 --> 00:30:37.400]   Politicians are trying to, are using more and more.
[00:30:37.400 --> 00:30:42.400]   It's like just flawed everyone with information, contradictory information doesn't matter,
[00:30:42.400 --> 00:30:44.800]   because at some point you don't know, so you just give up.
[00:30:44.800 --> 00:30:48.400]   You want them to give up because then you have a free hand to do whatever you want.
[00:30:48.400 --> 00:30:49.400]   That's the Russian model.
[00:30:49.400 --> 00:30:50.400]   Yeah, exactly.
[00:30:50.400 --> 00:30:52.800]   The KGB developed that in the 20th century.
[00:30:52.800 --> 00:30:55.640]   But this is one of the several areas that exist.
[00:30:55.640 --> 00:30:58.560]   We don't talk enough about this, where we had the solution and then we abandoned it
[00:30:58.560 --> 00:30:59.800]   en masse.
[00:30:59.800 --> 00:31:05.840]   The solution was you find curators you trust, i.e. editors for publications that you trust.
[00:31:05.840 --> 00:31:08.520]   So you read the New York Times for a few years and after a while you're like, "You know what?
[00:31:08.520 --> 00:31:10.480]   I've been led astray too many times.
[00:31:10.480 --> 00:31:14.320]   I'm switching from the New York Times to this other paper that I trust."
[00:31:14.320 --> 00:31:15.800]   You trust those editors.
[00:31:15.800 --> 00:31:19.560]   If you really pay attention to a single publication, it's not just whatever comes across your
[00:31:19.560 --> 00:31:20.560]   feed.
[00:31:20.560 --> 00:31:25.120]   You're getting a balanced diet and you're getting follow-ups and corrections and revisions.
[00:31:25.120 --> 00:31:28.040]   It's an ongoing thing week after week, month after month.
[00:31:28.040 --> 00:31:32.480]   We just abandoned that en masse and now we just respond to like rats and some kind of
[00:31:32.480 --> 00:31:36.080]   weird experiment to whatever the algorithms throw in our face.
[00:31:36.080 --> 00:31:40.600]   We get this unbalanced diet that favors emotion and outrage.
[00:31:40.600 --> 00:31:46.200]   Is it because we live in a world with the internet and social media and so many inputs,
[00:31:46.200 --> 00:31:48.720]   24-hour news channels?
[00:31:48.720 --> 00:31:52.760]   I think maybe the most healthful thing you could do is move to Finland.
[00:31:52.760 --> 00:31:53.760]   Move the Finland.
[00:31:53.760 --> 00:31:55.840]   No, but cancel your internet.
[00:31:55.840 --> 00:32:03.840]   I just read an article by a guy who says, "I no longer read daily news, watch social
[00:32:03.840 --> 00:32:04.840]   media.
[00:32:04.840 --> 00:32:05.840]   I don't do Twitter.
[00:32:05.840 --> 00:32:06.840]   I don't do Facebook.
[00:32:06.840 --> 00:32:15.160]   I believe that a good idea will surface over a longer period of time."
[00:32:15.160 --> 00:32:21.360]   Anything that is such a short time frame is by definition unreliable and more importantly,
[00:32:21.360 --> 00:32:25.240]   overweights the importance of the day of the moment.
[00:32:25.240 --> 00:32:29.880]   Anything really important is going to have a longer lifespan.
[00:32:29.880 --> 00:32:30.880]   How about that?
[00:32:30.880 --> 00:32:31.880]   Is that a good method?
[00:32:31.880 --> 00:32:34.960]   I say that, but look at how the Panama Papers got buried.
[00:32:34.960 --> 00:32:36.760]   Look how Snowden leaks got buried.
[00:32:36.760 --> 00:32:41.200]   These things were life changing.
[00:32:41.200 --> 00:32:47.000]   The Panama Papers, how our own rulers are avoiding their own taxes, the Snowden leaks
[00:32:47.000 --> 00:32:49.800]   how we're being spied on in a way.
[00:32:49.800 --> 00:32:51.160]   Those really matter, though.
[00:32:51.160 --> 00:32:53.200]   They will survive and they'll be snowed.
[00:32:53.200 --> 00:32:54.960]   No, but the Snowden did, I think.
[00:32:54.960 --> 00:32:56.960]   The judges Snowden did have an effect.
[00:32:56.960 --> 00:33:01.920]   It had an effect in the US to the fact that they basically legalized all the behavior
[00:33:01.920 --> 00:33:05.760]   being going on before in the same way in the UK and the same in Australia.
[00:33:05.760 --> 00:33:16.520]   For us, it might not have changed a lot, but I think the regular people now understand
[00:33:16.520 --> 00:33:21.120]   that privacy is a thing which they didn't before.
[00:33:21.120 --> 00:33:26.720]   They might not care about it as much as we would like them to, but I think they do understand
[00:33:26.720 --> 00:33:31.640]   that this is something maybe we should be paying attention to.
[00:33:31.640 --> 00:33:34.360]   That is Snowden, which had that effect.
[00:33:34.360 --> 00:33:41.240]   I think Snowden did change some things, not enough, but Panama Papers, I'm not sure.
[00:33:41.240 --> 00:33:45.880]   But supporting your point, Leo, if you read the Atlantic Monthly and the New Yorker and
[00:33:45.880 --> 00:33:50.200]   if you want a conservative voice, maybe the National Review and a few other publications,
[00:33:50.200 --> 00:33:55.320]   you would get a lot of really contextualized information about Snowden, about all these
[00:33:55.320 --> 00:33:56.520]   different things.
[00:33:56.520 --> 00:34:01.360]   The problem is that we're hardwired for that digital crack of all the people that we
[00:34:01.360 --> 00:34:02.360]   want that hit.
[00:34:02.360 --> 00:34:03.360]   We do.
[00:34:03.360 --> 00:34:04.360]   This is the problem.
[00:34:04.360 --> 00:34:09.400]   This is what's being exploited in our nature, is our need to see what's happening right
[00:34:09.400 --> 00:34:11.840]   now and to sort of keep on.
[00:34:11.840 --> 00:34:15.720]   You get sucked into these arguments and it just, you know, we're hardwired.
[00:34:15.720 --> 00:34:17.320]   There's a journalist like it.
[00:34:17.320 --> 00:34:19.120]   Sorry, I'll have to ask you.
[00:34:19.120 --> 00:34:20.720]   Oh, well, you're too kind.
[00:34:20.720 --> 00:34:22.920]   Thank you, good sir.
[00:34:22.920 --> 00:34:30.600]   I just wanted to say it's difficult to evaluate the effect it's going to have on us as humans
[00:34:30.600 --> 00:34:32.360]   and on society.
[00:34:32.360 --> 00:34:39.680]   I wonder if we shouldn't, I don't know that we should wait, but the real effect is going
[00:34:39.680 --> 00:34:45.040]   to be understood in a generation or maybe two.
[00:34:45.040 --> 00:34:50.600]   It might be very difficult until then, but I wonder how the kids who grew up with this
[00:34:50.600 --> 00:34:53.360]   react about all of it.
[00:34:53.360 --> 00:34:59.320]   And more importantly, even how will they approach it when they are in a stage of life
[00:34:59.320 --> 00:35:04.080]   where it matters when they're 25, 30, 35, even more.
[00:35:04.080 --> 00:35:09.080]   And that guy, I wonder if we're too old for it anyway, and we're reacting to it with the
[00:35:09.080 --> 00:35:14.120]   mindset of the previous before that paradigm shift, shift existed.
[00:35:14.120 --> 00:35:19.480]   So we're panicking just the way maybe someone who lived before electricity then doesn't
[00:35:19.480 --> 00:35:22.800]   understand the world anymore because everything's so fast and every, you know, that kind of
[00:35:22.800 --> 00:35:23.800]   thing.
[00:35:23.800 --> 00:35:28.080]   So there's hope because we're not evolved to handle this modern world.
[00:35:28.080 --> 00:35:30.720]   The young people will and they will accept.
[00:35:30.720 --> 00:35:32.120]   The TikTok crowd.
[00:35:32.120 --> 00:35:33.360]   They'll just be comfortable.
[00:35:33.360 --> 00:35:39.200]   They're going to be comfortable with it, but will they be better informed?
[00:35:39.200 --> 00:35:41.400]   Well, they're the rub.
[00:35:41.400 --> 00:35:43.840]   The TikTok users are so well informed.
[00:35:43.840 --> 00:35:51.040]   Maybe they'll understand that a tweet is just a tweet, you know, like Mike was saying,
[00:35:51.040 --> 00:35:57.080]   maybe they'll understand that this is just the instant reaction that people are going
[00:35:57.080 --> 00:36:01.440]   for and they won't fall for it.
[00:36:01.440 --> 00:36:03.600]   It's a really interesting question.
[00:36:03.600 --> 00:36:06.640]   And it's a world that we're headed to at full speed.
[00:36:06.640 --> 00:36:11.720]   So I hope, I do hope young people will develop some sort of organ in their brain that lets
[00:36:11.720 --> 00:36:16.520]   them handle it better than those of us who've grown up without it.
[00:36:16.520 --> 00:36:19.880]   The important thing is that you realize that it's a dangerous world out there.
[00:36:19.880 --> 00:36:23.120]   There's a lot of hacking and you have to manage your passwords.
[00:36:23.120 --> 00:36:26.480]   Well, he's trying to set it up in a hat.
[00:36:26.480 --> 00:36:27.480]   You are so good, Mike.
[00:36:27.480 --> 00:36:28.560]   All right, let's take a break.
[00:36:28.560 --> 00:36:31.760]   We'll come back after we teach you how to manage your passwords.
[00:36:31.760 --> 00:36:33.880]   I think this is a great, fascinating discussion.
[00:36:33.880 --> 00:36:35.240]   It's been on my mind lately.
[00:36:35.240 --> 00:36:37.600]   I wish I could remember the article that I read about this guy.
[00:36:37.600 --> 00:36:39.920]   He said, you know what, you got to go to news and social media.
[00:36:39.920 --> 00:36:43.320]   He called it, there was the pushkin effect or something, there's some effect.
[00:36:43.320 --> 00:36:49.360]   And he said, and you should really just evaluate something by how long it's survived and the
[00:36:49.360 --> 00:36:54.360]   stuff, the more ephemeral, which is of course news, social media, the more ephemeral something
[00:36:54.360 --> 00:36:58.520]   is, the less you can judge its value, the less valuable probably is.
[00:36:58.520 --> 00:37:02.200]   But if it survives, for instance, the Snowden effect has survived.
[00:37:02.200 --> 00:37:03.840]   And so we know that that was important.
[00:37:03.840 --> 00:37:04.840]   I think we'll see.
[00:37:04.840 --> 00:37:07.800]   The Panama Papers is to be determined.
[00:37:07.800 --> 00:37:12.880]   But I think that that's not a bad, the problem, the big mistake would be to give up, to say,
[00:37:12.880 --> 00:37:18.240]   I give up, I can't, truth is not determinable because there's so much noise now.
[00:37:18.240 --> 00:37:23.520]   Everything is so fuzzy, I just give up, I'm going to go make dinner and watch our concerns.
[00:37:23.520 --> 00:37:24.960]   And I'm trying to weed it.
[00:37:24.960 --> 00:37:25.960]   It's hard not to.
[00:37:25.960 --> 00:37:26.960]   Yeah.
[00:37:26.960 --> 00:37:27.960]   It's hard not to.
[00:37:27.960 --> 00:37:28.960]   That's a natural result.
[00:37:28.960 --> 00:37:30.480]   It's like really they don't all lie.
[00:37:30.480 --> 00:37:31.480]   But that's what they want.
[00:37:31.480 --> 00:37:35.560]   And we got to fight that because that commission will be a little bit more reliable.
[00:37:35.560 --> 00:37:44.640]   And to sort of blow our own horn a little bit here, the only group that is really poised
[00:37:44.640 --> 00:37:49.320]   to save us from this mess is the journalist, journalism.
[00:37:49.320 --> 00:37:52.920]   It's the journalists who are digging into this stuff, asking these questions, finding
[00:37:52.920 --> 00:37:59.800]   out the fact, you look at all the, sort of the, all of the liars and the political like
[00:37:59.800 --> 00:38:04.320]   cheaters have turned radically pro in the last few years.
[00:38:04.320 --> 00:38:11.840]   And there's this massive like new world of like super sophisticated propaganda.
[00:38:11.840 --> 00:38:14.360]   And it's the journalists who are uncovering the facts about all this stuff.
[00:38:14.360 --> 00:38:18.520]   And so it's really unfortunate that journalism has such a bad reputation.
[00:38:18.520 --> 00:38:22.360]   I think we're, we're down there with dog catchers and what is the other.
[00:38:22.360 --> 00:38:24.600]   We're below insurance agents at this point.
[00:38:24.600 --> 00:38:30.600]   So well at root, what journalism should be in a good journalist does is seek the truth.
[00:38:30.600 --> 00:38:32.480]   We've heard it before.
[00:38:32.480 --> 00:38:40.360]   Speak truth to power to, you know, what is it to, to, to bring down the powerful?
[00:38:40.360 --> 00:38:41.360]   There's a phrase.
[00:38:41.360 --> 00:38:42.360]   Well, stick it to the man.
[00:38:42.360 --> 00:38:43.360]   Stick it to the man.
[00:38:43.360 --> 00:38:45.160]   The truth to power is the classic one.
[00:38:45.160 --> 00:38:49.320]   But the, what, when I was doing my journalism training 30 years ago, then it was, you had
[00:38:49.320 --> 00:38:50.560]   to be objective.
[00:38:50.560 --> 00:38:53.400]   You had to get all the facts in there so that we try to get to the truth.
[00:38:53.400 --> 00:38:54.400]   Yeah.
[00:38:54.400 --> 00:38:57.480]   So you put all the facts in there so that really can make their own decisions, your objective,
[00:38:57.480 --> 00:39:01.240]   and you try and give some guidance as to what's accurate and what isn't.
[00:39:01.240 --> 00:39:06.520]   But in the last, certainly in the last five, 10 years, you've seen whole publications,
[00:39:06.520 --> 00:39:10.720]   whole news organizations who have abandoned objectivity completely.
[00:39:10.720 --> 00:39:12.880]   And it's enormously disruptive.
[00:39:12.880 --> 00:39:16.440]   Because that is the foundation on which you make rational decisions.
[00:39:16.440 --> 00:39:20.880]   You know, it's like you don't go to a scientific research and say, I want that vaccine approved,
[00:39:20.880 --> 00:39:21.880]   find me a way to do it.
[00:39:21.880 --> 00:39:23.840]   Or some people would say that.
[00:39:23.840 --> 00:39:28.320]   But I mean, you, the whole point of scientific thinking is that you weigh up the pros and
[00:39:28.320 --> 00:39:29.480]   cons of each argument.
[00:39:29.480 --> 00:39:33.240]   You look at what works, what doesn't, and then you make your decision out there.
[00:39:33.240 --> 00:39:34.960]   And yeah, there are a lot of bad journalists out there.
[00:39:34.960 --> 00:39:36.440]   There are a lot of good journalists out there.
[00:39:36.440 --> 00:39:39.240]   So it's a question of identifying those ones and working with them.
[00:39:39.240 --> 00:39:42.840]   And for the youth of Australia, the important thing is to know is there are no money in journalism
[00:39:42.840 --> 00:39:43.840]   to the poverty.
[00:39:43.840 --> 00:39:47.080]   Get into finance or something else, because it's a terrible job.
[00:39:47.080 --> 00:39:51.040]   UOS gave me the phrase I was looking for.
[00:39:51.040 --> 00:39:53.920]   To comfort the afflicted and afflict the comfortable.
[00:39:53.920 --> 00:39:54.920]   Yeah, that's a good one.
[00:39:54.920 --> 00:39:55.920]   I don't know.
[00:39:55.920 --> 00:39:57.920]   That's more of a Jimmy Brezzling kind of journalism.
[00:39:57.920 --> 00:40:02.680]   Well, the famous quote, which has been attributed to Twain Orwell and various others, which
[00:40:02.680 --> 00:40:07.640]   is news is what someone doesn't want to see on the front page of the newspaper.
[00:40:07.640 --> 00:40:08.640]   That's news.
[00:40:08.640 --> 00:40:09.640]   Yeah.
[00:40:09.640 --> 00:40:10.640]   Yeah.
[00:40:10.640 --> 00:40:13.840]   So, lots more to talk about.
[00:40:13.840 --> 00:40:14.840]   Smart panel.
[00:40:14.840 --> 00:40:15.840]   Love that.
[00:40:15.840 --> 00:40:18.560]   Ian Thompson from the register.co.uk.
[00:40:18.560 --> 00:40:25.680]   Our gastro nomad Mike Elgin and Patrick Bezha from frenchspin.fr.
[00:40:25.680 --> 00:40:28.360]   And it is an honor to have all three of you here.
[00:40:28.360 --> 00:40:32.640]   I show today you probably noticed we're coming to you from the last past studios.
[00:40:32.640 --> 00:40:37.320]   It's a kind of a nice thing to sell the naming rights for the studio to a company that I've
[00:40:37.320 --> 00:40:41.000]   used and believed in for more than a decade long before they were an advertiser.
[00:40:41.000 --> 00:40:45.840]   We're really, I feel like it's almost a public service announcement to tell people, "Choose
[00:40:45.840 --> 00:40:47.040]   LastPass.
[00:40:47.040 --> 00:40:51.900]   You need to have a better strategy than writing your passwords on post it notes that you stick
[00:40:51.900 --> 00:40:53.680]   to the side of the screen.
[00:40:53.680 --> 00:40:58.240]   You need to have a better strategy than using the same password over and over and over on
[00:40:58.240 --> 00:41:02.720]   every site or making it your aunt's maiden name and your dog's birthday.
[00:41:02.720 --> 00:41:04.320]   Those don't work.
[00:41:04.320 --> 00:41:09.320]   And in this day and age of breaches where a password you use on one site could suddenly
[00:41:09.320 --> 00:41:15.040]   be available to a hacker to try on every site, this is just a strategy for disaster.
[00:41:15.040 --> 00:41:20.000]   LastPass solves the problem by helping you create long, strong passwords, storing them
[00:41:20.000 --> 00:41:25.040]   in a vault that only you have access to that's only decrypted on your devices, never anywhere
[00:41:25.040 --> 00:41:30.320]   else, and then letting you get access to all of that by just remembering one password.
[00:41:30.320 --> 00:41:31.320]   Imagine.
[00:41:31.320 --> 00:41:37.520]   And if you only had one password to remember and yet had a strong secure system to have
[00:41:37.520 --> 00:41:42.360]   passwords, unique passwords for every site you visit, every app you use, that's LastPass.
[00:41:42.360 --> 00:41:45.680]   17.8 million people use LastPass.
[00:41:45.680 --> 00:41:47.280]   That's individuals businesses too.
[00:41:47.280 --> 00:41:51.120]   We use LastPass Enterprise, 61,000 businesses.
[00:41:51.120 --> 00:41:54.400]   And if you think about it, if you're a business you need LastPass because your employees are
[00:41:54.400 --> 00:41:58.680]   the ones with all these bad habits, they've got the keys to the kingdom, the keys to your
[00:41:58.680 --> 00:42:03.760]   bank accounts, your databases, your website, you need to lock those down.
[00:42:03.760 --> 00:42:08.480]   LastPass is an award-winning security solution that helps individuals and businesses navigate
[00:42:08.480 --> 00:42:10.560]   their online lives easily and securely.
[00:42:10.560 --> 00:42:15.760]   We use LastPass family at home because it's very easy for me to share passwords.
[00:42:15.760 --> 00:42:17.600]   I just drag it to the shared folder.
[00:42:17.600 --> 00:42:21.400]   So anytime I create a new password or a new account that leads to these access to I drag
[00:42:21.400 --> 00:42:25.360]   it there, LastPass families also offers emergency access.
[00:42:25.360 --> 00:42:29.440]   Very important, if anything should happen to me, my wife and my daughter would both be
[00:42:29.440 --> 00:42:31.760]   able to request access to my vault.
[00:42:31.760 --> 00:42:35.520]   And there's certain security features built in to make sure that they can't do that unless
[00:42:35.520 --> 00:42:36.800]   something's happened to me.
[00:42:36.800 --> 00:42:42.320]   But that's, I know you don't want to think about it, but vital, vital to protecting your
[00:42:42.320 --> 00:42:45.640]   financial assets, should you become disabled or die.
[00:42:45.640 --> 00:42:48.440]   There's also LastPass premium for a single person.
[00:42:48.440 --> 00:42:52.960]   There's LastPass business plans like Teams, Enterprise, MFA, and Identity.
[00:42:52.960 --> 00:42:59.040]   I love the single sign-on that LastPass offers that does something normally impossible to
[00:42:59.040 --> 00:43:03.240]   make you more secure and make it more convenient.
[00:43:03.240 --> 00:43:07.480]   Strong passwords, I keep everything in my LastPass vault because it's the most secure
[00:43:07.480 --> 00:43:08.480]   thing on my drive.
[00:43:08.480 --> 00:43:12.880]   I have lots of various crypto solutions, but the LastPass vault is where I put my driver's
[00:43:12.880 --> 00:43:14.560]   license, my social security.
[00:43:14.560 --> 00:43:17.680]   When I travel, my passports are in there.
[00:43:17.680 --> 00:43:22.400]   Our corporate credit cards, everything I need can be stored in LastPass because only I
[00:43:22.400 --> 00:43:23.400]   have access to it.
[00:43:23.400 --> 00:43:25.520]   And by the way, it works everywhere I work.
[00:43:25.520 --> 00:43:28.880]   Windows, Mac, Linux, iOS, Android.
[00:43:28.880 --> 00:43:29.880]   You're going to love LastPass.
[00:43:29.880 --> 00:43:32.080]   If you're not using it, use it.
[00:43:32.080 --> 00:43:35.880]   If you are using it, tell your friends and family to use it and tell your company to
[00:43:35.880 --> 00:43:39.360]   use it, lastpass.com/twit.
[00:43:39.360 --> 00:43:45.200]   You need LastPass for amazing features that improve security in your business and your
[00:43:45.200 --> 00:43:46.200]   home.
[00:43:46.200 --> 00:43:47.200]   Lastpass.com/twit.
[00:43:47.200 --> 00:43:49.360]   It's a public service in that space.
[00:43:49.360 --> 00:43:51.120]   Quick thing about LastPass.
[00:43:51.120 --> 00:43:55.200]   Same thing as since you named the studio, there's like 150 hackers outside and they can't get
[00:43:55.200 --> 00:43:56.200]   in.
[00:43:56.200 --> 00:43:57.200]   It's amazing.
[00:43:57.200 --> 00:43:59.240]   It's really made it more secure in the studio.
[00:43:59.240 --> 00:44:05.400]   But if secure, I write about cybersecurity as one of my jobs.
[00:44:05.400 --> 00:44:09.040]   And if people are confused about the complexity of security, there's three things you need
[00:44:09.040 --> 00:44:10.040]   to do.
[00:44:10.040 --> 00:44:14.080]   You need to use VPN, like ExpressVPN, which is fantastic, which is what I use.
[00:44:14.080 --> 00:44:15.080]   Another sponsor.
[00:44:15.080 --> 00:44:17.800]   You need to use two-factor authentication for everybody who offers it.
[00:44:17.800 --> 00:44:18.800]   I use it.
[00:44:18.800 --> 00:44:19.800]   And not SMS two-factor authentication.
[00:44:19.800 --> 00:44:20.800]   That's right.
[00:44:20.800 --> 00:44:24.960]   Well, we know that because those SIM swap attacks are, but I carry a UBT on my keychain.
[00:44:24.960 --> 00:44:26.200]   That is a great way to do that.
[00:44:26.200 --> 00:44:27.760]   I'm on the Google Advanced Perception thing.
[00:44:27.760 --> 00:44:28.760]   Me too.
[00:44:28.760 --> 00:44:29.760]   Yeah, turn on.
[00:44:29.760 --> 00:44:30.760]   And the third thing is use LastPass.
[00:44:30.760 --> 00:44:31.760]   And don't just use it for passwords.
[00:44:31.760 --> 00:44:33.160]   Let it create the passwords.
[00:44:33.160 --> 00:44:35.200]   You never even need to know what your passwords are.
[00:44:35.200 --> 00:44:36.680]   Let LastPass create your passwords.
[00:44:36.680 --> 00:44:37.840]   But use it for all those other things.
[00:44:37.840 --> 00:44:39.160]   Put your credit card stuff in there.
[00:44:39.160 --> 00:44:41.920]   Put your everything that you don't want anybody to get in.
[00:44:41.920 --> 00:44:42.920]   Put it in there.
[00:44:42.920 --> 00:44:43.920]   There's a place in there for it.
[00:44:43.920 --> 00:44:47.840]   And then the fourth of my three things, Leo, is a Chromebook.
[00:44:47.840 --> 00:44:49.240]   He's a Pixelbook.
[00:44:49.240 --> 00:44:50.240]   So I use it in a Pixelbook?
[00:44:50.240 --> 00:44:51.840]   I'm using all those things right now.
[00:44:51.840 --> 00:44:53.440]   I'm basically unhackable.
[00:44:53.440 --> 00:44:57.120]   I can't think of it any way that somebody could hack me because of those four things
[00:44:57.120 --> 00:44:58.120]   I'm doing.
[00:44:58.120 --> 00:44:59.120]   Go ahead, kids.
[00:44:59.120 --> 00:45:00.120]   Give us a shot.
[00:45:00.120 --> 00:45:01.120]   See if you can come at me, bro.
[00:45:01.120 --> 00:45:03.400]   I've just moved off the Chromebook because I was going to say...
[00:45:03.400 --> 00:45:06.200]   I know you're using a ThinkPad, dude.
[00:45:06.200 --> 00:45:07.200]   Yeah, I'm using an X.
[00:45:07.200 --> 00:45:09.240]   After six years, I've given up the Chromebook.
[00:45:09.240 --> 00:45:10.240]   Why?
[00:45:10.240 --> 00:45:13.800]   Well, a glass of red wine was involved over the keyboard, which didn't really give me
[00:45:13.800 --> 00:45:14.800]   a lot of choice.
[00:45:14.800 --> 00:45:16.800]   But honestly, for the original...
[00:45:16.800 --> 00:45:17.800]   You had the original...
[00:45:17.800 --> 00:45:19.280]   I had the original Pixel as well.
[00:45:19.280 --> 00:45:20.840]   I spent the Christmas taking it apart.
[00:45:20.840 --> 00:45:22.520]   I couldn't get the damn thing to work again.
[00:45:22.520 --> 00:45:24.440]   But I agree with you.
[00:45:24.440 --> 00:45:30.520]   When it comes to security conferences in DEF CON and Blackout, I will take a burner Chromebook.
[00:45:30.520 --> 00:45:35.120]   But for day-to-day use, Chrome has become so painfully bad.
[00:45:35.120 --> 00:45:36.800]   I just decided to try something new.
[00:45:36.800 --> 00:45:37.880]   I went into Firefox.
[00:45:37.880 --> 00:45:38.880]   I'm happy.
[00:45:38.880 --> 00:45:42.240]   Firefox is much more secure than private.
[00:45:42.240 --> 00:45:45.520]   Well, and if you don't want ads and trackers and all that stuff, that's right.
[00:45:45.520 --> 00:45:47.480]   Yeah, unfortunately, it's Windows 10, which means...
[00:45:47.480 --> 00:45:48.480]   There's Microsoft.
[00:45:48.480 --> 00:45:49.480]   I know you ads.
[00:45:49.480 --> 00:45:51.160]   There's a nasty trend I'm starting to see.
[00:45:51.160 --> 00:45:57.800]   I wonder if you guys are seeing this, because I do use Brave and Firefox, which is anti-tracking.
[00:45:57.800 --> 00:46:01.680]   And more and more, I'm getting the sites to say, "You know, without third-party cookies
[00:46:01.680 --> 00:46:04.240]   turned on, you can't do this."
[00:46:04.240 --> 00:46:05.600]   And I'm seeing that more and more.
[00:46:05.600 --> 00:46:13.240]   Just today, I was trying to log in to enable the Fox Sports app so I could watch the Superbowl
[00:46:13.240 --> 00:46:15.840]   4K on Sunday.
[00:46:15.840 --> 00:46:17.200]   And it wouldn't work.
[00:46:17.200 --> 00:46:21.680]   And I realized it's because third-party cookies are turned off because you have to do a cross-logging
[00:46:21.680 --> 00:46:22.680]   through your cable company.
[00:46:22.680 --> 00:46:25.200]   I turned it on and all worked fine.
[00:46:25.200 --> 00:46:26.200]   And I'm seeing...
[00:46:26.200 --> 00:46:30.120]   And they even say, "Make sure you don't have privacy tracking on because that's going to
[00:46:30.120 --> 00:46:31.120]   make..."
[00:46:31.120 --> 00:46:32.120]   Well, no, I'm seeing more and more.
[00:46:32.120 --> 00:46:33.120]   I run privacy.
[00:46:33.120 --> 00:46:34.120]   I run privacy about you're on this.
[00:46:34.120 --> 00:46:38.280]   And the amount of sites, NBC, LA Times, and the rest of it, that's not bulk or site.
[00:46:38.280 --> 00:46:39.280]   No, it really is.
[00:46:39.280 --> 00:46:41.080]   Well, it is effectively, I guess.
[00:46:41.080 --> 00:46:43.520]   But they don't want you to run any of that stuff.
[00:46:43.520 --> 00:46:44.520]   No.
[00:46:44.520 --> 00:46:45.520]   It's hysterical.
[00:46:45.520 --> 00:46:49.960]   I think we talked about it last week, but we certainly talked about it on Twig on Wednesday.
[00:46:49.960 --> 00:46:53.680]   Google has announced that they're going to turn off third-party cookies in Chrome in
[00:46:53.680 --> 00:46:54.680]   2022.
[00:46:54.680 --> 00:46:55.680]   Kind of one of the...
[00:46:55.680 --> 00:46:56.680]   Kind of one of the...
[00:46:56.680 --> 00:46:57.680]   They've got another system in place.
[00:46:57.680 --> 00:46:58.680]   Well, that's the key.
[00:46:58.680 --> 00:46:59.680]   Yeah.
[00:46:59.680 --> 00:47:05.280]   Google, which is, of course, one of the number one violators of this with AdTech, I mean,
[00:47:05.280 --> 00:47:07.840]   they're an ad company.
[00:47:07.840 --> 00:47:11.040]   The only reason they would turn off third-party cookies is if they had a better system that
[00:47:11.040 --> 00:47:12.840]   no one else has access to, right?
[00:47:12.840 --> 00:47:13.840]   Yeah, exactly.
[00:47:13.840 --> 00:47:14.840]   This is it.
[00:47:14.840 --> 00:47:17.960]   So this is why they're doing this two years down the line rubbish.
[00:47:17.960 --> 00:47:19.520]   Let's talk about Sonos.
[00:47:19.520 --> 00:47:20.520]   Ooh.
[00:47:20.520 --> 00:47:21.520]   Yes.
[00:47:21.520 --> 00:47:23.360]   I have rants available on this.
[00:47:23.360 --> 00:47:25.440]   Yeah, this is an interesting story.
[00:47:25.440 --> 00:47:29.080]   And I think that there is more than just a Sonos story.
[00:47:29.080 --> 00:47:33.600]   So Sonos, which makes those internet-connected speakers, they've been making them longer
[00:47:33.600 --> 00:47:34.600]   than anybody.
[00:47:34.600 --> 00:47:40.000]   In fact, I think it probably was my first IoT device, because it was a speaker system that
[00:47:40.000 --> 00:47:42.720]   would play internet radio, streaming services.
[00:47:42.720 --> 00:47:46.480]   And in those days, it wasn't Apple Music or Google Music.
[00:47:46.480 --> 00:47:51.800]   I don't remember what my first streaming service was, but it was probably maybe Spotify.
[00:47:51.800 --> 00:47:53.320]   It was a long time ago.
[00:47:53.320 --> 00:47:56.800]   You could stream it through these speakers you could have, and this was their magic, their
[00:47:56.800 --> 00:47:59.680]   secret sauce, whole home audio.
[00:47:59.680 --> 00:48:00.720]   They called it party mode.
[00:48:00.720 --> 00:48:04.160]   If you turn on the speakers all over it, we have them here in the studio or all over
[00:48:04.160 --> 00:48:05.160]   the house.
[00:48:05.160 --> 00:48:09.400]   You wouldn't get weird echoey experience because of latency.
[00:48:09.400 --> 00:48:12.800]   Somehow they managed to sync all the speakers up, and it sounded like your whole house
[00:48:12.800 --> 00:48:15.440]   was just one big speaker, one big party.
[00:48:15.440 --> 00:48:17.880]   It was a really great system.
[00:48:17.880 --> 00:48:20.960]   But it's an IoT system.
[00:48:20.960 --> 00:48:22.360]   And that's the key.
[00:48:22.360 --> 00:48:26.760]   And I think that's the key to this Sonos story.
[00:48:26.760 --> 00:48:30.560]   Well, by the way, they backed down a little bit since the...
[00:48:30.560 --> 00:48:31.760]   Yeah, that was the first one.
[00:48:31.760 --> 00:48:32.760]   Yeah, that was the first one.
[00:48:32.760 --> 00:48:33.760]   ...to the first one.
[00:48:33.760 --> 00:48:36.200]   So Sonos has a newer platform that does more stuff.
[00:48:36.200 --> 00:48:40.680]   It uses Amazon Echo or Google Assistant, but it also, I guess, in some way has some
[00:48:40.680 --> 00:48:41.680]   improved capability.
[00:48:41.680 --> 00:48:44.960]   I don't know what that could be because it does everything else fine.
[00:48:44.960 --> 00:48:48.360]   But somehow the new systems are incompatible with the old systems.
[00:48:48.360 --> 00:48:49.880]   Sonos tries to get everybody to upgrade.
[00:48:49.880 --> 00:48:50.880]   I got the email.
[00:48:50.880 --> 00:48:55.880]   It will give you a 30% trade-in.
[00:48:55.880 --> 00:49:00.080]   But in order to take advantage of this to buy new gear or 30% off, you have to agree
[00:49:00.080 --> 00:49:02.400]   to brick your old devices.
[00:49:02.400 --> 00:49:03.400]   Exactly.
[00:49:03.400 --> 00:49:07.440]   They're usable, they're speakers, but unusable as speakers, you basically had a sentimental
[00:49:07.440 --> 00:49:08.440]   recycler.
[00:49:08.440 --> 00:49:09.440]   You couldn't sell them.
[00:49:09.440 --> 00:49:12.160]   Sonos said, "Well, we did that because we don't want anybody to buy them and then find
[00:49:12.160 --> 00:49:14.360]   out they don't work with the modern platform."
[00:49:14.360 --> 00:49:15.640]   So much rubbish.
[00:49:15.640 --> 00:49:16.640]   I agree.
[00:49:16.640 --> 00:49:22.560]   Then they announced, and something they've taken back, "Oh, all of your older stuff is
[00:49:22.560 --> 00:49:25.000]   going to stop getting updates.
[00:49:25.000 --> 00:49:29.480]   And if you have newer stuff on a network with older stuff, the newer stuff won't get updates
[00:49:29.480 --> 00:49:30.480]   either."
[00:49:30.480 --> 00:49:35.120]   Basically, strong arming people to get rid of their old Sonos gear, which is very pricey.
[00:49:35.120 --> 00:49:37.440]   You have thousands of dollars invested in it.
[00:49:37.440 --> 00:49:40.240]   Then replace it with equally expensive new Sonos gear.
[00:49:40.240 --> 00:49:44.120]   Since some of the gear they were at end of life, it was five years old.
[00:49:44.120 --> 00:49:47.080]   Growing up, I had speakers which lasted 50 years.
[00:49:47.080 --> 00:49:49.080]   Okay, so this is why I'll take this.
[00:49:49.080 --> 00:49:50.080]   Go ahead.
[00:49:50.080 --> 00:49:55.920]   So, Patrick, what prevents, again, going to be a little bit of the devil's advocate here,
[00:49:55.920 --> 00:50:01.840]   being prevents you from using them just as they are, just as the old speakers from the
[00:50:01.840 --> 00:50:05.000]   1700s you had when you were growing up.
[00:50:05.000 --> 00:50:08.080]   Yes, Patrick, they don't change.
[00:50:08.080 --> 00:50:16.360]   You cannot feed them line in like a speaker without going through the Sonos software.
[00:50:16.360 --> 00:50:21.200]   You have to use the Sonos software to say, "Monitor the line import."
[00:50:21.200 --> 00:50:26.880]   So as soon as it, but you can't use the Sonos software anymore, you can't use the line
[00:50:26.880 --> 00:50:27.880]   import.
[00:50:27.880 --> 00:50:29.360]   That's also you're not getting security updates.
[00:50:29.360 --> 00:50:30.680]   No, no, but you can use it.
[00:50:30.680 --> 00:50:35.560]   You can use it as long as you don't have any of the new speakers on your network.
[00:50:35.560 --> 00:50:39.360]   Well, and they, by the way, backed up and said, "Okay, we figure it out way.
[00:50:39.360 --> 00:50:43.120]   We can make two networks with the old stuff and the new stuff, so the new stuff will get
[00:50:43.120 --> 00:50:44.120]   updates."
[00:50:44.120 --> 00:50:47.640]   But they won't talk to each other, which means they're no longer that fabulous Sonos
[00:50:47.640 --> 00:50:48.640]   system.
[00:50:48.640 --> 00:50:50.480]   Right, trying to detect the pull with my mother on that one.
[00:50:50.480 --> 00:50:51.480]   That's going to be fun.
[00:50:51.480 --> 00:50:53.520]   You're right, but you could kind of use it.
[00:50:53.520 --> 00:50:58.480]   Here's my, I would say this, Patrick, what you thought you were buying as speakers,
[00:50:58.480 --> 00:51:03.040]   what you were buying as an Internet of Things device and like a computer and like all computer
[00:51:03.040 --> 00:51:07.160]   systems, all IoT systems, at some point they reach end of life.
[00:51:07.160 --> 00:51:09.000]   Your Chromebook, eight years.
[00:51:09.000 --> 00:51:11.800]   Windows, no, not even eight years, six Macs.
[00:51:11.800 --> 00:51:12.800]   Well, they just expanded.
[00:51:12.800 --> 00:51:14.040]   I drink Red wine too, so I feed you.
[00:51:14.040 --> 00:51:15.040]   It's any day span.
[00:51:15.040 --> 00:51:16.040]   Oh, right.
[00:51:16.040 --> 00:51:17.040]   And you drink one.
[00:51:17.040 --> 00:51:18.040]   My Pixel phone, three years.
[00:51:18.040 --> 00:51:19.040]   Three years.
[00:51:19.040 --> 00:51:21.000]   My device, three years.
[00:51:21.000 --> 00:51:24.080]   Your Windows machine, though, if you had Windows 7 on there after 10 years, you're going
[00:51:24.080 --> 00:51:25.160]   to not get updates.
[00:51:25.160 --> 00:51:27.920]   So this is the way it is in the software space.
[00:51:27.920 --> 00:51:31.680]   The disconnect here is people thought they were buying speakers, but they weren't.
[00:51:31.680 --> 00:51:33.960]   You can't use them as speakers again.
[00:51:33.960 --> 00:51:37.360]   Until at some point Sonos disables the software.
[00:51:37.360 --> 00:51:40.240]   And then we'll talk about it then.
[00:51:40.240 --> 00:51:41.800]   But this is the one.
[00:51:41.800 --> 00:51:47.080]   Everyone is talking about it as if Sonos was going to come in your house and dismantle
[00:51:47.080 --> 00:51:48.080]   your speaker.
[00:51:48.080 --> 00:51:50.080]   All of this is optional.
[00:51:50.080 --> 00:51:52.320]   Only if you take the 30%.
[00:51:52.320 --> 00:51:53.800]   No, but this is exactly.
[00:51:53.800 --> 00:51:55.320]   This is worse than that.
[00:51:55.320 --> 00:51:58.160]   They're not doing the security updates for the speakers.
[00:51:58.160 --> 00:52:03.520]   So you've now got insecure IoT devices in your house, communicating with your main computer
[00:52:03.520 --> 00:52:05.840]   and with your other IoT devices.
[00:52:05.840 --> 00:52:09.400]   Effectively, yes, you can carry on using them, but it's a really big.
[00:52:09.400 --> 00:52:11.840]   No, you can't carry them on because you'll be insecure.
[00:52:11.840 --> 00:52:13.200]   That is the other issue.
[00:52:13.200 --> 00:52:17.280]   What you're talking about, Ian, is the support for those speakers, which is a different
[00:52:17.280 --> 00:52:22.160]   issue from the problem of not being able to use it with your new gear.
[00:52:22.160 --> 00:52:25.960]   If Patrick, there were a wire and there may be a wire I could cut in there that would
[00:52:25.960 --> 00:52:30.360]   make the line in go directly to the speaker without interference in the software, I could
[00:52:30.360 --> 00:52:34.160]   disable the software so there's no security flaw, then it's a speaker.
[00:52:34.160 --> 00:52:36.160]   Don't cut the green wire because they're all exploding.
[00:52:36.160 --> 00:52:37.160]   No, it's the green.
[00:52:37.160 --> 00:52:38.160]   No, it's the green.
[00:52:38.160 --> 00:52:41.320]   Then it's a speaker, but I don't think I don't know if you can do that.
[00:52:41.320 --> 00:52:45.080]   And there is a great hazard to continuing to use them as standard speakers because they're
[00:52:45.080 --> 00:52:48.000]   still online, they're still connected to your network.
[00:52:48.000 --> 00:52:51.160]   I guess you could maybe, could you take them offline?
[00:52:51.160 --> 00:52:56.400]   No, you can't because you still need to get into them to say, "Use line in."
[00:52:56.400 --> 00:53:01.600]   I made the mistake of giving my Sonos, a single Sonos speaker in college four years ago.
[00:53:01.600 --> 00:53:05.200]   I realized I thought, "Oh, he could just plug his phone into it or use it."
[00:53:05.200 --> 00:53:06.200]   They couldn't.
[00:53:06.200 --> 00:53:08.680]   You had to go through the Sonos software, had to join a Wi-Fi network.
[00:53:08.680 --> 00:53:11.360]   I suspect that's still the problem.
[00:53:11.360 --> 00:53:16.680]   What you should do, and the right thing from now on to think about, is decouple software
[00:53:16.680 --> 00:53:24.240]   computer stuff from durable goods stuff by speakers that are dumb speakers, by a TV
[00:53:24.240 --> 00:53:26.600]   that's a dumb TV.
[00:53:26.600 --> 00:53:33.720]   And then I will say, dumb shows, get an external box that has the Sonos functionality, it drives
[00:53:33.720 --> 00:53:38.200]   those speakers, or an external box like a Roku that drives the TV.
[00:53:38.200 --> 00:53:46.760]   The one thing I will definitely agree, I actually agree again with a lot of what you said.
[00:53:46.760 --> 00:53:52.240]   The thing that irks me the most about those devices is that you can't just plug in with
[00:53:52.240 --> 00:53:54.880]   the line in something and you're good.
[00:53:54.880 --> 00:53:57.640]   I think that is an issue.
[00:53:57.640 --> 00:54:03.520]   Hopefully competitively, Sonos will be encouraged to do it down the line because this is just
[00:54:03.520 --> 00:54:06.800]   frustrating for no really good reason.
[00:54:06.800 --> 00:54:13.280]   What really stuck in my craw about this was Sonos was saying, if you look on their website,
[00:54:13.280 --> 00:54:16.680]   we believe in environmental qualities and helping to save the planet.
[00:54:16.680 --> 00:54:21.280]   Oh, by the way, we're bricking these for 30% of the cost and everyone, the main environmental
[00:54:21.280 --> 00:54:23.680]   cost is building new kit.
[00:54:23.680 --> 00:54:27.600]   Allow it to be resold, allow it to be repaired, allow it to be updated for goodness.
[00:54:27.600 --> 00:54:31.680]   They're not, okay, sorry, I'm going to be honest about this again.
[00:54:31.680 --> 00:54:34.880]   They are not disallowing it to be resold.
[00:54:34.880 --> 00:54:39.440]   They're only disallowing it to be resold if you take that 30%.
[00:54:39.440 --> 00:54:46.760]   I think they're promoting that 30% and then giving you the ability to sell it anyway.
[00:54:46.760 --> 00:54:49.000]   I think Sonos got a good education.
[00:54:49.000 --> 00:54:51.040]   They backed down a little bit.
[00:54:51.040 --> 00:54:53.240]   I think they understand people's concern.
[00:54:53.240 --> 00:54:56.040]   There was a lot of hatred, a lot of anger on Twitter.
[00:54:56.040 --> 00:54:59.280]   Of course it was, that's Twitter.
[00:54:59.280 --> 00:55:04.400]   But I also think, and I'm defending them, believe it or not, Patrick, the problem is
[00:55:04.400 --> 00:55:05.800]   they're an IoT device.
[00:55:05.800 --> 00:55:09.360]   And all IoT devices, this will happen to all of them.
[00:55:09.360 --> 00:55:14.520]   And so it's like saying, well, why can't I use my security camera after the company
[00:55:14.520 --> 00:55:15.720]   stops working?
[00:55:15.720 --> 00:55:20.640]   Well, because you need the software, you need the service.
[00:55:20.640 --> 00:55:24.520]   So I think a really important lesson for us all would be if you're going to buy a durable
[00:55:24.520 --> 00:55:32.680]   good, there were Samsung refrigerators that had a screen and a browser, but it was IE8.
[00:55:32.680 --> 00:55:34.560]   And after that, they never updated it.
[00:55:34.560 --> 00:55:40.160]   So you had a durable good, a refrigerator attached to a computer system that wasn't up
[00:55:40.160 --> 00:55:41.160]   to date.
[00:55:41.160 --> 00:55:46.280]   Now that was annoying because you have a big screen on your refrigerator that does nothing.
[00:55:46.280 --> 00:55:51.320]   But you still had a refrigerator and maybe, Patrick, maybe you still have a speaker, but
[00:55:51.320 --> 00:55:58.520]   really the thing is this is a moral that all of us need to remember, which is decouple.
[00:55:58.520 --> 00:56:04.120]   If you want a TV to be a TV, I mean, you can't not buy a smart TV, but you shouldn't pay
[00:56:04.120 --> 00:56:05.120]   any attention.
[00:56:05.120 --> 00:56:06.720]   This touches on, I'm sorry.
[00:56:06.720 --> 00:56:09.640]   I never connect my smart TVs to the Internet.
[00:56:09.640 --> 00:56:11.800]   This story touches on a bunch of different themes.
[00:56:11.800 --> 00:56:16.640]   One of them is just, does the public really want smart things or do we prefer dumb things?
[00:56:16.640 --> 00:56:23.000]   And I tend to think that all this smart stuff is taking control away from us, which is not
[00:56:23.000 --> 00:56:24.120]   what we want.
[00:56:24.120 --> 00:56:26.640]   Another thing is that Sonos is a dinosaur and they'll be gone in 10 years.
[00:56:26.640 --> 00:56:27.640]   I think he's going to kill them.
[00:56:27.640 --> 00:56:31.880]   They don't have any secret sauce left and everybody can easily copy everything they
[00:56:31.880 --> 00:56:32.880]   do now and smart speakers.
[00:56:32.880 --> 00:56:35.960]   They're suing Google because they said Google did copy.
[00:56:35.960 --> 00:56:41.520]   I'm kind of rooting for them because they're from my hometown of Santa Barbara.
[00:56:41.520 --> 00:56:46.760]   I love them and I spent more than $5,000 on Sonos Gear over the last 10 years.
[00:56:46.760 --> 00:56:48.800]   I love them, but they've been replaced.
[00:56:48.800 --> 00:56:49.800]   They're obsolete.
[00:56:49.800 --> 00:56:50.800]   Right, exactly.
[00:56:50.800 --> 00:56:55.960]   And I thought Stacey Higginbotham had a great point on Twig, which is that technology, anything
[00:56:55.960 --> 00:56:59.440]   that has software in it, should come with an expiration date like it was milk.
[00:56:59.440 --> 00:57:01.000]   Yeah, because it will expire.
[00:57:01.000 --> 00:57:02.720]   I think this would be good for the companies too.
[00:57:02.720 --> 00:57:09.320]   So Microsoft ships a product and says, "Okay, the expiration date is five years from now."
[00:57:09.320 --> 00:57:13.520]   And if you know that when you buy it, then we're good.
[00:57:13.520 --> 00:57:14.520]   We have a choice.
[00:57:14.520 --> 00:57:19.280]   I think the promise is that it's a new world where we have this concept, "This is a durable
[00:57:19.280 --> 00:57:20.280]   good.
[00:57:20.280 --> 00:57:21.280]   This is a TV.
[00:57:21.280 --> 00:57:22.280]   This is a speaker system."
[00:57:22.280 --> 00:57:23.960]   And we forget that the software is not.
[00:57:23.960 --> 00:57:24.960]   The software has a real--
[00:57:24.960 --> 00:57:25.960]   But if we had a right to apply.
[00:57:25.960 --> 00:57:26.960]   It's true.
[00:57:26.960 --> 00:57:29.000]   It was like the issue there.
[00:57:29.000 --> 00:57:34.280]   I probably should say Sonos was a sponsor on Long Day, we take a few months ago.
[00:57:34.280 --> 00:57:38.480]   So I don't want it to seem like I'm defending them because of that.
[00:57:38.480 --> 00:57:41.920]   I actually think that what they did was an mistake.
[00:57:41.920 --> 00:57:46.960]   But I think the lesson here for them is the end of life came way too quickly.
[00:57:46.960 --> 00:57:48.600]   And that's the huge issue.
[00:57:48.600 --> 00:57:53.600]   If it was a 10-year-old device, I think the rom-links would be a lot less audible.
[00:57:53.600 --> 00:57:57.640]   And that I think they won't do again.
[00:57:57.640 --> 00:58:01.400]   Now whether or not that will be enough for them to survive in a world where everyone
[00:58:01.400 --> 00:58:03.840]   is a connected speaker, I don't know.
[00:58:03.840 --> 00:58:08.480]   But I think they will take that part, for sure, to heart.
[00:58:08.480 --> 00:58:12.280]   Media Dude in our chat room says, "Right to repair solvices."
[00:58:12.280 --> 00:58:13.280]   Does that solve it?
[00:58:13.280 --> 00:58:14.280]   No, right to repair.
[00:58:14.280 --> 00:58:17.880]   If you want to do, you declare something end of life.
[00:58:17.880 --> 00:58:20.680]   And if you then say, "Right, since end of life, we're not going to support it.
[00:58:20.680 --> 00:58:22.120]   We're going to open source the code."
[00:58:22.120 --> 00:58:24.320]   And you could then use it.
[00:58:24.320 --> 00:58:28.160]   There are an army of hackers out there who would like nothing better than to go through
[00:58:28.160 --> 00:58:29.160]   this.
[00:58:29.160 --> 00:58:30.160]   Yeah.
[00:58:30.160 --> 00:58:31.640]   Improve it, tweak it, get ahead with it.
[00:58:31.640 --> 00:58:32.640]   What's the same?
[00:58:32.640 --> 00:58:37.240]   There must be a Raspberry Pi solution that does all the Sonos stuff that I could then
[00:58:37.240 --> 00:58:39.000]   hook up all my problems with Sonos.
[00:58:39.000 --> 00:58:44.160]   If you actually try and put that out, it's the same without, they're in Congress these
[00:58:44.160 --> 00:58:49.440]   last few months arguing that people should not be allowed to repair their iPhones or
[00:58:49.440 --> 00:58:54.400]   their iDevices because it might put them at risk because, in the risk of bankruptcy,
[00:58:54.400 --> 00:58:59.640]   if you go to the Genius bar, you should be able to repair stuff that you buy.
[00:58:59.640 --> 00:59:00.640]   It's as simple as that.
[00:59:00.640 --> 00:59:01.640]   I bought it.
[00:59:01.640 --> 00:59:04.320]   I want the ability to take it apart and have some fun with it.
[00:59:04.320 --> 00:59:09.360]   One of the things Sonos has done, though, is made deals with all of these streaming services
[00:59:09.360 --> 00:59:11.520]   so that you can use them on their equipment.
[00:59:11.520 --> 00:59:13.000]   I don't know if I...
[00:59:13.000 --> 00:59:17.200]   This is called a High-Fi Berry.
[00:59:17.200 --> 00:59:25.680]   It's a Raspberry Pi that a guest does basically the Internet radio stuff.
[00:59:25.680 --> 00:59:27.400]   You could certainly hook that up to a stereo.
[00:59:27.400 --> 00:59:30.120]   See, stereos don't go obsolete every five years.
[00:59:30.120 --> 00:59:31.120]   No, right.
[00:59:31.120 --> 00:59:33.120]   I still got my amp from when I was a student.
[00:59:33.120 --> 00:59:34.120]   It still works.
[00:59:34.120 --> 00:59:35.120]   Yeah.
[00:59:35.120 --> 00:59:39.960]   As long as you don't mind having only two speakers, you could do that.
[00:59:39.960 --> 00:59:42.080]   I'll get a High-Fi Berry.
[00:59:42.080 --> 00:59:47.800]   It's got a DAC, a DSP, digital inputs and outputs for applications.
[00:59:47.800 --> 00:59:49.400]   It's interesting.
[00:59:49.400 --> 00:59:51.640]   That's really interesting.
[00:59:51.640 --> 00:59:54.640]   I do think this is the future of IoT, though.
[00:59:54.640 --> 00:59:59.240]   The myriad problems that are coming when we have IoT devices every night, just in our
[00:59:59.240 --> 01:00:03.800]   homes with factories and enterprises and so on, it's going to be such a mess.
[01:00:03.800 --> 01:00:05.480]   The security issues are going to be a mess.
[01:00:05.480 --> 01:00:08.120]   The updates are going to be a mess.
[01:00:08.120 --> 01:00:11.160]   A lot of IoT devices actually run on batteries.
[01:00:11.160 --> 01:00:14.720]   If you're a big company and you install 10,000 little sensors all over the thing and then
[01:00:14.720 --> 01:00:17.520]   the batteries, there goes one, there goes another one.
[01:00:17.520 --> 01:00:19.480]   Airpods are going to go around changing their parts.
[01:00:19.480 --> 01:00:21.320]   Airpods are a good case in point.
[01:00:21.320 --> 01:00:23.200]   They're just knocking out two years.
[01:00:23.200 --> 01:00:24.640]   The battery dies, there's no replacement.
[01:00:24.640 --> 01:00:25.640]   That's it.
[01:00:25.640 --> 01:00:26.640]   That's right.
[01:00:26.640 --> 01:00:30.120]   Here in California, we've had the power company taking down power for two or three days at
[01:00:30.120 --> 01:00:32.360]   a time and that all goes into it.
[01:00:32.360 --> 01:00:37.120]   I mean, particularly after I come on these shows, Leah, people are just like, "You don't
[01:00:37.120 --> 01:00:40.280]   have any IoT devices in your house whatsoever."
[01:00:40.280 --> 01:00:42.680]   It's like, "No, but you're a technology journalist."
[01:00:42.680 --> 01:00:44.680]   Yeah, that's why.
[01:00:44.680 --> 01:00:49.040]   You speak to security people, they don't have this stuff in their house.
[01:00:49.040 --> 01:00:50.880]   It is untrustworthy.
[01:00:50.880 --> 01:00:54.920]   Or they do their own role, their own operating systems with their own source.
[01:00:54.920 --> 01:00:58.280]   With their firewall and their own local data system.
[01:00:58.280 --> 01:00:59.280]   Yeah.
[01:00:59.280 --> 01:01:05.520]   Because one way to address this a little bit would be to do something that I think half
[01:01:05.520 --> 01:01:12.320]   of the panel will dislike and the other half might be in favor of.
[01:01:12.320 --> 01:01:23.600]   Make it a legal requirement for companies to specify on the box how long they support
[01:01:23.600 --> 01:01:24.840]   the device.
[01:01:24.840 --> 01:01:26.840]   And I think that is an offer that...
[01:01:26.840 --> 01:01:27.840]   A sell buy date.
[01:01:27.840 --> 01:01:28.840]   A dead buy date.
[01:01:28.840 --> 01:01:29.840]   Yeah.
[01:01:29.840 --> 01:01:38.040]   And when you see that some phones have five years guarantee or six years guarantee support
[01:01:38.040 --> 01:01:44.360]   and others have one or two or three, that would affect a lot of things significantly.
[01:01:44.360 --> 01:01:45.360]   It's in.
[01:01:45.360 --> 01:01:46.800]   And the industry would love this too.
[01:01:46.800 --> 01:01:48.040]   And I support what you're saying.
[01:01:48.040 --> 01:01:50.480]   And like I said earlier, I think an expiration date would be great and we should all push
[01:01:50.480 --> 01:01:51.480]   for it.
[01:01:51.480 --> 01:01:52.480]   There should be a movement in favor of that.
[01:01:52.480 --> 01:01:53.480]   But it's a little bit like the...
[01:01:53.480 --> 01:01:57.440]   I don't know if you read about the J-Walking laws.
[01:01:57.440 --> 01:02:02.080]   J-Walking laws existed because when they first started having cars on highways, people getting
[01:02:02.080 --> 01:02:04.560]   killed because they didn't understand how fast they went.
[01:02:04.560 --> 01:02:07.000]   And the car company was like, "Let's have J-Walking laws.
[01:02:07.000 --> 01:02:08.000]   Let's make it their fault."
[01:02:08.000 --> 01:02:10.400]   You're not supposed to walk on the street.
[01:02:10.400 --> 01:02:12.040]   That's why people are getting killed.
[01:02:12.040 --> 01:02:13.760]   And so this would be the same thing.
[01:02:13.760 --> 01:02:16.360]   If they put expiration dates, they'd be off the hook.
[01:02:16.360 --> 01:02:17.360]   You bought it.
[01:02:17.360 --> 01:02:18.360]   It said right on the package.
[01:02:18.360 --> 01:02:19.360]   Five years.
[01:02:19.360 --> 01:02:20.360]   Five years when it's buying?
[01:02:20.360 --> 01:02:21.360]   Yeah, but you don't know.
[01:02:21.360 --> 01:02:22.360]   People don't know.
[01:02:22.360 --> 01:02:29.600]   If you put it, it's like the information about energy consumption that is required to be
[01:02:29.600 --> 01:02:32.760]   on any device you buy now.
[01:02:32.760 --> 01:02:39.640]   We're discussing something which is a little bit similar maybe to what we're talking about.
[01:02:39.640 --> 01:02:46.080]   Repairability indexes in France are going to be on the boxes.
[01:02:46.080 --> 01:02:51.920]   And I think there is an element of consumers not having the information so they can't make
[01:02:51.920 --> 01:02:53.320]   the decision.
[01:02:53.320 --> 01:02:57.120]   And if you don't tell them that their device is not going to be updated and going to be
[01:02:57.120 --> 01:03:02.640]   dangerous in two years, that is an important part, piece of information to have when you
[01:03:02.640 --> 01:03:03.680]   make your purchase.
[01:03:03.680 --> 01:03:15.480]   And it invokes a lot of competitiveity which is currently not being put into the game.
[01:03:15.480 --> 01:03:20.800]   And so companies can do whatever they want with that because it's not part of the conversation
[01:03:20.800 --> 01:03:24.080]   or the purchasing decision.
[01:03:24.080 --> 01:03:28.160]   Do you support the EU's charger charging brick?
[01:03:28.160 --> 01:03:29.160]   Damn right.
[01:03:29.160 --> 01:03:30.160]   Rules.
[01:03:30.160 --> 01:03:35.360]   So it's a little bit, it shows the mismatch between the time it takes to make legislation
[01:03:35.360 --> 01:03:38.480]   work and the speed with the tech industry works.
[01:03:38.480 --> 01:03:42.960]   When the EU proposed these rules, there were something like 30 different charging standards.
[01:03:42.960 --> 01:03:44.800]   We're not talking about the connector.
[01:03:44.800 --> 01:03:48.720]   In fact, early on these news stories implied that it was something about the lightning
[01:03:48.720 --> 01:03:49.720]   port.
[01:03:49.720 --> 01:03:51.760]   We're talking about the charging brick.
[01:03:51.760 --> 01:03:58.480]   There are now three but nevertheless, there's several, what was it, 61,000 tons of charging
[01:03:58.480 --> 01:04:00.320]   bricks in the landfill every year.
[01:04:00.320 --> 01:04:01.960]   And we've all been in the industry.
[01:04:01.960 --> 01:04:04.440]   We've all got that box of cables and power bricks.
[01:04:04.440 --> 01:04:07.080]   Yeah, there was a great Wall Street Journal story about that.
[01:04:07.080 --> 01:04:08.080]   It was wonderful.
[01:04:08.080 --> 01:04:09.080]   We all have the box.
[01:04:09.080 --> 01:04:10.080]   Yeah.
[01:04:10.080 --> 01:04:11.080]   Yeah.
[01:04:11.080 --> 01:04:12.920]   And they all wind into it so they'd like Medusa's hair and it's just.
[01:04:12.920 --> 01:04:14.920]   And you'll never have anything to go with again.
[01:04:14.920 --> 01:04:19.960]   I spent half a day this new year's trimming through my electronics and I got it down to
[01:04:19.960 --> 01:04:21.800]   just the last box of cables.
[01:04:21.800 --> 01:04:22.800]   Nice.
[01:04:22.800 --> 01:04:24.320]   And then you're just spending half a day.
[01:04:24.320 --> 01:04:25.320]   Does this work in that?
[01:04:25.320 --> 01:04:26.320]   Right, okay, right on that.
[01:04:26.320 --> 01:04:27.920]   That's what that's that for.
[01:04:27.920 --> 01:04:30.160]   And I still ended up with half a bunch of things.
[01:04:30.160 --> 01:04:31.160]   You've got to throw away.
[01:04:31.160 --> 01:04:33.640]   They turn into a landfill and you can do nothing for them.
[01:04:33.640 --> 01:04:38.280]   Standardized cable makes sense for everyone except the company that produces the one that
[01:04:38.280 --> 01:04:39.280]   doesn't.
[01:04:39.280 --> 01:04:40.280]   Looking at you, Apple.
[01:04:40.280 --> 01:04:43.320]   I'm not sure that the EU proposal will do the trick though.
[01:04:43.320 --> 01:04:49.280]   I think what law would be required is to have a law that says that charging cables have
[01:04:49.280 --> 01:04:51.600]   to be sold separately at a separate price.
[01:04:51.600 --> 01:04:53.120]   Disincentivize the purchase.
[01:04:53.120 --> 01:04:56.400]   Because even if you have perfectly standard cables, if every device comes with yet another
[01:04:56.400 --> 01:04:57.400]   cable, right?
[01:04:57.400 --> 01:04:58.400]   If it's in the box.
[01:04:58.400 --> 01:04:59.480]   It's not the cable, it's the brick.
[01:04:59.480 --> 01:05:00.480]   The brick, right.
[01:05:00.480 --> 01:05:01.960]   If every device comes with the charging.
[01:05:01.960 --> 01:05:02.960]   Well, that's why you have standard.
[01:05:02.960 --> 01:05:06.720]   You have type C on that on the brick end.
[01:05:06.720 --> 01:05:09.240]   So if every charging brick just had a type C port.
[01:05:09.240 --> 01:05:10.240]   Yes.
[01:05:10.240 --> 01:05:13.680]   If every product comes with another brick, then you haven't solved anything.
[01:05:13.680 --> 01:05:16.120]   You have to take that brick out of the pack.
[01:05:16.120 --> 01:05:17.120]   That's exactly right.
[01:05:17.120 --> 01:05:18.120]   Otherwise you don't make less bricks.
[01:05:18.120 --> 01:05:19.120]   The battery's not included.
[01:05:19.120 --> 01:05:23.240]   The method of problems with Christmas where it's like you give someone this toy and it's
[01:05:23.240 --> 01:05:24.240]   batteries not included.
[01:05:24.240 --> 01:05:25.720]   It's the death knell of Christmas.
[01:05:25.720 --> 01:05:26.720]   Yes.
[01:05:26.720 --> 01:05:28.800]   Because you know you've got to have a screaming child and there's nowhere to buy batteries
[01:05:28.800 --> 01:05:29.800]   on Christmas.
[01:05:29.800 --> 01:05:32.240]   It would suck and it wouldn't be as convenient as having the thing come in there and everybody
[01:05:32.240 --> 01:05:33.240]   would hate it.
[01:05:33.240 --> 01:05:34.520]   But that's how you would solve this problem.
[01:05:34.520 --> 01:05:40.000]   What I'm saying is that the problem is there's the one to one ratio of devices that need charging
[01:05:40.000 --> 01:05:41.600]   bricks and charging bricks.
[01:05:41.600 --> 01:05:42.600]   It's one to one.
[01:05:42.600 --> 01:05:46.240]   If you make that charging brick standard and they still all come with a charging brick,
[01:05:46.240 --> 01:05:49.080]   you have exactly the same problem you had before.
[01:05:49.080 --> 01:05:50.080]   Exactly.
[01:05:50.080 --> 01:05:57.880]   I think in the case of chargers as well, after about two days, everyone has a charging charger
[01:05:57.880 --> 01:05:58.880]   anyway.
[01:05:58.880 --> 01:06:03.120]   So I don't think it's as bad as the batteries not included problem.
[01:06:03.120 --> 01:06:06.600]   We all have 15 million chargers anyway.
[01:06:06.600 --> 01:06:09.440]   We all have this box, right?
[01:06:09.440 --> 01:06:11.320]   This is the most fictional I've made it.
[01:06:11.320 --> 01:06:14.600]   You have a box of course you'll never ever use again.
[01:06:14.600 --> 01:06:18.260]   Electric gadgets fade away, but they're cables and it's not just cables, it's those power
[01:06:18.260 --> 01:06:19.260]   bricks.
[01:06:19.260 --> 01:06:20.260]   Live on.
[01:06:20.260 --> 01:06:21.260]   It's on a tip.
[01:06:21.260 --> 01:06:23.560]   The inside of toilet rolls are really good for storing cables in.
[01:06:23.560 --> 01:06:26.960]   You wind them up, you jam them into the inside of a toilet roll, you write what's on it on
[01:06:26.960 --> 01:06:28.800]   the outside and you can stack them up really easily.
[01:06:28.800 --> 01:06:31.600]   Much more tidy for your box of cables.
[01:06:31.600 --> 01:06:39.280]   So do you think there's anything to Tim Cook's claim that freezing in time, the charging
[01:06:39.280 --> 01:06:45.440]   port, because again, I don't know that we've made it clear, the EU wants everyone, every
[01:06:45.440 --> 01:06:52.320]   manufacturer, especially phones to use a USB-C port on the charger.
[01:06:52.320 --> 01:06:53.320]   Good.
[01:06:53.320 --> 01:06:55.040]   What they do on the phone, whatever they want.
[01:06:55.040 --> 01:06:57.720]   But on the charger, they have to use a USB-C port.
[01:06:57.720 --> 01:06:58.720]   Good.
[01:06:58.720 --> 01:07:04.400]   Tim Cook was saying this would, if you freeze that in time and no one can change it ever,
[01:07:04.400 --> 01:07:06.240]   well, that's not exactly what the EU wants to do.
[01:07:06.240 --> 01:07:07.720]   That's not what they're saying.
[01:07:07.720 --> 01:07:08.720]   Yeah.
[01:07:08.720 --> 01:07:11.040]   Then you stifle innovation.
[01:07:11.040 --> 01:07:12.040]   Cool.
[01:07:12.040 --> 01:07:13.600]   Tim Cook's full of it.
[01:07:13.600 --> 01:07:14.600]   And here's why.
[01:07:14.600 --> 01:07:20.840]   So Apple would be able to support any standard on the phone side and then they can innovate
[01:07:20.840 --> 01:07:25.680]   any way they like on the brick side in a way that supports the standard and that would
[01:07:25.680 --> 01:07:27.640]   be a value add.
[01:07:27.640 --> 01:07:31.200]   He just wants, you know, the Apple has made so much money on these accessories.
[01:07:31.200 --> 01:07:32.200]   Yeah, absolutely.
[01:07:32.200 --> 01:07:33.840]   And they want to put microprocessor in things.
[01:07:33.840 --> 01:07:35.840]   Here's the counter example.
[01:07:35.840 --> 01:07:40.160]   That's not a great counter example, but we have a standard for the plug sockets in the
[01:07:40.160 --> 01:07:41.440]   wall in the United States.
[01:07:41.440 --> 01:07:44.400]   Unfortunately, it's different than the UK and Finland and everywhere else.
[01:07:44.400 --> 01:07:49.120]   But at least there's a standard that has not stifled the innovation in plug sockets.
[01:07:49.120 --> 01:07:50.120]   No.
[01:07:50.120 --> 01:07:51.120]   Okay.
[01:07:51.120 --> 01:07:54.400]   But if we had had that law, again, I'm the...
[01:07:54.400 --> 01:07:55.400]   Imagine if we had...
[01:07:55.400 --> 01:08:00.320]   Imagine if you had had five different kinds of plug sockets to accommodate the devices
[01:08:00.320 --> 01:08:02.520]   that you wanted on the chargers.
[01:08:02.520 --> 01:08:09.840]   From the chargers, if we had had that law, you know, in 2012, it would be, I don't know,
[01:08:09.840 --> 01:08:10.840]   USB-A or...
[01:08:10.840 --> 01:08:12.960]   Well, yeah, that's why you have to say it.
[01:08:12.960 --> 01:08:13.960]   But laws evolve.
[01:08:13.960 --> 01:08:15.280]   That's the thing you can say.
[01:08:15.280 --> 01:08:16.280]   Okay.
[01:08:16.280 --> 01:08:20.440]   In 18 months or two years time, we're going to move from USB-C to USB-C.
[01:08:20.440 --> 01:08:22.600]   There's actually a good example for this.
[01:08:22.600 --> 01:08:26.680]   In the EU, they originally did say that you had to have the same connector on every phone.
[01:08:26.680 --> 01:08:29.800]   It was micro-USB, which was crappy.
[01:08:29.800 --> 01:08:31.520]   But they've now updated that, right?
[01:08:31.520 --> 01:08:32.800]   The hub-C is acceptable.
[01:08:32.800 --> 01:08:33.800]   Is that right?
[01:08:33.800 --> 01:08:34.800]   In the EU?
[01:08:34.800 --> 01:08:36.760]   So they've updated it.
[01:08:36.760 --> 01:08:43.280]   And I'm glad because until that EU law, every phone, every computer, every device,
[01:08:43.280 --> 01:08:45.600]   had a unique connector.
[01:08:45.600 --> 01:08:46.600]   And none of them matched.
[01:08:46.600 --> 01:08:51.440]   I have phones I can't charge in my museum because I don't have that connector.
[01:08:51.440 --> 01:08:55.520]   And that's, by the way, what led to the cable box, this fear of, oh, I'm going to never
[01:08:55.520 --> 01:08:57.600]   be able to charge this again if I lose this cable.
[01:08:57.600 --> 01:08:58.600]   Exactly.
[01:08:58.600 --> 01:08:59.760]   I can't throw out any of these cables.
[01:08:59.760 --> 01:09:06.120]   In defense of Apple and Tim Cook, I don't trust the EU to pass legislation that is wise
[01:09:06.120 --> 01:09:09.520]   or that will actually work in the real world considering all the things that they're going
[01:09:09.520 --> 01:09:10.520]   to pass.
[01:09:10.520 --> 01:09:11.520]   Hang on, it has in the past.
[01:09:11.520 --> 01:09:14.240]   Yeah, not in terms of plugs.
[01:09:14.240 --> 01:09:15.240]   In terms of like...
[01:09:15.240 --> 01:09:19.240]   One of the insistent on the micro-USB standard, that worked did an awful lot concerningly
[01:09:19.240 --> 01:09:20.240]   and updated it.
[01:09:20.240 --> 01:09:25.600]   Right, but I'm talking about in general, like for example, their right to be forgotten
[01:09:25.600 --> 01:09:26.600]   rules, the...
[01:09:26.600 --> 01:09:30.360]   Look, legislation is in a perfect technique.
[01:09:30.360 --> 01:09:33.960]   Regulation in the EU is no worse or better than regulation in the United States.
[01:09:33.960 --> 01:09:34.960]   Exactly.
[01:09:34.960 --> 01:09:35.960]   It's an important thing.
[01:09:35.960 --> 01:09:36.960]   I think it's better.
[01:09:36.960 --> 01:09:37.960]   I would disagree with that strongly.
[01:09:37.960 --> 01:09:38.960]   Really?
[01:09:38.960 --> 01:09:39.960]   So, if you had...
[01:09:39.960 --> 01:09:41.800]   Who were the people who held Google to account?
[01:09:41.800 --> 01:09:43.600]   Who were the people who held Microsoft to account?
[01:09:43.600 --> 01:09:45.280]   It wasn't the US government.
[01:09:45.280 --> 01:09:48.040]   You know, it was only the EU stepping in on things like...
[01:09:48.040 --> 01:09:50.440]   We would not have had the browser ballot without the EU.
[01:09:50.440 --> 01:09:51.920]   We wouldn't have had the browser ballot.
[01:09:51.920 --> 01:09:54.840]   Google wouldn't have been held to account for skewing the search results.
[01:09:54.840 --> 01:09:58.120]   The idea of the US regulation, it's a joke.
[01:09:58.120 --> 01:09:59.640]   Google hasn't been held to account.
[01:09:59.640 --> 01:10:00.640]   They're still arguing over...
[01:10:00.640 --> 01:10:01.640]   Well, they're still arguing over...
[01:10:01.640 --> 01:10:03.520]   Maybe a percent of what they were doing before.
[01:10:03.520 --> 01:10:09.880]   When I go to Europe, using the internet as kind of a nightmare, granted, I open thousands
[01:10:09.880 --> 01:10:10.880]   of people...
[01:10:10.880 --> 01:10:14.520]   Does anybody enjoy these pop-ups on every freaking website saying we use cookies?
[01:10:14.520 --> 01:10:15.880]   Is that okay?
[01:10:15.880 --> 01:10:17.360]   That is a...
[01:10:17.360 --> 01:10:24.360]   If you add up all the waste of all of us clicking that nonsensical pop-up, it must be
[01:10:24.360 --> 01:10:25.360]   millions of man-hours.
[01:10:25.360 --> 01:10:26.360]   It's ridiculous.
[01:10:26.360 --> 01:10:28.880]   And by the way, this is one of the great things about ExpressVPN.
[01:10:28.880 --> 01:10:33.720]   I can be in Paris and tell them I'm in Boston.
[01:10:33.720 --> 01:10:37.480]   And I'm going to go pop-up now because everybody says, "Well, we got to support the cheap
[01:10:37.480 --> 01:10:38.480]   people."
[01:10:38.480 --> 01:10:40.040]   But at least I can read the Boston newspaper.
[01:10:40.040 --> 01:10:42.800]   There's like 600 newspapers in the US you can't read in Europe.
[01:10:42.800 --> 01:10:43.800]   That's right.
[01:10:43.800 --> 01:10:44.800]   I'm trying to do research.
[01:10:44.800 --> 01:10:45.800]   I can't read this.
[01:10:45.800 --> 01:10:46.800]   But that's...
[01:10:46.800 --> 01:10:47.800]   Who's fault is that?
[01:10:47.800 --> 01:10:48.800]   I feel like the newspapers in the United States are being found.
[01:10:48.800 --> 01:10:49.800]   We came to another...
[01:10:49.800 --> 01:10:50.800]   We've noticed on GDPR.
[01:10:50.800 --> 01:10:51.800]   They had two years.
[01:10:51.800 --> 01:10:52.800]   A local newspaper has no incentive.
[01:10:52.800 --> 01:10:53.800]   There's no incentive.
[01:10:53.800 --> 01:10:55.880]   There's two obey European law.
[01:10:55.880 --> 01:10:57.920]   It's like they're trying to serve the local community.
[01:10:57.920 --> 01:11:00.120]   But anyway, it's a...
[01:11:00.120 --> 01:11:01.560]   I don't trust the EU.
[01:11:01.560 --> 01:11:02.680]   I don't trust the US.
[01:11:02.680 --> 01:11:07.120]   I don't trust Silicon Valley because they're too self-interested and selfish.
[01:11:07.120 --> 01:11:11.960]   I don't really trust anybody to get these charging ports, right?
[01:11:11.960 --> 01:11:16.320]   And so I think what's probably going to happen is, "Are you going to do their thing?
[01:11:16.320 --> 01:11:21.400]   Apple's going to support it and we'll all move on and it's not going to be a big deal."
[01:11:21.400 --> 01:11:26.960]   So you know the problem with this is that I understand what you're saying and I think
[01:11:26.960 --> 01:11:34.080]   a lot of people share that sentiment that you can trust politicians to do the right thing.
[01:11:34.080 --> 01:11:39.200]   And everyone who is an expert in their field is going to find issues with any law that
[01:11:39.200 --> 01:11:40.800]   concerns their field.
[01:11:40.800 --> 01:11:46.160]   The problem is, if you go that route, then you just sit down and cry and don't write
[01:11:46.160 --> 01:11:49.400]   any law about anything anywhere ever.
[01:11:49.400 --> 01:11:55.480]   And that can make us strong basis for regulation in the United States, giving us much better
[01:11:55.480 --> 01:11:57.160]   auto safety, right?
[01:11:57.160 --> 01:11:59.640]   Without seat belt regulations and...
[01:11:59.640 --> 01:12:00.640]   Exactly.
[01:12:00.640 --> 01:12:01.640]   They say...
[01:12:01.640 --> 01:12:03.840]   And millions of lives.
[01:12:03.840 --> 01:12:04.840]   And there are...
[01:12:04.840 --> 01:12:05.840]   By the way, these are the only cookies...
[01:12:05.840 --> 01:12:06.840]   These are the only cookies.
[01:12:06.840 --> 01:12:08.720]   These are the only cookies.
[01:12:08.720 --> 01:12:13.600]   I support the Tim Tams brought to us by our Australian friends.
[01:12:13.600 --> 01:12:14.600]   Thank you very much.
[01:12:14.600 --> 01:12:15.600]   These are great.
[01:12:15.600 --> 01:12:16.600]   So good.
[01:12:16.600 --> 01:12:17.600]   Thank you.
[01:12:17.600 --> 01:12:19.360]   Patrick, you always defend regulations.
[01:12:19.360 --> 01:12:23.640]   You always bring you on with some libertarian American.
[01:12:23.640 --> 01:12:29.680]   I'm just government is bad.
[01:12:29.680 --> 01:12:32.480]   You can't always have perfect regulations.
[01:12:32.480 --> 01:12:37.400]   Probably you're going to have a lot of issues with them and I certainly do as well.
[01:12:37.400 --> 01:12:39.800]   But the alternative is just worse.
[01:12:39.800 --> 01:12:41.520]   So I agree.
[01:12:41.520 --> 01:12:47.880]   You can't have the perfect situation, so you have to support the least bad.
[01:12:47.880 --> 01:12:50.040]   Maybe GDPR isn't perfect.
[01:12:50.040 --> 01:12:54.480]   Maybe the charger USB-C law isn't perfect.
[01:12:54.480 --> 01:12:55.920]   Maybe another one isn't perfect.
[01:12:55.920 --> 01:12:58.360]   The cookie or the right to be forgotten.
[01:12:58.360 --> 01:13:03.760]   But if you hate all of them and tele-government don't legislate anything, then you end up
[01:13:03.760 --> 01:13:08.640]   in another extreme, which I think is the US, where there are a lot of serious issues which
[01:13:08.640 --> 01:13:14.000]   you were talking about all the time on these shows.
[01:13:14.000 --> 01:13:15.680]   No, I mean, this is it.
[01:13:15.680 --> 01:13:20.040]   You've got to have regulation and they've got to be enforced with actual fines, which
[01:13:20.040 --> 01:13:21.800]   people are going to be scared of.
[01:13:21.800 --> 01:13:26.760]   I mean, with the whole Facebook saga, which has still fighting in the courts, by the way,
[01:13:26.760 --> 01:13:30.080]   five billion of fines for Facebook, they were laughing.
[01:13:30.080 --> 01:13:31.520]   They'd already satisfied three billion.
[01:13:31.520 --> 01:13:35.520]   That cost them less than three months profit and their share price rocked it when they found
[01:13:35.520 --> 01:13:38.080]   out they were going to get away with that extra regulation.
[01:13:38.080 --> 01:13:41.640]   This is the kind of thing that just doesn't work and we're all going to get shafted by
[01:13:41.640 --> 01:13:42.640]   it.
[01:13:42.640 --> 01:13:48.920]   Let me take a little break and we will have more on that note.
[01:13:48.920 --> 01:13:54.880]   With our guest, Patrick Bejaw from French Spin and Le Ronde vous tech, French Spin.com.
[01:13:54.880 --> 01:13:56.200]   I said FR before.
[01:13:56.200 --> 01:13:57.800]   What would I get at French Spin.FR?
[01:13:57.800 --> 01:13:59.760]   Would that be French shows?
[01:13:59.760 --> 01:14:00.760]   Yeah.
[01:14:00.760 --> 01:14:03.560]   And then at .com you get the English shows.
[01:14:03.560 --> 01:14:04.560]   Okay.
[01:14:04.560 --> 01:14:05.560]   So there you go.
[01:14:05.560 --> 01:14:06.560]   There you have it.
[01:14:06.560 --> 01:14:08.320]   Good way to learn, by the way, good way to learn French.
[01:14:08.320 --> 01:14:10.360]   Listen to French Spin.FR.
[01:14:10.360 --> 01:14:11.360]   Yes.
[01:14:11.360 --> 01:14:18.080]   On L'Honté vous tech, I am usually the right wing nut that defends.
[01:14:18.080 --> 01:14:19.080]   Wow.
[01:14:19.080 --> 01:14:22.320]   It's all relative, isn't it?
[01:14:22.320 --> 01:14:25.000]   Isn't there a strike going on in France right now?
[01:14:25.000 --> 01:14:26.000]   Oh, yes.
[01:14:26.000 --> 01:14:29.160]   There's always a strike going on in France.
[01:14:29.160 --> 01:14:31.280]   That one is the strike.
[01:14:31.280 --> 01:14:32.280]   Yeah.
[01:14:32.280 --> 01:14:34.240]   What strike is it?
[01:14:34.240 --> 01:14:40.400]   The government is trying to reform the retirement system and it's not going over well.
[01:14:40.400 --> 01:14:41.680]   The strike has been going on.
[01:14:41.680 --> 01:14:47.000]   It's not a general strike, but a lot of the transportation is on strike and it's been
[01:14:47.000 --> 01:14:50.280]   going on for five or six weeks now.
[01:14:50.280 --> 01:14:57.200]   It's getting a little bit less strong, so it seems like it might subside, but it's the
[01:14:57.200 --> 01:14:59.960]   longest one we've had and we've had a lot.
[01:14:59.960 --> 01:15:00.960]   Yeah.
[01:15:00.960 --> 01:15:02.440]   My mother's down in France at the moment.
[01:15:02.440 --> 01:15:04.600]   She was worried that she was going to be able to make it down.
[01:15:04.600 --> 01:15:06.000]   But perhaps you can correct me on this.
[01:15:06.000 --> 01:15:13.520]   She was saying that French train drivers under current rules can retire on 90% salary at 58.
[01:15:13.520 --> 01:15:14.520]   Is that correct?
[01:15:14.520 --> 01:15:15.520]   Yes.
[01:15:15.520 --> 01:15:16.520]   That sounds very low.
[01:15:16.520 --> 01:15:17.520]   A lot.
[01:15:17.520 --> 01:15:19.520]   I'm so fond of that.
[01:15:19.520 --> 01:15:20.520]   It is.
[01:15:20.520 --> 01:15:26.320]   I'm not sure exactly what age is.
[01:15:26.320 --> 01:15:29.520]   I think it's pretty low indeed, something like that.
[01:15:29.520 --> 01:15:37.720]   And it comes from when they had to actually shovel coal in the furnace on the train.
[01:15:37.720 --> 01:15:39.280]   I should stop throwing this show.
[01:15:39.280 --> 01:15:40.280]   I should get a...
[01:15:40.280 --> 01:15:43.400]   It's not coal, Leo.
[01:15:43.400 --> 01:15:48.440]   I would like to get 90% salary at my age.
[01:15:48.440 --> 01:15:50.160]   Well, anyway, enjoy.
[01:15:50.160 --> 01:15:51.160]   I guess you don't.
[01:15:51.160 --> 01:15:52.840]   Do the finish?
[01:15:52.840 --> 01:15:54.400]   Do the fins ever strike?
[01:15:54.400 --> 01:15:55.400]   No.
[01:15:55.400 --> 01:16:03.640]   There was a strike maybe a month ago in the postal service.
[01:16:03.640 --> 01:16:05.280]   But it's very rare.
[01:16:05.280 --> 01:16:10.360]   It's the first one I've heard about since I've been living here for two or three years.
[01:16:10.360 --> 01:16:11.360]   So it's rare.
[01:16:11.360 --> 01:16:12.360]   But it does happen.
[01:16:12.360 --> 01:16:16.920]   Any more yellow jacket protesters that over?
[01:16:16.920 --> 01:16:22.440]   The people make yellow jackets when I'm struggling.
[01:16:22.440 --> 01:16:24.480]   It kind of merged with this movement.
[01:16:24.480 --> 01:16:28.160]   Which is an audio.
[01:16:28.160 --> 01:16:31.120]   Our show today brought to you by FreshBooks.
[01:16:31.120 --> 01:16:37.480]   If you are a freelancer, it's up to you to get your pension together, to get your act
[01:16:37.480 --> 01:16:39.080]   together, to get your books together.
[01:16:39.080 --> 01:16:42.160]   And that's why I ran the FreshBooks.
[01:16:42.160 --> 01:16:46.080]   This has actually been now 15 years since I started using FreshBooks.
[01:16:46.080 --> 01:16:47.440]   I had to send out invoices.
[01:16:47.440 --> 01:16:48.440]   I hated it.
[01:16:48.440 --> 01:16:49.440]   It was painful.
[01:16:49.440 --> 01:16:54.280]   Turns out, as much as people hate paying bills at the end of every month, the people
[01:16:54.280 --> 01:16:58.680]   who send you the bills, at least if your freelancers hate sending the bills just as much.
[01:16:58.680 --> 01:17:00.000]   FreshBooks saved my bacon.
[01:17:00.000 --> 01:17:04.360]   They made it easy for me to make beautiful professional looking invoices.
[01:17:04.360 --> 01:17:06.680]   But then something magical happened.
[01:17:06.680 --> 01:17:12.520]   In the process of making the invoices, putting the expense report into the invoice by taking
[01:17:12.520 --> 01:17:18.680]   pictures of receipts, I actually was doing, don't tell anybody, accounting.
[01:17:18.680 --> 01:17:22.960]   I was actually doing the accounts receivable, the accounts received.
[01:17:22.960 --> 01:17:25.120]   I was doing expenses.
[01:17:25.120 --> 01:17:28.640]   The beauty part about FreshBooks with that, just doing the things you would normally
[01:17:28.640 --> 01:17:33.480]   do, suddenly you can go on the front page of your FreshBooks account and see whether
[01:17:33.480 --> 01:17:36.520]   you made money this month, this week, this year.
[01:17:36.520 --> 01:17:40.360]   I didn't even know whether I was making money until tax time.
[01:17:40.360 --> 01:17:42.680]   Why be surprised at tax time?
[01:17:42.680 --> 01:17:48.320]   FreshBooks is always adding new features because it's a SaaS, a software as a service,
[01:17:48.320 --> 01:17:50.480]   so you use it online.
[01:17:50.480 --> 01:17:54.440]   Not only get invoices out the door faster, you can create customizable proposals that
[01:17:54.440 --> 01:17:56.400]   will impress your clients.
[01:17:56.400 --> 01:18:00.080]   You can give clients the ability to approve a proposal, but just clicking because it's
[01:18:00.080 --> 01:18:01.080]   a website.
[01:18:01.080 --> 01:18:02.320]   They can click on it.
[01:18:02.320 --> 01:18:05.120]   You can view and respond to client feedback about an estimate.
[01:18:05.120 --> 01:18:07.840]   You can preview estimates and quotes before you send them off.
[01:18:07.840 --> 01:18:09.560]   You can easily add discounts.
[01:18:09.560 --> 01:18:11.200]   You can send estimates in any currency.
[01:18:11.200 --> 01:18:12.480]   I loved that.
[01:18:12.480 --> 01:18:16.880]   I was setting out invoices in Canadian dollars and that was a pain in the butt for me.
[01:18:16.880 --> 01:18:18.640]   FreshBooks took all the pain out.
[01:18:18.640 --> 01:18:19.640]   They just said, "No, no problem.
[01:18:19.640 --> 01:18:20.640]   We converted."
[01:18:20.640 --> 01:18:25.440]   Create an email and estimate from anywhere within the FreshBooks mobile app.
[01:18:25.440 --> 01:18:26.880]   The mobile app is fantastic.
[01:18:26.880 --> 01:18:32.440]   That's how you take pictures of your receipts and then you get these reports just without
[01:18:32.440 --> 01:18:34.360]   doing any extra effort.
[01:18:34.360 --> 01:18:36.120]   They show you just what you need.
[01:18:36.120 --> 01:18:41.600]   Color-coded breakdown of spending, a summary of the most recent activity, profit, loss,
[01:18:41.600 --> 01:18:42.600]   sales tax.
[01:18:42.600 --> 01:18:46.160]   Coming up on tax time, you're going to need to know how much sales tax you paid.
[01:18:46.160 --> 01:18:49.200]   You can take that discount.
[01:18:49.200 --> 01:18:52.160]   FreshBooks will pay for itself, honestly.
[01:18:52.160 --> 01:18:55.000]   Accounts-aging, payments collected, all that accounting stuff.
[01:18:55.000 --> 01:18:56.080]   I don't even know what it means.
[01:18:56.080 --> 01:18:57.080]   You don't have to.
[01:18:57.080 --> 01:18:58.920]   It just works.
[01:18:58.920 --> 01:19:02.560]   By the way, don't forget, your private data is their top priority.
[01:19:02.560 --> 01:19:07.480]   Of course, protected by 256-bit SSL encryption.
[01:19:07.480 --> 01:19:11.760]   They store everything on secure servers.
[01:19:11.760 --> 01:19:15.960]   You can feel confident in running your business knowing you have the help of FreshBooks and
[01:19:15.960 --> 01:19:19.120]   that they're protecting everything online.
[01:19:19.120 --> 01:19:23.880]   And the best thing, Leo, the best thing of all, I use it for everything.
[01:19:23.880 --> 01:19:25.440]   That's the only way I do invoicing.
[01:19:25.440 --> 01:19:29.000]   You send an invoice and you always think, what if it's sometimes emailed?
[01:19:29.000 --> 01:19:30.000]   It's lost.
[01:19:30.000 --> 01:19:33.760]   I send a VML as an attachment, but it tells you below the invoice, okay, they opened
[01:19:33.760 --> 01:19:34.760]   it.
[01:19:34.760 --> 01:19:35.760]   You know when they saw it?
[01:19:35.760 --> 01:19:36.760]   Yeah.
[01:19:36.760 --> 01:19:39.760]   They frowned a bit when they saw the amount of your charge, but they went ahead and printed
[01:19:39.760 --> 01:19:40.800]   it and submitted it.
[01:19:40.800 --> 01:19:42.200]   You see updates.
[01:19:42.200 --> 01:19:44.640]   You also get paid fast because they can pay.
[01:19:44.640 --> 01:19:46.880]   In the invoice, they hate paying bills, right?
[01:19:46.880 --> 01:19:47.880]   Everybody does.
[01:19:47.880 --> 01:19:51.600]   But if it's easy, it gets it off their desk, so they just pay you right away.
[01:19:51.600 --> 01:19:53.200]   That by itself helps a lot.
[01:19:53.200 --> 01:19:55.760]   There's no guesswork.
[01:19:55.760 --> 01:19:59.880]   FreshBooks estimates and reports tell you exactly what's going on, what's going to
[01:19:59.880 --> 01:20:00.880]   go on.
[01:20:00.880 --> 01:20:01.880]   You got to try it.
[01:20:01.880 --> 01:20:02.880]   FreshBooks.com/twit.
[01:20:02.880 --> 01:20:05.320]   Enter this week in Tech and then how did you hear about a section?
[01:20:05.320 --> 01:20:06.960]   You'll get 30 days free.
[01:20:06.960 --> 01:20:07.960]   You're going to get hooked.
[01:20:07.960 --> 01:20:08.960]   This is the year.
[01:20:08.960 --> 01:20:09.960]   Get it all in order.
[01:20:09.960 --> 01:20:10.960]   FreshBooks.com/twit.
[01:20:10.960 --> 01:20:16.640]   As a freelancer, you know, having that, you've definitely read and printed this invoice when
[01:20:16.640 --> 01:20:20.040]   it comes to arguing over late payment of invoices, that stuff's gold.
[01:20:20.040 --> 01:20:22.880]   It has automatic late payment thing.
[01:20:22.880 --> 01:20:25.840]   You know, saying, "Hey, it makes it off."
[01:20:25.840 --> 01:20:31.080]   It's great for anybody with a spouse because your spouse will say, "Did they get the invoice?"
[01:20:31.080 --> 01:20:34.480]   Because, you know, if you go on vacation, you can go, "Yes."
[01:20:34.480 --> 01:20:35.480]   It's nice.
[01:20:35.480 --> 01:20:38.760]   Also, coming back to regulation, you know, in the UK, I don't know what it's like in
[01:20:38.760 --> 01:20:42.800]   the rest of Europe, but if someone over doesn't pay their invoice for 90 days, you can charge
[01:20:42.800 --> 01:20:44.040]   them in interest.
[01:20:44.040 --> 01:20:45.040]   And if you've got that proof, you can start--
[01:20:45.040 --> 01:20:46.040]   Oh, I like that.
[01:20:46.040 --> 01:20:47.040]   Yeah.
[01:20:47.040 --> 01:20:48.040]   Nice.
[01:20:48.040 --> 01:20:50.040]   Speaking of regulation, okay.
[01:20:50.040 --> 01:20:55.480]   Sooner Pichai, the new CEO of Alphabet, he was, of course, for a long time, the CEO
[01:20:55.480 --> 01:20:59.960]   of Google as well, is calling for regulation of AI.
[01:20:59.960 --> 01:21:02.080]   He published this in the Financial Times.
[01:21:02.080 --> 01:21:04.560]   I can't pull that up because he's got to pay--
[01:21:04.560 --> 01:21:05.560]   Paywall.
[01:21:05.560 --> 01:21:07.080]   Yeah.
[01:21:07.080 --> 01:21:10.960]   He said, "Artificial intelligence needs to be regulated.
[01:21:10.960 --> 01:21:12.560]   There's no question in my mind.
[01:21:12.560 --> 01:21:13.880]   It's too important not to.
[01:21:13.880 --> 01:21:18.200]   The only question is how to approach it."
[01:21:18.200 --> 01:21:19.200]   And that's--
[01:21:19.200 --> 01:21:20.200]   Of course, yeah.
[01:21:20.200 --> 01:21:21.200]   Easy to say, regulate it.
[01:21:21.200 --> 01:21:22.560]   A lot harder to say, "How?"
[01:21:22.560 --> 01:21:23.560]   Yeah.
[01:21:23.560 --> 01:21:29.680]   I mean, it's very handy for Google to pop up and say this now because we do need regulation
[01:21:29.680 --> 01:21:30.680]   of AI.
[01:21:30.680 --> 01:21:31.680]   And what are you saying?
[01:21:31.680 --> 01:21:34.280]   But I don't know if we know what to say, what to do, how to do it.
[01:21:34.280 --> 01:21:35.560]   I don't think we know enough now.
[01:21:35.560 --> 01:21:37.360]   Well, I mean, we've got some interesting cases.
[01:21:37.360 --> 01:21:42.200]   Illinois at the moment has probably the strongest biometric safety laws in the US, which is
[01:21:42.200 --> 01:21:45.760]   why Clearview's being sued there at the moment because they've said, "If you're going to
[01:21:45.760 --> 01:21:50.800]   use my biometric information, you need to ask me first," which seems kind of logical.
[01:21:50.800 --> 01:21:53.560]   Call me a wild, wacky regulator.
[01:21:53.560 --> 01:21:57.200]   But if someone's using my personal data, I want to say, and it's just whether or not
[01:21:57.200 --> 01:21:58.200]   that works or that should happen.
[01:21:58.200 --> 01:22:02.000]   I have to say, Bruce Schneier had a really good opinion piece in the New York Times in
[01:22:02.000 --> 01:22:07.200]   which he said, "It's a mistake to focus on face recognition."
[01:22:07.200 --> 01:22:08.200]   Yes.
[01:22:08.200 --> 01:22:09.200]   Yeah.
[01:22:09.200 --> 01:22:12.120]   Because that's just the tip of a very big iceberg.
[01:22:12.120 --> 01:22:13.120]   That's right.
[01:22:13.120 --> 01:22:16.520]   He says, "The issue is we're being tracked in thousands of ways, whether it's the MAC
[01:22:16.520 --> 01:22:23.000]   address on our phone, our heartbeat and gate can be measured at hundreds of feet by lasers.
[01:22:23.000 --> 01:22:25.360]   We can be identified in so many ways."
[01:22:25.360 --> 01:22:26.360]   That's right.
[01:22:26.360 --> 01:22:35.600]   The number of ID, of AI-based ID, is multiple versions at once.
[01:22:35.600 --> 01:22:42.320]   Pentagon put out a call for contracts, whatever they call it, DARPA, for a system that would
[01:22:42.320 --> 01:22:47.240]   track somebody at 500 yards using thermal imaging.
[01:22:47.240 --> 01:22:53.800]   Thermal imaging can track somebody in a fog, both face ID and gate recognition and other
[01:22:53.800 --> 01:22:55.800]   things.
[01:22:55.800 --> 01:22:59.400]   Through a windshield, their specs are amazing.
[01:22:59.400 --> 01:23:04.480]   Of course, anything the Pentagon does, they will have this in the field within a year and
[01:23:04.480 --> 01:23:07.960]   it will be available at Best Buy within seven years.
[01:23:07.960 --> 01:23:11.240]   That's how it goes.
[01:23:11.240 --> 01:23:18.520]   The thing is though, face recognition is being used everywhere now and more and more.
[01:23:18.520 --> 01:23:22.840]   I think it's not unreasonable to say, "All right, just wait a second.
[01:23:22.840 --> 01:23:25.280]   What do we do about this?"
[01:23:25.280 --> 01:23:30.560]   On the line, maybe it's going to be five years from now, there are going to be other ways
[01:23:30.560 --> 01:23:35.680]   to track people as well and maybe we need to address them then.
[01:23:35.680 --> 01:23:44.800]   But if you just let face recognition, facial recognition run rampant for another five years
[01:23:44.800 --> 01:23:51.560]   as you wait for everything else to be figured out, I don't think I like the picture I'm starting
[01:23:51.560 --> 01:23:52.560]   to see there.
[01:23:52.560 --> 01:23:55.240]   I'm not making a case for non-regulation.
[01:23:55.240 --> 01:24:01.240]   I'm just saying that basically I'm basically alerting because I wrote a piece about this
[01:24:01.240 --> 01:24:06.400]   also behind the paywall at Insider Pro on January 17th.
[01:24:06.400 --> 01:24:14.440]   The facial recognition backlash basically has the biggest source of it is the fact that
[01:24:14.440 --> 01:24:18.840]   AI recognizes people of different skin colors and races unevenly.
[01:24:18.840 --> 01:24:24.320]   So if police are using it, then there's a fear that black people specifically will be more
[01:24:24.320 --> 01:24:27.560]   likely to be falsely accused of things, et cetera, et cetera.
[01:24:27.560 --> 01:24:33.360]   However, the fact that AI is imperfect is a temporary thing.
[01:24:33.360 --> 01:24:37.960]   AI recognition is going to get to be 99.9% accurate at some point.
[01:24:37.960 --> 01:24:41.920]   And when hoax will get rid of the biases in here and it doesn't do as well with women
[01:24:41.920 --> 01:24:44.960]   and people of color because it's trained mostly with white men.
[01:24:44.960 --> 01:24:45.960]   Exactly.
[01:24:45.960 --> 01:24:47.120]   Presumably that will get better.
[01:24:47.120 --> 01:24:51.600]   I mean, in this country, NIST has just finished doing a series of studies into the realms of
[01:24:51.600 --> 01:24:53.400]   efficiency of different AI systems.
[01:24:53.400 --> 01:24:58.080]   If you're using an AI built in China, for example, in Japan, it's greater recognizing
[01:24:58.080 --> 01:25:01.000]   people from Southeast Asia, but not so great at white men like people.
[01:25:01.000 --> 01:25:04.400]   If you do want to vote in America, it's great on white people, but not so good on black
[01:25:04.400 --> 01:25:05.400]   or Asian.
[01:25:05.400 --> 01:25:09.080]   You know, these things are going to work themselves out and it's going to take some time.
[01:25:09.080 --> 01:25:10.080]   You're right.
[01:25:10.080 --> 01:25:11.360]   It's going to become very accurate.
[01:25:11.360 --> 01:25:17.480]   Are you guys subscribing to the school of thought that says any technology that can be used
[01:25:17.480 --> 01:25:18.480]   will be used?
[01:25:18.480 --> 01:25:21.600]   Like it's just it's just impossible for us to invent this and NIST not use it.
[01:25:21.600 --> 01:25:27.120]   Well, it is being used right now and it's not perfect, but as it gets better, it would
[01:25:27.120 --> 01:25:28.120]   be more used.
[01:25:28.120 --> 01:25:32.280]   The reason the reason I based the identification of all kinds, including face recognition, is
[01:25:32.280 --> 01:25:37.080]   going to take over and become universal is because everybody's going to want it.
[01:25:37.080 --> 01:25:40.280]   But the problem with face recognition is not face recognition.
[01:25:40.280 --> 01:25:44.880]   It's the problem is the authoritarian government says in the case of China that you use it.
[01:25:44.880 --> 01:25:45.880]   Isn't it?
[01:25:45.880 --> 01:25:49.400]   I mean, isn't that what we should be worried about is how it's used not the fact that it
[01:25:49.400 --> 01:25:50.400]   exists?
[01:25:50.400 --> 01:25:56.120]   Well, the rub is if you use it, then someone's going to use it in that way.
[01:25:56.120 --> 01:25:59.360]   And that's why the concern is there.
[01:25:59.360 --> 01:26:06.160]   And that's why it's not only about biases, which of course is a huge issue.
[01:26:06.160 --> 01:26:11.760]   And you know, skin color that changes how reliable it is.
[01:26:11.760 --> 01:26:15.040]   But it's also about using it at all.
[01:26:15.040 --> 01:26:19.440]   I do wonder though, if we can do anything about it because.
[01:26:19.440 --> 01:26:21.400]   Well, let me tell you how.
[01:26:21.400 --> 01:26:27.480]   I'm working on a long form piece on smart streetlights.
[01:26:27.480 --> 01:26:31.600]   And this is something that's affecting cities all around the US and around the world.
[01:26:31.600 --> 01:26:33.440]   But basically, here's how it goes.
[01:26:33.440 --> 01:26:36.840]   A city goes, oh, we're spending all this money on electricity for these lights.
[01:26:36.840 --> 01:26:39.560]   They're incandescent with a much more efficient LED bulbs.
[01:26:39.560 --> 01:26:40.560]   Let's replace it.
[01:26:40.560 --> 01:26:46.200]   And if these light things are internet connected, then we can see which bulbs are out.
[01:26:46.200 --> 01:26:49.640]   And since it's internet connected, why don't we put some sensors in there to check smog?
[01:26:49.640 --> 01:26:53.120]   And we give a cameras in there to check traffic and foot traffic and parking.
[01:26:53.120 --> 01:26:54.120]   And we'll have all these.
[01:26:54.120 --> 01:26:55.440]   And one thing leads to another.
[01:26:55.440 --> 01:26:57.720]   And next thing you know, it's freaking Orwell.
[01:26:57.720 --> 01:27:01.680]   The city is tracking everybody with face recognition mapping where everybody goes.
[01:27:01.680 --> 01:27:05.800]   The cameras are getting license plates, faces, gate recognition, all this kind of stuff.
[01:27:05.800 --> 01:27:08.640]   And it's a slippery slope to like, oh, look at that.
[01:27:08.640 --> 01:27:10.840]   And then the city gets addicted to the money they made.
[01:27:10.840 --> 01:27:13.040]   They put a red light camera on every block.
[01:27:13.040 --> 01:27:13.880]   You know what I mean?
[01:27:13.880 --> 01:27:15.200]   It's like it's slippery slope.
[01:27:15.200 --> 01:27:16.360]   So how do we arrest them?
[01:27:16.360 --> 01:27:21.560]   We had the same thing in the UK because the UK invested very heavily in CCTV systems
[01:27:21.560 --> 01:27:26.040]   in the '90s because we had the IRA threat and it was sold as the next big thing.
[01:27:26.040 --> 01:27:29.480]   And then, yeah, before you know it, they're putting cameras on there.
[01:27:29.480 --> 01:27:30.840]   They're putting microphones on there.
[01:27:30.840 --> 01:27:31.840]   That's another thing.
[01:27:31.840 --> 01:27:32.840]   Well, London is...
[01:27:32.840 --> 01:27:40.040]   The Metro Police in London just announced they're going to use live facial recognition as a
[01:27:40.040 --> 01:27:41.040]   test for example.
[01:27:41.040 --> 01:27:42.040]   Exactly.
[01:27:42.040 --> 01:27:45.120]   And the last time they tried it, they got a 99% failure rate.
[01:27:45.120 --> 01:27:46.120]   I remember that.
[01:27:46.120 --> 01:27:47.120]   It was just...
[01:27:47.120 --> 01:27:48.120]   Yeah.
[01:27:48.120 --> 01:27:49.120]   It was a...
[01:27:49.120 --> 01:27:50.120]   We're getting better.
[01:27:50.120 --> 01:27:52.040]   So first of all, why just a few hours a day?
[01:27:52.040 --> 01:27:53.040]   I don't understand.
[01:27:53.040 --> 01:27:54.640]   I think it's a test.
[01:27:54.640 --> 01:27:57.440]   Spoonful of sugar helps the medicines.
[01:27:57.440 --> 01:28:00.800]   So ease into it.
[01:28:00.800 --> 01:28:05.760]   It's LFR live facial recognition technology.
[01:28:05.760 --> 01:28:07.720]   And what they're trying to do is what?
[01:28:07.720 --> 01:28:11.160]   Stop crime or catch criminals with warrants?
[01:28:11.160 --> 01:28:12.160]   What are they trying to do?
[01:28:12.160 --> 01:28:13.160]   Well, okay.
[01:28:13.160 --> 01:28:14.160]   Catch criminals.
[01:28:14.160 --> 01:28:15.160]   Yeah.
[01:28:15.160 --> 01:28:17.760]   I mean, it's basically down to, you know, we could identify if someone's gotten outstanding.
[01:28:17.760 --> 01:28:19.600]   Warren against them, that sort of thing.
[01:28:19.600 --> 01:28:24.800]   But one thing we learned with CCTV cameras is that it doesn't stop the crime from happening.
[01:28:24.800 --> 01:28:28.480]   It just makes it slightly easier to identify who did it.
[01:28:28.480 --> 01:28:29.480]   You know, so...
[01:28:29.480 --> 01:28:32.480]   The camera won't stop you being mugged.
[01:28:32.480 --> 01:28:35.560]   You know, you can still get mugged and have the living hell beaten out of you, but they
[01:28:35.560 --> 01:28:38.880]   might have a slightly better chance of finding out the person who did it.
[01:28:38.880 --> 01:28:46.400]   Well, down the line when would the criminals understand that it is more likely they will
[01:28:46.400 --> 01:28:50.520]   be caught and it might reduce crime.
[01:28:50.520 --> 01:28:57.000]   But I think that is potentially an interesting approach to this.
[01:28:57.000 --> 01:29:04.680]   The arguments for and against are both valid, you know, saying it helps fight crime.
[01:29:04.680 --> 01:29:10.680]   If it's true, then maybe we should have some of that technology put in place.
[01:29:10.680 --> 01:29:17.000]   The fact that it reduces freedoms because it reduces privacy is also a valid argument.
[01:29:17.000 --> 01:29:18.760]   That's a more abstract argument.
[01:29:18.760 --> 01:29:24.200]   I mean, I think there's a very concrete argument which is offered by Assistant Commissioner
[01:29:24.200 --> 01:29:27.040]   at the Metropolitan Police Nick F. Grave.
[01:29:27.040 --> 01:29:31.200]   He says as a modern police force, I believe we have a duty to use new technologies to
[01:29:31.200 --> 01:29:34.040]   keep people safe in London.
[01:29:34.040 --> 01:29:37.920]   Every day our police officers are briefed about suspects they should look out for.
[01:29:37.920 --> 01:29:40.640]   LFR improves the effectiveness of this tactic.
[01:29:40.640 --> 01:29:45.720]   Similarly, if it can help locate missing children or vulnerable adults swiftly and keep them
[01:29:45.720 --> 01:29:49.480]   from harm and exploitation, we have a duty to deploy.
[01:29:49.480 --> 01:29:51.160]   I think that's concrete.
[01:29:51.160 --> 01:29:52.160]   That's not abstract.
[01:29:52.160 --> 01:29:57.520]   Compared to the abstract, oh, but our privacy be invaded, I think the concrete benefits
[01:29:57.520 --> 01:29:58.800]   kind of outweigh the abstract.
[01:29:58.800 --> 01:30:01.480]   There's a larger conversation about policing.
[01:30:01.480 --> 01:30:07.360]   Policing is the only undemocratic aspect of municipal government.
[01:30:07.360 --> 01:30:11.520]   The public should be telling the police how the public wants to be policed.
[01:30:11.520 --> 01:30:16.440]   The way that anybody involved with security or policing approaches the job is like, oh,
[01:30:16.440 --> 01:30:20.240]   we're doing safety and security and therefore we decide how it all goes and we're going
[01:30:20.240 --> 01:30:21.240]   to get our way.
[01:30:21.240 --> 01:30:24.880]   As a journalist, my job would be so much easier if there was a law that said when I called
[01:30:24.880 --> 01:30:28.720]   Jeff Bezos, he'd better answer the phone and that would make my job easier.
[01:30:28.720 --> 01:30:32.200]   My professional men have to be balanced against other demands.
[01:30:32.200 --> 01:30:34.120]   But we give the police that power.
[01:30:34.120 --> 01:30:35.120]   I think we have.
[01:30:35.120 --> 01:30:36.880]   I don't think we did give them that power.
[01:30:36.880 --> 01:30:37.880]   I think we do.
[01:30:37.880 --> 01:30:45.240]   We want to be safe in our homes and if this helps us, I think there is clearly a cost,
[01:30:45.240 --> 01:30:48.000]   but the cost is minor compared to the benefit.
[01:30:48.000 --> 01:30:49.000]   Well, that's the claim.
[01:30:49.000 --> 01:30:53.880]   I know what the benefit is and what we need is once those things because they are happening
[01:30:53.880 --> 01:30:56.520]   and they're going to happen at least as tests.
[01:30:56.520 --> 01:31:01.720]   What we need is to know how well they work because we keep having those theoretical conversations.
[01:31:01.720 --> 01:31:03.320]   Oh, it would make people safer.
[01:31:03.320 --> 01:31:05.000]   It would invade our privacy.
[01:31:05.000 --> 01:31:07.160]   We don't know how safer we are.
[01:31:07.160 --> 01:31:13.640]   I would love if the London Police Department comes out after six months of tests and says,
[01:31:13.640 --> 01:31:21.480]   "Okay, listen, we've managed to arrest 17 more people thanks to this system specifically
[01:31:21.480 --> 01:31:23.480]   and it's audited and it's verified.
[01:31:23.480 --> 01:31:24.480]   It's truthful."
[01:31:24.480 --> 01:31:27.160]   Then that's a specific kind of conversation.
[01:31:27.160 --> 01:31:31.680]   If they say we've arrested two people and one of them was released because it was wrong,
[01:31:31.680 --> 01:31:33.360]   then it's a different kind of conversation.
[01:31:33.360 --> 01:31:36.040]   But you can't tell that till you do the test.
[01:31:36.040 --> 01:31:38.040]   You got to do the test.
[01:31:38.040 --> 01:31:39.040]   Exactly.
[01:31:39.040 --> 01:31:44.720]   It's a good point, Patrick, but my concern is the fact that it's almost inevitable that
[01:31:44.720 --> 01:31:46.560]   these things will be perfected.
[01:31:46.560 --> 01:31:47.560]   That's the world I'm concerned about.
[01:31:47.560 --> 01:31:51.760]   I'm concerned about my notion of report where I'm just related to works.
[01:31:51.760 --> 01:31:53.600]   Let's stipulate it works.
[01:31:53.600 --> 01:31:54.960]   Isn't that a better world?
[01:31:54.960 --> 01:31:59.760]   Isn't it true that when you're in a city where you're not safe, that it is a significant
[01:31:59.760 --> 01:32:06.880]   burden on your comfort, your stress level, your ability to get things done and when you're
[01:32:06.880 --> 01:32:08.040]   in a safer city?
[01:32:08.040 --> 01:32:09.040]   Do you not watch people who are happy?
[01:32:09.040 --> 01:32:10.040]   People are happy.
[01:32:10.040 --> 01:32:11.040]   You're in movies.
[01:32:11.040 --> 01:32:12.040]   Didn't you see "Dentalistic Man?"
[01:32:12.040 --> 01:32:14.640]   Where every time he used a cuss word he had to get the paper.
[01:32:14.640 --> 01:32:16.720]   Well, that's not nobody's proposing that.
[01:32:16.720 --> 01:32:17.720]   That's what...
[01:32:17.720 --> 01:32:18.720]   This is Mission Creep.
[01:32:18.720 --> 01:32:20.080]   This is where we do weigh in.
[01:32:20.080 --> 01:32:22.720]   And we get to choose which laws are enforced.
[01:32:22.720 --> 01:32:24.920]   Look, this is where the public does weigh in.
[01:32:24.920 --> 01:32:25.920]   I've just driven up a piece.
[01:32:25.920 --> 01:32:26.920]   That's way to explain.
[01:32:26.920 --> 01:32:27.920]   But we don't get to choose.
[01:32:27.920 --> 01:32:28.920]   Okay.
[01:32:28.920 --> 01:32:29.920]   Well, we're supposed to get to the Jews.
[01:32:29.920 --> 01:32:30.920]   That's called legislative oversight.
[01:32:30.920 --> 01:32:31.920]   Go ahead.
[01:32:31.920 --> 01:32:37.360]   But no, I mean, I've just driven up on the freeway and the police, if we're carrying
[01:32:37.360 --> 01:32:41.760]   phones with GPS and which have movement trackers in, about half the people on that freeway
[01:32:41.760 --> 01:32:43.160]   would have been getting speeding tickets.
[01:32:43.160 --> 01:32:44.160]   Good.
[01:32:44.160 --> 01:32:45.160]   They should be stopped.
[01:32:45.160 --> 01:32:49.400]   Was it Lisa who posted a picture of this military police vehicle in Petaloma?
[01:32:49.400 --> 01:32:51.200]   Yeah, Petaloma apparently has a tank.
[01:32:51.200 --> 01:32:52.200]   Did you approve that?
[01:32:52.200 --> 01:32:53.200]   What?
[01:32:53.200 --> 01:32:54.200]   You didn't approve that?
[01:32:54.200 --> 01:32:56.000]   Yes, they have a tank with like, yes.
[01:32:56.000 --> 01:32:59.040]   It's like this assault vehicle that's like you...
[01:32:59.040 --> 01:33:01.120]   This is in case the annual cheese and butter contest.
[01:33:01.120 --> 01:33:05.680]   It was just down at Street View's Bud House.
[01:33:05.680 --> 01:33:09.440]   Well they were worried because there was a, there were arrests in people they knew were
[01:33:09.440 --> 01:33:10.440]   armed.
[01:33:10.440 --> 01:33:11.960]   There wasn't an active shooter case.
[01:33:11.960 --> 01:33:13.200]   There wasn't anything going on.
[01:33:13.200 --> 01:33:14.520]   They just, these guys are armed.
[01:33:14.520 --> 01:33:15.920]   We're going to arrest them.
[01:33:15.920 --> 01:33:17.160]   So bring in the tank.
[01:33:17.160 --> 01:33:22.720]   And this is actually, I think this is an interesting argument that militarization of local police
[01:33:22.720 --> 01:33:27.240]   in the United States because so much of this gear is made for the armed forces and because
[01:33:27.240 --> 01:33:35.160]   budgets allow a lot of cities, municipalities have basically strategic arms in a surplus
[01:33:35.160 --> 01:33:36.920]   and they get it at a discount.
[01:33:36.920 --> 01:33:37.920]   Yeah.
[01:33:37.920 --> 01:33:41.480]   Unlike the UK where a guy shows up with a Billy Club and a funny hat and that's it.
[01:33:41.480 --> 01:33:43.080]   Okay, just to clarify.
[01:33:43.080 --> 01:33:46.120]   No, 5% of the police are armed.
[01:33:46.120 --> 01:33:51.320]   But if they are armed, they go through extensive training before hand.
[01:33:51.320 --> 01:33:55.520]   If they kill anyone, then they go through two inquiries.
[01:33:55.520 --> 01:33:59.520]   I have a friend who's an armed police officer in the UK and they actually show US training
[01:33:59.520 --> 01:34:04.320]   videos to British Bobbies and saying that's not how you do it.
[01:34:04.320 --> 01:34:08.880]   You don't immediately pump everywhere, everywhere in the area full of bullets.
[01:34:08.880 --> 01:34:11.120]   You fire very carefully and as little as all of them.
[01:34:11.120 --> 01:34:13.240]   To be fair, this is the vehicle.
[01:34:13.240 --> 01:34:14.680]   It's not exactly a tank.
[01:34:14.680 --> 01:34:16.720]   It's kind of scary.
[01:34:16.720 --> 01:34:19.040]   You know, not exactly Andy Griffith.
[01:34:19.040 --> 01:34:20.680]   If I was going to bet that.
[01:34:20.680 --> 01:34:23.640]   Oh, wait, let's get the squad vehicle.
[01:34:23.640 --> 01:34:25.480]   I'll be in it.
[01:34:25.480 --> 01:34:28.120]   Let's go down to the fishing hole.
[01:34:28.120 --> 01:34:33.760]   Can I get back to the policing facial recognition thing with CCTV?
[01:34:33.760 --> 01:34:38.000]   It's just for a second because I think there's a point that needs to be made.
[01:34:38.000 --> 01:34:39.400]   Somebody stole my Tim Tim.
[01:34:39.400 --> 01:34:40.400]   That's the point.
[01:34:40.400 --> 01:34:42.240]   And I want face recognition imagery.
[01:34:42.240 --> 01:34:44.400]   John, pull it up.
[01:34:44.400 --> 01:34:48.120]   This is to be full.
[01:34:48.120 --> 01:34:53.280]   And Leo, knowing who stole your Tim Tam is the benefit.
[01:34:53.280 --> 01:34:55.720]   That's the benefit.
[01:34:55.720 --> 01:35:01.440]   The concern that Mike and others are worried about, legitimately so I would say, is the
[01:35:01.440 --> 01:35:03.600]   other effect, which is no privacy.
[01:35:03.600 --> 01:35:05.840]   And how do you illustrate no privacy?
[01:35:05.840 --> 01:35:12.320]   I think if we ask everyone anywhere, do you behave in your room, in your house, the way
[01:35:12.320 --> 01:35:15.680]   you do in the street?
[01:35:15.680 --> 01:35:20.960]   Everyone would say, no, you don't have a right to privacy in public.
[01:35:20.960 --> 01:35:21.960]   Do you?
[01:35:21.960 --> 01:35:24.240]   No, but that's the question.
[01:35:24.240 --> 01:35:33.880]   Do you feel like, and that's an answer that could be interesting to ask, would you want
[01:35:33.880 --> 01:35:39.520]   everywhere to become as public as the most public place?
[01:35:39.520 --> 01:35:44.360]   And so you don't have the freedom to act the way you would if you knew you weren't being
[01:35:44.360 --> 01:35:45.360]   watched.
[01:35:45.360 --> 01:35:49.560]   And that's not about committed crime, just being yourself.
[01:35:49.560 --> 01:35:53.560]   And I think that is a concern that is important.
[01:35:53.560 --> 01:35:55.400]   When you're in your house, you behave a certain way.
[01:35:55.400 --> 01:36:00.840]   If we put a camera in your house, it's you behave with cameras in our own houses.
[01:36:00.840 --> 01:36:04.960]   I don't want people to urinate in public.
[01:36:04.960 --> 01:36:06.800]   I think it's good to have one.
[01:36:06.800 --> 01:36:09.240]   By the way, apparently we don't have just one tank.
[01:36:09.240 --> 01:36:10.240]   We have two.
[01:36:10.240 --> 01:36:11.240]   Two tanks.
[01:36:11.240 --> 01:36:12.240]   Because here's one of the tanks.
[01:36:12.240 --> 01:36:13.680]   That's Luma is the rough edge of the gas.
[01:36:13.680 --> 01:36:17.000]   By the town of 55,000 people, here's one of the tanks.
[01:36:17.000 --> 01:36:18.000]   Here's the other one.
[01:36:18.000 --> 01:36:19.000]   Oh, I like that one.
[01:36:19.000 --> 01:36:20.000]   That's kind of cool.
[01:36:20.000 --> 01:36:21.000]   I'd be fun to drive that around.
[01:36:21.000 --> 01:36:24.600]   I think actually Alex Jones was driving that around in Richmond.
[01:36:24.600 --> 01:36:25.600]   That was at the Alex Jones.
[01:36:25.600 --> 01:36:28.520]   Just looks like an irregular American car.
[01:36:28.520 --> 01:36:29.520]   I don't know.
[01:36:29.520 --> 01:36:30.520]   It's a car.
[01:36:30.520 --> 01:36:31.520]   A car.
[01:36:31.520 --> 01:36:32.520]   A blizzard.
[01:36:32.520 --> 01:36:36.360]   And if I have the flag going in and out so we'll know a lot.
[01:36:36.360 --> 01:36:39.280]   But that does look like they might have a gun turret on the top.
[01:36:39.280 --> 01:36:40.280]   That's a little concern.
[01:36:40.280 --> 01:36:42.920]   Anti-aircraft because you never know.
[01:36:42.920 --> 01:36:45.800]   Okay, so this we're making fun of this.
[01:36:45.800 --> 01:36:50.000]   But this is a perfect example of Petalema police would say, well this protects our officers
[01:36:50.000 --> 01:36:53.640]   and helps us do a better job of protecting the citizenry of Petalema.
[01:36:53.640 --> 01:36:55.240]   But it also escalates the situation.
[01:36:55.240 --> 01:37:00.400]   It also gives them the ability to shoot down the flying craft.
[01:37:00.400 --> 01:37:07.240]   The whole point of policing when I grew up growing up was that they de-escalated situations.
[01:37:07.240 --> 01:37:10.520]   The whole point of stuff over here, and I have to say the bulk of the police I found
[01:37:10.520 --> 01:37:13.160]   over here is they are trying to dominate the situation.
[01:37:13.160 --> 01:37:14.160]   Right.
[01:37:14.160 --> 01:37:15.160]   Get control of it.
[01:37:15.160 --> 01:37:16.160]   That's poor training.
[01:37:16.160 --> 01:37:17.160]   It's poor policing.
[01:37:17.160 --> 01:37:24.520]   And I think that I do think that the equipment, whether it's surveillance equipment or armored
[01:37:24.520 --> 01:37:28.840]   vehicles, I think it sort of like it takes us to that next level.
[01:37:28.840 --> 01:37:33.000]   Okay, so we're going to use this equipment and you want to catch more bad guys.
[01:37:33.000 --> 01:37:34.400]   You want to be more effective.
[01:37:34.400 --> 01:37:36.440]   Everybody wants to be better at their jobs.
[01:37:36.440 --> 01:37:41.200]   It's just that for some reason when it comes to policing, we don't do a good job of balancing
[01:37:41.200 --> 01:37:44.560]   the need for them to do their jobs against other concerns.
[01:37:44.560 --> 01:37:48.040]   And especially we have to consider this slippery slope problem that we're going to get to
[01:37:48.040 --> 01:37:51.800]   the point where all this recognition is perfected.
[01:37:51.800 --> 01:37:52.800]   Everybody's going to have it.
[01:37:52.800 --> 01:37:53.800]   The banks going to have it.
[01:37:53.800 --> 01:37:54.800]   The stores going to have it.
[01:37:54.800 --> 01:37:55.800]   The street lights are going to have it.
[01:37:55.800 --> 01:37:56.800]   The police.
[01:37:56.800 --> 01:37:58.400]   And so everywhere you go, you're going to be recognized.
[01:37:58.400 --> 01:37:59.400]   And do we want that?
[01:37:59.400 --> 01:38:02.120]   But the thing is, I think a lot of people do want that.
[01:38:02.120 --> 01:38:03.120]   I think so.
[01:38:03.120 --> 01:38:07.680]   If you got a pair of glasses that you could wear and you would never again meet someone
[01:38:07.680 --> 01:38:08.840]   and go, "Oh, I know you all.
[01:38:08.840 --> 01:38:09.840]   What's your name?
[01:38:09.840 --> 01:38:10.840]   What damned if I can remember?"
[01:38:10.840 --> 01:38:12.640]   You've got a little microphone behind you.
[01:38:12.640 --> 01:38:14.520]   It says, "This is so-and-so-and-so."
[01:38:14.520 --> 01:38:15.960]   You worked together three years ago.
[01:38:15.960 --> 01:38:16.960]   She's currently here.
[01:38:16.960 --> 01:38:19.840]   And then that would sell like hotcakes.
[01:38:19.840 --> 01:38:20.840]   And it's--
[01:38:20.840 --> 01:38:26.960]   What would be wrong with this perfected technology if everybody had access to it?
[01:38:26.960 --> 01:38:28.200]   What's the hazard here?
[01:38:28.200 --> 01:38:32.880]   I mean, I know the hazard in some senses is an authoritarian government that uses it
[01:38:32.880 --> 01:38:34.520]   to put down its people.
[01:38:34.520 --> 01:38:37.120]   But that's the hazard, the authoritarian government.
[01:38:37.120 --> 01:38:39.000]   That's a real and genuine hazard.
[01:38:39.000 --> 01:38:41.440]   But what would be the hazard just of the technology?
[01:38:41.440 --> 01:38:43.160]   Why would that be a problem?
[01:38:43.160 --> 01:38:47.640]   Because some of us still believe in freedom and living in a free society.
[01:38:47.640 --> 01:38:48.640]   Why are you not free?
[01:38:48.640 --> 01:38:50.640]   Just because I know your face was fine.
[01:38:50.640 --> 01:38:51.640]   You're not free.
[01:38:51.640 --> 01:38:53.120]   So if I'm-- it's two o'clock in the morning.
[01:38:53.120 --> 01:38:54.120]   You're a hippie.
[01:38:54.120 --> 01:38:55.120]   I'm driving home.
[01:38:55.120 --> 01:38:56.120]   I'm a hippie.
[01:38:56.120 --> 01:38:57.120]   And I'm driving home.
[01:38:57.120 --> 01:39:00.600]   And there's like no cars as far as the eye can see.
[01:39:00.600 --> 01:39:02.400]   And there's a red light.
[01:39:02.400 --> 01:39:03.840]   I'm just going to go.
[01:39:03.840 --> 01:39:06.120]   I make that choice and I want to do that.
[01:39:06.120 --> 01:39:10.240]   If that results in a ticket every single time, 100% of the time--
[01:39:10.240 --> 01:39:12.600]   Because that's an inherently dangerous thing to do.
[01:39:12.600 --> 01:39:13.600]   No, there's no really nothing.
[01:39:13.600 --> 01:39:16.440]   No, there's a rule that you don't go through red lights.
[01:39:16.440 --> 01:39:19.200]   And just because you think there's no one there doesn't mean you're not going to hit
[01:39:19.200 --> 01:39:20.200]   something.
[01:39:20.200 --> 01:39:21.200]   We have to balance--
[01:39:21.200 --> 01:39:23.280]   You should have that discretion.
[01:39:23.280 --> 01:39:24.280]   We have a awful society.
[01:39:24.280 --> 01:39:27.920]   On the one hand, and we want to be free people on the other.
[01:39:27.920 --> 01:39:29.520]   And we have to find that balance.
[01:39:29.520 --> 01:39:33.840]   Giving 100% of the power over to one side takes away that balance.
[01:39:33.840 --> 01:39:36.360]   So you can run red lights in the middle of the night?
[01:39:36.360 --> 01:39:37.360]   Well, it's--
[01:39:37.360 --> 01:39:38.360]   Yes, exactly.
[01:39:38.360 --> 01:39:40.360]   And I think it's--
[01:39:40.360 --> 01:39:41.360]   So you're that guy.
[01:39:41.360 --> 01:39:42.360]   I was wondering if you were that guy.
[01:39:42.360 --> 01:39:43.360]   My wife is arguing to be lost.
[01:39:43.360 --> 01:39:47.240]   I'm probably just arguing to be made through the possibility of transgression.
[01:39:47.240 --> 01:39:51.920]   There's an argument to be made for the possibility of transgression to an extent.
[01:39:51.920 --> 01:39:59.880]   If you live in a society where no transgression is even possible, I think that is something
[01:39:59.880 --> 01:40:01.920]   that is chilling.
[01:40:01.920 --> 01:40:04.760]   And that's where that technology leads potential--
[01:40:04.760 --> 01:40:07.440]   I just want the possibility of transgression, Leo.
[01:40:07.440 --> 01:40:08.440]   That's all I have.
[01:40:08.440 --> 01:40:16.320]   And just so that you can do that, you're arguing to suppress a technology that has some real
[01:40:16.320 --> 01:40:17.320]   value and a really utility.
[01:40:17.320 --> 01:40:18.320]   What about a--
[01:40:18.320 --> 01:40:21.280]   I'm talking about an intellectual construct about where we're going.
[01:40:21.280 --> 01:40:27.360]   So whenever there's new technology, people in government and policing and so on always
[01:40:27.360 --> 01:40:32.200]   say, oh, great, this will give us a huge advantage in this balance of power against the public
[01:40:32.200 --> 01:40:33.200]   and all the other--
[01:40:33.200 --> 01:40:34.600]   Well, that's the wrong way to think it.
[01:40:34.600 --> 01:40:35.600]   I think that should be fought against.
[01:40:35.600 --> 01:40:36.600]   So, okay.
[01:40:36.600 --> 01:40:39.640]   Is it a balance of power against the public?
[01:40:39.640 --> 01:40:40.640]   They are the public.
[01:40:40.640 --> 01:40:42.760]   But my people surveil them as well.
[01:40:42.760 --> 01:40:48.080]   My classic example of this is if we have a-- a Moxie Marlin spike, the creator of signal,
[01:40:48.080 --> 01:40:52.160]   right, came up with a great expression which was, in order for society to advance, you
[01:40:52.160 --> 01:40:54.240]   have to have the ability to break the law.
[01:40:54.240 --> 01:40:57.080]   Now, the classic example of this is America.
[01:40:57.080 --> 01:41:01.680]   If the British had had the kind of capabilities that even the NSA have now, a low-facial
[01:41:01.680 --> 01:41:02.680]   recognition--
[01:41:02.680 --> 01:41:03.680]   There would be no America.
[01:41:03.680 --> 01:41:04.680]   That's right.
[01:41:04.680 --> 01:41:05.680]   That's right.
[01:41:05.680 --> 01:41:08.080]   You're against America, Leo.
[01:41:08.080 --> 01:41:09.080]   That's what you're telling me, right?
[01:41:09.080 --> 01:41:10.080]   Well, this is it.
[01:41:10.080 --> 01:41:13.160]   But, I mean, you wouldn't have the civil rights movement, you wouldn't have the gay rights movement,
[01:41:13.160 --> 01:41:16.520]   you would have had feminism, you could crack down on all this stuff.
[01:41:16.520 --> 01:41:19.680]   And I know there's going to be some people on Twitter who are like, yeah, that'd be great.
[01:41:19.680 --> 01:41:21.680]   And say, yeah, we'll screw that.
[01:41:21.680 --> 01:41:22.680]   Never mind.
[01:41:22.680 --> 01:41:25.400]   But that's a really-- so philosophically, that's a very interesting--
[01:41:25.400 --> 01:41:26.400]   You've got to have the ability to found the law.
[01:41:26.400 --> 01:41:32.040]   --and somewhat profound argument, which is that perfect law enforcement is not a goal
[01:41:32.040 --> 01:41:38.480]   to be desired because transgression is important for creativity, for growth, for innovation.
[01:41:38.480 --> 01:41:39.480]   We need a balance.
[01:41:39.480 --> 01:41:40.640]   Let me tell you a little story.
[01:41:40.640 --> 01:41:46.200]   So years ago, there was-- so years and years ago, there were no cameras in police interrogation
[01:41:46.200 --> 01:41:47.200]   rooms.
[01:41:47.200 --> 01:41:49.120]   There was a room, and the police go in there, and they talk to you.
[01:41:49.120 --> 01:41:50.120]   They do whatever they want.
[01:41:50.120 --> 01:41:53.520]   And then at some point, they invented the video camera, and they started installing those.
[01:41:53.520 --> 01:41:55.080]   And we've all seen the cop shows.
[01:41:55.080 --> 01:41:58.160]   They go and unplug it right before they do the police brutality, and they plug it back
[01:41:58.160 --> 01:41:59.520]   in, or whatever.
[01:41:59.520 --> 01:42:04.120]   But you have a technology that gives a huge advantage to one side against the other.
[01:42:04.120 --> 01:42:09.800]   But a few years ago, maybe 10 years ago or something like that, some kid had a music
[01:42:09.800 --> 01:42:11.800]   player that could also record audio.
[01:42:11.800 --> 01:42:15.720]   And he went into an interrogation room, and he recorded it.
[01:42:15.720 --> 01:42:20.120]   And this big interrogation, and then when in the court, the police lied about everything
[01:42:20.120 --> 01:42:21.120]   that happened.
[01:42:21.120 --> 01:42:22.560]   And he's like, oh, yeah, listen to this.
[01:42:22.560 --> 01:42:24.040]   And then they played what really happened.
[01:42:24.040 --> 01:42:27.040]   The police was fired and actually served some time and all that stuff.
[01:42:27.040 --> 01:42:32.240]   And that was a case where the argument is not that he should have been allowed to break
[01:42:32.240 --> 01:42:33.720]   that law.
[01:42:33.720 --> 01:42:37.520]   The argument is that if one side gets surveillance power, okay, great.
[01:42:37.520 --> 01:42:39.080]   The other side gets surveillance power too.
[01:42:39.080 --> 01:42:40.080]   Well, that's in a way.
[01:42:40.080 --> 01:42:45.040]   The really good thing about technology is it isn't complicated.
[01:42:45.040 --> 01:42:46.400]   It isn't expensive.
[01:42:46.400 --> 01:42:48.040]   It can be in everybody's hands.
[01:42:48.040 --> 01:42:50.840]   Moxley, the Marlin Spike is a perfect example.
[01:42:50.840 --> 01:42:56.280]   And so if face recognition is going to happen, let's make it happen to everybody's better.
[01:42:56.280 --> 01:42:58.360]   And let's be fully aware of what they're doing.
[01:42:58.360 --> 01:43:00.280]   Do you know why Florida man stories exist?
[01:43:00.280 --> 01:43:01.680]   Have you ever heard about this?
[01:43:01.680 --> 01:43:04.280]   So Florida man, my favorite Florida man.
[01:43:04.280 --> 01:43:10.600]   Florida man claimed told police that the syringes found in his backside.
[01:43:10.600 --> 01:43:12.080]   Yeah, we're not his.
[01:43:12.080 --> 01:43:13.080]   My mind.
[01:43:13.080 --> 01:43:14.080]   My man.
[01:43:14.080 --> 01:43:21.640]   The reason Florida man stories exist is Florida has a law that says that every single call
[01:43:21.640 --> 01:43:23.880]   the police get has to be public.
[01:43:23.880 --> 01:43:25.880]   Oh my God.
[01:43:25.880 --> 01:43:28.680]   Just go through the thing and they're like, oh my God, like this, another naked drunk
[01:43:28.680 --> 01:43:29.680]   guy on a tractor.
[01:43:29.680 --> 01:43:34.160]   How did you find that so fast?
[01:43:34.160 --> 01:43:38.880]   And so that's why it's we need full disclosure about everything the police are doing with
[01:43:38.880 --> 01:43:39.880]   surveillance.
[01:43:39.880 --> 01:43:45.360]   Florida man tells police bag of cocaine found in car must have blown in from the winds.
[01:43:45.360 --> 01:43:47.720]   Oh yeah.
[01:43:47.720 --> 01:43:50.600]   This is a site devoted to Florida man.
[01:43:50.600 --> 01:43:52.880]   It's Florida man dot com.
[01:43:52.880 --> 01:43:53.880]   Oh, good grief.
[01:43:53.880 --> 01:43:55.480]   You're leaving it t-shirts as well.
[01:43:55.480 --> 01:43:59.360]   But yes, it's, you know, I'm agree with this is why body cams have been so important.
[01:43:59.360 --> 01:44:03.440]   They picked up an awful lot of stuff and it speaks volumes now to juries when those body
[01:44:03.440 --> 01:44:06.920]   cams malfunctioned or have to be turned off.
[01:44:06.920 --> 01:44:09.560]   And then the JUKE is it used to be certainly in the UK.
[01:44:09.560 --> 01:44:13.280]   If a policeman gave evidence in court, they were believed almost unquestioningly.
[01:44:13.280 --> 01:44:18.000]   And now you've got body cams and it's just like, ooh, maybe they told fibs on that one.
[01:44:18.000 --> 01:44:20.000]   Another Florida man story Leo.
[01:44:20.000 --> 01:44:25.000]   I'm sorry.
[01:44:25.000 --> 01:44:33.520]   Florida man sprays neighbors with bug spray hits himself in the head with none chucks.
[01:44:33.520 --> 01:44:38.760]   Yeah, I don't know what to say.
[01:44:38.760 --> 01:44:40.600]   Is Australia have a Florida?
[01:44:40.600 --> 01:44:41.600]   Tells my name.
[01:44:41.600 --> 01:44:42.600]   I'll play you.
[01:44:42.600 --> 01:44:43.600]   Where are they?
[01:44:43.600 --> 01:44:44.600]   What's part of Florida?
[01:44:44.600 --> 01:44:46.240]   They have Australia.
[01:44:46.240 --> 01:44:49.520]   Do they diss some of the northern parts of Brisbane.
[01:44:49.520 --> 01:44:50.520]   Belgium.
[01:44:50.520 --> 01:44:51.520]   Sydney man.
[01:44:51.520 --> 01:44:52.520]   West.
[01:44:52.520 --> 01:44:55.520]   Oh, right.
[01:44:55.520 --> 01:44:56.520]   Purse man.
[01:44:56.520 --> 01:44:57.520]   Purse fellow.
[01:44:57.520 --> 01:44:58.880]   You've got the Bogan thing as well.
[01:44:58.880 --> 01:45:00.520]   So that's kind of, but yeah.
[01:45:00.520 --> 01:45:01.520]   All right.
[01:45:01.520 --> 01:45:04.800]   We have a great bunch of students in here from Ken Vara.
[01:45:04.800 --> 01:45:06.520]   Grammar school, thank you for being here.
[01:45:06.520 --> 01:45:09.120]   If you need to flee at any point, please do.
[01:45:09.120 --> 01:45:11.440]   Happy Australia day to everybody.
[01:45:11.440 --> 01:45:13.360]   What is Australia Day commemorate?
[01:45:13.360 --> 01:45:18.040]   What event happened on this day?
[01:45:18.040 --> 01:45:21.720]   When Cook landed, he said, you got any breadfruit?
[01:45:21.720 --> 01:45:23.640]   And Australia was born.
[01:45:23.640 --> 01:45:26.680]   And they said, it reminds me of Wales, South Wales.
[01:45:26.680 --> 01:45:28.160]   Well, new South Wales.
[01:45:28.160 --> 01:45:30.920]   I barely Cook landed right at the end of the rainy season.
[01:45:30.920 --> 01:45:31.920]   So it was just lush paradise.
[01:45:31.920 --> 01:45:36.400]   I think I said all these convicts down there are like, yeah, we've been sold a pup on this
[01:45:36.400 --> 01:45:37.400]   one, you know.
[01:45:37.400 --> 01:45:38.920]   But people settled.
[01:45:38.920 --> 01:45:41.520]   It's got, you know, it's a fantastic country.
[01:45:41.520 --> 01:45:44.440]   Ladies and gentlemen, we had a fun week this week on Twitter.
[01:45:44.440 --> 01:45:50.120]   We've prepared this fine video for your enjoyment and watch.
[01:45:50.120 --> 01:45:54.280]   Previously on tweet, this week on Hands on Photography, we're going to take a look at
[01:45:54.280 --> 01:46:00.760]   that little funny looking chart that you see in your photo editors, also known as the histogram.
[01:46:00.760 --> 01:46:02.160]   This week in Google.
[01:46:02.160 --> 01:46:07.320]   So knows on Tuesday, everybody got their email saying end of software updates.
[01:46:07.320 --> 01:46:14.160]   So what is happening is if you have a product that was introduced between 2005 and 2011,
[01:46:14.160 --> 01:46:20.680]   those devices after May will not receive software updates into new features.
[01:46:20.680 --> 01:46:21.680]   Tech News Weekly.
[01:46:21.680 --> 01:46:25.640]   How did Bezos and MBS come to communicate within WhatsApp?
[01:46:25.640 --> 01:46:27.520]   In April 2018, they had a dinner.
[01:46:27.520 --> 01:46:29.640]   Apparently, they swapped numbers there.
[01:46:29.640 --> 01:46:36.080]   And then they didn't really chat for a while until when the Crown Prince sent an MP4 video
[01:46:36.080 --> 01:46:39.280]   file to Bezos' phone.
[01:46:39.280 --> 01:46:52.200]   Backbreak Weekly.
[01:46:52.200 --> 01:46:54.160]   It's true.
[01:46:54.160 --> 01:46:57.560]   Technology for your eyes and your holes.
[01:46:57.560 --> 01:47:02.960]   It's probably a highly carcinogenic chemical in there, but it smells like blueberries.
[01:47:02.960 --> 01:47:04.960]   I mean, both of them are bigger than my neck.
[01:47:04.960 --> 01:47:05.960]   Oh, yeah.
[01:47:05.960 --> 01:47:07.700]   That is like Mr. Yeah.
[01:47:07.700 --> 01:47:08.700]   He lifts.
[01:47:08.700 --> 01:47:09.700]   He's a great presenter, though.
[01:47:09.700 --> 01:47:10.700]   You can write great new high.
[01:47:10.700 --> 01:47:11.700]   I love that.
[01:47:11.700 --> 01:47:12.700]   Yeah.
[01:47:12.700 --> 01:47:15.960]   Our show today brought to you by HealthIQ, a life insurance agency that does things a
[01:47:15.960 --> 01:47:21.400]   little bit different for people who lift, people who get a good night's sleep, people
[01:47:21.400 --> 01:47:25.560]   who eat right, people who care about their health.
[01:47:25.560 --> 01:47:29.160]   Lower life insurance rates for people like you.
[01:47:29.160 --> 01:47:33.040]   For example, a million dollar life insurance policy from $36 a month.
[01:47:33.040 --> 01:47:38.680]   See, the thing is the people who are healthy, people who know and care about what they're
[01:47:38.680 --> 01:47:44.020]   eat, what they do, what they exercise, have always subsidized those who are not so health
[01:47:44.020 --> 01:47:45.020]   conscious.
[01:47:45.020 --> 01:47:46.020]   It's not a conspiracy.
[01:47:46.020 --> 01:47:47.020]   It's just statistics.
[01:47:47.020 --> 01:47:48.500]   It's how life insurance works.
[01:47:48.500 --> 01:47:51.060]   You might be healthy, but does your insurance company know?
[01:47:51.060 --> 01:47:52.620]   That's a perfect example.
[01:47:52.620 --> 01:47:57.580]   Because he lifts his body mass index is very high, which the insurance company say, "Oh,
[01:47:57.580 --> 01:47:58.580]   you're fat."
[01:47:58.580 --> 01:48:00.700]   They don't know that it's because he lifts.
[01:48:00.700 --> 01:48:03.900]   That's why you got to go to HealthIQ.
[01:48:03.900 --> 01:48:07.980]   HealthIQ is a concierge life insurance agency.
[01:48:07.980 --> 01:48:09.260]   They give you white glove service.
[01:48:09.260 --> 01:48:12.020]   They walk you through the entire process.
[01:48:12.020 --> 01:48:15.060]   Your policy will be underwritten by one of the top 30 insurance companies.
[01:48:15.060 --> 01:48:16.060]   Here's the difference.
[01:48:16.060 --> 01:48:20.420]   They will go to those insurance companies and say, "Look, this guy qualifies for those
[01:48:20.420 --> 01:48:22.860]   special health IQ savings.
[01:48:22.860 --> 01:48:27.500]   This gal takes care of herself and they will go to bat for you."
[01:48:27.500 --> 01:48:28.840]   That is amazing.
[01:48:28.840 --> 01:48:30.180]   It starts with the HealthIQ quiz.
[01:48:30.180 --> 01:48:34.020]   You can do it right now if you go to healthIQ.com/twit.
[01:48:34.020 --> 01:48:40.020]   It's a proprietary healthIQ quiz that assesses your health literacy, your knowledge.
[01:48:40.020 --> 01:48:41.420]   It's not self-assessment.
[01:48:41.420 --> 01:48:43.340]   It's a knowledge assessment.
[01:48:43.340 --> 01:48:47.660]   They put it together with a team of the nation's leading medical, health, and fitness experts.
[01:48:47.660 --> 01:48:49.580]   It's a cutting-edge analysis.
[01:48:49.580 --> 01:48:54.620]   Then depending on your scores, as well as other related qualifying factors, for instance,
[01:48:54.620 --> 01:48:55.620]   completely voluntarily.
[01:48:55.620 --> 01:48:59.100]   But you can say, "Hey, I'll give you my Fitbit or my Apple Watch data."
[01:48:59.100 --> 01:49:04.180]   You can save up to 41% on your life insurance premiums compared to other providers.
[01:49:04.180 --> 01:49:05.180]   There's no commitment.
[01:49:05.180 --> 01:49:08.660]   You'll learn even more about the potential opportunities to be rewarded for your commitment
[01:49:08.660 --> 01:49:09.660]   to living healthy.
[01:49:09.660 --> 01:49:10.900]   This is a really great idea.
[01:49:10.900 --> 01:49:13.660]   HealthIQ.com/twit.
[01:49:13.660 --> 01:49:15.980]   They will go to bat for you.
[01:49:15.980 --> 01:49:17.060]   They will go to bat for you.
[01:49:17.060 --> 01:49:18.060]   That's really cool.
[01:49:18.060 --> 01:49:23.300]   HealthIQ's concierge service will help you get the life insurance you deserve.
[01:49:23.300 --> 01:49:24.300]   See if you qualify.
[01:49:24.300 --> 01:49:26.100]   Go to healthIQ.com/twit.
[01:49:26.100 --> 01:49:31.100]   Make that quiz.
[01:49:31.100 --> 01:49:34.140]   You can get those savings you've earned for your healthy lifestyle.
[01:49:34.140 --> 01:49:35.140]   I love this idea.
[01:49:35.140 --> 01:49:36.140]   HealthIQ.com/twit.
[01:49:36.140 --> 01:49:41.860]   I thank you for supporting this week in tech.
[01:49:41.860 --> 01:49:45.460]   We thank you for supporting this week in tech by going to healthIQ.com/twit.
[01:49:45.460 --> 01:49:48.140]   I can see one.
[01:49:48.140 --> 01:49:49.140]   Just come back to Facial Recognition.
[01:49:49.140 --> 01:49:53.300]   I can see one area in which it really worked because obviously we've heard about the tragic
[01:49:53.300 --> 01:49:54.780]   death of Kobe Bryant today.
[01:49:54.780 --> 01:49:55.780]   Just happened.
[01:49:55.780 --> 01:50:01.300]   The BBC has just put out a clip of Kobe Bryant but not with Kobe Bryant.
[01:50:01.300 --> 01:50:02.300]   Help with LeBron James.
[01:50:02.300 --> 01:50:03.300]   Oh my God.
[01:50:03.300 --> 01:50:05.700]   Well, they do all look alike.
[01:50:05.700 --> 01:50:07.540]   Anybody over seven feet tall to me.
[01:50:07.540 --> 01:50:09.540]   I can't even see the face.
[01:50:09.540 --> 01:50:11.660]   No, this happens all the time.
[01:50:11.660 --> 01:50:12.660]   It happens all.
[01:50:12.660 --> 01:50:14.180]   It's even happened to us once.
[01:50:14.180 --> 01:50:15.180]   Once.
[01:50:15.180 --> 01:50:17.020]   Right, Carsten?
[01:50:17.020 --> 01:50:18.580]   Never again.
[01:50:18.580 --> 01:50:23.700]   It's very easy to put the wrong picture of somebody up on the screen.
[01:50:23.700 --> 01:50:27.700]   So you're right, Facial Recognition had fixed that.
[01:50:27.700 --> 01:50:28.700]   Right.
[01:50:28.700 --> 01:50:32.100]   Can I tell you a quick Facial Recognition story, Leo?
[01:50:32.100 --> 01:50:33.100]   Yes.
[01:50:33.100 --> 01:50:34.420]   Went to El Salvador recently.
[01:50:34.420 --> 01:50:36.180]   And while I was there, my nieces were there.
[01:50:36.180 --> 01:50:37.260]   We had a bunch of family there.
[01:50:37.260 --> 01:50:42.460]   And I showed them the feature in Pixel phones where it'll take a picture if you smile.
[01:50:42.460 --> 01:50:44.580]   So I held it in front of their faces.
[01:50:44.580 --> 01:50:46.300]   They were both wearing sunglasses.
[01:50:46.300 --> 01:50:50.940]   And then when I did an ego search on Google, does the Facial Recognition within Google
[01:50:50.940 --> 01:50:52.440]   Photos?
[01:50:52.440 --> 01:50:54.140]   It showed that picture as me.
[01:50:54.140 --> 01:50:55.140]   What?
[01:50:55.140 --> 01:50:57.340]   Because my arm was in the reflection of one of those.
[01:50:57.340 --> 01:50:58.780]   Oh, it saw your arm?
[01:50:58.780 --> 01:50:59.780]   No.
[01:50:59.780 --> 01:51:00.780]   Yes.
[01:51:00.780 --> 01:51:01.780]   In the reflection of sunglasses?
[01:51:01.780 --> 01:51:02.780]   Really?
[01:51:02.780 --> 01:51:03.780]   Could tell it was you.
[01:51:03.780 --> 01:51:04.780]   Yes.
[01:51:04.780 --> 01:51:05.780]   Whoa.
[01:51:05.780 --> 01:51:06.780]   Do you think so?
[01:51:06.780 --> 01:51:07.940]   Or just they thought you were on the search.
[01:51:07.940 --> 01:51:08.940]   It was there.
[01:51:08.940 --> 01:51:09.940]   It said that.
[01:51:09.940 --> 01:51:10.940]   No, I searched for me.
[01:51:10.940 --> 01:51:11.940]   I said, show me all the pictures.
[01:51:11.940 --> 01:51:12.940]   And I had a picture of your arm.
[01:51:12.940 --> 01:51:13.940]   Oh, my arm?
[01:51:13.940 --> 01:51:14.940]   So it's not just face recognition.
[01:51:14.940 --> 01:51:15.940]   It's arm recognition.
[01:51:15.940 --> 01:51:17.500]   And I know that Facebook does this too.
[01:51:17.500 --> 01:51:19.660]   They recognize your clothes, your stuff.
[01:51:19.660 --> 01:51:20.660]   I'll show you.
[01:51:20.660 --> 01:51:21.660]   I'll show you.
[01:51:21.660 --> 01:51:23.660]   So one good thing about Brexit--
[01:51:23.660 --> 01:51:24.660]   That's a good question.
[01:51:24.660 --> 01:51:26.660]   And by the way, Brexit--
[01:51:26.660 --> 01:51:27.660]   Next week?
[01:51:27.660 --> 01:51:28.660]   One good thing about Brexit.
[01:51:28.660 --> 01:51:30.660]   Am I going to have to hurt you at the moment?
[01:51:30.660 --> 01:51:34.660]   No, I think you will even agree this is a good thing about Brexit.
[01:51:34.660 --> 01:51:38.360]   OK, hit me.
[01:51:38.360 --> 01:51:42.160]   The EU Copyright Law, Article 13.
[01:51:42.160 --> 01:51:43.160]   Oh.
[01:51:43.160 --> 01:51:47.360]   The guy is the-- I'm going to find his name.
[01:51:47.360 --> 01:51:51.160]   He's the head of museums and science or something like that.
[01:51:51.160 --> 01:51:56.360]   Chris Skidmore, University and Science Minister.
[01:51:56.360 --> 01:52:00.060]   That's the M-I-C-K-A-Y M-O-U-S-C version of a government job.
[01:52:00.060 --> 01:52:01.060]   Yes.
[01:52:01.060 --> 01:52:02.060]   OK.
[01:52:02.060 --> 01:52:03.060]   The University is in Science Minister.
[01:52:03.060 --> 01:52:04.060]   We have to have one.
[01:52:04.060 --> 01:52:05.660]   It says, no.
[01:52:05.660 --> 01:52:12.160]   Now that we're not part of the EU, we will not adopt the EU Copyright Law and Article 13,
[01:52:12.160 --> 01:52:14.160]   which was the anti-meme law.
[01:52:14.160 --> 01:52:19.000]   Well, it could have been-- it could conceivably have been used by anti-meme if you stretch
[01:52:19.000 --> 01:52:20.520]   it to it's logical.
[01:52:20.520 --> 01:52:22.120]   It's furthest logical consumption.
[01:52:22.120 --> 01:52:24.920]   Well, maybe that's what they're doing in Germany.
[01:52:24.920 --> 01:52:29.600]   Their new law says it's in German, but I'm going to translate because I speak perfect
[01:52:29.600 --> 01:52:36.400]   German that your memes can't be more than 128 pixels by 128 pixels.
[01:52:36.400 --> 01:52:40.320]   It's what happens when legislators get half-fieder of what they're doing.
[01:52:40.320 --> 01:52:42.520]   In video, this is the point I was making earlier.
[01:52:42.520 --> 01:52:44.120]   It could only be three seconds long.
[01:52:44.120 --> 01:52:46.320]   Now, OK, Patrick, back me up on this.
[01:52:46.320 --> 01:52:50.520]   There's Wilson as envisaged to bad law, but--
[01:52:50.520 --> 01:52:56.720]   Well, I mean, you know, what I was saying earlier, sometimes you have laws that aren't
[01:52:56.720 --> 01:52:57.720]   great.
[01:52:57.720 --> 01:53:03.920]   I would say that one is not ideal.
[01:53:03.920 --> 01:53:08.760]   And you know, in the same way that I say you shouldn't say all laws are bad, I don't
[01:53:08.760 --> 01:53:11.320]   think you should say laws are good.
[01:53:11.320 --> 01:53:12.320]   Case in point.
[01:53:12.320 --> 01:53:14.920]   I have a question for you as an ex-patriot--
[01:53:14.920 --> 01:53:16.920]   Please, I'm an immigrant.
[01:53:16.920 --> 01:53:18.920]   He's a citizen now.
[01:53:18.920 --> 01:53:19.920]   No, not yet.
[01:53:19.920 --> 01:53:20.920]   But you're on your way.
[01:53:20.920 --> 01:53:21.920]   You're on the path.
[01:53:21.920 --> 01:53:23.920]   You're not pregnant, are you?
[01:53:23.920 --> 01:53:24.920]   OK.
[01:53:24.920 --> 01:53:26.920]   Well, I know it looks that way, but it's just too many Tim Tams, mate.
[01:53:26.920 --> 01:53:30.920]   I heard you talked about earlier about the London police and Facebook recognition.
[01:53:30.920 --> 01:53:32.920]   Would that have been possible without Brexit?
[01:53:32.920 --> 01:53:34.920]   In other words, don't you?
[01:53:34.920 --> 01:53:37.920]   No, they were doing it while we were still in part of a party.
[01:53:37.920 --> 01:53:41.920]   So Brexit, the EU has no laws that would prevent that from--
[01:53:41.920 --> 01:53:48.920]   Well, they're a disgusting one now, which would put a ban on facial recognition in public
[01:53:48.920 --> 01:53:56.920]   spaces by public or private actors for three to five years as we're figuring things out.
[01:53:56.920 --> 01:54:02.120]   But with importance exceptions for both research and national security, in both of those cases
[01:54:02.120 --> 01:54:04.920]   then you could use it in a public sense.
[01:54:04.920 --> 01:54:05.920]   That's the--
[01:54:05.920 --> 01:54:08.560]   But yeah, I mean, it's still coming on.
[01:54:08.560 --> 01:54:12.560]   So yeah, the Brexit thing wouldn't have stopped that at all.
[01:54:12.560 --> 01:54:18.560]   It's just-- the police have been very keen on CCTV for so many years.
[01:54:18.560 --> 01:54:23.560]   It was logical they were trying out at music festivals a couple of years ago, again with
[01:54:23.560 --> 01:54:26.560]   a stunning lack of success.
[01:54:26.560 --> 01:54:30.560]   At the moment, it just generates far more false positives than it does actual accurate.
[01:54:30.560 --> 01:54:35.560]   And the UK has been the most surveilled country in the world until recently when China said,
[01:54:35.560 --> 01:54:36.560]   "Hold my beer."
[01:54:36.560 --> 01:54:38.560]   Or "Hold my rice wine or whatever."
[01:54:38.560 --> 01:54:43.560]   Yeah, it's-- yeah, I mean, Britain was the CCTV capital of the world.
[01:54:43.560 --> 01:54:49.560]   I remember during the final IRA bombing campaign they built the Wall of Steel around the city
[01:54:49.560 --> 01:54:54.560]   of London, the main financial centre, and they put cameras up everywhere, and the IRA exploded
[01:54:54.560 --> 01:54:56.560]   a bomb inside it within two weeks.
[01:54:56.560 --> 01:54:58.560]   I mean, it's not perfect.
[01:54:58.560 --> 01:54:59.560]   It costs an awful lot.
[01:54:59.560 --> 01:55:03.560]   There are huge privacy aspects to be taken into account.
[01:55:03.560 --> 01:55:04.560]   And yes, it's going to happen.
[01:55:04.560 --> 01:55:08.560]   And just for full disclosure, for those of you unaware, the city of London is different
[01:55:08.560 --> 01:55:09.560]   from London the city.
[01:55:09.560 --> 01:55:14.560]   Yes, the city of London is in fact an independent body with its own mayor, its own police force,
[01:55:14.560 --> 01:55:17.560]   its acknowledges the Queen, but it has a very--
[01:55:17.560 --> 01:55:18.560]   What?
[01:55:18.560 --> 01:55:19.560]   --interesting-- oh, yeah.
[01:55:19.560 --> 01:55:20.560]   This is bizarre.
[01:55:20.560 --> 01:55:22.560]   No, no, it's like a Vatican within--
[01:55:22.560 --> 01:55:23.560]   This is totally bizarre.
[01:55:23.560 --> 01:55:24.560]   Is this the financial quarter?
[01:55:24.560 --> 01:55:27.560]   Yeah, this is basically the old Roman walled section.
[01:55:27.560 --> 01:55:33.560]   But I didn't know it was somehow distinct legally from police force, own coat of arms,
[01:55:33.560 --> 01:55:36.560]   technically could set its own taxation rate, but chooses not to.
[01:55:36.560 --> 01:55:37.560]   It has its own parliament.
[01:55:37.560 --> 01:55:38.560]   I think they should see it.
[01:55:38.560 --> 01:55:39.560]   It has its own parliament.
[01:55:39.560 --> 01:55:40.560]   It has its own parliament.
[01:55:40.560 --> 01:55:41.560]   Yeah.
[01:55:41.560 --> 01:55:44.560]   It's not bound by the laws of the big boy parliament.
[01:55:44.560 --> 01:55:45.560]   It's a--
[01:55:45.560 --> 01:55:48.560]   There is a relationship between the two.
[01:55:48.560 --> 01:55:51.560]   Yeah, there is a relationship between the two.
[01:55:51.560 --> 01:55:57.560]   But basically, the city of London is ruled by guilds and by free men of London.
[01:55:57.560 --> 01:56:00.560]   And there are like 130 guilds, and you have to be elected to a guild.
[01:56:00.560 --> 01:56:04.560]   Companies also have their own representation on the organizing body.
[01:56:04.560 --> 01:56:05.560]   I don't know how fantastic it is.
[01:56:05.560 --> 01:56:06.560]   I think it's CPD-grade.
[01:56:06.560 --> 01:56:11.560]   I knew there was City of London, and I knew there was distinct geographically.
[01:56:11.560 --> 01:56:12.560]   Yeah.
[01:56:12.560 --> 01:56:14.560]   But I didn't know it was legally distinct.
[01:56:14.560 --> 01:56:18.560]   Well, there's a marvelous video by I think it's CPG-grade.
[01:56:18.560 --> 01:56:19.560]   Oh, yeah.
[01:56:19.560 --> 01:56:20.560]   He's very good at this.
[01:56:20.560 --> 01:56:24.560]   Yeah, he goes in for two episodes as to why the City of London is distinct from London,
[01:56:24.560 --> 01:56:26.560]   the city, and it's fast enough.
[01:56:26.560 --> 01:56:28.560]   I mean, I grew up in the country.
[01:56:28.560 --> 01:56:29.560]   I had no idea.
[01:56:29.560 --> 01:56:33.560]   I mean, the level of complex, you know, shuffle the--
[01:56:33.560 --> 01:56:37.560]   I hope they cover this in the next season of The Crown, I'm just saying.
[01:56:37.560 --> 01:56:38.560]   Oh, I still haven't watched that.
[01:56:38.560 --> 01:56:39.560]   I just can't bring myself to.
[01:56:39.560 --> 01:56:43.560]   So Brexit is important, but can we talk about something really important?
[01:56:43.560 --> 01:56:44.560]   Yes.
[01:56:44.560 --> 01:56:45.560]   Megxit.
[01:56:45.560 --> 01:56:46.560]   Oh.
[01:56:46.560 --> 01:56:47.560]   It's Megxit.
[01:56:47.560 --> 01:56:49.560]   That's Harry and Meg going to kill.
[01:56:49.560 --> 01:56:50.560]   Oh.
[01:56:50.560 --> 01:56:51.560]   It's the royal family.
[01:56:51.560 --> 01:56:55.560]   Britain's longest-running soap opera with the added illusion of audience participation.
[01:56:55.560 --> 01:56:56.560]   Yeah.
[01:56:56.560 --> 01:56:57.560]   Basically--
[01:56:57.560 --> 01:56:59.560]   Is there a tech angle to Megxit?
[01:56:59.560 --> 01:57:00.560]   No.
[01:57:00.560 --> 01:57:03.560]   Well, actually, they're going to make that living through Instagram.
[01:57:03.560 --> 01:57:04.560]   They're going to be influencers?
[01:57:04.560 --> 01:57:06.560]   Oh, I can easily so depress.
[01:57:06.560 --> 01:57:10.560]   In fact, I will make use prediction within five years, one or other than we'll be on dancing
[01:57:10.560 --> 01:57:11.560]   on the stars.
[01:57:11.560 --> 01:57:12.560]   Ah!
[01:57:12.560 --> 01:57:16.560]   I don't understand why all the tabloids aren't using the phrase "royal pain in the ass."
[01:57:16.560 --> 01:57:17.560]   Ah!
[01:57:17.560 --> 01:57:18.560]   Because you--
[01:57:18.560 --> 01:57:21.560]   Like, they should have been waiting for decades to use that phrase.
[01:57:21.560 --> 01:57:23.560]   Ah, it's a little rude.
[01:57:23.560 --> 01:57:26.560]   Honestly, the bulk of the population in the UK is support-roof.
[01:57:26.560 --> 01:57:28.560]   I think support Harry and Megxit's decision.
[01:57:28.560 --> 01:57:31.560]   They didn't choose to be born into the members of the royal family.
[01:57:31.560 --> 01:57:33.560]   He's seen his mother killing lives.
[01:57:33.560 --> 01:57:34.560]   Oh, yeah.
[01:57:34.560 --> 01:57:36.560]   He's way down the thing.
[01:57:36.560 --> 01:57:37.560]   Yeah.
[01:57:37.560 --> 01:57:42.960]   And she didn't want to be-- you know, because his mom was Princess Diana, I think they quite
[01:57:42.960 --> 01:57:45.560]   reasonably did not want to be the focus of paparazzi.
[01:57:45.560 --> 01:57:46.560]   Yeah.
[01:57:46.560 --> 01:57:50.560]   If your mother was effectively killed by paparazzi, and you say--
[01:57:50.560 --> 01:57:51.560]   I'm a taxi driver as well, but yes.
[01:57:51.560 --> 01:57:55.560]   Well, yeah, but I don't want to be in the limelight anymore because it's a--
[01:57:55.560 --> 01:57:58.560]   Well, they do want to be in the limelight, but they want to control it.
[01:57:58.560 --> 01:57:59.560]   This is the whole point of Instagram.
[01:57:59.560 --> 01:58:07.560]   Well, I think that the problem was that a large section of the UK press has been massively
[01:58:07.560 --> 01:58:13.560]   unfair towards Harry and Megan in terms of how they've portrayed her to the public in their
[01:58:13.560 --> 01:58:14.560]   papers.
[01:58:14.560 --> 01:58:16.560]   And if you look at the-- there have been some very interesting articles.
[01:58:16.560 --> 01:58:20.560]   If you look at how Kate Middleton was treated versus how--
[01:58:20.560 --> 01:58:22.560]   Megan was treated, it's pretty shameful.
[01:58:22.560 --> 01:58:24.560]   It's shameful and it's racist.
[01:58:24.560 --> 01:58:28.560]   But here's the thing that a lot of people don't realize, and there is a tech angle to this
[01:58:28.560 --> 01:58:35.560]   Leo, which is that the royal family has a deal with a small list of newspapers in the UK,
[01:58:35.560 --> 01:58:39.960]   including the most shameless rags who are just ripping into them, but they're forced by their
[01:58:39.960 --> 01:58:43.560]   circumstances by this deal to constantly provide access and information.
[01:58:43.560 --> 01:58:44.560]   Who made that deal?
[01:58:44.560 --> 01:58:45.560]   Who knows?
[01:58:45.560 --> 01:58:49.560]   It's something the royal family basically have evolved since the turn of the last sentence.
[01:58:49.560 --> 01:58:50.560]   It's kind of a tip for the little man.
[01:58:50.560 --> 01:58:55.560]   Well, basically, what you're saying is you don't hang around our back door, try and
[01:58:55.560 --> 01:58:56.560]   break into fucking a palace.
[01:58:56.560 --> 01:58:58.560]   But we will give you access.
[01:58:58.560 --> 01:59:01.560]   And there's some lovely open mic moment.
[01:59:01.560 --> 01:59:04.560]   You can imagine with Prince Philip in particular, some lovely open mic moments where they see
[01:59:04.560 --> 01:59:08.560]   one of the royal correspondence, you know, there's that goss little man again, we're going to have
[01:59:08.560 --> 01:59:09.560]   to talk to him.
[01:59:09.560 --> 01:59:11.560]   They love these people because they're basically--
[01:59:11.560 --> 01:59:16.560]   Well, wouldn't you if you were following every journalist and you crafted your trade and
[01:59:16.560 --> 01:59:19.560]   face recognition isn't driven on privacy?
[01:59:19.560 --> 01:59:23.560]   Imagine, Cameron lens is pointing in your face everywhere you go.
[01:59:23.560 --> 01:59:24.560]   But here's the tech angle.
[01:59:24.560 --> 01:59:31.560]   In the age of the Instagram influencers and YouTube stars, these two people know that
[01:59:31.560 --> 01:59:35.560]   those antiquated laws are just some horrible money in their way.
[01:59:35.560 --> 01:59:36.560]   It's getting in their way.
[01:59:36.560 --> 01:59:39.560]   Nightmare that they are forced to go through when they know that there are eight-year-olds
[01:59:39.560 --> 01:59:44.560]   on YouTube making $10 million a year, they are famous and will continue to be famous and
[01:59:44.560 --> 01:59:46.560]   monetize that to the cows.
[01:59:46.560 --> 01:59:48.560]   They're separate financially.
[01:59:48.560 --> 01:59:50.560]   A lot depend on how they do it though.
[01:59:50.560 --> 01:59:54.560]   If they do it in a way which is seen as bringing the crown into disrespect, they get a lose
[01:59:54.560 --> 01:59:56.560]   and awful lot of respect.
[01:59:56.560 --> 01:59:58.560]   But I think they're smart enough to do it tastefully.
[01:59:58.560 --> 02:00:02.560]   I mean, Patrick, you got rid of your milky a long, long time ago and France has been much
[02:00:02.560 --> 02:00:03.560]   the better for it.
[02:00:03.560 --> 02:00:04.560]   How's it looking overall?
[02:00:04.560 --> 02:00:06.560]   They also got rid of their heads at the same time.
[02:00:06.560 --> 02:00:11.560]   It's interesting because a lot of people say that we got rid of our king, but so our
[02:00:11.560 --> 02:00:20.560]   president kind of has to play that role and the people still want some kind of royal figure.
[02:00:20.560 --> 02:00:28.560]   It's true that the president has that always, whatever the president is, I think the country
[02:00:28.560 --> 02:00:31.560]   expects something like that of the president to an extent.
[02:00:31.560 --> 02:00:32.560]   You can have our king.
[02:00:32.560 --> 02:00:33.560]   We'll pass him along.
[02:00:33.560 --> 02:00:39.560]   But I mean, the president of France had a second at a mistress who he had a love child with.
[02:00:39.560 --> 02:00:40.560]   The press knew about this.
[02:00:40.560 --> 02:00:41.560]   Oh, that was, yes.
[02:00:41.560 --> 02:00:42.560]   They kept quiet about it.
[02:00:42.560 --> 02:00:43.560]   Yes.
[02:00:43.560 --> 02:00:44.560]   Yeah.
[02:00:44.560 --> 02:00:46.560]   And tell the few when they had to explain who this woman and her son was.
[02:00:46.560 --> 02:00:50.560]   He's sitting just behind the presence of the family.
[02:00:50.560 --> 02:00:51.560]   So sad.
[02:00:51.560 --> 02:00:58.360]   Joe Biden calls game developers little creeps who make titles that teach you how to kill.
[02:00:58.360 --> 02:01:00.160]   He really is becoming the Madal grandpa.
[02:01:00.160 --> 02:01:01.160]   He really is a grandpa.
[02:01:01.160 --> 02:01:06.680]   Apparently, this is a meeting that was held in the Obama White House.
[02:01:06.680 --> 02:01:12.480]   People are trying to figure out who he was talking about.
[02:01:12.480 --> 02:01:17.680]   Kotaku thinks it might be electronic arts then CEO Joe Ricciatello.
[02:01:17.680 --> 02:01:24.000]   I'll give you the full quotes because you wouldn't want to quote this out of context.
[02:01:24.000 --> 02:01:28.800]   When asked about the Silicon Valley's expansion of power during his time in the Obama administration
[02:01:28.800 --> 02:01:31.760]   during this interview with the New York Times and their vetting candidates, he said, "And
[02:01:31.760 --> 02:01:35.960]   you may recall the criticism I got for meeting with the leaders in Silicon Valley when I
[02:01:35.960 --> 02:01:39.680]   was trying to work out an agreement dealing with them protecting intellectual property
[02:01:39.680 --> 02:01:41.680]   for artists in the United States of America.
[02:01:41.680 --> 02:01:46.280]   At one point, one of the little creeps sitting around that table who was a multi close to
[02:01:46.280 --> 02:01:51.400]   a billionaire who told me he was an artist because he was able to come up with games that
[02:01:51.400 --> 02:01:54.440]   teach you how to kill people.
[02:01:54.440 --> 02:02:00.200]   And then, oh Biden went on, one of these righteous people said to me, "You know, we are the economic
[02:02:00.200 --> 02:02:01.600]   engine of America.
[02:02:01.600 --> 02:02:02.600]   We are the ones.
[02:02:02.600 --> 02:02:05.680]   Fortunately, I'd done a little homework before I went and I said, "You know, I find
[02:02:05.680 --> 02:02:09.240]   it fascinating as I added up the seven outfits.
[02:02:09.240 --> 02:02:10.240]   Everyone's there."
[02:02:10.240 --> 02:02:13.760]   But Microsoft, I said, "You have fewer people on your payroll than all the losses that General
[02:02:13.760 --> 02:02:16.640]   Motors just faced in the last quarter of employees.
[02:02:16.640 --> 02:02:19.400]   So don't lecture me about how you've created all this employment."
[02:02:19.400 --> 02:02:21.760]   You know, he's not alone, by the way.
[02:02:21.760 --> 02:02:25.080]   I think there are other candidates for any Sanders, I think, as one of them who are not
[02:02:25.080 --> 02:02:27.840]   fond of video games and video game developers.
[02:02:27.840 --> 02:02:32.280]   But there's never been, I mean, we've had this ever since the existence of video games
[02:02:32.280 --> 02:02:33.920]   and before that the existence of violence.
[02:02:33.920 --> 02:02:35.920]   I think it's a generational...
[02:02:35.920 --> 02:02:36.920]   Yes, absolutely.
[02:02:36.920 --> 02:02:37.920]   Yes.
[02:02:37.920 --> 02:02:38.920]   It is a generational...
[02:02:38.920 --> 02:02:44.120]   Now, I will say we just got the...
[02:02:44.120 --> 02:02:49.880]   I think it was the NPD, yes, that released the numbers of the most...
[02:02:49.880 --> 02:02:56.360]   The games that generated the most income in the last decade and I will make the story
[02:02:56.360 --> 02:02:57.360]   short.
[02:02:57.360 --> 02:03:01.800]   Seven out of the top 10 games are Call of Duty titles.
[02:03:01.800 --> 02:03:06.680]   First person shooters, military first person shooters, that's in the US.
[02:03:06.680 --> 02:03:10.480]   If you go to the top 20, 10 of them are Call of Duty.
[02:03:10.480 --> 02:03:14.560]   So I understand how some people could get that idea.
[02:03:14.560 --> 02:03:15.560]   Well, if you think about this...
[02:03:15.560 --> 02:03:19.720]   If you think about video games are not violent and no one's saying we don't like video games
[02:03:19.720 --> 02:03:20.720]   that are...
[02:03:20.720 --> 02:03:23.440]   We like violent video games, but there is also no one...
[02:03:23.440 --> 02:03:24.880]   Well, I shouldn't say this.
[02:03:24.880 --> 02:03:27.320]   There's no evidence that that leads to actual violence.
[02:03:27.320 --> 02:03:28.320]   Of course.
[02:03:28.320 --> 02:03:29.320]   No, no, look at what is the climate...
[02:03:29.320 --> 02:03:30.320]   The climate is...
[02:03:30.320 --> 02:03:32.320]   The cartoons have been violent for years.
[02:03:32.320 --> 02:03:36.840]   What is the number one computer gaming country in the world?
[02:03:36.840 --> 02:03:37.840]   It's Japan.
[02:03:37.840 --> 02:03:39.800]   And what has some of the lowest violent...
[02:03:39.800 --> 02:03:41.760]   But you're a violent car wreck.
[02:03:41.760 --> 02:03:46.440]   It's also somewhat ironic that Call of Duty type games are...
[02:03:46.440 --> 02:03:51.960]   They're essentially building a world where people get to fantasize about participating
[02:03:51.960 --> 02:03:57.120]   in wars that Biden, as part of the Obama administration, actually had a hand in...
[02:03:57.120 --> 02:03:58.120]   Actual violence.
[02:03:58.120 --> 02:04:00.280]   And conducting and not ending and so on.
[02:04:00.280 --> 02:04:05.720]   So it's kind of weird that these games imitate Biden's work.
[02:04:05.720 --> 02:04:07.920]   Actual violence.
[02:04:07.920 --> 02:04:13.200]   He was apparently when he was vice president in 2013, he proposed a tax on violent media,
[02:04:13.200 --> 02:04:15.200]   including violent video games.
[02:04:15.200 --> 02:04:16.600]   Tax which was not an actor.
[02:04:16.600 --> 02:04:18.960]   It's the old dog whistle, you know?
[02:04:18.960 --> 02:04:22.960]   And it's like, we had the same thing when arcade games came out with other teenage...
[02:04:22.960 --> 02:04:24.440]   Oh, he'll rot the kids' minds.
[02:04:24.440 --> 02:04:25.600]   He'll take the super violent.
[02:04:25.600 --> 02:04:26.600]   The only thing he did.
[02:04:26.600 --> 02:04:27.600]   Right.
[02:04:27.600 --> 02:04:31.400]   Playing Pac-Man did lead, might have been construed to lead into a lot of people bouncing around
[02:04:31.400 --> 02:04:32.400]   dark rooms.
[02:04:32.400 --> 02:04:33.400]   And over even.
[02:04:33.400 --> 02:04:34.400]   Inspired over eating.
[02:04:34.400 --> 02:04:38.240]   But yeah, I mean, this has been going on since time in Moriel.
[02:04:38.240 --> 02:04:40.480]   There is no evidence to back it up whatsoever.
[02:04:40.480 --> 02:04:48.320]   It's also very interesting that to back you up even more, I'm a big video game fan.
[02:04:48.320 --> 02:04:51.120]   I talk about video games on podcasts.
[02:04:51.120 --> 02:04:57.440]   And I was actually an employee of Blizzard, which is part of Activision Blizzard.
[02:04:57.440 --> 02:04:59.360]   Part of the problem.
[02:04:59.360 --> 02:05:00.360]   Yes.
[02:05:00.360 --> 02:05:02.000]   Part of the problem, sure.
[02:05:02.000 --> 02:05:07.480]   The problem seems to only manifest in the US if there is a problem at all.
[02:05:07.480 --> 02:05:15.200]   Because actually, ever since the video game generation started happening, violence has
[02:05:15.200 --> 02:05:17.160]   been actually, it's not since then.
[02:05:17.160 --> 02:05:21.040]   But for a long time, violence has been going down.
[02:05:21.040 --> 02:05:26.880]   And in Finland, there's a funny side effect as well.
[02:05:26.880 --> 02:05:29.720]   Alcoholism has been a problem for a long time.
[02:05:29.720 --> 02:05:35.360]   And that has been decreasing because the kids are playing games and hanging out on the internet.
[02:05:35.360 --> 02:05:43.000]   So I don't know how much killing teaching those games are doing because people are killing
[02:05:43.000 --> 02:05:45.200]   and being less and less violent.
[02:05:45.200 --> 02:05:47.480]   So yes, it is a generational thing.
[02:05:47.480 --> 02:05:48.800]   They don't understand it.
[02:05:48.800 --> 02:05:50.160]   And they just don't like it.
[02:05:50.160 --> 02:05:53.120]   I have to say, I'm shocked to find that younger Finns are not drinking so much.
[02:05:53.120 --> 02:05:56.040]   I had some epic hangovers from trips to Finland.
[02:05:56.040 --> 02:05:57.280]   Nobody drinks like those.
[02:05:57.280 --> 02:06:02.160]   I was like, if you saw someone put the top back on a vodka bottle, you were shocked.
[02:06:02.160 --> 02:06:03.160]   You know?
[02:06:03.160 --> 02:06:04.160]   Exactly.
[02:06:04.160 --> 02:06:06.680]   I actually should correct myself because I don't want to misstate.
[02:06:06.680 --> 02:06:09.720]   I don't know if Bernie Sanders was one of the people critical of video games.
[02:06:09.720 --> 02:06:14.760]   In fact, he said in the past that video games have been a scapegoat for gun violence.
[02:06:14.760 --> 02:06:15.640]   And that's inappropriate.
[02:06:15.640 --> 02:06:19.040]   So he's also called for the unionization of video games developers.
[02:06:19.040 --> 02:06:20.040]   So I don't know.
[02:06:20.040 --> 02:06:21.040]   Oh, that's a big problem.
[02:06:21.040 --> 02:06:24.640]   We also have to take the cynical political view, which is that Bernie Sanders is going
[02:06:24.640 --> 02:06:25.640]   after the youth.
[02:06:25.640 --> 02:06:28.600]   Like his supporters are younger than people against video games.
[02:06:28.600 --> 02:06:31.400]   And to a certain extent, Biden is going after.
[02:06:31.400 --> 02:06:35.320]   He's trying to already run the election against Trump and the main.
[02:06:35.320 --> 02:06:37.360]   You know, he's basically going for the center.
[02:06:37.360 --> 02:06:41.880]   So he's going for the older voters who are going to also be disgusted by violent video
[02:06:41.880 --> 02:06:42.880]   games and so on.
[02:06:42.880 --> 02:06:45.160]   So I think that most of this is just political politics.
[02:06:45.160 --> 02:06:50.680]   I'm middle aged though, the very idea that Call of Duty teaches people to kill.
[02:06:50.680 --> 02:06:54.440]   You know, it's like there's a world of difference between firing an actual gun and firing a
[02:06:54.440 --> 02:06:55.440]   virtual water.
[02:06:55.440 --> 02:06:57.480]   And I know you're going to be an American citizen at some point, right?
[02:06:57.480 --> 02:06:59.960]   So I can tell you where you can get a good deal on some of that.
[02:06:59.960 --> 02:07:01.080]   Hey, I go to gun ranges.
[02:07:01.080 --> 02:07:04.600]   I enjoy the pleasure of getting a good good fit right in.
[02:07:04.600 --> 02:07:08.600]   You know, I shot as a school kid in the UK when you're still good.
[02:07:08.600 --> 02:07:09.600]   I mean, Fox Hunt.
[02:07:09.600 --> 02:07:10.600]   I've got no pro.
[02:07:10.600 --> 02:07:13.720]   No, I draw the line at dressing up like a complete idiot and writing over people's
[02:07:13.720 --> 02:07:15.720]   fields without asking them.
[02:07:15.720 --> 02:07:19.720]   Now I think it's much more considerate to the Fox to shoot it on site.
[02:07:19.720 --> 02:07:23.720]   But no, the whole thing about, oh, it's teaching people to kill.
[02:07:23.720 --> 02:07:28.720]   It just tries to mean it's the kind of thing that it's happy lies that you sell to grandparents
[02:07:28.720 --> 02:07:32.720]   who are worried about their kids, which is, I think, what Biden is going for.
[02:07:32.720 --> 02:07:38.720]   And how do we feel just briefly about calling people who have accomplished quite a bit at
[02:07:38.720 --> 02:07:40.720]   a very young age, little creeps?
[02:07:40.720 --> 02:07:47.720]   Is this an inappropriate thing to say to somebody who's a CEO of a company that is successful?
[02:07:47.720 --> 02:07:51.720]   Ricci Tello is a little bit real little green.
[02:07:51.720 --> 02:07:53.720]   I mean, I don't want to.
[02:07:53.720 --> 02:08:02.720]   He does look like a villain from a dystopian novel.
[02:08:02.720 --> 02:08:08.720]   And I think a lot of video gamers would not really embrace electronic arts particularly.
[02:08:08.720 --> 02:08:13.720]   They've got a scummy record of dealing with their employees overworking and harassing.
[02:08:13.720 --> 02:08:18.720]   I mean, EA has, I've heard so many people to say horror stories of people working at EA
[02:08:18.720 --> 02:08:21.720]   and some other games companies when there's a rush on.
[02:08:21.720 --> 02:08:25.720]   Still, just the way of the industry it seems.
[02:08:25.720 --> 02:08:32.720]   DHS Department of Homeland Security warning people about patient monitors sold by GE Healthcare
[02:08:32.720 --> 02:08:39.720]   on a scale of one to ten.
[02:08:39.720 --> 02:08:44.720]   The severity of five of these six vulnerabilities is ten.
[02:08:44.720 --> 02:08:49.720]   These are collectively known as MD Hex.
[02:08:49.720 --> 02:08:50.720]   They exist.
[02:08:50.720 --> 02:08:56.720]   It's nothing you probably are using, but something your doctor, my GE's line of care-scape patient monitors,
[02:08:56.720 --> 02:09:01.720]   including some versions of the central information center product, the Apex telemetry server,
[02:09:01.720 --> 02:09:04.180]   and the other two levels of the
[02:09:04.180 --> 02:09:04.820]   hospitals, the
[02:09:04.820 --> 02:09:11.720]   hospitals, the hospitals, the hospitals, the hospitals, the hospitals, the hospitals, the hospitals.
[02:09:11.720 --> 02:09:12.720]   I don't know.
[02:09:12.720 --> 02:09:17.720]   Well, I mean, there was some truly horrifying talks on this at security conferences.
[02:09:17.720 --> 02:09:21.720]   If you look at the state of MedTech, it's pathetically bad at the moment.
[02:09:21.720 --> 02:09:22.720]   And they managed to...
[02:09:22.720 --> 02:09:24.720]   And are these things online?
[02:09:24.720 --> 02:09:29.720]   They said they set up a remote hack, so if you got with a five feet of someone,
[02:09:29.720 --> 02:09:33.720]   they're pacemakers, just go constant jing jing jing jing jing jing.
[02:09:33.720 --> 02:09:37.720]   If somebody did hack this, they could actually discharge patients.
[02:09:37.720 --> 02:09:38.720]   Not a bad thing.
[02:09:38.720 --> 02:09:39.720]   All of them.
[02:09:39.720 --> 02:09:41.720]   You're all better.
[02:09:41.720 --> 02:09:42.720]   Go home.
[02:09:42.720 --> 02:09:48.720]   And also the problem is, they were saying on one conference that, okay, if somebody sets your pacemaker to zap you constantly,
[02:09:48.720 --> 02:09:52.720]   you can take it out, but there are an awful lot of doctors who have virtually no training
[02:09:52.720 --> 02:09:56.720]   in how to take these things out, because once they're in there, they never come out.
[02:09:56.720 --> 02:09:59.720]   It's supposed to take them out.
[02:09:59.720 --> 02:10:04.720]   And so, after, obviously, before cremation, but, you know, I mean, they are designed to last as long as the patient does.
[02:10:04.720 --> 02:10:09.720]   And having to know which wires to pull out without killing the patient is something a lot of doctors don't know how to do.
[02:10:09.720 --> 02:10:14.720]   By the way, we were talking about SWAT and the Petaluma tanks.
[02:10:14.720 --> 02:10:22.720]   There is a good reason why you wouldn't want your municipality to have heavy warfare armor swatting.
[02:10:22.720 --> 02:10:27.720]   In fact, there's always been a problem with swatting, which is people calling falsely saying,
[02:10:27.720 --> 02:10:32.720]   you know, I'm being held hostage or there's gunmen in my house, and then SWAT teams come out.
[02:10:32.720 --> 02:10:39.720]   It's very dangerous because these teams, people do get killed from time to time by the police, by SWAT teams.
[02:10:39.720 --> 02:10:43.720]   Apparently, people are calling SWAT teams to Tech Executives House.
[02:10:43.720 --> 02:10:46.720]   The tech backlash has begun.
[02:10:46.720 --> 02:10:51.720]   Adam Masseri, who's a senior Facebook executive, was swatted in November.
[02:10:51.720 --> 02:10:57.720]   The police in San Francisco, New York, responded to a series of telephone calls claiming hostages were being held in his home.
[02:10:57.720 --> 02:10:59.720]   He has two homes, and they were both swatted.
[02:10:59.720 --> 02:11:00.720]   Yeah.
[02:11:00.720 --> 02:11:01.720]   One of them, York, and one of them.
[02:11:01.720 --> 02:11:04.720]   And by the way, I doubt that those addresses are public.
[02:11:04.720 --> 02:11:06.720]   Right? So, somebody had to figure out where he lives.
[02:11:06.720 --> 02:11:10.720]   What I learned from this whole story is that this is actually a hobby.
[02:11:10.720 --> 02:11:14.720]   There are groups of people who get together in chat rooms and talk about best practices for SWAT.
[02:11:14.720 --> 02:11:15.720]   Oh, yeah.
[02:11:15.720 --> 02:11:18.720]   Well, I mean, the kids in Kansas have got kills.
[02:11:18.720 --> 02:11:19.720]   Little creeps.
[02:11:19.720 --> 02:11:20.720]   Those are little creeps.
[02:11:20.720 --> 02:11:21.720]   Last year.
[02:11:21.720 --> 02:11:26.720]   I mean, somebody arranged, they got into an argument over a call at duty match.
[02:11:26.720 --> 02:11:30.720]   He contacted the guy who was pissed off, got in contact with somebody else who could SWAT.
[02:11:30.720 --> 02:11:32.720]   He swatted the wrong person.
[02:11:32.720 --> 02:11:34.720]   The police turned up and he was shot and shot and dead.
[02:11:34.720 --> 02:11:36.720]   They're now facing 20 years in prison.
[02:11:36.720 --> 02:11:39.720]   I hope they rot there to be quite frank, but, you know, it's just...
[02:11:39.720 --> 02:11:42.720]   It would only be possible.
[02:11:42.720 --> 02:11:43.720]   It would...
[02:11:43.720 --> 02:11:47.720]   Okay, it's possible in any country, but it's particularly dangerous in the US
[02:11:47.720 --> 02:11:52.720]   because things are a little more trigger happy over here because everyone has to assume that everyone else has guns.
[02:11:52.720 --> 02:11:56.720]   Yeah, I mean, if a Barbie comes to my house with a truncheon, it seems unlikely.
[02:11:56.720 --> 02:12:01.720]   No, you see, you mock the truncheon and you've been hit by one of those bubbles because it really hurts.
[02:12:01.720 --> 02:12:07.720]   I've started student demos in the 90s and I've received a truncheon to the side and I can say that it really hurts
[02:12:07.720 --> 02:12:10.720]   and it doesn't capacitate you for a couple of days afterwards.
[02:12:10.720 --> 02:12:11.720]   Yeah, it breaks.
[02:12:11.720 --> 02:12:16.720]   Apparently these forums you're talking about, the Times talks about one forum.
[02:12:16.720 --> 02:12:19.720]   3,000 people on this forum.
[02:12:19.720 --> 02:12:20.720]   What should we do next?
[02:12:20.720 --> 02:12:22.720]   Read one message in the forum last month.
[02:12:22.720 --> 02:12:25.720]   The responses included gun emojis.
[02:12:25.720 --> 02:12:29.720]   That's the symbol for an attack in which the police were successfully called to the targets home.
[02:12:29.720 --> 02:12:37.720]   Many of the responses laced with profanity shocking as well as suggestions for ex-girlfriends who should be swatted.
[02:12:37.720 --> 02:12:41.720]   Oh, God, don't doubt the insult to him getting involved without the useless...
[02:12:41.720 --> 02:12:47.720]   I would imagine most of the people on these forums I would guarantee are not active swatters.
[02:12:47.720 --> 02:12:48.720]   Yeah.
[02:12:48.720 --> 02:12:49.720]   Edgleards.
[02:12:49.720 --> 02:12:54.720]   By the way, the result, by the way, that I've failed shooting in Kansas 20 years in federal prison.
[02:12:54.720 --> 02:12:55.720]   20 years, just want to let you know.
[02:12:55.720 --> 02:12:56.720]   That's fine.
[02:12:56.720 --> 02:13:00.720]   I mean, they'll be out in 10 with good behavior, but even so, that's a significance.
[02:13:00.720 --> 02:13:07.720]   Message to the rest of the community who see that this is not going to be some considered by some kind of little prank by the courts.
[02:13:07.720 --> 02:13:09.720]   It is a scary, but...
[02:13:09.720 --> 02:13:12.720]   And I assume he's not allowed to use the prison phone.
[02:13:12.720 --> 02:13:17.720]   Well, you say that, but we did a story a few years back.
[02:13:17.720 --> 02:13:23.720]   Somebody had managed to assemble a computer in the ceiling panels above the teaching room.
[02:13:23.720 --> 02:13:27.720]   It was really impressive stuff. I'd say, "Let this go out and hire him as I see it."
[02:13:27.720 --> 02:13:28.720]   I'm not even mad.
[02:13:28.720 --> 02:13:29.720]   I'm just...
[02:13:29.720 --> 02:13:30.720]   Yeah, no, it's just fantastic.
[02:13:30.720 --> 02:13:36.720]   Let's take a break and we're going to wrap it up with a few of the little tidbits that have sunk to the bottom of the rundown.
[02:13:36.720 --> 02:13:38.720]   Mike Elgin is here.
[02:13:38.720 --> 02:13:39.720]   Elgin.com.
[02:13:39.720 --> 02:13:40.720]   Your newsletter?
[02:13:40.720 --> 02:13:41.720]   Yes, Mike's List.
[02:13:41.720 --> 02:13:42.720]   Mike's List.
[02:13:42.720 --> 02:13:44.720]   Weekly comes out every Saturday.
[02:13:44.720 --> 02:13:45.720]   The Elgin Nation.
[02:13:45.720 --> 02:13:49.720]   Elgin Nation is my website where I have a podcast and a whole bunch of other stuff.
[02:13:49.720 --> 02:13:50.720]   Nice.
[02:13:50.720 --> 02:13:51.720]   Nice.
[02:13:51.720 --> 02:13:55.720]   Of course, Gastronomad.net for people who want to go on these amazing Gastronomads.
[02:13:55.720 --> 02:13:56.720]   Yup.
[02:13:56.720 --> 02:13:57.720]   I'm the Prosecco.
[02:13:57.720 --> 02:13:58.720]   Oh, man.
[02:13:58.720 --> 02:13:59.720]   I'm so jealous.
[02:13:59.720 --> 02:14:00.720]   I have your mind blown by the bubbles of the...
[02:14:00.720 --> 02:14:03.720]   Ian Thompson and I are going to go to the new pedal on the Shake Shack.
[02:14:03.720 --> 02:14:04.720]   That's our treat.
[02:14:04.720 --> 02:14:05.720]   Nice.
[02:14:05.720 --> 02:14:06.720]   Oh, yeah.
[02:14:06.720 --> 02:14:07.720]   Yes, I've been...
[02:14:07.720 --> 02:14:09.720]   You have been raving about this place.
[02:14:09.720 --> 02:14:11.720]   If you're going to be an American, you got to try Shake Shack.
[02:14:11.720 --> 02:14:12.720]   There's no...
[02:14:12.720 --> 02:14:13.720]   Staking Shake actually.
[02:14:13.720 --> 02:14:14.720]   It's all the donuts we can tell you.
[02:14:14.720 --> 02:14:15.720]   Staking Shake.
[02:14:15.720 --> 02:14:16.720]   Staking Shake.
[02:14:16.720 --> 02:14:17.720]   That's all the line at that.
[02:14:17.720 --> 02:14:18.720]   Yes.
[02:14:18.720 --> 02:14:21.720]   He's from the register.co.uk from frenchspin.com.
[02:14:21.720 --> 02:14:24.720]   Our wonderful friend Patrick Bezha.
[02:14:24.720 --> 02:14:25.720]   It's great to see you.
[02:14:25.720 --> 02:14:30.720]   Our show today brought to you literally, quite literally, by CashFly, our content delivery network.
[02:14:30.720 --> 02:14:34.720]   You want a content delivery network if you have podcasts, of course, or any content you can
[02:14:34.720 --> 02:14:40.720]   deliver to your users or your viewers, whether it's an app or data.
[02:14:40.720 --> 02:14:45.720]   Because the CDN makes sure the roads roll, that the podcasts get delivered.
[02:14:45.720 --> 02:14:51.720]   The data never stops and CashFly makes it possible at a lower cost than anybody else.
[02:14:51.720 --> 02:14:58.720]   Rich media content 10 times faster than traditional delivery methods, even 30% faster than the other big CDNs.
[02:14:58.720 --> 02:15:08.720]   And with a 100% SLA, CashFly guarantees the best user experience for all your customers, no matter where they are or what device they're on.
[02:15:08.720 --> 02:15:15.720]   Because CashFly puts our shows close to you on a server near you, it downloads faster.
[02:15:15.720 --> 02:15:17.720]   And that's really important to me.
[02:15:17.720 --> 02:15:19.720]   We were struggling in the early years of Twitch.
[02:15:19.720 --> 02:15:22.720]   We've had a bit torrent and all sorts of different ways to deliver.
[02:15:22.720 --> 02:15:27.720]   Along came Matt Levine, the founder of CashFly said, "Let us help you."
[02:15:27.720 --> 02:15:29.720]   And man, it's been a 10-year relationship.
[02:15:29.720 --> 02:15:35.720]   Every month, we literally deliver petabytes of data to our listeners and viewers over CashFly.
[02:15:35.720 --> 02:15:36.720]   We love CashFly.
[02:15:36.720 --> 02:15:37.720]   We're not alone.
[02:15:37.720 --> 02:15:42.720]   LG, Microsoft, Adobe, R's, Technica, all use CashFly.
[02:15:42.720 --> 02:15:50.720]   Say goodbye to checking multiple times a week or even daily to make sure you don't exceed some artificial CDN limit.
[02:15:50.720 --> 02:15:52.720]   There are no billing spikes with CashFly.
[02:15:52.720 --> 02:15:58.720]   You'll get a custom plan tailored to your needs based on yearly usage so that smooths out all those spikes.
[02:15:58.720 --> 02:16:03.720]   On average customers who switch to CashFly save more than 20%.
[02:16:03.720 --> 02:16:06.720]   Right now, CashFly is giving you a complimentary detailed analysis.
[02:16:06.720 --> 02:16:11.720]   You bring them your CDN bill, your usage trends, and they'll show you what they can do for you.
[02:16:11.720 --> 02:16:12.720]   You've got to do this.
[02:16:12.720 --> 02:16:13.720]   It's well worth it.
[02:16:13.720 --> 02:16:15.720]   You may well be overpaying.
[02:16:15.720 --> 02:16:17.720]   Go to twit.cashfly.com.
[02:16:17.720 --> 02:16:19.720]   No sales pressure.
[02:16:19.720 --> 02:16:20.720]   They're nice people.
[02:16:20.720 --> 02:16:21.720]   They'll help you.
[02:16:21.720 --> 02:16:22.720]   twit.cashfly.com.
[02:16:22.720 --> 02:16:27.720]   This is the way to deliver your content, the best CDN in the business.
[02:16:27.720 --> 02:16:33.720]   I didn't even know this happened, but I found out about it as I do most things in the register.co.uk.
[02:16:33.720 --> 02:16:44.720]   Alan Turing, his OB/E metal, his PhD certificate, and other of his personal items, 250 of them, went missing decades ago.
[02:16:44.720 --> 02:16:48.720]   Turing, of course, a great computer pioneer.
[02:16:48.720 --> 02:16:52.720]   Because he was gay, he was forced, ultimately committed suicide.
[02:16:52.720 --> 02:16:56.720]   He was harassed by the British police in the 50s.
[02:16:56.720 --> 02:17:00.720]   Later, of course, apology was issued to Alan Turing.
[02:17:00.720 --> 02:17:03.720]   Thanks to our friend John Graham coming at Cloudflare.
[02:17:03.720 --> 02:17:06.720]   He got that petition started and the UK government did apologize.
[02:17:06.720 --> 02:17:09.720]   Finally, and in 2013, I believe, yeah.
[02:17:09.720 --> 02:17:11.720]   But I didn't know his documents were missing.
[02:17:11.720 --> 02:17:13.720]   Apparently, they were found.
[02:17:13.720 --> 02:17:15.720]   Yeah, in Colorado.
[02:17:15.720 --> 02:17:16.720]   In Colorado?
[02:17:16.720 --> 02:17:21.720]   This is one of the weirdest tales we've covered in quite some time.
[02:17:21.720 --> 02:17:26.720]   Basically, various documents, including his OB/E, his PhD, his school reports.
[02:17:26.720 --> 02:17:28.720]   Order of the British Empire, his knighthood.
[02:17:28.720 --> 02:17:29.720]   It's not a knighthood.
[02:17:29.720 --> 02:17:31.720]   It's a little less than that.
[02:17:31.720 --> 02:17:34.720]   But they were stored by his old boarding school.
[02:17:34.720 --> 02:17:39.720]   In the 80s, this woman turned up and asked to see them.
[02:17:39.720 --> 02:17:42.720]   They didn't keep an eye on her, and she felt an awful lot of documents.
[02:17:42.720 --> 02:17:44.720]   That's kind of inexcusable.
[02:17:44.720 --> 02:17:46.720]   Well, she then sent a few of them back.
[02:17:46.720 --> 02:17:50.720]   She left a note story on the archive saying, "I'm very sorry I've stolen these.
[02:17:50.720 --> 02:17:54.720]   I will be looking after them well, and I will return to them after it returns."
[02:17:54.720 --> 02:17:56.720]   And they didn't know what had been stolen, so they thought it was.
[02:17:56.720 --> 02:17:57.720]   No, that's even not here.
[02:17:57.720 --> 02:17:59.720]   No, they didn't know what had been stolen.
[02:17:59.720 --> 02:18:03.720]   She sent some back, but this woman is obviously several flying buttresses.
[02:18:03.720 --> 02:18:05.720]   She claimed to be his daughter.
[02:18:05.720 --> 02:18:06.720]   She claimed to be his daughter.
[02:18:06.720 --> 02:18:07.720]   She claimed to be his daughter.
[02:18:07.720 --> 02:18:09.720]   She changed her last name to Turing.
[02:18:09.720 --> 02:18:16.720]   She changed her middle name to his mouth-a-son, which I think was his middle name.
[02:18:16.720 --> 02:18:19.720]   Clearly, several flying buttresses short of a cathedral.
[02:18:19.720 --> 02:18:26.720]   She tried to sue for copyright over pictures of photos that she'd stolen herself.
[02:18:26.720 --> 02:18:32.720]   And then she gave one of these things to her sister, who took it to the police saying it was stolen.
[02:18:32.720 --> 02:18:38.720]   And they found them two years ago, hidden in a briefcase behind her toilet.
[02:18:38.720 --> 02:18:44.720]   And it's only just now come to a fact that the US government is saying that it were imported illegally,
[02:18:44.720 --> 02:18:50.720]   and therefore they should go back to the school, which is hopefully take a slightly more carer than this time.
[02:18:50.720 --> 02:18:51.720]   These are important documents.
[02:18:51.720 --> 02:18:53.720]   The school is a little culpable, for instance.
[02:18:53.720 --> 02:18:59.720]   They didn't know what she had taken, so she sent some stuff back, and they said, "Oh, well, I guess we got everything back."
[02:18:59.720 --> 02:19:05.720]   She kept his OBE and sent them somebody else's gong.
[02:19:05.720 --> 02:19:07.720]   I guess the OBE looks like a little bit like a gong.
[02:19:07.720 --> 02:19:11.720]   You can buy them for 30 bucks, but they said somebody else's gong.
[02:19:11.720 --> 02:19:13.720]   And said, "This is the OBE."
[02:19:13.720 --> 02:19:17.720]   But she kept the original, which came with a message from King George VI,
[02:19:17.720 --> 02:19:21.720]   apologizing for not being able to give the award in person.
[02:19:21.720 --> 02:19:24.720]   Wow, I mean, this is historic stuff.
[02:19:24.720 --> 02:19:26.720]   Well, no, I mean, she was also...
[02:19:26.720 --> 02:19:29.720]   She tried the same thing in the Manchester archives, where an awful lot of his stuff is kept.
[02:19:29.720 --> 02:19:32.720]   And thankfully they kept a...
[02:19:32.720 --> 02:19:35.720]   I think Superfan is being overly polite.
[02:19:35.720 --> 02:19:38.720]   This woman was scarily obsessed with Turing.
[02:19:38.720 --> 02:19:43.720]   And she wrote letters to Pink News when the film came out about him,
[02:19:43.720 --> 02:19:46.720]   just like, "This is terrible. Why was I consulted as a contract?
[02:19:46.720 --> 02:19:48.720]   As a consultant, that's the thing."
[02:19:48.720 --> 02:19:53.720]   It's just, you know, as I say, this is a strong case for better mental health than...
[02:19:53.720 --> 02:19:56.720]   In her defense, her real name was Schwinghammer.
[02:19:56.720 --> 02:19:59.720]   [LAUGHTER]
[02:19:59.720 --> 02:20:01.720]   So maybe she just...
[02:20:01.720 --> 02:20:06.720]   Now, I can understand why she has to change it, but to steal the nation's heritage is possibly...
[02:20:06.720 --> 02:20:08.720]   [LAUGHTER]
[02:20:08.720 --> 02:20:09.720]   Okay.
[02:20:09.720 --> 02:20:10.720]   Anyway...
[02:20:10.720 --> 02:20:11.720]   [INTERPOSING VOICES]
[02:20:11.720 --> 02:20:14.720]   That just sounded like the next Wayne's World thing.
[02:20:14.720 --> 02:20:16.720]   I want to...
[02:20:16.720 --> 02:20:21.720]   We have a good friend, throwboy, who makes amazing stuff.
[02:20:21.720 --> 02:20:24.720]   I have his full-sized Macintosh pillow.
[02:20:24.720 --> 02:20:27.720]   Actually, John, would you fetch that out of my office?
[02:20:27.720 --> 02:20:31.720]   He's now making little pocket pillows, put it up on Kickstarter.
[02:20:31.720 --> 02:20:35.720]   Three days ago, he's already doubled his pledges.
[02:20:35.720 --> 02:20:38.720]   He's got 10,000 raised and more to come.
[02:20:38.720 --> 02:20:42.720]   Wouldn't you like a little pocket pillow of the classic...
[02:20:42.720 --> 02:20:44.720]   He can't call it a Macintosh, probably.
[02:20:44.720 --> 02:20:47.720]   There's also the Bondi Blue, you know who...
[02:20:47.720 --> 02:20:50.720]   Named after the beautiful beach in Sirolecud.
[02:20:50.720 --> 02:20:51.720]   That's gonna be sad.
[02:20:51.720 --> 02:20:52.720]   Here, throw me the...
[02:20:52.720 --> 02:20:53.720]   Throw me...
[02:20:53.720 --> 02:20:54.720]   This is not the pocket pillow.
[02:20:54.720 --> 02:20:57.720]   This is the full-sized pillow, but it is...
[02:20:57.720 --> 02:20:58.720]   Isn't that cute?
[02:20:58.720 --> 02:20:59.720]   Isn't that cute?
[02:20:59.720 --> 02:21:00.720]   It's gonna take you back.
[02:21:00.720 --> 02:21:01.720]   Yeah.
[02:21:01.720 --> 02:21:05.720]   I keep that in my office so I can sleep on whenever I get tired.
[02:21:05.720 --> 02:21:09.720]   So I just want to give throwboy a little plug, good job throwboy.
[02:21:09.720 --> 02:21:12.720]   And there it is.
[02:21:12.720 --> 02:21:13.720]   And...
[02:21:13.720 --> 02:21:17.720]   Let's see, there's a couple of other things I want to do before we wrap it up.
[02:21:17.720 --> 02:21:20.720]   Oh, actually, two sad stories, and I'll mention.
[02:21:20.720 --> 02:21:22.720]   Clayton Christensen, his passed away.
[02:21:22.720 --> 02:21:24.720]   He was the guy who wrote the Innovators Dilemma.
[02:21:24.720 --> 02:21:28.720]   He was only 67, but a very influential thinker.
[02:21:28.720 --> 02:21:34.720]   His books were quoted and used by many in Silicon Valley, including Steve Jobs,
[02:21:34.720 --> 02:21:39.720]   Reed Hastings of Netflix, Andy Grove of Intel, Jeff Bezos at Amazon.
[02:21:39.720 --> 02:21:47.720]   The Innovators Dilemma is an absolute classic business book and describes a dilemma that every modern tech company faces,
[02:21:47.720 --> 02:21:52.720]   the difficulty of innovating when you've got a successful product.
[02:21:52.720 --> 02:21:54.720]   It's tough to do.
[02:21:54.720 --> 02:21:58.720]   And then also a little bit closer and nearer, dear to our heart.
[02:21:58.720 --> 02:22:06.720]   Leila Jana, who was an amazing entrepreneur, working hard to make AI more equitable,
[02:22:06.720 --> 02:22:09.720]   passed away at the age of 37 of complications.
[02:22:09.720 --> 02:22:16.720]   She's very young, yeah, a cancer, a bachelioid carcinoma or sarcoma.
[02:22:16.720 --> 02:22:18.720]   She had fallen ill a couple of years ago.
[02:22:18.720 --> 02:22:20.720]   We interviewed her on triangulation.
[02:22:20.720 --> 02:22:21.720]   There you go.
[02:22:21.720 --> 02:22:29.720]   About 2017, I think, and she was just such an impressive, such a smart, talented person.
[02:22:29.720 --> 02:22:32.720]   So, very sorry for her friends and family.
[02:22:32.720 --> 02:22:35.720]   Leila Jana passed away too young.
[02:22:35.720 --> 02:22:41.720]   And of course, Terry Jones, Mottie Pythons, Terry Jones passed away at the age of 77.
[02:22:41.720 --> 02:22:45.720]   Graham Chapman passed away about 20 years ago in '85.
[02:22:45.720 --> 02:22:47.720]   She's so gosh, that's about almost 40 years ago.
[02:22:47.720 --> 02:22:51.720]   Also, I would watch out for the, hopefully, the release footage of the funeral,
[02:22:51.720 --> 02:22:53.720]   because if you watch Graham Chapman's funeral...
[02:22:53.720 --> 02:22:56.720]   I've seen it with John Cleese's eudity to him.
[02:22:56.720 --> 02:22:57.720]   It is just marvelous.
[02:22:57.720 --> 02:23:00.720]   You cannot watch it without tears and their eyes and their tears of laughter.
[02:23:00.720 --> 02:23:02.720]   It's just genius.
[02:23:02.720 --> 02:23:05.720]   And I'm sure he will do the same for Terry Jones.
[02:23:05.720 --> 02:23:07.720]   Yeah, well, Terry was a very naughty boy.
[02:23:07.720 --> 02:23:08.720]   So...
[02:23:08.720 --> 02:23:11.720]   Well, passed away at the age of 77.
[02:23:11.720 --> 02:23:12.720]   He suffered from dementia.
[02:23:12.720 --> 02:23:14.720]   He got prefrontal dementia, so it was kind of a blessing in a way.
[02:23:14.720 --> 02:23:15.720]   Yeah.
[02:23:15.720 --> 02:23:18.720]   I think that's about it.
[02:23:18.720 --> 02:23:21.720]   Is there anything else you want to cover, Patrick?
[02:23:21.720 --> 02:23:25.720]   Did I miss any of the big stories in your world?
[02:23:25.720 --> 02:23:33.720]   I don't think it's a huge story, but there is a question about vine coming back as well.
[02:23:33.720 --> 02:23:36.720]   Are you going to download it right away, bite?
[02:23:36.720 --> 02:23:37.720]   Vine's coming back.
[02:23:37.720 --> 02:23:38.720]   Well, the guy who's...
[02:23:38.720 --> 02:23:40.720]   Okay, vine, what a sad story that is.
[02:23:40.720 --> 02:23:41.720]   Yeah.
[02:23:41.720 --> 02:23:42.720]   The guy who started vine...
[02:23:42.720 --> 02:23:44.720]   Actually, we're a couple of founders.
[02:23:44.720 --> 02:23:53.720]   One of the guys, Vine was sold to Twitter, which killed it almost instantly because vine creators
[02:23:53.720 --> 02:24:00.720]   went to Twitter and said, "We want to be compensated because we're making your product.
[02:24:00.720 --> 02:24:01.720]   We're making a success."
[02:24:01.720 --> 02:24:02.720]   And Twitter said, "Absolutely not."
[02:24:02.720 --> 02:24:04.720]   So they all pulled out.
[02:24:04.720 --> 02:24:08.720]   And Twitter ended up killing Vine very, very quickly in 2017.
[02:24:08.720 --> 02:24:14.720]   Dom Hoffman, who's one of the co-founders, has been saying, "I'm going to bring Vine back
[02:24:14.720 --> 02:24:15.720]   after months and closed beta.
[02:24:15.720 --> 02:24:17.720]   It is back now on Android and iOS.
[02:24:17.720 --> 02:24:21.720]   It's called bite, B-Y-T-E."
[02:24:21.720 --> 02:24:22.720]   Unlike...
[02:24:22.720 --> 02:24:23.720]   It's a little late because TikTok is...
[02:24:23.720 --> 02:24:31.720]   Yeah, it's pretty much taken the vine mantle, but bite is limited to six second videos like
[02:24:31.720 --> 02:24:33.720]   Vine was.
[02:24:33.720 --> 02:24:35.720]   And I downloaded it.
[02:24:35.720 --> 02:24:40.720]   It really is exactly Vine, and I don't know that it's going to...
[02:24:40.720 --> 02:24:45.720]   Because vine did have, for some reason, I wasn't a huge fan, but it did have a community.
[02:24:45.720 --> 02:24:47.720]   It was very creative.
[02:24:47.720 --> 02:24:50.720]   Like 60 million people or something.
[02:24:50.720 --> 02:24:56.720]   Oh, and Vine created some big, big stars who have gone on to start them on YouTube and other
[02:24:56.720 --> 02:24:57.720]   places I'm playing on.
[02:24:57.720 --> 02:24:59.720]   And Twitter killed it because server space is expensive.
[02:24:59.720 --> 02:25:02.720]   No, no, they killed it because all the creators left.
[02:25:02.720 --> 02:25:05.720]   They killed it because they wouldn't give the creators any money, by the way.
[02:25:05.720 --> 02:25:07.720]   Dom has learned a little bit from that.
[02:25:07.720 --> 02:25:13.720]   And TikTok, which does share revenue and has lots of ways for creators to profit, bite will
[02:25:13.720 --> 02:25:15.720]   apparently do the same thing.
[02:25:15.720 --> 02:25:16.720]   So...
[02:25:16.720 --> 02:25:17.720]   Well, I think they're playing on a better...
[02:25:17.720 --> 02:25:27.720]   I mean, I think one of the complaints of TikTok users is that it's hard to monetize, which is why so many of them go to TikTok videos and they put them on YouTube.
[02:25:27.720 --> 02:25:31.720]   This is always going to be a problem.
[02:25:31.720 --> 02:25:38.720]   And you live on these platforms and you die on these platforms and you hope that these platforms will compensate you.
[02:25:38.720 --> 02:25:40.720]   YouTube isn't much better.
[02:25:40.720 --> 02:25:46.720]   I look at so many people pour their life, their blood into the YouTube and make no money at all.
[02:25:46.720 --> 02:25:53.720]   But they look at, they revere the 20 people like the eight-year-old who talk about who are making millions of dollars a year, but it's hard to get to that position.
[02:25:53.720 --> 02:25:55.720]   Well, usually it's not a lie for YouTube.
[02:25:55.720 --> 02:25:57.720]   We get literally nothing.
[02:25:57.720 --> 02:25:59.720]   Oh, no, I get the fair amount of abuse.
[02:25:59.720 --> 02:26:01.720]   Let's be fair.
[02:26:01.720 --> 02:26:04.720]   That's a good one. Thank you, Patrick. I had neglected to mention that.
[02:26:04.720 --> 02:26:10.720]   Yeah, just kind of mean more people like Logan Paul and the rest of them, just useless wastes of flesh and organs.
[02:26:10.720 --> 02:26:15.720]   Anything I missed in your world, Ian Thompson, any stories of these other big ones?
[02:26:15.720 --> 02:26:19.720]   Well, fortunately, I was a week later on this, but the invention of the laser printer died.
[02:26:19.720 --> 02:26:21.720]   I don't know if you covered this in this week's show.
[02:26:21.720 --> 02:26:22.720]   No, we did not.
[02:26:22.720 --> 02:26:24.720]   But that was a sad one.
[02:26:24.720 --> 02:26:26.720]   The obituaries are always never fun.
[02:26:26.720 --> 02:26:30.720]   Honestly, we're getting to that stage in technology.
[02:26:30.720 --> 02:26:33.720]   The first of the three years as a...
[02:26:33.720 --> 02:26:34.720]   Yeah, they're getting on.
[02:26:34.720 --> 02:26:45.720]   I know we've had the co-founder of ARPANET die in the last six months, and if I could get the time and the money, I would just spend a year going round all these first movers into the field.
[02:26:45.720 --> 02:26:55.720]   Honestly, that's been the point of my career back at Tech TV, and here with triangulation was to talk to as many of those people and get them on tape, get video games, and get video games.
[02:26:55.720 --> 02:27:03.720]   So a record would be kept because in the early days, they weren't lionized, they weren't revered, they weren't famous.
[02:27:03.720 --> 02:27:07.720]   They just were amazing inventors who actually changed the world.
[02:27:07.720 --> 02:27:14.720]   And years to come, people will look back at people like Douglas Engelbart and say, "Wow!" or Alan Kay, and so it's important to...
[02:27:14.720 --> 02:27:16.720]   We who know who they are, I remember those.
[02:27:16.720 --> 02:27:19.720]   No, I think there's a different project to be done there.
[02:27:19.720 --> 02:27:25.720]   Well, I think we've done some of it, and I encourage others to do the same because it is...
[02:27:25.720 --> 02:27:28.720]   We can all agree Steve Jobs was a wanker, but yeah, it's just...
[02:27:28.720 --> 02:27:29.720]   I never did interview him.
[02:27:29.720 --> 02:27:33.720]   Gary Starkweather was the inventor of the laser printer.
[02:27:33.720 --> 02:27:38.720]   We have to be quite careful at the rush because we have sort of near to the knuckle headlines, and we did get some...
[02:27:38.720 --> 02:27:43.720]   When I heard about that, it was just who we do, runs out of toner, is that too strong?
[02:27:43.720 --> 02:27:50.720]   No, no, no, no.
[02:27:50.720 --> 02:28:02.520]   Well, we did it with one of the fans of the IBM PC, and it's like when Blue Screen all goes and disc
[02:28:02.520 --> 02:28:17.520]   anyone who's ever played will appreciate it.
[02:28:17.520 --> 02:28:20.520]   Oh, yeah, no, they're trying to buy HP ink.
[02:28:20.520 --> 02:28:21.520]   Oh, really?
[02:28:21.520 --> 02:28:23.520]   Xerox is doing a hostile takeover of HP ink.
[02:28:23.520 --> 02:28:25.520]   There's a story we didn't cover.
[02:28:25.520 --> 02:28:28.520]   Oh, okay, this was a couple of weeks ago.
[02:28:28.520 --> 02:28:34.520]   It's a call I think it is and a bunch of institutes and investors, they're...
[02:28:34.520 --> 02:28:37.520]   They've got 24 billion dollars in funding to do this.
[02:28:37.520 --> 02:28:42.520]   Yeah, they're loading up on debt, they're going to go for Xerox, and they're going to go for that patent bundle.
[02:28:42.520 --> 02:28:43.520]   Oh, that's sad.
[02:28:43.520 --> 02:28:48.520]   They're going to go for HP, and they're going to go for the patent bundle and milk the ink ink.
[02:28:48.520 --> 02:28:50.520]   Just as HP is starting to make some...
[02:28:50.520 --> 02:28:55.520]   Finally, make some really great computers, they went through a bad spell with the pavilion and so forth.
[02:28:55.520 --> 02:28:56.520]   Oh, those were done.
[02:28:56.520 --> 02:28:58.520]   The laptops are fantastic.
[02:28:58.520 --> 02:29:00.520]   That's very sad out here.
[02:29:00.520 --> 02:29:04.520]   Like, any stories I missed, have you talked about Octi on any of your videos?
[02:29:04.520 --> 02:29:10.520]   Octi is basically an AR app that pivoted to become a social network.
[02:29:10.520 --> 02:29:16.520]   So basically what works now is after you've established a friend connection on the Octi app,
[02:29:16.520 --> 02:29:22.520]   you walk up to them, you hold your phone, and on the phone, the content they have posted is orbiting around their body.
[02:29:22.520 --> 02:29:24.520]   Oh, man, I love this.
[02:29:24.520 --> 02:29:28.520]   I don't know if you can tap on something and get their music that they're playing or their status update or whatever.
[02:29:28.520 --> 02:29:30.520]   It's a little weird because you're standing right there.
[02:29:30.520 --> 02:29:32.520]   That's kind of brilliant.
[02:29:32.520 --> 02:29:39.520]   Yeah, but I mean, I think for high school students, stuff like that, it's a way to basically carry your social networking around in physical space.
[02:29:39.520 --> 02:29:42.520]   Presumably you've got to have a handset powerful enough to handle this.
[02:29:42.520 --> 02:29:46.520]   I don't know why anything modern wouldn't do this.
[02:29:46.520 --> 02:29:48.520]   It's an interesting idea.
[02:29:48.520 --> 02:29:50.520]   It's an interesting idea.
[02:29:50.520 --> 02:29:55.520]   There have been multiple attempts to create real world, meat space kind of social networking.
[02:29:55.520 --> 02:29:59.520]   Remember, what was it called? Color where you could just like everybody in.
[02:29:59.520 --> 02:30:00.520]   Yeah, big flop.
[02:30:00.520 --> 02:30:01.520]   Almost instant flop.
[02:30:01.520 --> 02:30:05.520]   But it was an interesting idea to socially network with the people you were saying.
[02:30:05.520 --> 02:30:10.520]   I think the problem is that I don't really know anybody in real life.
[02:30:10.520 --> 02:30:13.520]   I don't think you're the target audience.
[02:30:13.520 --> 02:30:14.520]   Oh, okay.
[02:30:14.520 --> 02:30:19.520]   Although, could you imagine somebody walks in to do your show, you just hold the thing up and say,
[02:30:19.520 --> 02:30:20.520]   I'm downloading it right now.
[02:30:20.520 --> 02:30:22.520]   It's available on iOS, OC.
[02:30:22.520 --> 02:30:23.520]   Yeah, I think it's only.
[02:30:23.520 --> 02:30:24.520]   Yeah, yeah.
[02:30:24.520 --> 02:30:25.520]   Of course it is.
[02:30:25.520 --> 02:30:27.520]   Because why wouldn't you?
[02:30:27.520 --> 02:30:29.520]   Why would you want to be on any other platform?
[02:30:29.520 --> 02:30:30.520]   Exactly.
[02:30:30.520 --> 02:30:32.520]   Ladies and gentlemen, I thank you so much for being here.
[02:30:32.520 --> 02:30:35.520]   Thank you so much to our friends from the Cambera Grammar School.
[02:30:35.520 --> 02:30:36.520]   It was great to have you.
[02:30:36.520 --> 02:30:37.520]   Thanks for the Tim Tams.
[02:30:37.520 --> 02:30:38.520]   They're all gone.
[02:30:38.520 --> 02:30:39.520]   Thanks.
[02:30:39.520 --> 02:30:40.520]   They're all gone.
[02:30:40.520 --> 02:30:41.520]   They got it.
[02:30:41.520 --> 02:30:43.520]   Happy Australia Day to you.
[02:30:43.520 --> 02:30:46.520]   I guess we'll have to eat these shapes crackers next.
[02:30:46.520 --> 02:30:47.520]   Dad, thank you.
[02:30:47.520 --> 02:30:48.520]   I like them.
[02:30:48.520 --> 02:30:50.520]   Now that we're out of sugar, we'll run it.
[02:30:50.520 --> 02:30:52.520]   You guys are great.
[02:30:52.520 --> 02:30:55.520]   We really appreciate seeing you and I hope you have a wonderful time.
[02:30:55.520 --> 02:30:57.520]   You said you've been to Facebook.
[02:30:57.520 --> 02:30:59.520]   You're going to Google Next.
[02:30:59.520 --> 02:31:01.520]   Did you get to see the Apple campus yet?
[02:31:01.520 --> 02:31:03.520]   Yeah, was that cool?
[02:31:03.520 --> 02:31:04.520]   Yeah, really neat.
[02:31:04.520 --> 02:31:08.520]   And you're going wine tasting later because this is the wine country.
[02:31:08.520 --> 02:31:09.520]   Yeah, sure.
[02:31:09.520 --> 02:31:12.520]   Just tell them you're, you know, I have an autographed picture.
[02:31:12.520 --> 02:31:13.520]   Oh, nice.
[02:31:13.520 --> 02:31:14.520]   That is nice.
[02:31:14.520 --> 02:31:15.520]   Thank you all for watching.
[02:31:15.520 --> 02:31:23.920]   We do this week in tech every Sunday afternoon to 30 Pacific, 530 Eastern, 2230 UTC.
[02:31:23.920 --> 02:31:26.280]   You should tune in live if you want.
[02:31:26.280 --> 02:31:30.920]   You can watch us make the show at twit.tv/liveaudio and videos streaming there.
[02:31:30.920 --> 02:31:36.520]   If you are watching live, make sure you get in the chatroom, irc.twit.tv.
[02:31:36.520 --> 02:31:41.280]   You can chat along with the other folks who are drinking and watching at the same time.
[02:31:41.280 --> 02:31:43.040]   All that they drinking crew.
[02:31:43.040 --> 02:31:46.720]   We also do a download version of it.
[02:31:46.720 --> 02:31:48.040]   It's a podcast after all.
[02:31:48.040 --> 02:31:52.400]   And you can get those at twit.tv/twit.tv/youtube as well.
[02:31:52.400 --> 02:31:57.280]   If you are a store and forward type, you might want to join our asynchronous social network.
[02:31:57.280 --> 02:32:01.080]   It's our Twit community, a great form, a twit.community.
[02:32:01.080 --> 02:32:03.080]   We've also set up a Mastodon instance now.
[02:32:03.080 --> 02:32:08.080]   So we have Twitter style communing at twit.social.
[02:32:08.080 --> 02:32:10.520]   If you're not yet in a Mastodon instance, you should check it out.
[02:32:10.520 --> 02:32:14.880]   And if you are, you can check it out anyway because it's federated and that's the beauty
[02:32:14.880 --> 02:32:15.880]   of it.
[02:32:15.880 --> 02:32:19.560]   If you do us a favor, subscribe.
[02:32:19.560 --> 02:32:21.680]   That way you'll get every show that's available.
[02:32:21.680 --> 02:32:24.520]   Plenty of time for your Monday morning commute.
[02:32:24.520 --> 02:32:28.360]   Just find your favorite podcast app and press the subscribe button.
[02:32:28.360 --> 02:32:32.360]   One more request, if you don't mind, our Twit survey is out.
[02:32:32.360 --> 02:32:36.760]   We do this once a year at twit.to/survey20.
[02:32:36.760 --> 02:32:37.960]   Quick and easy.
[02:32:37.960 --> 02:32:39.520]   We answer a few questions.
[02:32:39.520 --> 02:32:40.960]   We're not collecting personal information.
[02:32:40.960 --> 02:32:42.720]   We don't ask for your email address.
[02:32:42.720 --> 02:32:45.480]   We just want to get to know our audience in aggregate.
[02:32:45.480 --> 02:32:49.360]   It helps us make shows that you are interested in and also helps us sell advertising.
[02:32:49.360 --> 02:32:50.600]   And of course, that's our bread and butter.
[02:32:50.600 --> 02:32:54.440]   So your help is greatly appreciated, but it's completely voluntary.
[02:32:54.440 --> 02:32:55.440]   We don't track you.
[02:32:55.440 --> 02:32:57.640]   This is all we do once a year.
[02:32:57.640 --> 02:33:00.080]   Twit.to/survey20.
[02:33:00.080 --> 02:33:02.840]   Thanks so much.
[02:33:02.840 --> 02:33:04.080]   Great to have you.
[02:33:04.080 --> 02:33:05.680]   And we will see you next time.
[02:33:05.680 --> 02:33:06.680]   Another Twit.
[02:33:06.680 --> 02:33:07.680]   It's in the case.
[02:33:07.680 --> 02:33:08.680]   Bye-bye.
[02:33:09.680 --> 02:33:17.640]   [MUSIC PLAYING]
[02:33:17.640 --> 02:33:27.640]   [BLANK_AUDIO]

