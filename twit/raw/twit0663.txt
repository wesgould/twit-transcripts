;FFMETADATA1
title=Reasonably Miserable
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=663
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:06.160]   Hi, coming up on Twitch, we have the Week in Security conferences, the banning of by
[00:00:06.160 --> 00:00:12.280]   Twitter of Kaspersky and a look at why iPhone is making quite so much money out of its latest
[00:00:12.280 --> 00:00:17.120]   handset. This is Ian Thompson at the registers, standing in for Leona Port, and this is another
[00:00:17.120 --> 00:00:30.560]   tweet.
[00:00:30.560 --> 00:00:43.560]   Bandwidth for this Week in Tech is provided by CashFly at C-A-C-H-E-F-L-Y dot com.
[00:00:43.560 --> 00:00:51.720]   This is Twitch, episode 663 recorded on April 22, 2018, reasonably miserable.
[00:00:51.720 --> 00:00:57.280]   This Week in Tech is brought to you by LastPass. Join over 13 million LastPass users and start
[00:00:57.280 --> 00:01:03.640]   managing and securing your passwords today. Learn more at LastPass dot com slash Twitch.
[00:01:03.640 --> 00:01:09.640]   And by Zippercruder hiring Zippercruder as revolutionized how you do it. Their technology
[00:01:09.640 --> 00:01:14.400]   identifies people with the right experience and invites them to apply to your job.
[00:01:14.400 --> 00:01:20.500]   Zippercruder finds great candidates for you. Try it free today at zippercruder.com/twit.
[00:01:20.500 --> 00:01:25.520]   And by Betterment, the largest independent online financial advisor. Sign up today at
[00:01:25.520 --> 00:01:30.640]   betterment.com/twit and get up to one year managed free.
[00:01:30.640 --> 00:01:37.520]   And by Eero. Never think about Wi-Fi again with Eero's hyperfast, super simple Wi-Fi
[00:01:37.520 --> 00:01:44.040]   system. And now the second generation Eero is tri-band and twice as fast. For free overnight
[00:01:44.040 --> 00:01:50.200]   shipping to the US or Canada visit Eero.com. Select overnight shipping at checkout and
[00:01:50.200 --> 00:01:54.480]   enter the code TWIT.
[00:01:54.480 --> 00:01:58.720]   I am welcome to another TWIT. I am Ian Thompson from the Register standing in for Leo Le Port
[00:01:58.720 --> 00:02:03.400]   who is currently investigating the Far East and no doubt playing Mario Kart in Tokyo and
[00:02:03.400 --> 00:02:09.600]   having an awful lot of good ramen. With me is as regular TWIT regulars will be familiar.
[00:02:09.600 --> 00:02:12.480]   Michael who is in this country for a future.
[00:02:12.480 --> 00:02:15.600]   I mean this country, can you believe it? You are the traveling technology.
[00:02:15.600 --> 00:02:21.680]   I am also in this country. And you are in person. Yeah. So yeah, I'm glad you clarified
[00:02:21.680 --> 00:02:27.200]   that you are Ian and not Leo because I thought Leo has done something with his hair.
[00:02:27.200 --> 00:02:31.520]   And I was leaving chess film. Weird accent. He always does these weird accents and I
[00:02:31.520 --> 00:02:34.240]   thought this was really good. I tried to get in there with the shirt though.
[00:02:34.240 --> 00:02:36.600]   Yeah, okay. It helps. It helps.
[00:02:36.600 --> 00:02:40.600]   But yeah, also providing some snark from our Australian friends, although based in Britain
[00:02:40.600 --> 00:02:46.960]   we have Greg. Hello. Greg has you as you know, one of the three of mine podcasts. You are
[00:02:46.960 --> 00:02:52.720]   up fairly late it seems. So yeah, we are looking forward to this. How is it going?
[00:02:52.720 --> 00:02:57.080]   It is all going well. It has been another inspirationally cynical week in technology
[00:02:57.080 --> 00:03:01.520]   of course. As always big companies are really doing dumb things just as you would expect
[00:03:01.520 --> 00:03:06.640]   them to do. So I am looking forward to running down the list tonight and giving you some
[00:03:06.640 --> 00:03:11.520]   insights from the other side where I live. Okay. And then last but definitely no means
[00:03:11.520 --> 00:03:14.480]   least considering you have been, I was thinking about it. We have actually got probably a
[00:03:14.480 --> 00:03:19.240]   century of technology experience just in the four of us here. You don't have to get nasty.
[00:03:19.240 --> 00:03:23.840]   No, no. I am very proud of it. I got my RSA badge. I had 20 year veteran veteran on it.
[00:03:23.840 --> 00:03:32.360]   I am an old fart but still. But Dwight is running from Houston and you have been doing
[00:03:32.360 --> 00:03:37.840]   this now. You are online in 2000. I mean way ahead of most of the field. How is it going
[00:03:37.840 --> 00:03:44.320]   down there? Yeah. Good. I actually have been doing this since 1990. So it has been forever.
[00:03:44.320 --> 00:03:49.240]   It is great here at Houston. We have a beautiful day, almost California like weather. And I
[00:03:49.240 --> 00:03:53.720]   hope it lasts. Oh, yes. Although Houston and humidity tend to go together
[00:03:53.720 --> 00:04:00.240]   like eggs and bacon. But yes. Right. Well, it has been a very, very busy week. We have
[00:04:00.240 --> 00:04:06.120]   had not one but three security conferences in San Francisco. It starts off with B-Sides
[00:04:06.120 --> 00:04:12.760]   on Sunday. Then we had the main RSA 40,000 people jamboree kicking off in the main town.
[00:04:12.760 --> 00:04:18.760]   But also the ARA, I say conference, which was set up after RSA managed to get one female
[00:04:18.760 --> 00:04:23.560]   keynote speaker and a bunch of people in the industry said, hang on a second. We do have
[00:04:23.560 --> 00:04:27.840]   more women than that. An infosecond. Then RSA gave out the solution, which is well, there
[00:04:27.840 --> 00:04:31.560]   is only very few women in for sex. It is not something worth worrying about. And in a
[00:04:31.560 --> 00:04:36.120]   couple of days they have managed to sort out 14 female speakers and one token mail.
[00:04:36.120 --> 00:04:41.280]   Did you get down to RSA? I signed up and then didn't go because I just didn't have
[00:04:41.280 --> 00:04:45.440]   the time. But I have gone before. I missed the old days because then you could just use
[00:04:45.440 --> 00:04:51.880]   the women's bathroom and there was no line. Fantastic. If you had the guts to do that.
[00:04:51.880 --> 00:04:55.240]   But yeah, I guess things change and now you have to wait a minute.
[00:04:55.240 --> 00:05:00.000]   It was a total sausage first. It was a good one after the Indigma Conference earlier this
[00:05:00.000 --> 00:05:03.240]   year. And they said one of the really encouraging signs is that there is a line for the ladies
[00:05:03.240 --> 00:05:07.480]   as well for the gents. It's progress. It's progress. We are getting there. I mean, it's
[00:05:07.480 --> 00:05:12.520]   I mean, it was only thing that really sort of grabbed your attention from this. RSA
[00:05:12.520 --> 00:05:15.680]   was always very tricky because they sell a lot of the keynote. It's often not a lot
[00:05:15.680 --> 00:05:19.480]   gets said. But I don't know. There is some interesting stuff.
[00:05:19.480 --> 00:05:23.480]   There was a lot of interesting stuff going on. I think one of the most interesting things
[00:05:23.480 --> 00:05:33.200]   in the sort of culture of security technology in general is that the threats and the problems
[00:05:33.200 --> 00:05:37.960]   and the exploits and all that stuff is so they're so common. They're so large. They're
[00:05:37.960 --> 00:05:42.920]   so frequent that there at any given time now there's like 15 major things for people to
[00:05:42.920 --> 00:05:47.480]   stress out and worry about. And you know, you really almost have to go to this a conference
[00:05:47.480 --> 00:05:52.440]   like this to have the slightest inkling of exactly what the threats are, what the threats
[00:05:52.440 --> 00:05:58.640]   aren't. And we're and it's just keeps getting worse. And so, you know, I think it's getting
[00:05:58.640 --> 00:06:03.280]   the point where platforms like the Chromebook, it's getting the point where people are just
[00:06:03.280 --> 00:06:08.880]   going to have to do pretty serious if they want to have any security at all. Pretty serious,
[00:06:08.880 --> 00:06:15.640]   serious extreme measures just to have basic security because, you know, it's an arms race.
[00:06:15.640 --> 00:06:19.600]   And I feel like people who want security are losing that arms race.
[00:06:19.600 --> 00:06:24.040]   I think very much so. I mean, it's a question of I mean, defense is always much harder than
[00:06:24.040 --> 00:06:28.600]   offense. But I mean, in terms of stuff that we've got coming through the line, Dwight
[00:06:28.600 --> 00:06:31.400]   Greg, anything that really grabbed your grab your attention?
[00:06:31.400 --> 00:06:35.440]   No, no, the RSA conference is generally a waste of time. I have a completely different
[00:06:35.440 --> 00:06:37.440]   opposite of you tonight, Logan.
[00:06:37.440 --> 00:06:42.840]   You know, there's a couple of RSA marketers putting their name on a dartboard right now.
[00:06:42.840 --> 00:06:46.840]   I don't go to any of the mega conferences because it's basically so much noise and effectively
[00:06:46.840 --> 00:06:52.840]   zero signal. The challenge with the RSA conference is it only happens once a year. And the thing
[00:06:52.840 --> 00:06:57.400]   about security is we're actually, in my view, is you're actually patching what is fundamentally
[00:06:57.400 --> 00:07:04.240]   broken products. So how much effort do we expend trying to make windows safe and fit for use?
[00:07:04.240 --> 00:07:08.760]   How much effort do you spend making Android bug free or, you know, trying to get your
[00:07:08.760 --> 00:07:12.840]   patches on or all that sort of stuff? The simple fact is the whole security industry exists
[00:07:12.840 --> 00:07:17.960]   because IT vendors are so bad at making products and that they've and then they've doubled
[00:07:17.960 --> 00:07:24.080]   down on convincing us to fix their products by going into an aftermarket to fix the faults
[00:07:24.080 --> 00:07:25.680]   that shouldn't have been in there in the first place.
[00:07:25.680 --> 00:07:29.120]   So Greg, the reason you think that they're a waste of time is because you're not going
[00:07:29.120 --> 00:07:34.600]   on a press pass. If you're in the press, it's a convenient way to meet all kinds of people
[00:07:34.600 --> 00:07:36.400]   plus free alcohol.
[00:07:36.400 --> 00:07:41.680]   So I've done the conferences on the press pass and same thing holds true. You still don't
[00:07:41.680 --> 00:07:46.560]   meet anybody that you use for worthwhile. You meet executives who make one or two decisions
[00:07:46.560 --> 00:07:50.240]   a year and think that they're really impressive and important. But the real work is actually
[00:07:50.240 --> 00:07:54.760]   done amongst the hackers and they don't go to RSA except to go and hang out in bars and
[00:07:54.760 --> 00:07:58.920]   to practice karate moves on each other and stroke each other's ponytails and tell each
[00:07:58.920 --> 00:07:59.920]   other.
[00:07:59.920 --> 00:08:01.440]   So let's forget the suspense.
[00:08:01.440 --> 00:08:07.320]   So less anybody be confused that there's actually the full the in general the quality
[00:08:07.320 --> 00:08:13.040]   of the people you can meet is in the middle. So the big conferences like CES, you can't
[00:08:13.040 --> 00:08:18.200]   meet anybody like you know, it's or you know, mobile world congress is difficult as well,
[00:08:18.200 --> 00:08:22.520]   although there are some smaller European vendors you can reach. Very small is conference.
[00:08:22.520 --> 00:08:28.160]   Nobody's there either. The middle size conferences, which I actually think conferences like RSA
[00:08:28.160 --> 00:08:33.240]   are are is in the ballpark. You actually get some really interesting you get technologists
[00:08:33.240 --> 00:08:36.560]   who are leading some of the sessions you can buttonhole them after their sessions and
[00:08:36.560 --> 00:08:41.680]   learn some things as an opinion columnist. It's a great way to like sort of get a spark
[00:08:41.680 --> 00:08:45.960]   of an idea where you're like, it's not the information. It's the it's the guy with the
[00:08:45.960 --> 00:08:49.040]   ponytail stroking thereof and so on.
[00:08:49.040 --> 00:08:54.360]   That wasn't RSA this time round. This was that was B sites. B sites was too.
[00:08:54.360 --> 00:08:59.200]   I remember that. Not only do they do they have just it's a two day run. They've got genuine
[00:08:59.200 --> 00:09:02.920]   hackers there. They also to come back to your radio point, give out drinks tickets with
[00:09:02.920 --> 00:09:08.680]   the conference. And Marcus Hutchins from the one of Christ thing was there this year's
[00:09:08.680 --> 00:09:12.840]   a lot of interesting research. I mean Dwight, what's your view on big conferences? They
[00:09:12.840 --> 00:09:16.440]   were trouble or is it just like marketing fluff?
[00:09:16.440 --> 00:09:21.360]   I think well, I think it depends kind of on who you are. You know, if you're if you are
[00:09:21.360 --> 00:09:26.120]   somebody that they want to talk to, you know, if you're from the New York Times or the Wall
[00:09:26.120 --> 00:09:31.080]   Street Journal, the Washington Post, you're somebody that has a big megaphone and a large
[00:09:31.080 --> 00:09:34.760]   audience, you'll find the people who want to talk to you and you can you can buttonhole
[00:09:34.760 --> 00:09:42.680]   them. You know, I have worked for a long time for a mid mid level paper that sometimes gets
[00:09:42.680 --> 00:09:47.640]   some attention and sometimes gets some love from these folks. And so I think they can
[00:09:47.640 --> 00:09:52.720]   be if you know who to talk to and you have something very specific, as far as security
[00:09:52.720 --> 00:09:57.720]   conferences go, I kind of like Defcon and Black Hat. Those are the ones I mean, if you
[00:09:57.720 --> 00:10:02.800]   could survive it as a member of the media because they'll harass the hell out of you.
[00:10:02.800 --> 00:10:08.200]   But I think Defcon and Black Hat are probably the better choices for if you really want
[00:10:08.200 --> 00:10:10.080]   to talk to people and find out what's going on.
[00:10:10.080 --> 00:10:11.880]   Then you have to go to Vegas and nobody wants that.
[00:10:11.880 --> 00:10:12.880]   Well, I have to do it.
[00:10:12.880 --> 00:10:13.880]   That's right.
[00:10:13.880 --> 00:10:18.800]   Yeah, I hope to every year and it's the one thing that will get me into Vegas in August
[00:10:18.800 --> 00:10:23.080]   besides a cattle prod. But I would disagree on Black Hat because that now is basically
[00:10:23.080 --> 00:10:30.080]   RSA with hookers. Whereas Defcon has got very big, there are 20,000 people there last year,
[00:10:30.080 --> 00:10:34.240]   so it's going to get too big to be functional. But again, besides in Las Vegas going on just
[00:10:34.240 --> 00:10:38.800]   before the main shows kick off, I went there for the first time last year, pretty damn good.
[00:10:38.800 --> 00:10:45.000]   Yeah, I mean, Black Hat. Once a conference gets beyond 5,000 people, there's just too
[00:10:45.000 --> 00:10:51.120]   much physically getting around is very difficult. Finding signal in the noise, finding the people
[00:10:51.120 --> 00:10:56.360]   that you want to talk to, it stops being a happy day. But particularly security conferences,
[00:10:56.360 --> 00:11:01.840]   most of the time what you're seeing is grandstanding or stunt hacking. The security companies are
[00:11:01.840 --> 00:11:06.720]   saving up their best product announcements for that week. And you end up with all this
[00:11:06.720 --> 00:11:13.360]   news crammed into a week. And then you can't cover it because the news cycle is such that
[00:11:13.360 --> 00:11:18.640]   when we cover those conferences in the shows that I publish, you really have to pick out
[00:11:18.640 --> 00:11:22.960]   no more than three or four things, but so much is announced in a single week. And really
[00:11:22.960 --> 00:11:27.280]   these vendors would be better off just going into the release cycle and looking for the
[00:11:27.280 --> 00:11:32.800]   quiet periods and announcing their products or the transitions when not at a football
[00:11:32.800 --> 00:11:37.360]   game. But when there's a quiet time and places for us to cover it.
[00:11:37.360 --> 00:11:43.040]   Yeah, it helps to go in with a focus. I mean, if you just go in and wander around and talk
[00:11:43.040 --> 00:11:47.080]   to people, you'll get something. But if you do your homework, do stuff, look for stuff
[00:11:47.080 --> 00:11:53.000]   in advance, figure out exactly what you want to know and who might be able to talk to you
[00:11:53.000 --> 00:11:55.240]   about it, things will come out a lot better.
[00:11:55.240 --> 00:11:59.560]   Well, this is it. Once the speakers list is announced, then every journalist is just
[00:11:59.560 --> 00:12:02.920]   like, right, OK, let's go through the speakers list, see if they're willing to talk to us
[00:12:02.920 --> 00:12:06.080]   early that way, can save myself trogging around Caesar's game, trying to get to the
[00:12:06.080 --> 00:12:12.120]   right place. But yeah, in many ways, the conference season seems to have got a little
[00:12:12.120 --> 00:12:16.960]   bit too large in some areas. But then again, we have, you know, we have CES over here,
[00:12:16.960 --> 00:12:21.600]   we've got Mobile World Congress in Spain, you've got Seabit and Hanover if you're really
[00:12:21.600 --> 00:12:22.600]   a masochist.
[00:12:22.600 --> 00:12:26.800]   So one of the things that's interesting, two of the things interesting in technology in
[00:12:26.800 --> 00:12:32.560]   the Bay Area is that there are so many conferences. And the other one is there's so much experimentation
[00:12:32.560 --> 00:12:38.360]   in terms of startups. So every half the startups that have some experimental thing will roll
[00:12:38.360 --> 00:12:43.160]   out in one city, that city will be San Francisco. Every once in a while, it's Bay Area, like
[00:12:43.160 --> 00:12:46.760]   pizza robots started in Mountain View. The whole thing about, you know, somebody would
[00:12:46.760 --> 00:12:50.440]   a concierge would come and park your car. That was in San Francisco. People come and
[00:12:50.440 --> 00:12:54.520]   take out your trash. That was San Francisco. And so it's the Bay Area is an interesting
[00:12:54.520 --> 00:12:59.120]   place for conferences. And the reason for that, I don't think it's the attendees. I think
[00:12:59.120 --> 00:13:02.920]   it's the speakers and so on. So if you have a conference on artificial intelligence and
[00:13:02.920 --> 00:13:07.200]   you have it in the Bay Area, there's some really good speakers there. And you have Google
[00:13:07.200 --> 00:13:11.920]   people showing up and all this kind of stuff. And so it's a really nice place. New York
[00:13:11.920 --> 00:13:17.600]   City is pretty good too. But generally speaking, conferences are a whole different plot. But
[00:13:17.600 --> 00:13:21.760]   the downside is half the conferences that you see on a calendar of conferences are
[00:13:21.760 --> 00:13:25.880]   complete garbage. There for wannabes who just and you go and you go to these things and
[00:13:25.880 --> 00:13:30.360]   it's just wannabes talking to wannabes. Nobody's really doing anything interesting. And so you
[00:13:30.360 --> 00:13:35.880]   got to pick and choose. But there's some really good conferences in San Francisco. Again,
[00:13:35.880 --> 00:13:39.720]   around artificial intelligence, some of the some of the sort of leading edge, you know,
[00:13:39.720 --> 00:13:44.800]   interface conferences, very specific conferences that are actually pretty cool. And you know,
[00:13:44.800 --> 00:13:48.720]   like Greg said, these are, you know, you're going to have like a thousand people or 2,000
[00:13:48.720 --> 00:13:52.680]   people at these days. Yeah. It's true. Like you said, it's easy to get speakers in San
[00:13:52.680 --> 00:13:57.800]   Francisco. And a lot of easy to get speakers who don't want to get paid in San Francisco,
[00:13:57.800 --> 00:14:02.680]   which is a big deal to making conferences profitable. So or indeed selling off the keynote
[00:14:02.680 --> 00:14:07.800]   themselves, which is another way to make them insanely profitable. But one of those things.
[00:14:07.800 --> 00:14:11.840]   Okay, well, we'll return to security matters a little later on. But right now Leo may be
[00:14:11.840 --> 00:14:16.720]   far away, but he does have this message from our sponsors. Thank you, Ian. Let me interrupt
[00:14:16.720 --> 00:14:21.040]   just for a moment. I know I'm in Japan, but I had to come back and tell you about last
[00:14:21.040 --> 00:14:26.800]   pass. I am such a believer. It's really nice when we can get an advertiser that I've been
[00:14:26.800 --> 00:14:31.920]   using forever. Actually, a lot of our advertisers are that way. Certainly last pass. You've heard
[00:14:31.920 --> 00:14:36.400]   me talk about last pass. We like last pass so much. Steve Gibson interviewed the creator,
[00:14:36.400 --> 00:14:43.040]   Joe Seagrest. Boy, that's a few years ago now. Joe was, you know, very kind to Steve,
[00:14:43.040 --> 00:14:47.480]   showed him everything, how it works, all the code. And Steve gave it his absolute seal
[00:14:47.480 --> 00:14:51.920]   of approval. He uses last pass. If you have to keep track and it's not just passwords,
[00:14:51.920 --> 00:14:56.680]   although that's the big thing, but of passwords, but I also use it for drivers license, social
[00:14:56.680 --> 00:15:05.120]   security numbers, private stuff of all kinds where I know it's safe and it's both safe,
[00:15:05.120 --> 00:15:12.240]   locked up, but also accessible wherever I am. Desktop, laptop, smartphone, tablet. My
[00:15:12.240 --> 00:15:17.760]   last pass goes with me everywhere. That means I can log into any site anytime. Patrick Delahandy,
[00:15:17.760 --> 00:15:23.840]   our programmer guy here, who's also a last pass user, says he likes it because he'll
[00:15:23.840 --> 00:15:27.840]   create an account for a site like DMV once every three years, right? You've got to make
[00:15:27.840 --> 00:15:33.680]   a department of motor vehicles log in to make an appointment. You don't remember that. You
[00:15:33.680 --> 00:15:37.760]   may not even remember you made the site, but when you go to the site, the last pass little
[00:15:37.760 --> 00:15:41.760]   logo pops up and you fill it in. You go, "Oh, yeah, I do have an account. I do that all the time."
[00:15:42.560 --> 00:15:47.520]   All the time. Last pass goes through all of your if you want. They have a great security check
[00:15:47.520 --> 00:15:51.920]   goes through all your passwords tells you which ones need to be updated. It has one button automated
[00:15:51.920 --> 00:15:58.320]   update for many, many sites. It works so easily and write it and iOS where it just fills it in
[00:15:58.320 --> 00:16:06.080]   automatically. So no typing means no more mistakes. I can go on and on. Last pass is the best way
[00:16:06.080 --> 00:16:11.280]   to keep track of all of your passwords and credentials and serial numbers and special
[00:16:11.280 --> 00:16:18.560]   documents. When I travel, I put my passport in last pass. It's secure there, but then I have a copy
[00:16:18.560 --> 00:16:23.840]   of my passport on everything. That's the cool thing about last pass. It synchronizes with
[00:16:23.840 --> 00:16:27.760]   everything. Now the passport vault, which is synchronizing is completely secure. 256
[00:16:27.760 --> 00:16:35.120]   AES encryption. Even last pass can unlock it, which is nice. I add, in addition to that, I add
[00:16:35.120 --> 00:16:38.960]   second factor authentication. So it's got a good long, strong password. I use two factor
[00:16:38.960 --> 00:16:44.000]   authentication. I feel very, very confident that that password vault is safe. And yet it's
[00:16:44.000 --> 00:16:48.720]   everywhere. When I set up a new computer, first thing I put on my computer, first thing I put on
[00:16:48.720 --> 00:16:53.840]   my new phone, last pass, because it's going to help me log into everything else. We use last pass at
[00:16:53.840 --> 00:16:57.680]   work. We have last pass enterprise. And one of the benefits we give all employees is a last pass
[00:16:57.680 --> 00:17:02.800]   account for free because I'm such a strong believer in this. It's the number one most important thing
[00:17:02.800 --> 00:17:08.480]   you can do to protect yourself online. Last pass products for enterprise for premium for
[00:17:08.480 --> 00:17:14.240]   personally used for families, last pass for teams. They've got a product that's right for you. Find
[00:17:14.240 --> 00:17:21.440]   out more. Fix your password woes. Protect yourself. Improve your security. And it's more convenient.
[00:17:21.440 --> 00:17:26.560]   LastPass.com/twit. You know, I always say there's a trade up between security and convenience.
[00:17:26.560 --> 00:17:33.200]   In this case, you get both. You really do. LastPass.com/twit. If you're not yet a
[00:17:33.200 --> 00:17:39.040]   last pass customer, what's holding you up? Pause the podcast and go do it. LastPass.com/twit.
[00:17:39.040 --> 00:17:46.240]   Are you all right? You're done? Okay. Now we can resume Ian Thompson in the Twit family. Go ahead,
[00:17:46.240 --> 00:17:52.640]   guys. Right. Okay. So it's been a headline grabbing week for Apple. When is it not been? But
[00:17:52.640 --> 00:17:58.480]   we just have to report that when it comes to actual smartphone sales, Apple and the product
[00:17:58.480 --> 00:18:04.400]   line are taking over a third of the entire revenue straight out the back. So all those mobile phone
[00:18:04.400 --> 00:18:09.840]   manufacturers out there, the billions of smartphones out there, Apple is sucking it up. Now we have a
[00:18:09.840 --> 00:18:15.440]   mixed panel here, some Apple users, some Android users. Mike, you've actually bought your wood framed
[00:18:15.440 --> 00:18:20.480]   iPad here. You have you haven't gone for the iPhone 10 or X, depending on how you describe it.
[00:18:20.480 --> 00:18:25.520]   No. 10 or X, which one would 10? Yeah. The 10. Yep. Because I think the next one's going to be an
[00:18:25.520 --> 00:18:31.360]   11. They pull the Microsoft, they skipped a generation. There has been no iPhone 9. But yeah, iPhone
[00:18:31.360 --> 00:18:36.880]   10 for sure. iPhone 789, sorry. One of the things I was surprised about it. Obviously, you know,
[00:18:36.880 --> 00:18:41.520]   Apple always dominates profits. If you think about what does Apple make, the one thing they make
[00:18:41.520 --> 00:18:47.600]   better than anyone is profits. But iPhone 10 actually had much significantly higher profits than any
[00:18:47.600 --> 00:18:53.520]   of the other iPhones. The numbers are ridiculously priced. Yeah. Well, I guess, I mean, we're probably
[00:18:53.520 --> 00:18:57.360]   going to talk about the Samsung, the cost of the Samsung screen and so on. So it's expensive for
[00:18:57.360 --> 00:19:04.080]   them to make. And you know, it's amazing. They got as many people to buy it as they did. But 35% of
[00:19:04.080 --> 00:19:13.920]   the industry's profits were the iPhone 10, 19% the iPhone 8, 15% the iPhone 8 plus, 6% iPhone 7,
[00:19:13.920 --> 00:19:23.120]   5% iPhone 7. The first non Apple device on the list is the Galaxy Note 8 at 3.9%, basically 4%
[00:19:23.120 --> 00:19:28.960]   of the industry profits. So Apple, once again, is winning it all. And this doesn't even tell you
[00:19:28.960 --> 00:19:33.840]   what they're making on app sales. They get a third of all the app sales getting on the
[00:19:33.840 --> 00:19:39.520]   streaming services like Apple Music and so on. It goes on and on and on. They make money on
[00:19:39.520 --> 00:19:45.120]   everything, every aspect of the, just about every aspect of the phones. But this is just
[00:19:45.120 --> 00:19:50.800]   for selling the hardware. And it's really, it's the business story of, I think, the decade of the
[00:19:50.800 --> 00:19:54.640]   millennium or something like that, they just are printing money. And it's kind of ridiculous.
[00:19:54.640 --> 00:19:58.480]   They're on track to be the first trillion dollar valuation company.
[00:19:58.480 --> 00:20:01.760]   I think Amazon might get there first. I'm not sure.
[00:20:01.760 --> 00:20:04.960]   Could be. They may have a fight for it at the moment.
[00:20:04.960 --> 00:20:07.200]   And not if President Trump has anything to do.
[00:20:07.200 --> 00:20:12.160]   We may come on to that later on. I mean, Greg and Dwight, what's your view on this? I mean,
[00:20:12.160 --> 00:20:14.720]   are you Apple fanboys? Are you Android users?
[00:20:16.880 --> 00:20:23.120]   I am an Apple user and I've, I use pretty much all their products.
[00:20:23.120 --> 00:20:29.920]   I'm, you know, it's not a surprise. They are aiming at the high end of the market,
[00:20:29.920 --> 00:20:35.680]   the where the profits naturally are better. They made Apple an aspirational brand. So
[00:20:35.680 --> 00:20:42.640]   you want to have it, maybe even if you can't afford it. And they have a variety of products,
[00:20:42.640 --> 00:20:48.720]   you know, in a variety of price ranges. So I think they're being very smart about it.
[00:20:48.720 --> 00:20:54.880]   The question is, is how much can they sustain? You know, they have earnings coming up on May 1st.
[00:20:54.880 --> 00:21:01.040]   And there has been several analysts who have said, well, they're just not doing as well as,
[00:21:01.040 --> 00:21:08.080]   as expected on the iPhone 10. And so we'll actually, we'll get a better look at what is actually going
[00:21:08.080 --> 00:21:14.240]   to happen when those earnings drop. So I'm an Apple user or an Apple consumer. I'm not a,
[00:21:14.240 --> 00:21:19.440]   I'm not a fanboy. I was a fanboy, but increasingly I'm less inspired by Apple's going forward.
[00:21:19.440 --> 00:21:26.240]   I think the price is getting out of whack with the value being delivered. So, you know, as it says
[00:21:26.240 --> 00:21:32.080]   here in the 21% of the total revenue goes to Apple, but they make 35% of the total industry
[00:21:32.080 --> 00:21:37.280]   profits. I've heard different numbers. I heard they sort of take 30% of the total revenue,
[00:21:37.280 --> 00:21:42.560]   but 70% of the total profits or whatever. But either way, Apple's charging is working in the
[00:21:42.560 --> 00:21:47.840]   premium end of the market and charging premium pricing that it has a vast profit margin.
[00:21:47.840 --> 00:21:52.480]   But then not only that, but part of the reason they're making the profit margin is a couple of
[00:21:52.480 --> 00:21:58.880]   things. One is security. Unlike a Microsoft or an Android, your device is more or less secure,
[00:21:58.880 --> 00:22:04.000]   although there's signs that there's cracks in that coming forward. It's not buggy compared to
[00:22:04.560 --> 00:22:09.920]   anybody else's smartphones or anybody else's products. And so they do actually have a reason
[00:22:09.920 --> 00:22:15.520]   for being regarded as a premium supplier. But I think the other thing that we are not covering
[00:22:15.520 --> 00:22:20.880]   here that's not covered in this report, of course, is that Apple is very much increasing its output,
[00:22:20.880 --> 00:22:27.520]   avenue revenue per customer or average revenue per user to be literal. By having things like the
[00:22:27.520 --> 00:22:32.880]   headphones, you know, the Apple earphones they've got with the X1 chip inside, Apple TVs, the Mac
[00:22:32.880 --> 00:22:38.320]   has increasingly an accessory to the iPhone, the App Store, the music, the HomePod.
[00:22:38.320 --> 00:22:43.120]   You know, all those accessories mean that you're not just buying the phone anymore. The phone is
[00:22:43.120 --> 00:22:49.280]   the linchpin of an entire ecosystem around, which you're going to buy one or more of those fries
[00:22:49.280 --> 00:22:55.520]   with the iPhone burger. And I think you don't underestimate that part of the strategy.
[00:22:55.520 --> 00:23:00.560]   Greg, just to follow up on that and clarify, you said that your understanding was that the
[00:23:01.680 --> 00:23:08.080]   Apple was north of 70% total profits. That used to be the case and now they're up to 87%.
[00:23:08.080 --> 00:23:15.200]   The 35% is the iPhone 10 alone. So the iPhone 10 by itself as one of the many profitable Apple
[00:23:15.200 --> 00:23:20.880]   devices makes more profit than the top 600 Android makers combined.
[00:23:20.880 --> 00:23:25.040]   It's utterly bonkers. I mean, it's almost like an Android is a race to the bottom,
[00:23:25.040 --> 00:23:29.760]   whereas Apple has just said, yeah, let's make this a premium thing. But then it isn't really
[00:23:29.760 --> 00:23:33.840]   reflected in their other product lines. And that, I mean, Greg, you said this is the linchpin,
[00:23:33.840 --> 00:23:38.800]   but I know a lot of MacBook users who are really, really annoyed at the moment that
[00:23:38.800 --> 00:23:43.440]   their laptops are not getting love. We're using outdated hardware. They've just said that the
[00:23:43.440 --> 00:23:49.040]   next MacBook isn't going to be coming through the line until 2019. I mean, as Apple given up
[00:23:49.040 --> 00:23:56.080]   on laptops, I think there's a few things happening there. One is Intel's product line has been
[00:23:56.080 --> 00:24:00.800]   disrupted. They've missed a couple of generations in the CPUs. We always expected to see Intel
[00:24:00.800 --> 00:24:05.680]   release new CPUs. They did the TikTok and we expected them to happen every year and then Intel
[00:24:05.680 --> 00:24:12.720]   shifted to a three year strategy. And I just have the sense, and this is just pure speculation on my
[00:24:12.720 --> 00:24:20.080]   part, Apple was doing something and they missed a generation or two because whatever it was they
[00:24:20.080 --> 00:24:26.480]   were working on didn't work. So I know that, for example, Apple Intel completely failed to deliver
[00:24:26.480 --> 00:24:32.560]   on mobile processes and mobile CPUs. And yeah, that's right. And so if you were betting,
[00:24:32.560 --> 00:24:37.360]   you know, you had a whole production line ready to go, and then Intel suddenly pulls the pin on
[00:24:37.360 --> 00:24:43.440]   that CPU that they were going to push out there and your Apple, because Apple puts all of its weight
[00:24:43.440 --> 00:24:49.280]   behind a single product. There's not like, in a Samsung, they have like nine to 10 product families.
[00:24:49.280 --> 00:24:54.640]   Apple has two smartphones in the market today, basically the X and the eight. They don't have
[00:24:54.640 --> 00:24:59.120]   this massive diversity, which allows them to fail in one product line and fail over. They go
[00:24:59.120 --> 00:25:06.080]   all the way in. So if Intel pulled the product line too late, then Apple might not have had
[00:25:06.080 --> 00:25:09.840]   a backup strategy in place. And that's why we haven't seen the iteration.
[00:25:09.840 --> 00:25:17.040]   So I'm not entirely sure that putting the blame at Apple's feet is the thing to do. Of course,
[00:25:17.040 --> 00:25:21.840]   it is because it's up to them to meet the market and meet users expectations and to manage user
[00:25:21.840 --> 00:25:26.240]   expectations. I think that's the thing that Apple's failed to do here. We have an expectation as
[00:25:26.240 --> 00:25:31.760]   Apple customers to see a refresh cycle on the Mac roughly every two years, a major trend.
[00:25:31.760 --> 00:25:36.640]   And we haven't seen that. And they haven't come out and talked about it or been public about it.
[00:25:36.640 --> 00:25:42.480]   And we really feel a bit, a bit abandoned. Like I'm sitting here with a 2012 MacBook waiting
[00:25:42.480 --> 00:25:47.040]   patiently for the next one, because I'm not leaving my ports behind. So yeah, I'm in that.
[00:25:47.040 --> 00:25:53.600]   Well, the other thing is that you could wait with a 2012 MacBook Pro because it still works.
[00:25:53.600 --> 00:26:00.560]   It's still fast. It still uses the most recent operating system. One of the things I think Apple
[00:26:00.560 --> 00:26:08.960]   has some runway to coast on because its products do last forever. I'm working here with a 2015
[00:26:08.960 --> 00:26:15.120]   MacBook Pro. I have no desire to go to anything else. I've got a 2012 Mac Mini at home,
[00:26:15.120 --> 00:26:20.800]   which is a Core i7. And I've put in two SSDs and it's as fast as anything
[00:26:20.800 --> 00:26:26.640]   that I could otherwise that I could get from Apple. I'm very happy with it. And so they have
[00:26:26.640 --> 00:26:31.840]   some grace there, I think, with their users that allow them while they do have probably the pro side
[00:26:31.840 --> 00:26:36.640]   people who the ones who want something new all the time. I think people who buy them and hold on to
[00:26:36.640 --> 00:26:40.800]   their machines for a long time can do that. And they have some good will.
[00:26:40.800 --> 00:26:45.040]   I think sometimes though also you get to the point where a product category
[00:26:45.040 --> 00:26:50.560]   reaches, it becomes as good as it kind of can possibly be in a way. And for a long time Apple
[00:26:50.560 --> 00:26:55.840]   was leading the charge with little things like unibody, aluminum construction and the retina
[00:26:55.840 --> 00:27:00.240]   display and all that they were able to stay ahead. Now it's the point where everybody's kind of caught
[00:27:00.240 --> 00:27:06.560]   up that you can buy much lower cost laptops that have those kinds of features. They a lot
[00:27:06.560 --> 00:27:11.920]   of them look just like they have the aluminum bodies, they look a lot like the MacBook Pros and stuff.
[00:27:11.920 --> 00:27:18.480]   Meanwhile there's this gradual shift toward mobile, towards phones and to a lesser extent
[00:27:18.480 --> 00:27:22.560]   tablets, but mostly phones where more people are doing more stuff and spending more time in their
[00:27:22.560 --> 00:27:27.520]   phones. And so it's less important. I think the next big thing that Apple's going to do, and this
[00:27:27.520 --> 00:27:31.120]   is going to be a controversial point because everybody right now says I'm going to hate this,
[00:27:31.120 --> 00:27:38.720]   which is going to be a solid state laptop. I think they're going to have, I think within the next
[00:27:38.720 --> 00:27:44.560]   few years Apple's going to come out with a laptop that runs iOS that has a, it's going to be two
[00:27:44.560 --> 00:27:49.040]   screens, clamshell with two screens, the bottom screen, the keyboard will be an on-screen keyboard.
[00:27:49.040 --> 00:27:52.400]   There are all kinds of advantages, there are all kinds of disadvantages. I've written pretty
[00:27:52.400 --> 00:27:58.640]   extensively about this. Guys like us hate the idea, but I think this is the future because kids,
[00:27:58.640 --> 00:28:05.600]   I mean if you look at people entering the workforce today, many of them never ever use a physical
[00:28:05.600 --> 00:28:12.000]   keyboard. Even using a larger device larger than a phone is somewhat alien to the iGen or whatever
[00:28:12.000 --> 00:28:16.880]   you want to call this upcoming generation. But it hasn't Tim Cook actually explicit one,
[00:28:16.880 --> 00:28:21.280]   not explicitly, but he gave us a pretty strong hint this week that they didn't think the Mac OS
[00:28:21.280 --> 00:28:25.440]   and iOS should be merged. That's right, they're not going to be merged. Well I'm talking about iOS,
[00:28:25.440 --> 00:28:29.440]   pure iOS, I mean they're going to continue to have the cars and trucks,
[00:28:29.440 --> 00:28:34.320]   diversion, Steve Jobs, if you recall said well some people need a truck, some people need a car,
[00:28:34.320 --> 00:28:39.440]   iOS is a car, I think Mac OS is going to be a truck. They will still have Mac OS laptops and
[00:28:39.440 --> 00:28:44.080]   I think they're going to have iOS laptops. I think they're going to have real keyboard laptops and
[00:28:44.080 --> 00:28:48.800]   I think they're going to have on-screen keyboard laptops. And by the way these on-screen keyboard
[00:28:48.800 --> 00:28:53.840]   laptops are actually going to be kind of great because the bottom, whole bottom of this clamshell
[00:28:54.400 --> 00:28:59.680]   will become whatever you want it to be. It can become like a tablet for drawing, it can become a
[00:28:59.680 --> 00:29:06.480]   DJ scratch pad, it can become anything that the app demands it to be. Meanwhile if you do want
[00:29:06.480 --> 00:29:11.840]   to have a physical keyboard, if you write like we do, you just have a Bluetooth keyboard and as I
[00:29:11.840 --> 00:29:16.240]   do with my iPad. So I don't think it's the end of the world for them. They've got tons of patents
[00:29:16.240 --> 00:29:23.040]   and I'm pretty sure the first of these devices is actually going to be a future case for the iPad.
[00:29:23.040 --> 00:29:27.120]   I think they can have an iPad where the bottom right now they have this sort of like physical
[00:29:27.120 --> 00:29:31.360]   keyboard. So you're talking about a Chromebook style, a Chromebook style iPad. There's got a
[00:29:31.360 --> 00:29:37.520]   keyboard and a screen but runs iOS. Well no it has a screen and another screen and the
[00:29:37.520 --> 00:29:44.480]   the bottom screen is exactly. And on the higher end devices what we don't sort of think enough
[00:29:44.480 --> 00:29:49.520]   about is how amazing haptics will be first of all. And in like five, six, seven, eight years,
[00:29:50.880 --> 00:29:57.520]   these screens will actually have little bumps that rise and fall. When you tap the thing you'll
[00:29:57.520 --> 00:30:04.240]   feel it drop. There'll be key actual key travels, key travel on a all screen laptop. And that's
[00:30:04.240 --> 00:30:10.720]   going to be pretty crazy technology that will change the whole sort of the whole reputation
[00:30:10.720 --> 00:30:16.080]   of on screen keyboards I think. But there's been an Apple patent on that. I've seen I think
[00:30:16.640 --> 00:30:22.320]   Pat and Lee Apple has done something with that. So that actually is obviously could be done.
[00:30:22.320 --> 00:30:25.760]   And Mike, take my money because I'll buy that. Yeah, me too.
[00:30:25.760 --> 00:30:31.920]   But I've seen how they Google has tried to merge Chrome OS and Android and it's just it's
[00:30:31.920 --> 00:30:36.000]   buggy as all halent. Well I think that's why they're creating Fuchsia. For a long time I was a
[00:30:36.000 --> 00:30:42.640]   Fuchsia denialist. Fuchsia if you're not super familiar with Fuchsia, the Fuchsia OS is an operating
[00:30:42.640 --> 00:30:49.840]   system that Google has been working on from scratch. And you can find it on GitHub. And it
[00:30:49.840 --> 00:30:54.960]   basically you can even look at it in a browser. I just wrote a piece about mobile operating systems
[00:30:54.960 --> 00:30:58.480]   on computer world. If you want to check out the link to the browser, I guess that's the most
[00:30:58.480 --> 00:31:03.760]   efficient way to find it. Go to my Twitter feed, Mike Elgin, you can find it there. But basically
[00:31:03.760 --> 00:31:11.040]   it looks like it this is an operating system that could run on phones and on tablets. It could
[00:31:11.040 --> 00:31:15.120]   replace Android and Chrome. But I think that the model for it is going to be like,
[00:31:15.120 --> 00:31:21.520]   what do they call it? What does Google call it? The instant apps where only the parts of the app
[00:31:21.520 --> 00:31:27.120]   that you need are downloaded. You never install an app. Imagine operating system when all the apps
[00:31:27.120 --> 00:31:31.840]   are like that. It'd be pretty good. I mean Fuchsia is an attempt to fix the problems of Android as I
[00:31:31.840 --> 00:31:37.040]   understand it. So the Android operating system has reached the practical limit of what it can do.
[00:31:38.480 --> 00:31:44.480]   And when they OEMed it and open sourced it, all the other companies out there who've been using
[00:31:44.480 --> 00:31:48.960]   the Android operating systems to sell smartphones, most of them still working on a version of that
[00:31:48.960 --> 00:31:56.240]   code from 2011, I believe, or 2014, version four, whatever that is. And they've got no motivation
[00:31:56.240 --> 00:32:01.040]   to upgrade those devices and move forward. So the purpose behind Fuchsia is to actually build
[00:32:01.040 --> 00:32:06.880]   an operating system which automatically patches, automatically updates so that when OEM vendors
[00:32:06.880 --> 00:32:11.600]   take it, they won't be able to ignore the requirement for security and patching.
[00:32:11.600 --> 00:32:18.800]   And then, as you say, the feature that Google wants or that Google things can differentiate itself
[00:32:18.800 --> 00:32:23.680]   from its competitors is to have the instant install. So instead of going to an app store and
[00:32:23.680 --> 00:32:28.880]   downloading the app and having it download a whole bunch of stuff, why not just download a
[00:32:28.880 --> 00:32:32.960]   stub and then while you always start playing with the app in the background, it's streaming down.
[00:32:32.960 --> 00:32:37.600]   That's something Google's been trying out for quite some time. I don't think that's going to be
[00:32:37.600 --> 00:32:42.400]   successful not because it won't be technologically successful, but because there's not enough bandwidth
[00:32:42.400 --> 00:32:48.800]   in the world to make that happen. You have to be in places where 4G, 5G with massive fat pipes and
[00:32:48.800 --> 00:32:53.520]   content delivery network nodes close to the point where you can actually stream the app
[00:32:53.520 --> 00:32:57.840]   out to the phone. You're assuming there's enough bandwidth. And if you look at countries like Indonesia
[00:32:57.840 --> 00:33:04.480]   and out there where the vast numbers of these low-cost phones go, that technology isn't going to work.
[00:33:04.480 --> 00:33:14.400]   Well, you can also imagine a world where an operating system where it works like a Chromebook,
[00:33:14.400 --> 00:33:19.840]   where you download it and it stays there. It's persistent and/or it can download the background.
[00:33:19.840 --> 00:33:27.280]   And again, I think that Google will always have sort of a light version of whenever it's mobile
[00:33:27.280 --> 00:33:32.880]   operating system is. And we also don't know what the timeline is. Maybe Fuchsia comes online in 10
[00:33:32.880 --> 00:33:38.400]   years or something like that when we all have jetpacks and all that stuff. So it's pretty slow
[00:33:38.400 --> 00:33:42.880]   going. They don't have a whole lot of, they have a few important people working on Fuchsia,
[00:33:42.880 --> 00:33:46.560]   but not a lot of people. It's like 100 people or something like that, which for Google is like
[00:33:46.560 --> 00:33:51.760]   close enough. For an operating system, it's enough. You don't need that many people to make our
[00:33:51.760 --> 00:33:56.800]   operating system. Really, a team of 100 top-notch computer scientists is all you need. As long as
[00:33:56.800 --> 00:34:01.440]   you don't have this infinite scope of works, I'm not too worried about the numbers, what I'm
[00:34:01.440 --> 00:34:07.600]   thinking about. There's research out there showing that 55% of people who own phones never
[00:34:07.600 --> 00:34:14.000]   install an app. And that's the need that they're identifying. You need a certain amount of
[00:34:14.000 --> 00:34:17.120]   technical infrastructure and I'm not convinced that that's possible. Sorry Ian, I shouldn't have
[00:34:17.120 --> 00:34:23.440]   jumped down. Just to be a Debbie Downer about this thing. So the instinct for those of us who
[00:34:24.240 --> 00:34:28.640]   think about technology a lot is, oh, Fuchsia is going to replace Android. It's going to solve
[00:34:28.640 --> 00:34:34.800]   Android problems and replace Android and it's going to replace the Chrome OS. Remember, this is
[00:34:34.800 --> 00:34:41.920]   Google we're talking about. If the past is any guide, we're facing a world that will have Fuchsia
[00:34:41.920 --> 00:34:49.360]   and Android and Chrome OS, a big mess on our hands. This is kind of what Google does. They are
[00:34:50.880 --> 00:34:55.120]   spread across the waters and see what comes up and whether or not it sinks. They're messaging
[00:34:55.120 --> 00:34:58.960]   and then communication. Well, actually, we're going to be coming to that in just a little second.
[00:34:58.960 --> 00:35:04.240]   But first off, we have another message from Leo and for the people that keep Twitch on the
[00:35:04.240 --> 00:35:10.080]   air. So over to you, Leo. The Twitch show this week brought to you by Zip Recruiter. If you are
[00:35:10.080 --> 00:35:14.000]   hiring, you're doing something, you're doing God's work. You're doing the most important part of
[00:35:14.000 --> 00:35:20.320]   the company. You're building it piece by piece. A company is really nothing more than a bunch of
[00:35:20.320 --> 00:35:26.880]   people with an aligned common goal. And the people who are at your company are what makes the company
[00:35:26.880 --> 00:35:33.200]   succeed or fail. So why hiring is the most important job and it's yours. If it is yours,
[00:35:33.200 --> 00:35:38.480]   you got to know about Zip Recruiter. It is the way to bring the right person into your enterprise
[00:35:38.480 --> 00:35:43.680]   and to make sure you never hire the wrong person to. Every business needs a better way to find
[00:35:43.680 --> 00:35:48.560]   great people and Zip Recruiter is the one better than posting your job online. Just hoping the
[00:35:48.560 --> 00:35:51.760]   right people see it. The great thing about Zip Recruiter is that you're posting it
[00:35:51.760 --> 00:35:57.040]   to 100 plus job boards a minute, you click the button. So it's getting out to the most people.
[00:35:57.040 --> 00:36:02.080]   And then Zip Recruiter does something really cool. They build a platform that finds the right
[00:36:02.080 --> 00:36:08.800]   candidates for you. So get the Zip Recruiter learns what you're looking for, identifies people in
[00:36:08.800 --> 00:36:13.280]   their giant database, millions of resumes, identifies people with the right experience,
[00:36:13.840 --> 00:36:20.160]   then invites them to apply to your job. It's like you've got a headhunter working for you,
[00:36:20.160 --> 00:36:25.440]   the minute you post. These invitations have revolutionized how people find the next hire.
[00:36:25.440 --> 00:36:30.560]   In fact, 80% of employers who post a job on Zip Recruiter get a quality candidate through
[00:36:30.560 --> 00:36:36.480]   the site in just one day. You post today, tomorrow you'll have a quality candidate.
[00:36:36.480 --> 00:36:41.760]   If you're in a hurry, this is the best. And Zip Recruiter doesn't stop there. They even spotlight
[00:36:41.760 --> 00:36:46.480]   the best applications. So you never miss a match. You see, oh, you should look at this one. The
[00:36:46.480 --> 00:36:52.800]   right candidates are out there. You need them. Zip Recruiter is how you find them. Businesses of
[00:36:52.800 --> 00:36:57.920]   all sizes trust Zip Recruiter for their hiring needs right now. You can try Zip Recruiter absolutely
[00:36:57.920 --> 00:37:08.560]   free. Yeah, free. Go to ziprecruiter.com/twit. ZipRecruiter.com/twit. ZipRecruiter is the smartest way
[00:37:08.560 --> 00:37:13.520]   to hire ziprecruiter.com/twit. We thank them for their support of this week in tech.
[00:37:13.520 --> 00:37:19.120]   Now back to the show. Thanks, Lea. Okay. Now we just mentioned Google's messaging.
[00:37:19.120 --> 00:37:26.160]   There was a piece in a couple of titles. Google hasn't said anything official on this point,
[00:37:26.160 --> 00:37:30.960]   but has leaked some friendly media people who it knows just to, I think, float some trial balloons
[00:37:30.960 --> 00:37:37.280]   about once again, trying it with messaging. Now we've seen over the years, Google try an awful
[00:37:37.280 --> 00:37:42.080]   lot of things with messaging, lots of different apps all over the place, then trying to merge
[00:37:42.080 --> 00:37:47.920]   them, then splitting them apart. Mike, Google, should they just stop trying to do messaging?
[00:37:47.920 --> 00:37:53.440]   It's not going to happen for them. No, they should keep trying. And in fact, this latest move,
[00:37:53.440 --> 00:37:59.040]   which is being portrayed in the press as, oh, here's another thing in messaging from Google.
[00:37:59.040 --> 00:38:04.880]   This isn't another thing. This is the thing that Google's been working behind the scenes on for
[00:38:04.880 --> 00:38:08.720]   many, many years. And it's a very positive thing. And here's what essentially we're talking about.
[00:38:08.720 --> 00:38:12.960]   SMS has been with us forever. SMS stands for short message service. It's basically
[00:38:12.960 --> 00:38:18.400]   long story short. It's something that already existed. It was a channel that already existed.
[00:38:18.400 --> 00:38:22.800]   It was not just over-carrages. Yeah, exactly. And then so let's use this. It's free for the
[00:38:22.800 --> 00:38:27.040]   carriers and yet we can charge for it. It's free money. Well, only in the US and Europe,
[00:38:27.040 --> 00:38:31.520]   you got it for free. One of the things coming over here was just like, hang on, you're charging
[00:38:31.520 --> 00:38:38.080]   me for SMS. It's ridiculous. So how are they actually building that into the new messaging
[00:38:38.080 --> 00:38:42.320]   clone that you can see? Well, basically what they're doing is Google has been working on this
[00:38:42.320 --> 00:38:50.720]   replacement for SMS, which is RCS. And RCS is problematic. In the old days, you could build
[00:38:50.720 --> 00:38:55.920]   standards. There weren't a million multi-billion dollar corporations all trying to get advantage
[00:38:55.920 --> 00:39:01.440]   in new standards. And so you could just have a single standard. The internet was built on these
[00:39:01.440 --> 00:39:05.840]   single standards. And that's why it all works together, whereas nowadays is very difficult. So
[00:39:05.840 --> 00:39:10.480]   Google has actually been doing the right thing for a change. They've been exercising their heft
[00:39:10.480 --> 00:39:18.400]   and leadership to get all the carriers to buy into RCS, to a single type of implementation of RCS
[00:39:18.400 --> 00:39:22.880]   that will make it interoperable. Because again, without somebody like Google, you can see
[00:39:22.880 --> 00:39:27.040]   moving from SMS to RCS and then going back to the days when you had to be on the same carrier,
[00:39:27.040 --> 00:39:30.400]   you know, multiple incompatible versions, and it's a big nightmare and it wouldn't work.
[00:39:30.400 --> 00:39:36.560]   And so RCS, just to be clear, is not something that will function like SMS. It's a feature. It's a
[00:39:36.560 --> 00:39:43.680]   technology that's built into the apps. So any app could support the Google implementation of RCS.
[00:39:43.680 --> 00:39:48.240]   You need a phone to support RCS. You need the carrier to support RCS. Right now, RCS exists,
[00:39:48.240 --> 00:39:53.520]   but nobody uses it because you need perfect alignment. Both parties need the phone, the app,
[00:39:53.520 --> 00:39:57.280]   and the carrier. And it's still lucky in encryption. No end to it.
[00:39:57.280 --> 00:40:03.600]   No end to it. Exactly. This is not iMessage. And so iMessage or any number of other messaging apps
[00:40:03.600 --> 00:40:09.600]   have end-end encryption, but they have the flaw that not everybody supports it. So only iPhone
[00:40:09.600 --> 00:40:15.280]   users can use take advantage of it. I mean, vice-in, which I do commonly, if I send a message to
[00:40:15.280 --> 00:40:21.360]   somebody who uses Android, well, that that is not encrypted. The pictures and videos are
[00:40:21.920 --> 00:40:26.640]   dumbed down and become low quality. There's all kinds of problems with it. So this is a best-case
[00:40:26.640 --> 00:40:32.160]   scenario for a leader like Google to get everybody singing from the same hymnbook for the future of
[00:40:32.160 --> 00:40:38.960]   the SMS replacement. It's in general a very good thing. Their history with apps is a very bad thing,
[00:40:38.960 --> 00:40:43.600]   but this is actually a very good thing. Yeah. Doubtful, though. I think RCS is probably dead.
[00:40:43.600 --> 00:40:50.640]   Is flogging a dead horse. The carriers don't want it. The people in the telco industry who
[00:40:50.640 --> 00:40:56.400]   monitor this sort of thing basically can't see the certain technical challenges around RCS,
[00:40:56.400 --> 00:41:00.560]   you're asking the telcos to go out and replace all of their base stations
[00:41:00.560 --> 00:41:06.800]   and to not only keep the SMS functionality, but to layer RCS over the top. And there's no money
[00:41:06.800 --> 00:41:12.160]   attached to it. So for these telcos to go and implement RCS, where's the money that they're
[00:41:12.160 --> 00:41:19.040]   going to get from supporting this new service? And there is none because SMSs are basically free.
[00:41:19.040 --> 00:41:24.560]   So why would they go out and deploy this RCS? Two, the technology behind RCS is actually pretty
[00:41:24.560 --> 00:41:28.640]   rubbish. People don't like it very much. There's not too many products out there that make it work.
[00:41:28.640 --> 00:41:35.200]   And then the final thing is that getting everything right. So it's one of these network
[00:41:35.200 --> 00:41:40.480]   effects. Once everybody's got RCS, then it becomes useful. And yes, it would be, I agree with your
[00:41:40.480 --> 00:41:45.680]   mic, that it would be a very good thing to replace SMS with the rich communication services,
[00:41:45.680 --> 00:41:52.000]   which allows SMS to look like it's something from 2010 instead of like 1999.
[00:41:52.000 --> 00:41:58.880]   But I don't have a universal messaging platform that's not linked to somebody like Apple's iMessage
[00:41:58.880 --> 00:42:07.200]   or Facebook Messenger or WhatsApp or whatever it is. But I just don't see telcos globally coming
[00:42:07.200 --> 00:42:13.280]   together to implement RCS in the networks to replace SMS when there's no money attached to that
[00:42:13.280 --> 00:42:18.000]   service where there's no value add, there's nothing that drives customers, and there's nothing that
[00:42:18.000 --> 00:42:24.160]   improves the customer experience. So even then there's just nothing that brings the carriers
[00:42:24.160 --> 00:42:29.040]   into joining this. Well, except they don't want to be left out. In fact, 55 operators carriers
[00:42:29.040 --> 00:42:33.600]   have already signed up for it, including AT&T, Verizon, T-Mobile, Sprint, Rogers and Orange.
[00:42:33.600 --> 00:42:37.120]   So the major ones have already been- They all sign up for it, but they never deploy it.
[00:42:37.120 --> 00:42:42.320]   They've signed up for hundreds of years in the year. So you're getting in that, Dwight.
[00:42:42.320 --> 00:42:51.200]   So one of these, I mentioned this Galaxy S9. The review unit I got came from Samsung. So it's an
[00:42:51.200 --> 00:42:57.520]   AT&T phone that didn't come from AT&T. But even just coming from Samsung, it has already on it
[00:42:57.520 --> 00:43:06.000]   two messenger messaging services. If this had come from AT&T, it would have their messaging
[00:43:06.000 --> 00:43:11.120]   service on it as well. And so there's no guarantee that you put one more messaging service on it
[00:43:11.120 --> 00:43:16.640]   that anybody's going to use it over any of these others. I have a friend of mine who just switched
[00:43:16.640 --> 00:43:24.240]   from iPhone to the Samsung Galaxy S8. And he came to me and said, "So which one of these messaging
[00:43:24.240 --> 00:43:30.320]   things is the one that talks to other people?" And I said, they have their features where they
[00:43:30.320 --> 00:43:36.640]   will do things if they talk to the same messenger, but they'll both do SMS. And so there's no guarantee
[00:43:36.640 --> 00:43:43.040]   that if you put yet another Android chat thing on here, that people who are already using what they
[00:43:43.040 --> 00:43:51.040]   have are going to use it. And so even if it's as wonderful as my hopes it is, there's no guarantee
[00:43:51.040 --> 00:43:55.440]   that users will actually pick it up and use it. But one of those apps that you mentioned is no
[00:43:55.440 --> 00:44:01.680]   doubt Google's own app, which is actually very popular, has 100 million users. And many of those
[00:44:01.680 --> 00:44:08.880]   users love it. It's probably their best messaging platform. And that one will get RCS. The carrier
[00:44:08.880 --> 00:44:13.600]   one will also probably get RCS. So of the four apps you mentioned, at least two of them are almost
[00:44:13.600 --> 00:44:19.760]   certainly have RCS built in. So I think what Google is trying to do, and I think that they might
[00:44:19.760 --> 00:44:25.440]   succeed, it looks like so far they might succeed is you need to get a certain amount of momentum
[00:44:25.440 --> 00:44:30.800]   behind something. And once you have a sufficient momentum behind something like this, then people
[00:44:30.800 --> 00:44:36.320]   have to join because their users, their customers will be left out. This ability to communicate
[00:44:36.320 --> 00:44:40.240]   with each other. But this was the original problem when telcos started to try and shift from SMS
[00:44:40.240 --> 00:44:45.040]   to different services that they could actually monetize in that we had the whole MMS, the multimedia
[00:44:45.040 --> 00:44:49.840]   messaging services, we just died on its ass because nobody was prepared to use it. There's a whole
[00:44:49.840 --> 00:44:54.320]   bunch of conflicting standards. Isn't this the same kind of thing? I mean, Google wants to create
[00:44:54.320 --> 00:44:58.960]   this unified app, but just doesn't seem to be able to get people to use it. Well, again,
[00:44:58.960 --> 00:45:04.720]   if they get the carriers to use it and get a significant number of app developers to use it,
[00:45:04.720 --> 00:45:11.120]   and they themselves in their own apps will use it, you're seeing, you're getting pretty close. I
[00:45:11.120 --> 00:45:15.680]   think as journalists though, we should be cheerleading this thing because anything that gets people off
[00:45:15.680 --> 00:45:22.480]   Facebook Messenger is a good thing. I agree. I agree with that. I know it's a message. But yes,
[00:45:22.480 --> 00:45:27.600]   I mean, sorry, correct. I was going to say, I mean, the point of it, this is to give you a rich
[00:45:27.600 --> 00:45:33.200]   text messaging service that's independent of the vendor that's providing it. So in theory,
[00:45:33.200 --> 00:45:38.000]   RCS should provide us with an iMessage, Apple's iMessage, Facebook Messenger,
[00:45:38.000 --> 00:45:45.200]   WhatsApp, Snapchat type experience, but using the Telco network. And that means that any phone
[00:45:45.200 --> 00:45:50.320]   could talk to any phone regardless of operating system, regardless of app, it becomes,
[00:45:50.320 --> 00:45:56.800]   in effectively what TCP/IP is to the internet, this messaging, RCS messaging service. However,
[00:45:57.440 --> 00:46:02.800]   there's the challenge that, and I love Mike's inspiration and his belief that if we talk about
[00:46:02.800 --> 00:46:09.360]   it enough, I don't can't see where money is. Where's the money for the Telcos to spend to deploy
[00:46:09.360 --> 00:46:14.160]   this technology to upgrade their infrastructure, to support this messaging across their backbones,
[00:46:14.160 --> 00:46:19.920]   which is not an insignificant cost. You're talking hundreds of millions for those sorts of organizations
[00:46:19.920 --> 00:46:24.480]   to do. Where's the motivations for them to do this? And I'm not sure I see that.
[00:46:24.480 --> 00:46:30.480]   Is any kind of infrastructure upgrade required? Is it not just data?
[00:46:30.480 --> 00:46:35.920]   No, it needs to be in the network. So where your 3G4G comes in?
[00:46:35.920 --> 00:46:40.560]   They've got to put appliances in there that receive the RCS and therefore,
[00:46:40.560 --> 00:46:45.520]   in the same way that there are SMS messaging platforms inside the Telcos network handling
[00:46:45.520 --> 00:46:51.520]   the SMS. It's not IP. Today in 3G4G, it comes in as 3G PVP format of packets and then gets
[00:46:51.520 --> 00:46:57.440]   translated through a bunch of appliances, etc. Is this why it's not encrypted?
[00:46:57.440 --> 00:47:05.920]   Well, in the days when SMS was invented, it was actually meant to be inside the network.
[00:47:05.920 --> 00:47:10.400]   It was meant to be an administrative back channel. And the idea was that the SMS was
[00:47:10.400 --> 00:47:16.080]   send a query to the phone. Are you out there? Yes, no. You could do some diagnostics on the
[00:47:16.080 --> 00:47:20.960]   handset. And that's what the original idea was before. It was very loosely based on the ISDN,
[00:47:20.960 --> 00:47:25.040]   was always two B channels and a D. So when they built the SMS standard,
[00:47:25.040 --> 00:47:29.280]   they decided to build a D signaling channel, but just left it open. And then they realized they
[00:47:29.280 --> 00:47:35.680]   could use it for messaging. So back in the late 1990s, there was no encryption A because we couldn't
[00:47:35.680 --> 00:47:39.680]   the CPU. Why is it this encrypted? Why is it this encrypted? Why is it RCS?
[00:47:39.680 --> 00:47:42.080]   As the killer point. Why? That's what I want to know.
[00:47:42.080 --> 00:47:45.520]   It's going to be for the messaging. Because it's inside the network.
[00:47:45.520 --> 00:47:48.960]   It doesn't need to be encrypted if it's inside the network in theory,
[00:47:48.960 --> 00:47:51.840]   because the network itself is safe from external influences.
[00:47:51.840 --> 00:47:57.840]   Yeah, that's a 7 kind of. But not from spying, but not from spying and not from reading my messages.
[00:47:57.840 --> 00:48:04.720]   And that's key here. Governments don't want to see encrypted messaging. They want to be able to
[00:48:04.720 --> 00:48:10.800]   intercept. And unencrypted messaging running across private networks is perfect for telcos,
[00:48:10.800 --> 00:48:15.600]   because they can then exploit your messages, get in there and sell that data off to other people.
[00:48:15.600 --> 00:48:23.040]   Verizon is already making a $50 billion industry out of selling data about you to ad brokers today.
[00:48:23.040 --> 00:48:27.680]   So if they can get their hands on your messaging data and start selling that off to the ad brokers,
[00:48:27.680 --> 00:48:34.160]   or, and you can pack it up in say call it law enforcement. We give you what legal
[00:48:34.160 --> 00:48:38.320]   intercept and all that sort of stuff. But I think the real underlying hearing here behind
[00:48:38.320 --> 00:48:43.680]   RCS is that Verizon and AT&T want to see your SMS messages so they can sell that data just like
[00:48:43.680 --> 00:48:50.000]   Facebook does. I think the best model for how it should work is Apple's model, which is basically
[00:48:50.000 --> 00:48:56.640]   you have one thing that is end-end encrypted, very secure for people who are also using the app
[00:48:56.640 --> 00:49:00.880]   on the other end. And then you have the other thing, which is not secure, it's not encrypted,
[00:49:00.880 --> 00:49:06.640]   but it's very universal. And so we're talking about replacing the second one without getting
[00:49:06.640 --> 00:49:10.880]   rid of the first one. I think that all of us should be using encrypted apps or signals,
[00:49:10.880 --> 00:49:15.200]   a whole bunch of them that are very good. And we should be using those when we have sensitive
[00:49:15.200 --> 00:49:18.320]   communication and so on. If we're sending stickers around with our friends and stuff like that,
[00:49:18.320 --> 00:49:23.360]   it doesn't have to be that secure, theoretically. And so we're talking about whether SMS continues
[00:49:23.360 --> 00:49:30.160]   another decade of life or gets replaced by something a little better. Like Greg said, it's
[00:49:30.160 --> 00:49:37.600]   nowhere near as good as the better messaging apps that exist today. But we, but it has the
[00:49:37.600 --> 00:49:44.240]   potential quality of being the universal also ran that you use instead of the very proprietary
[00:49:44.240 --> 00:49:51.360]   specific encrypted messaging service that you want to use. I just want to jump in. I just
[00:49:51.360 --> 00:49:55.040]   thought of why it's not encrypted and I've just realized it's because who owns the keys?
[00:49:55.040 --> 00:50:01.680]   Exactly. For a message to be encrypted, there has to be an agreed private public key.
[00:50:01.680 --> 00:50:04.880]   Saying that another way is that in order for it to be universal, it can't be encrypted.
[00:50:05.520 --> 00:50:09.760]   Exactly. That just struck me while I was thinking about that because otherwise,
[00:50:09.760 --> 00:50:13.680]   you've got to have a root certificate authority and you've got to cross sign it and every telco
[00:50:13.680 --> 00:50:17.920]   would actually be answerable to a root and getting all those telcos to agree
[00:50:17.920 --> 00:50:23.920]   to trust a given certificate authority. I mean, imagine getting the Chinese carriers
[00:50:23.920 --> 00:50:29.760]   to agree to a US based certificate authority that's encrypting all the RCS messages. I don't think,
[00:50:29.760 --> 00:50:34.640]   yes, so unencrypted. So it'll be up to the apps, the RCS apps on the end to then encrypt and use
[00:50:34.640 --> 00:50:38.160]   that signaling I would think. You're looking slightly cynical about this, Dwight. What's your
[00:50:38.160 --> 00:50:44.000]   take on it? You just look cynical all the time. I'm just sitting here thinking, you know,
[00:50:44.000 --> 00:50:47.520]   you know what's going to happen tomorrow? I'm going to get a press release in my inbox saying,
[00:50:47.520 --> 00:50:53.040]   solving the universal messaging encryption problem, colon blockchain. I know that.
[00:50:53.040 --> 00:50:56.000]   Oh, God, no. Blockchain with everything.
[00:50:56.000 --> 00:50:59.040]   Right. I had to drop the B word. Yeah.
[00:51:00.160 --> 00:51:06.160]   I apologize. I apologize. But I mean, I can't help feeling the, as you pointed out, I mean,
[00:51:06.160 --> 00:51:10.000]   we're going to be coming to this later in the show, but Facebook Messenger seems to be the most
[00:51:10.000 --> 00:51:15.920]   egregious part of this where it is taking messaging and monetizing it and not giving it proper
[00:51:15.920 --> 00:51:20.640]   security. And I've got a nasty feeling. Well, I'm hearing rumors that WhatsApp has really
[00:51:20.640 --> 00:51:24.160]   balked its signal implementation is running to similar situations.
[00:51:24.160 --> 00:51:30.080]   Facebook. And so in all roads lead to Facebook and that has to change because Facebook is not
[00:51:30.080 --> 00:51:35.200]   to be trusted, in my opinion. And they just impressed by his Android appearance and the
[00:51:35.200 --> 00:51:38.320]   English. I was impressed by his Android like appearance. Yes, that was the only part.
[00:51:38.320 --> 00:51:42.800]   That was amazing. Yes. Tenant Colonel. We've got your data.
[00:51:42.800 --> 00:51:49.680]   Yeah. The data meme was awesome from that. It was just painful to watch. I mean,
[00:51:49.680 --> 00:51:54.160]   I feel bad because some of our reporters actually had to sit through the entire congressional hearing
[00:51:54.800 --> 00:52:01.440]   and Facebook stock price rocketed afterwards. He basically earned $4 billion from
[00:52:01.440 --> 00:52:06.640]   spending two days explaining how technology works to old people in the particular way that he did it.
[00:52:06.640 --> 00:52:09.920]   But I mean, is Facebook Messenger the enemy Mike? Yes.
[00:52:09.920 --> 00:52:15.360]   They very much are Facebook and Facebook Messenger. WhatsApp less so.
[00:52:15.360 --> 00:52:21.520]   As you know, as you all know, as people who travel outside the US, WhatsApp is the
[00:52:22.960 --> 00:52:28.800]   platform for messaging. Whenever I travel in Europe or elsewhere in North Africa or anywhere I go,
[00:52:28.800 --> 00:52:35.680]   they're like, "Well, what's your WhatsApp?" And initially when it first came out and everybody
[00:52:35.680 --> 00:52:39.040]   started doing that, I was like, "What is WhatsApp?" I don't even know what that is.
[00:52:39.040 --> 00:52:42.160]   Eventually Facebook bought it. Now it's a Facebook thing and now they're starting to
[00:52:42.160 --> 00:52:48.320]   Facebook eyes it, which means they're starting to use it to exploit users for various reasons
[00:52:48.320 --> 00:52:55.120]   in this kind of bizarre way, steal their privacy, etc. And it's just a real problem because
[00:52:55.120 --> 00:53:04.480]   the reason everybody's on Facebook, the reason Facebook has dominance is that at the point when
[00:53:04.480 --> 00:53:08.960]   social networking went mainstream, Facebook was the mainstream social network.
[00:53:08.960 --> 00:53:14.720]   So they just won the lottery there and now they have a monopoly on everybody. They have a monopoly on
[00:53:15.680 --> 00:53:19.920]   the fact that everybody's there. So everybody's on Facebook because everybody's on Facebook.
[00:53:19.920 --> 00:53:27.600]   And this is a terrible reason. And we risk continuing the slide to where Facebook is the
[00:53:27.600 --> 00:53:34.480]   de facto standard for all social and messaging communication. Everything else is an also ran.
[00:53:34.480 --> 00:53:38.480]   And that would be a disastrous world. Scott Galloway is a professor at
[00:53:38.480 --> 00:53:44.640]   and he's been calling for them to break up all of Big Tech actually. And he's making a fairly
[00:53:44.640 --> 00:53:49.440]   compelling case. Now he's got a great YouTube channel where he explains it. He's published a
[00:53:49.440 --> 00:53:54.880]   book recently. He's a professor at NYU Stone. And what he's saying is that you're going to have to
[00:53:54.880 --> 00:53:59.600]   break them up somehow. So Facebook could be forced to take Instagram and WhatsApp and float them
[00:53:59.600 --> 00:54:04.480]   off as separate companies and they need to start breaking up Apple and Google. And his point would
[00:54:04.480 --> 00:54:10.480]   be is that these companies are so large that there's no longer any way for a capitalist market to
[00:54:10.480 --> 00:54:15.360]   function. And we've seen this before and he lays out the entire case in his book and in his YouTube
[00:54:15.360 --> 00:54:22.160]   videos that we saw Amazon recently announced that it was going to go into pharmaceuticals,
[00:54:22.160 --> 00:54:26.960]   was going to distribute pharmaceuticals. And that caused a $30 billion drop in pharmaceuticals market.
[00:54:26.960 --> 00:54:32.400]   That's not a capital market working that because Amazon's actually got a product and coming to
[00:54:32.400 --> 00:54:37.520]   market and therefore you should be shifting your money to Amazon because it's going to use that
[00:54:37.520 --> 00:54:43.360]   capital more efficiently than the old than the previous companies. That's a, as soon as Amazon
[00:54:43.360 --> 00:54:48.160]   does anything, they're going to squash the competition. That's monopolist power there. And so I do
[00:54:48.160 --> 00:54:52.480]   think we're going to have to start seeing more moves against the companies to break them up into
[00:54:52.480 --> 00:54:57.440]   pieces so that they don't dominate the market like they do today. But when you come to pharmaceuticals,
[00:54:57.440 --> 00:55:03.600]   you already have an oligopoly in the US. You have a very, very inflexible market, a couple of large
[00:55:03.600 --> 00:55:09.200]   companies dominating it. Wouldn't a company like Apple be coming in just to disrupt things? I mean,
[00:55:09.200 --> 00:55:14.320]   could they really get that kind of market leverage? The point was that Amazon didn't even have a
[00:55:14.320 --> 00:55:23.040]   product or business. They were just a rumor. And then they recently said that they're not going to do
[00:55:23.040 --> 00:55:28.080]   that. Yeah. And but they're still thinking about it and working on it and stuff like that.
[00:55:28.080 --> 00:55:36.720]   The problem with regulatory breakups as opposed to just, I mean, the ideal thing would be for
[00:55:36.720 --> 00:55:42.320]   people to wander away voluntarily from Facebook and have them become the new Myspace. And there's,
[00:55:42.320 --> 00:55:47.440]   I think there's a real chance that that could happen. I mean, right now the public esteem,
[00:55:47.440 --> 00:55:55.200]   the percentage of the public that says in polls that they don't trust Facebook after these
[00:55:55.200 --> 00:56:00.400]   hearings jumped from 20 something or 30 something to 70 something or 80 something. I mean, it really,
[00:56:00.400 --> 00:56:05.520]   there's really been a turning point in the lack of trust of Facebook. And that's really the way to
[00:56:05.520 --> 00:56:14.480]   do it. And you see in a lot of the antitrust action in the US, it's so delayed that it's,
[00:56:14.480 --> 00:56:18.800]   you know, you look at the classic example of, you know, the big threat of Internet Explorer,
[00:56:18.800 --> 00:56:23.360]   dominating the world. I cover that heavily like, like, like,
[00:56:23.360 --> 00:56:28.080]   Microsoft got away with it in the US and in the EU, they got hammered. Yeah. But in the US,
[00:56:28.080 --> 00:56:32.640]   it's kind of like, well, promise not to. But they didn't get away with much because they,
[00:56:32.640 --> 00:56:37.280]   the market took care of it. The market took care of exactly. And that's the point I'm making is
[00:56:37.280 --> 00:56:42.800]   that that's not no, that's not how other people see it. That's how the US sees it, but that's not
[00:56:42.800 --> 00:56:49.040]   how everybody else sees it. I mean, so you don't think the rise of Chrome kind of crush and the
[00:56:49.040 --> 00:56:55.200]   failures and the horrible reputation that Internet Explorer had is what dropped Internet Explorer
[00:56:55.200 --> 00:57:01.120]   to. Well, no, Internet Explorer had a de facto market monopoly. They had 95% of the browser traffic.
[00:57:01.120 --> 00:57:05.680]   And once they got that, they stopped development on it. Yeah. And pretty much dead. I know people
[00:57:05.680 --> 00:57:10.400]   on the, on the who were then on the IE team, and they were basically said, just guys coast for a
[00:57:10.400 --> 00:57:14.240]   year, find another department, you're interested in working in, we're not going to be doing in here.
[00:57:14.240 --> 00:57:19.440]   Anything here, then Mozilla came along, then you're like, Chrome came along. And these were,
[00:57:19.440 --> 00:57:26.000]   elements of how the market should work. But at the same time, why did it take so long in Europe,
[00:57:26.000 --> 00:57:31.760]   whereas, sorry, in the US, whereas Europe would just like that's anti-competitive, we need to level
[00:57:31.760 --> 00:57:35.920]   levy a couple of billion dollars of fines on you. Well, I think it has something to do with the
[00:57:35.920 --> 00:57:40.320]   fact that, I mean, if you recall, it wasn't the Justice Department alone. It was the state's
[00:57:40.320 --> 00:57:46.160]   attorney general going after this stuff. So it's like, we're like an EU with with 51 countries in it.
[00:57:46.160 --> 00:57:52.880]   Right. So the 51st, we're talking the U.K. The 51st is Washington, D.C.
[00:57:52.880 --> 00:57:57.440]   It's the federal government. And so, and so it's really problematic. Plus, there's,
[00:57:57.440 --> 00:58:02.080]   it's a controversial idea. I mean, you know, Americans kind of like secretly love monopolies,
[00:58:02.080 --> 00:58:06.960]   you know, especially in a global marketplace where the US monopoly is dominant globally.
[00:58:06.960 --> 00:58:12.080]   So it's kind of a benefit to American, I guess, the government or whatever,
[00:58:12.080 --> 00:58:18.160]   powerful people in general would prefer that the U.S.
[00:58:18.160 --> 00:58:20.400]   or the US government were done in the Russian one.
[00:58:20.400 --> 00:58:25.360]   You're talking that you're bordering on the edge of US imperialism at this point.
[00:58:25.360 --> 00:58:33.200]   I think the point is, is that Microsoft did basically create its own demise in the end,
[00:58:33.200 --> 00:58:38.000]   and then the Internet Explorer was reasonably dreadful. And as a product was nowhere near
[00:58:38.000 --> 00:58:42.000]   as competent as its competitors. But that was also because at that time,
[00:58:42.000 --> 00:58:46.960]   Microsoft didn't believe in the Internet. It just felt it had to respond to Netscape to the point
[00:58:46.960 --> 00:58:49.360]   where it was. Recently dreadful. Now there's a product, but product marketing.
[00:58:49.360 --> 00:58:53.120]   Oh, I don't know that I agree with that. Yeah, I don't agree with that.
[00:58:53.120 --> 00:58:57.520]   That Microsoft didn't believe in the Internet. There's plenty of writings from the time
[00:58:57.520 --> 00:59:04.720]   it's still reading. I mean, I still got a copy of his book where he just smised it as CB radio,
[00:59:04.720 --> 00:59:10.400]   but that was admittedly 92, 93. But they didn't go to it late and then rushed in.
[00:59:10.400 --> 00:59:15.280]   Yeah, the Windows 95, they knew what was going on.
[00:59:15.280 --> 00:59:21.520]   Yeah, and they threw a lot of effort and resources. Their fundamental argument was the reason
[00:59:21.520 --> 00:59:26.400]   Internet Explorer is dominant is not because it's bundled with Windows. It's because it's the
[00:59:26.400 --> 00:59:29.520]   best browser. If another company came along with a better browser,
[00:59:29.520 --> 00:59:34.560]   then we would become the minority market share. And that's exactly what happened.
[00:59:34.560 --> 00:59:41.360]   Yeah, but can you honestly say that I, I, one, it's market share honestly on simple usability,
[00:59:41.360 --> 00:59:44.960]   or because it was the first thing that people didn't know squat about the Internet.
[00:59:44.960 --> 00:59:48.720]   Oh, that's a browser. I'll click on that. It's a gray area because on the one hand,
[00:59:48.720 --> 00:59:54.240]   one of the one of the aspects of its convenience was the fact that it was bundled.
[00:59:54.240 --> 00:59:58.960]   Yeah, but, but Internet Explorer, if you recall back in, you know, like, like Dwight saying that
[00:59:58.960 --> 01:00:06.400]   the heyday of Microsoft Windows and Explorer was 1995. And at that moment, the, the Explorer browser
[01:00:06.400 --> 01:00:11.280]   was essentially integrated. It wasn't just bundled. It was integrated. Like it was in the,
[01:00:11.280 --> 01:00:15.680]   in the operating system, baked in all the way through. And it was really convenient to use.
[01:00:15.680 --> 01:00:20.480]   And it was a really good browser. And you remember, this is, this is before Chrome.
[01:00:20.480 --> 01:00:25.600]   This is before a lot of the innovation in browsers. Safari is actually not a bad browser nowadays.
[01:00:25.600 --> 01:00:30.400]   And back in those days, it was horrible. You know, it was absolutely horrible. And so it was,
[01:00:30.400 --> 01:00:35.360]   it was pretty good. I mean, it was a pretty good browser. Plus the other thing that you recall is
[01:00:35.360 --> 01:00:39.920]   a lot of people didn't know how to download a browser. Like they didn't know you alluded to
[01:00:39.920 --> 01:00:44.640]   that. It's the year of modems in the year of modems, you know, getting all the fun foxes,
[01:00:44.640 --> 01:00:52.640]   no, was a substantial task. So yes, it was. And that was, but that was often seen as a competitive,
[01:00:52.640 --> 01:00:59.360]   not just as anti competitive, because there was no way for firefox or Chrome or any of the other,
[01:00:59.360 --> 01:01:03.440]   there was quite a few other browser companies out there at the time. In particular, Netscape,
[01:01:03.440 --> 01:01:10.000]   it was charging 90 to $100 to buy their browser. They were basically taken out of the market by,
[01:01:10.000 --> 01:01:14.480]   by that monopolistic behavior that Microsoft decided to say, we're just going to bundle
[01:01:14.480 --> 01:01:18.960]   it up for free and that'll kill off that competitor. And that ultimately was a debate.
[01:01:18.960 --> 01:01:22.640]   Oh, sorry. Yeah. We'll come back to this in a little sec because I'd let's see how this,
[01:01:22.640 --> 01:01:26.880]   how this relates to Facebook because they've had some pretty interesting news weeks as well.
[01:01:26.880 --> 01:01:32.880]   Not least this last one, but in the meantime, here's Leo with the word for the latest sponsor
[01:01:32.880 --> 01:01:36.800]   from Twit. Thanks for letting me horn in here a little bit just to tell you about something I
[01:01:36.800 --> 01:01:44.480]   think is really cool, but I can't do it. SEC regulations prohibit me from doing an ad
[01:01:44.480 --> 01:01:50.960]   and for using betterment. And that tries me nuts. Betterment is the largest independent online
[01:01:50.960 --> 01:01:58.480]   financial advisor. They are so awesome. They're designed to help you plan for retirement,
[01:01:58.480 --> 01:02:05.920]   build your wealth, achieve your financial goals. And I have to say, and you know, many of you probably
[01:02:06.880 --> 01:02:14.960]   you're like me think you can do it yourself. I'm sure I set it all up, you know, read all the books,
[01:02:14.960 --> 01:02:20.240]   made all the investments. Problem is you're supposed to keep track of them, like pay attention at least
[01:02:20.240 --> 01:02:25.440]   every quarter rebalance, pay it, you know, kind of make sure you don't get over over invested in
[01:02:25.440 --> 01:02:30.240]   one sector, all that stuff. And I did the first few years and then, you know, I forgot about it.
[01:02:31.280 --> 01:02:37.120]   Has this happened to you? And then a few years later, you go back and go, Oh, wow, probably should
[01:02:37.120 --> 01:02:42.960]   have changed those investments. Betterments doing it for you. In fact, they do it better than you
[01:02:42.960 --> 01:02:47.840]   ever could not checking it every quarter or every month or every week, or even every day, they're
[01:02:47.840 --> 01:02:54.080]   checking it many, many times a day, because computers constantly making sure that your investment is
[01:02:54.080 --> 01:02:58.800]   on the right track. It's rebalanced. They're doing something. And this is actually a good time to do
[01:02:58.800 --> 01:03:03.440]   a tax loss harvesting when you take a loss in the market, because the market's been kind of volatile
[01:03:03.440 --> 01:03:08.640]   people are doing that this last few months. Do you know how to do that yourself? No, but betterment
[01:03:08.640 --> 01:03:14.800]   does it automatically, which means you reduce your tax liability and increase your investment
[01:03:14.800 --> 01:03:24.640]   returns. This is the way to save. It's a flat fee. No hidden costs. There is never a transaction fee.
[01:03:24.640 --> 01:03:30.880]   You know, that can kill you. If you're buying and selling mutual funds or stocks or any ETFs,
[01:03:30.880 --> 01:03:35.200]   any instrument, and those transaction fees really add up, you have to make a lot more
[01:03:35.200 --> 01:03:39.680]   return to make up for the trans-- not a betterment, no transaction fees ever.
[01:03:39.680 --> 01:03:47.440]   You get everything for one low transparent management fee, 25 basis points. That means for
[01:03:47.440 --> 01:03:52.400]   a hundred-- let's say you have $100,000 under investment, $250 a year to manage it.
[01:03:53.600 --> 01:03:59.280]   And as a fiduciary, this is really important. That means they represent you and your best interest.
[01:03:59.280 --> 01:04:04.640]   They make-- they're not incentivized. They don't make commission. They're not incentivized to
[01:04:04.640 --> 01:04:09.440]   recommend any funds. They don't have their own investment products to sell. They work on your
[01:04:09.440 --> 01:04:16.080]   behalf. So you're getting the best investment advice. This is just easily the best way to do it.
[01:04:16.080 --> 01:04:20.880]   Betterment offers personalized advice and a suite of tools to help you know whether you're on track
[01:04:22.000 --> 01:04:25.840]   to hit your investment goals and get the retirement you want. And when you need it,
[01:04:25.840 --> 01:04:31.920]   their tools and guidance can help you improve your investments or you just set it on automatic.
[01:04:31.920 --> 01:04:37.200]   Do remember, of course, always investing involves risk. But we've got a great deal for you. Our
[01:04:37.200 --> 01:04:43.600]   listeners get up to one year managed free, not even 25 basis points, not even 0.25 percent free.
[01:04:43.600 --> 01:04:51.360]   For more information, visit betterment.com/twit. Betterment.com/twit. There is a better way
[01:04:52.000 --> 01:04:59.120]   there is. This is it. Betterment.com/twit. Thank you for their support.
[01:04:59.120 --> 01:05:04.880]   Back to Ian. Thanks, Leo. Okay. Now, we were talking a little bit earlier about
[01:05:04.880 --> 01:05:11.280]   Microsoft being the day fact terminopoly, Facebook being the day fact terminopoly in some areas. We've
[01:05:11.280 --> 01:05:16.000]   had-- yet, I mean, I don't know about you guys, but I'm hardly sick about reporting on Facebook
[01:05:16.000 --> 01:05:17.920]   stuff at the moment. But-- [CHEERING]
[01:05:17.920 --> 01:05:24.000]   The company that keeps on giving the headlines. Have you seen the story today in the Wall Street
[01:05:24.000 --> 01:05:30.000]   Journal online, Christopher Mims? I can't read it because it's behind the paywall.
[01:05:30.000 --> 01:05:35.520]   It's the guy who works for a newspaper that's also behind the paywall. But essentially,
[01:05:35.520 --> 01:05:41.360]   he looks at the data that Google collects and talks about if you think Facebook is bad,
[01:05:41.360 --> 01:05:46.880]   look at what Google collects and what it does with it. When this broke and I did a story about
[01:05:46.880 --> 01:05:54.480]   how to download your data from all these different services. And when I downloaded Google's data,
[01:05:54.480 --> 01:06:00.320]   it came in at like 3.5 gig of data. I've been using Google a lot longer than I have Facebook,
[01:06:00.320 --> 01:06:04.080]   so that's not too much of a surprise. But it's just a huge amount of data.
[01:06:04.080 --> 01:06:09.360]   And I think people underestimate when they look-- when they point the finger at Facebook,
[01:06:09.360 --> 01:06:14.720]   I think a lot of them underestimate just how much information the data that Google gets and
[01:06:14.720 --> 01:06:19.280]   monetizes in the same way that Facebook does. And there's a couple of reasons for that.
[01:06:19.280 --> 01:06:22.880]   There are three things that people should be--
[01:06:22.880 --> 01:06:23.920]   But there's just a couple of things.
[01:06:23.920 --> 01:06:29.120]   --might be freaked out about. One of them is the fact that Google knows-- is very likely to know
[01:06:29.120 --> 01:06:34.080]   your exact location at every moment of your life for the last 10 years or whatever. If you go into
[01:06:34.080 --> 01:06:36.800]   their-- what do they call it? The Google--
[01:06:36.800 --> 01:06:37.360]   The dashboard.
[01:06:37.360 --> 01:06:38.880]   --the dashboard.
[01:06:38.880 --> 01:06:43.040]   And you go in there. It's actually quite fascinating. Like, oh yeah, I remember when we went to that little town.
[01:06:43.040 --> 01:06:45.760]   And if you have location turned off, it's still triangulating.
[01:06:45.760 --> 01:06:49.920]   They have lots of ways to-- because you're using Google Maps. You're using this. You're using that.
[01:06:49.920 --> 01:06:55.440]   And they basically collect all that in a single place. The second thing that freaks people out,
[01:06:55.440 --> 01:06:59.920]   if they didn't know this was happening, is that Google records and retains every time you talk to
[01:06:59.920 --> 01:07:05.280]   Google Home, they were-- so you can go in and listen to your own voice talking to Google Home.
[01:07:05.280 --> 01:07:11.040]   And you're like, wow, everything I've ever said to Google Home is right there. Or also the voice search
[01:07:11.600 --> 01:07:12.960]   feature. They collect it all.
[01:07:12.960 --> 01:07:14.800]   But Amazon will do the same thing, presumably.
[01:07:14.800 --> 01:07:16.560]   And Siri as well.
[01:07:16.560 --> 01:07:24.480]   Yeah, absolutely. So Amazon is a lot less transparent about it. They don't have something like--
[01:07:24.480 --> 01:07:25.600]   Yes, you don't have it.
[01:07:25.600 --> 01:07:25.600]   --like--
[01:07:25.600 --> 01:07:26.800]   --so it's in their app.
[01:07:26.800 --> 01:07:33.600]   It's in their app. If you look in the Alexa app, you can go in and see what's said and see exactly
[01:07:33.600 --> 01:07:39.840]   what triggers Alexa, which sometimes is pretty weird. Alexa has popped off when I have no idea
[01:07:39.840 --> 01:07:43.040]   what it was. And you can go in there and hear what you said.
[01:07:43.040 --> 01:07:47.200]   So yeah, it's available to-- I think Apple discards it. I think Apple uses it
[01:07:47.200 --> 01:07:53.920]   for improving Siri's voice recognition. And then they say they discard that data quickly.
[01:07:53.920 --> 01:08:02.240]   The biggest, egregious thing that Google does that people don't care that much about is that in
[01:08:02.240 --> 01:08:10.480]   Google Photos, anyone can identify you personally with the face recognition of your face.
[01:08:10.480 --> 01:08:14.160]   So Facebook does this as well, except Facebook is actually more transparent than Google in this
[01:08:14.160 --> 01:08:17.920]   regard. So in Facebook, there's a place where you can go on Facebook if you care about it.
[01:08:17.920 --> 01:08:22.000]   And you can see that it's happening. You can turn it off. You can do this, that, and the other thing.
[01:08:22.000 --> 01:08:27.920]   Whereas in Google Photos, that may be the case. I'm not certain. But in fact, so many people use
[01:08:27.920 --> 01:08:34.000]   Google Photos. And I use this-- I'm guilty myself. I use this feature. I go into Google Photos. I see
[01:08:34.000 --> 01:08:38.880]   that the people who have been identified all rise to the top. And in my case, I probably have
[01:08:38.880 --> 01:08:44.800]   40 people that are identified by name. And I go in and like, "Oh, look, there's Leo.
[01:08:44.800 --> 01:08:51.120]   Leo is identified up here. But down here is a picture of Leo that it didn't correctly. I'm going
[01:08:51.120 --> 01:08:56.160]   to tell him that that's Leo." So you're always refining their ability to do face recognition on
[01:08:56.160 --> 01:09:01.040]   the plus side. Google is very secure. They don't make that information available to other people,
[01:09:01.040 --> 01:09:06.560]   but they have it. And again, just to be clear about what the transgression is,
[01:09:06.560 --> 01:09:14.800]   they are getting other people to perfect the connection between your specific identity
[01:09:14.800 --> 01:09:19.760]   and your face without your knowledge or permission. That's the problem.
[01:09:19.760 --> 01:09:25.360]   But you see now, Facebook is massively losing on the PR stakes, even though
[01:09:25.360 --> 01:09:29.280]   Google, as you say, doesn't sell that stuff. They just collect it and use it for their own purposes.
[01:09:29.280 --> 01:09:34.000]   But they also came out with a bunch of privacy standards. I mean, at the Redge,
[01:09:34.000 --> 01:09:38.320]   we did a deep dive through these and found them to be pretty much useless. I mean,
[01:09:38.320 --> 01:09:41.040]   the rest of the panel, what do you think? Have you actually tried this out and checked out your
[01:09:41.040 --> 01:09:48.880]   own status? I've dug around in there. And it depends on what you're looking for. I found things that
[01:09:48.880 --> 01:09:55.760]   I wanted, that I did want to know. And the same thing is true with the capabilities for Facebook.
[01:09:55.760 --> 01:09:59.600]   But I always got the impression there was something else there that I was missing.
[01:09:59.600 --> 01:10:06.560]   So I'm deleting my Facebook account. I'm just waiting for May the first when the GPDR comes in,
[01:10:06.560 --> 01:10:11.600]   because I don't believe that if I deleted it now, that Facebook would actually delete my data.
[01:10:11.600 --> 01:10:15.920]   I don't believe they're trustworthy enough to be relied upon unless there's a force of a law
[01:10:15.920 --> 01:10:20.880]   behind them. I don't use Facebook for anything, so I'm not going to miss it. I don't understand why
[01:10:20.880 --> 01:10:25.040]   people would want to use it. So to some extent, the whole kerfuffle about Facebook kind of baffles
[01:10:25.040 --> 01:10:31.920]   me. I've never used Facebook for anything meaningful. But hey, there you go. I think the point here
[01:10:31.920 --> 01:10:35.360]   is that exploitation of data is happening in multiple points. You're talking about Facebook
[01:10:35.360 --> 01:10:41.280]   and Google. I'm thinking about Verizon, AT&T, BT, Telstra. Those types of organizations are
[01:10:41.280 --> 01:10:46.320]   capturing the same data and actually have just as much personally identifiable information.
[01:10:46.320 --> 01:10:51.520]   There was an article in the Guardian for Sunday. Sorry, it's Monday here now.
[01:10:51.520 --> 01:10:59.680]   And it was talking about how the company that owns an insurance company, the ones in, you have
[01:10:59.680 --> 01:11:04.240]   to submit all your personal details to get a quote. They're now giving the data to a Cambridge
[01:11:04.240 --> 01:11:09.120]   Analytica. And Cambridge Analytica is then using that data to then do political profiling.
[01:11:09.120 --> 01:11:15.920]   That is the concern. To some extent, I'm less concerned about Facebook and Google, although
[01:11:15.920 --> 01:11:21.920]   they're evil, to some extent, in terms of its Facebook's exploitation of the data. It's not
[01:11:21.920 --> 01:11:26.320]   actually that Facebook. I think the problem with Facebook is that they let someone else take the
[01:11:26.320 --> 01:11:32.560]   data and now we don't know who's got it. Cambridge Analytica has gone from saying it was 22 million
[01:11:32.560 --> 01:11:38.400]   to 57 million. And today, it's now 87 million. And they gave the question on the pinky swear saying,
[01:11:38.400 --> 01:11:41.040]   no, no, we'll delete it when we're done on the rest of it.
[01:11:41.040 --> 01:11:44.480]   Yes. And they will tell you that they have changed that policy and stuff like that. But I
[01:11:44.480 --> 01:11:50.000]   don't personally don't believe in this. This is based on the information that we have. There's
[01:11:50.000 --> 01:11:54.560]   probably a lot behind the scenes we don't know. But my current belief is that Facebook and Google
[01:11:54.560 --> 01:11:59.040]   don't belong in the same category in terms of trustworthiness. And Google is far more trustworthy.
[01:11:59.040 --> 01:12:04.000]   I think Google actually tries pretty hard to be honest and upfront about what's happening with
[01:12:04.000 --> 01:12:09.200]   your data, whereas Facebook is like a easel behind that dirty tricks and all the rest to get your
[01:12:09.200 --> 01:12:14.160]   data and do things with it. So the flip side of that debate is there's no way for somebody to come
[01:12:14.160 --> 01:12:19.440]   up and compete with Google because they can't get the data that's Google's got. So the reason that
[01:12:19.440 --> 01:12:24.160]   Google doesn't share the data that it has or your search history with other people is because that
[01:12:24.160 --> 01:12:28.320]   it locks in their dominant position. Whereas Facebook has made a serious boo boo here,
[01:12:28.320 --> 01:12:32.960]   it's made two boo boos. A, it's got children in charge. I mean, Mark Zuckerberg is clearly not an
[01:12:32.960 --> 01:12:39.280]   adult who should have the responsibility to have children. But let's have in control of it. I mean,
[01:12:39.280 --> 01:12:45.840]   Silicon Valley is a factory of failure. Does it actually produce anything except accidentally?
[01:12:45.840 --> 01:12:50.560]   Like, you know, the one in 1000, there's a defect. And goodness me, that's a successful defect.
[01:12:50.560 --> 01:12:56.240]   But anyway, I digress. So I think the point here is that we're seeing in competent people like
[01:12:56.240 --> 01:13:00.080]   Zuckerberg and the people who are in charge of these companies, like we saw Google go out and
[01:13:00.080 --> 01:13:05.920]   get grownups who are now in charge of the company. And they were, you know, this don't be evil
[01:13:05.920 --> 01:13:11.440]   thing sort of came around when, you know, what's his name, the weirdie guy that used to be the CEO
[01:13:11.440 --> 01:13:15.360]   of Google came in and sort of put good procedures and stuff like that around. That's the first.
[01:13:15.360 --> 01:13:20.320]   But I think that's right. And so, you know, we put an adult in charge, somebody who's got a
[01:13:20.320 --> 01:13:25.040]   grown up and normal person actually has a, you know, some sort of an emotional attachment to the
[01:13:25.040 --> 01:13:29.600]   world instead of living in some ivory bubble. And the second thing about Facebook is that they
[01:13:29.600 --> 01:13:33.840]   actually don't know what they're doing. They gave away their data to their competitors.
[01:13:33.840 --> 01:13:39.200]   They aren't secure. When you're inside Facebook, you've got access to anything. So the employees
[01:13:39.200 --> 01:13:43.520]   inside of Facebook actually have access to the entire system. So if I'm the Chinese government
[01:13:43.520 --> 01:13:47.920]   and I want to get access to all the details, I'd just go and put an operative inside of Facebook
[01:13:47.920 --> 01:13:52.960]   and start nicking all the data. I don't think all that data's gone. And we're starting to see
[01:13:52.960 --> 01:14:00.000]   that people are realizing this, that it's not safe to be associated with Facebook. And I think
[01:14:00.000 --> 01:14:05.280]   Facebook is going to lose its friends, if it had any fairly quickly as people realize just how
[01:14:05.280 --> 01:14:10.240]   much of the impact is that Facebook's been leaking all of this capability and just how little control
[01:14:10.240 --> 01:14:14.720]   it's got over its own business. It just doesn't know what it wants to do. And that, I think,
[01:14:14.720 --> 01:14:18.480]   is the message that keeps coming out is clearly Facebook doesn't know what it's doing. It doesn't
[01:14:18.480 --> 01:14:22.960]   know why it's doing it. And it doesn't know how it's doing it. And that's why we keep stumbling
[01:14:22.960 --> 01:14:24.720]   from disaster to disaster to disaster.
[01:14:24.720 --> 01:14:28.880]   I don't necessarily disagree with you, Greg. But I would think of it, I think of all of what
[01:14:28.880 --> 01:14:35.520]   you said in a different way. So first of all, I think Silicon Valley, there is something there.
[01:14:35.520 --> 01:14:38.960]   There's a lot of blundering. There's a lot of failure. But there is a lot of success. You can't
[01:14:38.960 --> 01:14:44.000]   argue with the fact that Silicon Valley invented the semiconductor, for example, or the most valuable
[01:14:44.000 --> 01:14:49.120]   company in history, or the search engine that dominates the globe in terms of search engines,
[01:14:49.120 --> 01:14:52.720]   or the social network that dominates the globe, and so on. And it's problematic that they dominate
[01:14:52.720 --> 01:14:56.960]   the globe. But you certainly can't say that Facebook and Google and Apple and so on aren't
[01:14:56.960 --> 01:15:01.040]   successful. You can't say Twitter is not successful, maybe. But you haven't put it as yet to make a
[01:15:01.040 --> 01:15:06.000]   pro-kill. We should rip in the Twitter at some point. But back to the point about Facebook,
[01:15:06.000 --> 01:15:10.320]   I think the thing about Facebook is not that they're a bunch of frat boys who don't know what
[01:15:10.320 --> 01:15:16.800]   they're doing. I think that their culture is based on Mark Zuckerberg's personal mindset,
[01:15:16.800 --> 01:15:23.840]   which is a mindset of amorality. My working theory is that Mark Zuckerberg personally
[01:15:23.840 --> 01:15:29.520]   doesn't understand ethics. I don't know why. I don't know what it is about it. But basically,
[01:15:29.520 --> 01:15:33.760]   they see all ethical issues as sort of an engineering problem. So they try everything.
[01:15:33.760 --> 01:15:39.040]   And when there's pushback, they're like, wow, that's surprising. I guess we shouldn't do that.
[01:15:39.040 --> 01:15:45.040]   There's sort of a complete absence of an ethical compass. What you're saying is Zuckerberg is
[01:15:45.040 --> 01:15:50.080]   incompetent. He's not fit to hold office that he has because he's not. I'll agree with that.
[01:15:50.080 --> 01:15:57.440]   He doesn't have the sort of 360 degrees sensor or the emotional range or the societal awareness
[01:15:57.440 --> 01:16:02.000]   or the political cape. I'm not too worried about the technology side because he doesn't do that
[01:16:02.000 --> 01:16:06.320]   either. He's got people handling all of that. So let's be concrete about this. So as an example
[01:16:06.320 --> 01:16:12.240]   of one of the things that Facebook does, they're required by the GDPR to have a buy-in for the
[01:16:12.240 --> 01:16:17.040]   privacy thing. So they rolled this out. They started rolling this out. It's going to roll out
[01:16:17.040 --> 01:16:20.640]   globally, they say, although it's going to be a different version, despite what they've said.
[01:16:20.640 --> 01:16:27.120]   But basically, when you you'll now in Europe, I think, get a dialogue box that says,
[01:16:27.120 --> 01:16:32.640]   we'd like to use your data for advertising and also scan your face for face recognition.
[01:16:32.640 --> 01:16:39.280]   Would you like to accept and continue? Or not? There is not a not button.
[01:16:39.280 --> 01:16:42.800]   I can't say, yes, you can have my data, but no, I don't want my face.
[01:16:42.800 --> 01:16:48.160]   But the point is there's it's not a yes or no. It's like yes or here's a complicated thing.
[01:16:48.160 --> 01:16:53.280]   The complicated thing is the dialogue box basically says manage data settings. So it's
[01:16:53.280 --> 01:16:57.440]   accept and continue to use Facebook or manage data settings. You go into the manage data
[01:16:57.440 --> 01:17:01.120]   settings, it's like, wait a minute. I'm sure you don't want to just accept you really. This is
[01:17:01.120 --> 01:17:06.960]   called dark pattern or dark patterns interface design where the interface is designed to get
[01:17:06.960 --> 01:17:11.280]   users to do things that are not in the user's interest, but are in fact in the interest of the
[01:17:11.280 --> 01:17:14.320]   company. Facebook is a master of this. They're a master of this.
[01:17:14.320 --> 01:17:18.160]   I mean, you've been covering this since Mark Zuckerberg was a glint in the Miltman's eye,
[01:17:18.160 --> 01:17:22.640]   but I mean, in terms of sort of where you think they're doing, do you think the company's
[01:17:22.640 --> 01:17:25.920]   serious about privacy? Do you think they're just basically going through the motions?
[01:17:27.440 --> 01:17:36.960]   I agree with the whole concept that Zuckerberg kind of charges in, sets something up, says,
[01:17:36.960 --> 01:17:43.760]   oh, there's a problem and then backs away from it. I think when you saw him testifying before the
[01:17:43.760 --> 01:17:49.680]   House and the Senate committees, he had a fairly good handle on what he knew about.
[01:17:49.680 --> 01:17:55.680]   But when you went into issues of business and you went into other areas that he basically
[01:17:55.680 --> 01:18:01.840]   wasn't versed in, it really showed. And there were comments from afterwards saying from
[01:18:01.840 --> 01:18:07.600]   people who had talked to employees inside Facebook saying that Zuckerberg doesn't care about the
[01:18:07.600 --> 01:18:12.320]   business end of it, that he's more interested in this connection and this community.
[01:18:12.320 --> 01:18:21.040]   That I think is what keeps people in Facebook. I did a story when a lot of this first broke about
[01:18:21.040 --> 01:18:27.760]   why people weren't leaving Facebook or wanted to. And if you talk to everyday users,
[01:18:27.760 --> 01:18:33.440]   they are angry about this, but they still want to see the photos of their grandchildren.
[01:18:33.440 --> 01:18:40.000]   And they still want to make sure that they're included in the event invites for their high school
[01:18:40.000 --> 01:18:46.240]   reunion. And the thing is, is that Facebook has 2.2 billion users. It is used extensively in
[01:18:46.240 --> 01:18:52.320]   everybody's everyday life. And if you're not on Facebook, you are left out of a lot of things.
[01:18:52.320 --> 01:18:58.080]   And the penetration for the usage of it is such that people look at it and go, "Yeah, but I
[01:18:58.080 --> 01:19:03.440]   really, I have to stay here because all my friends are here and I don't think anything."
[01:19:03.440 --> 01:19:05.440]   That's called the monopoly. Well, here's the thing.
[01:19:05.440 --> 01:19:06.240]   That's an uplifting question.
[01:19:06.240 --> 01:19:09.360]   I just call that depending on how you look at it. Because I mean, it always used to be the way that,
[01:19:09.360 --> 01:19:13.680]   you know, we saw with Friendster, you saw with MySpace, they would go up and up and up,
[01:19:13.680 --> 01:19:18.240]   their next big thing comes along and then it dies away again. And it hasn't happened with Facebook.
[01:19:18.240 --> 01:19:22.960]   And you were talking, Mike, about where we could go from this. We've had LO, which was supposed to
[01:19:22.960 --> 01:19:27.600]   be the non-adversion of Facebook. We've had a couple more pictures this week about it. And I think,
[01:19:27.600 --> 01:19:31.840]   is there any way, and this is a question for the whole panel, but is there any way that you can
[01:19:31.840 --> 01:19:35.040]   break this Facebook monopoly and get a better social network in place?
[01:19:35.040 --> 01:19:39.440]   I think it's possible because something other than social networking comes along.
[01:19:39.440 --> 01:19:45.760]   I mean, you know, some people hope that it would be messaging. That doesn't quite work the way it
[01:19:45.760 --> 01:19:52.480]   could, partly because Facebook owns two or three of the biggest messaging platforms.
[01:19:52.480 --> 01:19:56.320]   It actually owns its possible competitors. Yeah, exactly.
[01:19:56.320 --> 01:20:02.160]   Right. And it's a Swiss Army knife. It does everything. And in order for people to want to wander away
[01:20:02.160 --> 01:20:08.080]   from it, you're going to have to meet all of those needs. And there's nothing out there right now
[01:20:08.080 --> 01:20:14.320]   that does that. The closest thing historically to what Facebook is was AOL. And AOL failed because
[01:20:14.320 --> 01:20:20.720]   of an issue with the pipe that it was running on. It was modem-based. And so when people went to the
[01:20:20.720 --> 01:20:27.840]   Internet, AOL lost it. But Facebook doesn't face that at the moment. And there's nothing on the
[01:20:27.840 --> 01:20:32.960]   horizon at the moment that looks like it could do what Facebook does in its entire world.
[01:20:32.960 --> 01:20:38.640]   Don't laugh at me, Dwight. But there is one thing, there is a social network that's actually bigger
[01:20:38.640 --> 01:20:44.640]   than Facebook and more universal, which is email. Now, email is kind of gets it has a mixed reputation.
[01:20:44.640 --> 01:20:50.400]   There are people, people our age have been using email for decades and get a lot out of it and need
[01:20:50.400 --> 01:20:55.520]   it. It's just there. It's always in the background. And younger people will kind of snicker at email
[01:20:55.520 --> 01:21:02.800]   in the old thing. However, email has a significantly higher number of users than Facebook.
[01:21:02.800 --> 01:21:07.120]   And there's a lot of potential innovation that can happen on there. The thing that,
[01:21:07.120 --> 01:21:12.640]   again, the monopoly on everybody that Facebook has, you go to Facebook because everybody's on
[01:21:12.640 --> 01:21:18.720]   Facebook. Well, even more people are on email. And so if we could somehow turn email into a social
[01:21:18.720 --> 01:21:24.400]   network, I think that could be part of the solution. I think a lot of companies are actually working on
[01:21:24.400 --> 01:21:30.160]   that. I want to take the debate a slightly different way. We recently saw Uber and Travis
[01:21:30.160 --> 01:21:34.960]   Kalanik finally come to a grim end. And now that Travis Kalanik is out of the way,
[01:21:34.960 --> 01:21:42.800]   Uber actually shows all the signs of being a company on the mend, if you will, or making good.
[01:21:42.800 --> 01:21:48.640]   Now that it's got a grown up in charge, could we actually see that as a template? Could there
[01:21:48.640 --> 01:21:52.960]   actually be a movement to say, you know what, we actually need to have some proper CEOs,
[01:21:52.960 --> 01:21:56.960]   somebody in charge of Facebook who is actually a competent human being?
[01:21:57.760 --> 01:22:02.240]   Because has rigged the entire share system so that there's no possible way you can be got rid of.
[01:22:02.240 --> 01:22:06.880]   As did Kalanik, but he still got displaced. So I'm not disagreeing with you, but I'm saying,
[01:22:06.880 --> 01:22:12.080]   if there was enough of a push, if the politicians started to cut up rough, and the financial backers
[01:22:12.080 --> 01:22:17.120]   started to cut up rough, and the users started to say, you know, we need to see some change,
[01:22:17.120 --> 01:22:20.320]   there is a chance here that we could see him turfed out.
[01:22:20.320 --> 01:22:24.160]   It's interesting. We're going to be coming back to something to, you know, commercial and
[01:22:24.160 --> 01:22:30.160]   government pressures in it a little while. In particular, as it relates to Kaspersky and also the
[01:22:30.160 --> 01:22:34.960]   Microsoft email privacy thing. But first here's Leo with a quick verse, quick word of our sponsors
[01:22:34.960 --> 01:22:40.720]   for this week's show. Thank you, Ian. Our show today brought to you by Eero. I think everything
[01:22:40.720 --> 01:22:50.000]   on this show today I use. Yeah. Eero is all over my house. I got, I got Eero all over my house.
[01:22:50.640 --> 01:22:55.280]   Eero all over mom's house too, because she was having trouble with her Wi-Fi. Eero is a better
[01:22:55.280 --> 01:23:00.560]   Wi-Fi. Eero solves the problem of modern Wi-Fi. You know, when we first started using Wi-Fi,
[01:23:00.560 --> 01:23:05.680]   many, many moons ago, what do you have? You had a laptop, a desktop, maybe a phone and a tablet,
[01:23:05.680 --> 01:23:10.480]   you know, a few devices. Now it's not at all unusual to see dozens of devices on your Wi-Fi
[01:23:10.480 --> 01:23:18.240]   network. Oh, look, I have 62. Yeah, because doorbells, lights, all that stuff. And it's just killing
[01:23:18.240 --> 01:23:22.880]   Wi-Fi. Not to mention the fact that your neighbors got a new Wi-Fi booster that's knocking your
[01:23:22.880 --> 01:23:29.680]   signal out. Wi-Fi, which used to be great. I think it was great. It's just really gotten
[01:23:29.680 --> 01:23:34.640]   problematic. If you're suffering from stuttering and buffering when you watch your Netflix, if you
[01:23:34.640 --> 01:23:40.800]   can't download fast, if you're waiting for email to arrive, you need Eero. Eero was started not so
[01:23:40.800 --> 01:23:48.160]   long ago, early 2016. Since then they've learned every, every system they install helps them get
[01:23:48.160 --> 01:23:52.800]   better. Hundreds of thousands of systems have made them smarter, faster, more reliable. In fact,
[01:23:52.800 --> 01:23:59.360]   their new second generation Eero, that's why my mom, I gave her my original Eero, which actually
[01:23:59.360 --> 01:24:03.760]   is fine. It's really been a boon for her. So I could get the second generation Eero,
[01:24:03.760 --> 01:24:09.040]   which is so cool. It's got the base station and the beacons, which just plug in anywhere.
[01:24:09.040 --> 01:24:16.000]   There's a wall socket. Beautiful design. The beacons act as a nightlight too, which I put them in the
[01:24:16.000 --> 01:24:23.840]   halls, three radios, two 5G's and a 2.4. So that's tri-band. It's twice as fast as the first generation
[01:24:23.840 --> 01:24:29.600]   Eero, which means you can do more. You and everybody else in the house can do more simultaneously.
[01:24:29.600 --> 01:24:34.880]   The new thread radio means Eero connects to low power devices like lock store bells and other
[01:24:34.880 --> 01:24:42.640]   sensors easily and simply expanding your coverage is easy. We started as most people do with three
[01:24:42.640 --> 01:24:47.040]   Eero's, a base station and two beacons, but we have a pretty big house. So we got two more.
[01:24:47.040 --> 01:24:51.840]   That's really helped out in the far reaches of the house. You just plug it into wall and it joins.
[01:24:51.840 --> 01:24:57.680]   You completely control it with your phone. Eero plus means I've got filtering against malware.
[01:24:57.680 --> 01:25:03.760]   The kid can't get on adult sites. I can even pause the kid's internet when it's bedtime.
[01:25:03.760 --> 01:25:08.960]   I love that. I can even use my echo to do that. I can say echo. Pause Michael's internet.
[01:25:09.360 --> 01:25:16.080]   Oh, I love that. He can't un-pause it either. He has to get it. It's the best router you've ever had.
[01:25:16.080 --> 01:25:20.480]   It's more than a router. It's a Wi-Fi system for free overnight shipping to the US or Canada.
[01:25:20.480 --> 01:25:26.720]   Visit E-E-R-O-Eero.com and at checkout, select overnight shipping, then enter TWIT and that makes
[01:25:26.720 --> 01:25:33.280]   it free. US and Canada free overnight. You do want this as fast as possible. Eero, I'm not kidding.
[01:25:33.280 --> 01:25:40.480]   It will solve your Wi-Fi woes. Eero.com enter the code TWIT. Thank you, Eero, for their support.
[01:25:40.480 --> 01:25:45.280]   We thank you for supporting them and we thank Ian Thompson for hosting TWIT this week while I'm on
[01:25:45.280 --> 01:25:50.880]   vacation. Back to you, Ian. Thanks, Leo. Okay, now I'm sure plenty of you have seen
[01:25:50.880 --> 01:25:55.440]   avid watches of TWIT have seen some of these. But here's something, here's a few things that you
[01:25:55.440 --> 01:26:01.280]   may have missed from this week's broadcasts. Previously on TWIT. Mike Boas, who watches the
[01:26:01.280 --> 01:26:07.920]   show, Hi Mike, Mad Dog Movies made us this. This is the closest thing so far as Stacey has to the
[01:26:07.920 --> 01:26:21.680]   Punish Leo button. Yeah, is that satisfying? Security now. In the US, this is our tax filing
[01:26:21.680 --> 01:26:29.360]   deadline date. And one of the headlines I got, I got a kick out of, said that the IRS's E-filing
[01:26:29.360 --> 01:26:36.960]   system is... Wait for it. Over-tax. Because what I saw was that the IRS didn't know why it wasn't
[01:26:36.960 --> 01:26:42.960]   working. They don't. No, it may not be over-taxed, it may be something else. Under-attack. Yes.
[01:26:42.960 --> 01:26:50.720]   All about Android. Let's talk about it. Yeah. Huawei P20 and P20 Pro. You can actually turn
[01:26:50.720 --> 01:26:55.440]   the notch off. I don't have a problem with notches, especially when they're implemented like this.
[01:26:55.440 --> 01:26:59.600]   You don't see the notch anymore, but the notch is still physically being used by putting the
[01:26:59.600 --> 01:27:05.760]   battery icon and the reception icons in it. The new screensabers. You got to play around with the
[01:27:05.760 --> 01:27:12.000]   Nintendo Labo kits. We're looking at a lot of cardboard, one rubber band and a few stickers.
[01:27:12.000 --> 01:27:16.320]   Is it time for you to go put that suit on? It's like a backpack. Oh, so you just stand up like
[01:27:16.320 --> 01:27:21.920]   this one. No way! That was so cool. To it. The happiest place on earth.
[01:27:21.920 --> 01:27:30.240]   Well, I'm glad Steve Gibson mentioned the IRS there because it is tax week in the US and
[01:27:30.240 --> 01:27:34.080]   everyone has been frantically scrambling to get their pound of flesh out of the government and
[01:27:34.080 --> 01:27:39.840]   vice versa, of course. And of course, the IRS website went completely tits up at the important
[01:27:39.840 --> 01:27:45.040]   time. They've had to extend the deadline and in reports onto this, they've been shown that they've
[01:27:45.040 --> 01:27:51.360]   got 50 or 60% of their servers and now obviously drop some lessons. They have one mainframe going
[01:27:51.360 --> 01:27:57.360]   all the way back to 1964. America is supposed to be the cutting edge when it comes to computer
[01:27:57.360 --> 01:28:03.440]   technology. What exactly went wrong? Do I mic your local sale? What's your view on it?
[01:28:03.440 --> 01:28:10.960]   Well, the US is supposed to be cutting edge. The government never has been and the government
[01:28:10.960 --> 01:28:16.080]   is frequently behind every new administration except for the current one. They've said what
[01:28:16.080 --> 01:28:20.640]   we're going to do is we're going to spend some money and bring in the expertise to fix things.
[01:28:20.640 --> 01:28:27.520]   Never seems to actually happen. The IRS also has had a bunch of budget cuts itself. So,
[01:28:27.520 --> 01:28:33.040]   they're on to many personnel there and probably a little fewer IT personnel as well.
[01:28:33.040 --> 01:28:38.800]   Or may not be a victim of shrinking resources.
[01:28:38.800 --> 01:28:43.280]   Actually, it's kind of saved us. The fact that the US, the government is behind the times
[01:28:43.280 --> 01:28:49.840]   means that we're still voting with like savages, with like pieces of paper in a cardboard box or
[01:28:49.840 --> 01:28:55.440]   something like that. And that's harder to hack than the alternative, which is a nationwide system.
[01:28:55.440 --> 01:28:56.960]   Some of us are. Some of us are.
[01:28:56.960 --> 01:29:04.240]   There's more problems with voting machines all around the country and where there is no paper
[01:29:04.240 --> 01:29:08.320]   ballot. And as we've seen at a couple of DEF CONs, those
[01:29:08.320 --> 01:29:10.800]   existing key things are...
[01:29:10.800 --> 01:29:11.440]   Okay, some points.
[01:29:11.440 --> 01:29:11.760]   Exactly.
[01:29:11.760 --> 01:29:16.320]   They haven't even finished the opening presentation and some guy had managed to hack into one of
[01:29:16.320 --> 01:29:22.080]   these systems. And I'm currently with you on this, Mike. Paper voting is incredibly difficult to
[01:29:22.080 --> 01:29:26.000]   hack. You've got to get a large number of people signing on boxes, stuffing, ballot paper.
[01:29:26.000 --> 01:29:29.760]   Of course, in Russia, it didn't work because they have a similar thing where they have paper
[01:29:29.760 --> 01:29:33.680]   ballots and stuff. And they actually put cameras at all the ballot boxes. And we all sat there and
[01:29:33.680 --> 01:29:37.920]   watched people stuffing the ballot box and committing all kinds of crimes. And then nothing happened.
[01:29:37.920 --> 01:29:42.960]   Yeah, but the point that I think the thing to realize here is that as far as I'm aware,
[01:29:42.960 --> 01:29:49.920]   the only country that has fairly substantial use of voting machines is the US. And they're the only
[01:29:49.920 --> 01:29:51.760]   people with this problem as far as I know.
[01:29:51.760 --> 01:29:56.480]   Yeah, I mean, Estonia has got some issues, but they had some issues with their security cards
[01:29:56.480 --> 01:30:02.480]   as it stood. But yeah, after the 2000 election, then the government threw money and said,
[01:30:02.480 --> 01:30:07.120]   "By electronic voting things, these things are pathetically insecure." I mean, how comfortable
[01:30:07.120 --> 01:30:13.600]   you having the republic in the hands of not Debulb, but whoever the company has renamed itself.
[01:30:13.600 --> 01:30:22.000]   Well, the dominant company itself is sort of like compromise in a lot of ways. I've spent a
[01:30:22.000 --> 01:30:27.280]   while since I've read about the nature of it. But basically, there's a resistance to building
[01:30:27.280 --> 01:30:32.160]   in real security for a variety of reasons. I don't want to talk too much about it because I don't
[01:30:32.160 --> 01:30:36.880]   know that much about it. But it is a real problem. And I think we should go back to the way that
[01:30:36.880 --> 01:30:42.480]   used to vote in ancient Sparta, which is that all of the Spartiots would gather in one place.
[01:30:42.480 --> 01:30:49.680]   And then they would throw out a name and then they'd bang on their shields and the loudest noise
[01:30:49.680 --> 01:30:52.400]   that was a winner. And so I think we should go back to that.
[01:30:52.400 --> 01:30:54.800]   Well, I think that you can't hack that.
[01:30:54.800 --> 01:31:00.000]   They did have slavery in Sparta as well, but quite a little slaughter. But yeah, I mean,
[01:31:00.000 --> 01:31:04.240]   Greg, in the UK, are they going for this sort of thing in a big way or is Theresa May actually
[01:31:04.240 --> 01:31:06.880]   shown some elements of brain cells to rub together?
[01:31:06.880 --> 01:31:11.680]   No, no, there's no signs of having brain cells to rub together. But there's no signs
[01:31:11.680 --> 01:31:16.720]   voting genes being adopted here, nor in Australia, which is the other place that I watch the
[01:31:16.720 --> 01:31:18.000]   politics for. And I think all of them are sort of...
[01:31:18.000 --> 01:31:19.440]   Well, voting is compulsory in Australia, right?
[01:31:19.440 --> 01:31:21.760]   Voting is compulsory in Australia.
[01:31:21.760 --> 01:31:22.880]   It's good to say.
[01:31:22.880 --> 01:31:27.280]   96, 97% participation rate in the voting in Australia.
[01:31:28.240 --> 01:31:32.160]   Nobody gets to say, "I didn't vote for that president," or that person in charge,
[01:31:32.160 --> 01:31:33.200]   because everybody did.
[01:31:33.200 --> 01:31:38.480]   I think the interesting thing is that most countries have not implemented voting machines
[01:31:38.480 --> 01:31:43.120]   for the simple reason that you couldn't audit the results. So the part of the
[01:31:43.120 --> 01:31:49.840]   constitution of countries like UK and Australia was that you must have an audit trail.
[01:31:49.840 --> 01:31:54.320]   There must be able to be a counted vote. And there has never been a push into voting
[01:31:54.320 --> 01:31:58.400]   machines because it was always felt that the audit trails or the integrity of those was not
[01:31:58.400 --> 01:32:02.320]   actually up to snuff. And we've seen these voting machines. It turns out they're using
[01:32:02.320 --> 01:32:06.880]   like Microsoft access databases from like in the 2000 era.
[01:32:06.880 --> 01:32:07.680]   And you can actually...
[01:32:07.680 --> 01:32:09.280]   What does CE for goodness sake?
[01:32:09.280 --> 01:32:10.720]   And that's called Winz and Kid Reason.
[01:32:10.720 --> 01:32:11.280]   Some of them at its core.
[01:32:11.280 --> 01:32:15.440]   And you can use well-known vulnerabilities to compromise them on the land port, which
[01:32:15.440 --> 01:32:20.160]   is exposed on the back. And you can just hook your computer up and you can crack it in less
[01:32:20.160 --> 01:32:23.520]   than three minutes using any sort of off-the-shelf tool that you need.
[01:32:23.520 --> 01:32:27.280]   On the other hand, there's an advantage to insecure voting machines, which is that the hackers
[01:32:27.280 --> 01:32:28.640]   will probably pick a better president.
[01:32:28.640 --> 01:32:34.160]   Yeah, come on, you've seen 4chan, that's what those daughters of goodness say.
[01:32:34.160 --> 01:32:37.200]   We'd have, I don't know, sort of PewDiePie.
[01:32:37.200 --> 01:32:41.280]   It depends on whether it's Chinese or the Russian hackers that are doing the hacking.
[01:32:41.280 --> 01:32:43.600]   Well, this is it. How are things down in Texas?
[01:32:43.600 --> 01:32:44.240]   Either.
[01:32:44.240 --> 01:32:45.040]   But...
[01:32:45.040 --> 01:32:45.760]   Well, in Texas...
[01:32:45.760 --> 01:32:50.560]   I just feel that the paper trails is still the way to go for the time being.
[01:32:50.560 --> 01:32:54.640]   And that... I understand that cost is a big issue.
[01:32:54.640 --> 01:32:57.040]   Voting machines are substantially cheaper than paper.
[01:32:57.040 --> 01:33:00.000]   And having to move the paper around and organizing everything.
[01:33:00.000 --> 01:33:01.040]   I understand that.
[01:33:01.040 --> 01:33:04.720]   And American government is very big on not spending money because people in America
[01:33:04.720 --> 01:33:06.800]   don't like to spend, to pay taxes.
[01:33:06.800 --> 01:33:11.200]   So there's not a lot of money to spend on building up infrastructure and doing things in
[01:33:11.200 --> 01:33:13.760]   ways that other people might choose to be.
[01:33:13.760 --> 01:33:18.720]   But it probably is time for them to just roll it back and start using paper, I would think.
[01:33:18.720 --> 01:33:20.480]   Yeah, I mean, how do they do it in Texas to work?
[01:33:20.480 --> 01:33:25.440]   So there are different counties handle the elections in Texas.
[01:33:25.440 --> 01:33:28.560]   That's true in a lot of the states around the country.
[01:33:28.560 --> 01:33:32.000]   And so the counties actually buy the voting machines.
[01:33:32.000 --> 01:33:36.480]   One of the problems is that a couple of decades ago there was a...
[01:33:36.480 --> 01:33:44.720]   Maybe about 10 years ago, there was Congress approved a bunch of money to help counties
[01:33:45.440 --> 01:33:49.600]   modernize their election systems. And they bought voting machines all over the country,
[01:33:49.600 --> 01:33:52.960]   including here in Texas and in Harris County, where Houston is.
[01:33:52.960 --> 01:34:00.080]   And what has happened is those machines have aged, but it's very expensive to replace them.
[01:34:00.080 --> 01:34:04.800]   It costs tens of millions of dollars in accounting the size of a Harris,
[01:34:04.800 --> 01:34:06.960]   where you have about 8 million people living.
[01:34:06.960 --> 01:34:10.080]   And so if you try to do that, it's...
[01:34:10.080 --> 01:34:13.280]   Essentially, they're stuck with these older voting machines.
[01:34:13.280 --> 01:34:16.560]   There's a company based in Austin called Heart Intercivic,
[01:34:16.560 --> 01:34:20.880]   that is one of the biggest suppliers of voting machines in the country.
[01:34:20.880 --> 01:34:22.800]   They also make the paper stuff as well.
[01:34:22.800 --> 01:34:28.880]   And they have been going county to county and trying to sell their wares with their newest version,
[01:34:28.880 --> 01:34:33.120]   which is an electronic voting machine that also has a paper ballot attached to it.
[01:34:33.120 --> 01:34:38.000]   And that is seen as kind of the compromise that a lot of people want to see,
[01:34:38.000 --> 01:34:41.440]   where you have some way to back up what the voter actually intended to do.
[01:34:42.320 --> 01:34:46.080]   Yeah, I mean, it's a question of everyone keeping their pieces of paper at the end of the vote.
[01:34:46.080 --> 01:34:49.440]   But while we're on the topic of data security, we also had the
[01:34:49.440 --> 01:34:53.440]   the US Supreme Court actually chuck out a case, which has been
[01:34:53.440 --> 01:34:57.760]   a bubbling under for about the last four years, just in terms of background.
[01:34:57.760 --> 01:34:59.440]   This was the Microsoft Dublin case.
[01:34:59.440 --> 01:35:05.200]   What Microsoft was doing was fighting a subpoena from US law enforcement,
[01:35:05.200 --> 01:35:09.120]   who wanted data that was stored on their Dublin servers.
[01:35:09.120 --> 01:35:13.040]   They said under Irish protection law, we can't give this to you.
[01:35:13.040 --> 01:35:15.200]   And also, you're going to need something more than a subpoena,
[01:35:15.200 --> 01:35:17.840]   something a judge might actually have to lay into.
[01:35:17.840 --> 01:35:20.880]   This had been bubbling under four years.
[01:35:20.880 --> 01:35:25.040]   Microsoft has been saying, we will fight for the rights of our cloud customers,
[01:35:25.040 --> 01:35:28.080]   and also make sure our cloud business doesn't disappear entirely.
[01:35:28.080 --> 01:35:33.040]   If we actually fall over on this, then in the omnibus spending bill earlier in the month,
[01:35:33.040 --> 01:35:41.520]   then the cloud act got shoved in at page 2000, I think it was 2000 and 23 out of a 2,200 page act,
[01:35:41.520 --> 01:35:43.280]   which basically negated this whole thing.
[01:35:43.280 --> 01:35:45.760]   And now the Supreme Court has turned it down.
[01:35:45.760 --> 01:35:49.840]   And Microsoft can cheerfully with its hand on its heart say, yep, have all the data.
[01:35:49.840 --> 01:35:51.920]   Was this a win for us or a loss?
[01:35:51.920 --> 01:35:57.040]   Who knows, but I think it's definitely a win for whoever came up with the clarifying lawful
[01:35:57.040 --> 01:35:59.280]   overseas use of data or cloud.
[01:35:59.280 --> 01:36:00.720]   Oh, but come on, Americans, love this.
[01:36:00.720 --> 01:36:02.720]   Thanks for your time.
[01:36:02.720 --> 01:36:03.600]   I hate that.
[01:36:03.600 --> 01:36:05.200]   I hate those attributes.
[01:36:05.200 --> 01:36:05.680]   It just...
[01:36:05.680 --> 01:36:07.760]   I don't...
[01:36:07.760 --> 01:36:11.520]   I mean, on the one hand, we all want better security.
[01:36:11.520 --> 01:36:17.440]   We all want data to be out of the hands of governments and others and just get...
[01:36:17.440 --> 01:36:20.400]   We need privacy, and if that means the criminals get privacy too,
[01:36:20.400 --> 01:36:22.640]   that's just something that's going to have to happen.
[01:36:22.640 --> 01:36:24.560]   That's my own view.
[01:36:24.560 --> 01:36:27.920]   On the other hand, you don't want these shell games where you can just move data
[01:36:27.920 --> 01:36:29.920]   around theoretically in other countries.
[01:36:29.920 --> 01:36:36.000]   It's a ridiculous concept that data exists in a specific country, just on a server somewhere.
[01:36:36.000 --> 01:36:45.040]   All this gymnastics about data and where it resides is just a ridiculous idea.
[01:36:45.040 --> 01:36:45.600]   Wow.
[01:36:45.600 --> 01:36:50.160]   And you see countries like Russia and China demanding that data on their own...
[01:36:50.160 --> 01:36:54.560]   And there's only one reason for that is so that they themselves can get access to that data
[01:36:54.560 --> 01:36:58.560]   so that they can repress human rights and democracy and things like that.
[01:36:58.560 --> 01:36:58.560]   Yeah.
[01:36:58.560 --> 01:37:04.640]   I mean, Greg, GDPR coming in on May 25th is going to throw a major spanner in the works on this one.
[01:37:04.640 --> 01:37:07.760]   I mean, how are these two philosophies going to interact?
[01:37:07.760 --> 01:37:09.440]   It's going to be interesting.
[01:37:09.440 --> 01:37:09.920]   I think...
[01:37:09.920 --> 01:37:12.960]   I don't think GPDR is the right regulation to consider here.
[01:37:12.960 --> 01:37:17.440]   GPDR is saying, if you're a company and you're holding data on users,
[01:37:17.440 --> 01:37:23.200]   you must only hold the minimum amount of data that's related to what you need to run the business.
[01:37:23.200 --> 01:37:26.800]   And you must throw it away when you have finished needing it.
[01:37:26.800 --> 01:37:28.880]   So you can't just gather up all the...
[01:37:28.880 --> 01:37:33.440]   You can't do a Cambridge Analytica, suck up all this data and keep it forever.
[01:37:33.440 --> 01:37:34.400]   You must delete it.
[01:37:34.400 --> 01:37:37.120]   And if you're found to be otherwise, the punishment is quite broad.
[01:37:37.120 --> 01:37:39.840]   So that's got nothing to do with this case as such.
[01:37:39.840 --> 01:37:41.200]   I think in...
[01:37:41.200 --> 01:37:41.600]   What's...
[01:37:41.600 --> 01:37:43.280]   We're going to see a really interesting thing here.
[01:37:43.280 --> 01:37:48.560]   U.S. sort of extending an imperial arm to say we can use any U.S. company
[01:37:48.560 --> 01:37:50.960]   as an extension of our law enforcement operation.
[01:37:51.520 --> 01:37:57.440]   What happens when the UK government legislates to say we're going to use that to take stuff
[01:37:57.440 --> 01:38:03.280]   out of the U.S. or if we start saying they've reached into Ireland and demanding data that they
[01:38:03.280 --> 01:38:04.640]   want. And...
[01:38:04.640 --> 01:38:09.200]   Or what happens if the Irish government creates a law which says it's illegal for the U.S.
[01:38:09.200 --> 01:38:10.240]   government to have that data?
[01:38:10.240 --> 01:38:12.320]   Yeah, I mean...
[01:38:12.320 --> 01:38:15.200]   These are issues that are currently underway.
[01:38:15.200 --> 01:38:19.760]   The European government has shown its willingness to confront those types of issues head on
[01:38:19.760 --> 01:38:25.920]   and to have those and to go against what it is that America wants in this situation.
[01:38:25.920 --> 01:38:29.840]   And if they just made it outright illegal to take data out of Europe,
[01:38:29.840 --> 01:38:31.360]   then where does that leave us?
[01:38:31.360 --> 01:38:32.560]   Who's in charge?
[01:38:32.560 --> 01:38:38.880]   Well clearly the answer is for the U.S. to drag European leaders into a sort of a
[01:38:38.880 --> 01:38:41.440]   coliseum type of situation and feed them to the alliance.
[01:38:41.440 --> 01:38:45.280]   Two men and so, one man leaves.
[01:38:45.280 --> 01:38:47.520]   It's an old-fashioned solution but still.
[01:38:47.520 --> 01:38:48.160]   Yeah.
[01:38:48.160 --> 01:38:49.360]   It's just...
[01:38:49.360 --> 01:38:51.600]   Who's jurisdiction applies?
[01:38:51.600 --> 01:38:55.600]   So the U.S. government has decided that they can reach into...
[01:38:55.600 --> 01:38:59.440]   That a U.S. company operating in Ireland is actually part of the U.S.
[01:38:59.440 --> 01:39:04.640]   jurisdiction and therefore they can demand that that company cough up the data.
[01:39:04.640 --> 01:39:06.560]   But technically it's actually in...
[01:39:06.560 --> 01:39:10.320]   on Irish soil and that data belongs to Ireland.
[01:39:10.320 --> 01:39:13.680]   There's a definite clash of intention here that...
[01:39:13.680 --> 01:39:17.360]   That's going to be played out over time.
[01:39:17.360 --> 01:39:22.720]   I mean it's not going to lead to countries siloing off information within their own borders.
[01:39:22.720 --> 01:39:24.560]   I mean Dwight, what's your take on this?
[01:39:24.560 --> 01:39:31.680]   Because I mean it strikes me that that breaks one of the fundamental advantages of the internet
[01:39:31.680 --> 01:39:32.720]   network communications.
[01:39:32.720 --> 01:39:39.360]   Well you can store data in one specific location and I think that when you start...
[01:39:39.360 --> 01:39:43.040]   when you do that you must be bound by the laws of that country.
[01:39:43.840 --> 01:39:47.360]   I think that that has to be sovereign in that way.
[01:39:47.360 --> 01:39:52.240]   But the thing is that you don't have to store data in any one country.
[01:39:52.240 --> 01:39:58.560]   I mean Google's data for its search engine is stored all over the place.
[01:39:58.560 --> 01:40:06.240]   When you end up with making a call to a website, the data that it uses may not even come from your
[01:40:06.240 --> 01:40:07.360]   own country.
[01:40:07.360 --> 01:40:12.960]   And so I think that you need to keep that in mind as well and the laws need to be written to
[01:40:13.840 --> 01:40:15.360]   take that into account.
[01:40:15.360 --> 01:40:21.200]   The problem is we don't have lawmakers in any country who understand that or who can write laws
[01:40:21.200 --> 01:40:23.840]   that are technologically savvy I don't think.
[01:40:23.840 --> 01:40:26.960]   It doesn't seem to be much evidence certainly in Europe.
[01:40:26.960 --> 01:40:31.440]   Well Europe's... I always tell me there are some tech savvy legislators in Europe.
[01:40:31.440 --> 01:40:37.600]   In the US there are a few but the bulk of them seem to be lawyers and operating on about 50 years
[01:40:37.600 --> 01:40:38.160]   out of date.
[01:40:38.160 --> 01:40:41.920]   Do you have any hope that politicians can actually get this right or is this going to be
[01:40:41.920 --> 01:40:45.600]   something that's just going to be worked out by Hacken Slash and a lot of people are going to
[01:40:45.600 --> 01:40:46.560]   call to the crossfire?
[01:40:46.560 --> 01:40:48.240]   No. No hope at all.
[01:40:48.240 --> 01:40:50.880]   Okay well with that note we'll just hang out there.
[01:40:50.880 --> 01:40:54.080]   No I think...
[01:40:54.080 --> 01:40:54.720]   I agree with Mike.
[01:40:54.720 --> 01:40:56.240]   I think it is a...
[01:40:56.240 --> 01:41:03.360]   that until you have people who run almost on a technological platform
[01:41:03.360 --> 01:41:09.760]   who tout that and have their bona fides, I think it's going to be pretty touch and go in
[01:41:09.760 --> 01:41:12.320]   terms of laws for the next 20 years.
[01:41:12.320 --> 01:41:16.000]   And this stuff won't be determined by technical merit.
[01:41:16.000 --> 01:41:19.840]   It'll be determined by the flaws in human nature and also politics.
[01:41:19.840 --> 01:41:28.240]   In all of these scenarios the problem is that the case being made is well we can have law and order
[01:41:28.240 --> 01:41:33.760]   but we can let the bad guys get away with hiding their dirty deeds on foreign servers.
[01:41:33.760 --> 01:41:39.360]   When it's framed like that you're not going to get enough high-minded people,
[01:41:39.360 --> 01:41:43.440]   enough fair-minded people to say you know what that's not really what's happening here.
[01:41:43.440 --> 01:41:45.680]   We have to balance multiple... no no no that doesn't happen.
[01:41:45.680 --> 01:41:47.520]   Everybody wants to pander to law and order.
[01:41:47.520 --> 01:41:55.360]   Everybody wants to... human nature is such that we tend to focus on the problem of bad people
[01:41:55.360 --> 01:42:02.320]   getting away with stuff rather than the threats to good people when data is generally
[01:42:02.320 --> 01:42:03.760]   abused in that fashion.
[01:42:03.760 --> 01:42:11.440]   So I really don't think that the politics of our era will allow the kind of solution that
[01:42:11.440 --> 01:42:14.160]   will make everybody happy, at least everybody on this show right now.
[01:42:14.160 --> 01:42:14.640]   Happy.
[01:42:14.640 --> 01:42:19.600]   Isn't it interesting that this whole show has been a discussion around politics, business,
[01:42:19.600 --> 01:42:27.280]   privacy and we haven't really privacy and we really haven't talked about a technology at all.
[01:42:27.280 --> 01:42:32.240]   And this seems like a major transition in technology that we're no longer talking about
[01:42:32.240 --> 01:42:33.760]   the technology itself.
[01:42:33.760 --> 01:42:39.840]   We're really talking about how we as a fit into society.
[01:42:39.840 --> 01:42:41.680]   How do we fit into the political system?
[01:42:41.680 --> 01:42:47.040]   How do we make it so that technology can go beyond that first step that we sort of
[01:42:47.040 --> 01:42:49.040]   been through over the last 20 years?
[01:42:49.040 --> 01:42:50.320]   And now it's seriously.
[01:42:50.320 --> 01:42:56.000]   So in a sense I think what we're seeing is this emergence of tech as becoming mainstream.
[01:42:56.000 --> 01:43:01.120]   And this is the convulsions of teenage years in tech turning into an adult.
[01:43:01.120 --> 01:43:06.800]   And now we have to become part of society and part of politics and part of the business process
[01:43:06.800 --> 01:43:10.960]   that we never used to have in 10 years gone by because five years ago on this show,
[01:43:10.960 --> 01:43:16.000]   the only thing that we would have talked about is Apple iOS and the latest memory and the CPUs
[01:43:16.000 --> 01:43:16.480]   and that's it.
[01:43:16.480 --> 01:43:18.000]   That's all we ever discussed.
[01:43:18.000 --> 01:43:23.520]   Well, yeah, but that's in part in evidence that the technology has matured to such an
[01:43:23.520 --> 01:43:25.440]   estate that we don't need to be constantly.
[01:43:25.440 --> 01:43:27.280]   I mean, you remember what it was like here.
[01:43:27.280 --> 01:43:31.280]   You're all remember what it was like in sort of the early 90s where you bought the new
[01:43:31.280 --> 01:43:35.360]   processor because you had to buy the new processor to make the latest software run.
[01:43:35.360 --> 01:43:38.240]   Now, I mean, this computer is what, five, six years old?
[01:43:38.240 --> 01:43:39.680]   OK, you're ahead of the game.
[01:43:39.680 --> 01:43:46.080]   But a lot of us are using computer hardware, which is in terms of the 1990s,
[01:43:46.080 --> 01:43:48.640]   obsolescence or completely obsolete.
[01:43:48.640 --> 01:43:51.920]   And I think Greg, you're right in that we're becoming because technology is becoming
[01:43:51.920 --> 01:43:54.560]   that much more mainstream, that much more accepted.
[01:43:55.680 --> 01:44:02.000]   I'll grant my parents using laptops, which would have been gold mines back in the day.
[01:44:02.000 --> 01:44:05.920]   But you think it's going to be 20 years before we get this sorted out?
[01:44:05.920 --> 01:44:11.920]   Well, I think that technology is not new anymore.
[01:44:11.920 --> 01:44:16.560]   In general, the idea that anything that could run on a microprocessor,
[01:44:16.560 --> 01:44:21.440]   it's involved in every aspect of our world and it's getting more complicated.
[01:44:21.440 --> 01:44:26.640]   I wrote a piece for Fast Company last year, which is one of the first in a long string
[01:44:26.640 --> 01:44:29.360]   that continues of articles about what happened to Silicon Valley?
[01:44:29.360 --> 01:44:30.720]   How did Silicon Valley go by?
[01:44:30.720 --> 01:44:32.320]   Why does everybody hate Silicon Valley now?
[01:44:32.320 --> 01:44:37.440]   Well, these articles started back in fall of last year and I wrote one of the first
[01:44:37.440 --> 01:44:38.160]   articles on that.
[01:44:38.160 --> 01:44:43.440]   And one of the points that I was making is that technology used to be so much fun.
[01:44:43.440 --> 01:44:46.720]   But at first, we were enthusiasts, we were programmers, we were builders and makers,
[01:44:46.720 --> 01:44:48.800]   and we were tinkerer and we'd mess with you.
[01:44:48.800 --> 01:44:53.120]   I remember that in the 90s, it was all about, "Oh, you can add more RAM and you can do this,
[01:44:53.120 --> 01:44:54.400]   that thing, build your own PC."
[01:44:54.400 --> 01:44:59.600]   It was all fun and then it was really fun in the 2000s because it was gadgets and smartphones
[01:44:59.600 --> 01:45:00.320]   and all this kind of stuff.
[01:45:00.320 --> 01:45:03.600]   It was just fun and we related to it on the level of fun.
[01:45:03.600 --> 01:45:07.760]   Well, we got used to all that and now we're dealing with AI, taking our jobs.
[01:45:07.760 --> 01:45:12.320]   And we're dealing with all these complicated subjects that the public just does not understand
[01:45:12.320 --> 01:45:15.360]   but is directly affected by and they feel victims of this.
[01:45:15.360 --> 01:45:20.720]   This privacy thing, building up the lion's share of what we talked about
[01:45:20.720 --> 01:45:25.920]   today probably and many of these shows, this is a huge point at which the world of technology,
[01:45:25.920 --> 01:45:30.320]   the world of Silicon Valley is directly affecting our lives and there's nothing good about it.
[01:45:30.320 --> 01:45:37.520]   And to make matters worse, all of this harvesting of personal information is all in the service
[01:45:37.520 --> 01:45:38.960]   of contextual advertising.
[01:45:38.960 --> 01:45:41.440]   Is advertising really all that contextual?
[01:45:41.440 --> 01:45:46.640]   If we were collecting all this personal data to do health research,
[01:45:46.640 --> 01:45:54.480]   to discover if cancer or to find out more about mental health issues or how we could,
[01:45:54.480 --> 01:46:00.000]   all this data that we could have done with health science, all we've managed to do is turn
[01:46:00.000 --> 01:46:01.120]   it into advertising.
[01:46:01.120 --> 01:46:06.640]   There is something very depressing about the fact that the finest minds in computer science
[01:46:06.640 --> 01:46:12.240]   aren't about solving the next process of gap, aren't about getting down to properly drilling
[01:46:12.240 --> 01:46:14.320]   down into how we build the next bits of kit.
[01:46:14.320 --> 01:46:16.240]   It's about how we can sell people stuff.
[01:46:16.240 --> 01:46:18.640]   Well, actually, I mean, I don't agree with that.
[01:46:18.640 --> 01:46:19.520]   I don't agree with that.
[01:46:19.520 --> 01:46:23.920]   I can make one quick follow-up point and sorry to trample over you just because you're not here,
[01:46:23.920 --> 01:46:24.320]   Dwight.
[01:46:24.320 --> 01:46:30.560]   It's really hard to be on that on the end of Skype because it's like we have another second
[01:46:30.560 --> 01:46:31.040]   bastard.
[01:46:31.040 --> 01:46:35.440]   But just to follow up on that point, I think all of the good things are also happening but
[01:46:35.440 --> 01:46:36.160]   we don't see it.
[01:46:36.160 --> 01:46:40.800]   There is research going on to cure cancer and to 23 and me as using all this data.
[01:46:40.800 --> 01:46:42.560]   And there's a lot of good stuff happening.
[01:46:42.560 --> 01:46:43.200]   We never see it.
[01:46:43.200 --> 01:46:44.640]   It's invisible behind the scenes.
[01:46:44.640 --> 01:46:46.080]   What is actually touching us?
[01:46:46.080 --> 01:46:49.600]   Well, data privacy, some of this other stuff, we're being tracked.
[01:46:49.600 --> 01:46:50.640]   There's this general sense.
[01:46:50.640 --> 01:46:55.280]   So I think there's a lot of good, a lot of bad that's happening, but the bad parts right now
[01:46:55.280 --> 01:46:56.480]   happen to be affecting us.
[01:46:56.480 --> 01:46:58.800]   And I'll stop talking and let you talk to Dwight.
[01:46:58.800 --> 01:47:03.600]   Well, Mike, that was exactly what I was going to say is that there is, I mean, people are using
[01:47:03.600 --> 01:47:06.880]   this data to look at ways to defeat cancer.
[01:47:06.880 --> 01:47:12.000]   People are using social media data to track epidemiology and to track diseases.
[01:47:12.000 --> 01:47:17.120]   I think it is a, there's a lot of good stuff going on there.
[01:47:17.120 --> 01:47:19.040]   This is what's in the headlines right now.
[01:47:19.040 --> 01:47:25.280]   And I also think among tech writers, there is a little guilt going on.
[01:47:25.280 --> 01:47:30.000]   You know, I was, as I know you were, like we were optimists.
[01:47:30.000 --> 01:47:31.680]   We were advocates.
[01:47:32.640 --> 01:47:42.160]   One of the proudest conversations I had was with a compact executive in the late '90s who told me
[01:47:42.160 --> 01:47:47.360]   that he thought that I was probably the person most responsible for teaching Houston how to get
[01:47:47.360 --> 01:47:49.680]   on the internet because I wrote the hell out of it.
[01:47:49.680 --> 01:47:51.600]   And that made me proud.
[01:47:51.600 --> 01:47:56.000]   But I kind of look back on that now and go, you know, what have we done?
[01:47:56.000 --> 01:47:57.600]   Yeah, you really shouldn't have done that, Dwight.
[01:47:57.600 --> 01:47:59.040]   You should have had it off the internet.
[01:47:59.040 --> 01:47:59.520]   I know.
[01:47:59.520 --> 01:48:01.120]   Well, I was being paid to.
[01:48:01.120 --> 01:48:08.480]   So it's the thing is, we were so good at the data scientists and they were at $100 billion.
[01:48:08.480 --> 01:48:15.120]   And we can't even funnel a handful of billions of, you know, we talk about Apple coming up on a
[01:48:15.120 --> 01:48:16.800]   trillion dollars out of smartphones.
[01:48:16.800 --> 01:48:20.080]   And we can't even put like $10 billion into health sciences.
[01:48:20.080 --> 01:48:20.960]   Oh, well, come on, Greg.
[01:48:20.960 --> 01:48:25.760]   I mean, Mark Zuckerberg and his wife have claimed that they've set up the the the the
[01:48:25.760 --> 01:48:32.640]   chunk of Zuckerberg Foundation, but you're the world of all known diseases in the next 20 years.
[01:48:32.640 --> 01:48:38.160]   And Greg, but you know, Greg, Greg, I would I would invite you to come to Houston and spend
[01:48:38.160 --> 01:48:42.960]   some time in the Texas Medical Center, which is one of the largest medical complexes in the world.
[01:48:42.960 --> 01:48:47.440]   There are billions being spent on medical technology.
[01:48:47.440 --> 01:48:50.480]   It's just, again, as Mike said, you don't see it.
[01:48:51.760 --> 01:48:57.680]   I've toured some of those and I've worked in the medical system over 30 years as a corporate IT
[01:48:57.680 --> 01:49:02.720]   person. And yes, there is money being spent, but it's still a fraction of what was I mean,
[01:49:02.720 --> 01:49:07.280]   there's an article in here somewhere that Facebook is now working on its own artificial
[01:49:07.280 --> 01:49:12.880]   intelligence chips. We need those chips in health sciences. Why is why is it that they're
[01:49:12.880 --> 01:49:18.800]   not being funded for that sort of technology? Why is it that an ad tech company is getting to make
[01:49:18.800 --> 01:49:22.640]   these market leading innovations instead of something useful?
[01:49:22.640 --> 01:49:27.280]   Who's to say that Facebook won't sell them to medical researchers?
[01:49:27.280 --> 01:49:31.840]   Well, they've done a little bit of an open compute project. They've actually managed to get
[01:49:31.840 --> 01:49:35.840]   some decent server designs out there out there, out on the large scale. But with something like
[01:49:35.840 --> 01:49:39.520]   that, where they're looking at the level of investment, you're looking to AI chips, they're
[01:49:39.520 --> 01:49:44.160]   they're not really going to earn that over surely. Well, you might sell it if you sell it as a
[01:49:44.160 --> 01:49:46.640]   product. I mean, that's what they do is they sell products.
[01:49:46.640 --> 01:49:48.560]   Yeah.
[01:49:48.560 --> 01:49:54.560]   According to Zuckerberg, but actually that that was actually to me the single most disturbing
[01:49:54.560 --> 01:49:58.240]   point of all that where they were talking about fake news and they were talking about all this
[01:49:58.240 --> 01:50:01.200]   kind of stuff. And Zuckerberg said they were saying, well, what are you going to do about this
[01:50:01.200 --> 01:50:03.840]   fake news? It's a real problem. What are you going to do about it? And he said, well,
[01:50:03.840 --> 01:50:08.320]   where to the point where within 10 years we'll have AI that can catch it and delete it instantly.
[01:50:08.320 --> 01:50:12.400]   And they're like, okay, that sounds great. I was like, are you kidding? That does not sound great.
[01:50:13.040 --> 01:50:16.800]   This is all going to happen invisibly behind the scenes. We don't know what was deleted or why.
[01:50:16.800 --> 01:50:21.520]   They're just going to decide what's deleted and what isn't. Some algorithm is going to decide
[01:50:21.520 --> 01:50:26.240]   that like with no record or trace of what's happened. I mean, that's a disaster.
[01:50:26.240 --> 01:50:28.640]   Yeah. I mean, coming back to what you were saying.
[01:50:28.640 --> 01:50:29.760]   No transparency.
[01:50:29.760 --> 01:50:34.880]   Yeah, no, exactly. And but just one final point, because we ended up the week on Friday with
[01:50:34.880 --> 01:50:40.080]   some quite unusual news and a bit of, you know, war of words going across line.
[01:50:40.080 --> 01:50:45.760]   When Twitter out of the blue decided that they were no longer going to carry ads for Kaspersky.
[01:50:45.760 --> 01:50:52.160]   Now we've seen the US government has already put, you know, a moratorium on Kaspersky software
[01:50:52.160 --> 01:50:57.360]   being used in the government. European governments have said, we don't have a problem with it. We
[01:50:57.360 --> 01:51:03.440]   work with them all the time. What is behind all this? Was this just Twitter in its endless quest
[01:51:03.440 --> 01:51:07.600]   to carry on losing money and not make a profit? Or is there something you should be seriously
[01:51:07.600 --> 01:51:11.120]   concerned about this about Kaspersky software and the way it works?
[01:51:11.120 --> 01:51:18.000]   Well, a lot of this, again, is politics and there may be more that we don't know behind the scenes
[01:51:18.000 --> 01:51:23.920]   of all this, but there's this association. It's the use by the Russian government and
[01:51:23.920 --> 01:51:30.560]   the Russian intelligence services of Twitter for to forward the objectives of the Putin administration
[01:51:30.560 --> 01:51:36.880]   in Russia that is generally disturbing. So on the on the most, on one end of the spectrum,
[01:51:36.880 --> 01:51:40.320]   it could be that Twitter wants to look like they're being tough on the Russians.
[01:51:40.320 --> 01:51:45.360]   And on the other end of the spectrum, there could be genuine problems with Kaspersky
[01:51:45.360 --> 01:51:50.320]   and what they're doing and they want to bump them off the network. Either way, it's not going to
[01:51:50.320 --> 01:51:55.920]   make much of a dent. I mean, it's like, you know, really how much does Kaspersky need Twitter?
[01:51:55.920 --> 01:52:00.640]   Yeah. I mean, it's it just seems slightly hypocritical, you know, and that you don't see
[01:52:00.640 --> 01:52:06.480]   I mean, the CIA's investment arm in Q tell has funded an awful lot of security companies like,
[01:52:06.480 --> 01:52:10.880]   you know, FireEye and a bunch of others. And you don't see other companies saying, well,
[01:52:10.880 --> 01:52:13.600]   they're funded by the US government. We're not going to use them. I mean,
[01:52:13.600 --> 01:52:17.920]   I'm getting a little bit sick of being told Kaspersky is a threat. Kaspersky threat.
[01:52:17.920 --> 01:52:22.640]   What's your evidence? Oh, you're just going to have to trust us on that one. And we're still
[01:52:22.640 --> 01:52:27.600]   looking for chemical weapons in Iraq. And I'm reaching the point where I'm not really
[01:52:27.600 --> 01:52:35.680]   leveled. So the scottle about around Kaspersky is there was a person. So here, let's sketch out
[01:52:35.680 --> 01:52:43.280]   a potential story that may or may not be true. There was an FBI or a CIA person who was taking
[01:52:43.280 --> 01:52:54.400]   data from classified secure data. Yeah. And as part of that process, that person had the
[01:52:54.400 --> 01:53:00.080]   machine at home was running Kaspersky. And as part of the process of Kaspersky scanning for viruses,
[01:53:00.080 --> 01:53:04.080]   it found a document in there which had a virus in it or thought it had a virus.
[01:53:04.080 --> 01:53:09.920]   And the document was then uploaded to Kaspersky servers. And they think that somebody in Kaspersky,
[01:53:09.920 --> 01:53:16.000]   who was probably an operator for the KGB or one of the or the FSB realized that this person was
[01:53:16.000 --> 01:53:21.840]   actually holding on to confidential or top secret documents and then use Kaspersky to leak that
[01:53:21.840 --> 01:53:26.800]   data, either to run a run a full blooded op to get in there and steal the computer and thus
[01:53:26.800 --> 01:53:31.920]   all the data in it. Now, this person, this employee should not have had the data at home.
[01:53:32.880 --> 01:53:36.960]   And the fact that it leaked through Kaspersky may actually be an accident. So that is,
[01:53:36.960 --> 01:53:43.920]   Kaspersky, as a company may not have been acting deliberately or intentionally as an arm of the
[01:53:43.920 --> 01:53:48.320]   Russian government. But maybe there was an operative just happened to be in the right place at the
[01:53:48.320 --> 01:53:54.640]   right time and saw what was happening. The net result is that Kaspersky ends up looking like an
[01:53:54.640 --> 01:53:58.960]   instrument of the Russian government. The Russian government is or took steps this week. Of course,
[01:53:58.960 --> 01:54:03.680]   if you want to take the reverse political play to make sure the telegram can operate. So
[01:54:03.680 --> 01:54:08.080]   they've made a decision. The courts over there have decided the telegram is a danger to the country
[01:54:08.080 --> 01:54:12.800]   and the Russian ISPs are now blocking all the IP addresses that telegram uses,
[01:54:12.800 --> 01:54:18.560]   which basically took large swabs of AWS and Google's clouds offline so that certain services
[01:54:18.560 --> 01:54:23.120]   stop working over there. So there's a lot of tit-for-tat. I don't forget that the Chinese
[01:54:23.120 --> 01:54:28.000]   government has been blocking out US services from working over their Google documents, for example.
[01:54:28.000 --> 01:54:30.560]   Google's rolled over on VPNs in China as well.
[01:54:30.560 --> 01:54:37.200]   Exactly. So it's not fair to say that the US is the one that's taking the hits here. I think
[01:54:37.200 --> 01:54:42.800]   there's an awful lot of geopolitical maneuverings going on here. Today Kaspersky is getting it in
[01:54:42.800 --> 01:54:48.400]   the neck in the US, but there's hundreds of other movements going along. We saw the Cisco this week.
[01:54:48.400 --> 01:54:56.800]   There was a joint announcement from UK's GCHQ and the NSA in the US and the DOD in Australia,
[01:54:56.800 --> 01:55:02.720]   highlighting the fact that Cisco routers have no invulnerability and that there are actors
[01:55:02.720 --> 01:55:07.440]   believed to be state actors, Russian and Chinese actors, who are actually implanting those routers
[01:55:07.440 --> 01:55:13.120]   to hold them as potential staging points for future compromises and sort of pleading with
[01:55:13.120 --> 01:55:17.680]   operators to get out there and patch these systems so that those implants can be removed
[01:55:17.680 --> 01:55:23.520]   from in the network. So this whole security issue, this is why I'm not at RSA because this sort of
[01:55:23.520 --> 01:55:28.720]   stuff doesn't get talked about at RSA. And that's the real security issue is that 300,000 routers
[01:55:28.720 --> 01:55:35.040]   out there are now open to a remote code exploit, single packet, hammer it, you've got yourself,
[01:55:35.040 --> 01:55:39.600]   you own the router, you can then use the router to configure a GRE tunnel and snuff in the traffic
[01:55:39.600 --> 01:55:43.200]   off. If you know what you're looking for, you can send the traffic off and then capture it and
[01:55:43.200 --> 01:55:48.000]   then do what you want with it or you can pop the router and wipe it, take it out like big sways
[01:55:48.000 --> 01:55:53.120]   of the Iran ISPs went down when somebody went in there and popped all the routers and wiped them
[01:55:53.120 --> 01:55:58.560]   all out. And also, I mean, as we saw with Slingshot, when you've got access to the router, who's the
[01:55:58.560 --> 01:56:03.280]   person that goes in and configures the router? That's the IT admin and they are the golden ticket
[01:56:03.280 --> 01:56:08.080]   if you're trying to hack an envelope, get full admin access for your administrator and then job
[01:56:08.080 --> 01:56:12.480]   done. I mean, Dwight, what's your take on this? I mean, do you would you trust Russian software on
[01:56:12.480 --> 01:56:19.200]   your computer or is it a do you think it's it's overblown? I think I want to see more evidence. I'm
[01:56:19.200 --> 01:56:27.280]   also just as skeptical of the US government's attempt to make sure people don't use ZTE and
[01:56:27.280 --> 01:56:35.200]   Huawei and other Chinese products. You know, you keep hearing from the feds that there are
[01:56:35.200 --> 01:56:40.080]   issues and you shouldn't trust it. But I have yet to see any technical discussion or any technical
[01:56:40.080 --> 01:56:46.000]   proof that there are indeed back doors in any of these products. There may be and certainly,
[01:56:46.560 --> 01:56:53.040]   you know, the Chinese government has has that history, but I have not seen any technical
[01:56:53.040 --> 01:56:57.440]   proof of it unless I've missed it. Mike, have you seen anything on this?
[01:56:57.440 --> 01:57:07.520]   No, not proof, not smoking gun proof. But I do think that governments and agencies tend to suspect
[01:57:07.520 --> 01:57:12.960]   that their rivals do the very things that they in fact do. And you can sometimes tell what
[01:57:12.960 --> 01:57:16.400]   spy agencies are doing by what they're accusing others of doing. So remember,
[01:57:16.400 --> 01:57:21.840]   few years ago, the NSA was caught intercepting laptops that had been ordered abroad. They were
[01:57:21.840 --> 01:57:27.680]   intercepting the package. Stalling stuff inside of the laptops, repackaging them, shipping them off
[01:57:27.680 --> 01:57:33.520]   with Amazon's full support as well. But this is the kind of thing that the US government is
[01:57:33.520 --> 01:57:40.000]   accusing ZTE and Huawei of doing. And it may be because they are doing something like that,
[01:57:40.000 --> 01:57:45.120]   it may be because they might possibly be doing something like that, or maybe because the US
[01:57:45.120 --> 01:57:48.960]   has done something like that and figures, well, they ought to be doing it if they're not.
[01:57:48.960 --> 01:57:53.840]   So we can't take any chances. And in any event, it's good to sort of swag down. They're more
[01:57:53.840 --> 01:58:00.560]   concerned about ZTE and Huawei's telecommunications equipment, not their phones. ZTE's troubles
[01:58:00.560 --> 01:58:06.240]   are something unrelated to that whole issue, which is the Iran, you know, violating the Iran
[01:58:06.240 --> 01:58:09.600]   sanctions and so on. But yeah, I don't know.
[01:58:09.600 --> 01:58:15.600]   AT&T at the time said we're pressured to stop by the US government to not sell those phones.
[01:58:15.600 --> 01:58:18.880]   And you know, AT&T walked away from a deal. They were just about to close.
[01:58:18.880 --> 01:58:24.000]   Yeah. Yeah. Huawei got quite heavily hammered on that one. And we also had the announcement
[01:58:24.000 --> 01:58:28.320]   today with this week with the Block on ZTE, which has actually hit some American companies
[01:58:28.320 --> 01:58:31.920]   quite hard. I mean, Qualcomm have got other markets, but one of the other companies,
[01:58:31.920 --> 01:58:38.320]   and they sell their stock prices go down by third. It's really bad. I've heard some
[01:58:38.320 --> 01:58:42.560]   reports that ZTE is actually the number three smartphone vendor in the United States.
[01:58:42.560 --> 01:58:49.440]   They hit the very, very low end. They're an Android Go partner within the US and so on. But
[01:58:49.440 --> 01:58:57.040]   it's still not clear, A, whether they'll be able to get around the sanctions somehow,
[01:58:57.840 --> 01:59:02.640]   around Android, Google and ZTE are working together to figure that out. But even more,
[01:59:02.640 --> 01:59:07.040]   something that people aren't talking about enough is that they may not be able to update
[01:59:07.040 --> 01:59:12.960]   current phones. It's possible that they will be blocked from actually giving security updates
[01:59:12.960 --> 01:59:18.080]   to the millions of ZTE phones owned by Americans right now. So this is a, this is a real question
[01:59:18.080 --> 01:59:21.440]   that has to be resolved. And I hope that it's resolved in a way that that's going to leave a
[01:59:21.440 --> 01:59:25.600]   swamp of infected phones out there just spreading that stuff around everyone else.
[01:59:26.160 --> 01:59:33.440]   Now, there's also some business issues here. If you figure that by just while we in ZTE are two
[01:59:33.440 --> 01:59:39.040]   of the most aggressive competitors in the technology space, and if they've now been frozen out of
[01:59:39.040 --> 01:59:44.080]   the US market, which is fine, the government can, and the people can make that decision,
[01:59:44.080 --> 01:59:48.560]   then that leaves what those companies now aggressively competing in Europe.
[01:59:48.560 --> 01:59:54.000]   So if you're a US multinational who's already losing ground in China, now all of a sudden,
[01:59:54.000 --> 01:59:59.040]   your European market is going to start to wither away because the Chinese people are going to go,
[01:59:59.040 --> 02:00:05.760]   sorry, the Chinese firms are going to latch on to Europe. So, and the US economy will now,
[02:00:05.760 --> 02:00:12.320]   may suffer as the US companies say, well, you know, we're the only last people standing,
[02:00:12.320 --> 02:00:17.120]   there's no competitors here. So we'll raise our prices and not worry about innovation and not
[02:00:17.120 --> 02:00:22.000]   worry about advancing the product cycle. And then over in Europe, we're buying the same technology
[02:00:22.000 --> 02:00:27.280]   for half the price and the competing against the US companies. And, you know, we get the best of
[02:00:27.280 --> 02:00:32.080]   all the bet, all of those worlds. There's an argument to be made here that this actually has
[02:00:32.080 --> 02:00:38.960]   long-term impacts on US companies where if they, by kicking out while we in ZTE actually leaves Europe
[02:00:38.960 --> 02:00:45.120]   gaining the benefit of those vendors and their technology and leaving the US vendors in second
[02:00:45.120 --> 02:00:51.040]   place. I would say the US, I mean, certainly comes to mobile phones, then, you know, it's the
[02:00:51.040 --> 02:00:56.320]   China does seem to be, you know, really, obviously most mobile phones are made in China, but the
[02:00:56.320 --> 02:01:02.240]   Chinese brands, how is that to you? They seem to be coming on because they aren't going for the same
[02:01:02.240 --> 02:01:05.680]   market that Apple's going for coming back to what we were talking about at the start of the show.
[02:01:05.680 --> 02:01:09.280]   They're going for the low cost, easy to use, you know, and-
[02:01:09.280 --> 02:01:14.960]   Oh, no, for both of these things I was talking about is 5G. So both while we in ZTE are doing
[02:01:14.960 --> 02:01:21.680]   5G networks, while we've got routers and switches and wireless solutions and servers and storage
[02:01:21.680 --> 02:01:27.360]   arrays, as well as smartphones. So while we as a $50 billion a year, 50 billion turnover a year
[02:01:27.360 --> 02:01:33.040]   company, and it's not just smartphones, it's right across the board of technology. ZTE is one of the
[02:01:33.040 --> 02:01:38.560]   biggest telco suppliers in the world today. And that's why companies like Sienna took such a hit
[02:01:38.560 --> 02:01:43.440]   when they got penalized by the US government. It kind of makes you feel that it wouldn't be
[02:01:43.440 --> 02:01:46.560]   nice to go back to the old days when Nokia was handling all this stuff because
[02:01:46.560 --> 02:01:51.920]   Nokia and Ericsson, because everyone trusts, you know, the Swedes and the Finns, but no one
[02:01:51.920 --> 02:01:56.960]   trusts the Chinese and the US. That's right. So where do we go from here? That's right. It's
[02:01:56.960 --> 02:02:02.240]   very complicated in the sense. But you know, if you say to, if you pull the competition out
[02:02:02.240 --> 02:02:07.040]   against the US companies, do the US companies maintain their pace of innovation, maintain their
[02:02:07.040 --> 02:02:13.280]   push and their momentum? Can they come to Europe? And then all of a sudden, when they get to Europe,
[02:02:13.280 --> 02:02:16.720]   they're competing in a completely different market. They've got to compete against the Chinese
[02:02:16.720 --> 02:02:21.520]   makers and the Chinese vendors and their products and their aggressive pricing.
[02:02:21.520 --> 02:02:26.080]   And then all of a sudden, they may start to lose ground in Europe. And then the US companies
[02:02:26.080 --> 02:02:30.320]   start to pull back to just the US. And then you hope you will go back to where we were in the 80s
[02:02:30.320 --> 02:02:37.440]   and the 90s, where US telecoms was, you know, arguably the least best technology in the world.
[02:02:37.440 --> 02:02:44.240]   I think the biggest change will happen. The rise of the Chinese smartphone vendors is the demise
[02:02:44.240 --> 02:02:49.920]   of Samsung as a smartphone vendor. I think Apple will be okay. You think Samsung's going to come
[02:02:49.920 --> 02:02:54.640]   straight on chips because they've actually cracked the single digit nanometer processing in a way
[02:02:54.640 --> 02:02:58.480]   that Intel still can't manage to do chips and all kinds of other components as well. There's a lot
[02:02:58.480 --> 02:03:03.200]   of profit in that. And if they can maintain their lead in the components business and also keep their
[02:03:03.200 --> 02:03:09.280]   foot in the global smartphone, you go around the world, you go to the African continent,
[02:03:09.280 --> 02:03:15.520]   and it's all Samsung. It used to be. And now increasingly that's being taken over by Chinese
[02:03:15.520 --> 02:03:23.200]   companies. But in terms of the market, mindshare in Africa, half of the billboards that you see
[02:03:23.200 --> 02:03:29.120]   in a lot of African countries are for smartphones and 95% of those are Samsung. They spend a fortune
[02:03:29.120 --> 02:03:37.440]   to market Samsung phones globally. So I think Samsung is in a world heard. I don't think Apple
[02:03:37.440 --> 02:03:42.720]   will be okay. And Google will probably be okay. They're not dominant now, but I think they'll
[02:03:42.720 --> 02:03:48.160]   slowly rise in their position. So I think we're facing a world that, yeah, will be US and China.
[02:03:48.160 --> 02:03:55.280]   And I think the days where it was the Swedes, the Finns and the Canadians dominating the world
[02:03:55.280 --> 02:04:00.400]   phone market with BlackBerry, I don't think we're returning to that.
[02:04:00.400 --> 02:04:04.720]   No, I mean, BlackBerry is essentially a patent monetization company. Now Nokia got killed by
[02:04:04.720 --> 02:04:09.120]   Microsoft in the worst possible way. And well, also because they drop the ball on the market.
[02:04:09.120 --> 02:04:16.160]   Alcatel is going nowhere. It does seem like it's China robust at the moment.
[02:04:16.160 --> 02:04:21.520]   Well, I mean, Nokia and Ericsson are still very strong in the 5G market and still hoping to make
[02:04:21.520 --> 02:04:29.600]   substantial revenues in that market. And they remain the strongest players in the 5G market today,
[02:04:29.600 --> 02:04:36.880]   although ZTE is very much the third wheel there. And Qualcomm also has a lot of patents and stuff
[02:04:36.880 --> 02:04:40.640]   like that around the 5G technology. So it's going to be interesting to think about this
[02:04:40.640 --> 02:04:45.920]   in terms of that dynamic as the technology rolls out around the world. Maybe you end up like back
[02:04:45.920 --> 02:04:51.040]   where we were in the 2000s where, you know, the US, all the US technology was built by Qualcomm and
[02:04:51.040 --> 02:04:57.200]   then outside of it was all done by Nokia and Ericsson for 5G. And the question now, of course,
[02:04:57.200 --> 02:05:01.600]   China's arrived and you've got ZTE handling the Asia Pacific and the Chinese regions.
[02:05:01.600 --> 02:05:07.600]   Maybe that's the way it's going to pan out and it's going to go back to a sort of local technology
[02:05:07.600 --> 02:05:12.800]   for local solutions. Well, this is it. I mean, and Dwight, I mean, you were born
[02:05:12.800 --> 02:05:17.280]   away. You sort of you've been in the heart of compact and seen that blow up and then die down.
[02:05:17.280 --> 02:05:17.760]   Oh, yeah.
[02:05:17.760 --> 02:05:21.280]   We're going to say the same sort of thing, the same sort of thing occurring when it comes to the
[02:05:21.280 --> 02:05:27.600]   mobile sphere. Well, you know, the comment about the local companies doing local solutions,
[02:05:27.600 --> 02:05:32.800]   that's kind of what the nationalist movement wants. You know, they want everybody kind of off in their
[02:05:32.800 --> 02:05:39.440]   own in their own ring. And, you know, I'm not sure that you could put the genie back in the bottle.
[02:05:39.440 --> 02:05:45.200]   I think that they're that they're going to try. The other thing is, is I'm curious as to just how
[02:05:45.200 --> 02:05:51.360]   much the blocking of these Chinese vendors in the United States is a function of the current
[02:05:51.360 --> 02:05:57.760]   administration. You know, you may have a change in administrations in 2020 and things may change.
[02:05:57.760 --> 02:06:03.760]   But it comes at a bad time as as we mentioned because of the 5G rollout. These companies are
[02:06:03.760 --> 02:06:08.640]   very much involved in it. So I think initially, at least for the next four years, I think we're
[02:06:08.640 --> 02:06:13.200]   going to see everybody kind of off in their own silo. Yeah, it looks it's going to be looking that
[02:06:13.200 --> 02:06:18.880]   way. Well, thank you very much for everyone for appearing. Mike, you're now the traveling tech
[02:06:18.880 --> 02:06:23.760]   reporter and go on. Once the next what's the next stop for you? That's right. So the next thing,
[02:06:23.760 --> 02:06:27.840]   so just to feel if you haven't heard about what we do, my wife and I, it's mostly her business,
[02:06:27.840 --> 02:06:32.640]   but we both participate. It's called the Gastronomat Experiences. So what we do is we go to an
[02:06:32.640 --> 02:06:37.600]   amazing food place and we live together in a big beautiful house for about a week. And we do
[02:06:37.600 --> 02:06:42.480]   amazing, we take cooking classes, we learn to make cheese, we learn to make and taste wine, we do
[02:06:42.480 --> 02:06:46.240]   all this kind of stuff. So the next ones are the Prosecco Experience in Northern Italy,
[02:06:46.240 --> 02:06:51.280]   about an hour north of Venice in May 21st. And then after that, the Provence Experience,
[02:06:51.280 --> 02:06:56.400]   which is June 26th, again, for about a week. Now here's what we're doing. These are fully booked,
[02:06:56.400 --> 02:07:02.800]   both of them. But we will make room for a couple, two people, if they are a Twit Army
[02:07:02.800 --> 02:07:09.360]   member. So it's we have a potential reserve spot in each of these, one couple for each,
[02:07:09.360 --> 02:07:16.480]   but only if you're a Twit audience member. And because we love the Twit Army, we absolutely do.
[02:07:16.480 --> 02:07:20.960]   And so I recommend that people go to gastronomat.net/experiences.
[02:07:20.960 --> 02:07:27.040]   Or go to gastronomat.net and just click on the experiences link and check it out. If you want to
[02:07:27.040 --> 02:07:32.400]   have the foodie adventure of a lifetime, definitely should join us. And again, this is for Twit Army
[02:07:32.400 --> 02:07:38.160]   people and we'd love to have. If you want to be doing the food experience, then yeah,
[02:07:38.160 --> 02:07:44.480]   the way to go. And it's full of secrets, but I would just promise that it'll be the greatest
[02:07:44.480 --> 02:07:49.200]   experience of your life. Excellent. You should come, in fact. Well, I've just come back from
[02:07:49.200 --> 02:07:53.440]   Europe, but next time I'm over, I definitely shall. And Greg, you can all the panelists are all
[02:07:53.440 --> 02:07:58.720]   the panelists eligible. Yeah, absolutely. As long as you've listened to Twit shows.
[02:07:58.720 --> 02:08:03.520]   Oh, but come on, Dwight, could you honestly give up the joys of barbecue and huge stakes?
[02:08:05.040 --> 02:08:13.440]   You have a point. Yeah. Actually, I love food. I would love to go to the Prosecco one, just sounds
[02:08:13.440 --> 02:08:17.600]   awesome. I love food from that region. So in particularly the wine. So I would love to do that.
[02:08:17.600 --> 02:08:20.400]   Excellent. Well, thank you very much, Dwight Silverman from Houston Chronicle,
[02:08:20.400 --> 02:08:25.200]   runner of the tech burger site. And as you said, we've been in the tech sphere for
[02:08:25.200 --> 02:08:31.680]   since 1990, which I guess puts you in it longer than some of our listeners. But I got the same
[02:08:31.680 --> 02:08:35.040]   sort of feeling when I got my RSA badge and found out it was a 20 year veteran this year.
[02:08:35.040 --> 02:08:42.240]   It catches up on us all. And finally, what's, I'm sorry. I made the comment earlier about
[02:08:42.240 --> 02:08:46.960]   kind of feeling guilty. But, you know, I was away from doing this for a while and I'm back
[02:08:46.960 --> 02:08:55.360]   covering tech and it's it remains a joy. And by the way, I want to say, I've done a lot of
[02:08:55.360 --> 02:09:01.280]   this week in tech episodes. This easily has been one of the best and the most interesting and the
[02:09:01.280 --> 02:09:06.000]   most robust. You've done a great job Ian. Oh, thank you very much. I think it's down to the
[02:09:06.000 --> 02:09:11.360]   panelists more than those. Yes. But yes, and Greg also you've had a Friday afternoon,
[02:09:11.360 --> 02:09:16.800]   the pub enjoying Britain's unseasonably glorious weather. Can you see my tan? Can you see my tan?
[02:09:16.800 --> 02:09:22.480]   Oh, yeah. But come on. I mean, you know, we're naturally British. Our natural color is pale blue
[02:09:22.480 --> 02:09:27.120]   and it takes a week to get white. Greg, your skin is rose gold and your hair is space gray.
[02:09:27.120 --> 02:09:34.400]   You look like an happy user. Ian, you did a great job today. It's been great. Thanks so much for
[02:09:34.400 --> 02:09:38.880]   inviting me. And if people would like to find me, you can find me on Twitter. Is that a theory
[02:09:38.880 --> 02:09:44.480]   on mind? And if you're an IT infrastructure nerd like me, I have a pat you can head on over to
[02:09:44.480 --> 02:09:50.640]   packet pushes.net, which is our podcast channel where we punch out really nerdy, really deep
[02:09:50.640 --> 02:09:54.720]   content on enterprise IT and cloud infrastructure. We'd love to see you over there.
[02:09:54.720 --> 02:09:59.120]   Well worth listening to. I know I certainly sort of, it's certainly on my download list. But
[02:09:59.120 --> 02:10:04.160]   there it is. Another Twitter is in the bag, another weekend technology gone by and some good
[02:10:04.160 --> 02:10:09.040]   robust discussion and not a little after on the show. And we'll hope you join us for next week
[02:10:09.040 --> 02:10:14.160]   where we Becky Woolley will be hosting the show until Leo gets back. But in the meantime, have an
[02:10:14.160 --> 02:10:15.040]   excellent week.
[02:10:15.040 --> 02:10:25.040]   [Music]

