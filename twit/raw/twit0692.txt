;FFMETADATA1
title=Ravioli for the Recount
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=692
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:01.480]   It's time for Twent This Week in Tech.
[00:00:01.480 --> 00:00:05.040]   Our Veterans Day Episode 1111 2018,
[00:00:05.040 --> 00:00:11.040]   the 100th anniversary of Armistice in World War I, 1111 1918.
[00:00:11.040 --> 00:00:14.640]   And thank you to all of our veterans for your service.
[00:00:14.640 --> 00:00:15.680]   We won't forget.
[00:00:15.680 --> 00:00:16.840]   We appreciate it.
[00:00:16.840 --> 00:00:19.480]   Our show today features Lisa Schmeiser, editor at IT Pro
[00:00:19.480 --> 00:00:22.000]   today, Wesley Faulkner, whose developer relations advocate
[00:00:22.000 --> 00:00:26.880]   at IBM, and Mike Asargent of iMore and Chihuahua.coffee.
[00:00:26.880 --> 00:00:28.960]   We'll talk about the new Apple hardware
[00:00:28.960 --> 00:00:32.640]   and what it all means Samsung's folding display.
[00:00:32.640 --> 00:00:37.080]   Why people don't trust Mark Zuckerberg, but do trust Oprah.
[00:00:37.080 --> 00:00:37.840]   And hold on more.
[00:00:37.840 --> 00:00:39.600]   It's all coming up next on Twent.
[00:00:39.600 --> 00:00:44.680]   Netcast you love.
[00:00:44.680 --> 00:00:46.040]   From people you trust.
[00:00:46.040 --> 00:00:51.320]   This is Twent.
[00:00:51.320 --> 00:00:54.320]   This is Twent.
[00:00:54.320 --> 00:01:06.320]   This Week in Tech, episode 692, recorded Sunday, November 11, 2018.
[00:01:06.320 --> 00:01:08.320]   Ravioli for the recount.
[00:01:08.320 --> 00:01:11.320]   This Week in Tech is brought to you by ExpressVPN.
[00:01:11.320 --> 00:01:13.320]   Protect your online activity today.
[00:01:13.320 --> 00:01:16.320]   For an extra three months free with a one year package,
[00:01:16.320 --> 00:01:19.320]   go to expressvpn.com/twent.
[00:01:19.320 --> 00:01:21.320]   And by Robinhood.
[00:01:21.320 --> 00:01:24.320]   An investing app that lets you buy and sell stocks, ETFs, options,
[00:01:24.320 --> 00:01:27.320]   and crypto, commission-free.
[00:01:27.320 --> 00:01:31.320]   Sign up at twit2.robinhood.com for a free stock, like Apple,
[00:01:31.320 --> 00:01:34.320]   forward or sprint, to help you build your portfolio.
[00:01:34.320 --> 00:01:36.320]   And by Ring.
[00:01:36.320 --> 00:01:40.320]   Ring's alarm security kit is a smarter way to protect your entire home.
[00:01:40.320 --> 00:01:44.320]   Go to ring.com/twit to learn how you can get whole home security
[00:01:44.320 --> 00:01:46.320]   for only $10 a month.
[00:01:46.320 --> 00:01:51.320]   And by FreshBooks, the ridiculously easy to use cloud accounting software
[00:01:51.320 --> 00:01:54.320]   that helps small business owners thrive.
[00:01:54.320 --> 00:01:59.320]   Try it free for 30 days at freshbooks.com/twit.
[00:01:59.320 --> 00:02:05.320]   It's time for Twent this Week in Tech, the show where we cover the week's tech news.
[00:02:05.320 --> 00:02:08.320]   We're the best tech journalist in the business.
[00:02:08.320 --> 00:02:14.320]   From Windows IT Pro, ladies and gentlemen, I give you, actually, sorry, IT Pro today.
[00:02:14.320 --> 00:02:16.320]   Let's get the name right, Lisa.
[00:02:16.320 --> 00:02:19.320]   Come on, Lisa Schmeiser, editor of IT Pro today.
[00:02:19.320 --> 00:02:20.320]   Hey, hello, Lisa.
[00:02:20.320 --> 00:02:21.320]   Hi, it's nice to be back.
[00:02:21.320 --> 00:02:22.320]   Nice to see you.
[00:02:22.320 --> 00:02:23.320]   Welcome.
[00:02:23.320 --> 00:02:25.320]   In town.
[00:02:25.320 --> 00:02:28.320]   But everybody else is on Skype.
[00:02:28.320 --> 00:02:32.320]   Wesley Faulkner is all the way in Austin, Texas, where he works in developer relations.
[00:02:32.320 --> 00:02:35.320]   He's developer relations avocado at IBM.
[00:02:35.320 --> 00:02:37.320]   It's good to see you.
[00:02:37.320 --> 00:02:38.320]   Good to be here.
[00:02:38.320 --> 00:02:39.320]   Thanks for having me.
[00:02:39.320 --> 00:02:44.320]   Congratulations.
[00:02:44.320 --> 00:02:52.320]   Thank you.
[00:02:52.320 --> 00:02:59.320]   Thank you.
[00:02:59.320 --> 00:03:06.320]   Welcome to the show.
[00:03:06.320 --> 00:03:09.320]   The new iMac is here.
[00:03:09.320 --> 00:03:12.320]   It's so pretty.
[00:03:12.320 --> 00:03:16.320]   It looks like the old iMac.
[00:03:16.320 --> 00:03:18.320]   This one's a really old one.
[00:03:18.320 --> 00:03:21.320]   We used to use these by the dozen.
[00:03:21.320 --> 00:03:23.320]   We've got several still left.
[00:03:23.320 --> 00:03:24.320]   The new iMac.
[00:03:24.320 --> 00:03:26.320]   This is so much like the old iMac, though.
[00:03:26.320 --> 00:03:32.320]   They're in server farms and they need the button to be the same spot as before.
[00:03:32.320 --> 00:03:35.320]   That Mac mini is bigger than the other Mac mini.
[00:03:35.320 --> 00:03:37.320]   So why are we still calling it mini?
[00:03:37.320 --> 00:03:38.320]   That's like Mac medium.
[00:03:38.320 --> 00:03:40.320]   This was the old Mac mini, but it was this is thinner.
[00:03:40.320 --> 00:03:41.320]   Ah, I see.
[00:03:41.320 --> 00:03:42.320]   It's thinner.
[00:03:42.320 --> 00:03:44.320]   It's like they squished it down.
[00:03:44.320 --> 00:03:48.320]   Yeah, it's like a it's like a Samoa after you've been keeping your back pocket for a couple of days.
[00:03:48.320 --> 00:03:52.320]   There's a marshmallow that they've toasted and squished down a little bit.
[00:03:52.320 --> 00:03:53.320]   I think he's your beautiful.
[00:03:53.320 --> 00:03:57.320]   They announced new Mac book airs, which look a lot like the old Mac book airs.
[00:03:57.320 --> 00:03:59.320]   Actually, I kind of like it for that reason.
[00:03:59.320 --> 00:04:02.320]   Both this and the Mac mini, the Mac cook air and the Mac mini.
[00:04:02.320 --> 00:04:03.320]   I feel like it's old home week.
[00:04:03.320 --> 00:04:04.320]   I feel good about that.
[00:04:04.320 --> 00:04:08.320]   I don't want things to change too much.
[00:04:08.320 --> 00:04:10.320]   You know, you said it looks good.
[00:04:10.320 --> 00:04:13.320]   The new Mac or looks the same, but if you're looking at it,
[00:04:13.320 --> 00:04:17.320]   it's not going to feel the same because it's got that new retina display.
[00:04:17.320 --> 00:04:18.320]   Oh, what is it like that?
[00:04:18.320 --> 00:04:20.320]   Yeah, finally, finally, finally.
[00:04:20.320 --> 00:04:24.320]   It's about time like the Mac book air used to be the computer that I would say.
[00:04:24.320 --> 00:04:34.320]   If someone comes up to me and says, I want to get an Apple laptop and all they do, you know, is email and normal everyday stuff.
[00:04:34.320 --> 00:04:36.320]   I didn't have a computer to recommend to them for a while.
[00:04:36.320 --> 00:04:38.320]   I was like, do you think you could get by with an iPad?
[00:04:38.320 --> 00:04:43.320]   But now that the Mac book air is back, I'm happy that that's there so I can say this is the one you should get.
[00:04:43.320 --> 00:04:45.320]   Kind of is the Mac for the rest of us, I think.
[00:04:45.320 --> 00:04:51.320]   And I was concerned because they're using a Y processor, a slower processor, but after using it for a few days now,
[00:04:51.320 --> 00:04:53.320]   I got to guess mine on a Thursday.
[00:04:53.320 --> 00:04:55.320]   I feel it's fast enough.
[00:04:55.320 --> 00:04:57.320]   Does the price not bother you though?
[00:04:57.320 --> 00:04:58.320]   Oh, okay.
[00:04:58.320 --> 00:05:00.320]   Let's say this right up front.
[00:05:00.320 --> 00:05:04.320]   If money is a concern, you shouldn't be buying any Apple product at all.
[00:05:04.320 --> 00:05:06.320]   Right?
[00:05:06.320 --> 00:05:10.320]   In fact, I mentioned this on Mac break weekly.
[00:05:10.320 --> 00:05:14.320]   It's free level error was somewhat.
[00:05:14.320 --> 00:05:17.320]   Yeah, you can get an iPad now at 3.29.
[00:05:17.320 --> 00:05:18.320]   So, okay, we'll leave that out.
[00:05:18.320 --> 00:05:23.320]   But any of the new stuff, it's really for rich folks.
[00:05:23.320 --> 00:05:25.320]   And I know people who are willing to pay a design premium.
[00:05:25.320 --> 00:05:27.320]   I don't feel great about that.
[00:05:27.320 --> 00:05:32.320]   I feel like it used to be that was their tagline, the computer for the rest of us.
[00:05:32.320 --> 00:05:34.320]   It's not the computer for the rest of us if you've got bank.
[00:05:34.320 --> 00:05:39.320]   Yeah, but when I was the computer for the rest of us, the idea that they were selling then was this is a computer
[00:05:39.320 --> 00:05:43.320]   where you don't have to know programming to make sense of the interface and the applications.
[00:05:43.320 --> 00:05:44.320]   It was never cheap.
[00:05:44.320 --> 00:05:48.320]   In fact, I bought, I went to Macy's because I couldn't afford the first time Mac,
[00:05:48.320 --> 00:05:49.320]   charged it to my Macy's car.
[00:05:49.320 --> 00:05:50.320]   It was $2,500.
[00:05:50.320 --> 00:05:51.320]   It was never cheap.
[00:05:51.320 --> 00:05:58.320]   No, but the idea was computer for the rest of us was drawing a very bright line between people who did computer related things for living
[00:05:58.320 --> 00:06:02.320]   versus people who were going to use a computer to do non-computing things,
[00:06:02.320 --> 00:06:05.320]   either recreationally or for a living.
[00:06:05.320 --> 00:06:09.320]   But now I would argue that they charge the prices because they can.
[00:06:09.320 --> 00:06:10.320]   You get away with it?
[00:06:10.320 --> 00:06:16.320]   And we've also had nearly 20 years of teaching people that design is a premium worth paying for.
[00:06:16.320 --> 00:06:24.320]   When it comes to consumer goods, people pay money to think that what they're using has been designed well and thoughtfully and beautifully.
[00:06:24.320 --> 00:06:25.320]   I just noticed.
[00:06:25.320 --> 00:06:27.320]   You're using the old Mac book here.
[00:06:27.320 --> 00:06:28.320]   Yeah, I'm cheap.
[00:06:28.320 --> 00:06:29.320]   I don't upgrade to all that.
[00:06:29.320 --> 00:06:32.320]   Still designed well though, right?
[00:06:32.320 --> 00:06:34.320]   You know, it's funny.
[00:06:34.320 --> 00:06:37.320]   I liken the new Mac book here to mom's home cooking.
[00:06:37.320 --> 00:06:45.320]   Maybe you could get a more gourmet dinner out, but this is what you, since 2008...
[00:06:45.320 --> 00:06:48.320]   On the reporter, I don't need a lot of processing power.
[00:06:48.320 --> 00:06:50.320]   I don't edit video.
[00:06:50.320 --> 00:06:55.320]   I don't edit a lot of files with a lot of data, and I'm not a gamer.
[00:06:55.320 --> 00:06:58.320]   So I don't need a machine that's souped up.
[00:06:58.320 --> 00:07:03.320]   I could probably comfortably use this until it gets to the point where Apple releases an operating system that's not compatible.
[00:07:03.320 --> 00:07:04.320]   Right.
[00:07:04.320 --> 00:07:06.320]   I should also add, I'm still using my...
[00:07:06.320 --> 00:07:09.320]   Oh my God, it hurts my eyes just to see it.
[00:07:09.320 --> 00:07:10.320]   What number is that?
[00:07:10.320 --> 00:07:11.320]   It's a 5S.
[00:07:11.320 --> 00:07:13.320]   It's the smallest thing I've ever seen.
[00:07:13.320 --> 00:07:14.320]   I'm still using...
[00:07:14.320 --> 00:07:15.320]   How do you live?
[00:07:15.320 --> 00:07:17.320]   Because I use it as a phone.
[00:07:17.320 --> 00:07:18.320]   That's it.
[00:07:18.320 --> 00:07:19.320]   Oh, well, that's the problem.
[00:07:19.320 --> 00:07:20.320]   I haven't used my iPhone.
[00:07:20.320 --> 00:07:21.320]   No, actually.
[00:07:21.320 --> 00:07:22.320]   You've always called them, actually.
[00:07:22.320 --> 00:07:24.320]   I also use this when I'm reporting because I can use it to...
[00:07:24.320 --> 00:07:25.320]   To record.
[00:07:25.320 --> 00:07:27.320]   I can use it for recording and things like that.
[00:07:27.320 --> 00:07:29.320]   You wouldn't want to take notes on that.
[00:07:29.320 --> 00:07:30.320]   I do.
[00:07:30.320 --> 00:07:31.320]   I can just...
[00:07:31.320 --> 00:07:32.320]   Leo is the side himself.
[00:07:32.320 --> 00:07:33.320]   Leo is the side himself.
[00:07:33.320 --> 00:07:34.320]   And I have to require to do it.
[00:07:34.320 --> 00:07:36.320]   But, I mean, look, this is how I've set up...
[00:07:36.320 --> 00:07:37.320]   The horror, the horror.
[00:07:37.320 --> 00:07:39.320]   At least you're safe from any helium releases.
[00:07:39.320 --> 00:07:40.320]   Yeah.
[00:07:40.320 --> 00:07:42.320]   By the way, that does not work.
[00:07:42.320 --> 00:07:44.320]   We tried to kill my iPhone.
[00:07:44.320 --> 00:07:45.320]   I was very brave.
[00:07:45.320 --> 00:07:46.320]   I sacrificed.
[00:07:46.320 --> 00:07:47.320]   I put an iPhone in an...
[00:07:47.320 --> 00:07:48.320]   Oh, yeah.
[00:07:48.320 --> 00:07:50.320]   Samsung Note 9 in a bag of helium.
[00:07:50.320 --> 00:07:52.320]   And they refused to die, damn it.
[00:07:52.320 --> 00:07:54.320]   But yeah, this is how I've set up my home screen is because I want...
[00:07:54.320 --> 00:07:56.320]   Oh, that's so pretty.
[00:07:56.320 --> 00:07:57.320]   You don't have any...
[00:07:57.320 --> 00:07:58.320]   By the way, this thing is hot.
[00:07:58.320 --> 00:07:59.320]   You don't...
[00:07:59.320 --> 00:08:01.320]   It's working hard to display that.
[00:08:01.320 --> 00:08:03.320]   You don't have any icons on there.
[00:08:03.320 --> 00:08:06.320]   You just have a notepad, reminders, messages.
[00:08:06.320 --> 00:08:08.320]   You don't even have a phone icon on it.
[00:08:08.320 --> 00:08:10.320]   No, because I don't call people much.
[00:08:10.320 --> 00:08:14.320]   But the point is, I cleared off my screen to remind me to spend less time on my phone anyway.
[00:08:14.320 --> 00:08:15.320]   This is actually kind of nice.
[00:08:15.320 --> 00:08:16.320]   Wow.
[00:08:16.320 --> 00:08:17.320]   Okay, I kind of like that.
[00:08:17.320 --> 00:08:18.320]   She's got a river running through it.
[00:08:18.320 --> 00:08:19.320]   Yeah, that's...
[00:08:19.320 --> 00:08:20.320]   That's...
[00:08:20.320 --> 00:08:21.320]   Bernie Falls.
[00:08:21.320 --> 00:08:22.320]   I went hiking there this past summer.
[00:08:22.320 --> 00:08:23.320]   That's pretty.
[00:08:23.320 --> 00:08:24.320]   So I have a there to remind me to get outdoors too.
[00:08:24.320 --> 00:08:27.320]   Is that the same as the Palm Phone?
[00:08:27.320 --> 00:08:29.320]   Oh, I had an early Palm Phone.
[00:08:29.320 --> 00:08:31.320]   I want one of these.
[00:08:31.320 --> 00:08:34.320]   This is the new hotness.
[00:08:34.320 --> 00:08:37.320]   All your apps are able to fit in that one folder stack then.
[00:08:37.320 --> 00:08:38.320]   Yeah, they do.
[00:08:38.320 --> 00:08:39.320]   That's incredible.
[00:08:39.320 --> 00:08:40.320]   Well, I also...
[00:08:40.320 --> 00:08:42.320]   And this is where you all just like, kill over and shock.
[00:08:42.320 --> 00:08:44.320]   It's only a 16 megabyte phone.
[00:08:44.320 --> 00:08:47.320]   Okay, I gotta go.
[00:08:47.320 --> 00:08:48.320]   I gotta get out of here.
[00:08:48.320 --> 00:08:50.320]   Just put that next to this phone.
[00:08:50.320 --> 00:08:53.320]   So it's been great because it forces me to actually just pare down the apps.
[00:08:53.320 --> 00:08:56.320]   And keep the ones I'm going to use regularly.
[00:08:56.320 --> 00:08:58.320]   This is the new iPhone Tennis Max.
[00:08:58.320 --> 00:09:00.320]   Oh my gosh, I want it so precious.
[00:09:00.320 --> 00:09:02.320]   Oh, it's adorable.
[00:09:02.320 --> 00:09:04.320]   It's so tiny.
[00:09:04.320 --> 00:09:05.320]   I know.
[00:09:05.320 --> 00:09:08.320]   It looks like the remote control for my phone.
[00:09:08.320 --> 00:09:12.320]   The remote control.
[00:09:12.320 --> 00:09:13.320]   Yeah.
[00:09:13.320 --> 00:09:14.320]   Holy cow.
[00:09:14.320 --> 00:09:16.320]   But you know, also as a reporter, one of the things...
[00:09:16.320 --> 00:09:19.320]   But you didn't pay $1250 for that either.
[00:09:19.320 --> 00:09:22.320]   But you know, one of the nice things about actually using lagging is
[00:09:22.320 --> 00:09:25.320]   actually using lagging edge tech on a regular basis too.
[00:09:25.320 --> 00:09:27.320]   But you can touch with the people, the little people.
[00:09:27.320 --> 00:09:30.320]   Well, I wouldn't say little people, but I think what it does is it helps
[00:09:30.320 --> 00:09:36.320]   keep computing in context outside of my job bucket, if that makes sense.
[00:09:36.320 --> 00:09:37.320]   Right.
[00:09:37.320 --> 00:09:38.320]   It's smart.
[00:09:38.320 --> 00:09:44.320]   And I wish I could do that, but I think I have to be in touch with the rich early adopters.
[00:09:44.320 --> 00:09:45.320]   Those are your people.
[00:09:45.320 --> 00:09:46.320]   Those are my people.
[00:09:46.320 --> 00:09:49.320]   Who will speak for the rich early adopters?
[00:09:49.320 --> 00:09:51.320]   Yeah, somebody has to speak for them.
[00:09:51.320 --> 00:09:55.320]   So the truth is the thing that was most interesting.
[00:09:55.320 --> 00:09:57.320]   And by the way, this is not new.
[00:09:57.320 --> 00:09:59.320]   This was announced two weeks ago, but they finally came this week.
[00:09:59.320 --> 00:10:01.320]   And so we were able to play with them.
[00:10:01.320 --> 00:10:07.320]   The thing that really, I think is most interesting is Apple is releasing a Mac mini and a Macbook
[00:10:07.320 --> 00:10:13.320]   air that are very much kind of just a evolutionary upgrade on the existing products, kind of giving
[00:10:13.320 --> 00:10:17.320]   people what they wanted without changing, even changing the design substantially.
[00:10:17.320 --> 00:10:22.320]   And then they gave us the computer from the future, which is the iPad Pro.
[00:10:22.320 --> 00:10:26.320]   And this thing is not this year's computer.
[00:10:26.320 --> 00:10:28.320]   It's probably not even next year's computer.
[00:10:28.320 --> 00:10:30.320]   This feels like the computer from 2029.
[00:10:30.320 --> 00:10:35.320]   It's really futuristic and partly because of the chip in here.
[00:10:35.320 --> 00:10:40.320]   And I think this is where you really look at Apple, what Apple's doing with the A12, in this case,
[00:10:40.320 --> 00:10:43.320]   the A12X for the iPad.
[00:10:43.320 --> 00:10:52.320]   And Intel's way behind, seven nanometer, eight core GPU, four high power, four low power,
[00:10:52.320 --> 00:10:57.320]   although if necessary, Apple said all eight of them can kick in, which means this thing has
[00:10:57.320 --> 00:10:58.320]   huge overhead.
[00:10:58.320 --> 00:11:03.320]   It's got seven GPU chips, seven GPU cores in here.
[00:11:03.320 --> 00:11:07.320]   It has its own neural processing chip.
[00:11:07.320 --> 00:11:12.320]   This is a great, by the way, conversation on ours, Technica.
[00:11:12.320 --> 00:11:14.320]   It turns out a non, now we know what a non is doing.
[00:11:14.320 --> 00:11:21.320]   A non from a non tech is now at Apple and gave the demonstration and the explanation of what's going on
[00:11:21.320 --> 00:11:23.320]   with this A1210.
[00:11:23.320 --> 00:11:25.320]   Also, don't forget about the T2.
[00:11:25.320 --> 00:11:27.320]   The T210, there's another chip in there.
[00:11:27.320 --> 00:11:30.320]   There's a T2 security chip, which does a whole lot more than that.
[00:11:30.320 --> 00:11:32.320]   It does sound processing.
[00:11:32.320 --> 00:11:37.320]   It runs the storage, so you don't have to put a disk storage card on there.
[00:11:37.320 --> 00:11:45.320]   So in all the new Macs, plus the iPads, the T2 gives you super fast disk performance.
[00:11:45.320 --> 00:11:51.320]   It's really interesting what Apple's doing, and that is also an Apple designed chip.
[00:11:51.320 --> 00:11:54.320]   But a number of people have written it, and I have to concur.
[00:11:54.320 --> 00:11:59.320]   I started with a Neelite Patel at the Verge, but I've seen many others write this.
[00:11:59.320 --> 00:12:03.320]   I really liked, who was it that wrote?
[00:12:03.320 --> 00:12:08.320]   I think a kind of a critique of the iPad Pro is the software.
[00:12:08.320 --> 00:12:17.320]   It isn't anywhere near sophisticated enough for this processor, for this chip.
[00:12:17.320 --> 00:12:23.320]   You have this amazing screen, you have this new user interface, you have so much hotness in here.
[00:12:23.320 --> 00:12:25.320]   I'm being absolutely sincere.
[00:12:25.320 --> 00:12:32.320]   This thing is such a mind-blowing piece of hardware, and it's running on essentially a blown up iPhone operating system.
[00:12:32.320 --> 00:12:38.320]   They talk about how the iOS is sort of it coddles its users.
[00:12:38.320 --> 00:12:47.320]   It is hugging the array of tens, if you will, and it's just making, it's meant to be simple and easy to use.
[00:12:47.320 --> 00:12:53.320]   So literally, I was about to ask you, as you're talking about all these awesome things that the iPad does,
[00:12:53.320 --> 00:12:56.320]   what is the most powerful thing that you've done on that device since you've gotten it?
[00:12:56.320 --> 00:12:58.320]   Well, it's great for watching Netflix.
[00:12:58.320 --> 00:13:02.320]   Exactly. It's crazy.
[00:13:02.320 --> 00:13:03.320]   It is disappointing.
[00:13:03.320 --> 00:13:10.320]   Craig Mod on his blog, Craig Mod.com, says the new iPad Pro is a computer from the future with software from yesterday.
[00:13:10.320 --> 00:13:16.320]   I couldn't agree more, and I think that the more and more people are playing with it, they're realizing that.
[00:13:16.320 --> 00:13:23.320]   Jason Snell told us yesterday that there was a rumor that there were many more features left out of iOS 12,
[00:13:23.320 --> 00:13:31.320]   designed to make the iPad more of a real computer, and that will come maybe in iOS 13.
[00:13:31.320 --> 00:13:42.320]   And I should point out, if there's things you do, like photo editing, that work on this, this is an amazing device.
[00:13:42.320 --> 00:13:44.320]   There's a great article here.
[00:13:44.320 --> 00:13:46.320]   I've got to find all these articles.
[00:13:46.320 --> 00:13:50.320]   Iceland iPad Pro.
[00:13:50.320 --> 00:13:59.320]   There's a great article by AustinMan, AustinMan.com, talking about taking the iPad Pro to Iceland and using it exclusively for editing
[00:13:59.320 --> 00:14:09.320]   and saying, "Yes, my pictures look different," edited on the iPad Pro, but this is a much more effective artistic expression for me,
[00:14:09.320 --> 00:14:14.320]   using the pencil, the iPad Pro, and Lightroom CC to edit.
[00:14:14.320 --> 00:14:18.320]   He says it's a powerhouse workflow that is ultra portable.
[00:14:18.320 --> 00:14:22.320]   I can't help but feel like they're catching up with the Surface Mindshare.
[00:14:22.320 --> 00:14:23.320]   Maybe.
[00:14:23.320 --> 00:14:27.320]   Because Surface has had pencils for a while.
[00:14:27.320 --> 00:14:38.320]   I mean, Apple has too, but Microsoft has been very aggressive with their evangelizing to let you see how you can use the surface
[00:14:38.320 --> 00:14:43.320]   both for office contacts or for coding or for more creative work.
[00:14:43.320 --> 00:14:51.320]   They've done a great job of positioning it as a machine that will help you get things done and is also much more versatile than a laptop.
[00:14:51.320 --> 00:14:53.320]   That's an interesting point.
[00:14:53.320 --> 00:14:55.320]   I'm sitting in front of a Surface Studio with a pen.
[00:14:55.320 --> 00:14:59.320]   I do use that pen and it is a giant screen.
[00:14:59.320 --> 00:15:04.320]   It's almost like the next iPad should be a surface like a Surface Studio.
[00:15:04.320 --> 00:15:10.320]   But I feel like that's an interesting point because there it is a desktop operating system on iPad like hardware.
[00:15:10.320 --> 00:15:15.320]   Microsoft has been moving towards that though with a lot of their universal Windows applications.
[00:15:15.320 --> 00:15:26.320]   They've been trying very hard to build a user experience where you can move from your desktop computer to your laptop to your surface tablet and back again.
[00:15:26.320 --> 00:15:28.320]   So maybe that's my mistake.
[00:15:28.320 --> 00:15:30.320]   Maybe this isn't the computer of the future.
[00:15:30.320 --> 00:15:32.320]   I should have just bought a Surface Pro instead of an iPad.
[00:15:32.320 --> 00:15:34.320]   It depends on the rest of the system.
[00:15:34.320 --> 00:15:43.320]   Microsoft is always ahead of the curve too far ahead of their time. They've had tablets forever and it took a while and took someone else to be able to bring it mainstream.
[00:15:43.320 --> 00:15:46.320]   Bill Gates was a big believer in tablets 20 years ago.
[00:15:46.320 --> 00:15:53.320]   Yeah, so I think the pen, if it comes on a Microsoft then wait five years and then come out with it again and be new.
[00:15:53.320 --> 00:15:54.320]   The pencil.
[00:15:54.320 --> 00:15:58.320]   Okay, the Apple pencil though is better than the Microsoft pen.
[00:15:58.320 --> 00:16:00.320]   Right, because they learn from the mistakes.
[00:16:00.320 --> 00:16:04.320]   The pioneers, they get the arrows in the back.
[00:16:04.320 --> 00:16:08.320]   So everyone learns about what's the future.
[00:16:08.320 --> 00:16:14.320]   And if you look at what's that project, the folding Microsoft thing that never came out.
[00:16:14.320 --> 00:16:17.320]   I'm supposed to come out.
[00:16:17.320 --> 00:16:22.320]   It was called Courier and then it was called Andromeda and now it's called the Samsung.
[00:16:22.320 --> 00:16:25.320]   Yeah, folding phone.
[00:16:25.320 --> 00:16:40.320]   They're learning a lot from their labs and I think that they are releasing things when they think that it's good enough for them and not thinking about smart people or not so smart people or finger out a way to transition between those.
[00:16:40.320 --> 00:16:41.320]   Interesting.
[00:16:41.320 --> 00:16:43.320]   I left Microsoft out.
[00:16:43.320 --> 00:16:45.320]   I probably shouldn't have.
[00:16:45.320 --> 00:16:47.320]   Well, one of the things I don't want to use Windows.
[00:16:47.320 --> 00:16:48.320]   I have the Surface Go.
[00:16:48.320 --> 00:16:51.320]   I have a Surface Studio as you can see.
[00:16:51.320 --> 00:16:55.320]   But it's running Windows which to me doesn't feel as elegant.
[00:16:55.320 --> 00:16:59.320]   Well, one of the things I've noticed about Microsoft is they use that they eat their own dog food.
[00:16:59.320 --> 00:17:03.320]   Everything that they release to the public, they use internally first.
[00:17:03.320 --> 00:17:07.320]   And on the one hand, it's great because they've got a use pool in place.
[00:17:07.320 --> 00:17:18.320]   But on the other hand, I think it may create an effect sometimes where because it works for them, they may not be the awareness that the rest of the world hasn't had the same learning curve at the same speed.
[00:17:18.320 --> 00:17:24.320]   For example, they have been using workplace metrics on their office software now for a couple of years.
[00:17:24.320 --> 00:17:25.320]   It's working great for them.
[00:17:25.320 --> 00:17:38.320]   It's helped them figure out time management and move them towards this new idea they're pushing out which is that they want to eliminate multitasking and introduce people to the idea of just flow.
[00:17:38.320 --> 00:17:45.320]   See, that's part of the problem I have with the iPad is that basically, no matter what you're doing, and I know, don't write me, I know there's multitasking.
[00:17:45.320 --> 00:17:47.320]   But basically, you're doing one thing at a time.
[00:17:47.320 --> 00:17:48.320]   Yeah.
[00:17:48.320 --> 00:17:55.320]   But basically, the point is Microsoft has been told they've been overhauling their own culture and how they work internally.
[00:17:55.320 --> 00:17:56.320]   They've now baked it into their products.
[00:17:56.320 --> 00:17:57.320]   You don't get the feeling.
[00:17:57.320 --> 00:18:01.320]   They're going to release it to the wild, but I don't, like Wesley said, it's a little bit ahead of its time.
[00:18:01.320 --> 00:18:04.320]   I'm not sure it's going to be something that people are like, "Oh, thank goodness.
[00:18:04.320 --> 00:18:11.320]   I now have terrifying metrics that tell me exactly how much time I spend emailing somebody and how many hours a week I spend in meetings.
[00:18:11.320 --> 00:18:13.320]   And what am I supposed to do with this?
[00:18:13.320 --> 00:18:18.320]   We're not quite there yet, but people who have been eating the dog food for a couple of years, they're there."
[00:18:18.320 --> 00:18:29.320]   Yeah, it says, "Microsoft left a psychology out of technology so they can figure out how to do things that work good for them, but they do not factor in the rest of the population."
[00:18:29.320 --> 00:18:32.320]   Is that a marketing problem more than anything else?
[00:18:32.320 --> 00:18:33.320]   No.
[00:18:33.320 --> 00:18:40.320]   It's a smart people and a smart culture who, it's a reinforcing feedback loop, if that makes sense.
[00:18:40.320 --> 00:18:45.320]   Well, is it the problem that Silicon Valley has always had, which is engineers designed for engineers?
[00:18:45.320 --> 00:18:46.320]   Oh, no, they've got a great UI.
[00:18:46.320 --> 00:18:47.320]   Okay.
[00:18:47.320 --> 00:18:55.320]   I think, again, the thing is, is there's a big difference between designing something that works for a culture internally versus one that's going to work for a larger market.
[00:18:55.320 --> 00:19:08.320]   Well, to use a different metaphor, in the '90s, you could always tell when a website was really poorly designed when it reflected the internal structure of a company, rather than the customer facing things people want to do in a website.
[00:19:08.320 --> 00:19:21.320]   And so when you're looking at how products get developed, sometimes it doesn't hurt to ask, does this product just reflect the company culture that they have, or does this actually reflect to know where in this of who their customers are and what their customers want?
[00:19:21.320 --> 00:19:26.320]   It's ironic because Microsoft seems to be leaving desktop computing behind.
[00:19:26.320 --> 00:19:28.320]   No, they're very clear about that.
[00:19:28.320 --> 00:19:30.320]   They're very clear that we're in a post.
[00:19:30.320 --> 00:19:31.320]   We're in a post...
[00:19:31.320 --> 00:19:33.320]   It's all about the cloud now.
[00:19:33.320 --> 00:19:46.320]   Remember, Satya Nodel's first thing was mobile first cloud first, and then they moved to the idea of digital transformation, which is the notion that computing is all about the digital information that you either create or you manipulate or you extract value from.
[00:19:46.320 --> 00:19:49.320]   And now what they're moving into is...
[00:19:49.320 --> 00:20:01.320]   Now they're trying to push you to a post-app environment, too, where the idea is not so much you open this app, this app, and this app to do your job, but you identify your task flow, and then they seamlessly integrate with each other so that you don't have to switch between them.
[00:20:01.320 --> 00:20:02.320]   Yeah.
[00:20:02.320 --> 00:20:04.320]   I don't know if I trust that guy.
[00:20:04.320 --> 00:20:23.320]   It sounds cool in theory, but I still have the file system on iOS, I think, is an example of this whole idea that you have a task that you want to complete, and so it doesn't matter where your files are, it doesn't matter where this is or what app you're using.
[00:20:23.320 --> 00:20:50.320]   You just use tags to make sure everything's organized how you want it. Yeah, I don't like that. And maybe that's the difference between still being in that area where we've got holdovers from the way that we've done computing for so long, whereas maybe my youngest sibling where he's not thinking so much in terms of apps and thinking in terms of this idea where it's like workflows that you follow.
[00:20:50.320 --> 00:20:56.320]   It might make more sense to him, but I don't know, I'm just I'm stuck in my ways. That's terrifying to me.
[00:20:56.320 --> 00:21:08.320]   Michael, you're not even 30. No, but as long as I've been using computers, this is like your digital native, right? You grew up. You've always had the internet. You've always had computers.
[00:21:08.320 --> 00:21:19.320]   I've had I've had dial up. I've had dial up. I guess that doesn't count. Yeah. Yeah. Like I started on your brother. Your younger brother's digital native. Oh, yeah, he's abs. Yeah. And that's what I'm talking about.
[00:21:19.320 --> 00:21:34.320]   Like the difference between where I still use computers like everybody else does versus he using computers. Like he would perhaps fit better into that new way of things that you're talking about there.
[00:21:34.320 --> 00:21:43.320]   That's what I often wonder is that maybe I'm trying to shoehorn an iPad experience into my previous experience of desktop computing.
[00:21:43.320 --> 00:21:51.320]   And to some degree, by the way, Microsoft also does that. And maybe there is a new paradigm of computing that does make sense.
[00:21:51.320 --> 00:22:08.320]   Can I roll out a theory? Yes. Roll out a theory. So you I think it was you hit the nail on the hell head when you said that it's the hardware is way ahead of its time before the OS because my theory is that the iPad Pro is the development platform
[00:22:08.320 --> 00:22:30.320]   platform for the next era of computing. And they need something more powerful for where they're going rather than something that fits the needs of today. It feels like that feels like and if you look at what they're doing with their processors, the T2 trip, they're continuously getting closer and closer to controlling everything that's needed for something radical to happen.
[00:22:30.320 --> 00:22:53.320]   And if you look at people didn't touch on this when they changed their reporting structure for their financials, saying they will not break down individual units, they probably are going to release something that's very radical, their future that won't sell very well, but will be disguised in terms of how well or how well it's doing.
[00:22:53.320 --> 00:23:04.320]   So I have to do it. Now I got to wrap my mind around this one. Actually, Apple did that. There's a history of doing that. The Macintosh did not sell well. The Lisa really didn't sell well. Sorry, Lisa.
[00:23:04.320 --> 00:23:17.320]   I'm used to it. But they clearly reinvented computing. And in fact, Apple may be in that exact same stage they were at when they had the conferences at Apple II forever.
[00:23:17.320 --> 00:23:33.320]   We'll never abandon the Apple II. Meanwhile, here's the Macintosh. Forget the Apple II. And they did shortly after kill the Apple II. Maybe they're in that transition phase. One thing we probably do know is that this is almost the end of the line for Intel and Apple.
[00:23:33.320 --> 00:23:59.320]   They've got this. It's pretty clear when you look at what's going on in this A12X bionic that they've leapfrogged and tell dramatically. And because they're designing chips for their own operating systems and their own environments, they can, instead of making a general purpose chip, they can make a chip that is tuned to work as well as possible the existing hardware and operating system.
[00:23:59.320 --> 00:24:17.320]   And if you look at the T2, it's an accelerator. When you break it down, it's a cryptography accelerator. It's an encoder accelerator. So anything that wherever their bionic chip falls short, they can just accelerate into the T2 and keep iterating there separately and still be able to
[00:24:17.320 --> 00:24:34.320]   stay ahead of the curb. If a new technology comes out, there's just rapid into the T2 without breaking their development of their bionic processor. They did say that the iPad Pro is faster than 92% of all laptops sold this year.
[00:24:34.320 --> 00:24:35.320]   Wow.
[00:24:35.320 --> 00:24:49.320]   I mean, you've got a thing. iOS 13 has to have. I mean, because we saw that when I was like a point release where we saw a lot of fun stuff happen for iPad where the multitasking improved and all that kind of thing.
[00:24:49.320 --> 00:25:04.320]   And so maybe, I don't know if it'll be a point release, but in the next iteration of iOS completely, we'll see another one of those things happen where our iPad gets, you know, a whole lot more features that like Jason Snell was talking about.
[00:25:04.320 --> 00:25:16.320]   Because, yeah, right now it does feel like you've got this incredibly powerful vehicle that you can, I don't know, like go underwater and fly through the sky.
[00:25:16.320 --> 00:25:24.320]   But right now, those features like aren't available to you. You can't turn those on. So you get to the water and it stops you. You don't get to go underwater.
[00:25:24.320 --> 00:25:32.320]   And it seems like when you can look at this thing and go, well, it's faster than all of these computers and it can do this and it can do that.
[00:25:32.320 --> 00:25:39.320]   But then you go to the App Store and you look for something that uses even a third of that processing power.
[00:25:39.320 --> 00:25:50.320]   It's hard to find anything that does that. Even folks that have been doing, you know, video editing and audio editing and things like that on the iPad, they've been able to do that just fine with the devices that are out there, right?
[00:25:50.320 --> 00:26:01.320]   Or, you know, with the devices that have been available so far. So now we've got this incredible machine and it doesn't feel like we've given it anything to stretch its legs with.
[00:26:01.320 --> 00:26:04.320]   It feels like a super fast Netflix machine.
[00:26:04.320 --> 00:26:13.320]   So Wesley, do you have a thought about what this new product that Apple might be thinking about will look like?
[00:26:13.320 --> 00:26:22.320]   Well, if you, sorry, I harp on this so much, but if you look at the T2 chip, this, I think it's a big key that no one is spending too much time on.
[00:26:22.320 --> 00:26:28.320]   It is the hybridization of their processors and Intel processors, if you think about it.
[00:26:28.320 --> 00:26:42.320]   So more and more functions and their desktops will be moved over to the T2 or their laptops to the point where the processor does just the bare minimum and then they'll switch over and replace Intel processors.
[00:26:42.320 --> 00:26:49.320]   And so the reason why I was saying that the iPad makes sense, that makes sense. That's a natural transition.
[00:26:49.320 --> 00:27:08.320]   But it sounded like you were also saying that maybe there's also a device in here that is neither desktop, laptop or iPad. There's some sort of new kind of device they're envisioning.
[00:27:08.320 --> 00:27:12.320]   So the iPad itself has a USB C port.
[00:27:12.320 --> 00:27:13.320]   Right.
[00:27:13.320 --> 00:27:19.320]   And we've been playing with in all sorts of ways. We were able to get video out of it.
[00:27:19.320 --> 00:27:24.320]   We're able to, it's got data, it's can charge, it can charge in both directions.
[00:27:24.320 --> 00:27:31.320]   It can import camera right now, but it can't talk to an external hard drive yet.
[00:27:31.320 --> 00:27:33.320]   But that's a driver issue. Can't talk about keyboard.
[00:27:33.320 --> 00:27:38.320]   That's a driver issue. Apple's chosen not to support that but could easily.
[00:27:38.320 --> 00:28:02.320]   And so what I think that the iPad Pro's development platform is because they are plugging in either external accelerators or external devices like the keyboard, but think of a keyboard within, they have a keyboard with a trackpad or some other interface that can be expandable, which means you can retrofit your old iPad to be whatever their new computing paradigm is.
[00:28:02.320 --> 00:28:06.320]   I don't know, that's augment reality with the camera or whatever.
[00:28:06.320 --> 00:28:23.320]   And that will come out with some sort of desktop replacement or laptop replacement that will have all that built in and then say, "Hey, all of everything with the USB C port, now you can be upgraded into whatever this new thing is."
[00:28:23.320 --> 00:28:37.320]   You know, Steven Sonofsky who was kicked out at Microsoft, he was in charge of Windows 8 and which was kind of a mess, but he has, but at the same time I think he's a smart guy.
[00:28:37.320 --> 00:28:44.320]   Yeah, he's a smart guy. I think he was given an impossible task, which was also this kind of difficult transition from desktop to tablet computing.
[00:28:44.320 --> 00:28:51.320]   They did a weird hybrid that didn't, nobody wanted, and I think they've come, by the way, come out of it pretty well as we were just talking about.
[00:28:51.320 --> 00:28:55.320]   I think Windows 10 on a Surface Pro is... They had to skip Windows 9.
[00:28:55.320 --> 00:29:04.320]   Yeah, but Sonofsky says it's a mistake for people to focus on replacing laptops with iPads.
[00:29:04.320 --> 00:29:16.320]   He also thinks that it's the next generation that these iPads are aimed at, a generation that's never going to want to connect external storage to a device that lives in the cloud.
[00:29:16.320 --> 00:29:20.320]   This is the thing is how we compute is changing.
[00:29:20.320 --> 00:29:21.320]   Right.
[00:29:21.320 --> 00:29:22.320]   So...
[00:29:22.320 --> 00:29:29.320]   Historically difficult though for a company to throw a dart ahead five years and say that's where we want to be.
[00:29:29.320 --> 00:29:41.320]   I mean, IBM made typewriters at one point. They've made computers. Companies can and will deal with successive layers of technology as people change what they're doing in the workplace.
[00:29:41.320 --> 00:29:52.320]   It seems like what we're doing now is we're trying to, like you say, throw a dart for five years and say, "The people who have grown up in a swiping tactile world, what are they going to ask for when they hit the workplace?"
[00:29:52.320 --> 00:29:56.320]   I mean, you can be like, "In the future, everyone has Ironman gloves. We don't know."
[00:29:56.320 --> 00:29:58.320]   It's hard for me.
[00:29:58.320 --> 00:30:07.320]   And five years, don't forget in five years, we all have to change computing paradigms anyway because we will be moving towards a unified memory paradigm.
[00:30:07.320 --> 00:30:08.320]   So there's no RAM.
[00:30:08.320 --> 00:30:11.320]   Well, wait a minute. Slow down, buddy. What the hell are you talking about?
[00:30:11.320 --> 00:30:12.320]   Yeah, what's that?
[00:30:12.320 --> 00:30:13.320]   Right.
[00:30:13.320 --> 00:30:16.320]   I know you work at IBM, but for those of us who don't, would you explain that?
[00:30:16.320 --> 00:30:19.320]   I understood Ironman gloves, but I don't know what this means.
[00:30:19.320 --> 00:30:23.320]   You mean there's not going to be a station with storage in RAM? Is that what you're saying?
[00:30:23.320 --> 00:30:24.320]   Right.
[00:30:24.320 --> 00:30:29.320]   It means that large storage will get fast and fast storage to achieve.
[00:30:29.320 --> 00:30:32.320]   So that you basically the same.
[00:30:32.320 --> 00:30:38.320]   So you won't find, you won't look at a phone or a laptop and say, "How much RAM does it have and how much storage does it have?"
[00:30:38.320 --> 00:30:45.320]   It'll be just one number where your operating system at your storage for your data have to live together.
[00:30:45.320 --> 00:30:50.320]   And so that takes a whole other way of approaching an operating system, memory management and storage.
[00:30:50.320 --> 00:30:54.320]   And we're getting closer and closer and closer.
[00:30:54.320 --> 00:30:57.320]   And so everything has to change when that happens.
[00:30:57.320 --> 00:31:02.320]   Is this the opt-on, the 3D RAM that...
[00:31:02.320 --> 00:31:07.320]   No, no. That's inefficient, but it's also not affordable.
[00:31:07.320 --> 00:31:09.320]   That's like RAM bus.
[00:31:09.320 --> 00:31:11.320]   It's the RAM bus of our generation.
[00:31:11.320 --> 00:31:13.320]   Right, exactly.
[00:31:13.320 --> 00:31:14.320]   Yeah.
[00:31:14.320 --> 00:31:18.320]   So I'm not saying when it's going to happen, but five years sounds reasonable.
[00:31:18.320 --> 00:31:28.320]   And if you look at, there's research where IBM was able to change the magnetism of a single atom,
[00:31:28.320 --> 00:31:38.320]   where it takes like 100,000 atoms for regular storage, you can see how you can really dramatically increase the density of memory.
[00:31:38.320 --> 00:31:42.320]   And when you can make things smaller, you can also make them cheaper.
[00:31:42.320 --> 00:31:43.320]   And faster.
[00:31:43.320 --> 00:31:44.320]   Yeah.
[00:31:44.320 --> 00:31:45.320]   Okay.
[00:31:45.320 --> 00:31:46.320]   Well, cheaper.
[00:31:46.320 --> 00:31:47.320]   Okay, boy.
[00:31:47.320 --> 00:31:52.320]   Well, cheaper always changes the nature of computing too, because when you think about when cell phones were expensive,
[00:31:52.320 --> 00:31:54.320]   very few people had the menus them.
[00:31:54.320 --> 00:32:01.320]   But when Apple and other companies persuaded carriers to underwrite the cost of cell phones,
[00:32:01.320 --> 00:32:04.320]   and they became mobile smartphones, they became cheaper for a while.
[00:32:04.320 --> 00:32:05.320]   Yeah.
[00:32:05.320 --> 00:32:06.320]   And they were ubiquitous.
[00:32:06.320 --> 00:32:07.320]   They became ubiquitous.
[00:32:07.320 --> 00:32:10.320]   And that changed computing because that's what nudged us into a mobile-first model.
[00:32:10.320 --> 00:32:14.320]   People like my phone is a hard drive, and it's also something that connects me to the Internet.
[00:32:14.320 --> 00:32:15.320]   This is basically a tiny computer.
[00:32:15.320 --> 00:32:22.320]   Is Apple smart enough to be able to predict the future and skate to where the puck is going, as it were?
[00:32:22.320 --> 00:32:32.320]   So, I have a slightly heretical perspective in that I don't think Apple is a computing company so much as I think they're a consumer company
[00:32:32.320 --> 00:32:34.320]   whose focus is computing products.
[00:32:34.320 --> 00:32:35.320]   I don't think Apple's--
[00:32:35.320 --> 00:32:36.320]   Or a fashion company.
[00:32:36.320 --> 00:32:41.320]   Yeah, I don't think Apple should be considered in the same category as Microsoft or IBM.
[00:32:41.320 --> 00:32:42.320]   Yeah.
[00:32:42.320 --> 00:32:44.320]   Or a company that offers technical services and goods.
[00:32:44.320 --> 00:32:46.320]   The A12X is innovative technology.
[00:32:46.320 --> 00:32:47.320]   Yeah.
[00:32:47.320 --> 00:32:48.320]   Right?
[00:32:48.320 --> 00:32:50.320]   The T2 is innovative technology.
[00:32:50.320 --> 00:32:52.320]   But they don't sell people on the technology.
[00:32:52.320 --> 00:32:56.320]   They sell people on the experience or they sell people on the consumer goods.
[00:32:56.320 --> 00:32:58.320]   Well, that's just good marketing.
[00:32:58.320 --> 00:32:59.320]   Yeah.
[00:32:59.320 --> 00:33:00.320]   But that's--
[00:33:00.320 --> 00:33:01.320]   Make great technology, then sell them on the experience.
[00:33:01.320 --> 00:33:02.320]   That's what Steve Jobs always did.
[00:33:02.320 --> 00:33:08.320]   But again, you know, we consider and talk processor speed and storage and things like that.
[00:33:08.320 --> 00:33:09.320]   I can--
[00:33:09.320 --> 00:33:11.320]   Apple knows real people about care.
[00:33:11.320 --> 00:33:12.320]   Exactly.
[00:33:12.320 --> 00:33:15.320]   Most people who walk into an Apple store are not here because they're like, "I really crave
[00:33:15.320 --> 00:33:16.320]   a faster processor."
[00:33:16.320 --> 00:33:21.320]   What they want is they're like, "I want something that will let me post to the gram," or, "I
[00:33:21.320 --> 00:33:25.200]   want something that will let me take notes in a meeting," and I can rely on it being
[00:33:25.200 --> 00:33:28.360]   a good user experience that seamlessly interlocks with all of the other things in my hardware
[00:33:28.360 --> 00:33:29.360]   ecosystem.
[00:33:29.360 --> 00:33:30.360]   But doesn't the one inform the other?
[00:33:30.360 --> 00:33:37.760]   I mean, doesn't hire faster, cheaper technology, then make it possible to do what normal people
[00:33:37.760 --> 00:33:38.760]   want to do better?
[00:33:38.760 --> 00:33:39.760]   No?
[00:33:39.760 --> 00:33:40.760]   They're not related?
[00:33:40.760 --> 00:33:43.560]   They have to kind of break it out where user experience makes or breaks something.
[00:33:43.560 --> 00:33:49.000]   For example, Apple didn't set out to kill the mid-market digital camera market, but it
[00:33:49.000 --> 00:33:52.440]   did because it was easier to pull out your phone and take a photo than it was to carry
[00:33:52.440 --> 00:33:55.360]   on a phone and a $600 digital camera.
[00:33:55.360 --> 00:33:59.800]   It's only a geek who says this iPad has all this power but doesn't live up to it because
[00:33:59.800 --> 00:34:02.040]   most people just go, "Well, it either works for me or not."
[00:34:02.040 --> 00:34:05.240]   They're not thinking about the T2 chip or the H1.
[00:34:05.240 --> 00:34:07.240]   Oh, give me that T2 chip, won't you?
[00:34:07.240 --> 00:34:08.240]   I'm not here for it.
[00:34:08.240 --> 00:34:10.080]   You have anything with a T2 in it.
[00:34:10.080 --> 00:34:15.240]   I think that in the larger tech industry as a whole though, we're looking at companies
[00:34:15.240 --> 00:34:17.920]   that are effectively, you can put them in a bucket and be like, "Oh, they all trade
[00:34:17.920 --> 00:34:18.920]   on Nasdaq."
[00:34:18.920 --> 00:34:25.080]   But Apple is in no way the same type of company as a Microsoft, as a Google, as an IBM, or
[00:34:25.080 --> 00:34:27.240]   oh, God, I'm trying to think of it.
[00:34:27.240 --> 00:34:29.520]   Does that give them an advantage?
[00:34:29.520 --> 00:34:30.800]   It depends on how you're targeting.
[00:34:30.800 --> 00:34:33.960]   I mean, Apple's not going to be able to go into the enterprise and take it over right
[00:34:33.960 --> 00:34:34.960]   now.
[00:34:34.960 --> 00:34:35.960]   They could if they wanted to.
[00:34:35.960 --> 00:34:36.960]   They could if they wanted to.
[00:34:36.960 --> 00:34:37.960]   They're the most valuable company in the world right now.
[00:34:37.960 --> 00:34:38.960]   Right now, yeah.
[00:34:38.960 --> 00:34:43.320]   Boy, this segment was food for thought.
[00:34:43.320 --> 00:34:46.680]   You've completely rocked my world.
[00:34:46.680 --> 00:34:52.760]   I mean, I'm still stuck on the Ironman gloves, obviously.
[00:34:52.760 --> 00:34:53.760]   Yeah.
[00:34:53.760 --> 00:34:57.120]   So, this is, and this is just, but what's interesting, and again, I have the benefit of being around
[00:34:57.120 --> 00:35:02.560]   short people an awful lot, but they're primary method for interfacing with a computer is
[00:35:02.560 --> 00:35:03.560]   swiping.
[00:35:03.560 --> 00:35:04.560]   Yeah.
[00:35:04.560 --> 00:35:05.560]   It's very tactile.
[00:35:05.560 --> 00:35:06.560]   It's very physical.
[00:35:06.560 --> 00:35:10.000]   I can't help but think of a generation that's raised on Minecraft, which is all about building
[00:35:10.000 --> 00:35:11.760]   things in 3D.
[00:35:11.760 --> 00:35:13.160]   And they're used to swiping.
[00:35:13.160 --> 00:35:14.160]   They're used to tactile.
[00:35:14.160 --> 00:35:17.680]   Like they have to have keyboarding classes to type, but it kind of makes no sense to
[00:35:17.680 --> 00:35:23.480]   teach them a technology that was developed for an earlier technological leap.
[00:35:23.480 --> 00:35:30.880]   Like to them, why would you not just make your body part of the user interface and move?
[00:35:30.880 --> 00:35:34.140]   What could you do in computing or how could you use computing in ways that you're not
[00:35:34.140 --> 00:35:35.320]   using it now?
[00:35:35.320 --> 00:35:41.880]   If you have 360 degrees of movement around you and you can physically rearrange things.
[00:35:41.880 --> 00:35:45.800]   So we're going to have a minority report style UI.
[00:35:45.800 --> 00:35:46.800]   Who knows?
[00:35:46.800 --> 00:35:47.800]   Who knows?
[00:35:47.800 --> 00:35:48.800]   Who knows?
[00:35:48.800 --> 00:35:51.800]   I mean, I've done hollow lens demonstrations where-
[00:35:51.800 --> 00:35:54.760]   Yeah, and I just did the magic leap.
[00:35:54.760 --> 00:35:58.920]   I had to build like a factory floor and design it using that.
[00:35:58.920 --> 00:36:03.520]   And then I had to also fix a pipe while having a customer service person walk me through
[00:36:03.520 --> 00:36:06.120]   it on the upper right hand thing and what really-
[00:36:06.120 --> 00:36:07.120]   Oh, that's cool.
[00:36:07.120 --> 00:36:12.520]   And what blew my mind about it was again, it's a much more immersive experience because
[00:36:12.520 --> 00:36:18.400]   it is very physical and you're using your voice, you're using your body to gesture and
[00:36:18.400 --> 00:36:19.800]   things like that.
[00:36:19.800 --> 00:36:25.880]   And I was thinking why wouldn't this be the next stage for computing?
[00:36:25.880 --> 00:36:27.800]   You're always going to have accessibility issues.
[00:36:27.800 --> 00:36:28.800]   You have to get around.
[00:36:28.800 --> 00:36:29.800]   There's no way around.
[00:36:29.800 --> 00:36:30.800]   There's no way to avoid that.
[00:36:30.800 --> 00:36:32.840]   Like there are going to be people who can't use their bodies.
[00:36:32.840 --> 00:36:36.400]   But I think that we're going to move away from the keyboard as your primary interface
[00:36:36.400 --> 00:36:37.400]   for data.
[00:36:37.400 --> 00:36:41.360]   So you're going to see a buff guy walking down the street and you're like, "Oh, he must
[00:36:41.360 --> 00:36:42.360]   have a desk job."
[00:36:42.360 --> 00:36:43.360]   Yes, exactly.
[00:36:43.360 --> 00:36:44.360]   That's funny.
[00:36:44.360 --> 00:36:47.000]   Look at the size of his forefinger.
[00:36:47.000 --> 00:36:48.000]   My God.
[00:36:48.000 --> 00:36:53.520]   Yes, all those triceps are super buff because he's like writing formulas in Excel.
[00:36:53.520 --> 00:36:59.160]   All right, let's do the startup that does that.
[00:36:59.160 --> 00:37:00.160]   Yeah.
[00:37:00.160 --> 00:37:05.160]   Tech companies are, so I'm going to ask the question again, are smart and know what's
[00:37:05.160 --> 00:37:06.160]   going to happen?
[00:37:06.160 --> 00:37:09.680]   Or they're looking for solutions to problems that don't exist.
[00:37:09.680 --> 00:37:14.120]   They're throwing spaghetti on the wall and seeing what sticks.
[00:37:14.120 --> 00:37:17.240]   In the case of Apple, they are never first.
[00:37:17.240 --> 00:37:18.240]   They don't care.
[00:37:18.240 --> 00:37:19.240]   They don't need to be first.
[00:37:19.240 --> 00:37:20.240]   They don't need to be first.
[00:37:20.240 --> 00:37:23.640]   They just look what works and just like, "Okay, we'll do that 10 times better."
[00:37:23.640 --> 00:37:25.840]   Let's wrap it in white plastic and sell it to people.
[00:37:25.840 --> 00:37:29.040]   Nevertheless, I keep coming back to the T2 and the A12X.
[00:37:29.040 --> 00:37:32.160]   They're doing stuff that we've had accelerators.
[00:37:32.160 --> 00:37:33.160]   We've had processors.
[00:37:33.160 --> 00:37:34.560]   They're just bringing it in-house.
[00:37:34.560 --> 00:37:37.040]   They're like, "Well, these are our goals.
[00:37:37.040 --> 00:37:38.640]   This is not for all these other companies.
[00:37:38.640 --> 00:37:41.240]   It's just for our use, so we want to put money here.
[00:37:41.240 --> 00:37:42.400]   We want to reduce this part.
[00:37:42.400 --> 00:37:43.640]   We want to cut this part out.
[00:37:43.640 --> 00:37:48.000]   We're going to speed this up and price is no object because we don't have to then sell
[00:37:48.000 --> 00:37:49.600]   it and then make margins on it.
[00:37:49.600 --> 00:37:56.280]   We have margins by not having to resell it at a loss, at a sale, or get this much volume
[00:37:56.280 --> 00:38:00.120]   because we know our customer base because we are our own customers.
[00:38:00.120 --> 00:38:03.600]   They can focus on what they need to focus on.
[00:38:03.600 --> 00:38:07.640]   Then there's Samsung with a foldable phone.
[00:38:07.640 --> 00:38:11.360]   I look at that and I wonder, is this something everybody's going to have in the future or
[00:38:11.360 --> 00:38:17.400]   is this something Samsung thinks might be something everybody wants?
[00:38:17.400 --> 00:38:19.280]   With our aging population, yeah.
[00:38:19.280 --> 00:38:20.520]   It's a big screen.
[00:38:20.520 --> 00:38:25.960]   If you're 78-inch-screen in your pocket, which our population is moving towards, you're going
[00:38:25.960 --> 00:38:27.840]   to want a big screen.
[00:38:27.840 --> 00:38:30.760]   It's funny because at the event Samsung turned out the lights.
[00:38:30.760 --> 00:38:34.360]   I didn't wrap it in something too.
[00:38:34.360 --> 00:38:36.360]   It turned either way.
[00:38:36.360 --> 00:38:37.360]   Yeah.
[00:38:37.360 --> 00:38:41.040]   This is obviously a concept video of the phone.
[00:38:41.040 --> 00:38:45.320]   Although I think it could very much look like this with a small screen on the front,
[00:38:45.320 --> 00:38:52.080]   then it opens up with this folding OLED screen technology to a single screen inside, 360-degree
[00:38:52.080 --> 00:38:58.360]   foldable display.
[00:38:58.360 --> 00:39:00.920]   I look at this and I feel like, "Oh, I don't want this."
[00:39:00.920 --> 00:39:02.640]   Yeah, same.
[00:39:02.640 --> 00:39:06.920]   My initial thing is it's a solution in search of a problem, but now that you've mentioned
[00:39:06.920 --> 00:39:11.560]   an older population, that makes perfect sense because you're talking about people where
[00:39:11.560 --> 00:39:13.760]   there may be either vision or dexterity issues.
[00:39:13.760 --> 00:39:14.760]   Isn't that funny?
[00:39:14.760 --> 00:39:20.120]   I think to some degree, I always assume technology companies are designing for the next generation.
[00:39:20.120 --> 00:39:22.640]   Maybe they're actually just designing for baby boomers.
[00:39:22.640 --> 00:39:23.640]   They have the money.
[00:39:23.640 --> 00:39:25.640]   And the next generation will do what it does.
[00:39:25.640 --> 00:39:26.640]   Why do you rob a bank?
[00:39:26.640 --> 00:39:27.640]   You rob a bank because that's what it's like.
[00:39:27.640 --> 00:39:28.640]   That's where the money is.
[00:39:28.640 --> 00:39:30.240]   It's not the 15-year-olds.
[00:39:30.240 --> 00:39:32.120]   It's the 60-year-olds.
[00:39:32.120 --> 00:39:33.120]   Yeah.
[00:39:33.120 --> 00:39:39.760]   I will say anecdotally because I try not to make the, well, my grandma comparison, but
[00:39:39.760 --> 00:39:45.520]   this is an actual real my grandma comparison, she has, I think, like an iPhone 5C or something
[00:39:45.520 --> 00:39:46.520]   like that.
[00:39:46.520 --> 00:39:51.880]   She doesn't really ever use that because a long time ago, I gave her an iPad Mini and
[00:39:51.880 --> 00:39:57.120]   she uses the iPad Mini for most of the stuff that she does because that is that bigger
[00:39:57.120 --> 00:40:01.400]   screen that she, it's still small enough for her to carry around in her purse and things
[00:40:01.400 --> 00:40:05.120]   like that, but it's bigger than that tiny screen.
[00:40:05.120 --> 00:40:10.240]   And so she does most of her iMessage conversations on there, her email, this, that, and the other.
[00:40:10.240 --> 00:40:13.040]   And she has a computer too, but she doesn't really ever use that.
[00:40:13.040 --> 00:40:15.360]   She's got that iPad Mini that's like the perfect size for her.
[00:40:15.360 --> 00:40:20.120]   So I could see that definitely being a case where, you know, when you're out and about
[00:40:20.120 --> 00:40:26.200]   and you're just talking on the phone because that's something that she still does, then
[00:40:26.200 --> 00:40:27.720]   you want that smaller device with you.
[00:40:27.720 --> 00:40:30.920]   But then when you get somewhere where you're like trying to see, okay, what's going on
[00:40:30.920 --> 00:40:34.200]   on the screen or the messages and things like that, yeah, they'll be able to fold that out
[00:40:34.200 --> 00:40:39.800]   and say, ah, okay, I can see this nice and big now is actually a pretty good idea.
[00:40:39.800 --> 00:40:41.600]   Wow.
[00:40:41.600 --> 00:40:42.600]   My mind is blown.
[00:40:42.600 --> 00:40:43.600]   I'm going to have to think about this.
[00:40:43.600 --> 00:40:44.600]   Let's take a break.
[00:40:44.600 --> 00:40:47.600]   Because I got to figure out what you all just said.
[00:40:47.600 --> 00:40:51.240]   Wesley Faulkner lives in the future apparently.
[00:40:51.240 --> 00:40:54.720]   He's at IBM where he's doing developer relations advocacy.
[00:40:54.720 --> 00:40:57.000]   Nice to have you Wesley at IBM.
[00:40:57.000 --> 00:40:58.480]   Thanks for having me.
[00:40:58.480 --> 00:41:03.320]   Micah Sargent, are you not an iMore or you just want us to talk about Chihuahua Coffee?
[00:41:03.320 --> 00:41:06.120]   No, I've recently gotten freelance actually.
[00:41:06.120 --> 00:41:07.120]   Thank you.
[00:41:07.120 --> 00:41:08.120]   Congratulations.
[00:41:08.120 --> 00:41:09.120]   Thank you.
[00:41:09.120 --> 00:41:11.960]   And we should follow you at Chihuahua.coffee.
[00:41:11.960 --> 00:41:16.360]   Yeah, it's got links to all the stuff I do or if you just want to see what I'm tweeting
[00:41:16.360 --> 00:41:19.000]   about, then that's @MicahSargent on Twitter.
[00:41:19.000 --> 00:41:20.000]   Nice.
[00:41:20.000 --> 00:41:21.680]   Well, that's exciting.
[00:41:21.680 --> 00:41:24.120]   Good luck in the new career.
[00:41:24.120 --> 00:41:25.120]   Thank you.
[00:41:25.120 --> 00:41:26.120]   Yeah, Chihuahua.coffee.
[00:41:26.120 --> 00:41:30.160]   You have to figure out how to spell it.
[00:41:30.160 --> 00:41:31.920]   Just like it sounds, right Micah?
[00:41:31.920 --> 00:41:32.920]   Yeah.
[00:41:32.920 --> 00:41:33.920]   Yeah.
[00:41:33.920 --> 00:41:34.920]   Chihuahua.
[00:41:34.920 --> 00:41:35.920]   Chihuahua.
[00:41:35.920 --> 00:41:38.080]   Oh, it's that new Chinese phone everybody's talking about.
[00:41:38.080 --> 00:41:39.080]   The Chihuahua.
[00:41:39.080 --> 00:41:40.840]   I know that one.
[00:41:40.840 --> 00:41:42.320]   I got a Chihuahua 20.
[00:41:42.320 --> 00:41:43.720]   It's the other day.
[00:41:43.720 --> 00:41:44.720]   No?
[00:41:44.720 --> 00:41:45.720]   No.
[00:41:45.720 --> 00:41:48.440]   And that's Lisa Schmeiser, who is keeping me honest.
[00:41:48.440 --> 00:41:49.920]   Editor at ITPro today.
[00:41:49.920 --> 00:41:50.920]   She's an editor.
[00:41:50.920 --> 00:41:52.760]   She's already red penciled me.
[00:41:52.760 --> 00:41:53.760]   All over.
[00:41:53.760 --> 00:41:54.760]   I'm bringing a big pump.
[00:41:54.760 --> 00:41:56.560]   I'll put a prop pencil next time.
[00:41:56.560 --> 00:41:57.400]   You just haul it out.
[00:41:57.400 --> 00:41:58.400]   I have one.
[00:41:58.400 --> 00:41:59.400]   We'll get it for you.
[00:41:59.400 --> 00:42:02.600]   I'll show you today brought to you by ExpressVPN.
[00:42:02.600 --> 00:42:07.080]   I don't know what the kids are using today, but I do know that keeping yourself protected
[00:42:07.080 --> 00:42:13.440]   and private online is a big deal, especially with all the news about security breaches
[00:42:13.440 --> 00:42:16.440]   and spying.
[00:42:16.440 --> 00:42:21.800]   You want to consider where is your data going and who's keeping an eye on things.
[00:42:21.800 --> 00:42:26.560]   We know you're being tracked online by social media sites, by marketing companies, frankly,
[00:42:26.560 --> 00:42:29.880]   by your internet service provider and your mobile phone company.
[00:42:29.880 --> 00:42:31.400]   They can record your browsing history.
[00:42:31.400 --> 00:42:36.680]   They often say we know they sell it to other companies who want to profit for your information.
[00:42:36.680 --> 00:42:42.360]   As always, talking about Google and Facebook, but your ISP is also without any safeguards
[00:42:42.360 --> 00:42:43.880]   keeping an eye on what you're up to.
[00:42:43.880 --> 00:42:49.640]   That's why I backed my privacy and you'll want to do with ExpressVPN.
[00:42:49.640 --> 00:42:56.040]   A strong VPN is your best way to stay safe and private online.
[00:42:56.040 --> 00:42:57.600]   ExpressVPN is easy to use apps.
[00:42:57.600 --> 00:43:00.400]   They run in the background on your computer, your phone, your tablet.
[00:43:00.400 --> 00:43:05.040]   You could turn them on with one click, secure an anonymize your internet browsing by encrypting
[00:43:05.040 --> 00:43:07.520]   your data, hiding your public IP address.
[00:43:07.520 --> 00:43:10.400]   Of course, ExpressVPN does not log.
[00:43:10.400 --> 00:43:13.320]   So you're completely anonymous.
[00:43:13.320 --> 00:43:18.120]   You could safely surf on public Wi-Fi without being snooped on or hacked.
[00:43:18.120 --> 00:43:20.280]   It's the number one VPN service.
[00:43:20.280 --> 00:43:21.480]   That's tech radar's rating.
[00:43:21.480 --> 00:43:26.960]   It comes with a 30 day money back guarantee costs less than $7 a month.
[00:43:26.960 --> 00:43:27.960]   It is the best.
[00:43:27.960 --> 00:43:30.120]   I know people are we get a lot of calls these days.
[00:43:30.120 --> 00:43:31.120]   I'm looking for a VPN.
[00:43:31.120 --> 00:43:32.120]   I'm looking for a VPN.
[00:43:32.120 --> 00:43:38.440]   Go to expressvpn.com/twit and they'll give you three extra months free with a one year
[00:43:38.440 --> 00:43:39.440]   package.
[00:43:39.440 --> 00:43:40.440]   ExpressVPN.com/twit.
[00:43:40.440 --> 00:43:45.640]   Add three months to your one year package free.
[00:43:45.640 --> 00:43:47.680]   ExpressVPN.com/twit.
[00:43:47.680 --> 00:43:52.960]   Protect yourself online now more than ever.
[00:43:52.960 --> 00:43:54.760]   Let's see.
[00:43:54.760 --> 00:43:58.360]   We were talking about the folding phone.
[00:43:58.360 --> 00:44:01.640]   I guess we've said everything we need to say about that.
[00:44:01.640 --> 00:44:02.640]   It's for old people.
[00:44:02.640 --> 00:44:09.080]   Now I understand as an old person, I know I should have gotten that right away.
[00:44:09.080 --> 00:44:13.280]   Is there anything else to say about the new Apple stuff?
[00:44:13.280 --> 00:44:16.640]   We did talk about the fact that their unit sales are no longer going to be reported.
[00:44:16.640 --> 00:44:18.760]   That's kind of makes sense.
[00:44:18.760 --> 00:44:19.760]   I don't know.
[00:44:19.760 --> 00:44:23.520]   Some people say it's because Apple doesn't want you to know, but I'm lately been more
[00:44:23.520 --> 00:44:27.560]   convinced that it's just because it's not as important as how much money they're making
[00:44:27.560 --> 00:44:30.000]   per customer, which is what they will report.
[00:44:30.000 --> 00:44:34.280]   That was the argument they made in the call.
[00:44:34.280 --> 00:44:40.440]   Now that Serenity Caldwell has moved on to the fruit company, I handled the transcription
[00:44:40.440 --> 00:44:43.840]   of the financial call for iMore.
[00:44:43.840 --> 00:44:47.320]   They brought that up quite a bit.
[00:44:47.320 --> 00:44:53.560]   Then when the folks asked about it, the analysts asked about it afterward, they pretty much
[00:44:53.560 --> 00:44:55.440]   just said the same thing over and over again.
[00:44:55.440 --> 00:45:01.840]   They might as well just played a soundbite of Luca because it was what you just said.
[00:45:01.840 --> 00:45:06.600]   I think Tim Cook even ended the conversation by saying something like, "When you roll up
[00:45:06.600 --> 00:45:13.920]   a cart at the grocery store and you get your total cost at the end of the day, it doesn't
[00:45:13.920 --> 00:45:17.360]   matter what each individual thing in the cart costs.
[00:45:17.360 --> 00:45:20.040]   It doesn't matter what that is.
[00:45:20.040 --> 00:45:23.240]   All you care about is the total that you get to at the end."
[00:45:23.240 --> 00:45:30.680]   The idea there I think is that Apple is focusing more on making sure that the products that
[00:45:30.680 --> 00:45:35.720]   it sells are the ones that make their customers happy.
[00:45:35.720 --> 00:45:40.600]   There's the argument that if we have analysts talking about how, "Well, the iPhone is now
[00:45:40.600 --> 00:45:48.560]   not doing well," then that runs the risk of Apple not being able to focus on continuing
[00:45:48.560 --> 00:45:50.880]   this right product experience.
[00:45:50.880 --> 00:45:56.360]   It's all very confusing and I don't know what the real reason is, but I did like Tim Cook's
[00:45:56.360 --> 00:45:59.040]   little thing at the end about shopping carts.
[00:45:59.040 --> 00:46:02.080]   Speaking of shopping, you know this is Singles Day.
[00:46:02.080 --> 00:46:09.400]   It is Veterans Day, the 100th anniversary of the armistice in World War I, 100 years ago,
[00:46:09.400 --> 00:46:16.720]   11/11/19/18, and it is 11/11/11/11/18, the war ended.
[00:46:16.720 --> 00:46:22.680]   Of course, we commemorate Veterans on this day and I think it's a good thing to do.
[00:46:22.680 --> 00:46:24.760]   There was a big parade in Petaluma today.
[00:46:24.760 --> 00:46:27.400]   A lot of fun.
[00:46:27.400 --> 00:46:35.400]   But in China, they're spending because 1-1-1-1 is a lot of ones and it's Singles Day.
[00:46:35.400 --> 00:46:40.600]   I think Alibaba, this is probably, talk about a hallmark holiday, invented this some years
[00:46:40.600 --> 00:46:48.320]   ago as a way to celebrate single people, but also it's their Black Friday and typically
[00:46:48.320 --> 00:46:53.360]   worldwide the number one buying day of the year.
[00:46:53.360 --> 00:46:54.880]   For the last 10 years it has been.
[00:46:54.880 --> 00:46:59.920]   Alibaba, which is kind of the Amazon of Asia, has set a record.
[00:46:59.920 --> 00:47:02.200]   They set in the first 85 seconds.
[00:47:02.200 --> 00:47:04.960]   25 seconds, 1 billion.
[00:47:04.960 --> 00:47:11.600]   1 billion dollars in the first 24 hours, 30.8 billion in sales.
[00:47:11.600 --> 00:47:16.680]   30 point, that's for one store, Alibaba.
[00:47:16.680 --> 00:47:19.880]   The record was last year, 25 billion.
[00:47:19.880 --> 00:47:26.640]   So that's a 20% increase year over year.
[00:47:26.640 --> 00:47:32.040]   What I'd like to know is if bricks and mortar retailers are seeing a boost from this or
[00:47:32.040 --> 00:47:37.120]   if they're actually losing business because Alibaba is locking up so much of it.
[00:47:37.120 --> 00:47:39.720]   It's a China thing though, right?
[00:47:39.720 --> 00:47:41.560]   We don't see that here or do we?
[00:47:41.560 --> 00:47:46.640]   I've seen some US retailers who have started, and I wish I could remember who it was.
[00:47:46.640 --> 00:47:50.560]   I was doing the board clicking through on a Friday night and the couch brain dead thing
[00:47:50.560 --> 00:47:53.520]   and I saw a US retailer who was like, "Here's our Singles Day."
[00:47:53.520 --> 00:47:54.520]   It's Singles Day.
[00:47:54.520 --> 00:47:55.520]   Wow.
[00:47:55.520 --> 00:47:57.160]   And I'm thinking, "Oh, how it's come over here?"
[00:47:57.160 --> 00:47:58.720]   So maybe...
[00:47:58.720 --> 00:48:03.520]   It's kind of just already Black Friday deals have bled into October.
[00:48:03.520 --> 00:48:05.280]   Well, there's now Black Friday.
[00:48:05.280 --> 00:48:09.680]   There's Cyber Monday, there's Giving Tuesday, there's a green e-commerce holiday that goes
[00:48:09.680 --> 00:48:11.320]   into it too.
[00:48:11.320 --> 00:48:13.480]   There's also a gray...
[00:48:13.480 --> 00:48:16.320]   There's a holiday that's like a gray Thursday, I think they call it.
[00:48:16.320 --> 00:48:17.320]   Gray Thursday.
[00:48:17.320 --> 00:48:18.320]   What is Giving Tuesday?
[00:48:18.320 --> 00:48:19.320]   What is Giving Tuesday?
[00:48:19.320 --> 00:48:23.560]   It's the idea that either you donate money that day or that you buy things where a percentage
[00:48:23.560 --> 00:48:24.560]   goes to charity.
[00:48:24.560 --> 00:48:25.560]   Oh, okay.
[00:48:25.560 --> 00:48:26.560]   Yeah.
[00:48:26.560 --> 00:48:27.860]   It's another effort for e-commerce.
[00:48:27.860 --> 00:48:30.080]   It's November 27th this year.
[00:48:30.080 --> 00:48:31.080]   See?
[00:48:31.080 --> 00:48:33.680]   But it's more than e-commerce, I would hope.
[00:48:33.680 --> 00:48:35.600]   It's right, it's about giving back.
[00:48:35.600 --> 00:48:36.600]   Yeah.
[00:48:36.600 --> 00:48:38.920]   But there have been a number of these commerce-driven holidays.
[00:48:38.920 --> 00:48:43.460]   I mean, we've got Amazon Prime Day, which has spawned a whole lot of other retailers
[00:48:43.460 --> 00:48:47.160]   to trot out their own specials at that time too.
[00:48:47.160 --> 00:48:50.640]   Walmart was going to do it over that this year.
[00:48:50.640 --> 00:48:53.120]   Target was rolling things out at the same time too.
[00:48:53.120 --> 00:48:57.160]   All right, I'm going to get a little dystopian on your ass.
[00:48:57.160 --> 00:48:58.160]   Oh dear.
[00:48:58.160 --> 00:49:01.460]   I said that, should I?
[00:49:01.460 --> 00:49:08.340]   It was rewind that.
[00:49:08.340 --> 00:49:16.580]   Texi, have any of you read Yuval Noah Harari's book, Sapiens or Homo Deus or his new one,
[00:49:16.580 --> 00:49:19.900]   which just came out, which I just got, but I haven't read yet.
[00:49:19.900 --> 00:49:26.700]   He is a Israeli philosopher, PhD from Oxford, teaches at the Hebrew University in Jerusalem.
[00:49:26.700 --> 00:49:33.460]   The Sapiens was amazing and apparently has become, he's become kind of a poster child
[00:49:33.460 --> 00:49:34.860]   in Silicon Valley.
[00:49:34.860 --> 00:49:43.020]   But the funny thing is, his book, "21 Lessons for the 21st Century" is really about something
[00:49:43.020 --> 00:49:48.420]   that you would think the tech leaders wouldn't want him to say.
[00:49:48.420 --> 00:49:59.400]   Basically, that we are entering a fascist world run by tech companies with no, democracy
[00:49:59.400 --> 00:50:03.780]   is over in effect.
[00:50:03.780 --> 00:50:08.700]   Everything he says undermines the premises of advertising and engagement model, the models
[00:50:08.700 --> 00:50:13.900]   at Google and Facebook and everybody else supports.
[00:50:13.900 --> 00:50:20.820]   He's worried that because the tech revolutions work requires so few laborers, Silicon Valley
[00:50:20.820 --> 00:50:28.540]   is creating a tiny ruling class and then a giant, he calls it the useless class.
[00:50:28.540 --> 00:50:35.180]   That in the past, in the past, autocrats had to keep the peasants around because who else
[00:50:35.180 --> 00:50:37.420]   was going to grow their food.
[00:50:37.420 --> 00:50:45.100]   But in the future, the rich few, the one percenters will have everything they need and they won't
[00:50:45.100 --> 00:50:51.580]   need the workers, which means they're just going to kill them.
[00:50:51.580 --> 00:50:54.980]   That is the current season of American Horror Story.
[00:50:54.980 --> 00:50:58.300]   That's the whole story there, seriously.
[00:50:58.300 --> 00:51:01.100]   The useless class is literally useless.
[00:51:01.100 --> 00:51:07.060]   There's no reason for Silicon Valley to pay any attention to them or even listen to what
[00:51:07.060 --> 00:51:10.540]   they have to say.
[00:51:10.540 --> 00:51:15.340]   He says that's one of the reasons that this universal basic income is so popular.
[00:51:15.340 --> 00:51:17.820]   It's because, well, we'll throw them a bone.
[00:51:17.820 --> 00:51:21.020]   We don't really need them, but we're nice guys.
[00:51:21.020 --> 00:51:23.220]   We'll give them enough money to live on.
[00:51:23.220 --> 00:51:26.660]   Maybe they'll buy some of our products.
[00:51:26.660 --> 00:51:28.940]   Apparently, Silicon Valley loves this guy.
[00:51:28.940 --> 00:51:30.460]   He's going to dinners.
[00:51:30.460 --> 00:51:35.660]   He's in town for speeches.
[00:51:35.660 --> 00:51:41.940]   I agree, but I think it's mostly the government side rather than the tech side that's causing
[00:51:41.940 --> 00:51:43.740]   most of the problem.
[00:51:43.740 --> 00:51:45.100]   That's what he says.
[00:51:45.100 --> 00:51:51.300]   He says, "Because government's so dysfunctional, at some point, Mark Zuckerberg, Larry Page,
[00:51:51.300 --> 00:51:55.700]   Jack Dorsey, and most importantly, Jeff Bezos are just going to say, "Oh, you know what,
[00:51:55.700 --> 00:51:56.700]   government doesn't work.
[00:51:56.700 --> 00:51:58.100]   Throw it out.
[00:51:58.100 --> 00:51:59.660]   We'll take it from here."
[00:51:59.660 --> 00:52:02.580]   The issue is there is no government support.
[00:52:02.580 --> 00:52:08.140]   If you look at the postal system, there's UPS, there's FedEx, and then we have the postal
[00:52:08.140 --> 00:52:14.260]   system because it is deemed that getting mail, at least at the time, was more important
[00:52:14.260 --> 00:52:18.020]   than making money because people need to communicate.
[00:52:18.020 --> 00:52:24.500]   There is no equivalent for the digital age in terms of internet connectivity.
[00:52:24.500 --> 00:52:30.980]   The ability to move from one class to another is wider.
[00:52:30.980 --> 00:52:35.900]   The gap is wider because the access to information is further away.
[00:52:35.900 --> 00:52:38.700]   Of course, we have libraries which are being underfunded.
[00:52:38.700 --> 00:52:40.940]   I think people are saying, "Why do we still have libraries?"
[00:52:40.940 --> 00:52:45.940]   They're very important because of that, with people who don't have access any other way.
[00:52:45.940 --> 00:52:54.580]   If you look at institutions that are trying to give accessibility to learn so that you
[00:52:54.580 --> 00:52:59.220]   can move forward, they're being challenged saying, "Government shouldn't be doing that
[00:52:59.220 --> 00:53:00.220]   for people.
[00:53:00.220 --> 00:53:05.060]   Government should get out of the business and leave it to the private sector."
[00:53:05.060 --> 00:53:09.140]   The government is pushing people to the private sector and not giving a safety net for those
[00:53:09.140 --> 00:53:13.340]   that the private sector chooses not to support.
[00:53:13.340 --> 00:53:20.940]   That's why those rural broadband problems, because the private sector should be taking
[00:53:20.940 --> 00:53:23.140]   care of that, but they choose not to.
[00:53:23.140 --> 00:53:29.260]   There is no recourse because there is no safety net because it is government ceding all of
[00:53:29.260 --> 00:53:30.260]   that.
[00:53:30.260 --> 00:53:33.300]   The most important part to the private sector and there is no recourse.
[00:53:33.300 --> 00:53:37.740]   The government recently defunded programs that were designed either for rural internet access
[00:53:37.740 --> 00:53:39.820]   or low-income internet access.
[00:53:39.820 --> 00:53:42.060]   These programs were funded under the previous administration.
[00:53:42.060 --> 00:53:43.940]   They've been defunded under this one.
[00:53:43.940 --> 00:53:48.420]   I've done a couple stories on rural broadband and what I've consistently gotten from centrist
[00:53:48.420 --> 00:53:49.620]   or right-wing think tanks.
[00:53:49.620 --> 00:53:55.260]   When I ask them, "Why can't we do internet like TVA did electricity and water?"
[00:53:55.260 --> 00:53:58.260]   Their answer is, "Well, technical standards change so fast.
[00:53:58.260 --> 00:54:01.740]   You don't want to waste a lot of tax-paramony on internet just to have it be upgraded in
[00:54:01.740 --> 00:54:03.820]   a few years."
[00:54:03.820 --> 00:54:08.780]   What it comes down to is a more fundamental failure on the part of government, I would
[00:54:08.780 --> 00:54:12.420]   say, to argue that no, access to the internet is at this point a utility.
[00:54:12.420 --> 00:54:16.220]   It's as important as a phone program, which they subsidize for years.
[00:54:16.220 --> 00:54:17.700]   It's as important as electricity.
[00:54:17.700 --> 00:54:19.020]   It's as important.
[00:54:19.020 --> 00:54:25.620]   Like Wesley said, the ability to move from one class to another economically in this
[00:54:25.620 --> 00:54:32.780]   country is much, much less than it was 10 years ago, 20 years ago, 50 years ago.
[00:54:32.780 --> 00:54:35.580]   It comes down to a failure.
[00:54:35.580 --> 00:54:39.420]   It comes down to both the government not making a case for itself and politicians not making
[00:54:39.420 --> 00:54:44.740]   a case to people that government is a way to provide basic infrastructure to allow people
[00:54:44.740 --> 00:54:46.700]   to create and access opportunities.
[00:54:46.700 --> 00:54:51.620]   In this time, dystopian guy says, "No, opportunity.
[00:54:51.620 --> 00:54:52.620]   No one needs opportunity."
[00:54:52.620 --> 00:54:53.620]   No one needs opportunity.
[00:54:53.620 --> 00:54:55.620]   It's very short-sighted.
[00:54:55.620 --> 00:55:02.380]   I mean, honestly, maybe I'm a cynic, but I just assume that really they don't want government
[00:55:02.380 --> 00:55:07.700]   to do anything that private should do everything, that that's just kind of the...
[00:55:07.700 --> 00:55:09.260]   So back in the '90s when I was...
[00:55:09.260 --> 00:55:11.260]   Ideology of this, the dogma of this...
[00:55:11.260 --> 00:55:15.020]   Back in the '90s when I was coding, I freelanced on the side, and one of the pieces I wrote
[00:55:15.020 --> 00:55:19.340]   was asking why coders and website developers didn't unionize.
[00:55:19.340 --> 00:55:20.340]   Right.
[00:55:20.340 --> 00:55:23.300]   Because it was kind of crazy to me that all of these people were bragging about, "Oh,
[00:55:23.300 --> 00:55:24.820]   I worked 70 hours this week."
[00:55:24.820 --> 00:55:25.820]   But they don't want to.
[00:55:25.820 --> 00:55:29.940]   Well, this is the thing is every developer I talk to is like, "If I unionize, then someone
[00:55:29.940 --> 00:55:34.220]   else is going to be responsible for salary negotiations, someone else will become my
[00:55:34.220 --> 00:55:37.380]   benefits, and I can't optimize my own value."
[00:55:37.380 --> 00:55:39.020]   This is part of that same arrogance.
[00:55:39.020 --> 00:55:41.780]   It's part of that same arrogance that's driving this.
[00:55:41.780 --> 00:55:45.100]   Everybody is under the impression that they're going to be the one who can maximize it.
[00:55:45.100 --> 00:55:46.100]   I could do it best.
[00:55:46.100 --> 00:55:47.100]   Yeah, exactly.
[00:55:47.100 --> 00:55:48.100]   No collective vision at all.
[00:55:48.100 --> 00:55:51.660]   But you take a look now, and we're going to the point where programming can be something
[00:55:51.660 --> 00:55:54.980]   that is effectively written by tools.
[00:55:54.980 --> 00:55:56.900]   You don't need people to...
[00:55:56.900 --> 00:55:57.900]   Right.
[00:55:57.900 --> 00:55:58.900]   Let me read...
[00:55:58.900 --> 00:56:02.540]   Your utilization would have done a whole lot of good for these guys back in the 90s.
[00:56:02.540 --> 00:56:03.540]   You're playing right into this.
[00:56:03.540 --> 00:56:07.420]   This is from the New York Times article about a Harari.
[00:56:07.420 --> 00:56:08.580]   Harari's puzzled.
[00:56:08.580 --> 00:56:10.620]   Why is it that I've been embraced by Silicon Valley?
[00:56:10.620 --> 00:56:13.700]   And the Times writes, "This is Nelly Bowles, by the way, writing is great."
[00:56:13.700 --> 00:56:17.860]   Part of the reason might be Silicon Valley at a certain level is not optimistic on the
[00:56:17.860 --> 00:56:19.500]   future of democracy.
[00:56:19.500 --> 00:56:23.900]   The more of a mess Washington becomes, the more interested the tech world is in creating
[00:56:23.900 --> 00:56:24.900]   something else.
[00:56:24.900 --> 00:56:28.260]   And it might not look like elected representation.
[00:56:28.260 --> 00:56:32.980]   Tech and file coders, exactly what you said, Lisa, have long been wary of regulation and
[00:56:32.980 --> 00:56:35.020]   curious about alternative forms of government.
[00:56:35.020 --> 00:56:38.980]   A separatist streak runs through the place.
[00:56:38.980 --> 00:56:43.820]   Venture capitalists periodically call for California to secede or shatter or for the creation
[00:56:43.820 --> 00:56:46.540]   of corporate nation states.
[00:56:46.540 --> 00:56:51.380]   And this summer, Mark Zuckerberg, who incidentally has recommended Harari to his book club, acknowledged
[00:56:51.380 --> 00:56:52.900]   a fixation with...
[00:56:52.900 --> 00:56:53.900]   Caesar Augustus.
[00:56:53.900 --> 00:56:54.900]   Caesar Augustus.
[00:56:54.900 --> 00:56:59.260]   He had that in the New Yorker profile too, where he's really into the idea of conquering
[00:56:59.260 --> 00:57:00.860]   and imposing peace.
[00:57:00.860 --> 00:57:04.980]   Basically Zuckerberg told the New Yorker through a really harsh approach.
[00:57:04.980 --> 00:57:07.940]   Caesar established 200 years of world peace.
[00:57:07.940 --> 00:57:08.940]   You see?
[00:57:08.940 --> 00:57:10.660]   The train's ran on time.
[00:57:10.660 --> 00:57:12.820]   And on your perspective, right?
[00:57:12.820 --> 00:57:18.060]   So let me add one more piece to this dystopian puzzle.
[00:57:18.060 --> 00:57:19.060]   Sweden.
[00:57:19.060 --> 00:57:25.060]   This is the deputy governor of the central bank of Sweden, writing for the World Economic
[00:57:25.060 --> 00:57:27.660]   Forum.
[00:57:27.660 --> 00:57:31.180]   Sweden is moving rapidly away from using cash.
[00:57:31.180 --> 00:57:35.740]   The outstanding value of cash and circulation has dropped to 1% of GDP.
[00:57:35.740 --> 00:57:38.740]   Basically it's a cashless society.
[00:57:38.740 --> 00:57:39.900]   That sounds fine, right?
[00:57:39.900 --> 00:57:40.980]   We're all moving towards that.
[00:57:40.980 --> 00:57:41.980]   You use credit cards.
[00:57:41.980 --> 00:57:44.100]   They have something called "swish."
[00:57:44.100 --> 00:57:46.420]   Everybody in Sweden uses "swish" to "swish" monies.
[00:57:46.420 --> 00:57:47.620]   You become a verb.
[00:57:47.620 --> 00:57:54.060]   It completely bypasses central banknotes and coins.
[00:57:54.060 --> 00:57:55.060]   But here's the problem.
[00:57:55.060 --> 00:58:00.900]   If cash stops working, it leaves everyone to rely on the private sector for access to
[00:58:00.900 --> 00:58:03.540]   money and payment methods.
[00:58:03.540 --> 00:58:05.740]   It would be a historic change without precedent.
[00:58:05.740 --> 00:58:08.340]   No, it's the company's store all over again.
[00:58:08.340 --> 00:58:11.980]   You owe your soul due to company's store.
[00:58:11.980 --> 00:58:12.980]   Yeah, think about it.
[00:58:12.980 --> 00:58:15.380]   So we're moving in that direction too, right?
[00:58:15.380 --> 00:58:17.220]   This is a conversation.
[00:58:17.220 --> 00:58:21.580]   When you think about how many workers in America are compensated, it's not just salary.
[00:58:21.580 --> 00:58:25.740]   It's also access to healthcare benefits that won't bankrupt you.
[00:58:25.740 --> 00:58:32.980]   That is dependent on the largess of a company and what they choose to pay for health insurance.
[00:58:32.980 --> 00:58:35.420]   Instead of it being something where to get back to Wesley's point, instead of it being
[00:58:35.420 --> 00:58:39.820]   something where you've got a government as the regulatory body ensuring equality of
[00:58:39.820 --> 00:58:44.740]   access for everybody, you have people with wildly disparate levels of healthcare access
[00:58:44.740 --> 00:58:50.460]   at wildly disparate prices because it's linked to private corporations and private enterprise
[00:58:50.460 --> 00:58:51.460]   instead.
[00:58:51.460 --> 00:58:57.660]   So what Sweet is proposing, and maybe this is a window into what our future might hold,
[00:58:57.660 --> 00:58:59.980]   is the e-crona.
[00:58:59.980 --> 00:59:08.740]   The central bank says, "We're going to have to create our own digital currency instead
[00:59:08.740 --> 00:59:13.260]   of cash so that there will be the government will still have some role to play in the economic
[00:59:13.260 --> 00:59:15.540]   life of people."
[00:59:15.540 --> 00:59:20.940]   You'll trade in your ordinary crona one to one for e-crona, which will basically appear
[00:59:20.940 --> 00:59:27.380]   as cash on your swish account.
[00:59:27.380 --> 00:59:30.780]   I feel like we're going to see this in a few years.
[00:59:30.780 --> 00:59:33.500]   This will be proposed in the United States, don't you think?
[00:59:33.500 --> 00:59:37.500]   I don't see how this works though.
[00:59:37.500 --> 00:59:41.940]   They're trying to say it won't be based on blockchain.
[00:59:41.940 --> 00:59:42.940]   Oh, it will be.
[00:59:42.940 --> 00:59:43.940]   They just don't know.
[00:59:43.940 --> 00:59:45.940]   Everyone's trying to watch a government.
[00:59:45.940 --> 00:59:46.940]   Yeah.
[00:59:46.940 --> 00:59:53.260]   And then what, if you're a homeless person, someone has to have a computer or a buddy.
[00:59:53.260 --> 00:59:54.260]   Yeah.
[00:59:54.260 --> 00:59:56.900]   You need a phone.
[00:59:56.900 --> 01:00:00.020]   The reason they don't want blockchain is because blockchain is fundamentally decentralized
[01:00:00.020 --> 01:00:01.020]   technology.
[01:00:01.020 --> 01:00:03.060]   You don't need a bank if you have blockchain.
[01:00:03.060 --> 01:00:05.060]   Everybody has the ledger.
[01:00:05.060 --> 01:00:07.780]   Well, I think it depends on what kind of blockchain.
[01:00:07.780 --> 01:00:10.220]   You can have a private blockchain.
[01:00:10.220 --> 01:00:14.460]   You can have your control all of the nodes and the servers.
[01:00:14.460 --> 01:00:16.660]   So it doesn't have to be non-disputed and open.
[01:00:16.660 --> 01:00:18.180]   It could be a closed blockchain.
[01:00:18.180 --> 01:00:20.500]   So that's possible.
[01:00:20.500 --> 01:00:24.980]   So you can distribute it, but all of the data scissors are owned by you.
[01:00:24.980 --> 01:00:31.540]   So if it was distributed and open, you could be open to a 51% attack.
[01:00:31.540 --> 01:00:33.540]   Have you heard of that?
[01:00:33.540 --> 01:00:34.540]   Yeah.
[01:00:34.540 --> 01:00:37.180]   I heard about that on Silicon Valley.
[01:00:37.180 --> 01:00:38.180]   Yeah.
[01:00:38.180 --> 01:00:39.180]   Yeah.
[01:00:39.180 --> 01:00:41.780]   And so you'll lose control of the blockchain.
[01:00:41.780 --> 01:00:42.780]   Yeah.
[01:00:42.780 --> 01:00:44.900]   So they could use blockchain.
[01:00:44.900 --> 01:00:48.380]   I don't know why they're out right saying they won't.
[01:00:48.380 --> 01:00:50.500]   But then same thing.
[01:00:50.500 --> 01:00:55.500]   Not only will they hand in your crona, you should get a crona and a phone.
[01:00:55.500 --> 01:00:59.100]   Or I guess I'm sort of a reader.
[01:00:59.100 --> 01:01:01.020]   You got a little crona card.
[01:01:01.020 --> 01:01:02.020]   Yeah.
[01:01:02.020 --> 01:01:03.020]   I got a little crona card.
[01:01:03.020 --> 01:01:04.180]   The flip side of the chip.
[01:01:04.180 --> 01:01:06.540]   The flip side is the China use social credit system.
[01:01:06.540 --> 01:01:08.380]   Oh, is that scary?
[01:01:08.380 --> 01:01:12.620]   Which-- and this broke-- not broke, but this was basically something that grabbed headlines
[01:01:12.620 --> 01:01:18.660]   for a minute last month where China is now assigning, for lack of better word, social
[01:01:18.660 --> 01:01:23.940]   credit ratings to individual citizens based on a wide variety of things, including quote
[01:01:23.940 --> 01:01:25.380]   unquote frivolous spending.
[01:01:25.380 --> 01:01:30.260]   So this is, of course, one of the things you'd have to-- you'd have to watch out for when
[01:01:30.260 --> 01:01:35.260]   you get a lot of government involvement in your currency and your spending life is when
[01:01:35.260 --> 01:01:40.300]   they start side-lying what you purchase and assign a weight and a value to it.
[01:01:40.300 --> 01:01:44.580]   But who would you prefer doing the side-lying?
[01:01:44.580 --> 01:01:47.020]   Jeff Bezos or Donald Trump?
[01:01:47.020 --> 01:01:49.580]   I'm not sure which is worse, to be honest with you.
[01:01:49.580 --> 01:01:55.300]   I talked to a woman who was 13 years chief reporter for a news service in Beijing and
[01:01:55.300 --> 01:01:56.300]   China.
[01:01:56.300 --> 01:02:00.900]   Recently left, she was afraid of the government.
[01:02:00.900 --> 01:02:07.460]   I asked her about this social credit system and she said, "What's really interesting
[01:02:07.460 --> 01:02:08.500]   that's happened in China?"
[01:02:08.500 --> 01:02:14.740]   China has always had these totalitarian leaders forever, really, if you include the emperors.
[01:02:14.740 --> 01:02:20.940]   But what's changed is technology and that President Xi has so much more power because
[01:02:20.940 --> 01:02:25.060]   of cameras everywhere and digital technology and the ability to collect information about
[01:02:25.060 --> 01:02:27.540]   its citizenry and to use that information.
[01:02:27.540 --> 01:02:30.900]   I said, "Well, how do the people feel about this?"
[01:02:30.900 --> 01:02:35.380]   She said, "Well, it's interesting.
[01:02:35.380 --> 01:02:38.140]   They don't seem to really care.
[01:02:38.140 --> 01:02:44.500]   If you're middle class or higher, you like the social order it imposes.
[01:02:44.500 --> 01:02:49.580]   If you're poorer, you like the improved economic mobility.
[01:02:49.580 --> 01:02:56.500]   I remember even 10 years ago going to China in a small village that was agriculturally
[01:02:56.500 --> 01:02:58.300]   based.
[01:02:58.300 --> 01:03:00.740]   They all had flat screen TVs.
[01:03:00.740 --> 01:03:03.940]   Our guide said, "Yeah, that's the gift of the year from the government.
[01:03:03.940 --> 01:03:05.300]   Last year was refrigerators.
[01:03:05.300 --> 01:03:07.420]   The year before was air conditioning.
[01:03:07.420 --> 01:03:15.060]   Government keeps the poor people happy by continually bribing them with goods, economic
[01:03:15.060 --> 01:03:16.060]   goods.
[01:03:16.060 --> 01:03:17.780]   Everybody's happy.
[01:03:17.780 --> 01:03:25.660]   Everybody's complaining except maybe the intellectuals or the weagers or those in rebellion.
[01:03:25.660 --> 01:03:27.660]   Talk about dystopia.
[01:03:27.660 --> 01:03:29.140]   That's common."
[01:03:29.140 --> 01:03:35.700]   Did you know that Russians can see more blues than Americans?
[01:03:35.700 --> 01:03:37.460]   They have different words for it, right?
[01:03:37.460 --> 01:03:38.460]   Exactly.
[01:03:38.460 --> 01:03:40.260]   Different colors of blue?
[01:03:40.260 --> 01:03:41.260]   Not the blues.
[01:03:41.260 --> 01:03:44.460]   No, there are literally different words for different shades of blue.
[01:03:44.460 --> 01:03:45.460]   Robert Johnson.
[01:03:45.460 --> 01:03:49.780]   The color blue.
[01:03:49.780 --> 01:03:53.180]   That was the idea in that movie.
[01:03:53.180 --> 01:03:54.180]   Arrival.
[01:03:54.180 --> 01:03:57.180]   The language forms language.
[01:03:57.180 --> 01:03:59.180]   Yeah, it's entirely useless.
[01:03:59.180 --> 01:04:02.580]   But yeah, I have a friend who's a Russian translator who talks about it.
[01:04:02.580 --> 01:04:07.500]   And societies where they are not or they don't have the words or they don't have the culture
[01:04:07.500 --> 01:04:09.860]   around a certain idea.
[01:04:09.860 --> 01:04:12.900]   They can't necessarily- I see where you're going.
[01:04:12.900 --> 01:04:18.260]   I see where Y1 is better than the other because it's just not in their vocabulary.
[01:04:18.260 --> 01:04:19.420]   They don't dream about it.
[01:04:19.420 --> 01:04:22.380]   It's not in their society.
[01:04:22.380 --> 01:04:25.540]   When you say, "Does this bother you?"
[01:04:25.540 --> 01:04:27.540]   It's always going to be, "Well, this is how things are.
[01:04:27.540 --> 01:04:28.940]   This is how I've lived.
[01:04:28.940 --> 01:04:33.780]   This is what I'm used to as opposed to others who might speak other languages, visit to
[01:04:33.780 --> 01:04:40.580]   other locations and get a bigger picture and able to understand the world from a different
[01:04:40.580 --> 01:04:41.580]   context.
[01:04:41.580 --> 01:04:46.660]   I know it seems like it's unrelated saying that Russians can see more blues.
[01:04:46.660 --> 01:04:52.260]   But it's more of the same thing of being able to- if you have more context and you have
[01:04:52.260 --> 01:04:59.100]   more education around just the fundamental workings of what's allowed, not allowed.
[01:04:59.100 --> 01:05:04.100]   If you can try to move a little bit beyond the construct of what's socially acceptable,
[01:05:04.100 --> 01:05:10.620]   then you can be able to say, "Yes, this is a choice that I have and be able to move there."
[01:05:10.620 --> 01:05:17.420]   If they don't understand that there's a choice of not having this type of control, it's not
[01:05:17.420 --> 01:05:24.340]   in their vocabulary to talk about freedom, then yeah, I can see how they can say things
[01:05:24.340 --> 01:05:25.340]   are fine.
[01:05:25.340 --> 01:05:27.380]   I'm trying not to get depressed.
[01:05:27.380 --> 01:05:30.580]   This has been our dystopia segment.
[01:05:30.580 --> 01:05:32.740]   I hope you've enjoyed it.
[01:05:32.740 --> 01:05:36.500]   Things- look, the biggest constant is change.
[01:05:36.500 --> 01:05:42.140]   We're having conversations about things that were probably no- on maybe 10 people in the
[01:05:42.140 --> 01:05:45.140]   world's radar back in the 1990s.
[01:05:45.140 --> 01:05:50.540]   We don't know what transformative technology is coming and from where that will change
[01:05:50.540 --> 01:05:52.940]   people's interactions and priorities.
[01:05:52.940 --> 01:05:57.020]   We're sitting in this.
[01:05:57.020 --> 01:05:58.540]   It's an interesting thing.
[01:05:58.540 --> 01:06:03.940]   One of the reasons I always was fascinated by technology and ended up making it my beat,
[01:06:03.940 --> 01:06:10.460]   and I suspect it's true for you too, Lisa, and you too, Micah, is I wanted to be on the
[01:06:10.460 --> 01:06:15.780]   sidelines of the world that is most changing and it's never boring.
[01:06:15.780 --> 01:06:17.020]   It's always interesting.
[01:06:17.020 --> 01:06:21.500]   I kind of always knew it was important, but now what we're seeing, and I don't know if
[01:06:21.500 --> 01:06:28.540]   I have the frankly the tools to cover it, what we're seeing is some dramatic, unexpected
[01:06:28.540 --> 01:06:32.580]   changes in our society.
[01:06:32.580 --> 01:06:35.180]   I think we're all kind of grappling with that.
[01:06:35.180 --> 01:06:41.860]   Absolutely, and figuring out how to cover it, and I think figuring out our place in all
[01:06:41.860 --> 01:06:43.380]   of this.
[01:06:43.380 --> 01:06:49.300]   I've seen people completely get out of this because it's sort of a depressing thing where
[01:06:49.300 --> 01:06:51.860]   you're busy covering products that release-
[01:06:51.860 --> 01:06:56.100]   I'm trained to talk about the A12X bionic.
[01:06:56.100 --> 01:07:03.740]   I don't know anything about social justice and transformation of society, and yet that's
[01:07:03.740 --> 01:07:05.380]   the beat now, isn't it?
[01:07:05.380 --> 01:07:07.460]   Yeah, it's an important thing.
[01:07:07.460 --> 01:07:11.300]   I want to bring up something I think I've talked about it before on This Week in Tech,
[01:07:11.300 --> 01:07:19.700]   but it's just one very silly example of the way that third-party companies are getting
[01:07:19.700 --> 01:07:26.060]   involved in government, and that is the very stupid program that Domino's, the pizza company,
[01:07:26.060 --> 01:07:28.260]   did, where they were- I loved that.
[01:07:28.260 --> 01:07:29.260]   They were comfortable in potholes.
[01:07:29.260 --> 01:07:32.860]   Yeah, I thought that was a joke until somebody said, "No, they're really doing it."
[01:07:32.860 --> 01:07:33.860]   Yeah, yeah.
[01:07:33.860 --> 01:07:39.660]   So, Domino's comes in and gets a grant to the city to cover the potholes, and again,
[01:07:39.660 --> 01:07:43.180]   that's not the local government doing any of that stuff.
[01:07:43.180 --> 01:07:45.660]   It's this pizza company that makes a bunch of money.
[01:07:45.660 --> 01:07:46.660]   It's interesting.
[01:07:46.660 --> 01:07:52.660]   Although, as a citizen of pothole city USA, Petaloma, California, I would like to volunteer.
[01:07:52.660 --> 01:07:58.660]   We will change our name to Domino's if you would just please fix the streets, please.
[01:07:58.660 --> 01:08:03.060]   That's all I ask.
[01:08:03.060 --> 01:08:06.860]   Domino's California, I like it.
[01:08:06.860 --> 01:08:07.860]   It's not bad.
[01:08:07.860 --> 01:08:10.020]   I could live with that.
[01:08:10.020 --> 01:08:11.260]   For no potholes, for sure.
[01:08:11.260 --> 01:08:13.860]   For sipping Domino's going to win.
[01:08:13.860 --> 01:08:16.060]   I'm always going to change that stuff.
[01:08:16.060 --> 01:08:21.420]   They've always said that all politics is local, and really it's funny because you could
[01:08:21.420 --> 01:08:23.300]   talk about stuff going on in Washington, D.C.
[01:08:23.300 --> 01:08:26.620]   You don't get the immediate impact of any of that stuff.
[01:08:26.620 --> 01:08:31.700]   But when there are potholes all over your town, because I don't know why, because there's
[01:08:31.700 --> 01:08:36.940]   city councils incompetent or because there's no local revenue or what, I don't know, that
[01:08:36.940 --> 01:08:38.020]   impacts you.
[01:08:38.020 --> 01:08:42.660]   You realize immediately the importance of local politics.
[01:08:42.660 --> 01:08:44.500]   It's the rains.
[01:08:44.500 --> 01:08:45.500]   There's something.
[01:08:45.500 --> 01:08:46.500]   It rains.
[01:08:46.500 --> 01:08:47.500]   Look it.
[01:08:47.500 --> 01:08:48.500]   No, because this is the thing.
[01:08:48.500 --> 01:08:51.380]   I drive into Marin County, where it rains just as much and the roads are perfect.
[01:08:51.380 --> 01:08:55.020]   No, but I'm going to say the potholes are predicated by extreme weather shifts, and we
[01:08:55.020 --> 01:08:56.020]   have to figure out.
[01:08:56.020 --> 01:08:57.660]   Oh, so it's going to get worse.
[01:08:57.660 --> 01:08:59.420]   Well, this is an exciting infrastructure challenge.
[01:08:59.420 --> 01:09:00.420]   Look this way.
[01:09:00.420 --> 01:09:01.420]   It's a Christ-a-tunity.
[01:09:01.420 --> 01:09:02.420]   Christ-a-tunity.
[01:09:02.420 --> 01:09:03.420]   Christ-a-tunity.
[01:09:03.420 --> 01:09:04.420]   Christ-a-tunity.
[01:09:04.420 --> 01:09:08.700]   It's an exciting infrastructure challenge to figure out how to build basic infrastructure
[01:09:08.700 --> 01:09:10.300]   that's going to handle extreme weather events.
[01:09:10.300 --> 01:09:11.980]   This used to be the butter and eggs.
[01:09:11.980 --> 01:09:15.540]   Capital worlds could be the pepperoni sausage capital in the world, I think.
[01:09:15.540 --> 01:09:16.980]   I hate so much.
[01:09:16.980 --> 01:09:19.340]   You know, now I really want to be.
[01:09:19.340 --> 01:09:20.340]   We can call dominoes.
[01:09:20.340 --> 01:09:21.340]   It's the worst.
[01:09:21.340 --> 01:09:23.220]   Oh, I should say good things about it.
[01:09:23.220 --> 01:09:25.780]   Oh, because they're saying you don't have to say good things until they fill in your
[01:09:25.780 --> 01:09:27.620]   potholes until it's open.
[01:09:27.620 --> 01:09:28.620]   Yeah.
[01:09:28.620 --> 01:09:30.460]   Hey, I'll say bad things until you fill the potholes.
[01:09:30.460 --> 01:09:31.460]   Then I'll be nice.
[01:09:31.460 --> 01:09:32.460]   How about that?
[01:09:32.460 --> 01:09:33.460]   I like their app.
[01:09:33.460 --> 01:09:35.620]   My daughter likes dominoes, and so will do it.
[01:09:35.620 --> 01:09:36.620]   Why do kids use dominoes?
[01:09:36.620 --> 01:09:39.420]   Because it has no flavors in children of our taste buds.
[01:09:39.420 --> 01:09:40.420]   Oh, no.
[01:09:40.420 --> 01:09:41.420]   What's going on here?
[01:09:41.420 --> 01:09:43.980]   dominoes also has a good gluten-free pizza.
[01:09:43.980 --> 01:09:45.620]   I can talk about that.
[01:09:45.620 --> 01:09:49.340]   It actually is, I was surprised at how nice it tasted.
[01:09:49.340 --> 01:09:55.460]   So when I am like, I don't know, really not feeling like making something myself or praying
[01:09:55.460 --> 01:09:59.820]   that some new restaurant offers some sort of thing, then I'll get the gluten-free pizza
[01:09:59.820 --> 01:10:00.820]   at dominoes.
[01:10:00.820 --> 01:10:01.820]   It's really good.
[01:10:01.820 --> 01:10:02.820]   The app is ridiculous.
[01:10:02.820 --> 01:10:04.780]   The Dominoes is also the Netflix of pizza.
[01:10:04.780 --> 01:10:06.040]   You can order it on Twitter.
[01:10:06.040 --> 01:10:07.580]   You can order it for your text message.
[01:10:07.580 --> 01:10:10.660]   You can order it like your smart speaker.
[01:10:10.660 --> 01:10:13.220]   You can order it in any way that you can think of.
[01:10:13.220 --> 01:10:14.220]   That's what you're talking about.
[01:10:14.220 --> 01:10:15.220]   It's so ridiculous.
[01:10:15.220 --> 01:10:18.820]   That's what's-- because the first time it saved my order and then the next time I logged
[01:10:18.820 --> 01:10:22.420]   in and they're like, do you want to order the same thing again, I thought, this is amazing.
[01:10:22.420 --> 01:10:23.420]   I don't have to think.
[01:10:23.420 --> 01:10:24.420]   I just have to click.
[01:10:24.420 --> 01:10:25.860]   It saved my location.
[01:10:25.860 --> 01:10:27.860]   It saved my payment information.
[01:10:27.860 --> 01:10:32.340]   It literally took me less than 20 seconds to order my kid the pizza that we were going
[01:10:32.340 --> 01:10:35.300]   to have while watching Netflix that night.
[01:10:35.300 --> 01:10:38.020]   And I thought, wow, this is how they get to--
[01:10:38.020 --> 01:10:41.580]   There's somehow this really fits this conversation.
[01:10:41.580 --> 01:10:45.020]   Just because we can order it online, we're going to eat crappy pizza.
[01:10:45.020 --> 01:10:48.220]   No, sometimes when we eat nice pizza, but there are some nights when you're just like,
[01:10:48.220 --> 01:10:50.020]   no, I can't do it.
[01:10:50.020 --> 01:10:51.940]   Some nights when we eat pizza.
[01:10:51.940 --> 01:10:56.340]   The chat room is insisting that gluten-free and pizza don't belong in the same sentence.
[01:10:56.340 --> 01:11:04.940]   So what I had was a gluten-free bread adjacent item with sauce and some vegetable on top.
[01:11:04.940 --> 01:11:07.620]   Yeah, no, they talk about carburent with the catch of my daughter.
[01:11:07.620 --> 01:11:12.220]   My daughter likes the thin crust, which is basically a salt to put a little bit of ketchup
[01:11:12.220 --> 01:11:13.220]   and pepperoni on it.
[01:11:13.220 --> 01:11:16.660]   So everyone in the studio is like, we're quailing on.
[01:11:16.660 --> 01:11:19.660]   That's pretty awful.
[01:11:19.660 --> 01:11:23.340]   You know, I was-- for a while thought, oh, no, people are going to fight for democracy.
[01:11:23.340 --> 01:11:25.700]   We're going to stand up for human rights.
[01:11:25.700 --> 01:11:26.700]   We're going to take--
[01:11:26.700 --> 01:11:27.700]   We do.
[01:11:27.700 --> 01:11:31.180]   But now I realize, we'll do-- we'll even eat crap pizza as long as we can get it on our
[01:11:31.180 --> 01:11:32.180]   iPhone.
[01:11:32.180 --> 01:11:33.180]   That is why we got--
[01:11:33.180 --> 01:11:36.180]   I know these talking in VRAP is used to be--
[01:11:36.180 --> 01:11:38.220]   These two can converge, though.
[01:11:38.220 --> 01:11:42.820]   I had a friend who, this week, with election week happening and all that, because the
[01:11:42.820 --> 01:11:46.980]   lines at her local voting polling place for two and a half hours long, she ordered them
[01:11:46.980 --> 01:11:48.620]   pizza using her phone.
[01:11:48.620 --> 01:11:49.620]   See?
[01:11:49.620 --> 01:11:53.460]   So you can fight for democracy and get your pizza at the same time.
[01:11:53.460 --> 01:11:57.620]   I actually sent $100 to pizza to the polls.
[01:11:57.620 --> 01:11:58.620]   There you go.
[01:11:58.620 --> 01:12:01.940]   So that it would buy pizzas for people who were stuck in long lines.
[01:12:01.940 --> 01:12:07.100]   We were lucky enough not to have long lines here in Petaluma.
[01:12:07.100 --> 01:12:11.300]   But I wanted everybody who's taken their time to vote.
[01:12:11.300 --> 01:12:13.020]   Those dot pizza, what happens now?
[01:12:13.020 --> 01:12:17.260]   I think that a couple of years it'll be back.
[01:12:17.260 --> 01:12:18.260]   Tacos for 2020.
[01:12:18.260 --> 01:12:19.260]   Recount pizza.
[01:12:19.260 --> 01:12:21.260]   I think anyone wants to launch Tacos for 2020.
[01:12:21.260 --> 01:12:22.900]   Oh, that's it.
[01:12:22.900 --> 01:12:23.900]   Pizza for the recount.
[01:12:23.900 --> 01:12:26.100]   Ravioli for recount?
[01:12:26.100 --> 01:12:27.100]   Ravioli.
[01:12:27.100 --> 01:12:29.100]   Tacos for 2020.
[01:12:29.100 --> 01:12:30.100]   Chef 4D.
[01:12:30.100 --> 01:12:31.100]   Ooh.
[01:12:31.100 --> 01:12:32.100]   [LAUGHTER]
[01:12:32.100 --> 01:12:38.340]   They sent 10,000 pizzas to 568 polling places in 40 states.
[01:12:38.340 --> 01:12:39.340]   Wow.
[01:12:39.340 --> 01:12:40.340]   Yeah.
[01:12:40.340 --> 01:12:42.460]   There's a lot going on with polls.
[01:12:42.460 --> 01:12:44.220]   You have a lot of people working very hard.
[01:12:44.220 --> 01:12:46.220]   And it's fundamentally very bulky.
[01:12:46.220 --> 01:12:47.220]   Yeah.
[01:12:47.220 --> 01:12:51.020]   See, this is what actually-- any time I'm over disrupting technology, here's a place where
[01:12:51.020 --> 01:12:54.940]   you do-- we'll do your laundry and give you a cookie, which was an actual startup app.
[01:12:54.940 --> 01:12:57.300]   We'll do your laundry and give you a cookie.
[01:12:57.300 --> 01:12:57.820]   Exactly.
[01:12:57.820 --> 01:12:59.300]   It was an actual startup for a while.
[01:12:59.300 --> 01:13:01.700]   And I keep thinking of all of the things you want to disrupt.
[01:13:01.700 --> 01:13:05.460]   Maybe take a look at making voting easier and more accessible to people.
[01:13:05.460 --> 01:13:07.500]   Or maybe take a look at filling potholes.
[01:13:07.500 --> 01:13:10.660]   Or maybe take a look at upgrading our civic infrastructure.
[01:13:10.660 --> 01:13:11.660]   Nah.
[01:13:11.660 --> 01:13:12.660]   Laundry and cookies.
[01:13:12.660 --> 01:13:13.660]   Laundry and cookies.
[01:13:13.660 --> 01:13:14.660]   [SIGHS]
[01:13:14.660 --> 01:13:15.660]   [SIGHS]
[01:13:15.660 --> 01:13:16.660]   Let's take a break.
[01:13:16.660 --> 01:13:17.660]   OK.
[01:13:17.660 --> 01:13:20.860]   We're going to get back to shiny objects that make you happy in a moment.
[01:13:20.860 --> 01:13:21.860]   [LAUGHTER]
[01:13:21.860 --> 01:13:25.060]   I can't wait.
[01:13:25.060 --> 01:13:29.700]   There's got to be something shiny in here.
[01:13:29.700 --> 01:13:31.180]   Let me talk a little bit about something cool.
[01:13:31.180 --> 01:13:33.100]   This is Robinhood.
[01:13:33.100 --> 01:13:44.220]   It's an investing app that lets you buy and sell stocks, ETFs, and cryptocurrency commission-free.
[01:13:44.220 --> 01:13:51.060]   It's a good name, Robinhood, because basically these guys are doing God's work.
[01:13:51.060 --> 01:13:55.940]   They're trying to make financial services work for everyone, not just the wealthy.
[01:13:55.940 --> 01:14:00.540]   Other brokerages, as you probably know, charge up to $10 for every trade.
[01:14:00.540 --> 01:14:04.100]   Robinhood, they don't charge commission fees.
[01:14:04.100 --> 01:14:06.940]   You will trade stocks and you'll keep all your profits.
[01:14:06.940 --> 01:14:08.340]   It's secure.
[01:14:08.340 --> 01:14:09.660]   It's encrypted.
[01:14:09.660 --> 01:14:10.700]   You get market data.
[01:14:10.700 --> 01:14:12.220]   You get charts.
[01:14:12.220 --> 01:14:13.660]   And it's a great app.
[01:14:13.660 --> 01:14:15.700]   You can place a trade with four taps.
[01:14:15.700 --> 01:14:17.940]   Boom, boom, boom, boom.
[01:14:17.940 --> 01:14:21.100]   The web platform lets you view stock collections.
[01:14:21.100 --> 01:14:25.140]   The 100 most popular sectors like entertainment and social media are there.
[01:14:25.140 --> 01:14:29.300]   That's-- you know, so I want-- let me look at the entertainment market basket or the
[01:14:29.300 --> 01:14:30.300]   social media market.
[01:14:30.300 --> 01:14:35.460]   You could view analyst ratings and buy, hold, and sell recommendations for every stock.
[01:14:35.460 --> 01:14:36.540]   You could discover new stocks.
[01:14:36.540 --> 01:14:41.580]   You could track favorite companies with personalized news feeds, build your portfolio, and there's
[01:14:41.580 --> 01:14:43.780]   no commission.
[01:14:43.780 --> 01:14:45.180]   Custom notifications for price movements.
[01:14:45.180 --> 01:14:48.940]   If you've been looking for ways to invest, you've got to download the app.
[01:14:48.940 --> 01:14:55.260]   And they're giving you a free stock of Apple, Ford, or Sprint to help you start when you
[01:14:55.260 --> 01:14:59.820]   sign up at twit2.robinhood.com.
[01:15:00.820 --> 01:15:04.380]   Twit the number two-- one word-- twit2.robinhood.com.
[01:15:04.380 --> 01:15:06.620]   You'll get a free stock.
[01:15:06.620 --> 01:15:07.620]   You get started.
[01:15:07.620 --> 01:15:10.220]   I think this is great.
[01:15:10.220 --> 01:15:11.940]   No brokerage fees.
[01:15:11.940 --> 01:15:13.660]   No commission.
[01:15:13.660 --> 01:15:14.660]   Trade stock.
[01:15:14.660 --> 01:15:15.980]   Keep it all.
[01:15:15.980 --> 01:15:18.420]   What could possibly be wrong?
[01:15:18.420 --> 01:15:19.900]   This is awesome.
[01:15:19.900 --> 01:15:20.900]   twit2.robinhood.com.
[01:15:20.900 --> 01:15:25.020]   When I found out about this, I said, I want-- this is cool.
[01:15:25.020 --> 01:15:27.260]   I want no more.
[01:15:27.260 --> 01:15:30.900]   twit2.robinhood.com.
[01:15:30.900 --> 01:15:32.220]   Thank you so much for their support.
[01:15:32.220 --> 01:15:36.100]   Brand new sponsor.
[01:15:36.100 --> 01:15:38.100]   It's amazing.
[01:15:38.100 --> 01:15:40.300]   It's amazing.
[01:15:40.300 --> 01:15:46.060]   So turns out people don't like Facebook that much.
[01:15:46.060 --> 01:15:47.060]   Turns out.
[01:15:47.060 --> 01:15:48.620]   Turns out.
[01:15:48.620 --> 01:15:53.340]   So Pew does these great research studies on the internet use.
[01:15:53.340 --> 01:15:57.380]   They found out that 44% of people 18 to 25
[01:15:57.380 --> 01:16:00.460]   have deleted their Facebook app on their phone.
[01:16:00.460 --> 01:16:03.020]   44%.
[01:16:03.020 --> 01:16:04.860]   Are they still on Instagram though, which is awesome?
[01:16:04.860 --> 01:16:05.700]   Well, they are.
[01:16:05.700 --> 01:16:06.060]   Yeah.
[01:16:06.060 --> 01:16:07.260]   I mean, this is the thing.
[01:16:07.260 --> 01:16:11.940]   And of-- this is a pole conductor for Fortune.
[01:16:11.940 --> 01:16:15.900]   22% of Americans trust Facebook.
[01:16:15.900 --> 01:16:21.940]   Only 22% Amazon 49% Google 41% Microsoft 40%.
[01:16:21.940 --> 01:16:23.420]   None of this is great.
[01:16:23.420 --> 01:16:26.660]   Apple, for weirdly enough, less than Amazon Google
[01:16:26.660 --> 01:16:28.700]   and Microsoft 39%.
[01:16:28.700 --> 01:16:32.020]   But Facebook, the bottom of the heap,
[01:16:32.020 --> 01:16:36.340]   only 22% of Americans trust Facebook.
[01:16:36.340 --> 01:16:38.740]   I guess that's not a surprise.
[01:16:38.740 --> 01:16:42.220]   So it's about trust, not so much about liking it?
[01:16:42.220 --> 01:16:44.780]   Well, I don't think anybody likes it.
[01:16:44.780 --> 01:16:45.340]   OK, good.
[01:16:45.340 --> 01:16:47.860]   Yeah, that's like 99.2%.
[01:16:47.860 --> 01:16:49.300]   Do you suppose the trust issue has
[01:16:49.300 --> 01:16:52.620]   to do with Zuckerberg's fundamental-- the public perception
[01:16:52.620 --> 01:16:54.140]   of Zuckerberg as a CEO?
[01:16:54.140 --> 01:16:54.620]   Yes.
[01:16:54.620 --> 01:16:56.780]   Because you look at Tim Cook, who gets out there,
[01:16:56.780 --> 01:16:57.980]   and he's, hi, everyone.
[01:16:57.980 --> 01:16:58.820]   I'm Tim Cook.
[01:16:58.820 --> 01:17:03.540]   I care about privacy and human rights and 12-and-a-plus phone.
[01:17:03.540 --> 01:17:07.900]   Or you get Sachin Adele, who writes a book, which is really--
[01:17:07.900 --> 01:17:09.380]   you know, I believe in human potential,
[01:17:09.380 --> 01:17:11.300]   and I believe in distributing opportunities equally.
[01:17:11.300 --> 01:17:14.500]   And I also believe that we're in a post desktop world.
[01:17:14.500 --> 01:17:17.660]   Or you even get Google CEO who's like, yeah,
[01:17:17.660 --> 01:17:19.860]   I will go to the airport and wave a sign around
[01:17:19.860 --> 01:17:21.420]   when a travel ban comes down.
[01:17:21.420 --> 01:17:23.180]   And then you get Zuckerberg.
[01:17:23.180 --> 01:17:28.100]   And I don't know if he doesn't know the optics that go
[01:17:28.100 --> 01:17:30.700]   with being a CEO, or he genuinely doesn't care.
[01:17:30.700 --> 01:17:33.980]   But I wonder how much of the Facebook trust problem
[01:17:33.980 --> 01:17:36.860]   is Zuckerberg's perceived--
[01:17:36.860 --> 01:17:38.140]   I just want to point out--
[01:17:38.140 --> 01:17:39.140]   --reaction a response.
[01:17:39.140 --> 01:17:44.060]   In a poll of adult Romans, only 22% trusted Caesar.
[01:17:44.060 --> 01:17:47.260]   [LAUGHTER]
[01:17:47.260 --> 01:17:48.460]   I was like, where's this guy?
[01:17:48.460 --> 01:17:51.900]   [LAUGHTER]
[01:17:51.900 --> 01:17:56.060]   You don't have to be loved and trusted to change the world.
[01:17:56.060 --> 01:18:00.020]   And I think Zuck really thinks--
[01:18:00.020 --> 01:18:02.300]   I know he's a true believer, right?
[01:18:02.300 --> 01:18:03.220]   I don't think he's cynical.
[01:18:03.220 --> 01:18:05.380]   I think he's a true believer that life is better
[01:18:05.380 --> 01:18:08.020]   when you're connected, blah, blah, blah.
[01:18:08.020 --> 01:18:11.100]   I also think that he thinks he thinks he can do it better.
[01:18:11.100 --> 01:18:12.300]   He does have a PR problem.
[01:18:12.300 --> 01:18:13.100]   There's no question.
[01:18:13.100 --> 01:18:17.220]   Five countries now are demanding he testify on data misuse.
[01:18:17.220 --> 01:18:21.100]   It's a joint international grand committee of members
[01:18:21.100 --> 01:18:22.740]   of the UK and Canadian parliaments
[01:18:22.740 --> 01:18:25.740]   investigating disinformation and online election
[01:18:25.740 --> 01:18:27.300]   influence campaign campaigns.
[01:18:27.300 --> 01:18:31.060]   They've added Argentina, Australia, and Ireland.
[01:18:31.060 --> 01:18:33.660]   He's been invited by British and Canadian officials
[01:18:33.660 --> 01:18:37.420]   to attend the first joint hearing in November,
[01:18:37.420 --> 01:18:40.300]   but he's declined.
[01:18:40.300 --> 01:18:41.460]   So not yet.
[01:18:41.460 --> 01:18:43.460]   [LAUGHTER]
[01:18:43.460 --> 01:18:45.460]   Yeah, I don't really feel like I'm--
[01:18:45.460 --> 01:18:48.620]   Yeah, I don't like traveling home holidays.
[01:18:48.620 --> 01:18:49.980]   It's raining.
[01:18:49.980 --> 01:18:51.180]   It's raining.
[01:18:51.180 --> 01:18:52.580]   Yeah, it's raining.
[01:18:52.580 --> 01:18:54.380]   The hell, how do you keep doing that?
[01:18:54.380 --> 01:18:55.340]   Everyone knows that.
[01:18:55.340 --> 01:18:58.180]   That creepy Facebook VR thing that would be there.
[01:18:58.180 --> 01:19:03.060]   I went to Puerto Rico and toured via VR.
[01:19:03.060 --> 01:19:07.980]   It's not possible, wrote Facebook officials, to a letter,
[01:19:07.980 --> 01:19:10.780]   for Mr. Zuckerberg to be available to all parliaments.
[01:19:10.780 --> 01:19:13.140]   OK?
[01:19:13.140 --> 01:19:15.340]   Why not?
[01:19:15.340 --> 01:19:17.180]   The parliaments wrote, we are very disappointed
[01:19:17.180 --> 01:19:18.500]   with this dismissive response.
[01:19:18.500 --> 01:19:20.700]   Five parliaments are now calling and you do the right thing
[01:19:20.700 --> 01:19:23.380]   by 170 million users in the countries they represent.
[01:19:23.380 --> 01:19:29.060]   I mean, I guess you could take sides in this.
[01:19:29.060 --> 01:19:31.420]   You could be on Mark's side and said, well, come on.
[01:19:31.420 --> 01:19:33.460]   This is just a lot of grandstanding
[01:19:33.460 --> 01:19:36.340]   by politicians in these countries.
[01:19:36.340 --> 01:19:39.620]   After all, he did testify before the US Congress
[01:19:39.620 --> 01:19:42.020]   in what was completely a sham.
[01:19:42.020 --> 01:19:43.380]   Right?
[01:19:43.380 --> 01:19:44.380]   I mean, he might--
[01:19:44.380 --> 01:19:47.100]   Fascinating, that whole thing was interesting.
[01:19:47.100 --> 01:19:50.340]   Just the way that went down and the questions he was asked
[01:19:50.340 --> 01:19:52.700]   and the tech support questions he was asked.
[01:19:52.700 --> 01:19:55.860]   I think it points to a fundamental disconnect
[01:19:55.860 --> 01:19:59.780]   between, again, with the tech industry, things
[01:19:59.780 --> 01:20:01.260]   are its priorities and its messaging
[01:20:01.260 --> 01:20:03.340]   versus what people who are not in the industry
[01:20:03.340 --> 01:20:06.180]   may be receiving.
[01:20:06.180 --> 01:20:08.020]   Because I also would argue it's a failure
[01:20:08.020 --> 01:20:10.540]   on the part of the staffers for those Congress people
[01:20:10.540 --> 01:20:14.180]   to adequately write questions and educate them
[01:20:14.180 --> 01:20:15.620]   on here's what you have to ask and why you have to ask.
[01:20:15.620 --> 01:20:16.980]   But they even structured it badly
[01:20:16.980 --> 01:20:18.300]   because they only had five minutes.
[01:20:18.300 --> 01:20:20.060]   There was no time for follow up.
[01:20:20.060 --> 01:20:22.540]   They ended up grandstanding or asking them,
[01:20:22.540 --> 01:20:24.060]   how does this phone work?
[01:20:24.060 --> 01:20:28.700]   No, like it's a failure on all sides.
[01:20:28.700 --> 01:20:32.700]   But if you-- going back to the PR issue,
[01:20:32.700 --> 01:20:34.980]   that was a good thing for Mark.
[01:20:34.980 --> 01:20:38.180]   Because all the focus was on the dumb questions, right?
[01:20:38.180 --> 01:20:40.220]   Anything bad that Facebook did.
[01:20:40.220 --> 01:20:42.060]   And if he read the room right, especially
[01:20:42.060 --> 01:20:47.100]   in the European Union, they feel that they have no control
[01:20:47.100 --> 01:20:49.220]   of all these American tech companies
[01:20:49.220 --> 01:20:51.380]   that are taking control of their citizens.
[01:20:51.380 --> 01:20:54.780]   And if he refuses to show up, which he already is doing,
[01:20:54.780 --> 01:20:58.300]   they have more ammunition to feed the narrative
[01:20:58.300 --> 01:21:01.260]   that they don't care about us over here.
[01:21:01.260 --> 01:21:05.660]   They're going to do whatever they want without any thought
[01:21:05.660 --> 01:21:07.260]   that we can do anything against them
[01:21:07.260 --> 01:21:09.580]   because they feel that we are so dependent.
[01:21:09.580 --> 01:21:13.300]   He should show up. He should say, I want to hear you.
[01:21:13.300 --> 01:21:15.180]   You're very important.
[01:21:15.180 --> 01:21:19.260]   Whether it's true or not, if you look on both sides,
[01:21:19.260 --> 01:21:21.180]   it would be good for Mark.
[01:21:21.180 --> 01:21:23.220]   And it would be better for these politicians
[01:21:23.220 --> 01:21:26.980]   to figure out for them to even say that, hey, we care about you.
[01:21:26.980 --> 01:21:28.020]   So we're bringing Mark in.
[01:21:28.020 --> 01:21:30.460]   And Mark says, hey, I care about you, so I'm going to go.
[01:21:30.460 --> 01:21:33.300]   And he's not reading the room correctly.
[01:21:33.300 --> 01:21:35.700]   Well, he might want to read this graph correctly.
[01:21:35.700 --> 01:21:38.700]   Although I have to say, it's kind of goofy.
[01:21:38.700 --> 01:21:40.420]   How confident are you?
[01:21:40.420 --> 01:21:41.740]   This is the Fortune poll.
[01:21:41.740 --> 01:21:45.500]   In the leadership abilities of the CEOs of each of the following
[01:21:45.500 --> 01:21:49.380]   companies, when it comes to ethical use of data
[01:21:49.380 --> 01:21:51.540]   and private information.
[01:21:51.540 --> 01:21:54.700]   And 77% of respondents said that they were at least
[01:21:54.700 --> 01:21:57.580]   somewhat confident that Jeff Bezos was going to protect
[01:21:57.580 --> 01:21:59.460]   their private information.
[01:21:59.460 --> 01:22:01.020]   What?
[01:22:01.020 --> 01:22:03.700]   But only 59% said Mark Zuckerberg.
[01:22:03.700 --> 01:22:05.540]   I guess if you don't tell people how you're using
[01:22:05.540 --> 01:22:07.100]   their information, they're just like, oh!
[01:22:07.100 --> 01:22:08.500]   Jeff seems like a nice guy.
[01:22:08.500 --> 01:22:09.700]   He looks good.
[01:22:09.700 --> 01:22:10.220]   He's good.
[01:22:10.220 --> 01:22:12.900]   I've got this tower in my house I can talk to.
[01:22:12.900 --> 01:22:14.900]   And it's been so nice tonight.
[01:22:14.900 --> 01:22:16.180]   I love Jeff.
[01:22:16.180 --> 01:22:18.740]   Jeff Bezos, number one.
[01:22:18.740 --> 01:22:20.580]   Tim Cook, number two.
[01:22:20.580 --> 01:22:21.940]   Satya Nadella, number three.
[01:22:21.940 --> 01:22:23.100]   Sundar Pachai, number four.
[01:22:23.100 --> 01:22:24.580]   I bet you half the audience didn't even know
[01:22:24.580 --> 01:22:26.340]   who Sundar Pachai was.
[01:22:26.340 --> 01:22:30.460]   Mark Zuckerberg, number five, the lowest.
[01:22:30.460 --> 01:22:35.100]   59% at least somewhat confident that Facebook
[01:22:35.100 --> 01:22:38.660]   would use their information ethically.
[01:22:38.660 --> 01:22:41.300]   I am confident that's why I bought a Facebook portal, which
[01:22:41.300 --> 01:22:42.700]   will be coming soon.
[01:22:42.700 --> 01:22:44.540]   I'm going to put that in my house.
[01:22:44.540 --> 01:22:45.180]   Two of them.
[01:22:45.180 --> 01:22:46.740]   Yeah, well, you have to have two because--
[01:22:46.740 --> 01:22:47.940]   Did you get the spinny one?
[01:22:47.940 --> 01:22:49.220]   Yeah.
[01:22:49.220 --> 01:22:51.660]   The camera that follows you around uncannily,
[01:22:51.660 --> 01:22:53.500]   like Mona Lisa's eyes.
[01:22:53.500 --> 01:22:55.860]   Are you going to call me and read me a story?
[01:22:55.860 --> 01:22:57.300]   Yeah, would you like me to?
[01:22:57.300 --> 01:22:57.820]   I would.
[01:22:57.820 --> 01:22:58.320]   I would.
[01:22:58.320 --> 01:23:00.820]   The Chinese surveillance thing and the talk about vocabulary.
[01:23:00.820 --> 01:23:02.780]   Do you realize that outside this country, it probably
[01:23:02.780 --> 01:23:05.820]   seems insane that we pay money to voluntarily bring
[01:23:05.820 --> 01:23:08.300]   surveillance devices into our house?
[01:23:08.300 --> 01:23:10.060]   Begging them.
[01:23:10.060 --> 01:23:10.580]   Yeah.
[01:23:10.580 --> 01:23:11.080]   Please.
[01:23:11.080 --> 01:23:11.980]   We're like, oh, this is a perk.
[01:23:11.980 --> 01:23:14.380]   [LAUGHTER]
[01:23:14.380 --> 01:23:15.980]   You know, I'm sure that--
[01:23:15.980 --> 01:23:17.060]   and we're swimming in this culture.
[01:23:17.060 --> 01:23:18.700]   So I was like, oh, we can opt in or not.
[01:23:18.700 --> 01:23:21.060]   Maybe somebody from another culture like--
[01:23:21.060 --> 01:23:22.140]   why would you do this?
[01:23:22.140 --> 01:23:23.460]   You control nothing about it.
[01:23:23.460 --> 01:23:23.700]   Yeah.
[01:23:23.700 --> 01:23:25.820]   You control-- you don't control your data.
[01:23:25.820 --> 01:23:27.300]   You don't even know where your data is going.
[01:23:27.300 --> 01:23:28.300]   You don't know who's feeling your data.
[01:23:28.300 --> 01:23:29.860]   They gave you a little clip you could put over the camera
[01:23:29.860 --> 01:23:30.380]   if you want.
[01:23:30.380 --> 01:23:31.420]   Oh, that's mighty.
[01:23:31.420 --> 01:23:32.420]   [LAUGHTER]
[01:23:32.420 --> 01:23:33.420]   I'm not going to stop him.
[01:23:33.420 --> 01:23:34.420]   But like--
[01:23:34.420 --> 01:23:36.540]   [LAUGHTER]
[01:23:36.540 --> 01:23:37.580]   I trust Mark.
[01:23:37.580 --> 01:23:38.580]   Yeah.
[01:23:38.580 --> 01:23:39.580]   [LAUGHTER]
[01:23:39.580 --> 01:23:41.820]   I've got an echo view.
[01:23:41.820 --> 01:23:42.460]   Go ahead.
[01:23:42.460 --> 01:23:45.580]   As I said, the story about the echo and the court order.
[01:23:45.580 --> 01:23:46.460]   The murders.
[01:23:46.460 --> 01:23:47.020]   The double murders.
[01:23:47.020 --> 01:23:48.020]   Yeah.
[01:23:48.020 --> 01:23:49.020]   Sorry, Micah.
[01:23:49.020 --> 01:23:49.740]   Go ahead.
[01:23:49.740 --> 01:23:51.660]   No, I was just going to-- I have an echo spot.
[01:23:51.660 --> 01:23:54.860]   That's the one that's like circular and has the little screen
[01:23:54.860 --> 01:23:55.380]   on the front.
[01:23:55.380 --> 01:23:58.500]   Did you buy that because it was number one on Oprah's list?
[01:23:58.500 --> 01:24:00.060]   Oh, heavens no.
[01:24:00.060 --> 01:24:02.060]   I got it because I wanted to have--
[01:24:02.060 --> 01:24:03.060]   No, I didn't--
[01:24:03.060 --> 01:24:04.420]   When did it get on Oprah's list?
[01:24:04.420 --> 01:24:05.420]   I got it like--
[01:24:05.420 --> 01:24:06.420]   It's number one.
[01:24:06.420 --> 01:24:07.900]   It's her number one tech gadget.
[01:24:07.900 --> 01:24:09.020]   I got it when it launched.
[01:24:09.020 --> 01:24:12.660]   And I was really excited to have that clock, that digital clock.
[01:24:12.660 --> 01:24:16.500]   And I had first had it in my office.
[01:24:16.500 --> 01:24:18.460]   And I realized that I wasn't ever looking at it
[01:24:18.460 --> 01:24:21.580]   because I have a clock on my computer and on my watch
[01:24:21.580 --> 01:24:22.900]   everywhere else.
[01:24:22.900 --> 01:24:24.820]   And so I thought, oh, the bathroom
[01:24:24.820 --> 01:24:27.780]   would be a really nice place to have a clock.
[01:24:27.780 --> 01:24:30.780]   But I don't want this camera.
[01:24:30.780 --> 01:24:35.820]   So I took it apart and I completely covered up the camera
[01:24:35.820 --> 01:24:38.140]   on the inside with a piece of electrical tape
[01:24:38.140 --> 01:24:39.820]   and then put it all back together.
[01:24:39.820 --> 01:24:43.380]   And now the camera-- because they have a camera off button,
[01:24:43.380 --> 01:24:45.900]   but I'm paranoid and I'm like, I don't trust that camera off
[01:24:45.900 --> 01:24:45.900]   button.
[01:24:45.900 --> 01:24:48.660]   Do you think Jeff Bezos wants to watch you poop?
[01:24:48.660 --> 01:24:52.620]   I think Jeff Bezos wants to see what toilet paper I use
[01:24:52.620 --> 01:24:53.140]   so that he can--
[01:24:53.140 --> 01:24:54.140]   I believe.
[01:24:54.140 --> 01:24:55.180]   --put toilet paper to me.
[01:24:55.180 --> 01:24:56.100]   Is that--
[01:24:56.100 --> 01:24:57.060]   Cotton Naller-Sharmon.
[01:24:57.060 --> 01:24:57.900]   I can't tell.
[01:24:57.900 --> 01:24:59.940]   Can you look closer?
[01:24:59.940 --> 01:25:02.140]   Also, they do have time to work on those coordinates.
[01:25:02.140 --> 01:25:02.940]   Center.
[01:25:02.940 --> 01:25:03.820]   Enhance.
[01:25:03.820 --> 01:25:05.140]   Zoom in.
[01:25:05.140 --> 01:25:05.860]   It's Charmin.
[01:25:05.860 --> 01:25:08.140]   It's definitely Charmin.
[01:25:08.140 --> 01:25:10.420]   We got to make Amazon's basic toilet paper camera.
[01:25:10.420 --> 01:25:11.980]   You buy it on Amazon.
[01:25:11.980 --> 01:25:13.340]   They know.
[01:25:13.340 --> 01:25:15.020]   I literally do buy it on Amazon.
[01:25:15.020 --> 01:25:17.780]   Or they don't need a camera in your--
[01:25:17.780 --> 01:25:19.340]   I have my spot.
[01:25:19.340 --> 01:25:21.980]   It couldn't put it on the bedside table for the same reasons.
[01:25:21.980 --> 01:25:25.020]   My wife is just as nutty as you, Micah.
[01:25:25.020 --> 01:25:28.260]   And so I have it in my closet.
[01:25:28.260 --> 01:25:29.100]   In your closet?
[01:25:29.100 --> 01:25:29.940]   Yeah.
[01:25:29.940 --> 01:25:31.060]   He's put his tech in a closet.
[01:25:31.060 --> 01:25:32.540]   I keep my spot in the closet.
[01:25:32.540 --> 01:25:32.980]   You know why?
[01:25:32.980 --> 01:25:34.100]   It's a nice little clock.
[01:25:34.100 --> 01:25:36.220]   I could say what the weather's going to be like.
[01:25:36.220 --> 01:25:37.460]   I dress in my closet.
[01:25:37.460 --> 01:25:39.180]   It's a little bigger than a little closet.
[01:25:39.180 --> 01:25:40.260]   It's a big closet.
[01:25:40.260 --> 01:25:41.900]   I don't ever want to come out.
[01:25:41.900 --> 01:25:43.260]   It's in there, and I live in there,
[01:25:43.260 --> 01:25:44.900]   and I've got a little spot, and I could talk to it
[01:25:44.900 --> 01:25:46.900]   and listen to music on a tinny little speaker.
[01:25:46.900 --> 01:25:48.780]   But it's looking at what you're putting on
[01:25:48.780 --> 01:25:49.500]   and deciding--
[01:25:49.500 --> 01:25:50.660]   Absolutely.
[01:25:50.660 --> 01:25:51.660]   Some new clothes for you.
[01:25:51.660 --> 01:25:53.620]   It's the Amazon wardrobe model, remember?
[01:25:53.620 --> 01:25:56.900]   It was going to be the idea that it could recommend to you--
[01:25:56.900 --> 01:25:59.100]   Oh, you're out, it looks amazing today.
[01:25:59.100 --> 01:26:00.020]   Or something like that.
[01:26:00.020 --> 01:26:02.620]   But that at least-- so here's Oprah's favorite things, which,
[01:26:02.620 --> 01:26:04.140]   by the way, is on Amazon.
[01:26:04.140 --> 01:26:08.620]   So that might explain why number one is the Echo Spot.
[01:26:08.620 --> 01:26:11.180]   Ow.
[01:26:11.180 --> 01:26:15.620]   Also the Dog DNA Test by Embark.
[01:26:15.620 --> 01:26:18.260]   How come we don't have them as a sponsor?
[01:26:18.260 --> 01:26:23.060]   DNA for your dogs, truffle infused hot sauce,
[01:26:23.060 --> 01:26:27.420]   carbonator 2 by Arkey, empowered brass bracelets.
[01:26:27.420 --> 01:26:29.060]   Do you think she owns all of these things?
[01:26:29.060 --> 01:26:31.860]   You've got to really wonder where this list comes from.
[01:26:31.860 --> 01:26:32.780]   Yeah, who does this?
[01:26:32.780 --> 01:26:33.860]   Yeah.
[01:26:33.860 --> 01:26:37.380]   Letters for a year of gratitude by Chronicle Books,
[01:26:37.380 --> 01:26:41.460]   Chi Private Tea Trio, Lit Bang by Person.
[01:26:41.460 --> 01:26:43.060]   It feels like it's just one big ad.
[01:26:43.060 --> 01:26:43.980]   But here she is.
[01:26:43.980 --> 01:26:45.020]   Here's Oprah.
[01:26:45.020 --> 01:26:47.620]   Looking very excited about it.
[01:26:47.620 --> 01:26:51.740]   Saying, I love that coffee maker.
[01:26:51.740 --> 01:26:54.820]   Oh, maybe she's trying the Insta Shia Tzu heated foot
[01:26:54.820 --> 01:26:56.220]   massager by True Medic.
[01:26:56.220 --> 01:26:58.260]   Do you know how the Oprah's favorite things get picked?
[01:26:58.260 --> 01:26:58.780]   No.
[01:26:58.780 --> 01:26:59.300]   So--
[01:26:59.300 --> 01:26:59.900]   You know?
[01:26:59.900 --> 01:27:01.060]   Yes.
[01:27:01.060 --> 01:27:02.500]   You're on this show.
[01:27:02.500 --> 01:27:03.860]   You're here at the right time.
[01:27:03.860 --> 01:27:05.060]   How do they get picked?
[01:27:05.060 --> 01:27:07.420]   Companies start sending things to her as early as July.
[01:27:07.420 --> 01:27:09.860]   I have to imagine the crap she gets.
[01:27:09.860 --> 01:27:10.500]   All sorts of stuff.
[01:27:10.500 --> 01:27:12.180]   And the companies and the staffers
[01:27:12.180 --> 01:27:14.740]   are responsible for vetting it by category.
[01:27:14.740 --> 01:27:16.060]   And they break it down.
[01:27:16.060 --> 01:27:17.740]   And then Oprah does the final filter.
[01:27:17.740 --> 01:27:20.540]   But they have to win it down from literally thousands
[01:27:20.540 --> 01:27:24.140]   of products to the 100 or so that Oprah reviews--
[01:27:24.140 --> 01:27:25.780]   To all of the other products.
[01:27:25.780 --> 01:27:27.740]   I didn't find out because I suspect the answer is,
[01:27:27.740 --> 01:27:29.220]   I got to take them home.
[01:27:29.220 --> 01:27:31.940]   The person who's telling me this didn't want me to know.
[01:27:31.940 --> 01:27:32.940]   Yeah.
[01:27:32.940 --> 01:27:33.740]   So who got it?
[01:27:33.740 --> 01:27:34.260]   Pick that.
[01:27:34.260 --> 01:27:36.380]   I would actually love to know what the harpo rules are
[01:27:36.380 --> 01:27:37.420]   on gifts and things like that.
[01:27:37.420 --> 01:27:38.820]   Because I know in a lot of newsrooms,
[01:27:38.820 --> 01:27:39.940]   there's the rule that you can't--
[01:27:39.940 --> 01:27:40.940]   Oh, you're not supposed to keep that stuff.
[01:27:40.940 --> 01:27:41.620]   You can't bring stuff.
[01:27:41.620 --> 01:27:42.780]   We send everything back.
[01:27:42.780 --> 01:27:43.700]   Yeah, exactly.
[01:27:43.700 --> 01:27:45.620]   But I know in some companies--
[01:27:45.620 --> 01:27:47.580]   Except that big TV I'm keeping.
[01:27:47.580 --> 01:27:53.380]   And in some glossy media properties that are--
[01:27:53.380 --> 01:27:57.740]   How many X5 multi-port USB card chargers by RapidX?
[01:27:57.740 --> 01:27:58.500]   Do you think she got this?
[01:27:58.500 --> 01:27:59.820]   Got on the list.
[01:27:59.820 --> 01:28:01.540]   This is one of the top.
[01:28:01.540 --> 01:28:06.660]   Oprah writes, each of these X5 card chargers
[01:28:06.660 --> 01:28:11.020]   with extra long cord can simultaneously boost up
[01:28:11.020 --> 01:28:14.020]   five devices from phones to tablets.
[01:28:14.020 --> 01:28:17.060]   Translation, both front and backseat drivers
[01:28:17.060 --> 01:28:19.740]   can get some juice without coming to blows.
[01:28:19.740 --> 01:28:21.180]   Signed Oprah.
[01:28:21.180 --> 01:28:23.460]   You know that she's got a staff of ghostwriters to do.
[01:28:23.460 --> 01:28:26.100]   That Oprah is not tapping this out for every year.
[01:28:26.100 --> 01:28:27.060]   No, Oprah wrote that.
[01:28:27.060 --> 01:28:28.740]   Says Oprah wrote that.
[01:28:28.740 --> 01:28:31.180]   Someone in the chat said that those extra items, the one
[01:28:31.180 --> 01:28:33.460]   that don't make the 100, they send to Martha Stewart.
[01:28:33.460 --> 01:28:36.540]   [LAUGHTER]
[01:28:36.540 --> 01:28:38.580]   Oh, Martha.
[01:28:38.580 --> 01:28:39.700]   There's a package for her.
[01:28:39.700 --> 01:28:40.900]   She is looking at--
[01:28:40.900 --> 01:28:41.980]   I love Martha Stewart.
[01:28:41.980 --> 01:28:43.380]   --soap.
[01:28:43.380 --> 01:28:44.780]   Different soaps.
[01:28:44.780 --> 01:28:46.140]   Oh, what soaps made the list?
[01:28:46.140 --> 01:28:47.460]   Is it goat soap?
[01:28:47.460 --> 01:28:53.020]   The La Chatele and Ham Cream Tin by Tan Savon, Incorporated.
[01:28:53.020 --> 01:28:56.260]   You know, that's my favorite hand cream tin I got to tell you.
[01:28:56.260 --> 01:29:00.180]   Of all the ham cream tins in all the world.
[01:29:00.180 --> 01:29:03.740]   Faux Fermittons by Glamour Puss.
[01:29:03.740 --> 01:29:06.220]   We've officially reached the Chinese things portion of the--
[01:29:06.220 --> 01:29:07.860]   I told you I'd have them.
[01:29:07.860 --> 01:29:10.340]   Professional lasagna trio pan.
[01:29:10.340 --> 01:29:11.020]   Wait a minute.
[01:29:11.020 --> 01:29:13.340]   Why make one lasagna when you can make--
[01:29:13.340 --> 01:29:17.100]   when you have a family of varying appetites, writes Oprah,
[01:29:17.100 --> 01:29:18.820]   these will come in handy.
[01:29:18.820 --> 01:29:21.900]   All three pan sections are lasagna noodle size,
[01:29:21.900 --> 01:29:24.180]   great for that gang of vegetarian, gluten-free,
[01:29:24.180 --> 01:29:25.540]   and carnivorous eaters.
[01:29:25.540 --> 01:29:27.500]   I thought it was because the corner pieces of lasagna
[01:29:27.500 --> 01:29:27.980]   are the best--
[01:29:27.980 --> 01:29:29.100]   The best, more corners.
[01:29:29.100 --> 01:29:30.420]   --the cheese gets more crunchy.
[01:29:30.420 --> 01:29:32.020]   This is a 12-corner pan.
[01:29:32.020 --> 01:29:32.660]   Yeah, see?
[01:29:32.660 --> 01:29:35.780]   Why have a four-corner pan when you could have 12 corners?
[01:29:35.780 --> 01:29:37.620]   They have a brownie pan like that, too,
[01:29:37.620 --> 01:29:39.260]   where every piece is an edge piece.
[01:29:39.260 --> 01:29:41.100]   Yes.
[01:29:41.100 --> 01:29:43.060]   Because we live in a really--
[01:29:43.060 --> 01:29:45.380]   That's on Micah's favorite things list.
[01:29:45.380 --> 01:29:46.860]   Lisa made me buy.
[01:29:46.860 --> 01:29:49.700]   Micah, if you tweet that list, I will probably buy some--
[01:29:49.700 --> 01:29:50.700]   I would buy Micah's list.
[01:29:50.700 --> 01:29:51.700]   I'm serious.
[01:29:51.700 --> 01:29:53.260]   But you have to write every description.
[01:29:53.260 --> 01:29:56.820]   Lisa made me buy a muffin tin, because I would make--
[01:29:56.820 --> 01:29:57.460]   there it is--
[01:29:57.460 --> 01:29:59.900]   Baker's Edge nonstick edge brownie pan.
[01:29:59.900 --> 01:30:02.860]   It looks like a little maze for brownies, a brownie maze.
[01:30:02.860 --> 01:30:04.820]   A delicious dessert maze.
[01:30:04.820 --> 01:30:06.620]   It's amazing.
[01:30:06.620 --> 01:30:08.580]   I used to make breakfast muffins.
[01:30:08.580 --> 01:30:11.420]   And Lisa would have tear the top off, and not eat the bottom.
[01:30:11.420 --> 01:30:12.420]   The tops, yeah.
[01:30:12.420 --> 01:30:13.420]   Muffin tops.
[01:30:13.420 --> 01:30:14.420]   So she'd bawling--
[01:30:14.420 --> 01:30:15.900]   It'd be an entire side-filled episode
[01:30:15.900 --> 01:30:16.180]   about the muffin tops.
[01:30:16.180 --> 01:30:16.980]   That's right.
[01:30:16.980 --> 01:30:19.180]   And what happens to the bottoms, right?
[01:30:19.180 --> 01:30:23.020]   So you can buy a muffin top tin.
[01:30:23.020 --> 01:30:24.220]   Just don't recommend it.
[01:30:24.220 --> 01:30:25.220]   It only makes the tops.
[01:30:25.220 --> 01:30:26.220]   How are the bottoms?
[01:30:26.220 --> 01:30:27.540]   Well, it's very shallow.
[01:30:27.540 --> 01:30:28.180]   Oh, OK.
[01:30:28.180 --> 01:30:29.500]   Soapy.
[01:30:29.500 --> 01:30:30.580]   I have it if you want it.
[01:30:30.580 --> 01:30:32.260]   I'll send it along to you.
[01:30:32.260 --> 01:30:33.420]   I'll pass on that one.
[01:30:33.420 --> 01:30:33.920]   Yeah.
[01:30:33.920 --> 01:30:34.420]   One of my lips.
[01:30:34.420 --> 01:30:36.020]   You don't really need that.
[01:30:36.020 --> 01:30:40.180]   Organic coffee infused vermont maple syrup.
[01:30:40.180 --> 01:30:44.500]   For those of you who I used to drink maple syrup infused coffee,
[01:30:44.500 --> 01:30:45.340]   that was good.
[01:30:45.340 --> 01:30:47.300]   Oh, for one moment, I thought you were scuttling
[01:30:47.300 --> 01:30:48.580]   up the coffee part of that.
[01:30:48.580 --> 01:30:50.020]   I love maple syrup.
[01:30:50.020 --> 01:30:52.420]   Every day I start with a shot of maple syrup.
[01:30:52.420 --> 01:30:55.340]   Well, it goes great with your holiday dippers
[01:30:55.340 --> 01:30:59.460]   by Eli's Cheesecake.
[01:30:59.460 --> 01:31:01.140]   It's a-- What is a holiday dipper?
[01:31:01.140 --> 01:31:03.220]   It's a cheesecake on a stick.
[01:31:03.220 --> 01:31:03.940]   So a lot of--
[01:31:03.940 --> 01:31:04.780]   A festive consolation.
[01:31:04.780 --> 01:31:08.220]   [LAUGHTER]
[01:31:08.220 --> 01:31:09.220]   Oh.
[01:31:09.220 --> 01:31:11.500]   And here's-- they have to show pictures of Oprah
[01:31:11.500 --> 01:31:13.460]   trying this stuff, or you wouldn't believe it.
[01:31:13.460 --> 01:31:14.460]   Oh, she's using her--
[01:31:14.460 --> 01:31:15.460]   She's a Clarisonic.
[01:31:15.460 --> 01:31:16.620]   Yeah, I use one of those.
[01:31:16.620 --> 01:31:17.900]   Yeah, here she comes.
[01:31:17.900 --> 01:31:18.420]   Here, Oprah.
[01:31:18.420 --> 01:31:19.940]   But the pictures make it look like she spends
[01:31:19.940 --> 01:31:21.460]   like all of five minutes on each product.
[01:31:21.460 --> 01:31:22.300]   Yeah, you know.
[01:31:22.300 --> 01:31:25.060]   This is like-- here, let's-- let me--
[01:31:25.060 --> 01:31:27.020]   Oh, this is just amazing.
[01:31:27.020 --> 01:31:29.740]   You know, Amazon is almost love that we're giving them
[01:31:29.740 --> 01:31:30.340]   for advertising.
[01:31:30.340 --> 01:31:35.780]   This guy makes $400,000 a year showing Oprah's
[01:31:35.780 --> 01:31:38.660]   correct, ridiculous.
[01:31:38.660 --> 01:31:40.420]   And the thing I'm also excited about is
[01:31:40.420 --> 01:31:41.820]   picking up Goats Opere John.
[01:31:41.820 --> 01:31:43.460]   Like, that's what you do for the year,
[01:31:43.460 --> 01:31:46.060]   is you're like, ooh, but the Transnoot soap is here.
[01:31:46.060 --> 01:31:47.060]   [LAUGHTER]
[01:31:47.060 --> 01:31:48.380]   So it's favorite.
[01:31:48.380 --> 01:31:48.900]   They shape the paper.
[01:31:48.900 --> 01:31:50.300]   Oprah's favorite thing.
[01:31:50.300 --> 01:31:52.820]   I'm a connoisseur of fine goat soap.
[01:31:52.820 --> 01:31:54.140]   Goat soap's good.
[01:31:54.140 --> 01:31:56.220]   If you don't mind smelling like a goat--
[01:31:56.220 --> 01:31:57.860]   [LAUGHTER]
[01:31:57.860 --> 01:31:59.980]   Well, here's lots of videos of Oprah--
[01:31:59.980 --> 01:32:00.780]   wait a minute.
[01:32:00.780 --> 01:32:01.780]   I think I see this.
[01:32:01.780 --> 01:32:04.220]   Oprah trying a smokeless indoor grill.
[01:32:04.220 --> 01:32:05.580]   Oh, this grill.
[01:32:05.580 --> 01:32:08.180]   This can only end in disaster.
[01:32:08.180 --> 01:32:08.780]   It's going to--
[01:32:08.780 --> 01:32:10.260]   No, she's not really tasting the grill.
[01:32:10.260 --> 01:32:11.620]   She's eating the burger.
[01:32:11.620 --> 01:32:13.380]   She's not tasting the grill.
[01:32:13.380 --> 01:32:14.380]   [LAUGHTER]
[01:32:14.380 --> 01:32:15.980]   Oh, there's Oprah's friend.
[01:32:15.980 --> 01:32:16.540]   What's her name?
[01:32:16.540 --> 01:32:17.020]   Gail.
[01:32:17.020 --> 01:32:17.020]   Gail.
[01:32:17.020 --> 01:32:17.940]   Gail is on.
[01:32:17.940 --> 01:32:18.700]   Aw.
[01:32:18.700 --> 01:32:19.900]   Well, that's her best friend, right?
[01:32:19.900 --> 01:32:20.900]   It's good to be Gail.
[01:32:20.900 --> 01:32:22.900]   But to be Gail, that's who gets all the extras.
[01:32:22.900 --> 01:32:24.260]   She's like, here.
[01:32:24.260 --> 01:32:27.060]   Oh, look, they have little stickers printed up, yes or no.
[01:32:27.060 --> 01:32:27.780]   And they've got a yes.
[01:32:27.780 --> 01:32:28.700]   Oh, that's kind of fun.
[01:32:28.700 --> 01:32:30.100]   I wouldn't be part of that.
[01:32:30.100 --> 01:32:30.900]   All right.
[01:32:30.900 --> 01:32:32.300]   You get a yes.
[01:32:32.300 --> 01:32:34.500]   This is a long list.
[01:32:34.500 --> 01:32:36.180]   Holy cow.
[01:32:36.180 --> 01:32:38.980]   And this is all-- so Amazon sponsors this, basically.
[01:32:38.980 --> 01:32:41.660]   So you can buy all this stuff on Amazon.
[01:32:41.660 --> 01:32:43.420]   They got like a burger kit.
[01:32:43.420 --> 01:32:44.500]   Not just a burger kit.
[01:32:44.500 --> 01:32:46.700]   It's a truffle burger kit.
[01:32:46.700 --> 01:32:48.380]   See, this is when I saw this.
[01:32:48.380 --> 01:32:50.180]   She recommended this, which is there
[01:32:50.180 --> 01:32:51.980]   are many 360 degree cameras.
[01:32:51.980 --> 01:32:53.740]   I happen-- I don't know anything about burger kits.
[01:32:53.740 --> 01:32:57.180]   But I know that you should not buy the Theta SC360 still
[01:32:57.180 --> 01:32:59.020]   in video camera by Rico.
[01:32:59.020 --> 01:33:01.700]   So what I'm admiring about the way this is set up
[01:33:01.700 --> 01:33:05.380]   is you've got these beauty shots of the products.
[01:33:05.380 --> 01:33:07.820]   And then you've got Oprah's personal endorsement.
[01:33:07.820 --> 01:33:10.260]   There are no price tags.
[01:33:10.260 --> 01:33:12.460]   Well, you shouldn't have to worry about how much is going
[01:33:12.460 --> 01:33:12.820]   to cost.
[01:33:12.820 --> 01:33:14.380]   I just think it's very, very interesting
[01:33:14.380 --> 01:33:15.820]   that even when you click through--
[01:33:15.820 --> 01:33:18.540]   I've seen, for example, the slow juicer,
[01:33:18.540 --> 01:33:19.620]   the initial picture--
[01:33:19.620 --> 01:33:19.980]   That's quick through.
[01:33:19.980 --> 01:33:20.900]   --and Oprah's favorite thing.
[01:33:20.900 --> 01:33:22.460]   Yeah, it's $559.
[01:33:22.460 --> 01:33:23.300]   See, there you go.
[01:33:23.300 --> 01:33:23.300]   And--
[01:33:23.300 --> 01:33:24.300]   Sure.
[01:33:24.300 --> 01:33:24.800]   --I think--
[01:33:24.800 --> 01:33:25.940]   But by then, you're in.
[01:33:25.940 --> 01:33:27.220]   I am betting that--
[01:33:27.220 --> 01:33:28.860]   well, and they've got the data on you.
[01:33:28.860 --> 01:33:29.540]   What did you click?
[01:33:29.540 --> 01:33:29.940]   And what's--
[01:33:29.940 --> 01:33:31.580]   Oh my god, I just told them.
[01:33:31.580 --> 01:33:33.100]   And what's your price limit?
[01:33:33.100 --> 01:33:33.620]   Yeah.
[01:33:33.620 --> 01:33:36.140]   And it's probably got an Oprah tag on there.
[01:33:36.140 --> 01:33:37.860]   Bezos is already in your closet, though.
[01:33:37.860 --> 01:33:39.500]   So you know you were about to click it.
[01:33:39.500 --> 01:33:43.540]   I'm just saying that this is usually with magazine gift
[01:33:43.540 --> 01:33:47.420]   guides, they almost always have price tags attached.
[01:33:47.420 --> 01:33:49.940]   And what I find interesting about this Amazon one
[01:33:49.940 --> 01:33:54.620]   is you see the product by the third exposure to the product.
[01:33:54.620 --> 01:33:55.980]   That's when you finally get the price.
[01:33:55.980 --> 01:33:58.860]   But by that point, you've already seen it twice
[01:33:58.860 --> 01:34:00.220]   and are clearly committed to--
[01:34:00.220 --> 01:34:00.980]   It's in my head.
[01:34:00.980 --> 01:34:01.980]   No, it's average tag.
[01:34:01.980 --> 01:34:02.480]   Yeah.
[01:34:02.480 --> 01:34:04.100]   I hate when they make you put it in the cart
[01:34:04.100 --> 01:34:05.540]   before you can see the price.
[01:34:05.540 --> 01:34:07.580]   It's like you can see the price of this in your cart.
[01:34:07.580 --> 01:34:12.100]   Nothing makes me feel like old manuals at cloud like that
[01:34:12.100 --> 01:34:13.980]   where you'll see the price.
[01:34:13.980 --> 01:34:15.740]   No, I won't see the price.
[01:34:15.740 --> 01:34:16.700]   And I'm not getting the price.
[01:34:16.700 --> 01:34:17.180]   Yeah, exactly.
[01:34:17.180 --> 01:34:18.660]   I'm like, no, I'm not putting it in my cart.
[01:34:18.660 --> 01:34:22.060]   So why do they do that, by the way?
[01:34:22.060 --> 01:34:23.460]   Just to see if you're willing to buy,
[01:34:23.460 --> 01:34:25.060]   and then if you reject it, they know
[01:34:25.060 --> 01:34:26.100]   that the price is too high.
[01:34:26.100 --> 01:34:26.540]   Probably.
[01:34:26.540 --> 01:34:28.540]   Yeah.
[01:34:28.540 --> 01:34:31.740]   So Wesley wanted to know about Amazon Echo murders.
[01:34:31.740 --> 01:34:33.540]   Mm-hmm.
[01:34:33.540 --> 01:34:35.700]   So here for you, Wesley.
[01:34:35.700 --> 01:34:36.940]   New Hampshire judge--
[01:34:36.940 --> 01:34:38.660]   I am not affiliated with the murders.
[01:34:38.660 --> 01:34:40.580]   I'll just say it's not--
[01:34:40.580 --> 01:34:41.060]   IBM's not--
[01:34:41.060 --> 01:34:43.300]   He was in Boston at the time.
[01:34:43.300 --> 01:34:43.820]   But you know what?
[01:34:43.820 --> 01:34:47.860]   We could find out because we're getting all of the Echo stuff.
[01:34:47.860 --> 01:34:53.260]   Judge has ordered the Amazon handover data in a 2017 murder
[01:34:53.260 --> 01:34:53.540]   case.
[01:34:56.660 --> 01:34:58.980]   They have a suspect who was pleaded not guilty.
[01:34:58.980 --> 01:35:02.380]   There will be a trial in May.
[01:35:02.380 --> 01:35:07.460]   And so what the police asked for is not only all the Amazon
[01:35:07.460 --> 01:35:08.940]   Echo audio files--
[01:35:08.940 --> 01:35:11.940]   because frankly, I don't know if that would be useful--
[01:35:11.940 --> 01:35:14.820]   but associated data which might be like what phones were
[01:35:14.820 --> 01:35:18.140]   paired to the smart speakers.
[01:35:18.140 --> 01:35:19.700]   So you could know--
[01:35:19.700 --> 01:35:21.380]   does Amazon know when you're home?
[01:35:21.380 --> 01:35:23.380]   Yeah, because your phone arrived.
[01:35:23.380 --> 01:35:23.900]   Right?
[01:35:23.900 --> 01:35:24.900]   Mm-hmm.
[01:35:24.900 --> 01:35:30.340]   Um, prosecutors believe there's probable cause
[01:35:30.340 --> 01:35:33.700]   to think there's evidence on the Echo, like audio recordings
[01:35:33.700 --> 01:35:34.580]   of the attack.
[01:35:34.580 --> 01:35:37.380]   When you're getting murdered, you don't go, Echo, record this.
[01:35:37.380 --> 01:35:39.860]   [LAUGHTER]
[01:35:39.860 --> 01:35:40.780]   No, you don't.
[01:35:40.780 --> 01:35:41.380]   It was--
[01:35:41.380 --> 01:35:43.300]   [GROANS]
[01:35:43.300 --> 01:35:45.300]   That's not-- that's not likely.
[01:35:45.300 --> 01:35:48.700]   Well, what I find interesting is Amazon's official policy
[01:35:48.700 --> 01:35:50.540]   is, well, we didn't seek to obstruct justice.
[01:35:50.540 --> 01:35:52.900]   We're just protecting the privacy rights of Echo users.
[01:35:52.900 --> 01:35:53.500]   Right.
[01:35:53.500 --> 01:35:54.820]   So they fought it.
[01:35:54.820 --> 01:35:57.540]   But the thing is, Amazon has never really explicitly
[01:35:57.540 --> 01:36:00.860]   outlined what your privacy rights are as an Echo user,
[01:36:00.860 --> 01:36:03.300]   or specifically what the relationship is with your data.
[01:36:03.300 --> 01:36:05.540]   So what rights are they protecting?
[01:36:05.540 --> 01:36:09.820]   Have they defined those rights to begin with?
[01:36:09.820 --> 01:36:13.620]   Amazon told the Associated Press it would not
[01:36:13.620 --> 01:36:16.740]   give up data without a valid and binding legal demand
[01:36:16.740 --> 01:36:17.980]   properly served on us.
[01:36:17.980 --> 01:36:20.580]   So you can't just go over to Amazon and say, can I just--
[01:36:20.580 --> 01:36:21.900]   I'd like to take a look at that.
[01:36:21.900 --> 01:36:23.500]   I'd like to one click on this download, please.
[01:36:23.500 --> 01:36:25.940]   Yeah.
[01:36:25.940 --> 01:36:28.220]   Remember the same thing happened in Arkansas.
[01:36:28.220 --> 01:36:31.300]   And Amazon refused and eventually didn't
[01:36:31.300 --> 01:36:33.460]   have to hand it over because they had other evidence that
[01:36:33.460 --> 01:36:35.980]   was effective.
[01:36:35.980 --> 01:36:37.660]   I feel like police are going to--
[01:36:37.660 --> 01:36:40.260]   and I don't blame them if they're trying to solve a crime
[01:36:40.260 --> 01:36:41.660]   or trying to build a case--
[01:36:41.660 --> 01:36:43.340]   this is in this case probably the prosecutor's
[01:36:43.340 --> 01:36:44.620]   trying to build a case--
[01:36:44.620 --> 01:36:47.220]   ask for whatever they can get.
[01:36:47.220 --> 01:36:49.180]   Go to the phone company, subpoena all the phone records.
[01:36:49.180 --> 01:36:51.700]   They don't know if there's anything there.
[01:36:51.700 --> 01:36:53.260]   But they're going to find everything.
[01:36:53.260 --> 01:36:55.100]   And that's kind of the issue.
[01:36:55.100 --> 01:36:58.580]   And this goes to another case we talked about last week
[01:36:58.580 --> 01:37:02.020]   where a judge ruled that you can't force somebody
[01:37:02.020 --> 01:37:06.420]   to give the password up on their phone unless you have
[01:37:06.420 --> 01:37:10.940]   a specific bit of information you're looking for.
[01:37:10.940 --> 01:37:12.340]   I think that there is this notion
[01:37:12.340 --> 01:37:15.340]   that you're protected against law enforcement
[01:37:15.340 --> 01:37:17.180]   or prosecutorial phishing expeditions.
[01:37:17.180 --> 01:37:18.500]   Well, there might be something there.
[01:37:18.500 --> 01:37:20.580]   Let's just see what we can find.
[01:37:20.580 --> 01:37:22.300]   Maybe there'll be something there.
[01:37:22.300 --> 01:37:23.980]   That's not it.
[01:37:23.980 --> 01:37:26.500]   In this case, the judge said, nope.
[01:37:26.500 --> 01:37:31.100]   And so I don't know how much the prosecutors told the judge,
[01:37:31.100 --> 01:37:34.140]   like they said there's probable cause
[01:37:34.140 --> 01:37:36.620]   to believe there's evidence on the echo.
[01:37:36.620 --> 01:37:38.740]   Why would-- what's the probable cause?
[01:37:38.740 --> 01:37:41.100]   Echo doesn't record everything.
[01:37:41.100 --> 01:37:41.540]   It only records--
[01:37:41.540 --> 01:37:43.260]   Wouldn't it be a lower bar to say,
[01:37:43.260 --> 01:37:47.620]   can you show me if the echo was triggered and for how long?
[01:37:47.620 --> 01:37:50.740]   And that way they can get information to know, like,
[01:37:50.740 --> 01:37:53.260]   oh, well, we know the murders are here or the alibi
[01:37:53.260 --> 01:37:55.860]   for the suspect is for this period.
[01:37:55.860 --> 01:37:58.100]   And so that's the only snippet that
[01:37:58.100 --> 01:38:01.220]   could pertain to this case instead of asking for the whole day.
[01:38:01.220 --> 01:38:05.980]   Yeah, but it doesn't sound like that's what they said.
[01:38:05.980 --> 01:38:09.740]   They said we want all the recordings for that time.
[01:38:09.740 --> 01:38:14.300]   As if they knew that the victim shouted echo right
[01:38:14.300 --> 01:38:15.980]   before she was stabbed, I don't know.
[01:38:16.980 --> 01:38:17.980]   I don't know.
[01:38:17.980 --> 01:38:20.980]   I worry about-- see, this is the problem
[01:38:20.980 --> 01:38:22.980]   because we have all these technological marvels
[01:38:22.980 --> 01:38:24.980]   in our home that do have information
[01:38:24.980 --> 01:38:26.980]   and I worry about police just saying,
[01:38:26.980 --> 01:38:27.980]   well, we might as well just ask for it.
[01:38:27.980 --> 01:38:28.980]   Yeah.
[01:38:28.980 --> 01:38:29.980]   Let's see what we can find.
[01:38:29.980 --> 01:38:30.980]   Yeah.
[01:38:30.980 --> 01:38:31.980]   Because that's not actually supposed to happen.
[01:38:31.980 --> 01:38:33.980]   Again, if you're the one who's voluntarily
[01:38:33.980 --> 01:38:35.980]   bringing this surveillance device into your home--
[01:38:35.980 --> 01:38:38.980]   Oh, but maybe you're opening yourself up, you think?
[01:38:38.980 --> 01:38:39.980]   No.
[01:38:39.980 --> 01:38:40.980]   No.
[01:38:40.980 --> 01:38:42.980]   But what about the rights of the people in the room?
[01:38:42.980 --> 01:38:43.980]   Yeah.
[01:38:43.980 --> 01:38:44.980]   That didn't opt into this.
[01:38:44.980 --> 01:38:44.980]   Yeah.
[01:38:44.980 --> 01:38:44.980]   Right?
[01:38:44.980 --> 01:38:46.980]   The murderer didn't opt in.
[01:38:46.980 --> 01:38:47.980]   Exactly.
[01:38:47.980 --> 01:38:48.980]   Yeah.
[01:38:48.980 --> 01:38:50.980]   The murderer didn't want to know.
[01:38:50.980 --> 01:38:54.980]   That would be a heck of a case.
[01:38:54.980 --> 01:38:56.980]   Echo, record this.
[01:38:56.980 --> 01:38:58.980]   That's why you want a spot.
[01:38:58.980 --> 01:38:59.980]   So if somebody merges me in my closet--
[01:38:59.980 --> 01:39:00.980]   I did not agree.
[01:39:00.980 --> 01:39:01.980]   I mean, the murderer got it.
[01:39:01.980 --> 01:39:02.980]   Exactly.
[01:39:02.980 --> 01:39:03.980]   You're in your closet.
[01:39:03.980 --> 01:39:04.980]   You see somebody.
[01:39:04.980 --> 01:39:05.980]   You're like, all right, you've got to get the phone filled.
[01:39:05.980 --> 01:39:06.980]   I'm going to record this in the video!
[01:39:06.980 --> 01:39:07.980]   Send it off!
[01:39:07.980 --> 01:39:09.980]   And I have it on my phone.
[01:39:09.980 --> 01:39:13.980]   A shortcut so that when I get pulled over by the po-po--
[01:39:13.980 --> 01:39:15.980]   Oh, yeah, I saw that shortcut.
[01:39:15.980 --> 01:39:16.980]   Yeah.
[01:39:16.980 --> 01:39:21.980]   I don't know if I'll have the presence of mind to use it.
[01:39:21.980 --> 01:39:23.980]   But it's kind of interesting.
[01:39:23.980 --> 01:39:29.980]   It's called-- I think I say, "Ciri, I'm getting pulled over."
[01:39:29.980 --> 01:39:31.980]   And then this is what it does.
[01:39:31.980 --> 01:39:33.980]   It pauses the music, turns on, "Do not disturb."
[01:39:33.980 --> 01:39:37.980]   Sets the brightness to zero so they can't see what my phone's doing.
[01:39:37.980 --> 01:39:40.980]   Yeah, this is from-- this is not the ACLU app.
[01:39:40.980 --> 01:39:43.980]   This is an Apple series shortcut.
[01:39:43.980 --> 01:39:45.980]   There is an ACLU app.
[01:39:45.980 --> 01:39:46.980]   This isn't that.
[01:39:46.980 --> 01:39:51.980]   Gets the current location, sends a message to my wife saying, "I'm getting pulled over.
[01:39:51.980 --> 01:39:54.980]   My current location is here, latitude and longitude."
[01:39:54.980 --> 01:40:01.980]   Then it opens the camera up, starts shooting a video, saves that video to the photo album,
[01:40:01.980 --> 01:40:05.980]   and then sends that to my blog.
[01:40:05.980 --> 01:40:09.980]   Here's a video of the police interaction.
[01:40:09.980 --> 01:40:16.980]   Robert A. Pearson put this up on Reddit, uploads the video to the iCloud, into the Dropbox,
[01:40:16.980 --> 01:40:20.980]   and-- oh, I have to give it access to Dropbox.
[01:40:20.980 --> 01:40:21.980]   I'll do that after the show.
[01:40:21.980 --> 01:40:24.980]   And then it turns everything back on.
[01:40:24.980 --> 01:40:25.980]   I love that, honestly.
[01:40:25.980 --> 01:40:27.980]   I mean, I think that--
[01:40:27.980 --> 01:40:30.980]   That's the best use to app shortcuts I've ever seen.
[01:40:30.980 --> 01:40:31.980]   Yeah, exactly.
[01:40:31.980 --> 01:40:36.980]   Because genuinely, I was going through that whole website looking for like, which-- what--
[01:40:36.980 --> 01:40:39.980]   none of these make any sense or things that I need.
[01:40:39.980 --> 01:40:42.980]   And I saw that one, and I was like, "This is a public service.
[01:40:42.980 --> 01:40:44.980]   This is really cool."
[01:40:44.980 --> 01:40:45.980]   Yeah.
[01:40:45.980 --> 01:40:49.980]   I don't actually get arrested or pulled over because I'm white, and then adult ale.
[01:40:49.980 --> 01:40:52.980]   I got pulled over for the first time the other day.
[01:40:52.980 --> 01:40:56.980]   I was on the highway, and so I worked from home, so I hardly ever drive my car anywhere.
[01:40:56.980 --> 01:41:04.980]   I was on the highway, and I had completely forgotten that my registration tag on my license plate
[01:41:04.980 --> 01:41:08.980]   expired, and never have I ever before been pulled over.
[01:41:08.980 --> 01:41:15.980]   So I was freaking out, but playing it cool, but I was still very scared because I just never had that happen before.
[01:41:15.980 --> 01:41:18.980]   And thank goodness the guy was super nice and everything went well.
[01:41:18.980 --> 01:41:24.980]   But just that fear that exists there, it's good to have that if you need it.
[01:41:24.980 --> 01:41:25.980]   It's got to be a tense interaction.
[01:41:25.980 --> 01:41:31.980]   And I also feel for the law enforcement officer, because he or she's walking up to a car.
[01:41:31.980 --> 01:41:33.980]   You don't know what the heck's going on there.
[01:41:33.980 --> 01:41:37.980]   But somebody who has expired registration could be anything.
[01:41:37.980 --> 01:41:38.980]   Yeah.
[01:41:38.980 --> 01:41:40.980]   Especially because you're a little brown.
[01:41:40.980 --> 01:41:42.980]   You could be a drug dealer.
[01:41:42.980 --> 01:41:43.980]   Yeah.
[01:41:43.980 --> 01:41:44.980]   I am, in fact.
[01:41:44.980 --> 01:41:46.980]   You know what I tell my kids?
[01:41:46.980 --> 01:41:48.980]   When you get pulled over, put your hands on the wheel.
[01:41:48.980 --> 01:41:50.980]   Don't move them.
[01:41:50.980 --> 01:41:51.980]   Yeah.
[01:41:51.980 --> 01:41:55.980]   Sit them there, and then when the officer asks for your license registration to say, "Okay, it's in my glove compartment.
[01:41:55.980 --> 01:41:57.980]   Is it all right if I reach down there now?"
[01:41:57.980 --> 01:41:58.980]   Yeah.
[01:41:58.980 --> 01:41:59.980]   And that's exactly what I did.
[01:41:59.980 --> 01:42:03.980]   I explained as I was moving around in my car.
[01:42:03.980 --> 01:42:05.980]   I mean, that's what we all get told.
[01:42:05.980 --> 01:42:06.980]   It's terrifying.
[01:42:06.980 --> 01:42:07.980]   Yep.
[01:42:07.980 --> 01:42:09.980]   You know?
[01:42:09.980 --> 01:42:13.980]   And much more so for some people than others, unfortunately.
[01:42:13.980 --> 01:42:18.980]   The DEA and ICE are hiding surveillance.
[01:42:18.980 --> 01:42:21.980]   Are people pretty nice in Austin to you, Wesley?
[01:42:21.980 --> 01:42:23.980]   They know you.
[01:42:23.980 --> 01:42:26.980]   No, nobody knows me.
[01:42:26.980 --> 01:42:28.980]   I don't know.
[01:42:28.980 --> 01:42:29.980]   You ran for, wait a minute.
[01:42:29.980 --> 01:42:30.980]   You ran for office.
[01:42:30.980 --> 01:42:31.980]   Yeah.
[01:42:31.980 --> 01:42:32.980]   Yeah.
[01:42:32.980 --> 01:42:33.980]   You're well known.
[01:42:33.980 --> 01:42:36.980]   Well, I would have won if I was well known.
[01:42:36.980 --> 01:42:37.980]   Oh.
[01:42:37.980 --> 01:42:38.980]   Yeah.
[01:42:38.980 --> 01:42:39.980]   Yeah.
[01:42:39.980 --> 01:42:43.980]   I've had my first share of problems with the cops.
[01:42:43.980 --> 01:42:44.980]   Like, here's my phone.
[01:42:44.980 --> 01:42:46.980]   See if you can see it.
[01:42:46.980 --> 01:42:47.980]   Yeah.
[01:42:47.980 --> 01:42:52.980]   And if you click it, I don't know if you can see that.
[01:42:52.980 --> 01:42:53.980]   What does it say?
[01:42:53.980 --> 01:42:55.980]   It says, "I do not consent to search."
[01:42:55.980 --> 01:42:56.980]   Oh, nice.
[01:42:56.980 --> 01:42:58.980]   Does that work?
[01:42:58.980 --> 01:43:00.980]   Oh, I hope not.
[01:43:00.980 --> 01:43:01.980]   I mean, I hope not.
[01:43:01.980 --> 01:43:03.980]   Let me put that on my phone.
[01:43:03.980 --> 01:43:04.980]   I do not consent to search.
[01:43:04.980 --> 01:43:05.980]   That should stop everything.
[01:43:05.980 --> 01:43:06.980]   Yeah.
[01:43:06.980 --> 01:43:07.980]   Oh, I'm sorry, sir.
[01:43:07.980 --> 01:43:09.980]   We'll let you go.
[01:43:09.980 --> 01:43:10.980]   Yeah.
[01:43:10.980 --> 01:43:11.980]   Yeah.
[01:43:11.980 --> 01:43:12.980]   Yeah.
[01:43:12.980 --> 01:43:14.980]   There's probably going to be scary.
[01:43:14.980 --> 01:43:17.980]   If you're an African American, it's got to be terrifying.
[01:43:17.980 --> 01:43:23.980]   But again, I also understand police officers who have to confront unknown situations every day.
[01:43:23.980 --> 01:43:24.980]   And that's scary too.
[01:43:24.980 --> 01:43:25.980]   I get it.
[01:43:25.980 --> 01:43:26.980]   I get it.
[01:43:26.980 --> 01:43:28.980]   Well, I would -- a little off topic.
[01:43:28.980 --> 01:43:31.980]   So my sister went through the police academy.
[01:43:31.980 --> 01:43:38.980]   And the paramilitary style training that they give cops is that they always perceive that
[01:43:38.980 --> 01:43:39.980]   there's a danger.
[01:43:39.980 --> 01:43:40.980]   Yes.
[01:43:40.980 --> 01:43:45.980]   Better go to court than come home in a box, kind of a thing.
[01:43:45.980 --> 01:43:51.980]   And I think that persistent drilling of people are dangerous.
[01:43:51.980 --> 01:43:55.980]   And the scenarios they build up is inherent to the system.
[01:43:55.980 --> 01:44:04.740]   And the way you're set up, it doesn't matter if what color you are, but it amps up people's
[01:44:04.740 --> 01:44:06.740]   perception of there might be danger.
[01:44:06.740 --> 01:44:13.700]   And so if you see someone who is disarming, then you're like, "Okay, well, I can relax
[01:44:13.700 --> 01:44:15.060]   for this person."
[01:44:15.060 --> 01:44:21.300]   But if someone who is remarkably matches in your brain could be a danger, it's no longer
[01:44:21.300 --> 01:44:23.820]   a five, it's now a 10 or a 50.
[01:44:23.820 --> 01:44:24.820]   That's right.
[01:44:24.820 --> 01:44:25.820]   That's right.
[01:44:25.820 --> 01:44:31.540]   There was in the Petaluma, there was law enforcement officers some years ago shot in
[01:44:31.540 --> 01:44:32.540]   the country.
[01:44:32.540 --> 01:44:39.460]   My wife, a day or two later, was driving in that area, clearly not a threat, but was
[01:44:39.460 --> 01:44:40.940]   pulled over by sheriffs.
[01:44:40.940 --> 01:44:44.860]   All five of them with guns drawn and aimed at her.
[01:44:44.860 --> 01:44:45.860]   Whoa.
[01:44:45.860 --> 01:44:47.820]   And it's exactly that.
[01:44:47.820 --> 01:44:50.980]   It's amped up, right?
[01:44:50.980 --> 01:44:55.780]   She doesn't, I think, look like a threat in any respect, but it's amped up because they
[01:44:55.780 --> 01:44:59.460]   were nervous because somebody had been shot a couple of days ago.
[01:44:59.460 --> 01:45:00.460]   Yeah.
[01:45:00.460 --> 01:45:05.300]   And that's inherently a dangerous situation if you've got five people with guns trained
[01:45:05.300 --> 01:45:06.300]   on you.
[01:45:06.300 --> 01:45:12.180]   And the authority is the biggest hammer that they have saying, "Do what I say."
[01:45:12.180 --> 01:45:13.180]   Yes.
[01:45:13.180 --> 01:45:14.180]   And people say, "Oh."
[01:45:14.180 --> 01:45:16.060]   They feel like, "Well, I said to do it."
[01:45:16.060 --> 01:45:22.460]   So people's rights get trampled all the time because people feel that their authority is
[01:45:22.460 --> 01:45:25.220]   being questioned.
[01:45:25.220 --> 01:45:26.780]   Even if the law is not being broken.
[01:45:26.780 --> 01:45:27.780]   Yes.
[01:45:27.780 --> 01:45:28.780]   And so that's also extremely scary.
[01:45:28.780 --> 01:45:34.780]   And there was like a teacher who was told to get out of the car and she says, "She asked
[01:45:34.780 --> 01:45:38.780]   why I think she was maybe 120 pounds."
[01:45:38.780 --> 01:45:42.020]   And she got yanked out of the car.
[01:45:42.020 --> 01:45:45.060]   And that happened here in Austin.
[01:45:45.060 --> 01:45:46.660]   It's because she asked why.
[01:45:46.660 --> 01:45:51.340]   And just questioning authority sometimes can just feel like an escalation to someone
[01:45:51.340 --> 01:45:54.780]   who feels that they have every right to tell you what to do.
[01:45:54.780 --> 01:45:57.700]   Be careful out there, kids.
[01:45:57.700 --> 01:46:01.780]   Every here of a company called Cowboy Street Light Concealments?
[01:46:01.780 --> 01:46:02.780]   No.
[01:46:02.780 --> 01:46:03.780]   Yes.
[01:46:03.780 --> 01:46:13.820]   According to courts, Cowboy Street Light Concealments has been selling hidden video cameras to
[01:46:13.820 --> 01:46:16.300]   ICE and the DEA.
[01:46:16.300 --> 01:46:17.900]   They get placed in streetlights.
[01:46:17.900 --> 01:46:21.420]   It's Cowboy Street Light Concealments.
[01:46:21.420 --> 01:46:26.740]   And we only know this because we've seen the bills, $22,000 since June for video recording
[01:46:26.740 --> 01:46:29.980]   and reproducing equipment, $28,000 from...
[01:46:29.980 --> 01:46:35.460]   That was for the DEA, $28,000 from ICE for the same period of time.
[01:46:35.460 --> 01:46:43.220]   So just be aware, it's probably not illegal to put hidden cameras in streetlights.
[01:46:43.220 --> 01:46:49.340]   They also apparently are placing covert surveillance cameras inside traffic barrels.
[01:46:49.340 --> 01:46:50.340]   You can buy this.
[01:46:50.340 --> 01:46:53.900]   Here's an ad for the covert traffic barrel shell.
[01:46:53.900 --> 01:46:58.260]   It's a PTZ camera, which means they can aim it.
[01:46:58.260 --> 01:46:59.260]   There's a lot of...
[01:46:59.260 --> 01:47:00.740]   Now, what is the idea that you...
[01:47:00.740 --> 01:47:02.660]   What can you see with one of those cameras?
[01:47:02.660 --> 01:47:03.660]   Is it...
[01:47:03.660 --> 01:47:06.500]   I guess because it's right there and you can aim it, you can see anything.
[01:47:06.500 --> 01:47:11.380]   It's a powerful, fully custom, pre-configured covert indoor...
[01:47:11.380 --> 01:47:13.980]   I'm sorry, outdoor digital vehicle surveillance system.
[01:47:13.980 --> 01:47:17.060]   What a great way to track license plate traffic.
[01:47:17.060 --> 01:47:18.060]   That's common.
[01:47:18.060 --> 01:47:19.060]   Okay, license plates.
[01:47:19.060 --> 01:47:20.060]   Because that's the only thing...
[01:47:20.060 --> 01:47:22.460]   You can just like point at a person and figure out something about...
[01:47:22.460 --> 01:47:23.460]   If you're doing...
[01:47:23.460 --> 01:47:24.460]   I mean, you could assume...
[01:47:24.460 --> 01:47:27.980]   For example, if you're doing surveillance and you want to figure out if there's somebody
[01:47:27.980 --> 01:47:31.620]   who has regular meetups and you want to establish a pattern where they know where they may
[01:47:31.620 --> 01:47:36.140]   know somebody, you can track how often they're driving a specific place.
[01:47:36.140 --> 01:47:38.380]   Is there any frequency to it?
[01:47:38.380 --> 01:47:43.300]   Can that frequency then be correlated to transfers of money or transfers of collateral?
[01:47:43.300 --> 01:47:45.380]   Here's the thing to look for.
[01:47:45.380 --> 01:47:52.020]   If in your town, instead of fixing potholes, they proposed a smart LED streetlight system.
[01:47:52.020 --> 01:47:57.260]   Apparently, this is exactly what they do.
[01:47:57.260 --> 01:47:58.260]   There's no oversight.
[01:47:58.260 --> 01:47:59.260]   There's no public debate.
[01:47:59.260 --> 01:48:01.580]   They just put in a smart LED streetlight system.
[01:48:01.580 --> 01:48:03.740]   Each light has a camera.
[01:48:03.740 --> 01:48:04.900]   Whoa.
[01:48:04.900 --> 01:48:08.140]   So it's not lights that are LED.
[01:48:08.140 --> 01:48:09.140]   They're smart.
[01:48:09.140 --> 01:48:11.220]   It's really deep, but then also a camera is built in.
[01:48:11.220 --> 01:48:13.100]   Yeah, they're smart because they have cameras in them.
[01:48:13.100 --> 01:48:14.100]   Lord have mercy.
[01:48:14.100 --> 01:48:20.940]   And by the way, of course, this ties into the story about Amazon offering face recognition
[01:48:20.940 --> 01:48:24.180]   to the Department of Homeland Security.
[01:48:24.180 --> 01:48:28.940]   You talked about China and the social currency system and facial recognition and all that,
[01:48:28.940 --> 01:48:30.500]   but it's not just China.
[01:48:30.500 --> 01:48:31.500]   Not just China.
[01:48:31.500 --> 01:48:34.860]   The truth is, it doesn't scare me that much that the government's doing this because
[01:48:34.860 --> 01:48:38.300]   I'm guessing this is somewhat targeted because these can't be super cheap.
[01:48:38.300 --> 01:48:41.020]   They have to spend the money where it makes sense.
[01:48:41.020 --> 01:48:46.460]   The problem is that you can't just trust the government to have this information.
[01:48:46.460 --> 01:48:49.540]   You have to trust the government not to ever lose this information.
[01:48:49.540 --> 01:48:55.460]   And so if anybody cracks their system and gets access to this data, it could-- and how
[01:48:55.460 --> 01:49:02.980]   ubiquitous, like machine learning and facial recognition is to the general public, China
[01:49:02.980 --> 01:49:08.700]   could get it or whatever and be able to pull in a whole bunch of information.
[01:49:08.700 --> 01:49:11.300]   And I just don't trust the government to keep this information.
[01:49:11.300 --> 01:49:12.300]   Yeah.
[01:49:12.300 --> 01:49:13.300]   No, that's a very good point.
[01:49:13.300 --> 01:49:18.260]   I don't trust people within the government not to use it for selfish or inappropriate ends
[01:49:18.260 --> 01:49:21.460]   because all you need is somebody who has a grudge against somebody else.
[01:49:21.460 --> 01:49:23.580]   I wanted my ex-wife's been driving down that street.
[01:49:23.580 --> 01:49:25.100]   I want to see where she's going.
[01:49:25.100 --> 01:49:26.100]   Exactly.
[01:49:26.100 --> 01:49:27.100]   Yeah.
[01:49:27.100 --> 01:49:28.100]   Yeah.
[01:49:28.100 --> 01:49:30.700]   We're putting cameras in the chat room.
[01:49:30.700 --> 01:49:32.940]   Somebody said, yeah, I think that's a good idea from now on.
[01:49:32.940 --> 01:49:33.940]   I'm keeping an eye.
[01:49:33.940 --> 01:49:35.860]   I'm keeping my eye on you.
[01:49:35.860 --> 01:49:37.580]   I have a camera on my front door.
[01:49:37.580 --> 01:49:42.660]   I think the other side of this is it's nice as an individual to have cameras on your property.
[01:49:42.660 --> 01:49:45.180]   I was never a big believer in that.
[01:49:45.180 --> 01:49:46.540]   But I have a camera on my front door.
[01:49:46.540 --> 01:49:47.540]   I have a ring video doorbell.
[01:49:47.540 --> 01:49:50.660]   And that's been very useful to see when somebody comes to the door to know when people
[01:49:50.660 --> 01:49:51.940]   are coming and going.
[01:49:51.940 --> 01:49:55.540]   When packages arrive, I know that they're there when somebody rings a doorbell.
[01:49:55.540 --> 01:49:58.980]   I can answer them even if I'm not home, which adds to the security in my house.
[01:49:58.980 --> 01:50:04.180]   Now, besides reinventing the doorbell, they've got the new home alarm system.
[01:50:04.180 --> 01:50:06.180]   This is awesome.
[01:50:06.180 --> 01:50:08.060]   Ring is one of our sponsors, I should mention.
[01:50:08.060 --> 01:50:12.420]   We all know traditional alarm companies make their money not so much in the gear, although
[01:50:12.420 --> 01:50:15.860]   they do seem to love having an installer come out and charge you thousands of dollars to
[01:50:15.860 --> 01:50:17.140]   put this stuff in.
[01:50:17.140 --> 01:50:22.580]   But then your troubles begin because they put you on a two or often three year contract
[01:50:22.580 --> 01:50:26.780]   at $45 or more a month for their monitoring.
[01:50:26.780 --> 01:50:29.940]   Ring has decided to change that entirely.
[01:50:29.940 --> 01:50:32.180]   The Ring system is easy to install.
[01:50:32.180 --> 01:50:33.180]   You could do it yourself.
[01:50:33.180 --> 01:50:36.300]   And by the way, it's easy to remove when you move.
[01:50:36.300 --> 01:50:38.180]   So it's great for renters.
[01:50:38.180 --> 01:50:40.140]   It's an affordable home security system.
[01:50:40.140 --> 01:50:41.860]   There are no long term contracts.
[01:50:41.860 --> 01:50:44.540]   You build a system that's right for your home.
[01:50:44.540 --> 01:50:48.300]   You can have it up and running in minutes with a base station that keeps your alarm system
[01:50:48.300 --> 01:50:50.700]   online and connected to mobile devices.
[01:50:50.700 --> 01:50:56.380]   A keypad, which arms and disarms your alarm system, contact sensors for your windows and
[01:50:56.380 --> 01:51:01.620]   doors, motion detectors to keep an eye on hallways and a range extender.
[01:51:01.620 --> 01:51:07.380]   So if you wanted to reach out to the garage or the shed, you could do that too.
[01:51:07.380 --> 01:51:10.220]   And the Ring Alarm Security Kit is very affordable.
[01:51:10.220 --> 01:51:15.500]   It gets you started with home security for $10 a month.
[01:51:15.500 --> 01:51:20.540]   No long term contract, professional monitoring, $10 a month.
[01:51:20.540 --> 01:51:22.140]   I love my rings.
[01:51:22.140 --> 01:51:27.700]   But this is a great alarm system for anybody, renter or homeowner that wants to protect
[01:51:27.700 --> 01:51:31.380]   their family, their loved ones, their house affordably.
[01:51:31.380 --> 01:51:36.140]   The Ring Alarm Security Kit available at Ring.com and retail stores all over the country.
[01:51:36.140 --> 01:51:37.900]   Everybody knows and trusts Ring.
[01:51:37.900 --> 01:51:41.060]   Now you can get home security from them for only $10 a month.
[01:51:41.060 --> 01:51:45.700]   Go to Ring.com/twit to learn more.
[01:51:45.700 --> 01:51:50.220]   Ring.com/twit.
[01:51:50.220 --> 01:51:52.020]   We gave you the bad news.
[01:51:52.020 --> 01:51:53.780]   I'll give you some good news.
[01:51:53.780 --> 01:51:55.340]   This is great.
[01:51:55.340 --> 01:52:00.420]   So Virus Total is a company owned by Chronicle, which is owned by Google.
[01:52:00.420 --> 01:52:08.020]   And it keeps track of, oops, it's also playing music in my ear, keeps track of malware.
[01:52:08.020 --> 01:52:14.660]   And the US Cyber Command has now started uploading malware samples that they collect
[01:52:14.660 --> 01:52:20.180]   from overseas, if you will, to Virus Total.
[01:52:20.180 --> 01:52:23.860]   And already Virus Total says this is amazing.
[01:52:23.860 --> 01:52:25.540]   We're getting some stuff we've never seen before.
[01:52:25.540 --> 01:52:29.940]   The first submission for something called LoJack malware included files that weren't
[01:52:29.940 --> 01:52:34.900]   previously in Virus Total.
[01:52:34.900 --> 01:52:44.220]   We've talked before about how exploits created or found or discovered and weaponized by the
[01:52:44.220 --> 01:52:47.420]   NSA and other government agencies have leaked out.
[01:52:47.420 --> 01:52:48.420]   And that's not good.
[01:52:48.420 --> 01:52:52.940]   This is good that they're at least keeping an eye on this stuff and then sharing it instead
[01:52:52.940 --> 01:52:57.660]   of keeping it themselves, sharing it to help us all be secure.
[01:52:57.660 --> 01:53:04.060]   So US Cyber Com's decision to provide these malware samples to Virus Total and let the
[01:53:04.060 --> 01:53:08.820]   world know about it is probably a good thing.
[01:53:08.820 --> 01:53:14.060]   Although there are those who are saying it's part of the new name and shame effort on the
[01:53:14.060 --> 01:53:18.380]   part of Western governments who have lately been very active and maybe this goes back
[01:53:18.380 --> 01:53:23.460]   to the Bloomberg Super Microcase in exposing and indicting Chinese, Russian, Iranian and
[01:53:23.460 --> 01:53:26.400]   North Korean hackers.
[01:53:26.400 --> 01:53:30.020]   Sometimes I worry we're being manipulated a little bit.
[01:53:30.020 --> 01:53:32.300]   You know why there's a real threat out there?
[01:53:32.300 --> 01:53:33.420]   We've got to do something about it.
[01:53:33.420 --> 01:53:34.420]   I don't know.
[01:53:34.420 --> 01:53:37.260]   Who would be doing the manipulating?
[01:53:37.260 --> 01:53:40.740]   Well, US CyberCom perhaps.
[01:53:40.740 --> 01:53:46.060]   You know, we talk about this Super Micro thing.
[01:53:46.060 --> 01:53:50.620]   You know, ad nauseum when it happened, the Bloomberg story and how all the companies
[01:53:50.620 --> 01:53:52.540]   involved denied it vigorously.
[01:53:52.540 --> 01:53:57.780]   The mandatory tractions Bloomberg has stood by its reporting and has not retracted.
[01:53:57.780 --> 01:54:00.460]   And we're really at a stalemate right now.
[01:54:00.460 --> 01:54:06.300]   There is the possible theory that Bloomberg was played by US intelligence officials who
[01:54:06.300 --> 01:54:11.900]   wanted to scare us about the supply chain in particular about stuff from China.
[01:54:11.900 --> 01:54:13.060]   Holy moly.
[01:54:13.060 --> 01:54:16.060]   I talked to Huawei the other day.
[01:54:16.060 --> 01:54:17.580]   You know, they make a really nice laptop.
[01:54:17.580 --> 01:54:19.300]   It's Chinese company.
[01:54:19.300 --> 01:54:21.260]   I think part owned by the Chinese government.
[01:54:21.260 --> 01:54:22.700]   So they're not necessarily our friends.
[01:54:22.700 --> 01:54:24.260]   But they make a beautiful laptop.
[01:54:24.260 --> 01:54:25.660]   They make an amazing phone.
[01:54:25.660 --> 01:54:27.820]   We're going to talk about that in a second.
[01:54:27.820 --> 01:54:31.820]   But that phone isn't sold in the United States because even though they were about to do
[01:54:31.820 --> 01:54:38.300]   a deal with AT&T and Verizon, the US government scared AT&T Verizon off said, no, you better
[01:54:38.300 --> 01:54:41.300]   not carry that Huawei Chinese phone.
[01:54:41.300 --> 01:54:46.260]   And Huawei's decided not to sell it in the United States because without a carrier deal,
[01:54:46.260 --> 01:54:47.340]   it's very hard to succeed.
[01:54:47.340 --> 01:54:51.700]   They don't want to spend the marketing money to just create demand for a phone they can't
[01:54:51.700 --> 01:54:52.700]   sell.
[01:54:52.700 --> 01:54:53.700]   Yeah.
[01:54:53.700 --> 01:54:57.340]   Same thing with 5G equipment that they don't want Chinese made 5G equipment right here
[01:54:57.340 --> 01:54:59.300]   in the States.
[01:54:59.300 --> 01:55:04.180]   Lenovo's Chinese, everything we buy is made in much of what we buy is made in China.
[01:55:04.180 --> 01:55:08.540]   So the supply chain is clearly a threat of vulnerability.
[01:55:08.540 --> 01:55:12.140]   But I also, it's hard to know what's true nowadays, isn't it?
[01:55:12.140 --> 01:55:13.300]   Oh, golly.
[01:55:13.300 --> 01:55:14.300]   Yeah.
[01:55:14.300 --> 01:55:16.140]   I just saw, I can't remember what it was.
[01:55:16.140 --> 01:55:22.020]   There was something just the other day where it was more of that technology that shows how
[01:55:22.020 --> 01:55:26.020]   folks are able to talk.
[01:55:26.020 --> 01:55:28.980]   And then it makes it look like the person is speaking.
[01:55:28.980 --> 01:55:33.540]   And we just had that whole story about the deep in press guy.
[01:55:33.540 --> 01:55:34.540]   Deep fakes.
[01:55:34.540 --> 01:55:35.540]   Yes, yes.
[01:55:35.540 --> 01:55:37.540]   And we have this story the other day.
[01:55:37.540 --> 01:55:42.540]   Jim Acosta, you know, sped it up and slowed it down just right to make it look the way
[01:55:42.540 --> 01:55:43.540]   that it did.
[01:55:43.540 --> 01:55:45.740]   It looked like he was karate shopping an intern when in fact he was just kind of fending
[01:55:45.740 --> 01:55:46.740]   her off.
[01:55:46.740 --> 01:55:49.420]   And some said that had been modified.
[01:55:49.420 --> 01:55:53.140]   The info wars editor who made the video said, no, no, I didn't modify it.
[01:55:53.140 --> 01:55:54.940]   I just zoomed in.
[01:55:54.940 --> 01:55:58.340]   Well, I don't know what's true, honestly.
[01:55:58.340 --> 01:55:59.540]   And that's the problem.
[01:55:59.540 --> 01:56:00.940]   It's very hard.
[01:56:00.940 --> 01:56:04.140]   If I mean, we're tech journalists, we can't even figure it out.
[01:56:04.140 --> 01:56:06.380]   I don't know how an average person is supposed to figure it out.
[01:56:06.380 --> 01:56:08.060]   It makes me feel really jaded.
[01:56:08.060 --> 01:56:13.900]   Honestly, I just sing so much stuff and I'm in a place where I'm going, do I believe this?
[01:56:13.900 --> 01:56:14.900]   Do I believe this?
[01:56:14.900 --> 01:56:17.900]   Well, and that's the ability to check everything, you know what I mean?
[01:56:17.900 --> 01:56:19.660]   But not everybody thinks about that.
[01:56:19.660 --> 01:56:20.660]   That's a well known.
[01:56:20.660 --> 01:56:27.460]   That means to add to pile on Russian technique, propaganda technique is confuse you, bury you
[01:56:27.460 --> 01:56:32.380]   under conflicting stories to the point where you don't trust anything you read.
[01:56:32.380 --> 01:56:39.580]   And then you have this Chinese AI anchor where you can just feed it whatever you want
[01:56:39.580 --> 01:56:43.740]   and it'll say the news exactly how the state says it.
[01:56:43.740 --> 01:56:45.260]   Oh, I like that.
[01:56:45.260 --> 01:56:46.260]   Where can I get that?
[01:56:46.260 --> 01:56:48.740]   It's so Blade Runner ask.
[01:56:48.740 --> 01:56:51.180]   Let me get that story.
[01:56:51.180 --> 01:56:54.980]   So this is the AI news anchor.
[01:56:54.980 --> 01:56:58.940]   So this is actually something that's on Chinese TV.
[01:56:58.940 --> 01:57:01.900]   This is Xinhua News Agency.
[01:57:01.900 --> 01:57:06.060]   The world's first artificial intelligence news anchor.
[01:57:06.060 --> 01:57:07.860]   They showed it at the we want to see it.
[01:57:07.860 --> 01:57:11.820]   It looks a lot realer than those fake ones we've seen elsewhere.
[01:57:11.820 --> 01:57:14.620]   I mean, let me turn up the sound.
[01:57:14.620 --> 01:57:16.140]   Here is the real anchor.
[01:57:16.140 --> 01:57:17.140]   The real.
[01:57:17.140 --> 01:57:19.340]   No, this is the fake anchor.
[01:57:19.340 --> 01:57:24.340]   This is a hello everyone in many English artificial intelligence anchor.
[01:57:24.340 --> 01:57:29.380]   This is my very first day in Zinghua News Agency, my voice and appearance are modeled on Zhang
[01:57:29.380 --> 01:57:34.540]   Zhao, a real anchor with Xinhua, the development of the media industry calls for continuous
[01:57:34.540 --> 01:57:39.660]   innovation and deep integration with the international advanced technologies.
[01:57:39.660 --> 01:57:45.740]   I will work tirelessly to keep you informed as texts will be typed into my system uninterrupted.
[01:57:45.740 --> 01:57:50.380]   I look forward to bringing you the brand new news experiences.
[01:57:50.380 --> 01:57:52.540]   I look forward to when the AIs fight each other.
[01:57:52.540 --> 01:57:57.060]   Now you can tell it's an AI right now.
[01:57:57.060 --> 01:58:00.660]   But honestly, they could probably make one you couldn't tell, right?
[01:58:00.660 --> 01:58:04.220]   Yeah, I was going to say that's just like they're just showing us that, but they've probably
[01:58:04.220 --> 01:58:07.420]   got one that's I mean, maybe I'm not right now.
[01:58:07.420 --> 01:58:09.860]   Pay no attention to that, Micah Sargent.
[01:58:09.860 --> 01:58:11.420]   Look at this over here.
[01:58:11.420 --> 01:58:17.180]   This very much reminds me of the William Gibson Adorot trilogy, which is.
[01:58:17.180 --> 01:58:19.220]   What a great story.
[01:58:19.220 --> 01:58:20.220]   Yeah.
[01:58:20.220 --> 01:58:23.860]   We're one of the characters is blackmailed into doing something by somebody basically creating
[01:58:23.860 --> 01:58:26.900]   a deep fake video of him and pointing out they can create a digital model.
[01:58:26.900 --> 01:58:29.140]   Micah, have you do anything I want?
[01:58:29.140 --> 01:58:31.700]   Exactly, yeah.
[01:58:31.700 --> 01:58:36.740]   We need another shiny thing Leo.
[01:58:36.740 --> 01:58:37.740]   Quick, quick.
[01:58:37.740 --> 01:58:38.740]   Yeah, let's go on.
[01:58:38.740 --> 01:58:41.620]   It keeps me so sad.
[01:58:41.620 --> 01:58:47.740]   Elon Musk says if you want to save people from the fires, you need a Model X or Model
[01:58:47.740 --> 01:58:51.340]   S with the Bio Weapon Defense Mode.
[01:58:51.340 --> 01:58:59.300]   I actually have a Model X and as I was driving around Petaluma avoiding potholes, I did use
[01:58:59.300 --> 01:59:02.300]   the Bio Weapon Defense to filter out the smoke.
[01:59:02.300 --> 01:59:04.140]   This is like Blade Runner 2040.
[01:59:04.140 --> 01:59:05.140]   2040?
[01:59:05.140 --> 01:59:06.140]   How was it?
[01:59:06.140 --> 01:59:07.140]   Works.
[01:59:07.140 --> 01:59:08.140]   Did it?
[01:59:08.140 --> 01:59:09.140]   Oh, that's great.
[01:59:09.140 --> 01:59:10.140]   No smell or anything?
[01:59:10.140 --> 01:59:11.140]   No.
[01:59:11.140 --> 01:59:12.140]   Wow.
[01:59:12.140 --> 01:59:15.540]   And here's a measurement of the particulate matter was very high.
[01:59:15.540 --> 01:59:20.580]   You know, it was well over 400 in some areas.
[01:59:20.580 --> 01:59:28.300]   The Bio Weapon Defense Mode is a hospital quality HEPA filter which eliminates the particulates.
[01:59:28.300 --> 01:59:31.060]   So anybody wants to go for a ride in my AIM Model X?
[01:59:31.060 --> 01:59:34.100]   See, we who have money are going to survive.
[01:59:34.100 --> 01:59:35.100]   You guys.
[01:59:35.100 --> 01:59:36.100]   Oh, dearly.
[01:59:36.100 --> 01:59:37.100]   I'll be careful.
[01:59:37.100 --> 01:59:41.460]   You know, eat the riches of smoking for his.
[01:59:41.460 --> 01:59:44.740]   He's pretty much the same.
[01:59:44.740 --> 01:59:45.740]   It's a bit organic.
[01:59:45.740 --> 01:59:46.740]   Did you know?
[01:59:46.740 --> 01:59:47.820]   Did you cast your raised eat?
[01:59:47.820 --> 01:59:50.900]   You can sign up for a service from the US Postal Service.
[01:59:50.900 --> 01:59:52.700]   I signed up for it.
[01:59:52.700 --> 01:59:57.260]   And by the way, I'm getting way too many texts now that it's called.
[01:59:57.260 --> 01:59:58.980]   What is it called?
[01:59:58.980 --> 01:59:59.980]   Informed delivery.
[01:59:59.980 --> 02:00:01.340]   Yeah, informed delivery.
[02:00:01.340 --> 02:00:02.340]   I love it.
[02:00:02.340 --> 02:00:03.500]   You're a member?
[02:00:03.500 --> 02:00:04.500]   Oh, yeah.
[02:00:04.500 --> 02:00:05.700]   So, get me to.
[02:00:05.700 --> 02:00:06.700]   What?
[02:00:06.700 --> 02:00:07.700]   Okay.
[02:00:07.700 --> 02:00:09.100]   I just found out about this.
[02:00:09.100 --> 02:00:14.700]   So I signed up and then last night at, you know, like three in the morning, I got a
[02:00:14.700 --> 02:00:18.780]   text saying item status out for delivery.
[02:00:18.780 --> 02:00:19.780]   It's been scanned.
[02:00:19.780 --> 02:00:22.820]   It's coming your way soon delivered at mailbox.
[02:00:22.820 --> 02:00:25.700]   I mean, hundreds of text messages, all the mail.
[02:00:25.700 --> 02:00:27.300]   I guess it has the mail text.
[02:00:27.300 --> 02:00:29.020]   Oh, well, you don't have to do text.
[02:00:29.020 --> 02:00:30.260]   You could do it in other ways.
[02:00:30.260 --> 02:00:35.100]   I get it in email that sends me a little photo of a scan of whatever mail is coming
[02:00:35.100 --> 02:00:36.100]   to me.
[02:00:36.100 --> 02:00:37.100]   Oh, I want the pictures.
[02:00:37.100 --> 02:00:38.100]   Yeah.
[02:00:38.100 --> 02:00:39.100]   That's nice.
[02:00:39.100 --> 02:00:42.140]   Because so I guess the automated anything that's automated, a scan by the automated equipment
[02:00:42.140 --> 02:00:43.460]   will show up here.
[02:00:43.460 --> 02:00:44.460]   Yep.
[02:00:44.460 --> 02:00:51.500]   So apparently ID thieves are abusing the service, signing up as you.
[02:00:51.500 --> 02:00:55.700]   Cribs on security says it's not too hard to sign up as somebody because they do have
[02:00:55.700 --> 02:00:59.460]   identity proof, but they ask you questions that basically he said, basically, you can
[02:00:59.460 --> 02:01:03.460]   look up the answer on the internet, you know, where you lived, stuff like that.
[02:01:03.460 --> 02:01:07.420]   I think it pulled it from your credit report was where the questions come from.
[02:01:07.420 --> 02:01:08.420]   Yeah, it looks like it.
[02:01:08.420 --> 02:01:09.740]   Did you ever live in this house?
[02:01:09.740 --> 02:01:10.900]   How much did you pay for it?
[02:01:10.900 --> 02:01:11.900]   That kind of stuff.
[02:01:11.900 --> 02:01:13.460]   What car did you have at this point?
[02:01:13.460 --> 02:01:14.460]   Yeah.
[02:01:14.460 --> 02:01:15.620]   A corning quid.
[02:01:15.620 --> 02:01:20.860]   There's an internal alert sent by the Secret Service November 6 to its law enforcement
[02:01:20.860 --> 02:01:21.860]   partners.
[02:01:21.860 --> 02:01:24.740]   They're talking about a recent case in Michigan in which seven people arrested for allegedly
[02:01:24.740 --> 02:01:31.500]   stealing credit cards from residents mailboxes after signing up as those victims.
[02:01:31.500 --> 02:01:33.500]   So they can see when the credit cards are coming.
[02:01:33.500 --> 02:01:34.980]   It saves you some time.
[02:01:34.980 --> 02:01:37.220]   You don't have to go through a bunch of mailboxes.
[02:01:37.220 --> 02:01:40.260]   Just go right to the ones with the credit cards.
[02:01:40.260 --> 02:01:44.660]   Fraudsters were also observed on criminal forums discussing using informed delivery to
[02:01:44.660 --> 02:01:49.300]   surveil potential identity theft victims.
[02:01:49.300 --> 02:01:54.780]   So I immediately as soon as I read the circle signed up, that's myself as myself.
[02:01:54.780 --> 02:01:56.300]   Yes, as you as me.
[02:01:56.300 --> 02:01:58.860]   But it's just one more thing to be aware of.
[02:01:58.860 --> 02:02:00.580]   So you guys knew about this.
[02:02:00.580 --> 02:02:04.780]   Yeah, because UPS and FedEx have their versions.
[02:02:04.780 --> 02:02:11.580]   And then I got an email I think from the postal service, not the band, but the actual agency.
[02:02:11.580 --> 02:02:14.940]   And they had that available and I was like, oh, absolutely.
[02:02:14.940 --> 02:02:20.500]   Because right before I had moved in, we had had someone come through and steal a neighbor's
[02:02:20.500 --> 02:02:23.300]   birthday card out of their mailbox.
[02:02:23.300 --> 02:02:25.820]   And so I immediately became kind of suspicious.
[02:02:25.820 --> 02:02:30.020]   So dear, if that mail thief comes back, I want to know what mail actually showed up and what
[02:02:30.020 --> 02:02:31.020]   doesn't.
[02:02:31.020 --> 02:02:34.100]   And there's a link in the email where you can say, hey, I didn't receive this piece of
[02:02:34.100 --> 02:02:35.100]   mail.
[02:02:35.100 --> 02:02:38.060]   And then they can sort of help you try and figure out what happened to it.
[02:02:38.060 --> 02:02:41.060]   So it's really handy.
[02:02:41.060 --> 02:02:43.540]   But yeah, if someone else is signing up is you, that's not good.
[02:02:43.540 --> 02:02:45.460]   That's not so handy.
[02:02:45.460 --> 02:02:54.020]   And we were all worried after the FCC withdrew its net neutrality regulation that maybe telecom
[02:02:54.020 --> 02:02:58.860]   carriers would do something to throttle competitors, charge them extra.
[02:02:58.860 --> 02:02:59.860]   They wouldn't do that.
[02:02:59.860 --> 02:03:01.980]   Adjut Pai said they wouldn't do that.
[02:03:01.980 --> 02:03:02.980]   Nobody's going to do that.
[02:03:02.980 --> 02:03:03.980]   Why would they want to do that?
[02:03:03.980 --> 02:03:04.980]   Well, wait a minute.
[02:03:04.980 --> 02:03:05.980]   Maybe they would.
[02:03:05.980 --> 02:03:09.100]   Sprint is throttling Skype according to a study.
[02:03:09.100 --> 02:03:11.940]   Well, their whole network is throttled.
[02:03:11.940 --> 02:03:12.940]   Oh, OK.
[02:03:12.940 --> 02:03:13.940]   Well, that's all right.
[02:03:13.940 --> 02:03:14.940]   That's slow.
[02:03:14.940 --> 02:03:17.700]   Slow, slow, slow, throttling.
[02:03:17.700 --> 02:03:19.940]   So it's kind of complicated.
[02:03:19.940 --> 02:03:27.420]   A hundred thousand consumers used a program, an app to test internet connections, the Wehe
[02:03:27.420 --> 02:03:29.420]   smartphone app.
[02:03:29.420 --> 02:03:30.420]   Oh, yeah.
[02:03:30.420 --> 02:03:31.420]   Yeah.
[02:03:31.420 --> 02:03:32.420]   Yeah.
[02:03:32.420 --> 02:03:39.700]   According to the results, Sprint, the only one throttling Skype at the moment, 34% of Skype
[02:03:39.700 --> 02:03:41.900]   calls were throttled, slowed down.
[02:03:41.900 --> 02:03:47.020]   In the case of a video call, the video quality would be much poorer, poorer than what the
[02:03:47.020 --> 02:03:48.020]   network supports.
[02:03:48.020 --> 02:03:52.860]   No, as the network could do it better, but doesn't.
[02:03:52.860 --> 02:03:59.580]   Sprint spokesperson said the telecom company doesn't single out Skype or any individual
[02:03:59.580 --> 02:04:00.700]   content provided this way.
[02:04:00.700 --> 02:04:01.900]   We just suck in general.
[02:04:01.900 --> 02:04:02.900]   Yeah.
[02:04:02.900 --> 02:04:04.980]   I think that's rough.
[02:04:04.980 --> 02:04:06.820]   And the researchers couldn't recreate the problem.
[02:04:06.820 --> 02:04:08.540]   They couldn't recreate it.
[02:04:08.540 --> 02:04:09.540]   Yeah.
[02:04:09.540 --> 02:04:12.940]   They're thinking maybe because it affects only certain subscription plans.
[02:04:12.940 --> 02:04:14.940]   They're not the one they bought.
[02:04:14.940 --> 02:04:17.980]   I'm glad they really put the effort into this.
[02:04:17.980 --> 02:04:22.060]   We only bought one.
[02:04:22.060 --> 02:04:26.420]   Wehe, by the way, was rejected from the app store initially in December.
[02:04:26.420 --> 02:04:30.580]   And then Apple after the outcry approved and published the app.
[02:04:30.580 --> 02:04:35.940]   But that helped because as a result, tens of thousands of new testers.
[02:04:35.940 --> 02:04:40.700]   The work is funded by the National Science Foundation, Alphabet, and the French telecom
[02:04:40.700 --> 02:04:43.060]   regulator.
[02:04:43.060 --> 02:04:44.060]   So we'll see.
[02:04:44.060 --> 02:04:48.140]   I'm glad they're doing this and I hope to see more.
[02:04:48.140 --> 02:04:51.460]   If somebody is throttling, I want to know about it.
[02:04:51.460 --> 02:04:52.460]   So we can throttle that.
[02:04:52.460 --> 02:04:53.460]   Yes.
[02:04:53.460 --> 02:04:57.900]   On the good cut of Sprint, they just announced that they're raising their cap on tethering
[02:04:57.900 --> 02:04:59.060]   to 50 gigs.
[02:04:59.060 --> 02:05:00.060]   Oh, nice.
[02:05:00.060 --> 02:05:01.060]   Yeah.
[02:05:01.060 --> 02:05:02.740]   So just to balance your pace.
[02:05:02.740 --> 02:05:03.740]   Nice.
[02:05:03.740 --> 02:05:07.500]   I don't blame Sprint because they made a bad bet on YMAX years ago.
[02:05:07.500 --> 02:05:09.980]   And that really ended up hurting their network overall.
[02:05:09.980 --> 02:05:13.980]   Now that they're, are they going to, is the merger with T-Mobile going to go ahead?
[02:05:13.980 --> 02:05:14.980]   Who knows?
[02:05:14.980 --> 02:05:15.980]   I so hope so.
[02:05:15.980 --> 02:05:16.980]   They really need it.
[02:05:16.980 --> 02:05:17.980]   Yeah.
[02:05:17.980 --> 02:05:22.660]   I'm a T-Mobile customer and T-Mobile ads have really been hammering hard on the patriotism
[02:05:22.660 --> 02:05:25.180]   of T-Mobile and how they're an outstanding American citizen.
[02:05:25.180 --> 02:05:26.340]   Oh, that worries me.
[02:05:26.340 --> 02:05:28.700]   It basically, please approve this.
[02:05:28.700 --> 02:05:29.700]   Please.
[02:05:29.700 --> 02:05:30.700]   Please, we love America.
[02:05:30.700 --> 02:05:31.700]   Yeah.
[02:05:31.700 --> 02:05:32.700]   There's been a whole lot.
[02:05:32.700 --> 02:05:33.700]   We love the veterans without us.
[02:05:33.700 --> 02:05:34.700]   Veterans can't talk to their parents.
[02:05:34.700 --> 02:05:35.700]   That's a good point.
[02:05:35.700 --> 02:05:36.700]   Oh boy.
[02:05:36.700 --> 02:05:37.700]   That's a good point.
[02:05:37.700 --> 02:05:39.140]   No, there's been a lot of ads where it's, it's team up.
[02:05:39.140 --> 02:05:40.540]   We're the backbone of this country.
[02:05:40.540 --> 02:05:42.340]   Please let us merge with Sprint.
[02:05:42.340 --> 02:05:44.860]   I know it's a Japanese company, but yeah.
[02:05:44.860 --> 02:05:45.860]   Yeah.
[02:05:45.860 --> 02:05:50.460]   No, there's the advertising blitz has been impressive.
[02:05:50.460 --> 02:05:53.940]   And I have been hard on Adjut Pie, but I'm going to give him some credit because he
[02:05:53.940 --> 02:05:59.400]   has stepped forward and said Sprint and a few other US telecoms have to do better
[02:05:59.400 --> 02:06:01.320]   fighting robo calls.
[02:06:01.320 --> 02:06:07.560]   And by the end of next year, he wants to implement a scheme, believe it or not, called
[02:06:07.560 --> 02:06:09.560]   shaken and stirred.
[02:06:09.560 --> 02:06:11.560]   Do you tell?
[02:06:11.560 --> 02:06:14.880]   This is not, this is not a martini.
[02:06:14.880 --> 02:06:21.720]   It's just very interesting acronyms for essentially a certificate program.
[02:06:21.720 --> 02:06:24.320]   So that, so they love their acronyms.
[02:06:24.320 --> 02:06:25.320]   They love the acronyms.
[02:06:25.320 --> 02:06:31.440]   So the idea is that a outgoing call would get authenticated, would get a, it's basically
[02:06:31.440 --> 02:06:38.660]   private public key crypto would get the shaken stir framework would validate handoff of calls
[02:06:38.660 --> 02:06:44.180]   because the outbound telecom would give it an authentication saying, yes, it's from our
[02:06:44.180 --> 02:06:45.720]   network, it's this person.
[02:06:45.720 --> 02:06:51.760]   And then the incoming call could verify that it was from the person making it.
[02:06:51.760 --> 02:06:57.120]   And the theory being, well, you know, spammers, robo callers aren't going to use real authentication.
[02:06:57.120 --> 02:07:00.360]   The problem with shaken and stirred sprints as it's very expensive for us to implement
[02:07:00.360 --> 02:07:06.000]   and it won't work because until every telecom in the world uses it, no one's going to turn
[02:07:06.000 --> 02:07:12.320]   on shaken and stir because they will, they'll, it'll reject international calls and things
[02:07:12.320 --> 02:07:14.080]   like that, right?
[02:07:14.080 --> 02:07:17.840]   Because not that these are bad callers, but because they're not authenticated because
[02:07:17.840 --> 02:07:20.760]   they're not using shaken and stir.
[02:07:20.760 --> 02:07:28.280]   Obviously, there's some, also there's some IP, telecoms that are genuine, but like, right?
[02:07:28.280 --> 02:07:29.840]   Have you heard of magic Jack?
[02:07:29.840 --> 02:07:30.840]   Right.
[02:07:30.840 --> 02:07:32.680]   That they're not going to use.
[02:07:32.680 --> 02:07:33.680]   Yeah.
[02:07:33.680 --> 02:07:34.680]   Yeah, they're not going to use.
[02:07:34.680 --> 02:07:35.680]   That's not going to be worth it.
[02:07:35.680 --> 02:07:37.680]   And bad guys are probably using VoIP for these calls.
[02:07:37.680 --> 02:07:39.760]   I mean, that's why there's so many of them.
[02:07:39.760 --> 02:07:40.760]   Yeah.
[02:07:40.760 --> 02:07:44.960]   So it's a, it's a, I mean, that everybody gets their own calls from Crockett, California.
[02:07:44.960 --> 02:07:47.160]   I'm the only one lucky enough to get those every day.
[02:07:47.160 --> 02:07:48.160]   Right.
[02:07:48.160 --> 02:07:49.160]   From your locale, right?
[02:07:49.160 --> 02:07:50.560]   Your area code.
[02:07:50.560 --> 02:07:52.560]   I get calls from my area code.
[02:07:52.560 --> 02:07:56.200]   Yeah, my area code and the number is similar to my own number.
[02:07:56.200 --> 02:07:57.200]   Yeah.
[02:07:57.200 --> 02:07:58.200]   Yeah.
[02:07:58.200 --> 02:07:59.200]   All right.
[02:07:59.200 --> 02:08:00.200]   Let's take a break.
[02:08:00.200 --> 02:08:01.200]   We can wrap things up.
[02:08:01.200 --> 02:08:02.200]   Our show today brought to you by FreshBooks.
[02:08:02.200 --> 02:08:05.480]   I was just talking to somebody a fan yesterday.
[02:08:05.480 --> 02:08:07.440]   He's a bodyguard.
[02:08:07.440 --> 02:08:11.320]   He's a bodyguard for like famous people like the Kardashians.
[02:08:11.320 --> 02:08:12.480]   Oh, yeah.
[02:08:12.480 --> 02:08:18.120]   He says, but the, you, whenever you talk about FreshBooks, I go, yeah, it's a pain in the
[02:08:18.120 --> 02:08:19.240]   butt to do invoices.
[02:08:19.240 --> 02:08:22.320]   When you're a freelancer and you have to send out invoices, it's a pain.
[02:08:22.320 --> 02:08:25.280]   But if you don't send out invoices, you don't get paid.
[02:08:25.280 --> 02:08:26.840]   FreshBooks changed my life.
[02:08:26.840 --> 02:08:28.160]   And he was telling me it changed his.
[02:08:28.160 --> 02:08:29.600]   He uses it.
[02:08:29.600 --> 02:08:37.240]   Well, the beauty of FreshBooks makes it easy to create professional looking beautiful invoices
[02:08:37.240 --> 02:08:39.560]   that have on them a pay me button.
[02:08:39.560 --> 02:08:42.520]   As a FreshBooks customer, you are able to take online payments.
[02:08:42.520 --> 02:08:44.160]   You don't have to do anything extra.
[02:08:44.160 --> 02:08:46.920]   And it turns out your customers want to pay you.
[02:08:46.920 --> 02:08:49.760]   They just, it's a pain in the butt for them to pay bills just like it is for you to send
[02:08:49.760 --> 02:08:50.760]   bills.
[02:08:50.760 --> 02:08:52.880]   So when it's easy for them to pay, I'm just paying me right now.
[02:08:52.880 --> 02:08:54.080]   I'm looking at the invoice.
[02:08:54.080 --> 02:08:57.600]   You get paid on average twice as fast.
[02:08:57.600 --> 02:08:59.440]   And then here's the other thing.
[02:08:59.440 --> 02:09:03.360]   Because you're using it to send invoices to records, received invoices to keep track of
[02:09:03.360 --> 02:09:04.360]   expenses.
[02:09:04.360 --> 02:09:05.360]   He says he loves that.
[02:09:05.360 --> 02:09:10.200]   You can take pictures of the expense receipts with your phone, goes right in the invoices.
[02:09:10.200 --> 02:09:16.480]   And all of that together is accounts receivable, accounts payable, expenses.
[02:09:16.480 --> 02:09:19.560]   You're doing full industry standard accounting.
[02:09:19.560 --> 02:09:23.640]   FreshBooks puts it all together and gives you all the reports like general ledger and
[02:09:23.640 --> 02:09:26.880]   trial balance that your accountant could ever want.
[02:09:26.880 --> 02:09:29.400]   When tax time comes, you're ready, baby.
[02:09:29.400 --> 02:09:31.320]   FreshBooks is amazing.
[02:09:31.320 --> 02:09:35.040]   It makes it so easy to keep track of, for instance, as a freelancer, I never knew if
[02:09:35.040 --> 02:09:36.040]   I made money.
[02:09:36.040 --> 02:09:39.680]   You know, it was only at tax time when I said, well, all the expenses and then what I made,
[02:09:39.680 --> 02:09:40.680]   and yeah, I made money.
[02:09:40.680 --> 02:09:42.240]   Or, no, I didn't make money.
[02:09:42.240 --> 02:09:44.400]   With FreshBooks, you always know.
[02:09:44.400 --> 02:09:45.520]   You can do so much more too.
[02:09:45.520 --> 02:09:48.600]   So Web Apps, so that means they're always adding features like proposals.
[02:09:48.600 --> 02:09:52.120]   Now you can create proposals with rich text content and images.
[02:09:52.120 --> 02:09:57.640]   You can accept clients e-signatures as acceptance, legally binding.
[02:09:57.640 --> 02:10:02.800]   You can send invoices, estimates and proposals in multiple languages, multiple currencies.
[02:10:02.800 --> 02:10:05.880]   FreshBooks will even automatically connect to your bank account and update expenses every
[02:10:05.880 --> 02:10:06.880]   day.
[02:10:06.880 --> 02:10:11.520]   So you have a continual up-to-date information about how you're doing.
[02:10:11.520 --> 02:10:14.360]   With the mobile app, you can keep track on your, keep tabs on your business no matter
[02:10:14.360 --> 02:10:17.120]   what you're doing, where you are.
[02:10:17.120 --> 02:10:20.280]   Easily search for uncategorized expenses in your FreshBooks account.
[02:10:20.280 --> 02:10:21.760]   Find them, categorize them.
[02:10:21.760 --> 02:10:25.480]   Save time and automate more of your workflow with more than 70 apps and integrations that
[02:10:25.480 --> 02:10:27.880]   FreshBooks offers, including EverLance.
[02:10:27.880 --> 02:10:29.040]   I don't know if you use EverLance.
[02:10:29.040 --> 02:10:33.360]   It lets you maximize deductions and automatically capture every work mile.
[02:10:33.360 --> 02:10:35.480]   Flows right into FreshBooks.
[02:10:35.480 --> 02:10:40.200]   Bulk actions, marking, cent, paid, download as PDF, that kind of thing.
[02:10:40.200 --> 02:10:41.560]   Just I can go on and on.
[02:10:41.560 --> 02:10:44.920]   In the year on a high note, hit the ground running in 2019.
[02:10:44.920 --> 02:10:46.000]   Get FreshBooks.
[02:10:46.000 --> 02:10:48.120]   You could try it free right now.
[02:10:48.120 --> 02:10:54.320]   For 30 days at freshbooks.com/twit, join the 24 million people who like me, who've used
[02:10:54.320 --> 02:10:58.840]   at FreshBooks to painlessly send invoices, track time, capture expenses.
[02:10:58.840 --> 02:11:00.320]   Oh yeah, because he's a bodyguard.
[02:11:00.320 --> 02:11:01.320]   He tracks the time.
[02:11:01.320 --> 02:11:02.680]   He says, "Relize you have the app.
[02:11:02.680 --> 02:11:04.360]   When I go on duty, I press a button.
[02:11:04.360 --> 02:11:07.000]   When I go off duty, I press a button."
[02:11:07.000 --> 02:11:12.080]   Go to freshbooks.com/twit, try it free for 30 days and enter this week in tech.
[02:11:12.080 --> 02:11:13.880]   And how did you hear about this section?
[02:11:13.880 --> 02:11:17.000]   FreshBooks.com/twit.
[02:11:17.000 --> 02:11:18.000]   We had fun this week.
[02:11:18.000 --> 02:11:23.200]   I think we have a mini movie illustrating the fine week that we just went through on
[02:11:23.200 --> 02:11:24.200]   Twit.
[02:11:24.200 --> 02:11:25.200]   Let's watch it.
[02:11:25.200 --> 02:11:26.200]   Previously on Twit.
[02:11:26.200 --> 02:11:27.200]   I see you.
[02:11:27.200 --> 02:11:28.680]   The UPS man has arrived.
[02:11:28.680 --> 02:11:29.680]   Oh my God.
[02:11:29.680 --> 02:11:30.680]   What happened there?
[02:11:30.680 --> 02:11:31.680]   Santa.
[02:11:31.680 --> 02:11:32.680]   There's a pile of boxes in front of me.
[02:11:32.680 --> 02:11:35.600]   He's all seem to be from a company named AI.
[02:11:35.600 --> 02:11:36.600]   So go ahead.
[02:11:36.600 --> 02:11:37.600]   Go ahead.
[02:11:37.600 --> 02:11:38.600]   What were you saying?
[02:11:38.600 --> 02:11:41.240]   Tech news weekly.
[02:11:41.240 --> 02:11:45.440]   We talked to Adrian Westaway from a company called Special Projects about a magical new
[02:11:45.440 --> 02:11:47.040]   UI for the phone.
[02:11:47.040 --> 02:11:51.440]   The idea really simply is that when you're kind of working with pen and paper or physical
[02:11:51.440 --> 02:11:54.760]   kind of things, you would lay them out on your desk in front of you.
[02:11:54.760 --> 02:11:57.720]   And just to move from one thing to another, you wouldn't even think about it.
[02:11:57.720 --> 02:12:03.640]   The invention allows you to kind of assign apps to certain spaces.
[02:12:03.640 --> 02:12:08.160]   By moving the device to those different spaces and bringing those apps into focus.
[02:12:08.160 --> 02:12:10.320]   The new screen sabers.
[02:12:10.320 --> 02:12:16.200]   Australian intelligence says Huawei was used in espionage in Australia.
[02:12:16.200 --> 02:12:19.680]   The biggest part of this story is that there's this general discomfort.
[02:12:19.680 --> 02:12:24.920]   This becomes a part of that conversation, which is how can we trust your hardware?
[02:12:24.920 --> 02:12:27.920]   Every single Apple product we're going to show is built in China.
[02:12:27.920 --> 02:12:29.320]   Is assembled in China, yeah.
[02:12:29.320 --> 02:12:30.320]   Absolutely.
[02:12:30.320 --> 02:12:32.280]   My favorite Windows laptop is a Lenovo.
[02:12:32.280 --> 02:12:33.280]   Right.
[02:12:33.280 --> 02:12:34.280]   It's a Chinese company.
[02:12:34.280 --> 02:12:35.280]   Absolutely.
[02:12:35.280 --> 02:12:38.280]   I don't, I just don't know what to think.
[02:12:38.280 --> 02:12:40.040]   Well, we give you the news.
[02:12:40.040 --> 02:12:43.200]   We don't, we don't know what to think.
[02:12:43.200 --> 02:12:44.200]   That's right.
[02:12:44.200 --> 02:12:45.200]   That's our job.
[02:12:45.200 --> 02:12:46.200]   Twit.
[02:12:46.200 --> 02:12:47.200]   We read things.
[02:12:47.200 --> 02:12:48.200]   You decide.
[02:12:48.200 --> 02:12:49.200]   You think.
[02:12:49.200 --> 02:12:50.200]   Tech.
[02:12:50.200 --> 02:12:51.200]   Just like you like it.
[02:12:51.200 --> 02:12:52.640]   Hot, fresh and shiny.
[02:12:52.640 --> 02:12:55.440]   Thank you everybody for being here today.
[02:12:55.440 --> 02:12:57.960]   It's always a pleasure.
[02:12:57.960 --> 02:12:59.360]   You're great to have here.
[02:12:59.360 --> 02:13:02.440]   Editor, you should bring Girl Scout cookies next time though, if you don't mind.
[02:13:02.440 --> 02:13:04.440]   So invite me in Q1 of 2019.
[02:13:04.440 --> 02:13:05.440]   Is that when it is?
[02:13:05.440 --> 02:13:06.440]   Yeah.
[02:13:06.440 --> 02:13:09.320]   We can't, we, I actually have to order the cookies for my troop in December.
[02:13:09.320 --> 02:13:10.720]   Kickoff is at the end of January.
[02:13:10.720 --> 02:13:12.640]   We'll be selling to the beginning of March.
[02:13:12.640 --> 02:13:14.480]   Carsten, make a note of that, will you?
[02:13:14.480 --> 02:13:15.480]   Get that out.
[02:13:15.480 --> 02:13:16.480]   Schmeiser's.
[02:13:16.480 --> 02:13:17.480]   Get that out.
[02:13:17.480 --> 02:13:18.480]   Girl Scout cookies.
[02:13:18.480 --> 02:13:19.480]   You'll find the-
[02:13:19.480 --> 02:13:20.480]   Make your orders now.
[02:13:20.480 --> 02:13:21.480]   Yeah, please.
[02:13:21.480 --> 02:13:22.960]   You'll finally said IT Pro today.
[02:13:22.960 --> 02:13:26.320]   She's editor there and on the Twitter at L Schmeiser SCHMEISER.
[02:13:26.320 --> 02:13:27.320]   Thank you Lisa.
[02:13:27.320 --> 02:13:28.920]   It's great to have you.
[02:13:28.920 --> 02:13:30.760]   Mike Asargent, always a pleasure.
[02:13:30.760 --> 02:13:31.760]   He's at-
[02:13:31.760 --> 02:13:32.760]   Enjoy it.
[02:13:32.760 --> 02:13:37.320]   Every time I hear Chihuahua coffee, I feel like it must be a hopped up little doggy.
[02:13:37.320 --> 02:13:38.320]   Chihuahua.com.
[02:13:38.320 --> 02:13:39.320]   Can you imagine?
[02:13:39.320 --> 02:13:40.320]   Don't feed-
[02:13:40.320 --> 02:13:41.320]   Don't feed coffee.
[02:13:41.320 --> 02:13:43.160]   Don't feed coffee to Chihuahua's folks.
[02:13:43.160 --> 02:13:44.160]   No.
[02:13:44.160 --> 02:13:45.160]   They're bad enough as they-
[02:13:45.160 --> 02:13:46.160]   Do you have Chihuahua's?
[02:13:46.160 --> 02:13:48.160]   I have two Chihuahua's, yeah.
[02:13:48.160 --> 02:13:49.160]   And I don't give them coffee.
[02:13:49.160 --> 02:13:50.560]   And they are not bad enough as it is.
[02:13:50.560 --> 02:13:51.560]   I heard that.
[02:13:51.560 --> 02:13:52.560]   No, they're cute.
[02:13:52.560 --> 02:13:57.840]   They're little, they're cute Chihuahua's.
[02:13:57.840 --> 02:13:59.080]   Chihuahua.coffee.
[02:13:59.080 --> 02:14:03.880]   Mike Asargent, he's on Twitter at mikahsargent.
[02:14:03.880 --> 02:14:10.040]   And all the way from the People's Republic of Austin, Texas, Wesley Faulkner.
[02:14:10.040 --> 02:14:14.000]   Was it a good campaign, a good election day for you?
[02:14:14.000 --> 02:14:17.560]   2016 knows horrible and multiple fronts.
[02:14:17.560 --> 02:14:18.560]   Yeah, Stacy was kind of-
[02:14:18.560 --> 02:14:19.560]   That's kind of a bonus too.
[02:14:19.560 --> 02:14:22.040]   Yeah, I'm not just talking about my race.
[02:14:22.040 --> 02:14:23.040]   Yeah.
[02:14:23.040 --> 02:14:24.040]   Yeah.
[02:14:24.040 --> 02:14:32.360]   But what I do want people to vote on is that we IBM, I guess now I'm speaking for IBM.
[02:14:32.360 --> 02:14:35.120]   Wesley does not speak for IBM unless he does.
[02:14:35.120 --> 02:14:36.120]   Mm-hmm.
[02:14:36.120 --> 02:14:40.360]   The project I'm currently working on is for IBM Systems of getting more reviews for our
[02:14:40.360 --> 02:14:41.360]   hardware products.
[02:14:41.360 --> 02:14:45.560]   So I know there are a lot of IT professionals who watch this program.
[02:14:45.560 --> 02:14:52.640]   If you could do me a personal favor, go to G2 Crowd or Trust Radius and just put in a review
[02:14:52.640 --> 02:14:53.640]   or rating.
[02:14:53.640 --> 02:14:55.560]   I would highly appreciate it.
[02:14:55.560 --> 02:15:02.840]   If you need links to those, just hit up my Twitter link and it would do me a world of
[02:15:02.840 --> 02:15:07.640]   good, if I can get at least one review, on either of those sites for any IBM systems
[02:15:07.640 --> 02:15:08.880]   that you currently own.
[02:15:08.880 --> 02:15:09.880]   Any IBM systems.
[02:15:09.880 --> 02:15:14.840]   That if you're on the mainframe, which is Z Linux 1, if you're on storage, especially
[02:15:14.840 --> 02:15:18.960]   if you have flash storage, our flash systems, we're looking for more reviews.
[02:15:18.960 --> 02:15:23.000]   And if you have any of our servers, which is Power9 specifically.
[02:15:23.000 --> 02:15:24.000]   Are you having fun?
[02:15:24.000 --> 02:15:26.680]   It was a relatively new job last time we talked.
[02:15:26.680 --> 02:15:28.120]   Oh, yeah, it's black.
[02:15:28.120 --> 02:15:29.120]   Yes.
[02:15:29.120 --> 02:15:30.120]   Settled in?
[02:15:30.120 --> 02:15:31.120]   No, never settle.
[02:15:31.120 --> 02:15:32.120]   I'll never tell people.
[02:15:32.120 --> 02:15:33.720]   There's so much to learn.
[02:15:33.720 --> 02:15:35.720]   There's so many people to learn from too.
[02:15:35.720 --> 02:15:42.160]   I don't know if you know how large IBM is, but we have over 380,000 employees and plus
[02:15:42.160 --> 02:15:44.160]   just a red hat.
[02:15:44.160 --> 02:15:47.840]   And so I have a lot of friends who work for red hat.
[02:15:47.840 --> 02:15:49.760]   And so getting reacquainted.
[02:15:49.760 --> 02:15:51.520]   So things are complicated.
[02:15:51.520 --> 02:15:54.160]   Things will always change and I will always change with it.
[02:15:54.160 --> 02:15:55.160]   I love red hat.
[02:15:55.160 --> 02:15:56.320]   I always loved red hat.
[02:15:56.320 --> 02:15:59.160]   So it's going to be very interesting to watch what happens there.
[02:15:59.160 --> 02:16:02.960]   Wesley Faulkner is developer relations advocate at IBM.
[02:16:02.960 --> 02:16:05.800]   He's Wesley 83 on Twitter.
[02:16:05.800 --> 02:16:06.800]   Thanks for joining us.
[02:16:06.800 --> 02:16:07.800]   All three of you.
[02:16:07.800 --> 02:16:09.120]   It was a lot of fun.
[02:16:09.120 --> 02:16:10.360]   There was a lot of food for thought.
[02:16:10.360 --> 02:16:13.080]   My brain expanded a lot today.
[02:16:13.080 --> 02:16:14.080]   Thank you.
[02:16:14.080 --> 02:16:15.080]   I appreciate it.
[02:16:15.080 --> 02:16:16.080]   I hope yours did too.
[02:16:16.080 --> 02:16:20.800]   I've been here every Sunday afternoon, 3 p.m. Pacific, 6 p.m. Eastern, 2300 UTC.
[02:16:20.800 --> 02:16:21.960]   Tune in live if you want.
[02:16:21.960 --> 02:16:25.520]   YouTube is not one of our streaming services.
[02:16:25.520 --> 02:16:28.560]   But there's a long story there.
[02:16:28.560 --> 02:16:29.720]   Is there an update on that?
[02:16:29.720 --> 02:16:33.280]   We've got a strike from covering the Apple event.
[02:16:33.280 --> 02:16:39.040]   And they pulled us down an Apple, some slimy lawyer from Apple's citizen email.
[02:16:39.040 --> 02:16:40.880]   But we have have they contested it.
[02:16:40.880 --> 02:16:44.160]   There will be more news towards the end of this coming week.
[02:16:44.160 --> 02:16:45.160]   Okay.
[02:16:45.160 --> 02:16:49.520]   Meanwhile, we have plenty of other very nice providers like Twitch and Mixer and New Stream
[02:16:49.520 --> 02:16:51.000]   who you can watch.
[02:16:51.000 --> 02:16:52.440]   You can see audio and video.
[02:16:52.440 --> 02:16:56.720]   We have audio at Spreaker as well at Twitch.tv/live.
[02:16:56.720 --> 02:16:57.720]   That's where you should go.
[02:16:57.720 --> 02:16:59.240]   Pick the stream that works for you.
[02:16:59.240 --> 02:17:03.480]   If you're watching or listening live, do join us in the chatroom at IRC.twit.tv.
[02:17:03.480 --> 02:17:08.680]   That's a great place to kind of join the community and participate.
[02:17:08.680 --> 02:17:12.880]   It's a lot of fun in the chatroom as they're watching at the same time as you are.
[02:17:12.880 --> 02:17:15.040]   Now, of course, I know you've got a busy life.
[02:17:15.040 --> 02:17:18.720]   So if you can't watch live and chat live, you can always get on demand versions of everything
[02:17:18.720 --> 02:17:22.680]   we do at our website, Twitch.tv.
[02:17:22.680 --> 02:17:24.920]   The best way to participate though is subscribe.
[02:17:24.920 --> 02:17:26.760]   That way you'll get a copy of every episode.
[02:17:26.760 --> 02:17:31.440]   The minute it's available later in the day on Sunday, right after we do it.
[02:17:31.440 --> 02:17:35.080]   And you'll always have it sitting on your phone.
[02:17:35.080 --> 02:17:37.800]   You can even listen on your smart assistant.
[02:17:37.800 --> 02:17:40.920]   Ask your echo or your Siri or your Google assistant.
[02:17:40.920 --> 02:17:41.920]   You just say listen to Twitch live.
[02:17:41.920 --> 02:17:47.400]   If you want to listen live stream or listen to this week in tech and almost every case
[02:17:47.400 --> 02:17:50.080]   it'll play the most recent version of any of our shows.
[02:17:50.080 --> 02:17:51.080]   Thank you.
[02:17:51.080 --> 02:17:52.240]   You would also record if you're going to get murdered.
[02:17:52.240 --> 02:17:53.760]   If you're getting murdered, shout echo.
[02:17:53.760 --> 02:17:56.800]   I'm dying and hope the police have the brains to subpoena.
[02:17:56.800 --> 02:17:57.800]   I don't think you'd be dying.
[02:17:57.800 --> 02:17:58.800]   You have to say echo.
[02:17:58.800 --> 02:17:59.800]   I'm being killed.
[02:17:59.800 --> 02:18:00.800]   Bye.
[02:18:00.800 --> 02:18:01.800]   Echo.
[02:18:01.800 --> 02:18:02.800]   Someone's killing me.
[02:18:02.800 --> 02:18:03.800]   Schmeiser is killing me.
[02:18:03.800 --> 02:18:05.600]   Always start with the name of the murderer.
[02:18:05.600 --> 02:18:06.600]   There you go.
[02:18:06.600 --> 02:18:08.880]   Because they always say my murderer was.
[02:18:08.880 --> 02:18:10.880]   Start with the name.
[02:18:10.880 --> 02:18:12.760]   Schmeiser was my murderer.
[02:18:12.760 --> 02:18:13.760]   Always start with the name, right?
[02:18:13.760 --> 02:18:17.760]   I feel like this is when having a hard to pronounce last name actually works in my favor.
[02:18:17.760 --> 02:18:20.680]   Because because because like shake your heart.
[02:18:20.680 --> 02:18:22.480]   That wasn't me.
[02:18:22.480 --> 02:18:24.360]   Try not to say but I know.
[02:18:24.360 --> 02:18:26.320]   They didn't pronounce the name correctly.
[02:18:26.320 --> 02:18:27.880]   It couldn't have been me.
[02:18:27.880 --> 02:18:29.880]   The signatures don't match.
[02:18:29.880 --> 02:18:30.880]   Yeah.
[02:18:30.880 --> 02:18:33.440]   Schmeiser is my.
[02:18:33.440 --> 02:18:34.880]   See that wouldn't work either.
[02:18:34.880 --> 02:18:35.880]   Schmeiser murderer.
[02:18:35.880 --> 02:18:36.880]   Yeah.
[02:18:36.880 --> 02:18:37.880]   That would work.
[02:18:37.880 --> 02:18:38.880]   Okay.
[02:18:38.880 --> 02:18:39.880]   Everything's everything.
[02:18:39.880 --> 02:18:40.880]   Thanks for trying.
[02:18:40.880 --> 02:18:42.760]   We'll see you next time.
[02:18:42.760 --> 02:18:45.160]   Another twin is in the can.
[02:18:45.160 --> 02:18:46.600]   Next be I'm dying.
[02:18:46.600 --> 02:18:47.600]   Do it the twin.
[02:18:47.600 --> 02:18:48.600]   Do it the twin.
[02:18:48.600 --> 02:18:49.600]   All right.
[02:18:49.600 --> 02:18:50.600]   Do it the twin baby.
[02:18:50.600 --> 02:18:51.600]   Do it the twin.
[02:18:51.600 --> 02:18:52.600]   All right.
[02:18:52.600 --> 02:18:53.600]   Do it the twin.

