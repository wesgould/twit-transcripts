;FFMETADATA1
title=An Electric Cannonball
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=731
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.000]   It's time for Twit this week in Tech. What a panel!
[00:00:02.000 --> 00:00:04.880]   I'm excited. Brianna Wu is here.
[00:00:04.880 --> 00:00:07.280]   Sammabool's submit and Ben Brock Johnson.
[00:00:07.280 --> 00:00:12.880]   Video games. Brianna's got a editorial in the Washington Post about video games in violence.
[00:00:12.880 --> 00:00:18.880]   We'll talk about that. We'll talk about Waz. He wants you off Facebook and why is the U.S.
[00:00:18.880 --> 00:00:23.040]   Navy ditching touchscreen controllers. It's all coming up next on Twit.
[00:00:25.600 --> 00:00:28.880]   Netcasts you love. From people you trust.
[00:00:28.880 --> 00:00:34.240]   This is Twit.
[00:00:34.240 --> 00:00:49.520]   This is Twit this week at Tech. Episode 731 recorded Sunday August 11th 2019.
[00:00:50.480 --> 00:00:57.120]   An electric cannonball. This week at Tech is brought to you by ZipRecruiter. Hiring is
[00:00:57.120 --> 00:01:01.840]   challenging but there is one place you can go where hiring is simple and smart. That place
[00:01:01.840 --> 00:01:09.440]   is ZipRecruiter where growing businesses connect to qualified candidates. Try it free at ziprecruiter.com/twit.
[00:01:09.440 --> 00:01:16.080]   And by Wasabi Hot Cloud Storage. Thinking about moving your data storage to the cloud? Wasabi
[00:01:16.080 --> 00:01:21.840]   is enterprise class cloud storage. One-fifth the price of Amazon S3. And up to six times faster
[00:01:21.840 --> 00:01:27.520]   with no hidden fees for egress or API requests. Calculate your savings and try Wasabi with free
[00:01:27.520 --> 00:01:34.640]   unlimited storage for a month at Wasabi.com. Code Twit and by Audible. Start a 30-day trial
[00:01:34.640 --> 00:01:42.880]   in your first audiobook plus two Audible originals are free. Go to Audible.com/Twit2 or text Twit2
[00:01:42.880 --> 00:01:49.920]   to 500 500. And by Kaptera. Find the right tools to make an informed software decision for your
[00:01:49.920 --> 00:02:00.400]   business. Visit Kaptera's free website at kaptera.com/twit. It's time for Twit this week in Tech.
[00:02:00.400 --> 00:02:05.520]   Shall we talk about the week's tech news? Give you some deep thinking analysis
[00:02:05.520 --> 00:02:11.120]   from great tech journalist joining me in studio today. Sam Evel, Sam@he is principal researcher at
[00:02:11.120 --> 00:02:16.880]   Navigant. He's my car guy. Yeah, it's good to have you Sam. He's also the host of the Wheel
[00:02:16.880 --> 00:02:22.720]   Bering's podcast at Wheel Bering's media and regular on the radio show. It's good to have you
[00:02:22.720 --> 00:02:27.840]   driving today. You're driving Honda Insight. It's always different with you. Tomorrow you'll be
[00:02:27.840 --> 00:02:32.960]   driving a Lincoln aviator. I will. And we can talk about that next time. And someday I'll be
[00:02:32.960 --> 00:02:39.440]   driving a Porsche Taycan. Cass! Certainly hope so. Brianna Wu is a car gal. She knows what I'm
[00:02:39.440 --> 00:02:43.840]   talking about. She's a Porsche fan too. But you would never drive an EV. Would you? You're
[00:02:43.840 --> 00:02:48.400]   a guy. Oh, I'd buy one the instant they come up with an EV coupe. I will buy it that day. You
[00:02:48.400 --> 00:02:54.960]   better believe it. Yeah. I saw a Tesla Roadster this morning. Yeah. Sorry, go ahead.
[00:02:54.960 --> 00:03:00.960]   He says he saw a Tesla Roadster. Yeah. And point rest. That's the little one. The original
[00:03:00.960 --> 00:03:06.800]   Roadster. Not the new one. No. Yeah. I've thought about buying one of those. They're $30,000.
[00:03:06.800 --> 00:03:12.160]   Like even you second go up to $50. I just, no, I can't do it. Oh, don't get that.
[00:03:12.160 --> 00:03:17.040]   Don't get a Tesla at all. We'll talk about it a little bit. Brianna is a candidate for
[00:03:17.040 --> 00:03:23.120]   Congress in Massachusetts. It's 8th. She is also Space Cat Gal. But don't say that anymore. It's
[00:03:23.120 --> 00:03:30.000]   at Brianna Wu on the Twitter. Her people wouldn't like that. She's also a game developer and long-time
[00:03:30.000 --> 00:03:33.040]   game developer. We're actually going to talk about your editorial in just a second. Before we do
[00:03:33.040 --> 00:03:37.520]   that, let me introduce Ben Brock Johnson is also with us senior producer. W. B. U. R.
[00:03:37.520 --> 00:03:44.880]   and Boston. He also co-hosts the podcast endless thread. And how are you? Hey, it's great to see
[00:03:44.880 --> 00:03:49.680]   you. Welcome back. Yeah. Thanks for having me. What is that over here? Is that a raccoon?
[00:03:49.680 --> 00:03:59.600]   No, it's just, you know, it's my, it's my like plushie toy for my kids. It's a spirit animal.
[00:03:59.600 --> 00:04:03.680]   Yeah, it's my spirit animal. It's my back checker from Pocahontas. My back checker.
[00:04:03.680 --> 00:04:09.280]   Is it Mika from Pocahontas? I have no idea. I don't know. It's just a mics like it. Are they
[00:04:09.280 --> 00:04:15.040]   like it? I think Brianna has no children knows that character. Come on. I played a lot of Pocahontas
[00:04:15.040 --> 00:04:21.600]   on Genesis. Oh, you played it on the Sega. Okay, that's fine, Ben. Okay, fine. I don't know.
[00:04:21.600 --> 00:04:27.360]   No, I love it. It's cute. Keep it there. Keep it there. It's awesome. It's awesome. Perfect.
[00:04:27.360 --> 00:04:34.320]   Right there. So, one thing I noticed before the show begins, Brianna, you have a great podcast,
[00:04:34.320 --> 00:04:38.960]   Rockets, that you do with Simone de Roche for who's been on the show. And of course, Christina Warren
[00:04:38.960 --> 00:04:43.760]   has been on this show. Ben has... I did ask you, is your studio still standing after having Simone
[00:04:43.760 --> 00:04:48.880]   on? Simone is awesome. I think she's still here. Yeah, she is awesome. Now, she had been in studio.
[00:04:48.880 --> 00:04:53.840]   That might not be the case. Yeah. No, I want to get her in studio sometime. She is great. She was
[00:04:53.840 --> 00:05:00.160]   so much fun. I love her. Sam has a podcast, Wheel bearings, of course. Ben Brock Johnson is a
[00:05:00.160 --> 00:05:06.560]   podcaster too. I'm a podcaster. Yes, sir. Yeah. And I was thinking the other day, because I used to,
[00:05:06.560 --> 00:05:10.080]   when people said, "What do you do?" I always said, "Oh, I have a radio show." I would never say I'm a
[00:05:10.080 --> 00:05:14.880]   podcaster because I didn't want to get in the long conversation of what is that. But I realized,
[00:05:14.880 --> 00:05:20.880]   we're, as you said, Ben Peake podcast. People know what it is now. Yeah, man. We're hot. They're
[00:05:20.880 --> 00:05:26.800]   like, they're surprised. They're like, "Radio, what is that?" Yeah. Radio? Is that like a podcast?
[00:05:26.800 --> 00:05:31.520]   Is that like a podcast but not on the internet? Yeah. Is that what it is? Yeah, kind of. They do,
[00:05:31.520 --> 00:05:37.040]   kind of. Oh, radio? Is that still around? People still do that. They still put them in cars. It came,
[00:05:37.040 --> 00:05:43.200]   why? I don't know. It's for when your USB cable breaks or something. That must be it.
[00:05:43.200 --> 00:05:48.000]   The reason it comes up for me is because tomorrow we're flying out. Lisa and I are flying out to,
[00:05:48.000 --> 00:05:53.040]   along with my son Henry who sells for a tour, we're flying out to the podcast movement,
[00:05:53.040 --> 00:06:01.120]   Orlando in August where the feels like temperature is a balmy 105 degrees.
[00:06:01.120 --> 00:06:08.560]   Oh, yeah, yeah. But it's going to be fun. I think this, is this the first podcast movement
[00:06:08.560 --> 00:06:13.440]   since we became Peake podcast? I think maybe it's going to be interesting. It'd be interesting to
[00:06:13.440 --> 00:06:19.360]   see how people, people are. Are you going to stop by Disney World because you can,
[00:06:19.360 --> 00:06:25.760]   nowadays you can pay, what is it, like $400. You can go to a secret exhibit at the Star Wars side
[00:06:25.760 --> 00:06:30.080]   and you can make your own lightsaber and you get to choose if you're a good guy or a Seth.
[00:06:30.080 --> 00:06:36.880]   I'm betting Seth for you. That's Disney Land, not Disney World, right? Or is it Disney World too?
[00:06:36.880 --> 00:06:41.280]   I think it's Disney World. I'm pretty sure. Yeah. In both places, it's $200. You get a
[00:06:41.280 --> 00:06:44.960]   special special special. Oh, we're doing it. Oh, we're doing it.
[00:06:44.960 --> 00:06:48.640]   I think we also have a studio where you make your own podcast.
[00:06:48.640 --> 00:06:56.640]   But you have to talk about Star Wars. Who does it? We already have and we just begun.
[00:06:56.640 --> 00:07:00.960]   I think that was a serenity Caldwell who was debating whether to spend that money and make
[00:07:00.960 --> 00:07:07.760]   her own lightsaber. I believe it was. Anyway, she did. What's the debate? If you're there,
[00:07:07.760 --> 00:07:11.840]   you might as well. Did you get to take it home? I'd be afraid if we're a real lightsaber,
[00:07:11.840 --> 00:07:16.640]   I know I'd cut a hand off like before I even got it out of the place. We just like, oh,
[00:07:16.640 --> 00:07:24.320]   darn it. Hey, the incidence of light lightsaber wounds goes up dramatically when the lightsaber
[00:07:24.320 --> 00:07:29.600]   goes into the home. Oh my God. And then who thought of a double ended lightsaber like that
[00:07:29.600 --> 00:07:35.040]   Sith light? That's crazy talk, man. Or the, you know, the one that Kyla Ren uses, you know, with
[00:07:35.040 --> 00:07:40.080]   the little shoots, a little light, because what could possibly go wrong on that run?
[00:07:40.080 --> 00:07:46.320]   See video games don't cause violence or do they actually, this is a timely conversation.
[00:07:46.320 --> 00:07:51.360]   Brianna Wu just wrote a piece, opinion piece for the Washington Post.
[00:07:51.360 --> 00:08:00.080]   And this comes up because after the tragic shootings in, well, I have to, I should start with
[00:08:00.080 --> 00:08:04.960]   Gilroy, although you start going back, you'll go back a long, long, long, long way, but Gilroy
[00:08:04.960 --> 00:08:11.520]   and then Dayton, Ohio and of course El Paso, Texas. And unfortunately, two things are blamed
[00:08:11.520 --> 00:08:18.160]   immediately video games and mental illness, except that they play video games in countries all over
[00:08:18.160 --> 00:08:22.160]   the world. And they don't have mass shootings like this. That's a good point. So yeah.
[00:08:22.160 --> 00:08:27.200]   So Brianna's piece is said is titled video games don't cause mass shootings, but, and this is an
[00:08:27.200 --> 00:08:31.920]   interesting take on it. Gamer culture does encourage hate. You or of course, the subject
[00:08:31.920 --> 00:08:38.640]   of a lot of hate during gamer games. Yeah. I mean, Achan was literally formed to target me
[00:08:38.640 --> 00:08:45.280]   and other industry women. Yeah. Leah, this is some really serious subject to talk about, but I,
[00:08:45.280 --> 00:08:51.520]   I, three times over the years have gotten threats from Achan. So serious about conducting a mass
[00:08:51.520 --> 00:08:57.120]   shooting. I've had to talk to the FBI about it because I found it extremely credible.
[00:08:57.120 --> 00:09:05.920]   One of these was just a few weeks ago. So, you know, this is a very, very, very serious topic.
[00:09:05.920 --> 00:09:11.600]   I come from the game industry. I really wish I could sit here and just tell you there's no problems.
[00:09:11.600 --> 00:09:18.320]   We're doing great, but it's, it's not the case. And I think when you're seeing repeated mass
[00:09:18.320 --> 00:09:25.760]   shootings, planned, executed, you know, manifestos posted on Achan, I really think it's time for
[00:09:25.760 --> 00:09:30.720]   our industry to take a very hard look in the mirror. I think this is a really interesting take
[00:09:30.720 --> 00:09:36.640]   because generally it comes down to, yes, they do know they don't. They cause violence, they don't.
[00:09:36.640 --> 00:09:42.160]   And of course, there's examples, plenty of examples right here in this studio of people who play
[00:09:42.160 --> 00:09:49.280]   violent video games and are not even angry or, you know, let alone slapping anybody.
[00:09:49.280 --> 00:09:54.720]   So it obviously, in the vast majority of people who play video games are not violent people.
[00:09:54.720 --> 00:10:00.400]   But I think your take is unique and interesting, which is the culture of video games
[00:10:00.400 --> 00:10:07.760]   is a little, and any, all it takes is a minute in a, you know, in any game, if you're listening
[00:10:07.760 --> 00:10:13.760]   to the back chatter and the taunting to kind of get this, that is pretty ugly.
[00:10:13.760 --> 00:10:17.280]   You don't, you don't think that it leads to violence or do you?
[00:10:17.280 --> 00:10:23.360]   No, I think that, I think there are cultures somewhere along the way, became very fundamentally
[00:10:23.360 --> 00:10:29.760]   broken. I didn't get into this in the piece because it was already almost 1500 words when I turned
[00:10:29.760 --> 00:10:35.760]   turned it in. But I want to take you back in time a little bit. When Xbox Live, the very first
[00:10:35.760 --> 00:10:42.720]   generation of Xbox, the one before the 360, we take it for granted now, but it really led the way for
[00:10:42.720 --> 00:10:50.080]   online multiplayer and matchmaking in a really seamless way. And the man that was in charge of
[00:10:50.080 --> 00:10:57.600]   that at Microsoft, his name was Stepto. He's a fantastic guy, an industry leader. And when Microsoft
[00:10:57.600 --> 00:11:04.320]   was kind of setting the norms for what matchmaking was going to be on the consoles, they took very,
[00:11:04.320 --> 00:11:09.920]   very, very aggressive policies for the first generation of it. They had a one strike in your
[00:11:09.920 --> 00:11:16.560]   out policy that they considered reading the terms of service to be a warning. And they actually made
[00:11:16.560 --> 00:11:22.800]   the outcomes of bands public for people to go look at. I met with Stepto and I got to know him a
[00:11:22.800 --> 00:11:29.280]   bit before he passed two years ago. And he was telling me about all the battles he had with
[00:11:29.280 --> 00:11:35.280]   Microsoft behind the scenes. When they moved over to the Xbox 360, they were looking at the human
[00:11:35.280 --> 00:11:42.080]   cost of basically looking at all these automation reports and looking at the loss of a player base
[00:11:42.080 --> 00:11:48.000]   from banning people for harassing behavior. So they moved to kind of an automated system and they
[00:11:48.000 --> 00:11:53.440]   decided to kind of pit the jerks with the other jerks in games. And we kind of laughed at it at
[00:11:53.440 --> 00:12:01.040]   the time. But I believe that one decision really set our industry down a very different path.
[00:12:01.040 --> 00:12:05.760]   Because if you look at what started happening on IGN with the comments at that time,
[00:12:05.760 --> 00:12:12.800]   if you look at the policies, PlayStation adopted and later Steam, there really became an expectation
[00:12:12.800 --> 00:12:18.960]   that you could say anything and behave in any way on these platforms. And I feel like today,
[00:12:18.960 --> 00:12:24.400]   it's gotten to the point where no, video games do not directly lead to violence. But it is kind of
[00:12:24.400 --> 00:12:32.320]   a chamber where people are so furious that they are amplifying each other. And it's very directly
[00:12:32.320 --> 00:12:38.720]   leading to recruitment in these kind of white supremacist chat rooms. And I think we can see
[00:12:38.720 --> 00:12:44.880]   it directly leading to school shootings. Yeah, it's interesting how it starts to become a safe
[00:12:44.880 --> 00:12:52.320]   space for hate. And this is in my mind a problem in a lot of kind of closed communities or
[00:12:52.320 --> 00:12:59.760]   communities online that can be a little bit insular. And video games end up building these
[00:12:59.760 --> 00:13:05.040]   platforms, not purposefully, obviously. But multiplayer online video games end up building
[00:13:05.040 --> 00:13:13.840]   these platforms that can make it a lot easier for people to kind of gather around specific ideas.
[00:13:14.560 --> 00:13:20.240]   Even if that's kind of a bug, not a feature of the game itself. And I think it's been really
[00:13:20.240 --> 00:13:28.160]   interesting to see the debate around this around H&N and Reddit and other websites.
[00:13:28.160 --> 00:13:34.880]   And it's really problematic, I think, for the companies that build these platforms,
[00:13:34.880 --> 00:13:40.480]   because they still don't know what to do with it or seem to know what to do with it. They try
[00:13:40.480 --> 00:13:46.400]   to build out their trust and safety teams. You have Facebook, another place where hate groups
[00:13:46.400 --> 00:13:55.440]   can organize and have organized in safety, trying to figure out how to build algorithms to catch
[00:13:55.440 --> 00:14:02.080]   stuff. And it's really, I just think it's really, really tricky. And weirdly, a lot of these tech
[00:14:02.080 --> 00:14:07.120]   companies really need to think about just building out their trust and safety teams even further
[00:14:07.120 --> 00:14:13.200]   than they already are. And that's expensive. And tech companies don't always want to do that.
[00:14:13.200 --> 00:14:16.000]   But it really is becoming a bigger and bigger problem.
[00:14:16.000 --> 00:14:25.680]   You want to be careful because you don't want to get a bunch of old male senators
[00:14:25.680 --> 00:14:31.520]   to say, "Oh, we figured out what the problem is. It's video games. Let's just ban violent video
[00:14:31.520 --> 00:14:38.720]   games." All done. Definitely. Definitely not. Because there's clearly many, many causes to this.
[00:14:38.720 --> 00:14:44.160]   And you could replace video games with Twitter and YouTube and a bunch of other things and say,
[00:14:44.160 --> 00:14:50.160]   including bad parenting. I mean, you can go on and on and on. There's a lot of reasons this
[00:14:50.160 --> 00:14:58.080]   happens. So when you start to combine all of those factors together, when you have a confluence of
[00:14:58.960 --> 00:15:07.520]   bad parenting, the culture, the games, the social media channels, the means of communication,
[00:15:07.520 --> 00:15:12.560]   that all of it starts to amplify. And that's the problem. It feels like a modern problem. It
[00:15:12.560 --> 00:15:20.960]   feels like something that we have as technologists, but also society as a whole has kind of been
[00:15:20.960 --> 00:15:27.200]   going in this direction for some time. And we are now, we've sowed the wind and we're reaping the
[00:15:27.200 --> 00:15:32.320]   hurricane. It feels like this is something we've been building up to. But let's talk specifically
[00:15:32.320 --> 00:15:36.000]   about games. And then I would like to talk about YouTube and other platforms. Brianna,
[00:15:36.000 --> 00:15:38.880]   what should gaming companies be doing differently?
[00:15:38.880 --> 00:15:44.960]   Well, I really just before I say that, I want to echo what you're saying, Leo. It is unbelievably
[00:15:44.960 --> 00:15:51.040]   critical that we don't take this too far. The liberal right to free speech in this country,
[00:15:51.040 --> 00:15:57.680]   it is one of our greatest achievements as a culture. And we need to think extremely
[00:15:57.680 --> 00:16:03.520]   carefully when we're talking anything around here. That said, the conclusion I have come to
[00:16:03.520 --> 00:16:10.080]   through direct interaction with H.M. for years and years of violent threats is I don't consider
[00:16:10.080 --> 00:16:16.320]   them different than ISIS or ISIL, where we do freely take down those sites for recruitment.
[00:16:16.320 --> 00:16:22.080]   I do think it's become a haven for terrorists, in my opinion, as far as actions that the game
[00:16:22.080 --> 00:16:27.120]   industry needs to do. Again, I want to take you back in time when I was thinking about starting
[00:16:27.120 --> 00:16:32.800]   my game studio, there was a podcast on IGN called Girl Fight, where they got some of the best known
[00:16:32.800 --> 00:16:38.960]   women at IGN to basically put a podcast together. It wasn't political, it was just about the games
[00:16:38.960 --> 00:16:44.320]   that they liked. When we made Rocket, we actually took the Girl Fight formula and just copied it
[00:16:44.320 --> 00:16:52.320]   and made it for wider tech. And in that era, IGN was very unwilling to go through and moderate the
[00:16:52.320 --> 00:16:58.400]   comments and ban people for acting in bad faith and basically harassing these women.
[00:16:58.400 --> 00:17:04.400]   I think what just happened is we've created a culture where there are no consequences
[00:17:04.400 --> 00:17:10.080]   for that kind of behavior. So I think first of all, across the industry, not just in games,
[00:17:10.080 --> 00:17:16.080]   but for game journalist sites and on Reddit, I want to see a lot more investment in the terms of
[00:17:16.080 --> 00:17:21.280]   service. If you're threatening to murder someone that's not a free speech issue, your account needs
[00:17:21.280 --> 00:17:26.720]   to be banned. And I do think that law enforcement needs to look into some of the more serious threats.
[00:17:26.720 --> 00:17:31.200]   There is a lot of education. And we're seeing it already because Achan,
[00:17:31.200 --> 00:17:38.160]   which a cloud flare pulled the plug on finally last week and two cows, their domain registrar,
[00:17:38.160 --> 00:17:44.560]   pulled the plug on. So everybody went to zero, Achan. And this is part of the problem with this.
[00:17:44.560 --> 00:17:49.520]   You ban a Twitter account, they create a new account. You ban somebody on Reddit, they create a new
[00:17:49.520 --> 00:17:56.880]   account. It feels like whack-a-mole. It doesn't feel like this is too easy to do. I mean,
[00:17:56.880 --> 00:18:01.120]   it seems like a hard thing to shut down. And there's even this larger concern. There's the
[00:18:01.120 --> 00:18:06.640]   motherboard article about Achan moving to the, and I hate the use of this term, dark web.
[00:18:07.600 --> 00:18:14.480]   Because it's a silly term. But my fear is you force this underground,
[00:18:14.480 --> 00:18:18.000]   then it still goes on. It just goes on underground. That didn't solve anything.
[00:18:18.000 --> 00:18:21.120]   But you don't want them recruiting. Is that the point?
[00:18:21.120 --> 00:18:28.800]   I do think in Achan's particular case, forcing them to go into different, again,
[00:18:28.800 --> 00:18:34.240]   I also hate that phrase dark web. It does make it harder to access. So I do think it's
[00:18:34.240 --> 00:18:37.840]   step in the direction. We don't have a-- So put it back under that rock. We thought for a long
[00:18:37.840 --> 00:18:44.960]   time, light would disinfect. That's apparently not the case. I think saying you cannot operate
[00:18:44.960 --> 00:18:51.600]   this kind of website in a reputable company like CloudFlare or Reddit or something like that. I
[00:18:51.600 --> 00:18:56.240]   think that's a reasonable step to say. But I just want to stress, this is not something I say with
[00:18:56.240 --> 00:19:03.200]   any joy in my heart. It's a very serious action to take. But again, I had to report to the FBI
[00:19:03.200 --> 00:19:09.040]   incredible mass shooting where thousands of people could have been killed just a few weeks ago,
[00:19:09.040 --> 00:19:13.440]   from Achan. This is serious stuff.
[00:19:13.440 --> 00:19:21.200]   That's part of the problem. It's impossible to distinguish the serious stuff. Clearly El Paso
[00:19:21.200 --> 00:19:28.560]   Dayton was serious. But it's impossible to distinguish the El Paso shooters manifesto on Achan
[00:19:28.560 --> 00:19:34.640]   from a dozen copycats who are just kids in their jammies. I don't know how-- I mean,
[00:19:34.640 --> 00:19:38.400]   that's when you send out the Secret Service. You send out the FBI and you have them go interview
[00:19:38.400 --> 00:19:45.680]   on my guest. But I also really worry that-- So one of the things you're talking about, I take it,
[00:19:45.680 --> 00:19:51.840]   is this notion of domestic terrorism and red flagging. And this is a debate that's going on in
[00:19:51.840 --> 00:19:59.920]   Congress right now and nationally right now. As it happens, law enforcement, it's difficult for
[00:19:59.920 --> 00:20:06.400]   them to red flag an American because of this fear of chilling effect on their First Amendment
[00:20:06.400 --> 00:20:13.520]   rights. And so family and friends who are saying, this guy is nuts and has guns and I'm worried,
[00:20:13.520 --> 00:20:19.200]   can't necessarily go to the police and say, do something. The fact is that the case,
[00:20:19.200 --> 00:20:22.720]   Brandon, that often the local police can't or won't do anything.
[00:20:22.720 --> 00:20:29.440]   That's just been my experience. I also think you cannot overstate just how poorly prepared
[00:20:29.440 --> 00:20:36.000]   local police jurisdictions are to deal with online crimes. Here, Massachusetts were relatively
[00:20:36.000 --> 00:20:40.880]   well-funding. I can tell you, our cyber division is much more effective today than it was at the
[00:20:40.880 --> 00:20:46.480]   start of game or game. But it was a ramp up process to learn that. These are very difficult
[00:20:46.480 --> 00:20:54.720]   problems, Leo, and we don't have 100% solution, but we have 101% solutions, if that makes sense.
[00:20:54.720 --> 00:20:59.600]   We have a lot of little things that we can do to make this better. It's going to be federal laws,
[00:20:59.600 --> 00:21:05.280]   it's going to be local laws, it's going to be state laws. But bullets don't care if you're a
[00:21:05.280 --> 00:21:10.800]   Republican or a Democrat. They're going to harm you either way. And we've really got to tackle this.
[00:21:11.760 --> 00:21:17.360]   The other thing is, you talked about red flagging a minute ago, you have to be careful, even if
[00:21:17.360 --> 00:21:23.360]   you are going to have law enforcement go in and investigate these kinds of threats online,
[00:21:23.360 --> 00:21:27.760]   you have to be careful about how they do that because then you end up in situations like these
[00:21:27.760 --> 00:21:34.400]   swatting scenarios. Far too often, our police in this country have become way too militarized
[00:21:34.400 --> 00:21:41.840]   and way too ready to pull the trigger before actually investigating something. So if we're
[00:21:41.840 --> 00:21:47.920]   going to try to take a more aggressive approach to investigating these kinds of threats,
[00:21:47.920 --> 00:21:55.440]   at the same time, we have to rein in the law enforcement and make sure that they're doing it
[00:21:55.440 --> 00:22:00.400]   in a responsible way. Well, and furthermore, I worry about government efforts in general.
[00:22:00.400 --> 00:22:06.000]   It's not too far from that to go to the Chinese social credit system where suddenly you lose
[00:22:06.000 --> 00:22:12.720]   rights and privileges because you're not a good member of society or in Turkey now,
[00:22:12.720 --> 00:22:18.080]   where they're requiring licenses for streaming broadcasters, including podcasters, before they
[00:22:18.080 --> 00:22:25.120]   can make shows. And almost always, this is done with the very plausible rationale that,
[00:22:25.120 --> 00:22:30.960]   well, we're protecting public safety. I was thinking about this the other day. Leo,
[00:22:30.960 --> 00:22:35.520]   I think your point about asking government to come up with tech solutions,
[00:22:35.520 --> 00:22:44.960]   which often gets really tricky is really interesting. At least in my mind, you could see a scenario
[00:22:44.960 --> 00:22:50.160]   where you see more regulation in terms of the government actually saying, stipulating to
[00:22:50.160 --> 00:22:57.280]   tech companies saying, you have to spend this percent of your revenue on solving this problem,
[00:22:57.280 --> 00:23:02.160]   basically saying you like more of a budgetary measure, like you literally you have to build a
[00:23:02.160 --> 00:23:09.840]   division within your company to solve this problem. And I wonder if that would be a way forward
[00:23:09.840 --> 00:23:19.280]   in some scenarios, basically forcing tech companies to look at this stuff more carefully and leverage
[00:23:19.280 --> 00:23:25.360]   resources towards it. I think there's also an interesting culture conversation happening here.
[00:23:25.360 --> 00:23:32.480]   We did, on Endless Thread, in the beginning of the summer, we did a big series on vaccines and
[00:23:32.480 --> 00:23:40.320]   anti-vaxxers. And what we found on Facebook was really fascinating because you discover
[00:23:40.320 --> 00:23:45.760]   on places like Facebook, which is now actually sort of updated their policy on this stuff.
[00:23:48.480 --> 00:23:55.760]   People become more radicalized, the sort of natural inclination of some of the algorithms that
[00:23:55.760 --> 00:24:01.920]   serve the information to people who are not radical at all and are just kind of curious about X, Y,
[00:24:01.920 --> 00:24:06.960]   and Z is that over and over they get further and further radicalized by the information that the
[00:24:06.960 --> 00:24:12.480]   platform serves them up. So I think even at that level, some of these companies have to be thinking
[00:24:12.480 --> 00:24:19.280]   more carefully about how they serve information to people who are trying to access information.
[00:24:19.280 --> 00:24:25.440]   And I know that that's a little bit different than what we're talking about in terms of the
[00:24:25.440 --> 00:24:30.000]   gaming industry, but I feel like there's a broader cultural conversation here about
[00:24:30.000 --> 00:24:38.800]   avoiding people becoming radicalized by the information that pops up in front of them
[00:24:38.800 --> 00:24:44.400]   when they put in a simple search term. And I think that's, I don't know, I feel like these two things
[00:24:44.400 --> 00:24:50.800]   are connected and clearly we should be thinking about it. Clearly there's a problem, but I also
[00:24:50.800 --> 00:24:55.200]   fear that there are people and there are people in every country, but in this country who will take
[00:24:55.200 --> 00:25:06.960]   advantage of the fear we are now under to create, I think, really egregiously awful laws,
[00:25:07.600 --> 00:25:13.600]   according to CNN on Friday, the White House is proposing to have the FCC and the FTC police
[00:25:13.600 --> 00:25:19.120]   social media. And in fact, what they want to do is they want to basically undermine
[00:25:19.120 --> 00:25:28.560]   Section 230. And, you know, I mean, it's the name of the act according to CNN, and this has not
[00:25:28.560 --> 00:25:36.720]   been confirmed by the government at all, is the Protecting Americans from Online Sensorship Act.
[00:25:36.720 --> 00:25:43.520]   It would be an executive order that would force the FCC to cut back on CDA Section 230 protection
[00:25:43.520 --> 00:25:50.880]   for internet platforms. And I think you can, you know, he's proposing this because he is his
[00:25:50.880 --> 00:25:56.400]   contention unproven that there is a prejudice against conservative thought on Twitter and other
[00:25:56.400 --> 00:26:02.160]   social media. But I think you could also use this to say, well, these platforms are being used to
[00:26:02.160 --> 00:26:07.520]   spread hate speech. And we need to have more control over this. And that's what I worry about.
[00:26:07.520 --> 00:26:14.800]   I this is a very challenging problem. And we're clearly at a point where we all feel like something
[00:26:14.800 --> 00:26:19.680]   has to be done. But I worry about what we might might do.
[00:26:19.680 --> 00:26:26.640]   I think I would say this, Leo. I mean, you know, I'm running for Congress because we have to have
[00:26:26.640 --> 00:26:32.480]   people thinking about these actions in a thoughtful way. I read what the Trump administration is
[00:26:32.480 --> 00:26:38.720]   proposing. I don't mean this as a left versus right thing. It doesn't strike me as a thoughtful
[00:26:38.720 --> 00:26:45.520]   solution that takes into account the entire problem. We need leaders, not just in Congress,
[00:26:45.520 --> 00:26:52.800]   but the state level at the local level, thinking through this and addressing it. And it's going
[00:26:52.800 --> 00:26:58.880]   to be a gargantuan challenge. But when you think about it, like, this is the information age.
[00:26:58.880 --> 00:27:04.480]   Like these tools, these systems, they define our society. They define our friends. They
[00:27:04.480 --> 00:27:11.040]   define how we get our jobs. We cannot shirk from taking this on. So I just think it's incredibly
[00:27:11.040 --> 00:27:16.000]   important that we get technology, technology literate people making those decisions.
[00:27:16.000 --> 00:27:20.000]   Is that the problem with this? Is that it's technologically illiterate?
[00:27:20.560 --> 00:27:24.800]   I think so. I think in terms of regulators, yes, I think most of the people that are in a position
[00:27:24.800 --> 00:27:30.720]   to regulate this are technologically illiterate. And most of the people that are making proposals
[00:27:30.720 --> 00:27:38.080]   like Josh Hawley and the White House are technologically illiterate. But at the same time, I think we
[00:27:38.080 --> 00:27:42.960]   also have a problem where the people running these platforms and these companies are ethically
[00:27:42.960 --> 00:27:49.280]   illiterate. They are technically illiterate, but they completely have no moral compass.
[00:27:49.280 --> 00:27:55.120]   Exactly. And this is part of the problem. And they're willing to let anything go.
[00:27:55.120 --> 00:28:03.360]   And in fact, they're even in the cases of certain individuals. They're even exempting them from
[00:28:03.360 --> 00:28:09.440]   their rules. In the case of Twitter, they have explicitly said that, no, we're not going to ban
[00:28:09.440 --> 00:28:15.680]   a certain individual who's the things that he has been saying are often quoted in these
[00:28:15.680 --> 00:28:20.800]   manifestos that have gone along with these acts of violence. This is actually this proposal from
[00:28:20.800 --> 00:28:26.160]   the Trump White House. And again, it has not a draft circulated according to CNN, but it has not
[00:28:26.160 --> 00:28:30.960]   been signed. Who knows? It could be a tribal. But probably would have the opposite effect,
[00:28:30.960 --> 00:28:40.560]   making it harder for sites like Twitter or even 8chan to ban violent speech. So basically, under
[00:28:40.560 --> 00:28:45.920]   the draft proposal, this is CNN. The FCC will be asked to find that social media sites do not qualify
[00:28:45.920 --> 00:28:52.160]   for Section 230's good faith immunity if they remove or suppress content without notifying the
[00:28:52.160 --> 00:28:56.160]   user who posted the material or if the decision is proven to be evidence of any competitive,
[00:28:56.160 --> 00:29:04.960]   unfair, deceptive practices. Ron Wyden who wrote Section 230 said the whole point of 230 was to
[00:29:04.960 --> 00:29:12.000]   allow platforms to get slime and hate off the platform without consequence, without liability.
[00:29:12.000 --> 00:29:20.320]   If you undermine 230, it's going to make it very difficult for platforms to block and ban anything.
[00:29:20.320 --> 00:29:27.840]   Yeah, you don't want to add a brand new layer or two of bureaucracy to the process, right?
[00:29:29.280 --> 00:29:35.600]   Because I do think that becomes problematic really fast. Again, in fact,
[00:29:35.600 --> 00:29:42.720]   Wyden says he doesn't see the FCC or FTC to jump in at this to do it. He said,
[00:29:42.720 --> 00:29:46.560]   "Well, Evan jumped at regulating anything else. So why would they start with this?"
[00:29:46.560 --> 00:29:56.800]   This is my fear, is that we can also act out of fear, act quickly and do the wrong thing.
[00:29:57.600 --> 00:30:04.240]   Of course, with this Cloudflare solution, I would really encourage Americans to think about how
[00:30:04.240 --> 00:30:11.120]   serious this is. The open access to the free internet is so important. Everyone on this show
[00:30:11.120 --> 00:30:18.880]   today understands this. It is hard fought. I hate that they're forcing us to go down this
[00:30:18.880 --> 00:30:26.560]   road because it's, as you say, it's unbelievably serious. But it's also at a point where we have
[00:30:26.560 --> 00:30:32.880]   basically been ignoring this for at least the last five years since Game Arcade.
[00:30:32.880 --> 00:30:37.280]   At the end of this month, it is the five-year anniversary since Game Arcade.
[00:30:37.280 --> 00:30:44.080]   I want to tell you, it affects my life every single day, every day. I get death threats.
[00:30:44.080 --> 00:30:49.600]   You just would not believe to this day. People showing up, taking pictures of my house,
[00:30:49.600 --> 00:30:54.880]   it is very real to me. I hate to blame anything, though. We have an
[00:30:54.880 --> 00:31:01.040]   uncivil society, clearly. There are many, many causes. But I think it's unfair to say video
[00:31:01.040 --> 00:31:08.400]   games cause it any more than television, cause my baby boomer generation to be whatever bad thing
[00:31:08.400 --> 00:31:19.520]   you want to accuse us of. Media, I hate to say media can be blamed for this. I don't know what
[00:31:19.520 --> 00:31:24.160]   the answer is. I just don't know. I don't think blaming media is the solution.
[00:31:24.160 --> 00:31:34.160]   I love that. What's that meme of all the meme that the language is? Look at this technology
[00:31:34.160 --> 00:31:39.200]   that's completely isolating us. It has Jeff Jarvis in the newspaper on the train.
[00:31:39.200 --> 00:31:43.360]   As Jeff Jarvis will say, as soon as Gutenberg invented the printing press, people said,
[00:31:43.360 --> 00:31:47.840]   "It's end of civilization. It's all over. Kids will be reading books instead of going outside
[00:31:47.840 --> 00:31:54.880]   to play." Look how that turned out. We've played every new form of media, and I think video games
[00:31:54.880 --> 00:32:02.000]   and social media are the newest for all of our ills. Clearly, we have ills. Clearly.
[00:32:02.000 --> 00:32:07.200]   That's a human problem. It's a human problem. Is it worse now?
[00:32:07.200 --> 00:32:17.520]   I think what's worse now is the constituents have amplified our awareness of it.
[00:32:18.480 --> 00:32:25.040]   We've got this combination of that amplification of those voices and our awareness of it,
[00:32:25.040 --> 00:32:31.200]   and the ready access to high-powered firearms. I think we're inches away from... Russia just
[00:32:31.200 --> 00:32:37.360]   shut down the mobile networks because protesters in Moscow were using their phones to organize.
[00:32:37.360 --> 00:32:43.680]   It's been done elsewhere in the last few years. We are inches away from this kind of
[00:32:43.680 --> 00:32:49.200]   mass government intervention. I hate to give them more ammunition out of fear.
[00:32:49.200 --> 00:32:57.120]   It's been a really interesting transition when you think about the fact that,
[00:32:57.120 --> 00:33:02.400]   and obviously the First Amendment part of this conversation is also really interesting because
[00:33:02.400 --> 00:33:09.360]   I do think, actually, that even though we can all agree that tech companies are probably underfunding
[00:33:10.800 --> 00:33:19.520]   their ethics departments. I do think there's been this interesting transition where you think about
[00:33:19.520 --> 00:33:27.120]   a KKK march 20 years ago or something like that. That was happening on a public street.
[00:33:27.120 --> 00:33:38.240]   There were rules about where those people could march. Police are there enforcing, etc.
[00:33:39.440 --> 00:33:45.200]   In some ways, the public square has now moved online, but it's no longer a public square.
[00:33:45.200 --> 00:33:53.120]   It's on private platforms. It really does seem like these private platforms need to now
[00:33:53.120 --> 00:33:59.360]   enforce some of these regulations that, sure, if you want to preserve the First Amendment,
[00:33:59.360 --> 00:34:04.160]   okay, but if you're going to do that, you really need to
[00:34:05.200 --> 00:34:09.840]   cordon it off in a way that preserves the safety of other users.
[00:34:09.840 --> 00:34:16.160]   I have to say something about that because I went to the University of Mississippi,
[00:34:16.160 --> 00:34:22.080]   and I've seen the KKK march to the streets many times in my life. One of the most inspirational
[00:34:22.080 --> 00:34:27.760]   things I ever saw while I was in Mississippi was the KKK came to march at Old Miss. This was
[00:34:27.760 --> 00:34:35.360]   around 2003, if I remember correctly. I want for you to imagine hundreds of conservative
[00:34:35.360 --> 00:34:41.600]   Southerners standing out there, turning their backs to the making it clear that they didn't stand
[00:34:41.600 --> 00:34:48.640]   with them. It was such an inspirational thing. That's not something you can have online. Also,
[00:34:48.640 --> 00:34:55.280]   when the KKK came to Old Miss to protest, the police were there. I can promise you, if any one
[00:34:55.280 --> 00:35:01.440]   of those KKK people had done something that threatened a person of color, someone would have
[00:35:01.440 --> 00:35:10.000]   gone to jail. I can promise you that. As it is, law enforcement treats these kinds of online
[00:35:10.000 --> 00:35:19.520]   activity much differently than we do the KKK. I think that's why we make people go before a judge,
[00:35:19.520 --> 00:35:24.640]   do process, follow the law, probable cause, all of those things. But it's very clear to me,
[00:35:24.640 --> 00:35:29.600]   we need to fund more law enforcement online. I totally agree with that.
[00:35:29.600 --> 00:35:34.800]   Extremism of all stripes, regardless of political stripes, extremism feeds on fear.
[00:35:34.800 --> 00:35:39.360]   Whether you're talking about the far right or the far left or anywhere in between,
[00:35:39.360 --> 00:35:49.680]   they're always using fear to build support for extremism. That's, I think, the key. I don't know
[00:35:49.680 --> 00:35:53.360]   what the answer is to get away from it. I think part of what you said, Brie, about
[00:35:53.360 --> 00:36:01.040]   people turning their backs on the KKK, that's a tangible example of people rejecting fear.
[00:36:01.040 --> 00:36:06.080]   I think that's what we need to do broadly, is we need to come together and reject fear,
[00:36:06.080 --> 00:36:14.880]   fear of the other, fear of the unknown. We need to find ways to say to leaders that are trying to
[00:36:14.880 --> 00:36:22.080]   foment fear by whatever means that, no, that's not acceptable. We will not be afraid.
[00:36:22.080 --> 00:36:26.640]   I think it's only then that we start to solve this problem.
[00:36:26.640 --> 00:36:35.760]   Let's take a break. It's such an important discussion. It's such a difficult
[00:36:35.760 --> 00:36:40.160]   problem. I don't know what the solution is at all.
[00:36:41.600 --> 00:36:45.520]   I somewhat fear that every site is going to use it to exploit, is going to exploit it to
[00:36:45.520 --> 00:36:52.400]   push their own agenda, whether it's gun control or banning video games or
[00:36:52.400 --> 00:37:01.280]   mental illness or whatever. I don't know if there's any one solution. I think social media is equal,
[00:37:01.280 --> 00:37:04.160]   as much to blame as video games. If you talk about-
[00:37:04.160 --> 00:37:05.360]   It's not more.
[00:37:05.360 --> 00:37:09.760]   If not more, if you talk about somewhere that's fostering a culture and propagandizing,
[00:37:09.760 --> 00:37:15.920]   and I mean, it's doing all of that stuff. 8chan is social media. It's not a video game. It's social
[00:37:15.920 --> 00:37:23.200]   media. Banning Twitter is not the solution either. I don't know what the answer is.
[00:37:23.200 --> 00:37:25.920]   But banning the people that are fomenting fear.
[00:37:25.920 --> 00:37:29.200]   You can't. They just create another account.
[00:37:29.200 --> 00:37:31.040]   You ban them again. You can keep doing it.
[00:37:31.040 --> 00:37:36.720]   You'll never win. No, this is the real problem. Facebook and Twitter face no amount of-
[00:37:36.720 --> 00:37:38.880]   There aren't enough people in the world to police them.
[00:37:38.880 --> 00:37:41.920]   It feels like they're now rhythmically.
[00:37:41.920 --> 00:37:48.320]   I was just going to say, it feels like no matter what we do here, someone's going to use it as
[00:37:48.320 --> 00:37:55.280]   an excuse to go after and hurt someone they already don't like on all sides. It makes it
[00:37:55.280 --> 00:37:57.360]   very hard to address this constructively.
[00:37:57.360 --> 00:38:01.840]   Yeah. Well, there you go. This is a conversation we have a lot on this network.
[00:38:01.840 --> 00:38:06.320]   I wish we didn't start Twitter. I didn't get into technology journalism.
[00:38:06.320 --> 00:38:10.560]   Because I wanted to talk about this. I wanted to talk about the latest computer chip.
[00:38:10.560 --> 00:38:16.800]   But unfortunately, the consequences of what we have wrought
[00:38:16.800 --> 00:38:23.440]   are starting out way the actual hardware. And I don't know what the answer is.
[00:38:23.440 --> 00:38:29.200]   I don't think we're well equipped to solve it. Maybe just have to ride this ride to the end to
[00:38:29.200 --> 00:38:33.680]   see what happens. I just don't want the wrong solution to be promulgated.
[00:38:33.680 --> 00:38:37.200]   And then five years from now, we look back and say, well, that didn't work.
[00:38:37.200 --> 00:38:38.480]   Well, that's worse.
[00:38:38.480 --> 00:38:42.400]   Well, let's talk about chips.
[00:38:42.400 --> 00:38:47.840]   No, the new phones are here. I don't know. We'll find something just a second.
[00:38:47.840 --> 00:38:51.280]   I showed it. I brought to you, by the way, great panel. Thank you, Ben Brock Johnson,
[00:38:51.280 --> 00:38:56.800]   for being here from WBUR. It is Austin. He's a senior producer there.
[00:38:56.800 --> 00:39:00.640]   Candidate for the Massachusetts 8th. When is the primary?
[00:39:01.760 --> 00:39:04.480]   September 20th. Oh, my. I ran a week.
[00:39:04.480 --> 00:39:05.040]   Twenty-twenty.
[00:39:05.040 --> 00:39:06.320]   Thirteen months. Thirteen.
[00:39:06.320 --> 00:39:09.520]   Yes. Oh, September 20th of next year. Oh, she's correct.
[00:39:09.520 --> 00:39:12.160]   I thought, oh, my God, it's good. She's next month. She's just getting warmed up.
[00:39:12.160 --> 00:39:14.160]   No, I wouldn't be here if it was that close.
[00:39:14.160 --> 00:39:17.200]   Oh, man. Yeah, you're going to get busy. You're going to get real busy.
[00:39:17.200 --> 00:39:21.840]   I kind of wish you would all be over by then. I would love for it to be over by then.
[00:39:21.840 --> 00:39:25.280]   Let's do it next month. Do we just move it all up and just do it next month? That would be nice.
[00:39:26.080 --> 00:39:31.840]   Let the people speak. And of course, my car guy, my own personal car guy,
[00:39:31.840 --> 00:39:36.320]   Sam, will submit. We'll talk about cars. Let's talk about cars. That's a good subject.
[00:39:36.320 --> 00:39:39.840]   That's a fun subject. Autonomous cars are going to kill us all.
[00:39:39.840 --> 00:39:40.480]   Oh, crap.
[00:39:40.480 --> 00:39:47.520]   I showed they brought to you by ZipRecruiter. Hiring used to be hard, right? In fact,
[00:39:47.520 --> 00:39:50.960]   you're always hiring at the worst possible time, especially a small company like ours.
[00:39:50.960 --> 00:39:53.920]   You're down a person or two, and you've got to fill positions.
[00:39:54.800 --> 00:40:00.400]   Plus, I think for us, and I bet it's true for your company too, I always feel like the right
[00:40:00.400 --> 00:40:06.000]   person's there somewhere. The question is how you reach them. There are hundreds of job boards.
[00:40:06.000 --> 00:40:08.960]   How do you know which job board they're on? How do you know what they're looking at?
[00:40:08.960 --> 00:40:13.520]   So it all starts with ZipRecruiter because you post a job on ZipRecruiter.
[00:40:13.520 --> 00:40:20.480]   It instantly is posted on over 100 of the web's leading job boards, including Twitter and
[00:40:20.480 --> 00:40:24.080]   Facebook, the social media sites everywhere. I mean, this is going to maximize the chance
[00:40:24.080 --> 00:40:29.200]   of your getting to that person who's out there just waiting to find out about your job. But they
[00:40:29.200 --> 00:40:34.400]   don't stop there. They go even farther with ZipRecruiter's powerful matching technology.
[00:40:34.400 --> 00:40:39.360]   See, a lot of people come to ZipRecruiter applying for jobs. They'll scan those to find
[00:40:39.360 --> 00:40:43.600]   people with the exact experience you're looking for, and then say to them that they'll invite
[00:40:43.600 --> 00:40:49.680]   them to apply to your job. And then as the applications come in, they don't come into your email box
[00:40:49.680 --> 00:40:55.040]   or your phone. They go into the ZipRecruiter interface. ZipRecruiter analyzes each one automatically spot
[00:40:55.040 --> 00:41:00.160]   lights the top candidates. You never miss a great match. They pre-format their resume, so it's easy
[00:41:00.160 --> 00:41:05.360]   to scan them. You can even have screening questions that help you eliminate candidates that aren't
[00:41:05.360 --> 00:41:12.000]   right for the job. ZipRecruiter works so well. And this is out of our own experience. The four out
[00:41:12.000 --> 00:41:16.320]   of five employers who post on ZipRecruiter will get a quality candidate through the site within the
[00:41:16.320 --> 00:41:21.840]   first day. In our case, Lisa posted at breakfast by lunch. She had three candidates. They kept
[00:41:21.840 --> 00:41:26.480]   coming in. She'd go, "Oh, this one's good. Oh, this one's really good. Oh my God." It really was
[00:41:26.480 --> 00:41:32.080]   an eye-opener. Right now, this week at Tech listeners can try ZipRecruiter free, but you have to go to
[00:41:32.080 --> 00:41:37.600]   ziprecruiter.com/twit. And that's a great way to show your support for the show. Plus,
[00:41:38.480 --> 00:41:47.520]   cut through that difficult job hiring process with a great solution. ZipRecruiter.com/twit.
[00:41:47.520 --> 00:41:54.320]   Z-I-P-R-E-C-R-U-I-T-E-R. ZipRecruiter.com/twit. ZipRecruiter is the smartest way to hire.
[00:41:54.320 --> 00:42:00.160]   Thank you, ZipRecruiter, for supporting our show. Do you find Mike Anant on ZipRecruiter?
[00:42:00.160 --> 00:42:06.640]   No, I already knew about them. In a way, this show and the other shows we do,
[00:42:06.640 --> 00:42:12.560]   they're the kind of... The farm leagues? The farm leagues for our shows. It's a great way to find
[00:42:12.560 --> 00:42:20.320]   people. And the people we get on, like you and Ben and Brianna are just fantastic. I feel like
[00:42:20.320 --> 00:42:25.600]   I feel privileged every week to get together with people who do these shows. That's just really
[00:42:25.600 --> 00:42:30.080]   an honor. And you know, this is why I bring up these tough questions, like how do we solve
[00:42:30.080 --> 00:42:35.360]   the gun violence problem? Because if you guys can't solve it, I don't know anybody who can.
[00:42:36.160 --> 00:42:40.640]   Right? If we can't... I mean, imagine some poor senator who still doesn't know what
[00:42:40.640 --> 00:42:45.120]   Twitter is trying to figure out what's going on. It's not easy. We're going to send Brianna to
[00:42:45.120 --> 00:42:49.040]   Congress. That'll solve. That'll get it. That'll get it going. And it is getting good.
[00:42:49.040 --> 00:42:54.160]   I did. I did always like the Chris Rock solution. The every bullet should cost $5,000.
[00:42:54.160 --> 00:42:57.680]   That's good. That's how committed are you? How committed are you?
[00:42:57.680 --> 00:43:02.640]   I have a sneaking suspicion that most of the people are committing these acts probably could
[00:43:02.640 --> 00:43:08.160]   not afford $5,000 bullets. We don't know. If only rich people can buy bullets,
[00:43:08.160 --> 00:43:13.680]   then only rich people will be outlaws. No, that doesn't make sense. Perhaps they should.
[00:43:13.680 --> 00:43:22.880]   Rich people already are outlaws, right? They just have more subtle ways of prosecuting their agenda.
[00:43:22.880 --> 00:43:27.920]   Speaking of rich people, Goldman Sachs, bank of the rich and powerful,
[00:43:29.200 --> 00:43:34.720]   is according to CNBC dipping into subprime lending with the Apple Card.
[00:43:34.720 --> 00:43:39.120]   Goldman does the back end of the Apple Card. It started to roll out. I haven't got mine yet.
[00:43:39.120 --> 00:43:47.520]   Apple focused on the fact that it's a titanium card, the privacy. There's no number on it,
[00:43:47.520 --> 00:43:51.760]   the wallet that lets you plan your future. But really, the most important part of the card is
[00:43:51.760 --> 00:43:59.920]   the back end, which is Goldman Sachs. They decide who gets it, by the way. I found interesting.
[00:43:59.920 --> 00:44:03.200]   Laura Gil knows somebody who had a... What was it? 730?
[00:44:03.200 --> 00:44:04.000]   Yes, 730.
[00:44:04.000 --> 00:44:08.720]   Which is not the best in the world, but not bad. He's paying the top interest rate.
[00:44:08.720 --> 00:44:14.960]   23% or 24% is the top interest rate. I'm not sure how this is going to work. According to CNBC,
[00:44:15.520 --> 00:44:20.480]   Goldman is accepting some applications from users with less than stellar credit scores.
[00:44:20.480 --> 00:44:27.360]   Partly, I think, because of pressure from Apple, which really wants as many people as
[00:44:27.360 --> 00:44:33.600]   possible to be using Apple Pay. "I was absolutely shocked I got it," says one early user with a
[00:44:33.600 --> 00:44:37.920]   FICO score of 620. Is 620 that bad? Maybe it is.
[00:44:37.920 --> 00:44:39.600]   It's not great. Not great.
[00:44:39.600 --> 00:44:42.960]   I'd have a hard time getting a mortgage with a score of 60.
[00:44:42.960 --> 00:44:51.120]   It's funny. We rag on China for their social credit system. Oh my god, you have four social
[00:44:51.120 --> 00:44:56.480]   credit. You can't get bank loan. What the hell is a FICO score? But a social credit score, right?
[00:44:56.480 --> 00:45:02.720]   And for most people, it's a mystery. I think people more and more know there is now, thank goodness.
[00:45:02.720 --> 00:45:06.960]   But for a long time, nobody tell you what your score is. They just say, "Yeah, not you."
[00:45:06.960 --> 00:45:12.160]   The key difference is that your FICO score doesn't go down if you criticize your government.
[00:45:12.160 --> 00:45:14.080]   That's true. But that's true about that.
[00:45:14.080 --> 00:45:17.040]   That doesn't matter. We don't know really. It's just a matter of time.
[00:45:17.040 --> 00:45:18.720]   I mean, it's a pretty opaque formula.
[00:45:18.720 --> 00:45:25.920]   I think it's so surprising Apple is operating in this space. I just don't get it. When there
[00:45:25.920 --> 00:45:31.840]   were rumors about Apple doing an Apple car, my first thought was, "Wow, is this what Apple wants
[00:45:31.840 --> 00:45:38.880]   to be associated with? Your iPod doesn't run you over in the street, right? Or the headache of
[00:45:38.880 --> 00:45:42.080]   going and getting it repaired. It just seems really off-brand."
[00:45:42.080 --> 00:45:48.960]   Today, Sony has basically the last time I looked two profitable divisions. The first one is their
[00:45:48.960 --> 00:45:54.400]   PlayStation division and the other is their consumer finance division. For a company like
[00:45:54.400 --> 00:46:01.360]   Sony that doesn't really have the hottest products right now, I understand it. It's a bizarre place
[00:46:01.360 --> 00:46:08.080]   for Apple to be operating in because the stories that people getting into tons of debt on this card
[00:46:08.080 --> 00:46:15.760]   are just incoming. They're inevitable. Apple is part of Apple's becoming a service company.
[00:46:15.760 --> 00:46:20.960]   When the iPhone sales start to taper off, Apple says, "Well, we're not going to sell as much stuff,
[00:46:20.960 --> 00:46:25.600]   so we need to figure out a way to make more money per customer." That is going to be through a
[00:46:25.600 --> 00:46:33.040]   constant revenue stream on services. I think Apple looks at Apple Pay as the prime way they
[00:46:33.040 --> 00:46:38.880]   can make money. Right now, it's the App Store. They get 30% of every sale. It's Apple Music.
[00:46:38.880 --> 00:46:44.960]   It's successful. It's no Spotify, but it's doing all right. iCloud, which they push on everybody
[00:46:44.960 --> 00:46:49.840]   all the time. Really, if you think about it, if everybody would just start using Apple Pay on
[00:46:49.840 --> 00:46:53.680]   their phone and their watch, Apple would get a percentage of all the transactions.
[00:46:53.680 --> 00:46:58.720]   That's real profit. It's like what you've been talking about for years around Amazon. Amazon
[00:46:58.720 --> 00:47:04.400]   getting into all these different businesses, where for every transaction in the economy,
[00:47:04.400 --> 00:47:09.040]   they get a small percentage. They get a cut. Apple's trying to go in that same direction.
[00:47:09.040 --> 00:47:16.320]   Most companies are trying to move away from a model of sell something once and then
[00:47:16.320 --> 00:47:20.400]   forget it, move on, try to sell the customer something else at some later date to
[00:47:20.400 --> 00:47:26.400]   continuous recurring payments. That's what you want. As you've talked about,
[00:47:26.400 --> 00:47:31.680]   a revenue stream, you want that steady revenue stream coming in every month.
[00:47:31.680 --> 00:47:34.960]   Once it gets going, it's really hard to stop it.
[00:47:34.960 --> 00:47:41.280]   You're probably right, Brianna. Apple, why would Apple want to get in this business?
[00:47:41.280 --> 00:47:48.480]   It's nothing but a black mark on its escutcheon, because they need to. There's only so much money
[00:47:48.480 --> 00:47:53.120]   you can make selling singles. They need to.
[00:47:54.480 --> 00:48:00.000]   Yeah, I think it's interesting. Our mutual friend Christina Warren, she will buy anything Apple
[00:48:00.000 --> 00:48:06.160]   puts out. She has the worst judgment with this stuff. I don't want to, but I have to. I'm going
[00:48:06.160 --> 00:48:10.320]   to be buying a new iPhone next month. I don't need a new iPhone. I just bought a new Note 10.
[00:48:10.320 --> 00:48:14.640]   I don't need a new iPhone or a Note 10 or any of that. I'm saying it out this year again,
[00:48:14.640 --> 00:48:21.440]   but even Christina Warren is like, I don't want this car. I would not trust a member of Congress
[00:48:21.440 --> 00:48:24.400]   that had a new phone every year. If you're doing the right thing,
[00:48:24.400 --> 00:48:30.160]   Warren Buffett drives a Chevy Gio or something. I don't know what he drives.
[00:48:30.160 --> 00:48:40.400]   Yeah, it's interesting. I feel like you raised an interesting point with the Apple car. Do you
[00:48:40.400 --> 00:48:44.720]   want the guy who designed the iPod to be designing your car? It's funny you should say that because
[00:48:44.720 --> 00:48:50.640]   we had a really good conversation on Friday with an auto writer. You know him. He's the editor of
[00:48:50.640 --> 00:48:55.280]   a camera. He's the mobility editor of the drive at Needlemyer.
[00:48:55.280 --> 00:49:02.640]   Yeah. I love him. You know, Ed, his new book just coming out this week called Tesla. I'm sorry,
[00:49:02.640 --> 00:49:10.080]   called Ludacris, the story of Tesla, the car company. And his, I thought it, you know, by the way,
[00:49:10.080 --> 00:49:17.120]   you think it's, you think being a female game designer is dangerous, writing about Tesla and
[00:49:17.120 --> 00:49:22.800]   anything that's not 100% positive. You are going to get flamed and poor.
[00:49:22.800 --> 00:49:28.000]   They're done. Yeah. Or Ed is just hammered by this. But I think he's tried really to be very
[00:49:28.000 --> 00:49:34.240]   even handed. And I think the conclusion he came up with is the problem is Tesla is being run,
[00:49:34.240 --> 00:49:40.000]   intentionally being run like a Silicon Valley startup, like a software company. But cars,
[00:49:40.000 --> 00:49:44.880]   the demand of a car, first of all, it's a very expensive durable good. It's one of the most
[00:49:44.880 --> 00:49:48.400]   expensive things you buy in your life. Second, second biggest after your house.
[00:49:48.400 --> 00:49:54.400]   And it, and you, and it's safety is the number one job. It's got to get you to working back,
[00:49:54.400 --> 00:49:58.640]   not only with not breaking down, but without the wheels falling off or veering into the wrong
[00:49:58.640 --> 00:50:06.720]   lane. And so car, real car companies have spent a lot of energy on process so that they can make a
[00:50:06.720 --> 00:50:11.280]   product that reliably make 10 million of them a year reliably. And they're not going to endanger
[00:50:11.280 --> 00:50:15.040]   people's lives. And the Ford Pinto not really standing, they do a pretty good job.
[00:50:15.040 --> 00:50:19.600]   Well, I mean, there have been plenty of examples over the years, including most recently GM with
[00:50:19.600 --> 00:50:25.280]   their ignition switches, you know, in the past decade. You know, they companies, you know, car
[00:50:25.280 --> 00:50:30.560]   companies make mistakes. They do it on a fairly regular basis. You know, the Volkswagen diesel
[00:50:30.560 --> 00:50:34.800]   gate scandal, well, that wasn't a mistake. That was on purpose. But they do things they,
[00:50:34.800 --> 00:50:38.400]   they make decisions that they shouldn't make. Let's put it that way.
[00:50:38.400 --> 00:50:43.600]   Yeah. They're not perfect. Yeah. But, but they, but they do have processes and they do understand
[00:50:43.600 --> 00:50:47.920]   that safety is crucial. But to compare the number of mistakes they make to the number of mistakes,
[00:50:47.920 --> 00:50:53.040]   a software company makes. And this is the difference is that the prime motivating factor with a
[00:50:53.040 --> 00:50:57.440]   software company, just look at Facebook's motto. What does it fail fast?
[00:50:57.440 --> 00:51:01.200]   Still fast and iterate and move and move fast and break things.
[00:51:01.200 --> 00:51:06.000]   Yeah. When you're driving a car failing fast and breaking things is not a good motto.
[00:51:06.880 --> 00:51:11.680]   No. And I have to say, as a Tesla owner for three years, it was kind of like that. My wife calls it
[00:51:11.680 --> 00:51:17.120]   our beta car. Well, it's funny, you know, back about 10, 11 years ago, when, when Jeff Jarvis
[00:51:17.120 --> 00:51:21.200]   wrote his book, What Would Google Do? One of the chapters in there, he talked about, you know,
[00:51:21.200 --> 00:51:27.280]   that car companies should build beta vehicles. And that's exactly what Tesla has done.
[00:51:27.280 --> 00:51:31.360]   He's just never got to and it did final version. Well, yeah, you know, and it, you know, it,
[00:51:31.360 --> 00:51:36.560]   that hasn't worked out so well. You know, and in fact, I, I wrote a rebuttal on auto blog. I was
[00:51:36.560 --> 00:51:41.600]   writing for Auto blog at the time. I wrote a rebuttal to, to, there was an article, I think,
[00:51:41.600 --> 00:51:46.400]   in Business Week, you know, that was basically an excerpt from, from the book that was focused on
[00:51:46.400 --> 00:51:50.560]   that aspect of, you know, that they should build, and car companies should build beta vehicles.
[00:51:50.560 --> 00:51:57.360]   Yeah. And I, I wrote a rebuttal, you know, saying no, they should not. This is a terrible, terrible
[00:51:57.360 --> 00:52:04.000]   idea, at least not for somebody who's in driving them. Yeah. And so they do do betas, but they don't
[00:52:04.000 --> 00:52:08.960]   sell them publicly. Right. They, they, they do internal betas. Yeah. And the, the, the difference
[00:52:08.960 --> 00:52:15.200]   between the software business and, you know, building vehicles is the consequences of failure
[00:52:15.200 --> 00:52:20.320]   are very, very different. You know, if Instagram crashes on you or Facebook won't load, you know,
[00:52:20.320 --> 00:52:25.920]   or Twitter, you know, is offline and showing a fail well, it doesn't matter. There's no,
[00:52:25.920 --> 00:52:31.360]   there's no real consequence to that. But if you're, if you're operating system in your car,
[00:52:31.360 --> 00:52:37.040]   suddenly blue screens, I literally every few months would do a control alt delete.
[00:52:37.040 --> 00:52:42.160]   In my Tesla, there's, you have to hold the two buttons. There's a three finger salue. You do
[00:52:42.160 --> 00:52:47.360]   it in a Tesla to reboot it. You can still drive it. It's not unsafe, but well, it's kind of unsafe.
[00:52:47.360 --> 00:52:51.520]   The whole screen goes black. I don't know what you do in a model three, because that screen
[00:52:51.520 --> 00:52:55.200]   controls everything. They actually have this problem right now with the Airbus A350.
[00:52:55.760 --> 00:53:01.920]   Well, okay. So they have to literally reboot airlines have to reboot the A350 every 149
[00:53:01.920 --> 00:53:05.360]   hours. This is what worries me about software mentality creeping into other realms.
[00:53:05.360 --> 00:53:10.480]   Is it? Oh, yeah. Isn't this what went wrong? Kind of at Boeing? That's exact. Well, it's a very
[00:53:10.480 --> 00:53:15.040]   big part of what went wrong at Boeing that, you know, they did not, well, there's a number of
[00:53:15.040 --> 00:53:21.040]   factors of Boeing. One is the problem of, you know, this increasing trend over the last decade or two
[00:53:21.040 --> 00:53:26.640]   towards allowing industries to self-regulate. And the FAA, you know, giving up too much
[00:53:26.640 --> 00:53:33.920]   responsibility to aircraft manufacturers like Boeing for doing self-certification. And this is
[00:53:33.920 --> 00:53:39.200]   actually a problem in the auto industry as well. A lot of the regulations around the auto industry,
[00:53:39.200 --> 00:53:43.680]   the manufacturers actually do the certification tests and they submit the documentation to NHTSA
[00:53:43.680 --> 00:53:50.400]   or the EPA. And those agencies audit a certain percentage of the new vehicles that come out,
[00:53:50.400 --> 00:53:54.880]   you know, to verify that, you know, they actually meet what's in those documents.
[00:53:54.880 --> 00:54:01.600]   But the whole trend towards industries regulating themselves is a terrible idea.
[00:54:01.600 --> 00:54:04.720]   Yeah. But that's going to say it's also been a problem in the banking industry.
[00:54:04.720 --> 00:54:11.200]   Yeah. Oh, in any industry. Yeah. All of them. So Sam, I was so happy. We were going to be on this
[00:54:11.200 --> 00:54:16.800]   on Twitch this week together. Did you see the fully charged video that came out fully charged
[00:54:16.800 --> 00:54:22.880]   as a YouTube channel? It covers electric vehicles. And they finally got to do electric Porsche,
[00:54:22.880 --> 00:54:29.440]   the Taycan industry. Did we see it? Did we see it? We watched it over and over and over again.
[00:54:29.440 --> 00:54:33.360]   It's amazing. Zero to 200 kilometers in 12 seconds. Yes. Yes. It's awesome.
[00:54:33.360 --> 00:54:38.240]   Or whatever. And back to zero again. But what I think is so interesting is they've
[00:54:38.240 --> 00:54:43.520]   engineered it in a way where it's got liquid cooling for the battery. So it's not like the Tesla
[00:54:43.520 --> 00:54:47.200]   and ludicrous mode where you can only do it once. And that's it. Well, actually, Tesla does
[00:54:47.200 --> 00:54:51.760]   look at all the batteries too. But oh, really? But there is an issue though,
[00:54:51.760 --> 00:54:55.200]   running at high speed for longer periods of time, at least in the Tesla. But another like,
[00:54:55.200 --> 00:54:59.600]   that was of over the motor. The motors in power electronics are where it starts to overheat.
[00:54:59.600 --> 00:55:04.400]   And that's what that's what causes them to go into limp home. Will the Taycan not have that
[00:55:04.400 --> 00:55:10.640]   problem? If it's engineered correctly, it no, it shouldn't. We'll see. Based on that video,
[00:55:10.640 --> 00:55:15.600]   it appears that Porsche has done a more solid job of engineering that aspect of the vehicle. So
[00:55:15.600 --> 00:55:23.600]   that shouldn't be a problem. And Porsche is committed. The Taycan should perform in every
[00:55:23.600 --> 00:55:29.760]   respect as you would expect a Porsche to, which means sustained strong performance.
[00:55:29.760 --> 00:55:33.840]   And that's actually part of the reason why this year Jaguar, for example, with the I-PACE,
[00:55:33.840 --> 00:55:39.840]   launched the I-PACE E-Trophy series as a support series for Formula E. So that they could demonstrate
[00:55:39.840 --> 00:55:48.160]   that these cars can run on the track at high speeds, lap after lap for sustained periods of time
[00:55:48.160 --> 00:55:53.200]   without going into limp home mode, something which has been an issue for Teslas. Teslas are
[00:55:53.200 --> 00:55:59.040]   very quick launching once or twice. And then they start to slow down until everything cools down
[00:55:59.040 --> 00:56:02.640]   again. And then you can do it again. I never. So I have a proposal for you.
[00:56:02.640 --> 00:56:10.320]   Okay, we will never beat the official Cannonball for the what's his name? The guy that. Oh, no,
[00:56:10.320 --> 00:56:15.440]   Vin Wicke, the guy. And I forget his name. We'll never beat that one because he was driving
[00:56:15.440 --> 00:56:20.160]   a 120 miles an hour the entire time. But we could do an electric Cannonball.
[00:56:20.160 --> 00:56:26.240]   Let's do it. I'll be burnt Reynolds. Yeah, I get you flied Boston, Leo.
[00:56:26.240 --> 00:56:32.080]   They're actually is an electric Cannonball record. And it's actually been broken twice in the last
[00:56:32.080 --> 00:56:37.120]   few weeks. I saw that and I saw it. I'm like, I can beat that. I will be that.
[00:56:37.120 --> 00:56:41.840]   Alex Roy was actually the first one to to set that record. And then now it's been broke. First
[00:56:41.840 --> 00:56:50.640]   though at boiling it at Bolean. First we have to buy a Ticon. Yeah. So I'll sign up for that. Okay.
[00:56:50.640 --> 00:57:01.360]   I'll do some driving. If Lisa lets me. I actually it's gonna be hard to get one 30,000
[00:57:01.360 --> 00:57:10.480]   pre orders. They're already they claim sold out for 2020 next year. And the CEO of Portia
[00:57:10.480 --> 00:57:15.040]   saying it's mostly Tesla owners. When do I get my Porsche?
[00:57:15.040 --> 00:57:21.200]   And then you have to be amazed at that though, right? Like you have to at least give Tesla.
[00:57:21.200 --> 00:57:25.760]   I'm not a Tesla owner. I don't care about Tesla. I mean, I can't afford it. So I don't care about
[00:57:25.760 --> 00:57:31.120]   it. But like you have to at least give Tesla credit for kind of pushing. Oh, this wouldn't
[00:57:31.120 --> 00:57:36.400]   exist in this world. Right. And I've always given Tesla enormous credit for
[00:57:36.400 --> 00:57:42.400]   demonstrating that electric vehicles can be something that our is an
[00:57:42.400 --> 00:57:46.080]   EV can something be truly appealing in and of its own in its own right. You know,
[00:57:46.080 --> 00:57:51.440]   regardless of its green credentials, just on it's own. I don't ever want to drive a gas car.
[00:57:51.440 --> 00:57:56.320]   Again, I love EV. Yeah, on its own merits, you know, based on design and performance and
[00:57:56.320 --> 00:58:00.880]   everything else, you know, an EV can be something, you know, it doesn't have to be a glorified golf
[00:58:00.880 --> 00:58:06.880]   card like it was in the old days. Right. But you know, now, okay, great, we've got that part.
[00:58:06.880 --> 00:58:11.280]   Now let's make it so that it has all the other attributes that we have come to expect of modern
[00:58:11.280 --> 00:58:16.640]   cars that it's reliable and safe and gets you where you need to go every time, you know, that
[00:58:16.640 --> 00:58:21.600]   that doesn't not start half of the time. You know, the kinds of things that especially
[00:58:21.600 --> 00:58:25.760]   mainstream consumers expect of their cars because they rely on them to get them where they need to
[00:58:25.760 --> 00:58:31.920]   go. And that's that's where Tesla has fallen down is on the fundamental components of
[00:58:31.920 --> 00:58:36.560]   creating a product that the product that consumers can use as as intended.
[00:58:36.560 --> 00:58:42.080]   And Boeing, but Sam, they had all the part noise things. They had to build the fart noise thing.
[00:58:42.080 --> 00:58:46.480]   They couldn't focus on that. I think it is. I did turn the Atari games into the screen.
[00:58:46.480 --> 00:58:49.760]   Yeah, but I did try the fart mode. It was it was loads of fun.
[00:58:51.680 --> 00:58:57.520]   So you can have random farts or you can have it whenever you do the turn signal instead of going
[00:58:57.520 --> 00:59:05.440]   click, click, click, click, click, because oh my god, my 16 year old enjoyed it. I'm just saying.
[00:59:05.440 --> 00:59:13.680]   I have thought so much. I have a 2000 Boxster S.I. Love. It's a $7,000 car and they have kits for
[00:59:13.680 --> 00:59:19.600]   it that you can take it and remove the engine in this case is the M96 motor, which isn't that
[00:59:19.600 --> 00:59:26.720]   reliable anyway. You can convert it into an electric vehicle. So I am I'm ultra serious about doing
[00:59:26.720 --> 00:59:33.040]   this to this car because I just I think it's it will make it more reliable. It will just stop
[00:59:33.040 --> 00:59:36.880]   destroying the environment. I think it would be a real cool project. But what about that?
[00:59:36.880 --> 00:59:42.240]   On battery, some Ed said that if Tesla were to build all the cars in the world, there wouldn't be
[00:59:42.240 --> 00:59:47.760]   enough cobalt cobalt. Yeah. Yeah. And and that you know that is that is an issue. You know,
[00:59:47.760 --> 00:59:51.680]   some of the some of the raw materials that go into these batteries and into the power
[00:59:51.680 --> 00:59:57.360]   electronics and the motors, you know, are the mining and extraction of those materials and
[00:59:57.360 --> 01:00:03.920]   the processing is problematic. But that said, you know, engineers are working on alternatives.
[01:00:03.920 --> 01:00:09.360]   They're trying to develop alternatives to using materials like cobalt and new new batteries are
[01:00:09.360 --> 01:00:13.680]   coming out. They're using less and less cobalt in them. Okay. I do worry though about this
[01:00:14.880 --> 01:00:20.720]   adulation of Silicon Valley. And of course, Silicon Valley is the example of American,
[01:00:20.720 --> 01:00:26.480]   you know, innovation and know how taken to the nth degree and every company in the world wants
[01:00:26.480 --> 01:00:31.280]   to run their company like Silicon Valley does, except there are absolutely industries and maybe
[01:00:31.280 --> 01:00:36.560]   the banking industry is another one. Well, it does really work so well. An issue of, you know,
[01:00:36.560 --> 01:00:41.680]   the adulation of the CEO of the celebrity CEO. That's another problem. That's that's a bit more
[01:00:41.680 --> 01:00:47.760]   broadly that's been spread throughout the year. I mean, every CEO now makes 1000 times more than
[01:00:47.760 --> 01:00:54.560]   the lowest worker. It's it's out of control. Speaking of credit cards, if you had a Amazon
[01:00:54.560 --> 01:01:04.320]   dot CA rewards visa or Marriott rewards premier visa in Canada, good news, Chase Bank wants so
[01:01:04.320 --> 01:01:08.240]   badly to get out of the Canadian market, they're actually forgiving your debt.
[01:01:09.840 --> 01:01:14.800]   They are forgiving your debt. This guy, this picture, this smiling guy, he had won the old
[01:01:14.800 --> 01:01:22.800]   $1645 on a Amazon rewards card. Chase said, you owe zero Zippo, Zippity Duda. They said,
[01:01:22.800 --> 01:01:27.440]   there is cheaper for us to do this. It's faster. It's the only way we're going to ever get out of
[01:01:27.440 --> 01:01:32.720]   Canada. So they're giving there was just saying, you don't know, it's fine. You don't know
[01:01:32.720 --> 01:01:39.200]   anything. Wow. And go get that. Now you can get an Apple card. No, you can't.
[01:01:39.200 --> 01:01:47.200]   You're in Canada. You can't. Sorry. Run away. Run away. It's interesting. I didn't know this,
[01:01:47.200 --> 01:01:52.800]   but according to CNBC, it was Steve Jobs idea to create a credit card.
[01:01:52.800 --> 01:02:00.800]   He went Apple held discussions with Capital One about creating a joint card in the late 1990s.
[01:02:02.000 --> 01:02:08.080]   Steve Jobs had an aversion to rejecting any customers. They tested a card but didn't roll
[01:02:08.080 --> 01:02:12.080]   it out broadly. And partly because I think Steve said, you can't turn anyone down.
[01:02:12.080 --> 01:02:17.840]   So that's on the context of the time. I mean, Apple was still just starting to recover.
[01:02:17.840 --> 01:02:20.640]   That's true. The late 90s. And they couldn't afford to turn anybody.
[01:02:20.640 --> 01:02:27.680]   Right. But apparently the same pressure on Goldman to approve everyone, I still have an option
[01:02:27.680 --> 01:02:33.280]   to get it. So I'll find out and then I'll let you know. It was interesting to see in that
[01:02:33.280 --> 01:02:39.440]   CNBC story, at least, the paragraph about the fact that Goldman is under pressure to do this.
[01:02:39.440 --> 01:02:45.520]   Right. It's not just Apple looking for more users, but Goldman needs to, I guess, show its
[01:02:45.520 --> 01:02:51.200]   investors that it can grow more revenue. Right. I think this is the first card that Goldman's
[01:02:51.200 --> 01:02:57.360]   done. They're just starting to break in the business. They also started an online bank
[01:02:57.360 --> 01:03:04.720]   called Marcus. And I wonder, it's my thought that maybe Apple would like to do all of your banking.
[01:03:04.720 --> 01:03:11.840]   I get solicitations from Marcus in the mail about every other week.
[01:03:11.840 --> 01:03:16.880]   I started up for an account. I started the application process. Then when I saw the things
[01:03:16.880 --> 01:03:21.120]   I had to do, I stopped and I still get a statement from them for some reason, for an
[01:03:21.120 --> 01:03:23.440]   nonexistent Marcus account. And I think it's probably-
[01:03:23.440 --> 01:03:24.640]   Might just go straight into the shredder.
[01:03:24.640 --> 01:03:30.240]   Yeah, it's probably that. It's like, well, you kind of have one. So finish up. Finish up.
[01:03:30.240 --> 01:03:35.360]   As long as we're talking Apple, one more Apple story, then we'll move on. Apple is apparently-
[01:03:35.360 --> 01:03:41.600]   This is according to iFixit. We love iFixit, former sponsor. And I really like their right
[01:03:41.600 --> 01:03:50.800]   to repair platform. Apparently, Apple's locking iPhone batteries now. There's a software lock
[01:03:50.800 --> 01:03:55.600]   on the newest iPhones. And if something other than an Apple battery goes in,
[01:03:55.600 --> 01:04:00.720]   I think it's even with an Apple battery if it's done by-
[01:04:00.720 --> 01:04:04.480]   If you don't do it yourself. Yeah, if it's done by a non-Apple, the service person.
[01:04:04.480 --> 01:04:08.640]   You'll get a service message and it's not a bug. It's a feature Apple wants,
[01:04:08.640 --> 01:04:13.760]   unless an Apple genius or an Apple authorized service provider authenticates the battery to
[01:04:13.760 --> 01:04:19.120]   the phone that phone will never show battery health and always report a vague,
[01:04:20.240 --> 01:04:25.040]   ominous message unable to verify this phone is a genuine Apple battery.
[01:04:25.040 --> 01:04:32.240]   I have to say, when I'm elected to Congress, the first thing we're going to do is pass a
[01:04:32.240 --> 01:04:37.600]   national right to repair law. This makes no sense. It's consumer hostile. If it's something for a
[01:04:37.600 --> 01:04:42.960]   fingerprint scanner, I get it. Yes, for security. Yes. For security. Yes. For security. The battery
[01:04:42.960 --> 01:04:48.880]   is a fungible part. This is bad for the environment. It encourages people to throw things away,
[01:04:48.880 --> 01:04:55.040]   rather than repair them. It's a consumer rights issue, frankly. Even if you put in a verified
[01:04:55.040 --> 01:05:01.040]   Apple battery, you're still going to get that message. If you do it yourself, or that is not
[01:05:01.040 --> 01:05:08.400]   a stealer, doesn't it? Apparently, this comes from a YouTuber, Justin at the Art of Repair.
[01:05:08.400 --> 01:05:13.440]   There's a Texas Instruments microcontroller. I knew we'd get a chip in here somewhere.
[01:05:15.120 --> 01:05:18.800]   On the battery that provides information to the phone like battery capacity temperature and how
[01:05:18.800 --> 01:05:25.680]   much time till discharge. Apple uses its own proprietary version, but pretty much all smartphone
[01:05:25.680 --> 01:05:31.520]   batteries have some version of this chip. The newer iPhones, though, have an authentication feature
[01:05:31.520 --> 01:05:38.560]   that stores the info for pairing the battery to the logic board. That's the thing that the
[01:05:38.560 --> 01:05:44.320]   genius can do, but no one else can. We've seen this gone for years from
[01:05:44.320 --> 01:05:49.360]   printer companies that put chips in there. Ink cartridges to make sure you don't use a third party.
[01:05:49.360 --> 01:05:54.320]   Ink. Eric does it with their coffee makers. That's the wire. That's the wire.
[01:05:54.320 --> 01:06:00.160]   I mean, that's just the thing. You punch a hole in the foil on the top and put water through it.
[01:06:00.160 --> 01:06:05.840]   Anybody can make these. Currig won't work if you have a non-currig pod.
[01:06:05.840 --> 01:06:12.960]   There are version two machines, I think they switched to a system with DRM where there's a QR code or
[01:06:12.960 --> 01:06:19.600]   something printed on the pod that it reads. That's the Silicon Valley mentality.
[01:06:19.600 --> 01:06:25.920]   Copy protection, in this case, coming to durable goods. Coffee makers.
[01:06:25.920 --> 01:06:30.320]   I mean, they're going to do whatever they can. That's good for their bottom line. That's great
[01:06:30.320 --> 01:06:35.840]   for Apple. The answer is, you know, we need regulation to we have to advocate on the computer
[01:06:35.840 --> 01:06:41.520]   suicide. I'm not angry when Apple does that. I expect them to. You just need people on your side.
[01:06:41.520 --> 01:06:42.880]   You should say it's because I want to move.
[01:06:42.880 --> 01:06:47.760]   So I want to be able to vote for you. I'm looking for Datto, which is where Paul
[01:06:47.760 --> 01:06:53.920]   is used to go. Datto's a great city. Westwood, I think Quincy is a lovely home.
[01:06:53.920 --> 01:07:00.080]   I would be happy in Quincy. Parts of the bus, just to vote for you. What is the residency requirement?
[01:07:00.080 --> 01:07:03.680]   How many months do I have to live there? I don't know. You should find that out.
[01:07:03.680 --> 01:07:07.840]   I should find that out. There are a few geeks. You know, they have who would do it. They have
[01:07:07.840 --> 01:07:12.400]   an internet there. So they have heard they have internet and dead them. I have heard that.
[01:07:12.400 --> 01:07:18.160]   Brianna Wu is here. She is. And do we is there any? So this is why I don't want the FCC to
[01:07:18.160 --> 01:07:23.200]   regulate podcasts. I don't have any requirement. If I bring you on to bring your opponent on or
[01:07:23.200 --> 01:07:27.360]   anything like that, right? Yeah. Yeah. It's ridiculous. I don't have to get a Republican on to
[01:07:27.360 --> 01:07:31.600]   counter you or anything like that. Do I? I hope not.
[01:07:31.600 --> 01:07:39.200]   Running for Congress. We asked you since eight. So just full disclosure, we have contributed to
[01:07:39.200 --> 01:07:44.480]   her campaign and we love having her on because she's the best. Thank you. Same with this fellow
[01:07:44.480 --> 01:07:49.520]   over here, Brock Johnson, Ben Brock Johnson, not to be confused with the 1972 Academy Award-winning
[01:07:49.520 --> 01:07:54.640]   Brock Ben Brock Johnson. I can also ride a horse though. I can ride a horse. Can you ride a horse?
[01:07:54.640 --> 01:08:00.240]   Okay. Not well. What baffles me is that Ben Johnson, the actor, gets credit for being the only
[01:08:00.240 --> 01:08:06.160]   Western star that actually could ride a horse. It's not that hard, kids. It's not. It's basically
[01:08:06.160 --> 01:08:11.760]   you sit on it and a horse does its thing. I think he probably, you know, but it's like that Western
[01:08:11.760 --> 01:08:17.600]   thing, right? He probably did a lot of galloping jumping off the horse and jumping from the roof
[01:08:17.600 --> 01:08:22.480]   of the thing on the horse. You know, he's riding a horse. Really, the horse is riding him.
[01:08:22.480 --> 01:08:28.080]   He's posting wrong. He's weird. He's not. That's it. Yeah. Yeah. Get a good stand.
[01:08:28.080 --> 01:08:34.160]   That's how I ride a horse. That's how. Yeah. Me too. Great to have Sam. I will submit also from
[01:08:34.160 --> 01:08:38.000]   Navigant Research. He's a principal analyst. He's my car guy and he's going to get me.
[01:08:38.000 --> 01:08:41.840]   You don't have to write the check, but you're going to get me in line for that Porsche type
[01:08:41.840 --> 01:08:46.000]   gun, right? I will do that. I'm counting on it. I'll talk to my friend Dave. It's all sold out.
[01:08:46.000 --> 01:08:51.680]   I don't need it till a year from Christmas. I'm stuck driving a gas car until then.
[01:08:52.320 --> 01:08:57.120]   I can't tell you. In fact, I bicycle to work rather than drive that gas car.
[01:08:57.120 --> 01:09:03.440]   Wow. It's good. It's an electric bike. So perfect. Make me feel bad here, Leo. I feel like
[01:09:03.440 --> 01:09:08.240]   the biggest jerk on there. No, no, no, no. Your boxers really cool, but wouldn't it be cool?
[01:09:08.240 --> 01:09:13.280]   I drive a 30 year old car. He drives a Miata for crying out loud. Miata is a great car.
[01:09:13.280 --> 01:09:17.440]   Does your bike have fart mode? It has all these driver's. Yeah, it does, but it's not a
[01:09:17.440 --> 01:09:22.960]   mechanical, if you know what I mean. Forward collision warning. His t-shirt has all of his
[01:09:22.960 --> 01:09:28.480]   Miata cockpit with all of them, but the driver does all of that. That's from that's from blipshift,
[01:09:28.480 --> 01:09:33.520]   by the way. If you like great car auto pilot is the side mirror.
[01:09:33.520 --> 01:09:37.680]   Forward collision detection is the front. He'll hold with the
[01:09:37.680 --> 01:09:45.280]   parking brake. He'll hold. I think they put he'll hold in the Tesla because of me.
[01:09:46.160 --> 01:09:50.880]   Lisa and I caught we're having problems with our Tesla rolling one way while we were in the other
[01:09:50.880 --> 01:09:58.080]   gear. And we called him and said, it's something wrong. I'll be in reverse and it pulls it goes
[01:09:58.080 --> 01:10:04.800]   forward when I put my foot on the gas and they checked the log. Said no, was that a date 47?
[01:10:04.800 --> 01:10:11.760]   Yeah. No, no, you were going you were in reverse. But how do you know that? Oh, we have it all.
[01:10:11.760 --> 01:10:16.560]   We know everything Leo everywhere you've been. We know. You were not the only one to have that
[01:10:16.560 --> 01:10:21.120]   problem that I saw multiple reports. And then a week later they call me up and say, oh, by the way,
[01:10:21.120 --> 01:10:26.640]   press hard on the we just updated your Tesla press hard on the brake pedal. You got he'll hold.
[01:10:26.640 --> 01:10:31.840]   Oh, thank you very much. Oh, really? I wasn't the only one? No, there were a lot of reports.
[01:10:31.840 --> 01:10:35.200]   That was the beginning of the end for Lisa that and when the Falcon doors kept hitting her in the
[01:10:35.200 --> 01:10:41.840]   head. Oh, well, there aren't as many sensors in a Tesla as they might lead you to believe.
[01:10:41.840 --> 01:10:49.200]   There's a there's a very good reason why car makers put going doors on their concept cars,
[01:10:49.200 --> 01:10:54.720]   but almost never put them on production. What is that? Well, they're expensive and they tend to
[01:10:54.720 --> 01:11:00.960]   hit people in the head. They really did. We finally had a protocol. We had a protocol that I couldn't
[01:11:00.960 --> 01:11:04.880]   press. There's a close all button. That was the problem right on the screen. And she said,
[01:11:04.880 --> 01:11:11.280]   before you press that button, you have to audibly shout, is everyone in the vehicle? Are all your
[01:11:11.280 --> 01:11:18.880]   limbs in the vehicle doors closing in three, two, huh? It was an operator error. It wasn't the
[01:11:18.880 --> 01:11:23.200]   Tesla's fault, but but in theory, you shouldn't be able to chop the operators error. The operators
[01:11:23.200 --> 01:11:29.200]   error was driving a Tesla. Maybe I love my Tesla, but it was a beta vehicle. That's there's no question
[01:11:29.200 --> 01:11:33.920]   about that. She has a she bought a bolt. She has a heavy bolt. She's loving. Oh, she's loving.
[01:11:33.920 --> 01:11:39.760]   Those are those are fast little cars. Yeah, it's not ludicrous mode, but it's, you know,
[01:11:39.760 --> 01:11:47.120]   it's peppy for a little tiny car or a little car, tiny wheels. Yeah, cute little car. I like it,
[01:11:47.120 --> 01:11:52.720]   but I want a ticon. I don't blame you. I've written in the second, but an old white man
[01:11:52.720 --> 01:11:58.880]   and old white men should always drive sports cars, right? It's a sedate. Everyone should
[01:11:58.880 --> 01:12:05.600]   drive a very respectable car. It's a sedan. He says it's a sedan. It just looks like a Porsche.
[01:12:05.600 --> 01:12:11.440]   Our show today brought to you by Wasabi. There are places where the software mentality makes a big
[01:12:11.440 --> 01:12:19.440]   difference. And I think this is one example. My friend, my friend, David friend and his buddy,
[01:12:19.440 --> 01:12:25.680]   Jeff Flowers, some years ago, created a way to write to a hard drive where you'd lay the data on the
[01:12:25.680 --> 01:12:31.200]   disc just sequentially instead of bisector bisector as opposed to blocks. It seems like a simple
[01:12:31.200 --> 01:12:37.280]   thing, but it was incredibly efficient. That was the foundation for carbonite. They founded
[01:12:37.280 --> 01:12:42.160]   carbonite a couple of years ago. They said, you know, we could use this other way as they created
[01:12:42.160 --> 01:12:50.000]   Wasabi hot cloud storage that's 80% less expensive because of this patented technology that the
[01:12:50.000 --> 01:13:00.480]   only ones can do it six times faster than Amazon S3 and fully secure. I love this. This is innovation.
[01:13:00.480 --> 01:13:04.080]   This is doing it right now. A lot of people, we know businesses are moving to the cloud. This
[01:13:04.080 --> 01:13:07.920]   is the next big thing. Everybody's going to be in the cloud. And sometimes there's concern that,
[01:13:07.920 --> 01:13:12.160]   well, as the cloud is secure, I would submit the cloud is more secure than that hard drive. You
[01:13:12.160 --> 01:13:17.520]   have in the closet or the data center you have down the road. This is a better way to do it.
[01:13:18.240 --> 01:13:24.800]   In fact, according to Gartner, 10% of all enterprises have traditional data centers today.
[01:13:24.800 --> 01:13:32.640]   80% of those enterprises will have shut them down and moved to the cloud. This is a big transformation
[01:13:32.640 --> 01:13:36.880]   of way people do business. And let me tell you why you want to look at Wasabi. I know you're going
[01:13:36.880 --> 01:13:40.080]   to look at Google and Amazon on Microsoft. I know those are the big three. You're going to have
[01:13:40.080 --> 01:13:46.640]   those on your list. Just had a fourth name for me wasabi. Not only is it faster, six times faster
[01:13:46.640 --> 01:13:52.880]   than S3. Not only is it less expensive, one fifth of cost of S3, 11 nines of durability.
[01:13:52.880 --> 01:13:59.600]   Plus they haven't built an integrity checking on your data to check it automatically to make
[01:13:59.600 --> 01:14:03.840]   sure it has not been modified. But my favorite feature in this will appeal to anybody who's worried
[01:14:03.840 --> 01:14:08.320]   about ransomware. You can designate some of your data immutable or all of it. If you want,
[01:14:08.320 --> 01:14:12.880]   you could say that data can't be changed, not by ransomware, not by a fumble fingered employee.
[01:14:12.880 --> 01:14:20.960]   That data is golden. And that's fantastic. Immutable storage. Redundant data centers. Of course,
[01:14:20.960 --> 01:14:30.480]   HIPAA compliant. Yes, FINRA, CJIS compliant. Yes. And there's no charge for API access. And unlike
[01:14:30.480 --> 01:14:36.240]   Amazon, no charge for egress, you can download free. So in every respect, this is a better solution.
[01:14:36.240 --> 01:14:41.200]   I know you've never heard of them. I want you to think about Wasabi hot cloud storage.
[01:14:41.200 --> 01:14:46.400]   At least do this for me. Try it. You can get it for free unlimited storage for a month for free.
[01:14:46.400 --> 01:14:52.720]   So you can really bang on it. If you go to wasabi.com, click the free trial link and use the offer code
[01:14:52.720 --> 01:14:57.840]   to make it unlimited. Join the movement migrate your data to the cloud, but do it without worry,
[01:14:57.840 --> 01:15:04.160]   without confidence and tell the boss it's going to be one fifth the cost and 600% faster.
[01:15:04.160 --> 01:15:10.960]   And it's the Amazon S3 API. So you already know how to use it was sabi.com offer code to it.
[01:15:10.960 --> 01:15:15.040]   We thank Wasabi so much for their support. And I thank you for supporting us by using that offer
[01:15:15.040 --> 01:15:22.720]   code, letting them know. Yeah, I've we looked at using Amazon S3 for a product I use a while back.
[01:15:22.720 --> 01:15:28.720]   People really don't like it gets really expensive really fast, depending on how fast you scale it.
[01:15:28.720 --> 01:15:33.440]   The way they price it, it feels like it's really cheap, right? Until you get certain, you know,
[01:15:33.440 --> 01:15:39.200]   paying for all the it's like a Porsche. Yes, starts cheap. Unless you want wheels. Well,
[01:15:39.200 --> 01:15:44.800]   that's going to cost you. Or you want you want that leather that that matches, you know,
[01:15:44.800 --> 01:15:50.560]   want a particular dress or, you know, suit and, you know, then, oh, absolutely, sir, we can do
[01:15:50.560 --> 01:15:55.920]   that for you. That's not a problem. Here's the bill. I'm going to be so nervous walking into a
[01:15:55.920 --> 01:16:00.800]   Porsche dealership. I'm going to find like I'm under dressed. I don't I they're going to know
[01:16:00.800 --> 01:16:05.040]   immediately. You're you're going to score is under age. You're in the Bay area. Oh, yeah,
[01:16:05.040 --> 01:16:09.840]   we all dress. Yeah, it's like a t-shirt and jeans shorts. That's right. Yeah. Yeah.
[01:16:09.840 --> 01:16:13.520]   Rich is rich on you. I know and everywhere sucks. Yeah. It's like you're going to force
[01:16:13.520 --> 01:16:18.400]   socks. Where's some socks? Oh, just put on a hoodie and you'll be good. Yeah.
[01:16:18.400 --> 01:16:28.800]   Get some Adidas shower shower thongs. Oh, no, don't do that. Don't do that. No, no,
[01:16:30.080 --> 01:16:35.680]   FedEx ends its ground delivery deal with Amazon here is a big change in the world.
[01:16:35.680 --> 01:16:44.160]   I remember reading that great book about Amazon, the Everything Store, and they talked about the
[01:16:44.160 --> 01:16:49.840]   battle Amazon had with FedEx to FedEx wanted to raise prices in Amazon. Of course, you know,
[01:16:49.840 --> 01:16:55.920]   take no prisoners. They said, fine, see ya. And they were able to negotiate a great price,
[01:16:55.920 --> 01:17:00.880]   but I have to feel like FedEx and UPS for a long time ago and we got to get out from one of this.
[01:17:00.880 --> 01:17:10.960]   This is FedEx air was discontinued some time ago and now no ground. Two months after FedEx said its
[01:17:10.960 --> 01:17:15.120]   express units wouldn't extend an agreement to fly Amazon's packages, but Amazon, see,
[01:17:15.120 --> 01:17:21.280]   this is why you don't mess with Jeff. They already have their own planes, their own fleet of vans.
[01:17:21.920 --> 01:17:26.480]   There's a bunch of, you know, I can't remember the last time I got an Amazon package delivered
[01:17:26.480 --> 01:17:32.560]   to anything but an Amazon Prime BAM or an unmarked car. Yeah. Oh, actually, yeah, a couple of weeks
[01:17:32.560 --> 01:17:37.680]   ago, I was out working in the yard and some guy pulled up into my driveway in a Honda Civic.
[01:17:37.680 --> 01:17:44.320]   Yeah. And handed me a package. Yeah. Yeah. Thank you. I think that's a big issue at hand here.
[01:17:44.320 --> 01:17:49.760]   You know, UPS and FedExes are physically demanding jobs, but you know, they pay pretty well. They've
[01:17:49.760 --> 01:17:56.720]   got decent benefits. And by the way, they train their drivers and safely, extensively.
[01:17:56.720 --> 01:18:03.360]   They do. They're only allowed to make, if I remember, it's right hand turns or left hand turns.
[01:18:03.360 --> 01:18:08.240]   That was, that was, I think that's not true. No, actually, that is something UPS started doing
[01:18:08.240 --> 01:18:11.920]   about 10 years ago. Right hand turn only because well, Dan, you have to sit in the lane and click.
[01:18:11.920 --> 01:18:18.320]   Yeah. They actually, when they, they started, they reprogrammed their routing system so that they
[01:18:19.360 --> 01:18:24.400]   they now route the delivery schedule to minimize the number of left hand turns. And it's actually
[01:18:24.400 --> 01:18:28.480]   it's safe to him about between 10 and 15% in fuel consumption. Sometimes you have to make a left
[01:18:28.480 --> 01:18:32.720]   hand turn. Yeah. Occasionally. You can avoid it. Right. But there are times when it's actually,
[01:18:32.720 --> 01:18:36.400]   and especially in certain cities where it's quicker to make three right hand turns than it is to make
[01:18:36.400 --> 01:18:42.080]   one left hand turn. Wow. Yeah. Sometimes I feel like Google does that to me for no reason.
[01:18:42.080 --> 01:18:46.560]   Well, ways does that. That's right. Yeah. No, you don't want to turn here.
[01:18:47.760 --> 01:18:52.880]   No, I was just saying, you know, when Amazon's basically, you know, they're adding onto their fleet
[01:18:52.880 --> 01:18:57.440]   with these very low, lowly paid workers, you know, they don't get benefits. They're
[01:18:57.440 --> 01:19:02.000]   treated as poor at least people do. And then they in Amazon distribution warehouse,
[01:19:02.000 --> 01:19:06.560]   I had to tell you, right? For office, I've met people that have worked in Amazon warehouses.
[01:19:06.560 --> 01:19:14.080]   It sounds like a, a beyond dreadful job. Yeah. Forgive the capitalist, didn't he?
[01:19:14.080 --> 01:19:16.800]   Sure. But you can give me the argument.
[01:19:16.800 --> 01:19:22.320]   I'm open-minded. I will listen. But they took that job. Yeah. They knew what they were getting
[01:19:22.320 --> 01:19:26.880]   into. They could quit it and get another job. Unemployment's pretty low. It's not like this is
[01:19:26.880 --> 01:19:35.840]   the only job in town. Except that increasingly, the jobs are poor paying jobs like that, you know,
[01:19:35.840 --> 01:19:40.240]   or their gig economy jobs. So there's no security, you have no benefits, you have,
[01:19:40.240 --> 01:19:43.760]   right? No, no, no. So everybody's a sweatshop now. Yes.
[01:19:44.400 --> 01:19:47.280]   Is that what it is? Everybody's a freelance sweatshop. Yeah.
[01:19:47.280 --> 01:19:55.360]   I just, I, it just makes me sad. Like I would like to see Amazon raise the, the amount that
[01:19:55.360 --> 01:20:00.240]   they're paying people, increase benefits. I just, I would like to see it. So that was my first thought
[01:20:00.240 --> 01:20:05.280]   with this story. Well, I'm a union guy. I'm in the sag, the screen actor's guilt.
[01:20:05.280 --> 01:20:11.840]   No, I am a union guy. I believe in that. And I believe in the dignity of work and getting a
[01:20:11.840 --> 01:20:18.720]   fair wage for a hard day's work. And I know, I don't think that Amazon workers are being
[01:20:18.720 --> 01:20:22.560]   a childish here. I think that those conditions do sound really tough.
[01:20:22.560 --> 01:20:28.080]   I mean, you know, if you have a 30 minute break and you have, it takes you 12 minutes to walk across,
[01:20:28.080 --> 01:20:32.720]   you know, to the break area, and then you have five minutes to sit down, eat your lunch,
[01:20:32.720 --> 01:20:36.560]   and then, you know, 12 minutes to walk back. Yeah, that's, that's not fair. That's not good.
[01:20:36.560 --> 01:20:41.920]   Let's not forget they are owned by the richest man in the world who could kick in a little.
[01:20:41.920 --> 01:20:46.640]   Forget about going to Mars, you know, pay your workers a little bit more. Give them a little bit
[01:20:46.640 --> 01:20:50.560]   longer break time or put break stations closer to where they're working in the warehouse.
[01:20:50.560 --> 01:20:57.600]   Although I am more bathrooms. I am not a member of the Rupert Murdoch School of Journalism.
[01:20:57.600 --> 01:21:04.000]   This headline, Jeff Bezos, the richest man in the world keeps wearing the same swim trunks.
[01:21:04.880 --> 01:21:07.840]   Because God forbid you should ever be seen in the same swim trunks twice.
[01:21:07.840 --> 01:21:12.720]   Are we sure it's not 150 pairs of the same swim trunks?
[01:21:12.720 --> 01:21:16.080]   Aha! Yes, there you go. You know, he's that's very silica.
[01:21:16.080 --> 01:21:19.760]   Like Steve Jobs, you don't want to waste any of the parents making a swim trunk choice.
[01:21:19.760 --> 01:21:23.760]   So just give me, you know, I don't wear a black t-shirt next. I throw him out.
[01:21:23.760 --> 01:21:29.520]   They don't, by the way, comment on the fact that his girlfriend Lauren Sanchez is wearing the same hat.
[01:21:31.600 --> 01:21:35.360]   She's not the richest woman in the world, but still, I mean, come on, man.
[01:21:35.360 --> 01:21:37.200]   Come on, man. That's page six.
[01:21:37.200 --> 01:21:44.960]   Page six, which also pointed out that Kate Middleton was spotted in shorts in the first time in 10 years.
[01:21:44.960 --> 01:21:53.840]   Shocking. Man. She's a princess. The future, she's a duchess.
[01:21:53.840 --> 01:21:58.640]   What's she wearing? When's the last time you saw a duchess in shorts? I ask you.
[01:22:00.880 --> 01:22:05.440]   Yeah, I think you make an excellent point, Ben. He probably does have more than one pair.
[01:22:05.440 --> 01:22:11.040]   Yeah. I mean, if anybody has like a psychotic wardrobe, it's got to be just pages.
[01:22:11.040 --> 01:22:18.000]   Speaking of Bezos, one of Amazon's acquisitions of former Sp,
[01:22:18.000 --> 01:22:26.240]   pretty much if you want to get acquired, sponsor, TWIT, because many of our former advertisers
[01:22:27.360 --> 01:22:32.480]   were acquired by Amazon, including Pilpac. Oh, can I buy ads for wheel bearings on TWIT?
[01:22:32.480 --> 01:22:39.040]   Would you please? We'd be glad to give you a substantial discount. Only $15 an hour. Oh, no,
[01:22:39.040 --> 01:22:43.440]   that's Amazon. Amazon's Pilpac is battling, apparently, with local drug stores.
[01:22:43.440 --> 01:22:52.640]   They're complaining that actually, Pilpac is complaining that CVS and Walgreens
[01:22:53.200 --> 01:22:58.720]   will not forward their customers' prescriptions to Pilpac. Because Pilpac's a pharmacy,
[01:22:58.720 --> 01:23:02.960]   but it's an online pharmacy. I think Pilpac's really cool. I was using it for a long time.
[01:23:02.960 --> 01:23:08.480]   I use it too. Yeah, it's really great. It bundles up your pills into the little pouches. It's
[01:23:08.480 --> 01:23:13.680]   great for somebody like you who just on the road all the time, because it's already ready to go.
[01:23:13.680 --> 01:23:19.840]   According to Pilpac, CVS and Walgreens are rejecting an increasing number of those requests
[01:23:20.480 --> 01:23:25.120]   for prescription transfers, claiming Pilpac isn't getting proper consent from patients.
[01:23:25.120 --> 01:23:29.360]   Pilpac says, "But we always get patient approval before making transfer requests
[01:23:29.360 --> 01:23:34.080]   and blames the pharmacy giants for unfairly refusing to honor the requests,
[01:23:34.080 --> 01:23:40.480]   sometimes hanging up on Pilpac's pharmacists or throwing the request forms in the trash."
[01:23:40.480 --> 01:23:45.280]   Wow. Retail war. Retail war.
[01:23:48.640 --> 01:23:55.040]   Yeah, it does make sense. Remember when Amazon bought Pilpac, stocks for CVS and Walgreens
[01:23:55.040 --> 01:23:59.120]   dropped dramatically, just like when Amazon bought Whole Foods and gross new stocks.
[01:23:59.120 --> 01:24:03.280]   Yeah, you're not really rooting for the hometown local pharmacy,
[01:24:03.280 --> 01:24:07.280]   but the CVS are Walgreens. These are huge corporations.
[01:24:07.280 --> 01:24:12.400]   Did you see the was on TMZ?
[01:24:14.960 --> 01:24:19.680]   If there's any proof at all that Silicon Valley is now the new celebrity royalty,
[01:24:19.680 --> 01:24:23.840]   this is that. The was on TMZ. Let me give you the sound here.
[01:24:23.840 --> 01:24:31.680]   No, you don't want to... You afraid the TMZ will take us down? They'll take us down? No, TMZ is a
[01:24:31.680 --> 01:24:37.200]   nice channel. That Levine guy. We'd never take us down. All right, well, I'll tell you what he said.
[01:24:37.200 --> 01:24:43.680]   He says, "There are many different kinds of people." See, I can't do it like was. We do.
[01:24:43.680 --> 01:24:47.280]   There are many different kinds of people. For some, the benefits of Facebook are worth the
[01:24:47.280 --> 01:24:53.680]   loss of privacy. To many like myself, my recommendation is to most people, you should figure out a way
[01:24:53.680 --> 01:25:04.080]   to get off Facebook. It's good advice. I like that it's come to you have to figure out how to do it.
[01:25:04.080 --> 01:25:09.680]   Figure out a way. There must be a way. It should not be hard.
[01:25:11.200 --> 01:25:15.600]   Depending on what he could have meant, just trying to find the place in the settings where you
[01:25:15.600 --> 01:25:19.360]   deactivate your account. Exactly. That's impossible. That does take some work.
[01:25:19.360 --> 01:25:23.760]   Actually, they're hard to harder than canceling a New York Times subscription.
[01:25:23.760 --> 01:25:29.360]   At least at the times, you can call somebody and get help with that.
[01:25:29.360 --> 01:25:37.360]   Yeah, for me, it's like I am racked with ethical conundrums every single day in this
[01:25:37.360 --> 01:25:43.680]   campaign. You need to be out of it. We looked at the data in 90 percent of voters on Facebook
[01:25:43.680 --> 01:25:51.200]   and only 15 percent or 20 are on Twitter. I like Twitter. I just feel like a monster
[01:25:51.200 --> 01:25:58.080]   when we run an ad and I'm feeding money into this machine. I feel guilty, Leo. I'm part of the
[01:25:58.080 --> 01:26:03.600]   problem. I am Mr. White Privilege because I got off Facebook last year.
[01:26:04.640 --> 01:26:09.600]   But of course, Twitter has a presence there and every show has a presence there because you're
[01:26:09.600 --> 01:26:15.200]   right. That's where the audience is. It's a luxury for me to say, "Oh, I'm not on Facebook,
[01:26:15.200 --> 01:26:20.560]   but my company is." If you're running for Congress, you'd be nuts not to be on Facebook.
[01:26:20.560 --> 01:26:23.200]   In fact, I'm going to bet you're buying some Facebook ads.
[01:26:23.200 --> 01:26:27.920]   You better believe it. We'll talk about the most efficient. That's how Donald Trump
[01:26:27.920 --> 01:26:34.560]   got. You could blame Russia. You could blame a lot of things. It's pretty clear to me that the
[01:26:34.560 --> 01:26:39.120]   reason Trump won is he used Facebook more effectively than anybody ever has in the past.
[01:26:39.120 --> 01:26:47.040]   I hope you all mind me saying this, but now that I've run for office and see the amount of voter
[01:26:47.040 --> 01:26:52.240]   data you can get on people and can purchase from people, I have to tell you, Leo, it should not be
[01:26:52.240 --> 01:27:01.120]   legal. It should not be legal. The detailed information I can get on people, it's cheating.
[01:27:01.120 --> 01:27:10.240]   To talk to a voter and to know what their life's on to that. It's an area and I understand why
[01:27:10.240 --> 01:27:16.160]   politicians would not be interested in regulating it because it cuts off your money. I have to say,
[01:27:16.160 --> 01:27:21.680]   it's very ethically concerned with what I've seen so far running for office. I bet you,
[01:27:21.680 --> 01:27:25.360]   I'm sure you would never do this, but I bet you, there are many elected representatives who,
[01:27:25.360 --> 01:27:30.560]   when they do their phone time to raise money, have a piece of paper in front of them and they go,
[01:27:30.560 --> 01:27:35.920]   "Hey, Joe, how are you doing? How's the dog? Is the toe better?" They probably have that whole thing.
[01:27:35.920 --> 01:27:40.640]   You take notes when you talk to people. You keep track of it. You keep track of it.
[01:27:40.640 --> 01:27:45.680]   They will tell you stuff, but if you start using it dossier generated by a social network,
[01:27:45.680 --> 01:27:52.240]   that's a little scary. Jeff Jarvis demonstrated something on Twig a few months ago. We were
[01:27:52.240 --> 01:27:56.960]   looking at ad buys on Facebook, political ad buys on Facebook because they do have a tool that
[01:27:56.960 --> 01:28:02.320]   will let you see that. Few of these buys were more than $100. They were very small buys and
[01:28:02.320 --> 01:28:10.240]   the reason being it's hyper-targeted. It's the easiest way to reach the exact right people that
[01:28:10.240 --> 01:28:16.000]   you want to reach. You make a $10,000 buys. You're making a lot of buys, but each buy is super
[01:28:16.000 --> 01:28:25.440]   targeted. Then, of course, each ad is tailored to that segment. Are you tempted to do that, Brianna?
[01:28:25.440 --> 01:28:28.880]   No, I mean, isn't that what you have to do to win now, though?
[01:28:28.880 --> 01:28:35.200]   You do have to raise money. That is a really unfortunate part of running for office. I'll be
[01:28:35.200 --> 01:28:40.560]   honest with you, Lea, at this time, I've spent five hours a day in this exact chair calling people.
[01:28:40.560 --> 01:28:46.640]   It's just the job. You got to put in the work, because you have to respect the process. At the
[01:28:46.640 --> 01:28:55.680]   same time, I see a culture of being very not concerned with people's privacy in the way that
[01:28:55.680 --> 01:29:02.880]   you should be. I've not hired people when they've said things to me that make me feel like they're
[01:29:02.880 --> 01:29:07.680]   not going to respect people's data. I've told my team, anyone that's sharing email addresses or
[01:29:07.680 --> 01:29:13.040]   information of anyone we talk to is going to be fired on the spot. We can't run on a privacy
[01:29:13.040 --> 01:29:18.720]   campaign. Then, do this. We just like the rest of the app.
[01:29:18.720 --> 01:29:21.040]   Don't you think your opponent is doing all those things?
[01:29:21.040 --> 01:29:26.080]   I don't want to speculate only as there is not, but I know a lot of politicians are.
[01:29:28.000 --> 01:29:32.640]   So, you're kind of fighting with one arm tied behind your back, if you won't use tools.
[01:29:32.640 --> 01:29:35.280]   Yeah, that's true. But the thing is sleeping at night.
[01:29:35.280 --> 01:29:39.680]   I know. I hope we don't get to a time where you have to to get elected. And if that's the case,
[01:29:39.680 --> 01:29:43.920]   the country is over. I'd resign before I do something like that.
[01:29:43.920 --> 01:29:46.560]   When the country is over, there's no democracy left.
[01:29:46.560 --> 01:29:54.480]   Speaking of Amazon schoolchildren in China, this was a boy. This was an expose from the Guardian.
[01:29:55.680 --> 01:30:00.880]   Leaked documents so children as young as 16 recruited by Foxconn to work for Amazon,
[01:30:00.880 --> 01:30:05.040]   grueling and illegal hours, sometimes through the middle of the night on school nights.
[01:30:05.040 --> 01:30:11.360]   On a school night, the teenagers drafted in from schools and technical colleges around
[01:30:11.360 --> 01:30:18.720]   Heng Yang are classified as interns. Their teachers are paid by the factory to accompany them.
[01:30:18.720 --> 01:30:24.960]   Teachers are asked to encourage uncooperative pupils to accept over time work.
[01:30:25.520 --> 01:30:31.520]   On top of regular shifts, they're making dots. They're making your echo dot along with kindles.
[01:30:31.520 --> 01:30:41.280]   This is, I'm sure not an isolated case, but this is, and I'm sure Amazon is not
[01:30:41.280 --> 01:30:44.160]   not even remotely close to the only company doing this.
[01:30:44.160 --> 01:30:48.720]   No. And probably, Foxconn didn't even, yeah, didn't even know about it.
[01:30:48.720 --> 01:30:55.360]   This is pressure on Foxconn from Amazon to produce them at a price in a quantity
[01:30:55.360 --> 01:31:01.360]   that maybe Foxconn feels like, well, the only way we can do this is if we bring in teenagers,
[01:31:01.360 --> 01:31:08.400]   Amazon says, if we find violations, we take appropriate steps, including requesting immediate
[01:31:08.400 --> 01:31:15.040]   corrective action Amazon uses independent auditors to monitor compliance. So they said,
[01:31:15.040 --> 01:31:19.680]   we're investigating an additional team of specialists that arrived on site yesterday to
[01:31:19.680 --> 01:31:24.880]   investigate, and we've initiated weekly audits of the issue. It's embarrassing to Amazon, but I
[01:31:24.880 --> 01:31:29.200]   don't know if you can blame Amazon. I'll bet you that whoever's manufacturing Google Home
[01:31:29.200 --> 01:31:36.800]   Minis and any of these other devices is probably doing the same thing. Yeah. Yeah. Worst homework
[01:31:36.800 --> 01:31:45.120]   ever. 17 year old Shao Fong started work at the factory last month. It's her job
[01:31:45.120 --> 01:31:52.640]   to apply a protective film to about 3000 echo dots every day. She was initially told by a teacher
[01:31:52.640 --> 01:31:56.480]   she'd be working eight hours a day, five days a week. That since changed to 10 hours a day,
[01:31:56.480 --> 01:32:00.480]   six days a week, the lights in the workshop are very bright, so it gets really hot.
[01:32:00.480 --> 01:32:07.040]   Doesn't sound like fun. So, but this is, you know, I hate, I hate to just blame Amazon. I feel
[01:32:07.040 --> 01:32:13.280]   like this is the world we live in today. We blame ourselves. We demand these cheap products.
[01:32:13.280 --> 01:32:16.960]   We want $30 echo dots. Yeah. Some people want them.
[01:32:19.600 --> 01:32:24.720]   I wouldn't put that in my house. Yeah. I still have my Google Home.
[01:32:24.720 --> 01:32:33.360]   It's still in the box. Oh my God. I have homes everywhere. I have echoes and homes. I even have
[01:32:33.360 --> 01:32:40.240]   Siri and Cortana. I have three Google, I have three echo dots in a drawer that have been gifted to me.
[01:32:40.240 --> 01:32:46.480]   Guys don't enable those. I love it. I took one out. I plugged it in once, you know, for a few
[01:32:46.480 --> 01:32:50.400]   minutes just to mess around with it and didn't find it all that useful and then I plugged it in.
[01:32:50.400 --> 01:32:54.000]   I think so. My partner won't allow it. Really?
[01:32:54.000 --> 01:32:57.840]   She's like, don't put that thing in. No.
[01:32:57.840 --> 01:33:03.200]   Put that thing in my house. Well, she's right because we know we've known that human contractors
[01:33:03.200 --> 01:33:06.160]   are getting to listen to some recordings, especially those inadvertent recordings.
[01:33:06.160 --> 01:33:11.200]   And really, you know, that's something that we're going to have to deal with more broadly.
[01:33:11.200 --> 01:33:15.920]   It's not just those recordings. Anywhere where data is being collected,
[01:33:15.920 --> 01:33:20.960]   there are humans that are looking at that data, listening to that data,
[01:33:20.960 --> 01:33:27.680]   training data for autonomous cars, any type of AI system, machine learning system,
[01:33:27.680 --> 01:33:33.760]   somebody is looking at that data to label it so that it can be fed back into the system to train
[01:33:33.760 --> 01:33:37.600]   these systems. In a way, it's always been the dirty little secret of artificial intelligence.
[01:33:37.600 --> 01:33:44.640]   This is often humans. Yeah. I've always, you know, I've thought a lot about this. I wonder if,
[01:33:44.640 --> 01:33:49.920]   you know, like Apple got in a bunch of stuff recently because it was found out that
[01:33:49.920 --> 01:33:56.880]   humans were auditing some of the Siri requests. But I looked more deeply into that and I'm like,
[01:33:56.880 --> 01:34:02.080]   well, they took away anything. It could personally identify the person that was talking before it
[01:34:02.080 --> 01:34:07.760]   was audited. And this just seems like error checking to me. I wonder if you had federal
[01:34:07.760 --> 01:34:13.120]   regulations kind of bringing in differential privacy because it's not the fact that people
[01:34:13.120 --> 01:34:16.800]   are listening to it as much as it's trackable and attributable to this.
[01:34:16.800 --> 01:34:21.760]   But you know, even if you're listening to it, I mean, you know, human voices are distinct.
[01:34:21.760 --> 01:34:25.680]   And, you know, if it's images, I was going to say, yeah, it might recognize exactly.
[01:34:25.680 --> 01:34:29.360]   Yeah. I mean, there are going to be times when you're going to recognize somebody or,
[01:34:29.360 --> 01:34:32.240]   you know, even if you don't know who it is, you know, if you're listening to a bunch of these
[01:34:32.240 --> 01:34:37.760]   clips and you hear, you're going to be able to correlate, you're going to hear the same voice
[01:34:37.760 --> 01:34:42.080]   sometimes. And when you start, you're going to be able to correlate. Oh, that's the guy who said
[01:34:42.080 --> 01:34:46.240]   this and this, you know, and you know, you can start to make connections.
[01:34:46.240 --> 01:34:52.880]   I agree. But I think like something like mandating a differential privacy for large data sets like
[01:34:52.880 --> 01:34:58.560]   this, I do think it would, it would certainly would make it much, much, much harder to say this
[01:34:58.560 --> 01:35:04.160]   comes from this person here because you're, you're taking in the middle, you're scrambling it,
[01:35:04.160 --> 01:35:07.360]   you know, it's harder to figure out the entire piece of the puzzle.
[01:35:07.360 --> 01:35:15.280]   So by the way, the good news is all three companies, Amazon, Google and Apple have said we were
[01:35:15.280 --> 01:35:18.320]   going to stop these programs unless people opt in, we're going to make them opt in.
[01:35:18.320 --> 01:35:23.840]   And so, you know, but still people, but what that's going to result in is you're going to end up
[01:35:23.840 --> 01:35:28.240]   having less, a less diverse data set, which could create new problems of its own. That's
[01:35:28.240 --> 01:35:32.720]   right. And you need diverse data sets in order to train these systems to be robust.
[01:35:32.720 --> 01:35:38.080]   Sam, your wife's here. I ride is here. So we're going to let Sam go. He's got to get out of here.
[01:35:38.080 --> 01:35:43.040]   Where are you going? Going to your own bill. Oh, I'm going to your film. That's because he's
[01:35:43.040 --> 01:35:47.200]   going to be driving the Lincoln aviator tomorrow. That's right. Fun. Oh, great. Having you Sam
[01:35:47.200 --> 01:35:52.720]   Abul Samid. He is the host of the Wheel Bering's podcast, wheel bearings.media, principal analyst
[01:35:52.720 --> 01:35:57.520]   at Naviigant Research. And he's my personal car guy. And I appreciate it. Thank you, Sam.
[01:35:57.520 --> 01:36:03.120]   He's got a great shirt too. Got to give him that. Awesome. You can get shirts like this at
[01:36:03.120 --> 01:36:08.400]   blipshift.com. Great site for if you're a car fan. Is it all? Thank you. Is it all car stuff?
[01:36:08.400 --> 01:36:12.800]   It's all car related stuff. And what they do is they have different designs each day.
[01:36:12.800 --> 01:36:18.560]   And the designs are usually available for 48 or 72 hours. And then every once in a while,
[01:36:18.560 --> 01:36:21.920]   they'll come back. They'll bring back some of the more popular ones and they'll have sales.
[01:36:21.920 --> 01:36:25.600]   Do you know about this, Brianna? I don't. I'm going to log on to say.
[01:36:25.600 --> 01:36:30.960]   Look at all the stuff. I'll show you. I'm about to look for the fart mode T-shirt.
[01:36:30.960 --> 01:36:38.160]   See what today's designs are all submitted by anybody can submit designs and they pick out
[01:36:38.160 --> 01:36:44.480]   the ones they like and they offer them for sale. Nice. Oh, yeah. A lot of cool themes.
[01:36:44.480 --> 01:36:46.880]   I can see. Go back to the Lamborghini. That was gorgeous.
[01:36:46.880 --> 01:36:53.200]   I don't even know. There's a whole section. Oh, here. Oh, yeah. Oh, yeah.
[01:36:53.200 --> 01:36:57.760]   Oh, you know, it says the high score. I love it. It's from a game. You need this.
[01:36:57.760 --> 01:37:02.000]   Is that from now? Why is that from one of those?
[01:37:02.000 --> 01:37:06.560]   One of those? Yeah, because it's all. That was the Testerosa for outrun.
[01:37:06.560 --> 01:37:12.880]   Yeah. 1988. Look at that. Wouldn't that be cool? Not bad.
[01:37:12.880 --> 01:37:15.200]   All right. I just gave him a free ad. Blip shift.
[01:37:15.200 --> 01:37:21.200]   Send him a bill. All right. Thank you, Sam. Have a great day. Our show today brought to you by
[01:37:21.200 --> 01:37:26.800]   Yes Another Company. I've advertised on Twitter for many years and then was bought by Amazon.
[01:37:26.800 --> 01:37:35.280]   I get the list is very long. Euro, pill pack, Audible. Amazon's got good taste in this case.
[01:37:35.280 --> 01:37:41.840]   Audible. We are huge Audible fans. I live on Audible books. I first started. I've been an Audible
[01:37:41.840 --> 01:37:47.040]   subscriber since the year 2000. I first 20, almost 20 years. In fact, they should get a prize on my
[01:37:47.040 --> 01:37:51.520]   20th anniversary. It was before you had to get special hardware to listen.
[01:37:51.520 --> 01:37:58.160]   They had their own Audible Otis player and all that. Now Audible couldn't be easier. There's
[01:37:58.160 --> 01:38:03.440]   Audible apps on iOS and Android. I keep Audible on everything on my computer. I can listen.
[01:38:03.440 --> 01:38:08.160]   I really like it in my iPad Pro because the speakers are good and it's got lots of storage.
[01:38:08.160 --> 01:38:15.680]   Audible is awesome. Whether you're listening to nonfiction to learn, I'm listening to some
[01:38:15.680 --> 01:38:22.320]   great books by the linguist John McWhorter about English language. One of them
[01:38:22.320 --> 01:38:29.440]   recommended to me by Jeff Jarvis, who's a fan. I'm listening to McWhorter's
[01:38:29.440 --> 01:38:36.960]   great courses on English, but he also wrote our magnificent bastard tongue, the untold story of
[01:38:36.960 --> 01:38:43.680]   English from Audible. There is so much great stuff. I like fiction too. In fact, I just finished.
[01:38:43.680 --> 01:38:49.120]   Let me go to my library, which is now more than 500 books. I just finished Neil Stevenson's newest
[01:38:49.120 --> 01:38:55.040]   fall. That's a great 31-hour listen. But you know what I'm interested in is Audible Originals,
[01:38:55.040 --> 01:38:59.760]   too. Audible's recording a lot of original stuff. Did you know that William Gibson,
[01:38:59.760 --> 01:39:05.360]   our favorite science fiction author, creator of NeuroMancer, wrote a script never produced for
[01:39:05.360 --> 01:39:13.600]   Alien 3. Never produced. Audible has produced it, dramatized it, to mark the 40th anniversary
[01:39:13.600 --> 01:39:20.400]   of the Alien franchise. It's a full cast, including Michael Bean and Lance Hernaickson,
[01:39:20.400 --> 01:39:24.960]   who reprised their iconic roles as Corporal Hicks and Bishop. Bishop is back.
[01:39:24.960 --> 01:39:31.120]   This was written in 1987 as a sequel to Aliens Never Made It to the Big Screen,
[01:39:31.120 --> 01:39:37.680]   but fans know about it. It's become a cult thing. And now you can actually hear an Aliens
[01:39:37.680 --> 01:39:42.800]   installment written by William Gibson. Is that awesome? That's an Audible original.
[01:39:42.800 --> 01:39:47.360]   I love Audible Originals. I get two new Audible Originals as part of my subscription every month.
[01:39:47.360 --> 01:39:54.800]   So Audible members choose an audiobook every month, plus two Audible Originals every month. You
[01:39:54.800 --> 01:40:00.720]   can't hear anywhere else. Such an Audible fan. Let me see what's in my library. What am I listening
[01:40:00.720 --> 01:40:10.240]   to right now? Oh, Quicksilver. After reading the, after reading the Neil Stevenson, newest Neil
[01:40:10.240 --> 01:40:14.160]   Stevens, I thought I should go back and do Quicksilver, which I skipped because it was so long.
[01:40:14.160 --> 01:40:18.320]   And this is another Audible original. I'm really interested in the man who knew the way to the moon.
[01:40:18.320 --> 01:40:24.960]   This isn't about a guy who worked at NASA, John Hubalt. When NASA was thinking about going to the
[01:40:24.960 --> 01:40:30.000]   moon, they thought, including Vernivon Braun, thought, "Oh, the best way to do this is you get one giant
[01:40:30.000 --> 01:40:38.720]   spacecraft that goes all the way there, lands and returns, like a cartoon." But Hubalt said, "No,
[01:40:39.520 --> 01:40:45.760]   you need a lunar orbit rendezvous. You need a lunar lander." And of course, that's how we landed
[01:40:45.760 --> 01:40:51.680]   on the moon. So for the 50th anniversary Audible has offered this book, "The Story of the Man Who
[01:40:51.680 --> 01:40:55.680]   Knew the Way to the Moon." You see all the great stuff you get from Audible? Would you like a free
[01:40:55.680 --> 01:41:06.960]   book? We can do it for you right now. If you go to audible.com/twit2, A-U-D-I-B-L-E.com/twit2,
[01:41:06.960 --> 01:41:17.600]   or you can text "twit2" to 500-500. Text "twit2" to 500-500. And you'll get that free book. You're
[01:41:17.600 --> 01:41:22.000]   going to love the Audible Originals. I feel like the Audible Originals are kind of like,
[01:41:22.000 --> 01:41:28.400]   so cool. I'm so, I mean, it's like, this is a free gift. I get two new books every month,
[01:41:28.400 --> 01:41:35.920]   as well as my regular subscription. I love my Audible. You will too. Audible.com/twit2.
[01:41:36.640 --> 01:41:41.280]   The number two. Or text "twit2." You can do this. In fact, you might want to do it because then you
[01:41:41.280 --> 01:41:45.600]   can do it on your phone and get the, I mean, that's basically where the book's looking to live.
[01:41:45.600 --> 01:41:55.840]   Anyway, text "twit2" to 500-500. Audible. I love Audible. I'm a huge fan.
[01:41:55.840 --> 01:42:01.520]   Let's see. The Galaxy Note 10 was announced this week.
[01:42:03.120 --> 01:42:09.360]   I know I already have a Galaxy S10+, but I ordered a Note 10+, so did Jason from all about Android.
[01:42:09.360 --> 01:42:16.320]   But I didn't pay enough attention. We streamed the event on Wednesday. Jason Howell was with me,
[01:42:16.320 --> 01:42:22.800]   so was Jeff Jarvis, so was Stacey Higginbotham. We're talking about it. We're talking. But we missed,
[01:42:22.800 --> 01:42:27.440]   I think a fairly, a couple of fairly important points that kind of surprised me now that I
[01:42:27.440 --> 01:42:34.400]   think about it. Samsung, number one, Samsung for years has run ads mocking Apple
[01:42:34.400 --> 01:42:38.240]   for losing the headphone jack, right? Courage.
[01:42:38.240 --> 01:42:41.920]   And now they deleted all those ads, right?
[01:42:41.920 --> 01:42:45.680]   They deleted the ads from their YouTube channel. They deleted them because guess what?
[01:42:45.680 --> 01:42:46.800]   There's no headphone jack.
[01:42:46.800 --> 01:42:49.600]   That's awkward.
[01:42:49.600 --> 01:42:52.320]   Awkward. Be careful what you mock.
[01:42:53.360 --> 01:43:03.120]   You might be doing it. But then another thing. So every, there's one of the headphone jack ads.
[01:43:03.120 --> 01:43:08.800]   Every one of the Samsung phones for the last couple of years has had this vestigial extra button.
[01:43:08.800 --> 01:43:18.000]   The Bixby button. This is my S10. The Bixby button. You press it and Amazon's assistant Bixby
[01:43:19.200 --> 01:43:25.520]   pops up. Amazon, I mean, Samsung, not only didn't mention Bixby,
[01:43:25.520 --> 01:43:28.640]   but they didn't neglect it and mention the fact the Bixby button's gone.
[01:43:28.640 --> 01:43:34.560]   Bixby is now in the closet with Cortana series next.
[01:43:34.560 --> 01:43:40.080]   Voice assistants who just didn't make it. Didn't make it.
[01:43:40.080 --> 01:43:41.600]   Playing seven minutes in hell.
[01:43:41.600 --> 01:43:41.920]   Yep.
[01:43:46.080 --> 01:43:51.280]   They're in the closet playing seven minutes in hell. I feel so bad for them.
[01:43:51.280 --> 01:43:55.360]   What was the third thing? This was from PC Magazine. There were three things they didn't mention.
[01:43:55.360 --> 01:44:02.320]   Oh, the A word. Samsung never mentioned Google or Android.
[01:44:02.320 --> 01:44:09.200]   Despite the fact that it absolutely is an Android phone, but they did mention Microsoft.
[01:44:09.200 --> 01:44:15.120]   In fact, and this was surprising. Microsoft CEO Satya Nadella strides up on the stage
[01:44:15.120 --> 01:44:16.720]   to talk about their partnership.
[01:44:16.720 --> 01:44:24.320]   Forget Google. We got Microsoft. It's not like they're going to be using a Microsoft operating system.
[01:44:24.320 --> 01:44:28.240]   That would be crazy. That would be nuts.
[01:44:28.240 --> 01:44:31.280]   That makes sense. It's Microsoft's liquid data strategy.
[01:44:31.280 --> 01:44:35.280]   Right? That's the problem. Microsoft had to figure out a way. We don't have a phone.
[01:44:35.280 --> 01:44:37.280]   We're never going to have a phone. We failed in the phone.
[01:44:37.280 --> 01:44:42.160]   Clearly, the phone is the platform of computing. People use more than any other.
[01:44:43.280 --> 01:44:47.360]   They don't run Windows. What can we do? Actually, I thought the announcement,
[01:44:47.360 --> 01:44:52.000]   they didn't really... I think there's more to be seen. It's one of the reasons I bought the Note 10.
[01:44:52.000 --> 01:45:00.000]   You connect a Note 10 to your Windows or your Mac, by the way, with a type C cable.
[01:45:00.000 --> 01:45:04.800]   All of a sudden, your phone is on your computer. You can run the Android programs
[01:45:04.800 --> 01:45:11.360]   from your phone. You can text messages. You can read text. It's kind of an interesting thing.
[01:45:12.160 --> 01:45:19.360]   That's the dream. It is, isn't it? That's the dream. It's weird that more companies haven't
[01:45:19.360 --> 01:45:27.920]   done that. I guess maybe they're going to make less money by doing it. I think that's great.
[01:45:27.920 --> 01:45:31.840]   I would almost buy it just for that. It's kind of brilliant on Microsoft.
[01:45:31.840 --> 01:45:37.360]   I think it makes sense with the Note. There's a stylus involved with it. You're
[01:45:37.360 --> 01:45:44.320]   kind of waking up, "Sintique for free." I don't know. I can't think of any reason I ever want to hook
[01:45:44.320 --> 01:45:52.080]   my iPhone up to my Mac. That's the point. You don't need to. This is where Microsoft was
[01:45:52.080 --> 01:45:57.200]   falling behind Apple. You've got continuity. You can easily send a picture. You could take a
[01:45:57.200 --> 01:46:02.720]   picture on your phone and it goes immediately to your Mac. You can do Apple's iMessages work fine
[01:46:02.720 --> 01:46:07.280]   on your Mac. Really, you don't need to on your Mac. Those are all features that are
[01:46:07.280 --> 01:46:14.240]   not their apps in on Windows and Android. I think this in a way, this is a response to what
[01:46:14.240 --> 01:46:18.640]   Apple's doing. What's nice is it's not an ecosystem play. These are two different companies.
[01:46:18.640 --> 01:46:24.160]   I think you really have to give Microsoft credit. Their whole liquid data
[01:46:24.160 --> 01:46:30.080]   like strategy is working. Azure is unbelievably great right now. If you think about really the
[01:46:30.080 --> 01:46:36.240]   tech company embroiled in the least number of scandals consistently, I think that speaks to them.
[01:46:36.240 --> 01:46:44.000]   I think a week from Thursday, my note, 10 will come and Jason's will and we'll be talking a lot
[01:46:44.000 --> 01:46:49.840]   about it. I will demonstrate it. For those of you who watch this show, and that's a small number,
[01:46:49.840 --> 01:46:55.440]   I've always had a Surface Studio on the desk in front of me because it's a big screen. It's easy.
[01:46:55.440 --> 01:47:00.480]   I could tell us straight it with a pen. I replaced the Surface Studio this week. This is a new machine
[01:47:00.480 --> 01:47:11.440]   from Lenovo. It does the same thing. It's a Lenovo Yoga 940, D940. It does the thing that was key for
[01:47:11.440 --> 01:47:17.040]   me with the Surface, which is Tilt's back. It's not quite as flat. Surface Studio goes to 15 degrees.
[01:47:17.040 --> 01:47:25.280]   This is 10 degrees. This is 15. Still, I think it gets out of the way. I have a pen
[01:47:25.360 --> 01:47:31.120]   that comes with a pen so I can tell us straight it. It's half the price, which is a big selling point
[01:47:31.120 --> 01:47:37.920]   for me. I'm really so far very pleased. Much faster. It's an i7, a Real i7 processor. It's got
[01:47:37.920 --> 01:47:46.880]   two drives and SSD and VME M.2 SSD. It's very fast. Mine, even, I paid $1,800. I got it on sale.
[01:47:46.880 --> 01:47:51.840]   Because it was on sale, they forgot to put the second drive in. But fine, I don't want a 5,400
[01:47:51.840 --> 01:47:56.800]   RPM drive anyway. You can keep your stupid drive line of all. I'll put an iS SSD in here later.
[01:47:56.800 --> 01:48:04.160]   But yeah, I just mentioned it also has a knob. So the Microsoft had a free-floating knob you
[01:48:04.160 --> 01:48:10.640]   can even put on the screen. This one's a USB device, but it has two scrolls. So I can use one scroll to
[01:48:10.640 --> 01:48:16.720]   scroll up in that and one to make the text bigger or smaller, which is really handy. And then it
[01:48:16.720 --> 01:48:21.680]   has a button which I can use to mute. You can program it to do other things, but I use it to
[01:48:21.680 --> 01:48:28.000]   unmute the sound. When you're using a 3D development engine, I have to tell you, Leo, if you've ever
[01:48:28.000 --> 01:48:35.120]   read the mouse commands for Unreal to navigate a space in 3D and 2D, it's not just that you have
[01:48:35.120 --> 01:48:41.280]   to have a three-button mouse. You have to memorize the most Byzantine shortcuts. And what I hear from
[01:48:41.280 --> 01:48:48.080]   everyone is the Surface knob. It's really, really great for that because it's just more innovative.
[01:48:48.080 --> 01:48:53.040]   It just feels more natural. So I'd love to play around with that. Lenovo's doing, I think,
[01:48:53.040 --> 01:48:58.240]   something similar. The knob senses if you're running Adobe Lightroom or Photoshop.
[01:48:58.240 --> 01:49:02.320]   It changes to a different color for each program you're running and has different commands.
[01:49:02.320 --> 01:49:08.080]   I know, isn't that cool? Wow. That's cool. I like, I have to say, as much as I love Max and
[01:49:08.080 --> 01:49:15.280]   I use Max and I'm kind of a Linux fan, I have to say, the PC space is by far the most hardware
[01:49:15.280 --> 01:49:20.560]   innovative space. There's anything you would want. Whatever crazy thing you could think of,
[01:49:20.560 --> 01:49:24.800]   you can get as a PC. And then I just put Linux on it. The other reason I like Lenovo is because
[01:49:24.800 --> 01:49:31.200]   I can put Linux on it. So I'll be happy. Here is good news for all of you stoners.
[01:49:31.200 --> 01:49:35.680]   And I'm doing it just because the register's headline is so good.
[01:49:35.680 --> 01:49:42.080]   Let us be... FBI NSA to hackers. Let us be blunt. We'd need your help. We'll hire you,
[01:49:42.080 --> 01:49:47.360]   even if you've smoked a little pot in the past. In the past, if you were applying for a job at
[01:49:47.360 --> 01:49:51.600]   any of these agencies and they asked you, did you ever smoke pot? And you said, "Yes, that's it.
[01:49:51.600 --> 01:49:58.960]   Goodbye." Marijuana is now legal over much of the country. So I guess Uncle Sam had to...
[01:49:58.960 --> 01:50:04.800]   An NSA representative told the register, "Look, I used to... Actually, he said it like this."
[01:50:04.800 --> 01:50:10.880]   "Look, dude, I used to smoke weed in high school. Now, so long as you could pass a drug test to
[01:50:10.880 --> 01:50:18.080]   many more at your application." That's a really good speccoli. That's a solid speccoli right there.
[01:50:18.080 --> 01:50:24.880]   So, I think... I mean, there's some serious issues here. Here in the United States, we do not have
[01:50:24.880 --> 01:50:31.280]   enough trained people in information security and cyber security. We've got to expand our workforce.
[01:50:31.280 --> 01:50:37.600]   And it's a real problem that some of the best candidates are going to Facebook. They're going
[01:50:37.600 --> 01:50:41.840]   to Amazon. They're going to Microsoft. There are many ways to serve your country. And I
[01:50:41.840 --> 01:50:47.600]   absolutely think that working on cybersecurity for the United States is a way to do it.
[01:50:47.600 --> 01:50:55.360]   But I think what this article points out is how we're really behind the times in the culture
[01:50:55.360 --> 01:51:01.600]   and standards we're expecting people interested in cybersecurity to come from. So, this just makes
[01:51:01.600 --> 01:51:06.640]   sense to me. I think it should be if you're using this in a place where it's legal,
[01:51:06.640 --> 01:51:12.240]   it should just be completely normalized. If you're able to do your job
[01:51:12.240 --> 01:51:17.040]   and smoke marijuana, I just don't think it's anyone's business, what medication you're taking.
[01:51:17.040 --> 01:51:22.400]   I agree. Also, alcohol is very problematic. Yes.
[01:51:22.400 --> 01:51:30.640]   Alcohol has been fine for decades as far as that part of the line of questioning goes,
[01:51:30.640 --> 01:51:37.440]   which obviously they're catching up to the times here. But in some scenarios,
[01:51:37.440 --> 01:51:44.720]   I'd much rather have a pothead than an alcoholic dealing with issues of national security.
[01:51:44.720 --> 01:51:51.520]   I'd rather have neither. But if I had to choose, I don't know. I'm not sure I'd prefer as somebody
[01:51:51.520 --> 01:51:58.240]   who had an actual alcohol problem. This was at Black Hat, which happened this week, Defcon, of course,
[01:51:58.240 --> 01:52:04.240]   too. Here's a story about the voting village. We haven't heard yet about how many of these
[01:52:04.240 --> 01:52:09.440]   machines were hacked. But I'm glad to see that one of the machines at voting village this year
[01:52:09.440 --> 01:52:16.240]   was DARPA's prototype $10 million voting machine DARPA, trying to create a secure voting machine.
[01:52:16.240 --> 01:52:20.720]   We're learning that we just learned recently that many, many of these voting machines being
[01:52:20.720 --> 01:52:31.760]   used by states today are still on the internet. DARPA is trying to create an open source voting
[01:52:31.760 --> 01:52:39.760]   platform built on secure hardware. In fact, you can actually use it. If you were at Defcon,
[01:52:39.760 --> 01:52:45.280]   you could vote on one of two important issues, which is the best Star Wars movie
[01:52:47.760 --> 01:52:57.280]   and our hot dogs sandwiches. It was a touchscreen system. I presume as any good
[01:52:57.280 --> 01:53:04.880]   voting system, it will have a weighted validate or audit of votes. Paper trail is so important.
[01:53:04.880 --> 01:53:11.520]   We haven't thought you'd be up. Go ahead, Brad. No, it's fine. I was just going to say,
[01:53:11.520 --> 01:53:16.640]   we have a cybersecurity proposal coming out in this next week. One of the things we
[01:53:16.640 --> 01:53:23.280]   advocate is reviving the Office of OTA, the Office of Technology Assessment, which was dismantled
[01:53:23.280 --> 01:53:30.240]   in the 1990s, just as we needed this. I don't think 99% of voting machines could pass the OTA
[01:53:30.240 --> 01:53:38.080]   if we put it back into work to look at this. I think we need a total ban until we can verify
[01:53:38.080 --> 01:53:42.720]   that these machines are safe. It's clear that they're not. Reluctance, though, at the federal level
[01:53:42.720 --> 01:53:48.400]   involved, because voting is seen as such a state's right issue, as a local issue, that the feds
[01:53:48.400 --> 01:53:50.720]   are reluctant to say, "No, this is how you're going to do it."
[01:53:50.720 --> 01:53:54.000]   That's appropriate. That's appropriate.
[01:53:54.000 --> 01:54:01.040]   But I think in this particular case, you're trying to safeguard the process in fundamental
[01:54:01.040 --> 01:54:11.520]   ways. Interestingly, the software for this DARPA voting system is online at securehardware.org
[01:54:12.320 --> 01:54:20.000]   and in fact, the guy Dan Wallach who wrote it said, "There's a terrible vulnerability in there.
[01:54:20.000 --> 01:54:24.640]   I know because I wrote it. It's a web server anyone can connect to and read and write arbitrary
[01:54:24.640 --> 01:54:29.680]   memory. That's so bad. But the idea is even with that in there in a attacker still won't be able to
[01:54:29.680 --> 01:54:34.480]   get to things like crypto keys or anything really. All they can do is crash the system. So he actually
[01:54:34.480 --> 01:54:40.560]   put a flaw in there expecting Defcon attendees would find the bugs and have some solutions,
[01:54:40.560 --> 01:54:46.720]   but he was very curious if they could still get in there and use the flaw to cause a problem.
[01:54:46.720 --> 01:54:54.000]   And then there's this guy. This may be the last year he does this. Mike Spicer,
[01:54:54.000 --> 01:55:04.960]   he is wearing what he calls the Wi-Fi cactus. It's made up of 25 pineapples. Wi-Fi pineapples.
[01:55:04.960 --> 01:55:10.080]   You can see the pineapple on the top. Pineapples, that hack five device that you can intercept and
[01:55:10.080 --> 01:55:17.440]   manipulate network traffic with. He says it weighs on his back, weighs about 35 pounds,
[01:55:17.440 --> 01:55:22.960]   which is down from the 60 pound version he wore some years ago. And it also looks pretty prickly.
[01:55:22.960 --> 01:55:29.520]   I wouldn't. Gosh, I hope he's not giving himself some sort of sterility treatment.
[01:55:29.520 --> 01:55:36.640]   He has collected. So he's going around Defcon collecting data from Wi-Fi. He says he's
[01:55:36.640 --> 01:55:42.400]   already got 427 gigabytes of network traffic. Yeah, eight gigabytes an hour.
[01:55:42.400 --> 01:55:48.240]   What he didn't say is how much of that data is encrypted. And I think that'll be interesting.
[01:55:48.240 --> 01:55:54.000]   He presented his findings at Defcon. I haven't seen it yet. Looking for insecure apps that leak
[01:55:54.000 --> 01:55:58.880]   personal information, attacks could be easily avoided. But I would bet nowadays, and this is
[01:55:58.880 --> 01:56:04.480]   the really good news, a lot of the data he's getting, a lot of those 427 gigabytes are well
[01:56:04.480 --> 01:56:08.960]   encrypted using HTTPS TLS. And that's probably good news.
[01:56:08.960 --> 01:56:14.080]   Wi-Fi. He's like a target ghostbuster. Yeah, he looks like a ghostbuster.
[01:56:14.080 --> 01:56:21.120]   You're telling, right? The Wi-Fi cactus found a bunch of fake access points, including 17
[01:56:21.120 --> 01:56:26.800]   with the lyrics of never going to give you up. Obviously, Rick rolled, right?
[01:56:29.840 --> 01:56:35.920]   So I just, I don't know, he's been doing this for years. He says, this might be the last time.
[01:56:35.920 --> 01:56:41.680]   It's kind of a pain to travel with magic going through security inspection.
[01:56:41.680 --> 01:56:53.680]   Imagine that conversation with TSA. I can't even explain it to you. I can't even tell you.
[01:56:53.680 --> 01:56:59.520]   Tuesday, it's funny. I expect to get stopped all the time with a lot of the radio.
[01:56:59.520 --> 01:57:05.120]   Equipment that I travel with, they don't care. It looks so, I expect, it looks terrible.
[01:57:05.120 --> 01:57:09.200]   I mean, it looks really weird, but they never, they never stop me.
[01:57:09.200 --> 01:57:14.560]   I'm not surprised. I had something, it was the hot new thing. I can't remember what it was. It
[01:57:14.560 --> 01:57:19.680]   might have been an Amazon Echo or something. And they asked me for information about it. They
[01:57:19.680 --> 01:57:23.440]   said, we don't think it's a threat, but we just like to know ahead of time. So, because we're
[01:57:23.440 --> 01:57:26.720]   going to probably see a lot more of these, right? And I said, yeah, you probably are. So,
[01:57:27.760 --> 01:57:32.320]   we just like to know what it is, what's doing, so we can kind of have a profile of it.
[01:57:32.320 --> 01:57:36.880]   So, maybe they just already know about radio equipment. It's not exactly the least thing.
[01:57:36.880 --> 01:57:42.800]   It's like podcasts.
[01:57:42.800 --> 01:57:49.920]   You just wouldn't understand.
[01:57:56.080 --> 01:58:01.360]   Twitter has now unfrozen Mitch McConnell's account. Okay. That's just crazy. The whole
[01:58:01.360 --> 01:58:04.800]   thing was crazy. They froze it. Well, I want to, you know what? Let me take a little break,
[01:58:04.800 --> 01:58:10.640]   because I do want to, before we go, since Brianna's here, I want to talk about what Elizabeth Warren
[01:58:10.640 --> 01:58:16.400]   proposed for the internet. Big, big, interesting. First of all, I commend her
[01:58:16.400 --> 01:58:22.000]   as a presidential candidate to actually have an internet policy is probably unheard of. So,
[01:58:22.000 --> 01:58:26.240]   I'm really glad it's part of-- She's got a lot of policy.
[01:58:26.240 --> 01:58:30.080]   She's got a lot of policy. Her policy game is strong. Pretty strong.
[01:58:30.080 --> 01:58:33.200]   Strong. Yeah. And I'll be in, you know,
[01:58:33.200 --> 01:58:41.120]   I'll just say for full disclosure that I wasn't really, I was supporting somebody else. I won't
[01:58:41.120 --> 01:58:47.520]   say who. It's early days. We know we'll be changing our minds, but I gave, I started contributing to
[01:58:47.520 --> 01:58:51.600]   her campaign when I read this, because I think this is really important. And I really like what
[01:58:51.600 --> 01:58:56.320]   she said, whether it's doable is another matter. But we'll talk about that in just a second.
[01:58:56.320 --> 01:59:02.160]   I'll show today brought to you by Capterra. If you are in business and you have a, you know,
[01:59:02.160 --> 01:59:06.400]   we all have in business line of business software we have to use. If you're in real estate, the MLS,
[01:59:06.400 --> 01:59:11.520]   if you're, you know, managing a veterinary office, you've got your software for booking
[01:59:11.520 --> 01:59:18.640]   clients and appointments and ordering supplies. But for a lot of us, those programs are pretty
[01:59:18.640 --> 01:59:23.680]   darn old, you know, because one third of all the machines in the United States are still running
[01:59:23.680 --> 01:59:28.560]   Windows XP. There's no, the only reason one third of all the machines in the United States are running
[01:59:28.560 --> 01:59:36.320]   Windows XP is because they got some dumb program. The boss's nephew, Joey, wrote when he was on
[01:59:36.320 --> 01:59:42.800]   a summer break, Joey went off to do something else. But the whole business runs on the software and
[01:59:42.800 --> 01:59:48.000]   they don't dare take it down. Let's do this. This is kept here is doing its part to get Windows XP
[01:59:48.000 --> 01:59:55.440]   and Internet Explorer eight out of the ecosystem. Capterra is the leading free online resource to
[01:59:55.440 --> 02:00:01.840]   help you find modern software for your business. There really is something better. It'll run on a
[02:00:01.840 --> 02:00:06.240]   modern operating system. It'll run securely. It'll do a better job. It'll run faster. But how do
[02:00:06.240 --> 02:00:12.400]   you find it? You don't Google it. You go to Capterra. Capterra has 700 categories of software,
[02:00:12.400 --> 02:00:18.480]   all the big ones, project management, email marketing, CRM, but also a lot of specific line of business
[02:00:18.480 --> 02:00:23.040]   software. Carson always takes this as a challenge when he's doing the show to find the craziest
[02:00:23.040 --> 02:00:29.120]   business. Farm management software. What a fact server software. Yes, it still exists.
[02:00:29.120 --> 02:00:35.280]   So you can go in there, find software. Here's the best part. You can check boxes to select the
[02:00:35.280 --> 02:00:40.080]   features you want, the reviews, it's got the quality of the software, all of that stuff. Narrow
[02:00:40.080 --> 02:00:45.280]   it down, get a side-by-side comparison chart of up to four different programs. And then the best part
[02:00:45.280 --> 02:00:51.680]   of all, because you're getting all the information you need, the best part of all reviews, they are
[02:00:51.680 --> 02:00:58.560]   getting close now to a million real reviews from real users, 975,000 reviews of the 1000 new reviews
[02:00:58.560 --> 02:01:05.280]   every single day. Those reviews are critical because you can see how actual users are using
[02:01:05.280 --> 02:01:09.440]   the software, whether they like it, whether it does the job, whether this is exactly what you
[02:01:09.440 --> 02:01:13.840]   want. As this is, it's if you got a million friends who are helping you choose the right software,
[02:01:13.840 --> 02:01:17.600]   no matter what kind of software your business needs, Kepterra makes it easy to discover the
[02:01:17.600 --> 02:01:22.640]   right solution fast. Millions of people use Kepterra every month. That's why there's so many reviews.
[02:01:22.640 --> 02:01:28.720]   And can I tell you the most important part? It's free. Not free. They're going to charge you
[02:01:28.720 --> 02:01:33.920]   later. Not free. They're going to upsell you free, like free period done. In fact, the only thing I'd
[02:01:33.920 --> 02:01:39.520]   suggest if you've I mean, this is such a great service for free, leave a review, pay it forward.
[02:01:39.520 --> 02:01:45.280]   Help the next person choose the best software. Kepterra believes that software makes the world a
[02:01:45.280 --> 02:01:50.080]   better place because software can help every organization become a more efficient, effective
[02:01:50.080 --> 02:01:57.760]   version of itself. You should see this site. It's awesome. And if you do that, go there, go there
[02:01:58.480 --> 02:02:08.240]   using this URL so they know you saw it on Twitter. Kepterra.com/twit. C A P T E double R A Kepterra.com/twit.
[02:02:08.240 --> 02:02:15.680]   Kepterra.com/twit. Kepterra is software selection simplified. And it's a really great site. I'm really
[02:02:15.680 --> 02:02:17.920]   glad to have their support.
[02:02:21.040 --> 02:02:29.040]   On Medium. Team Warren. My plan to invest in rural America, and there's a lot to this,
[02:02:29.040 --> 02:02:34.240]   I'm very curious what you guys think of this. But the thing that attracted me, I mean, everything
[02:02:34.240 --> 02:02:41.440]   I thought in here was very thoughtful, as usual from Elizabeth Warren. But I thought that some of
[02:02:41.440 --> 02:02:51.120]   the things she's proposing for the internet were really smart. She wants to invest $85 billion.
[02:02:51.120 --> 02:02:57.360]   She says the internet is crucial for rural America. It's for economic security, for participating
[02:02:57.360 --> 02:03:05.200]   in our democracy. The internet is important. We know that. One of the best tools for unlocking
[02:03:05.200 --> 02:03:10.160]   economic opportunity and advances in healthcare, she writes like telemedicine is access to reliable
[02:03:10.160 --> 02:03:15.360]   high speed internet. In the 21st century, every home should have access to this technology. We're
[02:03:15.360 --> 02:03:21.920]   not even close to that today. According to the FCC, which by the way, has very low standards for
[02:03:21.920 --> 02:03:29.360]   what broadband is, 26% of people living in rural areas, 32% of people living on tribal lands do not
[02:03:29.360 --> 02:03:35.440]   have access to the minimum speed broadband, which is 25 megabits. And given the notorious
[02:03:35.440 --> 02:03:39.280]   loophole in FCC reporting requirements, that's something else she wants to address. These figures
[02:03:39.280 --> 02:03:44.560]   underestimate the gap. She wants to earmark a significant amount of money. I think this is
[02:03:44.560 --> 02:03:49.520]   partly the key to what she's doing compared to what other candidates have proposed.
[02:03:49.520 --> 02:03:55.280]   Now, this one thing maybe I'm not crazy about, is create the office of broadband access.
[02:03:55.280 --> 02:04:00.960]   That's in the economic development department that will manage an $85 billion federal grant
[02:04:00.960 --> 02:04:06.720]   to massively expand broadband access across the country. Kind of like
[02:04:07.680 --> 02:04:12.960]   the rural electrification program of Great Depression, where we decided as a country,
[02:04:12.960 --> 02:04:17.840]   you know what? Everyone should have electricity. You shouldn't be left out. And the Tennessee
[02:04:17.840 --> 02:04:22.160]   Valley Authority was created. Electrification spread across this country.
[02:04:22.160 --> 02:04:27.440]   I'd say where I grew up, Lea, that had a huge effect to this day. I was just about to say,
[02:04:27.440 --> 02:04:35.360]   and Mississippi absolutely. No, this is, you know, Lea, your very first sponsor on this show was
[02:04:35.360 --> 02:04:42.320]   about finding jobs online, right? So this is access to the internet. It is a fundamental right,
[02:04:42.320 --> 02:04:48.240]   as much as access to electricity or water is a right. And I just want to say this is a plan that
[02:04:48.240 --> 02:04:52.880]   is not really going to help blue states that much. This is for the middle of the country.
[02:04:52.880 --> 02:04:55.040]   I'm 100% for this.
[02:04:55.040 --> 02:05:00.160]   I kind of admire a Democratic candidate proposing something that doesn't help Democratic voters
[02:05:00.160 --> 02:05:05.120]   particularly. But it's about doing the right thing. It's about playing people participate
[02:05:05.120 --> 02:05:10.320]   in the democracy. This about helping that economic development. There's a lot more that's there.
[02:05:10.320 --> 02:05:15.520]   I do want to say, you know, like you referenced the Tennessee Valley Authority. And yes, some of
[02:05:15.520 --> 02:05:22.960]   that was corporate subsidies. But it does, it makes me go, are we just going to be subsidizing
[02:05:22.960 --> 02:05:29.040]   Comcast and Verizon for them to, you know, build a better way. That has not worked out. That's
[02:05:29.040 --> 02:05:33.600]   what we've been doing up to now in those companies without any requirement that they build rural.
[02:05:35.040 --> 02:05:39.440]   Plants, those companies have ignored their requirements or ignore it.
[02:05:39.440 --> 02:05:45.040]   We saw that happen with phone lines, right? I mean, this this reminds me of like, you know,
[02:05:45.040 --> 02:05:51.280]   you know, Bell and all of this history of like companies basically saying, look, it's not worth
[02:05:51.280 --> 02:05:56.960]   it for us to to wire up these rural communities and just refuses to do it.
[02:05:56.960 --> 02:05:58.800]   It isn't. And I understand.
[02:05:58.800 --> 02:06:04.560]   If you're Comcast, you're not going to spend money trenching out to a part of the country
[02:06:04.560 --> 02:06:08.080]   where there's five people per square mile, you cannot make your money back.
[02:06:08.080 --> 02:06:09.520]   That's why the government has to do it.
[02:06:09.520 --> 02:06:14.240]   And the government would, yeah, you're right. There are subsidies.
[02:06:14.240 --> 02:06:21.120]   You know, they're going to basically pay 90 cents on the dollar for construction under these
[02:06:21.120 --> 02:06:25.760]   grants. But in exchange, applicants will be required to offer high-speed public broadband
[02:06:25.760 --> 02:06:32.800]   to every home in the area they're applying for at least one plan with 100 megabits per second
[02:06:32.800 --> 02:06:39.520]   symmetric. And one discount plan for low-income customers with a prepaid feature or a low monthly
[02:06:39.520 --> 02:06:45.280]   rate, $5 billion will be set aside for tribal lands, which is very important.
[02:06:45.280 --> 02:06:50.960]   Brianna Brianna probably knows about this, but there's a community that's right next to me
[02:06:50.960 --> 02:07:00.160]   leverage it that has, you know, that built their own municipal system. And these communities
[02:07:00.160 --> 02:07:04.800]   really, really need it. I mean, I have friends who live in upstate New York who, I mean,
[02:07:04.800 --> 02:07:13.840]   they have plenty of economic opportunity themselves, but they talk about how hard it is to get access
[02:07:13.840 --> 02:07:21.120]   and to do their jobs from there. And it really is true that it's an economic driver at this point.
[02:07:21.120 --> 02:07:22.000]   It's essential.
[02:07:22.000 --> 02:07:24.480]   And so I think it makes a lot of sense.
[02:07:24.480 --> 02:07:31.520]   So you're lucky that leverage could do that because in more than I think 20 states in the country,
[02:07:31.520 --> 02:07:37.200]   it's illegal for municipalities to create their own municipal Wi-Fi. Because the big telecom
[02:07:37.200 --> 02:07:42.160]   companies come in, they lobby the state legislatures and they get it shut down. And it started in
[02:07:42.160 --> 02:07:48.480]   Philadelphia, started putting in municipal Wi-Fi in Comcast's backyard. And they said,
[02:07:48.480 --> 02:07:53.760]   "Uh-uh." So one of the things also important plank in this is make it clear in federal
[02:07:53.760 --> 02:07:58.080]   statute, municipalities have the right to build their own broadband networks.
[02:07:58.080 --> 02:07:59.040]   Yep.
[02:07:59.040 --> 02:07:59.520]   Yeah.
[02:07:59.520 --> 02:08:00.560]   It's 26 states.
[02:08:00.560 --> 02:08:01.200]   It's illegal.
[02:08:01.200 --> 02:08:02.640]   But it's worth trying.
[02:08:02.640 --> 02:08:03.760]   Yeah. Okay.
[02:08:03.760 --> 02:08:06.880]   That's a whole different conversation. Can this happen?
[02:08:06.880 --> 02:08:07.920]   Could she do this? Sure.
[02:08:07.920 --> 02:08:13.040]   The president isn't a dictator. You can't just write a law and say, "That's it. You got to get it."
[02:08:13.040 --> 02:08:13.360]   Yes.
[02:08:13.360 --> 02:08:15.600]   Congress. So we got to, well, like Brianna Wu.
[02:08:16.960 --> 02:08:19.280]   I would vote for this. I would absolutely vote for this.
[02:08:19.280 --> 02:08:25.840]   I do want to say, there are two other issues here. 18% of people that do not have internet
[02:08:25.840 --> 02:08:30.880]   access is because they can't afford it. So I do appreciate that she has a plan there to help
[02:08:30.880 --> 02:08:36.560]   give low-income people access to this. The other thing is I feel like people that don't live in
[02:08:36.560 --> 02:08:44.000]   Massachusetts, conflate Boston and the rest of our state. And we have real problems in Western
[02:08:44.000 --> 02:08:51.760]   Massachusetts with access to broadband. Over 10% of our population does not have access to DSL.
[02:08:51.760 --> 02:08:58.320]   And if you count cable in some ways, you can fudge that number and say it's 2%. But the reality is,
[02:08:58.320 --> 02:09:04.160]   there are hundreds of thousands of people. In our state, one of the richest states in America
[02:09:04.160 --> 02:09:09.680]   that don't have access to this. So this does primarily affect the middle of America more,
[02:09:09.680 --> 02:09:12.160]   but everybody's going to win from a plan like this.
[02:09:12.160 --> 02:09:17.280]   One other thing I think we'd all agree, prohibit the range of sneaky maneuvers giant private
[02:09:17.280 --> 02:09:23.040]   providers used to unfairly squeeze out competition, hold governments hostage and drive up prices.
[02:09:23.040 --> 02:09:30.320]   Correct. Things like she wants to return control of utility poles and conduits to cities.
[02:09:30.320 --> 02:09:35.920]   Perhibit landlords are making side deals with private ISPs to limit choices in their properties.
[02:09:35.920 --> 02:09:41.200]   I talked to some of the other day who hates the ISP and wants to bring in his own internet.
[02:09:41.200 --> 02:09:46.480]   I said, well, I got bad news for you. Your apartment complex negotiated that deal with that ISP.
[02:09:46.480 --> 02:09:49.920]   That's your one and only choice. Yeah. That's your one.
[02:09:49.920 --> 02:09:53.840]   There's a Boston startup that I think ran up against that. I don't know if there's still a
[02:09:53.840 --> 02:10:00.320]   round or not Brianna Starry. I think it's called the guy who I forget his name now,
[02:10:00.320 --> 02:10:05.840]   but his previous company went all the way to the Supreme Court with those little antennas that
[02:10:05.840 --> 02:10:11.840]   they were letting people rent to stream television channels. You know what I'm talking about, Liam?
[02:10:11.840 --> 02:10:14.400]   All right. Yeah, I do. I do. I do. Absolutely.
[02:10:14.400 --> 02:10:18.720]   Absolutely. That's right. That's right. And Starry was, I think, trying to do this.
[02:10:18.720 --> 02:10:24.320]   Same thing. I forget what the technology was, but they were essentially trying to make inroads
[02:10:24.320 --> 02:10:33.200]   into housing in Boston in order to use their technology as an ISP. I think it was almost like
[02:10:33.200 --> 02:10:37.760]   in tenant based yet again, somehow, that they were picking up the signal.
[02:10:37.760 --> 02:10:42.880]   I wonder if 5G changes this equation. I mean, right? Yeah.
[02:10:42.880 --> 02:10:46.640]   People in the chat are talking about that a lot mentioning 5G. Yeah.
[02:10:46.640 --> 02:10:53.040]   I mean, I think it's, I've talked to Motorola when they were first bringing this technology out.
[02:10:53.040 --> 02:10:57.520]   They came on rocket to talk about it. And I don't think it's going to be a panacea.
[02:10:57.520 --> 02:11:02.240]   And of course, information coming from Motorola, you know, consider the source, obviously. But
[02:11:02.240 --> 02:11:08.080]   it's certainly, it's interesting. It's really interesting because it has two modes. You've got this
[02:11:08.080 --> 02:11:13.280]   really, really fast local mode that can, you know, rival broadband. And then you've got this
[02:11:13.280 --> 02:11:17.600]   long range mode that could be used to help spread internet access.
[02:11:17.600 --> 02:11:22.640]   I have to say we've heard this story before. Remember Ymax? Yeah.
[02:11:22.640 --> 02:11:26.400]   When Ymax first came around, it was going to be the hope for rural areas.
[02:11:27.440 --> 02:11:32.480]   But of course, there's not money, there's very little money in wiring or rural areas. So the
[02:11:32.480 --> 02:11:38.000]   first place Ymax rolled out was major metros. It's actually a good thing because Ymax was a flop.
[02:11:38.000 --> 02:11:44.480]   But it didn't go to rural areas first. And I'm sure 5G won't either. It's just not worth it.
[02:11:44.480 --> 02:11:50.160]   It's not worth it. She also says, we'll make sure that landlords, oh,
[02:11:50.160 --> 02:11:53.200]   band companies from limiting access to wires inside buildings.
[02:11:54.160 --> 02:11:58.400]   All new buildings are fiber ready so any network can deliver service there. We'll also enact
[02:11:58.400 --> 02:12:04.320]   dig once policies. I love this one to require that conduit is laid. Conduit is laid. Anytime
[02:12:04.320 --> 02:12:10.800]   the ground is open for a public infrastructure project. That makes sense. Yeah. I think there's a
[02:12:10.800 --> 02:12:16.000]   lot. I mean, I don't expect a lot from politicians. Please forgive me, Brianna.
[02:12:16.000 --> 02:12:19.040]   No, it's fine. It's fine. But whoever.
[02:12:19.040 --> 02:12:25.200]   Dennis seemed the guys around here too. He will impact me up. Yeah. Absolutely.
[02:12:25.200 --> 02:12:30.320]   I was really impressed by this enough. So as I said, and for full disclosure,
[02:12:30.320 --> 02:12:36.400]   to contribute to her campaign because I don't know if you can do it. But anybody who's smart enough
[02:12:36.400 --> 02:12:42.160]   to write this deserves a shot. And maybe if nothing else, this will begin a conversation
[02:12:42.160 --> 02:12:47.200]   among all the candidates. This is something I think we absolutely need
[02:12:48.080 --> 02:12:54.480]   in this country. Yeah. It's a big part of income inequality, inequality in general,
[02:12:54.480 --> 02:12:58.400]   and geographic, I think discrimination.
[02:12:58.400 --> 02:13:03.440]   Well, also cultural isolation. The first topic we were talking about is why are we so
[02:13:03.440 --> 02:13:09.520]   feeling so distant from each other. I would certainly never suggest that everybody getting
[02:13:09.520 --> 02:13:19.040]   online will solve that problem. But I think it's a bigger thing, Leo. But I think the bigger thing
[02:13:19.040 --> 02:13:24.240]   in America is I think the irony is we're more connected to each other than ever before.
[02:13:24.240 --> 02:13:33.120]   And we all feel so isolated and alone at the same time. So I think there's a conversation to be had
[02:13:33.120 --> 02:13:38.480]   about that gap that all of us are feeling. It's hard to solve. It's about two years ago that the
[02:13:38.480 --> 02:13:42.800]   USS John McCain collided with a Liberian oil tanker. Remember this?
[02:13:42.800 --> 02:13:51.280]   The crash killed 10 sailors injured 48 aboard the McCain. They lost control of the ship
[02:13:51.280 --> 02:13:56.560]   putting into the path of the tanker. And it turns out that happened when crew members tried to
[02:13:56.560 --> 02:14:02.320]   split throttle and steering control. These are computer controlled ships these days
[02:14:02.320 --> 02:14:07.760]   between consoles. The report that just came out said that while fatigue and lack of training
[02:14:07.760 --> 02:14:14.080]   played a role in the accident, it was the design of the control console contributed to it because
[02:14:14.080 --> 02:14:20.080]   the ship's control console features a pair of touch screens. Both on the helm and the lee
[02:14:20.080 --> 02:14:26.560]   helm stations, crews use touch screens to steer and propel the ship. The crew had placed it in
[02:14:26.560 --> 02:14:33.360]   backup manual mode that removed the computer's assist because they wanted more direct communication
[02:14:33.360 --> 02:14:40.560]   between steering and the ship's control console is as a result, they're going to replace touch
[02:14:40.560 --> 02:14:47.200]   screen controls on naval vessels with mechanical ones. Good. No more touch screens.
[02:14:47.200 --> 02:14:55.840]   This is so crazy to me. Like we are talking about the US military. And I just feel like,
[02:14:55.840 --> 02:15:01.360]   don't make it a touch screen. Why do you have to control the thing with a touch screen?
[02:15:01.360 --> 02:15:07.840]   Right. I want six different dudes and ladies and whoever to have to turn the key at the same time
[02:15:07.840 --> 02:15:15.600]   do the thing to do the thing. It's like, I don't want you to controlling a military vessel with an
[02:15:15.600 --> 02:15:21.040]   iPad. Please stop trying to do this. It's exactly by the way. That's exactly what
[02:15:21.040 --> 02:15:29.440]   real Admiral Bill Galenis said. Just because you can doesn't mean you should. Just because you
[02:15:29.440 --> 02:15:36.480]   can make them touch screens. Don't doesn't necessarily mean he said if the NTSB said if they had throttles,
[02:15:36.480 --> 02:15:41.680]   regular old mechanical controls have been present, the helmsman would likely have been alerted that
[02:15:41.680 --> 02:15:47.920]   there was an issue early on avoiding the collision entirely. So they're going to put back throttles.
[02:15:47.920 --> 02:15:54.960]   Leah, this is like right back to the conversation. Yes. Yeah, the most confessing conversation I've
[02:15:54.960 --> 02:16:01.280]   ever had in my entire career regarding UI was with someone that helped design the UI for
[02:16:01.280 --> 02:16:10.480]   basically military vehicles, like helicopters, fighter aircraft, all of that. They have a really
[02:16:10.480 --> 02:16:15.760]   well done standard for all of this. Think about the movie where they're opening up the cover over
[02:16:15.760 --> 02:16:23.200]   the switch and they're flicking it or the alarm going off. There's a ton of UI thought around that.
[02:16:23.200 --> 02:16:30.080]   And it's all to only alert you when things are really, really, really critical that you can't
[02:16:30.080 --> 02:16:37.520]   screw them up. So if they have all this wonderful design language, it just seems bad to move over
[02:16:37.520 --> 02:16:46.720]   to a touch screen. It's like when your spouse wires up your house for voice control and suddenly
[02:16:47.360 --> 02:16:54.400]   the light switch on the wall does nothing. This was not an improvement. Speaking from personal
[02:16:54.400 --> 02:17:03.360]   experience. Yes. Poor Stacey Higginbotham's husband has never gotten over the fact that he cannot
[02:17:03.360 --> 02:17:11.600]   close the blinds with a string. Anyway, yeah, I mean, it's a serious issue. And I just find it.
[02:17:11.600 --> 02:17:18.240]   Yes, it's telling. I guess it turns out naval vessels or automobiles fail fast and break things
[02:17:18.240 --> 02:17:26.560]   does not always work. Yep. Does not always work. My friends, the time has come to say goodbye to
[02:17:26.560 --> 02:17:30.880]   all our family. Thank you so much. Ben Brock Johnson, always a pleasure.
[02:17:30.880 --> 02:17:34.560]   Plug to be with you both. Plug something, Ben.
[02:17:36.400 --> 02:17:44.080]   I make a show every week about Reddit. It's interesting. Sometimes it's scary. Sometimes it's funny.
[02:17:44.080 --> 02:17:51.440]   I just did an episode actually just did a two parter about a mysterious mountain of dishware
[02:17:51.440 --> 02:18:00.400]   in the woods. That's Reddit. It's a mysterious mountain of dishware in the woods.
[02:18:00.400 --> 02:18:06.000]   Yeah. And we solved it this week's episode, which you're looking at right now is about the growth
[02:18:06.000 --> 02:18:15.520]   in the audio erotica industry. Yeah. And the huge, huge, huge, huge community on Reddit called
[02:18:15.520 --> 02:18:24.720]   Gumwild Audio 300,000 subscribers. Really interesting conversations about both the most basic part
[02:18:24.720 --> 02:18:31.520]   of this, which is audio erotica, but also how some members of that community are using some of
[02:18:31.520 --> 02:18:40.400]   the content to move towards better sexual health. So it really runs the gamut for us every week
[02:18:40.400 --> 02:18:45.120]   from all the way from mountains of plates in the woods that a bunch of map nerds are trying to
[02:18:45.120 --> 02:18:52.080]   figure out where the mountain of plates are to audio porn. And there was an example of this audio
[02:18:52.080 --> 02:18:58.960]   porn that we described that was based on a next generation episode where there's like a
[02:18:58.960 --> 02:19:06.960]   transporter issue and you get two different versions of Riker. Oh, no. But this episode in this sort
[02:19:06.960 --> 02:19:12.080]   of fanfic, I guess we'll call it one of them is a female. It doesn't have to be obviously
[02:19:12.080 --> 02:19:17.520]   they're both have beards. They know one of them doesn't have a beard. So it really wasn't a
[02:19:17.520 --> 02:19:23.360]   good replica. Yeah. I want to hear your amber room piece. I'm going to be listening this because
[02:19:23.360 --> 02:19:28.240]   I've been in the amber room in St. Petersburg, which is beautiful. Yeah, absolutely. The
[02:19:28.240 --> 02:19:34.720]   reconstructive is fake. Is there something I should know? Is it plastic? No, no. The one that's been
[02:19:34.720 --> 02:19:40.880]   the one that's been constructed in St. Petersburg, it is a recreation. But that one, but that story
[02:19:40.880 --> 02:19:45.760]   is super fascinating. Yeah, they admit that. That story is super fascinating. The Nazis stole it
[02:19:45.760 --> 02:19:51.600]   from say from Catherine's palace. They took it. Exactly. Yep. And a lot of treasure hunters
[02:19:51.600 --> 02:19:57.760]   still think it's out there somewhere. Super fascinating story. Really interesting. Talk to
[02:19:57.760 --> 02:20:04.720]   somebody who basically wrote the book on it. Oh, neat. So yeah. So yeah, I hope you listen and enjoy.
[02:20:04.720 --> 02:20:07.360]   I will because I've been there and it was an amazing thing to see.
[02:20:07.360 --> 02:20:16.320]   Absolutely. I have to tell you, WBUR is a treasure here in Massachusetts. You guys do amazing work.
[02:20:16.320 --> 02:20:22.480]   And frankly, one of the reasons our state functions is because we have really strong local
[02:20:22.480 --> 02:20:30.240]   journalism like yours. So if it's on there, it's well worth your time. It's 100% true. WBUR.org.
[02:20:30.240 --> 02:20:35.680]   Come visit. I'm sure you will be. I've been down there for a few times. Yeah. Yeah. Yeah.
[02:20:35.680 --> 02:20:39.120]   Yeah. Yeah. Good move. I think it was a good move to go to BUR. That's great. Well done.
[02:20:39.120 --> 02:20:44.240]   Ben Brock Johnson. Thank you. And of course, everybody in the Massachusetts 8th, you know what
[02:20:44.240 --> 02:20:52.240]   you need to do. Register to vote. And then next year, vote for Brianna Wu for Congress. Where can
[02:20:52.240 --> 02:20:57.680]   they go to support your campaign? You can do that by going to supportbrianna.com.
[02:20:57.680 --> 02:21:04.160]   You know, a reality is running for Congress takes money. I'm a Democrat. I believe in paying
[02:21:04.160 --> 02:21:10.160]   my team. And we have a really bright, just unbelievable young field coordinator right now.
[02:21:10.160 --> 02:21:15.200]   And I want to give him a great job. So you can do that by going to supportbrianna.com.
[02:21:15.200 --> 02:21:21.120]   I shall. Are using our website with the type that type that, you know,
[02:21:21.120 --> 02:21:26.400]   that I'm forgetting the word now for it. But the fact that it types out when you look at it. Yeah.
[02:21:26.400 --> 02:21:30.240]   Yeah. Yeah. The cursor. That's what I'm looking for. Yeah. That's so cool.
[02:21:30.240 --> 02:21:36.480]   She knows how to do JavaScript. I'm just saying. Yeah. I did not code this. I raised the
[02:21:36.480 --> 02:21:42.320]   money to pay for it. So do you use XBLUE? We do. We do. It's another Boston based
[02:21:42.320 --> 02:21:50.640]   business. So they are amazing. So both Amy Klobuchar and so when I move my
[02:21:50.640 --> 02:21:56.880]   support from Amy to Elizabeth Warren, I was already on act blue. So it was very easy.
[02:21:56.880 --> 02:22:01.680]   They're making it easy. A lot of Democrats. I'll just log in and I'll give you some money too.
[02:22:01.680 --> 02:22:05.600]   It's just another button. Yes. Thank you, Leo. We appreciate that. Absolutely. Good luck,
[02:22:05.600 --> 02:22:09.200]   Brianna. And we'll sure be seeing a lot more of you before the election. But
[02:22:09.200 --> 02:22:14.960]   I'm going to win this time, Leo. And you're going to come do TWET from the tech subcommittee
[02:22:14.960 --> 02:22:23.120]   room in Congress. Yeah. Oh, oh, yes. Now they'll never let me in. No, I will get you
[02:22:23.120 --> 02:22:30.640]   journalist clearance. Oh, I can't support you because it will look like a bribe. Oh, that's true.
[02:22:30.640 --> 02:22:39.680]   We had this conversation never happened. Never happened. Always a pleasure. Thanks also to Sam
[02:22:39.680 --> 02:22:44.080]   Eble submit from Navigate Research who was here earlier. We thank all of you for being here too.
[02:22:44.080 --> 02:22:49.520]   We had a great studio audience from Santa Clara, Clarita, Bob and Sandy. Thanks for joining us.
[02:22:49.520 --> 02:22:53.760]   We appreciate it. I hope it wasn't too miserable at the time. If you want to be in the studio,
[02:22:53.760 --> 02:22:58.000]   we actually did have another couple who's here, ran. They ran screaming. But if you,
[02:22:58.000 --> 02:23:02.480]   and we don't lock you in. So you could do that if you want to be here.
[02:23:02.480 --> 02:23:08.720]   Just email tickets at twit.tv. We'll put a chair out for you. You can also watch the live stream
[02:23:08.720 --> 02:23:13.920]   or listen to the live stream as we make any of our shows, twit.tv/liveaudio and videos there.
[02:23:13.920 --> 02:23:18.000]   If you're doing that, please join us in the chat room. That's where the conversation happens.
[02:23:18.000 --> 02:23:24.400]   It's a lot of fun. And Pruitt's in there right now. He's getting the most of the studio as well
[02:23:24.400 --> 02:23:32.000]   as Ben. Just irc.twit.tv. It is a traditional IRC server. So you can use your, you know,
[02:23:32.000 --> 02:23:38.880]   Merck or your textual or your IRC client of your choice. I use Mutter. But if you don't,
[02:23:39.680 --> 02:23:45.040]   or IRSSI, there you go. Command line. How about that? If you don't want to be in the chat room,
[02:23:45.040 --> 02:23:48.560]   you could still listen. That's okay. But it's nice if you're in the chat room too. We get a lot
[02:23:48.560 --> 02:23:53.280]   of, I get all my good ideas from the chat room. After the fact on demand versions of everything
[02:23:53.280 --> 02:24:00.560]   we do available, see it's thing, this thing called a podcast. You can download. Man, I hate that name.
[02:24:00.560 --> 02:24:06.880]   I fought it for years, but I've given up now. You can download a copy of our podcast by going
[02:24:06.880 --> 02:24:12.560]   to twit.tv. And actually, there's subscription buttons on all the pages for all the shows.
[02:24:12.560 --> 02:24:17.600]   That's an easy way to subscribe and make the show part of your regular download. That way,
[02:24:17.600 --> 02:24:21.760]   you'll have it ready every Monday morning as you get in the car. You can listen to Twit.
[02:24:21.760 --> 02:24:25.440]   Thank you everybody for joining us. We'll see you next time. Another Twit.
[02:24:26.320 --> 02:24:28.000]   This is amazing.
[02:24:28.000 --> 02:24:37.920]   Do the Twit. All right. Do the Twit, baby. Do the Twit. All right. Do the Twit.
[02:24:37.920 --> 02:24:59.920]   [ Silence ]

