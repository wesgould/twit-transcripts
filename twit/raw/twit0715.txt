;FFMETADATA1
title=8K + 5G
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=715
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:03.120]   It's time for Twit this week in Tech. What a great panel we have for you.
[00:00:03.120 --> 00:00:07.520]   Dylan Twini is here. Nate Langson from Bloomberg and our great buddy from
[00:00:07.520 --> 00:00:11.480]   Mengajit Devindra, Harder War. There's lots to talk about including Samsung's
[00:00:11.480 --> 00:00:17.320]   folding phone fail. The mental health apps that secretly share your data and
[00:00:17.320 --> 00:00:21.800]   ransomware attacks. Are they actually an act of war? It's all coming up next on
[00:00:21.800 --> 00:00:24.200]   Twit.
[00:00:24.200 --> 00:00:31.200]   Netcasts you love. From people you trust.
[00:00:31.200 --> 00:00:35.600]   This is Twit.
[00:00:35.600 --> 00:00:50.360]   This is Twit this week in Tech. Episode 715 recorded Sunday April 21st 2019. 8k
[00:00:50.360 --> 00:00:55.960]   plus 5G. This week in Tech is brought to you by Atlassian. Atlassian software
[00:00:55.960 --> 00:01:00.200]   powers the full spectrum of collaboration between IT teams and the rest of your
[00:01:00.200 --> 00:01:06.200]   organization. Visit Atlassian.com/IT to see what IT can be by giving their products
[00:01:06.200 --> 00:01:12.440]   a try for free. And by Wasabi Hot Cloud Storage. From the founders of
[00:01:12.440 --> 00:01:15.560]   Carminei comes the cloud storage technology that's disrupting the
[00:01:15.560 --> 00:01:19.280]   industry. See for yourself with free unlimited storage for a month. Go to
[00:01:19.280 --> 00:01:25.840]   Wasabi.com, click free trial and use the offer code Twit. And by Stamps.com. Buy and
[00:01:25.840 --> 00:01:29.880]   print real US postage the instant you need it right from your desk. For our
[00:01:29.880 --> 00:01:36.080]   special offer go to Stamps.com, click the microphone and enter Twit. And by Simple
[00:01:36.080 --> 00:01:40.480]   Contacts. Simple Contacts is an easy and convenient way to renew your contact
[00:01:40.480 --> 00:01:44.680]   lens prescription or reorder your contacts from anywhere within minutes.
[00:01:44.680 --> 00:01:49.960]   Get $20 off your first order by visiting simplecontacts.com/twit and
[00:01:49.960 --> 00:01:56.600]   entering the promo code Twit at Checkout. It's time for Twit this week in Tech. The
[00:01:56.600 --> 00:01:59.200]   show where we get together with the best tech journalists in the world and
[00:01:59.200 --> 00:02:05.200]   discuss the latest tech news. Great to have Nate Langson on board for all the
[00:02:05.200 --> 00:02:10.800]   way from the UK where he is the tech editor at Bloomberg. Hey Nate. Hello
[00:02:10.800 --> 00:02:14.880]   Leo. Hello guys. It's nice to be back. Nate will be doing a drum solo a little
[00:02:14.880 --> 00:02:19.560]   later on in the show. Yeah, if you're very very lucky because it is very late and
[00:02:19.560 --> 00:02:23.840]   my wife is asleep. Well, those look like he drums. You could do you could do the
[00:02:23.840 --> 00:02:27.600]   e-drum thing patch it into a Skype and no one would know no one be the wiser.
[00:02:27.600 --> 00:02:32.600]   That is true. Yeah. Yeah, that would be fun. That's when the band goes off and
[00:02:32.600 --> 00:02:36.760]   drinks Jack Daniels for half an hour. That is generally what happens. Yeah,
[00:02:36.760 --> 00:02:42.840]   exactly. That's what's keeping my wife asleep right now. Also, you're
[00:02:42.840 --> 00:02:47.320]   Dylan Twini. He is, well, you know Dylan for years. He's been everywhere but right
[00:02:47.320 --> 00:02:51.240]   now had a communications at, that sounds bad when I say he's been everywhere. He's
[00:02:51.240 --> 00:02:56.880]   had a number of journalistic jobs over the years currently head of communications
[00:02:56.880 --> 00:03:01.480]   at Valley Mail, which is a way or Valle Mail, which is the way of validating
[00:03:01.480 --> 00:03:06.680]   outbound email, which companies need to use. Hi Dylan. Yeah. Hey, how are you
[00:03:06.680 --> 00:03:12.200]   doing? Do you miss sometimes, you know, working at the big tech publications, you
[00:03:12.200 --> 00:03:15.960]   kind of wish, gosh, I wish I could rip off an editorial here or something like
[00:03:15.960 --> 00:03:20.840]   that. You know, it is easier to get people to call me back. Yeah, of course.
[00:03:20.840 --> 00:03:24.480]   When you know, when you're a journalist, it was easier to get people to call me
[00:03:24.480 --> 00:03:29.120]   back and I got invited to more parties. So I miss those two things. Yeah, I've
[00:03:29.120 --> 00:03:35.040]   been doing this so long that I no longer get invited. So it is possible to
[00:03:35.040 --> 00:03:39.800]   overstay your welcome. Shall we put it that way? There we go. I wanted to switch
[00:03:39.800 --> 00:03:44.040]   lanes before that happened. Very smart. Formerly senior editor Wired, when
[00:03:44.040 --> 00:03:47.760]   that's, I think we're Devendra Hardawar knows him from right? Devendra? No,
[00:03:47.760 --> 00:03:52.680]   said venture beat. Venture beat. There. Okay. Awesome. Devendra's senior editor
[00:03:52.680 --> 00:03:58.280]   and gadget. He can hold a job. Audi. You've been there. How long have you been
[00:03:58.280 --> 00:04:02.640]   there? Oh, I think going on for years now. It's been a while. Yeah. That's in
[00:04:02.640 --> 00:04:07.480]   an internet years. That's like 400. Yeah, we've seen so many different types of
[00:04:07.480 --> 00:04:11.280]   phones. Screen sizes have exploded since then. It's great. Well, let me ask you.
[00:04:11.280 --> 00:04:18.280]   Because the Galaxy Fold comes out at the end of this week. I was thinking of
[00:04:18.280 --> 00:04:23.040]   running down to my T-Mobile store on Friday, plunking down a couple of big
[00:04:23.040 --> 00:04:29.520]   ones, a couple of thousand dollars and purchasing one until our friend Steve
[00:04:29.520 --> 00:04:34.800]   Kovecke said, "My phone broke after two days." Our friend, Dieter Bones, said, "Oh,
[00:04:34.800 --> 00:04:40.240]   there's a big bulge in the phone." My friend, Margaise Brownlee, said, "It's not
[00:04:40.240 --> 00:04:46.520]   working any." I think four of the early reviewers all had broken fold units.
[00:04:46.520 --> 00:04:50.640]   Joanna Stern, too, I think. That's right, Joanna. Monica, I'm in over at
[00:04:50.640 --> 00:04:56.480]   Bloomberg with us. Yeah. So it's five, six. I love it. That's a bad sign for a new
[00:04:56.480 --> 00:05:00.800]   phone. It's probably a really small sample group, too. So it's like, "Oh, what is that
[00:05:00.800 --> 00:05:06.480]   ratio to look like with consumers?" Like 100% of product reviewers. So it turns out
[00:05:06.480 --> 00:05:10.880]   that Steve Kovecke and Margaise Brownlee, at least those two, maybe others, removed
[00:05:10.880 --> 00:05:15.440]   what looked like a temporary plastic coating. I know my S10+ had one. It was a
[00:05:15.440 --> 00:05:20.640]   screen protector, but removed it as I did on my S10. And it turns out there was a
[00:05:20.640 --> 00:05:25.360]   warning in the box that said, "Whatever you do, do not remove this plastic film."
[00:05:25.360 --> 00:05:28.480]   I think they were saying there wasn't a warning. And then with future shipments,
[00:05:28.480 --> 00:05:31.520]   there was a warning. There will be a warning. So I'm unclear.
[00:05:31.520 --> 00:05:34.960]   That's not a good sign. People do not read warnings.
[00:05:34.960 --> 00:05:36.080]   Exactly.
[00:05:36.080 --> 00:05:40.320]   After years of pulling those useless plastic things off your new phone, that's going to be the first
[00:05:40.320 --> 00:05:45.760]   thing everybody does. Well, exactly. It shows how quickly they rushed this out the gate,
[00:05:45.760 --> 00:05:48.880]   basically. They had to get all this tech out there. They had to get a folding phone out
[00:05:48.880 --> 00:05:53.840]   there before all the other companies did. So instead of sealing that screen a little,
[00:05:53.840 --> 00:05:56.720]   you have a very visible layer right on top. It's crazy.
[00:05:56.720 --> 00:06:00.400]   And then Dieter Bonne at the Verge said, "Well,
[00:06:00.400 --> 00:06:07.680]   he did not remove his film, but he did have a bulge come up out of the hinge that broke the
[00:06:07.680 --> 00:06:16.000]   screen anyway." His review was entitled "Broken Dream." It turns out they put a little bit of putty
[00:06:16.000 --> 00:06:21.120]   underneath the phone to prop it up during a photo shoot. And I think maybe that got into the hinge.
[00:06:21.840 --> 00:06:25.120]   So it is clearly a fragile beast.
[00:06:25.120 --> 00:06:28.800]   But yeah, I assume a lot of things are going to get into that little bulge there.
[00:06:28.800 --> 00:06:31.280]   But yours is okay. I didn't gauge it.
[00:06:31.280 --> 00:06:36.320]   Yeah. We haven't had any problems yet. I mean, we're keeping an eye out for it,
[00:06:36.320 --> 00:06:40.160]   but it's going to be Chris Velasco doing the review. I believe our video's up already.
[00:06:40.160 --> 00:06:45.840]   And Sherlin Lo did the hands on. I played with a little... It's really cool, but that front screen
[00:06:45.840 --> 00:06:50.960]   is not good. That front screen feels like a joke, honestly. And it just seems like Samsung really,
[00:06:50.960 --> 00:06:53.440]   really had to rush this out there to get their folding phone.
[00:06:53.440 --> 00:06:58.960]   Oh, that's interesting. Because some of the early... And what I say early, I mean, in the first
[00:06:58.960 --> 00:07:05.920]   day, obviously, before the phone broke, early thoughts were that, "Hey, I get it. This is great."
[00:07:05.920 --> 00:07:10.800]   But you do have to make a sacrifice because that front screen is only what four inches,
[00:07:10.800 --> 00:07:11.520]   something like that.
[00:07:11.520 --> 00:07:16.720]   It's like 4.7 and it's really, really skinny. So it's kind of useless. Honestly,
[00:07:16.720 --> 00:07:21.600]   you could do some very basic lookups with it. But I always think about how would I use this phone
[00:07:21.600 --> 00:07:26.160]   on the subway or something or in a crowded way and really the only way to use the phone to its full
[00:07:26.160 --> 00:07:31.360]   potentials to open it up. And then it's a two-handed device. And it's a tablet. So is that really
[00:07:31.360 --> 00:07:33.760]   more convenient for a lot of people? I don't know.
[00:07:33.760 --> 00:07:35.760]   Shelton wrote, "It's fun to open and shut."
[00:07:35.760 --> 00:07:45.360]   Maybe don't do that too much, Sherlin. And she does say, "Satisfying despite the crease."
[00:07:45.360 --> 00:07:48.800]   The crease is another word I don't like to hear on a smart phone.
[00:07:48.800 --> 00:07:49.840]   Smart phone.
[00:07:49.840 --> 00:07:54.400]   And also the cameras up top, that is such an ugly thing to see.
[00:07:54.400 --> 00:08:00.320]   Oh, look at that screen. I see the problem right there. There's a Sherlin's picture of that screen.
[00:08:00.320 --> 00:08:02.000]   Yeah, the front screen.
[00:08:02.000 --> 00:08:05.600]   So, David, do you really think that people are going to be rushing?
[00:08:05.600 --> 00:08:10.880]   Do you have folding phones out? Are we going to see a horde of these?
[00:08:10.880 --> 00:08:15.600]   Well, we definitely saw a whole bunch. Didn't Huawei, they showed one off at Mobile World
[00:08:15.600 --> 00:08:16.240]   where they were suddenly--
[00:08:16.240 --> 00:08:17.680]   Huawei's will be available later this summer.
[00:08:17.680 --> 00:08:20.320]   So, like a host of them got announced.
[00:08:20.320 --> 00:08:21.200]   You could see, yes, there was another--
[00:08:21.200 --> 00:08:22.240]   Nobody, the royal.
[00:08:22.240 --> 00:08:24.320]   Yeah. Nobody cares about royal.
[00:08:24.320 --> 00:08:28.800]   But nobody complained that the royal broke after day two. Maybe nobody bought it.
[00:08:28.800 --> 00:08:32.080]   We broke the royal during the CES preview.
[00:08:32.080 --> 00:08:37.680]   Yeah. During the preview, that thing broke. Like it's a mechanical object.
[00:08:37.680 --> 00:08:42.080]   It's going to break more often than a solid phone. But yeah, these things are trouble.
[00:08:42.080 --> 00:08:45.840]   They're all trying to rush them out this year. And that seems like a bad, bad decision.
[00:08:45.840 --> 00:08:49.520]   Well, you just saved me $1990 bucks, I think.
[00:08:49.520 --> 00:08:54.800]   I was thinking, well, I really ought to go out and kind of validate the experience of
[00:08:54.800 --> 00:08:58.000]   all these early reviewers. We didn't get a review unit.
[00:08:58.000 --> 00:09:00.320]   Yeah. I mean, I'm sure you want to, Leo.
[00:09:00.320 --> 00:09:04.080]   Like, I think it's a cool thing for you to buy just to have that experience and see what it's like.
[00:09:04.080 --> 00:09:06.880]   Well, actually, now I think I'm going to hope it breaks right away.
[00:09:06.880 --> 00:09:08.560]   So I can return and get my money back.
[00:09:08.560 --> 00:09:13.280]   Honestly, buy it for 30 days. This is what I used to do before I could get review.
[00:09:13.280 --> 00:09:18.240]   And I buy has a great return policy. A lot of places to buy it. Try it.
[00:09:18.240 --> 00:09:19.760]   And then return if you don't like it.
[00:09:19.760 --> 00:09:27.680]   I can tell you the Huawei one. So I've used the Huawei one. And when I was using it,
[00:09:27.680 --> 00:09:32.880]   it was the most excited I was about a phone since the first iPhone.
[00:09:33.600 --> 00:09:38.880]   So I could not see a crease in that thing at all. I mean, I only got to use it for maybe 20,
[00:09:38.880 --> 00:09:43.040]   25 minutes, something like that. It was one of these behind closed doors,
[00:09:43.040 --> 00:09:48.800]   behind closed doors thing. The only restriction they put on me is that I wasn't allowed to personally
[00:09:48.800 --> 00:09:53.920]   fold it on camera, which is a really, really weird restriction to put on people.
[00:09:53.920 --> 00:09:56.960]   But you could fold it yourself just not on camera.
[00:09:56.960 --> 00:10:01.040]   You could fault, but I could fold it. And it is instrument. I've seen the Royal.
[00:10:01.040 --> 00:10:07.120]   I've seen the Galaxy Fold. And none of them look like this, like genuinely when it's folded out,
[00:10:07.120 --> 00:10:15.040]   the display, how thin it is, it's really weird. No one's bothered comparing it to a kindle for
[00:10:15.040 --> 00:10:20.720]   very good reasons. It's about 5 million times as expensive. But in terms of reading on this thing,
[00:10:20.720 --> 00:10:24.400]   it is properly nice. It is a beautiful, beautiful device.
[00:10:24.400 --> 00:10:25.360]   And the other side.
[00:10:25.360 --> 00:10:25.920]   And the other side.
[00:10:25.920 --> 00:10:30.160]   On the outside too, which I think is much more useful than a tiny, useless display on the outside.
[00:10:30.160 --> 00:10:31.840]   And the folding screen on the inside.
[00:10:31.840 --> 00:10:32.240]   Yeah.
[00:10:32.240 --> 00:10:37.760]   Yeah. So it's a trifold. The screen is on the outside. You open it out and it's the same screen.
[00:10:37.760 --> 00:10:40.400]   It just becomes larger. You see both wings.
[00:10:40.400 --> 00:10:44.000]   Yeah. It just becomes this really thin, 8-inch tablet.
[00:10:44.000 --> 00:10:50.560]   Yeah. It's gorgeous. And the screen, the main thing I wanted to find out with that thing was,
[00:10:50.560 --> 00:10:55.040]   can you see creases down the center of the screen? Because obviously on the Samsung,
[00:10:55.040 --> 00:10:59.360]   that's one of the things we've seen. And maybe this was a brand new straight out of the box unit.
[00:10:59.360 --> 00:11:03.520]   But I was, you know, I was bending it. I was looking at it in different lights. And you can't
[00:11:03.520 --> 00:11:08.400]   really see like there is a tiniest, tiniest hint. But it was very, very exciting. So if you're
[00:11:08.400 --> 00:11:13.600]   going to buy any of them, Leo, I would definitely go for that one for 30 days and then send it back.
[00:11:13.600 --> 00:11:15.760]   Nate, you just understand I'm buying them all.
[00:11:15.760 --> 00:11:22.080]   Okay. Well, that's perfect. But it really is. Yeah. At the end of the day, like anything that
[00:11:22.080 --> 00:11:26.160]   has moving parts, you know, we've tried to move away from moving parts and almost everything.
[00:11:26.160 --> 00:11:30.640]   It's a reason why the iPad was so successful. Well, one of the reasons they are so successful.
[00:11:30.640 --> 00:11:35.920]   They don't go on it. It has no, it has no moving parts. It has no fan. So I kind of think it's a
[00:11:35.920 --> 00:11:40.560]   step backwards in one way, but a step forward in a different one. Be interesting. Nate,
[00:11:40.560 --> 00:11:44.560]   Nate, I think you've convinced me that I want to wait for the Kindle version of whatever.
[00:11:44.560 --> 00:11:51.360]   So that I can read on an e-ink screen. That's a comfortable size. But for a phone, I'm not
[00:11:51.360 --> 00:11:56.080]   persuaded that I need that much screen or that much risk of the video.
[00:11:56.080 --> 00:12:00.800]   I mean, there was already, yeah, there was a Russian company that had a dual screen phone
[00:12:00.800 --> 00:12:04.960]   with an e-ink screen on the back and a color one on the front. I can't remember the name of it now,
[00:12:04.960 --> 00:12:12.160]   but they did bankrupt. As a matter of fact, I'm just reading about that. Just this week,
[00:12:12.160 --> 00:12:16.240]   they went out of business. Oh, really? Oh, well, that was the yada phone.
[00:12:16.240 --> 00:12:18.960]   Yada. Yeah. That's it. Yeah. That's it. Yeah.
[00:12:18.960 --> 00:12:22.880]   I think you're onto something, Dylan. I think if we could make an e-ink device,
[00:12:22.880 --> 00:12:26.480]   it could fold out like this. You could have something that feels like a paperback and then
[00:12:26.480 --> 00:12:31.040]   you fold it out. It's the size of a magazine or something. And that could be really cool for
[00:12:31.040 --> 00:12:36.000]   really niche audience. There it is. Seriously, I could just unroll it and be like a newspaper.
[00:12:36.000 --> 00:12:40.000]   Yeah. Well, I think that's kind of where this all comes from, is that sci-fi notion of,
[00:12:40.000 --> 00:12:45.360]   you've got a thing folded up in your pocket that you unfold. But despite the fact that we can currently
[00:12:46.400 --> 00:12:52.880]   roll up and unfold all led screens, there's lots of other issues about the electronics that are
[00:12:52.880 --> 00:12:57.040]   attached to it, the hinges, the screens themselves. I don't think we're any close.
[00:12:57.040 --> 00:13:01.360]   The glass, like there's not glass on these phones because they have to use plastic because you can't
[00:13:01.360 --> 00:13:08.320]   fold glass. Right. So, okay, they're too expensive. Clearly, I mean, these early versions were not
[00:13:08.320 --> 00:13:12.960]   intended for normal users. They were intended for a special, weird class of people that,
[00:13:13.840 --> 00:13:18.240]   for whom price is no object and having the latest thing that's clearly different than
[00:13:18.240 --> 00:13:22.640]   everything else is worth that extra price. But if it's going to break right away.
[00:13:22.640 --> 00:13:28.160]   You know, this generally reminds me of, do you remember when Windows Vista was announced and we
[00:13:28.160 --> 00:13:34.640]   got those weird laptops that had a little miniature screen on the outside of the device,
[00:13:34.640 --> 00:13:40.880]   where you could do a little bit of email checking on notifications and the ones that were
[00:13:40.880 --> 00:13:46.800]   around. And everyone sort of thought, like, what's the point? Like, why does this exist? And obviously,
[00:13:46.800 --> 00:13:51.440]   it went away and we moved in a completely different direction. And I kind of get the feeling that
[00:13:51.440 --> 00:13:56.960]   we'll move, we'll look back at these devices in a similar sort of way, like a nice experiment
[00:13:56.960 --> 00:14:02.720]   at the expense, literally, of the consumer. But maybe it helps us figure out, okay, we don't
[00:14:02.720 --> 00:14:07.040]   want to go down that road, cool, we'll go down this road. And maybe that's what the industry needs
[00:14:07.040 --> 00:14:12.240]   to do. Is the tech industry a particular offender here? I mean, I think every industry, I think
[00:14:12.240 --> 00:14:20.960]   the auto industry, try stuff that doesn't pay off too well and then moves on. But the tech industry
[00:14:20.960 --> 00:14:26.720]   seems particularly prone to just throw in spaghetti on the wall and hoping something sticks.
[00:14:26.720 --> 00:14:32.320]   Why is that pretty much? I mean, it's where we're addicts, right? We're innovation addicts.
[00:14:32.320 --> 00:14:35.200]   They know people will buy it. They know people will buy it.
[00:14:35.200 --> 00:14:37.920]   They know people will buy it. But also, I think you look at the gadget hounds,
[00:14:37.920 --> 00:14:41.680]   people who read and gadget and listen to the twin and everything, we're always chasing the
[00:14:41.680 --> 00:14:47.040]   next high, right? The iPhone changed the world. So many things changed the world. What is next?
[00:14:47.040 --> 00:14:52.080]   We're always searching for that. And I'm guilty of that too. I think I've reached a point where
[00:14:52.080 --> 00:14:56.240]   I'm like, I do like to take a step back and say, do we really need this? Should you buy this?
[00:14:56.240 --> 00:14:59.840]   Like this year, we're also going to see a ton of 5G phones. Nobody should buy those this year.
[00:14:59.840 --> 00:15:04.240]   Like, don't forget how bad the early LTE phones were. Just wait to see how those like that one.
[00:15:04.240 --> 00:15:06.720]   Samsung's already selling its 5G Galaxy S10.
[00:15:06.720 --> 00:15:10.480]   I mean, it's almost pointless because where are you going to use it?
[00:15:10.480 --> 00:15:11.920]   Where are you going to use it? It's pointless.
[00:15:11.920 --> 00:15:14.560]   I think there are places you could use it.
[00:15:14.560 --> 00:15:21.760]   I think to vendor, Scott, you totally put your finger on one piece, which is the consumer side.
[00:15:21.760 --> 00:15:27.520]   Like we are totally obsessed about the latest new gadgets. There's also a product development
[00:15:27.520 --> 00:15:31.760]   side, which is that everyone in tech is completely bought into this agile development
[00:15:32.480 --> 00:15:37.680]   approach more in software than in hardware. But I think it affects both sides. And the idea of that
[00:15:37.680 --> 00:15:42.160]   is like, let's just ship it. Let's do two weeks worth of development, ship it, get it out the door.
[00:15:42.160 --> 00:15:45.600]   And then if something is broken, we'll fix it in the next two weeks sprint.
[00:15:45.600 --> 00:15:51.920]   And I think that works really effectively for some things, maybe not so much for folding OLED
[00:15:51.920 --> 00:15:52.720]   screens.
[00:15:52.720 --> 00:15:56.160]   For hardware, it's bad. You don't want to do that for hardware. For software, you can just iterate,
[00:15:56.160 --> 00:16:00.960]   like, send it up to no problem. Hardware is a problem to do that with. I think Google's face that
[00:16:00.960 --> 00:16:04.240]   issue over time too, because they're such a software-focused company.
[00:16:04.240 --> 00:16:04.800]   Yeah.
[00:16:04.800 --> 00:16:06.720]   Whenever they produce hardware, it's been kind of problematic.
[00:16:06.720 --> 00:16:11.120]   And Amazon, I think, has had a lot of issues as well along the same lines.
[00:16:11.120 --> 00:16:11.920]   Fireball.
[00:16:11.920 --> 00:16:16.240]   And we've seen it for decades. We've seen it for decades. Normally, companies do this kind of
[00:16:16.240 --> 00:16:21.040]   stuff. They have their R&D labs. They innovate this stuff, and they pay it in stuff. And a lot
[00:16:21.040 --> 00:16:24.320]   of the time, it never comes out. They build one, they do a prototype, and they say, yeah,
[00:16:24.320 --> 00:16:27.520]   this isn't going to sell. We're not going to ship this. So they check it to one side and move on.
[00:16:28.400 --> 00:16:33.680]   But there's a cache that now comes with being seen as an innovator, and everyone wants to be
[00:16:33.680 --> 00:16:39.200]   that innovator. Samsung desperately wants to be seen. It needs to be seen as that innovator.
[00:16:39.200 --> 00:16:44.880]   So it's bringing these things out. And it's essentially trying these out on the public
[00:16:44.880 --> 00:16:48.640]   without regard for whether they're actually going to be successful, or whether they're going to
[00:16:48.640 --> 00:16:53.680]   support them in five years' time. And that's just a change in the way I think these companies
[00:16:53.680 --> 00:16:59.680]   are operating. We are the R&D guinea pigs, and it's at the cost of our wallets.
[00:16:59.680 --> 00:17:02.480]   Yeah. And I mean, they're coming off of a line of exploding phones.
[00:17:02.480 --> 00:17:05.120]   Right? They push things out. That's why I feel bad for Samsung.
[00:17:05.120 --> 00:17:07.440]   We're floating. It's like, so I think yes, 10 is an amazing thing.
[00:17:07.440 --> 00:17:10.320]   They're floating. I think yes, 10 is an amazing phone.
[00:17:10.320 --> 00:17:18.240]   But then Samsung stumbles, and it's, I feel bad for them. Is Apple better because they do this
[00:17:18.240 --> 00:17:24.480]   stuff behind closed doors. I mean, it's not a better quality control. There's no doubt their
[00:17:24.480 --> 00:17:28.960]   quality control is better. Yeah. But you got to wonder, do they have some magical folding phone
[00:17:28.960 --> 00:17:32.960]   in the lab or they're just not, I mean, declining. Yeah, I don't know. I mean,
[00:17:32.960 --> 00:17:37.280]   Apple's never really done like proper market research. Like, I think that's one of the
[00:17:37.280 --> 00:17:42.240]   differences. Like, Apple comes out with something and says, you're going to need this for this
[00:17:42.240 --> 00:17:47.280]   reason and you'll create the need for it. Whereas a lot of other companies, they do their market
[00:17:47.280 --> 00:17:51.200]   research. They go out, they say, okay, well, people want this. People are bored of form factors.
[00:17:51.200 --> 00:17:57.120]   They're bored of six inch black slabs of glass and things. So what can we do? What can we do that
[00:17:57.120 --> 00:18:01.520]   physically in a shop window or on a website makes them excited. And someone said, what if they
[00:18:01.520 --> 00:18:04.880]   fold in half? And someone yet went, great idea. Let's do that.
[00:18:04.880 --> 00:18:10.960]   Well, sometimes, yeah, I'm sorry, Nate. Sometimes it works and sometimes it doesn't. I mean,
[00:18:11.920 --> 00:18:18.560]   nobody really wanted giant phones when Samsung came out with a Galaxy Note line. But that
[00:18:18.560 --> 00:18:23.440]   kicked off a huge trend. So, you know, I think they throw a lot of spaghetti against the wall
[00:18:23.440 --> 00:18:28.080]   and sometimes it sticks and sometimes it doesn't. Apple doesn't have a patent for a folding phone.
[00:18:28.080 --> 00:18:33.680]   You have to think they've got one in the lab somewhere that they're going,
[00:18:33.680 --> 00:18:40.720]   but it's different. There's a difference that, you know, they patent tons of stuff that never
[00:18:40.720 --> 00:18:45.600]   comes out. You know, they patent stuff. The fact that there's an entire blog dedicated only to
[00:18:45.600 --> 00:18:50.720]   like posting Apple patents, like they post this stuff just in case somebody else develops it and
[00:18:50.720 --> 00:18:55.920]   they don't want to lose their royalties or whatever. But with the Galaxy Note, it's a really good
[00:18:55.920 --> 00:19:02.800]   example, Dylan, because I think that was something that really did take off in the Asian market.
[00:19:02.800 --> 00:19:08.560]   That was a big deal. People really liked those huge devices. But over here in the US and in Europe,
[00:19:08.560 --> 00:19:12.240]   we were like, dude, why would you want a phone that's twice the size of other phones?
[00:19:12.240 --> 00:19:14.960]   And we just took a little while to catch up.
[00:19:14.960 --> 00:19:18.640]   And also the hard work got better too. Like the big screen phones got slimmer,
[00:19:18.640 --> 00:19:22.960]   the bezels got slimmer. So they became more holdable and usable. So everything kind of
[00:19:22.960 --> 00:19:27.360]   congealed, I guess, into one spot. But Nate, you're onto something there. Like,
[00:19:27.360 --> 00:19:31.280]   with Apple, their design is always very top-down, right? You're going to like this. You're going
[00:19:31.280 --> 00:19:36.000]   to like a MacBook Pro with no usable ports. You're going to like a keyboard with no travel,
[00:19:36.000 --> 00:19:39.920]   deal with it. And I don't think quality control has been better for them, honestly.
[00:19:39.920 --> 00:19:43.600]   I think they've been faltering too. Look at those MacBook keyboards. But it's a very different
[00:19:43.600 --> 00:19:46.000]   philosophy than like Samsung or Google or something.
[00:19:46.000 --> 00:19:53.040]   There's a, I kind of ties into something I read this week. It was actually a blog post
[00:19:53.040 --> 00:19:58.240]   from a few years ago. A speech by Claude Shannon. It was never published. Claude Shannon, of course,
[00:19:58.240 --> 00:20:02.800]   one of the great theorists in computer science is if you don't know his name,
[00:20:03.360 --> 00:20:08.000]   you know, read the Wikipedia article, but he gave this speech in 1952 at Bell Labs,
[00:20:08.000 --> 00:20:14.160]   was not widely published about creative thinking. And he said a small percentage of the population
[00:20:14.160 --> 00:20:20.480]   produces the greatest proportion of the important ideas. And he talks a lot about this. It's funny,
[00:20:20.480 --> 00:20:26.720]   it's just coincidental. But a lot about this idea of innovation. And one of the reasons he says
[00:20:26.720 --> 00:20:33.600]   it happens, particularly in the tech sector, is because people are dissatisfied. Things could be
[00:20:33.600 --> 00:20:37.120]   done better. I think there's a neater way to do things. I think it could be improved a little.
[00:20:37.120 --> 00:20:42.080]   There's a continual irritation when things don't look quite right. And I think that
[00:20:42.080 --> 00:20:47.360]   dissatisfaction he wrote is present in present days is a key driving force in good. Now he called
[00:20:47.360 --> 00:20:53.440]   it scientists, but of course it was quickly technologists. But I also think that there is a
[00:20:54.320 --> 00:20:59.920]   intense pressure from the stock market and investors and the market in general to come up with the
[00:20:59.920 --> 00:21:06.640]   next new thing. And even just pride, what's the next new thing? And unfortunately, we're the guinea
[00:21:06.640 --> 00:21:13.280]   pigs for that. Jeff Bezos has a phrase that he used, which really irritates me, but I think gets
[00:21:13.280 --> 00:21:19.840]   to the same point that Claude Shannon made, which is Bezos talks about divine discontent and how
[00:21:20.480 --> 00:21:26.400]   the customer is never satisfied for very long with anything that you provide them.
[00:21:26.400 --> 00:21:33.680]   So for Bezos, he interprets that as a need for the company, for any tech company, really to
[00:21:33.680 --> 00:21:39.280]   continually innovate and continually be moving forward. Because last year's totally amazing
[00:21:39.280 --> 00:21:43.760]   thing is something that everybody has now. And you're like, yeah, could be better.
[00:21:43.760 --> 00:21:48.560]   We wondered with the exploding note, was it the note seven, the note eight, with the exploding note?
[00:21:48.560 --> 00:21:54.480]   If that would be a permanent mark on Samsung, and they seem to have completely dodged that bullet,
[00:21:54.480 --> 00:22:07.120]   will the failing folding phone be the next black mark on Samsung and will it have a lasting impact?
[00:22:07.120 --> 00:22:11.280]   People are incredibly forgiving of tech companies. I mean, look at what happened with Facebook and
[00:22:11.280 --> 00:22:16.720]   the Cambridge Analytica stuff. They're stock plummeted. They were calls for resignations.
[00:22:16.720 --> 00:22:23.200]   There was a giant, a new movement in terms of privacy awareness globally. And you looked at
[00:22:23.200 --> 00:22:27.360]   it today, a year later, and it's using them as a higher than ever. It's stock is higher than ever.
[00:22:27.360 --> 00:22:36.480]   It's just like, nobody cares. In tech, in tech, it's quite specific to tech. People are extremely
[00:22:36.480 --> 00:22:44.320]   forgiving in the technology world. And broadly speaking, they are. It's not just the geeks,
[00:22:44.320 --> 00:22:48.160]   like us who will talk about this stuff. And actually, the real world is very different.
[00:22:48.160 --> 00:22:53.040]   It's the opposite way around. And I think people just forgive tech companies because they just
[00:22:53.040 --> 00:22:56.720]   want the ladies and graces. I mean, Ford survived the exploding pinto.
[00:22:56.720 --> 00:23:01.920]   That's a lot worse than an exploding football. I think so.
[00:23:01.920 --> 00:23:06.800]   You know, I see. Look at Boeing today, like they're going through a lot.
[00:23:06.800 --> 00:23:12.160]   Interesting. And Southwest just announced it wants to buy a whole bunch of new 737 maxes.
[00:23:12.720 --> 00:23:15.120]   Yeah. I mean, there is.
[00:23:15.120 --> 00:23:17.440]   Figure that out. Figure that out.
[00:23:17.440 --> 00:23:19.520]   Are you going to screw it up twice? Are you going to screw it up twice?
[00:23:19.520 --> 00:23:23.600]   Yes, of course you would. You fly a 737 max.
[00:23:23.600 --> 00:23:28.560]   There was also that story about how lax they're basically there are testing it.
[00:23:28.560 --> 00:23:32.480]   Yeah, for the dreamliner, New York Times big expose this Sunday,
[00:23:32.480 --> 00:23:41.760]   from people working inside the factory at Boeing, how lax the processes are for building the dream
[00:23:41.760 --> 00:23:45.840]   liner. That's a little word. That's actually a good illustration of the software,
[00:23:45.840 --> 00:23:50.160]   agile software development thing, which is, I don't know if they're using an agile methodology
[00:23:50.160 --> 00:23:55.760]   in Boeing or not, but the reason that they started having stalling and out of control
[00:23:55.760 --> 00:23:59.920]   problems is they pushed a software update, which is designed to make the plane more efficient,
[00:23:59.920 --> 00:24:01.600]   move fast and break things.
[00:24:01.600 --> 00:24:04.640]   Don't train people. But not on airplanes.
[00:24:04.640 --> 00:24:11.520]   Please. But you notice Facebook doesn't say that. That used to be their motto.
[00:24:11.520 --> 00:24:16.880]   They don't say that much anymore. But I think it really is, at least tacitly,
[00:24:16.880 --> 00:24:19.200]   the model of motto of Silicon Valley. Move fast.
[00:24:19.200 --> 00:24:22.560]   Facebook moved fast and broke democracy. So now they can't say it anymore.
[00:24:22.560 --> 00:24:22.800]   Right.
[00:24:22.800 --> 00:24:30.400]   One of the nice details in Fred Vogelstein's story about Facebook and
[00:24:30.400 --> 00:24:33.920]   and Wired this week was, he said a story. Wow.
[00:24:33.920 --> 00:24:38.320]   Oh my God. It has so many great details, but there's one detail, which is he sort of throws
[00:24:38.320 --> 00:24:41.920]   outside of these little tidbits that he picks up during reporting.
[00:24:41.920 --> 00:24:45.840]   And one of them was, well, they're not really saying move fast and break things anymore.
[00:24:45.840 --> 00:24:51.040]   But if you go to their headquarters, the Wi-Fi password is still move fast.
[00:24:51.040 --> 00:24:57.920]   It's like, it's not totally gone there. The attitude is not totally over.
[00:24:57.920 --> 00:25:05.840]   This is an amazing story, which recounts a lot of the stuff we already knew. I mean,
[00:25:07.360 --> 00:25:12.160]   apparently, Nicholas Thompson and Fred Vogelstein have been working on it for a long time.
[00:25:12.160 --> 00:25:17.440]   Jeff Jarvis said he ran into, I think it was Nicholas at Davos two years or last year.
[00:25:17.440 --> 00:25:24.560]   And he was writing the story then. And in fact, it starts in Davos and the special Facebook,
[00:25:24.560 --> 00:25:31.840]   you know, sweet or hotel room they had in Davos, where they were planning a temporary headquarters,
[00:25:33.200 --> 00:25:38.800]   where they were planning the it was more like a bunker. One that saw a succession of tense meetings
[00:25:38.800 --> 00:25:45.520]   with the same tycoons, ministers and journalists who had agreed with George Soros when he said earlier,
[00:25:45.520 --> 00:25:52.480]   the owners of the, well, I guess basically the Facebook's days are numbered.
[00:25:52.480 --> 00:25:57.040]   The owners of the platform giants consider themselves the masters of the universe, Soros said.
[00:25:57.040 --> 00:26:02.240]   But in fact, they're slaves to preserving their dominant position. I would agree.
[00:26:02.240 --> 00:26:08.320]   Davos is a good place to announce that their days are numbered. That was a year ago, more than a year ago.
[00:26:08.320 --> 00:26:13.360]   Let's talk, we'll talk about Facebook because there's a lot to say about Facebook.
[00:26:13.360 --> 00:26:19.040]   This is a good, this is a good example of a company that, as you pointed out earlier,
[00:26:19.040 --> 00:26:26.560]   can survive almost anything. Blackmarks everywhere. We'll do that in just a little bit.
[00:26:26.560 --> 00:26:31.040]   But first, hey, what a great panel. The vendor hardware here from Engadget,
[00:26:31.040 --> 00:26:35.360]   his senior editor there, a Dylan Twaney. Great to have you back now.
[00:26:35.360 --> 00:26:41.600]   Valameo, many years, adventure beaten, wired in many other places. And of course, all the way
[00:26:41.600 --> 00:26:45.680]   from the UK where it is in the middle of the night, Nate Langson, tech editor at Bloomberg.
[00:26:45.680 --> 00:26:49.760]   But I really appreciate your staying up late with us. Thank you. You don't have Game of Thrones
[00:26:49.760 --> 00:26:54.640]   mania in the UK, do you? Now I'm one of the seven people that doesn't actually like it.
[00:26:54.640 --> 00:26:59.280]   Oh my God. It's also delayed there too. So I feel bad for UK Game of Thrones fans.
[00:27:00.000 --> 00:27:06.320]   Yeah, the same night. Yeah, I don't know. I think we, I think they did air it on the same,
[00:27:06.320 --> 00:27:11.200]   at the same time, but it was like 3 a.m. last week or something. I don't know. There's some
[00:27:11.200 --> 00:27:17.840]   deal, but I don't know. My wife is a lot like Facebook to me. Yeah, you hate it, but you can't
[00:27:17.840 --> 00:27:22.000]   quit it. Like after the red wedding, and I know spoilers here, but after the red wedding,
[00:27:22.000 --> 00:27:27.520]   I said, I never watching this show again. That is the worst, the worst thing I've ever seen.
[00:27:28.640 --> 00:27:34.240]   What a way to end a season. I'm devastated and I'm never watching this show again. Of course,
[00:27:34.240 --> 00:27:40.480]   the minute it comes back in the next season, I'm glued to the TV. It's just like Facebook. You
[00:27:40.480 --> 00:27:45.360]   can't leave it. I think they got off to a pretty good start though last Sunday. So we'll get this
[00:27:45.360 --> 00:27:51.360]   over before Devindra has to rush off. Exactly. Because I have a feeling you are watching it.
[00:27:51.360 --> 00:27:53.600]   Yeah, you'll just see a cartoon cloud of me right away.
[00:27:56.240 --> 00:28:00.800]   We've just got a whole other podcast about Game of Thrones. I know. Yeah, all sorts of stuff.
[00:28:00.800 --> 00:28:03.760]   Yeah. And movies. I'm wearing a Game of Thrones shirt right now. I got this at South
[00:28:03.760 --> 00:28:08.400]   By for the blood donation thing. So it's the Iron Throne in like blood splatter form. It's fun.
[00:28:08.400 --> 00:28:12.480]   Does it actually say Game of Thrones or anything? Or are you just supposed to recognize it?
[00:28:12.480 --> 00:28:16.880]   It says Game of Thrones on the back, but I think it's more of like a South By insider thing.
[00:28:16.880 --> 00:28:20.560]   Oh, you don't need blood to Game of Thrones. You got this shirt. I recognize that. That's the
[00:28:21.200 --> 00:28:27.120]   Iron Throne in blood. Yeah. It's one Iron Throne. It's one Iron Throne. So I was having this
[00:28:27.120 --> 00:28:32.800]   conversation earlier this evening here that shouldn't the name of the show be Games of Throne?
[00:28:32.800 --> 00:28:42.400]   If it's one Iron Throne is the prize, but they're little earth thrones. They're smaller drones.
[00:28:42.400 --> 00:28:46.720]   Yeah. Because you don't beat that. Yeah. You could be king of the north, but that doesn't mean
[00:28:46.720 --> 00:28:51.600]   you get to sit on the by the way, the bigger question is why would you want to sit on a chair
[00:28:51.600 --> 00:28:58.640]   made out of knives and swords? Honestly, does not look that comfortable. Kind of a bad,
[00:28:58.640 --> 00:29:02.400]   bad sign too. Yeah. Yeah. It's just not a little fit.
[00:29:02.400 --> 00:29:08.880]   Oh, there were a lot of memes that came out of the first episode last week. And again,
[00:29:08.880 --> 00:29:15.200]   no spoilers. But my favorite meme was the no elephants meme. And you know what I'm talking about.
[00:29:15.760 --> 00:29:23.440]   It was it was the funniest thing ever. And somebody said, I think this might be true,
[00:29:23.440 --> 00:29:30.880]   that this was a little jab by the writers at HBO that wouldn't give them the money to do the CGI
[00:29:30.880 --> 00:29:37.040]   elephants. So and I don't think it's a spoil to say, sir. He said, where's the elephants?
[00:29:37.920 --> 00:29:44.160]   There are no elephants, my lady. What? There's an HBO wouldn't pay for them, my lady.
[00:29:44.160 --> 00:29:50.560]   Are sure that's not a spoiler. Is that a spoiler? I'm bad with spoilers. That's
[00:29:50.560 --> 00:29:54.800]   a good spoiler. No, I think that's okay. They're going to be I'm going to get email from people
[00:29:54.800 --> 00:30:01.760]   said, what? There are no elephants. Maybe they're going to have elephants later. This was a tease.
[00:30:02.960 --> 00:30:09.200]   Our show today brought to you by Atlassian. If you're an IT, I you know, we were just talking
[00:30:09.200 --> 00:30:14.160]   about agile, right? Everybody knows Jira, right? Like if you're doing agile, you're using Jira.
[00:30:14.160 --> 00:30:20.240]   We use Jira not just for software development art. IT team uses it to keep track of projects.
[00:30:20.240 --> 00:30:25.840]   Who's doing what? What stage the project at? One of the things I really like about Atlassian's
[00:30:25.840 --> 00:30:30.480]   tools, and there are a whole bunch of them, is it's all about, well, not just getting the job done.
[00:30:30.480 --> 00:30:36.240]   Of course, that's key, but communication as well. In a modern enterprise in a cloud-based world,
[00:30:36.240 --> 00:30:41.200]   IT teams are at the center of everything. And not only do they have to plan and execute,
[00:30:41.200 --> 00:30:45.360]   they have to do it faster than ever. They have to do it right. They have to be open, agile.
[00:30:45.360 --> 00:30:50.400]   They have to coordinate between operations and software development teams. Expectations are high.
[00:30:50.400 --> 00:30:57.200]   The stakes are high, and IT is smack dab in the center. And you don't get to fail. You got to
[00:30:57.200 --> 00:31:04.560]   get it done. So of course, the best IT teams use Atlassian. Not only Jira, but we also use
[00:31:04.560 --> 00:31:08.560]   confluence, because it's very important when you get something done to document what you did so
[00:31:08.560 --> 00:31:14.080]   that people understand that people who come after you can say, "Oh, this is how it works."
[00:31:14.080 --> 00:31:19.520]   So we use confluence like crazy, and the whole idea that you can use these tools like Jira and
[00:31:19.520 --> 00:31:24.960]   confluence, Bitbucket, if you've got a source code database, and never leave, not have to use some
[00:31:24.960 --> 00:31:31.840]   third tool to get the job done really encourages communication. And I think that's so important.
[00:31:31.840 --> 00:31:38.480]   IT tools, not just for developers, Atlassian offers an affordable, reliable suite of tools for
[00:31:38.480 --> 00:31:44.800]   all kinds of teams, all sizes from DevOps to Agile to IT apps to ops to ITSM, whatever
[00:31:44.800 --> 00:31:51.760]   is next. Atlassian provides a technology backbone to help modern IT organizations plan, service,
[00:31:51.760 --> 00:31:56.880]   and support exactly the kind of change that propels business. So I mentioned Jira,
[00:31:56.880 --> 00:32:01.680]   confluence, Bitbucket, but there's lots more. There's for people who have managed ops,
[00:32:01.680 --> 00:32:06.080]   there's ops genie status page that'll help teams better detect incidents, coordinate response
[00:32:06.080 --> 00:32:11.200]   efforts, resolve issues faster. And once again, this thing that for me at least is really important,
[00:32:11.200 --> 00:32:16.640]   keep customers and stakeholders and the boss updated. Communication is so important.
[00:32:17.280 --> 00:32:22.240]   Your team can choose the right tools for your current framework, but trust that as you grow
[00:32:22.240 --> 00:32:27.200]   as your needs change Atlassian has something for you. They will grow with you. And of course,
[00:32:27.200 --> 00:32:30.960]   everything integrates seamlessly. Your team doesn't have to bounce from platform to platform.
[00:32:30.960 --> 00:32:35.760]   Like all of Atlassian's products, the tools for your IT team are easy and free to try.
[00:32:35.760 --> 00:32:42.240]   Just head to Atlassian.com/IT and find out which Atlassian offering is right for your team. We're
[00:32:42.240 --> 00:32:47.200]   really proud here at Twit to say we're in Atlassian house. You should be to try Atlassian to
[00:32:47.200 --> 00:32:55.600]   say to see what it can be Atlassian.com/IT. Let's talk about, oh, by the way, we thank Atlassian
[00:32:55.600 --> 00:33:04.160]   for their support. Let's talk about Facebook because it's just an endless litany. I do absolutely
[00:33:04.160 --> 00:33:10.720]   recommend Fred's great article on Wired 15 months of fresh hell inside of Facebook.
[00:33:10.720 --> 00:33:16.560]   We're there. I don't Dylan tell me. Were there things that weren't widely known in here or is it
[00:33:16.560 --> 00:33:23.600]   just really putting it all together? I don't think there's a lot that was really widely
[00:33:23.600 --> 00:33:32.880]   on a bit of it. There's some inside baseball about the movements of various executives that I
[00:33:32.880 --> 00:33:37.200]   hadn't heard before or hadn't heard all spelled out. But mostly it's just weaving the whole story
[00:33:37.760 --> 00:33:45.280]   and painting the picture of just how crazy and I guess I would have to say in-nept
[00:33:45.280 --> 00:33:52.000]   Facebook's responses were over the course of 2018 to the various scandals that embroiled it.
[00:33:52.000 --> 00:33:56.800]   Seems to me even anybody just paying the slightest attention to it would quickly come up
[00:33:56.800 --> 00:34:02.560]   with the idea that Facebook would just do whatever it wanted to, get caught,
[00:34:03.360 --> 00:34:08.400]   apologize, say it wouldn't do it again, and then the whole cycle would repeat.
[00:34:08.400 --> 00:34:15.200]   Sometimes they didn't even apologize. Sometimes they just spent like five days sitting there going
[00:34:15.200 --> 00:34:19.520]   like, what are we going to say? What's our response? And then they'd come out and they'd
[00:34:19.520 --> 00:34:23.760]   solve a different problem. The problem was with data leakage and they'd say, okay, we're going
[00:34:23.760 --> 00:34:30.400]   to fix this problem with untrustworthy news. And their solution is some completely half-assed
[00:34:30.400 --> 00:34:34.320]   thing that shows they don't really understand the news business and they didn't really talk to
[00:34:34.320 --> 00:34:37.600]   me. Anybody in news and then it doesn't work for a year and then they pull the plug on that.
[00:34:37.600 --> 00:34:46.400]   It seems very, at least the picture that Fred paints lines up with what I've seen from other
[00:34:46.400 --> 00:34:51.280]   coverage, which is just that they don't really have their arms around the problems that they're
[00:34:51.280 --> 00:34:56.320]   causing in any serious way. What they add though also is the behind-the-scenes
[00:34:57.440 --> 00:35:01.760]   kind of machinations going on. They talk a lot about why Systrom left,
[00:35:01.760 --> 00:35:08.800]   why Chris Cox left, and it confirms everything, those guys said at the time,
[00:35:08.800 --> 00:35:13.200]   but also everything we suspected, I guess. It's kind of like the Mueller report.
[00:35:13.200 --> 00:35:16.480]   It's like, you know all this, but now you're seeing it in print, right?
[00:35:16.480 --> 00:35:22.560]   It just confirms what we know. Also, best Facebook move dropped terrible news in an old blog post
[00:35:22.560 --> 00:35:25.200]   during the Mueller report release. Bravo.
[00:35:25.200 --> 00:35:28.800]   Oh man, you're talking about the Instagram password debacle.
[00:35:28.800 --> 00:35:35.680]   So first Facebook says, first it stored thousands of passwords,
[00:35:35.680 --> 00:35:42.080]   Instagram passwords, unencrypted on its servers. By the way, this is a week after we found out
[00:35:42.080 --> 00:35:50.320]   that Facebook passwords were also stored on their servers. Then, timed perfectly on the same
[00:35:50.320 --> 00:35:56.800]   morning that the Mueller report came out, Facebook said, "Oh, it's not thousands. It's millions of
[00:35:56.800 --> 00:36:02.400]   Instagram user passwords." And they did this by revising the existing blog post.
[00:36:02.400 --> 00:36:06.880]   Just going to change thousands to millions. No one will know.
[00:36:06.880 --> 00:36:08.720]   Is that some zero? It's not a five.
[00:36:08.720 --> 00:36:15.440]   No, I have to say, it's not the worst news in the world. It wasn't publicly published. It was
[00:36:15.440 --> 00:36:19.600]   internal, but it meant that anybody who worked, not anybody, but many thousands of people who
[00:36:19.600 --> 00:36:25.680]   worked in Facebook had access to these passwords. Facebook said, "As far as we can tell, nobody
[00:36:25.680 --> 00:36:29.680]   used them in any malicious way, but they could."
[00:36:29.680 --> 00:36:33.440]   They could. Probably not the best sign for one of the biggest companies in the world.
[00:36:33.440 --> 00:36:41.440]   That's all. It's bad operations, it's bad practices. You would expect them
[00:36:43.120 --> 00:36:50.240]   to know better. I think it could be a function of them just being too big, too. Who knows what
[00:36:50.240 --> 00:36:53.440]   all these contractors and other people who have asked to the state are doing,
[00:36:53.440 --> 00:36:56.880]   maybe they're too big to even manage everybody effectively.
[00:36:56.880 --> 00:37:02.800]   Well, that's a good point. My sense is that for years, nothing mattered at Facebook other
[00:37:02.800 --> 00:37:08.240]   than growing user numbers and growing engagement. They would basically do anything to increase
[00:37:08.240 --> 00:37:14.240]   engagement and get people spending more time on the site. I think the result is there may be
[00:37:14.240 --> 00:37:22.320]   that Zerk and Cheryl and other people at the top are actually honestly wanting to control things
[00:37:22.320 --> 00:37:26.000]   now, but there's so much momentum and so much culture behind this at Facebook now.
[00:37:26.000 --> 00:37:33.680]   Everything has been designed to facilitate engagement without any kind of breaks on that
[00:37:33.680 --> 00:37:37.760]   or any kind of controls or any kind of meaningful vetting built in from the start.
[00:37:37.760 --> 00:37:42.960]   So what they're trying to do now is slow down the runaway train or install a break system on the
[00:37:42.960 --> 00:37:47.600]   train or safety controls on the train while it's already going 180 miles an hour down the track.
[00:37:47.600 --> 00:37:55.920]   To me, it feels very consistent with the way Facebook has been run for years, that they just
[00:37:55.920 --> 00:38:02.800]   don't care about anything except growth. It's going to take a long time for them to change that,
[00:38:02.800 --> 00:38:12.240]   even if they really want to. Definitely. I guess the question and maybe there's no answer is,
[00:38:12.240 --> 00:38:23.840]   what is going on in Sandberg and Zuckerberg's heads? Is it as you said innocent Dylan?
[00:38:23.840 --> 00:38:28.800]   It's too hard when you're this big and moving this fast to get it right every time.
[00:38:29.920 --> 00:38:35.520]   Oh, I didn't say innocent. Well, that's one possibility. I mean that they're not
[00:38:35.520 --> 00:38:40.080]   malicious. And then the completely other end of the scale is that they are
[00:38:40.080 --> 00:38:46.880]   Machiavellianly malicious actors who are just covering up as fast as they can.
[00:38:46.880 --> 00:38:53.840]   If you had some monopoly fat cat billionaire saying, "Oh, I don't care about anything except
[00:38:53.840 --> 00:38:58.880]   making money. I'm just going to prioritize making money." You'd be like, "I have sort of
[00:38:59.440 --> 00:39:04.080]   some moral issues with that." There might be some things you'd want to be concerned about besides
[00:39:04.080 --> 00:39:09.360]   making money. I think you could fairly call that malicious or at least...
[00:39:09.360 --> 00:39:16.320]   How about amoral? Not amoral, but amoral. Okay. All right. So Facebook is amoral.
[00:39:16.320 --> 00:39:18.000]   So they could be chaotic evil.
[00:39:18.000 --> 00:39:28.960]   Or chaotic neutral. I don't think they're good. Yeah, that's very nerdy. Let's roll this excited
[00:39:28.960 --> 00:39:35.200]   dice. I bet that's what Zuckerberg does. Just like with all of these things. Like, how do we
[00:39:35.200 --> 00:39:41.840]   respond? Roll the dice. Let's just go. If part of the reason this is important is
[00:39:41.840 --> 00:39:49.760]   going forward. Well, Ken, is it reasonable to say there's a path forward where Facebook will be a
[00:39:49.760 --> 00:39:55.600]   responsible actor? Or it sounds to me like that might not even be doable. I don't think we can
[00:39:55.600 --> 00:39:59.440]   trust these companies at this point. They've proven time and time again that they don't know how to
[00:39:59.440 --> 00:40:05.680]   basically rule themselves. I've said for a long time that it seems like the way we've kind of
[00:40:05.680 --> 00:40:12.240]   controlled or at least stopped bad actors in the past is through some sort of government
[00:40:12.240 --> 00:40:17.040]   regulation. We did that with Ma Bell. It's happened before. Yeah. And that helped prevent
[00:40:17.040 --> 00:40:21.200]   monopolies. But yeah, the timing is as bad as it can get because... Oh, yeah.
[00:40:21.200 --> 00:40:25.840]   Do you really want the... Is this the time the government should get step in? Not this government,
[00:40:25.840 --> 00:40:31.280]   but who... Yeah, some government. Not our government. Not our government, but also like we need,
[00:40:31.280 --> 00:40:35.360]   we need legislators to actually know what's going on. Let's get parliament to do it. They seem to be
[00:40:35.360 --> 00:40:42.880]   quite well organized these days. Yeah, that's definitely doing everything that everyone wants.
[00:40:42.880 --> 00:40:50.880]   They tried to get Zuck to appear, right? They've tried to get Facebook to answer for what happened
[00:40:50.880 --> 00:40:58.320]   during the Brexit election. And he just blows them off. He does. And I've met with the guy,
[00:40:58.320 --> 00:41:03.360]   the lawmaker, his name's Damian Collins. I've met with him before. He's the guy that chairs these
[00:41:03.360 --> 00:41:11.600]   committee meetings where they've done some very deliberately sort of PRE stunts. For example,
[00:41:11.600 --> 00:41:17.280]   when they demanded Zuckerberg appeared and he wouldn't, what they did is they put a seat out for him,
[00:41:17.280 --> 00:41:22.480]   they put in Zuckerberg nameplate, and then they published the photo that basically just looked like
[00:41:22.480 --> 00:41:27.760]   he was absent, that he just hadn't shown up. And of course, everyone used the picture. And
[00:41:27.760 --> 00:41:35.040]   they do try. I mean, the thing that they're trying at the moment to do is to prevent companies like
[00:41:35.040 --> 00:41:43.840]   Snapchat, from having these streaks features, because they're very concerned that technology is
[00:41:43.840 --> 00:41:49.440]   addictive in such a way that long term, it'll be extremely detrimental for children. So they
[00:41:49.440 --> 00:41:55.120]   don't want Snapchat having streaks. They don't want Facebook having the like button. And that's
[00:41:55.120 --> 00:42:02.080]   where a lot of their attention is right now. That's all I mean, micromanaging product design.
[00:42:02.080 --> 00:42:08.560]   I'm not sure that's an effective approach, but I don't know. We owe parliament a little debt of
[00:42:08.560 --> 00:42:15.120]   gratitude because last year, parliament was investigating Facebook and obtained a
[00:42:15.120 --> 00:42:25.120]   kind of scary means obtained a trove of documents, documents that have been given in the discovery
[00:42:25.120 --> 00:42:35.360]   in another lawsuit by a application called Pakenys that was designed to
[00:42:36.880 --> 00:42:45.680]   show up bikini pictures of friends and friends of friends on Facebook. And Facebook shut down
[00:42:45.680 --> 00:42:50.640]   Pakenys access to the friends of friends information, everybody else's as well. And so they sued.
[00:42:50.640 --> 00:42:59.600]   And in the suit, there was a, of course, discovery, 4000 page trove of documents, including emails,
[00:43:00.400 --> 00:43:06.480]   internal company documents, then the head of Pakenys was staying in a hotel in England
[00:43:06.480 --> 00:43:12.160]   and got tricked into hand. He says tricked into handing them over to parliament. Now they've been
[00:43:12.160 --> 00:43:17.920]   leaked and NBC News had a big story. And I don't know about their interpretation. It's hard to tell
[00:43:17.920 --> 00:43:23.520]   because they don't quote these documents directly. They mostly just publish their interpretation of
[00:43:23.520 --> 00:43:29.520]   it. The headline Mark Zuckerberg leveraged Facebook user data to fight rivals and help friends
[00:43:30.000 --> 00:43:34.880]   leaked documents show Facebook's responses. Well, those documents are cherry picked for a lawsuit
[00:43:34.880 --> 00:43:41.760]   in a different matter. Nevertheless, at least some of the quotes are pretty shocking Facebook,
[00:43:41.760 --> 00:43:49.840]   for instance, according to NBC, decided to give plenty of data about users to Amazon because
[00:43:49.840 --> 00:43:56.000]   Amazon had decided to use Facebook to market its fire phone. But then when there was a messaging app
[00:43:56.000 --> 00:44:01.920]   that Facebook thought it was competitive, they cut off access to data user data to the messaging
[00:44:01.920 --> 00:44:12.080]   application. I don't know. Did you guys read this stuff? And do you think that NBC's interpretation
[00:44:12.080 --> 00:44:18.080]   is fair? Yeah, I mean, I think a lot of thought goes into this. And I know that Olivia Solon,
[00:44:18.080 --> 00:44:23.840]   who's one of the two reports on the byline, she's very thorough. I've worked with her for many years.
[00:44:23.840 --> 00:44:29.360]   She's a good friend of mine. And I do sort of trust that when she comes out with something like this,
[00:44:29.360 --> 00:44:34.080]   she's gone through this with a tooth comb. So I do think that the interpretation is pretty good.
[00:44:34.080 --> 00:44:41.440]   And you are talking about 4000 pages of documents. I saw when they previously released,
[00:44:41.440 --> 00:44:49.520]   I say they, it was parliament over 400 pages. Yeah. And they published a lot of those
[00:44:49.520 --> 00:44:55.120]   with redactions. And I had a copy of a lot of those and was going through it. And on the one hand,
[00:44:55.120 --> 00:45:00.000]   you can see why Facebook would argue that things have been cherry-picked, because clearly they
[00:45:00.000 --> 00:45:04.880]   they have, you know, you have to pick certain documents out in certain sentences out. But at the
[00:45:04.880 --> 00:45:11.040]   same time, there are still email chains within these documents where you can see who said what
[00:45:11.040 --> 00:45:16.000]   and who replied to whom, and then what was said then, and like, you can't make that up.
[00:45:16.000 --> 00:45:20.800]   Like they're not, they're not publishing one email and then redacting four. And then another one,
[00:45:20.800 --> 00:45:26.480]   like you can see that conversation take place. And a lot of those conversations had Sheryl Sandberg
[00:45:26.480 --> 00:45:30.640]   as a sender, some of them had Zuckerberg as a sender. And it's pretty clear. And you know,
[00:45:30.640 --> 00:45:35.040]   the killer example for me and the one that I used as an example in my story for Bloomberg back
[00:45:35.040 --> 00:45:41.440]   when this came out was about cutting off data to Vine, because Twitter saw Vine as this big
[00:45:41.440 --> 00:45:48.560]   competitor. And they didn't want Vine essentially being able to piggyback off Facebook's data and
[00:45:48.560 --> 00:45:53.760]   Facebook's user base in order to grow what they saw as a rival service. And it's well worth looking
[00:45:53.760 --> 00:45:57.440]   at, because you can, even if you are taking it out of context, like the words in the email are
[00:45:57.440 --> 00:46:00.640]   right there, you know, and Zuckerberg knew what was going on for those things.
[00:46:00.640 --> 00:46:11.440]   And maybe even more damning than that. Olivia writes that often, she writes, "However, among
[00:46:11.440 --> 00:46:16.720]   the documents, there's very little evidence that privacy was a major concern of Facebook. And the
[00:46:16.720 --> 00:46:22.000]   issue was rarely discussed in the thousands of pages of emails and meeting summaries. But where
[00:46:22.000 --> 00:46:28.160]   it is mentioned, it's often in the context of how Facebook can use it as a public relations
[00:46:28.160 --> 00:46:33.360]   strategy to soften the blow of sweeping changes to developers' access to user data.
[00:46:33.360 --> 00:46:39.280]   When they did think about privacy, they thought about it only as a way to market Facebook to the
[00:46:39.280 --> 00:46:47.120]   public." We saw it with the other way around as well. In the previous batch that was included in
[00:46:47.120 --> 00:46:56.080]   these 4,000 pages, there was discussion around an update to the Android app, Facebook on Android.
[00:46:56.080 --> 00:47:01.120]   And there was discussion in those emails about that a PR strategy was prepared in advance,
[00:47:01.120 --> 00:47:06.960]   because they knew that they were essentially slipping this out into the public, and they needed
[00:47:06.960 --> 00:47:11.600]   to have a response ready just in case a counter blew up. So they're aware of these things.
[00:47:11.600 --> 00:47:16.880]   They've got their PR strategy in case it goes wrong, and they're essentially weighing everything
[00:47:16.880 --> 00:47:20.880]   up versus reward when it comes to testing these things. Yeah, absolutely right.
[00:47:20.880 --> 00:47:27.120]   Yeah, good for the world, but not good for us was one of the phrases Zuckerberg wrote.
[00:47:27.120 --> 00:47:34.080]   Ooh, ooh. Yeah, that's nothing. Yeah, it's totally innocent. Nothing to hide.
[00:47:34.080 --> 00:47:37.600]   That's a very James Bond villain kind of thing to say.
[00:47:37.600 --> 00:47:42.560]   Mr. Bond, that would be very good for the world. But not so for me.
[00:47:42.560 --> 00:47:49.680]   There was also the TED Talk this week that you guys should watch to buy the Guardian journalist.
[00:47:49.680 --> 00:47:54.880]   I forget her name. It was a very compelling talk about basically everything Facebook knew about how
[00:47:54.880 --> 00:48:00.720]   they basically help facilitate Brexit and everything. This is all reporting that's happened, but seeing
[00:48:00.720 --> 00:48:06.400]   it all condensed to 15 minutes is kind of a mind blowing up. Yeah, who is it? Carol Kudwallader.
[00:48:06.400 --> 00:48:09.440]   Carol Kudwallader, yeah. Yeah, it's a really good talk.
[00:48:09.440 --> 00:48:14.240]   And then there's the New York Times article. It's not just Facebook. There's the New York Times
[00:48:14.240 --> 00:48:26.160]   article about apps. It was a study of 36 apps. In the study, they downloaded apps that specifically
[00:48:26.160 --> 00:48:33.040]   were had keywords with depression and smoking cessation. Some of these apps were designed to
[00:48:33.040 --> 00:48:37.200]   kind of support people who are going through emotional difficulty. Some of them designed
[00:48:38.240 --> 00:48:45.360]   for people who were trying to quit smoking. Of the 36 apps downloaded, 33 of them
[00:48:45.360 --> 00:48:53.920]   sent private mental health information out to third parties, including in some cases food diaries,
[00:48:53.920 --> 00:49:01.200]   health diaries, self reports about substance abuse associated with user names. This was published
[00:49:01.200 --> 00:49:08.080]   Friday in the Journal of American Medical Association Network Open. So these apps, and we've seen this
[00:49:08.080 --> 00:49:13.920]   again. This isn't the first time in the Wall Street Journal also reported that flow, the menstrual
[00:49:13.920 --> 00:49:19.760]   app was telling third parties when women were on their periods. Not just third parties, but
[00:49:19.760 --> 00:49:27.280]   they're employers, their bosses. They also explain the rise of all the like pregnancy tracking apps
[00:49:27.280 --> 00:49:31.760]   and everything too. Like there is the big business in collecting this data and selling it and really
[00:49:31.760 --> 00:49:36.640]   not telling people what's happening. I feel like consumers have to be more aware of the fact that
[00:49:36.640 --> 00:49:40.560]   they can't really trust all these random apps that they're playing with, even if they look nice
[00:49:40.560 --> 00:49:46.480]   and slick on their iPhones or something. Half the apps did not disclose third party data sharing.
[00:49:46.480 --> 00:49:52.480]   Nine apps had no privacy policy at all. Okay, well, don't download those. Five apps did,
[00:49:52.480 --> 00:49:58.080]   but didn't, but lied. They didn't say the data would be shared this way. Three apps actively said
[00:49:58.080 --> 00:50:07.520]   this kind of data sharing would not happen. Those last three, according to the Verge stood out to
[00:50:07.520 --> 00:50:12.960]   Stephen Chan, a physician, the Veterans Affairs Palo Alto healthcare system, who says they're
[00:50:12.960 --> 00:50:18.240]   basically lying. They're lying. They're saying, oh, no, we don't disclose this. A lot of times they
[00:50:18.240 --> 00:50:25.760]   say it in kind of anodyne language like under the third party sharing, we share with third parties to
[00:50:25.760 --> 00:50:34.640]   make our app work better. Yes. In other words, so we get paid more so we can continue to make
[00:50:34.640 --> 00:50:42.480]   this app better or whatever. It's not just Facebook, I guess, is the point.
[00:50:42.480 --> 00:50:48.160]   This particular thing has been happening for quite a long time. I remember reporting on
[00:50:49.680 --> 00:50:59.120]   Facebook, sorry, PayPal's user agreement, which is like it's 50,000 words long or was at one point.
[00:50:59.120 --> 00:51:06.080]   It's longer than some novels. The fact is you can defend in court because they were, look, we had
[00:51:06.080 --> 00:51:11.920]   this here in this document that you agreed to. The fact is that that's technically okay, even
[00:51:11.920 --> 00:51:16.880]   though the document is 50,000 words long in written and complex legal ease that no real person can
[00:51:16.880 --> 00:51:23.040]   understand. There's a need for a change there. That's going down the route of GDPR, which I think
[00:51:23.040 --> 00:51:28.400]   everyone's bored with at this point. These terms and conditions are very problematic, I think.
[00:51:28.400 --> 00:51:36.000]   It's boring, I guess, in our circles. GDPR, we're asking, what do we need? How do we stop these
[00:51:36.000 --> 00:51:42.240]   companies? Really, that's it. It's not perfect. It's a start towards really focusing on privacy
[00:51:42.240 --> 00:51:48.400]   and data and what it means to users promoting easily understandable user agreements and really
[00:51:48.400 --> 00:51:52.320]   making sure people are aware of what these companies are doing. We definitely need something like that
[00:51:52.320 --> 00:51:56.560]   in America. We're getting some side benefit to it because now everybody has to update for that.
[00:51:56.560 --> 00:52:01.200]   Yeah, but now it's not just personal privacy. Now it's a little bit more of a three-alarm fire,
[00:52:01.200 --> 00:52:07.680]   as Carol Cadwalter points out, because this data is also being used to sub-born democracy.
[00:52:07.680 --> 00:52:13.920]   It's being used by the Russians in the United States and in the UK to change election results.
[00:52:13.920 --> 00:52:23.920]   That seems to me pretty serious matter at this point. Yeah, she called it the largest election
[00:52:23.920 --> 00:52:30.560]   fraud in the UK in 100 years. It's hard for people to wrap their heads. It's not even for me to wrap
[00:52:30.560 --> 00:52:36.240]   my heads around it because it isn't like you broke into voting machines and changed the tally.
[00:52:36.960 --> 00:52:40.880]   It's much more subtle than that. But as we learned from the Mueller report,
[00:52:40.880 --> 00:52:46.640]   the Russians were organizing rallies in the United States that appeared to be patriotic
[00:52:46.640 --> 00:52:52.400]   Americans and in fact were Russian actors. You know, using even Craigslist for that,
[00:52:52.400 --> 00:53:00.480]   it's insane. Yeah, and so I wonder, I don't know, I talk to people, non-tech people,
[00:53:01.520 --> 00:53:08.560]   with different political views in mind, obviously, I'm a raging liberal. And they don't seem to be
[00:53:08.560 --> 00:53:13.840]   too convinced to buy any of this. Yeah, they're not worried. I've definitely talked to people who
[00:53:13.840 --> 00:53:19.680]   aren't so concerned by it and maybe slightly more on the libertarian side of things. I think
[00:53:19.680 --> 00:53:24.080]   often they just tell me, "Oh, it's sour grapes. You lost all boo-hoo." In some way,
[00:53:24.080 --> 00:53:28.880]   they're probably benefiting from all these broken rules and from companies basically doing whatever
[00:53:28.880 --> 00:53:33.520]   they want with our data. So yeah, as long as it's helping them, they're not going to argue against it.
[00:53:33.520 --> 00:53:37.680]   Is it not the case that at least one thing you could say from the Mueller report is,
[00:53:37.680 --> 00:53:44.320]   it's very clear how much Russian involvement there was, how active it was, how aggressive it was
[00:53:44.320 --> 00:53:49.600]   about throwing the election to Donald Trump. I mean, not that he, I'm not even saying he wouldn't
[00:53:49.600 --> 00:53:55.360]   have won otherwise, but it was very clear they were working hard. Yeah, that much is clear. And I
[00:53:55.360 --> 00:53:59.200]   think as much as we could tell from the report, the Trump administration was aware. The only thing
[00:53:59.200 --> 00:54:03.360]   they could prove is that they were working together, which seems like, "Okay, all right, sure."
[00:54:03.360 --> 00:54:09.200]   Aware or not, you know. Yeah. I think we can leave that part out. That's more of a
[00:54:09.200 --> 00:54:14.400]   that's a political discussion. But this is all a political discussion, right?
[00:54:14.400 --> 00:54:19.360]   But it's also a technical discussion. Yeah, it's the intersection. But it's also germane because
[00:54:20.080 --> 00:54:25.520]   if the people in power don't want to acknowledge it, then there's no way you can fight it in future
[00:54:25.520 --> 00:54:32.560]   elections. What is it like in the UK? Is it generally understood that the Russians wanted Brexit?
[00:54:32.560 --> 00:54:43.120]   No, it's pretty well understood in the broad sort of public consensus that it was the politicians
[00:54:43.120 --> 00:54:46.240]   that were doing a lot of money. Yeah, you had lovely people like Nigel Farage.
[00:54:47.040 --> 00:54:49.360]   Yes, he's a lovely gentleman. I respect him dearly.
[00:54:49.360 --> 00:54:58.160]   We had, for example, the one that everyone gets is we had this giant red bus, this double deck
[00:54:58.160 --> 00:55:04.960]   of bus that said, "We should be sending the £350 million a week that we're sending to Brussels to
[00:55:04.960 --> 00:55:10.720]   Europe. We should be sending that to our National Health Service." And everyone knew at the time
[00:55:10.720 --> 00:55:16.640]   that that was a ridiculous claim to make. And after what's... It was a lie. It was not true.
[00:55:16.880 --> 00:55:21.280]   And it doesn't account for what you get in return for money that is sent over.
[00:55:21.280 --> 00:55:26.960]   So anyway, that's the thing that people are really angry about. And I think that overshadows
[00:55:26.960 --> 00:55:32.480]   the sort of accusations of Russian meddling, at least in the sort of broadest senses.
[00:55:32.480 --> 00:55:37.760]   And there's no evidence that the big red bus was Russian organized.
[00:55:37.760 --> 00:55:43.840]   No, the big red bus. I actually tracked it down. And I found the company who leased it.
[00:55:43.840 --> 00:55:50.320]   And I'm trying to remember now what it was. But I think it was leased out and they painted it.
[00:55:50.320 --> 00:55:54.720]   And it was after the fact was then released to a company promoting
[00:55:54.720 --> 00:56:00.880]   investment in the UK or investment in Europe. I would need to look up the story, but I definitely
[00:56:00.880 --> 00:56:07.280]   wrote a piece. I thought it was Nigel Farage's claim. 50 million pounds a week we sent to the EU,
[00:56:07.280 --> 00:56:11.680]   which we will no longer send to the EU. Can you guarantee that's going to go to the NHS?
[00:56:12.400 --> 00:56:14.480]   No, I can't. And I would never have made that claim.
[00:56:14.480 --> 00:56:16.640]   70 million people have voted for Lee.
[00:56:16.640 --> 00:56:20.320]   I mean, just one of the many things wrong with that process.
[00:56:20.320 --> 00:56:26.080]   So I guess in a way, and you could probably say this too, about the US presidential election
[00:56:26.080 --> 00:56:32.400]   of 2016, there were many things going on. And I think that's further problem. There is so much
[00:56:32.400 --> 00:56:36.640]   going on. It's kind of hard to say, well, this one thing is bad and Facebook is bad and the
[00:56:36.640 --> 00:56:41.120]   Russians are bad. But it's kind of like all of the things we have to be worried about. We have to
[00:56:41.120 --> 00:56:44.240]   confront and we have to figure out the broader solution for a lot of that.
[00:56:44.240 --> 00:56:48.320]   You could see the benefit to Russia. Can we talk about the technology used to count the votes
[00:56:48.320 --> 00:56:53.680]   in America? Well, that's a mess too. But Dylan, there's no evidence that there
[00:56:53.680 --> 00:56:57.760]   were there was election fraud in that regard. Was there?
[00:56:57.760 --> 00:57:01.760]   Well, you know why there's no evidence because those voting machines are not.
[00:57:01.760 --> 00:57:05.360]   No paper trail. You wouldn't know even if that happened.
[00:57:06.000 --> 00:57:11.920]   Also, you don't need the evidence if you're gerrymandering districts and you're excluding
[00:57:11.920 --> 00:57:16.880]   people from voting and you're accepting people with false, you don't need to even worry about
[00:57:16.880 --> 00:57:21.040]   that part if the basic tenets of how people are getting facts is broken.
[00:57:21.040 --> 00:57:26.960]   I guess in that regard, you could say, well, Russian influences moot because there were so
[00:57:26.960 --> 00:57:34.400]   many other influences. Yet, I think everybody would agree we would prefer that Russia not way in
[00:57:35.040 --> 00:57:42.800]   on our process and it is manifestly illegal for them to do so. So why don't we try to prevent
[00:57:42.800 --> 00:57:51.440]   that from happening in 2020? That seems like a non partisan point of view.
[00:57:51.440 --> 00:57:55.600]   You think Leo, but what's not going to be on? I want to know what side they're going to be on
[00:57:55.600 --> 00:58:00.160]   before I decide if I decide. Well, maybe the Russians this time because Donald didn't work out
[00:58:00.160 --> 00:58:05.680]   as well as they thought. Maybe they'll say, I don't know, you know, that perfectly for them.
[00:58:05.680 --> 00:58:09.520]   He's exactly what they want. That Pete Buttigieg, he might be good for us too.
[00:58:09.520 --> 00:58:15.040]   Let's make him win this time. Yeah, but speaking of chaos, that's what you don't want. You don't
[00:58:15.040 --> 00:58:20.720]   want Putin sitting in the Kremlin saying, who should win in 2020? Let me think. That's what you don't want.
[00:58:20.720 --> 00:58:26.160]   It's more like from a lot of the reporting and reading we've seen is like they wanted chaos.
[00:58:26.160 --> 00:58:29.760]   They tried many, many different things to introduce that and they got it. So,
[00:58:29.760 --> 00:58:34.400]   you know, therefore, Trump was perfect. But you definitely blame Silicon Valley for all the
[00:58:34.400 --> 00:58:39.360]   for chaos too. For sure. Yeah. Good Lord. I mean,
[00:58:39.360 --> 00:58:48.480]   yeah, I try not to get political on this show because we have viewers of every political affiliation
[00:58:48.480 --> 00:58:54.800]   and I don't want to or smudge anybody for what they think and how they voted. It's not that.
[00:58:55.440 --> 00:59:03.680]   It's just that we don't want companies like Facebook to provide an active avenue for malefactors.
[00:59:03.680 --> 00:59:11.280]   Of course, in the Ukraine, they've now elected a comedian, which seems like the best solution
[00:59:11.280 --> 00:59:18.000]   the problem in general. Wow. I mean, they're truth tellers, right? Usually. Yeah, you know what?
[00:59:18.000 --> 00:59:22.640]   Nobody's more honest than a comedian. It's funny because it's true. But you know what?
[00:59:22.640 --> 00:59:27.360]   There's a guy in Britain called Boris Johnson and a lot of people talk about him being
[00:59:27.360 --> 00:59:35.040]   sort of next in line for the sort of the premier position in government here. And he's a former
[00:59:35.040 --> 00:59:40.240]   journalist. Yeah. He used to be a journalist. He was a mayor of London for a while. Everyone
[00:59:40.240 --> 00:59:44.400]   kind of when he was the mayor of London, everyone kind of joked about him. And he's one of these
[00:59:44.400 --> 00:59:48.400]   guys that said, you know, he's funny as long as he hasn't got any real power. And now this is
[00:59:48.400 --> 00:59:52.560]   very real conversation about him potentially being in charge and everyone sort of having that
[00:59:52.560 --> 00:59:56.080]   moment scratching their heads thinking like, Oh, God, is this really going to happen? And
[00:59:56.080 --> 01:00:01.840]   yeah, sometimes you'd have to laugh. I think you could say it would be safe to say that the
[01:00:01.840 --> 01:00:10.240]   Russians like blondes with wild hairdos. That's one way of putting it. Yeah. Maybe not their
[01:00:10.240 --> 01:00:15.040]   natural hair colors. I don't know. Like there's a lot going on. Maybe that's all it is. You know,
[01:00:15.040 --> 01:00:20.960]   Putin has a thing for blondes. That's all. It's not malicious. It's not politics.
[01:00:20.960 --> 01:00:25.040]   It's not policies. He just likes a good comb over. Nothing wrong with that.
[01:00:25.040 --> 01:00:36.400]   You got to laugh, right? We'll continue on with with more tech news. We're going to talk about
[01:00:36.400 --> 01:00:43.440]   Qualcomm Apple. That's a big story that broke. And then Intel kind of waited at the end. That
[01:00:43.440 --> 01:00:51.280]   was kind of funny. Amazon and Google seem to be patching things up or are they? And well,
[01:00:51.280 --> 01:00:56.800]   there's a lot more to get to. But first a word from our sponsor, Mike Good friends,
[01:00:56.800 --> 01:01:01.760]   David friend who was the CEO and founder of carbonite and his buddy Jeff Flowers,
[01:01:01.760 --> 01:01:06.800]   their technology guy, when they found a carbonite, they came up with a really brilliant process.
[01:01:07.760 --> 01:01:14.160]   A unique process actually patented it to lay data on disks, not sector by sector as is done
[01:01:14.160 --> 01:01:19.760]   traditionally with all your disks, but sequentially. It turns out this was so much more efficient that
[01:01:19.760 --> 01:01:24.720]   they were able to create storage. And this was for carbonite that was cheaper and faster.
[01:01:24.720 --> 01:01:29.920]   Then they had a brilliant idea. They said, we should start a new company, a cloud storage
[01:01:29.920 --> 01:01:36.160]   company that takes advantage of this stuff. And wasabi was born. Good name to wasabi is hot cloud
[01:01:36.720 --> 01:01:42.720]   storage data storage moving to the cloud. Of course, the topic everybody is interested in.
[01:01:42.720 --> 01:01:47.360]   The ability to store efficiently and affordably data in the cloud is critical for businesses.
[01:01:47.360 --> 01:01:52.080]   Companies who want to put data in the cloud have many concerns among them.
[01:01:52.080 --> 01:01:58.640]   How secure will it be? How safe? How fast? How affordable wasabi has an answer that you're really
[01:01:58.640 --> 01:02:03.440]   going to like? Now, I know it's a new name to you. And people think Google Amazon Microsoft,
[01:02:03.440 --> 01:02:10.160]   but I want you to add a fourth name wasabi because wasabi storage is 100% S3 compatible,
[01:02:10.160 --> 01:02:19.760]   but 600% faster and 80% less than S3. One of the reasons it's more affordable, no egress charges,
[01:02:19.760 --> 01:02:25.280]   none at all. So you can plan because you don't have to pay to get your data back.
[01:02:25.280 --> 01:02:31.680]   No charges for API requests. And wasabi is something that is super cool. They call it immutable data.
[01:02:31.680 --> 01:02:37.920]   This is an answer to companies that have data in the cloud that gets corrupted or damaged or destroyed
[01:02:37.920 --> 01:02:44.480]   by ransomware or just, you know, goofball employees, you can designate data immutable. You could say
[01:02:44.480 --> 01:02:52.880]   this data cannot be changed. And it'll be safe up there in the cloud on wasabi wasabi is secure.
[01:02:52.880 --> 01:02:57.760]   In most cases, more secure, even than your local storage is HIPAA compliant, FINRA compliant,
[01:02:57.760 --> 01:03:04.080]   CJIS compliant, it's more affordable. It's more efficient. In fact, they have this wasabi ball,
[01:03:04.080 --> 01:03:10.160]   which I love. Basically, it's a hard drive. They send you, you can put petabytes of data on it,
[01:03:10.160 --> 01:03:14.160]   migrate it right up to wasabi, you send it back to them. And with just one tier of service and
[01:03:14.160 --> 01:03:18.640]   free unlimited egress, you're planning and budgeting gets a lot easier. So here's what you got to do,
[01:03:18.640 --> 01:03:24.160]   add the name wasabi to your list, show the boss, talk about the benefits. And I think the boss is
[01:03:24.160 --> 01:03:27.200]   going to do the smart thing. They're going to say, Hey, you know, this wasabi is pretty good. We
[01:03:27.200 --> 01:03:33.600]   should try it out. Good news. You can right now. If you go to wasabi.com, click the free trial link.
[01:03:33.600 --> 01:03:38.080]   If you use Twit as the offer code, you'll get unlimited storage at wasabi.com for a month.
[01:03:38.080 --> 01:03:41.920]   So you can really bang on it. You can upload a ton of stuff. And I think you'll see it's the best
[01:03:41.920 --> 01:03:46.880]   wasabi.com. If it's time to move to the cloud, do it right. Thank you wasabi for your support. I
[01:03:46.880 --> 01:03:49.920]   appreciate it. And when you use that offer code to it, you're supporting us. So we appreciate it.
[01:03:49.920 --> 01:03:58.080]   When you do that, ransomware, what was I just saw? Mondeles, the food company, the candy bar company,
[01:03:58.080 --> 01:04:02.880]   ransomware hit them $100 million loss. They couldn't
[01:04:02.880 --> 01:04:11.280]   move inventory for three weeks. I'm writing a piece for business week as we speak about this,
[01:04:11.280 --> 01:04:16.480]   that I think is coming out later this week around that. And the problem with cyber insurance
[01:04:16.480 --> 01:04:20.240]   and public companies not paying out. Well, that's the other thing. It's
[01:04:20.240 --> 01:04:25.200]   deemed by some insurers as an act of war. So it's not insurable.
[01:04:25.200 --> 01:04:31.440]   Because the Russians originated that ransomware. That means it's an act of war.
[01:04:31.440 --> 01:04:38.240]   I think it's not in most cases. It's just some hacker in Bulgaria who wants to make some money.
[01:04:38.240 --> 01:04:42.320]   But often, nation state hacking, there's a lot of it. Maybe it is.
[01:04:43.840 --> 01:04:52.000]   The weather channel down for 90 minutes turns out that was also ransomware. But the difference,
[01:04:52.000 --> 01:04:57.200]   the big difference is they had backups. And maybe they're not quite as big in operation. So it took
[01:04:57.200 --> 01:05:02.880]   IT about 90 minutes to get their systems back up. Actually, that's really fast work if you think
[01:05:02.880 --> 01:05:08.480]   about it. Our local public radio station Leo KQED was they weren't off the air, but they
[01:05:08.480 --> 01:05:15.360]   lost pretty much their entire computer network due to ransomware a year and a half ago. And it
[01:05:15.360 --> 01:05:25.040]   took a month to rebuild it. They were doing stories with, they were printing things out through USB
[01:05:25.040 --> 01:05:32.320]   cables on an onwired printer. The phone system didn't work. So they were completely hammered by
[01:05:32.320 --> 01:05:37.680]   ransomware. And that, I really hate it when a nonprofit gets hit like that. That's tragic.
[01:05:37.680 --> 01:05:43.760]   The cyber insurance thing is interesting because I think, Nate, I'm looking forward to your story
[01:05:43.760 --> 01:05:52.000]   because I think that what insurance covers and does not cover is going to be increasingly
[01:05:52.000 --> 01:05:57.600]   important for big companies. And what they, what the insurance companies are in a very powerful
[01:05:57.600 --> 01:06:03.840]   position to be able to say, Oh, you need to do XYZ in your, you know, in your setup in order to
[01:06:03.840 --> 01:06:10.080]   to be sufficiently protected that we will, we will cover you if in the event that you do get hacked.
[01:06:10.080 --> 01:06:17.440]   So it, I mean, it's, it's an area that I don't know a whole lot about yet. And yet I think it's
[01:06:17.440 --> 01:06:25.920]   becoming increasingly important. So the insurance companies, it seems to me this, this is not a brand
[01:06:25.920 --> 01:06:30.400]   new thing that this happened before. But do they tell people ahead of time? Oh, by the way,
[01:06:30.400 --> 01:06:34.560]   we're going to deem ransomware an act of war and we're not going to protect you.
[01:06:34.560 --> 01:06:39.840]   Not, not specifically, no, I mean, a lot of the problem is that some of the wording in these
[01:06:39.840 --> 01:06:45.920]   documents are, you know, they've been around for a long time. So the act of war clause has been
[01:06:45.920 --> 01:06:50.800]   in there for a long time. Yeah, that's more like if a tank rolls over your building or a bomb goes
[01:06:50.800 --> 01:06:57.040]   off, right? It's not cyber warfare. And this is what this is what some of the lawyers for
[01:06:57.040 --> 01:07:01.920]   Mandalays has been saying. And I was going through the court documents. I think they filed, I don't
[01:07:01.920 --> 01:07:06.800]   remember where they filed them now. I want to say Illinois, I think it might be. But anyway,
[01:07:06.800 --> 01:07:11.280]   these documents basically said, look, it says act of war, but what is an act of war, you know,
[01:07:11.280 --> 01:07:18.480]   historically, and this has been traditional ballistics, you know, it's basically if it's not nukes and
[01:07:18.480 --> 01:07:24.800]   warheads, then it's not an act of war. And NATO, there was a guy from NATO that said that
[01:07:24.800 --> 01:07:32.320]   that a ransomware attack could be used to trigger one of the articles in the NATO, you know,
[01:07:32.320 --> 01:07:37.440]   documents that basically says this is something that we would rally behind to protect one of the
[01:07:37.440 --> 01:07:42.640]   member states of NATO, i.e., it's an act of war, i.e., ransomware, would be considered an act of
[01:07:42.640 --> 01:07:49.120]   war. So it's really, it's very, very messy. It's very interesting. And it's taken quite a lot of
[01:07:49.120 --> 01:07:54.080]   reading to get my head around it too. But yeah, it's going to happen.
[01:07:54.080 --> 01:07:59.120]   Are any of these ransomware attacks, I think Petra, was Petra a nation state? No.
[01:07:59.120 --> 01:08:08.320]   Petra, it was facilitated by an NSA technology, but it was not written by a nation state.
[01:08:09.120 --> 01:08:12.320]   I thought the assumption was not Petra is what you're talking about, right?
[01:08:12.320 --> 01:08:14.640]   We're not Petra. We're not Petra.
[01:08:14.640 --> 01:08:24.000]   Petra and WannaCry, yeah. And some of them were using NSA technology. I forget which one it was,
[01:08:24.000 --> 01:08:29.520]   but there was one that hit some power plants, I think, in one of the Eastern European countries.
[01:08:29.520 --> 01:08:35.840]   I'm not sure which one at the top of my head. And WannaCry, a lot of people pegged to North Korea,
[01:08:35.840 --> 01:08:42.320]   like the US concluded it was North Korea that had sort of pushed that out. And I know the UK
[01:08:42.320 --> 01:08:45.280]   government as well blamed North Korea officially for that. Yeah.
[01:08:45.280 --> 01:08:51.360]   Yeah. Evidence is mounting. And this comes from an article from a couple of years ago
[01:08:51.360 --> 01:08:58.240]   that not Petra is not just overly aggressive ransomware, but a cyber weapon.
[01:08:58.240 --> 01:09:04.400]   Yeah, it was a nation state, attributed to a nation state actor. I've contributed to
[01:09:05.280 --> 01:09:12.880]   Shamoon, which has been targeting Saudi Arabia in the recent past. So I don't know who Shamoon is.
[01:09:12.880 --> 01:09:19.040]   I guess that's another one of these malware groups like Fancy Bear.
[01:09:19.040 --> 01:09:23.920]   Wow. So that's interesting. I mean, I guess if I mean, look, insurance companies from
[01:09:23.920 --> 01:09:29.040]   time and memorial have tried to figure out ways not to pay out. But boy, I mean,
[01:09:29.040 --> 01:09:34.960]   monoliths lost $100 million. So they say, yeah, that tens of thousands of
[01:09:34.960 --> 01:09:42.240]   like 20,000 laptops, it's a lot of stuff. And yeah, they want 100 million out of,
[01:09:42.240 --> 01:09:48.160]   who's it? This is Zurich, who is ensuring that. Yeah. Interesting.
[01:09:48.160 --> 01:09:56.480]   Wow. Speaking of malware, Marcus Hutchins has played guilty. This was a story
[01:09:57.280 --> 01:10:05.840]   just a fascinating story. Marcus was arrested after he attended Defcon. Was it a,
[01:10:05.840 --> 01:10:09.360]   it was last year, right? It was more than a year ago.
[01:10:09.360 --> 01:10:18.160]   And he was well known at the time because he was the guy who stopped WannaCry
[01:10:18.160 --> 01:10:24.640]   by figuring out what the server WannaCry phoned home to a server. And he stopped it
[01:10:25.200 --> 01:10:32.160]   by registering the domain name and taking that, that phone home server out of business.
[01:10:32.160 --> 01:10:39.600]   But it turns out he had a long history of writing malware, whether for, for fun and
[01:10:39.600 --> 01:10:45.680]   profits unclear, it almost seems like they were exercises, including the Chronos malware,
[01:10:45.680 --> 01:10:51.440]   which has been used to steal banking information. It was a plea agreement. I wouldn't necessarily
[01:10:52.400 --> 01:10:58.560]   assume that Marcus is saying, yeah, I'm a bad guy. I did it. I think more likely the feds said,
[01:10:58.560 --> 01:11:04.240]   you're going to go to jail for a really long time if you don't accept responsibility.
[01:11:04.240 --> 01:11:10.480]   Although he pled guilty to two of 10 counts. The other eight were dropped,
[01:11:10.480 --> 01:11:16.400]   but each of those two counts carries up to five years in prison. So he could still see some serious
[01:11:16.400 --> 01:11:20.800]   prison time. Usually though an agreement like that, the implication is well, by admitting that
[01:11:20.800 --> 01:11:26.400]   you did it and take responsibility apologizing, you could.
[01:11:26.400 --> 01:11:30.000]   This is one of those classic situations, I think, where I just,
[01:11:30.000 --> 01:11:37.600]   I never want to be the guy that stands up to try and defend criminals if charges are levied.
[01:11:37.600 --> 01:11:48.720]   But there is a lot to be said for hiring smart people, maybe putting aside what they have done.
[01:11:48.720 --> 01:11:51.920]   I mean, obviously there's a laundry list of things you would never put aside.
[01:11:51.920 --> 01:11:56.400]   But when it comes to things like computer hacking and fraud and stuff like that,
[01:11:56.400 --> 01:12:00.080]   do you want someone behind bars and banning them from computers? Or do you want to say,
[01:12:00.080 --> 01:12:04.800]   look, your parent says you're going to go and work for insert company here, and you're going to
[01:12:04.800 --> 01:12:07.920]   help figure out how to stop this kind of thing happening.
[01:12:07.920 --> 01:12:15.120]   There's a lot of evidence that he did this stuff when he was younger. I mean, he's a young
[01:12:15.120 --> 01:12:20.720]   guy anyway. And then as he got more mature, he turned from black hat or maybe not even black
[01:12:20.720 --> 01:12:25.280]   hat, but gray hat to white hat hacking. And he's done a lot of good as a malware researcher.
[01:12:25.280 --> 01:12:33.120]   He wrote, as you may on his blog, malware tech.com, as you may be aware, I've pled guilty to two
[01:12:33.120 --> 01:12:37.840]   charges related to writing malware in the years prior to my career in security. I regret these
[01:12:37.840 --> 01:12:42.800]   actions and accept full responsibility from my mistakes. Having grown up, I've since been using
[01:12:42.800 --> 01:12:47.280]   the same skills I misused several years ago for constructive purposes.
[01:12:47.280 --> 01:12:51.280]   I will continue to vote my time to keeping people safe from malware attacks. This is the
[01:12:51.280 --> 01:12:54.640]   beginning of what he will, what he and as attorneys will say in court, of course,
[01:12:54.640 --> 01:13:01.040]   trying to convince a judge that I'd be exactly, as you say, Nate, I'd be more useful at a jail
[01:13:01.040 --> 01:13:05.520]   fighting malware. Yeah, I think governments would want to keep these folks around too.
[01:13:05.520 --> 01:13:08.880]   We actually know how to help prevent similar attacks within their countries.
[01:13:08.880 --> 01:13:13.040]   And I think a lot of people felt a bad. Marcus had a good reputation when he was arrested.
[01:13:13.040 --> 01:13:17.120]   A lot of people had a bad taste in their mouth. He was arrested at the airport as he was leaving
[01:13:17.120 --> 01:13:24.080]   the United States. There was some, in 2017, there was some real concern among security researchers
[01:13:24.080 --> 01:13:29.200]   that it was going to be risky to come to the United States because you might be arrested on
[01:13:29.200 --> 01:13:34.960]   your way in or your way out. And a lot of conferences no longer come to the US for that reason.
[01:13:35.840 --> 01:13:42.240]   Unfortunately, the feds have a long history of coming down really hard on people who commit
[01:13:42.240 --> 01:13:49.680]   cyber security crimes who are otherwise fairly innocuous or not all that harmful and would be
[01:13:49.680 --> 01:13:56.480]   quite useful as white hat hackers. They have a tendency to want to make an example of people
[01:13:56.480 --> 01:14:02.800]   and lean on them really hard. He was a teenager and I think there's no evidence he used Kronos himself
[01:14:04.800 --> 01:14:11.760]   to be ill-effect but he did release it. Perhaps he sold it in which case he deserves the punishment.
[01:14:11.760 --> 01:14:18.000]   Anyway, that's an update. We've been covering that since it happened in 2017.
[01:14:18.000 --> 01:14:25.760]   Apple and Qualcomm have buried the hatchet. Kind of a shock.
[01:14:25.760 --> 01:14:30.880]   What a whirlwind of news. I know. I know. I mean Monday the trial began.
[01:14:31.600 --> 01:14:36.880]   Multi-billion dollar trial. This has been an ongoing battle. Apple owed Qualcomm billions.
[01:14:36.880 --> 01:14:45.680]   Qualcomm was withholding technology. They actually impaneled a jury. They had our opening arguments
[01:14:45.680 --> 01:14:50.400]   and then the very next day it's over. We of course we don't know what the settlement was although
[01:14:50.400 --> 01:14:56.400]   apparently Apple gave Qualcomm some amount of money. We don't know how much. And Qualcomm,
[01:14:57.040 --> 01:15:02.320]   and its part has reached a six-year license agreement with Apple. They're going to buy their chips
[01:15:02.320 --> 01:15:08.000]   for six years with an option of two years to extend. Now I have lots of theories about why this
[01:15:08.000 --> 01:15:15.440]   happened. One of them is fueled by the fact that almost immediately after Intel said, "Oh, thank
[01:15:15.440 --> 01:15:22.320]   God we don't have to make five G-phones." We're out of the business. What a relief. Apple was turning
[01:15:22.320 --> 01:15:30.480]   to... Apple was using Intel modems this year and was slowly phasing out Qualcomm chips.
[01:15:30.480 --> 01:15:34.560]   Partly because Qualcomm wouldn't give them the chips. Apple's contention in public was,
[01:15:34.560 --> 01:15:39.520]   "Oh, those are crappy chips anyway." Although one of the things Apple admitted to doing in the
[01:15:39.520 --> 01:15:45.920]   Qualcomm suit 'em for is slowing down Qualcomm radios on some iPhones so they wouldn't be any
[01:15:45.920 --> 01:15:52.320]   faster than the Intel radios and the other iPhones. They got to make it fair. Oh, man.
[01:15:52.320 --> 01:15:59.280]   This is great news for Apple and Qualcomm, I guess, because of me and the road to the 5G
[01:15:59.280 --> 01:16:06.480]   iPhone, be it next year or 2021, is kind of set. But this is another big loss for Intel.
[01:16:06.480 --> 01:16:10.080]   I feel like we're not talking about that enough too because a couple of years ago,
[01:16:10.080 --> 01:16:14.400]   they felt really burned by missing out on mobile CPUs and all that. And I had talked to some
[01:16:14.400 --> 01:16:19.600]   Intel executives and they were making a big play for modems. And they made it. They got it into the
[01:16:19.600 --> 01:16:25.360]   iPhones. I don't know what this means for Intel's mobile chip business in general, if you can't even
[01:16:25.360 --> 01:16:29.840]   do modems anymore. Yeah, I mean, it's bad for Intel. I think the other reason Apple said,
[01:16:29.840 --> 01:16:34.400]   "Let's not continue this," is Discovery is always painful and Apple's learned this in their long
[01:16:34.400 --> 01:16:38.560]   battle with Samsung. And a lot of times, things that Apple would like to keep secret
[01:16:38.560 --> 01:16:43.600]   that any company would like to keep secret leak out in Discovery, including that email from Apple
[01:16:43.600 --> 01:16:46.400]   saying, "Oh, these Qualcomm modems, they're the best."
[01:16:46.400 --> 01:16:50.880]   Even though Apple publicly is saying, "Oh, they're terrible."
[01:16:50.880 --> 01:16:57.120]   That was... It gives Tim Cook was going to have to testify too. I'm sure they didn't want to put
[01:16:57.120 --> 01:17:03.920]   him on the stand and have him be a witness. Yeah. And yeah, it's a little... In fact,
[01:17:03.920 --> 01:17:09.680]   Qualcomm's stock price went up almost 20%. Apple's went up a little bit mostly because Qualcomm was
[01:17:09.680 --> 01:17:15.760]   under a lot of... The weight of this was a big depressant to its stock price. But now that it's
[01:17:15.760 --> 01:17:21.920]   resolved, Qualcomm can go ahead and sell chips to Apple. Apple, I'm sure, has thousands of
[01:17:21.920 --> 01:17:28.880]   engineers as we speak working long hours, even on Easter, trying to come up with a 5G modem for an
[01:17:28.880 --> 01:17:32.960]   iPhone. But that's not going to be... They don't have to worry for six years anyway.
[01:17:32.960 --> 01:17:38.320]   I'm also a little bummed about this because Qualcomm basically has a stranglehold on this market,
[01:17:38.320 --> 01:17:44.080]   a little competition is always better. It makes everybody better. I guess we'll see what will
[01:17:44.080 --> 01:17:48.560]   happen now. If Intel can't even compete, who can? Time for the question.
[01:17:48.560 --> 01:17:55.840]   Which came first? Was it Intel saying it was going to pull out or was it the Apple Qualcomm
[01:17:55.840 --> 01:18:00.560]   Saturn? No, the settlement happened. And then within hours, Intel said, "We're out."
[01:18:00.560 --> 01:18:05.040]   But the lawyers talked behind the scenes before either of those two things happened. So I'm just
[01:18:05.040 --> 01:18:10.240]   curious, behind the scenes, was that the order that things took place or did something happen?
[01:18:10.240 --> 01:18:16.560]   Oh, so maybe you're right. Maybe Intel went to Apple and said, "Dudes,
[01:18:16.560 --> 01:18:22.400]   this 5G modem thing is not working. We're not going to have it for you or we can't do it."
[01:18:22.400 --> 01:18:28.480]   That's what I wanted. I'm sure... No, I think that's exactly what happened.
[01:18:28.480 --> 01:18:32.080]   Yeah. Even Intel's stock went up after this announcement.
[01:18:33.360 --> 01:18:37.200]   That might be a sign of... You're going to focus on making better processors for
[01:18:37.200 --> 01:18:41.200]   desktops. What do you think Intel's future is?
[01:18:41.200 --> 01:18:50.160]   So they had announced last year that they... First of all, they stole the head graphics guy from AMD.
[01:18:50.160 --> 01:18:55.840]   So he's over the guy who revamped all the Radeon cards. He's now over at Intel,
[01:18:55.840 --> 01:19:00.080]   creating a discrete graphics thing. They say their integrated graphics are going to be better.
[01:19:00.080 --> 01:19:03.280]   We're waiting to hear about more details about their ninth generation mobile chips.
[01:19:03.280 --> 01:19:09.520]   They're making a lot of progress, but I do feel like outside of this core PC laptop desktop market,
[01:19:09.520 --> 01:19:14.320]   Intel doesn't have that much going on. So it is kind of funny to see them run away from modem so
[01:19:14.320 --> 01:19:19.600]   quickly. And not that it's going to really hurt Intel, but Apple is clearly on a path to abandon
[01:19:19.600 --> 01:19:24.400]   Intel chips entirely, not just in its iPhones, but on its desktop and laptop computers. I don't
[01:19:24.400 --> 01:19:32.960]   know if that's a big deal for Intel. It's embarrassing. Well, Apple's also racing to give us the lowest
[01:19:32.960 --> 01:19:39.120]   spec things that they can call a MacBook. That new MacBook Air is basically running on the phone.
[01:19:39.120 --> 01:19:45.680]   So depressing. Like the iPad Pro, like eventually the iPad Pro and the MacBook
[01:19:45.680 --> 01:19:49.440]   is going to be first. They're saying, what's the slowest computer people will actually buy?
[01:19:49.440 --> 01:19:54.000]   I guess that's the iPad Pro, right? Like iPad Pro is their vision for where they're not.
[01:19:54.000 --> 01:20:01.120]   iPad Pro is fast. The 12x in there is like desktop class. It's really good. It's of course hampered
[01:20:01.120 --> 01:20:06.720]   by 10 year old software. iOS. Yeah. iOS, you know, I mean, hasn't changed much in years.
[01:20:06.720 --> 01:20:13.040]   But that may change iOS 13 is rumored to be a redesign for iPad, particularly.
[01:20:13.040 --> 01:20:18.000]   I'm going to tell you something that is really shocking to me to realize, right?
[01:20:18.000 --> 01:20:24.640]   So when the most recent MacBook generations, the late 2018 ones released, I went out and I bought
[01:20:24.640 --> 01:20:30.480]   one 15 inch top spec. And then in November, I think it was the new iPad Pro is announced.
[01:20:30.480 --> 01:20:37.920]   I went out and I bought one of those, the 11 inch. And I realized a few weeks ago that I've
[01:20:37.920 --> 01:20:43.360]   basically not used that MacBook Pro since the iPad, since I got the iPad Pro.
[01:20:44.000 --> 01:20:48.400]   And I'm now selling the MacBook Pro because I don't need it. I don't need it.
[01:20:48.400 --> 01:20:53.200]   What do you choose? Is it for music? What do you write your articles on it?
[01:20:53.200 --> 01:20:59.200]   Do you? I do. Yeah. I write my articles on it. So my podcast that I do outside of Bloomberg,
[01:20:59.200 --> 01:21:05.040]   I edit now on the iPad. I upload it from the iPad. I do the show notes and the iPad.
[01:21:05.040 --> 01:21:11.520]   I've done video editing when I went to mobile world Congress at the end of in February,
[01:21:11.520 --> 01:21:17.280]   or it was beginning in March. Earlier this year, it was the first time in 13 years of covering
[01:21:17.280 --> 01:21:21.680]   tech conferences that I didn't take a laptop. It's not that I took one and left it in the hotel.
[01:21:21.680 --> 01:21:27.840]   I didn't even take one with me because I did everything on that iPad. Video editing, photo editing,
[01:21:27.840 --> 01:21:34.560]   all my writing, all my uploads, absolutely everything I did on the iPad Pro. And the only
[01:21:34.560 --> 01:21:40.880]   thing now for me holding it back is the fact that you, there is no real file system. So you can't
[01:21:40.880 --> 01:21:45.680]   plug in a USB drive and pull files off it. You have to go around that. But apart from that,
[01:21:45.680 --> 01:21:49.760]   it really has got to the point where I don't need my Mac Pro anymore and I'm selling it.
[01:21:49.760 --> 01:21:52.160]   It also has a better keyboard than the MacBook Pro. So there you go.
[01:21:52.160 --> 01:21:58.720]   A clay tablet has a better keyboard than the MacBook Pro.
[01:21:58.720 --> 01:22:05.520]   That's not saying a whole lot. I love that keyboard. But even little things like
[01:22:05.520 --> 01:22:13.200]   plugging a microphone in by USB-C straight into the iPad Pro. It's amazing. It works
[01:22:13.200 --> 01:22:19.600]   fantastically well. It's really quite amazing. So yeah, I think the power in that thing is excellent.
[01:22:19.600 --> 01:22:24.000]   It's got a lot more efficient as well. The fact you can have two apps running side by side.
[01:22:24.000 --> 01:22:28.160]   You can have a third app overlaid over the top of that. You can have video if you need running
[01:22:28.160 --> 01:22:32.720]   picture and picture and you can still have stuff running in the background. The power in that
[01:22:32.720 --> 01:22:38.640]   thing is really quite amazing. IOS generally needs an overhaul if it's going to compete
[01:22:38.640 --> 01:22:44.240]   more broadly with desktops. But it's definitely got to a point where I don't need that Mac
[01:22:44.240 --> 01:22:47.760]   Pro. I need my desktop. Definitely. I still need my desktop for my main work.
[01:22:47.760 --> 01:22:54.320]   Oh, I get it. You still have a desktop. You're just not using a laptop.
[01:22:54.320 --> 01:23:02.320]   I get it. Everything on the go is now. What was previously Mac Pro for the last 10 years,
[01:23:02.320 --> 01:23:09.040]   whatever is now. I'd love to say that. I bought an i9 MacBook Pro as well and gave it to my son.
[01:23:09.040 --> 01:23:11.520]   I don't use it. But that was more because I couldn't bear the keyboard.
[01:23:11.520 --> 01:23:18.320]   I often feel like when I'm using iOS, I'm struggling harder than I should. I can get it to do stuff,
[01:23:18.320 --> 01:23:24.160]   but it's harder to do stuff. You don't feel that way? No, I really don't. I mean,
[01:23:24.160 --> 01:23:30.640]   the one thing that I use as well is I have a remote desktop app that I use. So on the very
[01:23:30.640 --> 01:23:38.960]   a rare occasion that I need to. I can remote into a desktop, but it's so, so, so rare. And a lot of
[01:23:38.960 --> 01:23:44.480]   the time it is only because I need something that's specific to work or to Bloomberg or something
[01:23:44.480 --> 01:23:52.480]   like that. And that's it. But it's so close. It is so close. And I mean, the fact that I can,
[01:23:52.480 --> 01:23:57.360]   for me, it's the podcasting side of things, right? It's the fact that I can record all that
[01:23:57.360 --> 01:24:02.560]   stuff on there. I can do my multi-track editing on there, all the effects, same with video.
[01:24:02.560 --> 01:24:07.360]   And I can do it all on the iPad is just amazing. Like, if you listen to the show,
[01:24:07.360 --> 01:24:11.840]   you wouldn't be able to tell whether one was edited in Logic and one was edited on Fairight,
[01:24:11.840 --> 01:24:15.440]   which is what I use on the iPad. It's really, it's really quite interesting.
[01:24:15.440 --> 01:24:20.240]   You said there's no real file system though. So my interpretation of that and tell me if this
[01:24:20.240 --> 01:24:26.320]   is right is that if you were working with other people who had, you know, you were sending a lot
[01:24:26.320 --> 01:24:32.240]   of files around or collaborating on PowerPoints or Word documents instead of cloud-based stuff,
[01:24:32.240 --> 01:24:37.360]   that might be a problem, right? No, you can still do that. And what I mean with file system is,
[01:24:37.360 --> 01:24:41.760]   you know, on a Mac or on a PC, if you've got files on a hard drive, you just plug it in by USB
[01:24:41.760 --> 01:24:47.120]   and copy stuff over. You can't plug a hard drive into an iPad and just copy files. You've got,
[01:24:47.120 --> 01:24:51.600]   you've got, if you download it from the web or you have some FTB app or whatever,
[01:24:51.600 --> 01:24:53.600]   you can still get those files onto it. There's no problem.
[01:24:53.600 --> 01:24:58.640]   Well, you have to do it from an application. So it requires that the application could see
[01:24:58.640 --> 01:25:04.000]   those files and can open them. But if they can, then you can use drop a, so your PowerPoint example,
[01:25:04.000 --> 01:25:08.720]   you could drop box at PowerPoint and somebody else could open it. But you can only do it from
[01:25:08.720 --> 01:25:12.960]   PowerPoint. There's no independent way to do it. You have to do it from within the app. And that's
[01:25:12.960 --> 01:25:18.960]   a security and convenience, a dumbing down of the app. I always feel like when I'm using the iPad,
[01:25:18.960 --> 01:25:25.360]   I always feel like, I don't know, like a Raptor, like my elbows and I can only, it's like,
[01:25:25.360 --> 01:25:31.280]   it's not fully constraining, but it's just completely like, just enough. Yeah, it wouldn't be free,
[01:25:31.280 --> 01:25:36.560]   like a bird with a fly. Yeah. But you know, there's something like, there's something so
[01:25:36.560 --> 01:25:43.280]   liberating. Like, I'm really, really big up. And every year I get more so on the, so the mental
[01:25:43.280 --> 01:25:48.880]   health impacts of technology. And one of the things I think I really like about, about the iPad
[01:25:48.880 --> 01:25:54.160]   specifically, is that it's not trying to be a desktop where I've got a million windows open,
[01:25:54.160 --> 01:25:59.040]   I've got three displays, everything's blinking at me. Like there's that, there's that ability to
[01:25:59.040 --> 01:26:03.680]   slightly control better, what is in front of me. It's the same argument for why people like a
[01:26:03.680 --> 01:26:07.760]   Kindle for reading instead of an iPad, they don't notifications popping up, they can just focus on
[01:26:07.760 --> 01:26:12.960]   a book. And I think that that similar is true when it comes to the iPad. And I've just got a
[01:26:12.960 --> 01:26:18.160]   better ability to control what shouting at me from a screen, which then helps me be more productive,
[01:26:18.160 --> 01:26:22.640]   less stressed and things like that. It also helps that that is one of the most beautiful
[01:26:22.640 --> 01:26:27.680]   gadgets around right now. That thing looks amazing. The only really issues we're pointing to is like
[01:26:27.680 --> 01:26:33.920]   iOS not being up this now. Yeah, the hardware's stunning. Yeah. Yeah. I usually say, my tagline is,
[01:26:33.920 --> 01:26:39.680]   this is a computer from the future running an OS from the past. And it's just a mismatch. And
[01:26:39.680 --> 01:26:44.960]   Apple could totally fix that. But I think they're reluctant to go too far because A, they want to
[01:26:44.960 --> 01:26:49.680]   keep it simple. Probably that's their most important rationale and B, they're not quite ready to kill
[01:26:49.680 --> 01:26:55.440]   Macintosh. I don't think they want to kill Mac OS. This is the thing. Like, yeah, I remember there
[01:26:55.440 --> 01:27:00.560]   was that great quote that Steve Jobs gave probably was about the iPad, which is, you know, no one takes
[01:27:00.560 --> 01:27:06.480]   a truck to the shop. And there's a need for trucks. And there's a need for little nimble,
[01:27:06.480 --> 01:27:10.880]   you know, single-seater self-driving electric vehicles that just takes you to the store and back.
[01:27:12.000 --> 01:27:15.840]   And I kind of think that there's still a need for that, definitely. Like, I would, I'm not going to
[01:27:15.840 --> 01:27:19.680]   give up my desktop right now. And I can't see why I would get rid of my desktop. I've got a
[01:27:19.680 --> 01:27:24.800]   34-inch ultra-wide monitor that you can't see hooked up on the left. I've got this big iMac
[01:27:24.800 --> 01:27:30.640]   sitting around to me on the right. Like, I need that for, you know, many types of work application,
[01:27:30.640 --> 01:27:35.040]   but I don't need it all the time. And a lot of the time, I just need, I need everything that's just
[01:27:35.040 --> 01:27:39.120]   in front of me. I can take it wherever I go. And that's what the iPad is. And it's really getting
[01:27:39.120 --> 01:27:41.440]   there. It's not for everyone, but it's definitely got to that point for me.
[01:27:41.440 --> 01:27:52.320]   Okay. We'll see iOS 13, which will, I'm sure, learn a lot more about in June at WWDC,
[01:27:52.320 --> 01:27:57.840]   Apple's Developers Conference, and of course, it will come out with a new iPhone in September.
[01:27:57.840 --> 01:28:03.200]   But supposedly has a lot more multitasking capability, a lot of stuff that will make the iPad
[01:28:04.640 --> 01:28:11.040]   a more usable computer. Honestly, though, I don't see that one thing that I agree with you,
[01:28:11.040 --> 01:28:16.480]   we really need Nate, which is the ability to access files directly over there.
[01:28:16.480 --> 01:28:20.000]   The fact they put a type C on it was really wonderful.
[01:28:20.000 --> 01:28:26.320]   I mean, what they call it, Pro. And it's lacking the one feature that I would argue every single Pro
[01:28:26.320 --> 01:28:34.320]   user needs. It's a joy to edit photos with, except you have to import photos into photos
[01:28:34.720 --> 01:28:39.120]   first, and then import it from photo. This is where the lack of the file system really hurts,
[01:28:39.120 --> 01:28:43.120]   then imported from Apple's photos into Lightroom or whatever you're using.
[01:28:43.120 --> 01:28:47.200]   It is funny how every Apple device now is becoming like this weird Twilight Zone
[01:28:47.200 --> 01:28:52.400]   conclusions. Like, oh, you have the most beautiful tablet in the world, but you can't really edit
[01:28:52.400 --> 01:28:58.480]   files with it. Submit it for your approval. Amanda. I was just trying to edit some files.
[01:28:58.480 --> 01:29:04.000]   The iOS zone. All right. We're going to take a little break. There's a lot more to talk about.
[01:29:04.000 --> 01:29:09.920]   Including Apple at News Plus, I'd like to get your impression because people who use texture
[01:29:09.920 --> 01:29:17.600]   about to go without. And that was a magazine app I really like. But first, we did make a little,
[01:29:17.600 --> 01:29:22.080]   I think we made a little feature film. We're going to submit it to the Venice Film Festival.
[01:29:22.080 --> 01:29:27.760]   All about this week on Twitch. Previously on Twitch.
[01:29:27.760 --> 01:29:36.400]   On April 17th, 2005, we did the very first episode of what was at the time called the Revenge of
[01:29:36.400 --> 01:29:44.240]   the Screen Savers, right? And it went so well. So many people listen that I can't chase them all
[01:29:44.240 --> 01:29:51.520]   away. And this is, in a nutshell, the story of Twitch. All about Android. People got their hands
[01:29:51.520 --> 01:29:57.040]   on the Samsung Galaxy Fold, and you were one of them, correct? You mean this one? Oh, yeah.
[01:29:57.600 --> 01:30:02.960]   Oh, we got this, first then. My first question is, what does the Fold feel like? Do you feel it
[01:30:02.960 --> 01:30:09.680]   creaking? How does it sound? This weekend, Enterprise Tech. Ablying it. This story that we're
[01:30:09.680 --> 01:30:15.920]   talking about today calls out a well-known food brand. This company was struck by the not pet
[01:30:15.920 --> 01:30:22.080]   chest cyber strike in 2017. They were blocked by the insurance company who used a loophole,
[01:30:22.080 --> 01:30:27.600]   their war exclusion clause, which protects the insurer from costs related to the damage from
[01:30:27.600 --> 01:30:34.160]   war. In this case, cyber war. I think what this will begin is a series of negotiations about what
[01:30:34.160 --> 01:30:42.160]   precisely cyber warfare looks like. Words matter, and the use of one word over another has consequences
[01:30:42.160 --> 01:30:48.880]   in the real world, some of which can cost real money. Twitch, for help with the technology addiction
[01:30:48.880 --> 01:30:59.200]   problem, call 1-800-TWEAT. And then the phone will say, yeah? And you have some more numbers for me?
[01:30:59.200 --> 01:31:04.240]   Our show today brought to you by Stamps.com. We don't go to the post office here at Twitch. No,
[01:31:04.240 --> 01:31:11.120]   no, no. We're much more modern than that. We buy and print all our postage right here from our desks
[01:31:11.120 --> 01:31:15.200]   with our computers. No, I'm not talking about postage meter. That's even worse. No, no. We use
[01:31:15.200 --> 01:31:20.320]   Stamps.com. See, I can buy postage. I could print postage. In fact, when the rates went up, man,
[01:31:20.320 --> 01:31:25.040]   it was awesome. We were ready. We had we had stamps. We print them on demand. You could print
[01:31:25.040 --> 01:31:30.080]   right on an envelope. Stamps.com will automatically fill in the return address, will automatically take
[01:31:30.080 --> 01:31:34.480]   the addresses of the people you're mailing to from your contact list. Or, you know, if you're an
[01:31:34.480 --> 01:31:39.840]   Etsy buyer or seller rather, an eBay Amazon seller, it'll take it right off the website.
[01:31:39.840 --> 01:31:44.800]   Saves you a lot of time. Fill out all the forms you need for international mail,
[01:31:44.800 --> 01:31:50.720]   for certified mail. So you spend less time, you get it. And by the way, it looks so much more
[01:31:50.720 --> 01:31:55.520]   professional. When you print on an envelope, you get your company logo, your return address. It's
[01:31:55.520 --> 01:32:00.800]   so gorgeous. Even that little barcode that the post office likes for fast routing to make sure
[01:32:00.800 --> 01:32:06.480]   your mail really gets to where it's going. Plus, you get discounts. You can't get at the post office.
[01:32:06.480 --> 01:32:11.920]   So when the price went up, when we were printing out new stamps, we got five cents off every first
[01:32:11.920 --> 01:32:18.240]   class stamp and up to 40% off priority mail because we use stamps.com. I mean, that's awesome.
[01:32:18.240 --> 01:32:24.000]   Not to mention, it's a fraction of the cost of a postage. Stamps.com is a no-brainer. It'll save
[01:32:24.000 --> 01:32:29.840]   you time. It'll save you money. It makes you look more professional. Over 700,000 small businesses
[01:32:29.840 --> 01:32:35.120]   already use stamps.com. That's what we use. We love it so much. You also, I'm going to show you
[01:32:35.120 --> 01:32:39.680]   how you can get a USB scale so you'll always have exactly the right postage. It just sends it right
[01:32:39.680 --> 01:32:45.280]   into the software. You could print postage for any letter, but also any package. Any class of
[01:32:45.280 --> 01:32:50.400]   mail stamps.com will even suggest more affordable. We'll say, is that a book we could do media mail?
[01:32:50.400 --> 01:32:55.920]   You want to do media mail? It is amazing. Right now, you can enjoy the stamps.com service with a
[01:32:55.920 --> 01:33:04.400]   great offer we have for your four-week trial plus free postage. Yeah, free postage and a digital scale
[01:33:04.400 --> 01:33:09.920]   with no long-term commitment. You see that? Click the microphone. Enter the code TWIT. This is a secret.
[01:33:09.920 --> 01:33:18.800]   A $110 bonus offer, including $55 worth of postage coupons. This is the deal you want. Go to
[01:33:18.800 --> 01:33:27.440]   stamps.com. Click the microphone at the top of the homepage and enter TWITSTAMPS.com. It is great.
[01:33:27.440 --> 01:33:30.960]   I love the post office, but you should only go to the post office because you want to visit your
[01:33:30.960 --> 01:33:37.120]   postal carrier. You just want to see it. It's a nice place. If you're mailing something, just do
[01:33:37.120 --> 01:33:45.440]   it from your desk with stamps.com. Let's see. Where were we going? I forgot what I said I wanted
[01:33:45.440 --> 01:33:51.600]   to talk about. There's all sorts of news. Let's do some more Apple news. We were talking about
[01:33:51.600 --> 01:33:58.240]   texture. I can't believe I'm going to quote the New York Post here. But they have a media column.
[01:33:58.240 --> 01:34:04.720]   It's pretty good. Keith Kelly. Apple to shutter texture for news app leave Android users out of
[01:34:04.720 --> 01:34:09.440]   luck. May 28th, if you've been subscribing to texture, and I know a lot of you do because they
[01:34:09.440 --> 01:34:16.480]   were an advertiser for a long time, Apple is going to shut down those 240,000 subscribers.
[01:34:16.480 --> 01:34:22.800]   If you're on iOS, you can just move to news plus, which is pretty much exactly what texture was.
[01:34:24.080 --> 01:34:28.960]   Or if you're on Android, there are other choices, but I don't think they have the same number of
[01:34:28.960 --> 01:34:34.080]   magazines. Texture was the best. So many companies have tried this whole subscription magazine thing,
[01:34:34.080 --> 01:34:38.480]   and there's a reason Apple bought texture. They built a whole service around it. It really was
[01:34:38.480 --> 01:34:44.880]   the best. Do you like Apple news plus? It's fine. I signed up for the free trial. Actually,
[01:34:44.880 --> 01:34:49.760]   as we were doing this conversation, I had to remind myself to go cancel it because it's fine.
[01:34:49.760 --> 01:34:55.120]   It's perfectly fine, but I don't really need it. Magazine articles once in a while.
[01:34:55.120 --> 01:34:59.600]   I only really read magazines because I like the feel and I want to sit down with that long
[01:34:59.600 --> 01:35:04.640]   form stuff. It's on the web. If the magazine article is on the web, I'll read it there. I
[01:35:04.640 --> 01:35:08.720]   don't need this whole other app to deal with that. I feel the same way. And then the magazines that
[01:35:08.720 --> 01:35:16.960]   I really do want to support, note support as opposed to read, like the New Yorker and the Atlantic,
[01:35:16.960 --> 01:35:19.920]   I will subscribe. I'll use their apps and subscribe.
[01:35:19.920 --> 01:35:25.120]   Does anybody actually read the New Yorker? The New Yorker app is great. I don't read it,
[01:35:25.120 --> 01:35:29.760]   but boy, is it great. You go right to the cartoon. You like to say you subscribe and that you know
[01:35:29.760 --> 01:35:36.080]   the cartoon. Especially in our business these days, they're doing really good tech. They do.
[01:35:36.080 --> 01:35:40.240]   They have good stuff. And so especially in our business, I feel like there is an article by Ken
[01:35:40.240 --> 01:35:44.960]   Oletta or somebody like that that I have to read at least once a month. There's a long,
[01:35:45.840 --> 01:35:49.360]   so there's a long form article I want to read in the New Yorker. Atlantic is the same thing. I feel
[01:35:49.360 --> 01:35:53.520]   like there's a, especially for politics coverage at Atlantic and the New Yorker, I have to have
[01:35:53.520 --> 01:35:59.280]   those. And then I pay for the New York Times, which is not on News Plus. And I pay for the Wall Street
[01:35:59.280 --> 01:36:04.720]   Journal, which is, you know, with a big beneficiary of News Plus is, in my opinion, is the Los Angeles
[01:36:04.720 --> 01:36:09.840]   Times. It's a chance for that. That's one of the things you get with the News Plus subscription is
[01:36:09.840 --> 01:36:12.000]   a real chance for them to get a national profile.
[01:36:14.080 --> 01:36:23.280]   So two things that stand out here. The first is that I see absolutely no reason why Apple won't release
[01:36:23.280 --> 01:36:30.160]   News Plus for Android. If you look at everything that it's doing recently, it's all about services,
[01:36:30.160 --> 01:36:37.440]   right? Apple needs services for its future. You know, they've announced Apple TV that's going to be on
[01:36:37.440 --> 01:36:43.840]   Samsung televisions. They've got Apple Music on Android. They're going to have News Plus on
[01:36:43.840 --> 01:36:48.880]   Android, because why would you shut out hundreds of millions of potential subscribers to your
[01:36:48.880 --> 01:36:53.840]   to your services product? So it's going to happen. There's no doubt in my mind that it's going to
[01:36:53.840 --> 01:37:01.680]   happen. And then the second thing is more of a rant, which is that one of the main reasons why I
[01:37:01.680 --> 01:37:09.920]   like using Apple News as an app, that is, is because I have never hated browsing the web more than I do
[01:37:09.920 --> 01:37:17.040]   today. It has got to the point. It has got to the point. That's a good point. That the ads on websites
[01:37:17.040 --> 01:37:22.320]   are the least annoying thing on a website, particularly in Europe. And this is honestly,
[01:37:22.320 --> 01:37:27.520]   this is more so than in the US, because in Europe, you have the cookies pop up. That's asking you
[01:37:27.520 --> 01:37:33.360]   one. No, we get that too. That's what really makes me mad. It's some stupid European law,
[01:37:33.360 --> 01:37:40.400]   but we get it too. Okay, imagine that. But on top of that, you then have a pop up that says,
[01:37:40.400 --> 01:37:46.640]   we value your privacy, click here to accept all these terms on every website you go on every device
[01:37:46.640 --> 01:37:50.560]   that you're on. And then that's on top of your on the ads, that's on top of the
[01:37:50.560 --> 01:37:57.920]   user, but blame GDPR blame the you parliament for that. I do. Yeah, blame it all. You don't get any
[01:37:57.920 --> 01:38:03.360]   of that, but you don't get any of that when you are in in a news app like Apple News.
[01:38:03.360 --> 01:38:12.560]   This is a perfect example of regulation. I think GDPR is on the balance of great benefit.
[01:38:12.560 --> 01:38:18.320]   But this is a perfect example of where sometimes regulation just goes badly wrong. That cookies banner
[01:38:18.320 --> 01:38:24.800]   does nothing but annoy. It doesn't. In fact, it has the opposite impact. It just makes people go,
[01:38:24.800 --> 01:38:32.080]   yeah, yeah, yeah. I don't want to read that. It's just like clicking yes, except on terms and
[01:38:32.080 --> 01:38:37.600]   conditions or privacy policy. It's just about as meaningful. You wrote Nate about the browser
[01:38:37.600 --> 01:38:44.080]   ballot. Microsoft famously was recorded required to do that by the EU. Now Google is going to do that.
[01:38:44.080 --> 01:38:50.640]   Where are they doing that though? They are doing that in in Europe. So,
[01:38:51.360 --> 01:38:54.320]   but on what? Where? I mean, on Android, where do you get that?
[01:38:54.320 --> 01:39:00.480]   On Android. So, if I get a brand new Android phone, one of the first things I'm going to do is have
[01:39:00.480 --> 01:39:06.880]   to choose which browser? We don't know exactly how. I mean, it was meant to be rolling out. I think
[01:39:06.880 --> 01:39:14.320]   on it was Thursday, right? I think on Thursday, the response to the EC's 4.3 billion euro fine.
[01:39:14.320 --> 01:39:20.640]   Yeah, well, they wanted to avoid further antitrust fines. The EU had basically said,
[01:39:20.640 --> 01:39:28.640]   look, you can't use Android to strong arm people into using Chrome and into using Google search.
[01:39:28.640 --> 01:39:34.560]   So, Google agreed that it would make some changes to make it less apparent that it was strong
[01:39:34.560 --> 01:39:38.720]   arming people into using Chrome and Android. And one of the ways that they've done that is to follow
[01:39:38.720 --> 01:39:47.520]   is to textbook. Follow what Microsoft did with its next. Which is when you fire up,
[01:39:47.520 --> 01:39:53.040]   you fire up the Play Store. This is all after a software update. You fire up the Play Store and
[01:39:53.040 --> 01:39:57.920]   you're asked, do you want to change your search engine from Google to something else? And do you
[01:39:57.920 --> 01:40:03.120]   want to change? Do you want to install another browser? And there are some key differences that
[01:40:03.120 --> 01:40:06.240]   I think need to be worked out. Like, I don't think it's saying, do you want to install this,
[01:40:06.240 --> 01:40:11.120]   remove Chrome and set the new one as your default? It's like, look, there are some other browsers
[01:40:11.120 --> 01:40:14.560]   available. Maybe you want to install them, and that's fine. So, that's what they're doing.
[01:40:15.200 --> 01:40:18.880]   And it's very similar to what Microsoft did. And that was what 10 years ago,
[01:40:18.880 --> 01:40:23.360]   it was in 2009. This is the infamous Windows browser ballot.
[01:40:23.360 --> 01:40:29.760]   These were offered in random order. So, you might get as your very first choice, say, sleep near.
[01:40:29.760 --> 01:40:31.120]   That's all of everything.
[01:40:31.120 --> 01:40:37.920]   This was user friendly. The difference now, the difference now that's so fascinating,
[01:40:37.920 --> 01:40:43.360]   is that at the time, the legislation had come too late. IE was already on the down,
[01:40:44.960 --> 01:40:49.440]   falling down because of, I think, Firefox had overtaken it in Europe at the time that that
[01:40:49.440 --> 01:40:56.640]   settlement was reached. Whereas, at the moment, Chrome, in worldwide figures, Chrome,
[01:40:56.640 --> 01:41:04.080]   specifically on Android, it has close to 90% of the market. IE did not have 90% of the market at
[01:41:04.080 --> 01:41:09.920]   the time that they settled with the EU. So, a lot of people said, well, the browser choice
[01:41:09.920 --> 01:41:15.120]   screen for Windows didn't really affect IE because it was doomed anyway. On this occasion,
[01:41:15.120 --> 01:41:20.320]   I'm very interested to see how it pans out because I don't know why you would switch from
[01:41:20.320 --> 01:41:24.320]   Chrome to something else, or why you would switch from Google to Bing or Duckbit. Well,
[01:41:24.320 --> 01:41:27.040]   I know that one a bit better, actually. I don't know why you'd leave Chrome.
[01:41:27.040 --> 01:41:32.400]   But whether I make a difference, I don't know. But I think it will be more interesting to see
[01:41:32.400 --> 01:41:34.800]   this as the Windows equivalent.
[01:41:34.800 --> 01:41:39.440]   It's really interesting to see how these things have turned around to because on Windows 10,
[01:41:39.440 --> 01:41:44.560]   now Edge is your default. It's pre-installed. If you go to download Chrome, at least in the US,
[01:41:44.560 --> 01:41:50.080]   it's like, you sure you want to do that? Edge is pretty great. You don't want this other browser
[01:41:50.080 --> 01:41:53.840]   on your system. But I guess that's OK legally at this point.
[01:41:53.840 --> 01:41:58.720]   I'm switching my search engine is one of the first things I always do on a new phone. But,
[01:41:58.720 --> 01:42:03.280]   yeah, I don't feel the need to switch to a different browser than Chrome, that's for sure.
[01:42:05.200 --> 01:42:10.560]   I think Chrome, at the time that it came out, there were some really great reasons to use Chrome.
[01:42:10.560 --> 01:42:14.560]   I mean, actually, more so even with Firefox. When Firefox came out, no one was used to this
[01:42:14.560 --> 01:42:19.440]   concept of add-ons and tabbed browsing and things like that. So when that came out, there was this
[01:42:19.440 --> 01:42:24.080]   sudden, just crazy excitement that there was a different way to browse the web and different
[01:42:24.080 --> 01:42:29.360]   way to do things online. And that was great. And then Firefox got very sluggish and slow,
[01:42:29.360 --> 01:42:33.520]   and Chrome came along, and it was just slick and fast, and everything was tied into Google.
[01:42:33.520 --> 01:42:38.000]   And again, that really helped take things, pick up the pace and get people excited about browsers
[01:42:38.000 --> 01:42:44.640]   again. But on Chrome and Android, I don't know what you would want to add or change.
[01:42:44.640 --> 01:42:51.680]   Yeah. I mean, on iOS, you have to use Safari as the default browser period.
[01:42:51.680 --> 01:42:56.400]   On Android, you can take off Chrome. You could put anything you want on it if you care.
[01:42:56.400 --> 01:43:01.280]   And I would submit that most users, maybe not Chrome, but most users want the Google apps.
[01:43:01.920 --> 01:43:05.440]   And this has nothing to do with the fact that Android's laden with Google apps.
[01:43:05.440 --> 01:43:14.000]   So I don't. This seems a lot like the Windows browser ballot issue all over again.
[01:43:14.000 --> 01:43:19.120]   Yeah. And I think you get a point of fatigue at some point where users just go,
[01:43:19.120 --> 01:43:23.760]   "Why are they scrolling with us? I just want to use my phone in the place."
[01:43:23.760 --> 01:43:27.120]   It's another 10 pop-up that I've got to click on.
[01:43:27.120 --> 01:43:28.560]   It is. It's just another pop-up.
[01:43:29.760 --> 01:43:33.440]   I wish, by the way, we need to make a legal all those of the pop-ups.
[01:43:33.440 --> 01:43:38.720]   Can this website notify you for anything? Why would I want notifications from a website?
[01:43:38.720 --> 01:43:40.160]   Oh, that drives me freaking nuts.
[01:43:40.160 --> 01:43:47.440]   Or location alerts. Let this website track your location when you're not even like a map thing.
[01:43:47.440 --> 01:43:48.960]   I don't know what's happened to the modern web.
[01:43:48.960 --> 01:43:53.360]   You can, I believe, go into Chrome or whatever browser you use and say, "Please,
[01:43:53.360 --> 01:43:58.720]   nobody should get notifications. Nobody. Just zero. Don't ask me."
[01:43:59.360 --> 01:44:01.440]   I run into, I run new computers enough.
[01:44:01.440 --> 01:44:02.080]   I know me too.
[01:44:02.080 --> 01:44:03.040]   This is constantly a problem.
[01:44:03.040 --> 01:44:03.280]   Yeah.
[01:44:03.280 --> 01:44:07.280]   And it's like, this is, all these pop- so I agree with you, Nate. And yet it's a shame
[01:44:07.280 --> 01:44:14.080]   because the open web is the best alternative to these silos, these walled gardens, these
[01:44:14.080 --> 01:44:19.600]   gated communities or things like the News Plus app. I don't think it's a good thing for
[01:44:19.600 --> 01:44:25.040]   content to be aggregated, to be disaggregated really from their original source.
[01:44:25.040 --> 01:44:28.400]   And stuck in an app is not good for anybody.
[01:44:28.400 --> 01:44:35.680]   I think it's quite clear too why the web experience is so crummy these days and why there are so
[01:44:35.680 --> 01:44:43.760]   many pop-ups like that saying, "Can we alert you or subscribe to our newsletter? Those newsletter
[01:44:43.760 --> 01:44:48.720]   pop-ups that show up some random number of seconds after you started getting into reading
[01:44:48.720 --> 01:44:50.480]   the thing just when you're really engaged?"
[01:44:51.280 --> 01:44:57.440]   The reason that that's happening is that on publisher news sites and magazines and publishers of any
[01:44:57.440 --> 01:45:02.240]   kind, they're just desperate to make money any way they can because so much of the value has
[01:45:02.240 --> 01:45:07.200]   been sucked out of the advertising ecosystem by the bigger players, by Google and the Facebook.
[01:45:07.200 --> 01:45:13.040]   So they have to do this. They have to throw a bunch of pop-ups at you because they need to
[01:45:13.040 --> 01:45:17.040]   wring out any money that they can from the system and that's all that's left.
[01:45:17.040 --> 01:45:21.520]   It makes me sad because our shows have basically turned into when good tech goes wrong.
[01:45:21.520 --> 01:45:30.960]   The great promise and excitement over tech, the internet, all these interesting gadgets and
[01:45:30.960 --> 01:45:37.440]   computers of the 90s has been replaced by this sad dystopia that we're living in.
[01:45:37.440 --> 01:45:38.320]   Only for the moment.
[01:45:38.320 --> 01:45:39.200]   Only for the moment.
[01:45:39.200 --> 01:45:40.640]   Do you think it's going to pass?
[01:45:40.640 --> 01:45:44.320]   Yeah, of course it'll pass. It's brilliant. People want this to be great.
[01:45:44.320 --> 01:45:47.200]   As long as people want it to be great, then new things will come along.
[01:45:47.200 --> 01:45:52.880]   I think you look at the success of something like Twitter or Blogger was a guy I did it before.
[01:45:52.880 --> 01:45:56.480]   It was successful because of what it didn't have.
[01:45:56.480 --> 01:46:01.360]   That was the reason that Twitter was so good because it didn't have the massive crap that
[01:46:01.360 --> 01:46:04.560]   Facebook's got and people were like, "Yeah, this is great. It's super simple."
[01:46:04.560 --> 01:46:07.600]   So it's what you leave out that becomes what's good about that product.
[01:46:07.600 --> 01:46:13.040]   I think the same will happen for the web in some form. It'll just take a little bit of time.
[01:46:14.080 --> 01:46:18.160]   I had another point to making it's gone out of my head because it's half past 12.
[01:46:18.160 --> 01:46:20.160]   I can't remember what it was. I'm sure it was fascinating.
[01:46:20.160 --> 01:46:23.760]   Well, Game of Thrones starts pretty soon, so don't worry.
[01:46:23.760 --> 01:46:24.480]   This will be over.
[01:46:24.480 --> 01:46:24.960]   It's coming soon.
[01:46:24.960 --> 01:46:29.600]   But Leo to your point, I think we're still used to tech being counterculture too.
[01:46:29.600 --> 01:46:32.480]   Like I wired back in the day. That was everything.
[01:46:32.480 --> 01:46:32.960]   Right.
[01:46:32.960 --> 01:46:34.080]   You were the rebels.
[01:46:34.080 --> 01:46:34.480]   Right.
[01:46:34.480 --> 01:46:36.880]   And now tech is one. Tech is everything.
[01:46:36.880 --> 01:46:37.840]   That sucks, man.
[01:46:37.840 --> 01:46:43.280]   Tech is controlling everything. It's not great, but we can move on to the next stage where we make it better.
[01:46:43.280 --> 01:46:44.720]   We want to be losers again.
[01:46:44.720 --> 01:46:50.720]   Too much winning. I can't take all this winning.
[01:46:50.720 --> 01:46:54.640]   Actually, I thought when I thought Dylan, when you were going to say,
[01:46:54.640 --> 01:46:57.760]   "There's one thing wrong." Really, the thing wrong is ad tech.
[01:46:57.760 --> 01:47:01.200]   But actually, that's not because now it's government pop-ups too.
[01:47:01.200 --> 01:47:03.120]   It's privacy pop-ups, it's alerts.
[01:47:03.120 --> 01:47:03.600]   Hit it.
[01:47:03.600 --> 01:47:04.080]   Yeah.
[01:47:04.080 --> 01:47:04.080]   Yeah.
[01:47:04.080 --> 01:47:06.320]   And then the ad model.
[01:47:06.320 --> 01:47:06.800]   That's the ad model.
[01:47:06.800 --> 01:47:10.080]   I just remembered the point that I was going to make,
[01:47:10.080 --> 01:47:12.640]   which I'm just going to throw out really quickly.
[01:47:13.600 --> 01:47:19.280]   Which is the nature of ads has changed in the point that websites are now having to move to
[01:47:19.280 --> 01:47:26.160]   these affiliate models where they're essentially linking through to products,
[01:47:26.160 --> 01:47:28.880]   and that becomes the way that they're making their money,
[01:47:28.880 --> 01:47:32.080]   because the ad business has been sucked up by Google and Facebook.
[01:47:32.080 --> 01:47:35.200]   And also, the ad business is also full of lies.
[01:47:35.200 --> 01:47:36.560]   So that's a whole thing.
[01:47:36.560 --> 01:47:37.920]   Like everything is falling apart.
[01:47:37.920 --> 01:47:38.160]   Great.
[01:47:38.160 --> 01:47:40.080]   Yeah.
[01:47:40.080 --> 01:47:41.360]   Could you get me, John?
[01:47:42.240 --> 01:47:46.560]   Those crap products that you cleaned up that are on against the wall,
[01:47:46.560 --> 01:47:47.600]   there's two things.
[01:47:47.600 --> 01:47:49.680]   This was, I went to, I can't remember, it was tech-crite.
[01:47:49.680 --> 01:47:51.440]   It was something like Good Sight that I went to.
[01:47:51.440 --> 01:47:54.080]   And I see this more and more.
[01:47:54.080 --> 01:47:58.560]   You nailed it, Nate, because more and more sites are turning to basically,
[01:47:58.560 --> 01:48:01.360]   either if it's not native content, which is horrible,
[01:48:01.360 --> 01:48:03.760]   which is an ad posing as actual content,
[01:48:03.760 --> 01:48:07.840]   to ads for affiliate products.
[01:48:09.520 --> 01:48:12.400]   And they're really just blatant, the Huxterism.
[01:48:12.400 --> 01:48:15.520]   And so I was fooled.
[01:48:15.520 --> 01:48:18.240]   I was on a site that used to be a Good Sight.
[01:48:18.240 --> 01:48:19.440]   I don't know what it way had those.
[01:48:19.440 --> 01:48:22.560]   And it said, "Hey, boy, you got to take advantage of this deal.
[01:48:22.560 --> 01:48:28.080]   You can get a sonic electric toothbrush for like $29.95."
[01:48:28.080 --> 01:48:29.360]   And I thought, "Oh, that's great."
[01:48:29.360 --> 01:48:31.520]   Then I went and I ordered it.
[01:48:31.520 --> 01:48:36.960]   And it's a fake Chinese knockoff of an electric toothbrush
[01:48:36.960 --> 01:48:39.600]   from smilebrightsdoor.com.
[01:48:39.600 --> 01:48:43.760]   Obviously, it was an affiliate link for something terrible.
[01:48:43.760 --> 01:48:46.960]   I ordered two, which was stupid, but the good news is,
[01:48:46.960 --> 01:48:48.800]   well, I was going to give one away.
[01:48:48.800 --> 01:48:50.320]   I thought, "This is too good a deal.
[01:48:50.320 --> 01:48:51.760]   That's $100 toothbrush."
[01:48:51.760 --> 01:48:54.720]   And then the good news is instead of sending me a toothbrush,
[01:48:54.720 --> 01:48:57.520]   they sent me a facebrush for the second one,
[01:48:57.520 --> 01:49:02.080]   which isn't, but it is not, and it is from mylifemyshop.com.
[01:49:02.080 --> 01:49:05.200]   But they're both in this fake mint color.
[01:49:06.160 --> 01:49:10.480]   I'd not even open these because they're clearly just going to explode in my hand
[01:49:10.480 --> 01:49:11.680]   the minute I pipe them in.
[01:49:11.680 --> 01:49:14.560]   It drove me nuts.
[01:49:14.560 --> 01:49:18.240]   And that was used to be a stop.
[01:49:18.240 --> 01:49:20.640]   We have to put a stop to your late night shopping, Leo.
[01:49:20.640 --> 01:49:21.120]   I think that's it.
[01:49:21.120 --> 01:49:23.120]   Well, that's the other thing I want to point out.
[01:49:23.120 --> 01:49:23.760]   Add more.
[01:49:23.760 --> 01:49:24.880]   Add's do work.
[01:49:24.880 --> 01:49:25.600]   I had to stop.
[01:49:25.600 --> 01:49:28.720]   I kind of love this about you, Leo.
[01:49:28.720 --> 01:49:30.080]   You're like, "I have no idea what this is,
[01:49:30.080 --> 01:49:31.200]   but it looks like a pretty deal."
[01:49:31.200 --> 01:49:32.160]   I'm not too!
[01:49:32.160 --> 01:49:32.960]   I'm too!
[01:49:32.960 --> 01:49:35.120]   I'll buy a folding phone.
[01:49:35.120 --> 01:49:35.920]   It said...
[01:49:35.920 --> 01:49:36.960]   I'm too!
[01:49:36.960 --> 01:49:37.520]   It said...
[01:49:37.520 --> 01:49:39.120]   It said...
[01:49:39.120 --> 01:49:40.560]   It said on it...
[01:49:40.560 --> 01:49:42.720]   Oh, and it has a UV sanitizing system.
[01:49:42.720 --> 01:49:47.520]   It said something like sonic toothbrush, but it said it...
[01:49:47.520 --> 01:49:48.480]   Yeah, it does.
[01:49:48.480 --> 01:49:51.120]   The Smile Bright Store Platinum Sonic Toothbrush,
[01:49:51.120 --> 01:49:52.480]   but it's in lowercase S.
[01:49:52.480 --> 01:49:54.800]   That's where I went wrong.
[01:49:54.800 --> 01:50:01.280]   But you know, I did have to stop doing Instagram,
[01:50:01.280 --> 01:50:02.640]   not because I didn't like Instagram.
[01:50:02.640 --> 01:50:03.040]   I don't.
[01:50:03.040 --> 01:50:04.960]   I don't like Facebook, but more because
[01:50:04.960 --> 01:50:06.720]   I kept buying stuff on it.
[01:50:06.720 --> 01:50:07.200]   Oh, man.
[01:50:07.200 --> 01:50:08.480]   Those ads work!
[01:50:08.480 --> 01:50:09.280]   Dangerous.
[01:50:09.280 --> 01:50:10.320]   Those ads work.
[01:50:10.320 --> 01:50:12.400]   So it's possible they get ads at work.
[01:50:12.400 --> 01:50:14.720]   I'd like to think our ads work.
[01:50:14.720 --> 01:50:17.040]   You know what's not working?
[01:50:17.040 --> 01:50:18.800]   This is a great article in the New York Times.
[01:50:18.800 --> 01:50:19.680]   Facebook, apparently.
[01:50:19.680 --> 01:50:20.240]   I didn't know this.
[01:50:20.240 --> 01:50:24.240]   Facebook created something called Summit Learning,
[01:50:24.240 --> 01:50:30.320]   which was an internet learning curriculum.
[01:50:30.320 --> 01:50:32.720]   Promoting an educational approach
[01:50:32.720 --> 01:50:34.000]   called Personalized Learning,
[01:50:34.000 --> 01:50:36.800]   which uses online tools to customize education.
[01:50:36.800 --> 01:50:39.520]   Mark Zuckerberg and Priscilla Chan,
[01:50:39.520 --> 01:50:41.600]   their foundation, funded it.
[01:50:41.600 --> 01:50:44.480]   It was developed by five Facebook engineers.
[01:50:44.480 --> 01:50:46.160]   Mark said, "Go work on this."
[01:50:46.160 --> 01:50:49.600]   It's been rolled out in a number of towns,
[01:50:49.600 --> 01:50:51.840]   particularly towns.
[01:50:51.840 --> 01:50:55.040]   And this was the great high goal of all of this,
[01:50:55.040 --> 01:50:58.560]   towns where schools were underfunded
[01:50:58.560 --> 01:51:00.240]   and the test scores were going down.
[01:51:00.240 --> 01:51:02.320]   Under the program,
[01:51:02.320 --> 01:51:04.880]   students spend much of the day on their laptops,
[01:51:04.880 --> 01:51:07.520]   go online for lessons, plans, and quizzes,
[01:51:07.520 --> 01:51:08.960]   which they completed at their own pace.
[01:51:08.960 --> 01:51:11.280]   Teachers assist students with a workhold
[01:51:11.280 --> 01:51:13.520]   mentoring sessions, lead special products.
[01:51:13.520 --> 01:51:14.960]   The system is free to schools.
[01:51:14.960 --> 01:51:16.480]   The laptops are bought separately.
[01:51:16.480 --> 01:51:18.000]   This sounds great, right?
[01:51:18.000 --> 01:51:19.520]   What could-- this is brilliant.
[01:51:19.520 --> 01:51:23.600]   So almost everywhere Summit Learning is,
[01:51:23.600 --> 01:51:24.720]   people are rebelling.
[01:51:24.720 --> 01:51:27.280]   Students are striking.
[01:51:27.280 --> 01:51:30.000]   According to the New York Times,
[01:51:30.000 --> 01:51:33.520]   the students started coming home with headaches and hand cramps.
[01:51:33.520 --> 01:51:35.040]   Some said they felt more anxious.
[01:51:35.040 --> 01:51:37.520]   One child began having a recurrence of seizures.
[01:51:37.520 --> 01:51:40.480]   Another asked to bring her dad's hunting ear muffs to class
[01:51:40.480 --> 01:51:44.960]   to block out classmates because work was now done largely alone.
[01:51:44.960 --> 01:51:48.640]   Summit's response is,
[01:51:48.640 --> 01:51:51.360]   well, these people have just had an old-fashioned nostalgia
[01:51:51.360 --> 01:51:53.520]   for the old form of education.
[01:51:53.520 --> 01:51:55.200]   But there is a mounting--
[01:51:55.200 --> 01:51:56.560]   - When we didn't have headaches.
[01:51:56.560 --> 01:51:57.840]   - Yeah, no, yeah, no, no, no, no,
[01:51:57.840 --> 01:51:59.280]   head there is a mounting--
[01:51:59.280 --> 01:52:02.080]   According to the Times, a mounting nationwide opposition to Summit.
[01:52:02.080 --> 01:52:06.080]   It's now in 380 schools used by 74,000 students.
[01:52:06.080 --> 01:52:08.640]   In Brooklyn, high school students walked out in November
[01:52:08.640 --> 01:52:10.960]   after their schools started using Summit.
[01:52:10.960 --> 01:52:15.920]   In Indiana, Pennsylvania, 70% of students wanted Summit dropped or made optional.
[01:52:15.920 --> 01:52:20.400]   - Just to be clear, the idea is that this is all like screen learning.
[01:52:20.400 --> 01:52:21.840]   Not like your teacher doing stuff.
[01:52:21.840 --> 01:52:23.200]   - You're on screen, baby.
[01:52:23.200 --> 01:52:27.760]   Here's a sign that popped up in a neighborhood
[01:52:27.760 --> 01:52:30.080]   stomachs are churning with Summit learning.
[01:52:30.080 --> 01:52:34.080]   - They can't do anything, right?
[01:52:34.080 --> 01:52:34.080]   - Wow.
[01:52:34.080 --> 01:52:34.880]   - Man.
[01:52:34.880 --> 01:52:40.080]   - Well, but it also, it's really a perfect example of Facebook,
[01:52:40.080 --> 01:52:47.280]   not Facebook, Silicon Valley's kind of blind belief that technology can fix everything.
[01:52:47.280 --> 01:52:48.480]   - Yes, yeah.
[01:52:48.480 --> 01:52:51.440]   - And that this is gonna go great.
[01:52:51.440 --> 01:52:52.960]   And this is a great way--
[01:52:52.960 --> 01:52:53.840]   And look, I don't--
[01:52:53.840 --> 01:52:56.320]   I think that their motives are pure, that it's non-profit.
[01:52:57.360 --> 01:52:58.400]   - Mm-hmm.
[01:52:58.400 --> 01:53:02.400]   - They sent it to school districts who were underfunded,
[01:53:02.400 --> 01:53:03.760]   where kids weren't doing well.
[01:53:03.760 --> 01:53:07.200]   But it seems to have made the children sick.
[01:53:07.200 --> 01:53:09.360]   (laughing)
[01:53:09.360 --> 01:53:10.720]   - That's so bad.
[01:53:10.720 --> 01:53:13.920]   What are they doing?
[01:53:13.920 --> 01:53:16.000]   What are they doing wrong?
[01:53:16.000 --> 01:53:17.760]   - Oh my God.
[01:53:17.760 --> 01:53:22.640]   - And by the way, programs like this usually get somebody who's familiar with education programming,
[01:53:22.640 --> 01:53:26.320]   like how to build a system like this, and who knows if they even manage to do that.
[01:53:26.320 --> 01:53:30.720]   Because I can't imagine somebody who studied kids in education would be like,
[01:53:30.720 --> 01:53:32.960]   "Let's just have them stare at screens all day,
[01:53:32.960 --> 01:53:35.200]   rather than engage with a human being."
[01:53:35.200 --> 01:53:40.720]   - Well, and I've been on the board of a private school,
[01:53:40.720 --> 01:53:43.520]   and one of the reasons they want me on the board is they say,
[01:53:43.520 --> 01:53:47.200]   "Well, you're a technologist, you can help us be more technology forward."
[01:53:47.200 --> 01:53:50.800]   And I always said, "No, you don't want more technology, you want less technology."
[01:53:50.800 --> 01:53:51.200]   - Yeah.
[01:53:51.200 --> 01:53:52.640]   - "You've got great teachers.
[01:53:52.640 --> 01:53:55.440]   It's the personal relationship the teachers offer the students.
[01:53:56.080 --> 01:53:57.200]   That's most important."
[01:53:57.200 --> 01:54:01.920]   And by the way, if you teach people how to use Microsoft Word by the time they get out of college,
[01:54:01.920 --> 01:54:04.080]   it won't be Microsoft Word.
[01:54:04.080 --> 01:54:06.800]   So you shouldn't teach them technical skills.
[01:54:06.800 --> 01:54:08.560]   You probably shouldn't even teach them coding.
[01:54:08.560 --> 01:54:10.800]   You should teach them things like critical thinking,
[01:54:10.800 --> 01:54:14.800]   you know, deep things that have been around for hundreds of years that are important.
[01:54:14.800 --> 01:54:17.600]   And they'll learn the technology.
[01:54:17.600 --> 01:54:19.360]   I'm not worried about kids in technology.
[01:54:19.360 --> 01:54:20.400]   They're going to learn the technology.
[01:54:20.400 --> 01:54:24.320]   Look at this is Wellington, Kansas, written on the storefront.
[01:54:24.320 --> 01:54:25.920]   Don't plummet with summit.
[01:54:25.920 --> 01:54:27.120]   No proof of success.
[01:54:27.120 --> 01:54:29.520]   Summit equals summer schools.
[01:54:29.520 --> 01:54:30.480]   Stop the lies.
[01:54:30.480 --> 01:54:32.160]   Wow.
[01:54:32.160 --> 01:54:36.080]   I mean, there's like this grassroots hatred of this thing.
[01:54:36.080 --> 01:54:40.240]   I love that it's the kids like rebelling against it too,
[01:54:40.240 --> 01:54:41.680]   which I think is powerful.
[01:54:41.680 --> 01:54:41.920]   Yeah.
[01:54:41.920 --> 01:54:42.480]   That's good.
[01:54:42.480 --> 01:54:42.960]   Yeah.
[01:54:42.960 --> 01:54:45.840]   I also think it's kind of funny that Summit says,
[01:54:45.840 --> 01:54:48.160]   "Oh, that's just nostalgia for the old way of learning."
[01:54:48.160 --> 01:54:51.040]   Just get used to the seizures.
[01:54:51.040 --> 01:54:52.240]   Yes.
[01:54:52.240 --> 01:54:53.040]   Sagers.
[01:54:53.040 --> 01:54:55.200]   It was causing seizures in one child.
[01:54:55.920 --> 01:54:57.760]   Because she was supposed to, you know, doctor said,
[01:54:57.760 --> 01:54:59.040]   "Oh, she'd only give her 30 minutes.
[01:54:59.040 --> 01:55:00.000]   She's got epilepsy.
[01:55:00.000 --> 01:55:01.200]   She only have 30 minutes of screen time.
[01:55:01.200 --> 01:55:01.840]   It's bad for her."
[01:55:01.840 --> 01:55:03.360]   So it just made her...
[01:55:03.360 --> 01:55:05.760]   Anyway, I just...
[01:55:05.760 --> 01:55:07.760]   I thought that was interesting.
[01:55:07.760 --> 01:55:12.880]   There are times is asking people who use Summit to respond to a questionnaire
[01:55:12.880 --> 01:55:14.880]   and gather more information about it.
[01:55:14.880 --> 01:55:18.640]   But I think that that's a perfect example of the high hopes of Silicon Valley,
[01:55:18.640 --> 01:55:20.400]   the magic that we thought was going to happen.
[01:55:20.400 --> 01:55:24.560]   Well, not to beat up on Facebook anymore,
[01:55:24.560 --> 01:55:25.440]   although I'm about to.
[01:55:25.440 --> 01:55:27.120]   Please do.
[01:55:27.120 --> 01:55:30.640]   I have a little anecdote because I think this speaks to kids
[01:55:30.640 --> 01:55:32.320]   and their attitudes towards things.
[01:55:32.320 --> 01:55:34.320]   I was talking to my daughter earlier this week,
[01:55:34.320 --> 01:55:36.240]   and she's 18 senior in high school.
[01:55:36.240 --> 01:55:43.680]   I said something like, "Oh, maybe I should go work for a non-profit or something.
[01:55:43.680 --> 01:55:45.440]   At some point, I want to go do some good in the world."
[01:55:45.440 --> 01:55:46.480]   And she's like, "Oh, don't worry, Dad.
[01:55:46.480 --> 01:55:48.720]   Your company does good things that you work for now."
[01:55:48.720 --> 01:55:49.280]   It's nice.
[01:55:49.280 --> 01:55:49.920]   Yeah.
[01:55:49.920 --> 01:55:50.800]   Which was very sweet.
[01:55:50.800 --> 01:55:54.240]   And then she added, "And anyway, it's not like you work for Facebook
[01:55:54.240 --> 01:55:54.720]   or anything."
[01:55:54.720 --> 01:55:56.880]   I was like, "Whoa."
[01:55:56.880 --> 01:55:58.000]   It could be worse, Dad.
[01:55:58.000 --> 01:56:04.000]   So she has a very low opinion of Facebook and her costs.
[01:56:04.000 --> 01:56:07.680]   Apparently, people under 25, nobody's using Facebook.
[01:56:07.680 --> 01:56:08.560]   Yeah.
[01:56:08.560 --> 01:56:10.880]   She does use Instagram.
[01:56:10.880 --> 01:56:11.760]   Yeah.
[01:56:11.760 --> 01:56:12.720]   And they don't realize that.
[01:56:12.720 --> 01:56:13.120]   They don't know.
[01:56:13.120 --> 01:56:13.680]   And what's that?
[01:56:13.680 --> 01:56:17.120]   She knows, but she still uses it.
[01:56:17.120 --> 01:56:17.600]   So.
[01:56:17.600 --> 01:56:21.120]   Well, Instagram isn't nearly as intrusive or obnoxious as Facebook,
[01:56:21.120 --> 01:56:25.440]   although again, every ninth post, there's an ad, and I fall for every one of them.
[01:56:25.440 --> 01:56:30.640]   Instagram hasn't thrown any elections yet either, I don't think.
[01:56:30.640 --> 01:56:31.200]   Oh, no.
[01:56:31.200 --> 01:56:31.920]   Oh, wait a minute.
[01:56:31.920 --> 01:56:32.800]   No, that's not true.
[01:56:32.800 --> 01:56:33.520]   Yeah.
[01:56:33.520 --> 01:56:35.440]   Really?
[01:56:35.440 --> 01:56:42.880]   Now, I'm trying to remember the story, but there are a number of weird fake Instagram accounts,
[01:56:42.880 --> 01:56:46.320]   fake Instagram accounts designed to sway public opinion.
[01:56:46.320 --> 01:56:49.040]   There's a lot of weird stuff that happens on Instagram.
[01:56:49.040 --> 01:56:49.280]   Yeah.
[01:56:49.280 --> 01:56:50.320]   There's weird stuff.
[01:56:50.320 --> 01:56:50.720]   That's true.
[01:56:50.720 --> 01:56:52.720]   I just haven't seen any, yeah.
[01:56:52.720 --> 01:56:54.320]   Actually, I should look into that more.
[01:56:54.320 --> 01:56:54.800]   No, yeah.
[01:56:54.800 --> 01:56:59.520]   It's going to get there because they want to integrate Instagram with WhatsApp and
[01:56:59.520 --> 01:57:02.320]   Facebook Messenger and everything too, like to put it all under one system.
[01:57:02.320 --> 01:57:04.880]   So it's a great way to get all that spam everywhere.
[01:57:04.880 --> 01:57:06.400]   Yes.
[01:57:06.400 --> 01:57:11.200]   And of course, yeah, there's no, the thing about Instagram, you don't have to,
[01:57:11.200 --> 01:57:13.120]   if you don't follow it, you don't see it.
[01:57:13.120 --> 01:57:18.640]   So, you know, let's take a little break and then I'm going to give you some happy.
[01:57:18.640 --> 01:57:19.760]   We're going to find some happiness.
[01:57:19.760 --> 01:57:24.880]   We're going to find one way, at least one way, the technology has made your life better this week.
[01:57:24.880 --> 01:57:27.600]   Carson, can you get on that?
[01:57:27.600 --> 01:57:29.520]   You've got one minute.
[01:57:29.520 --> 01:57:32.160]   I'm looking, I'm looking just one way.
[01:57:32.160 --> 01:57:33.040]   That's all I ask.
[01:57:33.040 --> 01:57:34.240]   All right.
[01:57:34.240 --> 01:57:34.880]   I got one.
[01:57:34.880 --> 01:57:36.640]   I'll tell you one way that my life is better.
[01:57:36.640 --> 01:57:38.640]   I'm wearing them right now, my simple contacts,
[01:57:38.640 --> 01:57:44.400]   simple contacts, a very easy way to get contact lenses, but I have to say,
[01:57:44.400 --> 01:57:47.360]   I always run out, right?
[01:57:47.360 --> 01:57:49.520]   And then I got, oh, I got to make an appointment.
[01:57:49.520 --> 01:57:51.280]   I got a renewable prescription.
[01:57:51.280 --> 01:57:53.120]   So, I found simple contacts.
[01:57:53.120 --> 01:57:53.680]   It's an app.
[01:57:53.680 --> 01:57:54.400]   It's awesome.
[01:57:54.400 --> 01:58:00.480]   It actually makes the time consuming process of renewing your contact lens prescription
[01:58:00.480 --> 01:58:03.680]   very easy because you actually use the app.
[01:58:03.680 --> 01:58:05.840]   It brings the doctor's office to your home.
[01:58:05.840 --> 01:58:06.880]   It was so fun.
[01:58:06.880 --> 01:58:07.920]   I set the phone up.
[01:58:07.920 --> 01:58:10.080]   You have to get a certain distance for the phone.
[01:58:10.080 --> 01:58:11.520]   They give you an eye test.
[01:58:11.520 --> 01:58:12.720]   You do a video of it.
[01:58:12.720 --> 01:58:15.200]   And then it's reviewed by a doctor.
[01:58:15.200 --> 01:58:19.120]   I explained some things that are unusual about my vision.
[01:58:19.120 --> 01:58:20.240]   They contacted me.
[01:58:20.240 --> 01:58:21.040]   They said, great.
[01:58:21.040 --> 01:58:21.520]   Okay.
[01:58:21.520 --> 01:58:23.200]   It's the eye exam is $20.
[01:58:23.200 --> 01:58:25.280]   And then you buy the contacts.
[01:58:25.280 --> 01:58:27.280]   And it's very easy.
[01:58:27.280 --> 01:58:29.600]   And I saved 100 bucks on the contacts.
[01:58:29.600 --> 01:58:32.240]   I used to order them from another online place.
[01:58:32.240 --> 01:58:33.360]   It was 100 bucks less.
[01:58:33.360 --> 01:58:35.840]   Simple contacts.
[01:58:35.840 --> 01:58:37.520]   Now, you should go in.
[01:58:37.520 --> 01:58:41.040]   We're not saying you should replace your periodic full eye health exam.
[01:58:41.040 --> 01:58:42.160]   They, you know, the Puff test.
[01:58:42.160 --> 01:58:44.640]   And for me, I have type two diabetes.
[01:58:44.640 --> 01:58:47.040]   I got to get a picture of my retina every year and stuff like that.
[01:58:47.040 --> 01:58:48.080]   So I still believe me.
[01:58:48.080 --> 01:58:48.960]   I still do that.
[01:58:48.960 --> 01:58:51.440]   But when I run out of contacts and I need to renew,
[01:58:51.440 --> 01:58:53.120]   this is so much easier.
[01:58:53.120 --> 01:58:56.480]   I get great contact lenses and I get them for less.
[01:58:56.480 --> 01:58:58.960]   In fact, we're going to get you even better deal.
[01:58:58.960 --> 01:59:01.360]   You could save $20 on your first simple contacts order.
[01:59:01.360 --> 01:59:04.160]   That in fact makes the eye exam free, right?
[01:59:04.160 --> 01:59:06.720]   Go to simple contacts.com/twit.
[01:59:06.720 --> 01:59:08.720]   Use the promo code TWIT at checkout.
[01:59:08.720 --> 01:59:10.800]   Simple contacts.
[01:59:10.800 --> 01:59:12.560]   I don't know how you get your contact lenses.
[01:59:12.560 --> 01:59:16.400]   I love my eye doctor, but you know what?
[01:59:16.400 --> 01:59:18.240]   He tried just like three times more.
[01:59:18.880 --> 01:59:21.520]   So I started getting them online.
[01:59:21.520 --> 01:59:23.680]   And now I found simple contacts.
[01:59:23.680 --> 01:59:25.120]   Not only can I get them online for less,
[01:59:25.120 --> 01:59:27.600]   but I get the prescription renewed as easily.
[01:59:27.600 --> 01:59:29.040]   It just takes a minute.
[01:59:29.040 --> 01:59:30.960]   Simple contacts.com/twit.
[01:59:30.960 --> 01:59:33.600]   Use the promo code TWIT at checkout.
[01:59:33.600 --> 01:59:34.480]   I'm a big fan.
[01:59:34.480 --> 01:59:36.880]   I got a year's worth a year's supply.
[01:59:36.880 --> 01:59:38.080]   I'm wearing them right now.
[01:59:38.080 --> 01:59:38.640]   Can you tell?
[01:59:38.640 --> 01:59:41.040]   Simple contacts.com/twit.
[01:59:41.040 --> 01:59:42.160]   We thank you for their support.
[01:59:42.160 --> 01:59:45.840]   And we thank you for supporting us by using that offer code TWIT.
[01:59:45.840 --> 01:59:47.360]   You'll save $20.
[01:59:48.320 --> 01:59:49.680]   Okay, a couple of bad things.
[01:59:49.680 --> 01:59:52.320]   Horrific attacks in Sri Lanka.
[01:59:52.320 --> 01:59:55.280]   Just terrible.
[01:59:55.280 --> 01:59:56.720]   Last I saw 200 deaths.
[01:59:56.720 --> 01:59:59.200]   A lot of tourists, it's Easter.
[01:59:59.200 --> 02:00:01.280]   The Catholic churches were attacked.
[02:00:01.280 --> 02:00:02.640]   Tourists locations were attacked.
[02:00:02.640 --> 02:00:04.000]   Interesting though.
[02:00:04.000 --> 02:00:06.080]   The first thing the Sri Lankan government did is
[02:00:06.080 --> 02:00:08.560]   take, turn off Facebook, Instagram, and Twitter.
[02:00:08.560 --> 02:00:09.760]   They turned off social networks.
[02:00:09.760 --> 02:00:11.280]   What do you think?
[02:00:11.280 --> 02:00:12.320]   Is that the right thing to do?
[02:00:12.320 --> 02:00:16.640]   Probably, I mean, what we saw happened immediately
[02:00:16.640 --> 02:00:19.200]   after those attacks was a lot of misinformation spreading too.
[02:00:19.200 --> 02:00:19.760]   Yes.
[02:00:19.760 --> 02:00:22.560]   So probably the smart move in the midst of like,
[02:00:22.560 --> 02:00:24.400]   yeah, a major terrorist event or something.
[02:00:24.400 --> 02:00:29.680]   When Notre Dame caught on fire, my wife told me it was a terrorist attack
[02:00:29.680 --> 02:00:31.920]   because she'd been watching a YouTube feed.
[02:00:31.920 --> 02:00:35.840]   And YouTube paired it with a 9/11 Wikipedia article.
[02:00:35.840 --> 02:00:40.000]   YouTube initially misidentified it as a terrorist attack.
[02:00:40.000 --> 02:00:44.000]   And so it's very easy, even though YouTube fixed that quickly,
[02:00:44.000 --> 02:00:45.680]   for those things to accident.
[02:00:45.680 --> 02:00:46.480]   And they escalate.
[02:00:46.480 --> 02:00:50.720]   The YouTube one was automated.
[02:00:50.720 --> 02:00:51.040]   Yes.
[02:00:51.040 --> 02:00:53.280]   And YouTube apologized and they fixed it quickly.
[02:00:53.280 --> 02:00:56.880]   But nevertheless, it caused that misapprehension.
[02:00:56.880 --> 02:00:58.960]   And both she and I were like devastated for an hour
[02:00:58.960 --> 02:01:00.560]   until I figured out that it wasn't.
[02:01:00.560 --> 02:01:02.960]   I thought that's awful.
[02:01:02.960 --> 02:01:03.760]   Who would do that?
[02:01:03.760 --> 02:01:08.000]   I'm sorry, you were saying something Dylan?
[02:01:08.000 --> 02:01:14.960]   Yeah, I guess I was going to say as long as the social networks
[02:01:14.960 --> 02:01:19.840]   are unable to or unwilling to shut down the spread of panic.
[02:01:19.840 --> 02:01:25.680]   I mean, it makes sense that governments like Sri Lanka are going to do exactly that.
[02:01:25.680 --> 02:01:26.640]   They're going to do it for them.
[02:01:26.640 --> 02:01:32.560]   Apple and Google blocking TikTok in India at the request,
[02:01:32.560 --> 02:01:35.200]   actually the order of the Indian government.
[02:01:35.200 --> 02:01:37.120]   I'm not sure how TikTok is dangerous.
[02:01:37.120 --> 02:01:40.240]   All those memes.
[02:01:40.240 --> 02:01:40.720]   Porn.
[02:01:40.720 --> 02:01:41.440]   And music.
[02:01:41.440 --> 02:01:42.640]   Is there porn on TikTok?
[02:01:42.640 --> 02:01:43.040]   Too much.
[02:01:44.720 --> 02:01:45.200]   Really?
[02:01:45.200 --> 02:01:45.920]   Is that why they shouldn't?
[02:01:45.920 --> 02:01:46.800]   Porn on everything.
[02:01:46.800 --> 02:01:49.200]   I guess that's what they said.
[02:01:49.200 --> 02:01:49.840]   That's what they said.
[02:01:49.840 --> 02:01:56.160]   I mean, mostly what I saw in TikTok is like teenagers doing karaoke sing-alongs
[02:01:56.160 --> 02:01:58.160]   and vine style videos.
[02:01:58.160 --> 02:01:59.680]   But I guess you can't, you know.
[02:01:59.680 --> 02:02:02.080]   Well, hey, good news.
[02:02:02.080 --> 02:02:06.400]   At least in the UK, you'll be protected.
[02:02:06.400 --> 02:02:08.720]   They're going to introduce porn age checks in July.
[02:02:08.720 --> 02:02:10.960]   Yeah.
[02:02:10.960 --> 02:02:11.840]   Another pop up?
[02:02:11.840 --> 02:02:13.200]   Another pop up.
[02:02:13.200 --> 02:02:15.520]   Uh, no.
[02:02:15.520 --> 02:02:22.160]   Well, they want to make all websites, like commercially popular websites,
[02:02:22.160 --> 02:02:25.200]   put up an age gate,
[02:02:25.200 --> 02:02:28.320]   asks you to prove how old you are.
[02:02:28.320 --> 02:02:30.320]   And there are several things that are wrong with this.
[02:02:30.320 --> 02:02:37.600]   The first is that the, sort of the group responsible for determining which
[02:02:37.600 --> 02:02:42.880]   websites need to put up these age gates is the group that assigns age ratings
[02:02:43.120 --> 02:02:45.840]   to movies and games and things like that.
[02:02:45.840 --> 02:02:53.360]   Which is a very well-intentioned group, but is not especially this group and has banned some
[02:02:53.360 --> 02:02:57.440]   some sexual acts.
[02:02:57.440 --> 02:02:59.440]   I'm trying to be very family-friendly here.
[02:02:59.440 --> 02:03:03.200]   From appearing in commercially available pornography that I think is
[02:03:03.200 --> 02:03:07.440]   questionable while allowing certain other things.
[02:03:07.440 --> 02:03:12.160]   And the other thing is that the way that, well, one of the ways that you're going to be able to
[02:03:12.160 --> 02:03:19.120]   prove your age is by scanning your passport or driver's license and uploading it to a company
[02:03:19.120 --> 02:03:25.200]   who I looked into the company is a company called MindGeek, which runs websites like
[02:03:25.200 --> 02:03:25.840]   Pornhub.
[02:03:25.840 --> 02:03:28.480]   Yeah, MindGeek is, runs them all basically.
[02:03:28.480 --> 02:03:30.000]   They're the biggest of the bunch here.
[02:03:30.000 --> 02:03:37.440]   So you go to Pornhub and it says, okay, you can watch, but first upload your passport
[02:03:37.440 --> 02:03:39.520]   or driver's license.
[02:03:39.520 --> 02:03:41.760]   What could possibly go wrong?
[02:03:42.400 --> 02:03:49.360]   You know, and it's very easy to laugh about this and you should in many, for many, many reasons.
[02:03:49.360 --> 02:03:53.920]   But the really worrying thing is that you look at what has happened in the past.
[02:03:53.920 --> 02:03:59.520]   And we talked about this earlier, I think with the mental health app that was allowing,
[02:03:59.520 --> 02:04:03.920]   or it was mental health app or the fertility apps that were sharing data,
[02:04:03.920 --> 02:04:09.760]   is the problems that can happen when a very personal preference, whether that's
[02:04:10.960 --> 02:04:16.160]   a mental health condition or sexuality or what have you, is then associated with a real world
[02:04:16.160 --> 02:04:18.160]   identifier leaking out.
[02:04:18.160 --> 02:04:23.360]   Because in many countries where we do have very liberal populations, that's okay.
[02:04:23.360 --> 02:04:26.240]   You know, I'll say it's okay, it's not, it's terrible, it shouldn't happen.
[02:04:26.240 --> 02:04:31.520]   But you're not going to get stoned to death for being homosexual.
[02:04:31.520 --> 02:04:36.960]   Whereas there are many countries in the world where you potentially could be in some very serious
[02:04:36.960 --> 02:04:42.960]   life-threatening danger if certain aspects of your personality or sexuality or whatever were
[02:04:42.960 --> 02:04:48.240]   leaked. And I find it very worrying that that's something that we're essentially relying on,
[02:04:48.240 --> 02:04:54.640]   not happening in order to allow something like a pornography site to operate legally.
[02:04:54.640 --> 02:05:02.400]   I have to assume that really the plan of whoever created this, I presume, parliament
[02:05:02.960 --> 02:05:09.520]   is not so much to get age identification as to just turn people away, like to stop using it.
[02:05:09.520 --> 02:05:14.480]   If you're gay and you provide your passport to a site so you can watch gay videos,
[02:05:14.480 --> 02:05:16.640]   that seems a very risky thing to do.
[02:05:16.640 --> 02:05:21.040]   Yeah, I mean, it seems like it might be a GDPR problem.
[02:05:21.040 --> 02:05:26.160]   And it's a yes. And it feels like what they're figuring is, well, just people will go walk away,
[02:05:26.160 --> 02:05:29.440]   they're not going to do it. By the way, there's another way you don't have to,
[02:05:29.440 --> 02:05:36.720]   you can also go to a news agent and buy a, what they call a porn pass, an age verification card,
[02:05:36.720 --> 02:05:40.560]   not only the news agent will know who you are.
[02:05:40.560 --> 02:05:47.920]   Yeah. And that costs about five pounds, it's sort of six or seven bucks or something like that.
[02:05:47.920 --> 02:05:52.800]   But now you have to carry a porn pass in your wallet, which doesn't seem like a good idea either.
[02:05:52.800 --> 02:05:55.600]   I mean, someone said to me not long ago,
[02:05:57.520 --> 02:06:01.120]   people are just going to be too embarrassed to walk into a shop and buy a porn pass.
[02:06:01.120 --> 02:06:04.480]   And I said, well, I remember being, you know, 11, 12 years old.
[02:06:04.480 --> 02:06:09.360]   And I remember what you did is you put the dirty magazine inside a very respectable newspaper
[02:06:09.360 --> 02:06:14.400]   and then pay for the newspaper. And that was a very good way of getting around that embarrassing.
[02:06:14.400 --> 02:06:19.920]   But yeah, the bottom line is that there are good intentions behind the law,
[02:06:19.920 --> 02:06:24.240]   which is to protect children from accidentally stumbling on porn on the problem.
[02:06:24.240 --> 02:06:26.880]   And that's a very difficult thing to do in the modern internet.
[02:06:26.880 --> 02:06:31.680]   Very difficult. But the problem is, is how many kids are accidentally stumbling
[02:06:31.680 --> 02:06:36.240]   on pornography websites like this? They're not. If they're going to those websites,
[02:06:36.240 --> 02:06:40.000]   it's because they're typing it in. What they're stumbling across it, sorry,
[02:06:40.000 --> 02:06:44.560]   where they're stumbling across it are things like Twitter, Tumblr, messaging apps, TikTok.
[02:06:44.560 --> 02:06:48.960]   We just talked about that. And they're not covered by this because they don't fall
[02:06:48.960 --> 02:06:52.960]   under the criteria of a third or more of their content being pornographic in nature.
[02:06:52.960 --> 02:06:57.440]   So the places where kids are accidentally stumbling on it aren't getting covered by
[02:06:57.440 --> 02:07:01.600]   this at all. And the places. But go ahead and do a Google search for Snow White and the
[02:07:01.600 --> 02:07:05.600]   Seven Dwarfs and see what you find. Do I want to? No.
[02:07:05.600 --> 02:07:12.720]   That's the problem. Is that a lot of the stuff that you would might innocently search for
[02:07:12.720 --> 02:07:19.280]   turns up results that are reprehensible or just certainly not appropriate for the
[02:07:20.080 --> 02:07:25.920]   child. I don't know what the answer is. I mean, in the States, people put filtering programs on.
[02:07:25.920 --> 02:07:31.440]   They don't work very well. I don't know. I suppose, I mean, I think it's a case of you
[02:07:31.440 --> 02:07:35.280]   have to be seen to be doing something. Because if you're not seen to be doing something,
[02:07:35.280 --> 02:07:40.080]   then it looks like you don't care. The problem is, is that I don't think this is a good solution.
[02:07:40.080 --> 02:07:44.400]   And I don't think enough consultation with people who know about this kind of stuff.
[02:07:44.400 --> 02:07:49.440]   I don't think enough of that has happened to inform the decision here. I think people have just
[02:07:49.440 --> 02:07:54.480]   agreed that, yes, stopping kids accidentally seeing pornography is a good thing. I don't think too
[02:07:54.480 --> 02:08:00.640]   many people would disagree with that in general. But this is the wrong way to go about it. I think
[02:08:00.640 --> 02:08:05.200]   it's a problem. It's very troubling. I don't think there's any good answer. And I really feel
[02:08:05.200 --> 02:08:10.080]   bad for a generation of children is growing up basically without innocence of any kind.
[02:08:10.080 --> 02:08:15.680]   Some may say, oh, that's without ignorance of any kind. But I don't think so because the stuff
[02:08:15.680 --> 02:08:25.600]   that kids are seeing in porn is not normal love, not normal sexuality, but a bizarre kind of sexuality.
[02:08:25.600 --> 02:08:31.840]   And I see it in kids. They don't have that innocence anymore. And I think that's sad.
[02:08:31.840 --> 02:08:38.800]   All right, Carsten, did you find a good story? I found three. Oh, man, you win.
[02:08:38.800 --> 02:08:43.120]   Would be a security one, a products one, or a gaming one.
[02:08:43.120 --> 02:08:46.480]   All right, let's start with security. Okay, the security one is
[02:08:46.480 --> 02:08:56.160]   strangely enough in Utah. Utah bans police. Thank God. From searching digital data without a warrant,
[02:08:56.160 --> 02:09:01.600]   first state in the nation to ban warrantless searches of electronic data. Did you know that
[02:09:01.600 --> 02:09:07.680]   was legal? One wouldn't think so. Under the electronic information or Data Privacy Act,
[02:09:07.680 --> 02:09:13.520]   HP 57 state law enforcement can only access someone's transmitted or stored digital data.
[02:09:13.520 --> 02:09:19.680]   That would include emails, writing images, audio. If a court issues, a search warrant based on probable
[02:09:19.680 --> 02:09:25.040]   cause, the act ensures that search engines, email providers, social media, cloud storage,
[02:09:25.040 --> 02:09:29.200]   and any other third party electronic communication service, remote computing service,
[02:09:29.200 --> 02:09:35.680]   is fully protected under the fourth amendment. Hallelujah.
[02:09:37.120 --> 02:09:42.960]   That's a great president. Let's hope it sticks. Yeah, one state, but it's a start.
[02:09:42.960 --> 02:09:47.600]   Very good. Okay, that's good. You win, Carsten. Give me another one.
[02:09:47.600 --> 02:09:53.280]   The second story concerns Google and Amazon coming to terms.
[02:09:53.280 --> 02:09:58.640]   I know. Is this a good story? I don't know. Amazon and Google have settled their feud,
[02:09:58.640 --> 02:10:04.720]   which means now what? You can buy fire devices. It's a fire TV owners who didn't have you to
[02:10:04.720 --> 02:10:08.960]   for a year because of this fat. That was super dumb. YouTube is back on fire TV. Remember when
[02:10:08.960 --> 02:10:15.040]   you couldn't watch YouTube on Apple TV? Well, this was like that. They're so petty. These
[02:10:15.040 --> 02:10:20.640]   companies are so petty. I actually don't like fire TV because it just seems like a big ad for Amazon.
[02:10:20.640 --> 02:10:25.440]   Is anyone using it? I have it. I have the cube because you could talk to it.
[02:10:25.440 --> 02:10:30.080]   I think it's also very popular because we were talking about like default browsers and stuff.
[02:10:30.080 --> 02:10:34.800]   Amazon really pushes their default hardware. So people looking for streaming sticks or something,
[02:10:34.800 --> 02:10:40.240]   I think most of the people who are using fire TV sticks are using it to pirate stuff to be honest.
[02:10:40.240 --> 02:10:43.440]   Yes. That's the real answer to that question.
[02:10:43.440 --> 02:10:55.680]   Finally, you said you have a gaming story. Yes. Just this week, Nintendo released a patch or
[02:10:55.680 --> 02:11:02.480]   an update to Super Smash Bros. Ultimate that lets you make your own stages.
[02:11:02.480 --> 02:11:10.800]   Lots of people are making lots of cool stages. You are a geek. I am a geek. My son has actually
[02:11:10.800 --> 02:11:18.800]   created his own Twit-based Super Smash Bros. level, but I can't show it to you because it has some...
[02:11:18.800 --> 02:11:22.960]   It violates our copyright? Violates somebody else's copyright. There's a
[02:11:24.560 --> 02:11:30.960]   that violates somebody else's copyright, but I will put it in the show notes for our audience to...
[02:11:30.960 --> 02:11:34.800]   Are you saying you want to avoid yet another YouTube takedown of this fine program?
[02:11:34.800 --> 02:11:36.320]   Yeah, yeah. I kind of...
[02:11:36.320 --> 02:11:37.840]   Jerry, you get really mad at me.
[02:11:37.840 --> 02:11:42.960]   So far, I don't think we've done anything that YouTube would hold against us, but let's not start.
[02:11:42.960 --> 02:11:51.040]   I thought you... By the way, that is very good news. I guess. I don't know. I thought you might
[02:11:51.040 --> 02:11:58.080]   say something about this, Assassin's Creed Unity, which among other things takes place in Notre-Dame.
[02:11:58.080 --> 02:12:04.240]   In order to make it, they laser scan the entire cathedral a couple of years ago,
[02:12:04.240 --> 02:12:12.880]   and those laser scans, which are incredibly detailed, will be used to reconstruct the cathedral.
[02:12:12.880 --> 02:12:16.000]   That's pretty cool. The best thing to come out of a terrible game. It's great.
[02:12:16.000 --> 02:12:20.000]   Is it a terrible game? It's really bad. Centuriously like buggy and Russian.
[02:12:20.000 --> 02:12:24.720]   Yeah, yeah. This is pretty cool. I'm surprised where you guys excited by the PlayStation 5
[02:12:24.720 --> 02:12:29.200]   hardware too, because that or whatever that's going to be called, because the bits we heard
[02:12:29.200 --> 02:12:36.160]   were pretty cool. So this was a leak or... No, it was an exclusive... Just a hint at the hardware
[02:12:36.160 --> 02:12:41.760]   that Wired got. Oh, all right. Yeah, because E3 is coming up, so we're going to learn a lot more.
[02:12:41.760 --> 02:12:46.160]   Well, they're not participating in E3. So that's the big thing this year.
[02:12:46.160 --> 02:12:51.200]   It's Sony is doing its own thing. They're doing these video direct announcements like Nintendo's
[02:12:51.200 --> 02:12:54.640]   been doing. So we got a glimpse of this hardware and it seems pretty cool.
[02:12:54.640 --> 02:12:59.920]   7-nanometer Zen processor 8-core processor. That's one of the AMD Ryzen
[02:12:59.920 --> 02:13:06.880]   processor. 7-nanometers, wow. 7-nanometers and upcoming GPU. I think they're really...
[02:13:06.880 --> 02:13:11.840]   All the hardware you'd expect. One of the things they really mentioned though is this next generation
[02:13:11.840 --> 02:13:20.720]   SSD technology may be using the next version of PCIE, I guess, but it's supposedly going to be
[02:13:20.720 --> 02:13:25.440]   able to load games almost instantly. I think that's huge, because that's been the big problem for
[02:13:25.440 --> 02:13:29.840]   gaming consoles is the past few generations. You're installing games, they have to go the hard drive,
[02:13:29.840 --> 02:13:33.920]   you have to wait for them to load, you're using slow, rotating laptop hard drives.
[02:13:33.920 --> 02:13:40.160]   Not great. So having an SSD, maybe an NVMe type thing that loads super quickly, that could be huge.
[02:13:40.960 --> 02:13:47.840]   This new GPU, they're going to use much like the new Nvidia RTX GPUs will support
[02:13:47.840 --> 02:13:52.720]   hardware ray tracing. We're not quite sure what that means, but yeah, it could.
[02:13:52.720 --> 02:13:58.960]   Well, that could be huge. That allows games to do amazing realistic lighting and smoke effects
[02:13:58.960 --> 02:14:05.680]   and so forth. Ray tracing is a really neat technology. We saw an update of... What was it?
[02:14:05.680 --> 02:14:11.200]   Doom done and ray traced with the new... Quake 2? Oh, it was Quake 2. That's what it was. Yeah,
[02:14:11.200 --> 02:14:16.400]   with a new Nvidia processor and it was really beautiful. It looks amazing. I mean, that tech
[02:14:16.400 --> 02:14:22.080]   has a huge potential. The PC side hasn't really seen many games supported, but I think as it comes
[02:14:22.080 --> 02:14:26.960]   to consoles and developers like learn to use it, that could be huge. That could be amazing.
[02:14:26.960 --> 02:14:31.600]   We still don't quite know what that means though. We don't know if it's like dedicated ray tracing
[02:14:31.600 --> 02:14:37.120]   hardware. Like that's on the Nvidia cards or are they going to do it through other processing
[02:14:37.120 --> 02:14:41.840]   means which could be more costly. There's still a lot left up in the air. I'm just really excited
[02:14:41.840 --> 02:14:45.840]   about the loading thing and it sounds like the hardware is going to be a step up all around.
[02:14:45.840 --> 02:14:50.240]   And you didn't mention the most important number. It will be potentially 8K.
[02:14:50.240 --> 02:14:57.680]   Not even. Let's not go down this road. Anybody talking about 8K right now is a liar and broad
[02:14:57.680 --> 02:15:02.160]   and they're trying to sell you something because yeah, they're saying like, oh yeah, it could
[02:15:02.160 --> 02:15:07.040]   potentially run a K maybe for like a 2D stick figure game or something because the amount of
[02:15:07.040 --> 02:15:14.720]   processing power needed for AK at a native resolution is insane. If you add a K to 5G,
[02:15:14.720 --> 02:15:21.520]   you're going to get 13 GK. It's going to be amazing. It's going to be amazing. It's going to be
[02:15:21.520 --> 02:15:29.360]   amazing. That's by the way. I just I'm going to patent 13 KG 13 kilograms. That's the new acronym
[02:15:29.360 --> 02:15:33.520]   for the brand new tech century that Nate says is going to be amazing.
[02:15:33.520 --> 02:15:38.880]   Thank you. Thank you for all the bands with all the resolution.
[02:15:38.880 --> 02:15:43.440]   All the bandwidth you could possibly handle. And it's going to fix all the moral problems
[02:15:43.440 --> 02:15:48.480]   with the current generation. Absolutely. Facebook will suddenly be private and secure just like Mark
[02:15:48.480 --> 02:15:58.080]   promised. Nate Langston, thank you so much for being here. He is a tech editor at Bloomberg.
[02:15:58.080 --> 02:16:06.640]   Are you in London? I am in London. Yes. Oh, and we ran out of time for your drum solo. I apologize.
[02:16:06.640 --> 02:16:12.160]   That's OK. I can record it and send it in later. We'll edit it into the final edition.
[02:16:12.160 --> 02:16:16.320]   Yeah. Thank you, Nate, for staying up late with us. I really appreciate it.
[02:16:16.320 --> 02:16:18.720]   No. My pleasure. Thank you for having me.
[02:16:18.720 --> 02:16:25.040]   At Nate Langston, LA and XON on the Twitter. We're always thrilled to have Dylan
[02:16:25.040 --> 02:16:29.760]   Twiney on with us. He is, of course, longtime or adventure beat and wire, but now head of
[02:16:29.760 --> 02:16:37.120]   communication at Valomail, V-A-L-I-M-A-I-L.com. If you are sending email from your business,
[02:16:37.120 --> 02:16:43.760]   Valomail does that validation. That means it's authentic. And I think that's real. I'm a big
[02:16:43.760 --> 02:16:48.400]   supporter of that. I think that's really important. So thank you for being here, Dylan.
[02:16:48.400 --> 02:16:52.160]   It's great to be back, Leo. It's really nice to talk with you.
[02:16:52.160 --> 02:16:57.840]   Yeah. I feel like both you and Nate, we should get you on more. I apologize for not being
[02:16:57.840 --> 02:17:04.080]   more aggressive about pursuing you. I would. Yeah. You want to come back?
[02:17:04.080 --> 02:17:07.920]   I'll always come back. Yeah. I'll come back. Let's do it again.
[02:17:07.920 --> 02:17:11.280]   We'll do it again. I'll plug my own podcast next time.
[02:17:11.280 --> 02:17:15.200]   Oh, what's your podcast? Oh, you know, I should everybody. Everybody has a freaking podcast.
[02:17:15.200 --> 02:17:18.400]   Oh, yeah. I should ask everybody. What's your podcast, Nate?
[02:17:18.400 --> 02:17:21.440]   Oh, my podcast is called text message.
[02:17:21.440 --> 02:17:26.080]   So... Can I get it on my phone? I was gonna get it on your phone.
[02:17:26.080 --> 02:17:32.080]   Yeah. Using Apple's messages. You can get it on any device where a podcast can be found.
[02:17:32.080 --> 02:17:34.720]   Oh, I get it. T-E-C-H apostrophe S.
[02:17:34.720 --> 02:17:38.000]   There you go. That's very clever. Oh, I like it. Thank you.
[02:17:38.640 --> 02:17:41.600]   Yeah. We went into quite a lot of detail on the porn,
[02:17:41.600 --> 02:17:45.840]   age, gate stuff, because there's so much behind that story to unpack. So we went into pretty good
[02:17:45.840 --> 02:17:53.120]   detail about that. Yeah. techpodcast.uk. Excellent. Welcome any listeners, of course.
[02:17:53.120 --> 02:17:56.240]   Excellent. Text message. Oh, I'm gonna have to start listening. That looks great.
[02:17:56.240 --> 02:17:59.520]   Do you... Is it you alone or you said we? Who else is on it?
[02:17:59.520 --> 02:18:05.600]   It's me, my co-host Ian Morris. So he and I used to work at CNET together back in 2007.
[02:18:05.600 --> 02:18:12.400]   He's written for like Gizmodo, Forbes, and other places. But I have sort of a rotating panel
[02:18:12.400 --> 02:18:16.160]   who come on every now and again, like Tom Merritt's been on. He's a good friend of mine.
[02:18:16.160 --> 02:18:22.000]   A bunch of other people have been onto. So yeah, it's good fun every week.
[02:18:22.000 --> 02:18:24.800]   That sounds fantastic. I shall listen from now on. Thank you.
[02:18:24.800 --> 02:18:32.160]   How about you, Dylan? You got a podcast? I do not have a podcast at the moment. I'm sorry, Leo.
[02:18:32.160 --> 02:18:36.560]   But bring me on again and all. Yeah, you can be an artist. Okay, have a podcast next time.
[02:18:36.560 --> 02:18:43.520]   I'll work on that. Everybody has a podcast. I know this guy, Devindra Harderwar, does his senior
[02:18:43.520 --> 02:18:49.840]   editor and gadget. And what is your podcast? Oh, I do the slash film cast. That's the slash film.com.
[02:18:49.840 --> 02:18:55.440]   So we review movies and TV shows. We're about ready to start our summer movie wager, which is this
[02:18:55.440 --> 02:19:01.440]   fun thing we do every summer where we basically predict the top 10 movies of the summer season.
[02:19:01.440 --> 02:19:06.880]   And try to see who wins at the end and whoever wins has to force everybody to watch a movie of
[02:19:06.880 --> 02:19:10.960]   their own choosing. Nice. So yeah, prepping for that, that's going to be a lot of fun.
[02:19:10.960 --> 02:19:16.000]   I'm also doing a tech show at no more tech.net and that's no with a K. And it's like just answering
[02:19:16.000 --> 02:19:20.880]   people's questions and talking about like timely news and stuff. Sometimes this podcast thing's
[02:19:20.880 --> 02:19:28.000]   going to really take off and you guys are going to be millionaires. Oh boy. It's all for the love
[02:19:28.000 --> 02:19:30.960]   of it right now. Just talking to microphones. I love that. Believe me, I know.
[02:19:30.960 --> 02:19:36.720]   That's Devindra on the Twitter. Yes. And everything else is in gadgets.
[02:19:36.720 --> 02:19:41.360]   Yes. And we love having you on to as often as we can. It's great to have. What a great panel.
[02:19:41.360 --> 02:19:46.400]   Thank you guys for being a panel. Yeah. We do Twitter every Sunday afternoon, even on Easter,
[02:19:46.400 --> 02:19:52.400]   round after the radio show. So it depends how long it takes us to get started. Round about 230,
[02:19:52.400 --> 02:20:00.720]   Pacific 530 Eastern time. That would be 2130 UTC. Come by, say hi, watch the show. You can watch
[02:20:00.720 --> 02:20:06.160]   it live or listen live at Twit.tv/live. You can also, if you're doing that, join us in the chat
[02:20:06.160 --> 02:20:12.480]   room because there's always a great conversation going on in there. That's irc.twit.tv. On-demand
[02:20:12.480 --> 02:20:17.680]   versions of the show are always available at our website for everything we do. Twit.tv.
[02:20:18.400 --> 02:20:23.520]   And if you want, the best thing to do, be subscribe. That way you get it automatically.
[02:20:23.520 --> 02:20:26.160]   The minute it's available so you haven't time for your Monday commute,
[02:20:26.160 --> 02:20:31.920]   just go to Twit.tv or your favorite podcast application and click subscribe.
[02:20:31.920 --> 02:20:38.800]   I'm offering for sale from My Life My Shop, the ultimate spin face scrubber, and the Smile
[02:20:38.800 --> 02:20:47.600]   Bright Store UV sanitizer toothbrush at a garage sale near you. So just come by, pick it up.
[02:20:47.600 --> 02:20:54.640]   We've got a deal. I'm really big deal. Thank you everybody for joining us. We'll see you next time.
[02:20:54.640 --> 02:21:09.520]   Another Twit.

