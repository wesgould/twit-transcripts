;FFMETADATA1
title=The Matador Defense
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=658
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.200]   It's time for Twit this week in tech.
[00:00:02.200 --> 00:00:04.320]   Greg Ferro from the Packet Bushers Network is here.
[00:00:04.320 --> 00:00:06.520]   Along with Georgia Dow, Jason Heiner.
[00:00:06.520 --> 00:00:08.600]   We'll talk about those AMD security flaws.
[00:00:08.600 --> 00:00:13.320]   Are they genuine or just a stock manipulation attempt?
[00:00:13.320 --> 00:00:16.800]   We'll also talk about Qualcomm and Broadcom
[00:00:16.800 --> 00:00:19.160]   and why the US government killed the deal
[00:00:19.160 --> 00:00:21.680]   and whether it was a good idea
[00:00:21.680 --> 00:00:24.040]   and why I'm quitting Facebook.
[00:00:24.040 --> 00:00:25.880]   This time for the last time.
[00:00:25.880 --> 00:00:27.680]   It's all coming up next on Twit.
[00:00:27.680 --> 00:00:30.800]   [MUSIC PLAYING]
[00:00:30.800 --> 00:00:32.840]   Netcast you love.
[00:00:32.840 --> 00:00:34.200]   From people you trust.
[00:00:34.200 --> 00:00:38.040]   [MUSIC PLAYING]
[00:00:38.040 --> 00:00:40.400]   This is Twit.
[00:00:40.400 --> 00:00:45.200]   Bandwidth for this week in tech is provided by cashfly at CACHE
[00:00:45.200 --> 00:00:46.760]   F-L-Y dot com.
[00:00:46.760 --> 00:00:51.920]   [MUSIC PLAYING]
[00:00:51.920 --> 00:00:54.280]   This is Twit this week in tech.
[00:00:54.280 --> 00:00:59.040]   Episode 658 recorded Sunday, March 18, 2018.
[00:00:59.040 --> 00:01:00.960]   The Matador Defense.
[00:01:00.960 --> 00:01:03.760]   This week in tech is brought to you by Eero.
[00:01:03.760 --> 00:01:07.240]   Never think about Wi-Fi again with Eero's hyperfast,
[00:01:07.240 --> 00:01:09.760]   super simple Wi-Fi system.
[00:01:09.760 --> 00:01:13.760]   And now the second generation Eero is tri-banded twice as fast.
[00:01:13.760 --> 00:01:17.880]   For free overnight shipping to the US or Canada, visit Eero.com.
[00:01:17.880 --> 00:01:21.680]   Select overnight shipping at checkout and enter the code Twit.
[00:01:21.680 --> 00:01:25.640]   And by Roman, a men's health company that offers remote online
[00:01:25.640 --> 00:01:29.120]   diagnosis for ED and convenient monthly delivery
[00:01:29.120 --> 00:01:30.160]   of medication.
[00:01:30.160 --> 00:01:34.720]   For $50 off your first month, visit getroman.com/twit.
[00:01:34.720 --> 00:01:36.360]   And by Quip.
[00:01:36.360 --> 00:01:39.360]   Make a fresh start this year with a Quip Electric Toothbrush.
[00:01:39.360 --> 00:01:41.600]   It cleans like a premium electric brush
[00:01:41.600 --> 00:01:43.080]   at a fraction of the cost.
[00:01:43.080 --> 00:01:47.080]   Visit getquip.com/twit to get your first refill pack free
[00:01:47.080 --> 00:01:50.200]   when you purchase any Quip electric toothbrush.
[00:01:50.200 --> 00:01:53.240]   And by Rocket Mortgage from Quip and Loans.
[00:01:53.240 --> 00:01:54.880]   Home plays a big role in your life.
[00:01:54.880 --> 00:01:57.720]   That's why Quip and Loans created Rocket Mortgage.
[00:01:57.720 --> 00:02:00.280]   It lets you apply simply and understand the entire mortgage
[00:02:00.280 --> 00:02:01.440]   process fully.
[00:02:01.440 --> 00:02:03.640]   So you could be confident you're getting the right mortgage
[00:02:03.640 --> 00:02:03.980]   for you.
[00:02:03.980 --> 00:02:07.880]   Get started at rocketmortgage.com/twit2.
[00:02:07.880 --> 00:02:11.840]   [MUSIC PLAYING]
[00:02:11.840 --> 00:02:12.840]   It's time for Twit.
[00:02:12.840 --> 00:02:16.080]   This week in tech, the show where we talk about the latest tech
[00:02:16.080 --> 00:02:17.400]   news.
[00:02:17.400 --> 00:02:19.160]   And each week we assemble a new panel
[00:02:19.160 --> 00:02:24.000]   hoping to find the perfect combination of wit, wisdom,
[00:02:24.000 --> 00:02:25.120]   and savoir fare.
[00:02:25.120 --> 00:02:26.360]   And I think we've done it.
[00:02:26.360 --> 00:02:27.360]   We've done it.
[00:02:27.360 --> 00:02:31.000]   Let's start with Jason Heiner from Tech Republic.
[00:02:31.000 --> 00:02:32.200]   What is that on your lip?
[00:02:32.200 --> 00:02:36.000]   Lip loss.
[00:02:36.000 --> 00:02:36.800]   Yeah.
[00:02:36.800 --> 00:02:39.320]   You have grown since I saw you last.
[00:02:39.320 --> 00:02:40.880]   You've grown what they call it.
[00:02:40.880 --> 00:02:41.440]   What do they call that?
[00:02:41.440 --> 00:02:42.360]   A hip soul patch.
[00:02:42.360 --> 00:02:42.960]   Soul patch.
[00:02:42.960 --> 00:02:44.040]   Soul patch.
[00:02:44.040 --> 00:02:44.560]   You look good.
[00:02:44.560 --> 00:02:45.560]   I like it.
[00:02:45.560 --> 00:02:46.060]   Yeah.
[00:02:46.060 --> 00:02:49.080]   Are you taking up the clarinet?
[00:02:49.080 --> 00:02:50.880]   No saxophone.
[00:02:50.880 --> 00:02:51.600]   It's good.
[00:02:51.600 --> 00:02:52.320]   It's good.
[00:02:52.320 --> 00:02:52.800]   It's good.
[00:02:52.800 --> 00:02:53.280]   I like it.
[00:02:53.280 --> 00:02:53.760]   Just kidding.
[00:02:53.760 --> 00:02:57.160]   I can't-- but I did play the clarinet, actually, in high school.
[00:02:57.160 --> 00:02:58.720]   Mostly because I wanted to play the saxophone,
[00:02:58.720 --> 00:03:00.560]   but my family owned a clarinet.
[00:03:00.560 --> 00:03:02.880]   And so they said you get to play the clarinet.
[00:03:02.880 --> 00:03:05.000]   One reads much like the other.
[00:03:05.000 --> 00:03:05.520]   Indeed.
[00:03:05.520 --> 00:03:06.880]   Nice to see you, Jason.
[00:03:06.880 --> 00:03:09.560]   To Jason's right, we have the fabulous Georgia
[00:03:09.560 --> 00:03:11.320]   Dow from iMore.com.
[00:03:11.320 --> 00:03:12.800]   Hello, Georgia.
[00:03:12.800 --> 00:03:13.480]   Hello.
[00:03:13.480 --> 00:03:15.000]   I wanted to learn the drums.
[00:03:15.000 --> 00:03:17.280]   So my parents got me an accordion.
[00:03:17.280 --> 00:03:18.280]   [LAUGHTER]
[00:03:18.280 --> 00:03:20.280]   What is wrong with parents?
[00:03:20.280 --> 00:03:21.920]   They didn't love me enough.
[00:03:21.920 --> 00:03:22.680]   Get the instrument.
[00:03:22.680 --> 00:03:24.280]   They used to make the kit once.
[00:03:24.280 --> 00:03:26.200]   It was also a family member who had it.
[00:03:26.200 --> 00:03:27.720]   They could get it for $50.
[00:03:27.720 --> 00:03:30.600]   So I was the accordion player.
[00:03:30.600 --> 00:03:34.200]   And I did, in fact, buy my child a drum kit
[00:03:34.200 --> 00:03:35.160]   when he was about eight.
[00:03:35.160 --> 00:03:37.600]   And that was the biggest mistake I ever made.
[00:03:37.600 --> 00:03:39.080]   [LAUGHTER]
[00:03:39.080 --> 00:03:40.920]   Do not get drum kits for your children.
[00:03:40.920 --> 00:03:43.080]   I understand what your parents are up to.
[00:03:43.080 --> 00:03:47.680]   They did not want to hear you banging the skins at 4 a.m.
[00:03:47.680 --> 00:03:50.560]   Greg Ferro, he's the packet pusher from Packet Pushers
[00:03:50.560 --> 00:03:52.240]   Network and a serial mind of the Twitter.
[00:03:52.240 --> 00:03:54.120]   Great to see you again, Greg.
[00:03:54.120 --> 00:03:55.160]   Thank you so much, Leo.
[00:03:55.160 --> 00:03:56.440]   It's good to be back.
[00:03:56.440 --> 00:03:56.800]   Sorry.
[00:03:56.800 --> 00:03:58.920]   I haven't been able to get up there physically in person,
[00:03:58.920 --> 00:04:02.360]   but I'm curtailing my travel plans for the year ahead
[00:04:02.360 --> 00:04:04.440]   to try and focus on generating content.
[00:04:04.440 --> 00:04:05.200]   Nice.
[00:04:05.200 --> 00:04:07.280]   On the Packet Pushers Network.
[00:04:07.280 --> 00:04:07.760]   Yeah, yeah.
[00:04:07.760 --> 00:04:11.960]   We're upgrading, upping our writing and video work.
[00:04:11.960 --> 00:04:14.280]   So we're increasing our YouTube commentary.
[00:04:14.280 --> 00:04:16.400]   And we're also building, overhauling the website
[00:04:16.400 --> 00:04:17.480]   and doing static content.
[00:04:17.480 --> 00:04:19.120]   So we're looking forward to getting that.
[00:04:19.120 --> 00:04:21.320]   So I understand you've gotten a lot of trouble
[00:04:21.320 --> 00:04:26.080]   with your audience for making a change in your recommendations
[00:04:26.080 --> 00:04:27.200]   recently.
[00:04:27.200 --> 00:04:30.520]   Yeah, well, part of being an IT expert,
[00:04:30.520 --> 00:04:33.520]   when you're an IT professional, you get a lot of certifications.
[00:04:33.520 --> 00:04:35.360]   We all go out and study and learn stuff.
[00:04:35.360 --> 00:04:38.960]   And then some people go on to pass exams to qualify them.
[00:04:38.960 --> 00:04:41.600]   And it's time for me to move on and to walk away.
[00:04:41.600 --> 00:04:43.960]   So I just published a little post saying,
[00:04:43.960 --> 00:04:47.440]   letting my certification status go in this area.
[00:04:47.440 --> 00:04:48.240]   You don't need it.
[00:04:48.240 --> 00:04:49.760]   You're certified.
[00:04:49.760 --> 00:04:53.080]   Certifications are people who don't have experience.
[00:04:53.080 --> 00:04:55.640]   Well, it's like the people who go to the insane asylum.
[00:04:55.640 --> 00:04:58.880]   And you get a certificate when you come out to say that you're saying.
[00:04:58.880 --> 00:05:01.320]   But anybody who's never been to the insane asylum hacks,
[00:05:01.320 --> 00:05:02.200]   you have a certificate.
[00:05:02.200 --> 00:05:05.480]   So which, sir, is it that you're letting go by the wayside?
[00:05:05.480 --> 00:05:08.080]   It's associated with the Cisco Cisco CCIE program.
[00:05:08.080 --> 00:05:09.080]   It's their elite.
[00:05:09.080 --> 00:05:10.640]   You don't need that anymore.
[00:05:10.640 --> 00:05:14.400]   Do you pay every year to be a CCIE?
[00:05:14.400 --> 00:05:16.320]   It's complicated.
[00:05:16.320 --> 00:05:17.160]   Something like that.
[00:05:17.160 --> 00:05:21.800]   Yeah, you have to maintain touch and status and lodge some stuff to say that you're still
[00:05:21.800 --> 00:05:23.240]   working in the industry and you're in touch.
[00:05:23.240 --> 00:05:26.240]   You haven't just walked away and done nothing for the last five years.
[00:05:26.240 --> 00:05:32.800]   I believe that you are a certified inter-network expert.
[00:05:32.800 --> 00:05:33.800]   I will.
[00:05:33.800 --> 00:05:34.560]   That's no joke, though.
[00:05:34.560 --> 00:05:36.880]   It's like the PhD of certifications.
[00:05:36.880 --> 00:05:39.560]   So I see why people were probably like,
[00:05:39.560 --> 00:05:43.000]   "Oh, my gosh, why would you do that?"
[00:05:43.000 --> 00:05:44.560]   I did way back in the day.
[00:05:44.560 --> 00:05:45.640]   This is like 20 years ago.
[00:05:45.640 --> 00:05:48.240]   I did CCNA, which is sort of the entry lesson.
[00:05:48.240 --> 00:05:50.200]   I remember that, yeah.
[00:05:50.200 --> 00:05:51.600]   You know, certification.
[00:05:51.600 --> 00:05:52.600]   So CCIE.
[00:05:52.600 --> 00:05:57.080]   Did you look up at CCIEs like they were the gods?
[00:05:57.080 --> 00:05:59.160]   Of course, absolutely.
[00:05:59.160 --> 00:06:00.160]   Yes.
[00:06:00.160 --> 00:06:03.560]   I mean, I think when I entered the room and everything, you know.
[00:06:03.560 --> 00:06:06.600]   I think that there's a substantial change going on in technology.
[00:06:06.600 --> 00:06:11.560]   So for people who are IT professionals, we're seeing a change away from certifications
[00:06:11.560 --> 00:06:17.360]   and basic knowledge as a path, as a career path to people building portfolios, career
[00:06:17.360 --> 00:06:21.080]   portfolios in the same way that artists have a portfolio.
[00:06:21.080 --> 00:06:26.960]   I think that IT professionals must have a GitHub site with code and a blog showing that
[00:06:26.960 --> 00:06:29.640]   they know about these things and writing stories.
[00:06:29.640 --> 00:06:31.040]   And that shows you can communicate.
[00:06:31.040 --> 00:06:32.040]   It shows what you know.
[00:06:32.040 --> 00:06:34.440]   It demonstrates your capabilities.
[00:06:34.440 --> 00:06:38.320]   Rather than, you know, I pass this exam, therefore, I must know what I'm doing.
[00:06:38.320 --> 00:06:42.960]   I think employers are looking for much more interesting capabilities in the old days of
[00:06:42.960 --> 00:06:45.880]   certificates as being the bill and in dollars passed.
[00:06:45.880 --> 00:06:46.880]   That's my logic.
[00:06:46.880 --> 00:06:47.880]   No doubt.
[00:06:47.880 --> 00:06:52.640]   Since you guys are both here and you too, George, although I think you and I will have
[00:06:52.640 --> 00:06:59.800]   less to say about this, let's talk about Rise and Fall, which is a wonderful name for
[00:06:59.800 --> 00:07:00.800]   an exploit.
[00:07:00.800 --> 00:07:08.280]   There are four critical flaws, 13 critical flaws, four basic ideas that are affecting
[00:07:08.280 --> 00:07:10.480]   AMD processors.
[00:07:10.480 --> 00:07:12.080]   We learned about it on Tuesday.
[00:07:12.080 --> 00:07:17.520]   In fact, Steve Gibson took this so seriously, kind of rebuilt security now to talk about
[00:07:17.520 --> 00:07:18.520]   this.
[00:07:18.520 --> 00:07:20.800]   But I haven't heard a word since.
[00:07:20.800 --> 00:07:27.520]   And there was some concern because the group that found this wasn't super well known, CTS
[00:07:27.520 --> 00:07:33.480]   labs, and they did something that is considered anathema to the security industry.
[00:07:33.480 --> 00:07:39.200]   They discovered it and revealed it pretty much at the same time without giving AMD their
[00:07:39.200 --> 00:07:43.760]   requisite 90 days to patch.
[00:07:43.760 --> 00:07:49.640]   Have you heard anything about Rise and Fall since then as AMD stepped forward?
[00:07:49.640 --> 00:07:50.640]   What do we know?
[00:07:50.640 --> 00:07:55.240]   I think my favorite part about this story is that apparently they're monetizing the bug
[00:07:55.240 --> 00:07:57.720]   by short-selling AMD stock.
[00:07:57.720 --> 00:07:59.200]   That's what worried me.
[00:07:59.200 --> 00:08:07.480]   And that was kind of the, there was this undercurrent of concern that maybe this company really,
[00:08:07.480 --> 00:08:10.800]   first of all, they didn't put out proof of concept code, although some say they've seen
[00:08:10.800 --> 00:08:11.800]   it.
[00:08:11.800 --> 00:08:15.280]   So it's hard to demonstrate that this is an actual flaw.
[00:08:15.280 --> 00:08:19.160]   And yeah, that was some concern that maybe they're short sellers just trying to get AMD
[00:08:19.160 --> 00:08:22.680]   stock to dump and they can make some money on that.
[00:08:22.680 --> 00:08:27.240]   The story that I've heard about the Rise and Vulnerabilities is it's pretty hard to understand
[00:08:27.240 --> 00:08:32.440]   how the scale of this, without the code showing the vulnerabilities and without AMD admitting
[00:08:32.440 --> 00:08:33.440]   to what's happening.
[00:08:33.440 --> 00:08:37.920]   And they haven't had enough time to examine this and to see and to make a public, literally
[00:08:37.920 --> 00:08:42.800]   they announced it on one, gave them 24 hours notice, which isn't enough time for CTS.
[00:08:42.800 --> 00:08:47.960]   So it's hard to criticize AMD for not reacting already.
[00:08:47.960 --> 00:08:53.800]   The theory is that increasingly the security researchers aren't releasing bugs without
[00:08:53.800 --> 00:08:55.000]   making money out of them.
[00:08:55.000 --> 00:08:59.640]   So the downside of the bug bounty programs that we've seen start, all of the bug bounty
[00:08:59.640 --> 00:09:04.840]   programs that are going on, is that security researchers reasonably, in my opinion, expect
[00:09:04.840 --> 00:09:06.800]   to get paid for finding these vulnerabilities.
[00:09:06.800 --> 00:09:12.480]   Because the companies who get the benefit of these bugs are for profit, like sometimes
[00:09:12.480 --> 00:09:14.280]   billions of dollars worth of profit.
[00:09:14.280 --> 00:09:15.280]   Why?
[00:09:15.280 --> 00:09:18.320]   Because I'm not arguing against that.
[00:09:18.320 --> 00:09:20.600]   And Apple refused to do this for the longest time.
[00:09:20.600 --> 00:09:22.760]   They've only recently started paying bug bounties.
[00:09:22.760 --> 00:09:27.000]   Their concern was, and I think it's legitimate, that then you create a market for bugs and
[00:09:27.000 --> 00:09:32.080]   it's hard to outbid governments that will pay millions of dollars for these bugs if
[00:09:32.080 --> 00:09:34.880]   they're usable for exploits.
[00:09:34.880 --> 00:09:40.640]   And so suddenly you have this auction that goes through the roof.
[00:09:40.640 --> 00:09:45.920]   I think it's not unreasonable to expect security firms to notify the company that created the
[00:09:45.920 --> 00:09:50.000]   software or hardware and give them a fair amount of time to fix it.
[00:09:50.000 --> 00:09:54.360]   And I don't think necessarily saying, "But you have to give us a hundred thousand dollars
[00:09:54.360 --> 00:09:55.360]   first."
[00:09:55.360 --> 00:09:58.040]   It makes me feel a little queasy.
[00:09:58.040 --> 00:10:00.760]   I don't think AMD even has a bug bounty program.
[00:10:00.760 --> 00:10:02.880]   So how else were they going to monetize it?
[00:10:02.880 --> 00:10:05.280]   By short selling the stock?
[00:10:05.280 --> 00:10:06.280]   Why not?
[00:10:06.280 --> 00:10:09.280]   It's as good away as any and it's virtually untruthable.
[00:10:09.280 --> 00:10:10.280]   Good lord.
[00:10:10.280 --> 00:10:15.640]   And, you know, if AMD is not going to play ball, is not going to own up to its responsibilities
[00:10:15.640 --> 00:10:19.600]   and offer a bug bounty for people who report them, then this is the sort of thing that
[00:10:19.600 --> 00:10:20.600]   you're going to get.
[00:10:20.600 --> 00:10:22.120]   And these researchers are doing it for money.
[00:10:22.120 --> 00:10:25.040]   And they, you know, the bug bounty programs love them or hate them.
[00:10:25.040 --> 00:10:26.360]   Yes, you're right.
[00:10:26.360 --> 00:10:31.680]   Some security researchers will only work white hat and increasingly they'll only work inside
[00:10:31.680 --> 00:10:35.600]   of the bug bounty programs because they get legal protection and corporate protection when
[00:10:35.600 --> 00:10:37.320]   they're inside the bug bounty companies.
[00:10:37.320 --> 00:10:42.760]   Linus Torvalds, a creator of Linux, did raise this specter that maybe these are short sellers.
[00:10:42.760 --> 00:10:48.120]   CTS Labs, which isn't well known, he said, "When was the last time you saw a security
[00:10:48.120 --> 00:10:52.760]   advisory that was basically, quote, "If you replace the BIOS or the CPU microcode with
[00:10:52.760 --> 00:10:55.640]   an evil version, you might have a security problem."
[00:10:55.640 --> 00:10:56.640]   Yeah.
[00:10:56.640 --> 00:11:00.760]   He says, you know, it isn't really a flaw.
[00:11:00.760 --> 00:11:07.280]   And the idea of publicizing this so quickly was really to make money off a short sell.
[00:11:07.280 --> 00:11:14.480]   Dan Guido, who has a great name, he is the CEO of Trail of Bits, which is a security company
[00:11:14.480 --> 00:11:17.200]   that at least is somewhat known, tweeted.
[00:11:17.200 --> 00:11:21.240]   And I'll show you his Guido's tweet.
[00:11:21.240 --> 00:11:24.840]   He said, "Yeah, no, I've seen the proof of code, by the way.
[00:11:24.840 --> 00:11:28.720]   Here's proof of Chrome being sucky on Windows 10.
[00:11:28.720 --> 00:11:29.720]   Come on, Chrome.
[00:11:29.720 --> 00:11:30.800]   Come on, you can do it.
[00:11:30.800 --> 00:11:31.800]   Show that tweet.
[00:11:31.800 --> 00:11:35.520]   I don't know why it has so much trouble rendering Twitter.
[00:11:35.520 --> 00:11:36.520]   You see what's doing here?
[00:11:36.520 --> 00:11:37.520]   It's just going crazy."
[00:11:37.520 --> 00:11:44.240]   Anyway, Dan Guido's response on Twitter, oh, came up briefly.
[00:11:44.240 --> 00:11:49.200]   On Twitter was, "Regardless of the hype around the release, the bugs are real, accurately
[00:11:49.200 --> 00:11:54.140]   described in the technical report, which is not available to public, and their exploit
[00:11:54.140 --> 00:11:55.720]   code works."
[00:11:55.720 --> 00:12:02.800]   Now, the flaws do require admin privileges, but they are all flaws, not expected functionality.
[00:12:02.800 --> 00:12:11.240]   So the fact that you can read more about it at the CTS custom crafted website, AMDFlaws.com.
[00:12:11.240 --> 00:12:14.240]   Which, by the way, is-
[00:12:14.240 --> 00:12:15.240]   They're good vulnerabilities.
[00:12:15.240 --> 00:12:16.240]   They're brandy.
[00:12:16.240 --> 00:12:18.160]   They're clearly going to have a brand for you.
[00:12:18.160 --> 00:12:19.400]   They clearly spent some time.
[00:12:19.400 --> 00:12:24.520]   They've got a clever name, rise and fall, master key, fall out in Chimera.
[00:12:24.520 --> 00:12:26.440]   They've got logos.
[00:12:26.440 --> 00:12:28.920]   They've got a YouTube video.
[00:12:28.920 --> 00:12:32.520]   I mean, they've been working on this a lot harder for the last-
[00:12:32.520 --> 00:12:33.520]   I would say month.
[00:12:33.520 --> 00:12:36.400]   See what I mean about a portfolio?
[00:12:36.400 --> 00:12:40.120]   Now you've got a portfolio, you've built your brand, you've got your box out there.
[00:12:40.120 --> 00:12:43.480]   And so, next time you go for a job, you can say, "Yeah, I was rising for all that was
[00:12:43.480 --> 00:12:44.480]   me."
[00:12:44.480 --> 00:12:48.920]   Show demonstrate proof of work.
[00:12:48.920 --> 00:12:53.520]   I think it's right for these researchers to expect to get paid for the work.
[00:12:53.520 --> 00:12:57.320]   They're fundamentally doing work that these companies have failed to do themselves, in
[00:12:57.320 --> 00:12:58.320]   my view.
[00:12:58.320 --> 00:12:59.320]   That's a good point.
[00:12:59.320 --> 00:13:04.560]   AMD, I didn't tell you about the vulnerability in their CPUs and actively ignored it, is the
[00:13:04.560 --> 00:13:05.560]   message that I'm not saying.
[00:13:05.560 --> 00:13:08.160]   They ignored it for 20-some years they ignored speculation.
[00:13:08.160 --> 00:13:10.960]   And it's been found several times, I believe.
[00:13:10.960 --> 00:13:12.640]   Yeah, speculative execution.
[00:13:12.640 --> 00:13:18.080]   We saw a white paper written in 1995 that said, "This is going to leak information."
[00:13:18.080 --> 00:13:20.240]   And everybody just blindly ignored it.
[00:13:20.240 --> 00:13:25.680]   So Jason, what do you tell your enterprise readers that they should do about this?
[00:13:25.680 --> 00:13:27.680]   Is this something they should worry about?
[00:13:27.680 --> 00:13:29.560]   I mean, this was a tough one, right?
[00:13:29.560 --> 00:13:33.720]   Because you don't really know yet what the potential damage.
[00:13:33.720 --> 00:13:38.040]   Now a lot of companies aren't using servers running AMD processors.
[00:13:38.040 --> 00:13:42.960]   That's the things that they care a lot about is the data that's on servers.
[00:13:42.960 --> 00:13:46.320]   AMD is not in a whole lot of servers.
[00:13:46.320 --> 00:13:50.160]   Intel has an even bigger share of that market.
[00:13:50.160 --> 00:13:55.360]   But obviously, you have devices out there that have this, that it's going to put some
[00:13:55.360 --> 00:13:58.480]   of your most important data at risk, potentially.
[00:13:58.480 --> 00:14:04.720]   And so, until we know what a better, have a better idea what some of the risks are,
[00:14:04.720 --> 00:14:10.720]   what you have to do is just sort of be on, is have your radar up, which they always do
[00:14:10.720 --> 00:14:12.920]   anyway, of course.
[00:14:12.920 --> 00:14:19.240]   But when you're looking at which devices to put out there and which devices are most
[00:14:19.240 --> 00:14:23.040]   vulnerable, which devices might have some of your most valuable data, most sensitive
[00:14:23.040 --> 00:14:24.240]   stuff on it.
[00:14:24.240 --> 00:14:30.840]   You may want to be careful if you've got devices that have AMD CPUs that might have
[00:14:30.840 --> 00:14:37.520]   some super, super sensitive IP or other kinds of data, and you may want to move it away
[00:14:37.520 --> 00:14:39.800]   from some of those devices.
[00:14:39.800 --> 00:14:44.880]   Those are the kinds of things that enterprises and think about from a risk management standpoint.
[00:14:44.880 --> 00:14:50.080]   CTS Labs when asked by Tom's hardware, well, why didn't you give AMD the normal 90-day
[00:14:50.080 --> 00:14:51.080]   courtesy?
[00:14:51.080 --> 00:14:55.880]   They said, well, we consider these so severe, we didn't think AMD would be able to fix this
[00:14:55.880 --> 00:14:58.840]   for many, many months or even a year.
[00:14:58.840 --> 00:15:02.640]   So we decided to give them 24 hours.
[00:15:02.640 --> 00:15:03.640]   Interesting.
[00:15:03.640 --> 00:15:06.880]   It doesn't fly.
[00:15:06.880 --> 00:15:11.920]   I mean, just to go back to what Jason was saying, I just to draw some specifics out of
[00:15:11.920 --> 00:15:12.920]   that.
[00:15:12.920 --> 00:15:19.560]   A lot of firewalls, routers, storage arrays, a lot of custom appliances run AMD CPUs.
[00:15:19.560 --> 00:15:25.560]   Intel, most people who buy servers from the traditional vendors, they're not AMD's, but
[00:15:25.560 --> 00:15:28.720]   the vendors who make hard appliances are often running AMD.
[00:15:28.720 --> 00:15:32.520]   Now they're not off-learning accessible code.
[00:15:32.520 --> 00:15:37.440]   So if you're looking at your firewalls, it's hard to get an injection point or to get through
[00:15:37.440 --> 00:15:41.600]   the attack surface, but they're the devices that rise and fall as much more likely to
[00:15:41.600 --> 00:15:45.320]   affect because AMD is much stronger in the appliance market.
[00:15:45.320 --> 00:15:49.920]   By the way, other people like Alex Aonescu, who's well known in the security community,
[00:15:49.920 --> 00:15:51.640]   have said, I've seen the technical details.
[00:15:51.640 --> 00:15:55.720]   They're a legit design and implementation issues worth discussing as part of a coordinated
[00:15:55.720 --> 00:15:57.240]   disclosure effort.
[00:15:57.240 --> 00:16:01.920]   The media storm and handling around that is sadly distracting from a real conversation
[00:16:01.920 --> 00:16:04.200]   around security boundaries.
[00:16:04.200 --> 00:16:11.000]   And so his takeaway from this is really the issue is people shouldn't have admin level
[00:16:11.000 --> 00:16:13.800]   access to this hardware.
[00:16:13.800 --> 00:16:15.360]   There's another issue that's interesting.
[00:16:15.360 --> 00:16:21.040]   One of the reasons AMD was bit by some of these flaws is that they, in their system
[00:16:21.040 --> 00:16:26.520]   on a chip, they used chips created by a third company that apparently left a backdoor in
[00:16:26.520 --> 00:16:28.440]   the hardware.
[00:16:28.440 --> 00:16:33.680]   And whether intentionally or by accident, that's a big issue as well, right?
[00:16:33.680 --> 00:16:34.680]   Yeah.
[00:16:34.680 --> 00:16:37.520]   And like, obviously this is something they're all doing because Intel had that problem a
[00:16:37.520 --> 00:16:43.560]   while back as well with their onboard management chip running Minix, which has got-
[00:16:43.560 --> 00:16:45.040]   So many vulnerabilities.
[00:16:45.040 --> 00:16:52.160]   It's basically unsafe for anybody to use, much less to put it inside a world-class CPU.
[00:16:52.160 --> 00:16:56.960]   So I think what we're seeing here is all of the silicon makers have sort of been caught
[00:16:56.960 --> 00:17:00.280]   out here with the increasing focus on security.
[00:17:00.280 --> 00:17:01.280]   You're going to see more of this.
[00:17:01.280 --> 00:17:04.080]   I think we're going to see more in baseband modems.
[00:17:04.080 --> 00:17:06.920]   There's the iPhone vulnerability, which is on the list to talk about tonight.
[00:17:06.920 --> 00:17:08.080]   Same sort of thing.
[00:17:08.080 --> 00:17:09.560]   There's a lot more money on the table.
[00:17:09.560 --> 00:17:13.720]   These bug bounty programs, places to sell these compromises means there's more work
[00:17:13.720 --> 00:17:15.240]   being done on security.
[00:17:15.240 --> 00:17:19.200]   You're going to see much more of this type of stuff come out in the short term because
[00:17:19.200 --> 00:17:20.400]   it's worthwhile doing.
[00:17:20.400 --> 00:17:22.320]   It's now actually a financial basis.
[00:17:22.320 --> 00:17:26.480]   People can spend their lives making a living out of just finding these vulnerabilities.
[00:17:26.480 --> 00:17:27.480]   Yeah.
[00:17:27.480 --> 00:17:29.000]   And again, that's both good and bad.
[00:17:29.000 --> 00:17:31.760]   That's one of the reasons bug bounties are both good because they encourage people to
[00:17:31.760 --> 00:17:36.920]   find them, but bad because they encourage people to find them.
[00:17:36.920 --> 00:17:38.920]   So I have mixed feelings.
[00:17:38.920 --> 00:17:41.960]   Obviously security is not a good kind of security.
[00:17:41.960 --> 00:17:43.760]   So it is better to get these out.
[00:17:43.760 --> 00:17:44.760]   By the way, bottom.
[00:17:44.760 --> 00:17:47.120]   They call this Matador defense.
[00:17:47.120 --> 00:17:51.040]   You just lift the cape and let them right on through.
[00:17:51.040 --> 00:17:52.040]   Yeah.
[00:17:52.040 --> 00:17:53.600]   So unfortunately it's showing up.
[00:17:53.600 --> 00:17:59.920]   We're finding so much more than we have before, which is a good thing.
[00:17:59.920 --> 00:18:04.760]   That's the one counter argument to this is by them making it public, people that to Greg's
[00:18:04.760 --> 00:18:08.560]   point that might have a storage array with some of their most sensitive data that has
[00:18:08.560 --> 00:18:14.240]   AMD chip in it, that they're going to likely move that data off of there because they don't
[00:18:14.240 --> 00:18:15.800]   know because of the unknown.
[00:18:15.800 --> 00:18:22.240]   And so it's better to know than to have nation states or other bad guys on the black market
[00:18:22.240 --> 00:18:24.240]   that do know and are going to compromise.
[00:18:24.240 --> 00:18:26.200]   Bottom line from motherboards.
[00:18:26.200 --> 00:18:30.080]   Some of these new AMD flaws will be hard to patch and malicious hackers with a certain
[00:18:30.080 --> 00:18:34.720]   level of skill might be able to find ways to exploit them before they're patched according
[00:18:34.720 --> 00:18:35.720]   to Guido.
[00:18:35.720 --> 00:18:40.320]   But, and this is, I guess, the message for our audience, regular consumers shouldn't worry
[00:18:40.320 --> 00:18:41.320]   about them probably.
[00:18:41.320 --> 00:18:44.960]   The real problems are more for cloud providers and big enterprises.
[00:18:44.960 --> 00:18:48.400]   And now that they know about them, they can do the Matador defense.
[00:18:48.400 --> 00:18:50.880]   Does that follow a pole and a red cape?
[00:18:50.880 --> 00:18:51.880]   I'm not sure.
[00:18:51.880 --> 00:18:54.840]   You know, the Matador defense, you hold the cape up and then you just let them right
[00:18:54.840 --> 00:18:55.840]   on through.
[00:18:55.840 --> 00:18:56.840]   Yeah.
[00:18:56.840 --> 00:18:57.840]   Over here.
[00:18:57.840 --> 00:18:58.840]   Right on through.
[00:18:58.840 --> 00:19:02.880]   You know, making sure people don't get admin access, things like that.
[00:19:02.880 --> 00:19:03.880]   Yeah.
[00:19:03.880 --> 00:19:07.800]   You know, if you have to have admin access to take advantage of these, well, that's that's
[00:19:07.800 --> 00:19:11.040]   something that enterprises can address and servers can address.
[00:19:11.040 --> 00:19:14.080]   And they shouldn't be allowing admin access.
[00:19:14.080 --> 00:19:16.920]   Anyway, I guess you maybe have a, this would be a cascade.
[00:19:16.920 --> 00:19:23.440]   It's every have a malware that gets you escalated access and then you can apply these.
[00:19:23.440 --> 00:19:24.440]   Yeah.
[00:19:24.440 --> 00:19:25.440]   Yeah.
[00:19:25.440 --> 00:19:27.360]   This is where, you know, the impact of this is fairly unknown at this point in time.
[00:19:27.360 --> 00:19:29.200]   The exploit code's not published.
[00:19:29.200 --> 00:19:33.240]   That doesn't mean that people aren't out there actively trying to write code as we speak.
[00:19:33.240 --> 00:19:36.040]   But at this point in time, there doesn't seem to be anything in the wild.
[00:19:36.040 --> 00:19:40.920]   Whereas with Spectre and Meltdown, people were publishing exploit code within a few hours
[00:19:40.920 --> 00:19:45.160]   of that coming live, you know, or proof of concept, exploit code, not a working exploit.
[00:19:45.160 --> 00:19:49.320]   And by the way, there's a little bit of karma in this because remember when Spectre and
[00:19:49.320 --> 00:19:53.640]   Meltdown revealed AMD, immediately put out a press release saying, not us.
[00:19:53.640 --> 00:19:54.640]   And then we knew that.
[00:19:54.640 --> 00:19:56.120]   Well, as a matter of fact, you.
[00:19:56.120 --> 00:19:57.120]   Yeah.
[00:19:57.120 --> 00:20:00.320]   Because that karma is, is hitting pretty hard right now.
[00:20:00.320 --> 00:20:02.800]   It's the karma gonna get you.
[00:20:02.800 --> 00:20:07.320]   Georgia, we'll have something for you to talk about in a sec.
[00:20:07.320 --> 00:20:08.320]   Don't worry.
[00:20:08.320 --> 00:20:09.320]   Poor Georgia.
[00:20:09.320 --> 00:20:11.160]   We're just sitting here going, well, all right.
[00:20:11.160 --> 00:20:14.880]   But I actually, I want to take a break when we come back and talk to you about why I deleted
[00:20:14.880 --> 00:20:17.000]   my Facebook account last night.
[00:20:17.000 --> 00:20:18.880]   Uh, and I'm pretty head up.
[00:20:18.880 --> 00:20:21.400]   I'm pretty mad about what Facebook's been up to.
[00:20:21.400 --> 00:20:24.120]   So maybe, maybe we can get into that in a second.
[00:20:24.120 --> 00:20:27.840]   First, let's talk about making your wifi work.
[00:20:27.840 --> 00:20:32.400]   The worst thing in the world is the shout.
[00:20:32.400 --> 00:20:33.720]   And I hear it from time to time.
[00:20:33.720 --> 00:20:39.600]   I did anyway from your spouse saying, honey, the wifi's down or worse.
[00:20:39.600 --> 00:20:45.520]   You're watching, you know, the last season of the last episode of the last season of Game
[00:20:45.520 --> 00:20:52.640]   of Thrones and all of a sudden the buffering and the buffering and you go, wait, she walked
[00:20:52.640 --> 00:20:56.440]   in the fire and then, but what?
[00:20:56.440 --> 00:20:57.480]   That's what we got in the Euro.
[00:20:57.480 --> 00:21:03.080]   And I haven't had the problem since I'm happy to say Euro is enterprise grade wifi in your
[00:21:03.080 --> 00:21:04.420]   home.
[00:21:04.420 --> 00:21:09.520]   That's easy to set up, easy to use and solves those problems.
[00:21:09.520 --> 00:21:12.240]   It's designed to solve the problems.
[00:21:12.240 --> 00:21:16.040]   Modern wifi, unfortunately, you know, we live in an environment where everything we've got,
[00:21:16.040 --> 00:21:19.560]   we went from one or two or three devices on your wifi network.
[00:21:19.560 --> 00:21:22.080]   I have 45 on my wifi network.
[00:21:22.080 --> 00:21:27.640]   And that's pretty common between your lights and your echoes, your TVs, your laptops,
[00:21:27.640 --> 00:21:28.640]   your phones.
[00:21:28.640 --> 00:21:30.280]   Wifi is doing a lot of work.
[00:21:30.280 --> 00:21:34.880]   Plus your neighbors got wifi and sometimes your neighbor has one of those wifi routers
[00:21:34.880 --> 00:21:39.520]   with 18 antennas that's designed to knock you off.
[00:21:39.520 --> 00:21:40.640]   Euro solves this problem.
[00:21:40.640 --> 00:21:45.560]   We started to play with Euro when it first came out two years ago, early 2016.
[00:21:45.560 --> 00:21:47.400]   And here's one of the things that's great about Euro.
[00:21:47.400 --> 00:21:51.760]   They've learned over the last two years from hundreds of thousands of systems and they've
[00:21:51.760 --> 00:21:54.040]   been making them smarter, faster, more reliable.
[00:21:54.040 --> 00:21:58.560]   A couple of things you want in a router and any IoT device.
[00:21:58.560 --> 00:22:04.040]   Number one, you want it to be over the air firmware upgradeable and Euro does exactly
[00:22:04.040 --> 00:22:05.040]   that.
[00:22:05.040 --> 00:22:06.360]   Upgrades come automatically.
[00:22:06.360 --> 00:22:11.200]   They're automatically applied, not just security, but they're improving the system all the time.
[00:22:11.200 --> 00:22:14.960]   In fact, the new second generation Euro and the Euro beacon, those are great.
[00:22:14.960 --> 00:22:19.880]   The Euro beacon is just plugging into the wall are more perfectly tailored to fit your
[00:22:19.880 --> 00:22:21.560]   needs in your home than ever before.
[00:22:21.560 --> 00:22:23.120]   More speed and range.
[00:22:23.120 --> 00:22:25.040]   Their tri-band now.
[00:22:25.040 --> 00:22:27.040]   Same beautiful design people love.
[00:22:27.040 --> 00:22:32.240]   I don't mind people seeing the router in the hall or in the living room because it's
[00:22:32.240 --> 00:22:34.560]   unobtrusive, it's gorgeous.
[00:22:34.560 --> 00:22:38.840]   And because they're now tri-band, they have that third 5 gigahertz radio.
[00:22:38.840 --> 00:22:42.960]   The second generation Euro is twice as fast as its predecessor.
[00:22:42.960 --> 00:22:46.080]   And that means you can do more in every room of your home.
[00:22:46.080 --> 00:22:49.960]   They have a thread radio now, which means you can connect to low power devices like locks
[00:22:49.960 --> 00:22:52.400]   and doorbells and other sensors.
[00:22:52.400 --> 00:22:54.280]   It's easy to expand your coverage.
[00:22:54.280 --> 00:22:57.600]   We started with the basic kit, which was a base unit and two beacons.
[00:22:57.600 --> 00:23:01.840]   I've added a couple of beacons because then I put a camera outside and I wanted to make
[00:23:01.840 --> 00:23:06.200]   sure it could get to the Wi-Fi from the garage to put a Euro in the garage.
[00:23:06.200 --> 00:23:10.480]   It's easy to do if there's an outlet, there's Wi-Fi.
[00:23:10.480 --> 00:23:12.280]   Free overnight shipping to the US or Canada?
[00:23:12.280 --> 00:23:16.480]   Visit Euro.com and at Checkout Select overnight shipping then enter the offer code TWIT to
[00:23:16.480 --> 00:23:17.640]   make it free.
[00:23:17.640 --> 00:23:22.240]   I love also Euro has the new Euro Plus, which gives me much more control.
[00:23:22.240 --> 00:23:24.360]   I can do things like with my Amazon Echo.
[00:23:24.360 --> 00:23:29.760]   I can say what you do is I've assigned all the devices in the house to different users.
[00:23:29.760 --> 00:23:34.960]   And our 15 year old, I assigned his computer, his phone, his tablet to Michael and now I
[00:23:34.960 --> 00:23:38.800]   can tell Amazon Echo, pause Michael's internet.
[00:23:38.800 --> 00:23:40.320]   And it's so much fun.
[00:23:40.320 --> 00:23:42.040]   You wait for the scream.
[00:23:42.040 --> 00:23:43.040]   You need to hear you.
[00:23:43.040 --> 00:23:45.040]   One, two, three.
[00:23:45.040 --> 00:23:46.040]   Hey!
[00:23:46.040 --> 00:23:49.560]   He can't un-pause it by the way.
[00:23:49.560 --> 00:23:52.760]   With the Echo, he has to use the app and he doesn't have access to the app.
[00:23:52.760 --> 00:23:58.040]   We also are able to filter for safe sites, for violence, for sex, all sorts of things.
[00:23:58.040 --> 00:23:59.040]   And malware too.
[00:23:59.040 --> 00:24:02.880]   In fact, they have the whole house filtered through Euro Plus for malware.
[00:24:02.880 --> 00:24:04.640]   It's just a great system.
[00:24:04.640 --> 00:24:07.080]   Try it at Euro, E-E-R-O.com.
[00:24:07.080 --> 00:24:11.040]   And again, the offer code TWIT gets you free overnight shipping to the US or Canada.
[00:24:11.040 --> 00:24:14.920]   I thank you, Euro, for making a Wi-Fi that really works.
[00:24:14.920 --> 00:24:15.920]   No more.
[00:24:15.920 --> 00:24:17.920]   I hear screams, but it's a different kind.
[00:24:17.920 --> 00:24:18.920]   Hey!
[00:24:18.920 --> 00:24:20.920]   I'm playing here.
[00:24:20.920 --> 00:24:21.920]   Yeah.
[00:24:21.920 --> 00:24:22.920]   My bad.
[00:24:22.920 --> 00:24:24.920]   Go to bed.
[00:24:24.920 --> 00:24:26.400]   We are such a techie household.
[00:24:26.400 --> 00:24:28.080]   Now Lisa will text Michael.
[00:24:28.080 --> 00:24:29.920]   Brush your teeth and go to bed.
[00:24:29.920 --> 00:24:32.520]   She sends him a text.
[00:24:32.520 --> 00:24:34.000]   It's crazy.
[00:24:34.000 --> 00:24:35.560]   I did wire up the house.
[00:24:35.560 --> 00:24:40.960]   When the Amazon added the intercom feature to the Echo, where you could have...
[00:24:40.960 --> 00:24:44.880]   You could say Michael go to bed through the Echo, but he's smart.
[00:24:44.880 --> 00:24:48.200]   He immediately unplugged his Echo.
[00:24:48.200 --> 00:24:50.920]   We've had to find other means.
[00:24:50.920 --> 00:24:52.600]   Your kids aren't old enough yet, Georgia.
[00:24:52.600 --> 00:24:55.160]   Are they to have to do that?
[00:24:55.160 --> 00:24:56.160]   I don't.
[00:24:56.160 --> 00:24:57.160]   They're not really old enough.
[00:24:57.160 --> 00:25:00.680]   We make sure that we restrict the amount of time that they're on technology.
[00:25:00.680 --> 00:25:05.280]   But when they're playing a video game on their phone, I will text them and say, "Go grab
[00:25:05.280 --> 00:25:06.280]   this or get that."
[00:25:06.280 --> 00:25:08.320]   It's just so much to scream through the house.
[00:25:08.320 --> 00:25:09.320]   Right.
[00:25:09.320 --> 00:25:11.680]   It's easy to get up and actually walk.
[00:25:11.680 --> 00:25:12.680]   So...
[00:25:12.680 --> 00:25:13.680]   My mother...
[00:25:13.680 --> 00:25:14.920]   That's one of the cases.
[00:25:14.920 --> 00:25:20.200]   My mother in the old days before the internet, she got tired of shouting, "Dinner!"
[00:25:20.200 --> 00:25:22.000]   So she got a bell.
[00:25:22.000 --> 00:25:23.160]   And she just would ring a bell.
[00:25:23.160 --> 00:25:24.920]   And now, any time I hear a bell, I salivate.
[00:25:24.920 --> 00:25:25.920]   I don't...
[00:25:25.920 --> 00:25:26.920]   Very plaid.
[00:25:26.920 --> 00:25:27.920]   A little text message.
[00:25:27.920 --> 00:25:30.760]   The text message is just a bell.
[00:25:30.760 --> 00:25:31.760]   It's an electronic bell.
[00:25:31.760 --> 00:25:32.760]   Is that what you're saying?
[00:25:32.760 --> 00:25:35.800]   Yeah, basically that's all it is.
[00:25:35.800 --> 00:25:36.800]   Should we stay?
[00:25:36.800 --> 00:25:37.800]   Should we stay...
[00:25:37.800 --> 00:25:39.920]   Well, let me do the Facebook thing.
[00:25:39.920 --> 00:25:41.600]   We have more security stuff to talk about.
[00:25:41.600 --> 00:25:43.480]   There's actually a ton of stuff to talk about.
[00:25:43.480 --> 00:25:45.720]   Jason Heiner is here.
[00:25:45.720 --> 00:25:49.800]   We've got of course Greg Farrow here and The Wonderful Georgia Dow.
[00:25:49.800 --> 00:25:51.880]   And Georgia, I think you'd be proud of me.
[00:25:51.880 --> 00:25:53.320]   Maybe not.
[00:25:53.320 --> 00:25:54.600]   Last night, I finally had it.
[00:25:54.600 --> 00:25:56.280]   I read the story.
[00:25:56.280 --> 00:25:57.280]   There's...
[00:25:57.280 --> 00:25:59.240]   By the way, we've reported on this.
[00:25:59.240 --> 00:26:03.280]   We've been reporting on this for over a year.
[00:26:03.280 --> 00:26:04.280]   Facebook.
[00:26:04.280 --> 00:26:10.160]   I've told people for more than a year, don't do Facebook quizzes because Facebook allows
[00:26:10.160 --> 00:26:15.560]   a quiz designer not only to get all the information about you because you took the quiz, but...
[00:26:15.560 --> 00:26:18.280]   And this is incredibly infuriating.
[00:26:18.280 --> 00:26:24.920]   They also allow the quiz designer to get information about your friends.
[00:26:24.920 --> 00:26:26.120]   Facebook says, "Well, wait a minute.
[00:26:26.120 --> 00:26:29.200]   No, we only allow that to imp...
[00:26:29.200 --> 00:26:32.920]   Let me see if I can find the stupid quote.
[00:26:32.920 --> 00:26:37.920]   They're only allowing collection of friends data to improve user experience in the app.
[00:26:37.920 --> 00:26:44.280]   It can't be sold or used for advertising, except that's exactly what Cambridge Analytica
[00:26:44.280 --> 00:26:45.480]   did.
[00:26:45.480 --> 00:26:51.480]   And now we know for a fact, even though we've known this for a while, we now have a whistleblower
[00:26:51.480 --> 00:26:59.000]   who has told the story of how Cambridge Analytica basically stole 50 million Facebook profiles,
[00:26:59.000 --> 00:27:00.760]   got all the information they need.
[00:27:00.760 --> 00:27:05.800]   Cambridge Analytica is owned by the Robert Mercer family and was run at the time by Steve
[00:27:05.800 --> 00:27:07.080]   Bannon.
[00:27:07.080 --> 00:27:12.720]   And of course, the information was intended to be used by Trump during the campaign.
[00:27:12.720 --> 00:27:18.120]   Although I don't blame Cambridge Analytica as much as I blame Facebook for even allowing
[00:27:18.120 --> 00:27:19.120]   this to happen.
[00:27:19.120 --> 00:27:23.040]   And you probably could say that other campaigns had done the same thing.
[00:27:23.040 --> 00:27:30.120]   The whistleblower said that they, since early 2014, they built a system that would profile
[00:27:30.120 --> 00:27:36.720]   user US voters in order to target them with personalized political advertisements.
[00:27:36.720 --> 00:27:40.840]   We exploited Facebook to harvest millions of people's profiles and built models to exploit
[00:27:40.840 --> 00:27:44.560]   what we knew about them and target their inner demons.
[00:27:44.560 --> 00:27:50.040]   This was the basis the entire company was built on.
[00:27:50.040 --> 00:27:57.600]   You know, it's funny because Dan Patterson, who writes for me, was on this story in August
[00:27:57.600 --> 00:27:59.520]   of 2016.
[00:27:59.520 --> 00:28:02.760]   He was one of the first to write about this.
[00:28:02.760 --> 00:28:10.280]   And he was on it from when Ted Cruz's campaign, or using Cambridge Analytica.
[00:28:10.280 --> 00:28:17.640]   And he was saying that there's just something fishy about this and it doesn't smell right.
[00:28:17.640 --> 00:28:25.840]   And it's amazing that we just didn't pay that enough people did not pay attention to this.
[00:28:25.840 --> 00:28:26.840]   Right?
[00:28:26.840 --> 00:28:33.600]   Kevin Arndt's a year ago, the observer which broke this story, saw the documents and this
[00:28:33.600 --> 00:28:39.880]   was confirmed by a Facebook statement that said that by late 2015, Facebook knew that
[00:28:39.880 --> 00:28:42.960]   this information had been harvested on unprecedented scale.
[00:28:42.960 --> 00:28:44.760]   It did not alert users.
[00:28:44.760 --> 00:28:49.880]   It took only limited steps to recover and secure the private information.
[00:28:49.880 --> 00:28:56.280]   And in fact, this really frustrates me when Facebook was told by the observer that we
[00:28:56.280 --> 00:28:59.120]   have this information, we're going to go live with a story tomorrow.
[00:28:59.120 --> 00:29:02.800]   Then and only then they kicked Cambridge Analytica off the platform.
[00:29:02.800 --> 00:29:03.800]   Yep.
[00:29:03.800 --> 00:29:04.800]   Yep.
[00:29:04.800 --> 00:29:05.800]   Yep.
[00:29:05.800 --> 00:29:06.800]   They knew.
[00:29:06.800 --> 00:29:09.600]   They knew for years.
[00:29:09.600 --> 00:29:10.600]   And really did nothing.
[00:29:10.600 --> 00:29:16.200]   It was completely a cover up of everything that was happening to that.
[00:29:16.200 --> 00:29:19.360]   And the thing is, is that no company can police itself.
[00:29:19.360 --> 00:29:21.280]   We need to have legislation that's in place.
[00:29:21.280 --> 00:29:22.280]   I'm sorry.
[00:29:22.280 --> 00:29:23.560]   Yes, legislation, government.
[00:29:23.560 --> 00:29:26.520]   I hear you, but no one can police themselves.
[00:29:26.520 --> 00:29:33.600]   The problem is, I agree with you 100% Georgia, but Facebook's a black box to Congress and
[00:29:33.600 --> 00:29:34.600]   it's regulated.
[00:29:34.600 --> 00:29:35.600]   It can't be, right?
[00:29:35.600 --> 00:29:36.600]   Like it can't be.
[00:29:36.600 --> 00:29:40.160]   How do you get that information if they don't want to give it?
[00:29:40.160 --> 00:29:43.240]   Well if they want to operate in the United States, they're going to have to be able to
[00:29:43.240 --> 00:29:45.160]   let people know how some things run.
[00:29:45.160 --> 00:29:46.920]   What is the information going to be used for?
[00:29:46.920 --> 00:29:50.360]   There you will have to be something that's readable to everyone that's going to be able
[00:29:50.360 --> 00:29:51.760]   to deal with it.
[00:29:51.760 --> 00:29:58.160]   And people, we have to reinstate educating people that work in the government about technology.
[00:29:58.160 --> 00:30:01.120]   Which you know, we've ended up just funding.
[00:30:01.120 --> 00:30:03.440]   So why doesn't Facebook just relocate to the Philippines?
[00:30:03.440 --> 00:30:06.320]   They're already in tight with the Philippine president.
[00:30:06.320 --> 00:30:10.680]   We've already seen accusations leveled at Facebook saying that they are actively supporting
[00:30:10.680 --> 00:30:12.680]   the regime of Duarte over there who's-
[00:30:12.680 --> 00:30:13.680]   Oh, horrible.
[00:30:13.680 --> 00:30:14.680]   Quite.
[00:30:14.680 --> 00:30:18.600]   You know, I don't want to get too carried away, but carrying out terrible things against
[00:30:18.600 --> 00:30:19.600]   the citizens.
[00:30:19.600 --> 00:30:22.680]   So, Facebook could just up from Silicon Valley and relocate to the Philippines to continue
[00:30:22.680 --> 00:30:26.480]   on in the US government as vectorly zero control, right?
[00:30:26.480 --> 00:30:28.880]   Yeah, it's, you know, it's true.
[00:30:28.880 --> 00:30:35.160]   Like the thing is, there are three companies right now that are disrupting markets that
[00:30:35.160 --> 00:30:42.720]   are up, that are turning society upside down in so many ways.
[00:30:42.720 --> 00:30:47.840]   And it's because they are five to ten years ahead of everybody else on data.
[00:30:47.840 --> 00:30:51.240]   And they know more about us than we know about ourselves.
[00:30:51.240 --> 00:30:57.360]   And they're using that data to monetize the living crap, you know, out of everything that
[00:30:57.360 --> 00:30:58.360]   they have.
[00:30:58.360 --> 00:31:04.760]   And they are incented to keep that as private and as proprietary as possible because it's
[00:31:04.760 --> 00:31:06.200]   a goldmine, right?
[00:31:06.200 --> 00:31:08.200]   It's an absolute goldmine.
[00:31:08.200 --> 00:31:09.200]   And obviously-
[00:31:09.200 --> 00:31:13.800]   They're very sensitive to keep it to themselves because if they give it away, they lose control.
[00:31:13.800 --> 00:31:14.800]   Somebody else can monetize.
[00:31:14.800 --> 00:31:15.800]   So the thing that-
[00:31:15.800 --> 00:31:16.800]   Yep.
[00:31:16.800 --> 00:31:20.640]   I bet I'm willing to bet a substantial sum of money that the executives inside of Facebook
[00:31:20.640 --> 00:31:25.600]   are mega pissed that someone else is making money from their data, right?
[00:31:25.600 --> 00:31:28.040]   That's the problem with gamer-channel, I think.
[00:31:28.040 --> 00:31:29.200]   They're not making that much.
[00:31:29.200 --> 00:31:31.120]   You're supposed to buy that from us.
[00:31:31.120 --> 00:31:32.120]   What do you get?
[00:31:32.120 --> 00:31:33.360]   Doom.
[00:31:33.360 --> 00:31:37.120]   And the thing that frustrates me is I don't take Facebook quizzes because I know that
[00:31:37.120 --> 00:31:38.560]   that gives them your information.
[00:31:38.560 --> 00:31:42.320]   That's, you know, you see these quizzes, which game of Thrones character are you?
[00:31:42.320 --> 00:31:43.840]   Are you smarter than a fifth grader?
[00:31:43.840 --> 00:31:45.040]   How's your spelling?
[00:31:45.040 --> 00:31:49.080]   And I see so many people on my timeline saying, "See how smart I am?
[00:31:49.080 --> 00:31:50.920]   I'm in the 99th percentile in spelling."
[00:31:50.920 --> 00:31:52.080]   I'm saying, "You're not smart.
[00:31:52.080 --> 00:31:53.080]   You're a moron.
[00:31:53.080 --> 00:31:54.800]   You just took that quiz.
[00:31:54.800 --> 00:31:56.360]   That was a dopey quiz.
[00:31:56.360 --> 00:31:57.360]   That was made up quiz.
[00:31:57.360 --> 00:31:59.320]   They just wanted your personal information."
[00:31:59.320 --> 00:32:02.440]   But you know what really frost me is, "I don't take the quiz.
[00:32:02.440 --> 00:32:03.440]   It doesn't matter.
[00:32:03.440 --> 00:32:04.440]   My friends did.
[00:32:04.440 --> 00:32:05.440]   They got my information."
[00:32:05.440 --> 00:32:06.440]   Yeah.
[00:32:06.440 --> 00:32:07.440]   And that's infuriating.
[00:32:07.440 --> 00:32:08.440]   It's true.
[00:32:08.440 --> 00:32:13.680]   It was like 270,000 people downloaded the app and 500 million people's information is out
[00:32:13.680 --> 00:32:14.680]   there.
[00:32:14.680 --> 00:32:17.000]   It's a huge amount of people that did not do it.
[00:32:17.000 --> 00:32:20.440]   And you're still, because you're part of the ecosystem, in the end, the only thing that
[00:32:20.440 --> 00:32:25.200]   matters to Facebook is if you delete Facebook and ask them to delete all the data that they
[00:32:25.200 --> 00:32:28.120]   have on you because they're going to keep it anyways.
[00:32:28.120 --> 00:32:33.280]   And in the end, the amount of media literacy that we teach to our children and to ourselves.
[00:32:33.280 --> 00:32:38.680]   Like we really, we are so easily sucked into these applications for internet points that
[00:32:38.680 --> 00:32:40.640]   it's pretty sad.
[00:32:40.640 --> 00:32:52.920]   The good news is thanks to the EU and the GDPR, Facebook now has a way to actually permanently
[00:32:52.920 --> 00:32:54.200]   delete your information.
[00:32:54.200 --> 00:33:01.760]   In the past, when you got off of Facebook, they would deactivate your account for six
[00:33:01.760 --> 00:33:05.960]   months, hoping that you would at some point accidentally log in and they go, "Oh, welcome
[00:33:05.960 --> 00:33:06.960]   back."
[00:33:06.960 --> 00:33:10.600]   By the way, when you leave Facebook, I should have done this on the air because it's hysterical.
[00:33:10.600 --> 00:33:17.000]   They put pictures of all your friends and they look sad and they say, "It literally
[00:33:17.000 --> 00:33:20.600]   said, 'George Adao is so sorry you're leaving Facebook.
[00:33:20.600 --> 00:33:23.200]   Do you want to send her a note telling her why?
[00:33:23.200 --> 00:33:25.960]   It's the most offensive."
[00:33:25.960 --> 00:33:27.960]   Emotional blackmail.
[00:33:27.960 --> 00:33:28.960]   Awesome.
[00:33:28.960 --> 00:33:29.960]   Yeah.
[00:33:29.960 --> 00:33:30.960]   Yeah.
[00:33:30.960 --> 00:33:36.160]   And G. So now you can do a complete delete of your Facebook data.
[00:33:36.160 --> 00:33:39.720]   And I really think this is because coming in May, they were going to get in trouble with
[00:33:39.720 --> 00:33:41.600]   the EU if they didn't offer this.
[00:33:41.600 --> 00:33:44.000]   So it's not just deactivating.
[00:33:44.000 --> 00:33:45.960]   It does still take two weeks.
[00:33:45.960 --> 00:33:51.760]   So last night, and I see here Facebook saying it'll take 90 days to delete all the things
[00:33:51.760 --> 00:33:52.760]   you've posted.
[00:33:52.760 --> 00:33:53.760]   Well, we'll see.
[00:33:53.760 --> 00:33:54.760]   Why would it take 90 days?
[00:33:54.760 --> 00:33:55.760]   Our computers will be faster.
[00:33:55.760 --> 00:33:58.600]   Because they're hoping you're going to come back.
[00:33:58.600 --> 00:33:59.600]   Right.
[00:33:59.600 --> 00:34:00.600]   Cash is.
[00:34:00.600 --> 00:34:04.480]   It's not just the data that's in the primary system, but to do a complete deletion, you
[00:34:04.480 --> 00:34:06.240]   have to reach into all of the backups.
[00:34:06.240 --> 00:34:07.240]   Well, I hope they do this.
[00:34:07.240 --> 00:34:08.240]   Exactly.
[00:34:08.240 --> 00:34:11.360]   Well, really, anyway, I said this is it.
[00:34:11.360 --> 00:34:14.480]   The only way to really punish Facebook, yes, they should be regulated.
[00:34:14.480 --> 00:34:19.760]   Yes, you know, Mark Warner's honest ads bill should go through and then should require
[00:34:19.760 --> 00:34:24.520]   that just as on radio and TV, political ads, you have to be identified.
[00:34:24.520 --> 00:34:28.040]   You have to say this ad was paid for by so-and-so.
[00:34:28.040 --> 00:34:29.840]   That's not a requirement digital advertising.
[00:34:29.840 --> 00:34:30.840]   It should be.
[00:34:30.840 --> 00:34:31.840]   I hope happens.
[00:34:31.840 --> 00:34:32.840]   Yeah.
[00:34:32.840 --> 00:34:35.240]   But it's still not going to...
[00:34:35.240 --> 00:34:38.080]   Don't we know Mark Zuckerberg well enough by now?
[00:34:38.080 --> 00:34:39.080]   It's not going to stop.
[00:34:39.080 --> 00:34:42.760]   Are we ever going to see an adult in charge of these companies like an actual grownup instead
[00:34:42.760 --> 00:34:46.760]   of these overblown teenagers that actually sort of-
[00:34:46.760 --> 00:34:48.240]   Are grownups really better?
[00:34:48.240 --> 00:34:49.240]   He's a grownup.
[00:34:49.240 --> 00:34:51.200]   He's maximizing revenue.
[00:34:51.200 --> 00:34:54.280]   This is a grownup who has become one of the richest men in the world.
[00:34:54.280 --> 00:34:55.280]   That's a grownup.
[00:34:55.280 --> 00:34:57.080]   Grownups are no better.
[00:34:57.080 --> 00:34:58.080]   Grownups are no better.
[00:34:58.080 --> 00:35:01.560]   In the end, any of these companies, all they want to do is make money.
[00:35:01.560 --> 00:35:04.560]   And I get it, but we have to make sure that we can make it.
[00:35:04.560 --> 00:35:08.480]   I honestly don't even blame Facebook or the engineers.
[00:35:08.480 --> 00:35:09.720]   They're doing what...
[00:35:09.720 --> 00:35:10.720]   This is capitalism.
[00:35:10.720 --> 00:35:12.000]   They're doing what?
[00:35:12.000 --> 00:35:13.920]   They have a fiduciary responsibility.
[00:35:13.920 --> 00:35:16.200]   They're shareholders to do maximize profit.
[00:35:16.200 --> 00:35:17.600]   They're supposed to do it legally.
[00:35:17.600 --> 00:35:18.600]   Okay.
[00:35:18.600 --> 00:35:22.680]   Honestly, that's probably not right, but they're not completely legal, but they're trying their
[00:35:22.680 --> 00:35:29.000]   best to be sort of quasi-legal, but they're maximizing profit.
[00:35:29.000 --> 00:35:30.000]   That's fine.
[00:35:30.000 --> 00:35:33.320]   So instead of saying let's regulate them, I'm going to vote with my feet.
[00:35:33.320 --> 00:35:35.600]   And by the way, I don't...
[00:35:35.600 --> 00:35:39.640]   This is not the first time I've quit Facebook, but this is the last time I've ever gone back.
[00:35:39.640 --> 00:35:40.640]   I'm never going back.
[00:35:40.640 --> 00:35:41.640]   I'm never going back.
[00:35:41.640 --> 00:35:42.640]   I'm going to remember, though.
[00:35:42.640 --> 00:35:43.640]   I'm going to remember Leo.
[00:35:43.640 --> 00:35:44.640]   No, I never look back.
[00:35:44.640 --> 00:35:45.640]   When you go back to Facebook, I'm going to be like, "Oh."
[00:35:45.640 --> 00:35:47.440]   I don't think I'm alone in this.
[00:35:47.440 --> 00:35:53.480]   We learned Facebook even said that 2 million fewer users under 18 in the past year.
[00:35:53.480 --> 00:35:55.560]   I think this is the beginning of an exodus.
[00:35:55.560 --> 00:36:00.560]   And I really believe this might be the final straw for a lot of users.
[00:36:00.560 --> 00:36:03.480]   I don't know, but the story is the data.
[00:36:03.480 --> 00:36:05.040]   The data is the story, right?
[00:36:05.040 --> 00:36:06.040]   It's not.
[00:36:06.040 --> 00:36:07.960]   Cambridge Analytic is not making that much money.
[00:36:07.960 --> 00:36:14.080]   They were able to do this because of what Facebook has and the data that they have.
[00:36:14.080 --> 00:36:20.120]   And that data is a goldmine, data is the new oil, data is where the money is.
[00:36:20.120 --> 00:36:25.640]   And like I said, there's three companies that are so far ahead of everybody else, Microsoft,
[00:36:25.640 --> 00:36:26.640]   not Microsoft.
[00:36:26.640 --> 00:36:27.640]   Google.
[00:36:27.640 --> 00:36:28.640]   Amazon.
[00:36:28.640 --> 00:36:29.640]   Amazon.
[00:36:29.640 --> 00:36:30.640]   And Facebook.
[00:36:30.640 --> 00:36:31.640]   And Facebook.
[00:36:31.640 --> 00:36:32.640]   And Alibaba.
[00:36:32.640 --> 00:36:33.640]   Now, there's a bunch of others.
[00:36:33.640 --> 00:36:34.640]   Tencent.
[00:36:34.640 --> 00:36:36.640]   Alibaba, you're forgetting the rest of the world.
[00:36:36.640 --> 00:36:37.640]   Okay, ready.
[00:36:37.640 --> 00:36:38.640]   There's going to be a million.
[00:36:38.640 --> 00:36:39.640]   We chat.
[00:36:39.640 --> 00:36:40.640]   There's going to be a million.
[00:36:40.640 --> 00:36:41.640]   Our amazing.
[00:36:41.640 --> 00:36:42.640]   And they're ahead.
[00:36:42.640 --> 00:36:48.200]   But in terms of global reach, right, they're still so focused on the Chinese market that,
[00:36:48.200 --> 00:36:52.640]   you know, they will eventually be global companies, but they aren't currently.
[00:36:52.640 --> 00:36:59.000]   But those three companies are, and because they're in, you know, they have very, very
[00:36:59.000 --> 00:37:05.000]   close relationships with their government, they're a bit protected for the moment.
[00:37:05.000 --> 00:37:11.320]   But those three companies that I mentioned, they have really been able to run roughshod
[00:37:11.320 --> 00:37:19.480]   over the entire globe with the exception of the EU and basically be able to do whatever
[00:37:19.480 --> 00:37:25.280]   they want with all this data and be, have no transparency about what they're doing.
[00:37:25.280 --> 00:37:30.280]   And that's the problem.
[00:37:30.280 --> 00:37:33.520]   Cambridge Analytica is just like a NAT that was able to use this platform to siphon a
[00:37:33.520 --> 00:37:36.480]   little bit off, right?
[00:37:36.480 --> 00:37:41.680]   The real problem, the real issue is the data and the fact that we have no regulation about
[00:37:41.680 --> 00:37:42.680]   it.
[00:37:42.680 --> 00:37:45.640]   And it's getting, we're getting later and later in the game.
[00:37:45.640 --> 00:37:50.320]   And the EU and GDPR is making a difference because these companies as well as a lot of
[00:37:50.320 --> 00:37:53.160]   others, you know, they essentially are making that their baseline.
[00:37:53.160 --> 00:37:57.760]   If they're going to have to do that there, then, you know, in Europe to be in that market,
[00:37:57.760 --> 00:38:02.200]   then it is having effect on what they're doing in other markets as well because it's
[00:38:02.200 --> 00:38:06.040]   just less expensive for them to get back to fiduciary responsibility.
[00:38:06.040 --> 00:38:10.760]   But, you know, we still have this huge problem that we just haven't woken up to the fact
[00:38:10.760 --> 00:38:16.360]   that, you know, that data is the new oil and we can't let it be a wild, wild, west.
[00:38:16.360 --> 00:38:17.360]   Yeah.
[00:38:17.360 --> 00:38:21.600]   And even if they're operating somewhere else, if you put legislation in place that if you're
[00:38:21.600 --> 00:38:27.080]   operating here as well, which they want to in the States, is a huge area for them.
[00:38:27.080 --> 00:38:30.880]   So then they'll end up like, you know, falling into line.
[00:38:30.880 --> 00:38:35.080]   And we need to, in the end, what we need though is like media literacy.
[00:38:35.080 --> 00:38:38.720]   We need to teach our kids how to deal with social media, what's happening with it and
[00:38:38.720 --> 00:38:39.960]   why.
[00:38:39.960 --> 00:38:42.920]   And I think that, you know, old data is worth nothing.
[00:38:42.920 --> 00:38:46.800]   And old is like a really short period of time when we talk about the technological age.
[00:38:46.800 --> 00:38:51.040]   So if a lot of people, there's an exodus from Facebook, which, you know, in my, I don't
[00:38:51.040 --> 00:38:53.480]   use Facebook, so I think that would be great.
[00:38:53.480 --> 00:38:56.920]   But most of the young kids, they're still using other sets of social media and our brains
[00:38:56.920 --> 00:39:01.280]   are primed for wanting to get those clicks on social media.
[00:39:01.280 --> 00:39:07.200]   That validation is going less and less with real people and more and more with internet
[00:39:07.200 --> 00:39:08.200]   clicks.
[00:39:08.200 --> 00:39:09.200]   And we're primed for that.
[00:39:09.200 --> 00:39:13.560]   I have to say that it's easy to leave Facebook these days because it's not that compelling
[00:39:13.560 --> 00:39:14.560]   to be honest.
[00:39:14.560 --> 00:39:19.720]   And if you leave Facebook, you should also leave Facebook's WhatsApp and Instagram as
[00:39:19.720 --> 00:39:21.480]   well.
[00:39:21.480 --> 00:39:25.880]   But I haven't left Google and I haven't left Amazon and there'd be a lot harder to leave
[00:39:25.880 --> 00:39:26.880]   Google, right?
[00:39:26.880 --> 00:39:27.880]   Yeah.
[00:39:27.880 --> 00:39:28.880]   What am I going to use?
[00:39:28.880 --> 00:39:29.880]   Bingo is sad.
[00:39:29.880 --> 00:39:30.880]   Duck Duck go.
[00:39:30.880 --> 00:39:31.880]   I use it.
[00:39:31.880 --> 00:39:32.880]   It's sad.
[00:39:32.880 --> 00:39:33.880]   I'm just going to say it.
[00:39:33.880 --> 00:39:34.880]   It's hard.
[00:39:34.880 --> 00:39:36.040]   And I would have to give up Gmail.
[00:39:36.040 --> 00:39:37.320]   I would have to give up a lot of things.
[00:39:37.320 --> 00:39:39.800]   I actually did move my main mail account off Gmail.
[00:39:39.800 --> 00:39:40.800]   I used to use Gmail.
[00:39:40.800 --> 00:39:42.720]   I don't anymore.
[00:39:42.720 --> 00:39:44.560]   But it's a lot harder.
[00:39:44.560 --> 00:39:45.840]   It's easy to leave Facebook.
[00:39:45.840 --> 00:39:48.280]   So I'm putting a stake in the sand here.
[00:39:48.280 --> 00:39:49.480]   But I admit it's challenging.
[00:39:49.480 --> 00:39:51.800]   And I still buy a ton of stuff from Amazon.
[00:39:51.800 --> 00:39:56.240]   And Amazon arguably has more real data on me than Facebook did because they know everything
[00:39:56.240 --> 00:39:57.640]   I've purchased.
[00:39:57.640 --> 00:39:59.600]   They have microphones in my house.
[00:39:59.600 --> 00:40:04.560]   Yeah, but Amazon, I think the elephant in the room here is the political angle.
[00:40:04.560 --> 00:40:06.400]   And we haven't touched on that.
[00:40:06.400 --> 00:40:14.360]   The simple fact is that the data that Facebook let their partners, because these were signed
[00:40:14.360 --> 00:40:18.720]   up legally obligated partners who promised not to steal the data, but they stole the
[00:40:18.720 --> 00:40:23.800]   data anyway, highlights the fact that Facebook has very little control over its data, had
[00:40:23.800 --> 00:40:24.800]   very little.
[00:40:24.800 --> 00:40:29.520]   And even now has, once you order a Facebook employee, you can basically do anything you
[00:40:29.520 --> 00:40:30.520]   like.
[00:40:30.520 --> 00:40:34.040]   And the only reason we haven't seen more of this is just sheer blind luck.
[00:40:34.040 --> 00:40:38.040]   It seems to me to be more blatant than any other of these other companies.
[00:40:38.040 --> 00:40:39.040]   It's stupid.
[00:40:39.040 --> 00:40:40.800]   It is the most stupid technology company.
[00:40:40.800 --> 00:40:42.800]   Google is not being caught up in politics.
[00:40:42.800 --> 00:40:45.600]   Amazon is not being caught up in politics.
[00:40:45.600 --> 00:40:51.520]   Facebook consistently makes horrendous, unforced errors in the face of every political situation.
[00:40:51.520 --> 00:40:56.120]   So every time something comes out about Russia, Facebook says, no, no, not us, not us.
[00:40:56.120 --> 00:40:58.920]   And then somebody comes up with the evidence and say, yeah, you got us.
[00:40:58.920 --> 00:40:59.920]   And then it goes through.
[00:40:59.920 --> 00:41:00.920]   So frustrating.
[00:41:00.920 --> 00:41:05.520]   So, so, Greg, you're saying that them asking for all the information to be destroyed wasn't
[00:41:05.520 --> 00:41:09.400]   enough for them to do because they just asked and then they were, they were okay with it.
[00:41:09.400 --> 00:41:11.320]   They said that they did.
[00:41:11.320 --> 00:41:12.320]   There's nothing they can do.
[00:41:12.320 --> 00:41:13.960]   All they can do is leave us.
[00:41:13.960 --> 00:41:14.960]   They tick the little box.
[00:41:14.960 --> 00:41:17.400]   Yeah, you have to agree and sign an agreement.
[00:41:17.400 --> 00:41:21.040]   And if they find out later on, then they can sue, blah, blah, blah, blah.
[00:41:21.040 --> 00:41:24.240]   But the horses got the, you know, the gates open, the horse is gone.
[00:41:24.240 --> 00:41:30.520]   But the real issue here is that Cambridge Analytica was a UK company funded by alt-right,
[00:41:30.520 --> 00:41:33.800]   won by Steve Bannon, which is in Trump's government.
[00:41:33.800 --> 00:41:36.840]   The whole alt-right got involved in the Brexit thing here in the UK.
[00:41:36.840 --> 00:41:39.960]   We've now got the information commissioner's office in the UK announcing that they will
[00:41:39.960 --> 00:41:42.560]   open an investigation into this whole issue.
[00:41:42.560 --> 00:41:44.600]   So Facebook is now under fire.
[00:41:44.600 --> 00:41:49.560]   You're talking about the right wing of the American government is now looking at Facebook
[00:41:49.560 --> 00:41:51.840]   going, are you with us or are you against us?
[00:41:51.840 --> 00:41:52.840]   Oh, that's scary.
[00:41:52.840 --> 00:41:56.360]   Then you've got Cape General Analytica getting onto the right wing over here and they're using
[00:41:56.360 --> 00:41:58.000]   it and they're trying to say.
[00:41:58.000 --> 00:41:59.000]   This is scary.
[00:41:59.000 --> 00:42:00.000]   Yeah.
[00:42:00.000 --> 00:42:01.000]   Do you want to say?
[00:42:01.000 --> 00:42:04.840]   If you want to create an authoritarian regime, Facebook's your best friend.
[00:42:04.840 --> 00:42:07.520]   And that's exactly what they've done in the Philippines under Duarte.
[00:42:07.520 --> 00:42:09.760]   Same thing in Myanmar.
[00:42:09.760 --> 00:42:11.480]   Same thing's happening in many other countries.
[00:42:11.480 --> 00:42:18.160]   Facebook has been co-opted by governments, strong men governments to control the population
[00:42:18.160 --> 00:42:21.200]   and to control the flow of information.
[00:42:21.200 --> 00:42:24.000]   And there's no reason for Facebook to stay in the US.
[00:42:24.000 --> 00:42:27.920]   It could just bunk out at any time except for the fact that the US is the market which
[00:42:27.920 --> 00:42:29.360]   generates the most revenue for them.
[00:42:29.360 --> 00:42:33.000]   But they could probably just scoot off if they needed to if they thought to pressure.
[00:42:33.000 --> 00:42:34.160]   And they're childish enough.
[00:42:34.160 --> 00:42:40.560]   I mean, your average Silicon Valley executive has the mental brainpower of a 16 year old
[00:42:40.560 --> 00:42:41.760]   with a lot of hormones.
[00:42:41.760 --> 00:42:42.760]   They're so competitive.
[00:42:42.760 --> 00:42:44.560]   They're so inwardly looking.
[00:42:44.560 --> 00:42:46.720]   They're so focused on winning.
[00:42:46.720 --> 00:42:49.920]   They're not focused on the money as much as they are on the winning.
[00:42:49.920 --> 00:42:54.520]   They're socially incompetent to the level where I'm winning if I'm making more money.
[00:42:54.520 --> 00:42:56.560]   And so they're not actually following capitalism.
[00:42:56.560 --> 00:42:58.920]   They're not following any rules of society.
[00:42:58.920 --> 00:43:03.840]   They're just trying to win blindly, aggressively over and over and over, win, win, win.
[00:43:03.840 --> 00:43:07.080]   And the way that I keep score about winning is to make more money.
[00:43:07.080 --> 00:43:10.240]   And at some point that's going to come off the rails because there's no more money to
[00:43:10.240 --> 00:43:15.320]   make I suspect or something else happens.
[00:43:15.320 --> 00:43:22.880]   And so just to play devil's advocate here, I do think that to a degree Mark Zuckerberg
[00:43:22.880 --> 00:43:25.200]   is aware of the problem.
[00:43:25.200 --> 00:43:30.800]   And I think you've seen him the last couple of years in pretty clear some statements knowing
[00:43:30.800 --> 00:43:35.320]   that this thing has gotten out of control and he knows there's some serious problems.
[00:43:35.320 --> 00:43:39.360]   I mean, his number one, his new year's resolution for this year was fixed Facebook.
[00:43:39.360 --> 00:43:40.760]   Like that's pretty bold statement.
[00:43:40.760 --> 00:43:44.840]   That's basically telling everybody, including your shareholders, that something's broken
[00:43:44.840 --> 00:43:45.840]   and he's be fixed.
[00:43:45.840 --> 00:43:48.760]   >> And I mean, >> Someone shut the face right into it.
[00:43:48.760 --> 00:43:50.800]   They did, he did true, working out for himself.
[00:43:50.800 --> 00:43:55.000]   Somebody had to slam his face into the desk and go, look, bang, bang, bang.
[00:43:55.000 --> 00:43:59.480]   He got, his head got slammed into the desk 10, 12, 14 times before he went, oh yeah, there's
[00:43:59.480 --> 00:44:00.480]   a problem.
[00:44:00.480 --> 00:44:02.360]   >> No doubt, but he did admit it.
[00:44:02.360 --> 00:44:05.040]   He didn't just, you know, he wasn't just blathering on about, you know.
[00:44:05.040 --> 00:44:09.600]   >> He says fix it, but I'd be interested to see what he's actually doing to fix it.
[00:44:09.600 --> 00:44:14.160]   The latest thing is Facebook told CNN, oh, it was a rogue employee.
[00:44:14.160 --> 00:44:17.840]   We figured out it was a rogue employee that gave up all that information.
[00:44:17.840 --> 00:44:19.480]   So it wasn't our fault.
[00:44:19.480 --> 00:44:24.120]   My real problem is that if you're a normal person using Facebook, it's a very attractive
[00:44:24.120 --> 00:44:25.120]   thing.
[00:44:25.120 --> 00:44:26.320]   It's how you stay in touch with family and friends.
[00:44:26.320 --> 00:44:29.520]   You discover your high school sweetheart and what she's been up to.
[00:44:29.520 --> 00:44:31.480]   It's very attractive.
[00:44:31.480 --> 00:44:35.480]   Facebook acts as if you're giving them information, but they're keeping it private.
[00:44:35.480 --> 00:44:36.480]   You have control of it.
[00:44:36.480 --> 00:44:40.840]   You say, who's a friend who's an acquaintance, who is not to see your stuff.
[00:44:40.840 --> 00:44:44.960]   They really act as if, you know, you are controlling that information.
[00:44:44.960 --> 00:44:48.360]   They don't tell people that when you take a quiz, you're giving all your information
[00:44:48.360 --> 00:44:52.040]   in that company and you're giving up all your friends.
[00:44:52.040 --> 00:44:53.520]   I mean, you're a leader.
[00:44:53.520 --> 00:44:55.560]   You don't tell you that.
[00:44:55.560 --> 00:44:59.240]   They don't do it anymore because they realize that giving away the data meant other people
[00:44:59.240 --> 00:45:01.040]   will make it money or Facebook's platform.
[00:45:01.040 --> 00:45:03.040]   They don't do that third parties.
[00:45:03.040 --> 00:45:04.840]   No, I don't think so.
[00:45:04.840 --> 00:45:05.840]   They do still.
[00:45:05.840 --> 00:45:06.840]   They want to do.
[00:45:06.840 --> 00:45:11.880]   They can check it on or off if you choose, but people usually don't even read that or
[00:45:11.880 --> 00:45:12.880]   know what they're doing.
[00:45:12.880 --> 00:45:17.080]   I think that, you know, I would love to think that Zuckerberg actually, you know, wants
[00:45:17.080 --> 00:45:19.880]   to fix Facebook because who knows what that means.
[00:45:19.880 --> 00:45:23.680]   But the best way to tell of someone's behavior in the future is by their behavior in the
[00:45:23.680 --> 00:45:26.840]   past and they waited two years to be able to deal with this.
[00:45:26.840 --> 00:45:28.840]   They were not transparent about it.
[00:45:28.840 --> 00:45:33.700]   They only deleted them from their system when they found out and the information was
[00:45:33.700 --> 00:45:35.520]   still there anyways.
[00:45:35.520 --> 00:45:41.440]   So we know that in the end, their most important thing was Facebook and keep saving face in
[00:45:41.440 --> 00:45:42.840]   making the most amount of money.
[00:45:42.840 --> 00:45:46.840]   So no, I don't think that they really want to make a difference in the world or try to
[00:45:46.840 --> 00:45:47.840]   do the right thing.
[00:45:47.840 --> 00:45:51.920]   I think that they'll only do that if they have to or if it ends up hurting their bottom line
[00:45:51.920 --> 00:45:54.000]   by people deleting Facebook.
[00:45:54.000 --> 00:45:58.120]   And in the end, that's really like legislation I think is important, but I think that you're
[00:45:58.120 --> 00:46:01.480]   right, Leo, that you know, deleting Facebook is the biggest message that you could send
[00:46:01.480 --> 00:46:02.480]   to them.
[00:46:02.480 --> 00:46:05.040]   And if there's a huge exodus, they'll start to listen.
[00:46:05.040 --> 00:46:10.760]   My point was that I think Zuckerberg, I think Zuckerberg realizes there's a problem, but
[00:46:10.760 --> 00:46:13.760]   at this point, I'm not sure even what he could do.
[00:46:13.760 --> 00:46:17.680]   But do you think that he cares or does he care because he's going to put his daughter
[00:46:17.680 --> 00:46:18.680]   in economically?
[00:46:18.680 --> 00:46:21.360]   No, he cares because of that.
[00:46:21.360 --> 00:46:24.000]   But he's also going to build Gates territory.
[00:46:24.000 --> 00:46:25.400]   He's going to have done something.
[00:46:25.400 --> 00:46:27.200]   He owns the company outright.
[00:46:27.200 --> 00:46:29.040]   He has full control.
[00:46:29.040 --> 00:46:31.720]   All the voting stock exists in his pocket.
[00:46:31.720 --> 00:46:34.000]   If he wanted to do something, it would be done.
[00:46:34.000 --> 00:46:38.800]   Remember what happened in 2015 when he said, you know what, now we're going to make money.
[00:46:38.800 --> 00:46:40.680]   We're going to make money out of mobile ads.
[00:46:40.680 --> 00:46:42.200]   We're going to make money out of desktop ads.
[00:46:42.200 --> 00:46:44.560]   And guess how quickly they brought ads online?
[00:46:44.560 --> 00:46:45.560]   Nine months.
[00:46:45.560 --> 00:46:47.960]   We've already pulled out a lot of making to profits.
[00:46:47.960 --> 00:46:51.880]   This is a much more difficult problem than making ads off of mobile though.
[00:46:51.880 --> 00:46:58.440]   No, it's a huge problem because your business model is intertwined with this lack of privacy.
[00:46:58.440 --> 00:47:00.000]   I mean, that's the whole business model.
[00:47:00.000 --> 00:47:04.760]   What he would have to do is kind of what I'm getting to is he would have to be transparent
[00:47:04.760 --> 00:47:07.640]   about the way they're handling data, which is what they need to do.
[00:47:07.640 --> 00:47:11.480]   That's what I would recommend that they do, not because it's going to make them a lot more
[00:47:11.480 --> 00:47:12.480]   money.
[00:47:12.480 --> 00:47:14.160]   The thing is a cash cow.
[00:47:14.160 --> 00:47:15.480]   It's the right thing to do.
[00:47:15.480 --> 00:47:17.200]   But it's the right thing to do.
[00:47:17.200 --> 00:47:20.640]   And it is ultimately going to be the right thing to do in the US.
[00:47:20.640 --> 00:47:21.880]   What are you going to do in the Philippines?
[00:47:21.880 --> 00:47:23.320]   What are you going to do in Burma?
[00:47:23.320 --> 00:47:25.400]   What are you going to do in Australia or China?
[00:47:25.400 --> 00:47:26.400]   What are you going to do in the UK?
[00:47:26.400 --> 00:47:27.400]   Look what's happening in China.
[00:47:27.400 --> 00:47:33.920]   I mean, I really, China has now said that it, I didn't, this is so black mirror.
[00:47:33.920 --> 00:47:34.920]   I'm stunned.
[00:47:34.920 --> 00:47:41.720]   I didn't know this, but China has a social credit system that you can gain or lose social
[00:47:41.720 --> 00:47:44.680]   credit depending on how you behave.
[00:47:44.680 --> 00:47:48.080]   And if your social credit gets low enough, they're not going to let you on a plane or
[00:47:48.080 --> 00:47:49.840]   a train.
[00:47:49.840 --> 00:47:52.200]   You won't be able to travel.
[00:47:52.200 --> 00:47:53.200]   Anti-troll.
[00:47:53.200 --> 00:47:54.760]   It's like the anti-troll mechanism.
[00:47:54.760 --> 00:47:55.760]   Yeah.
[00:47:55.760 --> 00:47:56.760]   A government branded anti-troll.
[00:47:56.760 --> 00:48:02.760]   If you spread false, and this is, remember, the Chinese government is defining this.
[00:48:02.760 --> 00:48:06.400]   If you spread false information about terrorism, what does that mean?
[00:48:06.400 --> 00:48:11.860]   Maybe you say something bad about President Xi, I don't know, cause trouble on flights.
[00:48:11.860 --> 00:48:18.300]   If you use an expired ticket or you smoke on a train, you can lose social credit and
[00:48:18.300 --> 00:48:19.300]   be banned.
[00:48:19.300 --> 00:48:21.780]   Well, smoking on a train, I'm in favor of that.
[00:48:21.780 --> 00:48:24.020]   I know, that one's not so bad.
[00:48:24.020 --> 00:48:27.980]   You should never get enough.
[00:48:27.980 --> 00:48:33.260]   This is, see, this is just part of a whole bunch of new things in China.
[00:48:33.260 --> 00:48:37.180]   Police are now wearing face recognition cameras.
[00:48:37.180 --> 00:48:41.340]   And there seems to be, I'm not really sure about this because I'm not an expert on the
[00:48:41.340 --> 00:48:46.260]   Chinese people, but there seems to be generalized acceptance that, well, if we have a more orderly
[00:48:46.260 --> 00:48:53.620]   society, it's okay if we have a social credit ranking and we ban people with low credit
[00:48:53.620 --> 00:48:54.620]   from the trains.
[00:48:54.620 --> 00:48:57.420]   It feels very black mirror to me.
[00:48:57.420 --> 00:49:02.260]   And I really feel like if you want to watch what's really going to happen or what could
[00:49:02.260 --> 00:49:07.100]   happen, watch what's happening in China now, it's not human rights.
[00:49:07.100 --> 00:49:08.660]   Yeah.
[00:49:08.660 --> 00:49:09.660]   It's different, though.
[00:49:09.660 --> 00:49:14.220]   I think that as culturally, they have such a hatred of violence and social unrest.
[00:49:14.220 --> 00:49:17.660]   I know they seem to be embracing it culturally.
[00:49:17.660 --> 00:49:23.820]   Yeah, whereas I think you have such a different cultural mindset in the US.
[00:49:23.820 --> 00:49:29.060]   I mean, we can't even agree to have background checks so people can't get semi-automatic
[00:49:29.060 --> 00:49:31.060]   weapons to shoot.
[00:49:31.060 --> 00:49:33.220]   No, we're the exact opposite, aren't we?
[00:49:33.220 --> 00:49:35.180]   Actually, that's a good point.
[00:49:35.180 --> 00:49:38.580]   Sometimes that's such a bad thing and a freedom.
[00:49:38.580 --> 00:49:43.220]   I don't know, the need to be forced into conformity can become a really dangerous thing.
[00:49:43.220 --> 00:49:48.180]   And if you look on Facebook or on Twitter, on Snapchat, people are trying to get as much
[00:49:48.180 --> 00:49:49.940]   internet credits already as they have.
[00:49:49.940 --> 00:49:52.940]   And if you have more followers, you're a better person than I am.
[00:49:52.940 --> 00:49:57.100]   And I feel- We have an unofficial social credit system, don't we?
[00:49:57.100 --> 00:49:58.100]   We do.
[00:49:58.100 --> 00:49:59.100]   And it works really well.
[00:49:59.100 --> 00:50:00.540]   We are hardwired.
[00:50:00.540 --> 00:50:06.020]   Our brains are hardwired to want other people to validate us, to socially validate us.
[00:50:06.020 --> 00:50:09.940]   And we love getting treats and perks because we're a better person than someone else's.
[00:50:09.940 --> 00:50:13.140]   If you take a look at, I have a more expensive phone than you do.
[00:50:13.140 --> 00:50:14.860]   I have a better car than you do.
[00:50:14.860 --> 00:50:19.820]   I have the winning team that's the one that's my team versus your team.
[00:50:19.820 --> 00:50:24.220]   Tribalism is strongly inclined to us and it was one of the things that helped us survive
[00:50:24.220 --> 00:50:25.220]   as a people.
[00:50:25.220 --> 00:50:30.540]   But now it can be used against us in a way to control our behavior and also for governments
[00:50:30.540 --> 00:50:35.940]   to be able to censure and sanction on people that are doing things that they don't want.
[00:50:35.940 --> 00:50:38.900]   It works almost implicitly, like too well.
[00:50:38.900 --> 00:50:40.660]   And because of that, it can be really dangerous.
[00:50:40.660 --> 00:50:41.660]   Well said.
[00:50:41.660 --> 00:50:45.580]   I don't know about you, but I'm terrified of people who've got guns.
[00:50:45.580 --> 00:50:47.620]   You know, the idea.
[00:50:47.620 --> 00:50:52.820]   You're worried about people dropping the loud on trains because they've been bad people.
[00:50:52.820 --> 00:50:56.380]   I'm just terrified walking down the street in America knowing that people are allowed
[00:50:56.380 --> 00:50:57.380]   to have guns.
[00:50:57.380 --> 00:50:59.460]   Some of those people are nuts.
[00:50:59.460 --> 00:51:03.820]   Do you actually feel when you come to the States, you live in the UK, we should say,
[00:51:03.820 --> 00:51:04.820]   you're Australian.
[00:51:04.820 --> 00:51:09.020]   Australia has a really interesting story where there was a terrible mass shooting.
[00:51:09.020 --> 00:51:10.740]   Was that in Tasmania, I think?
[00:51:10.740 --> 00:51:11.740]   Yes.
[00:51:11.740 --> 00:51:17.460]   He went into a theme park fundamentally and shot up 196 people, walked around for eight
[00:51:17.460 --> 00:51:19.780]   hours, killing people hour after hour.
[00:51:19.780 --> 00:51:22.180]   And Australian government decided that's it.
[00:51:22.180 --> 00:51:23.180]   We're not going to do it anymore.
[00:51:23.180 --> 00:51:27.380]   They changed the laws, but they also did a massive gun buyback, which was very successful.
[00:51:27.380 --> 00:51:31.220]   They took millions of guns out of circulation and there hasn't been another mass shooting
[00:51:31.220 --> 00:51:32.220]   since.
[00:51:32.220 --> 00:51:38.700]   And now if you're an American, they're crime level in Australia went down starkly.
[00:51:38.700 --> 00:51:44.860]   They're now higher than Canada's for safety and Canada's in the top 10.
[00:51:44.860 --> 00:51:49.380]   Now, you're an American would say though, that's great as long as you've got really
[00:51:49.380 --> 00:51:51.580]   good government that you trust.
[00:51:51.580 --> 00:51:53.380]   Yeah, but I got to be honest with you.
[00:51:53.380 --> 00:51:54.380]   But you can't fight the government.
[00:51:54.380 --> 00:51:55.380]   Be honest with you.
[00:51:55.380 --> 00:51:57.380]   You can have all the big things.
[00:51:57.380 --> 00:52:02.180]   There's a way you can fight the government anyways.
[00:52:02.180 --> 00:52:03.180]   You've got cruise missiles.
[00:52:03.180 --> 00:52:04.180]   I'm not advocating that point of view, you guys.
[00:52:04.180 --> 00:52:06.180]   I'm just saying this is what Americans mindset.
[00:52:06.180 --> 00:52:07.180]   That's the first place you're facing.
[00:52:07.180 --> 00:52:12.180]   This is the way the political system's been hijacked by organizations such as the NRA
[00:52:12.180 --> 00:52:20.780]   to distort the debate politically.
[00:52:20.780 --> 00:52:24.260]   And I suspect that a certain significant amount of money.
[00:52:24.260 --> 00:52:27.820]   One of the maybe we should move the conversation on talking about how politics and money in
[00:52:27.820 --> 00:52:29.780]   the Broadcom versus Qualcomm discussion.
[00:52:29.780 --> 00:52:30.860]   I would love to get to that.
[00:52:30.860 --> 00:52:31.940]   We will in just a second.
[00:52:31.940 --> 00:52:33.820]   That's an interesting one too.
[00:52:33.820 --> 00:52:39.420]   President Trump took credit for nixing that acquisition, but it turns out it really wasn't.
[00:52:39.420 --> 00:52:42.140]   It's a part of the US government that's not widely known.
[00:52:42.140 --> 00:52:44.460]   We'll talk about that in just a second.
[00:52:44.460 --> 00:52:45.540]   We had a great week this week.
[00:52:45.540 --> 00:52:47.700]   I hope you saw some of our shows.
[00:52:47.700 --> 00:52:54.300]   If you didn't, don't worry because we've actually created a short movie for your enjoyment.
[00:52:54.300 --> 00:52:56.740]   Some of the things you missed this week on Twitter.
[00:52:56.740 --> 00:52:58.580]   Previously, on Twitter.
[00:52:58.580 --> 00:53:00.100]   So does this look like me?
[00:53:00.100 --> 00:53:01.740]   That does look like you.
[00:53:01.740 --> 00:53:03.740]   It actually looks like Mike Gelligan.
[00:53:03.740 --> 00:53:05.860]   Well, that's actually a compliment.
[00:53:05.860 --> 00:53:06.860]   I'll take it.
[00:53:06.860 --> 00:53:07.860]   You can change it.
[00:53:07.860 --> 00:53:09.660]   Oh, God, I'm wearing yellow shorts.
[00:53:09.660 --> 00:53:11.660]   Oh, you're so cheerful.
[00:53:11.660 --> 00:53:14.740]   Yeah, it's just like me.
[00:53:14.740 --> 00:53:16.140]   The new screen savers.
[00:53:16.140 --> 00:53:21.540]   A very own Jason Howell and producer went down to San Francisco to check out the Nano Fair.
[00:53:21.540 --> 00:53:23.780]   It's a tiny, tiny little fair.
[00:53:23.780 --> 00:53:26.580]   You can go a range of 10 miles on a single battery charge.
[00:53:26.580 --> 00:53:27.580]   Hey, it works.
[00:53:27.580 --> 00:53:30.140]   Not that bad.
[00:53:30.140 --> 00:53:31.380]   It's a triangulation.
[00:53:31.380 --> 00:53:32.980]   Annalie Newitz is my guest.
[00:53:32.980 --> 00:53:34.540]   Who in the book is autonomous?
[00:53:34.540 --> 00:53:37.860]   I want to point out right away that this is not that book.
[00:53:37.860 --> 00:53:41.540]   It's not utopian, but you wouldn't say it's dystopian either, right?
[00:53:41.540 --> 00:53:42.540]   It's utopian.
[00:53:42.540 --> 00:53:43.540]   You know, it's utopian.
[00:53:43.540 --> 00:53:45.340]   Yeah, it's a mixture.
[00:53:45.340 --> 00:53:46.340]   It's a mixture.
[00:53:46.340 --> 00:53:48.660]   It's a mixed bag.
[00:53:48.660 --> 00:53:54.420]   To it, the happiest place on earth.
[00:53:54.420 --> 00:53:55.740]   For those of you listening.
[00:53:55.740 --> 00:53:57.500]   Build your own vibrator.
[00:53:57.500 --> 00:53:59.940]   Jason's approach to boost at the Nano Fair.
[00:53:59.940 --> 00:54:01.940]   No, Jason.
[00:54:01.940 --> 00:54:02.940]   That he decided to decline.
[00:54:02.940 --> 00:54:04.620]   Well, guess what?
[00:54:04.620 --> 00:54:06.900]   There's part two of this coming up later.
[00:54:06.900 --> 00:54:15.940]   Will he or will he build your own vibrator people?
[00:54:15.940 --> 00:54:19.300]   Which segues right into our first ad this week.
[00:54:19.300 --> 00:54:22.460]   Actually, I guess it's our second ad this week.
[00:54:22.460 --> 00:54:27.340]   And I don't know how to do this, but maybe you can maybe Georgia Dow, you're a psychotherapist.
[00:54:27.340 --> 00:54:28.940]   Maybe you can help me with this.
[00:54:28.940 --> 00:54:32.860]   Maybe you just want to keep your hands off.
[00:54:32.860 --> 00:54:36.060]   Men's health is a topic that meant we were not good.
[00:54:36.060 --> 00:54:39.860]   Men are not good about talking about health issues, right?
[00:54:39.860 --> 00:54:42.340]   And there's one issue that we will just not bring up at all.
[00:54:42.340 --> 00:54:43.420]   You don't want to tell your doctor.
[00:54:43.420 --> 00:54:44.820]   You don't want to tell your friends.
[00:54:44.820 --> 00:54:48.180]   You definitely don't want to tell your wife erectile dysfunction, right?
[00:54:48.180 --> 00:54:53.340]   This is something that people are just nervous about, but you don't have to live with it
[00:54:53.340 --> 00:55:00.980]   because there's Roman, a men's health company that will do remote online, completely private
[00:55:00.980 --> 00:55:06.380]   diagnosis for ED and then offer convenient monthly delivery of medication.
[00:55:06.380 --> 00:55:08.020]   Now don't be embarrassed, guys.
[00:55:08.020 --> 00:55:10.380]   It's okay.
[00:55:10.380 --> 00:55:12.380]   This is going to help you.
[00:55:12.380 --> 00:55:15.980]   Guys don't like talking about this, but there's no reason to ignore it.
[00:55:15.980 --> 00:55:17.300]   All it takes is five minutes.
[00:55:17.300 --> 00:55:20.340]   You'll do an online survey about your medical history.
[00:55:20.340 --> 00:55:23.780]   You can give your preferences and medication too if you've got a preference.
[00:55:23.780 --> 00:55:25.260]   Roman handles everything.
[00:55:25.260 --> 00:55:30.260]   From online diagnosis to prescription delivery for ED meds, US licensed physicians will review
[00:55:30.260 --> 00:55:34.300]   the treatment requests within two hours and if appropriate.
[00:55:34.300 --> 00:55:38.340]   If it's not a harmful situation, they will write a prescription for you and then the
[00:55:38.340 --> 00:55:40.060]   medications delivered free to your door.
[00:55:40.060 --> 00:55:42.740]   This is not one of those phony online pharmacies.
[00:55:42.740 --> 00:55:48.140]   This is a real pharmacy, Roman pharmacy, discreetly packaged with RHP on the front.
[00:55:48.140 --> 00:55:50.700]   Everybody feels happened automatically every month or every quarter.
[00:55:50.700 --> 00:55:52.860]   I know you don't want to talk about this to your buddies.
[00:55:52.860 --> 00:55:57.420]   You don't want to talk about it to your doctor, but Roman's a place to start $50 off
[00:55:57.420 --> 00:55:59.340]   your first month.
[00:55:59.340 --> 00:56:00.340]   Try it.
[00:56:00.340 --> 00:56:01.340]   Look at there.
[00:56:01.340 --> 00:56:02.420]   Nice lady, Dr. Jocelyn.
[00:56:02.420 --> 00:56:03.420]   I would trust her.
[00:56:03.420 --> 00:56:04.340]   Dr. Pepper.
[00:56:04.340 --> 00:56:06.860]   That's a real name.
[00:56:06.860 --> 00:56:09.900]   Dr. Pepper and Dr. Steven.
[00:56:09.900 --> 00:56:10.900]   I want Dr. Pepper.
[00:56:10.900 --> 00:56:12.260]   Can I have Dr. Pepper?
[00:56:12.260 --> 00:56:19.060]   We'll review and prescribe at getroman.com/twit.
[00:56:19.060 --> 00:56:21.300]   Getroman.com/twit.
[00:56:21.300 --> 00:56:25.700]   Actually, when they approached us, everybody said, "You shouldn't do this."
[00:56:25.700 --> 00:56:26.700]   No, wait a minute.
[00:56:26.700 --> 00:56:27.700]   I think we should do this, Ed.
[00:56:27.700 --> 00:56:29.740]   I think this is something people should talk about.
[00:56:29.740 --> 00:56:31.380]   You shouldn't be embarrassed to talk about this.
[00:56:31.380 --> 00:56:32.380]   We shouldn't.
[00:56:32.380 --> 00:56:34.100]   We're horrible here about body functions.
[00:56:34.100 --> 00:56:35.100]   Yeah.
[00:56:35.100 --> 00:56:36.100]   We really are.
[00:56:36.100 --> 00:56:37.500]   And that's a really an North American thing.
[00:56:37.500 --> 00:56:39.460]   It's a North American thing.
[00:56:39.460 --> 00:56:43.220]   If you go down to Europe and other places, people are so much more open about talking
[00:56:43.220 --> 00:56:45.060]   about body functions.
[00:56:45.060 --> 00:56:48.700]   Often people will wait a really long time before they tell me about their body that's
[00:56:48.700 --> 00:56:49.700]   not working right.
[00:56:49.700 --> 00:56:50.700]   No.
[00:56:50.700 --> 00:56:53.140]   And if you're a doctor, you're an MFT.
[00:56:53.140 --> 00:56:55.100]   You're here to get help.
[00:56:55.100 --> 00:56:56.100]   Yeah.
[00:56:56.100 --> 00:56:57.340]   We all have stuff.
[00:56:57.340 --> 00:56:58.340]   And I can...
[00:56:58.340 --> 00:57:04.700]   A rectal dysfunction is a horrible thing to have happen, especially you have a loved
[00:57:04.700 --> 00:57:09.020]   person in your life and you want to be functional.
[00:57:09.020 --> 00:57:10.380]   This is a good thing.
[00:57:10.380 --> 00:57:11.380]   That's all.
[00:57:11.380 --> 00:57:13.540]   Thank you Puritans for making this all messy.
[00:57:13.540 --> 00:57:17.460]   Just growing it up for all of us.
[00:57:17.460 --> 00:57:18.820]   All right.
[00:57:18.820 --> 00:57:19.820]   Let's talk.
[00:57:19.820 --> 00:57:28.180]   So, Qualcomm, San Diego company, US founded, US run, of course, they own pretty much every
[00:57:28.180 --> 00:57:29.460]   patent for CDMA.
[00:57:29.460 --> 00:57:31.060]   They own many LTE patents.
[00:57:31.060 --> 00:57:32.820]   That's a very profitable part of their business.
[00:57:32.820 --> 00:57:39.860]   They also do chip designs and Qualcomm chips are in almost every smartphone made.
[00:57:39.860 --> 00:57:43.540]   Recently, Apple's been trying to pull back from Qualcomm by using Intel chips, but they
[00:57:43.540 --> 00:57:45.460]   weren't as good.
[00:57:45.460 --> 00:57:47.540]   So this is a good business.
[00:57:47.540 --> 00:57:52.380]   Broadcom also, chip manufacturer, used to be in the US.
[00:57:52.380 --> 00:57:55.300]   They went to Singapore, right?
[00:57:55.300 --> 00:57:56.620]   It sounds like Greg, you're up on this.
[00:57:56.620 --> 00:57:59.020]   So I'm going to let you take it from here.
[00:57:59.020 --> 00:58:01.820]   They made an offer to buy Qualcomm.
[00:58:01.820 --> 00:58:02.740]   Yep.
[00:58:02.740 --> 00:58:04.460]   Is it a hostile takeover?
[00:58:04.460 --> 00:58:05.860]   Yes, it was hostile.
[00:58:05.860 --> 00:58:07.300]   Qualcomm doesn't want to be acquired.
[00:58:07.300 --> 00:58:09.340]   They're looking for a much higher price.
[00:58:09.340 --> 00:58:15.660]   Broadcom offered $60, Qualcomm wants $90, which is kind of like a big, you know, two
[00:58:15.660 --> 00:58:18.020]   fingers telling you that you're really going to.
[00:58:18.020 --> 00:58:19.020]   That's a way.
[00:58:19.020 --> 00:58:21.860]   50% up is a very big ask.
[00:58:21.860 --> 00:58:22.860]   The game's been going backwards and forwards.
[00:58:22.860 --> 00:58:25.460]   If you go back a little bit, let's get some history here.
[00:58:25.460 --> 00:58:30.540]   Broadcom was originally a substantial part of Broadcom was the old Bell Labs.
[00:58:30.540 --> 00:58:35.980]   So there's a business called Fargo, which is the silicon part of HP and before that
[00:58:35.980 --> 00:58:38.220]   Compaq and Dell and blah, blah, blah.
[00:58:38.220 --> 00:58:44.380]   And so a substantial part of Broadcom's portfolio is a US business that then moved to Singapore.
[00:58:44.380 --> 00:58:48.740]   Our studios are in an old Broadcom building and Broadcom's from next door, actually.
[00:58:48.740 --> 00:58:49.740]   Yep.
[00:58:49.740 --> 00:58:54.380]   So, a Fargo and the progenesis or the core of the Avago acquisition that was part of a merger
[00:58:54.380 --> 00:58:57.420]   just a couple of years ago is still a US business.
[00:58:57.420 --> 00:59:02.060]   So the bulk of Broadcom's revenue and business still exists in the US, although the company
[00:59:02.060 --> 00:59:04.700]   is now domiciled in Singapore about-
[00:59:04.700 --> 00:59:06.380]   They've wanted to repatriate though.
[00:59:06.380 --> 00:59:07.980]   They want to come back, right?
[00:59:07.980 --> 00:59:10.140]   Well, they went and spoke to President Trump.
[00:59:10.140 --> 00:59:14.140]   They did a deal, got some great press and then announced that they're relocating back
[00:59:14.140 --> 00:59:15.980]   to the US.
[00:59:15.980 --> 00:59:20.700]   President Trump used that to say his grade is going to be great for jobs, US businesses
[00:59:20.700 --> 00:59:21.700]   and all that stuff.
[00:59:21.700 --> 00:59:23.540]   I remember that press conference.
[00:59:23.540 --> 00:59:27.820]   And so part of it that is the logic here is that Broadcom then took that opportunity
[00:59:27.820 --> 00:59:30.940]   to make another acquisition, so to take over Qualcomm.
[00:59:30.940 --> 00:59:35.380]   So what we're looking at here is the market for chips is starting to stagnate.
[00:59:35.380 --> 00:59:37.740]   The innovation pace is slowing down.
[00:59:37.740 --> 00:59:43.100]   So one way to keep your profits growing is to start acquiring your competitors and get
[00:59:43.100 --> 00:59:47.220]   big, go into scale, get large as quickly as possible so that you own the most market
[00:59:47.220 --> 00:59:51.700]   share and you can potentially grab a dominant market and then control the market to your
[00:59:51.700 --> 00:59:52.700]   benefit.
[00:59:52.700 --> 00:59:54.060]   Broadcom wants to buy Qualcomm.
[00:59:54.060 --> 00:59:56.580]   Qualcomm doesn't want to be acquired.
[00:59:56.580 --> 01:00:00.620]   Qualcomm goes to the long and short of it is that Qualcomm did a whole bunch of moves.
[01:00:00.620 --> 01:00:04.980]   Broadcom made moves to be appointed to the Qualcomm board.
[01:00:04.980 --> 01:00:08.100]   And then all of a sudden we see President Trump come out and say he's decided to kill
[01:00:08.100 --> 01:00:09.340]   the Qualcomm announcement.
[01:00:09.340 --> 01:00:16.460]   Now in the meantime, Qualcomm is spent over 100 million in Washington in lobbyists fees
[01:00:16.460 --> 01:00:17.540]   over the last 12 months.
[01:00:17.540 --> 01:00:23.540]   So Qualcomm has a long history of buying lobbyists in Washington to support its business.
[01:00:23.540 --> 01:00:27.900]   So a big part about what it spends its money on isn't is just related to protecting its
[01:00:27.900 --> 01:00:28.900]   patents.
[01:00:28.900 --> 01:00:32.860]   So if you have a large patent portfolio, you need politicians and political support to
[01:00:32.860 --> 01:00:37.340]   make sure that your portfolio doesn't get scuppered in some way to make sure that legal
[01:00:37.340 --> 01:00:39.020]   protections are in place.
[01:00:39.020 --> 01:00:44.220]   Broadcom failed to recognize that Qualcomm has a number of supporters in government literally
[01:00:44.220 --> 01:00:46.860]   due to how much money it pays politicians.
[01:00:46.860 --> 01:00:52.460]   And Qualcomm has had a long history, a 30, 20 or 30 year history of being using the US
[01:00:52.460 --> 01:00:54.820]   government to prop up its profits.
[01:00:54.820 --> 01:00:59.700]   That is it might get the US government to mandate the use of US technology, which just
[01:00:59.700 --> 01:01:03.420]   so happens to be Qualcomm only technology like CDMA.
[01:01:03.420 --> 01:01:04.420]   Right.
[01:01:04.420 --> 01:01:09.860]   So the reason that Qualcomm CDMA was forced onto Verizon was that the US government said
[01:01:09.860 --> 01:01:15.260]   we want one carrier to be using 3G and we want one carrier to be using CDMA, two technologies,
[01:01:15.260 --> 01:01:21.180]   so if one fails and the CDMA must be from Qualcomm because that's a UK company blubber,
[01:01:21.180 --> 01:01:22.180]   blubber, blubber.
[01:01:22.180 --> 01:01:24.020]   And in the end, of course, Verizon got stung.
[01:01:24.020 --> 01:01:28.820]   They went out, they wasted tens of billions of dollars going down a technology path that
[01:01:28.820 --> 01:01:34.340]   nobody wanted because the only country in the world to deploy CDMA was but Qualcomm made
[01:01:34.340 --> 01:01:35.340]   out like bandits.
[01:01:35.340 --> 01:01:36.340]   Right.
[01:01:36.340 --> 01:01:37.580]   They made billions of billions out of life.
[01:01:37.580 --> 01:01:39.900]   So you can use CDMA as well.
[01:01:39.900 --> 01:01:41.780]   China, China used some CDMA.
[01:01:41.780 --> 01:01:43.020]   A different band.
[01:01:43.020 --> 01:01:44.020]   Yeah.
[01:01:44.020 --> 01:01:46.900]   But LTE is the winner in all of this in the future.
[01:01:46.900 --> 01:01:48.900]   And in fact, even for Verizon's moving to LTE.
[01:01:48.900 --> 01:01:53.260]   Well, 4G LTE and ultimately 5G will have a much wider range of choice.
[01:01:53.260 --> 01:01:55.460]   So it was a very much a political one.
[01:01:55.460 --> 01:02:04.020]   It was CFIUS, the committee on foreign investment in the US that technically made this decision.
[01:02:04.020 --> 01:02:09.500]   But it sounds to me like your contention, Greg, is that this is just another example
[01:02:09.500 --> 01:02:12.660]   of lobbying on Qualcomm's part.
[01:02:12.660 --> 01:02:13.660]   That's my understanding.
[01:02:13.660 --> 01:02:17.180]   Qualcomm spent a lot of money and has had a long history of getting political decisions
[01:02:17.180 --> 01:02:18.620]   to go its way.
[01:02:18.620 --> 01:02:22.340]   It was able to go to CFIUS, as you say, get it?
[01:02:22.340 --> 01:02:26.060]   And then that went to President Trump, who was then able to claim the victory as he's
[01:02:26.060 --> 01:02:27.380]   own, protecting US jobs.
[01:02:27.380 --> 01:02:29.300]   I think there are some valid national security.
[01:02:29.300 --> 01:02:30.740]   Well, that's my real question.
[01:02:30.740 --> 01:02:33.460]   And I include Jason in this as well.
[01:02:33.460 --> 01:02:36.780]   And I've seen a number of articles saying, well, we don't like how it went down.
[01:02:36.780 --> 01:02:41.980]   But it wasn't a bad thing to prevent Broadcom from buying Qualcomm.
[01:02:41.980 --> 01:02:45.180]   I mean, it wasn't a great hostile takeover.
[01:02:45.180 --> 01:02:46.180]   I still broke.
[01:02:46.180 --> 01:02:48.180]   Broadcom is one of those weird companies.
[01:02:48.180 --> 01:02:50.260]   Greg characterized it perfectly.
[01:02:50.260 --> 01:02:55.900]   There's much of almost like a standards organization, a portfolio company, then really somebody
[01:02:55.900 --> 01:02:56.980]   that makes something.
[01:02:56.980 --> 01:03:02.980]   They're one of those companies that has a lot of IP.
[01:03:02.980 --> 01:03:04.980]   And there's a
[01:03:04.980 --> 01:03:05.980]   Sorry, Broadcom.
[01:03:05.980 --> 01:03:08.380]   Broadcom actually makes things.
[01:03:08.380 --> 01:03:09.380]   Okay.
[01:03:09.380 --> 01:03:10.380]   Actually has really.
[01:03:10.380 --> 01:03:14.260]   I think the way around, don't I have Broadcom chips and all of my stuff?
[01:03:14.260 --> 01:03:15.580]   No, Broadcom makes chips.
[01:03:15.580 --> 01:03:17.780]   Qualcomm is mostly just an IP.
[01:03:17.780 --> 01:03:20.860]   They're free branches, but most of the red becomes from IP.
[01:03:20.860 --> 01:03:25.980]   Qualcomm does make chips, but Broadcom's core business is chip design and manufacture.
[01:03:25.980 --> 01:03:29.420]   Qualcomm is about creating the technology and then licensing it as it's called.
[01:03:29.420 --> 01:03:35.460]   I guess I'm splitting hairs, but I think of it more the other way around on everything
[01:03:35.460 --> 01:03:36.940]   that I know of the two companies.
[01:03:36.940 --> 01:03:43.700]   But the point is that what the White House is talking about is all optics.
[01:03:43.700 --> 01:03:48.900]   I don't think there's not going to change any job from being in Singapore, which is
[01:03:48.900 --> 01:03:49.900]   the one place in the world.
[01:03:49.900 --> 01:03:52.180]   Was that the issue jobs or security?
[01:03:52.180 --> 01:03:53.980]   Well, it's both, right?
[01:03:53.980 --> 01:04:02.140]   We don't want a non-US company making the fundamental technologies in our smartphones.
[01:04:02.140 --> 01:04:03.940]   Singapore has a close relationship with China, right?
[01:04:03.940 --> 01:04:08.340]   So there's a little bit of a Singapore is an ally of the United States as well, right?
[01:04:08.340 --> 01:04:11.540]   100% UK protectorate for a long time, right?
[01:04:11.540 --> 01:04:12.540]   All that.
[01:04:12.540 --> 01:04:14.620]   It's very confusing for.
[01:04:14.620 --> 01:04:16.580]   So the point is it's optics, right?
[01:04:16.580 --> 01:04:17.580]   It's one of those things.
[01:04:17.580 --> 01:04:21.180]   It was easy to go to the president for the organization, right?
[01:04:21.180 --> 01:04:25.340]   To go to the president for CFIUS and say, "We're not going to do this.
[01:04:25.340 --> 01:04:30.780]   We shouldn't do this because it looks like a hostile takeover of a US company by an
[01:04:30.780 --> 01:04:33.460]   international company in Asia."
[01:04:33.460 --> 01:04:37.940]   And so that's why they did it from optics.
[01:04:37.940 --> 01:04:40.580]   They're both very well positioned in Washington.
[01:04:40.580 --> 01:04:47.980]   They both are companies that make chips, but really they make more money off the licensing
[01:04:47.980 --> 01:04:51.500]   of patents that they own.
[01:04:51.500 --> 01:05:00.780]   They're not companies that are big employers necessarily and somebody like Intel and Samsung
[01:05:00.780 --> 01:05:06.980]   that are employing lots and lots of people that are building the next generation.
[01:05:06.980 --> 01:05:12.660]   Of late, Broadcom has been more about investment in portfolio acquisition than any real technology
[01:05:12.660 --> 01:05:13.660]   company, right?
[01:05:13.660 --> 01:05:14.660]   Yes.
[01:05:14.660 --> 01:05:21.100]   And the other part about this is the rise of Huawei and ZTE as networking makers.
[01:05:21.100 --> 01:05:24.300]   And they're pushing very hard into the telco market.
[01:05:24.300 --> 01:05:29.980]   So the US market is largely closed to these Chinese companies and Broadcom makes the chips
[01:05:29.980 --> 01:05:34.420]   that companies like Huawei and ZTE and others can use to put in.
[01:05:34.420 --> 01:05:40.180]   And the US security apparatus is very concerned that they may end up where all the chips are
[01:05:40.180 --> 01:05:45.540]   designed by an international company, probably based in they don't see Broadcom necessarily
[01:05:45.540 --> 01:05:48.420]   as a viable owner of that.
[01:05:48.420 --> 01:05:52.580]   And they would also feel that they may end up beholden to Huawei providing the technology
[01:05:52.580 --> 01:05:55.780]   that would run the mobile phone networks in the US.
[01:05:55.780 --> 01:06:00.260]   5G is going to be primarily Huawei, right?
[01:06:00.260 --> 01:06:01.260]   Yes.
[01:06:01.260 --> 01:06:05.820]   Well, so there is not primarily, it's a very wide spectrum.
[01:06:05.820 --> 01:06:10.300]   Nokia, Ericsson, Cisco is trying to get in there.
[01:06:10.300 --> 01:06:13.340]   Qualcomm's got a lot of the patents around some of the 5G stuff.
[01:06:13.340 --> 01:06:17.860]   Well, they're trying to get their patents into the 5G portfolio so they can get revenue.
[01:06:17.860 --> 01:06:21.180]   Yeah, because they have a problem because their CDMA patents are going to be worthless
[01:06:21.180 --> 01:06:23.300]   soon enough.
[01:06:23.300 --> 01:06:25.220]   Some of them are fundamental.
[01:06:25.220 --> 01:06:26.860]   It's very complicated because there's thousands of them.
[01:06:26.860 --> 01:06:31.580]   And of course Apple and Qualcomm are in a vicious fight over patent royalties.
[01:06:31.580 --> 01:06:33.140]   Apple, yes.
[01:06:33.140 --> 01:06:36.980]   So you're looking at, for example, Broadcom is currently its wide infrastructure.
[01:06:36.980 --> 01:06:39.060]   So it does a lot of Ethernet chips today.
[01:06:39.060 --> 01:06:44.060]   So it's ASIC engines for Ethernet, it's one of its biggest divisions, 1.8 billion.
[01:06:44.060 --> 01:06:48.380]   All the chips in your Wi-Fi base stations are all Broadcom.
[01:06:48.380 --> 01:06:59.940]   Is it silly to worry then about security from chips made in China or Chinese related countries
[01:06:59.940 --> 01:07:00.940]   like Singapore?
[01:07:00.940 --> 01:07:01.940]   I mean, should we-
[01:07:01.940 --> 01:07:02.940]   It's right.
[01:07:02.940 --> 01:07:03.940]   It is rational.
[01:07:03.940 --> 01:07:04.940]   It's something we should-
[01:07:04.940 --> 01:07:07.940]   It is logically rational, but I do think it's practically silly.
[01:07:07.940 --> 01:07:08.940]   The chances of putting something-
[01:07:08.940 --> 01:07:13.220]   There's going to be a Chinese chip in almost anything you use.
[01:07:13.220 --> 01:07:16.700]   That's where it's going now anyways, that most things are going to be made there because
[01:07:16.700 --> 01:07:19.220]   it's so much more affordable for companies to be manufactured.
[01:07:19.220 --> 01:07:24.420]   Well, but there's a difference between using an iPhone, which is manufactured in China,
[01:07:24.420 --> 01:07:27.140]   but under the, I would hope, tight control of Apple.
[01:07:27.140 --> 01:07:31.300]   I'm sure they're test chips before they use them in the phone and so forth.
[01:07:31.300 --> 01:07:38.740]   In a Chinese company like Huawei or ZTE or Xiaomi, where it's at least partially owned
[01:07:38.740 --> 01:07:41.740]   by the Chinese military.
[01:07:41.740 --> 01:07:43.260]   So there is a difference there.
[01:07:43.260 --> 01:07:46.180]   I think you could trust an iPhone where you may not trust a Xiaomi phone.
[01:07:46.180 --> 01:07:47.180]   I don't know.
[01:07:47.180 --> 01:07:50.740]   I want a Xiaomi phone, so I don't know.
[01:07:50.740 --> 01:07:52.240]   I don't know.
[01:07:52.240 --> 01:07:54.500]   I think it's rational to ask the question.
[01:07:54.500 --> 01:08:00.020]   It's practically silly because we are not in a position to rationally evaluate that because
[01:08:00.020 --> 01:08:02.940]   chips are so phenomenally complicated.
[01:08:02.940 --> 01:08:07.980]   But I think let's assume that for whatever reason Qualcomm has decided to take a position
[01:08:07.980 --> 01:08:10.540]   to oppose the Broadcom board.
[01:08:10.540 --> 01:08:14.540]   And if you believe the proposition that I've put forward, which is that they've politically
[01:08:14.540 --> 01:08:18.060]   been able to work faster than Broadcom and outclass them at that level.
[01:08:18.060 --> 01:08:19.620]   So it really was just lobbying.
[01:08:19.620 --> 01:08:20.620]   All of it was just lobbying.
[01:08:20.620 --> 01:08:24.540]   Well, the interesting question now is we've seen Intel in a great deal of trouble.
[01:08:24.540 --> 01:08:28.620]   Does Intel now make a play for Qualcomm to get large and to compete with Broadcom?
[01:08:28.620 --> 01:08:29.620]   Yeah.
[01:08:29.620 --> 01:08:35.420]   Because the US government now actively support an Intel buyer.
[01:08:35.420 --> 01:08:36.740]   You have to kind of hope not.
[01:08:36.740 --> 01:08:42.940]   Even though, like we said, like Qualcomm and Broadcom, I know that they do make chips.
[01:08:42.940 --> 01:08:44.500]   It's the smaller chips.
[01:08:44.500 --> 01:08:46.500]   It's the networking chips.
[01:08:46.500 --> 01:08:47.500]   Yeah, but it's critical infrastructure.
[01:08:47.500 --> 01:08:51.980]   But we know of problems, security issues with the space band radio.
[01:08:51.980 --> 01:08:55.980]   And I mean, this is fairly critical infrastructure.
[01:08:55.980 --> 01:09:00.460]   If every phone in the country is hackable, that's a problem.
[01:09:00.460 --> 01:09:03.580]   I mean, obviously every phone in the nation is hackable.
[01:09:03.580 --> 01:09:04.580]   I know.
[01:09:04.580 --> 01:09:05.580]   I already.
[01:09:05.580 --> 01:09:07.580]   It has been famous.
[01:09:07.580 --> 01:09:08.580]   It has.
[01:09:08.580 --> 01:09:20.100]   Well, I think that what we have to worry about is, you know, is the fact that these companies,
[01:09:20.100 --> 01:09:27.460]   you know, like with Intel buying Qualcomm, if we get that kind of vertical integration,
[01:09:27.460 --> 01:09:29.980]   then that's almost always a bad thing for consumers.
[01:09:29.980 --> 01:09:32.300]   It almost always means higher prices.
[01:09:32.300 --> 01:09:40.540]   It almost always is something, whether it was Broadcom or Intel buying them, you know,
[01:09:40.540 --> 01:09:49.380]   the friction between x86 and the ARM processors has been a good thing for consumers.
[01:09:49.380 --> 01:09:50.740]   It's been a good thing for processors.
[01:09:50.740 --> 01:09:56.900]   Now it could be that, you know, every company and every technology runs its course.
[01:09:56.900 --> 01:10:01.540]   And so it could be that Qualcomm, you know, is a target because, you know, that they're
[01:10:01.540 --> 01:10:06.140]   sort of they've kind of run their course and, you know, Broadcom, Intel, maybe it wouldn't
[01:10:06.140 --> 01:10:07.140]   matter.
[01:10:07.140 --> 01:10:13.740]   But I do worry that, you know, that competitive pressure is helping is what's helping keep
[01:10:13.740 --> 01:10:17.420]   technology, the cost of it lower.
[01:10:17.420 --> 01:10:18.980]   And so we'll see.
[01:10:18.980 --> 01:10:25.540]   Well, so I'm curious if anybody knows, but George and I were, I think, referring to the
[01:10:25.540 --> 01:10:31.300]   hack, the SS7 hack that we learned about two years ago, as far as I know, has not been
[01:10:31.300 --> 01:10:32.300]   mitigated.
[01:10:32.300 --> 01:10:38.180]   Greg, do you know if this is the software that's used in the radios and all of our phones,
[01:10:38.180 --> 01:10:39.180]   right?
[01:10:39.180 --> 01:10:40.180]   Yeah.
[01:10:40.180 --> 01:10:41.180]   Can't be mitigated.
[01:10:41.180 --> 01:10:42.180]   It can't be mitigated.
[01:10:42.180 --> 01:10:43.180]   So it's there.
[01:10:43.180 --> 01:10:44.180]   Is there?
[01:10:44.180 --> 01:10:45.180]   And there's nothing you could do about it.
[01:10:45.180 --> 01:10:46.180]   No.
[01:10:46.180 --> 01:10:48.820]   That's why people are saying, you know how we get reaching this?
[01:10:48.820 --> 01:10:52.940]   The SMS messages that they send us are all triggered over SS7 signaling.
[01:10:52.940 --> 01:10:57.780]   And this is why people are calling for the end of SMS messages with the, you know, the
[01:10:57.780 --> 01:11:01.700]   how you get PayPal and they'll send you a text message with a pin number.
[01:11:01.700 --> 01:11:04.660]   Yeah, that's a terrible, terrible way to do it.
[01:11:04.660 --> 01:11:08.180]   Because SS7 is inherently insecure, it's a 30 year old technology was never designed to
[01:11:08.180 --> 01:11:09.180]   be secure.
[01:11:09.180 --> 01:11:13.380]   It was always assumed that the network was secure and therefore the protocol didn't need
[01:11:13.380 --> 01:11:15.820]   to be encrypted or safe.
[01:11:15.820 --> 01:11:20.740]   And there's nothing they could do about it, shorter for placing it, but there's no momentum
[01:11:20.740 --> 01:11:23.780]   to replace it because there's no money and voice.
[01:11:23.780 --> 01:11:30.220]   So SS7 would allow a hacker to send, read, forward, intercept text messages.
[01:11:30.220 --> 01:11:34.540]   But apparently you could do the same with calls as well, right?
[01:11:34.540 --> 01:11:37.300]   You can track the location of a phone.
[01:11:37.300 --> 01:11:38.300]   You can.
[01:11:38.300 --> 01:11:42.140]   I mean, this is, and this has been around, we've known about this for you.
[01:11:42.140 --> 01:11:43.540]   So what are we worried about?
[01:11:43.540 --> 01:11:44.540]   Broadcom.
[01:11:44.540 --> 01:11:50.020]   Well, the trick is to usually to get into the SS7 signaling, you've got to be attached to
[01:11:50.020 --> 01:11:52.460]   a network where the signaling is.
[01:11:52.460 --> 01:11:55.380]   And normally those networks are secured and safe.
[01:11:55.380 --> 01:11:58.740]   What we're finding increasingly is that the telcos who are in charge of those networks
[01:11:58.740 --> 01:12:00.980]   are no longer being safe.
[01:12:00.980 --> 01:12:07.180]   They're no longer spending money on security or maintaining those because the voice network,
[01:12:07.180 --> 01:12:08.580]   it doesn't generate revenue for them.
[01:12:08.580 --> 01:12:12.900]   So they're pushing it away to go and work on data or, you know, or like Verizon, they
[01:12:12.900 --> 01:12:17.740]   go and buy Yahoo and media companies and so forth to try and make money.
[01:12:17.740 --> 01:12:20.980]   And the voice network is fundamentally being abandoned because it's not a profit center
[01:12:20.980 --> 01:12:21.980]   for them.
[01:12:21.980 --> 01:12:29.140]   You remember watching 60 Minutes where they surveilled a congressman using a S7 hack and
[01:12:29.140 --> 01:12:31.220]   you're telling me it can't be fixed.
[01:12:31.220 --> 01:12:34.100]   I mean, Firefox and X in the chatroom said it best.
[01:12:34.100 --> 01:12:35.100]   SS7 is a feature.
[01:12:35.100 --> 01:12:36.100]   It's not a bug.
[01:12:36.100 --> 01:12:38.860]   Like it's been around forever.
[01:12:38.860 --> 01:12:43.980]   And it's until you replace that infrastructure, the protocol, right?
[01:12:43.980 --> 01:12:45.900]   It's not as good as the feeling of that.
[01:12:45.900 --> 01:12:46.940]   There's no momentum for that.
[01:12:46.940 --> 01:12:54.580]   There's a lot of entrenched entities that would prefer we just don't talk about this.
[01:12:54.580 --> 01:12:58.220]   SS7, I'll be the trick is you're going to get a new song.
[01:12:58.220 --> 01:13:03.140]   Including governmental agencies who would say, you know, let's just downplay this SS7.
[01:13:03.140 --> 01:13:06.140]   Because have you heard anything about it in the last couple of years?
[01:13:06.140 --> 01:13:07.140]   Has it been fixed?
[01:13:07.140 --> 01:13:08.780]   It's a nation state.
[01:13:08.780 --> 01:13:10.180]   It's a nation state level hack.
[01:13:10.180 --> 01:13:11.180]   Really.
[01:13:11.180 --> 01:13:14.460]   It's not something that ordinary, you know, I'm a classic the internet.
[01:13:14.460 --> 01:13:16.660]   SS7 doesn't usually travel over the internet.
[01:13:16.660 --> 01:13:20.900]   Although we're seeing stingrays everywhere, right?
[01:13:20.900 --> 01:13:21.900]   Different.
[01:13:21.900 --> 01:13:22.900]   That's a different thing.
[01:13:22.900 --> 01:13:24.860]   They actually have a stingray.
[01:13:24.860 --> 01:13:27.260]   You could use an SS7 hack with the stingray.
[01:13:27.260 --> 01:13:30.700]   Could you don't need an SS7 hack because you actually become a phone.
[01:13:30.700 --> 01:13:32.260]   Because you're getting everything.
[01:13:32.260 --> 01:13:36.900]   Yeah, you've got all of the metadata there because you're actually all your data is
[01:13:36.900 --> 01:13:39.100]   flowing through the meta station and the 3GPPP.
[01:13:39.100 --> 01:13:40.100]   So we're screwed.
[01:13:40.100 --> 01:13:42.460]   Any 100 different ways, basically.
[01:13:42.460 --> 01:13:43.460]   Pretty much until.
[01:13:43.460 --> 01:13:45.540]   But so for now, it's mostly a nation state.
[01:13:45.540 --> 01:13:50.460]   And I think there's kind of like a cyber war that's happening behind the scenes around
[01:13:50.460 --> 01:13:52.060]   SS7 that we don't see.
[01:13:52.060 --> 01:13:53.340]   That's what I think too.
[01:13:53.340 --> 01:13:54.340]   That's what I think too.
[01:13:54.340 --> 01:13:58.300]   I think the challenge here of course is that now that voice calls don't generate profits,
[01:13:58.300 --> 01:14:00.460]   there's no incentive here to fix that.
[01:14:00.460 --> 01:14:01.460]   Right.
[01:14:01.460 --> 01:14:04.100]   And I'm likely to be any soon.
[01:14:04.100 --> 01:14:05.100]   Yeah.
[01:14:05.100 --> 01:14:08.660]   That's why Google wants to do RCS and stuff like that.
[01:14:08.660 --> 01:14:09.660]   Or is that separate?
[01:14:09.660 --> 01:14:10.660]   Is that unruly?
[01:14:10.660 --> 01:14:11.740]   No, that's all to do with IoT.
[01:14:11.740 --> 01:14:16.140]   So there's a bunch of standards to do with RCS, low-rah, NBIOT.
[01:14:16.140 --> 01:14:18.140]   They're three low-powered.
[01:14:18.140 --> 01:14:23.180]   I thought RCS was their rich communications messaging that they want them.
[01:14:23.180 --> 01:14:24.180]   They did.
[01:14:24.180 --> 01:14:25.180]   RCS is dead.
[01:14:25.180 --> 01:14:27.180]   No one wants to have anything.
[01:14:27.180 --> 01:14:29.420]   Really what we're looking at is low-rah and NBIOT.
[01:14:29.420 --> 01:14:34.580]   There's a big fight there to do sub like old modem speed, like modem speed, like bits
[01:14:34.580 --> 01:14:37.340]   per second or 100,000 bits per second.
[01:14:37.340 --> 01:14:44.340]   So that a battery operated in like a CR2032 battery, the size of a 50 cent piece, 50
[01:14:44.340 --> 01:14:49.340]   pence piece, those types of devices, and they should be able to run for like 10 years
[01:14:49.340 --> 01:14:50.660]   on that battery.
[01:14:50.660 --> 01:14:55.140]   But they'll be able to just transmit little tiny bursts of like a temperature sensor.
[01:14:55.140 --> 01:15:00.900]   And it just basically once every 15 minutes wakes up and says 22 degrees.
[01:15:00.900 --> 01:15:04.540]   And to think that it all started.
[01:15:04.540 --> 01:15:13.900]   With this guy back in 1973, Steve Jobs, this was a resume.
[01:15:13.900 --> 01:15:14.900]   I don't know.
[01:15:14.900 --> 01:15:20.180]   Job application from Steve where he says he doesn't have a phone.
[01:15:20.180 --> 01:15:25.020]   When asked if he asks us to transportation, he says possible, but not probable.
[01:15:25.020 --> 01:15:30.740]   You could tell he was kind of a jerk even back then.
[01:15:30.740 --> 01:15:33.820]   Asked if he had any skills typing, no machines, no.
[01:15:33.820 --> 01:15:35.740]   He punched no computer and calculator.
[01:15:35.740 --> 01:15:36.740]   Yes.
[01:15:36.740 --> 01:15:38.780]   Design and tech.
[01:15:38.780 --> 01:15:39.780]   He's got a special ability.
[01:15:39.780 --> 01:15:45.700]   He wants to be electronics tech or design engineer for digital products.
[01:15:45.700 --> 01:15:51.620]   This went this job application from a teenage Steve Jobs.
[01:15:51.620 --> 01:15:56.780]   He would have been 18 when he did this hundred twenty.
[01:15:56.780 --> 01:15:58.300]   Probably not wearing any shoes at the same time.
[01:15:58.300 --> 01:16:00.260]   Probably not wearing any shoes or deodorant.
[01:16:00.260 --> 01:16:01.260]   Yeah.
[01:16:01.260 --> 01:16:07.020]   Went for sale at auction for a hundred seventy five, a hundred seventy four thousand seven
[01:16:07.020 --> 01:16:08.780]   hundred fifty seven dollars.
[01:16:08.780 --> 01:16:09.780]   Wow.
[01:16:09.780 --> 01:16:10.780]   Yeah.
[01:16:10.780 --> 01:16:11.780]   Wow.
[01:16:11.780 --> 01:16:12.780]   It's a historian's dream right there.
[01:16:12.780 --> 01:16:13.780]   Look at that.
[01:16:13.780 --> 01:16:14.780]   It's a pretty awesome document.
[01:16:14.780 --> 01:16:15.780]   I guess.
[01:16:15.780 --> 01:16:16.780]   Who do you think bought it?
[01:16:16.780 --> 01:16:17.780]   I don't know.
[01:16:17.780 --> 01:16:18.780]   I think that's overpriced.
[01:16:18.780 --> 01:16:19.780]   Hopefully a museum.
[01:16:19.780 --> 01:16:22.940]   Hopefully somebody like a museum or you know the computer history museum in Mountain View
[01:16:22.940 --> 01:16:23.940]   or somebody.
[01:16:23.940 --> 01:16:28.460]   I hope it was somebody like that or somebody that bought it and donated to them.
[01:16:28.460 --> 01:16:35.660]   I'll never forget going to I think it was the Cleveland Rock and Roll Hall of Fame.
[01:16:35.660 --> 01:16:39.660]   It might have been Seattle's Experience Music Center, but it was a great rock and roll
[01:16:39.660 --> 01:16:40.660]   museum.
[01:16:40.660 --> 01:16:49.260]   I think it was Cleveland and I saw John Lennon's handwritten lyrics for In My Life.
[01:16:49.260 --> 01:16:50.260]   Yeah.
[01:16:50.260 --> 01:16:52.860]   And that's worth a hundred twenty seven thousand dollars.
[01:16:52.860 --> 01:16:53.860]   It's fine.
[01:16:53.860 --> 01:16:55.660]   I don't think this is worth a hundred twenty seven.
[01:16:55.660 --> 01:16:56.660]   Yeah.
[01:16:56.660 --> 01:16:57.660]   Yeah.
[01:16:57.660 --> 01:16:58.660]   It's a Silicon Valley.
[01:16:58.660 --> 01:16:59.660]   It's a Silicon Valley.
[01:16:59.660 --> 01:17:00.660]   It's a Silicon Valley.
[01:17:00.660 --> 01:17:02.460]   Stupid is a stupid does.
[01:17:02.460 --> 01:17:03.460]   Yeah.
[01:17:03.460 --> 01:17:06.380]   It's got to be a you know Peter Thiel type that bought this.
[01:17:06.380 --> 01:17:07.380]   Like $10,000 worth.
[01:17:07.380 --> 01:17:08.380]   A letter.
[01:17:08.380 --> 01:17:10.740]   I hope it ends up in a museum somewhere though.
[01:17:10.740 --> 01:17:11.740]   It is kind of fun.
[01:17:11.740 --> 01:17:12.740]   It's just looking.
[01:17:12.740 --> 01:17:13.740]   Right?
[01:17:13.740 --> 01:17:17.580]   Because the point is that it shows you can start out you know not really knowing what
[01:17:17.580 --> 01:17:21.980]   you're doing not you know having it not having much of a clue and you can eventually
[01:17:21.980 --> 01:17:22.980]   figure it out.
[01:17:22.980 --> 01:17:23.980]   Yeah.
[01:17:23.980 --> 01:17:24.980]   I love it.
[01:17:24.980 --> 01:17:27.060]   Apple has announced they are going to have a March event.
[01:17:27.060 --> 01:17:29.620]   There were lots of rumors about a March event.
[01:17:29.620 --> 01:17:32.020]   The invites went out.
[01:17:32.020 --> 01:17:33.660]   They're kind of cool looking.
[01:17:33.660 --> 01:17:36.260]   Georgia have you seen give you to get one of these yet?
[01:17:36.260 --> 01:17:37.260]   No they don't.
[01:17:37.260 --> 01:17:38.260]   They don't.
[01:17:38.260 --> 01:17:39.260]   They don't invite me.
[01:17:39.260 --> 01:17:40.260]   They invite me.
[01:17:40.260 --> 01:17:42.460]   Renee Renee Renee gets to enjoy all kinds of stuff.
[01:17:42.460 --> 01:17:44.740]   I don't want to ask them on Tuesday.
[01:17:44.740 --> 01:17:51.260]   Let's take a field trip it says and kind of an a calligraphic illustration of an apple.
[01:17:51.260 --> 01:17:54.620]   Join us to your creative new ideas for teachers and students.
[01:17:54.620 --> 01:18:00.060]   It's going to be to prep school in Chicago Lane Tech College prep high school in Chicago.
[01:18:00.060 --> 01:18:06.100]   March 27th 10 a.m. Chicago time that's we're going to be covering it live that Tuesday.
[01:18:06.100 --> 01:18:07.860]   Both stream live 8 a.m.
[01:18:07.860 --> 01:18:11.980]   My time and then go right at iOS today.
[01:18:11.980 --> 01:18:12.980]   What do you think Georgia?
[01:18:12.980 --> 01:18:14.780]   What do you think Apple is going to announce?
[01:18:14.780 --> 01:18:18.820]   Well I think it's I think it's a wonderful thing of how to use Apple products in the
[01:18:18.820 --> 01:18:23.580]   classroom how to deal with accessibility how to help students be able to learn better
[01:18:23.580 --> 01:18:27.620]   and to be able to use Apple products because in the end if you you know you end up once
[01:18:27.620 --> 01:18:31.780]   you learn a certain ecosphere you end up staying on that ecosphere you feel comfortable
[01:18:31.780 --> 01:18:32.780]   with it so I think that Apple.
[01:18:32.780 --> 01:18:34.180]   I think that famous for doing that.
[01:18:34.180 --> 01:18:38.900]   I mean yeah well that's what really brought back right is is being in the classroom so
[01:18:38.900 --> 01:18:42.180]   I think that they're going back to that and I think that there's a lot of push that we
[01:18:42.180 --> 01:18:46.980]   need to have our kids understand media and be able to handle it and I think Apple wants
[01:18:46.980 --> 01:18:51.540]   to make sure that they're there at the forefront of it and don't lose ground to Google.
[01:18:51.540 --> 01:18:54.940]   They are losing ground Chromebooks have kind of dominated in the school.
[01:18:54.940 --> 01:18:55.940]   Oh my god they're there.
[01:18:55.940 --> 01:18:58.460]   They're just so much more incredible.
[01:18:58.460 --> 01:19:01.660]   Yeah the schools can't afford Apple products.
[01:19:01.660 --> 01:19:07.020]   So Apple has to figure out how can they get them back into the school system because if
[01:19:07.020 --> 01:19:11.500]   you use that at school then you're going to want to get that at home it makes sense to
[01:19:11.500 --> 01:19:15.340]   that and even though my kids don't use technology they have.
[01:19:15.340 --> 01:19:17.020]   Wait a minute what?
[01:19:17.020 --> 01:19:20.660]   They use technology they have to pay for their own technology they don't just get to run
[01:19:20.660 --> 01:19:25.300]   rampant on video games and have computers and how do they pay.
[01:19:25.300 --> 01:19:29.860]   They end up paying by using good marks getting good marks and classes doing homework doing
[01:19:29.860 --> 01:19:34.580]   things like that so we end up you know they do well in the school stuff and then they
[01:19:34.580 --> 01:19:38.660]   end up getting to be able to use technology and play VR do ever else they want for it.
[01:19:38.660 --> 01:19:45.140]   Mom and dad have not one but two VR simulator rooms in the house.
[01:19:45.140 --> 01:19:46.140]   Three now.
[01:19:46.140 --> 01:19:47.140]   Three.
[01:19:47.140 --> 01:19:48.140]   Three.
[01:19:48.140 --> 01:19:52.700]   We do have the PSVR set up as well but you know.
[01:19:52.700 --> 01:19:56.740]   I can just hear the conversation do you go to the kids when you're a grown up you can
[01:19:56.740 --> 01:20:00.220]   have your own VR until then you go to school.
[01:20:00.220 --> 01:20:04.580]   We have our degrees we've already done it luckily they didn't have VR with the kids
[01:20:04.580 --> 01:20:05.580]   so we didn't have to worry.
[01:20:05.580 --> 01:20:06.580]   That's right.
[01:20:06.580 --> 01:20:11.180]   All the social skills that we needed to the kids are lacking in the ability like the only
[01:20:11.180 --> 01:20:15.820]   problem with more tech in the classroom is that we already have kids that have an inability
[01:20:15.820 --> 01:20:20.700]   to be able to read emotions and understand body language and cues and the amount of social
[01:20:20.700 --> 01:20:22.740]   anxiety is kind of skyrocketing.
[01:20:22.740 --> 01:20:28.780]   Our son Lisa's son Michael is going to take a class is that this fall Lisa or the summer
[01:20:28.780 --> 01:20:29.780]   right.
[01:20:29.780 --> 01:20:36.060]   That's what the design the classes designed to teach you how to read people not in a
[01:20:36.060 --> 01:20:40.660]   negative bad way but so that you can see if somebody's if you're getting cues from somebody
[01:20:40.660 --> 01:20:46.260]   they're upset or they're happy because yeah great because like most kids he's like they
[01:20:46.260 --> 01:20:51.860]   don't they don't and it's weird it's not implicit we actually learned that through mimicry so
[01:20:51.860 --> 01:20:56.580]   if we're our heads are stuck into a computer or your parents heads are stuck in their computers
[01:20:56.580 --> 01:21:02.260]   are or on VR then you're not learning how to read other people's cues and I do that
[01:21:02.260 --> 01:21:06.900]   a lot in session of helping people be able to read what does someone mean because I do
[01:21:06.900 --> 01:21:11.500]   have kids come in and they have no clue if someone's upset or annoyed or they've insulted
[01:21:11.500 --> 01:21:17.740]   someone and most of body language 80% of language sorry is through body language and so you need
[01:21:17.740 --> 01:21:21.900]   to be able to do both I think it's a great idea to have a class to that but also we need
[01:21:21.900 --> 01:21:24.100]   to do that through personal interactions.
[01:21:24.100 --> 01:21:30.860]   Do you think males are particularly bad males are particularly you know myopic and and you
[01:21:30.860 --> 01:21:34.660]   know closed off to it and so have to work a little harder to overcome nature a little
[01:21:34.660 --> 01:21:38.740]   bit right to learn those. There is a little bit yes a little bit of that is actually biology
[01:21:38.740 --> 01:21:44.860]   right so sure sure and do more of the hunting and the fighting for things and women usually
[01:21:44.860 --> 01:21:49.340]   and again this is a little bit of bias people don't get angry to me but it's true women did
[01:21:49.340 --> 01:21:53.780]   work in larger social groups where they were watching over the kids and they had to foretell
[01:21:53.780 --> 01:21:57.860]   what these children were going to do wrong before they did it so that they would survive
[01:21:57.860 --> 01:22:01.700]   and be able to read other women that they were working with and so that was a we're
[01:22:01.700 --> 01:22:07.260]   usually by and large better at it but still I notice men and women right now young young
[01:22:07.260 --> 01:22:11.740]   adults that are having difficulty with being able to read people and because of that having
[01:22:11.740 --> 01:22:14.620]   a lot of social anxiety when they go into new events.
[01:22:14.620 --> 01:22:23.460]   It might really explain a lot about the bro culture an insensitivity to you know flame wars
[01:22:23.460 --> 01:22:27.740]   that's one of the reasons twitter becomes such as this god awful outrage engine there's
[01:22:27.740 --> 01:22:33.420]   no social cues going on and so you're you you would have conversations at twitter you
[01:22:33.420 --> 01:22:35.660]   would never have in real life.
[01:22:35.660 --> 01:22:38.940]   Everybody said the same thing about television they said the same thing about radio they said
[01:22:38.940 --> 01:22:41.660]   the same thing about if you go back to the 17th century.
[01:22:41.660 --> 01:22:43.060]   But it's true this time.
[01:22:43.060 --> 01:22:48.780]   But it actually true for even radio it is actually true for radio and TV and for other
[01:22:48.780 --> 01:22:53.820]   things we are not as good at delaying gratification.
[01:22:53.820 --> 01:22:58.140]   We're not as good at delaying gratification as we used to kids are now no longer ever
[01:22:58.140 --> 01:23:03.140]   able to be bored it causes them a lot of distress and dealing with that as with time
[01:23:03.140 --> 01:23:08.780]   now that we have a more instantaneous reward system our brains become more inclined to
[01:23:08.780 --> 01:23:14.860]   get more rewards more quickly and we actually feel a sense of pain it's not true pain but
[01:23:14.860 --> 01:23:18.940]   a feeling of longing and sadness when we're not getting rewarded immediately and we have
[01:23:18.940 --> 01:23:25.620]   a lot of overly reactive young adults now because they're kind of used to getting things immediately.
[01:23:25.620 --> 01:23:30.580]   And so yes even though it's a smaller difference in between that now that we do things that
[01:23:30.580 --> 01:23:35.220]   are instantaneous I get upset if I can't like I used to have to get up and actually turn
[01:23:35.220 --> 01:23:39.500]   the channels of the TV now I don't even want to reach over if I can't find the Apple remote
[01:23:39.500 --> 01:23:43.780]   I want to try to talk to my TV to be able to do it and I get annoyed for that.
[01:23:43.780 --> 01:23:47.820]   So if you get if you get a Chromebook instead of a Mac book you could have this instant sense
[01:23:47.820 --> 01:23:52.820]   of anger and anger management.
[01:23:52.820 --> 01:23:53.820]   I know.
[01:23:53.820 --> 01:23:59.500]   So I've got two teenage daughters one's well actually one's 20 and the other one's 16 sorry
[01:23:59.500 --> 01:24:02.260]   one's 18 and one's 16.
[01:24:02.260 --> 01:24:07.180]   They have been through all of that and they end up just building coping mechanisms just
[01:24:07.180 --> 01:24:12.540]   like I had to go through coping mechanisms of the era I think that generally the challenge
[01:24:12.540 --> 01:24:16.300]   that we have at the moment is that people just haven't adapted to the new environment.
[01:24:16.300 --> 01:24:21.260]   So I don't subscribe to this apocalyptic you know world ending view that you know we're
[01:24:21.260 --> 01:24:22.460]   rewiring our brains.
[01:24:22.460 --> 01:24:26.940]   Yes we're rewiring our brains but it's no different to the industrial age in the 18th
[01:24:26.940 --> 01:24:31.180]   century when people came off the land to work in factories it's no different to when people
[01:24:31.180 --> 01:24:35.300]   started printing Bibles and the and the priest was saying you can't give ordinary people
[01:24:35.300 --> 01:24:37.100]   Bibles they have no way to interpret it.
[01:24:37.100 --> 01:24:41.740]   It's just a matter of working through it don't pretend it's a problem just it's just progress.
[01:24:41.740 --> 01:24:45.860]   No but you don't want to put your head in the sand and say everything that we do is okay
[01:24:45.860 --> 01:24:47.180]   just because we do it.
[01:24:47.180 --> 01:24:52.020]   You want to be able to open up your eyes and be able to see that whatever we do at every
[01:24:52.020 --> 01:24:57.060]   moment yes neurons fire together they wire together that's the way that we work and if
[01:24:57.060 --> 01:25:00.460]   you're not going to learn a skill you're not going to get better at it if we never allowed
[01:25:00.460 --> 01:25:05.220]   our children to walk they wouldn't learn how to this is not something that doesn't happen
[01:25:05.220 --> 01:25:09.980]   without practice so you want to be able to be knowledgeable to it I love tech but you
[01:25:09.980 --> 01:25:13.860]   want to be honest also with what are the pros and the cons to what you use.
[01:25:13.860 --> 01:25:19.140]   I mean I think both of you are putting your values on tech so yeah so you know one of
[01:25:19.140 --> 01:25:23.340]   the reasons that I you know we opened up with talking about certifications and I need
[01:25:23.340 --> 01:25:27.580]   to move past the things that I've done in the past instead of dragging them along behind
[01:25:27.580 --> 01:25:32.980]   me I don't I don't spend all my life attached to my phone but you know what I also don't
[01:25:32.980 --> 01:25:35.940]   have to put up with all the stuff you've used to work with because some of those people
[01:25:35.940 --> 01:25:36.940]   were really.
[01:25:36.940 --> 01:25:40.340]   Greg we don't we don't use that word anymore that's that's it.
[01:25:40.340 --> 01:25:45.620]   I almost you do all over the stream.
[01:25:45.620 --> 01:25:50.420]   Sorry Greg Greg you spend too much time looking at your phone.
[01:25:50.420 --> 01:25:53.740]   So I mean the people that I used to work with are stupid the companies I used to work with
[01:25:53.740 --> 01:25:57.500]   are inherently any big companies inherently stupid right.
[01:25:57.500 --> 01:26:01.660]   Due to the blessings of technology I don't have to put up with that life for it in a situation
[01:26:01.660 --> 01:26:06.140]   that's a good point there's pros and cons can we agree on that.
[01:26:06.140 --> 01:26:13.380]   100% like I mean look progress and and egress are right they they go hand in hand and so
[01:26:13.380 --> 01:26:16.940]   there's things that were moving backward on and there's things that were that were
[01:26:16.940 --> 01:26:22.060]   improving and the things it the thing is in time like we're going to have to learn how
[01:26:22.060 --> 01:26:28.460]   to deal with whether it's Facebook whether it's screen time mobile devices all of these
[01:26:28.460 --> 01:26:35.780]   things are inherently just tools and but but we can also use those tools in the same way
[01:26:35.780 --> 01:26:41.660]   that humans can do everything for good or ill right we are still figuring out what those
[01:26:41.660 --> 01:26:46.620]   things are in creating the boundaries which I think is what ultimately George is getting
[01:26:46.620 --> 01:26:51.980]   at is you know we understanding those things and then figuring out where the boundaries
[01:26:51.980 --> 01:26:56.700]   are so that we can you know manage them to the best effect is the challenge that we're
[01:26:56.700 --> 01:27:02.300]   going to now because things are are moving so quickly that we're not having a whole
[01:27:02.300 --> 01:27:08.780]   lot of time to to process it and to you know put up the kind of guidelines that we need
[01:27:08.780 --> 01:27:11.380]   to you know manage these things effectively.
[01:27:11.380 --> 01:27:17.140]   You know it gave me hope just the other day my daughter who's 26 by the way and did grow
[01:27:17.140 --> 01:27:21.620]   up through this whole technological era but I think it's very good at reading cues and
[01:27:21.620 --> 01:27:26.300]   emotions and stuff she's really really good at that she called me up and said dad I need
[01:27:26.300 --> 01:27:30.780]   to get electric toothbrush I feel I'm not brushing my teeth well enough and I thought
[01:27:30.780 --> 01:27:37.100]   hallelujah how long have I been telling you that so I ordered her this I got her quip
[01:27:37.100 --> 01:27:41.540]   this is the bed and I'm not kidding I actually said honey I'll take care of it I know exactly
[01:27:41.540 --> 01:27:45.900]   what to get you this is the best electric toothbrush I said first of all it doesn't
[01:27:45.900 --> 01:27:51.220]   plug in you don't have to have a charger she said oh I like that it has a it comes with
[01:27:51.220 --> 01:27:56.300]   a it has a triple a battery in it and so that means it it you you it runs for I don't
[01:27:56.300 --> 01:28:00.380]   know how long I haven't had to put a new battery in for a while I think probably several months
[01:28:00.380 --> 01:28:05.100]   and then you just put in a new battery she liked that it also has this great I love this
[01:28:05.100 --> 01:28:10.100]   little holder that has a stick them on the back of it and you put that somebody keeps
[01:28:10.100 --> 01:28:15.380]   taping this down for some reason you put this on your mirror or wherever I'll put it right
[01:28:15.380 --> 01:28:20.500]   here on you Georgia like that and then and then you have it right there you just pull
[01:28:20.500 --> 01:28:25.940]   it out it's got all the things that a good electric toothbrush needs like every 30 seconds
[01:28:25.940 --> 01:28:30.140]   it says do another quadrant so you get two minutes of brushing it's actually got a great
[01:28:30.140 --> 01:28:33.660]   brush with very soft bristles you don't with electric toothbrush you don't want a hard
[01:28:33.660 --> 01:28:39.380]   bristle because it could actually wear away your nammo and it comes with very lovely toothpaste
[01:28:39.380 --> 01:28:43.900]   it tastes phenomenal and you won't believe how affordable it is the quip toothbrush starts
[01:28:43.900 --> 01:28:51.980]   at $25 for a very good electric toothbrush I love my quip I know she's gonna have very
[01:28:51.980 --> 01:28:59.260]   nice shiny teeth and fresh breath and her checkups are gonna be phenomenal quip backed
[01:28:59.260 --> 01:29:04.300]   by over 10,000 dental professionals it'll even give you tips on oral care things you
[01:29:04.300 --> 01:29:08.940]   never knew I got this little quip manual for instance you know this Georgia because you're
[01:29:08.940 --> 01:29:14.380]   a mom but I don't know maybe you don't you know you don't after your brush you don't
[01:29:14.380 --> 01:29:17.100]   want to rinse out your mouth you want to leave the toothpaste in there for a while don't
[01:29:17.100 --> 01:29:21.780]   rinse right away did you know that you want to keep the fluoride right?
[01:29:21.780 --> 01:29:26.580]   you want to keep the fluoride rinsing it off my whole life spit rinse after your brush
[01:29:26.580 --> 01:29:31.380]   right? no you're not supposed to thank you quip you taught me something you're supposed
[01:29:31.380 --> 01:29:39.700]   to wash but not rinse and then wash this off but not rinse your mouth it tells you scrub
[01:29:39.700 --> 01:29:45.700]   your tongue this is awesome so yes you get a little dental education as well time magazine's
[01:29:45.700 --> 01:29:54.380]   best invention of the year quip starts at just $25 and if you go to get quip g-e-t-q-u-i-p
[01:29:54.380 --> 01:29:59.020]   dot com slash twit you get your first refill pack free when you purchase any quip electric
[01:29:59.020 --> 01:30:05.820]   toothbrush a variety of shades she chose the green I said what color do you want I can't
[01:30:05.820 --> 01:30:11.500]   remember it was like red silver she chose the green you get your first refill pack free
[01:30:11.500 --> 01:30:17.100]   when you purchase a quip electric toothbrush at our website get quip g-e-t-q-u-i-p dot com
[01:30:17.100 --> 01:30:24.780]   slash twit and this is I just felt like she's this is a big step forward in adulting for
[01:30:24.780 --> 01:30:30.140]   my daughter you know what I mean you know what I mean right? I totally know what I mean
[01:30:30.140 --> 01:30:35.260]   she's a totally no dream yeah there are adulting moments when you're as your children flee the
[01:30:35.260 --> 01:30:41.060]   nest yeah adulting and so I was very happy dad was happy to get quip get it for your adult
[01:30:41.060 --> 01:30:45.460]   children or for yourself and actually because they were for your young children or young
[01:30:45.460 --> 01:30:48.660]   children right you know this is fun they like they like brushing with this yeah they like
[01:30:48.660 --> 01:30:53.900]   it and by the way I should mention that the different colors are helpful because you can
[01:30:53.900 --> 01:30:58.460]   have you know four different people in your bathroom at the same time and you'll all know
[01:30:58.460 --> 01:31:04.980]   which toothbrushes who's by the quip color I really like my quip get quip dot com so this
[01:31:04.980 --> 01:31:09.740]   apple event here's what I think and Ming Chi Kuo who is one of the apple rumor guys he's
[01:31:09.740 --> 01:31:17.980]   one with the real supply side event because he's an analyst in China and he says according
[01:31:17.980 --> 01:31:25.620]   to Ming that apple is gonna do yes for education as you said Georgia finally inexpensive because
[01:31:25.620 --> 01:31:30.020]   I don't think apple sells anything less than a thousand maybe even more than that a fine
[01:31:30.020 --> 01:31:34.900]   laptop not a laptop not a lot yeah not finally an expensive MacBook Air and by the way
[01:31:34.900 --> 01:31:38.460]   I'm just thrilled they're gonna keep selling the MacBook Air because that's great with
[01:31:38.460 --> 01:31:42.820]   a retina display which is something that they needed to do they he says seven ninety nine
[01:31:42.820 --> 01:31:47.220]   eight ninety nine which would be you know kind of necessary for a school the current
[01:31:47.220 --> 01:31:51.580]   MacBook Air starts at nine ninety nine it's still too expensive but yeah I wish it were
[01:31:51.580 --> 01:31:55.460]   less I mean you're competing against three hundred dollar Chromebooks Microsoft you know
[01:31:55.460 --> 01:32:01.900]   it's funny Microsoft is it apple already was out of the classroom they weren't even competitive
[01:32:01.900 --> 01:32:06.020]   it was Windows cheap Windows machines and even they have been losing ground to Chromebooks
[01:32:06.020 --> 01:32:13.700]   and one of the things I got this week I'll show you is I think Microsoft's kind of trying
[01:32:13.700 --> 01:32:19.300]   to answer this Chromebook threat with something called Windows 10 S yeah and less expensive
[01:32:19.300 --> 01:32:25.820]   computers this is the first Windows computer based on the ARM processors not Windows RT
[01:32:25.820 --> 01:32:33.380]   this is Windows 10 S running on a Snapdragon Qualcomm chip 835 this is now it's a little
[01:32:33.380 --> 01:32:38.420]   pricey it's a thousand dollars but it does include the keyboard and the pen it comes from
[01:32:38.420 --> 01:32:45.420]   HP it's called the NV X2 I got it because I'm very curious what these are like given
[01:32:45.420 --> 01:32:50.340]   that they're running not on desktop processors but on mobile processors they're claiming 22
[01:32:50.340 --> 01:32:54.620]   hours battery life it sure is the longest battery life I've ever gotten I doubt it'll
[01:32:54.620 --> 01:32:59.940]   be 22 hours you know I haven't really been able to completely test it but I would say
[01:32:59.940 --> 01:33:09.660]   you know I fairly heavy use over 24 hour periods so maybe maybe 12 15 hours the only
[01:33:09.660 --> 01:33:15.140]   negative is it is slow it's not slow if you only do Windows 10 S and Microsoft's edge
[01:33:15.140 --> 01:33:20.380]   browser that's feels pretty snappy but put Chrome on it you'll be sorry and you can because
[01:33:20.380 --> 01:33:25.580]   you can upgrade a Windows 10 pro with all of these windows yeah it's just still too complicated
[01:33:25.580 --> 01:33:31.100]   I think that those things are getting crushed in in education because the Chromebook is so
[01:33:31.100 --> 01:33:38.420]   simple you flip it on it turns on right away like instant on and then they're so cheap
[01:33:38.420 --> 01:33:46.300]   it's if yeah you don't you're not saving data in it you know Google Docs is huge in education
[01:33:46.300 --> 01:33:53.420]   for obvious reasons and a classroom as well Google classroom they've now made that much
[01:33:53.420 --> 01:34:02.020]   more widely available and Google is just absolutely crushing Microsoft and Apple in the classroom
[01:34:02.020 --> 01:34:07.260]   and I don't think that this this thing that they're doing I think it's good that they're
[01:34:07.260 --> 01:34:11.420]   having a cheaper Mac book era I think that's smart just in general I think there's lots
[01:34:11.420 --> 01:34:19.700]   of regular workers that could use that device and be happy with it we have you know some
[01:34:19.700 --> 01:34:24.580]   old we have a lot of Mac book airs in our in our company people love Mac book people are
[01:34:24.580 --> 01:34:30.220]   holding on to them right they're holding on to them for a long time a new Mac book era
[01:34:30.220 --> 01:34:34.700]   will do great it just won't be in the classroom it will not be in the classroom yeah other
[01:34:34.700 --> 01:34:38.820]   than the most you know other than some private schools right that are gonna hand these out
[01:34:38.820 --> 01:34:44.140]   and some students who will buy them themselves or their parents will buy them for them right
[01:34:44.140 --> 01:34:49.020]   it'll it'll do well but it's gonna be you know the same segment of the market that Apple
[01:34:49.020 --> 01:34:53.780]   already has right the upper somebody saying about this Windows on arm if it doesn't roam
[01:34:53.780 --> 01:34:57.900]   chrome if doesn't run chrome well but that's exactly what a Chromebook does do which is
[01:34:57.900 --> 01:35:02.860]   run chrome well yeah that's that's a huge differentiator that's not gonna serve Microsoft
[01:35:02.860 --> 01:35:07.260]   very well and on these windows on arm I met with I met with some IT administrators of a
[01:35:07.260 --> 01:35:12.500]   school I think it was about a year ago and I said you know what why what is it about
[01:35:12.500 --> 01:35:16.780]   the Chromebook that you like and they went it works and it's secure yeah I don't think
[01:35:16.780 --> 01:35:22.300]   Microsoft Microsoft will never win in the education market yeah yeah because it's not safe it's
[01:35:22.300 --> 01:35:27.900]   not secure and it's not actually easy to operate to install the operating system on that device
[01:35:27.900 --> 01:35:34.580]   is a massive pain in the butt whereas a Chromebook is trivial every time you turn it on it basically
[01:35:34.580 --> 01:35:38.620]   loads the operating system scratch it's gone can Apple succeed in this environment can
[01:35:38.620 --> 01:35:43.420]   an iPad for instance I think that the iPads could I think that the problem is is that once
[01:35:43.420 --> 01:35:49.540]   a school has invested one of teachings teachers how to be able to use a certain set of technology
[01:35:49.540 --> 01:35:53.540]   it's really hard to teach them something else I think that iPads they're they're they're
[01:35:53.540 --> 01:35:57.300]   not that expensive they're kind of pricey but they're not that expensive they're definitely
[01:35:57.300 --> 01:36:02.180]   safe and secure they're very easy to use but the teachers are already proved to be able
[01:36:02.180 --> 01:36:06.540]   to use it and there's already probably Chromebooks in the school and so what they're going to
[01:36:06.540 --> 01:36:09.340]   do is they're not going to throw all these Chromebooks out if they're going to invest
[01:36:09.340 --> 01:36:14.380]   in others they're not going to then train teachers to be able to use iPads and the different
[01:36:14.380 --> 01:36:18.940]   systems that are there because all of the schools in our area are set up to Google
[01:36:18.940 --> 01:36:23.780]   classroom and so I think that it's going to be an uphill battle for Apple and they really
[01:36:23.780 --> 01:36:27.460]   need to give something that's going to cause a push and make it affordable because in the
[01:36:27.460 --> 01:36:31.860]   end schools work on the bottom line like unless you're a private school you're working on
[01:36:31.860 --> 01:36:35.740]   how much money can you say because if you take from one area if you give to one area
[01:36:35.740 --> 01:36:39.940]   you're taking from another and so I think it's going to be hard for Apple to crack through
[01:36:39.940 --> 01:36:45.220]   they're doing well in like the K through about three the iPads right iPads are still pretty
[01:36:45.220 --> 01:36:51.020]   simple for for those you know for those kids and and they are still doing well in a lot
[01:36:51.020 --> 01:36:55.580]   of schools that are using that but once you get a kid to where they have to write something
[01:36:55.580 --> 01:37:02.140]   they have to you know do a response paper they have to you know maybe work some some basic
[01:37:02.140 --> 01:37:09.940]   software on their own by software I mean usually websites right then then almost all
[01:37:09.940 --> 01:37:15.980]   of them that we see and all the schools that we talk to and administrators and CIOs of
[01:37:15.980 --> 01:37:23.500]   schools and and your school systems I should say you know their Chromebook is is almost
[01:37:23.500 --> 01:37:28.220]   a hundred percent of what we see there's no incentive to go to Apple Apple's got no incentive
[01:37:28.220 --> 01:37:31.780]   to introduce a low-cost device because if they do they undercut everything so if they
[01:37:31.780 --> 01:37:35.460]   introduced a five hundred dollar MacBook people are going to stop buying a thousand
[01:37:35.460 --> 01:37:40.540]   dollar MacBook and all about up yeah yeah it's all about increasing the Avenue average
[01:37:40.540 --> 01:37:45.300]   revenue per user its share price is going to go it's going to get slammed if they suddenly
[01:37:45.300 --> 01:37:48.860]   introduce something cheap so no they're done with the education market but but they can't
[01:37:48.860 --> 01:37:54.100]   be because they're having an event at prep school a week from Tuesday there's some going
[01:37:54.100 --> 01:37:59.460]   on here they're gonna make some faux faux attempt and Microsoft can't win in this market
[01:37:59.460 --> 01:38:03.980]   either because it's products are rubbish they're unsafe to use the answer constantly insecure
[01:38:03.980 --> 01:38:08.020]   and they're too hard to administer down on the ground even if they could match the price
[01:38:08.020 --> 01:38:12.300]   of the Chromebook even if Microsoft could squeeze its corporate soul to do something right
[01:38:12.300 --> 01:38:16.700]   for a change it still couldn't make it so that the administration the people who actually
[01:38:16.700 --> 01:38:21.420]   put the computers in front of the kids need something that just works every time they
[01:38:21.420 --> 01:38:25.980]   take it off the right how long can a school use a Chromebook two three four years what
[01:38:25.980 --> 01:38:32.620]   is the easily easily three or four I pad really after two years is unusable right it's
[01:38:32.620 --> 01:38:37.500]   just you know and if it survives handling by three yeah they're like two to three I'd
[01:38:37.500 --> 01:38:41.340]   say you know because I'm gonna if Apple gets the iPads down and the rumor is that there'll
[01:38:41.340 --> 01:38:44.700]   be a nine point seven inch iPad for two hundred fifty nine dollars even if the Apple gets
[01:38:44.700 --> 01:38:50.260]   the price down there that's not gonna be for most administrators enough of a pitch and
[01:38:50.260 --> 01:38:55.140]   besides you don't just you don't just get iPads now you have to get charging stations
[01:38:55.140 --> 01:39:01.300]   you have to get curriculum you have to take it's a hell yeah it's completely they have
[01:39:01.300 --> 01:39:07.620]   to rewrite all of your get a just a rewrite all of the classes yeah you know it's not
[01:39:07.620 --> 01:39:14.180]   an easy idea if what they'll do is go ahead and I will decided to donate and to be able
[01:39:14.180 --> 01:39:18.100]   to give to a certain set of schools and they were gonna be able to train all of the teachers
[01:39:18.100 --> 01:39:22.220]   I think that that would be a big push for them and be able to do that's a good point
[01:39:22.220 --> 01:39:27.140]   it's gonna take that you know systems or if they even said like they would you know
[01:39:27.140 --> 01:39:31.780]   do a free fix and you know if you break something we're gonna fix it for free I think that Apple
[01:39:31.780 --> 01:39:36.460]   has the they could be able to do that and that would start a system and then once people
[01:39:36.460 --> 01:39:40.660]   are kind of stuck in the ecosphere odds are they're gonna continue to and so if Apple
[01:39:40.660 --> 01:39:44.940]   was willing to support the school systems I think that that would be a really big deal
[01:39:44.940 --> 01:39:49.980]   for Apple we do know I'm sure that they will talk about something called class kit which
[01:39:49.980 --> 01:39:56.900]   we've seen in beta for iOS 11.3 it's a framework for educational apps so I mean this is gonna
[01:39:56.900 --> 01:40:02.700]   be a push from Apple but I can't imagine it'll be too compelling for K through three I think
[01:40:02.700 --> 01:40:06.900]   you got to think of it is K through three it's gonna it's gonna be really good for them and
[01:40:06.900 --> 01:40:10.380]   probably you're likely to see I think George's points are is a great one they're likely
[01:40:10.380 --> 01:40:16.140]   to partner with some schools right especially ones that don't have access to good technology
[01:40:16.140 --> 01:40:21.180]   and they're likely to either donate or give them a massive discount but to Greg's point
[01:40:21.180 --> 01:40:25.620]   stuff to support it and so that that's you know that's its own challenge and so Apple's
[01:40:25.620 --> 01:40:30.580]   probably gonna have to you know have a larger a larger program in place there and then these
[01:40:30.580 --> 01:40:36.380]   other things the Mac book and other it's gonna support again the same percent of the market
[01:40:36.380 --> 01:40:41.700]   that Apple already owns which is that like top 10% they cherry pick the best part of
[01:40:41.700 --> 01:40:48.460]   the market where the biggest margins are where the people that can afford it typically want
[01:40:48.460 --> 01:40:56.380]   to invest in a Mac versus a PC and they will want to keep that in education in the same
[01:40:56.380 --> 01:41:01.860]   way they do in the large part going on at Apple though I am gonna refer to Neil Seibart's
[01:41:01.860 --> 01:41:08.660]   above Avalon blog he published a couple of days ago he's observed that apples are indeed
[01:41:08.660 --> 01:41:16.420]   spent his job yeah hugely they're gonna spend more in fiscal year 2018 than they spent from
[01:41:16.420 --> 01:41:24.580]   1998 to 2011 together and that yeah by the way that decade more saw the launch of the
[01:41:24.580 --> 01:41:32.740]   iPod the iPhone and the iPad so they're spending something a lot it's traditionally Apple's
[01:41:32.740 --> 01:41:38.100]   not known for their R&D expenditure but they have to they know that they're not on to the
[01:41:38.100 --> 01:41:41.900]   next big thing right and so they're trying everything they're trying cars they're trying
[01:41:41.900 --> 01:41:47.340]   health care they're trying education they're trying I think you're probably seeing a lot
[01:41:47.340 --> 01:41:51.580]   of that isn't health care they really think that they've got a good thing going there and
[01:41:51.580 --> 01:41:58.460]   they think you know with 11.3 iOS 11.3 the biggest thing in there class kit is in there
[01:41:58.460 --> 01:42:05.700]   but the new health record is in there and you know that has the potential we've done
[01:42:05.700 --> 01:42:10.460]   some coverage of this you know that has some potential to be a potential winner for them
[01:42:10.460 --> 01:42:19.420]   at least in the US market where it's so bifurcated not bifurcated but you know fragmented
[01:42:19.420 --> 01:42:24.860]   fragment it thank you where you know in terms of health records and these health
[01:42:24.860 --> 01:42:29.460]   rec these health systems not being able to share records and then people not being able
[01:42:29.460 --> 01:42:34.580]   to carry their own records with them so they have a great opportunity there they see it
[01:42:34.580 --> 01:42:40.100]   and I think that you see them working more and more with companies that are doing health
[01:42:40.100 --> 01:42:45.180]   either not just health care but proactive health kind of things from folks like sleep
[01:42:45.180 --> 01:42:51.540]   number to other other companies that are making health devices they're working really closely
[01:42:51.540 --> 01:42:57.140]   with a lot of them so you have to think that they're making some of these bets where they're
[01:42:57.140 --> 01:43:02.180]   kind of next sort of big market push could be actually you know it's interesting because
[01:43:02.180 --> 01:43:08.300]   and I'm sure Georgia you're doing this to Apple has with their Apple watch a heart health
[01:43:08.300 --> 01:43:14.940]   thing it's a it's a heart study that they're doing where they're collecting information
[01:43:14.940 --> 01:43:22.660]   about heart rate and a fibrillation or to what a fib and I've I've done this and you
[01:43:22.660 --> 01:43:29.380]   can sign up for it but but Samsung has just announced a new phone that does something
[01:43:29.380 --> 01:43:36.180]   very interesting that competes directly with this and they're doing a study with UCSF and
[01:43:36.180 --> 01:43:42.860]   I did not realize this Samsung has not touted this but the new Samsung Galaxy S9 has apparently
[01:43:42.860 --> 01:43:46.540]   not just a heart rate monitor which Samsung phones have had for a while where you can put
[01:43:46.540 --> 01:43:50.340]   your finger on a little sensor right under the flash and it will tell you what your heart
[01:43:50.340 --> 01:43:56.620]   rate is but apparently that sensor can also now measure blood pressure and that's a big
[01:43:56.620 --> 01:44:03.980]   first something the Apple watch and the iPhone do not do they are partnering with UCSF they've
[01:44:03.980 --> 01:44:11.940]   launched an app which I've been using called my BP lab which apparently allows them to
[01:44:11.940 --> 01:44:17.980]   measure blood pressure by the smartphone without any external hardware I signed up for it I
[01:44:17.980 --> 01:44:22.660]   need to measure my BP using this phone three times a day and then they do questionnaires
[01:44:22.660 --> 01:44:26.700]   like were you in the room with a loved one you're getting your blood pressure have you
[01:44:26.700 --> 01:44:32.220]   had sex lately have you called get Roman that no they didn't ask me that but I but it
[01:44:32.220 --> 01:44:35.580]   was interesting that there this is going to be a study I don't know if you know anything
[01:44:35.580 --> 01:44:40.860]   about this but this is going to be a study it's a three work three week study for you
[01:44:40.860 --> 01:44:45.580]   the part of a three week study that measures not just blood pressure but sleep exercise
[01:44:45.580 --> 01:44:49.780]   diet and I guess they're trying to look for some sort of correlation as Apple is doing
[01:44:49.780 --> 01:44:56.420]   with with the heart rate I think it I think it's wonderful I just I always wonder you know
[01:44:56.420 --> 01:45:02.300]   Apple I maybe perhaps naively trust with my data and I feel very comfortable with that
[01:45:02.300 --> 01:45:06.460]   because we pay a premium for that kind of thing and you know if you're not paying a premium
[01:45:06.460 --> 01:45:11.340]   then you probably are what's making the company money I worry about people putting in a lot
[01:45:11.340 --> 01:45:16.180]   of information to Samsung because in the end then if the government gets that jobs or your
[01:45:16.180 --> 01:45:20.060]   company finds out that you have a heart issue they may say you know what you're going to
[01:45:20.060 --> 01:45:24.100]   be really expensive to us and we don't want to hire you and so I would just read through
[01:45:24.100 --> 01:45:28.380]   all of the privacy information before you sign up for something that I did I feel like
[01:45:28.380 --> 01:45:32.780]   it's okay you actually read through do you read through all of the well you listen privacy
[01:45:32.780 --> 01:45:39.940]   no now my blood pressure is going up you're ruining my blood pressure true I was going
[01:45:39.940 --> 01:45:46.060]   to say we're Georgia Dow during this I'm actually measuring my blood pressure right now says
[01:45:46.060 --> 01:45:51.060]   please keep still going to do mine I might have got my you have a cup like yeah I have
[01:45:51.060 --> 01:45:57.300]   one of those two from why things yeah yeah yeah yeah yeah there's a cup that's gone nowhere
[01:45:57.300 --> 01:46:02.340]   since it was a quiet Samsung now right yeah notice even Samsung's not using a why things
[01:46:02.340 --> 01:46:07.340]   cup they're just doing it with their phone my blood pressure is 4.7 below my baseline
[01:46:07.340 --> 01:46:13.140]   measurement so I'm actually I'm actually very relaxed what was currently in the room
[01:46:13.140 --> 01:46:22.500]   with their strangers have you exercise vigorously in the last 30 minutes absolutely not how are
[01:46:22.500 --> 01:46:28.260]   you feeling are you positive and activated negative and activated positive and not activated
[01:46:28.260 --> 01:46:35.060]   negative and not activated negative after all that security talk I'm positive how intensely
[01:46:35.060 --> 01:46:39.220]   are you feeling positive and activated Georgia you'd probably recognize this is a kind of
[01:46:39.220 --> 01:46:44.580]   standard you know kind of personality in the yeah yeah exactly they want to they want
[01:46:44.580 --> 01:46:47.820]   to kind of track everything that you're going through though I think that those questions
[01:46:47.820 --> 01:46:52.620]   seem like positive and activated seems I think would be more confusing than most standard
[01:46:52.620 --> 01:46:56.380]   they give you more descriptions I'll evaluate yeah they give you more descriptions do you
[01:46:56.380 --> 01:47:00.820]   feel bored or you know do you wish you were somewhere else indicate by tapping on the
[01:47:00.820 --> 01:47:06.940]   line below don't lie we're watching don't lie you're not okay maybe a little bit no I
[01:47:06.940 --> 01:47:11.860]   thought Facebook goes giving away a lot of information there's not a lot of data do you
[01:47:11.860 --> 01:47:17.780]   like things are overwhelming right now if I can correlate that data with what you've
[01:47:17.780 --> 01:47:22.860]   been doing on Facebook I know an awful lot about you well I'm not I quit Facebook on
[01:47:22.860 --> 01:47:28.820]   a quick Facebook so I could give the University of California Sam wait a minute we have trouble
[01:47:28.820 --> 01:47:35.260]   authenticating your account oh man now I'm gonna do it all over again that's the second
[01:47:35.260 --> 01:47:39.260]   time that's happened there's a bug in there I don't know what's going on but I think it's
[01:47:39.260 --> 01:47:43.660]   interesting I mean I don't you know they don't tell you your blood pressure I noticed
[01:47:43.660 --> 01:47:49.180]   but they do claim and Samsung claims and UCSF which I don't think is lying to me claim
[01:47:49.180 --> 01:47:54.420]   they have a very good medical school I claimed that they're not exceptionally accurate and
[01:47:54.420 --> 01:47:59.780]   that's why they don't want to give you a specific number cause a lot of people to freak out
[01:47:59.780 --> 01:48:03.420]   then they'll be going to see their doctors then the doctors will be angry at some side
[01:48:03.420 --> 01:48:08.260]   I know you're I know you're Canadian but wouldn't they need FDA in the US anyway approval to
[01:48:08.260 --> 01:48:13.420]   do something like that no not for blood pressure cuffs because you're not administering
[01:48:13.420 --> 01:48:17.300]   edification and they would say like listen you should always check this with probably
[01:48:17.300 --> 01:48:21.100]   you know they probably have somewhere in that form that you didn't read they probably have
[01:48:21.100 --> 01:48:25.940]   a coverage to be able to say you know yeah well I know with that it might be like FDC
[01:48:25.940 --> 01:48:32.220]   more like then FDA right I know with the apple heart thing if you if they see something abnormal
[01:48:32.220 --> 01:48:37.980]   a doctor will do a FaceTime with you and and you get a constant if you're registered if
[01:48:37.980 --> 01:48:42.420]   you're registered with a study well you have to register to do it yeah then you don't get
[01:48:42.420 --> 01:48:46.820]   that in the UK for example oh interesting because you're not allowed to collect it yeah
[01:48:46.820 --> 01:48:51.700]   and the doctors won't usually take what's in your watch because it's not calibrated right
[01:48:51.700 --> 01:48:57.540]   and you already have health insurance here we don't have any of them we're on our own
[01:48:57.540 --> 01:49:03.180]   baby so I was talking to a doctor about it recently I had to go in and have some meat
[01:49:03.180 --> 01:49:08.060]   maintenance done on the on the chassis here and they said that you know they don't like
[01:49:08.060 --> 01:49:11.860]   to take the data that comes from cuffs or watches because they've not been calibrated
[01:49:11.860 --> 01:49:15.340]   right turns out that the gear in the hospitals and so forth is all calibrated and tested
[01:49:15.340 --> 01:49:19.260]   regularly to make sure that the results are accurate and so unless you can prove that
[01:49:19.260 --> 01:49:24.340]   you know that's a very good that makes sense eventually I'm sure that that those the devices
[01:49:24.340 --> 01:49:31.860]   will be you know within within normal parameters and that will go away but that certainly makes
[01:49:31.860 --> 01:49:35.860]   sense you know and you're also asking for the medical people to accept it as well which
[01:49:35.860 --> 01:49:40.820]   is not true that's true let's just say that the the medical system is not exactly a a
[01:49:40.820 --> 01:49:45.340]   center for a hotbed of innovation let's take a quick break we'll come back with more we've
[01:49:45.340 --> 01:49:50.460]   got Greg Farrow from the packet pushers network here packet pushers is a packet pushers.net
[01:49:50.460 --> 01:49:54.300]   it should be packet pushers.net yes I strongly recommend you don't listen to it and listen
[01:49:54.300 --> 01:50:00.060]   unless you are nerd. Well you can say that about this show too at a theory online on
[01:50:00.060 --> 01:50:05.180]   Twitter. Georgia Dash she's with iMore and senior editor there at Georgia underscore
[01:50:05.180 --> 01:50:10.940]   down on Twitter and don't forget she's also a licensed psychotherapist we bring her in
[01:50:10.940 --> 01:50:18.180]   on a regular basis to fix me and still not working by the way Georgia but I do have I
[01:50:18.180 --> 01:50:23.500]   have to say I'm very happy to have your anxiety videos actually you you set your partner sent
[01:50:23.500 --> 01:50:30.460]   me the whole set which is really yes me and my partner I didn't say not to send them okay
[01:50:30.460 --> 01:50:38.420]   you didn't stop her but these are great these are not just anxiety but she's got DVDs on
[01:50:38.420 --> 01:50:44.180]   things like sleeping better boundaries and consequences that's a good one one of these
[01:50:44.180 --> 01:50:50.780]   days I'll watch that one yeah I got no boundaries special series on parenting this is a really
[01:50:50.780 --> 01:50:56.460]   great series and I want to tell everybody about it so they can go look at anxiety dash videos
[01:50:56.460 --> 01:51:02.740]   dot com and who doesn't want more of Georgia on their screen after all right and you're
[01:51:02.740 --> 01:51:09.660]   and you're wonderful partner who sent me the DVDs yes Sandra even though you didn't stop
[01:51:09.660 --> 01:51:20.700]   her no it's okay I give you credit to yeah thank you and Jason Heiner who is uh
[01:51:20.700 --> 01:51:25.100]   always welcome on our network we love having a monitor actually all of you are editor in chief
[01:51:25.100 --> 01:51:31.180]   at Tech Republic great to have you back as well at Jason Heiner on Twitter a show today brought
[01:51:31.180 --> 01:51:36.620]   to you by quick and loans we should set off some fireworks light a candle or something because
[01:51:36.620 --> 01:51:41.660]   quick and loans as of a couple of months ago became the number one lender in the country we've
[01:51:41.660 --> 01:51:47.980]   always said number one in your hearts number one in the JD power customer satisfaction polls for
[01:51:47.980 --> 01:51:53.260]   eight years running for mortgage origination four years running for mortgage servicing I mean
[01:51:53.260 --> 01:51:58.540]   they really are good now they're also the number one lender overall in the country and I think I'm
[01:51:58.540 --> 01:52:02.700]   going to take some credit for that we've been telling you about quick and loans for some time
[01:52:02.700 --> 01:52:07.340]   you know they're revitalizing Detroit they've done a great job and they also understand that
[01:52:07.340 --> 01:52:12.940]   we geeks are a little different maybe it's because we don't understand emotional cues I don't know but
[01:52:12.940 --> 01:52:19.660]   we don't want to buy a house the last thing you want to do go to a bank say please sir can I have
[01:52:19.660 --> 01:52:25.820]   a loan alone well fill out this 30 page application and we'll get back to you so you fill out the
[01:52:25.820 --> 01:52:30.460]   application and then you're not done you got to go to the attic find pay stubs balance check
[01:52:30.460 --> 01:52:37.020]   statements all the paperwork facts it who has a fax machine facts it into I don't have a fax machine
[01:52:37.820 --> 01:52:43.420]   this was very 18th century 7 19th century maybe I mean this is not so quick and long said look we
[01:52:43.420 --> 01:52:49.580]   can do better dance said we could do we got computers now what if we had a loan approval process you did
[01:52:49.580 --> 01:52:55.020]   all online you didn't have to go to a bank you don't have to fill out an application you didn't
[01:52:55.020 --> 01:52:59.900]   have to go to the attic you could do it all on your phone or on a computer that's when rocket
[01:52:59.900 --> 01:53:06.140]   mortgage was born good by paperwork do it all at rocket mortgage comm slash twit two
[01:53:06.140 --> 01:53:11.740]   and what I love about this is completely simple you just answer a few questions you already know
[01:53:11.740 --> 01:53:17.420]   the answer to they have financial they have partnerships with all the financial institutions so
[01:53:17.420 --> 01:53:22.700]   with your permission they get your information and then they crunch the numbers based on your
[01:53:22.700 --> 01:53:27.260]   income your assets your credit they will say here's the loans you qualify for you choose the
[01:53:27.260 --> 01:53:35.020]   rate the term the down payment completely transparent and you got a loan and all of this beginning to end
[01:53:35.020 --> 01:53:40.140]   not including the time it took to put on your pants eight minutes because you don't have to put
[01:53:40.140 --> 01:53:46.220]   on your pants eight minutes apply simply understand fully mortgage confidently with rocket
[01:53:46.220 --> 01:53:52.300]   mortgage from quick and loans to get started that even if you're not in the midst of buying a house
[01:53:52.300 --> 01:53:56.300]   right now maybe tomorrow you're going to go to an open house or maybe you're going to see something
[01:53:56.300 --> 01:54:00.060]   you really like or maybe you want to refi because rates aren't going up it's a good time to refi
[01:54:00.060 --> 01:54:04.380]   to get started create that account right now rocket mortgage comm slash twit two
[01:54:04.380 --> 01:54:11.900]   rocket mortgage comm slash twit and the number two equal housing lender licensed in all 50 states
[01:54:11.900 --> 01:54:17.660]   and MLS consumer access dot org number 30 30 rocket mortgage from quick and loans rocket
[01:54:17.660 --> 01:54:26.540]   mortgage comm slash twit and the number two couple of stories to wrap things up
[01:54:26.540 --> 01:54:35.260]   oh I had a good one oh I'm this is not a good one but it's a sad one but I should mention of
[01:54:35.260 --> 01:54:41.180]   course Stephen Hawking passed away this week at the age of 76 show of hands how many of you own
[01:54:41.180 --> 01:54:47.820]   a brief history of time how many of you Africa actually read it oh you read it you read it very
[01:54:47.820 --> 01:54:53.180]   not you read it I don't know if I'm doing everything in it I got the illustrated version
[01:54:53.180 --> 01:54:59.020]   so I looked at the pictures is that it does that count accounts that counts 100 percent
[01:54:59.020 --> 01:55:05.660]   100 percent I saw the movie the theory of everything I saw that I saw no it's a it's a you know
[01:55:05.660 --> 01:55:10.460]   and we played a little video on the new screen savers I won't do it today I don't want if you saw
[01:55:10.460 --> 01:55:15.260]   that already it's beautiful video is put together in honor of professor Hawking 75th
[01:55:15.260 --> 01:55:23.420]   birthday but he was very you know important not just to physicists for his theories about
[01:55:23.420 --> 01:55:28.220]   black hole and information but also to all of us because he was such an inspiration here's a guy
[01:55:28.220 --> 01:55:35.740]   with a great mind whose body completely failed him he got ALS in his 20s lived another 50 years
[01:55:35.740 --> 01:55:41.340]   basically enable unable to move he could speak only with the help of a computer in fact he's very
[01:55:41.340 --> 01:55:46.620]   famous for beginning all of his talks with can you hear me in his synthesized voice and it became
[01:55:46.620 --> 01:55:53.900]   kind of his trademark here's a guy whose mind shown so brightly that his body transcended his body
[01:55:53.900 --> 01:56:01.900]   and I think he was a great inspiration to all of us it's a great way to say it yeah I am I actually
[01:56:02.460 --> 01:56:10.780]   I quoted the poet Wordsworth's words about Isaac Newton and I think that they
[01:56:10.780 --> 01:56:20.700]   completely appropriately described Stephen Hawking a mind forever voyaging through strange worlds
[01:56:20.700 --> 01:56:27.580]   alone a great man Stephen Hawking sorry to lose him not the only person the tech community lost
[01:56:28.460 --> 01:56:34.380]   this week Adrian Lamo passed away as well we knew Adrian fairly well he'd been on
[01:56:34.380 --> 01:56:37.820]   you're not logged into Facebook either huh karsten
[01:56:37.820 --> 01:56:44.940]   I can't read this is what happens you can't read it if you're not on Facebook but his father
[01:56:44.940 --> 01:56:52.060]   Mario Lamo posted these words on on Friday with great sadness and a broken heart after lit
[01:56:52.060 --> 01:56:57.100]   all of Adrian's friends and acquaintances know he is dead a bright mind and compassionate soul
[01:56:57.100 --> 01:57:02.940]   is gone he was my beloved song Lamo was a controversial figure a hacker who was we often
[01:57:02.940 --> 01:57:07.180]   call him the homeless hacker even when we interviewed him on the new screensavers and the old screensavers
[01:57:07.180 --> 01:57:12.700]   he was always on the road always parapetetic he actually ended his days in Kansas he had lived
[01:57:12.700 --> 01:57:17.660]   in the San Francisco Bay area for a while it was quite famous for having hacked a number of companies
[01:57:17.660 --> 01:57:25.020]   including Yahoo the New York Times and Microsoft not to get in but merely to show that their security
[01:57:25.020 --> 01:57:30.540]   in effect he considered himself a pen tester that their security was inadequate although he kind of
[01:57:30.540 --> 01:57:35.180]   raised the ire of the New York Times when he added himself to the New York Times editorial
[01:57:35.180 --> 01:57:43.580]   board that was that was a line too far the times went after him and in 2004 he was indicted
[01:57:43.580 --> 01:57:47.260]   turned himself in we actually had a conversation with him right before he turned himself in
[01:57:47.260 --> 01:57:57.020]   to the FBI received a home detention sentence he wasn't in prison and of course then afterwards
[01:57:57.020 --> 01:58:05.020]   was very outspoken activist for hackers for rights and I think a really great guy
[01:58:05.020 --> 01:58:13.820]   don't know what happened the Kansas police say it was not foul play I fear to learn more I hope
[01:58:14.540 --> 01:58:20.700]   I don't know what his mental state was towards the end he had been hospitalized for asperger's
[01:58:20.700 --> 01:58:28.380]   in the past and he was most controversial because he was the hacker who turned turned in then
[01:58:28.380 --> 01:58:36.140]   Bradley Manning now Chelsea Manning when she was exfiltrated a bunch of information
[01:58:36.140 --> 01:58:41.260]   and put it on Wikileaks about the US government some memos and so forth
[01:58:42.780 --> 01:58:47.900]   I think he I don't know if he regretted it I think he felt like he didn't have any choice he had been
[01:58:47.900 --> 01:58:53.820]   talking to Manning on chat rooms found out what Manning had done and it ended up turning her in
[01:58:53.820 --> 01:58:59.260]   Manning of course served seven years in prison and was later her sentence was
[01:58:59.260 --> 01:59:05.020]   communicated by President Obama about a year ago a more than a year ago so sorry to lose Adrian as
[01:59:05.020 --> 01:59:15.500]   well you know he's he's kind of a mixed bag yep like all of us indeed yeah yeah yeah yeah back
[01:59:15.500 --> 01:59:21.500]   in the days when security hacking was mostly about pranking people yeah I don't I know him and
[01:59:21.500 --> 01:59:28.380]   I know he was never malicious never used his abilities his vast hacking abilities to hurt anybody
[01:59:28.380 --> 01:59:33.580]   so no but pranks but but yeah pranks putting his name on the uh yeah I like that putting your name
[01:59:33.580 --> 01:59:38.540]   on the New York Times editorial yeah corporate corporate entities don't have a 10-0 they tend
[01:59:38.540 --> 01:59:46.380]   to react badly to pranking SEC has has begun very badly bug bandiers as well by the way pardon me
[01:59:46.380 --> 01:59:52.060]   they react badly to people shorting their stock instead of getting a bug bounty uh-huh uh-huh
[01:59:52.060 --> 01:59:58.460]   that's uh could be a problem down the road as well uh Elizabeth Holmes CEO of Theranos and Theranos
[01:59:58.460 --> 02:00:04.620]   is of Theranos's former president Sonny Balwani are now being charged by the Securities and
[02:00:04.620 --> 02:00:09.660]   Exchange Commission for fraud they raised more than 700 million dollars you know for Theranos
[02:00:09.660 --> 02:00:15.020]   the SEC alleges they exaggerated and made false statements about the company's technology they were
[02:00:15.020 --> 02:00:20.460]   you know supposedly developing a technology for blood testing they required just a pinprick a
[02:00:20.460 --> 02:00:26.220]   little dot of blood it never did work and there's some evidence that they knew that for years
[02:00:26.220 --> 02:00:33.100]   nevertheless um you know there will be an investigation at this point uh SEC has filed complaints against
[02:00:33.100 --> 02:00:39.900]   Theranos Elizabeth Holmes and Sonny Balwani claiming that Theranos' products were deployed by the
[02:00:39.900 --> 02:00:44.540]   US Department of Defense in the battlefield in Afghanistan on medevac helicopters the company
[02:00:44.540 --> 02:00:49.980]   generated more than 100 million dollars in revenue in 2014 oh they claimed it I'm sorry Theranos
[02:00:49.980 --> 02:00:54.620]   claimed that they never were deployed and generated less than 100 thousand dollars in revenue from
[02:00:54.620 --> 02:00:58.380]   the US Department there's a whole bunch of questions here about the viability of Silicon Valley
[02:00:58.380 --> 02:01:05.340]   investors these people have given this person 700 million dollars on the theory and you would
[02:01:05.340 --> 02:01:12.700]   imagine that they had done some due diligence and actually validated that the claims have been
[02:01:12.700 --> 02:01:19.820]   reasonable and it's it's obviously clear that at any cursory inspection of the technology would
[02:01:19.820 --> 02:01:25.980]   have shown up that they were lying through their teeth yeah um it does really question the validity
[02:01:25.980 --> 02:01:32.220]   of the Silicon Valley investment community if they cannot actually detect someone who's just
[02:01:32.220 --> 02:01:38.700]   flat out lying exaggerating and then dissembling for years on years and then to be caught out like
[02:01:38.700 --> 02:01:45.340]   this is incredibly embarrassing I think well I'd like such a fervor to catch out onto the fastest
[02:01:45.340 --> 02:01:52.220]   the best new thing that people you know grab gravitate for it and they did make really good
[02:01:52.220 --> 02:01:58.220]   looking you know presentation she wore a black turtleneck she was the female Steve Joanna
[02:01:58.220 --> 02:02:04.620]   Steve Joanna yeah and in fairness there were plenty of VCs that called bunk on it and was like
[02:02:04.620 --> 02:02:11.580]   I'm not even I just don't believe that there's there even close to anything um and so uh but
[02:02:11.580 --> 02:02:18.060]   they can visit enough people to buy into it to buy into the promise they can go gaining you know
[02:02:18.060 --> 02:02:22.940]   momentum well you look at companies I mean they raised 700 million but how much is uber raised 10
[02:02:22.940 --> 02:02:28.460]   billion almost over they've lost I should say almost 10 billion dollars over 10 years never
[02:02:28.460 --> 02:02:33.660]   showed a profit um but I go on the other hand you could look at uh both tharinos and uber and
[02:02:33.660 --> 02:02:39.100]   say well if they succeed this is going to be a windfall and and the problem is you write that
[02:02:39.100 --> 02:02:49.980]   due diligence and it was a scam and she's gotten away with it half a million dollar fine and she's
[02:02:49.980 --> 02:02:53.900]   barred from being the director of a company but she still walked off with millions in cash
[02:02:53.900 --> 02:02:59.020]   yeah what I wonder is what the investors I mean shouldn't they be howling for her blood and more
[02:02:59.020 --> 02:03:04.300]   than a bin prick potentially I I assume there's going to be lawsuits where they try and recover
[02:03:04.300 --> 02:03:10.540]   yeah yeah they see the ball seats over the now that there will be so there's an admitted guilt
[02:03:10.540 --> 02:03:17.180]   here the SEC is charged to yeah with lying but she hasn't admitted guilt just settled base so yeah
[02:03:17.180 --> 02:03:24.620]   yeah uh Plattsburgh New York good place to live if you want cheap electricity four cents a uh uh
[02:03:24.620 --> 02:03:28.460]   kilowatt hour it's the lowest in the country that's why so many
[02:03:30.060 --> 02:03:36.620]   bitcoin miners have moved there and it's near hydro electric it is it's near hydro electric
[02:03:36.620 --> 02:03:42.220]   and as a result the city council of Pittsburgh on thursday unanimously voted to impose an 18
[02:03:42.220 --> 02:03:50.300]   month moratorium on bitcoin mining wow the bitcoin mining is done I bet you're gonna see some it's
[02:03:50.300 --> 02:03:55.500]   a great publicity for that place exactly you're gonna see people google's gonna open up a data
[02:03:55.500 --> 02:04:02.700]   center there like you know in three two one you know I mean it's like yeah yeah uh bitcoin mining
[02:04:02.700 --> 02:04:09.660]   now uses more power than the country of Poland and is uh is well on its way to uh accelerating
[02:04:09.660 --> 02:04:16.940]   global climate change all to generate uh some profits for some bitcoin bros I mean the funny thing
[02:04:16.940 --> 02:04:23.820]   to think about you know the bitcoin mining thing obviously has uh a reputation now but
[02:04:24.540 --> 02:04:29.740]   the it's actually a fairly ingenious thing because it's needed in order to make the leg
[02:04:29.740 --> 02:04:36.380]   ledger distributed right like it gives you incentive proof of work yeah yeah it's a brilliant um
[02:04:36.380 --> 02:04:43.020]   a brilliant brilliant concept obviously it's gone too far and and you know you guys
[02:04:43.020 --> 02:04:47.500]   need some decent flaws in it we need to maybe back to the drawing board and think of a way to do
[02:04:47.500 --> 02:04:54.780]   this without using up all the electricity in the world indeed also all of the um also all of
[02:04:54.780 --> 02:05:01.660]   it's almost impossible to get high end oh gpu's yeah gpu's yeah because my bitcoin
[02:05:01.660 --> 02:05:06.380]   how are you playing your video games huh i mean well my my husband actually totally
[02:05:06.380 --> 02:05:10.860]   important medical research not just video games really important medical research and other
[02:05:10.860 --> 02:05:16.780]   things are used for that what did your husband do jimmy my husband took uh old macbook and an egp
[02:05:16.780 --> 02:05:24.540]   graphics adapter to try to figure out how he could uh mine ethereum oh man and uh it worked it worked
[02:05:24.540 --> 02:05:30.380]   you can do this too follow me make any money this article um he's gonna lose three dollars in a month
[02:05:30.380 --> 02:05:39.020]   where's the article it's on i'm more you can just look up how to mine ethereum uh no on i'm more
[02:05:39.020 --> 02:05:44.700]   is it here as inefficient as bitcoin or is it a little bit better it's pretty bad you know what
[02:05:44.700 --> 02:05:49.100]   that's what he didn't try for mining bitcoin so i'm not really sure he's gonna have to tell them
[02:05:49.100 --> 02:05:53.900]   yeah here it is yeah how to mine ethereum with your macbook and egpu
[02:05:53.900 --> 02:05:58.460]   anthony kesela that's your husband that's my husband i didn't know that
[02:05:58.460 --> 02:06:05.500]   i'm gonna call you i know i did i'm gonna call you georgia kesela from now oh yeah in kebak you
[02:06:05.500 --> 02:06:10.220]   don't take your husband's name you can't i know you don't i know you don't yeah yeah it's very strange
[02:06:10.220 --> 02:06:16.540]   yeah yeah no georgia dad is such a perfect name i wouldn't change a thing uh so the interesting part
[02:06:16.540 --> 02:06:20.380]   about this story i think leo is we're also seeing the same thing happen in iceland so this isn't
[02:06:20.380 --> 02:06:29.340]   unique to american story is the lack of uh infrastructure so there's a lot of talk in the press uh
[02:06:29.340 --> 02:06:34.140]   particularly if you're into data centers like i am i get very excited about data centers and and
[02:06:34.140 --> 02:06:39.980]   discussing them uh but the problem with data centers is that there's not enough the american us
[02:06:39.980 --> 02:06:44.780]   grid where they distribute the electricity across the backbone of the country at you know megawatts
[02:06:44.780 --> 02:06:50.300]   is in such poor condition that they're generating the electricity there but they can't transport it
[02:06:50.300 --> 02:06:54.460]   to where it's being consumed and that's why it's the cheapest electricity because it's literally just
[02:06:54.460 --> 02:06:59.740]   the hydro plants are producing more electricity to make it put into the grid right yeah because
[02:06:59.740 --> 02:07:04.460]   nobody's building the power lines to take the power to where it needs to be there is good news i
[02:07:04.460 --> 02:07:08.940]   think the russians are about to take over our grid and i'm sure one of the first things they'll do is
[02:07:08.940 --> 02:07:13.580]   make it more efficient i'm sure that that's exactly that we're also seeing the same thing happen in
[02:07:13.580 --> 02:07:19.020]   iceland so iceland also because they have the geothermal yeah capability so i dropped a link into the
[02:07:19.020 --> 02:07:23.580]   chat room have a look at that same story the interesting part about this is there's electricity
[02:07:23.580 --> 02:07:28.700]   but these things are also placed in places where there's no networking so normal data centers
[02:07:28.700 --> 02:07:34.460]   like amazon or google carpeal data centers there because there's no data infrastructure in place
[02:07:34.460 --> 02:07:39.980]   bitcoin doesn't need vast amounts of bandwidth like google and a ws and microsoft data and
[02:07:39.980 --> 02:07:47.260]   those types of people do so these are great places to put bit like mining centers because
[02:07:47.260 --> 02:07:51.100]   they don't need to high bandwidth but they do need the power so it is actually an interesting
[02:07:51.100 --> 02:07:57.660]   infrastructural play if you look at the technology of it uh... and up to us is the u_s is um you know
[02:07:57.660 --> 02:08:03.740]   it's funny that the power grid thing hasn't come up in a while in the u_s it is still a huge problem
[02:08:03.740 --> 02:08:10.220]   it was it's been about five years ago since i went to a um a big press conference at the
[02:08:10.220 --> 02:08:15.180]   white house where their big announcement was okay we're you know making real progress on this power
[02:08:15.180 --> 02:08:20.460]   grid stuff and they rolled out this huge plan massive you know multi decade plan to upgrade
[02:08:20.460 --> 02:08:25.500]   the power grid but it's like it's extremely difficult to get updates and not before it changes
[02:08:25.500 --> 02:08:30.620]   administration even to get updates on like how how is that coming how are we doing let me guess
[02:08:30.620 --> 02:08:38.380]   it's been exactly um but but i'm just saying it's a known problem and you it's fallen off the
[02:08:38.380 --> 02:08:45.340]   radar even though it's so critical to the future of of our of our infrastructure infrastructure
[02:08:45.340 --> 02:08:51.660]   it's just melting down it's very difficult actually because they're now already predicting the end
[02:08:51.660 --> 02:08:58.220]   of the rise the the adoption of new light bulbs led bulbs the low powered devices we're seeing
[02:08:58.220 --> 02:09:02.700]   computers replaced with smartphones you're seeing efficient appliances so electricity demand
[02:09:03.340 --> 02:09:09.180]   mostly in those worlds actually flat and all declining slightly it's flat yeah yeah no that's
[02:09:09.180 --> 02:09:16.220]   interesting and increasingly uh with the arrival of electric vehicles and the the tail of demand
[02:09:16.220 --> 02:09:21.820]   we're actually seeing uh there's a possibility that co2 is going to be a happy story we're actually
[02:09:21.820 --> 02:09:28.540]   seeing uh drops in the production of co2 so if you follow uh the blue bird and energy for them
[02:09:29.260 --> 02:09:35.420]   um they're talking about uh how the predictions for co2 production may actually be overly aggressive
[02:09:35.420 --> 02:09:39.980]   and we may actually have some hope to survive climate change as if the if the trends to electric
[02:09:39.980 --> 02:09:45.420]   cars and you know power efficient houses and so forth and if people stop mining Bitcoin well i
[02:09:45.420 --> 02:09:52.140]   i think Bitcoin is over fine i mean but with electric cars is attacking a drive up demand again
[02:09:52.140 --> 02:09:58.140]   sorry isn't electric cars going to drive up the demand potentially you know right we got i'm
[02:09:58.140 --> 02:10:02.940]   very proud to say we got 30 solar panels on our house because we were getting an electric car
[02:10:02.940 --> 02:10:07.260]   so that we would exactly why it would be an answer yeah yeah that's exactly why the
[02:10:07.260 --> 02:10:12.780]   yeah yeah because you'll see distributed grid right so where you by the way at least here in
[02:10:12.780 --> 02:10:19.660]   california over our power companies dead bodies they hate the idea of a distributed grid
[02:10:19.660 --> 02:10:24.860]   even though they're quasi not-for-profit organizations they are ultimately for profit
[02:10:24.860 --> 02:10:29.660]   organizations and they don't want to see consumers generating their own power so they make it as
[02:10:29.660 --> 02:10:35.500]   hard as it possibly could be these things will change over time changing yeah yeah but you know
[02:10:35.500 --> 02:10:41.020]   the point is is that uh we're talking about uh in in the technology space where i operate we're
[02:10:41.020 --> 02:10:45.420]   talking about this edge computing thing about how today we're moving everything into the data
[02:10:45.420 --> 02:10:48.620]   center now we're talking about going out to the edge well if you start to do the math around edge
[02:10:48.620 --> 02:10:52.380]   computing and how everything's going to have computers at the edge there's not enough power in the
[02:10:52.380 --> 02:10:57.660]   world but you can generate two kilowatts to run a good sized edge data center just from a couple of
[02:10:57.660 --> 02:11:03.020]   solar panels and a couple of bags of batteries right if you can run a car exactly what Stephen
[02:11:03.020 --> 02:11:07.740]   Hawking discovered that the universe is expanding and then we'll turn into a giant black hole and
[02:11:07.740 --> 02:11:13.340]   contract again that's right so it's like it's really going to be it has to be a distributed power grid
[02:11:13.340 --> 02:11:18.060]   uh everybody will do some generation locally and i think we'll see the emergence of some sort of
[02:11:18.060 --> 02:11:23.580]   storage technology where your house will store that's the key is store cities will have a local
[02:11:23.580 --> 02:11:29.260]   storage array whether it's you know air pumped into an underground reservoir or water pumped up
[02:11:29.260 --> 02:11:34.060]   into a tower and then it drops down and acts like a pseudo hydrate there'll be some sort of
[02:11:34.060 --> 02:11:37.580]   in there's dozens of different ways this could work out we'll see how it works out over time
[02:11:37.580 --> 02:11:44.380]   to the to that effect one of the coolest things that i um learned about recently in the last six
[02:11:44.380 --> 02:11:51.260]   months was a company um well well uh healed company that's doing some research on
[02:11:51.260 --> 02:11:58.060]   floors that actually take the energy of people walking around in the floors and convert that into
[02:11:58.060 --> 02:12:02.700]   usable energy in the same it's the same process through which you know the Prius breaks right and
[02:12:02.700 --> 02:12:07.020]   it takes that energy and converts it into usable energy well this you know it takes a battery
[02:12:07.020 --> 02:12:11.340]   system similar to like power wall but it takes the floors in your in your so if they they put these
[02:12:11.340 --> 02:12:16.540]   into normal floors in the same way that you know you'll un-musque wants to put it into uh you know
[02:12:16.540 --> 02:12:23.100]   regular shingles and so your floors actually can can take that energy of people walking um not
[02:12:23.100 --> 02:12:27.260]   just in houses but you can imagine it somewhere like Grand Central Station right and you convert
[02:12:27.260 --> 02:12:31.420]   that energy into usable into usable energy super super cool stuff.
[02:12:31.420 --> 02:12:36.860]   I also tell you about doing the same thing with uh you know uh speed bumps to be able to do the
[02:12:36.860 --> 02:12:41.900]   same thing and roadways it's just you know to be able to convert that power and store it in a
[02:12:41.900 --> 02:12:50.300]   way that's really efficient. I think this would be a good time on an up note to end the show so
[02:12:50.300 --> 02:12:55.980]   we're all feeling good and positive because it was pretty negative at the beginning here Jason
[02:12:55.980 --> 02:12:59.980]   Heiner from Tech Republic thank you so much for being here we really appreciate it at Jason.
[02:12:59.980 --> 02:13:06.460]   Very good and my book. Your book. Follow the geeks. Follow the geeks um on audible
[02:13:07.020 --> 02:13:14.060]   you can find it on audible and on amazon um and the sample chapter on audible as I always say is
[02:13:14.060 --> 02:13:20.860]   me chapter nine Leo LePorte. Uh very very good book it's the closest I'll ever get to having a
[02:13:20.860 --> 02:13:26.860]   memoir it is I highly recommend it and Jason you and Lindsey did a great job uh interviewing me
[02:13:26.860 --> 02:13:32.380]   and writing up my story but not just me lots of interesting people and frankly if you're if you're
[02:13:32.380 --> 02:13:37.420]   a twit fan you'll probably recognize a lot of the names on this book it's really really
[02:13:37.420 --> 02:13:40.780]   definitely or great listen. Unhonable thank you Jason.
[02:13:40.780 --> 02:13:47.580]   George Adele always a thrill always a pleasure things going well for you.
[02:13:47.580 --> 02:13:51.340]   Yeah yeah things are on the upswing it can't get any worse so.
[02:13:51.340 --> 02:13:55.660]   Oh yeah George your lost your mom a couple of months ago and I know that was that's been a
[02:13:55.660 --> 02:14:00.700]   tough time but we're glad we're glad you're feeling better thank you thank you yeah thanks for being
[02:14:00.700 --> 02:14:04.860]   out here and congratulations on marrying Anthony that's that's really good.
[02:14:04.860 --> 02:14:10.700]   I've seen this byline for a long time and I didn't I didn't put two together.
[02:14:10.700 --> 02:14:13.980]   Yeah that's true there's no picture anything there right.
[02:14:13.980 --> 02:14:15.420]   Oh I just didn't put two and two together.
[02:14:15.420 --> 02:14:20.620]   Thank you Georgia Greg Farrow you're a pistol always a pleasure to have you on
[02:14:20.620 --> 02:14:25.900]   packet pushers I know I know gun control is an issue but nobody's going to control that mouth
[02:14:25.900 --> 02:14:32.380]   packet pushers.net ethereal mind on the Twitter Greg you're a pleasure to have on and I know it's
[02:14:32.380 --> 02:14:36.060]   now the now after midnight so we're gonna we're gonna have to let you go I think.
[02:14:36.060 --> 02:14:38.860]   No problems thanks very much for having me back.
[02:14:38.860 --> 02:14:40.860]   You're losing an hour tonight right.
[02:14:40.860 --> 02:14:45.900]   Yes yes the clocks change I'm sitting here looking at my clock wondering if it's going to change
[02:14:45.900 --> 02:14:47.100]   before we wrap up.
[02:14:47.100 --> 02:14:51.900]   If you stay on the show Lee hours it was always it's a it's a huge pleasure it's loads of fun.
[02:14:51.900 --> 02:14:55.340]   You're the greatest thank you Greg thank you everybody for being here we had a great studio
[02:14:55.340 --> 02:14:59.740]   audience thank you for joining us if you want to be in the studio just email tickets at twit.tv
[02:14:59.740 --> 02:15:03.740]   there's no charge we'd love to have you and we'd like to know you're coming so we don't get
[02:15:03.740 --> 02:15:09.660]   surprised we thought there were gonna be 12 people but Mark Burke was putting out chairs for 12
[02:15:09.660 --> 02:15:15.900]   people I don't know we thought there'd be more so thank you you few you hearty you brave souls who
[02:15:15.900 --> 02:15:19.180]   who braved the snow to get here I don't know.
[02:15:19.180 --> 02:15:22.300]   Shout out to the Hoosiers too.
[02:15:22.300 --> 02:15:24.460]   Hoosiers we get a lot of Hoosiers in the house.
[02:15:25.260 --> 02:15:28.620]   If you want to watch live you can also watch our live stream you don't have to come here you
[02:15:28.620 --> 02:15:36.620]   just go to twit.tv/live if you do that though make sure you join us in the chat room at irc.twit.tv
[02:15:36.620 --> 02:15:40.940]   a big part of the show your feedback your comments I'm always watching the chat room
[02:15:40.940 --> 02:15:49.100]   that's 3 p.m. Pacific every Sunday 6 p.m. Eastern time 2200 UTC please stop by and say hi if you
[02:15:49.100 --> 02:15:53.180]   can't watch on demand you can't be in studio we still can't watch live it can't be in studio we still
[02:15:53.180 --> 02:15:59.980]   have on demand versions of all our shows on our website this week in tech is at twit.tv
[02:15:59.980 --> 02:16:05.340]   or subscribe that way you don't have to do anything it'll just appear magically on your phone the
[02:16:05.340 --> 02:16:11.340]   minute it's done thanks for being here we'll see you next time another twit is in the camp bye bye
[02:16:11.500 --> 02:16:21.260]   do the twit all right do the twit baby do the twit all right do it the twit

