;FFMETADATA1
title=May Contain Nuts
artist=Leo Laporte, Phil Libin, Dwight Silverman, Glenn Fleishman
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2022-11-21
track=902
language=English
genre=Podcast
comment=Evernote bought, Trump on Twitter, Holmes sentencing, FTX mess, Artemis launch
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:03.000]   It's time for "Dwight" this week in Tech.
[00:00:03.000 --> 00:00:04.680]   We have a great panel for you.
[00:00:04.680 --> 00:00:06.880]   Glenn Fleischman is here.
[00:00:06.880 --> 00:00:09.240]   Dwight Silverman, formerly of The Chronicle,
[00:00:09.240 --> 00:00:13.780]   and a CEO who knows a lot, Mr. Phil Libben,
[00:00:13.780 --> 00:00:16.000]   one of the founders of Evernote and the creator of,
[00:00:16.000 --> 00:00:19.000]   mm-hmm, the app with a crazy name.
[00:00:19.000 --> 00:00:20.880]   We'll talk about what's going on at Twitter.
[00:00:20.880 --> 00:00:23.720]   Phil has some calming words for us.
[00:00:23.720 --> 00:00:27.760]   Elizabeth Holmes gets 11 years in federal prison.
[00:00:27.760 --> 00:00:29.160]   Is that too much?
[00:00:29.160 --> 00:00:33.720]   And we now know the Earth weighs six rhonograms.
[00:00:33.720 --> 00:00:34.920]   What's a rhonogram?
[00:00:34.920 --> 00:00:36.120]   Stay tuned and find out.
[00:00:36.120 --> 00:00:39.360]   "Twit" is next.
[00:00:39.360 --> 00:00:41.640]   Podcasts you love.
[00:00:41.640 --> 00:00:44.160]   From people you trust.
[00:00:44.160 --> 00:00:45.800]   This is "Twit."
[00:00:45.800 --> 00:00:53.880]   This is "Twit" this week in Tech.
[00:00:53.880 --> 00:00:59.120]   Episode 902, recorded Sunday, November 20, 2022.
[00:00:59.120 --> 00:01:01.520]   Make contained nuts.
[00:01:01.520 --> 00:01:04.880]   This week in Tech is brought to you by ZipRecruiter.
[00:01:04.880 --> 00:01:07.520]   ZipRecruiter makes it easy to hire for even the most
[00:01:07.520 --> 00:01:11.160]   specific role, like one old mascot in Missouri.
[00:01:11.160 --> 00:01:12.920]   In fact, four out of five employers
[00:01:12.920 --> 00:01:15.280]   find a quality candidate within the first day.
[00:01:15.280 --> 00:01:18.840]   Try it free today at ziprecruiter.com/twit.
[00:01:18.840 --> 00:01:22.360]   ZipRecruiter, the smartest way to hire.
[00:01:22.360 --> 00:01:23.920]   And by Nureva.
[00:01:23.920 --> 00:01:26.960]   Nureva has simplified everything about meetings
[00:01:26.960 --> 00:01:28.960]   and classroom audio.
[00:01:28.960 --> 00:01:32.640]   You get great audio and systems that are easy to install and manage.
[00:01:32.640 --> 00:01:38.120]   Visit nureva.com/twit and get 50% off one Nureva HDL 300
[00:01:38.120 --> 00:01:41.840]   system for mid-sized rooms when you get a live online demo.
[00:01:41.840 --> 00:01:45.120]   And by before December 16, 2022.
[00:01:45.120 --> 00:01:46.800]   And by Wealthfront.
[00:01:46.800 --> 00:01:49.880]   Visit wealthfront.com/twit to get started
[00:01:49.880 --> 00:01:54.440]   and get your free $50 bonus with an initial deposit of $500.
[00:01:54.440 --> 00:01:58.080]   That's wealthfront.com/twit.
[00:01:58.080 --> 00:02:01.160]   And by ExpressVPN.
[00:02:01.160 --> 00:02:04.160]   Protect yourself with the VPN that I use and trust.
[00:02:04.160 --> 00:02:07.560]   Use ExpressVPN.com/twit today.
[00:02:07.560 --> 00:02:10.720]   And you'll get an extra three months free on a one year package.
[00:02:10.720 --> 00:02:19.400]   It's time for Twit this week in Tech.
[00:02:19.400 --> 00:02:23.280]   The show we cover the week's tech news.
[00:02:23.280 --> 00:02:25.800]   And as Phil said, there's not much to talk about this week.
[00:02:25.800 --> 00:02:26.600]   Phil Living is here.
[00:02:26.600 --> 00:02:27.880]   It's great to have him.
[00:02:27.880 --> 00:02:31.880]   Love Phil first became aware of him when he was founder and CEO
[00:02:31.880 --> 00:02:35.400]   of one of my all time favorite note taking apps, EverNote.
[00:02:35.400 --> 00:02:36.960]   He has since moved on.
[00:02:36.960 --> 00:02:40.560]   He is now the co-founder and CEO of All Turtles, which
[00:02:40.560 --> 00:02:45.280]   is what an AI kind of proving ground.
[00:02:45.280 --> 00:02:52.640]   And the app with the name MMHMM that he's using right now
[00:02:52.640 --> 00:02:54.720]   to be flying in his private jet.
[00:02:54.720 --> 00:02:56.720]   Hi, Phil.
[00:02:56.720 --> 00:02:58.240]   Hey, Leon, nice to be with you.
[00:02:58.240 --> 00:03:00.920]   Great to have you on the show.
[00:03:00.920 --> 00:03:02.480]   Always welcome.
[00:03:02.480 --> 00:03:04.680]   I brought you on this week because, of course,
[00:03:04.680 --> 00:03:05.600]   EverNote is in the news.
[00:03:05.600 --> 00:03:07.240]   And we'll talk about that in just a little bit.
[00:03:07.240 --> 00:03:08.720]   I'd like to get your take.
[00:03:08.720 --> 00:03:10.360]   But then there's many other things I
[00:03:10.360 --> 00:03:11.120]   want to talk to you about.
[00:03:11.120 --> 00:03:13.520]   Of course, you've run companies.
[00:03:13.520 --> 00:03:16.920]   You know what it's like to take over a company
[00:03:16.920 --> 00:03:19.640]   to have technical infrastructure, have technical debt.
[00:03:19.640 --> 00:03:22.600]   I want to know what you think of what's going on at Twitter.
[00:03:22.600 --> 00:03:24.960]   And because you were born in the Soviet Union and have
[00:03:24.960 --> 00:03:27.880]   Ukrainian family, I'd love to hear your thoughts about all
[00:03:27.880 --> 00:03:28.200]   of that.
[00:03:28.200 --> 00:03:29.160]   So we have lots to do.
[00:03:29.160 --> 00:03:30.320]   All the fun topics.
[00:03:30.320 --> 00:03:30.840]   All right.
[00:03:30.840 --> 00:03:31.680]   Sorry.
[00:03:31.680 --> 00:03:32.760]   I'll throw some--
[00:03:32.760 --> 00:03:33.760]   We'll do something silly.
[00:03:33.760 --> 00:03:35.920]   We'll throw something silly.
[00:03:35.920 --> 00:03:36.760]   That's Glenn Fleischman.
[00:03:36.760 --> 00:03:39.120]   He's in charge of fun here at the network.
[00:03:39.120 --> 00:03:40.440]   We love seeing Glenn.
[00:03:40.440 --> 00:03:42.240]   Glenn.fun is his website.
[00:03:42.240 --> 00:03:43.960]   You see him on Mac Break Weekly.
[00:03:43.960 --> 00:03:45.400]   You see him on our Mastodon, where
[00:03:45.400 --> 00:03:46.680]   he is a great contributor.
[00:03:46.680 --> 00:03:47.880]   Hi, Glenn.
[00:03:47.880 --> 00:03:48.440]   Hello.
[00:03:48.440 --> 00:03:51.440]   Thanks, Remy, back for this boring, boring week.
[00:03:51.440 --> 00:03:53.280]   So we can watch nothing whatsoever happened.
[00:03:53.280 --> 00:03:54.920]   Nothing anywhere in Sakhalin.
[00:03:54.920 --> 00:03:55.680]   Nothing.
[00:03:55.680 --> 00:03:56.960]   Nothing.
[00:03:56.960 --> 00:03:57.880]   Nothing.
[00:03:57.880 --> 00:03:58.960]   We'll find something to talk about.
[00:03:58.960 --> 00:03:59.760]   So slow.
[00:03:59.760 --> 00:04:03.160]   And a dear friend who's been with us for many, many years--
[00:04:03.160 --> 00:04:05.680]   I remember talking to you when the iPad came out
[00:04:05.680 --> 00:04:06.800]   how many years ago is that.
[00:04:06.800 --> 00:04:10.280]   Dwight Silverman, many years at the Houston Chronicle,
[00:04:10.280 --> 00:04:12.920]   he ran a radio show and added Texas for a long time.
[00:04:12.920 --> 00:04:16.120]   He's at authory.com/dsilverman.
[00:04:16.120 --> 00:04:18.360]   That's where all of his work goes.
[00:04:18.360 --> 00:04:19.560]   And there's quite a bit of it.
[00:04:19.560 --> 00:04:21.360]   Good to see you, Dwight.
[00:04:21.360 --> 00:04:22.680]   And it's really good to be here.
[00:04:22.680 --> 00:04:23.680]   Yeah.
[00:04:23.680 --> 00:04:25.240]   I'm looking forward to talking this week,
[00:04:25.240 --> 00:04:28.480]   because as Phil said, it's a slow news week.
[00:04:28.480 --> 00:04:31.160]   We've got a chance to make stuff up this week.
[00:04:31.160 --> 00:04:33.920]   And I'm all about that.
[00:04:33.920 --> 00:04:34.360]   Wow.
[00:04:34.360 --> 00:04:35.880]   I don't even know where to start.
[00:04:35.880 --> 00:04:36.840]   We should have had a vote.
[00:04:36.840 --> 00:04:42.000]   Holy cow.
[00:04:42.000 --> 00:04:44.120]   Holy cow.
[00:04:44.120 --> 00:04:46.200]   Yeah, let's do a Twitter poll.
[00:04:46.200 --> 00:04:49.080]   So you said the word Twitter might as well do it.
[00:04:49.080 --> 00:04:52.880]   Donald Trump is back on the blue bird,
[00:04:52.880 --> 00:04:54.240]   not that he's said anything.
[00:04:54.240 --> 00:04:56.960]   In fact, in a way, I don't know if he should be too glad he's
[00:04:56.960 --> 00:05:02.600]   back, because the tweets are the last tweets he made on January 6.
[00:05:02.600 --> 00:05:05.480]   Someone incriminating, maybe?
[00:05:05.480 --> 00:05:07.880]   He has said that he's going to stay on his own site,
[00:05:07.880 --> 00:05:08.520]   Truth Social.
[00:05:08.520 --> 00:05:11.960]   But this is the latest thing that Elon
[00:05:11.960 --> 00:05:14.560]   did that is kind of contradictory to something
[00:05:14.560 --> 00:05:15.240]   he said earlier.
[00:05:15.240 --> 00:05:18.440]   He said, we're going to have a panel of experts
[00:05:18.440 --> 00:05:22.240]   to approve the return and departure of people.
[00:05:22.240 --> 00:05:24.720]   And then forget that.
[00:05:24.720 --> 00:05:26.240]   Let's have a poll.
[00:05:26.240 --> 00:05:30.360]   As many have pointed out, that poll is easily game.
[00:05:30.360 --> 00:05:33.520]   Somebody said, well, now we know what the GRU wants.
[00:05:33.520 --> 00:05:36.080]   Although, I got to say, it was surprisingly close.
[00:05:36.080 --> 00:05:37.920]   I thought it would be overwhelmingly in favor
[00:05:37.920 --> 00:05:40.680]   of bringing back the former president.
[00:05:40.680 --> 00:05:42.880]   So much has happened.
[00:05:42.880 --> 00:05:46.080]   Twitter is the gift that keeps on giving.
[00:05:46.080 --> 00:05:50.760]   Although I saw Mike Maples Jr. kind of snappishly--
[00:05:50.760 --> 00:05:52.320]   maybe you saw this too, Phil--
[00:05:52.320 --> 00:05:56.120]   on Twitter saying to one of the--
[00:05:56.120 --> 00:05:58.600]   I think it was to Casey Newton of platformer,
[00:05:58.600 --> 00:06:00.480]   who's been covering this, doing a very good job.
[00:06:00.480 --> 00:06:02.000]   He's got a lot of sources on Twitter,
[00:06:02.000 --> 00:06:04.720]   saying, why don't you cover something more productive
[00:06:04.720 --> 00:06:07.120]   than the demise of Twitter?
[00:06:07.120 --> 00:06:08.480]   I think this is a bigger story.
[00:06:08.480 --> 00:06:10.760]   This is not-- this is a real news story, isn't it?
[00:06:10.760 --> 00:06:13.960]   Or is it just a soap opera, Phil?
[00:06:13.960 --> 00:06:16.080]   I mean, it's both.
[00:06:16.080 --> 00:06:20.240]   I am not expecting the demise of Twitter out of this.
[00:06:20.240 --> 00:06:24.480]   There's more drama than is probably strictly necessary.
[00:06:24.480 --> 00:06:26.480]   But yeah, it's been interesting to watch.
[00:06:26.480 --> 00:06:29.360]   It's definitely maximizing for my entertainment.
[00:06:29.360 --> 00:06:31.080]   It is entertaining.
[00:06:31.080 --> 00:06:34.720]   It was very sad on Twitter on Friday night
[00:06:34.720 --> 00:06:40.080]   when the news came that this was Elon's deadline for engineers
[00:06:40.080 --> 00:06:43.280]   to either go hardcore or go home.
[00:06:43.280 --> 00:06:47.880]   And he put out a form, a Google form of oddly enough
[00:06:47.880 --> 00:06:49.720]   that somebody should check saying, yes,
[00:06:49.720 --> 00:06:52.160]   I'm willing to go hardcore with you or no,
[00:06:52.160 --> 00:06:54.760]   I'll take my three-month severance now.
[00:06:54.760 --> 00:06:56.680]   I imagine a number of-- we don't know
[00:06:56.680 --> 00:06:58.040]   what the actual response--
[00:06:58.040 --> 00:06:59.880]   so the New York Times is reporting--
[00:06:59.880 --> 00:07:02.600]   and Casey Newton is reporting about 1,100 engineers--
[00:07:02.600 --> 00:07:05.880]   took advantage of that three-month severance.
[00:07:05.880 --> 00:07:07.280]   I think that's the sensible thing to do.
[00:07:07.280 --> 00:07:08.320]   But it's not binding.
[00:07:08.320 --> 00:07:11.040]   I imagine a large number of people just said,
[00:07:11.040 --> 00:07:12.680]   I don't have to answer that.
[00:07:12.680 --> 00:07:14.120]   It's going to come to work.
[00:07:14.120 --> 00:07:15.880]   Is anybody left there who could fire then?
[00:07:15.880 --> 00:07:17.480]   That's the question of reading--
[00:07:17.480 --> 00:07:19.000]   I think of New York Times.
[00:07:19.000 --> 00:07:20.840]   One of the anecdotes they had was a woman
[00:07:20.840 --> 00:07:22.520]   roaming around the building for two days
[00:07:22.520 --> 00:07:25.080]   because her manager had been fired to try to give notice.
[00:07:25.080 --> 00:07:28.160]   And she finally found her new manager gave notice.
[00:07:28.160 --> 00:07:30.800]   And then that manager was fired the next day or left.
[00:07:30.800 --> 00:07:33.520]   So it does have a kind of Keystone Cop,
[00:07:33.520 --> 00:07:36.840]   Smark's Brothers, Fellini vibe.
[00:07:36.840 --> 00:07:39.880]   There's just a lot of stuff happening all at once
[00:07:39.880 --> 00:07:43.040]   in some of its farce and some of its overwhelming.
[00:07:43.040 --> 00:07:45.440]   And some of this rumor that is probably not provably true.
[00:07:45.440 --> 00:07:48.600]   For instance, there was a confirmed story
[00:07:48.600 --> 00:07:52.440]   that Badjax was turned off on Friday.
[00:07:52.440 --> 00:07:53.520]   And then nobody could go in.
[00:07:53.520 --> 00:07:55.640]   Nobody's going to be able to go in until Monday.
[00:07:55.640 --> 00:07:59.400]   But Elon, at 1.20 on Saturday morning,
[00:07:59.400 --> 00:08:02.880]   posted a picture of him going beast mode
[00:08:02.880 --> 00:08:05.200]   with the remaining engineers.
[00:08:05.200 --> 00:08:06.240]   It's a small group.
[00:08:06.240 --> 00:08:14.000]   And there's only one, two, a few women, mostly guys.
[00:08:14.000 --> 00:08:17.040]   This is what's left, Elon inside.
[00:08:17.040 --> 00:08:20.280]   This is his so-called code review.
[00:08:20.280 --> 00:08:25.280]   He was telling, bring 10 screenshots of your code.
[00:08:25.280 --> 00:08:28.240]   This is what he posted on his Twitter.
[00:08:28.240 --> 00:08:29.920]   It doesn't look like code.
[00:08:29.920 --> 00:08:34.440]   It looks like they're telling him how Twitter works at this point.
[00:08:34.440 --> 00:08:36.480]   Also, I wonder when he disabled Cardkey Access,
[00:08:36.480 --> 00:08:38.200]   was he trying to keep people in or keep them out?
[00:08:38.200 --> 00:08:38.840]   That wasn't fair.
[00:08:38.840 --> 00:08:42.920]   Supposedly, the rumor was that the Cardkey Access ended
[00:08:42.920 --> 00:08:47.200]   because the whole team that managed it was gone.
[00:08:47.200 --> 00:08:48.200]   That was a bad--
[00:08:48.200 --> 00:08:50.160]   That was a tweet from a prankster, by the way.
[00:08:50.160 --> 00:08:51.320]   Yes, right, right, right.
[00:08:51.320 --> 00:08:53.280]   And the prankster said nobody can get out,
[00:08:53.280 --> 00:08:54.520]   so they had to call me back in.
[00:08:54.520 --> 00:08:56.560]   But of course, Cardkeys don't work that way.
[00:08:56.560 --> 00:08:58.320]   They keep it without not keep people in.
[00:08:58.320 --> 00:09:02.120]   You'd have a fire code violation if you couldn't get out.
[00:09:02.120 --> 00:09:03.920]   The deadline was Thursday.
[00:09:03.920 --> 00:09:04.920]   Yeah.
[00:09:04.920 --> 00:09:09.760]   And one of the things-- and supposedly, the form that you went to
[00:09:09.760 --> 00:09:13.080]   when you clicked on his link was simply yes.
[00:09:13.080 --> 00:09:14.480]   Oh, I didn't do that.
[00:09:14.480 --> 00:09:15.480]   I was interested.
[00:09:15.480 --> 00:09:19.960]   Yes, and the people who didn't click yes were presumed to have--
[00:09:19.960 --> 00:09:21.040]   By default, that's no.
[00:09:21.040 --> 00:09:22.560]   --resignation, right.
[00:09:22.560 --> 00:09:23.080]   Right.
[00:09:23.080 --> 00:09:25.440]   So that's how it worked.
[00:09:25.440 --> 00:09:28.960]   You've run technical teams, Phil.
[00:09:28.960 --> 00:09:29.840]   Yeah.
[00:09:29.840 --> 00:09:32.240]   Phil, what are you--
[00:09:32.240 --> 00:09:36.040]   How do engineers take to this kind of thing?
[00:09:36.040 --> 00:09:40.400]   Look, I think Elon's always been an outlier, and Twitter's
[00:09:40.400 --> 00:09:43.160]   an outlier, and there's not that much that we can learn from
[00:09:43.160 --> 00:09:44.880]   really studying outliers.
[00:09:44.880 --> 00:09:47.560]   By definition, most things don't behave like this.
[00:09:47.560 --> 00:09:49.920]   Most companies don't run like this.
[00:09:49.920 --> 00:09:53.240]   I think it's hard to predict how it's going to go, other
[00:09:53.240 --> 00:09:57.080]   than, look, at the end of the day, it's a website.
[00:09:57.080 --> 00:09:58.600]   They're going to figure it out.
[00:09:58.600 --> 00:10:02.080]   This isn't the hardest thing that Elon's built.
[00:10:02.080 --> 00:10:03.640]   I'm pretty sure they're going to get it right.
[00:10:03.640 --> 00:10:07.240]   Again, there's going to be a lot more drama than I would have
[00:10:07.240 --> 00:10:11.520]   liked to see, and a lot of people's lives get turned upside
[00:10:11.520 --> 00:10:16.560]   down, or at least add a lot of uncertainty around jobs.
[00:10:16.560 --> 00:10:18.160]   So it's drama.
[00:10:18.160 --> 00:10:19.480]   It's theater.
[00:10:19.480 --> 00:10:21.560]   But I think people like predicting that this is the end
[00:10:21.560 --> 00:10:22.560]   of Twitter.
[00:10:22.560 --> 00:10:23.040]   I don't know.
[00:10:23.040 --> 00:10:23.880]   I mean, maybe.
[00:10:23.880 --> 00:10:26.280]   Hard to know the future, but I'm certainly not expecting it
[00:10:26.280 --> 00:10:27.120]   to disappear.
[00:10:27.120 --> 00:10:29.400]   I don't think a lot of people said, oh, it's only a matter
[00:10:29.400 --> 00:10:31.440]   of time if the website fails.
[00:10:31.440 --> 00:10:34.080]   First of all, you design it to keep going.
[00:10:34.080 --> 00:10:36.040]   Even if everybody walked out of the building, it would keep
[00:10:36.040 --> 00:10:39.000]   going for some time.
[00:10:39.000 --> 00:10:39.600]   Yeah, you're right.
[00:10:39.600 --> 00:10:41.680]   I don't see this as the end of Twitter.
[00:10:41.680 --> 00:10:45.400]   Maybe the bigger question is the end of content moderation.
[00:10:45.400 --> 00:10:49.440]   And for a while, people were posting full length Hollywood
[00:10:49.440 --> 00:10:51.800]   movies on Twitter.
[00:10:51.800 --> 00:10:53.360]   They fixed that, by the way.
[00:10:53.360 --> 00:10:55.360]   The crew that was taking that stuff down
[00:10:55.360 --> 00:10:59.920]   came either arrived or finally noticed.
[00:10:59.920 --> 00:11:03.320]   Yeah, I got a strongly disagree on the technical side,
[00:11:03.320 --> 00:11:06.000]   not because I have magic insight into Twitter's code base.
[00:11:06.000 --> 00:11:08.800]   But every report that's come out of there from people
[00:11:08.800 --> 00:11:12.080]   who've left recently, and many people in the past,
[00:11:12.080 --> 00:11:16.840]   is that they have an incredibly fragile infrastructure
[00:11:16.840 --> 00:11:20.160]   that they've barely been able to keep alive for years,
[00:11:20.160 --> 00:11:23.520]   and that there's so much accumulated technical debt
[00:11:23.520 --> 00:11:27.320]   without working on core restructuring and refactoring,
[00:11:27.320 --> 00:11:30.400]   all the rest of it, to keep it more reliable.
[00:11:30.400 --> 00:11:33.480]   Mudge, who was the engineer who left and became a whistleblower,
[00:11:33.480 --> 00:11:35.920]   he said that thing about, which makes a lot of sense,
[00:11:35.920 --> 00:11:37.720]   is that there's so many services that
[00:11:37.720 --> 00:11:38.840]   depend on each other.
[00:11:38.840 --> 00:11:41.720]   If there were actually a complete temporary collapse
[00:11:41.720 --> 00:11:44.080]   of the systems, everything had to be shut down, basically
[00:11:44.080 --> 00:11:46.720]   power cycle, everything, then they might not
[00:11:46.720 --> 00:11:48.840]   be able to bring it back up because some services are
[00:11:48.840 --> 00:11:50.200]   dependent on other things running.
[00:11:50.200 --> 00:11:52.280]   And if those aren't running, they can't come up.
[00:11:52.280 --> 00:11:55.520]   So I don't want to predict a doom,
[00:11:55.520 --> 00:12:00.240]   but when you get 75% or 80% of the people at a company
[00:12:00.240 --> 00:12:02.800]   are gone, if they're running their own data center operations
[00:12:02.800 --> 00:12:04.960]   for the most part, which is unusual for a company
[00:12:04.960 --> 00:12:08.320]   of that particular scale and with those kind of operations,
[00:12:08.320 --> 00:12:11.600]   there's so much that could easily go wrong.
[00:12:11.600 --> 00:12:15.360]   And the person who knows how to fix it is nowhere in sight.
[00:12:15.360 --> 00:12:18.120]   So I don't think it's necessary that the site just
[00:12:18.120 --> 00:12:21.400]   goes down as entropy, and that they can't fix things.
[00:12:21.400 --> 00:12:23.960]   But that there may simply be too many plates spinning
[00:12:23.960 --> 00:12:27.040]   that all crash the ground at once and they can't catch them.
[00:12:27.040 --> 00:12:29.600]   There may be, or it may be OK.
[00:12:29.600 --> 00:12:31.600]   Well, I think it's-- but it's not to mean--
[00:12:31.600 --> 00:12:35.200]   if you fired 80% of yourself, could you
[00:12:35.200 --> 00:12:37.160]   keep everything running on an operation that
[00:12:37.160 --> 00:12:39.120]   serves hundreds of millions of people
[00:12:39.120 --> 00:12:44.360]   and has got all of these conflicting regulatory and other--
[00:12:44.360 --> 00:12:46.080]   I mean, they've got regulatory burdens to meet.
[00:12:46.080 --> 00:12:47.280]   They have technical burdens to meet.
[00:12:47.280 --> 00:12:50.160]   They run their own infrastructure.
[00:12:50.160 --> 00:12:51.680]   I guess that's a good question, is which
[00:12:51.680 --> 00:12:53.640]   is going to be the first to go?
[00:12:53.640 --> 00:12:59.680]   Is it going to be the content layer or the technical layer?
[00:12:59.680 --> 00:13:00.920]   The content's going to be tough.
[00:13:00.920 --> 00:13:02.680]   You've got, as you said-- and I think
[00:13:02.680 --> 00:13:05.560]   Elon underestimated how many different countries
[00:13:05.560 --> 00:13:08.640]   he was going to have to appease, many of which he does
[00:13:08.640 --> 00:13:11.560]   business with Tesla.
[00:13:11.560 --> 00:13:15.280]   That's going to be a real challenge for him.
[00:13:15.280 --> 00:13:22.560]   He also seems to have a failing comment among some billionaires
[00:13:22.560 --> 00:13:26.920]   that he seems to be very hands-on.
[00:13:26.920 --> 00:13:29.880]   And I little bit worried that when he says,
[00:13:29.880 --> 00:13:32.120]   we're going to turn off 80% of microservices.
[00:13:32.120 --> 00:13:32.920]   That's it.
[00:13:32.920 --> 00:13:34.800]   Yeah.
[00:13:34.800 --> 00:13:38.120]   That there's no one there to say, Elon, that's a bad idea.
[00:13:38.120 --> 00:13:39.120]   And here's why.
[00:13:39.120 --> 00:13:42.200]   Joelle Roth, for a long time, Jeff Jarvis was saying,
[00:13:42.200 --> 00:13:44.520]   well, it's not going to be too bad because Joelle Roth is
[00:13:44.520 --> 00:13:46.480]   there, head of trust and safety.
[00:13:46.480 --> 00:13:48.640]   He's not.
[00:13:48.640 --> 00:13:50.880]   In fact, wrote a piece on the New York Times.
[00:13:50.880 --> 00:13:54.360]   He was very judicious, I think.
[00:13:54.360 --> 00:13:57.880]   But he said, they don't need a head of trust and safety
[00:13:57.880 --> 00:14:01.640]   because Elon is making the decisions now.
[00:14:01.640 --> 00:14:09.240]   In other words, it's not a democracy.
[00:14:09.240 --> 00:14:11.280]   He doesn't have advisors.
[00:14:11.280 --> 00:14:12.240]   It's Elon.
[00:14:12.240 --> 00:14:13.880]   And he says, well, you don't need me anymore
[00:14:13.880 --> 00:14:18.560]   because I got nothing to say about anything.
[00:14:18.560 --> 00:14:19.240]   And they may be.
[00:14:19.240 --> 00:14:21.280]   And I know probably this was another story
[00:14:21.280 --> 00:14:24.840]   was that some engineers were worried about long-term liability
[00:14:24.840 --> 00:14:27.740]   if they stuck around and had no power to counter
[00:14:27.740 --> 00:14:30.760]   Elon's worst impulses.
[00:14:30.760 --> 00:14:37.240]   But OK, so look, I don't remember a previous time
[00:14:37.240 --> 00:14:40.760]   where so many people have actively and gleefully
[00:14:40.760 --> 00:14:42.000]   wanted a company to--
[00:14:42.000 --> 00:14:43.120]   That's a good point.
[00:14:43.120 --> 00:14:44.440]   And there is it very much.
[00:14:44.440 --> 00:14:45.360]   And so publicly.
[00:14:45.360 --> 00:14:47.360]   Yeah.
[00:14:47.360 --> 00:14:49.480]   And many of the people who wanted to fall apart
[00:14:49.480 --> 00:14:51.480]   also wanted to stay enough all apart.
[00:14:51.480 --> 00:14:55.120]   You can have both of those ideas in your head at the same time.
[00:14:55.120 --> 00:14:58.960]   Twitter in the long term has been one of the companies
[00:14:58.960 --> 00:15:03.560]   that's really, I think, forced our society and our discourse
[00:15:03.560 --> 00:15:10.000]   to become maximized, to become all about exaggerating conflict.
[00:15:10.000 --> 00:15:15.200]   Twitter has helped professional wrestling eyes
[00:15:15.200 --> 00:15:16.600]   most of our conversation.
[00:15:16.600 --> 00:15:18.480]   I don't think they've been as guilty of this as Facebook.
[00:15:18.480 --> 00:15:20.720]   I think Facebook has been worse.
[00:15:20.720 --> 00:15:22.920]   But Twitter certainly contributed to that.
[00:15:22.920 --> 00:15:26.760]   And a few years ago, Jack decided, hey, this is bad.
[00:15:26.760 --> 00:15:28.960]   And so they're going to focus on healthy conversations.
[00:15:28.960 --> 00:15:30.640]   And they tried to figure out our tone down.
[00:15:30.640 --> 00:15:32.600]   And they were successful to some extent.
[00:15:32.600 --> 00:15:34.600]   But it's appropriate.
[00:15:34.600 --> 00:15:37.320]   Like Twitter, the company that made everything
[00:15:37.320 --> 00:15:40.680]   into high drama is now experiencing.
[00:15:40.680 --> 00:15:42.600]   What a surprise.
[00:15:42.600 --> 00:15:44.600]   But you started to start.
[00:15:44.600 --> 00:15:45.160]   Well, yeah.
[00:15:45.160 --> 00:15:47.120]   But this isn't ironic.
[00:15:47.120 --> 00:15:48.200]   It's the opposite.
[00:15:48.200 --> 00:15:50.960]   It's exactly what you would expect to happen.
[00:15:50.960 --> 00:15:52.240]   It's inevitable.
[00:15:52.240 --> 00:15:55.040]   But it doesn't mean that it doesn't--
[00:15:55.040 --> 00:15:57.520]   like, yeah, it's going to go through a period of high drama.
[00:15:57.520 --> 00:16:00.440]   I think, again, it's hard to predict the future.
[00:16:00.440 --> 00:16:03.240]   I have seen a lot of the stuff that Elon's done.
[00:16:03.240 --> 00:16:04.320]   I think we all have.
[00:16:04.320 --> 00:16:07.200]   I have some sense of the complexity required to run systems
[00:16:07.200 --> 00:16:08.800]   at hundreds of millions of people.
[00:16:08.800 --> 00:16:10.800]   I've never operated systems that more than hundreds
[00:16:10.800 --> 00:16:11.600]   of millions of people use.
[00:16:11.600 --> 00:16:13.480]   But I have operated systems at hundreds of millions
[00:16:13.480 --> 00:16:16.000]   of people use, which is not quite the scale of Twitter.
[00:16:16.000 --> 00:16:17.920]   But also the average for me many years ago,
[00:16:17.920 --> 00:16:20.280]   things have gotten a little bit easier with infrastructure.
[00:16:20.280 --> 00:16:22.200]   So I have some appreciation of that.
[00:16:22.200 --> 00:16:24.160]   And I've seen other stuff that Elon's done.
[00:16:24.160 --> 00:16:27.320]   And they're like orders of magnitude harder than--
[00:16:27.320 --> 00:16:28.560]   And SpaceX is harder.
[00:16:28.560 --> 00:16:30.320]   What he's done with Tesla is harder.
[00:16:30.320 --> 00:16:31.680]   The boring company is harder.
[00:16:31.680 --> 00:16:32.840]   The boring company.
[00:16:32.840 --> 00:16:35.320]   Like, look, I would have preferred that he buy Twitter
[00:16:35.320 --> 00:16:37.920]   and rename it to the other boring company.
[00:16:37.920 --> 00:16:39.360]   [LAUGHTER]
[00:16:39.360 --> 00:16:41.440]   He could calm and calm everything down.
[00:16:41.440 --> 00:16:43.160]   And he decided to go in a different direction.
[00:16:43.160 --> 00:16:43.640]   That's Elon.
[00:16:43.640 --> 00:16:44.480]   He's much more complex.
[00:16:44.480 --> 00:16:46.280]   Phil, I want to make sure I didn't actually
[00:16:46.280 --> 00:16:48.680]   insult you earlier, because I realized what you're just saying.
[00:16:48.680 --> 00:16:52.400]   If you built a company and you laid off 80% of people
[00:16:52.400 --> 00:16:55.000]   that worked for you, that inevitability had to happen
[00:16:55.000 --> 00:16:58.000]   for business reasons or whatever, I believe your company
[00:16:58.000 --> 00:16:59.280]   might actually still run.
[00:16:59.280 --> 00:17:01.400]   I also believe Tesla was built--
[00:17:01.400 --> 00:17:03.400]   Elon came in a little bit into it.
[00:17:03.400 --> 00:17:04.240]   He built the company.
[00:17:04.240 --> 00:17:04.760]   It is today.
[00:17:04.760 --> 00:17:07.640]   He made nearly every decision.
[00:17:07.640 --> 00:17:09.200]   Same thing with SpaceX.
[00:17:09.200 --> 00:17:10.360]   This is not a company.
[00:17:10.360 --> 00:17:13.280]   He may not have invented the fundamental technology involved.
[00:17:13.280 --> 00:17:14.640]   He's not a space engineer.
[00:17:14.640 --> 00:17:15.840]   He made a lot of decisions.
[00:17:15.840 --> 00:17:18.800]   And he's responsible for good or bad--
[00:17:18.800 --> 00:17:20.040]   or everything that's come out of that.
[00:17:20.040 --> 00:17:21.520]   And their ability to perform today.
[00:17:21.520 --> 00:17:22.840]   He did not build Twitter.
[00:17:22.840 --> 00:17:25.680]   And he went into Twitter as if he had built it.
[00:17:25.680 --> 00:17:28.320]   And thus, intuitively knew everything that went on.
[00:17:28.320 --> 00:17:29.480]   And I think you.
[00:17:29.480 --> 00:17:32.320]   I'd like to picture you going to Twitter having spent $45
[00:17:32.320 --> 00:17:33.040]   billion.
[00:17:33.040 --> 00:17:34.680]   I'm sure you've got the lying around.
[00:17:34.680 --> 00:17:36.680]   And have bought it and gone in there.
[00:17:36.680 --> 00:17:38.040]   And how you would have approached it.
[00:17:38.040 --> 00:17:42.000]   I can't have imagined would be like him at all
[00:17:42.000 --> 00:17:42.920]   because you didn't build it.
[00:17:42.920 --> 00:17:44.080]   You didn't build that technology.
[00:17:44.080 --> 00:17:45.280]   Yeah, look, obviously.
[00:17:45.280 --> 00:17:49.280]   So I don't think I would lay off 80% of my stuff.
[00:17:49.280 --> 00:17:50.400]   I'm not sure that Elon has either.
[00:17:50.400 --> 00:17:51.680]   We're not sure what that is.
[00:17:51.680 --> 00:17:52.800]   We don't have any idea.
[00:17:52.800 --> 00:17:54.680]   We know it's a 50% to 80%.
[00:17:54.680 --> 00:17:55.560]   Yeah.
[00:17:55.560 --> 00:17:57.880]   But if you phrase it a different way,
[00:17:57.880 --> 00:18:00.640]   if I was running something like Twitter at 80%
[00:18:00.640 --> 00:18:06.520]   and my staff became incapacitated to COVID 23 or something,
[00:18:06.520 --> 00:18:07.560]   would I be able to keep it running?
[00:18:07.560 --> 00:18:08.560]   Yeah, I would be.
[00:18:08.560 --> 00:18:09.560]   Yeah, I believe that.
[00:18:09.560 --> 00:18:10.680]   If you build it, I believe it.
[00:18:10.680 --> 00:18:14.400]   And well, I mean, I don't think everything is a reducer--
[00:18:14.400 --> 00:18:20.040]   or is reducibly, in complex enough
[00:18:20.040 --> 00:18:22.600]   that I think looking at Twitter from the outside,
[00:18:22.600 --> 00:18:23.840]   it feels very fragile.
[00:18:23.840 --> 00:18:29.080]   And watching Musk tear wires out, it makes it feel very fragile.
[00:18:29.080 --> 00:18:31.760]   So if it's more resilient than it appears, that's great.
[00:18:31.760 --> 00:18:33.440]   And I don't want to dance on Twitter's grave,
[00:18:33.440 --> 00:18:36.120]   because it's responsible for a lot of professional success
[00:18:36.120 --> 00:18:37.680]   and friendships and so forth.
[00:18:37.680 --> 00:18:38.880]   But I also don't want it to--
[00:18:38.880 --> 00:18:40.800]   I think it's climbed out of a deep hole,
[00:18:40.800 --> 00:18:42.640]   and I don't want it to fall back into it, which
[00:18:42.640 --> 00:18:45.240]   is what it seems like he's leaping broadly into
[00:18:45.240 --> 00:18:46.440]   without a bungee cord.
[00:18:46.440 --> 00:18:49.600]   Let's say two quick things, kind of structurally about this.
[00:18:49.600 --> 00:18:52.360]   First of all, in some part, thanks to Twitter--
[00:18:52.360 --> 00:18:55.440]   not entirely, but in some part, thanks to Twitter--
[00:18:55.440 --> 00:18:58.040]   most things seem worse than they really are.
[00:18:58.040 --> 00:19:00.360]   [LAUGHTER]
[00:19:00.360 --> 00:19:04.040]   Like most things in life seem worse than they really are,
[00:19:04.040 --> 00:19:06.920]   because engagement-based business models,
[00:19:06.920 --> 00:19:10.000]   ad-based micro-clicking business models,
[00:19:10.000 --> 00:19:12.360]   incentivize everything to seem worse than they really is.
[00:19:12.360 --> 00:19:15.160]   And Twitter, old Twitter, bears some of the responsibility
[00:19:15.160 --> 00:19:15.660]   for that.
[00:19:15.660 --> 00:19:20.640]   I don't think not as much as meta or Facebook, but some.
[00:19:20.640 --> 00:19:22.640]   And I think, one of the things that Elon is doing,
[00:19:22.640 --> 00:19:25.800]   trying to reduce their reliance on advertising,
[00:19:25.800 --> 00:19:28.320]   is a very good thing, because it really
[00:19:28.320 --> 00:19:31.400]   can dial the temperature down, because otherwise, the incentive
[00:19:31.400 --> 00:19:33.800]   is to make everything seem worse than it really is.
[00:19:33.800 --> 00:19:34.920]   So that's kind of the first thing.
[00:19:34.920 --> 00:19:37.800]   And again, Twitter is now at the eye of the Twitter storm.
[00:19:37.800 --> 00:19:39.640]   It's like, all of the inflated drama
[00:19:39.640 --> 00:19:40.840]   is not being focused on itself.
[00:19:40.840 --> 00:19:42.240]   So of course, it seems terrible.
[00:19:42.240 --> 00:19:43.360]   That's exactly what you mean.
[00:19:43.360 --> 00:19:46.880]   It's not saying it's not bad, but it's probably not as bad
[00:19:46.880 --> 00:19:47.360]   as it seems.
[00:19:47.360 --> 00:19:49.400]   It probably looks worse than it really is.
[00:19:49.400 --> 00:19:53.760]   The second thing is, I don't think that Elon--
[00:19:53.760 --> 00:19:56.640]   I don't know him very well personally.
[00:19:56.640 --> 00:19:59.960]   But I very much don't get the sense
[00:19:59.960 --> 00:20:03.000]   that he is a person that surrounds himself with the S-Men.
[00:20:03.000 --> 00:20:03.360]   Really?
[00:20:03.360 --> 00:20:03.920]   People that--
[00:20:03.920 --> 00:20:04.840]   See, this is--
[00:20:04.840 --> 00:20:05.520]   Very much interest.
[00:20:05.520 --> 00:20:06.360]   Wow.
[00:20:06.360 --> 00:20:06.840]   OK.
[00:20:06.840 --> 00:20:07.600]   That's good news.
[00:20:07.600 --> 00:20:09.000]   That's a good thing.
[00:20:09.000 --> 00:20:11.520]   Does there's somebody who decides Jason Calicanis
[00:20:11.520 --> 00:20:13.400]   and David Sachs advising him?
[00:20:13.400 --> 00:20:16.600]   His text messages would not support your statement.
[00:20:16.600 --> 00:20:19.280]   Because he's in professional wrestling mode.
[00:20:19.280 --> 00:20:20.640]   No, I mean, it's private text messages.
[00:20:20.640 --> 00:20:22.520]   So he's doing a whole cogan at this point.
[00:20:22.520 --> 00:20:23.720]   Yeah.
[00:20:23.720 --> 00:20:26.000]   Privately and publicly, he makes the same kinds of statements.
[00:20:26.000 --> 00:20:30.560]   I know several people that are relatively close to him
[00:20:30.560 --> 00:20:32.280]   and other companies, they know what he's built.
[00:20:32.280 --> 00:20:36.040]   You don't return rocket boosters synchronized--
[00:20:36.040 --> 00:20:36.760]   That's pretty impressive.
[00:20:36.760 --> 00:20:37.680]   --back to Earth.
[00:20:37.680 --> 00:20:38.080]   I agree.
[00:20:38.080 --> 00:20:39.960]   But being surrounded by Yes-Men, you just don't.
[00:20:39.960 --> 00:20:40.920]   But that's the conundrum.
[00:20:40.920 --> 00:20:42.080]   That is not a thing that happens.
[00:20:42.080 --> 00:20:44.000]   It's the conundrum about Elon is there
[00:20:44.000 --> 00:20:46.640]   is this amazing track record.
[00:20:46.640 --> 00:20:48.400]   And I really loved the manifesto he
[00:20:48.400 --> 00:20:51.120]   wrote for Tesla way back in the day.
[00:20:51.120 --> 00:20:52.600]   And it's very impressive.
[00:20:52.600 --> 00:20:57.440]   But then there's this other guy, the guy we see on Twitter.
[00:20:57.440 --> 00:20:59.440]   And it's like a different person.
[00:20:59.440 --> 00:21:02.960]   It's like a guy who's used too much acid and is confused
[00:21:02.960 --> 00:21:05.640]   and seems to believe his own story.
[00:21:05.640 --> 00:21:08.000]   And it is possible, isn't it, Phil,
[00:21:08.000 --> 00:21:10.960]   that he's changed a little bit since--
[00:21:10.960 --> 00:21:11.600]   It's possible.
[00:21:11.600 --> 00:21:12.600]   I don't know.
[00:21:12.600 --> 00:21:13.080]   It's possible.
[00:21:13.080 --> 00:21:13.480]   Yeah, I don't know.
[00:21:13.480 --> 00:21:14.440]   It's obviously possible.
[00:21:14.440 --> 00:21:16.520]   But it's also possible that it's going to be fine.
[00:21:16.520 --> 00:21:17.600]   Yeah, I would--
[00:21:17.600 --> 00:21:19.760]   I want it to be fine because I'll tell you one thing.
[00:21:19.760 --> 00:21:20.960]   And I think everybody agrees.
[00:21:20.960 --> 00:21:22.920]   Twitter's important.
[00:21:22.920 --> 00:21:26.440]   And it would be a horrific outcome
[00:21:26.440 --> 00:21:28.760]   if somebody buys it and drives it into the ground.
[00:21:28.760 --> 00:21:30.080]   There's been some speculation.
[00:21:30.080 --> 00:21:31.840]   Wesley Faulkner sent me a tweet--
[00:21:31.840 --> 00:21:33.120]   or I'm sorry, a toot--
[00:21:33.120 --> 00:21:37.520]   saying he thinks that Elon was forced to buy it.
[00:21:37.520 --> 00:21:39.200]   He knew the court was going to go against him.
[00:21:39.200 --> 00:21:40.240]   He was going to buy it.
[00:21:40.240 --> 00:21:42.920]   And what he's trying to do is get out of his debt
[00:21:42.920 --> 00:21:46.240]   by forcing a bankruptcy and a reorganization.
[00:21:46.240 --> 00:21:47.880]   So he doesn't have to pay back the debt.
[00:21:47.880 --> 00:21:52.600]   He's got a very large nut to cover, a $1.3 billion interest
[00:21:52.600 --> 00:21:54.440]   payment alone every year.
[00:21:54.440 --> 00:21:57.520]   So that's a completely out of nowhere theory.
[00:21:57.520 --> 00:22:01.360]   I don't know about finance and the way you do, obviously.
[00:22:01.360 --> 00:22:03.520]   But is it possible that that's what's going on?
[00:22:03.520 --> 00:22:05.680]   That Elon just wants to get out of this?
[00:22:05.680 --> 00:22:08.600]   And this was the only way he thought he could do it?
[00:22:08.600 --> 00:22:11.680]   What's the outcomes for his explanation?
[00:22:11.680 --> 00:22:13.080]   God, I don't think--
[00:22:13.080 --> 00:22:16.880]   That's the simplest solution is always the right one.
[00:22:16.880 --> 00:22:19.000]   But I don't know what the simple solution is.
[00:22:19.000 --> 00:22:22.320]   Here's the scenario that sounds like the Occam's razor to me.
[00:22:22.320 --> 00:22:25.400]   Elon in a jest almost.
[00:22:25.400 --> 00:22:28.920]   And maybe in a fit of peak said, I want to buy it.
[00:22:28.920 --> 00:22:31.400]   And then for 54.20-- the very fact
[00:22:31.400 --> 00:22:35.720]   that it was 54.20 is the price to me implies jest,
[00:22:35.720 --> 00:22:39.760]   the 420 in there is a marijuana reference--
[00:22:39.760 --> 00:22:42.920]   that then somehow--
[00:22:42.920 --> 00:22:45.160]   this is the question, Mark-- how do you get in this?
[00:22:45.160 --> 00:22:47.120]   He made an agreement with Twitter
[00:22:47.120 --> 00:22:49.400]   that he would buy it without due diligence, which
[00:22:49.400 --> 00:22:53.120]   no intelligent business person would ever, ever do.
[00:22:53.120 --> 00:22:55.040]   So I don't know what happened there.
[00:22:55.040 --> 00:22:57.600]   Remember, he bought 9% of it.
[00:22:57.600 --> 00:22:59.640]   And then in January and then in April,
[00:22:59.640 --> 00:23:01.880]   went public with that, wanted a board seat.
[00:23:01.880 --> 00:23:03.720]   Twitter did not want him on the board.
[00:23:03.720 --> 00:23:05.920]   He got thrown off within 24 hours.
[00:23:05.920 --> 00:23:07.600]   And I think that that was what happened.
[00:23:07.600 --> 00:23:08.840]   I don't think he stepped out.
[00:23:08.840 --> 00:23:09.880]   I think he was thrown off.
[00:23:09.880 --> 00:23:13.000]   At that point, he got pissed off.
[00:23:13.000 --> 00:23:16.600]   Is that when he made this bad deal in any event ever since?
[00:23:16.600 --> 00:23:19.600]   Within 24 hours, he was writing to his lawyers saying,
[00:23:19.600 --> 00:23:21.000]   hey, World War III is going to break out.
[00:23:21.000 --> 00:23:22.320]   Can we back down now?
[00:23:22.320 --> 00:23:24.520]   He said, I want to hear what Putin has to say before we
[00:23:24.520 --> 00:23:26.600]   continue the purchase.
[00:23:26.600 --> 00:23:29.040]   Like Putin was going to create World War III,
[00:23:29.040 --> 00:23:30.840]   and maybe we better not own Twitter.
[00:23:30.840 --> 00:23:33.680]   He was trying to squirm.
[00:23:33.680 --> 00:23:34.040]   Right?
[00:23:34.040 --> 00:23:35.040]   He was squirming.
[00:23:35.040 --> 00:23:38.360]   He wanted to get out of it for a long time.
[00:23:38.360 --> 00:23:42.080]   At which point, Brett Taylor, chairman of the Twitter board,
[00:23:42.080 --> 00:23:44.240]   he says, no, we're going to court.
[00:23:44.240 --> 00:23:45.640]   We're going to hold his feet to the fire.
[00:23:45.640 --> 00:23:46.600]   He has an agreement.
[00:23:46.600 --> 00:23:48.520]   We're going to make him agree.
[00:23:48.520 --> 00:23:50.160]   Elon said, no, no, there's bots.
[00:23:50.160 --> 00:23:52.200]   He came up with all sorts of things.
[00:23:52.200 --> 00:23:54.040]   I think we were getting very close the day
[00:23:54.040 --> 00:23:56.600]   before his deposition.
[00:23:56.600 --> 00:24:00.320]   We'd already seen this tranche of personal DMs that were--
[00:24:00.320 --> 00:24:01.800]   not embarrassing to Elon, by the way,
[00:24:01.800 --> 00:24:04.120]   but embarrassing to every single other person who
[00:24:04.120 --> 00:24:06.560]   was DMing him, including Larry Ellison who says,
[00:24:06.560 --> 00:24:07.280]   I'll give you a billion.
[00:24:07.280 --> 00:24:08.360]   And Elon says, can you give me two?
[00:24:08.360 --> 00:24:10.680]   He says, yeah, two, whatever.
[00:24:10.680 --> 00:24:12.080]   He raised the money.
[00:24:12.080 --> 00:24:13.880]   He went through all the steps.
[00:24:13.880 --> 00:24:16.360]   That takes some clout.
[00:24:16.360 --> 00:24:17.520]   That takes some ability.
[00:24:17.520 --> 00:24:19.640]   He negotiated with a Saudi sovereign fund.
[00:24:19.640 --> 00:24:21.640]   He negotiated with Larry Ellison.
[00:24:21.640 --> 00:24:24.040]   He got Goldman Sachs and a bunch of banks
[00:24:24.040 --> 00:24:28.000]   to give him a $13 billion loan, or is it $11 billion,
[00:24:28.000 --> 00:24:30.400]   some huge amount.
[00:24:30.400 --> 00:24:31.800]   But he wants to get out of it.
[00:24:31.800 --> 00:24:35.720]   I think on the day before he's supposed to give his deposition,
[00:24:35.720 --> 00:24:38.680]   somebody told him, maybe Spiro, his personal counsel,
[00:24:38.680 --> 00:24:40.800]   said, you're going to have to buy this.
[00:24:40.800 --> 00:24:41.840]   It's going to go against you.
[00:24:41.840 --> 00:24:43.040]   The court is pretty clear.
[00:24:43.040 --> 00:24:44.640]   The Delaware Court of Chancery is going
[00:24:44.640 --> 00:24:46.960]   to make you buy this for $44 billion.
[00:24:46.960 --> 00:24:49.600]   Because at that point, he says, all right, I don't want to go
[00:24:49.600 --> 00:24:49.960]   to court.
[00:24:49.960 --> 00:24:50.880]   I don't want this deposition.
[00:24:50.880 --> 00:24:53.360]   I don't want any more DMs revealed.
[00:24:53.360 --> 00:24:55.000]   I'll buy it.
[00:24:55.000 --> 00:24:56.640]   All of that-- is that inaccurate, Phil?
[00:24:56.640 --> 00:24:58.240]   That timeline?
[00:24:58.240 --> 00:25:00.920]   That seems like that's pretty much what happened.
[00:25:00.920 --> 00:25:01.840]   Yeah?
[00:25:01.840 --> 00:25:06.400]   Well, first of all, I own CourtofChancery.com, a URL.
[00:25:06.400 --> 00:25:08.400]   You do?
[00:25:08.400 --> 00:25:09.400]   Yeah.
[00:25:09.400 --> 00:25:10.400]   That's a good domain.
[00:25:10.400 --> 00:25:11.560]   Wouldn't you buy that?
[00:25:11.560 --> 00:25:12.160]   It's for sale.
[00:25:12.160 --> 00:25:14.880]   I think on the day, I think when Brett tweeted,
[00:25:14.880 --> 00:25:17.880]   I'll see you at the Delaware Court of Chancery.
[00:25:17.880 --> 00:25:19.040]   Smooth move.
[00:25:19.040 --> 00:25:21.000]   So yeah, best offer accepted.
[00:25:21.000 --> 00:25:22.520]   That's as good as three--
[00:25:22.520 --> 00:25:23.720]   as good as three feet.
[00:25:23.720 --> 00:25:24.560]   Yeah.
[00:25:24.560 --> 00:25:28.040]   But look, sure.
[00:25:28.040 --> 00:25:31.840]   I mean, some version of that probably happened.
[00:25:31.840 --> 00:25:36.080]   But I think there's a different Occam's razor way
[00:25:36.080 --> 00:25:36.840]   to look at this, right?
[00:25:36.840 --> 00:25:37.920]   The simplest explanation.
[00:25:37.920 --> 00:25:39.720]   What's the simplest explanation?
[00:25:39.720 --> 00:25:43.360]   Like Elon's kind of being obnoxious on Twitter
[00:25:43.360 --> 00:25:45.920]   because that's what one does on Twitter.
[00:25:45.920 --> 00:25:48.200]   And that's what people are rewarded for on Twitter.
[00:25:48.200 --> 00:25:49.720]   And that's the point of Twitter.
[00:25:49.720 --> 00:25:55.640]   And he kind of has that as part of his personality traits.
[00:25:55.640 --> 00:25:57.200]   I'm sure you guys are right.
[00:25:57.200 --> 00:25:59.400]   And he probably underestimated some of the complexity.
[00:25:59.400 --> 00:26:00.840]   Probably came in there thinking, I
[00:26:00.840 --> 00:26:04.600]   build rockets that can land vertically back on Earth.
[00:26:04.600 --> 00:26:05.400]   Like, how hard could it be?
[00:26:05.400 --> 00:26:06.960]   And I'm sure he underestimated it.
[00:26:06.960 --> 00:26:08.920]   And he pissed a bunch of people off.
[00:26:08.920 --> 00:26:11.520]   And a bunch of people quit and a bunch more people quit.
[00:26:11.520 --> 00:26:12.400]   That all makes sense.
[00:26:12.400 --> 00:26:14.120]   But at the end of the day, he really
[00:26:14.120 --> 00:26:16.960]   did build these rockets that land back on Earth.
[00:26:16.960 --> 00:26:19.160]   And he really did build the car that I drive right now, which
[00:26:19.160 --> 00:26:21.040]   is the best car that I've ever owned.
[00:26:21.040 --> 00:26:25.600]   And Twitter, like, yeah, it's more complicated than he thought.
[00:26:25.600 --> 00:26:27.080]   But it's less complicated than the stuff
[00:26:27.080 --> 00:26:29.000]   that he's done before.
[00:26:29.000 --> 00:26:31.120]   And I think there's a very strong chance
[00:26:31.120 --> 00:26:34.040]   that, again, with way more drama than I would have wanted to see,
[00:26:34.040 --> 00:26:35.520]   it's going to turn out OK.
[00:26:35.520 --> 00:26:37.720]   And if you can actually do some of the things that you start
[00:26:37.720 --> 00:26:39.360]   about it-- and of course, there's going to be outages.
[00:26:39.360 --> 00:26:40.200]   There will be failures.
[00:26:40.200 --> 00:26:40.800]   There will be outages.
[00:26:40.800 --> 00:26:42.040]   But we all remember the fail-well.
[00:26:42.040 --> 00:26:43.000]   We have to fail well.
[00:26:43.000 --> 00:26:43.760]   We can live.
[00:26:43.760 --> 00:26:44.320]   We can survive.
[00:26:44.320 --> 00:26:47.360]   So, like, yeah, it'll be outages.
[00:26:47.360 --> 00:26:49.320]   And I think, again, I'm not guaranteeing this.
[00:26:49.320 --> 00:26:49.880]   I don't know.
[00:26:49.880 --> 00:26:52.280]   And I don't predict the future.
[00:26:52.280 --> 00:26:55.680]   I think there's a very strong chance that, within a few months,
[00:26:55.680 --> 00:26:58.200]   it's going to be better than it was a few months ago.
[00:26:58.200 --> 00:26:59.880]   And it'll be fine.
[00:26:59.880 --> 00:27:01.160]   And that's kind of what I'm counting for,
[00:27:01.160 --> 00:27:03.400]   because I would try and mess it up.
[00:27:03.400 --> 00:27:05.360]   But I can deal with another elephant app right now.
[00:27:05.360 --> 00:27:05.640]   So--
[00:27:05.640 --> 00:27:06.760]   [LAUGHTER]
[00:27:06.760 --> 00:27:09.200]   --he'd put it in the market.
[00:27:09.200 --> 00:27:10.880]   You know, by the way, I love this.
[00:27:10.880 --> 00:27:12.240]   You're talking about Mastodon.
[00:27:12.240 --> 00:27:14.880]   I love the fact that some people have left Twitter
[00:27:14.880 --> 00:27:16.200]   for the Fediverse.
[00:27:16.200 --> 00:27:18.680]   Mastodon is just one instance, but the Fediverse.
[00:27:18.680 --> 00:27:22.200]   And those people are a certain kind of geeky,
[00:27:22.200 --> 00:27:25.960]   tend to be liberals, tend to be left-wing.
[00:27:25.960 --> 00:27:26.960]   And they're finding a home.
[00:27:26.960 --> 00:27:28.320]   And that's fine.
[00:27:28.320 --> 00:27:29.600]   And I would love to see Twitter.
[00:27:29.600 --> 00:27:30.560]   I think you're right, Phil.
[00:27:30.560 --> 00:27:32.760]   I think he will find a way to make this work.
[00:27:32.760 --> 00:27:35.520]   He spent way too much money.
[00:27:35.520 --> 00:27:37.400]   And so he'll find a way to make this work.
[00:27:37.400 --> 00:27:41.200]   And there have to be good engineers out there he could bring in.
[00:27:41.200 --> 00:27:46.080]   There may be a learning curve for them as well as him.
[00:27:46.080 --> 00:27:47.880]   Twitter's so important.
[00:27:47.880 --> 00:27:51.440]   My problem is that the hardest thing about Twitter
[00:27:51.440 --> 00:27:54.560]   is something, by the way, that they never really solved.
[00:27:54.560 --> 00:27:57.600]   Forget monetization, because advertisers are already going.
[00:27:57.600 --> 00:27:58.840]   I don't want to even do with this.
[00:27:58.840 --> 00:28:00.960]   CBS came back, though, which is weird.
[00:28:00.960 --> 00:28:01.480]   Not as an average--
[00:28:01.480 --> 00:28:04.000]   They said they were gone from much of the weekend.
[00:28:04.000 --> 00:28:06.000]   Yeah, it's just like weird.
[00:28:06.000 --> 00:28:07.240]   That's like much of the weekend.
[00:28:07.240 --> 00:28:09.720]   That was a strange thing.
[00:28:09.720 --> 00:28:11.040]   I took a nap for much of the weekend.
[00:28:11.040 --> 00:28:11.560]   I know.
[00:28:11.560 --> 00:28:12.040]   I know.
[00:28:12.040 --> 00:28:13.320]   It was really weird.
[00:28:13.320 --> 00:28:14.360]   Oh, no, we're back.
[00:28:14.360 --> 00:28:16.240]   But advertisers, by the way, are not doing that.
[00:28:16.240 --> 00:28:21.040]   I have to say advertisers are leaving the tech sector everywhere.
[00:28:21.040 --> 00:28:24.120]   So that's-- I mean, we can't sell podcast advertising
[00:28:24.120 --> 00:28:26.040]   and save our life in 2023.
[00:28:26.040 --> 00:28:29.640]   So that's not just Twitter's problem.
[00:28:29.640 --> 00:28:31.240]   But that's also not my problem.
[00:28:31.240 --> 00:28:33.600]   Because Elon will figure out how to monetize or not.
[00:28:33.600 --> 00:28:35.000]   But he'll figure that out.
[00:28:35.000 --> 00:28:37.760]   I worry more about the moderation problem.
[00:28:37.760 --> 00:28:44.520]   And what is that old saw-- you probably know this, Glenn,
[00:28:44.520 --> 00:28:46.720]   where you let one Nazi into your bar, and then
[00:28:46.720 --> 00:28:48.640]   pretty soon you own a Nazi bar.
[00:28:48.640 --> 00:28:50.280]   There's somebody-- yeah, there's a bartender who
[00:28:50.280 --> 00:28:52.600]   told a good story about that on Twitter about right.
[00:28:52.600 --> 00:28:55.120]   It was like the first one comes in, and they seem--
[00:28:55.120 --> 00:28:56.920]   they're there by themselves, and they
[00:28:56.920 --> 00:28:58.080]   don't make much of a fuss.
[00:28:58.080 --> 00:29:00.720]   And if you don't throw that guy out,
[00:29:00.720 --> 00:29:01.960]   then pretty soon you're a Nazi bar.
[00:29:01.960 --> 00:29:04.160]   It's like an inevitable-- I mean, this
[00:29:04.160 --> 00:29:08.560]   is all the tolerant being overwhelmed by the intolerant.
[00:29:08.560 --> 00:29:10.240]   There's a whole political philosophy
[00:29:10.240 --> 00:29:13.240]   about how we should not-- or an argument.
[00:29:13.240 --> 00:29:16.120]   I don't want to say it hasn't been decided, right?
[00:29:16.120 --> 00:29:17.760]   This is all the societal issue.
[00:29:17.760 --> 00:29:20.360]   Is it better to let people talk and let sunshine in,
[00:29:20.360 --> 00:29:23.200]   or to moderate, suppress, do other things outside
[00:29:23.200 --> 00:29:26.240]   of governmental approaches, not government censorship,
[00:29:26.240 --> 00:29:29.880]   to prevent points of view that crowd out other speech?
[00:29:29.880 --> 00:29:33.280]   This is always the battle we have is free speech when people
[00:29:33.280 --> 00:29:36.120]   who are free speech so-called maximalists talk about it.
[00:29:36.120 --> 00:29:38.480]   They talk about everyone being able to speak freely,
[00:29:38.480 --> 00:29:41.240]   and yet some speech crowds out other speech,
[00:29:41.240 --> 00:29:43.000]   and there's no balance in that power.
[00:29:43.000 --> 00:29:45.400]   So I think that's the Nazi bar scenario,
[00:29:45.400 --> 00:29:47.680]   is like if you let too many Nazis on a Twitter--
[00:29:47.680 --> 00:29:49.680]   and this is the thing.
[00:29:49.680 --> 00:29:54.520]   I think on suspending Kathy Griffin and Donald Trump
[00:29:54.520 --> 00:29:56.800]   and Jordan Peterson and a few other people,
[00:29:56.800 --> 00:29:58.960]   all at once is actually sort of a master stroke.
[00:29:58.960 --> 00:30:01.000]   If he had just done people who are right-wing figures
[00:30:01.000 --> 00:30:04.080]   or people in a certain cultural matrix,
[00:30:04.080 --> 00:30:06.040]   but he'll let Kathy Griffin back on,
[00:30:06.040 --> 00:30:08.160]   and she's over masted on saying, no, thank you.
[00:30:08.160 --> 00:30:09.960]   I'm not even going to pay attention to that.
[00:30:09.960 --> 00:30:11.680]   That's a whole different argument
[00:30:11.680 --> 00:30:13.120]   about what he's trying to chart.
[00:30:13.120 --> 00:30:16.200]   Yeah, I think the Kathy Griffin was a throw-in
[00:30:16.200 --> 00:30:19.760]   because everybody else cat-turd and the bumblebee--
[00:30:19.760 --> 00:30:20.760]   Cat-turd.
[00:30:20.760 --> 00:30:24.360]   Cat-turd, bumblebee and Donald Trump, the big three.
[00:30:24.360 --> 00:30:26.880]   Those are all on the right-hand side of the aisle.
[00:30:26.880 --> 00:30:29.000]   I think that that is not Elon--
[00:30:29.000 --> 00:30:30.800]   Elon's, I'm sure, not a right-winger.
[00:30:30.800 --> 00:30:33.920]   He's probably a libertarian.
[00:30:33.920 --> 00:30:37.160]   And probably wants the free speech thing.
[00:30:37.160 --> 00:30:38.480]   He likes that idea.
[00:30:38.480 --> 00:30:43.400]   But as he's quickly learning, free speech doesn't sell ads.
[00:30:43.400 --> 00:30:45.880]   And it's a Nazi bar problem because--
[00:30:45.880 --> 00:30:47.720]   It doesn't comply to national law.
[00:30:47.720 --> 00:30:51.120]   They're going to have CSAM problems immediately.
[00:30:51.120 --> 00:30:53.520]   This is unless they have the staff in place--
[00:30:53.520 --> 00:30:54.480]   You can still watch--
[00:30:54.480 --> 00:30:55.480]   --so much--
[00:30:55.480 --> 00:30:58.160]   --speed, I'm told, on Twitter.
[00:30:58.160 --> 00:30:59.080]   Tweet by tweet.
[00:30:59.080 --> 00:31:00.560]   You only get a few minutes per tweet.
[00:31:00.560 --> 00:31:01.800]   But you could still do that.
[00:31:01.800 --> 00:31:02.760]   And they haven't taken that.
[00:31:02.760 --> 00:31:05.120]   So they're going to have a big moderation problem.
[00:31:05.120 --> 00:31:09.200]   Now, maybe he's going to bring in 1,000 new moderators.
[00:31:09.200 --> 00:31:10.000]   It just takes one while--
[00:31:10.000 --> 00:31:11.000]   --a good AI.
[00:31:11.000 --> 00:31:11.960]   --takes a while to do that.
[00:31:11.960 --> 00:31:14.080]   And at that point, let's say it takes them a year,
[00:31:14.080 --> 00:31:16.680]   which is a reasonable amount of time.
[00:31:16.680 --> 00:31:19.760]   Who's going to be left and who's going to want to be part of it?
[00:31:19.760 --> 00:31:23.040]   Look, I think how much of the problems of the speech problems
[00:31:23.040 --> 00:31:27.680]   in Twitter right now would have existed a few weeks ago,
[00:31:27.680 --> 00:31:31.560]   would have existed pre-Elon if the people who are making
[00:31:31.560 --> 00:31:34.560]   the problems were all incented to right now go and do the stuff
[00:31:34.560 --> 00:31:35.880]   that they're doing.
[00:31:35.880 --> 00:31:38.440]   You're kind of having two things happen.
[00:31:38.440 --> 00:31:40.560]   The first thing that happened is Elon took over.
[00:31:40.560 --> 00:31:43.560]   And now, every Nazi or anything else,
[00:31:43.560 --> 00:31:44.360]   this is the time.
[00:31:44.360 --> 00:31:47.480]   This is like, ah, this is my moment.
[00:31:47.480 --> 00:31:49.360]   Now is when I'm going to do this.
[00:31:49.360 --> 00:31:51.760]   Whereas before, their activity was spread out
[00:31:51.760 --> 00:31:52.760]   over the course of many years.
[00:31:52.760 --> 00:31:56.080]   Now, everyone in the same week is going to be like, yeah,
[00:31:56.080 --> 00:31:57.760]   I'm going to make fake corporate accounts,
[00:31:57.760 --> 00:31:59.720]   and I'm going to upload the movie Speed,
[00:31:59.720 --> 00:32:01.680]   and I'm going to be a Nazi, because that's
[00:32:01.680 --> 00:32:02.560]   where all the attention is.
[00:32:02.560 --> 00:32:04.720]   Because then CNN is breathlessly reporting
[00:32:04.720 --> 00:32:07.040]   about how Twitter is falling apart.
[00:32:07.040 --> 00:32:09.240]   If you were going to do on Twitter,
[00:32:09.240 --> 00:32:10.840]   you would want to do it last week.
[00:32:10.840 --> 00:32:14.120]   Because the time of Sauron is on you.
[00:32:14.120 --> 00:32:17.360]   So even if Elon had changed nothing,
[00:32:17.360 --> 00:32:19.600]   and it was literally the same exact code base, which
[00:32:19.600 --> 00:32:21.680]   I think mostly still is, there's obviously
[00:32:21.680 --> 00:32:24.040]   some changes, you still probably would have
[00:32:24.040 --> 00:32:26.200]   had the same problems.
[00:32:26.200 --> 00:32:29.960]   So your question really kind of decouples into two parts.
[00:32:29.960 --> 00:32:31.120]   You said, what if it takes them a year?
[00:32:31.120 --> 00:32:32.680]   It decouples into two parts.
[00:32:32.680 --> 00:32:34.880]   How long does it take for it to get incrementally better
[00:32:34.880 --> 00:32:35.920]   than it used to be?
[00:32:35.920 --> 00:32:37.840]   And I think every couple of weeks,
[00:32:37.840 --> 00:32:39.520]   it can get incrementally better.
[00:32:39.520 --> 00:32:43.080]   And at the same time, how long does the moment
[00:32:43.080 --> 00:32:44.560]   for the Nazis stick around?
[00:32:44.560 --> 00:32:45.880]   Because they're going to lose their interest.
[00:32:45.880 --> 00:32:48.940]   They're not going to keep up this intensity of douche
[00:32:48.940 --> 00:32:50.480]   baggery for the next year.
[00:32:50.480 --> 00:32:51.560]   Well, like, hey, I might--
[00:32:51.560 --> 00:32:52.520]   It's going to slow down.
[00:32:52.520 --> 00:32:53.520]   I might argue with that.
[00:32:53.520 --> 00:32:57.840]   Because we have fans who have never given up
[00:32:57.840 --> 00:33:01.200]   after five years of trolling us.
[00:33:01.200 --> 00:33:01.680]   Of course.
[00:33:01.680 --> 00:33:04.840]   The people who are into this are very persistent
[00:33:04.840 --> 00:33:08.680]   and do not give up because they're nuts.
[00:33:08.680 --> 00:33:13.280]   But the people like posting movies and like that kind
[00:33:13.280 --> 00:33:13.760]   of stuff.
[00:33:13.760 --> 00:33:14.640]   There's a lot of like--
[00:33:14.640 --> 00:33:16.080]   Those people go away, of course.
[00:33:16.080 --> 00:33:16.920]   But that's most of them.
[00:33:16.920 --> 00:33:18.680]   That's trolls.
[00:33:18.680 --> 00:33:19.800]   I don't know if that's most of them.
[00:33:19.800 --> 00:33:21.560]   I mean, who's on truth social?
[00:33:21.560 --> 00:33:23.040]   I don't know if that's most of them.
[00:33:23.040 --> 00:33:27.600]   There is a large contingent of Americans, about half,
[00:33:27.600 --> 00:33:32.200]   who are filled with hate.
[00:33:32.200 --> 00:33:34.400]   You know, one filling half of hate.
[00:33:34.400 --> 00:33:35.400]   Yeah, I think half.
[00:33:35.400 --> 00:33:37.360]   Yeah, I think half.
[00:33:37.360 --> 00:33:43.560]   Phil, you talk about, well, he has put rockets in space
[00:33:43.560 --> 00:33:46.680]   and revolutionized the electric car company.
[00:33:46.680 --> 00:33:49.040]   But rockets and cars are not media.
[00:33:49.040 --> 00:33:53.560]   And media is a lot harder than it looks.
[00:33:53.560 --> 00:33:55.800]   And Twitter is media.
[00:33:55.800 --> 00:33:59.000]   And Leo's right about the moderation problem.
[00:33:59.000 --> 00:34:00.920]   Those trolls do not go away.
[00:34:00.920 --> 00:34:01.800]   Look at 4chan.
[00:34:01.800 --> 00:34:02.640]   Look at 8chan.
[00:34:02.640 --> 00:34:03.360]   Right.
[00:34:03.360 --> 00:34:04.360]   Right.
[00:34:04.360 --> 00:34:11.320]   And so I think Elon has two personality failings
[00:34:11.320 --> 00:34:14.200]   that he's always had.
[00:34:14.200 --> 00:34:18.520]   And they come into this situation
[00:34:18.520 --> 00:34:19.800]   and kind of have bloomed.
[00:34:19.800 --> 00:34:21.640]   One of them is hubris.
[00:34:21.640 --> 00:34:28.080]   And the other is he really believes he huffs his own smoke.
[00:34:28.080 --> 00:34:30.480]   And he really believes that he knows better than anybody
[00:34:30.480 --> 00:34:31.760]   around him.
[00:34:31.760 --> 00:34:35.680]   And so he tears it up and then is kind of surprised
[00:34:35.680 --> 00:34:39.000]   at the mess he's made and calls them back.
[00:34:39.000 --> 00:34:43.400]   He essentially kind of doesn't know what he's doing
[00:34:43.400 --> 00:34:44.800]   and is now winging it.
[00:34:44.800 --> 00:34:46.960]   And he may indeed be able to bring it back.
[00:34:46.960 --> 00:34:50.120]   So supposedly he's got this plan
[00:34:50.120 --> 00:34:56.720]   to create a kind of Uber app, x.com.
[00:34:56.720 --> 00:35:00.640]   So essentially, what he may be thinking as well,
[00:35:00.640 --> 00:35:02.200]   before you can create something, you
[00:35:02.200 --> 00:35:03.160]   have to destroy it.
[00:35:03.160 --> 00:35:05.440]   And that's kind of what he's doing.
[00:35:05.440 --> 00:35:08.000]   But it didn't have to be that way.
[00:35:08.000 --> 00:35:09.920]   He's ruined lives.
[00:35:09.920 --> 00:35:14.120]   And he has crippled careers.
[00:35:14.120 --> 00:35:16.200]   A lot of these people are going out into a market
[00:35:16.200 --> 00:35:19.760]   where tech companies are laying off, not hiring.
[00:35:19.760 --> 00:35:22.800]   And so it didn't have to be done this way.
[00:35:22.800 --> 00:35:27.720]   I saw a headline that referred to his brutal management style.
[00:35:27.720 --> 00:35:30.840]   And I think that that's the problem.
[00:35:30.840 --> 00:35:33.320]   The question becomes if you're a Twitter user,
[00:35:33.320 --> 00:35:36.880]   if you're a Twitter investor, if you're a regulator,
[00:35:36.880 --> 00:35:39.120]   does the In justify the means?
[00:35:39.120 --> 00:35:42.480]   And Demi, it sure doesn't.
[00:35:42.480 --> 00:35:45.480]   I agree that it didn't have to do it like this.
[00:35:45.480 --> 00:35:47.360]   I think he would probably agree with you at this point
[00:35:47.360 --> 00:35:49.520]   that he didn't have to do it like this.
[00:35:49.520 --> 00:35:53.880]   Yeah, much more drama than I would have wanted to see.
[00:35:53.880 --> 00:35:57.720]   But a separate question from is it really time
[00:35:57.720 --> 00:35:59.560]   to write the Twitter biciaries?
[00:35:59.560 --> 00:36:01.640]   I very much doubt that it's time to write the Twitter.
[00:36:01.640 --> 00:36:02.400]   I think you could--
[00:36:02.400 --> 00:36:03.680]   I think it felt like the Twitter--
[00:36:03.680 --> 00:36:04.680]   --it's a big on Friday night.
[00:36:04.680 --> 00:36:06.080]   I got to say everybody was--
[00:36:06.080 --> 00:36:07.120]   --with saying goodbye.
[00:36:07.120 --> 00:36:08.120]   --by little squeeze.
[00:36:08.120 --> 00:36:14.640]   And it was wildly entertaining and both bittersweet
[00:36:14.640 --> 00:36:15.520]   at the same time.
[00:36:15.520 --> 00:36:18.600]   I can't remember an evening on Twitter
[00:36:18.600 --> 00:36:21.440]   that I think was that affecting.
[00:36:21.440 --> 00:36:25.960]   And you saw Ryan Broderick and Katie Nonopolis from Buzzfeed.
[00:36:25.960 --> 00:36:27.960]   They started Twitter-- what is it called?
[00:36:27.960 --> 00:36:29.320]   Social Spaces?
[00:36:29.320 --> 00:36:30.880]   That was a weird event.
[00:36:30.880 --> 00:36:32.760]   With like 20,000 people.
[00:36:32.760 --> 00:36:35.320]   So in the middle of it was fascinating to say,
[00:36:35.320 --> 00:36:37.720]   Twitter's dying, but here's 20,000 people
[00:36:37.720 --> 00:36:39.640]   who want to join a Twitter thing.
[00:36:39.640 --> 00:36:41.440]   And it mostly ran OK.
[00:36:41.440 --> 00:36:43.760]   And I tuned it for, I don't know, 20 or 30 minutes.
[00:36:43.760 --> 00:36:45.560]   And it was wild.
[00:36:45.560 --> 00:36:48.120]   It was actually an example of the best of what Twitter
[00:36:48.120 --> 00:36:48.800]   has to offer.
[00:36:48.800 --> 00:36:51.960]   And Elon pointed out they had the biggest weekend of all time.
[00:36:51.960 --> 00:36:53.160]   I'm not surprised.
[00:36:53.160 --> 00:36:54.000]   Everybody feels a little--
[00:36:54.000 --> 00:36:55.320]   I know, but that's a rubber necking.
[00:36:55.320 --> 00:36:55.840]   That's right.
[00:36:55.840 --> 00:36:56.760]   That's rubber necking.
[00:36:56.760 --> 00:36:58.360]   That's watching a car crash.
[00:36:58.360 --> 00:36:58.860]   Yeah.
[00:36:58.860 --> 00:37:00.160]   I mean, people feeling like they're going to.
[00:37:00.160 --> 00:37:02.200]   It's like, why do you go to the speed way?
[00:37:02.200 --> 00:37:04.480]   People often go to the speed way to watch cars crash.
[00:37:04.480 --> 00:37:05.840]   I'm really glad we had John Phil,
[00:37:05.840 --> 00:37:08.400]   because I knew that you would be the sense of the voice of reason
[00:37:08.400 --> 00:37:09.400]   in all of this.
[00:37:09.400 --> 00:37:11.000]   And with your experience and expertise,
[00:37:11.000 --> 00:37:12.600]   I wanted to hear what you think.
[00:37:12.600 --> 00:37:15.760]   And you're not an Elon Musk stand.
[00:37:15.760 --> 00:37:18.200]   But I think you're quite reasonable in this.
[00:37:18.200 --> 00:37:20.920]   And I hope you're right, because I'd
[00:37:20.920 --> 00:37:22.840]   hate to see Twitter just turn into 4chan.
[00:37:22.840 --> 00:37:25.720]   I think that that would be a very sad end to something
[00:37:25.720 --> 00:37:28.400]   that was so vital for so many people.
[00:37:28.400 --> 00:37:30.720]   One of the things you were seeing on Saturday and Friday
[00:37:30.720 --> 00:37:34.960]   was people saying, I met my spouse here.
[00:37:34.960 --> 00:37:38.520]   Some of the best interactions I ever had in my life on Twitter.
[00:37:38.520 --> 00:37:40.600]   And some of the most hateful interactions
[00:37:40.600 --> 00:37:42.680]   I've ever had in my life around Twitter as well.
[00:37:42.680 --> 00:37:46.000]   But Twitter is important.
[00:37:46.000 --> 00:37:46.960]   And it'd be a shame to lose it.
[00:37:46.960 --> 00:37:48.840]   I feel more that way about Twitter
[00:37:48.840 --> 00:37:50.280]   than I do about Facebook, for instance,
[00:37:50.280 --> 00:37:52.440]   which I don't think will be a huge loss.
[00:37:52.440 --> 00:37:52.960]   You know?
[00:37:52.960 --> 00:37:54.640]   I wouldn't be sitting here talking to the three of you
[00:37:54.640 --> 00:37:55.440]   if it wasn't for Twitter.
[00:37:55.440 --> 00:37:56.000]   Exactly.
[00:37:56.000 --> 00:37:56.800]   That's how we got to know you.
[00:37:56.800 --> 00:37:57.280]   Exactly.
[00:37:57.280 --> 00:37:59.240]   We're all special friends.
[00:37:59.240 --> 00:37:59.520]   Yes.
[00:37:59.520 --> 00:37:59.960]   Yeah.
[00:37:59.960 --> 00:38:01.760]   Most of the best things have happened my professional life.
[00:38:01.760 --> 00:38:04.840]   And many of my personal life happened in the last decade
[00:38:04.840 --> 00:38:05.320]   on Twitter.
[00:38:05.320 --> 00:38:07.480]   I've been able to change my career from being
[00:38:07.480 --> 00:38:10.440]   a technology journalist into a 19th century printing
[00:38:10.440 --> 00:38:12.560]   expert in part because of Twitter.
[00:38:12.560 --> 00:38:14.000]   So thank you for all your--
[00:38:14.000 --> 00:38:14.520]   For all your--
[00:38:14.520 --> 00:38:16.760]   For sure that's a career direction I would recommend for--
[00:38:16.760 --> 00:38:18.120]   No, there's lots of-- let me tell you,
[00:38:18.120 --> 00:38:21.960]   there's lots of money and 19th century printing reasons.
[00:38:21.960 --> 00:38:24.480]   But Phil, I think your points are really well taken.
[00:38:24.480 --> 00:38:26.600]   And you're the voice of reason.
[00:38:26.600 --> 00:38:27.520]   So thank you.
[00:38:27.520 --> 00:38:30.240]   It is true that it's no surprise that there's
[00:38:30.240 --> 00:38:36.200]   a lot of outrage and storm and drawing associated with Twitter.
[00:38:36.200 --> 00:38:38.120]   That's what it was designed.
[00:38:38.120 --> 00:38:39.640]   Phil, I want to hire you as my therapist
[00:38:39.640 --> 00:38:40.640]   because you've totally--
[00:38:40.640 --> 00:38:41.640]   I feel much better.
[00:38:41.640 --> 00:38:44.440]   I mean, I'll say I've run businesses in which I've had
[00:38:44.440 --> 00:38:46.080]   at least one employee.
[00:38:46.080 --> 00:38:49.640]   So I feel very qualified to talk about an enterprise with 7,500.
[00:38:49.640 --> 00:38:51.440]   So I feel you're in a better position.
[00:38:51.440 --> 00:38:53.040]   But it's also-- I think it's good.
[00:38:53.040 --> 00:38:54.480]   It's very easy.
[00:38:54.480 --> 00:38:57.720]   I think what we're talking about is an excellent example
[00:38:57.720 --> 00:39:00.080]   of that phenomenon you're describing, which is Twitter
[00:39:00.080 --> 00:39:01.160]   is about drama.
[00:39:01.160 --> 00:39:02.880]   It's optimized for drama because it
[00:39:02.880 --> 00:39:05.720]   is optimized for engagement, which improves advertising
[00:39:05.720 --> 00:39:08.920]   itself through if it's not too horrible.
[00:39:08.920 --> 00:39:10.480]   Advertisers don't want to sell against horror,
[00:39:10.480 --> 00:39:13.360]   but they want to sell against a certain level of churn.
[00:39:13.360 --> 00:39:15.840]   And so I feel drawn into that because I'm watching.
[00:39:15.840 --> 00:39:16.840]   Every day, there's nonsense.
[00:39:16.840 --> 00:39:18.640]   People will be like, chaos.
[00:39:18.640 --> 00:39:20.400]   And I'm like, oh, but I can listen to Phil.
[00:39:20.400 --> 00:39:21.800]   And I can step back and say, you know,
[00:39:21.800 --> 00:39:23.480]   this is going to settle out or it's not.
[00:39:23.480 --> 00:39:26.760]   And I don't have to get all fussed about it.
[00:39:26.760 --> 00:39:28.640]   So I actually appreciate that very much.
[00:39:28.640 --> 00:39:29.160]   Thank you.
[00:39:29.160 --> 00:39:30.280]   We're going to take a little break
[00:39:30.280 --> 00:39:33.440]   and talk about something of much more consequence.
[00:39:33.440 --> 00:39:35.840]   Crypto in just a minute.
[00:39:35.840 --> 00:39:36.520]   Just kidding.
[00:39:36.520 --> 00:39:37.640]   We'll find something.
[00:39:37.640 --> 00:39:39.760]   We'll cheer you up in just a bit.
[00:39:39.760 --> 00:39:40.920]   Great to have Phil Liben here.
[00:39:40.920 --> 00:39:42.520]   Actually, I want to talk a little bit
[00:39:42.520 --> 00:39:44.640]   about the history of Evernote.
[00:39:44.640 --> 00:39:47.480]   CEO and founder of allturtles.com.
[00:39:47.480 --> 00:39:51.280]   But in his previous life, he was the guy who put Evernote
[00:39:51.280 --> 00:39:52.480]   on the map.
[00:39:52.480 --> 00:39:55.040]   And Evernote is in the news again this week.
[00:39:55.040 --> 00:39:56.520]   We'll talk about that in a little bit.
[00:39:56.520 --> 00:40:00.680]   Glenn Fleischman, he's in charge of fun at Glenn.fun.
[00:40:00.680 --> 00:40:03.320]   And fun and flongs is his motto.
[00:40:03.320 --> 00:40:04.880]   Fun and flongs, there we go.
[00:40:04.880 --> 00:40:07.280]   And always a pleasure having you.
[00:40:07.280 --> 00:40:09.960]   And of course, like great friend Dwight Silverman.
[00:40:09.960 --> 00:40:13.680]   Authoriy, A-U-T-H-O-R-Y.com/d-Silverman.
[00:40:13.680 --> 00:40:17.520]   Both Glenn and Dwight use Authoriy to collate all
[00:40:17.520 --> 00:40:23.000]   of their many multifarious work, which is really cool.
[00:40:23.000 --> 00:40:24.640]   I didn't realize you also used it.
[00:40:24.640 --> 00:40:28.360]   And it actually solves a problem that people like you,
[00:40:28.360 --> 00:40:32.880]   modern journalists have, which is you're everywhere.
[00:40:32.880 --> 00:40:33.920]   We're talking about--
[00:40:33.920 --> 00:40:35.040]   We're talking about--
[00:40:35.040 --> 00:40:36.040]   Yeah, we've got abouts.
[00:40:36.040 --> 00:40:36.600]   We've got abouts.
[00:40:36.600 --> 00:40:38.560]   A piece of irony is that I wrote my first article
[00:40:38.560 --> 00:40:40.360]   about Linkrot in 1997.
[00:40:40.360 --> 00:40:42.840]   And of course, it was dead by 1999.
[00:40:42.840 --> 00:40:44.880]   Could not get to the article.
[00:40:44.880 --> 00:40:46.000]   It was like, that's irony.
[00:40:46.000 --> 00:40:49.440]   The solution to Linkrot, Authoriy.com.
[00:40:49.440 --> 00:40:53.000]   Our show today brought to you by Zip Recruiter.
[00:40:53.000 --> 00:40:54.880]   We have been so happy with Zip Recruiter.
[00:40:54.880 --> 00:40:58.040]   Some of our best staff hired on Zip Recruiter.
[00:40:58.040 --> 00:41:01.000]   Because this is what happens.
[00:41:01.000 --> 00:41:04.040]   And Lisa's the one who ends up suffering.
[00:41:04.040 --> 00:41:05.920]   Somebody says, I'm going to give you my two weeks.
[00:41:05.920 --> 00:41:08.480]   I got another job, or a moving, or whatever.
[00:41:08.480 --> 00:41:10.000]   And now we got to fill that position.
[00:41:10.000 --> 00:41:12.200]   And of course, the problem is the person who's filling the
[00:41:12.200 --> 00:41:14.520]   position, at least in a small company like ours, is also
[00:41:14.520 --> 00:41:16.560]   the one who's going to have to do the work of the person who's
[00:41:16.560 --> 00:41:17.800]   leaving while they're filling.
[00:41:17.800 --> 00:41:21.920]   And we all merit many hats in a business like ours.
[00:41:21.920 --> 00:41:25.880]   And it's hard to find people fast who are great.
[00:41:25.880 --> 00:41:28.280]   Well, it was until we found Zip Recruiter.
[00:41:28.280 --> 00:41:32.240]   Now, when we need somebody, we go to Zip Recruiter.
[00:41:32.240 --> 00:41:34.080]   It's been our experience within an hour or two.
[00:41:34.080 --> 00:41:35.480]   We'll get great candidates.
[00:41:35.480 --> 00:41:38.280]   And let me tell you why this works so well.
[00:41:38.280 --> 00:41:40.240]   It doesn't matter whether you're hiring a civil engineer
[00:41:40.240 --> 00:41:43.680]   in New York, a pediatric nurse in Nebraska, an attorney in
[00:41:43.680 --> 00:41:47.720]   Colorado, or even a mascot in Missouri, if you've seen the
[00:41:47.720 --> 00:41:51.640]   ads, or a continuity manager in Petaluma.
[00:41:51.640 --> 00:41:54.480]   Zip Recruiter helps you find quality candidates fast.
[00:41:54.480 --> 00:41:56.080]   And the way it works is so great.
[00:41:56.080 --> 00:41:58.520]   You post your opening on Zip Recruiter.
[00:41:58.520 --> 00:42:01.360]   Now, they're going to post it immediately to more than 100
[00:42:01.360 --> 00:42:03.000]   other job sites and social networks.
[00:42:03.000 --> 00:42:05.400]   So you're immediately casting a wide net.
[00:42:05.400 --> 00:42:08.360]   But that's when Zip Recruiter's technology kicks in.
[00:42:08.360 --> 00:42:11.640]   Because they will find people with the right experience and
[00:42:11.640 --> 00:42:16.600]   then tell you about them so you can invite them to apply.
[00:42:16.600 --> 00:42:18.680]   So this is really cool because it turns out when you have a
[00:42:18.680 --> 00:42:20.960]   job opening and you're inviting somebody, you're saying,
[00:42:20.960 --> 00:42:22.840]   hey, I saw your resume.
[00:42:22.840 --> 00:42:25.120]   And I think you'd be great for this job actually, Zip Recruiter
[00:42:25.120 --> 00:42:26.320]   did it, but we don't tell them that.
[00:42:26.320 --> 00:42:27.600]   And we think you'd be great for that job.
[00:42:27.600 --> 00:42:29.640]   That person is so excited to hear from you.
[00:42:29.640 --> 00:42:31.840]   They show up, they do the interview.
[00:42:31.840 --> 00:42:33.920]   I don't know if you had his experience, but ghosting
[00:42:33.920 --> 00:42:36.240]   interviews is a very common thing nowadays.
[00:42:36.240 --> 00:42:38.760]   You don't get that when you use Zip Recruiter.
[00:42:38.760 --> 00:42:41.000]   Plus all of those people applying for your job, they don't
[00:42:41.000 --> 00:42:42.800]   come to your phone or your email.
[00:42:42.800 --> 00:42:44.640]   They go into the Zip Recruiter interface.
[00:42:44.640 --> 00:42:47.480]   You can screen them with yes, no questions, multiple choice,
[00:42:47.480 --> 00:42:49.360]   even essay questions.
[00:42:49.360 --> 00:42:52.240]   They reformat the resume so it's easy to read them.
[00:42:52.240 --> 00:42:56.280]   They do all this stuff to make it easy to hire fast.
[00:42:56.280 --> 00:43:00.000]   And fast is important when you're wearing many hats, right?
[00:43:00.000 --> 00:43:02.760]   Four out of five employers who post on Zip Recruiter get a
[00:43:02.760 --> 00:43:06.080]   quality candidate within the first day.
[00:43:06.080 --> 00:43:07.960]   But I could tell you our experience has always been within
[00:43:07.960 --> 00:43:10.760]   a few hours, which is such a relief.
[00:43:10.760 --> 00:43:12.640]   Because now we know we're going to find somebody.
[00:43:12.640 --> 00:43:13.720]   I love Lisa.
[00:43:13.720 --> 00:43:15.160]   She'll post a breakfast.
[00:43:15.160 --> 00:43:17.720]   And by lunchtime, she's going, oh, this person is great.
[00:43:17.720 --> 00:43:18.800]   Oh, we got another one.
[00:43:18.800 --> 00:43:20.680]   It's such a relief.
[00:43:20.680 --> 00:43:24.800]   Try it free today, ziprecruiter.com/twit.
[00:43:24.800 --> 00:43:31.080]   It is the smart way to hire ziprecruiter.com/twit.
[00:43:31.080 --> 00:43:33.680]   We thank Zip Recruiter for the job they do for us.
[00:43:33.680 --> 00:43:35.680]   We thank them for advertising on the show.
[00:43:35.680 --> 00:43:38.840]   And we thank you as listeners for using that address.
[00:43:38.840 --> 00:43:40.440]   So they know you saw it here.
[00:43:40.440 --> 00:43:44.520]   That really helps us too, ziprecruiter.com/twit,
[00:43:44.520 --> 00:43:46.800]   the smartest way to hire.
[00:43:46.800 --> 00:43:48.720]   Thank you, Zip Recruiter.
[00:43:48.720 --> 00:43:51.040]   Good conversation.
[00:43:51.040 --> 00:43:53.720]   The first kind of sensible conversation we've had about
[00:43:53.720 --> 00:43:56.280]   what's going on over at Twitter.
[00:43:56.280 --> 00:44:00.120]   So thank you, all three of you, for your analysis.
[00:44:00.120 --> 00:44:04.360]   OK, we need a breather.
[00:44:04.360 --> 00:44:13.000]   Let me find something not so depressing and serious.
[00:44:13.000 --> 00:44:15.520]   I was going to say, oh, what about Fed Brooks has died?
[00:44:15.520 --> 00:44:17.320]   Oh, no, that's not--
[00:44:17.320 --> 00:44:18.320]   Let's not do that.
[00:44:18.320 --> 00:44:20.120]   Greg Baird to-- oh, no.
[00:44:20.120 --> 00:44:23.600]   How about Elizabeth Holmes going to jail for-- whoa.
[00:44:23.600 --> 00:44:26.840]   11 and a quarter years.
[00:44:26.840 --> 00:44:28.280]   Yeah, I had funny feelings about it.
[00:44:28.280 --> 00:44:29.280]   Me too.
[00:44:29.280 --> 00:44:33.000]   I've had to-- I feel like I've had to look inside myself
[00:44:33.000 --> 00:44:35.640]   because my reaction has been very shodden-froy to E
[00:44:35.640 --> 00:44:38.920]   about her, where I think that's unfortunate.
[00:44:38.920 --> 00:44:41.640]   I think she did-- listen, the jury
[00:44:41.640 --> 00:44:42.800]   decided she defrauded people.
[00:44:42.800 --> 00:44:44.720]   I think there's a lot of legal things you could say.
[00:44:44.720 --> 00:44:46.800]   But what she did-- but I found myself
[00:44:46.800 --> 00:44:49.040]   having a little glee about, like, oh, good, they got her.
[00:44:49.040 --> 00:44:53.120]   And then I'm thinking, ah, this poor woman at some level.
[00:44:53.120 --> 00:44:55.760]   She did cause actual-- or seemingly cause actual harm
[00:44:55.760 --> 00:44:58.720]   to people who got misleading blood results.
[00:44:58.720 --> 00:45:00.440]   Like, she could have put people in danger.
[00:45:00.440 --> 00:45:01.960]   And there are issues there.
[00:45:01.960 --> 00:45:03.640]   But I also think she got--
[00:45:03.640 --> 00:45:06.280]   she got disproportionate attention because of her gender.
[00:45:06.280 --> 00:45:09.640]   And I think it was-- there was a sort of gendered response to it.
[00:45:09.640 --> 00:45:11.480]   She did lead a giant fraud, and she
[00:45:11.480 --> 00:45:14.040]   should take responsibility for what she did
[00:45:14.040 --> 00:45:16.000]   and doesn't seem to be able to.
[00:45:16.000 --> 00:45:18.520]   But I also-- I don't feel like I should feel great about anybody
[00:45:18.520 --> 00:45:20.680]   going to jail, especially when--
[00:45:20.680 --> 00:45:22.560]   it's clear she has lots of-- the fact
[00:45:22.560 --> 00:45:24.960]   that she can't really see that she did anything wrong,
[00:45:24.960 --> 00:45:28.840]   that these things she--
[00:45:28.840 --> 00:45:31.320]   was a futurist who was too optimistic.
[00:45:31.320 --> 00:45:36.840]   I think that is a sad thing, not necessarily be celebrated.
[00:45:36.840 --> 00:45:39.240]   Dwight, what do you think?
[00:45:39.240 --> 00:45:43.400]   Well, you know, she-- I agree with half of what Glenn said.
[00:45:43.400 --> 00:45:47.200]   She committed fraud.
[00:45:47.200 --> 00:45:49.120]   She defrauded investors.
[00:45:49.120 --> 00:45:50.920]   She misled people.
[00:45:50.920 --> 00:45:54.040]   She, to a certain extent, she provided hope
[00:45:54.040 --> 00:45:56.320]   when there was no hope, really.
[00:45:56.320 --> 00:45:59.720]   And the sentencing guidelines were what?
[00:45:59.720 --> 00:46:02.480]   11 years to 20 years?
[00:46:02.480 --> 00:46:03.480]   And I was looking at that.
[00:46:03.480 --> 00:46:08.920]   And I was thinking, you know, her conduct was so egregious
[00:46:08.920 --> 00:46:12.000]   that I was thinking the judge could go 15 to 20.
[00:46:12.000 --> 00:46:14.840]   And so I was a little surprised that she only--
[00:46:14.840 --> 00:46:16.360]   and I say only--
[00:46:16.360 --> 00:46:17.640]   She got the minimum, I think.
[00:46:17.640 --> 00:46:19.080]   She got the minimum.
[00:46:19.080 --> 00:46:20.280]   And although--
[00:46:20.280 --> 00:46:22.200]   To a certain extent, the judge has discretion
[00:46:22.200 --> 00:46:25.880]   and can go lower than the guidelines.
[00:46:25.880 --> 00:46:27.640]   She's not required to go.
[00:46:27.640 --> 00:46:28.840]   I don't know if it only gets case.
[00:46:28.840 --> 00:46:30.040]   But she did, in this case.
[00:46:30.040 --> 00:46:31.120]   Yeah.
[00:46:31.120 --> 00:46:34.560]   I just-- I look at somebody like Alan Weisselberg, who
[00:46:34.560 --> 00:46:36.640]   was the CFO of the Trump Organization, who got what?
[00:46:36.640 --> 00:46:37.880]   Six months?
[00:46:37.880 --> 00:46:39.880]   Well, he might get 100 days, I think,
[00:46:39.880 --> 00:46:41.640]   if he fully cooperates.
[00:46:41.640 --> 00:46:43.960]   So I just feel like for stealing--
[00:46:43.960 --> 00:46:44.560]   I mean, for--
[00:46:44.560 --> 00:46:49.680]   Here's to me, the rule is don't defraud George Schulz.
[00:46:49.680 --> 00:46:53.440]   Because if you defraud the biggest, most important,
[00:46:53.440 --> 00:46:55.880]   most powerful people in the country, we're going to get you.
[00:46:55.880 --> 00:46:56.240]   OK, wait.
[00:46:56.240 --> 00:46:57.640]   You want something fun to talk about?
[00:46:57.640 --> 00:47:00.440]   Is George Schulz has a tiger tattoo on part of his body?
[00:47:00.440 --> 00:47:01.520]   Because he's a Princeton man.
[00:47:01.520 --> 00:47:01.960]   He's all--
[00:47:01.960 --> 00:47:02.800]   Yes, exactly.
[00:47:02.800 --> 00:47:03.840]   --and he's--
[00:47:03.840 --> 00:47:04.720]   Do you don't-- wait a minute.
[00:47:04.720 --> 00:47:06.640]   Tell me you don't have a bulldog on your butt.
[00:47:06.640 --> 00:47:08.440]   I have no bulldogs on my behind the thing.
[00:47:08.440 --> 00:47:11.680]   What kind of Yale man are you?
[00:47:11.680 --> 00:47:12.600]   Phil, what do you think?
[00:47:12.600 --> 00:47:17.880]   11 years, outrageous or appropriate?
[00:47:17.880 --> 00:47:19.560]   I have really complicated feelings about it.
[00:47:19.560 --> 00:47:22.520]   I think it feels unfair to me.
[00:47:22.520 --> 00:47:27.720]   It feels unfair, not compared to other people
[00:47:27.720 --> 00:47:29.960]   that have been sentenced for fraud,
[00:47:29.960 --> 00:47:34.480]   made off, got 150 years, and Jeffrey Schilling got 14 years
[00:47:34.480 --> 00:47:34.880]   or whatever.
[00:47:34.880 --> 00:47:37.000]   So that seems online.
[00:47:37.000 --> 00:47:39.040]   But it feels unfair when you compare to all the people
[00:47:39.040 --> 00:47:43.360]   that we know have done far worse that never get prosecuted.
[00:47:43.360 --> 00:47:45.320]   So I think it depends on the frame of reference.
[00:47:45.320 --> 00:47:47.960]   If you're comparing her to other people that
[00:47:47.960 --> 00:47:50.240]   have been sentenced for this kind of stuff, then yeah,
[00:47:50.240 --> 00:47:51.480]   it's about right.
[00:47:51.480 --> 00:47:53.840]   But it's hard for me not to compare it to all the people
[00:47:53.840 --> 00:47:57.920]   that I know do far worse every day
[00:47:57.920 --> 00:48:01.480]   and that don't get prosecuted and don't get anything.
[00:48:01.480 --> 00:48:05.600]   And I think in general, I don't like these send a message
[00:48:05.600 --> 00:48:07.640]   of sentences.
[00:48:07.640 --> 00:48:08.400]   I think they're unfair.
[00:48:08.400 --> 00:48:10.400]   I think what we should do is we should prosecute many more
[00:48:10.400 --> 00:48:11.560]   people.
[00:48:11.560 --> 00:48:14.720]   We should be much more consistent with prosecuting fraud.
[00:48:14.720 --> 00:48:18.760]   We should have much more prosecution on white-collar crime
[00:48:18.760 --> 00:48:21.840]   so that it should be a predictable outcome
[00:48:21.840 --> 00:48:23.400]   of defrauding people.
[00:48:23.400 --> 00:48:25.720]   As it is right now, we prosecute very few people.
[00:48:25.720 --> 00:48:27.200]   And then the ones that we convict,
[00:48:27.200 --> 00:48:28.760]   sometimes they get massive sentences.
[00:48:28.760 --> 00:48:31.400]   But I don't-- A, that doesn't seem fair to the person
[00:48:31.400 --> 00:48:32.040]   getting a sentence.
[00:48:32.040 --> 00:48:34.400]   And B, that doesn't seem like the right kind of deterrent
[00:48:34.400 --> 00:48:38.240]   effect because I don't think most would-be fraudsters are
[00:48:38.240 --> 00:48:40.920]   deterred by, oh, yeah, this is the one in a million shot
[00:48:40.920 --> 00:48:42.880]   that maybe I wouldn't go to jail.
[00:48:42.880 --> 00:48:43.320]   If you were--
[00:48:43.320 --> 00:48:45.640]   The next Elizabeth Holmes isn't looking at this going,
[00:48:45.640 --> 00:48:48.040]   oh, well, I better not defraud anybody.
[00:48:48.040 --> 00:48:51.560]   But if you were going to do this and you'd be like, well,
[00:48:51.560 --> 00:48:54.400]   there's a 25% chance that I'm going to wind up being convicted
[00:48:54.400 --> 00:48:56.520]   and going to jail for a year, I think
[00:48:56.520 --> 00:48:58.360]   that would be a much less return.
[00:48:58.360 --> 00:49:00.480]   So it feels wrong to me and it feels wrong
[00:49:00.480 --> 00:49:03.120]   because I know lots of people who do far worse
[00:49:03.120 --> 00:49:04.800]   and they don't get prosecuted at all.
[00:49:04.800 --> 00:49:06.240]   I hope you turn them in, Phil.
[00:49:06.240 --> 00:49:08.960]   [LAUGHTER]
[00:49:08.960 --> 00:49:10.920]   By the way, Phil's plane is landed.
[00:49:10.920 --> 00:49:13.840]   And now apparently he's in Tokyo for the cherry blossom.
[00:49:13.840 --> 00:49:14.840]   In the spring.
[00:49:14.840 --> 00:49:16.200]   Yeah, that's great.
[00:49:16.200 --> 00:49:16.720]   That's great.
[00:49:16.720 --> 00:49:18.920]   Tokyo last year in February.
[00:49:18.920 --> 00:49:21.360]   So--
[00:49:21.360 --> 00:49:23.440]   And we all have mixed feelings.
[00:49:23.440 --> 00:49:25.400]   Part of my mixed feelings are inappropriate,
[00:49:25.400 --> 00:49:27.040]   which is that she has a one-year-old
[00:49:27.040 --> 00:49:28.520]   and she's pregnant with another child.
[00:49:28.520 --> 00:49:31.040]   That's two children who will not have their mom.
[00:49:31.040 --> 00:49:33.760]   Now, will she do 11 years or is there a good time?
[00:49:33.760 --> 00:49:34.800]   Good time offer.
[00:49:34.800 --> 00:49:35.280]   Oh, it's a federal--
[00:49:35.280 --> 00:49:37.120]   It's a federal sentence.
[00:49:37.120 --> 00:49:39.240]   Unless her appeal comes in, she's in.
[00:49:39.240 --> 00:49:39.720]   There's no--
[00:49:39.720 --> 00:49:40.920]   That's a lot in the federal--
[00:49:40.920 --> 00:49:44.440]   Even if she goes to country club jail, that's hard time.
[00:49:44.440 --> 00:49:45.040]   Oh, look at this.
[00:49:45.040 --> 00:49:46.400]   It's federal prisoners.
[00:49:46.400 --> 00:49:47.880]   Of federal--
[00:49:47.880 --> 00:49:49.800]   Yeah, sorry.
[00:49:49.800 --> 00:49:52.960]   There's a great law and order episode that a number of years
[00:49:52.960 --> 00:49:54.600]   ago that I always think about in terms of this.
[00:49:54.600 --> 00:49:56.360]   When I try to calibrate my feelings,
[00:49:56.360 --> 00:49:59.240]   it's an episode that it plays on that of someone's kiddies
[00:49:59.240 --> 00:50:02.520]   who are stolen and they wake up in a tub of ice, urban myth,
[00:50:02.520 --> 00:50:03.680]   which circulates.
[00:50:03.680 --> 00:50:05.240]   This literally happens in the episode.
[00:50:05.240 --> 00:50:06.840]   If somebody wakes up, his kiddies
[00:50:06.840 --> 00:50:09.760]   been stolen and they eventually figure out
[00:50:09.760 --> 00:50:12.000]   that it's a guy-- it's a very rich man whose
[00:50:12.000 --> 00:50:14.120]   daughter needed a kidney and he couldn't get one
[00:50:14.120 --> 00:50:14.960]   through his move away.
[00:50:14.960 --> 00:50:18.520]   So he essentially hired someone to--
[00:50:18.520 --> 00:50:21.400]   hired goons to find somebody with a good kidney that
[00:50:21.400 --> 00:50:24.200]   was a match and then hired paid doctors huge amounts of money
[00:50:24.200 --> 00:50:25.040]   to perform the surgery.
[00:50:25.040 --> 00:50:26.880]   And the great line at the end on the stand
[00:50:26.880 --> 00:50:30.680]   was Mr. So-and-so, this time was a kidney.
[00:50:30.680 --> 00:50:31.320]   He survived.
[00:50:31.320 --> 00:50:33.520]   He's actually going to be fine, the person who's
[00:50:33.520 --> 00:50:35.120]   working you ripped from his body.
[00:50:35.120 --> 00:50:36.440]   But if it had been a heart, would you
[00:50:36.440 --> 00:50:37.920]   have done anything differently?
[00:50:37.920 --> 00:50:40.440]   And I sometimes think that's the calibration factor
[00:50:40.440 --> 00:50:43.360]   is I think about homes that I'm thinking,
[00:50:43.360 --> 00:50:44.560]   it does seem like too much.
[00:50:44.560 --> 00:50:46.120]   It doesn't seem like it has a deterrent effect.
[00:50:46.120 --> 00:50:48.240]   I feel bad for her children or family.
[00:50:48.240 --> 00:50:50.000]   And the harm she committed to cheat,
[00:50:50.000 --> 00:50:53.440]   was she out there actively killing people?
[00:50:53.440 --> 00:50:55.280]   Well, there's some arguments that there
[00:50:55.280 --> 00:50:57.840]   were adverse health effects that resulted from some people
[00:50:57.840 --> 00:51:00.560]   getting bad test information.
[00:51:00.560 --> 00:51:04.920]   And the thing is, I think if 100 people had died from this,
[00:51:04.920 --> 00:51:05.600]   as opposed to--
[00:51:05.600 --> 00:51:06.680]   That would be different.
[00:51:06.680 --> 00:51:07.680]   That would be different.
[00:51:07.680 --> 00:51:10.280]   But I think also, I don't think her behavior would have
[00:51:10.280 --> 00:51:11.960]   necessarily been any different is the problem.
[00:51:11.960 --> 00:51:12.960]   Well, and if I'm sunny--
[00:51:12.960 --> 00:51:15.280]   She has no more-- she is more restless.
[00:51:15.280 --> 00:51:18.400]   She was-- because she didn't think she feels like something.
[00:51:18.400 --> 00:51:21.440]   This is what you do in tech.
[00:51:21.440 --> 00:51:23.480]   I have to say, somewhat our own culture
[00:51:23.480 --> 00:51:27.040]   is to blame because we lionized her.
[00:51:27.040 --> 00:51:30.040]   And she was taught to some degree
[00:51:30.040 --> 00:51:32.960]   that you fake it till you make it, right?
[00:51:32.960 --> 00:51:35.160]   Yeah, absolutely.
[00:51:35.160 --> 00:51:36.960]   And that's how Steve Jobs made it.
[00:51:36.960 --> 00:51:38.960]   That's how Elon Musk made it.
[00:51:38.960 --> 00:51:42.680]   You just-- you go and you go and you go till you--
[00:51:42.680 --> 00:51:45.560]   you make it and sometimes you don't.
[00:51:45.560 --> 00:51:49.000]   I think there's two issues here that are separate.
[00:51:49.000 --> 00:51:50.360]   And so whenever I find myself having
[00:51:50.360 --> 00:51:52.440]   these conflicted feelings, I try to figure out,
[00:51:52.440 --> 00:51:54.520]   well, is there more than one thing
[00:51:54.520 --> 00:51:55.920]   that I'm having feelings about?
[00:51:55.920 --> 00:51:57.440]   And I think in this case, there are.
[00:51:57.440 --> 00:52:01.600]   I think the real issue here is that this verdict highlights
[00:52:01.600 --> 00:52:04.840]   how few people get prosecuted for.
[00:52:04.840 --> 00:52:07.160]   Like, that is more important to me
[00:52:07.160 --> 00:52:08.520]   than how much Elizabeth Holmes should serve.
[00:52:08.520 --> 00:52:11.000]   Because it's hard to-- I guess because it's hard to prove.
[00:52:11.000 --> 00:52:11.800]   It is hard to prove.
[00:52:11.800 --> 00:52:14.600]   A lot of money went into this trial, that's for sure.
[00:52:14.600 --> 00:52:16.760]   Yeah, for all sorts of reasons.
[00:52:16.760 --> 00:52:21.040]   But relatively, a few people get prosecuted for it.
[00:52:21.040 --> 00:52:22.520]   And this points that out.
[00:52:22.520 --> 00:52:26.480]   And that's a big problem.
[00:52:26.480 --> 00:52:30.120]   That's separate from, does she deserve 11 years or five years
[00:52:30.120 --> 00:52:30.800]   or whatever?
[00:52:30.800 --> 00:52:33.360]   And I'm less attached to that position.
[00:52:33.360 --> 00:52:36.000]   I think, personally, it doesn't really
[00:52:36.000 --> 00:52:38.600]   do anyone any good to lock her away for 11 years.
[00:52:38.600 --> 00:52:41.000]   So I would have done something a lot more lenient.
[00:52:41.000 --> 00:52:43.480]   But I'm also totally happy to be like, hey, I'm not the judge.
[00:52:43.480 --> 00:52:45.400]   This is the way the system works.
[00:52:45.400 --> 00:52:45.960]   Whatever.
[00:52:45.960 --> 00:52:46.320]   Let me get--
[00:52:46.320 --> 00:52:47.880]   The reason that I feel it's--
[00:52:47.880 --> 00:52:48.520]   Go ahead.
[00:52:48.520 --> 00:52:48.880]   I'm sorry.
[00:52:48.880 --> 00:52:49.440]   Finish your sentence.
[00:52:49.440 --> 00:52:50.280]   No, I said no.
[00:52:50.280 --> 00:52:52.040]   The reason that it feels unfair to me
[00:52:52.040 --> 00:52:54.000]   is because it points out how--
[00:52:54.000 --> 00:52:55.640]   Look at all these other people who are--
[00:52:55.640 --> 00:52:56.280]   But that's justice.
[00:52:56.280 --> 00:52:57.200]   --of getting prosecuted at all.
[00:52:57.200 --> 00:52:58.920]   Justice has always been uneven, right?
[00:52:58.920 --> 00:53:01.200]   It's impossible.
[00:53:01.200 --> 00:53:03.240]   It's the nature of justice.
[00:53:03.240 --> 00:53:05.000]   You do the best you can.
[00:53:05.000 --> 00:53:09.360]   You can't fault a sentence because not everybody gets
[00:53:09.360 --> 00:53:10.160]   the same sentence.
[00:53:10.160 --> 00:53:11.320]   It's unfair.
[00:53:11.320 --> 00:53:12.480]   Some people get six months.
[00:53:12.480 --> 00:53:14.240]   Some people get 11 years.
[00:53:14.240 --> 00:53:16.440]   Some people don't even get caught.
[00:53:16.440 --> 00:53:17.600]   We do the best we can.
[00:53:17.600 --> 00:53:20.200]   It's a very imperfect system.
[00:53:20.200 --> 00:53:23.320]   You can say that there should be more prosecutions
[00:53:23.320 --> 00:53:25.720]   for things that are likely for it.
[00:53:25.720 --> 00:53:28.280]   I think we could pull up Trevor Milton from last month
[00:53:28.280 --> 00:53:30.600]   or six weeks ago, the founder of Nicola,
[00:53:30.600 --> 00:53:32.040]   who was convicted of--
[00:53:32.040 --> 00:53:32.800]   I'm just wondering if it's clear.
[00:53:32.800 --> 00:53:33.360]   He's cleared.
[00:53:33.360 --> 00:53:33.860]   He's cleared.
[00:53:33.860 --> 00:53:36.520]   He's one kind of security fraud and two counts of wire fraud.
[00:53:36.520 --> 00:53:39.800]   But that is an amazing case.
[00:53:39.800 --> 00:53:42.880]   And that, I have no concerns about what time he gets put away
[00:53:42.880 --> 00:53:46.600]   for because the man is clearly completely pathological.
[00:53:46.600 --> 00:53:47.560]   He's facing 20 years ago.
[00:53:47.560 --> 00:53:49.400]   Up to 25 years of his sentencing is in jail.
[00:53:49.400 --> 00:53:51.400]   He's got a multi-decade career of telling people
[00:53:51.400 --> 00:53:52.320]   all kinds of things.
[00:53:52.320 --> 00:53:54.240]   And it's a very--
[00:53:54.240 --> 00:53:57.080]   It's similar fraud, except it wasn't health fraud.
[00:53:57.080 --> 00:53:58.960]   Nobody's life was endangered by Nicola.
[00:53:58.960 --> 00:53:59.480]   Yeah.
[00:53:59.480 --> 00:54:01.080]   I mean, right, some of the cars could have been dangerous
[00:54:01.080 --> 00:54:02.400]   if they'd actually worked.
[00:54:02.400 --> 00:54:04.880]   But I feel like it was more straightforward thing
[00:54:04.880 --> 00:54:06.640]   where it was clear to--
[00:54:06.640 --> 00:54:09.960]   I'm not always clear whether Elizabeth Holmes truly knew
[00:54:09.960 --> 00:54:13.240]   whether her stuff worked or not or she was being pushing
[00:54:13.240 --> 00:54:15.000]   the window, sometimes clearly not in the courts
[00:54:15.000 --> 00:54:17.400]   found or the jury found that she clearly went too far.
[00:54:17.400 --> 00:54:20.520]   But it's very clear that Milton knew he was pushing
[00:54:20.520 --> 00:54:23.160]   or should have known, like morally, ethically,
[00:54:23.160 --> 00:54:26.120]   and electually, that what he was saying was absolutely false.
[00:54:26.120 --> 00:54:27.160]   And it was intentional.
[00:54:27.160 --> 00:54:31.840]   It was just such a scam as opposed to what I'm sure.
[00:54:31.840 --> 00:54:33.920]   I mean, I know that Elizabeth Holmes absolutely
[00:54:33.920 --> 00:54:36.040]   wanted to make that business a real thing.
[00:54:36.040 --> 00:54:39.480]   Meanwhile, Billy McFarland, who did the fire festival,
[00:54:39.480 --> 00:54:44.920]   got six years and is in a halfway house now after four.
[00:54:44.920 --> 00:54:46.920]   Although Ray Hushpuppy got 11 years.
[00:54:46.920 --> 00:54:47.840]   So there you go.
[00:54:47.840 --> 00:54:49.080]   Ray Hushpuppy.
[00:54:49.080 --> 00:54:51.720]   [LAUGHTER]
[00:54:51.720 --> 00:54:52.920]   Same week.
[00:54:52.920 --> 00:54:59.800]   Nigerian man named Raymond Olarunwa Abas, aka Ray Hushpuppy,
[00:54:59.800 --> 00:55:01.400]   11 years in federal prison.
[00:55:01.400 --> 00:55:04.200]   He was a kind of--
[00:55:04.200 --> 00:55:05.000]   That guy.
[00:55:05.000 --> 00:55:05.760]   That guy.
[00:55:05.760 --> 00:55:07.600]   They got him in Dubai.
[00:55:07.600 --> 00:55:10.080]   And an extra died at him.
[00:55:10.080 --> 00:55:15.720]   He'd been involved in a vast money laundering email,
[00:55:15.720 --> 00:55:19.600]   compromised bank heists, all sorts of stuff.
[00:55:19.600 --> 00:55:20.840]   And he got 11 years.
[00:55:20.840 --> 00:55:21.240]   I don't know.
[00:55:21.240 --> 00:55:24.400]   I think Ray Hushpuppy, probably a worse guy
[00:55:24.400 --> 00:55:26.320]   than Elizabeth Holmes.
[00:55:26.320 --> 00:55:27.880]   What is the point of prison?
[00:55:27.880 --> 00:55:29.760]   Is prison to deter?
[00:55:29.760 --> 00:55:31.760]   Is prison to rehabilitate?
[00:55:31.760 --> 00:55:33.400]   Do you think Elizabeth Holmes will
[00:55:33.400 --> 00:55:37.200]   be a better person 11 years from now?
[00:55:37.200 --> 00:55:38.160]   This gets in that hole.
[00:55:38.160 --> 00:55:42.000]   I mean, I feel like the carceral state is a huge problem.
[00:55:42.000 --> 00:55:43.160]   And it feeds on itself.
[00:55:43.160 --> 00:55:45.400]   And we put people in jail to put people in jail.
[00:55:45.400 --> 00:55:48.160]   And it feeds the industrial prison complex.
[00:55:48.160 --> 00:55:49.120]   I think there's a whole bunch.
[00:55:49.120 --> 00:55:51.280]   But then there's people we need to be protected against
[00:55:51.280 --> 00:55:52.400]   as a society.
[00:55:52.400 --> 00:55:55.440]   And there's people who need to be protected from themselves.
[00:55:55.440 --> 00:55:57.000]   And I think the overlap of that is we
[00:55:57.000 --> 00:56:00.040]   throw many more people in the jail for reasons that don't make
[00:56:00.040 --> 00:56:03.480]   any sense and are non-productive for them and for society.
[00:56:03.480 --> 00:56:05.360]   So I'm not worried that Holmes would
[00:56:05.360 --> 00:56:07.920]   account in my house and steal my blood.
[00:56:07.920 --> 00:56:09.400]   So does she actually have to be in jail?
[00:56:09.400 --> 00:56:12.200]   Or are there other punishments that would serve a deterrent
[00:56:12.200 --> 00:56:14.520]   effect for her?
[00:56:14.520 --> 00:56:16.760]   But there are people who I am worried would break into my house
[00:56:16.760 --> 00:56:17.840]   and steal my blood.
[00:56:17.840 --> 00:56:18.360]   Right.
[00:56:18.360 --> 00:56:18.840]   They probably--
[00:56:18.840 --> 00:56:19.880]   There's some crux.
[00:56:19.880 --> 00:56:23.280]   I don't think Elizabeth Holmes is an ongoing danger to anybody.
[00:56:23.280 --> 00:56:25.640]   Yeah, I think that's the issue.
[00:56:25.640 --> 00:56:28.360]   Well, I think Phil, I wouldn't want to put this word
[00:56:28.360 --> 00:56:28.760]   into your mouth.
[00:56:28.760 --> 00:56:31.440]   But it's like Adam Newman is an example of somebody who
[00:56:31.440 --> 00:56:31.920]   raised--
[00:56:31.920 --> 00:56:33.200]   Failing awkward.
[00:56:33.200 --> 00:56:33.560]   Right.
[00:56:33.560 --> 00:56:36.280]   And then he's completely successful in--
[00:56:36.280 --> 00:56:39.680]   but I mean, I think he's a true believer in what he does.
[00:56:39.680 --> 00:56:41.480]   Absolutely, religiously so.
[00:56:41.480 --> 00:56:43.400]   But how was he never--
[00:56:43.400 --> 00:56:44.880]   I mean, I don't want to make accusations against him.
[00:56:44.880 --> 00:56:45.560]   I've read books.
[00:56:45.560 --> 00:56:46.640]   I've seen things.
[00:56:46.640 --> 00:56:49.120]   It's like, I don't know that he ever did anything that he's
[00:56:49.120 --> 00:56:50.720]   even technically illegal.
[00:56:50.720 --> 00:56:51.480]   I don't know.
[00:56:51.480 --> 00:56:52.480]   It's been charged with anything.
[00:56:52.480 --> 00:56:54.480]   The founder of Weenwerk who--
[00:56:54.480 --> 00:56:54.680]   Yeah.
[00:56:54.680 --> 00:56:57.120]   --who cost a sun sun.
[00:56:57.120 --> 00:56:58.080]   And that's a--
[00:56:58.080 --> 00:56:58.580]   Wow.
[00:56:58.580 --> 00:57:01.800]   --a mazzo Yoshi's son billions of dollars.
[00:57:01.800 --> 00:57:02.800]   A victimless crime.
[00:57:02.800 --> 00:57:04.520]   [LAUGHTER]
[00:57:04.520 --> 00:57:09.360]   And really put the Softbank Fund in kind of jeopardy
[00:57:09.360 --> 00:57:12.720]   after a sun sun kind of said, oh, I believe in you.
[00:57:12.720 --> 00:57:15.080]   Whatever it is you're selling, I want more of that.
[00:57:15.080 --> 00:57:16.160]   But that's the difference.
[00:57:16.160 --> 00:57:18.040]   What's the difference between Adam Newman and--
[00:57:18.040 --> 00:57:20.560]   He's worth 1.2 billion and just got
[00:57:20.560 --> 00:57:25.920]   a huge gift from Dresen Horowitz to do his next big thing.
[00:57:25.920 --> 00:57:27.920]   And I don't want to accuse him of anything.
[00:57:27.920 --> 00:57:30.440]   I think the fascinating part about him
[00:57:30.440 --> 00:57:33.640]   is I think he sold long and sold--
[00:57:33.640 --> 00:57:35.600]   or he talked long and sold short.
[00:57:35.600 --> 00:57:38.040]   So he couldn't fulfill exactly what he was promising.
[00:57:38.040 --> 00:57:40.880]   But I think he did it in a very carefully done way
[00:57:40.880 --> 00:57:42.040]   that had a potential.
[00:57:42.040 --> 00:57:44.840]   I mean, after one of the really well-researched books
[00:57:44.840 --> 00:57:47.520]   about WeWork, I came out of it thinking this guy
[00:57:47.520 --> 00:57:48.760]   was in a scammer.
[00:57:48.760 --> 00:57:51.920]   What he was was he had an arc where as long as he--
[00:57:51.920 --> 00:57:55.360]   this was Shades of FTX and Sam--
[00:57:55.360 --> 00:57:56.200]   what's his name--
[00:57:56.200 --> 00:57:59.480]   Bankman Fried.
[00:57:59.480 --> 00:58:01.760]   I think Newman actually had an arc where
[00:58:01.760 --> 00:58:03.160]   if you keep people believing long enough,
[00:58:03.160 --> 00:58:05.280]   there was a potential for profit to come at the other end
[00:58:05.280 --> 00:58:06.760]   of the pipe, maybe not the way you see it.
[00:58:06.760 --> 00:58:07.720]   I don't think so, actually.
[00:58:07.720 --> 00:58:08.320]   I think--
[00:58:08.320 --> 00:58:09.560]   Well, and I guess you're right.
[00:58:09.560 --> 00:58:11.080]   What about Travis Kalinek?
[00:58:11.080 --> 00:58:13.640]   So have you raised money, Phil?
[00:58:13.640 --> 00:58:15.400]   You've gone to VCs.
[00:58:15.400 --> 00:58:16.560]   A little bit, yeah.
[00:58:16.560 --> 00:58:18.480]   Yeah.
[00:58:18.480 --> 00:58:21.120]   You're putting me in a tough spot because I know all these people.
[00:58:21.120 --> 00:58:22.160]   I know you do.
[00:58:22.160 --> 00:58:25.960]   So you can-- at any point recuse yourself.
[00:58:25.960 --> 00:58:27.640]   But I'm just curious--
[00:58:27.640 --> 00:58:30.760]   Sonsan is currently a major investor in my company.
[00:58:30.760 --> 00:58:35.040]   I work for Sonsan when he bought Ziff Davis.
[00:58:35.040 --> 00:58:36.800]   And I have great respect for the man.
[00:58:36.800 --> 00:58:40.040]   I think he was the victim, frankly, of Adam Newman.
[00:58:40.040 --> 00:58:44.280]   But that aside, is there something broken in the way we do
[00:58:44.280 --> 00:58:48.040]   VC that it rewards people like Elizabeth Holmes?
[00:58:48.040 --> 00:58:48.880]   Oh, yeah.
[00:58:48.880 --> 00:58:50.640]   I mean, I think there's all sorts of interesting questions
[00:58:50.640 --> 00:58:52.000]   here.
[00:58:52.000 --> 00:58:53.840]   I mean, one, you can just very basic questions.
[00:58:53.840 --> 00:58:55.600]   Where did the money go?
[00:58:55.600 --> 00:58:58.920]   Where did the money go with Elizabeth Holmes?
[00:58:58.920 --> 00:59:01.720]   Where did the money go with Adam Newman?
[00:59:01.720 --> 00:59:03.080]   Where did the money go with SBF?
[00:59:03.080 --> 00:59:05.280]   And I think those are very different answers.
[00:59:05.280 --> 00:59:08.880]   And I think that answer is kind of important to determining
[00:59:08.880 --> 00:59:12.840]   the level of at least moral culpability of people.
[00:59:12.840 --> 00:59:14.960]   As far as we know, and I think we know pretty well,
[00:59:14.960 --> 00:59:16.680]   like Elizabeth Holmes didn't wind up
[00:59:16.680 --> 00:59:18.200]   with a big chunk of that money.
[00:59:18.200 --> 00:59:20.400]   Right.
[00:59:20.400 --> 00:59:21.880]   Adam Newman wound up with some of it.
[00:59:21.880 --> 00:59:23.800]   Significant amount, billion or so.
[00:59:23.800 --> 00:59:25.280]   It's interesting that Mark and Driesen
[00:59:25.280 --> 00:59:28.000]   would give him another $350 million.
[00:59:28.000 --> 00:59:31.080]   Well, but seriously, if you're evaluating
[00:59:31.080 --> 00:59:33.240]   fraud, potential fraud, or actual fraud,
[00:59:33.240 --> 00:59:36.000]   where did the money go?
[00:59:36.000 --> 00:59:36.560]   I think--
[00:59:36.560 --> 00:59:38.240]   So landlords, I think, mostly, right?
[00:59:38.240 --> 00:59:39.240]   I mean, we were--
[00:59:39.240 --> 00:59:40.440]   We were selling a lot of leases.
[00:59:40.440 --> 00:59:41.440]   And that was--
[00:59:41.440 --> 01:00:06.300]   In a hyperin
[01:00:06.300 --> 01:00:08.060]   judge decided what was the number?
[01:00:08.060 --> 01:00:09.180]   It was $180 million.
[01:00:09.180 --> 01:00:11.260]   It was something substantially lower.
[01:00:11.260 --> 01:00:13.820]   Like 22 investors said they lost whatever.
[01:00:13.820 --> 01:00:16.940]   And I think it was because the actual scope of--
[01:00:16.940 --> 01:00:18.660]   They didn't spend as much money as it sounds,
[01:00:18.660 --> 01:00:21.220]   because they had such a super high valuation that I think it was.
[01:00:21.220 --> 01:00:22.300]   It's the mark.
[01:00:22.300 --> 01:00:23.300]   Yeah.
[01:00:23.300 --> 01:00:28.780]   So Holmes, the money was spent for employees and equipment
[01:00:28.780 --> 01:00:29.660]   in real estate.
[01:00:29.660 --> 01:00:32.220]   But yeah, I don't feel like she had some nice houses,
[01:00:32.220 --> 01:00:34.540]   but her family was very wealthy or somewhat wealthy
[01:00:34.540 --> 01:00:35.140]   to begin with.
[01:00:35.140 --> 01:00:37.060]   So as far as we know, that money
[01:00:37.060 --> 01:00:39.700]   went to paying a lot of salaries for a lot of people
[01:00:39.700 --> 01:00:41.420]   and a lot of equipment.
[01:00:41.420 --> 01:00:43.820]   And if there was fraud, and to some extent,
[01:00:43.820 --> 01:00:45.340]   the court determined there was fraud.
[01:00:45.340 --> 01:00:45.820]   So it's fine.
[01:00:45.820 --> 01:00:46.180]   There's fraud.
[01:00:46.180 --> 01:00:47.140]   There's fraud.
[01:00:47.140 --> 01:00:48.500]   But I think it's very different types.
[01:00:48.500 --> 01:00:52.180]   And what probably happened with FTX, for example,
[01:00:52.180 --> 01:00:54.260]   where money was just outright stolen.
[01:00:54.260 --> 01:00:55.340]   Where is that money?
[01:00:55.340 --> 01:00:56.500]   The FTX money is like--
[01:00:56.500 --> 01:00:59.300]   Yeah, I mean, billions is gone.
[01:00:59.300 --> 01:01:01.060]   As far as fraud goes.
[01:01:01.060 --> 01:01:05.940]   Here, SPF, it looks like now the latest is took 300 million
[01:01:05.940 --> 01:01:08.260]   off the table in their last round.
[01:01:08.260 --> 01:01:09.340]   Yeah.
[01:01:09.340 --> 01:01:11.220]   So that's somewhere, right?
[01:01:11.220 --> 01:01:12.460]   Unless he-- I don't know.
[01:01:12.460 --> 01:01:14.260]   That's a lot of bean bags.
[01:01:14.260 --> 01:01:19.020]   I don't-- I don't know what-- that's somewhere out there.
[01:01:19.020 --> 01:01:19.980]   The incentives, though.
[01:01:19.980 --> 01:01:24.180]   You asked a very good question about what's broken about AC.
[01:01:24.180 --> 01:01:28.540]   And I think, like, look, I know, obviously, a lot of ACs.
[01:01:28.540 --> 01:01:32.620]   I was a VC myself for two years at a general catalyst.
[01:01:32.620 --> 01:01:35.460]   A bunch of people are friends of mine.
[01:01:35.460 --> 01:01:38.420]   And I think, for the most part, a lot of these people
[01:01:38.420 --> 01:01:40.300]   are generally good people.
[01:01:40.300 --> 01:01:41.580]   They're genuinely smart.
[01:01:41.580 --> 01:01:42.380]   They're genuinely good.
[01:01:42.380 --> 01:01:44.060]   They generally want to do the right thing.
[01:01:44.060 --> 01:01:45.580]   Not everyone.
[01:01:45.580 --> 01:01:46.740]   You know who you are.
[01:01:46.740 --> 01:01:48.300]   But for the most part--
[01:01:48.300 --> 01:01:52.060]   They're not, though, even thinking about--
[01:01:52.060 --> 01:01:52.540]   or are they?
[01:01:52.540 --> 01:01:53.140]   You tell me.
[01:01:53.140 --> 01:01:54.500]   You know.
[01:01:54.500 --> 01:01:56.060]   Do they think they're not trying
[01:01:56.060 --> 01:01:57.340]   to use their money to do good?
[01:01:57.340 --> 01:01:59.900]   They're trying to make an investment that will pay off.
[01:01:59.900 --> 01:02:01.700]   A lot of them are trying to use their money to do good.
[01:02:01.700 --> 01:02:02.180]   Really?
[01:02:02.180 --> 01:02:02.540]   That's right.
[01:02:02.540 --> 01:02:02.940]   A lot.
[01:02:02.940 --> 01:02:03.580]   Yeah, absolutely.
[01:02:03.580 --> 01:02:05.620]   But look, here's the thing.
[01:02:05.620 --> 01:02:08.420]   Here's the main thing that I figured out.
[01:02:08.420 --> 01:02:11.020]   The vast majority of people, myself included,
[01:02:11.020 --> 01:02:14.180]   will act according to our incentives.
[01:02:14.180 --> 01:02:15.820]   So first, we act according to our incentives.
[01:02:15.820 --> 01:02:17.500]   If you look at how the incentives are set up,
[01:02:17.500 --> 01:02:19.660]   that will predict how we act.
[01:02:19.660 --> 01:02:21.620]   And then most of us, myself included,
[01:02:21.620 --> 01:02:23.020]   will act according to our incentives
[01:02:23.020 --> 01:02:25.540]   and then make up a narrative about why that action is morally
[01:02:25.540 --> 01:02:25.860]   sound.
[01:02:25.860 --> 01:02:28.260]   That's how all decisions are made, by the way.
[01:02:28.260 --> 01:02:30.700]   Yeah, and that's how the mind works.
[01:02:30.700 --> 01:02:32.660]   And that narrative is true.
[01:02:32.660 --> 01:02:33.340]   We believe it.
[01:02:33.340 --> 01:02:35.500]   We really do.
[01:02:35.500 --> 01:02:38.300]   But it's not surprising that it just so happens
[01:02:38.300 --> 01:02:40.300]   that the morally correct thing that we tell ourselves
[01:02:40.300 --> 01:02:42.700]   happens to always line up with our financial incentives,
[01:02:42.700 --> 01:02:45.060]   the vast majority of the time.
[01:02:45.060 --> 01:02:48.340]   So if I want to lead a moral life, which I do,
[01:02:48.340 --> 01:02:50.420]   the best way to do it, since I can't trust myself
[01:02:50.420 --> 01:02:52.180]   to not follow my incentives, is to make sure
[01:02:52.180 --> 01:02:56.620]   that I set up my incentives first to go in the direction
[01:02:56.620 --> 01:02:57.180]   that I want to go.
[01:02:57.180 --> 01:02:59.180]   And not everyone does that.
[01:02:59.180 --> 01:03:01.540]   So when you look at how VCs operate,
[01:03:01.540 --> 01:03:04.380]   how do they make money, what's the incentives?
[01:03:04.380 --> 01:03:05.660]   Well, they make money by investing.
[01:03:05.660 --> 01:03:08.020]   They don't make money by not investing.
[01:03:08.020 --> 01:03:09.060]   They make money by investing.
[01:03:09.060 --> 01:03:11.180]   They make money by investing a lot.
[01:03:11.180 --> 01:03:13.220]   They make more money by investing a lot.
[01:03:13.220 --> 01:03:14.860]   They make more money by investing a lot quickly
[01:03:14.860 --> 01:03:16.580]   so they can raise the next round.
[01:03:16.580 --> 01:03:20.860]   So they raise the next fund so they can stack management fees
[01:03:20.860 --> 01:03:22.620]   and carry and all that stuff.
[01:03:22.620 --> 01:03:24.420]   - It's a business.
[01:03:24.420 --> 01:03:26.340]   - It's a business fundamentally, right?
[01:03:26.340 --> 01:03:30.780]   - 100%, almost all of the incentives are set up for invest
[01:03:30.780 --> 01:03:31.940]   invest as much as you can.
[01:03:31.940 --> 01:03:34.620]   Now the vast majority of these people will do it
[01:03:34.620 --> 01:03:36.620]   with due diligence or what they think is the right amount
[01:03:36.620 --> 01:03:39.300]   of due diligence and they'll do it because they genuinely
[01:03:39.300 --> 01:03:41.580]   think that it's money making.
[01:03:41.580 --> 01:03:43.020]   - But the due diligence is--
[01:03:43.020 --> 01:03:44.780]   - The question they're asking is,
[01:03:44.780 --> 01:03:47.460]   is this going to make the world a better place?
[01:03:47.460 --> 01:03:48.940]   Maybe that's a secondary question.
[01:03:48.940 --> 01:03:50.900]   The question is, is this going to make money?
[01:03:50.900 --> 01:03:51.740]   - Is it real?
[01:03:51.740 --> 01:03:52.660]   Is it going to make money?
[01:03:52.660 --> 01:03:55.460]   And you can say, well, but they should do a lot more due
[01:03:55.460 --> 01:04:00.180]   diligence, okay, but most of the funds, even that invested
[01:04:00.180 --> 01:04:03.820]   in FTX and stuff, those funds are actually doing great, right?
[01:04:03.820 --> 01:04:07.420]   'Cause the VC model is predicated upon, for the most part,
[01:04:07.420 --> 01:04:09.380]   believe founders.
[01:04:09.380 --> 01:04:12.020]   And yeah, once in a while, that's going to screw you,
[01:04:12.020 --> 01:04:15.180]   but the belief founders tends to, in the past,
[01:04:15.180 --> 01:04:17.460]   have historically generated very good returns
[01:04:17.460 --> 01:04:20.940]   because you do get the Steve Jobs and the everyone else's
[01:04:20.940 --> 01:04:22.740]   who like, yeah, like to some extent there's a fake it
[01:04:22.740 --> 01:04:25.840]   until you make it, but enough of a make it and make it big,
[01:04:25.840 --> 01:04:28.860]   that it's worthwhile.
[01:04:28.860 --> 01:04:32.140]   So like this is the model, the way that it's been set up.
[01:04:32.140 --> 01:04:34.100]   And that's why when crypto comes along,
[01:04:34.100 --> 01:04:37.340]   it's like the greatest thing that a lot of these investors
[01:04:37.340 --> 01:04:39.380]   have ever seen because the crypto comes along
[01:04:39.380 --> 01:04:44.380]   and they're like, we need $420 million.
[01:04:44.380 --> 01:04:46.580]   And you're like, for what?
[01:04:46.580 --> 01:04:48.540]   Well, I don't know because no one knows
[01:04:48.540 --> 01:04:50.140]   what crypto's going to cost.
[01:04:50.140 --> 01:04:51.820]   There's no, it's not like a SaaS company
[01:04:51.820 --> 01:04:53.700]   where you can kind of say, oh, you need this many engineers.
[01:04:53.700 --> 01:04:55.660]   You're like, I don't know.
[01:04:55.660 --> 01:04:58.140]   And so the investors are sitting there looking at like,
[01:04:58.140 --> 01:05:00.660]   wow, I can raise and I can write a giant check
[01:05:00.660 --> 01:05:04.780]   into this company, which means I can get my next fund.
[01:05:04.780 --> 01:05:07.780]   Like all of that, again, all the incentives take over.
[01:05:07.780 --> 01:05:10.660]   So it's like it is an incentive system
[01:05:10.660 --> 01:05:13.380]   sort of scamming itself, except actually over time
[01:05:13.380 --> 01:05:15.340]   for the most part, it works pretty well.
[01:05:15.340 --> 01:05:17.980]   But then we pick bits and pieces to be like outrage show.
[01:05:17.980 --> 01:05:20.340]   - This is really interesting.
[01:05:20.340 --> 01:05:24.380]   I feel like most of the time on this show,
[01:05:24.380 --> 01:05:27.500]   Glenn and Dwight and I, we're like playing pool
[01:05:27.500 --> 01:05:30.140]   and all of a sudden Phil comes in and he's got his cue
[01:05:30.140 --> 01:05:32.580]   in a case and he's opening it up.
[01:05:32.580 --> 01:05:34.420]   (laughing)
[01:05:34.420 --> 01:05:37.980]   He's saying, let me show you how the game is played.
[01:05:37.980 --> 01:05:39.900]   I mean, seriously, you're the pro.
[01:05:39.900 --> 01:05:40.780]   You're the pro from Dover.
[01:05:40.780 --> 01:05:43.020]   You can't understand how this stuff works.
[01:05:43.020 --> 01:05:45.300]   And you've been in there, you've got that mindset.
[01:05:45.300 --> 01:05:46.540]   So it's really great.
[01:05:46.540 --> 01:05:47.380]   It's really great to this.
[01:05:47.380 --> 01:05:50.340]   And the other thing I like about you, Phil, is you're thoughtful.
[01:05:50.340 --> 01:05:52.620]   And so even as you're going through this process,
[01:05:52.620 --> 01:05:57.300]   you're kind of self-aware about what's going on.
[01:05:57.300 --> 01:05:59.100]   I mean, the problem with crypto,
[01:05:59.100 --> 01:06:00.060]   if you're investing in it,
[01:06:00.060 --> 01:06:05.060]   is it's as purely as speculative investment as it can be, right?
[01:06:05.060 --> 01:06:07.860]   - It's all a scam, yeah, but definitionally.
[01:06:07.860 --> 01:06:09.740]   - Yeah. - It's true value is zero.
[01:06:09.740 --> 01:06:12.820]   - There is no value. - It's true value is zero.
[01:06:12.820 --> 01:06:15.860]   But can I tell you this, gold is the same
[01:06:15.860 --> 01:06:20.180]   because gold has a small industrial value.
[01:06:20.180 --> 01:06:21.980]   When you buy gold, you're not buying it
[01:06:21.980 --> 01:06:23.580]   for its industrial value.
[01:06:23.580 --> 01:06:26.540]   You're buying it because as a speculative investment,
[01:06:26.540 --> 01:06:28.180]   you think it's gonna be worth more tomorrow
[01:06:28.180 --> 01:06:30.660]   'cause somebody's gonna pay more, right?
[01:06:30.660 --> 01:06:32.140]   - It's not the same as gold.
[01:06:32.140 --> 01:06:36.780]   Zero connection, like no connection to objective reality
[01:06:36.780 --> 01:06:38.780]   is very different from a small connection to objective.
[01:06:38.780 --> 01:06:40.700]   (laughing)
[01:06:40.700 --> 01:06:44.100]   - Yeah, 'cause honestly, if a stock doesn't pay a dividend,
[01:06:44.100 --> 01:06:45.620]   you're buying a stock and a company
[01:06:45.620 --> 01:06:50.060]   doesn't really give you ownership of anything tangible
[01:06:50.060 --> 01:06:52.180]   because without the dividend,
[01:06:52.180 --> 01:06:54.860]   there's no payback if the company does well.
[01:06:54.860 --> 01:06:56.060]   Even when you're buying stock,
[01:06:56.060 --> 01:06:58.320]   you're buying something that you're presuming
[01:06:58.320 --> 01:07:02.780]   is gonna go up in value based on the news or whatever.
[01:07:02.780 --> 01:07:06.580]   So there's an all investments are somewhat speculative.
[01:07:06.580 --> 01:07:07.580]   - Or somewhat. - But you're saying
[01:07:07.580 --> 01:07:12.580]   even if stock, you are in theory,
[01:07:12.580 --> 01:07:17.900]   your value goes up if the quality of the product
[01:07:17.900 --> 01:07:20.380]   is good enough to warn it to go up.
[01:07:20.380 --> 01:07:22.900]   There are other factors like the news
[01:07:22.900 --> 01:07:24.900]   and there is speculation.
[01:07:24.900 --> 01:07:28.700]   But if, I mean, look at Apple,
[01:07:28.700 --> 01:07:33.180]   Apple's products were lackluster and dying on the vine
[01:07:33.180 --> 01:07:36.340]   and Steve Jobs came in and made good products.
[01:07:36.340 --> 01:07:38.900]   Some degree in illusion, unless a company buys back
[01:07:38.900 --> 01:07:41.540]   its stock, takes its profits and buys back its stock
[01:07:41.540 --> 01:07:44.300]   increasing your value or gives you a dividend,
[01:07:44.300 --> 01:07:48.860]   the actual stock value is what investors make up.
[01:07:48.860 --> 01:07:52.020]   - Yes, but the horror. - Look at GameStop.
[01:07:52.020 --> 01:07:55.580]   It wasn't 'cause their business suddenly was great.
[01:07:55.580 --> 01:07:57.740]   - No, that was a joke. - But that's what I'm saying
[01:07:57.740 --> 01:08:00.500]   is that kind of even stock investments
[01:08:00.500 --> 01:08:02.980]   are somewhat in that realm of speculative.
[01:08:02.980 --> 01:08:04.980]   But you made an excellent point.
[01:08:04.980 --> 01:08:07.980]   - So the even the smallest attachment to reality
[01:08:07.980 --> 01:08:09.460]   is better than zero.
[01:08:09.460 --> 01:08:11.180]   It's like a seed.
[01:08:11.180 --> 01:08:14.020]   It's a seed and everything else builds upon it.
[01:08:14.020 --> 01:08:15.900]   There are no seeds in crypto.
[01:08:15.900 --> 01:08:17.900]   - Yeah, if you buy pork belly futures,
[01:08:17.900 --> 01:08:19.620]   you could wind up with a bunch of them on your front lawn
[01:08:19.620 --> 01:08:21.020]   if you're not careful.
[01:08:21.020 --> 01:08:22.860]   You like the contract, Expire.
[01:08:22.860 --> 01:08:24.980]   - Gold, like yes, gold, you're not buying
[01:08:24.980 --> 01:08:27.340]   for speculative for its industrial value,
[01:08:27.340 --> 01:08:28.740]   but there's only gold.
[01:08:28.740 --> 01:08:31.500]   There's not like a gold two, gold three,
[01:08:31.500 --> 01:08:33.100]   infinite number of other things that people
[01:08:33.100 --> 01:08:34.260]   can invent to be gold.
[01:08:34.260 --> 01:08:37.300]   It's an actual thing that there's one of.
[01:08:37.300 --> 01:08:38.300]   - Yeah.
[01:08:38.300 --> 01:08:42.620]   - A stock is, the value of a company is the current value
[01:08:42.620 --> 01:08:45.860]   given net present discounts of all future profits.
[01:08:45.860 --> 01:08:47.220]   That's the floor of it.
[01:08:47.220 --> 01:08:49.180]   So most companies are worth something
[01:08:49.180 --> 01:08:51.300]   and so there's a floor because it is
[01:08:51.300 --> 01:08:54.860]   like the present value of future profits.
[01:08:54.860 --> 01:08:57.980]   So there's like a floor below which I would buy it.
[01:08:57.980 --> 01:08:59.300]   - Right.
[01:08:59.300 --> 01:09:00.860]   - Because there's some connection to reality.
[01:09:00.860 --> 01:09:03.540]   - But the price of a stock often isn't related to that.
[01:09:03.540 --> 01:09:05.820]   - No, no, no, but because there's a floor,
[01:09:05.820 --> 01:09:08.980]   you can do all sorts of financialization on top of it.
[01:09:08.980 --> 01:09:10.900]   Because the floor is a real thing.
[01:09:10.900 --> 01:09:14.180]   So you look at GameStop, which was absolutely a meme stunk.
[01:09:14.180 --> 01:09:16.740]   - I can't see.
[01:09:16.740 --> 01:09:18.620]   - But what probably happened, right,
[01:09:18.620 --> 01:09:19.860]   is like it was before this,
[01:09:19.860 --> 01:09:22.260]   it was actually undervalued because people were like,
[01:09:22.260 --> 01:09:25.020]   oh, it's physical stores and they're never gonna do anything.
[01:09:25.020 --> 01:09:26.980]   And then it became a meme stunk
[01:09:26.980 --> 01:09:28.060]   and there was like a lot of activities
[01:09:28.060 --> 01:09:29.260]   and it's settled into a range
[01:09:29.260 --> 01:09:31.100]   that's way off what its highs were,
[01:09:31.100 --> 01:09:32.260]   but also significantly higher
[01:09:32.260 --> 01:09:36.060]   than it's been trading it for the past five years before.
[01:09:36.060 --> 01:09:38.820]   So like, there is a,
[01:09:38.820 --> 01:09:40.660]   I think there's a big difference
[01:09:40.660 --> 01:09:43.740]   between like a tenuous connection and absolutely not.
[01:09:43.740 --> 01:09:44.580]   - Yeah.
[01:09:44.580 --> 01:09:46.260]   - And I think we kind of underappreciate
[01:09:46.260 --> 01:09:47.260]   the difference between those two.
[01:09:47.260 --> 01:09:50.060]   - There's no floor in Bitcoin.
[01:09:50.060 --> 01:09:51.460]   (laughing)
[01:09:51.460 --> 01:09:53.180]   - Well, what is the SPF of that great thing?
[01:09:53.180 --> 01:09:54.420]   Matt Levine cites it all the time.
[01:09:54.420 --> 01:09:57.620]   Matt Levine interviewed SPF on stage was a year ago
[01:09:57.620 --> 01:09:59.700]   or last summer, last summer, I think.
[01:09:59.700 --> 01:10:01.980]   And Sam was talking about,
[01:10:01.980 --> 01:10:05.340]   well, if you have a box and you have a black box
[01:10:05.340 --> 01:10:07.380]   and you put stuff in it and you never take the cash out,
[01:10:07.380 --> 01:10:09.660]   no one knows the boxes and you speculate on the box.
[01:10:09.660 --> 01:10:11.060]   And I was kind of like, what the hell?
[01:10:11.060 --> 01:10:12.140]   And Matt Levine's response was,
[01:10:12.140 --> 01:10:13.860]   you just described a Ponzi scheme.
[01:10:13.860 --> 01:10:15.980]   He's like, well, it's not exactly a Ponzi.
[01:10:15.980 --> 01:10:16.820]   (laughing)
[01:10:16.820 --> 01:10:18.660]   And that was the classic moment
[01:10:18.660 --> 01:10:22.300]   when somebody, the magician described how the trick was done,
[01:10:22.300 --> 01:10:25.300]   probably not for his own good.
[01:10:25.300 --> 01:10:26.700]   - We're talking all around SPF.
[01:10:26.700 --> 01:10:28.980]   Let's talk about FTX and SPF
[01:10:28.980 --> 01:10:30.340]   in just a little bit.
[01:10:30.340 --> 01:10:31.180]   Gotta take a break.
[01:10:31.180 --> 01:10:34.100]   Plus, I think Phil needs to find a new destination.
[01:10:34.100 --> 01:10:36.340]   What are you, are you using a HAN to do that?
[01:10:36.340 --> 01:10:38.620]   Mm-hmm, yeah, absolutely.
[01:10:38.620 --> 01:10:39.780]   Tell me about, mm-hmm.
[01:10:39.780 --> 01:10:43.620]   - Are you still happy with the name?
[01:10:43.620 --> 01:10:45.900]   (laughing)
[01:10:45.900 --> 01:10:48.540]   - I like the watermark on this episode.
[01:10:48.540 --> 01:10:49.540]   - Phil is a good spark.
[01:10:49.540 --> 01:10:50.860]   - The watermark is great on his screen.
[01:10:50.860 --> 01:10:52.380]   - I love the name.
[01:10:52.380 --> 01:10:53.820]   - You love the name good, all right.
[01:10:53.820 --> 01:10:54.660]   - It's good.
[01:10:54.660 --> 01:10:56.660]   - It's, it's, it's, people keep talking about it.
[01:10:56.660 --> 01:10:57.500]   - It's true.
[01:10:57.500 --> 01:10:58.500]   - It's pretty, it's pretty fantastic.
[01:10:58.500 --> 01:11:00.220]   It's, it's easy to remember it, easy to pronounce it.
[01:11:00.220 --> 01:11:02.220]   - Oh look, he's suddenly in his office.
[01:11:02.220 --> 01:11:03.060]   - No.
[01:11:03.060 --> 01:11:04.060]   (laughing)
[01:11:04.060 --> 01:11:05.220]   - We're going to get people back to the office.
[01:11:05.220 --> 01:11:06.500]   So, all about butts and seats people.
[01:11:06.500 --> 01:11:08.620]   - It's really, your timing was very good,
[01:11:08.620 --> 01:11:10.540]   of course, 'cause of COVID,
[01:11:10.540 --> 01:11:13.140]   everybody started to use Zoom and other apps.
[01:11:13.140 --> 01:11:14.740]   Mm-hmm, is for Mac and Windows,
[01:11:14.740 --> 01:11:17.020]   and it lets you, as you can see,
[01:11:17.020 --> 01:11:19.460]   put yourself anywhere, but also more importantly,
[01:11:19.460 --> 01:11:23.060]   maybe it allows you to do presentations, which is great.
[01:11:23.060 --> 01:11:24.700]   I mean, that's, that's very cool.
[01:11:24.700 --> 01:11:28.420]   And have over the shoulder shots like they do in real TV.
[01:11:28.420 --> 01:11:29.500]   And all of that.
[01:11:29.500 --> 01:11:31.900]   - I have a good description of mm-hmm as an outsider,
[01:11:31.900 --> 01:11:34.100]   which is mm-hmm, is OBS,
[01:11:34.100 --> 01:11:35.980]   if OBS made sense to human beings.
[01:11:35.980 --> 01:11:37.900]   (laughing)
[01:11:37.900 --> 01:11:39.820]   So for those of you who have opened,
[01:11:39.820 --> 01:11:42.700]   open broadcast system is called OBS, yeah.
[01:11:42.700 --> 01:11:44.180]   Which I've used, and you know, it's like,
[01:11:44.180 --> 01:11:46.100]   it's manageable and it does really unique things,
[01:11:46.100 --> 01:11:47.660]   but I feel what I'm done with it,
[01:11:47.660 --> 01:11:49.500]   like I've, like I've been,
[01:11:49.500 --> 01:11:52.860]   illegally engaging in surgical practice.
[01:11:52.860 --> 01:11:54.340]   - You think you've been generating Bitcoin
[01:11:54.340 --> 01:11:55.180]   and behind the scenes.
[01:11:55.180 --> 01:11:57.460]   - Yeah, it's really, it's like, I've actually,
[01:11:57.460 --> 01:11:59.980]   so I use OBS when I wanna do a Let's Play stream,
[01:11:59.980 --> 01:12:02.220]   which I do sometimes for the club and stuff,
[01:12:02.220 --> 01:12:03.100]   we play games.
[01:12:03.100 --> 01:12:04.420]   Could I use a horn to do that?
[01:12:04.420 --> 01:12:05.580]   (laughing)
[01:12:05.580 --> 01:12:07.060]   - To do that. - Yeah.
[01:12:07.060 --> 01:12:09.180]   So I can put a picture of the game
[01:12:09.180 --> 01:12:11.940]   and it probably do a better job coming to think of it.
[01:12:11.940 --> 01:12:14.540]   - That's a, does a lot of stuff you can do.
[01:12:14.540 --> 01:12:17.100]   The main idea is, you know,
[01:12:17.100 --> 01:12:18.700]   it's about communication superpowers.
[01:12:18.700 --> 01:12:19.540]   - Yeah. - I think,
[01:12:19.540 --> 01:12:23.300]   is like, it's like a warm-up
[01:12:23.300 --> 01:12:25.940]   to the rest of your life of not hating being on video.
[01:12:25.940 --> 01:12:28.180]   (laughing)
[01:12:28.180 --> 01:12:33.660]   - The name, the name reminds me of that fictional search engine
[01:12:33.660 --> 01:12:36.580]   in The Good Wife and The Good Fight Chum Hum.
[01:12:36.580 --> 01:12:38.820]   (laughing)
[01:12:38.820 --> 01:12:42.100]   The Good Fight, may it rest in peace.
[01:12:42.100 --> 01:12:43.420]   - Oh, what a great show, huh?
[01:12:43.420 --> 01:12:44.260]   It was a great show.
[01:12:44.260 --> 01:12:45.900]   - And a great show for technologists,
[01:12:45.900 --> 01:12:49.700]   'cause they always covered like real deal stuff, you know.
[01:12:49.700 --> 01:12:51.060]   - Yes. - Including probably kidneys
[01:12:51.060 --> 01:12:53.620]   in the, in the ice-filled bathtubs.
[01:12:53.620 --> 01:12:54.620]   (laughing)
[01:12:54.620 --> 01:12:58.980]   - Mm-hmm, is M-M-H-M-M.AP.
[01:12:58.980 --> 01:13:00.940]   Definitely worth taking a look at.
[01:13:00.940 --> 01:13:05.020]   And we're so glad to have its founder Phil Libben.
[01:13:05.020 --> 01:13:06.300]   I do also wanna talk about it,
[01:13:06.300 --> 01:13:07.500]   I never know just a little bit,
[01:13:07.500 --> 01:13:12.300]   but first a word, (speaking in foreign language)
[01:13:12.300 --> 01:13:14.300]   Now, we just talked about the video
[01:13:14.300 --> 01:13:16.180]   in your next conference call.
[01:13:16.180 --> 01:13:17.700]   What about the audio?
[01:13:17.700 --> 01:13:20.300]   And I think everybody knows,
[01:13:20.300 --> 01:13:22.060]   and if they don't, you should know,
[01:13:22.060 --> 01:13:23.420]   you can have great video.
[01:13:23.420 --> 01:13:26.020]   If the audio's bad, it's over.
[01:13:26.020 --> 01:13:27.220]   Game over, man.
[01:13:27.220 --> 01:13:28.500]   Game over.
[01:13:28.500 --> 01:13:30.940]   You gotta have good audio.
[01:13:30.940 --> 01:13:33.500]   And nowadays, this is problematic,
[01:13:33.500 --> 01:13:35.100]   'cause you're hybrid work, right?
[01:13:35.100 --> 01:13:38.700]   So there's people in the office, there's people at home.
[01:13:38.700 --> 01:13:39.780]   In order to have a meeting,
[01:13:39.780 --> 01:13:43.300]   you're gonna have, you know, a conference call.
[01:13:43.300 --> 01:13:46.460]   And that puts your IT professional in a tough spot.
[01:13:46.460 --> 01:13:48.420]   It means, you know, now you have to equip
[01:13:48.420 --> 01:13:51.420]   and support more spaces with audio
[01:13:51.420 --> 01:13:53.900]   and video conferencing systems.
[01:13:53.900 --> 01:13:56.220]   But, you know, you're also worried about the next,
[01:13:56.220 --> 01:13:59.300]   you know, email exploit, next spearfishing attack.
[01:13:59.300 --> 01:14:01.700]   You got a lot of issues with network security.
[01:14:01.700 --> 01:14:03.620]   You maybe you're doing your cloud shift,
[01:14:03.620 --> 01:14:04.980]   your infrastructure issues,
[01:14:04.980 --> 01:14:06.940]   and maybe you got, you know,
[01:14:06.940 --> 01:14:09.860]   you got problems with the card key system.
[01:14:09.860 --> 01:14:14.700]   So who has time to work on the audio in your meeting rooms?
[01:14:14.700 --> 01:14:17.380]   Now you can do it,
[01:14:17.380 --> 01:14:19.260]   and you don't have to think about it.
[01:14:19.260 --> 01:14:23.260]   An intelligent product that requires minimal effort from IT
[01:14:23.260 --> 01:14:25.660]   to deploy and manage its scale with a bonus
[01:14:25.660 --> 01:14:29.300]   of requiring zero end user training.
[01:14:29.300 --> 01:14:32.220]   And when it comes to conferencing in larger spaces,
[01:14:32.220 --> 01:14:33.580]   this is a great solution.
[01:14:33.580 --> 01:14:35.380]   You don't have to bring in some AV company
[01:14:35.380 --> 01:14:38.380]   to wire everything up and install it and maintain it
[01:14:38.380 --> 01:14:40.340]   and tweak it every single time.
[01:14:40.340 --> 01:14:43.220]   No, all you need is Nareva.
[01:14:43.220 --> 01:14:45.820]   And with Nareva, you get true full room,
[01:14:45.820 --> 01:14:47.800]   full room mic pickup.
[01:14:48.740 --> 01:14:51.620]   From just one or two microphone and speaker bars,
[01:14:51.620 --> 01:14:54.260]   to only if you've got a giant room.
[01:14:54.260 --> 01:14:55.900]   Compare that to all the microphones
[01:14:55.900 --> 01:14:58.300]   and the wiping down and the putting of the muffin
[01:14:58.300 --> 01:14:59.660]   and the speakers and the amps
[01:14:59.660 --> 01:15:01.460]   and the DSPs and the switchers.
[01:15:01.460 --> 01:15:05.260]   And you gotta tune it and know all this crazy in the cost.
[01:15:05.260 --> 01:15:07.300]   Nareva, you can install in most spaces
[01:15:07.300 --> 01:15:08.140]   in less than 30 minutes.
[01:15:08.140 --> 01:15:09.420]   Ever put up a sound bar?
[01:15:09.420 --> 01:15:10.740]   That's what it's like.
[01:15:10.740 --> 01:15:12.020]   For larger spaces, okay,
[01:15:12.020 --> 01:15:13.860]   you're gonna put up two, it's gonna take you an hour.
[01:15:13.860 --> 01:15:15.060]   Amazingly simple,
[01:15:15.060 --> 01:15:17.460]   no special expertise is required.
[01:15:17.460 --> 01:15:21.860]   You can manage and deploy it from your seat,
[01:15:21.860 --> 01:15:24.620]   adjust all your Nareva systems
[01:15:24.620 --> 01:15:26.620]   from their cloud based platform.
[01:15:26.620 --> 01:15:28.620]   It's called Nareva Console.
[01:15:28.620 --> 01:15:30.820]   Completely scalable for large organizations
[01:15:30.820 --> 01:15:32.220]   and the sound is great.
[01:15:32.220 --> 01:15:34.540]   Their patented microphone, miss technology,
[01:15:34.540 --> 01:15:36.520]   puts thousands of microphones in your space.
[01:15:36.520 --> 01:15:38.100]   People can walk around, they can move around,
[01:15:38.100 --> 01:15:39.620]   they can face any way they want.
[01:15:39.620 --> 01:15:41.820]   They can socially distance like they want.
[01:15:41.820 --> 01:15:45.460]   It's suddenly, it's flexible, it's easy.
[01:15:45.460 --> 01:15:47.140]   Users don't even have to think about it.
[01:15:47.140 --> 01:15:48.580]   It just works.
[01:15:48.580 --> 01:15:49.940]   Now compare that with installations
[01:15:49.940 --> 01:15:51.420]   for traditional systems.
[01:15:51.420 --> 01:15:53.580]   They could take your room down for days,
[01:15:53.580 --> 01:15:57.260]   cost thousands and thousands and thousands of dollars
[01:15:57.260 --> 01:15:59.100]   and require the IT guy to come down.
[01:15:59.100 --> 01:16:01.700]   You need an AV squad, right?
[01:16:01.700 --> 01:16:03.540]   They're gonna come down the hall.
[01:16:03.540 --> 01:16:08.380]   And now you can get 50% off on a Nareva HTL 300 system.
[01:16:08.380 --> 01:16:10.900]   That's perfect for a mid-sized room.
[01:16:10.900 --> 01:16:12.140]   Just get an online demo
[01:16:12.140 --> 01:16:14.900]   on buy before December 16th, 2022.
[01:16:14.900 --> 01:16:18.140]   NUR EVA.COM/TWIT.
[01:16:18.140 --> 01:16:20.740]   This is a solution as time has come.
[01:16:20.740 --> 01:16:24.700]   The right way to do audio for your next HTL,
[01:16:24.700 --> 01:16:27.220]   your next meeting, your next conference,
[01:16:27.220 --> 01:16:28.580]   your next all hands.
[01:16:28.580 --> 01:16:32.580]   NUR EVA, Noreva.COM/TWIT.
[01:16:32.580 --> 01:16:35.380]   We thank them so much for their support.
[01:16:35.380 --> 01:16:37.020]   For the show and the network,
[01:16:37.020 --> 01:16:38.260]   they've been with us for a long time.
[01:16:38.260 --> 01:16:39.380]   We really liked the product
[01:16:39.380 --> 01:16:41.180]   and we're really glad to share it with you.
[01:16:41.180 --> 01:16:43.940]   You do us a favor though and use Noreva.COM/TWIT
[01:16:43.940 --> 01:16:45.620]   so they know you saw it here.
[01:16:45.620 --> 01:16:47.020]   Thank you, Noreva.
[01:16:47.020 --> 01:16:53.020]   I do wanna talk, so tell me about bending spoons,
[01:16:53.020 --> 01:16:54.340]   Phil, who are these people?
[01:16:54.340 --> 01:16:56.340]   They just bought Evernote.
[01:16:56.340 --> 01:16:58.280]   Is it kind of the end of Evernote?
[01:16:58.280 --> 01:17:02.660]   I don't think so.
[01:17:02.660 --> 01:17:04.260]   I don't actually know that much about it.
[01:17:04.260 --> 01:17:05.940]   It's been eight years since I've been with--
[01:17:05.940 --> 01:17:07.340]   I know, but you must still,
[01:17:07.340 --> 01:17:10.660]   your heart is still right a little bit.
[01:17:10.660 --> 01:17:12.620]   I left my heart and said, "Let's just go."
[01:17:12.620 --> 01:17:14.820]   But I'm not even working, so I don't know.
[01:17:14.820 --> 01:17:17.780]   Rewarded, found.
[01:17:17.780 --> 01:17:22.140]   Yeah, look, I still use Evernote every day.
[01:17:22.140 --> 01:17:23.660]   I have a lot of friends there.
[01:17:23.660 --> 01:17:26.060]   It seems like a good outcome.
[01:17:26.060 --> 01:17:28.260]   They bought a filmic and they've done a,
[01:17:28.260 --> 01:17:30.340]   but mostly what they do, video stuff.
[01:17:30.340 --> 01:17:32.620]   So it seemed like a little weird.
[01:17:32.620 --> 01:17:33.900]   Was it that the owners,
[01:17:33.900 --> 01:17:35.460]   what just wanted to get out of from under it?
[01:17:35.460 --> 01:17:36.700]   Was it struggling?
[01:17:36.700 --> 01:17:37.540]   Do you know?
[01:17:37.540 --> 01:17:40.580]   I don't think it was struggling.
[01:17:40.580 --> 01:17:44.460]   So I continue to be a shareholder of it.
[01:17:44.460 --> 01:17:47.700]   But again, I've made the decision when I left
[01:17:47.700 --> 01:17:48.820]   about eight years ago.
[01:17:48.820 --> 01:17:54.820]   So this was like 2015, I think 2014, 2015.
[01:17:54.820 --> 01:17:57.300]   I said it to replace myself as the CEO.
[01:17:57.300 --> 01:18:00.980]   And my original plan was, "We'll get a CEO."
[01:18:00.980 --> 01:18:03.980]   And then I'll stay on as like executive chairman
[01:18:03.980 --> 01:18:04.940]   and I'll do product stuff.
[01:18:04.940 --> 01:18:06.420]   I'll do like a strategic re.
[01:18:06.420 --> 01:18:08.820]   I kind of wanted to do what like,
[01:18:08.820 --> 01:18:10.460]   Reid Hoffman did at LinkedIn,
[01:18:10.460 --> 01:18:11.580]   when he brought Jeff on.
[01:18:11.580 --> 01:18:13.020]   That was kind of my model.
[01:18:13.020 --> 01:18:15.460]   And I knew there was like a 50% chance
[01:18:15.460 --> 01:18:16.820]   that it would work and a figure of 10 chance
[01:18:16.820 --> 01:18:17.660]   that it wouldn't because like,
[01:18:17.660 --> 01:18:18.700]   you know, you bring in a CEO,
[01:18:18.700 --> 01:18:19.820]   like what's actually gonna happen
[01:18:19.820 --> 01:18:22.980]   is gonna depend very much on, you know, the new CEO.
[01:18:22.980 --> 01:18:28.220]   And so we did a search and it turned out
[01:18:28.220 --> 01:18:30.820]   within a few months of Chris O'Neill,
[01:18:30.820 --> 01:18:32.540]   it was the CEO who replaced me
[01:18:32.540 --> 01:18:35.260]   and then Ian Small took over from that.
[01:18:35.260 --> 01:18:36.660]   It turns out within a few months that like,
[01:18:36.660 --> 01:18:38.660]   yeah, like me hovering around was just like,
[01:18:38.660 --> 01:18:40.220]   way too difficult.
[01:18:40.220 --> 01:18:43.020]   It was way too difficult for me,
[01:18:43.020 --> 01:18:45.260]   for the new guy, for the company.
[01:18:45.260 --> 01:18:46.540]   It's just like it just made no sense.
[01:18:46.540 --> 01:18:48.140]   And so I made a decision about eight years ago
[01:18:48.140 --> 01:18:49.940]   that like, look, I'm, you know, okay,
[01:18:49.940 --> 01:18:51.620]   I gotta be out.
[01:18:51.620 --> 01:18:53.060]   And I gotta be out like completely,
[01:18:53.060 --> 01:18:54.380]   not like hovering around being like,
[01:18:54.380 --> 01:18:55.700]   you know, I would have done this.
[01:18:55.700 --> 01:18:56.540]   - Right.
[01:18:56.540 --> 01:18:58.100]   - You shouldn't really, are you sure about that?
[01:18:58.100 --> 01:19:00.740]   Like, 'cause the whole point is like,
[01:19:00.740 --> 01:19:02.100]   of course you would do things differently
[01:19:02.100 --> 01:19:02.940]   than I would have done them.
[01:19:02.940 --> 01:19:06.300]   That's why we decided to have him and not me.
[01:19:06.300 --> 01:19:08.220]   So I thought the best thing I could do
[01:19:08.220 --> 01:19:10.260]   is like, hey, I'm around for any kind of help
[01:19:10.260 --> 01:19:11.060]   if you ever need it.
[01:19:11.060 --> 01:19:13.620]   And I'm a supporter of the company and I'm a friend,
[01:19:13.620 --> 01:19:15.100]   but I'm not gonna hang around and I'm not.
[01:19:15.100 --> 01:19:17.660]   - What year was that that you kind of said, okay?
[01:19:17.660 --> 01:19:20.460]   - Oh no, 2014 or 2015.
[01:19:20.460 --> 01:19:22.900]   So it was like, it was a long time ago
[01:19:22.900 --> 01:19:24.780]   in a galaxy far, far away.
[01:19:24.780 --> 01:19:25.940]   And I--
[01:19:25.940 --> 01:19:27.740]   - Chris O'Neill took over.
[01:19:27.740 --> 01:19:29.860]   - Chris O'Neill took over and then he was there
[01:19:29.860 --> 01:19:31.860]   for a few years and then Ian Small took over
[01:19:31.860 --> 01:19:33.140]   and he's there now.
[01:19:35.260 --> 01:19:38.020]   - The role of Vata, who was the, the, at Sequoia,
[01:19:38.020 --> 01:19:39.900]   who was currently the senior shooter of Sequoia
[01:19:39.900 --> 01:19:42.220]   was kind of the main investor and never known.
[01:19:42.220 --> 01:19:45.100]   But I was there and he's still on my board at, mm-hmm.
[01:19:45.100 --> 01:19:47.500]   So, you know, I've kept close to a bunch of the people,
[01:19:47.500 --> 01:19:49.300]   obviously, so I have friends there.
[01:19:49.300 --> 01:19:53.200]   And I think it's, I think,
[01:19:53.200 --> 01:19:55.100]   bending spoons bought it.
[01:19:55.100 --> 01:19:56.540]   Like, why would they buy it?
[01:19:56.540 --> 01:19:57.820]   Well, they bought it because they love it
[01:19:57.820 --> 01:19:59.060]   because they think it's a great app
[01:19:59.060 --> 01:20:01.820]   and because they think they can make it even more successful.
[01:20:01.820 --> 01:20:03.820]   Like, this is not a, you know,
[01:20:03.820 --> 01:20:06.860]   there's no like magical nefarious reasons why an app company
[01:20:06.860 --> 01:20:09.020]   would buy something if they just intended to
[01:20:09.020 --> 01:20:09.940]   not do anything with it.
[01:20:09.940 --> 01:20:11.020]   So, I feel pretty good about it.
[01:20:11.020 --> 01:20:12.740]   But again, I don't wanna overstate
[01:20:12.740 --> 01:20:15.340]   my level of knowledge or involvement thing.
[01:20:15.340 --> 01:20:16.180]   So.
[01:20:16.180 --> 01:20:17.820]   - Well, I think, you know,
[01:20:17.820 --> 01:20:21.180]   boy, I was such a huge fan of Evernote.
[01:20:21.180 --> 01:20:22.980]   There's a--
[01:20:22.980 --> 01:20:23.820]   - I still do.
[01:20:23.820 --> 01:20:26.820]   - Did you read the blog post from Hit and Shaw,
[01:20:26.820 --> 01:20:29.460]   the history of Evernote?
[01:20:29.460 --> 01:20:32.020]   Or maybe I haven't seen it.
[01:20:32.020 --> 01:20:32.860]   - They do not.
[01:20:32.860 --> 01:20:35.180]   - This was, I recommend it.
[01:20:35.180 --> 01:20:36.540]   I don't know about its conclusions.
[01:20:36.540 --> 01:20:38.220]   And I, you know, without your input,
[01:20:38.220 --> 01:20:40.580]   I don't know if, you know,
[01:20:40.580 --> 01:20:42.340]   he says ahead of its time behind the curve
[01:20:42.340 --> 01:20:44.900]   why Evernote failed to realize his potential.
[01:20:44.900 --> 01:20:48.820]   He starts with Stapon Pachikov
[01:20:48.820 --> 01:20:52.140]   and you getting together, creating Evernote.
[01:20:52.140 --> 01:20:53.380]   That's about when I found it.
[01:20:53.380 --> 01:20:54.700]   I had been using OneNote
[01:20:54.700 --> 01:20:56.300]   and the thing I loved about Evernote
[01:20:56.300 --> 01:20:59.260]   was the ribbon thing that I think you brought to the table.
[01:20:59.260 --> 01:21:01.260]   This idea of this continuous note.
[01:21:02.180 --> 01:21:05.660]   I just loved it and put everything in Evernote
[01:21:05.660 --> 01:21:08.220]   for a long time.
[01:21:08.220 --> 01:21:10.220]   It was, long after you left,
[01:21:10.220 --> 01:21:13.100]   it was, I think when they went to the subscription model
[01:21:13.100 --> 01:21:14.140]   that I finally said, you know,
[01:21:14.140 --> 01:21:15.300]   I'm gonna find another solution.
[01:21:15.300 --> 01:21:18.740]   And nowadays there are a lot of open source free solutions.
[01:21:18.740 --> 01:21:21.420]   This has become a very crowded market
[01:21:21.420 --> 01:21:24.380]   with a lot of different segments of the market.
[01:21:24.380 --> 01:21:27.100]   Note taking by itself has, you know,
[01:21:27.100 --> 01:21:30.780]   become, you know, zettled costin and all this stuff.
[01:21:30.780 --> 01:21:32.820]   But Evernote for years was great.
[01:21:32.820 --> 01:21:34.580]   Were you there when they did the separate apps,
[01:21:34.580 --> 01:21:38.180]   like the Hello app and the Food app and all of that?
[01:21:38.180 --> 01:21:39.660]   - Yeah, so Evernote.
[01:21:39.660 --> 01:21:41.260]   - But then they killed it.
[01:21:41.260 --> 01:21:45.460]   - Well, so it started, there was a company called Evernote,
[01:21:45.460 --> 01:21:46.460]   it was a different company.
[01:21:46.460 --> 01:21:48.660]   We had a different capital and it's logo
[01:21:48.660 --> 01:21:50.660]   was like this like flying toilet paper.
[01:21:50.660 --> 01:21:52.740]   (laughing)
[01:21:52.740 --> 01:21:55.340]   - And not a great logo, okay, good.
[01:21:55.340 --> 01:21:56.500]   - Some other ones best logo.
[01:21:56.500 --> 01:21:59.740]   But, and that was started by Stapon.
[01:21:59.740 --> 01:22:03.300]   Patrick Gove was brilliant, brilliant entrepreneur and inventor.
[01:22:03.300 --> 01:22:07.980]   And then I had just sold with my team,
[01:22:07.980 --> 01:22:09.300]   and they were in Silicon Valley.
[01:22:09.300 --> 01:22:11.340]   I had just sold my second company in Boston
[01:22:11.340 --> 01:22:15.180]   and started working on what I was calling ribbon.
[01:22:15.180 --> 01:22:16.380]   As a way, it's like a ribbon,
[01:22:16.380 --> 01:22:17.260]   tire ribbon, roger finger,
[01:22:17.260 --> 01:22:19.060]   to a river of healthy, remember stuff
[01:22:19.060 --> 01:22:21.460]   that I also wanted to build, like an infinite memory.
[01:22:21.460 --> 01:22:24.420]   Missed upon and we just sort of really hit it off
[01:22:24.420 --> 01:22:26.460]   and decided to kind of merge the two companies.
[01:22:26.460 --> 01:22:28.900]   And so we recreated Evernote because it made a new corporate entity
[01:22:28.900 --> 01:22:30.340]   that was called Evernote in 2007.
[01:22:30.340 --> 01:22:32.580]   - No, no uppercase then, one word.
[01:22:32.580 --> 01:22:35.580]   - And yeah, so the thing that most people know
[01:22:35.580 --> 01:22:37.140]   with the elephant and all that stuff,
[01:22:37.140 --> 01:22:38.900]   that was, yeah, that's what we started.
[01:22:38.900 --> 01:22:40.860]   - Elephant never forgets, yeah.
[01:22:40.860 --> 01:22:43.540]   - And yeah, I remember everything was the slogan.
[01:22:43.540 --> 01:22:45.380]   That was still the best thing I've ever written.
[01:22:45.380 --> 01:22:46.980]   It's kind of sad for me, it's like the best thing.
[01:22:46.980 --> 01:22:48.980]   I'm probably ever right in my life as those two words.
[01:22:48.980 --> 01:22:50.300]   Just remember everything.
[01:22:50.300 --> 01:22:51.780]   (laughing)
[01:22:51.780 --> 01:22:54.980]   And yeah, I was there for the first nine years
[01:22:54.980 --> 01:22:56.460]   and then I stayed on as I think chairman
[01:22:56.460 --> 01:22:59.100]   for another year after that.
[01:22:59.100 --> 01:23:01.980]   But yeah, we did a bunch of different apps.
[01:23:01.980 --> 01:23:02.820]   We did a lot of stuff.
[01:23:02.820 --> 01:23:07.820]   I think we kind of made productivity something
[01:23:07.820 --> 01:23:09.780]   that was cool again, I think.
[01:23:09.780 --> 01:23:11.660]   - You were the first, yeah.
[01:23:11.660 --> 01:23:12.620]   I mean, one note was there,
[01:23:12.620 --> 01:23:14.660]   but one note was way too complicated.
[01:23:14.660 --> 01:23:16.820]   - Yeah, a bunch of people came after us, you know,
[01:23:16.820 --> 01:23:18.100]   afterwards, I'm happy to see it.
[01:23:18.100 --> 01:23:19.700]   I think the productivity industry right now
[01:23:19.700 --> 01:23:21.380]   is better than it's ever been.
[01:23:21.380 --> 01:23:23.780]   And that's cool, I feel a sense of pride
[01:23:23.780 --> 01:23:25.620]   to having contributed to that.
[01:23:25.620 --> 01:23:30.620]   - This is the page in 2008, I got it on the way back machine.
[01:23:30.620 --> 01:23:34.020]   This is the Remember Ever, see the cocktail napkin,
[01:23:34.020 --> 01:23:35.660]   remember everything.
[01:23:35.660 --> 01:23:38.500]   God, I just, those were the days, you know?
[01:23:38.500 --> 01:23:41.220]   - They've got about 20 smartphone in that image.
[01:23:41.220 --> 01:23:44.260]   - Yeah, this is when Twitter was young
[01:23:44.260 --> 01:23:46.980]   and the iPhone just barely had 3G.
[01:23:46.980 --> 01:23:49.940]   Those were the days, my friends.
[01:23:49.940 --> 01:23:51.980]   - Those were the iPhone, yeah, this was the first iPhone
[01:23:51.980 --> 01:23:53.740]   and that shot was probably their web app
[01:23:53.740 --> 01:23:55.380]   because it was right before apps.
[01:23:55.380 --> 01:23:56.540]   - Yeah, yeah.
[01:23:56.540 --> 01:23:59.380]   - So like, I think we had, we were on the app store
[01:23:59.380 --> 01:24:00.220]   on the first day.
[01:24:00.220 --> 01:24:03.620]   Yeah, we had a bunch of different apps.
[01:24:03.620 --> 01:24:07.260]   You know, a few hundred million users, I think total.
[01:24:07.260 --> 01:24:12.260]   And then, like I said, my plan was to,
[01:24:12.260 --> 01:24:15.500]   I basically decided once we got to like, I don't know,
[01:24:15.500 --> 01:24:17.620]   400 people, 450 people, I was like,
[01:24:17.620 --> 01:24:18.460]   I'm just not having to come on.
[01:24:18.460 --> 01:24:20.220]   - That's a fake company, yeah.
[01:24:20.220 --> 01:24:22.980]   - The company and I thought I'm just not,
[01:24:22.980 --> 01:24:25.740]   like I thought we could afford, we could get a better CEO
[01:24:25.740 --> 01:24:27.740]   because companies could sell.
[01:24:27.740 --> 01:24:29.340]   - That's true, that's true, Phil.
[01:24:29.340 --> 01:24:31.860]   (laughing)
[01:24:31.860 --> 01:24:34.700]   - And, you know, we talked a lot about being
[01:24:34.700 --> 01:24:36.940]   a hundred year startup, I think it was on your show.
[01:24:36.940 --> 01:24:38.260]   - I remember.
[01:24:38.260 --> 01:24:40.220]   - The hundred year startup meant like,
[01:24:40.220 --> 01:24:41.620]   that we want to be around in a hundred years,
[01:24:41.620 --> 01:24:42.620]   but we still want to be a startup.
[01:24:42.620 --> 01:24:45.180]   We still want to be like innovating.
[01:24:45.180 --> 01:24:47.420]   And a big part of the hundred year startup idea
[01:24:47.420 --> 01:24:49.100]   was like me getting comfortable with the fact
[01:24:49.100 --> 01:24:51.180]   that I'm not going to be the CEO for a hundred years.
[01:24:51.180 --> 01:24:52.380]   - Right, obvious.
[01:24:52.380 --> 01:24:54.940]   - So like, it has to be my job to get the next person
[01:24:54.940 --> 01:24:57.180]   who's better or else, you know, we failed.
[01:24:57.180 --> 01:24:59.420]   So once that happened, it was, again,
[01:24:59.420 --> 01:25:01.620]   it was time to step away when it became obvious to me
[01:25:01.620 --> 01:25:03.220]   that having two people hanging around
[01:25:03.220 --> 01:25:05.180]   and like making top decisions just wasn't going to be good
[01:25:05.180 --> 01:25:06.580]   for anyone, so.
[01:25:06.580 --> 01:25:10.940]   - Evernote is one of those rare apps that has,
[01:25:10.940 --> 01:25:13.580]   it doesn't have users, it has fans.
[01:25:13.580 --> 01:25:16.220]   And people will evangelize.
[01:25:16.220 --> 01:25:17.380]   - I was one of them.
[01:25:17.380 --> 01:25:19.500]   I was absolutely a fan.
[01:25:19.500 --> 01:25:24.500]   In a newsroom, Evernote, in the Houston Chronicle,
[01:25:24.500 --> 01:25:28.980]   reporters who got into Evernote would like become pests.
[01:25:28.980 --> 01:25:30.980]   You know, they would come up to you and go,
[01:25:30.980 --> 01:25:32.620]   are you not using Evernote?
[01:25:32.620 --> 01:25:35.140]   Why aren't you using, you know, it's like,
[01:25:35.140 --> 01:25:38.300]   it became something that was evangelical.
[01:25:38.300 --> 01:25:40.620]   And there aren't a lot of apps that are like that
[01:25:40.620 --> 01:25:42.540]   and Evernote certainly is one of them.
[01:25:42.540 --> 01:25:43.380]   - Yeah.
[01:25:43.380 --> 01:25:44.700]   - You know, the thing that was so great about it,
[01:25:44.700 --> 01:25:46.180]   I don't know when this feature was added,
[01:25:46.180 --> 01:25:48.140]   but I feel like it took it to the next level for me,
[01:25:48.140 --> 01:25:50.660]   'cause I've been using it for, I don't know, eight or 10 years.
[01:25:50.660 --> 01:25:53.340]   I was using Yo Jimbo, a bare bone.
[01:25:53.340 --> 01:25:56.620]   - I used Yo Jimbo from Rich Segal.
[01:25:56.620 --> 01:25:57.780]   Love Yo Jimbo.
[01:25:57.780 --> 01:25:59.660]   - It just didn't, I think it just didn't fit
[01:25:59.660 --> 01:26:00.940]   into their evolution.
[01:26:00.940 --> 01:26:02.980]   So I was like, ah, it's like Yo Jimbo is the thing
[01:26:02.980 --> 01:26:04.860]   that fit my brain best.
[01:26:04.860 --> 01:26:06.300]   And so when I counted Evernote, I'm like,
[01:26:06.300 --> 01:26:08.420]   oh, I'd actually figured out how to export Yo Jimbo
[01:26:08.420 --> 01:26:09.700]   to Evernote, it was great.
[01:26:09.700 --> 01:26:11.260]   And I was like, this is, I need a junk drawer
[01:26:11.260 --> 01:26:13.180]   from my brain that matches my brains
[01:26:13.180 --> 01:26:14.780]   in the Toronto Organization scheme,
[01:26:14.780 --> 01:26:16.260]   but the thing that took me over,
[01:26:16.260 --> 01:26:18.540]   the YS paid the subscription fee and still do,
[01:26:18.540 --> 01:26:21.540]   is the built-in OCR, where that was,
[01:26:21.540 --> 01:26:23.020]   that was not unheard of at the time,
[01:26:23.020 --> 01:26:24.780]   but it was pretty weak in a lot of apps.
[01:26:24.780 --> 01:26:27.060]   You had to use Acrobat have a paid subscription
[01:26:27.060 --> 01:26:28.180]   to Creative Cloud.
[01:26:28.180 --> 01:26:31.660]   And now I feel like the pervasiveness of OCR
[01:26:31.660 --> 01:26:34.140]   is especially Apple, the last couple of releases.
[01:26:34.140 --> 01:26:36.460]   I mean, they added this thing quietly
[01:26:36.460 --> 01:26:39.140]   where you could search in iOS 15
[01:26:39.140 --> 01:26:40.660]   before the release of iOS 16.
[01:26:40.660 --> 01:26:42.060]   Where only on the search screen,
[01:26:42.060 --> 01:26:44.980]   you could search for text in your photo library,
[01:26:44.980 --> 01:26:46.380]   you couldn't do it in photos,
[01:26:46.380 --> 01:26:47.740]   then they rolled it all out.
[01:26:47.740 --> 01:26:50.100]   And this notion that all text everywhere.
[01:26:50.100 --> 01:26:53.340]   So in Evernote now, in my Notes app and photos
[01:26:53.340 --> 01:26:55.660]   and almost everything I do everywhere,
[01:26:55.660 --> 01:27:00.660]   all graphical text is now fairly effectively searchable.
[01:27:00.660 --> 01:27:02.820]   So it's fairly effectively searchable,
[01:27:02.820 --> 01:27:04.260]   say that five times fast.
[01:27:04.260 --> 01:27:08.340]   That is a massive difference in like the history of humanity.
[01:27:08.340 --> 01:27:11.260]   Not just like, I mean, you know, data is great to store,
[01:27:11.260 --> 01:27:15.300]   but we have so much data that's not in text,
[01:27:15.300 --> 01:27:17.300]   entered, Unicode, whatever format.
[01:27:17.300 --> 01:27:20.140]   So anyway, Evernote, I felt like that was this big,
[01:27:20.140 --> 01:27:22.380]   eye-opening thing where like, I throw a thing in there,
[01:27:22.380 --> 01:27:24.140]   and at that time it took, I think, a few minutes
[01:27:24.140 --> 01:27:25.740]   sometimes to do the OCR,
[01:27:25.740 --> 01:27:27.820]   and now it's essentially instantaneous.
[01:27:27.820 --> 01:27:30.340]   And I just have, I don't have to worry about it anymore.
[01:27:30.340 --> 01:27:33.620]   It's just a seamless process across all these apps.
[01:27:33.620 --> 01:27:35.700]   >> Yeah, we did, I think we had a couple of innovations
[01:27:35.700 --> 01:27:37.700]   that are very much table stakes now
[01:27:37.700 --> 01:27:40.620]   that we kind of, we were mainstream with it first.
[01:27:40.620 --> 01:27:42.620]   You know, one of the OCR,
[01:27:42.620 --> 01:27:45.620]   one was just synchronizing automatically.
[01:27:45.620 --> 01:27:48.740]   It was the first time that I put something on my Mac
[01:27:48.740 --> 01:27:49.900]   and then pull it up on my iPhone.
[01:27:49.900 --> 01:27:50.740]   >> Huge.
[01:27:50.740 --> 01:27:52.340]   >> I don't have to like, I don't have to like,
[01:27:52.340 --> 01:27:53.900]   set up an FTP server,
[01:27:53.900 --> 01:27:56.500]   mask the DOM instance, whatever they're called now.
[01:27:56.500 --> 01:27:57.380]   Like it just worked.
[01:27:57.380 --> 01:27:58.900]   There was no, like, we were one of the first things
[01:27:58.900 --> 01:28:00.980]   that didn't have like the concept of a server.
[01:28:00.980 --> 01:28:04.740]   It wasn't the users didn't really have any like options,
[01:28:04.740 --> 01:28:08.020]   like did you want to use USB to move things over or FTP?
[01:28:08.020 --> 01:28:09.220]   It just worked.
[01:28:10.340 --> 01:28:11.380]   >> There's a lot of that kind of stuff.
[01:28:11.380 --> 01:28:13.100]   We were pre-cloud.
[01:28:13.100 --> 01:28:18.860]   Like the ubiquity of the cloud kind of came around
[01:28:18.860 --> 01:28:20.540]   after we were a couple years old already.
[01:28:20.540 --> 01:28:21.820]   We had our own data centers.
[01:28:21.820 --> 01:28:23.220]   Just like, you know, Twitter apparently does.
[01:28:23.220 --> 01:28:26.220]   Like we had to build our own data centers out.
[01:28:26.220 --> 01:28:28.300]   We were on the App Store from day one.
[01:28:28.300 --> 01:28:33.300]   We were kind of, as every company launched a mobile phone
[01:28:33.300 --> 01:28:34.900]   in an app, you know, we had Apple did it
[01:28:34.900 --> 01:28:37.700]   and then Google and then Blackberry and Palm
[01:28:37.700 --> 01:28:40.380]   and like all of these, you know, App Store is like,
[01:28:40.380 --> 01:28:42.860]   there was five apps that every device had to have,
[01:28:42.860 --> 01:28:44.300]   like on it, pre-installed.
[01:28:44.300 --> 01:28:48.900]   And it was always like Facebook, Twitter, a game,
[01:28:48.900 --> 01:28:50.980]   a web browser and I don't know.
[01:28:50.980 --> 01:28:52.580]   We were like, we were the default thing.
[01:28:52.580 --> 01:28:54.620]   And those are all thing accomplishments
[01:28:54.620 --> 01:28:55.460]   that I feel great about,
[01:28:55.460 --> 01:28:57.100]   I feel great about that part of that team.
[01:28:57.100 --> 01:28:57.940]   >> You should.
[01:28:57.940 --> 01:29:00.300]   >> And I think, but like, that's not enough.
[01:29:00.300 --> 01:29:01.460]   Now everyone does that.
[01:29:01.460 --> 01:29:04.420]   So it needs a new set of innovation.
[01:29:04.420 --> 01:29:06.820]   The stuff that Bending Spoon did,
[01:29:06.820 --> 01:29:08.980]   it's like honestly like, I hadn't heard of this company
[01:29:08.980 --> 01:29:11.020]   before, but I'd heard of their apps.
[01:29:11.020 --> 01:29:12.140]   >> Yes, and two.
[01:29:12.140 --> 01:29:14.020]   >> And the apps are cool and they're innovative
[01:29:14.020 --> 01:29:14.900]   and I feel hopeful.
[01:29:14.900 --> 01:29:15.740]   >> They're beautiful.
[01:29:15.740 --> 01:29:18.100]   >> You know, they're like, figure out the next amount
[01:29:18.100 --> 01:29:18.940]   of innovation.
[01:29:18.940 --> 01:29:20.220]   I mean, again, they wouldn't have bought it
[01:29:20.220 --> 01:29:22.180]   if they didn't think they can do it.
[01:29:22.180 --> 01:29:24.220]   >> Yuri Geller would never have founded the company.
[01:29:24.220 --> 01:29:25.060]   (laughing)
[01:29:25.060 --> 01:29:26.540]   >> Only a handful of getting confused.
[01:29:26.540 --> 01:29:29.460]   >> So I was pissed when I was like,
[01:29:29.460 --> 01:29:31.100]   this had better be a matrix reference
[01:29:31.100 --> 01:29:32.580]   and not a Yuri Geller.
[01:29:32.580 --> 01:29:33.900]   >> Oh good, you're right.
[01:29:33.900 --> 01:29:35.380]   >> Yeah, you're right.
[01:29:35.380 --> 01:29:39.180]   >> Because the Bending of Spoons in the Matrix was real.
[01:29:39.180 --> 01:29:41.700]   So that's the difference, you know, just wanna point that.
[01:29:41.700 --> 01:29:42.540]   >> He was definitely there.
[01:29:42.540 --> 01:29:43.380]   >> There it is.
[01:29:43.380 --> 01:29:44.220]   Look at, he's doing it.
[01:29:44.220 --> 01:29:45.300]   He's putting it up there.
[01:29:45.300 --> 01:29:46.140]   Look at that.
[01:29:46.140 --> 01:29:47.740]   How do you do that?
[01:29:47.740 --> 01:29:48.580]   Wow.
[01:29:48.580 --> 01:29:50.260]   >> It was definitely a Matrix reference.
[01:29:50.260 --> 01:29:51.260]   (laughing)
[01:29:51.260 --> 01:29:53.260]   I think they're too young to know who Yuri Geller was.
[01:29:53.260 --> 01:29:55.500]   (laughing)
[01:29:55.500 --> 01:29:57.180]   >> I'm old enough to know.
[01:29:57.180 --> 01:29:58.500]   >> One of the damn sites--
[01:29:58.500 --> 01:29:59.780]   >> The first book I ever bought, sorry.
[01:29:59.780 --> 01:30:01.380]   The first book I ever bought on Amazon,
[01:30:01.380 --> 01:30:03.420]   the first book I ever bought on the internet,
[01:30:03.420 --> 01:30:04.980]   was my first e-commerce purchase ever.
[01:30:04.980 --> 01:30:06.980]   It was in like, 1984.
[01:30:06.980 --> 01:30:08.820]   And it was a book called The Truth About Yuri Geller
[01:30:08.820 --> 01:30:09.980]   by J.H.H.H.D.
[01:30:09.980 --> 01:30:11.660]   >> James is the amazing Randy.
[01:30:11.660 --> 01:30:12.500]   >> Oh, he's amazing Randy.
[01:30:12.500 --> 01:30:13.340]   >> He's amazing Randy.
[01:30:13.340 --> 01:30:14.180]   >> Yeah.
[01:30:14.180 --> 01:30:15.940]   >> So it's all, so when I heard Bending Spoons,
[01:30:15.940 --> 01:30:17.340]   I'm like, better be a Matrix.
[01:30:17.340 --> 01:30:19.380]   (laughing)
[01:30:19.380 --> 01:30:21.140]   >> I'm thinking they're probably too young
[01:30:21.140 --> 01:30:22.940]   to remember Yuri Geller who was--
[01:30:22.940 --> 01:30:23.780]   >> Thankfully.
[01:30:23.780 --> 01:30:26.300]   >> A famous psychic who did a sleight of hand thing
[01:30:26.300 --> 01:30:27.300]   that made it look like.
[01:30:27.300 --> 01:30:28.540]   >> I can't bend the spoons here.
[01:30:28.540 --> 01:30:29.860]   There are fluorescent lights.
[01:30:29.860 --> 01:30:31.420]   (laughing)
[01:30:31.420 --> 01:30:32.420]   >> Which is one of the--
[01:30:32.420 --> 01:30:34.420]   (laughing)
[01:30:34.420 --> 01:30:35.260]   >> One of the down--
[01:30:35.260 --> 01:30:36.940]   >> Go ahead.
[01:30:36.940 --> 01:30:37.780]   >> You would just remember,
[01:30:37.780 --> 01:30:39.380]   because Yuri Geller claimed that he was bending spoons
[01:30:39.380 --> 01:30:40.380]   literally, we just take spoons,
[01:30:40.380 --> 01:30:41.220]   that was a trick, he was bending him,
[01:30:41.220 --> 01:30:42.700]   but he's bending him with psychic powers.
[01:30:42.700 --> 01:30:43.540]   >> Yes.
[01:30:43.540 --> 01:30:45.020]   >> And James Randy, you know, showed how he was,
[01:30:45.020 --> 01:30:46.900]   could also have been spoons in all sorts of ways.
[01:30:46.900 --> 01:30:47.900]   >> A lot too, yeah.
[01:30:47.900 --> 01:30:49.780]   >> And said, you know, I'm not saying that,
[01:30:49.780 --> 01:30:53.420]   that Yuri Geller isn't bending spoons with psychic powers.
[01:30:53.420 --> 01:30:54.540]   I'm just saying that if he is,
[01:30:54.540 --> 01:30:55.620]   he's doing it the hard way.
[01:30:55.620 --> 01:30:57.860]   (laughing)
[01:30:57.860 --> 01:31:01.980]   >> The great, amazing Randy.
[01:31:01.980 --> 01:31:02.820]   >> It's low stakes.
[01:31:02.820 --> 01:31:04.740]   >> You could have, you had telekinesis.
[01:31:04.740 --> 01:31:06.620]   I just feel like those are low stakes,
[01:31:06.620 --> 01:31:07.460]   then he's--
[01:31:07.460 --> 01:31:08.620]   >> Yeah, I would come up with something
[01:31:08.620 --> 01:31:09.860]   more interesting to do.
[01:31:09.860 --> 01:31:10.860]   >> Yeah, actually--
[01:31:10.860 --> 01:31:11.700]   >> Yeah, actually--
[01:31:11.700 --> 01:31:12.540]   >> Actually, yeah.
[01:31:12.540 --> 01:31:17.500]   >> The problem with a loyal,
[01:31:17.500 --> 01:31:20.340]   a vangelical fan base is they'll turn on you.
[01:31:20.340 --> 01:31:23.260]   They can turn on you,
[01:31:23.260 --> 01:31:26.140]   and you know, that's, you know,
[01:31:26.140 --> 01:31:29.020]   I think everybody who is, you know,
[01:31:29.020 --> 01:31:31.460]   buoyed up by these evangelical fans
[01:31:31.460 --> 01:31:33.260]   also realize there's a risk.
[01:31:33.260 --> 01:31:35.380]   And I think that at some point,
[01:31:35.380 --> 01:31:38.260]   Evernote lost some of its luster.
[01:31:38.260 --> 01:31:40.060]   Long after you were gone.
[01:31:40.060 --> 01:31:40.900]   >> Whoa.
[01:31:40.900 --> 01:31:41.740]   >> I hope they find it again,
[01:31:41.740 --> 01:31:43.060]   'cause it was a great program.
[01:31:43.060 --> 01:31:44.300]   It was way ahead of its time.
[01:31:44.300 --> 01:31:47.060]   And we all, you know, it's like your Palm Pilot.
[01:31:47.060 --> 01:31:48.500]   It's something that you remember
[01:31:48.500 --> 01:31:51.100]   and remember with love and affection.
[01:31:51.100 --> 01:31:52.500]   'Cause what a great product it was.
[01:31:52.500 --> 01:31:53.340]   >> Yeah, instant paper,
[01:31:53.340 --> 01:31:55.540]   remember all those as a monster paper?
[01:31:55.540 --> 01:31:58.020]   You know, I worked for Marco for a while,
[01:31:58.020 --> 01:31:59.660]   and I bought a publication, he started,
[01:31:59.660 --> 01:32:03.020]   and Marco is a fascinating guy.
[01:32:03.020 --> 01:32:05.540]   But you know, instant paper was like this great,
[01:32:05.540 --> 01:32:10.340]   it was that incredible era of needing to read things offline
[01:32:10.340 --> 01:32:11.380]   in a better format.
[01:32:11.380 --> 01:32:12.540]   And it felt like that also,
[01:32:12.540 --> 01:32:13.660]   it's one of those table stakes.
[01:32:13.660 --> 01:32:14.500]   You're saying is--
[01:32:14.500 --> 01:32:15.940]   >> It's built in every browser now.
[01:32:15.940 --> 01:32:17.820]   >> Yeah, every browser, but it's like you needed
[01:32:17.820 --> 01:32:20.700]   this mass group of people who are loyal to specific apps,
[01:32:20.700 --> 01:32:23.940]   sometimes paying, monthly, annual fees,
[01:32:23.940 --> 01:32:26.100]   to get this very simple thing, readability.
[01:32:26.100 --> 01:32:27.700]   One of the apps was readability.
[01:32:27.700 --> 01:32:29.700]   But then now as a,
[01:32:29.700 --> 01:32:31.340]   let's move towards greater accessibility,
[01:32:31.340 --> 01:32:33.020]   I think across all platforms,
[01:32:33.020 --> 01:32:34.740]   means that we get these things.
[01:32:34.740 --> 01:32:35.860]   I mean, accessibility, I have a friend
[01:32:35.860 --> 01:32:37.860]   who used to write about accessibility and design,
[01:32:37.860 --> 01:32:39.740]   and she was like, "Accessibility is something
[01:32:39.740 --> 01:32:42.060]   "that it works for everybody, for particular people.
[01:32:42.060 --> 01:32:45.460]   "It may help them access information better or tools,
[01:32:45.460 --> 01:32:47.540]   "but accessibility should be for everyone."
[01:32:47.540 --> 01:32:49.300]   And I think it turns out to be, which is--
[01:32:49.300 --> 01:32:50.140]   >> It does, everybody does.
[01:32:50.140 --> 01:32:50.980]   >> It does.
[01:32:50.980 --> 01:32:51.820]   >> Yeah, go ahead.
[01:32:51.820 --> 01:32:52.660]   >> Let me take--
[01:32:52.660 --> 01:32:55.700]   >> Leo, Leo was, I wanna go back to the thing
[01:32:55.700 --> 01:32:58.700]   you said about OneNote, and that it was very difficult
[01:32:58.700 --> 01:33:04.060]   to use, was OneNote, the app that was introduced
[01:33:04.060 --> 01:33:08.100]   as part of Microsoft's push towards a Windows tablet.
[01:33:08.100 --> 01:33:09.100]   Remember those big--
[01:33:09.100 --> 01:33:10.700]   >> Oh, yeah.
[01:33:10.700 --> 01:33:12.780]   >> Was that where OneNote came from?
[01:33:12.780 --> 01:33:14.100]   >> I don't know, but--
[01:33:14.100 --> 01:33:17.180]   >> Remember Bill Gates was, for 10 years,
[01:33:17.180 --> 01:33:20.940]   flogging tablets to no avail.
[01:33:20.940 --> 01:33:23.260]   I'm sure you guys remember, one year,
[01:33:23.260 --> 01:33:27.740]   I think it was Comdex, when they built houses
[01:33:27.740 --> 01:33:31.420]   in the parking lot of the Las Vegas Convention Center,
[01:33:31.420 --> 01:33:34.780]   and you'd go into the house, this is a big Microsoft booth,
[01:33:34.780 --> 01:33:36.420]   and you'd go to the house, and every room in the house
[01:33:36.420 --> 01:33:39.420]   had an actor with a tablet.
[01:33:39.420 --> 01:33:40.260]   >> Oh my gosh.
[01:33:40.260 --> 01:33:42.540]   >> Mom was in the kitchen, 'cause it was, you know,
[01:33:42.540 --> 01:33:46.180]   a while ago, dad was in the den, they had upstairs,
[01:33:46.180 --> 01:33:49.140]   the kid was upstairs, and they were all, you know,
[01:33:49.140 --> 01:33:52.020]   pretending they were using their tablets,
[01:33:52.020 --> 01:33:53.300]   and they were huge.
[01:33:53.300 --> 01:33:55.340]   >> They were like, they were big, they were clunky,
[01:33:55.340 --> 01:33:56.540]   they were awful.
[01:33:56.540 --> 01:33:58.660]   But yeah, you probably--
[01:33:58.660 --> 01:33:59.500]   >> Remember that's probably OneNote.
[01:33:59.500 --> 01:34:00.820]   >> I think that's where OneNote came from.
[01:34:00.820 --> 01:34:01.660]   >> Yeah, you probably were.
[01:34:01.660 --> 01:34:02.500]   >> You remember the story about that, too,
[01:34:02.500 --> 01:34:03.860]   Gates was totally behind it,
[01:34:03.860 --> 01:34:06.220]   but because of the siloization at Microsoft
[01:34:06.220 --> 01:34:09.940]   and the fiefdoms that I think have been broken down a bit
[01:34:09.940 --> 01:34:12.780]   in the last decade, that just before,
[01:34:12.780 --> 01:34:14.100]   I wanna say the launch of the tablet,
[01:34:14.100 --> 01:34:15.580]   if I'm remembering this right,
[01:34:15.580 --> 01:34:17.540]   the person who was in charge of Excel said
[01:34:17.540 --> 01:34:20.820]   you can't have it for, you can't have Excel for the tablet.
[01:34:20.820 --> 01:34:22.300]   I wish I was just trying to find the story,
[01:34:22.300 --> 01:34:23.540]   it's probably buried in a book somewhere,
[01:34:23.540 --> 01:34:25.740]   but it was, there was some, it wasn't sabotage,
[01:34:25.740 --> 01:34:28.220]   it's just like, we're not gonna let you use the apps.
[01:34:28.220 --> 01:34:29.420]   So that killed it.
[01:34:29.420 --> 01:34:32.020]   I think if Excel had come out in a Microsoft tablet,
[01:34:32.020 --> 01:34:33.220]   even if it was imperfect,
[01:34:33.220 --> 01:34:36.060]   it might have been its killer app for enough people.
[01:34:36.060 --> 01:34:36.900]   But--
[01:34:36.900 --> 01:34:37.780]   >> And that's company work.
[01:34:37.780 --> 01:34:38.700]   >> And that's I, VC.
[01:34:38.700 --> 01:34:39.660]   >> Yeah, hm?
[01:34:39.660 --> 01:34:41.380]   >> When I was first raising money for Never Note,
[01:34:41.380 --> 01:34:42.820]   Forever Note, I got asked,
[01:34:42.820 --> 01:34:46.300]   how are we gonna compete with OneNote?
[01:34:46.300 --> 01:34:47.140]   Because it was already out,
[01:34:47.140 --> 01:34:49.460]   and it was, how are you gonna compete with OneNote?
[01:34:49.460 --> 01:34:53.340]   And I said, well, some people are gonna need more than OneNote.
[01:34:53.340 --> 01:34:55.580]   (laughing)
[01:34:55.580 --> 01:34:59.260]   >> Tell your awards, man.
[01:34:59.260 --> 01:35:00.100]   >> I love it.
[01:35:00.100 --> 01:35:00.940]   >> I love it.
[01:35:00.940 --> 01:35:05.780]   >> November 17th, 2002, Bill Gates announced OneNote.
[01:35:05.780 --> 01:35:06.780]   >> Yeah.
[01:35:06.780 --> 01:35:10.260]   >> I remember I was a OneNote refugee when I moved to Ever Note.
[01:35:10.260 --> 01:35:14.780]   I was just, that was the solution for more than a decade
[01:35:14.780 --> 01:35:16.660]   for all my notes.
[01:35:16.660 --> 01:35:19.740]   >> Well, let's take a little break.
[01:35:19.740 --> 01:35:20.900]   We have much more to talk about.
[01:35:20.900 --> 01:35:21.900]   We have the best panel ever.
[01:35:21.900 --> 01:35:23.340]   So glad to have all of you.
[01:35:23.340 --> 01:35:27.380]   Dwight Silverman, Glenn Fleischman, Phil Libben.
[01:35:27.380 --> 01:35:30.380]   Our show today brought to you by Wealthfront.
[01:35:30.380 --> 01:35:33.980]   Wealthfront.com/twit.
[01:35:33.980 --> 01:35:38.060]   Wealthfront's goal, I'm really a fan of this company.
[01:35:38.060 --> 01:35:40.060]   And they're thinking, and they're ideas.
[01:35:40.060 --> 01:35:43.460]   I'm very excited to be able to share this
[01:35:43.460 --> 01:35:44.300]   with you.
[01:35:44.300 --> 01:35:46.460]   They make building long-term wealth easy.
[01:35:46.460 --> 01:35:50.420]   And they do it now in two ways, which is kind of interesting.
[01:35:50.420 --> 01:35:51.540]   For a long time, we've talked about
[01:35:51.540 --> 01:35:53.820]   their automated investing accounts.
[01:35:53.820 --> 01:35:57.500]   They now offer high-yield savings as well.
[01:35:57.500 --> 01:36:00.060]   All within a wonderful app,
[01:36:00.060 --> 01:36:02.780]   a beautifully designed interface.
[01:36:02.780 --> 01:36:04.740]   Is your bank keeping money that could be yours?
[01:36:04.740 --> 01:36:05.580]   Yes, they are.
[01:36:05.580 --> 01:36:07.820]   If you're learning less than Wealthfront's,
[01:36:07.820 --> 01:36:13.060]   get this, 3.30% API on your savings.
[01:36:13.060 --> 01:36:14.820]   3.30.
[01:36:14.820 --> 01:36:17.340]   Federal interest rates, of course, have been going up.
[01:36:17.340 --> 01:36:18.340]   You've heard that.
[01:36:18.340 --> 01:36:20.140]   The Fed keeps raising rates.
[01:36:20.140 --> 01:36:22.100]   That's, you know, means the banks are earning more
[01:36:22.100 --> 01:36:24.580]   in your savings, but they're keeping the money.
[01:36:24.580 --> 01:36:26.500]   According to the FDIC, the average US bank
[01:36:26.500 --> 01:36:30.740]   has only raised their interest rates to 0.21%.
[01:36:30.740 --> 01:36:33.740]   You might want to check,
[01:36:33.740 --> 01:36:36.420]   what's that right on your savings account?
[01:36:36.420 --> 01:36:38.140]   Wealthfront is offering their clients a rate
[01:36:38.140 --> 01:36:42.220]   that's about 15 times higher with the Wealthfront cash account.
[01:36:42.220 --> 01:36:43.780]   It's easy to sign up.
[01:36:43.780 --> 01:36:45.300]   You'll get unlimited transfers.
[01:36:45.300 --> 01:36:47.700]   Fee-free, love that.
[01:36:47.700 --> 01:36:51.660]   Up to $2 million in FDIC insurance through partner banks.
[01:36:51.660 --> 01:36:53.580]   So let me re-emphasize.
[01:36:53.580 --> 01:36:57.180]   There's no account fees, no minimum balance.
[01:36:57.180 --> 01:37:00.140]   And if you go right now to wealthfront.com/trit,
[01:37:00.140 --> 01:37:04.460]   a free $50 bonus with an additional deposit of $500.
[01:37:04.460 --> 01:37:06.460]   I bet you have that much in your savings account,
[01:37:06.460 --> 01:37:10.780]   earning 0.2% or less.
[01:37:10.780 --> 01:37:12.060]   Don't let your bank keep the interest.
[01:37:12.060 --> 01:37:13.740]   You should be earning move your savings
[01:37:13.740 --> 01:37:14.860]   to a high yield account,
[01:37:14.860 --> 01:37:19.500]   Wealthfront, and earn 3.30% API.
[01:37:19.500 --> 01:37:21.900]   Join the half a million people now
[01:37:21.900 --> 01:37:24.300]   who already use Wealthfront to earn 15 times more
[01:37:24.300 --> 01:37:25.140]   than the average bank.
[01:37:25.140 --> 01:37:26.820]   They're also great for investing.
[01:37:26.820 --> 01:37:30.460]   Wealthfront.com/trit to get started.
[01:37:30.460 --> 01:37:31.820]   You said the word table stakes.
[01:37:31.820 --> 01:37:33.100]   This is table stakes.
[01:37:33.100 --> 01:37:35.460]   You know, investments aside,
[01:37:35.460 --> 01:37:37.860]   if you're saving money and getting nothing,
[01:37:37.860 --> 01:37:40.100]   go to Wealthfront, at least do that.
[01:37:40.100 --> 01:37:42.020]   Wealthfront.com/trit,
[01:37:42.020 --> 01:37:45.180]   your free $50 bonus with an initial deposit of $500.
[01:37:45.180 --> 01:37:49.620]   If you go to that address, wealthfront.com/trit.
[01:37:49.620 --> 01:37:54.100]   This has been a paid endorsement for Wealthfront.
[01:37:54.100 --> 01:37:55.380]   We thank them so much for their support.
[01:37:55.380 --> 01:38:00.100]   I have to say that when I read these financial services ads,
[01:38:00.100 --> 01:38:03.580]   there is, and we do it on the onboarding call too,
[01:38:03.580 --> 01:38:06.500]   there are several pages of things.
[01:38:06.500 --> 01:38:08.140]   I can't say I have to say
[01:38:08.140 --> 01:38:11.140]   this highly regulated industry.
[01:38:11.140 --> 01:38:12.700]   Compare that.
[01:38:12.700 --> 01:38:16.500]   If I were to do an ad for, let's say FTX,
[01:38:16.500 --> 01:38:20.700]   compare that with Tom Brady telling Giselle,
[01:38:20.700 --> 01:38:22.020]   "I'm in, are you in?
[01:38:22.020 --> 01:38:23.380]   Let's all get in."
[01:38:23.380 --> 01:38:28.100]   A lot of celebrities now regretting their association
[01:38:28.100 --> 01:38:31.780]   with crypto in general, and specifically with FTX,
[01:38:31.780 --> 01:38:34.220]   there's a big FTX lawsuit
[01:38:34.220 --> 01:38:38.300]   that holds the celebrities' feet to the fire,
[01:38:38.300 --> 01:38:40.740]   which kind of surprises me.
[01:38:40.740 --> 01:38:43.500]   Steph Curry, the Golden State Warriors,
[01:38:43.500 --> 01:38:47.860]   quarterback Tom Brady, his supermodel wife, Giselle Bunchen,
[01:38:47.860 --> 01:38:52.860]   and Larry David, all being sued
[01:38:52.860 --> 01:38:56.260]   for the ads they did for FTX.
[01:38:56.260 --> 01:38:59.540]   Now I guess, is it true that if I had money in FTX
[01:38:59.540 --> 01:39:01.980]   that I'm out of luck, that I'm never gonna see that money again?
[01:39:01.980 --> 01:39:04.020]   I think that's the case.
[01:39:04.020 --> 01:39:07.220]   Although I heard over the weekend that SPF,
[01:39:07.220 --> 01:39:08.900]   Samuel Bankman Fried was going around
[01:39:08.900 --> 01:39:11.540]   trying to raise money to pay people back.
[01:39:11.540 --> 01:39:13.860]   Like, who's gonna give him money?
[01:39:13.860 --> 01:39:14.700]   That's the optimism.
[01:39:14.700 --> 01:39:17.380]   I'm always quoting Matt Levine at Bloomberg
[01:39:17.380 --> 01:39:18.380]   'cause he writes a great column.
[01:39:18.380 --> 01:39:19.220]   Very good.
[01:39:19.220 --> 01:39:21.860]   Trying to describe the difference between liquidity
[01:39:21.860 --> 01:39:25.380]   and solvency, whereas regards crypto exchanges.
[01:39:25.380 --> 01:39:28.740]   And it's a good read, and if I recall it correctly,
[01:39:28.740 --> 01:39:31.700]   it's kind of like, liquidity has to do
[01:39:31.700 --> 01:39:33.220]   with whether you can redeem funds,
[01:39:33.220 --> 01:39:36.660]   and solvency has to do with whether you can survive,
[01:39:36.660 --> 01:39:39.180]   more or less as a business entity.
[01:39:39.180 --> 01:39:40.660]   So if you have, I don't know,
[01:39:40.660 --> 01:39:44.700]   if you have $1,000 of assets that are locked up in illiquid,
[01:39:44.700 --> 01:39:46.460]   then you may have a liquidity crisis
[01:39:46.460 --> 01:39:47.940]   if you have to redeem $1,000,
[01:39:47.940 --> 01:39:49.020]   but you still have the assets,
[01:39:49.020 --> 01:39:50.540]   so maybe someone will buy you, right?
[01:39:50.540 --> 01:39:53.460]   Solvency is you have $1,000 in deficits
[01:39:53.460 --> 01:39:55.620]   for every dollar and assets you have,
[01:39:55.620 --> 01:39:57.740]   and there's no way you get out of that.
[01:39:57.740 --> 01:40:00.740]   And he's saying, SPF and FTX and MOUSE
[01:40:00.740 --> 01:40:03.300]   all have solvency issues,
[01:40:03.300 --> 01:40:05.540]   so you can't raise money into an environment
[01:40:05.540 --> 01:40:08.820]   in which there's no hope of ever getting an investor
[01:40:08.820 --> 01:40:10.860]   to get a return on putting that money in.
[01:40:10.860 --> 01:40:12.780]   They might as well let all the chips fall
[01:40:12.780 --> 01:40:16.980]   and if possible, the Enron,
[01:40:16.980 --> 01:40:19.540]   the guy who solved Enron after the fact, right?
[01:40:19.540 --> 01:40:21.420]   Got as much money as he could for Enron,
[01:40:21.420 --> 01:40:23.820]   shareholders who's in charge of the FTX.
[01:40:23.820 --> 01:40:24.700]   Although that's in dispute too.
[01:40:24.700 --> 01:40:26.260]   He's in charge of the FDF bankruptcy,
[01:40:26.260 --> 01:40:27.220]   but there's a competing bank,
[01:40:27.220 --> 01:40:29.900]   because claim from the regulators and the Bahamas also.
[01:40:29.900 --> 01:40:30.740]   Oh Lord.
[01:40:30.740 --> 01:40:32.860]   So anyway, but--
[01:40:32.860 --> 01:40:33.980]   What a mess.
[01:40:33.980 --> 01:40:35.020]   You remember the Madoff thing.
[01:40:35.020 --> 01:40:36.460]   I mean, Madoff is a good example.
[01:40:36.460 --> 01:40:38.900]   It's Bernie Madoff, ostensibly,
[01:40:38.900 --> 01:40:41.300]   lied to people about the value of their holdings,
[01:40:41.300 --> 01:40:43.220]   but he didn't necessarily lose all their money.
[01:40:43.220 --> 01:40:45.020]   And in the end, through clawbacks
[01:40:45.020 --> 01:40:46.900]   and an incredibly lucrative setback.
[01:40:46.900 --> 01:40:49.060]   Yeah, I think people got almost,
[01:40:49.060 --> 01:40:52.340]   almost 100% back on what they initially put in.
[01:40:52.340 --> 01:40:53.620]   They just didn't get any return on it,
[01:40:53.620 --> 01:40:55.700]   so they lost out on the biggest expansion
[01:40:55.700 --> 01:40:58.340]   in value of their money over that period of time.
[01:40:58.340 --> 01:41:00.500]   They put it in the S&P 500 or anything else.
[01:41:00.500 --> 01:41:03.060]   Right before FTX went insolvent,
[01:41:03.060 --> 01:41:04.700]   during the World Series,
[01:41:04.700 --> 01:41:08.540]   the umpires uniforms actually had FTX.
[01:41:08.540 --> 01:41:11.140]   You know, he said, "I'm gonna buy the people they trust."
[01:41:11.140 --> 01:41:13.660]   The umpires had FTX.
[01:41:13.660 --> 01:41:14.980]   Everybody loves an umpire.
[01:41:14.980 --> 01:41:15.860]   Oh my God.
[01:41:15.860 --> 01:41:18.420]   By the way, Phil has moved north a little bit in Japan.
[01:41:18.420 --> 01:41:20.380]   He's in now a Nagano,
[01:41:20.380 --> 01:41:22.540]   taking a hot tub with the monkeys apparently.
[01:41:22.540 --> 01:41:23.380]   He's nervous.
[01:41:23.380 --> 01:41:25.740]   (laughing)
[01:41:25.740 --> 01:41:27.820]   By the way, apparently, you know,
[01:41:27.820 --> 01:41:30.300]   so many tourists were bugging these monkeys
[01:41:30.300 --> 01:41:34.020]   in these hot springs that they've gotten very cranky
[01:41:34.020 --> 01:41:35.700]   and they do not like their picture taken.
[01:41:35.700 --> 01:41:38.260]   So do not wake that one up behind you, Gillies.
[01:41:38.260 --> 01:41:39.180]   Don't get too close.
[01:41:39.180 --> 01:41:40.940]   Don't get too close to Vary.
[01:41:40.940 --> 01:41:43.620]   I'm gonna try to moderate my comments.
[01:41:43.620 --> 01:41:45.820]   The umpires are not being sued,
[01:41:45.820 --> 01:41:48.940]   but everybody else is including Naomi Osaka,
[01:41:48.940 --> 01:41:53.020]   the tennis player, Shaquille O'Neal, Kevin O'Leary,
[01:41:53.020 --> 01:41:54.980]   the host of Shark Tank,
[01:41:54.980 --> 01:41:58.660]   all of them did ads for FTX.
[01:41:58.660 --> 01:42:01.140]   Well, the Larry David ad was like,
[01:42:01.140 --> 01:42:03.660]   I think he's off the hook 'cause he said no, right?
[01:42:03.660 --> 01:42:04.500]   Yeah, right.
[01:42:04.500 --> 01:42:06.100]   And then said, "Don't be a Larry."
[01:42:06.100 --> 01:42:08.940]   Oh, he literally said,
[01:42:08.940 --> 01:42:10.740]   he literally said, "I said don't invest in this.
[01:42:10.740 --> 01:42:12.580]   "It's a terrible idea."
[01:42:12.580 --> 01:42:14.500]   And they're like, "Don't listen to him."
[01:42:14.500 --> 01:42:15.340]   I don't know.
[01:42:15.340 --> 01:42:16.620]   "Don't listen to Larry."
[01:42:16.620 --> 01:42:17.460]   That's great.
[01:42:17.460 --> 01:42:18.340]   So there is a history,
[01:42:18.340 --> 01:42:20.580]   I didn't know this, but Jeff Jarvis being the,
[01:42:20.580 --> 01:42:24.700]   I guess antiquarian that he is,
[01:42:24.700 --> 01:42:27.780]   reminded us that this has happened before Pat Boone
[01:42:27.780 --> 01:42:31.620]   did ads for a zip cream that he claimed his daughter
[01:42:31.620 --> 01:42:35.180]   had used to clean up her skin, got sued,
[01:42:35.180 --> 01:42:37.980]   and was forced to pay over a lot of money
[01:42:37.980 --> 01:42:41.260]   and settle in and to make a public apology.
[01:42:41.260 --> 01:42:45.260]   This is, there is apparently some burden upon celebrities.
[01:42:45.260 --> 01:42:46.140]   I did not know this.
[01:42:46.140 --> 01:42:48.260]   And from now on, I promise you're on her,
[01:42:48.260 --> 01:42:52.780]   I'm gonna be very careful that they are responsible
[01:42:52.780 --> 01:42:54.620]   for their endorsements.
[01:42:54.620 --> 01:42:56.020]   I got a good story about that,
[01:42:56.020 --> 01:42:58.220]   which is that I believe that if you endure certain kinds
[01:42:58.220 --> 01:43:00.860]   of products, you're supposed to possess or have tried them.
[01:43:00.860 --> 01:43:02.220]   So just on the rule.
[01:43:02.220 --> 01:43:03.060]   Yes.
[01:43:03.060 --> 01:43:04.740]   So I had a friend, a friend of a friend,
[01:43:04.740 --> 01:43:07.780]   actually they made three friends,
[01:43:07.780 --> 01:43:10.300]   we had a friend of mine, had a friend whose friend
[01:43:10.300 --> 01:43:12.580]   was dating Tom Bosley's daughter.
[01:43:12.580 --> 01:43:13.420]   And Tom Bosley was--
[01:43:13.420 --> 01:43:15.340]   Wow, talk about a brush with fame.
[01:43:15.340 --> 01:43:16.180]   There we go.
[01:43:16.180 --> 01:43:17.020]   Absolutely.
[01:43:17.020 --> 01:43:17.860]   Yeah.
[01:43:17.860 --> 01:43:20.340]   And Tom Bosley was the glad trash bags spokesperson.
[01:43:20.340 --> 01:43:23.460]   And so this friend of a friend was over visiting his friend
[01:43:23.460 --> 01:43:25.420]   and Tom Bosley's daughter, and they opened the garage.
[01:43:25.420 --> 01:43:29.100]   And it was packed, packed with boxes of glad trash bags.
[01:43:29.100 --> 01:43:30.180]   I use them.
[01:43:30.180 --> 01:43:31.020]   I use them.
[01:43:31.020 --> 01:43:31.860]   This is crazy.
[01:43:31.860 --> 01:43:32.700]   He walks the talk.
[01:43:32.700 --> 01:43:33.700]   He talks about--
[01:43:33.700 --> 01:43:36.220]   No, the FTC tells us.
[01:43:36.220 --> 01:43:40.140]   And I actually, you know, when I, I'm leaving the radio show,
[01:43:40.140 --> 01:43:42.460]   but when I worked for, I still work for them.
[01:43:42.460 --> 01:43:46.500]   But working for Premiere, and that's the iHeart folks,
[01:43:46.500 --> 01:43:49.380]   I actually had to take every year,
[01:43:49.380 --> 01:43:53.260]   a fabulous flash-based ethics slideshow.
[01:43:53.260 --> 01:43:57.380]   And talking about the FTC rules, I cannot endorse a product
[01:43:57.380 --> 01:44:00.020]   I don't use.
[01:44:00.020 --> 01:44:03.140]   Now, this is interesting, because then I just did--
[01:44:03.140 --> 01:44:09.380]   says the SEC rules specifically say you cannot be--
[01:44:09.380 --> 01:44:13.140]   and a user of the financial instrument that you're--
[01:44:13.140 --> 01:44:15.980]   it's very weird.
[01:44:15.980 --> 01:44:17.940]   I cannot say I recommend them.
[01:44:17.940 --> 01:44:20.580]   I cannot say I am a client.
[01:44:20.580 --> 01:44:23.740]   And now they've added this is a paid endorsement.
[01:44:23.740 --> 01:44:26.140]   I think everybody's very nervous right now.
[01:44:26.140 --> 01:44:31.460]   But every other product, when I say I use it, I use it.
[01:44:31.460 --> 01:44:33.540]   We're very-- we're sticklers about that.
[01:44:33.540 --> 01:44:37.820]   And we'll have people say, can Leo endorse this e-bike?
[01:44:37.820 --> 01:44:40.580]   And Lisa will say, well, not unless he uses it.
[01:44:40.580 --> 01:44:41.300]   He can't.
[01:44:41.300 --> 01:44:42.300]   Are you going to send this one?
[01:44:42.300 --> 01:44:44.740]   And he's going to try it out and give you--
[01:44:44.740 --> 01:44:45.740]   and let you know then.
[01:44:45.740 --> 01:44:47.340]   And then they go, no.
[01:44:47.340 --> 01:44:50.300]   And we say, well, FTC rules.
[01:44:50.300 --> 01:44:52.900]   Prohabit, an endorsement.
[01:44:52.900 --> 01:44:54.580]   So I don't know, these guys--
[01:44:54.580 --> 01:44:56.900]   I mean, what would it take to use FDX?
[01:44:56.900 --> 01:44:59.180]   You'd just buy a thing.
[01:44:59.180 --> 01:45:00.020]   What is it you're buying?
[01:45:00.020 --> 01:45:01.060]   FT tokens?
[01:45:01.060 --> 01:45:03.980]   Well, isn't that part of the alleged dispute
[01:45:03.980 --> 01:45:05.700]   between Tom Brady and Giselle?
[01:45:05.700 --> 01:45:07.700]   That he put a bunch of more money into--
[01:45:07.700 --> 01:45:08.820]   or do they both agree to do that?
[01:45:08.820 --> 01:45:12.100]   There was some story that came out, the veracity, which I don't--
[01:45:12.100 --> 01:45:13.380]   I'm not able to personally confirm.
[01:45:13.380 --> 01:45:16.380]   They are now divorced or divorcing.
[01:45:16.380 --> 01:45:16.980]   But there--
[01:45:16.980 --> 01:45:18.940]   that's a strain if you put hundreds of millions of dollars
[01:45:18.940 --> 01:45:20.780]   into something that loses a lot of value that possibly
[01:45:20.780 --> 01:45:21.780]   has an effect in America.
[01:45:21.780 --> 01:45:23.900]   That's what was going on.
[01:45:23.900 --> 01:45:28.180]   I don't know how this case will end up.
[01:45:28.180 --> 01:45:29.540]   And it's not the FTC.
[01:45:29.540 --> 01:45:32.940]   It's a class action in federal court.
[01:45:32.940 --> 01:45:33.540]   For now.
[01:45:33.540 --> 01:45:36.300]   For now.
[01:45:36.300 --> 01:45:37.940]   I don't know how it'll end up.
[01:45:37.940 --> 01:45:38.500]   I mean--
[01:45:38.500 --> 01:45:39.700]   In a live-daddy with a follow-up--
[01:45:39.700 --> 01:45:40.940]   It's an HBO movie.
[01:45:40.940 --> 01:45:41.940]   Really?
[01:45:41.940 --> 01:45:43.940]   Oh, I can't wait.
[01:45:43.940 --> 01:45:46.140]   You know who's got the story that you want--
[01:45:46.140 --> 01:45:47.020]   an option, by the way.
[01:45:47.020 --> 01:45:49.860]   If you're a major Hollywood producer watching this show,
[01:45:49.860 --> 01:45:53.620]   as many do, you got to go to Louis--
[01:45:53.620 --> 01:45:56.100]   Michael Lewis-- because he's been interviewing--
[01:45:56.100 --> 01:45:56.100]   Oh, man.
[01:45:56.100 --> 01:45:57.340]   --as Shadow Wingham.
[01:45:57.340 --> 01:45:58.420]   He's been doing--
[01:45:58.420 --> 01:46:01.780]   And he's got the best end now for us.
[01:46:01.780 --> 01:46:03.780]   Is he in the shopping in the movie rates right now?
[01:46:03.780 --> 01:46:04.260]   I thought that was the--
[01:46:04.260 --> 01:46:06.500]   Gary T. U. He hasn't written the book yet.
[01:46:06.500 --> 01:46:07.900]   Right.
[01:46:07.900 --> 01:46:08.420]   Though it's--
[01:46:08.420 --> 01:46:10.940]   Many Michael Lewis books have made excellent movies already,
[01:46:10.940 --> 01:46:12.540]   including The Big Short.
[01:46:12.540 --> 01:46:14.020]   I think anyone had his--
[01:46:14.020 --> 01:46:14.820]   Yeah.
[01:46:14.820 --> 01:46:16.620]   What was the baseball film that they--
[01:46:16.620 --> 01:46:17.420]   Oh, oh--
[01:46:17.420 --> 01:46:18.220]   It's wonderful.
[01:46:18.220 --> 01:46:18.820]   Moneyball.
[01:46:18.820 --> 01:46:19.420]   Moneyball.
[01:46:19.420 --> 01:46:20.020]   That's great.
[01:46:20.020 --> 01:46:21.220]   That is a great film.
[01:46:21.220 --> 01:46:22.220]   Yeah.
[01:46:22.220 --> 01:46:24.460]   Anybody had better timing than him?
[01:46:24.460 --> 01:46:26.220]   You have to say-- so that's me being--
[01:46:26.220 --> 01:46:27.540]   I don't think he was just lucky.
[01:46:27.540 --> 01:46:29.980]   I think he obviously had a sense of--
[01:46:29.980 --> 01:46:32.060]   he has a sense of impending doom.
[01:46:32.060 --> 01:46:33.260]   He's a good journalist.
[01:46:33.260 --> 01:46:33.620]   He's a good journalist.
[01:46:33.620 --> 01:46:35.620]   He knows who to follow.
[01:46:35.620 --> 01:46:36.740]   I mean, because we wrote Moneyball.
[01:46:36.740 --> 01:46:40.340]   That was just before the entire baseball world kind of--
[01:46:40.340 --> 01:46:42.820]   like turned around Sabre metrics, right?
[01:46:42.820 --> 01:46:44.860]   Like it was-- he was there at kind
[01:46:44.860 --> 01:46:47.380]   of the inflection point happening
[01:46:47.380 --> 01:46:50.380]   as opposed to like three or five years after it did.
[01:46:50.380 --> 01:46:50.700]   Yeah.
[01:46:50.700 --> 01:46:54.980]   According to theankler.com--
[01:46:54.980 --> 01:46:58.380]   I don't know the reference, but I feel
[01:46:58.380 --> 01:47:00.500]   like it's a Hollywood reference.
[01:47:00.500 --> 01:47:07.060]   Hollywood is frenzily trying to get Michael Lewis to option
[01:47:07.060 --> 01:47:07.940]   his book.
[01:47:07.940 --> 01:47:09.060]   Got to be millions.
[01:47:09.060 --> 01:47:09.900]   Got to be millions.
[01:47:09.900 --> 01:47:15.700]   I remember for a long time was a friend of Big Hollywood
[01:47:15.700 --> 01:47:19.700]   producer at Trigger Street.
[01:47:19.700 --> 01:47:21.820]   And he told me the story-- actually,
[01:47:21.820 --> 01:47:24.300]   I think he told us on one of the shows.
[01:47:24.300 --> 01:47:29.900]   He was the guy who got House of Cards for Kevin Spacey.
[01:47:29.900 --> 01:47:32.580]   He was Kevin Spacey's producer.
[01:47:32.580 --> 01:47:34.700]   He told us the story of the Kevin Spacey,
[01:47:34.700 --> 01:47:36.540]   of how they got House of Cards.
[01:47:36.540 --> 01:47:39.100]   Some other big company already bid money.
[01:47:39.100 --> 01:47:42.580]   And Dane got on the phone.
[01:47:42.580 --> 01:47:44.380]   Dana Bernetti got on the phone with Kevin,
[01:47:44.380 --> 01:47:49.100]   said, we got to buy this for you and talked him out of it.
[01:47:49.100 --> 01:47:50.500]   I think they already sold it to HBO.
[01:47:50.500 --> 01:47:52.540]   And he got Netflix to talk about it.
[01:47:52.540 --> 01:47:55.780]   Anyway, he told me he was watching TV,
[01:47:55.780 --> 01:47:59.740]   saw the CNN story about the pirates
[01:47:59.740 --> 01:48:05.580]   taking over that Captain Phillips freighter,
[01:48:05.580 --> 01:48:07.860]   and the rescue and the Navy SEAL Team
[01:48:07.860 --> 01:48:09.540]   six coming in and saving him.
[01:48:09.540 --> 01:48:12.100]   And he says, I was on the phone instantly.
[01:48:12.100 --> 01:48:14.340]   And of course, he made a great movie Captain Phillips.
[01:48:14.340 --> 01:48:16.140]   I'm the captain now.
[01:48:16.140 --> 01:48:18.940]   So that is-- you know the Hollywood jumps on these things.
[01:48:18.940 --> 01:48:19.780]   They're looking for this.
[01:48:19.780 --> 01:48:22.380]   And what a great story this is going to be.
[01:48:22.380 --> 01:48:25.820]   I only hope that the producer-- who should
[01:48:25.820 --> 01:48:26.700]   produce David Russell?
[01:48:26.700 --> 01:48:28.460]   Who should produce this SPF?
[01:48:28.460 --> 01:48:29.540]   What should it be called?
[01:48:29.540 --> 01:48:31.220]   What should be called?
[01:48:31.220 --> 01:48:32.780]   That's a good--
[01:48:32.780 --> 01:48:33.540]   The bigger short.
[01:48:33.540 --> 01:48:33.940]   Wait a minute.
[01:48:33.940 --> 01:48:34.900]   Where'd you end up now?
[01:48:34.900 --> 01:48:35.900]   You're Norway?
[01:48:36.900 --> 01:48:37.900]   Where?
[01:48:37.900 --> 01:48:38.900]   It's a long show.
[01:48:38.900 --> 01:48:39.900]   [LAUGHTER]
[01:48:39.900 --> 01:48:43.900]   He's traveling the world.
[01:48:43.900 --> 01:48:44.900]   I've got it.
[01:48:44.900 --> 01:48:47.900]   But I got the title, The Funny Money Ball.
[01:48:47.900 --> 01:48:48.900]   Funny Money Ball.
[01:48:48.900 --> 01:48:49.900]   The bigger short--
[01:48:49.900 --> 01:48:50.900]   The bigger hair is not bad.
[01:48:50.900 --> 01:48:51.900]   The bigger--
[01:48:51.900 --> 01:48:52.900]   The bigger hair is not bad.
[01:48:52.900 --> 01:48:53.900]   The bigger hair is not bad.
[01:48:53.900 --> 01:48:54.900]   SPF.
[01:48:54.900 --> 01:48:56.900]   You know, it's funny because--
[01:48:56.900 --> 01:48:58.900]   Well, the first time I got him on my radar,
[01:48:58.900 --> 01:49:00.900]   I thought, this guy, just like you do with all these guys,
[01:49:00.900 --> 01:49:02.900]   we really worship these guys, don't we?
[01:49:02.900 --> 01:49:03.900]   I thought, this guy's a genius.
[01:49:03.900 --> 01:49:04.900]   He comes at it.
[01:49:04.900 --> 01:49:05.900]   He comes at it.
[01:49:05.900 --> 01:49:09.900]   Stanford runs a hedge fund and then says, wait a minute.
[01:49:09.900 --> 01:49:13.900]   And he was the whole effective altruism thing he was doing,
[01:49:13.900 --> 01:49:17.900]   where he put his money into good causes.
[01:49:17.900 --> 01:49:21.900]   And I thought this guy's incredible boy.
[01:49:21.900 --> 01:49:23.900]   Well, this is seriously incorrect.
[01:49:23.900 --> 01:49:24.900]   He's MIT, not Stanford.
[01:49:24.900 --> 01:49:25.900]   Oh, OK.
[01:49:25.900 --> 01:49:26.900]   MIT, pardon me.
[01:49:26.900 --> 01:49:28.900]   Completely just--
[01:49:28.900 --> 01:49:29.900]   Let's get that right.
[01:49:29.900 --> 01:49:30.900]   Yeah.
[01:49:30.900 --> 01:49:31.900]   Are you a Stanford grad?
[01:49:31.900 --> 01:49:32.900]   I'm thinking.
[01:49:32.900 --> 01:49:33.900]   No, I'm not.
[01:49:33.900 --> 01:49:34.900]   OK.
[01:49:34.900 --> 01:49:35.900]   [LAUGHTER]
[01:49:35.900 --> 01:49:39.900]   But a young Wunderkind, who ended up being--
[01:49:39.900 --> 01:49:42.900]   Look, he's my daughter's age.
[01:49:42.900 --> 01:49:46.900]   That's what really hit me.
[01:49:46.900 --> 01:49:50.900]   And he was worth, at one point, I think $92 billion,
[01:49:50.900 --> 01:49:52.900]   $92 billion in funny money.
[01:49:52.900 --> 01:49:53.900]   No, he wasn't, yeah.
[01:49:53.900 --> 01:49:54.900]   Yeah.
[01:49:54.900 --> 01:49:55.900]   It turns out no.
[01:49:55.900 --> 01:50:00.900]   Big donor to the Democratic Party,
[01:50:00.900 --> 01:50:03.900]   the second largest donor to Joe Biden's 2020 campaign.
[01:50:03.900 --> 01:50:04.900]   Yeah.
[01:50:04.900 --> 01:50:06.900]   Personally, he's owning $5.2 million.
[01:50:06.900 --> 01:50:09.900]   I see some people questioning, should the Democrats be
[01:50:09.900 --> 01:50:11.900]   returning money they received from him,
[01:50:11.900 --> 01:50:13.900]   given the money was probably, you know--
[01:50:13.900 --> 01:50:14.900]   But it's been spent--
[01:50:14.900 --> 01:50:16.900]   It was spent on TV ads.
[01:50:16.900 --> 01:50:17.900]   How do you return it?
[01:50:17.900 --> 01:50:18.900]   Yeah.
[01:50:18.900 --> 01:50:19.900]   He just taken from other money.
[01:50:19.900 --> 01:50:21.900]   He grays other money to repair it.
[01:50:21.900 --> 01:50:22.900]   That's right.
[01:50:22.900 --> 01:50:23.900]   He raised other money.
[01:50:23.900 --> 01:50:25.900]   It's a funny-- yeah.
[01:50:25.900 --> 01:50:28.900]   It's-- we did this-- I mean, you know, talking about Elizabeth Holmes,
[01:50:28.900 --> 01:50:32.900]   all these people, I think there's a desire in, you know,
[01:50:32.900 --> 01:50:34.900]   celebrity technology journalism, right?
[01:50:34.900 --> 01:50:39.900]   We have a desire to anoint one person as the savior of humanity
[01:50:39.900 --> 01:50:42.900]   and who has all the right ideas about X.
[01:50:42.900 --> 01:50:45.900]   And Elon Musk has filled a really big part of that.
[01:50:45.900 --> 01:50:48.900]   Since Steve Jobs left us, we have Elon Musk
[01:50:48.900 --> 01:50:50.900]   with so many different pairs of shoes there.
[01:50:50.900 --> 01:50:51.900]   Yeah.
[01:50:51.900 --> 01:50:54.900]   And Holmes was that-- remember Holmes, that famous story,
[01:50:54.900 --> 01:50:57.900]   where she was on the cover of the T-section of the New York Times,
[01:50:57.900 --> 01:51:01.900]   written by Mark Andreessen's wife, if I recall,
[01:51:01.900 --> 01:51:04.900]   in a slight conflict of interest that wasn't disclosed--
[01:51:04.900 --> 01:51:05.900]   Yeah.
[01:51:05.900 --> 01:51:06.900]   --that was later disclosed.
[01:51:06.900 --> 01:51:07.900]   I think it came out.
[01:51:07.900 --> 01:51:08.900]   But it wasn't--
[01:51:08.900 --> 01:51:11.900]   Was that before she started talking like this or was that after?
[01:51:11.900 --> 01:51:15.900]   But it's the same thing, you know, Sam Bankard Freed showing up on covers
[01:51:15.900 --> 01:51:20.900]   and it's like, this is what-- having lived through multiple waves of,
[01:51:20.900 --> 01:51:25.900]   you know, implosions in the market, I feel like one of the things
[01:51:25.900 --> 01:51:28.900]   that was different in, say, 2007, 2008 and is different now,
[01:51:28.900 --> 01:51:33.900]   is that companies made real things and had real revenue.
[01:51:33.900 --> 01:51:36.900]   And so when things went a little awry, they had something to fall back on,
[01:51:36.900 --> 01:51:38.900]   like actual business.
[01:51:38.900 --> 01:51:40.900]   And then the crypto market just sort of turned that back.
[01:51:40.900 --> 01:51:46.900]   We kind of wound the clock back much worse to 2001 era where companies were--
[01:51:46.900 --> 01:51:48.900]   I mean, this goes that substantive thing.
[01:51:48.900 --> 01:51:52.900]   You had companies like pets.com that were shipping 20-pound bags of--
[01:51:52.900 --> 01:51:53.900]   Kitty litter.
[01:51:53.900 --> 01:51:54.900]   Kitty litter.
[01:51:54.900 --> 01:51:58.900]   By the way, they just let it do early because we now buy bags of Kitty litter
[01:51:58.900 --> 01:51:59.900]   through the mail.
[01:51:59.900 --> 01:52:02.900]   We have a whole subscription plan for Kitty litter.
[01:52:02.900 --> 01:52:10.900]   So just to be clear, SPF was born on the campus of Stanford University.
[01:52:10.900 --> 01:52:12.900]   His parents are both Stanford professors.
[01:52:12.900 --> 01:52:17.900]   His parents are professors at Stanford Law School and he went to math camp.
[01:52:17.900 --> 01:52:20.900]   But MIT owns them.
[01:52:20.900 --> 01:52:22.900]   You're absolutely right.
[01:52:22.900 --> 01:52:26.900]   Look, I don't think we should.
[01:52:26.900 --> 01:52:29.900]   To me-- so Elizabeth Holmes actually pitched me when I was a VC.
[01:52:29.900 --> 01:52:30.900]   Oh, really?
[01:52:30.900 --> 01:52:31.900]   Yep.
[01:52:31.900 --> 01:52:34.900]   And I thought she was great.
[01:52:34.900 --> 01:52:36.900]   I did not pick up any red flags.
[01:52:36.900 --> 01:52:37.900]   Oh, interesting.
[01:52:37.900 --> 01:52:38.900]   Wow.
[01:52:38.900 --> 01:52:40.900]   I thought her voice sounded perfectly normal.
[01:52:40.900 --> 01:52:42.900]   She could talk like that then?
[01:52:42.900 --> 01:52:47.900]   I picked up-- no, I usually have a pretty decent, I think, like bullet filter.
[01:52:47.900 --> 01:52:49.900]   I was very impressed with her.
[01:52:49.900 --> 01:52:52.900]   Just being honest, it's easy for me to be like, hey, I knew something was hard to wait.
[01:52:52.900 --> 01:52:58.260]   No, but that's reasonable because what she was-- what you didn't know, what apparently
[01:52:58.260 --> 01:53:01.820]   George Schulz didn't know is whether the technology was viable.
[01:53:01.820 --> 01:53:03.900]   But the idea-- idea is great.
[01:53:03.900 --> 01:53:07.700]   --is world-changing and could have been a huge success.
[01:53:07.700 --> 01:53:09.700]   Why didn't you invest?
[01:53:09.700 --> 01:53:12.660]   Well, I was thinking about it.
[01:53:12.660 --> 01:53:15.700]   They were already at like 9 billion valuations.
[01:53:15.700 --> 01:53:22.700]   So it would have been a very large check.
[01:53:22.700 --> 01:53:23.700]   Smart.
[01:53:23.700 --> 01:53:24.700]   I don't know.
[01:53:24.700 --> 01:53:25.700]   I can't really do it.
[01:53:25.700 --> 01:53:26.700]   But I was going to do it.
[01:53:26.700 --> 01:53:27.700]   So I said, can I see-- can I come over?
[01:53:27.700 --> 01:53:28.700]   Can I see the machine?
[01:53:28.700 --> 01:53:30.700]   We can talk to me how it works.
[01:53:30.700 --> 01:53:32.700]   And they were like, yeah, of course, absolutely.
[01:53:32.700 --> 01:53:33.700]   Like, come over any time.
[01:53:33.700 --> 01:53:34.700]   We'll open it up.
[01:53:34.700 --> 01:53:35.700]   We'll show you.
[01:53:35.700 --> 01:53:38.700]   And then it just never quite got scheduled.
[01:53:38.700 --> 01:53:40.700]   And then they already wound up taking more money.
[01:53:40.700 --> 01:53:41.700]   And so I kind of missed the boat.
[01:53:41.700 --> 01:53:42.700]   And I felt bad.
[01:53:42.700 --> 01:53:43.700]   Honestly.
[01:53:43.700 --> 01:53:44.700]   I felt bad.
[01:53:44.700 --> 01:53:45.700]   I moved too slow.
[01:53:45.700 --> 01:53:47.700]   I'm not a good VC, which turned out to be true for other reasons.
[01:53:47.700 --> 01:53:52.700]   But I kind of thought, like, I should have just invested.
[01:53:52.700 --> 01:53:53.700]   I had this opportunity.
[01:53:53.700 --> 01:53:54.700]   Everyone wanted to be in this deal.
[01:53:54.700 --> 01:53:55.700]   She would have given to me.
[01:53:55.700 --> 01:53:57.700]   I could have just written a check.
[01:53:57.700 --> 01:54:00.700]   And I didn't because I was too slow because I had this like, I wanted to see it.
[01:54:00.700 --> 01:54:01.700]   What would that have shown me?
[01:54:01.700 --> 01:54:03.700]   Like, let's say I showed up.
[01:54:03.700 --> 01:54:04.700]   Let's say they scheduled it.
[01:54:04.700 --> 01:54:05.700]   And I show up and they opened the machine.
[01:54:05.700 --> 01:54:07.700]   There was like a family of raccoons in there.
[01:54:07.700 --> 01:54:10.700]   But I've been like, aha, they might be good at blood-housing.
[01:54:10.700 --> 01:54:11.700]   Yeah.
[01:54:11.700 --> 01:54:13.700]   And notice, by the way, that everybody on the board, nobody had--
[01:54:13.700 --> 01:54:16.700]   nobody had expertise in the field, right?
[01:54:16.700 --> 01:54:22.700]   They were very careful about choosing Mad Dog Mattis and George Schulz and Henry Kissinger.
[01:54:22.700 --> 01:54:24.700]   Influential people, but people who could not look at that.
[01:54:24.700 --> 01:54:26.700]   But they had a big DoD business.
[01:54:26.700 --> 01:54:28.700]   It made sense of those people who were on board.
[01:54:28.700 --> 01:54:29.700]   Again, I looked into it.
[01:54:29.700 --> 01:54:31.700]   They did a lot of business with the department of defense.
[01:54:31.700 --> 01:54:33.700]   That was their first customer for years.
[01:54:33.700 --> 01:54:35.700]   So it made total sense that they had DoD people.
[01:54:35.700 --> 01:54:40.700]   Like, I'm telling a story to say that I was impressed with her.
[01:54:40.700 --> 01:54:47.100]   The stuff that I checked out, checked out, and I regretted that I actually had so slow
[01:54:47.100 --> 01:54:48.100]   that I didn't invest.
[01:54:48.100 --> 01:54:50.700]   And I regretted that for three or four weeks until I scandal this.
[01:54:50.700 --> 01:54:51.700]   And then I stopped for a second.
[01:54:51.700 --> 01:54:53.700]   Then John Kerry-Rue came calling.
[01:54:53.700 --> 01:54:55.700]   But that's what happened.
[01:54:55.700 --> 01:55:00.700]   And so like, I can-- like, there, but by the grace of not responding to my emails in time,
[01:55:00.700 --> 01:55:01.700]   that would have been me.
[01:55:01.700 --> 01:55:02.700]   Yeah.
[01:55:02.700 --> 01:55:03.700]   This is totally different with SPF.
[01:55:03.700 --> 01:55:04.700]   That guy set off every single--
[01:55:04.700 --> 01:55:05.700]   You knew.
[01:55:05.700 --> 01:55:06.700]   You knew.
[01:55:06.700 --> 01:55:09.700]   You weren't asked to invest, or were you?
[01:55:09.700 --> 01:55:10.700]   I was not a VC at that point.
[01:55:10.700 --> 01:55:11.700]   Yeah.
[01:55:11.700 --> 01:55:13.700]   I was not a VC at that point, but I told a lot of people.
[01:55:13.700 --> 01:55:16.700]   Had he come in the door, you would have known.
[01:55:16.700 --> 01:55:23.700]   I've been pretty public in my loathing of crypto for years, and SPF was worse than average.
[01:55:23.700 --> 01:55:25.700]   So here's a question.
[01:55:25.700 --> 01:55:26.700]   I don't like--
[01:55:26.700 --> 01:55:29.700]   Here's something I've been wondering about.
[01:55:29.700 --> 01:55:38.700]   I think even if you're a crypto partisan, you would not be unreasonable to say, "Well,
[01:55:38.700 --> 01:55:40.700]   look, this was a scammer.
[01:55:40.700 --> 01:55:42.700]   This has nothing to do with crypto."
[01:55:42.700 --> 01:55:51.700]   The collapse of Bitcoin to $16,000 hurt a lot of companies that were over-leveraged, but
[01:55:51.700 --> 01:55:57.700]   it isn't a black mark on the overall technology, or is it?
[01:55:57.700 --> 01:55:59.700]   And that's kind of the question.
[01:55:59.700 --> 01:56:00.700]   It is.
[01:56:00.700 --> 01:56:01.700]   It is.
[01:56:01.700 --> 01:56:09.660]   As I said, the true value of any of these is zero, and anything that you put into it is
[01:56:09.660 --> 01:56:12.700]   on top of zero.
[01:56:12.700 --> 01:56:16.260]   And at its core, it is a scam.
[01:56:16.260 --> 01:56:21.940]   And eventually, all of these people who are running these big exchanges are going to,
[01:56:21.940 --> 01:56:23.620]   I think, are going to come down.
[01:56:23.620 --> 01:56:27.380]   I think this is just the first-- it's not the first, but it's the biggest.
[01:56:27.380 --> 01:56:28.380]   Yeah.
[01:56:28.380 --> 01:56:31.380]   I think this is still going to be a place for stablecoins, which are a whole different thing,
[01:56:31.380 --> 01:56:32.380]   but not run by third parties.
[01:56:32.380 --> 01:56:36.900]   Yeah, we talked about stablecoin or governmental central bank coins, digital dollars.
[01:56:36.900 --> 01:56:38.860]   Well, they're totally different things, though.
[01:56:38.860 --> 01:56:39.860]   Yeah, exactly.
[01:56:39.860 --> 01:56:43.300]   They're barely-- I mean, right, they're not stablecoins.
[01:56:43.300 --> 01:56:46.300]   But stablecoins backed by other--
[01:56:46.300 --> 01:56:50.540]   Well, a number of crypto-- I got to say, a number of stablecoins have collapsed.
[01:56:50.540 --> 01:56:51.540]   Yeah, yeah.
[01:56:51.540 --> 01:56:54.580]   I don't mean tether or anything like that.
[01:56:54.580 --> 01:56:55.580]   Yeah.
[01:56:55.580 --> 01:57:02.380]   So, say this is the complicated thing is, I think that tether, if they actually had--
[01:57:02.380 --> 01:57:06.980]   I mean, this is where you get to the layers upon layers upon layers.
[01:57:06.980 --> 01:57:09.580]   What is tether actually-- what is it doing?
[01:57:09.580 --> 01:57:11.580]   What is a stablecoin?
[01:57:11.580 --> 01:57:12.580]   To tell us what it is.
[01:57:12.580 --> 01:57:17.060]   I mean, it's supposed to be like a crypto reserve currency that you actually have or
[01:57:17.060 --> 01:57:21.620]   a gold standard-style currency, where you actually have a one-to-one valuation that's
[01:57:21.620 --> 01:57:26.300]   of assets or as close to one-to-one that was possible, that's backing a similar amount
[01:57:26.300 --> 01:57:28.940]   of a sensible buying power and fiat currency.
[01:57:28.940 --> 01:57:31.300]   I mean, that's the intent.
[01:57:31.300 --> 01:57:35.780]   And tether had claimed for a long time and then had to change those statements in the
[01:57:35.780 --> 01:57:40.180]   midst of a lot of things that they actually had deposits that were actually liquid or
[01:57:40.180 --> 01:57:44.220]   close to as liquid as possible-- cash and cash equivalents-- equal to the amount of
[01:57:44.220 --> 01:57:47.300]   tether they'd issued in various currency denominations.
[01:57:47.300 --> 01:57:51.140]   I can see a central bank doing it, where the central bank was using it as a-- but it's
[01:57:51.140 --> 01:57:55.660]   not a stable-- the question is, is a stablecoin when a central bank uses a cryptographically
[01:57:55.660 --> 01:58:01.260]   backed method of issuing currency or allowing currency to trade?
[01:58:01.260 --> 01:58:02.260]   They do it now.
[01:58:02.260 --> 01:58:08.020]   They just do it as an entry on a ledger that they retain, that the Fed or something manages.
[01:58:08.020 --> 01:58:10.060]   And not really blockchain either.
[01:58:10.060 --> 01:58:15.660]   So I feel the same way-- I feel the way about financial instruments that have the word stable
[01:58:15.660 --> 01:58:19.300]   in their name, so the way that I feel about seafood restaurants that have the word fresh
[01:58:19.300 --> 01:58:20.300]   in their name.
[01:58:20.300 --> 01:58:24.540]   So don't order seafood in Colorado.
[01:58:24.540 --> 01:58:26.060]   You're trying too hard.
[01:58:26.060 --> 01:58:27.060]   You're just trying too hard.
[01:58:27.060 --> 01:58:28.060]   It's fresh.
[01:58:28.060 --> 01:58:29.460]   Yeah, fresh.
[01:58:29.460 --> 01:58:34.340]   So that stuff is-- what your central bank digital currency is?
[01:58:34.340 --> 01:58:35.340]   Yeah, of course.
[01:58:35.340 --> 01:58:37.980]   That's a better-- sure, that's a better-- yeah.
[01:58:37.980 --> 01:58:38.980]   They probably shouldn't be blockchain-based.
[01:58:38.980 --> 01:58:40.660]   Blockchain is going to stupid for that.
[01:58:40.660 --> 01:58:44.260]   No, I think-- I mean, blockchain requires-- I've mentioned this still in private blockchains
[01:58:44.260 --> 01:58:49.180]   where you have participants who all have a stake against each other, where it's not
[01:58:49.180 --> 01:58:54.260]   an arbitrary, anonymized, participants-based thing.
[01:58:54.260 --> 01:58:59.780]   But I think there's a valid case to be made for using-- I mean, so DNS, which is a very
[01:58:59.780 --> 01:59:01.300]   technical thing, obviously.
[01:59:01.300 --> 01:59:06.860]   But at its root, I think DNS is a very effective distributed mechanism with certain centralized
[01:59:06.860 --> 01:59:12.620]   components that a lot of different, often, parties that are in disagreement all agree
[01:59:12.620 --> 01:59:15.100]   to let run in a way that's verifiable.
[01:59:15.100 --> 01:59:20.780]   So like DNS sec, like some of the cryptographically backed elements of DNS that have been gradually
[01:59:20.780 --> 01:59:24.700]   built up over the years, are really effective centralized decentralized things.
[01:59:24.700 --> 01:59:30.020]   And so I'd say we do have models of that, or even certificate authorities, revocation
[01:59:30.020 --> 01:59:31.980]   of certificate authorities, all that kind of thing.
[01:59:31.980 --> 01:59:35.740]   Those systems work the cryptographically based, and you have lots of parties whose interests
[01:59:35.740 --> 01:59:40.860]   aren't entirely aligned or the same modes of governance of countries and so forth.
[01:59:40.860 --> 01:59:46.060]   And it all generally works most of the time in a way that we find effective.
[01:59:46.060 --> 01:59:47.060]   Yeah.
[01:59:47.060 --> 01:59:52.780]   So look, I-- before I ran a company called Court Street, we were-- back when crypto met
[01:59:52.780 --> 01:59:55.740]   cryptography, so we were a cryptography company.
[01:59:55.740 --> 02:00:00.620]   We sold, you know, PKI, public key infrastructure systems to governments to defense the departments
[02:00:00.620 --> 02:00:01.780]   to large banks, that kind of stuff.
[02:00:01.780 --> 02:00:03.300]   And so, yeah, yeah, of course.
[02:00:03.300 --> 02:00:09.020]   Like, obviously, there's like all sorts of digital systems that have been around forever
[02:00:09.020 --> 02:00:10.300]   that are continuously improving.
[02:00:10.300 --> 02:00:13.380]   They just don't have anything to do with this, like, blockchain nonsense.
[02:00:13.380 --> 02:00:14.380]   Yeah.
[02:00:14.380 --> 02:00:18.580]   I mean, the only reason I like the blockchain, I say that, and then that's the last thing
[02:00:18.580 --> 02:00:19.580]   anyone hears, right?
[02:00:19.580 --> 02:00:24.580]   The thing that I find appealing about the notion of a blockchain is a way to create a
[02:00:24.580 --> 02:00:29.740]   permanently, you know, a permanent record that's globally accessible in a fashion.
[02:00:29.740 --> 02:00:35.420]   But I don't think it actually has a role in necessarily like financial transactions or
[02:00:35.420 --> 02:00:36.420]   the way it's been deployed.
[02:00:36.420 --> 02:00:38.540]   I think it is an interesting thing to think of.
[02:00:38.540 --> 02:00:41.940]   I just think of it as a decentralized database.
[02:00:41.940 --> 02:00:44.460]   There are lots of ways of doing that.
[02:00:44.460 --> 02:00:45.460]   You can rely on that.
[02:00:45.460 --> 02:00:47.460]   You know, tamper, like we have very similar--
[02:00:47.460 --> 02:00:49.460]   Is it really tamper-proof, though?
[02:00:49.460 --> 02:00:50.900]   Well, it's not tampered with.
[02:00:50.900 --> 02:00:51.900]   Yeah.
[02:00:51.900 --> 02:00:52.900]   It has to be tampered with.
[02:00:52.900 --> 02:00:53.900]   Not really.
[02:00:53.900 --> 02:00:54.900]   I mean, so--
[02:00:54.900 --> 02:00:56.900]   Yeah, we would tamper with crypto or a web3 thing.
[02:00:56.900 --> 02:00:57.900]   Yeah.
[02:00:57.900 --> 02:00:58.900]   Oh, I would-- what would the incentive be?
[02:00:58.900 --> 02:01:01.100]   It is the most tamperable thing in the universe.
[02:01:01.100 --> 02:01:02.100]   It's tamperable.
[02:01:02.100 --> 02:01:04.260]   Or is it fully anonymous, right?
[02:01:04.260 --> 02:01:05.260]   Yeah.
[02:01:05.260 --> 02:01:06.260]   It's not fully.
[02:01:06.260 --> 02:01:07.260]   It's de--
[02:01:07.260 --> 02:01:08.260]   Deanon--
[02:01:08.260 --> 02:01:09.260]   Web3.
[02:01:09.260 --> 02:01:18.620]   Web3 is basically-- if you look at the ingredients list for Web3, it's like 80% greed, 20% ideology,
[02:01:18.620 --> 02:01:22.620]   and like tiny amounts of interesting technological ideas.
[02:01:22.620 --> 02:01:27.060]   And by tiny amounts, I mean like-- like this was processed in a facility that also handles
[02:01:27.060 --> 02:01:28.060]   nuts.
[02:01:28.060 --> 02:01:29.060]   [LAUGHTER]
[02:01:29.060 --> 02:01:32.420]   A some outs of like interesting technology.
[02:01:32.420 --> 02:01:35.660]   It's funny you should say that because I always think of it as a thin layer of peanut
[02:01:35.660 --> 02:01:36.660]   butter on anything.
[02:01:36.660 --> 02:01:37.660]   Yeah.
[02:01:37.660 --> 02:01:38.660]   Yeah.
[02:01:38.660 --> 02:01:42.300]   There's really no peanuts in there, but there were peanuts like two months ago in the same
[02:01:42.300 --> 02:01:43.300]   compared.
[02:01:43.300 --> 02:01:44.300]   I don't know.
[02:01:44.300 --> 02:01:46.300]   Phil, if you keep up this attitude, I don't think you're ever going to invest in the
[02:01:46.300 --> 02:01:47.300]   next third of.
[02:01:47.300 --> 02:01:48.300]   [LAUGHTER]
[02:01:48.300 --> 02:01:49.300]   I don't think they're going to ask you.
[02:01:49.300 --> 02:01:53.900]   And a lot of the-- you know, and like, so the 80% greed, whatever, that's-- I don't need
[02:01:53.900 --> 02:01:54.900]   that.
[02:01:54.900 --> 02:01:58.940]   The 20% ideology is some of that ideology, not all, but some of it makes sense to me.
[02:01:58.940 --> 02:01:59.940]   Like some of it I like.
[02:01:59.940 --> 02:02:04.020]   Of course, like traditional financial institutions tend to be pretty exploitative and like, yeah,
[02:02:04.020 --> 02:02:08.540]   we need non-explanative financial institutions and all sorts of stuff.
[02:02:08.540 --> 02:02:12.300]   I can get behind most of the ideology, behind crypto and web3.
[02:02:12.300 --> 02:02:13.300]   Not all of it, but most of it.
[02:02:13.300 --> 02:02:15.900]   A lot of it is just sort of libertarian fantasies.
[02:02:15.900 --> 02:02:17.460]   But I can get behind most of it.
[02:02:17.460 --> 02:02:23.100]   It makes me nervous that it's really-- Andries and Horowitz's "I have vision for the future
[02:02:23.100 --> 02:02:24.100]   of the web."
[02:02:24.100 --> 02:02:26.380]   I don't-- you know, that kind of bugs me.
[02:02:26.380 --> 02:02:28.980]   It seems like A16Z is who's going to make the money on this one.
[02:02:28.980 --> 02:02:31.220]   Well, it ain't playing out very well, so they may--
[02:02:31.220 --> 02:02:32.220]   Web3's going just great.
[02:02:32.220 --> 02:02:33.220]   What are you talking about?
[02:02:33.220 --> 02:02:36.020]   Have you seen Twitter is going just great, I hope?
[02:02:36.020 --> 02:02:38.500]   Yes, also on "Based on the Molly White."
[02:02:38.500 --> 02:02:39.500]   Very good.
[02:02:39.500 --> 02:02:41.500]   Timeline technology, which is fantastic.
[02:02:41.500 --> 02:02:45.580]   Molly White, one of my favorite new people to have found in the past, like six months.
[02:02:45.580 --> 02:02:46.580]   Is she amazing?
[02:02:46.580 --> 02:02:47.580]   Fantastic.
[02:02:47.580 --> 02:02:48.580]   Really good.
[02:02:48.580 --> 02:02:50.420]   So she did, just for those who don't know what we're talking about, we've mentioned it
[02:02:50.420 --> 02:02:51.420]   many, many times.
[02:02:51.420 --> 02:02:56.020]   Web3 is going just great, which is a tragic, tragic.
[02:02:56.020 --> 02:02:59.260]   But if you look at the bottom on the railroad hand corner, it shows you how much money has
[02:02:59.260 --> 02:03:00.260]   been burned.
[02:03:00.260 --> 02:03:03.260]   I have to change the setting.
[02:03:03.260 --> 02:03:07.540]   Started total amount scam and subtract as you scroll or start at zero and as you scroll.
[02:03:07.540 --> 02:03:10.580]   That's the so-called "grift counter."
[02:03:10.580 --> 02:03:15.500]   Maybe my "grift counter" isn't working because by now it should be in the billions of dollars.
[02:03:15.500 --> 02:03:20.260]   So somebody has created using-- she opensourced the timeline software.
[02:03:20.260 --> 02:03:21.820]   It's on GitHub.
[02:03:21.820 --> 02:03:26.940]   So somebody has done-- Twitter is going just great or going great.
[02:03:26.940 --> 02:03:32.220]   And that is an equally wonderful timeline of horror.
[02:03:32.220 --> 02:03:38.180]   There's a great use case that was made for-- in fact, Cape Hall was making this case briefly.
[02:03:38.180 --> 02:03:44.500]   And I think they backed off from it last year, which was-- Crypto was a way to help worldwide
[02:03:44.500 --> 02:03:45.500]   remittances.
[02:03:45.500 --> 02:03:49.580]   There's some hundreds of billions of dollars that people who are economic and other immigrants
[02:03:49.580 --> 02:03:51.900]   to other countries send back home.
[02:03:51.900 --> 02:03:58.380]   The average rate they pay is upwards sometimes of 8% to 10% and it's a huge middleman thing.
[02:03:58.380 --> 02:04:00.860]   And the UN is set as a goal to reduce that.
[02:04:00.860 --> 02:04:02.260]   I want to say below 5%.
[02:04:02.260 --> 02:04:04.060]   Maybe it's a 3%.
[02:04:04.060 --> 02:04:06.980]   They have won their vision 2025 or whatever.
[02:04:06.980 --> 02:04:10.980]   And there's been a lot of work worldwide because every dollar that's taken from an economic
[02:04:10.980 --> 02:04:14.780]   migrant working in a different country or in the same country sending money back to their
[02:04:14.780 --> 02:04:18.260]   family or to others is just sort of stolen out of their pocket.
[02:04:18.260 --> 02:04:21.980]   There's very low costs involved when they're giving cash to an institution that's then
[02:04:21.980 --> 02:04:23.820]   just literally transferring it somewhere else.
[02:04:23.820 --> 02:04:27.820]   So that's a wonderful area that's right for development and people working on it.
[02:04:27.820 --> 02:04:29.420]   Doesn't necessarily need the blockchain.
[02:04:29.420 --> 02:04:30.420]   It was sold as well.
[02:04:30.420 --> 02:04:33.980]   Maybe we could use crypto to solve this because the fees would be very small.
[02:04:33.980 --> 02:04:37.220]   And then of course, the fees went up crazily on transactions.
[02:04:37.220 --> 02:04:41.620]   The whole Bitcoin and Ethereum went through the roof in terms of the cost and that whole
[02:04:41.620 --> 02:04:42.820]   market disappeared.
[02:04:42.820 --> 02:04:47.340]   So I do hope that there is actual attention continuing to be paid to reduce the cost of
[02:04:47.340 --> 02:04:49.300]   people sending money home.
[02:04:49.300 --> 02:04:51.220]   But crypto doesn't seem to be the answer there.
[02:04:51.220 --> 02:04:52.220]   Yeah.
[02:04:52.220 --> 02:04:53.220]   100%.
[02:04:53.220 --> 02:04:58.100]   Not only do you not need blockchain to do it, blockchain gets in the way.
[02:04:58.100 --> 02:04:59.100]   Yes.
[02:04:59.100 --> 02:05:01.060]   Of course, it should be cheaper to transfer money everywhere.
[02:05:01.060 --> 02:05:02.060]   Of course.
[02:05:02.060 --> 02:05:03.060]   But why isn't it?
[02:05:03.060 --> 02:05:07.620]   Is it because it costs like Visa MasterCard or Swift too much money to send those electrons?
[02:05:07.620 --> 02:05:10.980]   No, it costs that much money because somebody likes it.
[02:05:10.980 --> 02:05:15.020]   So if you want to make a non-explanatory financial system, the way to do it is to make
[02:05:15.020 --> 02:05:16.900]   a non-explanatory financial system.
[02:05:16.900 --> 02:05:17.900]   Make transfer-wise.
[02:05:17.900 --> 02:05:20.660]   Like transfer-wise or wise, I think they're just renamed.
[02:05:20.660 --> 02:05:21.660]   Right?
[02:05:21.660 --> 02:05:24.540]   Like, yeah, they let you send money to lots of places and they give you the cheapest possible
[02:05:24.540 --> 02:05:25.540]   rate.
[02:05:25.540 --> 02:05:30.260]   And like, it's not blockchain because it turns out like all you need to do is be like, I'm
[02:05:30.260 --> 02:05:33.260]   going to make a bank and I'm not going to screw people.
[02:05:33.260 --> 02:05:34.260]   Yeah.
[02:05:34.260 --> 02:05:37.340]   And it has nothing to do with like burning down the whole tech stack.
[02:05:37.340 --> 02:05:40.340]   No, it has to be with trying to make something non-explanatory.
[02:05:40.340 --> 02:05:41.340]   Right.
[02:05:41.340 --> 02:05:42.340]   Which I totally support.
[02:05:42.340 --> 02:05:43.340]   Right.
[02:05:43.340 --> 02:05:46.020]   Transfer wise, right, which is wise now that I've used them for years as a small business
[02:05:46.020 --> 02:05:50.020]   person where I have to send sometimes relatively large money when I get a book letter pressed
[02:05:50.020 --> 02:05:51.020]   printed in London.
[02:05:51.020 --> 02:05:55.100]   Leo, I have to send money to thousands of pounds to a printer in London.
[02:05:55.100 --> 02:05:59.020]   It's very complicated to do that and I've used that service because right, they use technology
[02:05:59.020 --> 02:06:01.780]   to actually make things better and to make-
[02:06:01.780 --> 02:06:02.780]   I am glad to know this.
[02:06:02.780 --> 02:06:03.780]   Real-time and transparent.
[02:06:03.780 --> 02:06:06.180]   Because we use PayPal to pay people overseas.
[02:06:06.180 --> 02:06:07.180]   Yeah.
[02:06:07.180 --> 02:06:08.380]   But they charge a lot.
[02:06:08.380 --> 02:06:09.380]   Yeah.
[02:06:09.380 --> 02:06:10.540]   Wise charges the least.
[02:06:10.540 --> 02:06:13.540]   Not only, it's not that they charge the least, they expose all their fees.
[02:06:13.540 --> 02:06:15.220]   So sometimes they're a better alternative.
[02:06:15.220 --> 02:06:17.420]   Sometimes I've done a direct wire through my credit union.
[02:06:17.420 --> 02:06:22.860]   But often I can use this and the money, there's some people, a podcasting editor I pay from
[02:06:22.860 --> 02:06:23.860]   time to time in Canada.
[02:06:23.860 --> 02:06:27.860]   And he gets the money sometimes like 10 minutes after I initiate the transfer.
[02:06:27.860 --> 02:06:28.860]   Yeah.
[02:06:28.860 --> 02:06:29.860]   You know, that kind of thing.
[02:06:29.860 --> 02:06:30.860]   Yeah.
[02:06:30.860 --> 02:06:35.900]   So we have many payees over out of the US and I don't want to say overseas because they're
[02:06:35.900 --> 02:06:37.540]   not overseas to themselves.
[02:06:37.540 --> 02:06:39.300]   We're overseas to them.
[02:06:39.300 --> 02:06:41.460]   Outside of the US.
[02:06:41.460 --> 02:06:43.620]   And we, yeah, that's good.
[02:06:43.620 --> 02:06:45.820]   I'll tell Lisa because this is good.
[02:06:45.820 --> 02:06:46.820]   Yeah.
[02:06:46.820 --> 02:06:49.180]   I have no financial, I assume Phil has no financial issues.
[02:06:49.180 --> 02:06:50.180]   I just, I did them.
[02:06:50.180 --> 02:06:53.140]   I just, really, it's great when you find something where you're like, this actually works and
[02:06:53.140 --> 02:06:56.140]   saves you money and it's technology done right.
[02:06:56.140 --> 02:07:01.340]   And I understand that for a lot of people, you know, Jay-Z started a school about crypto
[02:07:01.340 --> 02:07:07.980]   and under-served poor neighbourhood because he felt like it was going to help people who
[02:07:07.980 --> 02:07:15.060]   have been underserved or even worse, you know, redlined by traditional financial institutions
[02:07:15.060 --> 02:07:18.060]   to create their own financial future.
[02:07:18.060 --> 02:07:19.260]   It's unfortunate.
[02:07:19.260 --> 02:07:22.940]   And that's the problem because Bitcoin is not the answer.
[02:07:22.940 --> 02:07:25.340]   There are answers, but it's not the answer.
[02:07:25.340 --> 02:07:26.340]   Crypto is not the answer.
[02:07:26.340 --> 02:07:27.340]   No shortcut to it.
[02:07:27.340 --> 02:07:28.340]   Yeah.
[02:07:28.340 --> 02:07:29.340]   Yeah.
[02:07:29.340 --> 02:07:31.500]   I think like in general my, my Eurystek on this stuff is when you look at anything that's
[02:07:31.500 --> 02:07:36.020]   really screwed up in the world and you know, financial institutions is definitely one of
[02:07:36.020 --> 02:07:39.180]   them, but you pretty much don't get anything that's really screwed up in the world.
[02:07:39.180 --> 02:07:40.980]   And you kind of ask, well, why is this screwed up?
[02:07:40.980 --> 02:07:44.660]   The answer is almost all the time because somebody likes it that way.
[02:07:44.660 --> 02:07:48.660]   And then you have to say why, Quibono as they say.
[02:07:48.660 --> 02:07:49.660]   Yeah.
[02:07:49.660 --> 02:07:50.660]   And right.
[02:07:50.660 --> 02:07:51.660]   And the analysis is like, well, who likes it?
[02:07:51.660 --> 02:07:52.660]   Right.
[02:07:52.660 --> 02:07:53.660]   And what do they like about it?
[02:07:53.660 --> 02:07:56.540]   And what can we give them to like more than what they're going to like about it?
[02:07:56.540 --> 02:07:57.540]   Right.
[02:07:57.540 --> 02:07:59.940]   And, and very rarely is the answer.
[02:07:59.940 --> 02:08:01.340]   Well, why is something screwed up in the world?
[02:08:01.340 --> 02:08:05.540]   Oh, it's because we need a completely, we need to burn things to the ground and have
[02:08:05.540 --> 02:08:08.780]   something completely different and that's not a good answer.
[02:08:08.780 --> 02:08:10.140]   That's not not usually.
[02:08:10.140 --> 02:08:11.140]   No.
[02:08:11.140 --> 02:08:12.140]   Yeah.
[02:08:12.140 --> 02:08:16.100]   So yeah, but look, I'm glad we're having this conversation because us four old guys
[02:08:16.100 --> 02:08:18.580]   are totally going to kill web three.
[02:08:18.580 --> 02:08:23.140]   I assume that everything everyone that's heard it is like, well, we're done with this.
[02:08:23.140 --> 02:08:26.660]   And well, I've been saying I've been beating this drum for a while when when when this
[02:08:26.660 --> 02:08:30.380]   all first started, we were very interested in the technology as a lot of technologists
[02:08:30.380 --> 02:08:31.380]   were.
[02:08:31.380 --> 02:08:37.540]   But it's become pretty clear over the last year, started with NFTs and it's become pretty
[02:08:37.540 --> 02:08:38.540]   clear.
[02:08:38.540 --> 02:08:44.060]   And I think any so, so the answer my my initial question, it sounds like even though FTX doesn't
[02:08:44.060 --> 02:08:50.620]   tarnish all of crypto, it is kind of an eye opener that in the long run shows us this
[02:08:50.620 --> 02:08:52.740]   is not the path.
[02:08:52.740 --> 02:08:54.740]   Both things can be true at the same time.
[02:08:54.740 --> 02:09:02.180]   FTX is almost certainly, you know, a giant scam and regardless of crypto or not, it's
[02:09:02.180 --> 02:09:04.660]   just like its own thing again.
[02:09:04.660 --> 02:09:11.300]   You know, he's just put up a sign which I have to read now because 90% of the audience
[02:09:11.300 --> 02:09:14.860]   doesn't see your sign, not legal advice, not financial advice.
[02:09:14.860 --> 02:09:18.260]   This is all as I remember it by my memory might be faulty in parts.
[02:09:18.260 --> 02:09:19.260]   That's great.
[02:09:19.260 --> 02:09:20.260]   Can I have that for my show?
[02:09:20.260 --> 02:09:21.260]   That's wonderful.
[02:09:21.260 --> 02:09:23.660]   This is I'm just I'm just this is a direct quote from SPF.
[02:09:23.660 --> 02:09:26.060]   Is this is this is that what SPF says really?
[02:09:26.060 --> 02:09:29.180]   Yeah, this is a direct quote.
[02:09:29.180 --> 02:09:32.940]   And so yeah, so it's it's the Trumpian and it's brilliance.
[02:09:32.940 --> 02:09:37.980]   Yeah, it's it's probably FTX is a giant scam that would have been a scam even if it wasn't
[02:09:37.980 --> 02:09:42.500]   crypto and at the same time, crypto is a scam too.
[02:09:42.500 --> 02:09:44.700]   Are these two scams operating at the same time?
[02:09:44.700 --> 02:09:52.100]   Are these valid technologies valid advanced technologies that the scammers and the criminals
[02:09:52.100 --> 02:09:55.740]   get to first and ruin it for the bless a good question.
[02:09:55.740 --> 02:10:00.700]   It's a very good question, but I don't think so because again, like, okay, I built some
[02:10:00.700 --> 02:10:01.700]   stuff, right?
[02:10:01.700 --> 02:10:07.700]   That's like I guess web two and some stuff in web one and we build stuff before there
[02:10:07.700 --> 02:10:09.980]   was hype around it, right?
[02:10:09.980 --> 02:10:12.340]   We weren't like, Oh, look at us.
[02:10:12.340 --> 02:10:14.620]   We're building web 2.0.
[02:10:14.620 --> 02:10:18.580]   We build things and then millions of people use them and got benefit from it.
[02:10:18.580 --> 02:10:22.100]   And I don't mean like, I mean, by we, I mean, like ever know, but also like Dropbox and
[02:10:22.100 --> 02:10:27.220]   Uber and box and what's left and before that Yahoo and Google and Amazon and millions and
[02:10:27.220 --> 02:10:31.660]   millions and millions of people used it and loved it and got value out of it.
[02:10:31.660 --> 02:10:33.500]   And there wasn't like, there wasn't hype.
[02:10:33.500 --> 02:10:37.340]   It was like, you know, we weren't saying that this is like some new thing, we just build
[02:10:37.340 --> 02:10:39.500]   stuff that works.
[02:10:39.500 --> 02:10:41.540]   And it was mostly built by engineers.
[02:10:41.540 --> 02:10:44.740]   And then we have three, the engineers, like for the most part, there's actually not a lot
[02:10:44.740 --> 02:10:45.940]   of interesting technology in here.
[02:10:45.940 --> 02:10:46.940]   It's not a technologist thing.
[02:10:46.940 --> 02:10:50.980]   I think the reason Leo that you're kind of skeptical about it is like, your history is
[02:10:50.980 --> 02:10:54.940]   like your tech person and crypto is not tech, crypto is finance.
[02:10:54.940 --> 02:10:55.940]   Yeah.
[02:10:55.940 --> 02:10:59.620]   A bunch of the finance bros got involved and they just, there's just gibberish like all
[02:10:59.620 --> 02:11:02.180]   finance people.
[02:11:02.180 --> 02:11:06.540]   And they started like hyping this web three thing before there's a single, there's a single
[02:11:06.540 --> 02:11:10.620]   use case that's actually being used by millions of people getting value that isn't like self
[02:11:10.620 --> 02:11:14.900]   referential, that isn't about buying more crypto and scamming other people out of like
[02:11:14.900 --> 02:11:15.900]   crypto.
[02:11:15.900 --> 02:11:21.380]   And so like this is a case where like I understand that yes, there should be some, if we're going
[02:11:21.380 --> 02:11:24.860]   to call, if we're going to claim what like, you know, the previous generation was web
[02:11:24.860 --> 02:11:27.580]   two, then of course there's going to be something called web three because three is a larger
[02:11:27.580 --> 02:11:31.820]   number than two and it comes afterwards and like I get it and somebody will build something
[02:11:31.820 --> 02:11:34.380]   but it's not going to be based on the blockchain because the blockchain is a pretty idiotic
[02:11:34.380 --> 02:11:35.580]   idea technically.
[02:11:35.580 --> 02:11:41.460]   Like it's kind of interesting intellectually, not really, but, but technically like almost
[02:11:41.460 --> 02:11:45.740]   nothing could be built on it that's real and nothing has been built on at this real.
[02:11:45.740 --> 02:11:47.140]   And it's been long enough.
[02:11:47.140 --> 02:11:48.980]   Where's the real stuff?
[02:11:48.980 --> 02:11:50.500]   Where's the stuff built on blockchain?
[02:11:50.500 --> 02:11:55.700]   Again, that isn't self referential, that isn't about like speculating on other blockchain
[02:11:55.700 --> 02:11:56.700]   stuff, right?
[02:11:56.700 --> 02:12:02.340]   Like the first book, like it would be as if when Amazon got started for a while, you
[02:12:02.340 --> 02:12:06.180]   can only buy books about how to sell books on the internet.
[02:12:06.180 --> 02:12:09.820]   It's like all the books on Amazon were just like other how to books about how to sell
[02:12:09.820 --> 02:12:10.820]   books on the internet.
[02:12:10.820 --> 02:12:13.500]   And they'd be like, see it's successful.
[02:12:13.500 --> 02:12:15.700]   Look at all these books we have about how to sell books on the internet.
[02:12:15.700 --> 02:12:18.700]   Make money at home in your spare time.
[02:12:18.700 --> 02:12:23.260]   It would be like if YouTube got started and like all of the videos on YouTube was about
[02:12:23.260 --> 02:12:24.900]   like how to post videos on the internet.
[02:12:24.900 --> 02:12:25.900]   Yeah.
[02:12:25.900 --> 02:12:26.900]   Yeah.
[02:12:26.900 --> 02:12:27.900]   And like, but that's what web three is.
[02:12:27.900 --> 02:12:30.500]   It's all about just like more web three speculation.
[02:12:30.500 --> 02:12:32.340]   It's not anything.
[02:12:32.340 --> 02:12:33.340]   It's circular.
[02:12:33.340 --> 02:12:34.340]   It doesn't.
[02:12:34.340 --> 02:12:37.460]   It's just, it's good because it's good because it's good because it's good.
[02:12:37.460 --> 02:12:43.300]   Tim Bernardo the creator of the actual worldwide web is working on just what you talked about
[02:12:43.300 --> 02:12:45.300]   kind of a next generation web.
[02:12:45.300 --> 02:12:47.500]   He says ignore web three.
[02:12:47.500 --> 02:12:49.420]   Web three is not the web at all.
[02:12:49.420 --> 02:12:50.420]   He says.
[02:12:50.420 --> 02:12:51.420]   Yeah.
[02:12:51.420 --> 02:12:52.420]   Yeah.
[02:12:52.420 --> 02:12:54.660]   Who came up with the term web three?
[02:12:54.660 --> 02:12:55.660]   Mark Anderson.
[02:12:55.660 --> 02:12:56.660]   Where did that come from?
[02:12:56.660 --> 02:12:57.660]   Probably.
[02:12:57.660 --> 02:12:58.660]   Yeah.
[02:12:58.660 --> 02:12:59.660]   Probably.
[02:12:59.660 --> 02:13:00.660]   It wasn't Zuckerberg.
[02:13:00.660 --> 02:13:03.660]   I don't think we woke up one day and everyone was talking about it and nobody could define
[02:13:03.660 --> 02:13:04.660]   it.
[02:13:04.660 --> 02:13:05.660]   It was great.
[02:13:05.660 --> 02:13:06.660]   Yeah.
[02:13:06.660 --> 02:13:07.660]   It didn't do it.
[02:13:07.660 --> 02:13:08.660]   Was it me?
[02:13:08.660 --> 02:13:11.060]   It's according to a 16 Z web three.
[02:13:11.060 --> 02:13:13.740]   We deserve a better internet.
[02:13:13.740 --> 02:13:14.740]   We do.
[02:13:14.740 --> 02:13:18.020]   Web three, the third generation of the internet, a group of technologies at a campus is digital
[02:13:18.020 --> 02:13:23.300]   assets, decentralized finance, blockchains, tokens and dows, baby.
[02:13:23.300 --> 02:13:24.300]   No.
[02:13:24.300 --> 02:13:25.300]   No.
[02:13:25.300 --> 02:13:26.300]   No.
[02:13:26.300 --> 02:13:27.300]   That's not the internet we deserve.
[02:13:27.300 --> 02:13:29.300]   What ever happened to the internet to?
[02:13:29.300 --> 02:13:30.300]   We're living in it.
[02:13:30.300 --> 02:13:31.300]   Yeah.
[02:13:31.300 --> 02:13:32.300]   We're living in it.
[02:13:32.300 --> 02:13:34.020]   No, that was like a fast web.
[02:13:34.020 --> 02:13:35.020]   Web 2.0.
[02:13:35.020 --> 02:13:36.020]   Remember Web 2.0?
[02:13:36.020 --> 02:13:38.860]   I think it was a web apps, right?
[02:13:38.860 --> 02:13:39.860]   Yeah.
[02:13:39.860 --> 02:13:42.460]   In Florida, it was like interactive pages without reloading.
[02:13:42.460 --> 02:13:44.580]   It was like, remember Ajax?
[02:13:44.580 --> 02:13:45.580]   It was Ajax.
[02:13:45.580 --> 02:13:46.580]   It's still there.
[02:13:46.580 --> 02:13:47.580]   It's just not called anymore.
[02:13:47.580 --> 02:13:48.580]   It's React, right?
[02:13:48.580 --> 02:13:51.580]   I did a lot of low level Ajax programs.
[02:13:51.580 --> 02:13:52.580]   Yeah.
[02:13:52.580 --> 02:13:54.020]   It was learned to think low level JavaScript.
[02:13:54.020 --> 02:13:59.820]   There's a bunch of people that who aren't technologies and who aren't finance people.
[02:13:59.820 --> 02:14:02.700]   And to them, which is most of the world, most of the world is neither technologies from
[02:14:02.700 --> 02:14:03.700]   finance people.
[02:14:03.700 --> 02:14:09.340]   And to them, we may look the same because like we're both sort of like babble a lot and
[02:14:09.340 --> 02:14:11.500]   use like weird language.
[02:14:11.500 --> 02:14:16.500]   So I can see why for many people in the world, they would confuse technology with finance.
[02:14:16.500 --> 02:14:17.500]   But we're pretty different people.
[02:14:17.500 --> 02:14:18.500]   We're different.
[02:14:18.500 --> 02:14:19.500]   We're the nerds.
[02:14:19.500 --> 02:14:20.500]   Yeah.
[02:14:20.500 --> 02:14:21.700]   All right, let's take a break.
[02:14:21.700 --> 02:14:23.700]   I have some final stories to wrap up.
[02:14:23.700 --> 02:14:25.620]   I could go for hours with you guys.
[02:14:25.620 --> 02:14:28.060]   This is, for me, is like fit.
[02:14:28.060 --> 02:14:29.900]   I am, my eyes are opened.
[02:14:29.900 --> 02:14:31.420]   The scales have fallen.
[02:14:31.420 --> 02:14:35.460]   I'm going to throw my Bitcoin wallet into the sea virtually.
[02:14:35.460 --> 02:14:36.460]   The open sea.
[02:14:36.460 --> 02:14:37.460]   Don't throw it to the trashy.
[02:14:37.460 --> 02:14:38.460]   The open sea.
[02:14:38.460 --> 02:14:40.660]   You have to pay someone to dig it out of the trashy.
[02:14:40.660 --> 02:14:41.820]   He's never going to get it.
[02:14:41.820 --> 02:14:43.260]   Glenn Fleischman is here.
[02:14:43.260 --> 02:14:44.260]   Glenn.fun.
[02:14:44.260 --> 02:14:47.540]   Two ends, but lots of fun.
[02:14:47.540 --> 02:14:53.620]   Mr. Dwight Silverman, author.com/d silverman and the wonderful Phil Libbon.
[02:14:53.620 --> 02:14:54.820]   Mm hmm.
[02:14:54.820 --> 02:14:57.060]   Mm hmm.app.app.
[02:14:57.060 --> 02:14:59.180]   That's how he makes it snow, man.
[02:14:59.180 --> 02:15:00.980]   That's how he does it.
[02:15:00.980 --> 02:15:02.060]   We are going to take a little break.
[02:15:02.060 --> 02:15:07.500]   Come back with about 12 very quick stories just because I want to wrap it up in a couple
[02:15:07.500 --> 02:15:08.740]   of obituaries too.
[02:15:08.740 --> 02:15:13.620]   Our show today brought to you by ExpressVPN.
[02:15:13.620 --> 02:15:17.500]   We talk a lot about VPNs, the idea that you protect your privacy online.
[02:15:17.500 --> 02:15:22.140]   If you use a VPN that you protect your security, if you're an open Wi-Fi access point, that
[02:15:22.140 --> 02:15:27.020]   you can watch, you know, Netflix in Japan, if you like manga.
[02:15:27.020 --> 02:15:30.100]   Those benefits are real for a VPN.
[02:15:30.100 --> 02:15:35.740]   In effect, you take your browsing and you encrypt it and then you emerge into the public
[02:15:35.740 --> 02:15:37.340]   internet somewhere else.
[02:15:37.340 --> 02:15:41.380]   But I got to point out, it's really important that you choose the right provider because
[02:15:41.380 --> 02:15:46.620]   everything you're protecting yourself against with your VPN is suddenly available to the
[02:15:46.620 --> 02:15:47.620]   server.
[02:15:47.620 --> 02:15:52.620]   The other end, when you emerge, the encryption goes away, you know, you've got to choose a
[02:15:52.620 --> 02:15:59.380]   VPN provider who cares as much about your privacy and security as you do, who takes the
[02:15:59.380 --> 02:16:05.460]   money and by the way, never trust a free VPN ever because they have to monetize somehow.
[02:16:05.460 --> 02:16:06.460]   How do they do it?
[02:16:06.460 --> 02:16:07.460]   You.
[02:16:07.460 --> 02:16:12.740]   So, takes the money, you pay them a reasonable, fair amount of money and invests it in servers
[02:16:12.740 --> 02:16:14.300]   all over the world.
[02:16:14.300 --> 02:16:19.820]   Good bandwidth for every one of those servers rotates their IP addresses so that it's fresh
[02:16:19.820 --> 02:16:21.660]   every time you use it.
[02:16:21.660 --> 02:16:26.780]   And somebody who takes the time to make sure that your privacy is 100% protected, that's
[02:16:26.780 --> 02:16:28.420]   ExpressVPN.
[02:16:28.420 --> 02:16:32.140]   There was a great article I recommended if you're at all interested in leaping computer
[02:16:32.140 --> 02:16:34.500]   about how ExpressVPN works.
[02:16:34.500 --> 02:16:40.340]   They use a custom Debian distribution that wipes the drive on reboot and they reboot
[02:16:40.340 --> 02:16:41.340]   every day.
[02:16:41.340 --> 02:16:48.020]   So even if they were logging your activity, it'd be gone every morning when they started
[02:16:48.020 --> 02:16:52.460]   up fresh, but they're not logging because they also invented something called trusted
[02:16:52.460 --> 02:16:57.820]   server, which is a VPN server that runs in RAM only sandboxed.
[02:16:57.820 --> 02:17:00.500]   It cannot write to the hard drive.
[02:17:00.500 --> 02:17:04.460]   So when you press that big button on your ExpressVPN app, it launches that server.
[02:17:04.460 --> 02:17:09.220]   That server in RAM, it disappears when you close it and that's it.
[02:17:09.220 --> 02:17:10.700]   And we know it works.
[02:17:10.700 --> 02:17:15.900]   We know it works because they have independent third party audits that say, yes, they adhere
[02:17:15.900 --> 02:17:17.460]   to their privacy policy.
[02:17:17.460 --> 02:17:21.940]   Yes, trusted server works as stated.
[02:17:21.940 --> 02:17:22.940]   It's just really good.
[02:17:22.940 --> 02:17:24.780]   They're now using something new called lightweight.
[02:17:24.780 --> 02:17:30.220]   This is a new VPN protocol that they engineered to make user speeds faster than ever.
[02:17:30.220 --> 02:17:33.580]   I know sometimes when I talk about VPNs, people say, well, I don't want to slow my connection
[02:17:33.580 --> 02:17:34.580]   on.
[02:17:34.580 --> 02:17:38.140]   ExpressVPN is so fast, you'll forget you're using it.
[02:17:38.140 --> 02:17:42.300]   In fact, I often forget and leave it on, which is fine.
[02:17:42.300 --> 02:17:44.940]   You could stream video and HD quality, no buffering.
[02:17:44.940 --> 02:17:49.260]   It's thanks to this great lightweight VPN protocol.
[02:17:49.260 --> 02:17:50.420]   Really, really cool.
[02:17:50.420 --> 02:17:53.180]   ExpressVPN runs on everything you've got.
[02:17:53.180 --> 02:17:59.020]   Your Android, your iOS device, your Windows PC, your Mac, your Linux, your Chromebook.
[02:17:59.020 --> 02:18:02.220]   You can even use ExpressVPN on your router.
[02:18:02.220 --> 02:18:06.900]   They sell routers now with ExpressVPN on the router.
[02:18:06.900 --> 02:18:11.500]   And it's not just me saying this, business insider, the Verge, many other tech journals,
[02:18:11.500 --> 02:18:14.260]   rate ExpressVPN, the number one in the world for those reasons.
[02:18:14.260 --> 02:18:16.740]   Now, you say, all right, well, it's not free how much.
[02:18:16.740 --> 02:18:17.740]   It's not much.
[02:18:17.740 --> 02:18:19.540]   About seven bucks a month.
[02:18:19.540 --> 02:18:21.780]   And I'm telling you, you paid less than that.
[02:18:21.780 --> 02:18:24.700]   That's because they're taking advantage of you.
[02:18:24.700 --> 02:18:27.380]   Protect yourself with the VPN I use and trust.
[02:18:27.380 --> 02:18:28.740]   Go to expressvpn.com/twit.
[02:18:28.740 --> 02:18:35.260]   They've got a 30 day money back guarantee so you can verify everything I say is true.
[02:18:35.260 --> 02:18:37.660]   When you buy a one year package, you'll get three months free.
[02:18:37.660 --> 02:18:40.740]   That brings the price down to less than seven bucks a month.
[02:18:40.740 --> 02:18:42.300]   This is the key.
[02:18:42.300 --> 02:18:43.900]   You got to trust the server.
[02:18:43.900 --> 02:18:45.180]   You got to trust the server.
[02:18:45.180 --> 02:18:46.500]   I trust ExpressVPN.
[02:18:46.500 --> 02:18:48.060]   I think you should too.
[02:18:48.060 --> 02:18:50.660]   Expressvpn.com/twit.
[02:18:50.660 --> 02:18:53.580]   We thank them so much for supporting this week in tech.
[02:18:53.580 --> 02:18:57.460]   And we thank you when you use that address, when you buy ExpressVPN, we then they say,
[02:18:57.460 --> 02:19:01.060]   all that, those ads work and they buy more of them.
[02:19:01.060 --> 02:19:05.140]   Expressvpn.com/twit.
[02:19:05.140 --> 02:19:06.620]   We had a great week on Twit this week.
[02:19:06.620 --> 02:19:09.700]   We've prepared a little video presentation.
[02:19:09.700 --> 02:19:10.700]   We didn't use them.
[02:19:10.700 --> 02:19:12.180]   Maybe we should have watched.
[02:19:12.180 --> 02:19:14.940]   I think Charles Hayden Savage is on the line.
[02:19:14.940 --> 02:19:15.940]   Am I correct?
[02:19:15.940 --> 02:19:16.940]   Yes.
[02:19:16.940 --> 02:19:22.140]   Charles Hayden Savage is here and just to be clear for those of you who aren't up to
[02:19:22.140 --> 02:19:23.940]   the latest hit thing.
[02:19:23.940 --> 02:19:27.860]   I'm actually Steve Martin here on the phone with my old friend Leo.
[02:19:27.860 --> 02:19:31.300]   Previously on Twit, the tech guy.
[02:19:31.300 --> 02:19:36.820]   The reason I'm calling in is because there's a little announcement.
[02:19:36.820 --> 02:19:41.940]   I wanted you to tell people so they wouldn't, you know, get mad about.
[02:19:41.940 --> 02:19:42.940]   You cheer them up.
[02:19:42.940 --> 02:19:43.940]   You need them down.
[02:19:43.940 --> 02:19:50.300]   At the end of this year, Mr. Leo Laporte will be retiring from the radio.
[02:19:50.300 --> 02:19:51.780]   Is that accurate Leo?
[02:19:51.780 --> 02:19:52.780]   That is accurate.
[02:19:52.780 --> 02:19:53.780]   I, uh...
[02:19:53.780 --> 02:19:54.780]   Wow.
[02:19:54.780 --> 02:19:55.780]   I mean...
[02:19:55.780 --> 02:19:59.580]   I've been doing this show almost as long as you lived in the Arconia.
[02:19:59.580 --> 02:20:00.580]   All about Android.
[02:20:00.580 --> 02:20:04.620]   I'm going to be reviewing the Logitech G Cloud gaming device.
[02:20:04.620 --> 02:20:05.940]   I don't know man.
[02:20:05.940 --> 02:20:09.660]   When you compare it against the Steam Deck that does a ton more, I feel like the price
[02:20:09.660 --> 02:20:10.660]   is off.
[02:20:10.660 --> 02:20:13.940]   If this was a hundred, hundred, fifty dollars cheaper, I feel like it would be a no-brainer.
[02:20:13.940 --> 02:20:16.460]   Today on This Week in Space, who is Q?
[02:20:16.460 --> 02:20:18.380]   We visit with John Delancy.
[02:20:18.380 --> 02:20:24.580]   The closest that I could say is that he was an omnipotent being who was too stupid to
[02:20:24.580 --> 02:20:25.580]   know.
[02:20:25.580 --> 02:20:26.580]   I'm very...
[02:20:26.580 --> 02:20:32.260]   I just knocked behind me and said, "You have no idea what you've gotten yourself into."
[02:20:32.260 --> 02:20:41.460]   He was giving me a little bit of insight into the world that for the last thirty years has
[02:20:41.460 --> 02:20:44.180]   continued to reveal itself to me.
[02:20:44.180 --> 02:20:46.980]   If you missed Twit this week, you missed a lot.
[02:20:46.980 --> 02:20:48.980]   That's my last question.
[02:20:48.980 --> 02:20:49.980]   Okay.
[02:20:49.980 --> 02:20:50.980]   And, Matthew, you can...
[02:20:50.980 --> 02:20:51.980]   This will be your department.
[02:20:51.980 --> 02:20:52.980]   All right, stretching.
[02:20:52.980 --> 02:20:53.980]   I'm ready.
[02:20:53.980 --> 02:20:54.980]   I have some shortcuts.
[02:20:54.980 --> 02:20:55.980]   Wow.
[02:20:55.980 --> 02:20:58.180]   I'm telling you, this guy's good.
[02:20:58.180 --> 02:20:59.180]   Look at...
[02:20:59.180 --> 02:21:00.180]   Okay.
[02:21:00.180 --> 02:21:02.180]   He sent us his shortcuts.
[02:21:02.180 --> 02:21:04.380]   Micah is analyzing them now.
[02:21:04.380 --> 02:21:05.380]   Steve Martin, you...
[02:21:05.380 --> 02:21:06.380]   I'm so cool.
[02:21:06.380 --> 02:21:08.380]   I'm going to have to tune into that episode.
[02:21:08.380 --> 02:21:09.380]   I owe...
[02:21:09.380 --> 02:21:10.380]   Well, he was...
[02:21:10.380 --> 02:21:11.380]   You're pretty much son.
[02:21:11.380 --> 02:21:12.380]   He wasn't there that long.
[02:21:12.380 --> 02:21:13.380]   So...
[02:21:13.380 --> 02:21:16.780]   I owe Twitter for no one, Steve.
[02:21:16.780 --> 02:21:17.860]   Steve listens to the shows.
[02:21:17.860 --> 02:21:19.700]   I did not know that.
[02:21:19.700 --> 02:21:22.180]   But he d-end me on Twitter and said, "Hi, Steve Martin.
[02:21:22.180 --> 02:21:23.580]   You don't have to answer this."
[02:21:23.580 --> 02:21:25.580]   But I'm a big fan.
[02:21:25.580 --> 02:21:26.580]   And I said, "Yeah, yeah.
[02:21:26.580 --> 02:21:27.580]   I'm not going to answer that.
[02:21:27.580 --> 02:21:29.580]   Why would anyone want to talk to Steve?"
[02:21:29.580 --> 02:21:30.580]   And we formed...
[02:21:30.580 --> 02:21:31.580]   That was fifteen years ago.
[02:21:31.580 --> 02:21:32.580]   We formed a friend...
[02:21:32.580 --> 02:21:33.580]   That's lovely.
[02:21:33.580 --> 02:21:34.580]   Nice guy.
[02:21:34.580 --> 02:21:36.580]   That's how I got to know Rosanne Cash a little bit was through Twitter.
[02:21:36.580 --> 02:21:37.580]   Yeah, same thing.
[02:21:37.580 --> 02:21:38.580]   I think that's why Twitter...
[02:21:38.580 --> 02:21:39.580]   Twitter for so many of us...
[02:21:39.580 --> 02:21:40.580]   Not really was small.
[02:21:40.580 --> 02:21:41.580]   Not really was small.
[02:21:41.580 --> 02:21:43.580]   And Steve, remember he did a whole book of his tweets.
[02:21:43.580 --> 02:21:46.340]   He was the funniest guy on Twitter.
[02:21:46.340 --> 02:21:47.340]   Really good stuff.
[02:21:47.340 --> 02:21:50.740]   A little less a Twitter guy.
[02:21:50.740 --> 02:21:51.740]   He stays.
[02:21:51.740 --> 02:21:52.740]   I didn't ask him.
[02:21:52.740 --> 02:21:53.740]   I didn't want to say.
[02:21:53.740 --> 02:21:54.740]   I didn't want to...
[02:21:54.740 --> 02:21:56.540]   He's a very sweet guy.
[02:21:56.540 --> 02:21:57.540]   He's a cartoonist now.
[02:21:57.540 --> 02:21:59.340]   He's a cartoon writer with very bad books.
[02:21:59.340 --> 02:22:00.340]   Oh, it means.
[02:22:00.340 --> 02:22:01.340]   Yes.
[02:22:01.340 --> 02:22:05.620]   Well, that's how it happened is he sent me his new book and he said, "I miss talking to
[02:22:05.620 --> 02:22:06.620]   you."
[02:22:06.620 --> 02:22:07.620]   He autographed it.
[02:22:07.620 --> 02:22:09.020]   I said, "Oh, well, we can handle that."
[02:22:09.020 --> 02:22:10.020]   That's...
[02:22:10.020 --> 02:22:11.020]   But it's a very funny book.
[02:22:11.020 --> 02:22:12.020]   Have you seen it?
[02:22:12.020 --> 02:22:13.020]   I've got the first one.
[02:22:13.020 --> 02:22:14.020]   Is there a second one now?
[02:22:14.020 --> 02:22:15.020]   There's an idea.
[02:22:15.020 --> 02:22:18.660]   The Pigeons book and his newest just came out.
[02:22:18.660 --> 02:22:20.460]   See, I'm giving it a plug.
[02:22:20.460 --> 02:22:21.460]   He hates it.
[02:22:21.460 --> 02:22:23.620]   He hates it when I give him plugs.
[02:22:23.620 --> 02:22:25.100]   He always says, "I plugged the book."
[02:22:25.100 --> 02:22:28.020]   And he goes, "Nah, Leo, you don't have to do that."
[02:22:28.020 --> 02:22:29.020]   The plug is...
[02:22:29.020 --> 02:22:31.020]   His new book is with Harry Bliss.
[02:22:31.020 --> 02:22:33.140]   It's called Number One is Walking.
[02:22:33.140 --> 02:22:34.140]   It's all right.
[02:22:34.140 --> 02:22:35.140]   You don't have to go get it.
[02:22:35.140 --> 02:22:36.140]   It's all right.
[02:22:36.140 --> 02:22:37.140]   Number one is walking.
[02:22:37.140 --> 02:22:39.340]   I highly recommend it.
[02:22:39.340 --> 02:22:44.860]   His memories of his life in the movies.
[02:22:44.860 --> 02:22:46.020]   It's very funny.
[02:22:46.020 --> 02:22:47.500]   Harry Bliss is a great illustrator.
[02:22:47.500 --> 02:22:52.660]   I don't know if it was praise or not, but I said, "Steve, this reminds me a lot of mouse
[02:22:52.660 --> 02:22:53.660]   by Art Spiegelman."
[02:22:53.660 --> 02:22:54.660]   Wow.
[02:22:54.660 --> 02:22:56.580]   Mine is the Holocaust thing.
[02:22:56.580 --> 02:22:58.580]   That's a good one.
[02:22:58.580 --> 02:22:59.580]   Holy cow.
[02:22:59.580 --> 02:23:00.580]   Yeah, but it always...
[02:23:00.580 --> 02:23:02.220]   Oh, I saw some of this in the New Yorker.
[02:23:02.220 --> 02:23:03.220]   Yeah, yeah.
[02:23:03.220 --> 02:23:04.220]   It's really good.
[02:23:04.220 --> 02:23:05.820]   But it's beautifully drawn.
[02:23:05.820 --> 02:23:07.140]   Then there's a bunch of cartoons.
[02:23:07.140 --> 02:23:08.340]   I said, "Steve, did you...
[02:23:08.340 --> 02:23:09.340]   How does that work?"
[02:23:09.340 --> 02:23:10.540]   He says, "Yeah, I write the punch lines."
[02:23:10.540 --> 02:23:12.220]   Then Harry does the cartoon.
[02:23:12.220 --> 02:23:16.740]   It's Steve Martin, his most admirable person for figuring out what stage of his career
[02:23:16.740 --> 02:23:17.740]   he's in.
[02:23:17.740 --> 02:23:18.740]   Oh.
[02:23:18.740 --> 02:23:20.740]   His autobiography was so wonderful in talking about how...
[02:23:20.740 --> 02:23:22.740]   So this is the sequel to Martin standing up.
[02:23:22.740 --> 02:23:23.740]   Oh, okay.
[02:23:23.740 --> 02:23:24.740]   Oh, it's the...
[02:23:24.740 --> 02:23:25.740]   I see in this one's illustrator.
[02:23:25.740 --> 02:23:28.020]   Born standing up, the way that he said...
[02:23:28.020 --> 02:23:30.260]   He spent so long trying to achieve the pinnacle of his career.
[02:23:30.260 --> 02:23:33.340]   Then he realized he's staying there on stage in this massive auditorium.
[02:23:33.340 --> 02:23:35.260]   People are saying his lines as he's saying them.
[02:23:35.260 --> 02:23:36.620]   He was like, "That's kind of it."
[02:23:36.620 --> 02:23:37.620]   It's comedy.
[02:23:37.620 --> 02:23:38.620]   Then he moved on.
[02:23:38.620 --> 02:23:42.940]   How many know he's in his fourth or fifth successful different re-arcination of himself?
[02:23:42.940 --> 02:23:43.940]   There's the book.
[02:23:43.940 --> 02:23:44.940]   Steve and the book.
[02:23:44.940 --> 02:23:45.940]   He's the book.
[02:23:45.940 --> 02:23:46.940]   I didn't realize that.
[02:23:46.940 --> 02:23:47.940]   My life in the movies.
[02:23:47.940 --> 02:23:49.740]   So it picks up where...
[02:23:49.740 --> 02:23:51.340]   Born standing up ends.
[02:23:51.340 --> 02:23:52.340]   That's great.
[02:23:52.340 --> 02:23:55.260]   Talking about how he got in the movies.
[02:23:55.260 --> 02:23:57.740]   It ends with him saying, "I'm saying goodbye to the movies."
[02:23:57.740 --> 02:23:59.460]   Or maybe the movies say goodbye to me.
[02:23:59.460 --> 02:24:00.980]   He's moved on.
[02:24:00.980 --> 02:24:04.060]   He does the show he does with Martin Short.
[02:24:04.060 --> 02:24:07.060]   Not just the TV show, Only Murders in the Building.
[02:24:07.060 --> 02:24:08.060]   It's wonderful.
[02:24:08.060 --> 02:24:09.700]   But he also does a stand-up show with Martin.
[02:24:09.700 --> 02:24:10.700]   That's hysterical.
[02:24:10.700 --> 02:24:11.940]   I did not know about that.
[02:24:11.940 --> 02:24:13.580]   Oh, if you get a chance to see that.
[02:24:13.580 --> 02:24:14.580]   That's so busy.
[02:24:14.580 --> 02:24:15.580]   And his band.
[02:24:15.580 --> 02:24:16.580]   There's deep canyon rangers.
[02:24:16.580 --> 02:24:19.020]   He plays with them.
[02:24:19.020 --> 02:24:23.060]   He tours still with Martin Short.
[02:24:23.060 --> 02:24:27.260]   They call it a night you'll forget for the rest of your life.
[02:24:27.260 --> 02:24:30.020]   It's them and just funniest things you've ever seen.
[02:24:30.020 --> 02:24:31.660]   I mean, you're belly laughing.
[02:24:31.660 --> 02:24:34.420]   I like the model my career after him, except that not the funny part.
[02:24:34.420 --> 02:24:35.500]   I'm not funny.
[02:24:35.500 --> 02:24:41.260]   the like the professional reinvention and finding new volunteers, things. You know,
[02:24:41.260 --> 02:24:49.760]   he is a novelist. He's a super sweet, smart guy. I mean he's written an Apple shortcuts.
[02:24:49.760 --> 02:24:55.760]   What the hell? I was like really. Yeah, yeah I got some shortcuts and they want them to
[02:24:55.760 --> 02:25:00.080]   do some other things. So anyway, yeah, it was really fun to get him on and because he's had
[02:25:00.080 --> 02:25:04.080]   so many careers, I thought appropriate for him to say that I'm leaving something I've
[02:25:04.080 --> 02:25:13.680]   been doing for 46 years since 1976. My first love was radio. But podcasting scratches at
[02:25:13.680 --> 02:25:20.040]   itch. What is this? This is the same thing as radio. And I don't really need to work
[02:25:20.040 --> 02:25:26.480]   for so. So part of this is I never really felt like, well, I could probably stop. I could
[02:25:26.480 --> 02:25:33.160]   quit my day job and just do podcasting. Finally, after 15 years. Maybe this podcast thing,
[02:25:33.160 --> 02:25:38.000]   but it's just could work out. Okay, I could quit my day job finally. So I'm just leaving
[02:25:38.000 --> 02:25:44.600]   that radio show, the premier radio network that I work for. AM radio is not the most vital
[02:25:44.600 --> 02:25:51.120]   industry these days. But the reach, the number of miles it goes. Well, it's pretty neat. And
[02:25:51.120 --> 02:25:56.560]   the people I reach are generally older people who are baffled by technology and those people
[02:25:56.560 --> 02:26:00.800]   need help. So we, we, somebody's going to take the show Rich Demuro from KTLA. He was
[02:26:00.800 --> 02:26:05.880]   on CNET. It's great. Young guy knows his stuff. He's going to help those old people with their
[02:26:05.880 --> 02:26:11.600]   printer problems. So I don't have to. That's my, I know that audience very well. My rating,
[02:26:11.600 --> 02:26:18.320]   I have an aging audience of people aging along with me. Okay, couple of quick stories that
[02:26:18.320 --> 02:26:25.520]   I thought everybody should know about the FTC. I'm sorry, FCC has finally released its
[02:26:25.520 --> 02:26:33.080]   US broadband internet maps, which of course, you know, they're terrible. But the good news
[02:26:33.080 --> 02:26:40.840]   is you can go to the map, enter your address and correct it. So if, if, and you know, it's
[02:26:40.840 --> 02:26:46.480]   often the case, I'll enter in our business address here. And it should know it, but it
[02:26:46.480 --> 02:26:51.600]   doesn't. But way that's good means you haven't stored your address in some ways when it's
[02:26:51.600 --> 02:26:54.680]   good. Yeah, because isn't that weird that nowadays you'll enter an address and go,
[02:26:54.680 --> 02:27:00.080]   you mean? Oh, you mean there? And I go, yeah, how do you, how did you know that? So they
[02:27:00.080 --> 02:27:07.720]   say that we have nothing. So I could fix that. It doesn't look like we have any internet at
[02:27:07.720 --> 02:27:12.440]   all. But they will tell you what they think you have. And you can say, no, no, they're
[02:27:12.440 --> 02:27:17.440]   lying. I'm not getting anywhere near that. That's good. And that kind of stuff. So do
[02:27:17.440 --> 02:27:25.920]   correct it. Go there. It's a broadband map.fcc.gov. This is a long promised broadband map. The
[02:27:25.920 --> 02:27:36.000]   FCC's been working on for some years is finally out. Broadband map.fcc.gov. The earth weighs
[02:27:36.000 --> 02:27:44.320]   six rhinograms. I knew you'd want to know that. I was, we have a new thing. What do you call
[02:27:44.320 --> 02:27:51.520]   these? Scientific, it's an SI unit. Yes, international system of units. The last time
[02:27:51.520 --> 02:27:57.520]   they added new units was 1991, when they added Zeta and Yada. You know, there's Zeta
[02:27:57.520 --> 02:28:03.560]   bytes and Yada bytes. There's also, I mean, you didn't know this, a Yada meter, which
[02:28:03.560 --> 02:28:08.400]   is 24 zeros, one followed by 24 zeros. It's what my grandfather would say, you got a
[02:28:08.400 --> 02:28:15.480]   Hutsbud. Yada bytes. You got it. If you got a lot of bytes, you got a yeah. So, so there
[02:28:15.480 --> 02:28:26.600]   was a problem because Google started using hella bytes. And, and Bronto bytes. And that
[02:28:26.600 --> 02:28:33.800]   is not approved by the official governmental, an intergovernmental organization that's responsible
[02:28:33.800 --> 02:28:42.040]   for this, partly because they're alphabetic. So every letter's been used now except R
[02:28:42.040 --> 02:28:47.720]   and Q. So you couldn't use Bronto bytes or hella bytes. Those are already in use. So
[02:28:47.720 --> 02:28:54.640]   they had to use R and Q, although hella bytes would have been pretty cool. I did not know
[02:28:54.640 --> 02:29:04.000]   yeah. So R and Q are the new ones, Rana or Rano and Ketta Q, U, E, T, T, A or Queto. These
[02:29:04.000 --> 02:29:08.880]   are the new metric prefixes, the world's largest and smallest measurements when it ends with
[02:29:08.880 --> 02:29:18.560]   an A. It's large when it ends with it. Oh, it's small. So you have a kilo meter. No, I see
[02:29:18.560 --> 02:29:25.400]   the other way. I don't know. I don't understand this stuff. The larger prefixes end with A,
[02:29:25.400 --> 02:29:31.200]   the smaller in O. So I see. Yeah, most of them, but not all of them. Apparently not kilogram.
[02:29:31.200 --> 02:29:38.560]   Yeah. Kilogram. There's no kilogram and micro. Yeah. But nano meter and nano. I don't know
[02:29:38.560 --> 02:29:45.440]   anyway. So I just wanted to tell you, so you'd have this to use. It's the first time in 30
[02:29:45.440 --> 02:29:52.040]   years new prefixes have been added. The 27th general conference on weights and measures,
[02:29:52.040 --> 02:30:01.460]   which meets every four years at fair sigh, because why not has now proclaimed the two
[02:30:01.460 --> 02:30:12.120]   new things the earth. Now we can say way six Rana grams. That's a six followed by 27 zeros.
[02:30:12.120 --> 02:30:19.360]   Jupiter is two quetta grams. That's a two followed by 30 zeros. So you know, 27, then
[02:30:19.360 --> 02:30:28.040]   you add three and there's 30. So the Rana is 27 zeros. The quetta is 30 zeros. No helibites
[02:30:28.040 --> 02:30:33.080]   or Bronto bites. Okay. Nothing more to say about that. But just want to let you know.
[02:30:33.080 --> 02:30:37.400]   What are they going to do next? They're out of letters? Yeah, they're out of letters.
[02:30:37.400 --> 02:30:42.280]   We can't. Sorry. Stop. Alpha be alphabets. I don't know what they're going to do. That's
[02:30:42.280 --> 02:30:49.920]   a good question. Emoji. It'll be like, they'll go to hex. Yeah. That's always the solution.
[02:30:49.920 --> 02:30:54.080]   Oomle out you. Yeah. That's accurate. I don't know. That's a good question. Yeah,
[02:30:54.080 --> 02:31:00.360]   but I buy it. What do we do? I think everybody was very inspired by the autumn Artemis 2am
[02:31:00.360 --> 02:31:07.720]   launch. Late night. Beautiful launch. They're on their way tomorrow. They arrive at the moon.
[02:31:07.720 --> 02:31:11.680]   Was anybody shot by how fast I was watching it and they're like, T minus zero. It was
[02:31:11.680 --> 02:31:15.960]   like, and it was off. So it's like, I can't think of another launch in which it was just
[02:31:15.960 --> 02:31:20.040]   free of earth that quickly. You're right. Because it's the largest rocket we have ever
[02:31:20.040 --> 02:31:26.320]   made. Incredible. I was a little nervous that because they're using hydrogen that was
[02:31:26.320 --> 02:31:31.400]   very leaky because it's a small, it's a tiny, small, it's the smallest molecule. But they've
[02:31:31.400 --> 02:31:37.480]   figured it out, I guess. And they got rid of the leaks. So the flight plan is the trajectory
[02:31:37.480 --> 02:31:41.560]   is pretty extraordinary. A lot of swings around this and that and a lot of fun. Oh, it's a
[02:31:41.560 --> 02:31:46.960]   white effect. What was the site that Rod Pyle was on the tech guy and he gave us a site,
[02:31:46.960 --> 02:31:53.840]   a NASA site for the that's really cool simulation of Artemis. And you can see the orbit, which
[02:31:53.840 --> 02:31:59.560]   is very eccentric. Is that the word one uses for eccentric? I don't think it's eccentric.
[02:31:59.560 --> 02:32:04.920]   I think it's just it's a complicated. It's complicated. It's complicated. It allows you
[02:32:04.920 --> 02:32:11.120]   to have a camera view of either the orbit or the earth as the spacecraft sees it now or
[02:32:11.120 --> 02:32:21.280]   the moon. It's so cool. So it's a NASA gov. It's sash slash specials slash track Artemis.
[02:32:21.280 --> 02:32:25.920]   You're looking at it right now. There's Artemis. You can get a tour of I'm not going to do
[02:32:25.920 --> 02:32:30.960]   the tour, but there's you can see there's the moon. It's getting close, right? They're
[02:32:30.960 --> 02:32:37.720]   almost there. It's incredible. This is a simulation. You can you can obviously move
[02:32:37.720 --> 02:32:42.880]   it around. You can get the mission view as well and see the crazy orbits that it's going
[02:32:42.880 --> 02:32:47.200]   to do and all of this. It's great. I think ever since NASA's been doing this now for
[02:32:47.200 --> 02:32:51.600]   what since the 70s they did it with this thing where you swing around other planets to pick
[02:32:51.600 --> 02:32:56.040]   up gravity and change trajectory. It's the kind of thing that sounds more science fictiony.
[02:32:56.040 --> 02:32:59.360]   I guess that it is. The slingshot. Yeah, it's kind of awesome. I think they did that with
[02:32:59.360 --> 02:33:04.160]   Voyager to get it Voyager 2 to get it over to Jupiter. The outer planets right? The two
[02:33:04.160 --> 02:33:13.160]   pictures. Joe says the orbit is not eccentric. It's just misunderstood. Yeah. It's not the
[02:33:13.160 --> 02:33:19.280]   orbit that the final mission. I asked Rod who's he editor in chief of Ad Astra is at the National
[02:33:19.280 --> 02:33:23.320]   Space Society and expert his co-host on this week in space is the host of our this week
[02:33:23.320 --> 02:33:28.120]   in space shows co-hosts, Tarrick Malick space.com. I said, Rod, what's the projection? He said,
[02:33:28.120 --> 02:33:33.480]   well Donald Trump said we'd be on the moon in two years 2025, but he says my money's
[02:33:33.480 --> 02:33:38.800]   on 2027, but we are going back to the moon. We will have an orbital space station on
[02:33:38.800 --> 02:33:45.600]   the moon and it's all preparatory towards going past the moon and on to Mars. So very exciting.
[02:33:45.600 --> 02:33:52.560]   Very exciting for us geeks. Super cool. Yeah. Beautiful launch. The web stuff is super cool.
[02:33:52.560 --> 02:33:56.880]   Yeah. Well, you know what? You know, let's face it, NASA understands that there's a big
[02:33:56.880 --> 02:34:00.600]   part of their mission is PR. They got to get Congress to give them the money and to do
[02:34:00.600 --> 02:34:05.640]   that. They got to get us to tell our member of Congress. Get more money. Yeah. Well, you
[02:34:05.640 --> 02:34:11.240]   know, it was almost the James Web three sponsor, Brave TX. Yeah, guess why not? Yeah, James
[02:34:11.240 --> 02:34:15.920]   Web turns out the NASA administrator when many gay people were not allowed to work at
[02:34:15.920 --> 02:34:20.440]   NASA. So there's some concern, but they're not going to rename the telescope. Yeah, like
[02:34:20.440 --> 02:34:26.680]   keep reviewing it. But I like the James Web three. That's funny. This capsule may have
[02:34:26.680 --> 02:34:32.120]   been made in a factory that produces nuts. But it's so cool. Like the pictures are getting
[02:34:32.120 --> 02:34:36.760]   back from that. It's beautiful. NASA is like the thing that reminds me more than anything
[02:34:36.760 --> 02:34:41.240]   else. Like every so often. It's not so bad. Yeah. And like, it's kind of awesome. And
[02:34:41.240 --> 02:34:48.360]   there's like real stuff to be psyched about this. This mission has I think 14 very high
[02:34:48.360 --> 02:34:52.760]   quality cameras. The last time we did this, they had to send film back to be processed.
[02:34:52.760 --> 02:34:59.880]   Oh, God. Now we can get digital shots. And yet the moon rise, the earth rise. Some just
[02:34:59.880 --> 02:35:04.440]   stunning shots. We're going to get beautiful images of the moon. I did a story a few years
[02:35:04.440 --> 02:35:09.000]   ago for the economist when Curiosity launched and did a bunch of Curiosity related stories.
[02:35:09.000 --> 02:35:12.120]   And one was about the cameras on board because I think it had forgotten the total number of
[02:35:12.120 --> 02:35:16.680]   things at 13, which was unprecedented. And one of the people I talked to was a contractor.
[02:35:16.680 --> 02:35:20.360]   He said, well, this is the first time any camera I've designed is actually landed on a
[02:35:20.360 --> 02:35:24.440]   planet. And I said, what do you mean? He said, well, I have them. And he listed three doomed
[02:35:24.440 --> 02:35:28.760]   missions that his cameras have been on. So across his entire working career of 20 something
[02:35:28.760 --> 02:35:32.360]   years at this point, the work that he had done it finally. And then we're there, you know,
[02:35:32.360 --> 02:35:38.920]   NASA's firing on all cylinders, they say, for the last like 15 plus years and commercial
[02:35:38.920 --> 02:35:44.040]   firms as well, ESA as well has been so many successes. Let's give them a credit.
[02:35:44.040 --> 02:35:47.800]   picturing spending your entire working career having all of your cameras blow up in space or
[02:35:47.800 --> 02:35:51.640]   crash on landing. And then suddenly it's like, Oh, five of the ones in the Curiosity are ones
[02:35:51.640 --> 02:35:55.800]   that had my hands on. Amazing. Pretty slick. But amazing to be at that time when you can have
[02:35:55.800 --> 02:35:59.880]   that many cameras and they can send back data from relay stations. It's just good.
[02:35:59.880 --> 02:36:03.480]   You could have been you could have been an engineer working, you know, on the Bluetooth
[02:36:03.480 --> 02:36:08.280]   consortium for the past 30 years. And it still can't connect to a phone.
[02:36:08.280 --> 02:36:13.240]   I can't hear that. Yeah. Feel bad. Feel bad for them. It's not their entire
[02:36:13.240 --> 02:36:20.120]   laser fault. Oh gosh. A couple of obituaries we always end the show. Well, when there are
[02:36:20.120 --> 02:36:26.760]   people to memorialize and I'm sad to say there are two this week, the great science fiction author
[02:36:26.760 --> 02:36:33.560]   Greg Baer passed away. If you have not read his books, I couldn't recommend them more highly.
[02:36:33.560 --> 02:36:42.360]   I loved blood music. Really fascinating Darwin's radio. Many awards. He's won over 50 books. This
[02:36:42.360 --> 02:36:48.680]   would be a good excuse to go out and read some Greg Baer novels, Hugo award winning science fiction
[02:36:48.680 --> 02:36:57.240]   author passed away this week. And a book that I read years ago that Elon maybe should read now.
[02:36:57.240 --> 02:37:08.360]   The author of the mythical man month, Frederick Brooks, designed OS 360 IBM operating system,
[02:37:08.360 --> 02:37:17.560]   discovered the software. Tarpit and wrote one of the great classics of all time in 1975,
[02:37:17.560 --> 02:37:24.680]   the mythical man months. Have you have you read that book recently? Not recently. No. Why? Is it
[02:37:24.680 --> 02:37:31.320]   terrible? It does not hold up. Oh no. I remember reading that book in high school and being like,
[02:37:31.320 --> 02:37:36.200]   oh, this is so amazing. Yeah, it's great. Me too. Yeah, it doesn't hold up. So the premise
[02:37:36.200 --> 02:37:42.520]   eyes I remember it is that you can't throw money at software projects. The more people does not make
[02:37:42.520 --> 02:37:47.400]   a better product. I mean, the core idea I think is a really solid idea. I think the book is a
[02:37:47.400 --> 02:37:52.600]   book of its time. It was like pretty sexist. And like, it's, you know, it's what you expect from
[02:37:52.600 --> 02:37:58.360]   engineering culture to have been like and IBM 360. And I think maybe one of the reasons it doesn't
[02:37:58.360 --> 02:38:01.960]   hold up is because the basic idea has been the brace so much it's like it hardly seems worse.
[02:38:01.960 --> 02:38:05.880]   Everybody knows it now. Yeah. So now what's left when you read it is like the cringe.
[02:38:05.880 --> 02:38:10.680]   It sounds like he evolved is the interesting part. Stephen Bellaben, who's a great, you know,
[02:38:10.680 --> 02:38:18.440]   former AT&T Bellab's cryptography and other fellow, he wrote a wonderful tribute to Brooks and who
[02:38:18.440 --> 02:38:23.400]   had been his mentor and had really helped him in a lot of different ways. And it sounds like Brooks
[02:38:23.400 --> 02:38:27.320]   just had, he said he literally described with a capital C, a calling to go into teaching. And
[02:38:27.320 --> 02:38:33.480]   it sounds like he was constantly testing and reevaluating his ideas. So I think the sad part is he didn't
[02:38:33.480 --> 02:38:38.680]   write a, you know, mythical person month to book because it probably would have been a lot more
[02:38:38.680 --> 02:38:43.640]   interesting based on 30 more years in his working and teaching life.
[02:38:43.640 --> 02:38:49.960]   Well, I still have my copy. I'll pull it out. And a tip of the hat to two very important people
[02:38:49.960 --> 02:38:56.520]   in technology. Yeah. You know, regardless, he changed a lot of things.
[02:38:56.520 --> 02:39:03.240]   Absolutely changed my life. So yeah, there you go, right? Okay. Okay.
[02:39:05.480 --> 02:39:11.320]   You are now on the on the drone ship. Of course, I love you, I believe, waiting for
[02:39:11.320 --> 02:39:19.560]   something to land. You know, I didn't know this, but all of those weird drone ship names come from
[02:39:19.560 --> 02:39:25.560]   the Ian Banks culture series. Yeah. So I've downloaded all those audiobooks now and they're on my next
[02:39:25.560 --> 02:39:34.760]   on my list to read. I thought Elon was just a weirdo. Not just a weirdo. Not just any weirdo.
[02:39:34.760 --> 02:39:39.320]   There are there are I have read articles that say that he is so influenced by Ian Banks notion
[02:39:39.320 --> 02:39:44.840]   of artificial intelligence that this is in fact, if you want to understand Elon, it's a
[02:39:44.840 --> 02:39:49.400]   critical thing to read. So I'm going to I'm now embarking on the culture series.
[02:39:49.400 --> 02:39:57.240]   Phil, such a great pleasure to have Phil Libben on with us. Not just any weirdo. He's our weirdo.
[02:39:57.240 --> 02:40:05.480]   And we are so glad, so glad to have him on all dash turtles.com. And don't forget the app
[02:40:05.480 --> 02:40:14.280]   with the funny name MMHMM.app anything you want to plug or mention or say it's your chair, your
[02:40:14.280 --> 02:40:19.800]   chance here. I think, you know, it's a good what you just said is is interesting about the
[02:40:19.800 --> 02:40:25.400]   Elon's always like lists of books that he reads. And he is, I think quite enclosed by that and talks
[02:40:25.400 --> 02:40:31.800]   a lot about about his reading, obviously his list and then can contrast that to the famous as Bf quote,
[02:40:31.800 --> 02:40:35.560]   right about like, I have books, I have read books, books, I have read books, I have read books,
[02:40:35.560 --> 02:40:39.800]   I have read books. Yeah, kind of should have seen it come. No, I respect people who read. And
[02:40:39.800 --> 02:40:46.120]   and I do think that a lot of the world we live in today is inspired by the scientists,
[02:40:46.120 --> 02:40:50.280]   the technologists and the engineers who read science fiction as kids, who said, so you know,
[02:40:50.280 --> 02:40:54.600]   that'd be cool if we could just make that. So science fiction authors are pretty darn
[02:40:54.600 --> 02:41:00.840]   important. Phil always a pleasure. We will get you back soon. Absolutely. Now that I know it's
[02:41:00.840 --> 02:41:06.120]   okay to ask you, we will ask you. Glenn Fleischman on the other hand is so tired of us asking him
[02:41:06.120 --> 02:41:10.600]   that he probably needs a break. I just sit here all the time and occasionally I've seen it and
[02:41:10.600 --> 02:41:14.840]   you've got many change your shirts and select. Come on, I have a different shirt every show.
[02:41:14.840 --> 02:41:20.920]   Oh, okay. That's the file. Check the files. I have developed an extensive array of colorful
[02:41:20.920 --> 02:41:27.720]   shirts. Maybe that's it. They just all look the same. Glenn.com with two ends is his website.
[02:41:27.720 --> 02:41:33.000]   You read it many places. These, of course, a podcaster. You hear him on the incomparable.
[02:41:33.000 --> 02:41:40.040]   Many other great podcasts. He is, I'm so proud to say now on our Mastodon server so you can talk to
[02:41:40.040 --> 02:41:46.120]   him there at Twit.Social. In fact, he even put it up at the top of his page. I love that.
[02:41:46.120 --> 02:41:52.360]   My page. You replaced Twitter with Mastodon and Insta and Flicka. Great to have you.
[02:41:52.360 --> 02:41:56.840]   Fun place to talk. Thank you for having me back. I think we'll see more of you soon, I know,
[02:41:56.840 --> 02:42:05.160]   because Jeff Love's talking about flongs. I'm off to Europe on Tuesday for a couple of weeks.
[02:42:05.160 --> 02:42:07.640]   Where are you going and how are you going?
[02:42:07.640 --> 02:42:15.720]   Train. I'm flying to Europe. Not my boat. My older kid has taken his gap year. He's taken a few
[02:42:15.720 --> 02:42:20.680]   weeks in Europe, bumming around. I'm meeting him in Berlin in a few days and then we're going to
[02:42:20.680 --> 02:42:27.720]   Prague, Vienna, Ljubjana, Venice. It's going to be one of those running through town. Things
[02:42:27.720 --> 02:42:32.680]   we've got two weeks. We're going to go through five cities and see a lot of museums and climb a
[02:42:32.680 --> 02:42:38.600]   lot of mountains, see some old friends. It'll be a hoot. He's going to far-flong places. Somebody
[02:42:38.600 --> 02:42:45.160]   in the jet or far-flong. No, have a wonderful trip. That sounds so great. Will we see pictures on
[02:42:45.160 --> 02:42:49.560]   Instagram? I'll post pictures. I'm going to be visiting a letterpress spinner in Ljubjana. Of
[02:42:49.560 --> 02:42:56.360]   course, letterpress spinner in Stone Carver in Ljubjana, Slovenia. There's something like letter
[02:42:56.360 --> 02:43:00.440]   press in Stone Carving. They seem like they go together. Very different fields, but they go
[02:43:00.440 --> 02:43:03.240]   together and I'm going to be interested to see a studio, which will be a lot of fun.
[02:43:04.200 --> 02:43:10.600]   Mr. Dwight Silverman, old friend, old pal. Find all of his stuff. It's so cool that
[02:43:10.600 --> 02:43:21.320]   authoriy, A-U-T-H-O-R-Y dot com slash d silverman. It's got the Chronicle column that I do that
[02:43:21.320 --> 02:43:30.280]   runs every week, publishes online on Friday, print on Sunday, and also all of my stuff from
[02:43:30.280 --> 02:43:34.840]   Forbes when I was there for about 20 minutes. I was going to ask, but...
[02:43:34.840 --> 02:43:41.080]   I have a question though about Phil. Do you have a podcast, Phil?
[02:43:41.080 --> 02:43:47.160]   I used to have a podcast. We used to do the old turtles podcast. You should do one or Leo
[02:43:47.160 --> 02:43:55.400]   should put you on. I agree. Yeah. Yeah. You're great. I want to go to bed every night just talking
[02:43:55.400 --> 02:44:02.200]   calmly about technology. If the CEO thing doesn't work out, you could do stand up.
[02:44:02.200 --> 02:44:09.320]   There's the problem. And Glenn, when you go to Germany, you go to Berlin.
[02:44:09.320 --> 02:44:16.120]   There's a wonderful restaurant, very quirky restaurant, in the basement of the opera house,
[02:44:16.120 --> 02:44:21.320]   in Berlin. And you should hit that up. Get the soup. The soup is fantastic.
[02:44:21.320 --> 02:44:28.120]   I will look at a people recommending also, there's a restaurant that recreates East German delicacies.
[02:44:28.120 --> 02:44:36.520]   Oh, dear. Is it called Stasi Diesz? Is it German or Essewand?
[02:44:36.520 --> 02:44:41.080]   Well, there's one. No, I saw a video on it and then a friend's like, "Oh, maybe we should go there."
[02:44:41.080 --> 02:44:47.240]   I'm like, "I think I can skip nostalgia, but East German food. I think most East Germans do."
[02:44:48.040 --> 02:44:53.960]   So there is a place that's just like a few feet away from where Checkpoint Charlie used to be,
[02:44:53.960 --> 02:45:00.040]   called Stackpoint Charlie, which is worth a visit. I near Checkpoint Charlie anyway.
[02:45:00.040 --> 02:45:06.520]   We went when I was traveling around on the geek cruises we went to Berlin. I took my son who was
[02:45:06.520 --> 02:45:14.520]   about 10 to see Checkpoint Charlie. I don't know if he really sunk in, but we bought a bit of the
[02:45:14.520 --> 02:45:20.040]   Berlin Wall, which I kept for him. I gave him on his last birthday. I still don't think he understands
[02:45:20.040 --> 02:45:26.120]   what it is. But it was quite a trip. And it is something to see Checkpoint Charlie and the remains
[02:45:26.120 --> 02:45:31.160]   where the Berlin Wall was. And of course, the big Brandenburg Gates right there and everything.
[02:45:31.160 --> 02:45:36.600]   It was quite something to say. I spent a lot of time in university studying German history.
[02:45:36.600 --> 02:45:41.560]   So most of my knowledge of Germany is pre-Enduring World War II. I don't really know much about
[02:45:41.560 --> 02:45:44.760]   what it's like today. So it will be fascinating to see Berlin honestly.
[02:45:44.760 --> 02:45:50.360]   Great city. I think I'm 70 years old. Yeah, I think you'll have a... Well, Prague is amazing.
[02:45:50.360 --> 02:45:58.280]   Go to Old Town and see the clock, the 13th century clock that they blinded the clockmaker
[02:45:58.280 --> 02:46:02.360]   after he made it. So he would should not make it for any other person on the hour.
[02:46:02.360 --> 02:46:08.440]   Dancing people come out. It's an incredible thing to see. I'll go find the Golem of Prague.
[02:46:08.440 --> 02:46:11.320]   The Golem. Got to go see the Golem. Everybody, you know? Maybe.
[02:46:11.320 --> 02:46:15.880]   The Golem. And then if you ever go to Brussels, you can see the Mannequin piss and you'll be done.
[02:46:15.880 --> 02:46:21.880]   I see. I've seen enough of the Mannequin piss. How much Mannequin?
[02:46:21.880 --> 02:46:27.240]   Also in the subways in New York. There it is. Here we are at the beautiful Checkpoint Charlie's.
[02:46:27.240 --> 02:46:31.960]   No, no, this is the best curry worst in Berlin. Oh, I want to go. Yeah. Oh,
[02:46:31.960 --> 02:46:38.920]   okay. It's very good. It's very good. That's confusing. Is it a bit a little bit of India in
[02:46:38.920 --> 02:46:44.680]   Germany or Turkish? I'm not really sure why they call it that. It's a fusion. It's a curry
[02:46:44.680 --> 02:46:48.440]   powder. They've got a Turkish influence thing I'm looking for. Dernerkebab is the big Berlin
[02:46:48.440 --> 02:46:52.280]   innovation. It's supposed to be very good there. It's also curry worst.
[02:46:52.280 --> 02:46:57.480]   Have a curry worst and a Dernerkebab. Yeah. Get back to us.
[02:46:59.960 --> 02:47:06.520]   My arteries are last. I'm gonna trip back at all. We do to it every Sunday. Man, was this a fun
[02:47:06.520 --> 02:47:12.600]   one. I'm glad you were here for it. That two Pacific five Eastern 2200 UTC usually starts about
[02:47:12.600 --> 02:47:16.680]   half an hour in. But if you get here early, you get to see all the pre-show stuff. After the fact
[02:47:16.680 --> 02:47:21.800]   you can download a copy of every show we do on our website, twit.tv. You can get it on YouTube as
[02:47:21.800 --> 02:47:27.160]   well. There's a whole YouTube channel devoted to this week in tech. If you watch live, you should
[02:47:27.160 --> 02:47:32.040]   chat live at our IRC or if you're a member of club twit. In our discord club twit members,
[02:47:32.040 --> 02:47:37.560]   get all sorts of stuff, extra stuff. It's less than a blue check on Twitter, just seven bucks a
[02:47:37.560 --> 02:47:43.640]   month. But it really makes a big difference to us. It helps us out a lot. And it's one of the ways
[02:47:43.640 --> 02:47:47.240]   we were able to launch new shows. We do it in the club, including Hands on Windows with Paul
[02:47:47.240 --> 02:47:53.240]   Thorett, Hands on Mac with Michael Sargent, the untitled Linux show with Jonathan Bennett,
[02:47:53.240 --> 02:47:58.040]   the Stacey's book club, all the stuff we do that gives us thanks to club members. So we appreciate
[02:47:58.040 --> 02:48:04.520]   it. If you're not in the club, go to twit.tv/clubtwit. It's free for instance to join our Mastodon,
[02:48:04.520 --> 02:48:10.680]   but it's expensive. The club twit members help us with that. They help us with our forums as well.
[02:48:10.680 --> 02:48:16.040]   They're really the benefactors that make it possible for us to do so many things. We love
[02:48:16.040 --> 02:48:22.520]   doing what we're doing. I am not retiring. I'm just quitting radio. I plan to be here for a long time,
[02:48:22.520 --> 02:48:28.280]   but it's going to take the help of the club to do it. So twit.tv/clubtwit.
[02:48:28.280 --> 02:48:33.560]   Thanks for joining us. We'll see you next time. Another twit is in the can.
[02:48:33.560 --> 02:48:50.120]   I forgot to thank and we'll add this to the show because Andy Carlucio is here. He's the
[02:48:50.120 --> 02:48:55.400]   engineering event engineer at Zoom. It was thanks to Andy and his help that we were able to finally
[02:48:55.400 --> 02:49:01.720]   get Zoom ISO working. I don't know if you noticed this, but this has been the first time with it.
[02:49:01.720 --> 02:49:08.120]   There's no latency. Everybody can overlap. They could talk over each other. It's really been great.
[02:49:08.120 --> 02:49:12.760]   Thank you, Andy. He's in studio today, making sure it all works. I really appreciate it.
[02:49:12.760 --> 02:49:16.200]   We'll be using Zoom soon soon. Pretty fast. Yeah, yeah.

