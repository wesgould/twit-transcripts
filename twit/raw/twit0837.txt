;FFMETADATA1
title=The Mullet Office
artist=Leo Laporte, Kevin Rose, Lisa Schmeiser, Nate Lanxon
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2021-08-23
track=837
language=English
genre=Podcast
comment=T-Mobile hack, OnlyFans policy change, Cloudflare DDoS, Tesla's humanoid robot
encoded_by=Uniblab 5.3
date=2021
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:04.560]   It's time for Twith this week in Tech. Kevin Rose is here. Can't wait to talk to him.
[00:00:04.560 --> 00:00:10.080]   Nate Langson, Tech Editor from Bloomberg. He's always fun. And Lisa Schmeiser, Senior Editor at
[00:00:10.080 --> 00:00:17.600]   ITPro. Today we'll talk about the big reach at T-Mobile. Yeah, I got the text and why this is
[00:00:17.600 --> 00:00:22.960]   going to lead to more cases of simjacking and what you can do about it. Digital leadership on the
[00:00:22.960 --> 00:00:26.960]   table for Girl Scouts. Lisa talks about some of the requirements. You won't believe some of the
[00:00:26.960 --> 00:00:33.520]   things. Brownies are learning. Second graders are learning about digital literacy. And then
[00:00:33.520 --> 00:00:39.200]   we'll talk about only fans. They're dropping porn. Is there anything left? It's all coming up next.
[00:00:39.200 --> 00:00:40.640]   On Twith.
[00:00:40.640 --> 00:00:43.440]   [Music]
[00:00:43.440 --> 00:00:49.440]   Podcasts you love. From people you trust. This is Twith.
[00:00:49.440 --> 00:01:05.840]   This is Twith this week in Tech. Episode 837 recorded Sunday August 22nd, 2021.
[00:01:06.720 --> 00:01:12.160]   The Mollit Office. This episode of this week in Tech is brought to you by Mint Mobile. Mint
[00:01:12.160 --> 00:01:17.600]   Mobile's secret sauce is they're the first company to sell wireless service online only.
[00:01:17.600 --> 00:01:21.840]   To get your new wireless plan for just 15 bucks a month and get the plan shipped to your door for
[00:01:21.840 --> 00:01:31.280]   free go to mintmobile.com/twith. And by Worldwide Technology and Dell Technologies. With an
[00:01:31.280 --> 00:01:36.640]   innovative culture thousands of IT engineers application developers unmatched labs and
[00:01:36.640 --> 00:01:42.640]   integration centers for testing and deploying technology at scale. WWT helps customers bridge
[00:01:42.640 --> 00:01:51.120]   the gap between strategy and execution. To learn more about WWT visit www.wt.com/twith.
[00:01:51.120 --> 00:02:01.200]   And by Wealthfront. To get your first $5,000 managed free for life go to wealthfront.com/twith
[00:02:01.200 --> 00:02:03.120]   and start growing your savings today.
[00:02:03.120 --> 00:02:12.400]   It's time for Twith this week at Tech. The show we cover the week's Tech news. Oh we're gonna
[00:02:12.400 --> 00:02:18.080]   have some fun today. Some of my favorite people are with us all the way from the UK. Nate Langson
[00:02:18.080 --> 00:02:26.240]   staying up late in his secret room. Nate Langson is Tech Editor at Bloomberg and he is also apparently
[00:02:26.240 --> 00:02:33.040]   a Dreamseater aficionado. Yeah I've been told that all those symbols are actually
[00:02:33.040 --> 00:02:39.920]   barely enough to perform Dreamseater. Mike Portnoy back in the day he did have more symbols than me
[00:02:39.920 --> 00:02:48.720]   but I'm younger than him so I have more years to overtake. You're building a drum kit. Here's
[00:02:48.720 --> 00:03:00.160]   an image of Mike Portnoy's drum kit. Yeah I think it might be similar it might be of a similar size
[00:03:00.160 --> 00:03:06.240]   these days. Yours are synths though. We're not talking bronze here you can actually play
[00:03:06.240 --> 00:03:12.880]   completely silently in there except for some thumps. Oh it isn't silent so it was funny just
[00:03:12.880 --> 00:03:16.720]   before we started the show Kevin was talking about his secret room when you build a house. I only had
[00:03:16.720 --> 00:03:23.040]   two requirements for this place. One no neighbors and two a room big enough for a giant drum kit
[00:03:23.040 --> 00:03:28.640]   and we're the only two things. I let my wife decide all the rest of it because it's loud.
[00:03:28.640 --> 00:03:34.800]   It is loud. I love it. Great to have you know what's fun about doing this show is you get to see
[00:03:34.800 --> 00:03:40.240]   people in their natural habitat and you get to learn a little bit about their hobbies like Lisa
[00:03:40.240 --> 00:03:48.080]   Schmeiser who is a Girl Scout leader and senior editor of ITPro today. I'm not sure which title is
[00:03:48.080 --> 00:03:55.200]   more important to you. I don't like to rank them. Someone's feelings always in the picture of that
[00:03:55.200 --> 00:04:00.800]   one. We don't have to choose. But no I will say that in one of those roles I do get access to cookies.
[00:04:00.800 --> 00:04:08.080]   Yeah yeah there is a certain benefit. Also joining us one of the original
[00:04:08.080 --> 00:04:15.040]   tweets going back to episode zero. Kevin Rose is here now host of the Modern Finance podcast at
[00:04:15.040 --> 00:04:21.040]   Modern.finance. Hi Kevin. Hey how's it going Leo? Good to be here. You were showing us your your
[00:04:21.040 --> 00:04:26.480]   zombie. Yes we were talking crypto punks before the show started. I was trying to encourage you to buy
[00:04:26.480 --> 00:04:32.720]   one. So I listened to Modern Finance episode one in which you talk about NFTs non-fungible tokens
[00:04:32.720 --> 00:04:37.920]   and you mentioned the original which are these crypto punks. They're a little basically their
[00:04:37.920 --> 00:04:43.600]   icon sized digital art. Yeah I actually had the founders come on the show a few episodes later
[00:04:43.600 --> 00:04:48.240]   and talk about how they kicked off that project and how it defined what is now the standard for NFTs
[00:04:48.240 --> 00:04:57.200]   which is that ERC721 standard on Ethereum. So when you did that episode this zombie was worth
[00:04:57.920 --> 00:05:03.440]   a couple hundred thousand. It was probably around that yeah that sounds about right. What do you think
[00:05:03.440 --> 00:05:09.680]   it's worth now? It's a good question. I think the most recent sales of zombies have been around
[00:05:09.680 --> 00:05:14.560]   four and a half to five million dollars. Now what do I get if I spend four and a half to five
[00:05:14.560 --> 00:05:20.800]   million dollars? Do I? You will then take custody and ownership that is proven cryptographically and
[00:05:20.800 --> 00:05:26.720]   it'll be in your wallet and you will have a zombie. So whichever one's up for sale. There's only
[00:05:26.720 --> 00:05:33.600]   two of them. Why did I try to buy one when I heard about them? But no Leo said oh that's just silly.
[00:05:33.600 --> 00:05:38.400]   You don't have to get a zombie. There are less expensive options if you don't want to drop
[00:05:38.400 --> 00:05:44.240]   five on a new one. It's way out of my price range now. I was out of my price range then but I
[00:05:44.240 --> 00:05:51.120]   at least if I bought it then I'd be it'd be back in my price range I guess. I wouldn't know a thing
[00:05:51.120 --> 00:05:56.400]   about NFTs or crypto if it weren't for modern finance. So thank you for doing that show. It really is
[00:05:57.120 --> 00:06:01.520]   great. And I have no problem. And people will listen to our shows regularly probably know we
[00:06:01.520 --> 00:06:07.200]   do ads for modern finance. So thank you for buying some ads on your old podcast network.
[00:06:07.200 --> 00:06:13.440]   Oh man Leo you you kick started my career. So I'm happy to return the favor with some
[00:06:13.440 --> 00:06:18.960]   little tiny ads. Thank you. If you really wanted to send a zombie along
[00:06:18.960 --> 00:06:25.040]   you know just just maybe this the cap just just the top. Yeah maybe the earring.
[00:06:25.040 --> 00:06:27.280]   The earring just pop off the earring.
[00:06:27.280 --> 00:06:32.400]   Kevin was the dark tipper something he kind of wants to live down on the
[00:06:32.400 --> 00:06:38.320]   screensavers back in the late 90s early 2000s. Yeah used to do a little hacking tips and all
[00:06:38.320 --> 00:06:43.920]   that stuff. It was fun. I look back on those days and I'm just like that was such a special time.
[00:06:43.920 --> 00:06:49.840]   It really was. And even though it was only maybe 20 years ago it feels like an eternity
[00:06:50.720 --> 00:06:56.240]   ago. I mean the world has changed from I mean what would we have thought about zombie icons
[00:06:56.240 --> 00:07:05.200]   worth millions in 2020. I mean crazy. The world has changed. Let alone entering the second year of
[00:07:05.200 --> 00:07:15.040]   apocalyptic epidemic or pandemic. It's just crazy. I feel like Loki you know how they've used
[00:07:15.040 --> 00:07:19.600]   the show. Loki's been at work. Yes. So I feel like we took the wrong timeline like we were the
[00:07:19.600 --> 00:07:25.200]   deviant on some like horrible timeline that we were beyond. We need to be brought back to the
[00:07:25.200 --> 00:07:30.560]   normal one. Yeah what the hell happened. It's actually good for the show because the news is never
[00:07:30.560 --> 00:07:39.040]   boring. It's always something. It's always something isn't it. Just incredible.
[00:07:39.040 --> 00:07:41.680]   I don't even know where to start.
[00:07:44.000 --> 00:07:51.600]   T-Mobile admits that we talked about it last week as a speculation that T-Mobile had a massive breach.
[00:07:51.600 --> 00:07:55.120]   The very next day I got a text from T-Mobile.
[00:07:55.120 --> 00:08:02.320]   That's compromised. I was compromised. Thank you very much. Apparently I'm not alone.
[00:08:02.320 --> 00:08:10.000]   Social security numbers, driver's license information means physical address. Motherboard had the
[00:08:10.000 --> 00:08:16.240]   scoop on vice. They said that a hacker was selling part of what he said was 100 million user
[00:08:16.240 --> 00:08:21.440]   Trove. They verified the information and some of the records that the hacker was selling as being
[00:08:21.440 --> 00:08:26.240]   actual T-Mobile information. T-Mobile said, "Oh, we'll investigate it." That's the last time we
[00:08:26.240 --> 00:08:32.560]   talked about this. And then since this week they've announced, yeah. Yeah, they haven't said 100
[00:08:32.560 --> 00:08:39.280]   million. Here's what I got on Thursday. T-Mobile has determined that unauthorized access to some of
[00:08:39.280 --> 00:08:44.480]   your personal data has occurred. We have no evidence that your debit credit card information was
[00:08:44.480 --> 00:08:50.080]   compromised. That's not exactly saying it wasn't. We take the protection of our customers. Seriously,
[00:08:50.080 --> 00:08:54.480]   we're taking actions to protect your T-Mobile account. We recommend you take action to protect
[00:08:54.480 --> 00:09:02.320]   your credit. And they send me a link which tells me, "Oh, congratulations. You've just won two years
[00:09:03.120 --> 00:09:12.080]   of credit checking credit reporting. Thank you very much with McAfee. Sign up for McAfee ID threat
[00:09:12.080 --> 00:09:19.520]   protection service free for two years provided by T-Mobile." No, not going to do it. Thank you anyway.
[00:09:19.520 --> 00:09:24.560]   Not going to do it. I guess what I'm going to do is go to the credit reporting agencies and
[00:09:24.560 --> 00:09:29.120]   put a credit freeze on my accounts. That seems like- The other thing that's really important to
[00:09:29.120 --> 00:09:34.560]   remember here is a lot of people have their email backed up by their cell phone number for two-factor
[00:09:34.560 --> 00:09:39.840]   authentication. That can be tied to cryptocurrency accounts or whatever. When all this information is
[00:09:39.840 --> 00:09:44.640]   out there, anyone can call up T-Mobile and say, "I'm this person. Here's my social security number.
[00:09:44.640 --> 00:09:50.160]   Switch to this new SIM. I need to change SIMs. I need to change phones." And then all of a sudden,
[00:09:50.160 --> 00:09:54.800]   people are getting their accounts reset because they get SIM swaps. You just have to be really
[00:09:54.800 --> 00:09:59.360]   careful and make sure to do all your two-factor authentication in software, in something like
[00:09:59.360 --> 00:10:04.800]   one password or any of these modern password vaults that actually support that.
[00:10:04.800 --> 00:10:11.600]   They did send me underneath the offer of two free years of McAfee information about T-Mobile's
[00:10:11.600 --> 00:10:18.560]   account takeover protection, which is specifically to avoid that SIM jacking you just described.
[00:10:18.560 --> 00:10:24.000]   Apparently, and they're not saying this, but I've seen others who said T-Mobile was saying that their
[00:10:24.000 --> 00:10:29.040]   pin had been compromised. That was the thing that I did and most of us did, and we were telling
[00:10:29.040 --> 00:10:34.560]   people to do to prevent this SIM jacking was to provide an additional pin without that pin
[00:10:34.560 --> 00:10:39.920]   customer service reps could not then send this new SIM to a different address, that kind of thing,
[00:10:39.920 --> 00:10:46.320]   making it easy to take over your account. So apparently that pin has been compromised as well now.
[00:10:46.320 --> 00:10:49.280]   What precision people actually set that up? I'm curious.
[00:10:49.280 --> 00:10:55.040]   Yeah, well, that's another thing, probably very few. Kevin, you're right for bringing up the
[00:10:55.040 --> 00:11:02.240]   SIM swapping aspect to this because two FAs so frequently promoted as a good idea. It is a good
[00:11:02.240 --> 00:11:08.880]   idea, but you look at some of the people that have been targeted by SIM swaps, Jack Dorsey, I believe.
[00:11:08.880 --> 00:11:15.440]   Yes. It was a couple of years ago on Twitter. A lot of those hacks take place because of exactly
[00:11:15.440 --> 00:11:21.280]   this, SIM swapping. You just need enough detail about a person to call up and say, "Hey, it's me,
[00:11:21.280 --> 00:11:25.600]   I need to change my number, I need to change my phone, even you SIM," whatever. And you are
[00:11:25.600 --> 00:11:31.360]   potentially rewarded with access to some very, very high profile social media accounts,
[00:11:31.360 --> 00:11:35.600]   very influential, huge potential. It's a massive problem.
[00:11:35.600 --> 00:11:42.800]   Twitter's response to Jack Dorsey's account being hacked was to allow you to turn off SMS,
[00:11:44.400 --> 00:11:49.680]   account verification, and still have two factor using a UBQ or some other system.
[00:11:49.680 --> 00:11:57.520]   Last week on July 23rd, Twitter revealed how many people use any kind of two factor
[00:11:57.520 --> 00:12:02.240]   on their Twitter accounts. It's 2.3% of active accounts.
[00:12:02.240 --> 00:12:09.200]   So it's in a way, it's a bleak answer to your question, Kevin. I don't know how many people use
[00:12:09.200 --> 00:12:14.320]   pins on T-Mobile, but if only 2.3% of Twitter users even turn on two factor,
[00:12:14.320 --> 00:12:21.120]   I can imagine it's probably a lower number than that. By the way, of the 2.3% who had two factor
[00:12:21.120 --> 00:12:29.200]   turned on, 79.6% used SMS-based multi-factor. So, yeah, clearly.
[00:12:29.200 --> 00:12:34.640]   I'm surprised. I'm surprised it's as low as that. I would have assumed that the overwhelming
[00:12:34.640 --> 00:12:39.600]   majority of people with 2FA enabled would have been SMS because it's just such an obvious thing
[00:12:39.600 --> 00:12:43.840]   to check when you're signing up or when you're reviewing this security.
[00:12:43.840 --> 00:12:47.600]   They make it a little hard. You have to set up SMS and then you can turn it off later.
[00:12:47.600 --> 00:12:53.680]   I wanted to use a security key, which I do. By the way, of the 2.3% of Twitter users who have
[00:12:53.680 --> 00:12:59.920]   MFA, only 0.5% of that number have a security key, but that would be the, I would think,
[00:12:59.920 --> 00:13:05.920]   the most secure way to do it. But then you have to turn off the weak link of SMS, but you can
[00:13:05.920 --> 00:13:11.120]   only do that once you have some other system set up. I think an MFA app, I don't know, DarkTipper,
[00:13:11.120 --> 00:13:14.880]   is an MFA app something like Google Authenticator as good as a UBICI?
[00:13:14.880 --> 00:13:21.200]   I mean, it's only as good as how you're backing up that data, right? How are you going to restore
[00:13:21.200 --> 00:13:26.640]   that later? The question is, back in the day, we used to just back it up to iCloud,
[00:13:26.640 --> 00:13:30.080]   like some of those were a few options. Yeah, big mistake. Yeah.
[00:13:30.080 --> 00:13:37.440]   So I'm a fan of the hardware keys. I use them as well. I turn on, they have this thing,
[00:13:37.440 --> 00:13:40.560]   Google has it, you can call it's called the advanced threat protection.
[00:13:40.560 --> 00:13:45.280]   Do you use that? I tried that. I tried that. It really disables what you, a lot of things
[00:13:45.280 --> 00:13:48.720]   that you would might want to do. Or party apps. Yeah. It does a lot of the third party apps get
[00:13:48.720 --> 00:13:53.280]   disabled, but for certain accounts, like, here's a great example. You have your normal Gmail account,
[00:13:53.280 --> 00:13:58.400]   fine. Use a standard, like two factor auth, software based two factor auth. That's great.
[00:13:58.400 --> 00:14:04.080]   That's your personal email. Okay. You're pretty protected. But if you have financial documents,
[00:14:04.080 --> 00:14:08.960]   like things that you just want to keep on Google Drive, create a separate Google account.
[00:14:08.960 --> 00:14:12.160]   There you go. You have a be just for that. That's probably a good idea.
[00:14:12.160 --> 00:14:16.160]   All through secure where you don't need third party app access ever, and then do the advanced
[00:14:16.160 --> 00:14:20.880]   threat stuff. And it really, really, truly locks it down. And it requires a hardware key in order
[00:14:20.880 --> 00:14:28.560]   to actually enable that. Unfortunately, the Google Titan keys, which they use for that
[00:14:28.560 --> 00:14:37.040]   have been compromised. But, otherwise, it's a great idea. What do you do to protect your zombie?
[00:14:37.040 --> 00:14:43.040]   You don't keep 50, 66 in a vault or something. I mean, where do you, it's basically, you just
[00:14:43.040 --> 00:14:48.000]   have to rely on hardware based. Do you have a wallet keys? Yeah, there are hardware wallets
[00:14:48.000 --> 00:14:52.720]   out there. I'm testing a bunch of them right now. The two biggest ones are Ledger and Tesser,
[00:14:52.720 --> 00:14:59.120]   or the two big hardware wallet manufacturers. I'm using a ledger currently, but I think the UI
[00:14:59.120 --> 00:15:04.800]   is just not, it's lacking and it's a little clunky to use. There's a few other ones that are out there
[00:15:04.800 --> 00:15:08.640]   that I'm going to be trying out soon. Isn't Jack Dorsey's and Square doing something?
[00:15:08.640 --> 00:15:14.080]   I haven't seen Square now. I feel like they're going to do a wallet. Okay. I'm sure they must.
[00:15:14.080 --> 00:15:18.320]   They know, I think they did make an announcement, something like that I heard. Because obviously,
[00:15:18.320 --> 00:15:24.960]   they do custody right now of Bitcoin using the Square Cash app. But they haven't seen a wallet yet
[00:15:24.960 --> 00:15:31.440]   from them. They're definitely doing a hardware wallet. Yeah. The company, they said in June,
[00:15:31.440 --> 00:15:37.040]   they were considering one. This is from the Verge last month. Square's going to make a hardware
[00:15:37.040 --> 00:15:41.920]   wallet for Bitcoin. I love how every time you see a picture of Jack Dorsey, go back to that.
[00:15:42.480 --> 00:15:49.120]   He looks completely different. Sometimes he looks like a Buddhist monk. And then other times,
[00:15:49.120 --> 00:15:54.560]   he looks like a wild, crazy, homeless person. And other times he's like super thin cut Jack Dorsey.
[00:15:54.560 --> 00:15:57.280]   It's like a roll the dice of what version of Jack Dorsey you're going to get.
[00:15:57.280 --> 00:16:02.720]   I particularly like how his orange tie-dice t-shirt matches the Bitcoin logo behind it.
[00:16:02.720 --> 00:16:06.000]   Yeah. It's a very nice color. They make crypto punks that look like him,
[00:16:06.000 --> 00:16:09.360]   actually, with the two things like that. Yeah, they make big beard Jack Dorsey crypto.
[00:16:09.360 --> 00:16:13.280]   You have one. Look, you were an early investor. I'm sure you know Jack fairly well, right?
[00:16:13.280 --> 00:16:17.920]   I do. Yeah. I'm sure he's a cool guy, right? He's a very cool guy. And he's very
[00:16:17.920 --> 00:16:24.080]   super sharp, just like insanely sharp and a brilliant novel thinker. Yeah. I have a ton of
[00:16:24.080 --> 00:16:31.840]   respect for Jack. Yeah. Well, maybe his wallet will be a good one. He tweeted out maybe two
[00:16:31.840 --> 00:16:36.800]   different keywords that he uses Tezor right now as his hardware wallet for Bitcoin.
[00:16:37.600 --> 00:16:43.920]   So this is his tweet from June 4th, squares considering making a wallet for Bitcoin. Why
[00:16:43.920 --> 00:16:48.880]   Bitcoin? Why not any watch? He's a maximalist, man. He's a Bitcoin maximalist to the
[00:16:48.880 --> 00:16:53.120]   other. Oh, it's all Bitcoin all the time. Yeah. He has a heart. I don't think I've seen him.
[00:16:53.120 --> 00:16:58.320]   Even though Twitter did do a couple of Ethereum based NFTs and he did sell one of his first tweet
[00:16:58.320 --> 00:17:04.320]   over on the Ethereum network, he will not embrace any other cryptocurrencies. And I just,
[00:17:05.040 --> 00:17:10.480]   it kills me. What do you mean? It's opportunity. NFTs, you're NFTs using Ethereum, right?
[00:17:10.480 --> 00:17:18.800]   Yeah. Ethereum is like the primary network, I would say 95% of NFTs are collected and minted on.
[00:17:18.800 --> 00:17:25.840]   And then you have other networks, Flow, Max, or sorry, Flow, and then also wax is another one.
[00:17:25.840 --> 00:17:32.080]   Tezos is doing some, Solana is doing some now. So there's several other cryptocurrencies that
[00:17:32.080 --> 00:17:42.160]   support them. It's kind of dilution of the whole idea of crypto. Everything from dogecoin to Ethereum.
[00:17:42.160 --> 00:17:46.400]   Does that not dilute the power of crypto? Shouldn't there be just one?
[00:17:46.400 --> 00:17:52.960]   Well, I mean, the way I look at it is that they're kind of just databases in the end and they have
[00:17:52.960 --> 00:17:57.360]   different use cases. And some will be better at certain tasks than others. Like Solana is an
[00:17:57.360 --> 00:18:01.200]   insanely performant network. It could do 50,000 transactions per second. You can't-
[00:18:01.200 --> 00:18:02.720]   Problem with Bitcoin is-
[00:18:02.720 --> 00:18:04.160]   It's a transaction to Ethereum.
[00:18:04.160 --> 00:18:06.960]   It's very slow. It's because they're using proof of work, right?
[00:18:06.960 --> 00:18:14.480]   Yeah. We weren't designed for that. They just don't have the proper mechanics to even pull that
[00:18:14.480 --> 00:18:21.200]   off in terms of consensus and the way that they work. You have to have miners doing the work to
[00:18:21.200 --> 00:18:28.240]   maintain the blockchain and every transaction has to go through miners. And even worse now that
[00:18:28.240 --> 00:18:35.200]   the Chinese miners are all being shut down, transactions have gotten very slow on Bitcoin
[00:18:35.200 --> 00:18:36.640]   and Ethereum, I guess.
[00:18:36.640 --> 00:18:41.040]   Yeah. That's why Bitcoin has introduced the side chain type things like lightning network.
[00:18:41.040 --> 00:18:46.560]   And Ethereum has layer two scaling solutions that take things off-chain, but we'll do settlement
[00:18:46.560 --> 00:18:51.520]   back to the chain. So you can actually transact and do something in a more performant area and
[00:18:51.520 --> 00:18:55.840]   then settle back to the Ethereum blockchain. So there's hacks around it.
[00:18:55.840 --> 00:19:00.480]   Charting is coming with the next version of Ethereum, which should speed things up quite a bit, but not
[00:19:00.480 --> 00:19:03.600]   a ton. So, yeah, there'll be different-
[00:19:03.600 --> 00:19:07.680]   Some chains will support very large files. Some chains will be performance. You can do
[00:19:07.680 --> 00:19:09.920]   NASDAQ type transactions or Visa scale transactions.
[00:19:09.920 --> 00:19:12.640]   So there'll be different coins for different uses.
[00:19:12.640 --> 00:19:16.640]   Yeah. And they'll talk to each other. All that, those bridges and
[00:19:16.640 --> 00:19:19.520]   framework is all being built out now. So they're all going to communicate-
[00:19:19.520 --> 00:19:22.800]   Well, that's why it's strange that Jack wants to make it just Bitcoin because
[00:19:22.800 --> 00:19:26.400]   Tazor, you could have several different currencies in that one wallet, right?
[00:19:26.400 --> 00:19:31.280]   Right. And you could transact back and forth. And that's kind of how I think you would want to do it.
[00:19:31.280 --> 00:19:37.040]   By the way, this is not turning into the crypto show, but I got the modern finance guy here,
[00:19:37.040 --> 00:19:41.360]   so I'm going to ask him some questions. But- And I did note that Bitcoin seems to be coming back
[00:19:41.360 --> 00:19:43.440]   pretty strong. It's almost $50,000 again.
[00:19:43.440 --> 00:19:48.960]   It's pretty strong. But look at where Ethereum's at, 3,200 or so. And Solana, Solana,
[00:19:48.960 --> 00:19:55.440]   jumped up a ton. I think Solana is the biggest kind of up-and-comer that has the potential to take on
[00:19:55.440 --> 00:20:00.480]   a large chunk of Ethereum's market share. Based on blockchain still, yes.
[00:20:00.480 --> 00:20:06.080]   Yes, so blockchain, but just a kind of more modern novel take on how to do consensus. And that's what
[00:20:06.080 --> 00:20:11.280]   allows them to get that 50,000 transactions per second. They're all really low-level engineers
[00:20:11.280 --> 00:20:16.960]   that came from Qualcomm. So they just use hardware to scale their performance. So as
[00:20:17.520 --> 00:20:20.320]   hardware becomes more performant, so does the blockchain.
[00:20:20.320 --> 00:20:24.400]   They're using still proof of work, or are they doing proof of stake or something else?
[00:20:24.400 --> 00:20:29.680]   No, they do. It's like a proof of stake-type consensus. You stake with validators.
[00:20:29.680 --> 00:20:34.000]   That's another issue, of course, is the massive energy usage of proof of work.
[00:20:34.000 --> 00:20:41.360]   These Bitcoin miners use a lot of power. That's buy intent, by the way. That's the way Bitcoin
[00:20:41.360 --> 00:20:45.600]   was designed. Proof of stake is I hear. I don't know what I think about it. I hear this one,
[00:20:45.600 --> 00:20:50.800]   modern finances, where I hear it, that proof of stake is a little bit easier on the environment.
[00:20:50.800 --> 00:20:54.560]   And that's what's coming with the next version of Ethereum. So that should be out in the next
[00:20:54.560 --> 00:20:57.680]   like six to eight months. But they're not very good with their timelines.
[00:20:57.680 --> 00:21:00.560]   They've been promising it for a little longer than that.
[00:21:00.560 --> 00:21:05.520]   Yeah, but they've had some good progress. They just did a big upgrade about a week or so ago,
[00:21:05.520 --> 00:21:09.440]   two weeks ago now. That was a big step in the right direction. So they're getting there.
[00:21:10.320 --> 00:21:16.720]   The interesting thing about Bitcoin going up in value is, ransomware
[00:21:16.720 --> 00:21:23.120]   ransoms are going up in value. Going back to this T-Mobile breach, the sellers selling about a
[00:21:23.120 --> 00:21:30.400]   third of the total number of records, turned it for six Bitcoin, which is now a little bit more
[00:21:30.400 --> 00:21:40.080]   than it was a week ago. So I was speculating on the radio show this morning that
[00:21:40.080 --> 00:21:45.120]   maybe ransomware would not have gone as far and been as big a problem as it had been,
[00:21:45.120 --> 00:21:52.400]   had there not been a way to relatively anonymously charge ransoms. Bitcoin empowered
[00:21:52.400 --> 00:21:55.360]   ransomware. In the early days of ransomware, people were going to, they said,
[00:21:55.360 --> 00:22:02.160]   sending it to 7-11 to buy money cards because there was no really good anonymous way to do this.
[00:22:02.160 --> 00:22:07.120]   Once Bitcoin took off and they could expect their victims to know how to get Bitcoin and pay
[00:22:07.120 --> 00:22:09.760]   them in Bitcoin, it's put ransomware through the roof.
[00:22:09.760 --> 00:22:15.120]   It's very true. It doesn't enable a lot of that. But Bitcoin is a really poor solution for that
[00:22:15.120 --> 00:22:20.320]   because everything is traceable on the blockchain. So if they were smart, they'd be using Zcash or
[00:22:20.320 --> 00:22:22.880]   something like Manero or something. Don't tell them what to do.
[00:22:22.880 --> 00:22:27.200]   They already know what they're doing it. Don't talk, Tipper, Summit.
[00:22:27.200 --> 00:22:34.560]   All right. I mean, to leave you out, Nate and Lisa. But I find this stuff fascinating.
[00:22:35.840 --> 00:22:41.680]   I feel like a tourist in all of this. Right, Lisa? I mean, it's like a different world.
[00:22:41.680 --> 00:22:48.800]   Yes. I was thinking that one of the great things about tech reporting is every day,
[00:22:48.800 --> 00:22:52.640]   vast new vistas of things you know nothing about will open up before you.
[00:22:52.640 --> 00:23:00.320]   And then your brain gets stretched. You may be only fans should start taking Bitcoin.
[00:23:01.920 --> 00:23:07.920]   So this is actually interesting. Only fans, which as you know, really made its name
[00:23:07.920 --> 00:23:16.160]   with nudity and eroticism. People, sex workers could create an account on only fans and
[00:23:16.160 --> 00:23:22.960]   make a pretty good living according to a lot of people. Only fans announced that they were going
[00:23:22.960 --> 00:23:28.240]   to you could still post news, but they're going to stop any explicit adult material on only fans.
[00:23:28.240 --> 00:23:32.160]   And the speculation was this was because they were looking for investors, but an interesting
[00:23:32.160 --> 00:23:37.600]   tweet from post culture review saying a lot of people are getting the only fan story wrong.
[00:23:37.600 --> 00:23:45.920]   The problem is MasterCard that the credit cards are changing their policies
[00:23:45.920 --> 00:23:54.240]   and starting October 1st, MasterCard is going to require that any site that accepts MasterCard
[00:23:54.240 --> 00:24:00.800]   payments not only fully verify every user and every person who appears in every adult video,
[00:24:00.800 --> 00:24:07.120]   but review all posted content before publication, including real time review of live streams.
[00:24:07.120 --> 00:24:12.880]   The new record keeping review processes, verification and other requirements are expensive and time
[00:24:12.880 --> 00:24:19.920]   consuming. Only fans seems to have decided it's not worth it. That may that I'm sure it has to do
[00:24:19.920 --> 00:24:26.000]   with investors as well, but that makes a lot of sense. And it does show you the power credit card
[00:24:26.000 --> 00:24:31.440]   companies have. It's why ransomware never says, "Hey, give us your MasterCard number
[00:24:31.440 --> 00:24:38.000]   if we can just charge it." Credit cards in the chatroom that somebody could see are
[00:24:38.000 --> 00:24:40.080]   one is saying credit cards are the new church lady.
[00:24:42.960 --> 00:24:50.320]   I mean, this comes off the back of OnlyFans having a few problems, let's say, with underage
[00:24:50.320 --> 00:25:01.440]   activity and a variety of claims that people are not necessarily who they say they are on the
[00:25:01.440 --> 00:25:07.840]   service and they've had to respond to that. And I think the timing of this, which comes off the
[00:25:07.840 --> 00:25:15.440]   back of that, is probably quite significant. And I can't believe that it's only about investors
[00:25:15.440 --> 00:25:23.440]   and payment processes that has caused this about turn, essentially. Because I think a lot of people,
[00:25:23.440 --> 00:25:27.680]   if you think of OnlyFans, they think of pornographic content or adult content.
[00:25:27.680 --> 00:25:32.480]   I've heard there's a lot of non-pornographic stuff on there too.
[00:25:34.560 --> 00:25:41.520]   But if that's getting lost in the bigger picture about whether there are people who are being
[00:25:41.520 --> 00:25:46.560]   exploited or taken advantage of in some other way, it just strikes me that all together,
[00:25:46.560 --> 00:25:50.800]   they just say, "Look, this isn't worth it. This just isn't worth it. We're going to move
[00:25:50.800 --> 00:25:54.400]   away from all this." And this is just one of the reasons that they've decided to do that.
[00:25:56.320 --> 00:26:01.360]   The Twitter storm points to in October, I'm sorry, December,
[00:26:01.360 --> 00:26:07.280]   op-ed piece. In the New York Times, the scourge of child pornography.
[00:26:07.280 --> 00:26:14.240]   Why the sigh, Lisa? No, I'm just sighing because it's a thorny and
[00:26:14.240 --> 00:26:18.560]   interactical problem and interactable. Sorry. Yeah. Yeah. And
[00:26:20.800 --> 00:26:26.880]   if I'm MasterCard or Visa, which I am not a M-Tector analyst, if I'm MasterCard or Visa,
[00:26:26.880 --> 00:26:37.040]   then I'm doing everything I can to make sure that you can't put my name next to commodified child
[00:26:37.040 --> 00:26:46.080]   abuse. But I would add that doesn't do anything to actually address the problem. All it does is
[00:26:46.080 --> 00:26:49.280]   set up alternate and parallel economies, where this is still going to go on.
[00:26:50.080 --> 00:26:55.520]   Christoph is talking about Pornhub, which did lose the ability to use credit cards last year.
[00:26:55.520 --> 00:27:01.280]   And I don't know how that's affected Pornhub, but I imagine it's not been good.
[00:27:01.280 --> 00:27:08.000]   And now the same thing is happening to only fans. I have mixed feelings about this. Of course,
[00:27:08.000 --> 00:27:16.160]   no one wants exploitation, revenge porn, child pornography. There's all sorts of semi-evil kinds
[00:27:16.160 --> 00:27:21.680]   of adult content out there, and there's lots of demand for it. But at the same time, I don't.
[00:27:21.680 --> 00:27:29.600]   I when Apple does what it's doing with CSAM and others, it makes me nervous that there's a new
[00:27:29.600 --> 00:27:38.000]   pure, puretanical modality coming in. I think you take the puretanical aspect out of it. I think
[00:27:38.000 --> 00:27:44.160]   people are actually getting distracted by the sex and eroticism angle with only fans. And
[00:27:44.880 --> 00:27:50.000]   what we could be taking away from the story is one, credit card companies have the power to make
[00:27:50.000 --> 00:27:55.920]   or break an entire corporation by saying, if you want to work with us, we are going to require
[00:27:55.920 --> 00:28:01.520]   you to put these really labor intensive processes into place because this protects us legally. And
[00:28:01.520 --> 00:28:07.040]   if your internal processes don't work, not only do you lose us as a source of funding,
[00:28:07.040 --> 00:28:13.360]   you're also tremendously legally vulnerable. So companies now have to assess whether or not
[00:28:13.360 --> 00:28:18.320]   they want to do business with some of the major financial platforms in the world.
[00:28:18.320 --> 00:28:26.240]   But another aspect of this is the people who make money off of only fans are discovering as
[00:28:26.240 --> 00:28:32.400]   people on YouTube discovered when YouTube started demonetizing videos, or as other folks have
[00:28:32.400 --> 00:28:37.440]   discovered like Instagram influencers, if you make your living on a third party platform,
[00:28:38.080 --> 00:28:44.720]   you're terribly vulnerable. Because you have no say over what their
[00:28:44.720 --> 00:28:49.920]   standards and practices are going to be. They don't owe you any sort of runway or notice when
[00:28:49.920 --> 00:28:57.440]   the terms change, your revenue stream can dry up overnight. And we tend to valorize these stories.
[00:28:57.440 --> 00:29:04.080]   I was reading a roundup where somebody interviewed like five different sex workers who are up
[00:29:04.080 --> 00:29:08.240]   in arms over the OnlyFans thing. And one of them was saying, yeah, I make $100,000 a month,
[00:29:08.240 --> 00:29:12.800]   I'm not going to replicate that. And the thing is, is someone's going to see that as a success
[00:29:12.800 --> 00:29:17.680]   story and be like, oh, I can get them to OnlyFans. But this sex worker is not saying, I'm making
[00:29:17.680 --> 00:29:25.440]   $100,000 a month on OnlyFans. And I'm entirely at their mercy when it comes to terms and conditions
[00:29:25.440 --> 00:29:31.680]   under which I can use this platform. Well, to take it out of the porn realm, my son is trying to
[00:29:31.680 --> 00:29:39.680]   make a living as a TikTok guy. He makes food, cooking videos are quite good. He's very good at it.
[00:29:39.680 --> 00:29:44.880]   And I have the same thing. I say to him, don't be dependent on TikTok. Make sure they're on
[00:29:44.880 --> 00:29:50.240]   Instagram and YouTube as well and trying to monetize all three platforms. Because who knows
[00:29:50.240 --> 00:29:55.040]   the Chinese government might decide at any point, we don't want any more cooking videos on TikTok.
[00:29:55.040 --> 00:29:59.040]   And you're at their mercy, completely at their mercy. But on the other hand, let's not forget
[00:29:59.040 --> 00:30:05.280]   these platforms like OnlyFans and TikTok provide really, or I can we include Patreon,
[00:30:05.280 --> 00:30:10.080]   we sell club Twitch memberships on Patreon's member full site. But our really wonderful,
[00:30:10.080 --> 00:30:17.680]   unique ways for individuals to, I think it's great. If my son can make a living, he's got 100,000
[00:30:17.680 --> 00:30:22.800]   followers. His videos are getting a million, typically a million views per video. He's very
[00:30:22.800 --> 00:30:28.800]   close to that place where you go over the line. And now you can actually make a, you know,
[00:30:28.800 --> 00:30:36.240]   $10,000 a month, make a living doing videos on TikTok. Those are really empowering platforms.
[00:30:36.240 --> 00:30:41.760]   I mean, isn't that what we, isn't that what we are excited about with social media is how they
[00:30:41.760 --> 00:30:47.200]   can empower an individual? Remember, it does, but it reminds me a great deal of, you know,
[00:30:47.200 --> 00:30:52.560]   in a much broader sense of in the gig economy. And a lot of the arguments that went around with
[00:30:52.560 --> 00:30:59.280]   companies like Uber and Deliveroo and businesses where, you know, they're signing people up
[00:30:59.280 --> 00:31:03.840]   at an incredible pace. And they're providing a product via these
[00:31:03.840 --> 00:31:10.480]   economy workers that people really value and use. But when something goes wrong, you know,
[00:31:10.480 --> 00:31:16.240]   there's sickness, there's injury, there's some other force majeure. The company,
[00:31:16.240 --> 00:31:21.440]   and I don't mean him, Uber specifically, I mean, any of these companies don't typically have
[00:31:21.440 --> 00:31:28.320]   a foolproof way of protecting the people that their business depends on, but also on whom
[00:31:28.320 --> 00:31:35.280]   they are dependent. So there's no, there's no guarantee, there's no backup, there's no insurance
[00:31:35.280 --> 00:31:40.160]   policy that's very easy to get that would say, well, if you're making your living on a platform
[00:31:40.160 --> 00:31:44.960]   and the platform changes its terms and conditions because of payment processor influence or investor
[00:31:44.960 --> 00:31:49.280]   concern, whatever, there's no insurer that I'm aware of that's like, get more cover you for that
[00:31:49.280 --> 00:31:53.520]   no worry, we'll give you the $100,000 a month. Yes, our flag is not selling policies for that
[00:31:53.520 --> 00:32:00.800]   right now. Okay, but is an at will state anybody working in California can get fired for no reason
[00:32:00.800 --> 00:32:05.920]   at any time. And you're it's the same thing, right? I mean, if you're working for the man,
[00:32:05.920 --> 00:32:10.000]   you're working for you're at the mercy of a third party. It's how is that different?
[00:32:10.000 --> 00:32:16.880]   Because there are at least contracts there and there is there's procedure, you know, to go against
[00:32:16.880 --> 00:32:22.320]   unfair dismissal that you know, there are there are routes that you have and there there's a framework
[00:32:22.320 --> 00:32:27.600]   within which you can work to make sure that justices is is is served if if something has
[00:32:27.600 --> 00:32:32.160]   gone wrong in the system and you've been a victim of it. I don't think that exists
[00:32:32.160 --> 00:32:38.800]   for many of these sorts of platforms. There's not that existing. Yeah, actually, that's that's
[00:32:38.800 --> 00:32:46.080]   fairly timely because a judge ruled this week that prop 22, we had a proposition in California
[00:32:46.080 --> 00:32:54.400]   that said that was basically funded by Uber and Lyft. And it was approved by a majority of California's
[00:32:54.400 --> 00:33:00.800]   voters that classified drivers and careers as independent contractors and said, it's okay.
[00:33:00.800 --> 00:33:07.600]   Even though in the state and state law, it probably was not okay. Because of the threat of that
[00:33:07.600 --> 00:33:11.840]   Uber and Lyft put this proposition forward, it's fairly easy in California. It doesn't take very
[00:33:11.840 --> 00:33:16.480]   many signatures to get a proposition out there and then bought millions and millions of dollars in ads.
[00:33:16.480 --> 00:33:23.920]   Fooled me, I'll be honest, I voted yes on prop 22. They had a lot of nice moms saying, I want to be
[00:33:23.920 --> 00:33:27.440]   there when my kid gets home from school, I need a way to make money. I want to be able to make my
[00:33:27.440 --> 00:33:32.800]   own schedule. It's great. I could drive for Lyft and it's a it's a great thing. And I I bought I
[00:33:32.800 --> 00:33:40.800]   actually bought it. A judge has ruled now that it is unconstitutional in federal court on Friday,
[00:33:40.800 --> 00:33:47.120]   Alameda County Superior Court Judge Frank Roche said it's unenforceable because a section in the
[00:33:47.120 --> 00:33:52.080]   measure limits the ability of legislatures to amend the law. Boy, that tells you how smart Uber
[00:33:52.080 --> 00:33:56.560]   and Lyft were when they wrote it, they said, Oh, and by the way, the legislature can override this.
[00:33:56.560 --> 00:34:02.640]   And that's unconstitutional. It's it's a lucky day. I guess that they did that. I still am not
[00:34:02.640 --> 00:34:07.600]   sure how I would vote if that proposition went up again. Because there's plenty. I mean, if you
[00:34:07.600 --> 00:34:14.720]   look, there's plenty of gig workers who say, no, we we appreciate the ability to work on our own
[00:34:14.720 --> 00:34:19.920]   schedule. They do. And I mean, I've been covering this for, you know, for Bloomberg for a number of
[00:34:19.920 --> 00:34:24.720]   years now and spoken to a lot of Ubers, I actually spent hundreds of pounds at one point taking
[00:34:24.720 --> 00:34:28.160]   rides in Ubers to specifically say, Hey, I'm a journalist can't talk to you about this thing.
[00:34:28.160 --> 00:34:34.480]   And they all wanted to talk about it. And in the UK, I mean, Ubers is a very interesting case in
[00:34:34.480 --> 00:34:43.040]   Britain because earlier this year, they Uber did reclassify its drivers as workers. There's like
[00:34:43.040 --> 00:34:47.760]   60, 70,000 of them at work. That means they at least in the US, they'd have to pay benefits.
[00:34:47.760 --> 00:34:51.280]   They'd have certain rules about employment. That's right.
[00:34:51.280 --> 00:34:56.160]   That's right. Yeah. Yeah. But it's not the same as classing them as an employee.
[00:34:56.160 --> 00:35:03.360]   You know, so there are there there is a it's quite a specific definition, I think under British law.
[00:35:03.360 --> 00:35:06.480]   But a lot of people looked at it and said, look, this is the way it's going to go. And if you look
[00:35:06.480 --> 00:35:13.040]   across Europe, there are consultations, various stages of progress where countries are saying,
[00:35:13.040 --> 00:35:18.640]   look, you've got to offer protection to these guys. It's interesting because in the UK and
[00:35:18.640 --> 00:35:23.840]   Europe, you have nationalized health. So one thing that is not at risk for these workers is
[00:35:23.840 --> 00:35:28.560]   health care. In the United States, that might even be the biggest issue for these workers because
[00:35:28.560 --> 00:35:34.880]   they of course don't get health care when they're contractors. In the UK, certainly. Yeah.
[00:35:34.880 --> 00:35:39.600]   So that's real. I think that's interesting. It's still an issue in the UK, even though health
[00:35:39.600 --> 00:35:44.480]   care is not on the table. But health care, you know, there are gradients of health care. I mean,
[00:35:44.480 --> 00:35:49.680]   yes, we have we have free health care. Anyone here gets, you know, doctors and medicines, it's
[00:35:49.680 --> 00:35:55.280]   it's taken care of. It's free if you need it or heavily subsidized. But that doesn't necessarily
[00:35:55.280 --> 00:36:02.400]   entitle you to extremely quick being seen very quickly. Or if you have an emergency,
[00:36:02.400 --> 00:36:05.600]   obviously that's that's different. But if you've just got something that kind of needs doing,
[00:36:05.600 --> 00:36:08.720]   you still end up on a waiting list. You're not going to pay for it, but you still on a waiting
[00:36:08.720 --> 00:36:12.800]   list, whereas private health care, usually, you know, you're seen very, very quickly.
[00:36:12.800 --> 00:36:19.760]   And a lot of companies do offer that sort of work. So that would be that would be a benefit
[00:36:19.760 --> 00:36:24.240]   of employment is better is better health care. Yeah. And things like holiday, you know, vacation
[00:36:24.240 --> 00:36:30.800]   time as well. The way that Uber did it, I think is that, you know, you get a certain number of
[00:36:30.800 --> 00:36:37.280]   hours paid to you in lieu of having the days that you can take off because you're working your
[00:36:37.280 --> 00:36:42.080]   own hours. So it's more like, well, we'll give you a percentage like over the course of a year,
[00:36:42.080 --> 00:36:48.160]   if you're working full time, you may have had this many days paid vacation. So we'll take that as a
[00:36:48.160 --> 00:36:53.760]   percentage and just apply that as a sort of like a cash bonus on top of whatever hours you do.
[00:36:54.240 --> 00:36:58.960]   So it's not like you're getting the days as paid holiday. It's more like you're getting the money
[00:36:58.960 --> 00:37:03.360]   that you would have had based on how much you're driving, if that makes sense. It is really
[00:37:03.360 --> 00:37:06.960]   complicated and it's quite specific to Britain at the moment. I'm very conflicted about this,
[00:37:06.960 --> 00:37:14.400]   because on the one hand, I think it's it's it's a modern way of employment, gig employment,
[00:37:14.400 --> 00:37:18.480]   and people don't have to choose it. That's, I guess, the fundamental crux of it.
[00:37:18.480 --> 00:37:22.000]   Do people choose it because they have to? There's no other option out there,
[00:37:22.000 --> 00:37:26.560]   just like Amazon warehouse workers have to take a bad job because there's no other option.
[00:37:26.560 --> 00:37:34.000]   Or is it a fairly fluid labor market? Could they take a better job? In which case they're choosing
[00:37:34.000 --> 00:37:39.600]   this gig work, maybe for good reason. Well, let's go back to the ad you cited,
[00:37:39.600 --> 00:37:43.680]   where you talk about how in the ad there was the mom who said, I wanted to be there for my
[00:37:43.680 --> 00:37:50.400]   kids every day. One of the appeals of any sort of gig economy hustle is the idea that you do have
[00:37:50.400 --> 00:37:56.640]   control over your time so that you can, especially if you're somebody who is responsible for care
[00:37:56.640 --> 00:38:01.520]   giving either a parent or a child, so that you can balance the demands of your personal life
[00:38:01.520 --> 00:38:06.880]   against the very real need to make money. I suppose you could argue that they took the job
[00:38:06.880 --> 00:38:14.080]   because they had to, since being able to control when and how much you work is going to be a huge
[00:38:14.080 --> 00:38:25.280]   priority to people. The modern world is tough. The flip side is that it's sold as this,
[00:38:25.280 --> 00:38:31.040]   oh, you have total control over your time, but that's almost like, oh, the good news is it's a
[00:38:31.040 --> 00:38:36.080]   flexible schedule. Yeah, go ahead and work any 80 hours a week you want to work. Because,
[00:38:36.080 --> 00:38:40.880]   just like you mentioned with your son who's on TikTok, I don't think it's a coincidence that we're
[00:38:40.880 --> 00:38:44.560]   seeing a rise in the number of articles talking about TikTok influencer burnout where these
[00:38:44.560 --> 00:38:50.560]   kids are like, I just have to keep exactly. But it's his choice to do it.
[00:38:50.560 --> 00:38:56.240]   Well, with these gig economy type jobs, it's the same thing where the risk of burnout is real,
[00:38:56.240 --> 00:39:00.480]   and one of the hazards of being an independent contractor is if you don't have any sort of built
[00:39:00.480 --> 00:39:06.000]   in benefits, you can't take a two week paid vacation and you can't take a sick day and you may not
[00:39:06.000 --> 00:39:12.560]   have a boss who's forcing you to go to a webinar to tell you how to get burnout in the old days
[00:39:12.560 --> 00:39:19.520]   before whatever happened or politics happened. This was the kind of thing that would divide
[00:39:19.520 --> 00:39:23.920]   Republicans and Democrats. Democrats would say, no, no, you got to protect workers,
[00:39:23.920 --> 00:39:28.560]   Republicans would say, no, it's their choice. It's free choice. If you don't like it, get another
[00:39:28.560 --> 00:39:33.440]   job. And I think that's a that is a debate that is not an unreasonable debate. I don't know where I
[00:39:33.440 --> 00:39:39.840]   come down on that. I understand both sides of the issue. Uber and Lyft, by the way, say that this
[00:39:39.840 --> 00:39:46.000]   is outrageous. They will appeal. They will appeal the judge's decision.
[00:39:46.000 --> 00:39:51.920]   One of the things that I just wanted to mention on the only fans front, because I forgot to mention
[00:39:51.920 --> 00:40:00.000]   it earlier, is that the pandemic has made that platform that's and specifically that platform
[00:40:01.360 --> 00:40:05.760]   very popular for a large number of people who were suddenly out of work or had a lot of spare
[00:40:05.760 --> 00:40:13.680]   time on their hands and have made good money during the pandemic as a result of basically being
[00:40:13.680 --> 00:40:21.280]   stuck at home, but having an outlet for something they can do at home. And I wonder how many of those
[00:40:21.280 --> 00:40:26.000]   people during the period of time that they have now been at home, because, as be honest, this has
[00:40:26.000 --> 00:40:31.120]   gone on for an awful lot longer than any one of as looks like it's going to go on even
[00:40:31.120 --> 00:40:37.600]   longer, by the way. How many of them had got to the point where maybe they started doing something
[00:40:37.600 --> 00:40:42.240]   and thought, maybe this can support me. Maybe it'll just be for a couple of months. But over the
[00:40:42.240 --> 00:40:46.240]   course of the prolonged period of the pandemic has actually said, you know what, I don't need to go
[00:40:46.240 --> 00:40:50.960]   back to work. Like, I don't need furlough. Like, let's just go all in on this. This will keep me.
[00:40:50.960 --> 00:40:56.800]   And then this happened. And now they're out of money, potentially, and they're out of work as
[00:40:56.800 --> 00:41:00.080]   well. I don't know. I just think there will be a quite a few people that will fall into that category.
[00:41:00.080 --> 00:41:04.240]   It's complicated, right? It's hard to know where to come down on this. And you've studied a lot
[00:41:04.240 --> 00:41:09.120]   more than I have. You have direct contact with drivers. I mean, I have anecdotal contact with
[00:41:09.120 --> 00:41:15.040]   drivers. And of course, you can't really trust somebody who's doing it, because they have some
[00:41:15.040 --> 00:41:20.080]   investment in justifying the fact that they're doing it, even if it's a terrible, you know, gig
[00:41:20.080 --> 00:41:26.560]   for them. They might be more inclined to say, it's good, just because they just to justify the
[00:41:26.560 --> 00:41:34.160]   fact that they are doing it. You know, I don't know. DoorDash's minimum guarantee is $16.00
[00:41:34.160 --> 00:41:39.520]   an hour plus 30 cents a mile. That sounds pretty good. That doesn't sound like a bad gig.
[00:41:39.520 --> 00:41:46.880]   I just don't know. I would ask, with the DoorDash gig, what happens if a customer's dissatisfied,
[00:41:46.880 --> 00:41:51.760]   or are you required to eat the cost of a meal if a customer's like, this isn't what I ordered? Or
[00:41:51.760 --> 00:41:57.280]   it seems like it's one thing to say you're making $16 an hour. I would question what sort of protections
[00:41:57.280 --> 00:42:02.160]   are there for dealing with difficult customers? We have a local food delivery service called the
[00:42:02.160 --> 00:42:08.400]   Petaluma Food Taxi that recently has had to ask people, do not withdraw your tip
[00:42:08.400 --> 00:42:14.880]   after you get your food. So apparently what people are doing is saying, I'm going to give you a 30%
[00:42:14.880 --> 00:42:20.320]   tip. And then after they get the food, they cancel the tip as a way to get and send a good delivery.
[00:42:20.320 --> 00:42:25.520]   But then they don't, the driver gets nothing. And I thought, that's so low. But of course,
[00:42:25.520 --> 00:42:31.440]   people are going to do stuff like that. But if you work with the public in any capacity,
[00:42:31.440 --> 00:42:37.440]   you have to deal with that. I don't care if you're working at Starbucks or an Uber driver.
[00:42:37.440 --> 00:42:43.760]   Kevin, I actually wanted to ask you about Corey Doctorow's assertion that Uber never
[00:42:43.760 --> 00:42:49.920]   was intended to make money, that it was all a con. But let's take a break and then we'll do
[00:42:49.920 --> 00:42:55.440]   that. Kevin Rose is here from the Modern Finance podcast, Modern. Finance, of course, he's a
[00:42:55.440 --> 00:43:02.960]   famous angel and VC, angel investor in VC at True Ventures, formerly Google Ventures and
[00:43:02.960 --> 00:43:10.240]   an angel before that. And even maybe more famous as my personal friend. So it's so nice to have you
[00:43:10.240 --> 00:43:15.440]   on the show. Two kids now. Two little ones, three year old, two year old.
[00:43:15.440 --> 00:43:21.120]   Oh my. Keeps me busy. That is, those are, that's two little bundles of energy.
[00:43:21.120 --> 00:43:26.960]   Holy cow. I'm right in the thick of it, right? Holy cow. Is Dario with him right now or?
[00:43:26.960 --> 00:43:31.680]   Yeah, upstairs and like, you just never know when I'm doing these podcasts, you know,
[00:43:31.680 --> 00:43:35.680]   because I do a few a week. It's like, okay, what role did I, am I going to get today? I'm going to
[00:43:35.680 --> 00:43:39.760]   get it screaming baby that I have to test. You know, Dario, be like, take to the other side of the
[00:43:39.760 --> 00:43:46.160]   house. I, when my kids were that age, I had my own office, but they would, they knew I was in
[00:43:46.160 --> 00:43:53.120]   there. They would come and pound on the door and say, Daddy, Daddy, let me in. But I noted that you
[00:43:53.120 --> 00:43:58.800]   actually have a secret room. This is a secret. Yeah, you can't see because of the lower third,
[00:43:58.800 --> 00:44:04.720]   but there's a little tiny, like knob there, like a little twisty thing that allows access to the
[00:44:04.720 --> 00:44:09.360]   room. You're actually behind a bookshelf. So they don't know you're in here. That's correct.
[00:44:09.360 --> 00:44:13.760]   And they are also, yeah, they're, we have a child gate that keeps them from coming down
[00:44:13.760 --> 00:44:19.360]   stairs from the stairs there. So that's, that's good as well. Lisa, have you ever had trouble like
[00:44:19.360 --> 00:44:26.160]   that with your daughter? She's down on the door. Oh, yes. So there was one time I was recording a
[00:44:26.160 --> 00:44:31.760]   podcast with Jason Snell over at the incomparable when she was teething and she screamed so loudly,
[00:44:31.760 --> 00:44:37.920]   we had to suspend the podcast until she could calm down a little bit. Wow. Wow.
[00:44:37.920 --> 00:44:42.560]   Wow. But I mean, she's one, she's 10 now, so it's much easier. Yeah. And two,
[00:44:42.560 --> 00:44:47.440]   I arranged a mini golfing date for her. So it's not gonna be a problem. Oh, very nice.
[00:44:47.440 --> 00:44:53.040]   Nothing like putt, putt golf when you got to do a podcast. That's the key. It's outside. It's safe.
[00:44:53.040 --> 00:45:00.000]   Okay. Can I, can I embarrass Kevin? This is a little video. Oh, no. From the new screen savers,
[00:45:00.000 --> 00:45:03.200]   maybe it's more embarrassing than me. Your windows password is not very secure,
[00:45:03.200 --> 00:45:06.880]   especially if they have physical access to the machine. Oh, man, my brown hair.
[00:45:06.880 --> 00:45:09.600]   So cute. Let me show you. Let me give you a little background on windows password.
[00:45:09.600 --> 00:45:11.600]   Are you great now, Kevin? This right here. Look at this.
[00:45:11.600 --> 00:45:16.480]   I watch the command shells. Kevin, you're almost the age I was when I'm talking to you now here.
[00:45:16.480 --> 00:45:18.560]   That's right. Oh, my God.
[00:45:18.560 --> 00:45:20.480]   Oh, yeah. How old are you then?
[00:45:20.480 --> 00:45:20.800]   You can see the file here.
[00:45:20.800 --> 00:45:27.440]   Call us. Let's see. This was probably nine. Let's say it's nine. Let's say it's 2000.
[00:45:27.440 --> 00:45:34.560]   I would have been 44. No, this is 2002. 2002. So 46 or 45. Okay. So you're getting close.
[00:45:34.560 --> 00:45:41.120]   How old are you at? 44. Yeah. So you're basically the age I was when we first met a tech TV.
[00:45:41.120 --> 00:45:43.360]   That's amazing. You're gonna fire up a copy of this program.
[00:45:43.360 --> 00:45:48.320]   And this kid, he's the age of my kid now. This is coming. How about that? How about that?
[00:45:48.320 --> 00:45:52.080]   That's Henry's age. Yeah. Completely free. It's completely free. It's a
[00:45:52.080 --> 00:45:55.360]   lengthy pass where we were hacking hacking, hacking, hacking,
[00:45:55.360 --> 00:46:00.880]   and teep passwords there. Yep. Yeah. I think it's, it's has a little sped up. I don't think
[00:46:00.880 --> 00:46:04.080]   your voice was quite that high. I think I was really nervous.
[00:46:04.080 --> 00:46:10.800]   So much fun. Sorry. I hate to do that to you, but I have to do it to you every second.
[00:46:10.800 --> 00:46:14.000]   It's always fun. It's like a little brother. You got to just give him a little nuggy every once
[00:46:14.000 --> 00:46:20.080]   in a while. You have a poo spot. Our show today brought to you by Mint Mobile. Love these guys.
[00:46:20.080 --> 00:46:28.320]   Man, did I get a great deal from Mint Mobile? So Mint Mobile is a wireless company that is
[00:46:28.320 --> 00:46:34.080]   not like any other wireless company you used to. After years of fine print contracts getting
[00:46:34.080 --> 00:46:38.560]   ripped off by big wireless, if we've learned anything, we know there's always a catch.
[00:46:38.560 --> 00:46:44.240]   They say unlimited download unless you download so much, we're gonna have to turn it off. Or
[00:46:44.240 --> 00:46:51.200]   yeah, it's the data price is low, low, low. No, no, no. When I heard Mint Mobile, for instance,
[00:46:51.200 --> 00:46:55.120]   was offering premium wireless service starting at 15 bucks a month, I said, no.
[00:46:56.160 --> 00:46:59.600]   What's the catch? Where's the fine print? But you know what? I've been using their
[00:46:59.600 --> 00:47:04.960]   service now for more than a year and it's true. There is no catch. See, Mint Mobile's secret
[00:47:04.960 --> 00:47:11.200]   sauce is that the first companies sell wireless service online only. No retail stores, no crazy
[00:47:11.200 --> 00:47:16.560]   overhead costs. They have to pass down to youth in the form of mystery fees. It's just
[00:47:16.560 --> 00:47:22.960]   it's just the best. They offer premium wireless starting at $15 a month. Now you get four gigs
[00:47:22.960 --> 00:47:28.000]   a month unlimited talk and text with that, but they have an unlimited plan for $30 a month. It
[00:47:28.000 --> 00:47:32.480]   just depends how much data you need. All the plans come with unlimited talk and text. High speed
[00:47:32.480 --> 00:47:37.360]   data delivered on the nation's largest 5G network. You could bring your own phone. They'll send you
[00:47:37.360 --> 00:47:43.200]   a SIM free. The other guys actually charge you to send you a SIM and they'll make it easy to
[00:47:43.200 --> 00:47:46.560]   port your number over so you don't have to lose your number. If you're keeping your old phone,
[00:47:46.560 --> 00:47:51.280]   your contacts come right along with it. I got it. Actually, I went online and got one of their
[00:47:51.760 --> 00:47:56.560]   iPhone SEs for $15 a month. So that meant $30 a month. I got a brand new phone and
[00:47:56.560 --> 00:48:02.480]   service $30 a month. That's about a third of what I'm paying for just the service alone
[00:48:02.480 --> 00:48:06.800]   on the big boys. And of course, if you're not 100% satisfied, Mint Mobile has you covered with
[00:48:06.800 --> 00:48:14.480]   their seven day money back, guarantee. Shop around. You will not find a better plan
[00:48:14.480 --> 00:48:20.480]   for your cell phone. Get it for yourself. Get it for your family. Switch to Mint Mobile premium
[00:48:20.480 --> 00:48:27.520]   wireless service just $15 a month. See the calculator there? Use that. Bring your bill. You can
[00:48:27.520 --> 00:48:33.120]   figure out how much data you use on your current plan and you can easily figure out how much
[00:48:33.120 --> 00:48:38.080]   Mint Mobile will save you. I can promise you it's going to be a ton. To get your new wireless plan
[00:48:38.080 --> 00:48:42.960]   for just $15 a month and get the plan shipped to your door, absolutely free. No charge. Go to mint
[00:48:42.960 --> 00:48:50.320]   mobile.com/twit. Please go to that address so they know you saw it here. Mintmobile.com/twit
[00:48:50.320 --> 00:48:56.000]   as a very happy Mint Mobile customer. I have to ask the burning question, why the hell am I paying
[00:48:56.000 --> 00:49:05.680]   more for less? Cut your wireless bill to $15 a month. Mintmobile.com/twit. I can highly recommend
[00:49:05.680 --> 00:49:12.400]   them. I do. My father-in-law, everybody, I know. I got them on Mint Mobile.
[00:49:12.400 --> 00:49:20.720]   Corey Doctorow made an interesting assertion in his blog, Pluralistic.net a couple of weeks ago.
[00:49:20.720 --> 00:49:26.320]   I thought, "I'm going to get Kevin on here. He's an investor. He can explain what the hell's going
[00:49:26.320 --> 00:49:32.720]   on." Uber, Corey says, "Was never going to be profitable. It lured drivers and riders into cars
[00:49:32.720 --> 00:49:38.800]   by subsidizing rides." As we know, Uber loses money on every single ride, something like 40%
[00:49:38.800 --> 00:49:44.640]   on every single ride, no matter what they pay the drivers. Subsidizing rides with billions and
[00:49:44.640 --> 00:49:50.080]   billions of dollars from the Saudi royal family, big investors, keeping up the con artists ever
[00:49:50.080 --> 00:49:58.080]   shifting patter about how someday this will all stand on its own. Like the pretense that self-driving
[00:49:58.080 --> 00:50:01.840]   cars would eliminate all their labor costs, they knew this would never happen. They spent billions
[00:50:01.840 --> 00:50:06.640]   on a doomed effort, then had to bribe another company with a $400 million investment to take
[00:50:06.640 --> 00:50:14.400]   away its window dressing. Uber's whole game was to get investors to put in money all the way up to
[00:50:14.400 --> 00:50:21.920]   the IPO so that founders could cash out, walk away. He says, "Wistling innocently."
[00:50:21.920 --> 00:50:29.760]   By the way, there's been a side effect to this because Uber has also made cities
[00:50:29.760 --> 00:50:35.040]   more hostile to bicycles. By turning bike lanes into Uber drop off and pick up spots,
[00:50:35.040 --> 00:50:40.960]   they've increased traffic in Midtown Manhattan and other big cities. They've maybe even worse.
[00:50:40.960 --> 00:50:48.480]   They've in effect encouraged local governments to not consider mass transit options, to just say,
[00:50:48.480 --> 00:50:54.400]   "Well, we got Uber." It victimized workers, riders, cities, and even restaurants,
[00:50:56.960 --> 00:51:02.480]   quite famously, Uber was predating upon restaurants using SEO to trick people into thinking they
[00:51:02.480 --> 00:51:08.480]   were ordering from restaurants directly, non-consentually opting restaurants into its delivery service,
[00:51:08.480 --> 00:51:13.360]   subsidizing meals to set prices below break even. Then once Uber had diverted a restaurant's
[00:51:13.360 --> 00:51:18.080]   customers into relying on its service, this was really accelerated during the pandemic. It
[00:51:18.080 --> 00:51:23.520]   put the screws to restaurants, forcing them to pay "marketing fees" upon paying of having searches
[00:51:23.520 --> 00:51:30.560]   for their business diverted to Uber-affiliated ghost kitchens. It raised more than $200 million
[00:51:30.560 --> 00:51:42.400]   to pass Prop 22. It never has ever made money. It's lost money like crazy. Every quarter,
[00:51:42.400 --> 00:51:47.440]   it releases—this is Corey writing again—new lies laid out like a profit and loss statement,
[00:51:48.160 --> 00:51:52.800]   non-gap accounting. Every quarter, it's losing money. In fact,
[00:51:52.800 --> 00:51:57.280]   according to Corey, mid-2021, Uber's going broke.
[00:51:57.280 --> 00:52:04.720]   Not a lot of runway left. True accounting in the last quarter has Uber losing $0.38,
[00:52:04.720 --> 00:52:09.680]   and every dollar it took in. $3.7 billion of its assets are actually worthless paper
[00:52:09.680 --> 00:52:15.760]   from failing overseas ride-hail companies. Cash reserves declined by $4.7 billion in 2020,
[00:52:15.760 --> 00:52:21.680]   and $937 million more in the first half of 2021. They've only got $6.7 billion in the bank
[00:52:21.680 --> 00:52:30.960]   down from $14.6 in 2019. What do you think, Kevin? I don't know if you have an investment in Uber.
[00:52:30.960 --> 00:52:34.720]   I hope you don't. Was this just a con game, a shell game?
[00:52:34.720 --> 00:52:41.040]   I don't have an investment in Uber. I was there when we did the investment at Google Ventures.
[00:52:41.040 --> 00:52:47.520]   We did place a very large check at $254 million into Uber when I was at Google.
[00:52:47.520 --> 00:52:55.760]   I can tell you this because I knew the founders from the very beginning, Travis and Garrett and
[00:52:55.760 --> 00:53:05.280]   Ryan, they're not scammers. They set out to build a real business here, and they started off with
[00:53:05.280 --> 00:53:10.800]   just Black Car Service when it first launched. When you're in San Francisco, we were all using it,
[00:53:10.800 --> 00:53:14.560]   just a handful of Black Cars. We were like, "Oh, cool. Kind of date night. This is an awesome
[00:53:14.560 --> 00:53:19.440]   way to go out on a date." The Black Cars were more expensive. In fact, I remember taking it when
[00:53:19.440 --> 00:53:23.760]   they launched-- I think you were there in low web when they launched in Paris. It was a Black
[00:53:23.760 --> 00:53:30.480]   Car Service. It was nice. It was expensive. When they first launched, there was no any other
[00:53:30.480 --> 00:53:33.760]   option. We could only start with Black Cars, and that's all they did. They were like, "Okay,
[00:53:33.760 --> 00:53:37.360]   we're going to make it easier to book a Black Car." That's what they thought, like a cooler,
[00:53:37.360 --> 00:53:43.600]   like higher end car. What happened though is that the second that started to work,
[00:53:43.600 --> 00:53:49.520]   then there were a handful of other startups that entered the space. The second these other
[00:53:49.520 --> 00:53:53.600]   startups entered the space, they did two things. One, they said, "Okay, this doesn't have to be
[00:53:53.600 --> 00:53:58.480]   just applicable to Black Cars. It can be any car." Lift was really famous to come along with the
[00:53:58.480 --> 00:54:02.080]   mustache and saying, "It's all about fist bumps and we're a cooler."
[00:54:02.080 --> 00:54:06.640]   By the way, I have to confess my nephew invented the mustache.
[00:54:06.640 --> 00:54:10.400]   Okay, go on. Are you serious? You got to pull that up so people can see what we're talking about.
[00:54:10.400 --> 00:54:15.040]   They might not remember the mustache. The giant pink mustache on lift cars. You couldn't miss him.
[00:54:15.040 --> 00:54:24.160]   It was fun. He was the director of customer experience, something like that.
[00:54:25.760 --> 00:54:34.160]   I was fun. In fact, it made me want to take a picture of an Audi with a giant pink mustache.
[00:54:34.160 --> 00:54:39.520]   Yeah, they all had the mustaches on. When this came out, essentially what happened is now you have
[00:54:39.520 --> 00:54:46.000]   two well-funded companies or multiple companies that had venture funding. They saw this as a
[00:54:46.000 --> 00:54:51.040]   massive market. Venture capitalists poured tons and tons of money into these startups. The only
[00:54:51.040 --> 00:54:55.760]   way to really win was to reduce margins and reduce the cost.
[00:54:55.760 --> 00:54:58.640]   My dog's going to throw up in the back down here.
[00:54:58.640 --> 00:55:05.280]   That's okay. Hi, Toaster, the only dog with an Instagram filter named after him.
[00:55:05.280 --> 00:55:08.160]   Poor guy. He's now a little...
[00:55:08.160 --> 00:55:10.880]   He's like 10 years old now.
[00:55:10.880 --> 00:55:17.760]   Basically, margins got compressed and then all of a sudden, every ride was unprofitable.
[00:55:19.280 --> 00:55:24.000]   It was just a scale. Let's go for scale. Massive marketing budgets.
[00:55:24.000 --> 00:55:27.920]   Then you have consumers where if they would raise rates, they would just drop off and go to the
[00:55:27.920 --> 00:55:32.960]   competition. If Uber was trying to get a little bit more margin, all of a sudden, everyone would
[00:55:32.960 --> 00:55:39.920]   just go over to lift. It was just nasty battle that went on and on. They just haven't gotten out
[00:55:39.920 --> 00:55:46.560]   of that battle. There's no way out of it. I'm with everyone else here in that I don't see a path
[00:55:46.560 --> 00:55:52.400]   forward. Do these be becoming profitable entities? Yes, the margins on things like Uber Eats look
[00:55:52.400 --> 00:55:57.840]   a lot better. Yes, self-driving technology is coming, but it's not there yet. I still think we're
[00:55:57.840 --> 00:56:01.600]   another decade out until we're going to have something that other than just neighborhood trips,
[00:56:01.600 --> 00:56:06.240]   but actually highway and on and off ramp and side streets. It's going to be a while
[00:56:06.240 --> 00:56:11.920]   until that technology is ready. I don't hold any Uber shares right now.
[00:56:11.920 --> 00:56:18.720]   It's not incompatible with the fact that Travis and company had good intentions at the beginning.
[00:56:18.720 --> 00:56:23.040]   These things can run away with you. Oh, there was a ton of shady stuff that went down.
[00:56:23.040 --> 00:56:34.720]   Like, "Travis is ruthless. He is a ruthless hardcore competitor, and he's got that kind of
[00:56:34.720 --> 00:56:42.960]   like drive in him that he will do anything and everything to win." That just was unfortunately
[00:56:42.960 --> 00:56:49.520]   not the way to run that business. It really created a toxic culture internally.
[00:56:49.520 --> 00:56:57.600]   A lot of these business units did some really shady things to win at all costs. Travis is a
[00:56:57.600 --> 00:57:03.280]   very smart man, but he's also just like, "It's like a lot of these CEOs that you hear about that are
[00:57:03.280 --> 00:57:09.760]   just brutal. There's a lot of Fortune 500 CEOs. They get that way because they're just
[00:57:09.760 --> 00:57:12.160]   so cutthroat in that chain.
[00:57:12.160 --> 00:57:17.840]   I'll done lap. It comes to mind. They call him Chainsaw because he was the king of
[00:57:17.840 --> 00:57:22.640]   tearing up a company. By the way, this is not my nephew. I got it wrong. It's my cousin,
[00:57:22.640 --> 00:57:26.960]   Ethan Eiler, who was... He's currently... I didn't know he's still there. He had a brand
[00:57:26.960 --> 00:57:32.080]   product to lift, but back when he was the director of ride experience in lift, he invented the car
[00:57:32.080 --> 00:57:39.280]   stash, the glow stash, and amp. That is so awesome. He also developed an internal platform allowing
[00:57:39.280 --> 00:57:45.840]   for the scalable execution of in-car experiences such as Taco Mode with Taco Bell and the Mini
[00:57:45.840 --> 00:57:50.480]   Van Mode with Disney. There you go. Mike, how is it? It was so much more fun back then. Do you
[00:57:50.480 --> 00:57:55.520]   remember what it was? They used to have a puppy day. They would bring puppies to you. You could
[00:57:55.520 --> 00:58:00.400]   request an Uber or Lyft. I was filled with little puppies that were up for adoption or whatever.
[00:58:00.400 --> 00:58:03.520]   They just had a lot of fun with it, and then it just became nasty.
[00:58:03.520 --> 00:58:07.200]   I feel like this is all part of that thing you were talking about. We just took the wrong
[00:58:07.200 --> 00:58:12.560]   Loki timeline. We did. Everything was fun has now turned sour.
[00:58:12.560 --> 00:58:18.720]   I guess there's a precedent for that. I can remember I'm old enough to remember the summer
[00:58:18.720 --> 00:58:26.000]   of love in 1967, which went south in Hade, Ashbury with the advent of methamphetamine and other stuff.
[00:58:26.000 --> 00:58:35.840]   People just became ugly. I guess it's human nature. It all declines after a while.
[00:58:35.840 --> 00:58:47.920]   I don't know where to go after this. There's so many directions. I don't want to bring back
[00:58:47.920 --> 00:58:52.560]   the CSAM discussion, but we've got two parents here. We've got a Brit.
[00:58:55.600 --> 00:59:01.440]   This is one of those Apple things that at first I thought, it seems like a pretty good idea.
[00:59:01.440 --> 00:59:08.800]   I heard from a lot of people, especially experts in this perceptual hashing who said,
[00:59:08.800 --> 00:59:14.480]   "It's not such a good idea." People like the EFF who said, "Apple could be coerced by other
[00:59:14.480 --> 00:59:18.720]   governments to add this fingerprint technology for other kinds of imagery."
[00:59:20.400 --> 00:59:26.880]   Now I don't know what to think. New week, new panel, new bunch of people. Let me start with you,
[00:59:26.880 --> 00:59:31.520]   I mean, this is a very different discussion in the US than I imagine it is in the UK.
[00:59:31.520 --> 00:59:41.520]   From what I've read and people I've talked to, the arguments are broadly very similar,
[00:59:41.520 --> 00:59:45.840]   because it all boils down to two or three core things.
[00:59:45.840 --> 00:59:49.760]   Well, you have the Peppers Charter. There's Snoopers Charter in the UK.
[00:59:50.160 --> 00:59:55.600]   We've had a variety of things over the years proposed and watered down.
[00:59:55.600 --> 01:00:01.760]   What the government here, or many members of the government here want, is backdoors.
[01:00:01.760 --> 01:00:04.800]   Right. They want ways to break encryption. They want to be able to say,
[01:00:04.800 --> 01:00:12.240]   "We need to see the content of somebody's WhatsApp messages. Facebook, you need to build
[01:00:12.240 --> 01:00:17.360]   a back door so we can do that." Obviously, the company's all pushed back for very similar reasons.
[01:00:17.360 --> 01:00:22.800]   As Apple says, "This is your device. These are your messages. Keep us out of it."
[01:00:22.800 --> 01:00:31.600]   That's one side of this. I think the other side is mission creep. I haven't heard of an argument
[01:00:31.600 --> 01:00:35.520]   yet that I've, well, I can't even think I've heard of an argument of someone saying Apple
[01:00:36.480 --> 01:00:48.640]   shouldn't do anything to help prevent CSAM. The argument that people have put forward is that
[01:00:48.640 --> 01:00:54.000]   it's a slippery slope. You're opening the dam to say, "Well, you did it for this,
[01:00:54.000 --> 01:01:01.840]   so let's let this government have its influence and create another back door."
[01:01:01.840 --> 01:01:06.480]   I'm not buying that. I don't believe that would necessarily be the case.
[01:01:06.480 --> 01:01:13.440]   But the argument that I do buy is that, as we've seen with the likes of piracy,
[01:01:13.440 --> 01:01:20.720]   when a company puts in something like this as a policy or as a framework,
[01:01:20.720 --> 01:01:26.800]   it just forces the people who would be caught out by it to do something else.
[01:01:28.080 --> 01:01:32.240]   Whether that's forcing underground or just turning off iCloud photos, whatever it is,
[01:01:32.240 --> 01:01:41.760]   the solution they seek is, it doesn't necessarily create the atmosphere that the good intentions
[01:01:41.760 --> 01:01:48.160]   think that it should. It just pushes people to use something else. That's why I kind of agree that
[01:01:48.160 --> 01:01:53.840]   it's probably not the right way to do it for all the reasons that the privacy campaign is.
[01:01:53.840 --> 01:02:01.040]   We've seen dozens and dozens now of groups and of experts and people saying, "This is not the
[01:02:01.040 --> 01:02:05.440]   way to go, and this won't serve the good that you think it will."
[01:02:05.440 --> 01:02:12.480]   I've actually seen some people say that Apple's and the iPhones, Apple's devices,
[01:02:12.480 --> 01:02:17.520]   were considered a haven for CSAM because Apple was so reluctant to do any scanning.
[01:02:17.520 --> 01:02:25.360]   They only reported 256 incidents of child pornography on iCloud Drive last year when
[01:02:25.360 --> 01:02:33.040]   Facebook reported 125 million. Facebook is able to scan those
[01:02:33.040 --> 01:02:43.520]   in the cloud on its own servers. Most of these companies that do report much greater numbers
[01:02:43.520 --> 01:02:49.600]   are doing so because they are scanning every image or they are using AI to detect.
[01:02:49.600 --> 01:02:55.120]   Honestly, I wouldn't object to Apple doing that on their own servers. They have every right to
[01:02:55.120 --> 01:03:00.720]   say as a company, "We will not be hosting this kind of material." But they're not proposing to do
[01:03:00.720 --> 01:03:08.800]   that. I think what I suspect Apple is up to is that Apple wanted to end encryption on iCloud,
[01:03:09.680 --> 01:03:17.440]   precisely because the FBI and the UK demanding to access the iCloud. In fact, we know they can
[01:03:17.440 --> 01:03:24.240]   right now. They even told the San Bernardino shooter, "Oh, it's a mistake. You shouldn't
[01:03:24.240 --> 01:03:28.400]   let that phone lock. You should have just brought it back to his house." It would have uploaded to
[01:03:28.400 --> 01:03:33.280]   iCloud and then we could tell you exactly what was on that phone. Apple's never hid the fact that
[01:03:33.280 --> 01:03:37.440]   they have the keys to iCloud storage. But I think Apple's has wanted to encrypt it. I think
[01:03:37.440 --> 01:03:41.680]   it's possible that what Apple said is, "Before we do that, we better come up with a way
[01:03:41.680 --> 01:03:47.120]   to say, 'Oh, no, but we're making sure there's no child pornography on there.' The only way to do
[01:03:47.120 --> 01:03:55.680]   that is to scan on ingress. The only way to really do that is to put it on the phone, scan it before
[01:03:55.680 --> 01:04:00.640]   it's uploaded. That's in fact what they've implemented. I don't have any inside information.
[01:04:00.640 --> 01:04:03.920]   I don't know if that's what Apple was planning, but it would make sense to me that that would be
[01:04:04.480 --> 01:04:10.240]   they would do this before they would announce end-to-end encryption on iCloud. I think they
[01:04:10.240 --> 01:04:15.040]   have every right to scan iCloud. Nate, do you think the problem is that the scanning is done
[01:04:15.040 --> 01:04:21.520]   before it goes to iCloud? I think the problem is that... Well, part of the problem is that
[01:04:21.520 --> 01:04:27.920]   I don't think it's scanning in the same way that we traditionally think of scanning. When you think
[01:04:27.920 --> 01:04:34.720]   of scanning, you think of an image uploaded. Algorithms are run over it and somebody,
[01:04:34.720 --> 01:04:41.600]   well, a machine is determining the content of the image. That's not quite what's happening in this
[01:04:41.600 --> 01:04:52.560]   sense. It's more that the hashes, the fingerprints of those previously identified C-Sam material is
[01:04:52.560 --> 01:05:03.600]   on your phone. If the result of the hash matches and enough of them match, then it's flagged.
[01:05:03.600 --> 01:05:08.560]   But only on iCloud. They Apple said very specifically, if you turn out iCloud photos,
[01:05:08.560 --> 01:05:11.680]   if you do not attempt to upload this imagery, it will not be scanned.
[01:05:11.680 --> 01:05:19.360]   That's right. That's right. But I believe that just means that it's not being sent to Apple. I
[01:05:19.360 --> 01:05:24.560]   don't think it necessarily means that the potential to identify if we move from...
[01:05:24.560 --> 01:05:27.840]   They have that capability. That's right. No, they would still have the capability.
[01:05:27.840 --> 01:05:35.200]   Yes. Exactly. I think Apple made a bit of a mistake in announcing it when it did alongside the
[01:05:35.200 --> 01:05:44.880]   messages feature that I actually think is a good idea in many, many ways, which is if the
[01:05:46.080 --> 01:05:54.560]   child using a phone that is under restriction, the parental control switched on, if it looks like
[01:05:54.560 --> 01:06:00.880]   somebody is sending something that looks harmful, then it is blurred out and a parent is alerted.
[01:06:00.880 --> 01:06:07.680]   That's a very different method of scanning an identification that is using a much more,
[01:06:07.680 --> 01:06:13.120]   I don't know if it's a sophisticated system, but it's using something that is detecting a brand new
[01:06:13.120 --> 01:06:17.440]   never-before-seen images and saying, "Hey, this might be something you want to take a look at."
[01:06:17.440 --> 01:06:22.000]   It's also more prone to false positives, I think, because of the nature of what it's doing.
[01:06:22.000 --> 01:06:26.560]   Let me ask you, at least because you're the parent of a preteen,
[01:06:26.560 --> 01:06:30.560]   would you turn this on on her iPhone?
[01:06:30.560 --> 01:06:35.680]   Bold of you to assume I'm letting her have an iPhone.
[01:06:35.680 --> 01:06:38.880]   Actually, that's part of the conversation.
[01:06:40.400 --> 01:06:45.600]   That's part of the conversation because giving her an iPhone opens up a whole range of possibilities.
[01:06:45.600 --> 01:06:47.920]   You haven't done that.
[01:06:47.920 --> 01:06:55.760]   No, not yet. The advice I got from somebody who put it in very stark terms is they are like,
[01:06:55.760 --> 01:07:01.040]   "You realize the minute this kid gets an iPhone that she'll be watching porn."
[01:07:01.040 --> 01:07:06.240]   I was initially appalled by that, but what they were basically suggesting was once you give
[01:07:06.240 --> 01:07:12.320]   somebody a device that has access to the internet, you've seeded some form of control over
[01:07:12.320 --> 01:07:17.200]   what they're finding and how they find it, no matter how carefully you set up safeguards.
[01:07:17.200 --> 01:07:20.960]   There's always a way to work around them, and kids do pull this information.
[01:07:20.960 --> 01:07:26.640]   I had to be comfortable with her level of digital literacy and what kind of risk she was going to
[01:07:26.640 --> 01:07:31.040]   be exposed to. Right now, I'm not comfortable with that, so she doesn't have an iPhone.
[01:07:31.600 --> 01:07:36.400]   It strikes me that that's not Apple's job per se to protect them from that. That's your job.
[01:07:36.400 --> 01:07:40.720]   To have that conversation, you wouldn't want Apple to replace your
[01:07:40.720 --> 01:07:46.400]   parental look in local parentis.
[01:07:46.400 --> 01:07:58.800]   I'm going to repeat a variation on what I said with only a fan, which is you can take the exploitation
[01:07:58.800 --> 01:08:04.400]   or the purion content, or in this case, the CCM out of it and take a look at what
[01:08:04.400 --> 01:08:10.560]   the issue that's got everybody worked up is, which is that Apple wants to put a technology
[01:08:10.560 --> 01:08:20.720]   Apple wants on your phone, which purports to address a social problem, but also allows other
[01:08:20.720 --> 01:08:26.480]   actors a tremendously high degree of control over your networked activities.
[01:08:27.600 --> 01:08:33.920]   I do think it's notable to point out that right now it's CCM, but if it's in other countries,
[01:08:33.920 --> 01:08:40.480]   what's to stop Apple from saying, "Oh, fine, we'll flag any pro-democracy means or rhetoric
[01:08:40.480 --> 01:08:43.040]   that comes on," and you'll be able to see what users are sharing.
[01:08:43.040 --> 01:08:47.840]   But here's the question, at least from Apple's point of view, is you haven't bought an iPhone
[01:08:47.840 --> 01:08:53.440]   for your daughter yet. Would it help? Apple's asking you, would it help if we gave you this
[01:08:53.440 --> 01:09:00.240]   switch so that you would know if that stuff was being texted to her or vice versa? Would that help?
[01:09:00.240 --> 01:09:04.320]   Because that's what Apple's assuming is, "Well, this is going to make it more
[01:09:04.320 --> 01:09:08.000]   parents more comfortable with giving it on their kids." I feel like that's a technological solution
[01:09:08.000 --> 01:09:14.800]   to what's actually a social problem. I agree. The same way if you take a look at CCM, a tremendous
[01:09:14.800 --> 01:09:19.440]   amount of the exploitation happens with people that are in the children's social circle, either
[01:09:19.440 --> 01:09:26.400]   families or the wider community. There's no amount of technology that can go up against
[01:09:26.400 --> 01:09:33.040]   those really fraught and complicated familial and social situations. We've seen how it plays out
[01:09:33.040 --> 01:09:40.720]   when children who were abused by trusted community organizations, when they come forward,
[01:09:40.720 --> 01:09:46.560]   we've seen how it's just-- It's horrible. It's horrible. Exactly. There's no technology that's
[01:09:46.560 --> 01:09:55.200]   going to address the person-to-person in real-time meets-based social interaction.
[01:09:55.200 --> 01:10:00.800]   I could see where if Apple was saying what we're trying to do is we're just trying to prevent
[01:10:00.800 --> 01:10:08.160]   spreading this content and perpetually revictimizing somebody, but they kind of overreached a little
[01:10:08.160 --> 01:10:14.720]   bit in the pitch. They're not doing a darn thing to address concerns like, "How are you handling
[01:10:14.720 --> 01:10:19.120]   false positives? How would you be handling malicious attacks if somebody is trying to frame somebody
[01:10:19.120 --> 01:10:25.200]   else digitally? What reassurances do we have that this type of technology can't be used to
[01:10:25.200 --> 01:10:30.560]   restrict any type of content your customers demand?" None of those questions have been answered.
[01:10:30.560 --> 01:10:34.080]   Kevin, you don't have to worry about this for some years.
[01:10:34.080 --> 01:10:39.600]   Got a few years. Believe me, it goes faster than you think.
[01:10:44.160 --> 01:10:48.640]   10 years from now, your kids want a smartphone. Would it be reassuring to know this technology's
[01:10:48.640 --> 01:10:55.360]   built into an iPhone? Yeah, I think so. I would like to be sent that in terms of allowing me to
[01:10:55.360 --> 01:11:00.080]   have a conversation. You don't have to turn that on, by the way. Parent does not have to turn that
[01:11:00.080 --> 01:11:05.520]   on. That's up to the parent. Yeah, I would like to have to be notified so that we can just talk
[01:11:05.520 --> 01:11:12.720]   about it. I want to be one of those open and parents where no topic is off limits. Hopefully,
[01:11:13.280 --> 01:11:15.440]   that would just be something we could have a conversation around.
[01:11:15.440 --> 01:11:20.480]   It's my suspicion that the same kind of perceptual hashing they're looking for
[01:11:20.480 --> 01:11:26.160]   nudity and inbound and outbound text messages could easily be applied to websites. Of course,
[01:11:26.160 --> 01:11:30.480]   it could. Any image is coming into the phone. Well, a lot of routers do that today, right?
[01:11:30.480 --> 01:11:34.640]   Right. They have child protections and they can do it by you if they're going to certain sites and
[01:11:34.640 --> 01:11:39.120]   things of that nature. Historically, tools that look for nudity have been very
[01:11:40.560 --> 01:11:44.880]   have a huge false positive problem. They're not very good and false negative, frankly,
[01:11:44.880 --> 01:11:48.800]   problem. They're not very good at this. But let's say Apple comes up with a good
[01:11:48.800 --> 01:11:56.320]   form of perceptual hashing that can find sexual images. And Lisa, that might solve your
[01:11:56.320 --> 01:12:01.520]   qualms, right? Because it would then do the same thing with an inbound pornographic image in the web.
[01:12:01.520 --> 01:12:04.640]   Would that be a good thing? Would you turn that on?
[01:12:08.160 --> 01:12:12.320]   I don't know. I'd have to see how it works. It's challenging, isn't it?
[01:12:12.320 --> 01:12:20.800]   Well, again, I'm innately skeptical of technical solutions that are treating social interactions
[01:12:20.800 --> 01:12:25.360]   like a series of data exchanges. Because on one level, yes, when you converse in somebody,
[01:12:25.360 --> 01:12:31.840]   you are exchanging data. When you text somebody, you're exchanging data. But there's always a cloud
[01:12:31.840 --> 01:12:40.080]   of emotional and social and cultural expectations around those things. And that's where, as a parent,
[01:12:40.080 --> 01:12:43.840]   you really do have to do the work. It'd be nice if the tech tool helps you do the work. But I don't
[01:12:43.840 --> 01:12:50.080]   think that substitutes for being present and being hands on and taking case by case.
[01:12:50.080 --> 01:12:56.080]   Actually, it's funny because Nate, I kind of am the opposite of you. I don't mind scanning
[01:12:56.080 --> 01:13:00.400]   for stuff on iCloud. Apple has every right to say, "We don't want any child porn on
[01:13:00.400 --> 01:13:06.240]   pornography on iCloud." I don't like the on-phone scanning. And you're kind of the other way around.
[01:13:06.240 --> 01:13:22.400]   Am I? I'm not... I'm not... I'm not in favor of implementing a system that is...
[01:13:24.720 --> 01:13:34.560]   Basically, it largely, I don't know if I say punishes, it assumes wrongdoing on people who are
[01:13:34.560 --> 01:13:40.240]   behaving themselves. And for all the people who aren't, they'll just remove themselves from
[01:13:40.240 --> 01:13:47.840]   being subject to it in the first place. That's... I'm in favor of... If you're putting something
[01:13:47.840 --> 01:13:53.920]   in the cloud, if you're uploading something, you're sharing something, I'm in favor of that being
[01:13:53.920 --> 01:13:59.120]   cold. 100%. But you're not sharing it, though, really. You're just backing it up, though, right?
[01:13:59.120 --> 01:14:04.720]   That's right. You're putting it on Apple's cloud, but you're not necessarily giving it to anybody.
[01:14:04.720 --> 01:14:08.720]   You're just putting it on their cloud. But I think it's Apple's right to say, "Hey, we don't
[01:14:08.720 --> 01:14:13.760]   want that stuff on our cloud, and we're going to scan everything you try to upload." I think
[01:14:13.760 --> 01:14:17.280]   it's also interesting that they chose to do that on device. And I think they did that for
[01:14:17.280 --> 01:14:22.160]   some technical reasons, including perhaps their desire to go into an encryption on iCloud.
[01:14:22.160 --> 01:14:26.960]   Well, I think honestly what they should do is they should come in and say, "Listen, we're going to..."
[01:14:26.960 --> 01:14:31.440]   I know there's a lot of devil in the details here, and this is just a hardcore approach.
[01:14:31.440 --> 01:14:35.920]   But you could say, "Okay, we do want to address child pornography. We're going to scan everything
[01:14:35.920 --> 01:14:40.640]   that is uploaded in the cloud." That means that they have the private keys because they can go in
[01:14:40.640 --> 01:14:45.600]   there and look through your files. I know they're doing hash comparisons, but they're still looking
[01:14:45.600 --> 01:14:50.160]   and seeing the different files and files. They chose not to do that, though, right? That's the point.
[01:14:50.160 --> 01:14:54.480]   No, but what I'm saying is if they decide to do it globally, then you can say, "Listen,
[01:14:54.480 --> 01:14:59.760]   I'm someone that actually cares more about the privacy of my photos. Scan it on device all you
[01:14:59.760 --> 01:15:04.560]   want. Look for the child porn on device, but encrypt everything in the cloud so that no one has access
[01:15:04.560 --> 01:15:07.120]   to it in the cloud." I think that's what they're going to do. That's my production.
[01:15:07.120 --> 01:15:12.560]   Well, do both, right? That way you can say, "I don't want the on-device scanning just to the cloud
[01:15:12.560 --> 01:15:17.760]   scanning." But if I do want everything encrypt in the cloud, which I am a fan of that, I have photos
[01:15:17.760 --> 01:15:22.320]   of me and my wife like a during childbirth. No, I should have access to that.
[01:15:22.320 --> 01:15:26.480]   Yeah. Right. So they encrypt all that and look for child porn fine. I'm fine with that.
[01:15:26.480 --> 01:15:31.840]   But I want that cloud all encrypted so that no one, not even Apple engineers, could see it.
[01:15:31.840 --> 01:15:35.920]   That's how it should be. Now, I should point out Dropbox, Facebook, everybody who has cloud
[01:15:35.920 --> 01:15:41.840]   storage, Google does, in fact, use this NECMEC image database and does the fingerprint scanning
[01:15:41.840 --> 01:15:46.800]   because they also don't want to have this image re-on their storage. Google even does it to Gmail
[01:15:46.800 --> 01:15:51.280]   attachments. And I've been doing it for a long time and it hasn't raised any
[01:15:51.280 --> 01:15:59.840]   hackles. Go ahead, Nate. You said you agree. Yeah, I agree 100%. I just think that there is no
[01:15:59.840 --> 01:16:07.520]   perfect way to do this and of all the technological ways that I can think of that I know about that
[01:16:07.520 --> 01:16:14.880]   I've heard of, of doing this in a way that keeps privacy as secure as possible, this is probably the
[01:16:14.880 --> 01:16:22.080]   best way. Because it is, it is a hash, it is, it's not scanning a photo and saying we think this might be
[01:16:22.080 --> 01:16:29.360]   objectionable illegal content. Let's upload it and check it saying here is a list of hashes we
[01:16:29.360 --> 01:16:34.000]   know is problematic. And if we see enough of them on this device, we will flag it. They say, by the
[01:16:34.000 --> 01:16:38.560]   way, then we may throw it. They say now it's a threshold is 30, roughly 30 images.
[01:16:39.200 --> 01:16:45.600]   Yeah, which gets around that, you know, false positive problem. False positives. Yeah. And
[01:16:45.600 --> 01:16:51.920]   somebody, some idiot on on a forum, uploading something and it's something like that. So I agree.
[01:16:51.920 --> 01:16:55.520]   I think this is the best way. And I too, like Kevin, you were saying, like having everything
[01:16:55.520 --> 01:16:59.760]   encrypted in the cloud, it's that is incredibly important. And it's the reason why I trust Apple
[01:16:59.760 --> 01:17:03.200]   with all of my, you know, with all of my stuff. It's not though, because I trust it more than the
[01:17:03.200 --> 01:17:08.000]   other. It is not yet. And I think this is the first, I'm surprised Apple didn't announce end to end
[01:17:08.000 --> 01:17:12.240]   encryption at the same time. There's maybe political reasons they didn't. But they go, that seems to
[01:17:12.240 --> 01:17:16.640]   me they go hand in hand. All right, look, now we can have an encryption on iCloud, because we're
[01:17:16.640 --> 01:17:22.880]   scanning on the way in. I just see, I don't see this as such a, I mean, this is a database of known
[01:17:22.880 --> 01:17:28.560]   offensive child pornography. Like I could, I could go and in theory, take my iPhone when this is
[01:17:28.560 --> 01:17:33.840]   enabled. And I could take 500 pictures of my wife. And this is a horrible example. But you know what
[01:17:33.840 --> 01:17:39.120]   I'm saying? Anything that's personal to you? Yes. I'm not going to do that. But they could be
[01:17:39.120 --> 01:17:44.400]   anything. No, me on the john something, where I go, it would be the hot tub, it would never be
[01:17:44.400 --> 01:17:49.760]   flagged. It would never be flagged because it's not a known offensive image that is child pornography.
[01:17:49.760 --> 01:17:56.400]   So I don't know, I'm fine with it. Yeah. All right. I didn't want to bring up that whole subject again.
[01:17:56.400 --> 01:18:02.160]   But I, it's, I like to get the varying points of view because it's, it's going to be a conversation
[01:18:02.160 --> 01:18:05.520]   that's going to be going on for some time. We'll take a little break, come back with lots more.
[01:18:05.520 --> 01:18:13.680]   Kevin Rose is here his new podcast, modern finance at very cleverly modern dot finance.
[01:18:13.680 --> 01:18:18.800]   And it's a, it's a good list. And I, it's the only thing that's explained NFTs to me
[01:18:18.800 --> 01:18:22.640]   satisfactorily or crypto or any of that stuff. Thank you for doing that, Kevin.
[01:18:22.640 --> 01:18:26.080]   And it looks like you have fun doing it, I must say. Oh, I'm loving it. Yeah. Absolutely. It's a
[01:18:26.080 --> 01:18:31.680]   fun space. It's rapidly exciting. Yeah. Yeah. Yeah. Lisa Schmeiser is also here.
[01:18:31.680 --> 01:18:35.360]   She is in the fun space of senior editor at IT Pro today.
[01:18:35.360 --> 01:18:38.720]   At least fun for you. I don't know. But
[01:18:38.720 --> 01:18:45.120]   I've made this argument before. The fun thing about reporting on IT and IT infrastructure is you
[01:18:45.120 --> 01:18:50.080]   sort of get the first draft of how work and the economy are changing because of the tools that
[01:18:50.080 --> 01:18:54.720]   people use or change. No, that's true. That's, that's a good point. Yeah. And Nate Langston,
[01:18:54.720 --> 01:18:59.680]   he covers technology at Bloomberg. He's their tech editor also hosts his own podcast,
[01:19:00.240 --> 01:19:07.680]   UK Tech Show dot com. And that's true. I bet you, you're so sick of talking about Apple C, Sam,
[01:19:07.680 --> 01:19:13.920]   you could just. Well, actually, to be honest, we talk about it quite very little because it's
[01:19:13.920 --> 01:19:19.840]   currently only applicable to the US. So yeah, for us, we've, we've not got into it in a great,
[01:19:19.840 --> 01:19:24.080]   in a great detail. I just, I look at it from afar and think, well, it's the,
[01:19:24.080 --> 01:19:29.120]   yeah, not to resurrect the conversation, but it's, it's the best way of doing it now. But I
[01:19:29.120 --> 01:19:33.760]   totally get why a lot of people are nervous about what it could lead to. But right now it's,
[01:19:33.760 --> 01:19:35.520]   it doesn't affect anyone outside the US.
[01:19:35.520 --> 01:19:45.840]   Text message at UK Tech show dot com. Our show today brought to you by worldwide technology
[01:19:45.840 --> 01:19:53.040]   and Dell Technologies. WWT is the place to go. If you are ready to upgrade your infrastructure,
[01:19:53.040 --> 01:19:58.000]   if you're an enterprise, you want to improve security, you're looking at multi home cloud
[01:19:58.000 --> 01:20:04.320]   architectures, dev ops or agile. They're at the forefront of innovation. But what I love about
[01:20:04.320 --> 01:20:11.440]   WWT is that they know business. So everything they recommend, every system they install,
[01:20:11.440 --> 01:20:15.920]   everything that they do for you, they do, while looking at your business strategy,
[01:20:15.920 --> 01:20:20.640]   your business goals, there's no point in adopting technology. If it doesn't support what you're
[01:20:20.640 --> 01:20:26.160]   all about and WWT is great at doing that working with clients all over the world to transform their
[01:20:26.160 --> 01:20:31.600]   businesses. It all starts with the Advanced Technology Center. This is an amazing research and testing
[01:20:31.600 --> 01:20:37.040]   lab. WWT started building about a decade ago. It's now got more than half a billion dollars
[01:20:37.040 --> 01:20:44.080]   in equipment from all the leading OEMs and the little fast moving disruptors as well.
[01:20:44.080 --> 01:20:49.840]   And what's beautiful about the ATC, you know, the engineers at WWT use it to spin up proofs of
[01:20:49.840 --> 01:20:55.120]   concepts and pilots that can test integration. They can make sure that the customer's existing
[01:20:55.120 --> 01:20:59.680]   infrastructure will support their new changes, that kind of thing. They help their customers
[01:20:59.680 --> 01:21:05.200]   confidently select the best solutions. It's great for them. It cuts their valuation time from months
[01:21:05.200 --> 01:21:11.840]   to weeks. But now it started last summer. The ATC also offers hundreds of on demand and
[01:21:11.840 --> 01:21:17.360]   scheduleable labs to you. You don't even have to go to St. Louis. It's virtualized. So if you're a
[01:21:17.360 --> 01:21:22.720]   member of the ATC platform, you can access everything the labs have to offer anywhere in the world
[01:21:22.720 --> 01:21:29.040]   365 days a year. Things like Dell's VX Rail or CyberRecover Solutions, PowerStore, Unity,
[01:21:29.040 --> 01:21:37.120]   PowerMax, Data Protection Central and IDPA. These are the newest and latest advances in primary
[01:21:37.120 --> 01:21:42.160]   storage. And you can literally try them out ahead of time. You can learn about them. The labs don't
[01:21:42.160 --> 01:21:48.480]   just have these, you know, hands-on labs. There's ATC as technical articles, expert insights,
[01:21:48.480 --> 01:21:52.400]   demonstration videos, white papers, all the tools you need to stay up with the latest
[01:21:52.400 --> 01:21:58.640]   technology. And not just in primary storage, other labs in the ATC represent the newest advances
[01:21:58.640 --> 01:22:03.680]   in multi-cloud architecture and security and networking, primary and secondary storage,
[01:22:03.680 --> 01:22:09.520]   data analytics, AI, DevOps, so much more. When we were out at the labs last year,
[01:22:09.520 --> 01:22:17.120]   Lisa and I took a tour of the ATC. It was so cool. And they have, I said, what's that cage over in
[01:22:17.120 --> 01:22:22.960]   the corner with one little wire coming off of it? They said, that's our malware research center.
[01:22:22.960 --> 01:22:29.520]   That is, that is physically separated from the rest of the lab because that's where we study
[01:22:29.520 --> 01:22:35.360]   security and ransomware and things like that. It's really, really neat. And I want you to get
[01:22:35.360 --> 01:22:44.320]   access to it. And good news, it's free. You can, you can join the ATC platform and learn more about
[01:22:44.320 --> 01:22:50.640]   WWT gain access to all their free resources by going to WWT.com/twit.
[01:22:50.640 --> 01:22:56.640]   And more than just the ATC platform, check out WWT's events and communities. There's lots of places
[01:22:56.640 --> 01:23:00.960]   to learn about technology trends to hear about the latest research and insights from their experts
[01:23:00.960 --> 01:23:07.360]   to compare notes with other CEOs, CTOs, CSOs really kind of get a sense of what's going on in the
[01:23:07.360 --> 01:23:13.920]   world. You need this in your business. And WWT's got it. Whatever your business, they can deliver
[01:23:13.920 --> 01:23:21.200]   scalable, tried and tested tailored solutions just for you. WWT brings strategy and execution
[01:23:21.200 --> 01:23:25.520]   together to make a new world happen. Learn more about the ATC worldwide technology,
[01:23:25.520 --> 01:23:31.360]   taking access to all the free resources. Again, WWT.com/twit, create that free count
[01:23:31.360 --> 01:23:38.720]   on the ATC platform. Do me a favor, please. Use that URL, WWT.com/twit so they know you
[01:23:39.680 --> 01:23:47.360]   heard about it here on wwwt.com/twit on the Twit Pawngosh network.
[01:23:47.360 --> 01:23:54.240]   Wow, Dark Tipper, who would ever thought this cloud flare says it mitigated the largest
[01:23:54.240 --> 01:24:05.920]   DDoS attack ever, 17.2 million requests per second. Unbelievable hammering a customer in
[01:24:05.920 --> 01:24:13.200]   the financial sector. I'm reading the article from the record.media Caitlin Kintland.
[01:24:13.200 --> 01:24:20.720]   Caitlin or Kitalin, I think, says from this tweet from Bitmex, they think it might have been
[01:24:20.720 --> 01:24:28.800]   Bitmex. Bitmex tweeted on August 22nd. That's, I guess, this morning. We are currently under DDoS
[01:24:28.800 --> 01:24:34.000]   and are working to mitigate. Requests reach 7 million a minute at our edge and declining.
[01:24:34.800 --> 01:24:43.920]   The cloud flare says the attack peaked at 17.2 million HTTP requests a second. This is a
[01:24:43.920 --> 01:24:52.000]   volume, what they call a volumetric DDoS. Instead of jamming the bandwidth, they're trying to
[01:24:52.000 --> 01:24:58.880]   bring down the servers by sending junk HTTP requests to the victim's server in RAM.
[01:25:01.520 --> 01:25:10.160]   By the way, how do they do it? A botnet, 20,000 devices infected with a Mariah modified version
[01:25:10.160 --> 01:25:15.760]   of Mariah, which has been around for a couple of years. Now, that's the IoT malware, the router
[01:25:15.760 --> 01:25:21.360]   malware, the FBI was telling everybody, reboot your router. You might have Mariah on it.
[01:25:22.240 --> 01:25:32.000]   I guess we didn't eliminate Mariah. It was found in 2016. It attacks a variety of IoT devices,
[01:25:32.000 --> 01:25:37.440]   including cameras, but I think it's routers that are the most useful for these kinds of attacks.
[01:25:37.440 --> 01:25:44.240]   They just basically get on your router and start sending out HTTP requests. They're on
[01:25:45.280 --> 01:25:55.280]   IRC channel, a botnet channel. 17.2 million requests per second. That's 2.3 terabytes.
[01:25:55.280 --> 01:26:00.480]   Oh, no, I'm sorry. That's another one. That's a different one. That's a more traditional DDoS attack.
[01:26:00.480 --> 01:26:05.920]   Anything to say about that, Kevin? Except wow. I just love cloud flare. They're great.
[01:26:05.920 --> 01:26:10.400]   They're great. It's so awesome. They protect so many sites on the internet from this kind of stuff.
[01:26:10.960 --> 01:26:15.920]   I don't normally come in like cloud flare or there are lots of companies that offer this kind of
[01:26:15.920 --> 01:26:20.320]   mitigation. Just throw bandwidth at the problem. That wouldn't have solved this. In fact, it would
[01:26:20.320 --> 01:26:24.480]   have made it worse to throw more bandwidth at it because the attacks are going to the server and
[01:26:24.480 --> 01:26:28.240]   trying to bring down the servers. I guess you have to throw hardware at it. I don't know how you mitigate
[01:26:28.240 --> 01:26:37.440]   this. It's past my pay grade. I tell the story all the time about when you were starting Dig,
[01:26:37.440 --> 01:26:43.360]   how excited you were when you got a new server to put in the colo and you had to go over to the
[01:26:43.360 --> 01:26:47.840]   colo and install the server and put this on. Yeah, back in my day, back in the day, rack your own
[01:26:47.840 --> 01:26:54.000]   hardware before there was cloud flare before there was VPSs or any of this stuff. Cloud nothing.
[01:26:54.000 --> 01:27:04.960]   Yeah, there's nothing. Do you miss those dig days? It's a ton of fun. I don't miss them. They were
[01:27:04.960 --> 01:27:10.240]   insanely stressful. I think anytime you have to manage that many community people coming together
[01:27:10.240 --> 01:27:15.920]   to fight about articles and comments and spam and all that stuff, I'm just like, let
[01:27:15.920 --> 01:27:21.360]   Reddit have all that problem. I don't want to deal with it. It was a lot.
[01:27:21.360 --> 01:27:29.520]   You don't want to run a business these days. It's between the pandemic and it's just really
[01:27:30.320 --> 01:27:35.840]   for instance, Wall Street Journal had a story this week saying, if companies are starting to send
[01:27:35.840 --> 01:27:39.760]   people back home, Apple said, no, we thought people were going to come back next month.
[01:27:39.760 --> 01:27:46.320]   It's going to be next year. Sometimes CEOs are now worried that if this goes on too long,
[01:27:46.320 --> 01:27:54.160]   they'll never get employees back in the office. It's crazy. It's funny. Well, it's not funny,
[01:27:54.160 --> 01:27:59.760]   but during the pandemic, I didn't really know that many people that actually got COVID a few,
[01:27:59.760 --> 01:28:04.480]   but not a ton. I know a ton that have it now. They're fully vaccinated.
[01:28:04.480 --> 01:28:09.600]   And they're sick. They're not hospital sick, but they got hit pretty hard.
[01:28:09.600 --> 01:28:16.240]   My son got his first shot. Henry is a part of here, I guess. And then it was the alpha
[01:28:16.240 --> 01:28:21.040]   variant. Some kids came out from Michigan and he got after his first shot one week later,
[01:28:21.040 --> 01:28:24.160]   or maybe it was one week before his second shot. He got the alpha variant.
[01:28:24.160 --> 01:28:28.240]   But apparently he's not going to help him against the delta variant.
[01:28:28.720 --> 01:28:36.560]   So Apple is saying probably January at least, but I think it's going to be maybe even longer.
[01:28:36.560 --> 01:28:42.240]   They don't currently plan to close stores, although they've stepped up testing in Apple retail
[01:28:42.240 --> 01:28:48.880]   to twice a week. They're not requiring vaccines, which is a little surprising to me.
[01:28:48.880 --> 01:28:56.080]   Maybe a company that's that big feels like they can't tell everybody to get a vaccine.
[01:28:56.080 --> 01:29:01.760]   They're strongly encouraging vaccination, but you can as an option get tested twice a week instead.
[01:29:01.760 --> 01:29:07.200]   Well, IBM just closed its New York office of New York City offices for the same reason.
[01:29:07.200 --> 01:29:17.040]   Amid amid the COVID case rising. Apple closed its retail store this week in South Carolina,
[01:29:17.040 --> 01:29:21.760]   Charleston, South Carolina. 20 employees either tested positive four or were exposed to COVID-19.
[01:29:23.200 --> 01:29:28.320]   They also are reducing operating hours at some locations, partly because employees are missing
[01:29:28.320 --> 01:29:33.360]   work because of the virus. But also, I think a lot of companies are having a hard time finding
[01:29:33.360 --> 01:29:38.640]   employees. This is to me, this is one of the most fascinating things about the pandemic,
[01:29:38.640 --> 01:29:45.360]   is how it accelerated some changes like streaming video, you know, door to ash.
[01:29:45.360 --> 01:29:51.040]   And then and then it changed is changing the workplace. I suspect that do you cover this at all
[01:29:51.040 --> 01:29:59.360]   in ITPro? Oh, yes, we've been covering this since California stay at home order in March 2020.
[01:29:59.360 --> 01:30:02.640]   I think, you know, we have employees who don't want to come back.
[01:30:02.640 --> 01:30:08.640]   Well, there's been a phenomenal growth in cloud-based services, precisely for this reason.
[01:30:08.640 --> 01:30:15.440]   You know, since you do have ITPro's who instead of being able to just go to somebody's desk and
[01:30:15.440 --> 01:30:20.800]   ask them to turn the machine on and off, they're put in the challenging position of having
[01:30:20.800 --> 01:30:26.560]   to do a lot of remote troubleshooting and business is still going on as usual. So it's made sense to
[01:30:26.560 --> 01:30:33.600]   accelerate a migration to all sorts of services in the cloud from platform as a service to desktop
[01:30:33.600 --> 01:30:39.440]   as a service to, you know, line of business applications and things like that. Just because
[01:30:39.440 --> 01:30:44.160]   it's allowed for some semblance of business continuity, it's helped out overworked IT support
[01:30:44.160 --> 01:30:51.600]   people. And it's in some cases even helped keep costs down or on board new people more gracefully.
[01:30:51.600 --> 01:30:58.720]   So what's going on in the UK, Nate? Are companies going back to work or people reopening and
[01:30:58.720 --> 01:31:03.840]   returning to an oil? Yeah, I mean, so I tend to go into our office a couple of days a week
[01:31:03.840 --> 01:31:09.600]   at the moment at Bloomberg. We've got a big, a big office in London. There's like sort of three
[01:31:09.600 --> 01:31:14.560]   or four thousand others at the Bloomberg office in London. Yeah, it's the biggest outside of
[01:31:14.560 --> 01:31:24.640]   outside of New York. And so, you know, we have onsite testing and so on. And I was in there the
[01:31:24.640 --> 01:31:29.920]   other day, well, Thursday, Friday, this week just gone by. And when you walk around outside,
[01:31:29.920 --> 01:31:36.240]   it's kind of like there's no pandemic happening. Everything's open, streets are full, everything's
[01:31:36.240 --> 01:31:45.360]   just as it feels like it used to be pre pandemic. However, numbers are going up and companies
[01:31:45.360 --> 01:31:51.760]   seem to be sitting on the fence like they hadn't a lot of companies hadn't ordered their employees
[01:31:51.760 --> 01:31:56.720]   back. But we were here in rumors that a lot were strongly encouraging it. And I think at the moment,
[01:31:56.720 --> 01:32:02.960]   it's more like, let's just see how this goes. You know, we're not being told to come back.
[01:32:04.080 --> 01:32:10.160]   We know that the expect or the hope was that but from September, people would maybe be in sort of
[01:32:10.160 --> 01:32:16.320]   three days a week. But there's been no update on that. And I don't think the pressure is going to
[01:32:16.320 --> 01:32:22.320]   be there to be back in the office anytime soon. It's interesting that the journal thinks that
[01:32:22.320 --> 01:32:28.720]   it's going to be hard to get people to come back. We have had one employee has decided not to come
[01:32:28.720 --> 01:32:34.640]   back of ours. Doesn't want to work. You know, it's like, well, because we reopened the office,
[01:32:34.640 --> 01:32:39.440]   then the mask mandate came back. So now people wearing masks. But we one of our employees say
[01:32:39.440 --> 01:32:45.760]   they don't, I don't want to work in the office. I liked working at home. And I, you know, maybe
[01:32:45.760 --> 01:32:49.520]   we're making a mistake, but I think we want people to come back into the office. We kind of like
[01:32:49.520 --> 01:32:55.680]   having everybody, you know, we used to, we had, we would have Wednesday lunch. Everybody comes
[01:32:55.680 --> 01:32:59.680]   and we have lunch. We did it twice. And now we can't do it anymore. So,
[01:32:59.680 --> 01:33:05.360]   so, you know, I really great period. There was a really great piece in the Atlantic this past week
[01:33:05.360 --> 01:33:11.840]   talking about, they called it the remote work slash fertility connection. Well, it's a little
[01:33:11.840 --> 01:33:16.640]   and wait a minute. I don't know. It's a little bit clickbaity. But the premise of the piece was
[01:33:16.640 --> 01:33:23.680]   that people who work remotely often have a lot more flexibility and control over their time
[01:33:23.680 --> 01:33:28.640]   than people who go into an office do. And when you have more control over your time,
[01:33:28.640 --> 01:33:34.240]   you will make different family planning choices than you would if you have the kind of job where
[01:33:34.240 --> 01:33:38.960]   you're, where you're either your hours are unpredictable or your commute is grueling or what
[01:33:38.960 --> 01:33:45.200]   have you. And I would not be surprised if a lot of the resistance that that some workers are having
[01:33:45.200 --> 01:33:49.440]   to going back into the office to do the same work they can do at home while they can also get
[01:33:49.440 --> 01:33:53.760]   laundry going and meal prep per week and things like that. A lot of it is them saying,
[01:33:53.760 --> 01:34:00.480]   what is this going to add to my quality of life if I have to stay away from this house and I have
[01:34:00.480 --> 01:34:06.720]   a commute and things like that. And I would be interested to see how many employers start
[01:34:06.720 --> 01:34:13.440]   trying to draw a line or trying to make the pitch that in order to keep talent, they'd have to say,
[01:34:13.440 --> 01:34:17.840]   okay, you're not going to take a significant quality of life hit if you come back because
[01:34:17.840 --> 01:34:20.800]   you'll still have these great quality of life things happening in the office.
[01:34:20.800 --> 01:34:25.600]   I mean, I'm not saying all employers will do that far from it, but I think that this is something
[01:34:25.600 --> 01:34:31.600]   employers have to reckon with is you have a lot of people who are like, sure homeschooling,
[01:34:31.600 --> 01:34:36.320]   my kids was a nightmare, but I kind of like being able to work late at night once they go to bed,
[01:34:36.320 --> 01:34:46.720]   or I like being able to eat a good lunch every day instead of some terrible deli sandwich.
[01:34:46.720 --> 01:34:53.600]   The notion of all coming to work in an office really kind of an industrial age mistake,
[01:34:53.600 --> 01:34:59.520]   a dystopia kind of where everybody's sitting in rows upon rows of desks kind of like out of a
[01:34:59.520 --> 01:35:04.080]   sci-fi movie and you know, what they're adding machines. I don't know. I don't think so.
[01:35:04.080 --> 01:35:09.040]   I've worked at Home Remote Leaf for years, but I have to be honest, I love going to Texas,
[01:35:09.040 --> 01:35:12.000]   precisely because like I'm in a newsroom with a lot of other publications. I feel like we want
[01:35:12.000 --> 01:35:16.480]   other publications. I love that buzzy energy and I love the productivity.
[01:35:16.480 --> 01:35:21.600]   We kind of want to both ways. Don't we? Yeah. I think I think workers maybe just want a little
[01:35:21.600 --> 01:35:27.200]   bit more control over how they do their work and how they deliver it. And it would not be as
[01:35:27.200 --> 01:35:35.760]   curious to me. I swear, I tell you. It's almost like they think training expertise and time for
[01:35:35.760 --> 01:35:40.560]   wages gives them a say. How dare they? Nate, what were you going to say? I'm sorry, I cut you off.
[01:35:41.440 --> 01:35:44.320]   I don't know. I don't think it was as interesting as what Lisa was saying.
[01:35:44.320 --> 01:35:54.400]   I've already forgotten it. I remember what it was. Everyone's circumstances different.
[01:35:54.400 --> 01:35:59.200]   We don't have kids. I'm the loud one in this house. My wife's the one has to deal with me.
[01:35:59.200 --> 01:36:05.200]   You're the baby. I mean, yeah. Children. I'm a lot older than her, but I'm the loud one.
[01:36:06.000 --> 01:36:12.160]   But what I was going to say is that most of my work and hobbies, during the pandemic, has been in
[01:36:12.160 --> 01:36:19.920]   this studio, this office. It's basically work is this way and then fun is that way. And I don't
[01:36:19.920 --> 01:36:23.280]   know if you can tell. I mean, you can't really tell because it's half past midnight nearly here,
[01:36:23.280 --> 01:36:28.880]   but this window is blocked up. So when my door is shut and I'm in here, there's basically no
[01:36:28.880 --> 01:36:33.120]   discernible difference between day and night. There's no natural light. And I was working in here
[01:36:33.120 --> 01:36:38.400]   a lot. And then I was turning around and having a lot of fun behind me. And it really took its
[01:36:38.400 --> 01:36:44.320]   toll like mental health wise. I didn't pay enough attention to the lack of diversity and just how
[01:36:44.320 --> 01:36:49.440]   I was spending my day, even though I was keeping track of hours and switching off at the right
[01:36:49.440 --> 01:36:54.560]   times, just the very fact of not moving around and interacting with different environments.
[01:36:54.560 --> 01:37:00.560]   It took its toll. And so going back to the office has made a massive difference for me,
[01:37:00.560 --> 01:37:04.720]   just in terms of breaking up the day, breaking up the week, partly reminding me that I'm still
[01:37:04.720 --> 01:37:11.440]   a professional journalist and I'm not just a guy at home and pretends to write about business and
[01:37:11.440 --> 01:37:18.640]   finance all day, but is actually just playing at it. It's been a noticeable benefit for me.
[01:37:18.640 --> 01:37:25.280]   Everybody is different. I would never say this is going to be the same for people who have kids
[01:37:25.280 --> 01:37:31.760]   or who are dealing with various other lifestyle situations. But for me, the main benefit has been
[01:37:31.760 --> 01:37:37.120]   from a mental health standpoint. And I don't know how much that's been talked about in terms of a
[01:37:37.120 --> 01:37:41.280]   reason to go back to an office. But for me, it's been a big reason to keep going back.
[01:37:41.280 --> 01:37:46.640]   The chat room says you have a mullet office. It's business and front party in the back.
[01:37:46.640 --> 01:37:55.200]   Oh, here. Oh, yeah. Not your hair, your office. For people who aren't watching the video,
[01:37:55.200 --> 01:38:00.800]   Nate has quite an elaborate drum kit behind him. And you know, I think there's a good argument
[01:38:00.800 --> 01:38:04.240]   that if you do have to work, you should have something you can bang on every once in a while,
[01:38:04.240 --> 01:38:08.720]   just to get the frustrations out. That seems like... Oh, trust me. Yeah. When you get scooped at
[01:38:08.720 --> 01:38:14.960]   11 p.m. and nothing's better than playing. We'll go up some of the drums. Kevin, do you see people
[01:38:14.960 --> 01:38:21.280]   ever or do you ever leave the house? Do you have an office to go to? I just work from home.
[01:38:21.280 --> 01:38:26.720]   You know, we do, at True Ventures, we do get together and we try to do these like quarterly
[01:38:26.720 --> 01:38:31.840]   off sites. And so for us, it's just, you know, getting rapid tested 24 hours before and then
[01:38:31.840 --> 01:38:37.600]   all getting together in the same space and doing our thing and then just everyone going back to
[01:38:37.600 --> 01:38:41.680]   their house for the next few months. You always struck me as not an introvert, but as a fairly
[01:38:41.680 --> 01:38:48.160]   social... You like people. Is it hard for you and Dariot to be at home and just... I like the
[01:38:48.160 --> 01:38:54.960]   computer better. Yeah. Me too. I have no problem just being on a computer and just geeking out
[01:38:54.960 --> 01:39:00.240]   over something. So it doesn't... You know, it is tough though because here in Portland, you know,
[01:39:00.240 --> 01:39:07.120]   we get during the wintertime just nonstop rain and combine that with like not seeing humans.
[01:39:07.120 --> 01:39:13.280]   It's just like you have to do something. You have to plan a trip somewhere else, you know. Dear Dari,
[01:39:13.280 --> 01:39:19.280]   another day of rain. I have a lot of folks in the Pacific Northwest who go to Hawaii in the
[01:39:19.280 --> 01:39:24.480]   middle of the weekend. Yeah, that's a big thing. We do Cabo and that's awesome. Sounds nice. Yeah.
[01:39:24.480 --> 01:39:33.280]   Yeah. And, Eliza, you go into an office, right? No, we actually began working remotely full-time
[01:39:33.280 --> 01:39:40.160]   in, I want to say 2018. So this is the irony of it. Every single person who's on this podcast
[01:39:40.160 --> 01:39:47.040]   and on our podcast network, we're all hate people. Well, they turned my office into a
[01:39:47.040 --> 01:39:53.120]   hoteling situation where the only folks who had consistent desks were the sales team. I don't like
[01:39:53.120 --> 01:40:01.120]   that at all. And with the hoteling situation, if it was... I was like, why am I going to the
[01:40:01.120 --> 01:40:07.440]   effort of commuting when I can just have a workspace that works for me? I can work the hours that my
[01:40:07.440 --> 01:40:13.280]   East Coast team needs me to work. And I can still meet people in the city and still meet vendors and
[01:40:13.280 --> 01:40:21.040]   have interviews and things like that. So I do miss some of the collegiality of being in a newsroom
[01:40:21.040 --> 01:40:27.520]   with other people. We've done a good job creating a great team culture where I work, where we're
[01:40:27.520 --> 01:40:32.080]   checking in with each other a lot. There's socialization, there's team building, there's really good
[01:40:32.080 --> 01:40:36.560]   communication across time zones and across multiple vectors, blah, blah. But there's just something
[01:40:36.560 --> 01:40:41.680]   really nice about being able to shout to an editor two or three desks over about something and have
[01:40:41.680 --> 01:40:46.000]   a quick collab. And I miss that. I can see why there are people who make an argument that you need
[01:40:46.000 --> 01:40:52.880]   to be in a specific workspace with colleagues to get stuff done. I talk about this with people
[01:40:52.880 --> 01:41:00.960]   like Paul Theron. He says, I've been quarantined since 1995. I don't ever leave the house. I mean,
[01:41:00.960 --> 01:41:07.280]   my company recently reconfigured at San Francisco office. So it's not even smaller. And they're taking
[01:41:07.280 --> 01:41:13.680]   away a lot of the banks of desks that they used to have and doing more meeting rooms and more social
[01:41:13.680 --> 01:41:19.440]   spaces. And the conception now is that if you are in an office, you're not there to sit at a desk
[01:41:19.440 --> 01:41:24.160]   and work. You're there to do really project specific or event specific collaboration.
[01:41:24.160 --> 01:41:29.360]   So I thought it was interesting that we were heading towards that. And I do think there may be
[01:41:29.360 --> 01:41:36.560]   some other industries that have a business model or circumstances that are flexible enough to do
[01:41:36.560 --> 01:41:41.120]   that. I don't think it's going to permeate workplaces around the world and around different
[01:41:41.120 --> 01:41:44.640]   industries. You're never going to have a hospital or they're like, you know what, we think all the
[01:41:44.640 --> 01:41:52.880]   time, do their jobs remotely. Although I have to say, you could even think about reinventing this.
[01:41:52.880 --> 01:41:56.560]   I recently had a relative of a past way in the hospital. Would have been so much better
[01:41:57.200 --> 01:42:02.160]   had he had hospice at home and passed away with his family and friends at home because of COVID
[01:42:02.160 --> 01:42:07.600]   protocols. He couldn't be people couldn't say goodbye. It was just terrible. I'm so sorry. Yeah.
[01:42:07.600 --> 01:42:14.480]   Well, it wasn't it was on Lisa's side. So I didn't know him. But but I could watch this play out.
[01:42:14.480 --> 01:42:20.240]   And I think there's a lot to be said for not dying in a hospital. I told Lisa, I said,
[01:42:20.240 --> 01:42:26.560]   just in case you're interested, if when I get really sick, put me a hammock by the ocean in Hawaii.
[01:42:26.560 --> 01:42:32.720]   I'll expire there. That's fine. I don't I don't want to die in a hospital, even if it meant living
[01:42:32.720 --> 01:42:37.920]   three weeks longer. What's the point if you're, you know, in a hospital bed? It's not that's not
[01:42:37.920 --> 01:42:44.880]   what I want. So I agree. I actually during the pandemic, I attended my first ever virtual
[01:42:44.880 --> 01:42:52.960]   live streamed funeral, which was a very surreal experience. I was actually at the office and I was,
[01:42:52.960 --> 01:43:01.200]   you know, streaming it from the funeral home. And it was kind of like a, you know, they have a camera
[01:43:01.200 --> 01:43:09.200]   right at the back looking down. And it's a very it was a very surreal experience to watch a funeral
[01:43:09.200 --> 01:43:13.520]   remotely live, you know, with relatives. And I can see the back of their heads. Was it less
[01:43:13.520 --> 01:43:20.800]   terrifying? I mean, do you want to hug these people and you know what? It was weird, but I quite
[01:43:20.800 --> 01:43:25.760]   liked it because I physically couldn't be there. Like I couldn't be there. So it was either do that.
[01:43:25.760 --> 01:43:30.160]   Yeah, at least you got to do that. You wouldn't have been there anyway. So at least you got to do
[01:43:30.160 --> 01:43:36.240]   that. And the people who were there knew that my brother and I were watching remotely. Yeah.
[01:43:36.240 --> 01:43:41.360]   Good. So that was, yeah, it was, it was, it was, it was something. Yeah.
[01:43:44.560 --> 01:43:51.920]   Yeah, I just, it, this is just yet another way the world is changing. Another way the world is
[01:43:51.920 --> 01:43:57.120]   changing poor Scarlett Johansson's only going to get $20 million for Black Widow. And she's not
[01:43:57.120 --> 01:44:05.920]   happy about that. We are now finding out how much Black Widow made Disney made an interesting
[01:44:05.920 --> 01:44:13.520]   choice as did by the way Warner media with their movies. They decided to release to streaming
[01:44:13.520 --> 01:44:17.680]   to their own Disney Plus network the same day that they released to theaters.
[01:44:17.680 --> 01:44:22.000]   And we've mentioned this before Scarlett Johansson said, but my deal
[01:44:22.000 --> 01:44:29.520]   involved a percentage of the box office. And so you've put me at a disadvantage. Now we're seeing
[01:44:29.520 --> 01:44:36.800]   in discovery that Disney's got $125 million in online revenue from Black Widow, none of which
[01:44:37.680 --> 01:44:44.160]   Johansson will get. Although the company says even we're going to be so nice, even though we don't
[01:44:44.160 --> 01:44:50.960]   have to, we're going to give you a percentage from the, from the online revenue. She, Disney said,
[01:44:50.960 --> 01:44:56.880]   the actress had already been paid $20 million for her work on the film. But we will agree to
[01:44:56.880 --> 01:45:01.440]   include online revenue in the calculation for her bonuses, even though we're not obligated to do so.
[01:45:04.640 --> 01:45:08.720]   You know, my gut reaction when I read this right was I think like most people, which is, oh,
[01:45:08.720 --> 01:45:13.840]   let me find my tiny little violin and play you a song. There is a part of me though,
[01:45:13.840 --> 01:45:19.440]   that thinks if you agreed something ahead of time and it's written in a contract,
[01:45:19.440 --> 01:45:25.280]   and that's what you went into expecting, and then it doesn't happen, you're kind of in your right
[01:45:25.280 --> 01:45:30.640]   to be annoyed. And it's, you know, it's a huge amount of money. And it's, you know, it's for all
[01:45:30.640 --> 01:45:34.640]   my business, 50 or 60 million dollars that she's lost out on.
[01:45:34.640 --> 01:45:39.920]   She's still going to eat and have a very nice time and buy a new phone and a car, like whatever,
[01:45:39.920 --> 01:45:43.120]   I get that. But at the end of the day, if you're promising something and you sign something and
[01:45:43.120 --> 01:45:48.240]   then someone changes the rules and says, I kind of think fair enough to be annoyed at least.
[01:45:48.240 --> 01:45:52.080]   I understand. Look, Disney's saying, well, we would have loved to have a theoretical release,
[01:45:52.080 --> 01:45:55.920]   and we would have loved to share those revenues. We couldn't. Well, actually, they did, but we're
[01:45:55.920 --> 01:45:58.800]   not going to, we know we're not going to make as much money on the theatrical release.
[01:45:59.440 --> 01:46:05.600]   It is a little bit the case that they're going to benefit with new subscribers to Disney Plus,
[01:46:05.600 --> 01:46:09.760]   right? Yeah, but it wasn't even, it wasn't even that Disney Plus didn't offer for free. You had to
[01:46:09.760 --> 01:46:17.760]   pay for the movement. Yeah, 30 bucks. You do get to watch the movie more than once for like more than
[01:46:17.760 --> 01:46:22.320]   24 or 48 hours. So because how many days do you have to watch it if you pay for it?
[01:46:22.320 --> 01:46:26.400]   You know, I want to say it's at least two weeks. And the only reason I'm
[01:46:26.400 --> 01:46:32.720]   comfortable saying that is because when Riah and the last dragon came out,
[01:46:32.720 --> 01:46:41.520]   a friend did the $30 download slash purchase for her kid. And two weeks later, she's like,
[01:46:41.520 --> 01:46:46.480]   we're still watching them. Oh, she's like, I've amortized the cost of this movie several times.
[01:46:46.480 --> 01:46:50.480]   Honestly, I doubt I'd want to watch Black video more than twice, but okay, you know,
[01:46:50.480 --> 01:46:55.920]   the thing that I find the, I would love to find out how her contract and her deal for her solo
[01:46:55.920 --> 01:47:02.320]   movie stood up against anything, any deals that say Robert Denning Jr. or Chris Hemsworth or Chris
[01:47:02.320 --> 01:47:09.280]   Evans would have struck. And mind you, they all have the advantage of having solo outings,
[01:47:09.280 --> 01:47:17.040]   multiple solo outings before a pandemic. But I'd love to see what sort of deal her agent was able
[01:47:17.040 --> 01:47:21.360]   to get compared to the deals that these guys pulled the other Avengers who have solo movies
[01:47:21.360 --> 01:47:25.440]   were able to pull in. Oh, you know what? You're right. As long as you retain your subscription
[01:47:25.440 --> 01:47:29.360]   to Disney Plus, you've basically bought Black Widow for as long as you're on Disney Plus.
[01:47:29.360 --> 01:47:36.720]   Now it will be free in a couple of months. So that's, you know, until it's not. I mean, honestly,
[01:47:36.720 --> 01:47:41.120]   that's what I'm waiting to. Yeah, me too. I didn't have that jungle crew is going to have the same
[01:47:41.120 --> 01:47:46.160]   thing starting July 30th. It'll be on Disney Plus at the same time as they release it in the
[01:47:46.160 --> 01:47:51.360]   theaters. I'm not all that anxious to go to a theater. So on the one hand, I think Disney's
[01:47:51.360 --> 01:47:57.040]   understandable why Disney and Warner didn't put these movies exclusively in theaters,
[01:47:57.040 --> 01:48:02.320]   but they did have a deal. I mean, I don't know. The deal said you'll get a percentage of the box
[01:48:02.320 --> 01:48:07.920]   office. It didn't say, I just don't see why you don't pay her. Like, I just give her another
[01:48:07.920 --> 01:48:12.960]   movie for you. And she's amazing. She's the centerpiece of the movie. It's not like she was like some,
[01:48:12.960 --> 01:48:20.960]   you know, about her. Yeah. Yeah. I mean, she's expensive because she can be.
[01:48:20.960 --> 01:48:27.520]   So I wonder if that was part of it too. But it's not a good look for Disney because
[01:48:27.520 --> 01:48:34.080]   it's not a good look for multiple reasons. But among them is like it took forever to give
[01:48:34.080 --> 01:48:39.680]   Scarlett Johansson her solo movie to begin with. And it doesn't help the perception that
[01:48:39.680 --> 01:48:46.320]   Marvel was not particularly interested in cultivating a Marvel fan base beyond like comic book dudes.
[01:48:48.480 --> 01:48:52.400]   And so when you have a lawsuit where you're like, Oh, it took forever for the female
[01:48:52.400 --> 01:48:56.320]   adventure to get her solo movie. And now they're going to cheat her. Yeah. And then you're going
[01:48:56.320 --> 01:49:02.560]   to cheat her and chances are good that the they don't cheat for down each. Yeah, exactly.
[01:49:02.560 --> 01:49:06.320]   Like it's just bad PR. So for them to be able to say, okay, fine, we'll pay you
[01:49:06.320 --> 01:49:10.720]   our bad. Like this is a little bit of damage control, I think. Yeah.
[01:49:10.720 --> 01:49:18.080]   Let's take a little break. And then it's Elon's robot when we continue. Nate Langston is here
[01:49:18.080 --> 01:49:24.720]   technology editor for Bloomberg. He's based in the UK and of course has his own podcast
[01:49:24.720 --> 01:49:33.200]   at UK tech show.com Lisa Schmeiser editor at it pro today. Great to have you.
[01:49:33.200 --> 01:49:39.600]   And we were so close to having people back in the studio. I was looking forward to Girl Scout cookies.
[01:49:42.400 --> 01:49:49.440]   Nothing. Man, those Samoas would have tasted good right about now. And Kevin Rose, the dark
[01:49:49.440 --> 01:49:55.840]   tipper from tech TV's dark tipper. He all over the thin mints fan. Oh, yeah, those are good too.
[01:49:55.840 --> 01:50:01.440]   You're kind of an old guy. I'm gonna put him in the freezer. You're an old school guy. Oh, tasty.
[01:50:01.440 --> 01:50:04.800]   Tasty. He's not wrong. Actually, I'm wrong frozen girl.
[01:50:04.800 --> 01:50:08.480]   So when we're going to come back, we're going to talk a little bit about how the Girl Scouts are
[01:50:08.480 --> 01:50:13.760]   modernizing. It's very interesting. And a little bit, Kevin's got a podcast called Modern Finance.
[01:50:13.760 --> 01:50:20.480]   I highly recommend if you want to know how you can take an icon, a little mini icon of a zombie
[01:50:20.480 --> 01:50:25.920]   and make millions, you've got to listen, you got to listen to modern finance and modern dot
[01:50:25.920 --> 01:50:30.000]   finance. It's great to have all three of you are showed today brought to you by
[01:50:30.000 --> 01:50:37.440]   Wealthfront. Now this kind of speaks to me, maybe a little bit more than cryptocurrency and NFTs.
[01:50:37.440 --> 01:50:45.120]   I am a big fan. Somebody told me when I was in my 30s, Leo, take advantage of that 401k,
[01:50:45.120 --> 01:50:52.160]   put a little bit away on a regular basis because that nest egg grows thanks to the magic of compound
[01:50:52.160 --> 01:50:57.680]   interest. And by the time you're an old man, you're going to have a lot more. You got to start
[01:50:57.680 --> 01:51:04.320]   young and I tell my kids the same thing. You can talk about stonk memes and rocket ships and diamond
[01:51:04.320 --> 01:51:10.560]   hands and NFTs all you want. Day trading, sure, I'm sure it's fun. But if you want to grow your
[01:51:10.560 --> 01:51:15.840]   long term wealth and still make it to the moon, can I recommend a Wealthfront investment account
[01:51:15.840 --> 01:51:24.000]   today? This is not some brilliant insight on my part. Decades of data show that investors that
[01:51:24.000 --> 01:51:30.400]   trade individual stocks underperform the market every year. It's hard to beat the market to time
[01:51:30.400 --> 01:51:35.360]   your purchase and sale of an individual stock. Only 1% of day traders beat the market.
[01:51:35.360 --> 01:51:38.800]   Well, your chance is one in 100. I know you're smarter than all the other guys.
[01:51:38.800 --> 01:51:44.320]   Well, trust me, the odds are not in your favor if you're going in alone. Maybe you know what
[01:51:44.320 --> 01:51:49.600]   do at Lisa does, which is have a little bit of a fun account that you do those individual stocks
[01:51:49.600 --> 01:51:54.800]   with. But you really want to build long term wealth, save up for retirement, for college, for
[01:51:54.800 --> 01:52:01.040]   your kids, for that house, that first house team up with Wealthfront instead. It really simplifies
[01:52:01.040 --> 01:52:06.160]   it. I know investing can be complicated, but even if you've been investing for years, just look at
[01:52:06.160 --> 01:52:10.320]   what Wealthfront does. And I think you'll see it's the right way to do it. Wealthfront makes it easy.
[01:52:10.320 --> 01:52:14.560]   No matter what your goals are, in fact, that's the very first question they're going to ask you.
[01:52:14.560 --> 01:52:20.080]   Your timeframe, your how comfortable you are with risk, you don't have to be, by the way.
[01:52:20.080 --> 01:52:25.440]   They have got the right tools for every portfolio. They will create for you a portfolio of globally
[01:52:25.440 --> 01:52:31.200]   diversified low cost index funds personalized for you in minutes. No manual trades, you don't have
[01:52:31.200 --> 01:52:36.640]   to pick stocks. And what you really get in talking, stop doing is watching the stock market every day.
[01:52:36.640 --> 01:52:40.720]   They handle all the investing based on your preferences. That's what you control. You say
[01:52:40.720 --> 01:52:46.240]   what your goals are. They do things that are hard to do on your own. Things like tax loss harvesting,
[01:52:47.840 --> 01:52:53.280]   lowers the taxes you pay as you invest. And I'm telling you, all this stuff adds up over the years.
[01:52:53.280 --> 01:53:01.520]   The fee for this very low, 0.25%. In fact, so low that tax loss harvesting, in many cases,
[01:53:01.520 --> 01:53:06.640]   will just cover that advisory fee. And all of that happens automatically. Wealthfront's done so well.
[01:53:06.640 --> 01:53:12.160]   Now they have $20 billion in assets. And we've got a great deal for you. You can get your first $5,000
[01:53:12.640 --> 01:53:19.280]   managed for free. Just go to wealthfront.com/twit. Easy to open an account. All you need is $500
[01:53:19.280 --> 01:53:25.200]   to get started. It's like planting a tree. The best time to plant a tree is today.
[01:53:25.200 --> 01:53:32.160]   Even if you're my age, get started. Grow the wealth that you'll need, the easy way to let wealth
[01:53:32.160 --> 01:53:38.960]   front do the work for you. And what a great deal to get your first $5,000 managed free for life.
[01:53:39.760 --> 01:53:47.600]   That's fantastic. Go to wealthfront.com/twit. Wealthfront.com/twit. W-e-a-l-t-h-f-r-o-n-t.
[01:53:47.600 --> 01:53:54.000]   Wealthfront.com/twit. Start growing your savings. Now's the time. Go to wealthfront.com/twit
[01:53:54.000 --> 01:53:59.440]   and get started today. Actually, I'm going to say something about Wealthfront real quick.
[01:53:59.440 --> 01:54:04.400]   I'm an angel investor there. I have no idea. I have no idea.
[01:54:05.360 --> 01:54:09.680]   Yeah, I know. This is not paid or anything. I've had Andy Ratcliffe, CEO of my show before.
[01:54:09.680 --> 01:54:15.360]   Yes. I'm a huge fan, obviously, of what they've created. When I think about this stuff, when we
[01:54:15.360 --> 01:54:21.440]   talk about modern finance, I'm like, "Okay, you need the majority of your assets in something
[01:54:21.440 --> 01:54:24.400]   safe like Wealthfront that's fully diversified because that's going to be the safest place to
[01:54:24.400 --> 01:54:27.680]   have it." The other thing, though, that I'll tell you that it's brand new that you don't know this
[01:54:27.680 --> 01:54:33.200]   yet, Leo, probably. I'm pretty sure you don't. This is a great little hack that you can only do
[01:54:33.200 --> 01:54:38.640]   the Wealthfront. You can go inside to Wealthfront. You can go into your IRA or your tax-deferred
[01:54:38.640 --> 01:54:45.040]   account. You can now choose to have the Bitcoin trust put in there.
[01:54:45.040 --> 01:54:46.400]   What? I didn't know that.
[01:54:46.400 --> 01:54:51.040]   The Ethereum trust. Yeah. So, Grayscale has the Bitcoin trust or the Ethereum trust.
[01:54:51.040 --> 01:54:58.480]   Now, you're holding your cryptocurrency in your IRA inside of Wealthfront or your 401k.
[01:54:58.480 --> 01:55:02.320]   It's so brilliant. It's so cool. Then, when there's competitive other,
[01:55:02.320 --> 01:55:08.400]   eventually, when they can do the tax loss harvesting as well, they'll add that there
[01:55:08.400 --> 01:55:12.240]   on top of it. It's going to be really awesome. That's very interesting.
[01:55:12.240 --> 01:55:16.720]   It's like the best way to hold cryptocurrency in a tax-deferred account. It's really cool.
[01:55:16.720 --> 01:55:22.400]   Brilliant. Well, thank you for that additional plug. They didn't even know you were going to
[01:55:22.400 --> 01:55:27.520]   be here. Wealthfront.com/trit. Please don't use that address, though, so they know you saw it
[01:55:28.080 --> 01:55:32.240]   on Twitter. I've been talking to them a lot about how they can incorporate
[01:55:32.240 --> 01:55:35.520]   cryptocurrency related products and stuff in there. It's really great way. That's like a
[01:55:35.520 --> 01:55:40.880]   diversified way. That's what they're known for is just really that safety, which is awesome.
[01:55:40.880 --> 01:55:45.520]   Yeah. It's cool. Well, my daughter wanted to buy Dogecoin.
[01:55:45.520 --> 01:55:52.320]   I wanted to discourage her with the same time. It's fun. She's not going to spend a lot of money on
[01:55:52.320 --> 01:55:57.200]   it. Then, she wanted to do it in Robinhood. I had to explain to her, you're not really holding
[01:55:57.200 --> 01:56:01.520]   Dogecoin or any coin when you buy it through Robinhood. That's something else they're doing
[01:56:01.520 --> 01:56:09.520]   entirely. It's complicated. But as far as I could tell, they weren't backing that asset with actual
[01:56:09.520 --> 01:56:14.000]   Bitcoin. They were just giving you an investment vehicle that matched Bitcoin's return.
[01:56:14.000 --> 01:56:22.800]   Robinhood does hold their stuff on. Yeah. They do have the wallets and they actually hold the
[01:56:22.800 --> 01:56:26.400]   crypto there. I was wrong. But they do not give you the private keys and they don't give you the
[01:56:26.400 --> 01:56:29.200]   ability to transfer it outside. It's not your wallet. That's probably what you think.
[01:56:29.200 --> 01:56:36.640]   It's the classic crypto slogan of not your keys, not your crypto. You can't transfer it out,
[01:56:36.640 --> 01:56:42.720]   just like PayPal, which is sucks. What if you want to leave and take your crypto elsewhere
[01:56:42.720 --> 01:56:45.920]   and you just can't move it out. They said they're going to be adding that eventually.
[01:56:45.920 --> 01:56:50.560]   I don't know when the time went. What's your take on Robinhood? I guess I should ask you if you
[01:56:50.560 --> 01:56:57.440]   have an investment in it. We did invest at Google Ventures, but it was a pretty minor investment.
[01:56:57.440 --> 01:57:04.960]   But I'm fine with saying that I think that they were the first to, well, they've got a bunch of
[01:57:04.960 --> 01:57:09.840]   problems. They were some issues with front running and they were selling some of the data.
[01:57:09.840 --> 01:57:15.200]   When you offer a service for free, you have to make money somehow. Exactly.
[01:57:15.680 --> 01:57:20.080]   There were other ways and little tactics that they weren't fully disclosing or at least they
[01:57:20.080 --> 01:57:24.240]   weren't. They were talking them into certain areas of terms of service and things where
[01:57:24.240 --> 01:57:30.160]   user base didn't really know what was going on. I think they're going to fix some of that stuff.
[01:57:30.160 --> 01:57:36.320]   I don't hold any crypto there. I don't hold any assets there. I think for someone that wants to do
[01:57:36.320 --> 01:57:42.480]   a quick little $10 stock trade or $100 and you just don't want to go through a trouble of opening a
[01:57:42.480 --> 01:57:46.480]   Schwab account or whatever it may be. Yes, that's going to be the easiest way to do it.
[01:57:46.480 --> 01:57:51.840]   Although Square Cash App is also really convenient at holding fractional shares of stocks.
[01:57:51.840 --> 01:57:58.800]   I do like that. I do like that. I have to say, thanks to Robinhood, you're seeing the whole
[01:57:58.800 --> 01:58:04.640]   FinCen world change. They established you could have free trades. Now everybody's doing it.
[01:58:04.640 --> 01:58:09.840]   They get some credit for putting some pressure on the big guys like Schwab.
[01:58:10.560 --> 01:58:13.440]   Yeah, fractional ownership is huge too. I love that idea.
[01:58:13.440 --> 01:58:16.720]   Yeah, just because some people can't afford an entire share and that's the way it used to be.
[01:58:16.720 --> 01:58:20.480]   You'd have to have, you want to buy Google, you had to spend thousands of dollars before
[01:58:20.480 --> 01:58:27.360]   or wait for a stock split. Apple's $148. But for a dollar, you could buy a fractional share.
[01:58:27.360 --> 01:58:31.200]   I think that that gives you some sense. I like it because for people like Abby,
[01:58:31.200 --> 01:58:36.960]   she's in her 20s, it gives her some sense of participating. Really, that was my attitude.
[01:58:36.960 --> 01:58:40.960]   Yeah, go ahead and play with this a little bit because you need to learn about it.
[01:58:40.960 --> 01:58:43.840]   And then you should listen to Modern Finance and see what you did wrong.
[01:58:43.840 --> 01:58:50.640]   Actually, I met at Peter Thiel. I told Abby, get a Roth IRA while you're poor.
[01:58:50.640 --> 01:58:56.080]   Tell me what Peter Thiel did, Kevin. You probably understand this better.
[01:58:56.080 --> 01:59:01.840]   The Roth IRA, you have to have a low income level. I think you have to be under 144,000 a year.
[01:59:01.840 --> 01:59:08.480]   But you can put the money in post-tax, so it's dollars you've earned and paid taxes on.
[01:59:08.480 --> 01:59:16.080]   But then any income increase, capital gains in the Roth IRA are not taxable on withdrawal.
[01:59:16.080 --> 01:59:21.840]   What apparently smart billionaires have been doing is putting assets that they know are going to
[01:59:21.840 --> 01:59:27.840]   appreciate like crazy in these Roth IRAs. Thiel has billions in a Roth IRA.
[01:59:27.840 --> 01:59:31.920]   They'll never pay taxes on. That's right. You can transfer in assets.
[01:59:31.920 --> 01:59:36.240]   Let's just say you found a new company and you have founders shares of that company and you
[01:59:36.240 --> 01:59:40.800]   believe it's going to be massive. There are ways and vehicles to transfer in those assets into
[01:59:40.800 --> 01:59:45.120]   tax deferred accounts. Granted, he can't touch that until retirement age. I guess he's probably
[01:59:45.120 --> 01:59:49.680]   close to it now. But once that happens, it's going to be all tax-free.
[01:59:49.680 --> 01:59:53.440]   But anyone can do that. That's not just a weird deal.
[01:59:53.440 --> 01:59:59.040]   That's what I told her. I said, "Now while you're poor, invest in a company that's going to the moon."
[01:59:59.040 --> 02:00:07.120]   That's the trick. Thiel obviously knew how to do that. He turned $2,000 in a Roth IRA into $5 billion.
[02:00:07.120 --> 02:00:13.440]   Hasn't put any more money since '99. Now I take it that he probably had some years as
[02:00:13.440 --> 02:00:19.760]   sometimes really rich people do where he had no income. He was able to open a Roth IRA. That's
[02:00:20.800 --> 02:00:24.480]   the trick. What did he put in there? Was it PayPal shares, did it say?
[02:00:24.480 --> 02:00:29.840]   Something that he was involved in early on in those tax-fords.
[02:00:29.840 --> 02:00:34.880]   That's the thing. You have to know that it's going to be huge. No one knows that.
[02:00:34.880 --> 02:00:40.320]   I'm just looking to see what's in there. $1.7 million shares of PayPal.
[02:00:40.320 --> 02:00:47.600]   Bottom four. Get ready for this in 1999.001 cent a share. In other words, he got
[02:00:47.600 --> 02:00:53.680]   $1.7 million shares for $1,700. That's what happens when you're on the founding team.
[02:00:53.680 --> 02:00:58.400]   And you had every tech company. Yeah. And you had a believer in it.
[02:00:58.400 --> 02:01:04.160]   Did you have you done that? I have not. I've not transferred anything into any
[02:01:04.160 --> 02:01:11.760]   tax deferred. It's a backdoor Roth. That's a backdoor I'd like to try out.
[02:01:11.760 --> 02:01:16.560]   Hey, before we take a little break, before we go on and talk about Elon's robot and
[02:01:17.200 --> 02:01:23.680]   the girl scouts and a whole lot more. I did want to tell you about some of the things you
[02:01:23.680 --> 02:01:28.400]   might have missed this week. We had a fun week. A little mini movie for you. What happened this
[02:01:28.400 --> 02:01:36.080]   week on Twitter. CES 2022 is on, baby. Just bring your COVID card. He's going.
[02:01:36.080 --> 02:01:42.240]   What are you on? Could you put some crickets in there right there at that point?
[02:01:45.280 --> 02:01:51.040]   Previously on Twitter. Tech news weekly. In recent weeks about the metaverse,
[02:01:51.040 --> 02:01:58.000]   whatever that is called Horizon workrooms. And it was shown off to journalists this week,
[02:01:58.000 --> 02:02:02.880]   but designed for people working together. I can't imagine a worse time. Hands on photography.
[02:02:02.880 --> 02:02:07.600]   Today on hands on photography, I have another bit of feedback that's quite common. You know,
[02:02:07.600 --> 02:02:12.400]   someone wants to know what are your alternatives to Photoshop? Well, I got a couple things in mind.
[02:02:13.120 --> 02:02:21.360]   All about Android. The embargo is lifted for Pixel 5a with 5g. I happen to have it right here.
[02:02:21.360 --> 02:02:27.760]   I've had it for the past week. It's been my primary phone. Windows weekly. Amazon just got
[02:02:27.760 --> 02:02:34.560]   a different $10 billion cloud contract from the NSA. So this is a contract that's
[02:02:34.560 --> 02:02:40.000]   code named wild and stormy. That's a cocktail name, isn't it? That was the dark and stormy.
[02:02:40.000 --> 02:02:46.880]   Dark and stormy. We think it's a contract about involving NSA trying to consolidate
[02:02:46.880 --> 02:02:52.000]   all the data that it has in multiple repositories. They're going to replace that sex on the beach
[02:02:52.000 --> 02:02:57.040]   server. They've been using the fuzzy naval server. They're going to replace that with a wild and
[02:02:57.040 --> 02:03:00.160]   stormy. Twitter somewhere that's an age ago. They're on to a server.
[02:03:04.480 --> 02:03:10.240]   All right, let's talk about the Girl Scouts in a bizarre segue.
[02:03:10.240 --> 02:03:17.840]   It's not just a natural continuum from Peter. Peter Teal and Roth Iris,
[02:03:17.840 --> 02:03:22.320]   back to our Iris to Girl Scouts. Actually, you said this before the show. I thought it was very
[02:03:22.320 --> 02:03:30.960]   interesting. There is now a badge for digital literacy. It's digital leadership. Oh, even better.
[02:03:31.520 --> 02:03:36.080]   Yes, digital leadership, the Girl Scouts are offering it at all the levels starting with
[02:03:36.080 --> 02:03:40.560]   daisies where the really little guys kindergarten first grade all the way up through, I want to say
[02:03:40.560 --> 02:03:47.440]   seniors, senior Girl Scouts, which are your high schoolers. Yeah, no, all the way up to ambassador,
[02:03:47.440 --> 02:03:53.280]   I think. Oh, ambassadors, who are like your 11th graders or 12th graders? And the skill set for
[02:03:53.280 --> 02:03:58.560]   each of the badges remains the same. It's the sophistication for each, you know, growth of the
[02:03:58.560 --> 02:04:04.080]   age. But basically the girls are going to learn how to discover and assess what their digital
[02:04:04.080 --> 02:04:10.240]   landscape is, you know, to define what a digital landscape is. They will be learning how to detect
[02:04:10.240 --> 02:04:18.640]   misinformation. They'll be learning how to design or participate in a constructive digital community.
[02:04:18.640 --> 02:04:23.360]   They'll learn about the do's and don'ts of creating and putting content online.
[02:04:23.360 --> 02:04:26.320]   And then they'll share their best practices with other people.
[02:04:26.880 --> 02:04:31.040]   Look at this. This is for brownies that's second and third graders.
[02:04:31.040 --> 02:04:38.800]   Discover your digital footprint. The first, explore the differences between public and private
[02:04:38.800 --> 02:04:45.360]   information. This is second and third graders. Yeah. So the brownie, I've pulled up the curriculum
[02:04:45.360 --> 02:04:52.160]   now for the because in my troop, we have brownies, juniors and cadets. So our girls span about a
[02:04:52.160 --> 02:04:57.280]   five grade continuum. And starting at brownies, they're going to learn what catfishing is, what
[02:04:57.280 --> 02:05:03.600]   it is. Oh my God. The difference between public versus private information. And then by the time
[02:05:03.600 --> 02:05:09.520]   I'm talking with my middle schoolers, they'll also be learning about trolling, fishing,
[02:05:09.520 --> 02:05:10.560]   Wow.
[02:05:10.560 --> 02:05:17.200]   Slack division and hashtag activism. And then there's a whole exercise that you do on how to detect
[02:05:17.200 --> 02:05:22.960]   digital misinformation, how to debunk a debate online. And another thing they're talking about
[02:05:22.960 --> 02:05:27.360]   in the badges are where to go if you're being harassed or having trouble online, how to reach
[02:05:27.360 --> 02:05:31.200]   out and talk to somebody and get over the fear that you might be in trouble or that you've done
[02:05:31.200 --> 02:05:37.120]   something can't be undone. So look at this, the cadets public print out this, my digital data
[02:05:37.120 --> 02:05:44.400]   tracker, where they actually track which devices they use to go to which platform, what they did,
[02:05:44.400 --> 02:05:49.280]   what data or content they shared with whom do they share it? What was your mood before?
[02:05:49.280 --> 02:05:55.600]   And what was your mood after? Oh, this is the kind of thing every every kid should do, I think.
[02:05:55.600 --> 02:06:00.000]   There's a digital wellness routine. They're encouraging for the girls where they want them to
[02:06:00.000 --> 02:06:05.120]   monitor their screen time and be honest about how much time they're spending. They want them to,
[02:06:05.120 --> 02:06:10.240]   you know, before you post something, check in with your values and then check in with your
[02:06:10.240 --> 02:06:17.520]   feelings and ask for help if you need it. I'm going to do this. I like that they're adding
[02:06:17.520 --> 02:06:22.640]   skills that point out that what happens online is going to affect you period. Like it's a really
[02:06:22.640 --> 02:06:29.760]   holistic look because I think one of the things that people in say my I'm Gen X, but people like me
[02:06:29.760 --> 02:06:33.840]   who came of age using computers but not necessarily online until we got to school,
[02:06:33.840 --> 02:06:39.360]   there's still a tendency to distinguish between online and offline life. And that's simply
[02:06:40.160 --> 02:06:45.920]   not a helpful distinction. And what I love about these badge programs, you know, looking them over
[02:06:45.920 --> 02:06:50.640]   is that they don't make that distinction. It's basically this is and the Girl Scouts have always
[02:06:50.640 --> 02:06:55.280]   had badges on how to manage other parts of your life from personal finance to physical fitness
[02:06:55.280 --> 02:07:02.480]   to civic engagement. And they're just now extending this to this is another area where you're going
[02:07:02.480 --> 02:07:07.200]   to have to develop a set of skills that will serve you well in life. I love it. Lisa, I have a
[02:07:07.200 --> 02:07:11.360]   question for you about the Girl Scouts. I'm curious, you know, I was an Eagle Scout on the Boy Scouts
[02:07:11.360 --> 02:07:17.440]   side and over the last like decade or so or five or so years, I've just been kind of disgusted
[02:07:17.440 --> 02:07:21.600]   with a lot of the stuff that's been happening at the Boy Scout level. Does the Girl Scouts have
[02:07:21.600 --> 02:07:26.080]   a lot of that the same politics or is it a kind of a different organizational together?
[02:07:26.080 --> 02:07:30.640]   So my brother is an Eagle Scout. We were like a total scouting family. I've got my golden
[02:07:30.640 --> 02:07:38.400]   Girl Scouting. He has his evil. Organizational, they are very different. I've actually
[02:07:38.400 --> 02:07:47.280]   trainings where I when I got certified in wilderness recovery in first aid, I was like,
[02:07:47.280 --> 02:07:51.920]   why are we so risk-averse? Why is there so much certification? And one of the things they said
[02:07:51.920 --> 02:07:57.040]   one of the things they said was we want to make sure that we're reducing risk to the girls at
[02:07:57.040 --> 02:08:01.600]   every level. And they have that built into the culture. For example, if you have a married couple
[02:08:01.600 --> 02:08:05.280]   in a troop, you have to have like as leaders in a troop, there always has to be a third
[02:08:05.280 --> 02:08:11.760]   unrelated adult there. There are really, really strict rules as to who can shepherd on camping
[02:08:11.760 --> 02:08:18.880]   and why this is the case and they're communicated very clearly. So that was a way of side stepping
[02:08:18.880 --> 02:08:23.200]   some of the liability issues that have docked the Boy Scouts. As to some of the political and
[02:08:23.200 --> 02:08:30.480]   cultural issues, I'm in the Bay Area. So it may not be the same always, but I've been involved as
[02:08:30.480 --> 02:08:39.600]   an adult leader since 2001. And even as far back as 2001, anybody who thinks or identifies as a girl
[02:08:39.600 --> 02:08:46.880]   has been welcome in Girl Scouting. Oh, that's great. That's fantastic. And so far, is that really
[02:08:47.760 --> 02:08:55.200]   honored in spirit as well as by the rule? Okay, yeah. At least it is in my service unit and
[02:08:55.200 --> 02:09:01.920]   in the council stuff I've seen that's true. One of my favorite troop leaders in another troop,
[02:09:01.920 --> 02:09:07.440]   you know, she and her wife ran a troop successfully for several years. And so there's never really,
[02:09:07.440 --> 02:09:11.600]   not there's never because it's not true. But in my experience as an adult leader for 20 years,
[02:09:11.600 --> 02:09:17.680]   we haven't had the cultural flashpoints with what they called them Boy Scout or Girls Girls
[02:09:17.680 --> 02:09:24.560]   Gods Gaze. It hasn't been an issue in Girl Scouting. The biggest issue that's actually coming up is
[02:09:24.560 --> 02:09:31.040]   because of the Boy Scouts, because now that the Boy Scouts is open to women, or they're open to
[02:09:31.040 --> 02:09:35.440]   little girls, and you can have little girls go through Boy Scouting and get up to the Eagle Scout
[02:09:35.440 --> 02:09:40.640]   level, that's something where I've talked to families who were like, well, you know, no offense,
[02:09:40.640 --> 02:09:44.080]   but no one's ever heard of the gold award. Everyone knows what an Eagle Scout is. And so
[02:09:45.360 --> 02:09:52.480]   there is a little bit of organizational anxiety around what kind of relationship the Girl Scout
[02:09:52.480 --> 02:09:56.720]   organization is going to have with the Boy Scout organization. We don't even call it Boy Scouts
[02:09:56.720 --> 02:10:02.080]   anymore. It's Scouts BSA because of that. It's Scouts BSA, yeah. Interesting.
[02:10:02.080 --> 02:10:09.840]   Wait, were you anything? I mean, I got one Eagle Scout. I got one gold. What are we? You and I?
[02:10:09.840 --> 02:10:13.600]   They had Girl Guides in the UK. I don't know about the boys though. Did you get anything? Any
[02:10:13.600 --> 02:10:23.680]   honors as a young man? No. I didn't really want them. I was quite disruptive when I was young,
[02:10:23.680 --> 02:10:29.200]   so I didn't really want to get involved in that much stuff. I know my mum was a Girl Guide.
[02:10:29.200 --> 02:10:37.920]   I've seen photos and things when she was a Girl Guide. I think we, I may have been in something
[02:10:37.920 --> 02:10:44.480]   called Cubs, which is like, I think that's a younger version of Scouts here.
[02:10:44.480 --> 02:10:49.840]   We have that too. Cub Scouts is before Boy Scouts, yeah. Yeah. Cub Scouts. Yeah. Because Tigers
[02:10:49.840 --> 02:10:55.520]   Cubs, we below those Boy Scouts, right? Yeah. Got it. I think I might have been in that when I was
[02:10:55.520 --> 02:11:04.160]   very young. But yeah, when I was when I was older, I was more, I was more interested in
[02:11:04.720 --> 02:11:09.280]   and just playing the drums basically and anything that took time away from that. I wasn't really
[02:11:09.280 --> 02:11:14.080]   that interested in that all I did. I didn't compute as a part. My dad was the Scout leader,
[02:11:14.080 --> 02:11:18.800]   so like it was like there wasn't a choice for me. Yeah. I was like, no, they're going to Scouts.
[02:11:18.800 --> 02:11:23.120]   And I'd be like, yeah, I don't want to wear the uniform. Girls think it looks dumb. I'm embarrassed.
[02:11:23.120 --> 02:11:27.760]   And yeah, but I in retrospect, you know, many years later, you look back on it. You're like,
[02:11:27.760 --> 02:11:32.560]   those were fun camping trips. I learned a lot. It was like, it was time well spent. But at the time,
[02:11:32.560 --> 02:11:38.960]   I'd rather be skateboarding. Yeah. The uniform is like, especially as you get into middle school
[02:11:38.960 --> 02:11:44.880]   in high school. Oh, yeah. They're embarrassing. Yeah. And I'll have to check this because my first
[02:11:44.880 --> 02:11:49.760]   wave of girls is now is now middle school. When I was a Girl Scout, we were required to have the
[02:11:49.760 --> 02:11:56.080]   uniform before we could receive our silver or gold awards. And like when I was a teenager,
[02:11:56.080 --> 02:12:00.960]   I wanted nothing less than to head to tell Paul yes, you're with the truffles and why.
[02:12:00.960 --> 02:12:08.240]   I really hope it's not the same now, but. Oh, Leo, you have to Google Kevin Rose Boy Scout.
[02:12:08.240 --> 02:12:13.280]   I actually did post my Eagle Scout photo. Oh, and online at one point, you got to pull this.
[02:12:13.280 --> 02:12:22.160]   We were doing tech TV. We would get very regularly request to write letters for Eagle Scouts.
[02:12:22.720 --> 02:12:28.800]   Oh, my goodness. And I always took it very seriously. Is this is this your? Yeah, there you are. There
[02:12:28.800 --> 02:12:34.960]   you are. There's me. Look at that. I was like a late. This was like an Eagle Scout. I was a late
[02:12:34.960 --> 02:12:43.760]   bloomer. You got a lot of badges. I love it. That was heavy on those shoulders. What badge did you
[02:12:43.760 --> 02:12:50.560]   enjoy the most? Will it a survival was probably my favorite? Sure. Sure. Somewhere.
[02:12:50.560 --> 02:12:56.000]   I did not, unfortunately, I'm bombed. I didn't get a chance to.
[02:12:56.000 --> 02:12:59.040]   Yeah. Is that the big Jamboree?
[02:12:59.040 --> 02:13:07.840]   No, it's a campground camping site. It's like a. It's a it's a it's a it's a it's a
[02:13:07.840 --> 02:13:15.360]   one of adventure ranch in the high country in New Mexico. And you can go out there and do rock
[02:13:15.360 --> 02:13:20.800]   climbing and backcountry trekking. And it's it's like a really big deal for scouts when they get
[02:13:20.800 --> 02:13:26.080]   together. Wasn't there a big long hike as those see with that some big trip? Was that just I
[02:13:26.080 --> 02:13:31.760]   can't recall? There's also I know the boys cats also do like a rim to rim grand canyon thing too.
[02:13:31.760 --> 02:13:36.640]   So it's it's they do like the I feel like I should run up the fight for the girls guests. The girls
[02:13:36.640 --> 02:13:43.200]   cats do a lot of amazing tricks and things like that. But film was like a holy grail for boy scouts
[02:13:43.200 --> 02:13:49.520]   when my brother was in it. Yeah. Film on trips. So so I will say when I was looking at these digital
[02:13:49.520 --> 02:13:56.320]   leadership badges, I was perhaps unfairly assessing them with a gimlin eye because they were under
[02:13:56.320 --> 02:14:02.000]   written with a grant from Instagram. And so part of me was like is posting on Instagram going to
[02:14:02.000 --> 02:14:07.360]   be a requirement here or that's not so bad. I mean, no, it looks like if there's if there's
[02:14:07.360 --> 02:14:11.840]   anything, it's a light touch. But I do appreciate that they're teaching the girls how to identify
[02:14:11.840 --> 02:14:18.240]   clickbait and how to look how to look for how to assess digital bias and things like that. Because
[02:14:18.240 --> 02:14:25.280]   I mean, digital literacy is a huge concern for people who are growing up online. And this is it's
[02:14:25.280 --> 02:14:29.360]   anything that helps people get a set of skills will be a good to be good, I think. Yeah, that's
[02:14:29.360 --> 02:14:36.960]   great. Yeah. I was trying to find my my cubs cat picture if I but I don't think I can find it. So
[02:14:37.760 --> 02:14:41.280]   I'd love to see that. I was in cubs cats. I didn't make it to boy scouts.
[02:14:41.280 --> 02:14:46.640]   That's that's a lot better than the picture that I sent to my best friend the other day,
[02:14:46.640 --> 02:14:50.800]   which is the time that I was dressed in a two to.
[02:14:50.800 --> 02:14:54.560]   No judgment. Christmas tree.
[02:14:54.560 --> 02:14:59.280]   Christmas tree. Yeah. There were extenuating circumstances, you know, but
[02:14:59.280 --> 02:15:04.480]   that was an interesting photo to discover. Definitely get Apple flagged.
[02:15:05.440 --> 02:15:12.640]   Oh, yeah, there was. Yeah, it was a fun evening from what I remember of it.
[02:15:12.640 --> 02:15:22.080]   But I was like nine years ago. Yeah, exactly. I really was hoping I could find my
[02:15:22.080 --> 02:15:28.480]   cubs cat picture, but I know it's somewhere. I'll find it. I'll dredge it up. I'm doing this. I'm
[02:15:28.480 --> 02:15:36.800]   holding up my hand. Probably I guess it's supposed to be the right hand. Elon Musk has announced
[02:15:36.800 --> 02:15:44.160]   that within a year, Tesla will have a humanoid robot that can do all the boring stuff.
[02:15:44.160 --> 02:15:48.560]   He says, we know everything there is to know about how to do this.
[02:15:48.560 --> 02:15:55.120]   And, and, you know, in our research for self-driving vehicles and so forth,
[02:15:56.160 --> 02:16:01.840]   he probably maybe messed up the announcement a little bit. This is, let me refresh this page so
[02:16:01.840 --> 02:16:08.000]   you can see the robot marching to do the Charleston on this stage. Yeah. It wasn't a robot, though.
[02:16:08.000 --> 02:16:17.040]   It's very, and then it starts dancing. So it wasn't, it wasn't in fact a robot. It was a dancer in a
[02:16:17.040 --> 02:16:23.680]   spandex suit. That's a horrible announcement. Some people say it might have had something to do
[02:16:23.680 --> 02:16:27.280]   with the fact that the National Highway Transportation Safety Administration announced they were
[02:16:27.280 --> 02:16:32.480]   investigating Tesla's self-driving features after driving to a number of emergency vehicles.
[02:16:32.480 --> 02:16:40.640]   And, Elon was just trying to distract. Yeah. I mean, that is, that is a reaction gift
[02:16:40.640 --> 02:16:48.080]   just waiting to happen. Well, he talks about how it's going to quote unquote eliminate dangerous,
[02:16:48.080 --> 02:16:54.160]   repetitive, boring tasks. And I just want to know, has he taken a look at what robotics is already
[02:16:54.160 --> 02:17:01.440]   doing? Like it's, does he reel, like, does he actually know what the big challenges are right
[02:17:01.440 --> 02:17:06.880]   now in robotics process automation or any more of the Tesla pant in the Fremont where they have
[02:17:06.880 --> 02:17:12.640]   massive German robots that pick up the cars, flip them over, move them down the line. I mean,
[02:17:12.640 --> 02:17:18.480]   they use as many robots as they can in the production line of Tesla's. So he understands
[02:17:18.480 --> 02:17:23.040]   how many of them needs, how many of them need stage perfect jazz hands?
[02:17:23.040 --> 02:17:31.840]   The Tesla bot says Elon will stand five feet, eight inches tall way, 125 pounds,
[02:17:31.840 --> 02:17:41.120]   56 kilograms, have human level hands. And he says, we can do it in about a year. A number of people
[02:17:41.120 --> 02:17:48.960]   have also pointed out that it's taken Boston dynamics to do 10 years to do Atlas. Although
[02:17:48.960 --> 02:17:55.200]   Atlas can dance too. Let's let's not forget Atlas is a pretty, pretty, pretty dangerous,
[02:17:55.200 --> 02:18:01.440]   repetitive, boring task that he thinks he's going to somehow turn over to the province of the jazz
[02:18:01.440 --> 02:18:07.600]   hands robot. Well, I wonder if maybe he's thinking about Amazon warehouses, things like that.
[02:18:09.200 --> 02:18:14.080]   You don't need to have an anthropomorphic robot to stock or restock, you know?
[02:18:14.080 --> 02:18:16.240]   No, they have pick and picker machines that do it.
[02:18:16.240 --> 02:18:21.600]   Exactly. But on the other hand, because the environment is designed for humanoids in many
[02:18:21.600 --> 02:18:28.320]   respects, there are reasons to have humanoid robots. So I don't know. I just mean, bilateral
[02:18:28.320 --> 02:18:32.480]   symmetries, nice to look at, but let's not make let's not assume it's the most efficient use of
[02:18:32.480 --> 02:18:42.080]   space or task. Elon's a funny fella. That's all I can say. Let's see. Anything else that I miss?
[02:18:42.080 --> 02:18:45.760]   Any of the big stories we wanted to talk about? I think we got them all in here. We've kept you
[02:18:45.760 --> 02:18:52.480]   long enough. I do thank all of you. I think it's hysterical that China has passed a new data privacy
[02:18:52.480 --> 02:18:57.920]   law. But maybe we'll save that for another conversation another day. Nate Langston is up late.
[02:18:58.880 --> 02:19:05.440]   It's pushing 1am in England. Where in England are you? I always ask you this.
[02:19:05.440 --> 02:19:12.080]   I'm just north of London. I say London and it is technically the outskirts of London in
[02:19:12.080 --> 02:19:18.720]   Hertfordshire. Hertfordshire? I just wanted to say Hertfordshire. I live in Hertfordshire. It's true.
[02:19:18.720 --> 02:19:24.800]   Like a nature reserve in Hertfordshire. Oh, how nice. Not a cute little town, but actually in the
[02:19:24.800 --> 02:19:31.760]   country. Yeah, as close to the countries you can get when you work in the financial districts of
[02:19:31.760 --> 02:19:37.920]   London. Oh, you go into the city every but not every day, every every moment. A couple of days a
[02:19:37.920 --> 02:19:45.760]   week. But yeah, so it's sort of nature all around and then go into the chaos of the city when when
[02:19:45.760 --> 02:19:51.200]   needed. Some time we're going to get you to end this show with a drum solo. I'm just warning you.
[02:19:51.200 --> 02:19:55.040]   I would love to see the party in the back. That's all I'm saying.
[02:19:55.040 --> 02:20:00.800]   Well, you can see it. I use my Instagram these days almost exclusively for drum stuff. So if
[02:20:00.800 --> 02:20:05.600]   anyone wanted to see some of that or hear it, it's on my Instagram. Nate Langston Drums.
[02:20:05.600 --> 02:20:15.200]   They say Twitter, I keep the professional Bloomberg related stuff and Instagram is just a purely
[02:20:15.200 --> 02:20:22.320]   drums drumming stuff. And here comes the drums, ladies and gentlemen. Look at that. He's banging the skins.
[02:20:22.320 --> 02:20:28.560]   Yeah, my new 14 inch Roland V drums.
[02:20:28.560 --> 02:20:39.040]   Yeah, oh, the robots are I was going to say it sounds like robots. Let me turn the robots off so
[02:20:39.040 --> 02:20:46.160]   we can hear that. That's that did sound like robots. This is Nate on the drums. Much better.
[02:20:46.160 --> 02:20:50.720]   I could play this without fear of take down. I like it. Thank you, Nate.
[02:20:50.720 --> 02:20:58.320]   Thanks. No take down. Thank you also, Lisa Schmeiser.
[02:20:58.320 --> 02:21:05.200]   Windows. I'm sorry. IT Pro Today magazine senior editor. Always a pleasure to have you
[02:21:05.200 --> 02:21:10.240]   and your ghost cat cookies on. I wish we could well, we'll just have you in next time we can
[02:21:10.240 --> 02:21:14.320]   have people in here with some Girl Scout cookies. The sale season starts in January,
[02:21:14.320 --> 02:21:18.240]   so you'll know when to book. Good book you book you before that, but it's great to have you.
[02:21:18.240 --> 02:21:24.400]   And it's always a pleasure to have my old friend Kevin Rose on just adore you. And I'm so happy for
[02:21:24.400 --> 02:21:30.720]   your beautiful family. And thank you for and congratulations on the success of modern finance.
[02:21:30.720 --> 02:21:35.520]   That's a great modern dot. Thank you, then. For his podcast. It's a must listen if you're interested
[02:21:35.520 --> 02:21:44.800]   in the modern world of cryptocurrency NFTs. Fin sent is it fins? What is it? Fin DeFi DeFi.
[02:21:44.800 --> 02:21:50.480]   That's it. What does that stand for? Decentralized finance. There you go. DeFi.
[02:21:50.480 --> 02:21:58.160]   That's that's how Nate and I grew up as teenagers. We defied. And now and now Kevin's making money
[02:21:58.160 --> 02:22:02.400]   on it. Thank you, Kevin. Great to have you. Thanks to all of you for joining us. We do
[02:22:02.400 --> 02:22:09.280]   Twitter every Sunday afternoon to 30 Pacific 530 Eastern 2130 UTC. We'd love to have you watch us live.
[02:22:09.280 --> 02:22:14.000]   There's a live stream. It's kind of fun. You have a live audience. Can't have them in studios. So
[02:22:14.000 --> 02:22:19.040]   watch us in the live stream. There's audio and video at twit.tv/live. If you're watching live
[02:22:19.040 --> 02:22:25.600]   chat live. You can do that at IRC.twit.tv. And of course club twit members chat live with us
[02:22:25.600 --> 02:22:32.400]   in our discord server. I'll explain club twit another time. But it's a great place to hang out.
[02:22:32.400 --> 02:22:38.240]   After the fact on demand versions of the show are available, of course, on our website twit.tv.
[02:22:38.240 --> 02:22:41.760]   There's a YouTube channel dedicated to this week in tech. You can watch there.
[02:22:41.760 --> 02:22:46.160]   Best way probably is to subscribe in your favorite podcast client.
[02:22:46.160 --> 02:22:50.720]   That way you'll get it automatically. If there is a chance on that client to leave a review,
[02:22:50.720 --> 02:22:56.080]   please tell the world you listen to twit. Leave that five star review help us spread the word.
[02:22:56.080 --> 02:23:01.920]   We appreciate it. Thanks in advance. Thanks for your time this afternoon. This evening,
[02:23:01.920 --> 02:23:07.440]   whenever you listen and we'll see you next time. Another twit is in the can. 17 years, I've been saying.
[02:23:07.440 --> 02:23:08.480]   This is amazing.
[02:23:08.480 --> 02:23:08.960]   It's nice.
[02:23:08.960 --> 02:23:20.480]   [ outro music ]

