;FFMETADATA1
title=Android Nutroll
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=553
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2016
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:04.700]   It's time for Twit this week in Tech. Mark Millian is here from
[00:00:04.700 --> 00:00:08.760]   New York Week. Nathan Oliveris Giles from the Wall Street Journal. And yeah, David
[00:00:08.760 --> 00:00:12.760]   Pogue. He's joining us from South by Southwest where it's 96 degrees. We'll
[00:00:12.760 --> 00:00:16.880]   talk about the President's remarks at South Pie. We got a little gaming segment.
[00:00:16.880 --> 00:00:20.200]   We're talking a little bit about VR and the game developer conference coming up
[00:00:20.200 --> 00:00:23.360]   next week. And of course, the Apple event. It's going to be a great show.
[00:00:23.360 --> 00:00:35.080]   Stay tuned. Twit is next. Netcast you love. From people you trust.
[00:00:35.080 --> 00:00:41.200]   This is Twit. Bandwidth for this week in Tech is provided by CashFly at
[00:00:41.200 --> 00:00:53.760]   C-A-C-H-E-F-L-Y.com. This is Twit this week in Tech. Episode 553 recorded
[00:00:53.760 --> 00:01:00.440]   Sunday, March 13th, 2016. Android Nutroll. This week in Tech is brought to you by
[00:01:00.440 --> 00:01:05.440]   Casper, an online retailer of premium mattresses for a fraction of the price.
[00:01:05.440 --> 00:01:09.520]   Because everyone deserves a great night's sleep, get $50 off any mattress
[00:01:09.520 --> 00:01:15.080]   purchased by visiting casper.com/twit and entering the promo code TWIT.
[00:01:15.080 --> 00:01:19.960]   And Buy Carbonite. Keep your business safe this year. Protect files on your
[00:01:19.960 --> 00:01:24.480]   computer or server with automatic cloud backup from Carbonite. Try it free
[00:01:24.480 --> 00:01:28.160]   without a credit card at carbonite.com today. And when you use the offer code
[00:01:28.160 --> 00:01:33.680]   TWIT, you'll get two free bonus months if you decide to buy. And Buy Harries. For
[00:01:33.680 --> 00:01:37.320]   guys who want a great shave experience for a fraction of what you're paying now,
[00:01:37.320 --> 00:01:42.240]   go to harries.com for a limited time new customers can get a free trial and pay
[00:01:42.240 --> 00:01:48.720]   just three dollars for shipping by going to harries.com/twit. And Buy Stamps.com.
[00:01:48.720 --> 00:01:52.720]   Use stamps.com to buy and print real US postage the instant you need it right
[00:01:52.720 --> 00:01:56.960]   from your desk. For our special offer, go to stamps.com, click the microphone and
[00:01:56.960 --> 00:02:01.320]   enter TWIT. That's stamps.com offer code TWIT.
[00:02:01.320 --> 00:02:04.880]   It's time for Twit this week in Tech. The show where we cover the latest tech news
[00:02:04.880 --> 00:02:08.880]   with the best tech journalists out there. We'll start with Mark Millian from
[00:02:08.880 --> 00:02:12.280]   Bloomberg Business Week. Hey Mark. Hey Leo. Great to see you. Your new
[00:02:12.280 --> 00:02:16.040]   beat, your now tech, the charge of all tech coverage there. No, but that would be
[00:02:16.040 --> 00:02:18.400]   nice. Oh, no. Brad Stone actually. Brad Stone, actually.
[00:02:18.400 --> 00:02:22.480]   Oh, Brad, I love Brad. He's in charge of all. Brad's great. He's doing a great job.
[00:02:22.480 --> 00:02:26.880]   I am helping get our to get our new startup, the venture capital team off
[00:02:26.880 --> 00:02:31.080]   the ground. That's right. All right. And of course when there is a Mark Millian
[00:02:31.080 --> 00:02:34.880]   signing, we usually see Nathan Oliveris Giles from the Wall Street Journal.
[00:02:34.880 --> 00:02:37.680]   Good to see you. Nice seeing you. Thanks. Welcome. Thank you.
[00:02:37.680 --> 00:02:40.160]   Thank you. We're both dressed for rain, but David
[00:02:40.160 --> 00:02:46.360]   Pogue is dressed for 96 degree weather in Austin, Texas. From Yahoo Tech, David
[00:02:46.360 --> 00:02:49.720]   Pogue. Hi, David. South by Southwest, direct sunlight, man.
[00:02:49.720 --> 00:02:53.120]   Wow. Through the W Hotel, where the only place I could get a signal.
[00:02:53.120 --> 00:02:58.360]   So you're outside in 96 degree weather? Yes. I was trying to find a place where
[00:02:58.360 --> 00:03:04.040]   it would be quiet. And so they suggested the pool top rooftop area.
[00:03:04.040 --> 00:03:08.960]   And I'm in the corner because it's windy. So I'm trying to not be too noisy.
[00:03:08.960 --> 00:03:11.280]   Your panel is right after the show today. What are you going to do?
[00:03:11.280 --> 00:03:18.440]   This is Yahoo, OMD joint venture. I'll be interviewing a startup creator.
[00:03:18.440 --> 00:03:24.680]   Oh, fun. That's great. South by, of course, starts with the interactive
[00:03:24.680 --> 00:03:29.240]   and film and the music comes later in the week. How has it been so far?
[00:03:29.240 --> 00:03:32.960]   East it started Friday, right? You know, I just arrived.
[00:03:32.960 --> 00:03:37.640]   Oh, two hours. So I couldn't tell you. You didn't get to see the president.
[00:03:37.640 --> 00:03:40.360]   I saw him on video. Yeah.
[00:03:40.360 --> 00:03:45.120]   He actually, that's a big keynote for South by Southwest,
[00:03:45.120 --> 00:03:48.240]   have the president of the United States. I think that's got to be a first.
[00:03:48.240 --> 00:03:55.920]   He went to tell the techies visiting South by Southwest that we need them,
[00:03:55.920 --> 00:03:59.040]   that we need the tech community to get involved and help make government
[00:03:59.040 --> 00:04:02.560]   more efficient, more transparent, great message.
[00:04:02.560 --> 00:04:07.280]   You know, and I think it resonated well. Unfortunately, all of that completely
[00:04:07.280 --> 00:04:11.520]   got superseded by one of the questions towards the end of his presentation.
[00:04:11.520 --> 00:04:16.160]   Somebody asked him about the Department of Justice versus Apple case.
[00:04:16.680 --> 00:04:22.440]   And well, who wants to pick it up here? Why don't you pick you?
[00:04:22.440 --> 00:04:28.360]   You could pick it up if you want Mark Millian. He said, we got to stop fetishizing.
[00:04:28.360 --> 00:04:31.720]   Wait, this is a mistake. Stop fetishizing smartphones.
[00:04:31.720 --> 00:04:37.240]   That they can't be allowed to be black boxes and that the tech industry should
[00:04:37.240 --> 00:04:40.040]   work with the government to solve this. That's right. Yeah.
[00:04:41.400 --> 00:04:47.080]   He, you know, obviously he's going to side with law enforcement and with the federal government.
[00:04:47.080 --> 00:04:51.720]   That's not obvious, but I guess he's the president. I guess he has to.
[00:04:51.720 --> 00:04:56.280]   They do ultimately report to him so he'd hope the boss is on the same message as.
[00:04:56.280 --> 00:04:59.560]   That's one thing that's interesting. It doesn't seem like the government is actually
[00:04:59.560 --> 00:05:03.160]   of one voice on this. The NSA is promoting strong encryption.
[00:05:03.160 --> 00:05:07.640]   NSA says we need for security. We need end-to-end encryption everywhere.
[00:05:08.200 --> 00:05:12.280]   The FBI says we can't enforce the laws if we have it.
[00:05:12.280 --> 00:05:15.880]   So there isn't really kind of universal agreement in that government.
[00:05:15.880 --> 00:05:17.880]   David, where do you stand on all of this?
[00:05:17.880 --> 00:05:21.800]   You know, I'm not sure I took away the same message from Obama's speech.
[00:05:21.800 --> 00:05:27.080]   So what I got from him was a typical Obama-reason-measured effect.
[00:05:27.080 --> 00:05:32.040]   I heard him saying, let's not just slam the door and say neither one of us can move.
[00:05:32.040 --> 00:05:34.680]   Let's see if we can come up with a solution.
[00:05:35.240 --> 00:05:39.000]   And I mean, I have to say there must be a solution.
[00:05:39.000 --> 00:05:42.360]   If all the posturing went away and this weren't being done in the public eye,
[00:05:42.360 --> 00:05:45.320]   I'll bet you they could come up with a solution.
[00:05:45.320 --> 00:05:48.760]   For example, I mean, I didn't know the particulars of the software code,
[00:05:48.760 --> 00:05:53.640]   but suppose the FBI gave Apple the phone, said, don't create a backdoor.
[00:05:53.640 --> 00:05:56.280]   We don't need to have it. You're not going to give it out.
[00:05:56.280 --> 00:05:58.440]   But can you find the data on there for us?
[00:05:58.440 --> 00:06:03.640]   You know, help us hunt down a terrorist without sacrificing anybody else's privacy.
[00:06:03.640 --> 00:06:08.440]   I mean, it seems like there is a precedent for this, which is the warrant, right?
[00:06:08.440 --> 00:06:14.120]   If someone wants to search your home, they get a warrant by a judge who then says,
[00:06:14.120 --> 00:06:17.720]   okay, we need to search the home because we suspect you of something.
[00:06:17.720 --> 00:06:23.560]   So this idea of we need to pursue our investigation through your private area,
[00:06:23.560 --> 00:06:29.480]   it's not a new idea. And it just seems, it seems like Obama's right in that there could be some
[00:06:29.480 --> 00:06:30.120]   compromise.
[00:06:31.080 --> 00:06:37.880]   That was the argument he was trying to make in that, you know, throughout the history of technology,
[00:06:37.880 --> 00:06:43.000]   there have been ways for the government to get access to things, whether it's, you know,
[00:06:43.000 --> 00:06:51.000]   going to AT&T and, you know, pulling information off of their servers from, from cell phone data,
[00:06:51.000 --> 00:06:55.960]   or whether it is having a backdoor within Skype or just about any other software out there.
[00:06:55.960 --> 00:07:02.680]   In the specific Apple case, what they're asking Apple to do is to create a special version of
[00:07:02.680 --> 00:07:08.520]   their operating system that only Apple has access to. And the governments would be able to bring
[00:07:08.520 --> 00:07:15.000]   phones to Cupertino and say, install that version of your operating system on it so that we can
[00:07:15.000 --> 00:07:21.880]   brute force hack the passcode and get access to the phone. What Apple's saying is that if we do that,
[00:07:22.440 --> 00:07:29.400]   then, you know, somebody might hack our systems and get access to that software. And then, you know,
[00:07:29.400 --> 00:07:32.040]   they have a key to everyone's phone in the world.
[00:07:32.040 --> 00:07:36.120]   Isn't it telling though that the FBI could do exactly what you say, David? They could say,
[00:07:36.120 --> 00:07:39.720]   well, just here's the phone. Just in fact, that's what they used to do. Here's the phone. Just give
[00:07:39.720 --> 00:07:45.080]   us the data. But they chose not to. I think the FBI is very interested in establishing a precedent.
[00:07:45.080 --> 00:07:48.840]   And the precedent that worries me, the precedent they'd like to establish is not
[00:07:49.880 --> 00:07:56.360]   Apple's going to help us open up this phone, but that we can compel using the courts a tech company
[00:07:56.360 --> 00:08:02.600]   to write custom firmware. And that is, I think, what their really long term goal is, it's not about
[00:08:02.600 --> 00:08:06.360]   this phone. It's about getting a tech company to this. I'll tell you why I disagree with you,
[00:08:06.360 --> 00:08:11.560]   David, and with the president. The president said you can't take and he's a politician.
[00:08:11.560 --> 00:08:16.280]   Politics is the art of compromise of negotiation. And of course, from his point of view,
[00:08:16.280 --> 00:08:21.320]   there's always a negotiation that can go on. You can't take an absolute view on this, he says.
[00:08:21.320 --> 00:08:25.720]   If your argument is strong encryption, no matter what, and we can and could create
[00:08:25.720 --> 00:08:30.600]   black boxes, I think that does not strike the kind of balance we've lived with for 200, 300 years,
[00:08:30.600 --> 00:08:34.840]   and it's fetishizing our phones above every other value. And I think he's missing the point.
[00:08:34.840 --> 00:08:38.440]   I understand that that's a good political point of view, which is, no, no, we can,
[00:08:38.440 --> 00:08:43.400]   if we sit down, we can work this out. But it's not about politics, it's about math.
[00:08:44.040 --> 00:08:49.320]   And in my opinion, I think the technologists he's talking to probably are thinking the same thing.
[00:08:49.320 --> 00:08:53.000]   It's like the government saying, well, we don't like this two plus two equals four thing.
[00:08:53.000 --> 00:08:57.240]   Can we work it out? Can we compromise? Is there something we could do? Can we make it four and a half?
[00:08:57.240 --> 00:09:03.240]   Because the encryption exists, the math exists, is nothing anybody can do about that. It's out there.
[00:09:03.240 --> 00:09:08.360]   It's done. In fact, there's a guy with a tattoo on his chest of strong encryption.
[00:09:08.360 --> 00:09:11.880]   There's t-shirts. And we've done this once before. The government said,
[00:09:11.880 --> 00:09:16.840]   with munitions, rather said that the strong encryption was like munitions. And in the mid 90s,
[00:09:16.840 --> 00:09:22.200]   you remember this, David, they said, you cannot export strong encryption. So what happened? And
[00:09:22.200 --> 00:09:27.320]   we have history as a lesson here that apparently is not being paid attention to. What happened
[00:09:27.320 --> 00:09:33.320]   was Netscape said, all right, well, if you're going to insist on, you know, we can't export
[00:09:33.320 --> 00:09:39.240]   128-bit key encryption, we'll make 40-bit and it'll be in all our browsers. We're not, we can't
[00:09:39.240 --> 00:09:43.960]   make a separate browser for the US and Russia. So we'll make one browser. It'll have 40-bit
[00:09:43.960 --> 00:09:49.720]   encryption. And here we are 20 years later. The fact that 40-bit encryption was in that browser
[00:09:49.720 --> 00:09:55.560]   means we still have to support 48-bit encryption on websites. And it has become a real security
[00:09:55.560 --> 00:09:59.640]   problem to the point now, where many companies like Google and Microsoft are trying to force
[00:09:59.640 --> 00:10:08.360]   this weak encryption off the internet. But it's hard to do. So this was an example of by fiat,
[00:10:08.360 --> 00:10:12.520]   by legislative fiat, the government saying, well, you just can't have strong encryption.
[00:10:12.520 --> 00:10:17.320]   So what it does, it doesn't just break it for bad guys. In fact, it doesn't break it for bad guys,
[00:10:17.320 --> 00:10:23.320]   because bad guys can access strong encryption. It's out there. It's easy. Everybody can do it.
[00:10:23.320 --> 00:10:29.000]   So all it does is it takes strong encryption away from normal users.
[00:10:29.000 --> 00:10:34.760]   Yeah. And the government has argued that, you know, Apple is doing this for marketing reasons
[00:10:34.760 --> 00:10:41.400]   to protect the talent or business. But I think in many ways, if this were the president that
[00:10:41.400 --> 00:10:48.680]   were set, that the government could go to an American company and say, you need to build this
[00:10:48.680 --> 00:10:53.640]   version of your phone so that we can get into it. That really does potentially put American
[00:10:53.640 --> 00:11:00.040]   technology companies at a disadvantage if people do prioritize security overall else. I mean,
[00:11:00.040 --> 00:11:05.560]   you know, a company like Xiaomi or, you know, Blackphone or these non-American companies
[00:11:05.560 --> 00:11:09.960]   could get a potentially big boost from people who do prioritize their privacy.
[00:11:09.960 --> 00:11:14.360]   And then Apple and Google and the other companies would be able to disappear.
[00:11:14.360 --> 00:11:18.520]   And the bad guy, it doesn't stop if you want to, if a bad guy wants to have private conversations,
[00:11:18.520 --> 00:11:20.360]   they could do it. Yeah. Nothing they could do about it.
[00:11:20.360 --> 00:11:25.960]   Also, Apple cited in the hearing was telegram, which is this huge messaging service from
[00:11:25.960 --> 00:11:33.400]   the creator of the Facebook of Russia that has very strong encryption is used like throughout
[00:11:33.400 --> 00:11:39.720]   ISIS's organization. And you know, you're not, you can't go to them and tell them to build a
[00:11:39.720 --> 00:11:43.080]   version of their software that the FBI can have access to. They're not going to listen.
[00:11:43.080 --> 00:11:45.640]   Well, and here's the real problem right now is what's app?
[00:11:45.640 --> 00:11:53.560]   Forget, you know, the iPhone, what's app is being is being used, it has strong encryption.
[00:11:53.560 --> 00:11:59.560]   It's owned by Facebook, Facebook acquired it. And it is not, it's invisible to law enforcement.
[00:11:59.560 --> 00:12:02.840]   You can use what's what's app for crying out loud, free app out there. And there are lots of
[00:12:02.840 --> 00:12:09.080]   others. There's wire just got updated. It's a Swiss company. It's using OTR strong public key
[00:12:09.080 --> 00:12:13.240]   crypto. It's open source. How are you going to stop that?
[00:12:13.240 --> 00:12:18.440]   You know, it seems to me part of the problem is that there are so many conflated issues to
[00:12:18.440 --> 00:12:23.640]   argue about. In other words, are we arguing about being spied on? Are we arguing about
[00:12:23.640 --> 00:12:30.280]   the government pressuring a private company? I mean, a commercial company to bend its ways?
[00:12:30.280 --> 00:12:38.360]   Are we arguing about the San Bernardino terrorist? So let me ask you, Alio, if there were such a
[00:12:38.360 --> 00:12:47.400]   solution whereby no innocent individuals could have their phones broken into, but only
[00:12:48.200 --> 00:12:52.600]   bad guys are suspected bad guys. So that all the other issues of this go away.
[00:12:52.600 --> 00:12:55.720]   Would that be satisfactory? Oh, yeah, of course.
[00:12:55.720 --> 00:12:59.160]   So you're not saying even terrorists should have their privacy?
[00:12:59.160 --> 00:13:05.480]   Well, I'm saying you cannot limit terrorist privacy without breaking it for everyone. That's
[00:13:05.480 --> 00:13:12.680]   the real problem. And I understand, look, there's a long standing tradition, and this is a tradition
[00:13:12.680 --> 00:13:17.880]   we all have to support. This is what my society works, that if a court based on reasonable cause
[00:13:17.880 --> 00:13:23.320]   orders, a search of your home, that that's legal and proper and law enforcement can do that.
[00:13:23.320 --> 00:13:27.880]   And in fact, there is to up till now, there's only been, we talked about this last week, one
[00:13:27.880 --> 00:13:33.480]   place in the whole world that was protected. And that was your brain. The courts have held
[00:13:33.480 --> 00:13:38.920]   that the one place law enforcement can't force, you cannot be forced to testify against yourself.
[00:13:38.920 --> 00:13:43.880]   You could be forced to give a fingerprint, a hair, you can, but you cannot be forced to divulge
[00:13:43.880 --> 00:13:48.360]   the contents of your brain. We're going to, well, courts have already said this, we're going to
[00:13:48.360 --> 00:13:54.360]   mark this out as a private space. The problem is, so that's why I'm saying it's not a political
[00:13:54.360 --> 00:14:00.280]   negotiation, because of course, there, you know, you should be able to, with a lawful warrant,
[00:14:00.280 --> 00:14:05.240]   search anything. That's, you know, what our nation's based on. The problem is,
[00:14:05.240 --> 00:14:12.360]   it's too late, encryption exists. And you could tell Apple not to encrypt iPhones, but it doesn't
[00:14:12.360 --> 00:14:15.160]   mean that somebody can't use them WhatsApp on their iPhone.
[00:14:15.160 --> 00:14:19.800]   Yeah, part of what bothers me about the analogy with, you know, regular warrants and searching
[00:14:19.800 --> 00:14:24.680]   your home is if law enforcement wants to come into my home and search what I have,
[00:14:24.680 --> 00:14:30.040]   I have access to that warrant. I can know about it, I can get a copy of it, I can take it to my
[00:14:30.040 --> 00:14:35.640]   legal team with all that we've seen from what the NSA has been doing on, you know, spying. We don't
[00:14:35.640 --> 00:14:40.680]   know when they're asking tech companies already for our information. Right. And that's already
[00:14:40.680 --> 00:14:47.240]   even happening. Like that is already a precedent. Right. So if we're talking about now, breaking
[00:14:47.240 --> 00:14:51.960]   encryption to getting to getting into these sorts of devices, of course, the San Bernardino
[00:14:51.960 --> 00:14:57.080]   shooter is the example everyone's talking about right now. It's at the center of it. But in no,
[00:14:57.080 --> 00:15:03.480]   in no situation, is that where this would end at all? There's already been hundreds of requests
[00:15:03.480 --> 00:15:07.160]   that are similar. And there's even dozens, I think, from like the attorney general or something
[00:15:07.160 --> 00:15:12.360]   like that. And even in this interview at South by Southwest Obama, like expanded the scope of
[00:15:12.360 --> 00:15:17.400]   what we're talking about here outside of San Bernardino, you know, he also brought up the
[00:15:17.400 --> 00:15:25.000]   example of, you know, enforcing tax, like IRS taxes. He was like, everybody shouldn't have a Swiss
[00:15:25.000 --> 00:15:32.280]   Swiss bank account in their pockets. And so that already, you know, suggests how far does this go?
[00:15:32.280 --> 00:15:38.360]   Let's let, you know, let's say I don't report like my Amazon purchases on my tax return. Can they
[00:15:38.360 --> 00:15:43.320]   then like access my phone data to see that I that I purchased some stuff from Amazon and then
[00:15:43.320 --> 00:15:49.080]   David, David, do you I mean, I liked your hypothetical, but is that do you think that that's possible?
[00:15:49.080 --> 00:15:54.600]   I just wanted to clarify what we were arguing about, because I know there are people on the
[00:15:54.600 --> 00:16:00.840]   internet who say, you know, no access to anybody anytime. You know, it doesn't matter if I have
[00:16:00.840 --> 00:16:05.080]   child porn, it doesn't matter. I'm a terrorist. It's the principle of the thing. So I was just
[00:16:05.080 --> 00:16:09.960]   trying to peg where you are. Yeah, and I'm kind of standing back from that argument. I'm also not
[00:16:09.960 --> 00:16:14.040]   any government, which a lot of I think technologists just don't like the idea of government at all,
[00:16:14.040 --> 00:16:20.120]   and think privacy should be universal and so forth. But it doesn't even matter. What I'm saying is,
[00:16:20.120 --> 00:16:24.520]   yeah, you can have different points of view on that. But I know I think it doesn't matter at this
[00:16:24.520 --> 00:16:29.480]   point. You can somebody will make a strong encrypted phone. It won't be in the United States company,
[00:16:29.480 --> 00:16:35.080]   I guess. Somebody has already made many messaging programs that are completely secure. Telegram
[00:16:35.080 --> 00:16:40.120]   is actually a poor choice because it's using its own role, your own encryption, which is easily
[00:16:40.120 --> 00:16:45.720]   broken, apparently. But there are other systems. You know, you've got to figure that the government
[00:16:45.720 --> 00:16:49.960]   also is this is a little bit of a species argument from the government because
[00:16:49.960 --> 00:16:54.120]   they've even said, well, we're not too worried. You've got the internet of things coming. You're
[00:16:54.120 --> 00:16:58.120]   going to be putting 20 things in your house that we can use to spy on you at any time.
[00:16:59.080 --> 00:17:03.160]   Remember that Harvard Berkman Law Center study called Going Dark, which really concluded,
[00:17:03.160 --> 00:17:06.760]   and so a lot of good people on that, that there's no problem with Going Dark.
[00:17:06.760 --> 00:17:14.280]   I think law enforcement is not, I think what they're seeking is some pretty broad ability to
[00:17:14.280 --> 00:17:21.560]   compel tech companies to rewrite their firmware to their benefit. They may get it. I wouldn't be
[00:17:21.560 --> 00:17:25.480]   surprised if they got it. And I think President Obama's right to say that this, we should resolve
[00:17:25.480 --> 00:17:29.560]   this before it gets to Congress because Congress is probably going to write the good law.
[00:17:29.560 --> 00:17:37.480]   I'm really also concerned about what we do here in the United States, what this will mean for
[00:17:37.480 --> 00:17:40.680]   other countries. I mean, I know China's watching it closely. That's something that we've covered a
[00:17:40.680 --> 00:17:47.000]   lot at the journal. And there's questions about, okay, if how far the United States gets in its
[00:17:47.000 --> 00:17:51.880]   ability to compel tech companies to essentially create software for them to help them in their
[00:17:51.880 --> 00:17:59.000]   pursuits, what will that mean when China asks the same sort of thing? And then there's also been this
[00:17:59.000 --> 00:18:04.920]   WhatsApp executive in Brazil who was arrested, I think, for only a day, but nonetheless,
[00:18:04.920 --> 00:18:12.200]   he was arrested because WhatsApp wasn't able to turn over some data that the government requested.
[00:18:12.200 --> 00:18:15.560]   And the company argued, well, the data doesn't exist. We can't give you what doesn't exist.
[00:18:15.560 --> 00:18:16.520]   We don't have it.
[00:18:16.520 --> 00:18:20.200]   But there's a fundamental misunderstanding on the side of the government as to what exists
[00:18:20.200 --> 00:18:26.120]   and what is possible and what is new and what's there or isn't. And this guy got thrown in jail
[00:18:26.120 --> 00:18:26.520]   for it.
[00:18:26.520 --> 00:18:31.640]   I think it's kind of unfortunate because I really do feel like the president went to
[00:18:31.640 --> 00:18:35.640]   South by with a strong message, which is let's get the tech community working with government
[00:18:35.640 --> 00:18:40.440]   to make government more efficient, more responsive. But it's gotten completely overwhelmed.
[00:18:40.440 --> 00:18:42.280]   Do you had to move, David? Are you okay now?
[00:18:42.280 --> 00:18:43.320]   Yeah.
[00:18:43.320 --> 00:18:43.720]   Yeah.
[00:18:43.720 --> 00:18:50.520]   A hotel employee needed to sweep, make some adjustments, but I persuaded him to stay.
[00:18:50.520 --> 00:18:54.280]   I got to clean this concrete block behind you. It's just too gray.
[00:18:54.280 --> 00:18:59.720]   David and Sissy's in hotel. We're pretty sure he's in actually the Austin City jail.
[00:18:59.720 --> 00:19:03.320]   It seems that it was time for the other prisoners to have it.
[00:19:03.320 --> 00:19:06.840]   You've been in the yard too long, huh?
[00:19:06.840 --> 00:19:13.240]   It's an argument we've been talking about since this news broke weeks ago.
[00:19:13.240 --> 00:19:18.520]   And it's probably we've dealt it to death at Nausea. But I was a little disappointed.
[00:19:18.520 --> 00:19:23.160]   I feel like the president, I understand he's a politician. He's going to expect a political
[00:19:23.160 --> 00:19:26.520]   solution to this. But I think he doesn't understand it. It's not a question at this point of political
[00:19:26.520 --> 00:19:31.400]   solution. There's the math. And the math is not unfortunately tractable.
[00:19:31.400 --> 00:19:37.080]   How do you guys think it's going to turn out? Like, what if a judge says Apple, you lose?
[00:19:37.080 --> 00:19:39.640]   What are they going to do? Put 13,000 employees in jail?
[00:19:39.640 --> 00:19:44.200]   That will almost certainly happen. Yeah, I wonder what happens. Okay, so let's say it goes to the
[00:19:44.200 --> 00:19:48.120]   Supreme Court. It'll go to the Supreme Court no matter what. If Apple wins, if Apple loses,
[00:19:48.120 --> 00:19:52.440]   somebody whoever loses is going to appeal, it'll end up in the Supreme Court. If they take it,
[00:19:52.440 --> 00:19:56.280]   and let's say they rule against Apple, who goes to jail? Tim Cook.
[00:19:56.280 --> 00:20:03.560]   Who goes to jail? I think Apple, I think Apple complies is what happens. I think Apple doesn't
[00:20:03.560 --> 00:20:07.960]   want to comply. But I think Apple, if it was a, you know, if it's a court order and they've appealed
[00:20:07.960 --> 00:20:13.080]   it all the way and they lost, I think Apple complies. They're not an unlawful company.
[00:20:13.080 --> 00:20:18.440]   But I think ultimately this shouldn't be decided by the courts. This should be decided by Congress.
[00:20:18.440 --> 00:20:23.640]   Unfortunately, Congress is going to almost undoubtedly sit do the wrong thing. But they've
[00:20:23.640 --> 00:20:29.000]   been asked before to this is, you know, Kalea is the template for this, the Assistance to Law
[00:20:29.000 --> 00:20:36.360]   Enforcement Act, that Congress passed in the 90s, that said, telecom companies like AT&T must
[00:20:36.360 --> 00:20:41.880]   cooperate with law enforcement. That's why there's a secret room in AT&T in San Francisco, because
[00:20:41.880 --> 00:20:47.560]   of Kalea. There have been attempts to pass a Kalea for digital providers that have failed
[00:20:47.560 --> 00:20:55.080]   so far. I suspect we'll see an attempt at Kalea three in Congress. And then,
[00:20:55.080 --> 00:20:58.600]   let's play this out. It's the scenario you kind of talked about, Nate. We're,
[00:20:58.600 --> 00:21:03.240]   okay, now any company that wants to do business, the United States has to sell broken encryption.
[00:21:04.760 --> 00:21:08.920]   And if you want, and if you're a bad guy, then you just go buy this, the black phone.
[00:21:08.920 --> 00:21:17.880]   Yeah, I think honestly, you know, I think it would put us at a bit of a disadvantage. I mean,
[00:21:17.880 --> 00:21:25.000]   I'm kind of disappointing that the government itself is doing this in such a public way. And,
[00:21:25.000 --> 00:21:32.040]   you know, trying to put a little, you know, fire under Apple for this, because, I mean,
[00:21:33.160 --> 00:21:37.880]   of all the resources that they have, of all the brilliant people in the world,
[00:21:37.880 --> 00:21:40.760]   they can't figure this out on their own. They're very publicly saying,
[00:21:40.760 --> 00:21:46.360]   Apple needs to do this for us. And the fact of the matter is, is Apple doesn't just belong
[00:21:46.360 --> 00:21:49.800]   to the United States. Google doesn't just belong to the United States. Like, these are global
[00:21:49.800 --> 00:21:55.480]   companies that have their own, you know, whether we like it or not, political and social power,
[00:21:55.480 --> 00:22:02.040]   and their own influence all over the world. And these other governments are going to come
[00:22:02.040 --> 00:22:06.920]   at these companies in similar ways. So we might like it right now, because, you know, the United
[00:22:06.920 --> 00:22:11.960]   States government is trying to get its own thing. But when it spreads, and this becomes the norm
[00:22:11.960 --> 00:22:16.840]   in the practice, then there are flawed products out there for everybody. And the simple fact,
[00:22:16.840 --> 00:22:21.560]   I think, is that new technologies will be developed, and there will be new secret ways
[00:22:21.560 --> 00:22:27.000]   for people to share what they need to share and to communicate. And it'll, you know, the bar will
[00:22:27.000 --> 00:22:31.080]   just always, always be moved. So, you know, I think it's a little bit defeatist. I think it's a little
[00:22:31.080 --> 00:22:35.880]   bit short-sighted. It's definitely not just about the San Bernardino Shooters' phone.
[00:22:35.880 --> 00:22:41.400]   But it's about, I think, changing the expectation that we have as consumers for what we have in
[00:22:41.400 --> 00:22:45.640]   our pockets. Right now, you can see encryption as being something that leads you to being safe
[00:22:45.640 --> 00:22:52.440]   and private. But they're removing that expectation of privacy in a way, or they want to, I think,
[00:22:52.440 --> 00:22:55.880]   the thing the government wants to remove that expectation of privacy, in a way that mirrors
[00:22:55.880 --> 00:23:00.360]   some of the state-backed companies and technologies that you do see in countries like China.
[00:23:00.360 --> 00:23:04.440]   Yeah. I mean, if you buy a Huawei phone in China, you've got to presume that the Chinese government
[00:23:04.440 --> 00:23:09.240]   can do it. Yeah. But that's the thing. That is the, that is the answer is, well, it's not private
[00:23:09.240 --> 00:23:14.360]   anyway. So, why would you share or do certain things now? I agree with it.
[00:23:14.360 --> 00:23:17.480]   I agree with it. For president, we shouldn't, there's nothing particularly special about a
[00:23:17.480 --> 00:23:20.280]   smartphone that it, you know, has to shut up the phone. It's not even about the phone. It's about
[00:23:20.280 --> 00:23:23.240]   what we're talking about. It's not the tech. It's about encryption in general.
[00:23:23.240 --> 00:23:29.560]   You know, sitting in the back of my head through all of this, I think it was Jeffrey Fowler,
[00:23:29.560 --> 00:23:35.480]   the Wall Street Journal, who did this great column that I never saw coming. I didn't even think about
[00:23:35.480 --> 00:23:40.920]   this, but Google and Apple, who are competitors in some way, have a very different approach toward
[00:23:40.920 --> 00:23:47.560]   privacy. Apple is trying to make more and more with every month about how little of your data
[00:23:47.560 --> 00:23:53.240]   it maintains about how few connections there are between its various apps. Google, on the other
[00:23:53.240 --> 00:23:57.880]   hand, is like, oh, yeah, we know where you go. We know your email. We know your money. We know your
[00:23:57.880 --> 00:24:03.800]   phone. Now we have our Nest thermostats, knowing when you're home. You know, and they create products
[00:24:03.800 --> 00:24:09.160]   that exploit all this data in really clever ways. You know, so when you are using Google Maps and
[00:24:09.160 --> 00:24:15.000]   you start typing in an address, I have to type in like two letters of the street and it also
[00:24:15.000 --> 00:24:18.760]   works. I know exactly where you're going. How does it know that? I haven't typed it in
[00:24:18.760 --> 00:24:23.480]   for well. It's because it also has access to my Gmail and to my calendar, you know, it can,
[00:24:23.480 --> 00:24:29.400]   it can give us things in exchange for this data and followers saying Apple is
[00:24:29.400 --> 00:24:36.840]   hog tying itself by saying, oh, no, we're all about privacy. We're never going to make those
[00:24:36.840 --> 00:24:41.800]   connections. So what's curious about all this is the timing. So Apple's big marketing push,
[00:24:41.800 --> 00:24:47.080]   and I'm on the receiving end of PR missives about this all the time. Every time there's a new Apple
[00:24:47.080 --> 00:24:51.160]   product, they're like, and by the way, we don't maintain any of your data. They're trying to make
[00:24:51.160 --> 00:24:56.200]   it a sales point. They are. And so in some ways, that's in the back of my head through all of
[00:24:56.200 --> 00:25:02.840]   Tim Cook's protestations about this privacy thing. They're making a big public stink about just how
[00:25:02.840 --> 00:25:07.800]   seriously Apple takes privacy as a competitive advantage. And there's some merit to the
[00:25:07.800 --> 00:25:12.600]   Department of Justice saying see Apple's using this as a marketing opportunity that there is some
[00:25:12.600 --> 00:25:16.840]   merit to that. It is a valuable marketing opportunity. I think it's a little bit of a
[00:25:16.840 --> 00:25:21.080]   misrepresentation because we know, for instance, that Apple could have they even said,
[00:25:21.080 --> 00:25:26.280]   well, if a fruit could backed up his iPhone to the cloud, we could have given that to the FBI.
[00:25:26.280 --> 00:25:32.760]   So Apple has access to all this stuff. They choose not to mine it for information as Google does.
[00:25:32.760 --> 00:25:40.120]   Ironically, my Nexus 6P, which is encrypted by default, can be protected with a strong password
[00:25:40.120 --> 00:25:45.800]   that Google couldn't write a backdoor to. I mean, this is as encrypted as an iPhone,
[00:25:47.080 --> 00:25:51.400]   and doesn't have that kind of week for digit or six digit unlock if I don't want it to.
[00:25:51.400 --> 00:25:57.320]   But at the same time, any device you use, if the and this is why I worry, if the Department
[00:25:57.320 --> 00:26:02.440]   of Justice or anybody can compel a company to write custom firmware for that device,
[00:26:02.440 --> 00:26:06.920]   there's nothing we have in computing that can't be cracked and opened.
[00:26:06.920 --> 00:26:12.360]   True. I mean, Google could push firmware onto it onto an Android device that would give them
[00:26:12.360 --> 00:26:17.000]   access to all the data on an Android device as well. So that's the real I think that's the real
[00:26:17.000 --> 00:26:20.520]   risk. And I do unfortunately think that that's the the precedent the government wants to establish
[00:26:20.520 --> 00:26:27.320]   is, you know, in the pursuit of law enforcement under court order, we should be able to get custom
[00:26:27.320 --> 00:26:31.480]   firmware written for any device so that we can see what's on that device. In fact, as while you're
[00:26:31.480 --> 00:26:36.280]   at it, why don't I just give us that firmware so we can just put it on there as necessary.
[00:26:36.280 --> 00:26:41.400]   That way we don't have to keep bothering you. Yeah. I think that's the ultimate. That's the end.
[00:26:41.400 --> 00:26:46.840]   And in some ways, I wonder why we're getting so, you know, hept up over this issue on our
[00:26:46.840 --> 00:26:52.120]   smartphones. There are so many other realms where we're routinely being data harvested.
[00:26:52.120 --> 00:26:57.000]   Exactly. I mean, how do you know that Verizon isn't listening into every cell phone call you
[00:26:57.000 --> 00:27:01.640]   make or looking at your records? How do you know your grocery store isn't saying, oh, loading up
[00:27:01.640 --> 00:27:06.680]   on the Entenmann's Pastries a bit this month? This month, aren't you Leo or or how do you know Visa
[00:27:06.680 --> 00:27:11.880]   and MasterCard aren't, you know, perusing your credit card statements? They're all around us
[00:27:11.880 --> 00:27:17.160]   are things that we could be getting worried and upset about. And every time a reader says,
[00:27:17.160 --> 00:27:21.560]   you know, this really bothers me about my privacy. I'm like, if you're going to be paranoid,
[00:27:21.560 --> 00:27:25.560]   be rational about it. Yeah. You have much bigger fields to plow.
[00:27:25.560 --> 00:27:31.000]   We'll get real paranoid because frankly, you have no privacy. And that was true. That's true.
[00:27:31.000 --> 00:27:36.040]   In fact, if you use as an example of Verizon, Verizon, of course, is putting super cookies
[00:27:36.040 --> 00:27:41.240]   on all the web traffic from Verizon customers for a couple of years. They got in trouble with the FCC.
[00:27:41.240 --> 00:27:48.120]   The FCC is now finding Verizon the amazingly huge amount of $1.35 million.
[00:27:48.120 --> 00:27:53.400]   And they're going to keep using the super cookies. Of course they are. So Steve Gibson
[00:27:53.400 --> 00:27:56.600]   pointed out Verizon would happily pay that every year for permission.
[00:27:56.600 --> 00:28:01.720]   Because that's how they're making more than that from the people they sell that information to.
[00:28:03.080 --> 00:28:10.840]   It's a kind of a sad find, to be honest with you. It's a slap on the wrist, you know. And
[00:28:10.840 --> 00:28:17.160]   unfortunately, the super cookie will continue. The FCC has said that you have to be clear that
[00:28:17.160 --> 00:28:21.320]   you're doing it to Verizon and you have to have an opt out. But you know, here's the truth. I
[00:28:21.320 --> 00:28:27.640]   bet you noticed this, David. People don't really care. No, and it's also really, really generational.
[00:28:27.640 --> 00:28:32.440]   I mean, younger, the millennials are like, you're going to give me a free service in exchange for
[00:28:32.440 --> 00:28:37.960]   my data. Good deal. Like traffic speeds on Google Maps. Yeah. Sign me up. Yeah. It's just their
[00:28:37.960 --> 00:28:44.040]   parents. It's just old us old guys who still have one toe in the privacy thing. It really is
[00:28:44.040 --> 00:28:50.120]   so generational that we're going to die out and the incoming generation will be not nearly as
[00:28:50.120 --> 00:28:55.880]   concerned. I think you're kind of correct on that. You're kind of correct. You're a millennial.
[00:28:55.880 --> 00:28:59.240]   I am a millennial. As a matter of fact. I'm surrounded by millennials. So is David.
[00:28:59.240 --> 00:29:03.640]   Mark, but I mean, honestly, I think as to we're taking over slowly,
[00:29:03.640 --> 00:29:09.560]   please do, would you? I'm all the tired. But the fact of the matter is, I think that it is really
[00:29:09.560 --> 00:29:17.400]   easy to point to people millennial or older and or younger and say, you know, hey, well, you don't
[00:29:17.400 --> 00:29:21.640]   even you don't care about privacy. You like just getting free stuff. You like and you like the
[00:29:21.640 --> 00:29:26.280]   advantages of Google Maps. I think there's there's there's a fundamental misunderstanding of how this
[00:29:26.280 --> 00:29:32.040]   technology works and what we're giving up in trade for those services. So, you know, the first time
[00:29:32.040 --> 00:29:37.160]   that someone signs up for a Google account or a Facebook account, maybe nowadays they're, you know,
[00:29:37.160 --> 00:29:41.400]   in middle school or something like that. Do you think they really have an understanding of what
[00:29:41.400 --> 00:29:46.360]   data they're giving away? No. And as you live your life, I mean, you yourself, Pogue, you just said
[00:29:46.360 --> 00:29:50.840]   that, you know, you're looking at these people in getting these frustrated reader comments,
[00:29:50.840 --> 00:29:57.000]   and they don't understand they're being paranoid. I think you, myself, Mark, all of us as journalists
[00:29:57.000 --> 00:30:00.840]   need to do a better job of explaining what the help people are giving away. And we don't do a
[00:30:00.840 --> 00:30:05.960]   good job of that. Most detectives, because people don't really care people will really care. I think
[00:30:05.960 --> 00:30:13.320]   people didn't care if people didn't care. Why would Edward Snowden be a household name today?
[00:30:13.320 --> 00:30:18.040]   Why would we care about the NSA issues? Why was Edward Snowden the keynote speaker last year
[00:30:18.040 --> 00:30:22.680]   in South by Southwest before Obama was this year? It wasn't a mistake the president rolled through
[00:30:22.680 --> 00:30:27.000]   and happened to be talking about these things right as the FBI is showing out. But people,
[00:30:27.000 --> 00:30:31.480]   I think people know that Facebook sells their information. That's how Facebook makes money.
[00:30:31.480 --> 00:30:36.040]   But they do it in an abstract. They do in an abstract. It's like, well, they know what I like
[00:30:36.040 --> 00:30:39.240]   and they know who my friends are and they know who I am. So they don't really understand the
[00:30:39.240 --> 00:30:44.440]   pervasive. Exactly. Here's a report from a company, a group called Upturn. And this is a
[00:30:44.440 --> 00:30:51.800]   report they put out for policymakers in Washington DC. What ISPs can see clarifying the technical
[00:30:51.800 --> 00:30:58.760]   landscape of the broadband privacy debate and the takeaways are, you know, I mean, I'd love to see
[00:30:58.760 --> 00:31:03.320]   this published in the Wall Street Journal or the Bloomberg Business Week and Yahoo Tech.
[00:31:03.320 --> 00:31:08.360]   Truly pervasive encryption on the internet is still a long way off. For instance,
[00:31:08.360 --> 00:31:15.160]   86% of health sites do not encrypt browsing. 86%, 90% of news and 86% of shopping.
[00:31:15.160 --> 00:31:22.360]   And your ISP can see right into that Internet of Things devices often transmit data without
[00:31:22.360 --> 00:31:29.800]   encryption. Most people are using messaging apps that are not encrypted by default. I guess
[00:31:29.800 --> 00:31:33.720]   apples is, but that's just they use it because that's by default. And that's what apples kind of
[00:31:33.720 --> 00:31:40.200]   made their name. But even with HTTPS, ISPs can still see the domains their subscribers visit.
[00:31:40.200 --> 00:31:46.760]   So they can collect where you're going and what you're doing. It's all there. Your ISP knows a
[00:31:46.760 --> 00:31:51.400]   huge people. I often tell people this on the radio show. What are you worried about Google and
[00:31:51.400 --> 00:31:57.880]   Apple? Your ISP is the expert in what the hell you're doing on the internet. Yeah. And they are
[00:31:57.880 --> 00:32:02.760]   already cooperating with the government. And they're gladly in fact, remember carnivore,
[00:32:02.760 --> 00:32:08.840]   which was a big to do mostly because of the name. This was the box the FBI was going to require all
[00:32:08.840 --> 00:32:15.640]   ISPs put into their network operations center to keep track of what its their users were doing
[00:32:15.640 --> 00:32:21.000]   and keep track of it for two years just in case. Just in case the FBI wanted to investigate them.
[00:32:21.000 --> 00:32:24.120]   You think they're really only holding on to that for two years? Well, they changed the name,
[00:32:24.120 --> 00:32:30.680]   but basically the rules are the same. So yeah, carnivore was maybe not a good name. So now.
[00:32:32.440 --> 00:32:40.760]   So they decided to do something else. But basically that surveillance ISPs are required or strongly
[00:32:40.760 --> 00:32:45.800]   encouraged to keep 18 months of data. Yeah. And they know everything and they're handing it over.
[00:32:45.800 --> 00:32:50.920]   So to answer your question, Nathan, I think there's also a big audience question about the
[00:32:50.920 --> 00:32:57.800]   coverage of all of this stuff. Here we are, you know, four men in the tech industry, all tech
[00:32:57.800 --> 00:33:04.040]   writers, sitting here discussing what we think the masses feel about privacy and the trade-offs.
[00:33:04.040 --> 00:33:10.440]   I mean, we're not most people. We're the echo chamber of the techno-gencia or whatever.
[00:33:10.440 --> 00:33:16.280]   I think Edward Snowden freaked out the masses because it was said that they could see where
[00:33:16.280 --> 00:33:22.280]   we go on the internet. People suddenly were like, wait, the NSA knows what porn sites I go to?
[00:33:22.280 --> 00:33:28.600]   Now that would freak out everybody. But I don't think they care what they say on their phones or
[00:33:28.600 --> 00:33:34.680]   what address they put into Google Maps. I think many younger people say, I don't care about that
[00:33:34.680 --> 00:33:41.560]   stuff. I think young, I think your generation is giving up. I don't. I genuinely don't. I feel
[00:33:41.560 --> 00:33:47.000]   like if I were you, I'd surrender. I mean, and you know what, plug brings up a good point.
[00:33:47.000 --> 00:33:53.400]   We're not you. You can call him Mr. Pogue if you. Dave. Dave. Dave. Is he allowed to call you David?
[00:33:53.400 --> 00:34:01.880]   That's inmate, Dave. Yeah. What is your, what is your prison nickname, by the way, is like
[00:34:01.880 --> 00:34:10.520]   Scar by now or what is? I guess like, okay, you know, a glass half full glass half empty
[00:34:10.520 --> 00:34:18.760]   a lot of stuff. I mean, I look at the sort of things like, you know, people teaming up online and,
[00:34:18.760 --> 00:34:26.920]   you know, trying to do things for net neutrality and the movement around that. I look at the reaction
[00:34:26.920 --> 00:34:31.160]   to all the NSA stuff. I look at popular culture shows like Mr. Robot and things like that.
[00:34:31.160 --> 00:34:34.520]   Mr. Robot was a great example of people really getting some real information.
[00:34:34.520 --> 00:34:38.760]   Yeah. I mean, this is, this is in, this is in the national dialogue, whether we like it or not.
[00:34:39.800 --> 00:34:44.920]   So I like to give people the benefit of the doubt and say that if they really knew what was happening,
[00:34:44.920 --> 00:34:49.720]   they would care because when I've seen examples of them being enlightened to what is happened,
[00:34:49.720 --> 00:34:53.480]   people seem to care. Yeah. And people have lots of questions for me, whether it's, you know,
[00:34:53.480 --> 00:34:59.000]   my aunts and uncles, or whether it's my, you know, middle school cousins or my peers
[00:34:59.000 --> 00:35:04.920]   at publications, some of whom are millennials and some of whom aren't. So I think, you know,
[00:35:04.920 --> 00:35:10.440]   it's just like, it's just like that city hall reporter where no one reads the work that they do
[00:35:10.440 --> 00:35:14.200]   and that, you know, local newspapers wondering why they're even, you know,
[00:35:14.200 --> 00:35:19.480]   have that person at those meetings. And then as soon as the corruption comes out, suddenly people
[00:35:19.480 --> 00:35:25.560]   will care. You know, in the LA Times, we had a situation, I used to work there years ago,
[00:35:25.560 --> 00:35:29.160]   where they want a Pulitzer for exposing corruption, this small city called Bell.
[00:35:29.160 --> 00:35:33.640]   And it was in South LA and no one cared about Bell, but then once the explosion was corrupted,
[00:35:33.640 --> 00:35:37.880]   people started caring and talking about it. I think right now we have a situation where
[00:35:37.880 --> 00:35:43.800]   it's easy to say no one cares about privacy and all of these things, but it's in the national
[00:35:43.800 --> 00:35:47.320]   conversation. It's in popular culture. We're talking about it, whether we like it or not.
[00:35:47.320 --> 00:35:54.760]   I think as journalists, as media, the whole fifth estate concept that we're here to...
[00:35:54.760 --> 00:35:58.360]   It's our job. It's our job. So give them the information. Now...
[00:35:58.360 --> 00:36:00.760]   Don't you think they feel helpless though when given that information?
[00:36:00.760 --> 00:36:03.640]   I don't like it, but what am I going to do about it?
[00:36:03.640 --> 00:36:09.720]   Well, the gadget reviewer, you know, like David Pogue, you know, I write some reviews from time
[00:36:09.720 --> 00:36:13.640]   to time, like myself. Part of our job is to do that service journalism to show them how to
[00:36:13.640 --> 00:36:16.120]   use these things and how to react and how to handle it.
[00:36:16.120 --> 00:36:19.960]   David, that's why you started Yahoo Tech was to talk to real people about technology.
[00:36:19.960 --> 00:36:27.640]   Yeah. And I can tell you, we routinely started out, we thought we would be with the zeitgeist,
[00:36:27.640 --> 00:36:32.360]   we had our thumbs on the pulse of the populace, and we did stories on how to do...
[00:36:32.360 --> 00:36:39.480]   How to set up encryption on both ends and how to get a completely anonymous web browsing experience.
[00:36:39.480 --> 00:36:44.680]   And we did, you know, how to not leave tracks. We would run these stories and guess how many people
[00:36:44.680 --> 00:36:48.360]   clicked on them. It's us that cares. It's not...
[00:36:48.360 --> 00:36:53.640]   It's interesting because on the radio, and I'm dealing again with...
[00:36:55.000 --> 00:36:59.640]   Okay, we're all just tech elite here, right? The unwashed masses, where I'm dealing with normal
[00:36:59.640 --> 00:37:06.520]   people. And I don't spend a lot of time trying to explain how to be safe. I talk about how to be
[00:37:06.520 --> 00:37:13.080]   safe, but how to be encrypted or private. Mostly what I do is I say you're not. And so you shouldn't
[00:37:13.080 --> 00:37:19.000]   put it on Facebook if you don't want somebody to see it, that it would be a mistake to assume you're
[00:37:19.000 --> 00:37:21.640]   communicating privately. Yeah.
[00:37:21.640 --> 00:37:27.080]   Unless you really take the time and the effort to... And that's the irony of all this. If you're
[00:37:27.080 --> 00:37:32.280]   up to no good, your likelihood of being interested in this is much higher than if you're just a normal
[00:37:32.280 --> 00:37:37.880]   person. I think that's... People don't seem to really understand the consequences of... I mean,
[00:37:37.880 --> 00:37:43.160]   they think from a... I think a lot of people think from almost like a 1984, like, police
[00:37:43.160 --> 00:37:47.480]   state mindset, where it's like, "I'm not doing anything bad." Why what should I worry? Yeah, yeah.
[00:37:47.480 --> 00:37:51.880]   And they'll be able to catch the people who are doing bad things. I think a lot of people
[00:37:51.880 --> 00:38:00.120]   feel that way. But that's not really what this country was founded on. That's where... Well,
[00:38:00.120 --> 00:38:05.960]   I think it's people who do care about history and about civil liberties get fired up about this
[00:38:05.960 --> 00:38:16.920]   stuff because they understand the differences between our country and China or Germany 60 years
[00:38:16.920 --> 00:38:22.600]   ago. Well, one of the differences is that we have the rule of law that we have a court system
[00:38:22.600 --> 00:38:25.720]   that protects, is supposed to, and I think does, for the most part, protect
[00:38:25.720 --> 00:38:31.560]   individual's rights while giving law enforcement the tools they need to investigate.
[00:38:31.560 --> 00:38:35.640]   And I think that that's a good thing. I think that's one of the strengths of this country is the
[00:38:35.640 --> 00:38:43.640]   rule of law. It's one of the real foundations of America's greatness. I also feel like this is
[00:38:43.640 --> 00:38:50.600]   unfortunately kind of moot at this point because of the ability to use strong encryption and any
[00:38:50.600 --> 00:38:56.520]   attempt to undermine strong encryption is misguided. But it's a difficult, I think it's a technical
[00:38:56.520 --> 00:39:01.720]   argument almost. Yeah. And it may be that that's not an argument politicians will ever understand.
[00:39:01.720 --> 00:39:06.920]   They don't ever want to say, "Oh, well, two plus two is four always no matter what, no matter what I
[00:39:06.920 --> 00:39:12.280]   think." They would like it to be negotiable. We're going to take a break. David Pogue is here from
[00:39:12.840 --> 00:39:21.240]   somewhere in Austin. It's so nice to have. It's so great to see everything going well. Now,
[00:39:21.240 --> 00:39:25.240]   wait a minute, David, though, didn't is that, did they close down a Yahoo, close down the
[00:39:25.240 --> 00:39:29.400]   separate tech channel? Are you now just folding into general coverage? What's the latest in that?
[00:39:29.400 --> 00:39:34.680]   They shut down a few of the digital magazines like Food and Travel. So far they haven't
[00:39:34.680 --> 00:39:39.880]   done it down Yahoo tech. So we're still soldering on. Good. Because I think you did a, I think
[00:39:39.880 --> 00:39:43.880]   you do a great job there. And it's a really great site. I'm glad to hear that it's not been
[00:39:43.880 --> 00:39:52.040]   subsumed. Well, thank you. Good, sir. Yeah. David's at South By for his panel coming up
[00:39:52.040 --> 00:39:56.520]   about startups coming up right after this show. So if you're in Austin rush over there,
[00:39:56.520 --> 00:40:01.160]   wherever there is, I'm sure you have a guide you can find it.
[00:40:01.160 --> 00:40:05.240]   Are you going to leave right after your panel or do you going to stick around for a little bit
[00:40:05.240 --> 00:40:11.480]   and have some party time? Oh my god. This, this is just absurd. So this is a, a Yahoo,
[00:40:11.480 --> 00:40:18.600]   on D based sponsored panel at seven tonight. And then tomorrow morning, I'm speaking in San Diego.
[00:40:18.600 --> 00:40:23.800]   And then the next day I'm back at South By for another panel. What? Wow. David.
[00:40:23.800 --> 00:40:29.800]   A big yo-yo horizontally across the country. Oh man. Well, I'm really glad we could borrow a
[00:40:29.800 --> 00:40:33.640]   little bit of your time this afternoon. Thank you for doing that. I appreciate it. Also with us
[00:40:33.640 --> 00:40:38.360]   from the Wall Street Journal, Nathan, all of various Giles. Always great to have you. Always a pleasure.
[00:40:38.360 --> 00:40:46.040]   Get the millennial point of view in here. You young people. And Mark Millian. I guess you guys
[00:40:46.040 --> 00:40:51.960]   met at the LA Times, I guess. Yeah. Yeah. Was that story? What was the HBO show that was based on
[00:40:51.960 --> 00:40:58.360]   the corrupt little city? Oh, oh, that. Well, there's the wire in Baltimore. And then there's all
[00:40:58.360 --> 00:41:02.600]   show me the hero, which was in New York. Now there's the new one. Oh, shoot. I can't remember.
[00:41:02.600 --> 00:41:07.880]   Yonkers, right? Yeah. Yeah. Yeah. I was just wondering if it's based on the LA Times story,
[00:41:07.880 --> 00:41:15.160]   because it's about a city, an LA city that's so corrupt that this is not true detective.
[00:41:15.160 --> 00:41:18.760]   True detective. The second, second scene. Yeah. That was not based on Bell. No, it wasn't.
[00:41:18.760 --> 00:41:23.400]   No, it wasn't. But it was Vichy. Yeah. Yeah. It reminded me a little about. Yeah. A little bit
[00:41:23.400 --> 00:41:26.840]   of Bell, a little bit of the city of industry, which is another city down there. That's right.
[00:41:26.840 --> 00:41:30.280]   True detective. Yeah. I don't know. You know, I've never heard any connections to Bell directly,
[00:41:30.280 --> 00:41:35.640]   but I'm sure they must have had some sort of inspiration there.
[00:41:35.640 --> 00:41:40.360]   Mark's currently at Bloomberg Business Week. And it's great to have all three of you.
[00:41:40.360 --> 00:41:44.840]   Our show today brought to you by Casper Mattress. And you know, it's great.
[00:41:44.840 --> 00:41:49.320]   It comes in a very compact box that you just bring it right back to you. You open it up.
[00:41:49.320 --> 00:41:53.800]   And in fact, here's mine. Casper Mattress came in. This is a queen-sized mattress in a very
[00:41:53.800 --> 00:41:58.280]   small box. You open it up. The mattress opens up. Smells great. Feels great.
[00:41:58.280 --> 00:42:04.680]   It's a combination of latex and memory foam that eliminates the negatives of those and
[00:42:04.680 --> 00:42:09.560]   brings you all the positives. So you get this beautiful firm mattress with a supple top
[00:42:09.560 --> 00:42:13.720]   that breathes man. And that's one thing I had a memory foam mattress I didn't like because
[00:42:13.720 --> 00:42:18.280]   it didn't breathe. This breathes. Oh, and is it comfy? It's cool throughout the night.
[00:42:19.320 --> 00:42:24.040]   And the nice thing is you buy this online, which saves you a lot of money because they don't have
[00:42:24.040 --> 00:42:29.320]   a middleman and resellers and showrooms. And you might say, well, wait, I want to sleep on it
[00:42:29.320 --> 00:42:36.360]   before I commit. You can. You have 100 days. Buying online is completely risk-free. Casper will
[00:42:36.360 --> 00:42:41.080]   give you free delivery. You sleep on that mattress for up to 100 days or 100 nights, I guess.
[00:42:41.080 --> 00:42:45.480]   And if you don't like it anytime in the first of the night, you call them up. The courier will
[00:42:45.480 --> 00:42:51.960]   come. They'll take it away. Refund you every penny. It is lovely. It's so nice. Good night's sleep.
[00:42:51.960 --> 00:42:58.440]   We're really learning is an important critical portion of health and wellness and state of mind.
[00:42:58.440 --> 00:43:02.840]   While you're there, check out Casper's pillows. I have Casper pillows too. I love them.
[00:43:02.840 --> 00:43:08.840]   Another kind of dual layer pillow that is, get the king size because it's like a body pillow and
[00:43:08.840 --> 00:43:14.680]   you just wrap yourself around it. Casper's mattresses and pillows made in the USA and very
[00:43:14.680 --> 00:43:18.520]   affordably start at $500 for a twin. But I'm going to make it even better when you go to
[00:43:18.520 --> 00:43:24.120]   Casper CASPER, C-A-S-P-E-R dot com slash twit and use our offer code to it. You'll get 50 bucks off.
[00:43:24.120 --> 00:43:30.680]   Some terms and conditions apply for details. Visit casper dot com slash terms. Casper dot
[00:43:30.680 --> 00:43:39.640]   com slash twit for the deal. Casper mattresses. You're going to love them. David, did you get a
[00:43:39.640 --> 00:43:45.240]   Galaxy S7 yet? I have not. My reporter colleague, Daniel Howley, reviewed it.
[00:43:45.240 --> 00:43:51.720]   Yeah. I'm looking at his review. In fact, you get a great lineup of pictures, iPhone 6 versus
[00:43:51.720 --> 00:43:56.600]   Galaxy S7. I've had the Galaxy S7 for a couple of weeks now. I have to say the best camera.
[00:43:56.600 --> 00:44:01.400]   Evo. You loved it. The light stuff is amazing. Unbelievable.
[00:44:01.400 --> 00:44:05.160]   Of course, it makes me interested in what Apple does in the fall with the
[00:44:05.720 --> 00:44:12.760]   S7, but the iPhone 7. But I think the S7 is just finally an Android phone. Battery life is great.
[00:44:12.760 --> 00:44:18.360]   Isn't it weird that they took away the waterproof and the memory card and then brought them back
[00:44:18.360 --> 00:44:24.760]   a generation later? I guess they listened. Right? Yeah. Yeah. But is that a marketing strategy or
[00:44:24.760 --> 00:44:31.000]   something? They made a mistake. So let's just bring it back. They made a mistake apparently,
[00:44:31.000 --> 00:44:33.160]   which I didn't realize. A lot of people dropped their phones and toilets.
[00:44:34.440 --> 00:44:41.400]   Would you want to use it after? You rinse it off. Yeah. It's $800. You would want to use it after.
[00:44:41.400 --> 00:44:46.920]   These are expensive phones. Incidentally, this phone is extremely fragile and slippery like a
[00:44:46.920 --> 00:44:52.200]   fish. You have a crack on the mic. I already dropped it and look at that crack. Yeah. Brutal.
[00:44:52.200 --> 00:44:57.240]   It's like a little fish in your hands, like a little sardine. But boy, you got to admit,
[00:44:57.240 --> 00:45:02.040]   even with a crack, it is so pretty and the edge screen. I really like that. But isn't that slippery?
[00:45:02.040 --> 00:45:06.280]   Because it's all glass. Yeah. It's like, yeah. I find the same with the iPhone 6.
[00:45:06.280 --> 00:45:12.200]   It was very much. Yeah. Same problem. I bought this, you know, $5 thing off of Amazon, but it's
[00:45:12.200 --> 00:45:18.200]   nothing but a grip layer. That's all it actually stopped dropping it. I wish I had a grip layer.
[00:45:18.200 --> 00:45:23.800]   I needed a grip layer. But this was so new that there were no cases. In fact, I'm still waiting
[00:45:23.800 --> 00:45:28.600]   for my case to come. So that's why it will do a little too late. A little too late. It also
[00:45:28.600 --> 00:45:32.360]   is a fingerprint magnet, but man, very, very happy. Just cover the pack with rubber cement.
[00:45:32.360 --> 00:45:38.200]   That'll work great. Oh, yeah. Nice. Well, I'll put in a case and then I won't have any issues with it.
[00:45:38.200 --> 00:45:42.520]   I have the answer to our trivia question from before the break. What was our trivia question?
[00:45:42.520 --> 00:45:48.520]   True detective season two is based on the city of Vernon, California. There you go. There you go.
[00:45:48.520 --> 00:45:53.000]   That's a great one. That's a great one. That's a city of corruption that happens to border on the
[00:45:53.000 --> 00:45:59.800]   city of Bell. Awesome. In Southeast. So Vichy was Vernon. Awesome. Vernon. I love LA.
[00:45:59.800 --> 00:46:06.120]   Really? What's funny is for those of us who aren't from LA, we just think of it as LA. But really,
[00:46:06.120 --> 00:46:10.760]   it's a bunch of fiefdoms. It's like Italy. Yes. It's not one. There's no one Italy. It's like all
[00:46:10.760 --> 00:46:15.560]   these little places and the same thing with LA. There's no one LA. It's true. People from Santa
[00:46:15.560 --> 00:46:20.120]   Monica don't talk to people Compton and people from Compton stay away from the people in the
[00:46:20.120 --> 00:46:24.840]   Venice Beach and the Venice Beach people are too high to care. So it all works out.
[00:46:24.840 --> 00:46:31.960]   Just great. I don't know. I don't know LA very well. It's funny. I've been on the radio in LA since
[00:46:31.960 --> 00:46:37.640]   19, since 2004. But I don't know what I'm talking about. It sounds like you don't. Yeah.
[00:46:37.640 --> 00:46:45.960]   Thank you. Thank you. It's kind of like how there are some people from San Francisco who don't go
[00:46:45.960 --> 00:46:50.520]   to Oakland and vice versa. I'm one of those guys who goes everywhere. I would go all over LA. I go
[00:46:50.520 --> 00:46:53.960]   all over the Bay Area. Good for you. I'm always trying to get my friends in San Francisco to go
[00:46:53.960 --> 00:46:59.880]   out to Oakland with me. It's tough. But you know, I wasn't Berkeley. That's kind of like Oakland.
[00:46:59.880 --> 00:47:06.680]   I love Oakland. I love Berkeley. It's Berkeley is like the Santa Monica of Oakland. It is. Berkeley
[00:47:06.680 --> 00:47:13.320]   is the Santa Monica of Oakland. Who'd you see? We saw the Mark Moore's dance company performing a
[00:47:13.320 --> 00:47:20.360]   dance to a handle or a choreo. Next week, we're seeing Hamilton. Have you seen Hamilton, David?
[00:47:20.360 --> 00:47:25.800]   I have not. Take a seat. Hold out for like the next year and a half. Broadway composer.
[00:47:25.800 --> 00:47:31.800]   You should don't you have connections? I do. I haven't pursued them. But maybe I should. You're
[00:47:31.800 --> 00:47:37.080]   a nice guy. You're not going to say don't you know who I am? I have connections. I gave them a lot
[00:47:37.080 --> 00:47:44.600]   of Hamilton's. And that worked a couple of a couple of Franklin's in there as well, I believe.
[00:47:44.600 --> 00:47:53.640]   But it's good. I'm really looking forward to it. I can't wait to see it. So I will be leaving right
[00:47:53.640 --> 00:47:58.680]   after the Apple event flying to New York City. But the Apple event is the invitations have gone out.
[00:47:58.680 --> 00:48:03.960]   March 21st, Apple uncharacteristically a whole two weeks before the event.
[00:48:05.240 --> 00:48:11.320]   David, did you get your invite? I did. Oh, what a shot. It was going to be one week before the
[00:48:11.320 --> 00:48:16.200]   event because this is, as you may know, delayed from the original date. Yeah. So that's what the
[00:48:16.200 --> 00:48:22.280]   rumor said. Why do you think it was delayed? Oh, I'm sure some manufacturing hiccup. You know,
[00:48:22.280 --> 00:48:26.200]   that stuff goes on. You don't think it has to do with the fact that the day after the Apple event,
[00:48:26.200 --> 00:48:34.920]   the court will rule on the FBI lawsuit. Oh, I thought this is. Yeah, very conspiracy-minded.
[00:48:35.160 --> 00:48:37.880]   But here's my, here's it's it's a pleat B. S. I know.
[00:48:37.880 --> 00:48:42.920]   But I think Tim Cook thought, hey, what we could do is we could have a really big event,
[00:48:42.920 --> 00:48:50.760]   get a lot of goodwill for Apple. I could address the issue on stage and then win or lose tomorrow.
[00:48:50.760 --> 00:48:54.120]   We'll have had our moment in the sun. You don't want to have it afterwards and you don't want to
[00:48:54.120 --> 00:49:01.320]   have it too far ahead. Why not write the day before? I sure. So you're being invited back again?
[00:49:01.320 --> 00:49:06.920]   No, no, I'm not. I am totally persona non grata there. I don't know what I did.
[00:49:06.920 --> 00:49:11.960]   Oh, I thought you said you're going to be there. No, I'll be watching it from afar.
[00:49:11.960 --> 00:49:17.720]   Oh, I see. Oh, no, no, no. I meant Tim Cook. I was speaking in I was pretending I was Tim Cook.
[00:49:17.720 --> 00:49:23.240]   I do that sometimes. Don't we all? Yeah. I can see the resemblance. I roll in the money. Yeah.
[00:49:23.240 --> 00:49:28.840]   No, so what are we going to see? We're going to see an iPhone. This is rumors, of course, Apple
[00:49:28.840 --> 00:49:34.840]   doesn't say. But you all are pretty well connected. iPhone SE, which will be a four-inch iPhone based
[00:49:34.840 --> 00:49:44.440]   on the iPhone 6 platform. So won't have forced touch. We'll have. Oh, no, they touch. No.
[00:49:44.440 --> 00:49:50.200]   I feel like if they don't put 3D touch in it, they have to. They have to. That's the new interface.
[00:49:50.200 --> 00:49:56.360]   I mean, if you want people to see this phone as equal to the 6 and 6s and the eventually 7 or
[00:49:56.360 --> 00:50:03.800]   whatever, but just in a smaller size, you can't leave out what is the most cutting edge signature,
[00:50:03.800 --> 00:50:09.960]   even if it's not the most useful. Do you use it? I do use it. I always forget. Yeah. Yeah. I've
[00:50:09.960 --> 00:50:15.560]   gotten used to using it. David, you press hard on your screen sometime. Believe it or not, I don't
[00:50:15.560 --> 00:50:22.040]   have a 6s. I have a corporate issued 6. So I don't press on my screen. You don't press on your
[00:50:22.040 --> 00:50:26.840]   screen. And if you did, it would be fruitless. Actually, I press on my laptop screen all the
[00:50:26.840 --> 00:50:33.000]   time and all I get is dense. It's very interesting. It's not good. So the iPhone SE, which is not
[00:50:33.000 --> 00:50:37.320]   necessarily a low-cost iPhone, but a small iPhone. That's really the other. Yeah, which is smart.
[00:50:37.320 --> 00:50:42.440]   I mean, there are so many people who miss the small. My wife is still using a 5s because she's
[00:50:42.440 --> 00:50:46.200]   like, I'm not getting, she has small hands. She's like, I'm not getting that big phone. I'm not doing
[00:50:46.200 --> 00:50:51.000]   it. Meanwhile, her signal strength isn't as good as mine or cameras, not as good as mine. So,
[00:50:51.960 --> 00:50:55.560]   people like that will be very happy. And they've already gone big, right? So this is the only other
[00:50:55.560 --> 00:51:01.560]   direction they can go to expand the market. They have three iPad sizes, now three phone sizes,
[00:51:01.560 --> 00:51:07.560]   like, why not? You know, if the demand's there. Seven days, 19 hours, 10 minutes, and seven seconds
[00:51:07.560 --> 00:51:13.000]   from now, we'll find out. Can you believe the car? Oh, this is the telegram. The telegram has a
[00:51:13.000 --> 00:51:19.000]   countdown timer on their website. That's crazy. They're not even in the US. That's crazy.
[00:51:20.040 --> 00:51:24.120]   So it's funny, Nate said, well, you got a computer I could use. I said, well, what do you want? He
[00:51:24.120 --> 00:51:28.280]   said, you don't have an iPad pro lying around. And I did. It was, it was my request. So that's,
[00:51:28.280 --> 00:51:33.880]   that would be your preferred platform. You know, I've been, I've been using one. And I actually,
[00:51:33.880 --> 00:51:39.400]   I actually do like it. You know, it's, it's not size that you like, I guess the size in that it's
[00:51:39.400 --> 00:51:43.640]   just, you know, really light. The keyboard case is still kind of awkward. It's when you hold it up.
[00:51:43.640 --> 00:51:47.560]   The pencil you use that? Yeah, I do. I like to draw. I do like the pencil. So that's the other
[00:51:47.560 --> 00:51:51.800]   rumor is that there will be a new iPad. They didn't announce one in the fall, but it won't be an iPad
[00:51:51.800 --> 00:51:57.800]   Air three or four or whatever the next one is. It will be an iPad, a little iPad pro. I'd like that.
[00:51:57.800 --> 00:52:01.720]   That would make sense. Yeah, I kind of wish the, the pencil worked on the iPad mini that I have.
[00:52:01.720 --> 00:52:05.400]   Yeah, don't you? Yeah, it's like little, little portable kind of thing. I, but I mean,
[00:52:05.400 --> 00:52:08.840]   when you're doing real work, you still need a laptop. That's just the fact that I know they
[00:52:08.840 --> 00:52:13.960]   tried to push it this as a laptop replaceable. If all you're doing is writing and checking email,
[00:52:13.960 --> 00:52:18.280]   this is great. Right. That's awesome. But that's not all I do. Sometimes I want to edit videos,
[00:52:18.280 --> 00:52:23.320]   sometimes I'm editing photos, sometimes I need, you know, actual real robust software. I think
[00:52:23.320 --> 00:52:29.480]   it could get there, but you know, it's, it's early days. David, what do you think? I'm also hearing
[00:52:29.480 --> 00:52:35.800]   maybe a refresh of the watch. And I think something not a lot of people are talking about, but I
[00:52:35.800 --> 00:52:42.040]   have read a refresh of the 12 inch MacBook, which is really good. There's so many cool things about
[00:52:42.040 --> 00:52:46.440]   it. It's just slow to do anything with it. I love my MacBook. I love how thin it is,
[00:52:46.440 --> 00:52:52.120]   how light it is. The screen is great. It's a retina display. I like the keyboard. 12 inches is
[00:52:52.120 --> 00:52:55.800]   just right now. You're unusual in that because a lot of people complain about the keyboard. Very
[00:52:55.800 --> 00:53:00.280]   little travel on it. Yeah, I like it. You get you're, you're competent with it. Yeah, I'm cool. I do a
[00:53:00.280 --> 00:53:06.680]   lot of typos on my MacBook, but it is my Mac of choice. I really like that. So what would you do?
[00:53:06.680 --> 00:53:11.800]   Would you make it faster, David? Is that what you would do? I would make it faster. I wouldn't mind
[00:53:11.800 --> 00:53:18.200]   another USBC jack. On the other side, that's what Google did with the Pixel. Left side and right side.
[00:53:18.200 --> 00:53:23.160]   That way you can power and then connect or whatever. Speed is definitely an issue. Oh, you've got one.
[00:53:23.160 --> 00:53:28.360]   Yeah. No, no, no, no. That's not a MacBook. This is the new MacBook, whatever. The one with the
[00:53:28.360 --> 00:53:36.760]   single USB-C port. I've never seen a gray one. All mine are gold. Oh, yeah, they do gold silver and gray.
[00:53:40.520 --> 00:53:47.560]   I only buy gold. I only buy gold things now. I even got the rose gold iPhone. I don't know why.
[00:53:47.560 --> 00:53:56.280]   I think it's age. I also have plastic covers of my furniture. Is that strange? Is that weird?
[00:53:56.280 --> 00:54:01.640]   A little bit. Is that weird? Yeah. I want to go. I've literally never seen a gray one. I like the
[00:54:01.640 --> 00:54:08.360]   look of it. It's pretty. Yeah. It's very nice. Very industrial. Yeah. It looks like you work on it.
[00:54:09.400 --> 00:54:15.800]   Mine. It looks like I take it to ballets and dans with it. No, I really, I think it's a great
[00:54:15.800 --> 00:54:21.880]   size and I would love to see an upgrade. Yeah. Apple should probably upgrade all of its laptops
[00:54:21.880 --> 00:54:27.560]   because the Skylake processor is out until I put out the laptop version of that. I doubt we'd see
[00:54:27.560 --> 00:54:33.160]   that in a MacBook, though, would we? Are they going to do the mobile stick with the mobile?
[00:54:33.160 --> 00:54:36.840]   Yeah. Maybe the MacBook Pro. Yeah, they'll do it in the Pro. Yeah. They'll do it in the Air.
[00:54:36.840 --> 00:54:42.200]   Good. So I wonder, maybe we'll see a whole new, maybe, you know, sometimes Apple slips those out
[00:54:42.200 --> 00:54:46.440]   and doesn't do an event. This event is not a big event, right, Dave? But what does the invitation say?
[00:54:46.440 --> 00:54:52.040]   Loop me in. Loop us in. Let us loop you in or something like that. Let us loop you in. Yeah.
[00:54:52.040 --> 00:54:57.400]   Is there anything to be made of that? Infinite Loop in Cupertino. Oh, it's a small, small
[00:54:57.400 --> 00:55:01.480]   intimate. I thought maybe they were going to release a loop for the pencil for the iPad Pro
[00:55:01.480 --> 00:55:04.840]   was going to be the big product. Don't get any hopes. You're going to have a special event for that.
[00:55:05.480 --> 00:55:11.800]   Well, it's a small event. It's at the Apple cost 90 dollars. 90 dollar loop.
[00:55:11.800 --> 00:55:16.760]   That's a small venue, right? I mean, that's like a few hundred people. Yeah. They're smallest
[00:55:16.760 --> 00:55:21.560]   venue. They do events in. Oh, but we've been looking, haven't we, at the new theater?
[00:55:21.560 --> 00:55:27.560]   I'm hoping, David, maybe you can help. I'd like to get an invitation to the first event at the new
[00:55:27.560 --> 00:55:34.440]   campus next year. That's the one I want to have you seen that they put the roof on the theater?
[00:55:34.440 --> 00:55:40.760]   Oh, my gosh. That thing is looking really wild. Yeah. I was looking at that exact article.
[00:55:40.760 --> 00:55:46.440]   Scroll down and these are pictures Apple released, but Mashable had them all in beautiful. Oh, I see.
[00:55:46.440 --> 00:55:51.320]   Yeah. Look at these. They're gorgeous. And that's just the theater. So the theater is actually
[00:55:51.320 --> 00:55:57.640]   underground and that circular part. That's the lobby. That's the lobby. The lobby. Yeah.
[00:55:57.640 --> 00:56:04.760]   The lobby with a 360 degree view of the Apple campus. It just floats. You check in with the
[00:56:04.760 --> 00:56:12.440]   attendant there. What's holding it up? There's nothing holding it up. That's a trade secret, Leo.
[00:56:12.440 --> 00:56:21.400]   It's glass walls. Glass doesn't hold roofs. What's holding it up? What did it say? Eight tons that
[00:56:21.400 --> 00:56:28.840]   thing was on glass. I'm not going in there. Sweet in architecture.
[00:56:28.840 --> 00:56:35.720]   Looks scary. I thought you said Apple was good at math. Yeah, well, they know the math anyway.
[00:56:35.720 --> 00:56:45.080]   No, it's the largest freestanding roof in the world. It's a carbon fiber roof. So even though
[00:56:45.080 --> 00:56:49.560]   it weighs, what did you say? Eight tons. That's light. That's light for a roof of that size.
[00:56:49.560 --> 00:56:57.160]   It's made in Dubai. I don't know how they got it here. Can you imagine the FedEx bill?
[00:56:57.160 --> 00:57:06.040]   They're going to really big box. So yeah, so that's one thing. That would be the event.
[00:57:06.040 --> 00:57:09.640]   The first event they hold there, which would be presumably next year round, maybe around this
[00:57:09.640 --> 00:57:14.840]   time, maybe maybe the fall next year, iPhone 8. But that would be the event you'd want to go to.
[00:57:15.320 --> 00:57:21.480]   It'd be the first one in that beautiful theater. And I would guess, they've been
[00:57:21.480 --> 00:57:24.920]   coy about how they're going to name the new campus, but of course they'll name it after Steve,
[00:57:24.920 --> 00:57:29.240]   right? I would guess this is the Steve Jobs Theater or something like that.
[00:57:29.240 --> 00:57:33.400]   Wouldn't that be the right thing to do? I mean, he was the guy. He was the showman.
[00:57:33.400 --> 00:57:38.600]   The stage was his, right? The stage was his. Yeah, that would actually be kind of a nice little
[00:57:38.600 --> 00:57:45.160]   Steve Jobs Theater. Well, anyway, David, you're not going to pull any strings,
[00:57:45.160 --> 00:57:48.600]   are you? I could tell you just standing back. This guy can't even get into Hamilton. Why are
[00:57:48.600 --> 00:57:54.920]   you asking? The problem is I can't offer them Franklin's and Hamilton's to get into an
[00:57:54.920 --> 00:58:00.040]   Apple event. It doesn't work. Well, Leo, I can get you in, but I haven't heard you're off for you.
[00:58:03.320 --> 00:58:08.920]   So article and business insider about Steve's widow, Lorraine, who was a really, really,
[00:58:08.920 --> 00:58:14.920]   really sweet person. Really great. Not that mysterious. 50, she's in the 50 richest people
[00:58:14.920 --> 00:58:21.560]   in the world, according to wealth X, 14.4 billion dollars. So offering her a Hamilton is not going
[00:58:21.560 --> 00:58:28.120]   to work. No, maybe a friend. She's probably not the way to go. That's not the trick to get in.
[00:58:29.160 --> 00:58:34.520]   I met her and Steve many years ago. He was still at Pixar and she was just great. They had recently
[00:58:34.520 --> 00:58:38.760]   married. They had Reed was, I think, two. He was the same age as Abby, my daughter.
[00:58:38.760 --> 00:58:45.960]   It really is just a wonderful person. I hope she's doing well.
[00:58:45.960 --> 00:58:52.440]   One of the problems, of course, with the iPad is sales. Seems to have tapered off
[00:58:53.640 --> 00:59:00.520]   a little bit. The question people are asking is, is an iPad Pro, a small iPad Pro, is that going
[00:59:00.520 --> 00:59:10.440]   to make a difference? No. The answer is pretty straightforward. Why? That is correct. Why?
[00:59:10.440 --> 00:59:17.400]   They just seem to be doing a Samsung. Okay, sales of the 10 ish are slowing. Let's make one.
[00:59:17.400 --> 00:59:22.200]   There's 11 inches. No one's buying the L. Let's make nine inches. I mean, they can only milk it so far.
[00:59:23.240 --> 00:59:26.520]   Is it everybody who wanted an iPad has an iPad and that's that?
[00:59:26.520 --> 00:59:31.080]   I think the upgraded cycle on an iPad are more like computers and they are like phones.
[00:59:31.080 --> 00:59:36.840]   I think a lot of people are doing more of their computing on phones and seeing less of a need
[00:59:36.840 --> 00:59:40.360]   to upgrade their iPad and less of a need to upgrade their computers.
[00:59:40.360 --> 00:59:46.200]   Yeah, me for sure. Nailed it. Yeah, that's it. I have an iPad mini, but it's the first generation.
[00:59:48.200 --> 00:59:53.000]   Well, there's no need to. There's no need to. It's not like I'm doing real work on it. I'm watching
[00:59:53.000 --> 00:59:58.680]   videos and reading books, playing games. So, isn't that the iPad is not a success?
[00:59:58.680 --> 01:00:02.600]   It's a platform. It's a success. It's the most popular tablet in the entire world.
[01:00:02.600 --> 01:00:04.280]   Right. It's like the defining... That's not saying much.
[01:00:04.280 --> 01:00:07.720]   Well, but... Because the other guys aren't selling all that well.
[01:00:07.720 --> 01:00:11.000]   But it's true. I mean, like if you're going to buy a tablet,
[01:00:11.000 --> 01:00:15.240]   you know, seven out of ten times or something, it's like an iPad. Yeah, basically.
[01:00:15.240 --> 01:00:20.600]   Yeah, so... You know what I think is so weird? It seems like everybody chases each other in this
[01:00:20.600 --> 01:00:24.920]   industry, right? Oh, here's an iPad. Now everybody else is going to have a tablet. Why is no one
[01:00:24.920 --> 01:00:30.360]   chasing the Amazon Echo? Why is there any rules? I agree with you on that. Yeah, Sonos is now
[01:00:30.360 --> 01:00:34.600]   chasing. Oh, no, no, no. They cut some staff and said that they're going to refocus on. They buried
[01:00:34.600 --> 01:00:38.680]   the lead on that one. That was all... I think that was all spin. We're going to lay off people. Oh,
[01:00:38.680 --> 01:00:42.600]   by the way, we're going to do voice. Oh, yeah, they're definitely trying to... We're going to do voice.
[01:00:42.600 --> 01:01:12.600]   No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no
[01:01:12.600 --> 01:01:18.120]   But you have to wonder, is it too late for Sonos? You know, there's a lot of competition.
[01:01:18.120 --> 01:01:22.840]   Everybody's buying other people's speakers. If you could say you use something like a Chromecast
[01:01:22.840 --> 01:01:27.960]   audio to enable streaming. I think the Chromecast does pretty good multi-room.
[01:01:27.960 --> 01:01:33.800]   And maybe add a dot to give it voice. Or maybe Amazon, don't you think Amazon could do something
[01:01:33.800 --> 01:01:40.200]   like this? Yeah, well, I think it's probably not too late. I've evidenced by the fact that Amazon
[01:01:40.200 --> 01:01:45.080]   came out of nowhere with the speaker. And it's been wildly successful. They're working on a whole
[01:01:45.080 --> 01:01:51.160]   new line of them. I think with the Chromecast and Apple's airport express thing and some of the
[01:01:51.160 --> 01:01:56.440]   stuff they did with Apple TV on audio... And they tried this? They tried this, but people just want
[01:01:56.440 --> 01:02:00.440]   a device that they can plug in. Because as a speaker, it's easy. It's straightforward.
[01:02:00.440 --> 01:02:05.080]   Exactly. Yeah. And Apple has not really done a good job in speakers. They had the HiFi,
[01:02:05.080 --> 01:02:10.040]   which was a disaster. The iPod HiFi many years ago. Yeah. That's what... I went to that.
[01:02:10.040 --> 01:02:13.880]   Overpriced dock. Steve Jobs said I'm selling all of my high-priced stereo
[01:02:13.880 --> 01:02:18.200]   Quebec. This is so good. That's when I thought, "You know what? This guy's a good marketer."
[01:02:18.200 --> 01:02:26.760]   And I didn't really buy it that he sold his Macintosh 2-Bamp and his clipshorns. I'm sure
[01:02:26.760 --> 01:02:33.320]   he kept those around. You're probably right. Yeah, I don't think that HiFi sold all that well.
[01:02:33.320 --> 01:02:36.920]   No, it did not. All right. We're going to take a break. Go ahead, David.
[01:02:36.920 --> 01:02:40.520]   I was just going to say there's a self-help group somewhere for people who bought
[01:02:40.520 --> 01:02:46.840]   HiFi. The Macintosh TV and the HiFi and all these things that quickly went away.
[01:02:46.840 --> 01:02:52.520]   The land of 20th anniversary, Mac. I have one over there, David. I'm one of those guys. I have one
[01:02:52.520 --> 01:03:01.080]   over there, the 20th anniversary, Mac. It's an amazing thing. It must be very... It must be
[01:03:01.080 --> 01:03:05.560]   difficult, I think, for these companies. Now let's put ourselves in their shoes to make a product,
[01:03:05.560 --> 01:03:09.160]   spend years on it. Really believe in the product. I think it's the greatest thing ever, and people
[01:03:09.160 --> 01:03:18.040]   don't buy it. It must be very... You scratch your head. Why? What do we do wrong? Does anybody really
[01:03:18.040 --> 01:03:24.120]   understand the American consumer? Oh, look, here it comes. I bought it. I ought to get some
[01:03:24.120 --> 01:03:31.560]   mileage out of it. Blow the dust off of it, though. And it's gold, your favorite color.
[01:03:31.560 --> 01:03:37.080]   Well, it's kind of gold. It's bronze-ish. This is when... Oh, don't forget, by the way,
[01:03:37.080 --> 01:03:44.680]   the entire computer is stored in the subwoofer. It looks kind of like a precursor to the
[01:03:44.680 --> 01:03:49.400]   current Mac Pro. Yeah, the subwoofer is where it's a trash can. It's a Bose subwoofer, and this is
[01:03:49.400 --> 01:03:53.720]   my favorite part when I give me the connector, because I love the connector. This is how you connect.
[01:03:54.520 --> 01:04:01.880]   This is pre-USB. This is how you connect to the subwoofer. This is like an 82-pin din. Is that
[01:04:01.880 --> 01:04:07.240]   what we call planned obsolescence? What the? What? This is not a... You'll never see this connector
[01:04:07.240 --> 01:04:12.200]   at Halstead. This is... What the...? I think they use those in the Norang.
[01:04:12.200 --> 01:04:19.480]   But they had to do this because the computer, everything, was in that subwoofer,
[01:04:20.440 --> 01:04:25.000]   and you put that on a desk, and then you had this... They thought this was the greatest thing ever.
[01:04:25.000 --> 01:04:29.240]   Johnny Ive did this one, right? This is a Johnny Ive. This one was his first design.
[01:04:29.240 --> 01:04:32.920]   It was it? It wasn't at $10,000. Oh, yeah, that.
[01:04:32.920 --> 01:04:38.920]   So, here's a hint. So, did you buy this new, or did you get the wrong... Oh, you know what,
[01:04:38.920 --> 01:04:43.480]   I didn't buy this. Somebody used it. Somebody gifted. No, I didn't even buy it ever.
[01:04:43.480 --> 01:04:48.920]   One of our wonderful viewers... It appeared one day. I don't even know how it happened.
[01:04:49.560 --> 01:04:55.400]   One of our wonderful viewers brought it to us. I guess he spent $10,000. I love stuff like this.
[01:04:55.400 --> 01:05:02.600]   Like this, the Nexus Q, Google Glass. I mean, just these products that are full of good ideas,
[01:05:02.600 --> 01:05:08.120]   but the execution maybe isn't right. The Q is interesting because Google never even shipped it.
[01:05:08.120 --> 01:05:13.320]   No. They gave up. Well, they had some pre-sales. They shipped it to the people who bought it,
[01:05:13.320 --> 01:05:15.800]   and then they canceled it. Oh, to the... Yeah. So, if you actually paid for it...
[01:05:15.800 --> 01:05:18.200]   You would have gotten it. And people went to Google, I have got it.
[01:05:18.200 --> 01:05:24.040]   Yeah, I have one. Yeah. Do you use it? No, no. You can anymore. They killed the Android app,
[01:05:24.040 --> 01:05:31.560]   and support for it. It's like this beautiful art sculpture that is useless, but man, it had
[01:05:31.560 --> 01:05:38.840]   like a really great amp in it, and it was just too niche for its own good. But without it,
[01:05:38.840 --> 01:05:44.600]   would we have Chromecast? Right. Right. Exactly. All right, let's take a break. David Pogue is in
[01:05:44.600 --> 01:05:50.520]   the beautiful Austin area, where it's 96 degrees. I don't know how you stay so cool, David. It really,
[01:05:50.520 --> 01:05:55.240]   I mean... Oh, I'm in the shade. By the way, it's not really a jail. There's the lovely
[01:05:55.240 --> 01:06:01.000]   W Hotel rooftop. Far from it. That looks like... White collar prison. You know what that looks like?
[01:06:01.000 --> 01:06:04.600]   That looks like the place in Huli that they put you if they don't want to fire you.
[01:06:04.600 --> 01:06:12.440]   Yeah, Riffa, that's right. You got nothing to do. That's Yahoo's special rooftop office for David.
[01:06:12.440 --> 01:06:21.560]   He's not in Austin. He's just not going to comment on that at all. He's just going to sit this one out.
[01:06:21.560 --> 01:06:27.000]   I'm in trouble with the audio. What? You're breaking up. You're breaking up.
[01:06:27.000 --> 01:06:32.920]   Jason Oliveris Giles is also with us from the Wall Street Journal. Mr. Oliveris Giles. Yes, sir.
[01:06:32.920 --> 01:06:38.680]   And Mark Millian from Bloomberg Business Week. Mr. Millian, Mr. Pogue, Mr. Oliveris Giles.
[01:06:39.400 --> 01:06:45.480]   My team for this week in tech. We had a great week this week. Did you see all the stuff we did?
[01:06:45.480 --> 01:06:51.160]   You know what? Just in case you missed anything, we put together a small movie to show you.
[01:06:51.160 --> 01:06:54.760]   Previously on Twitter.
[01:06:54.760 --> 01:06:56.360]   Unless you're on your one.
[01:06:56.360 --> 01:06:58.120]   Unless you're on your one.
[01:06:58.120 --> 01:06:59.720]   You tell us all your one.
[01:06:59.720 --> 01:07:06.200]   This week in Google. So Aaron Nukem brought in this. Now, if you're a nerd, an old school nerd,
[01:07:06.200 --> 01:07:09.720]   you'll recognize a 20-sided dice.
[01:07:09.720 --> 01:07:11.240]   Oh, that's awesome.
[01:07:11.240 --> 01:07:12.440]   It uses an Arduino.
[01:07:12.440 --> 01:07:13.400]   Uses an accelerometer.
[01:07:13.400 --> 01:07:16.600]   And bring this to your next D&D. You'll be a superstar.
[01:07:16.600 --> 01:07:21.880]   Know how. You'll know how to choose between a Chromebook or a cloud book.
[01:07:21.880 --> 01:07:26.120]   If this had been the netbook, the netbook would have survived. Back then.
[01:07:26.120 --> 01:07:28.280]   Android App Arena.
[01:07:28.280 --> 01:07:32.360]   Have you ever wanted to try on somebody else's face and not in a leather face
[01:07:32.360 --> 01:07:34.440]   horror movie sort of way? That would be weird.
[01:07:34.440 --> 01:07:38.600]   And app called Mascarade is here to creep you out.
[01:07:38.600 --> 01:07:41.000]   Even Facebook agrees this app is awesome.
[01:07:41.000 --> 01:07:44.040]   They announced just today that they bought the company.
[01:07:44.040 --> 01:07:45.880]   Twit. Tell your boss.
[01:07:45.880 --> 01:07:47.080]   It's job related.
[01:07:47.080 --> 01:07:52.680]   It's just trying to deal with secret courts, making secret judgments, makes me,
[01:07:52.680 --> 01:07:55.560]   you know, more nervous than a long-tail cat in a room full of rocking chairs.
[01:07:55.560 --> 01:07:58.440]   Okay, got it.
[01:07:58.440 --> 01:08:03.480]   It's funny. Usually Ian brings us Britishism, but that was a Texasism.
[01:08:04.360 --> 01:08:07.880]   Our show today brought to you by carbonite. It's time to back up.
[01:08:07.880 --> 01:08:11.960]   Oh, man, I had a painful call on the radio show today. Guy calls up Omar.
[01:08:11.960 --> 01:08:15.080]   He says we got bit by ransomware.
[01:08:15.080 --> 01:08:19.320]   And I said, "A business?" He said, "Yeah."
[01:08:19.320 --> 01:08:23.480]   I said, "Well, that's okay because you have a backup, right?"
[01:08:23.480 --> 01:08:28.200]   He said, "The ransomware got copied to the backup.
[01:08:28.200 --> 01:08:30.520]   So the only backup we've got is two weeks ago."
[01:08:31.400 --> 01:08:33.480]   So the first thing I said is fire your IT guy.
[01:08:33.480 --> 01:08:36.120]   So you're not the IT guy, are you? He said, "No."
[01:08:36.120 --> 01:08:38.840]   I said, "Fire your IT guy because he didn't do right by you."
[01:08:38.840 --> 01:08:40.760]   Next, get carbonite.
[01:08:40.760 --> 01:08:45.240]   Actually, carbonite on their website, if you go to carbonite.com and you go to resources
[01:08:45.240 --> 01:08:49.880]   up at the top there, and there's a white paper, they have a white paper on what to do
[01:08:49.880 --> 01:08:53.480]   to protect yourself from ransomware. Carbonite is a great solution.
[01:08:53.480 --> 01:08:54.840]   It's backup done right.
[01:08:54.840 --> 01:08:57.960]   See, what carbonite does is it does versioning.
[01:08:57.960 --> 01:09:03.720]   So even if you get stuff encrypted on your hard drive, and even if it backs up the encrypted
[01:09:03.720 --> 01:09:09.000]   files, you can always get back to the latest version right before the encryption.
[01:09:09.000 --> 01:09:11.560]   It's just the best.
[01:09:11.560 --> 01:09:15.640]   If you're in business, if you're at home, automatic cloud backup is the solution.
[01:09:15.640 --> 01:09:17.560]   You don't want to backup next year.
[01:09:17.560 --> 01:09:20.120]   Well, you could backup your next year computer, but it shouldn't be your only backup.
[01:09:20.120 --> 01:09:24.680]   You've got to get it off site as well in case of a big disaster like fire or flood.
[01:09:25.400 --> 01:09:28.840]   Carbonite cloud backup will protect the files that keep your business or your home running
[01:09:28.840 --> 01:09:31.640]   smoothly. One and a half million people use carbonite.
[01:09:31.640 --> 01:09:33.160]   This is the stat I love.
[01:09:33.160 --> 01:09:37.480]   They have restored 50 billion files to date.
[01:09:37.480 --> 01:09:41.320]   That's 50 billion documents that would have been lost forever.
[01:09:41.320 --> 01:09:43.960]   That's kind of an amazing number.
[01:09:43.960 --> 01:09:47.880]   Whether it's human error or disaster, carbonite protects you.
[01:09:47.880 --> 01:09:49.640]   Start your free trial at carbonite.com.
[01:09:49.640 --> 01:09:51.320]   No credit card required.
[01:09:51.320 --> 01:09:55.080]   Use the offer code quit and get two free bonus months if you decide to buy.
[01:09:55.080 --> 01:09:57.480]   Right now is a good time to get 30% off as well.
[01:09:57.480 --> 01:09:59.880]   Use the offer code twit though to get that benefit.
[01:09:59.880 --> 01:10:01.480]   Carbonite.com.
[01:10:01.480 --> 01:10:05.240]   You got to back it up to get it back to it right with carbonite.
[01:10:05.240 --> 01:10:06.680]   I saw it by this poor guy Omar.
[01:10:06.680 --> 01:10:09.080]   He was calling saying, "Was there anything I can do?"
[01:10:09.080 --> 01:10:12.200]   And I said, "No, and don't pay the ransom either.
[01:10:12.200 --> 01:10:16.280]   Don't do like that hospital in LA did $17,000 ransom."
[01:10:16.280 --> 01:10:20.840]   A lot of times when it happens with the ransom ware, it's kind of bittersweet.
[01:10:20.840 --> 01:10:27.480]   His law enforcement cuts off the ransom ware server, so you pay them your Bitcoin.
[01:10:27.480 --> 01:10:28.760]   And then, but the server's down.
[01:10:28.760 --> 01:10:30.280]   You can't get your decryption key.
[01:10:30.280 --> 01:10:33.000]   So once it happens, don't pay them.
[01:10:33.000 --> 01:10:35.240]   Just bite the bullet and have a good backup.
[01:10:35.240 --> 01:10:38.280]   Have a good backup.
[01:10:38.280 --> 01:10:40.280]   That's something we can tell our readers.
[01:10:40.280 --> 01:10:40.600]   Yep.
[01:10:40.600 --> 01:10:43.560]   That's kind of one of the most important things to do.
[01:10:43.560 --> 01:10:47.720]   You guys are college basketball fans, March Bandits.
[01:10:47.720 --> 01:10:49.400]   You got the bug.
[01:10:49.400 --> 01:10:49.880]   Oh yeah.
[01:10:49.880 --> 01:10:50.440]   Go Terps.
[01:10:51.400 --> 01:10:51.880]   Terps.
[01:10:51.880 --> 01:10:53.160]   Those are the terra pens.
[01:10:53.160 --> 01:10:54.840]   Terra pens, yes.
[01:10:54.840 --> 01:10:55.800]   It's a type of turtle.
[01:10:55.800 --> 01:10:57.720]   Maryland.
[01:10:57.720 --> 01:10:59.560]   Maryland Terrapins.
[01:10:59.560 --> 01:11:01.720]   But they're called the Terps for no reasons.
[01:11:01.720 --> 01:11:03.000]   No, nobody understands.
[01:11:03.000 --> 01:11:05.800]   Are you a Terp?
[01:11:05.800 --> 01:11:06.600]   I am a Terp.
[01:11:06.600 --> 01:11:07.480]   And you, Nathan?
[01:11:07.480 --> 01:11:08.680]   I'm an Arizona wildcat.
[01:11:08.680 --> 01:11:09.240]   Wildcat.
[01:11:09.240 --> 01:11:12.040]   Gonna win the PEC-12 this year.
[01:11:12.040 --> 01:11:16.760]   David, we just look in horror because of course our team, the Bulldogs,
[01:11:16.760 --> 01:11:20.200]   has never been to the NCAA tournament.
[01:11:20.680 --> 01:11:21.400]   And never will.
[01:11:21.400 --> 01:11:21.960]   Which Bulldogs?
[01:11:21.960 --> 01:11:22.760]   Which Bulldogs?
[01:11:22.760 --> 01:11:23.560]   Never will.
[01:11:23.560 --> 01:11:24.040]   Never will.
[01:11:24.040 --> 01:11:24.600]   The New Haven.
[01:11:24.600 --> 01:11:25.560]   Never will.
[01:11:25.560 --> 01:11:27.720]   David and I went to the best school in Connecticut.
[01:11:27.720 --> 01:11:31.800]   Something wrong with your jaw there.
[01:11:31.800 --> 01:11:37.320]   Well, if you can't go to the March Bandits, you can't open your mouth.
[01:11:37.320 --> 01:11:39.880]   I don't like that.
[01:11:39.880 --> 01:11:42.760]   I say, we were whiffing poof, David.
[01:11:42.760 --> 01:11:44.920]   It was not a whiffing poof.
[01:11:44.920 --> 01:11:46.040]   I was an alley cat.
[01:11:46.040 --> 01:11:46.760]   An alley cat.
[01:11:46.760 --> 01:11:49.800]   I had a feeling you might be in one of those great singing groups.
[01:11:50.680 --> 01:11:52.120]   [LAUGHTER]
[01:11:52.120 --> 01:11:54.840]   The problem with a lock, y'all like that, is you can't be whiffing poof.
[01:11:54.840 --> 01:11:55.960]   You can't be whiffing poof.
[01:11:55.960 --> 01:11:57.640]   We are little lost lambs.
[01:11:57.640 --> 01:11:59.480]   We've gone straight, blah, blah, blah.
[01:11:59.480 --> 01:12:06.840]   So seriously, if you go to a school that doesn't participate in this way,
[01:12:06.840 --> 01:12:08.520]   you really don't get into March Bandits.
[01:12:08.520 --> 01:12:11.720]   True.
[01:12:11.720 --> 01:12:15.000]   Yeah, was there much competition between your school in UConn?
[01:12:15.000 --> 01:12:15.480]   Because you could--
[01:12:15.480 --> 01:12:18.120]   University of Connecticut, though those Huskies are too good for us.
[01:12:18.120 --> 01:12:18.520]   Yeah.
[01:12:18.520 --> 01:12:20.120]   I mean, you could adopt UConn as a--
[01:12:20.120 --> 01:12:20.760]   You could root for them.
[01:12:20.760 --> 01:12:21.960]   You could root for UConn.
[01:12:21.960 --> 01:12:23.640]   I'm not rooting for UConn, David.
[01:12:23.640 --> 01:12:24.760]   Do you root for UConn?
[01:12:24.760 --> 01:12:26.440]   You know what?
[01:12:26.440 --> 01:12:28.360]   I'm too busy playing with the Amazon Echo.
[01:12:28.360 --> 01:12:30.280]   We'll get back to the Echo.
[01:12:30.280 --> 01:12:31.800]   And give you sports scores.
[01:12:31.800 --> 01:12:33.000]   Actually, there was a big Echo store.
[01:12:33.000 --> 01:12:34.840]   I was just going to mention that March Bandits
[01:12:34.840 --> 01:12:36.600]   has a split screen thing on Apple TV,
[01:12:36.600 --> 01:12:38.840]   which I haven't seen because I haven't been watching the tournament.
[01:12:38.840 --> 01:12:39.720]   Have you tried it?
[01:12:39.720 --> 01:12:40.440]   No, I haven't actually.
[01:12:40.440 --> 01:12:40.920]   It looks cool.
[01:12:40.920 --> 01:12:40.920]   It's cool.
[01:12:40.920 --> 01:12:40.920]   It's cool.
[01:12:40.920 --> 01:12:41.880]   Yeah.
[01:12:41.880 --> 01:12:44.920]   They've done some really interesting things for sports with the Apple TV.
[01:12:44.920 --> 01:12:45.880]   That's smart.
[01:12:45.880 --> 01:12:46.040]   Yeah.
[01:12:46.040 --> 01:12:47.640]   It's really smart because those--
[01:12:47.640 --> 01:12:49.240]   You know, people watch this stuff, really.
[01:12:49.240 --> 01:12:53.560]   I think it's like maybe 60% of what I watch on my Apple TV is sports.
[01:12:53.560 --> 01:12:54.120]   Yeah.
[01:12:54.120 --> 01:12:56.120]   I hear-- I can't wait to baseball because they're going to have
[01:12:56.120 --> 01:12:56.920]   some baseball features.
[01:12:56.920 --> 01:12:56.920]   Yeah.
[01:12:56.920 --> 01:12:58.680]   Like multi-screen baseball.
[01:12:58.680 --> 01:13:00.680]   MLB got NBA and got MLS.
[01:13:00.680 --> 01:13:01.160]   Yeah, nice.
[01:13:01.160 --> 01:13:01.640]   Google TV.
[01:13:01.640 --> 01:13:02.120]   Yeah, soccer.
[01:13:02.120 --> 01:13:02.440]   Yeah.
[01:13:02.440 --> 01:13:05.800]   Fubo TV just got an investment from Fox and Sky.
[01:13:05.800 --> 01:13:06.520]   They're blowing up.
[01:13:06.520 --> 01:13:06.520]   Yeah.
[01:13:06.520 --> 01:13:06.520]   Yeah.
[01:13:06.520 --> 01:13:06.520]   Yeah.
[01:13:06.520 --> 01:13:07.080]   They're blowing up.
[01:13:07.080 --> 01:13:08.280]   Watch a little Barcelona.
[01:13:08.280 --> 01:13:12.120]   Who would have thought that IPTV would have ended up being about sports?
[01:13:12.120 --> 01:13:13.240]   TV is about sports.
[01:13:13.240 --> 01:13:16.680]   TV is-- well, TV-- but sports, which is live,
[01:13:17.240 --> 01:13:20.280]   is that you can watch all the house of cards you want,
[01:13:20.280 --> 01:13:22.920]   but live has always been traditionally difficult
[01:13:22.920 --> 01:13:25.240]   because the broadcasters don't want to give up.
[01:13:25.240 --> 01:13:26.760]   Those-- they spend a long time--
[01:13:26.760 --> 01:13:27.080]   Yeah.
[01:13:27.080 --> 01:13:28.040]   That's for all the monies, then.
[01:13:28.040 --> 01:13:29.400]   Yeah.
[01:13:29.400 --> 01:13:29.880]   Oh, good.
[01:13:29.880 --> 01:13:30.600]   I'm glad.
[01:13:30.600 --> 01:13:31.720]   I'm glad.
[01:13:31.720 --> 01:13:33.880]   So you're a big echo fan now, David.
[01:13:33.880 --> 01:13:35.240]   This has taken over your life.
[01:13:35.240 --> 01:13:36.360]   How many-- but wait a minute.
[01:13:36.360 --> 01:13:36.840]   Let's see.
[01:13:36.840 --> 01:13:37.800]   Let's measure.
[01:13:37.800 --> 01:13:39.000]   How many echoes do you have?
[01:13:39.000 --> 01:13:42.360]   Well, so here's the deal.
[01:13:42.360 --> 01:13:44.920]   I have the one that I was sent to review a few months ago.
[01:13:44.920 --> 01:13:45.400]   Yeah.
[01:13:45.400 --> 01:13:48.440]   And my birthday was this week, and my wife said it's disgusting.
[01:13:48.440 --> 01:13:50.040]   You haven't returned that thing yet.
[01:13:50.040 --> 01:13:51.160]   And I can say, I will.
[01:13:51.160 --> 01:13:51.720]   I will.
[01:13:51.720 --> 01:13:54.040]   So she bought me one for my birthday to replace the one
[01:13:54.040 --> 01:13:55.240]   that I should have sent back by now.
[01:13:55.240 --> 01:13:57.320]   So do you use it for music?
[01:13:57.320 --> 01:13:59.640]   Because I think it sounds like crap for music.
[01:13:59.640 --> 01:14:03.320]   Or do you actually use it to answer questions and the weather?
[01:14:03.320 --> 01:14:06.120]   Yeah, all of the above, mostly for music.
[01:14:06.120 --> 01:14:07.000]   I just find it really--
[01:14:07.000 --> 01:14:07.480]   Really?
[01:14:07.480 --> 01:14:09.800]   --so great to come into the kitchen for the keys on and say--
[01:14:09.800 --> 01:14:10.520]   The convenience is phenomenal.
[01:14:10.520 --> 01:14:10.840]   Yeah.
[01:14:10.840 --> 01:14:12.440]   Alexa, play some cooking music.
[01:14:12.440 --> 01:14:13.400]   And don't--
[01:14:13.400 --> 01:14:15.000]   Don't-- just a little word of warning.
[01:14:15.320 --> 01:14:19.880]   What you just did, set off hundreds of echoes all across the country.
[01:14:19.880 --> 01:14:20.760]   Yeah.
[01:14:20.760 --> 01:14:22.360]   And they were listening to the podcast,
[01:14:22.360 --> 01:14:24.440]   and now they're listening to something else.
[01:14:24.440 --> 01:14:24.920]   To cooking music.
[01:14:24.920 --> 01:14:25.400]   I know.
[01:14:25.400 --> 01:14:28.840]   Really to go for Yahoo Tech.
[01:14:28.840 --> 01:14:33.240]   I did a video demonstrating all of Alexa's new commands.
[01:14:33.240 --> 01:14:34.200]   Oh, it's amazing.
[01:14:34.200 --> 01:14:36.520]   Like I can pull my Nest thermostat with it now.
[01:14:36.520 --> 01:14:38.440]   You can say, Alexa, make it 72 degrees.
[01:14:38.440 --> 01:14:40.040]   Be careful about that, though, right?
[01:14:40.040 --> 01:14:41.000]   Oh, that's great.
[01:14:41.000 --> 01:14:42.680]   I'll call it Bob, OK?
[01:14:43.960 --> 01:14:45.800]   And you can now order Domino's Pizza.
[01:14:45.800 --> 01:14:48.520]   You can say, Bob, order my favorite pizza.
[01:14:48.520 --> 01:14:50.280]   And you can call an Uber with it now,
[01:14:50.280 --> 01:14:52.120]   which is super, super convenient.
[01:14:52.120 --> 01:14:54.040]   You know, you're busy, you're getting your stuff together,
[01:14:54.040 --> 01:14:55.080]   your jacket on.
[01:14:55.080 --> 01:14:56.760]   You just say, Bob, order me.
[01:14:56.760 --> 01:14:57.800]   And sure enough--
[01:14:57.800 --> 01:14:59.880]   But then you have the crappy Domino's Pizza.
[01:14:59.880 --> 01:15:02.200]   It's good.
[01:15:02.200 --> 01:15:02.920]   I hate to tell you.
[01:15:02.920 --> 01:15:04.120]   It's perfectly kind of a jacket.
[01:15:04.120 --> 01:15:04.520]   Oh.
[01:15:04.520 --> 01:15:05.240]   No.
[01:15:05.240 --> 01:15:05.560]   It's good?
[01:15:05.560 --> 01:15:06.360]   It's good pizza.
[01:15:06.360 --> 01:15:07.720]   The one I got in New York was anyway.
[01:15:07.720 --> 01:15:09.240]   I'm glad you're not a food writer, Dave.
[01:15:09.240 --> 01:15:11.160]   You know, it's so funny because if I have this debate,
[01:15:11.160 --> 01:15:13.640]   there's a guy in the chat room, Mike B,
[01:15:13.640 --> 01:15:15.880]   who lives in Jersey, which is a home of some of the best pizza
[01:15:15.880 --> 01:15:18.440]   in the world, who insists that Domino's makes good pizza.
[01:15:18.440 --> 01:15:20.360]   And it's like, well, maybe that's the case.
[01:15:20.360 --> 01:15:22.920]   The Domino's in New York and New Jersey makes good pizza.
[01:15:22.920 --> 01:15:23.800]   But out here--
[01:15:23.800 --> 01:15:24.280]   No.
[01:15:24.280 --> 01:15:26.440]   I grew up in New Jersey and around New York.
[01:15:26.440 --> 01:15:27.320]   There's not good Domino's.
[01:15:27.320 --> 01:15:28.520]   I grew up in New York now.
[01:15:28.520 --> 01:15:29.000]   No.
[01:15:29.000 --> 01:15:29.560]   No.
[01:15:29.560 --> 01:15:30.360]   All right.
[01:15:30.360 --> 01:15:31.320]   What is the thing?
[01:15:31.320 --> 01:15:32.520]   Can you plug in my echo?
[01:15:32.520 --> 01:15:33.720]   I want to order some pizza.
[01:15:33.720 --> 01:15:38.280]   So I have an echo here because we have to talk about it.
[01:15:38.280 --> 01:15:40.440]   I have three at home and I ordered two dots.
[01:15:40.440 --> 01:15:42.200]   Wow.
[01:15:42.200 --> 01:15:45.080]   I don't want to be in a room of the house that I can't say.
[01:15:45.080 --> 01:15:45.880]   You know what I use it for?
[01:15:45.880 --> 01:15:49.160]   It's not music so much as books because I have my honorable books on it.
[01:15:49.160 --> 01:15:49.720]   It reads to me.
[01:15:49.720 --> 01:15:52.120]   It's like having my mommy in every room.
[01:15:52.120 --> 01:15:54.280]   So the guy--
[01:15:54.280 --> 01:15:57.320]   there's this story-- yeah, plug it in somewhere.
[01:15:57.320 --> 01:15:57.960]   Like a--
[01:15:57.960 --> 01:15:58.920]   Oh, yeah.
[01:15:58.920 --> 01:15:59.960]   Bring the plug, too.
[01:15:59.960 --> 01:16:01.320]   We can't just bring the echo.
[01:16:01.320 --> 01:16:08.440]   So this guy in Jersey is listening to NPR's weekend edition
[01:16:08.440 --> 01:16:09.960]   and they did a story on the echo.
[01:16:09.960 --> 01:16:10.520]   Yes.
[01:16:11.880 --> 01:16:16.120]   And how it was helping customers do all sorts of things,
[01:16:16.120 --> 01:16:19.000]   including set their thermostats.
[01:16:19.000 --> 01:16:27.240]   So a listener wrote in to say that he was listening to NPR on his echo
[01:16:27.240 --> 01:16:31.000]   and reset his thermostat to 70 degrees.
[01:16:31.000 --> 01:16:36.920]   Jeff, this has been going on to our listeners for a long time now
[01:16:36.920 --> 01:16:38.360]   because many of our listeners have them.
[01:16:39.160 --> 01:16:44.200]   Jeff said he was listening and she heard her name and he started
[01:16:44.200 --> 01:16:45.640]   sharing her art playing the NPR News.
[01:16:45.640 --> 01:16:53.240]   So yes, you have to be careful when you say her name.
[01:16:53.240 --> 01:16:54.520]   Although this is a problem.
[01:16:54.520 --> 01:17:00.200]   They've added-- now used to be just ALEXA and Amazon were the trigger words,
[01:17:00.200 --> 01:17:01.800]   but they've made echo a trigger word now.
[01:17:01.800 --> 01:17:02.920]   So I don't know.
[01:17:02.920 --> 01:17:03.880]   We're going to call it Bob.
[01:17:03.880 --> 01:17:06.200]   We have to call it Bob.
[01:17:06.600 --> 01:17:08.120]   I have the same problem, Leo.
[01:17:08.120 --> 01:17:13.240]   After that video got posted, I got dozens of beats saying,
[01:17:13.240 --> 01:17:15.800]   "You just triggered my stupid Amazon echo."
[01:17:15.800 --> 01:17:20.280]   Well, Amazon's doing it themselves with those ads with Alec Baldwin.
[01:17:20.280 --> 01:17:25.240]   I'm watching the ad and the echo wakes up, so we just plugged the echo in.
[01:17:25.240 --> 01:17:26.520]   I'm going to see if I can order a pizza.
[01:17:26.520 --> 01:17:28.840]   Do I have to set up an account?
[01:17:28.840 --> 01:17:29.320]   Probably do.
[01:17:29.320 --> 01:17:29.800]   You do.
[01:17:29.800 --> 01:17:34.920]   Yeah, all it can do actually is order either the last phone you already ordered,
[01:17:34.920 --> 01:17:38.600]   using a Domino's app, or order one that-- using the app,
[01:17:38.600 --> 01:17:40.600]   you have designated it as your favorite pizza.
[01:17:40.600 --> 01:17:41.880]   So you couldn't do it right now.
[01:17:41.880 --> 01:17:44.840]   You'd have to order one manually the first time in the app.
[01:17:44.840 --> 01:17:47.080]   Oh, so I have to do it on the phone first.
[01:17:47.080 --> 01:17:47.800]   I can't just--
[01:17:47.800 --> 01:17:49.080]   It looks like she's trying to connect right now.
[01:17:49.080 --> 01:17:50.280]   I guess we're just gonna have to order two pizzas.
[01:17:50.280 --> 01:17:50.600]   Damn.
[01:17:50.600 --> 01:17:53.720]   She'll announce when she's just gonna have to order one on the phone.
[01:17:53.720 --> 01:17:54.040]   Right?
[01:17:54.040 --> 01:17:54.760]   I could do that.
[01:17:54.760 --> 01:17:55.800]   And then what was the order--
[01:17:55.800 --> 01:17:57.160]   All right, you guys talk amongst yourselves.
[01:17:57.160 --> 01:17:59.640]   Will I download and install the Domino's app?
[01:17:59.640 --> 01:18:01.320]   Order a pizza.
[01:18:01.320 --> 01:18:03.240]   No, it's a big hit at our house.
[01:18:03.240 --> 01:18:05.080]   I've still got kids in the house.
[01:18:05.080 --> 01:18:07.080]   We love corny as the sounds.
[01:18:07.080 --> 01:18:08.600]   We love the joke thing.
[01:18:08.600 --> 01:18:09.240]   I do too.
[01:18:09.240 --> 01:18:09.960]   Tell--
[01:18:09.960 --> 01:18:11.480]   The jokes are-- I've never heard these.
[01:18:11.480 --> 01:18:13.960]   They're really great corny puns, but they're good.
[01:18:13.960 --> 01:18:17.240]   Yeah, and you can have it tell dad jokes.
[01:18:17.240 --> 01:18:17.720]   Can you do--
[01:18:17.720 --> 01:18:19.240]   Yeah, they're dad jokes.
[01:18:19.240 --> 01:18:21.160]   Yeah, I think I'd set up to say echo.
[01:18:21.160 --> 01:18:23.960]   Give me a fart.
[01:18:23.960 --> 01:18:28.120]   Oh, it stopped listening.
[01:18:28.120 --> 01:18:29.240]   Maybe it thought I was rude.
[01:18:29.240 --> 01:18:31.400]   You'll edit all this out of your--
[01:18:31.400 --> 01:18:32.840]   Yeah, echo, give me a fart.
[01:18:32.840 --> 01:18:36.280]   [LAUGHTER]
[01:18:36.280 --> 01:18:37.160]   Oh, it's not turned up.
[01:18:37.160 --> 01:18:40.680]   Push it back.
[01:18:40.680 --> 01:18:41.720]   Try Nathan, give me a fart.
[01:18:41.720 --> 01:18:43.320]   [LAUGHTER]
[01:18:43.320 --> 01:18:44.360]   Yeah, you got it.
[01:18:44.360 --> 01:18:45.320]   Jeffy will love that.
[01:18:45.320 --> 01:18:46.600]   Don't do that on demand anymore.
[01:18:46.600 --> 01:18:48.760]   Just turn on the fart skill.
[01:18:48.760 --> 01:18:49.800]   That was--
[01:18:49.800 --> 01:18:50.280]   [LAUGHTER]
[01:18:50.280 --> 01:18:51.720]   You don't do that on demand anymore.
[01:18:51.720 --> 01:18:52.280]   No, it was college.
[01:18:52.280 --> 01:18:52.680]   Hold my finger.
[01:18:52.680 --> 01:18:53.320]   Yeah, OK.
[01:18:53.320 --> 01:18:57.080]   No, it's-- I don't know why echo.
[01:18:57.080 --> 01:18:59.720]   So the Amazon did something interesting.
[01:18:59.720 --> 01:19:02.360]   They made these two new echoes or the tap,
[01:19:02.360 --> 01:19:05.640]   which is an echo without a plug.
[01:19:05.640 --> 01:19:06.680]   It's a battery-powered echo.
[01:19:06.680 --> 01:19:09.880]   And they made a dot, which is an echo with just a little speaker.
[01:19:09.880 --> 01:19:11.800]   The idea being you plug it into a big speaker,
[01:19:11.800 --> 01:19:13.960]   which I-- that's why I ordered two of them,
[01:19:13.960 --> 01:19:14.920]   because that's really what I want.
[01:19:14.920 --> 01:19:17.000]   I want to make my Sonos echo aware, right?
[01:19:17.000 --> 01:19:20.520]   But the only way you could buy it was through your echo,
[01:19:20.520 --> 01:19:22.600]   which is weird.
[01:19:22.600 --> 01:19:24.360]   Well, it's echo inception.
[01:19:24.360 --> 01:19:24.760]   Yeah.
[01:19:24.760 --> 01:19:27.240]   Why did they do that?
[01:19:27.240 --> 01:19:28.520]   It's too--
[01:19:28.520 --> 01:19:31.000]   I even emailed Amazon PR to say,
[01:19:31.000 --> 01:19:32.600]   could I review the dot?
[01:19:32.600 --> 01:19:34.600]   And that was the answer even to reviewers.
[01:19:34.600 --> 01:19:36.440]   Oh, no, you have to order it through your echo.
[01:19:36.440 --> 01:19:37.800]   Yeah.
[01:19:37.800 --> 01:19:39.960]   There's so many skills now, though, that's a problem,
[01:19:39.960 --> 01:19:42.600]   because most of those skills--
[01:19:42.600 --> 01:19:44.760]   by the way, it's very easy to write skills, I found out.
[01:19:44.760 --> 01:19:47.720]   And you can do it yourself, really.
[01:19:47.720 --> 01:19:50.680]   And Amazon provides the infrastructure for it,
[01:19:50.680 --> 01:19:52.760]   and only charges you when the skill is activated.
[01:19:52.760 --> 01:19:54.520]   And it's like less than a penny.
[01:19:54.520 --> 01:19:57.000]   So you could easily have your own set of skills.
[01:19:57.000 --> 01:19:58.360]   But there's so many skills now,
[01:19:58.360 --> 01:20:00.040]   and they have to be enabled
[01:20:00.040 --> 01:20:01.320]   that it's kind of out of control.
[01:20:01.320 --> 01:20:03.960]   Like, you need like a dictionary next to your echo
[01:20:03.960 --> 01:20:05.400]   to know what it can do and not do.
[01:20:05.400 --> 01:20:08.680]   So you listen to music.
[01:20:08.680 --> 01:20:10.760]   My-- we gave one to my father-in-law.
[01:20:10.760 --> 01:20:13.720]   And he has like--
[01:20:13.720 --> 01:20:15.960]   He listens to Elvis all the time.
[01:20:15.960 --> 01:20:17.560]   He says, you know, echo play Elvis.
[01:20:17.560 --> 01:20:21.880]   I think I just still really like hearing music sound good.
[01:20:21.880 --> 01:20:22.440]   So--
[01:20:22.440 --> 01:20:22.840]   I know.
[01:20:22.840 --> 01:20:24.440]   I would love this.
[01:20:24.440 --> 01:20:25.400]   It's not the best speaker.
[01:20:25.400 --> 01:20:25.640]   Yeah.
[01:20:25.640 --> 01:20:26.200]   If it could--
[01:20:26.200 --> 01:20:29.240]   If Dot could control my Sonos and play music
[01:20:29.240 --> 01:20:30.360]   through my Sonos that way.
[01:20:30.360 --> 01:20:31.000]   It can't though.
[01:20:31.000 --> 01:20:31.960]   So what you'll have to do is turn it--
[01:20:31.960 --> 01:20:31.960]   So there's one--
[01:20:31.960 --> 01:20:34.040]   But the Sonos in auxiliary mode,
[01:20:34.040 --> 01:20:35.480]   plugging into the auxiliary port.
[01:20:35.480 --> 01:20:35.960]   It's just--
[01:20:35.960 --> 01:20:36.280]   Yeah.
[01:20:36.280 --> 01:20:36.760]   Yeah.
[01:20:36.760 --> 01:20:37.800]   I think it's going to be too much pain.
[01:20:37.800 --> 01:20:38.520]   It's too much trouble.
[01:20:38.520 --> 01:20:40.680]   I mean, but that kitchen scenario
[01:20:40.680 --> 01:20:41.640]   that Dave brought up earlier,
[01:20:41.640 --> 01:20:42.920]   if your hands are messy,
[01:20:42.920 --> 01:20:43.480]   and you just want to--
[01:20:43.480 --> 01:20:44.440]   I use the timer all the time.
[01:20:44.440 --> 01:20:44.840]   I use the timer all the time.
[01:20:44.840 --> 01:20:45.240]   Yeah.
[01:20:45.240 --> 01:20:45.640]   Yeah.
[01:20:45.640 --> 01:20:46.440]   It's not like--
[01:20:46.440 --> 01:20:47.880]   Yeah, timer's great.
[01:20:47.880 --> 01:20:48.120]   I use the timer.
[01:20:48.120 --> 01:20:49.160]   It's like multiple timers.
[01:20:49.160 --> 01:20:50.760]   Echo play some Elvis.
[01:20:50.760 --> 01:20:51.800]   And what?
[01:20:51.800 --> 01:20:52.600]   Let's see if she's--
[01:20:52.600 --> 01:20:53.480]   I don't know if she's--
[01:20:53.480 --> 01:20:58.040]   Broke my echo.
[01:20:58.040 --> 01:21:00.360]   She's responding.
[01:21:00.360 --> 01:21:03.320]   She's waking up, but she's not doing anything.
[01:21:03.320 --> 01:21:04.680]   And volume's up too.
[01:21:04.680 --> 01:21:07.160]   Yeah, normally, I mean, when we plugged your back in,
[01:21:07.160 --> 01:21:10.280]   she would say connecting to the network kind of a thing.
[01:21:10.280 --> 01:21:10.760]   It's tired of--
[01:21:10.760 --> 01:21:12.360]   After all these years, Leo,
[01:21:12.360 --> 01:21:15.240]   you still don't know the lesson of trying to do live demos
[01:21:15.240 --> 01:21:18.200]   that's happening without stuff.
[01:21:18.200 --> 01:21:20.120]   I-- you know, we're seriously thinking about
[01:21:20.120 --> 01:21:21.720]   whether we should do an echo show.
[01:21:21.720 --> 01:21:23.800]   Lisa says we absolutely should do an echo show.
[01:21:23.800 --> 01:21:26.040]   I'm thinking maybe an internet of things show,
[01:21:26.040 --> 01:21:27.000]   but mostly echo.
[01:21:27.000 --> 01:21:30.040]   I'm telling you, this thing is so unsung.
[01:21:30.040 --> 01:21:34.120]   Why isn't there a Samsung copycat and a microsoft copycat
[01:21:34.120 --> 01:21:35.160]   and an Apple copycat?
[01:21:35.160 --> 01:21:35.800]   It's coming.
[01:21:35.800 --> 01:21:37.560]   Everyone who gets one loves it.
[01:21:37.560 --> 01:21:39.320]   Maybe Apple announced that in March.
[01:21:39.320 --> 01:21:40.920]   You know, I mean--
[01:21:40.920 --> 01:21:41.480]   But it's smart.
[01:21:41.480 --> 01:21:42.040]   They have Siri.
[01:21:42.040 --> 01:21:43.640]   All they have to do is make a little thing.
[01:21:43.640 --> 01:21:46.760]   Well, I guess there's like--
[01:21:46.760 --> 01:21:47.880]   there's a little bit of a question.
[01:21:47.880 --> 01:21:50.920]   I mean, for Amazon, for Echo,
[01:21:50.920 --> 01:21:52.280]   it makes a ton of sense right now
[01:21:52.280 --> 01:21:55.480]   because you can buy lots of things from it.
[01:21:55.480 --> 01:21:57.240]   Yeah, for Amazon, it's huge.
[01:21:57.240 --> 01:21:57.720]   So for--
[01:21:57.720 --> 01:21:59.400]   I buy stuff all the time exactly.
[01:21:59.400 --> 01:21:59.880]   Exactly.
[01:21:59.880 --> 01:22:02.840]   But for Samsung, they have--
[01:22:02.840 --> 01:22:05.080]   what's the name of their internet of things?
[01:22:05.080 --> 01:22:05.800]   Smart things?
[01:22:05.800 --> 01:22:06.360]   Is that the name of their smartphone?
[01:22:06.360 --> 01:22:06.840]   Smart things.
[01:22:06.840 --> 01:22:08.200]   They bought smart things, which is a great--
[01:22:08.200 --> 01:22:09.640]   In fact, the echo works with smart things.
[01:22:09.640 --> 01:22:13.000]   So if your Samsung, the likelihood is that you would have
[01:22:13.000 --> 01:22:15.240]   it control those smart things products, right?
[01:22:15.240 --> 01:22:15.720]   Right.
[01:22:15.720 --> 01:22:17.640]   But Echo already does it.
[01:22:17.640 --> 01:22:17.880]   Yep.
[01:22:17.880 --> 01:22:20.200]   Echo works great with smart things.
[01:22:20.200 --> 01:22:21.880]   So-- and it works with if this, then that,
[01:22:21.880 --> 01:22:24.040]   which really makes it very capable.
[01:22:24.040 --> 01:22:25.080]   There's a lot more.
[01:22:25.080 --> 01:22:26.200]   It works with Nest too, doesn't it?
[01:22:26.200 --> 01:22:28.680]   I wonder, though, for Sonos, since this is where they say
[01:22:28.680 --> 01:22:30.760]   they're going to kind of, you know,
[01:22:30.760 --> 01:22:33.560]   spend some money and develop and grow their company.
[01:22:33.560 --> 01:22:35.560]   I feel like for all the folks who already have Sonos speakers,
[01:22:35.560 --> 01:22:37.160]   like all three of us, really,
[01:22:37.160 --> 01:22:41.320]   I mean, they're going to have to sell some sort of device
[01:22:41.320 --> 01:22:43.080]   that you plug into your existing Sonos speakers
[01:22:43.080 --> 01:22:44.280]   to get them to control it, right?
[01:22:44.280 --> 01:22:45.960]   I mean, you're not going to want to get through the--
[01:22:45.960 --> 01:22:47.800]   I'm feeling like Sonos--
[01:22:47.800 --> 01:22:50.840]   they're right-- what they said in their announcement was,
[01:22:50.840 --> 01:22:51.640]   we're laying off people.
[01:22:51.640 --> 01:22:53.080]   Oh, and by the way, forget that part.
[01:22:53.720 --> 01:22:57.000]   Uh, we realized that people are--
[01:22:57.000 --> 01:22:59.880]   what we focused on is playing your music collection.
[01:22:59.880 --> 01:23:01.960]   Which is what they already do.
[01:23:01.960 --> 01:23:04.680]   And we realized that's not the future
[01:23:04.680 --> 01:23:06.920]   that most of our users are using streaming services.
[01:23:06.920 --> 01:23:08.440]   They do support Apple Music now.
[01:23:08.440 --> 01:23:09.640]   They just added that.
[01:23:09.640 --> 01:23:13.320]   Paul Therat says it stopped working with Microsoft's groove.
[01:23:13.320 --> 01:23:15.320]   His anyway stopped working a few days with--
[01:23:15.320 --> 01:23:15.640]   No, it is not.
[01:23:15.640 --> 01:23:16.360]   --not much of a groove.
[01:23:16.360 --> 01:23:18.120]   That's what Echo says.
[01:23:18.120 --> 01:23:20.120]   What?
[01:23:20.120 --> 01:23:22.040]   I don't think I know what you're talking about.
[01:23:22.040 --> 01:23:24.440]   It used to be Xbox Music.
[01:23:24.440 --> 01:23:24.840]   Groove is--
[01:23:24.840 --> 01:23:25.240]   Oh, yeah.
[01:23:25.240 --> 01:23:25.720]   Yeah.
[01:23:25.720 --> 01:23:26.840]   Before that, Zoom.
[01:23:26.840 --> 01:23:27.240]   Yeah.
[01:23:27.240 --> 01:23:28.200]   Yeah, yeah, yeah.
[01:23:28.200 --> 01:23:29.400]   It's like their 15th pivot--
[01:23:29.400 --> 01:23:30.600]   Maybe that's what happens.
[01:23:30.600 --> 01:23:32.040]   Sonos lost track of the name.
[01:23:32.040 --> 01:23:35.800]   But it does work with Spotify very well.
[01:23:35.800 --> 01:23:39.960]   It works with Amazon Music as your own collection
[01:23:39.960 --> 01:23:40.840]   with title music.
[01:23:40.840 --> 01:23:44.680]   So Sonos does do a good job.
[01:23:44.680 --> 01:23:49.080]   But I just feel like they say we're going to try to--
[01:23:49.080 --> 01:23:52.200]   How do you go from 0 to 60 with voice recognition?
[01:23:52.200 --> 01:23:54.520]   Honestly, I don't think it would be that hard.
[01:23:54.520 --> 01:23:56.680]   If you're Sonos, you are a premium brand.
[01:23:56.680 --> 01:23:57.240]   Right?
[01:23:57.240 --> 01:24:00.600]   You make really great sounding hardware that sells at a high price.
[01:24:00.600 --> 01:24:04.120]   So it might be a small market for four Wi-Fi speakers.
[01:24:04.120 --> 01:24:05.080]   But who do you go?
[01:24:05.080 --> 01:24:08.120]   Is it like you just hire some guy in any rights of voice recognition system?
[01:24:08.120 --> 01:24:10.440]   You would buy services from Nuance for the--
[01:24:10.440 --> 01:24:11.640]   Nuance does a lot of this.
[01:24:11.640 --> 01:24:11.880]   Right?
[01:24:11.880 --> 01:24:13.400]   That's what S voice from Samsung is.
[01:24:13.400 --> 01:24:13.560]   Yeah.
[01:24:13.560 --> 01:24:17.960]   And then, like, Echo is not really a conversational AI so much.
[01:24:17.960 --> 01:24:18.840]   No, it's not that right.
[01:24:18.840 --> 01:24:19.640]   Like, command-based.
[01:24:19.640 --> 01:24:20.200]   Right.
[01:24:20.200 --> 01:24:24.120]   So once you have the ability to transcribe text for--
[01:24:24.120 --> 01:24:25.240]   You also have to have a Raymikes.
[01:24:25.240 --> 01:24:29.080]   Now, what's interesting is that the newest Sonos Play 5 has microphones.
[01:24:29.080 --> 01:24:30.760]   Microphones that are not enabled.
[01:24:30.760 --> 01:24:31.320]   Yep.
[01:24:31.320 --> 01:24:31.560]   Yep.
[01:24:31.560 --> 01:24:32.360]   It has those mics.
[01:24:32.360 --> 01:24:33.960]   So clearly, they're aiming at this.
[01:24:33.960 --> 01:24:34.360]   Yeah.
[01:24:34.360 --> 01:24:35.720]   I mean, they-- you know, just like--
[01:24:35.720 --> 01:24:39.800]   But I bought-- I have-- I'm not going to buy all new Play 5s,
[01:24:39.800 --> 01:24:44.280]   which is why if you buy something like the dot that works with your Sonos speakers that has--
[01:24:44.280 --> 01:24:45.640]   They should now build your thing.
[01:24:45.640 --> 01:24:48.440]   No, it has Nuance built in or someone built in.
[01:24:48.440 --> 01:24:49.000]   It could-- I mean--
[01:24:49.000 --> 01:24:51.800]   Why doesn't Amazon let this ecosystem just go everywhere?
[01:24:51.800 --> 01:24:55.640]   Because after all, really, I'm sure where they make money is in sales.
[01:24:55.640 --> 01:24:57.880]   I've ordered-- you know, I ran out of batteries,
[01:24:57.880 --> 01:25:00.040]   so I say Echo buy some more batteries.
[01:25:00.040 --> 01:25:01.240]   And it just does.
[01:25:01.240 --> 01:25:03.240]   And they come two days later.
[01:25:03.240 --> 01:25:05.720]   And you just made 40,000 people--
[01:25:05.720 --> 01:25:06.360]   Oh, god.
[01:25:06.360 --> 01:25:07.320]   I'm so sorry.
[01:25:07.320 --> 01:25:10.120]   We have done that.
[01:25:10.120 --> 01:25:11.160]   We have done that.
[01:25:11.160 --> 01:25:14.440]   You just caused a spike in energizers sales right there.
[01:25:14.440 --> 01:25:17.720]   We had Jason Calicanis on, and he decided to really troll everybody.
[01:25:17.720 --> 01:25:22.280]   And he issued like 20 Echo commands in a row, really loud, really fast.
[01:25:22.280 --> 01:25:25.320]   And it was like a mess.
[01:25:25.320 --> 01:25:26.600]   I don't know.
[01:25:26.600 --> 01:25:28.280]   I feel bad she's not working.
[01:25:28.280 --> 01:25:29.400]   Echo self-destruct.
[01:25:29.400 --> 01:25:30.760]   Oh, my god.
[01:25:30.760 --> 01:25:34.120]   Hey, Leo, I have a tech support question for you.
[01:25:34.120 --> 01:25:34.440]   Yeah.
[01:25:34.440 --> 01:25:37.720]   So I just got Sonos for Christmas.
[01:25:37.720 --> 01:25:37.880]   Yeah.
[01:25:37.880 --> 01:25:39.000]   And fantastic.
[01:25:39.000 --> 01:25:43.960]   But the one thing that boggles me is it doesn't seem to tap into the regular
[01:25:44.600 --> 01:25:46.120]   OS audio controls.
[01:25:46.120 --> 01:25:47.880]   So if I want to pause it or--
[01:25:47.880 --> 01:25:49.320]   No, right.
[01:25:49.320 --> 01:25:50.520]   Skip, I have to go in--
[01:25:50.520 --> 01:25:54.440]   I have to unlock the phone, go find the app and borrow into it.
[01:25:54.440 --> 01:25:56.040]   Isn't that crazy?
[01:25:56.040 --> 01:25:56.360]   Yes.
[01:25:56.360 --> 01:25:59.000]   There's no easier way?
[01:25:59.000 --> 01:25:59.240]   No.
[01:25:59.240 --> 01:26:01.800]   And well, of course they could do it.
[01:26:01.800 --> 01:26:02.520]   I would think--
[01:26:02.520 --> 01:26:04.440]   Well, even if they couldn't do it on an Apple,
[01:26:04.440 --> 01:26:05.800]   they could do it on an Android device.
[01:26:05.800 --> 01:26:07.320]   They could do it on an Android device.
[01:26:07.320 --> 01:26:11.080]   But they've done a little tougher because those controls are for what the phone is playing.
[01:26:11.080 --> 01:26:13.000]   And the app is a controller that sends
[01:26:13.720 --> 01:26:16.040]   commands to the speaker itself, not the phone.
[01:26:16.040 --> 01:26:19.480]   What you're seeing is a small company that made a premium product
[01:26:19.480 --> 01:26:22.920]   that was successful in a niche market because it was very pricey.
[01:26:22.920 --> 01:26:25.800]   That people-- it was much like Amazon's Echo.
[01:26:25.800 --> 01:26:28.520]   The tech people who have it, the people who own it were--
[01:26:28.520 --> 01:26:32.920]   or Tesla or something like that where it was a small group, but they were passionate.
[01:26:32.920 --> 01:26:33.320]   Yeah.
[01:26:33.320 --> 01:26:34.520]   And I'm one of them.
[01:26:34.520 --> 01:26:35.800]   And there was nothing else like it.
[01:26:35.800 --> 01:26:36.920]   And there was nothing else like it.
[01:26:36.920 --> 01:26:38.920]   But I think they created their own market.
[01:26:38.920 --> 01:26:39.960]   I don't think that it's--
[01:26:39.960 --> 01:26:41.560]   I think that the day may have--
[01:26:41.560 --> 01:26:43.800]   the competition may have passed and by.
[01:26:43.800 --> 01:26:45.640]   I think there's still time.
[01:26:45.640 --> 01:26:49.000]   I mean, we don't have Samsung's version this yet.
[01:26:49.000 --> 01:26:51.720]   We don't have Google or Apple's version this yet.
[01:26:51.720 --> 01:26:57.320]   And those AI, those artificial intelligence assistants or whatever,
[01:26:57.320 --> 01:27:00.600]   are much further along and more capable than Alexa is.
[01:27:00.600 --> 01:27:03.240]   I mean, the utility here is awesome.
[01:27:03.240 --> 01:27:05.000]   And the price is cheap and affordable.
[01:27:05.000 --> 01:27:06.120]   So it's super accessible.
[01:27:06.120 --> 01:27:07.960]   But it's still not cheap.
[01:27:07.960 --> 01:27:09.640]   It's 200 bucks for the Echo.
[01:27:09.640 --> 01:27:10.120]   Right?
[01:27:10.120 --> 01:27:14.440]   But it's AI can't do as much and isn't as smart as Google or Apple's.
[01:27:14.440 --> 01:27:15.080]   Well, that's what's funny.
[01:27:15.080 --> 01:27:16.920]   We all have this in our phones, but it's not.
[01:27:16.920 --> 01:27:18.600]   Somehow it's qualitatively different.
[01:27:18.600 --> 01:27:23.560]   David, I always quote you because when you were talking about you,
[01:27:23.560 --> 01:27:27.240]   the first I'd ever heard to really explain why drones were so interesting to me, people,
[01:27:27.240 --> 01:27:33.160]   because for the first time they were seeing their everyday life from a third dimension.
[01:27:33.160 --> 01:27:35.320]   And it really resonated with me.
[01:27:35.320 --> 01:27:36.600]   What do you think the secret--
[01:27:36.600 --> 01:27:40.280]   So you're clearly good at just kind of figuring out why these things catch on.
[01:27:40.280 --> 01:27:42.680]   What do you think the secret is?
[01:27:42.680 --> 01:27:50.120]   Why is the Echo so much better than the better speech recognition in Google now or Siri?
[01:27:50.120 --> 01:27:56.520]   Well, I mean, for the Echo, I think there's two magical elements to it.
[01:27:56.520 --> 01:28:02.120]   One is its vocabulary is so small that it's very accurate.
[01:28:02.120 --> 01:28:02.600]   Right.
[01:28:02.600 --> 01:28:04.760]   It has a very small number of things that needs to understand.
[01:28:04.760 --> 01:28:08.360]   Speaker independent, so anybody in the room can talk to it without training.
[01:28:08.360 --> 01:28:08.760]   That's right.
[01:28:08.760 --> 01:28:14.920]   And also people underestimate the engineering that had to go into those seven array microphones.
[01:28:14.920 --> 01:28:15.240]   Right.
[01:28:15.240 --> 01:28:18.040]   To be able to hear you and cancel out the Echo room.
[01:28:18.040 --> 01:28:18.520]   It's amazing.
[01:28:18.520 --> 01:28:20.040]   It's totally amazing.
[01:28:20.040 --> 01:28:20.920]   Here's a tip, David.
[01:28:20.920 --> 01:28:24.440]   Once you get to the multi-echo situation, we have one in the gym and one in the kitchen.
[01:28:24.440 --> 01:28:25.880]   They both respond all the time.
[01:28:25.880 --> 01:28:31.080]   You have to put them distant from one.
[01:28:31.080 --> 01:28:33.480]   Can you name one?
[01:28:33.480 --> 01:28:34.120]   Yes.
[01:28:34.120 --> 01:28:36.120]   That would probably be the solution is to give.
[01:28:36.120 --> 01:28:36.840]   That's probably, you know what?
[01:28:36.840 --> 01:28:39.800]   That's why they added a third name is that people are starting to get more than one.
[01:28:39.800 --> 01:28:39.960]   Yeah.
[01:28:39.960 --> 01:28:40.360]   Yeah.
[01:28:40.360 --> 01:28:40.840]   Yeah.
[01:28:40.840 --> 01:28:41.320]   Yeah.
[01:28:41.320 --> 01:28:42.040]   That's probably why.
[01:28:42.040 --> 01:28:43.240]   And then the-
[01:28:43.240 --> 01:28:44.600]   Leo, do you know what Viv is?
[01:28:44.600 --> 01:28:45.880]   Have you heard about Viv?
[01:28:45.880 --> 01:28:46.200]   No.
[01:28:46.200 --> 01:28:47.720]   V-I-I-V or V-I-V?
[01:28:47.720 --> 01:28:48.920]   V-I-V.
[01:28:48.920 --> 01:28:52.520]   The three guys who developed Siri and were bought by Apple.
[01:28:52.520 --> 01:28:53.080]   Oh, yeah.
[01:28:53.080 --> 01:28:54.040]   Viv.ai.
[01:28:54.040 --> 01:28:54.040]   Yes.
[01:28:54.040 --> 01:28:55.080]   Have the left Apple.
[01:28:55.080 --> 01:28:55.480]   Yes.
[01:28:55.480 --> 01:29:01.400]   And they've created this next generation Siri where it doesn't just look up information.
[01:29:01.400 --> 01:29:02.920]   It actually executes it.
[01:29:02.920 --> 01:29:09.880]   You can say, you know, what liquor store has Vuv Klico that's on my way to my brother-in-law's
[01:29:09.880 --> 01:29:10.280]   house.
[01:29:10.280 --> 01:29:13.880]   You know, so it needs to know the inventory of every liquor store.
[01:29:13.880 --> 01:29:16.200]   It needs to know who your brother is, where he lives.
[01:29:16.200 --> 01:29:21.800]   Or you can say, buy me an aisle seat to Austin this Friday after 6 p.m.
[01:29:21.800 --> 01:29:23.400]   And returning the following Monday.
[01:29:23.400 --> 01:29:24.760]   But who will know what all that is?
[01:29:24.760 --> 01:29:28.120]   This is what we're supposed to make is Apple bought Siri and then took some of those features out.
[01:29:28.120 --> 01:29:31.080]   You used to be able to make reservations with Siri when it was an app.
[01:29:31.080 --> 01:29:32.680]   And they took it out.
[01:29:32.680 --> 01:29:33.400]   So good for them.
[01:29:33.400 --> 01:29:34.840]   So they must have cashed out.
[01:29:34.840 --> 01:29:37.880]   They got their three years with Apple, got their stock vested.
[01:29:37.880 --> 01:29:41.160]   And they're going off to do it once again right this time.
[01:29:41.160 --> 01:29:42.840]   Soundhound has one called Hound.
[01:29:42.840 --> 01:29:43.640]   I've used Hound.
[01:29:43.640 --> 01:29:44.120]   I like it.
[01:29:44.120 --> 01:29:44.920]   It's pretty good.
[01:29:44.920 --> 01:29:45.560]   It's pretty smart.
[01:29:45.560 --> 01:29:46.520]   You can fast.
[01:29:46.520 --> 01:29:47.000]   Yeah.
[01:29:47.000 --> 01:29:48.440]   How is it so fast?
[01:29:48.440 --> 01:29:49.320]   Insanely fast.
[01:29:49.320 --> 01:29:52.520]   And it can do like hundreds of different commands.
[01:29:52.520 --> 01:29:55.560]   And you can stack the options like that in a kind of conversational way.
[01:29:55.560 --> 01:30:00.440]   So you can say, you know, find me five star pizza restaurants with Wi-Fi that are open,
[01:30:00.440 --> 01:30:02.120]   you know, until midnight tonight.
[01:30:02.120 --> 01:30:04.120]   I found a Domino's pizza near you.
[01:30:04.120 --> 01:30:06.600]   Damn it.
[01:30:06.600 --> 01:30:07.000]   Damn it.
[01:30:07.000 --> 01:30:08.440]   You're wrong.
[01:30:08.440 --> 01:30:09.400]   Why is Domino's so good?
[01:30:09.400 --> 01:30:11.400]   Why don't robots know about good pizza?
[01:30:11.400 --> 01:30:12.360]   Fogown.
[01:30:12.360 --> 01:30:19.640]   Soundhound is an, you know what, that actually kind of validates your point that Sonos could
[01:30:19.640 --> 01:30:23.320]   come up to speak pretty quickly because soundhound, how do they, I mean, they had the technology
[01:30:23.320 --> 01:30:24.360]   against the listen to music.
[01:30:24.360 --> 01:30:26.200]   Well, they've been working on it for about a decade.
[01:30:26.200 --> 01:30:28.520]   Oh, since the, so, so, okay.
[01:30:28.520 --> 01:30:30.520]   Well, it was like a Shazamat before.
[01:30:30.520 --> 01:30:31.000]   Right.
[01:30:31.000 --> 01:30:33.960]   So, so I was talking with the CEO about this.
[01:30:33.960 --> 01:30:37.320]   And what he said was, this was their goal the whole time.
[01:30:37.320 --> 01:30:38.760]   They've been working on it for the last decade.
[01:30:38.760 --> 01:30:42.520]   But Soundhound was the product that they needed to put out there to get like,
[01:30:42.520 --> 01:30:46.280]   to create a company and to have their PCs and stuff kind of on their inter room.
[01:30:46.280 --> 01:30:49.880]   And they were able to build a little bit of the speech recognition and things like that.
[01:30:49.880 --> 01:30:53.880]   So this, they say was the goal the whole time, but it works quite well.
[01:30:53.880 --> 01:30:57.320]   And they, they have open APIs.
[01:30:57.320 --> 01:31:00.200]   So Sonos could, could come up to speed really quickly.
[01:31:00.200 --> 01:31:04.280]   I think the, what they need to do is like, as just as, you know,
[01:31:04.280 --> 01:31:09.160]   Dave mentioned, buy somebody is, is get those Ray mics, build the hardware, get it out there.
[01:31:09.160 --> 01:31:10.760]   Boy, I think it's harder instead than that.
[01:31:10.760 --> 01:31:12.440]   I don't think it's something that happened right away.
[01:31:12.440 --> 01:31:18.280]   But in the next year, I think Sonos could have like a small little device.
[01:31:18.280 --> 01:31:24.040]   And like, like you mentioned, they have those Ray mics in the current play three, right?
[01:31:24.040 --> 01:31:25.880]   Or play five, yeah, play five.
[01:31:25.880 --> 01:31:29.080]   I mean, they, you know, they're already making steps in that direction anyways.
[01:31:29.080 --> 01:31:33.400]   David, you're one of the first people I knew back in the 2006, you were using
[01:31:33.400 --> 01:31:38.200]   Dragon Naturally Speaking to, I thought that was cool.
[01:31:38.200 --> 01:31:43.960]   You would write your books like normally, but then you'd do the index with speech recognition,
[01:31:43.960 --> 01:31:44.840]   with speech to text.
[01:31:44.840 --> 01:31:50.680]   Yeah, I have a long history with speech recognition, not by any foresight on my part.
[01:31:50.680 --> 01:31:54.040]   I got a horrible wrist ailment called Tinos Novitis.
[01:31:54.040 --> 01:31:55.560]   It's like some inflammation thing.
[01:31:55.560 --> 01:31:58.120]   And I couldn't type in the late '90s.
[01:31:58.120 --> 01:32:00.920]   I was having serious, I only do two things, right?
[01:32:00.920 --> 01:32:02.360]   I type and I play the piano.
[01:32:02.360 --> 01:32:03.560]   Those were my two careers.
[01:32:03.560 --> 01:32:04.920]   Great.
[01:32:04.920 --> 01:32:06.200]   And the doctors are simple.
[01:32:06.200 --> 01:32:07.480]   Just stop using your hands.
[01:32:07.480 --> 01:32:08.520]   Great.
[01:32:08.520 --> 01:32:13.000]   So I started with, with Power Secretary.
[01:32:13.000 --> 01:32:13.400]   What?
[01:32:13.400 --> 01:32:15.880]   $2,500 program.
[01:32:15.880 --> 01:32:16.440]   Remember that one.
[01:32:16.440 --> 01:32:21.000]   The very first speech recognition from what is now nuanced.
[01:32:21.000 --> 01:32:24.120]   And you spoke like this.
[01:32:24.120 --> 01:32:26.360]   You had to separate words.
[01:32:26.360 --> 01:32:27.240]   It was unbelievable.
[01:32:27.240 --> 01:32:28.120]   So that's how I started.
[01:32:28.120 --> 01:32:30.360]   At the end of the day, I'd be like, "Hi, honey.
[01:32:30.360 --> 01:32:31.640]   How was working?"
[01:32:31.640 --> 01:32:33.000]   Period.
[01:32:33.000 --> 01:32:34.200]   Exclamation mark.
[01:32:34.200 --> 01:32:35.000]   New paragraph.
[01:32:35.000 --> 01:32:39.320]   So I do consider myself something of an expert.
[01:32:39.320 --> 01:32:42.200]   Google, I know we have to let you go pretty soon, because you've got to get to your panel
[01:32:42.200 --> 01:32:42.920]   about half an hour.
[01:32:42.920 --> 01:32:44.360]   So I'm not going to keep you much longer.
[01:32:44.360 --> 01:32:47.160]   But it's great to have you.
[01:32:47.160 --> 01:32:49.400]   It's always great to see you, David.
[01:32:49.400 --> 01:32:50.680]   Come up and visit us sometime.
[01:32:50.680 --> 01:32:52.840]   And good luck with your panel.
[01:32:53.560 --> 01:32:54.680]   Well, thank you so much, sir.
[01:32:54.680 --> 01:32:56.040]   And good to join you, gentlemen.
[01:32:56.040 --> 01:32:56.760]   Always a pleasure.
[01:32:56.760 --> 01:33:00.120]   David Pogue, founder of yahootechtech.yahoo.com.
[01:33:00.120 --> 01:33:01.960]   Oh, oh, can't forget the book.
[01:33:01.960 --> 01:33:04.120]   Love your new book.
[01:33:04.120 --> 01:33:05.080]   Pogue's Basics.
[01:33:05.080 --> 01:33:06.440]   Life.
[01:33:06.440 --> 01:33:10.600]   Essential tips and shortcuts that no one bothers to tell you.
[01:33:10.600 --> 01:33:13.560]   This is such a great book.
[01:33:13.560 --> 01:33:20.760]   It's all these little weird hacks, like, you know, using pinhole finger to see without glasses.
[01:33:20.760 --> 01:33:24.120]   Oh, that's the best.
[01:33:24.120 --> 01:33:26.120]   It's true.
[01:33:26.120 --> 01:33:26.680]   It's the pinhole.
[01:33:26.680 --> 01:33:30.440]   If you're if you're over 40 and you need glasses, you guys don't know about this.
[01:33:30.440 --> 01:33:30.920]   Yeah.
[01:33:30.920 --> 01:33:34.440]   Like, like when you're, you know what, Leo, like when you're in a hotel shower,
[01:33:34.440 --> 01:33:35.960]   and you can't read the little bottles.
[01:33:35.960 --> 01:33:36.360]   Uh-huh.
[01:33:36.360 --> 01:33:37.160]   And you're making it.
[01:33:37.160 --> 01:33:37.400]   How is that?
[01:33:37.400 --> 01:33:38.600]   It's perfect.
[01:33:38.600 --> 01:33:39.960]   So you'll do it all the time.
[01:33:39.960 --> 01:33:40.680]   Do you really?
[01:33:40.680 --> 01:33:42.200]   I do it all the time.
[01:33:42.200 --> 01:33:44.440]   Jason and Clint, as our producer.
[01:33:44.440 --> 01:33:44.760]   Wow.
[01:33:44.760 --> 01:33:46.040]   Yep.
[01:33:46.040 --> 01:33:47.320]   So anyway, this is a great book.
[01:33:47.320 --> 01:33:49.560]   It's available on Kindle, available on Amazon.
[01:33:49.560 --> 01:33:50.520]   It's out in paperback.
[01:33:50.520 --> 01:33:52.360]   Pogue's basics.
[01:33:52.360 --> 01:33:53.480]   Life.
[01:33:53.480 --> 01:33:56.200]   David's written the missing manual for years and years and years.
[01:33:56.200 --> 01:33:59.080]   And usually those are about technology subjects.
[01:33:59.080 --> 01:33:59.880]   This one's about life.
[01:33:59.880 --> 01:34:01.240]   The missing manual for life.
[01:34:01.240 --> 01:34:03.000]   Nice.
[01:34:03.000 --> 01:34:04.600]   You got very good taste in books, Leo.
[01:34:04.600 --> 01:34:06.680]   I have mine and I love it.
[01:34:06.680 --> 01:34:08.680]   They actually have a copy of it?
[01:34:08.680 --> 01:34:09.080]   Oh, yeah.
[01:34:09.080 --> 01:34:09.880]   They sent me a copy.
[01:34:09.880 --> 01:34:10.680]   I was so pleased.
[01:34:10.680 --> 01:34:11.480]   I didn't buy it.
[01:34:11.480 --> 01:34:12.040]   They sent me one.
[01:34:12.040 --> 01:34:13.160]   I would have bought it if they hadn't.
[01:34:13.160 --> 01:34:14.520]   Got you.
[01:34:14.520 --> 01:34:15.720]   They, I don't know who they is.
[01:34:15.720 --> 01:34:17.640]   It's not Apple because they don't send me crap.
[01:34:18.280 --> 01:34:20.040]   I'll make sure you stay on the list.
[01:34:20.040 --> 01:34:21.160]   I'm just teasing.
[01:34:21.160 --> 01:34:21.880]   Thank you, David.
[01:34:21.880 --> 01:34:22.760]   Always great to see you.
[01:34:22.760 --> 01:34:23.720]   Thank you.
[01:34:23.720 --> 01:34:25.400]   Take care, David Pogue.
[01:34:25.400 --> 01:34:25.880]   Tech that.
[01:34:25.880 --> 01:34:27.000]   Yahoo Tech Tech that.
[01:34:27.000 --> 01:34:27.640]   Yahoo.com.
[01:34:27.640 --> 01:34:29.880]   And Pogue's basics.
[01:34:29.880 --> 01:34:30.600]   We're going to take a break.
[01:34:30.600 --> 01:34:31.640]   Come back with more Nathan.
[01:34:31.640 --> 01:34:32.200]   You can stay.
[01:34:32.200 --> 01:34:35.480]   Yeah, then I don't have a South by Southwest panel to get to.
[01:34:35.480 --> 01:34:36.680]   Unfortunately, not this year.
[01:34:36.680 --> 01:34:37.080]   Yeah.
[01:34:37.080 --> 01:34:38.520]   Have you done them perils at Southway?
[01:34:38.520 --> 01:34:38.840]   Oh, yeah.
[01:34:38.840 --> 01:34:40.120]   Last couple of years I was doing them.
[01:34:40.120 --> 01:34:40.440]   Yeah.
[01:34:40.440 --> 01:34:41.560]   How come you're not going this year?
[01:34:41.560 --> 01:34:46.680]   You know, I just had some things that I need to take care of here.
[01:34:46.680 --> 01:34:48.040]   I have to say we stopped cover.
[01:34:48.040 --> 01:34:48.840]   We used to go.
[01:34:48.840 --> 01:34:49.240]   Yeah.
[01:34:49.240 --> 01:34:51.320]   Remember I did this body surfing with it.
[01:34:51.320 --> 01:34:52.200]   Oh, yeah.
[01:34:52.200 --> 01:34:53.480]   That was a dig event, right?
[01:34:53.480 --> 01:34:53.720]   Yeah.
[01:34:53.720 --> 01:34:56.200]   At the barbecue there.
[01:34:56.200 --> 01:34:58.120]   But it just turned out to be stubs.
[01:34:58.120 --> 01:34:59.480]   It just turned out to be a party
[01:34:59.480 --> 01:35:01.880]   instead of like an actual work event, right?
[01:35:01.880 --> 01:35:02.440]   Yeah.
[01:35:02.440 --> 01:35:03.400]   There wasn't that much to cover.
[01:35:03.400 --> 01:35:04.280]   There would have been this year.
[01:35:04.280 --> 01:35:04.760]   There's the game.
[01:35:04.760 --> 01:35:07.320]   They had the gamer gate all day panel yesterday.
[01:35:07.320 --> 01:35:09.080]   We could talk a little bit about that when we come back.
[01:35:09.080 --> 01:35:11.480]   The president spoke.
[01:35:11.480 --> 01:35:13.400]   So there would have been more news there this year.
[01:35:13.400 --> 01:35:15.240]   But we just felt like there's other events.
[01:35:15.240 --> 01:35:16.360]   Like we're going to cover an AB.
[01:35:17.560 --> 01:35:19.960]   You know, we were at Mobile World Congress
[01:35:19.960 --> 01:35:21.480]   that we could cover more
[01:35:21.480 --> 01:35:24.440]   useful than a big party for the 10th.
[01:35:24.440 --> 01:35:26.600]   In the mid to late 2000s.
[01:35:26.600 --> 01:35:27.080]   It was amazing.
[01:35:27.080 --> 01:35:29.720]   It was actually seen as like a launching pad
[01:35:29.720 --> 01:35:30.920]   for some of the most of the maps.
[01:35:30.920 --> 01:35:32.280]   Twitter launched in 2004.
[01:35:32.280 --> 01:35:34.360]   Square, which we thought was going to be a huge sensation.
[01:35:34.360 --> 01:35:36.040]   Not much.
[01:35:36.040 --> 01:35:36.440]   You know what?
[01:35:36.440 --> 01:35:37.240]   It was for a little bit.
[01:35:37.240 --> 01:35:38.360]   I still check in.
[01:35:38.360 --> 01:35:40.840]   I still check in places.
[01:35:40.840 --> 01:35:46.120]   I used to care so much about the mayor and I just don't bear you more.
[01:35:46.120 --> 01:35:46.760]   Yeah.
[01:35:46.760 --> 01:35:48.760]   But what's on the front page?
[01:35:48.760 --> 01:35:50.440]   All my phones swarm.
[01:35:50.440 --> 01:35:52.600]   That's the check in version of four square.
[01:35:52.600 --> 01:35:53.160]   All my phones.
[01:35:53.160 --> 01:35:55.560]   The breakout apps last few years have been a
[01:35:55.560 --> 01:35:56.040]   Miracat.
[01:35:56.040 --> 01:35:56.360]   Where is it going?
[01:35:56.360 --> 01:35:57.000]   Miracat?
[01:35:57.000 --> 01:35:58.360]   That was a year ago.
[01:35:58.360 --> 01:35:58.760]   Highlight.
[01:35:58.760 --> 01:35:59.560]   Remember Highlight?
[01:35:59.560 --> 01:36:00.920]   Miracat's dead already.
[01:36:00.920 --> 01:36:01.480]   Highlight.
[01:36:01.480 --> 01:36:02.600]   Oh, that was a pop.
[01:36:02.600 --> 01:36:05.160]   Twitter kind of killed Miracat with Periscope.
[01:36:05.160 --> 01:36:05.400]   Right.
[01:36:05.400 --> 01:36:07.000]   Like, you know, the idea is.
[01:36:07.000 --> 01:36:09.240]   Even, I got to say, even Periscope.
[01:36:09.240 --> 01:36:13.400]   Do you really think people live streaming is all that?
[01:36:13.400 --> 01:36:13.720]   No.
[01:36:13.720 --> 01:36:14.920]   I think celebrities like it.
[01:36:14.920 --> 01:36:16.040]   But it's not really.
[01:36:16.040 --> 01:36:19.400]   Because, you know, like the Galaxy S7 comes with YouTube.
[01:36:19.400 --> 01:36:20.360]   Direct streaming to YouTube.
[01:36:20.360 --> 01:36:22.360]   I can do YouTube live right from the phone.
[01:36:22.360 --> 01:36:24.920]   I mean, I'm on the camera all the time,
[01:36:24.920 --> 01:36:26.200]   so I don't really need to.
[01:36:26.200 --> 01:36:27.560]   I think everybody uses Snapchat.
[01:36:27.560 --> 01:36:28.440]   That's all they really want.
[01:36:28.440 --> 01:36:30.920]   I'm going to Periscope when there's Snapchat a lot.
[01:36:30.920 --> 01:36:32.040]   Do you go to Periscope and look at stuff?
[01:36:32.040 --> 01:36:33.640]   When there's breaking news, when there's things happening
[01:36:33.640 --> 01:36:35.240]   around the world, you'll see something CNN.
[01:36:35.240 --> 01:36:35.880]   Oh, all right.
[01:36:35.880 --> 01:36:38.680]   And I'll go into the map mode of Periscope and see it.
[01:36:38.680 --> 01:36:42.360]   Like the fires that happened in Dubai, the hotel.
[01:36:43.400 --> 01:36:44.840]   The CNN was covering their thing.
[01:36:44.840 --> 01:36:47.480]   And I was like, you know, let me see what the people on the street are doing.
[01:36:47.480 --> 01:36:49.080]   And I got like eight different angles of it.
[01:36:49.080 --> 01:36:52.840]   You know, I was wondering, because there's a Periscope app on Apple TV.
[01:36:52.840 --> 01:36:54.040]   And I thought, well, what would that be?
[01:36:54.040 --> 01:36:55.400]   Because people like to watch.
[01:36:55.400 --> 01:36:57.240]   But isn't it vertical?
[01:36:57.240 --> 01:36:59.240]   I know, that's a little strange.
[01:36:59.240 --> 01:37:00.840]   You can shoot sideways now.
[01:37:00.840 --> 01:37:01.240]   Can't you?
[01:37:01.240 --> 01:37:02.600]   Yeah.
[01:37:02.600 --> 01:37:04.760]   I feel like I watched a lot of Periscope video
[01:37:04.760 --> 01:37:07.560]   in those breaking news situations in the Twitter app itself.
[01:37:07.560 --> 01:37:11.320]   But I don't really go to Periscope itself for that.
[01:37:11.320 --> 01:37:14.040]   But yeah, I'm just not the typical user or something.
[01:37:14.040 --> 01:37:14.440]   I don't know.
[01:37:14.440 --> 01:37:15.240]   Same with Vine.
[01:37:15.240 --> 01:37:18.600]   Like I'll watch the six second vines when they show up in my Twitter stream.
[01:37:18.600 --> 01:37:21.320]   But I don't ever go and look at the Vine app.
[01:37:21.320 --> 01:37:23.800]   And that's especially great during sports.
[01:37:23.800 --> 01:37:26.680]   When you want to watch like that awesome play over and over again.
[01:37:26.680 --> 01:37:27.160]   Is that me?
[01:37:27.160 --> 01:37:30.440]   Outside, I think?
[01:37:30.440 --> 01:37:31.080]   Is that outside?
[01:37:31.080 --> 01:37:32.760]   Is it a tsunami warning?
[01:37:32.760 --> 01:37:34.360]   Is that me?
[01:37:34.360 --> 01:37:34.360]   Is that me?
[01:37:34.360 --> 01:37:34.840]   Is that me?
[01:37:34.840 --> 01:37:35.640]   Is that me?
[01:37:35.640 --> 01:37:36.200]   Because I have a report of you?
[01:37:36.200 --> 01:37:36.600]   One?
[01:37:36.600 --> 01:37:37.400]   Part of you would be honking.
[01:37:37.400 --> 01:37:38.600]   I'm curious about this video.
[01:37:38.600 --> 01:37:40.120]   When will you get old?
[01:37:40.120 --> 01:37:42.440]   Then you tell me.
[01:37:42.440 --> 01:37:43.480]   No, I shouldn't.
[01:37:43.480 --> 01:37:45.160]   No, I shouldn't have that dominoes for girls.
[01:37:45.160 --> 01:37:47.720]   I feel bad now.
[01:37:47.720 --> 01:37:48.920]   People in the chat were saying,
[01:37:48.920 --> 01:37:51.640]   "How can I can't believe Leo doesn't like dominoes?"
[01:37:51.640 --> 01:37:53.080]   I would have to go to get some dominoes.
[01:37:53.080 --> 01:37:54.440]   No?
[01:37:54.440 --> 01:37:54.920]   I'm right?
[01:37:54.920 --> 01:37:55.240]   No.
[01:37:55.240 --> 01:37:58.760]   No one's saying that.
[01:37:58.760 --> 01:37:59.320]   No one's saying that.
[01:37:59.320 --> 01:38:00.200]   You're fine.
[01:38:00.200 --> 01:38:00.760]   It's okay.
[01:38:00.760 --> 01:38:01.400]   Oh, poor dominoes.
[01:38:01.400 --> 01:38:01.880]   Could it be?
[01:38:01.880 --> 01:38:03.880]   I'm not giving them the benefit of the doubt.
[01:38:03.880 --> 01:38:06.200]   When you have a New Yorker pizza, why would you go to dominoes?
[01:38:06.200 --> 01:38:07.240]   We have good pizza.
[01:38:07.240 --> 01:38:07.880]   Yeah.
[01:38:07.880 --> 01:38:09.240]   And it comes from New York.
[01:38:09.240 --> 01:38:09.560]   Yeah.
[01:38:09.560 --> 01:38:10.600]   Sal comes from New York.
[01:38:10.600 --> 01:38:11.480]   Sal is a New Yorker.
[01:38:11.480 --> 01:38:14.600]   He used to have a pizza place in Brooklyn.
[01:38:14.600 --> 01:38:17.000]   Then he came to California, came to Petaluma.
[01:38:17.000 --> 01:38:17.880]   No, it makes it here.
[01:38:17.880 --> 01:38:22.200]   No one wants cheddar cheese on a pizza.
[01:38:22.200 --> 01:38:24.920]   No one wants hot dogs in the crust of the pizza.
[01:38:24.920 --> 01:38:27.640]   Although initially, that sounds like a great idea.
[01:38:27.640 --> 01:38:30.920]   I actually really want to try that so bad.
[01:38:30.920 --> 01:38:36.040]   I haven't tried it, but I know it's going to be terrible,
[01:38:36.040 --> 01:38:37.880]   but I just want to try it and see what it's like.
[01:38:37.880 --> 01:38:39.160]   And just to know that it's terrible.
[01:38:39.160 --> 01:38:40.200]   Here's what I think.
[01:38:40.200 --> 01:38:42.760]   I think by talking about dominoes on this show,
[01:38:42.760 --> 01:38:46.360]   we have just sold millions of pizzas.
[01:38:46.360 --> 01:38:48.280]   Like people are going to be eating it for dinner tonight.
[01:38:48.280 --> 01:38:51.320]   This is going to be the thing.
[01:38:51.320 --> 01:38:54.440]   I want a hot dog stuffed crust pizza.
[01:38:54.440 --> 01:38:58.680]   This is in the UK.
[01:38:58.680 --> 01:39:00.440]   Of course, they could sell this in the UK.
[01:39:00.440 --> 01:39:03.000]   Deliverance, well, having delivered up orders.
[01:39:03.000 --> 01:39:05.560]   Quite a few things from dominoes.
[01:39:05.560 --> 01:39:07.240]   We have a local dominoes branch.
[01:39:07.240 --> 01:39:10.600]   This is not inspiring me to want to eat a dominoes pizza.
[01:39:10.600 --> 01:39:12.920]   It is giving me flashbacks to my high school mustache though.
[01:39:12.920 --> 01:39:16.680]   He's going to feed it to his dog.
[01:39:16.680 --> 01:39:19.560]   Oh man, talk about drawing it out.
[01:39:19.560 --> 01:39:22.360]   This is the unboxing of a hot dog stuffed crust pizza.
[01:39:22.360 --> 01:39:26.600]   How much tan can one person wear?
[01:39:26.600 --> 01:39:29.240]   That's this guy is killing it.
[01:39:29.240 --> 01:39:34.200]   At least he bought a Dyson vacuum, so he's loyal to his people.
[01:39:34.200 --> 01:39:35.560]   A generous ingredients on that.
[01:39:35.560 --> 01:39:37.800]   This feels very fresh and hot.
[01:39:37.800 --> 01:39:39.160]   We should not mock this.
[01:39:39.160 --> 01:39:39.880]   This is good.
[01:39:39.880 --> 01:39:41.560]   This is what YouTube was made for.
[01:39:41.560 --> 01:39:51.560]   The dog is staring at him as he chews.
[01:39:51.560 --> 01:39:52.120]   John, the pink is...
[01:39:52.120 --> 01:39:55.960]   I don't want to be this kid today.
[01:39:55.960 --> 01:39:57.480]   Him eating the cheese off his lip,
[01:39:57.480 --> 01:39:59.240]   kind of reminded me of what was it.
[01:39:59.240 --> 01:40:00.680]   Oh, he's a croose of the...
[01:40:00.680 --> 01:40:03.400]   Oh, look, there's hot talking there.
[01:40:03.400 --> 01:40:05.160]   There's a hot dog in there.
[01:40:05.160 --> 01:40:08.680]   Shut up, I've had enough.
[01:40:08.680 --> 01:40:09.480]   Thank you very much.
[01:40:09.480 --> 01:40:11.960]   That video actually makes me not want to eat the hot dog.
[01:40:11.960 --> 01:40:12.920]   I take back calls.
[01:40:12.920 --> 01:40:14.360]   That's why I played that.
[01:40:14.360 --> 01:40:15.720]   That was a public service for you.
[01:40:15.720 --> 01:40:18.600]   Thanks for curbing that.
[01:40:18.600 --> 01:40:20.120]   Now I'm sitting with two bearded guys,
[01:40:20.120 --> 01:40:22.360]   but I'll tell you what, I'll tell you something about beards.
[01:40:22.360 --> 01:40:23.480]   You still have to shave, don't you?
[01:40:23.480 --> 01:40:25.240]   You don't just let it go crazy.
[01:40:25.240 --> 01:40:27.560]   You got a groom around the beard, right?
[01:40:27.560 --> 01:40:29.560]   You don't want it to be the neck beard.
[01:40:29.560 --> 01:40:31.080]   I got to get you a Harry's.
[01:40:31.080 --> 01:40:31.880]   Where's my Harry's?
[01:40:31.880 --> 01:40:32.280]   Look at this.
[01:40:32.920 --> 01:40:33.560]   Here we go.
[01:40:33.560 --> 01:40:34.200]   We're going to get you.
[01:40:34.200 --> 01:40:35.240]   I'm going to give you this.
[01:40:35.240 --> 01:40:39.240]   Harry's makes the best razors,
[01:40:39.240 --> 01:40:42.120]   and they sell them to you at about half the price of the drugstore blades.
[01:40:42.120 --> 01:40:44.520]   In fact, they come to you direct from the factory in Germany.
[01:40:44.520 --> 01:40:46.440]   Harry's, when they started, they said,
[01:40:46.440 --> 01:40:47.960]   "Where are the best blades made?"
[01:40:47.960 --> 01:40:49.320]   Well, there's two companies.
[01:40:49.320 --> 01:40:51.000]   There's two factories in Germany.
[01:40:51.000 --> 01:40:52.840]   Okay, let's buy one.
[01:40:52.840 --> 01:40:53.480]   And they did.
[01:40:53.480 --> 01:40:56.520]   And they engineer the blades for performance.
[01:40:56.520 --> 01:40:59.960]   They engineer the blades for sharpness.
[01:40:59.960 --> 01:41:02.600]   Man, this is a great blade.
[01:41:02.600 --> 01:41:06.520]   I have the Winston set at home because that's, in fact,
[01:41:06.520 --> 01:41:07.960]   I got the winter Winston with the copper handles.
[01:41:07.960 --> 01:41:08.920]   Beautiful.
[01:41:08.920 --> 01:41:09.800]   They have the Truman set.
[01:41:09.800 --> 01:41:11.960]   This is a Truman with a plastic handle.
[01:41:11.960 --> 01:41:13.400]   Winston sets their metal handles.
[01:41:13.400 --> 01:41:14.520]   But really, it's the blades.
[01:41:14.520 --> 01:41:15.800]   It really are what matter.
[01:41:15.800 --> 01:41:18.120]   Everything is beautifully designed,
[01:41:18.120 --> 01:41:19.560]   and they come right to your door.
[01:41:19.560 --> 01:41:22.280]   And if you're paying 32 bucks for an eight pack,
[01:41:22.280 --> 01:41:23.640]   forget it.
[01:41:23.640 --> 01:41:24.360]   Get Harry's.
[01:41:24.360 --> 01:41:25.720]   Now, here's a great deal.
[01:41:25.720 --> 01:41:26.520]   This is something new.
[01:41:26.520 --> 01:41:28.200]   For a limited time,
[01:41:28.200 --> 01:41:30.680]   they're so confident you're going to love your Harry's shave.
[01:41:30.680 --> 01:41:31.880]   They're getting you,
[01:41:31.880 --> 01:41:33.080]   going to let you try it for free.
[01:41:33.080 --> 01:41:36.440]   So go to harries.com/twits.
[01:41:36.440 --> 01:41:38.120]   Sign up for a shave plan.
[01:41:38.120 --> 01:41:41.480]   So you'll subscribe to blades and either the gel or the cream.
[01:41:41.480 --> 01:41:42.120]   I like the cream.
[01:41:42.120 --> 01:41:43.480]   A lot of people like the gel.
[01:41:43.480 --> 01:41:44.520]   And that'll be shipped to you,
[01:41:44.520 --> 01:41:46.920]   depending on how often you shave every month or every other month.
[01:41:46.920 --> 01:41:48.680]   But when you do that,
[01:41:48.680 --> 01:41:52.840]   they will then send you a beautifully crafted kit
[01:41:52.840 --> 01:41:53.720]   with the razor handle,
[01:41:53.720 --> 01:41:55.000]   with a fly blade cartridge,
[01:41:55.000 --> 01:41:57.320]   a starter set of foaming,
[01:41:57.320 --> 01:41:59.000]   shared gel and travel cover.
[01:41:59.000 --> 01:42:00.760]   All you have to do is cover the three dollar shipping chart.
[01:42:00.760 --> 01:42:02.120]   So it's a great way to try Harry's.
[01:42:02.120 --> 01:42:03.000]   You know, if you didn't like it,
[01:42:03.000 --> 01:42:04.200]   you just canceled the subscription.
[01:42:04.200 --> 01:42:05.320]   You don't have to worry about it.
[01:42:05.320 --> 01:42:06.600]   But I think you're going to like it.
[01:42:06.600 --> 01:42:07.720]   It's the best shave ever.
[01:42:07.720 --> 01:42:09.000]   And everybody I've given Harry's to,
[01:42:09.000 --> 01:42:10.840]   including you, Nathan,
[01:42:10.840 --> 01:42:12.200]   Oliveris, Giles.
[01:42:12.200 --> 01:42:15.160]   It's time to clean up that neck beard.
[01:42:15.160 --> 01:42:18.680]   I give you your first Harry's kit,
[01:42:18.680 --> 01:42:20.680]   harries.com/twits.
[01:42:20.680 --> 01:42:22.040]   I'll have one for you next time.
[01:42:22.040 --> 01:42:22.440]   All right.
[01:42:22.440 --> 01:42:23.240]   I'll take you up on that.
[01:42:23.240 --> 01:42:23.480]   All right.
[01:42:23.480 --> 01:42:24.520]   Actually, we probably have another one.
[01:42:24.520 --> 01:42:27.240]   Can we get another kit for Mark?
[01:42:27.240 --> 01:42:28.680]   No, we keep them in stock.
[01:42:28.680 --> 01:42:30.200]   It's a, it's a, it's a, it's a parting kit.
[01:42:30.200 --> 01:42:31.720]   I didn't think I'd get a gift coming here.
[01:42:31.720 --> 01:42:34.440]   Harry's, you're going to love it.
[01:42:34.440 --> 01:42:36.360]   Harry's thought, how you fix for blades?
[01:42:36.360 --> 01:42:37.160]   You good?
[01:42:37.160 --> 01:42:37.560]   Harry's.
[01:42:37.560 --> 01:42:40.920]   Yeah, that, that, that arcing green handle is pretty sharp.
[01:42:40.920 --> 01:42:41.240]   Yeah.
[01:42:41.240 --> 01:42:41.880]   Isn't that nice?
[01:42:41.880 --> 01:42:42.200]   It's nice.
[01:42:42.200 --> 01:42:42.840]   I like that one.
[01:42:42.840 --> 01:42:43.960]   They have different colors, but I like that.
[01:42:43.960 --> 01:42:47.000]   Can I elect to take a hot dog pizza instead of a Harry?
[01:42:47.000 --> 01:42:47.960]   I mean, Harry sounds great.
[01:42:47.960 --> 01:42:48.200]   Let's see.
[01:42:48.200 --> 01:42:49.080]   Is he still eating it?
[01:42:49.080 --> 01:42:52.520]   He's still going.
[01:42:52.520 --> 01:42:53.240]   He's still eating it?
[01:42:53.240 --> 01:42:54.280]   He's always with the,
[01:42:54.280 --> 01:42:56.200]   we need to hook him up with the little Harry's action.
[01:42:56.200 --> 01:42:57.320]   Let's give that.
[01:42:57.320 --> 01:42:58.360]   I'm hot dog.
[01:42:58.360 --> 01:42:59.960]   Cross guys, this is what you want to know about.
[01:42:59.960 --> 01:43:00.840]   So let's get straight to this.
[01:43:00.840 --> 01:43:02.360]   The hot dog stuff crosses back.
[01:43:02.360 --> 01:43:04.440]   Oh god.
[01:43:04.440 --> 01:43:06.040]   The dog's really interested.
[01:43:06.040 --> 01:43:07.720]   The dog is, so.
[01:43:07.720 --> 01:43:09.560]   That's a nice accompaniment.
[01:43:09.560 --> 01:43:10.120]   I will say.
[01:43:10.120 --> 01:43:13.240]   The dog's interested because it smells like Alpo.
[01:43:13.240 --> 01:43:18.440]   That's a very good pizza.
[01:43:18.440 --> 01:43:19.800]   Oh, shut up.
[01:43:19.800 --> 01:43:21.880]   Oh, shut up.
[01:43:21.880 --> 01:43:22.440]   Go away.
[01:43:23.240 --> 01:43:24.600]   Hey, some sad news.
[01:43:24.600 --> 01:43:25.800]   Actually, an interesting story.
[01:43:25.800 --> 01:43:31.000]   A guy named Robert Paladino, who taught for many years
[01:43:31.000 --> 01:43:32.680]   calligraphy at Reed University.
[01:43:32.680 --> 01:43:36.760]   And that's where Steve Jobs credits him and that calligraphy class
[01:43:36.760 --> 01:43:38.280]   with his sense of design.
[01:43:38.280 --> 01:43:40.760]   Steve, as some know, went to Reed.
[01:43:40.760 --> 01:43:41.720]   Couldn't afford to stay there.
[01:43:41.720 --> 01:43:43.800]   It was only went there, I think, for one semester or two.
[01:43:43.800 --> 01:43:47.560]   But ended up after dropping out, continuing to go to classes.
[01:43:47.560 --> 01:43:51.640]   He audited Robert Paladino's calligraphy class
[01:43:51.640 --> 01:43:57.640]   and became a lover of great fonts and typography.
[01:43:57.640 --> 01:44:01.800]   Paladino was a trappist monk for many years,
[01:44:01.800 --> 01:44:06.200]   a Roman Catholic priest and a calligrapher.
[01:44:06.200 --> 01:44:09.000]   And he passed away, I'm sad to say, on February 26th,
[01:44:09.000 --> 01:44:10.440]   the age of 83.
[01:44:10.440 --> 01:44:17.000]   For years, he would give babies, he baptized, baptismal certificates that he had
[01:44:17.000 --> 01:44:19.720]   hand-written out there.
[01:44:19.720 --> 01:44:20.840]   That would be something to have.
[01:44:20.840 --> 01:44:21.640]   Yeah.
[01:44:21.640 --> 01:44:26.440]   And of course, you know there's a font called Paladino in the Macintosh
[01:44:26.440 --> 01:44:29.880]   and that's a tribute to Father Paladino.
[01:44:29.880 --> 01:44:32.360]   He says, "I never met Steve Jobs."
[01:44:32.360 --> 01:44:36.360]   He was actually, he said, because he taught him.
[01:44:36.360 --> 01:44:41.560]   I guess he met him, but I don't think he really kind of remembers Steve Jobs.
[01:44:41.560 --> 01:44:46.040]   But he was very glad that he had some influence on him,
[01:44:46.040 --> 01:44:47.560]   although he never owned a computer.
[01:44:47.560 --> 01:44:49.240]   Wow.
[01:44:49.240 --> 01:44:49.720]   Nope.
[01:44:49.720 --> 01:44:50.520]   Had no interest.
[01:44:50.520 --> 01:44:53.560]   He liked to write by him.
[01:44:53.560 --> 01:44:54.600]   He did have an iPad Pro.
[01:44:54.600 --> 01:44:56.760]   No, he didn't.
[01:44:56.760 --> 01:44:58.840]   I wonder if he would have liked the pencil, you know?
[01:44:58.840 --> 01:45:01.160]   I wonder, it's kind of a shame.
[01:45:01.160 --> 01:45:02.680]   Maybe he's passed away, you know.
[01:45:02.680 --> 01:45:05.880]   But yeah, that would have been cool to see if he liked it or not.
[01:45:05.880 --> 01:45:06.200]   Yeah.
[01:45:06.200 --> 01:45:10.520]   He was asked to 2013 what he remembered of Steve Jobs.
[01:45:10.520 --> 01:45:13.080]   He says, and this is how we know he doesn't know Steve Jobs.
[01:45:13.080 --> 01:45:14.120]   He was most pleasant.
[01:45:14.120 --> 01:45:18.280]   Maybe Steve was back then.
[01:45:18.280 --> 01:45:19.000]   It's just a kid.
[01:45:19.000 --> 01:45:23.560]   Have you been following the Google AlphaGo computer that's playing?
[01:45:23.560 --> 01:45:26.200]   Yes, this is epic.
[01:45:26.200 --> 01:45:26.520]   That's great.
[01:45:26.520 --> 01:45:27.240]   Isn't this epic?
[01:45:27.240 --> 01:45:29.080]   Amazing story.
[01:45:29.080 --> 01:45:30.680]   It's like our modern deep blue.
[01:45:30.680 --> 01:45:31.080]   It is.
[01:45:31.080 --> 01:45:32.200]   It's just IBM--
[01:45:32.200 --> 01:45:34.760]   So as a chess player, I was really interested 20 years ago
[01:45:34.760 --> 01:45:38.040]   when Deep Blue beat the world champion Gary Cusbarov in 1997.
[01:45:38.040 --> 01:45:41.480]   And it really roiled the chess world because people didn't like the idea that a computer
[01:45:41.480 --> 01:45:44.280]   could best, the best human in the world easily.
[01:45:45.880 --> 01:45:49.720]   Well, 20 years-- fast forward 20 years, they've never been able to make a Go play in computer.
[01:45:49.720 --> 01:45:50.600]   It's very hard.
[01:45:50.600 --> 01:45:52.120]   It's a 19 by 19 board.
[01:45:52.120 --> 01:45:54.440]   There's only one kind of pieces, just a stone.
[01:45:54.440 --> 01:45:57.000]   You place pieces on the board.
[01:45:57.000 --> 01:45:58.680]   You take turns placing pieces.
[01:45:58.680 --> 01:46:01.080]   And the goal is to occupy territory.
[01:46:01.080 --> 01:46:04.280]   You know, there's small versions of Go.
[01:46:04.280 --> 01:46:06.520]   Kids often play with a 5 by 5 board.
[01:46:06.520 --> 01:46:07.080]   Same idea.
[01:46:07.080 --> 01:46:13.800]   You surround territory to command it if your pieces are in there and your opponent surrounds you.
[01:46:13.800 --> 01:46:15.080]   He takes your pieces off.
[01:46:15.080 --> 01:46:18.360]   At the end of the game, you count how many squares you control.
[01:46:18.360 --> 01:46:19.800]   Whoever controls the most squares wins.
[01:46:19.800 --> 01:46:22.680]   It's a very difficult game to play for computers.
[01:46:22.680 --> 01:46:24.040]   For humans.
[01:46:24.040 --> 01:46:24.360]   And too.
[01:46:24.360 --> 01:46:26.120]   Yeah, it's not a complicated game.
[01:46:26.120 --> 01:46:30.680]   Never really took off in the US, but it's very big in Japan and China.
[01:46:30.680 --> 01:46:34.440]   Lisa Dole is a Korean player who was 18 times the world champion.
[01:46:34.440 --> 01:46:37.160]   He's the highest ranked player.
[01:46:37.160 --> 01:46:38.200]   He's a 9-dan.
[01:46:38.200 --> 01:46:41.080]   They rank him in a scale of Donzi's 9-dan.
[01:46:41.080 --> 01:46:43.000]   He's lost.
[01:46:43.000 --> 01:46:43.640]   Or Nago.
[01:46:43.640 --> 01:46:45.320]   Yeah, you might say that.
[01:46:45.320 --> 01:46:48.200]   He's not currently the number one ranked player.
[01:46:48.200 --> 01:46:50.760]   In fact, there is another guy who is number one who says,
[01:46:50.760 --> 01:46:52.360]   "All right, I want my turn."
[01:46:52.360 --> 01:46:55.160]   AlphaGo, created by a company called DeepMind.
[01:46:55.160 --> 01:46:57.560]   Google bought DeepMind in the fall of last year,
[01:46:57.560 --> 01:47:01.480]   was the first computer design really to win Echo.
[01:47:01.480 --> 01:47:07.160]   It played a bunch of games against less proficient players.
[01:47:07.160 --> 01:47:10.040]   But more importantly, it was a learning AI.
[01:47:10.040 --> 01:47:13.160]   And it played tens of thousands of games against itself.
[01:47:13.160 --> 01:47:16.920]   And taught itself to play, which is fascinating.
[01:47:16.920 --> 01:47:19.400]   It was a five game match.
[01:47:19.400 --> 01:47:23.880]   Game one, the computer wins, shocking.
[01:47:23.880 --> 01:47:26.840]   But Lisa Dole said, "Well, wait a minute.
[01:47:26.840 --> 01:47:28.360]   I didn't play that well."
[01:47:28.360 --> 01:47:30.360]   Game two, the computer wins, shocking.
[01:47:30.360 --> 01:47:32.360]   But still, there was some question.
[01:47:32.360 --> 01:47:35.640]   Is the computer playing well or is Lisa Dole thrown by the computer's style,
[01:47:35.640 --> 01:47:36.600]   which is non-human?
[01:47:37.480 --> 01:47:41.800]   Game three, which was on enough Friday night.
[01:47:41.800 --> 01:47:44.120]   Computer wins again.
[01:47:44.120 --> 01:47:45.240]   And this time, for the first time,
[01:47:45.240 --> 01:47:48.440]   I heard a number of Go players say, "No, you know what?
[01:47:48.440 --> 01:47:51.000]   This computer played better than any Go players ever played."
[01:47:51.000 --> 01:47:53.160]   And that's it. Five games, the computer won three.
[01:47:53.160 --> 01:47:54.440]   It won three. It was over.
[01:47:54.440 --> 01:47:55.800]   Lisa Dole said, "I want to keep playing."
[01:47:55.800 --> 01:47:57.240]   So they played another one, and he won.
[01:47:57.240 --> 01:48:01.560]   Game four, Lisa Dole won.
[01:48:01.560 --> 01:48:06.520]   So even though AlphaGo has won the match already,
[01:48:06.520 --> 01:48:07.640]   because it's the best of five.
[01:48:07.640 --> 01:48:12.440]   And then Game five is Monday night.
[01:48:12.440 --> 01:48:12.920]   Yep.
[01:48:12.920 --> 01:48:13.480]   Final match.
[01:48:13.480 --> 01:48:14.760]   See, a lot of interest in that.
[01:48:14.760 --> 01:48:19.800]   Some think that Lisa Dole figured out how the computer played,
[01:48:19.800 --> 01:48:21.320]   and he stayed up late.
[01:48:21.320 --> 01:48:22.680]   He stayed up till 6 a.m.
[01:48:22.680 --> 01:48:27.160]   Analyzing the game with his teammates.
[01:48:27.160 --> 01:48:28.280]   Pound and Red Bulls.
[01:48:28.280 --> 01:48:29.080]   Listen to music too.
[01:48:29.080 --> 01:48:29.480]   He did.
[01:48:29.480 --> 01:48:30.600]   Like obsessing over the...
[01:48:30.600 --> 01:48:31.160]   Obsessing.
[01:48:31.160 --> 01:48:34.120]   I've never had any play in the game before.
[01:48:34.120 --> 01:48:35.560]   I've never played it.
[01:48:36.280 --> 01:48:38.440]   I have played it. It's a beautiful game.
[01:48:38.440 --> 01:48:39.880]   But it's very hard.
[01:48:39.880 --> 01:48:41.240]   As a serious chess player,
[01:48:41.240 --> 01:48:46.520]   they talk a lot about how it's a game of intuition,
[01:48:46.520 --> 01:48:47.320]   and how it's...
[01:48:47.320 --> 01:48:47.880]   Well, you can't...
[01:48:47.880 --> 01:48:49.640]   It almost requires a human-like mindset.
[01:48:49.640 --> 01:48:54.040]   In chess, you can look ahead,
[01:48:54.040 --> 01:48:55.960]   and you can kind of calculate,
[01:48:55.960 --> 01:48:58.280]   and the computer course can calculate better than a human.
[01:48:58.280 --> 01:49:02.600]   But Go, there's so many possibilities.
[01:49:02.600 --> 01:49:04.760]   It's very hard to calculate, and win.
[01:49:05.960 --> 01:49:08.440]   So you really got to...
[01:49:08.440 --> 01:49:11.080]   A computer has to do a lot of pattern recognition.
[01:49:11.080 --> 01:49:14.200]   One of the big surprises from some of the people who watch...
[01:49:14.200 --> 01:49:17.640]   Who know how Go works, as I've heard.
[01:49:17.640 --> 01:49:19.640]   I don't really know a whole lot about the game,
[01:49:19.640 --> 01:49:21.320]   but they say that he doesn't...
[01:49:21.320 --> 01:49:24.920]   The machine doesn't play like a human at all.
[01:49:24.920 --> 01:49:26.360]   At one point in one of the matches,
[01:49:26.360 --> 01:49:30.600]   the machine made a move that was so unusual.
[01:49:30.600 --> 01:49:34.600]   Lisa Dole got up from his seat and left the room.
[01:49:34.600 --> 01:49:35.800]   Just a quantum play.
[01:49:35.800 --> 01:49:36.600]   He was shaking.
[01:49:36.600 --> 01:49:38.440]   He was shaking, and he's still on the clock.
[01:49:38.440 --> 01:49:39.960]   It's a lot like chess where you're on the clock.
[01:49:39.960 --> 01:49:43.000]   And so it affects you to wait, but he was just...
[01:49:43.000 --> 01:49:43.720]   Yeah.
[01:49:43.720 --> 01:49:45.720]   So we had on the new screensavers,
[01:49:45.720 --> 01:49:48.280]   we had the president of the American Go Association
[01:49:48.280 --> 01:49:49.400]   on to talk a little bit about this,
[01:49:49.400 --> 01:49:51.960]   because you need to have a Go player to explain it.
[01:49:51.960 --> 01:49:53.960]   He said, "One of the things that happens with Go
[01:49:53.960 --> 01:49:56.040]   is as you're playing the game as a human,
[01:49:56.040 --> 01:49:57.080]   you're always calculating,
[01:49:57.080 --> 01:49:58.120]   'Well, how far ahead am I?
[01:49:58.120 --> 01:50:00.760]   How many more squares do I control?'
[01:50:02.040 --> 01:50:05.480]   And even if you're 19 ahead,
[01:50:05.480 --> 01:50:07.800]   you kind of continue to build.
[01:50:07.800 --> 01:50:10.360]   If you're 19 behind, you work harder."
[01:50:10.360 --> 01:50:11.880]   He said, "The computer doesn't work that way at all.
[01:50:11.880 --> 01:50:13.800]   It's calculating its chance of winning the game.
[01:50:13.800 --> 01:50:16.360]   It doesn't care about the current standing.
[01:50:16.360 --> 01:50:19.160]   It's just saying, "What's the best move to win the game,
[01:50:19.160 --> 01:50:21.320]   even if I only win by one square?
[01:50:21.320 --> 01:50:22.040]   I don't care."
[01:50:22.040 --> 01:50:25.080]   And that's not how humans play Go.
[01:50:25.080 --> 01:50:28.680]   There's also a lot of tradition in Go.
[01:50:28.680 --> 01:50:30.680]   Oh, this verge had a good verge piece.
[01:50:30.680 --> 01:50:34.040]   Let me show you a little bit of the game of Go.
[01:50:34.040 --> 01:50:36.440]   It's like the random shot of the movie "I Robot."
[01:50:36.440 --> 01:50:37.960]   Yeah, well, you got to throw that in.
[01:50:37.960 --> 01:50:39.880]   Yeah, I mean, if you're going to do it,
[01:50:39.880 --> 01:50:41.080]   you got to throw in an "I Robot."
[01:50:41.080 --> 01:50:43.240]   Any Will Smith referencing and hacking into it?
[01:50:43.240 --> 01:50:44.760]   I'm going to do it to understand new possibilities.
[01:50:44.760 --> 01:50:46.280]   One of the greatest actors of all time.
[01:50:46.280 --> 01:50:47.560]   Will Smith?
[01:50:47.560 --> 01:50:48.760]   I like Will Smith.
[01:50:48.760 --> 01:50:50.120]   We give it to her.
[01:50:50.120 --> 01:50:51.080]   We give it to her.
[01:50:51.080 --> 01:50:52.600]   I love Will Smith.
[01:50:52.600 --> 01:50:53.960]   Yeah.
[01:50:53.960 --> 01:50:58.280]   So it's a huge AI step, frankly,
[01:50:58.280 --> 01:51:00.120]   because it's neural networks that they're using,
[01:51:00.120 --> 01:51:02.280]   and it's very sensitive.
[01:51:02.280 --> 01:51:04.440]   I think this is really cool.
[01:51:04.440 --> 01:51:07.880]   I don't think I'm as fascinated by this as everyone else
[01:51:07.880 --> 01:51:09.000]   supposedly seems to be.
[01:51:09.000 --> 01:51:13.240]   Maybe it's because I don't care about the game Go very much.
[01:51:13.240 --> 01:51:15.800]   I know it's a huge milestone for AI,
[01:51:15.800 --> 01:51:19.640]   but it also feels like when IBM's Watson
[01:51:19.640 --> 01:51:21.400]   beat a human being in jeopardy,
[01:51:21.400 --> 01:51:24.360]   or the chess situation you talked about,
[01:51:24.360 --> 01:51:28.440]   it's like maybe I'm jaded or I've seen too many science fiction movies,
[01:51:28.440 --> 01:51:30.920]   but it's kind of like, well, this was going to happen.
[01:51:30.920 --> 01:51:33.560]   This was inevitable that a computer reached this point.
[01:51:33.560 --> 01:51:34.280]   And so it's cool.
[01:51:34.280 --> 01:51:37.480]   I guess the surprising is how quickly it's...
[01:51:37.480 --> 01:51:40.200]   I mean, the people who had been following
[01:51:40.200 --> 01:51:42.600]   the developments of some of these AI
[01:51:42.600 --> 01:51:44.760]   thought it wouldn't happen for another five or 10 years.
[01:51:44.760 --> 01:51:46.520]   Yeah, but I mean, it's just kind of like...
[01:51:46.520 --> 01:51:50.040]   If you look at the way technology works,
[01:51:50.040 --> 01:51:52.280]   you're constantly building on what other people have done
[01:51:52.280 --> 01:51:53.160]   and what comes before.
[01:51:53.160 --> 01:51:55.240]   So in the...
[01:51:55.240 --> 01:51:57.880]   Facebook also working on a Go playing AI.
[01:51:57.880 --> 01:51:58.600]   Yeah.
[01:51:58.600 --> 01:52:01.080]   So it's like the computers...
[01:52:01.080 --> 01:52:02.600]   More because they have an AI challenge
[01:52:02.600 --> 01:52:03.960]   than because they want to win a Go on.
[01:52:03.960 --> 01:52:05.000]   Yeah, yeah, yeah.
[01:52:05.000 --> 01:52:08.280]   But these are basically stepping stones
[01:52:08.280 --> 01:52:10.360]   to building an actual useful AI.
[01:52:10.360 --> 01:52:10.840]   Yes.
[01:52:10.840 --> 01:52:14.680]   And so just in the same way that our smartphones are
[01:52:14.680 --> 01:52:18.440]   way more powerful than anyone predicted a computer
[01:52:18.440 --> 01:52:20.920]   could have been in an pocket 20 years ago or whatever.
[01:52:20.920 --> 01:52:23.320]   Like the kind of...
[01:52:23.320 --> 01:52:26.680]   The guesstomences to when we would get here mean less to me
[01:52:26.680 --> 01:52:27.880]   than just the milestone itself.
[01:52:27.880 --> 01:52:30.600]   So I kind of feel like it's cool, it's neat.
[01:52:30.600 --> 01:52:32.760]   And now I'm like already like what's next, you know?
[01:52:32.760 --> 01:52:34.920]   60 million Chinese watch the first game.
[01:52:34.920 --> 01:52:37.560]   This milestone from about a year ago
[01:52:37.560 --> 01:52:38.840]   is a little more interesting.
[01:52:38.840 --> 01:52:41.880]   The Google 360 AI system that plays video games.
[01:52:41.880 --> 01:52:42.440]   Yes.
[01:52:42.440 --> 01:52:43.720]   And watch it.
[01:52:43.720 --> 01:52:44.200]   So this was...
[01:52:44.200 --> 01:52:46.040]   You can pull it up on your screen.
[01:52:46.040 --> 01:52:47.800]   It's like...
[01:52:47.800 --> 01:52:49.480]   It has the progression where it shows
[01:52:49.480 --> 01:52:51.160]   what it was like early on in the process
[01:52:51.160 --> 01:52:53.480]   of trying to figure out how breakout works.
[01:52:53.480 --> 01:52:54.520]   And it was terrible.
[01:52:55.320 --> 01:52:56.360]   And then...
[01:52:56.360 --> 01:52:57.320]   Is it a little creepy?
[01:52:57.320 --> 01:53:00.200]   Do you find a little creepy to watch these things learn?
[01:53:00.200 --> 01:53:01.480]   Very creepy.
[01:53:01.480 --> 01:53:03.000]   I don't think it's that creepy.
[01:53:03.000 --> 01:53:03.880]   This is what they do.
[01:53:03.880 --> 01:53:07.080]   They figure out something and then they try and they fail
[01:53:07.080 --> 01:53:09.800]   and they figure out how to get around it by failing.
[01:53:09.800 --> 01:53:11.800]   It's like okay, this path did not work.
[01:53:11.800 --> 01:53:13.000]   Let's try this path did not work.
[01:53:13.000 --> 01:53:14.120]   Let's try this path did not work.
[01:53:14.120 --> 01:53:14.840]   This path worked.
[01:53:14.840 --> 01:53:15.400]   This path works.
[01:53:15.400 --> 01:53:17.080]   So they're able to build on that
[01:53:17.080 --> 01:53:19.800]   and it's just kind of a process of elimination.
[01:53:19.800 --> 01:53:20.120]   Like...
[01:53:20.120 --> 01:53:22.200]   Do you ever see a screensaver called
[01:53:22.200 --> 01:53:25.160]   "Brevewalk" or a Brevwalk or B-R-E-V-E?
[01:53:25.160 --> 01:53:27.080]   So this is another...
[01:53:27.080 --> 01:53:29.560]   Actually pretty old AI thing where...
[01:53:29.560 --> 01:53:31.800]   It's a great screensaver.
[01:53:31.800 --> 01:53:33.000]   I don't know if you can still get it.
[01:53:33.000 --> 01:53:33.800]   My kids used to love it.
[01:53:33.800 --> 01:53:37.320]   It gives you a creature.
[01:53:37.320 --> 01:53:40.120]   And the creature's goal is to learn to walk.
[01:53:40.120 --> 01:53:44.280]   So it tries many, many strategies of legs and walking.
[01:53:44.280 --> 01:53:46.600]   It's got four legs and it learns to walk.
[01:53:46.600 --> 01:53:47.560]   But it takes a long time.
[01:53:47.560 --> 01:53:51.320]   But watching it learn to walk is fascinating and creepy
[01:53:51.320 --> 01:53:52.200]   at the same time.
[01:53:52.200 --> 01:53:54.280]   But my kids...
[01:53:54.280 --> 01:53:54.920]   Brevwalker.
[01:53:54.920 --> 01:53:58.280]   My kids loved watching it.
[01:53:58.280 --> 01:53:59.640]   Yeah, you can get it on the App Store.
[01:53:59.640 --> 01:54:01.080]   Awesome.
[01:54:01.080 --> 01:54:04.200]   So you can now get your very own Brevwalker.
[01:54:04.200 --> 01:54:05.080]   That's what it looks like.
[01:54:05.080 --> 01:54:09.320]   App last updated December 2009.
[01:54:09.320 --> 01:54:10.040]   Yeah, it's old.
[01:54:10.040 --> 01:54:12.120]   Hey, what's wrong with that?
[01:54:12.120 --> 01:54:13.800]   You know, it's learning.
[01:54:13.800 --> 01:54:14.440]   It's a throwback.
[01:54:14.440 --> 01:54:15.320]   It's a throwback.
[01:54:15.320 --> 01:54:19.080]   That actually is newer than the one I was using,
[01:54:19.080 --> 01:54:20.600]   which was a screensaver.
[01:54:20.600 --> 01:54:21.160]   Here's a...
[01:54:21.160 --> 01:54:22.360]   You want to watch a little video?
[01:54:22.360 --> 01:54:23.560]   Sure, let's watch a little video.
[01:54:23.560 --> 01:54:25.240]   These are the Brevwalkers.
[01:54:25.240 --> 01:54:26.440]   So what's creepy is it that?
[01:54:26.440 --> 01:54:28.600]   It's not doing so well.
[01:54:28.600 --> 01:54:29.080]   It's like a little...
[01:54:29.080 --> 01:54:31.720]   They're all over the place.
[01:54:31.720 --> 01:54:32.360]   Yeah.
[01:54:32.360 --> 01:54:36.200]   What it shows you is AI can evolve and a thing can learn.
[01:54:36.200 --> 01:54:38.840]   And eventually over time, it actually does learn to walk.
[01:54:38.840 --> 01:54:43.480]   And in the meantime, there's some pretty funny failures.
[01:54:43.480 --> 01:54:46.520]   Just like the ARPA, Grand ARPA challenge,
[01:54:46.520 --> 01:54:47.800]   where the robots fall over.
[01:54:47.800 --> 01:54:48.600]   Yeah.
[01:54:49.560 --> 01:54:51.560]   Don't kick them though, because I think we really shouldn't
[01:54:51.560 --> 01:54:56.360]   exacerbate that problem that we're going to face in the near future.
[01:54:56.360 --> 01:55:02.520]   Oh, I was going to mention this before we had to let David go.
[01:55:02.520 --> 01:55:06.360]   Google is working on voice recognition that's offline.
[01:55:06.360 --> 01:55:10.360]   And because it's offline, it's a lot faster.
[01:55:10.360 --> 01:55:14.360]   Like 20 times faster, because it doesn't have to go to the server.
[01:55:14.360 --> 01:55:16.920]   And isn't that really where Siri falls down a lot?
[01:55:16.920 --> 01:55:18.920]   Is I can't get on the network.
[01:55:18.920 --> 01:55:19.800]   What did you say?
[01:55:19.800 --> 01:55:23.640]   What's interesting about this is only 20 megabytes.
[01:55:23.640 --> 01:55:26.680]   So you don't need to put a lot of data on the computer.
[01:55:26.680 --> 01:55:29.400]   I'm sorry, it's only seven times faster.
[01:55:29.400 --> 01:55:33.080]   You know, Apple used to have a version of this.
[01:55:33.080 --> 01:55:34.840]   And you're not even voice control.
[01:55:34.840 --> 01:55:37.160]   That would work with offline access.
[01:55:37.160 --> 01:55:39.720]   It would only respond to set commands.
[01:55:39.720 --> 01:55:43.160]   But I think it was faster.
[01:55:43.160 --> 01:55:44.200]   So you know how they trained it?
[01:55:44.200 --> 01:55:47.640]   Three million anonymous voice samplers, 2,000 hours.
[01:55:48.520 --> 01:55:53.000]   From Google search, each voice sample at 20 distorted versions created by extracting noise
[01:55:53.000 --> 01:55:54.520]   from YouTube videos.
[01:55:54.520 --> 01:55:55.880]   It's a learning machine.
[01:55:55.880 --> 01:55:56.680]   This is all boy.
[01:55:56.680 --> 01:55:57.720]   This is the key, isn't it?
[01:55:57.720 --> 01:55:58.440]   Yep.
[01:55:58.440 --> 01:56:01.160]   AI and any day now, it's over.
[01:56:01.160 --> 01:56:06.280]   I hope you've enjoyed your pathetic little life in the last 30,000 years.
[01:56:06.280 --> 01:56:07.720]   It's one of your dominoes.
[01:56:07.720 --> 01:56:09.080]   Live.
[01:56:09.080 --> 01:56:09.320]   Yeah.
[01:56:09.320 --> 01:56:11.560]   That's what happens when you eat hot dog crust pizzas.
[01:56:11.560 --> 01:56:13.560]   There's no future.
[01:56:14.680 --> 01:56:18.440]   Moot Chris Poole, founder of 4chan, went to Google.
[01:56:18.440 --> 01:56:19.880]   He's now working on Google.
[01:56:19.880 --> 01:56:21.720]   Plus, what?
[01:56:21.720 --> 01:56:23.560]   That's a punishment for creating 4chan.
[01:56:23.560 --> 01:56:27.080]   Pay your debt to society.
[01:56:27.080 --> 01:56:28.120]   Wow.
[01:56:28.120 --> 01:56:31.240]   It's like the West worse than the jail David was in.
[01:56:31.240 --> 01:56:36.120]   It's like the Google+ team is on a roof somewhere.
[01:56:36.120 --> 01:56:40.520]   I swear to God, I think that's Yahoo's hoolie right there.
[01:56:40.520 --> 01:56:42.360]   Holy roof plan.
[01:56:43.400 --> 01:56:47.400]   I put my Android N on my Nexus 6.
[01:56:47.400 --> 01:56:49.560]   I'm so pissed I couldn't get on my Nexus 5.
[01:56:49.560 --> 01:56:55.000]   Yeah, you still have a 6x or 6x.
[01:56:55.000 --> 01:56:55.560]   Do you have a...
[01:56:55.560 --> 01:56:58.040]   What was the little TV thing?
[01:56:58.040 --> 01:56:59.640]   Not the one you have, but the newer one.
[01:56:59.640 --> 01:57:01.320]   Oh, the Chromecast?
[01:57:01.320 --> 01:57:03.960]   I know the Android TV device.
[01:57:03.960 --> 01:57:04.760]   I like it.
[01:57:04.760 --> 01:57:06.360]   Actually, it's interesting,
[01:57:06.360 --> 01:57:08.040]   is they've never done this before, a public beta.
[01:57:08.040 --> 01:57:12.440]   And you can just go to android.com/beta, I think,
[01:57:12.440 --> 01:57:14.680]   and say, if you have one of those devices,
[01:57:14.680 --> 01:57:15.720]   you have a Nexus device.
[01:57:15.720 --> 01:57:18.040]   I put it on my Pixel C to the split screen,
[01:57:18.040 --> 01:57:20.200]   makes the Pixel C quite usable, I think.
[01:57:20.200 --> 01:57:20.680]   Interesting.
[01:57:20.680 --> 01:57:21.800]   It's a revolution.
[01:57:21.800 --> 01:57:24.120]   But what's interesting is how stable this is.
[01:57:24.120 --> 01:57:25.800]   This is the first release.
[01:57:25.800 --> 01:57:29.880]   It won't be out till, what is it, fall, or later.
[01:57:29.880 --> 01:57:32.280]   And it's working pretty nicely.
[01:57:32.280 --> 01:57:33.800]   There's a few little glitches here and there.
[01:57:33.800 --> 01:57:40.280]   I like how it consolidates notifications into a single chunk.
[01:57:40.280 --> 01:57:43.720]   And then you can expand the chunk and see what all of the notifications are.
[01:57:43.720 --> 01:57:44.840]   It really helps a lot with that.
[01:57:44.840 --> 01:57:46.520]   Is there split screen on the phone as well?
[01:57:46.520 --> 01:57:47.640]   I saw that.
[01:57:47.640 --> 01:57:48.040]   There is.
[01:57:48.040 --> 01:57:49.400]   You find it useful at all.
[01:57:49.400 --> 01:57:51.160]   No, I think it's too small a screen to be useful.
[01:57:51.160 --> 01:57:52.120]   It's great on the Pixel.
[01:57:52.120 --> 01:57:55.640]   And I couldn't get it to work as the other thing.
[01:57:55.640 --> 01:57:56.840]   So maybe that...
[01:57:56.840 --> 01:57:58.280]   I don't know, maybe it isn't on the phone.
[01:57:58.280 --> 01:58:00.840]   Because you're supposed to long press the reasons.
[01:58:00.840 --> 01:58:02.040]   And remember Jeff had it...
[01:58:02.040 --> 01:58:03.400]   He got it to work.
[01:58:03.400 --> 01:58:05.720]   On the 6p, I thought.
[01:58:05.720 --> 01:58:07.240]   It's never worked for me.
[01:58:07.240 --> 01:58:08.360]   It works fine on the Pixel C.
[01:58:08.840 --> 01:58:11.560]   So you go to the Grilled Cheese.
[01:58:11.560 --> 01:58:15.400]   Yeah, if you long press the reasons, you get the Grilled Cheese.
[01:58:15.400 --> 01:58:17.800]   But it's not happening.
[01:58:17.800 --> 01:58:18.760]   That sounds strange.
[01:58:18.760 --> 01:58:19.640]   I love Grilled Cheese.
[01:58:19.640 --> 01:58:20.440]   I don't know where you're talking about.
[01:58:20.440 --> 01:58:22.360]   So you know the hamburger menu is three lines?
[01:58:22.360 --> 01:58:22.920]   Oh yeah.
[01:58:22.920 --> 01:58:24.360]   It's a two-line hamburger menu.
[01:58:24.360 --> 01:58:25.960]   So we've decided that's a Grilled Cheese.
[01:58:25.960 --> 01:58:26.760]   I like it.
[01:58:26.760 --> 01:58:27.560]   I like it.
[01:58:27.560 --> 01:58:27.960]   Yeah.
[01:58:27.960 --> 01:58:29.560]   Better than a hot dog stuffed pizza.
[01:58:29.560 --> 01:58:30.440]   I could tell you that right now.
[01:58:30.440 --> 01:58:31.720]   I still don't know what you're talking about.
[01:58:31.720 --> 01:58:33.160]   The hamburger button.
[01:58:33.160 --> 01:58:34.680]   You know what the hamburger button is?
[01:58:34.680 --> 01:58:35.240]   Three lines?
[01:58:36.200 --> 01:58:37.240]   You tell me you've seen the hamburger.
[01:58:37.240 --> 01:58:39.320]   Is this like a bun with a piece of meat in it?
[01:58:39.320 --> 01:58:39.640]   Yeah.
[01:58:39.640 --> 01:58:40.760]   You've seen a hamburger menu.
[01:58:40.760 --> 01:58:43.240]   Have you held an Android phone before?
[01:58:43.240 --> 01:58:45.080]   No, it's like when you see a bun and a lot.
[01:58:45.080 --> 01:58:46.920]   So on Google Maps and the left-hand corner...
[01:58:46.920 --> 01:58:48.440]   Oh, I'm talking to my grandma.
[01:58:48.440 --> 01:58:49.240]   I love Google Maps.
[01:58:49.240 --> 01:58:50.360]   What the hell?
[01:58:50.360 --> 01:58:51.720]   You don't know what a hamburger menu?
[01:58:51.720 --> 01:58:52.920]   I do not know this one.
[01:58:52.920 --> 01:58:53.400]   See that?
[01:58:53.400 --> 01:58:53.960]   You've seen that?
[01:58:53.960 --> 01:58:55.000]   It's the hamburger button.
[01:58:55.000 --> 01:58:56.360]   Oh, the hamburger menu.
[01:58:56.360 --> 01:58:57.800]   Three horizontal lines.
[01:58:57.800 --> 01:58:59.240]   Yes, that's the worst thing.
[01:58:59.240 --> 01:58:59.960]   It's called the hamburger,
[01:58:59.960 --> 01:59:01.400]   because it looks like a hamburger, right?
[01:59:01.400 --> 01:59:01.960]   One's in a patty.
[01:59:01.960 --> 01:59:02.440]   All right.
[01:59:02.440 --> 01:59:04.120]   Now that you see it, you'll never see it.
[01:59:04.120 --> 01:59:07.720]   It's just the bread or something.
[01:59:07.720 --> 01:59:08.520]   Yeah.
[01:59:08.520 --> 01:59:10.040]   It really shouldn't even be a grilled cheese.
[01:59:10.040 --> 01:59:11.160]   It should be a bread sandwich.
[01:59:11.160 --> 01:59:12.280]   It should be like that.
[01:59:12.280 --> 01:59:12.840]   Bread sandwich.
[01:59:12.840 --> 01:59:15.080]   But I can't get it to do the bread sandwich for some reason.
[01:59:15.080 --> 01:59:18.360]   So I don't know if maybe there's something wrong out here.
[01:59:18.360 --> 01:59:20.040]   Anyway, nice.
[01:59:20.040 --> 01:59:21.320]   And it's good that they released it.
[01:59:21.320 --> 01:59:23.640]   And while I wouldn't recommend it on a phone that you absolutely
[01:59:23.640 --> 01:59:25.160]   need to have, I haven't any problems with it,
[01:59:25.160 --> 01:59:26.200]   which is surprising.
[01:59:26.200 --> 01:59:27.080]   It means it's closer.
[01:59:27.080 --> 01:59:29.720]   And I think it's one of the reasons they released it.
[01:59:29.720 --> 01:59:33.880]   It's closer than we thought as to what they will name
[01:59:33.880 --> 01:59:38.520]   and they're not saying it's got to be a dessert begins the letter
[01:59:38.520 --> 01:59:40.760]   and OK, here's a quiz.
[01:59:40.760 --> 01:59:41.160]   Nougat.
[01:59:41.160 --> 01:59:42.440]   That's what I think.
[01:59:42.440 --> 01:59:43.080]   But here's a quiz.
[01:59:43.080 --> 01:59:46.120]   Could you name all of the Android dessert versions?
[01:59:46.120 --> 01:59:47.000]   Oh, I can do it.
[01:59:47.000 --> 01:59:48.440]   I won't make you start.
[01:59:48.440 --> 01:59:50.920]   Well, I never wrote the A or B was never released.
[01:59:50.920 --> 01:59:50.920]   Right.
[01:59:50.920 --> 01:59:51.720]   It was no A or B.
[01:59:51.720 --> 01:59:52.520]   First one is C.
[01:59:52.520 --> 01:59:53.160]   Cupcake.
[01:59:53.160 --> 01:59:53.640]   Cupcake.
[01:59:53.640 --> 01:59:54.040]   Cupcake.
[01:59:54.040 --> 01:59:54.920]   Donut.
[01:59:54.920 --> 01:59:55.640]   Eclair.
[01:59:55.640 --> 01:59:56.280]   Froyo.
[01:59:56.280 --> 01:59:58.200]   G.
[01:59:58.200 --> 01:59:59.400]   Was gingerbread.
[01:59:59.400 --> 01:59:59.880]   Is it your bread?
[01:59:59.880 --> 02:00:00.760]   Honeycomb.
[02:00:00.760 --> 02:00:01.000]   Yeah.
[02:00:01.000 --> 02:00:03.080]   That was only for tablets.
[02:00:03.080 --> 02:00:03.560]   Yep.
[02:00:03.560 --> 02:00:05.000]   Ice cream sandwich.
[02:00:05.000 --> 02:00:05.320]   J.
[02:00:05.320 --> 02:00:05.320]   Ah.
[02:00:05.320 --> 02:00:07.320]   J.
[02:00:07.320 --> 02:00:07.800]   J.
[02:00:07.800 --> 02:00:08.320]   J.
[02:00:08.320 --> 02:00:08.840]   J.
[02:00:08.840 --> 02:00:09.360]   J.
[02:00:09.360 --> 02:00:09.880]   J.
[02:00:09.880 --> 02:00:10.880]   J.
[02:00:10.880 --> 02:00:12.200]   Did you say a bad word?
[02:00:12.200 --> 02:00:13.720]   [LAUGHTER]
[02:00:13.720 --> 02:00:14.880]   And K is--
[02:00:14.880 --> 02:00:15.360]   KitKat.
[02:00:15.360 --> 02:00:15.880]   KitKat.
[02:00:15.880 --> 02:00:17.640]   And L is lollipop.
[02:00:17.640 --> 02:00:19.200]   And there was Marshall.
[02:00:19.200 --> 02:00:19.720]   Marshall.
[02:00:19.720 --> 02:00:20.200]   Yeah.
[02:00:20.200 --> 02:00:20.200]   Yeah.
[02:00:20.200 --> 02:00:20.880]   There we are.
[02:00:20.880 --> 02:00:24.120]   So what is N going to be Hiroshi Luckheimer's in charge of Android
[02:00:24.120 --> 02:00:25.480]   kind of teased it in his blog post.
[02:00:25.480 --> 02:00:26.680]   Not by the way on Google+.
[02:00:26.680 --> 02:00:28.120]   But this is just the end.
[02:00:28.120 --> 02:00:28.600]   Yeah, it was--
[02:00:28.600 --> 02:00:29.120]   On Medium.
[02:00:29.120 --> 02:00:31.800]   [LAUGHTER]
[02:00:31.800 --> 02:00:33.680]   Take that, Chris Poole at the--
[02:00:33.680 --> 02:00:34.200]   Yeah.
[02:00:34.200 --> 02:00:35.480]   No kidding.
[02:00:35.480 --> 02:00:39.600]   Even Hiroshi's not using Google+, at the end, he says,
[02:00:39.600 --> 02:00:43.080]   "As to what we are going to call Android N,
[02:00:43.080 --> 02:00:44.680]   the burning question on everyone's mind,
[02:00:44.680 --> 02:00:46.280]   what will the end release be named,
[02:00:46.280 --> 02:00:48.920]   we're not telling you, NUT."
[02:00:48.920 --> 02:00:49.440]   NUT.
[02:00:49.440 --> 02:00:50.440]   NUT, NUT, NUT, NUT.
[02:00:50.440 --> 02:00:52.960]   You think NUT, or Nutty Buddy?
[02:00:52.960 --> 02:00:53.440]   NUT, NUT, NUT.
[02:00:53.440 --> 02:00:54.600]   How about Nutty Buddy?
[02:00:54.600 --> 02:00:58.200]   NUT, NUT, NUT.
[02:00:58.200 --> 02:00:59.680]   Yeah, quick, use Google.
[02:00:59.680 --> 02:01:01.800]   See if Google can search it.
[02:01:01.800 --> 02:01:05.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:01:05.400 --> 02:01:06.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:01:06.400 --> 02:01:09.200]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:01:09.200 --> 02:01:11.800]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:01:11.800 --> 02:01:15.800]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:01:15.800 --> 02:01:45.800]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:01:45.800 --> 02:02:15.800]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:02:15.800 --> 02:02:45.800]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:02:45.800 --> 02:03:15.800]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:03:15.800 --> 02:03:27.600]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:03:27.600 --> 02:03:27.600]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, N
[02:03:27.600 --> 02:03:51.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:03:51.400 --> 02:04:03.200]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:04:03.200 --> 02:04:15.200]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:04:15.200 --> 02:04:39.000]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:04:39.000 --> 02:04:50.800]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:04:50.800 --> 02:04:58.800]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:04:58.800 --> 02:05:04.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:05:04.400 --> 02:05:34.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:05:34.400 --> 02:05:41.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:05:41.400 --> 02:05:41.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, N
[02:05:41.400 --> 02:06:11.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:06:11.400 --> 02:06:41.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:06:41.400 --> 02:06:48.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:06:48.400 --> 02:06:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:06:57.400 --> 02:07:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:07:27.400 --> 02:07:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:07:57.400 --> 02:08:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:08:27.400 --> 02:08:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:08:57.400 --> 02:09:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:09:27.400 --> 02:09:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:09:57.400 --> 02:10:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:10:27.400 --> 02:10:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:10:57.400 --> 02:11:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:11:27.400 --> 02:11:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:11:57.400 --> 02:12:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:12:27.400 --> 02:12:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:12:57.400 --> 02:13:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:13:27.400 --> 02:13:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:13:57.400 --> 02:14:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:14:27.400 --> 02:14:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:14:57.400 --> 02:15:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:15:27.400 --> 02:15:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:15:57.400 --> 02:16:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:16:27.400 --> 02:16:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:16:57.400 --> 02:17:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:17:27.400 --> 02:17:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:17:57.400 --> 02:18:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:18:27.400 --> 02:18:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:18:57.400 --> 02:19:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:19:27.400 --> 02:19:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:19:57.400 --> 02:20:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:20:27.400 --> 02:20:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:20:57.400 --> 02:21:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:21:27.400 --> 02:21:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:21:57.400 --> 02:22:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:22:27.400 --> 02:22:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:22:57.400 --> 02:23:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:23:27.400 --> 02:23:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:23:57.400 --> 02:24:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:24:27.400 --> 02:24:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:24:57.400 --> 02:25:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:25:27.400 --> 02:25:57.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,
[02:25:57.400 --> 02:26:27.400]   NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT, NUT,

