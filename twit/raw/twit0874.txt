;FFMETADATA1
title=Malicious Compliance
artist=Leo Laporte, Brianna Wu, Alex Kantrowitz
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2022-05-09
track=874
language=English
genre=Podcast
comment=Tech stocks are crumbling, NFTs losing steam, SafeGraph, Google IO preview
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:03.940]   It's time for Treadt this week at Tech. We've got a great show for you.
[00:00:03.940 --> 00:00:07.800]   Brianna Wu is here from the big technology podcast and newsletter.
[00:00:07.800 --> 00:00:12.200]   Alex Kantruitz, we will talk a little bit about Elon and Twitter, but there's a lot more to
[00:00:12.200 --> 00:00:16.260]   talk about, including why tech stocks are crashing and burning.
[00:00:16.260 --> 00:00:23.400]   By Bitcoin and NFTs are losing steam. How 10 years of American life has been uniquely
[00:00:23.400 --> 00:00:27.600]   stupid. We'll talk about protecting your privacy online.
[00:00:27.600 --> 00:00:34.920]   Yeah, and which browser does it best. Plus, some big finds for some big companies are new.
[00:00:34.920 --> 00:00:41.320]   This is fine segment. It's all coming up next on Twitter.
[00:00:41.320 --> 00:00:46.320]   Podcasts you love from people you trust.
[00:00:46.320 --> 00:00:55.680]   This is Twitter.
[00:00:55.680 --> 00:01:04.480]   This is Twitter. This week at Tech. Episode 874 recorded May 8, 2022.
[00:01:04.480 --> 00:01:07.120]   Malicious compliance.
[00:01:07.120 --> 00:01:11.200]   This episode of This Week at Tech is brought to you by UserWay.org.
[00:01:11.200 --> 00:01:17.040]   UserWay is the world's number one accessibility solution, and it's committed to enabling the
[00:01:17.040 --> 00:01:21.560]   fundamental human right of digital accessibility for everyone.
[00:01:21.560 --> 00:01:25.720]   When you're ready to make your site compliant, deciding which solution to use is an easy
[00:01:25.720 --> 00:01:33.200]   choice to make, go to UserWay.org/twit for 30% off UserWay's AI-powered accessibility
[00:01:33.200 --> 00:01:34.920]   solution.
[00:01:34.920 --> 00:01:42.080]   And by World Wide Technology and Cisco. With an innovative culture, thousands of IT engineers,
[00:01:42.080 --> 00:01:47.160]   application developers, unmatched labs, and integration centers for testing and deploying
[00:01:47.160 --> 00:01:54.520]   technology at scale, WWT helps customers bridge the gap between strategy and execution.
[00:01:54.520 --> 00:02:00.680]   To learn more about WWT, visit www.wt.com/twit.
[00:02:00.680 --> 00:02:07.560]   And by Mint Mobile, those big wireless providers forget that families come in all shapes and
[00:02:07.560 --> 00:02:08.560]   sizes.
[00:02:08.560 --> 00:02:12.260]   That's why Mint Mobile decided to shake up the wireless industry with their brand new
[00:02:12.260 --> 00:02:17.660]   Modern Family Plan. To get your new wireless plan for just 15 bucks a month, including
[00:02:17.660 --> 00:02:23.300]   the Modern Family Plan, go to mintmobile.com/twit.
[00:02:23.300 --> 00:02:29.700]   And by Policy Genius. If someone relies on your financial support, whether it's a child,
[00:02:29.700 --> 00:02:37.060]   aging parent, or even a business partner, you need life insurance. Head to policygenius.com/twit
[00:02:37.060 --> 00:02:46.660]   to get your free life insurance quotes and see how much you could save.
[00:02:46.660 --> 00:02:52.900]   It's time for Twits. This week in tech, the show we cover the latest tech news. We had
[00:02:52.900 --> 00:02:56.060]   too many people in the show last week, so this week we're going to have too few. No,
[00:02:56.060 --> 00:03:01.380]   I think this is going to be just right. Brandon Ooo is here. Hello, Brandon Ooo from the Rebellion
[00:03:01.380 --> 00:03:07.300]   Pack gaming designer, woman about town, former-
[00:03:07.300 --> 00:03:12.740]   Marathon or Porsche collector? Wait a minute, Marathon. Is that new? Long Marathon? Sure.
[00:03:12.740 --> 00:03:17.980]   Oh, no, I have a like, you know, actually, we all hope this isn't too personal to share,
[00:03:17.980 --> 00:03:23.500]   but I was looking at the calendar this week and I've spent 20 years sober. And a big reason
[00:03:23.500 --> 00:03:26.940]   of how I got sober was learning to run every single day.
[00:03:26.940 --> 00:03:30.340]   Nice. You're running away from your demons.
[00:03:30.340 --> 00:03:35.780]   That's the end. It keeps you healthy. It just keeps me on balance. Hey, that's great.
[00:03:35.780 --> 00:03:40.500]   Yep. I've been doing that for a long time. Congratulations on that. Thank you. On the 20-year chip.
[00:03:40.500 --> 00:03:49.460]   Also with this, Alex Cantor with Mr. Big Tech. He's the newsletter's Big Technology.substack.com.
[00:03:49.460 --> 00:03:53.540]   He does the Big Technology podcast. Always great to see you, Alex. Thank you for being here.
[00:03:53.540 --> 00:03:57.060]   It's really great to be here. It's awesome to be here. Thank you for having me. Look about Amazon
[00:03:57.060 --> 00:04:01.380]   always day one on finer newsstands everywhere.
[00:04:01.380 --> 00:04:06.020]   Yeah, we got all the tech giants in there, but mostly Amazon.
[00:04:06.020 --> 00:04:09.460]   Well, yeah, if you're a Microsoft person, then pick it up anyway.
[00:04:09.460 --> 00:04:13.060]   Yeah, that's right. It all counts. It all matters.
[00:04:13.060 --> 00:04:16.820]   They've gone from day two to day one. So credit to them.
[00:04:16.820 --> 00:04:20.500]   I know I can feel it that there are people in the audience going, "Please don't let them talk
[00:04:20.500 --> 00:04:24.740]   about Elon. Please don't let him talk about Elon." This has been for the last three weeks.
[00:04:24.740 --> 00:04:28.500]   That's all. And we're all sick of it. I completely understand.
[00:04:28.500 --> 00:04:38.260]   The only news here is that Elon is going around trying to raise his stake in buying Twitter of
[00:04:38.260 --> 00:04:44.020]   the $44 billion is $21 billion, which even though he's... And this is an important lesson
[00:04:44.020 --> 00:04:49.780]   for all you youngsters. Even though he's the richest man in the world with an estimated net worth of
[00:04:49.780 --> 00:04:57.620]   $270 billion, he doesn't have two nickels to rub together. So he is going to bankers.
[00:04:57.620 --> 00:05:04.660]   I think he's got like $7 billion, just a few billion. So he's going to bankers to get the rest of it.
[00:05:04.660 --> 00:05:11.140]   And so he's got a deck, a PowerPoint, although with Elon, I doubt it's a PowerPoint. He's probably
[00:05:11.140 --> 00:05:15.060]   using something spacey like Prezi. But he's got something that he's going around saying,
[00:05:15.060 --> 00:05:19.460]   "Let me explain to you why I would be... You should give me money for Twitter."
[00:05:19.460 --> 00:05:25.220]   Have you seen these slides yet, Leo? Because they are crazy. There was one that came out today
[00:05:25.220 --> 00:05:32.260]   showing Elon's forecasts for Twitter. Insane! Like crazy pads. There is no way he's going to
[00:05:32.260 --> 00:05:38.100]   quadruple the number of people on Twitter. And I know venture capitalists are used to seeing
[00:05:38.100 --> 00:05:43.300]   optimistic projections, but this is not like someone working on their college dorm. This is
[00:05:43.300 --> 00:05:57.620]   Elon Musk. So, uh, paragon of strict financial accuracy. Perhaps you wrote a great piece, Alex.
[00:05:57.620 --> 00:06:05.700]   Based on Alex Reder, who once ran Twitter engineering on evaluating Elon's plans
[00:06:05.700 --> 00:06:12.260]   to fix Twitter, it's probably good to ask somebody who's actually at Twitter what they think.
[00:06:12.260 --> 00:06:18.260]   And what did that Alex think? It was interesting. So we did it as a podcast on big technology
[00:06:18.260 --> 00:06:22.740]   podcast. And I wrote up in the newsletter. My voice was totally shot. I had probably COVID
[00:06:22.740 --> 00:06:26.340]   lighter, whatever it was. But anyway, it was really interesting to speak to someone who had run
[00:06:26.340 --> 00:06:30.020]   engineering at Twitter and then asked them what their perspective is on all these ideas that
[00:06:30.020 --> 00:06:35.060]   Elon's been bringing up. There are some good ones in there. I think the idea to authenticate
[00:06:35.060 --> 00:06:40.820]   every human is really interesting. Twitter hasn't done that previously because it's a public
[00:06:40.820 --> 00:06:44.420]   company and it has to show user growth. And if they were going to say, if you want to be on
[00:06:44.420 --> 00:06:49.540]   Twitter, you got to use a phone number or an email address to be here, they would lose lots of people.
[00:06:49.540 --> 00:06:54.020]   So they just never did it. And so having a private, you know, having private ownership
[00:06:54.020 --> 00:06:58.340]   actually gives them the ability to do this without the scrutiny and the disaster to the stock
[00:06:58.340 --> 00:07:04.900]   that Wall Street would bring. So, so EFS has said very clearly that anonymity, which is often offered
[00:07:04.900 --> 00:07:13.780]   as a panacea for social networks to eliminate anonymity, has a never succeeded and B poses
[00:07:13.780 --> 00:07:19.060]   all sorts of issues for people who have good reason to want to communicate without giving away their
[00:07:19.060 --> 00:07:26.100]   true identity. So I think on the surface, authentication sounds reasonable. Brianna,
[00:07:26.100 --> 00:07:32.260]   do you have an opinion on that? I would imagine you do. I have an opinion on everything in your
[00:07:32.260 --> 00:07:37.860]   piece, Alex. And a lot of this is actually informed from my own experience working with Twitter.
[00:07:37.860 --> 00:07:43.940]   You know, when this was announced, I did interviews with New York Times, you know,
[00:07:43.940 --> 00:07:45.540]   for people who don't know,
[00:07:45.540 --> 00:07:50.180]   NBC Nightly knows everybody knows. Wait a minute, every scene Nightly knows I have
[00:07:50.180 --> 00:07:53.780]   missed that one. I missed that one. I want to have to watch that one.
[00:07:53.780 --> 00:07:58.260]   Last night I've had about four hours. Okay, no, no, it's good. I like the Nightly knows.
[00:07:58.260 --> 00:08:03.300]   And I'd like to watch it. No, but you have been the target of horrific trolling on Twitter.
[00:08:03.300 --> 00:08:08.420]   Sure. I've forced to move out of your house during gamergate. So people should know that
[00:08:08.420 --> 00:08:14.340]   you know a little bit about how bad it could be. So more specifically, though, Leo, something I
[00:08:14.340 --> 00:08:19.940]   did was I developed a, I finally disclosed this about three weeks ago. I've actually worked very
[00:08:19.940 --> 00:08:26.100]   closely with Twitter, so I trust in safety team over most of the things in your article, Alex.
[00:08:26.100 --> 00:08:32.420]   So, you know, when Elon is saying, I want to fix this, you know, the reality is there's actually a
[00:08:32.420 --> 00:08:38.180]   huge long history of Twitter working to fix this from behind the scenes. So kind of starting at
[00:08:38.180 --> 00:08:43.460]   the top of this, like making sure people are real. This is something Twitter actually spent
[00:08:43.460 --> 00:08:51.460]   quite a bit of time working on from 2014 to about 2018, because the problem was someone would do
[00:08:51.460 --> 00:08:57.780]   a death threat account, it would get suspended. And then all these 4chan, 8chan sock puppets,
[00:08:57.780 --> 00:09:04.020]   which is zerg the site over and over again, creating new accounts. So Twitter actually did
[00:09:04.020 --> 00:09:10.180]   a ton of work locking down IP addresses and actually requiring you after a certain point to
[00:09:10.180 --> 00:09:15.780]   start giving a phone number, if the same IP address was trying to register another Twitter account.
[00:09:15.780 --> 00:09:23.460]   I want to note that those restrictions have been largely lifted at Twitter in the last three years.
[00:09:23.460 --> 00:09:32.100]   So, I agree with this, but I think Elon doing that would be reinstating a policy that, frankly,
[00:09:32.100 --> 00:09:36.420]   the board took down, I assume, because it impeded growth at the company.
[00:09:36.420 --> 00:09:40.420]   Yeah, right. And that's the advantage, right? Because that he doesn't have to show growth.
[00:09:40.420 --> 00:09:45.140]   The board has accountable to shareholders. Elon will be the number one person making decision.
[00:09:45.140 --> 00:09:48.580]   Of course, he'll have investors and he wants to take it public again.
[00:09:48.580 --> 00:09:54.100]   But I think there are some things. He's going to make it public again. That's, I honestly think
[00:09:54.100 --> 00:09:57.700]   that's part of the deck, just because he's not, nobody's going to lend him money. If there's
[00:09:57.700 --> 00:10:02.180]   if there's not a clear path to profitability, Twitter has been 15 years trying to make money
[00:10:02.180 --> 00:10:08.180]   and failed, failed, failed in every respect. So I understand why I put that in. It's kind of like
[00:10:08.180 --> 00:10:13.700]   Michael Dell. He took Dell private. We talked about this last week and then a few years later
[00:10:13.700 --> 00:10:17.540]   went public and it's worth a hell of a lot more now. So that's a reasonable thing.
[00:10:17.540 --> 00:10:21.460]   Yeah. And the whole appeal of investing with Elon as he turns your stock into a meme stock,
[00:10:21.460 --> 00:10:26.740]   because there are online hordes of people that want to invest with. And actually, I was surprised.
[00:10:26.740 --> 00:10:31.380]   Would you put money if Elon came to you and let's say you had 100 million lying around,
[00:10:31.380 --> 00:10:35.860]   would you give him 100 million and say, yeah, you can double my money.
[00:10:35.860 --> 00:10:40.340]   On Twitter? No. Sure. Not on Twitter.
[00:10:40.900 --> 00:10:45.540]   That's the therein lies the problem. Twitter is tough. Twitter says super hard, but
[00:10:45.540 --> 00:10:51.380]   I mean, the guy just said, I just said, I don't care about the economics of this business.
[00:10:51.380 --> 00:10:54.980]   But that's what's interesting to ask me for 100 million. No way.
[00:10:54.980 --> 00:10:58.740]   But that's what's interesting because I wanted to get money on something that he cares about the
[00:10:58.740 --> 00:11:03.460]   economics of. Well, now all of a sudden he kind of cares about the economics because
[00:11:03.460 --> 00:11:08.420]   this deck he's going around showing is showing how the road to profitability because no one's going
[00:11:08.420 --> 00:11:12.580]   to lend him money. So suddenly he does care because he has to raise this money.
[00:11:12.580 --> 00:11:19.060]   So that's what part of the problem with Elon is. It's impossible to know what he's actually
[00:11:19.060 --> 00:11:23.140]   but the thing. Of course, he has the deck because he wants the money, but I tend to listen to the
[00:11:23.140 --> 00:11:28.740]   guy in his own words. He said it in multiple times. This is not about a business. Not on Twitter,
[00:11:28.740 --> 00:11:35.380]   on SpaceX and Tesla, absolutely. But not on Twitter. I would sooner lend Elon money to dig tunnels in
[00:11:35.380 --> 00:11:38.980]   LA than I would to have him run Twitter. Not to say he's going to do a bad job.
[00:11:38.980 --> 00:11:41.780]   I just think that this is a business perspective is wrong.
[00:11:41.780 --> 00:11:43.780]   And it certainly is not as a bad investment.
[00:11:43.780 --> 00:11:48.580]   It's Twitter's right to enforce authentication and it would certainly make it a better place.
[00:11:48.580 --> 00:11:53.220]   And there are other places people who need anonymity can go. So yeah, I mean,
[00:11:53.220 --> 00:11:56.420]   if you don't care about making money, if you don't care about losing people,
[00:11:56.420 --> 00:12:01.220]   he says free speech, free speech, free speech. But spam is not
[00:12:03.460 --> 00:12:06.340]   is a free speech. I mean, spam is protected speech.
[00:12:06.340 --> 00:12:09.540]   And this is one of the things that I spoke with Alex Ritter about.
[00:12:09.540 --> 00:12:14.420]   And what he said, you can what one. Okay, so if you're one of the ones number one things he
[00:12:14.420 --> 00:12:20.100]   wants to do is build a is to get rid of the spam box. To do that, you build a classifier that says,
[00:12:20.100 --> 00:12:25.380]   okay, there are spam here. There's no spam there. So let's do what we can to wipe out the spam on
[00:12:25.380 --> 00:12:30.500]   the site. Right. The thing is that like you turn a dial so you can make it like a weak classifier,
[00:12:30.500 --> 00:12:35.860]   and basically say, or the classifier, you could turn it weak and say, you know, we'll allow for
[00:12:35.860 --> 00:12:40.420]   complete spurs as close to free speech as we can. And we're going to get a couple of bots,
[00:12:40.420 --> 00:12:43.540]   or you can say, we want to nuke the bots, but then you're going to get humans when you're
[00:12:43.540 --> 00:12:47.540]   trying to get the class for us and be like, that looks kind of bad. Like spam email, right?
[00:12:47.540 --> 00:12:53.620]   We which we have not yet. For sure. Yeah. So if I could just say something with mine, spam email,
[00:12:53.620 --> 00:12:59.220]   with a newsletter, man, it's tough. Yeah. Go ahead. If I could just add something here,
[00:12:59.700 --> 00:13:04.820]   first of all, I just want to pause and say, I think we're falling in like agreeing the Elon
[00:13:04.820 --> 00:13:12.180]   wants free speech here. I don't agree with that assessment here. He wants to roll back anti-harassment
[00:13:12.180 --> 00:13:18.180]   policies, and that I think curtales speech for a lot of people. So I just want to say I don't
[00:13:18.180 --> 00:13:23.620]   agree with that framing coming back to the bot issue. Again, this is something I've very specifically
[00:13:23.620 --> 00:13:31.940]   worked with Twitter on for years. I would say throughout 2016 to 2017, I probably did between
[00:13:31.940 --> 00:13:38.580]   50 and 100 hours of work compiling bots that were actually dedicated for harassment of various
[00:13:38.580 --> 00:13:45.060]   people online and collating this information, sending out for Twitter to try get their engineers to
[00:13:45.060 --> 00:13:49.860]   cut down on this harassment. But I know that Twitter as an organization has dealt with a lot
[00:13:49.860 --> 00:13:57.060]   of these harassment bots. It did get better for a while. But again, the money men stuck
[00:13:57.060 --> 00:14:03.540]   stepped in and kind of twisted those dials in a way because they wanted more engagement.
[00:14:03.540 --> 00:14:10.500]   Something I noted in a lot of the interviews I did over the last few weeks was what happened is
[00:14:10.500 --> 00:14:18.260]   from 2014 to about 2017, these policies had a lot of support from Jack and Twitter as a whole.
[00:14:18.820 --> 00:14:25.060]   But then once Trump was elected, many of these policies became another stupid right versus left
[00:14:25.060 --> 00:14:31.060]   screaming match. So it wasn't normal professionals versus the trolls. It was the right versus left.
[00:14:31.060 --> 00:14:35.860]   And from my experience, I saw a lot of the will to really address these things at Twitter
[00:14:35.860 --> 00:14:42.180]   start to go away. And I personally seen a lot of those safeguards against bots really get rolled
[00:14:42.180 --> 00:14:48.420]   backwards. Coming back to one additional point, you're talking about making Twitter private and
[00:14:48.420 --> 00:14:54.260]   how that can have good things. Something I think is really under discussed is no one goes to work
[00:14:54.260 --> 00:15:01.220]   at a major tech company without stock options. My own husband is in biotech. Stock options are
[00:15:01.220 --> 00:15:08.180]   a non-trivial part of how people in the industry are paid or Microsoft or Google or Apple. And if
[00:15:08.180 --> 00:15:12.900]   this is a private company, I think it's a real open question how you're going to continue to
[00:15:12.900 --> 00:15:16.100]   attract talent. If that is not a steady part of your compensation.
[00:15:16.100 --> 00:15:21.060]   That's another confusing thing that Elon's done, which is said, I'm going to fire a bunch of people
[00:15:21.060 --> 00:15:25.780]   so that we can improve expenses. And then I'm going to hire a bunch more people.
[00:15:25.780 --> 00:15:33.060]   He's planning to really expand the number of employees at Twitter. And that's going to be hard
[00:15:33.060 --> 00:15:36.900]   to do without stock options, without compensation.
[00:15:36.900 --> 00:15:40.660]   Is it going to be interesting when Elon gets in there and he's faced with some of these
[00:15:40.660 --> 00:15:45.060]   contradictions? Like he's going to be the one that's faced with. Do you take the spam bots down or do
[00:15:45.060 --> 00:15:48.340]   you allow for basically people to say whatever they want on the platform?
[00:15:48.340 --> 00:15:52.100]   I do think in terms of stock, I don't think Elon's going to have any issue getting people to work
[00:15:52.100 --> 00:15:57.540]   for him. Either it's just that Elon halo that a lot of people working in tech would like to be
[00:15:57.540 --> 00:16:02.340]   around and be. He's basically going to make it into if he's planning to go, it's true. It's true.
[00:16:02.340 --> 00:16:05.620]   Whether I'm fan of your not. He's such a polarizing figure. It's so interesting.
[00:16:05.620 --> 00:16:09.940]   You love him or you hate him. I love him. There's a ball. There's a bunch of people that love him
[00:16:09.940 --> 00:16:15.780]   that will do it. And then he's essentially going to turn Twitter. We'll see what he can do with
[00:16:15.780 --> 00:16:20.180]   options and stuff like that. But he's essentially going to turn Twitter into one of the most high
[00:16:20.180 --> 00:16:25.380]   profile startups that we have in the tech world where it's going to be at three, four years,
[00:16:25.380 --> 00:16:29.780]   bring it public again. Maybe people working on the private version of Twitter then have an option
[00:16:29.780 --> 00:16:35.460]   out and buy in for the second IPO. I have to give him a quintuple revenue.
[00:16:36.660 --> 00:16:41.460]   500% going to happen. I mean, I have to disagree with that though. What makes Twitter,
[00:16:41.460 --> 00:16:46.020]   what makes this is why I don't agree with you. I think that's right. If you want to attract
[00:16:46.020 --> 00:16:51.780]   white male engineers in the field, I 100% agree with you. There are a ton of Elon Musk cultists out
[00:16:51.780 --> 00:16:56.660]   there that hang on his every word and would love to go work for him. What I am personally
[00:16:56.660 --> 00:17:02.340]   saying with women and people of color and LGBT people that I know that work in Silicon Valley
[00:17:02.900 --> 00:17:10.100]   is there's more of a stigma to working with him than Zuckerberg. And that's a non-trivial bar.
[00:17:10.100 --> 00:17:14.740]   And I think this affects the end product in a lot of ways. If you're talking about something
[00:17:14.740 --> 00:17:20.580]   like Coinbase and attracting a very certain kind of person there, ultimately it's more of a
[00:17:20.580 --> 00:17:27.460]   financial product. I believe Twitter will live or die based on the harassment policies. There are
[00:17:27.460 --> 00:17:32.260]   a lot of people that leave Twitter because they just throw out their hands and say, I can't deal
[00:17:32.260 --> 00:17:38.420]   with the death threats, the rape threats, the harassment, the doxing, the armies of sock puppets
[00:17:38.420 --> 00:17:46.020]   calling me names anymore. And it's not the Musk cultists that are going to be able to address that.
[00:17:46.020 --> 00:17:52.100]   It is women, it is people of color, it is LGBT people that care about these issues. So if you're
[00:17:52.100 --> 00:17:57.220]   subtly showing them the door, I just don't agree with you that Twitter is going to be able to find
[00:17:57.220 --> 00:18:02.180]   the people that need to solve those problems. Yeah. Well, I didn't mean look, I don't think that
[00:18:02.180 --> 00:18:06.420]   that you're going to find disagreement with me on that one. I do think that there's a good
[00:18:06.420 --> 00:18:11.060]   chance that Twitter ends up becoming worse because of this. However, he is going to be able to find
[00:18:11.060 --> 00:18:15.460]   people to work. Twitter is going in a different direction right now. And I definitely don't think
[00:18:15.460 --> 00:18:18.180]   that there's going to be a lot of Democrats or liberals that are going to want to work with
[00:18:18.180 --> 00:18:23.700]   Elon, especially if you look at what he's tweeting. And the question is, can he, it's a big financial
[00:18:23.700 --> 00:18:28.580]   investment for him? Can he get his money out, you know, without wrecking the company,
[00:18:28.580 --> 00:18:32.260]   without wrecking society? And that's sort of the experiment we're going to see with Elon over the
[00:18:32.260 --> 00:18:36.980]   next couple of years. So if Twitter, assuming the deal goes through, if Twitter, yeah, that's right,
[00:18:36.980 --> 00:18:43.380]   it may not, we still don't know. Let's say we need something beside, do we,
[00:18:43.380 --> 00:18:47.860]   hey, do we need something like Twitter? Do we need Twitter? And is there an alternative
[00:18:47.860 --> 00:18:52.900]   that people could would, could or would flock to if they didn't want to be on Twitter?
[00:18:53.780 --> 00:18:58.580]   Do let's start with the first one. Do we need something like Twitter? How important is it?
[00:18:58.580 --> 00:19:03.460]   We don't need it, but it is just part of the internet experience. I mean, it is in many
[00:19:03.460 --> 00:19:07.300]   ways the beating heart of the internet. I think that would Jack Dorsey called it the
[00:19:07.300 --> 00:19:11.860]   collective consciousness or the closest thing we have the two collections square. Yeah.
[00:19:11.860 --> 00:19:16.980]   You know, I think that it's the closest, it's the closest thing we have is Twitter real life,
[00:19:16.980 --> 00:19:22.100]   definitely not, you know, we should all remember that's been on the has 217 million monthly active
[00:19:22.100 --> 00:19:26.580]   users. It's a tiny portion of the population. I personally like the product is it going to be a
[00:19:26.580 --> 00:19:31.300]   loss and we'll survive. There's no Twitter. It's not like it's oxygen for us. But it,
[00:19:31.300 --> 00:19:36.980]   there will always be something real time live focused on news on the internet. It's just a
[00:19:36.980 --> 00:19:40.420]   fact to be internet. And right now the Twitter serves that role.
[00:19:40.420 --> 00:19:42.980]   Brianna, which, which would you give up Facebook or Twitter?
[00:19:42.980 --> 00:19:50.500]   Well, I think Facebook, I think Facebook, like if you look at the grand scheme of harm to the world,
[00:19:50.500 --> 00:19:56.740]   I think Facebook is worse, right? Like Twitter is not responsible for, you know, say a genocide,
[00:19:56.740 --> 00:20:03.940]   which Facebook has been so, you know, for me, I, this is a perspective I would ask you guys to
[00:20:03.940 --> 00:20:10.660]   consider. So take the game industry, which I used to work in. In the game industry, a lot of men
[00:20:10.660 --> 00:20:15.860]   just naturally network with each other, right? So when I was first getting started in games,
[00:20:15.860 --> 00:20:20.900]   I would go to bars after work and try to meet important people in that field to form the
[00:20:20.900 --> 00:20:26.340]   connections my game studio would need, right? So a bunch of dudes drinking at a bar and they
[00:20:26.340 --> 00:20:29.780]   would ask my husband if he's the engineer, right? My husband can't.
[00:20:29.780 --> 00:20:31.940]   You couldn't possibly be. Yeah. Yeah.
[00:20:31.940 --> 00:20:39.620]   So my message to you is Twitter from my experience has been a vital networking tool.
[00:20:40.980 --> 00:20:46.500]   As far as like my current boss, I met my boss because he was getting chased by Twitter mom
[00:20:46.500 --> 00:20:54.900]   and I stood up to him for him. And, you know, there are any number of just really close friends
[00:20:54.900 --> 00:20:59.140]   and professional connections I've got there. If you're talking about Twitter going away,
[00:20:59.140 --> 00:21:05.060]   I really do think this is a place for women and people of color to network. And I think that's
[00:21:05.060 --> 00:21:14.500]   really undervalued in the discussion about this. What I think is very interesting is to me,
[00:21:14.500 --> 00:21:20.420]   the key feature of Twitter that it's missing is a really big investment in trust and safety.
[00:21:20.420 --> 00:21:26.900]   And if I were working on that trust and safety team and Elon Musk was taking over,
[00:21:26.900 --> 00:21:30.420]   I personally would go straight down to the venture capitalists and say,
[00:21:30.420 --> 00:21:38.660]   look, give me this is not that complicated a product, right? Give me 200, 300 million dollars.
[00:21:38.660 --> 00:21:43.460]   Let me develop something that truly puts trust and safety first, not to say everyone doesn't
[00:21:43.460 --> 00:21:48.420]   have a voice, but we're going to get rid of the death and rate threats. That's garbage. It doesn't
[00:21:48.420 --> 00:21:54.180]   add anything into the dialogue. And I can really see something like that taking off and really
[00:21:54.180 --> 00:21:58.580]   succeeding. I would move there in a heartbeat and I think a lot of other journalists would too.
[00:21:58.580 --> 00:22:06.020]   You sound convinced that it's possible. I think so. I think App.net failed, but I think Dalton had
[00:22:06.020 --> 00:22:14.740]   just a reminder listeners, App.net was this $50 a month paid Twitter service that was open
[00:22:14.740 --> 00:22:20.420]   sources very similar to what they're doing now. But there was never a push to develop a really
[00:22:20.420 --> 00:22:26.340]   good first tier client for that. I think if you had someone that just won one client,
[00:22:26.340 --> 00:22:32.100]   they weren't trying to develop 50 different Twitter services and just focused on trust and
[00:22:32.100 --> 00:22:34.740]   safety. I think that's a product a lot of people would use.
[00:22:34.740 --> 00:22:42.660]   The I agree with Brianna here. I'll just say quickly that Twitter was founded in March 2006.
[00:22:42.660 --> 00:22:48.420]   So it's been around for 16 years. The human history has far outpaced that amount of time.
[00:22:48.420 --> 00:22:51.300]   And I think we're just at the beginning of the social internet.
[00:22:51.940 --> 00:22:57.860]   And so you look at that and you ask a question, can Twitter be usurped eventually?
[00:22:57.860 --> 00:23:02.100]   Not only do I think it's possible, I think it's likely and the question is what the product is,
[00:23:02.100 --> 00:23:05.860]   it's what we have now. But 100 years down the road, are we going to be all on Twitter yelling
[00:23:05.860 --> 00:23:11.220]   at each other? No. I think that's unlikely. And I think that's the beauty of having a market.
[00:23:11.220 --> 00:23:16.180]   If Elon goes in and breaks Twitter, there becomes an opening to build something different.
[00:23:16.180 --> 00:23:21.220]   Like Brianna's talking about, or maybe there'll be many different takes and let the best system
[00:23:21.220 --> 00:23:25.380]   win. And I think that's cool. Do you think though, it's interesting, you said Brianna,
[00:23:25.380 --> 00:23:32.900]   300 million dollars and I could build a safe place. So something like Mastodon, an open source
[00:23:32.900 --> 00:23:38.740]   federated solution, there's not anywhere near that kind of money to make a safe place.
[00:23:38.740 --> 00:23:42.660]   So you think it's going to take some big commercial entity to do it?
[00:23:42.660 --> 00:23:48.020]   I do. And I want to be really clear here. I'm not talking about a safe space. I'm talking
[00:23:48.020 --> 00:23:53.060]   about a place where anyone can express their opinions without getting death threats,
[00:23:53.060 --> 00:24:00.500]   rape threats, doxing, bots defiling their reputation online. I mean, I'm talking about a place where
[00:24:00.500 --> 00:24:05.540]   everyone can have free speech to be really clear. I think the problem is,
[00:24:05.540 --> 00:24:11.700]   see, either way, I love your, it's important to point out your definition of free speech is
[00:24:11.700 --> 00:24:16.580]   different than e-lons. Elon's is anything goes as long as it's not illegal. But you're saying,
[00:24:16.580 --> 00:24:21.540]   that's not really free because then there are a bunch of people who can't speak freely because
[00:24:21.540 --> 00:24:28.100]   they'll be immediately shouted down. That's exactly right. You know, I think the problem is with a lot
[00:24:28.100 --> 00:24:33.380]   of these products. You know, I'll respect to my engineer friends, sometimes we're a little
[00:24:33.380 --> 00:24:38.740]   idealist about this and you're like, look, you can just go run your own Mastodon instance and do all
[00:24:38.740 --> 00:24:44.420]   this free moderation work and your spare time and get everyone to download a client. It's going to
[00:24:44.420 --> 00:24:50.020]   be great. You have the reality is things like Discord catch on, like a very straightforward,
[00:24:50.020 --> 00:24:56.580]   well-coded solution. So I just think, I don't think it's that complicated Twitter,
[00:24:56.580 --> 00:25:00.100]   but with real money and trust and safety. I think that's what people want.
[00:25:00.100 --> 00:25:08.100]   And we also, maybe trying to buy Twitter should have just spent half that money or
[00:25:08.100 --> 00:25:13.700]   attended that amount of money and built something. But that money can build something if Elon
[00:25:13.700 --> 00:25:19.380]   ruins it. So it's almost like he's opening up. You need people, like this is a content-driven
[00:25:19.380 --> 00:25:23.860]   app and you need people to be able to go. So that's the problem. The network effect.
[00:25:23.860 --> 00:25:28.660]   Somebody to ruin it in order to be able to build a good leader. It's not a very technically complex
[00:25:28.660 --> 00:25:34.020]   product, let's be honest. So to be able to build something else for $1,200, it would be okay. You
[00:25:34.020 --> 00:25:37.620]   build the bones of it, but then you'd hire the trust and safety and say, I could do better, but
[00:25:37.620 --> 00:25:42.020]   you would need someone to ruin Twitter proper in order to do it. Also, I think one last thing
[00:25:42.020 --> 00:25:47.140]   about this, we're talking a lot about free speech. I also think that there's real credibility to
[00:25:47.140 --> 00:25:53.460]   the free speech versus freedom of reach, just distinction. And this is the thing that I'm on
[00:25:53.460 --> 00:25:59.460]   the high horse about, or the hill that I'll die on, for the remainder of the social media discussion
[00:25:59.460 --> 00:26:05.620]   is that you can allow people to say whatever you want, whatever they want. You don't need to allow
[00:26:05.620 --> 00:26:11.300]   them to be able to get amplified by the algorithms, show up in people's mentions.
[00:26:11.300 --> 00:26:15.380]   And so it's very possible to create a Twitter that there is, quote unquote, free speech.
[00:26:15.380 --> 00:26:21.220]   But one that doesn't necessarily, Twitter is the algorithm as an editor. So the editor doesn't
[00:26:21.220 --> 00:26:26.740]   need to give promotion to the horrible things that people say. It's making decisions every day.
[00:26:26.740 --> 00:26:29.860]   So the free speech is such a limited window to look at it.
[00:26:29.860 --> 00:26:38.420]   So Elon has raised about $5.2 billion toward his goal so far. 18 investors,
[00:26:38.420 --> 00:26:45.780]   35 million shares rolled over from Saudi Prince Awali bin Talal, which always makes me nervous
[00:26:45.780 --> 00:26:51.220]   when I see investments from Saudi. But unfortunately, that's kind of the way it is in Silicon Valley.
[00:26:51.220 --> 00:26:59.620]   A billion dollars from Larry Ellison, 800 million from Sequoia capital, 700 million from Vite capital,
[00:26:59.620 --> 00:27:05.460]   500 million from Binance, 400 million from Andreece and Horowitz. So that 100 million I was asking
[00:27:05.460 --> 00:27:10.740]   you for Alex, he's found a few people to hand over even more.
[00:27:10.740 --> 00:27:18.500]   If you then was really smart, he would put his 42 billion into Twitter and then give Breanna
[00:27:18.500 --> 00:27:24.180]   like maybe 300 million to build the alternate kind of hedge there and be like, listen, if I ruin this,
[00:27:24.180 --> 00:27:28.580]   and now I own half of this plot. Well, there is, in a way, there is something going on like that,
[00:27:28.580 --> 00:27:35.300]   because before Jack Dorsey left Twitter, he funded I think 54 million funded blue
[00:27:35.300 --> 00:27:43.220]   blue sky, which is an R&D project to create a federated open source Twitter. That funding has
[00:27:43.220 --> 00:27:47.700]   already been awarded to blue sky. It can't be taken away by anybody, including Elon.
[00:27:47.700 --> 00:27:54.900]   So there is a group going forward with something that was considered by the former Twitter CEO and
[00:27:54.900 --> 00:28:00.340]   one of its founders to be the future of Twitter blue sky. So maybe there is an alternative in the
[00:28:00.340 --> 00:28:06.260]   works. I don't worry that's going to get so caught up with this web three stuff. I really am. I think
[00:28:06.260 --> 00:28:11.380]   that's been Jack's focus recently. I do want to come back to something we were talking about,
[00:28:11.380 --> 00:28:17.780]   which was the investment here in how Elon is going to pay for it, because I think this is really a
[00:28:17.780 --> 00:28:25.300]   bigger discussion here. If you look at Elon's, if you look at say Tesla stock, before I say this,
[00:28:25.300 --> 00:28:32.500]   I want to stress I want EVs to win. The day Porsche puts out an electric boxer will be the day I buy
[00:28:32.500 --> 00:28:37.700]   it. I've already talked to my dude. He will have me first in line for it. I want EVs to win. But I
[00:28:37.700 --> 00:28:44.340]   would urge anyone to go out and look at the price to earnings ratio of Tesla and the amount of money
[00:28:44.340 --> 00:28:51.140]   they actually make versus what their stock price is, which is it's so many more times the rest of
[00:28:51.140 --> 00:28:58.660]   the industry. It is ludicrous. It just makes no sense from an objective stock market perspective.
[00:28:58.660 --> 00:29:03.460]   Like what can you make? It really is a meme stock, isn't it? Yeah, it's crazy.
[00:29:03.460 --> 00:29:10.900]   So I filed my for a while. I did the thing on Robin Hood, where I was just waiting for Elon to
[00:29:10.900 --> 00:29:18.100]   tweet about some meme stock and a meme Bitcoin or whatever. I would buy a bunch of it.
[00:29:18.100 --> 00:29:22.020]   And I was looking at it. I made a fair amount of money last year just doing that.
[00:29:22.020 --> 00:29:28.420]   At the same time, I think if you're looking at Tesla and how he's actually going to buy Tesla,
[00:29:28.420 --> 00:29:34.420]   because the tech stock market has taken such a beating, I think that's the real reason he's
[00:29:34.420 --> 00:29:39.780]   taking on all the rest of these private investors who are going to want to be paid back.
[00:29:39.780 --> 00:29:45.060]   Some of these people that he's working with on this don't have a great track record when it
[00:29:45.060 --> 00:29:51.220]   comes to social media. @netavari mentioned, once the last time you heard about clubhouse or
[00:29:51.220 --> 00:29:58.660]   went on there, there are real concerns here about how he's going to pay for it and what the long-term
[00:29:58.660 --> 00:30:05.140]   viability of this is going to be. So just consider me extremely skeptical about every bit of this
[00:30:05.140 --> 00:30:12.180]   endeavor, especially financially. It's really fascinating to watch. We live in a kind of a different kind
[00:30:12.180 --> 00:30:18.420]   of gilded age where we have these very, very wealthy people and they're able to do things,
[00:30:18.420 --> 00:30:25.540]   some of them like SpaceX and Tesla maybe, really are benefiting the world, some of them not.
[00:30:25.540 --> 00:30:32.020]   But it's really, it's not in the hands of the people where this money goes. It's in the hands of
[00:30:32.740 --> 00:30:39.140]   whatever these guys decide is important. And I'm not sure I fully trust these oligarchs to make
[00:30:39.140 --> 00:30:43.700]   those decisions, to be honest with you. I don't know if they're the best people to be doing that.
[00:30:43.700 --> 00:30:47.460]   But it's also the benefit of being in a capitalist system. Like if they mess it up,
[00:30:47.460 --> 00:30:50.340]   someone else can come in and build something better. True. Go to it. True.
[00:30:50.340 --> 00:30:57.540]   It'll be interesting to watch. All right. I said we were going to do any Elon, but I'd have to
[00:30:57.540 --> 00:31:02.740]   tell you the next couple of years, there's going to be a lot of Elon in the tech news.
[00:31:02.740 --> 00:31:07.940]   Rightly so. It's fascinating. And of course, there's always been an outside,
[00:31:07.940 --> 00:31:12.980]   Twitter has always had kind of an outsized interest for those of us in the tech media. I mean,
[00:31:12.980 --> 00:31:20.100]   as a lot of influence, we pay a lot of attention to it, even though the rest of the world may not.
[00:31:20.100 --> 00:31:25.780]   And I guess that's why we care a lot about what happens to Twitter. We live in interesting times.
[00:31:25.780 --> 00:31:37.300]   Our show today brought to you by userway.org. Watch userway.org. I'm talking about making your
[00:31:37.300 --> 00:31:43.860]   website ADA compliant accessible. Not only is it the right thing to do, because you're opening up
[00:31:43.860 --> 00:31:49.860]   your website to a much larger group, 60 million plus people, you have a responsibility to make
[00:31:49.860 --> 00:31:54.580]   your site accessible. It's a public entity. So you got to make it accessible. And with userway,
[00:31:54.580 --> 00:31:59.700]   it's easy. That was my biggest concern was, oh, I can't afford it or it's going to be too hard.
[00:31:59.700 --> 00:32:05.060]   No, userway is really affordable. And it's really easy and incredible. It's AI powered,
[00:32:05.060 --> 00:32:12.500]   tirelessly enforces all the accessibility guidelines, the WCAG WCAG guidelines. And I love this. So
[00:32:12.500 --> 00:32:17.460]   to our engineers, it's one line of JavaScript. That's it. Because userway is so good, it's used
[00:32:17.460 --> 00:32:23.220]   by more than a million websites, including the big guys, Coca-Cola, Disney, eBay. These are
[00:32:23.220 --> 00:32:28.580]   companies that really have to be accessible. And userway can do that. As you get bigger,
[00:32:28.580 --> 00:32:34.740]   they scale with you. If they can handle Disney, absolutely they can handle you. They make best-in-class
[00:32:34.740 --> 00:32:40.260]   enterprise level accessibility tools available to you, your small or medium-sized business. And
[00:32:40.260 --> 00:32:45.140]   then as you scale, you need userway and you're ready. It just makes business sense. Some of the
[00:32:45.140 --> 00:32:50.260]   biggest problems, nav menus, very difficult. So the way this works, if you're blind or you're
[00:32:50.260 --> 00:32:56.260]   using accessibility tools, there is what they call an accessibility layer. That's what the screen reader
[00:32:56.260 --> 00:33:01.700]   sees. So really, what Userway does is make sure that all the information available to the front
[00:33:01.700 --> 00:33:07.540]   page to the sighted user is available to the browser in the accessibility layer. It changes
[00:33:07.540 --> 00:33:12.100]   colors. Now you've got your Pantone color for your business. Of course, we do too. It doesn't
[00:33:12.100 --> 00:33:17.140]   change that. But it adjusts hue and luminance, so it's easier for people with vision issues to read.
[00:33:17.780 --> 00:33:21.940]   So Userway will generate all tags. That's one of the reasons it needs AI. It can actually see the
[00:33:21.940 --> 00:33:26.420]   picture and generate an all tag that matches the picture automatically. You can go in if you want,
[00:33:26.420 --> 00:33:32.580]   you can modify it. Of course, it fixes violations like vague links, fixes broken links,
[00:33:32.580 --> 00:33:38.100]   makes sure that your website uses accessible colors. And you'll get a detailed report of all the
[00:33:38.100 --> 00:33:42.580]   violations that were fixed on your website. So you know exactly what it did. Plus, you can work
[00:33:42.580 --> 00:33:49.220]   with it. Userway integrates seamlessly with your site builder software. Let Userway help your
[00:33:49.220 --> 00:33:54.020]   business meet its compliance goals, improve the experience for your users. Userway can make any
[00:33:54.020 --> 00:33:59.860]   website fully accessible, ADA compliant, and everyone who visits can browse seamlessly,
[00:33:59.860 --> 00:34:04.900]   customize it to fit their needs. It's a great way to show your brand's commitment to the millions
[00:34:04.900 --> 00:34:07.540]   of people with disabilities. It's the right thing to do.
[00:34:07.540 --> 00:34:20.900]   Userway can make any website fully accessible and ADA compliant. Just look at the bottom of
[00:34:20.900 --> 00:34:26.820]   Twit.tv in the lower right hand corner. You'll see the Userway icon. And you can see just with
[00:34:26.820 --> 00:34:32.260]   one line of code how it's transformed our website. With Userway, everyone who visits the site can
[00:34:32.260 --> 00:34:38.180]   browse seamlessly, can customize it to fit their needs. It's also a perfect way to showcase your
[00:34:38.180 --> 00:34:41.940]   brand's commitment to millions of people with disabilities. You don't want to leave them out,
[00:34:41.940 --> 00:34:48.980]   right? Go to Userway.org/Twit. You'll get 30% off Userway's AI powered accessibility solution
[00:34:48.980 --> 00:34:59.780]   right now. Userway, making the internet accessible for everyone. Userway.org/Twit.
[00:34:59.780 --> 00:35:05.540]   Thank you, Userway. And thank you, viewers and listeners. Now you can come back. We're not
[00:35:05.540 --> 00:35:09.620]   going to talk about Elon anymore. We're not going to talk about Twitter anymore. Although,
[00:35:09.620 --> 00:35:16.580]   I honestly could spend hours doing it. It's just somehow endlessly fascinating to me. Stocks have
[00:35:16.580 --> 00:35:25.540]   become fascinating to a lot of people. Big Nasdaq drop in tech stocks. Alex, you cover big tech.
[00:35:26.180 --> 00:35:33.220]   So obviously, you're covering, to some degree, the tech stock prices.
[00:35:33.220 --> 00:35:40.420]   Is this a reflection of some deeper problem with big tech or is this just the usual
[00:35:40.420 --> 00:35:47.540]   financial market fluctuation? I don't think this is a problem with big tech fundamentally.
[00:35:47.540 --> 00:35:52.340]   I think what we're seeing now is what I think is a perfect storm of a number of really challenging
[00:35:52.340 --> 00:35:57.540]   factors hitting tech all at the same time. Just to quickly list them, you have the Fed raising
[00:35:57.540 --> 00:36:03.060]   interest rates, which deprioritizes growth and prioritizes current profits. And we all know that
[00:36:03.060 --> 00:36:09.620]   the valuations of tech are much more about what they can do in the future because they have the
[00:36:09.620 --> 00:36:14.660]   ability to grow in a faster way than let's say, like a brick and mortar store. So that's number
[00:36:14.660 --> 00:36:19.300]   one. I think that's one of the biggest issues. It's called total re-rating the valuations of
[00:36:19.300 --> 00:36:24.900]   these companies. Number two is the Ukraine war. You take a look at companies like Netflix,
[00:36:24.900 --> 00:36:28.900]   which pulled out of Russia, lost to millions of subscribers, posted their first
[00:36:28.900 --> 00:36:35.940]   subscriber loss based off of that alone. It's also hit Facebook and Snap. I think those are big
[00:36:35.940 --> 00:36:42.660]   issues. The supply chain is still a mess. So any company that's going to sell based off of ads on
[00:36:42.660 --> 00:36:49.220]   these platforms is now starting to rethink it and trying to figure out, hey, how do I handle
[00:36:49.220 --> 00:36:55.460]   this? Inflation is going to cause people to change the way that they spend. And it goes on and on.
[00:36:55.460 --> 00:37:01.540]   And I think that when you have all this hitting at the same time, it has taken a lot of the air
[00:37:01.540 --> 00:37:06.180]   out of the market, which let's be honest, the market was not exactly running on the fundamentals
[00:37:06.180 --> 00:37:12.180]   for the last couple of years. And now it is. So this is a, if this selloff actually makes sense,
[00:37:12.180 --> 00:37:17.220]   it sounds like. Yeah, to me, the thing that didn't make sense was the run up on tech stocks over the
[00:37:17.220 --> 00:37:21.300]   last couple of years. Some of that was a pandemic though, right? Yeah, pandemic.
[00:37:21.300 --> 00:37:25.140]   Yeah, that's where I was going. Is the pandemic going to change the way that Amazon does business,
[00:37:25.140 --> 00:37:30.820]   Facebook does business, companies like Amazon or what we said Amazon, but Amazon, Facebook,
[00:37:30.820 --> 00:37:37.380]   Microsoft, Zoom, of course it is. Netflix, yes, definitely. And we're still seeing massive gains
[00:37:37.380 --> 00:37:42.020]   that have haven't gone away for these companies. But the market, I don't know exactly what happened
[00:37:42.020 --> 00:37:46.260]   for some reason investors got carried away here and thought that this is the way that we were
[00:37:46.260 --> 00:37:49.940]   just going to be living forever. And I think in the middle of a COVID fog, it's possible
[00:37:49.940 --> 00:37:54.260]   to think that we're going to be living in the COVID lifestyle forever, which means of course,
[00:37:54.260 --> 00:38:01.300]   Netflix should be $1,000 a share versus what it is now, $199, it's less, I might check.
[00:38:01.300 --> 00:38:06.580]   It got up to around 700. But it's obviously just not the case. We were always going to go back
[00:38:06.580 --> 00:38:10.260]   into the world. So then the Apple people like on clubhouse, they thought we'd just going to be
[00:38:10.260 --> 00:38:14.660]   on clubhouse forever. And then the first thing, first night we're able to go out for dinner,
[00:38:15.460 --> 00:38:23.060]   that goes away. And so like Earth to investors, like, you got to think beyond. And it's a good
[00:38:23.060 --> 00:38:27.060]   thing. You got to think beyond like a couple of years of COVID. And right now we're starting to
[00:38:27.060 --> 00:38:34.020]   see the hangover from what was in an e-breathed market that was just not working on fundamentals,
[00:38:34.020 --> 00:38:35.140]   working on for fairy tales.
[00:38:35.140 --> 00:38:43.700]   I would love your opinion on this because I have a theory about one of the main things is
[00:38:43.700 --> 00:38:49.220]   causing inflation that I don't think is discussed enough. And that is the supply chain.
[00:38:49.220 --> 00:38:54.340]   So let me tell you about two of my hobbies. The first is collecting classic portions, right?
[00:38:54.340 --> 00:39:01.700]   Those prices have just skyrocketed through the roof, right? I have a 997. It was worth $40,000
[00:39:01.700 --> 00:39:08.740]   three years ago. Today it's worth about 65 or 70,000. Pimball machines are another one because
[00:39:08.740 --> 00:39:13.700]   people are spending so much time at home. And it's so hard to buy these things new right now.
[00:39:13.700 --> 00:39:20.980]   My theory about why inflation is really leading to a lot of the fear in the stock market.
[00:39:20.980 --> 00:39:26.580]   I think a lot of it's the supply chain just because it's so hard to get anything.
[00:39:26.580 --> 00:39:34.020]   Cameras, even rare video game prices are just skyrocketing. Just across the board.
[00:39:35.220 --> 00:39:39.780]   I feel like we're not going to get a lot of these. I don't think we're going to get the market on
[00:39:39.780 --> 00:39:45.540]   the right track until we get our supply line under track because it's the two are very much
[00:39:45.540 --> 00:39:50.740]   connected. Yeah. And it doesn't look like the supply chain is going to get fixed anytime soon.
[00:39:50.740 --> 00:39:59.860]   Pat Galsinger, CEO of Intel, was saying 2025. Not next year. That's the year after, just in case
[00:39:59.860 --> 00:40:06.020]   you don't don't know. Go ahead, Alex. Well, the big debate is whether this inflation is
[00:40:06.020 --> 00:40:10.580]   supply chain related or whether it's interest rate related. I didn't agree with you, Biana.
[00:40:10.580 --> 00:40:14.740]   I think that it is supply chain related. Here's a quick story. One of my parents' neighbors
[00:40:14.740 --> 00:40:19.940]   works in shipping and to import a container from China, he called me over. He's like,
[00:40:19.940 --> 00:40:26.100]   Alex, we're making money hand off over fist because it used to cost $2,000. Now we can make $15,000.
[00:40:26.660 --> 00:40:32.900]   And now it's cost. The cost is in the 20s. So the supply chain stopped. It started. There was huge
[00:40:32.900 --> 00:40:38.500]   demand. Ships didn't go back online. And then you ended up having this massive increase in
[00:40:38.500 --> 00:40:43.700]   containers, which ends up and shut downs in China, which causes supply contraction.
[00:40:43.700 --> 00:40:47.700]   And then, yeah, prices go up. And my neighbor goes, listen, there's going to be inflation and
[00:40:47.700 --> 00:40:52.020]   lo and behold, if you're working in shipping, you know, and he knew. And that's where we are now.
[00:40:52.820 --> 00:40:56.740]   But that being said, the Fed is still going to raise the rate because the Fed understands
[00:40:56.740 --> 00:41:01.940]   that it's been an easy money environment for the last couple of years that it tried to stoke the
[00:41:01.940 --> 00:41:07.060]   economy because of COVID. And so it feels responsible too. And so you might end up in a situation where
[00:41:07.060 --> 00:41:13.780]   you have the Fed raising the rate, which inevitably does compress the valuation of stocks. And that
[00:41:13.780 --> 00:41:19.860]   not solving our inflation issue, which could lead us to all sorts of help. And so I do think
[00:41:19.860 --> 00:41:24.020]   that when people say, you know, there's a chance we're going to end up in a recession in 2023.
[00:41:24.020 --> 00:41:30.500]   And the Fed says we'll have a soft landing. I tend to believe that the people with the darker
[00:41:30.500 --> 00:41:35.300]   predictions on this one, because it's not going to be easy to fix. It was easy to keep our economy
[00:41:35.300 --> 00:41:40.740]   humming during a pandemic, which is, you know, somewhat of a miracle. But, you know, we have to
[00:41:40.740 --> 00:41:44.900]   pay the piper at a certain point. And this is this is where it's coming might not be that easy. We
[00:41:44.900 --> 00:41:52.420]   also spend a lot of money on COVID relief checks and loans. And some say that's also been a cause of
[00:41:52.420 --> 00:41:57.060]   well, it's like, yeah, exactly. It's like a credit card. Yeah, it's like credit card, you know,
[00:41:57.060 --> 00:42:01.940]   easy to whip that out and spend tons of cash at the mall. But then the bill comes and you're like,
[00:42:01.940 --> 00:42:05.620]   God damn, where's the money for all this? And it's like, Oh, we should have thought about that when
[00:42:05.620 --> 00:42:09.380]   we were doing it, because it felt like it was free when we're walking out of the mall. But
[00:42:09.380 --> 00:42:13.380]   eventually that bill does come due. And there's interest on it. Brianna, you told a story about
[00:42:13.380 --> 00:42:19.700]   inflation having to do with your and the supply chain having to do with your hobbies. I have
[00:42:19.700 --> 00:42:27.780]   purchased many a Pokeball plus in my life to play Pokemon go Lisa recently broke her Pokeball plus
[00:42:27.780 --> 00:42:34.980]   went online. It was $20 when I bought it before the pandemic, $144.
[00:42:34.980 --> 00:42:41.700]   140, but I can get it tomorrow. Now, Lisa's no fool. So she shopped around and she found somewhere
[00:42:41.700 --> 00:42:47.780]   where she could get it for $20, but you might not get it tomorrow. That was three months ago.
[00:42:47.780 --> 00:42:54.500]   And I think it's somewhere on a container ship between here in China. But you know,
[00:42:54.500 --> 00:42:58.900]   if you want it tomorrow, you're going to pay a little bit, a little bit more for your Pokeball
[00:42:58.900 --> 00:43:04.580]   plus. But you can tell Lisa, I've got mine and I don't play that game anymore. So if she needs
[00:43:04.580 --> 00:43:11.060]   that, oh, you know, we might need an emergency Pokeball plus loan. This allows you to walk around town
[00:43:11.700 --> 00:43:15.780]   without having your Pokemon go game out all the time and just press the button on the ball
[00:43:15.780 --> 00:43:22.660]   whenever you vibrate and you collect Pokemon. It's amazing. It's amazing. Alex, I want to get
[00:43:22.660 --> 00:43:28.100]   back to one of the points you were making though about lower interest rates. And you know, I do
[00:43:28.100 --> 00:43:34.020]   think that it's been artificially low for a really long time. And I think we don't talk about this
[00:43:34.020 --> 00:43:40.660]   enough that, you know, when the interest rate is that low, it does have, you know, consequences
[00:43:40.660 --> 00:43:45.780]   through the rest of the industry, right? Like a low interest rate is not automatically a good
[00:43:45.780 --> 00:43:53.300]   thing. The other part of that is, I think my biggest criticism now that kind of the emergency
[00:43:53.300 --> 00:43:58.500]   has passed and we can look at what we actually got for all those for all the COVID relief that we
[00:43:58.500 --> 00:44:04.180]   spent. And I think it's really important to remember we spent, we literally fired bazookas of cash
[00:44:04.180 --> 00:44:09.540]   at the Fed. There are plenty of people that made lots of money just following the stock market and
[00:44:09.540 --> 00:44:15.940]   seeing what the Fed was like basically propping up with all of that money. They made out like bandits
[00:44:15.940 --> 00:44:21.220]   there. And now that we're looking at how much of the money, the trillions we spent on that
[00:44:21.220 --> 00:44:26.900]   actually ended up in the hands of things like rent relief, right? Or, you know, things to actually
[00:44:26.900 --> 00:44:32.580]   help people. It's becoming more and more apparent that money was just frankly misallocated and we
[00:44:32.580 --> 00:44:38.900]   did need more oversight there. So, you know, I just think it's important to realize when we have an
[00:44:38.900 --> 00:44:44.820]   emergency, it matters how you spend that money. I think we're looking at it now and realizing
[00:44:44.820 --> 00:44:50.420]   it didn't really help people as much as it should have. Well, not only that, but to add insult to
[00:44:50.420 --> 00:44:58.180]   injury, the value of Bitcoin has plummeted. Plumbit, I say, over the last is now down to $34,000,
[00:44:58.180 --> 00:45:03.860]   which I, you know, if you don't pay a lot of money, a lot of attention to Bitcoin, I thought it was
[00:45:03.860 --> 00:45:11.140]   like well below 30. But apparently it had come back, goes up and goes down. I don't know. If you're
[00:45:11.140 --> 00:45:17.300]   all in on Bitcoin, it's a crazy ride, isn't it? Yeah, but you still did better in Bitcoin than
[00:45:17.300 --> 00:45:21.620]   you would have been like Shopify or Netflix last year. That's true. How much did Shopify lose 70%
[00:45:21.620 --> 00:45:28.980]   this year? Shopify is down 70%. 70%. What is, why are they hitting e-commerce sites?
[00:45:29.700 --> 00:45:34.420]   They're in the crosshairs of all these trends, right? I mean, supply chain, right? That's
[00:45:34.420 --> 00:45:39.780]   definitely like Shopify, of course. Amazon can survive supply chain. So,
[00:45:39.780 --> 00:45:44.260]   Shopify is much more difficult for smaller merchants too. And you put that and you combine that with
[00:45:44.260 --> 00:45:48.500]   inflation, right? People are going to try to think about what they're going to sacrifice.
[00:45:48.500 --> 00:45:52.180]   I'm going to sacrifice buying from that Shopify site, most likely. Not going to buy that impulse
[00:45:52.180 --> 00:45:57.460]   purchase from Facebook or Instagram anymore. And then, of course, they didn't have the growth,
[00:45:58.500 --> 00:46:03.300]   that they projected. And if you're in an environment that rewards growth stocks,
[00:46:03.300 --> 00:46:06.580]   then you go to an environment that punishes growth stocks and you're not growing and you're
[00:46:06.580 --> 00:46:10.580]   dealing with supply chain and inflation, your stocks are going to go down 70%. And that's what
[00:46:10.580 --> 00:46:16.420]   happened to Shopify. I don't know if it's related to the falling Bitcoin. And I don't know if I
[00:46:16.420 --> 00:46:23.460]   fully trust the Wall Street Journal on NFTs, but according to the journal, NFTs sales are
[00:46:23.460 --> 00:46:30.340]   flatlining. Actually, I've seen this in other places too. The daily average
[00:46:30.340 --> 00:46:40.580]   sale of non-fungible tokens down 92% from its peak of 225,000 in September down to 19,000
[00:46:40.580 --> 00:46:49.220]   tokens this week. The number of active wallets in the market, 88% down, 14,000 last week.
[00:46:49.860 --> 00:46:56.900]   Are what's going on? Is this just a people money's tight, not buying NFTs? Is this people saying,
[00:46:56.900 --> 00:47:02.180]   you know, this whole NFT thing was a speculative bubble? That's my personal feeling.
[00:47:02.180 --> 00:47:06.740]   People were rising up or is it just a normal slowdown?
[00:47:06.740 --> 00:47:10.500]   I think they ran out of bigger fools to market this.
[00:47:10.500 --> 00:47:17.060]   It's kind of my point of view. At some point, a pyramid scheme, you get to the top of the pyramid.
[00:47:17.620 --> 00:47:24.260]   It's done. 100%. I don't know if you saw this, Lea. Did you see there's a fantastic YouTube channel
[00:47:24.260 --> 00:47:31.780]   called LegalEagle? Yes. I did see it. The Discord chat sent me a link to it.
[00:47:31.780 --> 00:47:36.180]   It's beautiful. It's beautiful. So just in case your listeners have not seen this,
[00:47:36.180 --> 00:47:43.460]   it's a 40-minute video of basically the legal case around NFTs and asking yourself very critically,
[00:47:43.460 --> 00:47:48.500]   what are you actually buying? And I had to tell you, is this spectacular takedown?
[00:47:48.500 --> 00:47:54.100]   I was actually more NFT before I saw this video. But then when he walks through all the legal
[00:47:54.100 --> 00:48:00.340]   arguments, I'm like, "No, this is scam." So his basic argument here is, think of NFTs as basically
[00:48:00.340 --> 00:48:06.740]   a receipt showing that you've bought something. The receipt does not work in lieu of the strongest
[00:48:06.740 --> 00:48:11.860]   protection you have to actually own something like a work of art. That's a copy right here.
[00:48:11.860 --> 00:48:18.660]   You can't say that it's subbed in one for the other. So as far as who actually owns the NFT itself,
[00:48:18.660 --> 00:48:24.660]   it's actually a very, very murky argument. He also goes into the way a lot of these are marketed
[00:48:24.660 --> 00:48:31.380]   and how there's a very, very good legal argument that they fall under the good old-fashioned lawsuit
[00:48:31.380 --> 00:48:36.820]   that you can find yourself faced with for fraud. You know, pumping up schemes, promising something
[00:48:36.820 --> 00:48:44.020]   and getting something else. And even if you're a creator creating these NFTs and hoping to make
[00:48:44.020 --> 00:48:50.660]   money from them, you could actually find yourself legally bound to follow us through on some of
[00:48:50.660 --> 00:48:57.620]   these promises. An example he gives is someone that buys an NFT having a right to basically talk
[00:48:57.620 --> 00:49:02.100]   to a creator about that. Well, there's a certain way to look at that agreement saying,
[00:49:02.100 --> 00:49:07.060]   well, if someone buys an NFT, you've got to get out of bed at 2am and go jump on a Zoom meeting
[00:49:07.060 --> 00:49:13.620]   with them or you're out of line with the contract. So there's a lot of reason to be very legally
[00:49:13.620 --> 00:49:19.940]   careful with these. And I think that there's very little reason to feel like you actually own the
[00:49:19.940 --> 00:49:24.340]   work of art that you're actually buying with the NFT. Wow. Yeah. Watch the video. It's really
[00:49:24.340 --> 00:49:30.420]   worth watching. Go ahead, Alex. I was speaking to a Columbia Business School class and NFTs came up
[00:49:30.420 --> 00:49:35.780]   and I was a little bit probably too provocative, but I called it business QAnon, which is okay.
[00:49:35.780 --> 00:49:44.340]   My thought on it was that it felt a lot like a collective delusion to me that people are looking
[00:49:44.340 --> 00:49:49.220]   at signs and stuff and believing in something that just wasn't there. And the next day I get a
[00:49:49.220 --> 00:49:56.500]   FaceTime from an investor friend of mine, Jason Stein. And he's laughing and he has one of the
[00:49:56.500 --> 00:50:03.940]   students from Columbia Business School who was in that class sitting in his office talking about me.
[00:50:03.940 --> 00:50:10.340]   And I was like, all right. Can you believe he's called it business QAnon? Yeah. I know. Okay.
[00:50:10.340 --> 00:50:16.020]   That's fair. So Jason and I are going to have a debate about this on Big Tenons podcast this week.
[00:50:16.020 --> 00:50:21.860]   Oh, good. But I will say we spoke a little bit about it. I do see some merit to it, but I think
[00:50:21.860 --> 00:50:27.060]   why did NFTs explode the way they did? And it goes back again to zero interest rate policy,
[00:50:27.060 --> 00:50:32.100]   where you can't get a return by keeping your money on cash because their interest rate is zero.
[00:50:32.100 --> 00:50:37.060]   You look for alternate and riskier investments. And okay, that could be riskier bonds,
[00:50:37.060 --> 00:50:42.500]   riskier stocks. And then all of a sudden it became kind of anything Bitcoin, NFTs. And
[00:50:42.500 --> 00:50:47.620]   the thing is when the interest rate is zero and people are everyone's looking for those investments.
[00:50:47.620 --> 00:50:52.420]   So it does seem like the price and the value is just going to keep going up
[00:50:52.420 --> 00:50:57.460]   because there's just more and more money flowing into the system. So why are NFTs
[00:50:57.460 --> 00:51:02.020]   crashing at the same time the stock market is it's because now the Fed is ripping that under.
[00:51:02.020 --> 00:51:05.940]   And people are starting to see, I can get safer, more predictable returns. I don't need to be as
[00:51:05.940 --> 00:51:12.340]   risky as I did before. And they make too much sense. And so they leave business QAnon and they go into
[00:51:12.980 --> 00:51:16.820]   treasury bond, you know, kabals. And that's where it goes.
[00:51:16.820 --> 00:51:26.020]   I will say that I do not as a matter of editorial policy by individual stocks of any kind,
[00:51:26.020 --> 00:51:31.220]   nor NFTs. I do own some bitcoins because for a while we are allowing Bitcoin donations,
[00:51:31.220 --> 00:51:36.740]   but I can't access them because I forgot the password. So I really, I don't have a dog in this
[00:51:37.860 --> 00:51:45.300]   in any way. But I do have my all of my retirement money, the money I hope to live on at some point
[00:51:45.300 --> 00:51:53.220]   invested in the market in index funds. And so, you know, I am somewhat sensitive to this. And I
[00:51:53.220 --> 00:52:00.340]   realized that at least half of America does not own any stock as no, they're not in this at all.
[00:52:00.340 --> 00:52:05.300]   But it does impact the economy. It does it does affect inflation. It affects what the price you
[00:52:05.300 --> 00:52:10.420]   pay at the pump and at the grocery store. Maybe not directly, but it's certainly indirectly.
[00:52:10.420 --> 00:52:15.140]   And it's crazy right now. I mean, you can be in cash and then down 8.5% because of inflation,
[00:52:15.140 --> 00:52:20.100]   or you could be in the S&P 500 and be down 13%. Yeah, it's like nowhere to go right now.
[00:52:20.100 --> 00:52:25.220]   When the pandemic started, I thought I was real smart and I converted all my holdings to cash,
[00:52:25.220 --> 00:52:30.420]   figuring the market would completely crash. And that turned out to be the exactly the wrong thing
[00:52:30.420 --> 00:52:37.300]   to do. So, you know, I tuck my tail between my legs and got back into the S&P 500 into
[00:52:37.300 --> 00:52:42.740]   index funds. And it's been a great ride until, you know, a few months ago. Now I'm thinking,
[00:52:42.740 --> 00:52:49.540]   maybe I should have stayed in cash. I don't know. I don't know. It's pretty scary right now.
[00:52:49.540 --> 00:52:56.420]   You know, it's scary. You're 65. It's scary. Yeah. If you like most Americans didn't save
[00:52:56.420 --> 00:53:00.340]   enough money for retirement, your Social Security is not going to provide for you.
[00:53:00.340 --> 00:53:06.100]   It is scary. And as somebody in that age group, I'm very sensitive to that, you know,
[00:53:06.100 --> 00:53:11.540]   Oh, 100%. Yeah. You know, I think it's crazy is, you know, when I bought like my pinball machines
[00:53:11.540 --> 00:53:16.580]   to keep me sane over the pandemic, it's like, I mean, those have all made money. I could go
[00:53:16.580 --> 00:53:21.620]   sell them today and I will make 20% on what I paid for them. I wish I bought more of those
[00:53:21.620 --> 00:53:27.140]   poke balls to be honest with you. That's the best. That would buy him a 20-cell
[00:53:27.140 --> 00:53:36.100]   amount, 144. That's 700%. 100%. Yeah. I have a real, I have a really dark like, not dark,
[00:53:36.100 --> 00:53:41.860]   but this is my honest opinion about what's going on with NFTs. I think that as you said,
[00:53:41.860 --> 00:53:47.140]   Leah, we have an entire generation that doesn't invest in the stock market. They've really been
[00:53:47.140 --> 00:53:52.100]   kind of locked out of economic prosperity in the way that you're my generation. I think your
[00:53:52.100 --> 00:53:59.140]   generation has mine is I'm the boomers. And you know, we are the ones who I'm sorry. That's all I
[00:53:59.140 --> 00:54:08.900]   can say. We put you and my kids who are millennials and the Gen Zers, they are dead-end jobs. They're
[00:54:08.900 --> 00:54:16.500]   working their butts off. They have horrific and they can't afford a home. They are really
[00:54:16.500 --> 00:54:22.660]   screwed. Right. This thing's to be a millennial. You come out, you got a recession, then you move
[00:54:22.660 --> 00:54:29.460]   into the economy recovers, get another recession, and then you're just hitting your stride of your
[00:54:29.460 --> 00:54:35.060]   career and COVID happens. So horrible. Yeah. But to come back to my point with this,
[00:54:35.700 --> 00:54:41.220]   I 100% agree with that. I think that you have a generation there and they're looking at,
[00:54:41.220 --> 00:54:49.940]   well, how do I get on my feet? Right. How do I get a footing? And I think Bitcoin and NFTs have
[00:54:49.940 --> 00:54:54.500]   been, I think it really appeals to people. Well, it's magical thinking, but they are at the point
[00:54:54.500 --> 00:54:58.900]   where they need it. Right. They need that. Right. 100%. And they're thinking like, okay,
[00:54:58.900 --> 00:55:04.580]   I under like NFTs and Bitcoin are technically complicated. They just are. And you think to yourself,
[00:55:04.580 --> 00:55:10.420]   okay, I'm smart enough to understand this concept. Therefore, it's worth investing my money.
[00:55:10.420 --> 00:55:16.500]   And there's definitely this meme culture behind it that Elon's been very successful in, you know,
[00:55:16.500 --> 00:55:24.340]   tagging himself on to. Yeah. I think it's really led to these, these investments that are detached
[00:55:24.340 --> 00:55:29.860]   from things I certainly learned when I took business classes, you know, PDE ratio, or you're
[00:55:29.860 --> 00:55:36.980]   just basic fundamentals of a stock. And I think it's another scam on an entire generation, in my
[00:55:36.980 --> 00:55:44.180]   opinion. Yeah, I do. I understand that, and I've been having this kind of discussion with myself
[00:55:44.180 --> 00:55:50.740]   and with others for about a year, as stock prices get more and more divorced from fundamentals,
[00:55:50.740 --> 00:55:58.020]   they become more and more indistinguishable from cryptocurrencies. They're pure speculative
[00:55:58.980 --> 00:56:05.300]   investments. And at that point, well, why not invest in Bitcoin? It's just as speculative.
[00:56:05.300 --> 00:56:12.340]   There's no, if a stock, if Elon Musk's Tesla is worth hundreds of, you know, 100 times more than
[00:56:12.340 --> 00:56:19.540]   the entire auto industry put together, then it's speculative. So might as well buy Bitcoin. I
[00:56:19.540 --> 00:56:23.860]   completely understand that. Go ahead, Alex. I mean, I'll just say that I wish when I was younger,
[00:56:23.860 --> 00:56:29.140]   there was a game stop situation or an AMC. And I think the optimist thing.
[00:56:29.140 --> 00:56:31.460]   But don't you think many people are going to get hurt to buy that?
[00:56:31.460 --> 00:56:35.460]   Yeah, for every upside, there's a downside. Totally. But it's much better to get hurt in
[00:56:35.460 --> 00:56:40.260]   your 20s, because then you start to learn about how to not get hurt. And I do think that this moment
[00:56:40.260 --> 00:56:44.660]   really brought a lot of retail investors online, and they're going to make mistakes in their 20s that,
[00:56:44.660 --> 00:56:48.660]   you know, they otherwise might have 30s or 40s. Yeah. And learn, hey, wait, you know,
[00:56:48.660 --> 00:56:52.340]   what? Because that's a good point. I mean, like once people, when you put money into something,
[00:56:52.340 --> 00:56:56.420]   you all of a sudden have an incentive to learn a lot more about it. And maybe people will start
[00:56:56.420 --> 00:57:01.140]   to like, you know, they're probably, you have young people reading CNBC, you know, people,
[00:57:01.140 --> 00:57:05.940]   I didn't read it when I was in my 20s. You have young people reading the website watching the
[00:57:05.940 --> 00:57:09.700]   channel, and they're going to learn, you know, eventually you speak to enough people and you
[00:57:09.700 --> 00:57:13.700]   realize, you know, the way to make money in the markets is to put it in the indices,
[00:57:13.700 --> 00:57:17.380]   like you're doing Leo, and then wait for a while. Yeah, but I learned that you're right.
[00:57:17.380 --> 00:57:22.100]   I learned that to my 40s. Exactly. What ended up in awesome if you had a game stop when you
[00:57:22.100 --> 00:57:26.740]   were in your 20s where you could learn that hard lesson early and then make the right moves,
[00:57:26.740 --> 00:57:32.020]   because you know, that does, it does compound over time. So I took optimistic lens over this,
[00:57:32.020 --> 00:57:36.340]   and I say it's probably a good thing. And hopefully, you know, this crypto thing will sort itself out,
[00:57:36.340 --> 00:57:43.620]   but overall, I agree and disagree with that. I agree that it's good that some of these people
[00:57:43.620 --> 00:57:48.340]   are learning a hard lesson. Like there were stories about, you know, people and what they did during
[00:57:48.340 --> 00:57:56.260]   the game stop explosion, like people that went and took $80,000 of debt out at like 15% interest rates,
[00:57:56.260 --> 00:58:01.460]   right? Like just crazy stuff. At the same time, you know, if we're talking economics here,
[00:58:01.460 --> 00:58:07.140]   there's an externality to all of this. And the externality is you can look at poll numbers and
[00:58:07.140 --> 00:58:13.460]   you can see you can ask this generation, like do you believe in like the fundamentals of like
[00:58:13.460 --> 00:58:20.020]   the stock market working and, you know, like the basic promise of America? Like do you believe in
[00:58:20.020 --> 00:58:25.700]   things that frankly, I'm a Gen X or I'm the last year of Gen X, we believed in this. And I think
[00:58:25.700 --> 00:58:32.740]   that this generation is coming away remarkably cynical with this. And I think they do have a correct
[00:58:32.740 --> 00:58:38.900]   impression that the stock market is rigged for certain people. Like you look at payment for
[00:58:38.900 --> 00:58:45.620]   order flow and just the ways that you fail to like, you basically break the market for people
[00:58:45.620 --> 00:58:50.900]   with more information. I think they've come to a correct conclusion. So yes, I agree with you
[00:58:50.900 --> 00:58:55.700]   that they could learn a lesson here. But I think that lesson may be pretty dystopian.
[00:58:55.700 --> 00:59:04.260]   Yes, but look, I think that first of all, it's more than just the market that that is informing
[00:59:04.260 --> 00:59:10.820]   these opinions. And second of all, if you're in your twenties and you understand a concept like
[00:59:10.820 --> 00:59:16.340]   payment for order flow, you are way ahead of the game because in order to be the market.
[00:59:16.340 --> 00:59:21.940]   And many people learn that lesson from Robin Hood. Look, yes, you're going to just to bring this
[00:59:21.940 --> 00:59:28.100]   point home, the market is rigged. And if you understand that, that's when you can start to make
[00:59:28.100 --> 00:59:32.100]   decisions that are going to be good for your long term financial health. If you are not going to
[00:59:32.100 --> 00:59:36.580]   understand that and you're going to stay out, you're going to be in cash and you'd be down 8.5%
[00:59:36.580 --> 00:59:42.020]   because of inflation. So are there going to be horror stories that we can point to without a doubt?
[00:59:42.020 --> 00:59:47.060]   There are in every situation. That being said, is there going to be a large benefit because there's
[00:59:47.060 --> 00:59:51.540]   going to be financial literacy among young people that there wasn't, let's say in my generation?
[00:59:51.540 --> 00:59:55.700]   Absolutely 100%. I view that as a good thing. Here's the thing, Alex. And I think this is what
[00:59:55.700 --> 01:00:00.660]   Brianna is saying as well. Yeah, all well and good. They're getting an education. If
[01:00:01.380 --> 01:00:09.140]   there's an alternative that makes sense. And right now, all you're learning is it's all,
[01:00:09.140 --> 01:00:16.900]   you're out of luck. There is no like, well, okay, good. And now I understand that the market is rigged.
[01:00:16.900 --> 01:00:23.300]   So I'm going to do what? What is the alternative? I mean, it's obvious. Okay,
[01:00:23.300 --> 01:00:27.140]   it's where is it rigged? It's rigged in places like Robin Hood, where there's payment for order
[01:00:27.140 --> 01:00:31.940]   flow, where your free trade isn't trade. And all young kids know that right now. So what do you do?
[01:00:31.940 --> 01:00:35.780]   You're going to go to a different service where that doesn't take money off of payment for order
[01:00:35.780 --> 01:00:40.900]   flow and probably invest in index funds and sit there and wait for a long time. I hope so.
[01:00:40.900 --> 01:00:45.700]   And that's how you're going to make money. I hope so. I mean, that's why I'm always telling my kids.
[01:00:45.700 --> 01:00:50.900]   Absolutely. Yeah, buy the index funds. Yeah, there are a canon of books that get passed along
[01:00:50.900 --> 01:00:56.820]   once you speak enough about this stuff. And I think really highly of the younger generations
[01:00:56.820 --> 01:01:02.580]   right now. And I do believe, and speaking with people in the generation, I do believe they get it.
[01:01:02.580 --> 01:01:06.660]   I do believe there's a hunger to get it. And I think they're going to be way better off. Are
[01:01:06.660 --> 01:01:12.500]   there going to be mistakes? Yes. But can you find places to get good returns on your money?
[01:01:12.500 --> 01:01:19.540]   100% that is true. They could probably being young right now by the S&P 500 discounted,
[01:01:19.540 --> 01:01:24.180]   given that it's going through the hard time that it is at the moment. So I don't think it's all
[01:01:24.180 --> 01:01:30.020]   negative on this front. I'll if you're under a certain age, how old are you, Alex?
[01:01:30.020 --> 01:01:34.820]   35. Oh, see, you see, you're still a baby.
[01:01:34.820 --> 01:01:41.940]   Breanna, from my point of view, you're still a baby. This is when I woke up. And this was,
[01:01:41.940 --> 01:01:48.020]   I wish it had been sooner. By the way, you're zoomed in. Can you un-zoom in on my screen?
[01:01:50.100 --> 01:01:55.780]   The guy, he's passed away at the age of 67, is very sad. He was the guy who ran the institutional
[01:01:55.780 --> 01:02:02.580]   portfolio for Yale. And there you go. It did very well, surprisingly well, wrote a book called
[01:02:02.580 --> 01:02:10.660]   Unconventional Success that I highly recommend to anybody who is under Alex's age, who has
[01:02:10.660 --> 01:02:15.220]   learned this lesson, but then now doesn't know, well, okay, so what should I get? I guess I
[01:02:15.220 --> 01:02:22.900]   even lost my shirt on Dogecoin. What should I get? And that's exactly the strategy you and I have
[01:02:22.900 --> 01:02:26.740]   been talking about. And it's but it's a little bit more detailed, highly recommended.
[01:02:26.740 --> 01:02:32.100]   Unconventional Success by David Swenson, S-W-E-N-S-E-N.
[01:02:32.100 --> 01:02:36.020]   There is... Or you could do what I do and just put all your money into Portia's.
[01:02:36.020 --> 01:02:40.180]   Or by Portia's and people, machines, baby. Yeah, wait for those two to go up.
[01:02:40.180 --> 01:02:47.220]   That's a great strategy. A great strategy. You did say something, though, Brianna, that I think is
[01:02:47.220 --> 01:02:55.060]   problematic and not just in the markets, but in general. The United States, as I think any time
[01:02:55.060 --> 01:03:02.020]   people, humans, achieve something as a group, it's because they have a shared mythology.
[01:03:03.060 --> 01:03:09.620]   And in the US, we had, and I say it past tense, I'm sad to say, we had a shared mythology of
[01:03:09.620 --> 01:03:16.900]   you can make it with hard work and intelligence, that democracy is good, speech is good,
[01:03:16.900 --> 01:03:23.700]   that we all are in this together, that we need to compromise to get forward. There were all these
[01:03:23.700 --> 01:03:30.900]   mythologies we had about the United States and probably the most important, the rule of law.
[01:03:32.260 --> 01:03:37.940]   And those, I feel those mythologies have been shattered. And I think that once that happens
[01:03:37.940 --> 01:03:44.100]   in a country, and I've seen it happen in other countries, the center cannot hold things fall
[01:03:44.100 --> 01:03:51.140]   apart. You will not survive as a nation. And it is... Now, I say mythologies because they're kind of
[01:03:51.140 --> 01:03:59.460]   made up. I understand. But the belief in them, the fundamental belief in the perfectibility of
[01:03:59.460 --> 01:04:04.180]   humans and a country that can go forward and take care of all of its people and all of that,
[01:04:04.180 --> 01:04:08.980]   we've never really done that right. But we believed in it and we tried to do that,
[01:04:08.980 --> 01:04:14.100]   is what keeps a country together. And I feel like that is where we really are going to have a
[01:04:14.100 --> 01:04:18.740]   problem. And it's not just the markets. The markets are just a bellwether of what's going to happen
[01:04:18.740 --> 01:04:25.780]   ultimately, where we've lost our sense of what the American dream is all about.
[01:04:27.540 --> 01:04:33.060]   I don't know if you saw the Atlantic article a couple of weeks ago. This really struck me as
[01:04:33.060 --> 01:04:38.740]   the most true thing I've ever read. Jonathan Hape, right? Yeah. I think so. It was the one that
[01:04:38.740 --> 01:04:43.620]   basically talked about what is going on right now. It's been like the tower about 10 years of
[01:04:43.620 --> 01:04:49.940]   American life have been uniquely stupid. Right. It was talking about how it's like the tower
[01:04:49.940 --> 01:04:55.860]   babble myth in the Bible. And if you didn't read that growing up, basically what happens is
[01:04:55.860 --> 01:05:03.300]   myth that basically everyone left speaking different languages. And it's how we kind of fragmented
[01:05:03.300 --> 01:05:08.740]   as a species and went all around the globe. And I think that's really true. I mean, look at the
[01:05:08.740 --> 01:05:14.900]   discussion we just had on Elon Musk and what a different concept free speech means to me
[01:05:14.900 --> 01:05:20.740]   as someone that's really dealt with the brunt of trolls in a very dramatic way. And just someone
[01:05:20.740 --> 01:05:28.420]   like Elon Musk, we have such separate assumptions there. I think when society doesn't have a story
[01:05:28.420 --> 01:05:34.900]   that they can all make sense of the world with, I think it's really dangerous. And I think,
[01:05:34.900 --> 01:05:41.860]   for me, when I was coming of age, I remember the first Gulf War with George Bush senior. Right.
[01:05:42.580 --> 01:05:48.500]   And I think that that incident really shaped a lot of the way that like,
[01:05:48.500 --> 01:05:56.180]   my generation saw these American institutions because we saw all these things working, basically.
[01:05:56.180 --> 01:06:02.660]   And I think if you come to what's happened in all the years since, it just seems to get worse
[01:06:02.660 --> 01:06:07.940]   and worse and worse. And all of us have our own different stories about why we've gotten that way.
[01:06:08.420 --> 01:06:14.420]   And I just don't know how much longer American society can last if we don't have some sort of
[01:06:14.420 --> 01:06:20.900]   shared story about who we are, where we want to go. And I don't mean to say that if you were black,
[01:06:20.900 --> 01:06:28.020]   50 years ago, life was good. I don't mean this kind of foggy nostalgia for the good old days.
[01:06:28.020 --> 01:06:34.660]   I mean, and I think you would mean as well, I know you mean as well, Brianna, that dream of
[01:06:34.660 --> 01:06:41.620]   what it could be that was first set out in the Declaration of Independence and the Constitution.
[01:06:41.620 --> 01:06:47.140]   And of course, we've never lived up to, but we still have to dream and work and strive for that.
[01:06:47.140 --> 01:06:55.220]   And once people disagree and say, no, that's not it, then we work in different directions in the
[01:06:55.220 --> 01:07:00.180]   whole thing falls apart. And there was a story that I considerably really does.
[01:07:00.980 --> 01:07:06.340]   There was a story that George Swiss senior liked to tell about the first Iraq war and
[01:07:06.340 --> 01:07:12.180]   basically a bunch of American soldiers captured a bunch of Iraqis. And they were really, really
[01:07:12.180 --> 01:07:17.220]   worried that they were going to be killed and tortured. And the American soldiers laughed and
[01:07:17.220 --> 01:07:24.260]   said, look, we're Americans. We don't torture people, of course not. And not to say that it's
[01:07:24.260 --> 01:07:30.260]   not true that we haven't created atrocities as a nation. But I remember hearing that at 12 and saying,
[01:07:30.260 --> 01:07:35.780]   that's my ideal, who I want to be as a country, that we would laugh at the thought, which is why
[01:07:35.780 --> 01:07:43.380]   things like Abu Ghraib hurt so much. Because it was so contrary to my personal ideals. I think if
[01:07:43.380 --> 01:07:49.700]   you ask a lot of people in this generation, like, is this the story of America? Is this the direction
[01:07:49.700 --> 01:07:56.020]   we want to go? I think you got a much more cynical answer. And yeah, I think we can have an adult
[01:07:56.020 --> 01:08:01.300]   conversation about how we've missed the mark. And God knows we have, but we need stories about
[01:08:01.300 --> 01:08:05.060]   who we want to be and where we want to be. It's really about who we want to be, not who we were
[01:08:05.060 --> 01:08:10.100]   ever, but how we want to want to be. And of course, yes, soon as we decided the waterboarding is
[01:08:10.100 --> 01:08:17.540]   not torture, we did torture. Yeah. Yeah. We do have, I would just say we're suffering from a decline
[01:08:17.540 --> 01:08:25.460]   in institutions across the board. And important ones, religion, for instance, the fastest growing
[01:08:25.460 --> 01:08:30.820]   religion in the US is not right. People are not identifying with religion. Community organizations
[01:08:30.820 --> 01:08:37.460]   are in decline, especially after COVID. Our government is not actually exactly acting, you know, like
[01:08:37.460 --> 01:08:43.300]   adults in almost every, in many cases. And then work, work, you know, we get a lot of meaning from
[01:08:43.300 --> 01:08:51.940]   work. And, you know, a lot of jobs out there have gone away or, you know, are just like, yeah,
[01:08:51.940 --> 01:08:56.100]   not terrible, they're not good to be in, like, you know, for instance, in an Amazon film and
[01:08:56.100 --> 01:09:00.340]   center. And when all that stuff starts falling away and you don't have a link to your community,
[01:09:00.340 --> 01:09:05.620]   then you add in two, two years of being, you know, forced to sit at home. It does devastating
[01:09:05.620 --> 01:09:11.780]   things to society. Yeah, I think that's true. We said during a pandemic, this is bringing to a head
[01:09:11.780 --> 01:09:16.500]   problems have been simmering under the surface for some time. And now they're here.
[01:09:17.700 --> 01:09:22.900]   Yes. Yeah. Like income inequality and like a breakdown of institutions. And then you add on
[01:09:22.900 --> 01:09:27.620]   top of that the fact that the health institution hasn't didn't exactly conduct itself in a great
[01:09:27.620 --> 01:09:32.660]   way. They were way too sure. They said, we know this to be true. We know this not to be true. And
[01:09:32.660 --> 01:09:37.780]   they didn't know. And, you know, they lost credibility. And, you know, of course, then, then once it was
[01:09:37.780 --> 01:09:42.580]   very easy to politicize the health establishment, because they lost trust, you know, among the people,
[01:09:42.580 --> 01:09:47.300]   right? And, and especially if you come out of a pandemic, you can't, you can't trust in the
[01:09:47.300 --> 01:09:52.740]   institution of like your, your health, your health, your centralized health systems.
[01:09:52.740 --> 01:09:56.980]   What can you trust in? And the answer for many people became nothing.
[01:09:56.980 --> 01:10:00.740]   Let's not forget. This was the week that we crossed a million deaths.
[01:10:00.740 --> 01:10:03.460]   Damn. Do it. 19 in the United States.
[01:10:03.460 --> 01:10:10.740]   People. Yeah. That's a lot of people. Alex Kantaritz is here. Big technology. He does
[01:10:10.740 --> 01:10:15.860]   the big technology podcast, big technology.substack.com for his newsletter, the author of
[01:10:16.420 --> 01:10:23.940]   Always Day One about big tech. Of course, Brianna Wu, game developer, executive director at the
[01:10:23.940 --> 01:10:28.260]   rebellion pack and Porsche and pinball collector.
[01:10:28.260 --> 01:10:38.260]   I show today brought to you by worldwide technology, WWT and Cisco, WWT is working with
[01:10:38.260 --> 01:10:43.540]   clients all over the world to transform their businesses. At the heart of WWT, the advanced
[01:10:43.540 --> 01:10:50.420]   technology center, the ATC, an amazing, amazing research and testing lab that brings together
[01:10:50.420 --> 01:10:55.380]   technologies from all the leading OEMs, more than half a billion dollars in equipment invested in
[01:10:55.380 --> 01:11:01.140]   the lab. Lisa and I visited it a couple of years ago and we're blown away. I can't wait to go back.
[01:11:01.140 --> 01:11:05.860]   But what's great about the ATC? I mean, of course, it was designed initially for the engineers and
[01:11:05.860 --> 01:11:11.540]   partners at WWT to use it to spin up proofs of concept and pilots to understand technologies,
[01:11:11.540 --> 01:11:20.500]   how they interact to confidently select the best solutions. But now, huge, WWT has made it available
[01:11:20.500 --> 01:11:26.980]   to all of the members of its platform, you for free, hundreds of on demand and schedulable labs,
[01:11:26.980 --> 01:11:32.900]   representing the newest advances in multi cloud architecture and security, networking,
[01:11:32.900 --> 01:11:39.620]   primary and secondary storage data analytics, AI dev ops, you can test out, you can test out
[01:11:39.620 --> 01:11:45.300]   products and solutions at the ATC before you go to market, not just labs, technical articles,
[01:11:45.300 --> 01:11:50.340]   expert insights, demonstration videos, white papers, all the tools you need to stay up to date
[01:11:50.340 --> 01:11:56.660]   with the latest technology. Most recently, WWT's engineers and partners have been using the ATC
[01:11:56.660 --> 01:12:01.940]   to help customers confidently select the best solutions for enabling hybrid work.
[01:12:01.940 --> 01:12:08.660]   Something we're all facing now, a WWT.com you'll find valuable resources related to hybrid work
[01:12:08.660 --> 01:12:14.820]   technologies, office, hoteling, practical advice for reopening offices strategies for improving
[01:12:14.820 --> 01:12:22.260]   your digital workspace. We're all need this, this is a we are in a Terra incognita unknown lands
[01:12:22.260 --> 01:12:27.300]   right now, but WWT's been there and they can help. And when you're ready to dive deeper,
[01:12:27.300 --> 01:12:32.340]   you can launch on demand learning labs to gain hands on experience with specific technologies
[01:12:32.340 --> 01:12:39.620]   and develop your skillset in a risk-free environment. If you've got questions, WWT has all kinds of
[01:12:39.620 --> 01:12:44.580]   events where you'll hear directly from experts as they discuss solutions to common hybrid work
[01:12:44.580 --> 01:12:49.700]   challenges. If you want to learn more, there's all sorts of additional resources and demo videos
[01:12:49.700 --> 01:12:56.660]   and just it's amazing. There's so much to explore and it's all at wwwt.com. Create an account today.
[01:12:57.540 --> 01:13:02.900]   Follow hybrid work to stay up to date on the latest technologies, events, research, content,
[01:13:02.900 --> 01:13:10.500]   and more whatever your business need. WWT, worldwide tech, can deliver scalable, tried and tested,
[01:13:10.500 --> 01:13:16.900]   tailored solutions. Worldwide technology brings strategy and execution together to make a new
[01:13:16.900 --> 01:13:23.300]   world happen. And man, we are in a new world to learn more about WWT, the ATC to gain access
[01:13:23.300 --> 01:13:30.740]   to all those free resources. www.t.com/twit. Create a free account on the ATC platform.
[01:13:30.740 --> 01:13:38.420]   It's all there for you. www.t.com/twit. We thank you so much for supporting this week in tech.
[01:13:38.420 --> 01:13:46.820]   We get them very philosophical, very heady here. It's great. I love it. I love it. We have
[01:13:46.820 --> 01:13:51.220]   smart people on. It's great to talk about things that sometimes I think don't get talked about.
[01:13:51.940 --> 01:13:57.220]   You know? And they're so important to understanding what's going on. Otherwise, it's just chaos.
[01:13:57.220 --> 01:14:01.700]   It's all about the metaverse. We're really just living in the metaverse.
[01:14:01.700 --> 01:14:05.140]   I hope so. I can't wait. That's how it goes.
[01:14:05.140 --> 01:14:10.900]   As I've pointed out before, if you read about the metaverse in science fiction, invariably,
[01:14:10.900 --> 01:14:19.140]   I don't care if it's Neil Stevenson or William Gibson, it's to escape a dystopia, Ernie Klein.
[01:14:19.140 --> 01:14:27.460]   It's always to escape a horrific hellscape of real life. Give me them goggles. Let me slap them on.
[01:14:27.460 --> 01:14:34.020]   I was talking about... There was a story that came out last week. It was about the pope not
[01:14:34.020 --> 01:14:39.460]   wanting to go on the record, about a big, long, huge project they were doing in the metaverse. I was
[01:14:39.460 --> 01:14:46.580]   like, "Did you not read Snow Crash? This is literally the plot with Reverend Wayne's pearly gates."
[01:14:46.580 --> 01:14:51.620]   Oh my god. Who's Elba Brife? And this is Elsacharmark? Is it Elon?
[01:14:51.620 --> 01:14:57.140]   It's probably the main site for saying it. Father Robert Ballisare definitely involves...
[01:14:57.140 --> 01:15:03.140]   At least he's one of ours. Right? I would trust him. I would trust him.
[01:15:03.140 --> 01:15:09.780]   He talks about being... He says, "I can't talk about what we're working on right now."
[01:15:11.380 --> 01:15:16.420]   He's the digital Jesuit. He was called back. For those who don't know, he was a regular. He was
[01:15:16.420 --> 01:15:22.420]   one of our hosts called back to the Vatican some years ago. He was the guy who got the pope on Skype.
[01:15:22.420 --> 01:15:30.340]   He's a Jesuit, so as is the pope, and the Jesuits trust him, and I think he's their
[01:15:30.340 --> 01:15:38.260]   ambassador to the world of technology. I have to think Robert's fairly involved. And by the way,
[01:15:38.260 --> 01:15:44.660]   I should mention this Thursday, Robert's going to do a fireside chat on our club Twitch. So we're
[01:15:44.660 --> 01:15:50.500]   going to ask him. Aunt, you're going to ask him. Say, "Robert, are you working on the metaverse for
[01:15:50.500 --> 01:15:59.380]   Father, the Holy Father?" Father Robert Ballisare will be here at 9am. If you're a member of Club
[01:15:59.380 --> 01:16:05.460]   Twitch, you can watch, participate live, ask those questions. 9am Pacific, May 12th. Just one of
[01:16:05.460 --> 01:16:08.900]   many things that go on inside Club Twitch. If you're not yet a member, can I encourage you
[01:16:08.900 --> 01:16:16.340]   to join? It really helps us cover the bills, frankly. Seven bucks a month, not much to ask.
[01:16:16.340 --> 01:16:22.580]   You do get a lot of benefits. Add free versions of all the shows, because you're giving us money.
[01:16:22.580 --> 01:16:28.180]   We don't need to have advertisers. So that's nice. Access to the Discord, which is always great.
[01:16:28.180 --> 01:16:32.500]   There's lots of stuff going on in there. Events shows we don't put out on the feeds like the
[01:16:32.500 --> 01:16:37.700]   untitled Linux show that gives Fizz Stacey's book club. They're going to be doing Neil
[01:16:37.700 --> 01:16:43.140]   Stevenson's latest termination shock. They're so good. I can't wait to read it. I'm trying to
[01:16:43.140 --> 01:16:48.340]   read it before the it's big. It's thick. It's heavy. It's good. It's worth your time. I love Neil.
[01:16:48.340 --> 01:16:53.860]   So that's going to be the conversation on June 16th in about a month. You have a little time to read
[01:16:53.860 --> 01:17:01.380]   that. So much stuff going on, plus the Twitch plus feed, where stuff we talk about not in shows
[01:17:01.380 --> 01:17:07.700]   appears, plus those other shows. And every in the Discord, the Discord is incredible.
[01:17:07.700 --> 01:17:15.860]   Conversations about not just all the shows, but autos, coding, comics, ham radio and hardware and
[01:17:15.860 --> 01:17:26.180]   movies and music, sci-fi software, even sports and sport ball. That's the club twit Discord.
[01:17:26.180 --> 01:17:29.380]   Yeah. Nice. So it's moving well. That's awesome.
[01:17:29.380 --> 01:17:33.300]   Oh, yeah. I was here when you launched it and it looks like it's really we're very happy.
[01:17:33.300 --> 01:17:38.020]   For a bust. Yeah. That's awesome. I think it's become a great place to hang out.
[01:17:38.020 --> 01:17:43.700]   We're very happy with it. I realized Discord is a social network.
[01:17:43.700 --> 01:17:51.540]   Oh, yeah. It's really fantastic, actually. So $7 a month, twit.tv/club twit.
[01:17:51.540 --> 01:17:56.820]   Yeah. I think since, because we follow closely what you do, Alex and others,
[01:17:56.820 --> 01:18:02.500]   to kind of create a membership and we're trying to look at all the best practices and stuff.
[01:18:02.500 --> 01:18:07.380]   When we started, what was that a year ago now? Something like that.
[01:18:07.380 --> 01:18:14.260]   What is the history? Pretty soon, I think. We now have, I don't know, is it 4,000, 5,000
[01:18:14.260 --> 01:18:18.660]   members? The Discord itself is only about 3,000 people. Not everybody wants to join the Discord.
[01:18:18.660 --> 01:18:22.420]   But we're very, it's helped us a lot. 4,000 members, congratulations.
[01:18:22.420 --> 01:18:25.700]   Yeah. It's thank you. And thanks to our members. We really,
[01:18:26.580 --> 01:18:34.180]   we really appreciate it. All right. Let's talk. So before the show, I was talking about privacy and
[01:18:34.180 --> 01:18:41.860]   how I've changed my tune. For a long time, I worried that being absolutist about privacy was going to
[01:18:41.860 --> 01:18:49.700]   hurt the kinds of technologies, slow down development of technologies that would be fabulously useful.
[01:18:49.700 --> 01:18:56.260]   Things like Google Assistant, Siri, is Apple's privacy-forward version of that.
[01:18:56.260 --> 01:19:01.540]   Just not as good because it's privacy-forward. And for a long time, I thought, well, privacy,
[01:19:01.540 --> 01:19:07.460]   yeah, I mean, I understand the desire for privacy. But really, all of these tracking
[01:19:07.460 --> 01:19:15.940]   technologies are doing is targeting ads. What's the harm in that? Everybody makes a big deal
[01:19:15.940 --> 01:19:20.740]   about it. But you know, and people like Devark would say, well, just well, the insurance companies
[01:19:20.740 --> 01:19:25.460]   get a hold of it. And they deny you insurance because they know you went to Dunkin Donuts four
[01:19:25.460 --> 01:19:31.620]   times last week. Yeah, when that happens, you know, maybe there's a cause for concern. Well,
[01:19:31.620 --> 01:19:39.780]   it started to happen. So now I am a little more careful and a little less sanguine about privacy
[01:19:39.780 --> 01:19:45.540]   concerns. Here's the one that stopped me in my tracks. There's a data broker called Safegraft.
[01:19:45.540 --> 01:19:53.060]   Not a good name. Not an appropriate name. They were selling for 160 bucks because motherboards
[01:19:53.060 --> 01:20:00.340]   vice bought it. The data of everybody who visited a planned parenthood over a period of time.
[01:20:00.340 --> 01:20:07.380]   160 bucks, no warrant. Anybody could buy it. And now you immediately see the risk,
[01:20:07.380 --> 01:20:15.140]   especially in light of what may be the overturning of Roe v. Wade. That could be information that
[01:20:15.140 --> 01:20:25.380]   could put you in jail in Texas, for sure, and get you sued. Safegraft says, oh, whoops, we didn't
[01:20:25.380 --> 01:20:31.700]   mean to do that. And we're going to change it. Yeah, okay, fine. But these data brokers,
[01:20:31.700 --> 01:20:38.580]   you could see, you could start to see as as stories come out about law enforcement
[01:20:38.580 --> 01:20:43.620]   and others using these data brokers about people being docked. You know, there's a big story about
[01:20:43.620 --> 01:20:49.540]   how Apple, Google, Snap, and others had inadvertently given information to people
[01:20:49.540 --> 01:20:54.820]   posing as law enforcement. They didn't check because it was an emergency request. And said,
[01:20:54.820 --> 01:21:00.580]   yo, yo, yo, yo, it's an emergency. Here's a Brianna Wu's home address. We're starting to see the
[01:21:00.580 --> 01:21:06.900]   problem here. Your ob sec is probably very good by now, Brianna. I'm sure it is. I want to tell
[01:21:06.900 --> 01:21:11.940]   you, Leah, with my with my current job, we do a lot of ad targeting. We do work with a lot of
[01:21:11.940 --> 01:21:19.620]   these data brokers. And it's, I hesitate to use word dystopian, but it is very concerning just how
[01:21:19.620 --> 01:21:24.900]   much information they have and what they can do with it. Let me give you a specific example. If I
[01:21:24.900 --> 01:21:31.540]   want to, if I'm working in an election, and I want to target people that have, let's say, an issue of
[01:21:31.540 --> 01:21:39.620]   like, I don't know, a $15 minimum wage or let's say bankruptcy, right? I can actually go out there
[01:21:39.620 --> 01:21:46.500]   and request everyone. There's read an article on say, how to file for bankruptcy and their Google
[01:21:46.500 --> 01:21:54.260]   results. And then that will be tied to their unique ID identifier. And I can serve them ads on that
[01:21:54.260 --> 01:21:59.780]   across multiple networks. I mean, it is a truly staggering amount of information there. I've
[01:21:59.780 --> 01:22:05.620]   been saying for a long time, this needs to be regulated. And just one more point here, I didn't
[01:22:05.620 --> 01:22:10.900]   know this until I started running for Congress, I started talking to various people that
[01:22:10.900 --> 01:22:19.460]   were basically defendants, lawyers have worked defense cases. There's such an asymmetric power
[01:22:19.460 --> 01:22:25.860]   of discovery. And if the government was to pursue a case against you, in the information,
[01:22:25.860 --> 01:22:31.940]   they are able to subpoena and find we're talking nest cams, where your Google account has been.
[01:22:32.820 --> 01:22:37.860]   Basically, they can just keep collating all this data until they find something that is
[01:22:37.860 --> 01:22:43.700]   basically builds the case that they want. Oftentimes, the choosing data is incomplete or
[01:22:43.700 --> 01:22:47.460]   may give them an incorrect picture of the situation.
[01:22:47.460 --> 01:22:52.740]   But might be very compelling to a jury because it's technology. And well, we know how good that is.
[01:22:52.740 --> 01:22:59.540]   Really good example. There was a guy that had someone else's phone with them in his bag,
[01:22:59.540 --> 01:23:05.860]   and he ended up being put on the location of a murder scene in New York. That was very
[01:23:05.860 --> 01:23:11.540]   compelling evidence. And you don't have that same power discovery to prove that you aren't there.
[01:23:11.540 --> 01:23:17.060]   So this is a very important issue. And a lot of people are finally saying this.
[01:23:17.060 --> 01:23:22.980]   I'm sure this is your finally Alex saying, well, finally Leo, you finally came around,
[01:23:22.980 --> 01:23:24.500]   took you a long enough.
[01:23:24.500 --> 01:23:26.260]   Yeah. Okay. I mean,
[01:23:27.380 --> 01:23:30.980]   it's interesting because I am sympathetic with your view. Like I do think or your previous
[01:23:30.980 --> 01:23:34.980]   you, I do think that like a lot of times data can actually be useful for us,
[01:23:34.980 --> 01:23:40.100]   especially when it comes to target advertising. Like I would rather have better ads than worse ads.
[01:23:40.100 --> 01:23:44.340]   And I think that like many things on the internet, the discussion of privacy has become
[01:23:44.340 --> 01:23:49.060]   flattened and polarized. Whereas it's an extremely nuanced conversation,
[01:23:49.060 --> 01:23:53.940]   where we should say, you know, I don't think you can say it's good or evil. I can say there are,
[01:23:53.940 --> 01:23:58.340]   I would say there are useful and destructive purposes. And do we have the attention span
[01:23:58.340 --> 01:24:03.460]   to talk about some of the, you know, useful and destructive purposes and actually push us
[01:24:03.460 --> 01:24:08.180]   towards a better internet versus having to be all in or all out, you know, on when we are the
[01:24:08.180 --> 01:24:12.020]   other. And I feel like we've always had good discussions about it here, you know, on Twitter.
[01:24:12.020 --> 01:24:17.140]   And I think that this is, yes, yet another data point where we look and, you know, we found more
[01:24:17.140 --> 01:24:21.300]   stuff that we need to be skeptical about. But, you know, I'm going to go back to a point I made
[01:24:21.300 --> 01:24:27.380]   earlier, which is that we're in the like first inning of the internet. I mean, so early on,
[01:24:27.380 --> 01:24:31.700]   and this is like our opportunity to determine what the direction we're going in is going to be.
[01:24:31.700 --> 01:24:40.180]   And, you know, I think that like, if we can find the wherewithal to concentrate on these cases,
[01:24:40.180 --> 01:24:45.460]   we're actually going to be in a much better place than if we go all the way on one side and say
[01:24:45.460 --> 01:24:50.580]   privacy is good, you know, or all the way on the other side and say, you know, you know, it's bad.
[01:24:50.580 --> 01:24:55.220]   Like there's there's nuance here. But these cases that you're bringing up, I mean, are extremely,
[01:24:55.220 --> 01:25:00.980]   you know, concerning and alarming and stuff that we do need to get start to get dealing with.
[01:25:00.980 --> 01:25:06.340]   Here's one I have mixed feelings about. Also from motherboard advice, the CDC
[01:25:06.340 --> 01:25:15.700]   tracked millions of phones to see if Americans followed COVID lockdown orders. New documents
[01:25:15.700 --> 01:25:21.780]   from the CDC show that they bought access to location data again from these brokers harvested
[01:25:21.780 --> 01:25:27.860]   from tens of millions of phones. I mean, in this case, I think there's a real benefit for public
[01:25:27.860 --> 01:25:34.820]   health benefit. They were now, you know, they were analyzing in aggregate. You know, they didn't care
[01:25:34.820 --> 01:25:40.340]   about what you or I did. They wanted the massive people. They tracked patterns of people visiting
[01:25:40.340 --> 01:25:46.020]   K through 12 schools. They specifically monitored the effectiveness of policy in the Navajo nation.
[01:25:46.020 --> 01:25:51.540]   Good or bad?
[01:25:51.540 --> 01:25:58.980]   I think I read that and I'm like, okay, I can see what they're doing is a study about this to
[01:25:58.980 --> 01:26:04.260]   understand the effect of the policy that they are bringing up. And then you can see how it's
[01:26:04.260 --> 01:26:09.380]   going to be weaponized and turned it into another stupid left versus right screaming match, which is
[01:26:10.180 --> 01:26:17.620]   very concerning, obviously. Yeah, to come back to your point, Alex, I don't think that we need
[01:26:17.620 --> 01:26:24.180]   more conversations about this. What I think we need is smarter regulators who are actually
[01:26:24.180 --> 01:26:28.980]   interested in thinking about these policies and coming to better decisions on this.
[01:26:28.980 --> 01:26:33.780]   Doesn't ultimately matter what you and I say. There's going to, if it's legal, there's going to be a
[01:26:33.780 --> 01:26:38.020]   market for it and they're going to care about making money more than doing the right thing,
[01:26:38.020 --> 01:26:45.380]   as I think our current situation shows. So I think I just feel like there's no path forward.
[01:26:45.380 --> 01:26:50.580]   I have confidence in where Congress is going to get really interested in regulating
[01:26:50.580 --> 01:26:56.100]   ad tech to make sure it's not abused in these situations, unfortunately.
[01:26:56.100 --> 01:27:01.220]   Well, I mean, yeah, look, I think that like, it's not exactly what I say. I think the
[01:27:01.220 --> 01:27:06.100]   regulations always downstream of the conversations that experts have. And I hope that when we have
[01:27:06.660 --> 01:27:11.060]   if regulators are interested in this and I know they are, then they should also have nuanced
[01:27:11.060 --> 01:27:14.340]   conversations about it. But what I'm trying to say is,
[01:27:14.340 --> 01:27:19.380]   painting with the broad brush isn't going to do anyone any good, because there's plenty of
[01:27:19.380 --> 01:27:24.820]   details here that need to be addressed. And if we're going to go in and say, it's exactly the
[01:27:24.820 --> 01:27:28.580]   problem, going in and say, they need to be regulated, they don't need to be regulated,
[01:27:28.580 --> 01:27:31.860]   it sort of gets us back to a place where we're not making smart policy.
[01:27:31.860 --> 01:27:36.420]   So I'm going to, I'll stand here on the table and scream for nuanced conversations,
[01:27:36.420 --> 01:27:41.140]   you know, places like this and the public forum and then eventually when it gets there
[01:27:41.140 --> 01:27:43.620]   in Congress and in the halls of government regulators as well.
[01:27:43.620 --> 01:27:49.700]   Interesting sign note on this, by the way, Vice got this information from a Freedom of Information
[01:27:49.700 --> 01:27:59.620]   Act. CDC paid a data broker, guess who? Safegraft, $420,000 for access to a year of data.
[01:28:00.180 --> 01:28:04.740]   Safegraft's investors include Peter Thiel, the former head of Saudi Intelligence.
[01:28:04.740 --> 01:28:09.620]   Google was so concerned about Safegraft, they banned the company's apps from the
[01:28:09.620 --> 01:28:21.540]   play store in June. Unsafe graph. Unsafe. Unsafe graph. But again, I mean, I think the
[01:28:21.540 --> 01:28:28.420]   National Health Agency, the CDC, probably has a real interest, a public interest in
[01:28:28.420 --> 01:28:34.420]   finding out some general patterns on how people are behaving in pandemic.
[01:28:34.420 --> 01:28:44.260]   Although if you look at the list of potential use cases at the CDC listed, there's quite a few of them,
[01:28:44.260 --> 01:28:49.620]   quite a few of them, and some of them you might feel a little funny about. I think we do need to
[01:28:49.620 --> 01:28:54.660]   talk about this. Unfortunately, I don't really trust Congress to do anything sensible
[01:28:56.020 --> 01:29:02.340]   about any of this. So you use data brokers, which is interesting to me, Brianna. So you clearly,
[01:29:02.340 --> 01:29:05.700]   you have a use case that you feel is good and justified.
[01:29:05.700 --> 01:29:14.260]   So here, I just got done working in an election last week, right? Our candidate was very strongly
[01:29:14.260 --> 01:29:22.980]   advocating a $15 minimum wage, right? We targeted that ad at people that made under $60,000 a year,
[01:29:22.980 --> 01:29:29.620]   right? And we're part of the party that we were representing and we're registered voters, right?
[01:29:29.620 --> 01:29:35.540]   Those are some subgroups. And I think I would argue that an ethical use of all this data is,
[01:29:35.540 --> 01:29:41.220]   look, if there's a politician that's going to represent a policy that you believe in,
[01:29:41.220 --> 01:29:46.660]   I don't think it's really problematic for me to find that out and then show you information
[01:29:46.660 --> 01:29:51.940]   that will get you out to vote, right? What I am saying, and this is coming back to your
[01:29:51.940 --> 01:29:58.820]   newest conversation, Alex, is that when you really dig down deep in how they get those ad identifiers
[01:29:58.820 --> 01:30:05.300]   and how they figure out who is interested in what it's in some really creepy ways. And I think
[01:30:05.300 --> 01:30:09.940]   there's, I think we don't really have consent about all the ways we are being tracked around
[01:30:09.940 --> 01:30:17.860]   the internet. Just one last thing. I am pretty paranoid, I would say, in the amount of information
[01:30:17.860 --> 01:30:24.180]   I give up as I go around the internet. And I've looked at my own file there, and it's frightening
[01:30:24.180 --> 01:30:29.140]   the amount of information that's there, particularly with news sites and articles that I read that
[01:30:29.140 --> 01:30:33.940]   they end up having information about. So it's very tempting just to give up, isn't it?
[01:30:33.940 --> 01:30:36.500]   Yeah, it really is, to be honest. What are you going to do?
[01:30:36.500 --> 01:30:42.340]   So the CDC shouldn't be asking for any data because those people couldn't tie their
[01:30:42.340 --> 01:30:46.340]   shoes right during this. Yeah, well, that's, yeah, there's other recommendations they're
[01:30:46.340 --> 01:30:50.660]   giving, like, come on. Yeah, focus on the health stuff first and go get the data.
[01:30:50.660 --> 01:30:57.220]   Low public service announcement. So there has been for a long time, most of the browsers,
[01:30:57.220 --> 01:31:03.140]   except notably Google Chrome have had a setting called Do Not Track. Google says we don't do it
[01:31:03.140 --> 01:31:07.780]   because it doesn't do anything. And in fact, they're right. Do Not Track is a suggestion.
[01:31:09.540 --> 01:31:17.460]   And most, in fact, as far as I know, all sites ignore Do Not Track. Well, thanks to GDPR and the
[01:31:17.460 --> 01:31:25.940]   California Consumer Privacy, XCCPA, there is a new sheriff in town, which has some, this time,
[01:31:25.940 --> 01:31:33.140]   some real teeth. Global privacy control is part of GDPR. You may or may not know, but
[01:31:34.660 --> 01:31:40.580]   in GDPR, the fines can be as much as 10% of global revenue. They can be a serious,
[01:31:40.580 --> 01:31:45.220]   much more serious, publishment, punishment. That was a problem with Do Not Track. There was no
[01:31:45.220 --> 01:31:57.540]   consequence. CCPA and GDPR are giving us a new tool. And right now, this is available in Firefox
[01:31:57.540 --> 01:32:02.900]   with 100, which just came out. You can see I'm at a website called globalprivacycontrol.org.
[01:32:02.900 --> 01:32:09.140]   And you can see at the very top, I've got a little red light saying the GPC signal is not detected.
[01:32:09.140 --> 01:32:15.780]   Please download a browser extension that supports it. There are extensions. Steve Gibson talked
[01:32:15.780 --> 01:32:20.740]   about this on Wednesday on security. Now there are extensions you can add. I don't know if you can
[01:32:20.740 --> 01:32:26.260]   add it to Chrome to Safari, I believe an edge that will turn it on. But if you are lucky enough to
[01:32:26.260 --> 01:32:33.700]   be using Firefox, there's a good reason to use Firefox. You can type about colon config in Firefox.
[01:32:33.700 --> 01:32:38.340]   And that will warn you, "Yo, this is risky. You're going to do advanced configuration.
[01:32:38.340 --> 01:32:42.980]   Are you sure you know how to?" And then there's a search box at the top. Let me,
[01:32:42.980 --> 01:32:49.220]   okay, I'm in full screen. You can barely see this, but I'm going to type global privacy.
[01:32:50.020 --> 01:32:56.340]   One word. And I'll see before I finish two settings, privacy, global privacy control enabled,
[01:32:56.340 --> 01:33:02.260]   and privacy, global privacy control functionality enabled. They are both false by default. But
[01:33:02.260 --> 01:33:09.140]   if you click that double-hair-headed arrow, you can turn them to true. And now you've made
[01:33:09.140 --> 01:33:16.820]   Firefox any site you visit say, "I want global privacy. Now if I go to the globalprivacycontrol.org,
[01:33:16.820 --> 01:33:22.100]   it can see the signal." And you can go further if you want. You can test it against the reference
[01:33:22.100 --> 01:33:30.900]   server and see what's going on. I at least have some hope that this will be honored
[01:33:30.900 --> 01:33:37.940]   by websites. It is never going to be available in Chrome. It's pretty clear Google has no
[01:33:37.940 --> 01:33:44.100]   interest in global privacy of any kind. But at least in Firefox you can do this. And I think it's
[01:33:44.100 --> 01:33:47.700]   worth turning that on. It's a little public service announcement there.
[01:33:47.700 --> 01:33:53.620]   Yeah, it's so hard because Chrome is such a great product. But just for exactly the reason
[01:33:53.620 --> 01:34:00.100]   you just said, "Lio, I have no faith in any of the abstracting stuff on there." And sadly,
[01:34:00.100 --> 01:34:04.660]   I'm willing to sacrifice RAM and speed for privacy on my machine.
[01:34:04.660 --> 01:34:10.900]   I'm just going to say try Firefox. It's great. And the other reason I use Firefox
[01:34:10.900 --> 01:34:16.340]   is we're rapidly getting into a monoculture where we only have Chrome and Chrome derivatives. Edge
[01:34:16.340 --> 01:34:21.940]   is Chrome, Brave is Chrome, Vovaldi is Chrome. A lot of these browsers are de-googled,
[01:34:21.940 --> 01:34:28.180]   Chromium is Chrome. But there's still the Chrome engine. And regardless of how you feel about privacy,
[01:34:28.180 --> 01:34:34.180]   I don't think it's a healthy ecosystem for all the web to be dominated by one browser engine.
[01:34:34.180 --> 01:34:40.820]   It makes it easier for developers, I guess. And Firefox's usage numbers are tumbling now.
[01:34:41.380 --> 01:34:46.260]   I want to keep it alive. So I use it on all my machines. And it's a great browser.
[01:34:46.260 --> 01:34:50.420]   Highly recommending. It also containerizes Facebook. That's right.
[01:34:50.420 --> 01:34:58.740]   Yeah. And that's another good reason to use it. Whenever you go to say with a Facebook
[01:34:58.740 --> 01:35:04.100]   like button, you're sending a signal back to Facebook unless you're using Firefox and you can
[01:35:04.100 --> 01:35:11.220]   turn that on. And it will lock that. I have come completely around on this. I feel like,
[01:35:11.220 --> 01:35:20.420]   all right, especially government agencies have now shown a willingness to impinge on our privacy
[01:35:20.420 --> 01:35:26.180]   for their own gains. And it's too bad. Got a new guy here. I know.
[01:35:26.180 --> 01:35:31.620]   But I'm with you, Alex. I don't want to be privacy absolutist. It is new.
[01:35:31.620 --> 01:35:35.460]   That's the thing. Yeah. And I think that like you're from what I understand, like, you know,
[01:35:35.460 --> 01:35:40.100]   having spoken with you about this over the years, your standpoint has basically been like,
[01:35:40.100 --> 01:35:46.580]   it's almost as if the conversation went too far to one end and you're like a little sanity here.
[01:35:46.580 --> 01:35:50.340]   And now we're starting to see, okay, actually, now people are abusing and you're like a little
[01:35:50.340 --> 01:35:54.660]   sanity here. So I think your position has actually been consistent. It's about, you know,
[01:35:54.660 --> 01:35:58.340]   trying to rein in some of the polls on both sides, which I find valiant.
[01:35:59.380 --> 01:36:05.940]   Vallettes and quicksatic foolish. I just trying to understand the period of tech history where we
[01:36:05.940 --> 01:36:14.500]   went overboard on privacy, implementation and made users so safe that it made the product worse.
[01:36:14.500 --> 01:36:18.580]   And I just can't think of what that would have been. Yeah. I'm not saying implementation. I'm
[01:36:18.580 --> 01:36:23.940]   just saying that like there was a moment where the conversation, you know, became scaremongering
[01:36:23.940 --> 01:36:28.500]   and, you know, sort of lost credibility because it was being held by people who didn't have a
[01:36:28.500 --> 01:36:34.180]   full understanding of the technology and was proposing solutions that just were, you know,
[01:36:34.180 --> 01:36:39.060]   weren't going to be effective. And as I'm saying, I want those conversations to be drawn back to
[01:36:39.060 --> 01:36:42.980]   a place where we actually can have solutions we can implement that will work, you know,
[01:36:42.980 --> 01:36:49.140]   versus people like giving TED talks and selling books, you know, based off of, you know, ideas
[01:36:49.140 --> 01:36:52.820]   that sound really nice and when addressed in public, but are, you know, can be extreme and
[01:36:52.820 --> 01:36:57.140]   difficult to actually put into put into practice. And I'm just enough of a utopian,
[01:36:57.700 --> 01:37:05.940]   utopianist to think that there are some really amazing things, you know, that can be done
[01:37:05.940 --> 01:37:11.940]   with the information, the data stream that comes off of me, that would be very useful to me.
[01:37:11.940 --> 01:37:20.340]   And so in a way, what I really want to advocate for is tight controls on what can be done with
[01:37:20.340 --> 01:37:26.660]   that data so that I want to be able to give Google my data and not have it automatically be sent
[01:37:26.660 --> 01:37:34.740]   to somebody like Safegraft for use against me in a court of law. But I want it to be used by Google
[01:37:34.740 --> 01:37:40.900]   to give me valuable insights into, you know, or just simply to pop up my plane ticket when I
[01:37:40.900 --> 01:37:46.020]   arrive at the airport. Those are useful things. You may say those are such toys that I should
[01:37:46.020 --> 01:37:50.660]   probably give those up in favor of better privacy. And maybe I'm going to have to. But I think if
[01:37:50.660 --> 01:37:56.260]   you control it, if we control what they can do with it, then there are some real benefits to
[01:37:56.260 --> 01:38:00.580]   be gained by giving them that information. We just have to get to a point where we can trust them
[01:38:00.580 --> 01:38:05.140]   with it. I don't, you know, even Apple, I'm not sure I can completely trust Apple with that
[01:38:05.140 --> 01:38:08.740]   information. Maybe that for some people, that's the solution. Just use an iPhone.
[01:38:08.740 --> 01:38:14.660]   No, I think that's I think that's silly. If you think Apple's going to protect you from everything,
[01:38:14.660 --> 01:38:21.380]   I think another under discussed thing we're not talking about is as cars really become more
[01:38:21.380 --> 01:38:27.860]   always on internet appliances. You know, there's a there's a real risk of this this information,
[01:38:27.860 --> 01:38:32.260]   like let's say you drove to an abortion clinic, right? Absolutely. That if your car
[01:38:32.260 --> 01:38:39.860]   tests, you know, Tesla test, it records everywhere you go. One of my one of my newer cars, it has
[01:38:39.860 --> 01:38:47.220]   GPS built into it. It's used as like a subscription thing you can use to find out, you know, is someone
[01:38:47.220 --> 01:38:52.660]   speeding while they're driving it or where it's parked if it was stolen, right? But the downside
[01:38:52.660 --> 01:38:58.660]   to that is like, do I really believe that Porsche who hasn't updated their iPhone app since like
[01:38:58.660 --> 01:39:06.660]   the last 10 years? Do I really believe they've got top notch info sec team stopping those
[01:39:06.660 --> 01:39:12.020]   the servers from being hacked? Do I really, really believe Porsche is going to put up a real fight
[01:39:12.020 --> 01:39:17.780]   if the United States government starts subpoenaing them to find out where their users have been
[01:39:17.780 --> 01:39:22.740]   driving to? I have no faith in any of that. And I think that's why we need support regulation.
[01:39:22.740 --> 01:39:30.340]   Yeah. Yeah, completely agree. And it may be there is a technological solution. Somebody in the
[01:39:30.340 --> 01:39:36.420]   chat rooms reminding us about Tim Berners Lee, the solid foundation. This was a goal and still
[01:39:36.420 --> 01:39:41.300]   around as far as I know, the creator of the worldwide web wanted to create a system where you would
[01:39:41.860 --> 01:39:47.620]   kind of silo your personal information and control what happens to it and offer it,
[01:39:47.620 --> 01:39:54.100]   you know, intentionally to people who could use it appropriately, but maintain control of it.
[01:39:54.100 --> 01:39:58.260]   And I think it's a very good idea. We'll see if it happens. But I think there might be
[01:39:58.260 --> 01:40:03.300]   technological solutions. I might have higher hopes for that than in the regulatory solutions.
[01:40:03.300 --> 01:40:08.180]   Yeah, I think that's fair. Yeah. Although I am turning on that global privacy control for sure.
[01:40:09.700 --> 01:40:15.380]   I definitely, I definitely want that on. It's weird because like the best solutions are often like,
[01:40:15.380 --> 01:40:20.980]   you know, let people control and then let them make money on their data. Yeah, but those are just
[01:40:20.980 --> 01:40:24.740]   kind of, I mean, it's possible that that's where we end up getting to. But those can be
[01:40:24.740 --> 01:40:28.580]   tough to actually give people a strong enough return that they're going to be able to
[01:40:28.580 --> 01:40:34.980]   want to put the time in to do it. Yeah. Take a little tiny break more to come in just a bit
[01:40:34.980 --> 01:40:40.740]   with our great panel Alex Cantor, it's host of the big technology podcast. I'm going to definitely
[01:40:40.740 --> 01:40:46.100]   listen next week, or I guess it's going to be fun. I can't wait. Can't we're going to get into it.
[01:40:46.100 --> 01:40:52.180]   Yeah, your brain and FT. Do you have a format for debate or is it just a, you know, you back
[01:40:52.180 --> 01:40:58.420]   and forth or how do you do that? Yes. The format is no holds barred. Oh, God, it's the cage match.
[01:40:58.420 --> 01:41:03.220]   Where anything goes. That's right. But it is. It's going to definitely be
[01:41:03.860 --> 01:41:10.100]   full on podcast combat. It'll be fun. Oh, I can't wait. Just search for big technology podcast,
[01:41:10.100 --> 01:41:17.540]   wherever you get your podcasts. Yes. That's right. Okay. Brianna Wu, who also does her share of
[01:41:17.540 --> 01:41:25.060]   podcasts, including the fabulous rocket with Christina and Simone, Simone DeRosh four and
[01:41:25.060 --> 01:41:30.340]   Christina Warren, congratulate Christina. I'm sure you have are being featured by NPR.
[01:41:31.140 --> 01:41:36.500]   Oh my gosh. Yeah. I'm worried it's going to fuel her bad spending habits already. If you know,
[01:41:36.500 --> 01:41:43.060]   Christina Shittle waste money on anything. She was featured in NPR for her penchant to buy up
[01:41:43.060 --> 01:41:49.700]   dead tech company merch, like Theranos stuff. And here she is wearing a movie past T-shirt in the
[01:41:49.700 --> 01:41:57.780]   empirical. She has CNN plus pop socket. She said the Holy Grail was a her ther was Theranos. Any
[01:41:57.780 --> 01:42:04.420]   Theranos merchandise. And I've seen some Theranos merchandise like pens, very expensive. So you're
[01:42:04.420 --> 01:42:08.820]   right. You're working on that. I told her I'd go halfies with her. If she wants some pens, then
[01:42:08.820 --> 01:42:14.340]   yes, she can have three of them. I'd take two. Here she is with her fire festival T-shirt.
[01:42:14.340 --> 01:42:21.780]   This is what I love about rocket. We're a series show that we cover the really big stories.
[01:42:21.780 --> 01:42:29.300]   But the other half of is just ridiculous stuff like fire fest and Theranos. And we're really
[01:42:29.300 --> 01:42:40.340]   good mix of silly and serious relay dot FM slash rocket. And it is definitely two great shows,
[01:42:40.340 --> 01:42:46.340]   big technology podcast and rocket from our two great contributors are show today brought to you by
[01:42:46.900 --> 01:42:53.860]   Mint Mobile. Oh, I love my Mint Mobile, man. I spend as you might imagine a lot of money on
[01:42:53.860 --> 01:43:00.340]   cell phone service. You know, as an occupational hazard, I have Verizon Sprint T Sprint and T
[01:43:00.340 --> 01:43:04.420]   Mobile are kind of merging. That's been an interesting experience, by the way. I'll tell you that story.
[01:43:04.420 --> 01:43:10.820]   And AT&T, I have all the big three because I'm keeping an eye on all three. But I'll tell you what,
[01:43:10.820 --> 01:43:16.500]   when it's my money to spend, I got Mint Mobile. If it's your money you're spending,
[01:43:16.500 --> 01:43:25.460]   you'll want Mint Mobile, the best wireless carrier. $15 a month gives you an incredible deal,
[01:43:25.460 --> 01:43:30.420]   unlimited nationwide talk and text and plenty of data. You can buy more if you need it, but
[01:43:30.420 --> 01:43:36.500]   four gigs of data a month, I think for 15 bucks is a that's all in 15 bucks. Now they have a new
[01:43:36.500 --> 01:43:42.820]   family plan. And this is awesome. They call it the modern family plan. You'll only need two lines
[01:43:42.820 --> 01:43:50.420]   to get started. Mint Mobile is amazing. They basically got rid of the stores and saved enough money
[01:43:50.420 --> 01:43:56.420]   that they were able to give you wireless just 15 bucks a month. And now with the family plan,
[01:43:56.420 --> 01:44:01.940]   you're getting even more all plans will come with unlimited talk and text, high speed data on the
[01:44:01.940 --> 01:44:09.540]   nation's largest 5G network. The family plan lets you mix and match data plans. So it's like
[01:44:09.540 --> 01:44:14.660]   Goldilocks and the three bears. You can get it just right for whoever you are in the family.
[01:44:14.660 --> 01:44:20.180]   Pop a bear, mom a bear, a baby bear. Everybody gets the right amount of data for them. You can
[01:44:20.180 --> 01:44:25.460]   use your own phone, bring your own phone. They will send you a sim for free. They'll port your
[01:44:25.460 --> 01:44:30.340]   number over so your number doesn't change. Or you can buy a phone from the fact I've got an
[01:44:30.340 --> 01:44:36.100]   iPhone SE, I love my iPhone SE from Mint Mobile. To get your new wireless plan, take a look at the
[01:44:36.100 --> 01:44:41.940]   family plan if you've got two or more lines. Or just for yourself, 15 bucks a month, including the
[01:44:41.940 --> 01:44:51.220]   modern family plan, mintmobile.com/twit. It's minty fresh. They'll even send you the plan, the sim
[01:44:51.220 --> 01:44:59.780]   card and everything for free. Mintmobile.com/twit. It's time to shake up the wireless industry. And
[01:44:59.780 --> 01:45:05.220]   I'll tell you what, when it comes to spending my own money, that's where I go. Mintmobile.com/twit.
[01:45:05.220 --> 01:45:12.740]   Cut your wireless, build the 15 bucks a month. It's like a quarter of what I spent with these
[01:45:12.740 --> 01:45:22.580]   other guys. It's amazing for the same service. Let's see here, moving right along down the run
[01:45:22.580 --> 01:45:30.180]   down. Google I/O is coming up this week. Google's developer conference. We're going to do a live
[01:45:30.180 --> 01:45:37.460]   coverage of the keynote 10 a.m. on Wednesday. Jeff Jarvis will join me and Jason Howell as we cover
[01:45:37.460 --> 01:45:43.300]   the keynote. We don't know how long it'll be. This is sort of a semi return to normal. They're
[01:45:43.300 --> 01:45:48.260]   going to have an audience, but it will be mostly Google employees and I think some lucky journalists.
[01:45:48.260 --> 01:45:53.380]   We don't know what they're going to announce, but there seems to be some consensus they will
[01:45:53.380 --> 01:46:01.300]   announce some things including a pixel watch. Google has never made a watch. They've they've
[01:46:01.300 --> 01:46:07.620]   bought. Yeah, they've offered Android Wear for some time. Other companies have made it like
[01:46:07.620 --> 01:46:17.060]   Motorola and Fossil. This is in the middle comparing it to the Galaxy 4 Classic and the iPhone on the
[01:46:17.060 --> 01:46:22.980]   left in the middle is the Google Watch minus a band. This is the Google Watch that was found.
[01:46:22.980 --> 01:46:28.020]   See, I'm a little suspicious. I think Google planted it personally because they wanted the
[01:46:28.020 --> 01:46:33.380]   attention. But we know a lot about the watch now because this one was left behind in a bar or
[01:46:33.380 --> 01:46:41.220]   somewhere. Kind of like the iPhone 4. According to 9 to 5, Google cellular version will be wearable.
[01:46:41.220 --> 01:46:47.700]   I'm sorry with 300 milliamp hour battery, so they'll be both cellular and noncellular.
[01:46:47.700 --> 01:46:54.020]   It's going to be pretty and round. I like how it looks with detachable, interchangeable bands.
[01:46:54.020 --> 01:46:56.740]   Kind of like the Apple Watch.
[01:46:56.740 --> 01:47:09.140]   I think we've got numb to just how how do I say this badly designed a UI. The Apple Watch is.
[01:47:09.140 --> 01:47:16.580]   I didn't really understand this. It's terrible until I did. Twitter Blue did a survey thing where
[01:47:16.580 --> 01:47:22.500]   they wanted to ask users about if it was actually good or not. I'm like, sure, I'll do that. I'll
[01:47:22.500 --> 01:47:27.220]   show up. I'll participate in that. I used the money I got from that to buy Frank an Apple Watch.
[01:47:27.220 --> 01:47:33.460]   My husband is just not good with technologies. He's a PhD in that bacterial genetics. Smart
[01:47:33.460 --> 01:47:38.820]   guy worked on the coronavirus vaccine, but he does not understand technology at all.
[01:47:38.820 --> 01:47:47.700]   Watching him struggle to use this interface really made me go. There's a lot of potential here in
[01:47:47.700 --> 01:47:54.980]   the market for something like this that's actually usable for normal people. Just figuring out
[01:47:54.980 --> 01:48:00.580]   your messages. Push the button on the bottom, scroll down until you hit the right out,
[01:48:00.580 --> 01:48:03.300]   tap on it, wait for it to load. It's terrible.
[01:48:06.580 --> 01:48:11.140]   Can Google do a better job? Part of the problem is the screen is teensy-weensy. I don't know how
[01:48:11.140 --> 01:48:17.060]   you make a good UI on that screen. Samsung's done a pretty good job. Their bezel turns.
[01:48:17.060 --> 01:48:25.860]   The foundation for the operating system to see notifications on the Samsung Watch, you turn the
[01:48:25.860 --> 01:48:30.900]   bezel counterclockwise and it scrolls to the left. You turn it clockwise, it shows you apps on the
[01:48:30.900 --> 01:48:37.700]   right. It's a pretty intuitive thing. I really like it, but Apple does not do that. The only
[01:48:37.700 --> 01:48:42.420]   time I touch the watch is to unlock it. To do Apple Pay, I do do Apple Pay.
[01:48:42.420 --> 01:48:45.860]   Apparently Apple thinks I'm exercising right now, which is...
[01:48:45.860 --> 01:48:48.580]   That's another...
[01:48:48.580 --> 01:48:50.820]   Because what happens in the home stretch of the pod...
[01:48:50.820 --> 01:48:52.980]   Yeah, suddenly it feels like you're exercising.
[01:48:52.980 --> 01:48:59.780]   I just understand, okay, so I had to watch for a bit. Never really caught on with me.
[01:49:00.420 --> 01:49:02.980]   Can't your phone just do everything like, "Why do you like to watch the Lido?"
[01:49:02.980 --> 01:49:07.780]   It can and it can't. I mean, I could, on my phone, open up Apple Pay,
[01:49:07.780 --> 01:49:13.300]   tap the phone. It's a lot easier just to double-tap the button and go like this with the watch.
[01:49:13.300 --> 01:49:15.300]   The exercise features...
[01:49:15.300 --> 01:49:16.900]   They're pretty good.
[01:49:16.900 --> 01:49:22.660]   Yeah, I'm not going to carry a phone while I'm exercising, but before I go on a walk or before
[01:49:22.660 --> 01:49:28.820]   I go to work with my trainer, I will choose the appropriate workout and it monitors that,
[01:49:28.820 --> 01:49:30.820]   keeps track of that. Is that beneficial?
[01:49:30.820 --> 01:49:38.260]   It's the gamification of exercise. It's probably some value to me. A lot of people pay attention
[01:49:38.260 --> 01:49:43.380]   to their rings. We've seen some life-saving benefits in the Apple Watch. It will notify you
[01:49:43.380 --> 01:49:48.100]   if your heart rate is abnormally high, especially if you're not doing anything.
[01:49:48.100 --> 01:49:57.780]   I was just at a concert and it will monitor the audio level and warn you if it's above 90 decibels
[01:49:57.780 --> 01:50:03.300]   and can risk your hearing. Things like that are kind of cool.
[01:50:03.300 --> 01:50:05.300]   I think the fact that it's gone...
[01:50:05.300 --> 01:50:10.740]   I use the exercise features religiously. I never leave the house with that my Apple Watch.
[01:50:10.740 --> 01:50:18.740]   It's my favorite thing to use just because I love to work out. I'm for whatever reason,
[01:50:18.740 --> 01:50:24.820]   I'm very, very susceptible to the gamification of working out. Peloton has a new product,
[01:50:24.820 --> 01:50:29.940]   the Peloton Guide, which is a weight product that I love because it's the exact same thing.
[01:50:29.940 --> 01:50:32.420]   Can you fill up the meter as you're doing weight training?
[01:50:32.420 --> 01:50:41.860]   I feel like I'm such a freaking niche case for it. I don't think normal people
[01:50:41.860 --> 01:50:48.260]   want to make sure that they've burned X number of calories a day to remind them to do a second
[01:50:48.260 --> 01:50:51.140]   workout. I just don't think that's what normal people do.
[01:50:52.420 --> 01:50:56.580]   But the fact that it's gone health is probably helpful to Google's kids because Apple initially
[01:50:56.580 --> 01:51:00.900]   was reading Tripp Mickel's book after Steve recently. He talks about it.
[01:51:00.900 --> 01:51:05.140]   And Apple initially wanted it to be a fashion accessory. If it remained a fashion accessory,
[01:51:05.140 --> 01:51:10.660]   Google's screwed. But the fact that it's gone from fashion to health, I think puts Google in a
[01:51:10.660 --> 01:51:14.900]   position to actually start to compete with Apple. Are you saying that Google can't do fashion?
[01:51:14.900 --> 01:51:20.740]   Yes. I think you're exactly right.
[01:51:20.740 --> 01:51:28.260]   For the last wearable they did, I'll give you a hint. You wore it on your face.
[01:51:28.260 --> 01:51:32.420]   Oh, God, the Google blast. Oh, yeah. You're right. Oh, yeah.
[01:51:32.420 --> 01:51:41.060]   We called it the Nerds Contraceptive Device because you're never going to get a date
[01:51:41.060 --> 01:51:45.940]   when you're wearing that. Yeah, Google is kind of the classic,
[01:51:45.940 --> 01:51:52.020]   wash your hair with soap kind of engineering type, right? And you look, if it works, it works.
[01:51:52.020 --> 01:52:00.980]   Apple pushes this idea that their Apple Watch is super fashionable. And it's just not.
[01:52:00.980 --> 01:52:07.540]   It's not attractive. It's not even attractive. It's so ubiquitous that it's just everywhere.
[01:52:07.540 --> 01:52:12.420]   It's meaningless. I mean, I have a very nice one that's red with the Milanese Loop.
[01:52:12.420 --> 01:52:18.580]   And it's nice, but 900 million other people have it. And you're just, it's like saying
[01:52:18.580 --> 01:52:26.260]   doctors are fashion. It's so ubiquitous. It's just not. Right. So Christina strikes me as a kind of
[01:52:26.260 --> 01:52:33.140]   a fashion icon. Yeah, definitely. What is her opinion of that? I mean, she wears it.
[01:52:33.140 --> 01:52:39.460]   She has a bunch of the different bands and stuff. That's all you can do. Same thing with
[01:52:39.460 --> 01:52:44.580]   her and a Richie just buy hundreds of bands, which by the way, Apple makes a pretty penny on
[01:52:44.580 --> 01:52:51.380]   if you buy Apple bands. Holy cow. Anything else that you'd like to see from Google,
[01:52:51.380 --> 01:52:57.940]   they'll certainly talk about Android 13, which is already in the beta. I don't know if they will
[01:52:57.940 --> 01:53:05.060]   announce another pixel book. I wish they would. They seem to be in as typical Google. They just,
[01:53:05.060 --> 01:53:10.020]   they've got bored and they, their attention wandered and they've completely lost track of
[01:53:10.020 --> 01:53:17.620]   Chromebooks. I'm sure they'll say something about it. Google has an opportunity to do something
[01:53:17.620 --> 01:53:22.660]   with work from home, I think. I feel like the hybrid hybrid work is going to be interesting.
[01:53:22.660 --> 01:53:31.220]   Speaking of work from home, I've heard numbers as high as 50% of Apple employees are not happy
[01:53:31.220 --> 01:53:38.420]   with Apple's plans to bring workers back to the campus and people are starting to quit,
[01:53:38.420 --> 01:53:47.780]   including Apple's chief of machine learning who explicitly said, "I'm quitting because I don't
[01:53:47.780 --> 01:53:53.220]   want this new return to the office policy. I don't want to come back to the office."
[01:53:53.220 --> 01:54:00.100]   Wow, the director of machine learning, Ian Goodfellow has resigned. He was there three years now.
[01:54:00.100 --> 01:54:05.220]   Somebody, some wag on Twitter probably pointed out, three years is telling,
[01:54:05.220 --> 01:54:11.060]   that's usually how long it takes to vest your options. It could well be, he's just quitting to
[01:54:11.060 --> 01:54:16.020]   spend more time with his money. I don't know. I don't think it's probably not great to be
[01:54:16.020 --> 01:54:20.660]   machine learning scientist inside Apple. Or Google can talk to your colleagues. I'm saying it's
[01:54:20.660 --> 01:54:25.140]   probably better to be a machine learning worker. If you can keep your job, they keep firing people
[01:54:26.420 --> 01:54:34.020]   not towing the line. Goodfellow said, "I believe strongly more flexibility would have been the best
[01:54:34.020 --> 01:54:42.580]   policy for my team in his goodbye note." So, director of machine learning in the special projects
[01:54:42.580 --> 01:54:49.540]   group he's moved on. Petitions have been circulated. It's estimated, as I said, that about half of the
[01:54:49.540 --> 01:54:57.060]   Apple staff, which is a huge number, say, "We don't like this returned office." Apparently,
[01:54:57.060 --> 01:55:04.020]   great many of them are willing to quit. I remember there were complaints. I used to live in Palo Alto
[01:55:04.020 --> 01:55:10.020]   and I got to know a lot of Apple engineers when I lived there. There were a lot of people that
[01:55:10.020 --> 01:55:15.460]   were very frustrated with their very strict policies about working from home when you're sick. They
[01:55:15.460 --> 01:55:21.780]   would box them to a couple of days a month, if I remember correctly. If you think,
[01:55:21.780 --> 01:55:27.300]   I don't even think this is that complicated. The last time I was driving through Cupertino,
[01:55:27.300 --> 01:55:33.380]   I couldn't believe how much worse the traffic was than in the decades since I left there.
[01:55:33.380 --> 01:55:41.220]   Just difficulty getting around. Imagine being stuck in that for like one, two hours a day,
[01:55:41.220 --> 01:55:49.140]   both ways. Why would you want to do that? I see my own husband. He's been working from home for
[01:55:49.140 --> 01:55:56.340]   the entire pandemic. He's not going back to the office. I think if Apple wants to recruit top
[01:55:56.340 --> 01:55:58.980]   people, they're going to have to show some flexibility on this.
[01:55:58.980 --> 01:56:04.740]   I don't blame people. Although, through the entire pandemic, I've come to work.
[01:56:04.740 --> 01:56:10.900]   But I think you get spoiled working in your jammies with the refrigerator right there.
[01:56:10.900 --> 01:56:14.900]   And I don't think there's any evidence that you're not getting the same job done, right?
[01:56:14.900 --> 01:56:20.740]   Well, not everybody thinks that way. I think there are CEOs that I've spoken with who
[01:56:20.740 --> 01:56:25.540]   want their people in the office. I think that's the wrong perspective. But I can see,
[01:56:25.540 --> 01:56:31.700]   we all know, when people are working from home, it's different. Some people will work just as
[01:56:31.700 --> 01:56:35.460]   hard. A lot of people won't work just as hard. But I just find it interesting that it's Apple.
[01:56:36.180 --> 01:56:40.740]   Because Apple doesn't let people inside the different divisions speak with each other.
[01:56:40.740 --> 01:56:45.460]   There's a great tweet from Benedict Evans. He goes news report, Apple insists all staff go
[01:56:45.460 --> 01:56:50.820]   back to the office so they can bump into people from other teams in the hallways and discuss what
[01:56:50.820 --> 01:56:55.940]   they're working on in informal, unstructured ways. Oh, wait, because they're not allowed to do that.
[01:56:55.940 --> 01:57:00.740]   So it is surprising that Apple, out of all companies, is insisting that this happens.
[01:57:00.740 --> 01:57:03.380]   That was always Steve. You can't have that cross-pondlish.
[01:57:03.380 --> 01:57:08.500]   That was always Steve Jobs' dream story, maybe apocryphal. But the story was that
[01:57:08.500 --> 01:57:15.620]   Steve only wanted one bathroom per floor in that giant ring campus because he wanted people to
[01:57:15.620 --> 01:57:21.380]   move around and talk to each other and bump into each other and talk. And that Johnny I,
[01:57:21.380 --> 01:57:27.460]   I think, convinced him that no, he need more bathrooms. Steve, how is that?
[01:57:27.460 --> 01:57:32.900]   That's true reality distortion filter was when you believe that your employees can talk to each
[01:57:32.900 --> 01:57:36.500]   other about their different projects when you explicitly do not allow them to prevent them.
[01:57:36.500 --> 01:57:41.140]   How was that trip, Michael, book? Everybody seems to like it quite a bit.
[01:57:41.140 --> 01:57:47.220]   I learned a lot about, I enjoyed it. He just came on the pot also. I enjoyed learning a little bit
[01:57:47.220 --> 01:57:52.900]   more about Tim Cook as a young person and Johnny I was a young person. This stuff when it gets
[01:57:52.900 --> 01:57:57.460]   into the company, but learning a little bit more about where Tim Cook comes from. Tim
[01:57:57.460 --> 01:58:03.300]   went down to his hometown and actually found like he had said that he had seen a cross burning.
[01:58:03.300 --> 01:58:10.180]   And there was a deacon from like a nearby church and basically like the people from Tim Cook's
[01:58:10.180 --> 01:58:14.660]   hometown fact check him on that. And there's some things that don't fully add up. So I just
[01:58:14.660 --> 01:58:19.860]   found that to be kind of interesting. The New York Times reporter, good sources,
[01:58:19.860 --> 01:58:25.220]   talked, he said to 200 people to write the book. It seemed to be mostly about
[01:58:26.420 --> 01:58:34.500]   Tim Cook versus Johnny Ive and ultimately explained Johnny's leaving, which I think most of us
[01:58:34.500 --> 01:58:39.780]   suspected had something to do with Johnny not being happy with the direction Apple was taking.
[01:58:39.780 --> 01:58:46.740]   As an Apple user, as much as I love Johnny Ive's design sense, I'm kind of glad Apple's gotten
[01:58:46.740 --> 01:58:52.740]   back to function over form. And I think most Apple users feel the same. In fact, Apple's
[01:58:52.740 --> 01:58:58.500]   sales of the Macintosh have jumped their quarterly results were very good for the Macintosh.
[01:58:58.500 --> 01:59:05.060]   And Apple estimated that 50% of buyers of the new Macintosh computers had never owned a Mac before.
[01:59:05.060 --> 01:59:12.260]   So that is very good news for Apple. PC sales have not been great AMD itself though.
[01:59:12.260 --> 01:59:19.940]   Sales say sales jumped 71% for AMD. Maybe that's more of an indicator that people
[01:59:20.580 --> 01:59:27.700]   are looking for budget PCs. I don't know, Leah, I read that 100% supply chain stuff.
[01:59:27.700 --> 01:59:32.740]   Like it is so hard to get the parts to build a PC right now, a graphics card,
[01:59:32.740 --> 01:59:40.500]   but again, just the entire bit of it. Maybe easier to get Radeon chips than it is Nvidia chip.
[01:59:40.500 --> 01:59:44.100]   100% it's impossible right now with all the cryptocurrency miners.
[01:59:45.300 --> 01:59:51.460]   Oh, interesting. They also have a strong B2B business and in this past quarter B2B businesses tended
[01:59:51.460 --> 01:59:56.180]   to fare a lot better than businesses that are catering to consumers interests. So I think that
[01:59:56.180 --> 02:00:02.180]   bolster day and day in a big way. Lisa Sue doing a really good job there at AMD.
[02:00:02.180 --> 02:00:07.220]   Very impressive. Yeah. Yeah. All right, let's take one more break. We're almost done.
[02:00:10.980 --> 02:00:17.300]   I have to say that because I think this can be a marathon and for either one of you,
[02:00:17.300 --> 02:00:21.700]   I appreciate your patience. Last week, Corey Doctorow said, "I'll do the show,
[02:00:21.700 --> 02:00:26.660]   but I cannot sit for more than two and a half hours." So you got to keep it short. And I said,
[02:00:26.660 --> 02:00:32.340]   "Okay, for you, Corey, absolutely." Our show today brought to you by brand new sponsor. Very
[02:00:32.340 --> 02:00:37.220]   excited about a policy genius. I think you might know the name whether you're graduating from
[02:00:37.220 --> 02:00:44.580]   school or planning a wedding, welcoming a baby, switching jobs. It's Mother's Day. It's really
[02:00:44.580 --> 02:00:52.500]   time to think about protecting your family's finances. And that's why you need life insurance.
[02:00:52.500 --> 02:00:58.340]   I didn't have life insurance until I had kids, but that's when we got life insurance. It can give
[02:00:58.340 --> 02:01:03.460]   you peace of mind that if something happens to you, your loved ones will have a financial cushion.
[02:01:04.420 --> 02:01:11.940]   But you got to choose the right insurance at the right price. You may have life insurance for
[02:01:11.940 --> 02:01:19.140]   your job. We do, but it's not enough. It's not enough. Most people need up to 10 times more coverage
[02:01:19.140 --> 02:01:23.700]   to properly provide for their families. Of course, life insurance gets more expensive as you get
[02:01:23.700 --> 02:01:30.580]   older. So it's better to start a policy sooner rather than later. And I strongly suggest you go
[02:01:30.580 --> 02:01:36.580]   to Policy Genius to do it. A one-stop shop to find the insurance you need at the right price.
[02:01:36.580 --> 02:01:42.180]   There's a link at our show page where you can go to policygenius.com/twit
[02:01:42.180 --> 02:01:49.540]   policygenius.com/twit to get started. In minutes, you will get personalized quotes from
[02:01:49.540 --> 02:01:54.820]   a bunch of top companies. So you can find your lowest price. That actually can save you.
[02:01:55.780 --> 02:02:01.220]   There really can be a big difference in policies. Same policy from different companies can be as
[02:02:01.220 --> 02:02:06.980]   much as 50% apart in the cost. You could say, that's right. You could say 50% or more in life
[02:02:06.980 --> 02:02:13.780]   insurance by comparing quotes alone with Policy Genius. And then because it is, you are getting
[02:02:13.780 --> 02:02:19.300]   your life insurance via Policy Genius, they have licensed insurance agents. They are required to
[02:02:19.300 --> 02:02:24.900]   buy law. They'll be there to help you throughout the entire process. So you can ask them questions.
[02:02:24.900 --> 02:02:30.420]   They are not selling insurance though. This is the beauty of it. They're there to help you.
[02:02:30.420 --> 02:02:33.860]   So you can understand your options and make your decisions with confidence. They don't work for
[02:02:33.860 --> 02:02:38.820]   the insurance companies. They work for you. They're not salespeople. They're there to give you the
[02:02:38.820 --> 02:02:44.980]   information you need. Policy Genius doesn't add on extra fees. Very important giving our last
[02:02:44.980 --> 02:02:51.460]   conversation. They do not sell your info to third parties. They really understand that that privacy
[02:02:51.460 --> 02:02:56.980]   is very important to us. Just check their reviews on Google or Trustpilot. Thousands of five-star
[02:02:56.980 --> 02:03:03.060]   reviews. You can get coverage as in as little as a week. You can get coverage if you want to
[02:03:03.060 --> 02:03:08.900]   without medical exams. They've been doing this for quite a while since 2014. In fact, Policy
[02:03:08.900 --> 02:03:14.100]   Genius has now helped 30 million people shop for insurance. They've placed over $150 billion.
[02:03:14.980 --> 02:03:19.700]   In coverage. They do it the right way by giving you information and giving you a choice.
[02:03:19.700 --> 02:03:27.380]   Strongly recommend you do this. Policygenius.com/twit. Yes, they have home auto, disability,
[02:03:27.380 --> 02:03:32.980]   renters insurance and more. They have the full gamut. Today I want to because it's Mother's Day.
[02:03:32.980 --> 02:03:40.660]   You got to take care of your family. Mother or father. Sometimes that means
[02:03:41.700 --> 02:03:44.820]   you got to think about the unthinkable. If you're not going to be there to take care of them,
[02:03:44.820 --> 02:03:51.540]   who is PolicyGenius. PolicyGenius.com/twit. You can get free life insurance quotes.
[02:03:51.540 --> 02:03:57.140]   See how much you could save. See how little it'll cost to give you that kind of peace of mind.
[02:03:57.140 --> 02:04:05.060]   I was very glad I did it. I'm very glad. Henry's TikTok career is not necessarily going to take
[02:04:05.060 --> 02:04:12.020]   him to the moon and back. Do you know that Brianna? My son's two million followers and TikTok.
[02:04:12.020 --> 02:04:18.180]   Did you know that? Salt Hane? He got hungry. He'll make you hungry.
[02:04:18.180 --> 02:04:25.620]   Tuesday he's going to be on Access Hollywood again for something they're doing that's I think
[02:04:25.620 --> 02:04:33.380]   pretty exciting. It's called I think the sandwich head-to-head sandwich competition. He'll be
[02:04:34.180 --> 02:04:40.180]   on Access Hollywood on Tuesday with another sandwich maker, another famous sandwich maker.
[02:04:40.180 --> 02:04:48.260]   And then the audience will choose which one they like the best. If he makes the vodka
[02:04:48.260 --> 02:04:52.660]   parm sandwich, there is no question in my mind, not at all that he will win.
[02:04:52.660 --> 02:05:00.900]   We all know that if the count votes fairly, he will win and if not, rigged.
[02:05:00.900 --> 02:05:07.300]   Too soon? Maybe a bit.
[02:05:07.300 --> 02:05:14.580]   Let's come back with our final, a couple of final stories. In fact, a very big victory
[02:05:14.580 --> 02:05:20.340]   for people in the Southland. But first, let's take a look back at the week that was.
[02:05:20.340 --> 02:05:27.540]   Camio lays off close to 90, including the CPO, CTO, and VP of marketing.
[02:05:27.540 --> 02:05:32.260]   Why don't you get on Camio and see how you do? I'd be so curious.
[02:05:32.260 --> 02:05:36.260]   What should I say? Don't you want to have like your trademark thing that you say?
[02:05:36.260 --> 02:05:38.100]   Hey, hey, hey!
[02:05:38.100 --> 02:05:49.700]   Previously on Twitter, Mac break weekly, Apple's self-service repair is now available.
[02:05:49.700 --> 02:05:51.620]   Not equipment though, Leo.
[02:05:53.380 --> 02:05:59.300]   216 bucks. I think we should just get one of these for the studio. It looks like you can make a cup
[02:05:59.300 --> 02:06:07.620]   of coffee. Yeah. iOS today, let's talk about webcams. We can make these better. There are ways.
[02:06:07.620 --> 02:06:12.980]   There's two different apps that make using your iPhone as a web camera much easier. It allows you
[02:06:12.980 --> 02:06:17.380]   to take the great camera on the back of your device, even on an older iPhone, and use it as a web
[02:06:17.380 --> 02:06:21.700]   camera. Have you got a cat on your head, Micah? Now there's a cat on my head. Micah has an AI
[02:06:21.700 --> 02:06:28.820]   calon, is that okay? Hands on photography. The one and only, whoo, 49ers photographer,
[02:06:28.820 --> 02:06:34.660]   amongst other things, Canon Explorer of Light. Mr. Terrell Lloyd. Get it right in camera. If
[02:06:34.660 --> 02:06:39.780]   it's garbage in, it's garbage out. That's right. Inside the camera, do the least amount of post
[02:06:39.780 --> 02:06:46.500]   production work on it. I mean, if you have to, right? To it. Tell your boss it's job related.
[02:06:47.940 --> 02:06:52.340]   He'll believe it. He'll believe it. I should, we should have a segment on the show
[02:06:52.340 --> 02:07:03.380]   based on the meme. This is fine. It's time to play. This is fine. NVIDIA fined five and a half
[02:07:03.380 --> 02:07:08.980]   million dollars for allegedly. Why is it allegedly? If they got fined, we can say they did it,
[02:07:08.980 --> 02:07:17.220]   hiding how many gaming GPUs were sold to crypto miners. SEC said you misled investors
[02:07:17.220 --> 02:07:23.380]   by reporting a big boost in revenue related to gaming without alluding to the fact that no,
[02:07:23.380 --> 02:07:29.860]   it's not gaming. It's crypto mining. We're just talking about that. The problem is a five and a
[02:07:29.860 --> 02:07:36.500]   half million dollar fine for NVIDIA is nothing. It's the cost of doing business.
[02:07:37.940 --> 02:07:46.740]   And to it, paying a little bit bigger fine, 141 million dollars for free, free, free,
[02:07:46.740 --> 02:07:52.980]   TurboTax ads award free, free, free. Now, I think 141 million probably stings a little bit more.
[02:07:52.980 --> 02:07:55.620]   But again, these companies are making-
[02:07:55.620 --> 02:07:58.340]   Those are biggest scammers. They're turbo tax men.
[02:07:58.340 --> 02:08:04.580]   Yes. I feel so strongly about that one. Yeah. Part of like TurboTax is they came into agreement
[02:08:04.580 --> 02:08:10.740]   with the United States government who went to develop their own tax filing software as just like
[02:08:10.740 --> 02:08:15.300]   a service to taxpayers to make it easier. And they went to Congress and they said,
[02:08:15.300 --> 02:08:20.580]   look, we're going to give you a free version. It's going to be very easy for people to file.
[02:08:20.580 --> 02:08:25.620]   It will be open. And then only sophisticated people will need to pay for a full product here.
[02:08:25.620 --> 02:08:29.860]   Of course, it never happened. It's just a lie. And then you see this lawsuit.
[02:08:29.860 --> 02:08:34.260]   Oh, it gets me mad. I feel mad. Every year. I do my mom's taxes.
[02:08:34.260 --> 02:08:41.860]   She's 89. Her taxes are very simple. Every year, I select free. I let the free TurboTax.
[02:08:41.860 --> 02:08:45.780]   I end up paying $89 every year, no matter what.
[02:08:45.780 --> 02:08:50.660]   100% the same. This is our broadest point of agreement on the panel,
[02:08:50.660 --> 02:08:54.580]   which I'm very excited about because they deserve the buyer, the combined
[02:08:54.580 --> 02:08:59.460]   buyer of three of us. But is $141 million enough, right?
[02:08:59.460 --> 02:09:03.060]   No, do more. Do more. Make it make it hurt.
[02:09:03.060 --> 02:09:08.260]   Because what happens is these companies say, well, it's cost to a business.
[02:09:08.260 --> 02:09:10.660]   We made 800 million. I'll give you a hundred.
[02:09:10.660 --> 02:09:10.660]   Sure.
[02:09:10.660 --> 02:09:12.180]   $24 million.
[02:09:12.180 --> 02:09:16.980]   $80 million. There's 300 something million people in the US. 89 times a good chunk of them.
[02:09:16.980 --> 02:09:20.900]   And you can definitely be okay with that $141 million fine.
[02:09:20.900 --> 02:09:24.660]   They will have to suspend their free, free, free ad campaign,
[02:09:24.660 --> 02:09:30.260]   pay restitution to 4.4 million taxpayers. So maybe, you know, maybe this will,
[02:09:30.260 --> 02:09:34.100]   maybe this will cost them a little bit. They shouldn't have their CEO on video.
[02:09:34.100 --> 02:09:34.740]   Apologize.
[02:09:34.740 --> 02:09:35.540]   Yes.
[02:09:35.540 --> 02:09:37.060]   That as the, sorry, America.
[02:09:37.060 --> 02:09:37.540]   Bravo.
[02:09:37.540 --> 02:09:41.700]   They, you know what? We knew we were ripping you off, but we did it anyway.
[02:09:41.700 --> 02:09:45.620]   You can't charge these people enough. Humiliate them instead.
[02:09:45.620 --> 02:09:50.500]   Make them come on TV and say, we lied.
[02:09:50.500 --> 02:09:52.900]   We did it. We did it. We lied.
[02:09:52.900 --> 02:09:57.380]   I don't understand why people have to do so much of having lifting here.
[02:09:57.380 --> 02:10:01.460]   Yes. I agree. Many other countries, the government has a lot of this
[02:10:01.460 --> 02:10:04.180]   informational rate, like my mortgage deduction, right?
[02:10:04.180 --> 02:10:10.100]   Get that from the, like, you know how much money I made. You know my mortgage deductions.
[02:10:10.100 --> 02:10:14.580]   Like I'm going to have to do some things like, you know, camera equipment from my office to,
[02:10:14.580 --> 02:10:17.540]   to, to, to, to duck that, right? There will be some like work.
[02:10:17.540 --> 02:10:20.100]   In Finland, you get a postcard.
[02:10:20.100 --> 02:10:20.980]   Right.
[02:10:20.980 --> 02:10:25.540]   When tax time comes, it says, we think you owe this much. If you agree, set as a check.
[02:10:25.540 --> 02:10:26.660]   Right.
[02:10:26.660 --> 02:10:27.140]   That's it.
[02:10:27.140 --> 02:10:32.180]   I can't imagine that happening in America.
[02:10:32.180 --> 02:10:36.100]   I mean, it's hard not getting people to pay their taxes.
[02:10:36.100 --> 02:10:39.460]   Yeah. You also got big TurboTax lobbying the government.
[02:10:39.460 --> 02:10:40.980]   Well, that's the real problem.
[02:10:40.980 --> 02:10:42.420]   They threw it into crop software.
[02:10:42.420 --> 02:10:42.900]   Yeah.
[02:10:42.900 --> 02:10:43.940]   That's the real problem.
[02:10:43.940 --> 02:10:47.700]   You know, the federal government has a free file program.
[02:10:47.700 --> 02:10:50.740]   Okay.
[02:10:53.140 --> 02:10:56.100]   And then, and then finally, and this is fine.
[02:10:56.100 --> 02:10:59.140]   I love the segment.
[02:10:59.140 --> 02:11:00.740]   I'm going to do this every week now.
[02:11:00.740 --> 02:11:01.460]   This is great.
[02:11:01.460 --> 02:11:02.580]   This is fine.
[02:11:02.580 --> 02:11:03.780]   This is when we get a little less.
[02:11:03.780 --> 02:11:04.900]   This is fine.
[02:11:04.900 --> 02:11:05.540]   This is fine.
[02:11:05.540 --> 02:11:06.980]   This is fine.
[02:11:06.980 --> 02:11:08.900]   The world's burning, but this is fine.
[02:11:08.900 --> 02:11:13.220]   In this is fine.
[02:11:13.220 --> 02:11:14.020]   Frontier.
[02:11:14.020 --> 02:11:14.580]   Oh man.
[02:11:14.580 --> 02:11:19.060]   When Frontier bought all the customers from, I think it was Spectrum.
[02:11:19.060 --> 02:11:22.500]   They were leaving the LA area, the LA markets,
[02:11:22.500 --> 02:11:24.180]   a frontier bought all the customers.
[02:11:24.180 --> 02:11:28.260]   I was getting call after call on the radio show.
[02:11:28.260 --> 02:11:31.860]   Just people were, it was awful service.
[02:11:31.860 --> 02:11:32.660]   It was terrible.
[02:11:32.660 --> 02:11:37.620]   Corey Doctor has gone off on Frontier about,
[02:11:37.620 --> 02:11:40.820]   you know, intentionally keeping their physical plant
[02:11:40.820 --> 02:11:43.220]   underpowered and underperforming.
[02:11:43.780 --> 02:11:49.300]   FTC said, and this is as of May 5th,
[02:11:49.300 --> 02:11:51.620]   it has moved to stop internet service provider.
[02:11:51.620 --> 02:11:56.500]   Frontier from communications from lying to customers
[02:11:56.500 --> 02:11:58.660]   and charging them for high speed internet.
[02:11:58.660 --> 02:11:59.940]   It fails to deliver.
[02:11:59.940 --> 02:12:02.500]   They were sued last May.
[02:12:02.500 --> 02:12:04.900]   It took them a year, but on Thursday,
[02:12:04.900 --> 02:12:06.660]   they agreed to a settlement admitting no,
[02:12:06.660 --> 02:12:13.300]   no, no admission of guilt with the FTC and district
[02:12:13.300 --> 02:12:16.100]   attorneys in Los Angeles County and Riverside County,
[02:12:16.100 --> 02:12:17.780]   representing the people of California.
[02:12:17.780 --> 02:12:20.100]   But it's again, it's a slap on the wrist.
[02:12:20.100 --> 02:12:21.940]   Frontier has to pay eight and a half million dollars
[02:12:21.940 --> 02:12:26.180]   to California for investigation and litigation costs.
[02:12:26.180 --> 02:12:28.660]   And what do they give customers who were armed?
[02:12:28.660 --> 02:12:32.580]   250,000 will be distributed to Frontier customers.
[02:12:32.580 --> 02:12:34.580]   You're going to get a check for a buck 25.
[02:12:34.580 --> 02:12:38.500]   Whoever negotiated that settlement needs to be,
[02:12:38.500 --> 02:12:42.820]   that is professional malfeasance, right?
[02:12:42.820 --> 02:12:44.100]   They such a joke.
[02:12:44.100 --> 02:12:45.700]   Eight and a half million in California,
[02:12:45.700 --> 02:12:47.940]   250,000 to the consumers.
[02:12:47.940 --> 02:12:49.220]   Wanted joke.
[02:12:49.220 --> 02:12:50.020]   No, no, no.
[02:12:50.020 --> 02:12:52.740]   That whoever prosecuted that case for the government,
[02:12:52.740 --> 02:12:54.500]   they need to go find another line of work,
[02:12:54.500 --> 02:12:55.620]   and they probably will.
[02:12:55.620 --> 02:12:57.220]   And then they'll probably leave this settlement
[02:12:57.220 --> 02:12:58.020]   and go into the-
[02:12:58.020 --> 02:12:59.780]   They're going to work for the same people.
[02:12:59.780 --> 02:13:01.140]   Yeah, go to work Frontier.
[02:13:01.140 --> 02:13:04.420]   Frontier also has to let customers cancel service in no charge.
[02:13:04.420 --> 02:13:06.100]   Yes.
[02:13:06.100 --> 02:13:08.340]   Yes. Frontier was one of the main cable companies
[02:13:08.340 --> 02:13:10.340]   that charged you to cancel service.
[02:13:11.620 --> 02:13:13.780]   You could cancel service, but it's going to cost you.
[02:13:13.780 --> 02:13:16.180]   What other business in America?
[02:13:16.180 --> 02:13:19.140]   If you went to your dry cleaner and said,
[02:13:19.140 --> 02:13:20.900]   "I'm going to go to the dry cleaner across the street."
[02:13:20.900 --> 02:13:23.060]   Oh, that'll be $48.
[02:13:23.060 --> 02:13:23.860]   What?
[02:13:23.860 --> 02:13:25.940]   No other business does that?
[02:13:25.940 --> 02:13:26.980]   Cable companies do.
[02:13:26.980 --> 02:13:29.380]   So they can't do that anymore.
[02:13:29.380 --> 02:13:30.180]   Oh, well, that's good.
[02:13:30.180 --> 02:13:36.900]   And they will also discount the bills of California customers
[02:13:36.900 --> 02:13:38.660]   who have not been notified.
[02:13:38.660 --> 02:13:43.460]   They're getting DSL service that is much slower than the advertised speed.
[02:13:43.460 --> 02:13:45.220]   Much slower.
[02:13:45.220 --> 02:13:48.900]   A judge will have to approve this,
[02:13:48.900 --> 02:13:51.300]   although the FTC approved it for nothing.
[02:13:51.300 --> 02:13:53.860]   It was a slam dunk.
[02:13:53.860 --> 02:13:56.420]   And that is our segment.
[02:13:56.420 --> 02:13:57.620]   This is fine.
[02:13:57.620 --> 02:14:02.820]   I think all these companies should have to come on to quit
[02:14:02.820 --> 02:14:04.500]   and grovel before you move on.
[02:14:04.500 --> 02:14:05.140]   I'm sorry.
[02:14:05.140 --> 02:14:09.060]   Is it a judge show, just like Judge Judy, that judge me?
[02:14:09.060 --> 02:14:11.540]   And then you sat the fine.
[02:14:11.540 --> 02:14:13.220]   And I would watch that show.
[02:14:13.220 --> 02:14:14.260]   I'm sorry.
[02:14:14.260 --> 02:14:14.900]   I did it.
[02:14:14.900 --> 02:14:16.260]   I'm sorry.
[02:14:16.260 --> 02:14:24.740]   New York City is suing Activision, targeting Bobby Kotick,
[02:14:24.740 --> 02:14:26.340]   everybody's favorite CEO.
[02:14:26.340 --> 02:14:32.900]   How much did Kotick make when Microsoft bought Activision?
[02:14:34.260 --> 02:14:34.820]   A lot.
[02:14:34.820 --> 02:14:37.700]   Hundreds of millions of dollars.
[02:14:37.700 --> 02:14:47.220]   Of course, he has also been accused of all sorts of malfeasance,
[02:14:47.220 --> 02:14:49.780]   including turning a blind eye to harassment.
[02:14:49.780 --> 02:14:52.900]   I think he made him free speech.
[02:14:52.900 --> 02:14:54.420]   Free speech?
[02:14:54.420 --> 02:14:54.900]   That's right.
[02:14:54.900 --> 02:14:58.820]   CEO Bobby Kotick, new of sexual misconduct at the company,
[02:14:58.820 --> 02:15:03.220]   according to the allegations, but did nothing about it.
[02:15:04.180 --> 02:15:09.860]   New York sought access to Activision's books as a basis to sue
[02:15:09.860 --> 02:15:12.020]   for allegedly costing the company value.
[02:15:12.020 --> 02:15:13.940]   Kotick said, no.
[02:15:13.940 --> 02:15:16.020]   Anyway, we shall see.
[02:15:16.020 --> 02:15:17.140]   We shall see.
[02:15:17.140 --> 02:15:19.860]   I think he's going to skate, to be honest with you,
[02:15:19.860 --> 02:15:21.860]   and he's going to skate with a lot of money.
[02:15:21.860 --> 02:15:25.300]   He had threats on his own workers.
[02:15:25.300 --> 02:15:28.580]   I mean, go read the Wall Street Journal reporting.
[02:15:28.580 --> 02:15:33.380]   Yeah, this is like there are very few angels in game development.
[02:15:33.380 --> 02:15:37.460]   I feel very qualified to say Bobby Kotick is a particularly,
[02:15:37.460 --> 02:15:42.580]   I think his actions are extremely, extremely problematic.
[02:15:42.580 --> 02:15:45.300]   Culture comes from the top in the game industry.
[02:15:45.300 --> 02:15:48.260]   If you look at some of the things that happened under his watch,
[02:15:48.260 --> 02:15:53.380]   just to remind your listeners, one of them, you had a woman that was working for a man
[02:15:53.380 --> 02:15:55.300]   on this team.
[02:15:56.180 --> 02:15:57.780]   He sexually harassed her.
[02:15:57.780 --> 02:15:59.780]   She eventually died by suicide.
[02:15:59.780 --> 02:16:04.340]   And then that team passed around nude photos of her after her death
[02:16:04.340 --> 02:16:07.780]   for all the men on the team to watch and enjoy looking at.
[02:16:07.780 --> 02:16:10.980]   Some truly shocking stuff if you look at it.
[02:16:10.980 --> 02:16:16.820]   The fact that I think it's important to note also,
[02:16:16.820 --> 02:16:19.620]   this deal has not officially gone through yet.
[02:16:19.620 --> 02:16:22.180]   There are regulators that are looking at it.
[02:16:22.180 --> 02:16:28.180]   And I can tell you for a fact, there are people looking into the culture of
[02:16:28.180 --> 02:16:32.100]   Activision and wonder if it's going to be a good fit for Microsoft that could
[02:16:32.100 --> 02:16:35.780]   cause some complications and how this goes through.
[02:16:35.780 --> 02:16:39.460]   But overall, just an absolutely terrible tenure,
[02:16:39.460 --> 02:16:42.340]   probably the worst tenure of anyone in the history of games.
[02:16:42.340 --> 02:16:44.020]   And that's a really high bar.
[02:16:44.020 --> 02:16:45.860]   He ran Activision for 30 years.
[02:16:45.860 --> 02:16:49.780]   Microsoft's offering $95 a share.
[02:16:50.420 --> 02:16:56.980]   If that does go through, he stands to gain $520 million, half a billion.
[02:16:56.980 --> 02:17:02.820]   But the New York state is going after him.
[02:17:02.820 --> 02:17:06.660]   Okay, I don't want to end on that note.
[02:17:06.660 --> 02:17:07.860]   Let's find something happy to.
[02:17:07.860 --> 02:17:09.220]   Yeah, I feel like that should have been in this.
[02:17:09.220 --> 02:17:12.820]   Can we talk about the Apple machinery for fixing the iPhones?
[02:17:12.820 --> 02:17:13.780]   That is so cool.
[02:17:13.780 --> 02:17:17.460]   Yeah, we showed a little bit of that in the promo,
[02:17:17.460 --> 02:17:22.020]   Apple's self repair plan has gone into effect.
[02:17:22.020 --> 02:17:28.740]   And actually, I think I'm going to give Apple props because they could make you buy hundreds
[02:17:28.740 --> 02:17:30.980]   of dollars worth of equipment.
[02:17:30.980 --> 02:17:37.780]   Instead, they're going to rent it to you for a week for $49 plus the cost of the
[02:17:37.780 --> 02:17:40.980]   part you're going to repair.
[02:17:40.980 --> 02:17:45.780]   Now, you do have to get the machine for the device that you're repairing.
[02:17:45.780 --> 02:17:48.100]   These machines are very specific.
[02:17:48.100 --> 02:17:54.900]   But if you go to Apple's self service repair store, you can order the parts yourself.
[02:17:54.900 --> 02:17:58.740]   I would say you got to know what you're doing.
[02:17:58.740 --> 02:18:04.740]   Let's say I want to replace the battery in my iPhone 12 Pro Max.
[02:18:04.740 --> 02:18:08.660]   So the kit, the battery bundle itself, that's 71 bucks.
[02:18:08.660 --> 02:18:12.580]   But if you return the old battery, you get 24 bucks back.
[02:18:12.580 --> 02:18:15.700]   So that's about 50 bucks for the repair.
[02:18:15.700 --> 02:18:16.740]   That's not bad.
[02:18:16.740 --> 02:18:20.660]   You will have to rent some machinery.
[02:18:20.660 --> 02:18:28.740]   It comes in a couple of really nicely packed Pelican cases, weighing hundreds of pounds.
[02:18:28.740 --> 02:18:31.540]   These are not little, what?
[02:18:31.540 --> 02:18:33.300]   Yes, because you're going to need this.
[02:18:33.300 --> 02:18:34.580]   It's a battery press.
[02:18:34.580 --> 02:18:36.500]   79 pounds for the one I looked at.
[02:18:36.500 --> 02:18:38.340]   And this is what I love about it.
[02:18:38.340 --> 02:18:39.220]   You're going to do this.
[02:18:39.220 --> 02:18:41.620]   Apple, the company that's always talking, we're green.
[02:18:41.620 --> 02:18:44.580]   We love the environment, y'all.
[02:18:44.580 --> 02:18:50.900]   So our new plan is to ship 79 pound packages just all around the country constantly.
[02:18:50.900 --> 02:18:54.020]   And you better return it on time or you will owe.
[02:18:54.020 --> 02:18:57.380]   You will owe these only $49 to rent it.
[02:18:57.380 --> 02:19:00.180]   But yeah, you're going to owe a little bit more if you don't return it.
[02:19:00.180 --> 02:19:01.620]   I think it's only seven days.
[02:19:01.620 --> 02:19:03.300]   That's cool.
[02:19:03.300 --> 02:19:04.420]   But they pay for screen.
[02:19:04.420 --> 02:19:06.580]   I can fix my screen with one of these things.
[02:19:06.580 --> 02:19:10.980]   The toolkit comes in cases then when stacked on top of each other.
[02:19:11.460 --> 02:19:14.420]   Measure, measure four feet high.
[02:19:14.420 --> 02:19:19.380]   One case weighs 43 pounds, the other 36 pounds.
[02:19:19.380 --> 02:19:20.340]   Oh my God.
[02:19:20.340 --> 02:19:22.580]   The UPS driver is not going to like you.
[02:19:22.580 --> 02:19:23.380]   Oh, but good news.
[02:19:23.380 --> 02:19:26.980]   The cases do have roller wheels to aid in transport.
[02:19:26.980 --> 02:19:35.700]   So you're making the UPS guy literally lug $100 of equipment in your house because you're too lazy
[02:19:35.700 --> 02:19:36.980]   to get the Apple store.
[02:19:36.980 --> 02:19:40.740]   By the way, it is cheaper to bring it to the Apple store incidentally.
[02:19:40.740 --> 02:19:41.380]   You will save it.
[02:19:41.380 --> 02:19:41.780]   It is.
[02:19:41.780 --> 02:19:42.020]   Yeah.
[02:19:42.020 --> 02:19:43.060]   Oh.
[02:19:43.060 --> 02:19:45.940]   Well, we got the right to repair.
[02:19:45.940 --> 02:19:49.860]   But you have the way I feel like this is Apple saying you asked for it.
[02:19:49.860 --> 02:19:52.020]   You wanted it.
[02:19:52.020 --> 02:19:53.860]   And this is what it takes.
[02:19:53.860 --> 02:19:54.660]   It's not easy to do.
[02:19:54.660 --> 02:19:56.660]   You made daddy give it to you.
[02:19:56.660 --> 02:19:56.980]   You did.
[02:19:56.980 --> 02:19:57.460]   Daddy, yeah.
[02:19:57.460 --> 02:19:58.100]   Now you have it.
[02:19:58.100 --> 02:19:59.460]   There's a term for that.
[02:19:59.460 --> 02:20:01.140]   It's called malicious compliance.
[02:20:01.140 --> 02:20:02.740]   Yes.
[02:20:02.740 --> 02:20:03.940]   It's perfect.
[02:20:03.940 --> 02:20:04.420]   Perfect.
[02:20:04.420 --> 02:20:05.940]   Perfect.
[02:20:05.940 --> 02:20:06.340]   Perfect.
[02:20:06.340 --> 02:20:10.340]   Ladies and gentlemen, you have been a very patient
[02:20:10.340 --> 02:20:18.340]   and lovely audience, but I think it's time to roll this show up and declare it completed.
[02:20:18.340 --> 02:20:21.700]   Alex Cantor, it's always a pleasure to have you on.
[02:20:21.700 --> 02:20:22.660]   Thank you so much.
[02:20:22.660 --> 02:20:28.580]   The website is bigtechnology.substack.com.
[02:20:28.580 --> 02:20:30.020]   Subscribe to the newsletter.
[02:20:30.020 --> 02:20:31.460]   The podcast, is it free?
[02:20:31.460 --> 02:20:32.100]   I think it is.
[02:20:32.100 --> 02:20:32.580]   Yes.
[02:20:32.580 --> 02:20:35.300]   Yeah, free podcast, big technology podcast.
[02:20:35.300 --> 02:20:36.500]   It works on every app.
[02:20:36.500 --> 02:20:38.580]   And I must listen this week.
[02:20:38.580 --> 02:20:39.140]   Yeah, you don't.
[02:20:39.140 --> 02:20:40.900]   It's not Spotify special.
[02:20:40.900 --> 02:20:42.020]   That's right.
[02:20:42.020 --> 02:20:42.420]   Yeah.
[02:20:42.420 --> 02:20:45.700]   Bus Spotify, if you're listening, $100 million and it's yours.
[02:20:45.700 --> 02:20:48.260]   I always say the same thing.
[02:20:48.260 --> 02:20:52.580]   There was a look one day Leo.
[02:20:52.580 --> 02:20:53.140]   Someday.
[02:20:53.140 --> 02:20:53.700]   You wouldn't get that.
[02:20:53.700 --> 02:20:54.100]   I have that.
[02:20:54.100 --> 02:20:54.820]   That's right.
[02:20:54.820 --> 02:20:55.380]   Did you know?
[02:20:55.380 --> 02:20:57.380]   So Spotify is now worth 20.
[02:20:57.380 --> 02:21:01.380]   I think they actually paid 200 million to Rogan,
[02:21:01.380 --> 02:21:02.900]   and they're now worth 20 billion.
[02:21:02.900 --> 02:21:06.340]   So a full one-tenth of their valuation went to Joe Rogan.
[02:21:06.340 --> 02:21:07.300]   That's astounding.
[02:21:07.780 --> 02:21:08.660]   Pretty wild.
[02:21:08.660 --> 02:21:12.420]   I don't, in some ways, I don't mind Joe Rogan getting 200 million.
[02:21:12.420 --> 02:21:15.860]   It's called her daddy, who got 60 million for one show.
[02:21:15.860 --> 02:21:17.140]   Yeah.
[02:21:17.140 --> 02:21:20.340]   One show a week that irks me a little bit.
[02:21:20.340 --> 02:21:24.420]   It's just a little, I'm not a teenage woman, so I don't know.
[02:21:24.420 --> 02:21:27.940]   I mean, I'm sure it's a wonderful show for the young.
[02:21:27.940 --> 02:21:28.100]   Yeah.
[02:21:28.100 --> 02:21:28.580]   Youngs.
[02:21:28.580 --> 02:21:30.660]   But Leo, great to be on.
[02:21:30.660 --> 02:21:31.540]   Thank you for having me.
[02:21:31.540 --> 02:21:33.380]   It's really always a pleasure to talk tech with you.
[02:21:33.380 --> 02:21:33.940]   I'm Brianna.
[02:21:33.940 --> 02:21:35.380]   I mean, awesome talking with you.
[02:21:35.380 --> 02:21:36.180]   Really nice to meet you.
[02:21:36.180 --> 02:21:36.980]   This was super fun.
[02:21:37.620 --> 02:21:38.420]   Absolutely.
[02:21:38.420 --> 02:21:41.460]   Read your stuff all the time, so it's an honor.
[02:21:41.460 --> 02:21:45.460]   Trip Mickle on the last episode was Tim Cook the right choice for Apple.
[02:21:45.460 --> 02:21:47.620]   This week, the big debate.
[02:21:47.620 --> 02:21:48.900]   Big technology.
[02:21:48.900 --> 02:21:50.260]   NFT is good or bad.
[02:21:50.260 --> 02:21:56.340]   Scam or legit, are they the future of collectibles or business Q&A?
[02:21:56.340 --> 02:21:58.420]   Are you comparing like it's a debate?
[02:21:58.420 --> 02:22:01.220]   Like, did you do debate in school?
[02:22:01.220 --> 02:22:05.620]   Are you gathering your facts, marshalling your arguments?
[02:22:06.420 --> 02:22:07.060]   And not really.
[02:22:07.060 --> 02:22:11.620]   It's just going to be like me being like, but really, I mean, like,
[02:22:11.620 --> 02:22:15.620]   you're really, I watched, you know, I did watch line goes up.
[02:22:15.620 --> 02:22:19.780]   I mean, line goes up is this amazing YouTube video that like talks about the blockchain,
[02:22:19.780 --> 02:22:22.900]   NFTs, and it's one of like the best YouTube videos I've ever watched.
[02:22:22.900 --> 02:22:28.020]   So I did take a heck of a lot of notes and I will come armed with those notes.
[02:22:28.020 --> 02:22:31.060]   I watched a YouTube video and I am ready to debate.
[02:22:31.060 --> 02:22:33.300]   I'm not even ashamed to admit it is the truth.
[02:22:34.100 --> 02:22:36.740]   I'm ready to roll.
[02:22:36.740 --> 02:22:37.780]   It's a great video.
[02:22:37.780 --> 02:22:39.140]   Like, full of videos.
[02:22:39.140 --> 02:22:42.260]   And then I'm like, well, what else has this guy done?
[02:22:42.260 --> 02:22:44.100]   This is awesome.
[02:22:44.100 --> 02:22:50.260]   And then there's like, he has like a 10 hour video series on like analyzing the BDSM
[02:22:50.260 --> 02:22:51.380]   in Twilight.
[02:22:51.380 --> 02:22:53.780]   I'm like, what are you doing with this?
[02:22:53.780 --> 02:22:54.420]   What?
[02:22:54.420 --> 02:22:56.100]   You're for some different content.
[02:22:56.100 --> 02:22:58.660]   Oh, I have to play a little bit of this because.
[02:22:58.660 --> 02:22:59.140]   Oh, yeah.
[02:22:59.140 --> 02:23:00.260]   Oh, it's so good.
[02:23:00.260 --> 02:23:03.940]   Just do you have my other, if you watch line, if you watch line goes up.
[02:23:04.180 --> 02:23:05.300]   It's so good.
[02:23:05.300 --> 02:23:07.380]   Okay, I can't play it.
[02:23:07.380 --> 02:23:10.420]   I wish I could just watch it.
[02:23:10.420 --> 02:23:11.460]   This is the this is the one.
[02:23:11.460 --> 02:23:13.140]   This is the one with all the great quotes.
[02:23:13.140 --> 02:23:14.100]   They're hysterical.
[02:23:14.100 --> 02:23:16.500]   The line doesn't go up.
[02:23:16.500 --> 02:23:17.940]   That's the spoiler.
[02:23:17.940 --> 02:23:18.100]   Yeah.
[02:23:18.100 --> 02:23:19.300]   It's not the spoiler.
[02:23:19.300 --> 02:23:19.780]   Yeah.
[02:23:19.780 --> 02:23:20.020]   Yeah.
[02:23:20.020 --> 02:23:21.140]   Really good stuff.
[02:23:21.140 --> 02:23:22.420]   That and the legal eagle.
[02:23:22.420 --> 02:23:22.740]   Yeah.
[02:23:22.740 --> 02:23:24.580]   You then you set and you're set.
[02:23:24.580 --> 02:23:26.660]   Thank you, Alex.
[02:23:26.660 --> 02:23:28.180]   Brianna, we love you.
[02:23:28.180 --> 02:23:29.700]   Thank you so much for being here.
[02:23:29.700 --> 02:23:30.820]   Your voice is all better.
[02:23:30.820 --> 02:23:32.100]   It sounds great.
[02:23:32.100 --> 02:23:33.220]   It's mostly better.
[02:23:33.220 --> 02:23:36.580]   I've got a little bit more to heal, but it's a lot better than it has been.
[02:23:36.580 --> 02:23:37.540]   You look great.
[02:23:37.540 --> 02:23:38.500]   Things are going well.
[02:23:38.500 --> 02:23:40.660]   Tell us about rebellion pack.
[02:23:40.660 --> 02:23:42.820]   Rebellion pack.
[02:23:42.820 --> 02:23:44.740]   We have the midterms coming up.
[02:23:44.740 --> 02:23:46.740]   We're going to be supporting a lot of candidates.
[02:23:46.740 --> 02:23:47.220]   Now is the time.
[02:23:47.220 --> 02:23:47.220]   Yeah.
[02:23:47.220 --> 02:23:47.700]   This is not.
[02:23:47.700 --> 02:23:49.060]   Get out of vote.
[02:23:49.060 --> 02:23:51.460]   Do not let this stand.
[02:23:51.460 --> 02:23:52.420]   William, I'm sorry.
[02:23:52.420 --> 02:23:54.100]   No, no, no.
[02:23:54.100 --> 02:23:57.380]   I mean, it's not a this is not a political show.
[02:23:57.380 --> 02:23:59.620]   But I would imagine many of your listeners have watched
[02:23:59.620 --> 02:24:01.060]   events that have happened this week.
[02:24:01.060 --> 02:24:01.060]   Yes.
[02:24:01.060 --> 02:24:02.180]   That's intrepidation.
[02:24:02.180 --> 02:24:02.660]   Yes.
[02:24:02.660 --> 02:24:05.460]   If you want to, if you want to get involved,
[02:24:05.460 --> 02:24:06.980]   it's not enough just about
[02:24:06.980 --> 02:24:12.260]   you need to either run for office or donate to candidates or call.
[02:24:12.260 --> 02:24:13.700]   Should I avoid act blue?
[02:24:13.700 --> 02:24:15.220]   I feel like act blue.
[02:24:15.220 --> 02:24:17.300]   I don't should I just.
[02:24:17.300 --> 02:24:20.740]   I want to do a whole show with you, Leo.
[02:24:20.740 --> 02:24:25.140]   Sometimes talking about the ways that professional donors miss you
[02:24:25.140 --> 02:24:25.940]   your information.
[02:24:25.940 --> 02:24:26.580]   Thank you.
[02:24:26.580 --> 02:24:27.620]   Because thank you.
[02:24:27.620 --> 02:24:28.260]   I am.
[02:24:28.260 --> 02:24:32.740]   I will go on your show and take a lie detector test
[02:24:32.740 --> 02:24:36.660]   that I've never sold any information to anyone and never will.
[02:24:36.660 --> 02:24:41.860]   But there is a really cavalier attitude in my party
[02:24:41.860 --> 02:24:44.420]   and how we treat donors information.
[02:24:44.420 --> 02:24:47.140]   And it is so counterproductive.
[02:24:47.140 --> 02:24:47.940]   Plus because.
[02:24:47.940 --> 02:24:48.500]   I.
[02:24:48.500 --> 02:24:51.940]   There's dark patterns on the site that get you to do automatic.
[02:24:51.940 --> 02:24:52.820]   Yeah.
[02:24:52.820 --> 02:24:54.260]   Recurring donations.
[02:24:54.260 --> 02:24:57.220]   I was donating a thousand dollars a month for three months
[02:24:57.220 --> 02:24:57.940]   before I called it.
[02:24:57.940 --> 02:24:58.580]   Oh my god.
[02:24:58.580 --> 02:24:59.620]   I was a little upset.
[02:24:59.620 --> 02:25:03.300]   You know, I wanted the initial donation.
[02:25:03.300 --> 02:25:04.580]   I didn't want the subsequent,
[02:25:04.580 --> 02:25:06.660]   but I missed the little checkbox.
[02:25:06.660 --> 02:25:09.940]   And it was very upsetting.
[02:25:09.940 --> 02:25:11.060]   So yeah, so.
[02:25:11.060 --> 02:25:14.820]   We have some really we have some practices that are not
[02:25:14.820 --> 02:25:16.660]   justifiable in my opinion, but.
[02:25:16.660 --> 02:25:20.420]   So you can donate directly to rebellion pack at the website.
[02:25:20.420 --> 02:25:21.060]   Donate.
[02:25:21.060 --> 02:25:21.780]   Yes, you can.
[02:25:21.780 --> 02:25:23.860]   You can go to help the rebellion and do that.
[02:25:23.860 --> 02:25:25.540]   And I promise you, Leo will.
[02:25:26.100 --> 02:25:27.860]   Have words of me if I did this.
[02:25:27.860 --> 02:25:30.020]   We do not sell your information.
[02:25:30.020 --> 02:25:33.300]   I want to put up just one more quick thing, Leo.
[02:25:33.300 --> 02:25:35.780]   If any of your listeners are in Arizona,
[02:25:35.780 --> 02:25:37.700]   I have a really good friend of mine, Derek.
[02:25:37.700 --> 02:25:39.380]   He's actually a producer for.
[02:25:39.380 --> 02:25:41.940]   He's a producer for.
[02:25:41.940 --> 02:25:43.460]   What's the British car show?
[02:25:43.460 --> 02:25:44.660]   The really famous one.
[02:25:44.660 --> 02:25:45.140]   Oh, yeah.
[02:25:45.140 --> 02:25:46.980]   Yeah, but they have a new name.
[02:25:46.980 --> 02:25:48.580]   Oh god.
[02:25:48.580 --> 02:25:51.300]   I got four hours of sleep last night.
[02:25:51.300 --> 02:25:53.860]   Because we actually did workably well given your.
[02:25:53.860 --> 02:25:54.260]   Thank you.
[02:25:54.260 --> 02:25:55.220]   I appreciate that.
[02:25:55.220 --> 02:25:56.020]   Yeah.
[02:25:56.020 --> 02:25:57.940]   No, but I is a friend of mine.
[02:25:57.940 --> 02:25:59.140]   The British car show.
[02:25:59.140 --> 02:25:59.700]   With Sting.
[02:25:59.700 --> 02:26:00.660]   Yes, the British car.
[02:26:00.660 --> 02:26:01.140]   Yeah.
[02:26:01.140 --> 02:26:01.780]   Top gear.
[02:26:01.780 --> 02:26:02.340]   Top gear.
[02:26:02.340 --> 02:26:02.820]   Top gear.
[02:26:02.820 --> 02:26:08.020]   His mother, unfortunately, is 80 years old.
[02:26:08.020 --> 02:26:09.380]   She suffers from dementia.
[02:26:09.380 --> 02:26:12.100]   She left the house on Thursdays.
[02:26:12.100 --> 02:26:13.780]   We've been missing ever since.
[02:26:13.780 --> 02:26:17.780]   I've been donating a lot of time working to get people down there
[02:26:17.780 --> 02:26:20.500]   to get volunteers from the search and rescue effort.
[02:26:20.500 --> 02:26:24.180]   Actually, talking about good use of ad technology.
[02:26:24.180 --> 02:26:27.460]   We've been using the technology of micro-targeting ads
[02:26:27.460 --> 02:26:30.500]   to help get together people to go down there
[02:26:30.500 --> 02:26:34.500]   and basically scour to go hiking to try to go find her.
[02:26:34.500 --> 02:26:38.100]   If any Twitch listeners are interested in that,
[02:26:38.100 --> 02:26:39.540]   please reach out to me.
[02:26:39.540 --> 02:26:41.700]   I will happily put you in touch.
[02:26:41.700 --> 02:26:44.340]   Obviously, it has to be 100 degrees in Phoenix.
[02:26:44.340 --> 02:26:46.900]   Time is short, so we would really appreciate your help.
[02:26:46.900 --> 02:26:47.460]   Oh, golly.
[02:26:47.460 --> 02:26:50.180]   So just @briannawoo on Twitter.
[02:26:50.180 --> 02:26:50.740]   Yep.
[02:26:50.740 --> 02:26:51.940]   Just shoot me a tweet.
[02:26:51.940 --> 02:26:53.940]   I'll be happy to point you in the right direction.
[02:26:53.940 --> 02:26:54.420]   Wow.
[02:26:54.420 --> 02:26:55.620]   Wow.
[02:26:55.620 --> 02:26:57.220]   Yeah.
[02:26:57.220 --> 02:26:58.420]   That's something to do for Mother's Day.
[02:26:58.420 --> 02:26:59.700]   Yeah.
[02:26:59.700 --> 02:27:00.020]   Wow.
[02:27:00.020 --> 02:27:01.780]   All right.
[02:27:01.780 --> 02:27:08.020]   Kiss your mom, hug her, hold her tight because she's, I hope, still with you.
[02:27:08.020 --> 02:27:08.980]   And if not--
[02:27:08.980 --> 02:27:09.380]   I do too.
[02:27:09.380 --> 02:27:10.820]   Remember.
[02:27:10.820 --> 02:27:12.660]   Thank you, Brianna.
[02:27:12.660 --> 02:27:13.380]   Thank you, Alex.
[02:27:13.380 --> 02:27:15.620]   Thank you to all of you who watch and listen.
[02:27:15.620 --> 02:27:16.420]   We appreciate it.
[02:27:16.420 --> 02:27:18.740]   If you want to watch us do it live.
[02:27:18.740 --> 02:27:21.140]   It's always interesting when we're live, by the way.
[02:27:22.180 --> 02:27:25.940]   Not quite the same show you're going to get in the final polished edition.
[02:27:25.940 --> 02:27:31.220]   You can do it at 2 p.m. Pacific, 5 p.m. Eastern, 2100 UTC every Sunday evening,
[02:27:31.220 --> 02:27:36.180]   the live stream, audio or video live.tuit.tv.
[02:27:36.180 --> 02:27:40.820]   After the fact, all of our shows are available at the website, twit.tv.
[02:27:40.820 --> 02:27:44.100]   Or on the YouTube channel, each show has its own dedicated YouTube channel,
[02:27:44.100 --> 02:27:44.980]   where you can watch the video.
[02:27:44.980 --> 02:27:46.580]   We have audio and video of every show.
[02:27:46.580 --> 02:27:50.500]   Best thing to do is search for Twit on your favorite podcast app
[02:27:50.500 --> 02:27:52.980]   and subscribe to every single darn show.
[02:27:52.980 --> 02:27:56.500]   That would be the best thing to do.
[02:27:56.500 --> 02:27:57.940]   Thank you so much for listening.
[02:27:57.940 --> 02:28:00.660]   We will see you next time on another Twit.
[02:28:00.660 --> 02:28:01.140]   Isn't it?
[02:28:01.140 --> 02:28:01.620]   It's amazing.
[02:28:01.620 --> 02:28:13.780]   Bye bye.

