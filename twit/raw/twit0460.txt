;FFMETADATA1
title=Drones Delivering Diapers
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=460
genre=Podcast
comment=http://www.twit.tv/twit
copyright=These netcasts are released under a Creative Commons Attribution Non-Commercial Share-Alike license. TWiT and TWiT Logo are registered trademarks of Leo Laporte
publisher=TWiT
date=2014
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:03.200]   It's time for Twit, this weekend tech.
[00:00:03.200 --> 00:00:04.200]   Leo's out today.
[00:00:04.200 --> 00:00:05.600]   I'm Mike Elgin filling in for him.
[00:00:05.600 --> 00:00:07.600]   We have the technologizer, Harry McCracken.
[00:00:07.600 --> 00:00:10.560]   He's here, along with CNET's Lindsey Turntine
[00:00:10.560 --> 00:00:12.960]   and Katie Benner from The Information.
[00:00:12.960 --> 00:00:14.800]   We talk about major moves by Apple,
[00:00:14.800 --> 00:00:17.080]   including Beats, Healthbook, Smart Homes,
[00:00:17.080 --> 00:00:19.520]   and what's going to happen at WWDC this week.
[00:00:19.520 --> 00:00:23.520]   Plus, Google's crazy car and Microsoft's crazy smartwatch.
[00:00:23.520 --> 00:00:25.680]   It's all coming up right now on Twit.
[00:00:25.680 --> 00:00:28.120]   (electronic music)
[00:00:28.120 --> 00:00:30.200]   That casts you love.
[00:00:30.200 --> 00:00:31.720]   From people you trust.
[00:00:31.720 --> 00:00:36.880]   This is Twit.
[00:00:36.880 --> 00:00:41.160]   Bandwidth for this weekend tech is provided by CashFly
[00:00:41.160 --> 00:00:44.360]   at C-A-C-H-E-F-L-Y.com.
[00:00:44.360 --> 00:00:52.680]   This is Twit, this weekend tech episode 460
[00:00:52.680 --> 00:00:55.440]   recorded June 1st, 2014.
[00:00:55.440 --> 00:00:57.800]   Drones delivering diapers.
[00:00:57.800 --> 00:01:00.480]   This weekend tech is brought to you by Stamps.com.
[00:01:00.480 --> 00:01:03.360]   Start using your time more effectively, Stamps.com.
[00:01:03.360 --> 00:01:06.520]   You Stamps.com to buy and print real US postage,
[00:01:06.520 --> 00:01:08.720]   an instant you need it right from your desk.
[00:01:08.720 --> 00:01:11.040]   To get our special offer, go to Stamps.com now,
[00:01:11.040 --> 00:01:13.200]   click on the microphone and enter Twit.
[00:01:13.200 --> 00:01:16.840]   That's Stamps.com and enter Twit.
[00:01:16.840 --> 00:01:18.040]   And buy Audible.com.
[00:01:18.040 --> 00:01:19.960]   Sign up for the platinum plan and get two free books.
[00:01:19.960 --> 00:01:23.120]   Go to Audible.com/Twit2.
[00:01:23.120 --> 00:01:25.640]   Follow Audible on Twitter, user ID Audible,
[00:01:25.640 --> 00:01:27.320]   underscore COM.
[00:01:27.320 --> 00:01:28.840]   And by personal capital, you'll finally
[00:01:28.840 --> 00:01:31.240]   have all your financial life in one place,
[00:01:31.240 --> 00:01:33.400]   get a clear picture of everything you own.
[00:01:33.400 --> 00:01:35.080]   Best of all, it's free.
[00:01:35.080 --> 00:01:39.480]   Sign up, go to personalcapital.com/Twit.
[00:01:39.480 --> 00:01:41.880]   And by Carbonite, whether you have one computer at home
[00:01:41.880 --> 00:01:44.160]   or several at your small business, Carbonite backs up
[00:01:44.160 --> 00:01:47.120]   your files to the cloud automatically and continually.
[00:01:47.120 --> 00:01:50.040]   Plus access your files anytime, anywhere with a free app.
[00:01:50.040 --> 00:01:52.120]   Start your free trial at carbonite.com.
[00:01:52.120 --> 00:01:53.240]   No credit card required.
[00:01:53.240 --> 00:01:58.640]   Use offer code Twit to get two bonus months with purchase.
[00:01:58.640 --> 00:02:00.760]   It's time for Twit, this week in Tech,
[00:02:00.760 --> 00:02:03.520]   the show where we talk tech with some of the smartest people
[00:02:03.520 --> 00:02:04.720]   we can find.
[00:02:04.720 --> 00:02:07.040]   My name is Mike Elgin, Twit's News Director.
[00:02:07.040 --> 00:02:09.640]   And I'm subbing for Leela Port, who's off today.
[00:02:09.640 --> 00:02:13.640]   And we have a fantastic team of brilliant people,
[00:02:13.640 --> 00:02:17.840]   hands picked by me personally, starting with the technologizer
[00:02:17.840 --> 00:02:18.520]   Harry McCracken.
[00:02:18.520 --> 00:02:19.120]   Welcome, Harry.
[00:02:19.120 --> 00:02:19.600]   Thanks, Mike.
[00:02:19.600 --> 00:02:20.560]   It's great to be here.
[00:02:20.560 --> 00:02:23.640]   Now, before we introduce the other people on the show,
[00:02:23.640 --> 00:02:25.520]   I want to ask you about the technologizer,
[00:02:25.520 --> 00:02:27.520]   because this site is now reborn.
[00:02:27.520 --> 00:02:30.800]   You've been famously with Time.com for quite a while,
[00:02:30.800 --> 00:02:32.880]   bringing a lot of street cred to that publication,
[00:02:32.880 --> 00:02:33.840]   in my opinion.
[00:02:33.840 --> 00:02:36.040]   And now you're branching back out on your own.
[00:02:36.040 --> 00:02:38.000]   You re-energizing the technologizer.
[00:02:38.000 --> 00:02:39.680]   Tell us what you're going to do with that site.
[00:02:39.680 --> 00:02:41.200]   Well, I'm kind of going back to basics.
[00:02:41.200 --> 00:02:43.640]   I was at time for a little over two years.
[00:02:43.640 --> 00:02:45.960]   And technologizer was part of Time.com.
[00:02:45.960 --> 00:02:50.280]   So it was a tiny island and an extremely large ocean
[00:02:50.280 --> 00:02:51.600]   of content.
[00:02:51.600 --> 00:02:55.440]   And I decided to leave Time recently.
[00:02:55.440 --> 00:02:57.760]   And the cool thing was I was able to take technologizer back
[00:02:57.760 --> 00:03:01.000]   with me, and I put it back in WordPress.
[00:03:01.000 --> 00:03:03.400]   I mean, one of the cool things about being a journalist today
[00:03:03.400 --> 00:03:06.240]   is you can work for a large media company,
[00:03:06.240 --> 00:03:08.640]   but you can also reach a lot of people on your own.
[00:03:08.640 --> 00:03:12.200]   So I put together a new design.
[00:03:12.200 --> 00:03:13.920]   It's not going to be completely different
[00:03:13.920 --> 00:03:16.000]   from what I did at Time or what I did when it was--
[00:03:16.000 --> 00:03:17.640]   technologizer was a standalone brand.
[00:03:17.640 --> 00:03:21.600]   But I'm going to try even less hard to kind of be a news
[00:03:21.600 --> 00:03:22.880]   destination.
[00:03:22.880 --> 00:03:25.720]   There are all kinds of sites such as CNET and The Verge
[00:03:25.720 --> 00:03:29.920]   and others who are better for news than I can ever be on my own.
[00:03:29.920 --> 00:03:32.720]   But I think I'm pretty good at analysis and insight.
[00:03:32.720 --> 00:03:36.240]   And so I call it slow-cooked content.
[00:03:36.240 --> 00:03:39.120]   I'm not going to try to do 40 posts a day.
[00:03:39.120 --> 00:03:42.160]   I'm going to point people towards good posts elsewhere.
[00:03:42.160 --> 00:03:43.840]   And I'll do relatively little content,
[00:03:43.840 --> 00:03:46.760]   but hopefully of high enough value that people will notice it.
[00:03:46.760 --> 00:03:48.640]   And that's really one of the Uber trends that's
[00:03:48.640 --> 00:03:51.200]   making tech journalism and journalism in general so
[00:03:51.200 --> 00:03:54.040]   great these days, because people like you
[00:03:54.040 --> 00:03:56.600]   are leaving the big mainstream publications,
[00:03:56.600 --> 00:04:00.720]   and they're branching out into sort of these kind of startup
[00:04:00.720 --> 00:04:04.640]   mode operations ranging in size from the information--
[00:04:04.640 --> 00:04:05.760]   and we're going to talk about the information.
[00:04:05.760 --> 00:04:07.560]   And tech-- technologizer, and then
[00:04:07.560 --> 00:04:09.000]   doing the more in-depth reporting.
[00:04:09.000 --> 00:04:12.440]   And it's getting to the point where I think technology
[00:04:12.440 --> 00:04:17.000]   journalism is actually becoming one of the best forms,
[00:04:17.000 --> 00:04:18.720]   the highest quality forms of journalism.
[00:04:18.720 --> 00:04:20.800]   It's also-- there's a lot of garbage out there.
[00:04:20.800 --> 00:04:23.400]   Let's face it, but there's such good journalism these days.
[00:04:23.400 --> 00:04:24.760]   So I'm really excited about that.
[00:04:24.760 --> 00:04:29.160]   And the truth is that people don't go to time.com
[00:04:29.160 --> 00:04:31.280]   and say, I want to go to time.com because they
[00:04:31.280 --> 00:04:33.960]   have the best technology coverage.
[00:04:33.960 --> 00:04:37.160]   They go, I'm going to go read Harry McCracken.
[00:04:37.160 --> 00:04:39.760]   The individual calmness and analysts
[00:04:39.760 --> 00:04:41.480]   are the brand these days.
[00:04:41.480 --> 00:04:43.080]   And so it's great.
[00:04:43.080 --> 00:04:44.440]   You're going to bring your audience with you.
[00:04:44.440 --> 00:04:46.240]   And I'm really looking forward to seeing what you do.
[00:04:46.240 --> 00:04:47.680]   And an awfully high percentage of them
[00:04:47.680 --> 00:04:49.920]   when they go to content is because their friends or people
[00:04:49.920 --> 00:04:53.800]   they trust told them about it on Twitter or Facebook or Google
[00:04:53.800 --> 00:04:55.920]   Plus.
[00:04:55.920 --> 00:04:57.520]   So while time was a great place to be,
[00:04:57.520 --> 00:04:59.920]   I feel like the entire web is the front door
[00:04:59.920 --> 00:05:02.640]   to technologizer if my content is good enough.
[00:05:02.640 --> 00:05:03.120]   Absolutely.
[00:05:03.120 --> 00:05:04.120]   And it will be, I'm sure.
[00:05:04.120 --> 00:05:05.600]   I've been following you for a long time.
[00:05:05.600 --> 00:05:08.240]   You and I go way back to the PC Magazine Wars.
[00:05:08.240 --> 00:05:09.880]   They're all magazine days.
[00:05:09.880 --> 00:05:12.320]   You and I were both competing against PCMag, which
[00:05:12.320 --> 00:05:13.920]   was the 800 pound gorilla.
[00:05:13.920 --> 00:05:15.720]   But anyway, welcome and congratulations.
[00:05:15.720 --> 00:05:16.280]   Thank you, Mike.
[00:05:16.280 --> 00:05:16.880]   All right.
[00:05:16.880 --> 00:05:19.200]   Also joining us today is Lindsey Turrentine,
[00:05:19.200 --> 00:05:21.520]   editor in chief of CNET Reviews.
[00:05:21.520 --> 00:05:24.360]   Lindsey came all the way from slightly south.
[00:05:24.360 --> 00:05:25.320]   From Berkeley.
[00:05:25.320 --> 00:05:26.960]   Yeah, just a little ways.
[00:05:26.960 --> 00:05:29.240]   And so what have you been working on lately?
[00:05:29.240 --> 00:05:30.680]   You've been in the business for a while.
[00:05:30.680 --> 00:05:32.480]   And we've had you on Tech News today a bunch of times.
[00:05:32.480 --> 00:05:34.480]   And you are fantastic on that show.
[00:05:34.480 --> 00:05:36.200]   You seem to know everything.
[00:05:36.200 --> 00:05:37.560]   Well, that's my job.
[00:05:37.560 --> 00:05:38.920]   I have to know everything.
[00:05:38.920 --> 00:05:42.000]   We're working on a lot of exciting things.
[00:05:42.000 --> 00:05:43.720]   Some of the most exciting stuff that we've done recently
[00:05:43.720 --> 00:05:46.960]   is launching it in Español close to a year ago.
[00:05:46.960 --> 00:05:49.400]   Getting close to a year ago, and it's growing and growing.
[00:05:49.400 --> 00:05:53.680]   And now is the largest tech site in Spanish.
[00:05:53.680 --> 00:05:54.240]   That's fantastic.
[00:05:54.240 --> 00:05:55.720]   In the US, which is really exciting,
[00:05:55.720 --> 00:05:56.760]   has been a fun project.
[00:05:56.760 --> 00:05:59.200]   And we're doing a lot of really interesting stuff
[00:05:59.200 --> 00:06:01.400]   about the Connected Home.
[00:06:01.400 --> 00:06:03.680]   So we cover appliances already in a big way.
[00:06:03.680 --> 00:06:06.120]   And we have this facility in Kentucky where we do that.
[00:06:06.120 --> 00:06:07.640]   We're doing some really interesting stuff
[00:06:07.640 --> 00:06:08.840]   that we're going to be talking about soon.
[00:06:08.840 --> 00:06:09.520]   Yeah.
[00:06:09.520 --> 00:06:12.240]   I bet in the sort of home automation world
[00:06:12.240 --> 00:06:14.440]   is really about to take off.
[00:06:14.440 --> 00:06:16.320]   And I think that's really going to be launched
[00:06:16.320 --> 00:06:18.560]   in the stratosphere tomorrow.
[00:06:18.560 --> 00:06:20.280]   And we'll talk about that later in the show.
[00:06:20.280 --> 00:06:21.600]   But that's really exciting.
[00:06:21.600 --> 00:06:24.080]   You guys are all over that because that's really going
[00:06:24.080 --> 00:06:25.840]   to be a major, major thing that all of us
[00:06:25.840 --> 00:06:27.640]   are going to be talking about in the next few years.
[00:06:27.640 --> 00:06:28.600]   It's a very exciting time.
[00:06:28.600 --> 00:06:28.800]   All right.
[00:06:28.800 --> 00:06:30.680]   Well, welcome to TWIT.
[00:06:30.680 --> 00:06:33.600]   And we also have Skyping In all the way
[00:06:33.600 --> 00:06:36.800]   from San Francisco, California, a few miles south.
[00:06:36.800 --> 00:06:39.120]   Katie Benner, who is a reporter for the information.
[00:06:39.120 --> 00:06:40.840]   Welcome, Katie.
[00:06:40.840 --> 00:06:42.440]   Hey, thanks for having me.
[00:06:42.440 --> 00:06:45.400]   Now, you're with one of the entrepreneurial poster
[00:06:45.400 --> 00:06:48.800]   children of the new age of technology journalism,
[00:06:48.800 --> 00:06:51.800]   the information launched by Jessica Lesson.
[00:06:51.800 --> 00:06:53.840]   And how is that going for you guys?
[00:06:53.840 --> 00:06:56.360]   You seem to be cranking out some pretty awesome stories
[00:06:56.360 --> 00:06:57.880]   and making a lot of--
[00:06:57.880 --> 00:06:59.480]   sort of getting a lot of attention
[00:06:59.480 --> 00:07:02.000]   and generating a lot of scoops.
[00:07:02.000 --> 00:07:04.840]   What's it like to work for one of these entrepreneurial
[00:07:04.840 --> 00:07:07.480]   journalism startups?
[00:07:07.480 --> 00:07:09.320]   It's really, really great.
[00:07:09.320 --> 00:07:12.960]   The pace is incredibly fast because not only are we
[00:07:12.960 --> 00:07:15.000]   reporting on news, it's changing all the time.
[00:07:15.000 --> 00:07:17.400]   And the tech industry is so innovative and changing
[00:07:17.400 --> 00:07:18.640]   all the time.
[00:07:18.640 --> 00:07:20.520]   As anybody who has ever worked at a startup
[00:07:20.520 --> 00:07:22.760]   can tell you, the actual business itself
[00:07:22.760 --> 00:07:25.600]   seems to become a new company kind of every four weeks.
[00:07:25.600 --> 00:07:27.000]   You grow and you learn.
[00:07:27.000 --> 00:07:30.320]   And you're always incorporating new information
[00:07:30.320 --> 00:07:32.280]   and new ideas about how to run your business.
[00:07:32.280 --> 00:07:35.840]   So this is incredibly good.
[00:07:35.840 --> 00:07:37.400]   It's a good bootcamp for anybody who really
[00:07:37.400 --> 00:07:41.440]   wants to understand how to make the media industry a better
[00:07:41.440 --> 00:07:44.240]   place and more profitable, et cetera, et cetera.
[00:07:44.240 --> 00:07:45.840]   So you're writing exciting stories.
[00:07:45.840 --> 00:07:46.680]   We love it.
[00:07:46.680 --> 00:07:47.320]   Yes, you are.
[00:07:47.320 --> 00:07:50.040]   And you personally have a background
[00:07:50.040 --> 00:07:51.920]   in financial and business journalism.
[00:07:51.920 --> 00:07:53.440]   Is that right?
[00:07:53.440 --> 00:07:54.040]   That's right.
[00:07:54.040 --> 00:07:57.520]   So I was at Fortune Magazine for seven years
[00:07:57.520 --> 00:07:58.640]   covering Wall Street.
[00:07:58.640 --> 00:08:01.760]   So it started out as kind of a fun,
[00:08:01.760 --> 00:08:03.800]   be actually much like covering tech today
[00:08:03.800 --> 00:08:06.920]   is where it's exciting and things are changing a lot.
[00:08:06.920 --> 00:08:09.800]   And you just hear about new, new, new growth, growth, growth.
[00:08:09.800 --> 00:08:11.560]   And then suddenly the financial crisis happened
[00:08:11.560 --> 00:08:15.600]   and it became this extraordinarily fascinating thing
[00:08:15.600 --> 00:08:19.240]   to look at, to re-examine all the assumptions that people
[00:08:19.240 --> 00:08:22.800]   had had leading into 2008 and late 2007.
[00:08:22.800 --> 00:08:26.000]   And the things that people had missed
[00:08:26.000 --> 00:08:30.760]   because they were just awash in growth and optimism
[00:08:30.760 --> 00:08:32.320]   about what was happening on Wall Street.
[00:08:32.320 --> 00:08:36.000]   So this feels like a very interesting time
[00:08:36.000 --> 00:08:37.760]   to be covering tech.
[00:08:37.760 --> 00:08:39.640]   There are some similarities, for sure.
[00:08:39.640 --> 00:08:40.320]   Yeah, absolutely.
[00:08:40.320 --> 00:08:42.320]   It is a fascinating time and really enjoying
[00:08:42.320 --> 00:08:44.480]   what you guys are doing at the information.
[00:08:44.480 --> 00:08:46.000]   Well, let's launch into the show.
[00:08:46.000 --> 00:08:47.400]   Shall we?
[00:08:47.400 --> 00:08:50.040]   Let's start with the wackiest story, I think, of the week,
[00:08:50.040 --> 00:08:54.240]   which is Google's funky little clown car, Harry McCock.
[00:08:54.240 --> 00:08:54.800]   And what do you think?
[00:08:54.800 --> 00:08:59.240]   Why did they actually trot out a car that has no steering wheel
[00:08:59.240 --> 00:09:01.760]   as a way to make people feel more comfortable
[00:09:01.760 --> 00:09:03.400]   about self-driving cars?
[00:09:03.400 --> 00:09:06.400]   Well, I was fascinated by it because a couple of weeks
[00:09:06.400 --> 00:09:09.320]   before that news came out, they had their first big event
[00:09:09.320 --> 00:09:12.640]   for their earlier self-driving cars, which
[00:09:12.640 --> 00:09:17.400]   were converted Lexus SUVs, which had steering wheels and brakes
[00:09:17.400 --> 00:09:19.160]   and everything.
[00:09:19.160 --> 00:09:21.480]   And so I thought I was up to date on what they were doing.
[00:09:21.480 --> 00:09:24.200]   And then it turned out that actually, no,
[00:09:24.200 --> 00:09:25.760]   they had concluded that that was never
[00:09:25.760 --> 00:09:28.280]   really not going to work as a model for this.
[00:09:28.280 --> 00:09:31.400]   And they had been secretly building an entire car
[00:09:31.400 --> 00:09:35.240]   from scratch to be self-driving, which I have to say,
[00:09:35.240 --> 00:09:36.560]   I haven't been in that yet.
[00:09:36.560 --> 00:09:38.840]   But one of the things that was comforting about being
[00:09:38.840 --> 00:09:42.680]   in the Lexus was because there were two Google engineers
[00:09:42.680 --> 00:09:43.920]   in the front seat.
[00:09:43.920 --> 00:09:45.520]   Licensed drivers, what a concept.
[00:09:45.520 --> 00:09:47.480]   And they frequently explained to us
[00:09:47.480 --> 00:09:51.440]   that the whole idea was whenever the car came into danger
[00:09:51.440 --> 00:09:52.640]   or something where you kind of did not
[00:09:52.640 --> 00:09:55.800]   want your car making decisions, no problem.
[00:09:55.800 --> 00:09:57.800]   There was somebody at the wheel who could take over
[00:09:57.800 --> 00:10:02.160]   in the blink of an eye and steer you through it.
[00:10:02.160 --> 00:10:04.000]   And of course, these cars are going to have--
[00:10:04.000 --> 00:10:05.920]   they're going to build 100 prototypes, they say.
[00:10:05.920 --> 00:10:08.600]   And those prototypes will have steering wheels and brakes,
[00:10:08.600 --> 00:10:11.200]   the kinds of things that you want to be in a car.
[00:10:11.200 --> 00:10:15.800]   And the video, I thought, was kind of disingenuous in a way.
[00:10:15.800 --> 00:10:16.840]   It has a single button.
[00:10:16.840 --> 00:10:19.720]   So in this particular prototype, you push a button
[00:10:19.720 --> 00:10:22.800]   and it goes somewhere, and you push a button
[00:10:22.800 --> 00:10:25.480]   if you want it to stop if a squirrel runs out the road
[00:10:25.480 --> 00:10:26.640]   or something like that.
[00:10:26.640 --> 00:10:28.560]   And it's like, well, wait a minute,
[00:10:28.560 --> 00:10:31.400]   how do you even tell it where to go?
[00:10:31.400 --> 00:10:33.720]   I understand that you can do this in a parking lot,
[00:10:33.720 --> 00:10:37.880]   but it just seemed like they didn't really
[00:10:37.880 --> 00:10:40.880]   braise the basic issues of how this thing works.
[00:10:40.880 --> 00:10:45.880]   They just showed how cool it is for people getting excited,
[00:10:45.880 --> 00:10:47.840]   driving around in a parking lot.
[00:10:47.840 --> 00:10:48.960]   Lindsay Turnheim, what do you think?
[00:10:48.960 --> 00:10:51.040]   Was this-- yeah, I mean, they're obviously excited.
[00:10:51.040 --> 00:10:51.600]   But--
[00:10:51.600 --> 00:10:53.080]   Well, this is Google's way, right?
[00:10:53.080 --> 00:10:56.360]   To just start with an idea and kind of just throw it out there
[00:10:56.360 --> 00:10:57.720]   and say, start thinking about this,
[00:10:57.720 --> 00:10:59.520]   start to think about what this could be like
[00:10:59.520 --> 00:11:01.640]   and get people's imaginations going.
[00:11:01.640 --> 00:11:04.000]   And I think Google is--
[00:11:04.000 --> 00:11:06.120]   at its very base, it's all about the data.
[00:11:06.120 --> 00:11:09.320]   So they're seeing a future in which data drives your car.
[00:11:09.320 --> 00:11:10.440]   You tell it where you want to go,
[00:11:10.440 --> 00:11:12.680]   and it just does all the thinking for you.
[00:11:12.680 --> 00:11:18.040]   I think that there's a very long list of cultural problems
[00:11:18.040 --> 00:11:19.880]   that Google has to get over, and they know that.
[00:11:19.880 --> 00:11:21.640]   So they're trying to start early.
[00:11:21.640 --> 00:11:23.840]   But the thing that I've been thinking about a ton
[00:11:23.840 --> 00:11:28.440]   is that, let's say that this gets used in a small capacity.
[00:11:28.440 --> 00:11:30.880]   And we start using these for essentially Uber.
[00:11:30.880 --> 00:11:32.960]   You call one, and it takes you across the city,
[00:11:32.960 --> 00:11:37.600]   not on a 50-mile trip, but just to the grocery store.
[00:11:37.600 --> 00:11:40.640]   But what happens if you do need to take over at some point?
[00:11:40.640 --> 00:11:44.040]   And if this became a huge cultural norm,
[00:11:44.040 --> 00:11:46.880]   how do people get the hundreds of hours behind the wheel
[00:11:46.880 --> 00:11:50.440]   that they need to be able to take over safely when they have to?
[00:11:50.440 --> 00:11:54.800]   Because I don't think we're all going to be in self-driving cars
[00:11:54.800 --> 00:11:55.800]   in 10 years.
[00:11:55.800 --> 00:11:57.440]   It's going to take a lot longer than that.
[00:11:57.440 --> 00:11:59.840]   Yeah, well, I tend to think that it's
[00:11:59.840 --> 00:12:01.280]   going to be a kind of gradual thing.
[00:12:01.280 --> 00:12:04.000]   We're looking at super cruise control.
[00:12:04.000 --> 00:12:04.840]   Yeah, exactly.
[00:12:04.840 --> 00:12:06.640]   We've already got that to a certain extent.
[00:12:06.640 --> 00:12:09.840]   High-end cars, rich people are much safer than poor people
[00:12:09.840 --> 00:12:12.120]   because they can buy one of these high-end cars.
[00:12:12.120 --> 00:12:14.120]   And if somebody signs on the break in front of you--
[00:12:14.120 --> 00:12:17.280]   in fact, Vicndotra, of all people,
[00:12:17.280 --> 00:12:19.920]   did a commercial for one of the big car companies.
[00:12:19.920 --> 00:12:21.560]   I don't know if you remember that-- where you said,
[00:12:21.560 --> 00:12:23.360]   oh, this car saved my life because I
[00:12:23.360 --> 00:12:25.680]   wasn't paying attention and the car in front of me
[00:12:25.680 --> 00:12:27.160]   slammed on the brakes.
[00:12:27.160 --> 00:12:29.200]   And the car automatically slammed on the brakes.
[00:12:29.200 --> 00:12:30.040]   Yeah, for sure.
[00:12:30.040 --> 00:12:33.880]   And so that kind of thing is actually
[00:12:33.880 --> 00:12:36.440]   easy to do relative to the self-driving car thing.
[00:12:36.440 --> 00:12:39.840]   Because the self-driving car thing is all about maps
[00:12:39.840 --> 00:12:41.520]   and sophisticated maps.
[00:12:41.520 --> 00:12:45.400]   Yes, Google has completely mastered Mountain View, California.
[00:12:45.400 --> 00:12:46.480]   Oh, it's great in Mountain View?
[00:12:46.480 --> 00:12:47.680]   Yeah.
[00:12:47.680 --> 00:12:49.160]   But I love them probably not so much.
[00:12:49.160 --> 00:12:50.520]   Yeah.
[00:12:50.520 --> 00:12:55.680]   And we're talking about a couple of thousand miles of road
[00:12:55.680 --> 00:12:56.280]   that they've mapped.
[00:12:56.280 --> 00:12:58.200]   And in fact, there are millions and millions and millions
[00:12:58.200 --> 00:12:59.720]   of miles of roads yet to map.
[00:12:59.720 --> 00:13:02.520]   And of course, lots of companies are working on this kind
[00:13:02.520 --> 00:13:03.160]   of technology.
[00:13:03.160 --> 00:13:04.720]   All the car companies are working on it.
[00:13:04.720 --> 00:13:08.000]   I personally think that this car has two purposes.
[00:13:08.000 --> 00:13:11.240]   The first is to show that you can't just slap electronics
[00:13:11.240 --> 00:13:14.360]   on the roof of a pryus.
[00:13:14.360 --> 00:13:16.560]   You need sensors down below.
[00:13:16.560 --> 00:13:18.960]   You need it the whole car purpose built for self-driving
[00:13:18.960 --> 00:13:20.120]   if you really want to do it right.
[00:13:20.120 --> 00:13:22.160]   And the second thing is-- I mean, look at this thing.
[00:13:22.160 --> 00:13:23.520]   It has a face on it.
[00:13:23.520 --> 00:13:24.920]   I mean, who can stay mad at this car?
[00:13:24.920 --> 00:13:28.640]   It's like, they're trying to make it so warm and fuzzy
[00:13:28.640 --> 00:13:30.560]   that when they go to--
[00:13:30.560 --> 00:13:35.840]   This is the not-- it's the opposite of the muscle car
[00:13:35.840 --> 00:13:38.720]   experience that we all get advertised to us all the time.
[00:13:38.720 --> 00:13:40.640]   And I think that's what Google's trying to go after.
[00:13:40.640 --> 00:13:42.520]   Like, hey, this is not-- we're not trying to replace
[00:13:42.520 --> 00:13:44.760]   your amazing driving experience.
[00:13:44.760 --> 00:13:45.720]   This is functional.
[00:13:45.720 --> 00:13:47.600]   It's something that will make things easier for you.
[00:13:47.600 --> 00:13:48.640]   And it'll be fun.
[00:13:48.640 --> 00:13:50.440]   Like, if you're not a person who loves driving
[00:13:50.440 --> 00:13:51.760]   or you're a person who needs convenience,
[00:13:51.760 --> 00:13:54.440]   then you want to just text in the car,
[00:13:54.440 --> 00:13:56.840]   you can do that safely because you won't be driving.
[00:13:56.840 --> 00:13:57.800]   Yeah, exactly.
[00:13:57.800 --> 00:14:00.280]   And of course, anything that the self-driving car does,
[00:14:00.280 --> 00:14:04.160]   you run over an old lady, you hit a dog, whatever it is that you
[00:14:04.160 --> 00:14:06.760]   do, whatever it is the car does, whatever it is.
[00:14:06.760 --> 00:14:08.840]   Google's algorithms do, frankly.
[00:14:08.840 --> 00:14:10.160]   You're going to be liable.
[00:14:10.160 --> 00:14:12.040]   When these things hit the road, you're
[00:14:12.040 --> 00:14:14.280]   not going to be able to sit there and drinking scotch
[00:14:14.280 --> 00:14:16.600]   and playing backgammon and just not even
[00:14:16.600 --> 00:14:17.600]   worry about what's going on.
[00:14:17.600 --> 00:14:18.400]   You're going to be liable.
[00:14:18.400 --> 00:14:19.160]   I know.
[00:14:19.160 --> 00:14:21.000]   That's the bad news.
[00:14:21.000 --> 00:14:25.200]   I think this is where the data comes into play.
[00:14:25.200 --> 00:14:28.000]   Because I think that one thing that all of the self-driving
[00:14:28.000 --> 00:14:30.080]   car people are thinking about Google especially,
[00:14:30.080 --> 00:14:31.480]   and then even some of the automakers,
[00:14:31.480 --> 00:14:33.640]   is how do we make this the norm?
[00:14:33.640 --> 00:14:35.640]   And I think the way they do it is by getting
[00:14:35.640 --> 00:14:37.400]   the insurance companies on board.
[00:14:37.400 --> 00:14:39.680]   So the insurance companies are very, very concerned
[00:14:39.680 --> 00:14:40.160]   about data.
[00:14:40.160 --> 00:14:45.200]   And if data can prove that it's cheaper and safer
[00:14:45.200 --> 00:14:46.320]   for the insurance companies, they're
[00:14:46.320 --> 00:14:49.360]   going to encourage more and more and more automation
[00:14:49.360 --> 00:14:50.400]   in vehicles.
[00:14:50.400 --> 00:14:54.680]   And so we'll be pushed along as a public to accept technology
[00:14:54.680 --> 00:14:57.400]   that we might feel is kind of icky right now,
[00:14:57.400 --> 00:14:58.560]   just because it will be cheaper.
[00:14:58.560 --> 00:15:02.280]   I saw a really fascinating speech given by Dan Gere, who
[00:15:02.280 --> 00:15:03.640]   is over at Inkutel.
[00:15:03.640 --> 00:15:04.520]   And he's done a lot--
[00:15:04.520 --> 00:15:07.600]   he's just one of these guys who thinks about big tech problems.
[00:15:07.600 --> 00:15:09.440]   And he was like, there will probably be a day.
[00:15:09.440 --> 00:15:13.680]   Someday, not now, but not too far away,
[00:15:13.680 --> 00:15:16.200]   where none of us will really be able to afford
[00:15:16.200 --> 00:15:20.640]   to own and drive cars that don't have some level of extreme
[00:15:20.640 --> 00:15:24.120]   automation because the insurers will demand it.
[00:15:24.120 --> 00:15:26.360]   And so Google wants to make this friendly car.
[00:15:26.360 --> 00:15:27.120]   And it's really cute.
[00:15:27.120 --> 00:15:30.320]   And they want us to convince us that we want to drive it.
[00:15:30.320 --> 00:15:34.440]   And it's in the scariness, that sort of weird sci-fi
[00:15:34.440 --> 00:15:36.400]   or well-ianness of a self-driving car.
[00:15:36.400 --> 00:15:38.120]   We can get over it with the face.
[00:15:38.120 --> 00:15:39.420]   But in the background, they're also
[00:15:39.420 --> 00:15:43.560]   thinking very hard about how to not just make us feel better
[00:15:43.560 --> 00:15:45.840]   about it, but to force us to do another work.
[00:15:45.840 --> 00:15:47.760]   I personally want a self-driving car that
[00:15:47.760 --> 00:15:51.840]   has a sort of intriloquist dummy looking Johnny Cab kind of face
[00:15:51.840 --> 00:15:54.280]   there that's talking to me and being crazy.
[00:15:54.280 --> 00:15:56.800]   I think that would make it all worthwhile for me, personally.
[00:15:56.800 --> 00:15:58.040]   Yeah, would you like it to also speak out?
[00:15:58.040 --> 00:16:00.280]   I want to sofa and my self-driving car.
[00:16:00.280 --> 00:16:02.160]   A sofa, a dog bowl.
[00:16:02.160 --> 00:16:02.660]   Yeah.
[00:16:02.660 --> 00:16:03.520]   Sure, absolutely.
[00:16:03.520 --> 00:16:05.040]   I was very disappointed to see that there wasn't
[00:16:05.040 --> 00:16:06.840]   more comfortable seating in this thing.
[00:16:06.840 --> 00:16:08.480]   I know, put a bed in there or something.
[00:16:08.480 --> 00:16:10.820]   Put a hammock or something in there.
[00:16:10.820 --> 00:16:11.860]   That'd be great.
[00:16:11.860 --> 00:16:14.860]   The biggest practical thing that I keep
[00:16:14.860 --> 00:16:18.820]   thinking about the self-driving car is, gosh, I work all the time.
[00:16:18.820 --> 00:16:20.700]   If I had a self-driving car, I wouldn't ever
[00:16:20.700 --> 00:16:22.540]   have a chance not to work.
[00:16:22.540 --> 00:16:25.380]   Right now, driving is when I just don't work.
[00:16:25.380 --> 00:16:28.460]   In fact, for you, I think you should get a self-driving office.
[00:16:28.460 --> 00:16:31.900]   Because imagine if you could drive
[00:16:31.900 --> 00:16:34.820]   to the other side of the country to attend a trade show
[00:16:34.820 --> 00:16:38.260]   or something and slave away the entire way to have desk in there.
[00:16:38.260 --> 00:16:39.260]   Nirvana.
[00:16:39.260 --> 00:16:40.480]   Yeah, it'd be fantastic.
[00:16:40.480 --> 00:16:43.540]   It's weird to be in a place where I can't do email and whatnot,
[00:16:43.540 --> 00:16:45.120]   which is what a car is for me.
[00:16:45.120 --> 00:16:46.400]   Yeah, exactly.
[00:16:46.400 --> 00:16:49.280]   Well, remember when airplanes were like that.
[00:16:49.280 --> 00:16:52.600]   I used to love flying because it was like, OK, nobody can call me.
[00:16:52.600 --> 00:16:55.320]   Nobody can reach me on email or whatever.
[00:16:55.320 --> 00:16:56.200]   Now the stays are gone.
[00:16:56.200 --> 00:16:59.400]   Well, Google's up to a lot more than just self-driving cars.
[00:16:59.400 --> 00:17:04.320]   They have, according to reports, rumors, whatever you want to call it,
[00:17:04.320 --> 00:17:09.020]   they are working on Android TV to replace Google TV.
[00:17:09.020 --> 00:17:12.820]   Harry McCracken, what's the difference between Android TV and Google TV?
[00:17:12.820 --> 00:17:14.180]   Well, the rumors are a little fuzzy.
[00:17:14.180 --> 00:17:16.900]   I mean, it sounds like Android TV.
[00:17:16.900 --> 00:17:22.620]   A, it plays up the Android brand, which has lots of momentum of its own.
[00:17:22.620 --> 00:17:25.660]   And B, gaming is a big part of that.
[00:17:25.660 --> 00:17:31.020]   So that's a little bit reminiscent of what Amazon is doing with Fire TV,
[00:17:31.020 --> 00:17:32.460]   which is a TV box.
[00:17:32.460 --> 00:17:36.340]   But one which is reasonably serious about gaming.
[00:17:36.340 --> 00:17:42.060]   And I mean, depending on how you count this, this is Google's third,
[00:17:42.060 --> 00:17:46.900]   maybe fourth attempt to come into the living room with a device
[00:17:46.900 --> 00:17:48.860]   because there was Google TV.
[00:17:48.860 --> 00:17:51.940]   And there was Google TV 2.0.
[00:17:51.940 --> 00:17:56.780]   And there was the Nexus Q, which was that magic eight-ball looking thing,
[00:17:56.780 --> 00:18:00.300]   which I think they gave up on before they actually had anybody paying for it.
[00:18:00.300 --> 00:18:02.620]   Did anybody get that except Google I/O attendees?
[00:18:02.620 --> 00:18:05.500]   They gave it out of Google I/O, and then they sort of slowly decided
[00:18:05.500 --> 00:18:08.980]   that maybe it was not going to work after all and gave up on it.
[00:18:08.980 --> 00:18:11.540]   Of course, I mean, really, they're only--
[00:18:11.540 --> 00:18:13.700]   I mean, depending on how you count, there are, I think,
[00:18:13.700 --> 00:18:17.180]   either two or four companies that have succeeded at TV boxes.
[00:18:17.180 --> 00:18:20.980]   Those companies are Roku, Apple with the Apple TV,
[00:18:20.980 --> 00:18:25.380]   and probably Microsoft and Sony with the Xbox and the PlayStation,
[00:18:25.380 --> 00:18:28.100]   which are both used hugely for streaming video.
[00:18:28.100 --> 00:18:31.940]   Other than that, there have been dozens of not hundreds of TV boxes,
[00:18:31.940 --> 00:18:33.900]   which have come and gone over the years without really--
[00:18:33.900 --> 00:18:34.500]   Crumbcast.
[00:18:34.500 --> 00:18:35.500]   I mean, in the evening--
[00:18:35.500 --> 00:18:35.500]   Crumbcast has been--
[00:18:35.500 --> 00:18:36.500]   Crumbcast, actually.
[00:18:36.500 --> 00:18:37.420]   Very successful.
[00:18:37.420 --> 00:18:37.780]   Yeah.
[00:18:37.780 --> 00:18:39.500]   And it's limited, but it's--
[00:18:39.500 --> 00:18:40.900]   I guess Crumbcast has been successful.
[00:18:40.900 --> 00:18:42.580]   I mean, I think they managed to sell a lot of that.
[00:18:42.580 --> 00:18:44.900]   I'm kind of curious how many are actually in use,
[00:18:44.900 --> 00:18:48.820]   because they know an awful lot of people who were like, this is incredibly cheap.
[00:18:48.820 --> 00:18:50.300]   I'm going to buy one.
[00:18:50.300 --> 00:18:52.500]   And how many of them stayed in use?
[00:18:52.500 --> 00:18:53.580]   I'm not sure.
[00:18:53.580 --> 00:18:56.180]   So it seems to me that one of the fascinating things
[00:18:56.180 --> 00:18:57.980]   about these reports that we're hearing, again,
[00:18:57.980 --> 00:19:02.660]   all this information is not something that Google has announced.
[00:19:02.660 --> 00:19:05.780]   And it's something that I think some of us are expecting at Google I/O,
[00:19:05.780 --> 00:19:08.060]   which is not for some time.
[00:19:08.060 --> 00:19:09.140]   When is Google I/O, June 1?
[00:19:09.140 --> 00:19:10.140]   No, last week.
[00:19:10.140 --> 00:19:10.980]   End of the month?
[00:19:10.980 --> 00:19:11.500]   That's right.
[00:19:11.500 --> 00:19:11.980]   It's June already.
[00:19:11.980 --> 00:19:12.660]   End of this month.
[00:19:12.660 --> 00:19:12.820]   So--
[00:19:12.820 --> 00:19:13.580]   June Sanity.
[00:19:13.580 --> 00:19:14.980]   Almost a month.
[00:19:14.980 --> 00:19:19.500]   And one of the big differences between this and the Fire TV is the Fire TV is a product.
[00:19:19.500 --> 00:19:23.340]   You go to Amazon.com, and you order one, and they send you a box,
[00:19:23.340 --> 00:19:24.740]   and it has gaming, and it has apps,
[00:19:24.740 --> 00:19:29.100]   and it has some other things that are associated with your prime account.
[00:19:29.100 --> 00:19:31.940]   Whereas this is a platform for other people to build a box,
[00:19:31.940 --> 00:19:34.580]   for other people to build a TV with this stuff built in.
[00:19:34.580 --> 00:19:38.580]   But what they have in common is a strong emphasis on games.
[00:19:38.580 --> 00:19:43.740]   So does anybody think that Google is going to become a powerhouse in gaming?
[00:19:43.740 --> 00:19:47.060]   I think that Google wants to set itself up to be a powerhouse in gaming
[00:19:47.060 --> 00:19:48.900]   if that opportunity arises.
[00:19:48.900 --> 00:19:51.620]   And it wants to have an opening into everything.
[00:19:51.620 --> 00:19:54.420]   I also think that this is Google's way of--
[00:19:54.420 --> 00:20:01.260]   I mean, I am pretty impressed that they keep trying this after the Google TV.
[00:20:01.260 --> 00:20:02.260]   You know.
[00:20:02.260 --> 00:20:02.780]   Try it.
[00:20:02.780 --> 00:20:04.660]   If you ask, go try it again.
[00:20:04.660 --> 00:20:07.940]   But the difference between the two, or at least the rumored difference,
[00:20:07.940 --> 00:20:13.140]   is that Google TV tried to marry the traditional television,
[00:20:13.140 --> 00:20:15.740]   and then the streaming television experiences.
[00:20:15.740 --> 00:20:18.260]   And this is just the latter, right?
[00:20:18.260 --> 00:20:20.100]   And so it's really opening up a platform.
[00:20:20.100 --> 00:20:23.260]   If you can get people in to watch streaming TV seamlessly.
[00:20:23.260 --> 00:20:27.580]   And then once those games start to come over the internet and become more powerful,
[00:20:27.580 --> 00:20:30.060]   there's already that sandbox for it.
[00:20:30.060 --> 00:20:31.540]   Yeah, absolutely.
[00:20:31.540 --> 00:20:33.820]   And at Google I/O last year, you were there.
[00:20:33.820 --> 00:20:35.900]   I don't know if you went to Google I/O last year.
[00:20:35.900 --> 00:20:43.060]   But they were talking about using Google+ as the sort of communications
[00:20:43.060 --> 00:20:46.060]   medium for their coming game platform for Android.
[00:20:46.060 --> 00:20:51.100]   And I wonder how that's going to happen, whether it's going to be Google+
[00:20:51.100 --> 00:20:53.260]   whether it's going to be YouTube.
[00:20:53.260 --> 00:20:55.700]   Well, the latest rumors are that maybe they're moving forward,
[00:20:55.700 --> 00:20:59.420]   they're going to be less aggressive about Google+ being the platform for everything.
[00:20:59.420 --> 00:21:04.420]   And maybe saying, Google has all these services.
[00:21:04.420 --> 00:21:06.580]   And we're not going to--
[00:21:06.580 --> 00:21:08.140]   sorry, Mike, I know you like Google+.
[00:21:08.140 --> 00:21:08.620]   I do.
[00:21:08.620 --> 00:21:12.700]   We're not going to shove Google+ into the face of people who don't necessarily want it.
[00:21:12.700 --> 00:21:13.420]   Yep.
[00:21:13.420 --> 00:21:15.740]   But yeah, I mean, that's essentially my--
[00:21:15.740 --> 00:21:20.100]   I guess it's somewhere between an assumption and a sort of an analysis of the situation,
[00:21:20.100 --> 00:21:24.780]   which is that Vic and Dautra really drove the Google+
[00:21:24.780 --> 00:21:26.620]  ification of everything in the company.
[00:21:26.620 --> 00:21:32.340]   And from within Google, what that means is that no matter what division you were in,
[00:21:32.340 --> 00:21:36.340]   no matter what division you were in charge of, Google+ was more important than you.
[00:21:36.340 --> 00:21:39.260]   And you had to change your product for the objectives of Google+
[00:21:39.260 --> 00:21:40.780]   rather than your own objectives.
[00:21:40.780 --> 00:21:42.140]   And so YouTube and so on.
[00:21:42.140 --> 00:21:45.820]   And I think that there's got to be-- and again, I'm not a fly on the water.
[00:21:45.820 --> 00:21:46.980]   I don't know what's really going on in Google.
[00:21:46.980 --> 00:21:50.740]   But that's got to be why Vic and Dautra left, to a certain extent.
[00:21:50.740 --> 00:21:55.140]   He burned every bridge there was because he was the guy going around forcing everybody
[00:21:55.140 --> 00:21:56.660]   to do stuff they didn't want to do.
[00:21:56.660 --> 00:22:01.580]   And so yeah, I think that the days of forced integration that's widespread and aggressive
[00:22:01.580 --> 00:22:02.500]   are definitely over.
[00:22:02.500 --> 00:22:03.780]   And it doesn't affect Google+ at all.
[00:22:03.780 --> 00:22:09.140]   I mean, as a social network that cares, those things were all for the theoretical benefit
[00:22:09.140 --> 00:22:10.420]   of other Google properties.
[00:22:10.420 --> 00:22:15.140]   It might help Google+ given that among people who don't love Google+,
[00:22:15.140 --> 00:22:18.780]   it doesn't have a great reputation partially because people think about it as something
[00:22:18.780 --> 00:22:20.660]   now being forced on them.
[00:22:20.660 --> 00:22:24.740]   If Google+ succeeded because it was good, which it is in a lot of ways, it might be good
[00:22:24.740 --> 00:22:25.740]   for everybody.
[00:22:25.740 --> 00:22:26.740]   Yeah, absolutely.
[00:22:26.740 --> 00:22:31.540]   Well, Google is also having an interesting time in Europe these days because they often
[00:22:31.540 --> 00:22:36.500]   clash with the Europeans over a variety of things, things like Street View, Car, and
[00:22:36.500 --> 00:22:37.500]   so on.
[00:22:37.500 --> 00:22:42.340]   And so the way that Google+ has been doing this is that Google+ has been doing this
[00:22:42.340 --> 00:22:43.340]   and it's been doing this.
[00:22:43.340 --> 00:22:45.340]   And so it's been a very interesting time.
[00:22:45.340 --> 00:22:48.340]   And so it's been a very interesting time.
[00:22:48.340 --> 00:22:50.340]   And so it's been a very interesting time.
[00:22:50.340 --> 00:22:52.340]   And so it's been a very interesting time.
[00:22:52.340 --> 00:22:53.340]   And so it's been a very interesting time.
[00:22:53.340 --> 00:22:54.340]   And so it's been a very interesting time.
[00:22:54.340 --> 00:22:55.340]   And so it's been a very interesting time.
[00:22:55.340 --> 00:22:56.340]   And so it's been a very interesting time.
[00:22:56.340 --> 00:22:57.340]   And so it's been a very interesting time.
[00:22:57.340 --> 00:22:58.340]   And so it's been a very interesting time.
[00:22:58.340 --> 00:22:59.340]   And so it's been a very interesting time.
[00:22:59.340 --> 00:23:00.340]   And so it's been a very interesting time.
[00:23:00.340 --> 00:23:01.340]   And so it's been a very interesting time.
[00:23:01.340 --> 00:23:02.340]   And so it's been a very interesting time.
[00:23:02.340 --> 00:23:03.340]   And so it's been a very interesting time.
[00:23:03.340 --> 00:23:08.060]   And what that meant was that Google has now required to enable European users, because
[00:23:08.060 --> 00:23:14.420]   of one Spanish judge, by the way, to enable European users to submit a proposal that they
[00:23:14.420 --> 00:23:18.020]   have their information, the link, not the information, the link in Google, in Google's
[00:23:18.020 --> 00:23:20.900]   search engine and every search engine to be removed.
[00:23:20.900 --> 00:23:21.900]   So this affects not only Google.
[00:23:21.900 --> 00:23:22.900]   Google lost the case.
[00:23:22.900 --> 00:23:26.700]   They were the, I guess, the defendant or whatever you want to call it in a lawsuit.
[00:23:26.700 --> 00:23:29.540]   But they now have to comply.
[00:23:29.540 --> 00:23:30.540]   They have done so.
[00:23:30.540 --> 00:23:33.860]   This happened some time ago, and now they've actually put up their form saying, if you
[00:23:33.860 --> 00:23:37.780]   want to remove your link, here's the form, fill it out.
[00:23:37.780 --> 00:23:40.460]   And thousands of people have done that.
[00:23:40.460 --> 00:23:43.740]   Now this is a controversial thing.
[00:23:43.740 --> 00:23:45.700]   Katie Benner, what do you think of all this?
[00:23:45.700 --> 00:23:48.300]   I know you have a point of view on this.
[00:23:48.300 --> 00:23:49.300]   Oh, yeah.
[00:23:49.300 --> 00:23:53.660]   I mean, I think it initially it feels like a very good idea because I think that people
[00:23:53.660 --> 00:23:57.700]   are trying to find ways to take back control of their online identity.
[00:23:57.700 --> 00:24:01.620]   I mean, it's why things like Snapchat are successful or things that disappear so we don't feel
[00:24:01.620 --> 00:24:05.180]   stuck with everything we do online.
[00:24:05.180 --> 00:24:10.300]   But what it gets into a very tough territory of essentially sort of censoring the web.
[00:24:10.300 --> 00:24:13.580]   So I think Google, if they decide to take down a link, they're also going to note that
[00:24:13.580 --> 00:24:17.380]   a link has disappeared and how many links do they take down?
[00:24:17.380 --> 00:24:19.180]   What does that mean?
[00:24:19.180 --> 00:24:20.580]   Who are they rewriting the history for?
[00:24:20.580 --> 00:24:23.300]   Is it useful to have some of this information available?
[00:24:23.300 --> 00:24:24.580]   How do they decide?
[00:24:24.580 --> 00:24:27.180]   This is just such, such tricky territory.
[00:24:27.180 --> 00:24:35.340]   So I think it will actually be a lot harder than people think for this to be successful.
[00:24:35.340 --> 00:24:36.340]   Absolutely.
[00:24:36.340 --> 00:24:43.180]   I mean, does anybody in this Council of Wisdom support the European decision, this idea of
[00:24:43.180 --> 00:24:44.180]   right to be forgotten?
[00:24:44.180 --> 00:24:48.860]   Is this something that has value that outweighs the complications?
[00:24:48.860 --> 00:24:52.180]   I think I've been thinking about it a lot because I mean, we all probably have links
[00:24:52.180 --> 00:24:57.660]   we'd like to take down.
[00:24:57.660 --> 00:25:00.100]   I don't think it's a good idea.
[00:25:00.100 --> 00:25:03.500]   One thing I think that there's an entire industry that will grow up around it that
[00:25:03.500 --> 00:25:08.100]   will be, you know, you'll find a consultant who knows the right language to use in the
[00:25:08.100 --> 00:25:13.060]   form and all of the right tactics to take to get certain things taken down regardless
[00:25:13.060 --> 00:25:18.180]   of whether it's a good idea or it's really something that is a link that's no longer
[00:25:18.180 --> 00:25:19.180]   relevant.
[00:25:19.180 --> 00:25:25.140]   It doesn't seem like there are very good guidelines yet about what makes a link something that
[00:25:25.140 --> 00:25:27.500]   deserves to be taken off of Google.
[00:25:27.500 --> 00:25:29.420]   That's one of the crazy things about this.
[00:25:29.420 --> 00:25:34.300]   The European regulators have constantly told Google, Google, we don't trust you.
[00:25:34.300 --> 00:25:36.340]   We don't trust you with your street view car.
[00:25:36.340 --> 00:25:42.180]   We don't trust you with your, you know, with you listing your competitors on your search
[00:25:42.180 --> 00:25:43.180]   engine.
[00:25:43.180 --> 00:25:44.580]   We think you're favoring yourself.
[00:25:44.580 --> 00:25:47.460]   They go on and on about how they don't trust Google and they say, and then in this ruling
[00:25:47.460 --> 00:25:51.780]   they say, but you know what, you're in charge of deciding what's a good link, what's a
[00:25:51.780 --> 00:25:54.060]   bad link, what's a relevant link, what's an irrelevant link.
[00:25:54.060 --> 00:25:55.060]   That's all up to you, Google.
[00:25:55.060 --> 00:25:56.060]   Good luck.
[00:25:56.060 --> 00:25:57.060]   Yeah, that seems crazy.
[00:25:57.060 --> 00:25:59.340]   I mean, it seems like if that's going to happen and maybe there's a future in which there's
[00:25:59.340 --> 00:26:03.940]   a way that we get certain things taken down so that, you know, public interest in something
[00:26:03.940 --> 00:26:07.540]   that is untrue doesn't drive untruths to the top.
[00:26:07.540 --> 00:26:10.180]   But there needs to be legislation around that.
[00:26:10.180 --> 00:26:12.740]   It can't be up to, it can't be up to Google.
[00:26:12.740 --> 00:26:13.740]   Right.
[00:26:13.740 --> 00:26:14.740]   And to me, that--
[00:26:14.740 --> 00:26:20.100]   Oh, I was just going to say, there are also companies already that exist that do reputation
[00:26:20.100 --> 00:26:21.100]   scrubbing online.
[00:26:21.100 --> 00:26:25.020]   And of course, I mean, what the EU is saying is you shouldn't have to be like a really
[00:26:25.020 --> 00:26:28.580]   wealthy person who can hire reputation.com or one of these services.
[00:26:28.580 --> 00:26:30.820]   But this is something that already exists.
[00:26:30.820 --> 00:26:31.820]   Yeah, absolutely.
[00:26:31.820 --> 00:26:35.900]   But one of the things that's really-- the worst thing about this, and let me frame this
[00:26:35.900 --> 00:26:41.580]   in the way that sort of reveals it for what it really is.
[00:26:41.580 --> 00:26:44.940]   What they're asking Google to do-- so there's a beautiful situation that exists.
[00:26:44.940 --> 00:26:46.420]   We have an internet, right?
[00:26:46.420 --> 00:26:47.420]   It exists.
[00:26:47.420 --> 00:26:50.700]   We have search engines to help you find the things that are on the internet.
[00:26:50.700 --> 00:26:54.860]   So what this ruling does is it says, "Okay, Google, we want you to lie.
[00:26:54.860 --> 00:27:00.780]   We want you to have your search engine not reflect the actual internet, but to reflect
[00:27:00.780 --> 00:27:07.720]   whatever's left over after everybody who has the resources at the time, whatever, to scrub
[00:27:07.720 --> 00:27:08.720]   it."
[00:27:08.720 --> 00:27:10.740]   And by the way, this is only for Europe.
[00:27:10.740 --> 00:27:18.700]   So to me, Europe is going to have an increasingly inaccurate search engine.
[00:27:18.700 --> 00:27:22.780]   And Europeans who are savvy are going to find ways around it.
[00:27:22.780 --> 00:27:26.540]   They're just going to use the American version of Google or some other version of Google.
[00:27:26.540 --> 00:27:29.180]   And in fact, this is what people in China already do.
[00:27:29.180 --> 00:27:31.740]   This is what you do when you have a censored internet.
[00:27:31.740 --> 00:27:37.420]   You find-- you use various tools, which are freely available, to get around what's there.
[00:27:37.420 --> 00:27:40.740]   And then, again, it's another digital divide, isn't it?
[00:27:40.740 --> 00:27:44.180]   Because the tech savvy people, the knowledgeable people, the educated people are going to get
[00:27:44.180 --> 00:27:45.460]   the real internet.
[00:27:45.460 --> 00:27:48.780]   And then the average person is going to get a censored version of the internet.
[00:27:48.780 --> 00:27:49.940]   It's an awful state of affairs.
[00:27:49.940 --> 00:27:55.420]   And I think Europe needs to revisit this and not just allow one Spanish judge to essentially
[00:27:55.420 --> 00:27:58.300]   wreck the internet for an entire continent.
[00:27:58.300 --> 00:27:59.780]   And who decides what makes this--
[00:27:59.780 --> 00:28:00.780]   Well, come on.
[00:28:00.780 --> 00:28:01.780]   This is Europe.
[00:28:01.780 --> 00:28:04.540]   I mean, you know, this is very European.
[00:28:04.540 --> 00:28:10.380]   This is the same-- you know, the EU, they regulate the way that a tomato can look before it goes
[00:28:10.380 --> 00:28:11.380]   to the market.
[00:28:11.380 --> 00:28:16.700]   I mean, there's such an amazingly rule-bound, kind of hide-bound place.
[00:28:16.700 --> 00:28:18.900]   So it's not entirely surprising.
[00:28:18.900 --> 00:28:19.900]   And Mike, you're right.
[00:28:19.900 --> 00:28:25.140]   They sort of have been, you know, at war with Google for many years, overall, all kinds
[00:28:25.140 --> 00:28:26.140]   of stuff.
[00:28:26.140 --> 00:28:30.300]   And I think it may not entirely be a coincidence that Google is this large company headquartered
[00:28:30.300 --> 00:28:34.780]   in the US, which has so much impact in Europe.
[00:28:34.780 --> 00:28:38.020]   And there have been all these attempts to create the European Google, none of which
[00:28:38.020 --> 00:28:39.380]   have really taken off.
[00:28:39.380 --> 00:28:40.380]   That's right.
[00:28:40.380 --> 00:28:42.460]   And they take a different tact.
[00:28:42.460 --> 00:28:44.620]   And the tact doesn't really work, for example.
[00:28:44.620 --> 00:28:52.460]   There was some years ago, the French government has these cultural sort of divisions or whatever
[00:28:52.460 --> 00:28:53.620]   you want to call them.
[00:28:53.620 --> 00:28:57.300]   And they were freaking out that Google was digitizing all the books and sort of kind
[00:28:57.300 --> 00:29:00.980]   of becoming this powerhouse in the future of digital books.
[00:29:00.980 --> 00:29:03.140]   And so they wanted to do their own.
[00:29:03.140 --> 00:29:05.140]   And it flopped.
[00:29:05.140 --> 00:29:08.980]   And you know, it doesn't, it kind of stuff is hard to do by committee.
[00:29:08.980 --> 00:29:10.540]   You need billionaires to do that kind of thing.
[00:29:10.540 --> 00:29:16.220]   You need billionaires with Google Glass and Vibroms and private jets to do these things.
[00:29:16.220 --> 00:29:17.740]   You can't just do it by the eye.
[00:29:17.740 --> 00:29:19.060]   Well, we're going to talk about Apple.
[00:29:19.060 --> 00:29:21.820]   It's going to be a huge week for Apple.
[00:29:21.820 --> 00:29:26.660]   And there's lots of facts and also not so facts, not so big a facts rumor.
[00:29:26.660 --> 00:29:32.820]   See if you might call them about what Apple is going to be announcing at WWDC tomorrow.
[00:29:32.820 --> 00:29:36.180]   But first I want to tell you about stamps.com.
[00:29:36.180 --> 00:29:37.940]   Stamp.com is one of our sponsors today.
[00:29:37.940 --> 00:29:41.220]   And you know who goes to the post office and waits in line, the post office?
[00:29:41.220 --> 00:29:46.140]   Other people, if you have stats, stamps.com, going to the post office, slogging your way
[00:29:46.140 --> 00:29:51.340]   through traffic at the end of your work day and then getting in line with a whole bunch
[00:29:51.340 --> 00:29:58.140]   of people just to send something or to send a package or whatever is just a terrible idea.
[00:29:58.140 --> 00:30:03.340]   Because stamps.com will let you do all the post office stuff at your house.
[00:30:03.340 --> 00:30:06.940]   You can, especially if you have a small business, you want to do whatever it takes to make
[00:30:06.940 --> 00:30:08.820]   your business run efficiently.
[00:30:08.820 --> 00:30:12.420]   And if you want to be efficient, waiting in line to the post office is not the way to
[00:30:12.420 --> 00:30:13.860]   be efficient.
[00:30:13.860 --> 00:30:15.060]   It eats a valuable time.
[00:30:15.060 --> 00:30:17.220]   You could be spending on growing your business.
[00:30:17.220 --> 00:30:19.980]   So you need to go to stamps.com.
[00:30:19.980 --> 00:30:24.460]   You can buy and print official US postage for any letter, any package and using what you
[00:30:24.460 --> 00:30:26.580]   already have, your own computer, your own printer.
[00:30:26.580 --> 00:30:28.580]   And then just hand it to your mailman.
[00:30:28.580 --> 00:30:30.020]   It's that easy to do.
[00:30:30.020 --> 00:30:35.820]   Join the 500,000 small businesses that use stamps.com and never have to go to the post
[00:30:35.820 --> 00:30:36.980]   office again.
[00:30:36.980 --> 00:30:41.780]   There are no long term leases, no hidden fees, no expensive inks, nothing fancy.
[00:30:41.780 --> 00:30:44.900]   Stamp.com can give a small business a more professional look.
[00:30:44.900 --> 00:30:47.300]   So right now use the promo code TWIT.
[00:30:47.300 --> 00:30:51.900]   For our special offer, a notice trial, it's a $110 bonus offer that includes a digital
[00:30:51.900 --> 00:30:56.420]   scale and $55 free postage.
[00:30:56.420 --> 00:30:57.420]   So don't wait.
[00:30:57.420 --> 00:30:58.660]   Go to stamps.com.
[00:30:58.660 --> 00:31:01.580]   Before you do anything else, click the microphone to the top.
[00:31:01.580 --> 00:31:02.740]   Type in TWIT.
[00:31:02.740 --> 00:31:05.580]   That's stamps.com and type in TWIT.
[00:31:05.580 --> 00:31:07.940]   And you will thank stamps.com.
[00:31:07.940 --> 00:31:09.900]   It's a fantastic service.
[00:31:09.900 --> 00:31:12.580]   Well, Apple is in the news.
[00:31:12.580 --> 00:31:15.340]   They of course are doing WWDC.
[00:31:15.340 --> 00:31:16.340]   And I think Chad.
[00:31:16.340 --> 00:31:20.180]   We have an early look at, you know, people are wondering where they're going to launch
[00:31:20.180 --> 00:31:21.860]   it, a watch or not.
[00:31:21.860 --> 00:31:24.860]   We've got this early look at promotional video.
[00:31:24.860 --> 00:31:26.660]   Roll it, Chad.
[00:31:26.660 --> 00:31:32.100]   From the very beginning of time, man has continually asked one question.
[00:31:32.100 --> 00:31:34.100]   Houlat et aite.
[00:31:34.100 --> 00:31:35.900]   Qui ore es.
[00:31:35.900 --> 00:31:37.460]   Nias edu.
[00:31:37.460 --> 00:31:38.660]   This might not be official.
[00:31:38.660 --> 00:31:39.660]   What time is it?
[00:31:39.660 --> 00:31:41.980]   Today we at Apple will answer that question.
[00:31:41.980 --> 00:31:45.940]   It is time for the eye watch.
[00:31:45.940 --> 00:31:51.580]   We found users constantly reaching for their phones to check the time and that is the worst.
[00:31:51.580 --> 00:31:56.660]   So we figured, why not just strap it to your body?
[00:31:56.660 --> 00:32:01.580]   Introducing our magical new product, the eye watch.
[00:32:01.580 --> 00:32:07.060]   Now not only can you check the time, but you can check almost any other alert that your
[00:32:07.060 --> 00:32:08.900]   phone could push to it.
[00:32:08.900 --> 00:32:10.100]   Wow.
[00:32:10.100 --> 00:32:11.700]   The eye watch uses its built in.
[00:32:11.700 --> 00:32:12.700]   This guy has a great voice.
[00:32:12.700 --> 00:32:15.900]   Point out technology to wirelessly communicate with your iPhone.
[00:32:15.900 --> 00:32:21.020]   This way you can answer calls with ease even when your iPhone is in the other room.
[00:32:21.020 --> 00:32:25.300]   Sinking your eye watch to your iPhone happens all in the background with our eyesink technology.
[00:32:25.300 --> 00:32:29.300]   All you have to do to set this up is pair your existing iPhone with your eye watch.
[00:32:29.300 --> 00:32:32.100]   Make sure the confirmation code matches, bump them together, then input the shifting
[00:32:32.100 --> 00:32:34.340]   character passcode into each of the devices.
[00:32:34.340 --> 00:32:35.820]   It's really that simple.
[00:32:35.820 --> 00:32:36.900]   Repeat after every charge.
[00:32:36.900 --> 00:32:39.060]   We have taken this eyesink technology.
[00:32:39.060 --> 00:32:41.660]   Something of pretty good products to go.
[00:32:41.660 --> 00:32:46.300]   You can respond to text messages without your phone leaving your pocket.
[00:32:46.300 --> 00:32:51.300]   Zoom your latest e-book with the flick of a finger.
[00:32:51.300 --> 00:32:57.420]   Catch up on the latest news headlines pushed directly to your eye watch.
[00:32:57.420 --> 00:32:59.540]   The design that went into the eye...
[00:32:59.540 --> 00:33:01.420]   Suddenly he's Johnny I have...
[00:33:01.420 --> 00:33:07.420]   It's hard to believe that we could even fit a battery into this thing, but we did.
[00:33:07.420 --> 00:33:12.180]   And it will last you one entire hour of standby.
[00:33:12.180 --> 00:33:16.100]   You have never looked so attractive to the opposite sex.
[00:33:16.100 --> 00:33:17.900]   Yeah, it's that good.
[00:33:17.900 --> 00:33:20.180]   You can even use it when it's plugged in.
[00:33:20.180 --> 00:33:21.460]   You can charge it.
[00:33:21.460 --> 00:33:26.860]   Listen to music and sync it with your iMac all at the same time.
[00:33:26.860 --> 00:33:28.620]   Gaming has never been more fun.
[00:33:28.620 --> 00:33:32.860]   Play your favorite games from your iPhone or iPad right on your eye watch.
[00:33:32.860 --> 00:33:35.060]   Every existing game is compatible?
[00:33:35.060 --> 00:33:40.060]   We've even added support you've made for iPhone controllers.
[00:33:40.060 --> 00:33:46.340]   Never be away from Minecraft again.
[00:33:46.340 --> 00:33:48.140]   But there's one more thing.
[00:33:48.140 --> 00:33:51.540]   The eye watch comes with a built-in GPS-aware pedometer.
[00:33:51.540 --> 00:33:55.940]   We take privacy seriously and that's why we've granted a live stream of your location to
[00:33:55.940 --> 00:33:57.220]   the NSA.
[00:33:57.220 --> 00:33:58.300]   Stop complaining.
[00:33:58.300 --> 00:33:59.300]   You love the attention.
[00:33:59.300 --> 00:34:02.420]   Hey guys, hope you like that video.
[00:34:02.420 --> 00:34:08.420]   That's only slightly more silly than a lot of actual smart watches which exist today.
[00:34:08.420 --> 00:34:09.420]   That's right.
[00:34:09.420 --> 00:34:10.420]   That's right.
[00:34:10.420 --> 00:34:14.300]   And speaking of which, everybody expects Apple to launch an eye watch of some kind, a band
[00:34:14.300 --> 00:34:15.300]   something.
[00:34:15.300 --> 00:34:17.300]   They're going to do it tomorrow at the same time.
[00:34:17.300 --> 00:34:18.300]   No, they're not.
[00:34:18.300 --> 00:34:20.380]   Are they going to even mention it?
[00:34:20.380 --> 00:34:21.380]   I don't know.
[00:34:21.380 --> 00:34:25.060]   I mean, I think that they're going to talk a lot about iOS 8.
[00:34:25.060 --> 00:34:30.020]   And iOS 8, I would assume, contains some hints or some direction.
[00:34:30.020 --> 00:34:32.980]   And there's going to be something that we can sort of see in that experience.
[00:34:32.980 --> 00:34:38.300]   And some of the other apps and software that Apple will be talking about, they're going
[00:34:38.300 --> 00:34:44.260]   to be, the rumor is that Apple will be launching a health book app that brings all of your
[00:34:44.260 --> 00:34:49.020]   various sensor based health kind of data into a single app.
[00:34:49.020 --> 00:34:50.460]   They'll be like a pass book maybe.
[00:34:50.460 --> 00:34:51.940]   Yes, very much like a pass book.
[00:34:51.940 --> 00:34:56.860]   But for whatever you're tracking on your smart watch.
[00:34:56.860 --> 00:34:59.620]   So I would assume that there will be some hints in there.
[00:34:59.620 --> 00:35:05.700]   And I know that the developers conference program has a lot of the program, the later
[00:35:05.700 --> 00:35:09.980]   program, the lot of the sessions, the names are still blacked out.
[00:35:09.980 --> 00:35:12.820]   So there will be something that I don't think there's going to be a hardware tomorrow.
[00:35:12.820 --> 00:35:13.820]   I really don't.
[00:35:13.820 --> 00:35:15.940]   I think they're really focused on developers this year.
[00:35:15.940 --> 00:35:16.940]   Okay.
[00:35:16.940 --> 00:35:17.940]   Harry, what do you think?
[00:35:17.940 --> 00:35:19.420]   What are they going to talk about tomorrow?
[00:35:19.420 --> 00:35:26.580]   I mean, I think that a new version of OS 10 and a new version of iOS are a given.
[00:35:26.580 --> 00:35:27.940]   And that's a lot to chew on right there.
[00:35:27.940 --> 00:35:30.540]   It sounds like health book is real.
[00:35:30.540 --> 00:35:33.100]   Mark Gurman who writes for nine to five Mac.
[00:35:33.100 --> 00:35:39.060]   He's one of the few Apple reporters who if he reports a rumor, you can't have 100% confidence.
[00:35:39.060 --> 00:35:41.500]   He's right, but he's probably right.
[00:35:41.500 --> 00:35:44.460]   And he's written an awful lot about this stuff.
[00:35:44.460 --> 00:35:48.860]   I would expect some hardware, but probably not anything revolutionary.
[00:35:48.860 --> 00:35:49.860]   Yeah.
[00:35:49.860 --> 00:35:51.940]   There might be new Mac books.
[00:35:51.940 --> 00:35:52.940]   Yeah.
[00:35:52.940 --> 00:35:55.460]   It would be nice to have a MacBook Air with a retina screen someday.
[00:35:55.460 --> 00:35:57.580]   That would be nice.
[00:35:57.580 --> 00:36:04.260]   But people always think that Apple rolls out huge world changing hardware devices at WWDC.
[00:36:04.260 --> 00:36:07.540]   And they forget that the iPod, the original iPod was not a WWDC.
[00:36:07.540 --> 00:36:09.140]   The original I-Man was not.
[00:36:09.140 --> 00:36:10.940]   The iPhone was not.
[00:36:10.940 --> 00:36:13.300]   The iPad wasn't.
[00:36:13.300 --> 00:36:16.100]   It's like the second or third device in that category.
[00:36:16.100 --> 00:36:20.020]   They announced a WWDC and I have to expect something along those lines tomorrow.
[00:36:20.020 --> 00:36:22.740]   They don't want to steal attention from a major hardware rollout.
[00:36:22.740 --> 00:36:25.540]   And they don't want to mess up their supply chain either.
[00:36:25.540 --> 00:36:29.100]   So unless they're ready to hit the ground and start selling something immediately, they're
[00:36:29.100 --> 00:36:30.700]   really unlikely to do it.
[00:36:30.700 --> 00:36:32.900]   Which they usually don't do in the summer anyway.
[00:36:32.900 --> 00:36:36.660]   They did it with the iPhone for a while, but the iPhone is slipped into the fall.
[00:36:36.660 --> 00:36:39.580]   And this is an event for software developers.
[00:36:39.580 --> 00:36:43.580]   If you are a software developer and you write for Apple stuff, there's nothing you care
[00:36:43.580 --> 00:36:47.740]   more about than the next version of iOS or the next version of OS X.
[00:36:47.740 --> 00:36:52.580]   You don't care all that much usually about the specific hardware that it's running on.
[00:36:52.580 --> 00:36:53.580]   Yeah.
[00:36:53.580 --> 00:36:57.860]   Unless it's something like a Retina display or an iPhone with a larger screen, those kind
[00:36:57.860 --> 00:36:59.900]   of things do affect you and you care about them.
[00:36:59.900 --> 00:37:00.900]   Yeah.
[00:37:00.900 --> 00:37:04.100]   One of the interesting things about the coming spaceship campus that they're building, I
[00:37:04.100 --> 00:37:07.100]   think it's the current deadline on that.
[00:37:07.100 --> 00:37:09.940]   And of course, they're already tearing up the ground and laying the foundation for that
[00:37:09.940 --> 00:37:13.580]   and so on in Cupertino is that they have an underground bunker where they're going to
[00:37:13.580 --> 00:37:14.940]   do all their announcements.
[00:37:14.940 --> 00:37:19.220]   And so we've already, we know they're going to launch iOS 8 because we've seen the posters
[00:37:19.220 --> 00:37:24.740]   already, you know, the, what's the name of the conference facility in San Francisco,
[00:37:24.740 --> 00:37:25.740]   where they did?
[00:37:25.740 --> 00:37:26.740]   Los Cone West.
[00:37:26.740 --> 00:37:27.740]   Los Cone West.
[00:37:27.740 --> 00:37:30.300]   You can just walk in there, you know, they can't like keep the public out of those, but
[00:37:30.300 --> 00:37:34.060]   the underground bunker is going to allow them to summon journalists within short notice
[00:37:34.060 --> 00:37:38.260]   two or three days maybe and then they'll be able to go on any schedule they like.
[00:37:38.260 --> 00:37:39.260]   They don't have to book it.
[00:37:39.260 --> 00:37:43.660]   And you know, Moscone, you have to book probably what, a year or two in advance and so on.
[00:37:43.660 --> 00:37:47.860]   And those, I mean, people will see that there is a mysterious event happening at Moscone
[00:37:47.860 --> 00:37:50.180]   West on a given week in June.
[00:37:50.180 --> 00:37:51.180]   That's right.
[00:37:51.180 --> 00:37:53.540]   And even if it doesn't say Apple, people often can figure it out.
[00:37:53.540 --> 00:37:56.540]   It's literally impossible to keep that kind of information secret and they'll.
[00:37:56.540 --> 00:37:58.860]   Apple already does that actually at their campus.
[00:37:58.860 --> 00:38:02.300]   When they have a smaller event for journalists, they'll just bring people and they have a
[00:38:02.300 --> 00:38:03.300]   facility.
[00:38:03.300 --> 00:38:04.300]   A little theater.
[00:38:04.300 --> 00:38:05.300]   Yeah.
[00:38:05.300 --> 00:38:06.300]   Kind of thing.
[00:38:06.300 --> 00:38:07.300]   So that, so that'll be interesting.
[00:38:07.300 --> 00:38:08.460]   One of that you mentioned Mark Gurman.
[00:38:08.460 --> 00:38:12.380]   Mark Gurman broke the story this week that Apple's discussing iPhone payment service.
[00:38:12.380 --> 00:38:17.100]   Now he doesn't believe this is going to be a topic of a discussion at WWDC.
[00:38:17.100 --> 00:38:19.260]   But they're talking about a payment service.
[00:38:19.260 --> 00:38:25.060]   What they're doing is they're talking to retailers about having a way to use your iPhone
[00:38:25.060 --> 00:38:26.300]   as it's a credit card.
[00:38:26.300 --> 00:38:29.420]   Now Katie Benner, this is kind of a no-brainer for me.
[00:38:29.420 --> 00:38:31.420]   I've been writing about this for a long time.
[00:38:31.420 --> 00:38:33.140]   You know, when are they going to do this?
[00:38:33.140 --> 00:38:35.900]   They have phones that have fingerprint readers on them.
[00:38:35.900 --> 00:38:40.540]   They have Ibekin, which is an indoor location system that's perfect for indoor retail.
[00:38:40.540 --> 00:38:44.900]   They themselves have innovated indoor retail stuff at their Apple stores where instead of
[00:38:44.900 --> 00:38:47.860]   going to a cash register, they don't have cash registers.
[00:38:47.860 --> 00:38:50.340]   They have people with blue T-shirts.
[00:38:50.340 --> 00:38:53.540]   And so you just walk up to the blue T-shirt and you buy whatever you want.
[00:38:53.540 --> 00:38:55.900]   You walk out in the email, you're receipt or whatever.
[00:38:55.900 --> 00:38:59.740]   That's how Apple wants to remake, I think, the world of retail.
[00:38:59.740 --> 00:39:01.700]   And they have everything they need to do it.
[00:39:01.700 --> 00:39:07.180]   And the one thing that they have that nobody else has is 800 million credit cards.
[00:39:07.180 --> 00:39:12.740]   They have 800 million iTunes accounts that have active credit cards associated with them,
[00:39:12.740 --> 00:39:17.700]   which makes them, to me, that makes them the number one company that has the potential
[00:39:17.700 --> 00:39:20.020]   to dominate this kind of retail.
[00:39:20.020 --> 00:39:24.900]   Katie Benner, what do you think this is going to happen when they actually roll out some
[00:39:24.900 --> 00:39:28.100]   kind of mobile wallet system?
[00:39:28.100 --> 00:39:34.780]   I mean, I have no idea when it would happen, but I think it solves such a big problem for
[00:39:34.780 --> 00:39:39.180]   the retailers that I don't think it would be very hard for a company like Apple if they
[00:39:39.180 --> 00:39:42.500]   chose the right retail partners to make this happen.
[00:39:42.500 --> 00:39:45.980]   Because at the end of the day, we have these phones that we can go online, but we're not
[00:39:45.980 --> 00:39:48.020]   necessarily shopping or buying online.
[00:39:48.020 --> 00:39:49.860]   There have been a lot of studies on this.
[00:39:49.860 --> 00:39:54.700]   Nobody wants to input all of that information into that tiny, into all of those tiny fields.
[00:39:54.700 --> 00:40:00.740]   And so if you can make shopping as easy as it is to, you know, with your thumbprint, buy
[00:40:00.740 --> 00:40:02.980]   an app from the App Store, that would be great.
[00:40:02.980 --> 00:40:07.380]   And if you think about the Apple demographic, it tends to be pretty well-heeled.
[00:40:07.380 --> 00:40:14.140]   So if they were working with the Neiman Markuses of the World or name your retailer who really
[00:40:14.140 --> 00:40:21.220]   wants to move goods online stores that simply just do not right now, we don't do a lot of
[00:40:21.220 --> 00:40:24.580]   mobile shopping, it would be a perfect solution.
[00:40:24.580 --> 00:40:29.300]   Yeah, we had Mark Gurman on Tech News today this week and talking about the story.
[00:40:29.300 --> 00:40:34.540]   And he was pointing out and emphasized and also emphasized it in his article that it's
[00:40:34.540 --> 00:40:39.740]   actually a really big problem because each of these retailers has its own back-end system
[00:40:39.740 --> 00:40:43.180]   and the Apple system would have to be compatible with those systems.
[00:40:43.180 --> 00:40:45.900]   So they have to go on a chain-by-chain basis.
[00:40:45.900 --> 00:40:50.820]   So as he points out, they're going to go for the big high-end chains, you know, the
[00:40:50.820 --> 00:40:53.420]   Neiman Markuses and so on.
[00:40:53.420 --> 00:40:55.140]   And they're not going to go for the targets.
[00:40:55.140 --> 00:40:56.900]   And they're not going to go for mom-and-pop shops either.
[00:40:56.900 --> 00:41:00.500]   So they're going to have to start it with the big chains, establish what would amount
[00:41:00.500 --> 00:41:04.900]   to a standard and hope presumably that the rest of the world sort of retrofits what
[00:41:04.900 --> 00:41:09.220]   they've got to support Apple when this works.
[00:41:09.220 --> 00:41:13.500]   But it's a fascinating story to a certain extent, but it's also kind of a boring story
[00:41:13.500 --> 00:41:15.540]   because this is inevitable.
[00:41:15.540 --> 00:41:17.580]   Apple, I believe, is going to do that.
[00:41:17.580 --> 00:41:21.900]   And if this whole system and if they didn't do it, there would be morons because it's
[00:41:21.900 --> 00:41:22.900]   so lucrative.
[00:41:22.900 --> 00:41:30.420]   Well, they need to do it soon because they still dominate market share for any single
[00:41:30.420 --> 00:41:33.100]   device anyway.
[00:41:33.100 --> 00:41:37.780]   But that has a potential to wane a little bit, right?
[00:41:37.780 --> 00:41:43.620]   As these become commodities and a lot of people switch to Android and there's so much
[00:41:43.620 --> 00:41:48.340]   choice out there if Apple doesn't figure it out right now and get it out there with
[00:41:48.340 --> 00:41:50.860]   the next iPhone, I think that then it's in trouble.
[00:41:50.860 --> 00:41:51.860]   So now's the time.
[00:41:51.860 --> 00:41:52.860]   Yeah, absolutely.
[00:41:52.860 --> 00:41:54.860]   I think it's been smart.
[00:41:54.860 --> 00:41:57.100]   They've waited.
[00:41:57.100 --> 00:42:00.340]   Apple often does well because it swoops into a category after other people have failed
[00:42:00.340 --> 00:42:03.940]   and Google Wallet has not really gone much of anywhere.
[00:42:03.940 --> 00:42:09.860]   Square had a really cool app, which I think they've actually discontinued just because
[00:42:09.860 --> 00:42:14.060]   it's hard to get traction with these things partially because credit cards are actually
[00:42:14.060 --> 00:42:16.300]   a really well done way to make payments easy.
[00:42:16.300 --> 00:42:18.740]   Well, these people are comfortable with them.
[00:42:18.740 --> 00:42:22.580]   Credit cards set the bar high and it's not easy for a phone to be better than a credit
[00:42:22.580 --> 00:42:23.580]   card.
[00:42:23.580 --> 00:42:24.580]   It's actually quite difficult.
[00:42:24.580 --> 00:42:25.580]   Yeah.
[00:42:25.580 --> 00:42:26.740]   Yeah, it truly is.
[00:42:26.740 --> 00:42:31.500]   And I think that one of the things that, to your point, Lindsey, that Apple is going to
[00:42:31.500 --> 00:42:37.500]   do to sort of deal with the fact that hardware tends to become commoditized and the competition
[00:42:37.500 --> 00:42:44.100]   is very intense and the markets are very price sensitive is this purchase of beats.
[00:42:44.100 --> 00:42:47.940]   Now, right off the bat, was this a brilliant move or an idiotic move?
[00:42:47.940 --> 00:42:49.460]   What do you think?
[00:42:49.460 --> 00:42:53.340]   I think a lot of people think it makes no sense at all.
[00:42:53.340 --> 00:42:59.060]   I actually think that it's kind of a no brainer because what Apple does is it moves through
[00:42:59.060 --> 00:43:00.700]   these sort of pipelines.
[00:43:00.700 --> 00:43:05.660]   It'll launch a very glossy high end product for the well healed, as Katie said.
[00:43:05.660 --> 00:43:10.260]   And then over time starts to do it in more colors, starts to do it in smaller capacities.
[00:43:10.260 --> 00:43:11.820]   You saw this happen with the iPod, right?
[00:43:11.820 --> 00:43:17.420]   Like there was this huge, beautiful expensive, fancy brick that then got smaller and turned
[00:43:17.420 --> 00:43:20.540]   into the nano and a lot cheaper.
[00:43:20.540 --> 00:43:27.500]   So Apple is approaching that with the iPhone and now has multiple models and may have even
[00:43:27.500 --> 00:43:29.140]   more in the future.
[00:43:29.140 --> 00:43:33.020]   And it's becoming a commodity product that is easily paired with headphones.
[00:43:33.020 --> 00:43:40.100]   And it makes sense to put it together with a brand that is really widely loved with a
[00:43:40.100 --> 00:43:47.060]   lot of shoppers, even if we all kind of know, or those of us who read about it, that, and
[00:43:47.060 --> 00:43:51.900]   we test all these headphones that beats headphones are not, they're just not the best for quality.
[00:43:51.900 --> 00:43:54.300]   They're not, but they're the best for brand.
[00:43:54.300 --> 00:43:55.940]   And Apple loves that.
[00:43:55.940 --> 00:43:56.940]   Yeah.
[00:43:56.940 --> 00:43:57.940]   And you wrote about this.
[00:43:57.940 --> 00:43:58.940]   Also, I think that-
[00:43:58.940 --> 00:43:59.940]   Yeah, go ahead, Katie.
[00:43:59.940 --> 00:44:03.940]   Oh, as you can say, Jessica, a lesson, my editor at the information, she wrote a great
[00:44:03.940 --> 00:44:08.500]   piece also saying that one of the things Apple has to do because of the commoditization effect
[00:44:08.500 --> 00:44:12.260]   of on the phones is that they have to kind of keep things new and cool and make people
[00:44:12.260 --> 00:44:13.740]   want to come.
[00:44:13.740 --> 00:44:18.740]   And so by bringing Jimmy Iveen on board, they have somebody who can do sort of amazing deals
[00:44:18.740 --> 00:44:20.700]   with the record labels.
[00:44:20.700 --> 00:44:21.700]   And who knows?
[00:44:21.700 --> 00:44:22.700]   I mean, that could be-
[00:44:22.700 --> 00:44:23.700]   Who knows what form it would take?
[00:44:23.700 --> 00:44:27.860]   It could be free music or the right to share music or something else we don't know in terms
[00:44:27.860 --> 00:44:29.300]   of in the entertainment space.
[00:44:29.300 --> 00:44:31.980]   But he is a very good deal maker.
[00:44:31.980 --> 00:44:34.140]   He's worked with Eddy Q for like 10 years.
[00:44:34.140 --> 00:44:35.940]   You know, they've known one another for a long time.
[00:44:35.940 --> 00:44:38.500]   He could be a good cultural fit there.
[00:44:38.500 --> 00:44:46.180]   And that that would actually bring to Apple sort of an intellectual property and a study
[00:44:46.180 --> 00:44:50.540]   stream of great entertainment that a lot of other brands don't have.
[00:44:50.540 --> 00:44:52.220]   As Eminem would say, you forgot about Ray.
[00:44:52.220 --> 00:44:55.620]   Is he a good cultural fit with Apple?
[00:44:55.620 --> 00:44:58.180]   I won't make you answer that.
[00:44:58.180 --> 00:45:00.140]   Please.
[00:45:00.140 --> 00:45:02.980]   So you know, here's my view of it.
[00:45:02.980 --> 00:45:07.580]   From where I sit, which is far away from Hollywood as far as I can get, there seems
[00:45:07.580 --> 00:45:12.580]   to be that the music business has had two big shifts in its business in the last 15 years
[00:45:12.580 --> 00:45:13.580]   or something like that.
[00:45:13.580 --> 00:45:19.260]   The first is iTunes and the iPod, but the iTunes model of selling songs individually,
[00:45:19.260 --> 00:45:23.300]   digitally, and this has a positive benefit for the music industry and what they consider
[00:45:23.300 --> 00:45:24.300]   to a negative benefit.
[00:45:24.300 --> 00:45:28.060]   The positive benefit is people are actually paying for music instead of stealing it, which
[00:45:28.060 --> 00:45:30.660]   is super easy to do.
[00:45:30.660 --> 00:45:33.660]   And the negative business is that people are not buying albums.
[00:45:33.660 --> 00:45:40.540]   I mean, I remember when you'd go to a record store and you'd buy an $18 CD and you only
[00:45:40.540 --> 00:45:44.100]   wanted the one song, but $18 was the price to get that song.
[00:45:44.100 --> 00:45:47.500]   And that was a model that the music industry really seemed to love.
[00:45:47.500 --> 00:45:54.820]   So Steve Jobs' iTunes model was a nuclear bomb in the music business where everybody
[00:45:54.820 --> 00:45:57.460]   used to get rich selling songs.
[00:45:57.460 --> 00:46:00.300]   The second one is called the 360 deal.
[00:46:00.300 --> 00:46:04.620]   This is something that hit around 2007 or so, which is that everybody realized because
[00:46:04.620 --> 00:46:09.700]   of digitization, music is worthless because there's no scarcity with music.
[00:46:09.700 --> 00:46:10.860]   You have a digital file.
[00:46:10.860 --> 00:46:14.860]   It's just you can download it a billion times and it's the same file.
[00:46:14.860 --> 00:46:21.060]   It's very difficult to impose scarcity for the purpose of imposing revenue associated
[00:46:21.060 --> 00:46:22.060]   with that.
[00:46:22.060 --> 00:46:23.060]   So they came up with these 360 deals.
[00:46:23.060 --> 00:46:29.220]   Instead of going to a superstar, a musician and saying, "Okay, here's the record contract.
[00:46:29.220 --> 00:46:30.220]   We're going to make this much money.
[00:46:30.220 --> 00:46:33.300]   We're going to make platinum records and you get this percentage of the music sales."
[00:46:33.300 --> 00:46:35.580]   They instead go, "Okay, here's the deal.
[00:46:35.580 --> 00:46:38.580]   You're going to promote this and you're going to sell this and you're going to have
[00:46:38.580 --> 00:46:42.260]   co-brand with that and you're going to have this concert thing and that's the deal."
[00:46:42.260 --> 00:46:43.260]   Forget about the music.
[00:46:43.260 --> 00:46:44.260]   That's right.
[00:46:44.260 --> 00:46:45.260]   At the end of the day.
[00:46:45.260 --> 00:46:46.260]   That's right.
[00:46:46.260 --> 00:46:48.620]   And so the poster child for this concept of the 360 deal, who's probably done it better
[00:46:48.620 --> 00:46:50.620]   than anybody, is Lady Gaga.
[00:46:50.620 --> 00:46:56.620]   And her original business manager actually said that music sells everything except music.
[00:46:56.620 --> 00:47:00.380]   In other words, music is a great marketing vehicle and so let's use that and that's the
[00:47:00.380 --> 00:47:01.380]   new model.
[00:47:01.380 --> 00:47:06.860]   And Jimmy Iovine has been personally involved in that whole recreation.
[00:47:06.860 --> 00:47:12.220]   So the two people, most associated, maybe the three people, most associated with transforming
[00:47:12.220 --> 00:47:17.220]   and evolving the music business are Steve Jobs and Jimmy Iovine and to a certain extent,
[00:47:17.220 --> 00:47:20.380]   Lady Gaga and her business manager and so on.
[00:47:20.380 --> 00:47:26.700]   So I think that to a certain extent, iTunes Music is the real prize here and although it
[00:47:26.700 --> 00:47:33.700]   doesn't exist now in terms of having the 360 deal stuff, they have been working on getting
[00:47:33.700 --> 00:47:38.060]   beats music to the point where that's the 360 deal service.
[00:47:38.060 --> 00:47:42.140]   In other words, while everybody else is trying to sell subscriptions to streaming music, I
[00:47:42.140 --> 00:47:47.380]   think that beats music has been working on a system where that's the place where musicians
[00:47:47.380 --> 00:47:50.860]   and artists can sell everything except the music.
[00:47:50.860 --> 00:47:54.260]   You give the music away even to a certain extent.
[00:47:54.260 --> 00:47:57.180]   But then you sell it and of course beats has been at the center of this.
[00:47:57.180 --> 00:48:01.940]   If you look at what Lady Gaga has been making money on, it's been headphones and concert
[00:48:01.940 --> 00:48:04.100]   tickets and all these things that have nothing to do with music.
[00:48:04.100 --> 00:48:06.300]   So I really think that's what it's all about.
[00:48:06.300 --> 00:48:11.780]   They bought somebody who's like the Johnny Iov of music business, right?
[00:48:11.780 --> 00:48:17.540]   A special person who's super knowledgeable and irreplaceable and if he doesn't go with
[00:48:17.540 --> 00:48:20.340]   Apple, he's going to work for somebody else, probably Google or somebody like that.
[00:48:20.340 --> 00:48:24.460]   So I think that has a lot to do with this whole thing.
[00:48:24.460 --> 00:48:29.820]   So Katie Benner, I don't know what the future of music is going to be but it's going to
[00:48:29.820 --> 00:48:32.820]   involve very cheap music and very expensive headphones.
[00:48:32.820 --> 00:48:33.820]   Sure.
[00:48:33.820 --> 00:48:34.820]   I'd agree.
[00:48:34.820 --> 00:48:38.820]   And if you look at how they've been selling beats, it's been like, you know, there's a
[00:48:38.820 --> 00:48:41.820]   Lady Gaga version of beats and is this that and the other thing and I think that's really
[00:48:41.820 --> 00:48:45.420]   the future of what Apple is going to do and Apple wants to be the forefront of that.
[00:48:45.420 --> 00:48:46.420]   So we'll see how that goes.
[00:48:46.420 --> 00:48:50.420]   Yeah, I mean, no matter what you think of the quality of Beats products, it's one of
[00:48:50.420 --> 00:48:53.740]   the few consumer electronics brands that's been created in the last 10 or 20 years.
[00:48:53.740 --> 00:48:59.020]   It matters and it went from not existing to dominating a category amazingly quickly.
[00:48:59.020 --> 00:49:02.500]   And it sort of feels now that like Beats has been around forever even though I think
[00:49:02.500 --> 00:49:03.500]   it's about six years old.
[00:49:03.500 --> 00:49:04.500]   That's right.
[00:49:04.500 --> 00:49:07.100]   Almost nobody has done that in a long time.
[00:49:07.100 --> 00:49:08.100]   That's right.
[00:49:08.100 --> 00:49:15.020]   And the conventional wisdom is that you can make beats for 15 to $17, sell them for $200.
[00:49:15.020 --> 00:49:19.940]   And they own 65% of the so-called high-end headphones market.
[00:49:19.940 --> 00:49:22.060]   I mean, what's not to love?
[00:49:22.060 --> 00:49:25.500]   My kids don't, they don't really know of any other headphones.
[00:49:25.500 --> 00:49:28.140]   I mean, they just go straight to it.
[00:49:28.140 --> 00:49:29.140]   That's right.
[00:49:29.140 --> 00:49:30.420]   And that's what you have.
[00:49:30.420 --> 00:49:31.420]   And why?
[00:49:31.420 --> 00:49:35.860]   Because it's associated with celebrity and they really want the music and, you know, music
[00:49:35.860 --> 00:49:40.740]   fans really want to be into the bands and the singers and the artists and so on.
[00:49:40.740 --> 00:49:42.900]   And there's a hardware component to that, apparently.
[00:49:42.900 --> 00:49:44.580]   Well, there's a design component to it, too.
[00:49:44.580 --> 00:49:49.060]   I mean, I think it's worth not forgetting that Apple, more than any other electronics
[00:49:49.060 --> 00:49:54.340]   manufacturer cares about the design ethos, all their products.
[00:49:54.340 --> 00:49:55.940]   And Beats is just like that.
[00:49:55.940 --> 00:49:59.260]   I'm not saying they have exactly the same design or the same approach.
[00:49:59.260 --> 00:50:03.300]   But a lot of the money that you're paying for is for industrial design and for the colors
[00:50:03.300 --> 00:50:07.260]   and the shape and the fact that you want to be seen in the airport wearing these.
[00:50:07.260 --> 00:50:08.260]   Yeah.
[00:50:08.260 --> 00:50:11.260]   Although, oddly enough, I mean, all of the Beats products today have been designed by
[00:50:11.260 --> 00:50:14.620]   this guy who used to be Johnny Ives Boss at Apple.
[00:50:14.620 --> 00:50:19.900]   And already they've said that that company, Ammunition Group, will not be designing Beats
[00:50:19.900 --> 00:50:24.980]   products moving forward and will be intriguing to see who does design them and whether the
[00:50:24.980 --> 00:50:26.500]   look and feel changes at all.
[00:50:26.500 --> 00:50:27.500]   Yeah.
[00:50:27.500 --> 00:50:28.500]   They need help on multiple fronts.
[00:50:28.500 --> 00:50:31.220]   One is the design and Apple can help with that.
[00:50:31.220 --> 00:50:35.620]   Another one is they need help with Beats Music because signing up for Beats Music is really
[00:50:35.620 --> 00:50:36.780]   clunky and really horrible.
[00:50:36.780 --> 00:50:40.620]   I tried to do it over the last couple of days and I tried to get in on this AT&T deal
[00:50:40.620 --> 00:50:43.500]   so you can get like this family plan, five people for $15.
[00:50:43.500 --> 00:50:44.940]   It's a great deal.
[00:50:44.940 --> 00:50:48.020]   But trying to actually make it happen is very, very difficult.
[00:50:48.020 --> 00:50:50.140]   And so Apple might be able to help them with that.
[00:50:50.140 --> 00:50:57.260]   Well, another area where Apple is hoping to sort of create new business around home automation.
[00:50:57.260 --> 00:50:58.900]   And home automation is super, super exciting.
[00:50:58.900 --> 00:51:02.420]   We talked about what you're doing in home automation at CNET.
[00:51:02.420 --> 00:51:08.420]   And what Apple is doing according to the reports is really not that earth shattering, is it?
[00:51:08.420 --> 00:51:12.140]   I mean, already if you go to Kickstarter, you look around at what's really happening
[00:51:12.140 --> 00:51:16.020]   in home automation, Apple's already kind of at the forefront to the extent that people
[00:51:16.020 --> 00:51:20.020]   create apps that run on iOS first and Android second.
[00:51:20.020 --> 00:51:23.740]   And so they're already kind of an accidental leader and they're trying to get in front
[00:51:23.740 --> 00:51:24.740]   of the parade a little bit.
[00:51:24.740 --> 00:51:25.740]   So--
[00:51:25.740 --> 00:51:26.740]   What's going on here?
[00:51:26.740 --> 00:51:33.780]   Well, Apple is prepping a platform which is supposed to come out at WWDC tomorrow.
[00:51:33.780 --> 00:51:38.420]   And they're talking about some APIs and just sort of a lightweight getting in front of
[00:51:38.420 --> 00:51:44.700]   the parade that already exists for home automation and giving home automation creators a simpler
[00:51:44.700 --> 00:51:49.060]   way to embrace Apple's coming platform for home automation.
[00:51:49.060 --> 00:51:52.060]   Yeah, I mean, I think there's a huge opportunity.
[00:51:52.060 --> 00:51:57.380]   And one of the things that every time somebody from CNET's on a panel about home automation,
[00:51:57.380 --> 00:52:03.100]   one of the things that we end up talking about is the fact that there are-- there are
[00:52:03.100 --> 00:52:05.980]   so many opportunities out there, but you don't want to have a separate app for your
[00:52:05.980 --> 00:52:09.660]   vacuum and for your light bulb and then another app for your thermostat and then an app for
[00:52:09.660 --> 00:52:10.660]   your smart lock.
[00:52:10.660 --> 00:52:13.020]   Which is exactly what it is where you are today.
[00:52:13.020 --> 00:52:16.580]   Which is exactly where you are today if you're even ready to sort of invest your time and
[00:52:16.580 --> 00:52:19.380]   money in a pretty young category.
[00:52:19.380 --> 00:52:23.460]   And so what Apple wants to do, I think, is just create sort of a, you know, past book
[00:52:23.460 --> 00:52:24.820]   kind of style.
[00:52:24.820 --> 00:52:26.540]   Let's wrap it all up into a simple interface.
[00:52:26.540 --> 00:52:27.980]   I think it's kind of as an aside.
[00:52:27.980 --> 00:52:31.740]   I think it's kind of interesting that Apple which sort of created this, there's an app
[00:52:31.740 --> 00:52:33.140]   for everything.
[00:52:33.140 --> 00:52:37.500]   You know, millions of apps out there is now in a position to be being like, well, you
[00:52:37.500 --> 00:52:41.660]   don't really need-- let's-- maybe you don't need so many apps.
[00:52:41.660 --> 00:52:45.460]   Let's try to kind of get them corralled into a manageable space.
[00:52:45.460 --> 00:52:49.260]   The other thing that Apple has going for it here is that it has a little bit of a head
[00:52:49.260 --> 00:52:53.940]   start with some of this home automation because of its low powered Bluetooth in every single
[00:52:53.940 --> 00:52:54.940]   phone.
[00:52:54.940 --> 00:52:56.740]   Not all Android phones have that or other phones.
[00:52:56.740 --> 00:53:00.100]   And so Apple's already in early with some of the smart locks.
[00:53:00.100 --> 00:53:05.780]   And if they can sort of keep all of the third party developers and manufacturers thinking
[00:53:05.780 --> 00:53:11.260]   of Apple first, that's another reason to buy into the Apple ecosystem because it's just
[00:53:11.260 --> 00:53:12.420]   going to be in a tidy package.
[00:53:12.420 --> 00:53:15.540]   And so if you're a person who's going to go out and buy a thermostat and buy smart lights
[00:53:15.540 --> 00:53:22.060]   and buy a vacuum that you control with your phone, then that's sort of an easy choice.
[00:53:22.060 --> 00:53:23.060]   Yeah.
[00:53:23.060 --> 00:53:25.900]   And Apple was the first to support Bluetooth Low Energy.
[00:53:25.900 --> 00:53:29.940]   Bluetooth Smart, it's got multiple-- Bluetooth 4.0, there's got a bunch of names.
[00:53:29.940 --> 00:53:34.260]   But Apple was the first to put that into a phone, the iPhone 4S.
[00:53:34.260 --> 00:53:39.540]   And since then, every phone tablet laptop has supported Bluetooth Low Energy, now just
[00:53:39.540 --> 00:53:40.980]   about everybody does.
[00:53:40.980 --> 00:53:46.700]   The other thing that they have Harry McCracken that is really, I think, an underappreciated
[00:53:46.700 --> 00:53:49.500]   resource is Ibekin.
[00:53:49.500 --> 00:53:55.380]   Because if you remember Bill Gates built a revolutionary house years ago, and the way
[00:53:55.380 --> 00:53:57.820]   his house worked was you'd put on this little badge.
[00:53:57.820 --> 00:54:01.540]   He's welcome to Bill Gates' house and you'd get a badge or this pin or whatever it was.
[00:54:01.540 --> 00:54:04.100]   It was a little-- I guess it was RFID or something like that.
[00:54:04.100 --> 00:54:05.940]   It was some kind of radio thing.
[00:54:05.940 --> 00:54:10.380]   And as you walk through the house, or so I've heard, he hasn't invited me over yet for
[00:54:10.380 --> 00:54:12.820]   some reason.
[00:54:12.820 --> 00:54:15.820]   You can say, oh, I like Dr. Dre music.
[00:54:15.820 --> 00:54:19.780]   And everywhere you go in the house, Dr. Dre music would follow you when your lighting
[00:54:19.780 --> 00:54:22.180]   preferences would follow you around.
[00:54:22.180 --> 00:54:24.380]   That's totally great with Ibekin.
[00:54:24.380 --> 00:54:25.700]   That's how you want home automation to work.
[00:54:25.700 --> 00:54:28.740]   You want to walk up to the thing and have the porch light go on and the door to unlock
[00:54:28.740 --> 00:54:31.180]   and have it know where you are.
[00:54:31.180 --> 00:54:37.820]   Yeah, Ibekin has very quietly been very important in retail and things like stadiums.
[00:54:37.820 --> 00:54:42.700]   That's how a store or a stadium knows where you are and is able to push stuff to your
[00:54:42.700 --> 00:54:48.380]   phone in a way that actually does maintain your privacy because they only do it if you
[00:54:48.380 --> 00:54:50.500]   already have a relationship with them and have given them permission.
[00:54:50.500 --> 00:54:54.980]   And I think there are potentially a lot of parallels to what Apple might do in the home
[00:54:54.980 --> 00:55:01.220]   because Ibekin is mainly the fact that all the Apple devices support Bluetooth L8 and
[00:55:01.220 --> 00:55:06.220]   Apple worked on standards and stuff so that other companies can sell the beacon equipment
[00:55:06.220 --> 00:55:11.420]   and stores and be confident it will work with Apple devices.
[00:55:11.420 --> 00:55:16.940]   So Apple doesn't necessarily have to build enormous amounts of stuff on its own.
[00:55:16.940 --> 00:55:20.980]   Maybe all it does is it makes its devices the best platforms for other companies to
[00:55:20.980 --> 00:55:24.780]   build home automation on which they already sort of are already even without Apple having
[00:55:24.780 --> 00:55:26.460]   done too much yet.
[00:55:26.460 --> 00:55:32.260]   And I think that Ibekin is a seriously under appreciated or misunderstood or you know it's
[00:55:32.260 --> 00:55:33.660]   kind of below the radar.
[00:55:33.660 --> 00:55:35.460]   Apple doesn't understand how it works.
[00:55:35.460 --> 00:55:40.140]   For example, people don't seem to know that Android supports Android.
[00:55:40.140 --> 00:55:43.860]   So if you're an Android phone and Ibekin is really no big deal and it's also seen as
[00:55:43.860 --> 00:55:48.580]   a sort of an NSA spy thing that sort of reaches into your phone and doesn't do anything of
[00:55:48.580 --> 00:55:49.580]   the kind.
[00:55:49.580 --> 00:55:53.700]   Ibekins are to the best of my knowledge incapable of receiving information.
[00:55:53.700 --> 00:55:56.380]   They simply broadcast, "Here's where I am and then here."
[00:55:56.380 --> 00:55:57.380]   I'm here, I'm here.
[00:55:57.380 --> 00:55:58.380]   That's right.
[00:55:58.380 --> 00:56:01.780]   And then the app is the thing that goes out to the internet if the app has developed that
[00:56:01.780 --> 00:56:02.780]   capability.
[00:56:02.780 --> 00:56:08.260]   The app is the thing that knows, you know, the, "Oh, your Ibekin XYZ, Ibekin XYZ is in
[00:56:08.260 --> 00:56:09.820]   this particular location."
[00:56:09.820 --> 00:56:10.980]   The bekin doesn't even know where it is.
[00:56:10.980 --> 00:56:13.580]   It just knows who it is and so to a certain extent.
[00:56:13.580 --> 00:56:16.740]   So it's a really fascinating technology and one of the things that's most fascinating
[00:56:16.740 --> 00:56:17.740]   about it is that it's cheap.
[00:56:17.740 --> 00:56:20.020]   You can put bekins all over the place.
[00:56:20.020 --> 00:56:24.540]   A small business can put 10 bekins in and it costs them 100 bucks or something like that.
[00:56:24.540 --> 00:56:28.460]   You know, so it's a pretty exciting technology and I think it's really under-appreciated
[00:56:28.460 --> 00:56:30.460]   for home automation and a known brainer.
[00:56:30.460 --> 00:56:35.740]   I'm also curious about when the Googles and the Apples and the Amazons are going to build
[00:56:35.740 --> 00:56:38.740]   home automation into their TV set that boxes.
[00:56:38.740 --> 00:56:40.580]   Seems like an obvious place.
[00:56:40.580 --> 00:56:45.500]   So if I think, and this is just pure speculation, but if Apple is developing, is actually developing
[00:56:45.500 --> 00:56:49.780]   a television, wouldn't it make sense for them to start with one that's sort of small and
[00:56:49.780 --> 00:56:55.620]   beautiful in the way that, you know, a Mac Pro screen is or you've got the sort of retina.
[00:56:55.620 --> 00:57:01.500]   And then all of this home automation technology built right into that interface and to that
[00:57:01.500 --> 00:57:02.500]   television.
[00:57:02.500 --> 00:57:05.740]   So the first place you would think of putting that is in your kitchen or some place where
[00:57:05.740 --> 00:57:11.740]   you would automate or you would already go to sort of check in and see what's up and
[00:57:11.740 --> 00:57:17.060]   who came in the back door when and my back porch lights still on and all of that sort
[00:57:17.060 --> 00:57:20.940]   of built into a sort of smaller screen that's really beautiful and something that you want
[00:57:20.940 --> 00:57:23.820]   to be part of the decor of your home.
[00:57:23.820 --> 00:57:25.700]   It might make a ton of sense.
[00:57:25.700 --> 00:57:26.700]   Yeah, absolutely.
[00:57:26.700 --> 00:57:32.540]   Well, and just a sec, we're going to look at the latest outrage by the NSA and what
[00:57:32.540 --> 00:57:34.260]   they're harvesting now.
[00:57:34.260 --> 00:57:35.260]   It's going to be exciting.
[00:57:35.260 --> 00:57:36.860]   I can't wait to talk about that one.
[00:57:36.860 --> 00:57:40.260]   But first, I want to tell you about audible.com now.
[00:57:40.260 --> 00:57:44.820]   Leo Leport always says that he's been an audio listener for a long, long time.
[00:57:44.820 --> 00:57:48.060]   I think I was an audio audible.com customer before he was.
[00:57:48.060 --> 00:57:50.500]   I think I signed up in the year 2000.
[00:57:50.500 --> 00:57:52.260]   Believe it or not.
[00:57:52.260 --> 00:57:56.540]   And audible was actually a hardware, you were in high school and then see it was actually
[00:57:56.540 --> 00:57:59.060]   a hardware device that you would buy.
[00:57:59.060 --> 00:58:01.860]   Was this the weird teardrop shaped thing?
[00:58:01.860 --> 00:58:07.620]   And I remember I actually demoed it to Regis and Kathy Lee back in the year 2000.
[00:58:07.620 --> 00:58:11.860]   And ever since then I've been an audible.com listener and it's a fantastic service.
[00:58:11.860 --> 00:58:15.300]   Obviously audible has 150,000 titles to choose from.
[00:58:15.300 --> 00:58:19.380]   It's the world's largest selection of premium audio books and spoken word content.
[00:58:19.380 --> 00:58:21.660]   To me it's a no brainer.
[00:58:21.660 --> 00:58:25.260]   Stories are an oral medium until very recently.
[00:58:25.260 --> 00:58:31.740]   And to be read to by a professional actor to me just is a source of joy and wonder and
[00:58:31.740 --> 00:58:34.660]   enables me to do the dishes and still learn something.
[00:58:34.660 --> 00:58:36.500]   And I really love it.
[00:58:36.500 --> 00:58:40.660]   Now we have a special offer for this week in tech.
[00:58:40.660 --> 00:58:42.940]   We're offering a platinum plan from audible.com.
[00:58:42.940 --> 00:58:46.900]   This gives you two free audio books right out of the gate and two book credits a month.
[00:58:46.900 --> 00:58:51.740]   That means basically you can, on average you can download two books under this plan.
[00:58:51.740 --> 00:58:55.060]   And it's a great deal for people who really get a lot out of these books.
[00:58:55.060 --> 00:58:58.600]   You can get a free subscription to the Wall Street Journal or the New York Times daily audio
[00:58:58.600 --> 00:58:59.800]   programs.
[00:58:59.800 --> 00:59:00.880]   Take your pick.
[00:59:00.880 --> 00:59:05.540]   And if you want to get more details about the platinum plan go to audible.com/twits2.
[00:59:05.540 --> 00:59:08.940]   That's audible.com, Twit and the number 2.
[00:59:08.940 --> 00:59:12.060]   And you know there's a couple of new books that just hit in the last couple of days that
[00:59:12.060 --> 00:59:13.780]   I wanted to bring our attention to here.
[00:59:13.780 --> 00:59:18.700]   The first is our final invention, artificial intelligence and the end of the human era
[00:59:18.700 --> 00:59:20.500]   by James Barrett.
[00:59:20.500 --> 00:59:25.260]   Now Leo Laport interviewed James Barrett on the most recent episode of triangulation.
[00:59:25.260 --> 00:59:26.660]   And this picked my interest in this book.
[00:59:26.660 --> 00:59:30.780]   This sounds like a fantastic book and I haven't downloaded it yet or listened to it yet.
[00:59:30.780 --> 00:59:33.260]   But this sounds like a really, really fantastic book.
[00:59:33.260 --> 00:59:37.780]   And Chad can you play just play the sample there so we can take a listen.
[00:59:37.780 --> 00:59:41.940]   Being suspicious of AI was painful for two reasons.
[00:59:41.940 --> 00:59:46.380]   Thinking about its promise that planted a seed in my mind that I wanted to cultivate,
[00:59:46.380 --> 00:59:47.820]   not question.
[00:59:47.820 --> 00:59:52.180]   And second, I did not doubt AI's existence or power.
[00:59:52.180 --> 00:59:55.780]   What I was skeptical about was advanced AI safety.
[00:59:55.780 --> 00:59:56.780]   Sounds pretty awesome.
[00:59:56.780 --> 01:00:00.100]   I for one welcome our new artificial intelligence overlords.
[01:00:00.100 --> 01:00:02.300]   And can't wait to listen to this book.
[01:00:02.300 --> 01:00:07.340]   So let's look at another book that to me is a source of fascination and I'm going to
[01:00:07.340 --> 01:00:08.580]   get this on audible.com.
[01:00:08.580 --> 01:00:13.460]   It's called The Man Who Knew Too Much, Alan Turing and The Invention of the Computer
[01:00:13.460 --> 01:00:15.380]   by David Leavitt.
[01:00:15.380 --> 01:00:22.700]   And this of course, the life of Alan Turing is one of fascination for multiple reasons.
[01:00:22.700 --> 01:00:29.300]   He was just a genius as a child who is also in some ways not so bright as a child.
[01:00:29.300 --> 01:00:36.460]   He's one of these kind of idiots of aunt children, grew up to become an amazing codebreaker.
[01:00:36.460 --> 01:00:41.340]   And of course he was a homosexual who was persecuted for that and I think he was recently pardoned
[01:00:41.340 --> 01:00:42.860]   or something like that by some.
[01:00:42.860 --> 01:00:48.620]   Anyway, it's a fascinating story and I hope they do a movie but in the meantime, The Man
[01:00:48.620 --> 01:00:52.020]   Who Knew Too Much is an awesome audible.com book.
[01:00:52.020 --> 01:00:56.980]   And so these are the kinds of things that you get at audible.com and I recommend that
[01:00:56.980 --> 01:00:59.580]   everybody sign up if you don't already have a subscription.
[01:00:59.580 --> 01:01:05.700]   14 years I've had audible.com and that is why I am such a towering genius.
[01:01:05.700 --> 01:01:09.060]   That's why I have fun doing the dishes at least.
[01:01:09.060 --> 01:01:12.900]   Well NSA is harvesting something new.
[01:01:12.900 --> 01:01:17.980]   The gift to keep on giving the Edward Snowden revelations just keep coming from, I guess
[01:01:17.980 --> 01:01:22.700]   they all come from Glenn Greenwald ultimately, who is the person to whom Edward Snowden leaked
[01:01:22.700 --> 01:01:26.740]   these documents and he's trickling them out to keep the information high.
[01:01:26.740 --> 01:01:34.220]   But basically the NSA turns out it's been harvesting millions of pictures every single
[01:01:34.220 --> 01:01:35.780]   day.
[01:01:35.780 --> 01:01:41.940]   They harvest and a great thousands of them are sort of facial image recognition quality
[01:01:41.940 --> 01:01:48.500]   and apparently according to the latest revelations they are gathering these pictures, they're
[01:01:48.500 --> 01:01:52.500]   putting them in their database and what they're going for is they want a database that enables
[01:01:52.500 --> 01:01:56.900]   them to essentially take a picture from a security camera, run it through their system
[01:01:56.900 --> 01:01:59.780]   and say that's who this is.
[01:01:59.780 --> 01:02:08.540]   It's really quite stunning how many hard drives do you have to get at Best Buy in order to
[01:02:08.540 --> 01:02:12.540]   store millions of pictures downloaded every day.
[01:02:12.540 --> 01:02:13.940]   It's just incredible.
[01:02:13.940 --> 01:02:19.660]   Well the government already has tons of pictures of us stored because the State Department
[01:02:19.660 --> 01:02:25.220]   has all of those passport photos and I think that they're not saying whether they're intermingling
[01:02:25.220 --> 01:02:28.660]   what the NSA is doing, what those passport photos are not.
[01:02:28.660 --> 01:02:34.100]   I think it would be silly to say that this is inherently a terrible idea.
[01:02:34.100 --> 01:02:37.180]   I mean if they do it the right way this sounds like it could be a really good way to find
[01:02:37.180 --> 01:02:42.340]   people we want to find and the big question as always is how many other innocent people
[01:02:42.340 --> 01:02:44.100]   might get caught up in it.
[01:02:44.100 --> 01:02:45.100]   I think the other question is-
[01:02:45.100 --> 01:02:50.820]   It's all where we've done in Moreman High and I mean after 9/11 New York City its own
[01:02:50.820 --> 01:02:56.780]   counterterrorism unit created a lot of initiatives and one works with businesses all over Lower
[01:02:56.780 --> 01:03:03.220]   Manhatt and basically because all of these businesses have security footage and they
[01:03:03.220 --> 01:03:08.500]   are able to access that security footage and they do store some of it and they're basically
[01:03:08.500 --> 01:03:11.060]   looking for people who they need to find.
[01:03:11.060 --> 01:03:13.620]   So this isn't unheard of.
[01:03:13.620 --> 01:03:16.900]   This is a more extreme example but it's not unheard of.
[01:03:16.900 --> 01:03:18.540]   I think a lot of the-
[01:03:18.540 --> 01:03:21.540]   Whether or not there's an extreme concern about this practice has to do with where the
[01:03:21.540 --> 01:03:23.100]   images are coming from.
[01:03:23.100 --> 01:03:28.020]   If the images are coming from the open web well those images are out there and you know
[01:03:28.020 --> 01:03:32.460]   you put an image of yourself on the internet it's pretty likely that somebody's going to
[01:03:32.460 --> 01:03:33.460]   look at it.
[01:03:33.460 --> 01:03:38.340]   We know that that's the risk we take when we publish selfies.
[01:03:38.340 --> 01:03:43.300]   The question is like if the NSA were intercepting these and pulling them off your phone and
[01:03:43.300 --> 01:03:46.540]   they were private images that's a completely different situation.
[01:03:46.540 --> 01:03:51.740]   It's so far from what I've read I haven't seen that come up.
[01:03:51.740 --> 01:03:56.620]   Well I mean you know the revelations that started with one of the first revelations
[01:03:56.620 --> 01:04:01.740]   this first or second one was about PRISM which is about you know the NSA essentially
[01:04:01.740 --> 01:04:07.500]   finding ways to tap the internet connections coming and going from the likes of Google
[01:04:07.500 --> 01:04:12.100]   and Facebook servers or data centers and that stuff all has pictures in it.
[01:04:12.100 --> 01:04:16.300]   I mean if you look at Facebook alone you know I don't know how many pictures are uploaded
[01:04:16.300 --> 01:04:21.540]   to Facebook every day but it's just an astonishingly high number and if they're getting the
[01:04:21.540 --> 01:04:23.020]   data that data includes pictures.
[01:04:23.020 --> 01:04:27.220]   I mean I think that's what we're talking about here I think it's kind of obvious really in
[01:04:27.220 --> 01:04:29.460]   retrospect they're not just going to skim off the text.
[01:04:29.460 --> 01:04:34.660]   I mean you might think they would simply because of the scale of this thing but they're
[01:04:34.660 --> 01:04:37.020]   not worried about scale.
[01:04:37.020 --> 01:04:42.620]   There's an interesting controversy within Utah over the NSA's Bluffdale Utah data center
[01:04:42.620 --> 01:04:48.980]   which is supposed to be just massive and the scandal is that there are anti there are
[01:04:48.980 --> 01:04:56.060]   political actors within Utah state politics that are opposing this kind of mass surveillance
[01:04:56.060 --> 01:04:59.300]   and they want to shut down the NSA about cutting off their water.
[01:04:59.300 --> 01:05:03.980]   Data center like that needs massive amounts of water for cooling and so there's been a
[01:05:03.980 --> 01:05:09.820]   political fight within Utah to shut off the NSA's water they're probably going to fail
[01:05:09.820 --> 01:05:14.740]   but that's one of the interesting things about this whole scenario which is that a national
[01:05:14.740 --> 01:05:19.740]   organization like the NSA has to exist in a state or the or Washington DC and so they
[01:05:19.740 --> 01:05:24.660]   need essentially they need resources from state governments and so that is an interesting
[01:05:24.660 --> 01:05:27.340]   way to sort of put the brakes on NSA.
[01:05:27.340 --> 01:05:32.460]   We'll see if it goes anywhere but this whole story of the NSA collecting images is the
[01:05:32.460 --> 01:05:38.260]   outrage to sure and you know Harry McCracken we were on tech news today and I think we talked
[01:05:38.260 --> 01:05:44.420]   about the book No Place to Hide which I think I had just started it when we were talking
[01:05:44.420 --> 01:05:49.980]   and I recently finished it and that is a fascinating book that was really an incredible
[01:05:49.980 --> 01:05:56.900]   book because he not only goes in and details the sort of story about how he was contacted
[01:05:56.900 --> 01:06:01.660]   by Edward Snowden he kind of blew him off as a hack for many months because Snowden
[01:06:01.660 --> 01:06:05.060]   wanted him to install encryption he's like I don't have time to install encryption then
[01:06:05.060 --> 01:06:08.820]   the whole hotel room thing when they did the video and all that stuff Glenn Greenwald
[01:06:08.820 --> 01:06:13.180]   was the person sitting there interviewing him and then so there's the whole sort of chase
[01:06:13.180 --> 01:06:17.740]   cop and robbers chase thing and at the end he gives the most fascinating parts of the
[01:06:17.740 --> 01:06:23.060]   psychological effects of surveillance on the public which is that if you know you're
[01:06:23.060 --> 01:06:26.900]   being watched to change your behavior you know and that's the thing about you know the argument
[01:06:26.900 --> 01:06:30.940]   against the argument in favor of the NSA is they're not you know if you have nothing to
[01:06:30.940 --> 01:06:36.420]   hide you know it's okay I worry about it but the fact that we now know that they're surveilling
[01:06:36.420 --> 01:06:43.980]   us makes people you know stick to what they call I guess social norms of behavior instead
[01:06:43.980 --> 01:06:48.180]   of experimenting with things trying things and so on so it's that's a fascinating book
[01:06:48.180 --> 01:06:54.700]   that you come out of it liking Glenn Greenwald more I find him a little I admire him in some
[01:06:54.700 --> 01:06:59.020]   ways I also find it be so much grading because he spends so much time complaining about anybody
[01:06:59.020 --> 01:07:02.100]   and everybody who does not agree with him on everything yeah and I have not read the
[01:07:02.100 --> 01:07:06.260]   block partially because I'm a little intimidated by spending so much time with Glenn Greenwald
[01:07:06.260 --> 01:07:11.740]   yeah he is he is a and that's one of the you know I guess his personality in general
[01:07:11.740 --> 01:07:15.740]   is why Edward Snowden picked him because he's a bit of a bulldog as you can remember actually
[01:07:15.740 --> 01:07:23.020]   when time did not name Edward Snowden as person of the year Glenn Greenwald was appalled
[01:07:23.020 --> 01:07:31.540]   and said so incessantly we named the Pope I think there was also a good case for yeah
[01:07:31.540 --> 01:07:37.540]   the Pope is an unusual character as well just like Glenn Greenwald and Edward Snowden but
[01:07:37.540 --> 01:07:43.260]   you know you know Glenn Greenwald is as an editorialist yourself you would appreciate
[01:07:43.260 --> 01:07:46.380]   I think you'd come out of it with a similar view that I did which it makes a lot of good
[01:07:46.380 --> 01:07:50.940]   points and it's definitely worth reading he makes some faulty points as well there's
[01:07:50.940 --> 01:07:55.860]   he's got some bad reasoning in there for example he's been in debates with people who say oh
[01:07:55.860 --> 01:07:59.980]   you know surveillance is not you know that big of a deal and so he's challenged in the
[01:07:59.980 --> 01:08:02.700]   case so why don't you tell us your phone number and your credit card number and all that kind
[01:08:02.700 --> 01:08:07.020]   of stuff that that's a that's a that's a bad argument just from an argumentation standpoint
[01:08:07.020 --> 01:08:12.460]   because there's a difference between the revelation of data that will have 100 100% chance of being
[01:08:12.460 --> 01:08:17.100]   exploited in a negative way which is when a person who's in favor of the NSA publicly
[01:08:17.100 --> 01:08:21.460]   gives their personal information and the NSA when they're harvesting things and chances
[01:08:21.460 --> 01:08:27.100]   are you know nothing that that outrageous is going to happen those are that's apple and
[01:08:27.100 --> 01:08:32.980]   oranges that's a bad argument but he but the rest of it is so interesting and I just think
[01:08:32.980 --> 01:08:37.220]   it's I think it's worth reading even if it is a flawed account it's the best thing we've
[01:08:37.220 --> 01:08:41.140]   got and it's really you know there are few books that have that many revelations that
[01:08:41.140 --> 01:08:46.340]   much information about how the whole thing works and all of a sudden Don I think he's
[01:08:46.340 --> 01:08:52.120]   a force for good yeah I came out I have to admit that I came out of it with a greater
[01:08:52.120 --> 01:08:57.320]   respect for Edward Snowden who about whom I've been on the fence and I thought you know he's
[01:08:57.320 --> 01:09:02.320]   kind of a shameless self-aggrandizing whatever and then at the end of this book I thought
[01:09:02.320 --> 01:09:12.000]   you know he he's a he's he's a I guess the way to put it is that he's a more laudable
[01:09:12.000 --> 01:09:17.840]   person than I thought he's what he's doing is braver than I thought it was and a little
[01:09:17.840 --> 01:09:22.980]   bit more selfless than I thought it was and so I came out with it with a better view of
[01:09:22.980 --> 01:09:29.940]   him probably identical view of Glenn Greenwald who who I like I mean you know which that's
[01:09:29.940 --> 01:09:32.760]   that's the whole point you have somebody with strong opinions and you can oppose them with
[01:09:32.760 --> 01:09:38.620]   opinions of the year-own and he will attack you in the social media so it's all fair.
[01:09:38.620 --> 01:09:45.720]   Well speaking of the world of cloak and dagger true crypt had a weird termination this week
[01:09:45.720 --> 01:09:51.400]   essentially what happened true crypt is the is one of the tools that Edward Snowden personally
[01:09:51.400 --> 01:09:56.760]   recommended that journalists use and other people use to escape the clutches of the NSA
[01:09:56.760 --> 01:10:00.920]   and in fact it's one of the ones that he got he wanted Glenn Greenwald to use before they
[01:10:00.920 --> 01:10:07.560]   they had contact but all of a sudden they you went to to the true crypt site and you got
[01:10:07.560 --> 01:10:13.160]   to redirect to a page that basically said oh true crypt is not really that secure you
[01:10:13.160 --> 01:10:19.720]   should use a Microsoft product and never mind we're going to go away goodbye you know this
[01:10:19.720 --> 01:10:23.720]   is a weird thing and everybody thought it was a hack but it turns out that it may not
[01:10:23.720 --> 01:10:28.880]   have been you know that this is just one of the most bizarre things I've ever said but
[01:10:28.880 --> 01:10:33.600]   I guess one of the I've ever I've ever read so but one of the things that I wonder about
[01:10:33.600 --> 01:10:40.400]   is does this make open source projects look bad I mean especially after heart bleed I
[01:10:40.400 --> 01:10:44.480]   say heart bleed I think did that heart bleed did that and now this is doing that and you
[01:10:44.480 --> 01:10:48.640]   know it turns out you know nobody was I don't think they got a lot of attention it was a
[01:10:48.640 --> 01:10:52.080]   tool people used it or they didn't use it they knew about it or they didn't know about
[01:10:52.080 --> 01:10:56.120]   it now we know all about it and you know the developers are we're anonymous we don't
[01:10:56.120 --> 01:11:00.160]   even know what country they're in we don't know if there's one of them or a hundred people
[01:11:00.160 --> 01:11:04.560]   we don't know if they work for the Chinese government we don't know anything about we
[01:11:04.560 --> 01:11:08.320]   don't know what their motivations for maintaining something so let's say this is just as simple
[01:11:08.320 --> 01:11:12.840]   as they found a flaw that was so big they didn't they do this in their spare time there's no
[01:11:12.840 --> 01:11:16.560]   way they could tackle it in a responsible way and they just walked away even if it's
[01:11:16.560 --> 01:11:22.280]   that simple well there's no safety net there yeah there's no there's no accountability
[01:11:22.280 --> 01:11:27.080]   at all like you said yeah it's the other hand I mean if a program does have flaws I want
[01:11:27.080 --> 01:11:31.760]   to know about them and I'm far more likely to know about them if it's open source yeah
[01:11:31.760 --> 01:11:35.800]   that's true I mean it's the good and bad of open source people can look inside of it well
[01:11:35.800 --> 01:11:41.440]   there's a group of people who are security researchers who want to continue true crypt
[01:11:41.440 --> 01:11:46.320]   and right now they're trying to see if they can get the rights to do that as I understand
[01:11:46.320 --> 01:11:51.480]   it and if they do then they can sort of do a fork of true crypt and bring it forward
[01:11:51.480 --> 01:11:56.240]   and have something like this continue but it really raises the the point that that there's
[01:11:56.240 --> 01:12:01.320]   not a lot of choice in this kind of encryption it's kind of dis-concription there there really
[01:12:01.320 --> 01:12:06.440]   should be a lot more offerings out there that people can choose from and you know we talked
[01:12:06.440 --> 01:12:12.000]   to Steve Gibson who's one of the who's the co-host of security now and of course it's
[01:12:12.000 --> 01:12:15.280]   been in the industry for a long long time and he said he started to write something like
[01:12:15.280 --> 01:12:20.200]   true crypt to do exactly that and that he stopped because true crypt was so good that
[01:12:20.200 --> 01:12:24.560]   he didn't think it was necessary and he now threatening to bring that off the shelf and
[01:12:24.560 --> 01:12:29.880]   keep developing so maybe that's another challenge with open source is that unless an open source
[01:12:29.880 --> 01:12:35.600]   project is adopted by a company that's aiming to really make a profit there's not much incentive
[01:12:35.600 --> 01:12:41.520]   for competition and so it's hard to get redundancy built into an ecosystem if that's if there's
[01:12:41.520 --> 01:12:47.520]   just sort of one open source product that takes care of everything yeah exactly I think
[01:12:47.520 --> 01:12:52.920]   the the chat room is going nuts right now with true crypt conspiracy theories that this
[01:12:52.920 --> 01:12:58.840]   is obviously a topic people are very interested in it's it's a I think a couple of things
[01:12:58.840 --> 01:13:02.960]   that have come up just in some reporting around this that people are very curious about the
[01:13:02.960 --> 01:13:07.560]   fact that an audit had been conducted or you know had was in the works for a few months
[01:13:07.560 --> 01:13:12.160]   before this whole thing shut down people are wondering if that has anything to do with
[01:13:12.160 --> 01:13:17.920]   it professor green who's doing that audit I think obviously had very good intentions
[01:13:17.920 --> 01:13:22.840]   for it but people wonder what's happening there and then also I did speak with a couple
[01:13:22.840 --> 01:13:26.680]   of folks in security industry including Dan Kvinsky and I think a lot of people know who
[01:13:26.680 --> 01:13:34.280]   Dan is he I think in 2008 discovered a really big vulnerability in the DNS protocol he has
[01:13:34.280 --> 01:13:39.240]   spoken a lot after harp late and then of course he has his own company that's that's
[01:13:39.240 --> 01:13:46.680]   doing sort of white hat security stuff he is he said he had a completely crazy the quote
[01:13:46.680 --> 01:13:50.800]   was a completely crazy and baseless theory which is all was great but that the software
[01:13:50.800 --> 01:13:56.320]   had to have been developed by somebody related to government and he really does believe that
[01:13:56.320 --> 01:14:01.080]   they that they put a stop to it the government figured out that people within a government
[01:14:01.080 --> 01:14:08.560]   organization were had worked on this because you know they wanted to be anonymous the entire
[01:14:08.560 --> 01:14:13.000]   time they never wanted to give the project over to anybody else which often often happens
[01:14:13.000 --> 01:14:17.080]   in open source things like look at bitcoin the people who started were anonymous but
[01:14:17.080 --> 01:14:21.320]   eventually you know it's taken over by people who aren't anonymous and and it's it's maintained
[01:14:21.320 --> 01:14:26.880]   and that never happened and then sort of the weird references to Microsoft in in the in
[01:14:26.880 --> 01:14:30.920]   the notice when it was taken down so I just thought I would throw that out for all of
[01:14:30.920 --> 01:14:35.440]   the folks watching right now who are really interested in trying to figure out why this
[01:14:35.440 --> 01:14:40.080]   happened why it was taken down and you mentioned two weird references to Microsoft one of those
[01:14:40.080 --> 01:14:45.840]   weird references was that they associated the the termination of this project to the
[01:14:45.840 --> 01:14:52.000]   fact that Microsoft was not going to continue to keep XP going and that's weird because
[01:14:52.000 --> 01:14:57.280]   it has nothing to do with XP at all and it's also weird because and it we had a lot of conspiracy
[01:14:57.280 --> 01:15:02.760]   theories in the chatroom when we talked about this on tech news today because China essentially
[01:15:02.760 --> 01:15:09.800]   banned the Chinese government banned windows 8 for government use using the same reason
[01:15:09.800 --> 01:15:15.160]   that XP was no longer being supported and therefore don't use windows 8 which is and
[01:15:15.160 --> 01:15:19.040]   I guess the idea was that oh you know in 15 years they won't support windows 8 and we'll
[01:15:19.040 --> 01:15:24.400]   all still be using windows 8 by then and you know totally bizarre reason to do anything
[01:15:24.400 --> 01:15:30.920]   and the other one was that the determination note explicitly recommended that everyone
[01:15:30.920 --> 01:15:38.200]   move to Microsoft what is it called I forgot what the name of it is but Microsoft's encryption
[01:15:38.200 --> 01:15:44.480]   having a bit locker that's it bit locker and you know we talked to Steve Gibson about that
[01:15:44.480 --> 01:15:50.720]   and and and Steve said no that's not really the best choice at all yeah and it's controversial
[01:15:50.720 --> 01:15:55.480]   it was like nobody in this world would ever use bit locker like it's not our radar yeah
[01:15:55.480 --> 01:16:00.880]   totally random and you do you expect better from the makers of of true crypt to make a
[01:16:00.880 --> 01:16:04.880]   better recommendation so there are much better things out there well you know one of the
[01:16:04.880 --> 01:16:11.920]   things about all these NSA spying revelations is that you think well this is just the NSA
[01:16:11.920 --> 01:16:16.320]   is going nuts there they'd have unlimited resources they're doing all these things another view
[01:16:16.320 --> 01:16:21.960]   is that they're just a leading indicator that the application of big data principles to the
[01:16:21.960 --> 01:16:27.000]   collection of internet based stuff is kind of a no-brainer if you're an intelligence agency
[01:16:27.000 --> 01:16:31.240]   and that the NSA is just doing what other everybody else every national government would
[01:16:31.240 --> 01:16:37.400]   want to do and it turns out that in Germany there's a German report saying that German
[01:16:37.400 --> 01:16:43.440]   the German version of the NSA wants to do something similar to what the NSA is doing
[01:16:43.440 --> 01:16:47.160]   to do mass surveillance and they've actually requested four hundred million dollars I suspect
[01:16:47.160 --> 01:16:51.240]   it's going to cost more than that four hundred million dollars but they want to do something
[01:16:51.240 --> 01:16:57.280]   similar and of course we've seen the allies of the United States Britain Canada New Zealand
[01:16:57.280 --> 01:17:01.280]   the English speaking Australia the English speaking countries essentially who are all
[01:17:01.280 --> 01:17:06.320]   working in concert on a lot of this espionage stuff but I think we're going we're moving
[01:17:06.320 --> 01:17:12.440]   into a world where pretty much what the NSA is doing is a is a version of what everybody
[01:17:12.440 --> 01:17:18.240]   wants to do and will do simply because their job is intelligence and if the data is there
[01:17:18.240 --> 01:17:22.080]   why not harvest it and store it well certainly I mean I think that if you're in the intelligence
[01:17:22.080 --> 01:17:26.480]   community and you're not doing I'm I'm not making excuses for this but if but if that's
[01:17:26.480 --> 01:17:32.240]   your job and your goal is to find find all the information you're gonna do whatever you
[01:17:32.240 --> 01:17:39.240]   can to to achieve that and maybe get a little too get a little too far away from the big
[01:17:39.240 --> 01:17:42.760]   questions about why we're doing it whether it's the right thing to do but you had better
[01:17:42.760 --> 01:17:49.520]   bet that other non you know that China's I'm sure of course they're doing this and I
[01:17:49.520 --> 01:17:52.480]   would be shocked if they weren't and in fact I think there were quite a few people out there
[01:17:52.480 --> 01:17:57.480]   when all the NSA revelation started to come out who were and I'm not sure this is a good
[01:17:57.480 --> 01:18:03.840]   thing but the reaction was sort of like are you surprised that that the government is
[01:18:03.840 --> 01:18:08.800]   looking at your data didn't we all think that that was happening anyway so I don't
[01:18:08.800 --> 01:18:12.240]   know I think that it's it's not too surprising to hear that other countries are trying to
[01:18:12.240 --> 01:18:17.400]   do the same thing absolutely and of course the other thing that's interesting about this
[01:18:17.400 --> 01:18:22.200]   from a kind of I guess a political science perspective is that it's kind of giving espionage
[01:18:22.200 --> 01:18:27.120]   a bad name what's wrong with espionage we want we want our government to have information
[01:18:27.120 --> 01:18:32.080]   let's take an extreme case like North Korea you have two choices you can have espionage
[01:18:32.080 --> 01:18:35.320]   and learn things about what they're doing with their missiles and their rockets and their
[01:18:35.320 --> 01:18:40.800]   nuke program and their their labor camps and all that stuff or you can voluntarily choose
[01:18:40.800 --> 01:18:44.280]   to have no idea what they're doing I mean those are really the options and so we have
[01:18:44.280 --> 01:18:48.600]   espionage to spy on other countries to find out what they're doing and of course this
[01:18:48.600 --> 01:18:53.200]   whole this whole wiretapping communications thing goes way back back in the cold war the
[01:18:53.200 --> 01:18:57.120]   United States used to send submarines down to the bottom of the ocean and clamp these
[01:18:57.120 --> 01:19:03.600]   sort of like special purpose devices onto their underwater cables and we've listened
[01:19:03.600 --> 01:19:08.480]   to you know phone calls within Russia this was probably in the 50s and 60s and 70s that
[01:19:08.480 --> 01:19:14.880]   the United States used to do this there's you know they used to wiretap telegrams you
[01:19:14.880 --> 01:19:19.040]   know the te telegraph system and it turns out that the United States had this special
[01:19:19.040 --> 01:19:24.840]   the NSA in fact had a relationship with all the major telegraph companies to hand over
[01:19:24.840 --> 01:19:28.440]   data it's just like today and so this kind of thing has been going on for a long time
[01:19:28.440 --> 01:19:34.160]   the problem with the NSA spying is that it's in my opinion clearly unconstitutional to
[01:19:34.160 --> 01:19:38.200]   to harvest the data of people before they've been suspected of a crime and everything
[01:19:38.200 --> 01:19:41.000]   to do it preemptively is a violation of the Fourth Amendment.
[01:19:41.000 --> 01:19:45.760]   Yeah well and history tells us that when that when our when we start to surveil our own people
[01:19:45.760 --> 01:19:51.400]   especially people who are presumed innocent that information gets misused over time it
[01:19:51.400 --> 01:20:01.280]   just does it's the nature of of power is to find a reason to use those for the unintended
[01:20:01.280 --> 01:20:02.280]   purposes.
[01:20:02.280 --> 01:20:07.560]   Yeah and today they can do it at scale I mean like spying on one telegraph probably not that
[01:20:07.560 --> 01:20:12.920]   huge a deal with the internet it's just about as easy to spy on everybody as it is to spy
[01:20:12.920 --> 01:20:18.960]   on one person and so by definition you know people who deserve their privacy are going
[01:20:18.960 --> 01:20:21.960]   to get caught up in it and that was not true in the old days.
[01:20:21.960 --> 01:20:27.400]   Yeah I think that this first of all when I read this story I was really actually shocked
[01:20:27.400 --> 01:20:33.520]   that Germany was so far behind because I think it's been well documented that China, Iran,
[01:20:33.520 --> 01:20:37.920]   Israel they're all doing what the NSA is doing and more I mean some would say that China's
[01:20:37.920 --> 01:20:42.760]   doing more so I thought okay well maybe Angela Merkel was just really upset that she can't
[01:20:42.760 --> 01:20:46.680]   listen on other people's cellphone conversation she's going to catch up.
[01:20:46.680 --> 01:20:50.440]   But I think that all of these conversations have been really important and Snowden has
[01:20:50.440 --> 01:20:53.920]   been very important I talked to a lot of people who work in the security industry all the
[01:20:53.920 --> 01:20:59.760]   time folks you know from places like Palo Alto Networks as well as security researchers
[01:20:59.760 --> 01:21:04.760]   and hackers and they really do believe that this is a conversation that had to happen
[01:21:04.760 --> 01:21:10.040]   around the NSA but that nobody really there was no motivation for it to happen nobody
[01:21:10.040 --> 01:21:16.120]   wanted to be the person to force the conversation and the debate is going to change I mean this
[01:21:16.120 --> 01:21:20.800]   debate that we have with all these like ongoing revelations and more news coming out of Glenn
[01:21:20.800 --> 01:21:28.280]   Greenwald/ outwards Snowden and news stories like countries like Germany saying we need
[01:21:28.280 --> 01:21:33.500]   to start doing these things too you're finally you'll see the security industry change and
[01:21:33.500 --> 01:21:38.480]   start to acknowledge and have to take into account our constitutional rights which just
[01:21:38.480 --> 01:21:44.160]   hadn't happened since 9/11 I mean there was kind of an after after the terrorist attacks
[01:21:44.160 --> 01:21:49.640]   like it changed the conversation and so we're going to see the pendulum swing back again.
[01:21:49.640 --> 01:21:55.240]   You know one of the things that you know again espionage in general and principle can be
[01:21:55.240 --> 01:22:00.760]   a very very good thing and I think clearly with the NSA the problem is a lack of oversight
[01:22:00.760 --> 01:22:05.360]   one of the shocking things we learned from the from the Snowden revelations is that any
[01:22:05.360 --> 01:22:11.000]   analyst within the NSA above a certain level can simply call up a an application and search
[01:22:11.000 --> 01:22:16.120]   everything like searching Google you know then and maybe you know maybe they suspect
[01:22:16.120 --> 01:22:19.760]   their girlfriend is doing something and they can just call it up and find out everything
[01:22:19.760 --> 01:22:23.520]   there's no about this person they absolutely can do that and there's no checks on that
[01:22:23.520 --> 01:22:27.480]   there's no there's no external oversight and there's not a whole lot of internal oversight
[01:22:27.480 --> 01:22:34.360]   within the NSA as well so it's a really it's a really fascinating thing that we're all going
[01:22:34.360 --> 01:22:39.240]   to have to deal with and of course you know it raises the question are non-Americans protected
[01:22:39.240 --> 01:22:43.920]   by the Constitution is it okay to spy on people as long as they're not American citizens
[01:22:43.920 --> 01:22:47.240]   and I think the world has been shocked by the conversation we're having the US this is
[01:22:47.240 --> 01:22:51.160]   gone constitutional it's okay to do it for Germans you can you can spy on Germans just
[01:22:51.160 --> 01:22:58.560]   don't spy on me so that's a kind of interesting development so you know it's it's really it's
[01:22:58.560 --> 01:23:02.080]   it's a fascinating thing that and I hope these revelations keep coming because we really
[01:23:02.080 --> 01:23:06.800]   want to know a lot more about what's happening and it's a it's a it's a great data story
[01:23:06.800 --> 01:23:12.920]   as well the scale at which this thing is happening is just absolutely astonishing so we'll keep
[01:23:12.920 --> 01:23:16.560]   an eye on that well we're going to talk about what Microsoft is doing in just a sec but we're
[01:23:16.560 --> 01:23:20.360]   going to take a break and I want to tell you about one of our sponsors today which is
[01:23:20.360 --> 01:23:26.400]   personal capital one of the biggest barriers to getting ahead with your finances finances
[01:23:26.400 --> 01:23:31.480]   is understanding what's going on with your finances how much are you really spending on
[01:23:31.480 --> 01:23:34.920]   everything how much are you really saving are you on track with your retirement are you
[01:23:34.920 --> 01:23:39.960]   on track with your kids college money where are you with all this stuff we have accounts
[01:23:39.960 --> 01:23:44.600]   all over the place they're all online nowadays and so the way personal capital works is that
[01:23:44.600 --> 01:23:50.040]   you plug in all your different disparate financial accounts of all kinds your bank accounts your
[01:23:50.040 --> 01:23:56.760]   401k your your new name it stocks whatever it is that you have that's money related you
[01:23:56.760 --> 01:24:01.840]   plug it in and personal capital brings it to you on a single screen with charts and graphs
[01:24:01.840 --> 01:24:05.320]   that enable you to really have an intuitive understanding of what's happening with your
[01:24:05.320 --> 01:24:09.920]   money it's very possible that what's actually happening with your money is a little scary
[01:24:09.920 --> 01:24:15.000]   and it's good to know that now so you can plan ahead and make more intelligent decisions
[01:24:15.000 --> 01:24:18.520]   about how you're doing it also shows you how much you're overpaying on the fees that you're
[01:24:18.520 --> 01:24:23.640]   paying and it will guide you through reducing those fees so it will not only let you get
[01:24:23.640 --> 01:24:30.220]   a handle on your finances but it'll also actually materially save you money so why wait signing
[01:24:30.220 --> 01:24:35.040]   up takes just a minute and it pays big dividends personal capital gives you total clarity and
[01:24:35.040 --> 01:24:39.560]   transparency to make your investment decisions right away we've been using this I started
[01:24:39.560 --> 01:24:45.120]   using this my wife loves it and it just really that just that picture of your total picture
[01:24:45.120 --> 01:24:49.720]   of your finances is priceless so to set up your free account go to personal capital
[01:24:49.720 --> 01:24:54.240]   com slash twit remember that personal capital is free and the smart way to grow your money
[01:24:54.240 --> 01:25:00.920]   you just go to personal capital com slash twit and save your financial picture highly
[01:25:00.920 --> 01:25:08.360]   recommended well Microsoft is doing some interesting things including possibly maybe kind of a
[01:25:08.360 --> 01:25:15.240]   smartwatch this was an exclusive by parmy ulsen over at Forbes.com and she says that Microsoft
[01:25:15.240 --> 01:25:19.800]   is working on a smartwatch not surprising that working a smartwatch Microsoft's the kind
[01:25:19.800 --> 01:25:23.080]   of company that might want to do that sort of thing what was surprising was that her sources
[01:25:23.080 --> 01:25:27.800]   say that they could have something on the market by the end of the summer I would be
[01:25:27.800 --> 01:25:33.720]   shocked if they did that but does the world really want a I guess a windows phone like
[01:25:33.720 --> 01:25:34.720]   smartwatch?
[01:25:34.720 --> 01:25:40.000]   Well the reality is that I'm not sure the world really wants any smartwatches yet I mean
[01:25:40.000 --> 01:25:45.440]   we saw that spoof video a little while ago I think that something will happen somebody
[01:25:45.440 --> 01:25:50.720]   will invent an aspect to smartwatches that will make them something you really feel like
[01:25:50.720 --> 01:25:56.640]   you need to own but so far I haven't seen that that special feature quite yet and in
[01:25:56.640 --> 01:26:00.280]   fact we've been doing it's Sharon Vachkin who works for CNET and has been doing some
[01:26:00.280 --> 01:26:04.440]   interesting tests on heart rate monitors and even the heart rate functionality on most
[01:26:04.440 --> 01:26:11.440]   of these devices doesn't really work yeah I mean it works but in under very certain circumstances
[01:26:11.440 --> 01:26:17.960]   which is that you have to be holding perfectly stock still and even then they're not as accurate
[01:26:17.960 --> 01:26:23.320]   as you know an EKG or a chest based heart band so we're it's so young is what I'm so
[01:26:23.320 --> 01:26:27.120]   if you actually die it's very accurate it will say you're dead because you're holding
[01:26:27.120 --> 01:26:32.360]   still right so yes you have to be hold yeah I mean it'll say zero which would be accurate
[01:26:32.360 --> 01:26:37.000]   okay yeah that's right I've been kind of stunned we keep hearing about this revolution
[01:26:37.000 --> 01:26:42.520]   in in biometrics and everything is either a heart monitor or a pedometer it's like enough
[01:26:42.520 --> 01:26:47.760]   already I'm right you know my watch my phone unless you're going to work with the FDA which
[01:26:47.760 --> 01:26:51.440]   none of these companies seem to want to do you can't make any real medical claims so
[01:26:51.440 --> 01:26:55.040]   you've got to be like oh well help you count your calories loose some you know it's like
[01:26:55.040 --> 01:26:58.720]   they're like the weight watchers of apps or something it's like we'll make promises we
[01:26:58.720 --> 01:27:04.320]   don't have to keep them so heart rate pedometer of calories you know right I mean until somebody
[01:27:04.320 --> 01:27:08.680]   actually works with the FDA to do something that really does something it's a medical
[01:27:08.680 --> 01:27:13.320]   device that will make recommendations about your health that could hurt you or help you
[01:27:13.320 --> 01:27:17.200]   you're just going to see all these like gimmicky things well and working with the FDA is an
[01:27:17.200 --> 01:27:23.720]   incredibly laborious complicated process for very good reason and I know this because
[01:27:23.720 --> 01:27:28.840]   I this is this is really personal but I have an insulin pump and a continuous blood glucose
[01:27:28.840 --> 01:27:36.440]   monitor that goes under my skin and feeds data about my blood sugar to this pump because
[01:27:36.440 --> 01:27:42.520]   I'm type one diabetic and that that technology is so not something you would want on your
[01:27:42.520 --> 01:27:47.760]   wrist I mean it is incredibly complicated and just the layers of like tape and special
[01:27:47.760 --> 01:27:52.120]   kinds of adhesives that it takes to do that kind of thing is just very complicated I think
[01:27:52.120 --> 01:27:58.960]   it's going to be a really long time until we get devices that are sort of both medically
[01:27:58.960 --> 01:28:04.160]   accurate and useful and things that you want to go you know over to target and buy yeah
[01:28:04.160 --> 01:28:08.760]   from your body yeah right it's just a really complicated set of problems so I think that
[01:28:08.760 --> 01:28:13.400]   whatever we get in a smartwatch is not there may be some health aspects right like the
[01:28:13.400 --> 01:28:17.840]   pedometer and the sort of general awareness of your activity but you but there has to
[01:28:17.840 --> 01:28:22.280]   be something that's really not health related that is the killer feature yes that we we
[01:28:22.280 --> 01:28:28.000]   haven't quite seen yet I went to this Samsung event last week for their SIM band which is
[01:28:28.000 --> 01:28:33.600]   like yet another Samsung wearable device but really quite different than the the Galaxy
[01:28:33.600 --> 01:28:40.560]   Gear stuff because SIM band is in theory this open platform for really futuristic wearable
[01:28:40.560 --> 01:28:45.320]   devices and in fact they want companies to invent new kinds of sensors and I think they
[01:28:45.320 --> 01:28:51.000]   talked about blood glucose monitoring is a specific example they want people to invent
[01:28:51.000 --> 01:28:56.760]   a technology that works for that and so it's really intriguing I never thought of a Samsung
[01:28:56.760 --> 01:29:01.760]   as the kind of company that would would lead a open hardware platform but at least they're
[01:29:01.760 --> 01:29:08.360]   giving you to try and they conveniently announced it right before WWDC which I'm sure was intentional
[01:29:08.360 --> 01:29:12.600]   and sure it was well and Samsung has a medical devices business right I mean Samsung is
[01:29:12.600 --> 01:29:18.600]   such a huge conglomerate in Korea they have they they're they've got their fingers in
[01:29:18.600 --> 01:29:24.680]   everything right like I think they make you know I think they make ships yeah right so
[01:29:24.680 --> 01:29:29.360]   they do have an entire business against creating medical technology that I think that they're
[01:29:29.360 --> 01:29:35.160]   going to try to marry some of that with their consumer division yeah and the the press photos
[01:29:35.160 --> 01:29:42.360]   of the prototype band I guess that that they that they showed had I don't know what 30
[01:29:42.360 --> 01:29:45.960]   sensors on it I mean it was ridiculous it had so many things in it I mean what are they
[01:29:45.960 --> 01:29:49.560]   sensing there I mean I mean the first one that they're shipping to developers later this
[01:29:49.560 --> 01:29:55.480]   year does not look all that exciting inherently it's not radically different but the idea is
[01:29:55.480 --> 01:30:01.280]   that it's a starting point for new technologies one cool thing about it is they they want to
[01:30:01.280 --> 01:30:05.440]   create a wearable device which you actually can wear 24/7 which generally is picking you
[01:30:05.440 --> 01:30:10.200]   can't because of battery issues and they have like this little shuttle battery where you
[01:30:10.200 --> 01:30:14.400]   charge your battery and then you snap it on to your SIM band and so you don't have to
[01:30:14.400 --> 01:30:18.960]   take your SIM band off that sounds that sounds like a cool innovation they also announced
[01:30:18.960 --> 01:30:27.040]   a cloud service called Sami and I understand that that's going to support non-Samsung devices
[01:30:27.040 --> 01:30:31.320]   may be able to use that is that yeah I mean that that's also in theory an open platform
[01:30:31.320 --> 01:30:37.720]   and according to Samsung at least the great thing about Sami is the consumer controls all
[01:30:37.720 --> 01:30:42.840]   the data and there aren't any privacy issues because if it's part of Sami it's not going
[01:30:42.840 --> 01:30:48.080]   to be anything that anybody can try to monetize I've been stunned by the amount of attention
[01:30:48.080 --> 01:30:53.480]   that an association of medical related and health related things have been circulating
[01:30:53.480 --> 01:30:57.960]   around the smartwatch category Apple of course has been hiring all these medical experts
[01:30:57.960 --> 01:31:02.000]   that have been seen on the campus and have been hired and I just don't understand the
[01:31:02.000 --> 01:31:05.760]   attraction to that it's just like you know like you say Lindsay it doesn't seem like
[01:31:05.760 --> 01:31:10.640]   that's the killer app I think I think the real killer app for smartwatches is going to
[01:31:10.640 --> 01:31:17.920]   be frankly branding and design oh I totally agree I think that they have to look beautiful
[01:31:17.920 --> 01:31:23.840]   and find a way and I actually think that the killer feature with a watch is sort of the
[01:31:23.840 --> 01:31:28.840]   Google cards yeah experience which we're going to see later in June at Google I/O and
[01:31:28.840 --> 01:31:32.560]   when I think we're going to see that on some devices and I think that Google's really
[01:31:32.560 --> 01:31:36.800]   mean this is where Google really shines is there their predictive abilities right like
[01:31:36.800 --> 01:31:41.280]   we know that you have an airline ticket sitting in your inbox and your watch is just going
[01:31:41.280 --> 01:31:46.200]   to flash up and say you need to leave the house in five minutes to catch your flight
[01:31:46.200 --> 01:31:49.640]   I think that those sort of passive that passive interaction is where it's really going to
[01:31:49.640 --> 01:31:56.360]   shine because or some really sophisticated voice recognition but even that you know it
[01:31:56.360 --> 01:32:00.440]   would have to be at an arm's length to be really effective so that you could just it could
[01:32:00.440 --> 01:32:04.720]   just pick up on what you're saying which is also creepy yeah and in fact a Google executive
[01:32:04.720 --> 01:32:10.120]   posted some screenshots screenshots of Android Wear and showing a number of things including
[01:32:10.120 --> 01:32:15.280]   a podcasting app and you know some some a game even that was interesting and there was an
[01:32:15.280 --> 01:32:20.160]   authorized leak of a video showing an LG device playing Android Wear type stuff and then that
[01:32:20.160 --> 01:32:24.960]   was yanked down and ceremoniously by LG that appeared on YouTube and then was taken down
[01:32:24.960 --> 01:32:30.080]   and if there any illicit copies out there but it looks pretty much like what you'd expect
[01:32:30.080 --> 01:32:34.520]   and you know I think I really do think that that's really I agree with you completely
[01:32:34.520 --> 01:32:41.560]   it's a combination of really good notifications and great design and just one oh sorry one
[01:32:41.560 --> 01:32:46.040]   more point on why some of these hardware companies are all going after this the health space which
[01:32:46.040 --> 01:32:49.520]   does seem totally counterintuitive it doesn't make a lot of sense there's there's one data
[01:32:49.520 --> 01:32:56.360]   point that you might want we all might want to bear in mind is that 1.9 billion dollars
[01:32:56.360 --> 01:33:03.720]   in BC money went into digital health mostly apps software and that's double from 2011
[01:33:03.720 --> 01:33:07.120]   it's set to grow so I've spoken a lot of the venture capital guys about what they're investing
[01:33:07.120 --> 01:33:11.200]   in the especially the ones who've raised plus billion dollar funds in the last two years
[01:33:11.200 --> 01:33:15.440]   in the last two years we do a story you know where you're going to put all this money digital
[01:33:15.440 --> 01:33:20.440]   health came up again and again and again so I think some of these companies Samsung Apple
[01:33:20.440 --> 01:33:24.360]   they don't know where it's going to go they just know there's going to be a lot happening
[01:33:24.360 --> 01:33:29.120]   there in terms of apps and other devices around digital health as people try to figure this
[01:33:29.120 --> 01:33:35.360]   out so to be able to be the platform for this space that's just receiving tons of money
[01:33:35.360 --> 01:33:41.320]   double from 2011 they're almost two billion dollars now 2014 and 15 you're going to expect
[01:33:41.320 --> 01:33:48.720]   similar growth rates it's it's it's it's not a terrible place to be when you look at it
[01:33:48.720 --> 01:33:52.200]   from that perspective as a part of the health care industry I think you're absolutely right
[01:33:52.200 --> 01:33:56.760]   I mean if that if if there were if we got to a point and I think it would take quite a
[01:33:56.760 --> 01:34:00.640]   while but where these devices actually you can get a prescription for wanting to get them
[01:34:00.640 --> 01:34:05.240]   underwritten by your insurance and then they're part of the the health care establishment yeah
[01:34:05.240 --> 01:34:08.920]   that's a great place to be there's a ton of money there yeah absolutely yeah and there
[01:34:08.920 --> 01:34:13.080]   are a few companies out there doing stuff like that not very many I think Proteus is
[01:34:13.080 --> 01:34:18.320]   probably the one that's furthest ahead medical industrial complex man that is a great source
[01:34:18.320 --> 01:34:22.600]   of revenue and it's insurable maybe maybe we can get our watches covered and paid for
[01:34:22.600 --> 01:34:28.960]   by our health plans Obamacare we can do it the website works well Microsoft it was not
[01:34:28.960 --> 01:34:35.040]   only potentially working on a smartwatch they also showed off this week a sort of I guess
[01:34:35.040 --> 01:34:41.040]   a universal translator Star Trek style universal translator for our own planet that does instant
[01:34:41.040 --> 01:34:45.160]   translation via Skype so you can have a Skype call with somebody and you can speak English
[01:34:45.160 --> 01:34:50.040]   according to their demo and the person on the other end can hear what you say said in
[01:34:50.040 --> 01:34:53.480]   German and also read it on the screen and then they speak German to you and then you
[01:34:53.480 --> 01:34:57.760]   hear in English what they said it's a kind of a no-brainer it seems like the kind of thing
[01:34:57.760 --> 01:35:02.640]   Google would do as well but this is a this is fantastic technology making the world a
[01:35:02.640 --> 01:35:07.880]   better place unless there's some something about it I don't I watch the demo and I this
[01:35:07.880 --> 01:35:13.480]   is of all of this you know conversation about wearables and I be getting it this is the
[01:35:13.480 --> 01:35:19.200]   thing that got me the most excited this week I found it just amazing and even I'm sure there's
[01:35:19.200 --> 01:35:22.520]   a long way to go I mean this is one demo with just German and English I thought it was funny
[01:35:22.520 --> 01:35:28.640]   that they picked those languages I mean English but German okay they've previously demonstrated
[01:35:28.640 --> 01:35:33.560]   I think Mandarin or or standard Chinese translation I think a year or two ago there was a famous
[01:35:33.560 --> 01:35:38.600]   demo of that right right yeah but I found it incredibly compelling because this is a
[01:35:38.600 --> 01:35:42.880]   real challenge I mean I've heard people in the software development industry who worked
[01:35:42.880 --> 01:35:47.960]   really closely with companies in India recently have been pulling back partially just because
[01:35:47.960 --> 01:35:53.520]   of and that's just English those are other English speakers but partially because of communication
[01:35:53.520 --> 01:35:59.760]   issues mostly having to do with time zones but if you can imagine the ability to work
[01:35:59.760 --> 01:36:05.080]   just seamlessly across languages I don't know I think that's it's a huge economic opportunity
[01:36:05.080 --> 01:36:11.720]   and it's also just fascinating cool to see truly is and my wife and I were recently living
[01:36:11.720 --> 01:36:17.880]   in in Italy we spent some weeks living in Florence Italy and I was carrying around the
[01:36:17.880 --> 01:36:23.560]   what's called word lens I believe it's called it's an app that translates into image right
[01:36:23.560 --> 01:36:27.560]   exactly and I had Google so this is the first world this problem you can imagine I had Google
[01:36:27.560 --> 01:36:30.640]   Glass and I was saying man why don't they have this for Google Glass this would be so
[01:36:30.640 --> 01:36:35.960]   great poor me and then and so you hold this thing up to assign or a menu or something that's
[01:36:35.960 --> 01:36:40.240]   written in some foreign language in this case Italian and it would show you in English in
[01:36:40.240 --> 01:36:44.720]   the same typeface with the same colors and everything was it felt really magical like
[01:36:44.720 --> 01:36:50.960]   truly amazing and this is the world we're going to where that sort of thing will be in your
[01:36:50.960 --> 01:36:55.240]   smart glasses and tourists you'll be able to walk around and no matter what country you're
[01:36:55.240 --> 01:37:00.040]   in everything's in English for you that that's that's going to be standard like we're on the
[01:37:00.040 --> 01:37:04.560]   brink of that world and then when you talk you know you're going to hear in your ear the
[01:37:04.560 --> 01:37:07.400]   language when people talk to you you're going to hear English and then you can talk and
[01:37:07.400 --> 01:37:10.800]   they're going to hear their language it's really going to make the world a smaller place
[01:37:10.800 --> 01:37:14.640]   and I've already taken advantage of the translation feature built in a Google+ talk about it
[01:37:14.640 --> 01:37:18.240]   talking to a lot of people in a lot of countries and you just click a button and boom you see
[01:37:18.240 --> 01:37:23.760]   English it's just I agree with you this is a this is a this is a great new world we're
[01:37:23.760 --> 01:37:29.200]   going to be living in and people talk about it a real life babble fish it's like the answer
[01:37:29.200 --> 01:37:34.760]   really is 42 exactly that's exactly right and so it's it's you know people talk about
[01:37:34.760 --> 01:37:39.720]   wearables as being invasive and annoying and it's true but you know things like smart
[01:37:39.720 --> 01:37:43.720]   glasses can really you know enable you to break down language barriers on the other hand
[01:37:43.720 --> 01:37:48.640]   I guess to play the devil's advocate against my own excitement I love other languages I
[01:37:48.640 --> 01:37:53.320]   don't speak any of them very well but I love learning them to the extent that I can I think
[01:37:53.320 --> 01:37:56.600]   and I there's there's a same I feel the same sadness when I think about a future in which
[01:37:56.600 --> 01:37:59.880]   I don't need to learn another language that I feel when I think about a future in which
[01:37:59.880 --> 01:38:05.320]   I don't need to drive there's that there's a little there's a joy in driving there's a
[01:38:05.320 --> 01:38:10.280]   joy in learning another language that I I just sort of want a human level worry about losing
[01:38:10.280 --> 01:38:14.600]   because so much I feel like language is the fabric of your society and it's closely linked
[01:38:14.600 --> 01:38:18.760]   to your culture but you know if you really want to get depressed you really want to go
[01:38:18.760 --> 01:38:25.280]   down his rat hole the do what it's a foreign language is knowledge what do we need knowledge
[01:38:25.280 --> 01:38:31.680]   for I mean why why learn knowledge why learn facts if any fact can be conjured up instantly
[01:38:31.680 --> 01:38:38.680]   24/7 well somebody's got to put it on the internet yeah also I mean they it's gonna
[01:38:38.680 --> 01:38:43.960]   be a long long time before a computer can speak translate between languages as well as
[01:38:43.960 --> 01:38:49.080]   a human who gets fluent at it I mean it's like a lot of other technologies the first
[01:38:49.080 --> 01:38:54.480]   80% is relatively easy and the last 20% that really does make it magical is the hard part
[01:38:54.480 --> 01:38:59.680]   and yeah you do get there sometimes I feel like voice recognition kind of got there after
[01:38:59.680 --> 01:39:03.840]   many years or voice recognition was amazing but not quite amazing enough to actually be
[01:39:03.840 --> 01:39:11.160]   practical it actually is but translation is nowhere near that but it raises I think a
[01:39:11.160 --> 01:39:15.260]   serious issue for education what do you teach kids do you teach them a foreign language
[01:39:15.260 --> 01:39:19.880]   now as you said you teach them to do cursive writing do you teach kids to be able to function
[01:39:19.880 --> 01:39:24.160]   without a smartphone that's connected to the internet so the curse of writing question
[01:39:24.160 --> 01:39:28.400]   is really interesting and I think lately I have a fifth grader seem to be sixth grader
[01:39:28.400 --> 01:39:34.200]   who did learn cursive and his school district does teach it and part of the motivation for
[01:39:34.200 --> 01:39:40.200]   cursive a lot of schools have not been teaching it anymore is that for kids who have dyslexia
[01:39:40.200 --> 01:39:45.040]   or any sort of trouble writing or interpreting cursive helps there's actually it actually
[01:39:45.040 --> 01:39:49.960]   forces the two sides of the brain to talk to each other and they can spell better in cursive
[01:39:49.960 --> 01:39:54.760]   I've seen this with my own child it's very interesting so there are some skills I think
[01:39:54.760 --> 01:39:59.000]   that we don't know what they have until we stop doing them and then we realize oh we
[01:39:59.000 --> 01:40:03.240]   lost something there and maybe we should bring it back a little bit yeah you know I think
[01:40:03.240 --> 01:40:07.240]   we've already lost so much I mean it used to be you know 200 years ago kids would need
[01:40:07.240 --> 01:40:12.440]   to know how to milk a cow and they would need to do all these things which kids nowadays
[01:40:12.440 --> 01:40:17.320]   have trouble even recognizing what a cow is and so you know this is not in Petaluma not
[01:40:17.320 --> 01:40:21.840]   in Petaluma but but you know this is what this is this is the trajectory we're on and
[01:40:21.840 --> 01:40:26.040]   it's accelerating because of digital technology and you know in the education market we have
[01:40:26.040 --> 01:40:31.120]   to decide what we're going to teach kids I also have a I find this fascinating but I
[01:40:31.120 --> 01:40:35.520]   think that because of voice recognition because it's become so sophisticated there is a possible
[01:40:35.520 --> 01:40:43.600]   future in which we don't need to write at all right we speak and maybe you go in there
[01:40:43.600 --> 01:40:47.800]   and edit but but you're you're wearing you're wearing a smart glass you're wearing some sort
[01:40:47.800 --> 01:40:52.840]   of receiver you simply speak speak what it is that you want to communicate it comes out
[01:40:52.840 --> 01:40:57.040]   written you can read you everybody will need to read but I think that there is a possibility
[01:40:57.040 --> 01:41:02.920]   that we'll get to a point where cursive or print it doesn't matter it's funny to dictate
[01:41:02.920 --> 01:41:08.160]   the entire books yeah yep yeah I was talking to somebody who dictates all of his emails
[01:41:08.160 --> 01:41:12.640]   and all of his court like all of his correspondence and then a lot of his memos to his staff and
[01:41:12.640 --> 01:41:17.360]   and reports and he said that because of where the technology is he actually has to speak
[01:41:17.360 --> 01:41:20.760]   like a robot for it to work so he couldn't have the sort of conversation we're having
[01:41:20.760 --> 01:41:24.840]   with natural inflection he actually has to sound like a robot and that he does it for
[01:41:24.840 --> 01:41:29.600]   four hours a day and when he comes out it's confusing for his staff because they don't
[01:41:29.600 --> 01:41:32.520]   know what's happened to him you know and there were definitely people who would work with
[01:41:32.520 --> 01:41:36.040]   him and didn't know him well who'd only see him after in these moments and think that
[01:41:36.040 --> 01:41:40.600]   he had like some very severe form of autism he was like it's weird how the technology
[01:41:40.600 --> 01:41:47.320]   is changing our personalities and we interact and it's bizarre it is bizarre and and
[01:41:47.320 --> 01:41:51.000]   you know I've tried to use I don't know if you've tried this before Harry did sort of
[01:41:51.000 --> 01:41:55.680]   like dictate columns and things like that I it's great at first and then you just get
[01:41:55.680 --> 01:42:02.560]   tired of it and it alters your thinking process just different I've read book actually even
[01:42:02.560 --> 01:42:05.920]   before voice recognition there were people who dictate books on the tapes and have them
[01:42:05.920 --> 01:42:09.720]   transcribed and I've read a fair number of books that weren't all that great they were
[01:42:09.720 --> 01:42:16.200]   dictated because when you write you polish and edit and and think carefully and I think
[01:42:16.200 --> 01:42:20.800]   for most people that's harder to do when when talking out loud yeah absolutely well speaking
[01:42:20.800 --> 01:42:26.080]   of books we're going to talk in just a second about Amazon's war against one major publisher
[01:42:26.080 --> 01:42:30.600]   but first I think Chad don't don't we have a look at what happened here in the Twit Brook
[01:42:30.600 --> 01:42:37.960]   House this week here's what happened I hear a twit previously on Twitter a crap apple
[01:42:37.960 --> 01:42:45.080]   just bought beats tech news tonight apple confirmed it is indeed buying beats electronics for
[01:42:45.080 --> 01:42:50.600]   three billion dollars tech news today visitors to the true curbsite were redirected to a page
[01:42:50.600 --> 01:42:55.400]   in the source community site source forge by using user to stop using the product switched
[01:42:55.400 --> 01:43:03.960]   to Microsoft BitLocker it was a hack it was an absolute breach of all of the previous security
[01:43:03.960 --> 01:43:10.200]   which really is a stretch security now basically what title two does it would try to regulate
[01:43:10.200 --> 01:43:17.200]   the internet as if it was a 19th century telephone company the rules don't fit at all to it great
[01:43:17.200 --> 01:43:22.720]   tech news and analysis every day it just doesn't make sense from my point but obviously it makes
[01:43:22.720 --> 01:43:29.360]   sense to Apple so I have what you said about it go ahead it was a rumor created by dr.
[01:43:29.360 --> 01:43:34.960]   Dre and Jimmy Iovine an attempt to sell headphones and stock or whatever this was 17 days ago
[01:43:34.960 --> 01:43:41.200]   I'm interested in a company that is actually failing failing all right all right actually
[01:43:41.200 --> 01:43:44.880]   has to make a recording because I thought you know if it really does happen then you
[01:43:44.880 --> 01:43:51.960]   can mock me endlessly that's outrageous I did not say that this has been digitally
[01:43:51.960 --> 01:44:03.960]   inserted sorry Leo I'm gonna lose my job well Amazon we're talking about the future of
[01:44:03.960 --> 01:44:08.800]   books Amazon had a weird glitch with some hash yet books recently where if you went to try
[01:44:08.800 --> 01:44:14.080]   to pre-order some hash yet books you couldn't and and they it appeared that it turns out
[01:44:14.080 --> 01:44:19.200]   that that Amazon had been negotiating with hash yet over something presumably the price
[01:44:19.200 --> 01:44:25.280]   of the box that hash yet was publishing and a lot of people cried foul saying you know
[01:44:25.280 --> 01:44:31.200]   okay you're using your quasi monopoly to sort of like crush these publishers into you know
[01:44:31.200 --> 01:44:35.560]   amending them to your will and this is outrageous and then they came out with a rare statement
[01:44:35.560 --> 01:44:40.240]   saying no look we're here to negotiate on behalf of the customers who want the lowest
[01:44:40.240 --> 01:44:43.760]   possible prices and we don't know if we're going to be offering this books in the future
[01:44:43.760 --> 01:44:49.040]   because the negotiations aren't going so well and so why should we take pre-orders if you
[01:44:49.040 --> 01:44:52.240]   know if we might not be selling these books we may be terminating our relationship with
[01:44:52.240 --> 01:44:57.880]   hash yet and they may have to go to the other Amazon wherever that is so where do you fall
[01:44:57.880 --> 01:45:05.240]   on this what do you guys fall on this is this a case of a monopoly sort of dominating an
[01:45:05.240 --> 01:45:10.360]   industry and making everybody do it things their way or is this just a reasonable negotiation
[01:45:10.360 --> 01:45:15.840]   and the effect of that negotiation reflected in the catalog itself well I don't know if
[01:45:15.840 --> 01:45:19.880]   I can say whether or not it's reasonable because you'd have to be there to know what the term
[01:45:19.880 --> 01:45:23.680]   what the actual arguing is about what we do know is that this has been going on for some
[01:45:23.680 --> 01:45:29.640]   months and I think it was the New York Times that pointed out that that most of these negotiations
[01:45:29.640 --> 01:45:35.880]   happen within a month right this has been taking a while you know I think that this at
[01:45:35.880 --> 01:45:42.560]   the very least shows how important Amazon has become right it would make logical sense
[01:45:42.560 --> 01:45:46.080]   that they take down the pre-order button if they think that their negotiations may fall
[01:45:46.080 --> 01:45:50.240]   through but I think the entire world cries foul because they're like the negotiations aren't
[01:45:50.240 --> 01:45:55.520]   going to fall through what would Hashem do if they didn't have Amazon and that question
[01:45:55.520 --> 01:46:03.200]   right there is why people get so upset right how do you function as hash yet without Amazon
[01:46:03.200 --> 01:46:07.960]   I mean the part I find fascinating is not the negotiations between Amazon and Hashem
[01:46:07.960 --> 01:46:13.480]   because they're both big companies this stuff happens all the time it's the fact that Amazon
[01:46:13.480 --> 01:46:18.880]   has always called itself Earth's most customer centric company and for the most part it is
[01:46:18.880 --> 01:46:23.280]   I mean the level of customer service they offer is kind of astonishing but they've acknowledged
[01:46:23.280 --> 01:46:28.840]   that not only are they not taking pre-orders but they're also keeping fewer copies on hand
[01:46:28.840 --> 01:46:34.640]   their intentionally delaying shipments in some cases essentially customers are getting
[01:46:34.640 --> 01:46:41.640]   caught in the crossfire and of course there you know every company makes they weigh decisions
[01:46:41.640 --> 01:46:45.080]   and they do things that end up not being as as perfect for the customers as they might
[01:46:45.080 --> 01:46:50.400]   be but Amazon is such a history of doing things that sometimes seem crazy that make
[01:46:50.400 --> 01:46:55.600]   life better for its customers that to sort of have the curtain peeled back and to see
[01:46:55.600 --> 01:47:03.320]   them you know basically willingly not letting people get the books they want because of this
[01:47:03.320 --> 01:47:07.360]   I think it's kind of shocking in a way it would not have been if it was Walden books
[01:47:07.360 --> 01:47:13.920]   or whoever they remind me a bit Katie Benner of Walmart which is that yes you know people
[01:47:13.920 --> 01:47:20.640]   want lower prices they want things a certain way and so we Walmart are going to use our
[01:47:20.640 --> 01:47:25.600]   gigantic power in the industry to force everything to happen our way we're going to change the
[01:47:25.600 --> 01:47:28.920]   way people package their products we're going to change the way they ship them and we're
[01:47:28.920 --> 01:47:33.640]   going to definitely lower the price and and having everybody buy everything from Walmart
[01:47:33.640 --> 01:47:39.000]   is good for customers is Amazon that in a nutshell I'm sure you've heard about the diapers
[01:47:39.000 --> 01:47:44.280]   dot com scenario where Amazon has this algorithm that automatically changes prices based on
[01:47:44.280 --> 01:47:50.560]   what the competitors prices are and they undercut diapers dot com consistently over
[01:47:50.560 --> 01:47:55.480]   over a sustained period of time to the point where the valuation diapers dot com crashed
[01:47:55.480 --> 01:47:59.360]   and then they bought it at the lower price and now they own diapers dot com is that good
[01:47:59.360 --> 01:48:05.400]   for customers what do you think Katie is Amazon a force for good or evil well I don't know
[01:48:05.400 --> 01:48:08.920]   if they're forced for good or evil but I think that Amazon being good for customers is kind
[01:48:08.920 --> 01:48:13.600]   of a nice whitewash or veil for Amazon to be good for Amazon and I think the diapers
[01:48:13.600 --> 01:48:18.840]   dot com examples great and I think that your Walmart analogy is very interesting because
[01:48:18.840 --> 01:48:23.840]   Walmart is a very very low margin business you know they have to do volume because they
[01:48:23.840 --> 01:48:28.760]   do not have margins Amazon's similar as we know Amazon when you look at their you know
[01:48:28.760 --> 01:48:32.760]   every quarter and they put out their annual report this is not a money making company so
[01:48:32.760 --> 01:48:36.400]   it was very fascinating I think it was also the New York Times that had an editorial or
[01:48:36.400 --> 01:48:41.240]   a news analysis around this issue saying that they thought that it was interesting that
[01:48:41.240 --> 01:48:45.840]   this battle happened at a time when Wall Street investors were finally starting to get a little
[01:48:45.840 --> 01:48:50.320]   bit restless with Amazon about not being a produced profits despite all these sprawling
[01:48:50.320 --> 01:48:56.720]   businesses and everything that it does and in that statement from Amazon on essentially
[01:48:56.720 --> 01:49:01.520]   what the company said was we're playing the long game here we need to deal with publishers
[01:49:01.520 --> 01:49:06.880]   like a chef in a way that's going to be good for customers but at the end of the day good
[01:49:06.880 --> 01:49:11.640]   for Amazon and in the New York Times positive that maybe Amazon realized they needed to
[01:49:11.640 --> 01:49:16.760]   start building margins somewhere because you can't just run you know 50 different low
[01:49:16.760 --> 01:49:22.600]   margin businesses unless you can do Walmart type volume in all of them which they don't
[01:49:22.600 --> 01:49:23.600]   quite yet.
[01:49:23.600 --> 01:49:31.400]   Yeah the low margin approach to business is yet another questionable thing that sounds
[01:49:31.400 --> 01:49:36.520]   if you look at it from a certain perspective as an anti-competitive thing for example Amazon
[01:49:36.520 --> 01:49:41.680]   famously sells books at below the cost that they paid for them and you know they essentially
[01:49:41.680 --> 01:49:45.880]   say well you know we think this book is going to be a $9.99 book if they negotiate a price
[01:49:45.880 --> 01:49:50.400]   that's higher than that from the publisher they still sell it at $9.99 this is what got
[01:49:50.400 --> 01:49:55.200]   Apple into trouble when they colluded with other publishers to keep margins high so
[01:49:55.200 --> 01:49:59.280]   that publishers could actually make money and so on turns out that that's illegal but
[01:49:59.280 --> 01:50:03.720]   what they call dumping if you do it internationally it's dumping if you sell something below cost
[01:50:03.720 --> 01:50:08.280]   in another country that's against the international rules of trade but if you do it domestically
[01:50:08.280 --> 01:50:13.480]   it's okay and Amazon does that they also did that with their some of their tablets where
[01:50:13.480 --> 01:50:18.840]   they were reportedly selling tablets at lower cost than it took them to make with the intention
[01:50:18.840 --> 01:50:22.040]   of making it up later for selling things because essentially an Amazon tablet is basically
[01:50:22.040 --> 01:50:29.120]   a cash register for Amazon.com so it's you know it's it's it's it's really hard to get
[01:50:29.120 --> 01:50:35.240]   your brain around whether Amazon should have a more profitable business where they should
[01:50:35.240 --> 01:50:40.720]   be kinder and gentler it's it's almost impossible imagine them that way and I think one of the
[01:50:40.720 --> 01:50:45.440]   reasons they've come into a lot of criticism lately is Alibaba's in the news Alibaba's
[01:50:45.440 --> 01:50:50.880]   sort of kind of the Chinese Amazon not really they have different models very different
[01:50:50.880 --> 01:50:56.680]   models but they're essentially they dominate the Chinese buying things online scene in
[01:50:56.680 --> 01:51:02.360]   a similar way that Amazon does within the United States and Alibaba is massively profitable
[01:51:02.360 --> 01:51:06.480]   they make lots of money they hate you know they have bottom you know rock bottom prices
[01:51:06.480 --> 01:51:11.720]   on some of their you know categories some of their stores they have different types of
[01:51:11.720 --> 01:51:15.960]   stores but they you know they have like 40% of their revenue is profit or some making these
[01:51:15.960 --> 01:51:21.680]   numbers up it's very very high so I don't know I doubt that with Jeff Bezos in charge
[01:51:21.680 --> 01:51:26.760]   they're ever going to soften and become a I don't think so and he has said over and over
[01:51:26.760 --> 01:51:30.040]   and over again that he that they're there for the long haul right that every all the
[01:51:30.040 --> 01:51:34.040]   decisions he makes are so that they can build the business that they want to build for you
[01:51:34.040 --> 01:51:39.400]   know 15 or 20 years from now which is very interesting it's it's you would almost expect
[01:51:39.400 --> 01:51:44.840]   them to be softer with that approach but they seem to be just extremely rigid and dogmatic
[01:51:44.840 --> 01:51:50.760]   and it's just I don't think we'll know for 10 years if they're being good or evil yeah
[01:51:50.760 --> 01:51:55.160]   just talking about books specifically I would be happier if there was somebody who seemed
[01:51:55.160 --> 01:52:00.840]   like a true archival to Amazon in that category because Barnes and Noble you know is not an
[01:52:00.840 --> 01:52:07.480]   archival they're really in somewhat difficult shape and despite app looking to trouble the
[01:52:07.480 --> 01:52:13.040]   iBook store is not an archival to Amazon for eBooks and the day will come when Amazon does
[01:52:13.040 --> 01:52:16.880]   have an archival because it always happens but right now it's a little hard to see how
[01:52:16.880 --> 01:52:21.360]   that happens because they are so powerful or there will be an antitrust investigation
[01:52:21.360 --> 01:52:26.920]   I mean that could it really could happen when you think about it Amazon has if they get
[01:52:26.920 --> 01:52:32.360]   up to 70% market share and they basically have the entire self publishing market which
[01:52:32.360 --> 01:52:37.760]   is of their own design really not that's not necessarily a negative thing it's a positive
[01:52:37.760 --> 01:52:42.800]   thing in some ways but that's a huge yeah from an antitrust perspective though they're
[01:52:42.800 --> 01:52:46.880]   squeezing the publishers at one end and then they're competing directly with them with
[01:52:46.880 --> 01:52:51.760]   an entirely different model on the other end exactly it's not it's not it's not easy
[01:52:51.760 --> 01:52:55.840]   to be a publisher and there was some there was a small publisher to has come out in favor
[01:52:55.840 --> 01:53:00.400]   of Amazon invest and there are stories about small publishers reaching way more people
[01:53:00.400 --> 01:53:05.800]   and doing very well because of Amazon so I certainly don't think they're an ogre who
[01:53:05.800 --> 01:53:10.520]   is only bad for the publishing business in some ways they have been wonderful for publishing
[01:53:10.520 --> 01:53:16.880]   well I think we can all agree on this which is that Jeff Bezos is a genius and that Amazon
[01:53:16.880 --> 01:53:22.040]   is an incredibly disciplined company and and that's the source of their success in a very
[01:53:22.040 --> 01:53:26.600]   brutal market as far as I'm concerned if they deliver diapers via drone all is forgiven
[01:53:26.600 --> 01:53:32.120]   that's all I want that too much to ask well in a sec we're going to talk about another
[01:53:32.120 --> 01:53:37.840]   company with a bad reputation Comcast but first I want to tell you about Carbonite a company
[01:53:37.840 --> 01:53:43.400]   that saved my personal bacon many many times Carbonite is an automatic backup solution
[01:53:43.400 --> 01:53:46.240]   that backs everything up into the cloud and you really don't have to do anything that's
[01:53:46.240 --> 01:53:50.000]   one of the really cool things about Carbonite they were the first company the first backup
[01:53:50.000 --> 01:53:56.640]   company that just took all of the necessity of having any sort of technical acumen or
[01:53:56.640 --> 01:54:00.520]   basically foresight about backing up your files and they just did it automatically I
[01:54:00.520 --> 01:54:05.040]   first started using this back when I was a Windows user and on the Windows version you
[01:54:05.040 --> 01:54:09.520]   just install it and it figures out which which files you pretty much want to back up and
[01:54:09.520 --> 01:54:13.040]   then it puts a little circle next to every single file in your entire system that tells
[01:54:13.040 --> 01:54:17.560]   you whether we're not going to ever back this up we are going to back this up but haven't
[01:54:17.560 --> 01:54:21.840]   backed it up we have already backed this up so don't worry about this file it's so reassuring
[01:54:21.840 --> 01:54:25.600]   unfortunately that little user interface feature doesn't exist on the Mac version but the Mac
[01:54:25.600 --> 01:54:30.880]   version because of the way that the Mac is established it's apples fault not to Carbonite
[01:54:30.880 --> 01:54:35.280]   but essentially it's still that easy you simply install it in the default mode is that everything's
[01:54:35.280 --> 01:54:39.560]   just backed up into the cloud and then when a meteor shower destroys your house and breaks
[01:54:39.560 --> 01:54:45.400]   your laptop into multiple pieces you haven't lost any data so you don't have to worry
[01:54:45.400 --> 01:54:50.600]   and so Carbonite is really a fantastic service that I've been using for many many years
[01:54:50.600 --> 01:54:54.120]   backs up all your computers and not only that just servers external hard drives whatever
[01:54:54.120 --> 01:54:58.520]   it is into the cloud you know it's probably a good idea to have a local copy as well a
[01:54:58.520 --> 01:55:03.040]   little hard drive because sometimes it's easy to you know you may not have an internet connection
[01:55:03.040 --> 01:55:06.400]   you may need a file or whatever it's good to have redundancy but you definitely need
[01:55:06.400 --> 01:55:10.160]   that cloud based back up because you know you don't want all your stuff together there's
[01:55:10.160 --> 01:55:17.760]   the famous story of the film producer of Apocalypse Now what is his name Harry you have an
[01:55:17.760 --> 01:55:23.720]   exactly pedic knowledge of all Hollywood wisdom anyway the that's for Coppola that's the guy
[01:55:23.720 --> 01:55:28.800]   Francis for Coppola was was in Argentina and he had his screenplay and all of his personal
[01:55:28.800 --> 01:55:33.440]   photographs on a laptop but he was backing them up to a hard drive right next to the laptop
[01:55:33.440 --> 01:55:37.800]   the laptop was stolen the hard drive is stolen and he had nothing he lost a screenplay he
[01:55:37.800 --> 01:55:43.680]   lost the pictures and and that is he's now the poster child for why you need cloud backup
[01:55:43.680 --> 01:55:47.120]   so start your free trial today at Carbonite.com no credit card required at all you can just
[01:55:47.120 --> 01:55:51.800]   start using it without a credit card use the offer code TWIT and you get free bonus months
[01:55:51.800 --> 01:55:57.880]   two of them two free bonus months if you decide to buy that's Carbonite.com and the offer code
[01:55:57.880 --> 01:56:04.360]   TWIT well let's talk about Comcast because Comcast is getting a lot of bad press lately
[01:56:04.360 --> 01:56:09.680]   and they've been embroiled in this all these controversies around net neutrality and you
[01:56:09.680 --> 01:56:15.320]   know making matters worse the CEO of Comcast Brian Roberts recently came out and said we're
[01:56:15.320 --> 01:56:20.320]   going to tell you why everybody hates Comcast the reason everybody hates Comcast is when
[01:56:20.320 --> 01:56:26.440]   the people that originate the Comcast the data the sort of Netflix of the world and the
[01:56:26.440 --> 01:56:32.240]   YouTube's when they raise their prices everybody blames us we're just we're just trying to
[01:56:32.240 --> 01:56:36.000]   provide a good service and therefore we think that we're like the post office if you want
[01:56:36.000 --> 01:56:40.080]   to ship a package through the post office you got to pay the post office and he's saying
[01:56:40.080 --> 01:56:44.680]   that he thinks that companies that generate a lot of data like Netflix should be paying
[01:56:44.680 --> 01:56:49.320]   them and paying them quite a bit for the data even though the customers are also paying
[01:56:49.320 --> 01:56:55.240]   for the delivery of that data any thoughts is he is he got a good point here well he I
[01:56:55.240 --> 01:56:59.920]   mean the reason that came off is so silly is because the I don't think that's the reason
[01:56:59.920 --> 01:57:03.880]   that people hate Comcast at all they hate it because they don't like dealing with the
[01:57:03.880 --> 01:57:07.720]   customer service when they call up because there's a problem with their cable it takes
[01:57:07.720 --> 01:57:12.200]   forever you have to be stuck at home there's an I mean there are kinds of reasons I think
[01:57:12.200 --> 01:57:23.520]   that's the last of them yes exactly do you hate Comcast Katie it's it's yeah it nobody
[01:57:23.520 --> 01:57:27.720]   cares about what's happening with Netflix in terms of like whether or not we like the
[01:57:27.720 --> 01:57:33.080]   company it's it's it's exactly that they're horrible to their customers bad customer service
[01:57:33.080 --> 01:57:37.880]   but in terms of you know what Robert is saying to it almost feels like he kind of wants to
[01:57:37.880 --> 01:57:41.920]   have it all ways he was like we're just the pipe and so you just paid the pipe we're
[01:57:41.920 --> 01:57:46.160]   just the pipe but he also wants to be able to control the pipeline and he wants to not
[01:57:46.160 --> 01:57:50.720]   be a dumb pipe and he wants to be more than just the interchange and he wants to preserve
[01:57:50.720 --> 01:57:55.600]   a gatekeeper role to I don't really think you can have it always and he owns lots of
[01:57:55.600 --> 01:58:02.720]   content and yeah he's not a dumb pipe he's a dumb pipe that owns NBC and there's all
[01:58:02.720 --> 01:58:08.920]   kinds of stuff mixed movies I personally would love to live in a world where the pipes are
[01:58:08.920 --> 01:58:13.560]   as dumb as they could possibly be but just really fast and I'd love to you know I'd love
[01:58:13.560 --> 01:58:18.120]   to get content from a company you know you Google's the fat Google fiber which is only
[01:58:18.120 --> 01:58:21.520]   in two towns right now and they're looking at more towns but that's probably as fast
[01:58:21.520 --> 01:58:25.760]   as it gets in the United States for the delivery of content but Google's not a disinterested
[01:58:25.760 --> 01:58:31.480]   party they they you know they want you to get their ads as fast as you could possibly get
[01:58:31.480 --> 01:58:36.480]   you to get you to YouTube is the second biggest generator of data after Netflix in the United
[01:58:36.480 --> 01:58:42.640]   States and yeah absolutely and you know so I would I just there's got to be some way
[01:58:42.640 --> 01:58:46.920]   other than just having these things become common carriers where we can just have the
[01:58:46.920 --> 01:58:51.960]   dumbest pipes that have no you know no interest other than providing the fastest possible
[01:58:51.960 --> 01:58:57.040]   data service sadly there is no such thing as a disinterested large company I guess I'm
[01:58:57.040 --> 01:59:00.640]   just a dreamer well it could be government regulated but there are a lot of people who
[01:59:00.640 --> 01:59:04.400]   wouldn't want that either in Australia tried to do that and that fell apart yeah I mean
[01:59:04.400 --> 01:59:11.200]   you know there are some there are some countries a few of them South Korea but but really I
[01:59:11.200 --> 01:59:15.600]   mean that's the alternative yeah absolutely right it raises the question has the internet
[01:59:15.600 --> 01:59:20.200]   risen to the level of importance that it's a utility and it should be treated like utility
[01:59:20.200 --> 01:59:24.120]   and if that's the case well then that's very different but until that happens we're stuck
[01:59:24.120 --> 01:59:29.960]   with Brian Roberts yeah well and we shouldn't be the real problem the root problem whenever
[01:59:29.960 --> 01:59:34.280]   we talk about net neutrality whenever we talk about whether we hate Comcast or not is that
[01:59:34.280 --> 01:59:38.880]   there's often not much of an alternative Comcast as there are in other countries you
[01:59:38.880 --> 01:59:45.280]   go to the UK and you can choose from among four five six seven different ISPs and you
[01:59:45.280 --> 01:59:50.200]   know let the let the best ISP win and we don't have that here in some markets it's just one
[01:59:50.200 --> 01:59:54.720]   in others it's two it's very rarely more than three or four and that's really the problem
[01:59:54.720 --> 01:59:59.280]   and we need to figure out how to get some competition in this market I think we can all
[01:59:59.280 --> 02:00:07.040]   agree with that well that is twit that is today's twit the leola's version here and before we
[02:00:07.040 --> 02:00:14.280]   sign off I want to invite everyone to tune into our special coverage tomorrow WWDC developers
[02:00:14.280 --> 02:00:18.800]   conference keynote and that's going to be Leo Laporte we're gonna he's in the basement
[02:00:18.800 --> 02:00:22.560]   tied up right now we're gonna untie him for that Sarah Lane Alex Lindsey and me and we're
[02:00:22.560 --> 02:00:26.880]   gonna cover it live we're gonna heckle the keynote and see what it is that they announced
[02:00:26.880 --> 02:00:30.200]   tomorrow so tune in for that tech news today which is normally a ten o'clock is going to
[02:00:30.200 --> 02:00:34.200]   be at eight thirty am Pacific so here in McCracken I want to thank you for coming on
[02:00:34.200 --> 02:00:37.720]   Twitter today it's always a pleasure to have you on whatever show I happen to be hosting
[02:00:37.720 --> 02:00:42.040]   always good to see you Mike and so tell us more about where people can read your stuff
[02:00:42.040 --> 02:00:47.600]   with your new joint sure welcome to technologyizer dot com you'll see all my stuff or I'm Harry
[02:00:47.600 --> 02:00:52.760]   McCracken Twitter I'm also doing technologyizer and flip board you can find my my technology
[02:00:52.760 --> 02:00:56.840]  izer magazine there which will have all my stuff I didn't know that I just started doing that
[02:00:56.840 --> 02:01:00.640]   I'm gonna subscribe to that I love flip board and I figure why not make the experience as
[02:01:00.640 --> 02:01:04.960]   good as possible why not so it's always great to have a good source of content there's some
[02:01:04.960 --> 02:01:08.320]   of the stuff on flip board is not great but I'm sure yours is gonna be awesome is that
[02:01:08.320 --> 02:01:11.760]   just gonna be your stuff or you're gonna curate I'm gonna curate to and that I'm curating
[02:01:11.760 --> 02:01:15.520]   on technologyizer dot com to and the stuff I curate there I'll secure it on flip board
[02:01:15.520 --> 02:01:20.640]   all right wonderful well thank you for coming on to twit and Lindsey Turrentine editor in
[02:01:20.640 --> 02:01:25.480]   chief of CNET reviews thank you for coming on to twit you're welcome very fun and so
[02:01:25.480 --> 02:01:29.760]   tell us more about this a little bit more about this this secret lab that you have for
[02:01:29.760 --> 02:01:34.920]   home automation this is gonna be generating all kinds of like reviews of these products
[02:01:34.920 --> 02:01:39.600]   we actually have this now we have a 12,000 square foot facility in Louisville Kentucky
[02:01:39.600 --> 02:01:43.360]   it's a it's a warehouse that we've converted into an editorial space and a testing facility
[02:01:43.360 --> 02:01:47.720]   where we test large appliances and small connected appliances and we rate them and review them
[02:01:47.720 --> 02:01:51.640]   like all of the other technology that we review on CNET so that's great there's some exciting
[02:01:51.640 --> 02:01:55.840]   additional stuff we'll be doing I can't talk about quite yet but we'll be coming in the
[02:01:55.840 --> 02:02:01.120]   fall awesome wonderful and Katie Benner with the information thank you so much for coming
[02:02:01.120 --> 02:02:07.000]   on to tech news tech news today this is to it this is this week in tech this is the big
[02:02:07.000 --> 02:02:12.680]   show but thank you for coming on and where can people find what you write we are the information
[02:02:12.680 --> 02:02:16.840]   dot com it's a subscription site it's true but I think it's worth subscribing and I hope
[02:02:16.840 --> 02:02:20.760]   that you do join us over at the information the most important part of that URL is the
[02:02:20.760 --> 02:02:26.120]   word the information is easy to remember but don't forget you have to use the word the
[02:02:26.120 --> 02:02:31.040]   the information well thank you so much Katie Benner and this is been an exciting adventure
[02:02:31.040 --> 02:02:35.120]   for me personally doing this show I remember I used to be right where you're sitting sitting
[02:02:35.120 --> 02:02:39.360]   and right in that chair looking at Leo dude this week in tech and thinking there's no
[02:02:39.360 --> 02:02:42.960]   way I could do that there's no way I could do that show that I don't know how he does
[02:02:42.960 --> 02:02:46.920]   it I still don't know how he does it but it's been exciting for me and I want to thank
[02:02:46.920 --> 02:02:51.880]   you all for coming and so I get to say what Leo always says another twit is in the can
[02:02:51.880 --> 02:02:52.920]   always wanted to say that
[02:02:52.920 --> 02:02:59.920]   yeah
[02:02:59.920 --> 02:03:00.920]   you
[02:03:00.920 --> 02:03:03.320]   - Do it, baby. - Do it the twist.
[02:03:03.320 --> 02:03:05.160]   - All right. - Do it the twist.

