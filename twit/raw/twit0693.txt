;FFMETADATA1
title=Big Boy Easy Bake Oven
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=693
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:03.800]   It's time for Twit this week in Tech. What a great panel.
[00:00:03.800 --> 00:00:06.600]   Georgia Dow, Larry Magad, Brianna Wu.
[00:00:06.600 --> 00:00:12.400]   Yes, she's back from her election and we'll talk about election day 2016 for 2018 for Brianna.
[00:00:12.400 --> 00:00:16.400]   Facebook's Crisis Management, Julian Assange.
[00:00:16.400 --> 00:00:20.000]   He's apparently being charged. What's going on there?
[00:00:20.000 --> 00:00:24.600]   Amazon's new HQ and a whole lot more. It's going to be a great long Twit.
[00:00:24.600 --> 00:00:26.600]   Sit back. Enjoy.
[00:00:27.600 --> 00:00:31.600]   Netcast you love.
[00:00:31.600 --> 00:00:33.600]   From people you trust.
[00:00:33.600 --> 00:00:38.600]   This is Twit.
[00:00:38.600 --> 00:00:47.600]   This is Twit this week in Tech.
[00:00:47.600 --> 00:00:52.600]   Episode 693 recorded Sunday, November 18, 2018.
[00:00:52.600 --> 00:00:55.600]   Big boy easy bake oven.
[00:00:56.600 --> 00:00:59.600]   This week in Tech is brought to you by Masterclass.
[00:00:59.600 --> 00:01:02.600]   Online class is taught by the world's greatest minds.
[00:01:02.600 --> 00:01:09.600]   Visit masterclass.com/twit to unlock access to every Masterclass for one low annual price.
[00:01:09.600 --> 00:01:12.600]   And buy rocket mortgage from quick and loans.
[00:01:12.600 --> 00:01:14.600]   Introducing rate shield approval.
[00:01:14.600 --> 00:01:19.600]   If you're in the market to buy a home, rate shield approval locks up your rate for up to 90 days while you shop.
[00:01:19.600 --> 00:01:20.600]   It's a real game changer.
[00:01:20.600 --> 00:01:24.600]   Learn more and get started at rocketmortgage.com/twit2.
[00:01:25.600 --> 00:01:26.600]   And buy WordPress.
[00:01:26.600 --> 00:01:30.600]   Reach more customers when you build your business website on WordPress.com.
[00:01:30.600 --> 00:01:37.600]   Plan start at just $4 a month and get 15% off any new plan at WordPress.com/twit.
[00:01:37.600 --> 00:01:39.600]   And buy cash fly.
[00:01:39.600 --> 00:01:42.600]   Make this the last month your CDN bill gives you a headache.
[00:01:42.600 --> 00:01:45.600]   Join the thousands of others who trust cash flies.
[00:01:45.600 --> 00:01:46.600]   Reliable network.
[00:01:46.600 --> 00:01:49.600]   And just for Twit listeners receive up to $2,000 in credit.
[00:01:49.600 --> 00:01:51.600]   When you switch to cash fly before January 1st,
[00:01:51.600 --> 00:01:56.600]   learn more and get a complimentary quote at twit.cashfly.com.
[00:01:56.600 --> 00:02:03.600]   It's time for Twit this week in Tech to show where we cover the week's tech news with the best tech journalist
[00:02:03.600 --> 00:02:05.600]   so I can round up on short notice.
[00:02:05.600 --> 00:02:07.600]   And no, just get it.
[00:02:07.600 --> 00:02:12.600]   With the best tech journalist in the business like this guy right here, Larry Maggot has been doing it longer than anybody.
[00:02:12.600 --> 00:02:13.600]   CBS News Radio.
[00:02:13.600 --> 00:02:18.600]   Connects safely.org and an old friend, a good dear friend, not old friend.
[00:02:18.600 --> 00:02:19.600]   Hello Larry, good to see you.
[00:02:19.600 --> 00:02:21.600]   Oh, to a gray hair you noticed.
[00:02:21.600 --> 00:02:27.600]   Back from his tour of Europe you visited the House of Lords.
[00:02:27.600 --> 00:02:28.600]   I did.
[00:02:28.600 --> 00:02:30.600]   I visited the house that had lunch at the House of Lords.
[00:02:30.600 --> 00:02:33.600]   I have a friend who's in the House of Lords.
[00:02:33.600 --> 00:02:34.600]   It's a lifetime position.
[00:02:34.600 --> 00:02:37.600]   So as long as she's alive, I'll have a friend at the House of Lords.
[00:02:37.600 --> 00:02:41.600]   And then we went over to Brussels to do some meeting with the European Commission down to Luxembourg,
[00:02:41.600 --> 00:02:43.600]   also for European Commission.
[00:02:43.600 --> 00:02:47.600]   And then off to Paris for the Internet Governance Forum and also GovTech.
[00:02:47.600 --> 00:02:52.600]   It was tech week in Paris along with, you know, so literally hours after Trump left,
[00:02:52.600 --> 00:02:55.600]   I went to a meeting that Justin Trudeau spoke out.
[00:02:55.600 --> 00:03:02.600]   He has got, of all the people I didn't interview him, but of all the people I have been around in the tech world and policy,
[00:03:02.600 --> 00:03:04.600]   he probably knows more than Al Gore.
[00:03:04.600 --> 00:03:06.600]   Al Gore at the time was pretty good.
[00:03:06.600 --> 00:03:11.600]   And then after that, Macron, Manuel Macron spoke at the Internet Governance Forum and basically said,
[00:03:11.600 --> 00:03:12.600]   there are two kinds of Internet.
[00:03:12.600 --> 00:03:16.600]   So it's the California Internet where government has basically has nothing to do with it.
[00:03:16.600 --> 00:03:20.600]   It's laissez faire and there's the China Internet where the government controls it
[00:03:20.600 --> 00:03:24.600]   and Macron wants the Internet to be somewhere between the California Internet and the China Internet.
[00:03:24.600 --> 00:03:26.600]   That's an interesting thought.
[00:03:26.600 --> 00:03:28.600]   With government control or government involvement.
[00:03:28.600 --> 00:03:29.600]   I don't think you can.
[00:03:29.600 --> 00:03:31.600]   I think you, one or the other.
[00:03:31.600 --> 00:03:32.600]   I don't know.
[00:03:32.600 --> 00:03:33.600]   I don't know.
[00:03:33.600 --> 00:03:40.600]   Tim Cook came out, I think, tonight on Axios is going to say he acknowledges that regulation is coming.
[00:03:40.600 --> 00:03:42.600]   So I think that Macron is probably right.
[00:03:42.600 --> 00:03:43.600]   Yeah.
[00:03:43.600 --> 00:03:44.600]   And Cook agrees.
[00:03:44.600 --> 00:03:48.600]   Cook is, I think, one of the first people to say we have two Internet's.
[00:03:48.600 --> 00:03:49.600]   Yeah.
[00:03:49.600 --> 00:03:51.600]   Well, very interesting.
[00:03:51.600 --> 00:03:52.600]   Welcome.
[00:03:52.600 --> 00:03:55.600]   And I will introduce the rest of the panel before we get into the heavy conversation.
[00:03:55.600 --> 00:03:56.600]   Yeah.
[00:03:56.600 --> 00:03:57.600]   But that's an interesting topic.
[00:03:57.600 --> 00:03:59.600]   Georgia Dow is also here for MyMore.com.
[00:03:59.600 --> 00:04:00.600]   It's always a thrill.
[00:04:00.600 --> 00:04:01.600]   Hello, Georgia.
[00:04:01.600 --> 00:04:04.600]   She's senior editor over there at Georgia Dow.
[00:04:04.600 --> 00:04:07.600]   She's also, and we need her more than ever, psychotherapists.
[00:04:07.600 --> 00:04:18.600]   Who creates great videos about reducing anxiety, sleeping better, raising your kids at anxiety-videos.com.
[00:04:18.600 --> 00:04:19.600]   Hello, Georgia.
[00:04:19.600 --> 00:04:20.600]   Hello.
[00:04:20.600 --> 00:04:21.600]   We have two new videos, actually.
[00:04:21.600 --> 00:04:30.600]   So we have, like, we're starting the Master's series, which is more for, like, businesses and getting ahead and just leading a better life.
[00:04:30.600 --> 00:04:32.600]   So we have one on emotional intelligence.
[00:04:32.600 --> 00:04:35.600]   And that's about what do your emotions mean?
[00:04:35.600 --> 00:04:37.600]   What do other people's emotions mean?
[00:04:37.600 --> 00:04:38.600]   What is this social engineering?
[00:04:38.600 --> 00:04:41.600]   Why do people want certain things?
[00:04:41.600 --> 00:04:44.600]   And then we have another one for conflict.
[00:04:44.600 --> 00:04:46.600]   And that one's on conflict resolution.
[00:04:46.600 --> 00:04:54.600]   So how can you get to a conflict with someone and actually make it a win-win or even make your relationship better because you had a disagreement with someone?
[00:04:54.600 --> 00:05:01.600]   So it's just kind of how to not get stuck in being defensive or reactive and how you can deal with it.
[00:05:01.600 --> 00:05:03.600]   And you do these with Sandra Reich?
[00:05:03.600 --> 00:05:04.600]   Yeah, I do.
[00:05:04.600 --> 00:05:09.600]   Who's also a therapist and you're both at the Montreal Center for Anxiety and Depression.
[00:05:09.600 --> 00:05:11.600]   So that's anxiety dash.
[00:05:11.600 --> 00:05:12.600]   You make house calls?
[00:05:12.600 --> 00:05:13.600]   Yeah, really.
[00:05:13.600 --> 00:05:15.600]   We need your solar-convelliadair.
[00:05:15.600 --> 00:05:16.600]   Yeah, really.
[00:05:16.600 --> 00:05:18.600]   Hey, that's Brianna.
[00:05:18.600 --> 00:05:22.600]   Whoa, Canada for Congress and the Massachusetts 8th District.
[00:05:22.600 --> 00:05:24.600]   It still says that as your lower third.
[00:05:24.600 --> 00:05:25.600]   Are we going to leave that up?
[00:05:25.600 --> 00:05:26.600]   I think we should.
[00:05:26.600 --> 00:05:33.600]   So Brianna was primaryed out by her Democratic opponent who did, in fact, win his senior year.
[00:05:33.600 --> 00:05:35.600]   Like win his seat back in Congress.
[00:05:35.600 --> 00:05:36.600]   He was the incumbent.
[00:05:36.600 --> 00:05:39.600]   But you say you're not giving up.
[00:05:39.600 --> 00:05:40.600]   Nope.
[00:05:40.600 --> 00:05:41.600]   We've never got 17,000 votes.
[00:05:41.600 --> 00:05:49.600]   That is amazing for a first-time candidate.
[00:05:49.600 --> 00:05:51.600]   We had a very small team.
[00:05:51.600 --> 00:05:59.600]   And, you know, I always, you guys have from the beginning when I started running, that was probably going to have to run twice.
[00:05:59.600 --> 00:06:03.600]   And so, you have a very, very small chance of winning your first time.
[00:06:03.600 --> 00:06:06.600]   And my goal was always, you know, be an engineer.
[00:06:06.600 --> 00:06:08.600]   Get all my mistakes out of the way.
[00:06:08.600 --> 00:06:09.600]   Figure out how to do this.
[00:06:09.600 --> 00:06:12.600]   And, you know, we're already gearing up for 2020.
[00:06:12.600 --> 00:06:15.600]   It's amazing how much more I know at this point.
[00:06:15.600 --> 00:06:17.600]   I know how to file FEC reports.
[00:06:17.600 --> 00:06:19.600]   I know how leaders in every single town.
[00:06:19.600 --> 00:06:21.600]   I know how to give a speech.
[00:06:21.600 --> 00:06:22.600]   I know how to raise money.
[00:06:22.600 --> 00:06:26.600]   I know, like, leaders in every single part of my district.
[00:06:26.600 --> 00:06:30.600]   So, you know, I'm in 2020 to absolutely win.
[00:06:30.600 --> 00:06:32.600]   And keep them talking about tech.
[00:06:32.600 --> 00:06:33.600]   Absolutely.
[00:06:33.600 --> 00:06:35.600]   I have to say how brave that is.
[00:06:35.600 --> 00:06:39.600]   Because, of course, Brianna was also a very well-known victim of a gamer game.
[00:06:39.600 --> 00:06:42.600]   I know you don't particularly want to talk about that.
[00:06:42.600 --> 00:06:48.600]   But for you to stay in the public eye when probably every bone in your body said, let's just hide.
[00:06:48.600 --> 00:06:49.600]   Yeah.
[00:06:49.600 --> 00:06:52.600]   Shows how much, how much guts you have.
[00:06:52.600 --> 00:06:55.600]   And so, are you, so you're going to, you already filed for 2020?
[00:06:55.600 --> 00:06:56.600]   We already did.
[00:06:56.600 --> 00:06:58.600]   We already listed with the FEC.
[00:06:58.600 --> 00:07:02.600]   And one of the things, Leo, I was talking to you about this before the show.
[00:07:02.600 --> 00:07:08.600]   One of the mistakes I made is I hired people like I did in my game studio.
[00:07:08.600 --> 00:07:11.600]   We hired a lot of people straight out of college and gave them jobs.
[00:07:11.600 --> 00:07:15.600]   And we all figured out how to make software together.
[00:07:15.600 --> 00:07:21.600]   And that works well in engineering because you're developing something new every single time.
[00:07:21.600 --> 00:07:27.600]   But with politics, this is one of those fields that there is innovation, but some of the
[00:07:27.600 --> 00:07:30.600]   basics, you just can't disrupt your way around.
[00:07:30.600 --> 00:07:32.600]   You've got to shake hands.
[00:07:32.600 --> 00:07:33.600]   You've got to meet people.
[00:07:33.600 --> 00:07:35.600]   So this time around.
[00:07:35.600 --> 00:07:36.600]   Right.
[00:07:36.600 --> 00:07:39.600]   Well, I mean, you've got to get off the computer out into the real world.
[00:07:39.600 --> 00:07:44.600]   So one of the lessons I've learned is you've got to hire people at the experience.
[00:07:44.600 --> 00:07:46.600]   And that's exactly what we've done this time around.
[00:07:46.600 --> 00:07:50.600]   Well, you know, and I was talking before the show about this, but I have experience with
[00:07:50.600 --> 00:07:51.600]   friends who've run for office.
[00:07:51.600 --> 00:07:52.600]   And you're exactly right.
[00:07:52.600 --> 00:07:54.600]   The first time you're unknown and an quantity.
[00:07:54.600 --> 00:08:00.600]   The second time you're known and often name recognition is a sadly a huge part of why people
[00:08:00.600 --> 00:08:01.600]   win.
[00:08:01.600 --> 00:08:04.600]   I was talking to somebody about the pedal of a mayoral race.
[00:08:04.600 --> 00:08:06.600]   And as she said, she was going to vote for one of the candidates.
[00:08:06.600 --> 00:08:07.600]   I said, why?
[00:08:07.600 --> 00:08:10.600]   She said, because well, she has the most lawn signs.
[00:08:10.600 --> 00:08:14.600]   And honestly, I don't think that's an outlier.
[00:08:14.600 --> 00:08:15.600]   Yeah.
[00:08:15.600 --> 00:08:17.600]   It really name recognition is a lot of it.
[00:08:17.600 --> 00:08:18.600]   So I'm good.
[00:08:18.600 --> 00:08:19.600]   I'm glad to hear you're not giving up.
[00:08:19.600 --> 00:08:20.600]   You're going to continue to run.
[00:08:20.600 --> 00:08:25.600]   Now we have Brianna Wu 2018.com as the website that's gone.
[00:08:25.600 --> 00:08:27.600]   No, it's still up.
[00:08:27.600 --> 00:08:29.600]   We finally got Brianna Wu for Congress.
[00:08:29.600 --> 00:08:32.600]   So we're actually building that right now.
[00:08:32.600 --> 00:08:37.600]   Last time around, we went with a, again, we went with the disruptor nation builder.
[00:08:37.600 --> 00:08:40.600]   We're going to work with the tried and true NGP van this time.
[00:08:40.600 --> 00:08:43.600]   So someone know my team is migrating that currently.
[00:08:43.600 --> 00:08:47.600]   Have you thought about starting out with a reality show, maybe like, you know, where
[00:08:47.600 --> 00:08:50.600]   people apply for jobs and you say you're fired?
[00:08:50.600 --> 00:08:53.600]   No, it worked for some, but I think that's one guy.
[00:08:53.600 --> 00:08:55.600]   You can't keep going back to the well.
[00:08:55.600 --> 00:08:57.600]   You got a, you got a something new.
[00:08:57.600 --> 00:09:02.600]   I will say this and this isn't all seriousness, Leo, and hold me to the standard.
[00:09:02.600 --> 00:09:08.600]   I have talked to really high quality documentary journalists.
[00:09:08.600 --> 00:09:12.600]   And one of the things I've committed to is, you know, if I am fortunate enough to win
[00:09:12.600 --> 00:09:17.400]   in 2020, I want to bring people in and kind of show the American people the
[00:09:17.400 --> 00:09:18.400]   sausage.
[00:09:18.400 --> 00:09:23.160]   What happens if you call up the house minority and majority leader and try to get bills
[00:09:23.160 --> 00:09:24.160]   passed?
[00:09:24.160 --> 00:09:25.840]   What's really going on in Washington?
[00:09:25.840 --> 00:09:31.000]   And I want to open things up, especially on the technology subcommittee.
[00:09:31.000 --> 00:09:32.000]   I love it.
[00:09:32.000 --> 00:09:37.000]   Opening openness in government is a rare and valuable thing and much needed.
[00:09:37.000 --> 00:09:38.000]   Yep.
[00:09:38.000 --> 00:09:39.000]   I agree.
[00:09:39.000 --> 00:09:40.000]   Yeah.
[00:09:40.000 --> 00:09:43.800]   By the way, we should mention that Georgia Dow's president is Justin Trudeau.
[00:09:43.800 --> 00:09:44.800]   It's East down.
[00:09:44.800 --> 00:09:47.800]   Congratulations.
[00:09:47.800 --> 00:09:49.800]   Well done.
[00:09:49.800 --> 00:09:52.800]   You got any room in your country?
[00:09:52.800 --> 00:09:53.800]   You don't have any wall.
[00:09:53.800 --> 00:09:54.800]   No, no, stop that.
[00:09:54.800 --> 00:09:55.800]   Now stop it.
[00:09:55.800 --> 00:09:56.800]   There's tons of room in Canada.
[00:09:56.800 --> 00:09:58.800]   I have to hear most of these things.
[00:09:58.800 --> 00:09:59.800]   So need you here.
[00:09:59.800 --> 00:10:00.800]   It's really cold.
[00:10:00.800 --> 00:10:01.800]   Yeah.
[00:10:01.800 --> 00:10:02.800]   Yeah.
[00:10:02.800 --> 00:10:03.800]   That's too cold.
[00:10:03.800 --> 00:10:04.800]   Yeah.
[00:10:04.800 --> 00:10:07.800]   Because you don't have fires and pretty much all of California is now.
[00:10:07.800 --> 00:10:08.800]   Yeah.
[00:10:08.800 --> 00:10:09.800]   That's true.
[00:10:09.800 --> 00:10:11.800]   Actually, you had fires in BC a couple of years ago, right?
[00:10:11.800 --> 00:10:15.800]   We do, but they're not what you're going through right now.
[00:10:15.800 --> 00:10:16.800]   You know what?
[00:10:16.800 --> 00:10:18.800]   There's no historic precedent for what's happening right now, California.
[00:10:18.800 --> 00:10:19.800]   Right.
[00:10:19.800 --> 00:10:20.800]   It's devastating.
[00:10:20.800 --> 00:10:21.800]   Nope.
[00:10:21.800 --> 00:10:22.800]   And you're not far from it.
[00:10:22.800 --> 00:10:24.800]   Are you heavy in the smoke?
[00:10:24.800 --> 00:10:25.800]   It's pretty bad.
[00:10:25.800 --> 00:10:27.800]   It's just bad.
[00:10:27.800 --> 00:10:30.800]   So on health levels are over 200.
[00:10:30.800 --> 00:10:35.640]   It's just under 200 right now, but it has been over 200 for the last couple of days.
[00:10:35.640 --> 00:10:40.080]   So we're inside with our molecule air for air purifier running full bore.
[00:10:40.080 --> 00:10:41.800]   And we have a couple at home.
[00:10:41.800 --> 00:10:46.080]   I turned them all the way up and just try to stay inside.
[00:10:46.080 --> 00:10:47.080]   And it's tough.
[00:10:47.080 --> 00:10:50.000]   I wasn't paying too much attention to it.
[00:10:50.000 --> 00:10:52.320]   I thought, oh, I'm strong.
[00:10:52.320 --> 00:10:53.720]   I'm robust.
[00:10:53.720 --> 00:10:59.840]   And on Thursday, we were putting up the Christmas lights and I just got an electric bike.
[00:10:59.840 --> 00:11:01.120]   So I went on a bike ride.
[00:11:01.120 --> 00:11:03.120]   None of this with a mask.
[00:11:03.120 --> 00:11:05.920]   I woke up Friday morning.
[00:11:05.920 --> 00:11:08.040]   I thought I'd smoked a carton of cigarettes.
[00:11:08.040 --> 00:11:10.920]   I was coughing and it was terrible.
[00:11:10.920 --> 00:11:13.320]   And I realized, no, I'm not immune.
[00:11:13.320 --> 00:11:18.760]   And when the levels get that high, everybody's health is impacted.
[00:11:18.760 --> 00:11:23.840]   So that's minor compared to the people who people lost their homes living their lives.
[00:11:23.840 --> 00:11:25.720]   And people lost their lives.
[00:11:25.720 --> 00:11:28.800]   And we don't know how many, but a thousand people are missing.
[00:11:28.800 --> 00:11:29.800]   Yeah.
[00:11:29.800 --> 00:11:32.560]   That is a terrifying number.
[00:11:32.560 --> 00:11:38.240]   I mean, I think about, I was in Mississippi for Katrina and about 1,800 people died for
[00:11:38.240 --> 00:11:39.240]   that.
[00:11:39.240 --> 00:11:43.440]   So you think about at just this point, it's already 1,000.
[00:11:43.440 --> 00:11:45.080]   That's really scary.
[00:11:45.080 --> 00:11:49.440]   You know, terrifying.
[00:11:49.440 --> 00:11:51.160]   But that's just our little corner of the world.
[00:11:51.160 --> 00:11:52.960]   There's sadness all over.
[00:11:52.960 --> 00:11:56.920]   So we're going to focus on the good, like Facebook.
[00:11:56.920 --> 00:12:08.400]   Now, I, you know, this article in the New York Times, delay, deny and deflect how Facebook's
[00:12:08.400 --> 00:12:15.760]   leaders fought through crisis came out just, I think it was on Wednesday.
[00:12:15.760 --> 00:12:22.360]   And it is one of those stories by, you know, 12345 New York Times reporters.
[00:12:22.360 --> 00:12:25.960]   They say 50 sources, you know, very well sourced.
[00:12:25.960 --> 00:12:31.480]   It's one of those stories where it's inside the boardroom, inside the offices.
[00:12:31.480 --> 00:12:34.760]   So I always am a little nervous when I read that kind of story.
[00:12:34.760 --> 00:12:40.080]   You know, any story that has the lead, Cheryl Sandberg was seething inside Facebook's Men
[00:12:40.080 --> 00:12:44.560]   Low Park, California headquarters, top executives gathered in the glass walled conference from
[00:12:44.560 --> 00:12:47.120]   at Sonder Mark Zuckerberg, et cetera, et cetera.
[00:12:47.120 --> 00:12:50.400]   I'm always a little skeptical about articles like that.
[00:12:50.400 --> 00:12:56.200]   And indeed, Facebook has said that many points in this article, it got wrong.
[00:12:56.200 --> 00:13:01.920]   But I get the sense that the general thrust of it is not wrong, which is that Facebook
[00:13:01.920 --> 00:13:08.920]   went on a public relations offensive after the 2016 election.
[00:13:08.920 --> 00:13:14.600]   And even to the point where they hired a fairly sketchy company, which they have, by the way,
[00:13:14.600 --> 00:13:22.000]   since let go, that attempted to blame George Soros, unbelievable.
[00:13:22.000 --> 00:13:24.720]   It was called it's Definers Public Affairs.
[00:13:24.720 --> 00:13:31.080]   Facebook says now, oh yeah, we did use them, but we didn't know what they did or would
[00:13:31.080 --> 00:13:32.080]   do.
[00:13:32.080 --> 00:13:34.480]   And we have fired them since.
[00:13:34.480 --> 00:13:41.560]   But this is very much the Facebook playbook, which is, you know, slash and burn and apologize
[00:13:41.560 --> 00:13:42.560]   later.
[00:13:42.560 --> 00:13:43.560]   Yeah.
[00:13:43.560 --> 00:13:46.160]   So I don't know how much I credit.
[00:13:46.160 --> 00:13:48.200]   I'll be honest with you.
[00:13:48.200 --> 00:13:51.520]   I abandoned Facebook months ago in August.
[00:13:51.520 --> 00:13:53.080]   Did you stay to Wayne Leo?
[00:13:53.080 --> 00:13:54.080]   Yeah.
[00:13:54.080 --> 00:13:55.080]   Well, good for you.
[00:13:55.080 --> 00:13:56.080]   Yes.
[00:13:56.080 --> 00:13:57.080]   No.
[00:13:57.080 --> 00:13:58.080]   Okay.
[00:13:58.080 --> 00:14:01.000]   So this is one of the challenges of being a tech journalist is it is the story.
[00:14:01.000 --> 00:14:02.560]   I didn't kill my account.
[00:14:02.560 --> 00:14:04.480]   I deactivated it.
[00:14:04.480 --> 00:14:09.680]   And I had to reactivate it to buy, I'm sorry to say I'm embarrassed to say a Facebook portal.
[00:14:09.680 --> 00:14:10.680]   Yeah.
[00:14:10.680 --> 00:14:11.680]   Are you botling?
[00:14:11.680 --> 00:14:12.680]   Yeah.
[00:14:12.680 --> 00:14:15.080]   I told them they're coming.
[00:14:15.080 --> 00:14:16.080]   Facebook charged my card.
[00:14:16.080 --> 00:14:18.000]   At first I looked and I said, oh good.
[00:14:18.000 --> 00:14:19.480]   I something went wrong.
[00:14:19.480 --> 00:14:20.480]   They didn't.
[00:14:20.480 --> 00:14:21.480]   But no, they charged my card.
[00:14:21.480 --> 00:14:25.400]   So I will have to have a Facebook presence and I just gave them some hundreds of dollars.
[00:14:25.400 --> 00:14:28.560]   You know, they're not cheap, but we got a, but I feel like we, I don't know.
[00:14:28.560 --> 00:14:30.080]   At first, I thought we should review it.
[00:14:30.080 --> 00:14:32.680]   So I bought it because that's our job.
[00:14:32.680 --> 00:14:34.920]   Then I thought nobody's going to buy this.
[00:14:34.920 --> 00:14:35.920]   Right.
[00:14:35.920 --> 00:14:41.640]   Then I saw that Android Central Review, which said it's my favorite way to voice chat.
[00:14:41.640 --> 00:14:46.920]   So I don't know somebody in the chat room says I should move before they deliver them.
[00:14:46.920 --> 00:14:49.760]   But he's already given the money.
[00:14:49.760 --> 00:14:51.360]   So they already have my money.
[00:14:51.360 --> 00:14:53.600]   No, they want Leah's data.
[00:14:53.600 --> 00:14:54.600]   They won't be.
[00:14:54.600 --> 00:14:55.600]   That's right.
[00:14:55.600 --> 00:14:58.160]   They're in the room following you around the house.
[00:14:58.160 --> 00:15:00.920]   If you maybe walk around the house.
[00:15:00.920 --> 00:15:04.280]   So I have some thoughts on this.
[00:15:04.280 --> 00:15:08.560]   You one of the things that really struck me in this piece is, you know, I, I don't know
[00:15:08.560 --> 00:15:14.000]   Cheryl Sandberg personally, but she's certainly friendly with a lot of people that I know.
[00:15:14.000 --> 00:15:18.800]   Like if you're a woman in tech, you're, you've got connections to Cheryl Sandberg one way
[00:15:18.800 --> 00:15:20.280]   or another.
[00:15:20.280 --> 00:15:24.800]   And I, I was so disappointed with her role in this.
[00:15:24.800 --> 00:15:30.280]   And one of my main takeaways is, you know, Cheryl Sandberg is someone really associated
[00:15:30.280 --> 00:15:33.800]   with democratic politics associated with my party.
[00:15:33.800 --> 00:15:39.520]   But here she is going up and hiring a really sketchy right wing firm to attack critics
[00:15:39.520 --> 00:15:45.520]   with Facebook with what I think most of us would agree are anti-Semitic attacks.
[00:15:45.520 --> 00:15:53.520]   And I, I really think it, I think it speaks to a problem I've seen in the valley where
[00:15:53.520 --> 00:15:58.640]   some people, there's almost a perception that like, if you're on team Democrat, like
[00:15:58.640 --> 00:15:59.880]   you're fine.
[00:15:59.880 --> 00:16:02.120]   And that's the end of the story.
[00:16:02.120 --> 00:16:07.680]   And I think like with, with Cheryl Sandberg, this is really why you have to give more scrutiny
[00:16:07.680 --> 00:16:08.680]   than that.
[00:16:08.680 --> 00:16:09.920]   Does, does that make sense to you?
[00:16:09.920 --> 00:16:14.480]   Just because you're a Democrat and you write a book about women in tech, it doesn't mean
[00:16:14.480 --> 00:16:16.480]   you're fighting for the right things.
[00:16:16.480 --> 00:16:18.840]   And I really think this article shows that.
[00:16:18.840 --> 00:16:19.840]   Yeah.
[00:16:19.840 --> 00:16:23.280]   Part of the problem we have in this country is treating politics like team sports.
[00:16:23.280 --> 00:16:24.280]   Yeah.
[00:16:24.280 --> 00:16:27.200]   That you're on, that's my team right or wrong.
[00:16:27.200 --> 00:16:34.040]   And I have to tell you right now, even though the Democrats control the house, if, if they
[00:16:34.040 --> 00:16:38.800]   make it all about stopping Donald Trump instead of making good policy, there's a lot to do
[00:16:38.800 --> 00:16:44.040]   in this country, that they will be just as bad as the other guys.
[00:16:44.040 --> 00:16:46.720]   And I, it isn't my team right or wrong.
[00:16:46.720 --> 00:16:49.760]   There's a lot of work to be done and, and the work needs to be done.
[00:16:49.760 --> 00:16:52.840]   And I also honestly think the electorate feels the same way.
[00:16:52.840 --> 00:16:55.640]   It would be a huge mistake at this point.
[00:16:55.640 --> 00:16:56.640]   So I'm back to Cheryl.
[00:16:56.640 --> 00:16:57.640]   Yeah, back to Cheryl.
[00:16:57.640 --> 00:16:58.640]   I know Cheryl.
[00:16:58.640 --> 00:17:02.480]   I do know her quite well and she and I court, you know, I haven't talked to her about this
[00:17:02.480 --> 00:17:06.880]   particular New York Times article, but we correspond back and forth and I'm on Facebook
[00:17:06.880 --> 00:17:08.200]   Safety Advisory Board.
[00:17:08.200 --> 00:17:12.720]   So in a way, I'm a little bit close to the company and what I can say, and there's some
[00:17:12.720 --> 00:17:15.240]   things I can't say, but what I can't say is that they're conflicted.
[00:17:15.240 --> 00:17:19.960]   There are within the company different forces and around a lot of issues.
[00:17:19.960 --> 00:17:23.720]   And there's just a great deal of conflict as to what is right and what isn't.
[00:17:23.720 --> 00:17:28.120]   I was actually in Europe when this article came out, so I didn't focus on it.
[00:17:28.120 --> 00:17:32.320]   But on other issues, they often actually try to do the right thing, but wind up screwing
[00:17:32.320 --> 00:17:33.560]   it up.
[00:17:33.560 --> 00:17:39.760]   And again, I can't say that's true here, but it wouldn't surprise me if somebody didn't
[00:17:39.760 --> 00:17:41.480]   properly vet this PR agency.
[00:17:41.480 --> 00:17:46.160]   I mean, I'm not saying I'm not getting Zuckerberg and Sandberg off the hook, but it wouldn't
[00:17:46.160 --> 00:17:48.480]   surprise me if they just didn't know what was going on.
[00:17:48.480 --> 00:17:55.680]   We've seen a number of articles about Facebook employees having lost.
[00:17:55.680 --> 00:17:58.400]   Let me give you the headline from the business insider.
[00:17:58.400 --> 00:18:02.240]   Facebook employees react to the latest scandal.
[00:18:02.240 --> 00:18:07.280]   Why does our company now I've got an ad in top of it?
[00:18:07.280 --> 00:18:13.360]   I guess business and cider has just put up a fence of a paywall.
[00:18:13.360 --> 00:18:14.360]   Sorry, business insider.
[00:18:14.360 --> 00:18:16.720]   I guess I won't be reading that headline.
[00:18:16.720 --> 00:18:20.400]   Why does our company seem to lack a moral compass is what it said?
[00:18:20.400 --> 00:18:21.400]   Go ahead, Georgia.
[00:18:21.400 --> 00:18:26.640]   Yeah, I think that there's just a huge need for some radical responsibility when she said
[00:18:26.640 --> 00:18:31.520]   that she didn't know what was happening in the company.
[00:18:31.520 --> 00:18:34.120]   Being unaware does not mean you're not responsible.
[00:18:34.120 --> 00:18:38.880]   So if I was unaware that my child threw a ball in the neighbor's window and broke it,
[00:18:38.880 --> 00:18:42.320]   it doesn't mean that I'm not responsible for the damage of which that does.
[00:18:42.320 --> 00:18:46.800]   So then if I continue to be unaware, if my child keeps on breaking windows for, say,
[00:18:46.800 --> 00:18:51.720]   let's say, three years, then they'd call me negligent or willfully unaware and call
[00:18:51.720 --> 00:18:53.280]   social services.
[00:18:53.280 --> 00:18:57.200]   And then when people find out that I was actually getting paid because I own a window
[00:18:57.200 --> 00:19:04.080]   repair shop and getting some of the millions of dollars, maybe there's more purposeful
[00:19:04.080 --> 00:19:08.040]   behavior in the fact that I closed my eyes and didn't really know what my kids were up
[00:19:08.040 --> 00:19:09.040]   to.
[00:19:09.040 --> 00:19:12.480]   You're supposed to be adult supervision for Mark's report.
[00:19:12.480 --> 00:19:13.480]   Well, you know what?
[00:19:13.480 --> 00:19:17.600]   I think if they both, if you run a company, you are responsible for what your company
[00:19:17.600 --> 00:19:18.600]   does.
[00:19:18.600 --> 00:19:22.560]   And you saying that I don't know means either you should not be heading the company, but
[00:19:22.560 --> 00:19:25.520]   either way, you should still pay the price and make sure that you take care of it as
[00:19:25.520 --> 00:19:26.520]   quickly as possible.
[00:19:26.520 --> 00:19:31.560]   But you can't wait for three years and then say, you know what, I really did try to take
[00:19:31.560 --> 00:19:34.480]   a lot of responsibility to make sure that that happened.
[00:19:34.480 --> 00:19:37.000]   And they didn't really even fix the problem.
[00:19:37.000 --> 00:19:38.760]   You know, it's still a problem.
[00:19:38.760 --> 00:19:40.480]   It's that the excuse is wearing thin.
[00:19:40.480 --> 00:19:42.240]   I think you know, the problems continue.
[00:19:42.240 --> 00:19:43.240]   You're right.
[00:19:43.240 --> 00:19:44.240]   The problems continue it.
[00:19:44.240 --> 00:19:47.080]   And even the whole Cambridge Analytica stuff that they should have known that.
[00:19:47.080 --> 00:19:51.880]   In fact, when they announced originally that they were putting it into having an app economy,
[00:19:51.880 --> 00:19:55.200]   I happened to be at that press conference and I asked Zuckerberg, what are you going
[00:19:55.200 --> 00:19:57.560]   to do when some of these apps started violating your policy?
[00:19:57.560 --> 00:19:59.440]   And he had no answer for that.
[00:19:59.440 --> 00:20:00.440]   And it was obvious.
[00:20:00.440 --> 00:20:01.440]   You know, it didn't.
[00:20:01.440 --> 00:20:04.440]   There was no reason why he had to wait for that crisis.
[00:20:04.440 --> 00:20:07.080]   He could have figured that out years before it happened.
[00:20:07.080 --> 00:20:08.080]   Yeah.
[00:20:08.080 --> 00:20:12.680]   This is what really gives me a lot of pause here.
[00:20:12.680 --> 00:20:14.640]   I agree with you at first.
[00:20:14.640 --> 00:20:17.120]   I was like, how could they not know that?
[00:20:17.120 --> 00:20:21.800]   But my friend Eileen Carey, she's actually done this kind of work professionally before.
[00:20:21.800 --> 00:20:23.080]   She's a really good friend.
[00:20:23.080 --> 00:20:28.960]   And she told me, and this is on Twitter, anyone can see her thread, that this kind of
[00:20:28.960 --> 00:20:34.520]   keeping the CEO and the person hired you out of the loop, that is very much by design.
[00:20:34.520 --> 00:20:36.360]   That is how you do it.
[00:20:36.360 --> 00:20:38.720]   So your fingerprints are quote unquote clean.
[00:20:38.720 --> 00:20:41.120]   So to me, I don't really.
[00:20:41.120 --> 00:20:44.040]   But that's still in the various free, right?
[00:20:44.040 --> 00:20:46.440]   And they didn't, it's not like they gave back the money.
[00:20:46.440 --> 00:20:49.080]   They didn't say, you know what, this was wrong.
[00:20:49.080 --> 00:20:52.720]   So now we're going to give back the money and try to, you know, use that money that
[00:20:52.720 --> 00:20:57.240]   we got from ill, gotten gains to be able to do something good with it.
[00:20:57.240 --> 00:20:59.560]   They're like, you know what, we're going to keep the money.
[00:20:59.560 --> 00:21:00.560]   That's all good.
[00:21:00.560 --> 00:21:02.360]   And we're going to say, I'm sorry.
[00:21:02.360 --> 00:21:03.920]   And unfortunately, it's true.
[00:21:03.920 --> 00:21:05.960]   We have very short attention spans.
[00:21:05.960 --> 00:21:10.880]   We kind of, we will grab our pitchforks and run out there until the pitchfork gets too
[00:21:10.880 --> 00:21:13.880]   heavy or there's something else that we need to pitchfork.
[00:21:13.880 --> 00:21:18.040]   And so I think that that's what they were hoping for, is that people would end up forgetting
[00:21:18.040 --> 00:21:19.800]   and then going back to Facebook.
[00:21:19.800 --> 00:21:22.560]   And if you look at Facebook's numbers, yeah, it's been dwindling.
[00:21:22.560 --> 00:21:26.440]   But it isn't the amount of people that have, you know, left Facebook that really it should
[00:21:26.440 --> 00:21:28.560]   be if they understood what was happening.
[00:21:28.560 --> 00:21:31.280]   And that makes me feel kind of bitter and angry about it.
[00:21:31.280 --> 00:21:35.920]   Let me read you, since you didn't follow this, Larry, so closely when you're in Europe.
[00:21:35.920 --> 00:21:42.280]   But let me read to you from the Thursday article in the New York Times about this firm, Definers
[00:21:42.280 --> 00:21:44.000]   Public Affairs.
[00:21:44.000 --> 00:21:48.520]   They are apparently an opposition research firm.
[00:21:48.520 --> 00:21:56.040]   They were hired in the days before Sandberg was to testify to Congress back in September.
[00:21:56.040 --> 00:22:02.680]   And they were hired pretty apparently to target the 15 members of the Senate Intelligence Committee
[00:22:02.680 --> 00:22:06.440]   that were going to question her.
[00:22:06.440 --> 00:22:11.640]   In one document circulated a reporter's definers tallied what software the 15 members of the
[00:22:11.640 --> 00:22:16.840]   Intelligence Committee used to track visitors to their Senate websites.
[00:22:16.840 --> 00:22:20.520]   This was given to the press as a way to undermine these senators.
[00:22:20.520 --> 00:22:25.640]   Another document detailed how much each senator spent on Facebook ads, how much they'd received
[00:22:25.640 --> 00:22:32.840]   in campaign donations from Facebook or other big tech companies.
[00:22:32.840 --> 00:22:41.160]   There's no way Sandberg did not know who they were hiring and what they were going to do.
[00:22:41.160 --> 00:22:42.360]   This is what they do.
[00:22:42.360 --> 00:22:44.280]   This is what Definers does.
[00:22:44.280 --> 00:22:49.040]   And for Facebook and Sandberg now to apologize and say, "Oh, that we didn't know and we fired
[00:22:49.040 --> 00:22:51.560]   them strikes me as disingenuous."
[00:22:51.560 --> 00:22:55.640]   Yeah, they're just worried about getting regulated.
[00:22:55.640 --> 00:22:59.840]   They're worried about having regulations come in and they're worried about people deleting
[00:22:59.840 --> 00:23:02.800]   Facebook because that'll deal with their bottom line.
[00:23:02.800 --> 00:23:08.960]   Mark Zuckerberg's quote in the Times, "After they fired the Definers, I understand that
[00:23:08.960 --> 00:23:12.440]   a lot of DC-type firms might do this kind of work.
[00:23:12.440 --> 00:23:17.960]   When I learned about it, I decided we don't want to be doing it."
[00:23:17.960 --> 00:23:18.960]   That just...
[00:23:18.960 --> 00:23:23.960]   I'm sorry.
[00:23:23.960 --> 00:23:26.840]   I mean, maybe he's sincere.
[00:23:26.840 --> 00:23:31.480]   I am very comfortable with severing all ties with Facebook.
[00:23:31.480 --> 00:23:37.440]   We know that 44% of people 18 to 25 in the United States now have deleted Facebook from
[00:23:37.440 --> 00:23:39.160]   their phone.
[00:23:39.160 --> 00:23:43.720]   There's very much, I think, a backlash from young people.
[00:23:43.720 --> 00:23:48.400]   Older people, I think, I don't think many people love Facebook.
[00:23:48.400 --> 00:23:52.400]   But I think older people are more reluctant to delete it because that's how they stay
[00:23:52.400 --> 00:23:55.040]   in touch with distant friends and family.
[00:23:55.040 --> 00:23:56.040]   Yeah, friends.
[00:23:56.040 --> 00:23:57.040]   Absolutely.
[00:23:57.040 --> 00:23:59.000]   There's nothing to replace it.
[00:23:59.000 --> 00:24:01.120]   But then people just go on Instagram.
[00:24:01.120 --> 00:24:03.760]   I mean, this is the exact same thing that we did with Mark Zuckerberg.
[00:24:03.760 --> 00:24:04.760]   We have to get...
[00:24:04.760 --> 00:24:05.760]   Exactly.
[00:24:05.760 --> 00:24:06.760]   Yeah.
[00:24:06.760 --> 00:24:07.760]   Everyone on to Snapchat or something.
[00:24:07.760 --> 00:24:10.200]   I don't think that's any better.
[00:24:10.200 --> 00:24:11.200]   You know what?
[00:24:11.200 --> 00:24:13.680]   Delete all social networks now.
[00:24:13.680 --> 00:24:17.200]   They're not good for us.
[00:24:17.200 --> 00:24:18.840]   No, they're horrible for us.
[00:24:18.840 --> 00:24:20.000]   They don't make us feel better.
[00:24:20.000 --> 00:24:21.840]   They don't make us feel happy.
[00:24:21.840 --> 00:24:25.640]   But they do serve a purpose of connecting people where we couldn't before.
[00:24:25.640 --> 00:24:32.320]   I think that it's just Facebook is where everyone is and because less and less will be there.
[00:24:32.320 --> 00:24:34.440]   But until that actually happens.
[00:24:34.440 --> 00:24:37.760]   Where else could I have shown a picture of me in front of the Eiffel Tower just to say,
[00:24:37.760 --> 00:24:39.080]   "I'm in Paris and you're not."
[00:24:39.080 --> 00:24:40.080]   Yeah.
[00:24:40.080 --> 00:24:41.080]   Exactly.
[00:24:41.080 --> 00:24:43.320]   You made me feel like crap.
[00:24:43.320 --> 00:24:45.000]   Exactly.
[00:24:45.000 --> 00:24:49.560]   Do you want strangers to be good for you for being on the Eiffel Tower than I guess Facebook's
[00:24:49.560 --> 00:24:50.560]   place?
[00:24:50.560 --> 00:24:53.160]   But if you want to just send it to your friends and family, the people that actually love
[00:24:53.160 --> 00:24:56.320]   you genuinely love you, I'm sure that you're back.
[00:24:56.320 --> 00:24:57.320]   I sent postcards.
[00:24:57.320 --> 00:24:58.320]   Nobody loved you.
[00:24:58.320 --> 00:25:02.240]   On our last trip, I sent postcards to make my friends and family for bed.
[00:25:02.240 --> 00:25:03.240]   So I was...
[00:25:03.240 --> 00:25:04.240]   Can you get me to stack up postcards?
[00:25:04.240 --> 00:25:07.240]   I, by the way, I sent too many postcards.
[00:25:07.240 --> 00:25:08.240]   Wow.
[00:25:08.240 --> 00:25:10.480]   But I'm going to do that from now on.
[00:25:10.480 --> 00:25:14.360]   And that was because I had killed Instagram and I wanted to share my trip with my friends.
[00:25:14.360 --> 00:25:16.240]   Did you bring a Polaroid camera or something?
[00:25:16.240 --> 00:25:17.960]   You just bought postcards a little bit.
[00:25:17.960 --> 00:25:19.160]   No, no, no.
[00:25:19.160 --> 00:25:26.240]   I used an Apple service photo card from Bill Atkinson and I just picked a picture every
[00:25:26.240 --> 00:25:31.000]   day, way too many, every day that I took.
[00:25:31.000 --> 00:25:34.720]   And then you put a postcard and you don't actually mail it.
[00:25:34.720 --> 00:25:36.440]   He mails it from Palo Alto.
[00:25:36.440 --> 00:25:39.360]   I think he don't actually mail it.
[00:25:39.360 --> 00:25:42.400]   No, look, you put a fake stamp on it.
[00:25:42.400 --> 00:25:45.400]   And then he, the service, you pay for the service.
[00:25:45.400 --> 00:25:46.920]   I wrote little blurbs.
[00:25:46.920 --> 00:25:48.000]   You pay for the service.
[00:25:48.000 --> 00:25:51.920]   It's like a buck 50 and he mails it from Palo Alto, Bill Atkinson, the guy who...
[00:25:51.920 --> 00:25:53.400]   But you have to know people's address.
[00:25:53.400 --> 00:25:55.040]   How do you know people's mailing address?
[00:25:55.040 --> 00:25:56.040]   I know.
[00:25:56.040 --> 00:25:57.040]   Why?
[00:25:57.040 --> 00:25:59.480]   You'll find nobody who listens to the show got one of these.
[00:25:59.480 --> 00:26:01.080]   I don't know your address.
[00:26:01.080 --> 00:26:02.080]   But I did...
[00:26:02.080 --> 00:26:05.160]   My daughter said, "Dad, two tips.
[00:26:05.160 --> 00:26:07.400]   Send fewer cards and make them funnier."
[00:26:07.400 --> 00:26:09.400]   How many cards did you send?
[00:26:09.400 --> 00:26:10.400]   Seventeen.
[00:26:10.400 --> 00:26:11.400]   Okay.
[00:26:11.400 --> 00:26:13.400]   She said, "Send fewer."
[00:26:13.400 --> 00:26:14.400]   Yeah.
[00:26:14.400 --> 00:26:15.400]   It was a little too many.
[00:26:15.400 --> 00:26:16.400]   Oh my goodness.
[00:26:16.400 --> 00:26:24.400]   It satisfied my urge to rub my family's nose in it.
[00:26:24.400 --> 00:26:26.200]   I honestly think...
[00:26:26.200 --> 00:26:31.880]   And the other thing I did is I kind of put more stuff on my blog because I wanted...
[00:26:31.880 --> 00:26:37.400]   So that way, if people really want to know, they go to my site and they can see stuff.
[00:26:37.400 --> 00:26:40.680]   I don't want to give Facebook any money, but I don't want to snapchat any either.
[00:26:40.680 --> 00:26:43.000]   I don't want to give any of these guys anything.
[00:26:43.000 --> 00:26:44.680]   No, it doesn't actually.
[00:26:44.680 --> 00:26:49.000]   People's life, like happiness in life does not go down if you leave Facebook or any other
[00:26:49.000 --> 00:26:50.000]   kind of social media.
[00:26:50.000 --> 00:26:51.000]   I found out.
[00:26:51.000 --> 00:26:54.560]   You actually feel better and more at peace because all those lies that kind of go around
[00:26:54.560 --> 00:26:58.080]   everyone looks great and feels great and is doing amazing things.
[00:26:58.080 --> 00:27:01.440]   So I'm actually almost done with Twitter.
[00:27:01.440 --> 00:27:05.360]   And that's my last school on social media.
[00:27:05.360 --> 00:27:07.960]   Like I tweet only every...
[00:27:07.960 --> 00:27:09.760]   I don't know.
[00:27:09.760 --> 00:27:12.000]   Once in a while, like a little tiny bit.
[00:27:12.000 --> 00:27:13.000]   And it's wonderful.
[00:27:13.000 --> 00:27:15.040]   Not even to think that I have to go and chat.
[00:27:15.040 --> 00:27:16.040]   It's great.
[00:27:16.040 --> 00:27:17.680]   I still have it.
[00:27:17.680 --> 00:27:19.680]   I killed my Twitter account or deactivated.
[00:27:19.680 --> 00:27:20.880]   Did you kill one?
[00:27:20.880 --> 00:27:21.880]   Yeah.
[00:27:21.880 --> 00:27:23.800]   But I killed Instagram, Facebook, Twitter and Tumblr.
[00:27:23.800 --> 00:27:24.800]   But I did...
[00:27:24.800 --> 00:27:27.080]   And did you delete all of your history for Twitter as well?
[00:27:27.080 --> 00:27:28.080]   I did.
[00:27:28.080 --> 00:27:29.080]   Aw.
[00:27:29.080 --> 00:27:33.240]   Well, but the service I used only went back like five years.
[00:27:33.240 --> 00:27:34.240]   There's stuff from me like...
[00:27:34.240 --> 00:27:35.240]   It's still pretty good.
[00:27:35.240 --> 00:27:36.240]   But it was good.
[00:27:36.240 --> 00:27:38.120]   It's like anything's there is really, really old.
[00:27:38.120 --> 00:27:40.920]   And eventually I'll reactivate it, delete the rest.
[00:27:40.920 --> 00:27:42.560]   But I just don't want to deal with it at all.
[00:27:42.560 --> 00:27:46.280]   What I did do is I had an account where I was just posting links.
[00:27:46.280 --> 00:27:49.640]   And I kept that alive and I deleted anything that wasn't news.
[00:27:49.640 --> 00:27:50.640]   And he followed...
[00:27:50.640 --> 00:27:53.680]   I didn't follow anybody that's not just a news organization.
[00:27:53.680 --> 00:27:57.240]   And if I do feel like I need to have...
[00:27:57.240 --> 00:28:02.280]   If something big happens, I need to be able to go and see what they're saying about it
[00:28:02.280 --> 00:28:03.280]   on Twitter.
[00:28:03.280 --> 00:28:05.400]   And that's more for my job than my personal life.
[00:28:05.400 --> 00:28:07.400]   But I rarely check it.
[00:28:07.400 --> 00:28:11.160]   But Leo, that's where I think...
[00:28:11.160 --> 00:28:15.560]   First of all, for a personal decision, anyone decides to leave Twitter and Facebook more
[00:28:15.560 --> 00:28:16.560]   power to you.
[00:28:16.560 --> 00:28:17.560]   It's a great decision.
[00:28:17.560 --> 00:28:20.760]   Like George has said, these sites are not great for you.
[00:28:20.760 --> 00:28:26.520]   But maybe, Leo, you're such a bastion in the tech industry.
[00:28:26.520 --> 00:28:30.960]   You can probably leave Twitter and it's not going to affect you as much.
[00:28:30.960 --> 00:28:34.520]   But someone's getting started today in the tech industry.
[00:28:34.520 --> 00:28:37.200]   You've got to be on these sites to network.
[00:28:37.200 --> 00:28:39.080]   You've got to be on Facebook meeting people.
[00:28:39.080 --> 00:28:41.160]   You've got to be on Twitter meeting people.
[00:28:41.160 --> 00:28:43.560]   And I think it's really hard to not do that.
[00:28:43.560 --> 00:28:45.760]   As a candidate, you probably do too, right?
[00:28:45.760 --> 00:28:46.760]   I do.
[00:28:46.760 --> 00:28:48.320]   I have to run ads on Facebook.
[00:28:48.320 --> 00:28:49.320]   I hate it.
[00:28:49.320 --> 00:28:56.240]   And in my campaign, Satdale had a really hard talk with me for 2020 after having that come
[00:28:56.240 --> 00:29:00.280]   to Jesus meeting about what went well and what went wrong.
[00:29:00.280 --> 00:29:05.200]   We have to spend more time on Facebook because 80% of people in our district have accounts
[00:29:05.200 --> 00:29:06.200]   there.
[00:29:06.200 --> 00:29:07.200]   And I put in hate.
[00:29:07.200 --> 00:29:11.680]   No, I was just going to say I hate that I'm part of the problem because I'm feeding this
[00:29:11.680 --> 00:29:12.680]   monster.
[00:29:12.680 --> 00:29:17.560]   I'm doing it to specifically regulate Facebook, which is what I'm going to do.
[00:29:17.560 --> 00:29:23.440]   But I also want to say, what really troubled me is this story troubled me.
[00:29:23.440 --> 00:29:30.080]   But what troubled me a lot more, Leo was Mike Isaac's story that came out today talking
[00:29:30.080 --> 00:29:36.000]   about Mark Zuckerberg's response to the company after this news broke.
[00:29:36.000 --> 00:29:37.200]   And it's a short article.
[00:29:37.200 --> 00:29:39.800]   I invite anyone to it to read it.
[00:29:39.800 --> 00:29:42.880]   And the points of it are really frustrating.
[00:29:42.880 --> 00:29:48.800]   It is basically Zuckerberg going on telling his employees that Facebook is the real victim
[00:29:48.800 --> 00:29:49.800]   here.
[00:29:49.800 --> 00:29:55.080]   It is emphasizing that they are going to fire anyone that talks to the press.
[00:29:55.080 --> 00:30:00.040]   It says that Facebook thinks they should just lay their heads down low and wait until things
[00:30:00.040 --> 00:30:02.920]   to blow over and people to go chase another car.
[00:30:02.920 --> 00:30:06.800]   They don't really acknowledge doing harm to our democracy.
[00:30:06.800 --> 00:30:13.080]   And their only real concern about this story is that some of their employees care, it's
[00:30:13.080 --> 00:30:15.360]   affecting their morale.
[00:30:15.360 --> 00:30:17.360]   And Georgia, I'd love to know what you think.
[00:30:17.360 --> 00:30:26.880]   But to me, this feels like this is a company that is not incentivized to change their behavior.
[00:30:26.880 --> 00:30:31.080]   And I think it's not realistic to expect anything to change.
[00:30:31.080 --> 00:30:32.400]   I think that you're absolutely right.
[00:30:32.400 --> 00:30:35.000]   I don't think that it is in their best interest to change.
[00:30:35.000 --> 00:30:36.000]   I don't think that they want to.
[00:30:36.000 --> 00:30:38.600]   I think that they're hoping that it will blow over.
[00:30:38.600 --> 00:30:42.400]   The last time that they for the Cambridge Analytica, they ended up spending a lot of
[00:30:42.400 --> 00:30:48.800]   money to donate to different politicians in hopes that they get away with not having to
[00:30:48.800 --> 00:30:52.160]   be regulated and people looking over what they're doing.
[00:30:52.160 --> 00:30:53.240]   And we need that.
[00:30:53.240 --> 00:30:57.400]   We need people to look over these companies to make sure that they're still taking care
[00:30:57.400 --> 00:30:58.400]   of the people.
[00:30:58.400 --> 00:31:01.280]   Because in the end, like I understand, Facebook's a company.
[00:31:01.280 --> 00:31:03.000]   They want to make money.
[00:31:03.000 --> 00:31:07.080]   And Zuckerberg is not known for being the most empathic and thoughtful with the way that
[00:31:07.080 --> 00:31:12.320]   he deals with his responses and the people that are there to say the least of that.
[00:31:12.320 --> 00:31:16.560]   And so without regulation, and that's what they don't want, that's what they need.
[00:31:16.560 --> 00:31:20.080]   You're right about Zuckerberg, but I know people in Facebook, and maybe that's what he's
[00:31:20.080 --> 00:31:21.080]   talking about.
[00:31:21.080 --> 00:31:26.720]   I know folks at Facebook, much lower down the food chain who really do think about these
[00:31:26.720 --> 00:31:28.640]   issues and are really bothered by these issues.
[00:31:28.640 --> 00:31:33.480]   I think if you work in Facebook today, I will say this to anybody who listens who currently
[00:31:33.480 --> 00:31:36.880]   works at Facebook, you should be looking for another job.
[00:31:36.880 --> 00:31:38.720]   You should not be working at Facebook.
[00:31:38.720 --> 00:31:41.480]   You should not be supporting this network.
[00:31:41.480 --> 00:31:43.440]   Maybe Brianna has to.
[00:31:43.440 --> 00:31:46.160]   Others have to because it's the only place they can meet family and friends.
[00:31:46.160 --> 00:31:47.960]   The only way they can run for Congress.
[00:31:47.960 --> 00:31:54.240]   But you as an employee of Facebook are not are doing the devil's work.
[00:31:54.240 --> 00:31:56.240]   You're smart enough.
[00:31:56.240 --> 00:31:59.200]   You're good enough to work somewhere ethical.
[00:31:59.200 --> 00:32:00.200]   You should do it.
[00:32:00.200 --> 00:32:01.200]   I agree.
[00:32:01.200 --> 00:32:02.880]   And Larry, I agree with you.
[00:32:02.880 --> 00:32:04.160]   There are definitely a lot of people.
[00:32:04.160 --> 00:32:08.200]   I know people that work at Facebook that are caring, thoughtful people, but that's what
[00:32:08.200 --> 00:32:09.200]   he's doing.
[00:32:09.200 --> 00:32:10.880]   He's taking the people that have voiced that they're upset.
[00:32:10.880 --> 00:32:15.680]   And instead of fixing the problem, he's saying, well, you better not get caught saying anything.
[00:32:15.680 --> 00:32:19.000]   I better not find out because they'll be held to pay for it.
[00:32:19.000 --> 00:32:22.680]   And so it's just putting pressure on people that are just trying to make a living and
[00:32:22.680 --> 00:32:24.880]   do it in a way that they can feel good about it.
[00:32:24.880 --> 00:32:28.240]   And George, I want to add something on to that.
[00:32:28.240 --> 00:32:34.360]   It's one thing if Apple's firing someone for talking about iPhone and leaking an iPhone,
[00:32:34.360 --> 00:32:37.520]   as far as I see it, that is Apple's prerogative.
[00:32:37.520 --> 00:32:44.480]   But Facebook is shipping the information that we need to run our democracy.
[00:32:44.480 --> 00:32:46.520]   This is hand in hand with government.
[00:32:46.520 --> 00:32:48.520]   It's hand in hand with news.
[00:32:48.520 --> 00:32:51.720]   And there needs to be public accountability.
[00:32:51.720 --> 00:32:57.800]   So I really feel like it's a different use case for Facebook to just be threatening anyone
[00:32:57.800 --> 00:32:59.680]   that talks to the New York Times.
[00:32:59.680 --> 00:33:04.560]   When the New York Times is reporting things that they're doing that are so harmful for
[00:33:04.560 --> 00:33:08.920]   our democracy, Leo, I completely agree with what you said.
[00:33:08.920 --> 00:33:10.700]   This is gut check time.
[00:33:10.700 --> 00:33:15.480]   This is time for everyone that looks at Facebook to look in the mirror and to ask themselves
[00:33:15.480 --> 00:33:16.720]   who they are.
[00:33:16.720 --> 00:33:18.160]   What are you supporting?
[00:33:18.160 --> 00:33:19.320]   What are you building?
[00:33:19.320 --> 00:33:20.640]   What are you empowering?
[00:33:20.640 --> 00:33:22.800]   Is this good for the world?
[00:33:22.800 --> 00:33:27.360]   And in Silicon Valley, you can go get a job in five seconds.
[00:33:27.360 --> 00:33:33.680]   This is not going to stop until people that work there choose to stop working there.
[00:33:33.680 --> 00:33:39.360]   Did you read Facebook's Republic response to the New York Times article?
[00:33:39.360 --> 00:33:42.120]   It was kind of interesting.
[00:33:42.120 --> 00:33:44.120]   Yeah, I did.
[00:33:44.120 --> 00:33:47.320]   A lot of it is just simply, no, no, no, they got it wrong.
[00:33:47.320 --> 00:33:50.920]   Actually, they didn't even say they got it wrong factually in many cases.
[00:33:50.920 --> 00:33:53.680]   They just shaded it wrong, interpreted wrong.
[00:33:53.680 --> 00:33:57.680]   This one though, I want somebody to explain this point five, Android.
[00:33:57.680 --> 00:34:02.020]   Tim Cook has consistently criticized our business model and Mark has been equally clear he
[00:34:02.020 --> 00:34:03.600]   disagrees.
[00:34:03.600 --> 00:34:08.320]   So there's been no need to employ anyone else to do this for us.
[00:34:08.320 --> 00:34:12.440]   And we've long encouraged our employees and executives to use Android because it is the
[00:34:12.440 --> 00:34:14.000]   most popular operating system.
[00:34:14.000 --> 00:34:17.280]   I think Donald Trump would say, I don't understand what that.
[00:34:17.280 --> 00:34:18.280]   What are the points?
[00:34:18.280 --> 00:34:19.280]   What are they making there?
[00:34:19.280 --> 00:34:20.280]   Makes no sense.
[00:34:20.280 --> 00:34:21.280]   I don't know.
[00:34:21.280 --> 00:34:25.280]   Not to mention that a lot of the Facebook employees I know still have iPhones.
[00:34:25.280 --> 00:34:30.520]   Are they saying don't use Apple because we don't like Tim Cook and he's our chief critic.
[00:34:30.520 --> 00:34:34.960]   And by the way, since Tim Cook is, we don't need to hire anybody with a conscience at
[00:34:34.960 --> 00:34:35.960]   our company.
[00:34:35.960 --> 00:34:38.480]   What the hell is this statement?
[00:34:38.480 --> 00:34:39.480]   Yeah.
[00:34:39.480 --> 00:34:40.600]   It's just bizarre.
[00:34:40.600 --> 00:34:44.800]   But I will say on the sex trafficking side, they have done a good job.
[00:34:44.800 --> 00:34:45.800]   I mean, that's the area.
[00:34:45.800 --> 00:34:46.800]   Wait a minute.
[00:34:46.800 --> 00:34:48.800]   You better explain that.
[00:34:48.800 --> 00:34:49.800]   Okay.
[00:34:49.800 --> 00:34:50.800]   Wait a minute.
[00:34:50.800 --> 00:34:51.800]   Slow down, buddy.
[00:34:51.800 --> 00:34:57.040]   The area that I work with Facebook and their safety advisory board is around child safety.
[00:34:57.040 --> 00:34:58.040]   Yes.
[00:34:58.040 --> 00:34:59.960]   And in that area, I think they have worked really hard.
[00:34:59.960 --> 00:35:03.800]   Now I'm not saying they're perfect, but they have done a lot to employ what's called
[00:35:03.800 --> 00:35:08.320]   photo DNA and other technologies to try to cut back on child sex trafficking.
[00:35:08.320 --> 00:35:16.760]   So I know this is, I'm not at all thinking that Facebook has an easy job because everybody
[00:35:16.760 --> 00:35:20.800]   a billion and a half, maybe two billion now people use Facebook.
[00:35:20.800 --> 00:35:26.560]   That's almost impossible to edit and control your platform.
[00:35:26.560 --> 00:35:29.600]   You know, it's, I do not envy them.
[00:35:29.600 --> 00:35:35.640]   I think in a way the difficulties they face are in the nature of their success.
[00:35:35.640 --> 00:35:38.800]   And I'd say the same thing about Twitter.
[00:35:38.800 --> 00:35:41.440]   I also think these are intractable problems.
[00:35:41.440 --> 00:35:46.720]   You're never going to get all terrorists, all sex trafficking, all anything off Facebook.
[00:35:46.720 --> 00:35:49.200]   It's too big of a challenge.
[00:35:49.200 --> 00:35:50.360]   Same thing with Twitter.
[00:35:50.360 --> 00:35:52.120]   So I don't know what the answer is.
[00:35:52.120 --> 00:35:55.240]   They hate speech is a real challenge because they're kind of up against.
[00:35:55.240 --> 00:35:58.120]   They're also up against free speech issues and trying to figure out, try to keep the
[00:35:58.120 --> 00:36:04.040]   ADL happy on one side and the ACLU happy on the other and trying to, trying to balance
[00:36:04.040 --> 00:36:05.040]   that one is difficult.
[00:36:05.040 --> 00:36:09.720]   So, you know, again, I'm not deeply ingrained in this current controversy.
[00:36:09.720 --> 00:36:14.000]   I'm not here to defend Facebook at all, but I will say in the little area that I work,
[00:36:14.000 --> 00:36:17.160]   which is the child safety area, I think they have made some progress.
[00:36:17.160 --> 00:36:20.280]   So that's about as far as like, oh, that's your area.
[00:36:20.280 --> 00:36:21.640]   You know firsthand.
[00:36:21.640 --> 00:36:24.240]   And I, you know, I admire for them.
[00:36:24.240 --> 00:36:31.040]   It'd be my guess that, I mean, basically they have the Aegean stables here and there's
[00:36:31.040 --> 00:36:34.800]   no Hercules to clean these out.
[00:36:34.800 --> 00:36:40.400]   You have a literally an insurmountable problem that is based on what you're doing and the
[00:36:40.400 --> 00:36:42.120]   success of what you're doing.
[00:36:42.120 --> 00:36:46.760]   And it would be my guess that Facebook knows this.
[00:36:46.760 --> 00:36:48.760]   They know this not fixable.
[00:36:48.760 --> 00:36:53.680]   So what they've chosen is, look, we're going to do the best we can.
[00:36:53.680 --> 00:36:57.120]   We're going to defend what we're doing as best we can and we're going to keep on doing
[00:36:57.120 --> 00:36:59.000]   what we're doing because that's the business.
[00:36:59.000 --> 00:37:03.960]   And this, and by the way, that attitude would explain everything.
[00:37:03.960 --> 00:37:07.760]   You know, the only thing that bothers me about that Leo is that it's kind of like that too
[00:37:07.760 --> 00:37:09.560]   large to fail argument.
[00:37:09.560 --> 00:37:10.560]   Oh, yeah.
[00:37:10.560 --> 00:37:14.000]   You're, you're, which I do understand, but what you're saying is that, well, you know
[00:37:14.000 --> 00:37:16.880]   what, we have too many people to be able to control it.
[00:37:16.880 --> 00:37:20.920]   And then it just makes me want to say, well, then have a smaller pool of people that are
[00:37:20.920 --> 00:37:21.920]   on Facebook.
[00:37:21.920 --> 00:37:22.920]   I kind of have a party.
[00:37:22.920 --> 00:37:26.480]   You have a party that you won't unless legislation comes down to say that, you know
[00:37:26.480 --> 00:37:30.800]   what, you're going to have to pay money towards anyone that's, you know, whatever inciting
[00:37:30.800 --> 00:37:34.320]   violence or harassment or whatever it might be.
[00:37:34.320 --> 00:37:38.200]   But you know, you have a party and it's too big to control that, you know, the violence
[00:37:38.200 --> 00:37:40.080]   that happens at your party have a smaller party.
[00:37:40.080 --> 00:37:44.960]   If not, pay the price for the people that then have to clean up the mess.
[00:37:44.960 --> 00:37:45.960]   Yeah.
[00:37:45.960 --> 00:37:47.800]   No, I think you're dead on.
[00:37:47.800 --> 00:37:52.200]   And yeah, I thought Tim Cook, he said this so perfectly the other day.
[00:37:52.200 --> 00:37:57.760]   In fact, the, the speech I give on this, I pretty much, you know, we, we look at his points
[00:37:57.760 --> 00:37:59.440]   there because it was so well said.
[00:37:59.440 --> 00:38:04.960]   Yeah, I, I am personally not a pro regulation kind of person when it comes to technology
[00:38:04.960 --> 00:38:09.960]   because I don't think Washington can keep up with the technology industry.
[00:38:09.960 --> 00:38:17.960]   But the fact is here, you know, Facebook really plays such a huge role in our democracy.
[00:38:17.960 --> 00:38:21.520]   There was Russian interference with our election.
[00:38:21.520 --> 00:38:24.160]   There's consistent misinformation.
[00:38:24.160 --> 00:38:29.920]   We've had teenagers go and commit suicide after bullying that they've gotten on this
[00:38:29.920 --> 00:38:31.400]   platform.
[00:38:31.400 --> 00:38:35.520]   You know, they are putting media organizations out of business.
[00:38:35.520 --> 00:38:41.880]   They have lied about the number of video views that things have gotten like causing industries
[00:38:41.880 --> 00:38:45.240]   to pit to pit to pivot to video.
[00:38:45.240 --> 00:38:50.280]   And then, you know, like journalists lose their jobs over the decisions Facebook makes.
[00:38:50.280 --> 00:38:56.000]   This is a company that impacts all of us in huge ways.
[00:38:56.000 --> 00:39:01.520]   And the truth is this is our country and we can regulate the things that operate here
[00:39:01.520 --> 00:39:02.800]   like Facebook.
[00:39:02.800 --> 00:39:09.240]   And if we don't get this under control, I really, I know this is a strong statement by genuinely
[00:39:09.240 --> 00:39:14.960]   believe Facebook as is currently run is the biggest threat to democracy in America.
[00:39:14.960 --> 00:39:15.960]   Yeah.
[00:39:15.960 --> 00:39:17.800]   Here's, I would say there's three paths here.
[00:39:17.800 --> 00:39:22.920]   There's the Facebook could attempt to prevent all of this.
[00:39:22.920 --> 00:39:27.200]   And that I think is impossible because it's a judgment call.
[00:39:27.200 --> 00:39:32.720]   This could be forced to do that and still impossible.
[00:39:32.720 --> 00:39:36.360]   Facebook could dissolve, disband, change its business model.
[00:39:36.360 --> 00:39:41.080]   Like Georgia says, maybe be a small little boutiquey kind of social network.
[00:39:41.080 --> 00:39:42.720]   That's not going to happen.
[00:39:42.720 --> 00:39:48.720]   So given that none of those are in any way viable, Facebook is choosing the only option
[00:39:48.720 --> 00:39:55.280]   it has, which is just as fast as you can appease government because we can't, even if they
[00:39:55.280 --> 00:40:00.800]   regulate us, we can't do it, pretend we're trying to control all this stuff, say all
[00:40:00.800 --> 00:40:03.120]   the right things whenever possible.
[00:40:03.120 --> 00:40:06.360]   But meanwhile, our business has to continue.
[00:40:06.360 --> 00:40:09.400]   So no business is going to put a nail in its own coffin.
[00:40:09.400 --> 00:40:13.240]   Leo, a few months ago, Facebook made a change in the algorithm so that what you see on your
[00:40:13.240 --> 00:40:18.840]   feed today is going to be more the friends that you interact with and less to media organizations.
[00:40:18.840 --> 00:40:21.760]   Well, actually, I think it worked in a negative way.
[00:40:21.760 --> 00:40:26.120]   I'm actually finding Facebook more boring because every time I log in, I see the same
[00:40:26.120 --> 00:40:29.920]   people, the same, sometimes the same post that I saw yesterday.
[00:40:29.920 --> 00:40:32.520]   By the way, they knew it would be more boring.
[00:40:32.520 --> 00:40:34.880]   That's why they optimized it the other way.
[00:40:34.880 --> 00:40:40.040]   They know exactly what gets your clicks and your engagement and they were doing that.
[00:40:40.040 --> 00:40:46.360]   Well, that's my point is that to some extent, by making it quote, safer, they've actually
[00:40:46.360 --> 00:40:48.320]   made it less interesting.
[00:40:48.320 --> 00:40:52.640]   And I don't know what the happy medium is or the solution is, but the fact is that people
[00:40:52.640 --> 00:40:54.360]   want to yell at each other.
[00:40:54.360 --> 00:40:56.560]   It's not Facebook didn't create trolls.
[00:40:56.560 --> 00:40:57.560]   Facebook didn't create--
[00:40:57.560 --> 00:40:59.320]   No, they just weaponized it.
[00:40:59.320 --> 00:41:01.800]   They enabled people to weaponize them.
[00:41:01.800 --> 00:41:03.440]   And believe me, there are plenty of people who are.
[00:41:03.440 --> 00:41:04.440]   And I'm not--
[00:41:04.440 --> 00:41:05.680]   They're responsible.
[00:41:05.680 --> 00:41:10.400]   If my thesis is correct, Larry, Facebook did what it did under pressure from government
[00:41:10.400 --> 00:41:12.200]   and users.
[00:41:12.200 --> 00:41:15.600]   They're going to do it until people look away and they're going to go right back to the
[00:41:15.600 --> 00:41:19.280]   way that works the best for them gets the most engagement because that's their business
[00:41:19.280 --> 00:41:20.280]   model.
[00:41:20.280 --> 00:41:26.680]   And this is my point is Facebook is going to deflect, deny, agree, do whatever it can
[00:41:26.680 --> 00:41:30.040]   to keep people from regulating it, from leaving.
[00:41:30.040 --> 00:41:33.120]   But ultimately, they know what works and they're going to keep doing what works.
[00:41:33.120 --> 00:41:34.960]   And remember, they're also diversifying.
[00:41:34.960 --> 00:41:39.060]   They're more and more people are on Instagram, on WhatsApp, and for the service, what they
[00:41:39.060 --> 00:41:44.240]   call the blue service, Facebook, that could actually dwindle at some point and not necessarily
[00:41:44.240 --> 00:41:45.240]   with a company.
[00:41:45.240 --> 00:41:46.240]   Yeah.
[00:41:46.240 --> 00:41:48.800]   Because they just want real estate on your phone.
[00:41:48.800 --> 00:41:51.440]   The phone is what it's all about, sure.
[00:41:51.440 --> 00:41:55.960]   Or maybe this portal, Russell Holly, who I love and respect said portal from Facebook,
[00:41:55.960 --> 00:41:58.400]   my favorite new way to video chat.
[00:41:58.400 --> 00:41:59.400]   Wow.
[00:41:59.400 --> 00:42:01.760]   This is where Facebook's really good.
[00:42:01.760 --> 00:42:03.960]   They're good at what they do.
[00:42:03.960 --> 00:42:06.120]   I'm not saying they're not good at what they do.
[00:42:06.120 --> 00:42:07.320]   I haven't gotten mine yet.
[00:42:07.320 --> 00:42:09.200]   I'm not that excited about it.
[00:42:09.200 --> 00:42:12.280]   I'll tell you what, I'm glad to hear you have one so I can call you.
[00:42:12.280 --> 00:42:14.480]   Well, I will have one when it comes out.
[00:42:14.480 --> 00:42:15.480]   I need to call you.
[00:42:15.480 --> 00:42:18.040]   You cannot be calling me Leo.
[00:42:18.040 --> 00:42:19.040]   I'm sorry.
[00:42:19.040 --> 00:42:21.640]   No, you're not going to put a camera that follows you around in your house.
[00:42:21.640 --> 00:42:22.640]   I will.
[00:42:22.640 --> 00:42:23.640]   I'm not going to put it.
[00:42:23.640 --> 00:42:25.640]   I think you're going to put it around.
[00:42:25.640 --> 00:42:26.640]   Yeah, it doesn't.
[00:42:26.640 --> 00:42:29.920]   I should say it doesn't follow you around, but it's a large enough.
[00:42:29.920 --> 00:42:33.440]   I probably is a this is my guess because the Meevo, which is a Facebook live streaming
[00:42:33.440 --> 00:42:35.520]   device from live stream does the same thing.
[00:42:35.520 --> 00:42:43.200]   It's a 4K video 4K sensor, but that means that they have essentially four high def locations.
[00:42:43.200 --> 00:42:49.000]   And so they can zoom in to walk around the room and they'll just continue to be in full.
[00:42:49.000 --> 00:42:50.000]   It's a wide angle.
[00:42:50.000 --> 00:42:52.280]   As long as they can see everything in the room, they can zoom to that part of the room.
[00:42:52.280 --> 00:42:54.280]   The idea is that there's a mark.
[00:42:54.280 --> 00:42:58.480]   If you're grandma watching your four year old walking around the room, you'll see that
[00:42:58.480 --> 00:43:00.880]   kid as they walk around.
[00:43:00.880 --> 00:43:01.880]   I'm not exactly.
[00:43:01.880 --> 00:43:03.440]   I don't think it's a it's a cat.
[00:43:03.440 --> 00:43:05.360]   I think they do it with software.
[00:43:05.360 --> 00:43:10.360]   Yes, it's a 4K camera that they can zoom in to a higher resolution.
[00:43:10.360 --> 00:43:14.560]   And it's always it's not on until you turn it off.
[00:43:14.560 --> 00:43:16.200]   You got a camera and a mic on it.
[00:43:16.200 --> 00:43:17.200]   We don't know if it's on.
[00:43:17.200 --> 00:43:18.920]   They say they say the lens cover.
[00:43:18.920 --> 00:43:22.320]   Yeah, they say this is their privacy thing.
[00:43:22.320 --> 00:43:24.280]   It's in the it's in the materials.
[00:43:24.280 --> 00:43:26.440]   We have a clip you can cover the camera with.
[00:43:26.440 --> 00:43:29.560]   Yeah, the microphone's still on, but we can cover the camera.
[00:43:29.560 --> 00:43:33.480]   Well, nobody's going to by the way, no, they're going to who's going to lose that clip
[00:43:33.480 --> 00:43:35.000]   within an hour.
[00:43:35.000 --> 00:43:36.000]   Right?
[00:43:36.000 --> 00:43:40.600]   Again, still masking.
[00:43:40.600 --> 00:43:42.600]   We'll work.
[00:43:42.600 --> 00:43:45.080]   I have actually a band-aid over my webcam.
[00:43:45.080 --> 00:43:46.080]   That's on my laptop.
[00:43:46.080 --> 00:43:47.080]   Little round band-aid.
[00:43:47.080 --> 00:43:49.640]   Little or a small, just a round one.
[00:43:49.640 --> 00:43:50.640]   Yeah.
[00:43:50.640 --> 00:43:51.640]   It's the beige one.
[00:43:51.640 --> 00:43:52.640]   One of those dot a dot.
[00:43:52.640 --> 00:43:53.640]   Yeah.
[00:43:53.640 --> 00:43:54.640]   One of the beige band-aids.
[00:43:54.640 --> 00:43:55.640]   A dot.
[00:43:55.640 --> 00:43:56.640]   Yeah.
[00:43:56.640 --> 00:43:57.640]   It works.
[00:43:57.640 --> 00:43:58.640]   Except for it kind of makes windows.
[00:43:58.640 --> 00:44:00.080]   Hello doesn't work if you can't.
[00:44:00.080 --> 00:44:04.800]   I don't I don't want to be and I sound like I am the you know that guy who hates Facebook.
[00:44:04.800 --> 00:44:06.400]   Yeah, yeah, yeah, yeah.
[00:44:06.400 --> 00:44:07.400]   But I do agree with you.
[00:44:07.400 --> 00:44:13.640]   It is a threat to our own psychological well-being and to our democracy.
[00:44:13.640 --> 00:44:15.280]   Yeah.
[00:44:15.280 --> 00:44:17.680]   And I don't know what the answer is.
[00:44:17.680 --> 00:44:22.400]   It ain't going away and you you may, Brianna, God willing, you're going to get in Congress
[00:44:22.400 --> 00:44:26.320]   in 2020 along with a whole bunch of other people who feel the same way and you're going
[00:44:26.320 --> 00:44:32.160]   to pass stringent privacy and laws and it ain't going to change a thing because it's a global
[00:44:32.160 --> 00:44:33.160]   operation.
[00:44:33.160 --> 00:44:35.360]   Well, at the European the path to Virginia.
[00:44:35.360 --> 00:44:36.360]   Yeah.
[00:44:36.360 --> 00:44:37.360]   They pass.
[00:44:37.360 --> 00:44:38.360]   Oh, yeah.
[00:44:38.360 --> 00:44:39.360]   How could you use Facebook in Europe, right?
[00:44:39.360 --> 00:44:40.360]   Make a difference.
[00:44:40.360 --> 00:44:41.360]   I use it.
[00:44:41.360 --> 00:44:43.680]   I it's not that you expect people to stop using it.
[00:44:43.680 --> 00:44:49.440]   It's that you know the European privacy laws have undoubtedly affected the information that
[00:44:49.440 --> 00:44:51.520]   Facebook can collect and how they can sell.
[00:44:51.520 --> 00:44:52.520]   Yeah, they have.
[00:44:52.520 --> 00:44:54.320]   No one's trying to destroy Facebook.
[00:44:54.320 --> 00:44:56.960]   We just want them to do things in a way.
[00:44:56.960 --> 00:44:57.960]   They're less destructive.
[00:44:57.960 --> 00:45:02.200]   So you think you can make safe book a safe and healthy place?
[00:45:02.200 --> 00:45:05.560]   No, I don't, but I do think we can make it.
[00:45:05.560 --> 00:45:07.560]   I think there are two factors here.
[00:45:07.560 --> 00:45:11.360]   The fact that they bought Instagram really deeply concerns me.
[00:45:11.360 --> 00:45:16.320]   It's the exact same playbook that Microsoft used in the 90s and you know, Leo, you and
[00:45:16.320 --> 00:45:17.360]   I are both old enough.
[00:45:17.360 --> 00:45:19.200]   We've seen tech giants come and go.
[00:45:19.200 --> 00:45:24.520]   We saw IBM by Red Hat, you know, last week.
[00:45:24.520 --> 00:45:27.720]   You know, IBM was what they wrote about in 2001.
[00:45:27.720 --> 00:45:28.720]   Like that was the villain.
[00:45:28.720 --> 00:45:29.720]   How?
[00:45:29.720 --> 00:45:30.720]   1984, right?
[00:45:30.720 --> 00:45:31.720]   Right.
[00:45:31.720 --> 00:45:32.720]   I'm sorry, 2000.
[00:45:32.720 --> 00:45:33.720]   Right.
[00:45:33.720 --> 00:45:38.200]   You know, the Coca-Cola, both water companies and youth companies.
[00:45:38.200 --> 00:45:39.760]   What worries me about Facebook?
[00:45:39.760 --> 00:45:46.200]   I'm sure Facebook is going to eventually fall because the exact instant there's a competitor
[00:45:46.200 --> 00:45:49.160]   I can go by to move off of it.
[00:45:49.160 --> 00:45:51.400]   And I think other people will too.
[00:45:51.400 --> 00:45:55.920]   But what concerns me is the anti-competitive behavior at the start of the show, Leo, you
[00:45:55.920 --> 00:45:58.960]   were talking about how younger people tend to not be on Facebook.
[00:45:58.960 --> 00:46:00.720]   You're right because they're on Instagram.
[00:46:00.720 --> 00:46:03.520]   That's a much higher percentage of younger people.
[00:46:03.520 --> 00:46:08.480]   Facebook, there was another very promising social media startup that my friend Taylor
[00:46:08.480 --> 00:46:12.840]   over at the Atlantic wrote about that basically loops video.
[00:46:12.840 --> 00:46:16.240]   Facebook literally just copied it and put it right out.
[00:46:16.240 --> 00:46:20.200]   So I don't worry about people moving from Facebook.
[00:46:20.200 --> 00:46:25.840]   What I do worry about is Facebook continuing their anti-competitive tactics in the social
[00:46:25.840 --> 00:46:32.640]   media space that will be impossible to escape from basically leaders with this kind of fundamentally
[00:46:32.640 --> 00:46:36.200]   morally broken compass.
[00:46:36.200 --> 00:46:38.360]   It is such an interesting conversation.
[00:46:38.360 --> 00:46:44.000]   And I just don't know what the answer is.
[00:46:44.000 --> 00:46:48.840]   And I should really, if you're going to be fair, there's all sorts of amazing success
[00:46:48.840 --> 00:46:52.560]   stories that come straight out of social media, including Facebook and Twitter.
[00:46:52.560 --> 00:46:58.640]   And there's a lot of things very positive, very good, as well as very bad because it's
[00:46:58.640 --> 00:47:00.920]   like life.
[00:47:00.920 --> 00:47:03.800]   And so it can't be all tard with the same brush.
[00:47:03.800 --> 00:47:05.760]   However, I do feel it.
[00:47:05.760 --> 00:47:07.000]   It's a little bit of a problem.
[00:47:07.000 --> 00:47:08.960]   We got to figure this out.
[00:47:08.960 --> 00:47:09.960]   We all agree on that.
[00:47:09.960 --> 00:47:11.280]   Let's take a break.
[00:47:11.280 --> 00:47:13.000]   Brianna Wu is with us.
[00:47:13.000 --> 00:47:14.000]   You know what?
[00:47:14.000 --> 00:47:17.280]   We went to your website and they've taken it down.
[00:47:17.280 --> 00:47:18.840]   They did over at Nation Builder.
[00:47:18.840 --> 00:47:19.840]   They did.
[00:47:19.840 --> 00:47:20.840]   Yeah.
[00:47:20.840 --> 00:47:23.360]   We have for Congress right now.
[00:47:23.360 --> 00:47:26.040]   I could talk a lot about Nation Builder, but I won't.
[00:47:26.040 --> 00:47:27.040]   Okay.
[00:47:27.040 --> 00:47:28.040]   So moving on.
[00:47:28.040 --> 00:47:29.040]   Yes.
[00:47:29.040 --> 00:47:30.040]   We're moving over.
[00:47:30.040 --> 00:47:31.040]   So this is funny.
[00:47:31.040 --> 00:47:35.640]   Gamer Gate, when I first announced it, they got Brianna Wu for Congress and they registered
[00:47:35.640 --> 00:47:36.640]   it before.
[00:47:36.640 --> 00:47:38.640]   Oh my God, those jerks.
[00:47:38.640 --> 00:47:41.600]   But I then they didn't do it for another year.
[00:47:41.600 --> 00:47:43.800]   So I have got all of that domain name.
[00:47:43.800 --> 00:47:47.640]   So Brianna Broufer, Senate Brianna Broufer, president.
[00:47:47.640 --> 00:47:48.640]   Just get all the rest.
[00:47:48.640 --> 00:47:51.320]   Just grab them all now.
[00:47:51.320 --> 00:47:52.320]   That's the time.
[00:47:52.320 --> 00:47:55.120]   We're working for Chief for Queen or whatever.
[00:47:55.120 --> 00:48:00.560]   And for Larry Maggots also here, he's got a website, a number of them including Connects
[00:48:00.560 --> 00:48:02.280]   Safely.org.
[00:48:02.280 --> 00:48:03.280]   And what is it?
[00:48:03.280 --> 00:48:04.280]   Larry's place.
[00:48:04.280 --> 00:48:05.280]   Larry's world.
[00:48:05.280 --> 00:48:06.280]   Larry's world.
[00:48:06.280 --> 00:48:07.280]   Larry's world.
[00:48:07.280 --> 00:48:08.280]   Don't go to Larry's place.
[00:48:08.280 --> 00:48:10.280]   No, you don't want to go to my place.
[00:48:10.280 --> 00:48:14.320]   You don't want to go to his place.
[00:48:14.320 --> 00:48:15.320]   I don't publish my address.
[00:48:15.320 --> 00:48:17.160]   I don't even want your postcards for you.
[00:48:17.160 --> 00:48:18.160]   Thank you.
[00:48:18.160 --> 00:48:22.000]   I'll just put them on my blog for you, Larry.
[00:48:22.000 --> 00:48:23.000]   That'll work.
[00:48:23.000 --> 00:48:24.800]   Pull them instead of pushing them.
[00:48:24.800 --> 00:48:28.240]   And Georgia Dow, she is @anxiety-videos.com.
[00:48:28.240 --> 00:48:31.200]   And of course, senior editor at imore.com.
[00:48:31.200 --> 00:48:38.520]   Our show today brought to you by the best present you're ever going to give friends,
[00:48:38.520 --> 00:48:41.400]   family, masterclass.
[00:48:41.400 --> 00:48:44.480]   Maybe yourself, give this to yourself.
[00:48:44.480 --> 00:48:45.480]   Masterclass.
[00:48:45.480 --> 00:48:51.840]   Now how they did it, got the biggest names in the world to teach classes on their disciplines.
[00:48:51.840 --> 00:48:59.080]   Imagine learning tennis from Serena Williams, basketball from Steph Curry, chess from Gary
[00:48:59.080 --> 00:49:02.760]   Kaspar of poker from Daniel Negrato.
[00:49:02.760 --> 00:49:05.680]   Helen Mirren teaching acting.
[00:49:05.680 --> 00:49:09.480]   My friend Steve Martin teaches you how to be funny.
[00:49:09.480 --> 00:49:15.800]   I mean, this is amazing, Frank Geary on architecture and a Libovitz on photography.
[00:49:15.800 --> 00:49:18.320]   Diane von Furstenberg on fashion.
[00:49:18.320 --> 00:49:22.240]   And incidentally, this isn't like, oh, he does a 15 minute.
[00:49:22.240 --> 00:49:28.120]   These are classes that are full, rich, beautifully shot.
[00:49:28.120 --> 00:49:32.840]   Actually, I'm going to go into my account because I can show you some of the classes
[00:49:32.840 --> 00:49:35.320]   that I'm paying attention to.
[00:49:35.320 --> 00:49:36.560]   What do you, oh, how about this one?
[00:49:36.560 --> 00:49:38.560]   Samuel L. Jackson.
[00:49:38.560 --> 00:49:40.200]   I love this one.
[00:49:40.200 --> 00:49:42.160]   Teaching acting.
[00:49:42.160 --> 00:49:46.360]   One of the things he does in this, and so let's close this out, but just so you can see,
[00:49:46.360 --> 00:49:49.880]   this is not just, this isn't, look how many lessons it is.
[00:49:49.880 --> 00:49:52.080]   This is 21 lessons.
[00:49:52.080 --> 00:49:54.000]   There's a class workbook.
[00:49:54.000 --> 00:49:56.440]   He does a Q and A, he has office hours.
[00:49:56.440 --> 00:49:59.520]   This is not, this is a real class.
[00:49:59.520 --> 00:50:03.800]   One of the things he does, which is fantastic, breaking down a script, they take a script
[00:50:03.800 --> 00:50:04.920]   from Pulp Fiction.
[00:50:04.920 --> 00:50:10.320]   They take that scene in the restaurant from Pulp Fiction, and let me turn the audio off.
[00:50:10.320 --> 00:50:16.200]   And he takes acting students and he literally goes through it with them and talks about
[00:50:16.200 --> 00:50:17.200]   motive.
[00:50:17.200 --> 00:50:20.240]   This is, you can't pay for this.
[00:50:20.240 --> 00:50:23.680]   This is the, this is like mind bogglingly good.
[00:50:23.680 --> 00:50:24.680]   It's so well shot.
[00:50:24.680 --> 00:50:29.280]   It's so well done that you're going to put it on the big screen and just enjoy it like
[00:50:29.280 --> 00:50:30.440]   a documentary.
[00:50:30.440 --> 00:50:36.920]   If it's, you know, I mean, cooking from the best chefs in the world, this is so amazing.
[00:50:36.920 --> 00:50:40.480]   There's, I can't sell you hard enough on this.
[00:50:40.480 --> 00:50:42.640]   I was going to give it to my son for Christmas.
[00:50:42.640 --> 00:50:45.800]   And he said, I already got it for myself, which is kind of a bummer.
[00:50:45.800 --> 00:50:48.280]   He's, he's an aspiring chef.
[00:50:48.280 --> 00:50:50.960]   And it has really great cooking stuff.
[00:50:50.960 --> 00:50:57.640]   Gordon Ramsey has a class, um, Alice Waters, Wolfgang Puck.
[00:50:57.640 --> 00:51:02.800]   So I mean, you're learning, cooking from the best chefs in the world.
[00:51:02.800 --> 00:51:08.640]   Martin Scorsese teaching film directing David Mamet teaching playwriting.
[00:51:08.640 --> 00:51:14.640]   I mean, oh my God, you want to learn how to lay down beats dead mouse as a class.
[00:51:14.640 --> 00:51:17.240]   I'm making music.
[00:51:17.240 --> 00:51:19.680]   I can't, I just, I just, I love this.
[00:51:19.680 --> 00:51:20.680]   And I just want you to go.
[00:51:20.680 --> 00:51:25.320]   Now we've got, of course, as always, a very good deal for you.
[00:51:25.320 --> 00:51:31.360]   If you go to masterclass.com/twit, unlock access to every masterclass for a year.
[00:51:31.360 --> 00:51:34.120]   That is one of the things I think is really important.
[00:51:34.120 --> 00:51:37.320]   When I first went there, you know, I bought one and I thought, oh, wait a minute, I went,
[00:51:37.320 --> 00:51:38.320]   oh, I want that.
[00:51:38.320 --> 00:51:39.320]   You're going to want them all.
[00:51:39.320 --> 00:51:42.760]   So unlock them all 35 world class masters.
[00:51:42.760 --> 00:51:44.320]   And it's a very low annual price.
[00:51:44.320 --> 00:51:45.320]   I think you're going to like it.
[00:51:45.320 --> 00:51:51.480]   And what a great gift masterclass.com/twit unlimited access to masterclass.
[00:51:51.480 --> 00:51:55.520]   This is, I've just solved your holiday gift giving.
[00:51:55.520 --> 00:51:58.920]   This is day one of Hanukkah and you will be famous.
[00:51:58.920 --> 00:52:06.200]   This is, this is so awesome masterclass.com/twit.
[00:52:06.200 --> 00:52:09.120]   What they need though is Brianna Wu on how to run to Congress.
[00:52:09.120 --> 00:52:10.120]   That would be a good one.
[00:52:10.120 --> 00:52:12.120]   I was thinking they'd eat you there for broadcasting.
[00:52:12.120 --> 00:52:13.920]   Oh, they never had access.
[00:52:13.920 --> 00:52:14.920]   Yeah.
[00:52:14.920 --> 00:52:15.920]   That's true.
[00:52:15.920 --> 00:52:16.920]   Or running an ad read.
[00:52:16.920 --> 00:52:17.920]   You do the best ads.
[00:52:17.920 --> 00:52:18.920]   Yeah.
[00:52:18.920 --> 00:52:19.920]   No, but it's true.
[00:52:19.920 --> 00:52:20.920]   You actually.
[00:52:20.920 --> 00:52:22.120]   No, you like read it.
[00:52:22.120 --> 00:52:25.080]   It's like you've read it for the first time and I'm like, you've probably read it like
[00:52:25.080 --> 00:52:26.080]   75 times.
[00:52:26.080 --> 00:52:27.560]   But you can't make it sound sad.
[00:52:27.560 --> 00:52:33.120]   I tell you, my secret is we only accept ads from companies that I really love.
[00:52:33.120 --> 00:52:37.720]   And so it's honest because we turn, you don't know how many advertisers we turn down every
[00:52:37.720 --> 00:52:42.840]   week because I don't want, I want to be able to read each one of these with absolute sincerity.
[00:52:42.840 --> 00:52:46.800]   And I'll tell you the other reason, which is completely self-serving.
[00:52:46.800 --> 00:52:51.640]   If you subscribe to this and you hate it, they don't send email to masterclass.
[00:52:51.640 --> 00:52:53.400]   They yell at me.
[00:52:53.400 --> 00:52:54.400]   Right?
[00:52:54.400 --> 00:52:58.920]   Because my friend Leo told me about it.
[00:52:58.920 --> 00:53:03.800]   What, you know, if your friend told you, oh, you got to, you know, you got to buy a molecule
[00:53:03.800 --> 00:53:06.040]   air pure fire so you don't breathe fire.
[00:53:06.040 --> 00:53:07.320]   And it was terrible.
[00:53:07.320 --> 00:53:08.320]   You wouldn't yell at molecule.
[00:53:08.320 --> 00:53:12.000]   You'd come to your friend Leo and say, what are you talking about this thing?
[00:53:12.000 --> 00:53:14.600]   Fortunately, we only accept good advertisers.
[00:53:14.600 --> 00:53:15.600]   Occasionally.
[00:53:15.600 --> 00:53:16.600]   Just that.
[00:53:16.600 --> 00:53:21.200]   It's like you're reading like you're reading about friends from like, whoa, I'm like,
[00:53:21.200 --> 00:53:25.000]   I've heard to give this app before and still you make it sound like a story.
[00:53:25.000 --> 00:53:26.000]   Well, it's interesting.
[00:53:26.000 --> 00:53:27.000]   You're, see?
[00:53:27.000 --> 00:53:28.000]   You think I'm acting?
[00:53:28.000 --> 00:53:29.400]   I'm not that good an actor.
[00:53:29.400 --> 00:53:32.360]   Although now that I've taken the same old Jackson class.
[00:53:32.360 --> 00:53:36.000]   I don't think that I could say it that many times and still make it sound fresh.
[00:53:36.000 --> 00:53:38.400]   So there's definitely a stop at it.
[00:53:38.400 --> 00:53:40.400]   Well, I don't know how it works with your broadcast.
[00:53:40.400 --> 00:53:45.560]   It's like I'm not allowed to do that because CBS doesn't allow me to have any relationship
[00:53:45.560 --> 00:53:46.560]   with advertisers.
[00:53:46.560 --> 00:53:50.000]   But I guess it's a different world in the podcasting.
[00:53:50.000 --> 00:53:51.360]   No, I do this on the radio.
[00:53:51.360 --> 00:53:52.360]   Are you kidding?
[00:53:52.360 --> 00:53:53.360]   Right.
[00:53:53.360 --> 00:53:59.960]   Well, did you never, did you never listen to Paul Harvey for Paul's.
[00:53:59.960 --> 00:54:02.240]   The difference is he doesn't work for the news division.
[00:54:02.240 --> 00:54:07.240]   He works for the, it's a different, depending what, for example, even on CBS.
[00:54:07.240 --> 00:54:11.280]   There are people who, who the Charles Osgood used to work for CBS radio.
[00:54:11.280 --> 00:54:12.280]   He did ask.
[00:54:12.280 --> 00:54:13.840]   But he didn't work for CBS news.
[00:54:13.840 --> 00:54:15.840]   He was the smiley man who did ads.
[00:54:15.840 --> 00:54:16.840]   Yeah.
[00:54:16.840 --> 00:54:17.840]   Paul Harvey did the best ads.
[00:54:17.840 --> 00:54:20.480]   I really, if anybody, Paul Harvey used it.
[00:54:20.480 --> 00:54:23.120]   And you know where I get my inspiration.
[00:54:23.120 --> 00:54:25.640]   Only Larry's old enough to remember Arthur Godfrey.
[00:54:25.640 --> 00:54:27.120]   Oh, Arthur Godfrey.
[00:54:27.120 --> 00:54:30.800]   But he was, he was the king of doing radio ads.
[00:54:30.800 --> 00:54:35.160]   Because the only difference is that your show isn't sponsored by a single tobacco or
[00:54:35.160 --> 00:54:36.160]   coffee company.
[00:54:36.160 --> 00:54:37.160]   They work back.
[00:54:37.160 --> 00:54:38.160]   Oh, no, we do have a coffee company.
[00:54:38.160 --> 00:54:39.160]   No tobacco.
[00:54:39.160 --> 00:54:40.160]   No, but not a single one.
[00:54:40.160 --> 00:54:42.840]   This isn't the, you know, the Folger's Hour.
[00:54:42.840 --> 00:54:47.560]   We tried, we've been trying for years to sell naming rights to the studio.
[00:54:47.560 --> 00:54:48.560]   Wow.
[00:54:48.560 --> 00:54:54.120]   And now coming to you from the Lockheed Martin studios and beautiful downtown.
[00:54:54.120 --> 00:54:56.600]   I think it was rocket, diner rocket or whatever.
[00:54:56.600 --> 00:54:57.600]   Yeah, rocket.
[00:54:57.600 --> 00:54:58.600]   Yeah.
[00:54:58.600 --> 00:54:59.600]   Oh, rocket time.
[00:54:59.600 --> 00:55:02.360]   Oh, coming to you from the Arrowjet Rocketdyne studios.
[00:55:02.360 --> 00:55:04.120]   Doesn't that sound good?
[00:55:04.120 --> 00:55:07.520]   But he's a sea level executive there.
[00:55:07.520 --> 00:55:08.520]   Just talk to the boss.
[00:55:08.520 --> 00:55:13.360]   You know, Arrowjet Rocketdyne studios and beautiful downtown Petaluma.
[00:55:13.360 --> 00:55:15.960]   Man, we could have rockets.
[00:55:15.960 --> 00:55:21.640]   It's a one of our in studio audience members works there and they make the engines for
[00:55:21.640 --> 00:55:23.480]   all the rockets like the Apollo.
[00:55:23.480 --> 00:55:26.520]   You could give away the trips to the moon.
[00:55:26.520 --> 00:55:28.600]   Oh, that'd be nice.
[00:55:28.600 --> 00:55:29.600]   That'd be nice.
[00:55:29.600 --> 00:55:31.040]   Wouldn't that be fun?
[00:55:31.040 --> 00:55:32.040]   The Rocketdyne studios.
[00:55:32.040 --> 00:55:34.680]   That has a nice ring to it.
[00:55:34.680 --> 00:55:36.600]   I like it.
[00:55:36.600 --> 00:55:39.440]   Okay, I don't know.
[00:55:39.440 --> 00:55:40.440]   Let's see.
[00:55:40.440 --> 00:55:41.440]   Let's talk about shiny things.
[00:55:41.440 --> 00:55:42.440]   We've been talking about depressing things.
[00:55:42.440 --> 00:55:43.440]   I want to talk about shiny things.
[00:55:43.440 --> 00:55:44.440]   Yes.
[00:55:44.440 --> 00:55:45.440]   Yes.
[00:55:45.440 --> 00:55:47.680]   What's your favorite shiny thing these days?
[00:55:47.680 --> 00:55:49.920]   Brianna, what are you liking these days?
[00:55:49.920 --> 00:55:52.160]   I was talking to Georgia Dow.
[00:55:52.160 --> 00:55:55.480]   Dyson put out a new hair appliance.
[00:55:55.480 --> 00:56:01.600]   It's called the Dyson air wrap and it's breaking Instagram because every woman what's one of
[00:56:01.600 --> 00:56:04.520]   these things is just absolutely magical for doing your stuff.
[00:56:04.520 --> 00:56:05.520]   This is good because.
[00:56:05.520 --> 00:56:11.680]   Okay, so last year I tried to buy Lisa the Dyson hair dryer because it's really good.
[00:56:11.680 --> 00:56:12.680]   It's cool.
[00:56:12.680 --> 00:56:13.680]   It's great.
[00:56:13.680 --> 00:56:20.040]   Three times in a row I ordered it from Dyson and then next day got an email saying we don't
[00:56:20.040 --> 00:56:21.040]   trust you.
[00:56:21.040 --> 00:56:22.880]   We're not going to sell it to you.
[00:56:22.880 --> 00:56:23.880]   Three.
[00:56:23.880 --> 00:56:26.400]   I finally just gave up and she ended up buying it for herself.
[00:56:26.400 --> 00:56:31.520]   But maybe there's a chance for me to redeem myself by getting an air wrap because she does
[00:56:31.520 --> 00:56:32.520]   do this curly thing.
[00:56:32.520 --> 00:56:34.520]   So this is better than a curler.
[00:56:34.520 --> 00:56:36.880]   Oh, it's because it uses it.
[00:56:36.880 --> 00:56:38.720]   Well, it sucks up your hair.
[00:56:38.720 --> 00:56:39.720]   It's a vacuum.
[00:56:39.720 --> 00:56:41.320]   It uses this coriander effect.
[00:56:41.320 --> 00:56:46.200]   So they have this cool Jeff and you can see it and your hair will just magically wrap all
[00:56:46.200 --> 00:56:48.160]   around the barrel and then it.
[00:56:48.160 --> 00:56:50.160]   The Coriolis effect.
[00:56:50.160 --> 00:56:53.400]   The Coriander effect test of the do with cilantro.
[00:56:53.400 --> 00:56:54.400]   That's different.
[00:56:54.400 --> 00:56:55.400]   Sorry.
[00:56:55.400 --> 00:56:56.400]   Okay.
[00:56:56.400 --> 00:56:57.400]   Yes.
[00:56:57.400 --> 00:56:58.400]   Look at this.
[00:56:58.400 --> 00:56:59.400]   Wow.
[00:56:59.400 --> 00:57:00.400]   That one's really, really does.
[00:57:00.400 --> 00:57:01.960]   That's something weird about this guy.
[00:57:01.960 --> 00:57:02.960]   Dyson.
[00:57:02.960 --> 00:57:03.960]   He's just a strange dude.
[00:57:03.960 --> 00:57:04.960]   Yeah.
[00:57:04.960 --> 00:57:05.960]   I agree with that.
[00:57:05.960 --> 00:57:06.960]   Yeah.
[00:57:06.960 --> 00:57:07.960]   Cool.
[00:57:07.960 --> 00:57:08.960]   I'm just like watching your hair do that.
[00:57:08.960 --> 00:57:14.880]   Is he like some sort of like is he like he's a pro Brexit kind of guy and was he really
[00:57:14.880 --> 00:57:20.000]   some was he really interesting opinions on to do so.
[00:57:20.000 --> 00:57:22.480]   But he's also I think he's kind of like a Tesla, right?
[00:57:22.480 --> 00:57:25.240]   He's like he's like kind of this crazy inventor.
[00:57:25.240 --> 00:57:26.240]   I don't know.
[00:57:26.240 --> 00:57:27.240]   I don't know.
[00:57:27.240 --> 00:57:32.640]   I wish and I got a lot of a lot of pushback because some people you know, you've got the
[00:57:32.640 --> 00:57:36.920]   thing in bathrooms and dry their hands and some people say, oh yeah, it's a great bacteria
[00:57:36.920 --> 00:57:37.920]   into the atmosphere.
[00:57:37.920 --> 00:57:38.920]   Close it all over the place.
[00:57:38.920 --> 00:57:39.920]   Yeah.
[00:57:39.920 --> 00:57:40.920]   Right.
[00:57:40.920 --> 00:57:41.920]   Exactly.
[00:57:41.920 --> 00:57:46.320]   Just just why not put a big thing that blows bacteria all over the I know I stopped using
[00:57:46.320 --> 00:57:47.640]   those you know what I do now.
[00:57:47.640 --> 00:57:49.240]   This is my favorite shiny thing.
[00:57:49.240 --> 00:57:54.040]   I learned this in Japan because in Japan in the men's rooms, there are no dryers.
[00:57:54.040 --> 00:57:56.240]   There are no there are no paper towels.
[00:57:56.240 --> 00:57:58.240]   Everybody's expected to carry a handkerchief.
[00:57:58.240 --> 00:58:00.000]   Oh, you bring back the handkerchief.
[00:58:00.000 --> 00:58:01.000]   Yeah.
[00:58:01.000 --> 00:58:02.320]   Well, you know, this is great.
[00:58:02.320 --> 00:58:03.320]   No trees.
[00:58:03.320 --> 00:58:04.320]   No bad.
[00:58:04.320 --> 00:58:05.800]   All the bacteria is here.
[00:58:05.800 --> 00:58:07.840]   And by the way, when it dries, it's sterile anyway.
[00:58:07.840 --> 00:58:09.240]   And you use it on the door.
[00:58:09.240 --> 00:58:11.080]   No, I use it on the door knob.
[00:58:11.080 --> 00:58:12.920]   You doorknobs that would scare me.
[00:58:12.920 --> 00:58:15.080]   Don't have that's where you're throwing the washing.
[00:58:15.080 --> 00:58:17.760]   I carry two hankies.
[00:58:17.760 --> 00:58:21.200]   One for me to use for dance or whatever.
[00:58:21.200 --> 00:58:22.200]   Yes.
[00:58:22.200 --> 00:58:27.400]   Larry's old enough to know why I care the other hand key in case a woman cries.
[00:58:27.400 --> 00:58:32.280]   Oh, I can offer her a perfectly folded starched.
[00:58:32.280 --> 00:58:33.280]   Clean.
[00:58:33.280 --> 00:58:37.440]   See, if somebody near me is crying and it could be a guy, you don't want to pull this out
[00:58:37.440 --> 00:58:38.440]   of your pocket.
[00:58:38.440 --> 00:58:39.440]   Say here, blow your nose.
[00:58:39.440 --> 00:58:40.440]   I always thought they were so gross, actually.
[00:58:40.440 --> 00:58:41.440]   Yeah.
[00:58:41.440 --> 00:58:44.280]   So I have a second one that's I don't actually have it with me.
[00:58:44.280 --> 00:58:46.360]   I've already given it to a damsel in distress.
[00:58:46.360 --> 00:58:48.000]   And by the way, that's the other thing you do.
[00:58:48.000 --> 00:58:49.000]   These are cheap.
[00:58:49.000 --> 00:58:50.480]   Hankerchiefs are like a buck.
[00:58:50.480 --> 00:58:54.800]   So I buy 24 at a time and you sit, please.
[00:58:54.800 --> 00:58:57.280]   And then when she tries to give it back, she said, no, no, keep it.
[00:58:57.280 --> 00:58:59.280]   I don't want your stuff.
[00:58:59.280 --> 00:59:00.280]   So gallant.
[00:59:00.280 --> 00:59:01.280]   Oh my goodness.
[00:59:01.280 --> 00:59:06.280]   It's like a little, a little L. You need to have like an anagram.
[00:59:06.280 --> 00:59:07.280]   My phone number.
[00:59:07.280 --> 00:59:08.280]   Yeah, that's a great.
[00:59:08.280 --> 00:59:09.280]   Your phone.
[00:59:09.280 --> 00:59:10.280]   No, not.
[00:59:10.280 --> 00:59:11.280]   No.
[00:59:11.280 --> 00:59:12.280]   That's not.
[00:59:12.280 --> 00:59:13.280]   No.
[00:59:13.280 --> 00:59:14.280]   Happily married.
[00:59:14.280 --> 00:59:15.280]   I would never.
[00:59:15.280 --> 00:59:17.280]   No, don't do that.
[00:59:17.280 --> 00:59:19.280]   But single guys, you might want to consider that.
[00:59:19.280 --> 00:59:20.280]   That's just a thought.
[00:59:20.280 --> 00:59:23.280]   One of my new shiny things is so this is not new.
[00:59:23.280 --> 00:59:26.680]   Well, this is a new laptop, but tile, you know, that I lose things, right?
[00:59:26.680 --> 00:59:27.680]   Yeah.
[00:59:27.680 --> 00:59:28.680]   And the new tile, see if I get to work.
[00:59:28.680 --> 00:59:29.680]   They're really loud now.
[00:59:29.680 --> 00:59:30.680]   Oh, great.
[00:59:30.680 --> 00:59:31.680]   There we go.
[00:59:31.680 --> 00:59:32.680]   Geez, wait.
[00:59:32.680 --> 00:59:37.680]   And so everybody in the listening audience thinks their tile just went on.
[00:59:37.680 --> 00:59:39.480]   No, but they, their new ones are a lot.
[00:59:39.480 --> 00:59:43.280]   So actually, and they have a bigger, like a 300 meter or a 300 foot range.
[00:59:43.280 --> 00:59:46.880]   So I'm actually, because for the longest time I had a tile and I could, it never worked.
[00:59:46.880 --> 00:59:47.880]   I go off.
[00:59:47.880 --> 00:59:52.080]   So here's, here's, here's, this is an example of an advertiser that we stopped doing ads
[00:59:52.080 --> 00:59:53.080]   for.
[00:59:53.080 --> 00:59:54.080]   That was tracker.
[00:59:54.080 --> 00:59:55.080]   They're computer competition.
[00:59:55.080 --> 00:59:56.280]   Oh, they have a new one coming out though.
[00:59:56.280 --> 00:59:59.920]   I liked tracker because unlike tile, you could change the battery and I thought it was
[00:59:59.920 --> 01:00:00.920]   more eco friendly.
[01:00:00.920 --> 01:00:04.400]   So tiles changed that, which is good.
[01:00:04.400 --> 01:00:09.560]   And then tracker, I felt like they couldn't, they were having technical difficulties.
[01:00:09.560 --> 01:00:13.200]   So we don't have any lunch with our CEO next week and I'll, which you'll let me know.
[01:00:13.200 --> 01:00:14.520]   Yeah, they're showing new products.
[01:00:14.520 --> 01:00:16.280]   I have no idea what they're like.
[01:00:16.280 --> 01:00:18.120]   But I'll let you know.
[01:00:18.120 --> 01:00:24.000]   I have it on my dog, a tile because I was worried about losing my little shit because
[01:00:24.000 --> 01:00:26.960]   she's, she's very cute, but she's not that intelligent.
[01:00:26.960 --> 01:00:32.120]   But when we did lose her once, we couldn't find her at all with the tile.
[01:00:32.120 --> 01:00:34.920]   And then when we found her, she wasn't in the distance.
[01:00:34.920 --> 01:00:35.920]   Yeah.
[01:00:35.920 --> 01:00:37.720]   So she was in our backyard.
[01:00:37.720 --> 01:00:41.880]   She was like within 30 feet and the tile did not find her at all.
[01:00:41.880 --> 01:00:45.280]   Also, you could definitely her if you turned on the alarm.
[01:00:45.280 --> 01:00:46.280]   Right.
[01:00:46.280 --> 01:00:50.800]   Well, there is a, you could get this AKC tracking device for your dog, but the problem
[01:00:50.800 --> 01:00:55.320]   is you've got to charge the caller every 24 or 48 hours and who's going to take the
[01:00:55.320 --> 01:00:59.280]   caller off their dog and put it on a charger every 40.
[01:00:59.280 --> 01:01:02.680]   So I actually had it on my dog for about a week and I realized it was, the battery was
[01:01:02.680 --> 01:01:04.680]   dead and it wasn't doing them any good.
[01:01:04.680 --> 01:01:05.880]   So I took it off.
[01:01:05.880 --> 01:01:08.880]   I have both a tile and a tracker on my back.
[01:01:08.880 --> 01:01:09.880]   Yeah.
[01:01:09.880 --> 01:01:10.880]   And your dog, not in your dog.
[01:01:10.880 --> 01:01:12.200]   It's like belt and suspenders.
[01:01:12.200 --> 01:01:13.200]   You can't go in.
[01:01:13.200 --> 01:01:14.200]   One of them will work.
[01:01:14.200 --> 01:01:15.440]   I actually put one on my passport last year.
[01:01:15.440 --> 01:01:16.920]   I taped it to my passport.
[01:01:16.920 --> 01:01:17.920]   They're too sick for that.
[01:01:17.920 --> 01:01:18.920]   That's a good idea.
[01:01:18.920 --> 01:01:22.800]   But I feel like we're getting close enough that where you could have these miniaturized
[01:01:22.800 --> 01:01:25.000]   and they could be in the actual family.
[01:01:25.000 --> 01:01:26.000]   They should be embedded.
[01:01:26.000 --> 01:01:29.400]   They should actually be every laptop should have them built in.
[01:01:29.400 --> 01:01:31.080]   They should just automatically be there.
[01:01:31.080 --> 01:01:34.160]   And every phone should too, because the problem with your phone is when the phone battery
[01:01:34.160 --> 01:01:40.080]   dies, you know, you can use Android or Apple have a fine my phone apps, but if the battery
[01:01:40.080 --> 01:01:44.240]   is dead or the phone that arranged, you'll never find it.
[01:01:44.240 --> 01:01:47.200]   So it has a separate tile built in there.
[01:01:47.200 --> 01:01:54.000]   There used to be, I guess there still is a laptop, any theft thing called LoJack.
[01:01:54.000 --> 01:01:55.000]   Oh, Jack.
[01:01:55.000 --> 01:01:56.000]   Yeah.
[01:01:56.000 --> 01:01:57.000]   For tried that.
[01:01:57.000 --> 01:01:58.000]   Well, don't.
[01:01:58.000 --> 01:02:00.200]   Because they're not a sponsor anymore.
[01:02:00.200 --> 01:02:05.400]   No, they've been hijacked by Fancy Bear, the Russian hack.
[01:02:05.400 --> 01:02:13.200]   And there's actually a LoJack virus that will phone the Kremlin instead of home.
[01:02:13.200 --> 01:02:14.200]   Wow.
[01:02:14.200 --> 01:02:15.200]   Uh huh.
[01:02:15.200 --> 01:02:16.200]   Yeah.
[01:02:16.200 --> 01:02:23.800]   This is, this is, this story comes from last May, but in fact, I think there was a additional
[01:02:23.800 --> 01:02:26.000]   security weakness was discovered fairly recently.
[01:02:26.000 --> 01:02:28.720]   We were talking about it on security now.
[01:02:28.720 --> 01:02:30.080]   What's your shiny Georgia Dow?
[01:02:30.080 --> 01:02:32.480]   I'm going to make this a part of the show from now on.
[01:02:32.480 --> 01:02:35.400]   I'm really excited about this because we just got it.
[01:02:35.400 --> 01:02:36.400]   And I was so excited.
[01:02:36.400 --> 01:02:42.040]   My son actually put money towards this because he wanted us to get the high end version.
[01:02:42.040 --> 01:02:46.000]   So we have a Lilo Musso ice cream maker.
[01:02:46.000 --> 01:02:47.000]   Oh, yes.
[01:02:47.000 --> 01:02:51.560]   This sounds almost as bad as the roadi-matic.
[01:02:51.560 --> 01:02:53.760]   This is the top of the line.
[01:02:53.760 --> 01:02:59.800]   If you want ice cream that is like, you know, at a high end ice cream store, this is the
[01:02:59.800 --> 01:03:00.800]   ice cream maker.
[01:03:00.800 --> 01:03:03.200]   This would be such a bad thing to read to have.
[01:03:03.200 --> 01:03:04.200]   Oh, wow.
[01:03:04.200 --> 01:03:05.200]   So seriously.
[01:03:05.200 --> 01:03:07.200]   So you have to eat a lot of ice cream to justify that.
[01:03:07.200 --> 01:03:11.280]   Oh, no, no, you're not buying this to justify the cost to save money on ice cream.
[01:03:11.280 --> 01:03:12.280]   That's the first thing.
[01:03:12.280 --> 01:03:13.280]   Okay.
[01:03:13.280 --> 01:03:14.280]   This is not saving you money.
[01:03:14.280 --> 01:03:15.440]   You're not saving any money.
[01:03:15.440 --> 01:03:17.040]   You'd have to eat a lot of ice cream.
[01:03:17.040 --> 01:03:19.280]   I don't think anyone can eat that much ice cream.
[01:03:19.280 --> 01:03:22.840]   But it is like I like high end ice cream.
[01:03:22.840 --> 01:03:26.240]   And I love the fact that after we have supper, I already have the ice.
[01:03:26.240 --> 01:03:27.680]   It chills itself.
[01:03:27.680 --> 01:03:29.840]   It's easy to clean.
[01:03:29.840 --> 01:03:31.840]   It mixes it so there's no ice crystals.
[01:03:31.840 --> 01:03:35.640]   Like the mouth feel is like smooth, soft, amazing.
[01:03:35.640 --> 01:03:41.800]   And it will make gelato ice cream, French custard ice cream, sore base.
[01:03:41.800 --> 01:03:45.280]   And in like 30 minutes, it is done.
[01:03:45.280 --> 01:03:47.760]   Georgie, you're living the life.
[01:03:47.760 --> 01:03:49.800]   She will tell you this on the show.
[01:03:49.800 --> 01:03:54.800]   She got her house has a she buoyed a VR room in her house.
[01:03:54.800 --> 01:03:57.440]   One for a whole VR room.
[01:03:57.440 --> 01:04:01.200]   She got a whole other house to get a big VR room.
[01:04:01.200 --> 01:04:03.480]   And now you're just seeing a VR all day.
[01:04:03.480 --> 01:04:05.800]   You have three VR rooms.
[01:04:05.800 --> 01:04:10.440]   We have three spots for the VR action right now.
[01:04:10.440 --> 01:04:12.520]   Right now they're all playing VR.
[01:04:12.520 --> 01:04:16.160]   My two boys and my husband are playing VR because there's a new in rec room.
[01:04:16.160 --> 01:04:18.640]   There's a new quest that they're doing.
[01:04:18.640 --> 01:04:21.880]   And I've been playing Carnage Chronicles Brie.
[01:04:21.880 --> 01:04:24.440]   You and Frank have like Carnage Chronicles together.
[01:04:24.440 --> 01:04:26.360]   It is the best game.
[01:04:26.360 --> 01:04:27.360]   Huge shout out.
[01:04:27.360 --> 01:04:31.840]   It's an alpha and it's one of the best games I've played because you can play together.
[01:04:31.840 --> 01:04:32.840]   I'm the archer.
[01:04:32.840 --> 01:04:34.880]   My husband's like the night.
[01:04:34.880 --> 01:04:38.160]   We run out there, fight bad guys, get treasure, run back.
[01:04:38.160 --> 01:04:40.240]   It is absolutely amazing.
[01:04:40.240 --> 01:04:42.120]   But like life is to have fun.
[01:04:42.120 --> 01:04:45.360]   Then when you're done, you go out and you have homemade ice cream.
[01:04:45.360 --> 01:04:48.080]   I've already eaten my ice cream for today.
[01:04:48.080 --> 01:04:50.040]   I had a delicious salt chocolate.
[01:04:50.040 --> 01:04:51.040]   How do you know?
[01:04:51.040 --> 01:04:52.040]   800 pounds.
[01:04:52.040 --> 01:04:54.040]   And Justin Trudeau is our president.
[01:04:54.040 --> 01:04:55.040]   Oh my God.
[01:04:55.040 --> 01:04:56.040]   It's not fair.
[01:04:56.040 --> 01:04:57.040]   And pot is legal.
[01:04:57.040 --> 01:04:58.040]   All right.
[01:04:58.040 --> 01:05:00.280]   We'll pot legal here too.
[01:05:00.280 --> 01:05:03.280]   So I've got the next thing you guys should buy.
[01:05:03.280 --> 01:05:04.280]   Ooh.
[01:05:04.280 --> 01:05:05.280]   We've talked about another shows.
[01:05:05.280 --> 01:05:08.440]   I apologize if you watch all of our shows and you know, already know about the roadie
[01:05:08.440 --> 01:05:10.280]   madic.
[01:05:10.280 --> 01:05:12.400]   This is a, you know what a roadie is?
[01:05:12.400 --> 01:05:14.480]   Those flat breads, those Indian breads.
[01:05:14.480 --> 01:05:15.480]   Oh yeah.
[01:05:15.480 --> 01:05:16.480]   I love those.
[01:05:16.480 --> 01:05:17.480]   Yeah.
[01:05:17.480 --> 01:05:18.480]   I love them too.
[01:05:18.480 --> 01:05:19.480]   Wow.
[01:05:19.480 --> 01:05:20.480]   You don't make your own.
[01:05:20.480 --> 01:05:25.640]   All you add is you put flour, water and whatever ingredients in the hopper and then
[01:05:25.640 --> 01:05:27.160]   it cranks them out.
[01:05:27.160 --> 01:05:28.160]   Wow.
[01:05:28.160 --> 01:05:29.160]   It's a, I love those.
[01:05:29.160 --> 01:05:30.160]   Yeah.
[01:05:30.160 --> 01:05:31.160]   It's, yeah.
[01:05:31.160 --> 01:05:32.160]   I want one too.
[01:05:32.160 --> 01:05:34.360]   And if I got that in the ice cream machine, I'd never come to work.
[01:05:34.360 --> 01:05:36.360]   You'd have to try to make ice cream bread.
[01:05:36.360 --> 01:05:37.360]   Oh my goodness.
[01:05:37.360 --> 01:05:38.360]   Look at that.
[01:05:38.360 --> 01:05:39.360]   It sounds like fun.
[01:05:39.360 --> 01:05:40.360]   I have a flat bread.
[01:05:40.360 --> 01:05:41.360]   I have a roadie madic.
[01:05:41.360 --> 01:05:42.360]   Oh, you're still in order.
[01:05:42.360 --> 01:05:43.360]   What have I done?
[01:05:43.360 --> 01:05:44.720]   It's a thousand dollars.
[01:05:44.720 --> 01:05:46.040]   You don't want it, Jeff.
[01:05:46.040 --> 01:05:48.600]   I'm, I imagine crank.
[01:05:48.600 --> 01:05:53.240]   See, we, I, I asked, I asked my wife if we could get one for the studio because I know
[01:05:53.240 --> 01:05:54.240]   if I had it at home.
[01:05:54.240 --> 01:05:55.240]   That's, that's, that's.
[01:05:55.240 --> 01:05:57.080]   Here's a little boy making.
[01:05:57.080 --> 01:05:58.080]   Yes.
[01:05:58.080 --> 01:06:01.800]   The studio would be a good idea because people could have little tiny pizzas.
[01:06:01.800 --> 01:06:02.800]   Yes.
[01:06:02.800 --> 01:06:05.800]   It looks large though for like a unit.
[01:06:05.800 --> 01:06:06.800]   It's very big.
[01:06:06.800 --> 01:06:07.800]   Yeah.
[01:06:07.800 --> 01:06:12.800]   So, Carson's really lobbying for this.
[01:06:12.800 --> 01:06:13.800]   Really?
[01:06:13.800 --> 01:06:15.800]   Oh, Carson, I'm not with him.
[01:06:15.800 --> 01:06:17.720]   Carson should have this.
[01:06:17.720 --> 01:06:18.720]   And the ice cream maker.
[01:06:18.720 --> 01:06:19.720]   Yeah.
[01:06:19.720 --> 01:06:24.800]   We have not one, not two, not three, but four different coffee makers.
[01:06:24.800 --> 01:06:27.720]   Some people want kurig.
[01:06:27.720 --> 01:06:29.920]   Some people want espresso.
[01:06:29.920 --> 01:06:33.720]   Some people want ili automatic espresso.
[01:06:33.720 --> 01:06:36.720]   Some people want just plain old brew coffee.
[01:06:36.720 --> 01:06:40.520]   So we have all four of those.
[01:06:40.520 --> 01:06:42.560]   And now roadie and ice cream.
[01:06:42.560 --> 01:06:44.880]   Nobody will ever leave the, oh, wait a minute.
[01:06:44.880 --> 01:06:45.880]   That's a good idea.
[01:06:45.880 --> 01:06:48.120]   Ice cream in the coffee.
[01:06:48.120 --> 01:06:51.520]   You can have it in your office or at your home.
[01:06:51.520 --> 01:06:52.520]   Yeah.
[01:06:52.520 --> 01:06:53.520]   It's like Google, right?
[01:06:53.520 --> 01:06:55.480]   You just feed your employees and your relief.
[01:06:55.480 --> 01:07:00.160]   I was talking to, I was talking to somebody yesterday, Asha, who said it's, it's hell working
[01:07:00.160 --> 01:07:03.320]   in a startup because startups, that's the whole thing.
[01:07:03.320 --> 01:07:05.640]   You know, you put Mountain Dew in the fridge.
[01:07:05.640 --> 01:07:07.440]   You put M&Ms in a char.
[01:07:07.440 --> 01:07:09.720]   You keep it, you keep them loaded up.
[01:07:09.720 --> 01:07:13.160]   Keep them high on sugar and caffeine.
[01:07:13.160 --> 01:07:14.160]   And they just work harder.
[01:07:14.160 --> 01:07:15.160]   Right.
[01:07:15.160 --> 01:07:17.960]   You never let them leave.
[01:07:17.960 --> 01:07:22.560]   So somebody's saying the roadie maker is just basically a big boy, easy bake oven.
[01:07:22.560 --> 01:07:24.200]   That's a good thing.
[01:07:24.200 --> 01:07:25.200]   Yeah.
[01:07:25.200 --> 01:07:27.600]   I'm so really excited that's grown up a little bit.
[01:07:27.600 --> 01:07:29.400]   How hard it is to bake the meal.
[01:07:29.400 --> 01:07:30.400]   Fashion way.
[01:07:30.400 --> 01:07:31.400]   I mean, the people need to be a sheep.
[01:07:31.400 --> 01:07:32.400]   But it's hard.
[01:07:32.400 --> 01:07:37.440]   Because you have to do the dough, you need it, you have to let it rise, then you make a
[01:07:37.440 --> 01:07:39.600]   little thing and then you cook in a frying pan.
[01:07:39.600 --> 01:07:41.760]   It's hard to get it to puff up perfectly.
[01:07:41.760 --> 01:07:44.760]   It's work and it, you know, it's a little bit of butter.
[01:07:44.760 --> 01:07:46.160]   Oh, a lot of butter.
[01:07:46.160 --> 01:07:49.280]   Gee, I use gee for real authenticity.
[01:07:49.280 --> 01:07:54.720]   But, and it's delicious, but it's hard to get them really fluffy and light.
[01:07:54.720 --> 01:07:57.520]   Okay, let's take a break.
[01:07:57.520 --> 01:08:02.360]   I'm just, I haven't, I just thought it was a break.
[01:08:02.360 --> 01:08:03.640]   So those were our, you know what?
[01:08:03.640 --> 01:08:05.040]   That's a new segment.
[01:08:05.040 --> 01:08:06.040]   I like it.
[01:08:06.040 --> 01:08:08.040]   A shiny time because we have to cheer up.
[01:08:08.040 --> 01:08:10.200]   Sometimes the tech news is depressing.
[01:08:10.200 --> 01:08:12.760]   We'll just take a moment for shiny time.
[01:08:12.760 --> 01:08:15.080]   It becomes an expensive segment though.
[01:08:15.080 --> 01:08:16.080]   It is.
[01:08:16.080 --> 01:08:17.080]   It's very expensive.
[01:08:17.080 --> 01:08:18.080]   Yeah, really.
[01:08:18.080 --> 01:08:20.640]   I've spent $1,700 just watching the same.
[01:08:20.640 --> 01:08:21.920]   Rice, cream and roadies.
[01:08:21.920 --> 01:08:22.920]   Oh, Lord.
[01:08:22.920 --> 01:08:25.120]   Don't forget the Dyson.
[01:08:25.120 --> 01:08:26.120]   And the Dyson.
[01:08:26.120 --> 01:08:27.120]   Can my hair?
[01:08:27.120 --> 01:08:28.120]   It will do me a good?
[01:08:28.120 --> 01:08:29.120]   Yeah, a little bit of curls.
[01:08:29.120 --> 01:08:30.120]   Oh, I got a lot of curls.
[01:08:30.120 --> 01:08:31.120]   Look how curly he is.
[01:08:31.120 --> 01:08:32.120]   He's already curly.
[01:08:32.120 --> 01:08:34.320]   Somebody yesterday literally told me I look like Einstein.
[01:08:34.320 --> 01:08:35.560]   I wasn't sure if that was a compliment.
[01:08:35.560 --> 01:08:38.200]   If you could have it a little longer, you would look like Einstein.
[01:08:38.200 --> 01:08:39.200]   Yeah.
[01:08:39.200 --> 01:08:43.440]   You need to grow it out a little bit more and that can be your next year's Halloween outfit.
[01:08:43.440 --> 01:08:44.440]   Yeah.
[01:08:44.440 --> 01:08:45.440]   Yeah, every day.
[01:08:45.440 --> 01:08:49.840]   Every day is Halloween in Einstein land.
[01:08:49.840 --> 01:08:53.240]   We had a, this has been a fun show, but this whole week has been fun.
[01:08:53.240 --> 01:08:56.920]   That's why we made this little video for your edutainment watch.
[01:08:56.920 --> 01:08:59.160]   Previously on Twitter.
[01:08:59.160 --> 01:09:02.080]   So mom, we thought we'd have you on kind of a, it's a hot spot.
[01:09:02.080 --> 01:09:04.080]   It's a holiday tradition, right?
[01:09:04.080 --> 01:09:07.400]   I was getting some before the show, some cooking advice for Thanksgiving.
[01:09:07.400 --> 01:09:08.400]   We're doing some guilt.
[01:09:08.400 --> 01:09:09.400]   Some guilt?
[01:09:09.400 --> 01:09:10.400]   Some guilt.
[01:09:10.400 --> 01:09:11.400]   I'm not visiting.
[01:09:11.400 --> 01:09:12.400]   What kind of guilt?
[01:09:12.400 --> 01:09:13.400]   We're not calling your mother.
[01:09:13.400 --> 01:09:15.640]   Yeah, that kind of guilt.
[01:09:15.640 --> 01:09:16.640]   Tech news weekly.
[01:09:16.640 --> 01:09:19.880]   Is there a helper robot on your holiday wish list this year?
[01:09:19.880 --> 01:09:21.480]   If there isn't, why not?
[01:09:21.480 --> 01:09:25.600]   And if there is, might I recommend the onky vector robot?
[01:09:25.600 --> 01:09:26.600]   Hey, vector.
[01:09:26.600 --> 01:09:29.600]   Give me a fist bump.
[01:09:29.600 --> 01:09:30.600]   Oh.
[01:09:30.600 --> 01:09:37.440]   Oh my god.
[01:09:37.440 --> 01:09:38.440]   The new screen savers.
[01:09:38.440 --> 01:09:41.520]   What we're going to do from now through the end of the year is we're going to do gift
[01:09:41.520 --> 01:09:47.280]   guides every single episode and various hosts and I will bring in our favorite little toys
[01:09:47.280 --> 01:09:49.680]   and tricks and things you might want to think of as for a gift.
[01:09:49.680 --> 01:09:51.760]   And Alex does a lot of cooking, so you brought in a lot of cooking.
[01:09:51.760 --> 01:09:53.240]   But there's some other stuff in there too.
[01:09:53.240 --> 01:09:54.240]   Yeah.
[01:09:54.240 --> 01:09:55.880]   This is the Amazon basics microwave computer.
[01:09:55.880 --> 01:09:56.880]   You can change it.
[01:09:56.880 --> 01:09:58.680]   Microwave for two minutes.
[01:09:58.680 --> 01:10:00.480]   There you go.
[01:10:00.480 --> 01:10:01.480]   To it.
[01:10:01.480 --> 01:10:06.000]   It's what's for breakfast.
[01:10:06.000 --> 01:10:10.560]   Computer, stop microwave.
[01:10:10.560 --> 01:10:11.720]   That's pretty slick.
[01:10:11.720 --> 01:10:12.720]   I do like that.
[01:10:12.720 --> 01:10:13.720]   Yeah.
[01:10:13.720 --> 01:10:16.560]   Now I wish it would know that the corn has popped and started off.
[01:10:16.560 --> 01:10:17.560]   Right.
[01:10:17.560 --> 01:10:21.320]   Oh, that'd be cool if the microphone could listen to popping.
[01:10:21.320 --> 01:10:23.920]   Seems like an easy algorithm, says John.
[01:10:23.920 --> 01:10:25.720]   I do that in my sleep.
[01:10:25.720 --> 01:10:27.760]   I'm not a problem at all.
[01:10:27.760 --> 01:10:34.280]   My Amazon basic microwave arrived while I was in Paris and I just plugged it in last night.
[01:10:34.280 --> 01:10:36.520]   And I had about three seconds of fun playing with it.
[01:10:36.520 --> 01:10:40.000]   And now I'm trying to figure out why it's any better than the microwave that I bought
[01:10:40.000 --> 01:10:41.000]   ten years ago.
[01:10:41.000 --> 01:10:42.000]   It isn't.
[01:10:42.000 --> 01:10:43.000]   It's because you can talk to it.
[01:10:43.000 --> 01:10:45.320]   Yeah, but why do you want to talk to him?
[01:10:45.320 --> 01:10:49.160]   I mean, oh, really, I guess for things like pop, reheating a cup of coffee, it figured
[01:10:49.160 --> 01:10:50.160]   out how much time you can.
[01:10:50.160 --> 01:10:54.240]   It was kind of a pain because with the popcorn, we said make popcorn and said, okay, how many
[01:10:54.240 --> 01:10:55.640]   ounces is the popcorn?
[01:10:55.640 --> 01:10:56.640]   I don't know.
[01:10:56.640 --> 01:10:57.640]   Two and a half ounces.
[01:10:57.640 --> 01:10:58.640]   I tried to sell you the popcorn.
[01:10:58.640 --> 01:11:00.560]   And then it says, how long would you like to cook it?
[01:11:00.560 --> 01:11:02.280]   And then it tries to sell you popcorn.
[01:11:02.280 --> 01:11:03.280]   Exactly.
[01:11:03.280 --> 01:11:04.280]   It doesn't try to sell you.
[01:11:04.280 --> 01:11:05.280]   No, it does.
[01:11:05.280 --> 01:11:06.280]   No, no, no.
[01:11:06.280 --> 01:11:08.880]   The app actually recommended that I buy a certain kind of popcorn.
[01:11:08.880 --> 01:11:13.360]   And it'll automatically, it'll automatically renew the popcorn.
[01:11:13.360 --> 01:11:17.120]   Maybe it actually knows how much popcorn I'm eating and we'll say, oh, Larry, you're running
[01:11:17.120 --> 01:11:18.120]   out.
[01:11:18.120 --> 01:11:19.120]   That's interesting.
[01:11:19.120 --> 01:11:20.120]   They could.
[01:11:20.120 --> 01:11:24.120]   I was just sitting here thinking, how could that's a product I would have my home.
[01:11:24.120 --> 01:11:28.760]   Everyone can't monetize the amount of time it takes to reheat a cup of coffee.
[01:11:28.760 --> 01:11:29.760]   Yes, they can.
[01:11:29.760 --> 01:11:31.840]   And then you made it weird.
[01:11:31.840 --> 01:11:34.360]   Never underestimate the power of the Bezos.
[01:11:34.360 --> 01:11:35.360]   Yeah.
[01:11:35.360 --> 01:11:37.200]   So, yeah, I want that onky robot.
[01:11:37.200 --> 01:11:38.200]   That is the truth.
[01:11:38.200 --> 01:11:39.200]   I know.
[01:11:39.200 --> 01:11:40.200]   I want him.
[01:11:40.200 --> 01:11:43.760]   I think I might be getting him for one of my children for the holidays.
[01:11:43.760 --> 01:11:44.760]   Yeah.
[01:11:44.760 --> 01:11:45.760]   Two children.
[01:11:45.760 --> 01:11:48.200]   That's their third generation.
[01:11:48.200 --> 01:11:49.200]   That's the vector.
[01:11:49.200 --> 01:11:52.200]   And they keep getting better and better, but they also keep getting more and more expensive.
[01:11:52.200 --> 01:11:56.800]   It's so horrible.
[01:11:56.800 --> 01:11:57.800]   Let's take a break.
[01:11:57.800 --> 01:12:02.800]   We got to pay for the onky robot for Georgia here.
[01:12:02.800 --> 01:12:04.400]   Are sure today brought to you by rocket mortgage.
[01:12:04.400 --> 01:12:08.800]   If you're about to buy a house or you need a mortgage to buy a robot, I know they don't
[01:12:08.800 --> 01:12:09.800]   do more cut mortgage.
[01:12:09.800 --> 01:12:10.800]   More about more.
[01:12:10.800 --> 01:12:13.560]   They may start, but not right now.
[01:12:13.560 --> 01:12:14.560]   Quick and loads.
[01:12:14.560 --> 01:12:15.920]   Number one lender in the country.
[01:12:15.920 --> 01:12:17.960]   Number one, in a couple of ways.
[01:12:17.960 --> 01:12:19.440]   Number one, a customer satisfaction.
[01:12:19.440 --> 01:12:22.640]   That's according to JD power for the last eight years in a row.
[01:12:22.640 --> 01:12:27.240]   And now thanks to that, they are now as of last December, number one in volume.
[01:12:27.240 --> 01:12:28.160]   I think that makes sense.
[01:12:28.160 --> 01:12:33.640]   If you serve customers, if you focus on the customer experience, people are going to
[01:12:33.640 --> 01:12:35.200]   love you and they're going to come back.
[01:12:35.200 --> 01:12:37.800]   They're going to tell their friends that's exactly what happens with rocket mortgage.
[01:12:37.800 --> 01:12:42.920]   Let me tell you about actually, this is quick and loans product for nerds, for geeks, people
[01:12:42.920 --> 01:12:47.680]   like us, rocket mortgage, because it's an entirely online mortgage approval process.
[01:12:47.680 --> 01:12:50.000]   So already, I'm in favor of it.
[01:12:50.000 --> 01:12:54.720]   I don't want to go to the bank, get dressed up, fill out a big, long application.
[01:12:54.720 --> 01:12:57.120]   And then the bank sends you home and says, do homework.
[01:12:57.120 --> 01:13:02.360]   You got to find paperwork and bank statements from last year and pay stubs from your previous
[01:13:02.360 --> 01:13:03.360]   employer.
[01:13:03.360 --> 01:13:04.360]   That's crazy.
[01:13:04.360 --> 01:13:05.840]   Instead, rocket mortgage, you fired up.
[01:13:05.840 --> 01:13:07.840]   Go to rocketmortgage.com/twit2.
[01:13:07.840 --> 01:13:09.320]   You can even do it on your phone.
[01:13:09.320 --> 01:13:11.240]   Rocketmortgage.com/twit2.
[01:13:11.240 --> 01:13:13.600]   And you begin the power buying process.
[01:13:13.600 --> 01:13:19.440]   Step one, with literally just a few questions, no long application, they will check your
[01:13:19.440 --> 01:13:22.040]   credit and they will say, here's the loans for which you qualify.
[01:13:22.040 --> 01:13:23.760]   You choose the term, the rate, the down payment.
[01:13:23.760 --> 01:13:27.320]   They have very good rates, a variety of them.
[01:13:27.320 --> 01:13:30.400]   You pick the one you want and now you've got pre-qualified approval.
[01:13:30.400 --> 01:13:31.720]   That was less than 10 minutes.
[01:13:31.720 --> 01:13:34.640]   Good enough so that if you're at an open house, you could do it right there and show
[01:13:34.640 --> 01:13:36.880]   the realtor and say, we want to make an offer.
[01:13:36.880 --> 01:13:39.280]   But then the next step.
[01:13:39.280 --> 01:13:42.760]   Step two, quick and loans will verify your income, assets and credit.
[01:13:42.760 --> 01:13:45.800]   Really without any intervention on your part because they have relationships with all
[01:13:45.800 --> 01:13:48.520]   the banks and everything, they get all the information they need.
[01:13:48.520 --> 01:13:51.480]   And in less than 24 hours, they give you verified approval.
[01:13:51.480 --> 01:13:55.280]   You get a letter even, you could print out, show the seller that makes you basically a
[01:13:55.280 --> 01:13:57.160]   cash buyer.
[01:13:57.160 --> 01:13:58.760]   The seller looks at that and goes, oh, they're good for it.
[01:13:58.760 --> 01:14:00.240]   They got the loan already.
[01:14:00.240 --> 01:14:01.760]   That puts you right at the front of the line.
[01:14:01.760 --> 01:14:05.120]   You're way ahead of all those other people who are saying, I'd like to buy your house,
[01:14:05.120 --> 01:14:06.760]   but it's contingent on me getting a loan.
[01:14:06.760 --> 01:14:08.680]   Nope, you got verified approval.
[01:14:08.680 --> 01:14:12.000]   Step three, once you're verified, you qualify for something new.
[01:14:12.000 --> 01:14:14.320]   This is because rates are starting to tick up.
[01:14:14.320 --> 01:14:18.240]   Rocket mortgage, quick and loans, again, thinking about the customer experience.
[01:14:18.240 --> 01:14:19.240]   It makes you nervous.
[01:14:19.240 --> 01:14:22.840]   If the rates are going up, you're kind of in a hurry because if you wait, if it's not
[01:14:22.840 --> 01:14:25.920]   the perfect house and you want to look at some more, the rates could go up and it could
[01:14:25.920 --> 01:14:29.760]   cost you thousands of dollars more, even if the price hasn't changed, just because the
[01:14:29.760 --> 01:14:30.920]   rate went up.
[01:14:30.920 --> 01:14:34.840]   So once you're verified, you qualify for rate shield approval.
[01:14:34.840 --> 01:14:35.840]   This is awesome.
[01:14:35.840 --> 01:14:37.760]   They lock your rate for up to 90 days while you're shopping.
[01:14:37.760 --> 01:14:38.760]   Three months.
[01:14:38.760 --> 01:14:40.280]   So you have plenty of time to look.
[01:14:40.280 --> 01:14:41.720]   Your rate cannot go up.
[01:14:41.720 --> 01:14:43.640]   It's in the real world could go up.
[01:14:43.640 --> 01:14:46.040]   Your rate is locked.
[01:14:46.040 --> 01:14:47.720]   They need to have to do this, but I like this.
[01:14:47.720 --> 01:14:51.040]   If rates go down, your rate will go down.
[01:14:51.040 --> 01:14:52.760]   So it's only one direction.
[01:14:52.760 --> 01:14:54.040]   It's either down or flat.
[01:14:54.040 --> 01:14:55.040]   It can never go up.
[01:14:55.040 --> 01:14:56.040]   I love that.
[01:14:56.040 --> 01:14:58.800]   Now you have three months to find the right house instead of rushing.
[01:14:58.800 --> 01:15:03.960]   This is exactly why quick and loans is the largest and best mortgage lender in the country.
[01:15:03.960 --> 01:15:04.960]   Rocket mortgage.
[01:15:04.960 --> 01:15:09.160]   You could start right now, rocketmortgage.com/twit number two.
[01:15:09.160 --> 01:15:10.160]   Rocketmortgage.com/twit.
[01:15:10.160 --> 01:15:14.600]   Rate shield approval is only valid on certain 30-year purchase transactions.
[01:15:14.600 --> 01:15:17.080]   Additional conditions or exclusions may apply.
[01:15:17.080 --> 01:15:20.480]   This is based on quick and loans data in comparison to the public data records.
[01:15:20.480 --> 01:15:21.480]   Equal housing lender.
[01:15:21.480 --> 01:15:22.480]   Actually, that's important.
[01:15:22.480 --> 01:15:27.200]   Licensed in all 50 states and MLS consumer access.org number 30-30.
[01:15:27.200 --> 01:15:28.760]   You don't have to remember all that.
[01:15:28.760 --> 01:15:31.560]   Just remember rocketmortgage.com/twit2.
[01:15:31.560 --> 01:15:37.240]   If you think you're going to go out house hunting or you want to refi, go there right
[01:15:37.240 --> 01:15:39.240]   now, set up your account.
[01:15:39.240 --> 01:15:41.240]   You'll be ready.
[01:15:41.240 --> 01:15:46.240]   Rocketmortgage.com/twit and the number two.
[01:15:46.240 --> 01:15:49.360]   We're going to use that.
[01:15:49.360 --> 01:15:51.360]   We're buying our first house right now.
[01:15:51.360 --> 01:15:52.360]   How exciting.
[01:15:52.360 --> 01:15:57.640]   We need four VR rooms to keep it close to you.
[01:15:57.640 --> 01:15:58.640]   Yeah.
[01:15:58.640 --> 01:16:00.640]   We'll keep it up with the dowses.
[01:16:00.640 --> 01:16:01.640]   Great.
[01:16:01.640 --> 01:16:05.240]   We have to play carnage chronicles together.
[01:16:05.240 --> 01:16:09.160]   Now, Georgia, have you settled on Oculus Rift or Vive?
[01:16:09.160 --> 01:16:11.120]   Are you one or the other?
[01:16:11.120 --> 01:16:15.720]   I prefer the Vive.
[01:16:15.720 --> 01:16:16.720]   I do.
[01:16:16.720 --> 01:16:20.200]   My hubby usually plays an Oculus, but I do prefer the Vive.
[01:16:20.200 --> 01:16:24.680]   The controllers are still a little bit weird, but we are now wireless.
[01:16:24.680 --> 01:16:26.720]   I was just going to ask you.
[01:16:26.720 --> 01:16:29.240]   This is the reason I get the Vive.
[01:16:29.240 --> 01:16:30.680]   They have a wireless adapter now.
[01:16:30.680 --> 01:16:31.680]   You don't have that big reward.
[01:16:31.680 --> 01:16:32.920]   We thought we had wireless on both.
[01:16:32.920 --> 01:16:34.680]   Oh, that's the worst part of that.
[01:16:34.680 --> 01:16:35.680]   Wow.
[01:16:35.680 --> 01:16:36.680]   Get rid of the cord.
[01:16:36.680 --> 01:16:37.680]   It's amazing.
[01:16:37.680 --> 01:16:38.680]   Yeah.
[01:16:38.680 --> 01:16:39.680]   It's really amazing.
[01:16:39.680 --> 01:16:44.200]   I say that the first day I did notice there was a microfraction of a delay.
[01:16:44.200 --> 01:16:45.840]   After that, I'm fully comfortable now.
[01:16:45.840 --> 01:16:47.600]   Because you were used to the spin around.
[01:16:47.600 --> 01:16:49.160]   You can splash at your enemies.
[01:16:49.160 --> 01:16:50.160]   You can duck.
[01:16:50.160 --> 01:16:51.160]   Don't roll.
[01:16:51.160 --> 01:16:52.160]   It's dangerous.
[01:16:52.160 --> 01:16:53.160]   You could.
[01:16:53.160 --> 01:16:54.160]   Unless you're on fire.
[01:16:54.160 --> 01:16:55.920]   Unless you're on fire.
[01:16:55.920 --> 01:16:57.320]   Then stop, drop, and roll.
[01:16:57.320 --> 01:16:58.320]   Too soon.
[01:16:58.320 --> 01:16:59.320]   Too soon, Liam.
[01:16:59.320 --> 01:17:00.320]   Yeah, I'm not kidding.
[01:17:00.320 --> 01:17:02.040]   I think this is a really clever idea.
[01:17:02.040 --> 01:17:06.280]   Instead of having the wires come off the back of your head, you have these angel wings
[01:17:06.280 --> 01:17:07.280]   on their head.
[01:17:07.280 --> 01:17:08.280]   Yeah.
[01:17:08.280 --> 01:17:11.160]   It's a little bit heavier, but I didn't notice it too much.
[01:17:11.160 --> 01:17:15.320]   We used to have the wires that you can get from Amazon that you would hang the wires
[01:17:15.320 --> 01:17:16.320]   on the ceiling.
[01:17:16.320 --> 01:17:19.360]   But what was happening is that my children were spinning.
[01:17:19.360 --> 01:17:23.520]   I didn't know this before, but people spin a certain way.
[01:17:23.520 --> 01:17:25.400]   You favor a certain way to spin.
[01:17:25.400 --> 01:17:26.840]   You're not going to unspin yourself.
[01:17:26.840 --> 01:17:29.280]   You will spin more, say, left or right.
[01:17:29.280 --> 01:17:31.080]   They were destroying the internal wires.
[01:17:31.080 --> 01:17:34.840]   We had to spend $150 to buy a new set of wires.
[01:17:34.840 --> 01:17:36.600]   We weren't about to go without our...
[01:17:36.600 --> 01:17:37.600]   Are you concerned?
[01:17:37.600 --> 01:17:42.840]   Is it something that your children are living in a phony 3D world?
[01:17:42.840 --> 01:17:45.440]   Does that bother you at all?
[01:17:45.440 --> 01:17:48.080]   There is definitely a worry for that.
[01:17:48.080 --> 01:17:49.320]   We don't let our kids play.
[01:17:49.320 --> 01:17:53.320]   They don't play during the week at all, any technology at all.
[01:17:53.320 --> 01:17:57.800]   They get to play two hours a day during the weekend, and my son just got on a roll.
[01:17:57.800 --> 01:18:02.320]   We gave him four hours stretch.
[01:18:02.320 --> 01:18:05.800]   He got a four hour stretch to be able to play some games.
[01:18:05.800 --> 01:18:08.040]   That's why they're playing during Wellam on Twitter.
[01:18:08.040 --> 01:18:09.840]   You hear any noise?
[01:18:09.840 --> 01:18:10.840]   It's them.
[01:18:10.840 --> 01:18:12.680]   Is the noise going to be vomiting?
[01:18:12.680 --> 01:18:13.680]   No!
[01:18:13.680 --> 01:18:14.680]   You don't get sick.
[01:18:14.680 --> 01:18:17.880]   There are certain games that you will feel ill on, but really they've gotten much better
[01:18:17.880 --> 01:18:21.200]   with the motion tracking and not...
[01:18:21.200 --> 01:18:23.480]   It's that kind of fluid movement.
[01:18:23.480 --> 01:18:24.520]   Try to stay away from those.
[01:18:24.520 --> 01:18:26.440]   I use the teleport.
[01:18:26.440 --> 01:18:27.440]   But...
[01:18:27.440 --> 01:18:28.440]   Alright, I'll have to try it again.
[01:18:28.440 --> 01:18:29.440]   I'll have to try it again.
[01:18:29.440 --> 01:18:30.440]   I'll have to try it again.
[01:18:30.440 --> 01:18:31.920]   I want video of that.
[01:18:31.920 --> 01:18:34.800]   I want video of space pirate trainer Leo.
[01:18:34.800 --> 01:18:35.800]   Oh my god.
[01:18:35.800 --> 01:18:36.800]   They're shooting pirates.
[01:18:36.800 --> 01:18:38.800]   Oh man, that's just not...
[01:18:38.800 --> 01:18:42.800]   You can start the VR cough caucus in Congress, the brand.
[01:18:42.800 --> 01:18:43.800]   Yeah!
[01:18:43.800 --> 01:18:45.680]   You know, I gave VR a shot.
[01:18:45.680 --> 01:18:47.600]   I am not that into it.
[01:18:47.600 --> 01:18:48.800]   I'm enjoying it.
[01:18:48.800 --> 01:18:49.800]   I am too.
[01:18:49.800 --> 01:18:51.720]   So here's my fun.
[01:18:51.720 --> 01:18:52.720]   And maybe I can get some...
[01:18:52.720 --> 01:18:57.560]   I have Oculus Go and I got the Lenovo product, and they're both kind of cool, but I've never
[01:18:57.560 --> 01:18:59.800]   actually gone back and played a game more than once.
[01:18:59.800 --> 01:19:00.800]   So you need the non-fooler.
[01:19:00.800 --> 01:19:02.800]   Because it's a different experience than I do.
[01:19:02.800 --> 01:19:03.800]   I know, probably is.
[01:19:03.800 --> 01:19:07.280]   It's better, but VR is not relaxing.
[01:19:07.280 --> 01:19:08.280]   It's exhausting.
[01:19:08.280 --> 01:19:09.440]   Like you're playing, you're moving.
[01:19:09.440 --> 01:19:10.440]   It's not...
[01:19:10.440 --> 01:19:12.760]   If you're having a long day at work, I don't want to play VR.
[01:19:12.760 --> 01:19:17.080]   I want to sit and have something mindless that I can just play.
[01:19:17.080 --> 01:19:20.600]   VR, I'm tired and it causes more anxiety.
[01:19:20.600 --> 01:19:24.640]   So if you're already dealing with a high anxiety day, VR does not fit into your day
[01:19:24.640 --> 01:19:27.800]   then it's not one of those kind of soothing reactions to that.
[01:19:27.800 --> 01:19:31.860]   And I think that a lot of people will expect it to be the same thing as a sit down video
[01:19:31.860 --> 01:19:36.580]   game where you can kind of enjoy killing orcs or doing something else that you're having
[01:19:36.580 --> 01:19:37.860]   fun to.
[01:19:37.860 --> 01:19:39.020]   And I don't find that.
[01:19:39.020 --> 01:19:43.500]   Like walking around, ducking, running, hacking and slashing all through like 45 minutes and
[01:19:43.500 --> 01:19:44.500]   then I'm like done.
[01:19:44.500 --> 01:19:48.220]   Like I can play maybe for an hour and a half and then I don't want to play anymore and
[01:19:48.220 --> 01:19:51.460]   then I need to take a break because I've burned through like, I don't know what, 5,000
[01:19:51.460 --> 01:19:52.460]   calories or something.
[01:19:52.460 --> 01:19:53.460]   That's good.
[01:19:53.460 --> 01:19:54.460]   That's why you...
[01:19:54.460 --> 01:19:55.460]   And you can eat more ice cream.
[01:19:55.460 --> 01:19:57.380]   That's how I know how she does that.
[01:19:57.380 --> 01:19:58.380]   Yeah.
[01:19:58.380 --> 01:19:59.380]   So we need to get a vibe.
[01:19:59.380 --> 01:20:02.820]   How much do they cost combined if you get the ice cream maker and the vibe?
[01:20:02.820 --> 01:20:06.020]   Well, you also need a high powered computer.
[01:20:06.020 --> 01:20:10.820]   So I'm saying it'll be a little bit over 2,500 bucks.
[01:20:10.820 --> 01:20:11.820]   At least.
[01:20:11.820 --> 01:20:12.820]   It's about it.
[01:20:12.820 --> 01:20:13.820]   I don't know.
[01:20:13.820 --> 01:20:14.820]   I'm not sure though that the...
[01:20:14.820 --> 01:20:15.820]   I'm sure your story has a flash.
[01:20:15.820 --> 01:20:16.820]   Well, I'm sure your story has a free maker.
[01:20:16.820 --> 01:20:17.820]   Your vibe bundle.
[01:20:17.820 --> 01:20:18.820]   Exactly.
[01:20:18.820 --> 01:20:19.820]   They should go together.
[01:20:19.820 --> 01:20:24.180]   And you can eat your virtual ice cream.
[01:20:24.180 --> 01:20:25.180]   Go ahead, Brandon.
[01:20:25.180 --> 01:20:26.180]   I'm sorry.
[01:20:26.180 --> 01:20:27.180]   I interrupted you.
[01:20:27.180 --> 01:20:28.180]   Oh, no, no, no.
[01:20:28.180 --> 01:20:34.540]   I know, Nividio and the graphics card companies, they have a surplus of like GPUs now that the
[01:20:34.540 --> 01:20:37.220]   really high powered stuff you use in VR.
[01:20:37.220 --> 01:20:39.820]   You can also use it for cryptocurrency.
[01:20:39.820 --> 01:20:44.540]   And now that we've kind of hit a point where you can't mine cryptocurrency and make money
[01:20:44.540 --> 01:20:50.020]   very easily, they have like tons of like inventory leftover in their warehouses.
[01:20:50.020 --> 01:20:54.900]   So I wonder today if you're trying to build a VR PC if you could do it for a lot cheaper.
[01:20:54.900 --> 01:21:00.340]   Because my most expensive component by far was that $800 video card.
[01:21:00.340 --> 01:21:01.340]   Right.
[01:21:01.340 --> 01:21:02.340]   True.
[01:21:02.340 --> 01:21:05.700]   Actually, NVIDIA's stock is in trouble, right?
[01:21:05.700 --> 01:21:08.460]   Because Bitcoin's crashed.
[01:21:08.460 --> 01:21:13.940]   And the NVIDIA's stock went up because Bitcoin miners were buying GPUs.
[01:21:13.940 --> 01:21:16.460]   And with the crash in Bitcoin value, isn't that?
[01:21:16.460 --> 01:21:19.300]   Who would have thought, I feel bad for NVIDIA?
[01:21:19.300 --> 01:21:20.300]   Yeah.
[01:21:20.300 --> 01:21:23.100]   You know, who would have thought that that would affect their stock price?
[01:21:23.100 --> 01:21:25.900]   Their stock price directly tied to the value.
[01:21:25.900 --> 01:21:30.420]   A CNBC called it crypto hangover.
[01:21:30.420 --> 01:21:35.060]   NVIDIA nurses crypto hangover as demand for mining chips evaporates.
[01:21:35.060 --> 01:21:36.060]   Wow.
[01:21:36.060 --> 01:21:40.700]   You know, but they're doing some really interesting things.
[01:21:40.700 --> 01:21:43.900]   You know, before I was running for Congress, I was working in the game industry and they
[01:21:43.900 --> 01:21:48.100]   are doing some fascinating things with dynamic lighting layout.
[01:21:48.100 --> 01:21:50.460]   I mean, really next gen stuff.
[01:21:50.460 --> 01:21:53.900]   So, this is just a measure of how the stock market works.
[01:21:53.900 --> 01:21:57.020]   Blockchain, Bitcoin, invest.
[01:21:57.020 --> 01:21:58.620]   Because they're not thinking.
[01:21:58.620 --> 01:22:01.980]   It's all just kind of heard a reaction.
[01:22:01.980 --> 01:22:03.140]   So that was the hot thing.
[01:22:03.140 --> 01:22:05.060]   So that's why they were investing in NVIDIA.
[01:22:05.060 --> 01:22:10.540]   But people like us who pay attention to technology, but we're, you know, I doubt we move the market
[01:22:10.540 --> 01:22:11.540]   much, Brianna.
[01:22:11.540 --> 01:22:12.540]   I know I don't.
[01:22:12.540 --> 01:22:16.300]   Well, I don't find that my knowing about technology actually makes me a better investor.
[01:22:16.300 --> 01:22:17.300]   I mean, if it's all...
[01:22:17.300 --> 01:22:18.300]   It's quite the opposite.
[01:22:18.300 --> 01:22:19.300]   It's quite the opposite.
[01:22:19.300 --> 01:22:20.300]   Exactly.
[01:22:20.300 --> 01:22:23.380]   I remember my mother-in-law went to Google and public called me up to try to invest in
[01:22:23.380 --> 01:22:24.380]   Google.
[01:22:24.380 --> 01:22:26.980]   And I said, you know, I don't know if some companies go up, some kind of goes down.
[01:22:26.980 --> 01:22:28.540]   Of course, she didn't invest.
[01:22:28.540 --> 01:22:32.020]   And had she invested, she would have made a fortune and she never spoke to me again.
[01:22:32.020 --> 01:22:38.660]   My dad sent me an email a couple of months ago reminding me that when Steve Jobs passed
[01:22:38.660 --> 01:22:42.860]   away in 2011, I told him, "Dumb your apples, Doc."
[01:22:42.860 --> 01:22:43.860]   Oh, God.
[01:22:43.860 --> 01:22:45.660]   Because it's all over for Apple.
[01:22:45.660 --> 01:22:48.060]   They're not going to innovate anymore.
[01:22:48.060 --> 01:22:49.060]   That's...
[01:22:49.060 --> 01:22:50.060]   Well...
[01:22:50.060 --> 01:22:51.060]   He did.
[01:22:51.060 --> 01:22:52.060]   That was true.
[01:22:52.060 --> 01:22:53.060]   I want to point out he didn't.
[01:22:53.060 --> 01:22:57.020]   And what he sent in his email was the value of his Apple stock then and now.
[01:22:57.020 --> 01:23:00.620]   And you were wrong, son.
[01:23:00.620 --> 01:23:01.780]   Thanks for rubbing it in.
[01:23:01.780 --> 01:23:02.780]   Wow.
[01:23:02.780 --> 01:23:03.780]   Are you still at his will?
[01:23:03.780 --> 01:23:09.020]   He would have sent a much different message if he had actually dumped it and it probably
[01:23:09.020 --> 01:23:10.820]   would have been on many postcards.
[01:23:10.820 --> 01:23:11.820]   No.
[01:23:11.820 --> 01:23:12.820]   I'm thrilled.
[01:23:12.820 --> 01:23:14.140]   Yeah, I sent him 17 postcards.
[01:23:14.140 --> 01:23:15.620]   That might be why he responded, though.
[01:23:15.620 --> 01:23:16.620]   I thrilled.
[01:23:16.620 --> 01:23:19.620]   I'm thrilled that he didn't listen to me.
[01:23:19.620 --> 01:23:24.620]   And now I really learned the lesson because it isn't tied to...
[01:23:24.620 --> 01:23:28.260]   And you could argue that Apple has innovated.
[01:23:28.260 --> 01:23:30.100]   They certainly are the most valuable company in the world.
[01:23:30.100 --> 01:23:33.340]   Not a trillion dollar company anymore, but still very, very valuable.
[01:23:33.340 --> 01:23:37.140]   And the stock price, of course, has gone up 10 or 20 fold.
[01:23:37.140 --> 01:23:42.260]   But from a technological point of view, I think you could make the case that really
[01:23:42.260 --> 01:23:47.060]   their best days are in the past that financially know, but technologically so.
[01:23:47.060 --> 01:23:48.060]   I don't know.
[01:23:48.060 --> 01:23:50.260]   They haven't come out with either of mine.
[01:23:50.260 --> 01:23:51.260]   Yeah.
[01:23:51.260 --> 01:23:54.060]   They have a great iPhone every single year.
[01:23:54.060 --> 01:23:55.260]   I bought that iPhone 3G.
[01:23:55.260 --> 01:23:57.100]   That's when I did it.
[01:23:57.100 --> 01:24:00.060]   4, 4S, 5, 5S all the way through.
[01:24:00.060 --> 01:24:02.620]   And I got the phone this year.
[01:24:02.620 --> 01:24:06.100]   And it was really surprising because I wasn't sold on it.
[01:24:06.100 --> 01:24:08.460]   I was like, I'll wait till I see it at the Apple store.
[01:24:08.460 --> 01:24:09.460]   And I stopped buying.
[01:24:09.460 --> 01:24:12.460]   I saw it.
[01:24:12.460 --> 01:24:15.860]   Just two days after it came out and then a ton of stock at my local Apple store.
[01:24:15.860 --> 01:24:16.860]   And I bought it.
[01:24:16.860 --> 01:24:18.860]   And I got the plus.
[01:24:18.860 --> 01:24:25.460]   And I've never taken an Apple iPhone back to stick with the old one before ever because
[01:24:25.460 --> 01:24:27.180]   I'm a huge Apple fan.
[01:24:27.180 --> 01:24:33.460]   But it's just impossible to justify this year's iPhone from the 10th.
[01:24:33.460 --> 01:24:34.460]   Yeah.
[01:24:34.460 --> 01:24:36.780]   It's not like the large one.
[01:24:36.780 --> 01:24:39.980]   I feel doesn't bring anything better to the experience.
[01:24:39.980 --> 01:24:44.020]   The phone itself, like the deep learning stuff, I'm sure it will be great two or three
[01:24:44.020 --> 01:24:45.420]   years from now.
[01:24:45.420 --> 01:24:48.100]   But it's just this has really been the first year.
[01:24:48.100 --> 01:24:50.540]   I don't think they brought anything to the market with the iPhone.
[01:24:50.540 --> 01:24:53.540]   It's the XR, which is actually not a bad one.
[01:24:53.540 --> 01:24:54.540]   Yeah.
[01:24:54.540 --> 01:25:00.180]   It's actually a little bit smaller than the plus for $450 less or $350 less.
[01:25:00.180 --> 01:25:02.340]   So far to buy an iPhone, that's the one I get.
[01:25:02.340 --> 01:25:05.020]   But actually, I love the Google Pixel 3.
[01:25:05.020 --> 01:25:06.020]   It's my favorite.
[01:25:06.020 --> 01:25:07.700]   Played with a night's sight yet?
[01:25:07.700 --> 01:25:08.700]   Yeah.
[01:25:08.700 --> 01:25:10.500]   I just did yesterday as a matter of fact.
[01:25:10.500 --> 01:25:14.500]   My son was doing a concert in San Francisco in a very dark room.
[01:25:14.500 --> 01:25:17.740]   And the only problem is it made his hair look red and he doesn't have red hair.
[01:25:17.740 --> 01:25:18.900]   But other than that, it's not even pictures.
[01:25:18.900 --> 01:25:21.540]   One of the things that they're doing that's a filter.
[01:25:21.540 --> 01:25:24.500]   So night's sight, they take many, many images.
[01:25:24.500 --> 01:25:27.380]   So this is a very historically very hard picture for me to take.
[01:25:27.380 --> 01:25:30.020]   This is our Christmas lighting on our house.
[01:25:30.020 --> 01:25:34.660]   And the problem with this kind of lighting is it blows out, either the camera exposes
[01:25:34.660 --> 01:25:38.660]   for the lighting, in which case everything's pitch black, or it exposes for the background,
[01:25:38.660 --> 01:25:41.180]   in which case the lighting is blowing out.
[01:25:41.180 --> 01:25:42.980]   This is a perfectly balanced photo.
[01:25:42.980 --> 01:25:48.660]   And I think Google did a very good job of in software, mind you, remember now they're
[01:25:48.660 --> 01:25:53.660]   taking I think 15 images, some as slow as a quarter of a second.
[01:25:53.660 --> 01:25:55.420]   So and this is handheld.
[01:25:55.420 --> 01:26:00.500]   But if you do it on a tripod, it senses it's on a tripod, it'll even extend those low-end
[01:26:00.500 --> 01:26:01.500]   ones.
[01:26:01.500 --> 01:26:02.780]   Somebody's saying you have a sniper tower?
[01:26:02.780 --> 01:26:04.580]   Yeah, that's my sniper tower, right?
[01:26:04.580 --> 01:26:10.820]   It's a temporarily home of Christmas balls.
[01:26:10.820 --> 01:26:13.060]   But I think that this is an example.
[01:26:13.060 --> 01:26:15.500]   This is amazing that a camera phone could do this.
[01:26:15.500 --> 01:26:16.500]   Yeah, that's great.
[01:26:16.500 --> 01:26:19.380]   And so Google, this is computational.
[01:26:19.380 --> 01:26:23.660]   The funny thing is it didn't do this when we bought the Pixel 3.
[01:26:23.660 --> 01:26:25.140]   This is something they pushed out.
[01:26:25.140 --> 01:26:26.140]   You know, it's funny.
[01:26:26.140 --> 01:26:27.140]   I don't know if you can see this.
[01:26:27.140 --> 01:26:28.140]   Can you see this image here?
[01:26:28.140 --> 01:26:30.100]   Because that's the marquee at the SFJAS.
[01:26:30.100 --> 01:26:32.540]   And you see how it picked up Will Maggett and--
[01:26:32.540 --> 01:26:34.540]   You can read the text.
[01:26:34.540 --> 01:26:35.540]   You can actually read it.
[01:26:35.540 --> 01:26:37.340]   But the funny thing is that I was shooting it last night.
[01:26:37.340 --> 01:26:38.340]   I couldn't read it at all.
[01:26:38.340 --> 01:26:41.020]   And I thought, and just as you were talking, I said, I'm going to go back and look.
[01:26:41.020 --> 01:26:43.060]   And I didn't realize I had gotten it.
[01:26:43.060 --> 01:26:44.220]   That's nice.
[01:26:44.220 --> 01:26:49.300]   That's, you know, one of the things they're doing with their AI is, and this is really
[01:26:49.300 --> 01:26:55.580]   hard, is they're trying to understand what the picture is of and expose for that.
[01:26:55.580 --> 01:27:00.740]   So for instance, if I had people in front of the house, the people would be dark faced
[01:27:00.740 --> 01:27:02.260]   to get the lights right.
[01:27:02.260 --> 01:27:04.860]   If Google sees faces, it'll go, oh, you know what?
[01:27:04.860 --> 01:27:08.180]   We should expose for the face and let the light be over bright.
[01:27:08.180 --> 01:27:09.700]   We're going to expose for the face.
[01:27:09.700 --> 01:27:11.860]   So there's some really interesting things it's doing.
[01:27:11.860 --> 01:27:12.860]   And you know about Google Land.
[01:27:12.860 --> 01:27:17.860]   So for example, going back, I don't know how it knew it, but it knew that I was at SFJAS.
[01:27:17.860 --> 01:27:18.860]   It actually analyzed the--
[01:27:18.860 --> 01:27:20.860]   There are some who would say that spooky.
[01:27:20.860 --> 01:27:24.740]   Well, you know, it was really great in Europe when I was traveling.
[01:27:24.740 --> 01:27:27.740]   I'd be at some landmark, and I didn't know where I was.
[01:27:27.740 --> 01:27:31.260]   And I would take a picture of it, and it would tell me where I am.
[01:27:31.260 --> 01:27:33.260]   Well, maybe that's a good picture of people who are senile.
[01:27:33.260 --> 01:27:34.260]   Or am I?
[01:27:34.260 --> 01:27:35.260]   Or am I?
[01:27:35.260 --> 01:27:36.260]   Yeah.
[01:27:36.260 --> 01:27:37.260]   No, you know what?
[01:27:37.260 --> 01:27:38.260]   You're joking?
[01:27:38.260 --> 01:27:43.260]   But actually, well, at least now for people with low vision or no vision, camera phones
[01:27:43.260 --> 01:27:46.620]   are turning out to be hugely valuable.
[01:27:46.620 --> 01:27:51.140]   There are apps that are automatic and apps that are human driven that allow them to see
[01:27:51.140 --> 01:27:52.140]   things.
[01:27:52.140 --> 01:27:55.740]   There've always been things like bill readers and stuff, but now with Lens, a lot of that
[01:27:55.740 --> 01:27:56.940]   can be done on a phone.
[01:27:56.940 --> 01:27:57.940]   It's really--
[01:27:57.940 --> 01:28:00.260]   And I use my phone at the magnifying glass all the time.
[01:28:00.260 --> 01:28:01.260]   I do too.
[01:28:01.260 --> 01:28:02.260]   I can't read.
[01:28:02.260 --> 01:28:03.260]   Oh, yeah.
[01:28:03.260 --> 01:28:05.180]   Yeah, Larry, I do the exact same thing.
[01:28:05.180 --> 01:28:06.180]   There's something that I can't read.
[01:28:06.180 --> 01:28:07.140]   I take a photo of it.
[01:28:07.140 --> 01:28:09.580]   I was taking pictures of jewelry.
[01:28:09.580 --> 01:28:15.340]   I wanted to see what the little stamp on the at the hallmark inside was to tell what
[01:28:15.340 --> 01:28:18.380]   year the ring was made because it was from my mom.
[01:28:18.380 --> 01:28:20.220]   And I took a photo of it, and then I zoomed it out.
[01:28:20.220 --> 01:28:24.260]   And I took another photo of the zoom and zoomed it out even more.
[01:28:24.260 --> 01:28:25.380]   And it was like intense.
[01:28:25.380 --> 01:28:26.580]   I do that in serial numbers.
[01:28:26.580 --> 01:28:27.580]   I can never read--
[01:28:27.580 --> 01:28:28.580]   I think this really works.
[01:28:28.580 --> 01:28:29.580]   I can never read the serial numbers.
[01:28:29.580 --> 01:28:31.660]   I think that you can't see.
[01:28:31.660 --> 01:28:33.620]   You can put your phone into a funny angle and get--
[01:28:33.620 --> 01:28:34.620]   I'm not.
[01:28:34.620 --> 01:28:37.140]   It's incredibly valuable in ways that nobody--
[01:28:37.140 --> 01:28:41.140]   and you have to give Philippe Kahn the vent or the camera phone some credit here for--
[01:28:41.140 --> 01:28:42.940]   Actually, you heard that story right about it.
[01:28:42.940 --> 01:28:44.380]   Yeah, in fact, we've interviewed Philippe.
[01:28:44.380 --> 01:28:46.940]   He came in and we talked about it on triangulation.
[01:28:46.940 --> 01:28:48.900]   It's a great episode of triangulation.
[01:28:48.900 --> 01:28:52.620]   And about how Kodak didn't want it.
[01:28:52.620 --> 01:28:56.300]   And the phone makers didn't want it because they couldn't understand why phone camera
[01:28:56.300 --> 01:28:58.460]   companies couldn't understand why you'd want to build a phone in.
[01:28:58.460 --> 01:29:01.580]   Phone companies couldn't understand cameras and he wouldn't have did it anyway.
[01:29:01.580 --> 01:29:04.620]   It's a classic story of a father.
[01:29:04.620 --> 01:29:08.340]   This is always a problem if your father and your wife is giving birth.
[01:29:08.340 --> 01:29:09.940]   You're basically a fifth wheel.
[01:29:09.940 --> 01:29:11.740]   You've got nothing to do.
[01:29:11.740 --> 01:29:14.860]   She's suffering mightily, right, Georgia?
[01:29:14.860 --> 01:29:20.180]   And you're all you could do is go, oh, oh, oh, oh.
[01:29:20.180 --> 01:29:24.020]   And so I think a lot of dads come up with things to do.
[01:29:24.020 --> 01:29:28.860]   And the madmen era was stand out in the lobby smoking.
[01:29:28.860 --> 01:29:34.260]   But I wrote a hypercard stacked time contractions.
[01:29:34.260 --> 01:29:40.300]   And I wrote an Excel spreadsheet to predict the actual day of birth.
[01:29:40.300 --> 01:29:41.300]   There you go.
[01:29:41.300 --> 01:29:43.540]   And I had to run because he's an engineer.
[01:29:43.540 --> 01:29:44.540]   He tells a story.
[01:29:44.540 --> 01:29:46.980]   His wife is giving birth to their first child.
[01:29:46.980 --> 01:29:49.180]   This is actually a documentary that was shot.
[01:29:49.180 --> 01:29:53.580]   He knows he's got a phone that has a camera in it.
[01:29:53.580 --> 01:29:55.540]   But he wants someone to upload it to family and friends.
[01:29:55.540 --> 01:29:56.740]   He sees that connector.
[01:29:56.740 --> 01:30:05.940]   He runs down to his car, opens the trunk, pulls out stuff, solders together a solution, brings
[01:30:05.940 --> 01:30:06.940]   it.
[01:30:06.940 --> 01:30:07.940]   Wow.
[01:30:07.940 --> 01:30:11.220]   What it was was he needed a way to get the phone connected to the camera.
[01:30:11.220 --> 01:30:13.700]   And he had a kit, a car kit for his.
[01:30:13.700 --> 01:30:15.580]   This is in the hospital room.
[01:30:15.580 --> 01:30:16.580]   He's soldering it.
[01:30:16.580 --> 01:30:18.580]   And he drove this is why he drove phone.
[01:30:18.580 --> 01:30:19.580]   You're crazy.
[01:30:19.580 --> 01:30:20.580]   Yeah.
[01:30:20.580 --> 01:30:21.580]   There you go.
[01:30:21.580 --> 01:30:22.580]   Wow.
[01:30:22.580 --> 01:30:23.580]   He's like Sonya.
[01:30:23.580 --> 01:30:24.580]   He shared it with us.
[01:30:24.580 --> 01:30:25.580]   Yeah.
[01:30:25.580 --> 01:30:28.620]   When they shot this, they got people that looked just like Felipe and a young Felipe and Sonya.
[01:30:28.620 --> 01:30:29.620]   And it's a great story.
[01:30:29.620 --> 01:30:30.620]   This is a nice young lady.
[01:30:30.620 --> 01:30:33.420]   And so for the young lady, when you're the old, the girl, the lovely woman I've actually
[01:30:33.420 --> 01:30:35.820]   known who was born that year.
[01:30:35.820 --> 01:30:38.620]   She was the first camera phone picture.
[01:30:38.620 --> 01:30:39.620]   There she is.
[01:30:39.620 --> 01:30:40.620]   There she is.
[01:30:40.620 --> 01:30:46.180]   She was the first camera phone picture distributed over the internet in 1997.
[01:30:46.180 --> 01:30:50.100]   So I'm going to just give a little tiny clip though of like, don't do this.
[01:30:50.100 --> 01:30:51.260]   Your wife is giving birth.
[01:30:51.260 --> 01:30:52.260]   She's going to get there.
[01:30:52.260 --> 01:30:55.820]   And wait, I'm just going to throw this out there.
[01:30:55.820 --> 01:30:56.820]   Don't write.
[01:30:56.820 --> 01:30:57.820]   She didn't want to.
[01:30:57.820 --> 01:30:59.420]   She doesn't want you there.
[01:30:59.420 --> 01:31:03.260]   If she says, go write your code, then go write your code, but suffer along.
[01:31:03.260 --> 01:31:04.260]   Suffer along.
[01:31:04.260 --> 01:31:06.380]   What does your husband do?
[01:31:06.380 --> 01:31:10.300]   He sat there worried, worried as can be like really, really worried.
[01:31:10.300 --> 01:31:16.180]   But when I gave birth, I actually, after I gave birth, I had a panic attack.
[01:31:16.180 --> 01:31:18.740]   I didn't know I had a panic attack, but I had a panic attack.
[01:31:18.740 --> 01:31:20.300]   And I totally thought I was going to die.
[01:31:20.300 --> 01:31:23.100]   If you've ever had a panic attack, it's different than an anxiety attack.
[01:31:23.100 --> 01:31:25.540]   Anxiety attacks, you know it's anxiety.
[01:31:25.540 --> 01:31:26.540]   Panic attacks.
[01:31:26.540 --> 01:31:31.020]   So after I give birth, I throw up and then I feel this wave of anxiety because I was
[01:31:31.020 --> 01:31:36.060]   on so much betos and you could have killed a small mammal.
[01:31:36.060 --> 01:31:42.380]   And the coming off of that was just such a, it gave me such a reaction that I said to
[01:31:42.380 --> 01:31:46.900]   him, listen, I think that I'm dying, like just watch my pulse.
[01:31:46.900 --> 01:31:50.420]   And the poor guy, he just sat there for the entire time.
[01:31:50.420 --> 01:31:53.060]   And I said to myself, you know, I'm a therapist.
[01:31:53.060 --> 01:31:56.380]   If I was having a panic attack, I would know so I must be dying.
[01:31:56.380 --> 01:31:57.380]   Wow.
[01:31:57.380 --> 01:31:59.380]   And I know it's cool.
[01:31:59.380 --> 01:32:03.420]   You can now re-experience that on your vibe.
[01:32:03.420 --> 01:32:04.420]   Why?
[01:32:04.420 --> 01:32:05.420]   No, you can't.
[01:32:05.420 --> 01:32:06.420]   No, you can't.
[01:32:06.420 --> 01:32:12.660]   That you forget because there's a reason why I do it because I forgot.
[01:32:12.660 --> 01:32:15.900]   Yeah, you would never have another child and the human race would die out.
[01:32:15.900 --> 01:32:16.900]   Wow.
[01:32:16.900 --> 01:32:17.900]   Exactly.
[01:32:17.900 --> 01:32:18.980]   So it's my daughter needs to talk with you.
[01:32:18.980 --> 01:32:23.420]   She gets panic attacks all the time and thinks the world is coming to an end.
[01:32:23.420 --> 01:32:24.740]   Not the first video.
[01:32:24.740 --> 01:32:27.900]   It's really good on how to treat it.
[01:32:27.900 --> 01:32:29.580]   Anxiety is 100% treatable.
[01:32:29.580 --> 01:32:31.540]   It's exceptionally common.
[01:32:31.540 --> 01:32:36.140]   But we go through Sandra and I go through all of the basic techniques of what you can
[01:32:36.140 --> 01:32:37.860]   do so that you will never have one.
[01:32:37.860 --> 01:32:39.020]   They're not at all dangerous.
[01:32:39.020 --> 01:32:40.020]   They're not bad for you.
[01:32:40.020 --> 01:32:42.740]   They're actually good physiologically for you.
[01:32:42.740 --> 01:32:45.340]   They're just not good emotionally for you.
[01:32:45.340 --> 01:32:49.100]   And it kind of goes through all the steps of what we would do for the beginning sessions
[01:32:49.100 --> 01:32:54.220]   and session one session two, you should be pretty good for panic attacks.
[01:32:54.220 --> 01:32:56.900]   They're quite unpleasant and they really do disrupt life.
[01:32:56.900 --> 01:33:01.260]   Do you talk about how people, like the real question is when you're witnessing someone
[01:33:01.260 --> 01:33:06.620]   else have a panic attack and I do all the wrong things when somebody around me is anxious
[01:33:06.620 --> 01:33:07.620]   or panicking.
[01:33:07.620 --> 01:33:11.300]   Yeah, we do talk about what you should do.
[01:33:11.300 --> 01:33:13.300]   Which is just a really calm.
[01:33:13.300 --> 01:33:15.300]   Which one should I?
[01:33:15.300 --> 01:33:17.220]   Which one is that here?
[01:33:17.220 --> 01:33:18.220]   That's anxiety.
[01:33:18.220 --> 01:33:21.860]   I got them all, baby.
[01:33:21.860 --> 01:33:23.860]   I think it's session one.
[01:33:23.860 --> 01:33:25.420]   Session two, the journey continues.
[01:33:25.420 --> 01:33:27.660]   Treat your body anxiety responses.
[01:33:27.660 --> 01:33:28.660]   That one.
[01:33:28.660 --> 01:33:32.660]   Session three, calm, calm, calm, finally.
[01:33:32.660 --> 01:33:34.660]   Just the one that is.
[01:33:34.660 --> 01:33:35.660]   What anxiety is.
[01:33:35.660 --> 01:33:36.660]   There you go.
[01:33:36.660 --> 01:33:37.660]   That's session one.
[01:33:37.660 --> 01:33:40.020]   Yeah, that goes through what's anxiety.
[01:33:40.020 --> 01:33:42.700]   Why do we have it and then what to do about it?
[01:33:42.700 --> 01:33:45.940]   But if you're there with someone else and they're having a panic attack, one is stay
[01:33:45.940 --> 01:33:46.940]   there.
[01:33:46.940 --> 01:33:47.940]   Stay really calm.
[01:33:47.940 --> 01:33:51.140]   Someone else panicking while you're having a panic attack is horrible.
[01:33:51.140 --> 01:33:55.940]   Don't tell them to suck it up or stop or just think happy thoughts or there's nothing
[01:33:55.940 --> 01:33:57.380]   to be worried about.
[01:33:57.380 --> 01:34:02.700]   That can make someone feel bad and then now if they're angry and having a panic attack.
[01:34:02.700 --> 01:34:04.620]   Distractions work really well.
[01:34:04.620 --> 01:34:08.420]   Talking really soothing and trying to help them slow down their breathing.
[01:34:08.420 --> 01:34:11.660]   It's good to know this because your natural reaction is to freeze.
[01:34:11.660 --> 01:34:16.220]   It's a panic and it's going to be probably done in about 15 to 20 minutes.
[01:34:16.220 --> 01:34:17.220]   What is it?
[01:34:17.220 --> 01:34:19.620]   A sudden flood of brain chemicals that are still.
[01:34:19.620 --> 01:34:20.620]   It's adrenaline.
[01:34:20.620 --> 01:34:21.620]   It's a shot of adrenaline.
[01:34:21.620 --> 01:34:23.820]   Your body goes danger, danger, danger enough.
[01:34:23.820 --> 01:34:26.500]   That kind of fills up the level of a threshold.
[01:34:26.500 --> 01:34:30.580]   When it hits a certain threshold of danger, your body says it's fight or flight.
[01:34:30.580 --> 01:34:34.700]   It says I'm going to protect you because you're in a life or death situation.
[01:34:34.700 --> 01:34:37.980]   Once your body says I'm in a life or death situation, get a rush of adrenaline and you
[01:34:37.980 --> 01:34:39.820]   go through that response.
[01:34:39.820 --> 01:34:42.700]   Even if when you're talking to yourself, you say to yourself, you know what?
[01:34:42.700 --> 01:34:44.380]   This is difficult but I can handle it.
[01:34:44.380 --> 01:34:45.540]   I'm going to survive.
[01:34:45.540 --> 01:34:47.100]   No one's dying from this.
[01:34:47.100 --> 01:34:49.820]   Your brain goes, "Okay, well, if no one's dying, I don't need to shoot you filled with
[01:34:49.820 --> 01:34:50.820]   adrenaline to survive."
[01:34:50.820 --> 01:34:54.300]   Then why use up those resources?
[01:34:54.300 --> 01:34:58.260]   What you say and what you say to yourself inside of your head really can stop a panic
[01:34:58.260 --> 01:35:00.540]   attack all on its own, but it's practice.
[01:35:00.540 --> 01:35:04.820]   If somebody gets to my advanced age and has never had a panic attack, is it unlikely
[01:35:04.820 --> 01:35:06.940]   that I will have one?
[01:35:06.940 --> 01:35:07.940]   Probably.
[01:35:07.940 --> 01:35:08.940]   Probably not.
[01:35:08.940 --> 01:35:10.940]   You had one and that was for a while.
[01:35:10.940 --> 01:35:11.940]   But you had a good reason.
[01:35:11.940 --> 01:35:13.180]   You just gave birth to your first child.
[01:35:13.180 --> 01:35:14.180]   Well, you know what?
[01:35:14.180 --> 01:35:15.180]   Good reason?
[01:35:15.180 --> 01:35:16.180]   Like your body.
[01:35:16.180 --> 01:35:20.220]   If you knew what you were going to pay for college, you would have another one.
[01:35:20.220 --> 01:35:21.220]   Probably.
[01:35:21.220 --> 01:35:23.580]   But panic attacks are not that you're not good for adaptive.
[01:35:23.580 --> 01:35:28.740]   The most adaptive people that have really great amounts of being able to react really
[01:35:28.740 --> 01:35:33.060]   quickly under pressure and difficulty have strong anxiety systems that are there to
[01:35:33.060 --> 01:35:34.060]   keep you alive.
[01:35:34.060 --> 01:35:38.580]   That's why a lot of people from the military come back with a post-traumatic stress.
[01:35:38.580 --> 01:35:43.460]   They are now in a situation where they were prone to be able to react to a hair father,
[01:35:43.460 --> 01:35:45.300]   which is good for survival.
[01:35:45.300 --> 01:35:46.300]   But then they come back to regular life.
[01:35:46.300 --> 01:35:47.300]   Right.
[01:35:47.300 --> 01:35:48.300]   And they've got no way to deal with that reaction.
[01:35:48.300 --> 01:35:53.820]   Well, you've practiced this system to be really good at hitting anxiety where you're
[01:35:53.820 --> 01:36:00.020]   on survival mode very fast and then it's not needed anymore and it still can fire very
[01:36:00.020 --> 01:36:01.020]   quickly.
[01:36:01.020 --> 01:36:03.020]   So, not before a doubt.
[01:36:03.020 --> 01:36:06.260]   Like we wouldn't have survived if there was only type B's in the world.
[01:36:06.260 --> 01:36:07.260]   Right?
[01:36:07.260 --> 01:36:08.260]   Like T or E.
[01:36:08.260 --> 01:36:09.260]   Right.
[01:36:09.260 --> 01:36:11.460]   I just, I have a lazy brain.
[01:36:11.460 --> 01:36:14.060]   Stuff will happen and I'll go what?
[01:36:14.060 --> 01:36:15.060]   Right.
[01:36:15.060 --> 01:36:16.060]   Right.
[01:36:16.060 --> 01:36:17.660]   It's at legal pot in California.
[01:36:17.660 --> 01:36:19.660]   No, I'm not high or anything.
[01:36:19.660 --> 01:36:21.540]   I just don't know what the hell's going on.
[01:36:21.540 --> 01:36:22.540]   It takes tomorrow.
[01:36:22.540 --> 01:36:25.260]   I'll go, oh, that was bad, man.
[01:36:25.260 --> 01:36:26.260]   Yeah.
[01:36:26.260 --> 01:36:27.260]   Yeah.
[01:36:27.260 --> 01:36:30.940]   You see, when I went to a really dangerous, well, it wasn't really dangerous, but I went
[01:36:30.940 --> 01:36:32.500]   to part of the world.
[01:36:32.500 --> 01:36:34.060]   It wasn't that safe.
[01:36:34.060 --> 01:36:36.140]   My husband has a much stronger anxiety system.
[01:36:36.140 --> 01:36:40.100]   Well, if I had listened to my natural reactions, I would have been going with this guy that
[01:36:40.100 --> 01:36:41.100]   says, yeah, come with me.
[01:36:41.100 --> 01:36:42.100]   I'll bring you to the place.
[01:36:42.100 --> 01:36:46.820]   And I'm walking over to my husband had to actually pull me away because his anxiety system said,
[01:36:46.820 --> 01:36:49.140]   oh, this is not safe and he saved my life.
[01:36:49.140 --> 01:36:52.260]   So again, people that are calm think, oh, it's so great.
[01:36:52.260 --> 01:36:57.420]   But no, you're in dangerous situations, the people that are that have stronger anxiety
[01:36:57.420 --> 01:36:59.100]   systems that are one that live.
[01:36:59.100 --> 01:37:02.500]   So it's like hypochondriac, you know, hypochondriac, get sick sometimes.
[01:37:02.500 --> 01:37:06.460]   So every time I have a pain, I'm sure it's hypochondriac.
[01:37:06.460 --> 01:37:11.580]   And usually it is, but you always wonder, maybe this is the real one and how you know.
[01:37:11.580 --> 01:37:12.580]   Nice.
[01:37:12.580 --> 01:37:16.620]   That's good for you though, because you're false positive and too often and then people
[01:37:16.620 --> 01:37:20.500]   will dismiss it because they're like, oh, he's just doing his thing again.
[01:37:20.500 --> 01:37:25.660]   You want your level of fear to be within the range of natural life and you want to think
[01:37:25.660 --> 01:37:31.020]   more about how can I live more, not worry about not dying more because you can spend
[01:37:31.020 --> 01:37:35.100]   your whole life worrying about dying so much that you never live.
[01:37:35.100 --> 01:37:36.100]   Right.
[01:37:36.100 --> 01:37:37.100]   Exactly.
[01:37:37.100 --> 01:37:40.540]   And so for the health anxiety, it can really, I have people that are no longer living.
[01:37:40.540 --> 01:37:45.900]   They're just trapped in that bubble of constantly worrying about, you know, whatever a myriad
[01:37:45.900 --> 01:37:46.900]   of issues you like to have to write.
[01:37:46.900 --> 01:37:50.020]   I have to write you a check for $350 now for the sessions.
[01:37:50.020 --> 01:37:51.020]   Oh, this is good.
[01:37:51.020 --> 01:37:53.220]   Oh my gosh.
[01:37:53.220 --> 01:37:55.500]   Did you win on election night?
[01:37:55.500 --> 01:37:57.460]   Was there a little anxiety, Brianna?
[01:37:57.460 --> 01:37:58.460]   No.
[01:37:58.460 --> 01:38:03.940]   You know, I knew I was probably going to lose and I said to myself, I didn't want to set
[01:38:03.940 --> 01:38:05.780]   my expectations very high.
[01:38:05.780 --> 01:38:09.700]   So I was actually freaking delighted by how many votes we got.
[01:38:09.700 --> 01:38:12.300]   So election night was just amazing.
[01:38:12.300 --> 01:38:13.300]   Oh, God.
[01:38:13.300 --> 01:38:15.940]   I was expecting to lose and then we did way better.
[01:38:15.940 --> 01:38:19.620]   What do you think it's like with like for Bill Nelson or these, you know, Rick Scott, even
[01:38:19.620 --> 01:38:21.260]   you know, he goes on for weeks, right?
[01:38:21.260 --> 01:38:23.620]   They've got a lot of those elections.
[01:38:23.620 --> 01:38:27.940]   You know what the worst night was when Donald Trump realized he'd won.
[01:38:27.940 --> 01:38:28.940]   Right.
[01:38:28.940 --> 01:38:29.940]   Imagine the anxiety.
[01:38:29.940 --> 01:38:30.940]   Exactly.
[01:38:30.940 --> 01:38:31.940]   Exactly.
[01:38:31.940 --> 01:38:32.940]   Exactly.
[01:38:32.940 --> 01:38:35.180]   But we weren't supposed to win.
[01:38:35.180 --> 01:38:36.820]   Prevent it now.
[01:38:36.820 --> 01:38:42.060]   It's like that Robert Redford movie, the candidate where, you know, it's a wonderful
[01:38:42.060 --> 01:38:43.060]   movie at the end of it.
[01:38:43.060 --> 01:38:44.460]   They win.
[01:38:44.460 --> 01:38:46.460]   And Robert Redford goes, Oh crap.
[01:38:46.460 --> 01:38:47.460]   Now what?
[01:38:47.460 --> 01:38:49.260]   We got a cover.
[01:38:49.260 --> 01:38:52.860]   I started running for city council once many years ago, mainly because I wanted to raise
[01:38:52.860 --> 01:38:53.860]   some issues.
[01:38:53.860 --> 01:38:56.940]   And then I went to a city council meeting and they were literally talking about dog
[01:38:56.940 --> 01:38:57.940]   licenses.
[01:38:57.940 --> 01:39:01.700]   And I actually pulled out of the race because they had my God, I might win.
[01:39:01.700 --> 01:39:02.700]   It's so boring.
[01:39:02.700 --> 01:39:03.700]   I once.
[01:39:03.700 --> 01:39:08.020]   I used to be on the Petaluma Tech Committee, which was an official committee of the Petaluma
[01:39:08.020 --> 01:39:09.580]   city government.
[01:39:09.580 --> 01:39:12.460]   And it was the most painful process.
[01:39:12.460 --> 01:39:19.300]   I have such respect for people who can govern because it is very painful.
[01:39:19.300 --> 01:39:20.900]   I could not disagree more.
[01:39:20.900 --> 01:39:23.060]   And maybe this is because I used to be a journalist.
[01:39:23.060 --> 01:39:25.260]   My, I used to be a journalist too.
[01:39:25.260 --> 01:39:27.260]   I'm a journalist.
[01:39:27.260 --> 01:39:32.940]   Georgia, I would love to talk to you about this sometime that I feel like running for
[01:39:32.940 --> 01:39:39.820]   office makes you such a better person because for starters, like all of us in technology,
[01:39:39.820 --> 01:39:45.020]   we kind of, maybe this is just me, but I'm much more comfortable like in my electronic
[01:39:45.020 --> 01:39:46.020]   world.
[01:39:46.020 --> 01:39:47.020]   We're in our center.
[01:39:47.020 --> 01:39:48.020]   We're not outside.
[01:39:48.020 --> 01:39:49.540]   Yeah, I'm very in word focus.
[01:39:49.540 --> 01:39:55.420]   And it forces you to take a really hard inventory at yourself.
[01:39:55.420 --> 01:39:56.420]   What are my shortcomings?
[01:39:56.420 --> 01:39:58.300]   What am I good at?
[01:39:58.300 --> 01:39:59.620]   Where do I need to improve?
[01:39:59.620 --> 01:40:02.780]   How do I connect with people that aren't like me?
[01:40:02.780 --> 01:40:07.100]   Because you don't have that luxury of just saying, Oh, those people are dumb or whatever.
[01:40:07.100 --> 01:40:09.620]   Like you have to connect with people.
[01:40:09.620 --> 01:40:10.820]   That's the job.
[01:40:10.820 --> 01:40:18.660]   And I find I am genuinely interested in people that have problems that I don't like last
[01:40:18.660 --> 01:40:19.660]   weekend.
[01:40:19.660 --> 01:40:25.380]   I spent my weekend at a retirement home going and meeting senior citizens and kind of understanding
[01:40:25.380 --> 01:40:27.860]   what they need and what they're not getting.
[01:40:27.860 --> 01:40:33.980]   To me, that is it's a deeply interesting process because it's all about things I've just never
[01:40:33.980 --> 01:40:34.980]   thought about.
[01:40:34.980 --> 01:40:38.900]   I've never thought to myself, what happens after I can't drive anymore?
[01:40:38.900 --> 01:40:43.540]   Yeah, I need to go over to Walgreens to get basic stuff from my house.
[01:40:43.540 --> 01:40:44.860]   How do I get there?
[01:40:44.860 --> 01:40:50.180]   And I just I think running for office can make you a much better person than you are.
[01:40:50.180 --> 01:40:51.180]   Good for you.
[01:40:51.180 --> 01:40:52.180]   I'm glad you do it.
[01:40:52.180 --> 01:40:54.220]   It was just a wonderful thing.
[01:40:54.220 --> 01:40:58.100]   There's so many people that are lonely outside in the world and they're just hoping to connect.
[01:40:58.100 --> 01:41:03.300]   A lot of them that are exceptionally shy or have social anxiety head towards technology
[01:41:03.300 --> 01:41:06.340]   because it's a really easy way to do it.
[01:41:06.340 --> 01:41:10.420]   Like running for government or even finding something that you work for the community that's
[01:41:10.420 --> 01:41:14.780]   in your area is a really nice way that you can connect with other people and learn that
[01:41:14.780 --> 01:41:16.660]   people really aren't that scary.
[01:41:16.660 --> 01:41:21.900]   The unfortunate part to technology is that you often feel less safe with people in real
[01:41:21.900 --> 01:41:26.500]   life situations than the opposite to that and then you become more inclusive and more
[01:41:26.500 --> 01:41:28.260]   inside of your world.
[01:41:28.260 --> 01:41:31.220]   And it takes more of a toll, which can be really scary.
[01:41:31.220 --> 01:41:36.140]   But for you having to interact with people every single day and talking to people with
[01:41:36.140 --> 01:41:40.620]   very divergent views, that must have also made you feel much more open to differences
[01:41:40.620 --> 01:41:42.620]   that you may not have been open to before.
[01:41:42.620 --> 01:41:45.260]   Well, I think you've known me for a long time, George.
[01:41:45.260 --> 01:41:46.660]   I've got a lot of empathy.
[01:41:46.660 --> 01:41:53.140]   But I sort of got, I had the most amazing lunch this week.
[01:41:53.140 --> 01:41:57.940]   It was with the libertarian that ran for auditor here in Massachusetts.
[01:41:57.940 --> 01:41:59.300]   And I'm not a libertarian.
[01:41:59.300 --> 01:42:05.500]   I respect those views, but we sat down for two hours and had the most delightful lunch.
[01:42:05.500 --> 01:42:09.700]   Like, and we don't share a single view on anything.
[01:42:09.700 --> 01:42:16.020]   But it's really nice to develop those skills to be able to meet people where they are.
[01:42:16.020 --> 01:42:17.860]   And, you know, there it is.
[01:42:17.860 --> 01:42:18.860]   Someday.
[01:42:18.860 --> 01:42:19.860]   You're my next life.
[01:42:19.860 --> 01:42:22.020]   Well, I am a senior citizen.
[01:42:22.020 --> 01:42:26.380]   I'm hoping by the time I can't drive anymore, there can be a robotic car that will take you
[01:42:26.380 --> 01:42:27.380]   along the way.
[01:42:27.380 --> 01:42:28.380]   Yes.
[01:42:28.380 --> 01:42:29.380]   That's just around the corner.
[01:42:29.380 --> 01:42:30.380]   I think way more.
[01:42:30.380 --> 01:42:31.380]   I'm already starting that now.
[01:42:31.380 --> 01:42:32.380]   Sorry.
[01:42:32.380 --> 01:42:36.900]   They announced they're going to do a kind of Uber, self-driving car Uber in Phoenix and
[01:42:36.900 --> 01:42:38.700]   slowly roll out through the rest of the nation.
[01:42:38.700 --> 01:42:40.980]   If it's in Phoenix, there's a lot of retirees in Phoenix.
[01:42:40.980 --> 01:42:41.980]   Great place for it.
[01:42:41.980 --> 01:42:47.900]   Well, part of their business it looks like is going to be having companies like Walmart
[01:42:47.900 --> 01:42:58.140]   pay them to pick up and drive people to Walmart, have them shop, and then drive them home.
[01:42:58.140 --> 01:42:59.740]   Which is a very interesting business.
[01:42:59.740 --> 01:43:02.180]   So you have to game the system.
[01:43:02.180 --> 01:43:07.340]   Say you're going to Walmart, then you like meet someone there and then get driven home.
[01:43:07.340 --> 01:43:08.340]   Yeah.
[01:43:08.340 --> 01:43:12.660]   So we bought our Walmart once for lunch and we ended up spending a lot of money at Walmart.
[01:43:12.660 --> 01:43:15.140]   It was a bad idea.
[01:43:15.140 --> 01:43:17.820]   That's like I'm going to confess to a crime.
[01:43:17.820 --> 01:43:20.860]   One time I was at an SFO and I couldn't get an Uber to pick me up at the airport, but
[01:43:20.860 --> 01:43:24.180]   there was a bus that would take me to a hotel.
[01:43:24.180 --> 01:43:25.180]   And it was great.
[01:43:25.180 --> 01:43:27.660]   I got on the bus and it took me to the hotel with Closer to Home and I got an Uber really
[01:43:27.660 --> 01:43:28.660]   easily.
[01:43:28.660 --> 01:43:29.660]   Kind of like a Walmart car.
[01:43:29.660 --> 01:43:30.660]   That's really smart.
[01:43:30.660 --> 01:43:31.660]   That's really smart, Larry.
[01:43:31.660 --> 01:43:33.660]   I tipped the bus driver.
[01:43:33.660 --> 01:43:34.660]   I felt guilty.
[01:43:34.660 --> 01:43:38.300]   But we're also much more comfortable with self-driving cars.
[01:43:38.300 --> 01:43:48.700]   Like, since the AAA was doing a study where they said that in 2016 it's gone down, like
[01:43:48.700 --> 01:43:55.020]   15% people feel more comfortable by 15% from last year in a self-driving car.
[01:43:55.020 --> 01:43:57.220]   That's a big amount of people.
[01:43:57.220 --> 01:43:58.980]   You have a Tesla.
[01:43:58.980 --> 01:44:00.460]   You have the autopilot on your Tesla.
[01:44:00.460 --> 01:44:01.460]   Do you ever use that?
[01:44:01.460 --> 01:44:02.460]   No, but I have.
[01:44:02.460 --> 01:44:03.460]   It's practically self-driving.
[01:44:03.460 --> 01:44:04.460]   Yeah, I use it every time I drive.
[01:44:04.460 --> 01:44:05.460]   It's not really self-driving.
[01:44:05.460 --> 01:44:09.660]   It's just a kind of a better cruise control lane following mechanism.
[01:44:09.660 --> 01:44:12.820]   Well, do you have the new version that takes you actually from on-ramp to off-ramp?
[01:44:12.820 --> 01:44:15.380]   Nobody has that yet, but that's supposedly coming.
[01:44:15.380 --> 01:44:16.980]   Oh, I thought it without you.
[01:44:16.980 --> 01:44:18.460]   Well, maybe it is.
[01:44:18.460 --> 01:44:21.260]   I won't have it because I don't think I have hardware.
[01:44:21.260 --> 01:44:22.260]   Right hardware.
[01:44:22.260 --> 01:44:27.940]   Did you see that story this week about the guy that got control of the entire Tesla
[01:44:27.940 --> 01:44:28.940]   forum?
[01:44:28.940 --> 01:44:29.940]   Did you see that?
[01:44:29.940 --> 01:44:30.940]   The camera was on Twitter yesterday.
[01:44:30.940 --> 01:44:32.580]   Yeah, the exact site, right?
[01:44:32.580 --> 01:44:33.740]   No, no, no.
[01:44:33.740 --> 01:44:35.340]   This is a guy that bought a Tesla.
[01:44:35.340 --> 01:44:39.860]   He was one of the people that had huge delivery issues.
[01:44:39.860 --> 01:44:44.460]   He was trying to talk on the forums to people about that, and they would only lamppost one
[01:44:44.460 --> 01:44:46.100]   thing a day.
[01:44:46.100 --> 01:44:51.660]   He wrote to them and said, "Can you please classify my account as being an owner?"
[01:44:51.660 --> 01:44:52.660]   They said, "Okay."
[01:44:52.660 --> 01:44:57.300]   The IT department made him the owner of the entire forum.
[01:44:57.300 --> 01:44:58.300]   Of the account.
[01:44:58.300 --> 01:44:59.300]   Oh, okay.
[01:44:59.300 --> 01:45:03.380]   But could he hack the Tesla's while he was at it?
[01:45:03.380 --> 01:45:04.380]   Maybe then.
[01:45:04.380 --> 01:45:05.380]   No.
[01:45:05.380 --> 01:45:08.660]   He could go on and order superchargers to be starting a stream.
[01:45:08.660 --> 01:45:09.660]   Wow.
[01:45:09.660 --> 01:45:14.420]   Did you notice the last time Elon Musk logged in was more than three years ago.
[01:45:14.420 --> 01:45:15.420]   Yes.
[01:45:15.420 --> 01:45:20.900]   I mean, have you had customer service nightmares with yours like that?
[01:45:20.900 --> 01:45:21.980]   Not in the least.
[01:45:21.980 --> 01:45:24.540]   My experience has been nothing but great.
[01:45:24.540 --> 01:45:25.540]   I don't know.
[01:45:25.540 --> 01:45:27.540]   I probably know you're on the show.
[01:45:27.540 --> 01:45:28.540]   No, no, no.
[01:45:28.540 --> 01:45:29.540]   Be nice to you.
[01:45:29.540 --> 01:45:30.540]   You know what?
[01:45:30.540 --> 01:45:35.020]   I thought that I would get some special treatment because Jason Callican has said, "I'll mention
[01:45:35.020 --> 01:45:37.020]   to Elon that you try to get it."
[01:45:37.020 --> 01:45:38.020]   Nothing.
[01:45:38.020 --> 01:45:39.020]   I got nothing.
[01:45:39.020 --> 01:45:40.020]   Nothing.
[01:45:40.020 --> 01:45:41.020]   Nothing.
[01:45:41.020 --> 01:45:42.020]   But it's I like my Tesla.
[01:45:42.020 --> 01:45:43.020]   I'm a happy Tesla.
[01:45:43.020 --> 01:45:45.820]   I'm going to buy another one in a couple of years.
[01:45:45.820 --> 01:45:47.580]   I want to get a Model 3.
[01:45:47.580 --> 01:45:49.020]   We should probably talk about tech.
[01:45:49.020 --> 01:45:53.900]   Just briefly, I don't want to distract you guys.
[01:45:53.900 --> 01:45:55.900]   This is kind of people expected of us.
[01:45:55.900 --> 01:45:57.700]   Isn't this week in psychology?
[01:45:57.700 --> 01:45:58.700]   I'm sorry, Adrian.
[01:45:58.700 --> 01:45:59.700]   I'm sure.
[01:45:59.700 --> 01:46:00.700]   I'm very...
[01:46:00.700 --> 01:46:01.940]   No, not at all.
[01:46:01.940 --> 01:46:05.900]   I feel like I've learned a lot and that's been very good.
[01:46:05.900 --> 01:46:07.460]   I don't want to speak for our audience.
[01:46:07.460 --> 01:46:09.900]   They may be very happy, but I just...
[01:46:09.900 --> 01:46:11.540]   It is this week in tech and I thought, "Maybe."
[01:46:11.540 --> 01:46:12.540]   Just hold on for a second.
[01:46:12.540 --> 01:46:13.540]   We'll talk about tech.
[01:46:13.540 --> 01:46:14.540]   How about that when we come back?
[01:46:14.540 --> 01:46:15.540]   Okay.
[01:46:15.540 --> 01:46:16.540]   I showed it.
[01:46:16.540 --> 01:46:17.460]   They brought to you by WordPress.
[01:46:17.460 --> 01:46:21.860]   When I abandoned all those social networks, I did it thinking, "I'm going to blog more."
[01:46:21.860 --> 01:46:25.380]   I have and I love it because I'm on WordPress.com.
[01:46:25.380 --> 01:46:30.260]   I got my badge, my 12-year badge a couple of months ago on the WordPress app.
[01:46:30.260 --> 01:46:32.700]   That's how long I've been at WordPress.com.
[01:46:32.700 --> 01:46:36.380]   You want to see my WordPress blog, go to leoloport.com.
[01:46:36.380 --> 01:46:38.340]   I love it because it's mine.
[01:46:38.340 --> 01:46:44.940]   When I upload photos or videos or content, I just posted that picture I was showing you.
[01:46:44.940 --> 01:46:47.340]   To WordPress, I own it.
[01:46:47.340 --> 01:46:48.340]   I own it.
[01:46:48.340 --> 01:46:49.340]   It's mine.
[01:46:49.340 --> 01:46:52.980]   I can upload, but I can also download images.
[01:46:52.980 --> 01:46:55.980]   No one can say, "Hey, we don't like what you're doing.
[01:46:55.980 --> 01:46:57.460]   We're going to shut you down."
[01:46:57.460 --> 01:46:58.780]   It's not Mark Zuckerberg's.
[01:46:58.780 --> 01:47:00.460]   It's not Jack Dorsey's.
[01:47:00.460 --> 01:47:03.860]   It's my site, my home, my content.
[01:47:03.860 --> 01:47:08.860]   Every single person in this world, especially if you're a young person, you've got to have
[01:47:08.860 --> 01:47:10.020]   your own site.
[01:47:10.020 --> 01:47:15.300]   You've got to have a place that you can tweet, you can Facebook, you can Instagram, you can
[01:47:15.300 --> 01:47:19.700]   Snapchat, but you have to have a place it links back to, that you own, you control, that
[01:47:19.700 --> 01:47:20.700]   when people...
[01:47:20.700 --> 01:47:24.180]   It's the thing to think about, what are people going to find when they Google your name?
[01:47:24.180 --> 01:47:29.500]   You want to have control of that because if you don't, someone else does.
[01:47:29.500 --> 01:47:33.580]   Someone else gets to put up the video if you're having a good time the other night with your
[01:47:33.580 --> 01:47:35.020]   pants on your head.
[01:47:35.020 --> 01:47:38.460]   You don't want that to be what shows up when you Google your name.
[01:47:38.460 --> 01:47:39.900]   You want your great WordPress site.
[01:47:39.900 --> 01:47:42.100]   This goes double for a business.
[01:47:42.100 --> 01:47:43.580]   Every business.
[01:47:43.580 --> 01:47:44.580]   So important.
[01:47:44.580 --> 01:47:46.980]   Control your reputation online.
[01:47:46.980 --> 01:47:51.580]   What up a site that shows your business, that tells people what your hours are, your prices
[01:47:51.580 --> 01:47:54.220]   are, a blog from the owner that...
[01:47:54.220 --> 01:47:56.780]   If you're a plumber, talk about plumbing tips.
[01:47:56.780 --> 01:48:00.340]   If you're a website designer, talk about website designing tips.
[01:48:00.340 --> 01:48:04.340]   You don't have to worry about the hosting, the security, the software updates.
[01:48:04.340 --> 01:48:05.940]   WordPress does all that for you.
[01:48:05.940 --> 01:48:07.140]   There's no hassle.
[01:48:07.140 --> 01:48:08.660]   You do the content.
[01:48:08.660 --> 01:48:10.540]   They'll take care of the rest.
[01:48:10.540 --> 01:48:11.940]   I love the WordPress app.
[01:48:11.940 --> 01:48:14.700]   That's what we use to post as we are traveling around the world.
[01:48:14.700 --> 01:48:16.180]   I mean, it's so easy to do.
[01:48:16.180 --> 01:48:21.420]   I can also use a WordPress app to check comments, to block comments from spammers, to approve.
[01:48:21.420 --> 01:48:24.380]   I always have it so I approve comments and it makes it a great site.
[01:48:24.380 --> 01:48:25.940]   My comments are great.
[01:48:25.940 --> 01:48:29.980]   The people who are part of my WordPress site, I follow them.
[01:48:29.980 --> 01:48:30.980]   They follow me.
[01:48:30.980 --> 01:48:31.980]   It's just fantastic.
[01:48:31.980 --> 01:48:36.260]   It's a real social network and such a great way to build customers.
[01:48:36.260 --> 01:48:40.860]   They have built-in search engine optimization, social media linking so your customers and
[01:48:40.860 --> 01:48:44.500]   readers can link to their Facebook and Twitter, your content.
[01:48:44.500 --> 01:48:46.220]   This started just $4 a month.
[01:48:46.220 --> 01:48:51.020]   It's actually cost me less than when I used to host it myself and boy, it's a lot less
[01:48:51.020 --> 01:48:52.020]   headache.
[01:48:52.020 --> 01:48:56.100]   You can launch your website with confidence because you can get help from the 24-hour,
[01:48:56.100 --> 01:48:59.460]   seven-day-a-week support team whenever you need it.
[01:48:59.460 --> 01:49:03.700]   There's a real reason why 32 percent of all the websites in the world run on WordPress.
[01:49:03.700 --> 01:49:04.700]   It's the best.
[01:49:04.700 --> 01:49:06.460]   Did you hear me right?
[01:49:06.460 --> 01:49:07.620]   That's the number.
[01:49:07.620 --> 01:49:12.860]   One-third, almost one-third of all the websites in the world are running on WordPress.
[01:49:12.860 --> 01:49:13.860]   Yours should too.
[01:49:13.860 --> 01:49:15.900]   WordPress.com/twit.
[01:49:15.900 --> 01:49:19.580]   By the way, when you go there, you're going to save.
[01:49:19.580 --> 01:49:24.580]   We're going to give you a little bit of a 15 percent discount on your new plan purchase.
[01:49:24.580 --> 01:49:26.700]   Definitely, take that route.
[01:49:26.700 --> 01:49:29.700]   WordPress.com/twit.
[01:49:29.700 --> 01:49:31.180]   WordPress.com/twit.
[01:49:31.180 --> 01:49:33.980]   We thank them so much for their support.
[01:49:33.980 --> 01:49:39.180]   If I didn't have your email address, I put my postcards on my WordPress blog so you would
[01:49:39.180 --> 01:49:42.460]   get my endless postcards.
[01:49:42.460 --> 01:49:43.820]   That's what I did.
[01:49:43.820 --> 01:49:44.820]   That's the way to do it.
[01:49:44.820 --> 01:49:46.620]   I just love WordPress.
[01:49:46.620 --> 01:49:47.620]   Okay.
[01:49:47.620 --> 01:49:48.620]   Okay.
[01:49:48.620 --> 01:49:49.620]   Tech.
[01:49:49.620 --> 01:49:51.660]   How about this?
[01:49:51.660 --> 01:49:59.260]   Amazon selects New York City, well, not Queens, and Northern Virginia for its new headquarters.
[01:49:59.260 --> 01:50:06.060]   Actually, I don't know if you guys saw Steve Carella as Jeff Bezos on Saturday Night Live
[01:50:06.060 --> 01:50:08.060]   on Saturday Night last night.
[01:50:08.060 --> 01:50:15.420]   He said, "It's all trolling Donald Trump because it's in his birthplace, Queens, and
[01:50:15.420 --> 01:50:19.180]   just outside of Arlington National Cemetery in Nova."
[01:50:19.180 --> 01:50:20.580]   I don't think that's the reason.
[01:50:20.580 --> 01:50:26.060]   A little upset from cities that bid for it saying, "Hey, we thought you were going to
[01:50:26.060 --> 01:50:31.580]   be a more open process," and instead you chose the obvious spots.
[01:50:31.580 --> 01:50:32.580]   Anything to say about?
[01:50:32.580 --> 01:50:33.580]   I guess not.
[01:50:33.580 --> 01:50:34.580]   Go ahead.
[01:50:34.580 --> 01:50:38.700]   This was very close to coming to Boston.
[01:50:38.700 --> 01:50:40.820]   At first, I was really for this.
[01:50:40.820 --> 01:50:42.500]   I have a really good friend of mine.
[01:50:42.500 --> 01:50:47.100]   She went to college in Mississippi like I did, and she moved to Seattle.
[01:50:47.100 --> 01:50:50.140]   Amazon has been very good to her.
[01:50:50.140 --> 01:50:52.220]   She works on the AWS team.
[01:50:52.220 --> 01:50:56.260]   She's not particularly technical person, but she makes enough money to own a house and
[01:50:56.260 --> 01:50:59.140]   have a family and they can get good healthcare.
[01:50:59.140 --> 01:51:00.140]   Right.
[01:51:00.140 --> 01:51:06.660]   At first, I was very much for this, and then I started looking more closely at what the
[01:51:06.660 --> 01:51:09.700]   impact has been to Seattle.
[01:51:09.700 --> 01:51:15.380]   Here in Boston, we have really, really, really bad mass public transit, and we also have an
[01:51:15.380 --> 01:51:21.740]   affordable housing crisis because we're, I think, the third or fourth most expensive
[01:51:21.740 --> 01:51:24.260]   market in the entire country.
[01:51:24.260 --> 01:51:27.780]   I was very glad to see that we didn't come here.
[01:51:27.780 --> 01:51:29.020]   It didn't come here.
[01:51:29.020 --> 01:51:35.500]   I'm not like an anti-business kind of Democrat, but I do think you need to factor in the total
[01:51:35.500 --> 01:51:36.660]   cost of the community.
[01:51:36.660 --> 01:51:40.340]   I think Amazon also was considering the cost of housing.
[01:51:40.340 --> 01:51:41.340]   Absolutely.
[01:51:41.340 --> 01:51:42.340]   Right.
[01:51:42.340 --> 01:51:43.340]   Absolutely.
[01:51:43.340 --> 01:51:46.020]   There have been pushback in New York, and I think in Northern Virginia as well, from
[01:51:46.020 --> 01:51:51.660]   people who are questioning whether what Amazon got in terms of incentive and tax kickback
[01:51:51.660 --> 01:51:53.460]   is really worth it to the community.
[01:51:53.460 --> 01:51:54.460]   What is it?
[01:51:54.460 --> 01:51:55.460]   50 million.
[01:51:55.460 --> 01:51:56.460]   Some huge amount.
[01:51:56.460 --> 01:51:58.460]   Of course, the other thing, Brandon, I'll tell you somebody.
[01:51:58.460 --> 01:51:59.460]   1.5 billion.
[01:51:59.460 --> 01:52:01.660]   Sorry, I underestimated it.
[01:52:01.660 --> 01:52:02.660]   Wow.
[01:52:02.660 --> 01:52:07.100]   We think in Silicon Valley, it's impossible to get between Palo Alto and San Francisco
[01:52:07.100 --> 01:52:11.980]   in under two hours anywhere around rush hour because of all the successful tech companies,
[01:52:11.980 --> 01:52:16.500]   which is great that we've got all this prosperity in the area, but it's had a huge impact on
[01:52:16.500 --> 01:52:18.340]   people's lives, not always good.
[01:52:18.340 --> 01:52:25.540]   Don't you think, though, that certainly Queens can absorb another 55,000 people without too
[01:52:25.540 --> 01:52:27.100]   much impact?
[01:52:27.100 --> 01:52:31.820]   I don't know about Nova, but I think Nova probably can too.
[01:52:31.820 --> 01:52:34.620]   I mean, probably more easily than Boston certainly comes.
[01:52:34.620 --> 01:52:37.620]   I think it makes more sense.
[01:52:37.620 --> 01:52:40.500]   I'm glad we're having this conversation about it.
[01:52:40.500 --> 01:52:46.500]   I think people are very correct to ask why we can spend $1.5 billion on Amazon and not
[01:52:46.500 --> 01:52:48.780]   fix public transportation in New York.
[01:52:48.780 --> 01:52:51.620]   I think that's a fair question.
[01:52:51.620 --> 01:52:59.580]   That said, Amazon has brought good jobs to people I know and care about.
[01:52:59.580 --> 01:53:00.580]   These things are simple.
[01:53:00.580 --> 01:53:01.580]   They're complicated.
[01:53:01.580 --> 01:53:02.820]   I think you can make a strong case.
[01:53:02.820 --> 01:53:05.100]   It's going to improve the tax base.
[01:53:05.100 --> 01:53:07.740]   It's going to provide jobs.
[01:53:07.740 --> 01:53:11.740]   That's as important as fixing the traffic problems.
[01:53:11.740 --> 01:53:15.060]   It's not like it's all or nothing on any of that stuff.
[01:53:15.060 --> 01:53:20.660]   Now, in Toronto, and I'd like to your opinion on this, George Adao, a key side, which is
[01:53:20.660 --> 01:53:28.180]   on the waterfront, Alphabet has purchased 12 acres to create a smart city.
[01:53:28.180 --> 01:53:33.580]   Actually, the Intercept calls it a smart city of surveillance.
[01:53:33.580 --> 01:53:36.420]   It's a joint government effort.
[01:53:36.420 --> 01:53:42.260]   The government agency is Waterfront Toronto and Google's Sidewalk Labs.
[01:53:42.260 --> 01:53:45.820]   They're going to build the city from the ground up.
[01:53:45.820 --> 01:53:48.740]   Are you familiar with this in the controversy over at Georgia?
[01:53:48.740 --> 01:53:58.540]   Yeah, I talk about Google got rid of the "don't be evil" and they just went with "be creepy."
[01:53:58.540 --> 01:54:00.580]   People are talking about it.
[01:54:00.580 --> 01:54:04.620]   One of those things that they really like pushing, if you take a look on the site, you
[01:54:04.620 --> 01:54:11.500]   can see all of these really high-marketed about how this is going to be amazing.
[01:54:11.500 --> 01:54:14.300]   This is going to have accessible public services.
[01:54:14.300 --> 01:54:19.380]   It's going to be all wonderful and fabulous and you're not going to have any more problems
[01:54:19.380 --> 01:54:23.380]   with self-driving cars and no traffic and everything is going to happen.
[01:54:23.380 --> 01:54:28.060]   But then you take a look at all of the other systems where it talks about having an identity
[01:54:28.060 --> 01:54:33.660]   manager system and asking people that want to work for the company about what do you
[01:54:33.660 --> 01:54:39.460]   think about elections in Canada and how are they going to change with time.
[01:54:39.460 --> 01:54:45.020]   Their lack of transparency in how they're going to be dealing with this is really very
[01:54:45.020 --> 01:54:47.100]   scary.
[01:54:47.100 --> 01:54:50.980]   It's like one of those, they try to make it this utopian thought of green-roofed condos
[01:54:50.980 --> 01:54:58.340]   and rainbows and unicorns where really it's like this dystopian or well-ian thought of
[01:54:58.340 --> 01:55:05.540]   how now Google is going to be tracking everything you do when you use your cards, when you go
[01:55:05.540 --> 01:55:07.860]   to the hospital.
[01:55:07.860 --> 01:55:13.140]   The weird thing for this is that when you use an application, at least you have those terms
[01:55:13.140 --> 01:55:17.540]   and services that no one reads that you have to then give up all of your rights for.
[01:55:17.540 --> 01:55:20.220]   How do you do that for a city?
[01:55:20.220 --> 01:55:24.820]   You just suddenly go into there and now they're tracking you because they own this part of
[01:55:24.820 --> 01:55:25.820]   the city.
[01:55:25.820 --> 01:55:26.820]   But how clear is that?
[01:55:26.820 --> 01:55:32.100]   Do you have to swipe a card or use your fingerprints so that you can go in?
[01:55:32.100 --> 01:55:34.300]   It's scary to me.
[01:55:34.300 --> 01:55:40.220]   There's a precedent for this. Disney created a place called Celebration in Florida, which
[01:55:40.220 --> 01:55:45.140]   was a Disney-designed city.
[01:55:45.140 --> 01:55:50.180]   They eventually got out of it.
[01:55:50.180 --> 01:55:58.220]   On the one hand, I understand this is a really good example of how technocrats think about
[01:55:58.220 --> 01:56:02.500]   politics in the world.
[01:56:02.500 --> 01:56:06.460]   Not wrong necessarily that technology can solve a lot of problems.
[01:56:06.460 --> 01:56:11.340]   If we only had full, Larry Page said, "I wish we were on an island."
[01:56:11.340 --> 01:56:14.260]   We didn't have this government interference then.
[01:56:14.260 --> 01:56:17.300]   Remember that when he said that in Google I/O?
[01:56:17.300 --> 01:56:24.980]   They feel like if we just let us handle this, we can make a utopia.
[01:56:24.980 --> 01:56:30.460]   All these government regulations, just get in the way, all these zoning restrictions,
[01:56:30.460 --> 01:56:32.300]   privacy restrictions.
[01:56:32.300 --> 01:56:35.300]   On the one hand, I understand why Toronto might want to try it.
[01:56:35.300 --> 01:56:38.220]   It's only a small part of the waterfront.
[01:56:38.220 --> 01:56:44.580]   It's part that's not very attractive, industrial.
[01:56:44.580 --> 01:56:45.660]   There's some interesting stuff here.
[01:56:45.660 --> 01:56:46.660]   It's not all of Toronto.
[01:56:46.660 --> 01:56:51.740]   Toronto is a very diverse and lovely city because of its diversity.
[01:56:51.740 --> 01:56:54.260]   It's got not one but two Chinatowns.
[01:56:54.260 --> 01:56:57.300]   It's an amazing city.
[01:56:57.300 --> 01:57:02.900]   What if 12 acres is devoted to this experiment?
[01:57:02.900 --> 01:57:04.700]   It's the transparency though.
[01:57:04.700 --> 01:57:06.900]   It was not done transparently.
[01:57:06.900 --> 01:57:10.500]   People had to fight so that they could actually find out what was happening in the first sets
[01:57:10.500 --> 01:57:16.300]   of terms of service or whatever contract that they had set up with Google.
[01:57:16.300 --> 01:57:22.180]   They weren't like every time that the politicians and the people for the company were asked about
[01:57:22.180 --> 01:57:23.180]   it.
[01:57:23.180 --> 01:57:26.740]   They wouldn't say what would happen with the data, who would have access to it, what type
[01:57:26.740 --> 01:57:29.500]   of data would be tracked to that.
[01:57:29.500 --> 01:57:33.340]   They didn't start from this place of being exceptionally transparent and telling us what
[01:57:33.340 --> 01:57:35.660]   was going to happen and what wasn't going to happen.
[01:57:35.660 --> 01:57:38.140]   They only did that under duress.
[01:57:38.140 --> 01:57:40.340]   That always is that little red flag of life.
[01:57:40.340 --> 01:57:45.500]   What if only people, it's like celebration, only people who wanted to live in the Google
[01:57:45.500 --> 01:57:48.340]   world moved there and gave their permission.
[01:57:48.340 --> 01:57:50.140]   What if you're born there?
[01:57:50.140 --> 01:57:52.260]   You get a G-Della dress like a birth certificate?
[01:57:52.260 --> 01:57:53.260]   That's different.
[01:57:53.260 --> 01:57:55.860]   Now, this area is off-limits.
[01:57:55.860 --> 01:58:00.380]   This is now for only special people that get to use that.
[01:58:00.380 --> 01:58:01.380]   I don't know.
[01:58:01.380 --> 01:58:05.220]   I think that they chose Toronto because Canadians are known for being a little bit more complacent
[01:58:05.220 --> 01:58:06.220]   and easy going.
[01:58:06.220 --> 01:58:07.220]   Sorry to say.
[01:58:07.220 --> 01:58:10.220]   What happens if you're born there?
[01:58:10.220 --> 01:58:13.060]   You get a Google issue birth certificate?
[01:58:13.060 --> 01:58:16.060]   No, you're still a Canadian.
[01:58:16.060 --> 01:58:21.860]   When you're a baby, you sign the term the service of your finger.
[01:58:21.860 --> 01:58:22.860]   You have to.
[01:58:22.860 --> 01:58:25.300]   Dual citizenship in Google world.
[01:58:25.300 --> 01:58:32.180]   I do want to say, is someone that sat on a lot of local government meetings and commissions
[01:58:32.180 --> 01:58:40.420]   lately, I do think there is a role to play with technology working better with local municipalities.
[01:58:40.420 --> 01:58:46.660]   We were talking about automated vehicles earlier in the show.
[01:58:46.660 --> 01:58:50.860]   Something I didn't really think about until I started running for office is people with
[01:58:50.860 --> 01:58:53.220]   mobility issues.
[01:58:53.220 --> 01:58:56.140]   How much they're going to be relying on this?
[01:58:56.140 --> 01:59:01.820]   That's going to require things like zoning certain lanes to drop in, pick up passengers.
[01:59:01.820 --> 01:59:05.700]   We need to start thinking about the protocol for how we design roads.
[01:59:05.700 --> 01:59:12.420]   We want to put sensors on the side of it to give an auxiliary warning beyond camera
[01:59:12.420 --> 01:59:16.340]   data and GPS data about where the edges of where you can drive are.
[01:59:16.340 --> 01:59:20.780]   There are issues that we need to start working with cities on.
[01:59:20.780 --> 01:59:26.900]   One of my issues, I think the intercept where the story comes from, I think it's a good,
[01:59:26.900 --> 01:59:29.100]   they do good journalism overall.
[01:59:29.100 --> 01:59:33.060]   But Leo, as you're doing stories on Twitch, something I've always noticed is you take
[01:59:33.060 --> 01:59:36.260]   a second and you think about the other side and you give it.
[01:59:36.260 --> 01:59:42.860]   I find the intercept to be so reactionary that they really don't try to get another.
[01:59:42.860 --> 01:59:46.780]   They've decided how they feel going in and they do really good investigative journalism
[01:59:46.780 --> 01:59:47.780]   on it.
[01:59:47.780 --> 01:59:55.140]   I think this idea could be done well with oversight and with permission from the community.
[01:59:55.140 --> 01:59:56.140]   But I would agree with you.
[01:59:56.140 --> 01:59:57.540]   It was handled very poorly here.
[01:59:57.540 --> 02:00:02.900]   Well, let me give you the other side from an opinion piece in the Globe and Mail by David
[02:00:02.900 --> 02:00:10.580]   Frazier, who is a privacy lawyer that was hired by sidewalk labs to, he says, navigate
[02:00:10.580 --> 02:00:14.460]   the intricacies of Canadian privacy law.
[02:00:14.460 --> 02:00:20.220]   He points out, he says, the questions about privacy didn't begin with sidewalk labs.
[02:00:20.220 --> 02:00:24.980]   Most Canadian cities, and by the way, this is true in England too and I suspect true
[02:00:24.980 --> 02:00:30.020]   in the US, are full of sensors and we have no idea what's there, what they do, what
[02:00:30.020 --> 02:00:31.380]   data they collect.
[02:00:31.380 --> 02:00:36.580]   Each municipality that puts in those sensors is convinced they comply with the law, but
[02:00:36.580 --> 02:00:38.420]   they're not transparent.
[02:00:38.420 --> 02:00:40.340]   There's little accountability.
[02:00:40.340 --> 02:00:45.780]   He says, what we're doing at sidewalk is much more transparent and accountable than the norm
[02:00:45.780 --> 02:00:47.860]   in Canada.
[02:00:47.860 --> 02:00:50.900]   He reassures people, just wait, watch.
[02:00:50.900 --> 02:00:52.700]   Of course, this is a legitimate concern.
[02:00:52.700 --> 02:00:58.700]   That's why I as a privacy advocate was hired by Google.
[02:00:58.700 --> 02:01:03.140]   We think we're going to do it right and you hold us to a high standard.
[02:01:03.140 --> 02:01:05.420]   I think that that's another way to look at it.
[02:01:05.420 --> 02:01:09.340]   He says a lot of the data that they're talking about is things like weather data, pollution
[02:01:09.340 --> 02:01:15.860]   data, pollen count data, traffic counts, energy consumption, recyclables and things like that,
[02:01:15.860 --> 02:01:19.540]   not necessarily personal data.
[02:01:19.540 --> 02:01:22.820]   I think it's reasonable to be concerned.
[02:01:22.820 --> 02:01:23.820]   I think you're right.
[02:01:23.820 --> 02:01:30.140]   The intercept is a little knee jerk sometimes in these issues.
[02:01:30.140 --> 02:01:32.580]   There's both sides of it.
[02:01:32.580 --> 02:01:36.900]   I'm not going to move to celebration Florida because I don't want to live in Disney's
[02:01:36.900 --> 02:01:37.900]   world.
[02:01:37.900 --> 02:01:40.700]   It's truly dystopian.
[02:01:40.700 --> 02:01:46.420]   At the same time, I think it's interesting to hear at least attempts.
[02:01:46.420 --> 02:01:50.100]   This is really the problem we have in general, which is that I think Silicon Valley has a
[02:01:50.100 --> 02:01:53.340]   certain arrogance.
[02:01:53.340 --> 02:01:59.340]   Technocrats in general have a certain arrogance about A and I'm going to say our intelligence
[02:01:59.340 --> 02:02:01.540]   and our ability to solve these problems.
[02:02:01.540 --> 02:02:07.140]   We look at politicians and I did this on the committee and it's such a slow, arduous process.
[02:02:07.140 --> 02:02:08.300]   Let's just cut through this.
[02:02:08.300 --> 02:02:10.420]   I know what we should do.
[02:02:10.420 --> 02:02:14.780]   I had that experience serving on that digital committee in the city of Petaluma.
[02:02:14.780 --> 02:02:17.300]   It was a real pain in the butt.
[02:02:17.300 --> 02:02:22.220]   This conference I went to in the first conference I went to in Paris where Justin Trudeau spoke
[02:02:22.220 --> 02:02:24.220]   was actually called the GovTech Forum.
[02:02:24.220 --> 02:02:28.980]   It was all about European companies and European governments getting together to try to figure
[02:02:28.980 --> 02:02:31.860]   out how tech could make cities better and smarter.
[02:02:31.860 --> 02:02:39.460]   Things like a smart bench, maybe at a bus stop that had solar and had Wi-Fi and had information
[02:02:39.460 --> 02:02:43.900]   that was provided to citizens that would be in public spaces.
[02:02:43.900 --> 02:02:48.540]   There are some very cool things I think that tech can do to make cities better, but I'm
[02:02:48.540 --> 02:02:52.500]   a little nervous about the idea of a tech essentially owning the city or owning even
[02:02:52.500 --> 02:02:53.940]   a big chunk of the city.
[02:02:53.940 --> 02:02:55.740]   Maybe it should be a cooperative thing.
[02:02:55.740 --> 02:02:56.740]   Having them in an awful way.
[02:02:56.740 --> 02:02:57.740]   Exactly.
[02:02:57.740 --> 02:02:58.740]   It's a problem.
[02:02:58.740 --> 02:03:02.340]   Google has already done some great things for public spaces.
[02:03:02.340 --> 02:03:06.580]   There are free Wi-Fi and large amounts of mountain view, things of that nature that
[02:03:06.580 --> 02:03:07.900]   I think can be encouraged.
[02:03:07.900 --> 02:03:16.340]   Do you think that the example offered by Code for America or the US Digital Service is a
[02:03:16.340 --> 02:03:22.260]   good example of a public-private partnership to improve government transparency, government
[02:03:22.260 --> 02:03:28.260]   services with the best technology, but not independently, but not set up an independent
[02:03:28.260 --> 02:03:31.220]   government, but to work to make government work better for everybody.
[02:03:31.220 --> 02:03:32.500]   I think that's a good model.
[02:03:32.500 --> 02:03:34.340]   Yeah, they've done very good work.
[02:03:34.340 --> 02:03:36.500]   My friends mind the work there.
[02:03:36.500 --> 02:03:37.780]   They're doing the right thing.
[02:03:37.780 --> 02:03:42.260]   Matt Katsu is of course the acting director and has been for the last two years.
[02:03:42.260 --> 02:03:43.260]   Yeah.
[02:03:43.260 --> 02:03:44.980]   He's a great guy and he's been on the show many times.
[02:03:44.980 --> 02:03:49.220]   I think that they really, this is an example of doing a good job.
[02:03:49.220 --> 02:03:50.700]   Yeah, definitely.
[02:03:50.700 --> 02:03:56.380]   Making things better.
[02:03:56.380 --> 02:03:59.260]   Julian Assange.
[02:03:59.260 --> 02:04:00.260]   My friend Julian.
[02:04:00.260 --> 02:04:07.620]   Speaking of the intercept, right, Julian Assange, the creator of WikiLeaks apparently
[02:04:07.620 --> 02:04:11.220]   has been charged by the US government under seal.
[02:04:11.220 --> 02:04:20.260]   No one knew about this, but in a filing in an unrelated case, it came out in Washington
[02:04:20.260 --> 02:04:22.620]   Post got the story.
[02:04:22.620 --> 02:04:26.740]   He's been charged under seal prosecutors inadvertently revealed in a recently unsealed
[02:04:26.740 --> 02:04:29.340]   court filing.
[02:04:29.340 --> 02:04:34.860]   He's charged with, I guess, cooperating with the Russian government.
[02:04:34.860 --> 02:04:38.420]   I have very mixed feelings about this.
[02:04:38.420 --> 02:04:44.260]   On the, you know, we know that people like Roger Stone and others went to Julian, perhaps
[02:04:44.260 --> 02:04:50.140]   enlisted his help in publishing emails from the DNC that had been hacked by the Russians
[02:04:50.140 --> 02:04:53.300]   to undermine Clinton's campaign.
[02:04:53.300 --> 02:04:58.820]   On the other hand, I think WikiLeaks is in other cases done really good work.
[02:04:58.820 --> 02:05:04.780]   Governments hate things like revealing the US drone program.
[02:05:04.780 --> 02:05:09.580]   What do you, I don't know what to think about this one.
[02:05:09.580 --> 02:05:15.460]   I'm always amazed when people, when court cases are getting adjudicated and people want
[02:05:15.460 --> 02:05:19.140]   to make up their minds about it before any facts come to light.
[02:05:19.140 --> 02:05:21.260]   We don't even know what the charges are.
[02:05:21.260 --> 02:05:22.900]   We just know that he has been charged.
[02:05:22.900 --> 02:05:28.020]   And by the way, in this post piece, they mentioned that the Obama administration, remember Barack
[02:05:28.020 --> 02:05:33.940]   Obama was furious, really mad at Julian Assange as he was at Edward Snowden.
[02:05:33.940 --> 02:05:39.140]   But the Justice Department concluded, according to the post, that pursuing Assange would be
[02:05:39.140 --> 02:05:44.820]   akin to prosecuting a news organization, have a chilling effect on the First Amendment.
[02:05:44.820 --> 02:05:45.820]   Right.
[02:05:45.820 --> 02:05:46.820]   Yeah.
[02:05:46.820 --> 02:05:50.940]   I want to see the facts of the case come to light.
[02:05:50.940 --> 02:05:52.660]   I want to see what's going on there.
[02:05:52.660 --> 02:05:54.340]   And I think you said it perfectly, Leah.
[02:05:54.340 --> 02:05:55.500]   Like there are things they've done.
[02:05:55.500 --> 02:05:56.820]   They're very good.
[02:05:56.820 --> 02:06:01.500]   There are grave concerns to have about WikiLeaks and who's funding it and how they're getting
[02:06:01.500 --> 02:06:03.020]   information out there.
[02:06:03.020 --> 02:06:09.500]   I think there is reasonable suspicion that WikiLeaks does have some ties to the Kremlin.
[02:06:09.500 --> 02:06:11.140]   I think that's a fear.
[02:06:11.140 --> 02:06:12.660]   There's reasonable to have.
[02:06:12.660 --> 02:06:16.420]   And I look forward to the facts of this case coming to light.
[02:06:16.420 --> 02:06:18.420]   Very politically well spoken.
[02:06:18.420 --> 02:06:22.740]   People think that's like BS, but the truth is like-
[02:06:22.740 --> 02:06:23.740]   That's the right answer.
[02:06:23.740 --> 02:06:27.140]   It's just not a satisfying answer for people who want you to pick a side.
[02:06:27.140 --> 02:06:28.140]   Right.
[02:06:28.140 --> 02:06:33.020]   Well, like Avonade this week, you know, like he got a rest down some really very serious
[02:06:33.020 --> 02:06:34.020]   charges.
[02:06:34.020 --> 02:06:40.300]   Now, I don't know this man, but you know, being I also want used to be a crime reporter,
[02:06:40.300 --> 02:06:43.500]   I've seen people get charged with things and they look into the facts.
[02:06:43.500 --> 02:06:44.580]   It doesn't play out.
[02:06:44.580 --> 02:06:45.780]   Like it's just reality.
[02:06:45.780 --> 02:06:49.100]   We've got to wait to see what comes out in court.
[02:06:49.100 --> 02:06:50.100]   Right.
[02:06:50.100 --> 02:06:51.100]   Right.
[02:06:51.100 --> 02:06:52.100]   Right.
[02:06:52.100 --> 02:06:53.100]   People hate politicians.
[02:06:53.100 --> 02:06:54.100]   I'm sorry.
[02:06:54.100 --> 02:06:55.100]   Dang you.
[02:06:55.100 --> 02:06:56.100]   Please help me back.
[02:06:56.100 --> 02:06:57.100]   No, I love you.
[02:06:57.100 --> 02:06:58.660]   Are you kidding?
[02:06:58.660 --> 02:07:02.780]   Barry Pollock, one of Assange's attorneys said, quote, "The only thing more irresponsible
[02:07:02.780 --> 02:07:08.660]   than charging a person for publishing truthful information would be to put it in a public
[02:07:08.660 --> 02:07:14.060]   filing or to put in a public filing information that clearly was not intended for the public
[02:07:14.060 --> 02:07:15.820]   and without any notice to Assange."
[02:07:15.820 --> 02:07:16.820]   He's kind of pissed.
[02:07:16.820 --> 02:07:17.820]   Yeah.
[02:07:17.820 --> 02:07:21.940]   Obviously, I have no idea if he actually has been charged or for what, but the notion that
[02:07:21.940 --> 02:07:25.700]   federal criminal charges can be brought based on the publication of truthful information
[02:07:25.700 --> 02:07:28.660]   is an incredibly dangerous precedent to set.
[02:07:28.660 --> 02:07:30.660]   I kind of agree with that.
[02:07:30.660 --> 02:07:33.140]   This is the modern world is very difficult.
[02:07:33.140 --> 02:07:34.140]   Yeah.
[02:07:34.140 --> 02:07:40.500]   It's because on the one hand, WikiLeaks, if they're publishing truthful stuff, it's truthful.
[02:07:40.500 --> 02:07:41.940]   You know, they're not lying.
[02:07:41.940 --> 02:07:47.660]   On the other hand, if they're doing it with the support and behest of a foreign government
[02:07:47.660 --> 02:07:51.940]   with an intent to undermine an election, well, that's not good.
[02:07:51.940 --> 02:07:55.700]   So one of the problems with our current public discourse is we're supposed to like and hate
[02:07:55.700 --> 02:08:01.300]   people not based on what they actually did, but whether what they did, how and who they
[02:08:01.300 --> 02:08:03.460]   are relative to our political philosophy.
[02:08:03.460 --> 02:08:08.340]   So if you're a Democrat and the person that got arrested for sexual harassment, the Democrat
[02:08:08.340 --> 02:08:12.620]   you're supposed to defend them, but if you're a Republican, you're supposed to condemn them.
[02:08:12.620 --> 02:08:18.060]   And it might make sense as Breonna says to just sit back and look at the facts and judge
[02:08:18.060 --> 02:08:21.900]   people on what they did rather than who they happened to believe, whether their ideology
[02:08:21.900 --> 02:08:24.340]   and your ideology happened to coincide.
[02:08:24.340 --> 02:08:26.100]   But that doesn't seem to be the case.
[02:08:26.100 --> 02:08:28.180]   It doesn't drive traffic.
[02:08:28.180 --> 02:08:29.940]   It doesn't build ratings.
[02:08:29.940 --> 02:08:32.980]   It's, you know, we got a 24 hour news cycle here.
[02:08:32.980 --> 02:08:34.180]   We got a filler with something.
[02:08:34.180 --> 02:08:36.140]   Well, and the politicians are all over.
[02:08:36.140 --> 02:08:40.980]   I mean, you know, condemning, you know, condemning what's his name in Las Vegas who was when,
[02:08:40.980 --> 02:08:45.980]   who was a friend of Trump and then, but not condemning people who are friends.
[02:08:45.980 --> 02:08:50.980]   And the idea that politicians would parse things based on ideology rather than what kind
[02:08:50.980 --> 02:08:51.980]   of a crime was committed.
[02:08:51.980 --> 02:08:55.660]   Now, when Julian Assange first came on the scene, I kind of liked the guy.
[02:08:55.660 --> 02:09:00.260]   I mean, I thought of him as a muck-racker, the journalist, the guy who was uncovering
[02:09:00.260 --> 02:09:02.460]   bad stuff that the government was doing.
[02:09:02.460 --> 02:09:07.220]   But then I started seeing other things I didn't like, for example, exposing information about
[02:09:07.220 --> 02:09:10.260]   low level operatives and putting them in danger.
[02:09:10.260 --> 02:09:14.260]   That isn't a necessary component of exposing corrupt government.
[02:09:14.260 --> 02:09:20.860]   And so, you know, it's hard to kind of judge him because of the complexity and the various
[02:09:20.860 --> 02:09:22.460]   things he's done.
[02:09:22.460 --> 02:09:23.460]   Yeah.
[02:09:23.460 --> 02:09:25.220]   Maybe, maybe it isn't black and white.
[02:09:25.220 --> 02:09:26.820]   Maybe some things are good and some things are not.
[02:09:26.820 --> 02:09:27.820]   I don't know.
[02:09:27.820 --> 02:09:36.180]   You know, in 2010, WikiLeaks released classified US military video showing how drone strikes
[02:09:36.180 --> 02:09:45.500]   are used to kill not only bad guys, but other people, civilians, journalists.
[02:09:45.500 --> 02:09:48.780]   That was, you know, that's just doing good work.
[02:09:48.780 --> 02:09:49.780]   Exactly.
[02:09:49.780 --> 02:09:51.020]   This is when we first learned at WikiLeaks.
[02:09:51.020 --> 02:09:52.660]   So I just don't know.
[02:09:52.660 --> 02:09:53.660]   I just don't know.
[02:09:53.660 --> 02:09:54.740]   It's very hard.
[02:09:54.740 --> 02:09:58.780]   Yeah, I'm going to agree with Brianna and say, let's wait until we get some more facts.
[02:09:58.780 --> 02:09:59.780]   It doesn't really.
[02:09:59.780 --> 02:10:02.700]   I mean, for you, you know, sitting on that jury, right?
[02:10:02.700 --> 02:10:06.300]   The point of having a jury trial is it's going to be adjudicated.
[02:10:06.300 --> 02:10:09.220]   They're going to be given facts, charges will be brought.
[02:10:09.220 --> 02:10:13.460]   And you know, he will have a stay in court, which is exactly as it should be.
[02:10:13.460 --> 02:10:15.540]   Leo, you and I are not sitting on that jury.
[02:10:15.540 --> 02:10:17.500]   So we'll let someone else handle that.
[02:10:17.500 --> 02:10:20.340]   And believe me, when you sit on a jury, it's hard.
[02:10:20.340 --> 02:10:21.340]   It is hard.
[02:10:21.340 --> 02:10:22.340]   It's terrible.
[02:10:22.340 --> 02:10:23.340]   Yeah.
[02:10:23.340 --> 02:10:24.340]   I've been ordered on a jury.
[02:10:24.340 --> 02:10:26.340]   I did briefly on a federal jury.
[02:10:26.340 --> 02:10:28.740]   And it's a, it's a, that's hard work.
[02:10:28.740 --> 02:10:30.020]   And I commend people who do it.
[02:10:30.020 --> 02:10:33.780]   I know so many people who say, I got to get a wagget out of this jury duty.
[02:10:33.780 --> 02:10:36.220]   I got to figure out an excuse.
[02:10:36.220 --> 02:10:37.220]   Serve.
[02:10:37.220 --> 02:10:42.660]   This is one of the most important things you can do in our country is to, you know, if
[02:10:42.660 --> 02:10:46.860]   only the people who couldn't figure out how to get out of jury duty were on jury duty,
[02:10:46.860 --> 02:10:48.860]   you better hope you don't get arrested.
[02:10:48.860 --> 02:10:49.860]   Yeah.
[02:10:49.860 --> 02:10:50.860]   Right.
[02:10:50.860 --> 02:10:54.780]   What we can all agree on is that democracy won't survive in a vacuum.
[02:10:54.780 --> 02:10:58.700]   It's like an active process and it needs to take effort and monitoring to make sure that
[02:10:58.700 --> 02:11:01.180]   it thrives and stays healthy.
[02:11:01.180 --> 02:11:06.420]   And so we need to make sure that, you know, our journalism and what's out there is really
[02:11:06.420 --> 02:11:08.620]   an act to keep democracy alive.
[02:11:08.620 --> 02:11:09.620]   Yep.
[02:11:09.620 --> 02:11:13.580]   And I think one thing that is the positive sort of silver lining of the Trump administration
[02:11:13.580 --> 02:11:16.340]   is that journalism has been made great again.
[02:11:16.340 --> 02:11:21.700]   Politicians who are coming up like Briana to challenge people in authority have been made
[02:11:21.700 --> 02:11:23.700]   great again.
[02:11:23.700 --> 02:11:25.260]   Protest has made great again.
[02:11:25.260 --> 02:11:26.460]   So there is a lot going on.
[02:11:26.460 --> 02:11:27.460]   Okay.
[02:11:27.460 --> 02:11:28.660]   America is getting better.
[02:11:28.660 --> 02:11:30.260]   America is getting great.
[02:11:30.260 --> 02:11:32.100]   Maybe it was always great.
[02:11:32.100 --> 02:11:34.540]   But our pivot are getting great again.
[02:11:34.540 --> 02:11:35.540]   It worked.
[02:11:35.540 --> 02:11:36.540]   All right.
[02:11:36.540 --> 02:11:37.540]   Let's do it.
[02:11:37.540 --> 02:11:38.540]   I think Larry.
[02:11:38.540 --> 02:11:39.540]   Oh, I'm sorry.
[02:11:39.540 --> 02:11:40.540]   Go ahead.
[02:11:40.540 --> 02:11:41.540]   This will be quick.
[02:11:41.540 --> 02:11:47.260]   I go and vote, it's always 60 year old, 70 year old women running the polls.
[02:11:47.260 --> 02:11:51.420]   I think Trump has really been a wake up call to people of my generation.
[02:11:51.420 --> 02:11:55.820]   I just turned 42 this year that we've guys get up and serve and do our part.
[02:11:55.820 --> 02:12:01.360]   I've never voted in my entire life where I saw women my age running the machines and
[02:12:01.360 --> 02:12:03.460]   helping with the election.
[02:12:03.460 --> 02:12:07.940]   And I really do think it's really been a big wake up call to my generation.
[02:12:07.940 --> 02:12:09.940]   This is our country too.
[02:12:09.940 --> 02:12:13.940]   And no generation gets to sit it out, right?
[02:12:13.940 --> 02:12:18.260]   And this is our turn to kind of step up and steer the ship and do what we can.
[02:12:18.260 --> 02:12:21.620]   And when you see somebody, you have to deal with these issues.
[02:12:21.620 --> 02:12:30.460]   So you see somebody like Alexandria Ocasio-Cortez at the age of 29 during Congress in January.
[02:12:30.460 --> 02:12:31.460]   It's just inspiring.
[02:12:31.460 --> 02:12:37.020]   I want to see more millennials, more young people participate in the process that can
[02:12:37.020 --> 02:12:38.020]   only.
[02:12:38.020 --> 02:12:39.020]   And vote.
[02:12:39.020 --> 02:12:40.540]   Well, they did.
[02:12:40.540 --> 02:12:45.780]   I mean, we don't have a great history, especially in midterm elections of voter turnout, but
[02:12:45.780 --> 02:12:48.100]   it was historically high this time.
[02:12:48.100 --> 02:12:49.100]   Yeah.
[02:12:49.100 --> 02:12:50.100]   Yeah.
[02:12:50.100 --> 02:12:51.900]   And every one of them were fraudulent, according to some people.
[02:12:51.900 --> 02:12:58.340]   Well, you know, I just think that is technologically related, but not on the show notes of like,
[02:12:58.340 --> 02:13:00.780]   what's up with not your voting machines?
[02:13:00.780 --> 02:13:03.740]   What is up with not having paper ballots, paper?
[02:13:03.740 --> 02:13:04.740]   Paper.
[02:13:04.740 --> 02:13:05.740]   It's like, just, it's easy.
[02:13:05.740 --> 02:13:08.220]   You have paper and then you have a track of it after.
[02:13:08.220 --> 02:13:13.260]   I'm just throwing that out there as an idea that maybe you want to think about because
[02:13:13.260 --> 02:13:14.260]   I'm not going to.
[02:13:14.260 --> 02:13:18.860]   Well, I'll tell you why we're better than Canada.
[02:13:18.860 --> 02:13:24.300]   Because in this country, every county gets to choose its method.
[02:13:24.300 --> 02:13:28.860]   And it isn't a, voting is not a federal process.
[02:13:28.860 --> 02:13:31.620]   It is a local process.
[02:13:31.620 --> 02:13:36.860]   And unfortunately, the side effect of that is some localities aren't too smart.
[02:13:36.860 --> 02:13:43.980]   Florida, I'm looking at you, but in the long run, I think this is a beneficial thing.
[02:13:43.980 --> 02:13:48.820]   First of all, because we have such a heterogeneous system, it's impossible to hack.
[02:13:48.820 --> 02:13:52.540]   But also, I think that one of the things that did you say it's impossible to hack?
[02:13:52.540 --> 02:13:55.180]   Yes, you can hack an individual county.
[02:13:55.180 --> 02:13:56.180]   Not the entire county.
[02:13:56.180 --> 02:13:57.500]   You can have a machine.
[02:13:57.500 --> 02:13:58.500]   One machine.
[02:13:58.500 --> 02:13:59.500]   That's the problem.
[02:13:59.500 --> 02:14:00.700]   It's very hard.
[02:14:00.700 --> 02:14:02.940]   It's very hard to hack the entire system.
[02:14:02.940 --> 02:14:05.860]   You can have software that's on all of them when they update as well.
[02:14:05.860 --> 02:14:06.860]   But they're all different.
[02:14:06.860 --> 02:14:07.860]   Nobody uses it.
[02:14:07.860 --> 02:14:10.140]   You can't hack paper really hard.
[02:14:10.140 --> 02:14:11.140]   No, I agree.
[02:14:11.140 --> 02:14:12.460]   There should be a paper trail.
[02:14:12.460 --> 02:14:13.460]   I completely agree.
[02:14:13.460 --> 02:14:14.460]   And I think it's 13.
[02:14:14.460 --> 02:14:15.460]   And a machine.
[02:14:15.460 --> 02:14:17.460]   There are 13 states that don't have a paper trail.
[02:14:17.460 --> 02:14:18.460]   I agree with you.
[02:14:18.460 --> 02:14:19.460]   I have.
[02:14:19.460 --> 02:14:20.460]   Blood drops and paper.
[02:14:20.460 --> 02:14:21.460]   Blood drops I'm not sure about.
[02:14:21.460 --> 02:14:23.460]   But paper, I think, is important.
[02:14:23.460 --> 02:14:24.460]   Fine.
[02:14:24.460 --> 02:14:25.460]   I don't know, Leo.
[02:14:25.460 --> 02:14:29.340]   Like when you sit down, you're really working on running, winning an election.
[02:14:29.340 --> 02:14:30.980]   You sit down, you look at the county.
[02:14:30.980 --> 02:14:35.020]   So for like me in 2020, we know how many vets who got in Boston, we know how many vets
[02:14:35.020 --> 02:14:36.340]   who got in DATOM.
[02:14:36.340 --> 02:14:38.860]   It really is micro-targeted.
[02:14:38.860 --> 02:14:43.500]   And you're right that you can't hack the entire system.
[02:14:43.500 --> 02:14:49.060]   But the reality of winning elections is you're really hyper-focusing on one, two, three targets.
[02:14:49.060 --> 02:14:50.260]   I don't think that's a bad thing.
[02:14:50.260 --> 02:14:53.340]   I think that makes you responsive to those regions.
[02:14:53.340 --> 02:14:58.620]   Now I think there are things you can do to try to hack it much more damaging than hacking
[02:14:58.620 --> 02:15:02.500]   a voting machine is gerrymandering or voter suppression.
[02:15:02.500 --> 02:15:04.540]   There are things you can try to do.
[02:15:04.540 --> 02:15:08.620]   But honestly, I think that one of the things that makes this country strong is a strong
[02:15:08.620 --> 02:15:13.060]   focus on locality, on local politics.
[02:15:13.060 --> 02:15:16.060]   And I really do think that that is very, very powerful.
[02:15:16.060 --> 02:15:20.780]   It is also one of the reasons we have divisions in this country because geographically there
[02:15:20.780 --> 02:15:26.220]   are very disparate points of view, a lot of it depending on geography as much as it is
[02:15:26.220 --> 02:15:28.140]   on anything else.
[02:15:28.140 --> 02:15:31.860]   And that makes it tough to have a single unified point of view.
[02:15:31.860 --> 02:15:33.340]   I don't think that's a bad thing.
[02:15:33.340 --> 02:15:34.340]   But it is true.
[02:15:34.340 --> 02:15:38.780]   When Trump complains about all the so-called illegal voting, the people who push back are
[02:15:38.780 --> 02:15:43.100]   lodging the county clerks and the state attorneys general, many of whom are Republicans,
[02:15:43.100 --> 02:15:44.540]   many of whom love Trump.
[02:15:44.540 --> 02:15:47.940]   But they also love the fact that they have integrity and they want their proud of their
[02:15:47.940 --> 02:15:48.940]   community.
[02:15:48.940 --> 02:15:50.060]   You know what the strength of this nation is.
[02:15:50.060 --> 02:15:56.780]   And it really is in that free vote is in, I think all politics should be local.
[02:15:56.780 --> 02:16:00.180]   I don't think it, I don't like a completely federal system.
[02:16:00.180 --> 02:16:02.500]   So with all due respect to Canada, I don't know.
[02:16:02.500 --> 02:16:04.260]   Do you have a paper journal on your balancing case?
[02:16:04.260 --> 02:16:06.260]   They legalize marijuana country-wise.
[02:16:06.260 --> 02:16:08.140]   We actually, we don't have machines.
[02:16:08.140 --> 02:16:09.740]   We have only paper.
[02:16:09.740 --> 02:16:10.740]   Wow.
[02:16:10.740 --> 02:16:11.980]   We count them by hand.
[02:16:11.980 --> 02:16:13.420]   Like nothing wrong with that.
[02:16:13.420 --> 02:16:18.380]   But I honestly think that having a single federal way to vote is not a good idea.
[02:16:18.380 --> 02:16:22.380]   One person from each party is there while the votes are all counted.
[02:16:22.380 --> 02:16:28.100]   And if there is a vote that two people think should, like there's like three parties often.
[02:16:28.100 --> 02:16:31.460]   But then they end up having like, if there's a vote that's like a medium, like you're like,
[02:16:31.460 --> 02:16:34.460]   I don't know if this should be or shouldn't be included.
[02:16:34.460 --> 02:16:39.620]   They all then vote to whether they keep the voter if they do not keep the vote.
[02:16:39.620 --> 02:16:40.620]   Yeah.
[02:16:40.620 --> 02:16:43.380]   Just again, to try to keep it as honest as possible.
[02:16:43.380 --> 02:16:46.780]   Because I think that you're right, divergent views are really important.
[02:16:46.780 --> 02:16:48.260]   They make country strong.
[02:16:48.260 --> 02:16:49.940]   We need differences in opinion.
[02:16:49.940 --> 02:16:54.660]   But you also want everyone's vote to count because they've spent the time to go there.
[02:16:54.660 --> 02:16:58.820]   You don't want them to feel disenfranchised and frustrated and upset.
[02:16:58.820 --> 02:17:00.580]   So you want both.
[02:17:00.580 --> 02:17:04.620]   And there are, and we've done interviews and triangulation with people who have proposed
[02:17:04.620 --> 02:17:10.020]   more equitable solutions, more equitable systems, things like rank choice voting.
[02:17:10.020 --> 02:17:13.540]   There's a lot of thought being put into this academically.
[02:17:13.540 --> 02:17:17.100]   But I wouldn't really want to see a federal system employed.
[02:17:17.100 --> 02:17:23.540]   I really think that it's better for localities to decide how their localities run.
[02:17:23.540 --> 02:17:28.260]   But, Leo, if I can just push back on that for a second, how would you handle something
[02:17:28.260 --> 02:17:35.060]   like in Georgia where they had voting machines and they're left over in a warehouse and they're
[02:17:35.060 --> 02:17:38.740]   just not put out in certain precincts with people of color?
[02:17:38.740 --> 02:17:42.900]   I mean, to me, that kind of problem seems like it's really designed for some sort of
[02:17:42.900 --> 02:17:46.380]   federal oversight because, you know, we did.
[02:17:46.380 --> 02:17:50.700]   We until the Supreme Court overturned it, we used to have a system.
[02:17:50.700 --> 02:17:55.860]   But that was a correctional system to correct for inequities in the, mostly in the Southeast.
[02:17:55.860 --> 02:18:01.180]   You know, we've talked about the Voting Rights Act.
[02:18:01.180 --> 02:18:03.660]   I think the system, honestly, think the system works.
[02:18:03.660 --> 02:18:06.380]   I know this is a little controversial.
[02:18:06.380 --> 02:18:09.780]   I agree that there are inequities, local inequities.
[02:18:09.780 --> 02:18:12.300]   Georgia's might be a good example of this.
[02:18:12.300 --> 02:18:15.140]   And it's up to Georgia's to fix it.
[02:18:15.140 --> 02:18:17.380]   I honestly think it is up to Georgia's to fix it.
[02:18:17.380 --> 02:18:21.420]   And the best solution will come from Georgia, just as the best solution will come from Florida
[02:18:21.420 --> 02:18:23.340]   to their issues.
[02:18:23.340 --> 02:18:25.660]   That's how it should be done, in my opinion.
[02:18:25.660 --> 02:18:32.860]   I think that's where I kind of come down on the side of states' rights is a very loaded
[02:18:32.860 --> 02:18:34.860]   term because it's mostly used in slavery.
[02:18:34.860 --> 02:18:35.860]   I don't think it does.
[02:18:35.860 --> 02:18:39.380]   But I think there is something to be said about that.
[02:18:39.380 --> 02:18:42.060]   There's not going to be a perfect system.
[02:18:42.060 --> 02:18:43.700]   There's not going to be a perfect system.
[02:18:43.700 --> 02:18:47.100]   But I think better for Georgia to fix this.
[02:18:47.100 --> 02:18:48.100]   And you know what?
[02:18:48.100 --> 02:18:51.820]   If you're in the state of Georgia and, well, I have to say, I think they're making progress.
[02:18:51.820 --> 02:18:52.820]   Oh, definitely.
[02:18:52.820 --> 02:18:58.100]   I think this election was a really interesting turning point.
[02:18:58.100 --> 02:19:01.900]   And if you're in Georgia, if you're in Gwynette County and you're getting counted, if you're
[02:19:01.900 --> 02:19:05.300]   an African-American, and Georgia has been disenfranchised, it's time to stand up.
[02:19:05.300 --> 02:19:07.500]   That's why these things can be fixed.
[02:19:07.500 --> 02:19:11.020]   Don't you don't look to Washington fix it.
[02:19:11.020 --> 02:19:12.500]   Now we really are getting political.
[02:19:12.500 --> 02:19:16.580]   That was me.
[02:19:16.580 --> 02:19:20.020]   I do have a bunch of little stories we're going to get back to and finish this up because
[02:19:20.020 --> 02:19:23.060]   we've already gone to 17, but you guys are so amazing.
[02:19:23.060 --> 02:19:25.420]   I don't ever want to stop this show.
[02:19:25.420 --> 02:19:27.500]   I don't want to stop this show.
[02:19:27.500 --> 02:19:30.620]   But I do have to eventually because otherwise I'll faint with hunger.
[02:19:30.620 --> 02:19:31.620]   And so will you.
[02:19:31.620 --> 02:19:38.220]   Our show today and all our shows are brought to you by CashFly, a little tip of the hat,
[02:19:38.220 --> 02:19:40.300]   a nod, props to CashFly.
[02:19:40.300 --> 02:19:44.860]   The content distribution network that brings you to it every episode.
[02:19:44.860 --> 02:19:50.700]   If you download it, if your podcast application downloads it, you're getting it from CashFly.
[02:19:50.700 --> 02:19:53.620]   Make this the last, and the reason we can do this and we've been doing it for almost
[02:19:53.620 --> 02:20:00.660]   10 years, petabytes of data every single month is because CashFly makes it possible.
[02:20:00.660 --> 02:20:04.820]   I never get a call at three in the morning saying, "Oh, CashFly is down."
[02:20:04.820 --> 02:20:08.180]   No, and I never have to worry about billing spikes.
[02:20:08.180 --> 02:20:10.740]   Our demand is very spiky.
[02:20:10.740 --> 02:20:14.420]   Some months it's huge, some months it's lower, some days it's huge, some days it's
[02:20:14.420 --> 02:20:15.420]   lower.
[02:20:15.420 --> 02:20:16.420]   I don't have to worry.
[02:20:16.420 --> 02:20:20.260]   I don't have to log in every day to see, "Oh my God, am I going to exceed the bill?"
[02:20:20.260 --> 02:20:27.020]   We have a planned tailor to our CDN needs based on yearly, yearly not daily, monthly,
[02:20:27.020 --> 02:20:30.300]   weekly, yearly usage trends.
[02:20:30.300 --> 02:20:33.980]   On average customers like you who switch to CashFly will save more than 20%.
[02:20:33.980 --> 02:20:36.020]   That's a really good deal.
[02:20:36.020 --> 02:20:45.660]   CashFly eliminates CDN outages.
[02:20:45.660 --> 02:20:47.700]   They help customers reach new markets.
[02:20:47.700 --> 02:20:53.140]   If you are in the business where customers download software, podcasts, whatever kind
[02:20:53.140 --> 02:20:58.540]   of content, you need a CDN that brings the content closer to the customers, a distribution
[02:20:58.540 --> 02:21:00.820]   network all over the world.
[02:21:00.820 --> 02:21:01.980]   That's what we needed.
[02:21:01.980 --> 02:21:04.020]   We need 100% availability.
[02:21:04.020 --> 02:21:07.580]   We want to build it's predictable and we want to save money.
[02:21:07.580 --> 02:21:08.780]   That's CashFly.
[02:21:08.780 --> 02:21:11.420]   CashFly for us has been amazing.
[02:21:11.420 --> 02:21:13.780]   CashFly for you will be amazing.
[02:21:13.780 --> 02:21:17.940]   Since 2002, CashFly has been building trusted CDN relationships.
[02:21:17.940 --> 02:21:20.500]   Companies like, "Don't just take my word from an R's technical."
[02:21:20.500 --> 02:21:22.020]   R's is director of technology.
[02:21:22.020 --> 02:21:26.780]   Sometimes we have spike events generating 15 to 16 million page views.
[02:21:26.780 --> 02:21:29.340]   All at once with CashFly you don't see an issue.
[02:21:29.340 --> 02:21:34.980]   The CDN just absorbs it.
[02:21:34.980 --> 02:21:39.300]   We've been hosting all of our shows, audio and video on CashFly for almost 10 years.
[02:21:39.300 --> 02:21:41.220]   Let CashFly give you some sanity back.
[02:21:41.220 --> 02:21:42.820]   We've got a great deal.
[02:21:42.820 --> 02:21:44.260]   I'm really pleased to say this.
[02:21:44.260 --> 02:21:49.460]   If you go to twit.cashfly.com you can receive up to $2,000 in credits when you switch to
[02:21:49.460 --> 02:21:53.740]   CashFly before the end of the year, before January 1.
[02:21:53.740 --> 02:21:59.580]   So immediately go get your complimentary, "No pressure, no sales pitch that just talked
[02:21:59.580 --> 02:22:06.300]   to you about your current usage and how CashFly can save you, twit.cashfly.com.
[02:22:06.300 --> 02:22:08.380]   Rates are based off 30% off MRC.
[02:22:08.380 --> 02:22:10.180]   Build credit applied for a 12 month period.
[02:22:10.180 --> 02:22:11.180]   But don't wait.
[02:22:11.180 --> 02:22:15.340]   This only lasts through the end of the year, January 1.
[02:22:15.340 --> 02:22:18.020]   twit.cashfly.com.
[02:22:18.020 --> 02:22:23.340]   I can't say it long enough loud enough, often enough.
[02:22:23.340 --> 02:22:25.740]   Thank you CashFly for making Twit possible.
[02:22:25.740 --> 02:22:28.860]   This network would not exist without CashFly.
[02:22:28.860 --> 02:22:29.860]   All right.
[02:22:29.860 --> 02:22:30.860]   A couple of quick stories.
[02:22:30.860 --> 02:22:32.100]   We're going to run through these.
[02:22:32.100 --> 02:22:37.900]   I'm very happy and I'm sure Brianna Wu is doing a little dance.
[02:22:37.900 --> 02:22:46.460]   The California man who made that deadly swatting call is Brett Gilti and got 20 to 25 years.
[02:22:46.460 --> 02:22:47.980]   This is a plea bargain.
[02:22:47.980 --> 02:22:49.700]   The judge has to accept it.
[02:22:49.700 --> 02:22:53.900]   He had pled not guilty, but this is the kid.
[02:22:53.900 --> 02:22:58.140]   They were they had a $1.50 wager in a gaming thing.
[02:22:58.140 --> 02:23:01.780]   He swatted somebody gave him the wrong address.
[02:23:01.780 --> 02:23:07.060]   The police arrived, killed the completely innocent man answering the door.
[02:23:07.060 --> 02:23:11.420]   Andrew Finch, 28 years old, a family man.
[02:23:11.420 --> 02:23:13.220]   That's murder in my book.
[02:23:13.220 --> 02:23:20.380]   And good news, Tyler Barris, who was a serial swatter, has admitted to making the false
[02:23:20.380 --> 02:23:24.940]   report resulting in a death as well as cyber stalking and conspiracy.
[02:23:24.940 --> 02:23:30.980]   The deal he made with prosecutors sends him to jail from 20 to 25 years.
[02:23:30.980 --> 02:23:31.980]   This is really good news.
[02:23:31.980 --> 02:23:34.620]   I mean, a lot of wise stood up in gamer gays.
[02:23:34.620 --> 02:23:40.380]   I was hoping to build a legal precedent for exactly this kind of action.
[02:23:40.380 --> 02:23:47.140]   It's truly tragic that this man died because of this guy that was given far too many second
[02:23:47.140 --> 02:23:48.140]   chances.
[02:23:48.140 --> 02:23:51.260]   He had a real history of doing this.
[02:23:51.260 --> 02:23:57.860]   If I remember correctly, he called in threats to local television stations and somehow after
[02:23:57.860 --> 02:24:02.540]   spending time on jail was able to get yet another chance to do this thing.
[02:24:02.540 --> 02:24:07.620]   So I'm really happy this precedent has been set.
[02:24:07.620 --> 02:24:09.900]   I think a lot of people in gamer land.
[02:24:09.900 --> 02:24:11.340]   I said this as a gamer.
[02:24:11.340 --> 02:24:17.140]   We kind of think of a world without consequences for the things that we do.
[02:24:17.140 --> 02:24:20.580]   And this is a very stark evidence of the contrary.
[02:24:20.580 --> 02:24:21.580]   I agree.
[02:24:21.580 --> 02:24:26.780]   I think that a lot of gamers like kind of looked at it as something that was funny.
[02:24:26.780 --> 02:24:27.780]   It's funny.
[02:24:27.780 --> 02:24:34.940]   Yeah, like the real life consequences to dealing with this, not only resources, but the danger
[02:24:34.940 --> 02:24:36.540]   that happens to that.
[02:24:36.540 --> 02:24:41.860]   Hopefully, this brings all of that to light as not a funny, cute way to get when you're
[02:24:41.860 --> 02:24:45.500]   angry at someone to be able to get back at them.
[02:24:45.500 --> 02:24:47.900]   We were swatted a couple of years ago.
[02:24:47.900 --> 02:24:51.540]   Just if you've never been swatted, that's where if you've never been swatted.
[02:24:51.540 --> 02:24:53.380]   And I know there's a few of them who haven't.
[02:24:53.380 --> 02:24:58.380]   But that's where somebody pretends this person called the Petaluma police and said, "I have
[02:24:58.380 --> 02:25:01.780]   planted bombs throughout the Twitch studios.
[02:25:01.780 --> 02:25:05.740]   I am now going in with guns to kill everybody.
[02:25:05.740 --> 02:25:06.740]   Goodbye."
[02:25:06.740 --> 02:25:10.460]   I heard the recording is very chilling.
[02:25:10.460 --> 02:25:17.180]   But credit to the Petaluma police, they came over, they brought bomb dogs, but they did
[02:25:17.180 --> 02:25:18.500]   not come and force.
[02:25:18.500 --> 02:25:20.860]   They did not break down our door.
[02:25:20.860 --> 02:25:24.540]   They handled it exactly right, protected us.
[02:25:24.540 --> 02:25:26.260]   Everybody left the studio.
[02:25:26.260 --> 02:25:28.700]   We let them proceed searching for bombs.
[02:25:28.700 --> 02:25:31.100]   Of course, it was a hoax.
[02:25:31.100 --> 02:25:36.940]   And by the way, great expense to law enforcement that has to spend all that time they had to
[02:25:36.940 --> 02:25:40.700]   bring in dogs from another jurisdiction.
[02:25:40.700 --> 02:25:46.020]   But thank you, Petaluma, police, for handling it right and shame on anybody who does this.
[02:25:46.020 --> 02:25:47.020]   And you know what?
[02:25:47.020 --> 02:25:49.620]   You're risking significant jail time.
[02:25:49.620 --> 02:25:50.620]   Yeah.
[02:25:50.620 --> 02:25:51.620]   Did they catch them?
[02:25:51.620 --> 02:25:52.620]   No.
[02:25:52.620 --> 02:25:55.820]   Most of these guys, you know, you don't get caught.
[02:25:55.820 --> 02:25:56.820]   They use phony numbers.
[02:25:56.820 --> 02:25:59.340]   It's very hard to catch them.
[02:25:59.340 --> 02:26:02.940]   But this guy deserved to get caught because he kept doing it again.
[02:26:02.940 --> 02:26:07.100]   I think what was his Twitter handle was something like serial swatter, practically.
[02:26:07.100 --> 02:26:11.380]   He was like, "This guy was completely out in the open about the whole thing."
[02:26:11.380 --> 02:26:18.700]   Japan has appointed a government cyber security strategy team.
[02:26:18.700 --> 02:26:23.500]   Yoshitaka Sakurada, he has never used a computer.
[02:26:23.500 --> 02:26:24.500]   Wow.
[02:26:24.500 --> 02:26:29.740]   In response to a question from a lawmaker in the House session on Wednesday, Sakurada
[02:26:29.740 --> 02:26:34.700]   said, "Since I was 25 years old and independent, I have instructed my staff and secretaries,
[02:26:34.700 --> 02:26:37.500]   I've never used a computer."
[02:26:37.500 --> 02:26:38.660]   What do you think of that, Brie?
[02:26:38.660 --> 02:26:41.460]   Now he's in charge of cyber security.
[02:26:41.460 --> 02:26:49.580]   He has updated all relevant patches, is not vulnerable to zero days, is an impressively
[02:26:49.580 --> 02:26:52.460]   small attack surface.
[02:26:52.460 --> 02:26:54.820]   I think this guy is working at the next level.
[02:26:54.820 --> 02:26:55.820]   That's security, right?
[02:26:55.820 --> 02:26:56.820]   No, use a computer.
[02:26:56.820 --> 02:26:57.820]   Now hack me.
[02:26:57.820 --> 02:26:58.820]   Yeah.
[02:26:58.820 --> 02:26:59.820]   Right.
[02:26:59.820 --> 02:27:00.820]   Good role model.
[02:27:00.820 --> 02:27:05.580]   He's 68 years old, never used a computer.
[02:27:05.580 --> 02:27:09.340]   He's now in charge of cyber security in Japan.
[02:27:09.340 --> 02:27:10.340]   Wow.
[02:27:10.340 --> 02:27:12.020]   How does that even happen?
[02:27:12.020 --> 02:27:14.540]   Should there be a question somewhere?
[02:27:14.540 --> 02:27:15.540]   Who knows?
[02:27:15.540 --> 02:27:23.140]   John Musk got FCC approval for his plan to put 12,000 satellites in space, low Earth
[02:27:23.140 --> 02:27:25.140]   orbit.
[02:27:25.140 --> 02:27:26.140]   It's in two stages.
[02:27:26.140 --> 02:27:31.420]   The FCC just approved the second group of 7,000 Starlink internet satellites.
[02:27:31.420 --> 02:27:34.620]   Musk says Starlink will take about six years.
[02:27:34.620 --> 02:27:42.220]   So around 2025, every square inch on the planet Earth should be wired for high speed, low
[02:27:42.220 --> 02:27:45.060]   latency internet access.
[02:27:45.060 --> 02:27:46.740]   And he's not the only one.
[02:27:46.740 --> 02:27:52.780]   At the same day, the FCC approved three other companies, Kepler, Telesat and Leosat.
[02:27:52.780 --> 02:27:59.620]   That's my personal favorite to put in some sort of satellite internet.
[02:27:59.620 --> 02:28:01.620]   This is going to happen very fast.
[02:28:01.620 --> 02:28:04.340]   Now I know we don't have a great history of this.
[02:28:04.340 --> 02:28:06.620]   You may remember a company called Iridium.
[02:28:06.620 --> 02:28:09.100]   Yes, I had one of their phones.
[02:28:09.100 --> 02:28:10.500]   That kind of did.
[02:28:10.500 --> 02:28:14.780]   So you can build it, but you got to get people to use it and you got to have a business
[02:28:14.780 --> 02:28:15.780]   model and so forth.
[02:28:15.780 --> 02:28:17.780]   But I think it'll work.
[02:28:17.780 --> 02:28:18.780]   I think it'll work.
[02:28:18.780 --> 02:28:19.780]   I don't think it'll work.
[02:28:19.780 --> 02:28:22.460]   Iridium'd work, but they were really very unreliable the one I had.
[02:28:22.460 --> 02:28:24.060]   It was expensive in a rear-view bank.
[02:28:24.060 --> 02:28:25.060]   Very expensive.
[02:28:25.060 --> 02:28:27.500]   The thing is with satellites, they're still up there.
[02:28:27.500 --> 02:28:33.020]   One of the things the FCC required is a plan for when the satellites are either obsolete
[02:28:33.020 --> 02:28:36.580]   or starting to orbit, starting to decay.
[02:28:36.580 --> 02:28:42.340]   And I think in most cases, the plans are something to do with maybe somebody from Rocketdyne
[02:28:42.340 --> 02:28:43.340]   could help us.
[02:28:43.340 --> 02:28:45.020]   Maybe they have a jet to fire.
[02:28:45.020 --> 02:28:51.260]   They got to launch themselves into the atmosphere so they burn up.
[02:28:51.260 --> 02:28:54.620]   Or I guess you could launch yourself into space, but that's not going to be a good solution.
[02:28:54.620 --> 02:28:56.020]   It's a good burn-up burn-up.
[02:28:56.020 --> 02:29:02.220]   There are, in the hearing about this they were talking about, there are currently, I think
[02:29:02.220 --> 02:29:07.860]   NASA is tracking 500,000 individual pieces of space junk.
[02:29:07.860 --> 02:29:08.860]   Yeah.
[02:29:08.860 --> 02:29:09.860]   Wow.
[02:29:09.860 --> 02:29:11.860]   Is there any room up there for this stuff?
[02:29:11.860 --> 02:29:12.860]   It's a big area.
[02:29:12.860 --> 02:29:16.420]   It's the image of getting into a spaceship and having to vector around all these satellites
[02:29:16.420 --> 02:29:17.820]   that you get through.
[02:29:17.820 --> 02:29:23.620]   One of the FCC commissioners, Jessica Rosenworzel, who is one of my favorites, pointed out that
[02:29:23.620 --> 02:29:27.300]   she said, "My favorite example of this is an innocuous little screwdriver that slipped
[02:29:27.300 --> 02:29:32.700]   through an astronaut's grasp and has been circling low Earth orbit at 21,600 miles an
[02:29:32.700 --> 02:29:35.060]   hour for the last 35 years."
[02:29:35.060 --> 02:29:36.060]   Oh my gosh.
[02:29:36.060 --> 02:29:38.820]   You wouldn't want to run into that in a dark night.
[02:29:38.820 --> 02:29:40.620]   Yeah, well, so interestingly.
[02:29:40.620 --> 02:29:45.620]   I was, after I lost my election, I went down to a tour Kennedy Space Center, Sennifias,
[02:29:45.620 --> 02:29:48.460]   Benifidets, down there.
[02:29:48.460 --> 02:29:51.260]   It was really fascinating to go down there.
[02:29:51.260 --> 02:29:55.220]   This is good and it was bad at the same time.
[02:29:55.220 --> 02:30:01.180]   One of the biggest things ever impacted me was the loss of the Challenger when I was a
[02:30:01.180 --> 02:30:02.180]   child.
[02:30:02.180 --> 02:30:08.540]   You can go down there and it's all private companies that own a lot of those NASA landing
[02:30:08.540 --> 02:30:10.060]   sites down there now.
[02:30:10.060 --> 02:30:16.300]   You can see Jeff Bezos' Blue Origin and SpaceX was launching while I was down there.
[02:30:16.300 --> 02:30:18.620]   On the right, they lease them.
[02:30:18.620 --> 02:30:19.620]   Correct.
[02:30:19.620 --> 02:30:20.620]   They lease them from the government.
[02:30:20.620 --> 02:30:22.260]   But they have their logos and everything.
[02:30:22.260 --> 02:30:23.260]   It's like they own them.
[02:30:23.260 --> 02:30:24.260]   They do.
[02:30:24.260 --> 02:30:29.340]   I think as we're figuring out how we need to colonize space, I do think private industry
[02:30:29.340 --> 02:30:30.500]   has a role to play.
[02:30:30.500 --> 02:30:33.020]   It's good and it's bad.
[02:30:33.020 --> 02:30:37.580]   This is why things like we were talking earlier about just rooting for or against somebody.
[02:30:37.580 --> 02:30:40.020]   At some point, I feel for good reasons.
[02:30:40.020 --> 02:30:42.500]   We decided Elon was a villain.
[02:30:42.500 --> 02:30:50.300]   I was really happy to see this come through because I do think that they are doing instrumental
[02:30:50.300 --> 02:30:53.860]   work and gang us to the next chapter of space exploration.
[02:30:53.860 --> 02:30:56.380]   I think it has to be cooperative.
[02:30:56.380 --> 02:30:59.900]   We don't want private industry to own space.
[02:30:59.900 --> 02:31:05.900]   I think it's appropriate for private industry to work with governments.
[02:31:05.900 --> 02:31:08.700]   The last thing we want is a space force.
[02:31:08.700 --> 02:31:11.580]   A war up there and us fighting.
[02:31:11.580 --> 02:31:19.100]   At the same time, we don't want one company SpaceX to own the moon.
[02:31:19.100 --> 02:31:21.940]   It's all of ours.
[02:31:21.940 --> 02:31:23.420]   It's like an airline.
[02:31:23.420 --> 02:31:25.380]   Airlines don't own the cities that they fly to.
[02:31:25.380 --> 02:31:27.260]   They just get you back and forth.
[02:31:27.260 --> 02:31:28.260]   It's appropriate.
[02:31:28.260 --> 02:31:33.820]   I'm sure that many of these companies are looking forward to the day when they can harvest
[02:31:33.820 --> 02:31:34.820]   asteroids.
[02:31:34.820 --> 02:31:39.580]   There are huge amounts of valuable water, metals, all sorts of things.
[02:31:39.580 --> 02:31:44.100]   These asteroids, one asteroid could be with trillions of dollars.
[02:31:44.100 --> 02:31:47.260]   There's a monetary incentive, but that's great.
[02:31:47.260 --> 02:31:48.260]   That's great.
[02:31:48.260 --> 02:31:49.260]   Let them make some profit.
[02:31:49.260 --> 02:31:55.060]   I'm going to plug this because one of our regular contributors, Amy Webb, worked on
[02:31:55.060 --> 02:31:56.580]   this program.
[02:31:56.580 --> 02:31:57.580]   It's called The First.
[02:31:57.580 --> 02:31:58.580]   It's on Hulu.
[02:31:58.580 --> 02:32:03.940]   It's about a private company launching a trip to Mars, but it takes government support,
[02:32:03.940 --> 02:32:07.140]   government funding as well as a private company.
[02:32:07.140 --> 02:32:11.380]   What Amy did, she's a futurist, is she designed what the world will be like.
[02:32:11.380 --> 02:32:13.900]   I think it's 2030.
[02:32:13.900 --> 02:32:14.900]   That's a fun part of it.
[02:32:14.900 --> 02:32:16.980]   I really liked this show.
[02:32:16.980 --> 02:32:19.620]   Sean Penn, when Amy talked about it, I said, "Oh, I hate Sean Penn.
[02:32:19.620 --> 02:32:20.620]   You know what?
[02:32:20.620 --> 02:32:21.620]   He's great in it.
[02:32:21.620 --> 02:32:22.620]   I don't hate Sean Penn.
[02:32:22.620 --> 02:32:23.620]   He's great in it.
[02:32:23.620 --> 02:32:28.180]   It's a really fun show, eight episodes.
[02:32:28.180 --> 02:32:29.180]   It ends.
[02:32:29.180 --> 02:32:33.820]   Amy was quick to say this as they are launching to Mars.
[02:32:33.820 --> 02:32:34.820]   You don't get to Mars.
[02:32:34.820 --> 02:32:39.260]   I guess that's season two, The First on Hulu."
[02:32:39.260 --> 02:32:40.260]   All right.
[02:32:40.260 --> 02:32:44.300]   Continuing on.
[02:32:44.300 --> 02:32:45.300]   Sad.
[02:32:45.300 --> 02:32:50.980]   A couple of passings, we should probably note Stanley, 95 years old, the creator of Spider
[02:32:50.980 --> 02:32:57.780]   Man and I think a geek hero because a lot of us read comic books as children.
[02:32:57.780 --> 02:32:59.740]   They passed away at the age of 95.
[02:32:59.740 --> 02:33:03.140]   Here's one that's probably lesser known, but I think in many ways a very important person
[02:33:03.140 --> 02:33:06.880]   and one of the most important people in the early days of microcomputers, a guy named
[02:33:06.880 --> 02:33:07.880]   Bill Godbout.
[02:33:07.880 --> 02:33:08.880]   Yeah.
[02:33:08.880 --> 02:33:11.980]   Larry, you remember Godbout computers, Godbout electronics.
[02:33:11.980 --> 02:33:17.420]   He was a big promoter of a standardized bus for CPM computers called S100.
[02:33:17.420 --> 02:33:25.380]   It was a very important point in making computing accessible.
[02:33:25.380 --> 02:33:29.300]   I had to say he perished in the camp wildfire.
[02:33:29.300 --> 02:33:33.380]   He was in a town which mostly from 79 years old.
[02:33:33.380 --> 02:33:34.380]   Oh horrible.
[02:33:34.380 --> 02:33:35.380]   I really died.
[02:33:35.380 --> 02:33:37.380]   I didn't really die in the fire.
[02:33:37.380 --> 02:33:38.380]   I'm like, you didn't do the fire.
[02:33:38.380 --> 02:33:42.460]   Yeah, there is a GoFundMe that you might want to search up.
[02:33:42.460 --> 02:33:45.060]   Go fund me, search for a Bill Godbout.
[02:33:45.060 --> 02:33:49.780]   They're trying to raise some money for his family.
[02:33:49.780 --> 02:33:50.780]   Oh.
[02:33:50.780 --> 02:33:54.900]   So, I think this is a well worth contributing to.
[02:33:54.900 --> 02:33:59.380]   He was a really, we owe many, we owe great debt to a Bill Godbout.
[02:33:59.380 --> 02:34:04.060]   And the campfire, of course, one of the worst fires in the history of California.
[02:34:04.060 --> 02:34:06.020]   And that kind of brings it home.
[02:34:06.020 --> 02:34:08.420]   I didn't realize that's how he died.
[02:34:08.420 --> 02:34:09.420]   I know.
[02:34:09.420 --> 02:34:10.420]   I didn't either.
[02:34:10.420 --> 02:34:12.660]   I'm reading it out of the jury of his right now in the Guardian.
[02:34:12.660 --> 02:34:14.220]   He was, you know, it's funny.
[02:34:14.220 --> 02:34:18.300]   I don't think I remember the name because I had S100 computers.
[02:34:18.300 --> 02:34:20.380]   I was a beloved.
[02:34:20.380 --> 02:34:24.860]   That's when I first started playing with microcomputers in that era in the late '70s.
[02:34:24.860 --> 02:34:29.220]   But I think nowadays I wouldn't expect many people to remember the name Godbout.
[02:34:29.220 --> 02:34:30.220]   Yeah.
[02:34:30.220 --> 02:34:34.020]   Let's see.
[02:34:34.020 --> 02:34:35.420]   Something uplifting.
[02:34:35.420 --> 02:34:36.420]   Happy.
[02:34:36.420 --> 02:34:39.460]   How about alphabet and those contact lenses?
[02:34:39.460 --> 02:34:40.460]   That was really interesting.
[02:34:40.460 --> 02:34:41.460]   It's not happy.
[02:34:41.460 --> 02:34:42.460]   That's an example.
[02:34:42.460 --> 02:34:46.700]   I think it's a happy story because it's the Thanos.
[02:34:46.700 --> 02:34:47.700]   They're giving up.
[02:34:47.700 --> 02:34:48.700]   There are no such facts.
[02:34:48.700 --> 02:34:49.700]   Yeah.
[02:34:49.700 --> 02:34:50.700]   They're giving up.
[02:34:50.700 --> 02:34:53.140]   So alphabet has a company called Verily.
[02:34:53.140 --> 02:34:55.140]   Their life science division.
[02:34:55.140 --> 02:34:58.220]   Before it was Verily, it was still a Google company about four or five years ago.
[02:34:58.220 --> 02:35:00.540]   They announced and we talked about it.
[02:35:00.540 --> 02:35:01.620]   Everybody talked about it.
[02:35:01.620 --> 02:35:06.700]   A contact lens that would have circuitry in it that would measure glucose levels.
[02:35:06.700 --> 02:35:09.420]   It would be kind of the holy grail.
[02:35:09.420 --> 02:35:10.940]   It's a holy grail for a couple of reasons there.
[02:35:10.940 --> 02:35:14.060]   I think our 14 million diabetics type 1 and 2 in the country.
[02:35:14.060 --> 02:35:15.060]   I'm one of them.
[02:35:15.060 --> 02:35:20.020]   I'm a type 2 diabetic who will need to monitor our blood sugar for health reasons.
[02:35:20.020 --> 02:35:22.820]   In some cases, it's for life and death reasons.
[02:35:22.820 --> 02:35:26.980]   Right now it involves a pin prick and a draw of blood.
[02:35:26.980 --> 02:35:27.980]   It's painful.
[02:35:27.980 --> 02:35:28.980]   It's annoying.
[02:35:28.980 --> 02:35:30.700]   It's difficult.
[02:35:30.700 --> 02:35:32.340]   It's accurate.
[02:35:32.340 --> 02:35:37.380]   There's been a holy grail for us to not have to prick ourselves but also from the tech industry
[02:35:37.380 --> 02:35:40.020]   because that's a lot of money you could make.
[02:35:40.020 --> 02:35:45.180]   On 14 million diabetics, if you could just figure out a way not to have to prick your
[02:35:45.180 --> 02:35:46.660]   finger, no one's done it yet.
[02:35:46.660 --> 02:35:47.660]   You remember Tim?
[02:35:47.660 --> 02:35:49.540]   Is it Apple working on something?
[02:35:49.540 --> 02:35:50.540]   Oh, Tim Cook?
[02:35:50.540 --> 02:35:52.100]   Yeah, no.
[02:35:52.100 --> 02:35:53.700]   Tim Cook was wearing an Apple watch.
[02:35:53.700 --> 02:35:57.340]   He said, "Right now I'm wearing a diabetes sugar monitor on my watch."
[02:35:57.340 --> 02:36:02.420]   No, no one can figure out a non-invasive way to do this.
[02:36:02.420 --> 02:36:06.700]   The best they've got right now is a little patch that actually does penetrate the skin
[02:36:06.700 --> 02:36:09.180]   and you wear it and it'll give you a continuous measurement.
[02:36:09.180 --> 02:36:10.180]   That's pretty cool.
[02:36:10.180 --> 02:36:17.460]   Verily thought, "Oh, what we're going to do, the tears, sugar, turns out it's wildly
[02:36:17.460 --> 02:36:18.460]   inconsistent.
[02:36:18.460 --> 02:36:21.260]   It has nothing to do with your blood sugar."
[02:36:21.260 --> 02:36:22.260]   Yeah.
[02:36:22.260 --> 02:36:25.540]   And basically Verily has said, "Yeah, this isn't going to work."
[02:36:25.540 --> 02:36:30.700]   Maybe the reason I realized this is more personal for you than it is for me, Leo.
[02:36:30.700 --> 02:36:37.620]   So it's a setback for people with diabetes, undoubtedly.
[02:36:37.620 --> 02:36:43.300]   But I read this, I was thinking about John Kerry's reporting on Theranos in his blockbuster
[02:36:43.300 --> 02:36:45.020]   book, Bad Blood.
[02:36:45.020 --> 02:36:46.020]   What a great book.
[02:36:46.020 --> 02:36:47.020]   Oh.
[02:36:47.020 --> 02:36:54.180]   And I love to see Silicon Valley taking a step and saying, "You know what?
[02:36:54.180 --> 02:36:59.180]   If the science isn't there, we can't sell this like a...
[02:36:59.180 --> 02:37:03.060]   Yeah, be honest, the stakes are too high for vaporware.
[02:37:03.060 --> 02:37:04.900]   And let's put the patience first."
[02:37:04.900 --> 02:37:07.140]   So that was my read on this.
[02:37:07.140 --> 02:37:11.340]   I saw this as a step forward with the responsibility.
[02:37:11.340 --> 02:37:12.340]   You know what?
[02:37:12.340 --> 02:37:13.340]   That's an excellent spin.
[02:37:13.340 --> 02:37:16.420]   It is rare that a company will say, "Yeah, we tried it.
[02:37:16.420 --> 02:37:17.420]   It didn't work."
[02:37:17.420 --> 02:37:18.420]   Yeah.
[02:37:18.420 --> 02:37:25.300]   And I'm hearing mixed things from people about the Apple Watch and the EKG or the ECG monitoring.
[02:37:25.300 --> 02:37:26.300]   You know, I mean...
[02:37:26.300 --> 02:37:27.300]   That's still my way.
[02:37:27.300 --> 02:37:28.460]   That's not how we don't have work yet.
[02:37:28.460 --> 02:37:29.460]   No, I know.
[02:37:29.460 --> 02:37:33.180]   I've got mine right here and I'm waiting for that software update.
[02:37:33.180 --> 02:37:35.380]   But you know, we'll have to find out.
[02:37:35.380 --> 02:37:36.380]   It's a big experiment.
[02:37:36.380 --> 02:37:40.980]   If this can lead people to unnecessary trips to the hospital, either getting false positives
[02:37:40.980 --> 02:37:45.660]   or they're going to actually save lives or maybe both, you know, we don't know yet.
[02:37:45.660 --> 02:37:46.660]   I have a cardia.
[02:37:46.660 --> 02:37:47.660]   I don't have AC...
[02:37:47.660 --> 02:37:48.660]   Yeah, a cardia.
[02:37:48.660 --> 02:37:49.660]   But I bought a cardia.
[02:37:49.660 --> 02:37:50.940]   I'm actually meeting with them this week.
[02:37:50.940 --> 02:37:51.940]   It works.
[02:37:51.940 --> 02:37:54.300]   This is essentially how the Apple will work.
[02:37:54.300 --> 02:37:55.300]   A normal...
[02:37:55.300 --> 02:37:56.300]   It's only $99.
[02:37:56.300 --> 02:37:57.300]   Yeah.
[02:37:57.300 --> 02:38:02.300]   A normal EKG, you have, I think, 12 electrodes placed all over your body.
[02:38:02.300 --> 02:38:08.580]   Even with those, there's about a 25% false positive rate, 10 to 25%.
[02:38:08.580 --> 02:38:14.300]   So this system, the cardia system is very similar to what Apple Watch will do.
[02:38:14.300 --> 02:38:15.620]   It has two sensors.
[02:38:15.620 --> 02:38:19.900]   In the case of the cardia left hand, right hand, in the case of the Apple Watch, you're
[02:38:19.900 --> 02:38:22.860]   wrist and then you'll take your other hand and put it on the stem.
[02:38:22.860 --> 02:38:24.740]   So it's very similar.
[02:38:24.740 --> 02:38:27.540]   It will do an EKG.
[02:38:27.540 --> 02:38:29.380]   You raise the exact problem though.
[02:38:29.380 --> 02:38:33.580]   If it has a false positive and somebody goes in for treatment and there's nothing wrong
[02:38:33.580 --> 02:38:35.180]   with them, that's not a good thing.
[02:38:35.180 --> 02:38:36.180]   And what about...
[02:38:36.180 --> 02:38:37.180]   We need an anxiety doctor.
[02:38:37.180 --> 02:38:39.300]   No, I'm serious about that.
[02:38:39.300 --> 02:38:40.300]   The anxiety that...
[02:38:40.300 --> 02:38:43.940]   So every time I get a blood test, I am on pins and needles.
[02:38:43.940 --> 02:38:46.260]   And no pun intended until I get the results.
[02:38:46.260 --> 02:38:50.220]   Because I have this horrible anxiety that something bad is going to come out of it.
[02:38:50.220 --> 02:38:54.660]   And I have a cardia in a box and I'm actually nervous about you thinking...
[02:38:54.660 --> 02:38:56.100]   But you don't have any for good.
[02:38:56.100 --> 02:38:57.420]   And I have to know of.
[02:38:57.420 --> 02:39:02.060]   So somebody I know who has AFib, Jeff Jarvis, the host of This Week in Google, has had AFib
[02:39:02.060 --> 02:39:04.260]   has been treated and hospitalized for it.
[02:39:04.260 --> 02:39:09.980]   He is thrilled with the cardia because part of the problem with AFib is you may have some
[02:39:09.980 --> 02:39:12.940]   symptoms but be not fully symptomatic.
[02:39:12.940 --> 02:39:15.540]   So in a way it's a relief to him that he can do that.
[02:39:15.540 --> 02:39:17.100]   I don't have AFib.
[02:39:17.100 --> 02:39:20.180]   And by the way, in every case, both with the Apple Watch and the cardia, it gets said to
[02:39:20.180 --> 02:39:22.860]   a real physician, you're not self-diagnosing.
[02:39:22.860 --> 02:39:26.540]   But it can be one of those feeding loops, right?
[02:39:26.540 --> 02:39:29.260]   That you want to constantly check and look over and look over.
[02:39:29.260 --> 02:39:34.540]   I do have a lot of my clients that check their pulse constantly and then having an Apple
[02:39:34.540 --> 02:39:38.940]   Watch where you get this feeding loop of you're worried, you check your pulse, then you go
[02:39:38.940 --> 02:39:39.940]   better.
[02:39:39.940 --> 02:39:40.940]   That's a reward, right?
[02:39:40.940 --> 02:39:44.380]   So if you go through the cycle next time you worry, you check, you want to check your pulse
[02:39:44.380 --> 02:39:46.660]   again so you get that relief.
[02:39:46.660 --> 02:39:51.180]   It can become something that's a little bit addictive to certain set of the population.
[02:39:51.180 --> 02:39:55.100]   But if you ever thought you might be having a heart attack, what happens is the anxiety
[02:39:55.100 --> 02:39:59.700]   of worrying about the heart attack actually creates symptoms of a heart attack.
[02:39:59.700 --> 02:40:02.020]   And then you're going to become the self-fulfilling prophecy.
[02:40:02.020 --> 02:40:03.820]   Well, you don't get the heart attack.
[02:40:03.820 --> 02:40:08.100]   Well, lots of fulfilling but the fear of that fear is really traumatizing.
[02:40:08.100 --> 02:40:12.820]   And yes, a lot of people that go to the hospital think that they have.
[02:40:12.820 --> 02:40:18.380]   But every doctor I know says if you think you're having it yet, don't drive yourself,
[02:40:18.380 --> 02:40:24.060]   but get to a hospital because there is a direct connection between the amount of time that
[02:40:24.060 --> 02:40:28.180]   you get, how long it takes to get treatment and the chance for survival.
[02:40:28.180 --> 02:40:30.900]   So don't say, I'll sleep on it.
[02:40:30.900 --> 02:40:31.900]   No.
[02:40:31.900 --> 02:40:32.900]   Yeah, very good point.
[02:40:32.900 --> 02:40:38.060]   No, get your wife to drive you or your husband to drive you or go or get an ambulance.
[02:40:38.060 --> 02:40:39.060]   Don't take a chance.
[02:40:39.060 --> 02:40:42.260]   Nobody at the hospital is ever going to yell at you because, oh, no, you didn't have a
[02:40:42.260 --> 02:40:43.260]   heart attack.
[02:40:43.260 --> 02:40:44.260]   It was just gas.
[02:40:44.260 --> 02:40:45.460]   No one's ever going to yell at you.
[02:40:45.460 --> 02:40:46.460]   Right.
[02:40:46.460 --> 02:40:47.460]   It's a good thing to do.
[02:40:47.460 --> 02:40:50.700]   Now, I have to say, you don't have to worry about paying for it.
[02:40:50.700 --> 02:40:51.700]   Yeah.
[02:40:51.700 --> 02:40:52.700]   Well, that's a bit of an anxiety.
[02:40:52.700 --> 02:40:58.620]   I have this ring that I wear, which is very accurate, I think, a very accurate measurement
[02:40:58.620 --> 02:40:59.620]   of your sleep.
[02:40:59.620 --> 02:41:02.220]   And I also have for a while the sort of thing.
[02:41:02.220 --> 02:41:03.220]   Yeah.
[02:41:03.220 --> 02:41:07.060]   And I think I sleep worse because I know how badly I sleep.
[02:41:07.060 --> 02:41:08.060]   Yeah.
[02:41:08.060 --> 02:41:09.060]   Which could be true.
[02:41:09.060 --> 02:41:10.660]   How does the ring work?
[02:41:10.660 --> 02:41:15.460]   So it measures motion, of course, because it's got a cellarometer, but it also measures
[02:41:15.460 --> 02:41:17.900]   body temperature and heart rate.
[02:41:17.900 --> 02:41:21.060]   And because it's on this finger, it can do that very accurately.
[02:41:21.060 --> 02:41:22.060]   Wow.
[02:41:22.060 --> 02:41:23.060]   And then it sinks through.
[02:41:23.060 --> 02:41:25.700]   If you plug it in or does it go through Wi-Fi?
[02:41:25.700 --> 02:41:28.420]   No, it has a memory.
[02:41:28.420 --> 02:41:29.580]   So it just stores that.
[02:41:29.580 --> 02:41:31.020]   It has, I think, up to a week of memory.
[02:41:31.020 --> 02:41:37.980]   And it's, you know, they encourage you every day to use, open up the app on your phone,
[02:41:37.980 --> 02:41:40.060]   which I'll do, and it downloads your sleep.
[02:41:40.060 --> 02:41:42.260]   But you have to put it into cradle.
[02:41:42.260 --> 02:41:44.260]   It just breaks through your phone.
[02:41:44.260 --> 02:41:45.260]   No, no.
[02:41:45.260 --> 02:41:46.260]   It's Bluetooth, our Bluetooth LA or something.
[02:41:46.260 --> 02:41:47.740]   And that a little ring, that's a question.
[02:41:47.740 --> 02:41:48.740]   Yeah.
[02:41:48.740 --> 02:41:49.740]   Oh, I like this.
[02:41:49.740 --> 02:41:50.740]   That's amazing.
[02:41:50.740 --> 02:41:52.020]   And what is it called, Leo?
[02:41:52.020 --> 02:41:53.340]   Should I give them a free ad?
[02:41:53.340 --> 02:41:54.340]   Yes, you should.
[02:41:54.340 --> 02:41:55.340]   It's not an ad.
[02:41:55.340 --> 02:41:56.340]   It's a review.
[02:41:56.340 --> 02:41:57.340]   It's not an ad.
[02:41:57.340 --> 02:41:58.340]   It's a, yeah.
[02:41:58.340 --> 02:41:59.340]   It's the aura.
[02:41:59.340 --> 02:42:00.740]   And actually, as Kevin Rose who told me about it.
[02:42:00.740 --> 02:42:02.740]   Oh, you are a.
[02:42:02.740 --> 02:42:03.740]   Oh, right.
[02:42:03.740 --> 02:42:07.780]   If you know, you met, we were talking about Philippe Conner, he is a company now that makes
[02:42:07.780 --> 02:42:08.780]   -active ex.
[02:42:08.780 --> 02:42:09.780]   - Technology.
[02:42:09.780 --> 02:42:10.780]   I've got it.
[02:42:10.780 --> 02:42:11.780]   I've actually got to think under my bed.
[02:42:11.780 --> 02:42:13.580]   Yeah, he told me about the soda.
[02:42:13.580 --> 02:42:17.620]   That's their act of ex, motion ex, not act of ex, but that's something else.
[02:42:17.620 --> 02:42:18.620]   Motion ex.
[02:42:18.620 --> 02:42:23.060]   If you're in a relationship and one of you is out of town, don't have an affair because
[02:42:23.060 --> 02:42:25.740]   what'll happen is you'll get a reading of that person.
[02:42:25.740 --> 02:42:26.740]   Honey?
[02:42:26.740 --> 02:42:27.740]   Surely the bed.
[02:42:27.740 --> 02:42:28.740]   Who is that in bed with you?
[02:42:28.740 --> 02:42:30.260]   And why was her heart rate so high?
[02:42:30.260 --> 02:42:31.260]   Exactly.
[02:42:31.260 --> 02:42:36.860]   I'm glad she slept well afterwards.
[02:42:36.860 --> 02:42:37.860]   You know what?
[02:42:37.860 --> 02:42:42.140]   I took the soda out because I think I get better information from the ring because it
[02:42:42.140 --> 02:42:43.140]   measures temperature.
[02:42:43.140 --> 02:42:45.260]   Body temperature turns out to be very important.
[02:42:45.260 --> 02:42:48.660]   But the other thing is the guy who makes the ring told me this, so maybe not.
[02:42:48.660 --> 02:42:52.980]   He said, ask the soda people how much EMF it outputs.
[02:42:52.980 --> 02:42:58.180]   In order for that paddle under your mattress to measure, it's got to put out an electromagnetic
[02:42:58.180 --> 02:42:59.820]   field.
[02:42:59.820 --> 02:43:02.900]   And you put it right into your head.
[02:43:02.900 --> 02:43:06.020]   And I thought, yeah, maybe I'll disconnect that.
[02:43:06.020 --> 02:43:08.300]   I'm not saying you'll get superpowers.
[02:43:08.300 --> 02:43:09.500]   It could go the other way.
[02:43:09.500 --> 02:43:10.500]   This is passive.
[02:43:10.500 --> 02:43:13.340]   Maybe you get super bad.
[02:43:13.340 --> 02:43:19.220]   But to get back to our conversation, I think sometimes knowing too much about your sleep
[02:43:19.220 --> 02:43:23.420]   actually makes me feel more tired than if I just feel how I feel.
[02:43:23.420 --> 02:43:24.420]   And I feel tired today.
[02:43:24.420 --> 02:43:25.980]   Yeah, I feel a little tired.
[02:43:25.980 --> 02:43:27.380]   I don't know if I want to know.
[02:43:27.380 --> 02:43:32.380]   You got up six times, you were awake for half an hour and all that stuff.
[02:43:32.380 --> 02:43:36.100]   I had a doctor told me to stop taking my blood pressure at home because it was causing
[02:43:36.100 --> 02:43:37.780]   my blood pressure to go up.
[02:43:37.780 --> 02:43:38.780]   Yeah.
[02:43:38.780 --> 02:43:39.780]   To just relax.
[02:43:39.780 --> 02:43:41.180]   You're fine.
[02:43:41.180 --> 02:43:42.940]   I think maybe that's the best advice.
[02:43:42.940 --> 02:43:44.900]   That's the motto of this show.
[02:43:44.900 --> 02:43:45.900]   Just relax.
[02:43:45.900 --> 02:43:46.900]   Well, nothing.
[02:43:46.900 --> 02:43:47.900]   Don't take your blood pressure medicine, though.
[02:43:47.900 --> 02:43:48.900]   You're fine.
[02:43:48.900 --> 02:43:49.900]   I take my medicine.
[02:43:49.900 --> 02:43:50.900]   Yeah.
[02:43:50.900 --> 02:43:52.460]   I don't take my blood pressure four times a day anymore.
[02:43:52.460 --> 02:43:53.460]   I take it once in a while.
[02:43:53.460 --> 02:43:54.460]   Right.
[02:43:54.460 --> 02:43:55.460]   Exactly.
[02:43:55.460 --> 02:43:56.460]   Exactly.
[02:43:56.460 --> 02:44:00.400]   here, but a little bit more quenciling, because yeah, it could cause more stress than
[02:44:00.400 --> 02:44:01.380]   what you're getting.
[02:44:01.380 --> 02:44:02.380]   Exactly.
[02:44:02.380 --> 02:44:03.380]   But still be careful.
[02:44:03.380 --> 02:44:04.380]   Yeah, no, I agree.
[02:44:04.380 --> 02:44:06.860]   You want to look like you want to look like this baby right here.
[02:44:06.860 --> 02:44:10.320]   This is this is how we need to live life.
[02:44:10.320 --> 02:44:12.800]   Oh, get the sleep.
[02:44:12.800 --> 02:44:15.540]   You've always dreamed of it's one of the baby that worry ring.
[02:44:15.540 --> 02:44:16.540]   No ring.
[02:44:16.540 --> 02:44:18.980]   This baby does not checking its blood pressure.
[02:44:18.980 --> 02:44:21.540]   This baby is not worried about Julian Assange.
[02:44:21.540 --> 02:44:26.440]   This baby is happy and that's how you should be anxiety dash videos.com.
[02:44:26.440 --> 02:44:28.620]   Georgia Dow, thank you so much.
[02:44:28.620 --> 02:44:29.820]   It's always a pleasure.
[02:44:29.820 --> 02:44:31.300]   You can go play some VR.
[02:44:31.300 --> 02:44:34.100]   Have your, is your family been doing it since you came on three hours ago?
[02:44:34.100 --> 02:44:36.300]   I think that they've stopped an hour.
[02:44:36.300 --> 02:44:38.100]   I'm having ice cream now.
[02:44:38.100 --> 02:44:41.340]   But yeah, I'm having ice cream right now.
[02:44:41.340 --> 02:44:42.580]   Thank you so much, Georgia.
[02:44:42.580 --> 02:44:43.580]   Thank you, Brianna.
[02:44:43.580 --> 02:44:44.580]   You're the best.
[02:44:44.580 --> 02:44:45.580]   Yeah.
[02:44:45.580 --> 02:44:50.540]   I Brianna Wu 2020 in the Massachusetts eighth space.
[02:44:50.540 --> 02:44:52.580]   Go to support Brianna.com.
[02:44:52.580 --> 02:44:53.580]   Yeah.
[02:44:53.580 --> 02:44:55.140]   It's always a pleasure.
[02:44:55.140 --> 02:44:56.140]   Thank you so much.
[02:44:56.140 --> 02:44:57.140]   Is this now?
[02:44:57.140 --> 02:44:58.480]   It's so good to come on and talk tech.
[02:44:58.480 --> 02:45:01.520]   This is, you don't understand how much I love this.
[02:45:01.520 --> 02:45:03.440]   Well, we'll get soon.
[02:45:03.440 --> 02:45:04.440]   Can we get her back now?
[02:45:04.440 --> 02:45:06.440]   I just didn't want to hear you cry.
[02:45:06.440 --> 02:45:10.560]   So I want to wait for a month after the election.
[02:45:10.560 --> 02:45:11.560]   I was thrilled.
[02:45:11.560 --> 02:45:12.560]   Oh my gosh.
[02:45:12.560 --> 02:45:13.560]   Yeah.
[02:45:13.560 --> 02:45:17.720]   And you still doing, are you still working on, you know, on games and stuff or is it?
[02:45:17.720 --> 02:45:18.720]   Oh, I wish.
[02:45:18.720 --> 02:45:19.720]   Oh God.
[02:45:19.720 --> 02:45:22.840]   No, especially not the cycle where I've got a whole team.
[02:45:22.840 --> 02:45:25.560]   This is a full time job now for the next two years.
[02:45:25.560 --> 02:45:26.560]   It is.
[02:45:26.560 --> 02:45:33.140]   And one of the things like when we lost, I went and I read a large check to hire professionals
[02:45:33.140 --> 02:45:35.220]   for this for this time.
[02:45:35.220 --> 02:45:38.100]   They keep you on the stick and they will give you a guilt trip.
[02:45:38.100 --> 02:45:41.740]   Like last night I told them, I'm like, guys, I've worked 80 hours this week.
[02:45:41.740 --> 02:45:44.220]   Can I just go spend the whole thing with my husband?
[02:45:44.220 --> 02:45:45.860]   You've got to go to the cemetery.
[02:45:45.860 --> 02:45:47.820]   It's raining and who cares?
[02:45:47.820 --> 02:45:49.420]   But you're not joking.
[02:45:49.420 --> 02:45:50.420]   That's the job.
[02:45:50.420 --> 02:45:51.420]   Yes.
[02:45:51.420 --> 02:45:52.420]   There it is.
[02:45:52.420 --> 02:45:53.420]   Guess what?
[02:45:53.420 --> 02:45:54.420]   Yes.
[02:45:54.420 --> 02:45:55.420]   Yes.
[02:45:55.420 --> 02:45:56.420]   I'm talking tech with you.
[02:45:56.420 --> 02:45:57.700]   Nobody should run for Congress.
[02:45:57.700 --> 02:46:03.640]   If they want to take it easy, no, no, no, we want a job for you.
[02:46:03.640 --> 02:46:07.300]   Yeah, we want our elected representatives to work.
[02:46:07.300 --> 02:46:09.620]   Thank you, Brianna, for all the work you do.
[02:46:09.620 --> 02:46:12.220]   Brianna Wu 2020.
[02:46:12.220 --> 02:46:13.940]   And thank you, Mr. Larry Maggot.
[02:46:13.940 --> 02:46:18.860]   If you go to his website, Larry's world.com or connect safely.org, you can find all the
[02:46:18.860 --> 02:46:24.980]   good work he does to help kids especially be safe online, but also listen to him every
[02:46:24.980 --> 02:46:30.260]   day on CBS News Radio and every once in a while here.
[02:46:30.260 --> 02:46:31.260]   Thanks.
[02:46:31.260 --> 02:46:32.780]   And it was fun talking politics and psychology.
[02:46:32.780 --> 02:46:33.780]   I want to call this "Twip."
[02:46:33.780 --> 02:46:34.780]   Is it politics?
[02:46:34.780 --> 02:46:35.780]   It's actually...
[02:46:35.780 --> 02:46:43.340]   It's actually the saddest thing about this job is that I always have to talk about technology.
[02:46:43.340 --> 02:46:44.980]   Well, I'm telling a brief story.
[02:46:44.980 --> 02:46:47.100]   When I got hired by the LA Times, I called a friend.
[02:46:47.100 --> 02:46:48.860]   I said, I have good news and bad news.
[02:46:48.860 --> 02:46:49.860]   This is 1983.
[02:46:49.860 --> 02:46:50.860]   I said, "Good news.
[02:46:50.860 --> 02:46:53.980]   I'm running for America's second most popular newspaper at the time.
[02:46:53.980 --> 02:46:54.980]   It's about bad news.
[02:46:54.980 --> 02:46:56.540]   I have to write about computers.
[02:46:56.540 --> 02:46:58.460]   Who cares about computers?"
[02:46:58.460 --> 02:47:02.620]   And little did I know that it actually that would eventually become a really big story.
[02:47:02.620 --> 02:47:03.620]   You know what?
[02:47:03.620 --> 02:47:04.700]   I love my beat.
[02:47:04.700 --> 02:47:07.940]   And like you, Brianna, I love talking about technology.
[02:47:07.940 --> 02:47:10.180]   But sometimes we get together with a group.
[02:47:10.180 --> 02:47:11.180]   Yeah.
[02:47:11.180 --> 02:47:12.180]   You know what?
[02:47:12.180 --> 02:47:13.180]   The people who are on our shows are people I love.
[02:47:13.180 --> 02:47:15.740]   They're my close friends.
[02:47:15.740 --> 02:47:19.980]   And sometimes when you get together with friends, you just want to talk about stuff.
[02:47:19.980 --> 02:47:21.980]   Right.
[02:47:21.980 --> 02:47:27.580]   So I hope you listeners at home don't mind that we indulged a little bit this week.
[02:47:27.580 --> 02:47:29.500]   But it was just too much fun.
[02:47:29.500 --> 02:47:32.980]   When you get a group like this, yeah, it's good.
[02:47:32.980 --> 02:47:34.540]   Talk about everything.
[02:47:34.540 --> 02:47:35.540]   Thank you, Brianna.
[02:47:35.540 --> 02:47:36.620]   Thank you, Georgia.
[02:47:36.620 --> 02:47:37.900]   Thank you, Larry.
[02:47:37.900 --> 02:47:39.180]   Thanks to all of you.
[02:47:39.180 --> 02:47:43.580]   We do this show every Sunday, about 3 p.m. Pacific, 6 p.m. Eastern.
[02:47:43.580 --> 02:47:46.380]   We end sometimes after midnight.
[02:47:46.380 --> 02:47:48.420]   Like a baseball game.
[02:47:48.420 --> 02:47:52.460]   This was an 18 in game.
[02:47:52.460 --> 02:47:55.620]   We were nearing in 15 minutes, it'll be a three hour show.
[02:47:55.620 --> 02:48:00.420]   So I think that might be a record setter.
[02:48:00.420 --> 02:48:02.420]   But we had a lot to talk about.
[02:48:02.420 --> 02:48:03.420]   We do it.
[02:48:03.420 --> 02:48:04.740]   If you want to watch live, we do it live.
[02:48:04.740 --> 02:48:08.100]   You can watch audio or listen to video at twitter.tv/live.
[02:48:08.100 --> 02:48:10.540]   We're back on YouTube live.
[02:48:10.540 --> 02:48:12.060]   Apple decided not to sue us.
[02:48:12.060 --> 02:48:13.900]   So that's good news.
[02:48:13.900 --> 02:48:14.900]   We were pulled down.
[02:48:14.900 --> 02:48:15.900]   I don't know.
[02:48:15.900 --> 02:48:16.900]   I've told the story.
[02:48:16.900 --> 02:48:19.380]   We were pulled down.
[02:48:19.380 --> 02:48:21.020]   We've done this for years.
[02:48:21.020 --> 02:48:23.420]   I've done this since 2005.
[02:48:23.420 --> 02:48:27.660]   When Apple streams its events, we would broadcast a stream and comment on it.
[02:48:27.660 --> 02:48:31.500]   As journalists, one does, right?
[02:48:31.500 --> 02:48:35.620]   But for some reason, Apple hired a lawyer who decided to be a hard ass.
[02:48:35.620 --> 02:48:42.660]   And in the middle of our YouTube stream, they pulled us down, knocked us off.
[02:48:42.660 --> 02:48:44.580]   And we appealed immediately as we always do.
[02:48:44.580 --> 02:48:48.660]   But YouTube live is different from YouTube downloadable videos.
[02:48:48.660 --> 02:48:50.980]   The appeal takes a long time.
[02:48:50.980 --> 02:48:57.740]   And then they give the company that's complaining, that's complaining, something like 16 days
[02:48:57.740 --> 02:49:00.980]   to reply, Apple never replied.
[02:49:00.980 --> 02:49:02.380]   We said, no, no, this is a fair use.
[02:49:02.380 --> 02:49:03.900]   We're a news organization.
[02:49:03.900 --> 02:49:05.740]   Apple neither agreed or disagreed.
[02:49:05.740 --> 02:49:07.380]   They just didn't say anything.
[02:49:07.380 --> 02:49:11.380]   So YouTube removed the strike and we're back up as of I think Thursday, Wednesday or Thursday
[02:49:11.380 --> 02:49:12.380]   on YouTube.
[02:49:12.380 --> 02:49:13.380]   Good.
[02:49:13.380 --> 02:49:15.780]   Does that mean the next time you can comment?
[02:49:15.780 --> 02:49:17.380]   Well, it's no, it doesn't.
[02:49:17.380 --> 02:49:18.780]   It's a chilling effect, right?
[02:49:18.780 --> 02:49:21.180]   Now I have to think, what am I going to do?
[02:49:21.180 --> 02:49:23.340]   Because I don't want to get into that.
[02:49:23.340 --> 02:49:24.340]   That happened.
[02:49:24.340 --> 02:49:25.980]   It took us down for two weeks.
[02:49:25.980 --> 02:49:27.740]   We need to cut a five fair use.
[02:49:27.740 --> 02:49:29.940]   I feel more in the law.
[02:49:29.940 --> 02:49:31.500]   It's a very abstract principle.
[02:49:31.500 --> 02:49:33.500]   It's not even a principle.
[02:49:33.500 --> 02:49:34.500]   It's a defense.
[02:49:34.500 --> 02:49:38.900]   Apple temporarily stopped inviting me to events that I never even hit an intern.
[02:49:38.900 --> 02:49:39.900]   I mean, eventually.
[02:49:39.900 --> 02:49:44.260]   I feel like it's in the Supreme Court, Larry.
[02:49:44.260 --> 02:49:45.740]   That's the way to go.
[02:49:45.740 --> 02:49:47.700]   Anyway, we're glad that you can watch it.
[02:49:47.700 --> 02:49:48.980]   The thing is we have other streams.
[02:49:48.980 --> 02:49:49.980]   We have Twitch.
[02:49:49.980 --> 02:49:50.980]   We have mixer.
[02:49:50.980 --> 02:49:51.980]   We have use stream.
[02:49:51.980 --> 02:49:53.380]   We have lots of other streams in there all available.
[02:49:53.380 --> 02:49:56.580]   You pick the one that works best for you at twit.tv/live.
[02:49:56.580 --> 02:49:59.460]   If you do watch or listen live, please join us in the chat room.
[02:49:59.460 --> 02:50:05.420]   It's always a, there's a great side conversation going on 24/7 at IRC.twit.tv.
[02:50:05.420 --> 02:50:07.180]   That's become a community of friends.
[02:50:07.180 --> 02:50:09.820]   It's wonderful to go in there and everybody says, hi, welcome.
[02:50:09.820 --> 02:50:12.500]   And all that IRC.twit.tv.
[02:50:12.500 --> 02:50:16.140]   You can use your browser or if you're, you know, you have an IRC client, if you're one
[02:50:16.140 --> 02:50:18.580]   of the old timers, you can use that too.
[02:50:18.580 --> 02:50:25.100]   If you're not available at 3 p.m. Pacific, 6 p.m. Eastern, 2300 UTC on a Sunday evening,
[02:50:25.100 --> 02:50:26.100]   no problem.
[02:50:26.100 --> 02:50:32.140]   We make on demand audio and video available for everything we do at our website, twit.tv.
[02:50:32.140 --> 02:50:35.180]   You can download it there, but you know what the best thing to do would be and it would
[02:50:35.180 --> 02:50:38.780]   do me, you'd be doing me an honor if you'd subscribe.
[02:50:38.780 --> 02:50:42.620]   That way the minute the show is available, you get downloaded automatically to your phone
[02:50:42.620 --> 02:50:46.220]   and you can listen anytime you want.
[02:50:46.220 --> 02:50:47.540]   Just pick your favorite podcast app.
[02:50:47.540 --> 02:50:50.260]   I think you'll find this week in tech everywhere.
[02:50:50.260 --> 02:50:54.300]   You can even ask your Amazon Echo or your Google home or your series, say, listen to
[02:50:54.300 --> 02:50:57.660]   this week in tech and it'll play the most recent version.
[02:50:57.660 --> 02:50:58.820]   Thank you everybody.
[02:50:58.820 --> 02:51:00.380]   I think we're done.
[02:51:00.380 --> 02:51:03.740]   Another twit is in the can.
[02:51:03.740 --> 02:51:04.500]   We'll see you next time.
[02:51:04.500 --> 02:51:04.780]   Bye bye.
[02:51:04.780 --> 02:51:07.380]   (upbeat music)
[02:51:07.380 --> 02:51:09.960]   (upbeat music)
[02:51:09.960 --> 02:51:11.760]   ♪ Doin' the twit, baby ♪
[02:51:11.760 --> 02:51:12.600]   ♪ Doin' the twit ♪
[02:51:12.600 --> 02:51:13.600]   ♪ Alright ♪
[02:51:13.600 --> 02:51:14.820]   ♪ Doin' the twit ♪

