;FFMETADATA1
title=A Game of Hold My Beer
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=659
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:01.420]   as
[00:00:01.420 --> 00:00:04.500]   time for twit this week in tech we've got a great panel for you to these how
[00:00:04.500 --> 00:00:06.580]   will join us from this weekend law
[00:00:06.580 --> 00:00:10.780]   from the register dot co dot u_k_ the news editor in topson
[00:00:10.780 --> 00:00:13.220]   harry macracken from fast company
[00:00:13.220 --> 00:00:16.100]   and of course big the big story face book
[00:00:16.100 --> 00:00:17.540]   kimber janolitica
[00:00:17.540 --> 00:00:21.180]   the uber self-driving car who really was at fault
[00:00:21.180 --> 00:00:24.580]   uh... and a whole lot more it's a it's a big day today lots of stories all
[00:00:24.580 --> 00:00:26.620]   yell it's not forget what congress did
[00:00:26.620 --> 00:00:28.460]   what congress did
[00:00:28.460 --> 00:00:33.460]   so come up next on twit
[00:00:33.460 --> 00:00:35.460]   that has to love
[00:00:35.460 --> 00:00:41.020]   from people you trust
[00:00:41.020 --> 00:00:41.440]   this
[00:00:41.440 --> 00:00:43.020]   is to it
[00:00:43.020 --> 00:00:48.820]   bandwidth for this weekend tech is provided by cash fly at c_a_c_ h_e_ f_l_y_
[00:00:48.820 --> 00:00:54.820]   dot com
[00:00:54.820 --> 00:00:59.300]   this is twit this weekend tech episode six hundred fifty nine recorded sunday
[00:00:59.300 --> 00:01:01.820]   march twenty-fifth twenty eighteen
[00:01:01.820 --> 00:01:02.780]   a game
[00:01:02.780 --> 00:01:05.540]   of all my beer
[00:01:05.540 --> 00:01:07.500]   this weekend tech is brought to you by
[00:01:07.500 --> 00:01:10.500]   kubernetes engine on google cloud platform
[00:01:10.500 --> 00:01:14.220]   learn more at g dot c_o_ slash g_t_
[00:01:14.220 --> 00:01:16.740]   g_k_e_ today
[00:01:16.740 --> 00:01:17.660]   and by
[00:01:17.660 --> 00:01:22.620]   last pass join over thirteen million last pass users including me
[00:01:22.620 --> 00:01:26.860]   and start managing and securing your passwords today learn more at last pass
[00:01:26.860 --> 00:01:28.660]   dot com slash twit
[00:01:28.660 --> 00:01:29.700]   and by
[00:01:29.700 --> 00:01:34.060]   blue apron the number one fresh ingredient and recipe delivery service
[00:01:34.060 --> 00:01:35.100]   in the country
[00:01:35.100 --> 00:01:37.780]   check out this week's menu and get thirty dollars off your first order with
[00:01:37.780 --> 00:01:38.820]   free shipping
[00:01:38.820 --> 00:01:41.940]   by going to blue a print dot com slash twit
[00:01:41.940 --> 00:01:44.060]   and by zipper cruder
[00:01:44.060 --> 00:01:47.500]   hiring zipper cruder has revolutionized how you do it
[00:01:47.500 --> 00:01:51.180]   their technology identifies people with the right experience and invites them to
[00:01:51.180 --> 00:01:53.060]   apply to your job
[00:01:53.060 --> 00:01:54.340]   try free today
[00:01:54.340 --> 00:01:56.100]   at zipper cruder dot com
[00:01:56.100 --> 00:01:59.460]   slash twit
[00:01:59.460 --> 00:02:02.420]   it's time for twit this weekend tech the show we cover the weeks
[00:02:02.420 --> 00:02:06.180]   tech news did anything at all happen this week i think it's going to be very
[00:02:06.180 --> 00:02:06.980]   slow but
[00:02:06.980 --> 00:02:09.700]   it doesn't matter because we have an entertaining crew here for you in
[00:02:09.700 --> 00:02:10.820]   tumpsen
[00:02:10.820 --> 00:02:14.300]   from the register now uh... new title for you what is your new title
[00:02:14.300 --> 00:02:17.940]   i'm now news that is if the register very nice uh... yes i've become
[00:02:17.940 --> 00:02:20.220]   corporate and i'm actually since
[00:02:20.220 --> 00:02:23.660]   yeah i mean i might have to start wearing a t-shirt to work but yeah
[00:02:23.660 --> 00:02:27.980]   and i'm sure that i think whatever you're wearing looks very British
[00:02:27.980 --> 00:02:29.460]   uh...
[00:02:29.460 --> 00:02:31.620]   and you should keep it up
[00:02:31.620 --> 00:02:34.860]   so the people have sent you know i don't know it doesn't look like i don't know
[00:02:34.860 --> 00:02:38.420]   it's in shaco i don't know you're playing rugby or something i don't know
[00:02:38.420 --> 00:02:42.780]   what it is there's a very pretty is the beautiful game it is the beautiful game
[00:02:42.780 --> 00:02:46.620]   but it's a beautiful game unless unless your knees if your pair of knees rugby
[00:02:46.620 --> 00:02:49.220]   is not the beautiful gale teeth or collarbone
[00:02:49.220 --> 00:02:50.940]   the other body part
[00:02:50.940 --> 00:02:54.300]   you might mention harry macracken the technologist is also here
[00:02:54.300 --> 00:02:56.940]   harry's technology editor at fast company
[00:02:56.940 --> 00:03:00.580]   we've got some big spig names in here to hire a good to see you to be here
[00:03:00.580 --> 00:03:03.100]   always a pleasure to have you on
[00:03:03.100 --> 00:03:04.860]   and
[00:03:04.860 --> 00:03:08.620]   from right to left i guess the next would be denise howl from this week in
[00:03:08.620 --> 00:03:09.420]   law
[00:03:09.420 --> 00:03:10.660]   hello denise
[00:03:10.660 --> 00:03:12.660]   highly a high-hury high-end
[00:03:12.660 --> 00:03:13.620]   you are
[00:03:13.620 --> 00:03:17.140]   but we bring our legal counsel in because we're going to be talking about the law
[00:03:17.140 --> 00:03:19.860]   but it's all getting sued
[00:03:19.860 --> 00:03:21.820]   i'm not as an orange so you know
[00:03:21.820 --> 00:03:24.980]   so we've been uh... we've been talking beforehand and there's really three big
[00:03:24.980 --> 00:03:27.820]   stories will cover a number of them but the three big stories are going to be
[00:03:27.820 --> 00:03:30.820]   facebook slash kamri janel it is that really
[00:03:30.820 --> 00:03:34.820]   heated up a broke last week but it really heated up this most recent week
[00:03:34.820 --> 00:03:37.620]   uh... in fact today full page
[00:03:37.620 --> 00:03:40.860]   article in the new york times
[00:03:40.860 --> 00:03:44.740]   in the u_k_ was it in the uh... the observer observer which is where the
[00:03:44.740 --> 00:03:46.260]   story broke yet
[00:03:46.260 --> 00:03:49.020]   a pal mark bersucker burger apologizing
[00:03:49.020 --> 00:03:50.220]   you apologize
[00:03:50.220 --> 00:03:51.660]   not apologizing
[00:03:51.660 --> 00:03:55.100]   is not good at apologize that he was sorry but that that's not exactly the same
[00:03:55.100 --> 00:03:56.940]   all i thought that was an apology
[00:03:56.940 --> 00:03:58.540]   uh... the way he said it
[00:03:58.540 --> 00:04:02.300]   is hard to apologize without using the words i apologize which is more like i'm
[00:04:02.300 --> 00:04:05.140]   sorry this happens to me yeah
[00:04:05.140 --> 00:04:06.820]   so we got found out
[00:04:06.820 --> 00:04:09.420]   sorry we got discovered
[00:04:09.420 --> 00:04:13.700]   will also talk about and and and i'm glad to have some legal support on this
[00:04:13.700 --> 00:04:15.580]   one uh... congress
[00:04:15.580 --> 00:04:18.780]   are do nothing covers got very active last week
[00:04:18.780 --> 00:04:20.740]   and snuck some stuff in
[00:04:20.740 --> 00:04:25.060]   they passed up a bill that uh... ostensibly is against sex trafficking
[00:04:25.060 --> 00:04:26.900]   who's in favor of that
[00:04:26.900 --> 00:04:31.500]   but it has a much larger impact on blogs on craigslist
[00:04:31.500 --> 00:04:33.020]   on reddit
[00:04:33.020 --> 00:04:35.860]   uh... foster and sesta
[00:04:35.860 --> 00:04:40.780]   and they snuck in at the last minute to the budget appropriations bill
[00:04:40.780 --> 00:04:45.100]   page two thousand what was it two thousand two hundred and one out of a
[00:04:45.100 --> 00:04:49.140]   two thousand two hundred and thirty two page bill they snuck in the cloud act
[00:04:49.140 --> 00:04:51.420]   which they've been trying to get passed through congress
[00:04:51.420 --> 00:04:54.580]   and oddly enough microsoft and google facebook have been trying to get passed
[00:04:54.580 --> 00:04:56.180]   through congress all this time
[00:04:56.180 --> 00:04:59.580]   because it lets them off the hook so we'll talk about that exactly uh... we
[00:04:59.580 --> 00:05:03.780]   talked last week about ubers self-driving vehicle uh... sadly killing a
[00:05:03.780 --> 00:05:07.940]   pedestrian well now it looks like they may be evidence it's ubers fault
[00:05:07.940 --> 00:05:11.060]   we'll get into that as well let's start with face book though and marx ocher
[00:05:11.060 --> 00:05:12.460]   birds
[00:05:12.460 --> 00:05:15.020]   pseudo apology
[00:05:15.020 --> 00:05:19.820]   i tried to do the timeline is kamper jennel it is a really fast changing
[00:05:19.820 --> 00:05:21.780]   story
[00:05:21.780 --> 00:05:26.260]   in opane general pictures and you can correct me if i get it wrong or
[00:05:26.260 --> 00:05:28.780]   you know i'd the this mother jones article what kind of
[00:05:28.780 --> 00:05:32.180]   implies that that kamper jennel it go overstated its
[00:05:32.180 --> 00:05:36.020]   capabilities in order to some to fleece candidates for money including
[00:05:36.020 --> 00:05:39.740]   uh... ted crews who was one of the first uh... candidates to use
[00:05:39.740 --> 00:05:41.020]   kamper jennel it
[00:05:41.020 --> 00:05:43.140]   the story is this is a company
[00:05:43.140 --> 00:05:47.460]   created out of another british company called s l c
[00:05:47.460 --> 00:05:51.580]   what is this else sees job there's still around yet there are general
[00:05:51.580 --> 00:05:52.020]   uh...
[00:05:52.020 --> 00:05:56.020]   data monitoring and data merchants
[00:05:56.020 --> 00:05:57.020]   uh...
[00:05:57.020 --> 00:06:01.060]   it's coming across between public relations marketing advertising and they
[00:06:01.060 --> 00:06:05.420]   have many tori politicians in britain as clients i wouldn't surprise if they're
[00:06:05.420 --> 00:06:08.900]   a labor liberal democrat politicians as well but some
[00:06:08.900 --> 00:06:12.740]   now they uh... they can't they were already being investigated by the u_k_
[00:06:12.740 --> 00:06:13.500]   palman
[00:06:13.500 --> 00:06:17.300]   over fears that they didn't feel involved themselves in the brexit vote
[00:06:17.300 --> 00:06:18.740]   and uh...
[00:06:18.740 --> 00:06:21.820]   indeed one of their staffers put out a press release saying we are going to be
[00:06:21.820 --> 00:06:23.940]   working with the leave campaign for brexit
[00:06:23.940 --> 00:06:27.580]   and schedule a press conference and then got pulled very quickly and it's like
[00:06:27.580 --> 00:06:30.420]   no that was someone being over enthusiastically and haven't actually
[00:06:30.420 --> 00:06:32.020]   done the business with them
[00:06:32.020 --> 00:06:35.940]   but we've seen in the investigations over the week they are at their on video
[00:06:35.940 --> 00:06:40.420]   is saying oh yes we can we can not invoice us from ourselves we can
[00:06:40.420 --> 00:06:43.300]   find another dummy company we can invoice you from that in that way you
[00:06:43.300 --> 00:06:45.900]   could plausible to know that it is a they were doing something that they
[00:06:45.900 --> 00:06:49.540]   really been going on for decades the idea of trying to understand the public
[00:06:49.540 --> 00:06:52.980]   in their interests and how and their so and their weak spots their their
[00:06:52.980 --> 00:06:54.260]   their pressure points
[00:06:54.260 --> 00:06:55.580]   uh...
[00:06:55.580 --> 00:06:57.540]   if or mark for the purpose of marketing
[00:06:57.540 --> 00:06:59.220]   by observing behavior
[00:06:59.220 --> 00:07:04.140]   and the problem is that over the last decade can computers and big databases
[00:07:04.140 --> 00:07:05.420]   and information
[00:07:05.420 --> 00:07:08.340]   treasure tropes like google and face book have become
[00:07:08.340 --> 00:07:11.060]   such rich sources of this information
[00:07:11.060 --> 00:07:12.980]   that these companies have be
[00:07:12.980 --> 00:07:15.620]   or maybe not but the contention is these companies have
[00:07:15.620 --> 00:07:18.660]   in effect weaponizes with timber is lead yeah the creator of the of the
[00:07:18.660 --> 00:07:19.420]   website
[00:07:19.420 --> 00:07:20.860]   have weaponized
[00:07:20.860 --> 00:07:22.580]   these surveillance
[00:07:22.580 --> 00:07:23.660]   mechanisms
[00:07:23.660 --> 00:07:26.060]   to really take advantage of them
[00:07:26.060 --> 00:07:29.380]   and i think from s l c's point of view and christopher while i the whistle
[00:07:29.380 --> 00:07:30.180]   blower who
[00:07:30.180 --> 00:07:32.980]   who out of kimber jatlinica started at s l c
[00:07:32.980 --> 00:07:36.740]   and went along with andrin next and others to to work at kimber jatlinica
[00:07:36.740 --> 00:07:40.260]   i think where kimber jatlinica's genesis came from
[00:07:40.260 --> 00:07:41.900]   is this study
[00:07:41.900 --> 00:07:44.220]   that showed up in the uh...
[00:07:44.220 --> 00:07:45.780]   uh... the uh...
[00:07:45.780 --> 00:07:50.060]   proceedings of the national academy of sciences
[00:07:50.060 --> 00:07:51.500]   of the u_s_ of a
[00:07:51.500 --> 00:07:54.740]   in february twenty thirteen this is a five-year-old
[00:07:54.740 --> 00:07:55.540]   study
[00:07:55.540 --> 00:08:01.020]   and what what happened was they they uh... took fifty eight thousand volunteers
[00:08:01.020 --> 00:08:04.740]   they got from their volunteers their face book likes
[00:08:04.740 --> 00:08:09.180]   detailed demographic profiles and then given a bunch of psychometric tests
[00:08:09.180 --> 00:08:11.060]   and we're able to come up with some
[00:08:11.060 --> 00:08:12.740]   kind of surprising
[00:08:12.740 --> 00:08:15.620]   correlations and this gave marketers a
[00:08:15.620 --> 00:08:18.940]   just a little chill down their spine oh my god
[00:08:18.940 --> 00:08:22.140]   somebody's saying signs to which crowd can face book likes are pretty
[00:08:22.140 --> 00:08:24.740]   widely available in turns out
[00:08:24.740 --> 00:08:29.220]   can be fairly predictive of lots of things race gender
[00:08:29.220 --> 00:08:30.420]   politics
[00:08:30.420 --> 00:08:31.860]   intelligence
[00:08:31.860 --> 00:08:34.900]   here's some of the things that according to this article your face book likes
[00:08:34.900 --> 00:08:37.420]   can tell you with a very high accuracy
[00:08:37.420 --> 00:08:40.580]   the best predictors of high intelligence include
[00:08:40.580 --> 00:08:43.940]   likes for these categories thunderstorms
[00:08:43.940 --> 00:08:46.420]   the colbert report that's how old this is
[00:08:46.420 --> 00:08:47.700]   science
[00:08:47.700 --> 00:08:49.700]   and curly fries
[00:08:49.700 --> 00:08:52.020]   good curly fry that these are hot
[00:08:52.020 --> 00:08:53.980]   high but not just predictors
[00:08:53.980 --> 00:08:57.740]   highly correlated like a percent correlation
[00:08:57.740 --> 00:08:59.620]   good predictors of
[00:08:59.620 --> 00:09:01.020]   low intelligence
[00:09:01.020 --> 00:09:02.500]   so for a
[00:09:02.500 --> 00:09:04.460]   i love being a mom
[00:09:04.460 --> 00:09:05.940]   highly date
[00:09:05.940 --> 00:09:07.780]   i'm sorry it's Denise but
[00:09:07.780 --> 00:09:11.820]   actually somebody we did i mention this on us on wednesday and uh... this
[00:09:11.820 --> 00:09:15.140]   week in google and stacey said boy that's very sexist on both those but also
[00:09:15.140 --> 00:09:16.380]   hardly davis and
[00:09:16.380 --> 00:09:19.340]   in the country group lady antebellum
[00:09:19.340 --> 00:09:22.660]   but you can do is do it to predict sexual orientation within eighty eight
[00:09:22.660 --> 00:09:25.460]   percent accuracy if turns out if you like
[00:09:25.460 --> 00:09:28.580]   mac cosmetics and wicked the musical
[00:09:28.580 --> 00:09:30.020]   you probably gay
[00:09:30.020 --> 00:09:33.060]   i'd like both i use both
[00:09:33.060 --> 00:09:35.540]   while you said that you'd like to tell us
[00:09:35.540 --> 00:09:38.820]   so but the point is it's not perfect and in fact people lie to face book there's
[00:09:38.820 --> 00:09:42.500]   other reasons why it be imperfect says that i identify as
[00:09:42.500 --> 00:09:44.020]   african-american
[00:09:44.020 --> 00:09:46.660]   and go in and see what they tell advertisers
[00:09:46.660 --> 00:09:49.700]   they say that my cultural affinity is african-american isn't that interesting
[00:09:49.700 --> 00:09:53.260]   and i'm not i'm not sure why they may though not be completely forthright with
[00:09:53.260 --> 00:09:56.740]   you right because they also don't want people to know how much
[00:09:56.740 --> 00:09:59.860]   information could be deduced from your face but he comes down to how you use
[00:09:59.860 --> 00:10:03.540]   social media i mean if you just going on social media to report exactly what's
[00:10:03.540 --> 00:10:04.740]   happening to you
[00:10:04.740 --> 00:10:06.180]   every day of your life
[00:10:06.180 --> 00:10:09.900]   then it might be fairly accurate but most people i think you use it
[00:10:09.900 --> 00:10:13.260]   are only putting up a very small section of their life that they just want other
[00:10:13.260 --> 00:10:14.620]   people to know about right
[00:10:14.620 --> 00:10:18.740]   so i don't think it's entirely it's not but come on you press the like button
[00:10:18.740 --> 00:10:23.780]   from time to time oh yeah sure no i don't i've almost never liked a brand or
[00:10:23.780 --> 00:10:27.700]   a thing i like comments from my friends do you like
[00:10:27.700 --> 00:10:30.980]   wutang clan never expressed an opinion when we're together
[00:10:30.980 --> 00:10:35.540]   jack never said how about being confused after waking up from naps
[00:10:35.540 --> 00:10:40.180]   if you ever like that group that means you're straight experience that's a
[00:10:40.180 --> 00:10:44.420]   strong predictor male heterosexuality if you like waking up confused
[00:10:44.420 --> 00:10:48.260]   from naps i don't know why but and that's the point of this and that's why big
[00:10:48.260 --> 00:10:50.420]   data is interesting because it's not intuitive
[00:10:50.420 --> 00:10:55.540]   it's correlations it's just correlations if you like hello kitty
[00:10:55.540 --> 00:11:00.900]   do you like hello kitty anybody if you like hello kitty you i mean it's hard to
[00:11:00.900 --> 00:11:05.140]   hate hello kitty but if you actually press the like button hello kitty that's
[00:11:05.140 --> 00:11:09.540]   the key that you're right this isn't just like i like hello kitty who doesn't
[00:11:09.540 --> 00:11:14.820]   if you actively like hello kitty on facebook you tend to be high on openness
[00:11:14.820 --> 00:11:19.460]   but low on conscientiousness agreeableness and emotional stability
[00:11:19.460 --> 00:11:23.700]   now i don't know the i mean
[00:11:23.700 --> 00:11:27.220]   anyway that's the way it is they they saw i believe christopher wily and the
[00:11:27.220 --> 00:11:29.860]   folks at kambert generalica saw this study and said
[00:11:29.860 --> 00:11:32.820]   hmm because marketers are always looking for ways to find
[00:11:32.820 --> 00:11:36.420]   soft spots right in people to target and they actually created their own
[00:11:36.420 --> 00:11:39.780]   psychological test a guy named alexander kogan
[00:11:39.780 --> 00:11:43.300]   who kambert university is very anxious to point out
[00:11:43.300 --> 00:11:47.140]   yes he was a teacher here but no we did not approve this study we rejected it and
[00:11:47.140 --> 00:11:50.660]   he went over to the soviet to former soviet in russia
[00:11:50.660 --> 00:11:54.500]   and some russian university got them to approve it but he made a psychological
[00:11:54.500 --> 00:11:57.700]   similar to this study a psychological test
[00:11:57.700 --> 00:12:01.460]   uh... advertising on facebook got people to take it he said we'll pay you they
[00:12:01.460 --> 00:12:04.020]   they got a token they paid you but he also because the test
[00:12:04.020 --> 00:12:06.820]   somehow was linked to facebook was able to get this was in the days when
[00:12:06.820 --> 00:12:09.700]   facebook not only gave you
[00:12:09.700 --> 00:12:13.140]   and gave your information to these quizzes
[00:12:13.140 --> 00:12:17.220]   this was an off facebook quiz but somehow he got access to that and
[00:12:17.220 --> 00:12:20.100]   this was when friends of friends were still in act the face yeah turned that
[00:12:20.100 --> 00:12:21.300]   off a few years ago
[00:12:21.300 --> 00:12:26.580]   but he ends up after getting i think uh... i can remember 70 70 000
[00:12:26.580 --> 00:12:30.180]   questioners he got a quarter of no it was uh it was two hundred and seventy
[00:12:30.180 --> 00:12:34.100]   thousand questioners but he got fifty million people out of it because of the
[00:12:34.100 --> 00:12:35.140]   friends of friends
[00:12:35.140 --> 00:12:37.380]   that database which normally
[00:12:37.380 --> 00:12:41.620]   facebook holds on tight tube because after all this is their business model
[00:12:41.620 --> 00:12:44.100]   it's not that they don't want that information as they want to keep it
[00:12:44.100 --> 00:12:46.260]   themselves so they can sell it
[00:12:46.260 --> 00:12:49.860]   but came regen ledica because it was an academic study
[00:12:49.860 --> 00:12:52.820]   they claimed i was able to get it out of facebook and apparently keep
[00:12:52.820 --> 00:12:55.540]   it kept it for a long time even though they swore to mark zuckerberg
[00:12:55.540 --> 00:12:59.220]   i promise we deleted that and mark said well it was a legal document they
[00:12:59.220 --> 00:13:00.660]   must have
[00:13:00.660 --> 00:13:04.340]   uh nevertheless used that information on fifty million voters
[00:13:04.340 --> 00:13:08.980]   and here's and by the way that's exactly facebook's business model that's how
[00:13:08.980 --> 00:13:12.660]   facebook works yeah that's how it works today the only thing that they did
[00:13:12.660 --> 00:13:15.380]   wrong from facebook's point of view is kept the data instead of having to buy
[00:13:15.380 --> 00:13:16.420]   it
[00:13:16.420 --> 00:13:19.060]   from facebook but here's maybe something that you and i should be more
[00:13:19.060 --> 00:13:22.740]   considered about considered more of a problem is that they then
[00:13:22.740 --> 00:13:25.940]   apparently maybe gave it to the internet research agency
[00:13:25.940 --> 00:13:30.900]   the russian arm of troll farm and that information was used by them
[00:13:30.900 --> 00:13:32.500]   to create
[00:13:32.500 --> 00:13:36.020]   this and i don't you know it's you i see this again and again somebody just
[00:13:36.020 --> 00:13:39.700]   said it in the in the chair oh bomb i did the same thing it's just because it's
[00:13:39.700 --> 00:13:43.140]   trumped it that's not the problem so much every campaign does this
[00:13:43.140 --> 00:13:46.740]   yeah in fact the first uh came regen ledica customer was Ted Cruz
[00:13:46.740 --> 00:13:49.300]   yeah but
[00:13:49.300 --> 00:13:52.740]   the russians might have used it to sow dissent and discord in the united
[00:13:52.740 --> 00:13:56.660]   states by creating opposing groups all sorts of fake stuff
[00:13:56.660 --> 00:13:59.940]   uh and that's i think of interest if a foreign
[00:13:59.940 --> 00:14:05.700]   interest tried to create polarization in this country using this information
[00:14:05.700 --> 00:14:09.380]   in any event um it's all the chickens have come home to roost mark zucker
[00:14:09.380 --> 00:14:13.380]   berg did interviews he doesn't like doing interviews on cnn
[00:14:13.380 --> 00:14:16.580]   that recode with the new york times
[00:14:16.580 --> 00:14:22.420]   um did he didn't do you ever say i apologize as far as i know he has not
[00:14:22.420 --> 00:14:25.140]   used that word he's certainly expressed regret and said they
[00:14:25.140 --> 00:14:28.660]   messed up and that um they're taking actions to prevent it from happening
[00:14:28.660 --> 00:14:35.540]   again but any i think he said that um we we failed you and um if we can't
[00:14:35.540 --> 00:14:37.700]   keep your trust them you don't deserve to
[00:14:37.700 --> 00:14:43.220]   uh Alex stamos facebook's i think widely regarded uh highly regarded uh
[00:14:43.220 --> 00:14:47.060]   security chief he was a young look yeah i think people like him he's left
[00:14:47.060 --> 00:14:50.340]   facebook saying i tried to explain to the executive it's on his way out
[00:14:50.340 --> 00:14:53.940]   apparently yeah august will be his uh but and that's mostly a transitional
[00:14:53.940 --> 00:14:56.660]   thing he had a team of 120 people now to reduce to three so
[00:14:56.660 --> 00:15:00.340]   he's not really correct he hasn't really been doing anything for a while
[00:15:00.340 --> 00:15:03.380]   but he says i tried to convince facebook's executives at russian
[00:15:03.380 --> 00:15:06.020]   trolls were using this information they didn't listen
[00:15:06.020 --> 00:15:09.380]   uh so i think they listened they just didn't cast here's my about that's
[00:15:09.380 --> 00:15:12.740]   what kind of my question is isn't it denise is in this facebook's
[00:15:12.740 --> 00:15:16.340]   business model this is what they do or why is anybody surprised
[00:15:16.340 --> 00:15:21.620]   what's wrong with this picture uh well i think we have to go to the
[00:15:21.620 --> 00:15:25.940]   we have to back the timeline up a little further back than you even went
[00:15:25.940 --> 00:15:28.980]   um in fact we could back the timeline up all the way back to the
[00:15:28.980 --> 00:15:34.580]   inception of facebook when they first unleashed themselves from the
[00:15:34.580 --> 00:15:38.420]   universities where they were helping people hook up right
[00:15:38.420 --> 00:15:46.900]   and uh opened to the general public and their business model then was
[00:15:46.900 --> 00:15:50.820]   we want as many users as possible we don't know how we're going to make
[00:15:50.820 --> 00:15:56.580]   money off of this yet but we know that if we create a great service
[00:15:56.580 --> 00:16:01.780]   where people like to come user service they like to come back
[00:16:01.780 --> 00:16:06.820]   they trust us they are willingly handing over all this information
[00:16:06.820 --> 00:16:12.500]   then we can build a business model on that so over the course of the history
[00:16:12.500 --> 00:16:17.140]   of the company its priorities have changed it used to look after
[00:16:17.140 --> 00:16:22.020]   the interests of its users because that's what it needed at the time when it
[00:16:22.020 --> 00:16:24.500]   started right it really really wanted to build that
[00:16:24.500 --> 00:16:28.740]   huge millions and millions of of customer base
[00:16:28.740 --> 00:16:32.340]   and then it flipped right once it decided its business model was
[00:16:32.340 --> 00:16:35.620]   to sell all that information to advertisers
[00:16:35.620 --> 00:16:41.140]   in ways that hadn't been done before uh then the advertisers began to take
[00:16:41.140 --> 00:16:47.060]   precedence as to whose interests were going to be put first
[00:16:47.060 --> 00:16:50.740]   and and that's where we find ourselves now
[00:16:50.740 --> 00:16:54.900]   so as we've watched that progression over the years
[00:16:54.900 --> 00:16:59.220]   privacy watch dogs like for example the electronic privacy information
[00:16:59.220 --> 00:17:02.820]   center another mark to throw into the mix here mark
[00:17:02.820 --> 00:17:07.540]   rotenberg not zuckerberg heads the heads epic
[00:17:07.540 --> 00:17:12.740]   and uh he is is so ticked off at the ftc right now
[00:17:12.740 --> 00:17:16.900]   if you haven't seen his piece in tech economy
[00:17:16.900 --> 00:17:20.820]   uh that was published this week it is well worth checking out marks one of the
[00:17:20.820 --> 00:17:24.260]   good guys and epic is what is a really important group that protects our
[00:17:24.260 --> 00:17:29.940]   interests online so what did mark say he details there how
[00:17:29.940 --> 00:17:34.020]   you know we started to sound the alarm about this shift in priorities
[00:17:34.020 --> 00:17:38.980]   back in 2009 well we all but haven't we all been doing this
[00:17:38.980 --> 00:17:44.260]   right and and they were but it was the complaint that epic filed that ultimately
[00:17:44.260 --> 00:17:50.980]   led to the consent decree the settlement on facebook's part with the ftc
[00:17:50.980 --> 00:17:56.100]   uh as as part of that settlement uh the ftc
[00:17:56.100 --> 00:17:59.860]   states facebook represented that third party apps that users installed would
[00:17:59.860 --> 00:18:03.300]   have access only to user information that they needed to operate
[00:18:03.300 --> 00:18:08.020]   in fact the apps could access nearly all of users personal data
[00:18:08.020 --> 00:18:12.260]   dated the apps didn't need that was that was all going back to the
[00:18:12.260 --> 00:18:17.700]   original epic complaint in 2009 so epic continued to you know bang the drum
[00:18:17.700 --> 00:18:21.540]   as the years went on went back in in 2012 and said
[00:18:21.540 --> 00:18:25.140]   you know ftc you really need to be holding these companies feet to the fire for
[00:18:25.140 --> 00:18:29.300]   these settlements that we reached and and the fdc didn't
[00:18:29.300 --> 00:18:34.020]   do all that it could uh and we find ourselves
[00:18:34.020 --> 00:18:37.860]   here now so so but what i come back to you is you know you initially asked
[00:18:37.860 --> 00:18:42.340]   about the business model i think i think if facebook's gonna dig itself out of
[00:18:42.340 --> 00:18:46.820]   this if it's going to get to the point where tim burners lee wants them to get
[00:18:46.820 --> 00:18:51.540]   where they fix this uh they have to rethink that business model and it was
[00:18:51.540 --> 00:18:55.620]   somewhat disappointing to hear shell sandberg this week say oh no you know
[00:18:55.620 --> 00:19:01.060]   our business models just fine well maybe it is but i at minimum they have to
[00:19:01.060 --> 00:19:03.940]   shift the priorities around again so that
[00:19:03.940 --> 00:19:10.900]   user data is something that they respect and they understand
[00:19:10.900 --> 00:19:18.260]   that people aren't weighting weighing waiting into their privacy policies and
[00:19:18.260 --> 00:19:23.700]   data policies and figuring out oh gee i guess if i clicked that i did let
[00:19:23.700 --> 00:19:27.860]   kangbridge analytic adieu all this stuff that i wouldn't have wanted them to do
[00:19:27.860 --> 00:19:31.780]   i mean clearly the users who were affected by this
[00:19:31.780 --> 00:19:36.420]   uh would have liked some some actually comprehensible disclosure
[00:19:36.420 --> 00:19:40.740]   as to what was happening and many of them if not the majority of them probably
[00:19:40.740 --> 00:19:44.980]   would have said no so i think we have to get to the point where
[00:19:44.980 --> 00:19:49.860]   people understand what's going on here yeah the only reason i brought up all
[00:19:49.860 --> 00:19:52.820]   those you know hello kitty facebook life things
[00:19:52.820 --> 00:19:56.420]   is to point out that you may be leaking all sorts of information just by using
[00:19:56.420 --> 00:19:59.300]   facebook that you're not really aware of and facebook certainly it's not in
[00:19:59.300 --> 00:20:02.260]   their interest to disclose this no i always thought that if i liked
[00:20:02.260 --> 00:20:05.540]   hello kitty that was kind of meaningless not that i've liked hello kitty but if i
[00:20:05.540 --> 00:20:09.940]   if i liked whatever i thought it was meaningless and taking a quiz on
[00:20:09.940 --> 00:20:13.460]   facebook it's just fun the quiz thing really irritates the
[00:20:13.460 --> 00:20:16.900]   the bejesus out of me because yes i mean they they're built to you as like
[00:20:16.900 --> 00:20:20.260]   oh it's fun find out which star trek captain you would be or whatever
[00:20:20.260 --> 00:20:23.140]   and people didn't realize that in taking that quiz not only were they handing
[00:20:23.140 --> 00:20:26.340]   over their own personal information but up until 2014
[00:20:26.340 --> 00:20:29.620]   they were handling over handing over all their friends personal information as
[00:20:29.620 --> 00:20:32.740]   well and i've got relatives and friends on facebook who take these quizzes
[00:20:32.740 --> 00:20:36.260]   generally and you know invite you to kind of you have no control over that
[00:20:36.260 --> 00:20:39.700]   it's a larger problem though isn't it i mean the term that's
[00:20:39.700 --> 00:20:44.660]   widely used now is surveillance capitalism and it isn't just facebook this is
[00:20:44.660 --> 00:20:49.060]   google's business model as well right true uh amazon
[00:20:49.060 --> 00:20:53.460]   certainly spies on us in every way possible so they can offer us
[00:20:53.460 --> 00:20:56.340]   individual i mean you look at the amount of decisions made when you book a
[00:20:56.340 --> 00:20:59.380]   flight online and the amount of things that they can
[00:20:59.380 --> 00:21:02.980]   grab out from you and again as i said at the very beginning nothing new
[00:21:02.980 --> 00:21:06.420]   this has been going on since the 1950s
[00:21:06.420 --> 00:21:11.300]   but it's become to use tim bernizley's word weaponized because of big data and
[00:21:11.300 --> 00:21:15.540]   big computers yeah so yeah definitely and it's not
[00:21:15.540 --> 00:21:20.020]   just i mean it's it's down to the the way in which
[00:21:20.020 --> 00:21:24.020]   consent isn't extracted from us the graphical way
[00:21:24.020 --> 00:21:27.620]   uh consider whenever you're asked to
[00:21:27.620 --> 00:21:31.060]   release information how you get a big blue button
[00:21:31.060 --> 00:21:35.380]   that says yes i'd like to comply and then maybe there's some gray text down
[00:21:35.380 --> 00:21:38.740]   underneath that is opting you out you know i mean they're
[00:21:38.740 --> 00:21:42.740]   they're manipulating people at very fundamental levels yeah i really feel
[00:21:42.740 --> 00:21:45.060]   like i'm facebook when they give you our yes or no
[00:21:45.060 --> 00:21:48.900]   they should be in the same typeface same amount of emphasis they should not
[00:21:48.900 --> 00:21:51.460]   try to steer you in one direction or another
[00:21:51.460 --> 00:21:54.500]   there shouldn't be a little frowny face next to the i don't want to do that
[00:21:54.500 --> 00:21:56.900]   on facebook's done a lot worse though i mean they
[00:21:56.900 --> 00:22:01.380]   when do terte became uh the i don't know what the term is
[00:22:01.380 --> 00:22:04.740]   president a for life of the yeah dictator a strong man in the
[00:22:04.740 --> 00:22:07.300]   philippines he did it with the help of facebook
[00:22:07.300 --> 00:22:11.700]   and then when he won facebook came in and gave them so-called white glove
[00:22:11.700 --> 00:22:18.020]   service to help do terte stay in power do terte shut down the free press
[00:22:18.020 --> 00:22:22.580]   in the philippines and used facebook live to stream his
[00:22:22.580 --> 00:22:28.180]   speeches uh facebook would say well we don't want to pick sides
[00:22:28.180 --> 00:22:32.900]   in a political battle what is fit what and and i don't even just want to blame
[00:22:32.900 --> 00:22:36.100]   facebook because i think facebook although
[00:22:36.100 --> 00:22:39.460]   well as long as we're piling on let let's just let's pile on a little bit more
[00:22:39.460 --> 00:22:43.860]   sandy paracolas who was for a couple of years
[00:22:43.860 --> 00:22:47.540]   platform operations manager at facebook has stepped forward
[00:22:47.540 --> 00:22:51.460]   he's he was responsible for policing data breaches by 30 third party
[00:22:51.460 --> 00:22:56.100]   developers between 2011 and 2012 he said he he's to this is a guardian story
[00:22:56.100 --> 00:22:59.700]   warned senior executives of the company its lax approach to data protection
[00:22:59.700 --> 00:23:03.620]   risk to major breach he said he believes hundreds of millions
[00:23:03.620 --> 00:23:07.620]   of americans have been affected by this came for janolitica
[00:23:07.620 --> 00:23:11.860]   is just the tip of the iceberg i would just say i'm not at all surprised
[00:23:11.860 --> 00:23:16.340]   this is what facebook does uh what do you expect facebook to do this is
[00:23:16.340 --> 00:23:20.260]   what this is the business of facebook how could facebook
[00:23:20.260 --> 00:23:23.140]   create a business model that doesn't involve
[00:23:23.140 --> 00:23:26.900]   selling our information to the highest bidder what which
[00:23:26.900 --> 00:23:29.460]   facebook says we're going to a forensic analysis of
[00:23:29.460 --> 00:23:33.700]   every app ever written yeah let me guess it'll come back saying
[00:23:33.700 --> 00:23:37.380]   how are you gonna do that i mean it could be far more anonymized than it is
[00:23:37.380 --> 00:23:41.380]   that they a lot of the seckerberg explained which is true that a lot of
[00:23:41.380 --> 00:23:44.740]   this goes back to when facebook decided to be a platform
[00:23:44.740 --> 00:23:47.540]   and opened up the ability for third parties
[00:23:47.540 --> 00:23:50.900]   to integrate themselves with the facebook platform
[00:23:50.900 --> 00:23:53.380]   if that aspect of facebook didn't exist
[00:23:53.380 --> 00:23:56.420]   does it last for this matter there's a delete facebook movement you go to
[00:23:56.420 --> 00:23:59.700]   delete facebook dot com to learn how to do is it even matter though if people do
[00:23:59.700 --> 00:24:00.580]   that
[00:24:00.580 --> 00:24:05.300]   when everybody i mean somebody said even if you know
[00:24:05.300 --> 00:24:08.260]   10 percent of the united states delete its facebook pages more than made up
[00:24:08.260 --> 00:24:11.380]   for in one day by the rest of the world joining facebook and there's no
[00:24:11.380 --> 00:24:14.660]   particular evidence that there is a mass migration out of facebook yet
[00:24:14.660 --> 00:24:18.740]   i i actually delete my account and last night my wife said
[00:24:18.740 --> 00:24:21.380]   you know there's a side effect of this you may not realize
[00:24:21.380 --> 00:24:25.540]   i am now married to nobody on facebook it says
[00:24:25.540 --> 00:24:30.420]   lisa loport is married but it doesn't say to whom because i don't exist on facebook
[00:24:30.420 --> 00:24:35.060]   and that made me feel so bad sweetie i logged back in and reactivated my account
[00:24:35.060 --> 00:24:38.580]   and i kind of feel like it's it's counterproductive if what we want
[00:24:38.580 --> 00:24:42.340]   them to do is to fix this and and to
[00:24:42.340 --> 00:24:48.260]   realize the potential of what zuckerberg talks about connecting everyone and
[00:24:48.260 --> 00:24:53.540]   having this amazing experience then maybe quitting isn't the right
[00:24:53.540 --> 00:24:59.940]   protest step maybe we should take a page from these youngsters that we've seen
[00:24:59.940 --> 00:25:05.380]   this weekend making their voices heard and and really have people make their
[00:25:05.380 --> 00:25:09.220]   voices heard uh what would happen to facebook if
[00:25:09.220 --> 00:25:12.500]   the web rallied around this the way they did
[00:25:12.500 --> 00:25:16.660]   about opposing sopa and pippa a few years back
[00:25:16.660 --> 00:25:22.900]   and had a day where people didn't use facebook or even you know they didn't
[00:25:22.900 --> 00:25:28.660]   interact they didn't like or love or laugh or on any of the posts
[00:25:28.660 --> 00:25:32.420]   they checked in they got their news but they didn't react
[00:25:32.420 --> 00:25:36.580]   that would have a huge impact i would think it would send a message to facebook
[00:25:36.580 --> 00:25:40.900]   yeah invite and i mean despite everything i i don't agree with the
[00:25:40.900 --> 00:25:43.620]   folks who say that facebook inherently makes you miserable
[00:25:43.620 --> 00:25:47.780]   and is inherently pernicious and should go away i think facebook along with
[00:25:47.780 --> 00:25:51.140]   this infinite number of problems also has an infinite number of ways
[00:25:51.140 --> 00:25:54.340]   in which it has potential to make the world a better place
[00:25:54.340 --> 00:25:57.620]   um it seems some amazing things i don't i don't think zuckerberg is insincere
[00:25:57.620 --> 00:26:01.860]   when he talks about that that is also true yeah and leo you asked about the
[00:26:01.860 --> 00:26:06.660]   ad model and and i think sort of cast it in a way that it's
[00:26:06.660 --> 00:26:10.340]   it's a foregone conclusion that it's a negative
[00:26:10.340 --> 00:26:14.180]   but i think when facebook began tinkering around with all this we all thought
[00:26:14.180 --> 00:26:17.140]   maybe they're really going to figure this out maybe they're going to give me
[00:26:17.140 --> 00:26:21.540]   ads i want to see and that are useful and that are not trying to manipulate my
[00:26:21.540 --> 00:26:26.500]   political opinions and in ways that that you know
[00:26:26.500 --> 00:26:30.820]   are are underhanded i mean when we see political ads on tv
[00:26:30.820 --> 00:26:34.980]   which we do all the time uh we know what we're getting into there
[00:26:34.980 --> 00:26:38.180]   well partly because the law requires they be identified
[00:26:38.180 --> 00:26:42.900]   by the purchaser of the ad time which the law does not require of digital
[00:26:42.900 --> 00:26:46.100]   media no i think that's one thing we can change right now
[00:26:46.100 --> 00:26:49.300]   yeah and if you saw zuckerberg's interview on
[00:26:49.300 --> 00:26:53.540]   cnn and i assume he said this elsewhere uh when he was
[00:26:53.540 --> 00:26:57.860]   uh sort of referencing maybe we should be regulated more it seemed like that
[00:26:57.860 --> 00:27:01.620]   was the direction he was going in that there is an ad transparency build
[00:27:01.620 --> 00:27:04.820]   it's been sort of sitting around congress for a while it hasn't been
[00:27:04.820 --> 00:27:08.660]   enacted um i think it's more like warners bill right
[00:27:08.660 --> 00:27:12.740]   senator warner from uh virginia yes and john mccain i believe is the only
[00:27:12.740 --> 00:27:16.820]   republican who's who's bought into it but um
[00:27:16.820 --> 00:27:21.940]   it seems to me when i hear that and i hear him you know inviting regulation of
[00:27:21.940 --> 00:27:27.460]   that kind but but then putting money into opposing for example
[00:27:27.460 --> 00:27:33.060]   the california uh proposition that we may see on the
[00:27:33.060 --> 00:27:36.100]   ballot the california consumer privacy act
[00:27:36.100 --> 00:27:39.300]   um it seems like that could be a really uh nice
[00:27:39.300 --> 00:27:42.980]   opportunity for california to once again lead the way
[00:27:42.980 --> 00:27:47.780]   in privacy law be the tale that wags the dog and and uh
[00:27:47.780 --> 00:27:52.100]   get a lot of other uh get compliance that affects a lot of people that don't
[00:27:52.100 --> 00:27:55.540]   live in california there you see the response from facebook and google
[00:27:55.540 --> 00:27:59.060]   they're spending big bucks according to the sacramento v to fight
[00:27:59.060 --> 00:28:03.220]   the california data privacy measure right they understand that their business
[00:28:03.220 --> 00:28:06.980]   model is surveillance capitalism they don't want any limitation on that
[00:28:06.980 --> 00:28:10.580]   yeah i think they're you know if they don't want to
[00:28:10.580 --> 00:28:15.460]   to just punt and lose their business model altogether i think they're going to
[00:28:15.460 --> 00:28:18.820]   have to pay attention to this because they're either going to be regulated
[00:28:18.820 --> 00:28:23.540]   or i do think that the users have sort of said times up on this
[00:28:23.540 --> 00:28:28.180]   but yeah that there's a lot of concern especially i would think among young
[00:28:28.180 --> 00:28:34.260]   people who are not uh happy about where uh net neutrality is gone in the last
[00:28:34.260 --> 00:28:39.220]   year or so and if they become educated and informed enough to know that they
[00:28:39.220 --> 00:28:43.700]   are being manipulated by these companies when they don't have to when there are
[00:28:43.700 --> 00:28:49.460]   you know ways in which uh you can do an ad system that is very lucrative that's
[00:28:49.460 --> 00:28:53.300]   not violating people's expectations and consent
[00:28:53.300 --> 00:28:57.460]   um that that they're going to take action and maybe this bill in california is
[00:28:57.460 --> 00:29:02.020]   the first uh move toward that kind of step i almost feel like zebra
[00:29:02.020 --> 00:29:08.180]   zebra birds embracing of the um ad transparency bill in congress
[00:29:08.180 --> 00:29:13.140]   is sort of an entree to be able to go to advertisers and say
[00:29:13.140 --> 00:29:17.300]   gee you know we've been accommodating you guys for so long but
[00:29:17.300 --> 00:29:20.340]   now we're getting regulated and i'm sorry we're going to have to scale back
[00:29:20.340 --> 00:29:23.860]   and it's really not our fault congress is making us do it
[00:29:23.860 --> 00:29:27.540]   so maybe that's a step in the right direction too
[00:29:27.540 --> 00:29:32.740]   what should uh what should we do as users should we stay on facebook and try to
[00:29:32.740 --> 00:29:36.580]   change things from within one of the most one of the depressing tweets i saw
[00:29:36.580 --> 00:29:40.500]   this week was that's it i'm deleting facebook shifting to instagram and
[00:29:40.500 --> 00:29:45.140]   you're like uh what's that yeah you know yeah
[00:29:45.140 --> 00:29:49.540]   i know i mean uh i don't think it makes any difference to facebook or to
[00:29:49.540 --> 00:29:52.820]   my personal privacy whether i delete facebook or not
[00:29:52.820 --> 00:29:57.860]   it's a gesture it's not effective i'm not so sure i'm starting to think
[00:29:57.860 --> 00:30:01.060]   you know traditionally social networks have done that thing where they grow
[00:30:01.060 --> 00:30:03.860]   grow grow and that something better comes along and they die on the vine
[00:30:03.860 --> 00:30:07.540]   after friends to happen to my space and we always thought it wouldn't
[00:30:07.540 --> 00:30:10.660]   may probably wouldn't happen to facebook because they got scale
[00:30:10.660 --> 00:30:14.020]   you know they've got over a billion users it's going to be very hard to dislodge
[00:30:14.020 --> 00:30:18.260]   that but something like this and you know they were very keen throughout the
[00:30:18.260 --> 00:30:22.340]   entire week to make it about this is not a data breach it's not a data breach
[00:30:22.340 --> 00:30:25.780]   and not they don't like the word breach yeah but really
[00:30:25.780 --> 00:30:28.500]   they should embrace it because breach implies that they didn't want it to
[00:30:28.500 --> 00:30:31.860]   happen but then they did they didn't eventually say it was a breach of trust
[00:30:31.860 --> 00:30:35.780]   yes it was very carefully put which was sort of a great
[00:30:35.780 --> 00:30:38.900]   breach in the sense that somebody hacked facebook and stole the data
[00:30:38.900 --> 00:30:41.940]   they hacked the social engineering act you it's such a
[00:30:41.940 --> 00:30:45.700]   there's a legal distinction well if it's a data breach they're responsible you
[00:30:45.700 --> 00:30:51.540]   know california among other states uh require you to advise users
[00:30:51.540 --> 00:30:55.540]   send out letters and say oh gee sorry we've got to that your data has been
[00:30:55.540 --> 00:30:58.420]   subject to a breach and here are the steps you can take and
[00:30:58.420 --> 00:31:01.380]   uh there's a whole lot of transparency that's required
[00:31:01.380 --> 00:31:05.140]   around a breach so if we're not going to call it a breach that
[00:31:05.140 --> 00:31:10.260]   has legal significance and uh there's at least one
[00:31:10.260 --> 00:31:16.260]   professor out there idol killivati who published at tech crunch on this
[00:31:16.260 --> 00:31:19.380]   uh that thinks we should amend those data breach laws to
[00:31:19.380 --> 00:31:23.620]   encompass something like this sometimes i feel like
[00:31:23.620 --> 00:31:26.660]   maybe it's just me it's so overwhelming and it's
[00:31:26.660 --> 00:31:30.820]   it's just i give up it's like i'm just go home and watch killin's island i don't
[00:31:30.820 --> 00:31:35.060]   there's it's like what can we had kori doctor rohan then a
[00:31:35.060 --> 00:31:37.780]   screensaver yesterday and kori always cheers me up a little bit
[00:31:37.780 --> 00:31:40.420]   yes there's a number of things we can do one
[00:31:40.420 --> 00:31:45.860]   there are little small leveraged things you can do in congress that would
[00:31:45.860 --> 00:31:50.260]   help in a lot of this for instance uh congress has
[00:31:50.260 --> 00:31:54.580]   made it so that it's difficult or impossible correct me on this
[00:31:54.580 --> 00:32:01.220]   uh Denise uh to uh sue uh over these kinds of things
[00:32:01.220 --> 00:32:03.700]   they they were quite it's possible for a company like
[00:32:03.700 --> 00:32:07.860]   it affects to require binding arbitration
[00:32:07.860 --> 00:32:11.220]   instead of a lawsuit over a data breach and they always do pretty much
[00:32:11.220 --> 00:32:16.260]   yeah and he said if we could change that law just to allow us to sue these
[00:32:16.260 --> 00:32:20.980]   companies that would go a long way you know hit him in the pocketbook that
[00:32:20.980 --> 00:32:24.100]   would go a long way to to making a difference you
[00:32:24.100 --> 00:32:27.540]   is that the case Denise completely agree yeah that
[00:32:27.540 --> 00:32:32.500]   kori's right on about that and and the reason that uh binding arbitration is
[00:32:32.500 --> 00:32:35.540]   in so many of these terms of service that we have with
[00:32:35.540 --> 00:32:40.180]   various uh companies that we do business with is that litigation is so much more
[00:32:40.180 --> 00:32:44.020]   expensive so if you're if you're taking that
[00:32:44.020 --> 00:32:48.340]   cost savings off the table for them i think it definitely makes a difference
[00:32:48.340 --> 00:32:51.540]   it up well but then also and i'm sure they would argue this has all sorts of
[00:32:51.540 --> 00:32:54.500]   unintended consequences you get lots of frivolous lawsuits
[00:32:54.500 --> 00:32:59.140]   you tie up the courts um if you could if you could say only good lawsuits that
[00:32:59.140 --> 00:33:03.780]   would be good right only lawsuits with merit that would be good
[00:33:03.780 --> 00:33:08.580]   right but you can't this this proposed california privacy law
[00:33:08.580 --> 00:33:12.900]   would allow consumers to sue businesses for security breaches of consumer
[00:33:12.900 --> 00:33:16.900]   data as even if the consumers cannot prove injury
[00:33:16.900 --> 00:33:20.580]   oh that's another one yeah that's right you have to prove that it hurts that was
[00:33:20.580 --> 00:33:23.060]   a big problem with the nsa spying case because
[00:33:23.060 --> 00:33:26.820]   initially threw out cases well well you can't prove
[00:33:26.820 --> 00:33:30.900]   that the nsa was spying on you therefore you can't bring a lawsuit against them
[00:33:30.900 --> 00:33:36.340]   standing is it happened to you uh damages or harm
[00:33:36.340 --> 00:33:40.020]   mean that you were actually hurt by it and you have to be able to palpably
[00:33:40.020 --> 00:33:42.100]   show that and that is by the way that's a kind of
[00:33:42.100 --> 00:33:46.420]   a standings law in or a point of point of view in the in the
[00:33:46.420 --> 00:33:50.180]   united states right that there's no if there's not actual damages you have
[00:33:50.180 --> 00:33:56.660]   you have no cause right well this law would it's there's always
[00:33:56.660 --> 00:34:01.220]   some form of damage if you've been injured it's just a quite summer easier to
[00:34:01.220 --> 00:34:05.140]   hurt my feelings right hurt my feelings facebook
[00:34:05.140 --> 00:34:07.940]   although there is a layer of this we haven't discussed yet which is whether
[00:34:07.940 --> 00:34:11.140]   came what kamara janolica does is actually
[00:34:11.140 --> 00:34:15.940]   all that uh valuable to their customers well there's there's always been that
[00:34:15.940 --> 00:34:19.540]   and uh that the kamara janolica maybe overstating the value of what they're
[00:34:19.540 --> 00:34:22.740]   doing and they took credit for trump winning and in fact maybe they didn't
[00:34:22.740 --> 00:34:25.300]   have anything to do with it non and on and on
[00:34:25.300 --> 00:34:28.260]   there's a mother jones article that applied it was basically a ponzi
[00:34:28.260 --> 00:34:34.180]   yes kind of the Mercer family who um funded kamara janolica and also gives
[00:34:34.180 --> 00:34:37.860]   money to a lot of republican candidates the money kind of
[00:34:37.860 --> 00:34:42.660]   cycles from the mercers to the campaign who really has to give money to kamara
[00:34:42.660 --> 00:34:45.780]   janolica and alitica because the mercers tell them to
[00:34:45.780 --> 00:34:50.020]   which is good for the mercers and it's it's just not entirely clear whether
[00:34:50.020 --> 00:34:55.140]   this is quite as powerful in its form as used by companies like kamara janolica
[00:34:55.140 --> 00:34:58.740]   as kamara janolica which seems to like to make up claims about what they're doing
[00:34:58.740 --> 00:35:02.980]   says it is would you agree though that if this information got to the troll
[00:35:02.980 --> 00:35:05.700]   farm at the internet research agency it could
[00:35:05.700 --> 00:35:09.620]   their use uh and manipulation of facebook not merely with ads although ads for
[00:35:09.620 --> 00:35:12.740]   sure but uh creating phony groups creating phony
[00:35:12.740 --> 00:35:16.820]   youtube videos that maybe this could be much more damaging
[00:35:16.820 --> 00:35:20.900]   when it's used for something that that dirty whether or not it's
[00:35:20.900 --> 00:35:26.500]   effective as well less on my mind and now we know kevin pulsons article uh in
[00:35:26.500 --> 00:35:30.580]   the uh daily beast the daily beast figured out the kuchafur 2.0 was that
[00:35:30.580 --> 00:35:33.460]   hacker that was really good who leaked a lot of this information to
[00:35:33.460 --> 00:35:38.420]   wiki leaks alone hacker not a lone hacker right in fact
[00:35:38.420 --> 00:35:43.300]   he is uh an officer of the russian military intelligence director jid ji
[00:35:43.300 --> 00:35:46.340]   r u he forgot to turn on his vpn one time just
[00:35:46.340 --> 00:35:50.340]   like they came from within he came from inside the house
[00:35:50.340 --> 00:35:53.060]   yeah well i spoke to somebody at a i was at a security conference a couple of
[00:35:53.060 --> 00:35:56.420]   weeks ago down and they'd spoken to gukova
[00:35:56.420 --> 00:35:59.300]   and they were like i'm pretty sure it's two or three people
[00:35:59.300 --> 00:36:02.660]   and there's no way they're remaining so i threw some ruey n slang at them
[00:36:02.660 --> 00:36:05.700]   they weren't going for it they didn't understand what was talking about
[00:36:05.700 --> 00:36:09.220]   so it doesn't surprise me that it was coming from the g r u it also doesn't
[00:36:09.220 --> 00:36:12.260]   surprise me they didn't use the vr vpn because
[00:36:12.260 --> 00:36:15.860]   everybody slips up sooner or later we saw that we saw a true bar at robert's we
[00:36:15.860 --> 00:36:19.220]   saw it with everyone else everyone mucks up but
[00:36:19.220 --> 00:36:22.820]   all the same oh we're talking to gukova we've now discovered their russian
[00:36:22.820 --> 00:36:26.740]   military intelligence but we didn't work with the russians i'm having problems
[00:36:26.740 --> 00:36:32.820]   reconciling those those fights it's um it's it's clear now that the russians
[00:36:32.820 --> 00:36:36.660]   were playing a part how influential art was and
[00:36:36.660 --> 00:36:39.700]   who knew about it at the time i think that's going to be the big question to
[00:36:39.700 --> 00:36:42.100]   answer
[00:36:42.100 --> 00:36:46.900]   that was a very eloquent drug lio uh yeah we don't know we're never going to know
[00:36:46.900 --> 00:36:50.260]   are we and and yeah i mean clearly that's a not a
[00:36:50.260 --> 00:36:56.420]   good thing um and the russians are not our friends
[00:36:56.420 --> 00:37:04.020]   um and they've been able to use these uh tools against us
[00:37:04.020 --> 00:37:09.140]   i just don't know what we should do about this i mean and kori also said and i
[00:37:09.140 --> 00:37:13.220]   think this is good message as well that as geeks
[00:37:13.220 --> 00:37:17.780]   we should promote and maybe even create ourselves
[00:37:17.780 --> 00:37:22.740]   uh social networks that don't rely on uh surveillance what you and
[00:37:22.740 --> 00:37:26.260]   about from about eighteen eighteen months ago that was going to be the next big
[00:37:26.260 --> 00:37:29.780]   thing and it just kind of with it what happened to mastodon mastodon
[00:37:29.780 --> 00:37:31.460]   mastodon mastodon
[00:37:31.460 --> 00:37:35.140]   i asked bro yeah okay so question for you all do you know
[00:37:35.140 --> 00:37:39.460]   anyone under 30 who uses facebook no they all use instagram
[00:37:39.460 --> 00:37:42.900]   well that's a good enough although you're not giving them the same information
[00:37:42.900 --> 00:37:46.260]   by posting a picture that you would be with a mic right i don't know my nieces
[00:37:46.260 --> 00:37:50.100]   use it but then when we were down the pub they explained that
[00:37:50.100 --> 00:37:53.700]   they have a facebook account which is linked to their parents facebook
[00:37:53.700 --> 00:37:57.860]   account but they very seldom use it it's kind of like the camouflage account
[00:37:57.860 --> 00:38:01.060]   if you like that's what they that's what they want their parents to know and
[00:38:01.060 --> 00:38:03.620]   then they go to snapchat or instagram or
[00:38:03.620 --> 00:38:06.740]   cake or a bunch of other services to actually converse that way
[00:38:06.740 --> 00:38:10.340]   well i think we turns out kids were smarter than we realized they snapchat
[00:38:10.340 --> 00:38:13.460]   too right or where they feel like they're not giving away
[00:38:13.460 --> 00:38:18.580]   this stuff they sensed somehow that this wasn't a good idea
[00:38:18.580 --> 00:38:22.740]   and meanwhile us older farts kind of oh it's good i gotta meet my high school
[00:38:22.740 --> 00:38:28.020]   girlfriend yeah she's still hot right that's why i feel like
[00:38:28.020 --> 00:38:32.500]   facebook and google and and everyone else who's managing our data
[00:38:32.500 --> 00:38:35.940]   and doing what did you call it leo surveillance capitalism
[00:38:35.940 --> 00:38:39.540]   surveillance capitalism that that if they're not getting
[00:38:39.540 --> 00:38:43.860]   the message that you know it's not just that
[00:38:43.860 --> 00:38:47.780]   um they're current base of users is upset about it
[00:38:47.780 --> 00:38:51.140]   their future base of users is just steering clear
[00:38:51.140 --> 00:38:55.140]   yeah and lawmakers are bearing down on them from
[00:38:55.140 --> 00:39:00.260]   state federal and international fronts did you all read the guardian story
[00:39:00.260 --> 00:39:04.500]   where the information commissioner's office in the u_k_
[00:39:04.500 --> 00:39:09.700]   was storming came bridge analytic at in their jackets that look like d_e_a_
[00:39:09.700 --> 00:39:14.260]   jackets here in the u_s_ it was the most slow motion storming you ever seen
[00:39:14.260 --> 00:39:18.340]   uh because this broke on the friday and then the the information commissioner
[00:39:18.340 --> 00:39:21.540]   said okay well we're going to go in we should have a search warrant
[00:39:21.540 --> 00:39:25.060]   organized by about tuesday and then it came out that facebook had sent their
[00:39:25.060 --> 00:39:27.220]   own forensic team in there
[00:39:27.220 --> 00:39:30.260]   uh and they're like okay well we'll we'll we'll get it the next day and they
[00:39:30.260 --> 00:39:33.780]   were in on friday at which point all they're going to find is a bunch of
[00:39:33.780 --> 00:39:36.500]   wiped servers and a slightly straight memo saying
[00:39:36.500 --> 00:39:40.980]   remember chaps everybody obey the law and you know they they missed their chance
[00:39:40.980 --> 00:39:46.580]   completely it was it was a shameful display by the icio i want to get it
[00:39:46.580 --> 00:39:50.900]   had nice jacket photo op though yeah they were like it that they have a
[00:39:50.900 --> 00:39:54.500]   period at the end of icio oh i don't want punctuation's important
[00:39:54.500 --> 00:40:01.700]   i_c_o_ period or full stop enforcement or full stop we are the idea of full stop
[00:40:01.700 --> 00:40:06.020]   it's a reminder that each state of the united states and the federal government
[00:40:06.020 --> 00:40:09.300]   could have their own equivalent of that before too long
[00:40:09.300 --> 00:40:15.060]   even if they're a credit to his to uh uh harvard uh academic shoshana zuboff
[00:40:15.060 --> 00:40:19.220]   for the term surveillance capitalism not the first use according to wikipedia
[00:40:19.220 --> 00:40:22.660]   john bellamy foster robert mcchesney wrote an article using that term in
[00:40:22.660 --> 00:40:26.740]   monthly review but zuboff is writing a book called surveillance capitalism
[00:40:26.740 --> 00:40:30.820]   here's how she defines it she says surveillance capitalism emerged
[00:40:30.820 --> 00:40:35.300]   due to the cup the coupling of the vast powers of the digital
[00:40:35.300 --> 00:40:40.580]   which we've all talked about with the i love this the radical indifference
[00:40:40.580 --> 00:40:44.420]   and intrinsic narcissism of the financial capitalism
[00:40:44.420 --> 00:40:48.660]   and its neoliberal vision that have dominated commerce for at least three
[00:40:48.660 --> 00:40:52.340]   decades especially in the anglo economies
[00:40:52.340 --> 00:40:55.380]   and i think the russians might have looked at us and said uh-huh we found your
[00:40:55.380 --> 00:40:56.820]   weak spot
[00:40:56.820 --> 00:41:02.260]   you all made fun of us for communism but capitalism has its own problems
[00:41:02.260 --> 00:41:06.100]   oh capitalism has plenty of problems but yes it's but i mean this is
[00:41:06.100 --> 00:41:11.220]   she says google is the is to surveillance capitalism what ford was to mass
[00:41:11.220 --> 00:41:16.500]   production that they have perfected it they perfected it later adopted by
[00:41:16.500 --> 00:41:20.580]   facebook and of others it uses illegible mechanism i like that word
[00:41:20.580 --> 00:41:25.700]   illegible mechanisms in other words invisible mechanisms of extraction
[00:41:25.700 --> 00:41:28.420]   commodification control of behavior to produce
[00:41:28.420 --> 00:41:34.420]   new markets of behavioral prediction and modification
[00:41:34.420 --> 00:41:37.940]   she's brilliant she's shana but zibai the way i can't wait to read this book when
[00:41:37.940 --> 00:41:41.620]   it comes out we'll get her on the twit a triangulation of course immediately
[00:41:41.620 --> 00:41:45.300]   and she wrote a book probably more than a decade ago now called the support
[00:41:45.300 --> 00:41:49.780]   economy that basically forecasted
[00:41:49.780 --> 00:41:52.820]   everything that amazon has become first of all
[00:41:52.820 --> 00:41:56.740]   and all our personal assistance and everything else she's really smart
[00:41:56.740 --> 00:42:02.180]   google's chief economist how very unidentified the four key features
[00:42:02.180 --> 00:42:07.620]   in the logic of surveillance capitalism one the drive toward more and more data
[00:42:07.620 --> 00:42:12.340]   extraction and analysis to the development of new contractual forms
[00:42:12.340 --> 00:42:15.780]   using computer monitoring and automation
[00:42:15.780 --> 00:42:19.860]   three the desire to personalizing customize the services offered to users of
[00:42:19.860 --> 00:42:24.420]   digital platforms and finally the use of technological infrastructure to carry
[00:42:24.420 --> 00:42:28.980]   out continual experiments on its users and consumers
[00:42:28.980 --> 00:42:33.140]   if i would if i could pick the one thing that most bothers me about this is
[00:42:33.140 --> 00:42:37.300]   i feel like a guinea pig i feel like a lab rat and all you already are though
[00:42:37.300 --> 00:42:40.180]   because when we face book you remember facebook got caught out doing this
[00:42:40.180 --> 00:42:42.820]   thing where they had had an academic study where they would
[00:42:42.820 --> 00:42:46.740]   alter people's news feeds and see if they get them to get depressed or
[00:42:46.740 --> 00:42:50.740]   we know that facebook even published a study that said too much facebook
[00:42:50.740 --> 00:42:54.420]   gets you depressed unless but this is a little self-serving of facebook
[00:42:54.420 --> 00:42:57.940]   you put more content on facebook yeah then you won't be as depressed
[00:42:57.940 --> 00:43:00.580]   how how fortunate that was for them but i mean
[00:43:00.580 --> 00:43:03.780]   we know this stuff works we know that you can alter people's
[00:43:03.780 --> 00:43:06.900]   perceptions were going through by altering the newsfeed
[00:43:06.900 --> 00:43:10.260]   what i do find a somewhat of a stretch is
[00:43:10.260 --> 00:43:13.860]   whether or not you could actually change someone's political opinion using these
[00:43:13.860 --> 00:43:16.260]   kind of techniques because that seems to be something
[00:43:16.260 --> 00:43:20.020]   fatty group that's a thing that's a thing that's a priority i don't even
[00:43:20.020 --> 00:43:22.980]   think that's as much of a problem yeah because i think that really we
[00:43:22.980 --> 00:43:26.340]   we you know we talk a lot about fake news and how it but i think it was
[00:43:26.340 --> 00:43:28.980]   embraced by people who already believed it it was just a
[00:43:28.980 --> 00:43:31.860]   self-reinforcing mechanism that's not what bothers me so much
[00:43:31.860 --> 00:43:35.460]   as the way it can be used and it has apparently been used by Russia
[00:43:35.460 --> 00:43:39.620]   to see discord yes and and dissent and polarization
[00:43:39.620 --> 00:43:42.100]   and if there's anything that really has kind of
[00:43:42.100 --> 00:43:46.420]   frustrated the republic ex the republican experiment lowercase
[00:43:46.420 --> 00:43:49.300]   our experiment that the united states is it's this
[00:43:49.300 --> 00:43:51.940]   polarization that we've all observed over the last ten years
[00:43:51.940 --> 00:43:54.580]   were the two sides don't even talk to one another
[00:43:54.580 --> 00:43:59.860]   and that seems particularly pernicious if a foreign entity
[00:43:59.860 --> 00:44:04.260]   which doesn't like the liberal west decides hey we can really screw with
[00:44:04.260 --> 00:44:06.820]   them that's the ultimate i mean literally the word
[00:44:06.820 --> 00:44:10.900]   trolling that's the ultimate trolling yeah we don't care what the result is we
[00:44:10.900 --> 00:44:15.140]   just want to throw chaos into the mix well it was the russians who first
[00:44:15.140 --> 00:44:18.740]   invented the word disinformation if you look back in the 1920s
[00:44:18.740 --> 00:44:22.340]   um but yeah i'm seeing the same thing happening in the uk at the moment
[00:44:22.340 --> 00:44:26.500]   last time i was over there everyone's tremendously polarized around are you
[00:44:26.500 --> 00:44:31.220]   a brexitir or are you a remainer and over here the the level of tribalism in
[00:44:31.220 --> 00:44:34.180]   politics is it's just damning you know i mean you know
[00:44:34.180 --> 00:44:37.540]   people who won't even have friends who are of a different school
[00:44:37.540 --> 00:44:41.140]   persuasion and that's how we need to get all rounded yeah we need to get
[00:44:41.140 --> 00:44:43.940]   over that absolutely and it as far as changing people's
[00:44:43.940 --> 00:44:47.380]   minds go i agree with you that i don't think that it's going to necessarily
[00:44:47.380 --> 00:44:51.380]   alter your political opinion but what it might do is
[00:44:51.380 --> 00:44:55.620]   get you from a point of apathy and wanting to just stay home and watch
[00:44:55.620 --> 00:44:59.140]   Gilligan's island right to to going out and voting and
[00:44:59.140 --> 00:45:02.340]   that's a good point that makes it and voter and we do know that there were
[00:45:02.340 --> 00:45:06.660]   voter suppression ads as well that were very effective apparently in suppressing
[00:45:06.660 --> 00:45:10.980]   the vote so but that but again long tradition of voter suppression and a
[00:45:10.980 --> 00:45:14.260]   variety of different ways in the u.s. political
[00:45:14.260 --> 00:45:16.340]   i think it was held by the fact that you know for
[00:45:16.340 --> 00:45:19.780]   you know the democratic side the candidate wasn't really very
[00:45:19.780 --> 00:45:22.820]   you know a lot of people like well i'll hold my nose and vote for Hillary but i
[00:45:22.820 --> 00:45:25.860]   don't really feel and if you've got that kind of level amongst
[00:45:25.860 --> 00:45:27.860]   everyone's sees your push it and that direction
[00:45:27.860 --> 00:45:30.820]   well you know maybe you should just say that's really what it is it doesn't it
[00:45:30.820 --> 00:45:32.980]   can't change your mind but it can it can
[00:45:32.980 --> 00:45:37.140]   tilt you it could push you over if you're tilting it'll push you over the top
[00:45:37.140 --> 00:45:41.060]   maybe anyway i just i to me again i feel like a
[00:45:41.060 --> 00:45:44.820]   elaborate i feel like uh uh and i think this is the really the
[00:45:44.820 --> 00:45:48.260]   potential negative of this look we love technology westway i
[00:45:48.260 --> 00:45:52.180]   this this network exists is why i do what i do i love
[00:45:52.180 --> 00:45:55.060]   the potential for technology i love playing with it i think it's it's great
[00:45:55.060 --> 00:45:58.420]   in so many ways uh and so i don't want it to
[00:45:58.420 --> 00:46:02.900]   become this tool uh to abuse us i don't want it to become
[00:46:02.900 --> 00:46:06.260]   used against us and so we need to find ways to make it so that
[00:46:06.260 --> 00:46:09.540]   it isn't used against us and can be used for good
[00:46:09.540 --> 00:46:13.220]   and frankly i think you made the point facebook can be used for good it's not
[00:46:13.220 --> 00:46:18.260]   you know you're at lee evil it's just that uh it's so sad when it's used in
[00:46:18.260 --> 00:46:22.180]   this terrible way i do think i mean a tiny bit on the bright side
[00:46:22.180 --> 00:46:25.860]   marc zuckerberg has always been terrified of it all going away
[00:46:25.860 --> 00:46:29.780]   and something else taking over from p no because he did it to i space right
[00:46:29.780 --> 00:46:31.780]   which is why he bought instagram and and what's
[00:46:31.780 --> 00:46:33.780]   app yeah and i think that might be a little bit of
[00:46:33.780 --> 00:46:38.500]   mediating factor in in terms of him he's a sparkle yeah yes maybe he can
[00:46:38.500 --> 00:46:41.060]   fight a solution because there is a scenario where the
[00:46:41.060 --> 00:46:45.140]   stuff that's happening does lead to people right pulling back on facebook
[00:46:45.140 --> 00:46:48.340]   use and not trusting that an advertisers no longer wanting to be
[00:46:48.340 --> 00:46:51.060]   associated with that and that might push them in a
[00:46:51.060 --> 00:46:54.740]   direction of of doing some smart things that would uh
[00:46:54.740 --> 00:46:58.420]   lead people to say facebook is taking this seriously and is doing the right
[00:46:58.420 --> 00:47:01.780]   things yeah i think it certainly it does kill
[00:47:01.780 --> 00:47:04.820]   his presidential ambitions for the for the show
[00:47:04.820 --> 00:47:08.180]   the very chance that we're gonna sort of yeah we'll let marc zuckerberg run for
[00:47:08.180 --> 00:47:10.340]   run for president no i don't know i don't know if he's got all
[00:47:10.340 --> 00:47:13.460]   replaced the day so never say never though but he is already a
[00:47:13.460 --> 00:47:17.060]   pretty darn powerful person yeah that's what everybody said why would he
[00:47:17.060 --> 00:47:20.260]   want to be president he's got much more power running facebook he's global
[00:47:20.260 --> 00:47:23.540]   and this is kind of yet more evidence that that facebook is more or less a
[00:47:23.540 --> 00:47:26.740]   country under itself and it has powers that in the past you would have
[00:47:26.740 --> 00:47:30.740]   associated with countries rather than technology companies
[00:47:30.740 --> 00:47:34.900]   right yeah leo you said a moment ago is there going to be some upstart social
[00:47:34.900 --> 00:47:37.460]   network that addresses all these problems and and
[00:47:37.460 --> 00:47:40.580]   comes to users and say we know you we respect you
[00:47:40.580 --> 00:47:45.220]   we can do both those things when you jump when you if there were no
[00:47:45.220 --> 00:47:49.620]   alternatives at facebook i would jump in a moment i do jump i jumped on
[00:47:49.620 --> 00:47:53.220]   mastodon but nobody i knew followed so i yeah i went on to allow
[00:47:53.220 --> 00:47:56.740]   to try and make it work and that didn't work either it's just so
[00:47:56.740 --> 00:48:00.180]   do you think that's possible to be s well one little data point i don't know
[00:48:00.180 --> 00:48:04.980]   i've been watching this show on uh the science channel called silicon valley
[00:48:04.980 --> 00:48:08.260]   the untold story it's just this three episode
[00:48:08.260 --> 00:48:14.660]   whirlwind tour through silicon valley from the fifties until today
[00:48:14.660 --> 00:48:17.780]   and the theme that they come back to over and over again
[00:48:17.780 --> 00:48:21.620]   is impermanence and how people leave and start
[00:48:21.620 --> 00:48:24.820]   something else that completely disrupts what came before
[00:48:24.820 --> 00:48:28.340]   disrupts the company they worked at before so one little data point that i
[00:48:28.340 --> 00:48:30.340]   thought was interesting in the middle of all this
[00:48:30.340 --> 00:48:34.020]   is that facebook's information security officer left
[00:48:34.020 --> 00:48:38.340]   twitter's information security officer left i don't know maybe they'll all get
[00:48:38.340 --> 00:48:42.500]   together and do this i saw a post on twitter uh
[00:48:42.500 --> 00:48:47.140]   dave moron the guy who created path said you know maybe we should get the old
[00:48:47.140 --> 00:48:51.220]   gang back together he sold it to uh is it uh chinese japanese korean kapan
[00:48:51.220 --> 00:48:52.820]   korean korean kam
[00:48:52.820 --> 00:48:55.780]   maybe we should get the old gang would there be an interest in up and by the
[00:48:55.780 --> 00:48:59.060]   way that's why i joined path it was a limited to 50 people it didn't seem to
[00:48:59.060 --> 00:49:02.420]   have the same kind of uh intense surveillance
[00:49:02.420 --> 00:49:06.180]   behind it he said maybe we should get the old gang back i hope you guys
[00:49:06.180 --> 00:49:08.900]   dave anything we can do to support and help that
[00:49:08.900 --> 00:49:12.020]   and mastodon gargron the guy who created mastodon
[00:49:12.020 --> 00:49:15.540]   uh wrote a medium post saying don't forget
[00:49:15.540 --> 00:49:18.100]   there are social networks out there that are trending
[00:49:18.100 --> 00:49:22.420]   yes now it's funny because twitter which i don't think really is very good at
[00:49:22.420 --> 00:49:26.980]   surveillance capitalism and certainly doesn't have as much information
[00:49:26.980 --> 00:49:31.380]   uh but it has other problems that make it less uh you know not the utopia we
[00:49:31.380 --> 00:49:34.260]   thought it would be it's it's painful to go there too
[00:49:34.260 --> 00:49:36.580]   it can be it can be ugly and at the same time
[00:49:36.580 --> 00:49:42.820]   huge value right yeah huge value uh google go ahead and try to live
[00:49:42.820 --> 00:49:46.580]   without google yeah you can't right what do you well i feel like this week has
[00:49:46.580 --> 00:49:49.220]   been a huge boon to both of them right mmm
[00:49:49.220 --> 00:49:53.140]   mike algin is talking about how it's the resurgence of google plus oh no
[00:49:53.140 --> 00:49:58.580]   really really really i love i love mike daily but he does have a bit of a
[00:49:58.580 --> 00:50:01.060]   blood spiel he's listening right now i'm sure
[00:50:01.060 --> 00:50:05.060]   my krilli google plus really but realistically i feel like a lot of
[00:50:05.060 --> 00:50:07.620]   people are looking at twitter in a new light
[00:50:07.620 --> 00:50:11.700]   yeah yeah i'm well twitter and for a long time twitter got beat up more than
[00:50:11.700 --> 00:50:15.140]   anybody else for not dealing with stuff very well
[00:50:15.140 --> 00:50:18.900]   now we know that facebook is not dealing with it well youtube
[00:50:18.900 --> 00:50:21.620]   which you haven't really mentioned has all kinds of issues all sorts of
[00:50:21.620 --> 00:50:26.580]   pro yeah huge um google i mean google um
[00:50:26.580 --> 00:50:30.500]   other than youtube google is not blown up quite as much but it probably well at
[00:50:30.500 --> 00:50:33.620]   some point right i think for a number of reasons both this
[00:50:33.620 --> 00:50:37.060]   facebook story and also the uber story there are a lot of people at google just
[00:50:37.060 --> 00:50:40.820]   going wow we dodged some bullets this week because this could have been really
[00:50:40.820 --> 00:50:43.380]   ugly for us but what i really love them to do
[00:50:43.380 --> 00:50:50.340]   is to say now let's figure out a way to make something of value
[00:50:50.340 --> 00:50:53.300]   that doesn't make people feel like lab rats yeah
[00:50:53.300 --> 00:50:56.900]   because i think the world is ready for that and i think that people would jump
[00:50:56.900 --> 00:50:59.940]   on that and mark succerberg that is the real
[00:50:59.940 --> 00:51:05.140]   existential threat to facebook and you could do it too mark you know you could
[00:51:05.140 --> 00:51:09.780]   say facebook there are ways to do this if anything good comes out of this it'll
[00:51:09.780 --> 00:51:13.860]   be that we don't have to burn the house down just you know do some improvements
[00:51:13.860 --> 00:51:19.460]   on it we recognize there's value to it let's see how we can make it work
[00:51:19.460 --> 00:51:21.860]   it would be nice if it works out i think what they're worried about is the
[00:51:21.860 --> 00:51:24.980]   share price because that's what really got facebook
[00:51:24.980 --> 00:51:27.940]   well that puts you in a death spiral right because if your share price
[00:51:27.940 --> 00:51:31.780]   comments which you did facebook is fifty billion dollars in market value
[00:51:31.780 --> 00:51:35.140]   then you can't attract the best talent because you don't have shares that are
[00:51:35.140 --> 00:51:38.980]   worth anything and then you don't there's a death spiral because then you
[00:51:38.980 --> 00:51:42.180]   can't get good people to and it gets worse and worse and worse i don't know if
[00:51:42.180 --> 00:51:45.300]   they're at that i doubt they're at that point i think i think the stock
[00:51:45.300 --> 00:51:48.500]   president has recovered somewhat and i imagine it will continue to do so
[00:51:48.500 --> 00:51:56.020]   it's you know i i don't feel equipped to cover these stories to be honest with
[00:51:56.020 --> 00:52:02.820]   you i just if you're not leo who is yeah i got in the tech because i thought i
[00:52:02.820 --> 00:52:06.020]   could you know write reviews of software and get free computers i didn't know
[00:52:06.020 --> 00:52:11.780]   i thought this is fun this is the toy store right well do you
[00:52:11.780 --> 00:52:15.540]   remember the hack and manifesto back in the mid-90s and the internet was
[00:52:15.540 --> 00:52:18.580]   good exactly but the internet was going to bring all these diverse groups
[00:52:18.580 --> 00:52:21.540]   together we'd all talk we'd understand each other it would
[00:52:21.540 --> 00:52:25.300]   be it was i believe that i was rereading it uh
[00:52:25.300 --> 00:52:28.740]   last week when when all this broke and it was just like
[00:52:28.740 --> 00:52:32.500]   i wish it worked out that way but instead we've got polarized we've got
[00:52:32.500 --> 00:52:37.220]   crammed into narrow narrows silos well one of the one of the
[00:52:37.220 --> 00:52:41.860]   tenets of the hacker manifesto was information wants to be free
[00:52:41.860 --> 00:52:45.140]   and in fact that's to me the most important thing and that means not
[00:52:45.140 --> 00:52:50.020]   siloed not owned by any company not gathered to be
[00:52:50.020 --> 00:52:53.700]   used against you it wants to be free and that's the real promise of the
[00:52:53.700 --> 00:52:57.860]   internet and you know it's still hugely valuable i think now
[00:52:57.860 --> 00:53:02.420]   every day five or six times of of premises of things i could
[00:53:02.420 --> 00:53:05.380]   that i would have in the past had to go to a library and research which meant
[00:53:05.380 --> 00:53:09.540]   meaning i could be maybe one every six months now i can in in several times
[00:53:09.540 --> 00:53:13.540]   a day go out find out something do some research on something
[00:53:13.540 --> 00:53:17.380]   um and and that's amazing oh it's an enormously valuable tool
[00:53:17.380 --> 00:53:21.220]   choose i remember my father-in-law who was a science professor we gave him for
[00:53:21.220 --> 00:53:24.500]   the first time his he's passed away since but an i-pad
[00:53:24.500 --> 00:53:28.420]   with uh... the elements program on it and uh... some other science programs on
[00:53:28.420 --> 00:53:33.620]   he was a science teacher and he said if if if kapurna kiss had had this
[00:53:33.620 --> 00:53:37.780]   kapurna's spent most of his life grinding lenses so that he could observe the
[00:53:37.780 --> 00:53:41.140]   heavens so that he could come up with the theory that the earth revolves around
[00:53:41.140 --> 00:53:45.220]   the sun if he had something like this he wouldn't have a grind all those lenses
[00:53:45.220 --> 00:53:49.220]   he could get the data and then spend his energy coming up with theses and that's
[00:53:49.220 --> 00:53:53.620]   the world we live in today the data is now freely available is not
[00:53:53.620 --> 00:53:56.260]   uh... and high it is not a hot huge cost
[00:53:56.260 --> 00:53:59.780]   and and and and i think kids growing up today have a huge opportunity if they
[00:53:59.780 --> 00:54:00.820]   will use it
[00:54:00.820 --> 00:54:03.440]   to become great synthesizers
[00:54:03.440 --> 00:54:06.100]   but you've got to be able to handle data critically
[00:54:06.100 --> 00:54:08.980]   this is the thing that's right absolutely no we used to have a class at
[00:54:08.980 --> 00:54:12.020]   school called media studies when i was growing up where you
[00:54:12.020 --> 00:54:14.580]   you've been seen as an easy option but it's actually quite tough when you work
[00:54:14.580 --> 00:54:18.820]   into it where you watch tv programs and talk about newspaper articles and you
[00:54:18.820 --> 00:54:22.260]   work out why it's written the way it's written i think if we can have some kind
[00:54:22.260 --> 00:54:25.460]   of social media education either coming from parents or
[00:54:25.460 --> 00:54:28.820]   got help us from the schools i'm quite sure that would work but i mean some kind
[00:54:28.820 --> 00:54:32.020]   of parents can educate their their kids about
[00:54:32.020 --> 00:54:35.540]   this is what social media is about this is what they take from you this is what
[00:54:35.540 --> 00:54:38.180]   they expect in return and these are the benefits yeah
[00:54:38.180 --> 00:54:39.620]   education issue yeah
[00:54:39.620 --> 00:54:43.700]   and getting back to shifting business models again what you guys are talking
[00:54:43.700 --> 00:54:45.860]   about information wants to be free
[00:54:45.860 --> 00:54:49.620]   when uh... the blogging movement first took off
[00:54:49.620 --> 00:54:53.860]   one of its tenants where we can fact check your ass yes
[00:54:53.860 --> 00:54:59.220]   it becomes it becomes really hard to fact check and get your fact checking
[00:54:59.220 --> 00:55:01.140]   scene and vetted
[00:55:01.140 --> 00:55:04.180]   and taken as oh yeah you really took that down
[00:55:04.180 --> 00:55:06.860]   when algorithms are fighting you
[00:55:06.860 --> 00:55:09.860]   in getting your information out there and i think that's one of facebook's
[00:55:09.860 --> 00:55:13.540]   challenges and when you throw it back to why google is successful all these
[00:55:13.540 --> 00:55:14.580]   years later
[00:55:14.580 --> 00:55:15.700]   it's because
[00:55:15.700 --> 00:55:19.540]   their algorithms in their original search product
[00:55:19.540 --> 00:55:23.780]   we're providing you with the actual relevant information you were looking
[00:55:23.780 --> 00:55:28.180]   for they were not providing you with what was promoted
[00:55:28.180 --> 00:55:33.940]   or paid for otherwise yes absolutely right and that segues right into our
[00:55:33.940 --> 00:55:35.540]   first ad of the show
[00:55:35.540 --> 00:55:39.460]   hmm an hour and a half in
[00:55:39.460 --> 00:55:41.300]   and guess who it's from
[00:55:41.300 --> 00:55:43.300]   google
[00:55:43.380 --> 00:55:47.540]   our episode this week brought to you by google cloud the google cloud platform
[00:55:47.540 --> 00:55:48.180]   which
[00:55:48.180 --> 00:55:53.220]   hey really is amazing for anybody who wants to create the next social
[00:55:53.220 --> 00:55:54.100]   network
[00:55:54.100 --> 00:55:55.940]   create the next great thing
[00:55:55.940 --> 00:55:59.780]   when you're building an application you know the google cloud platform is a
[00:55:59.780 --> 00:56:00.900]   place to be
[00:56:00.900 --> 00:56:04.980]   and and this particular episode brought to you by the kubernetes engine
[00:56:04.980 --> 00:56:07.060]   on google cloud platform
[00:56:07.060 --> 00:56:10.900]   fast secure always evolving with the kubernetes engine developers can
[00:56:10.900 --> 00:56:15.220]   easily deploy containerized apps on a fully managed service from google
[00:56:15.220 --> 00:56:18.420]   cloud platform nobody does it better than google they scale
[00:56:18.420 --> 00:56:22.820]   they've been running production workloads and containers for more than 10 years
[00:56:22.820 --> 00:56:26.500]   oh sure you just heard about it but they've been doing for more than 10 years
[00:56:26.500 --> 00:56:29.620]   and they have built the best of what they learn into kubernetes engine
[00:56:29.620 --> 00:56:32.420]   kubernetes engine combines automatic scaling
[00:56:32.420 --> 00:56:36.340]   updates reliable self-healing infrastructure
[00:56:36.340 --> 00:56:39.460]   that's all the kind of thing you really need
[00:56:39.460 --> 00:56:42.340]   but there's also open source flexibility
[00:56:42.340 --> 00:56:45.780]   so you cut down your development cycles you can move from idea to production
[00:56:45.780 --> 00:56:49.300]   quickly and reliably i remember when my friend kevin rose started dig
[00:56:49.300 --> 00:56:51.780]   he had a he had a
[00:56:51.780 --> 00:56:56.260]   get a get a co-location buy a server put it in the cage
[00:56:56.260 --> 00:56:58.500]   set the whole thing up
[00:56:58.500 --> 00:57:02.180]   the next great application is out there in kubernetes engines ready to handle it
[00:57:02.180 --> 00:57:05.140]   with scheduling deployment for your workloads to maximize resource
[00:57:05.140 --> 00:57:08.100]   optimization you could focus on your apps
[00:57:08.100 --> 00:57:12.420]   it auto scales so when you succeed no problem
[00:57:12.420 --> 00:57:18.420]   those increased demands go up and by the way quiet periods scales down you save
[00:57:18.420 --> 00:57:21.540]   money that is really nice google is the only
[00:57:21.540 --> 00:57:28.020]   hyper scale cloud provider to offer an SLA for clusters running on kubernetes
[00:57:28.020 --> 00:57:31.380]   it's also backed by experts on google's security and reliability engineering
[00:57:31.380 --> 00:57:35.620]   team hip-a compliant pci compliant and of course
[00:57:35.620 --> 00:57:39.060]   it's open so you're never going to get locked in with kubernetes engine you're
[00:57:39.060 --> 00:57:41.300]   free to take your workloads out run them anywhere
[00:57:41.300 --> 00:57:45.540]   kubernetes is supported learn more about the great implementation
[00:57:45.540 --> 00:57:52.100]   of the kubernetes engine at g dot co slash get g ke today
[00:57:52.100 --> 00:57:58.180]   that's g dot co slash g e t g ke get google kubernetes engine
[00:57:58.180 --> 00:58:04.660]   g dot co slash g e t get g k e that's the short URL
[00:58:04.660 --> 00:58:09.140]   google cloud google cloud platform that's a really good example
[00:58:09.140 --> 00:58:12.580]   of the really empowering
[00:58:12.580 --> 00:58:18.260]   capabilities of these companies they can really empower people
[00:58:18.260 --> 00:58:23.940]   to do some amazing things it's why everybody well not everybody but
[00:58:23.940 --> 00:58:28.180]   learn to code learn to code that's my i think
[00:58:28.180 --> 00:58:33.540]   you know great media literacy it's good but if you have any interest in coding
[00:58:33.540 --> 00:58:38.100]   learn to code the sky's the limit and we need people who are aware and alert
[00:58:38.100 --> 00:58:41.700]   and smart and media literate and are thinking about this stuff to go out there
[00:58:41.700 --> 00:58:48.100]   right the next great app and do it ethically i love that
[00:58:48.100 --> 00:58:52.340]   all right moving along thank you Denise for being here we brought you here
[00:58:52.340 --> 00:58:56.900]   actually to talk about another issue which is very hot all of a sudden
[00:58:56.900 --> 00:59:00.660]   congress which hasn't been able to do anything is getting ready for
[00:59:00.660 --> 00:59:07.540]   i want to say siesta they're getting ready for the session and so they
[00:59:07.540 --> 00:59:10.260]   thought well we better get to work and do a few things obviously they didn't
[00:59:10.260 --> 00:59:15.860]   want the government shutdown so they passed it what was it a 1.3s 1.6
[00:59:15.860 --> 00:59:20.820]   trillion dollars trillion and on page one in two thousand and
[00:59:20.820 --> 00:59:25.140]   twenty four of this massive omnibus bill they stuck in a
[00:59:25.140 --> 00:59:30.420]   writer that put through the cloud act
[00:59:30.420 --> 00:59:34.500]   uh so first of all maybe maybe i better get the lawyer here
[00:59:34.500 --> 00:59:37.620]   explain to us this thing has been hanging around the cloud
[00:59:37.620 --> 00:59:40.820]   act's been hanging around for at least a year what is the cloud act
[00:59:40.820 --> 00:59:46.100]   it's been hanging around and it's been sort of put on the fast track because
[00:59:46.100 --> 00:59:50.260]   of a case before the supreme court right now involving microsoft
[00:59:50.260 --> 00:59:54.900]   uh where is the irish server case yes the irish server case
[00:59:54.900 --> 01:00:01.380]   where microsoft is is uh saying that they don't have to turn over
[01:00:01.380 --> 01:00:05.620]   information to law enforcement uh related to
[01:00:05.620 --> 01:00:11.220]   um a drug crime investigation because the information resides on a server that
[01:00:11.220 --> 01:00:14.420]   is completely under microsoft's control but is in
[01:00:14.420 --> 01:00:19.300]   ireland so they have taken that case all the way up to the supreme court it was
[01:00:19.300 --> 01:00:24.020]   argued yeah i think just last month uh we should have a decision on it
[01:00:24.020 --> 01:00:31.380]   soon but um right there in the chambers as it was being argued
[01:00:31.380 --> 01:00:35.940]   uh were lawmakers who are proponents of the cloud act
[01:00:35.940 --> 01:00:40.580]   uh as though to emphasize to the supreme court members
[01:00:40.580 --> 01:00:45.860]   that you know we may enact something that makes this completely moot for you
[01:00:45.860 --> 01:00:51.860]   well guess what they did they did um by sneaking it into the budget
[01:00:51.860 --> 01:00:55.380]   getting it passed and signed it is the law
[01:00:55.380 --> 01:00:59.220]   right this is let me let me tell this cloud stands for i love it it's a
[01:00:59.220 --> 01:01:03.380]   retronome the clarifying overseas use of data
[01:01:03.380 --> 01:01:08.580]   act what it does it creates an explicit provision
[01:01:08.580 --> 01:01:12.660]   for boy by the way thanks to uh orrin hatch lindsay graham coons in white
[01:01:12.660 --> 01:01:15.940]   house the force senators who created the cloud act
[01:01:15.940 --> 01:01:19.380]   it creates an explicit provision for u_s law enforcement
[01:01:19.380 --> 01:01:24.020]   whether it's the chief of police down the road and
[01:01:24.020 --> 01:01:29.140]   but boy utah or you know the national secure well let's see i guess it's the
[01:01:29.140 --> 01:01:34.740]   fbi to access or ice to access the contents of a wire or
[01:01:34.740 --> 01:01:38.820]   electronic communication and any record or other information
[01:01:38.820 --> 01:01:43.940]   about a person regardless of where they live
[01:01:43.940 --> 01:01:47.300]   or where that information is located on the globe
[01:01:47.300 --> 01:01:52.420]   let's say an irish national and their email is on a microsoft server in ireland
[01:01:52.420 --> 01:01:56.580]   for instance furthermore
[01:01:56.580 --> 01:02:00.580]   they don't need a warrant u_s police cappella service provider google
[01:02:00.580 --> 01:02:04.900]   facebook snapchat to hand over a user's content and metadata even if it's
[01:02:04.900 --> 01:02:08.420]   stored in a foreign country without following that foreign
[01:02:08.420 --> 01:02:11.220]   country's privacy law
[01:02:11.220 --> 01:02:15.220]   furthermore the president can enter into quote executive agreements in other
[01:02:15.220 --> 01:02:18.900]   words no oversight uh... with foreign governments that would allow those
[01:02:18.900 --> 01:02:22.260]   governments to acquire users data stored
[01:02:22.260 --> 01:02:26.100]   in other in the other country without following each other's privacy laws so
[01:02:26.100 --> 01:02:28.980]   china could come to google and say
[01:02:28.980 --> 01:02:32.740]   are chinese national and maybe a dissenter had a conversation
[01:02:32.740 --> 01:02:36.420]   with leo that's on your servers we would like that
[01:02:36.420 --> 01:02:39.700]   well there is one caveat to that they have to take a box saying we respect
[01:02:39.700 --> 01:02:41.380]   human rights
[01:02:41.380 --> 01:02:45.380]   it's the pinky swab version of of sort of uh... doing this
[01:02:45.380 --> 01:02:49.540]   oh my god and by the way this bill passed
[01:02:49.540 --> 01:02:53.540]   without being marked up without oversight without effect it was having
[01:02:53.540 --> 01:02:56.180]   trouble getting passed in the previously
[01:02:56.180 --> 01:03:00.180]   uh... it just snuck in at eight p.m. on wednesday
[01:03:00.180 --> 01:03:04.100]   this is what i don't get this is two thousand plus page bill
[01:03:04.100 --> 01:03:07.700]   two thousand release two hundred and thirty two page bill eight p.m. on a
[01:03:07.700 --> 01:03:10.660]   wednesday and you have to vote this tomorrow and they voted for it on
[01:03:10.660 --> 01:03:14.180]   thursday morning this is how nobody can have read that bill
[01:03:14.180 --> 01:03:18.420]   and it really strikes me as a strange thing for congress to enact in the first
[01:03:18.420 --> 01:03:20.900]   instance it really feels more like a treaty
[01:03:20.900 --> 01:03:25.620]   right we're getting some accommodations from other countries
[01:03:25.620 --> 01:03:30.100]   in exchange for the ability to empower u.s. police to go to their countries and
[01:03:30.100 --> 01:03:31.540]   grab data
[01:03:31.540 --> 01:03:35.940]   regardless if it's a u.s. persons or not no matter where it's stored so
[01:03:35.940 --> 01:03:40.660]   how how is that really something that we get to legislate it even bypasses
[01:03:40.660 --> 01:03:45.940]   american law on american soil so you you know your private data can be sent to
[01:03:45.940 --> 01:03:48.580]   a foreign country without a warrant without any
[01:03:48.580 --> 01:03:51.140]   regarding about it without any yes
[01:03:51.140 --> 01:03:55.780]   yeah uh so is there a good idea here or is this a fundamental a
[01:03:55.780 --> 01:04:00.820]   bad idea if if the idea was explored and discussed and
[01:04:00.820 --> 01:04:04.260]   and the kinks were worked out well what's weird is that i think
[01:04:04.260 --> 01:04:07.300]   microsoft supported this i think google so i think this was supported by it
[01:04:07.300 --> 01:04:10.660]   eventually initially they opposed it and then they changed the master hook
[01:04:10.660 --> 01:04:14.180]   right yeah they changed a few key words which basically reduces their legal
[01:04:14.180 --> 01:04:17.300]   liability to zero so they like they're like yeah okay we can live with
[01:04:17.300 --> 01:04:20.500]   companies like that like the certainty that this
[01:04:20.500 --> 01:04:24.340]   gives it also it gives them cover in the way i was saying maybe mark zuckerberg
[01:04:24.340 --> 01:04:28.820]   wants to be regulated so he has cover they can say oops sorry we you know we
[01:04:28.820 --> 01:04:32.820]   would protect your data on our foreign servers but we can't anymore
[01:04:32.820 --> 01:04:37.540]   because congress said no so supported the cloud act we i mean these are
[01:04:37.540 --> 01:04:41.460]   companies who claim all the effect for us yeah
[01:04:41.460 --> 01:04:46.500]   uh and yet they this is a clear example of them
[01:04:46.500 --> 01:04:51.620]   saying yeah we fight for you but go ahead pass that yeah we don't have to
[01:04:51.620 --> 01:04:55.620]   oh congress has tied our hands whoa who is me yes of course you can have that
[01:04:55.620 --> 01:05:00.260]   data so it just it's shame apple supported it
[01:05:00.260 --> 01:05:06.180]   yeah um microsoft supported it and you remember when microsoft when the
[01:05:06.180 --> 01:05:10.260]   doubling case first broke and microsoft were all up in arms about this just
[01:05:10.260 --> 01:05:14.180]   like we will fight for your rights they instructed the court to find them in
[01:05:14.180 --> 01:05:17.620]   contempt because they weren't prepared to play along with this
[01:05:17.620 --> 01:05:21.460]   and it was basically because this they knew this would throw an enormous
[01:05:21.460 --> 01:05:24.420]   curveball into their into their cloud business
[01:05:24.420 --> 01:05:26.900]   and now congress has acted on it and they can say
[01:05:26.900 --> 01:05:30.100]   well you know we tried and such his life but i guess we're just gonna have to
[01:05:30.100 --> 01:05:33.220]   obey what congress says here's the letterhead
[01:05:33.220 --> 01:05:37.620]   here's the letterhead sent to senator hatch graham coons in white house in
[01:05:37.620 --> 01:05:43.940]   support of the cloud act apple facebook google microsoft and oath
[01:05:43.940 --> 01:05:47.540]   i mean that's it right i'm surprised Comcast isn't on there but
[01:05:47.540 --> 01:05:50.100]   they're probably supported it too well they're keeping their head down up to
[01:05:50.100 --> 01:05:53.700]   that neutrality yeah getting back to harry's question i mean
[01:05:53.700 --> 01:05:56.500]   there are some practical realities here that this bill
[01:05:56.500 --> 01:06:00.740]   recognizes that you know it really makes no difference to microsoft where its
[01:06:00.740 --> 01:06:04.180]   servers are it has control over all of that data
[01:06:04.180 --> 01:06:09.540]   yeah and and i think that's what frustrated the lawmakers here or the
[01:06:09.540 --> 01:06:13.380]   prosecutors in the drug case that we have let me put myself in microsoft
[01:06:13.380 --> 01:06:16.820]   shoes uh this is look at the nature of the way
[01:06:16.820 --> 01:06:19.860]   technology works is it our day your data is going to be all over the place we
[01:06:19.860 --> 01:06:24.740]   don't want to have to figure out interlocking data protections data
[01:06:24.740 --> 01:06:28.180]   rules of all these different countries is impossible for us
[01:06:28.180 --> 01:06:35.060]   so we just want need some simple rule that that cuts through all of this
[01:06:35.060 --> 01:06:39.220]   um i understand that i mean i do understand especially if
[01:06:39.220 --> 01:06:43.300]   you can just it by the way just add up some language that lets us off the hook
[01:06:43.300 --> 01:06:47.380]   that would be nice or it's good doesn't deal
[01:06:47.380 --> 01:06:50.900]   so when apple says your personal data belongs to you
[01:06:50.900 --> 01:06:54.500]   hmm well in certain circumstances and conditions
[01:06:54.500 --> 01:06:59.780]   they're fly i just i i think that your mileage may vary
[01:06:59.780 --> 01:07:04.100]   yes exactly can we go ahead and and just declare
[01:07:04.100 --> 01:07:07.540]   that this whole bill acronym thing has gotten completely
[01:07:07.540 --> 01:07:11.140]   out the world terrible oh the patriot act was the worst
[01:07:11.140 --> 01:07:15.460]   one that protecting america just like they come up with a name and then they
[01:07:15.460 --> 01:07:19.940]   retro-nimit so that it makes yeah the eff says the cloud act is a new
[01:07:19.940 --> 01:07:23.060]   proposed backdoor to our data which bypasses the fourth
[01:07:23.060 --> 01:07:25.860]   amendment protections to communications privacy
[01:07:25.860 --> 01:07:29.860]   the aclu called the sinister piece of legislation
[01:07:29.860 --> 01:07:33.540]   the threatens activists abroad individuals here in the u_s
[01:07:33.540 --> 01:07:37.780]   would empower the attorney general in new and disturbing ways
[01:07:37.780 --> 01:07:42.820]   and uh and it supports foreign governments going after uh
[01:07:42.820 --> 01:07:46.660]   dissidents in the united states it does it does mean we're using for
[01:07:46.660 --> 01:07:49.940]   activists in the u_s_
[01:07:49.940 --> 01:07:53.460]   who might well take off company countries opposed by amnestine
[01:07:53.460 --> 01:07:56.100]   international people for the american way humans right
[01:07:56.100 --> 01:07:59.220]   whom in whites watch the national association of criminal defense
[01:07:59.220 --> 01:08:03.620]   lawyers all said that this bill is a bad idea
[01:08:03.620 --> 01:08:07.140]   well there's no oversight this is the thing i mean if the executive decides to
[01:08:07.140 --> 01:08:09.540]   conduct one of these deals with another country
[01:08:09.540 --> 01:08:13.060]   the only way you'd find out about it is if somebody leaks about it
[01:08:13.060 --> 01:08:16.340]   uh i don't believe is and and you can correct me if i'm wrong on this but i
[01:08:16.340 --> 01:08:20.180]   don't believe the the legislation requires the government to say who it
[01:08:20.180 --> 01:08:23.300]   has these agreements with uh and that's
[01:08:23.300 --> 01:08:27.460]   tremendously worrying into if you're a foreign activist who's based over here
[01:08:27.460 --> 01:08:30.500]   well and if you're a foreign activist you probably are going to stop using
[01:08:30.500 --> 01:08:34.820]   any american products period yeah right because you no longer
[01:08:34.820 --> 01:08:38.260]   have any protections so uh what should you do you should
[01:08:38.260 --> 01:08:41.300]   start you should be invest in encryption
[01:08:41.300 --> 01:08:44.740]   get signal yourself when you signal signal yeah it seems to be the gold
[01:08:44.740 --> 01:08:48.900]   stunted these days yeah uh and you sure it's now would be a
[01:08:48.900 --> 01:08:52.580]   really good time to donate to eff because you know their lawyers are
[01:08:52.580 --> 01:08:56.340]   looking at this uh you think there's a way to fight it
[01:08:56.340 --> 01:09:01.060]   uh well i i mean if they can figure out a way that congress has exceeded its
[01:09:01.060 --> 01:09:05.060]   authority in unconstitutional ways here
[01:09:05.060 --> 01:09:08.980]   uh then yeah i you know it's definitely something i'm sure
[01:09:08.980 --> 01:09:12.340]   is being examined i mean the courts took down large sections of the
[01:09:12.340 --> 01:09:15.700]   communications decency act they've they've done an awful lot of stuff in
[01:09:15.700 --> 01:09:19.140]   protecting encryption so it does offer a way forward and yeah
[01:09:19.140 --> 01:09:24.660]   the effr you know solid uh and well worth contributing to
[01:09:24.660 --> 01:09:31.780]   ray aussie by the way he's turned on us it reminded me why we know who ray aussies
[01:09:31.780 --> 01:09:36.740]   he created lotus uh notes right then went to microsoft microsoft ctl for a
[01:09:36.740 --> 01:09:41.860]   little while yeah he's forced out he kind of shared work
[01:09:41.860 --> 01:09:44.660]   environments right he was the guy who was supposed to bring
[01:09:44.660 --> 01:09:47.620]   microsoft into the cloud but they've enough people at microsoft hated his
[01:09:47.620 --> 01:09:50.900]   guts that they forced him out he created grove which was grove
[01:09:50.900 --> 01:09:55.140]   the collaboration widely agreed to be a genius
[01:09:55.140 --> 01:09:58.580]   maybe not so much in this respect he and others
[01:09:58.580 --> 01:10:03.220]   like him have agreed with the fbi and the justice department
[01:10:03.220 --> 01:10:06.980]   because of course the fbi and the justice department don't like it that
[01:10:06.980 --> 01:10:09.460]   there's stuff on phones they can't get to
[01:10:09.460 --> 01:10:13.220]   although i have to say we know we've seen this uh the report from uh
[01:10:13.220 --> 01:10:16.900]   the harvard uh bergman center going dark that in fact they have more ways of
[01:10:16.900 --> 01:10:21.940]   spying on us than ever before they don't i mean the problem is that your phone
[01:10:21.940 --> 01:10:26.340]   has everything has your life in here and i think need some specialized
[01:10:26.340 --> 01:10:31.060]   protection over and above you know just your computer or
[01:10:31.060 --> 01:10:33.780]   i mean this is you put everything in this phone
[01:10:33.780 --> 01:10:38.100]   so the justice department says here's what we how about this
[01:10:38.100 --> 01:10:41.620]   uh what if there were a mechanism to access the data on your phone that could
[01:10:41.620 --> 01:10:45.780]   be engineered without weakening the devices security against hacking
[01:10:45.780 --> 01:10:50.100]   some sort of secure enclave that contains the encryption key
[01:10:50.100 --> 01:10:54.020]   that would only be accessible to law enforcement
[01:10:54.020 --> 01:10:58.580]   with the help of a company and then we could then you know we could just go to
[01:10:58.580 --> 01:11:01.780]   apple would say okay look it's a special case
[01:11:01.780 --> 01:11:05.700]   could you unlock that phone what an amazing idea i'm amazed no one's
[01:11:05.700 --> 01:11:09.300]   thought of that one i mean seriously seriously we're gonna let
[01:11:09.300 --> 01:11:13.940]   we're gonna set this up and then trust that the government will look after
[01:11:13.940 --> 01:11:17.220]   the encryption key and ask the officer personnel management how good they are
[01:11:17.220 --> 01:11:20.180]   at that kind of stuff ask the nsa how good it is at keeping
[01:11:20.180 --> 01:11:23.380]   its private secrets private yeah or we're gonna trust it can
[01:11:23.380 --> 01:11:27.700]   companies like apple and google i mean people yes an encryption back door is
[01:11:27.700 --> 01:11:31.380]   a fantastic idea is a is a great idea in some circumstances
[01:11:31.380 --> 01:11:35.860]   but you can't build a backdoor into a system that no one else can find
[01:11:35.860 --> 01:11:39.300]   and if you tell people it's there they will move heaven and earth to find it
[01:11:39.300 --> 01:11:45.940]   so i agree and math says this is the case but there are people like ray aussie
[01:11:45.940 --> 01:11:50.900]   uh who he said quote this issue is not going away
[01:11:50.900 --> 01:11:54.020]   and we think that we need to have some constructive dialogue rather than
[01:11:54.020 --> 01:11:58.180]   saying it can't be done and i understand that people
[01:11:58.180 --> 01:12:03.380]   uh like aussie uh stephen savage who's a computer science professor at UCSD
[01:12:03.380 --> 01:12:06.180]   ernie brickel former chief security officer at intel
[01:12:06.180 --> 01:12:12.100]   these three have been meeting at mit uh to try to find a solution i i understand
[01:12:12.100 --> 01:12:16.100]   that they they're probably patriots they want to protect the nation they feel
[01:12:16.100 --> 01:12:19.460]   like the terrorists can use these technologies to
[01:12:19.460 --> 01:12:22.900]   operate unimpeded and that that law enforcement should have and i agree with
[01:12:22.900 --> 01:12:25.700]   all of that but i do think that there's a
[01:12:25.700 --> 01:12:29.860]   really substantive question is it possible
[01:12:29.860 --> 01:12:33.060]   to crack this stuff in a way that doesn't give
[01:12:33.060 --> 01:12:38.740]   bad guys access to my stuff as well well as as i read this
[01:12:38.740 --> 01:12:43.060]   and you guys correct me if i'm wrong but it seems like the distinction that they're
[01:12:43.060 --> 01:12:47.460]   working toward here is maybe having a unique
[01:12:47.460 --> 01:12:52.980]   key for each device that doesn't unlock the entire operating system for every
[01:12:52.980 --> 01:12:56.420]   other device right and that's what would be
[01:12:56.420 --> 01:13:00.500]   subpoenaed so does that make you feel any more comfortable
[01:13:00.500 --> 01:13:05.940]   and it lives on the device yes yeah it's a little bit like how apple pay
[01:13:05.940 --> 01:13:08.580]   works where there's a secure enclave
[01:13:08.580 --> 01:13:13.140]   um that nobody can get at except for apple pay
[01:13:13.140 --> 01:13:16.100]   this would be a secure enclave that nobody could get at
[01:13:16.100 --> 01:13:20.340]   except apple right and uh i don't remember go to apple to get at it
[01:13:20.340 --> 01:13:25.140]   although as we can see with the cloud act the standards for what the government
[01:13:25.140 --> 01:13:29.300]   has to do to get apple to agree have shifted dramatically
[01:13:29.300 --> 01:13:32.340]   yeah um and if they could just say by the way
[01:13:32.340 --> 01:13:36.340]   what's that key again um now i agree with you
[01:13:36.340 --> 01:13:39.620]   Denise there's a real benefit to fact the fact that it's done
[01:13:39.620 --> 01:13:42.820]   on a per phone basis that's a i think that's a good
[01:13:42.820 --> 01:13:46.420]   protection and actually you know Steve Gibson suggested exactly this
[01:13:46.420 --> 01:13:49.860]   solution and he said i think this is a reasonable compromise
[01:13:49.860 --> 01:13:53.300]   um i hope i'm not putting word in your mouth Steve but he said this was some
[01:13:53.300 --> 01:13:55.620]   months ago yeah this would be a solution that would
[01:13:55.620 --> 01:13:59.380]   you know at least be limited in its risks
[01:13:59.380 --> 01:14:02.900]   hmm it's fun i guess it has a precedent the
[01:14:02.900 --> 01:14:07.140]   New York Times article talks about symphony in the banking world right
[01:14:07.140 --> 01:14:12.740]   uh the uh symphony which is an encrypted messaging system for banks
[01:14:12.740 --> 01:14:18.340]   uh several banks agree to give copies of their symphony keys to law firms
[01:14:18.340 --> 01:14:21.460]   because symphony keeps a copy of encrypted data on servers that
[01:14:21.460 --> 01:14:24.500]   arrangement created a backup means for investigators to gain access to the
[01:14:24.500 --> 01:14:29.620]   messages if necessary christopher ray the fbi director former after i
[01:14:29.620 --> 01:14:32.500]   director said at the end of the data is he's former i can't remember it's
[01:14:32.500 --> 01:14:35.700]   changed so fast i think so at the end the data is still
[01:14:35.700 --> 01:14:39.380]   the director okay at the end the data in symphony was still secure still
[01:14:39.380 --> 01:14:42.500]   encrypted but also accessible to the regulators so they could do their
[01:14:42.500 --> 01:14:44.820]   jobs
[01:14:44.820 --> 01:14:50.340]   so okay so can we so maybe this is a solution that's okay
[01:14:50.340 --> 01:14:53.300]   it's moving in the right direction it sounds like
[01:14:53.300 --> 01:14:56.260]   it's not a master key to every iPhone on the planet
[01:14:56.260 --> 01:15:00.100]   it's a key to a particular person i instill of the opinion that that
[01:15:00.100 --> 01:15:04.420]   well yeah i don't know the fbi i managed perfectly well for the first 100 years
[01:15:04.420 --> 01:15:08.340]   they survived without this yeah and it just seems like yeah i feel like this
[01:15:08.340 --> 01:15:13.060]   is somehow a sprivelaged device the data we put in here
[01:15:13.060 --> 01:15:17.300]   it's like accessing my brain and that should be protected
[01:15:17.300 --> 01:15:20.580]   and this should be protected i'm not a well the other distinction that that
[01:15:20.580 --> 01:15:25.140]   ray aussie makes in in talking about this is i'm only working on the device
[01:15:25.140 --> 01:15:29.300]   problem how we unlock the device if things are encrypted on the device
[01:15:29.300 --> 01:15:32.820]   i'm not working on that good or at least not for now
[01:15:32.820 --> 01:15:36.340]   so but but i can tell you that the very next thing that happens yeah
[01:15:36.340 --> 01:15:39.780]   right the fbi says oh crap everybody's using signal
[01:15:39.780 --> 01:15:43.620]   we need a backdoor in signal by the way and now
[01:15:43.620 --> 01:15:47.780]   oh well it's a little easier because we got this we could do that
[01:15:47.780 --> 01:15:53.940]   hmm so i just it's a slippery slope and i i just i'm not i'm i'm again it
[01:15:53.940 --> 01:15:58.820]   yeah no i'm it's the same with with sester and fester
[01:15:58.820 --> 01:16:02.820]   it's it's the start of a slippery slope slippery slope okay we'll make this
[01:16:02.820 --> 01:16:06.500]   exception for child for child traffickers yeah
[01:16:06.500 --> 01:16:09.780]   even though the law itself is probably going to make them more more prone to
[01:16:09.780 --> 01:16:13.220]   being abused as like well and next time it'll be well
[01:16:13.220 --> 01:16:16.340]   there's the terrorist the terrorist that's a good one
[01:16:16.340 --> 01:16:18.900]   and then before you know it you're left with nothing
[01:16:18.900 --> 01:16:21.700]   let's say well let's get to sester and faster next
[01:16:21.700 --> 01:16:24.980]   but i want to take a little break uh it's great to have Harry McCracken here
[01:16:24.980 --> 01:16:27.700]   fast company how's things going everything good
[01:16:27.700 --> 01:16:30.580]   things are great you were uh you and marie were down at the
[01:16:30.580 --> 01:16:33.700]   south by did you enjoy that i actually set it out because i had too
[01:16:33.700 --> 01:16:37.220]   many colleagues you sent marie and you stayed home
[01:16:37.220 --> 01:16:40.420]   she's gotten so much trouble down there you didn't know anything about that did
[01:16:40.420 --> 01:16:44.100]   you no i'm teasing um t it was a lot of fun
[01:16:44.100 --> 01:16:47.140]   though it was really fun i i we didn't run into each other
[01:16:47.140 --> 01:16:50.900]   nice to have you here in uh congratulations on your promotion Ian
[01:16:50.900 --> 01:16:55.060]   Thompson news editor at the register dot co dot uk
[01:16:55.060 --> 01:16:59.940]   which is still a great you're you guys it's great everybody else is
[01:16:59.940 --> 01:17:03.060]   like suffering and you guys are beefing up the staff and
[01:17:03.060 --> 01:17:06.820]   you're doing great yeah it's it it seems to be working well it's
[01:17:06.820 --> 01:17:09.540]   um i think that's something to be said for being
[01:17:09.540 --> 01:17:13.700]   slightly snarky and cynical and love it love it
[01:17:13.700 --> 01:17:16.820]   it you know what it's an antidote to all of the just
[01:17:16.820 --> 01:17:20.820]   overwhelming sludge that we're uh crawling through here
[01:17:20.820 --> 01:17:23.300]   it doesn't make us popular with companies but what the hell when i hear
[01:17:23.300 --> 01:17:26.740]   to be popular so right it might add a tune exactly
[01:17:26.740 --> 01:17:30.260]   and the wonderful Denise how you got to listen to this week in law every
[01:17:30.260 --> 01:17:34.340]   Friday what time 11 o'clock pacific time
[01:17:34.340 --> 01:17:38.340]   1800 UTC you you sound like somebody i know
[01:17:38.340 --> 01:17:42.180]   a mere two hours of your time is all we ask it's so good it's a must listen
[01:17:42.180 --> 01:17:44.820]   you love this stuff i mean this is where you get the deep dive and you
[01:17:44.820 --> 01:17:49.380]   understand it and you have great people on and i just i always love it
[01:17:49.380 --> 01:17:53.460]   thank you for all for being here we had a fun week this week talking about
[01:17:53.460 --> 01:17:56.500]   all this stuff i think we have a little mini movie that we've prepared for
[01:17:56.500 --> 01:18:00.820]   your enjoyment watch previously on twit could be the end of facebook
[01:18:00.820 --> 01:18:04.260]   somewhere right what do you think we need to have something like facebook
[01:18:04.260 --> 01:18:08.980]   do we do we yeah i i do think we do this week in google this is mark
[01:18:08.980 --> 01:18:11.540]   succerberg's comment he said we have a responsibility
[01:18:11.540 --> 01:18:14.500]   to protect your data if we can't we don't deserve to serve you i'm
[01:18:14.500 --> 01:18:17.700]   disappointed that all he did was deal with the tactical details that came
[01:18:17.700 --> 01:18:21.060]   regenitica there's a much bigger issue here about what the public
[01:18:21.060 --> 01:18:25.300]   responsibility of these platforms is tech news weekly this week pedestrian
[01:18:25.300 --> 01:18:29.300]   elaine herzberg was killed after stepping into the path of a self-driving
[01:18:29.300 --> 01:18:33.380]   uber seem to describe a high level of what that dash cam video showed
[01:18:33.380 --> 01:18:36.420]   it actually tells quite a different story from what we first heard from the
[01:18:36.420 --> 01:18:39.540]   police on monday a contrary to what the police said this appears to have been
[01:18:39.540 --> 01:18:44.500]   an entirely avoidable accident ios today this is really i think this is kind of
[01:18:44.500 --> 01:18:49.140]   cool week roque i brought this up at many a cocktail party over the last week
[01:18:49.140 --> 01:18:54.100]   oh you must be a real welcome guest i know we're all gonna die
[01:18:54.100 --> 01:18:57.460]   i have like oh i have this ad that reminds me six times a day that i'm
[01:18:57.460 --> 01:19:01.940]   gonna die what do you think of that to it the happiest place on earth
[01:19:01.940 --> 01:19:06.340]   how many parties a week do you go to it's so many i haven't been to a party in
[01:19:06.340 --> 01:19:10.340]   months i'm sure you were invited to the party it was the school fundraiser that
[01:19:10.340 --> 01:19:13.380]   i brought it up to many different people probably i'm sure you were invited to
[01:19:13.380 --> 01:19:18.020]   that yeah my brother die that's a reminder of death isn't it our show
[01:19:18.020 --> 01:19:20.420]   today brought to you by somebody i can celebrate
[01:19:20.420 --> 01:19:24.420]   that i use we use it work and we're really happy i've been trying to get these
[01:19:24.420 --> 01:19:28.820]   guys as a sponsor literally since twits started last pass
[01:19:28.820 --> 01:19:32.580]   last pass keeps your everybody loves last pass if you're not using it you
[01:19:32.580 --> 01:19:36.340]   better get there and use it keeps your passwords organized secure right at
[01:19:36.340 --> 01:19:39.460]   your fingertips it solves the fundamental problem that
[01:19:39.460 --> 01:19:42.500]   passwords present you've got to remember a bunch of them you got to keep them
[01:19:42.500 --> 01:19:46.100]   secure but the problem is if you've got to remember a bunch of them you're
[01:19:46.100 --> 01:19:48.980]   gonna keep them secure you're gonna pick passwords you can remember you're
[01:19:48.980 --> 01:19:52.260]   gonna use the same password over and over and you're gonna use bad passwords
[01:19:52.260 --> 01:19:56.500]   your your niece's name the name of your dog and the birthday of your child that's
[01:19:56.500 --> 01:20:01.300]   a terrible password with last pass you let it generate
[01:20:01.300 --> 01:20:07.380]   long obscure it unmemorable passwords
[01:20:07.380 --> 01:20:12.260]   storm securely fully encrypted all you have to remember is
[01:20:12.260 --> 01:20:16.580]   one password your master password last pass does the rest
[01:20:16.580 --> 01:20:20.500]   you don't want to reuse passwords you want long i make my passwords i'm not
[01:20:20.500 --> 01:20:22.740]   gonna tell you the length because part of my
[01:20:22.740 --> 01:20:26.100]   security through obscurity is not using the standard lengths
[01:20:26.100 --> 01:20:29.700]   i make them like 17 or 23 i like prime numbers
[01:20:29.700 --> 01:20:37.300]   and then so long 58 long then last pass automatically remembers
[01:20:37.300 --> 01:20:41.220]   and fills in your passwords anytime anywhere not just on your computer
[01:20:41.220 --> 01:20:43.700]   on your browser but on your mobile device to in fact
[01:20:43.700 --> 01:20:48.420]   with a new uh android 8 1 last pass is so great now
[01:20:48.420 --> 01:20:53.460]   it just fills it in so easily and then you've got a last pass vault
[01:20:53.460 --> 01:20:56.660]   that's encrypted on last pass servers they don't have the key only you have
[01:20:56.660 --> 01:21:00.660]   the key strong encryption using some really sophisticated
[01:21:00.660 --> 01:21:03.140]   techniques i don't know if you remember but uh
[01:21:03.140 --> 01:21:06.740]   steve gipson actually got a deep dive from the creator of last pass joe's
[01:21:06.740 --> 01:21:10.740]   seagrist and was so impressed he started using it so
[01:21:10.740 --> 01:21:13.380]   impressed by the technologies that last pass is
[01:21:13.380 --> 01:21:19.300]   using to protect you and we use last pass enterprise and i gotta tell you
[01:21:19.300 --> 01:21:21.780]   this is great in fact we like last pass so much
[01:21:21.780 --> 01:21:24.580]   as a benefit to people who work at twit and we've done this for the last few
[01:21:24.580 --> 01:21:28.420]   years they get a free last pass account in addition to the last
[01:21:28.420 --> 01:21:32.660]   pass enterprise and they can merge that they can keep the two together that's
[01:21:32.660 --> 01:21:35.780]   what i do so i have access to all the company passwords and all my personal
[01:21:35.780 --> 01:21:38.580]   passwords it doesn't merge them it's separate but
[01:21:38.580 --> 01:21:40.900]   i log into one vault and i have it all
[01:21:40.900 --> 01:21:45.060]   81 percent of breaches are caused by weak passwords
[01:21:45.060 --> 01:21:49.380]   gotta use last pass it protects every password in your business without
[01:21:49.380 --> 01:21:53.220]   slowing down your employees aes 256 bit encryption
[01:21:53.220 --> 01:21:57.380]   to protect against man in the middle attacks they use pbk ddf whatever the
[01:21:57.380 --> 01:22:00.100]   heck that is where they just have anyway i can go on and on you should
[01:22:00.100 --> 01:22:02.900]   actually listen steve gipson did a really good
[01:22:02.900 --> 01:22:06.340]   segment on last pass where it explains what they do
[01:22:06.340 --> 01:22:11.300]   they've got products for homes for individuals for families we use last
[01:22:11.300 --> 01:22:16.500]   pass for families this is by the way i love this feature
[01:22:16.500 --> 01:22:20.660]   i uh there's a death benefit we're talking about death a second ago
[01:22:20.660 --> 01:22:24.420]   i can designate and i have my wife if something happens to me
[01:22:24.420 --> 01:22:27.140]   i i hear about this all the time when geeks die and they don't know their
[01:22:27.140 --> 01:22:29.220]   family does not get into any of their stuff
[01:22:29.220 --> 01:22:32.980]   she will have access my last pass so the way it works is she requested of last
[01:22:32.980 --> 01:22:38.020]   pass she says i'm the designated you know survivor
[01:22:38.020 --> 01:22:41.860]   she sends them a message they send me an email to the email address i
[01:22:41.860 --> 01:22:46.500]   specified with last pass if and then i can say if i don't respond after
[01:22:46.500 --> 01:22:50.180]   weak i'm dead if i don't i actually made it two days
[01:22:50.180 --> 01:22:53.780]   if i don't respond after two days i'm dead give her the password
[01:22:53.780 --> 01:22:59.140]   that is huge it really gave me peace of mind
[01:22:59.140 --> 01:23:02.500]   last pass premium for personal use last pass families for your whole family we
[01:23:02.500 --> 01:23:04.660]   use that all the time family sharing is fabulous
[01:23:04.660 --> 01:23:07.700]   last pass teams for teams are 50 or less
[01:23:07.700 --> 01:23:10.500]   there's a solution for you very affordable
[01:23:10.500 --> 01:23:14.820]   there's it you got to try it at work and at home fix your password woes with
[01:23:14.820 --> 01:23:17.860]   last pass it is the number one most preferred password
[01:23:17.860 --> 01:23:20.180]   manager is what i use what we use it to it
[01:23:20.180 --> 01:23:23.300]   learn more at last pass dot com slash twit
[01:23:23.300 --> 01:23:27.460]   lat there it is it is literally the first program i install and any new
[01:23:27.460 --> 01:23:30.260]   device or computer but you know why that is because then i can log into all the
[01:23:30.260 --> 01:23:34.740]   rest last pass dot com slash
[01:23:34.740 --> 01:23:39.460]   to it i actually put passports in their drivers license all the documents that
[01:23:39.460 --> 01:23:42.100]   i want to keep track of but i don't want anybody else to have access to because
[01:23:42.100 --> 01:23:44.820]   they they're important privacy documents i keep them
[01:23:44.820 --> 01:23:48.580]   oh that's a great idea yeah and you know what else i do with last pass which is
[01:23:48.580 --> 01:23:51.620]   great i use a authenticator separate authenticator
[01:23:51.620 --> 01:23:57.540]   but i the qr code that you use to i put that in last pass
[01:23:57.540 --> 01:24:00.740]   so because that's a safe place to store that so i can set up the authenticator
[01:24:00.740 --> 01:24:05.540]   on a new device episode 256 of security now if you want to
[01:24:05.540 --> 01:24:09.780]   watch our last pass dissection
[01:24:09.780 --> 01:24:12.340]   all right
[01:24:12.340 --> 01:24:20.500]   sausta festa festa sausta festa festa festa
[01:24:20.500 --> 01:24:23.460]   they're not the same or they are actually make sense
[01:24:23.460 --> 01:24:28.020]   fight online sex trafficking act or uh stop
[01:24:28.020 --> 01:24:31.140]   online sex trafficking act was one of the house and one of the same
[01:24:31.140 --> 01:24:33.860]   but they're acronyms to yeah i mean the idea of
[01:24:33.860 --> 01:24:37.540]   festa was the house sesta was the senate okay and then and they reconciled bill
[01:24:37.540 --> 01:24:40.500]   was was passed has has it yet been signed into law by president trump
[01:24:40.500 --> 01:24:44.820]   or yes it has so it's the law it is the law
[01:24:44.820 --> 01:24:47.300]   um
[01:24:47.300 --> 01:24:51.140]   so the the name implies and something nobody wants
[01:24:51.140 --> 01:24:54.820]   which is good stop enabling sex traffickers yeah who's who would be
[01:24:54.820 --> 01:24:58.900]   against that the problem is it might have
[01:24:58.900 --> 01:25:03.860]   go much farther than that danish explain well we've already seen the fallout of
[01:25:03.860 --> 01:25:07.060]   it just in the day since uh it was signed into law
[01:25:07.060 --> 01:25:13.300]   craigslist used to have personals where at lots of lots of people have
[01:25:13.300 --> 01:25:17.220]   have not that's not sex trafficking that's me saying
[01:25:17.220 --> 01:25:21.300]   hey i i was at a bar and i saw a beautiful girl with a red rose and
[01:25:21.300 --> 01:25:27.060]   what's your name i missed you right yes just like that
[01:25:27.060 --> 01:25:31.140]   there are also sex workers on there in the way in the wake of passing this
[01:25:31.140 --> 01:25:36.740]   craigslist has said we're so sorry uh but they're the first fallout of this act
[01:25:36.740 --> 01:25:41.460]   we don't dare have a personal section because we would be liable under
[01:25:41.460 --> 01:25:46.740]   so sofissa can i just call it stuff
[01:25:46.740 --> 01:25:50.820]   we would be liable and what is the liability
[01:25:50.820 --> 01:25:55.940]   uh well i mean the liability is for sex trafficking
[01:25:55.940 --> 01:26:00.180]   so it's as if craigslist was the sex trafficker yes
[01:26:00.180 --> 01:26:04.100]   exactly so section 230 of the communications decency act
[01:26:04.100 --> 01:26:09.140]   uh is is instrumental to how the web as we know it
[01:26:09.140 --> 01:26:14.020]   works um how people can have interactions with one another on the
[01:26:14.020 --> 01:26:20.020]   web some totally legal some not but uh the sites where they're
[01:26:20.020 --> 01:26:24.500]   having those interactions are by and large not responsible
[01:26:24.500 --> 01:26:30.580]   unless it's a criminal a federal criminal uh law that's being violated
[01:26:30.580 --> 01:26:34.100]   or of course what's carved out of um section 230
[01:26:34.100 --> 01:26:37.460]   as well is uh intellectual property violations
[01:26:37.460 --> 01:26:40.900]   so to the extent any of this would be that what we're concerned about are
[01:26:40.900 --> 01:26:45.700]   things that were federal crimes already section 230 already was drafted
[01:26:45.700 --> 01:26:50.660]   perfectly comfortably to accommodate that it didn't provide any shelter
[01:26:50.660 --> 01:26:55.380]   uh to sites uh for people who were engaging in federal crimes on their
[01:26:55.380 --> 01:26:59.860]   platforms uh and they were thus incentivized to
[01:26:59.860 --> 01:27:06.020]   prevent that kind of activity uh but now is what we're doing sex trafficking is
[01:27:06.020 --> 01:27:09.620]   that prostitution well that's a good i mean
[01:27:09.620 --> 01:27:13.780]   there's a lot of i mean i'm not in favor of sex slaves but it's right
[01:27:13.780 --> 01:27:16.900]   it's different right sex trafficking is is what you
[01:27:16.900 --> 01:27:21.940]   just described i think um people engaged in you know being forced to engage in
[01:27:21.940 --> 01:27:26.500]   sexual activities without without their consent and uh
[01:27:26.500 --> 01:27:30.260]   you know being dragooned into um things they don't want to do
[01:27:30.260 --> 01:27:34.340]   but your same section 230 did not protect
[01:27:34.340 --> 01:27:39.780]   uh a blog comment section or reddit or it didn't protect them against that
[01:27:39.780 --> 01:27:44.020]   crimes were already carved out now state crimes were not so
[01:27:44.020 --> 01:27:47.940]   uh it's safe sex trafficking this protects
[01:27:47.940 --> 01:27:52.900]   right right right so uh what it what this winds up doing is
[01:27:52.900 --> 01:27:56.580]   yes potentially putting it's it gives a very broad
[01:27:56.580 --> 01:28:02.500]   uh definition of what constitutes things that are going to be
[01:28:02.500 --> 01:28:06.580]   prevented and enforceable and prosecutable here
[01:28:06.580 --> 01:28:10.500]   so craigslist was worried enough that they said well we're not even going to
[01:28:10.500 --> 01:28:13.460]   take the chance so that's one problem is you're going to see
[01:28:13.460 --> 01:28:16.260]   people just say well we're not going to take the chance in fact i think some
[01:28:16.260 --> 01:28:19.620]   reddit sub-readits were closed as well uh for the same reason
[01:28:19.620 --> 01:28:22.740]   uh but there's also the issue and we were talking about how somebody should
[01:28:22.740 --> 01:28:25.940]   come along and disintermediate facebook by making a better
[01:28:25.940 --> 01:28:31.380]   privacy-focused facebook facebook has the resources perhaps to moderate and to
[01:28:31.380 --> 01:28:33.860]   search for and to get rid of anything that would violate
[01:28:33.860 --> 01:28:37.620]   sausta fess-sesta festa
[01:28:37.620 --> 01:28:42.740]   still stuff but if you're the new facebook if you're the little guy you may not
[01:28:42.740 --> 01:28:47.380]   and so this my godwin said this actually kills innovation to it it keeps you
[01:28:47.380 --> 01:28:50.900]   from getting a next facebook senator ron wyden said exactly the same thing
[01:28:50.900 --> 01:28:54.740]   on the senate floor i mean he actually wrote section 230 so he knows what he's
[01:28:54.740 --> 01:28:58.020]   talking about and he was saying it was shameful that the tech companies are
[01:28:58.020 --> 01:29:01.380]   supporting this because they know they've got the armies of lawyers needed and
[01:29:01.380 --> 01:29:04.180]   moderators that they can actually protect themselves with but if you're a
[01:29:04.180 --> 01:29:09.300]   startup your liability bill is just gone through the ceiling if you're having
[01:29:09.300 --> 01:29:13.220]   any kind of public forums on there so the big tech companies like this because
[01:29:13.220 --> 01:29:14.420]   it's an anti-competitive move
[01:29:14.420 --> 01:29:22.260]   here's uh here's a quote the compliance is incredibly expensive and and the
[01:29:22.260 --> 01:29:27.140]   problem is as you pointed out leo there there's a difference between sex
[01:29:27.140 --> 01:29:36.100]   trafficking and sexual discourse and the one will get curtailed in service of
[01:29:36.100 --> 01:29:40.500]   protecting liability from the other and there is a legitimate concern for sex
[01:29:40.500 --> 01:29:44.340]   workers who have been using things like sraigslist i mean that that is certainly
[01:29:44.340 --> 01:29:47.540]   goes on there to get off the streets and to get out of
[01:29:47.540 --> 01:29:52.020]   being pimped study after study has shown it's actually safer for for sex workers
[01:29:52.020 --> 01:29:56.100]   to to go online rather to get business online rather than actually having to
[01:29:56.100 --> 01:29:59.460]   go out into the street because you're not as you say you're not out there you're
[01:29:59.460 --> 01:30:03.460]   much more capable of running your own business yourself
[01:30:03.460 --> 01:30:06.500]   and you're not putting yourself in physical risk there's even a sort of
[01:30:06.500 --> 01:30:10.100]   group of sex workers who combine into a database of
[01:30:10.100 --> 01:30:13.940]   bad people who they know are weirdos and can be blocked based on their email
[01:30:13.940 --> 01:30:18.180]   address so i mean this this does undoubtedly make people safer
[01:30:18.180 --> 01:30:22.660]   uh if you're a secretary is going online and it becomes less if
[01:30:22.660 --> 01:30:24.980]   if they're not on craigslist the whole thing it becomes
[01:30:24.980 --> 01:30:29.220]   more shadowy right harder to find the people who do need to be in trouble
[01:30:29.220 --> 01:30:31.780]   for what they're doing that's an interesting point Alex Levy is a
[01:30:31.780 --> 01:30:35.700]   professor at Notre Dame he's quoted in gizmodo he teaches
[01:30:35.700 --> 01:30:40.500]   he i mean this guy's teaches a class in human trafficking and human markets
[01:30:40.500 --> 01:30:45.860]   he wrote the war on internet platforms is pageantry a kind of theater designed
[01:30:45.860 --> 01:30:50.740]   to satisfy people's need to identify and fight bad guys without regard
[01:30:50.740 --> 01:30:55.940]   to nuance or long-term outcome but from a tactical standpoint
[01:30:55.940 --> 01:30:58.980]   it's more than a distraction censoring these platforms
[01:30:58.980 --> 01:31:03.380]   means forfeiting a resource that naturally facilitates the recovery
[01:31:03.380 --> 01:31:08.340]   of victims section 230 doesn't cause lawlessness
[01:31:08.340 --> 01:31:11.540]   it creates a space in which many things including lawless behavior
[01:31:11.540 --> 01:31:16.100]   come to light and it's in that light that multitudes of organizations and people
[01:31:16.100 --> 01:31:19.380]   have taken proactive steps to usher victims to save the
[01:31:19.380 --> 01:31:23.460]   and apprehend their abusers it pushes that into the shadows
[01:31:23.460 --> 01:31:26.100]   star well they're going to the dark web now and there's no
[01:31:26.100 --> 01:31:29.860]   and there's no way to track them if they're actually on this on on craigslist or
[01:31:29.860 --> 01:31:33.540]   on other or on other open sites that would give the police and wealth
[01:31:33.540 --> 01:31:35.860]   information as to how to track these people down
[01:31:35.860 --> 01:31:41.140]   and it's just made the situation worse so it's bad for dangerous for sex workers
[01:31:41.140 --> 01:31:45.780]   it pushes bad behavior out of the light pushes victims
[01:31:45.780 --> 01:31:50.660]   out of the light it has a chilling effect on legitimate enterprises like craigslist
[01:31:50.660 --> 01:31:53.540]   and reddit so clearly it's a bad law
[01:31:53.540 --> 01:31:57.220]   now right and it's a harbinger of maybe bad law to come
[01:31:57.220 --> 01:32:00.660]   because section 230 has been really unpopular
[01:32:00.660 --> 01:32:06.260]   among our current lawmakers and prosecutors because they don't like the
[01:32:06.260 --> 01:32:09.860]   fact that it protects them against what they think is
[01:32:09.860 --> 01:32:14.660]   defanatory speech yes exactly uh side you know all manner
[01:32:14.660 --> 01:32:22.020]   of um bad things can go on between people under section 230 and have a site like
[01:32:22.020 --> 01:32:26.980]   facebook or google b or smaller sites be protected
[01:32:26.980 --> 01:32:30.020]   as long as it's not a federal crime or ip infringement
[01:32:30.020 --> 01:32:36.420]   uh so defamation would be one thing uh so this could be used to to chill speech
[01:32:36.420 --> 01:32:39.460]   definitely oh yeah first they came for the sex traffickers and i said nothing
[01:32:39.460 --> 01:32:42.180]   for i was not a sex trafficker i mean it's just
[01:32:42.180 --> 01:32:45.620]   i don't think that was the intent of no no but anyway i get the point
[01:32:45.620 --> 01:32:49.140]   it's very interesting that they've used exactly the same excuse in various
[01:32:49.140 --> 01:32:54.100]   states state to introduce laws where uh tech companies are mandated
[01:32:54.100 --> 01:32:57.860]   porn filters onto their devices and if you want it taken out you have to pay a
[01:32:57.860 --> 01:33:02.020]   $20 fee per year and it's like five Australia does this
[01:33:02.020 --> 01:33:04.980]   yeah there's like five or six states in the u.s have just introduced laws
[01:33:04.980 --> 01:33:08.980]   it's terrible it's all every single one of them has used the same excuse
[01:33:08.980 --> 01:33:12.900]   it's to combat sex traffickers right and this seems to be the excuse to do and
[01:33:12.900 --> 01:33:16.100]   i'm wondering who's coming up with this well child abuse is working for a while
[01:33:16.100 --> 01:33:19.300]   but now we've got another one so we got yeah but but i also
[01:33:19.300 --> 01:33:22.580]   okay i'm going to argue on on their on their side here
[01:33:22.580 --> 01:33:28.340]   on the other hand i mean we need tools to fight sex trafficking and child abuse
[01:33:28.340 --> 01:33:33.220]   and you've got to give us credit we're not going to over step our bounds here
[01:33:33.220 --> 01:33:38.580]   because i mean there well okay i couldn't even say it with a straight face
[01:33:38.580 --> 01:33:42.660]   so so everybody has said the courts will weigh in on this Denise will the courts
[01:33:42.660 --> 01:33:47.540]   protect section 230 uh yes they might there might be
[01:33:47.540 --> 01:33:51.860]   parts of this that are uh again deemed unconstitutional or beyond
[01:33:51.860 --> 01:33:56.900]   congress's scope of authority in one way or another and again eff and others
[01:33:56.900 --> 01:34:06.180]   will probably be leading the charge on on picking at uh the viability of this
[01:34:06.180 --> 01:34:09.300]   law and the cloud act and in both instances right it's like we're just
[01:34:09.300 --> 01:34:16.580]   gonna grant ourselves this authority in service of a noble goal and and as you
[01:34:16.580 --> 01:34:22.900]   say leo there's sort of this tacit uh implication we would never abuse that
[01:34:22.900 --> 01:34:29.140]   authority but it's really broad authority well as so uh now we just hope that the
[01:34:29.140 --> 01:34:31.940]   court that there will certainly be actions although it's interesting
[01:34:31.940 --> 01:34:35.700]   that craigslist didn't fight it they just said yeah okay fine
[01:34:35.700 --> 01:34:38.580]   well i think they were making a stand more than oh you think so i think yes
[01:34:38.580 --> 01:34:40.100]   but i'm sure they make a lot of money on those
[01:34:40.100 --> 01:34:42.660]   personals right uh and that's part of their business
[01:34:42.660 --> 01:34:46.900]   uh so they're free they're free so that's why craigslist is a job listings
[01:34:46.900 --> 01:34:50.100]   they make money from them okay and craigslist is also an itty bitty
[01:34:50.100 --> 01:34:53.860]   company without the resources to police this stuff in the way that
[01:34:53.860 --> 01:34:57.540]   the large ones might they're not they can't hire 10 000 people like
[01:34:57.540 --> 01:35:00.100]   facebook right but i mean also i mean look at the
[01:35:00.100 --> 01:35:03.380]   mad sex workers are on tinder and bumble and that sort of thing that's
[01:35:03.380 --> 01:35:06.740]   gonna come that's gonna have to come come into play it so in sooner or later
[01:35:06.740 --> 01:35:09.860]   they've got to be aware of this we've been contacted for comment on it since
[01:35:09.860 --> 01:35:12.660]   this came up and they're being very very quiet about it
[01:35:12.660 --> 01:35:15.380]   but i suspect their legal department is quietly having kittens over the
[01:35:15.380 --> 01:35:19.220]   prospect of being sued so i think the other thing we
[01:35:19.220 --> 01:35:22.740]   probably should point out is it probably won't do anything to fight sex
[01:35:22.740 --> 01:35:27.380]   traffic because that honestly that's not going to have that
[01:35:27.380 --> 01:35:30.980]   effect do you think that there were cynically the lawmakers were cynically
[01:35:30.980 --> 01:35:34.100]   saying well what we really want is a bill they'll keep those people from saying
[01:35:34.100 --> 01:35:38.180]   bad things about us and we'll just guy put it in the guise of sex
[01:35:38.180 --> 01:35:41.460]   trafficking i i wouldn't go that far but i do think
[01:35:41.460 --> 01:35:44.340]   only two senators voted against this bill it was a 90
[01:35:44.340 --> 01:35:49.940]   seven to vote i couldn't believe it with rann paul and ron wyden being the only
[01:35:49.940 --> 01:35:54.500]   two no votes i just think it's really hard for a senator to say yeah i voted
[01:35:54.500 --> 01:35:57.540]   against this bill that was designed to curb sex
[01:35:57.540 --> 01:36:01.860]   trafficking how do you go back to your constituents justify that
[01:36:01.860 --> 01:36:04.660]   unless you're good at explaining why
[01:36:04.660 --> 01:36:09.300]   and you know who who really is that good or wants to take that time
[01:36:09.300 --> 01:36:13.140]   i mean i think that's why that that's why the bill was named in its way so that
[01:36:13.140 --> 01:36:15.540]   you know it's somebody trying to get it through could say
[01:36:15.540 --> 01:36:18.660]   well you know you want to go back to your constituents and say now i've voted
[01:36:18.660 --> 01:36:22.980]   against a law that would you know would would go against sex traffickers
[01:36:22.980 --> 01:36:27.780]   i mean it's blatantly cynical um i think to be honest most of them
[01:36:27.780 --> 01:36:31.700]   if congress if if we've seen anything from congress's level of text having us
[01:36:31.700 --> 01:36:34.580]   most of them probably didn't really realize the implications of what they
[01:36:34.580 --> 01:36:37.860]   are voting for but that seems to be very much the run of course in congress
[01:36:37.860 --> 01:36:41.300]   these days and rann wyden there's one guy who kind of knows what he's doing when
[01:36:41.300 --> 01:36:44.340]   it comes to talk and and rann paul is a guy who's
[01:36:44.340 --> 01:36:47.540]   very comfortable with going the other way doesn't mind
[01:36:47.540 --> 01:36:51.060]   uh i think there is and it really this is this is you can
[01:36:51.060 --> 01:36:54.740]   attribute a lot of uh what's going on in congress right now
[01:36:54.740 --> 01:36:59.620]   to the power of these attack ads that that that members of congress know they're
[01:36:59.620 --> 01:37:02.260]   gonna go home they're gonna face opponents in their primary who are
[01:37:02.260 --> 01:37:06.820]   gonna run attack ads that say senator such is in favor of sex trafficking
[01:37:06.820 --> 01:37:11.540]   yeah and and that those will work and so it always comes down to frankly an
[01:37:11.540 --> 01:37:13.780]   electorate that's willing to fall for that yeah
[01:37:13.780 --> 01:37:17.940]   yeah and and in service of your cynicism argument
[01:37:17.940 --> 01:37:21.860]   professor goldman from the university of san klera who knows more about section
[01:37:21.860 --> 01:37:24.740]   230 of the communications decency act and anyone except
[01:37:24.740 --> 01:37:28.820]   saving maybe rann wyden uh when it testified before
[01:37:28.820 --> 01:37:33.060]   the senate about this and so it's not like they weren't gathering information
[01:37:33.060 --> 01:37:37.380]   from people who did understand it and could explain it clearly to them why
[01:37:37.380 --> 01:37:39.860]   this was a bad idea
[01:37:39.860 --> 01:37:43.700]   yeah it's um it's one of those things it's you're not gonna have the chance to
[01:37:43.700 --> 01:37:47.220]   explain it there's gonna be a attack ad with a big
[01:37:47.220 --> 01:37:52.660]   black screen that says senator wyden's in favor of sex trafficking you
[01:37:52.660 --> 01:37:55.460]   the and then that's that you don't have a chance to
[01:37:55.460 --> 01:37:58.820]   explain it with an ugly black and white photograph of him looking at
[01:37:58.820 --> 01:38:03.380]   looking shattered by the white and why he likes sex trafficking so much
[01:38:03.380 --> 01:38:06.420]   maybe a hand with a pair of handcuffs is putting money into his back pocket
[01:38:06.420 --> 01:38:09.860]   you know you know how these things work they're tasteless as all hell and it
[01:38:09.860 --> 01:38:13.700]   just uh it's again it comes back to the the
[01:38:13.700 --> 01:38:18.180]   dumbing down of politics um yeah ultimately it's our responsibility
[01:38:18.180 --> 01:38:21.220]   we're the electorate we got we got it it's happening in every country you
[01:38:21.220 --> 01:38:24.660]   know it's it's it's how Brexit happened yeah
[01:38:24.660 --> 01:38:27.220]   and we know that you know i've right came on the show that
[01:38:27.220 --> 01:38:30.580]   but i know we came up to the up up i'm down after Brexit and i predicted
[01:38:30.580 --> 01:38:34.260]   Trump would win and it was just did you really yeah blank that part out
[01:38:34.260 --> 01:38:38.100]   yeah trust me i was yeah i was having a discussion sitting there in
[01:38:38.100 --> 01:38:40.820]   November 8 saying all that he and Thompson what does he know
[01:38:40.820 --> 01:38:44.660]   what does he know hey i won a bottle of scotch based on that but did you
[01:38:44.660 --> 01:38:48.500]   really yeah it turns out needed to drink it that night but you know
[01:38:48.500 --> 01:38:51.460]   you're not the first bridge to say that john oliver said that also he said
[01:38:51.460 --> 01:38:56.340]   after going through Brexit i had a feeling yeah it was something was
[01:38:56.340 --> 01:39:00.100]   something was up um and the old ruse don't seem to apply
[01:39:00.100 --> 01:39:04.420]   come on guys you got to start reading learning and yeah taking your job as
[01:39:04.420 --> 01:39:09.700]   electors seriously yeah voter being the voters an important thing to do
[01:39:09.700 --> 01:39:13.300]   i was in london the morning after the vote i've never seen so many shell
[01:39:13.300 --> 01:39:15.940]   shocked people yeah really it was that same thing
[01:39:15.940 --> 01:39:20.580]   oh god i know even amongst the winners though when boris johnson got he came
[01:39:20.580 --> 01:39:24.100]   out he couldn't believe he came out of his house and saw the assembled press
[01:39:24.100 --> 01:39:26.180]   crew at eight o'clock in the morning after the vote
[01:39:26.180 --> 01:39:31.380]   i just had this look on his face of his what have i done you know
[01:39:31.380 --> 01:39:36.340]   it's gonna happen yeah that's um i mean that was the plus side of
[01:39:36.340 --> 01:39:39.540]   trump getting elected though because for three months all my friends over here
[01:39:39.540 --> 01:39:42.580]   were just like ah you see you can screw things up too
[01:39:42.580 --> 01:39:46.660]   america said hold my beer watch this
[01:39:46.660 --> 01:39:55.780]   wow what a world what a world uh let's take a little break uh on that note
[01:39:55.780 --> 01:39:59.460]   Denise i want to talk about food this will make me feel better Denise did you
[01:39:59.460 --> 01:40:02.900]   do blow apron i think you did yeah yeah isn't it great i love it yeah it's
[01:40:02.900 --> 01:40:06.340]   still subscribe yeah we get it we have blue apron in our fridge i might
[01:40:06.340 --> 01:40:08.660]   go home tonight i can't remember what it is but it's
[01:40:08.660 --> 01:40:12.020]   guaranteed to be something delicious blue apron is the number one
[01:40:12.020 --> 01:40:15.540]   fresh ingredient recipe delivery service in the country
[01:40:15.540 --> 01:40:19.060]   here's how it works you go to blue apron dot com slash twit by the way if you do
[01:40:19.060 --> 01:40:22.180]   that you're gonna get thirty dollars off your first order and free shipping
[01:40:22.180 --> 01:40:25.860]   blue apron dot com slash twit take a look at what's on the menu they have
[01:40:25.860 --> 01:40:30.820]   lots of different items you pick well two three or four recipes depending on
[01:40:30.820 --> 01:40:34.500]   what you want what fits your schedule there's 12 to pick from
[01:40:34.500 --> 01:40:38.420]   things like uh quick buccatini with broccoli and pecorino cheese i want
[01:40:38.420 --> 01:40:43.060]   that now right now pan fried chicken breast with sweet and tangy zucchini
[01:40:43.060 --> 01:40:49.140]   Italian style shrimp and sweet peppers over fragula sarda pasta
[01:40:49.140 --> 01:40:52.500]   parmesan crusted steaks with mashed potatoes and broccoli you choose the
[01:40:52.500 --> 01:40:57.060]   one you want they have two plans one for a couple one for a family of four
[01:40:57.060 --> 01:41:00.740]   the family of four version has kind of more kid-friendly ingredients by the way
[01:41:00.740 --> 01:41:04.580]   what you're not going to get is a pre-cooked meal that you steam
[01:41:04.580 --> 01:41:08.580]   or you microwave you're going to get exactly the ingredients fresh
[01:41:08.580 --> 01:41:12.660]   beautiful they picked produce better than anybody it's going to be beautiful
[01:41:12.660 --> 01:41:16.340]   everything you need right down to the clove of garlic the rib of celery
[01:41:16.340 --> 01:41:20.340]   the little tiny bottle of soy sauce whatever it is it's in the recipe
[01:41:20.340 --> 01:41:23.860]   and then you cook it and kids love this you go oh we got everything let's cook
[01:41:23.860 --> 01:41:27.620]   and it takes you just you know 45 minutes the house fills with these
[01:41:27.620 --> 01:41:32.500]   amazing beautiful sense of things like ginger they i noticed a blue
[01:41:32.500 --> 01:41:35.860]   apron i think they do this on purpose has beautiful aromatic
[01:41:35.860 --> 01:41:39.700]   ingredients that really make your nose go i can't do dinners
[01:41:39.700 --> 01:41:44.900]   dinners coming it's they're so good kids get excited about it
[01:41:44.900 --> 01:41:48.900]   and you know i have to say it's so easy we live such busy lives are so
[01:41:48.900 --> 01:41:52.740]   swamped i think a lot of times you go home you get something to go
[01:41:52.740 --> 01:41:56.260]   or you have to go to the fast food look with blue apron you're not just
[01:41:56.260 --> 01:41:59.380]   having burgers for dinner you're making short rib burgers with a hoppy
[01:41:59.380 --> 01:42:04.260]   cheddar sauce on a pretzel bun or seared steaks and thyme pan sauce with
[01:42:04.260 --> 01:42:09.460]   mashed potatoes green beans and crispy shallots oh my god
[01:42:09.460 --> 01:42:13.460]   blue apron look at you got to try this incredible ingredients chef-designed
[01:42:13.460 --> 01:42:18.100]   recipes always something new fresh ingredients
[01:42:18.100 --> 01:42:22.020]   a meal you make yourself from scratch and by the way once you do it i don't know
[01:42:22.020 --> 01:42:24.980]   if this is your experience today's ai learning about new you probably know
[01:42:24.980 --> 01:42:27.380]   all these ingredients but i didn't know really no they
[01:42:27.380 --> 01:42:30.500]   do they throw in some really cool sort of very
[01:42:30.500 --> 01:42:35.060]   great culture yeah ingredients sarda what is that
[01:42:35.060 --> 01:42:38.820]   so then i know how to do it and i tend to make these recipes because i was
[01:42:38.820 --> 01:42:41.220]   getting a little stale i was getting a little bit of a rut making the same
[01:42:41.220 --> 01:42:44.820]   thing over and over now i have a much bigger repertoire really is fun
[01:42:44.820 --> 01:42:48.020]   i love it for kids their recipes are really easy to follow sometimes i'll
[01:42:48.020 --> 01:42:51.460]   just say hey you're making dinner really and does he do it yeah here you go
[01:42:51.460 --> 01:42:55.860]   yeah the easier ones the pasta ones sure why not it's awesome blue apron
[01:42:55.860 --> 01:42:58.900]   is giving you 30 dollars off your first order and free shipping go to blue
[01:42:58.900 --> 01:43:03.540]   apron.com/twit blue if you haven't done this do it check out this week's menu
[01:43:03.540 --> 01:43:09.940]   and get 30 dollars off with free shipping blue apron.com/twit blue apron is
[01:43:09.940 --> 01:43:16.260]   a better way to cook all right uber so i you know when when
[01:43:16.260 --> 01:43:20.820]   Lisa told me about this uh uber car a very sad story tepiara zoneo uber
[01:43:20.820 --> 01:43:23.860]   self-driving vehicle with a safety driver at the helm
[01:43:23.860 --> 01:43:29.220]   but in autonomous mode 10 p.m uh almost pedestrian on a
[01:43:29.220 --> 01:43:33.460]   walking her bicycle steps out into a four lane and and they have these in
[01:43:33.460 --> 01:43:36.820]   arizona really these are city streets but they're four lanes the cars are
[01:43:36.820 --> 01:43:41.140]   whizzing down steps out and and gets hit and
[01:43:41.140 --> 01:43:44.100]   killed very sad uh she had her bicycle and she had
[01:43:44.100 --> 01:43:46.260]   bags on the bicycle she gets hit and killed
[01:43:46.260 --> 01:43:51.220]   uh but my first reaction was oh well clearly the pedestrian
[01:43:51.220 --> 01:43:54.660]   walked out from between a car or was in some way invisible because no
[01:43:54.660 --> 01:44:01.140]   my even my even my car not in autonomous mode would see and jam on the brakes
[01:44:01.140 --> 01:44:04.580]   if something like that happened because almost all cars now have collision
[01:44:04.580 --> 01:44:07.060]   avoidance and they would they would jam on the brakes something would there
[01:44:07.060 --> 01:44:10.900]   was no evidence that the brakes would slow down the the
[01:44:10.900 --> 01:44:13.940]   safety driver said i didn't see anything till the crash happened
[01:44:13.940 --> 01:44:18.740]   then we saw the video and the tempi police initially said yeah this is
[01:44:18.740 --> 01:44:21.780]   unavoidable there's no way anybody could avoid this
[01:44:21.780 --> 01:44:26.020]   but as you saw uh sam uh well samide and others
[01:44:26.020 --> 01:44:29.220]   brad templeton who i highly respect is a big advocate
[01:44:29.220 --> 01:44:32.020]   of autonomous vehicles he's talked about the how this is going to change the
[01:44:32.020 --> 01:44:36.100]   world and it's a great thing he said he was skeptical sam was skeptical
[01:44:36.100 --> 01:44:39.220]   said we looked at the video few things came to mind
[01:44:39.220 --> 01:44:42.500]   first of all maybe the least important that the car was traveling five miles
[01:44:42.500 --> 01:44:45.380]   above the speed limit now we all do that uh but that's
[01:44:45.380 --> 01:44:49.460]   that should be altered now it wasn't a 45 mile narrow road and it was going 40
[01:44:49.460 --> 01:44:53.460]   oh it was going slower than so it was okay slow as it should in the dark with
[01:44:53.460 --> 01:44:56.980]   visibility's bad exactly that's one thing a self-driving vehicle should do
[01:44:56.980 --> 01:45:01.060]   this the safety driver in the video was not watching no she was looking down
[01:45:01.060 --> 01:45:05.380]   at her phone and uh so she couldn't see it yeah yeah
[01:45:05.380 --> 01:45:08.660]   but and this is what brad pointed out and this is a big deal
[01:45:08.660 --> 01:45:14.740]   you can clearly see in the video five seconds before the car strikes the
[01:45:14.740 --> 01:45:18.020]   pedestrian the pedestrian lights off the pedestrian
[01:45:18.020 --> 01:45:22.260]   sneakers he said a lidar system can see in the dark
[01:45:22.260 --> 01:45:27.540]   it should have seen this this is clearly a failure
[01:45:27.540 --> 01:45:31.460]   of uber's autonomous vehicle and i have to say i agree uh now
[01:45:31.460 --> 01:45:37.220]   seeing more of this because even my tesla not in auto driving mode in many
[01:45:37.220 --> 01:45:40.900]   modern cars would have at least braced yeah
[01:45:40.900 --> 01:45:45.540]   if it had five seconds and this is the thing this is autonomous vehicles are
[01:45:45.540 --> 01:45:49.780]   being sold on us sold to us as this will make life so much simpler
[01:45:49.780 --> 01:45:53.540]   safer and will have less traffic and in fact the reasons people are struggling
[01:45:53.540 --> 01:45:56.660]   and the reason uber is rushing to develop this technology is because its
[01:45:56.660 --> 01:45:58.900]   business model doesn't make sense without it
[01:45:58.900 --> 01:46:02.820]   um so i think this kind of gives lie to the whole autonomous driving is going
[01:46:02.820 --> 01:46:06.820]   to be safer because these cars have done a pathetic amount of time on the roads
[01:46:06.820 --> 01:46:12.100]   and they're already killing people and or at least somebody has died in it
[01:46:12.100 --> 01:46:16.020]   so i don't think the technology could have worked i mean most lidar systems
[01:46:16.020 --> 01:46:19.380]   would have picked that up there is some we will know because the national
[01:46:19.380 --> 01:46:22.660]   transportation safety board is investigating the
[01:46:22.660 --> 01:46:26.180]   tampi police have now referred it for criminal investigation so they're
[01:46:26.180 --> 01:46:29.380]   obviously taking this more seriously family members of the
[01:46:29.380 --> 01:46:32.500]   pedestrian have now retained council and i expected to sue
[01:46:32.500 --> 01:46:36.100]   so there this will come out and at least one thing about autonomous vehicles
[01:46:36.100 --> 01:46:39.620]   there's lots of recording but one thing Brad speculated maybe the
[01:46:39.620 --> 01:46:44.180]   lidar was turned off it's not unusual in testing
[01:46:44.180 --> 01:46:50.020]   for lidar to be turned off in testing and what he said is this not appropriate
[01:46:50.020 --> 01:46:54.340]   maybe it should be the input of the lidar should be somehow disabled
[01:46:54.340 --> 01:47:01.700]   um that's bizarre and maybe uber has less of a of a record
[01:47:01.700 --> 01:47:04.660]   for all of this according to the new york times
[01:47:04.660 --> 01:47:07.860]   wemo the self-driving car at project of google
[01:47:07.860 --> 01:47:11.380]   its cars went on average of fifty six hundred miles before the driver had to
[01:47:11.380 --> 01:47:15.940]   take control the safety driver as of march uber was struggling to make its
[01:47:15.940 --> 01:47:21.220]   target of thirteen miles yeah fifty six hundred for
[01:47:21.220 --> 01:47:26.900]   wemo thirteen for google well because there's been very careful about this
[01:47:26.900 --> 01:47:30.660]   they've heard yeah i was the figure for humans
[01:47:30.660 --> 01:47:34.260]   without that's well yeah i mean of course and one of the things i worry
[01:47:34.260 --> 01:47:38.500]   about i don't want autonomous vehicles to be slammed in appropriately i mean
[01:47:38.500 --> 01:47:42.420]   at some point people this is going to happen because there are unavoidable
[01:47:42.420 --> 01:47:47.540]   circumstances even a very fast autonomous system can't stop a car
[01:47:47.540 --> 01:47:52.820]   in zero feet because it's physics but so and we know autonomous vehicles will
[01:47:52.820 --> 01:47:55.940]   ultimately save lives but if there is any evidence
[01:47:55.940 --> 01:47:59.460]   that uber and who wouldn't be surprised to find this out
[01:47:59.460 --> 01:48:04.500]   did not do everything right then i mean there are there a highly
[01:48:04.500 --> 01:48:06.660]   reputable company who've never played fast and
[01:48:06.660 --> 01:48:09.780]   flus with the rules at all we are i don't know what you're hinting at
[01:48:09.780 --> 01:48:13.460]   uber has halted its autonomous vehicles testing obviously
[01:48:13.460 --> 01:48:17.140]   yeah but it's interesting that under our under california law
[01:48:17.140 --> 01:48:20.980]   all the self-driving car companies who have their cars on the roads
[01:48:20.980 --> 01:48:24.100]   have to file a report if there's any kind of accident
[01:48:24.100 --> 01:48:26.740]   uh now under the arizona law they don't have to do that
[01:48:26.740 --> 01:48:30.260]   yeah arizona really wanted this to happen yeah that's one of the reasons why
[01:48:30.260 --> 01:48:33.300]   they're testing arizona because that's a little bit more lucy-goosey
[01:48:33.300 --> 01:48:38.180]   yeah i mean there's i i'm working on a piece of i can't say too much about it
[01:48:38.180 --> 01:48:40.980]   but there are other self-driving car companies who are
[01:48:40.980 --> 01:48:43.380]   going to be falling out of the foul of this as well
[01:48:43.380 --> 01:48:46.660]   i mean it was always going to happen that an autonomous vehicle kills somebody i
[01:48:46.660 --> 01:48:51.060]   mean it's it's the way of it you know was it 30 000 people get killed in cars
[01:48:51.060 --> 01:48:54.980]   every year in the u.s so if you could take half if autonomous vehicles only
[01:48:54.980 --> 01:48:59.220]   killed 15 000 people a year that'd be a plus but it would sure look bad
[01:48:59.220 --> 01:49:02.260]   but again i think there were people at way mohoo just like
[01:49:02.260 --> 01:49:05.380]   we dodged a bullet it wasn't us that did the first one maybe you know
[01:49:05.380 --> 01:49:09.380]   right and and the way in which uber may have dodged a bullet here is
[01:49:09.380 --> 01:49:13.380]   is there seems to have been some sort of fault on the part of
[01:49:13.380 --> 01:49:17.300]   elaine hertzberg um who was tragically killed here but
[01:49:17.300 --> 01:49:20.580]   when you watch the video she does seem to have you know
[01:49:20.580 --> 01:49:24.660]   she's not the crosswalk it's a dark night she's walking into the middle of
[01:49:24.660 --> 01:49:28.180]   four lanes of traffic at a 45 mile an hour zone
[01:49:28.180 --> 01:49:34.260]   you know that's not the best behavior and yet uh it seems to me now
[01:49:34.260 --> 01:49:38.180]   uh apparently many experts in this that this is the kind of thing in a ton of
[01:49:38.180 --> 01:49:40.420]   vehicles that just should not happen to us in that
[01:49:40.420 --> 01:49:43.060]   case but most accidents involve edge cases
[01:49:43.060 --> 01:49:45.860]   girl edge cases i mean i got him at the first time i saw that video i thought
[01:49:45.860 --> 01:49:49.460]   you know if i'd have been driving i probably would have hit her too
[01:49:49.460 --> 01:49:52.340]   right um but you're supposed to have all this
[01:49:52.340 --> 01:49:55.620]   whizbang technology which is going to make you know save people lives on the
[01:49:55.620 --> 01:49:59.140]   road and as brad pointed out uh she was carrying a big
[01:49:59.140 --> 01:50:02.740]   metal if you lighten up the the picture so that you can actually see what's
[01:50:02.740 --> 01:50:06.100]   going on it he says his line is it certainly looks
[01:50:06.100 --> 01:50:13.140]   bad for uber they they had five seconds yeah uh it's kind of hard to see because
[01:50:13.140 --> 01:50:18.500]   it's a dim video but they had time and they should have seen it
[01:50:18.500 --> 01:50:22.900]   that lydar should have seen it um and so
[01:50:22.900 --> 01:50:26.980]   well there's big questions but what's and it seems to open up questions about
[01:50:26.980 --> 01:50:31.220]   what the safety driver should be doing not looking at her phone if in fact
[01:50:31.220 --> 01:50:34.740]   safety is why they're in there you know i white knuckle it when my
[01:50:34.740 --> 01:50:38.500]   when i tesla which you know it has autopilot is not autonomous it has
[01:50:38.500 --> 01:50:41.860]   autopilot it's just a fancy cruise control but i got my hands on the wheel
[01:50:41.860 --> 01:50:44.420]   tesla makes you keep your hands on the wheel i pay attention
[01:50:44.420 --> 01:50:47.540]   because one of the problems is when you're letting a car drive is you're not
[01:50:47.540 --> 01:50:51.380]   paying attention it takes you a few seconds just to figure out what's going
[01:50:51.380 --> 01:50:57.380]   on yeah not enough time to stop the vehicle so you need to be watching
[01:50:57.380 --> 01:51:00.500]   no this is it i mean if you got this is kind of what freaked people out when
[01:51:00.500 --> 01:51:02.980]   google started testing their driverless cars with no
[01:51:02.980 --> 01:51:06.980]   no pedals or steering wheels uh and that's been kind of sort of scaled
[01:51:06.980 --> 01:51:10.100]   back a bit but yeah if you're going to have a safety driver in that
[01:51:10.100 --> 01:51:12.900]   they've got to be doing their job and making sure that it's as safe as it
[01:51:12.900 --> 01:51:16.100]   can be and that means sitting there with your hands on the wheel and with your
[01:51:16.100 --> 01:51:21.300]   feet near or on the pedals and i have to say there's no reason why a car
[01:51:21.300 --> 01:51:26.180]   should not be driving a little slower than a car with a human at the wheel
[01:51:26.180 --> 01:51:30.260]   i can be i can get there 30 seconds later uh
[01:51:30.260 --> 01:51:33.940]   the uber brad says the uber was traveling at what he calls
[01:51:33.940 --> 01:51:37.940]   the upper range of speeds at which it's safe to drive non-free way with just the
[01:51:37.940 --> 01:51:41.380]   lighter he calls it the valley of danger uber knows it
[01:51:41.380 --> 01:51:45.620]   it's about as fast as you should go you can do it even so some cars like to go a
[01:51:45.620 --> 01:51:48.820]   bit slower approaching crosswalks marked or not
[01:51:48.820 --> 01:51:51.460]   using the light are their perception system should have a pretty good
[01:51:51.460 --> 01:51:56.020]   impression of her by 50 meters 2.7 seconds and by then it should have at
[01:51:56.020 --> 01:52:00.740]   least hit the brakes it didn't yeah right so there's something going on
[01:52:00.740 --> 01:52:04.660]   there's more to this he says uber needs to say why this did not
[01:52:04.660 --> 01:52:08.820]   happen was the light are turned off i do feel for the new
[01:52:08.820 --> 01:52:12.100]   ceo but because he's being faced with endless
[01:52:12.100 --> 01:52:16.020]   yeah with with three or four big big things of car yeah before you actually
[01:52:16.020 --> 01:52:20.740]   got here we kind of did this thing and it's it's a wee bit on the illegal side
[01:52:20.740 --> 01:52:23.780]   or so we bit on the distasteful side and by all i can't deal with it now
[01:52:23.780 --> 01:52:27.780]   darakos for costra shahi is a really good guy no no solid boat yeah
[01:52:27.780 --> 01:52:31.300]   and uh in fact according to the new york times he considered killing the self
[01:52:31.300 --> 01:52:36.100]   driving program at uber when he became ceo and was convinced not to because
[01:52:36.100 --> 01:52:39.700]   frankly it's the only way uber makes any sense at all
[01:52:39.700 --> 01:52:42.820]   is if they if they don't have to pay drivers because otherwise
[01:52:42.820 --> 01:52:45.460]   there's no way to make work this business model doesn't work
[01:52:45.460 --> 01:52:48.420]   it's you know at the moment i think it's something like 40 percent of the cost
[01:52:48.420 --> 01:52:50.980]   of an uber ride is covered by the venture capitalist who's funding the
[01:52:50.980 --> 01:52:53.700]   company yeah and you can't burn through cash like that
[01:52:53.700 --> 01:52:57.540]   forever yeah so they're desperate to make self-driving cars work and that
[01:52:57.540 --> 01:53:02.020]   does kind of give an uber's record beg the question as to whether or not they
[01:53:02.020 --> 01:53:04.900]   cut corners at just the wrong time you've talked a lot about this and i know
[01:53:04.900 --> 01:53:07.620]   this we can law and the issues of self-driving vehicles who's
[01:53:07.620 --> 01:53:11.700]   responsible if an accident happens is there a consensus or do we
[01:53:11.700 --> 01:53:14.980]   understand this well enough or is it still in flux i think it's still in
[01:53:14.980 --> 01:53:18.260]   flux and i think this case is a really good example of how our
[01:53:18.260 --> 01:53:21.700]   negligence laws i've always kind of thought oh it might change everything
[01:53:21.700 --> 01:53:25.940]   that it's a self-driving car but i think our negligence laws as they exist
[01:53:25.940 --> 01:53:30.500]   today are probably very well capable of handling
[01:53:30.500 --> 01:53:35.060]   this kind of incident uh arizona is a comparative fault state
[01:53:35.060 --> 01:53:40.020]   so if this case were to be tried the lawyers who represent uh miss
[01:53:40.020 --> 01:53:43.860]   hurtsburg have said they expect it to settle but if this case were to be
[01:53:43.860 --> 01:53:47.300]   tried uh there would be evidence put in about the
[01:53:47.300 --> 01:53:51.940]   degree of fault that she had for having stepped out at that particular place
[01:53:51.940 --> 01:53:57.140]   in time and there would be an extensive investigation just like there would be
[01:53:57.140 --> 01:54:02.660]   in any car accident uh as to the fault of the
[01:54:02.660 --> 01:54:09.300]   person or entity piloting the car um so i think that the evidence would look
[01:54:09.300 --> 01:54:14.260]   a little bit different but um the the liability equation would probably
[01:54:14.260 --> 01:54:17.060]   be something that our courts are used to dealing with
[01:54:17.060 --> 01:54:21.780]   is there any legal uh precedent or legal language covering self-driving
[01:54:21.780 --> 01:54:26.420]   vehicles at all i don't think that that the negligence law at all
[01:54:26.420 --> 01:54:29.700]   has has been you know and for robots driving a car
[01:54:29.700 --> 01:54:32.900]   like to accommodate so that oh you have you have higher
[01:54:32.900 --> 01:54:36.020]   responsibilities if you're test testing self-driving cars
[01:54:36.020 --> 01:54:39.620]   that might be something that states think about in in the wake of this and
[01:54:39.620 --> 01:54:43.700]   certainly if we had an example where it seemed like the victim was not at
[01:54:43.700 --> 01:54:47.700]   fault at all where they're crossing in a crosswalk at a green light and they
[01:54:47.700 --> 01:54:52.180]   get smacked into yeah that would be responsible in that
[01:54:52.180 --> 01:54:55.860]   case the the company operating the vehicle
[01:54:55.860 --> 01:55:00.420]   i i would think so yeah if there if there's no fault at all on the part of the
[01:55:00.420 --> 01:55:04.500]   pedestrian um a test driver i mean the safety
[01:55:04.500 --> 01:55:07.780]   driver does that does that person have any the safety driver is
[01:55:07.780 --> 01:55:13.140]   is protected i think by the uh there the virtue of there being an employee but
[01:55:13.140 --> 01:55:16.180]   if they're doing something they're not supposed to do
[01:55:16.180 --> 01:55:20.420]   right um it's like a train engineer right you know
[01:55:20.420 --> 01:55:24.260]   texting and then the train as an accident that engineer is liable i'm
[01:55:24.260 --> 01:55:28.100]   sorry right of course but they you know that engineer is not going to be able to
[01:55:28.100 --> 01:55:31.300]   pay very much right yeah so you know it's the
[01:55:31.300 --> 01:55:35.140]   it's the company who who is on the hook for whatever
[01:55:35.140 --> 01:55:39.780]   many more stories like this over the next 10 years i think this is going to be
[01:55:39.780 --> 01:55:41.940]   uh one of the areas where we're going to hear a lot
[01:55:41.940 --> 01:55:46.100]   yeah i mean the fact is the freeways are the roads and the roads are an
[01:55:46.100 --> 01:55:49.700]   inherently dangerous place yeah you're driving a ton and a half or two tons of
[01:55:49.700 --> 01:55:54.020]   metal at very high speeds with contact patches on a tire about yay big
[01:55:54.020 --> 01:55:58.100]   right and this stuff is going to happen and also just on a personal note
[01:55:58.100 --> 01:56:00.180]   freeway driving over here is terrifying for a
[01:56:00.180 --> 01:56:04.020]   rip because if you leave everybody's on the right i don't understand that what's
[01:56:04.020 --> 01:56:06.900]   going on so there's that but also if you leave a decent stopping distance in
[01:56:06.900 --> 01:56:09.220]   front of you with the car in front two people try and cram
[01:56:09.220 --> 01:56:13.700]   themselves in because i do that i really try to keep two seconds between me and
[01:56:13.700 --> 01:56:16.740]   the car in front of me and everybody else says that an opportunity
[01:56:16.740 --> 01:56:20.660]   exactly just jam in the middle but that's okay wow that used to be just an l.a.
[01:56:20.660 --> 01:56:25.300]   thing now it's a northern california yeah is you trying new jersey i mean i don't
[01:56:25.300 --> 01:56:28.660]   even drive on new jersey roads anymore or sorry boston where i learned to drive
[01:56:28.660 --> 01:56:31.380]   oh good grief you must have nerves of steel
[01:56:31.380 --> 01:56:38.180]   now i'm a terrible driver and obnoxious how is it in phoenix matt people see if
[01:56:38.180 --> 01:56:41.780]   in arizona they have lots of space and the roads are wide and there's
[01:56:41.780 --> 01:56:45.540]   usually not that much traffic on the roads in fact this is a perfect place to
[01:56:45.540 --> 01:56:49.700]   test self-driving vehicles i would think if people would just stop walking in the
[01:56:49.700 --> 01:56:52.420]   middle of the road
[01:56:52.420 --> 01:56:55.540]   i need to make light of this because it's a tragedy
[01:56:55.540 --> 01:56:58.740]   it's a huge tragedy it is a human tragedy but just
[01:56:58.740 --> 01:57:03.140]   harkening back to what Ian said earlier about the uk and the united states being
[01:57:03.140 --> 01:57:08.100]   in a game of hold my beer i will comment that ashley vance who
[01:57:08.100 --> 01:57:13.380]   wrote the book on elan musk tweeted on march 19th this hold my beer game that
[01:57:13.380 --> 01:57:17.700]   facebook and uber are playing is next level oh yeah
[01:57:17.700 --> 01:57:21.540]   ashley's been great his twitter uh... food has been very high in the last
[01:57:21.540 --> 01:57:22.660]   mhm yes
[01:57:22.660 --> 01:57:24.980]   uh...
[01:57:24.980 --> 01:57:28.900]   travis calinik going wow i dodged that bullet he's got a new business
[01:57:28.900 --> 01:57:34.100]   they rehab real estate he's the ceo of a company formerly called cloud kitchens
[01:57:34.100 --> 01:57:37.940]   course travis has a little bit of money from the uber thing and so he
[01:57:37.940 --> 01:57:41.380]   has sunk a hundred fifty million dollars into it
[01:57:41.380 --> 01:57:42.900]   and uh...
[01:57:42.900 --> 01:57:45.540]   buys out all the other investors
[01:57:45.540 --> 01:57:49.980]   and i think he's renaming it to city storage systems
[01:57:49.980 --> 01:57:53.420]   which is not nearly as impressive as cloud kitchens
[01:57:53.420 --> 01:57:56.900]   but they've they focus on i don't even know what this means repurposing
[01:57:56.900 --> 01:58:00.340]   distressed real estate assets like parking lots
[01:58:00.340 --> 01:58:01.820]   or band and strip malls
[01:58:01.820 --> 01:58:05.180]   and turning them into spaces suited for new industries such as food delivery
[01:58:05.180 --> 01:58:07.020]   online retail
[01:58:07.020 --> 01:58:11.100]   property company you know it's just a little bit cash around this property
[01:58:11.100 --> 01:58:12.900]   that's who was a safe bet i guess
[01:58:12.900 --> 01:58:14.460]   doesn't sound terribly glamorous
[01:58:14.460 --> 01:58:19.140]   now you know maybe he's decided it could not to be so glamorous yeah maybe
[01:58:19.140 --> 01:58:20.780]   you know it's
[01:58:20.780 --> 01:58:23.900]   uh... you know how to involve sky dating
[01:58:23.900 --> 01:58:26.660]   there's a name we haven't heard a lot of a little bit of length mister
[01:58:26.660 --> 01:58:27.500]   earthlink
[01:58:27.500 --> 01:58:31.340]   ok he was the scientists who found it in rander thing for a long time i guess
[01:58:31.340 --> 01:58:32.140]   he's
[01:58:32.140 --> 01:58:34.260]   got these is an investor now
[01:58:34.260 --> 01:58:36.580]   he's a co-founder
[01:58:36.580 --> 01:58:40.140]   uh... i don't know i do so i just think that you know i think he was yeah
[01:58:40.140 --> 01:58:41.700]   wasn't he in my room was indeed
[01:58:41.700 --> 01:58:43.860]   yeah i could create
[01:58:43.860 --> 01:58:45.820]   his first name is a hint
[01:58:45.820 --> 01:58:47.380]   uh...
[01:58:47.380 --> 01:58:50.940]   is it sorry so i know these are the scientists are very powerful so z_n_u_
[01:58:50.940 --> 01:58:51.900]   be praised
[01:58:51.900 --> 01:58:54.220]   right in the press crazy new
[01:58:54.220 --> 01:58:56.500]   and give me a money yes
[01:58:56.500 --> 01:59:00.180]   arsho they brought to you by a zipper crooker if you're hiring you got a no
[01:59:00.180 --> 01:59:04.420]   bad zipper crooker they bring you the talent i love this idea we've talked
[01:59:04.420 --> 01:59:06.020]   about zipper crew before how
[01:59:06.020 --> 01:59:09.940]   you know one post on zipper crook goes to a hundred plus job sites
[01:59:09.940 --> 01:59:13.740]   plus social networks so more people see your application
[01:59:13.740 --> 01:59:14.940]   all those
[01:59:14.940 --> 01:59:18.260]   applicants don't go to your inbox or phone they go into the great zipper
[01:59:18.260 --> 01:59:21.100]   crew interface but i don't think we've emphasized enough
[01:59:21.100 --> 01:59:25.020]   the intelligence the platform that's in the pre-recorded brings
[01:59:25.020 --> 01:59:27.020]   the candidates to you
[01:59:27.020 --> 01:59:30.060]   sees it recruiters looks learns what you're looking for
[01:59:30.060 --> 01:59:31.580]   and then of course they have
[01:59:31.580 --> 01:59:34.380]   uh... uh... millions of resumes
[01:59:34.380 --> 01:59:37.460]   they identify people with the right experience and they actually invite them
[01:59:37.460 --> 01:59:38.500]   they say
[01:59:38.500 --> 01:59:42.180]   leo's got an opening they invite them there it's like their head hunting for
[01:59:42.180 --> 01:59:43.300]   you
[01:59:43.300 --> 01:59:47.740]   these invitations of totally revolutionized how you find your next iron fact
[01:59:47.740 --> 01:59:51.260]   eighty percent of employers who posted job on zipper crew to get a quality
[01:59:51.260 --> 01:59:54.820]   candidate through the site in just one day
[01:59:54.820 --> 01:59:58.020]   eighty percent in one day zipper crew doesn't stop there
[01:59:58.020 --> 02:00:01.420]   they even spotlight the strongest application so you never miss a great
[02:00:01.420 --> 02:00:04.260]   match here look here look these guys great
[02:00:04.260 --> 02:00:06.980]   it's like they're working for you the right candidates are out there we know
[02:00:06.980 --> 02:00:08.460]   that
[02:00:08.460 --> 02:00:12.020]   let's it recruit or make your job a lot easier you got the most important job in
[02:00:12.020 --> 02:00:12.740]   the business
[02:00:12.740 --> 02:00:14.180]   you're literally
[02:00:14.180 --> 02:00:15.660]   hiring
[02:00:15.660 --> 02:00:19.380]   the stuff the businesses made out of to it right with zipper crew to you to try
[02:00:19.380 --> 02:00:20.860]   it free
[02:00:20.860 --> 02:00:24.580]   right now business of all sizes trust it recruiters for their hiring needs
[02:00:24.580 --> 02:00:26.900]   just go to the recruiter dot com slash twit
[02:00:26.900 --> 02:00:30.180]   for your free trial zipper crew to dot com
[02:00:30.180 --> 02:00:31.380]   slash
[02:00:31.380 --> 02:00:35.100]   twit is literally the smartest way to hire
[02:00:35.100 --> 02:00:37.500]   zipper crew dot com slash
[02:00:37.500 --> 02:00:39.620]   twit they're very smart because
[02:00:39.620 --> 02:00:41.420]   they decided to use twit to get to you
[02:00:41.420 --> 02:00:44.580]   so thank them for that to zip recruiter dot com slash
[02:00:44.580 --> 02:00:48.260]   to a g_d_p_r_ just uh... more than a month away
[02:00:48.260 --> 02:00:49.220]   two months away
[02:00:49.220 --> 02:00:51.260]   inside a twenty-fifth
[02:00:51.260 --> 02:00:53.420]   and so i had two years to prepare
[02:00:53.420 --> 02:00:56.140]   and and are completely on a rate under
[02:00:56.140 --> 02:00:57.620]   completely unprepared
[02:00:57.620 --> 02:01:00.220]   this is the general data protection
[02:01:00.220 --> 02:01:01.860]   uh... privacy
[02:01:01.860 --> 02:01:05.100]   uh... regulation yes something like that i mean it's the it's probably
[02:01:05.100 --> 02:01:07.420]   something in fritch it's it's twenty one chapters of
[02:01:07.420 --> 02:01:08.820]   density you
[02:01:08.820 --> 02:01:11.140]   legislation legislation
[02:01:11.140 --> 02:01:14.260]   never use one chapter when you know twenty one will do when it comes to
[02:01:14.260 --> 02:01:16.140]   being so writing these laws up
[02:01:16.140 --> 02:01:20.820]   what do you think to me some of the the talk about the law looming large over
[02:01:20.820 --> 02:01:22.740]   attack
[02:01:22.740 --> 02:01:27.020]   yeah absolutely i mean that it were already starting to see uh... notices
[02:01:27.020 --> 02:01:31.500]   come through from companies like uh... google for example i got some email this
[02:01:31.500 --> 02:01:33.420]   week that was related to their
[02:01:33.420 --> 02:01:35.420]   g_d_p_r_
[02:01:35.420 --> 02:01:38.300]   p_d_r_ g_d_p_r_ compliance
[02:01:38.300 --> 02:01:39.300]   uh...
[02:01:39.300 --> 02:01:44.060]   so you know they've definitely been preparing for it for some time but
[02:01:44.060 --> 02:01:45.780]   you know i hope that
[02:01:45.780 --> 02:01:49.220]   the message that they're taking away from it aside from everything they have to
[02:01:49.220 --> 02:01:50.540]   do to
[02:01:50.540 --> 02:01:52.500]   comply in the u_s
[02:01:52.500 --> 02:01:56.020]   you know there but for the grace of congress
[02:01:56.020 --> 02:01:59.940]   we we definitely could move more in that direction who knows where what can
[02:01:59.940 --> 02:02:00.500]   happen
[02:02:00.500 --> 02:02:02.580]   that's the problem it's not predictable
[02:02:02.580 --> 02:02:05.980]   uh... somebody has found
[02:02:05.980 --> 02:02:10.060]   uh... child abuse imagery in the bitcoin blockchain
[02:02:10.060 --> 02:02:13.260]   you have a big point wallet on your computer you have that imagery on your
[02:02:13.260 --> 02:02:15.700]   computer are you liable
[02:02:15.700 --> 02:02:19.020]   it's a very good with its it's it was a very interesting piece of research that
[02:02:19.020 --> 02:02:20.180]   you could play to put it
[02:02:20.180 --> 02:02:21.300]   if you know just
[02:02:21.300 --> 02:02:24.420]   child abuse images but i mean you could put pretty much any benefit of data in
[02:02:24.420 --> 02:02:25.300]   there
[02:02:25.300 --> 02:02:29.460]   uh... it's an open source distributed ledger all bitcoin transactions are in
[02:02:29.460 --> 02:02:32.060]   the ledger it's hundreds of make gigabytes now
[02:02:32.060 --> 02:02:36.020]   and if you want to have a maintain your own bitcoin wallet on your service as a
[02:02:36.020 --> 02:02:39.980]   put on your service as opposed to using coin bases of the you have to download
[02:02:39.980 --> 02:02:44.180]   all i know cuz i have a wall on my computer what i didn't know is
[02:02:44.180 --> 02:02:48.060]   that there are sixteen hundred files stored in that blockchain people figure
[02:02:48.060 --> 02:02:50.140]   out a way to stick something in there
[02:02:50.140 --> 02:02:53.900]   of the files at least eight were of sexual content according to uh... arcan
[02:02:53.900 --> 02:02:57.100]   university germany r_w_t_h_ ocken university
[02:02:57.100 --> 02:03:00.260]   one thought to be an image of child abuse and to the contain
[02:03:00.260 --> 02:03:04.620]   links to child abuse content
[02:03:04.620 --> 02:03:06.020]   right which is a good
[02:03:06.020 --> 02:03:07.780]   important distinction correct
[02:03:07.780 --> 02:03:10.660]   i don't know you're the one that linking you know i can't believe this
[02:03:10.660 --> 02:03:12.860]   ledger from my hard drive in my
[02:03:12.860 --> 02:03:16.700]   you know let me take those bitcoins off your hands later you know what it's
[02:03:16.700 --> 02:03:20.580]   almost like the risk you can figure out the password they're yours my friend
[02:03:20.580 --> 02:03:23.060]   walked it down and i don't remember
[02:03:23.060 --> 02:03:27.180]   they did a pretty serious on this where they say you know this is a lot of
[02:03:27.180 --> 02:03:31.820]   smoke but not much fire and people have been criticizing
[02:03:31.820 --> 02:03:36.140]   bitcoin and its operation and the way the blockchain works from the get-go
[02:03:36.140 --> 02:03:39.100]   you're pulsing on a memo i guess in twenty fifteen saying
[02:03:39.100 --> 02:03:43.860]   this is the possibility malware could be injected into the blockchain
[02:03:43.860 --> 02:03:47.340]   and and i think it would wipe it because the blockchain has to live forever
[02:03:47.340 --> 02:03:50.620]   right and one of my listeners at twelve road and exactly what he and was saying
[02:03:50.620 --> 02:03:51.740]   you could put anything in there
[02:03:51.740 --> 02:03:52.860]   but the credit
[02:03:52.860 --> 02:03:54.380]   information
[02:03:54.380 --> 02:03:57.140]   you know personal data so uh... but i would
[02:03:57.140 --> 02:04:00.740]   and i mean i'm not liable for the stuff that's stuck in the wallages cuz i have
[02:04:00.740 --> 02:04:03.780]   it on my hard drive and i thought about that i presume
[02:04:03.780 --> 02:04:04.660]   your honor
[02:04:04.660 --> 02:04:08.460]   i had no idea
[02:04:08.460 --> 02:04:11.940]   right uh... yeah i don't want to have to make that case to law enforcement
[02:04:11.940 --> 02:04:13.140]   no
[02:04:13.140 --> 02:04:16.540]   all right i'm deleting my wallet i can't get it anyway
[02:04:16.540 --> 02:04:18.900]   that's just weird
[02:04:18.900 --> 02:04:22.340]   it's it was a really interesting bit of research because it did
[02:04:22.340 --> 02:04:25.060]   it's looking again this is just a personal view but
[02:04:25.060 --> 02:04:26.860]   it's looking more and more like
[02:04:26.860 --> 02:04:27.820]   bitcoin is
[02:04:27.820 --> 02:04:28.780]   kind of like
[02:04:28.780 --> 02:04:32.420]   it's the valiant first attempt the next generation is going to be better in the
[02:04:32.420 --> 02:04:34.740]   generation after that will probably get it right
[02:04:34.740 --> 02:04:37.100]   you know it's the old version three problem you never buy any mux of
[02:04:37.100 --> 02:04:38.980]   product until it gets to version three
[02:04:38.980 --> 02:04:42.500]   i think we're going to be cc the same with online currencies
[02:04:42.500 --> 02:04:45.980]   and what that kind of a bit kind three point hours at that well if it's still
[02:04:45.980 --> 02:04:50.220]   in a still in existence yes it's uh... jack dorsey says of all the
[02:04:50.220 --> 02:04:54.100]   well not bitcoin per se but some cryptocurrency will be
[02:04:54.100 --> 02:04:57.140]   the default currency in the world within ten years
[02:04:57.140 --> 02:04:59.580]   forget the euro for get the dollar
[02:04:59.580 --> 02:05:02.900]   he's he didn't say bitcoin he's despite that headline he said he thinks it will
[02:05:02.900 --> 02:05:04.260]   be the kind
[02:05:04.260 --> 02:05:05.860]   he does
[02:05:05.860 --> 02:05:06.900]   all your right
[02:05:06.900 --> 02:05:09.340]   the world ultimately will have a single currency the internet will have a
[02:05:09.340 --> 02:05:11.900]   single currency i personally believe it will be bitcoin
[02:05:11.900 --> 02:05:14.900]   that tells me jack dorsey has a few bitcoin is that
[02:05:14.900 --> 02:05:17.060]   that's what i think that's it
[02:05:17.060 --> 02:05:18.500]   do you see uh... square
[02:05:18.500 --> 02:05:21.860]   so there's an important question for
[02:05:21.860 --> 02:05:26.980]   square recently added the ability to buy and sell bitcoin in the square app
[02:05:26.980 --> 02:05:28.820]   hmm
[02:05:28.820 --> 02:05:34.180]   well how about the other story about uh... hacking or back during the the
[02:05:34.180 --> 02:05:36.580]   bitcoin wallet by i love that
[02:05:36.580 --> 02:05:39.140]   isn't that a great story so this was a
[02:05:39.140 --> 02:05:42.580]   unhackable wallet that should be a giveaway soon somebody says
[02:05:42.580 --> 02:05:45.740]   it's unhackable it will be hacked
[02:05:45.740 --> 02:05:48.740]   and uh... the funny thing is this time it was hacked
[02:05:48.740 --> 02:05:51.060]   by a fifteen-year-old
[02:05:51.060 --> 02:05:53.220]   i should just say that was a there's a
[02:05:53.220 --> 02:05:56.660]   general specializing security did have to have physical access to the wallet to
[02:05:56.660 --> 02:06:01.060]   do this okay but if i lost my wallet and you found and you picked it up it was
[02:06:01.060 --> 02:06:02.580]   with a french
[02:06:02.580 --> 02:06:06.660]   ledger it's called well or the french would say lugee i don't know
[02:06:06.660 --> 02:06:10.820]   uh... is melangee you found melange
[02:06:10.820 --> 02:06:14.100]   uh... well the fifteen-year-old from the u_k_
[02:06:14.100 --> 02:06:17.540]   posted on his personal blocks lemursheed
[02:06:17.540 --> 02:06:21.300]   he said uh... i can get into it
[02:06:21.300 --> 02:06:23.220]   three hundred three hundred bite
[02:06:23.220 --> 02:06:24.820]   proof of concept code
[02:06:24.820 --> 02:06:28.820]   i do all the the the young sister for his skills though that was uh...
[02:06:28.820 --> 02:06:32.340]   it's a significant and to deathcon next time around so you can talk about how
[02:06:32.340 --> 02:06:35.780]   that was done a lot of people do this have hardware physical hardware bitcoin
[02:06:35.780 --> 02:06:37.580]   wallets is that a common
[02:06:37.580 --> 02:06:40.260]   i know a couple of people with them i think they've sold said that they've
[02:06:40.260 --> 02:06:42.980]   sold millions of these wow
[02:06:42.980 --> 02:06:45.140]   that seems risky to me
[02:06:45.140 --> 02:06:47.460]   like if you lost that use
[02:06:47.460 --> 02:06:50.180]   course i've lost my password night
[02:06:50.180 --> 02:06:52.820]   same problem
[02:06:52.820 --> 02:06:55.220]   yes it's um
[02:06:55.220 --> 02:06:58.580]   well you know it's it's the old adage of why do you rob bangs is where the money
[02:06:58.580 --> 02:07:02.260]   is yes just i feel like bitcoin has some structural issues that are going to
[02:07:02.260 --> 02:07:05.300]   keep it from becoming the world's currency in ten years it costs a lot of
[02:07:05.300 --> 02:07:08.580]   money what is it forty dollars now or i guess it's gone back down
[02:07:08.580 --> 02:07:11.940]   twenty dollars to do a bitcoin transaction is slow because
[02:07:11.940 --> 02:07:14.740]   you know it's a slow process the proof of work
[02:07:14.740 --> 02:07:18.020]   is now using more power than the country of poland
[02:07:18.020 --> 02:07:23.140]   it's it's getting sillier this is it's it's i just feel like there's a long way
[02:07:23.140 --> 02:07:24.100]   to go on that
[02:07:24.100 --> 02:07:27.940]   i don't know how much power does it take to make paper money and coin money
[02:07:27.940 --> 02:07:31.620]   that's a good a lot i would guess i could see getting rid of that
[02:07:31.620 --> 02:07:34.260]   i i i i would love it if we get rid of the penny yes
[02:07:34.260 --> 02:07:36.420]   those things are with pennies yeah
[02:07:36.420 --> 02:07:39.700]   as things cost more than a penny to make and they're utterly useless
[02:07:39.700 --> 02:07:43.140]   that's michaels to maybe yeah i don't know it's covered at times while we're
[02:07:43.140 --> 02:07:46.740]   at it who needs quarters oh you need it for the laundry i'm sorry never
[02:07:46.740 --> 02:07:47.300]   my
[02:07:47.300 --> 02:07:50.820]   and parking meters i was sure i was about to show my age of saying telephone
[02:07:50.820 --> 02:07:54.740]   boxes and then uh what is that what is that daddy what's a telephone box
[02:07:54.740 --> 02:07:58.900]   yes that's uh the antiquated Ian Thompson he is
[02:07:58.900 --> 02:08:02.740]   new senator at the register dot co dot you can't equate to Ian Thompson
[02:08:02.740 --> 02:08:06.420]   he's not a number well actually is 796 apparently
[02:08:06.420 --> 02:08:10.420]   oh what number is that why does it say seven is that your prisoner number
[02:08:10.420 --> 02:08:13.620]   no no this was just basically a shirt i threw on in the i was
[02:08:13.620 --> 02:08:16.420]   up late watching the grand prix last night so i actually wanted to move
[02:08:16.420 --> 02:08:19.860]   she didn't want you're in the mood okay yeah formula one
[02:08:19.860 --> 02:08:23.620]   oh yes oh yes where is it uh australia at the moment
[02:08:23.620 --> 02:08:26.900]   oh fun yeah so the timing was just about right too
[02:08:26.900 --> 02:08:29.780]   i didn't have to get up at stupid o'clock in the morning to watch it
[02:08:29.780 --> 02:08:35.140]   we had uh last fall a hotel on the hairpin curve at monica
[02:08:35.140 --> 02:08:38.900]   oh i walked that route yeah i just want to go and watch
[02:08:38.900 --> 02:08:42.340]   as they go under the town under the bridge tunnels
[02:08:42.340 --> 02:08:46.100]   when the i've got the name of the corner now but yes i've walked down that and i
[02:08:46.100 --> 02:08:48.420]   thought i don't want to do that in a standard car
[02:08:48.420 --> 02:08:52.020]   let alone in a formula one i took videos of people trying to navigate it
[02:08:52.020 --> 02:08:57.780]   at 12 miles an hour yeah i'd love to see that someday
[02:08:57.780 --> 02:09:01.380]   that was a lot of highly recommended harry mccracken the technologizer i want
[02:09:01.380 --> 02:09:03.060]   to call you that i don't care if you're a technologist you
[02:09:03.060 --> 02:09:05.540]   editor fesca but you always be the technologist me
[02:09:05.540 --> 02:09:09.380]   harry he's at harry mccracken on the twitter
[02:09:09.380 --> 02:09:12.660]   hey i want to put in a plug for the the apple event on tuesday you're going
[02:09:12.660 --> 02:09:15.620]   and though he'll be in chicago we didn't even talk about that
[02:09:15.620 --> 02:09:18.820]   and that will be covering that for our new section at fest company dot com
[02:09:18.820 --> 02:09:21.940]   good okay so they're not streaming it other they're not streaming it so the
[02:09:21.940 --> 02:09:24.580]   only way to see yeah we were going to come in early
[02:09:24.580 --> 02:09:28.180]   what are they shamed and uh come right and well i don't i bet you i don't know do
[02:09:28.180 --> 02:09:31.700]   you think they'll be big announcements well if you're an ipad fan like i am
[02:09:31.700 --> 02:09:34.980]   you'll be excited and there'll be an education low cost ipad and there is
[02:09:34.980 --> 02:09:39.700]   this really interesting war between google and apple over the education market
[02:09:39.700 --> 02:09:43.780]   and chrome books such as eons have really done well 21
[02:09:43.780 --> 02:09:46.660]   percent partially because they're easy to manage and there are a lot of good
[02:09:46.660 --> 02:09:49.220]   things to be said from them as an education oh i see admins love them
[02:09:49.220 --> 02:09:53.140]   but also because the price point is attractive yes
[02:09:53.140 --> 02:09:56.900]   and they have a keyboard and they have a keyboard and children don't throw them
[02:09:56.900 --> 02:10:00.260]   like frisbees and they're pretty they're pretty sturdy and if you do
[02:10:00.260 --> 02:10:03.860]   break one and honestly if you're school how many years are you going to get out
[02:10:03.860 --> 02:10:06.900]   of an ipad one or two that's a lot of money spend yeah
[02:10:06.900 --> 02:10:10.660]   for something that's going to be obsoleteed so quickly apple really has a long
[02:10:10.660 --> 02:10:14.340]   way to go to make this an education product but we'll see Tuesday if they
[02:10:14.340 --> 02:10:17.700]   have pencil support that's really cool i think that's what that's what the
[02:10:17.700 --> 02:10:20.180]   invitation that would be an interactive thing which you can't get on a cheap
[02:10:20.180 --> 02:10:24.020]   chrome book right yeah but you can't draw a glass
[02:10:24.020 --> 02:10:27.460]   yes draw a rubber make them out of rubber all the way
[02:10:27.460 --> 02:10:30.900]   you get in the pixel block which is a really expensive crown book but a cool
[02:10:30.900 --> 02:10:33.460]   one uh the pixel book has a pen but so does the
[02:10:33.460 --> 02:10:37.460]   samson yeah five hundred five cents yes i reviewed that and i was in
[02:10:37.460 --> 02:10:40.820]   particularly oh i loved it really i've purchased two now but for the
[02:10:40.820 --> 02:10:44.100]   prominent charging what like five hundred bucks five hundred bucks
[02:10:44.100 --> 02:10:50.660]   so what how much do you pay for that um a lot more yeah okay but
[02:10:50.660 --> 02:10:53.060]   he's got a pixel the original pixel it looks like yeah
[02:10:53.060 --> 02:10:57.620]   that's a second generation it's v1 v1 pixel book no no they are called
[02:10:57.620 --> 02:11:00.660]   pixel Chromebook what they call it it's called the pixel book now
[02:11:00.660 --> 02:11:04.580]   it's i was in now i have the new pixel book yeah i know i have the new pixel
[02:11:04.580 --> 02:11:07.460]   book i really like it but it's a little pricey for
[02:11:07.460 --> 02:11:10.900]   Chromebook yeah Denise how what does your son use in school does he use a
[02:11:10.900 --> 02:11:16.020]   Chromebook uh no they have Chromebooks at the school
[02:11:16.020 --> 02:11:21.060]   that are sort of for communal use but my son was in the last class
[02:11:21.060 --> 02:11:24.500]   that didn't get their own to take home so yeah you know they can use them at
[02:11:24.500 --> 02:11:27.780]   school but he has his own computer and i bet he's well equipped i don't think
[02:11:27.780 --> 02:11:31.780]   there's any he's not bad but i would i you know uh they
[02:11:31.780 --> 02:11:35.700]   the schools here uh had Chromebooks and they took them back and
[02:11:35.700 --> 02:11:38.260]   they got they they got a grant and they bought
[02:11:38.260 --> 02:11:40.420]   iPads and i just thought it was a terrible
[02:11:40.420 --> 02:11:45.060]   regressive move i wasn't happy about it at all
[02:11:45.060 --> 02:11:48.820]   the only thing that they really used them for is to make movies
[02:11:48.820 --> 02:11:51.700]   you know because they had a camera so they'd be making movies but i didn't
[02:11:51.700 --> 02:11:54.980]   seem like there wasn't a lot of curriculum that i didn't feel like it was a really
[02:11:54.980 --> 02:11:58.260]   good move google has classroom they've got
[02:11:58.260 --> 02:12:01.300]   google docs if so many things you can do on a Chromebook i don't know well we'll
[02:12:01.300 --> 02:12:05.220]   see Tuesday Denise Howell she's on this week in law every
[02:12:05.220 --> 02:12:08.100]   Friday Denise howled on info is her personal website
[02:12:08.100 --> 02:12:12.340]   what is what is your tagline there wait a minute i got oh you'd have to
[02:12:12.340 --> 02:12:15.380]   remind me it's something about pretty funny about cats i think
[02:12:15.380 --> 02:12:19.940]   eight out of ten owners who expressed a preference said their cats preferred
[02:12:19.940 --> 02:12:22.500]   this lawyer
[02:12:22.500 --> 02:12:25.300]   Denise said gazeca you love a business i'm just curious
[02:12:25.300 --> 02:12:29.300]   uh you know i do find i don't know if that's what's doing it
[02:12:29.300 --> 02:12:34.180]   it's the cat lovers it's the cat lovers i did i do you do yeah you do a great
[02:12:34.180 --> 02:12:37.540]   job on this weekend law if and you're my personal
[02:12:37.540 --> 02:12:40.980]   attorney from now on i had a bot generate that and i was
[02:12:40.980 --> 02:12:43.700]   happy with it really a bot generator that yeah
[02:12:43.700 --> 02:12:48.660]   wow that's kind of interesting sideline thank you Denise thank you uh very much
[02:12:48.660 --> 02:12:51.620]   Harry thank you of course Ian it's always great to have all three of you on the
[02:12:51.620 --> 02:12:55.940]   show and thank thank you most of all for watching we do this week
[02:12:55.940 --> 02:13:00.580]   in tech every Saturday afternoon 3 p.m. pacific 6 p.m. eastern time 2200
[02:13:00.580 --> 02:13:03.380]   UTC if you want to stop by and watch live please do
[02:13:03.380 --> 02:13:07.060]   you can watch it twitter.tv/live if you're using the roku app that roku
[02:13:07.060 --> 02:13:09.700]   change their api that app is no longer functional
[02:13:09.700 --> 02:13:13.380]   but the good news is there many ways you could still watch live on our roku
[02:13:13.380 --> 02:13:15.780]   including the youtube act i think that's my favorite
[02:13:15.780 --> 02:13:20.020]   just search for the twit channel on youtube and you can watch us live on
[02:13:20.020 --> 02:13:24.660]   your big screen tv there are of course twit apps for all the
[02:13:24.660 --> 02:13:29.380]   phones and devices lots of them out there but get one of those or come to our
[02:13:29.380 --> 02:13:34.260]   website twit.tv/live watch there you can also join us in the chat room nice
[02:13:34.260 --> 02:13:37.220]   people did i say sund Saturday it's sunday
[02:13:37.220 --> 02:13:41.780]   did i say saturday it's sunday 3 p.m pacific 6 p.m. eastern time i apologize i
[02:13:41.780 --> 02:13:44.100]   hope i didn't confuse you saturday we do the
[02:13:44.100 --> 02:13:48.500]   screen savers sunday we do uh twit chatroom is irc.twit.tv and that's
[02:13:48.500 --> 02:13:51.460]   their job is to keep me from saying the wrong day
[02:13:51.460 --> 02:13:56.420]   among many others uh if you can't and if you want to be in studio we love
[02:13:56.420 --> 02:14:00.420]   having in studio visitors we've got marie and we got mike and we got
[02:14:00.420 --> 02:14:04.420]   matt from phoenix nice to have you please come say hi all you have to do is
[02:14:04.420 --> 02:14:07.220]   email tickets at twit.tv there's no charge we'd love to have you
[02:14:07.220 --> 02:14:11.060]   if you can't be here in studio if you can't watch live don't worry on demand
[02:14:11.060 --> 02:14:14.580]   it's a podcast folks on demand always available audio and
[02:14:14.580 --> 02:14:19.540]   yes video at twit.tv or wherever you get your podcast just
[02:14:19.540 --> 02:14:22.500]   subscribing that way you'll get it each and every
[02:14:22.500 --> 02:14:26.500]   week thank you everybody for being here and we'll see you next time another
[02:14:26.500 --> 02:14:30.180]   twit is in the can
[02:14:30.980 --> 02:14:37.460]   do the twit all right do the twit baby do the twit all right

