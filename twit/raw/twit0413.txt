;FFMETADATA1
title=Psychic Twins in a Hot Tub
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=413
genre=Podcast
comment=http://www.twit.tv/twit
copyright=These netcasts are released under a Creative Commons Attribution Non-Commercial Share-Alike license. TWiT and TWiT Logo are registered trademarks of Leo Laporte
publisher=TWiT
date=2013
encoder=Lavf58.76.100
;FFMETADATA1
title=Psychic Twins in a Hot Tub
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=413
genre=Podcast
comment=http://www.twit.tv/twit
copyright=These netcasts are released under a Creative Commons Attribution Non-Commercial Share-Alike license. TWiT and TWiT Logo are registered trademarks of Leo Laporte
publisher=TWiT
date=2013
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.480]   It's time for Twit this week at Tech.
[00:00:02.480 --> 00:00:03.840]   Why am I wearing this hat?
[00:00:03.840 --> 00:00:05.440]   Ask Jason Snell.
[00:00:05.440 --> 00:00:08.080]   He's here, along with Mike, Algin, and Roger Chang.
[00:00:08.080 --> 00:00:10.120]   We're going to talk about the week's tech news,
[00:00:10.120 --> 00:00:12.960]   social media versus mainstream news.
[00:00:12.960 --> 00:00:15.320]   We'll talk about Apple's conference this week,
[00:00:15.320 --> 00:00:17.400]   the Secret Conference, and what they may be planning
[00:00:17.400 --> 00:00:19.600]   for the fall, and a lot more.
[00:00:19.600 --> 00:00:21.920]   Stay tuned this week in Tech is next.
[00:00:21.920 --> 00:00:24.560]   [MUSIC PLAYING]
[00:00:24.560 --> 00:00:26.640]   Netcast you love.
[00:00:26.640 --> 00:00:28.000]   From people you trust.
[00:00:28.000 --> 00:00:31.360]   [MUSIC PLAYING]
[00:00:31.360 --> 00:00:34.280]   This is Twit.
[00:00:34.280 --> 00:00:36.160]   Audio bandwidth for this week in Tech
[00:00:36.160 --> 00:00:39.320]   is provided by the new WinApp for Android,
[00:00:39.320 --> 00:00:42.240]   featuring wireless sync and one-click iTunes import,
[00:00:42.240 --> 00:00:45.520]   now with free daily music downloads and full-length CD
[00:00:45.520 --> 00:00:46.680]   listening parties.
[00:00:46.680 --> 00:00:50.800]   Download it for free at winapp.com/android.
[00:00:50.800 --> 00:00:55.100]   Video bandwidth for Twit is provided by CashFly at CACHE
[00:00:55.100 --> 00:00:56.280]   F-L-Y dot com.
[00:00:56.280 --> 00:00:59.760]   [MUSIC PLAYING]
[00:00:59.760 --> 00:01:03.760]   This is Twit, this week at Tech.
[00:01:03.760 --> 00:01:08.120]   Episode 413, recorded July 7, 2013.
[00:01:08.120 --> 00:01:11.360]   Psychic twins in a hot tub.
[00:01:11.360 --> 00:01:14.560]   This week at Tech is brought to you by ProXPN.
[00:01:14.560 --> 00:01:16.800]   ProXPN is a virtual private network
[00:01:16.800 --> 00:01:19.440]   that allows you to use the internet the way it should be,
[00:01:19.440 --> 00:01:21.360]   anonymous and unfiltered.
[00:01:21.360 --> 00:01:25.820]   For 20% off your new account, go to proxpn.com/twit
[00:01:25.820 --> 00:01:30.400]   and use the code Twit20 and buy Carbonite.
[00:01:30.400 --> 00:01:32.000]   Whether you have one computer at home
[00:01:32.000 --> 00:01:33.640]   or several of your small business,
[00:01:33.640 --> 00:01:36.720]   Carbonite backs up your files for you automatically
[00:01:36.720 --> 00:01:40.120]   and continually for only $59.99 a year.
[00:01:40.120 --> 00:01:41.920]   Try it free at carbonite.com.
[00:01:41.920 --> 00:01:43.560]   No credit card required.
[00:01:43.560 --> 00:01:45.960]   Use the offer code Twit and you'll get two bonus months
[00:01:45.960 --> 00:01:47.480]   with purchase.
[00:01:47.480 --> 00:01:49.640]   And buy audible.com.
[00:01:49.640 --> 00:01:52.040]   Sign up for the platinum plan and get two free books.
[00:01:52.040 --> 00:01:54.800]   Go to audible.com/twit2 and don't forget
[00:01:54.800 --> 00:01:59.580]   to follow Audible on Twitter, user ID Audible_com.
[00:01:59.580 --> 00:02:01.820]   And buy Share File.
[00:02:01.820 --> 00:02:05.220]   Enhance your workflows and files of almost any size easily
[00:02:05.220 --> 00:02:08.260]   and securely with Share File from Citrix.
[00:02:08.260 --> 00:02:10.780]   Try Share File today for a 30 day free trial.
[00:02:10.780 --> 00:02:13.660]   Visit sharefile.com, click the radio microphone,
[00:02:13.660 --> 00:02:14.660]   and enter Twit.
[00:02:14.660 --> 00:02:16.620]   [MUSIC PLAYING]
[00:02:16.620 --> 00:02:17.980]   It's time for Twit this week at Tech
[00:02:17.980 --> 00:02:20.980]   to show where we cover the week's tech news all
[00:02:20.980 --> 00:02:24.180]   in studio, all live human bodies today.
[00:02:24.180 --> 00:02:25.580]   I love it when that happens.
[00:02:25.580 --> 00:02:26.980]   Let's say hi to Mike Elgin.
[00:02:26.980 --> 00:02:29.620]   Live human body might be an exaggeration.
[00:02:29.620 --> 00:02:30.180]   Case, but--
[00:02:30.180 --> 00:02:32.220]   He's the most lively of human bodies.
[00:02:32.220 --> 00:02:34.500]   He's here temporarily because I know you'll
[00:02:34.500 --> 00:02:35.700]   go back on the road at some point.
[00:02:35.700 --> 00:02:37.660]   But it's nice we've had you here in Silicon Valley
[00:02:37.660 --> 00:02:38.180]   for the summer.
[00:02:38.180 --> 00:02:39.060]   It's been great.
[00:02:39.060 --> 00:02:39.780]   Yeah.
[00:02:39.780 --> 00:02:40.380]   It's been fantastic.
[00:02:40.380 --> 00:02:41.820]   Wonderful.
[00:02:41.820 --> 00:02:44.340]   Google+, that's the place to find most of Mike's stuff,
[00:02:44.340 --> 00:02:45.700]   also a computer world.
[00:02:45.700 --> 00:02:46.580]   That's right.
[00:02:46.580 --> 00:02:47.700]   Cult of Matt, Cult of Android.
[00:02:47.700 --> 00:02:49.060]   Oh, yeah, you've been doing a lot of that.
[00:02:49.060 --> 00:02:49.560]   Et cetera.
[00:02:49.560 --> 00:02:50.060]   Yeah.
[00:02:50.060 --> 00:02:50.980]   Good to have any other places.
[00:02:50.980 --> 00:02:52.900]   From IDG, editorial director there,
[00:02:52.900 --> 00:02:56.020]   and editor in chief of Mac World magazine, Mr. Jason Stell,
[00:02:56.020 --> 00:02:56.900]   PC World 2.
[00:02:56.900 --> 00:02:58.420]   What is your title in the PC World, editorial director?
[00:02:58.420 --> 00:02:59.660]   Editorial director, yeah.
[00:02:59.660 --> 00:03:00.160]   OK.
[00:03:00.160 --> 00:03:02.500]   Hello, humans and everyone else on planet Earth.
[00:03:02.500 --> 00:03:03.140]   That's good.
[00:03:03.140 --> 00:03:04.020]   It's nice that we're all here.
[00:03:04.020 --> 00:03:04.660]   Briefly, same thing.
[00:03:04.660 --> 00:03:06.020]   It is so wonderful.
[00:03:06.020 --> 00:03:06.740]   It's amazing.
[00:03:06.740 --> 00:03:09.620]   Roger Chang, my old buddy from Tech Devine, Outrevision.
[00:03:09.620 --> 00:03:12.740]   Three, where he works on Techzilla and other shows.
[00:03:12.740 --> 00:03:13.180]   Yes.
[00:03:13.180 --> 00:03:14.580]   And is a Peanuts fan?
[00:03:14.580 --> 00:03:15.220]   Yes.
[00:03:15.220 --> 00:03:16.100]   That's kind of scary.
[00:03:16.100 --> 00:03:17.380]   That's the King of Peanuts.
[00:03:17.380 --> 00:03:18.580]   King of Thrones Peanuts.
[00:03:18.580 --> 00:03:19.220]   No.
[00:03:19.220 --> 00:03:20.340]   No?
[00:03:20.340 --> 00:03:21.580]   That's not the red wedding.
[00:03:21.580 --> 00:03:22.080]   No.
[00:03:22.080 --> 00:03:23.120]   What is Python?
[00:03:23.120 --> 00:03:24.540]   Oh, mighty Python Peanuts.
[00:03:24.540 --> 00:03:26.540]   Request for the Holy Grail.
[00:03:26.540 --> 00:03:27.180]   There are Peanuts.
[00:03:27.180 --> 00:03:28.380]   Oh, because it's a scary rabbit.
[00:03:28.380 --> 00:03:29.460]   Not Snoopy's a rabbit.
[00:03:29.460 --> 00:03:29.860]   I got it.
[00:03:29.860 --> 00:03:33.020]   And then you got Woodstock chained with a coconut.
[00:03:33.020 --> 00:03:34.340]   Ah!
[00:03:34.340 --> 00:03:37.020]   He's a laden sparrow.
[00:03:37.020 --> 00:03:37.520]   Swallow.
[00:03:37.520 --> 00:03:37.620]   Got it.
[00:03:37.620 --> 00:03:38.380]   Swallow.
[00:03:38.380 --> 00:03:39.700]   Got it.
[00:03:39.700 --> 00:03:40.860]   That's going a long way.
[00:03:40.860 --> 00:03:41.660]   I would have missed that one.
[00:03:41.660 --> 00:03:42.660]   Did you go to Nerdtacular?
[00:03:42.660 --> 00:03:43.540]   Is that what you were?
[00:03:43.540 --> 00:03:46.140]   No, I actually got this because Busset T's
[00:03:46.140 --> 00:03:48.460]   had like a 40% off.
[00:03:48.460 --> 00:03:49.500]   So I got to buy a bunch of stuff.
[00:03:49.500 --> 00:03:50.980]   It'd feel.
[00:03:50.980 --> 00:03:53.160]   T-shirts are the geek outfit these days.
[00:03:53.160 --> 00:03:55.320]   Did you say King of Thrones, by the way?
[00:03:55.320 --> 00:03:57.680]   That's like saying Dr. Spock on Star Wars.
[00:03:57.680 --> 00:03:58.080]   I know.
[00:03:58.080 --> 00:03:59.600]   I'm so messed up.
[00:03:59.600 --> 00:04:01.000]   Major geek points off for you.
[00:04:01.000 --> 00:04:03.880]   Oh, I watched my first episode of Doctor Who
[00:04:03.880 --> 00:04:04.360]   last night.
[00:04:04.360 --> 00:04:06.000]   I'm very confused.
[00:04:06.000 --> 00:04:06.340]   It's OK.
[00:04:06.340 --> 00:04:07.160]   It's wiggly wobbly.
[00:04:07.160 --> 00:04:08.920]   Oh, man.
[00:04:08.920 --> 00:04:11.160]   Well, now a lot of the things people have been saying,
[00:04:11.160 --> 00:04:13.360]   like it's bigger on the inside than the outside.
[00:04:13.360 --> 00:04:13.840]   Oh, no.
[00:04:13.840 --> 00:04:13.840]   You said it's--
[00:04:13.840 --> 00:04:14.840]   Now I get it.
[00:04:14.840 --> 00:04:16.080]   You know, Sonic's screwdriver.
[00:04:16.080 --> 00:04:17.360]   I understand these things.
[00:04:17.360 --> 00:04:18.120]   It totally makes sense.
[00:04:18.120 --> 00:04:19.320]   It all totally holds together.
[00:04:19.320 --> 00:04:19.800]   Yeah.
[00:04:19.800 --> 00:04:21.780]   [LAUGHTER]
[00:04:21.780 --> 00:04:22.620]   It's a great show.
[00:04:22.620 --> 00:04:23.120]   Sort of.
[00:04:23.120 --> 00:04:23.720]   It's a great show.
[00:04:23.720 --> 00:04:24.500]   It's one of my favorites.
[00:04:24.500 --> 00:04:25.980]   But is it a great show?
[00:04:25.980 --> 00:04:26.660]   I don't know.
[00:04:26.660 --> 00:04:29.300]   I'll say this last series has been kind of--
[00:04:29.300 --> 00:04:29.780]   I start with you.
[00:04:29.780 --> 00:04:31.180]   I know it's mostly Miss.
[00:04:31.180 --> 00:04:32.220]   I started with 2005.
[00:04:32.220 --> 00:04:33.620]   Yeah, you should start the reboot.
[00:04:33.620 --> 00:04:34.300]   It's good.
[00:04:34.300 --> 00:04:34.900]   It's good.
[00:04:34.900 --> 00:04:35.940]   It's getting better.
[00:04:35.940 --> 00:04:37.260]   It's got some F.E. years.
[00:04:37.260 --> 00:04:38.540]   The last year was kind of weak.
[00:04:38.540 --> 00:04:41.020]   I watched two episodes, and I thought I can do without this.
[00:04:41.020 --> 00:04:41.820]   It's a good show.
[00:04:41.820 --> 00:04:42.780]   Keep watching.
[00:04:42.780 --> 00:04:43.120]   All right.
[00:04:43.120 --> 00:04:45.020]   I'll give it a second chance.
[00:04:45.020 --> 00:04:48.540]   So a more serious note, of course,
[00:04:48.540 --> 00:04:54.780]   yesterday, a plane crash in San Francisco 1130 by 1135.
[00:04:54.780 --> 00:04:56.700]   Twitter was alive.
[00:04:56.700 --> 00:04:58.400]   And I'm watching CNN at the same time.
[00:04:58.400 --> 00:04:59.660]   I was doing the radio show.
[00:04:59.660 --> 00:05:01.420]   Nothing for 20 minutes.
[00:05:01.420 --> 00:05:03.040]   But boy, anything you wanted to know,
[00:05:03.040 --> 00:05:03.660]   you could find out.
[00:05:03.660 --> 00:05:08.140]   In fact, even a picture on path by a Samsung executive--
[00:05:08.140 --> 00:05:11.340]   that's the picture David Un posted on his path.
[00:05:11.340 --> 00:05:13.900]   And then it was really fun to watch mainstream media
[00:05:13.900 --> 00:05:17.340]   say that he tweeted it on path.
[00:05:17.340 --> 00:05:19.940]   And they just didn't understand what path was.
[00:05:19.940 --> 00:05:21.580]   It didn't end up on Twitter, of course.
[00:05:21.580 --> 00:05:22.300]   It passed on.
[00:05:22.300 --> 00:05:22.820]   It passed on.
[00:05:22.820 --> 00:05:25.300]   It passed on.
[00:05:25.300 --> 00:05:27.020]   There's the tweet.
[00:05:27.020 --> 00:05:28.060]   I just crash-landed it.
[00:05:28.060 --> 00:05:29.340]   SFO tail ripped off.
[00:05:29.340 --> 00:05:30.540]   Most everyone seems fine.
[00:05:30.540 --> 00:05:30.980]   I'm OK.
[00:05:30.980 --> 00:05:34.500]   So we did learn, of course, that two young Chinese girls
[00:05:34.500 --> 00:05:36.780]   were killed in that crash, tragic crash.
[00:05:36.780 --> 00:05:38.780]   But amazing.
[00:05:38.780 --> 00:05:40.780]   306 people did get off the plane,
[00:05:40.780 --> 00:05:43.860]   some with serious injuries, but they survived.
[00:05:43.860 --> 00:05:45.220]   People should know that David Un
[00:05:45.220 --> 00:05:47.500]   is actually a huge honcho.
[00:05:47.500 --> 00:05:50.380]   He's one of the top guys at Samsung.
[00:05:50.380 --> 00:05:54.460]   And he's been sent to America to reinvigorate the company.
[00:05:54.460 --> 00:05:56.100]   What a way to arrive.
[00:05:56.100 --> 00:05:57.780]   I actually thought of him when I found out
[00:05:57.780 --> 00:05:59.340]   that it was coming from Korea.
[00:05:59.340 --> 00:06:00.860]   I thought, I wonder if David Un is on there,
[00:06:00.860 --> 00:06:04.180]   because he's constantly-- this guy is back and forth
[00:06:04.180 --> 00:06:04.780]   all the time.
[00:06:04.780 --> 00:06:05.860]   Well, and then the weirdest thing
[00:06:05.860 --> 00:06:07.540]   was Sheryl Sandberg posts on Facebook.
[00:06:07.540 --> 00:06:09.140]   She's a COO at Facebook.
[00:06:09.140 --> 00:06:11.100]   I and my family were going to be on that flight.
[00:06:11.100 --> 00:06:13.540]   And I needed the miles, or I wanted to use miles,
[00:06:13.540 --> 00:06:15.020]   so we went United instead.
[00:06:15.020 --> 00:06:16.060]   Yeah.
[00:06:16.060 --> 00:06:17.220]   She's got a lot of money.
[00:06:17.220 --> 00:06:18.260]   I don't know why.
[00:06:18.260 --> 00:06:20.020]   I'm glad she's cheap.
[00:06:20.020 --> 00:06:20.620]   But--
[00:06:20.620 --> 00:06:23.060]   [LAUGHTER]
[00:06:23.060 --> 00:06:23.940]   I thought that was odd.
[00:06:23.940 --> 00:06:24.140]   Yeah.
[00:06:24.140 --> 00:06:25.620]   But anyway, good.
[00:06:25.620 --> 00:06:26.900]   And so she wasn't on the flight.
[00:06:26.900 --> 00:06:31.100]   I was actually scheduled to be at an event
[00:06:31.100 --> 00:06:33.380]   at the World Trade Center on 9/11.
[00:06:33.380 --> 00:06:34.340]   There was an HP event.
[00:06:34.340 --> 00:06:35.580]   And the last minute they canceled it
[00:06:35.580 --> 00:06:37.740]   and decided to have it here on the campus.
[00:06:37.740 --> 00:06:40.180]   So it's like a lot of that kind of stuff going around.
[00:06:40.180 --> 00:06:41.820]   But yeah, she was lucky.
[00:06:41.820 --> 00:06:44.020]   But she wrote a lot about it.
[00:06:44.020 --> 00:06:47.820]   Also amazing that somebody would get off the plane,
[00:06:47.820 --> 00:06:50.820]   slide down the slide, walk 100 feet away,
[00:06:50.820 --> 00:06:54.580]   and then turn around, take a picture, and put it on path.
[00:06:54.580 --> 00:06:55.780]   Yeah, I wouldn't have waited that long.
[00:06:55.780 --> 00:06:57.260]   [LAUGHTER]
[00:06:57.260 --> 00:06:57.740]   It would have been.
[00:06:57.740 --> 00:06:58.940]   You know what's great in his picture?
[00:06:58.940 --> 00:07:00.740]   There's another person taking a picture.
[00:07:00.740 --> 00:07:03.580]   Maybe that's the person who posted to Instagram with a filter.
[00:07:03.580 --> 00:07:04.080]   Right.
[00:07:04.080 --> 00:07:04.940]   My plane just crashed.
[00:07:04.940 --> 00:07:06.500]   I'm going to post to Instagram, which filter?
[00:07:06.500 --> 00:07:07.500]   With a filter.
[00:07:07.500 --> 00:07:08.300]   Should I use?
[00:07:08.300 --> 00:07:09.540]   With a filter.
[00:07:09.540 --> 00:07:10.540]   Black and white, maybe?
[00:07:10.540 --> 00:07:13.860]   Maybe the old timey sort of the gearotype filter, maybe.
[00:07:13.860 --> 00:07:15.100]   It's just amazing.
[00:07:15.100 --> 00:07:20.100]   Well, I'm glad that they are OK.
[00:07:20.100 --> 00:07:22.620]   And I'm sorry about the deaths and certainly hope everybody
[00:07:22.620 --> 00:07:24.140]   gets better quickly.
[00:07:24.140 --> 00:07:26.020]   And there's nothing else to say about it,
[00:07:26.020 --> 00:07:29.180]   except that it was an experience that we had on social media
[00:07:29.180 --> 00:07:32.100]   far more quickly than on mainstream.
[00:07:32.100 --> 00:07:33.420]   I first saw a video.
[00:07:33.420 --> 00:07:34.580]   The first thing I saw was a video
[00:07:34.580 --> 00:07:37.420]   well before this picture hit and long before CNN
[00:07:37.420 --> 00:07:38.980]   or any of the other mainstream media got it.
[00:07:38.980 --> 00:07:42.100]   It was a video taken from inside the terminal.
[00:07:42.100 --> 00:07:44.660]   And some people were speaking, I think,
[00:07:44.660 --> 00:07:46.220]   it was Mandarin or something like that.
[00:07:46.220 --> 00:07:49.580]   But you could see it off in the distance, smoking and--
[00:07:49.580 --> 00:07:50.140]   It's amazing.
[00:07:50.140 --> 00:07:50.980]   --of fire and shit.
[00:07:50.980 --> 00:07:53.700]   There are people staying at the hotels, the airport
[00:07:53.700 --> 00:07:56.300]   hotels that are across the water from the runways.
[00:07:56.300 --> 00:07:59.340]   And basically, anybody who used to be an eyewitness
[00:07:59.340 --> 00:08:01.100]   is now an eyewitness with a camera phone.
[00:08:01.100 --> 00:08:01.900]   With a camera phone.
[00:08:01.900 --> 00:08:04.220]   And so all of a sudden, immediately, a friend of mine
[00:08:04.220 --> 00:08:05.540]   was actually staying right across there.
[00:08:05.540 --> 00:08:08.420]   And he was tweeting within a minute
[00:08:08.420 --> 00:08:10.780]   with some pictures of the plane on the runway.
[00:08:10.780 --> 00:08:12.780]   It's amazing.
[00:08:12.780 --> 00:08:13.500]   I may be nervous.
[00:08:13.500 --> 00:08:14.100]   I'm on the air.
[00:08:14.100 --> 00:08:14.980]   I'm doing the radio show.
[00:08:14.980 --> 00:08:17.380]   So I'm actually talking to a fairly large audience.
[00:08:17.380 --> 00:08:19.420]   I noticed this is going on.
[00:08:19.420 --> 00:08:23.540]   I noticed that none of the news channels are covering it.
[00:08:23.540 --> 00:08:25.460]   And there's also this concern--
[00:08:25.460 --> 00:08:28.420]   it was pretty obviously happening.
[00:08:28.420 --> 00:08:31.060]   But there's this concern about rushing in
[00:08:31.060 --> 00:08:31.980]   to talk about stuff.
[00:08:31.980 --> 00:08:35.140]   And so here I am on mainstream media thinking, gosh,
[00:08:35.140 --> 00:08:37.540]   I don't know what to do at this point.
[00:08:37.540 --> 00:08:39.660]   Should I repeat what I'm seeing on Twitter,
[00:08:39.660 --> 00:08:40.900]   on social media?
[00:08:40.900 --> 00:08:43.180]   Should I wait to CNN confirms it?
[00:08:43.180 --> 00:08:45.860]   Well, I mean, it's one of those things where, yeah,
[00:08:45.860 --> 00:08:47.500]   you can do it spur of the moment.
[00:08:47.500 --> 00:08:52.820]   But at the same time, if you want to be a journalist about it,
[00:08:52.820 --> 00:08:55.340]   you also need to add some context to it.
[00:08:55.340 --> 00:08:59.460]   I mean, look at any kind of news event
[00:08:59.460 --> 00:09:01.940]   within the past five, six years.
[00:09:01.940 --> 00:09:04.740]   And when people tweet and post images,
[00:09:04.740 --> 00:09:06.980]   often it's without any kind of context.
[00:09:06.980 --> 00:09:09.620]   And people tend to draw conclusions
[00:09:09.620 --> 00:09:12.580]   without necessarily seeing the entire situation.
[00:09:12.580 --> 00:09:12.980]   Oh, yeah.
[00:09:12.980 --> 00:09:17.780]   And the whole Trayvon thing, I mean,
[00:09:17.780 --> 00:09:21.580]   that's one of those things where people will just kind of post
[00:09:21.580 --> 00:09:25.900]   comments and stuff without necessarily being--
[00:09:25.900 --> 00:09:28.060]   oh, I'm a journalism student, or I'm someone--
[00:09:28.060 --> 00:09:32.660]   But does this anointing by a journalism degree
[00:09:32.660 --> 00:09:36.420]   somehow make you more accurate, more likely to follow--
[00:09:36.420 --> 00:09:41.700]   are there rules that the unwashed masses don't know?
[00:09:41.700 --> 00:09:44.220]   That's kind of the tricky thing at this--
[00:09:44.220 --> 00:09:45.660]   We're the original sources, right?
[00:09:45.660 --> 00:09:47.060]   We're the original materials.
[00:09:47.060 --> 00:09:48.700]   Yeah, I mean, but at the same time,
[00:09:48.700 --> 00:09:51.260]   we're at this kind of this threshold where, yeah,
[00:09:51.260 --> 00:09:53.820]   technology has allowed a broad group of people
[00:09:53.820 --> 00:09:58.820]   to effectively be the eyes, ears, and voices
[00:09:58.820 --> 00:09:59.580]   for a bunch of people.
[00:09:59.580 --> 00:10:01.820]   But at the same time, that's a broad range
[00:10:01.820 --> 00:10:03.660]   of differing viewpoints.
[00:10:03.660 --> 00:10:05.820]   If you come into a situation with, oh,
[00:10:05.820 --> 00:10:07.260]   that's a really bad idea.
[00:10:07.260 --> 00:10:09.220]   That's something stupid.
[00:10:09.220 --> 00:10:12.420]   I'm going to tweet and take a photo saying,
[00:10:12.420 --> 00:10:14.260]   that guy's being a jerk, and he's
[00:10:14.260 --> 00:10:16.220]   hitting it on this woman or whatever.
[00:10:16.220 --> 00:10:17.540]   Someone else says, well, that woman
[00:10:17.540 --> 00:10:19.660]   was jacket caught on fire, and the guy's
[00:10:19.660 --> 00:10:21.700]   hitting it on her to put it out.
[00:10:21.700 --> 00:10:23.140]   You need to be able to stop it.
[00:10:23.140 --> 00:10:24.100]   Spacts, and there's opinion.
[00:10:24.100 --> 00:10:24.600]   Yeah.
[00:10:24.600 --> 00:10:26.420]   And that's what the journalist should be doing.
[00:10:26.420 --> 00:10:29.020]   There's always context to be explained
[00:10:29.020 --> 00:10:30.820]   in a situation like that.
[00:10:30.820 --> 00:10:32.620]   The most immediate one is, what do we know,
[00:10:32.620 --> 00:10:33.620]   and what do we don't know?
[00:10:33.620 --> 00:10:34.860]   For example, if one of the first things
[00:10:34.860 --> 00:10:36.780]   that Twitter formed a consensus around
[00:10:36.780 --> 00:10:39.580]   was the idea that the plane flipped around on its back,
[00:10:39.580 --> 00:10:40.580]   which didn't happen.
[00:10:40.580 --> 00:10:41.580]   Which is wrong.
[00:10:41.580 --> 00:10:44.740]   And so a good journalist who wants
[00:10:44.740 --> 00:10:48.620]   to participate in this enormous stream of information
[00:10:48.620 --> 00:10:50.260]   should jump in there and say, OK, well, here's
[00:10:50.260 --> 00:10:51.740]   what we actually know.
[00:10:51.740 --> 00:10:53.700]   We know that somebody has posted this picture.
[00:10:53.700 --> 00:10:55.660]   We know that there's reports of the choices.
[00:10:55.660 --> 00:10:57.820]   I'm listening and watching.
[00:10:57.820 --> 00:11:00.980]   I was very interesting for me as a case study,
[00:11:00.980 --> 00:11:01.900]   the mainstream media.
[00:11:01.900 --> 00:11:03.700]   And they were very reluctant to say, for instance,
[00:11:03.700 --> 00:11:06.380]   make deaths or injuries there were.
[00:11:06.380 --> 00:11:08.140]   Unconfirmed, unconfirmed, unconfirmed.
[00:11:08.140 --> 00:11:09.820]   And this is hours into it.
[00:11:09.820 --> 00:11:12.060]   Whereas on Twitter, I'm seeing quotes
[00:11:12.060 --> 00:11:17.060]   from emergency radio, which turned out to be accurate.
[00:11:17.060 --> 00:11:22.900]   And I feel like probably the best way to do this
[00:11:22.900 --> 00:11:27.740]   is to give the people the facts and let them decide.
[00:11:27.740 --> 00:11:29.540]   But give them the facts in context.
[00:11:29.540 --> 00:11:31.220]   So what I ended up doing on the radios--
[00:11:31.220 --> 00:11:33.820]   and I actually said it for our affiliates down the line
[00:11:33.820 --> 00:11:36.660]   or taking this live, there's a big story coming across Twitter.
[00:11:36.660 --> 00:11:38.140]   You should probably pay attention to this.
[00:11:38.140 --> 00:11:40.460]   This is what people are saying right now on Twitter.
[00:11:40.460 --> 00:11:43.020]   The context being, this is from Twitter.
[00:11:43.020 --> 00:11:44.940]   And I think that all of us need to learn,
[00:11:44.940 --> 00:11:47.540]   as we all consume social media directly,
[00:11:47.540 --> 00:11:49.740]   how to read this vet it.
[00:11:49.740 --> 00:11:51.780]   No enough not to-- and I think as we use it,
[00:11:51.780 --> 00:11:53.780]   we start to realize there'll be plenty of cases
[00:11:53.780 --> 00:11:56.220]   where there's just been wrong.
[00:11:56.220 --> 00:11:58.540]   Well, I mean, all social media users
[00:11:58.540 --> 00:12:00.380]   having to build up the muscles that I
[00:12:00.380 --> 00:12:02.140]   think a lot of journalism students had to learn.
[00:12:02.140 --> 00:12:05.780]   We're all not just reporters of what we see.
[00:12:05.780 --> 00:12:09.420]   We're also interpreters like a reporter of old used to be,
[00:12:09.420 --> 00:12:11.340]   about who is this person and do I trust them?
[00:12:11.340 --> 00:12:12.900]   And are they a reliable eyewitness?
[00:12:12.900 --> 00:12:14.140]   And are they retweeting something?
[00:12:14.140 --> 00:12:15.860]   Or were they actually there?
[00:12:15.860 --> 00:12:18.380]   And there was a time when people just said,
[00:12:18.380 --> 00:12:19.700]   oh, regular people can't do that.
[00:12:19.700 --> 00:12:21.260]   That's too much work for them.
[00:12:21.260 --> 00:12:22.620]   Well, too bad.
[00:12:22.620 --> 00:12:23.260]   Here we are.
[00:12:23.260 --> 00:12:24.260]   We all have to do that.
[00:12:24.260 --> 00:12:25.060]   They never will.
[00:12:25.060 --> 00:12:27.380]   Actually, the risks to media--
[00:12:27.380 --> 00:12:30.220]   the best example of the risks are a case
[00:12:30.220 --> 00:12:32.300]   that happened like two years ago or a year ago,
[00:12:32.300 --> 00:12:36.540]   sometime recently, where there was a local news TV show
[00:12:36.540 --> 00:12:39.300]   in Chicago reporting on a plane crash that landed on--
[00:12:39.300 --> 00:12:41.660]   I don't know-- one of the major streets in Chicago.
[00:12:41.660 --> 00:12:44.860]   And they reported this emergency for 20 minutes
[00:12:44.860 --> 00:12:48.700]   before they were informed that it was a movie set.
[00:12:48.700 --> 00:12:49.940]   Or an movie set.
[00:12:49.940 --> 00:12:51.340]   Yeah, they were filming a plane crash.
[00:12:51.340 --> 00:12:55.060]   And then they started blaming the fire department
[00:12:55.060 --> 00:12:56.660]   and other people, the movie people,
[00:12:56.660 --> 00:12:58.620]   because they should have informed the journalists.
[00:12:58.620 --> 00:12:59.460]   No, my submersors.
[00:12:59.460 --> 00:13:01.300]   But by the same token, that's the fear.
[00:13:01.300 --> 00:13:04.180]   That's why CNN takes 20 minutes, because they don't want
[00:13:04.180 --> 00:13:04.700]   to do that.
[00:13:04.700 --> 00:13:06.420]   Well, they are embarrassing to get it wrong,
[00:13:06.420 --> 00:13:07.860]   but it is to be late.
[00:13:07.860 --> 00:13:10.180]   I think it goes even beyond embarrassing.
[00:13:10.180 --> 00:13:14.420]   I mean, CNN, you have a certain amount of reputation
[00:13:14.420 --> 00:13:15.020]   at stake.
[00:13:15.020 --> 00:13:18.260]   And if you leverage that and you're wrong,
[00:13:18.260 --> 00:13:20.340]   that especially if you're a news outlet,
[00:13:20.340 --> 00:13:22.620]   that kind of shoots you in the foot as a business.
[00:13:22.620 --> 00:13:23.980]   Yeah, long term.
[00:13:23.980 --> 00:13:24.580]   If I is--
[00:13:24.580 --> 00:13:28.100]   Is that sure Lazar, whose relationship was severed with--
[00:13:28.100 --> 00:13:29.060]   was it CBS?
[00:13:29.060 --> 00:13:29.700]   I think yes, CBS.
[00:13:29.700 --> 00:13:32.380]   After tweeting incorrectly, the Steve Jobs had died.
[00:13:32.380 --> 00:13:34.300]   Well, what they need to do is see
[00:13:34.300 --> 00:13:36.740]   the CNNs of the world need to figure out how to leverage,
[00:13:36.740 --> 00:13:40.260]   very quickly, the camera phones and the unreforming--
[00:13:40.260 --> 00:13:40.700]   So I--
[00:13:40.700 --> 00:13:41.540]   --that those feeds coming in.
[00:13:41.540 --> 00:13:43.660]   This is what I saw very quickly.
[00:13:43.660 --> 00:13:45.660]   This is the path post of David on.
[00:13:45.660 --> 00:13:47.180]   This is the original post.
[00:13:47.180 --> 00:13:50.100]   And I looked at that, and I said, that's not a fake post.
[00:13:50.100 --> 00:13:51.860]   First of all, it's on the path.
[00:13:51.860 --> 00:13:54.620]   Which kind of inherently makes it a little bit more reliable,
[00:13:54.620 --> 00:13:56.140]   because it's a small network.
[00:13:56.140 --> 00:13:58.700]   People make fake accounts on path.
[00:13:58.700 --> 00:14:01.500]   The picture was clearly somebody who just
[00:14:01.500 --> 00:14:02.380]   gotten off that plane.
[00:14:02.380 --> 00:14:04.260]   He was very close.
[00:14:04.260 --> 00:14:07.940]   So this gives it a lot of weight when you see this.
[00:14:07.940 --> 00:14:10.020]   And big props to David Unfernat saying,
[00:14:10.020 --> 00:14:14.580]   and this was taken with a Samsung Galaxy S4.
[00:14:14.580 --> 00:14:15.940]   Although, has anybody looked at the XF?
[00:14:15.940 --> 00:14:17.700]   Because it'd be funny if it were in the iPhone.
[00:14:17.700 --> 00:14:19.060]   And iPhone, right.
[00:14:19.060 --> 00:14:19.560]   Wow.
[00:14:19.560 --> 00:14:20.980]   There's also the question of timeliness.
[00:14:20.980 --> 00:14:23.260]   We said CNN might want to harness this stuff
[00:14:23.260 --> 00:14:24.420]   and get it out there faster.
[00:14:24.420 --> 00:14:26.260]   There is also, if you're a news organization,
[00:14:26.260 --> 00:14:29.460]   that question of what's the public value in getting
[00:14:29.460 --> 00:14:31.340]   that report out five minutes earlier?
[00:14:31.340 --> 00:14:33.140]   For something like a Supreme Court decision,
[00:14:33.140 --> 00:14:34.500]   maybe there's a little bit more of it.
[00:14:34.500 --> 00:14:36.940]   For something like this to say, a plane is down.
[00:14:36.940 --> 00:14:38.020]   It's on fire.
[00:14:38.020 --> 00:14:40.140]   We're trying to figure out more.
[00:14:40.140 --> 00:14:41.740]   If you're CNN, if you're the New York Times,
[00:14:41.740 --> 00:14:43.060]   if you're the San Francisco Chronicle,
[00:14:43.060 --> 00:14:45.940]   waiting five minutes to get the details instead of being wrong,
[00:14:45.940 --> 00:14:46.900]   it's probably OK.
[00:14:46.900 --> 00:14:49.220]   Relaying what people are saying on social media
[00:14:49.220 --> 00:14:51.180]   isn't the same as endorsing it.
[00:14:51.180 --> 00:14:53.700]   As long as you qualify it and you give the source
[00:14:53.700 --> 00:14:58.380]   and you explain how it might not be the full story
[00:14:58.380 --> 00:15:00.740]   or it might be inaccurate, but this is what we're seeing right
[00:15:00.740 --> 00:15:01.180]   now.
[00:15:01.180 --> 00:15:02.820]   The reporting really isn't of the event.
[00:15:02.820 --> 00:15:05.660]   It's of what's happening on Twitter.
[00:15:05.660 --> 00:15:07.180]   And giving people that background information
[00:15:07.180 --> 00:15:08.180]   that might make it useful.
[00:15:08.180 --> 00:15:11.420]   And I think part of the problem is that news,
[00:15:11.420 --> 00:15:14.820]   especially broadcast news, is now more entertainment
[00:15:14.820 --> 00:15:15.740]   than information.
[00:15:15.740 --> 00:15:18.940]   And it's as a business, that's what they leverage that.
[00:15:18.940 --> 00:15:21.300]   CNN, actually, to be fair, had a difficult choice.
[00:15:21.300 --> 00:15:24.380]   They were covering the Canadian train explosion at the time.
[00:15:24.380 --> 00:15:27.700]   And that is, in some respects, a bigger story.
[00:15:27.700 --> 00:15:30.020]   I mean, a whole town blew up.
[00:15:30.020 --> 00:15:33.340]   And so I don't blame them for not jumping to this story.
[00:15:33.340 --> 00:15:40.460]   On the other hand, I was on the radio in San Francisco
[00:15:40.460 --> 00:15:40.940]   at the time.
[00:15:40.940 --> 00:15:44.180]   So it is relevant to tell people who are in the area
[00:15:44.180 --> 00:15:46.740]   don't drive down 101 because that's being blocked off now
[00:15:46.740 --> 00:15:47.900]   by emergency vehicles.
[00:15:47.900 --> 00:15:48.780]   There's stuff going on.
[00:15:48.780 --> 00:15:50.700]   If you see that smoke, that's what's going on.
[00:15:50.700 --> 00:15:51.700]   Airport is shutting down.
[00:15:51.700 --> 00:15:52.700]   Airport is shutting down.
[00:15:52.700 --> 00:15:55.980]   The thing that bugs me about CNN and the general coverage
[00:15:55.980 --> 00:16:01.140]   on TV news is that they devote the amount of time they have,
[00:16:01.140 --> 00:16:03.020]   not based on how much information they have,
[00:16:03.020 --> 00:16:04.620]   but based on how big the story is.
[00:16:04.620 --> 00:16:06.500]   Well, they have no information.
[00:16:06.500 --> 00:16:08.500]   But if they have no information about a huge story,
[00:16:08.500 --> 00:16:09.540]   then they sit there and tap down.
[00:16:09.540 --> 00:16:11.940]   They cover Zimmerman for a week.
[00:16:11.940 --> 00:16:14.380]   They should go ahead and cover the Quebec story
[00:16:14.380 --> 00:16:16.060]   and then jump in every two minutes with,
[00:16:16.060 --> 00:16:16.900]   here's what we know now.
[00:16:16.900 --> 00:16:17.580]   Here's what we know.
[00:16:17.580 --> 00:16:19.020]   And they don't do that.
[00:16:19.020 --> 00:16:19.660]   They're trying to get ready.
[00:16:19.660 --> 00:16:21.580]   I think the bottom line on this one move on
[00:16:21.580 --> 00:16:24.620]   is that you should incorporate social media into your--
[00:16:24.620 --> 00:16:27.460]   I mean, this is how I learn about stuff now, frankly.
[00:16:27.460 --> 00:16:30.340]   And you just have to understand how to use it and how to--
[00:16:30.340 --> 00:16:32.300]   as you said, develop that muscle.
[00:16:32.300 --> 00:16:36.060]   One more thing, though, if somebody
[00:16:36.060 --> 00:16:37.620]   was going to do one of these days is they're
[00:16:37.620 --> 00:16:40.140]   going to turn on Hangouts on Air on Google+,
[00:16:40.140 --> 00:16:41.860]   and they'll instantly have a larger audience.
[00:16:41.860 --> 00:16:43.700]   At either end, glass.
[00:16:43.700 --> 00:16:45.980]   Well, I mean, they'll have a larger audience than CNN
[00:16:45.980 --> 00:16:48.340]   immediately, 10 times bigger than CNN.
[00:16:48.340 --> 00:16:50.180]   So it's like, what do we need CNN for?
[00:16:50.180 --> 00:16:52.500]   Ultimately, if you have somebody standing next to the plane
[00:16:52.500 --> 00:16:53.820]   broadcasting live video--
[00:16:53.820 --> 00:16:54.460]   Amazing.
[00:16:54.460 --> 00:16:56.020]   Somebody just didn't think of doing that.
[00:16:56.020 --> 00:16:58.220]   I mean, so we already have it in our-- almost everybody
[00:16:58.220 --> 00:17:00.060]   in that plane was capable of doing that.
[00:17:00.060 --> 00:17:01.820]   Nobody thought of it.
[00:17:01.820 --> 00:17:03.900]   That's why CNN has iReport, and they
[00:17:03.900 --> 00:17:07.260]   fired a lot of reporters so that they could build up their iReport
[00:17:07.260 --> 00:17:07.820]   capability.
[00:17:07.820 --> 00:17:11.660]   But I think that that's going to be a big shift
[00:17:11.660 --> 00:17:13.700]   in how we perceive news.
[00:17:13.700 --> 00:17:16.180]   And at that point, CNN's got to do what we've done,
[00:17:16.180 --> 00:17:17.980]   which is say, look, our job is not
[00:17:17.980 --> 00:17:20.540]   to bring you the stories fastest, but to bring you the analysis
[00:17:20.540 --> 00:17:21.700]   and the understanding of the story.
[00:17:21.700 --> 00:17:22.260]   And some context.
[00:17:22.260 --> 00:17:24.940]   And somebody aggregating all these photos and clips
[00:17:24.940 --> 00:17:28.020]   and making something that makes more narrative sense
[00:17:28.020 --> 00:17:30.820]   for the person who's not tuned in in five minutes,
[00:17:30.820 --> 00:17:32.420]   but is looking at this three hours later
[00:17:32.420 --> 00:17:33.860]   and wants the bigger picture.
[00:17:33.860 --> 00:17:35.420]   That's a place where you can add value.
[00:17:35.420 --> 00:17:38.940]   I bet I did what most people did, which is I saw them feeds.
[00:17:38.940 --> 00:17:40.540]   I turned on CNN.
[00:17:40.540 --> 00:17:41.020]   Yeah.
[00:17:41.020 --> 00:17:42.980]   So it's a mutual thing.
[00:17:42.980 --> 00:17:43.740]   But you're right.
[00:17:43.740 --> 00:17:46.340]   If David's standing there with glass and Hangouts on Air
[00:17:46.340 --> 00:17:47.900]   live, that's what you're going to watch.
[00:17:47.900 --> 00:17:49.020]   But you're exactly right, though.
[00:17:49.020 --> 00:17:51.620]   I mean, even after all the time we spent on this,
[00:17:51.620 --> 00:17:53.980]   watching the story since it happened,
[00:17:53.980 --> 00:17:56.820]   I think most of us still don't know very much about what happened.
[00:17:56.820 --> 00:17:57.300]   Right.
[00:17:57.300 --> 00:18:00.100]   I mean, the list of facts that we actually
[00:18:00.100 --> 00:18:02.060]   know, the number of deaths, a few injuries,
[00:18:02.060 --> 00:18:03.900]   tail fell off, a couple of other facts.
[00:18:03.900 --> 00:18:05.980]   I think that's the extent of what we know.
[00:18:05.980 --> 00:18:09.540]   I had a commercial pilot, a guy who flies jets in studio
[00:18:09.540 --> 00:18:10.220]   at the time.
[00:18:10.220 --> 00:18:12.060]   He was what he told me about it.
[00:18:12.060 --> 00:18:15.340]   And because he got a feed or something.
[00:18:15.340 --> 00:18:16.860]   And he was very reluctant to say anything.
[00:18:16.860 --> 00:18:17.380]   Sure.
[00:18:17.380 --> 00:18:18.220]   Rightly so.
[00:18:18.220 --> 00:18:18.900]   Right.
[00:18:18.900 --> 00:18:20.380]   Because there's no information.
[00:18:20.380 --> 00:18:20.860]   Right.
[00:18:20.860 --> 00:18:22.220]   So it's all speculation.
[00:18:22.220 --> 00:18:23.540]   That's one thing that the news now
[00:18:23.540 --> 00:18:25.060]   worries have no trouble doing.
[00:18:25.060 --> 00:18:26.540]   It's just speculating a lot of things.
[00:18:26.540 --> 00:18:28.700]   As long as you can make a quick headline
[00:18:28.700 --> 00:18:29.460]   that she can throw up.
[00:18:29.460 --> 00:18:30.020]   Yeah.
[00:18:30.020 --> 00:18:30.460]   Yeah.
[00:18:30.460 --> 00:18:31.500]   All right.
[00:18:31.500 --> 00:18:33.180]   We are talking about the week's tech news.
[00:18:33.180 --> 00:18:35.340]   And there is a lot of it, a Google event.
[00:18:35.340 --> 00:18:36.860]   On Wednesday, Mike and I are invited.
[00:18:36.860 --> 00:18:39.860]   We can't tell you about it.
[00:18:39.860 --> 00:18:40.460]   You never heard that.
[00:18:40.460 --> 00:18:41.420]   Can you tell us about it?
[00:18:41.420 --> 00:18:41.820]   Sure.
[00:18:41.820 --> 00:18:43.500]   OK.
[00:18:43.500 --> 00:18:45.660]   We'll talk about a massive Android flaw
[00:18:45.660 --> 00:18:48.620]   that apparently let's hackers take over and control 99%
[00:18:48.620 --> 00:18:51.460]   of Android phones.
[00:18:51.460 --> 00:18:53.100]   Even Google can't do that.
[00:18:53.100 --> 00:18:53.660]   Yeah.
[00:18:53.660 --> 00:18:55.060]   That's pretty good.
[00:18:55.060 --> 00:18:56.180]   That's of high percentage.
[00:18:56.180 --> 00:18:59.780]   It's they finally ended all the malware fragmentation.
[00:18:59.780 --> 00:19:00.260]   Good for them.
[00:19:00.260 --> 00:19:03.100]   Microsoft about to embark on a reorganization.
[00:19:03.100 --> 00:19:06.820]   And one of the guys who might have been key in this splits
[00:19:06.820 --> 00:19:09.140]   to run Zinga.
[00:19:09.140 --> 00:19:10.740]   What?
[00:19:10.740 --> 00:19:12.060]   What?
[00:19:12.060 --> 00:19:16.860]   And Dell apparently is looking at a watch.
[00:19:16.860 --> 00:19:17.460]   Sure winner.
[00:19:17.460 --> 00:19:18.660]   That's kind of--
[00:19:18.660 --> 00:19:20.980]   They just want to know what time it is.
[00:19:20.980 --> 00:19:23.340]   All coming up in just a little bit on this week in tech.
[00:19:23.340 --> 00:19:25.780]   Mike Elgin, Jason Snell, Roger Chang.
[00:19:25.780 --> 00:19:27.220]   Glad we have you along.
[00:19:27.220 --> 00:19:28.940]   A nice big studio audience.
[00:19:28.940 --> 00:19:31.140]   Thank you all for being here.
[00:19:31.140 --> 00:19:32.460]   Our air conditioning has now failed.
[00:19:32.460 --> 00:19:36.300]   So if you want to strip down, please, be my guess.
[00:19:36.300 --> 00:19:38.660]   Our show today brought to you in a very timely fashion
[00:19:38.660 --> 00:19:41.540]   by proxpn.com.
[00:19:41.540 --> 00:19:44.340]   You probably know that if you are in an open Wi-Fi access
[00:19:44.340 --> 00:19:46.340]   spot, if you're at a hotel, if you're
[00:19:46.340 --> 00:19:48.340]   on a shared internet connection,
[00:19:48.340 --> 00:19:51.500]   that everything you do can be seen by everybody else
[00:19:51.500 --> 00:19:52.980]   on that network.
[00:19:52.980 --> 00:19:55.420]   It's not unusual in cases like that for people
[00:19:55.420 --> 00:19:57.620]   to try to use a VPN solution.
[00:19:57.620 --> 00:20:00.060]   Proxpn is open VPN.
[00:20:00.060 --> 00:20:00.780]   Implemented right.
[00:20:00.780 --> 00:20:02.100]   We had Steve Gibson look at it.
[00:20:02.100 --> 00:20:04.020]   He gave it its thumbs up.
[00:20:04.020 --> 00:20:05.980]   But it is so much more useful than just
[00:20:05.980 --> 00:20:08.420]   at an open Wi-Fi hotspot.
[00:20:08.420 --> 00:20:12.060]   It's a great way to give you complete online privacy
[00:20:12.060 --> 00:20:15.620]   through a 512-bit encryption tunnel via open VPN.
[00:20:15.620 --> 00:20:17.020]   And if you're using a mobile device that
[00:20:17.020 --> 00:20:18.900]   doesn't support open VPN, a lot of them don't.
[00:20:18.900 --> 00:20:20.140]   PPTP as well.
[00:20:20.140 --> 00:20:21.500]   You get to choose.
[00:20:21.500 --> 00:20:23.940]   If your ISP is monitoring what you're up to,
[00:20:23.940 --> 00:20:26.940]   and I think they are, you can protect yourself against them.
[00:20:26.940 --> 00:20:28.340]   The six-strength rule.
[00:20:28.340 --> 00:20:31.180]   You can keep your internet usage private at work.
[00:20:31.180 --> 00:20:34.220]   You can bypass internet filtering and blocked websites,
[00:20:34.220 --> 00:20:38.020]   bypass geographic restrictions for internet content.
[00:20:38.020 --> 00:20:41.340]   Proxpn has servers all over the world.
[00:20:41.340 --> 00:20:46.740]   Los Angeles, Dallas, Seattle, London, Singapore, Amsterdam.
[00:20:46.740 --> 00:20:51.940]   You can use it on Windows, Mac, iOS, and Android.
[00:20:51.940 --> 00:20:53.180]   You keep your stuff private.
[00:20:53.180 --> 00:20:55.540]   Protect yourself, especially nowadays.
[00:20:55.540 --> 00:20:57.900]   We now know that keeping yourself
[00:20:57.900 --> 00:21:00.060]   private is going to require a little extra effort,
[00:21:00.060 --> 00:21:01.260]   a little encryption.
[00:21:01.260 --> 00:21:02.940]   There is a free version you can try out.
[00:21:02.940 --> 00:21:06.820]   But if you visit proxpn.com/twit,
[00:21:06.820 --> 00:21:09.580]   we've got a special deal on the pro version.
[00:21:09.580 --> 00:21:11.820]   Normally a pro account in proxpn
[00:21:11.820 --> 00:21:17.300]   is either $9.95 a month or $75 for an entire year, $74.95
[00:21:17.300 --> 00:21:18.340]   for an entire year.
[00:21:18.340 --> 00:21:20.820]   But when you decide to buy at proxpn,
[00:21:20.820 --> 00:21:25.060]   if you use our offer code, twit20, you'll get 20% off,
[00:21:25.060 --> 00:21:26.180]   not for the first month of the year,
[00:21:26.180 --> 00:21:29.260]   but for the lifetime of your account.
[00:21:29.260 --> 00:21:30.740]   This is a good time to take advantage of this.
[00:21:30.740 --> 00:21:33.220]   That means less than five bucks a month in the yearly plan
[00:21:33.220 --> 00:21:37.060]   for absolute security with the best solution.
[00:21:37.060 --> 00:21:39.980]   OpenVPN, running on proxpn.
[00:21:39.980 --> 00:21:43.300]   Try it today, proxpn.com/twit.
[00:21:43.300 --> 00:21:47.100]   Use the offer code twit20.
[00:21:47.100 --> 00:21:49.420]   You probably heard, this actually is a story
[00:21:49.420 --> 00:21:51.180]   as much as it is part of the ad,
[00:21:51.180 --> 00:21:55.060]   that the credit cards have started to refuse a charges
[00:21:55.060 --> 00:21:56.540]   to pay for VPN accounts.
[00:21:56.540 --> 00:21:59.940]   And we asked proxpn about that.
[00:21:59.940 --> 00:22:02.020]   They said we have nobody has contacted us
[00:22:02.020 --> 00:22:06.300]   from MasterCard or Visa to this point,
[00:22:06.300 --> 00:22:07.220]   but that is something,
[00:22:07.220 --> 00:22:10.340]   and I gotta think that MasterCard or Visa are being prompted,
[00:22:10.340 --> 00:22:13.340]   I don't know whether it's by the recording industry,
[00:22:13.340 --> 00:22:15.500]   or if it's by the NSA,
[00:22:15.500 --> 00:22:19.860]   but I don't think it's in any way fair to say,
[00:22:19.860 --> 00:22:22.500]   oh yeah, anybody's using VPN is up to no good.
[00:22:22.500 --> 00:22:25.300]   So I'm a little shocked by this.
[00:22:25.300 --> 00:22:26.540]   - I'm gonna go with the NSA on that one.
[00:22:26.540 --> 00:22:28.500]   - I think it might be the NSA.
[00:22:28.500 --> 00:22:30.540]   So we don't like encryption.
[00:22:30.540 --> 00:22:33.860]   They wanna be able to see into every dark corner.
[00:22:33.860 --> 00:22:35.500]   - Unbelievable.
[00:22:35.500 --> 00:22:36.340]   - Unbelievable.
[00:22:36.340 --> 00:22:39.060]   Anyway, you can still use your credit card
[00:22:39.060 --> 00:22:42.900]   at proxpn.com/twit.
[00:22:42.900 --> 00:22:45.540]   Very sad to see that Doug Engelbark passed away,
[00:22:45.540 --> 00:22:48.060]   88 years old, he was the guy who created
[00:22:48.060 --> 00:22:50.660]   pretty much modern computing at SRI.
[00:22:50.660 --> 00:22:52.380]   Remember having him on tech TV,
[00:22:52.380 --> 00:22:54.420]   were you there, Roger, we had him in?
[00:22:54.420 --> 00:22:55.260]   - Potentially.
[00:22:55.260 --> 00:22:57.020]   - Yeah, it's been a long time.
[00:22:57.020 --> 00:22:57.860]   There were a lot of shows.
[00:22:57.860 --> 00:22:58.900]   - It was a long time ago.
[00:22:58.900 --> 00:23:00.380]   He brought the original mouse,
[00:23:00.380 --> 00:23:01.660]   which is made out of wood.
[00:23:01.660 --> 00:23:02.660]   It was about that big.
[00:23:02.660 --> 00:23:05.140]   Remember that, a big red button on it?
[00:23:05.140 --> 00:23:05.980]   - Pine, yeah.
[00:23:05.980 --> 00:23:07.740]   - It was pine with two metal wheels.
[00:23:07.740 --> 00:23:10.740]   - Amazing, he did what is, what do they call it?
[00:23:10.740 --> 00:23:12.860]   The world's most amazing demo.
[00:23:12.860 --> 00:23:14.220]   - The mother of all demos.
[00:23:14.220 --> 00:23:16.140]   - Mother of all demos.
[00:23:16.140 --> 00:23:18.100]   - It's really, you can't believe what you're looking at
[00:23:18.100 --> 00:23:19.260]   when you see it even today.
[00:23:19.260 --> 00:23:20.260]   - We should probably watch a little bit of it.
[00:23:20.260 --> 00:23:21.900]   - It looks futuristic, 'cause it knows it like mine.
[00:23:21.900 --> 00:23:23.260]   - 'Cause this was in '64.
[00:23:23.260 --> 00:23:25.740]   - It was '68, '68 when he did the demo.
[00:23:25.740 --> 00:23:28.060]   Invented the mouse in '64, '65, '65, something like that.
[00:23:28.060 --> 00:23:30.180]   But the other thing that I think
[00:23:30.180 --> 00:23:31.420]   he doesn't get enough credit for is
[00:23:31.420 --> 00:23:33.180]   he invented the concept of hypertext.
[00:23:33.180 --> 00:23:34.340]   So every time you click on a link,
[00:23:34.340 --> 00:23:36.140]   click on a picture that links somewhere,
[00:23:36.140 --> 00:23:38.020]   the whole world wide web is built on the concept
[00:23:38.020 --> 00:23:41.260]   of the hyperlink, he came up with that concept.
[00:23:41.260 --> 00:23:44.900]   So that's a pretty foundational idea.
[00:23:44.900 --> 00:23:46.100]   - This is it, to stand for here.
[00:23:46.100 --> 00:23:48.780]   I got it, okay, Chad, if you wanna control it, you can.
[00:23:48.780 --> 00:23:54.380]   This is under ARPA, NASA, and the Rome Air Development Center,
[00:23:54.380 --> 00:23:55.580]   part of the Air Force.
[00:23:55.580 --> 00:23:57.700]   - So there were a thousand people in the audience
[00:23:57.700 --> 00:24:01.620]   who all of which were top men, top men, top Leo.
[00:24:01.620 --> 00:24:03.460]   - Top men, that's what they called him in those days.
[00:24:03.460 --> 00:24:05.620]   - And they were slack jawed at this demo,
[00:24:05.620 --> 00:24:07.860]   'cause he'd just basically laid out the whole future.
[00:24:07.860 --> 00:24:10.620]   - So he's using his mouse.
[00:24:10.620 --> 00:24:12.580]   Nobody'd seen anything like this before.
[00:24:12.580 --> 00:24:15.380]   He's also on the left is a courting keyboard that he can--
[00:24:15.380 --> 00:24:18.540]   - A file, this file is one statement with a few words
[00:24:18.540 --> 00:24:20.380]   that just make more statements,
[00:24:20.380 --> 00:24:21.860]   I'll say copy that statement.
[00:24:21.860 --> 00:24:23.740]   - And Stug Engelbart himself doing the demo.
[00:24:23.740 --> 00:24:26.180]   - I wouldn't mind an interface like that now.
[00:24:26.180 --> 00:24:28.020]   - I just like to handle copy.
[00:24:28.020 --> 00:24:29.860]   - I know, it's a little better.
[00:24:29.860 --> 00:24:31.300]   - What do I get one of those?
[00:24:31.300 --> 00:24:36.060]   - Behind the scenes, Bill English from SRI as well,
[00:24:36.060 --> 00:24:39.220]   and they're all wearing headsets talking to each other,
[00:24:39.220 --> 00:24:41.380]   and talking to the Home Lab in Menlo Park.
[00:24:41.380 --> 00:24:44.500]   So he's in San Francisco doing this demo.
[00:24:44.500 --> 00:24:49.700]   And really a lot, now, is he gonna show,
[00:24:49.700 --> 00:24:52.020]   is there windowing in this as well?
[00:24:52.020 --> 00:24:53.460]   - He shows a whole range of things,
[00:24:53.460 --> 00:24:55.340]   including the concept of networking,
[00:24:55.340 --> 00:24:58.300]   the concept of icons, things like that.
[00:24:58.300 --> 00:25:01.740]   I mean, he was looking at a whole range of things
[00:25:01.740 --> 00:25:03.260]   that are just the fundamental building blocks
[00:25:03.260 --> 00:25:04.980]   of everything we do today,
[00:25:04.980 --> 00:25:08.740]   and most of it was brand new to all of these people.
[00:25:08.740 --> 00:25:10.860]   - Anybody, there's the mouse.
[00:25:10.860 --> 00:25:12.300]   Now, that's actually not the one he brought.
[00:25:12.300 --> 00:25:13.580]   That's a later model.
[00:25:13.580 --> 00:25:18.060]   - It had been under development for three or four years,
[00:25:18.060 --> 00:25:19.540]   by the time he demoed this.
[00:25:19.540 --> 00:25:21.980]   - This is at Stanford Research Institute.
[00:25:21.980 --> 00:25:25.420]   A lot of people think Xerox Spark, not part of park.
[00:25:25.420 --> 00:25:26.700]   - Yep.
[00:25:26.700 --> 00:25:29.620]   SRI is actually what they named Siri after,
[00:25:29.620 --> 00:25:33.380]   because Siri originated in SRI.
[00:25:33.380 --> 00:25:35.180]   - Wow.
[00:25:35.180 --> 00:25:37.020]   And of course, Smalltalk, a lot of this demo
[00:25:37.020 --> 00:25:39.700]   is done using Smalltalk,
[00:25:39.700 --> 00:25:42.220]   which at the time was also very innovative.
[00:25:42.220 --> 00:25:45.740]   It looks so long ago.
[00:25:45.740 --> 00:25:46.580]   - Yeah.
[00:25:46.580 --> 00:25:49.060]   - And yet so much of it was right.
[00:25:49.060 --> 00:25:51.620]   I mean, that's the amazing thing about it.
[00:25:51.620 --> 00:25:55.260]   I met him, Mac user, I think, back in the day,
[00:25:55.260 --> 00:25:56.780]   gave him an award.
[00:25:56.780 --> 00:25:58.540]   And he was the nicest guy.
[00:25:58.540 --> 00:26:00.580]   He was very friendly and grateful.
[00:26:00.580 --> 00:26:01.660]   And I think at that point,
[00:26:01.660 --> 00:26:03.180]   he'd come to terms with the fact that
[00:26:03.180 --> 00:26:05.300]   he was never gonna, you know,
[00:26:05.300 --> 00:26:07.260]   his patents all expired and all of that.
[00:26:07.260 --> 00:26:09.420]   But he was grateful to be recognized
[00:26:09.420 --> 00:26:11.660]   as being somebody who was at the forefront of this stuff.
[00:26:11.660 --> 00:26:13.100]   I think that was his in the end.
[00:26:13.100 --> 00:26:15.580]   He was very happy to have that recognition
[00:26:15.580 --> 00:26:16.580]   for all that time.
[00:26:16.580 --> 00:26:18.180]   - He never made a penny from the mouse.
[00:26:18.180 --> 00:26:20.980]   The patent was actually owned by company who worked for the
[00:26:20.980 --> 00:26:22.500]   SRI or somebody else.
[00:26:22.500 --> 00:26:25.020]   And he never made any money from that.
[00:26:25.020 --> 00:26:28.580]   He also, the track ball was actually invented in Canada
[00:26:28.580 --> 00:26:29.940]   before the mouse was invented.
[00:26:29.940 --> 00:26:30.780]   - Oh, interesting.
[00:26:30.780 --> 00:26:32.460]   - So if there are any Canadians out there.
[00:26:32.460 --> 00:26:33.300]   - Credit.
[00:26:33.300 --> 00:26:34.140]   - Track ball.
[00:26:34.140 --> 00:26:34.980]   - Props.
[00:26:34.980 --> 00:26:38.780]   - But yeah, he was an awesome guy.
[00:26:38.780 --> 00:26:39.620]   - Yeah.
[00:26:39.620 --> 00:26:44.020]   - 88 years old and really a legend.
[00:26:44.020 --> 00:26:46.980]   The guy who brought us a lot of what we use today.
[00:26:46.980 --> 00:26:48.780]   - And it's funny, we talk about Google Glass
[00:26:48.780 --> 00:26:52.700]   or the iWatch or other sort of weird speculative technologies.
[00:26:52.700 --> 00:26:54.660]   And I mean, I think this is an important lesson too,
[00:26:54.660 --> 00:26:57.620]   that a lot of this stuff in 1968 wasn't wrong.
[00:26:57.620 --> 00:27:01.820]   It was dead on and it still took 16 years for most people
[00:27:01.820 --> 00:27:03.380]   to see any device that has it.
[00:27:03.380 --> 00:27:04.220]   - Sure.
[00:27:04.220 --> 00:27:07.180]   - And probably more like 2025 for it to become truly mainstream.
[00:27:07.180 --> 00:27:09.420]   - If you think about networking and hyperlinking,
[00:27:09.420 --> 00:27:12.380]   those seemed like kind of boring inside baseball,
[00:27:12.380 --> 00:27:14.020]   he kind of things back in '68.
[00:27:14.020 --> 00:27:17.140]   But look at what that all became.
[00:27:17.140 --> 00:27:19.180]   I mean, it just became the whole world.
[00:27:19.180 --> 00:27:21.020]   It became everything we do.
[00:27:21.020 --> 00:27:22.980]   So you don't know what, some like Google Glass
[00:27:22.980 --> 00:27:24.740]   or some of these things seem like dorky things
[00:27:24.740 --> 00:27:26.660]   that they are dorky things.
[00:27:26.660 --> 00:27:27.900]   I want one.
[00:27:27.900 --> 00:27:31.900]   But they could become the foundation
[00:27:31.900 --> 00:27:35.340]   for how everybody lives and works and stuff like that.
[00:27:35.340 --> 00:27:37.020]   - Filming each other, recording every one.
[00:27:37.020 --> 00:27:38.020]   - Yes.
[00:27:38.020 --> 00:27:38.860]   Yeah.
[00:27:38.860 --> 00:27:40.300]   Robert Scobel in a shower, the whole thing,
[00:27:40.300 --> 00:27:41.140]   this is the future we face.
[00:27:41.140 --> 00:27:41.980]   - I dropped my show.
[00:27:41.980 --> 00:27:42.820]   - It's dark.
[00:27:42.820 --> 00:27:43.660]   - Don't don't do this.
[00:27:43.660 --> 00:27:45.740]   - People in showers, when years of now,
[00:27:45.740 --> 00:27:47.060]   we'll see that picture and think,
[00:27:47.060 --> 00:27:49.300]   oh my God, what have I done?
[00:27:49.300 --> 00:27:50.540]   What have I done?
[00:27:50.540 --> 00:27:52.380]   - Need to invent a time machine quick.
[00:27:52.380 --> 00:27:57.380]   - Google bought a full page ad on the 4th of July
[00:27:57.380 --> 00:27:59.740]   talking about a new phone from Motorola.
[00:27:59.740 --> 00:28:03.980]   This is the first phone really that was designed
[00:28:03.980 --> 00:28:06.140]   by Motorola after the acquisition by Google.
[00:28:06.140 --> 00:28:08.660]   They came out with phones in the past year,
[00:28:08.660 --> 00:28:10.060]   but they were already in the pipeline.
[00:28:10.060 --> 00:28:13.100]   So this will be the first real Google phone.
[00:28:13.100 --> 00:28:15.620]   The Moto X, we don't know anything about it,
[00:28:15.620 --> 00:28:17.820]   both Mike and I have been invited
[00:28:17.820 --> 00:28:20.060]   to an event at Google this week.
[00:28:20.060 --> 00:28:22.780]   Guy Kawasaki is now working for Motorola.
[00:28:22.780 --> 00:28:28.940]   And all I can say is I just got an email from them saying,
[00:28:28.940 --> 00:28:31.100]   here's what we're gonna talk about,
[00:28:31.100 --> 00:28:32.940]   and you can't tell anybody.
[00:28:32.940 --> 00:28:34.620]   It's embargoed for a while.
[00:28:34.620 --> 00:28:36.740]   I probably can't even say when the embargo ends.
[00:28:36.740 --> 00:28:37.580]   - There's actually a lot of--
[00:28:37.580 --> 00:28:39.020]   - You'll have to advise me on this.
[00:28:39.020 --> 00:28:41.460]   I'm not a journalist, I'm just some guy.
[00:28:41.460 --> 00:28:42.300]   - Sure you are.
[00:28:42.300 --> 00:28:44.140]   (laughing)
[00:28:44.140 --> 00:28:46.060]   That's my story and I'm sticking with it.
[00:28:46.060 --> 00:28:48.140]   - Well, I mean, it's in the absence of--
[00:28:48.140 --> 00:28:51.060]   - Not like Google denied after these reports came out.
[00:28:51.060 --> 00:28:53.220]   Google said, no, no, it's not about the Motorola X.
[00:28:53.220 --> 00:28:55.060]   - I hope not actually.
[00:28:55.060 --> 00:28:57.060]   I hope it's about a wristwatch.
[00:28:57.060 --> 00:28:58.820]   - That would be cool. - That would be awesome.
[00:28:58.820 --> 00:29:01.300]   But there have been some leaks and reports
[00:29:01.300 --> 00:29:03.300]   and stuff like that which don't sound very credible to me.
[00:29:03.300 --> 00:29:04.900]   They make a big deal out of the fact
[00:29:04.900 --> 00:29:06.260]   that it's gonna be built in the US.
[00:29:06.260 --> 00:29:07.580]   - Highly customizable.
[00:29:07.580 --> 00:29:09.420]   - And you were designing it.
[00:29:09.420 --> 00:29:10.660]   You the user are gonna design it.
[00:29:10.660 --> 00:29:11.660]   - Yeah, but what does that mean?
[00:29:11.660 --> 00:29:13.020]   - Well, it's got a-- - It's got a weaving.
[00:29:13.020 --> 00:29:16.300]   - Well, first of all, it's Foxconn or Hanhai or whatever.
[00:29:16.300 --> 00:29:17.140]   - It's building the plan.
[00:29:17.140 --> 00:29:18.940]   - It's building it in Texas.
[00:29:18.940 --> 00:29:20.220]   And I think I don't think it's awesome
[00:29:20.220 --> 00:29:22.780]   to get somewhere in Texas.
[00:29:22.780 --> 00:29:25.500]   - It's an old work? - It's an old work, maybe.
[00:29:25.500 --> 00:29:26.820]   - Flextronic plant, right?
[00:29:26.820 --> 00:29:27.660]   - Exactly.
[00:29:27.660 --> 00:29:30.180]   So the fact that it's being, like, US is a terrible place
[00:29:30.180 --> 00:29:31.140]   for a sweatshop.
[00:29:31.140 --> 00:29:31.980]   I mean, it's just--
[00:29:31.980 --> 00:29:34.100]   - But they need to build it here in order to customize it
[00:29:34.100 --> 00:29:34.940]   in a reasonable amount of time.
[00:29:34.940 --> 00:29:37.700]   - Well, what it tells me is that it's highly robot centric.
[00:29:37.700 --> 00:29:38.820]   They're manufacturing.
[00:29:38.820 --> 00:29:42.340]   And so, I think the best case scenario is they've got a way
[00:29:42.340 --> 00:29:44.940]   where you go through and checkbox all these features you want.
[00:29:44.940 --> 00:29:45.780]   - Right.
[00:29:45.780 --> 00:29:47.500]   - And then futuristic robot-- - Assemble it.
[00:29:47.500 --> 00:29:49.380]   - Assemble it and mail it to you.
[00:29:49.380 --> 00:29:51.860]   - So we've been able to customize PCs for a long time.
[00:29:51.860 --> 00:29:52.900]   So is it gonna be like that?
[00:29:52.900 --> 00:29:55.460]   How much RAM, how much storage?
[00:29:55.460 --> 00:29:56.620]   - I hope so.
[00:29:56.620 --> 00:29:59.740]   - Supposedly the color of the case is engraving.
[00:29:59.740 --> 00:30:01.260]   - They say engraving.
[00:30:01.260 --> 00:30:02.460]   - I hope it's not just engraving, though.
[00:30:02.460 --> 00:30:06.780]   I mean, it's supposed to have a Snapdragon 800 in it,
[00:30:06.780 --> 00:30:07.620]   so it'll be fast.
[00:30:07.620 --> 00:30:08.460]   - That's supposed to have a great camera.
[00:30:08.460 --> 00:30:09.620]   - That's the most famous Snapdragon very fast.
[00:30:09.620 --> 00:30:12.620]   It's supposed to be cheap.
[00:30:12.620 --> 00:30:14.620]   It'll probably be very Google Now centric.
[00:30:14.620 --> 00:30:16.620]   - I hear some reports saying mid-range,
[00:30:16.620 --> 00:30:20.620]   which means not Galaxy S4, HTC One, iPhone.
[00:30:20.620 --> 00:30:21.620]   - Do you know what the radios are?
[00:30:21.620 --> 00:30:22.620]   - No.
[00:30:22.620 --> 00:30:23.620]   - We don't know anything about it.
[00:30:23.620 --> 00:30:24.620]   - So I'm wondering if they--
[00:30:24.620 --> 00:30:25.620]   - If we did, we couldn't tell you.
[00:30:25.620 --> 00:30:29.620]   - So Nvidia showed off when they were doing their little demo
[00:30:29.620 --> 00:30:31.620]   they were talking about their next GPU.
[00:30:31.620 --> 00:30:33.620]   - The Tegra 4, would it be?
[00:30:33.620 --> 00:30:34.620]   - The Tegra 4 chip.
[00:30:34.620 --> 00:30:37.620]   But before that, they were talking about their new radio
[00:30:37.620 --> 00:30:40.620]   and they were actually a CPU that was reprogrammable.
[00:30:40.620 --> 00:30:41.620]   - Soft.
[00:30:41.620 --> 00:30:43.620]   - So it was a soft modem that you could essentially
[00:30:43.620 --> 00:30:44.620]   tweak for whatever.
[00:30:44.620 --> 00:30:45.620]   - Well, there you go.
[00:30:45.620 --> 00:30:48.620]   So then maybe the firmware says, "Okay, where are you?
[00:30:48.620 --> 00:30:50.620]   Okay, we're gonna customize it for that.
[00:30:50.620 --> 00:30:52.620]   What carrier are you gonna use?"
[00:30:52.620 --> 00:30:54.620]   - Well, if they really wanted to be revolutionary,
[00:30:54.620 --> 00:30:56.620]   because this is the thing that makes me think it's not about
[00:30:56.620 --> 00:30:59.620]   engraving and bright colors, we've heard some early people,
[00:30:59.620 --> 00:31:02.620]   early Motorola people saying this is gonna be life-changing
[00:31:02.620 --> 00:31:03.620]   for a lot of people.
[00:31:03.620 --> 00:31:04.620]   - Scoville said it was gonna be life-changing.
[00:31:04.620 --> 00:31:08.620]   - Yeah, so I'm thinking, so Scoville says a lot of things.
[00:31:08.620 --> 00:31:10.620]   - His life has changed daily.
[00:31:10.620 --> 00:31:13.620]   - Yes, he's really into changing lives.
[00:31:13.620 --> 00:31:19.620]   But to me, the darkest horse, the long shot here,
[00:31:19.620 --> 00:31:21.620]   is that they would build in mesh networking.
[00:31:21.620 --> 00:31:23.620]   So you know this project loon thing with the balloons?
[00:31:23.620 --> 00:31:25.620]   This is mesh networking where they relay,
[00:31:25.620 --> 00:31:29.620]   where each Wi-Fi net node is also relaying it in both directions.
[00:31:29.620 --> 00:31:33.620]   So imagine if a cell phone could be a Wi-Fi hotspot
[00:31:33.620 --> 00:31:35.620]   or a connectivity option.
[00:31:35.620 --> 00:31:37.620]   It's very unlikely.
[00:31:37.620 --> 00:31:38.620]   Don't quote me on this.
[00:31:38.620 --> 00:31:39.620]   - 'Cause of the privacy issues alone,
[00:31:39.620 --> 00:31:40.620]   I think you're gonna have trouble with that.
[00:31:40.620 --> 00:31:41.620]   - I'm just thinking of battery life.
[00:31:41.620 --> 00:31:42.620]   - Battery life?
[00:31:42.620 --> 00:31:43.620]   - You're sucking down like juice.
[00:31:43.620 --> 00:31:45.620]   - There's no way this would be the only radio.
[00:31:45.620 --> 00:31:46.620]   - You might be only on that light.
[00:31:46.620 --> 00:31:49.620]   - Right now Wi-Fi is not one of the big battery hogs
[00:31:49.620 --> 00:31:50.620]   on smartphones.
[00:31:50.620 --> 00:31:52.620]   - Yeah, but if you're sending out someone else's packets
[00:31:52.620 --> 00:31:55.620]   back and forth, you're always on.
[00:31:55.620 --> 00:31:58.620]   - Well, it would be a third option, third radio option
[00:31:58.620 --> 00:32:00.620]   after Wi-Fi and broadband.
[00:32:00.620 --> 00:32:02.620]   - Oh, what would be the advantage?
[00:32:02.620 --> 00:32:05.620]   So I have a connection and I can share it with everybody in here.
[00:32:05.620 --> 00:32:06.620]   - Exactly.
[00:32:06.620 --> 00:32:07.620]   What you do is you extend whatever the boundaries are
[00:32:07.620 --> 00:32:09.620]   of your connection and whatever that connection is,
[00:32:09.620 --> 00:32:11.620]   you extend those boundaries.
[00:32:11.620 --> 00:32:14.620]   And so maybe you're inside of a parking garage
[00:32:14.620 --> 00:32:17.620]   and you're having trouble getting some kind of signal.
[00:32:17.620 --> 00:32:18.620]   It would extend that.
[00:32:18.620 --> 00:32:19.620]   - Exactly.
[00:32:19.620 --> 00:32:21.620]   You'd blanket everywhere with signal.
[00:32:21.620 --> 00:32:22.620]   - Exactly.
[00:32:22.620 --> 00:32:24.620]   And this would be especially awesome in like remote areas.
[00:32:24.620 --> 00:32:27.620]   So imagine ballooning data to some remote village somewhere.
[00:32:27.620 --> 00:32:28.620]   - Right.
[00:32:28.620 --> 00:32:30.620]   - And then within the village, imagine if it continues.
[00:32:30.620 --> 00:32:31.620]   - Well, that's why loon makes a lot of sense.
[00:32:31.620 --> 00:32:32.620]   - Exactly.
[00:32:32.620 --> 00:32:35.620]   - But again, that's pure speculation, but I've always wondered
[00:32:35.620 --> 00:32:37.620]   why somebody didn't do something like that,
[00:32:37.620 --> 00:32:38.620]   because it's a fantastic--
[00:32:38.620 --> 00:32:40.620]   - Maraki was gonna do that.
[00:32:40.620 --> 00:32:41.620]   Remember the Maraki routers?
[00:32:41.620 --> 00:32:45.620]   They were originally, and then they got acquired by Cisco,
[00:32:45.620 --> 00:32:47.620]   I think, and then they became more commercial,
[00:32:47.620 --> 00:32:50.620]   but they were originally designed to do exactly that.
[00:32:50.620 --> 00:32:51.620]   I've got a Wi-Fi access spot.
[00:32:51.620 --> 00:32:52.620]   - Within an open spot.
[00:32:52.620 --> 00:32:53.620]   - Within an open spot within a neighborhood.
[00:32:53.620 --> 00:32:55.620]   I create a mesh.
[00:32:55.620 --> 00:32:56.620]   It's gonna happen.
[00:32:56.620 --> 00:32:57.620]   It's gonna happen.
[00:32:57.620 --> 00:32:59.620]   - In the meantime, I'm really mad at them,
[00:32:59.620 --> 00:33:02.620]   'cause I was all set to buy a phone, and now I can't buy a phone.
[00:33:02.620 --> 00:33:03.620]   - I know, you have to wait.
[00:33:03.620 --> 00:33:04.620]   You have to wait.
[00:33:04.620 --> 00:33:05.620]   What are you gonna do?
[00:33:05.620 --> 00:33:07.620]   - I just wonder if you guys have any thoughts about it.
[00:33:07.620 --> 00:33:10.620]   Google always has seemed to have this.
[00:33:10.620 --> 00:33:12.620]   They keep trying to get around the carriers.
[00:33:12.620 --> 00:33:14.620]   They keep trying to break people of subsidies.
[00:33:14.620 --> 00:33:17.620]   You've seen so many Nexus phones that are sold unlocked without
[00:33:17.620 --> 00:33:18.620]   subsidies.
[00:33:18.620 --> 00:33:19.620]   Hasn't really taken off.
[00:33:19.620 --> 00:33:22.620]   They're more political statements, I think, than products in many ways.
[00:33:22.620 --> 00:33:25.620]   I'm wondering now that Google is rolling out,
[00:33:25.620 --> 00:33:27.620]   it seems like the Google products from Motorola,
[00:33:27.620 --> 00:33:29.620]   not what was in the pipeline.
[00:33:29.620 --> 00:33:32.620]   Are they gonna try to do some other end runs around carriers?
[00:33:32.620 --> 00:33:33.620]   Or are they gonna play ball?
[00:33:33.620 --> 00:33:35.620]   - That's what mesh networking would do.
[00:33:35.620 --> 00:33:37.620]   That's one example of what they could do.
[00:33:37.620 --> 00:33:41.620]   - I wouldn't have to buy a 3G access or 4G access
[00:33:41.620 --> 00:33:42.620]   if I could get it from my friends.
[00:33:42.620 --> 00:33:45.620]   - Well, another alternative to that is, for example,
[00:33:45.620 --> 00:33:50.620]   in a lot of areas, AT&T is far better than the coverage is far better than T-Mobile,
[00:33:50.620 --> 00:33:52.620]   but T-Mobile might have a better--
[00:33:52.620 --> 00:33:54.620]   - Oh, so it would be cross-carrier even?
[00:33:54.620 --> 00:33:55.620]   - Well, no, that's not what I'm saying.
[00:33:55.620 --> 00:33:58.620]   What I'm saying is maybe T-Mobile would be more awesome if there were mesh networks
[00:33:58.620 --> 00:33:59.620]   everywhere you went in Petaluma.
[00:33:59.620 --> 00:34:01.620]   - It would be in their interest to do that, yeah.
[00:34:01.620 --> 00:34:05.620]   - You know, the weirdest one was that you could email,
[00:34:05.620 --> 00:34:09.620]   when you ordered online, you email a wallpaper and it comes with your wallpaper and stuff.
[00:34:09.620 --> 00:34:10.620]   - I don't care.
[00:34:10.620 --> 00:34:11.620]   - That's a big advantage.
[00:34:11.620 --> 00:34:13.620]   - I'm thinking about this aside.
[00:34:13.620 --> 00:34:14.620]   - I don't think that's gonna happen.
[00:34:14.620 --> 00:34:15.620]   - I think that's gonna happen.
[00:34:15.620 --> 00:34:16.620]   - Because then you're dependent.
[00:34:16.620 --> 00:34:17.620]   - A wallpaper?
[00:34:17.620 --> 00:34:18.620]   - Yeah, well, just doing the mesh.
[00:34:18.620 --> 00:34:19.620]   - Oh, the mesh, yeah.
[00:34:19.620 --> 00:34:20.620]   - You're dependent on other people and you're not getting good performance.
[00:34:20.620 --> 00:34:21.620]   You gotta make nice--
[00:34:21.620 --> 00:34:22.620]   - I gotta make friends.
[00:34:22.620 --> 00:34:23.620]   - I gotta get meshed.
[00:34:23.620 --> 00:34:25.620]   - Hey, you wanna mesh?
[00:34:25.620 --> 00:34:26.620]   Let's mesh, you and me.
[00:34:26.620 --> 00:34:27.620]   - Mesh buddies, Steve, be on a--
[00:34:27.620 --> 00:34:28.620]   - You wanna get coffees?
[00:34:28.620 --> 00:34:29.620]   - You wanna get coffees?
[00:34:29.620 --> 00:34:30.620]   - A mesh?
[00:34:30.620 --> 00:34:31.620]   (laughing)
[00:34:31.620 --> 00:34:34.620]   - You know, everybody wants Google.
[00:34:34.620 --> 00:34:36.620]   This is a classic, historically.
[00:34:36.620 --> 00:34:41.620]   Everybody wants Google to break these markets.
[00:34:41.620 --> 00:34:45.620]   You know, we wanted Google to buy the 700 MHz spectrum so they could break the cell industry.
[00:34:45.620 --> 00:34:46.620]   - Yeah.
[00:34:46.620 --> 00:34:50.620]   - We wanna gig a bit internet access to transform internet access.
[00:34:50.620 --> 00:34:53.620]   And Google, I think, is smart enough to move slowly.
[00:34:53.620 --> 00:34:56.620]   I think they agree, I think that's kind of their goal, but I think they also realize,
[00:34:56.620 --> 00:34:59.620]   hey, we live in the real world, we gotta be political about this.
[00:34:59.620 --> 00:35:01.620]   So we'll move a little bit slowly, but, uh--
[00:35:01.620 --> 00:35:04.620]   - They make their money from--
[00:35:04.620 --> 00:35:05.620]   And they'll say this.
[00:35:05.620 --> 00:35:06.620]   - They say that.
[00:35:06.620 --> 00:35:08.620]   - The more you use the internet, the more money we make.
[00:35:08.620 --> 00:35:09.620]   - Right, that's all they care about.
[00:35:09.620 --> 00:35:12.620]   - They're stuck with these dinosaurs.
[00:35:12.620 --> 00:35:14.620]   I mean, AT&T and all these companies just suck.
[00:35:14.620 --> 00:35:19.620]   They're horrible drains and breaks on the progress that Google's trying to make.
[00:35:19.620 --> 00:35:21.620]   So I think you're right, exactly Roger.
[00:35:21.620 --> 00:35:26.620]   I think that one way or another, they're gonna figure out how to make an end run around these carriers.
[00:35:26.620 --> 00:35:28.620]   They have to.
[00:35:28.620 --> 00:35:34.620]   - You know, it's not a directly related comment, but in light of the NSA and Prism all that,
[00:35:34.620 --> 00:35:37.620]   I mean, do you want Google to be the one?
[00:35:37.620 --> 00:35:40.620]   - You know, I trust them more than I trust.
[00:35:40.620 --> 00:35:45.620]   - I tweeted on the 4th of July, I said, in fact, I've still got it on my website.
[00:35:45.620 --> 00:35:52.620]   The internet defense fund was trying to get people aware of, you know, the NSA thing,
[00:35:52.620 --> 00:35:54.620]   and they were saying, "Let's raise money."
[00:35:54.620 --> 00:36:00.620]   And I was surprised, by far, the most responses I got is, "Why would you want to do that?"
[00:36:00.620 --> 00:36:02.620]   The internet defense league.org, by the way.
[00:36:02.620 --> 00:36:04.620]   Why would you want to do that?
[00:36:04.620 --> 00:36:10.620]   This is-- you'll change your tune when a church is blown up or a building is blown up by terrorists.
[00:36:10.620 --> 00:36:15.620]   I think the majority of Americans support the NSA spying.
[00:36:15.620 --> 00:36:20.620]   It's the geeks who watch this show, and I'm in a bubble who go, "What the heck?
[00:36:20.620 --> 00:36:23.620]   Everybody else is going right on."
[00:36:23.620 --> 00:36:25.620]   - You know, it's one of those things.
[00:36:25.620 --> 00:36:28.620]   You're keeping us safe.
[00:36:28.620 --> 00:36:30.620]   That's what they're saying.
[00:36:30.620 --> 00:36:34.620]   - Until something happens where that program is used directly at an individual,
[00:36:34.620 --> 00:36:38.620]   that person or a group of people, for them, it doesn't affect them.
[00:36:38.620 --> 00:36:40.620]   So it's like, "Why not?"
[00:36:40.620 --> 00:36:43.620]   - I think people think, "If you're not doing anything wrong, what are you going to worry about?"
[00:36:43.620 --> 00:36:46.620]   - And I think that's a result of a failure of our educational system.
[00:36:46.620 --> 00:36:47.620]   - I agree.
[00:36:47.620 --> 00:36:50.620]   - Because we don't understand the reason for the Fourth Amendment.
[00:36:50.620 --> 00:36:52.620]   That's the problem, fundamentally.
[00:36:52.620 --> 00:36:57.620]   And the other thing that we should be grappling with is, how do we transition from a physical age
[00:36:57.620 --> 00:37:00.620]   to a digital age, and what carries over, and what doesn't?
[00:37:00.620 --> 00:37:01.620]   - That's the big problem right now.
[00:37:01.620 --> 00:37:02.620]   - Exactly.
[00:37:02.620 --> 00:37:03.620]   The government says, "Nothing carries over."
[00:37:03.620 --> 00:37:05.620]   - Your mail is better protected than your phone calls.
[00:37:05.620 --> 00:37:06.620]   - Well, we just learned they're scanning that, too.
[00:37:06.620 --> 00:37:09.620]   They're scanning metadata of the actual envelopes and stuff like that.
[00:37:09.620 --> 00:37:10.620]   - Sorry.
[00:37:10.620 --> 00:37:12.620]   - They're not reading inside the inside.
[00:37:12.620 --> 00:37:14.620]   - No, they don't have to.
[00:37:14.620 --> 00:37:17.620]   - They just track where the mail goes.
[00:37:17.620 --> 00:37:22.620]   - Every organization that wants something politically will wait until something bad happens
[00:37:22.620 --> 00:37:27.620]   and they say, "Aha, now we have to have this thing that I've been calling for all along."
[00:37:27.620 --> 00:37:29.620]   - I think it's not just education.
[00:37:29.620 --> 00:37:34.620]   I think it's just society's answer to conflict is essentially to kind of
[00:37:34.620 --> 00:37:40.620]   hold up in these, for the lack of a better analogy, they're essentially gangs where you have
[00:37:40.620 --> 00:37:45.620]   groups of people with their set of ideologies, their set of beliefs.
[00:37:45.620 --> 00:37:52.620]   And if you don't jive with that particular set, then you're the enemy and then we'll do
[00:37:52.620 --> 00:37:55.620]   anything to hurt you, even if it hurts ourselves.
[00:37:55.620 --> 00:37:57.620]   Cut your nose despite your face.
[00:37:57.620 --> 00:38:02.620]   And I think we're at that point where we're, I mean, you just turn on any news program,
[00:38:02.620 --> 00:38:07.620]   you get a bunch of incredibly juvenile and sophomore debates going on.
[00:38:07.620 --> 00:38:09.620]   - That's why I don't do it.
[00:38:09.620 --> 00:38:11.620]   - Because that's what people are trained to do.
[00:38:11.620 --> 00:38:14.620]   That's kids watching on TVL, so that's how adults talk to each other.
[00:38:14.620 --> 00:38:16.620]   They talk like five-year-olds.
[00:38:16.620 --> 00:38:19.620]   You're an idiot, you're plant stupid, it's going to kill the world.
[00:38:19.620 --> 00:38:24.620]   It's one of those things where it's great for ratings, but in the end,
[00:38:24.620 --> 00:38:26.620]   it just kind of debases the entire conversation.
[00:38:26.620 --> 00:38:28.620]   - There's also a generational divide.
[00:38:28.620 --> 00:38:32.620]   I mean, when you talk about understanding this technology and what it means,
[00:38:32.620 --> 00:38:35.620]   we have a lot of judges who don't understand it.
[00:38:35.620 --> 00:38:37.620]   Most of Congress doesn't understand it.
[00:38:37.620 --> 00:38:40.620]   And a lot of people don't understand it.
[00:38:40.620 --> 00:38:45.620]   And, you know, maybe I'm being optimistic here, maybe I'm not sure.
[00:38:45.620 --> 00:38:47.620]   Help me out here.
[00:38:47.620 --> 00:38:51.620]   I keep thinking that down the road, somebody's going to realize that searching through all
[00:38:51.620 --> 00:38:56.620]   your files on your laptop or reading your email is no different from breaking into your house
[00:38:56.620 --> 00:39:01.620]   without a warrant and searching through your stuff, which we would never allow and is clearly unconstitutional.
[00:39:01.620 --> 00:39:07.620]   The problem is that the people who want to do that can get away with it now because everybody else
[00:39:07.620 --> 00:39:10.620]   doesn't really understand what's going on because they're not thinking of it.
[00:39:10.620 --> 00:39:11.620]   It's too abstract for them.
[00:39:11.620 --> 00:39:16.620]   - I tell you, if I ran the NSA, I would want everything handed to me on a silver card.
[00:39:16.620 --> 00:39:17.620]   - Absolutely.
[00:39:17.620 --> 00:39:18.620]   - I would say, yeah.
[00:39:18.620 --> 00:39:19.620]   - Courts are inconvenient.
[00:39:19.620 --> 00:39:21.620]   - Even my budget is classified.
[00:39:21.620 --> 00:39:26.620]   I can spend gazillions of dollars building these huge data centers and record every phone call,
[00:39:26.620 --> 00:39:29.620]   build a time machine and go back in time and record all those phone calls to...
[00:39:29.620 --> 00:39:30.620]   - What the heck?
[00:39:30.620 --> 00:39:31.620]   - I would want that.
[00:39:31.620 --> 00:39:32.620]   And I'm a good person.
[00:39:32.620 --> 00:39:33.620]   I trust myself.
[00:39:33.620 --> 00:39:38.620]   - That's exactly the conversation I had with somebody who's a law enforcement official on Twitter.
[00:39:38.620 --> 00:39:44.620]   Back and forth, his first tweet to me was, "NSA Minds Data to Protect You and You Protect.
[00:39:44.620 --> 00:39:47.620]   Google Minds Data to Sell Ads and you're okay with it."
[00:39:47.620 --> 00:39:48.620]   - Yes.
[00:39:48.620 --> 00:39:49.620]   - And I said, "Yes."
[00:39:49.620 --> 00:39:50.620]   - Wait a minute.
[00:39:50.620 --> 00:39:55.620]   And we went back and forth a little bit and he finally said, "Well, I guess it's because I'm a peace officer,
[00:39:55.620 --> 00:39:59.620]   but I think it's more important to have...
[00:39:59.620 --> 00:40:04.620]   I guess because I work in public safety, I don't share your tin foil conspiracy view of government.
[00:40:04.620 --> 00:40:07.620]   You can't have 100% safety and privacy."
[00:40:07.620 --> 00:40:13.620]   - But a policeman, if allowed to make the decisions entirely without considering other considerations
[00:40:13.620 --> 00:40:16.620]   would get rid of Miranda, they would get rid of...
[00:40:16.620 --> 00:40:17.620]   - Just get in their way.
[00:40:17.620 --> 00:40:21.620]   - And they're the ones who said that Miranda would destroy all law enforcement, which didn't happen.
[00:40:21.620 --> 00:40:22.620]   - Exactly.
[00:40:22.620 --> 00:40:23.620]   And I understand that point of view.
[00:40:23.620 --> 00:40:27.620]   If your goal is to, "I want to stop crime," these things slow me down.
[00:40:27.620 --> 00:40:33.620]   - They use terror and they use secrecy as a way to avoid the whole debate about tradeoffs.
[00:40:33.620 --> 00:40:36.620]   I mean, they're actually damaging Silicon Valley with this NSA thing.
[00:40:36.620 --> 00:40:42.620]   I mean, what gave them the right to say that the war on terror and making it more convenient
[00:40:42.620 --> 00:40:50.620]   and giving us more abilities in fighting terrorism is worth sacrificing the credibility of Silicon Valley.
[00:40:50.620 --> 00:40:53.620]   I mean, Europe is outraged that if you...
[00:40:53.620 --> 00:40:57.620]   Americans are like, "Oh, we're protected by the Constitution, not supposed to be spying on Americans."
[00:40:57.620 --> 00:41:00.620]   Europeans are like, "Wait a minute. We all use Facebook, too."
[00:41:00.620 --> 00:41:01.620]   - Yeah.
[00:41:01.620 --> 00:41:03.620]   - So you're not even arguing about whether it's okay to spy on us.
[00:41:03.620 --> 00:41:07.620]   - You know, what really bugs me is the false analogy with social networking, sharing, and spying,
[00:41:07.620 --> 00:41:10.620]   where people say, "And this is a version of your give-and-take Leo
[00:41:10.620 --> 00:41:16.620]   with that public safety officer," is, "Oh, well, people are so worried about the government looking at their stuff,
[00:41:16.620 --> 00:41:19.620]   but they share their photos on Twitter and Facebook."
[00:41:19.620 --> 00:41:24.620]   It's like, "We choose to share some things. Other things we choose not to.
[00:41:24.620 --> 00:41:28.620]   They're not related at all." And yet that's a legitimate argument that people are trying to make.
[00:41:28.620 --> 00:41:33.620]   - It's not an understanding. One is something that someone can opt in or not opt out of.
[00:41:33.620 --> 00:41:37.620]   Like, "I don't have to use Facebook. I don't have to use Google or any of their services."
[00:41:37.620 --> 00:41:39.620]   - That's kind of what I said to him.
[00:41:39.620 --> 00:41:45.620]   He said, "No, there's no opt out for Google that were enacted whether or not I agree."
[00:41:45.620 --> 00:41:50.620]   - The opt out is, "Don't visit it. Use DuckDuckGo or a virtual."
[00:41:50.620 --> 00:41:52.620]   - And where's my opt out for the NSA?
[00:41:52.620 --> 00:41:53.620]   - Yeah, there is no opt out.
[00:41:53.620 --> 00:41:57.620]   - So, but my point is that we are preaching to the choir. I think everybody lives on the show.
[00:41:57.620 --> 00:42:00.620]   I think all of us agree. I think everybody in the studio audience understands, at least.
[00:42:00.620 --> 00:42:05.620]   They may be people say, "Well, I'm willing to give up some privacy because we need security."
[00:42:05.620 --> 00:42:09.620]   But I think the general public to answer this is going back to what you were talking about, Roger.
[00:42:09.620 --> 00:42:13.620]   They don't care. And I think they feel like, "Hey, it makes us safe. I'm terrified.
[00:42:13.620 --> 00:42:18.620]   I'm really worried about another 9/11, and this is worth it."
[00:42:18.620 --> 00:42:23.620]   - I just feel it's those two things. It's that combination of it's fear, but it's also not understanding the technology.
[00:42:23.620 --> 00:42:28.620]   And that's a powerful combination because fear is always going to be an issue where people are afraid of the next attack.
[00:42:28.620 --> 00:42:30.620]   - So, we do what we can. - They also don't understand the technology.
[00:42:30.620 --> 00:42:33.620]   - We then need to do what we can to explain the technology.
[00:42:33.620 --> 00:42:36.620]   - Right. But you're right, we are kind of in a bubble. - We are kind of in a bubble.
[00:42:36.620 --> 00:42:42.620]   - I haven't explained the consequences. I mean, when taxes go up and the price of gasoline goes up,
[00:42:42.620 --> 00:42:44.620]   people, it affects their wallet directly.
[00:42:44.620 --> 00:42:51.620]   When their school shut down, their kids have to get bused off to another district, that affects them.
[00:42:51.620 --> 00:43:00.620]   But if it's something very abstract, what you were touching on is that it takes a while until something hits them directly until they appreciate...
[00:43:00.620 --> 00:43:04.620]   - Right. Until your Martin Luther King and Jake or Hoover's been collecting the dossier on you.
[00:43:04.620 --> 00:43:09.620]   - Which is why it might take some time for more people to become technically savvy enough to say,
[00:43:09.620 --> 00:43:12.620]   "Hey, wait a second." Or there'll be a big news story.
[00:43:12.620 --> 00:43:17.620]   I mean, the fact that the US government stops a lot of people at the borders, American citizens coming into the country,
[00:43:17.620 --> 00:43:21.620]   - And we were fine. - It says we are going to look at every file on your hard drive,
[00:43:21.620 --> 00:43:26.620]   - Right. - and if you don't decrypt with your passwords, we can hold you or not allow you back in the country.
[00:43:26.620 --> 00:43:29.620]   I mean, I think that's outrageous, but it's just not registering yet.
[00:43:29.620 --> 00:43:31.620]   - Right. - Maybe you will.
[00:43:31.620 --> 00:43:38.620]   - That's right. That's why I think Google, to a certain extent, Facebook, the models that they have in terms of showing you what they know about you is a good one.
[00:43:38.620 --> 00:43:43.620]   So for example, if you use Google Attitude, you can go there and say, "Show me what you know about where I've been."
[00:43:43.620 --> 00:43:45.620]   - And it shares a map where... - Love that.
[00:43:45.620 --> 00:43:51.620]   - Where have you been? And if you feel creeped out by that, you can take action, turn stuff off and do things.
[00:43:51.620 --> 00:43:54.620]   Same thing with Facebook tells you what apps you're connected with and what those are doing,
[00:43:54.620 --> 00:43:57.620]   and you can just sort of opt out of those in the spot.
[00:43:57.620 --> 00:44:05.620]   We need something like that. I mean, I think it's never going to happen, but that would be a good first step to know what it is that they know.
[00:44:05.620 --> 00:44:08.620]   Because right now, it's who knows.
[00:44:08.620 --> 00:44:16.620]   The other thing is everybody's talking about Apple made a big deal about the fact that they can't, or they claim that they can't decrypt their own messaging.
[00:44:16.620 --> 00:44:20.620]   - That's an interesting story. - And everybody said, "Yeah, the NSA can't decrypt that."
[00:44:20.620 --> 00:44:23.620]   And my first thought is really, you know that? How do you know that?
[00:44:23.620 --> 00:44:28.620]   This is an agency that exists to decrypt things secretly in ways that nobody knows.
[00:44:28.620 --> 00:44:31.620]   - They have supercomputers, even if they wanted to.
[00:44:31.620 --> 00:44:34.620]   - And there's even reasons to doubt what Apple said in general.
[00:44:34.620 --> 00:44:37.620]   - Well, whether Apple was completely honest.
[00:44:37.620 --> 00:44:43.620]   - Exactly, but nobody that I've heard can rightly claim that they know what the NSA is capable of.
[00:44:43.620 --> 00:44:50.620]   - Then I think that kind of brings light of the whole, just kind of focuses the entire discussion on, "We don't know.
[00:44:50.620 --> 00:44:53.620]   The problem is everything's in secret. They're secret course, they're secret laws."
[00:44:53.620 --> 00:45:01.620]   - And if you should be one of those people that helps people understand or know about it, you might just be running to Ecuador right about now, or where is he going? Bolivia.
[00:45:01.620 --> 00:45:03.620]   - Venezuela. - Venezuela.
[00:45:03.620 --> 00:45:07.620]   - Everyone wants to get... - Because he doesn't want to live in a surveillance society, so he's going to...
[00:45:07.620 --> 00:45:09.620]   - Is that ironic? The choices he had open to him were not there?
[00:45:09.620 --> 00:45:11.620]   - It's because he didn't think it through.
[00:45:11.620 --> 00:45:13.620]   - It seems to me... - I'm going to plan this better.
[00:45:13.620 --> 00:45:15.620]   - He had to pretend that Edward Snowden, obviously.
[00:45:15.620 --> 00:45:21.620]   - Yes, he had a full house and he just blew it straight up without necessarily making...
[00:45:21.620 --> 00:45:24.620]   - I don't know, and I'm really trying to figure this out, because this was not a dumb guy.
[00:45:24.620 --> 00:45:30.620]   He had people come visit him, take their cell phones, put him in the fridge, which is very clever.
[00:45:30.620 --> 00:45:34.620]   Because the metal in the fridge was keeping the cell phone from broadcasting.
[00:45:34.620 --> 00:45:37.620]   - He might be smart, but he might be incredibly naive too.
[00:45:37.620 --> 00:45:41.620]   - Or, well, first of all, he could have been deep throat and done this completely anonymously.
[00:45:41.620 --> 00:45:46.620]   I think he decided that it was better that he not do this anonymously so he could be vetted, right?
[00:45:46.620 --> 00:45:49.620]   - Yeah. - Okay, this guy maybe does know what he's saying.
[00:45:49.620 --> 00:45:51.620]   So he had to put himself on the line a little bit.
[00:45:51.620 --> 00:45:53.620]   He chose to do it in Hong Kong.
[00:45:53.620 --> 00:45:58.620]   - It's just very... - Are you saying he should have had a way out?
[00:45:58.620 --> 00:46:07.620]   - The problem is everything he's done up since he's disclosed the whole prism thing is that it just makes him look shadier and shadier.
[00:46:07.620 --> 00:46:12.620]   - Right, Putin doesn't want him to kick him out as quickly as possible off Russian soil.
[00:46:12.620 --> 00:46:15.620]   - And you're too shady for Putin. - Yeah, well, that's not...
[00:46:15.620 --> 00:46:17.620]   - That's a shame. - That is shame.
[00:46:17.620 --> 00:46:26.620]   - I mean, you know what I mean? - Suddenly you have this kind of shroud of people just questioning, well, what is this motive?
[00:46:26.620 --> 00:46:29.620]   - Yeah, but there was going to be character assassination against this guy regardless.
[00:46:29.620 --> 00:46:33.620]   - But he's thinking it was going to be, no matter who it was, they were going to find the Easter.
[00:46:33.620 --> 00:47:03.620]   - He's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's not, he's
[00:47:03.620 --> 00:47:07.620]   - And you take your licks? - I don't know, man.
[00:47:07.620 --> 00:47:10.620]   - It's hard to say that. - It's hard to say that.
[00:47:10.620 --> 00:47:14.620]   - I think ultimately it doesn't... I'm really glad that he did what he did.
[00:47:14.620 --> 00:47:18.620]   I don't think we know what his motives are, whether he's a good guy, bad guy, whatever.
[00:47:18.620 --> 00:47:21.620]   I don't think it really matters. He did what he did and now we're having these conversations.
[00:47:21.620 --> 00:47:26.620]   It's all kind of... It's not out in the open, but at least we're trying to find out what's going on.
[00:47:26.620 --> 00:47:30.620]   So that's a good thing. But I think that his... I wouldn't want to be him.
[00:47:30.620 --> 00:47:33.620]   - Then as well, it's very nice. - I'll be honest, I'm grateful to him.
[00:47:33.620 --> 00:47:36.620]   - Yeah, absolutely. - But who knows?
[00:47:36.620 --> 00:47:39.620]   I mean, I think he'll have a Wikipedia page.
[00:47:39.620 --> 00:47:43.620]   We'll kind of all forget about him and we'll never forget about this whole NSA thing.
[00:47:43.620 --> 00:47:45.620]   - It needed to be said. - Yeah.
[00:47:45.620 --> 00:47:49.620]   - And I think that this... I think he is a whistleblower in the best sense of the word.
[00:47:49.620 --> 00:47:54.620]   And it's funny because it's been going for a month and it's every week what's what we talk about.
[00:47:54.620 --> 00:48:00.620]   And it really has, I think, rattled a lot of us in the tech community more than we care to admit.
[00:48:00.620 --> 00:48:03.620]   Because we understand the power of Big Data.
[00:48:03.620 --> 00:48:07.620]   I think we understand it. - Big Data is... It's the big trend right now.
[00:48:07.620 --> 00:48:14.620]   We have the processing power and the bandwidth to do phenomenal things and to find out amazing amounts of stuff.
[00:48:14.620 --> 00:48:20.620]   And there is no big data than all communication, like storing it and saving it for later so that when you...
[00:48:20.620 --> 00:48:24.620]   And then harvesting the metadata, just to be very, very clear in case people don't understand what's happening.
[00:48:24.620 --> 00:48:32.620]   The harvest metadata of everybody, everything you do, every email, every text, every phone call, everything.
[00:48:32.620 --> 00:48:37.620]   They, you know, they want... Who you calling, how long they call last, all this metadata.
[00:48:37.620 --> 00:48:40.620]   And they're hunting for suspicious activity.
[00:48:40.620 --> 00:48:44.620]   When they find it, they go back to their recording of your actual phone call.
[00:48:44.620 --> 00:48:48.620]   They get a warrant and then they bust you.
[00:48:48.620 --> 00:48:51.620]   I mean, this is like, this is like the Orwellian nightmare.
[00:48:51.620 --> 00:48:52.620]   It's Orwellian.
[00:48:52.620 --> 00:49:02.620]   The fact that they can... It's the equivalent of preemptive body cavity and home searches of everybody, every day, in case they find anything.
[00:49:02.620 --> 00:49:06.620]   Wasn't that one of the main plot points of Minority Report?
[00:49:06.620 --> 00:49:08.620]   Exactly. You arrest someone who didn't pre-crime.
[00:49:08.620 --> 00:49:09.620]   They will.
[00:49:09.620 --> 00:49:13.620]   And that's what it's just for. That's what anti-terrorism is. It's pre-crime.
[00:49:13.620 --> 00:49:17.620]   They're trying to stop crimes, terrorist attacks before they happen.
[00:49:17.620 --> 00:49:25.620]   And if you don't have, like, psychic twins floating around in a hot tub, you need something.
[00:49:25.620 --> 00:49:27.620]   This is better than psychic clues.
[00:49:27.620 --> 00:49:29.620]   It's more expensive, though.
[00:49:29.620 --> 00:49:31.620]   And then you have a nice one.
[00:49:31.620 --> 00:49:33.620]   Hey, those twins have gotta eat.
[00:49:33.620 --> 00:49:38.620]   But when Obama says we're not listening to your phone calls, or David Simon writes his blog post,
[00:49:38.620 --> 00:49:42.620]   a very smart guy saying, who did the wire, saying, well, they're not listening to the calls,
[00:49:42.620 --> 00:49:44.620]   and, you know, we got all that information.
[00:49:44.620 --> 00:49:49.620]   The metadata tells you so much that in some ways you don't need to listen to the call,
[00:49:49.620 --> 00:49:51.620]   and if you've got the call recorded, you can go on with it.
[00:49:51.620 --> 00:49:55.620]   If you remember Zero Dark 30, they identified this guy as an Obama -- I mean,
[00:49:55.620 --> 00:49:56.620]   Obama -- excuse me.
[00:49:56.620 --> 00:49:58.620]   I hate that error.
[00:49:58.620 --> 00:50:01.620]   And I've never made it before, and I was proud of myself for making it.
[00:50:01.620 --> 00:50:08.620]   So they identified him as a courier for Osama bin Laden because he called his mother from different locations.
[00:50:08.620 --> 00:50:12.620]   That's all it took for them to really suspect this person.
[00:50:12.620 --> 00:50:15.620]   I mean, that's pretty flimsy metadata.
[00:50:15.620 --> 00:50:17.620]   And they figured it out.
[00:50:17.620 --> 00:50:19.620]   And without computers.
[00:50:19.620 --> 00:50:23.620]   I mean, it's literally a map of the -- if you assume that most people are using cell phones now,
[00:50:23.620 --> 00:50:28.620]   which is true, it's literally a map of every personal relationship that everybody has with everybody else.
[00:50:28.620 --> 00:50:31.620]   All of them, if you use a telephone at all.
[00:50:31.620 --> 00:50:32.620]   Right.
[00:50:32.620 --> 00:50:36.620]   And you can make the linkages from A to B to C to D in a --
[00:50:36.620 --> 00:50:37.620]   Absolutely.
[00:50:37.620 --> 00:50:38.620]   -- six degrees of separation.
[00:50:38.620 --> 00:50:39.620]   And one of those supercomputers, yeah.
[00:50:39.620 --> 00:50:40.620]   Right.
[00:50:40.620 --> 00:50:41.620]   Absolutely.
[00:50:41.620 --> 00:50:42.620]   But we're safe.
[00:50:42.620 --> 00:50:43.620]   I want one.
[00:50:43.620 --> 00:50:44.620]   Whoo.
[00:50:44.620 --> 00:50:45.620]   Are we?
[00:50:45.620 --> 00:50:46.620]   Well, you can't prove otherwise.
[00:50:46.620 --> 00:50:47.620]   I don't know how to say it.
[00:50:47.620 --> 00:50:48.620]   That's the thing.
[00:50:48.620 --> 00:50:49.620]   That's the thing.
[00:50:49.620 --> 00:50:51.620]   If you look at all these attacks that didn't happen, it's not proof of anything.
[00:50:51.620 --> 00:50:52.620]   It's safety the goal.
[00:50:52.620 --> 00:50:56.620]   I mean, you know, the whole purpose of the al-Qaeda is to get rid of our freedoms.
[00:50:56.620 --> 00:50:57.620]   They've succeeded.
[00:50:57.620 --> 00:50:58.620]   And they've succeeded.
[00:50:58.620 --> 00:50:59.620]   That's what I've been saying.
[00:50:59.620 --> 00:51:00.620]   The terrorists won.
[00:51:00.620 --> 00:51:01.620]   This is a clear victory.
[00:51:01.620 --> 00:51:02.620]   That's very sad.
[00:51:02.620 --> 00:51:04.620]   We're going to take a break.
[00:51:04.620 --> 00:51:08.620]   We'll talk a little bit about a big event Apple held this week.
[00:51:08.620 --> 00:51:12.620]   I don't know if you know more about the Tim Cook talk at Fort Mason.
[00:51:12.620 --> 00:51:15.620]   I think there's people in the audience who might have been there.
[00:51:15.620 --> 00:51:16.620]   I don't know.
[00:51:16.620 --> 00:51:17.620]   Watch them carefully.
[00:51:17.620 --> 00:51:18.620]   Maybe we can collect some metadata.
[00:51:18.620 --> 00:51:19.620]   That'd be great.
[00:51:19.620 --> 00:51:20.620]   Okay.
[00:51:20.620 --> 00:51:21.620]   Be great.
[00:51:21.620 --> 00:51:22.620]   Meanwhile.
[00:51:22.620 --> 00:51:25.620]   I had the worst call on the radio show.
[00:51:25.620 --> 00:51:26.620]   Oh, my gosh.
[00:51:26.620 --> 00:51:30.620]   I almost -- she burst into tears yesterday.
[00:51:30.620 --> 00:51:37.620]   She said my dad passed away and I had been sitting in his bedside writing down everything
[00:51:37.620 --> 00:51:41.620]   that he said for a couple of years and Microsoft works, lost it.
[00:51:41.620 --> 00:51:42.620]   I said, oh, yeah.
[00:51:42.620 --> 00:51:43.620]   Microsoft works.
[00:51:43.620 --> 00:51:44.620]   Yeah, works.
[00:51:44.620 --> 00:51:47.620]   I inadvertently saved a blank document on top of it.
[00:51:47.620 --> 00:51:48.620]   And I said, did you back up?
[00:51:48.620 --> 00:51:49.620]   She said, what?
[00:51:49.620 --> 00:51:50.620]   No.
[00:51:50.620 --> 00:51:53.620]   And I just -- I just really -- every time I get a call like that, it just hits me.
[00:51:53.620 --> 00:51:56.620]   How important backing up your data is.
[00:51:56.620 --> 00:51:59.620]   And so many people don't do it because it's hard.
[00:51:59.620 --> 00:52:00.620]   Sometimes you do it.
[00:52:00.620 --> 00:52:02.620]   I asked my dad, do you back up?
[00:52:02.620 --> 00:52:05.620]   And he said, yeah, every once in a while I'll take a USB key and I'll stick it in there
[00:52:05.620 --> 00:52:06.620]   and copy some files over.
[00:52:06.620 --> 00:52:07.620]   So how often do you do that?
[00:52:07.620 --> 00:52:13.700]   He said, well, whenever I think of it, I guarantee you, whenever you think of it is right after
[00:52:13.700 --> 00:52:16.220]   you lose all your data.
[00:52:16.220 --> 00:52:18.020]   So what you need is a backup solution.
[00:52:18.020 --> 00:52:20.380]   And what I've got for you is really the right way to do it.
[00:52:20.380 --> 00:52:22.820]   It's automatic so you don't have to remember it.
[00:52:22.820 --> 00:52:23.820]   It's continuous.
[00:52:23.820 --> 00:52:26.060]   Whenever you're on the Internet, it's backing up.
[00:52:26.060 --> 00:52:29.980]   It is, by the way, and I want to emphasize this, if you want, it is trust no one.
[00:52:29.980 --> 00:52:36.580]   So carbonite will allow you to generate public keys, private keys, and encrypt your data
[00:52:36.580 --> 00:52:39.580]   so that no one, not even carbonite has that key.
[00:52:39.580 --> 00:52:42.900]   Now you lose some capabilities as you would have to if you do something like this.
[00:52:42.900 --> 00:52:45.780]   And I just want to emphasize that one of the things carbonite does let you do is look
[00:52:45.780 --> 00:52:47.700]   at your cloud data from any computer.
[00:52:47.700 --> 00:52:51.580]   You can log on to your carbonite account, get individual files, email those files to
[00:52:51.580 --> 00:52:52.580]   somebody else.
[00:52:52.580 --> 00:52:56.660]   They have apps for the smartphone and the tablet and the Android.
[00:52:56.660 --> 00:52:59.220]   That won't work if you use the TNO encryption.
[00:52:59.220 --> 00:53:01.340]   So I think a lot of people don't.
[00:53:01.340 --> 00:53:02.340]   It's up to you.
[00:53:02.340 --> 00:53:03.340]   And that's the point.
[00:53:03.340 --> 00:53:05.740]   Carbonite is safe, secure backup.
[00:53:05.740 --> 00:53:07.820]   It uses SSL.
[00:53:07.820 --> 00:53:13.500]   So even if you're at an open access spot, the backup is completely secure.
[00:53:13.500 --> 00:53:15.220]   And that's the price.
[00:53:15.220 --> 00:53:17.340]   It starts at $59.99 a year.
[00:53:17.340 --> 00:53:21.460]   That is less than $5 a month for everything on your hard drive.
[00:53:21.460 --> 00:53:26.260]   If you're a business, there could be no more important thing to do than backup your data.
[00:53:26.260 --> 00:53:28.540]   Imagine a fire in your place of business.
[00:53:28.540 --> 00:53:29.540]   You lose your data.
[00:53:29.540 --> 00:53:31.900]   You lose the backups sitting next to the computer.
[00:53:31.900 --> 00:53:33.540]   Now do you have your accounts receivable?
[00:53:33.540 --> 00:53:35.180]   Do you have your client list?
[00:53:35.180 --> 00:53:36.420]   Do you have your supplier list?
[00:53:36.420 --> 00:53:37.500]   Can you get back in business?
[00:53:37.500 --> 00:53:39.060]   How long is that going to take?
[00:53:39.060 --> 00:53:40.540]   You got a backup to get it back.
[00:53:40.540 --> 00:53:42.540]   So do it right with carbonite.
[00:53:42.540 --> 00:53:48.820]   Flat rate plans for home, for office, for business, for Mac and Windows.
[00:53:48.820 --> 00:53:50.860]   And it starts at $59.99 a year.
[00:53:50.860 --> 00:53:53.420]   I want you to try it free for two weeks.
[00:53:53.420 --> 00:53:56.340]   Use our offer code TWIT and you'll get two weeks without a credit card.
[00:53:56.340 --> 00:53:58.380]   Just try it.
[00:53:58.380 --> 00:54:02.900]   If you decide to buy and only at that time, you'll use the credit card and then you'll
[00:54:02.900 --> 00:54:06.740]   get two bonus months with purchase, 14 months for the price of 12.
[00:54:06.740 --> 00:54:08.180]   You got to back it up to get it back.
[00:54:08.180 --> 00:54:10.620]   Please, I don't want to get a crying phone call.
[00:54:10.620 --> 00:54:16.980]   It was heart wrenching from anybody saying, I lost my data because I got to give her the
[00:54:16.980 --> 00:54:18.660]   bad news.
[00:54:18.660 --> 00:54:19.820]   It's gone.
[00:54:19.820 --> 00:54:21.780]   It's gone.
[00:54:21.780 --> 00:54:26.060]   And then I really don't want to spank her and say, and you should have backed it up.
[00:54:26.060 --> 00:54:28.380]   I'm thinking, why don't you have a backup?
[00:54:28.380 --> 00:54:29.740]   This is so valuable to you.
[00:54:29.740 --> 00:54:32.460]   I got a call once from a guy who lost his phone.
[00:54:32.460 --> 00:54:33.900]   He said, my dog died three years ago.
[00:54:33.900 --> 00:54:37.220]   The only pictures I have of the dog were on that phone and I lost the phone.
[00:54:37.220 --> 00:54:39.980]   I can't help you too late.
[00:54:39.980 --> 00:54:40.980]   Back it up.
[00:54:40.980 --> 00:54:42.220]   That's the only way.
[00:54:42.220 --> 00:54:44.420]   You have to embrace the power of negative thinking.
[00:54:44.420 --> 00:54:46.140]   Yeah, you have to play in for disaster.
[00:54:46.140 --> 00:54:47.820]   What horrible thing could happen.
[00:54:47.820 --> 00:54:51.460]   See, I don't have a problem with that because I always think of the worst.
[00:54:51.460 --> 00:54:53.780]   Yeah, I'm a very negative person.
[00:54:53.780 --> 00:54:55.700]   It's very helpful.
[00:54:55.700 --> 00:54:58.980]   My ex-wife was a psychotherapist and said, you have disaster mentality.
[00:54:58.980 --> 00:55:03.540]   I said, yes, I always think of, oh, the tire's going to blow.
[00:55:03.540 --> 00:55:04.540]   What am I?
[00:55:04.540 --> 00:55:07.820]   As I'm driving down the highway, I go, OK, now when I have the blowout, I'm going to
[00:55:07.820 --> 00:55:09.900]   lean into the skid.
[00:55:09.900 --> 00:55:11.180]   And I'm thinking this.
[00:55:11.180 --> 00:55:13.580]   If that guy leans, do you do that, Roger?
[00:55:13.580 --> 00:55:15.340]   You seem like a kind of glum guss.
[00:55:15.340 --> 00:55:16.340]   Yeah, you seem really--
[00:55:16.340 --> 00:55:17.340]   Yeah, I mean, it's--
[00:55:17.340 --> 00:55:18.340]   Debbie Downer.
[00:55:18.340 --> 00:55:21.900]   It's more like, you know, if I'm going to go, make sure everything is taken care of.
[00:55:21.900 --> 00:55:22.900]   Oh, that's interesting.
[00:55:22.900 --> 00:55:25.100]   So if you give in your passwords and your social--
[00:55:25.100 --> 00:55:27.700]   No, I don't want anyone accessing anything.
[00:55:27.700 --> 00:55:29.060]   You know, Google now has this thing.
[00:55:29.060 --> 00:55:31.020]   I actually have Patrick Norton.
[00:55:31.020 --> 00:55:32.020]   I'm authorized--
[00:55:32.020 --> 00:55:33.020]   You trust Patrick.
[00:55:33.020 --> 00:55:35.580]   I'm authorizing him to demolish my PC if my time is--
[00:55:35.580 --> 00:55:36.580]   With a sledgehammer.
[00:55:36.580 --> 00:55:37.580]   Something.
[00:55:37.580 --> 00:55:38.580]   You know what?
[00:55:38.580 --> 00:55:39.580]   Can I sign him up for that, too?
[00:55:39.580 --> 00:55:40.580]   Sure.
[00:55:40.580 --> 00:55:42.260]   I would trust him and his sledgehammer.
[00:55:42.260 --> 00:55:43.940]   That is a guy you can count on.
[00:55:43.940 --> 00:55:45.700]   You come in and you destroy the whole thing.
[00:55:45.700 --> 00:55:47.340]   And he'd love doing it every minute of it.
[00:55:47.340 --> 00:55:49.340]   He would be crying, but he would be--
[00:55:49.340 --> 00:55:50.340]   Yeah, he would be crying.
[00:55:50.340 --> 00:55:51.340]   You'd be crying.
[00:55:51.340 --> 00:55:53.140]   I miss you, Roger, but tears on the sledgehammer.
[00:55:53.140 --> 00:55:54.140]   Yeah.
[00:55:54.140 --> 00:56:00.340]   It's like John Goodman in the big Lebowski smashing that car,
[00:56:00.340 --> 00:56:04.460]   but not saying that he said that was me.
[00:56:04.460 --> 00:56:05.740]   Well, if somebody steals your laptop,
[00:56:05.740 --> 00:56:08.180]   you want to be able to just remotely wipe it.
[00:56:08.180 --> 00:56:10.340]   Google has this thing now.
[00:56:10.340 --> 00:56:12.860]   This was a dead man switch, right?
[00:56:12.860 --> 00:56:14.140]   They don't call it that.
[00:56:14.140 --> 00:56:14.660]   Oh, man.
[00:56:14.660 --> 00:56:16.020]   You have to check in every day.
[00:56:16.020 --> 00:56:16.540]   But it's--
[00:56:16.540 --> 00:56:18.260]   If they don't hear from you in a while--
[00:56:18.260 --> 00:56:19.260]   They close all your cuts.
[00:56:19.260 --> 00:56:20.580]   Well, you could tell them what.
[00:56:20.580 --> 00:56:22.900]   So I have one that sends a message to everybody
[00:56:22.900 --> 00:56:24.380]   in my context listening.
[00:56:24.380 --> 00:56:27.500]   I'm dead now, but you should know I'm Batman.
[00:56:27.500 --> 00:56:29.820]   [LAUGHTER]
[00:56:29.820 --> 00:56:31.380]   Look for a guy jumping around.
[00:56:31.380 --> 00:56:33.700]   That's how they know it's really from you.
[00:56:33.700 --> 00:56:34.820]   Yeah.
[00:56:34.820 --> 00:56:35.340]   That's the key.
[00:56:35.340 --> 00:56:36.460]   The only you would say that.
[00:56:36.460 --> 00:56:38.500]   But no, you should probably have that with--
[00:56:38.500 --> 00:56:40.140]   here's where my last pass account is,
[00:56:40.140 --> 00:56:42.580]   and here's the last pass password.
[00:56:42.580 --> 00:56:44.980]   I give half of it to one person, half to the other.
[00:56:44.980 --> 00:56:47.580]   Say, you should call Joe--
[00:56:47.580 --> 00:56:50.220]   Oh, Patrick, call Roger, because Roger's got the other half.
[00:56:50.220 --> 00:56:52.580]   And if Roger is dead, I'm dead.
[00:56:52.580 --> 00:56:53.460]   Maybe we die together.
[00:56:53.460 --> 00:56:54.340]   That would be bad.
[00:56:54.340 --> 00:56:55.580]   So we can't fly together.
[00:56:55.580 --> 00:56:57.700]   Could be romantic, though.
[00:56:57.700 --> 00:57:00.020]   We could be on a mesh network together.
[00:57:00.020 --> 00:57:01.660]   Even in the afterlife.
[00:57:01.660 --> 00:57:02.620]   So I like that.
[00:57:02.620 --> 00:57:04.260]   But what if they become your nemeses,
[00:57:04.260 --> 00:57:06.460]   and then use the powers for evil while you're still alive?
[00:57:06.460 --> 00:57:07.340]   He's only got half.
[00:57:07.340 --> 00:57:07.660]   We'll see.
[00:57:07.660 --> 00:57:10.220]   But what if they join up and see your cone nemeses?
[00:57:10.220 --> 00:57:13.380]   That essentially sets you up for three summer blockbusters
[00:57:13.380 --> 00:57:13.700]   afterwards.
[00:57:13.700 --> 00:57:15.700]   [LAUGHTER]
[00:57:15.700 --> 00:57:18.020]   Anyway, this is increasingly going to be an issue,
[00:57:18.020 --> 00:57:20.300]   is what happens to all your media, your stuff,
[00:57:20.300 --> 00:57:21.060]   all of that stuff.
[00:57:21.060 --> 00:57:21.980]   I don't know why I brought that up.
[00:57:21.980 --> 00:57:23.660]   It's depressing.
[00:57:23.660 --> 00:57:25.180]   Oh, disaster mentality.
[00:57:25.180 --> 00:57:27.340]   Because I'm always thinking the worst is going to happen.
[00:57:27.340 --> 00:57:28.300]   The worst is going to happen.
[00:57:28.300 --> 00:57:30.060]   This is the most depressing episode of this year.
[00:57:30.060 --> 00:57:31.780]   I'm going to cheer you up right now.
[00:57:31.780 --> 00:57:34.820]   Tim Cook says, we're going to sell more iPhones.
[00:57:34.820 --> 00:57:39.980]   He brought in from all over the world,
[00:57:39.980 --> 00:57:43.180]   Apple's retail store leaders from across the globe
[00:57:43.180 --> 00:57:47.820]   for a secret summit at Fort Mason Center in San Francisco.
[00:57:47.820 --> 00:57:50.820]   Of course, immediately, everything he said leaked right
[00:57:50.820 --> 00:57:52.500]   now.
[00:57:52.500 --> 00:57:55.460]   He spoke for three hours.
[00:57:55.460 --> 00:57:59.580]   During this time, this is from a 9 to 5 Mac.
[00:57:59.580 --> 00:58:03.780]   According to 9 to 5 Mac, he expressed satisfaction
[00:58:03.780 --> 00:58:06.700]   with the way Macs and iPads have been selling.
[00:58:06.700 --> 00:58:08.540]   In fact, so much so.
[00:58:08.540 --> 00:58:10.020]   They said, let's put those on the back burner.
[00:58:10.020 --> 00:58:11.820]   You don't have to push those anymore.
[00:58:11.820 --> 00:58:16.860]   What I'm not happy about is that 80% of all iPhones
[00:58:16.860 --> 00:58:20.420]   are purchased from someone else, AT&T.
[00:58:20.420 --> 00:58:23.740]   See, and this scares me because they're a premium brand.
[00:58:23.740 --> 00:58:25.140]   They're the premium brand.
[00:58:25.140 --> 00:58:26.540]   They have such a great reputation.
[00:58:26.540 --> 00:58:31.180]   And if the rumors are true of these plastic, fruity-colored
[00:58:31.180 --> 00:58:35.700]   iPhones, then this would be solid evidence
[00:58:35.700 --> 00:58:38.700]   that Apple is slouching toward becoming
[00:58:38.700 --> 00:58:39.580]   a conventional company.
[00:58:39.580 --> 00:58:41.460]   Because that's conventional company thinking.
[00:58:41.460 --> 00:58:43.180]   Apple never used to think like that.
[00:58:43.180 --> 00:58:43.820]   Oh my gosh.
[00:58:43.820 --> 00:58:45.420]   Let's make this product.
[00:58:45.420 --> 00:58:46.100]   Exactly.
[00:58:46.100 --> 00:58:49.740]   And the idea that they're going to go chasing these low margin
[00:58:49.740 --> 00:58:52.940]   markets for one thing, you can get an iPhone for free right now.
[00:58:52.940 --> 00:58:54.540]   You can get a 4S for free, right?
[00:58:54.540 --> 00:58:56.660]   What do you need to make a cheap iPhone for?
[00:58:56.660 --> 00:58:57.700]   Exactly.
[00:58:57.700 --> 00:59:00.540]   Or maybe, well, there are plenty of countries, not the US,
[00:59:00.540 --> 00:59:02.500]   where the subsidies don't exist.
[00:59:02.500 --> 00:59:04.180]   You have to lay out cash.
[00:59:04.180 --> 00:59:07.620]   But isn't it possible that Apple could have a $99?
[00:59:07.620 --> 00:59:08.420]   Maybe not.
[00:59:08.420 --> 00:59:10.620]   Maybe they have to make a plastic $99 phone.
[00:59:10.620 --> 00:59:12.420]   I mean, they really are apparently
[00:59:12.420 --> 00:59:15.660]   concerned about China, India, and other emerging markets.
[00:59:15.660 --> 00:59:17.460]   When I was in Kenya--
[00:59:17.460 --> 00:59:18.300]   That's where all the growth is.
[00:59:18.300 --> 00:59:20.220]   --to go, everybody had a sound.
[00:59:20.220 --> 00:59:24.060]   Every smartphone user had a sound sound or a Huawei.
[00:59:24.060 --> 00:59:26.100]   And so everybody's concerned about the Huawei's
[00:59:26.100 --> 00:59:27.380]   and the emerging Chinese.
[00:59:27.380 --> 00:59:28.380]   Well, and that is the future.
[00:59:28.380 --> 00:59:30.380]   We've saturated-- I think this is part of the thing that Cook
[00:59:30.380 --> 00:59:33.580]   said-- we've saturated the US market.
[00:59:33.580 --> 00:59:36.460]   So the smartphone market here is not growing anywhere
[00:59:36.460 --> 00:59:37.500]   near as fast as it did.
[00:59:37.500 --> 00:59:39.420]   It's kind of plateaued.
[00:59:39.420 --> 00:59:41.620]   So it's going to be the developing world
[00:59:41.620 --> 00:59:42.460]   where we're going to sell these.
[00:59:42.460 --> 00:59:45.300]   If we're going to grow, isn't the stock market saying to them,
[00:59:45.300 --> 00:59:46.060]   you got to grow?
[00:59:46.060 --> 00:59:50.020]   The problem is that the Apple sphere is so inward looking,
[00:59:50.020 --> 00:59:53.700]   and Apple has so many so few products
[00:59:53.700 --> 00:59:57.980]   that if Apple becomes known for a cheap phone,
[00:59:57.980 --> 00:59:59.740]   that's going to seriously dilute the brand.
[00:59:59.740 --> 01:00:01.060]   That's really what Apple has.
[01:00:01.060 --> 01:00:04.500]   They have this amazing reputation, this brand, the Apple
[01:00:04.500 --> 01:00:06.140]   stores, the whole image thing.
[01:00:06.140 --> 01:00:06.980]   It's aspirational.
[01:00:06.980 --> 01:00:09.300]   I think that's a long way to go to say
[01:00:09.300 --> 01:00:10.660]   that Apple's going to do a cheap phone,
[01:00:10.660 --> 01:00:12.580]   and therefore it's going to destroy its entire brand
[01:00:12.580 --> 01:00:14.180]   because it's got this reputation.
[01:00:14.180 --> 01:00:16.420]   First off, I can't remember the last time
[01:00:16.420 --> 01:00:19.660]   Apple did release a product that was lousy and cheap.
[01:00:19.660 --> 01:00:24.700]   The 3G and the 3GS both had partly carbonate backs too.
[01:00:24.700 --> 01:00:27.900]   And the people didn't get the pitch forks and the torches out
[01:00:27.900 --> 01:00:30.300]   and go to the Apple stores.
[01:00:30.300 --> 01:00:32.780]   I think maybe their goal here is to come up with something
[01:00:32.780 --> 01:00:36.020]   that feels new and doesn't feel like it's two years old
[01:00:36.020 --> 01:00:37.020]   because that's a problem with selling it.
[01:00:37.020 --> 01:00:38.420]   I'm concerned about the overall trend
[01:00:38.420 --> 01:00:42.060]   because the leaked images, which are of dubious validity,
[01:00:42.060 --> 01:00:44.340]   from both Apple and also the Moto X phone,
[01:00:44.340 --> 01:00:45.340]   they're both similar.
[01:00:45.340 --> 01:00:47.500]   The fruity colors and rounded backs
[01:00:47.500 --> 01:00:49.060]   and kind of plastically looking.
[01:00:49.060 --> 01:00:51.540]   I hope this isn't the trend because phones
[01:00:51.540 --> 01:00:52.740]   are starting to get really cool.
[01:00:52.740 --> 01:00:53.580]   You look at that.
[01:00:53.580 --> 01:00:54.420]   They're Pro.
[01:00:54.420 --> 01:00:55.340]   You look at the iPhone 5.
[01:00:55.340 --> 01:00:56.340]   They're more Pro.
[01:00:56.340 --> 01:00:57.020]   Yeah, exactly.
[01:00:57.020 --> 01:00:58.900]   And so I really--
[01:00:58.900 --> 01:01:00.940]   On the iMac, all those fruity colors on the iMac,
[01:01:00.940 --> 01:01:02.220]   that was a terrible failure.
[01:01:02.220 --> 01:01:04.980]   Actually, but it was in the MacBook,
[01:01:04.980 --> 01:01:07.060]   the original Toilet Seat MacBook.
[01:01:07.060 --> 01:01:08.220]   But the iMac did incredible.
[01:01:08.220 --> 01:01:11.940]   Yeah, I mean, I don't know.
[01:01:11.940 --> 01:01:13.740]   This is a weird-- I will agree with you.
[01:01:13.740 --> 01:01:15.900]   This is kind of a weird story for Apple,
[01:01:15.900 --> 01:01:19.940]   although selling two-year-old models for $0 with the subsidy.
[01:01:19.940 --> 01:01:20.940]   That's not good.
[01:01:20.940 --> 01:01:21.780]   It's also weird.
[01:01:21.780 --> 01:01:22.940]   And Apple's doing that today.
[01:01:22.940 --> 01:01:24.500]   And I think you're absolutely right,
[01:01:24.500 --> 01:01:26.380]   that the problem in the US, we don't see it
[01:01:26.380 --> 01:01:28.340]   because it's below the waterline of the subsidy.
[01:01:28.340 --> 01:01:30.020]   But the problem is everywhere else in the world,
[01:01:30.020 --> 01:01:32.980]   Apple does need to make a phone if they want to reach that.
[01:01:32.980 --> 01:01:34.740]   I'm not concerned about the two-year-old--
[01:01:34.740 --> 01:01:35.740]   Two-year-old--
[01:01:35.740 --> 01:01:37.900]   I have nothing against bright colors.
[01:01:37.900 --> 01:01:41.980]   But the strategy of chasing the low-margin phones
[01:01:41.980 --> 01:01:45.580]   is not an Apple strategy that we've seen.
[01:01:45.580 --> 01:01:47.340]   Why do they want market share?
[01:01:47.340 --> 01:01:48.900]   But why do they want market share?
[01:01:48.900 --> 01:01:49.940]   I agree with you.
[01:01:49.940 --> 01:01:53.180]   The question is, is this truly a low-margin phone?
[01:01:53.180 --> 01:01:54.700]   Or is it-- I mean, this may actually
[01:01:54.700 --> 01:01:58.820]   be a phone that has higher margins than selling the four
[01:01:58.820 --> 01:02:01.700]   for zero subsidized because they may re-engineer it
[01:02:01.700 --> 01:02:02.940]   to be a little bit cheaper.
[01:02:02.940 --> 01:02:05.540]   And if it doesn't come across as being a cheap product,
[01:02:05.540 --> 01:02:06.740]   then that might actually not--
[01:02:06.740 --> 01:02:08.700]   Do that with the iPod, though.
[01:02:08.700 --> 01:02:10.820]   They started with an expensive premium product,
[01:02:10.820 --> 01:02:12.980]   and then they created iPods that were $99,
[01:02:12.980 --> 01:02:15.540]   that were affordable in colors.
[01:02:15.540 --> 01:02:17.140]   There's an analogy there.
[01:02:17.140 --> 01:02:19.860]   And the cheap iPods were not--
[01:02:19.860 --> 01:02:22.020]   except for the one that was chewing gum.
[01:02:22.020 --> 01:02:23.020]   The shuffle.
[01:02:23.020 --> 01:02:24.980]   I swallowed one of those.
[01:02:24.980 --> 01:02:28.060]   But every other respect, they weren't like crap, were they?
[01:02:28.060 --> 01:02:28.580]   No.
[01:02:28.580 --> 01:02:29.740]   No, they were quality products.
[01:02:29.740 --> 01:02:31.540]   No, but they were never the low-price leader.
[01:02:31.540 --> 01:02:33.420]   And Apple never should be the low-price leader.
[01:02:33.420 --> 01:02:35.420]   And by the way, if I do, I might get a lower price.
[01:02:35.420 --> 01:02:37.780]   They killed the market for MP3 players.
[01:02:37.780 --> 01:02:38.220]   That's it.
[01:02:38.220 --> 01:02:39.180]   It's over.
[01:02:39.180 --> 01:02:39.980]   Apple owns it.
[01:02:39.980 --> 01:02:41.820]   But they came out with the cheaper ones
[01:02:41.820 --> 01:02:44.820]   after the iPod was no longer the flagship product.
[01:02:44.820 --> 01:02:46.180]   iPhone is the flagship product.
[01:02:46.180 --> 01:02:49.060]   It's where the vast majority of their profits come from.
[01:02:49.060 --> 01:02:51.380]   It's where the vast majority of Samsung's profits come.
[01:02:51.380 --> 01:02:53.380]   80% of Samsung's profits.
[01:02:53.380 --> 01:02:53.860]   And so--
[01:02:53.860 --> 01:02:54.540]   That's not true, though.
[01:02:54.540 --> 01:02:56.460]   I mean, the iPad mini and the iPad nano came out
[01:02:56.460 --> 01:02:58.460]   when the iPad was still growing.
[01:02:58.460 --> 01:03:01.300]   I mean, sorry, the iPod mini and iPod nano came out
[01:03:01.300 --> 01:03:04.020]   while the iPod was still a growing part of Apple's business.
[01:03:04.020 --> 01:03:05.900]   It wasn't a tailing off part of Apple's business.
[01:03:05.900 --> 01:03:07.180]   It was long before it started.
[01:03:07.180 --> 01:03:10.740]   And they helped make that growth increase.
[01:03:10.740 --> 01:03:15.100]   I'm worried about Apple becoming conventional.
[01:03:15.100 --> 01:03:20.420]   And they literally haven't shipped anything interesting.
[01:03:20.420 --> 01:03:21.540]   Since Steve Jobs died.
[01:03:21.540 --> 01:03:23.020]   So cook, I agree.
[01:03:23.020 --> 01:03:23.540]   I agree.
[01:03:23.540 --> 01:03:25.860]   And I don't think even the Mac Pro is anything
[01:03:25.860 --> 01:03:26.700]   that we're right home about.
[01:03:26.700 --> 01:03:29.380]   But I think you and I disagree on that one.
[01:03:29.380 --> 01:03:31.020]   Buy me one and I'll let you know.
[01:03:31.020 --> 01:03:32.100]   OK.
[01:03:32.100 --> 01:03:33.340]   I'm buying one for myself, but it's
[01:03:33.340 --> 01:03:34.780]   going to be a great home theater PC.
[01:03:34.780 --> 01:03:36.220]   I'm going to put a rental in my room.
[01:03:36.220 --> 01:03:37.940]   Another element of the iPhone sales push
[01:03:37.940 --> 01:03:40.340]   according to 9 and 5 Mac cook reportedly hinted
[01:03:40.340 --> 01:03:43.460]   is the upcoming launch of an iPhone trade-in program.
[01:03:43.460 --> 01:03:46.260]   I think this is smart for Apple stores.
[01:03:46.260 --> 01:03:48.620]   I think there are a lot of people out there with iPhone 4s,
[01:03:48.620 --> 01:03:51.500]   4s, who might want to say, hey, I can get something for it
[01:03:51.500 --> 01:03:52.740]   if I bring it to the Apple store.
[01:03:52.740 --> 01:03:55.500]   And they also bring them to the Apple store where they'll buy.
[01:03:55.500 --> 01:03:56.940]   One of the things he doesn't like
[01:03:56.940 --> 01:04:00.020]   is that 80% of iPhones are bought outside the Apple store.
[01:04:00.020 --> 01:04:02.740]   But 50% of returns and fixes come
[01:04:02.740 --> 01:04:04.060]   to the Apple store.
[01:04:04.060 --> 01:04:06.540]   He's not happy about that one.
[01:04:06.540 --> 01:04:09.140]   Well, he sees the third party, whether it's something
[01:04:09.140 --> 01:04:12.140]   like eBay or it's a website that offers you to buy back
[01:04:12.140 --> 01:04:13.060]   your iPhone.
[01:04:13.060 --> 01:04:15.460]   That's an opportunity for Apple to--
[01:04:15.460 --> 01:04:17.260]   I wasn't going to say, are they sponsored this week or not?
[01:04:17.260 --> 01:04:18.140]   But yeah, it's--
[01:04:18.140 --> 01:04:19.980]   It's sponsored, but they know, but that's right.
[01:04:19.980 --> 01:04:22.140]   They've got to look at Gazelle and say, why aren't we doing that?
[01:04:22.140 --> 01:04:22.500]   Why don't we do that?
[01:04:22.500 --> 01:04:25.260]   Because then we can convert them immediately into another iPhone.
[01:04:25.260 --> 01:04:25.980]   Exactly.
[01:04:25.980 --> 01:04:26.380]   Why wouldn't we--
[01:04:26.380 --> 01:04:28.340]   And get them in the store and give them another iPhone.
[01:04:28.340 --> 01:04:29.500]   They got all those stores.
[01:04:29.500 --> 01:04:30.580]   And that's another issue.
[01:04:30.580 --> 01:04:32.460]   I don't want to go down another rat hole.
[01:04:32.460 --> 01:04:34.700]   But there's an environmental component here
[01:04:34.700 --> 01:04:37.620]   with everybody chasing low-ends and having people who
[01:04:37.620 --> 01:04:40.220]   are barely spending anything have an entirely brand new phone
[01:04:40.220 --> 01:04:42.220]   instead of a refurbished phone.
[01:04:42.220 --> 01:04:43.860]   That's terrible for the environment.
[01:04:43.860 --> 01:04:44.380]   It's terrible.
[01:04:44.380 --> 01:04:44.860]   I agree.
[01:04:44.860 --> 01:04:46.820]   These phones should last 12 years.
[01:04:46.820 --> 01:04:50.060]   And we need some system to have them remain in use.
[01:04:50.060 --> 01:04:50.780]   Maybe that's the point.
[01:04:50.780 --> 01:04:52.180]   Because the only environmentally friendly phone
[01:04:52.180 --> 01:04:53.620]   is the one you never manufacture.
[01:04:53.620 --> 01:04:56.300]   Notice that the iPhone 5 is much more repairable, right?
[01:04:56.300 --> 01:04:58.060]   You can-- or is it not?
[01:04:58.060 --> 01:04:58.380]   Parts of--
[01:04:58.380 --> 01:04:59.860]   Don't they have a special machine?
[01:04:59.860 --> 01:05:01.220]   Parts of it are parts of it aren't.
[01:05:01.220 --> 01:05:03.780]   But if Apple's taking back old iPhones,
[01:05:03.780 --> 01:05:05.060]   it does make you wonder if they're
[01:05:05.060 --> 01:05:06.300]   going to use that--
[01:05:06.300 --> 01:05:07.660]   probably not put them in a landfill.
[01:05:07.660 --> 01:05:08.900]   But use them in some way.
[01:05:08.900 --> 01:05:11.260]   Maybe that's a way to do low-cost.
[01:05:11.260 --> 01:05:13.060]   That's a better way to do low-cost.
[01:05:13.060 --> 01:05:15.420]   And additional-- this is all from the 9 to 5 Mac story
[01:05:15.420 --> 01:05:16.460]   about the event.
[01:05:16.460 --> 01:05:18.340]   In addition to talking about iPhone hardware,
[01:05:18.340 --> 01:05:22.740]   Cook mentioned how critical iOS is to Apple's future.
[01:05:22.740 --> 01:05:25.700]   They demonstrated iOS to the Apple retail store leaders.
[01:05:29.740 --> 01:05:32.780]   So just looking to see if I'm getting any eye contact
[01:05:32.780 --> 01:05:33.780]   from those guys.
[01:05:33.780 --> 01:05:35.780]   Coupled with the new iPhone and iOS sales strategies,
[01:05:35.780 --> 01:05:39.100]   Apple will focus on opening up a few new major stores in Europe,
[01:05:39.100 --> 01:05:42.060]   including a new store in Italy.
[01:05:42.060 --> 01:05:44.500]   Rumored to be working on low-cost.
[01:05:44.500 --> 01:05:46.260]   They didn't talk about that.
[01:05:46.260 --> 01:05:48.380]   Store leaders, according to the people briefed on the talks,
[01:05:48.380 --> 01:05:49.660]   reportedly left the summit feeling
[01:05:49.660 --> 01:05:52.860]   confident about Apple's fall product line expect.
[01:05:52.860 --> 01:05:56.660]   And here's the interesting quote, "An army of new products
[01:05:56.660 --> 01:05:58.060]   this fall."
[01:05:58.060 --> 01:05:59.740]   That's the weakest rumor ever, right?
[01:05:59.740 --> 01:06:00.300]   Yeah.
[01:06:00.300 --> 01:06:02.180]   What Apple will have new products in the fall?
[01:06:02.180 --> 01:06:03.380]   Could be an army of one.
[01:06:03.380 --> 01:06:04.420]   It's not going to happen.
[01:06:04.420 --> 01:06:06.420]   Shocker.
[01:06:06.420 --> 01:06:08.380]   Apple did it though last year, remember?
[01:06:08.380 --> 01:06:11.820]   They had like at a crazy event where they announced like everything.
[01:06:11.820 --> 01:06:13.380]   The whole line is new.
[01:06:13.380 --> 01:06:14.700]   They could do that again.
[01:06:14.700 --> 01:06:16.780]   That was when October or September they did that last year.
[01:06:16.780 --> 01:06:19.060]   The thing is that they're judged on their performance
[01:06:19.060 --> 01:06:21.380]   relative to the same quarter in the previous year.
[01:06:21.380 --> 01:06:24.420]   So they have to knock something out of the park for the holidays
[01:06:24.420 --> 01:06:25.980]   or their toast unwall.
[01:06:25.980 --> 01:06:28.900]   This is going to do product category or just revamps
[01:06:28.900 --> 01:06:30.260]   of everything they already have.
[01:06:30.260 --> 01:06:31.340]   I watch something.
[01:06:31.340 --> 01:06:32.100]   I TV.
[01:06:32.100 --> 01:06:35.420]   I think the watch is a strong possibility for this year.
[01:06:35.420 --> 01:06:37.940]   They had one with the banana at one point.
[01:06:37.940 --> 01:06:39.140]   That's right.
[01:06:39.140 --> 01:06:40.820]   It's a really bad watch.
[01:06:40.820 --> 01:06:41.220]   But people--
[01:06:41.220 --> 01:06:43.180]   Accidental, bad watch.
[01:06:43.180 --> 01:06:44.020]   Yes.
[01:06:44.020 --> 01:06:46.300]   So Dell's going to do a watch.
[01:06:46.300 --> 01:06:48.700]   That'll be as successful as other other phones.
[01:06:48.700 --> 01:06:49.780]   It'll be gray.
[01:06:49.780 --> 01:06:51.980]   I had Dell at 413 if you want to know.
[01:06:51.980 --> 01:06:53.540]   It was sort of cool.
[01:06:53.540 --> 01:06:55.820]   What time is it?
[01:06:55.820 --> 01:06:57.500]   Dell should just get out of its phone and look there
[01:06:57.500 --> 01:06:58.340]   and see what time it is.
[01:06:58.340 --> 01:06:59.260]   Yeah.
[01:06:59.260 --> 01:07:00.340]   What phone?
[01:07:00.340 --> 01:07:00.980]   I don't know.
[01:07:00.980 --> 01:07:02.180]   It probably had a phone.
[01:07:02.180 --> 01:07:05.380]   I think the larger story with the watch
[01:07:05.380 --> 01:07:08.180]   is the number of companies that are announced--
[01:07:08.180 --> 01:07:09.180]   Everybody.
[01:07:09.180 --> 01:07:09.700]   --or rumored.
[01:07:09.700 --> 01:07:11.100]   That shows how strong Apple is.
[01:07:11.100 --> 01:07:13.660]   There was an article on this that
[01:07:13.660 --> 01:07:17.020]   gave the list of everybody who's doing a watch.
[01:07:17.020 --> 01:07:20.300]   And then there was the list of the major companies that are not.
[01:07:20.300 --> 01:07:21.780]   And the list of the companies that were not
[01:07:21.780 --> 01:07:22.820]   was like four companies.
[01:07:22.820 --> 01:07:25.260]   It was like Nokia, a couple of other companies.
[01:07:25.260 --> 01:07:28.700]   Every other major we know is working on it, including Dell.
[01:07:28.700 --> 01:07:31.180]   Because it's a new product category that no one has
[01:07:31.180 --> 01:07:32.260]   their big towing.
[01:07:32.260 --> 01:07:34.500]   I mean, this isn't one of the things that I've noticed,
[01:07:34.500 --> 01:07:36.700]   especially with large electronic conglomerates,
[01:07:36.700 --> 01:07:40.380]   is that they saturate each of those product categories
[01:07:40.380 --> 01:07:43.060]   to the point where they have the low, middle to end.
[01:07:43.060 --> 01:07:45.300]   But they have such thin margins.
[01:07:45.300 --> 01:07:47.580]   They need people to keep buying stuff.
[01:07:47.580 --> 01:07:51.900]   And it was very telling that when I was at the LG
[01:07:51.900 --> 01:07:54.900]   and the-- was it not Panasonic?
[01:07:54.900 --> 01:07:57.940]   One of the other was the Japanese electronics manufacturer.
[01:07:57.940 --> 01:08:00.380]   One of the things they were telling were a lot of home appliances.
[01:08:00.380 --> 01:08:01.700]   Smart--
[01:08:01.700 --> 01:08:02.500]   LG.
[01:08:02.500 --> 01:08:03.860]   Smart, smart refrigeration.
[01:08:03.860 --> 01:08:04.340]   You know why?
[01:08:04.340 --> 01:08:05.660]   Nobody's buying HD TVs.
[01:08:05.660 --> 01:08:06.220]   It's saturated.
[01:08:06.220 --> 01:08:07.140]   The market is done.
[01:08:07.140 --> 01:08:09.860]   I think the competitive dynamic that's happening here
[01:08:09.860 --> 01:08:12.620]   is that the major companies are using the watch
[01:08:12.620 --> 01:08:13.820]   as a lock-in product.
[01:08:13.820 --> 01:08:16.020]   So when you get the Apple iWatch, that's
[01:08:16.020 --> 01:08:18.260]   going to be like work only with the iPhone.
[01:08:18.260 --> 01:08:19.700]   It's going to make you need an iPhone.
[01:08:19.700 --> 01:08:20.700]   You're going to love it because it's
[01:08:20.700 --> 01:08:21.700]   going to be really fashionable.
[01:08:21.700 --> 01:08:23.660]   Google's probably going to do something similar.
[01:08:23.660 --> 01:08:25.100]   Samsung is going to do something similar.
[01:08:25.100 --> 01:08:26.140]   LG is going to do that, too.
[01:08:26.140 --> 01:08:27.900]   They're going to try to use the watch
[01:08:27.900 --> 01:08:29.500]   to lock you into the rest of the product.
[01:08:29.500 --> 01:08:32.140]   Well, don't name it an iWatch because Apple has now filed
[01:08:32.140 --> 01:08:38.300]   for the trademark name iWatch in Russia, Japan, Mexico, the US.
[01:08:38.300 --> 01:08:39.740]   I'll never get it in China.
[01:08:39.740 --> 01:08:41.220]   Is there an iWatch?
[01:08:41.220 --> 01:08:43.380]   There are actually multiple companies in China
[01:08:43.380 --> 01:08:44.740]   that have the iWatch.
[01:08:44.740 --> 01:08:46.700]   Brand and the Chinese government and courts
[01:08:46.700 --> 01:08:49.180]   are out to get Apple.
[01:08:49.180 --> 01:08:51.660]   Because they have encrypted messaging.
[01:08:51.660 --> 01:08:55.860]   And I normally don't pay attention to patent filings
[01:08:55.860 --> 01:08:58.420]   from Apple because they have a building full of lawyers.
[01:08:58.420 --> 01:08:59.580]   And of course, they're going to file.
[01:08:59.580 --> 01:09:01.980]   But filing for the trademark of iWatch--
[01:09:01.980 --> 01:09:03.500]   Well, why not do it even if you're--
[01:09:03.500 --> 01:09:04.020]   I guess.
[01:09:04.020 --> 01:09:06.020]   I don't think it's a confirmation of it,
[01:09:06.020 --> 01:09:07.540]   but why not do it?
[01:09:07.540 --> 01:09:10.460]   I do wonder when you talk about everybody doing a watch,
[01:09:10.460 --> 01:09:13.260]   if some aspect of that is this paranoia about Apple
[01:09:13.260 --> 01:09:14.660]   getting the jump on them, like there
[01:09:14.660 --> 01:09:16.420]   are all these rumors that Apple's working on a watch
[01:09:16.420 --> 01:09:17.540]   and what's it going to be.
[01:09:17.540 --> 01:09:20.580]   And that happens with tablets.
[01:09:20.580 --> 01:09:22.740]   And everybody had those slates at CES
[01:09:22.740 --> 01:09:24.900]   that didn't actually ever come out.
[01:09:24.900 --> 01:09:26.980]   Because the iPad came out and they're like, oh crap,
[01:09:26.980 --> 01:09:28.020]   we can't do that.
[01:09:28.020 --> 01:09:28.520]   Right?
[01:09:28.520 --> 01:09:30.860]   And I wonder-- and the game is a little different now.
[01:09:30.860 --> 01:09:32.700]   And I know Samsung is looking at this aggressively
[01:09:32.700 --> 01:09:34.380]   and a bunch of other manufacturers are.
[01:09:34.380 --> 01:09:36.100]   But I've got to think the part of it
[01:09:36.100 --> 01:09:38.140]   is that they don't want to get caught flat-footed
[01:09:38.140 --> 01:09:40.100]   by whatever Apple does this time.
[01:09:40.100 --> 01:09:42.820]   Now, we'll see if Apple does what we all expect them to do
[01:09:42.820 --> 01:09:45.500]   or it kind of surprises everybody.
[01:09:45.500 --> 01:09:48.340]   I wonder how much of this is that the CEO is at some event
[01:09:48.340 --> 01:09:50.140]   and says, oh yeah, we're doing a watch.
[01:09:50.140 --> 01:09:52.700]   And then runs back to his phone, calls back to headquarters
[01:09:52.700 --> 01:09:54.460]   and he's got to get going on a watch.
[01:09:54.460 --> 01:09:57.220]   You know, I don't think that's an unreasonable guess at all.
[01:09:57.220 --> 01:09:58.140]   I think there's a lot of that.
[01:09:58.140 --> 01:09:59.780]   All I know is that I want one.
[01:09:59.780 --> 01:10:01.140]   And it's like, I'm dying from--
[01:10:01.140 --> 01:10:02.940]   You're going to want one everywhere when you hear this.
[01:10:02.940 --> 01:10:07.100]   Apple just hired the former CEO of Eve Salah.
[01:10:07.100 --> 01:10:08.100]   You said it like that, didn't you?
[01:10:08.100 --> 01:10:09.100]   Eve Salah.
[01:10:09.100 --> 01:10:10.100]   Yeah.
[01:10:10.100 --> 01:10:12.980]   Fashion giant Eve Salah.
[01:10:12.980 --> 01:10:15.980]   Watch is a part of the accessory market.
[01:10:15.980 --> 01:10:17.820]   He's a fashion executive.
[01:10:17.820 --> 01:10:20.220]   He'll be running special--
[01:10:20.220 --> 01:10:21.220]   Special products.
[01:10:21.220 --> 01:10:22.220]   Special products.
[01:10:22.220 --> 01:10:23.220]   Special products.
[01:10:23.220 --> 01:10:24.220]   Everybody's talking about this guy,
[01:10:24.220 --> 01:10:27.860]   as if he's from the fashion runways of Europe and stuff.
[01:10:27.860 --> 01:10:29.780]   He started out as a bean counter at Exxon.
[01:10:29.780 --> 01:10:32.020]   Yeah, he's a business guy and he's a tech guy.
[01:10:32.020 --> 01:10:33.620]   Come on, you're ruining the story.
[01:10:33.620 --> 01:10:34.620]   He went to Stanford.
[01:10:34.620 --> 01:10:35.580]   He's much less fun that way.
[01:10:35.580 --> 01:10:37.980]   Oh, stupid facts.
[01:10:37.980 --> 01:10:40.700]   But his specialty is exactly what Apple wants.
[01:10:40.700 --> 01:10:43.780]   His specialty is to take something that's
[01:10:43.780 --> 01:10:46.380]   high-falutin, design-y kind of a thing
[01:10:46.380 --> 01:10:48.100]   and make it a mass market product.
[01:10:48.100 --> 01:10:49.700]   That's what Apple does.
[01:10:49.700 --> 01:10:52.260]   And that's what he did at some of these fashion companies
[01:10:52.260 --> 01:10:53.180]   that he's worked at.
[01:10:53.180 --> 01:10:56.580]   Apple's had a really hard time finding outside executives
[01:10:56.580 --> 01:10:57.620]   to bring into the company.
[01:10:57.620 --> 01:10:59.780]   We've seen it time and again that a lot of times,
[01:10:59.780 --> 01:11:01.180]   Apple's just such a different company
[01:11:01.180 --> 01:11:03.300]   and there are these cultural mismatches.
[01:11:03.300 --> 01:11:06.220]   And I look at this and exactly what you said about him.
[01:11:06.220 --> 01:11:08.220]   It's interesting.
[01:11:08.220 --> 01:11:10.020]   This might be a good fit.
[01:11:10.020 --> 01:11:11.100]   I guess we'll all find out.
[01:11:11.100 --> 01:11:11.940]   But look at him.
[01:11:11.940 --> 01:11:13.260]   He's a sort of shit guy.
[01:11:13.260 --> 01:11:14.540]   You sort of see it though, right?
[01:11:14.540 --> 01:11:17.580]   That this is that exactly sort of like the kind of game Apple
[01:11:17.580 --> 01:11:17.940]   plays.
[01:11:17.940 --> 01:11:18.780]   Exactly.
[01:11:18.780 --> 01:11:19.260]   Exactly.
[01:11:19.260 --> 01:11:24.660]   Even if I suppose like that, I look more like--
[01:11:24.660 --> 01:11:26.620]   Somebody super glued his thumb to his chin.
[01:11:26.620 --> 01:11:29.180]   I'm the guy in the basement who's putting his stuff together.
[01:11:29.180 --> 01:11:31.700]   No, you just use it right arm.
[01:11:31.700 --> 01:11:32.860]   Look at him.
[01:11:32.860 --> 01:11:35.420]   His name is Baldoniv.
[01:11:35.420 --> 01:11:35.980]   You know, but--
[01:11:35.980 --> 01:11:36.980]   But with Salahal.
[01:11:36.980 --> 01:11:38.300]   I have the feeling that this is going
[01:11:38.300 --> 01:11:39.380]   to be the differentiator.
[01:11:39.380 --> 01:11:41.540]   I mean, everybody's going to have a big bar of soap
[01:11:41.540 --> 01:11:44.220]   on the wrist like the Sony iWatch, which is probably
[01:11:44.220 --> 01:11:46.140]   a pretty nice watch the next one, the second one.
[01:11:46.140 --> 01:11:48.900]   But it's a big like squarish kind of like working thing.
[01:11:48.900 --> 01:11:50.300]   Look like the Casio calculator.
[01:11:50.300 --> 01:11:53.300]   I got my pebble here, which looks like the Casio calculator
[01:11:53.300 --> 01:11:53.900]   watch too.
[01:11:53.900 --> 01:11:54.380]   Yeah.
[01:11:54.380 --> 01:11:54.900]   I like it.
[01:11:54.900 --> 01:11:57.340]   And if Apple comes out with something that really looks
[01:11:57.340 --> 01:12:00.260]   like high end, you know, sleek, thin, all that stuff,
[01:12:00.260 --> 01:12:02.180]   which they are very likely to do,
[01:12:02.180 --> 01:12:03.820]   it's that's going to be the differentiator.
[01:12:03.820 --> 01:12:04.820]   See a swatch?
[01:12:04.820 --> 01:12:05.420]   He didn't say that.
[01:12:05.420 --> 01:12:07.060]   I hope they do it from the record.
[01:12:07.060 --> 01:12:08.460]   Can they do swatch time?
[01:12:08.460 --> 01:12:09.460]   Swatch time didn't catch up.
[01:12:09.460 --> 01:12:10.460]   That was internet time, right?
[01:12:10.460 --> 01:12:11.460]   That was a good time.
[01:12:11.460 --> 01:12:12.300]   I like that.
[01:12:12.300 --> 01:12:14.820]   It was completely indecipherable.
[01:12:14.820 --> 01:12:15.820]   No, it made no sense at all.
[01:12:15.820 --> 01:12:16.620]   No sense at all.
[01:12:16.620 --> 01:12:18.460]   But it was swatch time.
[01:12:18.460 --> 01:12:18.980]   What is that?
[01:12:18.980 --> 01:12:19.780]   That is so stupid.
[01:12:19.780 --> 01:12:21.100]   I'm going to invent a new kind of time.
[01:12:21.100 --> 01:12:22.340]   But you know, you could do that.
[01:12:22.340 --> 01:12:23.660]   Apple.
[01:12:23.660 --> 01:12:25.500]   We're going to make time decimal.
[01:12:25.500 --> 01:12:27.100]   It should have been decimal.
[01:12:27.100 --> 01:12:29.180]   Why is it not-- how many fingers do you chose?
[01:12:29.180 --> 01:12:29.980]   It should be decimal.
[01:12:29.980 --> 01:12:32.100]   Apple often looks back in history
[01:12:32.100 --> 01:12:33.780]   for influences and inspiration.
[01:12:33.780 --> 01:12:37.140]   So I believe it might have a sundial on it.
[01:12:37.140 --> 01:12:38.500]   [LAUGHTER]
[01:12:38.500 --> 01:12:39.500]   I like it.
[01:12:39.500 --> 01:12:42.260]   It will-- hey, it's reliable, unless it gets cloudy.
[01:12:42.260 --> 01:12:44.500]   Depending on what time of the year it is.
[01:12:44.500 --> 01:12:45.980]   I'm really disappointed that still won't--
[01:12:45.980 --> 01:12:49.500]   It doesn't automatically tell me the time in swatch time right now.
[01:12:49.500 --> 01:12:50.340]   It's not--
[01:12:50.340 --> 01:12:52.300]   You can't Google swatch time and find out?
[01:12:52.300 --> 01:12:54.060]   Well, there's sites, but Google should do that.
[01:12:54.060 --> 01:12:55.220]   No, it should be a good thing.
[01:12:55.220 --> 01:12:56.460]   That should be an April Fool's Day project.
[01:12:56.460 --> 01:12:57.500]   But yeah, about internet time.
[01:12:57.500 --> 01:12:59.340]   I think it's the same as swatch time, isn't it?
[01:12:59.340 --> 01:13:00.500]   Is it not?
[01:13:00.500 --> 01:13:00.500]   I don't know.
[01:13:00.500 --> 01:13:02.660]   It's where it's divided into beats instead of--
[01:13:02.660 --> 01:13:03.220]   Right.
[01:13:03.220 --> 01:13:04.860]   --cuz seconds and minutes are out-noted.
[01:13:04.860 --> 01:13:05.300]   It was decimal.
[01:13:05.300 --> 01:13:05.980]   Yes, it was decimal.
[01:13:05.980 --> 01:13:06.620]   It was decimal.
[01:13:06.620 --> 01:13:07.820]   That's what we need.
[01:13:07.820 --> 01:13:12.420]   So Professor Boston University says, hey, I did that.
[01:13:12.420 --> 01:13:13.820]   This is the problem with patent wars.
[01:13:13.820 --> 01:13:16.700]   You start a patent war, suddenly you get sued.
[01:13:16.700 --> 01:13:23.460]   And now this guy is saying he is asking that Apple be banned
[01:13:23.460 --> 01:13:27.100]   from selling iPhones and iPads because he invented
[01:13:27.100 --> 01:13:30.940]   gallium nitride thin film semiconductors back in 1997.
[01:13:30.940 --> 01:13:31.420]   What's crazy?
[01:13:31.420 --> 01:13:32.420]   At 1997.
[01:13:32.420 --> 01:13:35.820]   What's crazy is his patent expires next year.
[01:13:35.820 --> 01:13:36.820]   No, he's got to work fast.
[01:13:36.820 --> 01:13:38.140]   What took him so long?
[01:13:38.140 --> 01:13:39.660]   These devices have been around for years.
[01:13:39.660 --> 01:13:43.180]   You've been using gallium arsenide for a while.
[01:13:43.180 --> 01:13:44.180]   Yeah.
[01:13:44.180 --> 01:13:45.820]   What are you doing?
[01:13:45.820 --> 01:13:47.500]   He's seeking an injunction banning the sale
[01:13:47.500 --> 01:13:49.020]   of a wide range of Apple products,
[01:13:49.020 --> 01:13:53.820]   but also asking for an accounting of their profits.
[01:13:53.820 --> 01:13:55.260]   Be used involved in this.
[01:13:55.260 --> 01:13:56.980]   They want Apple to hand over its earnings
[01:13:56.980 --> 01:14:00.100]   from the last few years.
[01:14:00.100 --> 01:14:02.500]   Good luck.
[01:14:02.500 --> 01:14:05.260]   Stand and deliver.
[01:14:05.260 --> 01:14:06.100]   Wow.
[01:14:06.100 --> 01:14:07.420]   But you know what?
[01:14:07.420 --> 01:14:08.700]   This is not a patent troll.
[01:14:08.700 --> 01:14:11.540]   I mean, this guy invented it.
[01:14:11.540 --> 01:14:13.900]   Doesn't he have the right to say, hey, it's mine?
[01:14:13.900 --> 01:14:16.540]   It's more like patent performance art.
[01:14:16.540 --> 01:14:19.140]   It's just like, look how bad this could be at.
[01:14:19.140 --> 01:14:23.420]   But you start a war and you can't control where the shooting's
[01:14:23.420 --> 01:14:24.620]   going to end up.
[01:14:24.620 --> 01:14:26.900]   And Samsung got an injunction against Apple
[01:14:26.900 --> 01:14:30.460]   and we're in Korea or somewhere.
[01:14:30.460 --> 01:14:31.540]   I can't follow it.
[01:14:31.540 --> 01:14:32.820]   It's too complicated for me.
[01:14:32.820 --> 01:14:34.380]   My mind is limited.
[01:14:34.380 --> 01:14:35.740]   We'll take a break, come back with more.
[01:14:35.740 --> 01:14:37.820]   We'll talk about that massive Android flaw in X,
[01:14:37.820 --> 01:14:40.340]   but first a word from audible.com.
[01:14:40.340 --> 01:14:41.460]   Audio books.
[01:14:41.460 --> 01:14:42.700]   Somebody tweeted me.
[01:14:42.700 --> 01:14:45.180]   I made my wife listen to Twit.
[01:14:45.180 --> 01:14:47.380]   We drove across country the whole time.
[01:14:47.380 --> 01:14:48.340]   Poor woman.
[01:14:48.340 --> 01:14:49.860]   And made her listen.
[01:14:49.860 --> 01:14:50.740]   I made her listen.
[01:14:50.740 --> 01:14:53.860]   And now she-- and then as a result, she's an audible.
[01:14:53.860 --> 01:14:54.380]   She's a subscriber.
[01:14:54.380 --> 01:14:57.340]   She went to LegalZoom and filed a divorce.
[01:14:57.340 --> 01:14:58.660]   She went to all our advertisers.
[01:14:58.660 --> 01:14:59.980]   LegalZoom filed a divorce.
[01:14:59.980 --> 01:15:02.780]   First she sold her iPhone then.
[01:15:02.780 --> 01:15:05.140]   $99.
[01:15:05.140 --> 01:15:06.940]   You know, I don't know if they do divorcees, actually.
[01:15:06.940 --> 01:15:08.660]   That's an interesting question.
[01:15:08.660 --> 01:15:09.780]   Probably not.
[01:15:09.780 --> 01:15:12.140]   But I do know where you can get an audible subscription.
[01:15:12.140 --> 01:15:14.340]   In fact, I know where you get two books for free.
[01:15:14.340 --> 01:15:16.900]   Enough to get you across country if you get the right books.
[01:15:16.900 --> 01:15:19.220]   Actually, if you got the rise and fall of the third Reich,
[01:15:19.220 --> 01:15:21.380]   you could drive across back and forth three or four times.
[01:15:21.380 --> 01:15:23.740]   You could probably drive all the way around the world.
[01:15:23.740 --> 01:15:27.340]   Are you excited about the Lone Ranger movie?
[01:15:27.340 --> 01:15:28.140]   Me neither.
[01:15:28.140 --> 01:15:32.860]   But there is a book that I guess the movie is based on,
[01:15:32.860 --> 01:15:35.980]   The Lone Ranger Rides by Fran Stryker.
[01:15:35.980 --> 01:15:39.140]   Difficult men behind the scenes of a created revolution
[01:15:39.140 --> 01:15:43.180]   from the Sopranos and the wire to mad men and breaking bad.
[01:15:43.180 --> 01:15:45.540]   The evolution of TV writing.
[01:15:45.540 --> 01:15:46.460]   That would be great.
[01:15:46.460 --> 01:15:47.340]   Yeah, that looks like a great--
[01:15:47.340 --> 01:15:48.180]   Brett Martin.
[01:15:48.180 --> 01:15:49.940]   Wow.
[01:15:49.940 --> 01:15:53.340]   If you like thrillers-- well, everything from Dan Brown,
[01:15:53.340 --> 01:15:55.500]   his newest and Ferno is out on Audible,
[01:15:55.500 --> 01:15:58.860]   or the new Neil Gaiman, which I'm told is as much a memoir
[01:15:58.860 --> 01:16:02.220]   as a novel, the Ocean at the end of the Lane, Andy Red,
[01:16:02.220 --> 01:16:04.660]   and said it was great.
[01:16:04.660 --> 01:16:05.660]   Red by the author?
[01:16:05.660 --> 01:16:06.180]   Red.
[01:16:06.180 --> 01:16:06.700]   And you know what?
[01:16:06.700 --> 01:16:08.180]   Neil Gaiman reads--
[01:16:08.180 --> 01:16:10.380]   I listen, he's got the most beautiful voice.
[01:16:10.380 --> 01:16:12.700]   Not many authors can read their own works,
[01:16:12.700 --> 01:16:15.380]   but Neil Gaiman is always the go-to guy
[01:16:15.380 --> 01:16:17.460]   if you've got a Neil Gaiman book.
[01:16:17.460 --> 01:16:18.140]   Now, here's the deal.
[01:16:18.140 --> 01:16:19.660]   You can get two books for free.
[01:16:19.660 --> 01:16:22.500]   You play them back on your computer, any portable device,
[01:16:22.500 --> 01:16:23.860]   any tablet.
[01:16:23.860 --> 01:16:27.180]   There actually is great Audible software for iOS, Android,
[01:16:27.180 --> 01:16:28.500]   and Windows phone.
[01:16:28.500 --> 01:16:33.540]   When-- Windows Metro, there's a lovely Audible app for.
[01:16:33.540 --> 01:16:35.060]   That lets you see your whole library,
[01:16:35.060 --> 01:16:38.340]   download any book from your library, listen at any time.
[01:16:38.340 --> 01:16:39.500]   I listen all the time.
[01:16:39.500 --> 01:16:42.260]   I have a Sonos, so I can listen to my audio
[01:16:42.260 --> 01:16:44.180]   from my Audible in the entire house.
[01:16:44.180 --> 01:16:46.500]   Echoes with books.
[01:16:46.500 --> 01:16:47.940]   I am just such a fan.
[01:16:47.940 --> 01:16:48.980]   I want you to try it free.
[01:16:48.980 --> 01:16:51.700]   Go to audible.com.
[01:16:51.700 --> 01:16:54.100]   And slash--
[01:16:54.100 --> 01:16:55.900]   2--
[01:16:55.900 --> 01:16:57.820]   Audible.com/twit-- and the number 2,
[01:16:57.820 --> 01:16:59.660]   you're going to sign up for the Platinum account.
[01:16:59.660 --> 01:17:02.380]   That's two books a month, but the first month is free.
[01:17:02.380 --> 01:17:05.140]   Pay nothing for the first 30 days.
[01:17:05.140 --> 01:17:08.140]   You get two credits, but that's almost every case two books.
[01:17:08.140 --> 01:17:09.860]   There are some longer books that are two credits.
[01:17:09.860 --> 01:17:12.100]   If you get a really, really long book,
[01:17:12.100 --> 01:17:14.180]   maybe you'll use both credits on it.
[01:17:14.180 --> 01:17:15.500]   But here's the beauty part.
[01:17:15.500 --> 01:17:17.140]   Cancel it anytime in the first 30 days.
[01:17:17.140 --> 01:17:18.140]   The book is yours to keep.
[01:17:18.140 --> 01:17:19.540]   You pay absolutely nothing.
[01:17:19.540 --> 01:17:20.620]   I don't think you will.
[01:17:20.620 --> 01:17:23.140]   It's kind of a little bet I have with Audible.
[01:17:23.140 --> 01:17:25.580]   I don't think many people cancel once they start listening
[01:17:25.580 --> 01:17:27.500]   to audiobooks from Audible.com.
[01:17:27.500 --> 01:17:32.260]   Audible.com/twit2.
[01:17:32.260 --> 01:17:34.380]   There's a benefit to audiobooks that I don't think you've
[01:17:34.380 --> 01:17:36.940]   ever mentioned, and I've discovered it recently.
[01:17:36.940 --> 01:17:40.420]   I'm reading Eric Schmitz, The New Digital Age.
[01:17:40.420 --> 01:17:42.500]   And it's the dullest book you can imagine.
[01:17:42.500 --> 01:17:44.860]   I have to read it, because I'm a professional.
[01:17:44.860 --> 01:17:45.660]   Don't try this at home.
[01:17:45.660 --> 01:17:46.460]   This is a boy.
[01:17:46.460 --> 01:17:49.660]   Even I cannot bring myself to read this.
[01:17:49.660 --> 01:17:53.100]   I could never force my eyeballs to stay on those words,
[01:17:53.100 --> 01:17:54.300]   but I can listen to it.
[01:17:54.300 --> 01:17:55.260]   And if you have a fast--
[01:17:55.260 --> 01:17:56.940]   And if you need to go to bed.
[01:17:56.940 --> 01:17:58.300]   Yeah, you're right, because Audible
[01:17:58.300 --> 01:17:59.540]   let you listen at double speed.
[01:17:59.540 --> 01:17:59.820]   That's right.
[01:17:59.820 --> 01:18:00.300]   But you're right.
[01:18:00.300 --> 01:18:01.300]   Two minutes and you're out.
[01:18:01.300 --> 01:18:02.980]   Yeah, it's a 10-hour 48.
[01:18:02.980 --> 01:18:03.900]   Yeah, that's great.
[01:18:03.900 --> 01:18:05.300]   Great way to go to sleep.
[01:18:05.300 --> 01:18:08.700]   The New Digital Age.
[01:18:08.700 --> 01:18:11.820]   Which reshaping the future of people, nations, and--
[01:18:11.820 --> 01:18:12.700]   You don't want this.
[01:18:12.700 --> 01:18:13.940]   Eric Schmitz.
[01:18:13.940 --> 01:18:17.340]   With five billion more people set to join the virtual world,
[01:18:17.340 --> 01:18:18.900]   the boom and digital connectivity
[01:18:18.900 --> 01:18:22.540]   will bring games and productivity, health, education--
[01:18:22.540 --> 01:18:23.260]   No, surely he says something.
[01:18:23.260 --> 01:18:24.340]   --all the other watches.
[01:18:24.340 --> 01:18:27.140]   It's interesting topics, but it's just so dry.
[01:18:27.140 --> 01:18:28.660]   And just--
[01:18:28.660 --> 01:18:31.020]   Why did Eric write that book?
[01:18:31.020 --> 01:18:31.380]   I don't know.
[01:18:31.380 --> 01:18:31.740]   He's going to--
[01:18:31.740 --> 01:18:33.980]   Is he felt compelled to?
[01:18:33.980 --> 01:18:35.580]   He's playing it for history, I don't know.
[01:18:35.580 --> 01:18:36.700]   Maybe he's playing it for history.
[01:18:36.700 --> 01:18:37.980]   You might be right.
[01:18:37.980 --> 01:18:39.620]   You might be right.
[01:18:39.620 --> 01:18:41.140]   Anyway, there's lots of good books.
[01:18:41.140 --> 01:18:42.540]   I'm not going to recommend that one,
[01:18:42.540 --> 01:18:44.860]   but if you are in the business and feel
[01:18:44.860 --> 01:18:45.860]   that you need to keep--
[01:18:45.860 --> 01:18:47.700]   There are a lot of books that I actually listen to
[01:18:47.700 --> 01:18:48.580]   because I have to, right?
[01:18:48.580 --> 01:18:52.020]   Silicon Valley, Tech history books and stuff like that.
[01:18:52.020 --> 01:18:53.660]   Now, here's one that's not horrible.
[01:18:53.660 --> 01:18:55.020]   In The Plex by Stephen Levy.
[01:18:55.020 --> 01:18:57.620]   That is a great book.
[01:18:57.620 --> 01:18:59.340]   How Google thinks works and shapes our lives.
[01:18:59.340 --> 01:19:00.700]   Stephen got amazing access.
[01:19:00.700 --> 01:19:03.940]   And it's really-- some of it's quite dramatic.
[01:19:03.940 --> 01:19:06.660]   So you could read that and then read the Eric Schmitz.
[01:19:06.660 --> 01:19:09.340]   People should read the professor and the madman.
[01:19:09.340 --> 01:19:10.620]   Oh, isn't that great?
[01:19:10.620 --> 01:19:11.660]   The story of the octopus--
[01:19:11.660 --> 01:19:12.540]   He read that one?
[01:19:12.540 --> 01:19:15.540]   And the guy in an asylum who was the most
[01:19:15.540 --> 01:19:17.900]   valued outside contributor to the dictionary.
[01:19:17.900 --> 01:19:19.740]   And they didn't even know he was in an asylum
[01:19:19.740 --> 01:19:20.540]   for like a decade.
[01:19:20.540 --> 01:19:23.260]   That book cost me so much money.
[01:19:23.260 --> 01:19:24.100]   Has after--
[01:19:24.100 --> 01:19:24.940]   Is he by the OED after that?
[01:19:24.940 --> 01:19:26.420]   I bought the OED after I listened to it.
[01:19:26.420 --> 01:19:27.980]   Simon Winchester writes great books.
[01:19:27.980 --> 01:19:30.220]   He's written a lot of very interesting history books.
[01:19:30.220 --> 01:19:31.060]   And this is one of them.
[01:19:31.060 --> 01:19:34.500]   He narrates it actually, which is another guy unusual,
[01:19:34.500 --> 01:19:36.500]   but authors sometimes are very good.
[01:19:36.500 --> 01:19:39.340]   A momentary air of mutual embarrassment.
[01:19:39.340 --> 01:19:40.820]   A clock ticked loudly.
[01:19:40.820 --> 01:19:41.820]   Oh, nice, good stuff.
[01:19:41.820 --> 01:19:43.380]   There were maximum footsteps in the hall.
[01:19:43.380 --> 01:19:44.780]   A distant clank of keys.
[01:19:44.780 --> 01:19:46.140]   Highly recommended.
[01:19:46.140 --> 01:19:46.620]   Yeah.
[01:19:46.620 --> 01:19:48.340]   It is not the story of the Gilligan's Island.
[01:19:48.340 --> 01:19:49.540]   Some people thought it might be.
[01:19:49.540 --> 01:19:51.020]   No.
[01:19:51.020 --> 01:19:52.740]   It's untold story.
[01:19:52.740 --> 01:19:53.940]   Although that's a very good book.
[01:19:53.940 --> 01:19:55.060]   And the madman.
[01:19:55.060 --> 01:19:55.580]   Yeah.
[01:19:55.580 --> 01:19:56.860]   Three hours in your home.
[01:19:56.860 --> 01:19:58.380]   Promise.
[01:19:58.380 --> 01:19:58.860]   Three hours.
[01:19:58.860 --> 01:20:00.700]   Yeah, I bought-- not only did I buy the OED,
[01:20:00.700 --> 01:20:02.740]   but I didn't buy the one with the magnifying glass.
[01:20:02.740 --> 01:20:04.380]   I bought the full 20 volume.
[01:20:04.380 --> 01:20:04.780]   Wow.
[01:20:04.780 --> 01:20:05.300]   Dang.
[01:20:05.300 --> 01:20:05.980]   Dang.
[01:20:05.980 --> 01:20:07.260]   It's nice to have.
[01:20:07.260 --> 01:20:08.420]   You don't really go in.
[01:20:08.420 --> 01:20:10.420]   It's as tech people, that's a great book too,
[01:20:10.420 --> 01:20:12.380]   because you realize the steps that they had to go to
[01:20:12.380 --> 01:20:14.740]   because they didn't have a database in the 1800s.
[01:20:14.740 --> 01:20:17.100]   So this guy who compiled it, the professor
[01:20:17.100 --> 01:20:20.140]   had a little round shed, and it had
[01:20:20.140 --> 01:20:22.460]   hundreds-- thousands of slots.
[01:20:22.460 --> 01:20:24.300]   And every new word that they found-- because they'd
[01:20:24.300 --> 01:20:26.620]   have all these readers, including this madman in the--
[01:20:26.620 --> 01:20:27.420]   in "Silent."
[01:20:27.420 --> 01:20:29.060]   And they found an interesting word.
[01:20:29.060 --> 01:20:31.140]   They'd write it on a little slip of paper,
[01:20:31.140 --> 01:20:32.700]   and they put it in a slot.
[01:20:32.700 --> 01:20:33.940]   And then in that word came up.
[01:20:33.940 --> 01:20:35.380]   Again, they put another one in that slot,
[01:20:35.380 --> 01:20:39.220]   and they compiled the definitive dictionary, which
[01:20:39.220 --> 01:20:43.700]   is presumed to have every word in the English language.
[01:20:43.700 --> 01:20:44.460]   Unabridged.
[01:20:44.460 --> 01:20:47.340]   It's about this big.
[01:20:47.340 --> 01:20:49.180]   And to compile them, they just had to--
[01:20:49.180 --> 01:20:51.060]   what word are we up to when they go to the slot,
[01:20:51.060 --> 01:20:53.180]   and they take out all the paper, and then sort through it?
[01:20:53.180 --> 01:20:54.580]   No smoking in that room, I tell you.
[01:20:54.580 --> 01:20:55.620]   The database now.
[01:20:55.620 --> 01:20:57.740]   You got to listen to this book, because it really is a great
[01:20:57.740 --> 01:20:58.580]   story.
[01:20:58.580 --> 01:20:59.020]   And it did.
[01:20:59.020 --> 01:21:00.780]   It made me crave the only thing.
[01:21:00.780 --> 01:21:02.260]   I said, I got to have this.
[01:21:02.260 --> 01:21:04.180]   I had the--
[01:21:04.180 --> 01:21:05.140]   I think there was a CD.
[01:21:05.140 --> 01:21:06.460]   There's a CD wrong, yeah.
[01:21:06.460 --> 01:21:06.820]   Yeah.
[01:21:06.820 --> 01:21:07.300]   And that was--
[01:21:07.300 --> 01:21:07.300]   DV--
[01:21:07.300 --> 01:21:08.020]   That's not satisfying.
[01:21:08.020 --> 01:21:11.700]   You can actually subscribe to it in something like $300 a year.
[01:21:11.700 --> 01:21:13.220]   And I'm thinking if they've lowered that
[01:21:13.220 --> 01:21:16.020]   by an order of magnitude, they could have a pretty huge business.
[01:21:16.020 --> 01:21:17.140]   Why isn't it online?
[01:21:17.140 --> 01:21:17.620]   It is online.
[01:21:17.620 --> 01:21:18.460]   You can subscribe.
[01:21:18.460 --> 01:21:19.460]   But you have to pay $300 a year.
[01:21:19.460 --> 01:21:20.460]   You have to pay $300 a year.
[01:21:20.460 --> 01:21:20.460]   $100 a year.
[01:21:20.460 --> 01:21:21.140]   Every year.
[01:21:21.140 --> 01:21:22.140]   Every year.
[01:21:22.140 --> 01:21:22.640]   $20 a year.
[01:21:22.640 --> 01:21:23.140]   Yeah.
[01:21:23.140 --> 01:21:24.300]   And they would have a million users.
[01:21:24.300 --> 01:21:25.460]   Exactly.
[01:21:25.460 --> 01:21:29.500]   Because it's-- actually, for a writer, and you're all writers--
[01:21:29.500 --> 01:21:30.300]   Yeah.
[01:21:30.300 --> 01:21:34.300]   I'm not a writer, but I pretend it would--
[01:21:34.300 --> 01:21:37.140]   you read a-- you see a word like "comodious."
[01:21:37.140 --> 01:21:39.700]   And Stephen Gibson was saying, wow, that Stephen King is a smart
[01:21:39.700 --> 01:21:39.900]   guy.
[01:21:39.900 --> 01:21:42.060]   He used the word "comodious" in a sentence.
[01:21:42.060 --> 01:21:43.700]   And see, you look it up.
[01:21:43.700 --> 01:21:47.140]   You see, the first time it was used ever in literature.
[01:21:47.140 --> 01:21:48.580]   The etymology is the best part.
[01:21:48.580 --> 01:21:51.220]   Yeah, you see all the nuances of it.
[01:21:51.220 --> 01:21:52.820]   It is for anybody who loves languages.
[01:21:52.820 --> 01:21:54.620]   Wonderful, wonderful book.
[01:21:54.620 --> 01:21:56.780]   But it's not $300 a year, wonderful.
[01:21:56.780 --> 01:21:57.460]   Yeah.
[01:21:57.460 --> 01:21:58.060]   It is great.
[01:21:58.060 --> 01:22:00.420]   I think I spent well over $1,000 for the whole thing.
[01:22:00.420 --> 01:22:01.140]   But once.
[01:22:01.140 --> 01:22:01.500]   But once.
[01:22:01.500 --> 01:22:03.260]   And now I own it.
[01:22:03.260 --> 01:22:05.260]   And it's a great way to make it chicks.
[01:22:05.260 --> 01:22:07.660]   You see, you want to see my--
[01:22:07.660 --> 01:22:08.140]   doesn't work.
[01:22:08.140 --> 01:22:10.300]   And I don't need the magnifying glass.
[01:22:10.300 --> 01:22:11.940]   Look, every page.
[01:22:11.940 --> 01:22:12.580]   Are you feeling--
[01:22:12.580 --> 01:22:13.700]   Give me a letter, any letter.
[01:22:13.700 --> 01:22:16.980]   "comodious" today.
[01:22:16.980 --> 01:22:19.460]   Sometimes I just like to bring girls over and read to them
[01:22:19.460 --> 01:22:19.780]   from it.
[01:22:19.780 --> 01:22:20.540]   It's wonderful.
[01:22:20.540 --> 01:22:21.460]   Put them to sleep.
[01:22:21.460 --> 01:22:23.180]   Put them right out.
[01:22:23.180 --> 01:22:26.420]   So this will wake you up.
[01:22:26.420 --> 01:22:28.460]   There's a massive flaw in Android
[01:22:28.460 --> 01:22:34.500]   discovered by a security research named Blue Box.
[01:22:34.500 --> 01:22:37.860]   They say that it allows any malicious app.
[01:22:37.860 --> 01:22:39.740]   You don't have to have access to the device.
[01:22:39.740 --> 01:22:41.500]   You just have to get somebody to download your app.
[01:22:41.500 --> 01:22:44.980]   You could take existing apps and modify them.
[01:22:44.980 --> 01:22:48.100]   Will allow any hacker to get full access to your phone.
[01:22:48.100 --> 01:22:49.100]   Read anything on it.
[01:22:49.100 --> 01:22:50.380]   Get any passwords.
[01:22:50.380 --> 01:22:51.900]   Control any function.
[01:22:51.900 --> 01:22:52.940]   Send text.
[01:22:52.940 --> 01:22:54.180]   Make phone calls.
[01:22:54.180 --> 01:22:55.260]   Turn on the microphone.
[01:22:55.260 --> 01:22:56.860]   Turn on the camera.
[01:22:56.860 --> 01:23:00.500]   Almost 900 million Android devices are vulnerable.
[01:23:00.500 --> 01:23:03.300]   99% of all devices, according to Blue Box.
[01:23:03.300 --> 01:23:04.460]   Now we haven't been able to vet this
[01:23:04.460 --> 01:23:06.900]   because they haven't released the hack.
[01:23:06.900 --> 01:23:12.820]   They say they will at DEF CON or MSRA at Black Hat, which is in late July.
[01:23:12.820 --> 01:23:15.620]   So you've got a couple of weeks.
[01:23:15.620 --> 01:23:18.900]   This is a real problem for Android phones internationally
[01:23:18.900 --> 01:23:22.900]   because the vast majority of users don't use the Play Store.
[01:23:22.900 --> 01:23:24.380]   And--
[01:23:24.380 --> 01:23:26.380]   You're probably safe if you buy in the Play Store, right?
[01:23:26.380 --> 01:23:28.620]   You probably are because if they discover something that's
[01:23:28.620 --> 01:23:29.860]   using this, they'll pull the plug.
[01:23:29.860 --> 01:23:31.580]   And they'll notify users or whatever.
[01:23:31.580 --> 01:23:34.300]   And it's probably the safest place to go.
[01:23:34.300 --> 01:23:37.940]   There's something like 500 Android stores on the world.
[01:23:37.940 --> 01:23:39.380]   I was so surprised to read that.
[01:23:39.380 --> 01:23:45.300]   Well, you see these huge numbers of how many Android phones
[01:23:45.300 --> 01:23:45.820]   are out there.
[01:23:45.820 --> 01:23:49.860]   And these aren't people in the US and Europe for the most part.
[01:23:49.860 --> 01:23:52.700]   These are mostly like third world countries, China.
[01:23:52.700 --> 01:23:54.780]   And they're people who are not really playing ball
[01:23:54.780 --> 01:23:55.700]   with Google and Android.
[01:23:55.700 --> 01:23:57.820]   They don't give you Google stuff.
[01:23:57.820 --> 01:23:59.260]   They don't give you the Play Store.
[01:23:59.260 --> 01:24:00.700]   The vast majority of Android users
[01:24:00.700 --> 01:24:02.700]   have never heard of the Play Store.
[01:24:02.700 --> 01:24:06.780]   The company, the two-bit no-name company that makes the phone
[01:24:06.780 --> 01:24:08.380]   creates their own Play Store because that's
[01:24:08.380 --> 01:24:10.060]   how they make the money.
[01:24:10.060 --> 01:24:13.260]   And they don't vet stuff there.
[01:24:13.260 --> 01:24:15.340]   Furthermore, there's side load capabilities.
[01:24:15.340 --> 01:24:16.940]   You have to check a box in your settings,
[01:24:16.940 --> 01:24:19.460]   but a lot of us do.
[01:24:19.460 --> 01:24:22.700]   Now, Google was notified about the bug in February,
[01:24:22.700 --> 01:24:24.740]   according to Blue Box.
[01:24:24.740 --> 01:24:27.940]   And Google then, quote, notified their device partners.
[01:24:27.940 --> 01:24:29.380]   And that's part of the problem.
[01:24:29.380 --> 01:24:31.900]   I imagine if you're on a Nexus phone
[01:24:31.900 --> 01:24:34.220]   that you've been fixed already, I would hope.
[01:24:34.220 --> 01:24:36.980]   It's also possible that nobody has ever exploited this.
[01:24:36.980 --> 01:24:39.620]   This is only a potential security flaw.
[01:24:39.620 --> 01:24:43.620]   It's possible that no hacker or even the NSA
[01:24:43.620 --> 01:24:47.100]   has even exploited this flaw.
[01:24:47.100 --> 01:24:48.620]   And really, I don't know--
[01:24:48.620 --> 01:24:50.580]   it would be a difficult thing to do
[01:24:50.580 --> 01:24:53.100]   to gain access to a large number of phones
[01:24:53.100 --> 01:24:56.220]   and go through them and do all this kind of stuff.
[01:24:56.220 --> 01:24:58.100]   Well, as a simple way to make money,
[01:24:58.100 --> 01:25:03.060]   you can send texts to places in the Trinidad or somewhere
[01:25:03.060 --> 01:25:05.220]   where you could send a text for $25.
[01:25:05.220 --> 01:25:07.020]   And you split the money with the--
[01:25:07.020 --> 01:25:10.260]   it's a toll text.
[01:25:10.260 --> 01:25:10.760]   Yeah.
[01:25:10.760 --> 01:25:11.740]   It's a quick way to make a lot of money.
[01:25:11.740 --> 01:25:13.100]   Great idea.
[01:25:13.100 --> 01:25:15.420]   How do you do that?
[01:25:15.420 --> 01:25:18.500]   Well, that's an old hack where you send somebody
[01:25:18.500 --> 01:25:20.780]   an instant message saying, click this link.
[01:25:20.780 --> 01:25:22.220]   And it would send a text.
[01:25:22.220 --> 01:25:25.380]   And suddenly, you got a bill on your phone--
[01:25:25.380 --> 01:25:28.740]   $25 charge-- on your phone bill.
[01:25:28.740 --> 01:25:31.980]   So the-- and the other problem in the Google universe
[01:25:31.980 --> 01:25:35.260]   and the Android universe is--
[01:25:35.260 --> 01:25:38.100]   you know, and this has to be updated by Samsung.
[01:25:38.100 --> 01:25:39.420]   One has to be updated by HTC.
[01:25:39.420 --> 01:25:40.820]   They've got to make the modification.
[01:25:40.820 --> 01:25:41.820]   They're going to make the fix.
[01:25:41.820 --> 01:25:42.860]   They're going to push the fix out.
[01:25:42.860 --> 01:25:45.340]   Then they have to get the carriers to agree in most cases.
[01:25:45.340 --> 01:25:49.060]   The carriers may slow it down too.
[01:25:49.060 --> 01:25:50.940]   This fix may not get out for a long time.
[01:25:50.940 --> 01:25:53.180]   This is yet another opportunity to ask the question,
[01:25:53.180 --> 01:25:55.100]   would it be better if Google took more control?
[01:25:55.100 --> 01:25:55.600]   Yes.
[01:25:55.600 --> 01:25:56.900]   Control around Android.
[01:25:56.900 --> 01:26:00.620]   And part of me thinks, yeah, it might be a good thing
[01:26:00.620 --> 01:26:01.620]   if they just--
[01:26:01.620 --> 01:26:06.580]   just a little bit of apple juice in there somewhere.
[01:26:06.580 --> 01:26:07.620]   Close it up a little bit.
[01:26:07.620 --> 01:26:09.740]   Control it.
[01:26:09.740 --> 01:26:14.500]   According to John Kister--
[01:26:14.500 --> 01:26:16.100]   that can't be his name--
[01:26:16.100 --> 01:26:20.460]   Keith's here, writing for a venture beat.
[01:26:20.460 --> 01:26:21.380]   Kister is funnier.
[01:26:21.380 --> 01:26:22.780]   Kister could be his name.
[01:26:22.780 --> 01:26:24.180]   It could be pronounced that way.
[01:26:24.180 --> 01:26:25.700]   I'm just saying.
[01:26:25.700 --> 01:26:27.700]   And if I were my name, I would probably not
[01:26:27.700 --> 01:26:28.980]   pronounce it that way.
[01:26:28.980 --> 01:26:34.940]   But said that Google gave a patch to carriers in March.
[01:26:34.940 --> 01:26:35.580]   They figured it out.
[01:26:35.580 --> 01:26:38.460]   I fixed it right away.
[01:26:38.460 --> 01:26:39.700]   But I don't think--
[01:26:39.700 --> 01:26:41.180]   I don't know if we've been updated or not.
[01:26:41.180 --> 01:26:42.460]   I don't know which ones are updated.
[01:26:42.460 --> 01:26:43.500]   In March?
[01:26:43.500 --> 01:26:45.020]   They sent a patch to its partners
[01:26:45.020 --> 01:26:46.740]   at the beginning of March.
[01:26:46.740 --> 01:26:49.380]   So do they roll that out for Nexus?
[01:26:49.380 --> 01:26:50.300]   I would think so.
[01:26:50.300 --> 01:26:52.220]   Check my phone.
[01:26:52.220 --> 01:26:56.140]   You might have gotten it months ago and not known.
[01:26:56.140 --> 01:26:57.380]   Google, according to venture beat,
[01:26:57.380 --> 01:26:59.300]   has added checks in the Play Store,
[01:26:59.300 --> 01:27:04.940]   which will guard against apps that use this kind of attack.
[01:27:04.940 --> 01:27:08.500]   So Google Play should be safe.
[01:27:08.500 --> 01:27:10.300]   But I don't know who else is using it.
[01:27:10.300 --> 01:27:12.900]   We don't know what phones are safe.
[01:27:12.900 --> 01:27:14.620]   You use Lookout?
[01:27:14.620 --> 01:27:15.460]   Yeah.
[01:27:15.460 --> 01:27:18.220]   Wonder if they'll update it to kind of go through your apps.
[01:27:18.220 --> 01:27:20.060]   Well, you'd think that it would be a simple thing
[01:27:20.060 --> 01:27:22.580]   to look for certain strings in this hack, right?
[01:27:22.580 --> 01:27:24.020]   But we've got to see the hack first.
[01:27:24.020 --> 01:27:27.860]   So I don't know if Lookout's been given that hack by Bluebox.
[01:27:27.860 --> 01:27:29.780]   I don't know who knows what.
[01:27:29.780 --> 01:27:31.220]   There's a lot of mysteries about all this.
[01:27:31.220 --> 01:27:32.540]   Google says no comment.
[01:27:32.540 --> 01:27:39.620]   If you are using Google Play as an application verification
[01:27:39.620 --> 01:27:42.580]   tool-- I didn't know you could do this--
[01:27:42.580 --> 01:27:47.140]   you can go to your apps menu if you're using 4.2 or later.
[01:27:47.140 --> 01:27:52.500]   Tap Google Settings, Verify Apps, or in Settings Security,
[01:27:52.500 --> 01:27:53.660]   Verify Apps.
[01:27:53.660 --> 01:27:54.780]   That's a great tip.
[01:27:54.780 --> 01:27:55.500]   I had no idea.
[01:27:55.500 --> 01:27:57.020]   I'm going to have to see if that's on here.
[01:27:57.020 --> 01:27:57.900]   So that's Like Lookout.
[01:27:57.900 --> 01:28:00.700]   Lookout does the same thing as scans each app as you download it.
[01:28:00.700 --> 01:28:02.780]   But apparently, there's a built-in Google capability
[01:28:02.780 --> 01:28:03.380]   to do that.
[01:28:03.380 --> 01:28:05.180]   And in fact, it's using the Play Store
[01:28:05.180 --> 01:28:06.500]   in its verification technology.
[01:28:06.500 --> 01:28:08.540]   It's actually one of the first apps I tell people.
[01:28:08.540 --> 01:28:09.020]   Lookout.
[01:28:09.020 --> 01:28:09.980]   Yeah, Like Lookout a lot.
[01:28:09.980 --> 01:28:11.140]   When they get Android.
[01:28:11.140 --> 01:28:13.540]   Although, do we know if it works or-- I mean, do we know what it does?
[01:28:13.540 --> 01:28:16.420]   I use it just so I can remotely kill my phone.
[01:28:16.420 --> 01:28:20.180]   For that-- and it's free for that feature, which is good.
[01:28:20.180 --> 01:28:22.740]   Plus, it's like defragging used to be in the '90s.
[01:28:22.740 --> 01:28:24.940]   It just feels good.
[01:28:24.940 --> 01:28:30.460]   It can be false security, but it's like a security blanket.
[01:28:30.460 --> 01:28:31.460]   Verify Apps.
[01:28:31.460 --> 01:28:34.180]   Block or warm before installing apps that might cause harm.
[01:28:34.180 --> 01:28:37.020]   So this is a Galaxy S4, and it's built into the security--
[01:28:37.020 --> 01:28:39.500]   Every app from now on will potentially cause harm.
[01:28:39.500 --> 01:28:41.180]   But I also have, above it, checked,
[01:28:41.180 --> 01:28:44.780]   allow installation of apps and resources other than the Play Store.
[01:28:44.780 --> 01:28:47.900]   But yeah, well, if you're going to check that, check the verify, too.
[01:28:47.900 --> 01:28:52.540]   And I guess the good advice is to stick with no good source.
[01:28:52.540 --> 01:28:53.060]   Get an iPhone.
[01:28:53.060 --> 01:28:53.580]   I'm kidding.
[01:28:53.580 --> 01:28:54.980]   Get an iPhone.
[01:28:54.980 --> 01:28:55.660]   No, seriously.
[01:28:55.660 --> 01:28:56.660]   Go back to a flip phone.
[01:28:56.660 --> 01:28:58.180]   Or just stay in the Google Play Store.
[01:28:58.180 --> 01:28:58.700]   That's right.
[01:28:58.700 --> 01:28:59.700]   If you're in the Play Store, you're all right.
[01:28:59.700 --> 01:29:01.860]   Resist the temptation to sideload.
[01:29:01.860 --> 01:29:02.580]   I sideload a lot.
[01:29:02.580 --> 01:29:04.100]   You can hack your phone.
[01:29:04.100 --> 01:29:04.940]   I know.
[01:29:04.940 --> 01:29:05.940]   That's how I route things.
[01:29:05.940 --> 01:29:09.340]   And if I often wonder, you know, I'm always installing ROMs from--
[01:29:09.340 --> 01:29:11.380]   you know, it's a forum post on XDA.
[01:29:11.380 --> 01:29:11.700]   Well, that's--
[01:29:11.700 --> 01:29:12.380]   I got to get it.
[01:29:12.380 --> 01:29:13.420]   I got to get it.
[01:29:13.420 --> 01:29:16.140]   Yeah, it's got to be safe.
[01:29:16.140 --> 01:29:19.380]   Android is pushing 70% global markets.
[01:29:19.380 --> 01:29:20.860]   Global is the key word here.
[01:29:20.860 --> 01:29:22.220]   70% global market share.
[01:29:22.220 --> 01:29:23.140]   That's why.
[01:29:23.140 --> 01:29:23.460]   Yeah.
[01:29:23.460 --> 01:29:24.460]   That's why they're scared.
[01:29:24.460 --> 01:29:24.460]   Yeah.
[01:29:24.460 --> 01:29:25.460]   Yeah.
[01:29:25.460 --> 01:29:28.540]   But again, who wants markets share without running?
[01:29:28.540 --> 01:29:31.100]   A lot of those are low-end phones, though, that aren't going to be updated.
[01:29:31.100 --> 01:29:33.100]   And they're the security holes of the future.
[01:29:33.100 --> 01:29:34.460]   Because those are the ones that--
[01:29:34.460 --> 01:29:37.820]   those are like the zombie botnet PCs running XP--
[01:29:37.820 --> 01:29:38.460]   That's right.
[01:29:38.460 --> 01:29:40.180]   --that never got patched.
[01:29:40.180 --> 01:29:42.580]   That's the real scary thing is those phones--
[01:29:42.580 --> 01:29:44.060]   Because they will affect everybody else.
[01:29:44.060 --> 01:29:45.820]   They'll never get those security updates.
[01:29:45.820 --> 01:29:49.900]   The thing that people need to understand about the global market share numbers
[01:29:49.900 --> 01:29:52.380]   is that the biggest thing that's happening in the world right now
[01:29:52.380 --> 01:29:56.020]   is that people who used to have feature phones are getting smartphones.
[01:29:56.020 --> 01:29:56.540]   Smart phones?
[01:29:56.540 --> 01:29:57.820]   They're getting computers.
[01:29:57.820 --> 01:29:59.140]   And they're the--
[01:29:59.140 --> 01:30:03.580]   when my wife and I had been traveling around the world for like 10 months
[01:30:03.580 --> 01:30:05.740]   or something, it was shocking how many feature phones are out there.
[01:30:05.740 --> 01:30:09.980]   I mean, in significant European countries, some of them,
[01:30:09.980 --> 01:30:11.860]   a lot of people are just using feature phones.
[01:30:11.860 --> 01:30:16.300]   So everybody's going to have a smartphone within five years or something.
[01:30:16.300 --> 01:30:18.860]   So all this growth in smartphone markets,
[01:30:18.860 --> 01:30:20.740]   this is a lot of people who don't really even
[01:30:20.740 --> 01:30:21.860]   want a smartphone.
[01:30:21.860 --> 01:30:23.420]   That's just what they're selling.
[01:30:23.420 --> 01:30:25.340]   And so you have to take it with a grain of salt.
[01:30:25.340 --> 01:30:27.580]   They're also going to have people who never really have a computer
[01:30:27.580 --> 01:30:28.820]   or access to a computer before.
[01:30:28.820 --> 01:30:29.340]   Exactly.
[01:30:29.340 --> 01:30:33.380]   Now, their window to the internet is through their phone, which is pretty cool.
[01:30:33.380 --> 01:30:35.740]   But how they use it remains to be seen.
[01:30:35.740 --> 01:30:37.820]   It may be web browsing.
[01:30:37.820 --> 01:30:39.460]   Are there going to be lots of app downloads?
[01:30:39.460 --> 01:30:42.300]   Are they going to be buying things or just sort of doing the basics?
[01:30:42.300 --> 01:30:45.500]   We don't know exactly what those users look like.
[01:30:45.500 --> 01:30:48.580]   There's a big movement of foot by Google and also Facebook
[01:30:48.580 --> 01:30:52.700]   and a few other companies to go make deals with carriers in places
[01:30:52.700 --> 01:30:56.700]   where people are paying for every bite of data.
[01:30:56.700 --> 01:31:02.260]   And the way that works is in the case of Google just did a one in India,
[01:31:02.260 --> 01:31:05.700]   where if you use Gmail, Google Search, or Google+,
[01:31:05.700 --> 01:31:08.180]   you don't pay for the data, the minutes on that data.
[01:31:08.180 --> 01:31:11.220]   So that's favoring the usage in these countries
[01:31:11.220 --> 01:31:13.540]   to using these Google services.
[01:31:13.540 --> 01:31:15.620]   Why they're doing that, I'm not sure.
[01:31:15.620 --> 01:31:20.220]   But this is one of the big things you see in the third world
[01:31:20.220 --> 01:31:24.540]   and the second world where if you want to use the internet,
[01:31:24.540 --> 01:31:28.140]   you're using these services so that some services are free and some aren't
[01:31:28.140 --> 01:31:29.860]   based on what deals were made.
[01:31:29.860 --> 01:31:33.220]   If Google made enough money, they probably could subsidize these phones, right?
[01:31:33.220 --> 01:31:33.860]   I mean--
[01:31:33.860 --> 01:31:36.860]   That's what I wrote a column recently not to sound like the VORAC,
[01:31:36.860 --> 01:31:40.220]   but I wrote a column recently.
[01:31:40.220 --> 01:31:41.420]   He owns that by a trademark.
[01:31:41.420 --> 01:31:42.140]   Yeah, I know.
[01:31:42.140 --> 01:31:44.660]   I'm going to have to pay him royalties now.
[01:31:44.660 --> 01:31:47.820]   But I'm kind of thinking that we're getting the point where smartphones
[01:31:47.820 --> 01:31:52.740]   are going to be free as long as you add supported and so on.
[01:31:52.740 --> 01:31:54.340]   So we're getting to that point.
[01:31:54.340 --> 01:31:56.500]   I think it's a great thing.
[01:31:56.500 --> 01:31:58.860]   Yeah, that's how you resolve the privacy issue.
[01:31:58.860 --> 01:32:00.300]   Would you like a free phone?
[01:32:00.300 --> 01:32:01.140]   Just to do it.
[01:32:01.140 --> 01:32:03.300]   And if people don't want the free phone, they'd have to take it.
[01:32:03.300 --> 01:32:03.540]   That's right.
[01:32:03.540 --> 01:32:04.900]   If you want to pay for it, we--
[01:32:04.900 --> 01:32:07.020]   But what's sad is it means that only people with means
[01:32:07.020 --> 01:32:08.100]   will be able to afford privacy.
[01:32:08.100 --> 01:32:09.740]   Privacy will be a luxury item.
[01:32:09.740 --> 01:32:10.660]   And that's kind of sad.
[01:32:10.660 --> 01:32:12.820]   I'm a little concerned about the-- I mean, smartphones--
[01:32:12.820 --> 01:32:14.100]   it depends on how we're doing it.
[01:32:14.100 --> 01:32:16.380]   But a lot of these smartphones that are going to people who use feature
[01:32:16.380 --> 01:32:19.700]   phones before, it really is a--
[01:32:19.700 --> 01:32:21.020]   are they going to use those features?
[01:32:21.020 --> 01:32:24.220]   Or is it just kind of a scam that the carrier--
[01:32:24.220 --> 01:32:26.580]   especially in the US, I see this a lot--
[01:32:26.580 --> 01:32:30.060]   they're pushing these phones on people who might not use many of the features.
[01:32:30.060 --> 01:32:31.420]   Oh, it's got the internet on it.
[01:32:31.420 --> 01:32:32.460]   And it's free.
[01:32:32.460 --> 01:32:33.620]   But what they're really doing is they're
[01:32:33.620 --> 01:32:36.140]   getting them to buy that expensive data plan.
[01:32:36.140 --> 01:32:39.100]   And that's very profitable for them.
[01:32:39.100 --> 01:32:40.540]   But you may end up with a lot of people
[01:32:40.540 --> 01:32:44.060]   who are paying for a data plan that they don't really use, which is--
[01:32:44.060 --> 01:32:44.940]   it's wasteful.
[01:32:44.940 --> 01:32:46.140]   So that's my question.
[01:32:46.140 --> 01:32:49.100]   If all you're doing is some email and the occasional web browser,
[01:32:49.100 --> 01:32:53.700]   do you want to spend that amount of money on a data plan on that phone?
[01:32:53.700 --> 01:32:56.380]   So Sony is going to be coming out with this product that's essentially
[01:32:56.380 --> 01:32:59.580]   a Bluetooth dongle that's designed to work with their phablets.
[01:32:59.580 --> 01:33:01.940]   So the idea is you have this giant Sony phablets.
[01:33:01.940 --> 01:33:03.260]   You're just making up words now.
[01:33:03.260 --> 01:33:03.760]   I am now.
[01:33:03.760 --> 01:33:05.860]   I've heard you use the word phablets many times.
[01:33:05.860 --> 01:33:07.500]   Is it a phablet dongle?
[01:33:07.500 --> 01:33:09.020]   At least I haven't ever bought a phablet.
[01:33:09.020 --> 01:33:09.820]   Everybody's just tuning in.
[01:33:09.820 --> 01:33:10.660]   Yes, those are real words.
[01:33:10.660 --> 01:33:11.340]   Yes, yes.
[01:33:11.340 --> 01:33:12.380]   And we apologize.
[01:33:12.380 --> 01:33:15.780]   But what it is is it's a dongle that is--
[01:33:15.780 --> 01:33:17.180]   you can plug in earphones and stuff.
[01:33:17.180 --> 01:33:18.580]   But you can also answer it like a phone.
[01:33:18.580 --> 01:33:20.780]   It's basically a phone that doesn't do anything.
[01:33:20.780 --> 01:33:22.020]   And that's the benefit.
[01:33:22.020 --> 01:33:23.340]   Doesn't have much of a screen.
[01:33:23.340 --> 01:33:24.340]   Wait a minute.
[01:33:24.340 --> 01:33:24.860]   All right.
[01:33:24.860 --> 01:33:25.340]   OK.
[01:33:25.340 --> 01:33:25.860]   What?
[01:33:25.860 --> 01:33:29.700]   So imagine you-- so it's technically
[01:33:29.700 --> 01:33:31.740]   aware of all because it clips onto your clothing.
[01:33:31.740 --> 01:33:33.740]   So imagine a Bluetooth dongle that goes in your ear
[01:33:33.740 --> 01:33:35.060]   that we're all familiar with.
[01:33:35.060 --> 01:33:38.540]   It's like that except for-- it's like a stick-a-gum.
[01:33:38.540 --> 01:33:39.620]   It's a tiny little black thing.
[01:33:39.620 --> 01:33:41.060]   We could probably bring it up on screen.
[01:33:41.060 --> 01:33:42.340]   There's some nice pictures online.
[01:33:42.340 --> 01:33:44.980]   It's called the Sony Bluetooth.
[01:33:44.980 --> 01:33:46.660]   It's a terrible Sony--
[01:33:46.660 --> 01:33:47.700]   Not a Sony product name.
[01:33:47.700 --> 01:33:48.140]   Yes.
[01:33:48.140 --> 01:33:49.060]   Yeah, it's awful.
[01:33:49.060 --> 01:33:50.340]   They didn't want to use dongle.
[01:33:50.340 --> 01:33:51.500]   But they announced it recently.
[01:33:51.500 --> 01:33:52.900]   And they're shipping it next month.
[01:33:52.900 --> 01:33:54.260]   And it's actually kind of cool.
[01:33:54.260 --> 01:33:55.460]   But it clips under your shirt.
[01:33:55.460 --> 01:33:57.580]   And then when the phone rings, instead of bringing out
[01:33:57.580 --> 01:34:02.220]   your 15-inch phone, you just unclip the thing and you answer it.
[01:34:02.220 --> 01:34:03.980]   And you're back in--
[01:34:03.980 --> 01:34:06.940]   it's basically if you ever saw a Zoolander, it's basically
[01:34:06.940 --> 01:34:07.540]   that phone.
[01:34:07.540 --> 01:34:08.860]   It's just a phone phone.
[01:34:08.860 --> 01:34:09.820]   Yeah.
[01:34:09.820 --> 01:34:12.740]   So does it work in conjunction with whatever your--
[01:34:12.740 --> 01:34:13.420]   Exactly.
[01:34:13.420 --> 01:34:14.540]   We did a story last week.
[01:34:14.540 --> 01:34:15.300]   There it is.
[01:34:15.300 --> 01:34:16.340]   Is that it?
[01:34:16.340 --> 01:34:16.900]   That is it.
[01:34:16.900 --> 01:34:18.700]   Yeah, that's it.
[01:34:18.700 --> 01:34:21.580]   That's not a bad idea if you've got a tablet or you've
[01:34:21.580 --> 01:34:23.580]   got a tablet with a cellular connect connection.
[01:34:23.580 --> 01:34:24.860]   I don't want that.
[01:34:24.860 --> 01:34:25.380]   I want it too.
[01:34:25.380 --> 01:34:26.980]   And here's-- what is it too?
[01:34:26.980 --> 01:34:29.860]   I don't know.
[01:34:29.860 --> 01:34:30.780]   Makes you go cold.
[01:34:30.780 --> 01:34:30.780]   Exactly.
[01:34:30.780 --> 01:34:31.220]   You just want it.
[01:34:31.220 --> 01:34:33.020]   Well, this is the irony, though.
[01:34:33.020 --> 01:34:34.980]   This is the world we're entering into.
[01:34:34.980 --> 01:34:35.900]   It's got buttons.
[01:34:35.900 --> 01:34:37.020]   It's got a head full.
[01:34:37.020 --> 01:34:39.540]   People who are poor are going to get a free smartphone that
[01:34:39.540 --> 01:34:40.500]   does everything.
[01:34:40.500 --> 01:34:42.820]   And you have to be wealthy to have a phone that does nothing.
[01:34:42.820 --> 01:34:44.300]   Like, that's the--
[01:34:44.300 --> 01:34:45.500]   Ultimate irony of life.
[01:34:45.500 --> 01:34:45.980]   Exactly.
[01:34:45.980 --> 01:34:46.940]   Thank you, Roger.
[01:34:46.940 --> 01:34:48.020]   That's exactly it.
[01:34:48.020 --> 01:34:51.500]   So do any of you actually make regular phone calls?
[01:34:51.500 --> 01:34:53.780]   Because pretty much 95% of the--
[01:34:53.780 --> 01:34:54.780]   I don't make any calls.
[01:34:54.780 --> 01:34:55.260]   I am.
[01:34:55.260 --> 01:34:55.300]   I am.
[01:34:55.300 --> 01:34:55.460]   I am.
[01:34:55.460 --> 01:34:57.260]   People call me, though.
[01:34:57.260 --> 01:34:59.100]   No, no, despite my efforts.
[01:34:59.100 --> 01:35:00.740]   The only people that call me are the phone come.
[01:35:00.740 --> 01:35:01.500]   My mom calls me.
[01:35:01.500 --> 01:35:02.500]   My mom calls me.
[01:35:02.500 --> 01:35:03.020]   My mom calls me.
[01:35:03.020 --> 01:35:03.820]   Well, my dad calls me.
[01:35:03.820 --> 01:35:04.900]   But I got her on Skype.
[01:35:04.900 --> 01:35:07.620]   I'm getting her on the text messaging, that kind of thing.
[01:35:07.620 --> 01:35:08.220]   I want that.
[01:35:08.220 --> 01:35:09.340]   Can I have that?
[01:35:09.340 --> 01:35:09.660]   What is it?
[01:35:09.660 --> 01:35:12.500]   The SBH 52?
[01:35:12.500 --> 01:35:15.940]   Not to parrot what the CEO of Blackberry said.
[01:35:15.940 --> 01:35:18.260]   But when he said, oh, tablets.
[01:35:18.260 --> 01:35:19.740]   They're still around so far.
[01:35:19.740 --> 01:35:20.540]   Sorry, Canada.
[01:35:20.540 --> 01:35:22.460]   See, we say nice things about Canada.
[01:35:22.460 --> 01:35:23.740]   We say bad things about Canada.
[01:35:23.740 --> 01:35:26.380]   But they said, what he said was right that sooner or later,
[01:35:26.380 --> 01:35:28.220]   we're going to be carrying around something
[01:35:28.220 --> 01:35:29.460]   on our body somewhere.
[01:35:29.460 --> 01:35:29.900]   Yeah.
[01:35:29.900 --> 01:35:31.740]   NSA knows where.
[01:35:31.740 --> 01:35:33.660]   That it has the internet connection.
[01:35:33.660 --> 01:35:34.940]   And all the other devices are just
[01:35:34.940 --> 01:35:36.500]   going to attach to that internet connection.
[01:35:36.500 --> 01:35:37.940]   Maybe that's our phone.
[01:35:37.940 --> 01:35:39.340]   Maybe that's some other device.
[01:35:39.340 --> 01:35:41.460]   Because having a bunch of different devices
[01:35:41.460 --> 01:35:44.180]   that are kind of on the internet and don't talk to each other
[01:35:44.180 --> 01:35:45.820]   is ultimately is ridiculous.
[01:35:45.820 --> 01:35:47.660]   And if you want a little thing that you stick in your ear
[01:35:47.660 --> 01:35:48.340]   to talk to somebody--
[01:35:48.340 --> 01:35:49.900]   Now you can just buy this smartwatch.
[01:35:49.900 --> 01:35:50.500]   Smartwatch.
[01:35:50.500 --> 01:35:50.980]   I want that, too.
[01:35:50.980 --> 01:35:52.620]   Look at Sony makes that, too.
[01:35:52.620 --> 01:35:53.540]   They already make that.
[01:35:53.540 --> 01:35:54.040]   No, no, no.
[01:35:54.040 --> 01:35:56.140]   They have Sony accessory on every part of your body.
[01:35:56.140 --> 01:35:58.020]   There's a new one coming out next month that
[01:35:58.020 --> 01:35:59.460]   is actually more expensive.
[01:35:59.460 --> 01:36:00.660]   I hate it when that happens.
[01:36:00.660 --> 01:36:02.660]   You should build a smart belt.
[01:36:02.660 --> 01:36:03.700]   Because you can build it--
[01:36:03.700 --> 01:36:04.700]   You could put more in it.
[01:36:04.700 --> 01:36:05.460]   You could put more in it.
[01:36:05.460 --> 01:36:06.700]   You could put the batteries.
[01:36:06.700 --> 01:36:07.500]   Utility belt.
[01:36:07.500 --> 01:36:09.420]   And then the display could be glasses
[01:36:09.420 --> 01:36:10.940]   that you put on and connects wireless.
[01:36:10.940 --> 01:36:13.340]   OK, I'm going to share you my million dollar idea.
[01:36:13.340 --> 01:36:14.020]   Just among our--
[01:36:14.020 --> 01:36:15.420]   Don't tell anybody.
[01:36:15.420 --> 01:36:17.420]   You're all NDA to them bargains.
[01:36:17.420 --> 01:36:18.580]   Because nobody's--
[01:36:18.580 --> 01:36:19.180]   Nobody's--
[01:36:19.180 --> 01:36:19.660]   Nobody's watching.
[01:36:19.660 --> 01:36:20.020]   Just us.
[01:36:20.020 --> 01:36:21.460]   Just us.
[01:36:21.460 --> 01:36:23.260]   Because Google Glass, it looks kind of funny.
[01:36:23.260 --> 01:36:25.340]   It's hanging in front of your face.
[01:36:25.340 --> 01:36:28.220]   Smart hats.
[01:36:28.220 --> 01:36:29.060]   You right?
[01:36:29.060 --> 01:36:30.060]   Look, you do this.
[01:36:30.060 --> 01:36:30.580]   You have a slow time.
[01:36:30.580 --> 01:36:33.700]   On the bottom of the brim, it'll have lots of information.
[01:36:33.700 --> 01:36:36.300]   But from the outside, and there'll be a baseball hat.
[01:36:36.300 --> 01:36:38.180]   They'll be a fedora.
[01:36:38.180 --> 01:36:39.100]   They'll be a--
[01:36:39.100 --> 01:36:40.980]   There's so many traffic accidents.
[01:36:40.980 --> 01:36:43.260]   There's so many traffic accidents.
[01:36:43.260 --> 01:36:45.660]   Smart hats, it's going to happen.
[01:36:45.660 --> 01:36:46.340]   Are you drunk?
[01:36:46.340 --> 01:36:49.220]   I'm going to be the Doug Inglebar of Smart Hats.
[01:36:49.220 --> 01:36:51.700]   That's what I'm saying.
[01:36:51.700 --> 01:36:52.580]   I like it.
[01:36:52.580 --> 01:36:53.860]   Smart hats.
[01:36:53.860 --> 01:36:56.620]   Abe Lincoln used to store his speeches in his hat.
[01:36:56.620 --> 01:36:58.260]   You'd now he could just look up.
[01:36:58.260 --> 01:37:00.260]   His teleprompter would be in his hat.
[01:37:00.260 --> 01:37:02.180]   You could put an Apple--
[01:37:02.180 --> 01:37:04.780]   one of those new Apple computers in one of those hats.
[01:37:04.780 --> 01:37:08.260]   The smart hat is a good idea.
[01:37:08.260 --> 01:37:08.780]   Everything.
[01:37:08.780 --> 01:37:09.420]   Press it says--
[01:37:09.420 --> 01:37:10.060]   Talk to the smart hats.
[01:37:10.060 --> 01:37:11.180]   Digital.
[01:37:11.180 --> 01:37:11.660]   Smart hats.
[01:37:11.660 --> 01:37:12.500]   A lot of weight on your head.
[01:37:12.500 --> 01:37:13.260]   I want that.
[01:37:13.260 --> 01:37:14.700]   All right.
[01:37:14.700 --> 01:37:18.700]   Leo, are you sure you'll be the beta tester for the smart hat?
[01:37:18.700 --> 01:37:21.260]   All that wireless energy going straight through your skull.
[01:37:21.260 --> 01:37:22.380]   Those are hats.
[01:37:22.380 --> 01:37:23.660]   Those are hats, but they're not smart.
[01:37:23.660 --> 01:37:24.420]   They're not smart.
[01:37:24.420 --> 01:37:26.100]   It looks like if you wore this hat,
[01:37:26.100 --> 01:37:28.540]   you would probably say, well, it must be a smart hat.
[01:37:28.540 --> 01:37:30.780]   Otherwise, why would you be wearing that?
[01:37:30.780 --> 01:37:32.700]   It's a very small brim.
[01:37:32.700 --> 01:37:34.740]   No, it's like a--
[01:37:34.740 --> 01:37:37.060]   No, you want a small brim because you don't want--
[01:37:37.060 --> 01:37:44.380]   if it's like that, it's like a 52-inch TV four-feet away.
[01:37:44.380 --> 01:37:45.220]   It's the future, man.
[01:37:45.220 --> 01:37:48.060]   What I want is the anti-NSA Google Glass that
[01:37:48.060 --> 01:37:50.980]   has the nose and the mustache to disguise you
[01:37:50.980 --> 01:37:51.980]   so that they're not--
[01:37:51.980 --> 01:37:52.980]   So have you seen this?
[01:37:52.980 --> 01:37:53.420]   --in the tail in the cap.
[01:37:53.420 --> 01:37:57.420]   Have you seen those glasses that are designed to basically shoot
[01:37:57.420 --> 01:37:59.060]   out an infrared burst of lighting?
[01:37:59.060 --> 01:37:59.820]   Yeah, yeah, yeah.
[01:37:59.820 --> 01:38:01.660]   We were going to make one for Colleen.
[01:38:01.660 --> 01:38:04.420]   So if you can-- if you don't want to have anybody take
[01:38:04.420 --> 01:38:06.460]   your picture, you can have-- and she
[01:38:06.460 --> 01:38:08.620]   was going to have a collar that we--
[01:38:08.620 --> 01:38:09.300]   She would wear a collar.
[01:38:09.300 --> 01:38:12.460]   And she walked in the studio that would emit infrared.
[01:38:12.460 --> 01:38:14.580]   It's very, very bright, and cameras could see it,
[01:38:14.580 --> 01:38:15.660]   but humans can't.
[01:38:15.660 --> 01:38:17.860]   So she would look like a glowing head of--
[01:38:17.860 --> 01:38:18.860]   her head would look like a glowing ball.
[01:38:18.860 --> 01:38:19.740]   Like an angel.
[01:38:19.740 --> 01:38:23.380]   It would just be a little IR collar that would-- I think
[01:38:23.380 --> 01:38:24.380]   it's a good--
[01:38:24.380 --> 01:38:26.020]   Eye collar, a smart collar.
[01:38:26.020 --> 01:38:26.940]   Oh, man.
[01:38:26.940 --> 01:38:28.020]   And then the smart leash.
[01:38:28.020 --> 01:38:29.260]   How long before, though?
[01:38:29.260 --> 01:38:31.420]   I mean, people are concerned-- everybody's got a camera,
[01:38:31.420 --> 01:38:31.820]   right?
[01:38:31.820 --> 01:38:33.140]   I think-- you know, I worry.
[01:38:33.140 --> 01:38:35.540]   If I were a teenager today, nothing, you can't do anything.
[01:38:35.540 --> 01:38:36.500]   Teenagers don't worry.
[01:38:36.500 --> 01:38:37.700]   You can't get away with anything.
[01:38:37.700 --> 01:38:38.940]   That's the problem with teenagers.
[01:38:38.940 --> 01:38:40.460]   They'll try, but they won't get away with it.
[01:38:40.460 --> 01:38:42.020]   I feel like this show is going to be
[01:38:42.020 --> 01:38:44.700]   pryard in some horrible patent dispute in 10 years.
[01:38:44.700 --> 01:38:45.780]   We're like, see?
[01:38:45.780 --> 01:38:46.980]   See, he invented it.
[01:38:46.980 --> 01:38:49.180]   Smart hat, smart hat, smart hat, smart collar.
[01:38:49.180 --> 01:38:50.860]   Hey, don't forget the smart belt.
[01:38:50.860 --> 01:38:51.620]   Smart belt?
[01:38:51.620 --> 01:38:53.580]   Can you imagine the amount of lithium cells
[01:38:53.580 --> 01:38:54.620]   you could put on that thing?
[01:38:54.620 --> 01:38:58.500]   So this Don Mattrick story is a great story.
[01:38:58.500 --> 01:39:03.020]   He was Microsoft's-- everybody, look, your phone's all went off.
[01:39:03.020 --> 01:39:04.060]   People are texting you?
[01:39:04.060 --> 01:39:05.860]   OK.
[01:39:05.860 --> 01:39:08.700]   He was the Microsoft Interactive Entertainment President.
[01:39:08.700 --> 01:39:12.300]   He was the guy who, when Xbox One came out,
[01:39:12.300 --> 01:39:16.380]   said, "The always on internet wasn't a problem
[01:39:16.380 --> 01:39:17.820]   unless you were in a submarine."
[01:39:17.820 --> 01:39:19.340]   Right.
[01:39:19.340 --> 01:39:22.140]   And then was, I believe, forced--
[01:39:22.140 --> 01:39:24.140]   I think he got Scott forestalled.
[01:39:24.140 --> 01:39:24.780]   Yep.
[01:39:24.780 --> 01:39:27.100]   Where-- this is what happened to Scott, right?
[01:39:27.100 --> 01:39:28.620]   At Apple, they went to Scott and said,
[01:39:28.620 --> 01:39:31.100]   "You need to write an apology letter for maps."
[01:39:31.100 --> 01:39:33.500]   And Scott said, "I don't think so."
[01:39:33.500 --> 01:39:35.100]   And they said, "OK, goodbye."
[01:39:35.100 --> 01:39:37.900]   Tim Cook said, "I'll write it, but you are gone."
[01:39:37.900 --> 01:39:40.380]   I think the same thing happened to Don Mattrick.
[01:39:40.380 --> 01:39:44.700]   When Microsoft did the 180 on the Xbox, they said, "Don,
[01:39:44.700 --> 01:39:45.900]   would you like to write that letter?"
[01:39:45.900 --> 01:39:49.180]   And he said, "I would, but he's still gone."
[01:39:49.180 --> 01:39:53.620]   He is-- I don't know if this is the Booby Prize.
[01:39:53.620 --> 01:39:57.580]   He is now the CEO of Zynga.
[01:39:57.580 --> 01:39:58.300]   That's not good.
[01:39:58.300 --> 01:39:59.060]   That's not fitting.
[01:39:59.060 --> 01:40:01.380]   And although that's not good.
[01:40:01.380 --> 01:40:01.820]   Yeah.
[01:40:01.820 --> 01:40:03.820]   They probably gave him a lot of money.
[01:40:03.820 --> 01:40:06.300]   So Mark Pinkis, who ran Zynga, finally realized,
[01:40:06.300 --> 01:40:08.580]   I guess I'm not the right guy to run this company.
[01:40:08.580 --> 01:40:10.020]   Zynga's been really struggling.
[01:40:10.020 --> 01:40:12.380]   Zynga was on top with Farmville.
[01:40:12.380 --> 01:40:15.060]   And all those Facebook games, they had poker, right?
[01:40:15.060 --> 01:40:18.380]   It was the big winner for them, was some sort of head-to-head poker.
[01:40:18.380 --> 01:40:20.700]   They bought words with friends and all the words
[01:40:20.700 --> 01:40:24.380]   with friends thing.
[01:40:24.380 --> 01:40:26.380]   But what happened was it turned out
[01:40:26.380 --> 01:40:30.780]   being a Facebook game company is not a great place to be.
[01:40:30.780 --> 01:40:32.500]   They started to move mobile.
[01:40:32.500 --> 01:40:36.180]   They went out and bought OMG Pop for an insane amount of money.
[01:40:36.180 --> 01:40:36.820]   Then shut it down.
[01:40:36.820 --> 01:40:39.020]   Then shut it down.
[01:40:39.020 --> 01:40:41.020]   Also bought our previous building.
[01:40:41.020 --> 01:40:42.860]   And they are in the-- well, did they buy it?
[01:40:42.860 --> 01:40:43.460]   They literally--
[01:40:43.460 --> 01:40:44.100]   I thought they--
[01:40:44.100 --> 01:40:45.100]   Well, they shut that down too.
[01:40:45.100 --> 01:40:45.860]   They were in a tech TV building.
[01:40:45.860 --> 01:40:46.820]   Yeah, I thought they bought it.
[01:40:46.820 --> 01:40:48.900]   I thought they were on a lease and they eventually bought it.
[01:40:48.900 --> 01:40:49.180]   I could--
[01:40:49.180 --> 01:40:50.420]   They took it over, I think.
[01:40:50.420 --> 01:40:50.980]   Yeah.
[01:40:50.980 --> 01:40:53.020]   You know, but Microsoft isn't a great place to be right now,
[01:40:53.020 --> 01:40:53.500]   either.
[01:40:53.500 --> 01:40:53.940]   I mean--
[01:40:53.940 --> 01:40:56.020]   Well, they're about to undergo a rework, probably.
[01:40:56.020 --> 01:40:57.420]   And I guess that--
[01:40:57.420 --> 01:40:58.140]   Get rid of Walmart.
[01:40:58.140 --> 01:40:59.620]   This had really does not help.
[01:40:59.620 --> 01:41:00.980]   My credibility.
[01:41:00.980 --> 01:41:05.020]   I look like I'm a Jamaican taxi driver.
[01:41:05.020 --> 01:41:07.140]   Yeah, man, what do you want to go?
[01:41:07.140 --> 01:41:11.140]   I take you anywhere on the island.
[01:41:11.140 --> 01:41:11.780]   I don't want to go.
[01:41:11.780 --> 01:41:13.540]   You got an Egonjaman.
[01:41:13.540 --> 01:41:15.180]   All right.
[01:41:15.180 --> 01:41:15.980]   Taking the hat off.
[01:41:15.980 --> 01:41:17.660]   It's smart.
[01:41:17.660 --> 01:41:18.300]   Ish.
[01:41:18.300 --> 01:41:19.140]   You made a smart move.
[01:41:19.140 --> 01:41:20.620]   It was smart-ish.
[01:41:20.620 --> 01:41:23.060]   Take off the hat.
[01:41:23.060 --> 01:41:24.420]   I forgot what I was--
[01:41:24.420 --> 01:41:27.460]   Oh, because Microsoft's got some riser too.
[01:41:27.460 --> 01:41:29.580]   But I really think they've got to get rid of Balmer.
[01:41:29.580 --> 01:41:30.940]   This guy is just--
[01:41:30.940 --> 01:41:31.820]   It's kind of late.
[01:41:31.820 --> 01:41:35.100]   Being Bill Gates's college friend is not a good reason
[01:41:35.100 --> 01:41:36.460]   to run a company like that.
[01:41:36.460 --> 01:41:37.900]   And it's just been failure after failure.
[01:41:37.900 --> 01:41:41.100]   I think they've squandered so many opportunities.
[01:41:41.100 --> 01:41:42.020]   It's just smart.
[01:41:42.020 --> 01:41:43.460]   It's kind of tragic.
[01:41:43.460 --> 01:41:45.580]   Now, Steven Sinofsky, the man who
[01:41:45.580 --> 01:41:48.060]   inflicted Windows 8 on the world,
[01:41:48.060 --> 01:41:50.300]   has agreed to not compete with Microsoft
[01:41:50.300 --> 01:41:52.300]   through the end of this year.
[01:41:52.300 --> 01:41:54.420]   Yeah, that's not--
[01:41:54.420 --> 01:41:55.460]   Six months.
[01:41:55.460 --> 01:41:58.860]   He gets $14 million for it.
[01:41:58.860 --> 01:42:00.220]   I hope he enjoys his gardening.
[01:42:00.220 --> 01:42:02.540]   Who's running this company?
[01:42:02.540 --> 01:42:04.980]   Steven, please don't please whatever you please do not
[01:42:04.980 --> 01:42:05.660]   compete with us.
[01:42:05.660 --> 01:42:08.140]   What will it take to get you to not compete with us?
[01:42:08.140 --> 01:42:10.260]   Well, I won't compete with you until December if you give me
[01:42:10.260 --> 01:42:11.340]   $14 million.
[01:42:11.340 --> 01:42:14.460]   And they agreed to it.
[01:42:14.460 --> 01:42:17.180]   Does this story-- I wonder about the sequence here.
[01:42:17.180 --> 01:42:20.420]   If this was more like they're reporting on what his deal is,
[01:42:20.420 --> 01:42:22.700]   and that includes a non-compete.
[01:42:22.700 --> 01:42:23.940]   Because they're a public company, they
[01:42:23.940 --> 01:42:26.420]   had to file this with the SEC.
[01:42:26.420 --> 01:42:31.060]   They are giving him 418,000 shares of Microsoft stock.
[01:42:31.060 --> 01:42:33.260]   It's the retirement agreement.
[01:42:33.260 --> 01:42:36.180]   Also reveals Microsoft is enforcing the non-compete
[01:42:36.180 --> 01:42:36.580]   agreement.
[01:42:36.580 --> 01:42:37.660]   There's a non-compete, but there's
[01:42:37.660 --> 01:42:39.700]   also the no-disparage law, whatever it's called.
[01:42:39.700 --> 01:42:40.700]   There's no--
[01:42:40.700 --> 01:42:41.580]   Trash talk us law.
[01:42:41.580 --> 01:42:42.580]   We knew that was the case.
[01:42:42.580 --> 01:42:43.900]   And that's pretty standard.
[01:42:43.900 --> 01:42:46.660]   But the short period of time, I think,
[01:42:46.660 --> 01:42:49.420]   is pretty unstanded, usually like three years or something.
[01:42:49.420 --> 01:42:52.260]   Yeah, December 31, 2013, he will not
[01:42:52.260 --> 01:42:54.820]   be able to accept deployment of certain competitors
[01:42:54.820 --> 01:42:57.660]   or encourage customers of Microsoft
[01:42:57.660 --> 01:42:59.660]   to choose a competing offering.
[01:42:59.660 --> 01:43:01.060]   So he's no ads--
[01:43:01.060 --> 01:43:03.140]   So January 1, he's going to be out there
[01:43:03.140 --> 01:43:05.820]   hawking something else that directly competes.
[01:43:05.820 --> 01:43:08.500]   And the no-disparage clause is also in effect.
[01:43:08.500 --> 01:43:09.180]   You're right, Mike.
[01:43:09.180 --> 01:43:10.180]   This is Microsoft.
[01:43:10.180 --> 01:43:12.380]   You look at Microsoft's track record here,
[01:43:12.380 --> 01:43:15.620]   and it's easy for me as a guy who's always been following Apple
[01:43:15.620 --> 01:43:16.580]   to bash Microsoft.
[01:43:16.580 --> 01:43:18.500]   But Microsoft has done some really interesting things
[01:43:18.500 --> 01:43:19.500]   over the last few years.
[01:43:19.500 --> 01:43:21.620]   And I feel like the more I look at it,
[01:43:21.620 --> 01:43:24.460]   the more it's opportunities, really good opportunities
[01:43:24.460 --> 01:43:25.380]   kind of wasted.
[01:43:25.380 --> 01:43:26.420]   Absolutely.
[01:43:26.420 --> 01:43:28.460]   I think the biggest one is that they
[01:43:28.460 --> 01:43:30.220]   had the Microsoft Surface table before it
[01:43:30.220 --> 01:43:31.580]   was a tiny little thing.
[01:43:31.580 --> 01:43:34.140]   First of all, switching the name over to the laptop thing
[01:43:34.140 --> 01:43:35.340]   was a big--
[01:43:35.340 --> 01:43:35.860]   I don't know.
[01:43:35.860 --> 01:43:36.700]   That was a good name.
[01:43:36.700 --> 01:43:39.820]   Well, the Surface table and the future of the desktop
[01:43:39.820 --> 01:43:43.420]   is going to be these big screen giant things, I think.
[01:43:43.420 --> 01:43:44.500]   And that's a Surface.
[01:43:44.500 --> 01:43:46.380]   It's a great name for that.
[01:43:46.380 --> 01:43:49.820]   But branding aside, they had the Surface table,
[01:43:49.820 --> 01:43:52.820]   and then they bought the other leader in that space, which
[01:43:52.820 --> 01:43:53.020]   was--
[01:43:53.020 --> 01:43:54.020]   Pixel--
[01:43:54.020 --> 01:43:55.340]   Yeah, perceptive pixel.
[01:43:55.340 --> 01:43:55.940]   Perceptive pixel.
[01:43:55.940 --> 01:43:56.440]   Yeah.
[01:43:56.440 --> 01:43:57.820]   And so now they've got both of those.
[01:43:57.820 --> 01:43:59.540]   And I've been trying to love them.
[01:43:59.540 --> 01:44:00.220]   Like I've been trying to--
[01:44:00.220 --> 01:44:02.260]   That's the 85-inch touch screen.
[01:44:02.260 --> 01:44:05.980]   I've been trying to write about how great things they
[01:44:05.980 --> 01:44:06.820]   must be working on.
[01:44:06.820 --> 01:44:07.820]   And I want to talk to them.
[01:44:07.820 --> 01:44:09.300]   And I contact Microsoft.
[01:44:09.300 --> 01:44:13.820]   And they get back to me and say, we don't want to talk about it.
[01:44:13.820 --> 01:44:14.700]   I mean, it's insane.
[01:44:14.700 --> 01:44:16.820]   So if you listen to Windows Weekly for five minutes,
[01:44:16.820 --> 01:44:19.380]   you will hear Paul Therat and Mary Jo Foley, who
[01:44:19.380 --> 01:44:23.180]   are very much pro Microsoft products people.
[01:44:23.180 --> 01:44:25.020]   That's why they do what they do.
[01:44:25.020 --> 01:44:28.260]   Just bemoan the very poor communication that might--
[01:44:28.260 --> 01:44:30.540]   I don't know if you've run into this now at PC World.
[01:44:30.540 --> 01:44:33.140]   But Microsoft's PR is terrible.
[01:44:33.140 --> 01:44:34.420]   It's awful.
[01:44:34.420 --> 01:44:35.420]   Well, it's heart-free.
[01:44:35.420 --> 01:44:36.900]   It's heart-free.
[01:44:36.900 --> 01:44:38.340]   It's not PR.
[01:44:38.340 --> 01:44:39.740]   PR is not the problem.
[01:44:39.740 --> 01:44:43.740]   The companies that they hire to do PR and the intern PRs,
[01:44:43.740 --> 01:44:45.220]   they're actually good people.
[01:44:45.220 --> 01:44:50.060]   The problem is that there's a fatal sort of a silification
[01:44:50.060 --> 01:44:53.260]   of that company where everybody's afraid to say something
[01:44:53.260 --> 01:44:55.780]   about another company because they'll be held to pay.
[01:44:55.780 --> 01:44:57.060]   And everybody's constrained.
[01:44:57.060 --> 01:44:57.580]   It's the old--
[01:44:57.580 --> 01:45:00.620]   And each division has two beating interests.
[01:45:00.620 --> 01:45:03.220]   So you can't do too well in one area because the office
[01:45:03.220 --> 01:45:04.900]   division's going to say, hey, wait a minute.
[01:45:04.900 --> 01:45:07.060]   And I think you hit the nail on the head there,
[01:45:07.060 --> 01:45:10.460]   which is there is something in Microsoft politics
[01:45:10.460 --> 01:45:13.340]   about protecting Windows and protecting office.
[01:45:13.340 --> 01:45:14.620]   And those are cash cows.
[01:45:14.620 --> 01:45:15.500]   I totally get it.
[01:45:15.500 --> 01:45:18.100]   And yet what they're doing is interesting ideas
[01:45:18.100 --> 01:45:20.940]   kind of get squashed or they get bastardized.
[01:45:20.940 --> 01:45:25.940]   If the Windows phone interface had gone on the tablets directly
[01:45:25.940 --> 01:45:31.220]   instead of being this weird half-baked Windows RT
[01:45:31.220 --> 01:45:33.780]   tablet strategy that they did, but it's really Windows 8
[01:45:33.780 --> 01:45:34.540]   underneath.
[01:45:34.540 --> 01:45:38.620]   I mean, but it's just got the smell of good ideas
[01:45:38.620 --> 01:45:41.380]   that were then kind of screwed up by somebody
[01:45:41.380 --> 01:45:42.020]   protecting their turf.
[01:45:42.020 --> 01:45:44.260]   They're the Xerox park of our age.
[01:45:44.260 --> 01:45:47.180]   Their research labs are second to nine.
[01:45:47.180 --> 01:45:50.180]   They produce some of the most breathtaking technologies
[01:45:50.180 --> 01:45:51.780]   and they never see the light of day.
[01:45:51.780 --> 01:45:53.860]   And the stuff that we do see that's interesting
[01:45:53.860 --> 01:45:55.260]   is tends to be in the gaming space
[01:45:55.260 --> 01:45:57.660]   where Windows as a brand is not really relevant.
[01:45:57.660 --> 01:45:58.900]   You can't screw it up.
[01:45:58.900 --> 01:46:00.380]   Office and Windows can screw it up.
[01:46:00.380 --> 01:46:02.300]   You've seen Manu's--
[01:46:02.300 --> 01:46:03.460]   I have this hanging on my wall.
[01:46:03.460 --> 01:46:05.620]   He sent me an autograph personal edition
[01:46:05.620 --> 01:46:08.380]   of the org chart for different companies Amazon,
[01:46:08.380 --> 01:46:09.300]   which is pretty traditional.
[01:46:09.300 --> 01:46:11.380]   Google, which is very kind of flat.
[01:46:11.380 --> 01:46:15.260]   There's three people, Facebook, which is a network.
[01:46:15.260 --> 01:46:17.660]   But then the Microsoft one is the one that you should look at
[01:46:17.660 --> 01:46:21.100]   because there's different divisions all pointing guns
[01:46:21.100 --> 01:46:22.140]   at one another.
[01:46:22.140 --> 01:46:23.260]   Is there one for Sony?
[01:46:23.260 --> 01:46:25.540]   Because a lot of this sounds a lot like these issues
[01:46:25.540 --> 01:46:26.220]   with Sony.
[01:46:26.220 --> 01:46:28.020]   Yeah, so Sony is having to sell it.
[01:46:28.020 --> 01:46:29.380]   Well, what Sony does is that there's
[01:46:29.380 --> 01:46:30.820]   so much independence between groups
[01:46:30.820 --> 01:46:32.220]   is that multiple groups will come out
[01:46:32.220 --> 01:46:33.620]   with competing products.
[01:46:33.620 --> 01:46:34.140]   Oh, yeah.
[01:46:34.140 --> 01:46:35.620]   And then they don't talk to each other.
[01:46:35.620 --> 01:46:37.540]   They don't share their--
[01:46:37.540 --> 01:46:42.100]   You can buy that, by the way, from bonkersworld.net
[01:46:42.100 --> 01:46:42.900]   if you want that cartoon.
[01:46:42.900 --> 01:46:45.260]   It's a great cartoon, and I have it on my wall.
[01:46:45.260 --> 01:46:48.340]   It always informs my reporting on these companies.
[01:46:48.340 --> 01:46:51.420]   Because I think it's fairly accurate.
[01:46:51.420 --> 01:46:53.420]   I mean, is having such a--
[01:46:53.420 --> 01:46:55.700]   having getting to a certain size inevitable
[01:46:55.700 --> 01:46:59.700]   where your structure starts beginning to look more like a--
[01:46:59.700 --> 01:47:01.300]   Well, it is with leadership.
[01:47:01.300 --> 01:47:03.340]   That will be what's interesting about this rework.
[01:47:03.340 --> 01:47:05.220]   Unfortunately, they're not going to do what they need to do,
[01:47:05.220 --> 01:47:06.900]   which I agree is get rid of bomber.
[01:47:06.900 --> 01:47:09.500]   Or split into different companies, literally.
[01:47:09.500 --> 01:47:10.000]   Right.
[01:47:10.000 --> 01:47:10.500]   They're just--
[01:47:10.500 --> 01:47:11.580]   But they're not going to do that either.
[01:47:11.580 --> 01:47:13.740]   If you look at the difference between what Apple did
[01:47:13.740 --> 01:47:16.940]   with introducing iOS and the iPad compared
[01:47:16.940 --> 01:47:19.220]   with what Microsoft did, where it came in and said,
[01:47:19.220 --> 01:47:21.140]   well, we're going to kind of give you the future, which
[01:47:21.140 --> 01:47:22.300]   is touch screens.
[01:47:22.300 --> 01:47:23.740]   Plus, we'll give you the past.
[01:47:23.740 --> 01:47:25.540]   And then, well, OK, we won't give you so much future.
[01:47:25.540 --> 01:47:26.660]   We'll bring back the button.
[01:47:26.660 --> 01:47:27.220]   Blah, blah, blah.
[01:47:27.220 --> 01:47:28.060]   It's like this wishy.
[01:47:28.060 --> 01:47:29.620]   They don't have any vision at all.
[01:47:29.620 --> 01:47:31.700]   Apple came out and said, here's the tablet.
[01:47:31.700 --> 01:47:32.580]   This is how it is.
[01:47:32.580 --> 01:47:34.780]   Our way, the highway, this is the future.
[01:47:34.780 --> 01:47:35.860]   Clear leadership there.
[01:47:35.860 --> 01:47:37.700]   That moment at the deconference, actually,
[01:47:37.700 --> 01:47:38.820]   where they unveiled it for the first time
[01:47:38.820 --> 01:47:40.740]   where Sanoski was on stage unveiling it,
[01:47:40.740 --> 01:47:43.820]   it was so exciting to see that tablet interface and think,
[01:47:43.820 --> 01:47:46.580]   wow, Microsoft is really going to game on.
[01:47:46.580 --> 01:47:47.940]   That was my response.
[01:47:47.940 --> 01:47:50.220]   And then, at the back end of it, he was like, oh,
[01:47:50.220 --> 01:47:52.220]   but if we flip the switch, you're in the Windows desktop
[01:47:52.220 --> 01:47:53.620]   and you're going to run office with them,
[01:47:53.620 --> 01:47:54.340]   and you can attach a mouse.
[01:47:54.340 --> 01:47:55.860]   I'm like, oh, so close.
[01:47:55.860 --> 01:47:57.860]   And then, like, cold feet?
[01:47:57.860 --> 01:47:58.860]   Just back in a way.
[01:47:58.860 --> 01:48:01.020]   I think there's something-- what you guys are addressing
[01:48:01.020 --> 01:48:04.900]   was there's something like in their Microsoft genes where
[01:48:04.900 --> 01:48:09.580]   you need to keep the legacy user base on the entire time.
[01:48:09.580 --> 01:48:11.700]   So whatever you do, you have to bring them along.
[01:48:11.700 --> 01:48:12.860]   And I think that's what you see.
[01:48:12.860 --> 01:48:13.580]   Is you see kind of this?
[01:48:13.580 --> 01:48:15.140]   I have to say, I understand that, though.
[01:48:15.140 --> 01:48:17.820]   I mean, they sell primarily to the business market,
[01:48:17.820 --> 01:48:19.740]   unlike Apple and other companies.
[01:48:19.740 --> 01:48:21.740]   But Apple's the company that's taking over the business
[01:48:21.740 --> 01:48:23.980]   market because they have such a clear vision.
[01:48:23.980 --> 01:48:25.620]   What's happening in consumer electronics
[01:48:25.620 --> 01:48:28.020]   is that enterprises are people bringing--
[01:48:28.020 --> 01:48:29.980]   I think there's still a lot of Windows machines.
[01:48:29.980 --> 01:48:30.480]   Sure.
[01:48:30.480 --> 01:48:30.980]   But do they think--
[01:48:30.980 --> 01:48:32.780]   --sure a vast majority of businesses are still running
[01:48:32.780 --> 01:48:34.300]   Windows probably XP.
[01:48:34.300 --> 01:48:37.380]   Do they think so little of their innovations, though,
[01:48:37.380 --> 01:48:39.420]   that they figure unless they call it Windows
[01:48:39.420 --> 01:48:42.300]   and make it sort of like very much like an old PC
[01:48:42.300 --> 01:48:43.900]   is people aren't going to want it?
[01:48:43.900 --> 01:48:45.220]   Because that's what it sounds like to me.
[01:48:45.220 --> 01:48:48.700]   And it's too bad because I think a fully fledged
[01:48:48.700 --> 01:48:50.460]   sort of Windows phone-based tablet that
[01:48:50.460 --> 01:48:53.660]   wasn't this weird combination of Windows 8.
[01:48:53.660 --> 01:48:55.380]   I don't know if there's anything we could have done that.
[01:48:55.380 --> 01:48:57.220]   I think this is the innovators dilemma.
[01:48:57.220 --> 01:48:59.420]   I do not think there's anything they could have done.
[01:48:59.420 --> 01:49:00.220]   They had--
[01:49:00.220 --> 01:49:01.100]   They're trapped.
[01:49:01.100 --> 01:49:03.340]   You either say, OK, we're going to give business
[01:49:03.340 --> 01:49:07.260]   what it wants, which is Windows 7 continually.
[01:49:07.260 --> 01:49:09.140]   In which case, people will, like us,
[01:49:09.140 --> 01:49:11.780]   will say, well, they've lost their ability to innovate.
[01:49:11.780 --> 01:49:14.940]   They're just going to coast into the distance like IBM.
[01:49:14.940 --> 01:49:19.300]   Or you do what Jason says and you go full bore
[01:49:19.300 --> 01:49:22.260]   into the new Windows 8 touch world
[01:49:22.260 --> 01:49:23.780]   and you say goodbye to the desktop.
[01:49:23.780 --> 01:49:25.020]   Well, you don't say goodbye to the desktop,
[01:49:25.020 --> 01:49:26.660]   but tablet, smartphone.
[01:49:26.660 --> 01:49:28.340]   You can see what they did with the Xbox.
[01:49:28.340 --> 01:49:29.740]   I feel like they could have--
[01:49:29.740 --> 01:49:31.620]   Where does the desktop go in that world?
[01:49:31.620 --> 01:49:33.780]   Well, so I think part of it is that you can't--
[01:49:33.780 --> 01:49:34.220]   You can't--
[01:49:34.220 --> 01:49:35.660]   It sits there in businesses for a while.
[01:49:35.660 --> 01:49:36.900]   You continue to sell one of the--
[01:49:36.900 --> 01:49:37.420]   While they build--
[01:49:37.420 --> 01:49:39.980]   And you create a new brand that is the tablet brand.
[01:49:39.980 --> 01:49:41.860]   Well, I mean, they did it with Xbox.
[01:49:41.860 --> 01:49:45.140]   I mean, they created an entirely brand new platform that--
[01:49:45.140 --> 01:49:49.260]   I mean, until recently, had a really good mind share
[01:49:49.260 --> 01:49:50.060]   among the audience.
[01:49:50.060 --> 01:49:51.420]   And it was something that wasn't--
[01:49:51.420 --> 01:49:54.340]   I mean, yeah, they had the NT kernel as the basis for it.
[01:49:54.340 --> 01:49:56.380]   But it wasn't like you hit the start button,
[01:49:56.380 --> 01:49:59.500]   you go through it and you work it like a Windows machine.
[01:49:59.500 --> 01:50:00.460]   I think it's very tough.
[01:50:00.460 --> 01:50:01.380]   I think it's very tough.
[01:50:01.380 --> 01:50:02.380]   I think it's very tough.
[01:50:02.380 --> 01:50:04.700]   Perceptive pixel devices are ideal for enterprises.
[01:50:04.700 --> 01:50:07.020]   They're brilliant for enterprises.
[01:50:07.020 --> 01:50:10.300]   If you're an executive, you want one of these big screens
[01:50:10.300 --> 01:50:12.260]   in your office and you give presentations on it.
[01:50:12.260 --> 01:50:13.500]   It's like a TV.
[01:50:13.500 --> 01:50:14.340]   You lay it flat.
[01:50:14.340 --> 01:50:16.500]   You plan things.
[01:50:16.500 --> 01:50:17.220]   But there's no vision.
[01:50:17.220 --> 01:50:18.460]   They're also how much?
[01:50:18.460 --> 01:50:19.340]   They're expensive.
[01:50:19.340 --> 01:50:21.300]   Well, that's another reason why they're good for enterprises.
[01:50:21.300 --> 01:50:24.340]   How much does Microsoft charge for their software
[01:50:24.340 --> 01:50:25.380]   in enterprises?
[01:50:25.380 --> 01:50:27.260]   But this is something that they make that's hardware.
[01:50:27.260 --> 01:50:28.940]   This should be the new model.
[01:50:28.940 --> 01:50:31.220]   They should be more Apple-like and sell hardware and software
[01:50:31.220 --> 01:50:33.620]   like they're doing on the low end.
[01:50:33.620 --> 01:50:36.380]   And it's like there's nothing there.
[01:50:36.380 --> 01:50:40.700]   I also think it's just a broader kind of industry-wide dilemma
[01:50:40.700 --> 01:50:46.260]   because you are shifting from a desktop or computer
[01:50:46.260 --> 01:50:49.380]   format to people who've been using for the past 20 years
[01:50:49.380 --> 01:50:51.100]   and you're trying to--
[01:50:51.100 --> 01:50:52.620]   The ground has come out of hand.
[01:50:52.620 --> 01:50:54.660]   And everyone's literally scrambling
[01:50:54.660 --> 01:50:58.700]   finding out what the next kind of computer model will be.
[01:50:58.700 --> 01:51:01.740]   But that's when I bash Microsoft about this.
[01:51:01.740 --> 01:51:04.140]   Leo, you said what happens to the old PCs.
[01:51:04.140 --> 01:51:05.420]   But it's like that's what I mean when
[01:51:05.420 --> 01:51:07.940]   I say does Microsoft think so little of their products
[01:51:07.940 --> 01:51:10.100]   that they have to yoke everything to Windows?
[01:51:10.100 --> 01:51:12.380]   Because if they think that their tablet technology
[01:51:12.380 --> 01:51:14.220]   and their phone technology is so great,
[01:51:14.220 --> 01:51:16.820]   they should be pushing that as far as they can and not worry.
[01:51:16.820 --> 01:51:18.060]   Windows will take care of itself.
[01:51:18.060 --> 01:51:19.060]   It will be around for a while.
[01:51:19.060 --> 01:51:20.340]   Eventually it'll go away.
[01:51:20.340 --> 01:51:21.420]   I just don't think they believe it.
[01:51:21.420 --> 01:51:21.940]   And I think--
[01:51:21.940 --> 01:51:22.780]   Well, I think they can't--
[01:51:22.780 --> 01:51:23.340]   If they can't--
[01:51:23.340 --> 01:51:23.780]   If they can't--
[01:51:23.780 --> 01:51:24.980]   If they can't attach everything--
[01:51:24.980 --> 01:51:25.980]   With 8.1--
[01:51:25.980 --> 01:51:27.140]   They're saying, oh, we're sorry.
[01:51:27.140 --> 01:51:28.420]   We took out the desktop.
[01:51:28.420 --> 01:51:30.060]   We'll let you boot to the desktop.
[01:51:30.060 --> 01:51:32.100]   You want to start button while we'll do something like that.
[01:51:32.100 --> 01:51:33.380]   And that's fine, except then they're committing
[01:51:33.380 --> 01:51:35.180]   to be kind of a legacy business that's just
[01:51:35.180 --> 01:51:36.580]   going to kind of fade away.
[01:51:36.580 --> 01:51:37.620]   Well, I think that was the challenge.
[01:51:37.620 --> 01:51:38.780]   What they're going to do.
[01:51:38.780 --> 01:51:40.020]   I think it's--
[01:51:40.020 --> 01:51:43.340]   I think you're right that Steve Bomber is not the leader.
[01:51:43.340 --> 01:51:44.820]   But I don't know who would be.
[01:51:44.820 --> 01:51:47.700]   And I think there is a huge innovative dilemma.
[01:51:47.700 --> 01:51:49.220]   You're so successful.
[01:51:49.220 --> 01:51:52.460]   It's very difficult then to go to your next stage
[01:51:52.460 --> 01:51:55.220]   without cannibalizing your existing business.
[01:51:55.220 --> 01:51:56.580]   I just-- I don't know what you do.
[01:51:56.580 --> 01:51:58.220]   I think that that will be a--
[01:51:58.220 --> 01:52:00.700]   I mean, if I were a teaching business,
[01:52:00.700 --> 01:52:02.420]   that'd be case study number one.
[01:52:02.420 --> 01:52:02.940]   What do you do?
[01:52:02.940 --> 01:52:03.900]   Here you are.
[01:52:03.900 --> 01:52:05.900]   Well, I mean, that's why it's a dilemma, right?
[01:52:05.900 --> 01:52:07.260]   I mean, this is a real dilemma.
[01:52:07.260 --> 01:52:09.500]   This is why founders are such great leaders.
[01:52:09.500 --> 01:52:10.740]   This is what you see.
[01:52:10.740 --> 01:52:13.340]   And why they don't continue.
[01:52:13.340 --> 01:52:13.940]   You know, you want to--
[01:52:13.940 --> 01:52:16.140]   Steve Jobs leads, leaves, or dies.
[01:52:16.140 --> 01:52:16.740]   Yeah.
[01:52:16.740 --> 01:52:17.100]   Then what?
[01:52:17.100 --> 01:52:19.740]   But look at the difference between the Larry Page version
[01:52:19.740 --> 01:52:22.300]   of Google versus the Eric Schmidt version of Google.
[01:52:22.300 --> 01:52:24.900]   Larry Page is just laying waste to him.
[01:52:24.900 --> 01:52:29.060]   He's-- I mean, the boldest thing is to destroy Google Reader.
[01:52:29.060 --> 01:52:32.100]   That was a bold move that Eric Schmidt would never
[01:52:32.100 --> 01:52:33.100]   have been able to do.
[01:52:33.100 --> 01:52:35.100]   But this is part of the sort of house cleaning thing
[01:52:35.100 --> 01:52:36.980]   that Larry's doing because he's a founder,
[01:52:36.980 --> 01:52:39.180]   because he's this person who can make those kind of hard
[01:52:39.180 --> 01:52:39.980]   decisions.
[01:52:39.980 --> 01:52:40.700]   So it's very difficult.
[01:52:40.700 --> 01:52:43.620]   Maybe Bill Gates should come back.
[01:52:43.620 --> 01:52:45.180]   I've often thought that would be a good move.
[01:52:45.180 --> 01:52:45.700]   I don't know.
[01:52:45.700 --> 01:52:46.780]   I think Bill doesn't want to.
[01:52:46.780 --> 01:52:48.820]   I think he's very happy doing what he's doing.
[01:52:48.820 --> 01:52:51.500]   And I think we're very lucky he is doing what he's doing,
[01:52:51.500 --> 01:52:52.940]   because he's making a big difference.
[01:52:52.940 --> 01:52:54.620]   Promise we see all these names of people
[01:52:54.620 --> 01:52:57.260]   who seem like they might step up and be that new leader
[01:52:57.260 --> 01:52:59.300]   at Microsoft, and they're all getting pushed down.
[01:52:59.300 --> 01:53:00.260]   They're leaving.
[01:53:00.260 --> 01:53:02.260]   Look, Microsoft should go down kicking and screaming.
[01:53:02.260 --> 01:53:03.660]   I agree.
[01:53:03.660 --> 01:53:05.140]   Rage, rage against the dying of the light.
[01:53:05.140 --> 01:53:06.100]   Like a death.
[01:53:06.100 --> 01:53:06.900]   Yeah.
[01:53:06.900 --> 01:53:08.260]   But let's face it.
[01:53:08.260 --> 01:53:11.860]   In business in general, in technology in particular,
[01:53:11.860 --> 01:53:14.500]   it's very difficult to continue on.
[01:53:14.500 --> 01:53:16.820]   There's a natural life cycle.
[01:53:16.820 --> 01:53:18.140]   IBM--
[01:53:18.140 --> 01:53:19.380]   And they're making money, right?
[01:53:19.380 --> 01:53:21.100]   So you want to leave that money out?
[01:53:21.100 --> 01:53:22.460]   They're making a lot of money.
[01:53:22.460 --> 01:53:23.900]   They're making a lot of money out as long as possible.
[01:53:23.900 --> 01:53:26.220]   I think it's an incredible challenge.
[01:53:26.220 --> 01:53:28.020]   But it takes some leadership and maybe bomber
[01:53:28.020 --> 01:53:30.060]   needed to create a skunk works or do something.
[01:53:30.060 --> 01:53:30.620]   I don't know.
[01:53:30.620 --> 01:53:32.580]   Well, I mean, even IBM had to reinvent
[01:53:32.580 --> 01:53:35.300]   and go back to doing what they do best, which
[01:53:35.300 --> 01:53:38.980]   is selling large computer mainframes or--
[01:53:38.980 --> 01:53:39.860]   They don't sell anything now.
[01:53:39.860 --> 01:53:40.220]   There's services.
[01:53:40.220 --> 01:53:41.460]   Service is the company.
[01:53:41.460 --> 01:53:43.500]   They're a consultancy.
[01:53:43.500 --> 01:53:44.620]   So I mean--
[01:53:44.620 --> 01:53:46.100]   That's different company.
[01:53:46.100 --> 01:53:51.460]   But then they go back after what the ladies--
[01:53:51.460 --> 01:53:52.980]   They sold off all their hardware.
[01:53:52.980 --> 01:53:53.580]   Yeah.
[01:53:53.580 --> 01:53:55.380]   Well, that's how you succeed.
[01:53:55.380 --> 01:53:56.940]   You become a different company.
[01:53:56.940 --> 01:53:59.060]   Apple became a different company.
[01:53:59.060 --> 01:54:02.700]   After Jobs came back, Google is becoming a different company.
[01:54:02.700 --> 01:54:04.460]   In some respects, the opposite company
[01:54:04.460 --> 01:54:05.260]   that they used to be.
[01:54:05.260 --> 01:54:08.340]   Maybe IBM is a bad example because they really did it the way.
[01:54:08.340 --> 01:54:10.060]   And they're successful.
[01:54:10.060 --> 01:54:12.460]   It was a successful transition and a radical one.
[01:54:12.460 --> 01:54:15.780]   HP may very well become a very different company.
[01:54:15.780 --> 01:54:18.260]   So I think that's exactly what I'm saying they need.
[01:54:18.260 --> 01:54:21.300]   They need to just get over this like silification.
[01:54:21.300 --> 01:54:24.020]   They need to say, here's a clear vision of the future.
[01:54:24.020 --> 01:54:24.820]   And let's drive it.
[01:54:24.820 --> 01:54:26.780]   Let's essentially do what Apple does
[01:54:26.780 --> 01:54:28.700]   and force it down everybody's throats
[01:54:28.700 --> 01:54:31.460]   until people get it and realize that this is really--
[01:54:31.460 --> 01:54:33.420]   The most breathtaking thing that Apple ever did
[01:54:33.420 --> 01:54:35.660]   was they introduced a phone without a keyboard.
[01:54:35.660 --> 01:54:40.020]   And not only did they not build a physical keyboard
[01:54:40.020 --> 01:54:41.820]   to go with it, they banned other companies
[01:54:41.820 --> 01:54:42.940]   from making a physical keyboard.
[01:54:42.940 --> 01:54:44.700]   They said, we're going to give you two years
[01:54:44.700 --> 01:54:46.980]   where there is no physical keyboard that you can use
[01:54:46.980 --> 01:54:48.060]   with this phone.
[01:54:48.060 --> 01:54:49.020]   They're all in.
[01:54:49.020 --> 01:54:51.500]   And they trained us all to use the on-screen keyboard
[01:54:51.500 --> 01:54:52.820]   and they never look back.
[01:54:52.820 --> 01:54:53.860]   That's a kind of--
[01:54:53.860 --> 01:54:55.140]   A could of backfire.
[01:54:55.140 --> 01:54:56.020]   It could have.
[01:54:56.020 --> 01:54:56.860]   And it could have--
[01:54:56.860 --> 01:54:57.420]   Thanks, Scott.
[01:54:57.420 --> 01:55:01.900]   Yeah, it may backfire more for the Microsofts of the world.
[01:55:01.900 --> 01:55:02.980]   Yeah, I know what the problem is.
[01:55:02.980 --> 01:55:03.380]   Really.
[01:55:03.380 --> 01:55:04.780]   But that's what it takes.
[01:55:04.780 --> 01:55:06.580]   You have to really believe in the future
[01:55:06.580 --> 01:55:08.620]   that you're giving people and just give it to them
[01:55:08.620 --> 01:55:10.260]   and take your knocks and move forward.
[01:55:10.260 --> 01:55:12.180]   Because otherwise, they're just going to be--
[01:55:12.180 --> 01:55:14.060]   they're just quickly becoming an irrelevant dinosaur.
[01:55:14.060 --> 01:55:15.220]   Microsoft shut stuff down.
[01:55:15.220 --> 01:55:17.500]   They just shut down Web TV.
[01:55:17.500 --> 01:55:20.220]   They know how to cut the cord on a product.
[01:55:20.220 --> 01:55:20.700]   Yeah.
[01:55:20.700 --> 01:55:22.100]   But he's still selling that?
[01:55:22.100 --> 01:55:22.780]   Yes.
[01:55:22.780 --> 01:55:24.500]   Jesus.
[01:55:24.500 --> 01:55:26.660]   If you have a Web TV, which they rebranded--
[01:55:26.660 --> 01:55:29.220]   they bought it from Steve Perlman in '97.
[01:55:29.220 --> 01:55:32.140]   They rebranded it MSN TV.
[01:55:32.140 --> 01:55:34.380]   $425 million they gave Steve.
[01:55:34.380 --> 01:55:35.740]   Then, of course, remember, he went on--
[01:55:35.740 --> 01:55:37.540]   first he retired to his has a Tahoe.
[01:55:37.540 --> 01:55:37.940]   Remember this?
[01:55:37.940 --> 01:55:39.660]   And then he created Moxie.
[01:55:39.660 --> 01:55:41.860]   Because he was trying to figure out a way
[01:55:41.860 --> 01:55:46.860]   to get all his television in all the rooms of his mansion.
[01:55:46.860 --> 01:55:49.300]   And then Moxie got sued out of existence pretty much.
[01:55:49.300 --> 01:55:51.220]   I think they got sold to somebody.
[01:55:51.220 --> 01:55:53.900]   And then what did Steve do next?
[01:55:53.900 --> 01:55:54.740]   Does anybody know?
[01:55:54.740 --> 01:55:55.340]   No.
[01:55:55.340 --> 01:55:58.380]   Something pretty big, but I forgot what it is.
[01:55:58.380 --> 01:55:59.740]   I don't think there was a search engine.
[01:55:59.740 --> 01:56:00.940]   No, Steve Perlman.
[01:56:00.940 --> 01:56:01.700]   What is he doing?
[01:56:01.700 --> 01:56:05.420]   Moxie really looked good, but they decided to make--
[01:56:05.420 --> 01:56:06.740]   they were like Tivo, but they didn't make Tivo's next.
[01:56:06.740 --> 01:56:07.420]   Oh, I know you're next.
[01:56:07.420 --> 01:56:09.420]   I know you're next.
[01:56:09.420 --> 01:56:10.420]   I know you're next.
[01:56:10.420 --> 01:56:11.420]   I know you're next.
[01:56:11.420 --> 01:56:12.420]   I know you're next.
[01:56:12.420 --> 01:56:13.420]   I know you're next.
[01:56:13.420 --> 01:56:14.420]   I know you're next.
[01:56:14.420 --> 01:56:15.420]   I know you're next.
[01:56:15.420 --> 01:56:16.420]   I know you're next.
[01:56:16.420 --> 01:56:17.420]   I know you're next.
[01:56:17.420 --> 01:56:18.420]   I know you're next.
[01:56:18.420 --> 01:56:19.420]   I know you're next.
[01:56:19.420 --> 01:56:20.420]   I know you're next.
[01:56:20.420 --> 01:56:21.420]   I know you're next.
[01:56:21.420 --> 01:56:22.420]   I know you're next.
[01:56:22.420 --> 01:56:23.420]   I know you're next.
[01:56:23.420 --> 01:56:24.420]   I know you're next.
[01:56:24.420 --> 01:56:25.420]   I know you're next.
[01:56:25.420 --> 01:56:26.420]   I know you're next.
[01:56:26.420 --> 01:56:27.420]   I know you're next.
[01:56:27.420 --> 01:56:28.420]   I know you're next.
[01:56:28.420 --> 01:56:29.420]   I know you're next.
[01:56:29.420 --> 01:56:30.420]   I know you're next.
[01:56:30.420 --> 01:56:31.420]   I know you're next.
[01:56:31.420 --> 01:56:32.420]   I know you're next.
[01:56:32.420 --> 01:56:33.420]   I know you're next.
[01:56:33.420 --> 01:56:34.420]   I know you're next.
[01:56:34.420 --> 01:56:35.420]   I know you're next.
[01:56:35.420 --> 01:56:37.420]   I know you're next.
[01:56:37.420 --> 01:56:38.420]   I know you're next.
[01:56:38.420 --> 01:56:39.420]   I know you're next.
[01:56:39.420 --> 01:56:40.420]   I know you're next.
[01:56:40.420 --> 01:56:41.420]   I know you're next.
[01:56:41.420 --> 01:56:42.420]   I know you're next.
[01:56:42.420 --> 01:56:43.420]   I know you're next.
[01:56:43.420 --> 01:56:44.420]   I know you're next.
[01:56:44.420 --> 01:56:45.420]   I know you're next.
[01:56:45.420 --> 01:56:46.420]   I know you're next.
[01:56:46.420 --> 01:56:47.420]   I know you're next.
[01:56:47.420 --> 01:56:48.420]   I know you're next.
[01:56:48.420 --> 01:56:49.420]   I know you're next.
[01:56:49.420 --> 01:56:50.420]   I know you're next.
[01:56:50.420 --> 01:56:51.420]   I know you're next.
[01:56:51.420 --> 01:56:52.420]   I know you're next.
[01:56:52.420 --> 01:56:53.420]   I know you're next.
[01:56:53.420 --> 01:56:54.420]   I know you're next.
[01:56:54.420 --> 01:56:55.420]   I know you're next.
[01:56:55.420 --> 01:56:56.420]   I know you're next.
[01:56:56.420 --> 01:56:57.420]   I know you're next.
[01:56:57.420 --> 01:56:58.420]   I know you're next.
[01:56:58.420 --> 01:56:59.420]   I know you're next.
[01:56:59.420 --> 01:57:00.420]   I know you're next.
[01:57:00.420 --> 01:57:01.420]   I know you're next.
[01:57:01.420 --> 01:57:02.420]   I know you're next.
[01:57:02.420 --> 01:57:03.420]   I know you're next.
[01:57:03.420 --> 01:57:05.420]   I know you're next.
[01:57:05.420 --> 01:57:06.420]   I know you're next.
[01:57:06.420 --> 01:57:07.420]   I know you're next.
[01:57:07.420 --> 01:57:08.420]   I know you're next.
[01:57:08.420 --> 01:57:09.420]   I know you're next.
[01:57:09.420 --> 01:57:10.420]   I know you're next.
[01:57:10.420 --> 01:57:11.420]   I know you're next.
[01:57:11.420 --> 01:57:12.420]   I know you're next.
[01:57:12.420 --> 01:57:13.420]   I know you're next.
[01:57:13.420 --> 01:57:14.420]   I know you're next.
[01:57:14.420 --> 01:57:15.420]   I know you're next.
[01:57:15.420 --> 01:57:16.420]   I know you're next.
[01:57:16.420 --> 01:57:17.420]   I know you're next.
[01:57:17.420 --> 01:57:18.420]   I know you're next.
[01:57:18.420 --> 01:57:19.420]   I know you're next.
[01:57:19.420 --> 01:57:20.420]   I know you're next.
[01:57:20.420 --> 01:57:21.420]   I know you're next.
[01:57:21.420 --> 01:57:22.420]   I know you're next.
[01:57:22.420 --> 01:57:23.420]   I know you're next.
[01:57:23.420 --> 01:57:24.420]   I know you're next.
[01:57:24.420 --> 01:57:25.420]   I know you're next.
[01:57:25.420 --> 01:57:26.420]   I know you're next.
[01:57:26.420 --> 01:57:27.420]   I know you're next.
[01:57:27.420 --> 01:57:28.420]   I know you're next.
[01:57:28.420 --> 01:57:29.420]   I know you're next.
[01:57:29.420 --> 01:57:30.420]   I know you're next.
[01:57:30.420 --> 01:57:31.420]   I know you're next.
[01:57:31.420 --> 01:57:33.420]   I know you're next.
[01:57:33.420 --> 01:57:34.420]   I know you're next.
[01:57:34.420 --> 01:57:35.420]   I know you're next.
[01:57:35.420 --> 01:57:36.420]   I know you're next.
[01:57:36.420 --> 01:57:37.420]   I know you're next.
[01:57:37.420 --> 01:57:38.420]   I know you're next.
[01:57:38.420 --> 01:57:39.420]   I know you're next.
[01:57:39.420 --> 01:57:40.420]   I know you're next.
[01:57:40.420 --> 01:57:41.420]   I know you're next.
[01:57:41.420 --> 01:57:42.420]   I know you're next.
[01:57:42.420 --> 01:57:43.420]   I know you're next.
[01:57:43.420 --> 01:57:44.420]   I know you're next.
[01:57:44.420 --> 01:57:45.420]   I know you're next.
[01:57:45.420 --> 01:57:46.420]   I know you're next.
[01:57:46.420 --> 01:57:47.420]   I know you're next.
[01:57:47.420 --> 01:57:48.420]   I know you're next.
[01:57:48.420 --> 01:57:49.420]   I know you're next.
[01:57:49.420 --> 01:57:50.420]   I know you're next.
[01:57:50.420 --> 01:57:51.420]   I know you're next.
[01:57:51.420 --> 01:57:52.420]   I know you're next.
[01:57:52.420 --> 01:57:53.420]   I know you're next.
[01:57:53.420 --> 01:57:54.420]   I know you're next.
[01:57:54.420 --> 01:57:55.420]   I know you're next.
[01:57:55.420 --> 01:57:56.420]   I know you're next.
[01:57:56.420 --> 01:57:57.420]   I know you're next.
[01:57:57.420 --> 01:57:58.420]   I know you're next.
[01:57:58.420 --> 01:57:59.420]   I know you're next.
[01:57:59.420 --> 01:58:01.420]   I know you're next.
[01:58:01.420 --> 01:58:02.420]   I know you're next.
[01:58:02.420 --> 01:58:03.420]   I know you're next.
[01:58:03.420 --> 01:58:04.420]   I know you're next.
[01:58:04.420 --> 01:58:05.420]   I know you're next.
[01:58:05.420 --> 01:58:06.420]   I know you're next.
[01:58:06.420 --> 01:58:07.420]   I know you're next.
[01:58:07.420 --> 01:58:08.420]   I know you're next.
[01:58:08.420 --> 01:58:09.420]   I know you're next.
[01:58:09.420 --> 01:58:10.420]   I know you're next.
[01:58:10.420 --> 01:58:11.420]   I know you're next.
[01:58:11.420 --> 01:58:12.420]   I know you're next.
[01:58:12.420 --> 01:58:13.420]   I know you're next.
[01:58:13.420 --> 01:58:14.420]   I know you're next.
[01:58:14.420 --> 01:58:15.420]   I know you're next.
[01:58:15.420 --> 01:58:16.420]   I know you're next.
[01:58:16.420 --> 01:58:17.420]   I know you're next.
[01:58:17.420 --> 01:58:18.420]   I know you're next.
[01:58:18.420 --> 01:58:19.420]   I know you're next.
[01:58:19.420 --> 01:58:20.420]   I know you're next.
[01:58:20.420 --> 01:58:21.420]   I know you're next.
[01:58:21.420 --> 01:58:22.420]   I know you're next.
[01:58:22.420 --> 01:58:23.420]   I know you're next.
[01:58:23.420 --> 01:58:24.420]   I know you're next.
[01:58:24.420 --> 01:58:25.420]   I know you're next.
[01:58:25.420 --> 01:58:26.420]   I know you're next.
[01:58:26.420 --> 01:58:27.420]   I know you're next.
[01:58:27.420 --> 01:58:29.420]   I know you're next.
[01:58:29.420 --> 01:58:30.420]   I know you're next.
[01:58:30.420 --> 01:58:31.420]   I know you're next.
[01:58:31.420 --> 01:58:32.420]   I know you're next.
[01:58:32.420 --> 01:58:33.420]   I know you're next.
[01:58:33.420 --> 01:58:34.420]   I know you're next.
[01:58:34.420 --> 01:58:35.420]   I know you're next.
[01:58:35.420 --> 01:58:36.420]   I know you're next.
[01:58:36.420 --> 01:58:37.420]   I know you're next.
[01:58:37.420 --> 01:58:38.420]   I know you're next.
[01:58:38.420 --> 01:58:39.420]   I know you're next.
[01:58:39.420 --> 01:58:40.420]   I know you're next.
[01:58:40.420 --> 01:58:41.420]   I know you're next.
[01:58:41.420 --> 01:58:42.420]   I know you're next.
[01:58:42.420 --> 01:58:43.420]   I know you're next.
[01:58:43.420 --> 01:58:44.420]   I know you're next.
[01:58:44.420 --> 01:58:45.420]   I know you're next.
[01:58:45.420 --> 01:58:46.420]   I know you're next.
[01:58:46.420 --> 01:58:47.420]   I know you're next.
[01:58:47.420 --> 01:58:48.420]   I know you're next.
[01:58:48.420 --> 01:58:49.420]   I know you're next.
[01:58:49.420 --> 01:58:50.420]   I know you're next.
[01:58:50.420 --> 01:58:51.420]   I know you're next.
[01:58:51.420 --> 01:58:52.420]   I know you're next.
[01:58:52.420 --> 01:58:53.420]   I know you're next.
[01:58:53.420 --> 01:58:54.420]   I know you're next.
[01:58:54.420 --> 01:58:55.420]   I know you're next.
[01:58:55.420 --> 01:58:57.420]   I know you're next.
[01:58:57.420 --> 01:58:58.420]   I know you're next.
[01:58:58.420 --> 01:58:59.420]   I know you're next.
[01:58:59.420 --> 01:59:00.420]   I know you're next.
[01:59:00.420 --> 01:59:01.420]   I know you're next.
[01:59:01.420 --> 01:59:02.420]   I know you're next.
[01:59:02.420 --> 01:59:03.420]   I know you're next.
[01:59:03.420 --> 01:59:04.420]   I know you're next.
[01:59:04.420 --> 01:59:05.420]   I know you're next.
[01:59:05.420 --> 01:59:06.420]   I know you're next.
[01:59:06.420 --> 01:59:07.420]   I know you're next.
[01:59:07.420 --> 01:59:08.420]   I know you're next.
[01:59:08.420 --> 01:59:09.420]   I know you're next.
[01:59:09.420 --> 01:59:10.420]   I know you're next.
[01:59:10.420 --> 01:59:11.420]   I know you're next.
[01:59:11.420 --> 01:59:12.420]   I know you're next.
[01:59:12.420 --> 01:59:13.420]   I know you're next.
[01:59:13.420 --> 01:59:14.420]   I know you're next.
[01:59:14.420 --> 01:59:15.420]   I know you're next.
[01:59:15.420 --> 01:59:16.420]   I know you're next.
[01:59:16.420 --> 01:59:17.420]   I know you're next.
[01:59:17.420 --> 01:59:18.420]   I know you're next.
[01:59:18.420 --> 01:59:19.420]   I know you're next.
[01:59:19.420 --> 01:59:20.420]   I know you're next.
[01:59:20.420 --> 01:59:21.420]   I know you're next.
[01:59:21.420 --> 01:59:22.420]   I know you're next.
[01:59:22.420 --> 01:59:23.420]   I know you're next.
[01:59:23.420 --> 01:59:24.420]   I know you're next.
[01:59:24.420 --> 01:59:25.420]   I know you're next.
[01:59:25.420 --> 01:59:26.420]   I know you're next.
[01:59:26.420 --> 01:59:27.420]   I know you're next.
[01:59:27.420 --> 01:59:28.420]   I know you're next.
[01:59:28.420 --> 01:59:29.420]   I know you're next.
[01:59:29.420 --> 01:59:30.420]   I know you're next.
[01:59:30.420 --> 01:59:31.420]   I know you're next.
[01:59:31.420 --> 01:59:32.420]   I know you're next.
[01:59:32.420 --> 01:59:33.420]   I know you're next.
[01:59:33.420 --> 01:59:34.420]   I know you're next.
[01:59:34.420 --> 01:59:35.420]   I know you're next.
[01:59:35.420 --> 01:59:36.420]   I know you're next.
[01:59:36.420 --> 01:59:37.420]   I know you're next.
[01:59:37.420 --> 01:59:38.420]   I know you're next.
[01:59:38.420 --> 01:59:39.420]   I know you're next.
[01:59:39.420 --> 01:59:40.420]   I know you're next.
[01:59:40.420 --> 01:59:41.420]   I know you're next.
[01:59:41.420 --> 01:59:42.420]   I know you're next.
[01:59:42.420 --> 01:59:43.420]   I know you're next.
[01:59:43.420 --> 01:59:44.420]   I know you're next.
[01:59:44.420 --> 01:59:45.420]   I know you're next.
[01:59:45.420 --> 01:59:46.420]   I know you're next.
[01:59:46.420 --> 01:59:47.420]   I know you're next.
[01:59:47.420 --> 01:59:48.420]   I know you're next.
[01:59:48.420 --> 01:59:49.420]   I know you're next.
[01:59:49.420 --> 01:59:50.420]   I know you're next.
[01:59:50.420 --> 01:59:53.420]   I know you're next.
[01:59:53.420 --> 01:59:54.420]   I know you're next.
[01:59:54.420 --> 01:59:55.420]   I know you're next.
[01:59:55.420 --> 01:59:56.420]   I know you're next.
[01:59:56.420 --> 01:59:57.420]   I know you're next.
[01:59:57.420 --> 01:59:58.420]   I know you're next.
[01:59:58.420 --> 01:59:59.420]   I know you're next.
[01:59:59.420 --> 02:00:00.420]   I know you're next.
[02:00:00.420 --> 02:00:01.420]   I know you're next.
[02:00:01.420 --> 02:00:02.420]   I know you're next.
[02:00:02.420 --> 02:00:03.420]   I know you're next.
[02:00:03.420 --> 02:00:04.420]   I know you're next.
[02:00:04.420 --> 02:00:05.420]   I know you're next.
[02:00:05.420 --> 02:00:06.420]   I know you're next.
[02:00:06.420 --> 02:00:07.420]   I know you're next.
[02:00:07.420 --> 02:00:08.420]   I know you're next.
[02:00:08.420 --> 02:00:09.420]   I know you're next.
[02:00:09.420 --> 02:00:10.420]   I know you're next.
[02:00:10.420 --> 02:00:11.420]   I know you're next.
[02:00:11.420 --> 02:00:12.420]   I know you're next.
[02:00:12.420 --> 02:00:13.420]   I know you're next.
[02:00:13.420 --> 02:00:14.420]   I know you're next.
[02:00:14.420 --> 02:00:15.420]   I know you're next.
[02:00:15.420 --> 02:00:16.420]   I know you're next.
[02:00:16.420 --> 02:00:17.420]   I know you're next.
[02:00:17.420 --> 02:00:18.420]   I know you're next.
[02:00:18.420 --> 02:00:19.420]   I know you're next.
[02:00:19.420 --> 02:00:20.420]   I know you're next.
[02:00:20.420 --> 02:00:21.420]   I know you're next.
[02:00:21.420 --> 02:00:22.420]   I know you're next.
[02:00:22.420 --> 02:00:23.420]   I know you're next.
[02:00:23.420 --> 02:00:24.420]   I know you're next.
[02:00:24.420 --> 02:00:25.420]   I know you're next.
[02:00:25.420 --> 02:00:26.420]   I know you're next.
[02:00:26.420 --> 02:00:27.420]   I know you're next.
[02:00:27.420 --> 02:00:28.420]   I know you're next.
[02:00:28.420 --> 02:00:29.420]   I know you're next.
[02:00:29.420 --> 02:00:30.420]   I know you're next.
[02:00:30.420 --> 02:00:31.420]   I know you're next.
[02:00:31.420 --> 02:00:32.420]   I know you're next.
[02:00:32.420 --> 02:00:33.420]   I know you're next.
[02:00:33.420 --> 02:00:34.420]   I know you're next.
[02:00:34.420 --> 02:00:35.420]   I know you're next.
[02:00:35.420 --> 02:00:36.420]   I know you're next.
[02:00:36.420 --> 02:00:37.420]   I know you're next.
[02:00:37.420 --> 02:00:38.420]   I know you're next.
[02:00:38.420 --> 02:00:39.420]   I know you're next.
[02:00:39.420 --> 02:00:40.420]   I know you're next.
[02:00:40.420 --> 02:00:41.420]   I know you're next.
[02:00:41.420 --> 02:00:42.420]   I know you're next.
[02:00:42.420 --> 02:00:43.420]   I know you're next.
[02:00:43.420 --> 02:00:44.420]   I know you're next.
[02:00:44.420 --> 02:00:45.420]   I know you're next.
[02:00:45.420 --> 02:00:46.420]   I know you're next.
[02:00:46.420 --> 02:00:49.420]   I know you're next.
[02:00:49.420 --> 02:00:50.420]   I know you're next.
[02:00:50.420 --> 02:00:51.420]   I know you're next.
[02:00:51.420 --> 02:00:52.420]   I know you're next.
[02:00:52.420 --> 02:00:53.420]   I know you're next.
[02:00:53.420 --> 02:00:54.420]   I know you're next.
[02:00:54.420 --> 02:00:55.420]   I know you're next.
[02:00:55.420 --> 02:00:56.420]   I know you're next.
[02:00:56.420 --> 02:00:57.420]   I know you're next.
[02:00:57.420 --> 02:00:58.420]   I know you're next.
[02:00:58.420 --> 02:00:59.420]   I know you're next.
[02:00:59.420 --> 02:01:00.420]   I know you're next.
[02:01:00.420 --> 02:01:01.420]   I know you're next.
[02:01:01.420 --> 02:01:02.420]   I know you're next.
[02:01:02.420 --> 02:01:03.420]   I know you're next.
[02:01:03.420 --> 02:01:04.420]   I know you're next.
[02:01:04.420 --> 02:01:05.420]   I know you're next.
[02:01:05.420 --> 02:01:06.420]   I know you're next.
[02:01:06.420 --> 02:01:07.420]   I know you're next.
[02:01:07.420 --> 02:01:08.420]   I know you're next.
[02:01:08.420 --> 02:01:09.420]   I know you're next.
[02:01:09.420 --> 02:01:10.420]   I know you're next.
[02:01:10.420 --> 02:01:11.420]   I know you're next.
[02:01:11.420 --> 02:01:12.420]   I know you're next.
[02:01:12.420 --> 02:01:13.420]   I know you're next.
[02:01:13.420 --> 02:01:14.420]   I know you're next.
[02:01:14.420 --> 02:01:15.420]   I know you're next.
[02:01:15.420 --> 02:01:16.420]   I know you're next.
[02:01:16.420 --> 02:01:17.420]   I know you're next.
[02:01:17.420 --> 02:01:18.420]   I know you're next.
[02:01:18.420 --> 02:01:19.420]   I know you're next.
[02:01:19.420 --> 02:01:20.420]   I know you're next.
[02:01:20.420 --> 02:01:21.420]   I know you're next.
[02:01:21.420 --> 02:01:22.420]   I know you're next.
[02:01:22.420 --> 02:01:23.420]   I know you're next.
[02:01:23.420 --> 02:01:24.420]   I know you're next.
[02:01:24.420 --> 02:01:25.420]   I know you're next.
[02:01:25.420 --> 02:01:26.420]   I know you're next.
[02:01:26.420 --> 02:01:27.420]   I know you're next.
[02:01:27.420 --> 02:01:28.420]   I know you're next.
[02:01:28.420 --> 02:01:29.420]   I know you're next.
[02:01:29.420 --> 02:01:30.420]   I know you're next.
[02:01:30.420 --> 02:01:31.420]   I know you're next.
[02:01:31.420 --> 02:01:32.420]   I know you're next.
[02:01:32.420 --> 02:01:33.420]   I know you're next.
[02:01:33.420 --> 02:01:34.420]   I know you're next.
[02:01:34.420 --> 02:01:35.420]   I know you're next.
[02:01:35.420 --> 02:01:36.420]   I know you're next.
[02:01:36.420 --> 02:01:37.420]   I know you're next.
[02:01:37.420 --> 02:01:38.420]   I know you're next.
[02:01:38.420 --> 02:01:39.420]   I know you're next.
[02:01:39.420 --> 02:01:40.420]   I know you're next.
[02:01:40.420 --> 02:01:41.420]   I know you're next.
[02:01:41.420 --> 02:01:42.420]   I know you're next.
[02:01:42.420 --> 02:01:47.420]   I know you're next.
[02:01:47.420 --> 02:01:48.420]   I know you're next.
[02:01:48.420 --> 02:01:49.420]   I know you're next.
[02:01:49.420 --> 02:01:50.420]   I know you're next.
[02:01:50.420 --> 02:01:51.420]   I know you're next.
[02:01:51.420 --> 02:01:52.420]   I know you're next.
[02:01:52.420 --> 02:01:53.420]   I know you're next.
[02:01:53.420 --> 02:01:54.420]   I know you're next.
[02:01:54.420 --> 02:01:55.420]   I know you're next.
[02:01:55.420 --> 02:01:56.420]   I know you're next.
[02:01:56.420 --> 02:01:57.420]   I know you're next.
[02:01:57.420 --> 02:01:58.420]   I know you're next.
[02:01:58.420 --> 02:01:59.420]   I know you're next.
[02:01:59.420 --> 02:02:00.420]   I know you're next.
[02:02:00.420 --> 02:02:01.420]   I know you're next.
[02:02:01.420 --> 02:02:02.420]   I know you're next.
[02:02:02.420 --> 02:02:03.420]   I know you're next.
[02:02:03.420 --> 02:02:04.420]   I know you're next.
[02:02:04.420 --> 02:02:05.420]   I know you're next.
[02:02:05.420 --> 02:02:06.420]   I know you're next.
[02:02:06.420 --> 02:02:07.420]   I know you're next.
[02:02:07.420 --> 02:02:08.420]   I know you're next.
[02:02:08.420 --> 02:02:09.420]   I know you're next.
[02:02:09.420 --> 02:02:10.420]   I know you're next.
[02:02:10.420 --> 02:02:11.420]   I know you're next.
[02:02:11.420 --> 02:02:12.420]   I know you're next.
[02:02:12.420 --> 02:02:13.420]   I know you're next.
[02:02:13.420 --> 02:02:14.420]   I know you're next.
[02:02:14.420 --> 02:02:15.420]   I know you're next.
[02:02:15.420 --> 02:02:16.420]   I know you're next.
[02:02:16.420 --> 02:02:17.420]   I know you're next.
[02:02:17.420 --> 02:02:18.420]   I know you're next.
[02:02:18.420 --> 02:02:19.420]   I know you're next.
[02:02:19.420 --> 02:02:20.420]   I know you're next.
[02:02:20.420 --> 02:02:21.420]   I know you're next.
[02:02:21.420 --> 02:02:22.420]   I know you're next.
[02:02:22.420 --> 02:02:23.420]   I know you're next.
[02:02:23.420 --> 02:02:24.420]   I know you're next.
[02:02:24.420 --> 02:02:25.420]   I know you're next.
[02:02:25.420 --> 02:02:26.420]   I know you're next.
[02:02:26.420 --> 02:02:27.420]   I know you're next.
[02:02:27.420 --> 02:02:28.420]   I know you're next.
[02:02:28.420 --> 02:02:29.420]   I know you're next.
[02:02:29.420 --> 02:02:30.420]   I know you're next.
[02:02:30.420 --> 02:02:31.420]   I know you're next.
[02:02:31.420 --> 02:02:32.420]   I know you're next.
[02:02:32.420 --> 02:02:33.420]   I know you're next.
[02:02:33.420 --> 02:02:34.420]   I know you're next.
[02:02:34.420 --> 02:02:35.420]   I know you're next.
[02:02:35.420 --> 02:02:36.420]   I know you're next.
[02:02:36.420 --> 02:02:37.420]   I know you're next.
[02:02:37.420 --> 02:02:38.420]   I know you're next.
[02:02:38.420 --> 02:02:41.420]   I know you're next.
[02:02:41.420 --> 02:02:42.420]   I know you're next.
[02:02:42.420 --> 02:02:43.420]   I know you're next.
[02:02:43.420 --> 02:02:44.420]   I know you're next.
[02:02:44.420 --> 02:02:45.420]   I know you're next.
[02:02:45.420 --> 02:02:46.420]   I know you're next.
[02:02:46.420 --> 02:02:47.420]   I know you're next.
[02:02:47.420 --> 02:02:48.420]   I know you're next.
[02:02:48.420 --> 02:02:49.420]   I know you're next.
[02:02:49.420 --> 02:02:50.420]   I know you're next.
[02:02:50.420 --> 02:02:51.420]   I know you're next.
[02:02:51.420 --> 02:02:52.420]   I know you're next.
[02:02:52.420 --> 02:02:53.420]   I know you're next.
[02:02:53.420 --> 02:02:54.420]   I know you're next.
[02:02:54.420 --> 02:02:55.420]   I know you're next.
[02:02:55.420 --> 02:02:56.420]   I know you're next.
[02:02:56.420 --> 02:02:57.420]   I know you're next.
[02:02:57.420 --> 02:02:58.420]   I know you're next.
[02:02:58.420 --> 02:02:59.420]   I know you're next.
[02:02:59.420 --> 02:03:00.420]   I know you're next.
[02:03:00.420 --> 02:03:01.420]   I know you're next.
[02:03:01.420 --> 02:03:02.420]   I know you're next.
[02:03:02.420 --> 02:03:03.420]   I know you're next.
[02:03:03.420 --> 02:03:04.420]   I know you're next.
[02:03:04.420 --> 02:03:05.420]   I know you're next.
[02:03:05.420 --> 02:03:06.420]   I know you're next.
[02:03:06.420 --> 02:03:07.420]   I know you're next.
[02:03:07.420 --> 02:03:08.420]   I know you're next.
[02:03:08.420 --> 02:03:09.420]   I know you're next.
[02:03:09.420 --> 02:03:10.420]   I know you're next.
[02:03:10.420 --> 02:03:11.420]   I know you're next.
[02:03:11.420 --> 02:03:12.420]   I know you're next.
[02:03:12.420 --> 02:03:13.420]   I know you're next.
[02:03:13.420 --> 02:03:14.420]   I know you're next.
[02:03:14.420 --> 02:03:15.420]   I know you're next.
[02:03:15.420 --> 02:03:16.420]   I know you're next.
[02:03:16.420 --> 02:03:17.420]   I know you're next.
[02:03:17.420 --> 02:03:18.420]   I know you're next.
[02:03:18.420 --> 02:03:19.420]   I know you're next.
[02:03:19.420 --> 02:03:20.420]   I know you're next.
[02:03:20.420 --> 02:03:21.420]   I know you're next.
[02:03:21.420 --> 02:03:22.420]   I know you're next.
[02:03:22.420 --> 02:03:23.420]   I know you're next.
[02:03:23.420 --> 02:03:24.420]   I know you're next.
[02:03:24.420 --> 02:03:25.420]   I know you're next.
[02:03:25.420 --> 02:03:26.420]   I know you're next.
[02:03:26.420 --> 02:03:27.420]   I know you're next.
[02:03:27.420 --> 02:03:28.420]   I know you're next.
[02:03:28.420 --> 02:03:29.420]   I know you're next.
[02:03:29.420 --> 02:03:30.420]   I know you're next.
[02:03:30.420 --> 02:03:31.420]   I know you're next.
[02:03:31.420 --> 02:03:32.420]   I know you're next.
[02:03:32.420 --> 02:03:33.420]   I know you're next.
[02:03:33.420 --> 02:03:34.420]   I know you're next.
[02:03:34.420 --> 02:03:39.420]   I know you're next.
[02:03:39.420 --> 02:03:40.420]   I know you're next.
[02:03:40.420 --> 02:03:41.420]   I know you're next.
[02:03:41.420 --> 02:03:42.420]   I know you're next.
[02:03:42.420 --> 02:03:43.420]   I know you're next.
[02:03:43.420 --> 02:03:44.420]   I know you're next.
[02:03:44.420 --> 02:03:45.420]   I know you're next.
[02:03:45.420 --> 02:03:46.420]   I know you're next.
[02:03:46.420 --> 02:03:47.420]   I know you're next.
[02:03:47.420 --> 02:03:48.420]   I know you're next.
[02:03:48.420 --> 02:03:49.420]   I know you're next.
[02:03:49.420 --> 02:03:50.420]   I know you're next.
[02:03:50.420 --> 02:03:51.420]   I know you're next.
[02:03:51.420 --> 02:03:52.420]   I know you're next.
[02:03:52.420 --> 02:03:53.420]   I know you're next.
[02:03:53.420 --> 02:03:54.420]   I know you're next.
[02:03:54.420 --> 02:03:55.420]   I know you're next.
[02:03:55.420 --> 02:03:56.420]   I know you're next.
[02:03:56.420 --> 02:03:57.420]   I know you're next.
[02:03:57.420 --> 02:03:58.420]   I know you're next.
[02:03:58.420 --> 02:03:59.420]   I know you're next.
[02:03:59.420 --> 02:04:00.420]   I know you're next.
[02:04:00.420 --> 02:04:01.420]   I know you're next.
[02:04:01.420 --> 02:04:02.420]   I know you're next.
[02:04:02.420 --> 02:04:03.420]   I know you're next.
[02:04:03.420 --> 02:04:04.420]   I know you're next.
[02:04:04.420 --> 02:04:05.420]   I know you're next.
[02:04:05.420 --> 02:04:06.420]   I know you're next.
[02:04:06.420 --> 02:04:07.420]   I know you're next.
[02:04:07.420 --> 02:04:08.420]   I know you're next.
[02:04:08.420 --> 02:04:09.420]   I know you're next.
[02:04:09.420 --> 02:04:10.420]   I know you're next.
[02:04:10.420 --> 02:04:11.420]   I know you're next.
[02:04:11.420 --> 02:04:12.420]   I know you're next.
[02:04:12.420 --> 02:04:13.420]   I know you're next.
[02:04:13.420 --> 02:04:14.420]   I know you're next.
[02:04:14.420 --> 02:04:15.420]   I know you're next.
[02:04:15.420 --> 02:04:16.420]   I know you're next.
[02:04:16.420 --> 02:04:17.420]   I know you're next.
[02:04:17.420 --> 02:04:18.420]   I know you're next.
[02:04:18.420 --> 02:04:19.420]   I know you're next.
[02:04:19.420 --> 02:04:20.420]   I know you're next.
[02:04:20.420 --> 02:04:21.420]   I know you're next.
[02:04:21.420 --> 02:04:22.420]   I know you're next.
[02:04:22.420 --> 02:04:23.420]   I know you're next.
[02:04:23.420 --> 02:04:24.420]   I know you're next.
[02:04:24.420 --> 02:04:25.420]   I know you're next.
[02:04:25.420 --> 02:04:26.420]   I know you're next.
[02:04:26.420 --> 02:04:27.420]   I know you're next.
[02:04:27.420 --> 02:04:28.420]   I know you're next.
[02:04:28.420 --> 02:04:29.420]   I know you're next.
[02:04:29.420 --> 02:04:30.420]   I know you're next.
[02:04:30.420 --> 02:04:33.420]   I know you're next.
[02:04:33.420 --> 02:04:34.420]   I know you're next.
[02:04:34.420 --> 02:04:35.420]   I know you're next.
[02:04:35.420 --> 02:04:36.420]   I know you're next.
[02:04:36.420 --> 02:04:37.420]   I know you're next.
[02:04:37.420 --> 02:04:38.420]   I know you're next.
[02:04:38.420 --> 02:04:39.420]   I know you're next.
[02:04:39.420 --> 02:04:40.420]   I know you're next.
[02:04:40.420 --> 02:04:41.420]   I know you're next.
[02:04:41.420 --> 02:04:42.420]   I know you're next.
[02:04:42.420 --> 02:04:43.420]   I know you're next.
[02:04:43.420 --> 02:04:44.420]   I know you're next.
[02:04:44.420 --> 02:04:45.420]   I know you're next.
[02:04:45.420 --> 02:04:46.420]   I know you're next.
[02:04:46.420 --> 02:04:47.420]   I know you're next.
[02:04:47.420 --> 02:04:48.420]   I know you're next.
[02:04:48.420 --> 02:04:49.420]   I know you're next.
[02:04:49.420 --> 02:04:50.420]   I know you're next.
[02:04:50.420 --> 02:04:51.420]   I know you're next.
[02:04:51.420 --> 02:04:52.420]   I know you're next.
[02:04:52.420 --> 02:04:53.420]   I know you're next.
[02:04:53.420 --> 02:04:54.420]   I know you're next.
[02:04:54.420 --> 02:04:55.420]   I know you're next.
[02:04:55.420 --> 02:04:56.420]   I know you're next.
[02:04:56.420 --> 02:04:57.420]   I know you're next.
[02:04:57.420 --> 02:04:58.420]   I know you're next.
[02:04:58.420 --> 02:04:59.420]   I know you're next.
[02:04:59.420 --> 02:05:00.420]   I know you're next.
[02:05:00.420 --> 02:05:01.420]   I know you're next.
[02:05:01.420 --> 02:05:02.420]   I know you're next.
[02:05:02.420 --> 02:05:03.420]   I know you're next.
[02:05:03.420 --> 02:05:04.420]   I know you're next.
[02:05:04.420 --> 02:05:05.420]   I know you're next.
[02:05:05.420 --> 02:05:06.420]   I know you're next.
[02:05:06.420 --> 02:05:07.420]   I know you're next.
[02:05:07.420 --> 02:05:08.420]   I know you're next.
[02:05:08.420 --> 02:05:09.420]   I know you're next.
[02:05:09.420 --> 02:05:10.420]   I know you're next.
[02:05:10.420 --> 02:05:11.420]   I know you're next.
[02:05:11.420 --> 02:05:12.420]   I know you're next.
[02:05:12.420 --> 02:05:13.420]   I know you're next.
[02:05:13.420 --> 02:05:14.420]   I know you're next.
[02:05:14.420 --> 02:05:15.420]   I know you're next.
[02:05:15.420 --> 02:05:16.420]   I know you're next.
[02:05:16.420 --> 02:05:17.420]   I know you're next.
[02:05:17.420 --> 02:05:18.420]   I know you're next.
[02:05:18.420 --> 02:05:19.420]   I know you're next.
[02:05:19.420 --> 02:05:20.420]   I know you're next.
[02:05:20.420 --> 02:05:21.420]   I know you're next.
[02:05:21.420 --> 02:05:22.420]   I know you're next.
[02:05:22.420 --> 02:05:23.420]   I know you're next.
[02:05:23.420 --> 02:05:24.420]   I know you're next.
[02:05:24.420 --> 02:05:25.420]   I know you're next.
[02:05:25.420 --> 02:05:26.420]   I know you're next.
[02:05:26.420 --> 02:05:31.420]   I know you're next.
[02:05:31.420 --> 02:05:32.420]   I know you're next.
[02:05:32.420 --> 02:05:33.420]   I know you're next.
[02:05:33.420 --> 02:05:34.420]   I know you're next.
[02:05:34.420 --> 02:05:35.420]   I know you're next.
[02:05:35.420 --> 02:05:36.420]   I know you're next.
[02:05:36.420 --> 02:05:37.420]   I know you're next.
[02:05:37.420 --> 02:05:38.420]   I know you're next.
[02:05:38.420 --> 02:05:39.420]   I know you're next.
[02:05:39.420 --> 02:05:40.420]   I know you're next.
[02:05:40.420 --> 02:05:41.420]   I know you're next.
[02:05:41.420 --> 02:05:42.420]   I know you're next.
[02:05:42.420 --> 02:05:43.420]   I know you're next.
[02:05:43.420 --> 02:05:44.420]   I know you're next.
[02:05:44.420 --> 02:05:45.420]   I know you're next.
[02:05:45.420 --> 02:05:46.420]   I know you're next.
[02:05:46.420 --> 02:05:47.420]   I know you're next.
[02:05:47.420 --> 02:05:48.420]   I know you're next.
[02:05:48.420 --> 02:05:49.420]   I know you're next.
[02:05:49.420 --> 02:05:50.420]   I know you're next.
[02:05:50.420 --> 02:05:51.420]   I know you're next.
[02:05:51.420 --> 02:05:52.420]   I know you're next.
[02:05:52.420 --> 02:05:53.420]   I know you're next.
[02:05:53.420 --> 02:05:54.420]   I know you're next.
[02:05:54.420 --> 02:05:55.420]   I know you're next.
[02:05:55.420 --> 02:05:56.420]   I know you're next.
[02:05:56.420 --> 02:05:57.420]   I know you're next.
[02:05:57.420 --> 02:05:58.420]   I know you're next.
[02:05:58.420 --> 02:05:59.420]   I know you're next.
[02:05:59.420 --> 02:06:00.420]   I know you're next.
[02:06:00.420 --> 02:06:01.420]   I know you're next.
[02:06:01.420 --> 02:06:02.420]   I know you're next.
[02:06:02.420 --> 02:06:03.420]   I know you're next.
[02:06:03.420 --> 02:06:04.420]   I know you're next.
[02:06:04.420 --> 02:06:05.420]   I know you're next.
[02:06:05.420 --> 02:06:06.420]   I know you're next.
[02:06:06.420 --> 02:06:07.420]   I know you're next.
[02:06:07.420 --> 02:06:08.420]   I know you're next.
[02:06:08.420 --> 02:06:09.420]   I know you're next.
[02:06:09.420 --> 02:06:10.420]   I know you're next.
[02:06:10.420 --> 02:06:11.420]   I know you're next.
[02:06:11.420 --> 02:06:12.420]   I know you're next.
[02:06:12.420 --> 02:06:13.420]   I know you're next.
[02:06:13.420 --> 02:06:14.420]   I know you're next.
[02:06:14.420 --> 02:06:15.420]   I know you're next.
[02:06:15.420 --> 02:06:16.420]   I know you're next.
[02:06:16.420 --> 02:06:17.420]   I know you're next.
[02:06:17.420 --> 02:06:18.420]   I know you're next.
[02:06:18.420 --> 02:06:19.420]   I know you're next.
[02:06:19.420 --> 02:06:20.420]   I know you're next.
[02:06:20.420 --> 02:06:21.420]   I know you're next.
[02:06:21.420 --> 02:06:22.420]   I know you're next.
[02:06:22.420 --> 02:06:24.420]   I know you're next.
[02:06:24.420 --> 02:06:25.420]   I know you're next.
[02:06:25.420 --> 02:06:26.420]   I know you're next.
[02:06:26.420 --> 02:06:27.420]   I know you're next.
[02:06:27.420 --> 02:06:28.420]   I know you're next.
[02:06:28.420 --> 02:06:29.420]   I know you're next.
[02:06:29.420 --> 02:06:30.420]   I know you're next.
[02:06:30.420 --> 02:06:31.420]   I know you're next.
[02:06:31.420 --> 02:06:32.420]   I know you're next.
[02:06:32.420 --> 02:06:33.420]   I know you're next.
[02:06:33.420 --> 02:06:34.420]   I know you're next.
[02:06:34.420 --> 02:06:35.420]   I know you're next.
[02:06:35.420 --> 02:06:36.420]   I know you're next.
[02:06:36.420 --> 02:06:37.420]   I know you're next.
[02:06:37.420 --> 02:06:38.420]   I know you're next.
[02:06:38.420 --> 02:06:39.420]   I know you're next.
[02:06:39.420 --> 02:06:40.420]   I know you're next.
[02:06:40.420 --> 02:06:41.420]   I know you're next.
[02:06:41.420 --> 02:06:42.420]   I know you're next.
[02:06:42.420 --> 02:06:43.420]   I know you're next.
[02:06:43.420 --> 02:06:44.420]   I know you're next.
[02:06:44.420 --> 02:06:45.420]   I know you're next.
[02:06:45.420 --> 02:06:46.420]   I know you're next.
[02:06:46.420 --> 02:06:47.420]   I know you're next.
[02:06:47.420 --> 02:06:48.420]   I know you're next.
[02:06:48.420 --> 02:06:49.420]   I know you're next.
[02:06:49.420 --> 02:06:50.420]   I know you're next.
[02:06:50.420 --> 02:06:52.420]   I know you're next.
[02:06:52.420 --> 02:06:53.420]   I know you're next.
[02:06:53.420 --> 02:06:54.420]   I know you're next.
[02:06:54.420 --> 02:06:55.420]   I know you're next.
[02:06:55.420 --> 02:06:56.420]   I know you're next.
[02:06:56.420 --> 02:06:57.420]   I know you're next.
[02:06:57.420 --> 02:06:58.420]   I know you're next.
[02:06:58.420 --> 02:06:59.420]   I know you're next.
[02:06:59.420 --> 02:07:00.420]   I know you're next.
[02:07:00.420 --> 02:07:01.420]   I know you're next.
[02:07:01.420 --> 02:07:02.420]   I know you're next.
[02:07:02.420 --> 02:07:03.420]   I know you're next.
[02:07:03.420 --> 02:07:04.420]   I know you're next.
[02:07:04.420 --> 02:07:05.420]   I know you're next.
[02:07:05.420 --> 02:07:06.420]   I know you're next.
[02:07:06.420 --> 02:07:07.420]   I know you're next.
[02:07:07.420 --> 02:07:08.420]   I know you're next.
[02:07:08.420 --> 02:07:09.420]   I know you're next.
[02:07:09.420 --> 02:07:10.420]   I know you're next.
[02:07:10.420 --> 02:07:11.420]   I know you're next.
[02:07:11.420 --> 02:07:12.420]   I know you're next.
[02:07:12.420 --> 02:07:13.420]   I know you're next.
[02:07:13.420 --> 02:07:14.420]   I know you're next.
[02:07:14.420 --> 02:07:15.420]   I know you're next.
[02:07:15.420 --> 02:07:16.420]   I know you're next.
[02:07:16.420 --> 02:07:17.420]   I know you're next.
[02:07:17.420 --> 02:07:18.420]   I know you're next.
[02:07:18.420 --> 02:07:20.420]   I know you're next.
[02:07:20.420 --> 02:07:21.420]   I know you're next.
[02:07:21.420 --> 02:07:22.420]   I know you're next.
[02:07:22.420 --> 02:07:23.420]   I know you're next.
[02:07:23.420 --> 02:07:24.420]   I know you're next.
[02:07:24.420 --> 02:07:25.420]   I know you're next.
[02:07:25.420 --> 02:07:26.420]   I know you're next.
[02:07:26.420 --> 02:07:27.420]   I know you're next.
[02:07:27.420 --> 02:07:28.420]   I know you're next.
[02:07:28.420 --> 02:07:29.420]   I know you're next.
[02:07:29.420 --> 02:07:30.420]   I know you're next.
[02:07:30.420 --> 02:07:31.420]   I know you're next.
[02:07:31.420 --> 02:07:32.420]   I know you're next.
[02:07:32.420 --> 02:07:33.420]   I know you're next.
[02:07:33.420 --> 02:07:34.420]   I know you're next.
[02:07:34.420 --> 02:07:35.420]   I know you're next.
[02:07:35.420 --> 02:07:36.420]   I know you're next.
[02:07:36.420 --> 02:07:37.420]   I know you're next.
[02:07:37.420 --> 02:07:38.420]   I know you're next.
[02:07:38.420 --> 02:07:39.420]   I know you're next.
[02:07:39.420 --> 02:07:40.420]   I know you're next.
[02:07:40.420 --> 02:07:41.420]   I know you're next.
[02:07:41.420 --> 02:07:42.420]   I know you're next.
[02:07:42.420 --> 02:07:43.420]   I know you're next.
[02:07:43.420 --> 02:07:44.420]   I know you're next.
[02:07:44.420 --> 02:07:45.420]   I know you're next.
[02:07:45.420 --> 02:07:46.420]   I know you're next.
[02:07:46.420 --> 02:07:48.420]   I know you're next.
[02:07:48.420 --> 02:07:49.420]   I know you're next.
[02:07:49.420 --> 02:07:50.420]   I know you're next.
[02:07:50.420 --> 02:07:51.420]   I know you're next.
[02:07:51.420 --> 02:07:52.420]   I know you're next.
[02:07:52.420 --> 02:07:53.420]   I know you're next.
[02:07:53.420 --> 02:07:54.420]   I know you're next.
[02:07:54.420 --> 02:07:55.420]   I know you're next.
[02:07:55.420 --> 02:07:56.420]   I know you're next.
[02:07:56.420 --> 02:07:57.420]   I know you're next.
[02:07:57.420 --> 02:07:58.420]   I know you're next.
[02:07:58.420 --> 02:07:59.420]   I know you're next.
[02:07:59.420 --> 02:08:00.420]   I know you're next.
[02:08:00.420 --> 02:08:01.420]   I know you're next.
[02:08:01.420 --> 02:08:02.420]   I know you're next.
[02:08:02.420 --> 02:08:03.420]   I know you're next.
[02:08:03.420 --> 02:08:04.420]   I know you're next.
[02:08:04.420 --> 02:08:05.420]   I know you're next.
[02:08:05.420 --> 02:08:06.420]   I know you're next.
[02:08:06.420 --> 02:08:07.420]   I know you're next.
[02:08:07.420 --> 02:08:08.420]   I know you're next.
[02:08:08.420 --> 02:08:09.420]   I know you're next.
[02:08:09.420 --> 02:08:10.420]   I know you're next.
[02:08:10.420 --> 02:08:11.420]   I know you're next.
[02:08:11.420 --> 02:08:12.420]   I know you're next.
[02:08:12.420 --> 02:08:13.420]   I know you're next.
[02:08:13.420 --> 02:08:14.420]   I know you're next.
[02:08:14.420 --> 02:08:16.420]   I know you're next.
[02:08:16.420 --> 02:08:17.420]   I know you're next.
[02:08:17.420 --> 02:08:18.420]   I know you're next.
[02:08:18.420 --> 02:08:19.420]   I know you're next.
[02:08:19.420 --> 02:08:20.420]   I know you're next.
[02:08:20.420 --> 02:08:21.420]   I know you're next.
[02:08:21.420 --> 02:08:22.420]   I know you're next.
[02:08:22.420 --> 02:08:23.420]   I know you're next.
[02:08:23.420 --> 02:08:24.420]   I know you're next.
[02:08:24.420 --> 02:08:25.420]   I know you're next.
[02:08:25.420 --> 02:08:26.420]   I know you're next.
[02:08:26.420 --> 02:08:27.420]   I know you're next.
[02:08:27.420 --> 02:08:28.420]   I know you're next.
[02:08:28.420 --> 02:08:29.420]   I know you're next.
[02:08:29.420 --> 02:08:30.420]   I know you're next.
[02:08:30.420 --> 02:08:31.420]   I know you're next.
[02:08:31.420 --> 02:08:32.420]   I know you're next.
[02:08:32.420 --> 02:08:33.420]   I know you're next.
[02:08:33.420 --> 02:08:34.420]   I know you're next.
[02:08:34.420 --> 02:08:35.420]   I know you're next.
[02:08:35.420 --> 02:08:36.420]   I know you're next.
[02:08:36.420 --> 02:08:37.420]   I know you're next.
[02:08:37.420 --> 02:08:38.420]   I know you're next.
[02:08:38.420 --> 02:08:39.420]   I know you're next.
[02:08:39.420 --> 02:08:40.420]   I know you're next.
[02:08:40.420 --> 02:08:41.420]   I know you're next.
[02:08:41.420 --> 02:08:42.420]   I know you're next.
[02:08:42.420 --> 02:08:44.420]   I know you're next.
[02:08:44.420 --> 02:08:45.420]   I know you're next.
[02:08:45.420 --> 02:08:46.420]   I know you're next.
[02:08:46.420 --> 02:08:47.420]   I know you're next.
[02:08:47.420 --> 02:08:48.420]   I know you're next.
[02:08:48.420 --> 02:08:49.420]   I know you're next.
[02:08:49.420 --> 02:08:50.420]   I know you're next.
[02:08:50.420 --> 02:08:51.420]   I know you're next.
[02:08:51.420 --> 02:08:52.420]   I know you're next.
[02:08:52.420 --> 02:08:53.420]   I know you're next.
[02:08:53.420 --> 02:08:54.420]   I know you're next.
[02:08:54.420 --> 02:08:55.420]   I know you're next.
[02:08:55.420 --> 02:08:56.420]   I know you're next.
[02:08:56.420 --> 02:08:57.420]   I know you're next.
[02:08:57.420 --> 02:08:58.420]   I know you're next.
[02:08:58.420 --> 02:08:59.420]   I know you're next.
[02:08:59.420 --> 02:09:00.420]   I know you're next.
[02:09:00.420 --> 02:09:01.420]   I know you're next.
[02:09:01.420 --> 02:09:02.420]   I know you're next.
[02:09:02.420 --> 02:09:03.420]   I know you're next.
[02:09:03.420 --> 02:09:04.420]   I know you're next.
[02:09:04.420 --> 02:09:05.420]   I know you're next.
[02:09:05.420 --> 02:09:06.420]   I know you're next.
[02:09:06.420 --> 02:09:07.420]   I know you're next.
[02:09:07.420 --> 02:09:08.420]   I know you're next.
[02:09:08.420 --> 02:09:09.420]   I know you're next.
[02:09:09.420 --> 02:09:10.420]   I know you're next.
[02:09:10.420 --> 02:09:12.420]   I know you're next.
[02:09:12.420 --> 02:09:13.420]   I know you're next.
[02:09:13.420 --> 02:09:14.420]   I know you're next.
[02:09:14.420 --> 02:09:15.420]   I know you're next.
[02:09:15.420 --> 02:09:16.420]   I know you're next.
[02:09:16.420 --> 02:09:17.420]   I know you're next.
[02:09:17.420 --> 02:09:18.420]   I know you're next.
[02:09:18.420 --> 02:09:19.420]   I know you're next.
[02:09:19.420 --> 02:09:20.420]   I know you're next.
[02:09:20.420 --> 02:09:21.420]   I know you're next.
[02:09:21.420 --> 02:09:22.420]   I know you're next.
[02:09:22.420 --> 02:09:23.420]   I know you're next.
[02:09:23.420 --> 02:09:24.420]   I know you're next.
[02:09:24.420 --> 02:09:25.420]   I know you're next.
[02:09:25.420 --> 02:09:26.420]   I know you're next.
[02:09:26.420 --> 02:09:27.420]   I know you're next.
[02:09:27.420 --> 02:09:28.420]   I know you're next.
[02:09:28.420 --> 02:09:29.420]   I know you're next.
[02:09:29.420 --> 02:09:30.420]   I know you're next.
[02:09:30.420 --> 02:09:31.420]   I know you're next.
[02:09:31.420 --> 02:09:32.420]   I know you're next.
[02:09:32.420 --> 02:09:33.420]   I know you're next.
[02:09:33.420 --> 02:09:34.420]   I know you're next.
[02:09:34.420 --> 02:09:35.420]   I know you're next.
[02:09:35.420 --> 02:09:36.420]   I know you're next.
[02:09:36.420 --> 02:09:37.420]   I know you're next.
[02:09:37.420 --> 02:09:38.420]   I know you're next.
[02:09:38.420 --> 02:09:40.420]   I know you're next.
[02:09:40.420 --> 02:09:41.420]   I know you're next.
[02:09:41.420 --> 02:09:42.420]   I know you're next.
[02:09:42.420 --> 02:09:43.420]   I know you're next.
[02:09:43.420 --> 02:09:44.420]   I know you're next.
[02:09:44.420 --> 02:09:45.420]   I know you're next.
[02:09:45.420 --> 02:09:46.420]   I know you're next.
[02:09:46.420 --> 02:09:47.420]   I know you're next.
[02:09:47.420 --> 02:09:48.420]   I know you're next.
[02:09:48.420 --> 02:09:49.420]   I know you're next.
[02:09:49.420 --> 02:09:50.420]   I know you're next.
[02:09:50.420 --> 02:09:51.420]   I know you're next.
[02:09:51.420 --> 02:09:52.420]   I know you're next.
[02:09:52.420 --> 02:09:53.420]   I know you're next.
[02:09:53.420 --> 02:09:54.420]   I know you're next.
[02:09:54.420 --> 02:09:55.420]   I know you're next.
[02:09:55.420 --> 02:09:56.420]   I know you're next.
[02:09:56.420 --> 02:09:57.420]   I know you're next.
[02:09:57.420 --> 02:09:58.420]   I know you're next.
[02:09:58.420 --> 02:09:59.420]   I know you're next.
[02:09:59.420 --> 02:10:00.420]   I know you're next.
[02:10:00.420 --> 02:10:01.420]   I know you're next.
[02:10:01.420 --> 02:10:02.420]   I know you're next.
[02:10:02.420 --> 02:10:03.420]   I know you're next.
[02:10:03.420 --> 02:10:04.420]   I know you're next.
[02:10:04.420 --> 02:10:05.420]   I know you're next.
[02:10:05.420 --> 02:10:06.420]   I know you're next.
[02:10:06.420 --> 02:10:08.420]   I know you're next.
[02:10:08.420 --> 02:10:09.420]   I know you're next.
[02:10:09.420 --> 02:10:10.420]   I know you're next.
[02:10:10.420 --> 02:10:11.420]   I know you're next.

