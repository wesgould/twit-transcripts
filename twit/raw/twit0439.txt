;FFMETADATA1
title=Fist Like Monkey
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=439
genre=Podcast
comment=http://www.twit.tv/twit
copyright=These netcasts are released under a Creative Commons Attribution Non-Commercial Share-Alike license. TWiT and TWiT Logo are registered trademarks of Leo Laporte
publisher=TWiT
date=2014
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:06.360]   >> It's time for "Twit" this week in tech. We get ready for the international CES show
[00:00:06.360 --> 00:00:11.280]   which kicks off tonight. Ryan brushwoods here, Dan Patterson and Trey reklev. We'll talk
[00:00:11.280 --> 00:00:16.600]   about what's next with cameras, TVs, cars and more. "Twit" is next.
[00:00:16.600 --> 00:00:23.440]   >> Netcast, you love. >> From people you trust.
[00:00:23.440 --> 00:00:30.640]   >> This is "Twit." >> Bandwidth for this week in tech is provided
[00:00:30.640 --> 00:00:42.380]   by cash fly at CACHEFLY.com. This is "Twit" this week in tech. Episode
[00:00:42.380 --> 00:00:49.120]   439, recorded January 5th, 2014. >> Fist like monkey.
[00:00:49.120 --> 00:00:53.800]   >> This week in tech is brought to you by Stamps.com. Start using your time more effectively
[00:00:53.800 --> 00:00:58.840]   with Stamps.com. Use Stamps.com to buy and print real U.S. postage, the instant you need
[00:00:58.840 --> 00:01:03.600]   it right from your desk. For our special offer, go to Stamps.com. Click on the microphone
[00:01:03.600 --> 00:01:09.080]   and enter "Twit." And buy fresh books. The simple cloud accounting solution that helps
[00:01:09.080 --> 00:01:14.800]   thousands of entrepreneurs and small business owners save time, billing and get paid faster.
[00:01:14.800 --> 00:01:20.840]   Try it for free for 30 days at getfreshbooks.com and join over 5 million users running their
[00:01:20.840 --> 00:01:26.680]   business with ease. And buy Audible.com. Sign up for the platinum plan and get two free
[00:01:26.680 --> 00:01:32.680]   books, visit audible.com/twit2. And don't forget to follow Audible on Twitter, user ID,
[00:01:32.680 --> 00:01:40.160]   Audible_com. And buy Gazelle, the fast and simple way to sell your used gadgets. Find
[00:01:40.160 --> 00:02:07.120]   out what your used iPhone, iPad or other products are worth.
[00:02:07.120 --> 00:02:12.120]   Hey, Leo. How you doing? Hey Brian. Hey, Dan. Hey, everybody. I'm great. Right. Have
[00:02:12.120 --> 00:02:18.320]   you Brian brushable. He's got shingles. He's got the pox literally. Oh, yeah. I see we're
[00:02:18.320 --> 00:02:23.680]   just going to bring out my herpes right. Yeah, right. Herpes zoster, baby. This is actually
[00:02:23.680 --> 00:02:28.640]   not to be laughed at. In fact, you've inspired me and everybody over 50 to get a herpes to
[00:02:28.640 --> 00:02:33.680]   get a shingles shot because there is a vaccine won't prevent it but does reduce the. Yeah,
[00:02:33.680 --> 00:02:37.800]   well, I got to be honest, like it's not anything. By the way, it's just chicken pox. If you guys
[00:02:37.800 --> 00:02:42.480]   are freaking out, like brush was got herpes, put it on. But chicken pox never goes away.
[00:02:42.480 --> 00:02:47.400]   It's a systemic virus that continues your rest of your life, right? Yeah. Yeah. Well,
[00:02:47.400 --> 00:02:51.760]   and in this case, like I just noticed that my left side was sore and I went to the doctor
[00:02:51.760 --> 00:02:56.080]   and there was a news story saying if you got shingles before 40, you were at like some
[00:02:56.080 --> 00:02:59.640]   raised risk for a stroke down the right. I was like, wow, I don't know what she goes
[00:02:59.640 --> 00:03:03.240]   are. Wow, that sounds like that pain on my left side. So I went to the doctor and I start
[00:03:03.240 --> 00:03:07.000]   describing and he's like, well, let's take a look at all those are shingles.
[00:03:07.000 --> 00:03:17.400]   Holy cow. This will be I this will be notable as the single episode of this week in tech's
[00:03:17.400 --> 00:03:21.400]   tech where I'm highest as a kite. So enjoy my insight. Really? What do they give you?
[00:03:21.400 --> 00:03:24.680]   Uh, I don't know. I got a little bit of that.
[00:03:24.680 --> 00:03:25.680]   That's right. I think for you.
[00:03:25.680 --> 00:03:28.440]   Like it. Are you really you're on Viking in right now?
[00:03:28.440 --> 00:03:33.240]   I'm on I'm on a bike in an anti herpes medicine. So it's painful. What you're saying is very
[00:03:33.240 --> 00:03:39.480]   painful. Um, yeah, no, it sucks. I don't recommend it. If you have the means, don't get shingles.
[00:03:39.480 --> 00:03:45.080]   I hope you're I yeah, I hope you're feeling better and whatever you were a superstar. We'll
[00:03:45.080 --> 00:03:49.320]   get to that in just a second. A couple of days. And now look at me. I have a show.
[00:03:49.320 --> 00:03:50.360]   Now you got a man.
[00:03:50.360 --> 00:03:57.880]   By the way, it is not an STD. Okay. It's a childhood disease. Get that right. Also,
[00:03:57.880 --> 00:04:02.680]   with his dad Patterson from, uh, well, I got to get a new company to Nookie Labs. Hi, Dan.
[00:04:02.680 --> 00:04:07.640]   Hey, it's great to be here since you were here last. Dan, of course, a longtime radio
[00:04:07.640 --> 00:04:12.760]   journalist. Um, he for the last time you were here, you were at some all, uh, Dan Atkinson's
[00:04:12.760 --> 00:04:16.280]   company, uh, but still doing journalism. And now you're at Tanuki. What's Tanuki?
[00:04:16.280 --> 00:04:22.360]   So Tanuki is an incubator here in the New York City, uh, tech ecosystem. We build things. So,
[00:04:22.360 --> 00:04:29.400]   uh, primarily with the Ruby some node.js HTML five, uh, and, and they are kind enough to allow me to
[00:04:29.400 --> 00:04:34.280]   continue scratching my journalism. It's concurrently with doing some deep tech with them. So, uh, I
[00:04:34.280 --> 00:04:39.160]   will be traveling to the Middle East and, uh, using, uh, a lot of things that we've learned,
[00:04:39.160 --> 00:04:44.680]   particularly on security now with Steve Gibson, uh, many security tactics to reporters.
[00:04:44.680 --> 00:04:50.040]   At least we want to be a little discreet with the countries that we're visiting, but, uh, we're
[00:04:50.040 --> 00:04:54.440]   we're teaching things like PGP encryption, uh, and secure communication best practices.
[00:04:54.440 --> 00:04:57.720]   This seems to be a trend. I mean, I look at Robert Scoble at Rackspace. He's, you know,
[00:04:57.720 --> 00:05:02.120]   he is a journalist working within Rackspace. And I think more and more you're going to see companies,
[00:05:02.120 --> 00:05:07.400]   uh, doing content, even if it doesn't relate exactly to what the company is about.
[00:05:07.400 --> 00:05:13.080]   Uh, I don't know because it's a, it's good because it's a good thing. I don't know why.
[00:05:13.080 --> 00:05:14.040]   What's the percentage?
[00:05:14.040 --> 00:05:15.480]   Well, it's better to show than to tell, right?
[00:05:15.480 --> 00:05:20.680]   So, so, you know, with some on and continuing with, with Tanuki, it's way better to say,
[00:05:20.680 --> 00:05:25.080]   here is the capability. Why don't you just see the capability of what we can do as opposed to us
[00:05:25.080 --> 00:05:29.960]   just giving you a traditional marketing pitch. Now both can go concurrently. I fortunately don't
[00:05:29.960 --> 00:05:34.440]   have to touch the marketing angles, but for the most part, they, you know, a lot of companies are
[00:05:34.440 --> 00:05:40.200]   starting to see that the skills of journalism are directly applicable to the skills that, uh,
[00:05:40.200 --> 00:05:44.440]   technology companies need, but also do a really good job of showing and not telling.
[00:05:44.920 --> 00:05:49.960]   Yeah. You did an amazing thing covering the last presidential election on SoundCloud.
[00:05:49.960 --> 00:05:56.280]   You use Twitter, you use Medium. Uh, I think you storeify too for the original Occupy Wall Street
[00:05:56.280 --> 00:06:02.680]   stuff. That's exciting. It's cool to see somebody needs to somewhere try new forms of journalism
[00:06:02.680 --> 00:06:07.560]   instead of doing the same old thing over and over again. Well, it's nice to have the opportunity
[00:06:07.560 --> 00:06:11.880]   to participate in those forms of journalism as well as here in the tech, uh, Twit family.
[00:06:11.880 --> 00:06:16.920]   Yay. We're glad to have you, Dan. Uh, so I do a little props. I will get to the news in a second,
[00:06:16.920 --> 00:06:21.720]   but I just, you know, I got to acknowledge this New Year's Eve, uh, a few days ago. What was it,
[00:06:21.720 --> 00:06:27.960]   Wednesday, Thursday and Wednesday, and Brian came up for it and did an amazing magic show,
[00:06:27.960 --> 00:06:32.280]   which I think you've posted, but we're about to post all the video from New Year's Eve on our
[00:06:32.280 --> 00:06:38.920]   inside. It's with YouTube, uh, channel. So be YouTube.com/insight, Twit. What a great time.
[00:06:38.920 --> 00:06:44.680]   23 hour broadcast. Uh, we, we went all around the world. We, we, uh, train, we were hoping to have
[00:06:44.680 --> 00:06:50.760]   you in New Zealand, but we got very confused because New Zealand, and I think there were a lot of
[00:06:50.760 --> 00:06:55.400]   people confused that I was out taking photos. I got my new camera and I was all addicted out there
[00:06:55.400 --> 00:06:59.240]   and probably we, we both made mistakes. So don't worry about it. No, no, it's not your mistake,
[00:06:59.240 --> 00:07:04.280]   but I think New Zealand honors saving daylight savings time. And I think we, it would have had
[00:07:04.280 --> 00:07:10.440]   to be a 25 hour broadcast to have you or something like that. Anyway, remember that scene from
[00:07:10.440 --> 00:07:15.320]   Hitchhiker's got at the galaxy where he was actually his own grandfather because of a problem with a
[00:07:15.320 --> 00:07:23.000]   prophylactic and a time machine? That's what is like down here. It's anyway, good. Happy New Year
[00:07:23.000 --> 00:07:27.800]   to you. I'm sorry we didn't get you on, but, uh, it's, it's great to talk to you. Uh, now, and
[00:07:27.800 --> 00:07:33.240]   thank you, Brian, for doing an amazing magic act. I was, I didn't want to tell you at the time,
[00:07:33.240 --> 00:07:38.760]   but once I saw the fire ascending to the roof, I was just praying the sprinklers did not go off
[00:07:38.760 --> 00:07:45.000]   and grange the whole studio. That's one of those things where, uh, luckily in 15 years, we've never
[00:07:45.000 --> 00:07:50.760]   tripped a commercial alarm system. That's kind of, you get really good at analyzing what kind of
[00:07:50.760 --> 00:07:56.680]   system. Oh, so you checked one as you did. Sure. Sure. Okay. Yeah. We did not screw America Samoa.
[00:07:56.680 --> 00:08:03.160]   We had American Samoa. We screwed Samoa. There's a difference. Okay. I just want everybody to know.
[00:08:03.800 --> 00:08:09.720]   We screwed regular Samoa because they were early. We, but we got American Samoa. That was actually
[00:08:09.720 --> 00:08:16.840]   the last happy new, I popped 30 bottles of Cook's champagne at $6 a bottle that and they were
[00:08:16.840 --> 00:08:23.000]   make them still. Uh, that was fun. We have champagne all over the studio. And I think there's still a
[00:08:23.000 --> 00:08:29.000]   residue of kerosene in the carpet where I'm sitting from Brian's fire. Maybe it, it evaporates
[00:08:29.000 --> 00:08:33.320]   pretty quick. There's probably fake blood almost certainly right underneath you. That's fake.
[00:08:33.320 --> 00:08:39.720]   That's right. Sorry to disappoint you, Leo. Oh man, you magicians that it was real blood.
[00:08:39.720 --> 00:08:43.800]   Do you use that? What you use as an, as an accelerant? What do you use kerosene? What?
[00:08:43.800 --> 00:08:51.000]   I naffa. It's also called white gas or Coleman's camp fuel is the best. It burns bright and yellow.
[00:08:51.000 --> 00:08:56.520]   It's of course cancerous. But the, uh, what's you've had? There's nothing to fear.
[00:08:57.240 --> 00:09:00.920]   Yeah, whatever. Going downhill. How enjoyed my last appearance on Twitter?
[00:09:00.920 --> 00:09:09.160]   Cancer is really? Uh, sure. Everything is whatever. But, uh, but, you know, what's funny is the
[00:09:09.160 --> 00:09:14.360]   conversation you have with your doctor when you decide to quit your tech job to do a bizarre magic
[00:09:14.360 --> 00:09:18.360]   show and you sort of line by line, you're like, okay, look, you're not going to like any of the
[00:09:18.360 --> 00:09:23.160]   things I'm about to talk to you about. How horrified are you by? Let's start with fire.
[00:09:23.160 --> 00:09:28.680]   Drinking and naffa. Yeah, you, you, you come up with like best practices about like, for example,
[00:09:28.680 --> 00:09:33.000]   on the naffa thing, they don't worry about you swallowing it so much. They worry about you
[00:09:33.000 --> 00:09:38.520]   breathing it because that's what is, is cancerous. And in fact, if someone swallows kerosene,
[00:09:38.520 --> 00:09:43.880]   they give them charcoal and they tell them not to induce vomiting because the fear is, if you vomit,
[00:09:43.880 --> 00:09:48.840]   if you may aspirate it. Yeah, they're more worried about it getting in your lungs and your belly.
[00:09:48.840 --> 00:09:54.360]   So all that stuff. All about mitigated risks. I'm intrigued though that you actually went to a
[00:09:54.360 --> 00:09:58.120]   doctor. It doesn't feel like you really made that much planning. And so I'm, I'm glad. I wonder,
[00:09:58.120 --> 00:10:02.520]   how do you actually have you ever tried to like swallow charcoal? That sounds hard.
[00:10:02.520 --> 00:10:08.280]   Yeah. Yeah. I believe that comes in pill form now. Oh, yeah.
[00:10:08.280 --> 00:10:17.560]   So CES is next is a day. Well, starts tonight really. CES on vella. Just a few hours. Robert
[00:10:17.560 --> 00:10:23.000]   Ballis Arizona's way down there to cover that for us. You none of you are going to see. Yes,
[00:10:23.000 --> 00:10:29.000]   I take it. Thank God. No, I would have loved to. I'll tell you what the time that I that I came
[00:10:29.000 --> 00:10:33.960]   down and joined you guys was really a lot of fun. And I can understand how to someone whose job is
[00:10:33.960 --> 00:10:39.080]   is every year to go and see the same daily grind. Like, you know, I go and I'm all excited like,
[00:10:39.080 --> 00:10:44.680]   whoa, they're tasing people and they're like, yeah, that every year for you. And so I'm kind of glad
[00:10:44.680 --> 00:10:49.080]   that I only got the one time before I saw how the sausage was made and got jaded.
[00:10:49.080 --> 00:10:55.160]   It really is a measure of your status in the tech journalism field. When you're young, up and
[00:10:55.160 --> 00:11:00.520]   coming pop, getting to go to CES is a big deal. It's like, I got this. I got the ticket. I got
[00:11:00.520 --> 00:11:04.680]   the I'm going to see. Yes. I'm so excited. And then when you get to be like to Vorac,
[00:11:04.680 --> 00:11:10.120]   it's like, I'll never go to see yes again. And so that really is a way to determine where you
[00:11:10.120 --> 00:11:14.280]   stand on the tech scale. We are not going to be doing the sky booth that we've done. We didn't
[00:11:14.280 --> 00:11:16.680]   do it last year. We're not going to do it this year. But I'm really pleased to say
[00:11:16.680 --> 00:11:25.480]   that Callie Lewis and Geekbeat TV will be doing it along with Renee Richie of iMore.com and many
[00:11:25.480 --> 00:11:29.400]   others. They're actually taking our old booth spot and they're going to do live wall to wall
[00:11:29.400 --> 00:11:34.600]   coverage. I don't feel like we really need to do that anymore. It's so CES is so well covered.
[00:11:34.600 --> 00:11:40.440]   Saturated. There's no need to go. You can sit back, watch. I mean, everybody from Spike TV
[00:11:41.000 --> 00:11:46.840]   to USA Today to the Wall Street Journal. Everybody's there. So I don't feel the need and gadget and
[00:11:46.840 --> 00:11:54.760]   the verge and seeing it all have just like they send 50 people down. Giant staffs down there.
[00:11:54.760 --> 00:12:00.360]   So we're going to send Father Robert Baliser, the digital Jesuit. We're going to send an old
[00:12:00.360 --> 00:12:05.880]   priest and a young priest. We're going to send Dick Deed Bartolo, Mad Magazine's Mattis writer,
[00:12:05.880 --> 00:12:10.760]   and we're going to send Scott Wilkinson, our home theater guy. And my charge to them is find the
[00:12:10.760 --> 00:12:16.680]   top 10 products or the top 20 products, whatever you whatever that cut off is where after that,
[00:12:16.680 --> 00:12:21.320]   you don't really care because it's my position that probably there's no more than say 20 things
[00:12:21.320 --> 00:12:25.880]   that really matter at CES. Why don't we just focus on those and leave the vibrating for the
[00:12:25.880 --> 00:12:30.120]   top thing also is to figure out like which are the ones that matter. Right.
[00:12:30.120 --> 00:12:34.680]   It's like and again, I only really spent one year diving into it, but it's amazing out of the 50 or
[00:12:34.680 --> 00:12:39.960]   so things that I really paid attention to. Maybe three of them have turned into something and that's
[00:12:39.960 --> 00:12:43.640]   the big gamble. Right. Are you investing your time in something that's just going to be a giant
[00:12:43.640 --> 00:12:47.960]   waste or are you having a conversation with the folks who are going to be maker bot? You know,
[00:12:47.960 --> 00:12:51.400]   it's hard to know blow your minds to your. It's almost impossible to know.
[00:12:51.400 --> 00:12:57.480]   And why your own coverage matters, right? What individually, what is unique about your perspective
[00:12:57.480 --> 00:13:02.440]   and interpretation that really helps inform the audience. If we put them number one, right,
[00:13:02.440 --> 00:13:07.160]   we say the audience is what matters first. How can we lend our unique perspective to this that
[00:13:07.160 --> 00:13:11.720]   really adds some insight to an otherwise very commodified news cycle?
[00:13:11.720 --> 00:13:18.760]   Well, that is exactly right. And what would you say is the way to make CES coverage worth something?
[00:13:18.760 --> 00:13:25.000]   Well, I answer the number one question of why this matters to you, right? I think Twitter,
[00:13:25.000 --> 00:13:29.480]   of course, has carved out a very unique spot in the tech industry. And there is literally
[00:13:29.480 --> 00:13:35.880]   a chorus of voices here that all have a very unique identity and perspective. But for the most
[00:13:35.880 --> 00:13:42.520]   part, when we think about clickbait and the news beat, chart beat of the world driving instantaneous
[00:13:42.520 --> 00:13:49.560]   hyper optimized, listical traffic. I know I don't do that. There's not a lot of unique voice there.
[00:13:49.560 --> 00:13:55.480]   Well, that for instance, there will be an infinite or very close to approaching infinite number of
[00:13:55.480 --> 00:14:00.520]   Bluetooth speakers at CES this year. It's a category that was pioneered by Jambox.
[00:14:00.520 --> 00:14:05.000]   And that was a few years ago. And that was, you know, when the first when I got the first
[00:14:05.000 --> 00:14:10.520]   Jambox, that was, wow, this is great. Now there's 8,000 form factors. There's a million of them.
[00:14:10.520 --> 00:14:14.280]   I don't think that's worth covering at all a Bluetooth speakers, a Bluetooth speaker, right?
[00:14:14.280 --> 00:14:20.680]   They'll tell you what, man, how hard would it be to totally gamify CES and have like actual
[00:14:20.680 --> 00:14:27.560]   gladiatorial combat makes an avatar, you hire the biggest, strongest, toughest guy you can.
[00:14:27.560 --> 00:14:31.320]   You know, it's like, if you have the budget to be Sony, then you know, you get one of the guys
[00:14:31.320 --> 00:14:35.640]   from the TV show or whatever. And they just just slaughtering each other. Fight it out.
[00:14:35.640 --> 00:14:40.520]   That's a very, that's a very South Park approach to this. My favorite thing about CES is always the,
[00:14:40.520 --> 00:14:45.560]   I think it's all about the personalities that go and just putting really strong opinion into
[00:14:45.560 --> 00:14:49.720]   the products. Because we're also smart. We can just look at the top 10 products and we immediately
[00:14:49.720 --> 00:14:54.920]   can categorize it. We know what it is. We get it. But like, you know, when you see Conan go or do
[00:14:54.920 --> 00:15:00.440]   something ridiculous or Lady Gaga, remember she was there with that sort of the flavor of it.
[00:15:00.440 --> 00:15:03.000]   Otherwise, it's just sort of like dry tech.
[00:15:03.000 --> 00:15:06.360]   This is so funny because what you really have here is three people
[00:15:06.360 --> 00:15:14.200]   with the exact epitome of their personality saying this is what CES should be.
[00:15:14.200 --> 00:15:17.800]   Trey Rakcliffe was very humanistic, very focused on people. It's about the people.
[00:15:17.800 --> 00:15:22.200]   We got Dan Patterson saying it's about finding the right product and finding a unique voice.
[00:15:22.200 --> 00:15:26.200]   It's Brian Brushwood saying there should be death and killing.
[00:15:27.000 --> 00:15:32.680]   I'm saying it's about the big show and race your destiny CES. Make it about slaughter.
[00:15:32.680 --> 00:15:40.600]   And that really is what CES is. It is an elephant with 19,000 blind men fondling its parts.
[00:15:40.600 --> 00:15:44.280]   And you're trying to figure out what the hell am I looking at here?
[00:15:44.280 --> 00:15:50.120]   Well, and I'll tell you, a lot of this is kind of self, you have the marketplace of ideas. And in
[00:15:50.120 --> 00:15:54.120]   that regard, it's sort of self-police is because you got everybody who's making as big a noise as
[00:15:54.120 --> 00:15:57.480]   they can at the same time, which inherently is an odd way to do things.
[00:15:57.480 --> 00:15:57.960]   It's hard.
[00:15:57.960 --> 00:16:01.800]   Like let's all try to shout at the same moment and have the cream rise to the top.
[00:16:01.800 --> 00:16:05.240]   But you have stuff like Reddit, you can have a little tiny,
[00:16:05.240 --> 00:16:10.600]   oculus style product in the corner that somebody notices and it just explodes
[00:16:10.600 --> 00:16:13.720]   because it's the right idea at the right time. So it's like, I mean, I understand why you have
[00:16:13.720 --> 00:16:18.600]   to have a CES. And I understand you got to get all those same people in the same place,
[00:16:18.600 --> 00:16:24.040]   but the interpretation of that event, I think we're starting to virtualize as we have
[00:16:24.040 --> 00:16:25.880]   a lot of other experiences as well.
[00:16:25.880 --> 00:16:29.560]   Yeah. Let's take a break. When we come back, I wouldn't mind hearing from each of you what you
[00:16:29.560 --> 00:16:35.480]   look forward to. Trey, I mean, cameras are a part of CES. I know you've recently just made the move
[00:16:35.480 --> 00:16:41.560]   from being an icon guy to a Sony guy. And in particular, the new A7, I'm very interested in
[00:16:41.560 --> 00:16:48.200]   hearing intake on that and what we might see from Sony and others at CES. Dan Patterson is also
[00:16:48.200 --> 00:16:54.600]   here from Tanooki Labs. And of course, the great Brian Brushwood. And I'm hoping before this show
[00:16:54.600 --> 00:16:59.640]   is over, we can give you a link where you'll be able to find Brian's amazing performance.
[00:16:59.640 --> 00:17:06.360]   You can go see NSFW, the NSFW show we did there. It's a good one. Like, like normally, like NSFW
[00:17:06.360 --> 00:17:11.000]   has always been highly experimental Leo. And I'm probably not the first to suggest that maybe
[00:17:11.000 --> 00:17:15.800]   sometimes were hit, sometimes were missed. But this was easily, I would show, I would show
[00:17:15.800 --> 00:17:19.960]   anybody this last episode as a representation of the best that we can be.
[00:17:19.960 --> 00:17:23.000]   I would, you know, I was stunned. I didn't realize it was a funny show.
[00:17:23.000 --> 00:17:29.320]   A lot of the audience feels that way, Leo. I think you actually, you know what happened,
[00:17:29.320 --> 00:17:32.920]   because a lot of people were watching our coverage that don't normally watch NSFW.
[00:17:32.920 --> 00:17:37.560]   I think you actually did get a whole new bunch of people saying, like me, because I try not to
[00:17:37.560 --> 00:17:42.840]   watch NSFW because I don't want to have to cancel it. So, you know, I try to avoid, you know, I just,
[00:17:42.840 --> 00:17:46.840]   I it's caused plausible deniability. Plausible deniability. I don't know what they did.
[00:17:46.840 --> 00:17:51.480]   What are you talking about? But I was part of this show. And it was about the funniest thing.
[00:17:51.480 --> 00:18:01.240]   I could not stop laughing. I had so much fun. So it is, it is on twit.tv/NSFW episode 211, our
[00:18:01.240 --> 00:18:07.560]   New Year Show. Will Harris came out for that. And he is great. It was just a lot of fun.
[00:18:08.840 --> 00:18:14.280]   Will was in rare form. We got, we got Will singing a la Johnny Cash. He did great.
[00:18:14.280 --> 00:18:21.160]   He got to Leo alternately twerking and screaming like a goat. And by the way, I wasn't out of
[00:18:21.160 --> 00:18:26.920]   it or drunk or anything. I just fallen down. No, no, no, no. You're rocking it. Are you kidding
[00:18:26.920 --> 00:18:31.320]   me? You killed it, man. It was great. I told, I told J.R.Y. afterwards, I said, thank you for
[00:18:31.320 --> 00:18:35.880]   not making me sing. I could scream like a goat at the drop of a hat. Just thank you for not making
[00:18:35.880 --> 00:18:43.160]   me sing. Our show today brought to you by stamps.com. We're, you know, you probably see these giant
[00:18:43.160 --> 00:18:47.960]   mats that I've got in front of me. We're going to talk about that a little bit later. This company
[00:18:47.960 --> 00:18:53.480]   called Daniel came by from Maker Mat and he's making these giant mats. And he's going to mail
[00:18:53.480 --> 00:18:57.400]   them himself. And I said, actually, I guess you're getting Amazon to do a lot of them. But to get
[00:18:57.400 --> 00:19:01.880]   the international mailing, he says, I will do it if I have to mail it myself. So I said stamps.com.
[00:19:01.880 --> 00:19:09.640]   Stamps.com is for anybody who's doing fulfillment. Or maybe your business sends bills out, invoices,
[00:19:09.640 --> 00:19:15.480]   mailers. If you do mailing and you do it for a business, the last thing you want to do is go
[00:19:15.480 --> 00:19:20.360]   down to the post office to get postage or to mail stuff or have an employee do that. It's just
[00:19:20.360 --> 00:19:26.360]   not effective. Stamps.com maximizes every minute and every dollar for your small business. You don't
[00:19:26.360 --> 00:19:31.960]   even have to leave your desk to do everything. All the mailing stuff you need to do. In fact,
[00:19:31.960 --> 00:19:35.960]   really, it's a perfect synergy with a postal service. Because what does a postal service do best?
[00:19:35.960 --> 00:19:42.600]   They send a person to every single place in the entire country six days a week. And they do
[00:19:42.600 --> 00:19:47.640]   pickup and they do delivery. Let them do that. And you do the printing of the stamps, the printing
[00:19:47.640 --> 00:19:54.760]   of the on the envelopes, printing on the packages, all at a fraction of the cost of expensive postage
[00:19:54.760 --> 00:20:01.160]   meters. Stamps.com saves you time, saves you money. You get discounts. You cannot get it at the post
[00:20:01.160 --> 00:20:06.840]   office. The mail carrier will come to you and pick up that. There's even a button on the stamps.com
[00:20:06.840 --> 00:20:12.120]   site that says have a carrier come out. I missed the pickup. Send another one. It really is convenient.
[00:20:12.120 --> 00:20:15.640]   Now we've got a special no risk trial offer. You probably saw that $80 offer on the front
[00:20:15.640 --> 00:20:20.680]   page. Don't take that. Click the radio microphone in the upper right hand corner. Enter our offer
[00:20:20.680 --> 00:20:27.080]   code Twit and we TWIT and we will give you a $110 bonus offer. You get a free USB scale
[00:20:27.080 --> 00:20:33.160]   that lets you just plop the letter package on there and always have exactly the right postage.
[00:20:33.160 --> 00:20:40.760]   You get a $5 supply kit that kind of makes up for the shipping and handling on the USB scale.
[00:20:40.760 --> 00:20:45.320]   You get a $55 in free postage. That's a good deal. Plus a month of stamps.com.
[00:20:45.320 --> 00:20:49.640]   I mean, really, this is a no risk trial. There's no reason not to do it. And by the way, you can't
[00:20:49.640 --> 00:20:54.760]   cancel anytime. This scales yours to keep. Stamps.com before you do anything else. Click the
[00:20:54.760 --> 00:21:01.640]   microphone at the top of the homepage. Type in TWIT. That's stamps.com offer code TWIT. We love it.
[00:21:01.640 --> 00:21:07.960]   This week in tech, the pre-CES edition, I'm going down there tomorrow for the new media
[00:21:07.960 --> 00:21:12.200]   expo and I'm going to get out before CES. But I thought what I would do is I would be, you know,
[00:21:12.200 --> 00:21:17.080]   everybody has to do this. Somebody has to do this every year. I'm going to be patient zero.
[00:21:17.080 --> 00:21:19.800]   Bring the cold to CES that everybody can have it when they come back.
[00:21:19.800 --> 00:21:23.160]   Usually get sick afterwards. I thought I get sick beforehand.
[00:21:23.160 --> 00:21:29.880]   He's going to own it. I like it. I'm going to own it. I guess I should wear masks and stuff like
[00:21:29.880 --> 00:21:36.040]   that. I'll tell you what, you know, I did this, this TV special in Indonesia a couple of years
[00:21:36.040 --> 00:21:40.840]   ago and I was amazed at like when you go to the fashion boutiques at the mall, they have like
[00:21:40.840 --> 00:21:46.520]   fashionable masks and I don't know if it was to keep the pollution out or your disease in or what.
[00:21:46.520 --> 00:21:52.520]   But apparently America is really lagging on the adorable teddy bear disease masks.
[00:21:52.520 --> 00:21:57.800]   I thought that somebody told me that it was to keep the disease from emerging from you. It's not
[00:21:57.800 --> 00:22:01.720]   to protect yourself. It's if you're sick, you wear them. It's considered an aging cut.
[00:22:01.720 --> 00:22:06.600]   Yes, please. You go Leo, you should wear not a mask, but you should wear one of those cones
[00:22:06.600 --> 00:22:12.440]   like Knuter Dog wear. You can eject it. That way nobody can kiss me. Oh, I get it.
[00:22:12.440 --> 00:22:18.120]   Like an amplification union. Yeah. Yeah. Then people stay away. Your life is total silence in
[00:22:18.120 --> 00:22:24.360]   front of you. I wonder if I could get is it too late to get a Bane mask? You all go see yes,
[00:22:24.360 --> 00:22:30.840]   it moves me. Just walk around. I would love it. I mean, how much would you love to go under the
[00:22:30.840 --> 00:22:35.800]   knife and the doctors wearing a Bane mask? Oh, God, I'll be scary. I'm just keeping my diseases in.
[00:22:35.800 --> 00:22:44.280]   Brian. Terrifying. So Trey Radcliffe, I know cameras, there are other events that cameras get
[00:22:44.280 --> 00:22:50.280]   shown, but it doesn't seem to be that Nikon, Canon, Sony, Cassio, Pentax, they all go to CES.
[00:22:50.280 --> 00:22:55.560]   Do you expect any camera action? Well, these guys, they always announced stuff ahead of time,
[00:22:55.560 --> 00:23:02.920]   usually not at CES. But for years, I've been lambasted for getting on this sort of mirrorless
[00:23:02.920 --> 00:23:11.320]   bandwagon. And yeah, I've been a convert from Nikon to, as I say here, Nikon to Sony for about
[00:23:11.320 --> 00:23:15.240]   the last two years. And now that they came out with this new mirrorless camera, you love that,
[00:23:15.240 --> 00:23:22.600]   don't you? Super exciting. Yeah. Samsung will show a successor to its Galaxy camera.
[00:23:22.600 --> 00:23:28.840]   So it's like a Galaxy S4 glommed onto a camera, reportedly with better imaging.
[00:23:29.800 --> 00:23:34.280]   I think this is a big trend is computational photography. Yeah. Yeah.
[00:23:34.280 --> 00:23:37.960]   I walk me through this because I'm so much stuff happened to software now. Right.
[00:23:37.960 --> 00:23:42.520]   So walk me through this because I hear, I hear talk about, you know,
[00:23:42.520 --> 00:23:47.480]   a digital enhancement where they're able to take less information, but enhance it up to a higher
[00:23:47.480 --> 00:23:53.240]   resolution like pretend I'm an idiot magician who eats fire before living and describe to me
[00:23:53.240 --> 00:23:57.640]   why I should be excited about this. Okay, I'm putting myself into that mind space.
[00:23:58.280 --> 00:24:06.600]   So, let's take a step back here. I've got, I've got some visual aids here. This is a,
[00:24:06.600 --> 00:24:12.040]   let's set the framework of the conversation. Okay. This is a, look at that, lovely thing.
[00:24:12.040 --> 00:24:17.480]   This is a big old DSLR Nikon. Okay. This is what I shot with for years and years.
[00:24:17.480 --> 00:24:22.520]   And it weighs not sponsored by Sony or anything. No, nobody sponsored this. This thing weighs
[00:24:22.520 --> 00:24:26.920]   like five pounds. I mean, it's really heavy. Oh, no, it's huge. Look, I've got this huge
[00:24:26.920 --> 00:24:31.160]   like leather horse bridle attached to it. It's so happy. So I can carry the thing around. It's
[00:24:31.160 --> 00:24:37.800]   ridiculous. Okay. So let's compare this to the new Sony a7R, this mirrorless camera. Wow,
[00:24:37.800 --> 00:24:45.000]   look at the size difference. Wow. Now they're both full frame sensors. This one is 36 megapixel
[00:24:45.000 --> 00:24:51.080]   full frame sensor. So as opposed to that camera, you just mentioned the small Samsung, those are
[00:24:51.080 --> 00:24:56.760]   very tiny sensors, very, very tiny. And the importance of having a big sensor is low light or like
[00:24:56.760 --> 00:25:02.840]   dark photography, which you can argue is most of your photography 50, 60, 70% of your shots are
[00:25:02.840 --> 00:25:08.200]   probably taken like indoors or low light. So having a nice big sensors, super important. So
[00:25:08.200 --> 00:25:14.040]   not only is the camera smaller, but the lenses are smaller. And like you mentioned with computational
[00:25:14.040 --> 00:25:20.280]   photography, there's so many smarts now inside of this camera with the optical viewfinder and the
[00:25:20.280 --> 00:25:24.760]   amount of stuff that can figure out like not only has, you know, face detection spent around
[00:25:24.760 --> 00:25:28.680]   forever, right? We see a little square on the face, but they've taken the next step with this and now
[00:25:28.680 --> 00:25:34.760]   it has eye detection. And so you know this, since you're a photographer to Leo that when you want
[00:25:34.760 --> 00:25:39.560]   to take a photo of somebody's face and they're kind of turned to the side, if you can focus on
[00:25:39.560 --> 00:25:43.960]   something, get some shallow depth of field action, you want to, you want to focus on their closest
[00:25:43.960 --> 00:25:50.120]   eye. So the idea that this can just computationally figure out where their closest eye is and autofocus
[00:25:50.120 --> 00:25:55.160]   right there. I mean, that's kind of a game changer. But does a pro like you eschew that kind of thing?
[00:25:55.160 --> 00:26:00.600]   I mean, don't you say, Hey, I'm a professional, I know where the closest eye is. Do you really
[00:26:00.600 --> 00:26:06.280]   use that? I mean, don't you just do that? I mean, I understand for grandma, that's great. But really,
[00:26:06.280 --> 00:26:13.480]   you need that? No, no, I think I think any pro like quote pro that issues technology just because
[00:26:13.480 --> 00:26:17.880]   they'd like to be old school and manual. I don't think that's very open minded. And you do see
[00:26:17.880 --> 00:26:23.320]   that attitude from a lot of photographers, sadly. Yeah, but the tech, the reason that you're paying,
[00:26:23.320 --> 00:26:27.560]   you know, a couple thousand dollars for this is not so that you can operate it like an old
[00:26:27.560 --> 00:26:31.880]   reflex camera with flash powder. It's so that you can, you're buying a computer. So you might as
[00:26:31.880 --> 00:26:36.200]   well use the computer to do the work for you. And if it can help you autofocus better and help you
[00:26:36.200 --> 00:26:40.760]   get faster photos that are smarter, why, why would you turn that off? Right.
[00:26:41.960 --> 00:26:48.360]   So and of course, Trey, Trey has made a name for himself with making these gorgeous HDR
[00:26:48.360 --> 00:26:54.440]   photography, where it's very technical taking a high exposure, low exposure image and combine
[00:26:54.440 --> 00:27:00.280]   them together. And I got to wonder like, how much of what you're seeing now in cameras right now,
[00:27:00.280 --> 00:27:06.120]   Trey, is just a repeat of what we've already seen for still photography being done in video
[00:27:06.120 --> 00:27:12.280]   format instead. Like I, every time I see like video, I get annoyed because like the background's
[00:27:12.280 --> 00:27:17.160]   blown out or the foreground or whatever. Like how soon until we have HDR video, are you keeping tabs
[00:27:17.160 --> 00:27:25.160]   on that? Well, you know, no one can do a grad filter like top gear, right? Because you know,
[00:27:25.160 --> 00:27:28.360]   when you're watching top gear, you're just gonna have this heavy grad, they've got to actually put a
[00:27:28.360 --> 00:27:35.000]   physical graduated filter on top of the lens to keep that sky from being blown out. But
[00:27:35.000 --> 00:27:39.240]   the sensors are getting really good now. And you can do a lot of HDR stuff in camera,
[00:27:39.240 --> 00:27:45.720]   it can decrease the background of the these blown at areas. I know the new Epic Red has HDR,
[00:27:45.720 --> 00:27:52.600]   can shoot like 11 stops at once. So that's so I've seen there, I've seen rigs that do HDR by having
[00:27:52.600 --> 00:27:58.120]   multiple cameras shooting the same scene, you have to use mirrors, and then there's some sort of
[00:27:58.120 --> 00:28:04.520]   post processing. But you're saying that this can be done in with one camera, computationally,
[00:28:04.520 --> 00:28:08.200]   or where the sensor that has a huge dynamic range, something like that.
[00:28:08.200 --> 00:28:13.800]   Well, let's keep in mind that HDR video is a totally different beast. It's not because not
[00:28:13.800 --> 00:28:21.560]   everything looks good HDR, right? If you look at the way the human eye analyzes the world, okay,
[00:28:21.560 --> 00:28:26.520]   we actually use HDR on parts of the world where we actually care about the texture and the dynamic
[00:28:26.520 --> 00:28:30.920]   light. But there's other areas where we don't look at all the texture line. For example,
[00:28:30.920 --> 00:28:35.800]   like when you look at somebody's skin, like if you look at Brian Brushwood's disheveled,
[00:28:35.800 --> 00:28:42.520]   they got me there. You can see that. You actually don't look that closely at all the little physical
[00:28:42.520 --> 00:28:47.320]   flaws on people's faces because your eye just kind of glances over you look at people's eyes and
[00:28:47.320 --> 00:28:51.160]   maybe a few other features, but you don't look at all the micro texture everywhere else.
[00:28:51.160 --> 00:28:55.400]   But like that chair you're sitting in Leo, people are looking at the leather texture
[00:28:55.400 --> 00:28:58.440]   back there, looking at all the colors and the lights, they really look at this stuff.
[00:28:58.440 --> 00:29:01.720]   So, your sentiment, this is interesting. You're saying the flaws.
[00:29:01.720 --> 00:29:05.080]   It's looking at HDR. The flaws in the over-tanned skin of my face,
[00:29:05.080 --> 00:29:09.560]   they overlook those because they're looking at my eyes or whatever because that's how we're
[00:29:09.560 --> 00:29:13.960]   biologically wired. But when they're looking at something inanimate, they'll see more flaws.
[00:29:13.960 --> 00:29:20.040]   Yeah, we really appreciate the textures and the colors and the richness and the saturation in
[00:29:20.040 --> 00:29:25.800]   the world. But these software algorithms, they don't know that, right? They treat everything the
[00:29:25.800 --> 00:29:32.280]   same. So, they will go over texturize human skin, for example, or another good example,
[00:29:32.280 --> 00:29:36.680]   like a big problem with HDR. I don't want to go down this rabbit hole. I won't. But sometimes
[00:29:36.680 --> 00:29:42.760]   you see this like a nice blue sky and you'll see like a halo around the object and then blue sky.
[00:29:42.760 --> 00:29:46.520]   That's because people treat a blue sky just like human skin in that you just kind of like
[00:29:46.520 --> 00:29:51.560]   categorize it as like blue sky. But the algorithm will go there and try to find all the little
[00:29:51.560 --> 00:29:57.400]   micro differences between the neighboring textures. What about something like LITRO? I mean, somebody
[00:29:57.400 --> 00:30:03.240]   in the chat room says, "Why is LITRO making these cube cameras? Why aren't they licensing this
[00:30:03.240 --> 00:30:09.720]   ray technology to others?" The idea of the LITRO camera was one image, multiple focal points in that
[00:30:09.720 --> 00:30:16.440]   image. Well, I hope a Sony or an icon buys that technology because the idea that that sensor can
[00:30:16.440 --> 00:30:21.240]   capture some 3D depth, right? They can get the angle of the light coming in and then they can
[00:30:21.240 --> 00:30:26.120]   extrapolate the 3Dness or the Z depth of the image. That's pretty cool technology.
[00:30:26.120 --> 00:30:31.480]   That little LITRO camera, I don't think it's really hinting at quite yet. But let's hope that
[00:30:31.480 --> 00:30:36.280]   someone big acquires them. It might be Nikon's only chance. I think if Nikon and Canon don't get
[00:30:36.280 --> 00:30:40.280]   with it, that their camera divisions are going to like slowly dissolve them in the next four or
[00:30:40.280 --> 00:30:44.840]   five years and people they're doing interesting computational stuff like Sony and Samsung and
[00:30:44.840 --> 00:30:49.640]   others, they're going to rise to the top while these old school guys just kind of fall apart
[00:30:49.640 --> 00:30:55.400]   under the weight of their own grandfather's system. Are they focused? The companies like Nikon or
[00:30:55.400 --> 00:31:01.960]   Nikon and Canon focus on glass, is that really? I mean, that's how they've made their name like
[00:31:01.960 --> 00:31:08.200]   the Zeiss and it's great lenses. But a company like Samsung or Sony, I mean, yes, Sony owns,
[00:31:08.200 --> 00:31:14.280]   I guess Sony owns a Zeiss name, but they can focus more on, they're more known for computational
[00:31:14.280 --> 00:31:19.160]   photography. Well, there's no doubt that those cameras have good glass and that might be kind
[00:31:19.160 --> 00:31:23.880]   of their last bastion. But remember, a lot of that big heavy glass like this one, for example,
[00:31:23.880 --> 00:31:31.080]   it's heavy. It's big. This is a big DSLR, wide angle lens. This is like 16 to 35.
[00:31:31.080 --> 00:31:38.280]   And so if you compare it to this little one, this is 11 to 18, well, they both go to a full-frame
[00:31:38.280 --> 00:31:44.520]   sensor with no problem. The reason this one is so giant is because of the just the distance
[00:31:44.520 --> 00:31:50.520]   that the optics have to travel. So great like it lenses, you know, like they're a great company.
[00:31:50.520 --> 00:31:55.960]   They make super tiny lenses even smaller than this, which I find on a 35 millimeter full-frame
[00:31:55.960 --> 00:31:59.880]   sensor. That's that a7 aren't really, some have said is really just a body for like a lens is,
[00:31:59.880 --> 00:32:05.160]   you get the like a converter and now you've got something. Oh, I have a whole review on this on my
[00:32:05.160 --> 00:32:11.400]   website. And I attached about four different like lenses to this and they're super tiny and
[00:32:11.400 --> 00:32:15.640]   they're unbelievable. You know, the like a lenses are a little bit expensive. But if you want to
[00:32:15.640 --> 00:32:20.120]   talk about quality glass, you don't have to get Nikon or Canon lenses. You don't have to set them.
[00:32:20.120 --> 00:32:28.120]   Like a lenses or Zeiss lenses, this you can put any body on any lens nowadays. So you can take
[00:32:28.120 --> 00:32:32.280]   whatever converter you want to, even though this is ridiculous, but you can take all your giant
[00:32:32.280 --> 00:32:36.760]   old Nikon lenses or Canon lenses and put it on this little body, but it's weird. You know,
[00:32:36.760 --> 00:32:41.800]   it's kind of like putting Robert Scubble's head on Chris Proulault's body. That would be weird.
[00:32:41.800 --> 00:32:46.120]   That would be weird. Or hot if you read my slash, Vic.
[00:32:46.120 --> 00:32:55.480]   So you don't expect, do you expect what do you expect for CES in this realm, Trei Wreckle?
[00:32:55.480 --> 00:32:59.560]   Well, I think we'll probably see some cool stuff from Samsung. No big announcements from
[00:32:59.560 --> 00:33:05.960]   the big guys though. As far as the Sony camera goes, they've got their lineup of lenses coming
[00:33:05.960 --> 00:33:11.800]   out of the next few months and years. So that's that roadmap is done. I don't expect any surprises.
[00:33:11.800 --> 00:33:16.680]   Actually, I don't expect any surprises from people even outside of the camera world. I would
[00:33:16.680 --> 00:33:20.760]   like to get some surprises like in the older days. But isn't that always the way with CES?
[00:33:20.760 --> 00:33:25.480]   Is nobody expects surprises? And then when CES is over, everyone agrees that nobody was
[00:33:25.480 --> 00:33:30.760]   surprised. And then four months later, the big news is about that one thing that nobody really
[00:33:30.760 --> 00:33:36.520]   noticed this at CES. And now it's a big story. I mean, that's I don't know. I feel like it's
[00:33:36.520 --> 00:33:40.680]   kind of a suckers game to try to pick winners in that environment full stop.
[00:33:40.680 --> 00:33:47.400]   This will be a CES of TVs. There'll be a lot more 4K TVs, even though there's no 4K content
[00:33:47.400 --> 00:33:51.400]   you could put on these TVs. The prices it's interesting for 4K TVs are very low.
[00:33:51.400 --> 00:33:52.920]   Yeah. Okay.
[00:33:52.920 --> 00:33:54.040]   For HD screens.
[00:33:54.040 --> 00:34:00.520]   I'll tell you what, I actually legitimately hate the talk about 4K program. And keep in mind,
[00:34:00.520 --> 00:34:04.760]   when you go to the movie theater, oftentimes, even if they have a 4K projector, oftentimes,
[00:34:04.760 --> 00:34:09.320]   they're only projecting in 2K, which means slightly better than 1080p. And this is the movie
[00:34:09.320 --> 00:34:13.720]   theater that you're going to. And in fact, it's like I can't stop trying to identify individual
[00:34:13.720 --> 00:34:19.240]   pixels whenever there's something that might slightly alias on there. However, I am huge,
[00:34:19.240 --> 00:34:25.800]   huge, huge bullish on 4K displays in the home, not for watching television, not for watching content,
[00:34:25.800 --> 00:34:32.600]   even though you have stories like Netflix is promising their ultra super mega turbo EX HD or
[00:34:32.600 --> 00:34:36.440]   whatever. The reason I'm excited about it is because, and I've said this before,
[00:34:36.440 --> 00:34:42.920]   I am currently looking at five displays in front of me right now. And it's not because
[00:34:42.920 --> 00:34:47.400]   I just love multiple monitors. It's because there's so much content that I need to have in front of
[00:34:47.400 --> 00:34:54.040]   me in the studio. And there's not enough space on all these monitors. I love the idea of 4K
[00:34:54.040 --> 00:34:59.240]   displays as giant video walls for doing your computing, for playing your video games,
[00:34:59.240 --> 00:35:05.160]   for creating content and just getting breathing room in your desk space. And in fact, there was one
[00:35:05.160 --> 00:35:09.640]   4K display that was only like $500 over the holiday for like Black Friday or whatever.
[00:35:09.640 --> 00:35:14.920]   And I almost pulled the trigger on it until I heard about some minor ghosting issues and difficulty
[00:35:14.920 --> 00:35:21.480]   getting it arranged just so. But like, am I the only one who hates the idea of 4K video
[00:35:21.480 --> 00:35:25.240]   for content but loves the idea of 4K displays for a computer?
[00:35:25.240 --> 00:35:30.920]   I don't know. I mean, I've seen stuff in 4K and it's pretty dramatic. Last year or the year before,
[00:35:30.920 --> 00:35:36.680]   I think it was at NAB. There was a 4K theater who was doing it. It might have been,
[00:35:36.680 --> 00:35:42.120]   might have been a red. Unbelievable. I mean, and it's not about pours and hairs.
[00:35:42.120 --> 00:35:44.920]   It's just about the feeling of reality that you're looking at.
[00:35:44.920 --> 00:35:48.440]   And well, thank goodness we're talking about 4K TV and not 3D TV.
[00:35:49.000 --> 00:35:52.920]   Yeah. Well, I think that's what I'm saying. I think that this is all market driven.
[00:35:52.920 --> 00:35:58.520]   What we've seen, in fact, it's why Sony and Sharp and the Japanese manufacturers are really
[00:35:58.520 --> 00:36:03.720]   struggling is because nobody's buying new HD TVs. They all, we've all got them.
[00:36:03.720 --> 00:36:07.000]   And so they came up with 3D. They came up with 3D.
[00:36:07.000 --> 00:36:12.440]   What would have been the 4K TVs is people might put them on their walls and share their family
[00:36:12.440 --> 00:36:17.080]   photos on there. I think this might be one of these background things that happen. We'd do it
[00:36:17.080 --> 00:36:21.960]   with Apple TV or Google TV or whatever. It's just nice to have family photos appearing in
[00:36:21.960 --> 00:36:27.400]   super high res up there all the time. I wish, has Apple announced anything about making a 4K
[00:36:27.400 --> 00:36:31.240]   monitor? No. No. No. I'd like to buy one. No. So in fact, that's an interesting thing because,
[00:36:31.240 --> 00:36:35.560]   of course, Apple's Mac Pro is now shipping, although for most people, I'm going to have one on Tuesday,
[00:36:35.560 --> 00:36:40.120]   by the way, thanks to Ed, one of our listeners who bought one and said, "Ah, I don't really want it."
[00:36:40.120 --> 00:36:45.880]   He said, "They already shipped it. You want it?" And I said, "Yeah." So we'll, "Yeah." But Apple on its
[00:36:45.880 --> 00:36:51.400]   store is not, there is no 4K display. They talk a lot with the Mac Pro about 4K because the, you know,
[00:36:51.400 --> 00:36:56.200]   TV and movie industry needs a 4K workflow and they need a machine fast enough to handle this
[00:36:56.200 --> 00:37:00.840]   super high resolution video. They're selling, I think, a sharp 4K display on the Apple site.
[00:37:00.840 --> 00:37:06.280]   No word whether Apple will do a 4K cinema display. I think they want to. I think they'd like to.
[00:37:06.280 --> 00:37:09.080]   And you're right. That's very different from a 4K television set.
[00:37:10.520 --> 00:37:16.120]   So I agree with you, Brian. 4K, you know, that 4K or more on the desktop would be awesome.
[00:37:16.120 --> 00:37:22.120]   Well, and keep in mind also, it's like we're seeing in so many ways an exact repeat of what we
[00:37:22.120 --> 00:37:26.360]   saw. And I guess this is what annoys me is we're seeing a repeat with diminishing returns.
[00:37:26.360 --> 00:37:30.120]   Everything that's happening right now on the content side of things is a repeat of what we
[00:37:30.120 --> 00:37:37.320]   saw with high definition. House of Cards was shot in 4K even though it was released at 1080p or whatever.
[00:37:37.880 --> 00:37:41.880]   And this is what we saw on the screen. The next one apparently, season two is supposedly going to be
[00:37:41.880 --> 00:37:48.120]   4K. Right. Right. Well, yeah. And of course, they, and I believe the original was shot in 4K.
[00:37:48.120 --> 00:37:52.760]   Yeah, they'll be releasing it as well. It's just sort of like this preventative thing where it's
[00:37:52.760 --> 00:37:58.920]   like there's a few shows where it's kind of embarrassing that the shows started before HD.
[00:37:58.920 --> 00:38:03.160]   And you're like, well, you should have shot in HD and then released in 4x3 or whatever.
[00:38:03.160 --> 00:38:07.800]   So it's like we're seeing that again. But again, it's not the content. It's just the display.
[00:38:07.800 --> 00:38:13.480]   I just, it kills me that I'm looking at five stupid monitors right now when one video wall
[00:38:13.480 --> 00:38:18.600]   would do the job just as well. Be patient. Have you guys seen any 4K content? Does it feel like,
[00:38:18.600 --> 00:38:23.160]   because you know, I see this a lot with super high depth displays that even a very well shot
[00:38:23.160 --> 00:38:28.360]   thing just feels like a Mexican soap opera. It's very realistic. Yeah. And people complain about
[00:38:28.360 --> 00:38:32.760]   high frame rate, the same thing that I frame. The hobbit, which is shot down by you. I know you
[00:38:33.080 --> 00:38:38.920]   you're posting pictures of Hobbiton from time to time was shot in 48 frames per second instead
[00:38:38.920 --> 00:38:44.120]   of the traditional cinematic 24 frames per second. And a lot of people complained last at the last
[00:38:44.120 --> 00:38:49.240]   Hobbit, somebody somebody said, it looks like Gandalf got his staff at Staffs are us and it's
[00:38:49.240 --> 00:38:53.000]   you know, just too real. It's too real. And you can see how plastic it is.
[00:38:53.000 --> 00:38:57.880]   I guess. And that's a good way to put it, Leo, is that it is too real. And that's one of the
[00:38:57.880 --> 00:39:02.760]   weird things like the high frame rate debate. And I'm somebody who hates it. I, you know,
[00:39:02.760 --> 00:39:05.560]   I bought a Samsung TV that interpolated enough. But that's fake.
[00:39:05.560 --> 00:39:13.320]   That's a good regard. Right. But regardless, it just makes it here. Here's where it works very
[00:39:13.320 --> 00:39:18.680]   well for sports, because you do feel like you're seeing a window into another experience where
[00:39:18.680 --> 00:39:25.080]   everything is exactly the way you expect. It works very poorly in dramatic situations,
[00:39:25.080 --> 00:39:29.400]   because I remember I remember the first thing I did was put on a cool hand Luke. And I'm like,
[00:39:29.400 --> 00:39:37.560]   is this three a holes on a porch? You can really see that it's not real. Yes. Yeah, exactly.
[00:39:37.560 --> 00:39:43.640]   I think that we're actually we're entering the uncanny valley of video. And until it gets a lot
[00:39:43.640 --> 00:39:48.760]   more interesting, you know, like the other kind of uncanny valley, we're just going to just reject
[00:39:48.760 --> 00:39:54.760]   it. Our human sense will reject this is not quite real enough. Where there's you're just in this
[00:39:54.760 --> 00:39:59.880]   hinterland where it doesn't feel right. That is really interesting. So you're,
[00:39:59.880 --> 00:40:06.600]   I think you're absolutely right. The uncanny valley is something they talk about in in 3D graphics.
[00:40:06.600 --> 00:40:10.840]   You know, you watch Toy Story. And one of the reasons they make it of cartoon characters and
[00:40:10.840 --> 00:40:15.080]   toys is because if it's when it's real people, it looks kind of creepy because it's close enough
[00:40:15.080 --> 00:40:19.960]   that our bodies go, ooh, there's something wrong with that. And you're saying that as video quality
[00:40:19.960 --> 00:40:25.800]   or gets better and better and better, it right now, we know it's fake and we can live with that.
[00:40:25.800 --> 00:40:29.400]   But if it starts to look almost real, but not quite real, that's more disturbing.
[00:40:29.400 --> 00:40:34.280]   Yeah, suddenly we're buying all these TVs and make everything look like the polar express.
[00:40:34.280 --> 00:40:40.200]   There was an uncanny valley movie. Yeah. So here's my question I want to put to you guys.
[00:40:40.200 --> 00:40:45.320]   If I could play it, doubles have to kid. I'm going to suggest and I've and some other smarter
[00:40:45.320 --> 00:40:50.040]   people I've written articles to this effect that the backlash against 48 frames per second or
[00:40:50.040 --> 00:40:57.480]   our high frame rate might not be so much an artifact of it being a bad idea so much as us as a society
[00:40:57.480 --> 00:41:03.640]   having been trained to in the gaps of 24 frames per second project these larger than life images
[00:41:03.640 --> 00:41:08.680]   or whatever. But meanwhile, we've got this whole generation of kids who are coming in
[00:41:08.680 --> 00:41:14.840]   that don't have those preconceived notions. Kids who are playing to them, you know, call of duty
[00:41:14.840 --> 00:41:21.400]   in these high resolution video games that are running at 60 frames per second, 90, 120 frames
[00:41:21.400 --> 00:41:30.280]   per second to them. There's no stigma that as Trey put it, the Mexican soap opera stigma.
[00:41:30.280 --> 00:41:35.240]   It doesn't feel like anything associated with something bad. Could it be that five,
[00:41:35.240 --> 00:41:41.480]   10 years from now, it'll just be an old man thing that we wish for the good old 15 frames
[00:41:41.480 --> 00:41:45.400]   per second hand cranked look bad news for me. It's already an old man thing.
[00:41:45.400 --> 00:41:47.800]   Get off of my lawn, you four K.
[00:41:47.800 --> 00:41:52.920]   Now, I don't think you're right, Brian. I don't think it's it's like that law. I don't think that
[00:41:52.920 --> 00:41:57.320]   it's we're too old because the human brain is incredibly plastic. You know, we're actually really
[00:41:57.320 --> 00:42:01.160]   good implications of that because we we adopt all this new technology where early adopters,
[00:42:01.160 --> 00:42:05.640]   our brain will bend around like remember, you know, 10 years ago, we used to have like one tab on
[00:42:05.640 --> 00:42:10.040]   our browser. Now we have 30 tabs and our brains can handle it. We're super plastic in the way we
[00:42:10.040 --> 00:42:15.800]   think about things. But there is something that is inherently inhuman and unnatural about this
[00:42:15.800 --> 00:42:21.720]   uncanny valley of video. And there's some things that you never expect to work, but they actually do.
[00:42:21.720 --> 00:42:27.320]   I read this book by Walter Murch about editing. And he was one of the, you know, he's one of all
[00:42:27.320 --> 00:42:31.640]   these Academy Awards for editing video. And he was talking about the olden days of editing video,
[00:42:31.640 --> 00:42:36.520]   you know, in the beginning, they would just do one cut the entire time where there would just be
[00:42:36.520 --> 00:42:40.840]   one thing. And then they started making multiple angles. And they said when they first started
[00:42:40.840 --> 00:42:45.560]   editing, vote a video and showing different scenes, how it would jump outside, they would do a
[00:42:45.560 --> 00:42:50.520]   close up of the face and it would back up. They had no idea if audiences would actually understand
[00:42:50.520 --> 00:42:55.000]   that this is the same story is this one sort of contiguous story that's happening. Well,
[00:42:55.000 --> 00:43:00.120]   it turns out that the human brain did totally accept that. And now when we watch fast cuts and
[00:43:00.120 --> 00:43:05.560]   edits, the brain has no trouble understanding that. When it comes to the video fidelity,
[00:43:05.560 --> 00:43:11.800]   messing with what we know of as a realistic interaction between humans or organic things,
[00:43:11.800 --> 00:43:15.160]   if it doesn't hit that realism, then our brain just rejects it.
[00:43:15.160 --> 00:43:17.080]   Well, you didn't, I'd take it. You don't like 3D.
[00:43:17.080 --> 00:43:21.240]   Well, 3D doesn't work for me. But.
[00:43:21.240 --> 00:43:25.640]   Well, I don't like 3D. And I think one of the complaints, and it's not, it's not from Walter
[00:43:25.640 --> 00:43:32.840]   Murch, but another long time film guy, maybe it was Walter Murch come to think of it pointed out
[00:43:32.840 --> 00:43:38.840]   that the issue has to do with the very unreal focal length of you're looking at something at
[00:43:38.840 --> 00:43:43.560]   one distance and focusing in another distance. The brain is not so plastic that they can say,
[00:43:43.560 --> 00:43:48.920]   oh yeah, that's fine. I mean, we are tuned to know how far away things are. And this
[00:43:48.920 --> 00:43:53.000]   very disconcerting that you've, you, if you've, you only have one eye.
[00:43:53.000 --> 00:43:57.000]   Yeah. Yeah. I think we have, we have pretty much the same process.
[00:43:57.000 --> 00:43:59.400]   I only see one eye at the time myself, but.
[00:43:59.400 --> 00:44:06.680]   You know, film and TV, these are artistic creations. And the cinematographer has framed things in a
[00:44:06.680 --> 00:44:11.800]   certain way to tell a story, put some things in focus, some things out of focus, because you're
[00:44:11.800 --> 00:44:16.120]   entering storytelling mode. You don't want to have this interactive thing where you are choosing
[00:44:16.120 --> 00:44:22.120]   what to focus on. You are just sitting there consuming information and you're just living in
[00:44:22.120 --> 00:44:25.880]   the story. You're living in someone else's story. And so you don't want to be like an active part
[00:44:25.880 --> 00:44:29.160]   of that, because that just puts you in a totally different role.
[00:44:29.160 --> 00:44:35.880]   Interesting. I disagree. I think that there is a place for 3D. I think that cinematic 3D has
[00:44:35.880 --> 00:44:41.560]   come a long way. I think 3D and the television at home was a ridiculous idea from an industry
[00:44:41.560 --> 00:44:47.480]   that was hungry just to have a new big thing to promote. And they made a bad bet by betting on
[00:44:47.480 --> 00:44:51.720]   technology that was already a decade old and it failed to go anywhere. And I think that we're
[00:44:51.720 --> 00:44:56.200]   seeing that finally they're like, okay, well, the one move we know that will work will be to up the
[00:44:56.200 --> 00:45:01.720]   resolution going to 4K. Having said all that, there are a few, there's a reason that we go to
[00:45:01.720 --> 00:45:08.200]   movie theaters. And that is to get a novel experience. And 3D can be part of a very delightful,
[00:45:08.200 --> 00:45:14.040]   very powerful novel experience. I think that watching Avatar from James Cameron in 3D was a
[00:45:14.040 --> 00:45:17.640]   very good experience for me. I think it was the right way to shoot it. I think it was the right way
[00:45:17.640 --> 00:45:21.400]   to tell that story. Don't you think that you're more aware of the 3D that it takes you out of the
[00:45:21.400 --> 00:45:25.320]   movie a little bit? >> Not with, for example, gravity.
[00:45:25.320 --> 00:45:32.920]   Gravity. Now, keep in mind, a lot of times I'm glad I did not watch The Avengers in 3D because I
[00:45:32.920 --> 00:45:38.360]   got to see the story as it was meant to be. But something like gravity, where the very nature of
[00:45:38.360 --> 00:45:44.040]   the story is otherworldly. The very nature of the story is put yourself in a situation that is
[00:45:44.040 --> 00:45:49.560]   unlike the reality that you live in day to day. I think in that regard, having it in 3D was a big
[00:45:49.560 --> 00:45:54.200]   enhancement. Now, having said all that, I will say that everything that we're seeing at home is
[00:45:54.200 --> 00:45:59.240]   terrible and I don't like any of it. And I hate 3D televisions at home.
[00:45:59.240 --> 00:46:00.200]   >> Really? >> Really?
[00:46:00.200 --> 00:46:05.720]   No, no, no, I think they've done a bad job. Well, because of the technology, it's either either
[00:46:05.720 --> 00:46:10.360]   their number one, anything where you got to put crap on your face isn't going to work in the home.
[00:46:10.360 --> 00:46:17.400]   Or most of them were using the, was it the LCD, flippy lenses?
[00:46:17.400 --> 00:46:20.200]   >> Yeah, it's a flier, you're only seeing half the show. And then you give it time.
[00:46:20.200 --> 00:46:21.720]   >> So, I think all that was a bad idea.
[00:46:21.720 --> 00:46:25.560]   >> One of the things, Scott Wilkinson, we'll cover this in our coverage of CES. One of the things
[00:46:25.560 --> 00:46:32.600]   that's there is true, glass is free 3D. And I'm, I'm pooing it because I don't think it's actually
[00:46:32.600 --> 00:46:38.200]   possible. But we'll see. That would go a long way to eliminating the pain point for me,
[00:46:38.200 --> 00:46:42.600]   which is wearing these dumb glasses. It makes everything half as bright. It's just not as good.
[00:46:43.800 --> 00:46:47.800]   But, and here's the Walter merch. This is Walter merch writing to Roger Ebert
[00:46:47.800 --> 00:46:52.520]   from a couple of years ago. Why 3D doesn't work and never will case closed.
[00:46:52.520 --> 00:46:57.240]   And just the sentence that I was, but- >> By the way, that's a good thesis. Those kind of
[00:46:57.240 --> 00:47:00.680]   statements always go over well and never get mocked down in history.
[00:47:00.680 --> 00:47:05.880]   >> 3D films require us to focus at one distance and converge at the other.
[00:47:05.880 --> 00:47:12.440]   That's the screen distance versus the distance of whatever's on screen. After 600 million years of
[00:47:12.440 --> 00:47:18.120]   evolution has never presented this problem before, all living things with eyes have always focused
[00:47:18.120 --> 00:47:27.000]   and converged at the same point. And so 3D would, it'll work. But it's like tapping your head and
[00:47:27.000 --> 00:47:32.120]   rubbing your stomach. It's difficult. >> Like whatever it is he says, no matter how right he is
[00:47:32.120 --> 00:47:35.960]   technically, all I hear is like technical complaints. >> But you like it.
[00:47:35.960 --> 00:47:39.960]   >> Technical problems. >> But it's like, well, no, no, I love it in principle. And in fact,
[00:47:39.960 --> 00:47:45.080]   I will say that gravity was better by seeing it in 3D and Avatar was certainly better by seeing it
[00:47:45.080 --> 00:47:53.080]   in 3D. So it can be done, but again, how we get there is the question. There's a lot of folks who
[00:47:53.080 --> 00:47:59.560]   they bother to record these movies using two cameras. And then they just throw out one camera
[00:47:59.560 --> 00:48:03.640]   because they decided it's better to digitally enhance it to get the feeling of 3D after the
[00:48:03.640 --> 00:48:08.840]   fact rather than actually use the actual information. >> That's a jokey. Another big story we expect
[00:48:08.840 --> 00:48:14.600]   to see at CES is the car companies. This started a few years ago in Alan Malawi,
[00:48:14.600 --> 00:48:20.760]   keynoteed CES and Ford announced a bunch of consumer electronics features in its cars.
[00:48:20.760 --> 00:48:26.600]   Now Audi, Chrysler, Ford, General Motors, Mercedes and Toyota will all be at CES. It's become,
[00:48:26.600 --> 00:48:30.680]   even though the Detroit Auto Show is roughly the same time, it's become an auto show.
[00:48:30.680 --> 00:48:35.480]   And of course, what we'll see is a lot of telematics stuff. That's the computers
[00:48:36.280 --> 00:48:41.640]   inside the cars. One of the keynote addresses this year will be,
[00:48:41.640 --> 00:48:55.560]   I think GM's CEO, Chairman. Audi is announcing that they are going to use Google androids to power
[00:48:55.560 --> 00:49:03.560]   their in-car computers now instead of QNX. Laser headlights in the Audi Sport Quattro.
[00:49:05.160 --> 00:49:09.320]   >> Okay. What? Okay. I'll bite. What is the laser? >> I don't know. But according to Audi,
[00:49:09.320 --> 00:49:16.120]   passengers, as you ask them with frickin' lasers, they've all previous systems in the dark with
[00:49:16.120 --> 00:49:24.680]   their high performance. We are showing Zifjutrov Audi here. Ford will show the C-MEX solar energy.
[00:49:24.680 --> 00:49:30.760]   Now, there's a concept car, and that's important to say, but this will be a plug-in hybrid that can
[00:49:30.760 --> 00:49:39.320]   charge from the sun. And that would be amazing. >> Yes. Absolutely. And let me ask Dan this.
[00:49:39.320 --> 00:49:43.560]   You're back, right, Dan Patterson? >> Yeah, I think so. My apologies, guys. I think I ran out of
[00:49:43.560 --> 00:49:49.080]   my daily allotment of time on the internet. >> Can I borrow a cup of internet, please?
[00:49:49.080 --> 00:49:54.680]   >> Three gigs a day. >> So, to me, there's only one story that I really care about,
[00:49:54.680 --> 00:49:58.760]   about cars and technology, and that's how soon while they start driving themselves. And to me,
[00:49:58.760 --> 00:50:04.760]   the big question is, there are people who are right now drafting early versions of legislation
[00:50:04.760 --> 00:50:10.760]   to handle what happens when cars drive themselves. And understand, I am very pro cars driving
[00:50:10.760 --> 00:50:14.840]   themselves. I think it frees up the elderly. I think it cancels things like drunk driving,
[00:50:14.840 --> 00:50:21.880]   and even kids who are 12 years old, why not, hop in a car, whatever. But my question to Dan is-
[00:50:21.880 --> 00:50:24.760]   >> That can't wait till that day. >> Oh my god, dude.
[00:50:24.760 --> 00:50:28.360]   >> I'm not hopping the car, kid. >> Hey, kid, go get me a beer.
[00:50:28.360 --> 00:50:33.880]   >> Actually, I didn't even thought that's a good point, Leo.
[00:50:33.880 --> 00:50:42.360]   >> How do you think this is all going to go down? Are we going to see it in stages where we see,
[00:50:42.360 --> 00:50:46.920]   like, drive a cyst, stick around for 10 years? Or is it going to be like all at once, like,
[00:50:46.920 --> 00:50:50.520]   you just have cars that do all the driving? >> No, here's what's going to happen, I think.
[00:50:50.520 --> 00:50:56.200]   >> Yeah, I think- >> I know how in the US, legislation,
[00:50:56.200 --> 00:50:59.560]   lawyers, they just ruin everything. They're going to have a lot of trouble getting it there. But
[00:50:59.560 --> 00:51:04.200]   I think that if Google comes and launches the self-driving cars here in New Zealand,
[00:51:04.200 --> 00:51:09.480]   where they launched the Loon, Bloons, and like, legislation's pretty easy here, and they're just
[00:51:09.480 --> 00:51:15.480]   not so heavy-handed. But the first country to get these kind of self-driving cars, it'll just make
[00:51:15.480 --> 00:51:18.280]   all the other countries so jealous that they'll- >> Yeah.
[00:51:18.280 --> 00:51:22.440]   >> Like, you know how San Francisco prefers everyone. So I think it's going to be a country thing.
[00:51:22.440 --> 00:51:29.560]   >> It'll be kind of similar. In a lot of ways, we can look at what's happening with Colorado and
[00:51:29.560 --> 00:51:35.160]   the marijuana extensions that are occurring and apply that to technology like self-driving cars.
[00:51:35.160 --> 00:51:39.800]   On a federal level, I don't think there's a chance we're going to see this type of legislation
[00:51:39.800 --> 00:51:43.160]   anytime in the next, you know, a bajillion years unless it's tacked on to something.
[00:51:43.160 --> 00:51:47.800]   But on a state level, we will absolutely see places where there is a particular lobby.
[00:51:47.800 --> 00:51:53.640]   So where there is money, companies like Google, we will see them lobby on a state-by-state level.
[00:51:53.640 --> 00:51:58.920]   And then after that, we'll see kind of an avalanche or a tidal wave of change. But I think on a
[00:51:58.920 --> 00:52:05.080]   federal level, we can kind of forget about anything happening at least for the next nine months.
[00:52:05.080 --> 00:52:10.280]   And certainly after the midterms, we may see some legislation, but it's certainly not a high
[00:52:10.280 --> 00:52:14.360]   priority. >> Mashe chooses, and our chat room points out that this is something that the
[00:52:14.360 --> 00:52:19.480]   auto industry themselves may well lobby against because the ultimate goal of self-driving cars is
[00:52:19.480 --> 00:52:24.600]   to end personal, I think this may or may not be true, but to end personal ownership of vehicles.
[00:52:24.600 --> 00:52:29.160]   And certainly a lot of autonomous vehicle proponents have talked about this. If you,
[00:52:29.160 --> 00:52:35.160]   the problem with everybody having a car is you only use it 10% of the time. If we had self-driving
[00:52:35.160 --> 00:52:40.520]   cars, they could come to you, you could drive it, leave it wherever you left it, and you wouldn't
[00:52:40.520 --> 00:52:45.640]   need to own a car. It's kind of the ultimate Uber. >> I mean, that makes sense in theory,
[00:52:45.640 --> 00:52:50.200]   except for the fact that you're talking about like, these are the guys who are going to provide
[00:52:50.200 --> 00:52:54.920]   the new version of cars that everyone on planet Earth needs to buy. I mean, that's
[00:52:54.920 --> 00:52:57.640]   that's why I disagree with this. >> That's a good point.
[00:52:57.640 --> 00:52:59.320]   That's a good point. >> They're going to make money at first.
[00:52:59.320 --> 00:53:05.080]   >> Yeah, and maybe very, very iterative, right? It may be steps like we've seen it
[00:53:05.080 --> 00:53:09.480]   forward. I think what we've seen with Malawi at Ford in the last five years has been very
[00:53:09.480 --> 00:53:14.120]   exciting. But I think incrementally, we will get there a little change by a little change.
[00:53:14.120 --> 00:53:18.520]   >> I'm sure. Heath Allen always said, no, we're not doing autonomous vehicles. And then I
[00:53:18.520 --> 00:53:22.200]   kept saying, come on, Allen, in the back room, no, we believe people want to drive. And then,
[00:53:22.200 --> 00:53:26.360]   of course, yes, in the back room, Ford has autonomous vehicles, just like every other
[00:53:26.360 --> 00:53:29.480]   manufacturer in the world, I'm sure. >> Well, and I'll tell you what, I mean,
[00:53:29.480 --> 00:53:35.480]   think about how much better everything becomes from, first of all, the vast, we're talking orders
[00:53:35.480 --> 00:53:43.560]   of magnitude, of lives being saved because of our stupid dumb flesh handling stuff poorly.
[00:53:43.560 --> 00:53:47.880]   And meanwhile, freeing us up to do stuff that we truly love. We apparently really like
[00:53:47.880 --> 00:53:52.280]   to send text messages while we drive. Guess what? You can send all the text messages you want
[00:53:52.280 --> 00:53:59.160]   in the future. You can be as drunk as you want. I, for one, support a drunk text messaging future,
[00:53:59.160 --> 00:54:03.800]   in which the cars are taking care of us. >> Right on, Mr. Brian Brushwood, right on,
[00:54:03.800 --> 00:54:09.080]   my friend. We're talking about the week's tech news and what to look forward to from CES.
[00:54:09.080 --> 00:54:13.160]   I'm sure there'll be a lot of tech news emerging. Most of it kind of junkie, but maybe there'll be
[00:54:13.160 --> 00:54:17.320]   something of interest. We'll talk more in a bit. Dan Patterson is here from Tanooki Labs.
[00:54:17.320 --> 00:54:24.280]   Good friend of the show and a journalist who is reinventing what journalism means in the digital
[00:54:24.280 --> 00:54:30.840]   era. Brian Brushwood, magician extraordinaire, host of NSFW. And I got to give a plug to the
[00:54:30.840 --> 00:54:34.600]   new show, The Cord Killers. You're doing something interesting. You're doing this,
[00:54:34.600 --> 00:54:40.680]   you and Tom Merida doing this as a crowd funded show. And you've raised a lot of money.
[00:54:40.680 --> 00:54:45.160]   Did he suddenly get quiet? >> He just got back.
[00:54:45.160 --> 00:54:48.120]   >> Oh, he took off? He didn't know I was going to talk to him.
[00:54:48.120 --> 00:54:54.120]   >> No, I, you know what happened was, is I opened the window because it was lovely and cool outside,
[00:54:54.120 --> 00:54:58.360]   and then it became nighttime and cold as hell. So it just fixed. What did I miss?
[00:54:58.360 --> 00:55:01.320]   Oh, I was just giving you a plug. No big deal. We're moving on right now.
[00:55:01.320 --> 00:55:07.720]   I was talking about Patreon and the way that you guys, Tom and you are raising money to do the
[00:55:07.720 --> 00:55:13.080]   show, which I think is very innovative. >> Do you know that Patreon was created by the folks who do
[00:55:13.080 --> 00:55:16.760]   Pomplamoose? Have you ever seen Pomplamoose? >> The band?
[00:55:16.760 --> 00:55:22.040]   >> Yeah, I love that. >> Yeah, Jack Conte is the guy who,
[00:55:22.040 --> 00:55:26.840]   you know, I guess there's a generation of people who are making videos
[00:55:26.840 --> 00:55:30.760]   on YouTube and they're realizing that the YouTube revenues, not that great.
[00:55:30.760 --> 00:55:32.760]   >> Yeah. >> And so they're realizing that to put
[00:55:32.760 --> 00:55:38.360]   the time and effort to do in so many ways, it's like this market equality thing, which I love,
[00:55:38.360 --> 00:55:43.080]   because somewhere out there is somebody who wishes there was a way for them to throw more money in
[00:55:43.080 --> 00:55:50.120]   your face. And Patreon is basically a way for you to decide your own level of involvement on
[00:55:50.120 --> 00:55:56.360]   anything. I think they first reached out to us a while ago. But I think what they're doing is
[00:55:56.360 --> 00:56:03.000]   really interesting and I think people are, in many ways, it's this whole destabilization of
[00:56:03.000 --> 00:56:05.480]   the old media way. You don't get a mediator. >> I agree.
[00:56:05.480 --> 00:56:07.640]   >> Do somebody wants to give you money? Yeah, exactly.
[00:56:07.640 --> 00:56:12.200]   >> Yeah, and really that's what Kickstarter was supposed to be. It ended up being kind of a more
[00:56:12.200 --> 00:56:18.040]   of a product marketplace than kind of a creative support. And this is a little different because
[00:56:18.040 --> 00:56:23.560]   you're subscribing to a show here. You're not merely donating. So in the case of court killers,
[00:56:23.560 --> 00:56:27.800]   when you don't just give them money, you say, I'm going to give a certain amount per episode.
[00:56:27.800 --> 00:56:32.200]   >> Yeah, there's a little bit of a hiccup there because a lot of people,
[00:56:32.200 --> 00:56:37.160]   you look at them, for example, my friends over at Rage Select, they do video game playthroughs.
[00:56:37.160 --> 00:56:41.080]   And I think video game playthroughs are going to benefit a lot from a service like Patreon,
[00:56:41.080 --> 00:56:45.160]   because especially, I don't know if you've heard about this. >> Well, YouTube is hostile to
[00:56:45.160 --> 00:56:48.440]   those for one thing. >> Correct, correct. And specifically,
[00:56:48.440 --> 00:56:53.320]   like what Nintendo will do is when somebody plays a Nintendo game, it does a playthrough
[00:56:53.320 --> 00:56:59.240]   and monetizes it, Nintendo will go in and just take the money. They'll just say, yes, leave it online,
[00:56:59.240 --> 00:57:04.440]   send that check to us because we own everything that's on that. And of course, video games are
[00:57:04.440 --> 00:57:09.880]   this weird synergistic place where it's like, and I guess as you've experienced with the news as well,
[00:57:09.880 --> 00:57:16.040]   it's not just the content, it's also the comment and the character that gets put into it.
[00:57:16.040 --> 00:57:22.600]   And so in the case of Rage Select, they put out like maybe 20 videos a week. And so people will
[00:57:22.600 --> 00:57:30.040]   pledge, we'll say $5 per video or whatever. But since you can set a monthly limit to it,
[00:57:30.040 --> 00:57:34.680]   people are like, whoa, you guys are banking, you're doing $800 a video. And then they're like,
[00:57:34.680 --> 00:57:37.880]   yeah, we get maybe 200 of that because everyone hits their limit.
[00:57:37.880 --> 00:57:40.680]   >> Yeah, they're not the limit in the first two weeks or whatever.
[00:57:40.680 --> 00:57:46.520]   >> So it's not transparent. When I go to Rage Select, I'm seeing that they have 257 patrons,
[00:57:46.520 --> 00:57:52.120]   which in theory is $1,000 per video. But in fact, it could be considerably less.
[00:57:52.120 --> 00:57:57.080]   >> Right. They, from what I've been told and what they've said on the stream is that it ends
[00:57:57.080 --> 00:58:02.040]   up being closer to like $200, $250 an episode, which again, is enough to keep the lights on.
[00:58:02.040 --> 00:58:05.320]   And they're of course very thankful for it. But I wish there was a way that there was more
[00:58:05.320 --> 00:58:11.480]   transparency on Patreon for that kind of thing. >> Yeah. I think it's an innovative and interesting
[00:58:11.480 --> 00:58:17.080]   way of doing something. And I think it's great. And the nice thing is, unlike what we do, where you
[00:58:17.080 --> 00:58:22.440]   really 1,000 people would not be enough to make a show sustainable, at least not financially,
[00:58:22.440 --> 00:58:29.000]   even though it's a good size audience, on Patreon, it could be completely vital.
[00:58:29.000 --> 00:58:36.920]   >> And I guess that's that market efficiency, right? It adds another vector because in the old
[00:58:36.920 --> 00:58:42.680]   old medium of television, only one thing matters, how many eyeballs. And it didn't matter how much
[00:58:42.680 --> 00:58:47.640]   or how little they love the show. What matters is did they tune in on Tuesday at 7 p.m. >> Right.
[00:58:47.640 --> 00:58:53.720]   >> And nowadays we're getting to a place where you can care enough to use a sponsor,
[00:58:53.720 --> 00:58:58.280]   or even care enough to throw money in someone's face directly in whatever amount you want.
[00:58:58.280 --> 00:59:01.800]   >> I think that's one of the secrets to our success with advertising, is that our audience
[00:59:02.760 --> 00:59:06.600]   does realize that supporting a sponsor supports us, so our ads do better.
[00:59:06.600 --> 00:59:09.480]   >> Absolutely. >> Than another thing.
[00:59:09.480 --> 00:59:12.760]   Anyway, Patreon, if you want to know more at patreon.com/chordkillers,
[00:59:12.760 --> 00:59:18.760]   Brian and Tom's new show. And you're doing so far, you're doing great, almost 1,000 patrons.
[00:59:18.760 --> 00:59:21.960]   That's awesome. >> It's of course easy to have that way.
[00:59:21.960 --> 00:59:23.160]   >> Anything ever sale on YouTube?
[00:59:23.160 --> 00:59:28.920]   >> No, I haven't tried selling anything on YouTube. And you would think that,
[00:59:29.880 --> 00:59:35.480]   you know, scam school, of course, we do free magic tutorials. And you would think that would
[00:59:35.480 --> 00:59:41.560]   be a perfect marketplace. But instead, I've created some higher-end, more complicated tutorials,
[00:59:41.560 --> 00:59:49.160]   but we've sold them all through Shopify instead. And it's all DRM-free. But I mean,
[00:59:49.160 --> 00:59:54.760]   what about you? You do tutorials as well. >> Yeah, well, we sell tutorials through
[00:59:54.760 --> 00:59:59.560]   the main website, Stuck in Customs Direct, just like you do DRM-free. But we also have
[00:59:59.560 --> 01:00:04.760]   experimented on YouTube. Because you can make them rental, but we make our rentals forever.
[01:00:04.760 --> 01:00:11.160]   And it works great. Because it's kind of like Apple, once you're in Google Wallet and they
[01:00:11.160 --> 01:00:18.040]   got your credit card information, it's easy for people to just buy more stuff. So it's a pretty
[01:00:18.040 --> 01:00:22.280]   convenient model rather than sending people to a thousand different stores over the internet.
[01:00:22.280 --> 01:00:27.240]   You know, everyone's on YouTube. >> I just feel like YouTube's so hostile to some kinds of,
[01:00:27.240 --> 01:00:31.560]   your content's perfect for YouTube. But our content, they're very hostile to it because of
[01:00:31.560 --> 01:00:37.640]   content ID. >> Well, and what we saw with Rap Genius is that if you are so dependent on one
[01:00:37.640 --> 01:00:43.640]   mechanism of driving traffic, then you are also susceptible to that deciding that we no longer
[01:00:43.640 --> 01:00:48.360]   like your tactics of customer acquisition. And the same thing on YouTube, right? All of the,
[01:00:48.360 --> 01:00:54.200]   unfortunately, some of the great gamers or game streamers that we love to watch over the last,
[01:00:54.200 --> 01:01:00.440]   you know, six weeks have had their YouTube lives kind of rearranged by a seemingly arbitrary
[01:01:00.440 --> 01:01:03.240]   change in policies. So, you know, >> Yeah, I mean, we all,
[01:01:03.240 --> 01:01:08.680]   >> We all, it's great. >> So Rap Genius, which is a really great idea. It's a site for
[01:01:08.680 --> 01:01:17.560]   Rap lyrics, right? But kind of, it's kind of fun. They got banned by Google for
[01:01:17.560 --> 01:01:23.240]   what Google considered SEO, inappropriate SEO tactics. But we're all vulnerable to that,
[01:01:23.240 --> 01:01:26.680]   right? Google wields huge amount of power. Anybody who's on the web,
[01:01:26.680 --> 01:01:30.840]   if Google bans you, if Google removes you or deranks you, you're dead.
[01:01:30.840 --> 01:01:37.000]   Fortunately, Rap Genius said, "Oh, we're sorry." They said what they did wrong,
[01:01:37.000 --> 01:01:42.600]   and they've been brought back after 10 days. But this was, I mean, this could be the end of the
[01:01:42.600 --> 01:01:45.400]   world for them. >> It's sort of the same thing.
[01:01:45.400 --> 01:01:46.680]   >> Things could happen anywhere. >> Right.
[01:01:46.680 --> 01:01:52.840]   >> Yeah. Well, and there's a bit of a chess game happening at any given time, and it used to be
[01:01:52.840 --> 01:01:59.080]   that the chess game of power was those people who were in control and then could shape the message
[01:01:59.080 --> 01:02:06.040]   after the fact. But nowadays, we live in such a free zone of communication where you would think,
[01:02:06.040 --> 01:02:10.680]   if this happened 20 years ago, the story is Google busted them, these guys are out,
[01:02:10.680 --> 01:02:14.920]   and then Google just says whatever they want about them. But we live in a world where Rap Genius
[01:02:14.920 --> 01:02:19.880]   continues to have a microphone and continues after the fact to say, "Yeah, we probably abused
[01:02:19.880 --> 01:02:26.600]   the policy, but here's why it was designed." The system is designed that this is the way you win,
[01:02:26.600 --> 01:02:31.400]   so we tried to do that, and it worked well until now you're throwing us out.
[01:02:31.400 --> 01:02:37.480]   And so now it puts Google in the awkward position of like, okay, well, are we the empire who is like,
[01:02:37.480 --> 01:02:42.200]   no, you're done, you crossed us, and we're going to screw you off forever. And now all of a sudden,
[01:02:42.200 --> 01:02:47.800]   there's a value to Google to be gregarious and bring them back in. I think it's fascinating,
[01:02:47.800 --> 01:02:53.080]   and I think good for everyone in the long term that we live in a world where everyone has a voice,
[01:02:53.080 --> 01:02:57.000]   whether it's discussion. Yeah, the same thing with the gamers on YouTube,
[01:02:57.000 --> 01:03:04.440]   and that's driving discussion and traffic towards alternate forms of distribution as well.
[01:03:04.440 --> 01:03:09.960]   We can see the rise in Twitch in the last couple of weeks and the change in these policies,
[01:03:09.960 --> 01:03:14.760]   right? We're going to take... Twitch is going crazy. I was just looking at Twitch.tv, and right
[01:03:14.760 --> 01:03:21.240]   now that there's over 50,000 people watching Phantom Lord play live, and you can subscribe for
[01:03:21.240 --> 01:03:27.320]   live dollars in these individuals. We missed the boat because you kind of Brian Brushwood invented
[01:03:27.320 --> 01:03:32.280]   this, and I did a little bit of it too. You used to... I remember when Lord's the Old Republic,
[01:03:32.280 --> 01:03:41.160]   was it or Gil came out? You played it online, and your commentary. And when we did, I did that
[01:03:41.160 --> 01:03:47.080]   with Skyrim, and it was huge, and I just should have realized, oh, people want this. We should...
[01:03:47.080 --> 01:03:54.360]   Well, but it's also an emerging shape, right? Because on the one hand, yes, the most interesting
[01:03:54.360 --> 01:03:58.840]   media development in the last 10 years to me has been the fact that it turns out people love to
[01:03:58.840 --> 01:04:03.720]   watch other people play games. But now we're seeing the entanglements that come with it because
[01:04:03.720 --> 01:04:07.640]   if you want to monetize the fact that you're playing this game or whatever, we're seeing this
[01:04:07.640 --> 01:04:12.360]   backlash where it's like, well, I owned this or actually that song was licensed, but not for this
[01:04:12.360 --> 01:04:17.160]   use and so on. So, I mean, it's going to be ugly, which again, to go back to the Patreon thing,
[01:04:17.160 --> 01:04:21.960]   what's great is about that direct support sort of subverts it, so you're not monetizing it,
[01:04:21.960 --> 01:04:26.120]   but instead just sort of directly, hey, man, I'm going to hang out and play this game.
[01:04:26.120 --> 01:04:31.400]   If you think I'm awesome, throw me five dollars. Phantom Lord has a subscription as well, and
[01:04:31.400 --> 01:04:36.920]   there's pre-roll ads. I mean, there's definitely monetization going on in this, but 50,000 people
[01:04:36.920 --> 01:04:42.360]   watching. Wow, that's two pre-roll ads now. I skipped one and I've got the second one.
[01:04:42.360 --> 01:04:48.600]   Let's see if there's a third. Yes, there is three ads that I've had to skip through. Am I going to
[01:04:48.600 --> 01:04:53.320]   have to watch one to the very end? And again, this is, I actually suspect that this is the
[01:04:53.320 --> 01:05:00.520]   pro- oh, gastric bypass surgery. I think this is this is this is an unfortunate place that live
[01:05:00.520 --> 01:05:04.520]   playthroughs are dealing with right now. And I think that is part of the reason you're going to
[01:05:04.520 --> 01:05:07.880]   start to see more direct subscriptions. Hold on. What are you looking at? I'm skipping.
[01:05:07.880 --> 01:05:13.720]   It showed three seconds of Phantom Lord, and then went back to the ads. I guess I have to guess.
[01:05:13.720 --> 01:05:18.120]   I guess you got to get gastric bypass surgery, or you can't watch Phantom Lord.
[01:05:18.120 --> 01:05:27.000]   Maybe he thinks I'm too fat to watch. Huh? She's. I actually suspect that that this is sort of an
[01:05:27.000 --> 01:05:34.120]   indication of some version of this idealized gift economy, you know, where it's like, look,
[01:05:34.120 --> 01:05:38.200]   just don't show me ads. Give me on some service where I can watch you directly and I'll throw
[01:05:38.200 --> 01:05:44.760]   money in your face because people love the content providers enough that they don't feel bad about
[01:05:44.760 --> 01:05:49.480]   doing that. I mean, you've seen that firsthand, Ray Leo. Oh, yeah. Although it was never enough
[01:05:49.480 --> 01:05:56.120]   money to make Twit be as big as it's become. Free, sure. Yeah, people are very generous. And we've
[01:05:56.120 --> 01:06:00.760]   raised, you know, I don't know what, but a lot of money through donations and bricks and so forth.
[01:06:00.760 --> 01:06:06.360]   But ultimately, it's a fraction of what we need to build the network. We had to do advertising.
[01:06:06.360 --> 01:06:12.760]   What is great is to see a thousand models bloom. And there's some models that are appropriate.
[01:06:12.760 --> 01:06:17.960]   I feel like ultimately giving ad supported media is very democratic. Everybody gets it.
[01:06:17.960 --> 01:06:21.480]   And I don't have to worry about holding back. I don't have to say, well, you're, if you're not
[01:06:21.480 --> 01:06:26.200]   a subscriber, you can't see the special content, whatever. I want to get as many places as possible.
[01:06:26.760 --> 01:06:31.960]   And everybody wins. And so that's what I like. It's where I came from. But every there's,
[01:06:31.960 --> 01:06:36.200]   that's great that there's so many models for this. Well, I'm still watching the gastric bypass
[01:06:36.200 --> 01:06:42.360]   surgery. I just, I guess I'm never going to see this. People will die, Leo. Hey,
[01:06:42.360 --> 01:06:49.240]   let's say white thing about gastric bypass surgery ads and that it is at least disclosed and upfront.
[01:06:49.240 --> 01:06:54.440]   It may be disgusting to look at, but it's not, it's not native advertising, right? No, that's true.
[01:06:55.240 --> 01:06:59.560]   If you were watching, if you're watching a game and all of a sudden he had gastric bypass surgery in
[01:06:59.560 --> 01:07:06.440]   the game, product placement, that I don't like vertical. All right, let me do an ad.
[01:07:06.440 --> 01:07:09.960]   Since we're, and this is very clearly, if you see it on blue paper, it's an ad.
[01:07:09.960 --> 01:07:15.240]   Yeah, you want to be on with Brian brushwood Dan Patterson and the great tray racquet. By the way,
[01:07:15.240 --> 01:07:22.280]   here is the graph of the drop in views on raptor, man, from 700,000 unique,
[01:07:22.280 --> 01:07:28.840]   a day to 100,000 from delisting by Google. That's the heavy ban hammer Google wheels.
[01:07:28.840 --> 01:07:33.480]   And what was, what was, I'm sorry to hold us back. Like what was the specific
[01:07:33.480 --> 01:07:39.080]   infraction? It was complicated. Internal linking for the most part, the same tactic that a lot of
[01:07:39.080 --> 01:07:44.520]   publishers use, right? So if I am say, Mashable, who I love, I'm just, I'm not picking on them.
[01:07:44.520 --> 01:07:50.840]   I'm just using it as an example, but Mashable will say, let's say we're writing an article about
[01:07:50.840 --> 01:07:56.040]   the latest in wearable monkey technology. And they have a ton of posts about wearable monkey
[01:07:56.040 --> 01:08:02.440]   technology. So instead of linking to wearable monkey technology.com, they link internally to
[01:08:02.440 --> 01:08:10.520]   Mashable com slash tags slash monkey technology. So it inter it eight that using the anchor text,
[01:08:10.520 --> 01:08:15.720]   the H one tags and the anchor text, the loaded keywords in the front, the first paragraph or two
[01:08:15.720 --> 01:08:22.040]   of the post, they will push you further in and create. Google will see those links attached to
[01:08:22.040 --> 01:08:27.880]   the anchor text attached to high density keywords and say, Oh, this is a relevant result. And you
[01:08:27.880 --> 01:08:33.080]   link to yourself. So you drive more internal traffic and use yourself for Google juice, right? So
[01:08:33.080 --> 01:08:38.200]   they actually use the tactic that is very like you'll see this tactic everywhere. They just were
[01:08:38.200 --> 01:08:43.880]   very clever about it and turned the lyrics of rap songs into URLs, which meant that people searching
[01:08:43.880 --> 01:08:51.640]   for not rap genius, not even Tupac, but the actual lyric in the song will find not just the song
[01:08:51.640 --> 01:08:57.640]   itself, but the explicit lyric that they used. And that will drive them deeper into the site as
[01:08:57.640 --> 01:09:02.040]   opposed to bouncing off the site. So it lowers, lowers your bounce rate as well. Sorry,
[01:09:02.040 --> 01:09:08.440]   you keep trying to do the ad and that's that's an interesting thing. Because on the one hand,
[01:09:08.440 --> 01:09:14.200]   like on the one hand, that's the that's the house that Google built is to favor that kind of response.
[01:09:14.200 --> 01:09:17.720]   And then on the flip side, it's Google's house. So they have the freedom to say like,
[01:09:17.720 --> 01:09:21.560]   screw you, we don't like what you're doing. So we'll get Matt cuts because he's the guy who's in charge
[01:09:21.560 --> 01:09:25.240]   of all this. In fact, the guy who busted rap genius, we'll get him on this week in Google soon.
[01:09:25.240 --> 01:09:30.360]   He's a regular on the show and ask him what happened. They were busted by a blogger who was
[01:09:30.360 --> 01:09:37.880]   invited by rap genius to trade social media links for blog posts. So there was a lot of little
[01:09:37.880 --> 01:09:41.160]   stuff going, Hey, they're year up guys. They know how to play the game. These Yale guys,
[01:09:41.160 --> 01:09:46.920]   you got to watch out for them. They're a lot a shifty lot. Our show today brought to you by our
[01:09:46.920 --> 01:09:53.320]   good old friends, fresh books. Are you using word or Excel to create invoices? I used to do that.
[01:09:53.320 --> 01:09:58.680]   Have a shoebox or receipt to keep track of your expenses. Well, now you can save time and get
[01:09:58.680 --> 01:10:04.280]   paid faster with fresh books.com. The easiest way to send invoices, manage expenses and track
[01:10:04.280 --> 01:10:08.600]   your time there. Also really great guys. It was Amber MacArthur who introduced me to fresh books
[01:10:08.600 --> 01:10:14.200]   when I was working in Toronto. I had to build companies in the US and Canada. I would always put
[01:10:14.200 --> 01:10:17.880]   off invoicing. It was so embarrassing. You know, six months later, you send an invoice, they go,
[01:10:17.880 --> 01:10:24.280]   what's this? You can't wait that long. The invoices fresh books was a boon for me. A cloud
[01:10:24.280 --> 01:10:29.000]   accounting solution that's simple, easy to use and it's helped thousands of new entrepreneurs and
[01:10:29.000 --> 01:10:35.320]   small business owners save time with billing and really get paid faster. You can easily
[01:10:35.320 --> 01:10:40.120]   create invoices online, capture and track expenses on the go and get real time business reports with
[01:10:40.120 --> 01:10:44.680]   a few simple clicks. It's gotten much more sophisticated since I used it free for 30 days when you go
[01:10:44.680 --> 01:10:52.520]   to get fresh books.com. And yes, they're bringing back the birthday cake. Every day, they're giving
[01:10:52.520 --> 01:10:57.960]   away a birthday cake to someone who signs up for a new account from a twit. So for your chance to
[01:10:57.960 --> 01:11:03.560]   win when they say, how did you hear about us? You enter this weekend tech at get fresh books.com
[01:11:03.560 --> 01:11:09.400]   and you're in the running for and they're very nice birthday cakes, I might add. With fresh books,
[01:11:09.400 --> 01:11:16.200]   every day could be your birthday. Try it free for 30 days. Get fresh books.com. They were a lifesaver
[01:11:16.200 --> 01:11:20.040]   for me. I highly encourage it. If you're doing your own invoicing, you're doing it. I was doing
[01:11:20.040 --> 01:11:27.800]   it in Word. That was a fresh books.com. Hey, I want to show you a video. Let's do the promo
[01:11:27.800 --> 01:11:32.440]   because I want to show you a video of what happened. We talked about New Year's Eve. We've cut it down
[01:11:32.440 --> 01:11:39.560]   23 hours into 60 hot seconds of fun. If you missed our New Year's Eve promo, watch our
[01:11:40.120 --> 01:11:54.280]   previously on Twit. Matt Brake Weekly. Both buttons have popped off now.
[01:11:54.280 --> 01:11:59.560]   We're in New Year's Eve though. Yes listeners. That's how excited that the new Matt Pro makes Leo.
[01:11:59.560 --> 01:12:05.800]   He got a real tattoo, ladies and gentlemen.
[01:12:05.800 --> 01:12:10.280]   [Applause]
[01:12:10.280 --> 01:12:15.000]   NSFW. What this shows is the American public is unclear about whether people are dead
[01:12:15.000 --> 01:12:22.200]   and feel the need to search for better. I'd be like this is a startup opportunity. I think so.
[01:12:22.200 --> 01:12:28.200]   I'm like, "Great, 2014. We'll see you back here on Thursday. Bye bye."
[01:12:28.200 --> 01:12:35.160]   Twit. Wishing you a happy new year. Take that, Dick Clark. There's Steve Gibson dancing.
[01:12:35.160 --> 01:12:40.600]   With a cardboard cut out of Captain Kirk. You'll not see that on network television anywhere.
[01:12:40.600 --> 01:12:46.760]   Man, I think meeting Steve might have been one of my favorite moments of the entire
[01:12:46.760 --> 01:12:49.880]   night. Just getting to hang out with him and experience him one on one.
[01:12:49.880 --> 01:12:53.560]   I think we realized that the real fun of this, and by the way, we still have plenty of cooks
[01:12:53.560 --> 01:12:59.320]   champagne left. Six dollar magnums really go a long way. I just want to point out,
[01:12:59.320 --> 01:13:03.800]   should I open another one? Oh my god. What do we realize? The real value of--
[01:13:03.800 --> 01:13:05.880]   New Year's somewhere, Leo. Go ahead.
[01:13:05.880 --> 01:13:07.720]   But I realized it's--
[01:13:07.720 --> 01:13:10.040]   We're on it here. I'll hold my glass over here.
[01:13:10.040 --> 01:13:14.360]   We originally did it because we're international and we realized that it was new years for 24
[01:13:14.360 --> 01:13:19.160]   hours all over the world. We did. We talked to people all over the world. It was really amazing.
[01:13:19.160 --> 01:13:26.280]   The Skype calls to Samoa and to New Zealand and Australia. We talked to India. We talked to
[01:13:26.280 --> 01:13:32.600]   Bahrain. It was so cool. But what we also realized the value was seeing our hosts outside of their
[01:13:32.600 --> 01:13:38.280]   normal contexts to get to see Steve Gibson playing. What was he, the navigation officer
[01:13:38.280 --> 01:13:41.800]   on the Starship Enterprise? Sure. It was great. It was fun.
[01:13:41.800 --> 01:13:48.600]   And even getting him in person to show up during one of our NSFW Pro-XPN ads.
[01:13:48.600 --> 01:13:54.360]   Wasn't that funny? Yeah. I always wanted to do that. That's from Annie Hall, where Woody Allen
[01:13:54.360 --> 01:13:59.240]   is standing in line behind some pompous ass talking about Marshall McLuhan's theories.
[01:14:00.200 --> 01:14:04.760]   And Woody says, "You know nothing about Marshall McLuhan." He says, "In fact, I have him right here."
[01:14:04.760 --> 01:14:08.920]   And he pulls over Marshall McLuhan and says, "Marshome McLuhan says, 'Yes, you are a fool.'"
[01:14:08.920 --> 01:14:11.640]   And that's, I always wanted to do that. So that's what we did with Steve Gibson.
[01:14:11.640 --> 01:14:16.120]   Anyway, there's a lot of fun. We are going to do it again next year. We've already decided it's
[01:14:16.120 --> 01:14:19.800]   a Brian, you're booked for New Year's Eve for the rest of your life. Do you do any--
[01:14:19.800 --> 01:14:24.600]   I'll just write a new magic show. Can you do acts? Is there a demand for you on New Year's Eve?
[01:14:25.640 --> 01:14:30.760]   You know, yeah, holiday tends to be a big time for corporate shows. You know, most of my live
[01:14:30.760 --> 01:14:36.520]   stage shows tend to be at colleges, which is homecoming and new student orientations over the
[01:14:36.520 --> 01:14:43.160]   summer and stuff. But it's hit or miss on New Year's Eve. But I was glad you guys
[01:14:43.160 --> 01:14:47.320]   stole me this year. Thank you. Yeah. Well, and just to people who are worried, this didn't go to waste.
[01:14:47.320 --> 01:14:50.600]   We gave it to homeless shelters. So 30 or 40 bucks.
[01:14:53.000 --> 01:14:57.960]   It's good. There's a pressing need for booze and homeless shelters. More champagne in the homeless
[01:14:57.960 --> 01:15:05.720]   shelters. Schedule. Oh, we are changing our schedule. This is the first week coming up of our brand
[01:15:05.720 --> 01:15:09.400]   new schedule. I wanted to get Thursday and Friday off two days in a row, what a concept.
[01:15:09.400 --> 01:15:13.480]   Steve Gibson cracked me up. He said, "What are you going to do with two days off in a row?"
[01:15:13.480 --> 01:15:18.840]   Instead of Steve, that's called a weekend. It's normal. Steve, like many of us, works,
[01:15:18.840 --> 01:15:21.960]   and I'm sure this is true of you, Brian, every single day. I'm sure Dan as well.
[01:15:21.960 --> 01:15:27.560]   Yeah. By the way, the answer to that question, what do you do with two days off? Anything you
[01:15:27.560 --> 01:15:33.080]   want? Yes. It's called a weekend. So we are moving shows around. You can go to our inside
[01:15:33.080 --> 01:15:38.200]   Twitch blog running on Squarespace, inside.twit.tv. I won't be here Monday because I'm going to
[01:15:38.200 --> 01:15:42.760]   new media Expo tomorrow, but we'll be back. But Sarah's going to do iPad today with a special
[01:15:42.760 --> 01:15:47.640]   guest host, you, Chad Johnson. That's great. I don't think we're going to do a triangulation.
[01:15:47.640 --> 01:15:51.880]   Twitch, quiet, we'll of course continue. Then it's on Tuesday. Tech News today, of course,
[01:15:51.880 --> 01:15:55.240]   at 10 a.m. Monday through Friday. Now I'm trying to read it and I can't. Let's see,
[01:15:55.240 --> 01:15:59.480]   Mac break weekly and security now on Tuesday followed by before you buy.
[01:15:59.480 --> 01:16:03.560]   Wednesday, Floss weekly, Tech News today. Windows weekly. This week in Google,
[01:16:03.560 --> 01:16:08.840]   i5 for the iPhone and the Gizwiz, Amnation following that Thursday. Anyway, it's all there,
[01:16:08.840 --> 01:16:14.600]   the social hours. So moving a few shows around so that I can have a couple of days off in a row.
[01:16:14.600 --> 01:16:17.880]   And that does start this week. So if you're wondering where your favorite show went,
[01:16:17.880 --> 01:16:21.880]   if you watch live, you know, we found out in our survey, one of the really interesting things
[01:16:21.880 --> 01:16:26.920]   is that more than half of you at some point watch live right on. I'm very happy about that.
[01:16:26.920 --> 01:16:31.080]   I'd like to. We've been meaning to talk to you. We're going to need all of you to watch live
[01:16:31.080 --> 01:16:35.560]   all the time. All right. I don't think it's much to ask. Just 24 hours a day.
[01:16:35.560 --> 01:16:39.720]   Well, that's all we asked. Just leave it on somewhere in your house. It's all we ask.
[01:16:40.440 --> 01:16:47.000]   Hey, we started a new era of Tech News today with Mike Elgin hosting and Mike has a look at
[01:16:47.000 --> 01:16:51.320]   the week ahead, Mike. Thanks, Leo. Coming up in the week ahead, CES will dominate the Tech News
[01:16:51.320 --> 01:16:56.360]   course starting right now. The CES Unveiled event started at 4 p.m. today. And that's where
[01:16:56.360 --> 01:17:00.520]   about 70 companies are giving the media a sneak peek at the products they'll unveil at CES.
[01:17:00.520 --> 01:17:05.400]   Tomorrow is Press Day, which is packed with press conferences and announcements galore.
[01:17:05.400 --> 01:17:10.360]   And then Tuesday, of course, the show starts. So it's going to be all CES all the time next week.
[01:17:10.360 --> 01:17:14.840]   Back to you, Leo. So the week ahead, mostly CES coverage. And I want to, I'm very excited this
[01:17:14.840 --> 01:17:20.920]   weekend, Enterprise Tech. Robert Baliser will be down there. Father Robert will be covering CES.
[01:17:20.920 --> 01:17:24.280]   Scott Wilkinson will be doing his traditional home theater geeks. They're talking to all the
[01:17:24.280 --> 01:17:31.240]   TV manufacturers about UHD 4K and OLED, of course. And the Gizwiz will be there to find his usual
[01:17:31.240 --> 01:17:39.080]   weird stuff. In fact, it all begins, I think tonight, Robert's going to the CES Unveiled event tonight.
[01:17:39.080 --> 01:17:45.400]   Is this the year we see an eye watch? It seems like, I don't think we'll see this at CES,
[01:17:45.400 --> 01:17:49.880]   but it seems like wearables are going to be the product of the year 2014. Or is that nuts?
[01:17:49.880 --> 01:17:54.680]   What do you try? You wear Google Glass all the time, don't you?
[01:17:54.680 --> 01:17:59.160]   I do. I have it right here. In fact, it's out of charge. I've been wearing and
[01:17:59.720 --> 01:18:06.840]   recording so many videos, but I don't know about a watch because the kind of
[01:18:06.840 --> 01:18:13.720]   pro-watch. I'm team watch. Your team. You know what I am? I'm team heads up display. The problem
[01:18:13.720 --> 01:18:18.200]   with Google Glass is you have to look up to this little screen. I don't want to look. I want to
[01:18:18.200 --> 01:18:23.480]   see a heads up like a, like from demon, a heads up display that that's augmented reality. I want
[01:18:23.480 --> 01:18:27.480]   to know what's going on in the world without looking away from the world. I think Robert's right
[01:18:27.480 --> 01:18:33.080]   about that this year. I mean, in glass, I've been sitting on an explorer invite for ages and just
[01:18:33.080 --> 01:18:38.600]   can't bring this to $1,500. It's too much money, but it's all. I mean, Robert's right. This is
[01:18:38.600 --> 01:18:43.800]   coming. This is inevitable. Those of us who are glass. What do you say, Robert? You mean scoble?
[01:18:43.800 --> 01:18:50.040]   Scoble. Scoble. With his post last week. And that was the worst link they'd ever. The post's
[01:18:50.040 --> 01:18:56.760]   headline was Glass is doomed in which he of course said, no, it's not. Right. This year, this year
[01:18:56.760 --> 01:19:01.400]   Glass will be a peripheral product. But I think, I mean, whether we see something from Apple or not,
[01:19:01.400 --> 01:19:06.920]   who knows, but wearables are coming. And I think that was pretended by Siri and Google now a couple
[01:19:06.920 --> 01:19:11.880]   years ago, whether it's this year or not, who knows, Robert is right in that Glass is too clunky
[01:19:11.880 --> 01:19:17.960]   right now. But of course, it's prototypical. And we will see. It's not that the wearable technology
[01:19:17.960 --> 01:19:23.800]   is coming soon. It is that a desire for personal data and useful personal data is coming. So the
[01:19:23.800 --> 01:19:29.400]   Fitbit pretends this. Right. And in fact, not to plug my old employers, but some all in companies
[01:19:29.400 --> 01:19:34.760]   like Gecko board who are on the train with let's track analyze it's the, you know, quantified
[01:19:34.760 --> 01:19:42.040]   self movement that if not coming is already here. So you say it'll be health focused? I think it'll
[01:19:42.040 --> 01:19:46.520]   be data focused. I think gaming is another. I mean, that somebody hasn't hasn't dug deep into the
[01:19:46.520 --> 01:19:53.160]   steam and blizzard, battle.net API is shocking to me. I think that personal data and access to
[01:19:53.160 --> 01:19:58.440]   personal data is what's coming. Be very interesting to play a game. Is that what you're talking about?
[01:19:58.440 --> 01:20:03.800]   Kind of an augmented reality game. No, no, not necessarily playing a game, but tracking your data,
[01:20:03.800 --> 01:20:09.480]   collecting your data into one place and having access to it in a way that's useful. So for example,
[01:20:09.480 --> 01:20:13.880]   I, you know, I live in New York, but this could be just as easy in South Dakota. I have a Fitbit,
[01:20:13.880 --> 01:20:20.280]   right? That alone, that is simply technology that sits on me and it tracks and quantifies my steps
[01:20:20.280 --> 01:20:25.560]   per day, right? You use that every day, all of a sudden I can bend my data curve in a positive
[01:20:25.560 --> 01:20:31.960]   direction. I can bend with access to a knowledge of my own personal data. I can then influence the
[01:20:31.960 --> 01:20:38.360]   course of that data. So we can apply that same metaphor to gaming and say, well, with access to
[01:20:38.360 --> 01:20:43.880]   basic like time, spun played or achievements or progression in any capacity allows me to bend my
[01:20:43.880 --> 01:20:51.560]   data curve in gaming or almost any personal driving cars. The access to data and ability to manipulate
[01:20:51.560 --> 01:20:55.880]   it is what's coming. Wearables simply allow us to gather that data.
[01:20:55.880 --> 01:20:59.720]   Well, Dan, you know, you know what's really cool about this is they just released a new app like
[01:20:59.720 --> 01:21:06.840]   last week. It's called Strava Run. So now whenever I go on a run, I put this on and it has GPS data,
[01:21:06.840 --> 01:21:11.800]   it has my speed and has altitude and everything and it outflows immediately when I get back.
[01:21:11.800 --> 01:21:15.800]   And so I just look at a map and I see my little run around Lake Hayes and I see where I was going
[01:21:15.800 --> 01:21:20.280]   fast and slow. And so now I can't bear to go on a run without turning this on because I feel like
[01:21:20.280 --> 01:21:25.400]   I'm not, you know, I've kind of personally gamified it and Strava is incredible and it worked just
[01:21:25.400 --> 01:21:30.040]   flawlessly and it's really cool to be like running and look at how fast you're going and look at your
[01:21:30.040 --> 01:21:36.680]   lap speed and it's pretty awesome. You could go neighborhoods explored or, you know, paths I used
[01:21:36.680 --> 01:21:41.320]   to live in the mountains. I live in a big city and you could do it anywhere, right? Just saying like,
[01:21:41.320 --> 01:21:45.400]   this is what I, these are the benchmarks that have accomplished and these are my goals. And now I
[01:21:45.400 --> 01:21:50.680]   have the data that allows me to not just guesstimate it, but know it precisely. And just like you said,
[01:21:50.680 --> 01:21:55.800]   Trey, see it in a way that really resonates with my emotions by looking at a map. And that's so
[01:21:55.800 --> 01:22:00.760]   much more interesting than, you know, a spreadsheet. That's too much exercise. Would it, is it possible
[01:22:00.760 --> 01:22:06.360]   to have an app that watches what you're watching on TV and lets you know how much you watched TV?
[01:22:08.120 --> 01:22:13.400]   Or maybe how much you ate while you were watching TV. I'm, I'm sure to be honest, like the eating
[01:22:13.400 --> 01:22:18.920]   thing I would love to. Here's the thing is we exist, we exist as more than our physical bodies.
[01:22:18.920 --> 01:22:24.520]   And we even exist more than what we're doing at any time. We exist as our footprint on the social
[01:22:24.520 --> 01:22:30.840]   strata around us. We exist as both outputs and inputs of what people, you know, whenever there's
[01:22:30.840 --> 01:22:37.320]   a sale that happens on my online store at scam stuff, you know, my pebble vibrates and I, and I
[01:22:37.320 --> 01:22:43.800]   glance down and it's like, it's good input to know that, okay, my, not only my physical health, you
[01:22:43.800 --> 01:22:47.800]   know, we're good at monitoring our physical presence at any given time, but you know, your,
[01:22:47.800 --> 01:22:52.520]   your financial health, you want to keep track of, you want to keep track of the physical momentum,
[01:22:52.520 --> 01:22:56.200]   whether you're getting in your mental health, whether or not you're getting enough of x, y, or z,
[01:22:56.200 --> 01:23:01.320]   you want to know if, if somebody is, is reaching out to you, or if you just got a message and
[01:23:01.320 --> 01:23:07.240]   wearable tech is not just the future. It's inevitable. The version that we're seeing of it
[01:23:07.240 --> 01:23:13.480]   right now, I think that, that Google is right in that an ever present visual element will be part
[01:23:13.480 --> 01:23:19.000]   of the future. Unfortunately, they've done it in a very ostentatious way that makes a statement
[01:23:19.000 --> 01:23:24.840]   that a lot of people aren't comfortable with. On the flip side, you know, pebble has understated
[01:23:24.840 --> 01:23:31.400]   it. You know, pebble is in many ways the palm pilot where they took the same idea as the newton,
[01:23:31.400 --> 01:23:36.360]   but made it in a way that was palatable and, and, and would hint at what would you would see
[01:23:36.360 --> 01:23:41.480]   eventually with smartphones in general. So I think that we're going to see it on the wrist first,
[01:23:41.480 --> 01:23:46.680]   but I think we're going to eventually start seeing interesting stuff like imagine an
[01:23:46.680 --> 01:23:52.440]   anklet that you keep on you that does nothing but communicate to you vital information through
[01:23:52.440 --> 01:23:58.040]   series of taps or vibrations, something that, that gives you an important thing. Oh, my wife
[01:23:58.040 --> 01:24:03.720]   just got home. I know because it was three short, one long or whatever. Once you speak that language,
[01:24:03.720 --> 01:24:11.160]   eventually what we regard as ourselves will expand to a larger presence. And it will be
[01:24:11.160 --> 01:24:16.680]   expected, you know, that you, you summon your car by tapping your heels together while casually
[01:24:16.680 --> 01:24:21.640]   talking to someone and then your ankle vibrates because the car is now within a block and you say
[01:24:21.640 --> 01:24:27.320]   your goodbyes and walk out the door. To me, that is all, that's all great. It's obviously going to
[01:24:27.320 --> 01:24:32.680]   come. It's obviously definitely going to happen. And to me, it's very human as, as inhumane as,
[01:24:32.680 --> 01:24:40.280]   as it sounds. Yeah, it allows wearable technology allows for persistent data gathering. And that
[01:24:40.280 --> 01:24:46.120]   persistent data gathering, just like Brian was saying, you know, a basis watch can tell me whether
[01:24:46.120 --> 01:24:52.200]   my heart rate was up on days that the weather was good during the morning and that I sweat more in
[01:24:52.200 --> 01:24:57.320]   the evening, right? Putting that into a graph in a chart allows me to really understand what makes
[01:24:57.320 --> 01:25:05.400]   me happy or when am I happy? So this, this persistent data is really that, that wearable technology
[01:25:05.400 --> 01:25:12.040]   allows for a, a post-corperal future, right? So putting things on us, allow us to, just like Brian
[01:25:12.040 --> 01:25:19.240]   said, extend ourselves beyond just the idea of me as an individual, but me as a data footprint that
[01:25:19.240 --> 01:25:26.120]   is, is constantly emotion and changing. And now for the first time ever with wearables, I'm able to
[01:25:26.120 --> 01:25:32.440]   analyze those changes. I can, I can bring in and understand a lot of the things that have so far
[01:25:32.440 --> 01:25:39.480]   been abstract. Do you think with the revelations this year about the NSA that slows this kind of
[01:25:39.480 --> 01:25:44.840]   thing down? Because don't we now fear data collection because we fear that the government
[01:25:44.840 --> 01:25:51.160]   might get it? Not as much as we desire cool gadgets. Yeah. And that's the thing is, is we,
[01:25:51.160 --> 01:25:55.720]   we haven't felt the sting of what it means to have somebody scooping up all of our data
[01:25:55.720 --> 01:26:02.280]   full stop. So far, the only, like when I personally think of like what data is being scooped up on me,
[01:26:02.280 --> 01:26:07.960]   I think about like my lose it app where I gladly tell it every beer I drink, every chocolate I
[01:26:07.960 --> 01:26:13.400]   wolf down or whatever. And in exchange, I get an accurate picture of my life. We haven't seen
[01:26:13.400 --> 01:26:18.440]   the negative side of that yet. And who knows, maybe there is no negative side, maybe in 100 years
[01:26:18.440 --> 01:26:21.800]   we'll realize that the best thing you could do is have everyone know everything about you.
[01:26:21.800 --> 01:26:27.480]   But my guess is that there will be some very loud, very ostentatious stories of horrific
[01:26:27.480 --> 01:26:31.960]   things that have happened because of the the hoovering of data. And I think that's what it's
[01:26:31.960 --> 01:26:37.560]   going to take to put a stop to the NSA. But I do believe that there will be the perception.
[01:26:37.560 --> 01:26:44.200]   The problem is, is we all embrace the perception of these brief moments of total privacy of our
[01:26:44.200 --> 01:26:51.160]   inner self. And even if they're false, we like that feeling. The problem is that now,
[01:26:51.160 --> 01:26:59.640]   there will be a dollar motive for people to buy the plausible version of privacy from time to time.
[01:26:59.640 --> 01:27:06.760]   And we have this, this really interesting moment where we have to humans are forced with the cost
[01:27:06.760 --> 01:27:13.640]   benefit analysis to really make a zero sum type of decision based on, okay, yes, I know my data is
[01:27:13.640 --> 01:27:20.680]   being gathered, but that is an abstract negative weighted against the very practical positive of
[01:27:20.680 --> 01:27:27.080]   having a smartphone or a cool wearable in the future, right? You can't really exist in the now
[01:27:27.080 --> 01:27:33.000]   without some sort of access to the web and interaction with the web. That is a very tangible
[01:27:33.000 --> 01:27:38.680]   positive. And when you wait that against an abstract negative, like they, capital T, they might be
[01:27:38.680 --> 01:27:45.560]   watching most people who do that cost benefit go and just give me a phone. Yeah, I just want this
[01:27:45.560 --> 01:27:50.760]   stuff. I just want it to work. Right. Trey, you're doing something interesting with Glass. You want
[01:27:50.760 --> 01:27:58.760]   to talk about your mentoring project? Yeah. Unless it's not public. Do you, am I, am I,
[01:27:58.760 --> 01:28:05.400]   this? We just launched this actually, you know, you know, Lisa Bettany and all these people. We,
[01:28:05.400 --> 01:28:12.040]   so we just launched this thing. It's called the Arkanum, the Arkanum.com named after Patrick Rothfusses,
[01:28:12.040 --> 01:28:19.800]   the name of the wind Arkanum sort of homage to him. And basically what we're doing is bringing back
[01:28:19.800 --> 01:28:25.560]   the master and apprentice way of learning because I think this is something that's gotten lost over
[01:28:25.560 --> 01:28:33.640]   time, unfortunately. And you know, the internet's solution to education has been basically just to
[01:28:33.640 --> 01:28:38.200]   dump a ton of videos online. And if you want to learn something like Photoshop, you, you log in and,
[01:28:38.200 --> 01:28:42.520]   and you pay, you know, 20 or 30 or $40 a month and you have access to
[01:28:42.520 --> 01:28:48.200]   thousands and thousands of videos. But actually that's not how most people learn. Most people
[01:28:48.200 --> 01:28:54.680]   learn through a master to apprentice type situation. And a lot of our masters right now have Google
[01:28:54.680 --> 01:29:00.520]   Glass and the idea that you can communicate real time to your little group of apprentices.
[01:29:01.240 --> 01:29:05.400]   And they can ask you questions like in a Google Hangout. We're kind of all built on top of Google
[01:29:05.400 --> 01:29:10.520]   technologies. But it's a really cool thing. So it's like an augmented reality, Hogwarts,
[01:29:10.520 --> 01:29:17.400]   you're constantly connected to your master and your fellow apprentices. And it's a super fun way to
[01:29:17.400 --> 01:29:23.480]   learn. You've got some of my favorite photographers working on this. Is it just photography? What
[01:29:23.480 --> 01:29:29.080]   else are you going to cover? Well, you know, we're starting focus with just photography and visual
[01:29:29.080 --> 01:29:35.160]   arts. We do have a hand drawn art category. That'd be cool to watch somebody as a, as an artist.
[01:29:35.160 --> 01:29:41.560]   And, and learn how they do what they do via Glass. Oh, yeah, absolutely. It's
[01:29:41.560 --> 01:29:48.920]   anything that can be taught visually where you could see your hands or you get to log in live and
[01:29:48.920 --> 01:29:55.320]   see what someone else is seeing. That's incredibly valuable because the, the idea that you can connect
[01:29:55.320 --> 01:30:00.600]   with a fellow human and have this very human interaction with learning and you can ask questions in an
[01:30:00.600 --> 01:30:05.960]   interactive way and also learn while your fellow apprentices are learning. I think this is one of
[01:30:05.960 --> 01:30:09.960]   the key aspects learning that's, that's kind of fallen by the wayside with the internet. So we're
[01:30:09.960 --> 01:30:15.000]   bringing it back just through modern technology. We haven't invented anything at all. We're just
[01:30:15.000 --> 01:30:21.560]   synthesizing things that are already out there. Well, or virtualizing that which already works.
[01:30:21.560 --> 01:30:26.840]   All of the best development on the internet tend to be stuff that's just a virtualized version
[01:30:26.840 --> 01:30:32.360]   of something that already was established. You know, Facebook is a virtualized version of,
[01:30:32.360 --> 01:30:35.960]   you know, the relationship with your families, you know, that you no longer have to live near.
[01:30:35.960 --> 01:30:42.360]   You know, Twitter is the virtualized version of small talk and the Arkanum is a virtualized version
[01:30:42.360 --> 01:30:47.960]   of its access basically is what you're doing is you're making impossible access for people who
[01:30:47.960 --> 01:30:52.760]   otherwise physically would never get the chance to sit and ghost someone else.
[01:30:52.760 --> 01:30:56.680]   It's funny that you should say that, Brian, because I mean, and you may be right, certainly
[01:30:56.680 --> 01:31:00.440]   you're right so far, but I always thought that the internet wouldn't come until its own until
[01:31:00.440 --> 01:31:05.240]   you started doing stuff that was internet native that wasn't a virtualization of the real world.
[01:31:05.240 --> 01:31:09.880]   It wasn't, you know, magazines on the web or television or radio. I mean, clearly what we're
[01:31:09.880 --> 01:31:14.680]   doing is absolutely that and a lot of what we do. But ultimately, won't it be the internet
[01:31:14.680 --> 01:31:19.480]   generation that comes up with something that's sui generous that's completely unique to the internet?
[01:31:19.480 --> 01:31:26.440]   I don't think so. I think that I think that we're made of messy wetware that expects certain things.
[01:31:26.440 --> 01:31:31.960]   And I think that the more that we cater to giving our bodies those things that we expect, you know,
[01:31:31.960 --> 01:31:37.400]   look at look at Dunbar's number, this idea that you can really only handle the concept of about 150
[01:31:37.400 --> 01:31:43.240]   friends. That's why Facebook is huge because it allows you to isolate in on your own tribe.
[01:31:43.240 --> 01:31:49.560]   And even though it's an artificial construct, it's an abstraction, it allows you to spread
[01:31:49.560 --> 01:31:56.040]   messages easier and feel part of something tight while actually maintaining your role in the rest
[01:31:56.040 --> 01:32:02.440]   of society. I think that I think that the sooner that we all recognize the flawed, bizarre,
[01:32:02.440 --> 01:32:11.080]   clugy nature of our mechanics and that we figure out a way to, for example, soldiers,
[01:32:11.080 --> 01:32:14.920]   there's a reason that soldiers and their heads up display looks like a video game because that's
[01:32:14.920 --> 01:32:19.800]   what we like to see. We want to see a video game. So, so let's rather than try to retrain them with
[01:32:19.800 --> 01:32:24.280]   something new. Let's just make it a video game. And I and I, and I think it's okay.
[01:32:24.280 --> 01:32:32.360]   Yeah, the metaphors that that we use now are is television organic of us because we like to see
[01:32:32.360 --> 01:32:38.200]   stuff. Like you said, the messy wetware of humanity or is it just a very convenient thing that was
[01:32:38.200 --> 01:32:43.320]   developed in the mid 20th century that that just like you said, Leo, will eventually phase out
[01:32:43.320 --> 01:32:48.040]   and become something that is truly organic and of the web, right? Is it is the medium really the
[01:32:48.040 --> 01:32:54.280]   message? You guys say that biology is destiny. We can't transcend our meat sacks. I mean,
[01:32:54.280 --> 01:33:01.400]   we can certainly transcend the ambition of meat sacks just as we transcend our urges to
[01:33:01.400 --> 01:33:05.800]   rape and murder or whatever, you know, we can be better. Haven't done a great job of that yet,
[01:33:05.800 --> 01:33:11.000]   however. Well, I mean, you say that you say that and yet if you read Steven Pinker's Better
[01:33:11.000 --> 01:33:18.200]   Angels of our Nature, this is the most peaceful, most prosperous, best time in the entire history
[01:33:18.200 --> 01:33:24.920]   of humanity. We have never as a creature been more peaceful or more beneficial than we are right now.
[01:33:24.920 --> 01:33:28.680]   Oh, by leaps and bounds. So we mean, it's astonishing. So that's the question.
[01:33:28.680 --> 01:33:33.160]   And all his analyses, too, that is even though you hear all this horrible stuff on the news,
[01:33:33.160 --> 01:33:36.520]   you know, it's really just a percentage of a percentage, the bad things that happen.
[01:33:36.520 --> 01:33:41.800]   So we certainly are more aware of the bad stuff. Yeah. And yet there's no question that 20th century
[01:33:41.800 --> 01:33:46.520]   was the most bloody in human history. So maybe this is, I hope it's a new era or either
[01:33:46.520 --> 01:33:55.960]   regnum, a brief pause in between the 20th century suffered from an unfortunate prevalence of
[01:33:55.960 --> 01:34:02.920]   industrial technology in a time, you know, whereas like where war became mechanized at that point.
[01:34:02.920 --> 01:34:07.400]   That's right. But you'll notice sense then it's astonishing. It's astonishing and unprecedented at
[01:34:07.400 --> 01:34:16.440]   no time in all of humanity have not only have we seen fewer deaths in war, but our taste for
[01:34:16.440 --> 01:34:21.160]   torture and death is that an all time low. Steven Pinker's Better Angels of our Nature
[01:34:21.160 --> 01:34:23.160]   is utterly astonishing. It'll change your life.
[01:34:23.160 --> 01:34:27.400]   Beatmaster says, obviously Pinker never saw a single YouTube comment section.
[01:34:30.600 --> 01:34:37.480]   That's great. Like let's let that be the new standard for what is hideous and gross in our lives.
[01:34:37.480 --> 01:34:37.480]   Yes.
[01:34:37.480 --> 01:34:46.520]   You know, in Steven Pinker's book, he talks about how, what was it, broken, broke on the wheel.
[01:34:46.520 --> 01:34:51.800]   I forget what it is. They would basically take someone, take a wagon wheel for amusement,
[01:34:51.800 --> 01:34:56.440]   break all their bones and weave their body through a wagon wheel and spin it around.
[01:34:56.440 --> 01:35:02.040]   Like this is this is what humanity was built to do. And it's great to me that we are
[01:35:02.040 --> 01:35:05.240]   transcending it for our hope is right. I'll take trolls any day.
[01:35:05.240 --> 01:35:10.840]   Yeah. No, that's minor compared to drawing, quartering and things like that.
[01:35:10.840 --> 01:35:12.520]   We're going to take break.
[01:35:12.520 --> 01:35:17.560]   Hey, Leo, I know you guys are Peter of Hamilton fans. Have you read his new book?
[01:35:17.560 --> 01:35:19.560]   I just read Great North Road. What's his new one?
[01:35:19.560 --> 01:35:21.400]   Oh, that's what I mean. Great North Road.
[01:35:21.400 --> 01:35:21.720]   Yeah.
[01:35:21.720 --> 01:35:22.120]   Yeah.
[01:35:22.120 --> 01:35:22.600]   Yeah.
[01:35:22.600 --> 01:35:27.480]   Okay. I am only a third of the way into it. Please tell me why I should get back into it,
[01:35:27.480 --> 01:35:30.680]   because it seems like there's an awful lot of getting ready to get ready.
[01:35:30.680 --> 01:35:36.120]   It's a long procedural. Very long. You liked it? You liked the tray?
[01:35:36.120 --> 01:35:41.640]   Well, I wasn't going to talk about the plot points of the book, just more the vision of
[01:35:41.640 --> 01:35:48.360]   technology, fusing with humanism because it's not that's what Hamilton does, though, isn't it?
[01:35:48.360 --> 01:35:49.480]   Yeah.
[01:35:49.480 --> 01:35:49.800]   Yeah.
[01:35:49.800 --> 01:35:54.520]   So well, I like it because it takes place in Newcastle on time and it's still this industrial
[01:35:54.520 --> 01:36:03.640]   gray, snowy town, but it also happens to be the gateway to a space tunnel that warps you to another
[01:36:03.640 --> 01:36:07.320]   planet. I actually like that. You know what? This brings up audible.com.
[01:36:07.320 --> 01:36:12.520]   Good time to mention the way I listen, where I read books these days is by listening,
[01:36:12.520 --> 01:36:16.840]   and that's how I listen to Great North Road. Very nicely narrated by Toby Longworth, who does
[01:36:16.840 --> 01:36:21.080]   all the Peter F. Hamilton. Did you read it, tray, or listen to it?
[01:36:21.080 --> 01:36:25.560]   No, I'm actually, I'm about exactly where Brian is. I'm a third of the way through,
[01:36:25.560 --> 01:36:29.320]   and I was listening to it on my road trip. I love audible. That was my latest book,
[01:36:29.320 --> 01:36:31.320]   so I was kind of excited about it. Yeah, I think it's great.
[01:36:31.320 --> 01:36:39.000]   Can I reiterate my deep, hell belief that the best way to experience any kind of narrative
[01:36:39.000 --> 01:36:42.440]   fiction is by an audiobook. And I'll agree with you.
[01:36:42.440 --> 01:36:49.160]   So with anyone who challenges me on this, because you are for when I read, I'm using air quotes for
[01:36:49.160 --> 01:36:54.840]   that stupid translation of my eyes taking symbols and throwing gustilts in my brain,
[01:36:54.840 --> 01:36:59.400]   that's dumb and slow because it forces me to direct and I'm allows you director and I cheat
[01:36:59.400 --> 01:37:05.800]   and I jump ahead. I read stuff before I'm supposed to, but when you are forced to listen to every word,
[01:37:05.800 --> 01:37:13.320]   exactly the way the author intended it, you get a richer experience. Audible is the best way to
[01:37:13.320 --> 01:37:17.640]   experience all of the best stories. I don't even need to do an ad at this point, but I'm with you
[01:37:17.640 --> 01:37:21.880]   100%. Now, I admit it's not for everybody. And I think, you know, maybe you're saying, well,
[01:37:21.880 --> 01:37:25.720]   I don't know, I like to read books. I don't know if I can listen to a book. Maybe I'll lose track
[01:37:25.720 --> 01:37:30.280]   of what's going on or, you know, my attention will drift. So we invite you to try it. In fact,
[01:37:30.280 --> 01:37:37.160]   we've got a really good deal for two books for free for the first month. Audible.com/twit
[01:37:37.160 --> 01:37:41.720]   and the number two, you'll be signing up for the platinum account. That's the two books a month.
[01:37:41.720 --> 01:37:46.440]   That's what I'm a member of platinum and or two credits, but most books are a single credit.
[01:37:46.440 --> 01:37:51.080]   All the Peter F. Hamilton books are a single credit and despite the length and that really
[01:37:51.080 --> 01:37:58.200]   allows you to to get a sense of is this right for me? So please get the great North Road. Actually,
[01:37:58.200 --> 01:38:04.600]   I would if I'm going to pick a single Peter F. Hamilton novel to start with, they don't have
[01:38:04.600 --> 01:38:09.000]   drag and fall yet. I'm sure they're reading it right now. That's the great Peter F. Hamilton for
[01:38:09.000 --> 01:38:14.360]   the first one. Maybe Pandora star the first Pandora star. If you're going to pick one just to get
[01:38:14.360 --> 01:38:19.240]   started, I would recommend Pandora star move on to the void trilogy. You'll learn more about the
[01:38:19.240 --> 01:38:24.040]   bureaucracy of Crenshaw. I think I'll ever want to know in an entertaining way.
[01:38:24.680 --> 01:38:29.960]   Pandora star, you get that and you just on Jane for for free. That's a good deal.
[01:38:29.960 --> 01:38:36.120]   Keep in mind like like Hamilton's great strength is that he's able to take a future where it is an
[01:38:36.120 --> 01:38:41.080]   option to go post physical almost as a fashionable thing. You're like, why do you still have a body?
[01:38:41.080 --> 01:38:45.640]   Why don't you just download your consciousness and live in the ether or whatever? And yet,
[01:38:45.640 --> 01:38:49.640]   he still knows what people are going to want to do when they can go physical. What are they
[01:38:49.640 --> 01:38:54.520]   going to want to do? They're going to want to kick each other's ass and have sex. That's the world.
[01:38:54.520 --> 01:39:04.200]   So there you go. There you have it. Audible.com is not just sci-fi history fiction of all kinds,
[01:39:04.200 --> 01:39:09.480]   thrillers and mysteries and suspense. Classics too. Really great way to you know, you want to listen
[01:39:09.480 --> 01:39:14.200]   to Dickens? There's no better way to have Dickens come to life in your brain. The movie in your mind
[01:39:14.200 --> 01:39:19.320]   is amazing. There are over 150,000 titles. All the best sellers show up on Audible immediately.
[01:39:19.320 --> 01:39:25.880]   Of course, a lot of great kids stuff as well. In fact, their young adult selection and their
[01:39:25.880 --> 01:39:30.200]   children's selection is actually a great way to get a child into reading. Please do yourself.
[01:39:30.200 --> 01:39:34.520]   I would like to I would like to put a plug in for Stephen Pinker's Better Angels of our nation.
[01:39:34.520 --> 01:39:39.160]   Is that Audible? It's really astonishing. Yeah, yeah, it's it's amazing. I believe it might be
[01:39:39.160 --> 01:39:43.480]   two credits. You'll have to take a look. It's a big book, but it's one of those things that just
[01:39:43.480 --> 01:39:49.560]   changes the way you see the world. And so often you have these enlightening books that just make
[01:39:49.560 --> 01:39:55.160]   you depressed about the reality. Stephen Pinker's book will make you believe that we're going to
[01:39:55.160 --> 01:39:59.640]   get this thing licked. We're going to get this figured out and we're part of the greatest team
[01:39:59.640 --> 01:40:03.640]   in humanity's history. Downloading it right now. By the way, they just
[01:40:03.640 --> 01:40:09.320]   another good suggestion for you guys. Yeah. You want a major mind F. If you want to go sci-fi in
[01:40:09.320 --> 01:40:15.000]   a different direction, there's a Philip K. Dick book called Valus. Oh, yeah. Like Brian was saying
[01:40:15.000 --> 01:40:22.520]   about listening to an audiobook when you're inside P. K. D's head and he's reading or he doesn't read
[01:40:22.520 --> 01:40:28.680]   Valus, but when you're hearing it, I mean, it will do things to your brain that you might not be ready
[01:40:28.680 --> 01:40:33.240]   for, but it is an amazing sci-fi experience. I love this guy. There's something very visual
[01:40:33.240 --> 01:40:37.560]   about Philip K. Dick. Almost all of his books have been turned into classic sci-fi movies, minority
[01:40:37.560 --> 01:40:43.480]   report. Blade Runner. Blade Runner was based on when I'll do electric androids.
[01:40:43.480 --> 01:40:49.480]   Two androids. Yeah. Androids, three and a little cheap. Yeah. He's very visual somehow. So great stuff.
[01:40:49.480 --> 01:40:55.960]   Total recall is a Philip K. Dick short story, I think. Oh boy, we just given him too many choices.
[01:40:55.960 --> 01:41:01.560]   Pick two and get them for free audible.com/twit2. We thank them for their support many years now
[01:41:02.120 --> 01:41:10.520]   of Twit and all of our network shows. Snapchat hack. People say that Snapchat did not respond
[01:41:10.520 --> 01:41:21.240]   well to this. They confirmed a leak, 4.6 million user names, but they did not apologize. We have to
[01:41:21.240 --> 01:41:27.800]   apologize, isn't it? Didn't they ignore the white hat, which is the bad move? So that's the big
[01:41:27.800 --> 01:41:35.080]   problem is this Gibson security, not Steve Gibson, but an unrelated did in fact say there is a hack.
[01:41:35.080 --> 01:41:40.440]   Now did the white hack hold it back? They went to Snapchat and told them about it, right?
[01:41:40.440 --> 01:41:44.920]   But this was-- Yeah, they held it back and Snapchat just didn't respond.
[01:41:44.920 --> 01:41:54.440]   And of course, eventually the bad guys found out and used it using the functionality of fine
[01:41:54.440 --> 01:42:00.600]   friends to upload a large number of random phone numbers and then match them with Snapchat user names.
[01:42:00.600 --> 01:42:06.600]   That database of phone numbers and user names was released on New Year's Eve.
[01:42:06.600 --> 01:42:16.200]   They did what do they obscure the last two digits? 4.6 million Snapchat users phone numbers
[01:42:17.480 --> 01:42:25.800]   in the Snapchat DB. Now the bad guys said our motivation-- they told the Verge, our motivation
[01:42:25.800 --> 01:42:31.560]   behind the release was to raise public awareness around the issue and to put pressure on Snapchat
[01:42:31.560 --> 01:42:33.880]   to get this exploit fixed. So are the hackers white hats?
[01:42:33.880 --> 01:42:42.600]   I mean, I don't know as far as motivations or what the hackers were doing, but I could tell you
[01:42:42.600 --> 01:42:48.760]   this much. This is the beginning of what will be one of the defining commodities of the 21st century,
[01:42:48.760 --> 01:42:55.000]   which is privacy. I mean, people will pay big, big money for guaranteed privacy. And of course,
[01:42:55.000 --> 01:43:00.520]   what we're seeing with essentially-- that's what Snapchat, of course, provides-- I'm using air quotes
[01:43:00.520 --> 01:43:08.040]   for free-- is the ability to take a picture and know that it won't stick to your lifelong resume.
[01:43:08.920 --> 01:43:16.360]   And as stories like this come out, the value of a trusted brand or a trusted system for you for
[01:43:16.360 --> 01:43:21.160]   just one moment, for just one moment, do something that's not on your permanent record,
[01:43:21.160 --> 01:43:24.280]   will become all the sweeter and more valuable to people.
[01:43:24.280 --> 01:43:31.000]   You hit the right word there. Trust equity is the key to this story. And that is something where--
[01:43:31.000 --> 01:43:37.080]   I mean, certainly no judgment on-- I don't run Snapchat, so I don't make their communications
[01:43:37.080 --> 01:43:43.400]   decisions. But I would say that their reluctance or hesitance to apologize in any way, this very
[01:43:43.400 --> 01:43:52.760]   hubristic type of balls forward answer, that is indicative of their philosophy going forward.
[01:43:52.760 --> 01:43:57.960]   And I think that that is something that-- it's not going to kill the company, but trust is where
[01:43:57.960 --> 01:44:03.560]   consumers will make decisions going forward. And this ignores trust. This says us first,
[01:44:03.560 --> 01:44:13.800]   consumers second, mistakes be damned, all full speed ahead. Now, if you like that tactical approach,
[01:44:13.800 --> 01:44:19.960]   then I think you have no problem with Snapchat. However, users will pay a premium for privacy.
[01:44:19.960 --> 01:44:23.720]   Forget stickers and buttons and that kind of stuff. Yeah, they'll pay for that. But what they'll really
[01:44:23.720 --> 01:44:32.280]   pay for is the trust equity and knowing that my data is secure and that my privacy, my personhood,
[01:44:32.280 --> 01:44:39.400]   is taken seriously. And I think an answer like this is just a very interesting tactical response
[01:44:39.400 --> 01:44:44.680]   to a process that kind of ignores trust at the center of that equation.
[01:44:44.680 --> 01:44:51.000]   I think-- I think that-- Go ahead, Detre. I don't think the teenagers that use Snapchat even
[01:44:51.000 --> 01:44:55.880]   care. This stuff seems to happen all the time and they might just change your password. If they
[01:44:55.880 --> 01:45:01.640]   even hear about it, I bet only 2% of the 4.6 million people even heard about it.
[01:45:01.640 --> 01:45:05.160]   Like people talking about it or people on the techniques. Right. Not the teenagers who use
[01:45:05.160 --> 01:45:11.080]   Snapchat. If they don't care, I would wager that it's because they just don't understand the context,
[01:45:11.080 --> 01:45:15.960]   not that they don't want the privacy that it affords. The reason they're on Snapchat to begin with
[01:45:15.960 --> 01:45:21.400]   is because they want privacy. And to say they don't care, it's like I don't think that they
[01:45:21.400 --> 01:45:26.520]   go to Snapchat but don't care about privacy. I think they go and they just don't understand or
[01:45:26.520 --> 01:45:34.680]   haven't. I'm sorry to a little lag there. I think you're absolutely right. While it's easy,
[01:45:34.680 --> 01:45:39.080]   we can all be teenagers and go, "Oh, they really don't care. It's just the tech press." I totally
[01:45:39.080 --> 01:45:43.080]   agree that it's just the tech press talking about that. But they will care when the last 2
[01:45:43.080 --> 01:45:47.160]   digits of their parents phone number or their phone number leaks out and their parents find
[01:45:47.160 --> 01:45:52.520]   out about it or somebody who holds them accountable. Forget parents, let's just use accountability here.
[01:45:52.520 --> 01:45:57.160]   Right? So somebody who is going to hold that dick pick accountable to you,
[01:45:57.160 --> 01:46:01.560]   then you care on a micro level. Yeah, on a macro level, this probably doesn't affect
[01:46:01.560 --> 01:46:07.320]   Snapchat too much. But it does on a micro and a granular level when there is consequence to
[01:46:07.320 --> 01:46:13.000]   behavior and leaking something like this is inevitable. Mistakes happen. Failure to apologize
[01:46:13.000 --> 01:46:19.240]   or to be accountable for your own complicity in this leaking. At some point, some company will
[01:46:19.240 --> 01:46:24.280]   be held accountable by their users. I'm less upset by the fact that they didn't apologize
[01:46:24.280 --> 01:46:29.640]   than by the fact they didn't fix it. Yeah. That's actually more serious. They are releasing a new
[01:46:29.640 --> 01:46:35.400]   version of Snapchat where you can opt out of this flawed fine friends and they are rate limiting it
[01:46:35.400 --> 01:46:42.280]   so the bag I can't download as many as fast, but they have not changed the API which has the flaw in it.
[01:46:43.960 --> 01:46:50.040]   Man, that's tough because I understand where you're coming from, Leo, but if they were to fix it,
[01:46:50.040 --> 01:46:54.600]   then at some level, they are admitting that they're in the privacy business. And I believe
[01:46:54.600 --> 01:47:01.560]   up till this point, they haven't traded on privacy as one of their bedrock foundations.
[01:47:01.560 --> 01:47:09.400]   I don't know. It seems like that's a difficult promise to make, especially given in this
[01:47:10.280 --> 01:47:19.080]   NSA prevalent era of 2013 that we just experienced. Yeah. So on Christmas Eve, Gibson security
[01:47:19.080 --> 01:47:25.800]   publicly documented the API. This was security by obscurity that Snapchat was using. No one knew
[01:47:25.800 --> 01:47:31.160]   this whole existed. So we didn't worry about it. Gibson released it. Is Gibson at fault?
[01:47:31.160 --> 01:47:37.240]   They told Snapchat about it in August. As is often the case, White Hat sometimes get
[01:47:37.240 --> 01:47:41.960]   irritated when a company doesn't fix it and then they start telling more.
[01:47:41.960 --> 01:47:49.320]   Boking, sure. I don't know exactly who I blame, but it feels to me like the first thing
[01:47:49.320 --> 01:47:55.000]   Snapchat should do is fix it. That seems like more than a apology. That's what I'd like to see.
[01:47:55.000 --> 01:48:02.120]   I don't know. You don't have to ask my son and daughter, you Snapchat a lot. I'll do an informal
[01:48:02.120 --> 01:48:07.080]   survey to see if they've ever even heard of this. And actually, this is a weird
[01:48:07.080 --> 01:48:12.520]   space for me to even put my mind in because people are like, oh, Snapchat, that's for taking photos
[01:48:12.520 --> 01:48:18.760]   of boobies and setting them. It's not really not. It's not. It's a place where it's safe to do
[01:48:18.760 --> 01:48:24.040]   things that you'll regret. Not even that. I think the way my kids use it, and I've observed them
[01:48:24.040 --> 01:48:30.120]   using it, is it's the problem with stuff like Twitter and Facebook, it lives on. They want a
[01:48:30.120 --> 01:48:33.800]   place where they could take a picture that doesn't, that's not because they want to hide anything,
[01:48:33.800 --> 01:48:37.720]   but that doesn't have all that import to it. It doesn't have to be important. It could be a
[01:48:37.720 --> 01:48:43.640]   scoofy picture. And that's fine. I agree with Leo. I bet that's the vast majority of the pictures
[01:48:43.640 --> 01:48:49.800]   because I don't use it. But I have a good friend that used it. He's a dad and he's got three daughters,
[01:48:49.800 --> 01:48:54.040]   and they use it all the time, of course. But he just takes fun pictures of things and he sends
[01:48:54.040 --> 01:48:57.960]   it to him. And the pictures are just a little special, I guess, because they're ephemeral.
[01:48:57.960 --> 01:49:01.640]   They get to hold down and say, oh, my dad sent me something special. It's a little different than
[01:49:01.640 --> 01:49:07.320]   a Facebook. But as far as this whole trust thing goes, I think there's just general confusion,
[01:49:07.320 --> 01:49:11.960]   or people don't really think about it. Because, like, let's say the difference, let's say,
[01:49:11.960 --> 01:49:16.520]   between Snapchat and Facebook is that Facebook keeps a copy of everything on their servers,
[01:49:16.520 --> 01:49:20.200]   where Snapchat supposedly doesn't. But does it really matter?
[01:49:20.200 --> 01:49:21.080]   Supposedly they don't.
[01:49:21.080 --> 01:49:22.680]   The NSA has a copy of both.
[01:49:22.680 --> 01:49:25.240]   I guess, okay.
[01:49:25.240 --> 01:49:25.880]   I guess, okay.
[01:49:25.880 --> 01:49:31.320]   I think many people are not so worried about the NSA, and it does come down to, I think, trust.
[01:49:31.320 --> 01:49:36.840]   I'm critiquing their communication strategy, but I think that this communicates to a lot of people.
[01:49:36.840 --> 01:49:43.000]   No, maybe not to the teenagers who are using. Leo, you said import, right? That is the best
[01:49:43.000 --> 01:49:46.520]   way of putting it. There's just not a lot of weight on the content that I'm sharing.
[01:49:46.520 --> 01:49:52.360]   But that doesn't matter when it comes down to, you know, there may be so much velocity in Snapchat
[01:49:52.360 --> 01:50:00.040]   that it is unstoppable at this point. But allegedly, maybe I don't know storing or not storing or
[01:50:00.040 --> 01:50:06.520]   keeping or not keeping. At some point, the weight of not trusting and not knowing and not having a
[01:50:06.520 --> 01:50:12.200]   explicit statement that we do not store things, we delete things. This is gone.
[01:50:12.200 --> 01:50:18.280]   Like 4chan, it is when it's off the front page, it is gone. That is far more trustworthy of a
[01:50:18.280 --> 01:50:22.680]   statement than screw you. It happened. Moving on.
[01:50:22.680 --> 01:50:28.760]   Some security experts say that there's no safe way to implement a find friends feature,
[01:50:28.760 --> 01:50:32.920]   that that is inherently problematic. So in order to respond to this,
[01:50:32.920 --> 01:50:36.680]   Snapchat would have to remove the feature entirely. And that's something they're not
[01:50:36.680 --> 01:50:41.080]   willing to do because it is a big important part of this is to enter your phone number.
[01:50:41.080 --> 01:50:46.360]   And then what Snapchat does is it looks for your phone number in your friends contact list
[01:50:46.360 --> 01:50:52.280]   to see if they know each other. And that kind of functionality is inherently risky.
[01:50:52.280 --> 01:50:57.400]   So Snapchat would actually have to delete that from their capability. We've seen problems with
[01:50:57.400 --> 01:51:01.720]   the path at the same problem, upload your... Yeah. Or just say, guys, this is how we do it.
[01:51:01.720 --> 01:51:05.320]   Don't have an expectation of privacy. Right. Maybe that's it.
[01:51:05.320 --> 01:51:09.160]   And frankly, maybe my kids don't care. Maybe my kids don't care.
[01:51:09.160 --> 01:51:15.080]   Maybe my kids don't care. Or maybe their core business model isn't privacy. Maybe it's
[01:51:15.080 --> 01:51:21.480]   the ability to exchange low import photos. Yeah. Yeah. I should say maybe not their business model,
[01:51:21.480 --> 01:51:26.680]   but their value proposition to the consumer. Maybe that's why I find this lack of apology
[01:51:26.680 --> 01:51:34.280]   detestable. And that like, well, look, what you are offering me is counter to the hack that happened.
[01:51:34.280 --> 01:51:38.200]   I can trust you if you say, look, we're not entirely private. And yeah, we made mistakes.
[01:51:38.200 --> 01:51:43.080]   We're working on it. We're going to fix it. That's a trustworthy statement. But simply saying,
[01:51:43.080 --> 01:51:49.240]   nope, our value proposition is that you stay private. But except when we need your data.
[01:51:49.240 --> 01:51:55.160]   Right. I mean, when you start adding accepts to something, then exceptions run the game,
[01:51:55.160 --> 01:51:57.880]   run the table. We're going to run through a couple of top stories very quickly,
[01:51:57.880 --> 01:52:02.920]   including a new Kanye West themed cryptocurrency called coin. Yeah, west.
[01:52:02.920 --> 01:52:10.200]   This is not a joke. It just a moment. Don't be dogecoin is worth more. I think dogecoins
[01:52:10.200 --> 01:52:13.960]   worth a lot. And by the way, I do want to find out when we come back how to pronounce that.
[01:52:13.960 --> 01:52:19.240]   Because I don't know doggy. You see there in lies the problem. Our show today brought to you by
[01:52:19.240 --> 01:52:25.560]   gazelle.com. One thing I know for sure that gadget or do dad in your desk drawer or your closet is
[01:52:25.560 --> 01:52:32.440]   not getting more valuable. It's getting dusty and it's time to go to gazelle.com and get rid of it for
[01:52:32.440 --> 01:52:40.760]   money. Whether you have an old iPhone or a blackberry and HTC LG Motorola Nokia or Samsung phone,
[01:52:40.760 --> 01:52:46.600]   gazelle is the chance for you to sell your old stuff, get actual money for it. So you can get
[01:52:46.600 --> 01:52:53.240]   the new stuff. You got an old S3. Maybe you want to get a new S4, get 100 bucks for your old S3
[01:52:53.240 --> 01:52:57.640]   from gazelle. Now here's the beauty part. You're going to get a quote that's good for 30 days.
[01:52:57.640 --> 01:53:01.960]   You don't even have to pull the trigger. You can if you're thinking about getting a surface pro,
[01:53:01.960 --> 01:53:07.480]   maybe you too. Maybe you don't know, but you want to get rid of your old surface pro.
[01:53:07.480 --> 01:53:15.640]   Gazelle will give you a quote and lock it in for a full 30 days, giving you time to decide whether
[01:53:15.640 --> 01:53:19.560]   you want to get it, get the product, transfer your data over and then send it to gazelle.
[01:53:19.560 --> 01:53:24.760]   They'll send you a box. Is that true even when we're about to see like some big apple announcement?
[01:53:24.760 --> 01:53:29.880]   Now's the time. That just seems like, yeah, it seems like anytime you know you're within 30 days
[01:53:29.880 --> 01:53:36.520]   of some kind of an ounce. Just do it and just do it. They even buy broken iPhones and iPods.
[01:53:36.520 --> 01:53:40.680]   So there's a lot of people out there with crack devices. They will take the they can use it.
[01:53:40.680 --> 01:53:44.440]   Here's your here's the deal. Go to gazelle.com. Find out what your stuff is worth. When you decide
[01:53:44.440 --> 01:53:49.080]   to pull the trigger, they will send you a box prepaid mailer. They don't have to pay the postage.
[01:53:49.080 --> 01:53:53.320]   And when your device gets there, their experts will go over it, see what conditions and they'll
[01:53:53.320 --> 01:53:57.240]   even raise the value if it's in better condition than you thought it was. If you forget to wipe
[01:53:57.240 --> 01:54:02.360]   your data, no fear. They'll do it for you. And then they'll send you a check. You can get PayPal
[01:54:02.360 --> 01:54:06.760]   if you need it right away. This is my tip. If you buy a lot of stuff on Amazon, get the Amazon
[01:54:06.760 --> 01:54:15.000]   gift card. They'll bump it up 5%. GAZ, E-L-L-E. That's the place to go. If you've got old gadgets,
[01:54:15.000 --> 01:54:20.840]   you want to get rid of and get some cash for. Gazelle has now spent over $100 million.
[01:54:20.840 --> 01:54:27.400]   They've sent money out to over 700,000 customers for their old gadgets at Gazelle.
[01:54:28.600 --> 01:54:38.120]   Koine West. It is a cryptocurrency. I think it's based on the same technology that... Is it Doge,
[01:54:38.120 --> 01:54:46.920]   Doge, Dogga, Dye? How do you pronounce that Doge? Koine? I say Doge. You say Doge, but I don't know.
[01:54:46.920 --> 01:54:52.520]   You're in New Zealand. How do you say it? I always said doggy because I thought the background of
[01:54:52.520 --> 01:54:57.720]   it was involved with dogs. Is that mean? Is that mean? You know, there was a Iken has cheeseburger
[01:54:57.720 --> 01:55:05.080]   cat. And then doggy or Doge or Doge. How do you pronounce it? What does the urban know your meme?
[01:55:05.080 --> 01:55:10.680]   What do they say? Do they give you a pronunciation? There you go. Slang term for dog used to refer to
[01:55:10.680 --> 01:55:17.960]   a C primarily associated with pictures of Shiba Inus. Shiba Inus. Yeah. Yeah. Yeah. Those are those.
[01:55:17.960 --> 01:55:23.560]   That's the internet dog. Basically, basically, you get photos from Homestar Runner. Maybe the
[01:55:23.560 --> 01:55:27.960]   video will give us a tip here. I saw puppets. This must be educational.
[01:55:27.960 --> 01:55:31.960]   This cast fry.
[01:55:31.960 --> 01:55:41.080]   Like the bad Casio music. Yeah, it's Homestar Puppets. I'm almost done with this third quarter
[01:55:41.080 --> 01:55:50.760]   projection analysis spreadsheets and still no sign of... What is up my dog? Dog? Not your dog.
[01:55:50.760 --> 01:55:56.920]   Widerman, you crack me up. Crack me up. That's why you're my D-O-G.
[01:55:56.920 --> 01:56:01.560]   Your doge. What are you talking about? Uh oh. Is it doge?
[01:56:01.560 --> 01:56:06.120]   Widerman works in regional shipping management resources.
[01:56:06.120 --> 01:56:11.080]   Good one, Widerman. I mean... And this is why I hate you too right there.
[01:56:11.080 --> 01:56:14.440]   So that's doge, I think. I think we're gonna go with doge.
[01:56:15.400 --> 01:56:21.320]   Fine. Good enough for me. But I guess the meme for those of you who haven't seen it is basically,
[01:56:21.320 --> 01:56:26.360]   you got this man, I'm gonna use the word Gestalt again. Like what's going in the dogs
[01:56:26.360 --> 01:56:31.320]   minded in given moment based on the picture. But somebody made a currency based on it because
[01:56:31.320 --> 01:56:35.720]   apparently you can make a currency out of anything. Which to be honest, I think is kind of rad. I'm
[01:56:35.720 --> 01:56:41.080]   pro making currency out of stupid things. It's using, I presume, the light coin technology that
[01:56:41.080 --> 01:56:48.120]   Dogecoin is using. I think Coinier West is also using. We did a piece on the know-how. Robert
[01:56:48.120 --> 01:56:53.320]   Ballisare, did anyone have to build your own Dogecoin miner? Which probably could be used for Coinier West.
[01:56:53.320 --> 01:56:57.640]   Yeah, it's a three part piece. So they're gonna keep coming back to it to tell you how to
[01:56:57.640 --> 01:57:04.360]   mine Doge or any sort of cryptocurrency over time better and better and better and what to upgrade
[01:57:04.360 --> 01:57:10.120]   and what to swap out. Coinier West abuse January 11th. No word about when Kim Coin is coming in.
[01:57:10.120 --> 01:57:15.240]   The chat room is blowing up with suggestions of us making twits own currency.
[01:57:15.240 --> 01:57:21.240]   Oh, should coins Brian bucks. Yeah, because we joked about this on all of our other programs.
[01:57:21.240 --> 01:57:26.920]   I don't know. You're already got your own wine. I would say go for it. Go for it. And this
[01:57:26.920 --> 01:57:31.480]   have to be a point. Yeah, that would be pretty amazing. I think I think BB coin.
[01:57:31.480 --> 01:57:38.280]   Yeah, why not man? Let's do it. You know, Bitcoin, Bitcoin tumbled when China announced that it was
[01:57:38.280 --> 01:57:42.840]   going to put restrictions on Bitcoin, but it's come back. It is now over a thousand bucks again.
[01:57:42.840 --> 01:57:52.440]   According to Mount Gox. I don't know. What if what if Bitcoin was meant to be a pump-a-dump scheme?
[01:57:52.440 --> 01:57:57.720]   I think it is succeeding beside itself. What if dance as if that's in question?
[01:57:57.720 --> 01:58:02.360]   Well, I mean, the origin as we all know, the origin of Bitcoin is actually really
[01:58:02.360 --> 01:58:07.480]   fascinating. A lot of people think it was the NSA or a consortium of the NSA and you know,
[01:58:07.480 --> 01:58:12.120]   a friend of mine from blip TV and I over the summer, he and I created a little Bitcoin
[01:58:12.120 --> 01:58:18.200]   application that lets you send things to each other. And in that process did a lot of research
[01:58:18.200 --> 01:58:23.720]   into the guts of Bitcoin. And yeah, what if? Yeah, definitely. Well, Satoshi Nakamoto,
[01:58:23.720 --> 01:58:29.000]   the person or persons who created Bitcoin presumably has a lot of Bitcoin hanging out
[01:58:29.000 --> 01:58:33.480]   in their pocket because like any pyramid scheme, the earlier you got in on Bitcoin,
[01:58:33.480 --> 01:58:38.920]   the more likely you were to generate coins. Steve Gibson, who was only a couple of years ago,
[01:58:38.920 --> 01:58:44.040]   did his first Bitcoin mining. He got 50 Bitcoins like that. That's 50. Well, the Winkel by twins have...
[01:58:44.040 --> 01:58:48.360]   They've been investing. Yeah, they have like 20% of the market. They say it's going to be worth
[01:58:48.360 --> 01:58:55.800]   $40,000 in their dreams. I mean, the problem is Bitcoin could go to zero just like that.
[01:58:55.800 --> 01:59:00.840]   Have you seen the Reddit? Yeah, the big day of it. So, so, so everything could. I don't know.
[01:59:01.480 --> 01:59:07.960]   There's almost an honesty to it. At least you know, the problem with with dollars is that you're
[01:59:07.960 --> 01:59:14.040]   you have them based on the fantasy that there's a magical grandfather that's going to make sure
[01:59:14.040 --> 01:59:18.360]   they're worth something, at least with Bitcoin. You know you're buying nothing. You know, it's
[01:59:18.360 --> 01:59:23.080]   honest. And it's like, yeah, bro, you're buying you're buying a number. Good luck. Hopefully that
[01:59:23.080 --> 01:59:27.240]   number will be worth something. I know you're a libertarian, but I mean, it isn't exactly a
[01:59:27.240 --> 01:59:33.560]   magical grandfather. It's called the US government. Whatever until that guy falls down.
[01:59:33.560 --> 01:59:38.360]   Just explain that to my Confederate dollars. All right. Okay. All right.
[01:59:38.360 --> 01:59:44.920]   Speaking of which, you can now use Bitcoin to pay for virtual goods, virtual money for
[01:59:44.920 --> 01:59:50.280]   virtual goods in Farmville, Cityville, and other web games. Zynga has made a deal with BitPay.
[01:59:50.280 --> 01:59:54.920]   So now you got something you could do with your Bitcoin. You could buy...
[01:59:54.920 --> 02:00:01.160]   Tell you what, the imaginary goods. BitPay makes it real easy. We started accepting Bitcoin on
[02:00:01.160 --> 02:00:06.280]   scamstuff.com just through BitPay. It's a Shopify offers it and you just click a button and you're
[02:00:06.280 --> 02:00:11.640]   like, yeah, I'll take your magic and get money. Yeah. No, no, no. They immediately,
[02:00:11.640 --> 02:00:16.680]   the moment they do the transaction, they translate it to US dollars and throw it into your account.
[02:00:16.680 --> 02:00:21.960]   See, in my eye, so we take Bitcoin donations on our front page. And I just, my attitude is,
[02:00:21.960 --> 02:00:25.480]   it's free money. I just got to... We got seven Bitcoin so far. I just hold it, right?
[02:00:25.480 --> 02:00:32.600]   I sold out. I cashed in at a grand. I bought mine at under $40. Oh, you may. When I hit a grand,
[02:00:32.600 --> 02:00:37.400]   I was like, nope. That's... And that money was real money. I spent it with real hands. But what
[02:00:37.400 --> 02:00:43.720]   you feel stupid when if Bitcoin gets to 10 or 20 or $30,000? No, because I cashed in at $1,000
[02:00:43.720 --> 02:00:50.360]   with real cash money in my hands. Okay. Now, stop using that term real cash money. What you're
[02:00:50.360 --> 02:00:55.480]   saying in effect is, I got rid of those imaginary things for these imaginary things.
[02:00:55.480 --> 02:01:00.280]   Yes, but those imaginary things can be paid, can use to pay your taxes, can be used all around
[02:01:00.280 --> 02:01:05.640]   the world to buy oil. I mean, there is some... Admittedly, it's all fiat currency. It's all
[02:01:05.640 --> 02:01:12.520]   imaginary, Brian, but some are more imaginary than others. I mean, some have a longer track record,
[02:01:12.520 --> 02:01:15.880]   but if we're going to play that game, then all of a sudden, we're back to like, why are we
[02:01:15.880 --> 02:01:21.800]   giving gold ingots to each other? Yeah. Cash machines being... The bigger that the Bitcoin
[02:01:21.800 --> 02:01:29.720]   bot was not... Siggin? In fact, Brian, I'll play this with you.
[02:01:29.720 --> 02:01:35.880]   What does he do? In fact, I'll use some of that Bitcoin money, Brian, to drink a real beer with
[02:01:35.880 --> 02:01:41.000]   you. And then we can babble about this all night. Because I love my god. This sounds awesome. Dude,
[02:01:41.000 --> 02:01:48.600]   you had me at beer. This sounds awesome. Go. And also on bike again? And beer? Yes, Gary.
[02:01:48.600 --> 02:01:53.800]   And and Valtrex. Don't forget my anti-herpes medicine. You're feeling good. Silk road is down.
[02:01:53.800 --> 02:02:01.720]   So in 1964 at the World's Fair, which I remember very well, I was, I think, six or seven, no,
[02:02:01.720 --> 02:02:07.560]   I was eight years old. And I remember AT&T had the picture phone. You know, someday, by the year
[02:02:07.560 --> 02:02:14.360]   1970, you will be talking on picture phones. They asked Isaac Asimov what the world would look like.
[02:02:14.360 --> 02:02:21.400]   In 50 years, he wrote in the New York Times that by now 2014,
[02:02:21.400 --> 02:02:27.640]   gadgetry will continue to relieve mankind of tedious jobs. Kitchen units will be devised
[02:02:27.640 --> 02:02:32.760]   that prepare auto meals, heating water and converting it to coffee, toasting bread,
[02:02:32.760 --> 02:02:38.600]   frying, poaching or scrambling eggs, grilling bacon and so on. Breakfast will be ordered the night before
[02:02:38.600 --> 02:02:44.040]   to be ready by a specified hour the next morning. Did they not have toasters and back then?
[02:02:44.040 --> 02:02:49.160]   Didn't happen. But now this one did. Communications will become site sound. You will see,
[02:02:49.160 --> 02:02:53.880]   as well as hear the person you telephone. The screen can not only be used to see the people you
[02:02:53.880 --> 02:02:58.440]   call, but also for studying documents and photographs and reading passages from books.
[02:02:58.440 --> 02:03:04.520]   Synchronous satellites hovering in space will make it possible for you to direct dial any spot
[02:03:04.520 --> 02:03:09.560]   on the earth, including weather stations in Antarctica, undersea cables, but same thing.
[02:03:09.560 --> 02:03:16.680]   Men will continue to withdraw from nature in order to create an environment that will suit
[02:03:16.680 --> 02:03:22.200]   them better. By 2014, electro luminescent panels will be in common use.
[02:03:23.400 --> 02:03:28.920]   Ceilings and walls will glow softly in the variety of colors that will change at the touch of a button.
[02:03:28.920 --> 02:03:35.400]   Robots will be neither, robots will be neither common nor very good in 2014, but they will be in
[02:03:35.400 --> 02:03:41.160]   existence. That's right. I guess I think that might be my favorite of his predictions in that it
[02:03:41.160 --> 02:03:45.960]   was accurate in that the way it constrained itself, that it didn't make a blanket like,
[02:03:45.960 --> 02:03:51.160]   we'll all have magic robots doing everything. The fact that he specifically said, we will see the
[02:03:51.160 --> 02:03:58.360]   rudiments by this point. The appliances of 2014 will have no electric cords. Of course,
[02:03:58.360 --> 02:04:03.240]   for they will be powered by long lived batteries running on radio isotopes.
[02:04:03.240 --> 02:04:10.600]   Highways will have passed their peak by 2014, and there'll be increased emphasis on transportation
[02:04:10.600 --> 02:04:16.920]   that makes the least possible contact with surface. Even ground travel increasingly take to the air
[02:04:16.920 --> 02:04:23.560]   a foot or two off the ground. You can see how hard it is to figure the future.
[02:04:23.560 --> 02:04:29.480]   He did nail one thing. The world population will be 6.5 billion. The population of the US will be
[02:04:29.480 --> 02:04:38.040]   350 million. Almost on the nose. I guess you could predict that. It's a pretty consistent.
[02:04:38.040 --> 02:04:43.560]   In your growth? No, I would actually say not because one of the biggest stories of the last
[02:04:43.560 --> 02:04:51.400]   10 years has been the popular prediction in the 1960s. If you read population bomb or whatever,
[02:04:51.400 --> 02:04:55.000]   it was like, we're all screwed. It's going to be 13 million and we're all going to die.
[02:04:55.000 --> 02:04:59.080]   But for him to predict essentially the leveling off of populations,
[02:04:59.080 --> 02:05:03.400]   specifically both in the United States and worldwide, I think was a really good one.
[02:05:03.400 --> 02:05:08.440]   I wish these guys Arthur C. Clark did the same in Walter Crank. I wish you could get Arthur C.
[02:05:08.440 --> 02:05:12.680]   Clark and Isaac Asimov at today's CES and just hear what they think.
[02:05:12.680 --> 02:05:19.320]   Hey, it's. I got a question before we wrap up here because I've been thinking about
[02:05:19.320 --> 02:05:26.600]   I don't know, New Year or I'll get older, whatever, closer to dying and becoming death.
[02:05:26.600 --> 02:05:35.880]   Here's what is exciting about in all of human history, the fact that we live in this generation.
[02:05:36.600 --> 02:05:41.800]   One thing that sticks with me is if I could trade right now, just going back 20 years,
[02:05:41.800 --> 02:05:49.560]   would you trade your degraded sense of health, but in exchange have to give up the technology
[02:05:49.560 --> 02:05:53.720]   that we've seen for any amount of time? Would you be 20 years younger but give up
[02:05:53.720 --> 02:05:59.160]   the last 20 years of advancement in technology? No, yeah.
[02:06:01.960 --> 02:06:08.280]   And the reverse of that is how excited am I to become 60 and then 80 years old,
[02:06:08.280 --> 02:06:11.240]   knowing that concurrent with that, I'll get all the complete
[02:06:11.240 --> 02:06:16.440]   dope ass advancements that we're going to get. I'm going to be 60 in three years, Brian.
[02:06:16.440 --> 02:06:22.200]   No fun at all. Dude, okay. Now, would you trade? Would you trade? I mean, let's say,
[02:06:22.200 --> 02:06:27.560]   and this is serious. Would you go back to, so what, you're 57? So would you go back to 37?
[02:06:27.560 --> 02:06:33.880]   Look at like me, but can I look like you give up that? Yes, you can only look like me. That's,
[02:06:33.880 --> 02:06:39.480]   that's the penalty. You would have to give up the iPhone. You'd have to give up broadband.
[02:06:39.480 --> 02:06:44.440]   You'd have to give up the Twits Studio. You'd have to, I mean, would you?
[02:06:44.440 --> 02:06:47.320]   Didn't he actually already do that 20 years ago?
[02:06:47.320 --> 02:06:55.960]   Did they have Viagra 20 years ago? I'm curious. No, it was, it was, it was brand new.
[02:06:57.320 --> 02:07:02.120]   Do you have to give up? I think like 98. How do you know that?
[02:07:02.120 --> 02:07:09.480]   What fun? I don't know. I, that's a very good question. I think as you get older,
[02:07:09.480 --> 02:07:14.760]   sometimes the thought of going back in time, even if you had to relive all of the technological
[02:07:14.760 --> 02:07:20.120]   advances of the last 20 years, one by one, I would still do it. I'd like to, I don't know,
[02:07:20.120 --> 02:07:23.720]   though. I love the fact that I'm living in the future. Isn't that cool? Isn't that cool?
[02:07:23.720 --> 02:07:31.560]   Not me, man. Yeah. And no time in human history and all of humanity, have we had the ability to get
[02:07:31.560 --> 02:07:38.280]   to know each other better as humans over time. This is, this is the greatest time in all of history
[02:07:38.280 --> 02:07:44.440]   because we can, humans are inherently social. We are inherently drawn together. And now we have
[02:07:44.440 --> 02:07:50.600]   the tools, we've created the tools that facilitate us getting to know each other better over time,
[02:07:50.600 --> 02:07:56.760]   not degrading our friendships and relationships. As we grow and mature, I now have the opportunity
[02:07:56.760 --> 02:08:03.960]   to know my friends and my family in ways that my ancestors never did. And that alone is worth
[02:08:03.960 --> 02:08:08.760]   everything. I just hope I may, I'd like to make it another 20 or 30 years because I'm excited
[02:08:08.760 --> 02:08:13.720]   about what we might see in the next one. I think the singularity is close. I'd like to be there
[02:08:13.720 --> 02:08:18.600]   for that. Do you think it's near? Do you think we'll have it in our lifetime? But Jeron Lanier says
[02:08:18.600 --> 02:08:21.880]   we don't want that, right? He has very interesting reasoning. Yeah.
[02:08:21.880 --> 02:08:25.960]   Jeron's an interesting fella. I'm not sure I agree with him. You know,
[02:08:25.960 --> 02:08:31.080]   Tekko, what Dan and Brian were saying, and there was that one last Azimoth prediction that you didn't
[02:08:31.080 --> 02:08:38.120]   get to, which was kind of very weird prediction that there would be this major disease of boredom.
[02:08:38.120 --> 02:08:44.120]   And actually, I think something that he didn't foresee, which is a kind of innovative way that
[02:08:44.120 --> 02:08:51.000]   we've all ended up using technology and smartphones and everything. It actually has made us more human
[02:08:51.000 --> 02:08:58.920]   because two of the key aspects to being human are being curious and communicating with fellow humans.
[02:08:58.920 --> 02:09:05.800]   And all this technology basically allows us, allows our curiosity to go crazy and allows us to
[02:09:05.800 --> 02:09:15.000]   communicate better in a new ways than ever before. So this idea of boredom actually drives a lot
[02:09:15.000 --> 02:09:19.320]   of what we do and has ended up making us more human. So I'm with you guys. I think we're at
[02:09:19.320 --> 02:09:22.840]   the perfect time and the perfect place. Yeah, I really wouldn't want to be anywhere else.
[02:09:22.840 --> 02:09:29.000]   It's been fun. Thank you guys. Trey Rackliff, you're the greatest. Look forward to finding out
[02:09:29.000 --> 02:09:33.800]   more about the Arkanomites at the Arkanom.com and of course Trey's website. Stuckincustoms.com
[02:09:33.800 --> 02:09:38.600]   and he's always posting great stuff on Google+ Facebook and elsewhere. Nice to see you again,
[02:09:38.600 --> 02:09:46.280]   Trey. Good to see you Leo. Thanks so much. Dan Patterson is doing all sorts of interesting stuff.
[02:09:46.280 --> 02:09:50.520]   Soon to head to the Middle East to teach people how to use encryption to protect
[02:09:50.520 --> 02:09:54.360]   them, journalists how to use encryption to protect themselves and their sources online. What a
[02:09:54.360 --> 02:10:00.200]   great thing that is, Dan. Well, it was great to be here, Leo. And Trey and Brian, it was really
[02:10:00.200 --> 02:10:04.840]   great to meet you and talk with you this evening. So fun. We'll have you back real soon.
[02:10:04.840 --> 02:10:12.200]   tanookilabs.com. And looks like we got Trey Rackliff's family in there. Hi everybody.
[02:10:12.200 --> 02:10:19.080]   Oh, what? Say hello Uncle Leo. I'm going to have a contest. I need to get my kids in there.
[02:10:19.080 --> 02:10:22.760]   Get your kids in there. Do they love New Zealand? Do they have a great Christmas?
[02:10:22.760 --> 02:10:25.560]   Yes. It's really fun.
[02:10:26.600 --> 02:10:33.880]   Hey, you got an Xbox one. Is it weird? Wow. Is it weird having Christmas in the summer?
[02:10:33.880 --> 02:10:41.000]   Like is that messing you guys up? Yeah, it's super freaky. It's because it's bright until
[02:10:41.000 --> 02:10:45.480]   midnight here. And so you never get to see the Christmas lights. You have to come in at 3am
[02:10:45.480 --> 02:10:49.640]   to see the Christmas lights. That takes some of the fun out of it, doesn't it? Yeah.
[02:10:49.640 --> 02:10:55.640]   Trey, it's great to see you and your wonderful family down there in Queenstown, New Zealand.
[02:10:56.520 --> 02:10:59.480]   It's a this and look, this is amazing. I mean, we're what?
[02:10:59.480 --> 02:11:04.520]   15,000 miles separated or something. I don't know even what the distance is. But here we are.
[02:11:04.520 --> 02:11:07.720]   We're talking in real time. I'm seeing the family. We could have a conversation like this.
[02:11:07.720 --> 02:11:14.360]   It's great. Dan Patterson's in New York City. Brian Brushwood in Austin, Texas. It's great to
[02:11:14.360 --> 02:11:19.000]   have you all. I guess that's the thing. Like, like, it's weird. I don't know if a lot of people
[02:11:19.000 --> 02:11:25.080]   know this, but Justin and I, when we started doing before in a SWBB live show, I would say in the first
[02:11:25.080 --> 02:11:31.880]   two years of our online trying to do comedy experience, we saw each other physically, maybe five, six times.
[02:11:31.880 --> 02:11:38.280]   Wow. That's it. Like, like, it was weird to meet him in person and be, you know, someone who I,
[02:11:38.280 --> 02:11:42.440]   you know, regarded as one of my closest friends and I'm like, oh, that's right. You have that
[02:11:42.440 --> 02:11:45.000]   thing on your eyebrow. I think I did. I did. I did. I did.
[02:11:45.000 --> 02:11:54.840]   We live a very interesting time in a mail. What's that? Oh, I got mine too. We're excited.
[02:11:54.840 --> 02:12:01.080]   Yeah. We're excited. The new Daniel Suarez book. I've read the pony. Yeah. We're going to get Daniel
[02:12:01.080 --> 02:12:06.360]   on to talk about it on triangulation. I got mine too. It comes out in about a month. That's not
[02:12:06.360 --> 02:12:11.880]   audible yet, right? No. No, it's not even out yet. Yeah. Doesn't exist until audible. Yeah. Whatever.
[02:12:11.880 --> 02:12:18.200]   And you know what? It's a, John just read. It's called influx and it sounds really good. I love
[02:12:18.200 --> 02:12:24.920]   the premise, which is that we've already discovered all those amazing things, fusion power,
[02:12:24.920 --> 02:12:31.240]   genetic enhancements, artificial intelligence, cure for disease, extended human life. But there's
[02:12:31.240 --> 02:12:36.760]   this Bureau of Technology Control that keeps a lid on it because they didn't think it would
[02:12:36.760 --> 02:12:42.520]   upset society too much. The future's already here. Maybe Azimov was right.
[02:12:42.520 --> 02:12:45.880]   That sounds like a book like this. Is that a premise? Is that a premise?
[02:12:45.880 --> 02:12:50.920]   Libertarian crap. I love that. Those gosh darn government bureaucrats.
[02:12:50.920 --> 02:12:57.640]   And once again, it's your bad more Bitcoin. Thank you, Brian. Thank you, Brian. You can catch Brian
[02:12:57.640 --> 02:13:03.160]   on NSFW every week right here. Do watch his New Year's Eve show. I'm a little biased because I
[02:13:03.160 --> 02:13:08.520]   was on it, but that was an awfully fun show. A lot of fun. And we'll see you. You're still on
[02:13:08.520 --> 02:13:14.360]   Tuesday, right? You haven't moved. No, everything's good. And don't forget the comedy records. The
[02:13:14.360 --> 02:13:20.600]   number one comedy records in the world, the scam school store where you can buy stuff like lockpicks
[02:13:20.600 --> 02:13:25.960]   and other stuff. Yeah, other stuff. Scam stuff.com. But more importantly,
[02:13:25.960 --> 02:13:33.000]   night attack one night attack two and night attack live. This was 2013 was an amazing year, Leo.
[02:13:33.000 --> 02:13:38.680]   And I've said this before, said it on the live stream, but I'm so thankful that NSFW has been
[02:13:38.680 --> 02:13:44.520]   made available to us as a platform for Justin and I to try to work out our comedy ramblings
[02:13:44.520 --> 02:13:49.000]   that seem to be do do fairly well. And I owe it all to you. Thanks very funny.
[02:13:49.000 --> 02:13:54.680]   Working is it on it's on iTunes, right? Sure. Is that where you prefer we'd buy it?
[02:13:54.680 --> 02:14:03.400]   Uh, yeah, I don't care. Amazon. Yeah, Amazon's fine. Go to go to Amazon. Just look up night attack.
[02:14:03.400 --> 02:14:10.200]   You'll hear hilarious stories of me frolicking naked in a fountain in downtown Austin,
[02:14:10.200 --> 02:14:16.360]   not for the children, not for the weak of mind. It is explicit. Yes, for the weak of mind. That's
[02:14:16.360 --> 02:14:23.000]   what I call my children. I'm sorry. You are of the weak of mind. I'm just going to read you the
[02:14:23.000 --> 02:14:32.440]   titles of the first night attack. Mexican Hitler, high stakes with the EA fat kid Justin back to
[02:14:32.440 --> 02:14:34.680]   Mexican Hitler and then sweating to the fuhrer.
[02:14:34.680 --> 02:14:44.040]   Jeez. Stuck on a theme. Yeah. Yeah. It goes on. Uncle Bilbo missed call. It goes on. There's more
[02:14:44.040 --> 02:14:49.560]   of the same. If, uh, yeah, let's put it this way. Almost if twerking bothers you,
[02:14:49.560 --> 02:14:53.720]   you shouldn't get night attack. Yeah, probably not. Probably not. Probably not.
[02:14:53.720 --> 02:14:56.680]   Hobo Joe, Johnny jerk. Special massage.
[02:14:58.200 --> 02:15:04.200]   I mean, do you miss special massage? By the way, just tell you what that will tell you. Special
[02:15:04.200 --> 02:15:11.560]   massage is the painfully awkward tale of when I went to do a TV special in Indonesia and they had,
[02:15:11.560 --> 02:15:20.840]   they had a massage parlour upstairs and the awkward, almost angry negotiations in which
[02:15:20.840 --> 02:15:26.200]   someone gave me a high pressure sale. You want special massage? You want special massage?
[02:15:26.200 --> 02:15:32.520]   No, I just want to relax. No, you want special massage. Exactly. You're like, you're very strong.
[02:15:32.520 --> 02:15:39.320]   I was like, okay. I fist like monkey. You want special massage.
[02:15:39.320 --> 02:15:45.400]   Can we call this episode? Missed like monkey? Yeah, sure why not.
[02:15:45.400 --> 02:15:51.720]   Thank you guys. We do a twit. We have a move to it. We'll continue to do it Sunday afternoon.
[02:15:51.720 --> 02:15:58.680]   It's 3 p.m. Pacific 6 p.m. Eastern Time 2300 UTC on twit.tv. Please join us live. Love it if you do.
[02:15:58.680 --> 02:16:02.360]   But of course, we make on-demand audio and video of all of our shows available after the fact on
[02:16:02.360 --> 02:16:07.240]   our website, twit.tv or wherever. FinderNet casts are aggregated and distributed to you
[02:16:07.240 --> 02:16:14.680]   via the internet, such as iTunes. I'll be gone tomorrow. Going to go to the new media expo. If
[02:16:14.680 --> 02:16:22.040]   you happen to be in Vegas, come by. Say hi. Otherwise, I'll see you Tuesday. What?
[02:16:22.040 --> 02:16:33.560]   You're going to stream my panels? Oh good. 9 a.m. Tomorrow? Oh God. Another twit. It's in the can.
[02:16:33.560 --> 02:16:35.480]   Thank you everybody.
[02:16:35.480 --> 02:16:44.200]   Do you want a twit? All right. Do you want a twit, baby? Do you want a twit? All right. Do you want a twit, baby?
[02:16:44.200 --> 02:16:56.280]   And gentlemen, I am ready to go to Vegas. I have my brain mask ready to go to Vegas.
[02:16:56.280 --> 02:17:00.280]   I will be wearing this on the airplane. You think they'll TSA-
[02:17:00.280 --> 02:17:05.480]   I'm sure you're wondering. Yes. I wear this mask. I live in the darkness.
[02:17:05.480 --> 02:17:11.240]   That's pretty nice. I am twits reckoning.
[02:17:11.240 --> 02:17:15.080]   Gotham is dead. Hello.
[02:17:15.080 --> 02:17:44.080]   [ Silence ]

