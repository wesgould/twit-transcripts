;FFMETADATA1
title=Benji's Bag of Dongles
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=635
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:05.560]   It's time for Twit this weekend tech. Great panel for you. Ben Pars here. Christina Warren's
[00:00:05.560 --> 00:00:11.400]   back. Micah Sargent from Mobile Nations. We're going to talk about addictive algorithms.
[00:00:11.400 --> 00:00:17.560]   Is it your fault or Facebook's fault? Google's move towards Bluetooth earbuds. Is it the
[00:00:17.560 --> 00:00:24.200]   end of the headphone, Jack? And another IRS Equifax story that's just going to make your
[00:00:24.200 --> 00:00:38.580]   head spin. It's all coming up next. On Twit. Netcast you love. From people you trust. This
[00:00:38.580 --> 00:00:52.120]   is Twit. Bandwidth for this weekend tech is provided by cash fly at CACHEFLY.com. This
[00:00:52.120 --> 00:01:02.560]   is Twit this week at Tech. Episode 635 recorded Sunday October 8th 2017. Benji's bag of dongles.
[00:01:02.560 --> 00:01:06.720]   This week at Tech is brought to you by Tracker, a coin size tracking device that pairs with
[00:01:06.720 --> 00:01:11.840]   your smartphone and keeps you from losing your most valued possessions. Visit thetracker.com
[00:01:11.840 --> 00:01:19.520]   right now and enter the promo code TWIT to save 20% off any order. And by Fracture, a
[00:01:19.520 --> 00:01:23.960]   photo decor company that prints your photos directly onto glass and gets delivered to
[00:01:23.960 --> 00:01:30.040]   your door ready to display right out of the box. Visit fracture.me and use the code TWIT15
[00:01:30.040 --> 00:01:36.680]   at checkout to get 15% off your first order. And by ZipRecruiter. Are you looking to hire
[00:01:36.680 --> 00:01:41.480]   a tech professional? With ZipRecruiter you can post to 100+ job boards including social
[00:01:41.480 --> 00:01:46.920]   networks all with a single click, screen, rate and hire the right candidates fast. Try
[00:01:46.920 --> 00:01:54.480]   ZipRecruiter free at zippercruder.com/twit. And by Rocket Mortgage. By Quick and Loans,
[00:01:54.480 --> 00:01:58.920]   Home plays a big role in your life that's why Quick and Loans created Rocket Mortgage.
[00:01:58.920 --> 00:02:03.240]   It lets you apply simply and understand the entire mortgage process fully so you can be
[00:02:03.240 --> 00:02:13.520]   confident you're getting the right mortgage for you. Get started at rocketmortgage.com/twit2.
[00:02:13.520 --> 00:02:18.240]   It's time for TWIT. This week in Tech, the show we cover the latest tech news, we have
[00:02:18.240 --> 00:02:27.840]   assembled an odd panel today. I think this is going to be very interesting. To my left,
[00:02:27.840 --> 00:02:34.560]   Mr. Ben Parr, author of Captivology, Science of Capturing People's Attention. I first met
[00:02:34.560 --> 00:02:41.400]   Ben when he was at Mashable. You left very kind of famously left Mashable to pursue
[00:02:41.400 --> 00:02:47.320]   investing startups. How's it going? It seems to be doing well. Octane.ai is your new thing.
[00:02:47.320 --> 00:02:51.600]   What is that? It is a company that lets you communicate with your customers over Facebook
[00:02:51.600 --> 00:02:57.000]   Messenger. You were showing me how L'Oreal uses it. L'Oreal or famous people. Yep. Like
[00:02:57.000 --> 00:03:06.440]   Maroon 5, 30 seconds some more. I went from this journalism to the book to investing to
[00:03:06.440 --> 00:03:14.320]   the startup. I do a lot of things. I think a lot of people in tech journalism look and
[00:03:14.320 --> 00:03:20.360]   feel like we're on the sidelines watching all these people make billions of dollars.
[00:03:20.360 --> 00:03:25.200]   I think there's not a few of us. I do not have this problem but who say I want to do
[00:03:25.200 --> 00:03:29.960]   that? You do see people sometimes leave and say maybe not for the money. I don't think
[00:03:29.960 --> 00:03:33.680]   you did it for the money but to do it because I want to make something. I want to be in
[00:03:33.680 --> 00:03:40.160]   the battle instead of watching the battle. Mashable was an accident for me because I was studying
[00:03:40.160 --> 00:03:45.920]   entrepreneurship college and took entrepreneurship courses at Northwestern in Chicago and then
[00:03:45.920 --> 00:03:50.960]   I moved out and I just got lucky with the Mashable thing happening. I got recommended,
[00:03:50.960 --> 00:03:56.720]   I got articles, I got to join Christina. Ladies and gentlemen, Christina Warren's here. This
[00:03:56.720 --> 00:04:03.400]   is odd too because we haven't talked to Christina since she left publishing, writing, journalism
[00:04:03.400 --> 00:04:11.000]   and became a Microsofty senior cloud developer advocate at Microsoft and now a big superstar
[00:04:11.000 --> 00:04:18.360]   on Channel 9 Microsofts in house TV system. What do you do? I don't know about Superstar.
[00:04:18.360 --> 00:04:24.040]   It's new actually. For the first three or four months that I was at Microsoft, I was a senior
[00:04:24.040 --> 00:04:30.280]   content PM on a product called Microsoft Virtual Academy which is free online training in a
[00:04:30.280 --> 00:04:36.200]   variety of subjects targeted to developers and IT pros and as of last week, I'm now on the
[00:04:36.200 --> 00:04:41.640]   cloud developer advocate team which is a new team at Microsoft that basically we kind of sit
[00:04:41.640 --> 00:04:47.480]   between PMs and I guess like what you which traditionally call evangelists and the idea is
[00:04:47.480 --> 00:04:52.040]   basically for us to kind of communicate with the public. We have a they've hired a ton of really
[00:04:52.040 --> 00:04:56.120]   smart people from the community and from within Microsoft to kind of find out from customers what's
[00:04:56.120 --> 00:05:01.160]   the stuff that you need, what's important to you, listen to their feedback, be part of the community
[00:05:01.160 --> 00:05:05.000]   and then bring that stuff back to the people who are actually making the products. And then my
[00:05:05.000 --> 00:05:09.800]   role is as I'm working a lot with the video teams on Channel 9 and with the docs team and I'll be
[00:05:09.800 --> 00:05:14.760]   creating a lot of videos for Channel 9 going to events also maybe working with some of the other
[00:05:14.760 --> 00:05:19.640]   cloud developer advocates to you know visually kind of you know bring stuff out there. So that's
[00:05:19.640 --> 00:05:24.440]   that's my new job. So how is it working at Microsoft? I mean from within now you're seeing it from
[00:05:24.440 --> 00:05:28.920]   within. Is it what you imagined or is it different from how you imagined or?
[00:05:28.920 --> 00:05:34.360]   Well I didn't really have a lot of I wasn't really sure you know when I started when I got
[00:05:34.360 --> 00:05:37.640]   the job offer it was kind of or when I got the first I guess like dealer to say
[00:05:37.640 --> 00:05:42.120]   would you be interested in this? So they approached you they had hunted you.
[00:05:42.120 --> 00:05:45.720]   Yeah they had hunted me and because I'll be honest I don't know if I would have been
[00:05:45.720 --> 00:05:50.760]   confident enough to even think oh with my journalism background I can be a PM and I can
[00:05:50.760 --> 00:05:55.720]   you know not have a role that's in comms or marketing and there's not not to say that there's
[00:05:55.720 --> 00:05:59.080]   anything wrong with those and people who do that stuff are incredible but I just always thought
[00:05:59.080 --> 00:06:05.000]   that if I wasn't going to be doing something like that that I wouldn't have a place to fit at a
[00:06:05.000 --> 00:06:09.400]   bigger tech company and so when they approached me and I kind of learned more about my first role
[00:06:09.400 --> 00:06:13.880]   and now that I'm in my new team kind of learning about what I was doing I was like well this is
[00:06:13.880 --> 00:06:18.920]   interesting but when I got to Microsoft you know what I found is and we've seen that I saw this as
[00:06:18.920 --> 00:06:23.640]   an outsider as a reporter how you know the company has kind of changed in the last few years the
[00:06:23.640 --> 00:06:29.800]   new CEO kind of a new credit to such an Adele for really re-steering the ship and doing I think
[00:06:29.800 --> 00:06:35.400]   a brilliant job of it deserves some kind of tremendous kind of and I think you see it internally too
[00:06:35.400 --> 00:06:39.960]   where even people who've been there a long time kind of comment on how you know it's a newer Microsoft
[00:06:39.960 --> 00:06:44.760]   and obviously you know every big company has you know they're kind of microcosms within
[00:06:44.760 --> 00:06:48.840]   different departments and different teams but the teams that I've observed you know it's it's very
[00:06:48.840 --> 00:06:53.240]   different than what I expected you know when you when I've talked people who've worked at other tech
[00:06:53.240 --> 00:06:59.160]   companies a lot of times there's like no you know balance between work life and personal life and
[00:06:59.160 --> 00:07:03.000]   I'm sure that on some teams that's probably true but at least where I've been and people I work
[00:07:03.000 --> 00:07:08.200]   with you know people leave at a normal time every day which is great to see and and it's not one of
[00:07:08.200 --> 00:07:16.520]   those like you know when you expected nine to five really which as a journalist like I didn't have
[00:07:16.520 --> 00:07:22.200]   nine to five right you know and so it's weirdly that I had to go to like work at a big tech company
[00:07:22.200 --> 00:07:28.360]   work for you know a giant corporation to have like an actual place to have you know free time
[00:07:28.360 --> 00:07:33.800]   it's kind of funny well so Micah and I are looking at and thinking what did we go wrong here we're
[00:07:33.800 --> 00:07:40.440]   still we're still stuck in the in the media Micah starts us here he's senior editor with
[00:07:40.440 --> 00:07:45.160]   mobile nations sister publication to our good friends that I'm Warren it's great to have you
[00:07:45.160 --> 00:07:49.720]   on Micah's been on TNT many times today thinks yeah first time with me anyway you've been on
[00:07:49.720 --> 00:07:55.240]   Twitter I think you were on a when I was on vacation yes yes first time here with you happy to hang
[00:07:55.240 --> 00:08:01.480]   out yeah a podcast with you do cartoon cast with Christina Kristina a Kristina woman named Christina
[00:08:01.480 --> 00:08:08.440]   Warren yes we're about to make our triumphant return it's we've been on on hiatus for a little
[00:08:08.440 --> 00:08:12.920]   while but that's about to restart up as we're getting into the October months and we've got some
[00:08:12.920 --> 00:08:19.640]   spooky Halloween stuff going on so is it about cartoons yeah I mean okay here's the thing is like
[00:08:19.640 --> 00:08:25.800]   adults there's like the stigma with with adults like enjoying and talking about and loving cartoons
[00:08:25.800 --> 00:08:30.520]   and Kristina or an I are both like unashamed Lee in love with cartoons like Bob's burgers
[00:08:30.520 --> 00:08:35.880]   the shows for adults but also the ones are like for kids we had the guy who is the voice actor on a
[00:08:35.880 --> 00:08:41.560]   cartoon show called Clarence which is a show directed at kids but we loved it and you know we
[00:08:41.560 --> 00:08:45.880]   brought him on and interviewed him and it's just it's the very official fart meetings episode
[00:08:45.880 --> 00:08:51.960]   and anyway we we're not we're not ashamed to proclaim our love for cartoons so she and I talk
[00:08:51.960 --> 00:08:57.240]   about different shows that we've watched when you know that the older shows newer shows just all the
[00:08:57.240 --> 00:09:02.120]   all the cartoons are all good but I realized this when I think it was you Kristina who had the
[00:09:02.120 --> 00:09:10.520]   Louise costume yes one Halloween and I thought oh she's a cartoon fan yep yep I found those
[00:09:10.520 --> 00:09:13.720]   years I was cleaning the other day and I found those years and I was like yep not getting rid of
[00:09:13.720 --> 00:09:20.840]   them no no there's gonna be a movie now soon I apologize really well yeah did just see that
[00:09:20.840 --> 00:09:26.280]   oh how exciting anyway the reason I this is kind of an idiosyncratic panel up everybody knows
[00:09:26.280 --> 00:09:30.520]   everybody's a thrill to have you all you're all good friends just kind of a little different
[00:09:30.520 --> 00:09:35.800]   somebody works for Microsoft somebody who's a startup guy and then me and Micah so
[00:09:35.800 --> 00:09:41.960]   the journalists of the podcast journalists again so I don't know what do you want to talk about we
[00:09:41.960 --> 00:09:47.240]   could do the traditional thing which is rundown nine products that Google announced on Wednesday
[00:09:47.240 --> 00:09:53.320]   and I guess we'll probably get to that or we could talk about the Guardian article I think I'm
[00:09:53.320 --> 00:09:59.960]   going to start with the Guardian article interviewing a number of Silicon Valley folks who have decided
[00:09:59.960 --> 00:10:07.560]   well they feel guilty our minds have been hijacked they say it features the guy who wrote the like
[00:10:07.560 --> 00:10:15.880]   button on Facebook saying that he now when he gets a smartphone has his assistant turn on
[00:10:15.880 --> 00:10:26.120]   parental controls so he can't install stuff onto this he says it's dangerously addictive and
[00:10:26.120 --> 00:10:35.480]   I'm just wondering I mean this is Justin Rosenstein they interview a number of people for this piece
[00:10:35.480 --> 00:10:39.720]   and I think that this is kind of going on right now in Silicon Valley a number of people I remember
[00:10:39.720 --> 00:10:45.480]   Steve Jobs said I'd never let my kids have an iPad or an iPhone yeah and Johnny I've just said
[00:10:45.480 --> 00:10:52.280]   something about time frames like where his kids can do it can use any device or can't right what
[00:10:52.280 --> 00:10:57.080]   Johnny I've said he does what is Johnny I've just recently said something about how we're spending
[00:10:57.080 --> 00:11:00.840]   too much time on our phones I can't remember where he's being interviewed but the New York
[00:11:00.840 --> 00:11:06.920]   Festival yeah the New York yeah David Rymnick interviewed him I think it was Friday yeah Tristan
[00:11:06.920 --> 00:11:12.600]   Harris a former Google employee says all of us are jacked into the system all of our minds
[00:11:12.600 --> 00:11:19.560]   can be hijacked our choices are not as free as we think they are he has been according to the
[00:11:19.560 --> 00:11:25.560]   Guardian branded as the closest thing Silicon Valley has to a conscience he's a good he's a
[00:11:25.560 --> 00:11:32.200]   friend he he has been on a wall with this like like the whole article is really going down into
[00:11:32.200 --> 00:11:37.080]   like an area that I did research which is like the science of attention and a lot of ways it starts
[00:11:37.080 --> 00:11:42.360]   with near I all and his hooked book and I've interviewed near on triangulation he wrote a book
[00:11:42.360 --> 00:11:50.680]   that is a roadmap for how to addict people to your app or website how to build habit forming
[00:11:50.680 --> 00:11:59.560]   products it's called hooked and he studied as did Harris with a guy at Stanford named B.J. Fogg
[00:11:59.560 --> 00:12:05.080]   and that's where this all begins he's a behavioral scientist and apparently was the first to say
[00:12:05.080 --> 00:12:11.560]   we can we can use technological design to persuade people to hook people you are a world of warcraft
[00:12:11.560 --> 00:12:19.160]   fanatic right Christina no I mean I I I played never got addicted no no but I know people who did
[00:12:19.160 --> 00:12:24.360]   I know many people who did and before that mobile was on the EverQuest people used to call it like Ever
[00:12:24.360 --> 00:12:29.480]   Crack like you know I mean yeah there's but what I have been addicted to have been like the the
[00:12:29.480 --> 00:12:36.680]   stupid yeah like other people yeah oh yeah yeah yeah I mean I've spent actual money on candy crush
[00:12:36.680 --> 00:12:41.160]   saga and things like that you know it's not your fault because all of this stuff is cleverly
[00:12:41.160 --> 00:12:45.800]   designed I mean I use World of Warcraft as an example because they have all the data they watch
[00:12:45.800 --> 00:12:49.160]   they know exactly what you're doing in the world and when you play that game you're playing it online
[00:12:49.160 --> 00:12:53.400]   so you're playing it on their servers so they know exactly what everybody does and they can
[00:12:53.400 --> 00:12:59.800]   optimize for stickiness and that's really what's happening this is timely because uh Facebook
[00:12:59.800 --> 00:13:06.040]   the the chief security officer at Facebook did a tweet storm yesterday saying you guys don't
[00:13:06.040 --> 00:13:13.720]   understand how hard it is uh Facebook's a really good example I don't think Facebook's doing it
[00:13:13.720 --> 00:13:18.600]   nefariously I think some people do I don't think they are I think Facebook optimizes as any company
[00:13:18.600 --> 00:13:25.880]   should for profit and the way Facebook optimizes for profit is by having an algorithm that designs
[00:13:25.880 --> 00:13:31.160]   the newsfeed to make it stickier right to keep you on it to keep you sharing and liking and they
[00:13:31.160 --> 00:13:35.960]   know they have all the data points to to optimize it and they don't partake I don't think they're
[00:13:35.960 --> 00:13:41.720]   paying at this point particular attention to the political or uh long range impact of this I think
[00:13:41.720 --> 00:13:46.040]   they may be forced to I think they're gonna be forced to because of all the inquiries that are
[00:13:46.040 --> 00:13:50.360]   coming up and and you know there are open questions about saying okay if we have certain
[00:13:50.360 --> 00:13:55.320]   regulations around the sort of political/sufficient advertisements that are on you know broadcast
[00:13:55.320 --> 00:13:58.920]   television or on cable or whatever you know should those things be extended or should we be at least
[00:13:58.920 --> 00:14:04.120]   looking about how they're being put about on online networks especially when so much of the
[00:14:04.120 --> 00:14:09.000]   ad traffic is controlled by you know Facebook and by by Google and as you said you know they have
[00:14:09.000 --> 00:14:13.640]   so much information that they can kind of do I thought you know Alex from Facebook and I'm with
[00:14:13.640 --> 00:14:17.960]   you I don't think that they are nefarious by like choice you know what I mean like I don't look at
[00:14:17.960 --> 00:14:20.920]   what they're doing. They're doing what every company does they're optimizing for profit.
[00:14:20.920 --> 00:14:25.560]   Totally but I do think that it was a little bit his tweet storm was a little bit disingenuous and
[00:14:25.560 --> 00:14:29.640]   that he's kind of complaining saying it's really hard to get the full story out and journalists aren't
[00:14:29.640 --> 00:14:33.560]   doing this the right way and as a number of journalists pointed out and as I can say as someone who was
[00:14:33.560 --> 00:14:37.880]   a journalist until just a couple months ago you know Facebook is a really hard company to get a
[00:14:37.880 --> 00:14:42.760]   straight answer from they always have and it's become even increasingly more difficult as time has
[00:14:42.760 --> 00:14:46.120]   gone on and as they become bigger and bigger so it's not that people don't want to tell the
[00:14:46.120 --> 00:14:51.400]   stories that they'll reach out to Facebook and his own people won't let him talk to people.
[00:14:51.400 --> 00:14:56.200]   It's like people would love nothing more than to have a sit down very candid conversation with
[00:14:56.200 --> 00:15:00.600]   Alex Damos about how this stuff really works. They would love nothing more than to let Facebook
[00:15:00.600 --> 00:15:05.240]   explain things but the company won't talk and so it's a little disingenuous to say the reporting
[00:15:05.240 --> 00:15:10.280]   isn't getting the nuances right when the company itself won't actually engage with the reporters.
[00:15:10.280 --> 00:15:14.200]   Doesn't Facebook guard the algorithm like Coca-Cola guides guards the rest of them?
[00:15:14.200 --> 00:15:15.640]   Of course. Of course.
[00:15:15.640 --> 00:15:21.560]   All of it. But Facebook does, I mean Google does too but I think you can guard the algorithm and
[00:15:21.560 --> 00:15:26.040]   still have a conversation about how things work and about you know what's actually going on.
[00:15:26.040 --> 00:15:30.840]   Yours impact will be like on the long term societal impact and political impact like
[00:15:30.840 --> 00:15:36.600]   I feel like we're coming more and more to the realization that human beings are
[00:15:36.600 --> 00:15:42.440]   manipulated or easily manipulated by different kinds of cues and different kinds of signals
[00:15:42.440 --> 00:15:47.560]   and different subconscious biases that are hard for us to admit that like we can be really
[00:15:47.560 --> 00:15:51.880]   influenced by things as simple as like they talk about in the article how changing the
[00:15:51.880 --> 00:15:57.160]   notification from blue to red and the notification thing instantly changed how often people click
[00:15:57.160 --> 00:16:01.240]   the notification button. Small things like that have such major incredible impact.
[00:16:01.240 --> 00:16:05.000]   Yeah they pointed the Guardian pointed out that you're seeing red badges everywhere now
[00:16:05.000 --> 00:16:09.400]   on your iPhone and everywhere because red is a that's why all these red dots on the iPhone
[00:16:09.400 --> 00:16:13.800]   because red is a call to action. It's something you see blue you wouldn't react to but red is a
[00:16:13.800 --> 00:16:18.440]   hot color. So they're using it. Does that mean that Apple is trying to manipulate you? No they're
[00:16:18.440 --> 00:16:23.400]   just trying to optimizing. They're optimizing. Yeah. Here's the problem. Here's the problem.
[00:16:23.400 --> 00:16:28.200]   I'd love to hear and Alex if you want to be on the show anytime I have a huge respect for Alex
[00:16:28.200 --> 00:16:33.720]   Damos was the chief of security. Yahoo when they were broken into for three billion records.
[00:16:34.440 --> 00:16:39.480]   But he left because he said Marissa didn't tell me and now he's at Facebook doing the same thing.
[00:16:39.480 --> 00:16:43.960]   CSO but I do have huge respect very well respect in the community but here's the reason people are
[00:16:43.960 --> 00:16:48.840]   concerned about this Alex. It is a mysterious secret algorithm. I would grant you and I think
[00:16:48.840 --> 00:16:55.880]   we all agree it's optimized for profit right now but who's to say that it wouldn't be tuned to do
[00:16:55.880 --> 00:17:01.080]   something else? For instance, like Mark Zuckerberg president. Right it could be and that's that's
[00:17:01.080 --> 00:17:06.200]   the concern there and I think when we were talking about sort of the doing this
[00:17:06.200 --> 00:17:12.840]   nephariously certainly not like actively nephariously but through ignorance or through almost ignoring
[00:17:12.840 --> 00:17:17.400]   just the fact that this has happened. I mean we had Mark Zuckerberg sort of saying oh no there
[00:17:17.400 --> 00:17:21.800]   were there was no influence on anything because of the way that the algorithm was set up and now
[00:17:21.800 --> 00:17:26.680]   that's sort of being back tracked and we're seeing Twitter too where we're seeing that these different
[00:17:26.680 --> 00:17:33.240]   bots that existed help to spread news from certain organizations foreign or in organizations and
[00:17:33.240 --> 00:17:38.920]   things like that and so it's clear that the social media networks and these apps and things like that
[00:17:38.920 --> 00:17:46.440]   they can be used in nefarious ways and if you ignore that or you sort of tend to disagree with the data
[00:17:46.440 --> 00:17:51.640]   if you have the data to back it up then as Christina Warren saying like let's share that data
[00:17:51.640 --> 00:17:56.040]   and if you don't have the data to back it up then maybe listen to the people who are paying attention
[00:17:56.040 --> 00:18:01.000]   to this and who are you know collecting that data and say okay you know we can't just keep you know
[00:18:01.000 --> 00:18:05.320]   twiddling our thumbs and ignoring this stuff we have to pay attention to it because we're clearly
[00:18:05.320 --> 00:18:11.720]   making a huge difference and we're making behavioral changes to people. I also would tell Alex
[00:18:11.720 --> 00:18:19.160]   that's the concern is what the algorithm is doing and why and what it could be used to do later.
[00:18:19.160 --> 00:18:24.680]   He sets up a straw man maybe it's not a straw man saying you guys in the press think it would be
[00:18:24.680 --> 00:18:28.760]   so easy to design an algorithm that would find fake news. Well I want to tell you it's really
[00:18:28.760 --> 00:18:33.640]   hard. Well I believe it. In fact I've always said of course it's going to be hard one person's
[00:18:33.640 --> 00:18:40.680]   fake news is another person's rock truth and it would be very difficult and so I don't blame
[00:18:40.680 --> 00:18:48.600]   Facebook for that but I do think going back to our original question Facebook is designed to
[00:18:48.600 --> 00:18:55.960]   become more addictive and ultimately there is power there and Google too and that power isn't
[00:18:55.960 --> 00:19:01.800]   necessarily being misused now but could be could it not misused. So it does lead to another question
[00:19:01.800 --> 00:19:08.760]   which I'd be curious what the panel would think. Both T. Bannon and Democrats proposed the idea
[00:19:08.760 --> 00:19:16.280]   of things like Facebook becoming like utilities being more managed or more regulated is that a
[00:19:16.280 --> 00:19:22.440]   good idea is that a terrible idea because I feel like that's the course that this seems to be going
[00:19:22.440 --> 00:19:27.800]   down in some way. No I mean yeah you're not wrong I mean it becomes an interesting question I do
[00:19:27.800 --> 00:19:31.560]   think that if you do what I have actually any sort of regulations that that would have to be
[00:19:31.560 --> 00:19:37.080]   treated as a utility but that could go. I mean I want the government to have control of the
[00:19:37.080 --> 00:19:44.360]   algorithm that that's that's. Well there's there's a difference between the government having the
[00:19:44.360 --> 00:19:48.680]   control of the algorithm and the government putting in sanctions about how certain things can be
[00:19:48.680 --> 00:19:55.240]   done it. You know again like the the broadcast networks that's considered a utility so it's you
[00:19:55.240 --> 00:20:01.720]   know there are there are equal time rules. There were. You see the time tweet today.
[00:20:01.720 --> 00:20:06.440]   There have been equal time rules and sometimes the Trump tweet about. Yeah he did today.
[00:20:06.440 --> 00:20:10.840]   What does he want? He thinks it's unfair how much equal time he doesn't get.
[00:20:10.840 --> 00:20:18.600]   What? Oh it's on the Twitter. What? And then Bob Corker tweeted is like looks like that the
[00:20:18.600 --> 00:20:24.440]   president is optimized for attention. He's exactly like the news algorithm he's designed for
[00:20:24.440 --> 00:20:30.440]   his goodness. He gets more coverage than anybody. Yes he does. Maybe he's not exactly coverage he
[00:20:30.440 --> 00:20:37.400]   would like or can. Right. I'm not opposed in theory to companies having to be more transparent
[00:20:37.400 --> 00:20:42.040]   about how information is collected and about what they're doing with it. But I don't.
[00:20:42.040 --> 00:20:46.840]   I'm uncomfortable with the fact of saying that the government's going to regulate a
[00:20:46.840 --> 00:20:51.160]   surface like Facebook or a search engine like Google. I don't even know what rules you would make.
[00:20:51.160 --> 00:20:54.840]   I don't know. I mean well we've seen what's happened already in the EU with with Google and
[00:20:54.840 --> 00:20:59.800]   Google has had to and Microsoft my employers had to do things to where you have to abide by
[00:20:59.800 --> 00:21:02.760]   certain privacy standards and you have to abide by other rules and it can make it difficult to
[00:21:02.760 --> 00:21:08.840]   operate. And I just I don't know if that would be a net positive. I also in all real is like
[00:21:08.840 --> 00:21:14.520]   the current FCC. I don't think whatever approved that. I mean they're already looking at basically
[00:21:14.520 --> 00:21:19.880]   dismantling net neutrality and making the internet a utility. I can't see them taking the
[00:21:19.880 --> 00:21:24.520]   the going of level beyond that which would be dead. Yeah. Good.
[00:21:24.520 --> 00:21:30.280]   The entertainment industry though. Like the movie industry and also video game industry said
[00:21:30.280 --> 00:21:35.000]   Oh dear. The government is like on its way to come in and regulate us. So here's what we're
[00:21:35.000 --> 00:21:40.520]   going to do. We're going to set up these movie rating systems are PGPG 13 etc. And we're going
[00:21:40.520 --> 00:21:43.880]   to do that ourselves. We're going to regulate ourselves and we're going to be very forward about
[00:21:43.880 --> 00:21:47.880]   that. And then the government said okay you know we can keep our hands off. That's what I want to
[00:21:47.880 --> 00:21:53.480]   see these these different companies do. I think that's what's going on right now.
[00:21:53.480 --> 00:21:57.000]   I mean that's exactly what's going on right now. Facebook is finally cooperating with Congress
[00:21:57.000 --> 00:22:03.400]   after Twitter and Twitter of denying Facebook denied that they had any influence from Russia
[00:22:03.400 --> 00:22:07.000]   that Russia bought any ads for months. And then finally said oh yeah. Here's a few thousand.
[00:22:07.000 --> 00:22:13.960]   Here's it. This was on 60 minutes last or actually is it maybe it's it says October 6th.
[00:22:13.960 --> 00:22:22.280]   Trump campaign director Brad Parscale talking with Leslie Stahl I guess it'll be on the night
[00:22:23.160 --> 00:22:29.880]   said that Facebook and Twitter by the way had and Google embedded employees in the Trump campaign
[00:22:29.880 --> 00:22:37.160]   to help them maximize their effectiveness. Furthermore he says now this I wouldn't I'm not
[00:22:37.160 --> 00:22:41.080]   surprised to hear the first of course Google with if you're a big customer you're spending a lot of
[00:22:41.080 --> 00:22:46.520]   money on advertising will help you they'll send a salesperson. Yep. And I don't think I don't I
[00:22:46.520 --> 00:22:50.600]   agree I think that saying embedded is is a little bit off there right because really what it is is
[00:22:50.600 --> 00:22:54.280]   that you're a big customer and they're doing what they can to make sure that your buys are affected.
[00:22:54.280 --> 00:23:00.200]   It's not the same thing as saying oh we're actively working to you know you're just making sure that
[00:23:00.200 --> 00:23:04.440]   Parscale says that he screamed them to make he said they better be Republicans and he screamed
[00:23:04.440 --> 00:23:09.080]   to make sure they were Trump supporters that I don't credit that I don't. Yeah I don't. That's BS.
[00:23:09.080 --> 00:23:14.680]   So that's not surprising though right. I mean I think they would he would have tried. He would
[00:23:14.680 --> 00:23:19.000]   have tried. This is a problem. Yeah yeah I'm a supporter I'm a Republican fine. This is a practice
[00:23:19.000 --> 00:23:22.920]   that these companies have done for I had a friend who was one of these people like like the liaison
[00:23:22.920 --> 00:23:27.160]   to one of the big campaigns maybe. I'm sure they did the same thing for the Clinton campaign.
[00:23:27.160 --> 00:23:30.520]   Oh yeah they sure did. Of course they did. If you're buying enough ads they're going to come
[00:23:30.520 --> 00:23:39.000]   and help you and they want you to buy more ads. Yes right. So Alex come on the show Alex I'd love
[00:23:39.000 --> 00:23:45.560]   to have you. I'd love to hear your point of view. I think you're I think you're wrong about assuming
[00:23:45.560 --> 00:23:49.400]   the press doesn't understand how hard it would be to detect fake news. I think there are people
[00:23:49.400 --> 00:23:54.120]   there's a big drumbeat for Facebook should detect fake snooze. I agree that's a very difficult
[00:23:54.120 --> 00:23:59.160]   thing to do. I don't know how you would even approach that. Facebook is putting a more info
[00:23:59.160 --> 00:24:04.280]   button now on articles where you could find out more about the source which I think is a good start.
[00:24:04.280 --> 00:24:10.040]   Yep that's a safe fair start. Part of the news feed update they're going to give you
[00:24:10.920 --> 00:24:15.400]   context when you click a button you'll see information from the publisher's Wikipedia page.
[00:24:15.400 --> 00:24:19.960]   A link to follow the publisher's Facebook page. Other links that might be related.
[00:24:19.960 --> 00:24:24.520]   You know what else I'd like to see Facebook do they haven't done as yet. They have given Congress
[00:24:24.520 --> 00:24:30.280]   those Russian purchase ads in the campaign. It seems very simple for Facebook and I'm not
[00:24:30.280 --> 00:24:36.520]   sure why they wouldn't do this to have a database of all the Apple buying ads and all the ads they
[00:24:36.520 --> 00:24:41.080]   bought because part of the problem is these are dark ads when Russia buys and add only the very
[00:24:41.080 --> 00:24:47.640]   specifically targeted people see them and not the rest of us so we don't know what influence is
[00:24:47.640 --> 00:24:52.280]   trying to be exerted. That would be easy for Facebook to do. I think that Congress needs to
[00:24:52.280 --> 00:24:56.520]   at least suggest they do that. Maybe they'll do it voluntarily.
[00:24:56.520 --> 00:25:02.200]   You know with that first thing that the more info button the context all that kind of stuff
[00:25:03.000 --> 00:25:10.120]   I'm going to be a mean press person right now and say I think those are good ideas and there
[00:25:10.120 --> 00:25:14.600]   aren't direct solutions that I can offer but I think for the most part a lot of those things
[00:25:14.600 --> 00:25:20.280]   are tiny bit an empty gesture and the reason I think that is because you can go to any I mean
[00:25:20.280 --> 00:25:24.440]   Christina I'm sure you can cite plenty of articles been you could cite plenty of articles we can
[00:25:24.440 --> 00:25:30.280]   all cite plenty of articles where you literally have people asking in the comments of an article
[00:25:30.280 --> 00:25:35.320]   something that is answered in the article people read headlines they maybe read 140 character
[00:25:35.320 --> 00:25:41.480]   tweets they don't click more info buttons when when we were doing data studies to try and figure
[00:25:41.480 --> 00:25:46.440]   out how best to optimize our social media posts and things like that if you have a Facebook post
[00:25:46.440 --> 00:25:50.440]   that where you have to click that more button like 98 percent of people don't even click that
[00:25:50.440 --> 00:25:55.160]   more button to see more text nobody's looking for more info they're just looking at that first
[00:25:55.160 --> 00:25:59.240]   thing and then they have the issues people are just looking for stuff that reinforces their
[00:25:59.240 --> 00:26:03.960]   beliefs anyway yep so it doesn't really matter I don't I don't know fake news is as big of a problem
[00:26:03.960 --> 00:26:10.200]   as as it was made out to be I think it creates it I think it creates an echo chamber and it can
[00:26:10.200 --> 00:26:15.000]   you're not wrong but I think if you start hearing the same things over and over again you start
[00:26:15.000 --> 00:26:18.760]   reading the same things over and over again your your reality can become more than anything to
[00:26:18.760 --> 00:26:23.560]   see the point of view that somebody has who watches MSNBC for their news versus somebody
[00:26:23.560 --> 00:26:28.920]   watches Fox I'm working on different countries they are in different universes
[00:26:29.800 --> 00:26:35.160]   right I'm yes but I'm more concerned about people who aren't to already already have their
[00:26:35.160 --> 00:26:39.560]   opinions laid you know so so kids who are watching YouTube all the time who now have
[00:26:39.560 --> 00:26:45.560]   views you know warped by by youtubers who have certain opinions or or people who are there's a
[00:26:45.560 --> 00:26:47.960]   hole there's a hole there's a hole there's a hole there's a hole in the pie to teach your kids
[00:26:47.960 --> 00:26:51.960]   so how the hole is actually a hole in the pie that's already out of the pie that's already out of the
[00:26:51.960 --> 00:26:56.760]   YouTube world that is like there's a whole alt right section of YouTube that yes does not probably
[00:26:56.760 --> 00:27:00.760]   highlighted to most of us but it's totally I've seen other ones and like on the other hand there's
[00:27:00.760 --> 00:27:06.600]   like part says like and there's and there's Islamic terrorist YouTube videos designed to
[00:27:06.600 --> 00:27:11.080]   convince people to become terrorists there's a lot of stuff on YouTube yeah that we don't see
[00:27:11.080 --> 00:27:16.840]   it plays to the people who are kind of already in that camp I would guess right it's not they're
[00:27:16.840 --> 00:27:22.200]   not pers are they persuasive they could intensify your beliefs though like you might start out here
[00:27:22.200 --> 00:27:26.040]   and then as you see these things that sort of confirm the beliefs that you have you start to
[00:27:26.040 --> 00:27:30.120]   get inundated with more stuff and then you're suddenly you know going down the little route there and
[00:27:30.120 --> 00:27:35.160]   you're super far one way or the other you're young and then you join like a subreddit dedicated to
[00:27:35.160 --> 00:27:40.120]   the alt right isn't this what Eli Parris was talking about in his book the filter bubble that
[00:27:40.120 --> 00:27:49.160]   the way the internet works is it segregates information and people only hear the stuff they
[00:27:49.160 --> 00:27:54.760]   agree with basically and then and there's if you had an if you subscribe I don't know if this is a
[00:27:54.760 --> 00:28:01.480]   different difference from the past Jeff Jarvis says has always been going on he says you'd get
[00:28:01.480 --> 00:28:06.040]   the if you got the newspaper you'd get the liberal or the repar or the the conservative newspaper you
[00:28:06.040 --> 00:28:10.280]   there would always filter bubbles you talk the where you live the neighborhood you live in is
[00:28:10.280 --> 00:28:16.040]   very much a filter bubble we aren't really exposed in fact Jeff says it's quite the opposite the
[00:28:16.040 --> 00:28:21.720]   internet has given us exposure to a broader range of opinions just through serendipity and accident
[00:28:22.360 --> 00:28:27.880]   than ever before I think the difference is that there are fewer content source there were fewer
[00:28:27.880 --> 00:28:33.160]   content sources before so it would be difficult for you to have your entire media diet consumed
[00:28:33.160 --> 00:28:38.600]   by one point of view where is now because there is so many different content things and so many
[00:28:38.600 --> 00:28:43.880]   different channels if you never wanted to leave a bubble ever you could and why would you ever
[00:28:43.880 --> 00:28:49.560]   want to leave your bubble to steal wholesale from from Georgia Dow thank you Georgia
[00:28:50.520 --> 00:28:55.800]   it the fact is this is this is this is confirmation bias and cognitive dissonance and it goes like
[00:28:55.800 --> 00:29:01.080]   the this is the thing is like it goes back to our primitive brain when we were you know many many
[00:29:01.080 --> 00:29:06.680]   many many years ago hunting in packs and we were small little groups like we had to find the people
[00:29:06.680 --> 00:29:11.240]   who were like us and anything that was different was dangerous because it could mean that we don't
[00:29:11.240 --> 00:29:15.400]   get to eat that day or that someone was going to come steal our food and we have this primitive
[00:29:15.400 --> 00:29:20.680]   basis of our brain that still exists and that's why it's scary to have anything that goes against
[00:29:20.680 --> 00:29:25.160]   our beliefs and that's why like there's there's literal like pain in your brain whenever something
[00:29:25.160 --> 00:29:29.320]   challenges your very belief system and so when you see all these things that agree with you it's like
[00:29:29.320 --> 00:29:34.280]   oh this feels good this is nice but those things that exist outside there's like a danger to that
[00:29:34.280 --> 00:29:38.440]   and that is why we we get into these bubbles and why we don't because there's so much discomfort
[00:29:38.440 --> 00:29:43.640]   involved with sort of expanding our viewpoint and so that the challenge is to like to be
[00:29:43.640 --> 00:29:49.080]   more evolved humans is to you know fight past that cognitive dissonance fight past that
[00:29:49.080 --> 00:29:53.080]   confirmation bias and and let in those other things and so now we have that opportunity
[00:29:53.080 --> 00:29:58.040]   to find new viewpoints and find new beliefs but the fact is you have to take that or you can just
[00:29:58.040 --> 00:30:02.440]   stay in your little your little group and continue to sort of go down that hole and be part of that
[00:30:02.440 --> 00:30:09.560]   pack and then a way this takes us back to how we began which is these silicon valley refusenix
[00:30:09.560 --> 00:30:13.640]   who said you know we created something far too addictive and and and we think you should turn
[00:30:13.640 --> 00:30:21.160]   it off is that one way to get out of the filter bubble is uh uh to maybe I last night or two nights
[00:30:21.160 --> 00:30:26.520]   ago I was up at 3 a.m. on facebook and it got me so angry that it does that I deleted facebook
[00:30:26.520 --> 00:30:31.960]   instagram and twitter from my phone wow I it's not like a kill my account I still have it on the
[00:30:31.960 --> 00:30:36.680]   desktop it's worth the fact that covered in the same apple estimates that we pick up an unlock
[00:30:36.680 --> 00:30:41.640]   our phone what was it 80 times a day that we spent a lot of time doing this and I thought if I and
[00:30:41.640 --> 00:30:46.360]   you know what I haven't really my battery life really sort because I have no reason to turn my
[00:30:46.360 --> 00:30:53.560]   phone on there's nothing on here I want to see I have I have a theory that like we're seeing more
[00:30:53.560 --> 00:30:58.280]   and more people start to put implementations to like limit the amount of their facebook or remove
[00:30:58.280 --> 00:31:03.560]   their twitter from their uh phones but I also feel like it's a little bit of a privilege like if you
[00:31:03.560 --> 00:31:10.600]   are uh you are high paid or if you are lucky and you're like you people will still contact you
[00:31:10.600 --> 00:31:14.840]   even if you don't check those things regularly then you could do that but in like small
[00:31:14.840 --> 00:31:18.200]   difference a country rule like facebook is like where you meet talk to your friends and meet your
[00:31:18.200 --> 00:31:22.120]   friends and if you're not there you've got like nothing you can't it's like you can't do it because
[00:31:22.120 --> 00:31:27.720]   I don't like people so I don't mind so there could be so like my my guess is like they could also be
[00:31:27.720 --> 00:31:32.680]   sociologic so so that could do that yeah that's a really good point so what do we do so what how
[00:31:32.680 --> 00:31:36.600]   do we solve this so these are two problems we've got we've got the filter bubble we've got this
[00:31:36.600 --> 00:31:40.600]   you know kind of unified worldview that we're not and we're not hearing from other points of
[00:31:40.600 --> 00:31:46.200]   view and we've also got this addiction problem where these these not maliciously but these companies
[00:31:46.200 --> 00:31:56.440]   are designing super addictive products what's the answer if anyone actually do a good answer uh we
[00:31:56.440 --> 00:32:01.720]   so that person would also be a billionaire I I I have yeah this is like this is the hardest
[00:32:01.720 --> 00:32:06.440]   there the thing to hear is like you can't truly like blame facebook or any other company for like
[00:32:06.440 --> 00:32:12.360]   being evil because this is such a complicated question with so many complicated answers because
[00:32:12.360 --> 00:32:15.800]   no i'm stipulating they're not evil they're just trying to maximize profits but there's
[00:32:15.800 --> 00:32:21.000]   i don't actually have any clue what the answer is and that's hard I think the answer is it is up to us
[00:32:21.000 --> 00:32:26.600]   yeah you've got to delete facebook and twitter and instagram it itself control there you know
[00:32:26.600 --> 00:32:31.560]   whenever the apple and i know that google has had this for a long time so please don't be angry
[00:32:31.560 --> 00:32:36.440]   at me all of you out there listening when apple had come out with the do not disturb all driving
[00:32:36.440 --> 00:32:40.280]   thing i had wrote up a piece about that and i got a lot of flack because people are like why
[00:32:40.280 --> 00:32:45.560]   can't you just control yourself you don't need to have a second off i turned that dude i disturb
[00:32:45.560 --> 00:32:50.840]   on right away right because people will you know you have no notification pop up and then you're
[00:32:50.840 --> 00:32:54.360]   wanting to pay attention to it your brain is spinning circles thinking about it and so we do
[00:32:54.360 --> 00:32:58.840]   have to it is it's you got to take it into your own hands whether that be like go see a therapist
[00:32:58.840 --> 00:33:02.840]   to talk about you know if this is seriously something that's enough of a concern for you where you've
[00:33:02.840 --> 00:33:08.120]   got some sort of like facebook addiction or internet addiction versus just like finding a way to get
[00:33:08.120 --> 00:33:12.840]   to that self-control it's all about beating that primal brain i think is that passing the book
[00:33:12.840 --> 00:33:18.760]   christina though to say oh it's personal responsibility you come in a little bit keep maximizing profits
[00:33:18.760 --> 00:33:22.920]   don't it's our job i think it is a little bit no i i mean yeah i think i i mean obviously i think
[00:33:22.920 --> 00:33:27.000]   that ultimately it does maybe our job to do this i think that the big and the big solution and i
[00:33:27.000 --> 00:33:31.560]   don't know how you do this is you have to de-incentivize people from wanting to take advantage of these
[00:33:31.560 --> 00:33:35.640]   things which google has effectively done in some of the other algorithms in which facebook
[00:33:35.640 --> 00:33:40.680]   maybe you know should do too is when you figure out what dark patterns are existing and what people
[00:33:40.680 --> 00:33:45.800]   are doing it to to you know get people to to stay addicted in certain ways you have to look and say
[00:33:45.800 --> 00:33:51.240]   is this ultimately helpful or harmful um you know long term beyond just is this good for our revenue
[00:33:51.240 --> 00:33:55.080]   stream but i do think it is passing the buck a bit to say we should just all have self-control
[00:33:55.080 --> 00:33:58.840]   because these things are as you know we were saying at the top of the piece is the people who are in
[00:33:58.840 --> 00:34:04.440]   that guardian story are talking about um are you know they're using science they're there and
[00:34:04.440 --> 00:34:09.480]   and they're literally designing things so that so that people will be more engaged and will do it i
[00:34:09.480 --> 00:34:14.680]   mean it's it's it and um so they'll click more you know so that so that they'll be more addicted and
[00:34:14.680 --> 00:34:19.000]   and uh i don't think you can blame it'd be like you know blaming you know drug addicts for for
[00:34:19.000 --> 00:34:22.440]   taking you know drugs because you know they're addicted to them you know i mean it's part of
[00:34:22.440 --> 00:34:26.120]   it is personal responsibility the part of it is that people are on the streets and are offering
[00:34:26.120 --> 00:34:31.560]   it to you know so um i think it's passing back a little bit but like ben said i don't know the
[00:34:31.560 --> 00:34:37.160]   solution i wish i did we we do have a i mean the war on drugs is a failure yes yeah absolutely it is
[00:34:37.160 --> 00:34:41.320]   because the war on drugs has been a political movement not about really stopping drugs but stopping
[00:34:41.320 --> 00:34:46.760]   anyway i don't want to get into that but i'm not going i'm not going to do that but yeah the war
[00:34:46.760 --> 00:34:52.360]   in drugs has been a failure and i think that you know um the opioid crisis in particular it's just
[00:34:52.360 --> 00:34:57.240]   gotten worse over time and and i think that kind of shows that i think part of the reason the war
[00:34:57.240 --> 00:35:00.120]   in drugs has been a failure is because it's been attacked in the victims rather than attacking the
[00:35:00.120 --> 00:35:06.680]   source uh but if you but i mean i think we have tried to shut down uh the cartels the cocaine
[00:35:06.680 --> 00:35:12.040]   cartels we have tried to cut off uh the import of drugs in the united states it's just you can't do
[00:35:12.040 --> 00:35:17.400]   it because the demand is there the profit is so hot and the well that's the thing the incentivization
[00:35:17.400 --> 00:35:21.960]   incentive is too high and other countries they focus on the other side of the issue i will try
[00:35:21.960 --> 00:35:26.520]   not to make this a drug thing but on things that this weekend drugs well what would be the netherland's
[00:35:26.520 --> 00:35:32.120]   approach to a computer addiction so their solution to drug addiction is to legalize everything
[00:35:32.120 --> 00:35:39.400]   have treatment centers what would you do what is the equivalent for technology addiction
[00:35:40.200 --> 00:35:44.920]   technology treatment centers we need treatment you know this may be something where there is no
[00:35:44.920 --> 00:35:50.200]   answer to this may just be our future and i feel bad for our kids who are growing up this way
[00:35:50.200 --> 00:35:55.480]   uh and it does seem and this is the point of the guardian article it does seem to have somewhat
[00:35:55.480 --> 00:36:02.200]   perverted our political process uh and that's a cause for concern but maybe that's just a liberal
[00:36:02.200 --> 00:36:06.440]   point of view unhappy with the results of brexit and uh the presidential election in the united
[00:36:06.440 --> 00:36:11.800]   states maybe that's maybe it hasn't perverted our political process i'm just too much a little
[00:36:11.800 --> 00:36:19.640]   of relevance relat relativist i think whenever you know you think about uh drugs and where we are
[00:36:19.640 --> 00:36:25.720]   sort of with like marijuana and with some harder drugs like opium and things like that heroin
[00:36:25.720 --> 00:36:31.240]   we you know these drugs hit the scene and at the time people had trouble and there's a crisis yes
[00:36:31.240 --> 00:36:34.600]   but we also know more about the drugs and are continuing to learn more about the drugs and are
[00:36:34.600 --> 00:36:40.440]   continuing to get better at treatment for those drugs and you know we're living in this this
[00:36:40.440 --> 00:36:45.640]   technology boom right now and so later on down the line when we better understand this you know our
[00:36:45.640 --> 00:36:50.840]   kids are going to be so knowledgeable about this and you know they'll go on to be researchers and
[00:36:50.840 --> 00:36:55.000]   scientists and psychologists and psychiatrists and things like that so they'll probably know more
[00:36:55.000 --> 00:36:59.240]   about the technology as well and be able to better handle it right now we're sort of just like bathing
[00:36:59.240 --> 00:37:04.120]   in it and our learning as we go whereas they'll sort of have hindsight and things like that so
[00:37:04.120 --> 00:37:08.760]   you know it may be our future for a while but eventually i think we'll get to a place where
[00:37:08.760 --> 00:37:13.000]   either we're all killed because you know the artificial intelligence have taken over or we've
[00:37:13.000 --> 00:37:18.360]   gotten better at it it's hard for me not to just get grim and say oh we're screwed but every
[00:37:18.360 --> 00:37:25.720]   but but these are very very hard things to solve and no no apparent solution uh presents itself
[00:37:25.720 --> 00:37:29.640]   uh and yet at the same time i think it's really important i'm glad we talked about it because i
[00:37:29.640 --> 00:37:33.800]   think it's really important to admit that there is something going on there is something going on
[00:37:33.800 --> 00:37:39.400]   there is an issue. Tristan Harris when he wrote in 2013 a memo at google he was a product manager
[00:37:39.400 --> 00:37:45.240]   he was called a call to minimize distraction and respect users attention
[00:37:45.240 --> 00:37:51.800]   it's spread to 5,000 google employees included senior executives who said oh Tristan we're
[00:37:51.800 --> 00:37:57.160]   gonna give you a new job your your in-house design ethicist and product philosopher
[00:37:58.200 --> 00:38:04.440]   looking back Harris sees he was promoted into a marginal role he says that that basically was
[00:38:04.440 --> 00:38:09.320]   getting rid of me i got to sit in the corner and think and read and understand and that's that
[00:38:09.320 --> 00:38:14.440]   so that's that's one way a company can handle it we're gonna take a break when we come back
[00:38:14.440 --> 00:38:20.360]   google's being accused in a big lawsuit of racketeering kind of the same kind of thing
[00:38:20.360 --> 00:38:27.560]   Microsoft is accused of in the 90s the engulf and devour strategy we'll talk about that in just a
[00:38:27.560 --> 00:38:32.760]   little bit Ben par is here the author of cap divulgy the science of capturing people's attention
[00:38:32.760 --> 00:38:38.680]   and he's the founder of a new company called octane ai that helps you're you're part of the
[00:38:38.680 --> 00:38:44.360]   problem you're helping make bots part of what am i we're talking to the enemy he's sitting right
[00:38:44.360 --> 00:38:50.840]   here have you read hooked uh near his book i interviewed dear for the cap divulgy actually
[00:38:50.840 --> 00:38:55.400]   here's a smart guy yes he has i think even near has misgivings though about how his
[00:38:55.400 --> 00:39:00.040]   technology's used talks about it a little bit yeah how is like limiting it home in some way yeah
[00:39:00.040 --> 00:39:06.760]   what have we done it's like Oppenheimer when he uh when they invented the atomic bomb he said
[00:39:06.760 --> 00:39:10.920]   now what is now we are Shiva now we are we have been made destruction
[00:39:10.920 --> 00:39:19.080]   Sagan i have become death there's a happy thought the world did not die though
[00:39:19.080 --> 00:39:25.960]   not yet it will not die not yet give it time it's only 50 years old 60 what is it 80 years old
[00:39:25.960 --> 00:39:31.720]   the atomic bomb it's not that old yet i i prefer to be an optimist yeah i'm a good right too
[00:39:31.720 --> 00:39:37.800]   also with us it's great to have mica sergeant for the first time mica is a of course uh
[00:39:37.800 --> 00:39:44.280]   senior editor at mobile nations and hosts a ton of podcasts too many too many podcasts
[00:39:44.280 --> 00:39:49.640]   never such a thing is too many podcasts with many of our favorite people in the world too you work
[00:39:49.640 --> 00:39:56.040]   with Brianna woo and Christina and lots of other people this is Georgia Dow you mentioned yes yes
[00:39:56.040 --> 00:40:01.720]   what's the podcast you do with Georgia Georgia Brianna and Steve Lubitz and i all do a podcast
[00:40:01.720 --> 00:40:06.760]   called disruption it's uh it sort of like what we just talked about where it gets a little more
[00:40:06.760 --> 00:40:12.200]   political it's tech and the surrounding society basically uh and it's a question and answer
[00:40:12.200 --> 00:40:16.600]   show as well so we have people call in with their questions and we help them out with things it's
[00:40:16.600 --> 00:40:20.600]   great to have Georgia on that show how do you how do you do that that's like uh we were thinking
[00:40:20.600 --> 00:40:25.720]   we used to do that way back when with talk shoe we can take calls on the podcast what technology
[00:40:25.720 --> 00:40:30.600]   you used to take calls uh we actually have a number that calls into Skype and call recorder can
[00:40:30.600 --> 00:40:37.640]   actually leave a question yeah yeah believe yes we don't do it live although there is uh i can't
[00:40:37.640 --> 00:40:43.880]   even think of the technology now but it's uh made by one of the uh i'd like to do it real time
[00:40:43.880 --> 00:40:48.280]   wouldn't that be cool dangerous well that's what i do on the radio show it's like call on radio
[00:40:48.280 --> 00:40:53.480]   right it is dangerous it's very dangerous it would be fun would be fun yeah uh mica somebody in the
[00:40:53.480 --> 00:40:59.640]   chatroom uh Robert Bigelow says disruption and rocket are my favorite on relay FM to hey Christina
[00:40:59.640 --> 00:41:04.440]   is on on rocket yeah i think that's a show i sometimes get to join Christina on the Roche
[00:41:04.440 --> 00:41:09.640]   Ford and Brianna Wu that's a great show you are so good on that Christina oh thank you so much we
[00:41:09.640 --> 00:41:15.160]   love doing it we love doing it and Christina is here Christina Warren film girl now at microsoft
[00:41:15.160 --> 00:41:20.680]   where she's in charge of well she's a senior cloud dev advocate yes i work in the channel nine
[00:41:20.680 --> 00:41:25.560]   team and do some other cool stuff but yeah performed it reformed uh uh textur analyst Christina Warren
[00:41:25.560 --> 00:41:32.760]   i had a great experience the other day i was uh this is uh this is our ad for tracker i was in a uh
[00:41:32.760 --> 00:41:40.120]   we went to a concert and i went oh crap i i've lost my keys and because i had i was wearing a
[00:41:40.120 --> 00:41:44.600]   scottie vest and i have like a hundred pockets to put the keys in there so i i looked all around my
[00:41:44.600 --> 00:41:48.520]   seat couldn't find it and then i went back to the bar and i was searching all around i thought oh
[00:41:48.520 --> 00:41:53.400]   wait a minute i have a tracker attached to my keys and there's a button on the on the uh on the phone
[00:41:53.400 --> 00:41:57.240]   if i take a press it right now i don't i don't know where my keys are there's a button on the
[00:41:57.240 --> 00:42:03.080]   phone that makes the keys ring so i pressed you know so embarrassed because i heard the sound coming
[00:42:03.080 --> 00:42:09.240]   from my coat and i realized oh i put it in some obscure scottie vest pocket so you you absolutely
[00:42:09.240 --> 00:42:14.120]   have to have a tracker if you have a scottie vest because there's so many pockets you will lose it
[00:42:14.120 --> 00:42:18.360]   the tracker is a great bluetooth tracking device they have a couple of form factors there's the
[00:42:18.360 --> 00:42:24.520]   tracker bravo which is a uh aluminum anodized aluminum very lightweight but the size of a quarter
[00:42:25.080 --> 00:42:29.400]   i have that attached to my keys but i also have a tracker pixel which is actually phenomenal i
[00:42:29.400 --> 00:42:33.720]   put that on my remote controls because when you press the button on the phone app for the tracker
[00:42:33.720 --> 00:42:38.920]   pixel not only does it make a sound it lights up it's got uh LEDs all around it so if you when i
[00:42:38.920 --> 00:42:43.320]   lose the remote control down the cushions and stuff i can see it it lights up i could find it
[00:42:43.320 --> 00:42:49.960]   you will never lose anything again with the tracker tracker is bluetooth not gps in there but it pairs
[00:42:49.960 --> 00:42:55.240]   to your phone you can have up to ten trackers paired to the tracker app on your phone you can
[00:42:55.240 --> 00:43:00.760]   also and trackers the only one that does this have uh one tracker shared to multiple phones so
[00:43:00.760 --> 00:43:06.280]   everybody in your family can have the tracker app looking for your keys that kind of thing it uh
[00:43:06.280 --> 00:43:11.560]   has also the best crowd sourced network out there the crowd gps network that's really their secret
[00:43:11.560 --> 00:43:17.640]   sauce see they've sold five million trackers over the last couple of years that means there are
[00:43:17.640 --> 00:43:23.240]   people running the tracker app all over the world so here's the scenario you lose your keys i left
[00:43:23.240 --> 00:43:27.160]   let's say i left my keys at the bar now it's easy to find it if i left in the bar because the tracker
[00:43:27.160 --> 00:43:31.560]   app will say well the last time i saw him was in the bar i go there but wait a minute somebody picked
[00:43:31.560 --> 00:43:38.680]   them up at the bar and decided to move to Mozambique i hate it when that happens but fortunately the
[00:43:38.680 --> 00:43:45.000]   next time somebody running the tracker app walks by my keys the app says oh those are Leo's keys and
[00:43:45.000 --> 00:43:52.280]   sends my app and my phone a ping saying your keys are in Mozambique buddy that is awesome that's the
[00:43:52.280 --> 00:43:59.000]   tracker crowd crowd gps network and it is the secret sauce tracker t-r-a-c-k-r.com actually the hardest
[00:43:59.000 --> 00:44:03.560]   thing to find at this point will be the website you'll never lose anything again but the website
[00:44:03.560 --> 00:44:11.720]   it's a little hard to find a t-h-e-t-r-a-c-k-r there's no e and tracker at the end there t-h-h-e-t-r-a-c-k-r.com
[00:44:11.720 --> 00:44:16.360]   use a promo code to load up your basket okay get all get tracker bravos tracker pixels
[00:44:16.360 --> 00:44:21.000]   you can get this waterproof tracker cover so that you can use a tracker for your pet great way to
[00:44:21.000 --> 00:44:27.000]   keep track of your pet all kinds of things and and take 20% off any order boom right off the top
[00:44:27.000 --> 00:44:30.360]   when you use your offer code to it and you know what this is when you could tell your friends because
[00:44:30.360 --> 00:44:38.200]   you know they'll all save 20% off at the tracker.com promo code to it if you're if you're nervous
[00:44:38.200 --> 00:44:43.800]   30-day money back guarantee there that you have nothing to lose literally with the tracker the
[00:44:43.800 --> 00:44:53.400]   tracker.com promo code twit let's see I think I feel like we should do something light after
[00:44:53.400 --> 00:45:01.560]   that heavy discussion who's buying a pixel - you're all apple people aren't you yeah although if I
[00:45:01.560 --> 00:45:04.760]   was gonna get an Android phone that's probably what I would get yeah exactly yeah I'm looking for
[00:45:04.760 --> 00:45:12.600]   that iPhone X or iPhone 8 Christina iPhone 10 come on come on Leo yeah come on Leo Micah you're
[00:45:12.600 --> 00:45:18.120]   waiting for the 10 as well yeah yeah you know there's only about 30 of them for sale in the
[00:45:18.120 --> 00:45:24.040]   whole world. I know it's gonna be like I'll be up oh we're all gonna be up dude 1201
[00:45:24.040 --> 00:45:29.240]   Pacific time October 27th we're all gonna be going refresh refresh refresh you know what he's
[00:45:29.240 --> 00:45:32.920]   gonna get one you're gonna you know it's gonna be like February I'm gonna still be stuck with my
[00:45:32.920 --> 00:45:39.560]   7 plus no but I'm gonna get the pixel - yeah or the iPhone I got the 8 because I won't well like but
[00:45:39.560 --> 00:45:44.760]   the 8 you know is gonna in fact people criticized the pixel to the small one because it had bezels
[00:45:44.760 --> 00:45:49.560]   it's like everybody now bezels all of a sudden are like the kiss of death right oh look at the
[00:45:49.560 --> 00:45:54.440]   size of those bezels that's disgusting the new thing is gonna be bezel free I have a bezel is
[00:45:54.440 --> 00:46:02.440]   phone you've got a note no better than that this is the essential phone it's even got a notch like
[00:46:02.440 --> 00:46:10.760]   the iPhone 10 adorable you know how adorable is the word they sold 5000 all to you yeah I feel
[00:46:10.760 --> 00:46:15.960]   bad for Andy Rubin I decide I'm gonna be contrarian I'm not I'm gonna use the essential phone it's
[00:46:15.960 --> 00:46:19.960]   actually very nice phone I'm sure that it is you and all five thousand of your of your friends
[00:46:19.960 --> 00:46:28.280]   the only problem with this same problem with the iPhones 8 and the iPhone 7 and the same problem
[00:46:28.280 --> 00:46:33.080]   with the new pixel XL can you guess what problem I'm talking about battery life no headshot
[00:46:33.080 --> 00:46:42.120]   headphone jack oh yeah what the hell not that I mean what's the story there it's dead you agree
[00:46:42.120 --> 00:46:46.760]   with it it's dead I don't agree with it it's just the number one company in the world got rid of
[00:46:46.760 --> 00:46:53.480]   it a year ago and everyone of course followed suit so it's gone Neil I Patel said famously it was a
[00:46:53.480 --> 00:47:00.280]   user hostile gesture he's not wrong but it's still dead he made I thought a very good point
[00:47:00.280 --> 00:47:07.960]   on the verge saying this is just more walled garden because okay so obviously no headphone
[00:47:07.960 --> 00:47:11.960]   jack Bluetooth headphones right but not just any Bluetooth headphones if you want to get the most
[00:47:11.960 --> 00:47:19.160]   out of your iPhone 7 8 or 10 you get out your AirPods with a w1 chip and Siri if you want to get
[00:47:19.160 --> 00:47:23.640]   the now but now Google's doing if you want to get the most out of your pixel 2 you get the
[00:47:23.640 --> 00:47:33.720]   the google buds the big little buds the babblefish it's a terrible yeah the ones that'll get the
[00:47:33.720 --> 00:47:38.840]   babblefish yeah but you want that kit babblefish instant translation you want a google assistant
[00:47:38.840 --> 00:47:44.680]   your ear you gotta use a pixel so what Neil eyes point is and I think this is actually well taken
[00:47:44.680 --> 00:47:51.240]   is that the side effect maybe not even unintentional side effect of eliminating the headphone jack
[00:47:51.240 --> 00:47:57.240]   is now you have to buy the branded headphones to go with it yep big money 150 bucks for AirPods
[00:47:57.240 --> 00:48:04.360]   160 bucks for the google pixel buds I mean but if the headphone jack was there I mean there wasn't
[00:48:04.360 --> 00:48:09.560]   like an option at that point to get the best experience because of the headphone jack that like
[00:48:10.120 --> 00:48:14.600]   I don't understand sort of the argument that maybe because it's gone now there are walled
[00:48:14.600 --> 00:48:19.640]   gardens there sort of always were because apple may have made their best headphones at the time
[00:48:19.640 --> 00:48:24.200]   even when there was a headphone jack at least you could use as I do at a modic headphones with my
[00:48:24.200 --> 00:48:30.280]   iPhone and you still can't you might not have to perish the same way well Bluetooth first of all
[00:48:30.280 --> 00:48:34.680]   Bluetooth audio quality I think you would all agree is worse than wired audio quality yes yes
[00:48:36.360 --> 00:48:42.200]   problem number one problem number two even with a faunted w1 chip I still get Bluetooth dropping
[00:48:42.200 --> 00:48:47.960]   out once in a while losing calls right yeah because it's wireless wireless is inherent
[00:48:47.960 --> 00:48:53.000]   and three now in order to take advantage of these new phones you have to buy that companies you
[00:48:53.000 --> 00:48:57.000]   don't have a choice you have to buy that companies if you want the full feature suite right but you
[00:48:57.000 --> 00:49:02.200]   will right you want that instant translate that's cool yeah you want to have Siri in your ear you
[00:49:02.200 --> 00:49:08.840]   know I don't want Siri in my ear I use these uh bows like QC 35s which are like
[00:49:08.840 --> 00:49:14.200]   a google assistant now yeah I mean the new the new QC 35s have google assistant I did not know
[00:49:14.200 --> 00:49:20.040]   that until now and now I feel excited maybe I have to get a pixel too I don't think you have to have
[00:49:20.040 --> 00:49:24.360]   a pixel in that case somebody's saying there are dongles but that's not a good that's a that's
[00:49:24.360 --> 00:49:30.520]   not a good single or apple got dongles are horrible I have to have a type of seed dongle for the pixel
[00:49:30.520 --> 00:49:35.960]   and for the essential phone I have to have a lightning dongle for the iPhone I have to keep track of
[00:49:35.960 --> 00:49:41.080]   the dongles because I I know most of my dongle attached to whatever headphones yeah now the headphones
[00:49:41.080 --> 00:49:45.960]   are lightning headphones I guess that makes sense you have a dongle bag that's you have a dongle bag
[00:49:45.960 --> 00:49:51.000]   dongle bag here I have now this is what happens when you have dongle bags you spend time
[00:49:51.000 --> 00:49:57.000]   filled with dongle for just looking for your dongle I just have a dongle bag that's so sad it's like
[00:49:57.000 --> 00:50:03.000]   a mary poppins bag you just keep reaching out all right well so you disagree with
[00:50:03.000 --> 00:50:07.880]   nila you don't think this is a big deal no I mean I think it just think that it's passed I think
[00:50:07.880 --> 00:50:12.120]   that getting upset about it I mean we all got mad about it a year ago and we got over it and
[00:50:12.120 --> 00:50:17.720]   but google hadn't done it yet now google's done sam sung still can make a great phone with all the
[00:50:17.720 --> 00:50:22.600]   features of these other phones the note eight with a headphone jack you're right they can so why
[00:50:22.600 --> 00:50:28.600]   can't apple and google and guess they don't because because it's been proven over the last year that
[00:50:28.600 --> 00:50:34.600]   it doesn't matter that is is outraged as the technorati god it didn't matter because most
[00:50:34.600 --> 00:50:39.160]   people let's be honest most people it's not listening to this audience to be clear but most
[00:50:39.160 --> 00:50:43.400]   people who buy a phone use whatever headphones come with it so whether it's going to have a
[00:50:43.400 --> 00:50:48.200]   lightning cable a meter jack right doesn't matter you're going to use whatever comes with it is
[00:50:48.200 --> 00:50:52.440]   it more annoying now that you can't charge your phone and listen to your wired headphones at the
[00:50:52.440 --> 00:50:57.400]   same time sure that's frustrating but that aside I think most people use whatever comes with their
[00:50:57.400 --> 00:51:03.320]   phone they weren't upgrading to better headphones anyway and you know it's been much to do about
[00:51:03.320 --> 00:51:07.480]   nothing that doesn't mean that it's not used or hostile because I think that it is but I just like
[00:51:07.480 --> 00:51:10.920]   I wrote when I was I think I was even still up mashable when I wrote something I was like I've
[00:51:10.920 --> 00:51:14.520]   come to terms with the headphone jack going away I'm already planning for it it's terrible I'm not
[00:51:14.520 --> 00:51:18.600]   happy about it but I'm just I'm used to it I've come to terms with it I went through my five
[00:51:18.600 --> 00:51:23.400]   stages of grief and I feel like a year later I feel like a year later it's like yeah you would
[00:51:23.400 --> 00:51:27.400]   be surprising to me if the other companies hadn't followed suit if that makes any sense
[00:51:27.400 --> 00:51:32.600]   do you think Samsung will follow suit next year I mean I think it depends on
[00:51:32.600 --> 00:51:39.480]   maybe there's schematics and whatnot I mean and if they see it as as a true differentiator if
[00:51:39.480 --> 00:51:44.280]   anybody's actually buying their phones because maybe maybe they would keep it on but I don't
[00:51:44.280 --> 00:51:48.840]   but again I don't see anybody choose I don't think anybody is going to choose to buy the Galaxy Note
[00:51:48.840 --> 00:51:53.800]   8 or the Galaxy S8 because it has a headphone jack I think they're buying those phones for
[00:51:53.800 --> 00:51:57.320]   other reasons they want the camera they want the battery life they want that edge to edge screen
[00:51:57.320 --> 00:52:01.000]   right they want the Samsung experience I don't think anybody's saying oh well you know I was
[00:52:01.000 --> 00:52:05.720]   gonna get an iPhone but it doesn't have a headphone jack or I was gonna get a pixel but it doesn't
[00:52:05.720 --> 00:52:10.120]   have a headphone jack I think they're saying I want the phone for other reasons and didn't
[00:52:10.120 --> 00:52:14.200]   Samsung have it like a commercial last year where they're like yeah we have a headphone jack
[00:52:14.200 --> 00:52:17.320]   yeah but they also had a phone that blew up
[00:52:17.320 --> 00:52:27.400]   I cut it it would let your pants on fire yeah yeah all right so we just have to live with it
[00:52:27.400 --> 00:52:32.280]   are they're cool products though from am I am I old-fashioned and want a headphone jack is that
[00:52:32.280 --> 00:52:37.720]   like Passay now is that like well no I don't think it's Passay like I want a floppy disk in my
[00:52:37.720 --> 00:52:42.200]   computer well I mean I because I mean I think that in this goes back to the argument that we
[00:52:42.200 --> 00:52:48.120]   had a year ago I mean I think that the difference was that you had like when you replace floppy disks
[00:52:48.120 --> 00:52:53.880]   with with optical media or with flash media it was superior whereas you can or as you were saying
[00:52:53.880 --> 00:52:57.080]   you know Bluetooth it's getting better but you do still have drop-offs the audio quality is not
[00:52:57.080 --> 00:53:03.000]   as good so we haven't necessarily replaced it with better technology I do admit that I bought
[00:53:03.000 --> 00:53:09.560]   the Google Pixel Buds oh yeah because of the translation thing that goes awesome and in
[00:53:09.560 --> 00:53:14.200]   fairness like that's that's I like that I like that sort of thing I like that sort of pairing
[00:53:14.200 --> 00:53:18.040]   of hardware and software even if it annoys me as like an iPhone user that I wouldn't be able to get
[00:53:18.040 --> 00:53:21.720]   that same experience with an iPhone like that would that that could be one of those things where I
[00:53:21.720 --> 00:53:25.640]   would say if I were going abroad a lot and I didn't speak the language that would be a real
[00:53:25.640 --> 00:53:29.480]   selling point not just for Android but for the Google Pixel phone like that's a really cool feature
[00:53:30.680 --> 00:53:34.120]   I'm going to Japan the spring and I hope that I'll have it by then and be able to
[00:53:34.120 --> 00:53:38.520]   do the same one as one is it yeah it's supposed to come I'm supposed to get it next month but
[00:53:38.520 --> 00:53:43.240]   but I mean that would be really I don't know well I'd be I might be embarrassed to use it I
[00:53:43.240 --> 00:53:46.680]   I'm going to Germany at the end of the month I really kind of want to get them by then so you
[00:53:46.680 --> 00:53:51.720]   won't get it by the end of October someone only I want to review them will that be cool though yeah
[00:53:51.720 --> 00:53:57.880]   I need to review them see I yeah I think that especially well Japan for me would be it's impenetrable I
[00:53:57.880 --> 00:54:02.600]   don't it's not like a romance language where I can kind of understand them I can't have no idea
[00:54:02.600 --> 00:54:08.520]   what somebody's saying in Japanese so I think it would be really intriguing to now what the way it
[00:54:08.520 --> 00:54:13.720]   works is you you launch the translator and you do that with audio you tap the thing and you say
[00:54:13.720 --> 00:54:18.760]   I'd like to speak Japanese or something and then the person says you know what kind of
[00:54:18.760 --> 00:54:25.640]   much the whatever and then in my ear I hear how you're doing and then I say something in English
[00:54:26.360 --> 00:54:32.360]   and comes out of my phone in Japanese and the demonstration they did it was almost it wasn't
[00:54:32.360 --> 00:54:37.240]   simultaneous but it was almost instantaneous so as soon as I say something it comes out in Japanese
[00:54:37.240 --> 00:54:41.160]   as soon as she says something in Japanese that comes out in English in my ear you can now have
[00:54:41.160 --> 00:54:45.720]   a conversation that is remarkable now Microsoft demonstrates something very similar with Skype
[00:54:45.720 --> 00:54:52.760]   yes but that's Skype and that's not in person exactly I mean that that I mean and I mean that
[00:54:52.760 --> 00:54:56.280]   obviously this sort of technology has existed I mean Google has been doing stuff you know for
[00:54:56.280 --> 00:55:00.120]   visual stuff for a long time and I think they've even been doing new apps like to do a lingo have
[00:55:00.120 --> 00:55:04.040]   existed for a long time too that'll do this sort of conversion what's really remarkable about this
[00:55:04.040 --> 00:55:08.200]   assuming it works and I don't have any reason to believe that it won't is that like you said it's
[00:55:08.200 --> 00:55:13.400]   kind of that instantaneous on you know on the fly translation and that's really impressive like I
[00:55:13.400 --> 00:55:19.000]   I'm really interested in seeing it and seeing the views of it because if it works even half as well
[00:55:19.000 --> 00:55:25.320]   as what they're showing that could be huge for so many circumstances the Google Translate app
[00:55:25.320 --> 00:55:29.960]   actually already does it it just doesn't have of course you know the headphones and into your ear
[00:55:29.960 --> 00:55:35.560]   and all that kind of thing but I was just testing it I was out of town and for some reason I opened
[00:55:35.560 --> 00:55:39.960]   the Google Translate app for something and I forgot that that feature existed so I had tested it
[00:55:39.960 --> 00:55:43.560]   always trying to learn a Spanish phrase that had been set on the television so I was speaking in
[00:55:43.560 --> 00:55:48.520]   Spanish to it and hearing it sort of speak things back in English and so you know to have that
[00:55:48.520 --> 00:55:52.200]   instantaneous and right in your ear I think takes it to the next level that's really cool
[00:55:52.200 --> 00:55:55.960]   when I see that's one of the every once in a while you see something in this industry where you go
[00:55:55.960 --> 00:56:01.000]   okay now we're in the future it's like the Star Trek like yeah button that universal translate
[00:56:01.000 --> 00:56:07.320]   yeah now we're in the future that is actually useful and could even change the world right because
[00:56:07.320 --> 00:56:13.960]   if you can communicate with people that can change everything I want it I want it see that's
[00:56:13.960 --> 00:56:18.360]   why I'm gonna buy bluetooth headphones on a pixel two I guess I'm getting the pixel two now I'm
[00:56:18.360 --> 00:56:21.240]   convinced all right here's one two Google announced a Chromebook
[00:56:21.240 --> 00:56:31.720]   starts it's very nice but remember most Chromebooks are around 150 to 500 dollars
[00:56:31.720 --> 00:56:39.240]   Google's new pixel book starts at 1000 dollars they've gone premium well they were premium last
[00:56:39.240 --> 00:56:44.920]   time they've always been premium with their Chromebooks but is this a bad thing you felt like
[00:56:44.920 --> 00:56:50.120]   the last Chromebook pixel that Google did which was also over a thousand bucks was really just like
[00:56:50.120 --> 00:56:55.000]   a demonstration it's totally this one there's like oh it'll be in a thousand retail stores and I'm
[00:56:55.000 --> 00:57:01.480]   like really you best buy a cell who's gonna buy them that's I can't figure out because if you if
[00:57:01.480 --> 00:57:05.960]   you spec it all the way out and it can be very powerful right it's a nice seven that 512 gigabyte
[00:57:05.960 --> 00:57:12.600]   SSD 16 gigabytes of RAM you know this thing if you do all the bells and whistles it's 1650 dollars
[00:57:12.600 --> 00:57:19.160]   and and and I'm looking at that I'm like okay you don't even run a real operating system and I know
[00:57:19.160 --> 00:57:24.120]   I know I know I'm hearing all of you guys in the audience I get it you can you can run CH root on
[00:57:24.120 --> 00:57:29.240]   it you can get like the the version that's not fair though it's Chrome OS it's Chrome or whatever
[00:57:29.240 --> 00:57:35.000]   if you can hack it with it's great I agree exactly and and and for me I mean look the one thing that
[00:57:35.000 --> 00:57:39.160]   could make it sort of compelling but again this is for such a small use case um Ken White the
[00:57:39.160 --> 00:57:43.480]   security researcher was telling you us what are that apparently they've made some commits to the
[00:57:43.480 --> 00:57:48.440]   chromium OS where you can wear virtual machines um we'll we'll act as containers and can basically
[00:57:48.440 --> 00:57:52.200]   be people you know first class citizens so if you were like you could have a bunch of Docker
[00:57:52.200 --> 00:57:57.960]   containers potentially of your different way you can run Docker on Chrome OS well apparently
[00:57:57.960 --> 00:58:02.760]   that is it's not yet there like first party but apparently that looks like that's gonna be coming
[00:58:02.760 --> 00:58:07.160]   so then you could have a Mac OS that would actually be really cool I don't have to put up with this
[00:58:07.160 --> 00:58:11.080]   Mac operating system Mac hardware I can get the Mac operating system I might pick so I'm saying
[00:58:11.080 --> 00:58:15.160]   this that potentially makes it interesting right is if you were able to have Docker containers
[00:58:15.160 --> 00:58:19.560]   running natively that could be really cool but it's not there yeah but even even if you
[00:58:19.560 --> 00:58:23.800]   assume that that's going to happen and that's coming down the line I still feel like at that price
[00:58:23.800 --> 00:58:29.000]   point you're at a very very limited user base who's saying why would I get this machine for this
[00:58:29.000 --> 00:58:33.320]   price nice hardware aside when I could get you know a MacBook Pro where I could you know have
[00:58:33.320 --> 00:58:37.720]   Docker instances or I could have a service book or I could have a service book like why am I
[00:58:37.720 --> 00:58:41.960]   doing why am I not getting these things that are already fully functioned what I'll tell you why
[00:58:41.960 --> 00:58:49.000]   it makes it better because some people don't need the complexity and the security problems that a
[00:58:49.000 --> 00:58:56.280]   general purpose operating system offers okay so but again I guess I'm asking like why then spin
[00:58:56.280 --> 00:59:01.240]   why get the 1600 hours micro medium device yeah well all right so I bought the thousand dollar
[00:59:01.240 --> 00:59:05.480]   version which is still expensive I mean for a thousand bucks you can get an apple well maybe
[00:59:05.480 --> 00:59:12.120]   you can't but you can almost get a MacBook uh yeah an air well that's you know or you could you
[00:59:12.120 --> 00:59:17.400]   certainly get a play in Windows machines under a thousand dollars but maybe I don't want maybe
[00:59:17.400 --> 00:59:24.680]   don't need all the complexity of a Windows 10 maybe I just really surf the web do email uh you know
[00:59:24.680 --> 00:59:31.080]   send postcards to my grandkids maybe that's not a bad choice and by the way if this and it
[00:59:31.080 --> 00:59:36.680]   looks like it does fully supports the android store I could put Photoshop mobile on it I could put
[00:59:36.680 --> 00:59:41.480]   light removal on it I could put snap seat on it so I could do all my picture stuff I can I mean
[00:59:41.480 --> 00:59:47.000]   there's a lot of android apps to do almost anything yeah I mean Microsoft has excellent android apps
[00:59:47.000 --> 00:59:51.400]   I could have Microsoft yeah I think you Microsoft is great android apps but but I mean the bigger
[00:59:51.400 --> 00:59:56.440]   concern with me and I haven't tested the latest version so my you know my my tests are or I guess
[00:59:56.440 --> 01:00:01.480]   going back to April or so but last time I was trying to use um you know uh the android apps on
[01:00:01.480 --> 01:00:06.120]   on Chrome OS and I was using like a Samsung that had been specifically designed to kind of do that
[01:00:06.120 --> 01:00:10.200]   some of the apps you know some of the Adobe ones worked well and and Microsoft to their credit
[01:00:10.200 --> 01:00:15.000]   like I was actually Android apps are superb yeah they're great but they've also done a good job
[01:00:15.000 --> 01:00:20.760]   optimizing them to work on the Chromebooks having said that a lot of apps just aren't optimized
[01:00:20.760 --> 01:00:26.280]   to work on the Chromebook and so you it's kind of a you know like you never really know
[01:00:26.280 --> 01:00:31.240]   is this gonna work or is this not gonna work um you know that's true Google needs to be
[01:00:31.240 --> 01:00:35.880]   need to promote more people designing their android apps to work on both Chromebook and
[01:00:35.880 --> 01:00:42.760]   that and they need to to surface the good stuff in the store and maybe they'll do that I don't
[01:00:42.760 --> 01:00:46.360]   know I mean I hope so I mean you know we for a long time there's been rumors that the Google
[01:00:46.360 --> 01:00:52.120]   will formally kind of you know merge android and Chrome OS and and and I think that for this
[01:00:52.120 --> 01:00:55.560]   sort of thing to work especially if you're gonna have like a thousand dollar plus strategy I think
[01:00:55.560 --> 01:00:59.400]   you kind of have to do that because otherwise everything you're saying about why people buy
[01:00:59.400 --> 01:01:05.000]   Chromebooks even though I personally it's not not for me I I've tried this not just similar to why
[01:01:05.000 --> 01:01:09.560]   I wouldn't be able to use an iPad Air or not an iPad Air and iPad Pro is like my main computer like
[01:01:09.560 --> 01:01:14.760]   I just need different I have different needs but there are plenty of people who a Chromebook is
[01:01:14.760 --> 01:01:20.360]   perfect for them and I don't just count most people I would agree with you um the most people
[01:01:20.360 --> 01:01:25.080]   can do just fine with the Chromebook that said I just don't understand why you would choose
[01:01:25.080 --> 01:01:30.040]   a thousand dollar Chromebook over a really nice you know Samsung or Acer $500 Chromebook you know
[01:01:30.040 --> 01:01:34.040]   like it's a great build quality but it's gonna be much better than you should be spinning double
[01:01:34.040 --> 01:01:39.720]   like that's what I don't understand like if I were buying for my my parents or something like that
[01:01:39.720 --> 01:01:44.600]   would I be paying a for 16-year-old like you're a 5-0 plus yeah the Samsung Chromebook plus
[01:01:44.600 --> 01:01:47.640]   really yeah 5 months it would be the same it wouldn't there wouldn't be much of a difference
[01:01:47.640 --> 01:01:53.720]   for that and Google it actually Florence I and it's and I who covered the the stream as we do uh you
[01:01:53.720 --> 01:01:58.280]   know snarking about the stream during the event Florence I'm pointing out Google kept calling it a
[01:01:58.280 --> 01:02:06.280]   laptop is that fair to call it a laptop can you put in your lap all right yeah okay but I mean
[01:02:06.280 --> 01:02:12.600]   a laptop kind of implies it can it's like a full computer I don't know I I think this is a really
[01:02:12.600 --> 01:02:18.280]   interesting experiment Google is trying to say that this is a full computer even though really
[01:02:18.920 --> 01:02:26.040]   isn't well it is but it also isn't you can't but it is you can't stall apps on it right but uh I
[01:02:26.040 --> 01:02:29.720]   mean you can't install apps you can't install windows apps on you can't install Mac apps on it
[01:02:29.720 --> 01:02:33.720]   like a Chromebook is a kind of thing where like I don't think I could ever like none of us the
[01:02:33.720 --> 01:02:38.360]   real kind of well it makes a full computer what is it missing that that makes that it that
[01:02:38.360 --> 01:02:43.640]   full well I mean it's a funny it's the video shop I would say okay how many video editing
[01:02:44.360 --> 01:02:50.120]   video editing Photoshop audio editing I would say designing rocket ships building uh you know
[01:02:50.120 --> 01:02:56.680]   architectural designs for advanced programming yeah no you can do no you can do a lot of programming
[01:02:56.680 --> 01:03:00.680]   on uh on the internet there are a lot of cloud IDs I honestly think that and I've even talked
[01:03:00.680 --> 01:03:04.360]   people who say you know I do my full design workshop and you know people who are professional
[01:03:04.360 --> 01:03:09.160]   designers who use apps like Figma and and use you know Chromebooks for that and and obviously you
[01:03:09.160 --> 01:03:13.000]   know mica and I know a lot of people who are very proficient at using the knife head pro for all
[01:03:13.000 --> 01:03:16.760]   of their work flow tools I don't want to discount that although I think it takes more work but when
[01:03:16.760 --> 01:03:22.200]   I look at a Chromebook the one thing that is I think that a lot of people do um that you you still
[01:03:22.200 --> 01:03:26.760]   can't do uh you can't replicate this video editing and that's something that's you know you can
[01:03:26.760 --> 01:03:31.560]   at least do that on an iPad I never thought I never thought civilians would ever want a video at
[01:03:31.560 --> 01:03:37.400]   it as a you know as a tv person for years I went into edit booths with editors and you know
[01:03:37.400 --> 01:03:43.080]   slaved over a hot avid for hours and I thought why would anyone want to do this if they didn't
[01:03:43.080 --> 01:03:47.320]   have to do it and yet they do apparently because they all want to be youtube stars
[01:03:47.320 --> 01:03:52.920]   that's the incentive oh yeah it's the number one thing you ask like kids what do they want to be
[01:03:52.920 --> 01:03:57.160]   youtube star you want to be used to say I want to be Shaq now they want to be a youtube star yeah
[01:03:57.160 --> 01:04:01.160]   Shaq tried to be used to youtube star failed miserably hey let's talk about that when we come
[01:04:01.160 --> 01:04:07.000]   back youtube is back at it trying to get mainstream talent to do big time episodic
[01:04:07.000 --> 01:04:13.080]   television on youtube is that a smart move or are they just going to throw away another 100 million
[01:04:13.080 --> 01:04:17.480]   dollars like they did last time we're gonna take a break great panel here mica sergeant
[01:04:17.480 --> 01:04:22.200]   do you are you actually mica do everything on an iPad pro is that what Christina said no no no
[01:04:22.200 --> 01:04:30.040]   we know people who we know we know yeah and a couple other people like the the co-founders of relay
[01:04:30.040 --> 01:04:35.640]   uh mike herli and and a few other people they like only uses an iPad he well he says he does I mean
[01:04:35.640 --> 01:04:41.320]   can we really know for sure wow they they try to do everything possible on that but again like that
[01:04:41.320 --> 01:04:46.360]   that word try you know it feels like you're putting handcuffs on and saying but I can still
[01:04:46.360 --> 01:04:52.760]   uh you know give manicures I mean it's not why why do that why we're a mannequin why mannequals right
[01:04:52.760 --> 01:04:57.240]   who needs i'm gonna get internet punched for saying this but I agree with you like you that
[01:04:57.240 --> 01:05:04.840]   absolute it's like uh all right uh our show today brought to you by fracture fracture is a
[01:05:04.840 --> 01:05:11.080]   photo decor company that prints your photos onto glass delivers them to your house perfectly they
[01:05:11.080 --> 01:05:17.000]   have a really sweet packaging method and they look fantastic they're ready to hang you can just
[01:05:17.000 --> 01:05:22.200]   hang them right up on the wall uh and they look good I have to say printing on glass does something
[01:05:22.200 --> 01:05:28.600]   to the photo really the colors pop the contrast pops so you've got photos I know you have photos
[01:05:28.600 --> 01:05:34.360]   that are sitting on your phone or on your computer or in a digital vault somewhere you never look
[01:05:34.360 --> 01:05:39.560]   at them take some of your best pictures and hang them on the wall and i'm telling you it brings
[01:05:39.560 --> 01:05:44.920]   your house to life fracture starts with these little ones this is a four by eight by six by four
[01:05:44.920 --> 01:05:50.840]   so it's like a little postcard print this is one Lisa met made of her son's eighth grade graduation
[01:05:50.840 --> 01:05:55.880]   here's one that now this is how this is the way it comes I should point out in the box so it comes
[01:05:55.880 --> 01:06:01.400]   mounted on the the cardboard and then the cardboard has a little screw and on the back of the fracture
[01:06:01.400 --> 01:06:07.560]   there's a little mounting place so it's ready to go that's me you can make them borderless or we
[01:06:07.560 --> 01:06:13.160]   put borders on because sometimes our shots are three by two and so the the aspect ratio these
[01:06:13.160 --> 01:06:17.720]   is four by three or square they do you can import your instagram directly your facebook this is my
[01:06:17.720 --> 01:06:22.040]   son and his high school graduation with my daughter this is don't tell him but this is me a gift
[01:06:22.040 --> 01:06:27.480]   for a Christmas to a few of our family members grandma's gonna kind of get that don't you think
[01:06:27.480 --> 01:06:32.520]   she'll love that and look what it does you they have an advanced editor on the fracture site so
[01:06:32.520 --> 01:06:36.200]   you can make it monochrome and look what it does when it's black and white they're just something
[01:06:36.200 --> 01:06:41.640]   that it just you could fall into it don't you think man really think they look good all right i'm
[01:06:41.640 --> 01:06:47.080]   gonna show you how big you can get though this is the this is the the big one actually i gotta show
[01:06:47.080 --> 01:06:52.120]   you this i like showing off my pictures on fractures because they look really good this is my also my
[01:06:52.120 --> 01:06:56.840]   son and his high school graduation i i like this picture because it felt like it was frank Sinatra
[01:06:56.840 --> 01:07:03.320]   in the rat pack look at the look at the look he's given me like he's mad he's like stuck taking pictures
[01:07:03.320 --> 01:07:11.880]   dead isn't that great black and white all right it goes all the way up to 21.6 inches by 28.8 inches
[01:07:11.880 --> 01:07:22.520]   that is big look at that but see that you could hang that over the mantle right in the fireplace
[01:07:22.520 --> 01:07:29.640]   isn't that a great picture that that is a that is a sea lion this is from the Galapagos i took this
[01:07:29.640 --> 01:07:35.080]   this spring yelling at a flightless cormorant saying that's my spot
[01:07:35.080 --> 01:07:41.800]   the funny thing the funny thing is the cormorant just looked at him like yeah and never backed down
[01:07:41.800 --> 01:07:46.680]   so eventually the sea lion goes and lies next to him it was actually the sequence is funny i might
[01:07:46.680 --> 01:07:51.800]   i might do a thing of the sequence Lisa's done that on her blog because she has a similar picture
[01:07:51.800 --> 01:07:57.480]   so look how good your pictures do don't let those pictures kind of just die in obscurity go to
[01:07:57.480 --> 01:08:03.240]   fracture dot me we've got a deal for you you're a first order you get 15 off of you see off
[01:08:03.240 --> 01:08:09.080]   or code twit 15 all their fractures come with a 60 day happiness guarantee they're printed in the
[01:08:09.080 --> 01:08:14.840]   u.s in Gainesville, Florida from u.s source materials in a carbon neutral factory they do recycling
[01:08:14.840 --> 01:08:21.480]   of the glass they're just really great they come on a laser cut rigid backing so they're ready to
[01:08:21.480 --> 01:08:27.240]   display right out of the box including the wall anchor fracture dot me use the off or code twit 15
[01:08:27.240 --> 01:08:31.960]   to check out to get 15 percent off your first order if you're listening uh you're not seeing
[01:08:31.960 --> 01:08:36.920]   those beautiful prints but uh but go online and check them out and you know what make one
[01:08:36.920 --> 01:08:42.440]   because you it will blow you away it is really a great way to take your photography and put it on
[01:08:42.440 --> 01:08:47.960]   your wall and and keep those memories front and center and a great gift for the holidays fracture
[01:08:47.960 --> 01:08:56.440]   dot me off or code twit 15 we thank it for their support of this week in tech one thing google
[01:08:56.440 --> 01:09:02.760]   announced that I thought was really weird and maybe you guys can explain it is the clips camera
[01:09:02.760 --> 01:09:09.240]   now this is I don't even know if they even even I don't think even google takes this seriously
[01:09:09.240 --> 01:09:15.080]   two hundred forty nine dollar stand alone little camera it's tiny I mean it's the size of a postage
[01:09:15.080 --> 01:09:19.880]   stamp and the idea is it stands on its own or you can clip it in actually in their video onto a
[01:09:19.880 --> 01:09:25.480]   flower sack is how they did but the idea is it's got artificial intelligence built in and you just
[01:09:25.480 --> 01:09:30.120]   you know when you're like with the family you're doing something you pointed at and you just forget
[01:09:30.120 --> 01:09:34.600]   it for a while and then it's it takes the best pictures like of the most exciting I don't know
[01:09:34.600 --> 01:09:38.600]   how it would know but somehow artificial intelligence knows oh that's a great shot oh that's a great
[01:09:38.600 --> 01:09:44.040]   shot and you get to relate to your family and then at the end it's got 16 gigs of storage you take
[01:09:44.040 --> 01:09:48.120]   your phone and you you copy them to your phone pick the ones you want and upload them
[01:09:48.120 --> 01:09:57.240]   what do you think it's a cool concept it'll be used in some very interesting ways oh wow you have
[01:09:57.240 --> 01:10:06.200]   a dirty mind I didn't even I'm a crime but now I'm thinking sex oh my oh yeah now you are oh that's
[01:10:06.200 --> 01:10:12.440]   terrible there's a cool idea there of like being present and in the moment and having the thing
[01:10:12.440 --> 01:10:16.920]   like at a big event taking pictures so that you don't think about it but it totally could be used
[01:10:16.920 --> 01:10:25.240]   for all sorts of like other things and I like it's cool it's cool but it like it could also be
[01:10:25.240 --> 01:10:29.480]   used in creepy ways but we'll see what happens with it I didn't even think of that pen you are
[01:10:29.480 --> 01:10:35.240]   I did immediately did you really? Yeah yeah and like everyone I was talking to was like
[01:10:35.240 --> 01:10:39.960]   what you put in the bathroom or something would be things oh that's I mean you got I maybe
[01:10:39.960 --> 01:10:42.840]   you're being an optimist here which I'm not used to because we were just being really
[01:10:42.840 --> 01:10:47.640]   negative about things but oh don't tell me now tell me later you've got ideas they give
[01:10:47.640 --> 01:10:51.480]   about like a stalker or something like that they could put this thing in someone else's house
[01:10:51.480 --> 01:10:56.760]   or you all like at all their portraits that it's right but I mean this is just like another
[01:10:56.760 --> 01:11:01.880]   another more like mainstream possibility here and like the the interesting thing to me was the
[01:11:01.880 --> 01:11:07.960]   sort of press rollout that happened after google announced this immediately all of these big sites
[01:11:07.960 --> 01:11:12.440]   I can watch the Verge video on it and they were talking immediately about how yes this is creepy
[01:11:12.440 --> 01:11:17.400]   but everything happens on device the AI its storage is all local all of this and everything
[01:11:17.400 --> 01:11:22.840]   and so like google I think knew that people would be sort of skis'd out by this but I mean it's
[01:11:22.840 --> 01:11:27.320]   still regardless it's still sort of I understand where people are concerned well one of the things
[01:11:27.320 --> 01:11:30.360]   they did think that people skis'd out because it would be uploaded to the net so they were
[01:11:30.360 --> 01:11:34.760]   great pains to say no no this is local it only saves us local right right right right which
[01:11:34.760 --> 01:11:39.320]   I mean is better than than um you know it's sort of I don't know I mean it's it's in a lot of ways
[01:11:39.320 --> 01:11:43.960]   it's kind of similar to a GoPro right um except it's using your phone rather than you know a GoPro
[01:11:43.960 --> 01:11:49.560]   usually uses like an esky card I I wonder how many people are actually going to want to use this
[01:11:49.560 --> 01:11:54.760]   like I think that's the challenge more than the the the the the skeety factor is that how many
[01:11:54.760 --> 01:11:59.960]   people are going to remember to be like oh I'm I'm having this great time let me pull out you know
[01:11:59.960 --> 01:12:03.720]   a little camera and set it up and make sure I'm capturing everything who also said there's a light
[01:12:03.720 --> 01:12:10.440]   on it the there's a they intentionally made the lens really you look lensy so it's obviously a
[01:12:10.440 --> 01:12:14.440]   camera yeah no they've learned from google glass I'm just saying I wonder how many people are going
[01:12:14.440 --> 01:12:18.120]   to like want to carry the surround in addition to all the other stuff you carry around to capture
[01:12:18.120 --> 01:12:22.680]   the moments but I mean I don't mind the concept I mean obviously we're all kind of skeeted out by
[01:12:22.680 --> 01:12:27.640]   as as mica was saying I'm not even thinking that you guys are you know the pure mind
[01:12:27.640 --> 01:12:31.880]   well you know I wasn't even thinking about in in what context you're talking about I'm just
[01:12:31.880 --> 01:12:36.600]   saying like you know people potentially you know like capturing you when you're not sure what not
[01:12:36.600 --> 01:12:41.480]   I don't know although I it is what it is if people want to put spy cameras in your house they can
[01:12:41.480 --> 01:12:46.840]   and will you know drop camps and ask cams do those sorts of things now and they stream it to the
[01:12:46.840 --> 01:12:54.520]   clock oh now I'm horrified but I got it even think of that I just thought oh that's cool you're
[01:12:54.520 --> 01:12:59.160]   because my kids hated it when I took pictures of them they would always go like this and so I
[01:12:59.160 --> 01:13:02.840]   just like the idea I could you know put something there that would do that do that for me
[01:13:02.840 --> 01:13:07.960]   well I kind of like about it in some ways it's kind of similar to the snapshot spectacles which
[01:13:07.960 --> 01:13:12.360]   idiots like me waited in line for and and and now everyone's forgotten about but it's kind of the
[01:13:12.360 --> 01:13:15.960]   same idea where that you know again they went through great pains to like make sure that you know
[01:13:15.960 --> 01:13:20.360]   when it's recording and whatnot but the idea would be present in the situation and that's
[01:13:20.360 --> 01:13:23.560]   a similar thing where it would capture it and then transfer it to your phone and and then you
[01:13:23.560 --> 01:13:27.880]   would choose if you wanted to upload it or not but this is is obviously a separate device has better
[01:13:27.880 --> 01:13:34.680]   quality and and like Ben was saying I do kind of like the idea of of being at a party or or out
[01:13:34.680 --> 01:13:39.880]   someplace and and not having to be buried in your phone the whole time I mean I think this is what
[01:13:39.880 --> 01:13:43.240]   they're trying to get at I don't know if this is the right approach but I think with what they're
[01:13:43.240 --> 01:13:47.640]   aiming for and and this is I think actually pretty notable especially given what we were talking about
[01:13:47.640 --> 01:13:52.440]   at the at the beginning of the show is to say rather than being stuck in our phones all the time
[01:13:52.440 --> 01:13:57.720]   and and constantly on our screens you could be in the moment and still go back later and say
[01:13:57.720 --> 01:14:02.760]   these are the most important parts and yeah I'll share that yeah I mean that's a lot of
[01:14:02.760 --> 01:14:09.800]   now I'm thinking I'm probably on some list for ordering one I don't know maybe I won't buy it
[01:14:09.800 --> 01:14:14.840]   it is 250 bucks it's very expensive it's like like pull it out to like do that is it gonna be
[01:14:14.840 --> 01:14:19.560]   selfie like this no like for I would put it here yeah but for the most part for most parties like
[01:14:19.560 --> 01:14:23.240]   you wouldn't get the good angles like what I'm like thinking it's like cameras work is all about
[01:14:23.240 --> 01:14:27.000]   the angles it was all about no you're right lighting in the shot and you can't you don't control any
[01:14:27.000 --> 01:14:31.240]   of it's a strange product is a 130 degree field of use it's very wide
[01:14:31.240 --> 01:14:36.920]   um I don't know it is a strange product but it would work once we have those apps where you
[01:14:36.920 --> 01:14:41.080]   push the button and you don't know what the photo looks like and it like pretends to develop the
[01:14:41.080 --> 01:14:45.400]   photo for you you see it like the next day yeah I don't like that either I like to know what I
[01:14:45.400 --> 01:14:50.200]   got and take it again if I didn't get anything good by the way Christina don't feel bad uh
[01:14:50.200 --> 01:14:57.560]   Evan Spiegel uh Seagull says they sold 150 000 uh snapchat spectacles is that good I don't think
[01:14:57.560 --> 01:15:02.200]   that's good given all the hype really in the fact they're yeah I mean I don't know maybe maybe
[01:15:02.200 --> 01:15:08.200]   that's good I don't know that's 150 000 times a hundred bucks it's not bad I mean I guess doesn't
[01:15:08.200 --> 01:15:13.000]   make a dent for snapchat as a company yeah I don't know yeah that was a promotional thing
[01:15:13.000 --> 01:15:19.000]   they always do what is Google's purpose in making this thing the clips I mean I think that
[01:15:19.000 --> 01:15:23.400]   they're trying to maybe try to see I think I think what when I looked at a product like this you know
[01:15:23.400 --> 01:15:28.920]   what I kind of thought um I kind and I kind of got this from the the Google Home devices too is I
[01:15:28.920 --> 01:15:34.760]   feel a certain amount of of Amazon envy from Google with some of this stuff where Amazon has done or
[01:15:34.760 --> 01:15:38.360]   I think better than any other company right now and a lot and a lot of this kind of space is really
[01:15:38.360 --> 01:15:44.840]   kind of taken over the home space um because of the success of the echo products and some of their
[01:15:44.840 --> 01:15:49.000]   other things and so I look at the new Google Home minis and the redesigned Google Home and all that
[01:15:49.000 --> 01:15:52.760]   stuff and I look at even these things and I think that it's kind of like them trying to
[01:15:52.760 --> 01:15:59.480]   to succeed the way that Amazon has um in those kind of you know new new spaces that like the home
[01:15:59.480 --> 01:16:04.840]   well let's take a break and then we'll talk about that because we are going to have a war in the
[01:16:04.840 --> 01:16:10.280]   home there is going to be stuff galore listening to you taking pictures of you
[01:16:11.960 --> 01:16:19.400]   invading your privacy and Google's getting in on the action just as much as Amazon is and then now I
[01:16:19.400 --> 01:16:23.880]   guess uh Microsoft is there's going to be a Cortana appliance from Harman Carden
[01:16:23.880 --> 01:16:30.280]   Apple apparently there's going to be a series a number of Siri appliances your home's going to be
[01:16:30.280 --> 01:16:37.960]   all singing all talking soon it's fun to have you all Christina Warren's here new job but I'm you
[01:16:37.960 --> 01:16:42.360]   know at first I thought oh I can't have her on now because she works at Microsoft and I
[01:16:42.360 --> 01:16:46.920]   I thought no of course I can Christina is not gonna she's not gonna shut up or
[01:16:46.920 --> 01:16:54.040]   it's gonna be Christina and I was right always great to have you you're one of my favorite
[01:16:54.040 --> 01:16:59.400]   people on the show Ben Parr one of my favorite people period author of Captivology and my new
[01:16:59.400 --> 01:17:05.640]   best friend Micah Sargent that's great to have you too senior editor at Mobile Nations our
[01:17:05.640 --> 01:17:10.280]   show day brought to you by Zip recruiter if you're in the job hunt whether you're looking for a job
[01:17:10.280 --> 01:17:15.960]   or looking for an employee you ought to know about Zip recruiter Zip recruiter is for somebody who's
[01:17:15.960 --> 01:17:20.680]   doing the hiring and if I don't know if that's you and your company or maybe you're the HR person
[01:17:20.680 --> 01:17:25.560]   maybe it's just a small company and it's just you you really need to know about Zip recruiter because
[01:17:25.560 --> 01:17:32.360]   it is the way it's a smart tool using the power of the internet to reach out to more people so you
[01:17:32.360 --> 01:17:40.520]   are more likely to find that perfect employee you post on Zip recruiter instantly it's posted on
[01:17:40.520 --> 01:17:45.960]   over 100 of the web's leading job boards just one click at Zip recruiter plus Twitter plus Facebook
[01:17:45.960 --> 01:17:51.960]   plus all the social networks right away so you're instantly I mean within 24 hours you're going to
[01:17:51.960 --> 01:17:58.760]   start getting applicants rolling in they use their smart matching technology actively notifying
[01:17:58.760 --> 01:18:05.080]   qualified candidates about your job too so that's interesting they have millions of resumes lots of
[01:18:05.080 --> 01:18:11.000]   people looking for work at Zip recruiter.com they will instantly match them up unlike other
[01:18:11.000 --> 01:18:15.240]   hiring sites Zip recruiter doesn't depend on the right candidates finding you it goes out and it
[01:18:15.240 --> 01:18:19.960]   finds them you even get a head start on the interview process they make it very easy because
[01:18:19.960 --> 01:18:23.240]   of course if you're going to reach out to all these job boards you know you're going to get a lot
[01:18:23.240 --> 01:18:27.880]   of applicants but they don't come into your email inbox they don't come to your voicemail they go
[01:18:27.880 --> 01:18:33.880]   into the Zip recruiter interface where you can add screening questions to help qualify the most
[01:18:33.880 --> 01:18:39.240]   qualified candidates they format the resume so it's easy to read they're all the same
[01:18:39.240 --> 01:18:45.880]   it couldn't be easier than you just go through the the candidates that pass your your screening
[01:18:45.880 --> 01:18:51.000]   questions you rank them and you hire the right one fast 80% of employers who post on Zip recruiter
[01:18:51.000 --> 01:18:59.160]   get a qualified candidate through the site in one day one day couldn't be easier if you're hiring
[01:18:59.160 --> 01:19:05.080]   zip recruiter.com the smartest way to hire find out why Zip recruiter has been used by businesses
[01:19:05.080 --> 01:19:09.320]   look at all these business of all different sizes more than a million businesses we've used it little
[01:19:09.320 --> 01:19:16.760]   business like us but so has Netflix so as target so as a Volkswagen an AT&T I mean this is a really
[01:19:17.480 --> 01:19:24.840]   powerful platform and right now you could post jobs on Zip recruiter for free go to zip recruiter.com/twit
[01:19:24.840 --> 01:19:32.760]   zip recruiter.com/twit and by the way if you're looking to hire technical people
[01:19:32.760 --> 01:19:39.560]   it's a great place for any skill set anywhere in the nation zip recruiter.com/twit
[01:19:40.280 --> 01:19:44.440]   did you know that Siri is six years old turned six years old on October 4th.
[01:19:44.440 --> 01:19:51.000]   Yeah wow wow it seems like it hasn't really matured anyway.
[01:19:51.000 --> 01:19:58.440]   I remember the original Siri that the 2010 Siri which was an app before Apple bought it.
[01:19:58.440 --> 01:20:06.440]   Right in fact those guys started was it VIV.ai which they got purchased by Samsung. Yeah sure did.
[01:20:06.440 --> 01:20:14.920]   So they're still around it was on the iPhone 4S. So this was Apple's version of it on the iPhone
[01:20:14.920 --> 01:20:22.520]   4S. Siri was cute at first because she you know had funny responses but I okay you're all Apple
[01:20:22.520 --> 01:20:28.760]   phone users do you find Siri useful I find myself swearing at Siri more than I do thanking her.
[01:20:28.760 --> 01:20:34.680]   I use it alarms that's about it. Good for setting alarms reminders calendar appointments. Yeah
[01:20:34.680 --> 01:20:39.720]   limited limited use cases like there will be sometimes I will ask at a very basic question like the
[01:20:39.720 --> 01:20:43.560]   weather it'll work. Yeah I can do the weather but if you ask it anything more than that it'll
[01:20:43.560 --> 01:20:48.840]   almost always say I found something on the web for this right which is never anything you want.
[01:20:48.840 --> 01:20:55.240]   My favorite thing is when you get a new app and it's leaving you a bunch of stupid notifications
[01:20:55.240 --> 01:21:00.680]   and so you're getting annoyed by it you can ask Siri to open up the notification settings for
[01:21:00.680 --> 01:21:07.880]   that app to tap all the way through to get to the page. See this is part of the problem with all
[01:21:07.880 --> 01:21:12.840]   these voice assistants they can do things but there's no way to figure out what they can do.
[01:21:12.840 --> 01:21:19.800]   That's a great one Mike. That's really useful. So what do you say? Yeah you say open blah blah
[01:21:19.800 --> 01:21:23.480]   blah blah settings like open settings for the camera app.
[01:21:26.600 --> 01:21:31.000]   I have to unlock the iPhone first. Let's see what I found on the web for that.
[01:21:31.000 --> 01:21:37.080]   Oh no it did it worked. Yay Siri you're the best. I'm sorry it's anything bad about you.
[01:21:37.080 --> 01:21:43.640]   It should go directly to the yeah to the page so I like to use the I you know anytime those
[01:21:43.640 --> 01:21:48.040]   especially like food delivery apps they love to say oh we've got 20% off for the next hour.
[01:21:48.040 --> 01:21:51.960]   That's crazy. Open settings immediately. I agree with the right to that page and shut off the
[01:21:51.960 --> 01:21:57.000]   notifications. You like uninstalled some apps from your phone. My thing has been
[01:21:57.000 --> 01:22:01.480]   turning off notifications for every single thing except Slack. But Apple does not make that easy
[01:22:01.480 --> 01:22:06.520]   because you have to go app first of all it's always drive driven me crazy that all the settings in
[01:22:06.520 --> 01:22:10.680]   the iPhone they're not in the app. Well some of them are. Some of them are. Some of them are.
[01:22:10.680 --> 01:22:14.600]   Yeah that's bad. It's confusing. Some of them are and then some most of them are there.
[01:22:14.600 --> 01:22:18.280]   I guess Apple wants them to be in this notification. They wanted to be in the settings thing. Yeah
[01:22:18.280 --> 01:22:22.760]   they wanted to be in the settings app not the app itself but you're right. Some apps. There needs
[01:22:22.760 --> 01:22:27.640]   to be a switch though that says turn off. There's do not disturb but there needs to be any switch
[01:22:27.640 --> 01:22:33.160]   that says I don't want notification from anybody. Let me like reverse it. I'll tell you if I want
[01:22:33.160 --> 01:22:38.680]   notification from you. But the default is everybody notifies you for everything all the time. Yep.
[01:22:38.680 --> 01:22:42.760]   Don't like it. And I have hundreds of apps. I'm not going to go through these one by one.
[01:22:42.760 --> 01:22:46.040]   Part of that original information overload thing we talked about the beginning of this
[01:22:46.040 --> 01:22:51.320]   episode. Yeah. So all those notifications naturally you that's new information every single time one
[01:22:51.320 --> 01:22:56.520]   pops up you're like I have to check your your trained. You have to check it. You have to check
[01:22:56.520 --> 01:23:03.320]   it. The phrase is continuous partial attention. That's the phrase I bet you Georgia Dow uses.
[01:23:03.320 --> 01:23:06.440]   That sounds like some Georgia Dow would have thought it does. It does. Yeah.
[01:23:06.440 --> 01:23:10.600]   Continuous part. So I mean you're constantly spinning little parts cognitive load devoted
[01:23:10.600 --> 01:23:15.640]   to. It never paid attention to anything 100%. It's all partial attention to everything.
[01:23:15.960 --> 01:23:21.400]   I feel like in this assistant war. So there's like that. And then in this assistant war like
[01:23:21.400 --> 01:23:24.840]   I find for example I have a Google home and I have an Alexa and I find the Google home can
[01:23:24.840 --> 01:23:29.640]   answer more questions has better context but but the Alexa has a battery call it echo so we don't
[01:23:29.640 --> 01:23:35.560]   treat the echo. Yeah. Oh the echo has a better ecosystem. More skills have been built to. I use
[01:23:35.560 --> 01:23:40.760]   echo all the time and I have a Google home and I rarely use it but it recognizes more things if
[01:23:40.760 --> 01:23:47.240]   you like mostly because I use the echo for music and for timers. Yeah. And set like my
[01:23:47.240 --> 01:23:52.280]   echo is the one that set for all the like the lights in my house. Right. Yeah. Same. Well
[01:23:52.280 --> 01:23:56.520]   that's why I thought what Google did this week was interesting because they made a strong play
[01:23:56.520 --> 01:24:01.560]   for the home and I have actually talked to developers who say it's hard to develop for Apple's home.
[01:24:01.560 --> 01:24:08.280]   They're everybody's very interested though if you ask me everybody I've talked to in Amazon.
[01:24:08.280 --> 01:24:12.920]   That's the that's where you want to be. Google clearly says no no no we want to be the
[01:24:12.920 --> 01:24:18.120]   assistant that you control your home with but with the problem this is that ecosystem thing again
[01:24:18.120 --> 01:24:23.800]   consumers are going to you don't want all of them you're going to pick one and invest in one
[01:24:23.800 --> 01:24:28.520]   and then and and the investment at some point is going to get high enough that you're just done.
[01:24:28.520 --> 01:24:33.880]   Right. I mean it's which totally I mean and they think that that you know the fact that that
[01:24:33.880 --> 01:24:39.480]   Amazon and Microsoft are working together so that Cortana and and the echo will work together
[01:24:39.480 --> 01:24:45.000]   is it's kind of shows that even within those companies they're kind of picking winners so to speak.
[01:24:45.000 --> 01:24:49.080]   And you're right like Google is definitely making a big play for the home and I wouldn't count them
[01:24:49.080 --> 01:24:53.800]   out in the slightest and definitely I think that they are going to make it easier for people to
[01:24:53.800 --> 01:24:59.080]   bright things than you know the home kit stuff is because Apple's very specific about who can
[01:24:59.080 --> 01:25:03.240]   have home kit access and I understand that from a privacy perspective and a user data perspective
[01:25:03.240 --> 01:25:07.880]   that's all very good but what it means is that it's a lot more difficult for cool things to happen
[01:25:07.880 --> 01:25:12.840]   and so also frankly you know until the home pod which is very expensive comes out there won't be a
[01:25:12.840 --> 01:25:17.640]   single appliance that's not your phone that will be able to kind of do a lot of these things you
[01:25:17.640 --> 01:25:23.800]   know or your Apple TV to it to a much lesser degree but I think that you know Amazon has
[01:25:23.800 --> 01:25:29.480]   I don't think they expected the the echo the original echo to be so successful but I think
[01:25:29.480 --> 01:25:33.080]   with the echo dot and kind of this whole ecosystem and by having a really good
[01:25:33.080 --> 01:25:39.000]   SDK and an open API you know from the beginning for the skills and why not even if most of the
[01:25:39.000 --> 01:25:43.720]   stuff isn't that useful they really kind of have one mind share for a lot of people and so
[01:25:43.720 --> 01:25:48.040]   everything works with the echo you know everything works with Amazon whereas
[01:25:48.040 --> 01:25:53.720]   you know it's going to be a much harder thing for any of the other companies to kind of get even
[01:25:53.720 --> 01:25:58.120]   the bigger players on board not to mention that the smaller people like but if you are a consumer
[01:25:58.120 --> 01:26:03.960]   like if I'm trying to say what home assistant should I buy if you're really into the Google
[01:26:03.960 --> 01:26:07.960]   ecosystem a Google home could be great and like Ben said it can be better to answer certain questions
[01:26:07.960 --> 01:26:12.840]   right but if you're saying I have some things from this company some things from this company I
[01:26:12.840 --> 01:26:18.440]   really just want to control music maybe my lights maybe do a couple of other things basically every
[01:26:18.440 --> 01:26:23.080]   light provider and and every you know smart home provider at this point is is hooking into the
[01:26:23.080 --> 01:26:27.960]   Amazon ecosystem if they can so it's kind of hard to recommend against them if that makes any sense
[01:26:27.960 --> 01:26:34.280]   yeah no right now Amazon's the lead horse the real question is if Google can catch up but the
[01:26:34.280 --> 01:26:41.000]   other question is given that series the first of these what did Apple do wrong why isn't Apple
[01:26:41.000 --> 01:26:47.400]   doing better I don't a lot of people argue that it's the fact that it's because of Apple's like
[01:26:47.400 --> 01:26:53.800]   tied to privacy and things like that and and so they don't have necessarily as much of the online
[01:26:53.800 --> 01:26:58.440]   processing that some of these other companies have and the way that it works you know to collect
[01:26:58.440 --> 01:27:03.800]   information and process that and then roll it out but I also think it's the fact that up to this
[01:27:03.800 --> 01:27:09.880]   point like Apple is just now finally coming out with this sort of disembodied device that is just
[01:27:09.880 --> 01:27:14.920]   meant to interface with Siri whereas we've had the echo and we've had the Google home for quite
[01:27:14.920 --> 01:27:22.120]   some time and these devices have the Google assistant and a l e x a respectively and so we've sort of
[01:27:22.120 --> 01:27:29.160]   you know tied our brains at least to this assistant that lives in a tube or this weird circular thingy
[01:27:29.160 --> 01:27:34.360]   that the the Google home speaker is oh you got wait a minute you got one with the copper bottom
[01:27:34.360 --> 01:27:39.720]   yeah well it's orange really cool orange color now I don't like it as much
[01:27:39.720 --> 01:27:44.520]   did it come in orange or did you get one of those special inserts that they're making
[01:27:44.520 --> 01:27:49.160]   that I yeah I bought one because I didn't like it was like gray that it gets great fabric
[01:27:49.160 --> 01:27:54.280]   it goes all over the fabric I understand why everything's fabric colored again they really
[01:27:54.280 --> 01:27:58.200]   like that I mean and some people really like it I mean I think it does make it look a little
[01:27:58.200 --> 01:28:03.960]   bit less sterile you know it's not plastic in a way yeah exactly I mean and even if you look at
[01:28:03.960 --> 01:28:08.200]   this stuff that Amazon announced last week I mean they're kind of going more in that direction
[01:28:08.200 --> 01:28:12.440]   to have trying to make it and look at Apple's HomePod that's a fabric thing yeah right exactly
[01:28:12.440 --> 01:28:19.000]   fabric colored tater tot it was interesting Google clearly is responding to Apple's HomePod
[01:28:19.000 --> 01:28:27.240]   they have now the Google Home Mini which looks like a nice pink donut with sprinkles they have a
[01:28:27.240 --> 01:28:31.160]   Google Home they don't call it this but the Google Home MIDI the original Google Home and they have a
[01:28:31.160 --> 01:28:41.000]   Google Home Maxi for those heavy flow months no for this I'm sorry we got to avoid I try to avoid
[01:28:41.000 --> 01:28:46.040]   that and I could this is a little bit it's not as big as it might appear they're very careful
[01:28:46.040 --> 01:28:52.920]   they only show it in abstract but it's about as big as a shoe box looks like a sonos it looks a lot
[01:28:52.920 --> 01:28:58.840]   of a sonos I mean which was this week Sonos finally announced the official Amazon and it works I'm
[01:28:58.840 --> 01:29:05.160]   happy to say I installed it I can now I put a dot you have to connect because I don't get the Sonos
[01:29:05.160 --> 01:29:10.600]   one I don't have yet their new speaker that will do this but if you have an echo dot you could plug
[01:29:10.600 --> 01:29:14.280]   it into the back of the Sonos I don't know how they're doing it some sort of magic there's an echo
[01:29:14.280 --> 01:29:21.480]   skill that you have to turn on and now I can shout anywhere in my house I have to shout what do I
[01:29:21.480 --> 01:29:28.840]   shout it's a complicated it's it's if I had to parse this in English class I'd fail echo play
[01:29:28.840 --> 01:29:39.720]   Kenny Rogers on master bathroom Sonos and that oh no but then but the next play one will actually
[01:29:39.720 --> 01:29:44.840]   just have the echo stuff built in so presumably you'll be able to set it up and it works what's
[01:29:44.840 --> 01:29:49.640]   interesting is not all the Amazon echo features will work but but all but I can hear the music
[01:29:49.640 --> 01:29:54.840]   that I want all the Sonos music I am I actually this they should have done this months ago because
[01:29:54.840 --> 01:29:59.240]   by being so late to the market they were supposed to they were supposed to be they did originally
[01:29:59.240 --> 01:30:04.120]   Sonos that originally announced this integration in I want to say it was August of last year because
[01:30:04.120 --> 01:30:09.000]   I was at the event New York and they were they were in beta testing it's supposed to be out early 2017
[01:30:09.000 --> 01:30:12.680]   so now you know more than a year after it was announced it's finally rolled out but I thought
[01:30:12.680 --> 01:30:17.000]   the bigger news obviously the integration is great for the existing Sonos users who I think
[01:30:17.000 --> 01:30:20.760]   there's probably if you were to look at it probably huge overlap between people who have a Sonos and
[01:30:20.760 --> 01:30:25.480]   people who have at least one echo product but I think having the new play one that has it built
[01:30:25.480 --> 01:30:30.280]   in is really compelling and especially at its price point because at that point I'm saying okay
[01:30:30.280 --> 01:30:35.240]   well why would I buy a Google home max or why would I buy it's 199 right or why would I buy a
[01:30:35.240 --> 01:30:40.520]   home pod if I if you know if I can get this Sonos thing which will provide great sound and work
[01:30:40.520 --> 01:30:47.240]   with my existing and I think my sense is that you get one one and it controls all your Sonos
[01:30:47.240 --> 01:30:53.000]   speakers you don't have to yes so they're all now in echo enabled which is great yep yeah and
[01:30:53.000 --> 01:30:57.960]   later on there I think it was it in 2018 they'll bring the Google Assistant and see it well Siri
[01:30:57.960 --> 01:31:04.200]   through a an iOS device but the Google Assistant fullheartedly into the Sonos one as well so
[01:31:04.200 --> 01:31:07.960]   I think that that's really cool that you're basically getting to choose between the three
[01:31:07.960 --> 01:31:13.000]   with the Apple integration not as great as the other two but to be able to choose between
[01:31:13.000 --> 01:31:17.560]   a LEXA and the Google Assistant I think is really nice and I just want to set the record
[01:31:17.560 --> 01:31:20.120]   straight I don't actually listen to Kenny Rogers in the shower
[01:31:20.120 --> 01:31:27.240]   we should just that was an example just embrace it I listen to Led Zeppelin in the show
[01:31:28.360 --> 01:31:34.200]   I sing along too
[01:31:34.200 --> 01:31:41.960]   you know they made a real mistake I think with the Google Home Mini
[01:31:41.960 --> 01:31:46.920]   by not including a headphone jack I thought you were gonna say sprinkles
[01:31:46.920 --> 01:31:51.400]   okay you're right there I think you're right there I think you're dead on the headphone jack
[01:31:51.400 --> 01:31:55.400]   what would that be that's what the egg that's what makes the echo dot so great is that you can get
[01:31:55.400 --> 01:32:00.200]   a dot and then connect it to a fantastic speaker system that you already have in your home yeah not
[01:32:00.200 --> 01:32:06.600]   a head not for headphones but for a line out you know I agree that's the best thing about the
[01:32:06.600 --> 01:32:11.640]   dot in fact my dots I have all the dots I have in the house are connected to bigger speakers
[01:32:11.640 --> 01:32:15.800]   nicer speaker systems and in fact that's one of the things that allows Sonos to use a dot as
[01:32:15.800 --> 01:32:20.920]   its controller because you take the line out of the dot and put it into the lining on the Sonos so
[01:32:20.920 --> 01:32:24.440]   that's interesting why they didn't include why didn't they do them maybe it was
[01:32:24.440 --> 01:32:29.240]   same reason I put a headphone jack on the pixel it's just must be you have a dongle for that now
[01:32:29.240 --> 01:32:33.080]   yeah just say it takes too much space it's a bluetooth speaker though right you can
[01:32:33.080 --> 01:32:36.760]   yeah you can bluetooth you can bluetooth I mean which you can do with the dot as well but I think
[01:32:36.760 --> 01:32:40.440]   you're right I mean I do the same thing that you guys do like I use my dots I have them connected
[01:32:40.440 --> 01:32:45.960]   to better to better speakers that's what I think makes it such a good value at 50 bucks so what
[01:32:45.960 --> 01:32:52.920]   I'm consumers what's now we do this you did this earlier with the pixel book we're a one group
[01:32:53.640 --> 01:32:58.840]   obviously very different from the normal consumer what does anybody know what normal people think
[01:32:58.840 --> 01:33:04.760]   my in-law my in-law normal people without without without our prompting for a person what does a
[01:33:04.760 --> 01:33:12.120]   simple fuck do look I want to say this without promising my in-laws this year were really on
[01:33:12.120 --> 01:33:18.920]   the on the echo band wagon and and and got them for like a ton of people and including my husband
[01:33:18.920 --> 01:33:22.920]   like it was actually really interesting and they're not you know part of like they're not really
[01:33:22.920 --> 01:33:28.200]   tech savvy you know they they usually ask me for advice on things and they you know bought
[01:33:28.200 --> 01:33:33.160]   echo dots for a lot of people as Christmas gifts so they buy without asking you yes wow
[01:33:33.160 --> 01:33:37.560]   so that means they were confident they knew what they would do they they knew they would be well
[01:33:37.560 --> 01:33:43.240]   received so they really they under in other words they understand Amazon's echo should I mean
[01:33:43.240 --> 01:33:48.360]   maybe not all the intricacies but knew they've heard enough about it saw I agree Amazon's the
[01:33:48.360 --> 01:33:53.720]   winner in this yeah I mean and if you look at according to Amazon anyway you know they claim that
[01:33:53.720 --> 01:33:58.120]   they during the last holiday season and also I think during prime day that they sold the the
[01:33:58.120 --> 01:34:04.680]   best-selling item was was the echo dot so they're clearly selling tons of these things so I mean I
[01:34:04.680 --> 01:34:08.760]   think that regular people that's probably again I think this this this goes in line with what
[01:34:08.760 --> 01:34:13.000]   developers are doing and one of the reasons why the mind share tends to be there is that
[01:34:13.000 --> 01:34:18.280]   you know they're the ones that everyone has agreed that's been my experience as well I remember
[01:34:18.280 --> 01:34:23.320]   going over a friend's house who's not a techie in the slightest and he turned on the lights with
[01:34:23.320 --> 01:34:28.920]   a command to you know the the echo device and I was like you have an echo just wasn't expecting
[01:34:28.920 --> 01:34:33.560]   that and I mean that was the one that he body found out how to set it up got it all figured out
[01:34:33.560 --> 01:34:38.840]   and enjoyed it and that's been the experience that I've seen is is people going to that one I think
[01:34:38.840 --> 01:34:44.040]   part of the thing too is though it's like a lot of people do shop on Amazon and when that is right
[01:34:44.040 --> 01:34:48.120]   there and you're able to purchase it and you know you see you see the commercials but then you know
[01:34:48.120 --> 01:34:53.880]   where to go it's interesting how many people don't necessarily know like I need to go to what
[01:34:53.880 --> 01:34:58.280]   what Google site do I go to how do I find how to buy a Google home or how do I find where to buy
[01:34:58.280 --> 01:35:02.520]   a home pod it's not as it's going to buy echoes this whole food yeah I was going to
[01:35:02.520 --> 01:35:09.640]   go out for pretty soon like 10 to 15 years from now we'll be getting our check out with ALEXA
[01:35:09.640 --> 01:35:16.760]   at our Whole Foods yeah wow that's interesting wow you can order I mean I could order groceries
[01:35:16.760 --> 01:35:22.120]   through the echo I was at our whole food our local Whole Foods the other day they now have
[01:35:22.120 --> 01:35:29.320]   Amazon lockers there they have Amazon deals they cut the price on their ribeye stakes Amazon special
[01:35:29.320 --> 01:35:33.880]   so Amazon's really changing Whole Foods is very interesting and I bet you it will end up being
[01:35:33.880 --> 01:35:40.280]   a place you could buy Amazon hardware which is oh I'm sure yeah why would you not I mean they
[01:35:40.280 --> 01:35:44.120]   they have I mean kind of the same way that that you know the Apple Store kind of exists
[01:35:44.120 --> 01:35:47.880]   as a way to push things and you know Barnes and Noble when they were trying with the Kendall and
[01:35:47.880 --> 01:35:51.640]   things like that and Microsoft has their stores I mean Amazon it's really interesting they had
[01:35:51.640 --> 01:35:56.760]   some of the bookstores in various cities but now by buying this this grocery chain they've actually
[01:35:56.760 --> 01:36:03.400]   now have a way to push some of their official items even if it even if you wouldn't normally think
[01:36:03.400 --> 01:36:07.240]   that you would buy gadget in a grocery store but I mean that's what what the super Walmart
[01:36:07.240 --> 01:36:12.600]   have taught us is that you know clothing and clothes and and and and food and electronics can
[01:36:12.600 --> 01:36:20.680]   all sit side by side and no one really bats an eye so it's it's first of all this is a very
[01:36:20.680 --> 01:36:25.240]   surprising category they came out of nowhere I mean maybe with Siri people thought oh this is
[01:36:25.240 --> 01:36:32.360]   that but Amazon really really came out of nowhere and just owns this can they can they hold this
[01:36:32.360 --> 01:36:37.960]   lead or it is and who's their challenger it feels like Google's the only one that can offer them a
[01:36:37.960 --> 01:36:43.320]   serious challenge not Microsoft I don't think Siri's gonna offer a serious challenge is this
[01:36:43.320 --> 01:36:50.840]   Amazon's to lose at the moment for sure yeah and like like to their credit they had like 5,000
[01:36:50.840 --> 01:36:57.480]   people working on the amazon from on the echo division they like massively increase the number
[01:36:57.480 --> 01:37:02.200]   they're investing hard in it as they should but the Bezos has not won to lose a lead
[01:37:02.200 --> 01:37:08.280]   Jeff is an amazing fella I feel like I would never want to bet against Jeff Bezos never want to
[01:37:08.280 --> 01:37:13.000]   eat against base yeah no kidding have you seen those charts they're always going up yeah
[01:37:13.000 --> 01:37:16.920]   yeah pretty impressive but Google if anybody's gonna do it it'd be Google Google's got the
[01:37:16.920 --> 01:37:22.680]   resources where Google has a huge advantage and where they could I think right now it's a one horse
[01:37:22.680 --> 01:37:28.280]   race Amazon's way ahead but if I were looking at Google I'd say that's that that kid that kid could
[01:37:28.280 --> 01:37:33.480]   do it because they've got a huge advantage in artificial intelligence right no one has as much
[01:37:33.480 --> 01:37:39.080]   data no one's been doing it as long no one has as much machine learning Google could become
[01:37:39.080 --> 01:37:45.480]   you know her you know Scarlett Johansson in your ear but whereas I don't think Amazon's
[01:37:45.480 --> 01:37:51.240]   close to anything like that they don't have the data they don't have the the software no you
[01:37:51.240 --> 01:37:54.840]   think you're right although I do think again and I don't know all the details other than
[01:37:54.840 --> 01:37:59.640]   was publicly announced but I mean I think that's where like the Cortana Amazon relationship becomes
[01:37:59.640 --> 01:38:03.560]   sort of interesting because obviously and Microsoft has been doing a ton of stuff with
[01:38:03.560 --> 01:38:07.320]   artificial intelligence and machine learning and that actually does become interesting if you
[01:38:07.320 --> 01:38:12.280]   start to maybe think about how that partnership could help so you think this is saying well
[01:38:12.280 --> 01:38:17.800]   Microsoft's gonna give us the stuff we're missing in a term right and and and and and I think the
[01:38:17.800 --> 01:38:23.560]   reverse is true is that is that Microsoft is saying even though we're going to have devices
[01:38:23.560 --> 01:38:28.200]   in the home maybe through other people and even though you know Windows 10 which has you know
[01:38:28.200 --> 01:38:33.080]   hundreds of millions of installs has Cortana built into it and all that sort of thing we don't have
[01:38:33.080 --> 01:38:38.840]   the you know echo like product so this will help get us into more places in a different
[01:38:38.840 --> 01:38:44.360]   situation and Amazon saying and and we can use some of you know Microsoft's you know experience
[01:38:44.360 --> 01:38:49.000]   with AI and machine learning to help our stuff improve and then together they might actually be
[01:38:49.000 --> 01:38:55.720]   able to be you know a challenge to what the her sort of thing that that that that Google is
[01:38:55.720 --> 01:39:00.440]   is potentially doing. Here's an interesting question but all Microsoft with Cortana
[01:39:00.440 --> 01:39:06.920]   Apple with Siri even Google with their Chromebooks have a desktop assistant you could there's actually
[01:39:06.920 --> 01:39:10.840]   on the new pixel books there's a button for Google Assistant yeah of course Cortana you just say
[01:39:10.840 --> 01:39:17.960]   hey Cortana pops up Siri same thing I never use it I actually don't even really use it on the
[01:39:17.960 --> 01:39:22.200]   phone that much there's something magical at least for me about saying talking to my house is what
[01:39:22.200 --> 01:39:27.480]   I really want to do is that your experience as well that's my experience what I will say
[01:39:27.480 --> 01:39:33.800]   and I weirdly I never use Siri on my Mac ever ever I just in the year that I've done it I've
[01:39:33.800 --> 01:39:38.040]   almost never used it primarily because it's not that good I have found myself because I've been
[01:39:38.040 --> 01:39:43.080]   using a Surface Book at work for the last few months and before that I hadn't really used Cortana
[01:39:43.080 --> 01:39:47.240]   I will say although I don't speak to it I don't I don't talk to Cortana I do find myself typing
[01:39:47.240 --> 01:39:52.600]   things into the Cortana bar because I find that to be very good you know to find a certain file or
[01:39:52.600 --> 01:39:56.760]   to get information about the weather or or something else I find that's not a speech assistant though
[01:39:56.760 --> 01:40:02.920]   that's just right but it's still asking a specific question in a way that I couldn't ask
[01:40:02.920 --> 01:40:07.320]   spotlight it's still giving me more more updated information but I'm with you I for whatever reason
[01:40:07.320 --> 01:40:12.600]   I don't talk to my computer but I talk to my house and and it just feels natural it does feel different
[01:40:12.600 --> 01:40:17.240]   yeah oh you know you know the one and it's weird because here's the one case I do use Siri I use
[01:40:17.240 --> 01:40:23.800]   Siri with my Apple TV I use Siri with my Apple TV all the time and I use Google Assistant with
[01:40:23.800 --> 01:40:28.600]   my Android TV with my Android TV yeah and I use it's natural to search for you know I want
[01:40:28.600 --> 01:40:33.800]   Alec Baldwin movies it's natural to do that yeah but that's the one time you do it and it's because
[01:40:33.800 --> 01:40:39.480]   you can't really type on a TV you can't be terrible but he also works the way you expect it to work
[01:40:39.480 --> 01:40:42.760]   right that's the really important thing and I think this is still we're talking about how
[01:40:42.760 --> 01:40:47.400]   it's the sixth year anniversary of Siri I think part of the problem with Siri has been is that
[01:40:47.400 --> 01:40:52.760]   when it first came out you know it was good at certain things and it wasn't good at others and
[01:40:52.760 --> 01:40:56.760]   people kind of gave up on it and it has improved a lot over the years but a lot of people myself
[01:40:56.760 --> 01:41:00.840]   included just don't want to try because I just remember what it was like when it couldn't you
[01:41:00.840 --> 01:41:05.000]   know even now like you were saying you ask a question I'll send you to the web result
[01:41:05.000 --> 01:41:09.480]   for results or it was like I don't understand that and you know you just kind of got used to
[01:41:09.480 --> 01:41:13.240]   at least in my mind I was like well Siri is not going to be able to give me an answer so I'm just
[01:41:13.240 --> 01:41:18.600]   not even a way to think to ask it things whereas with the number of years that had passed by the
[01:41:18.600 --> 01:41:23.480]   time that you know Siri launched on the iPhone 4s and the first echo came out you know that was
[01:41:23.480 --> 01:41:30.520]   what like I guess three years and at that point because it was 2015 that the so I guess it was
[01:41:30.520 --> 01:41:34.680]   four years oh you know it was three years it was the end of 2011 and then the beginning of 2015
[01:41:34.680 --> 01:41:42.600]   in that time I think that you know things that improved to the point where we didn't have a lot
[01:41:42.600 --> 01:41:46.920]   of high expectations for the original echo and then when it started to be able to do things and
[01:41:46.920 --> 01:41:51.640]   and you know control your lights play music you know give the weather set a timer do that sort of
[01:41:51.640 --> 01:41:56.600]   stuff you become more comfortable with talking to it in addition to it just being more
[01:41:56.600 --> 01:42:01.560]   convenient to to talk to your house versus you know having to hold down originally on a button on
[01:42:01.560 --> 01:42:10.120]   your phone and and that sort of thing a data point there to my partner is like sort of my litmus
[01:42:10.120 --> 01:42:15.000]   test for the norms that's called people who are not as into technology as we are people who are
[01:42:15.000 --> 01:42:21.400]   not as steep in technology and it's interesting because you know early on he I think gave Siri way
[01:42:21.400 --> 01:42:26.520]   more chances than I ever did yeah we all got used to the fact that it failed a lot and it may have
[01:42:26.520 --> 01:42:30.920]   gotten better but I just don't want to take the time to watch it fail if it will but he uses
[01:42:30.920 --> 01:42:36.440]   aLEXA all the time we'll ask it questions we'll ask it about the traffic we'll ask it well I mean
[01:42:36.440 --> 01:42:42.360]   no problem at all and even when it will fail occasionally then you know he's forgiving of it
[01:42:42.360 --> 01:42:47.160]   and we'll try again or say it a different way so it's I think you know Amazon really has gotten out
[01:42:47.160 --> 01:42:52.280]   ahead here and has sort of these other companies have a lot of work to do I think it's also just
[01:42:52.280 --> 01:42:57.000]   even like having to pull out the phone and hold down the button to like do that that's so much
[01:42:57.000 --> 01:43:02.040]   trouble although you know you can say hey yeah but maybe the other thing too is just like the amount
[01:43:02.040 --> 01:43:06.760]   the the perfection and voice recognition really does matter and I feel like it aLE
[01:43:06.760 --> 01:43:11.080]   it just feels like maybe it isn't anymore but it used to feel like just Siri would miss
[01:43:11.080 --> 01:43:16.680]   at least two different words aLEXA will miss less words right google home even less and so I tend
[01:43:16.680 --> 01:43:21.800]   to talk to those two yeah my my wife and I like you Mike and my wife and I have a
[01:43:21.800 --> 01:43:26.840]   she uses it a lot we have kind of a standing joke I just say oh you continue to have faith
[01:43:26.840 --> 01:43:34.680]   don't you you you believe you believe and it never it never works out it's right although
[01:43:34.680 --> 01:43:39.480]   the when it does it's kind of magical isn't it like when you ask your own thing it's like oh
[01:43:39.480 --> 01:43:46.200]   good wow wow she she actually understood me and and said something instead of a snarky joke
[01:43:47.080 --> 01:43:51.240]   yeah in fact i'll be like the the jaded person you know he'll say something and i'm like that's
[01:43:51.240 --> 01:43:55.080]   not gonna work you realize that's like and then it works and i'm like uh
[01:43:55.080 --> 01:44:02.920]   thought yeah thought yeah i feel like i oh well it's this is to me it's the surprise category that
[01:44:02.920 --> 01:44:07.960]   really uh is exciting i mean i think it's one of the most exciting things is happening in tech
[01:44:07.960 --> 01:44:15.320]   it's not smartphones it's not cameras it's not uh self-driving cars it's it's voice assistance it's
[01:44:15.320 --> 01:44:20.200]   just it's really kind of taken off and it's interesting the battle is shaping now apples
[01:44:20.200 --> 01:44:27.960]   home pod comes out in december googles uh maxi comes out in uh december um this and i think the
[01:44:27.960 --> 01:44:33.240]   harmen carton cortana device comes out in december so it's gonna be a variant and an amazon has like
[01:44:33.240 --> 01:44:38.520]   18 form factors nobody even understands what is this why do you have that what is that and amazon's
[01:44:38.520 --> 01:44:44.120]   just like which which one goes best just take one fine this the real test will be i i ordered the
[01:44:44.120 --> 01:44:49.400]   what the clock one what is that called yes me too the dot yeah that's got a camera on it and the
[01:44:49.400 --> 01:44:54.680]   real test is if my wife will let me put it in on my bedside table or not and it's arriving
[01:44:54.680 --> 01:45:01.800]   it's coming so it's arriving on my birthday and i can't wait to set it on my uh on my table it's
[01:45:01.800 --> 01:45:04.920]   the disney you put in your bedroom mica oh absolutely
[01:45:04.920 --> 01:45:13.720]   okay i i know it's got a camera on it i know but it's uh yeah i mean i's like i don't know i
[01:45:13.720 --> 01:45:20.280]   see for me i don't care if it catches me walking around in my underwear but but i i think maybe
[01:45:20.280 --> 01:45:24.440]   it's different for women that they don't that they worry i don't know i feel like well who's
[01:45:24.440 --> 01:45:28.600]   gonna see that nobody's gonna see that on the other hand we know it could leak out right because
[01:45:28.600 --> 01:45:36.760]   everybody's been reached and bloo yahoo now says oh sorry it wasn't a billion it was three billion
[01:45:37.640 --> 01:45:43.800]   turns out everybody and if you had a yahoo account which makes sense because they'd reset
[01:45:43.800 --> 01:45:49.240]   everyone's password right um we just thought they were just being proactive turns out and now
[01:45:49.240 --> 01:45:53.560]   and they knew something yeah i i wonder how that how the board numbers that Verizon feel when they're
[01:45:53.560 --> 01:45:58.600]   like aren't they gonna be pissed yeah or because they paid they paid like a quarter or less like they
[01:45:58.600 --> 01:46:03.560]   shaved off you know what was it like like a billion dollars off of the sales price because of the
[01:46:03.560 --> 01:46:08.280]   because of the one billion disclosure and now that they realize actually it was three times as big
[01:46:08.280 --> 01:46:14.920]   i like every person like i'm like lost what are they gonna do who do they do exactly who exactly
[01:46:14.920 --> 01:46:20.840]   is like i mean you know what i mean like oh they made the deal they they clearly didn't do their
[01:46:20.840 --> 01:46:24.360]   due diligence enough you know i mean like yeah exactly like who are they gonna go after or but
[01:46:24.360 --> 01:46:29.560]   you make the case that yahoo covered it up i mean i guess if you can prove that you know but
[01:46:29.560 --> 01:46:36.280]   but that who never happened is marissa mire still there no she left she left she took her payout and
[01:46:36.280 --> 01:46:43.000]   yeah it's all tim i'm trying to and she's she's uh well she was gonna stay not with the oath part
[01:46:43.000 --> 01:46:48.760]   but with the what did they have silly alley-cranze alley bob a holding thing yeah the alley bob a
[01:46:48.760 --> 01:46:52.360]   holding thing i don't think she's with that she doesn't stay there either i don't think so she's
[01:46:52.360 --> 01:46:57.720]   just on the beach enjoying life with their hundred million dollar payout and can you blame her i
[01:46:57.720 --> 01:47:01.240]   i know no no it's funny though because usually i was the kids that's what i would do
[01:47:01.240 --> 01:47:07.000]   but usually people like her like immediately go oh well i'm my next big challenge is gonna be
[01:47:07.000 --> 01:47:11.880]   i'm gonna figure out and i'm sure she will have i'm sure she will have her own vc fund very soon
[01:47:11.880 --> 01:47:16.440]   you know just as soon as you know she's had some time to decompose or whatever i mean i'm
[01:47:16.440 --> 01:47:21.880]   she'll join you start the adventure doing venture cap i've asked with marissa sure we did one company
[01:47:21.880 --> 01:47:26.920]   together did you um a company called ubeam wireless electricity over distance utilize how's that
[01:47:26.920 --> 01:47:32.760]   working out at us working out super awesome and i know things that i cannot talk about it's working
[01:47:32.760 --> 01:47:36.680]   is working remember the rumor was going to be that apple was going to be able to charge you just
[01:47:36.680 --> 01:47:41.240]   go into the room and it would charge and i said at the time that's never gonna happen yeah they're
[01:47:41.240 --> 01:47:45.480]   they're not but you being was the technology everybody was talking about it you mean did showed off the
[01:47:45.480 --> 01:47:51.880]   technology um at a charging at distance earlier this year and showed that like it worked but like
[01:47:52.520 --> 01:47:58.360]   i invested because i literally tried it it's it but doesn't it like fry you i mean no i mean
[01:47:58.360 --> 01:48:03.160]   this ultra ultra sound does not fry be oh it's using sound that's right it's not using uh
[01:48:03.160 --> 01:48:09.800]   electricity or RF it's just sound interesting well it's so bad i know cool things there's so
[01:48:09.800 --> 01:48:14.680]   many cool things scramble your it will not no it will not okay
[01:48:14.680 --> 01:48:22.360]   okay i sell walls they're scrambling scrambling how far how far will it go i can't
[01:48:22.360 --> 01:48:30.520]   talk about that come on nobody's here just just us just the four of us just hold out your hands
[01:48:30.520 --> 01:48:37.400]   Leo and then start going in and then he'll say he'll not his head is it is it is it this far is
[01:48:37.400 --> 01:48:44.360]   it this far i've talked your ear is it this far yeah exactly blink once no i won't put
[01:48:44.360 --> 01:48:48.920]   pain on this stuff that's interesting though you're but you're an investor new game nice well
[01:48:49.640 --> 01:48:52.840]   i'm gonna stay friends with you
[01:48:52.840 --> 01:48:57.880]   we're all friends here today right we're all friends google's accused of racketeering and
[01:48:57.880 --> 01:49:06.440]   a well-known architect uh Eli Atia spent uh 50 years developing what he calls a game-changing
[01:49:06.440 --> 01:49:13.000]   new technology for building construction in 2010 google said hey Eli that's cool we'd like to
[01:49:13.000 --> 01:49:21.640]   work with you to commercialize it as software atia moved to Palo Alto to focus on it code
[01:49:21.640 --> 01:49:28.200]   named project genie it was part of google x effect was one of the very first google x moon shots
[01:49:28.200 --> 01:49:36.440]   but then according to the lawsuit google Larry Page's Sergey Bin Brin plotted to squeeze out of
[01:49:36.440 --> 01:49:44.840]   the project pretended to kill it but then spun off project genie into a new company which atia had
[01:49:44.840 --> 01:49:54.120]   no stake in atia is accusing google of racketeering saying it's not the first time it's not the only
[01:49:54.120 --> 01:49:59.080]   time they do this all the time it's cheaper to steal to develop your own technology this is what
[01:49:59.080 --> 01:50:04.600]   microsoft was accused of remembering the 90s they would do an nda with a company they would learn
[01:50:04.600 --> 01:50:08.600]   all about it saying we were just inquiring you and then they would say yeah no we decided not to
[01:50:08.600 --> 01:50:16.120]   and build exactly the same thing um a judge in san kler county superior court approved the
[01:50:16.120 --> 01:50:20.280]   addition of the racketeering claims of the lawsuit the suit was filed a few years ago but
[01:50:20.280 --> 01:50:29.160]   now this new racketeering charge has been added apparently uh according to some google likes to
[01:50:29.160 --> 01:50:35.160]   do this sort of thing they renamed project genie the flux factory now it's called flux it's
[01:50:35.160 --> 01:50:39.800]   headquartered in san francisco it sells building design software and markets itself as the first
[01:50:39.800 --> 01:50:46.280]   company launched by google x google says hey we paid him for his technology we own it now that's that
[01:50:46.280 --> 01:50:55.000]   we'll watch that uh that case with interest that while we don't know much about what was
[01:50:55.000 --> 01:51:00.040]   right or wrong in that case there is definitely a culture of bigger companies doing nda's
[01:51:00.040 --> 01:51:04.200]   finding out as much as they can and building their own stuff internally more than maybe even a few
[01:51:04.200 --> 01:51:08.440]   years ago it's always the fear of of an inventor that this will happen that they'll bring into a
[01:51:08.440 --> 01:51:12.600]   big company and they'll say oh that's very interesting but no we're not really interested and then build
[01:51:12.600 --> 01:51:19.160]   it so we'll don't know the merits of the case but interesting um
[01:51:23.400 --> 01:51:26.520]   i'm now looking at an old rundown i think because it says
[01:51:26.520 --> 01:51:30.040]   this is an old story let me see if i can find yeah here we go
[01:51:30.040 --> 01:51:37.240]   um actually let's take a break and then i'm going to ask you all why it is the tech community is so
[01:51:37.240 --> 01:51:46.680]   anxious to defend you jean kasperski okay okay when we can react before we get on with the show
[01:51:46.680 --> 01:51:51.080]   i i i realized that there were a lot of things that happened this week on twitter you might have
[01:51:51.080 --> 01:51:57.240]   missed but we decided we can make up for that by editing a little kind of highlight rea watch
[01:51:57.240 --> 01:52:01.000]   previously on twitch and if you really were using
[01:52:01.000 --> 01:52:06.520]   music as something horrible has happened to mary chow me
[01:52:06.520 --> 01:52:14.920]   the menace look at her i was just watching them i'm like no no no tech news weekly you wrote
[01:52:14.920 --> 01:52:20.200]   earlier that snapchat looks on their platform and didn't have any problems uh so are we to believe
[01:52:20.200 --> 01:52:25.000]   that we're living in a world where like the only news we can trust is from snapchat the
[01:52:25.000 --> 01:52:29.560]   russian intelligence agencies can't take out a tab on such a discover without you know setting
[01:52:29.560 --> 01:52:35.960]   up a deal with snapchat so that by itself makes it very difficult for uh for for anyone to to
[01:52:35.960 --> 01:52:42.120]   really game the system i owe us today we wanted to talk a little bit about terms of service so we have
[01:52:42.120 --> 01:52:47.880]   my favorite lawyer the princess of terms of service Denise howl what should people do when they're
[01:52:47.880 --> 01:52:52.760]   confronted with a 56 page legal document that they're asked to agree to before they can use
[01:52:52.760 --> 01:52:58.520]   their new iphone you can make this assumption that everything in there is in there uh because it
[01:52:58.520 --> 01:53:06.360]   benefits the company um and covers the company's rear end in some way i did assume that to it yeah
[01:53:06.360 --> 01:53:13.240]   we read the tech news so you don't have to i'm still testing whether uh it's shaking the phone
[01:53:13.240 --> 01:53:18.360]   makes a web page load faster it's how you shake it you got to do it like a polaroid
[01:53:18.360 --> 01:53:23.880]   like a polaroid we're doing it all wrong i've been i've been shaking it like a hammer rocket
[01:53:23.880 --> 01:53:30.120]   mortgages are sponsored today a big big company quick and loans the number two lender in the country
[01:53:30.120 --> 01:53:34.680]   billions of dollars and loans has created something just for geeks when that happens i have to celebrate
[01:53:34.680 --> 01:53:41.080]   it yay they're thinking us they have created an entirely online home loan process so you don't
[01:53:41.080 --> 01:53:45.880]   have to go to the bank you don't have to go to the attic to find all the pay stubs and all the
[01:53:45.880 --> 01:53:52.360]   paperwork you can do it all on your phone on your laptop you could do it on your phone at an open
[01:53:52.360 --> 01:53:57.560]   house and get loan approval in minutes from the best lender in the country quick and loans it's
[01:53:57.560 --> 01:54:03.320]   called rocket mortgage it gives you the confidence you need when it comes to buying a home or refinancing
[01:54:03.320 --> 01:54:09.080]   your existing home loan you'll understand all the details it's all very transparent because they
[01:54:09.080 --> 01:54:12.760]   have trusted financial partners you can share your information with rocket mortgage easily
[01:54:12.760 --> 01:54:17.880]   with a touch of a button and once they get that information they can crunch those numbers fast
[01:54:17.880 --> 01:54:25.000]   because computers last home loan i got about four years ago the guy actually had a calculator
[01:54:25.000 --> 01:54:30.840]   and he has a sheet of papers that he was calculating what the amortization table on his super duper
[01:54:30.840 --> 01:54:37.000]   calculator i thought this is not exactly 21st century technology here rocket mortgage is whether
[01:54:37.000 --> 01:54:42.840]   you're buying your first home of your tenth they can calculate in minutes and give you a loan
[01:54:42.840 --> 01:54:48.120]   based on income assets and credit that's right for you for a loan for which you qualify you choose
[01:54:48.120 --> 01:54:54.360]   the term you choose the right and you're done you could do it at an open house and buy it right then
[01:54:54.360 --> 01:54:59.080]   in their rocket mortgage by quick and loans apply simply understand fully mortgage confidently
[01:54:59.080 --> 01:55:04.920]   equal housing lender licensed in all 50 states at mls consumer access dot org number 30 30 now i
[01:55:04.920 --> 01:55:09.000]   know you may not be buying a house right this minute i hope not i hope you're just listening to us
[01:55:09.000 --> 01:55:17.720]   but bookmark this site if you do down the road want to buy a refi rocket mortgage dot com slash
[01:55:17.720 --> 01:55:27.240]   twit to rocket mortgage dot com slash twit to it's really a great idea and we thank quick and loans
[01:55:27.240 --> 01:55:36.440]   a rocket mortgage for their support of this week in tech so Eugene kaspersky is a very well-liked
[01:55:36.440 --> 01:55:42.760]   guy in the tech industry i know so many people say oh he's great i love Eugene kaspersky makes
[01:55:42.760 --> 01:55:47.080]   antivirus software i remember devorek it was his favorite software he loved it
[01:55:47.080 --> 01:55:56.920]   um and then recently i was at the department of defense said don't use kaspersky
[01:55:56.920 --> 01:56:04.360]   antivirus because kaspersky is known to have written software for the russian f s b the secret police
[01:56:04.360 --> 01:56:11.160]   the wall street journal this week published an article saying hackers working for the government
[01:56:11.160 --> 01:56:17.800]   for the russian government stole confidential material see an nsa contractor this keeps happening
[01:56:17.800 --> 01:56:23.400]   to the nsa it's just like edward ston and nsa contactor decided for you know i think i'm gonna
[01:56:23.400 --> 01:56:29.160]   bring all of this stuff home and put it on my personal computer my personal computer that's loaded
[01:56:29.160 --> 01:56:39.880]   with kaspersky antivirus according to the journal the government believes nsa believes that the kaspersky
[01:56:39.880 --> 01:56:48.040]   ava av scanning his computer found those documents maybe they were viruses created by the nsa
[01:56:48.040 --> 01:56:53.880]   notified kaspersky kaspersky notified hackers in the russian government who then exfiltrated
[01:56:53.880 --> 01:56:58.120]   the the stuff maybe with the help of the kaspersky software it's unknown
[01:56:58.120 --> 01:57:04.280]   and stole those penetrated the nsa contractors computer install the files
[01:57:04.280 --> 01:57:10.360]   now it may be that kaspersky had nothing to do with it
[01:57:10.360 --> 01:57:16.680]   right best buy in september stop selling their software and offered free removals
[01:57:17.560 --> 01:57:22.840]   and credits toward competing packages u_s_ department of homeland security directed all
[01:57:22.840 --> 01:57:27.480]   u_s_a_ agencies to stop using kaspersky products and services last month
[01:57:27.480 --> 01:57:37.160]   do you guys use kaspersky antivirus and yet i see dan good in ours tech again others defending
[01:57:37.160 --> 01:57:43.240]   kaspersky saying well we don't not so fast dan writes we don't know what really happened
[01:57:46.120 --> 01:57:50.520]   i'm defending the person or they defending i think well they're defending kaspersky
[01:57:50.520 --> 01:57:55.240]   the company but i think that i have to trace this back to the fact that Eugene kaspersky the
[01:57:55.240 --> 01:58:02.280]   founder it was is a very genial jovial guy who used to go to trade shows ces and comics
[01:58:02.280 --> 01:58:08.120]   bought drinks for people everybody loves Eugene kaspersky and i think they don't want to believe
[01:58:08.120 --> 01:58:14.680]   that this but if you were a spy wouldn't you buy drinks for everybody and be lovable and fun
[01:58:14.680 --> 01:58:22.600]   right anyway i guess none of you are friends of Eugene kaspersky and wanted to defend him
[01:58:22.600 --> 01:58:28.760]   kaspersky officials say kaspersky lab has not been provided any evidence substantiating
[01:58:28.760 --> 01:58:33.320]   the company's involvement in the alleged incident reported by the journal it's unfortunate the
[01:58:33.320 --> 01:58:38.200]   news coverage of unproven claims continue to perpetuate accusations about the company
[01:58:38.200 --> 01:58:43.400]   as a private company kaspersky lab which is in russia does not have inappropriate ties to any
[01:58:43.400 --> 01:58:47.960]   government including russia and the only conclusion seems to be kaspersky lab is caught in the middle
[01:58:47.960 --> 01:58:55.880]   of a geopolitical fight which is the second part for sure is true it almost doesn't matter at this
[01:58:55.880 --> 01:59:01.000]   point if the accusations are true or not the fact that you're talking about a russian basic
[01:59:01.000 --> 01:59:08.440]   security company just makes it difficult if not impossible for it to for in this environment
[01:59:09.000 --> 01:59:15.160]   be on us computers especially computers used by i'm not going to use it i mean i never well mean
[01:59:15.160 --> 01:59:19.800]   mac never used to buy to use antiviruses anyway because antiviruses inevitably open holes on your
[01:59:19.800 --> 01:59:23.800]   system yeah more than they protect you they're less important than they used to be yeah that's
[01:59:23.800 --> 01:59:29.560]   that's the point and but for like for kaspersky the company it's just it's a death now there's just
[01:59:29.560 --> 01:59:36.200]   like the wrong location wrong time and error yeah security company plus russia so who would you
[01:59:36.200 --> 01:59:43.800]   trust more eugene kaspersky or john mackefy i mean eugene kaspersky but but that's just because
[01:59:43.800 --> 01:59:51.080]   mackefy that's a but who would you like to fight maybe maybe he'll be the libertarian party leader
[01:59:51.080 --> 01:59:55.480]   for the next election that's right he wanted to run for president yeah actually good and does
[01:59:55.480 --> 02:00:01.160]   point out that the real story here is this is now the third time that private contractors have
[02:00:01.160 --> 02:00:07.720]   exfiltrated stuff from the nsa and and either leaked it or lost it so maybe nsa you want to
[02:00:07.720 --> 02:00:16.120]   start thinking about your uh security and i don't know maybe yeah maybe uh uh aqua fact says oh it
[02:00:16.120 --> 02:00:22.120]   wasn't 143 million it was 145 and a half million uh and it's everybody which i mean everybody ever
[02:00:22.120 --> 02:00:27.720]   and the ceo of aqua facts in his testimony before congress says you know what it's it boils down to
[02:00:27.720 --> 02:00:36.360]   one guy not doing his job yeah not him not me oh no not him he's he's he retired and and took his
[02:00:36.360 --> 02:00:42.680]   nice 90 million dollar um uh you know retirement uh package it just makes my blood boil and you really
[02:00:42.680 --> 02:00:50.440]   want your blood to boil because this this grat this is just unbelievable the irs has awarded
[02:00:50.440 --> 02:00:59.560]   Equifax a no bid seven and a quarter that's million dollar contract to help them keep track of uh
[02:00:59.560 --> 02:01:06.840]   the information that was leaked from Equifax or what didn't anyone at the iris i guess they
[02:01:06.840 --> 02:01:13.720]   stopped the iris's concern is that people will use the Equifax information to falsely apply for
[02:01:13.720 --> 02:01:17.720]   refunds so who better to ask than the company that leaked the information
[02:01:19.080 --> 02:01:27.000]   to help them figure that out more fe's plumbing oh so much yeah yeah that's all you can do oh
[02:01:27.000 --> 02:01:35.400]   m gee you know i must talking to the governor of Puerto Rico or as our president would say
[02:01:35.400 --> 02:01:46.840]   Puerto Rico oh god oh three times three times so horrible Puerto Rico uh he uh to rebuild the grid
[02:01:46.840 --> 02:01:50.200]   now this is actually an opportunity for Puerto Rico they're gonna have to rebuild their grid it was
[02:01:50.200 --> 02:01:55.080]   completely knocked out by hurricane Irma Musk says guess what we could do it with solar and power
[02:01:55.080 --> 02:02:01.240]   walls big batteries and solar what do you think let's do it it's a on must part it's brilliant to
[02:02:01.240 --> 02:02:06.840]   do that because it's good people can't lose it can't lose it works then every state in every country
[02:02:06.840 --> 02:02:11.000]   will want it isn't that always the opportunity though if you if you have no infrastructure you can
[02:02:11.000 --> 02:02:19.800]   leapfrog and do something really smart yeah it's that mean it's not a bad deal at all for Puerto Rico
[02:02:19.800 --> 02:02:29.720]   where to where so uber gets kicked out of London because they won't submit the fingerprints
[02:02:29.720 --> 02:02:35.960]   uh uber and lift kicked out of Austin because they said no no you can't fingerprint our contractors
[02:02:35.960 --> 02:02:40.920]   like state of California said no you know what they're right the public utilities commission
[02:02:41.880 --> 02:02:48.280]   says although we recognize the public's familiarity with fingerprinting we do not see that a demonstrably
[02:02:48.280 --> 02:02:55.080]   greater level of safety would be added over and above the current background check protocols the puc
[02:02:55.080 --> 02:03:01.240]   says you don't have to do fingerprints that was a bad idea see the public understands fingerprints
[02:03:01.240 --> 02:03:06.840]   and thinks that will help but it turns out there's a lot of false positives it isn't necessarily
[02:03:07.480 --> 02:03:13.240]   you know proving that the person is connected to whatever crime that fingerprints connected to
[02:03:13.240 --> 02:03:18.440]   fingerprint answers aren't the fingerprint checks aren't the answers says that puc
[02:03:18.440 --> 02:03:23.640]   I thought this was fascinating it turns out it's the taxi commissions taxi drivers are
[02:03:23.640 --> 02:03:28.520]   generally required to give fingerprints in London and Austin and other places it was the taxi
[02:03:28.520 --> 02:03:34.920]   commissions that said why should we have to do it and not uber and lift which is a fair thing to
[02:03:34.920 --> 02:03:39.720]   ask I mean in in New York City for instance all uber drivers have to be approved by the the
[02:03:39.720 --> 02:03:44.760]   taxi limits in commission but but uber pays and lift they basically pay the fees but you have to
[02:03:44.760 --> 02:03:50.680]   be registered with the tlc and and that's important because the tlc is not that is not the is not
[02:03:50.680 --> 02:03:55.880]   doesn't represent taxi drivers right no no no it just means that in order to have a car that can
[02:03:55.880 --> 02:04:00.440]   pick passengers you have to be registered with them and and and that's different from almost any
[02:04:00.440 --> 02:04:04.520]   other city that uber operates and and and lift to for that matter and they made that concession
[02:04:04.520 --> 02:04:09.640]   because New York was such an important market and and you know they they fought in Austin and
[02:04:09.640 --> 02:04:13.720]   ended up being reinstated and who knows what'll happen with London London might be an important
[02:04:13.720 --> 02:04:18.280]   enough market that the uber will change its its policies but but I mean but it's a valid question
[02:04:18.280 --> 02:04:24.040]   for the for the taxi you know operators to say why do our drivers have to follow these rules
[02:04:24.040 --> 02:04:30.600]   when the others don't especially since the services for the most part are so are so similar it does
[02:04:30.600 --> 02:04:33.960]   feel like there's more to this story than I had thought I just thought well why wouldn't they
[02:04:33.960 --> 02:04:39.000]   have fingerprints but why wouldn't uber lift to say okay well why wouldn't they why wouldn't they
[02:04:39.000 --> 02:04:44.760]   do that well apparently it's expensive it's expensive it's time consuming and it's it has a lot of a
[02:04:44.760 --> 02:04:49.960]   high rate of false positives yeah well that's the thing and it has a long and and for them you know
[02:04:49.960 --> 02:04:55.720]   you have to think of okay the big case in New York again it's kind of an outlier market because
[02:04:55.720 --> 02:04:59.480]   again most of the people who drive in New York are professionals or or at least trying to make
[02:04:59.480 --> 02:05:05.000]   their living kind of driving and and you know some other cities are like that too but New York is
[02:05:05.000 --> 02:05:09.960]   one of the big ones if I think that the big value proposition for uber and lift has always been
[02:05:09.960 --> 02:05:13.880]   even though this is false there there's like a great game that that I think fast company or
[02:05:13.880 --> 02:05:17.960]   someone made that actually shows how hard it is to like earn you know money driving for these
[02:05:17.960 --> 02:05:22.280]   services has been that anybody could kind of do it in their spare time and the more friction
[02:05:22.280 --> 02:05:25.640]   you bring into the process okay now I have to be fingerprinted now I have to go through this
[02:05:25.640 --> 02:05:29.160]   background check you do that the fewer people are going to be willing to be part of your
[02:05:29.160 --> 02:05:34.440]   ecosystem now okay all things said you know uber and lift obviously uber more than more than lift
[02:05:34.440 --> 02:05:39.480]   want to be in a place where self-driving taxis will pick everyone up anyway right but until we get
[02:05:39.480 --> 02:05:47.320]   to that point you do need to have um you know people willing to do it and and that it takes the
[02:05:47.320 --> 02:05:52.360]   more red tape you put in into it the harder it is to to have people willing to be your drivers so
[02:05:53.160 --> 02:06:01.640]   all right two things started 20 years ago this week one's surviving one's not yeah AOL instant
[02:06:01.640 --> 02:06:07.880]   messenger closing its doors finally rip that now you're young enough Christina I bet you you
[02:06:07.880 --> 02:06:13.400]   used aim a lot when you were a teenager yeah yeah oh well I mean I'm mica might be too young to
[02:06:13.400 --> 02:06:17.800]   use it but I know me and bingy for sure like you and I were going back forth on it what was your
[02:06:17.800 --> 02:06:23.720]   username film girl was it from ground that no no I was that was tb freak 998
[02:06:23.720 --> 02:06:31.080]   mine was yg rpg it stood for I was a video game nerd it stood for Yoshi Gino rpg from a
[02:06:31.080 --> 02:06:37.560]   video game oh my god I love it my daughter is 25 now grew up on aim that was you know instead of
[02:06:37.560 --> 02:06:43.640]   calling as high schoolers did when I was a kid we actually had phones back then uh they just used
[02:06:43.640 --> 02:06:49.800]   aim to talk but my son is 22 actually missed that he they didn't use aim by the time he was a teenager
[02:06:49.800 --> 02:06:54.600]   they were using Skype and video chat and video conferencing his Google Hangouts and stuff so it
[02:06:54.600 --> 02:07:00.840]   really was this kind of slice of time her uh her just just for completeness sake her aim uh
[02:07:00.840 --> 02:07:06.760]   handle was got a base not a life which I thought was good except that she didn't play the base but
[02:07:06.760 --> 02:07:11.320]   anyway it was a key it was clever I liked it I can't remember mine I'm sad about that I didn't use it
[02:07:11.320 --> 02:07:17.560]   as much as some of my other friends did um all the time you were on the tail end of it probably
[02:07:17.560 --> 02:07:24.360]   yeah I turned 25 this year so I was on that on the tail end but um we we wrote a eulogy over at
[02:07:24.360 --> 02:07:30.760]   i'm war um about it because yeah it's still sad to see it go and there were good times for sure so
[02:07:30.760 --> 02:07:39.400]   an ode to AOL instant messenger for Tory folk from mobile nations and ode is there actually a singing
[02:07:39.400 --> 02:07:44.040]   anything I could see there should be there should be a singing process
[02:07:44.040 --> 02:07:47.400]   always said our way messages is song lyrics like that was always the thing is that you could
[02:07:47.400 --> 02:07:51.800]   tell how emo someone was being based on what you know song lyrics they were choosing funny
[02:07:51.800 --> 02:07:59.160]   well I like this though thanks and this is kind of how it was on aim thanks yeah for no vowels for
[02:07:59.160 --> 02:08:05.640]   the muries and then a bunch of uh emoj you don't really have emojis hearts and yeah you can get
[02:08:05.640 --> 02:08:12.440]   a code yeah yeah in 1997-2007 you know what else was started in 1997 that my generation loves
[02:08:12.440 --> 02:08:20.360]   slash dot command slash dot rob maldec connect commander taco wrote a fee doesn't have anything to
[02:08:20.360 --> 02:08:24.840]   do with slash dot it's been sold and other companies write it but he wrote a really nice
[02:08:24.840 --> 02:08:34.040]   it's kind of history of slash dot on the medium on the free code camp medium feed uh it was originally
[02:08:34.040 --> 02:08:42.840]   a section on his home page called chips and dips and eventually he decided it was running static
[02:08:42.840 --> 02:08:50.760]   html so eventually he decided to create something a little bit more sophisticated called slash dot
[02:08:50.760 --> 02:08:57.880]   dot org it was running on a deck alpha of all things which he got for free for skinning a space
[02:08:57.880 --> 02:09:05.640]   invaders clone it was about a 486 speed but it ran Linux and he was pretty happy about that
[02:09:05.640 --> 02:09:09.000]   uh slash dot was almost immediately slash dotted
[02:09:09.000 --> 02:09:16.520]   which is kind of ironic but uh slash dot was pretty amazing for many years that was the source
[02:09:16.520 --> 02:09:22.840]   of uh tech news and it's now yeah 20 years old but it's still alive still don't it is still
[02:09:22.840 --> 02:09:25.960]   I've know it's so interesting because you know before there was hacker news before there was
[02:09:25.960 --> 02:09:30.520]   reddit before there was dig you know like it like slash dot was the place you know I mean even
[02:09:30.520 --> 02:09:34.040]   twitter to a certain extent like that's where you would kind of go to to figure out what was
[02:09:34.040 --> 02:09:37.800]   at least like in the in kind of the nerd sphere the tech sphere I think you can see it.
[02:09:37.800 --> 02:09:42.440]   And I know it's like a writer um I remember like when I first started writing professionally like if
[02:09:42.440 --> 02:09:47.080]   if the link got you know and slash dot that was a big deal and it then it became like you know dig
[02:09:47.080 --> 02:09:54.280]   and hacker news and and reddit and whatnot but yeah so funny I think in fact I remember uh Kevin
[02:09:54.280 --> 02:10:01.640]   telling me I think that slash dot uh inspired dig because he we use slash dot on uh on tech
[02:10:01.640 --> 02:10:08.840]   TV all the time so that gave him the idea to do dig and then uh dig was very clearly I think
[02:10:08.840 --> 02:10:14.840]   Alexis O'Hanean told me this the inspiration for reddit so it all really started uh way back here
[02:10:14.840 --> 02:10:22.920]   and it's run uh is it run who runs is it the um not sure who owns it these days says you
[02:10:22.920 --> 02:10:26.680]   have been sold it's been sold a couple times the source forage still it's source forage yeah
[02:10:26.680 --> 02:10:31.480]   to sort source forage odons it or yeah I'm looking on the wicked pd which you know
[02:10:31.480 --> 02:10:36.520]   someone bought it like dice bought it and sold it it says biz x owns it I don't even know what
[02:10:36.520 --> 02:10:40.440]   that is I'm well the irony of these sites is it doesn't really matter who owns it as long as
[02:10:40.440 --> 02:10:45.880]   they keep the code base working because it's really a creation of the people use it so slash
[02:10:45.880 --> 02:10:51.080]   dot today is not at all different from slash dot 20 years ago pretty much you all the you see
[02:10:51.080 --> 02:10:54.520]   kind of the same thing happened to dig too you know as you see like that some of the users and
[02:10:54.520 --> 02:10:59.480]   the editors like migrate from one place to another you know and and so the community around it like
[02:10:59.480 --> 02:11:06.200]   be you know becomes important to keeping those things relevant I mean ronalda was was was he was
[02:11:06.200 --> 02:11:11.960]   I think he left like 2011 I want to say is probably when he left um slash dot um but but he was there
[02:11:11.960 --> 02:11:17.880]   for a really really long time um and and kind of went through you know a bunch of the changes and
[02:11:17.880 --> 02:11:24.360]   and um yeah it's uh even though it's not the same place it was and and only certain people I think
[02:11:24.360 --> 02:11:28.520]   you know kind of like still hang on and kind of go to slash dot every day like I certainly don't
[02:11:28.520 --> 02:11:33.400]   visit it um ever unless you know like something like this happens and I see it you know weirdly I
[02:11:33.400 --> 02:11:38.840]   saw it on hacker news right I saw I saw the slash dot a link and and but I was like oh man yeah that
[02:11:38.840 --> 02:11:43.880]   was so that was such of its time and such an important part I think of like news culture and
[02:11:43.880 --> 02:11:48.040]   internet culture and it's it's awesome that that it still exists after 20 years and that
[02:11:48.040 --> 02:11:53.640]   the people like rober are still able to kind of share the oral history so to speak of of how it
[02:11:53.640 --> 02:12:03.560]   came to be and finally this was a bad week to be 66 years old first tom headie uh passed away and
[02:12:03.560 --> 02:12:13.320]   then a couple of days ago the the former CEO of Intel uh Paul O'Dolini passed away at the age of
[02:12:13.320 --> 02:12:21.400]   66 he oversaw a very big growth area era for Intel but also was there when Intel kind of missed the
[02:12:21.400 --> 02:12:29.880]   boat on mobile yeah so uh while while I think you could say his reign from 2005 to 2013 was
[02:12:29.880 --> 02:12:36.440]   pretty successful maybe he didn't set the the best tone for the future of Intel Intel's revenues went
[02:12:36.440 --> 02:12:42.760]   uh to 53 billion dollars at the end of his tenure from 34 billion dollars before he started
[02:12:42.760 --> 02:12:51.400]   ladies and gentlemen that concludes this edition of this week in tech I want to thank you guys
[02:12:51.400 --> 02:12:56.760]   you're fun everybody must come back I started this saying it was going to be a weird one and you
[02:12:56.760 --> 02:13:03.400]   guys did not disappoint thanks to thanks to mica sergeant he's the uh senior editor of mobile
[02:13:03.400 --> 02:13:12.040]   nations mikah sar gnt on twitter and uh of course you can hear his multiple podcasts including
[02:13:12.040 --> 02:13:17.800]   the cartoon podcast he the cartoon cast that he's resurrected with his partner Christina Warren
[02:13:17.800 --> 02:13:22.520]   film girl who's also with us today now at Microsoft but you know what that isn't
[02:13:22.520 --> 02:13:27.960]   slowed it down one senior cloud dev advocate you can catch her work soon on channel nine
[02:13:27.960 --> 02:13:37.400]   yay yay and Ben par he's a long time a mashable guy along with Christina they would get the
[02:13:37.400 --> 02:13:43.960]   mashable alum team on here also the author of a book called cap divulgies now co-founder at a
[02:13:43.960 --> 02:13:50.200]   company called octane.ai and an investor and it's great to see you what is cap divulgies about
[02:13:50.200 --> 02:13:55.880]   it's about the science and psychology of attention and why do we pay attention to all these things
[02:13:55.880 --> 02:14:00.200]   you should have spent more time asking you about that because that's what we were talking about
[02:14:00.200 --> 02:14:06.840]   wasn't it the this is for my research yeah you even talk about politicians and how they how
[02:14:06.840 --> 02:14:12.680]   they sell their agenda using these techniques framing yeah framing well everybody should read
[02:14:12.680 --> 02:14:17.480]   it the science of capturing people's attention captive ology it's in paperback now too but I
[02:14:17.480 --> 02:14:22.840]   happen to have an early hardback edition thank you all for being here we do this week in tech
[02:14:22.840 --> 02:14:29.720]   every sunday afternoon 3 p.m. pacific 6 p.m. eastern time 2200 utc please stop by and say hi you can
[02:14:29.720 --> 02:14:36.120]   watch live at twit.tv/live if you do join us in the chatroom at irc.twit.tv and we also have an
[02:14:36.120 --> 02:14:40.920]   open studio policy so if you'd like to be in the studio audience you're more than welcome we do
[02:14:40.920 --> 02:14:46.760]   ask if you want to be visit the studio that you email tickets at twit.tv our studio schedule is
[02:14:46.760 --> 02:14:51.400]   changing a little bit and I don't want you to come here and not be able to get in so there are days
[02:14:51.400 --> 02:14:56.680]   I think monday is one of them we won't be open at all anymore so please do just email tickets at
[02:14:56.680 --> 02:15:00.840]   twit.tv we'll send you directions we'll make sure that we're open at that time and we'll put a
[02:15:00.840 --> 02:15:04.760]   chair out for you we'd love to have you though it's always great to have a live studio audience
[02:15:04.760 --> 02:15:08.760]   while we do the show if you can't be here in person if you can't be here watching the stream or in
[02:15:08.760 --> 02:15:13.560]   the chatroom you can always get on demand versions of all of our shows yes you can ask your favorite
[02:15:14.280 --> 02:15:19.960]   speech assistant and in most cases it'll work if you have an echo just say echo listen to this
[02:15:19.960 --> 02:15:26.280]   weekend tech on tune in tune in is the provider on the echo you can also listen to our live stream
[02:15:26.280 --> 02:15:30.600]   echo listen to twit live on tune in and you'll be able to hear whatever is going on in the studio
[02:15:30.600 --> 02:15:37.480]   at any given moment you can also go to our website twit.tv download episodes or subscribe
[02:15:37.480 --> 02:15:42.840]   using your favorite podcast or pick catcher number one is still iTunes number two now is pocket
[02:15:42.840 --> 02:15:48.680]   casts which is interesting and then there's a overcast and stitcher and slacker and a lot of
[02:15:48.680 --> 02:15:53.240]   other platforms but we do like it if you subscribe that way you don't miss an episode thanks for being
[02:15:53.240 --> 02:15:58.760]   here we'll see you next time another twit is amazing
[02:15:58.760 --> 02:16:07.080]   do the twit all right do the twit baby do the twit all right do the

