;FFMETADATA1
title=The Ivermectin of Smartphones
artist=Leo Laporte, Steven Levy, Jeff Jarvis, Dan Gillmor
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2021-09-27
track=842
language=English
genre=Podcast
comment=Crackdown in China, Surface Duo 2, end of magazines, Peter Thiel		
encoded_by=Uniblab 5.3
date=2021
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.720]   It's time for Twit This Week in Tech. We have a great panel for you.
[00:00:02.720 --> 00:00:10.160]   Steven Levy, senior editor at large at Wired joins us. I love Steven Dan Gilmore. Love him too from
[00:00:10.160 --> 00:00:14.960]   Arizona State University's Walter Cronkite School of Journalism. And of course,
[00:00:14.960 --> 00:00:19.040]   coming on over from this week in Google, another professor of journalism.
[00:00:19.040 --> 00:00:23.360]   Jeff Jarvis, we'll talk about the end of magazines as we know it.
[00:00:23.360 --> 00:00:28.720]   William Shatner, Captain Kirk going into space. Actually, Steven was at the last
[00:00:28.720 --> 00:00:35.280]   Jeff Bezos launch. We'll be asking him about that. And Peter Teal is evil or just misunderstood.
[00:00:35.280 --> 00:00:37.520]   It's all coming up next on Twit.
[00:00:37.520 --> 00:00:45.920]   Podcasts you love from people you trust. This is Twit.
[00:00:53.920 --> 00:01:01.600]   This is Twit This Week in Tech, Episode 842, recorded Sunday, September 26th, 2021.
[00:01:01.600 --> 00:01:06.800]   The Ivermectin of smartphones. This Week in Tech is brought to you by
[00:01:06.800 --> 00:01:12.800]   Worldwide Technology and Cisco. With a return to the office in sight, are you prepared to safely
[00:01:12.800 --> 00:01:18.000]   welcome back employees and patrons? Do you have the right tools in place to support hybrid work?
[00:01:18.560 --> 00:01:24.640]   WWT combines strategy and execution to bring clarity to reopening plans and implement
[00:01:24.640 --> 00:01:30.800]   solutions that enable flexible working. Visit www.wt.com/twit to get started.
[00:01:30.800 --> 00:01:38.240]   And by podium. Today's customers expect on-demand everything, even from local businesses. Stay
[00:01:38.240 --> 00:01:42.560]   ahead of the competition. With podium, they have free plans for growing businesses plus all the
[00:01:42.560 --> 00:01:49.200]   power growing businesses need to scale. Get started free today at podium.com/twit.
[00:01:49.200 --> 00:01:57.760]   And by Modern Finance. Our NFT is here for the long haul, which cryptocurrency is a fad. How
[00:01:57.760 --> 00:02:04.160]   does decentralized finance work? Modern Finance podcast hosted by Kevin Rose looks to answer
[00:02:04.160 --> 00:02:09.520]   these questions and many more about the investment marketplace. Download and subscribe to Modern
[00:02:09.520 --> 00:02:14.800]   Finance wherever you listen to podcasts and get ahead of the future of finance.
[00:02:14.800 --> 00:02:24.080]   And by Stamps.com. Save time and money with Stamps.com. There's no risk. And with my promo code TWIT,
[00:02:24.080 --> 00:02:29.440]   you'll get a special offer that includes a four-week trial plus free postage and a digital scale.
[00:02:29.440 --> 00:02:34.320]   No long-term commitments or award contracts. Just go to Stamps.com. Click the microphone at the
[00:02:34.320 --> 00:02:46.960]   top of the homepage and type in TWIT. It's time for TWIT this week in tech. The show where you
[00:02:46.960 --> 00:02:51.760]   cover the week's tech news with a distinguished panel. This week it's such a distinguished panel.
[00:02:51.760 --> 00:02:56.480]   I'm just going to sit back and shut up and let them all talk. You already know Jeff Jarvis,
[00:02:56.480 --> 00:03:00.560]   the Leonard Tau Professor for journalistic innovation at the Craig Newmark.
[00:03:00.560 --> 00:03:05.360]   Craig, Craig, Craig, the Mark School of Journalism at the City University of New York. Without
[00:03:05.360 --> 00:03:10.960]   Ant Pruitt to do the low-based design. We need a free part harmony. So we brought Jeff in because
[00:03:10.960 --> 00:03:16.400]   you're going to run this show. I'm going to sit back because we have, this is all journalists
[00:03:16.400 --> 00:03:22.160]   today. And like the real deal, Dan Gilmore is here, co-founder of the Arizona State University
[00:03:22.160 --> 00:03:28.720]   news co-lab at the Walter Cronkite Journalism School, long-time observer of journalism,
[00:03:28.720 --> 00:03:32.240]   and of course an active journalist. It's good to see you, Dan.
[00:03:32.240 --> 00:03:38.640]   Nice to be back. And the man who specializes in slow journalism, at least that's the last time
[00:03:38.640 --> 00:03:44.080]   I talked to you, that's what you called it, editor at large at Wired, Steven Levy.
[00:03:44.080 --> 00:03:46.400]   It's great to have you, Steven. I appreciate it.
[00:03:46.400 --> 00:03:50.480]   When did each of you start covering tech? How long did you just go back?
[00:03:50.480 --> 00:03:59.120]   God, Steven wrote the semi-tech book Hackers about the MIT Hackers. I think it's 30 years now,
[00:03:59.120 --> 00:04:02.640]   isn't it? More. That book was out in 1985.
[00:04:02.640 --> 00:04:04.320]   Holy cackling. Wow.
[00:04:04.320 --> 00:04:13.520]   And I got introduced to Hackers. In the assignment, I got 1981, which resulted in a 1982 story for
[00:04:13.520 --> 00:04:20.800]   Rolling Stone about called Hackers and Paradise. So very early 80s is when I started.
[00:04:20.800 --> 00:04:23.920]   Wow. Uncle Steve. That's pretty much when computers started.
[00:04:23.920 --> 00:04:33.120]   At that time, most quote computer journalists were hobbyists. In the end of the story,
[00:04:33.120 --> 00:04:40.080]   they would put a little thing with their address and phone number in case you wanted to connect
[00:04:40.080 --> 00:04:44.800]   with them and call them up and ask them to type in a few lines of code or something.
[00:04:44.800 --> 00:04:50.400]   That was me, actually. I was writing in Bite Magazine in the early 80s as a hobbyist.
[00:04:50.400 --> 00:04:55.440]   And the reason I was doing it is because I was trying to get free software. So I'd
[00:04:55.440 --> 00:04:59.840]   review software and hardware. In fact, I wrote...
[00:04:59.840 --> 00:05:03.760]   So when was your first tech piece? Me? Yeah.
[00:05:04.720 --> 00:05:11.200]   Probably around 80. It was pre-IBMPC. So it would have been 80, 79 or 80.
[00:05:11.200 --> 00:05:13.440]   Right around that 10. When did you start?
[00:05:13.440 --> 00:05:22.240]   I started using it in the 70s, but as far as writing about it, probably not till the mid 80s.
[00:05:22.240 --> 00:05:28.240]   You were a sports writer for a while, right? Never. Never. Why do I think that?
[00:05:29.520 --> 00:05:36.320]   I don't know why. I started as a rock critic. Now you're talking. Actually,
[00:05:36.320 --> 00:05:41.920]   I always use an analogy talking about tech because in the early days of tech,
[00:05:41.920 --> 00:05:46.400]   when it was hobbyist, it was a lot about speeds and feeds and what your processor was and how
[00:05:46.400 --> 00:05:53.680]   much RAM you had. And I always liken that to the early days of stereo magazines like High-Fi.
[00:05:53.680 --> 00:05:58.800]   That wasn't even about the music. It was like you listened to the 1812 Overture because there
[00:05:58.800 --> 00:06:02.400]   was cannons and ringing bells. And that really tested your subwoofers.
[00:06:02.400 --> 00:06:09.200]   And it wasn't until roughly when Rolling Stone happened that suddenly it went from being about
[00:06:09.200 --> 00:06:14.960]   the equipment to being about the content. And I think we had a kind of an analogous transition
[00:06:14.960 --> 00:06:21.200]   in technology where nobody... Apple and Microsoft both announced new computers this week.
[00:06:23.040 --> 00:06:29.520]   Microsoft mentioned processors and RAM. Apple barely does anymore.
[00:06:29.520 --> 00:06:35.120]   I don't know about that. They have a whole lot of crazy made-up buzzwords that describe
[00:06:35.120 --> 00:06:41.040]   the technology and their chips. And I think we could talk about this. I think the big shift in
[00:06:41.040 --> 00:06:45.680]   Apple is it's moved from a design company to a silicon company to a chip company.
[00:06:45.680 --> 00:06:51.120]   There's certainly that. Design is still premier, but you're right. But now that they're doing
[00:06:51.120 --> 00:06:55.760]   they were placed Intel with their own silicon. Actually, that's a good point. They are talking
[00:06:55.760 --> 00:06:59.680]   much more about speeds and feeds. That has suddenly become a differentiator.
[00:06:59.680 --> 00:07:04.720]   When they bought Palo Alto, semiconductor or some years back,
[00:07:04.720 --> 00:07:15.280]   almost nobody ticked up on what that meant for where they were heading. And I certainly didn't.
[00:07:15.280 --> 00:07:22.880]   And it was in retrospect, that was quite the break from the past. And boy, they made
[00:07:22.880 --> 00:07:30.560]   some strides with the semiconductors. I think it was always Steve Jobs' idea that you make both
[00:07:30.560 --> 00:07:36.320]   the whole stack. You make software and you make hardware. Going back to, I think, Alan Kay
[00:07:36.320 --> 00:07:40.240]   saying, "If you want to control technology, you've got to make it all. You can't
[00:07:41.280 --> 00:07:46.400]   outsource the software. You can't outsource the hardware." It took them 30 plus years,
[00:07:46.400 --> 00:07:52.160]   40 years to do it. But they're still not doing it. They still have what Tim Cook calls legacy nodes,
[00:07:52.160 --> 00:07:56.960]   old chips that they have to put in their stuff. But they rapidly move it in that direction.
[00:07:56.960 --> 00:08:00.800]   But I think it's also where you're headed here. It's the Clay Shurkey argument,
[00:08:00.800 --> 00:08:05.200]   not that he's the only one who makes it. But the interesting thing starts happening when
[00:08:05.200 --> 00:08:08.400]   the technology becomes boring. Yes. I think that's it.
[00:08:08.400 --> 00:08:11.520]   And I think we may be at that point, because you've complained, "Oh, Google didn't do
[00:08:11.520 --> 00:08:17.120]   it in this year. I don't know what the hell." And I think that that's actually a good sign,
[00:08:17.120 --> 00:08:22.960]   because that democratizes it too. It means that we don't feel as intimidated by it. We have more
[00:08:22.960 --> 00:08:29.520]   power over it. It's pretty impressive. Let me ask, Tim, we have less power over it every year,
[00:08:29.520 --> 00:08:37.680]   because control is accruing into these companies more and more. And that's a separate.
[00:08:38.160 --> 00:08:47.440]   Issue. But the more Apple locks down everything, the more control it asserts over its entire
[00:08:47.440 --> 00:08:53.920]   ecosystem, even if a judge will push them a little bit in one direction. I'm not sure that
[00:08:53.920 --> 00:08:58.400]   Congress ever will. That would be a good conversation for the three of you.
[00:08:59.440 --> 00:09:05.920]   Big tech and the threat big tech poses or does not pose to our polity.
[00:09:05.920 --> 00:09:13.120]   Certainly, we talk about on this week in Google. And Jeff, I think I'd safe to characterize you
[00:09:13.120 --> 00:09:16.480]   on the side of big tech a little more than on the side of government.
[00:09:16.480 --> 00:09:23.040]   No, no. On the side of the internet and fearing regulation of the internet through big tech.
[00:09:25.200 --> 00:09:28.720]   Which puts you on the side of big tech really in a way because.
[00:09:28.720 --> 00:09:34.640]   Thank you, Stephen. I'm a telling them. I wish they were a better ally for the internet.
[00:09:34.640 --> 00:09:41.840]   Especially Facebook, a terrible, they make it real hard to defend the internet sometimes,
[00:09:41.840 --> 00:09:47.200]   as long as they're proprietors. But they're not forever proprietors. That's my point.
[00:09:47.200 --> 00:09:51.600]   Did Stephen win? This is for everybody, but I'll start with you, Stephen.
[00:09:53.200 --> 00:10:01.760]   I was certainly an internet optimist. I was of the, what is it? People of the internet.
[00:10:01.760 --> 00:10:07.920]   John Perry Barlow. John Perry Barlow's fabulous manifesto.
[00:10:07.920 --> 00:10:12.720]   I thought this was going to democratize. Everybody's going to get a voice. It was going to change
[00:10:12.720 --> 00:10:18.560]   the world. It was going to disintermediate. The incumbents would tumble. In fact, some of that
[00:10:18.560 --> 00:10:22.160]   happened. But I think I didn't really anticipate the negative consequences of it.
[00:10:22.160 --> 00:10:28.320]   Stephen, were you an optimist back there in the 80s about what technology would bring?
[00:10:28.320 --> 00:10:36.480]   I tilted towards the optimistic side. I always had an eye out for abuses and things like that.
[00:10:36.480 --> 00:10:45.840]   I had a skepticism to anything big. Look, I thought it was a way to smash the Oliarchy of
[00:10:46.640 --> 00:10:53.760]   telecom and all sorts of other nodes of control that this could take it down and
[00:10:53.760 --> 00:11:00.240]   could amplify individual voices. Facebook's proved that amplifying individual voices could
[00:11:00.240 --> 00:11:12.800]   be the most dangerous thing that could ever happen. I've always used the term among
[00:11:12.800 --> 00:11:18.880]   many people using the term about this being a double edged sword. But I didn't realize how
[00:11:18.880 --> 00:11:25.520]   sharp that bottom edge was. Had we known better, is there something we could have done?
[00:11:25.520 --> 00:11:34.080]   Lots, but each of those things we imagine now could have had other consequences.
[00:11:34.080 --> 00:11:38.640]   The folks who argue that anonymity is bad, and that's what caused the evils. Well,
[00:11:38.640 --> 00:11:43.280]   if we had created a system from the beginning of verified identity,
[00:11:43.280 --> 00:11:49.920]   then it'd be even better for the authoritarians. It'd be even worse for vulnerable populations.
[00:11:49.920 --> 00:11:56.320]   I think the thing I would say Leo, is it ain't done yet? It's not the internet, it's not baked.
[00:11:56.320 --> 00:12:02.480]   The point is that we've got to figure out how to take it back. This is why friend Doug Rushkoff
[00:12:02.480 --> 00:12:07.920]   argues often. We come at this from different ends. I was talking to Doug the other day,
[00:12:08.480 --> 00:12:12.160]   we're going to teach a course together in the future of the internet, designing the internet.
[00:12:12.160 --> 00:12:18.720]   Doug who wrote, throwing rocks at the Google bus, and I wrote, "What would Google do?"
[00:12:18.720 --> 00:12:22.160]   And Doug laughed at some point, and he said, "We end up at the same place, but we get there
[00:12:22.160 --> 00:12:28.320]   differently." He said, "Doug said, 'I want less evil, you want more good.' But we end up at the
[00:12:28.320 --> 00:12:33.440]   same place where we want to take charge of the internet again. We want to own it again. We want
[00:12:33.440 --> 00:12:39.200]   to imagine what it can be again." And I think that the question is, is that possible? If you think
[00:12:39.200 --> 00:12:45.680]   that it's done, and that Google and Facebook and company are the forever proprietors of it,
[00:12:45.680 --> 00:12:50.080]   yes, then that's cause for suicide. I don't think it's done. But if you think there's time,
[00:12:50.080 --> 00:12:52.880]   it's different. I don't think it's done, but I think the time for us to
[00:12:52.880 --> 00:12:58.400]   change it or to influence it is rapidly disappearing. No, no.
[00:12:59.760 --> 00:13:02.800]   Watch out, Leo. You're going to, guys. I do this on twig. Now you're going to get my Gutenberg.
[00:13:02.800 --> 00:13:09.200]   It's 150 years after the printing press before we created the newspaper, the modern novel,
[00:13:09.200 --> 00:13:13.600]   the modern essay, and the market for this place. It's as if one company owns the printing press.
[00:13:13.600 --> 00:13:17.920]   I don't think we have 150 years to spend before we find solutions to this.
[00:13:17.920 --> 00:13:24.080]   No, but I think we will invent new things that we can't imagine today because we see the future
[00:13:24.080 --> 00:13:30.880]   in the analog of the past. Dan, when you talk to your students who grew up in the middle of this,
[00:13:30.880 --> 00:13:36.160]   they're like the fish in the ocean that doesn't know about water. Are they aware of how things have
[00:13:36.160 --> 00:13:51.040]   changed? There are a little bit aware. What I'm heartened by is when I show students things about
[00:13:52.480 --> 00:14:02.880]   the control and centralization and what's actually going on, they get alarmed. They
[00:14:02.880 --> 00:14:10.080]   don't want to be controlled by huge enterprises and governments. They want to be able to do things
[00:14:10.080 --> 00:14:17.200]   themselves. Going back to your question a minute ago, though, if one thing we could have been done,
[00:14:17.200 --> 00:14:23.280]   we could have been doing all the way through this is to be a little more active in helping people
[00:14:23.280 --> 00:14:33.040]   understand basic civics, as we used to call it. We threw that away with STEM education and we
[00:14:33.040 --> 00:14:40.480]   better bring it back. That's an interesting point. I've always considered my mandate to teach people
[00:14:40.480 --> 00:14:49.200]   about technology so that they are empowered in the early days. I thought it would be a government
[00:14:49.200 --> 00:14:54.880]   that would use technology against them. Now I think it's industry that uses technology against
[00:14:54.880 --> 00:15:01.600]   them. In both cases, people need to take back the power by learning how to use technology and
[00:15:01.600 --> 00:15:06.240]   learning how to be used against them and learning what to defend and that kind of thing. That's
[00:15:06.240 --> 00:15:12.240]   not changed over the last 30 years at all. That's still a mandate and I think it's still something.
[00:15:12.240 --> 00:15:17.440]   But why civics? What part of civics do they need to learn?
[00:15:17.440 --> 00:15:23.920]   Well, I'm talking about it in a very broad way. I'm talking about participation. Let's
[00:15:23.920 --> 00:15:33.280]   stick to the US for the moment. We talk about democratization of things that if participation
[00:15:33.280 --> 00:15:41.200]   is the duty we have in a democracy, it's not just voting. It's participating in developing our future.
[00:15:41.200 --> 00:15:51.120]   Technology is giving us incredible tools to do that if we choose. But we have to do it better.
[00:15:51.120 --> 00:15:54.800]   So, Dan, can I ask you a question, Dan?
[00:15:54.800 --> 00:15:59.520]   So civics is normally tied with the nation and government.
[00:16:00.960 --> 00:16:05.840]   Let me ask you to spread that out and say, what does internet civics look like? What does internet
[00:16:05.840 --> 00:16:08.880]   governance in your vision then look like? What's the civics of the net?
[00:16:08.880 --> 00:16:16.240]   That's something we're still trying to understand and figure out. But it does start with recognizing that
[00:16:16.240 --> 00:16:28.160]   we are all part of it. We're not these endpoints of consumption.
[00:16:29.280 --> 00:16:38.160]   Where all we do is sit in front of a screen and go like that. It's something much more interesting,
[00:16:38.160 --> 00:16:44.000]   which is that we're instead of consumers, and this goes, we've known this for 20 years, but we're
[00:16:44.000 --> 00:16:49.920]   starting to maybe do something about it. But we're consumers, our participants and creators,
[00:16:49.920 --> 00:16:55.920]   and their collaborators, if we help them do it. And we're not doing enough of that.
[00:16:55.920 --> 00:17:05.120]   And we're not helping people understand what they can do themselves. I go nuts hearing the
[00:17:05.120 --> 00:17:16.000]   constant cries to the platforms, do something, do something, do something. Well, what exactly?
[00:17:16.000 --> 00:17:18.800]   And what can we do? What can we do exactly?
[00:17:18.800 --> 00:17:18.800]   Exactly.
[00:17:18.800 --> 00:17:23.840]   Some of this ourselves. Which was your great optimistic book, which I loved, which was also an
[00:17:23.840 --> 00:17:29.920]   Urtext for me, which is We The Media, which you wrote, Dan, and what you're?
[00:17:29.920 --> 00:17:36.800]   2004. I would point out that there are three chapters about what could go wrong.
[00:17:36.800 --> 00:17:46.320]   And I confess I did not anticipate how badly things might go wrong.
[00:17:46.320 --> 00:17:52.400]   And it proceeded social media, except for what was then social media, which was blogs.
[00:17:52.400 --> 00:17:56.000]   And those were the days.
[00:17:56.000 --> 00:18:04.480]   Yeah, well, you can't anticipate what's going to happen. At least I'm not very good at it.
[00:18:04.480 --> 00:18:07.760]   I think Stephen here is the only one who's got the
[00:18:08.880 --> 00:18:17.600]   cred for having done that for a long time. And Leo is there too. But I'm not a good predictor
[00:18:17.600 --> 00:18:24.080]   of technology. I just know it's going to get faster and more connected.
[00:18:24.080 --> 00:18:30.000]   Let me take advantage of the people on this panel. They asked this question.
[00:18:30.000 --> 00:18:35.840]   Everyone bemoans the loss of blogs. But if blogs were so important,
[00:18:35.840 --> 00:18:42.800]   wouldn't have they continued to find that audience? Couldn't have been that there wasn't some
[00:18:42.800 --> 00:18:47.120]   giant hand to say, we've changed into platforms. There's no more blogs.
[00:18:47.120 --> 00:18:52.800]   Maybe now what we thought of everyone mentions, where we thought of blogs is now
[00:18:52.800 --> 00:19:01.760]   part of a sub-stack rising or things like that. But I question this golden age of blogs.
[00:19:01.760 --> 00:19:06.560]   Maybe it wasn't something that people loved so dearly if we let it go away.
[00:19:06.560 --> 00:19:11.200]   I wasn't saying that at all. I think blogs ended up-
[00:19:11.200 --> 00:19:13.200]   No, it's a question. It wasn't a movie.
[00:19:13.200 --> 00:19:19.760]   Blogs ended up on Twitter and Facebook to a degree because
[00:19:19.760 --> 00:19:25.600]   for people who wanted to reach a lot of people, a lot of other people,
[00:19:26.960 --> 00:19:35.680]   that was more likely that they would. When Google tried to kill off RSS,
[00:19:35.680 --> 00:19:44.640]   that was a big blow to blogs. That was, again, a centralization thing. But blogs took a lot of
[00:19:44.640 --> 00:19:55.680]   work. People are still doing it. It's just that there's now other outlets that are easier to do.
[00:19:55.680 --> 00:20:00.000]   Well, there's also podcasts. Twitter will be for blogging.
[00:20:00.000 --> 00:20:08.480]   You could also make a point that blogs lost the ability to monetize, and that might have also
[00:20:08.480 --> 00:20:12.480]   not helped a little bit. And the blog would never agree.
[00:20:12.480 --> 00:20:18.320]   It's a hobby. Yeah. I think the same thing is happening to podcasting right now,
[00:20:18.320 --> 00:20:23.040]   there's going to be hobbyists and big companies, and there's nothing in between.
[00:20:23.040 --> 00:20:28.160]   So I asked Dave Weiner, who was one of the one of the-
[00:20:28.160 --> 00:20:30.240]   Has never stopped blogging, actually.
[00:20:30.240 --> 00:20:36.400]   Never stopped blogging. I said, and I was lamenting the loss of some of the wonderful days
[00:20:36.400 --> 00:20:40.960]   we had blog roles, and we loved each other, and we talked to each other. And he said,
[00:20:40.960 --> 00:20:44.640]   Jeff, everything is great when it starts. Yeah, that's true.
[00:20:44.640 --> 00:20:51.600]   It was a small group of people, mostly who knew each other. It was a very different environment.
[00:20:51.600 --> 00:20:55.040]   We got to know each other. Yeah. And that's how we got to know Dan Gilmore.
[00:20:55.040 --> 00:21:00.080]   You know, way early on. I don't think he held the first blogger con, and we were there.
[00:21:00.080 --> 00:21:03.840]   I don't think blogs went away. I think people have found more and have varied ways of
[00:21:03.840 --> 00:21:08.080]   expressing themselves, and blogs are still part of that, but not maybe as dominant,
[00:21:08.080 --> 00:21:12.320]   because there's other ways to do it. Well, media took them over for a while,
[00:21:12.320 --> 00:21:16.320]   right? So the New York Times first mocked blogs, and they were awful, and then they started doing
[00:21:16.320 --> 00:21:19.920]   blogs, and they started to change the voice of the New York Times, and then they rejected blogs,
[00:21:19.920 --> 00:21:26.080]   right? Then it was yesterday's tissue. There's a book by Charlton McElwain, who is the deputy
[00:21:26.080 --> 00:21:34.720]   provost at NYU called Black Software, that goes to the parallel creation of Black cultures
[00:21:34.720 --> 00:21:42.640]   online, the various efforts to do this. And a similar kind of arc happened, where some got
[00:21:42.640 --> 00:21:49.840]   co-opted by big companies like AOL, and then other flashy things came along, and it just kind of
[00:21:49.840 --> 00:21:55.360]   went away. What if we instead of saying blogs, what if we say the ability of the average person
[00:21:55.360 --> 00:22:00.160]   to have a voice in a way to publish, which is part of this promise that we thought of the internet,
[00:22:00.160 --> 00:22:04.640]   which was that everybody'd have a voice, there'd be a democratization, you wouldn't have to have
[00:22:04.640 --> 00:22:10.880]   a publisher or a radio station or a TV station. You could do that yourself. That all has blossomed,
[00:22:10.880 --> 00:22:16.480]   has it not? Everybody has a voice. In fact, really, that's the problem now, is that everybody has a voice.
[00:22:19.760 --> 00:22:20.760]   Well, they did.
[00:22:20.760 --> 00:22:26.800]   It was the cult of the amateur, is that's that? Oh, no. No, no, no, no.
[00:22:26.800 --> 00:22:34.320]   You know, when there wasn't many people on the internet, and you didn't have that power of the
[00:22:34.320 --> 00:22:42.320]   platforms, that was more true. You could still speak up, but I feel the Google, I mean, really,
[00:22:42.320 --> 00:22:48.480]   it's respectively the only search engine we have, is not going to rise you up like it used to.
[00:22:48.480 --> 00:22:53.040]   But it doesn't need to. If you are a TikTok star, you don't use Google to rise up through the
[00:22:53.040 --> 00:22:57.280]   ranks at TikTok or YouTube. So it was still a little property.
[00:22:57.280 --> 00:23:03.280]   But the content you do really isn't what we're talking about. You look at what goes viral on TikTok.
[00:23:03.280 --> 00:23:11.360]   It's not the same kind of thing. It's an entertainment channel. I know there's satire and other things
[00:23:11.360 --> 00:23:19.360]   in there, but it's a different kind of giving voice. You see on TikTok,
[00:23:19.360 --> 00:23:22.000]   they used to have on blogs or even that you do have on Twitter.
[00:23:22.000 --> 00:23:27.760]   But this notion of going viral is a vestige of mass media fake, that the only things that
[00:23:27.760 --> 00:23:32.400]   matter are the things that are big and scale. And what we saw in the blogging world is when,
[00:23:32.400 --> 00:23:36.400]   you know, tech bloggers got together, it was tiny, but they matter to each other.
[00:23:36.400 --> 00:23:42.240]   They was enough for them. And then after 9/11, the war bloggers came along, which I was one,
[00:23:42.240 --> 00:23:46.560]   the political bloggers at that time. And when we had our communities, and I think the same could
[00:23:46.560 --> 00:23:51.840]   be said of Black Twitter today, for example, where you don't need to have everybody and scale
[00:23:51.840 --> 00:23:57.360]   matters in the business model. It doesn't necessarily matter for the good of the communities involved.
[00:24:00.320 --> 00:24:10.560]   The formation of community of various kinds in all of these spaces is kind of the most,
[00:24:10.560 --> 00:24:16.000]   for me, the most interesting, where it's a large community, small community, middle. But
[00:24:16.000 --> 00:24:26.480]   as bad as some of them are, the Facebook group has had a huge impact in a lot of places.
[00:24:27.360 --> 00:24:34.320]   And I'm thinking about geographically the small town we live in next to San Francisco.
[00:24:34.320 --> 00:24:42.720]   There's no journalism ever done by traditional media about our town unless something bad happens.
[00:24:42.720 --> 00:24:47.040]   Or there's something that they find annoying and want to write about or cute.
[00:24:47.040 --> 00:24:54.720]   And yet in the Facebook group for our little town, that's where the news is.
[00:24:55.280 --> 00:25:03.920]   And it's very useful. It's not like where people are posting just stupid things. It's a well-moderated
[00:25:03.920 --> 00:25:08.480]   place where we tell each other what's going on. And people research and find out.
[00:25:08.480 --> 00:25:17.760]   Rather than it wasn't on Facebook, I'd rather that it was not on some centralized platform.
[00:25:18.480 --> 00:25:26.080]   But it's the best we have at the moment. And it's things like that that make me always step back
[00:25:26.080 --> 00:25:31.760]   and say this overall technology, what we're talking about is incredibly important
[00:25:31.760 --> 00:25:39.280]   for the voice that it's giving to people who did not have voices in the way we need them
[00:25:39.280 --> 00:25:44.480]   to live better civic lives and communicate with each other.
[00:25:44.480 --> 00:25:48.960]   Is that kind of what you envisioned with WeTheMedia? I mean, that's kind of what you were talking about,
[00:25:48.960 --> 00:25:57.280]   right? It is. I just didn't anticipate that it would be on Facebook. In places controlled by
[00:25:57.280 --> 00:26:09.120]   very, very big companies that are unable by definition because moderation simply does not scale.
[00:26:09.120 --> 00:26:15.040]   It can't be. So Dan, don't forget about it. Gutenberg didn't anticipate the 30 years war.
[00:26:15.040 --> 00:26:19.280]   That's it. You feel better, Dan?
[00:26:19.280 --> 00:26:27.760]   I'm not sure. I have to think about it. I don't think you anticipated that a young woman named
[00:26:27.760 --> 00:26:32.880]   Darnella Frazier would post a video of George Floyd being beaten to death that would transform
[00:26:32.880 --> 00:26:37.520]   the nation. And that was on Facebook. That's a civics. That's an act of civics, yes?
[00:26:39.040 --> 00:26:42.160]   So let me tell you a little bit. Go ahead, Dan. Sorry. Go ahead, Steve.
[00:26:42.160 --> 00:26:49.680]   No, I mean, well, Mark Zuckerberg didn't anticipate that either. I looked into some of the people
[00:26:49.680 --> 00:26:58.560]   who were helping set up Facebook Live, worried about people killing themselves or committing acts
[00:26:58.560 --> 00:27:06.560]   of violence on it, which also happened. That's right. But Facebook blew past them and came up with
[00:27:06.560 --> 00:27:14.080]   the product. When you have that critical mass of people, that network effect of people,
[00:27:14.080 --> 00:27:19.200]   all kinds of things can happen. And the question of Facebook is, Mark Zuckerberg,
[00:27:19.200 --> 00:27:26.400]   he'd love to hear this discussion so far with what Dan's saying because he feels his meaningful
[00:27:26.400 --> 00:27:32.560]   groups is really a core value of Facebook and proves that it's worth it. The question is,
[00:27:32.560 --> 00:27:39.360]   what's the cost of the things that aren't so good that we see on it? The things that happened
[00:27:39.360 --> 00:27:46.720]   that their moderators can't get on time in time or let pass for political reasons. That's
[00:27:46.720 --> 00:27:51.440]   what the Wall Street Journal piece essentially was about Facebook researchers saying, hey,
[00:27:51.440 --> 00:27:59.360]   this is intolerable. One fifth, the teenage girls who use Instagram feel bad about themselves,
[00:27:59.360 --> 00:28:06.640]   and we're making it worse. Is that worth the trade-off there? Is it something that's like a fender bender
[00:28:06.640 --> 00:28:14.560]   in this accumulation of good stuff? Or is it like a plane crash? And a lot of people feel
[00:28:14.560 --> 00:28:20.560]   it's the plane crash that you have to greatly minimize that kind of stuff. One fifth,
[00:28:20.560 --> 00:28:27.200]   the teenage girls on Instagram are millions of teenage girls. And to have one company
[00:28:27.200 --> 00:28:33.600]   making millions of teenage girls feel bad and some percentage of that feel really bad and have
[00:28:33.600 --> 00:28:38.480]   mental health issues is something that people find tough to swallow. So Stephen,
[00:28:38.480 --> 00:28:48.080]   go ahead, Dan. I know that stuff's well. I would like to know what percentage of teenage girls
[00:28:48.960 --> 00:29:01.200]   who watch popular television or read 17 magazines or basically who participate as consumers in
[00:29:01.200 --> 00:29:09.920]   more traditional forms of media, which for as long as I can remember have been
[00:29:09.920 --> 00:29:18.880]   exploiting images of women and girls and have been touting certain body shapes, etc.
[00:29:19.840 --> 00:29:27.280]   and fashion and makeup and all these things and sexualizing girls and women at very young ages.
[00:29:27.280 --> 00:29:34.320]   Did they feel worse about themselves? I don't know the answer, but I bet you there's research
[00:29:34.320 --> 00:29:39.520]   that would tell us whether this is a whole new thing or something.
[00:29:39.520 --> 00:29:43.040]   Well, I'm sure there's been research in those things, but
[00:29:44.960 --> 00:29:53.920]   I think the stuff we saw come out in the journal was researched by the super experience expert PhD
[00:29:53.920 --> 00:29:59.680]   levels, social scientists, people who can get a job at any great university, these people
[00:29:59.680 --> 00:30:08.640]   at Facebook that did studies that showed all that other stuff aside, the impact of Instagram
[00:30:10.000 --> 00:30:17.680]   alone, isolated was worse. People who watched TV and read magazines and did all the other things
[00:30:17.680 --> 00:30:23.360]   with Instagram on one hand and without Instagram on the other hand, that was the difference. So
[00:30:23.360 --> 00:30:26.800]   presumably they isolated Instagram in making their conclusions.
[00:30:26.800 --> 00:30:33.760]   The trick, well, I obviously is, how do you preserve the chance for Darnella Fraser to post
[00:30:33.760 --> 00:30:39.760]   that video at the same time? I mean, it's the double-edged sword. I don't understand how
[00:30:39.760 --> 00:30:44.800]   you can preserve the good and get rid of the bad. So Leo, can I address that directly?
[00:30:44.800 --> 00:30:50.560]   Because I had a bit of an epiphany this week and I went during a session that was put together
[00:30:50.560 --> 00:30:57.120]   by someone at the behest of the Facebook oversight board. And it was a chat house rule.
[00:30:57.120 --> 00:31:01.440]   So I'll talk about what I said and thought. And the question was Facebook has asked the
[00:31:01.440 --> 00:31:07.040]   oversight board to give them judgments about whether and what exceptions to have about Facebook's rule
[00:31:07.040 --> 00:31:15.040]   that you shouldn't have any identifying addresses or images of homes on Facebook.
[00:31:15.040 --> 00:31:19.440]   And whether there's a journalistic rule, a public policy rule, or protest,
[00:31:19.440 --> 00:31:27.360]   I mean exceptions to those rules. And what occurred to me during that was that I think we
[00:31:27.360 --> 00:31:34.960]   in media have a role here in having set the terms of the discussion in media terms around
[00:31:34.960 --> 00:31:41.840]   content and bad content and erasing content and getting rid of things as opposed to a service model.
[00:31:41.840 --> 00:31:47.840]   So Facebook hired 40,000 people now, 40,000 people to try to kill bad content like backable.
[00:31:47.840 --> 00:31:53.200]   And they created this rule about no address so that people wouldn't get harassed and wouldn't get
[00:31:56.560 --> 00:32:01.120]   threatening things happening. They're addressed fine. But at the same time people put up their
[00:32:01.120 --> 00:32:04.560]   pictures of their Christmas tree lights outside their house or I put up pictures of my house after
[00:32:04.560 --> 00:32:10.480]   Sandy or there's other reasons to do it. But the desire to have a rule that an algorithm could
[00:32:10.480 --> 00:32:16.560]   enforce and 40,000 people could enforce in a content-based world was any address bad.
[00:32:16.560 --> 00:32:22.240]   And it occurred to me two things. One, if George Floyd had been murdered on the driveway to his
[00:32:22.240 --> 00:32:26.640]   home, the algorithm might have killed the video before we saw it because you're trying to make a
[00:32:26.640 --> 00:32:31.680]   generalized rule about something. And second, what if instead of 40,000 content moderators,
[00:32:31.680 --> 00:32:36.080]   Facebook had 40,000 customer service people? And if someone felt that they were being
[00:32:36.080 --> 00:32:42.800]   harassed, they had someone who they could actually reach. But that's not the ethos that they have.
[00:32:42.800 --> 00:32:47.440]   You can't get any customer service at any of these companies. And so it's not about the problems.
[00:32:47.440 --> 00:32:51.600]   It's about we must create a rule that gets rid of all this stuff. So we will be in trouble anymore.
[00:32:52.160 --> 00:32:58.480]   And that is broken. A point there's not 40,000 content moderators. I think the Facebook says there's
[00:32:58.480 --> 00:33:05.680]   40,000 people involved in safety and security includes those moderators, most of them were on
[00:33:05.680 --> 00:33:12.000]   contract. The last figure they gave for the moderators was 15,000. And if they were customer
[00:33:12.000 --> 00:33:18.400]   service people, they couldn't handle a fraction of what they handle now. They have about 40 seconds
[00:33:18.400 --> 00:33:24.400]   to make a content decision on average on the things they say. I actually visited for my book,
[00:33:24.400 --> 00:33:27.520]   Facebook, The Inside Story, in case you're wondering.
[00:33:27.520 --> 00:33:40.400]   Evolution. Perfect. There we go. And these people check into the office or they used to check
[00:33:40.400 --> 00:33:46.640]   into the office. I think some of them are back in the office. And they just make a lot of decisions.
[00:33:46.640 --> 00:33:51.280]   A lot of them are really clear cut. Other ones aren't clear cut. Generally, they make them
[00:33:51.280 --> 00:33:57.360]   any way. And the difficult ones, they kind of kick to a level upstairs. The really super, super
[00:33:57.360 --> 00:34:03.360]   difficult ones go all the way up to Mark Zuckerberg. But there are so many decisions that that's the
[00:34:03.360 --> 00:34:09.360]   problem. They can't sit there and make new ones judgments. And they understand this. And Facebook
[00:34:09.360 --> 00:34:15.600]   feels that ultimately the answer is, well, we'll have an artificial intelligence to make zillions of
[00:34:15.600 --> 00:34:22.080]   these decisions. And a lot of stuff, matter of fact, is adjudicated. Sometimes even before it appears
[00:34:22.080 --> 00:34:28.720]   by artificial intelligence, but still, that's just a fraction. And when I asked the moderators,
[00:34:28.720 --> 00:34:34.720]   I said, do you ever feel that an AI can do your job? They just burst out laughing. That's just
[00:34:34.720 --> 00:34:40.160]   ridiculous. And the fact is, it's hard for a human to do, let alone exactly, exactly. It's one of those
[00:34:40.160 --> 00:34:45.840]   things that humans find it difficult to do. And it's particularly difficult when you don't have enough
[00:34:45.840 --> 00:34:52.960]   people in the different cultures and languages that Facebook covers in the world to make those
[00:34:52.960 --> 00:34:58.640]   decisions. It was pouting itself on the back recently for saying, Oh, we got these things solved in,
[00:34:58.640 --> 00:35:05.840]   or we're addressed in 50 languages of the 200, whatever is language is the Facebook is it.
[00:35:06.400 --> 00:35:11.040]   So wait a minute, what about the people in the languages? You don't cover, you don't get the
[00:35:11.040 --> 00:35:16.400]   pat yourself in the back because you're covering some, but not all of the countries that you're in.
[00:35:16.400 --> 00:35:21.040]   Is it your sense from running the book and your research you did that they are men of good and
[00:35:21.040 --> 00:35:28.800]   women of goodwill and that they want to solve this, or that they're using AI and the scale problem as
[00:35:28.800 --> 00:35:37.360]   kind of a shield? I think there are men women of goodwill, but the will gets weak when it comes to
[00:35:37.360 --> 00:35:46.000]   conflicts with growth and things like that, particularly that goes to Mark Zuckerberg. I don't think he's
[00:35:46.000 --> 00:35:53.600]   a bond villain necessarily, but he, when decisions come to him, and he looks at it and says, hmm,
[00:35:53.600 --> 00:35:59.840]   you know, we could do a better job of this problem if we adopt this course that's going to cut
[00:35:59.840 --> 00:36:07.200]   down the time spent on Facebook, he'll step back from that. Yeah. Ultimately, he's motivated by
[00:36:07.200 --> 00:36:15.840]   making a company successful. Yeah, he wants to, he wants the company to remain successful for
[00:36:15.840 --> 00:36:23.520]   the future as far as you can see. And in order to do that, he can't slow down. He doesn't want to
[00:36:23.520 --> 00:36:33.600]   become sun microsystems, who's former campus is now part of the sprawling Menlo Park complex
[00:36:33.600 --> 00:36:40.240]   that is mostly empty these days. But, and that's why he didn't take down the little sign that says
[00:36:40.240 --> 00:36:48.080]   sun on the back of the board there on Facebook way. If you walk around, that's interesting.
[00:36:48.080 --> 00:36:54.560]   If you're still see, son, he wants to remind her that they're not going away. His supposedly
[00:36:54.560 --> 00:37:00.480]   philosophy was always been that if people connect, that's going to be a net positive.
[00:37:00.480 --> 00:37:09.760]   So he still feel that way. I think he, I think he still feels that way, but he will
[00:37:09.760 --> 00:37:17.840]   readily admit now that it's a little more complicated than that. And there's also going to be
[00:37:17.840 --> 00:37:25.040]   a lot of negatives. And Facebook will never get rid of all the negatives, but we'll do it's best.
[00:37:25.040 --> 00:37:29.360]   That's where he comes out. Stephen, what do you think of him? Because you had more contact with
[00:37:29.360 --> 00:37:34.640]   him as a journalist than anybody. And you've seen, you know, I also saw him in the early days,
[00:37:34.640 --> 00:37:39.680]   much more than I have in recent times. And he changed, he grew up. What do you think of the,
[00:37:39.680 --> 00:37:43.520]   of the, of the progression of Mark Zuckerberg? One way or the other?
[00:37:44.320 --> 00:37:48.080]   I think it's interesting. I mean, do people change? I think he's grown.
[00:37:48.080 --> 00:37:53.360]   He's a kid. He's gotten married. He's certainly a moment of thought.
[00:37:53.360 --> 00:38:04.400]   And his personality has matured. I think he's always been the kind of person who is slow to
[00:38:04.400 --> 00:38:12.960]   trust other people. And I think if you go through a few years of the intense criticism, and you know,
[00:38:12.960 --> 00:38:21.680]   a lot of people hate the guy, you know, and that wall doesn't come down. He also understands that
[00:38:21.680 --> 00:38:31.120]   he's got a lot of work to do. He constantly says it. But he's a stubborn guy. He's a guy who
[00:38:31.120 --> 00:38:37.520]   won't make a big change until it's utterly clear to him that you have to make that. He
[00:38:37.520 --> 00:38:43.200]   believes that he'll come to a conclusion. He'll listen to all sides of an issue. And then I'll
[00:38:43.200 --> 00:38:48.160]   come to a conclusion. And then it takes a lot to move him off it. That's so different from
[00:38:48.160 --> 00:38:53.040]   move fast and break things. Is that is that just? Well, well, you know, it's possible to move fast
[00:38:53.040 --> 00:39:00.080]   and break things is a product thing with him. You know, you look at something. Yeah, I wrote a
[00:39:00.080 --> 00:39:04.800]   column once about the Facebook oversight, where which you mentioned. And it took, he thought of the
[00:39:04.800 --> 00:39:11.120]   idea or the idea was presented to him in early 2018. And you know, it wasn't until three years
[00:39:11.120 --> 00:39:16.240]   later, then they got it going. So I mentioned, you know, when it comes to something that serves
[00:39:16.240 --> 00:39:20.800]   the community like that, and you know, can might impact negatively on the product,
[00:39:20.800 --> 00:39:25.600]   then it's move slow and think things over guys. It isn't move fast and break things.
[00:39:25.600 --> 00:39:33.520]   He's gonna be facing the music a little bit. After the Facebook files series in the Wall Street
[00:39:33.520 --> 00:39:41.520]   Journal, apparently the whistleblower has now gone to Congress and according to the Washington Post
[00:39:41.520 --> 00:39:49.440]   offering the same trove of documents reviewed by the journal to Congress. In fact, Facebook is
[00:39:49.440 --> 00:39:56.800]   sending their global head of safety to testify about kids safety on Thursday before a Senate committee.
[00:39:58.880 --> 00:40:03.840]   This is going to be this is going to this is not over. In other words, was it was the Facebook files
[00:40:03.840 --> 00:40:11.920]   a fair, you know, sometimes Jeff and I doubt the Wall Street Journal's motives because of the Rupert
[00:40:11.920 --> 00:40:17.840]   Murdoch connection. Do you think the Facebook files was a fair take on what Facebook is doing?
[00:40:17.840 --> 00:40:22.800]   I think Facebook could have some legitimate gripes about the contextualization of it.
[00:40:24.160 --> 00:40:32.000]   I don't think reading the Facebook files, you got a sense of how difficult it is to solve these
[00:40:32.000 --> 00:40:40.800]   problems. But I think it's fair to say that these problems are such that they demand bigger changes
[00:40:40.800 --> 00:40:44.960]   than Facebook has been willing to make. Yeah, because that's a very fair statement.
[00:40:44.960 --> 00:40:49.680]   Facebook has testified that the company will not retaliate against the leakers behind the journal
[00:40:49.680 --> 00:40:55.760]   series. What do you mean? He constantly says, if you leak, we're going to fire you. I mean,
[00:40:55.760 --> 00:41:02.560]   that's a message. Then that would be that would be an exception to their leaking calls.
[00:41:02.560 --> 00:41:09.040]   Apparently, apparently, according to the journal, the whistleblower is seeking federal protection,
[00:41:09.040 --> 00:41:12.800]   federal whistleblower protection. So they may in fact be protected against retaliation.
[00:41:12.800 --> 00:41:15.440]   He would need a food taster when they reopen the capillation.
[00:41:18.320 --> 00:41:24.400]   Marsha Blackburn has received reams of documents, she says. So is the securities and exchange
[00:41:24.400 --> 00:41:31.680]   commission? Is this the kind of thing that takes the company down? How serious is this?
[00:41:31.680 --> 00:41:36.960]   So bigger than it was last year with all this stuff going on, still growing.
[00:41:36.960 --> 00:41:44.640]   Yeah, I know, and it's bad for Facebook. So I don't think Marsha Blackburn has a clue about
[00:41:45.600 --> 00:41:50.800]   the context of things I've seen her both in the room and on video,
[00:41:50.800 --> 00:42:01.120]   ex-found on Facebook. And she hasn't done her homework. She doesn't care to. So she's not a
[00:42:01.120 --> 00:42:05.440]   great person for Facebook to have in the judges' seat on this.
[00:42:05.440 --> 00:42:11.680]   Yeah, the idea of putting serious and Marsha Blackburn in one sentence.
[00:42:12.880 --> 00:42:18.080]   But she is an elected senator. Admittedly, her motives might not be pure, but she is an elected
[00:42:18.080 --> 00:42:25.840]   senator. And it's also a lot. It's also fair to note that much of what Facebook is doing is
[00:42:25.840 --> 00:42:33.840]   not illegal. It's not illegal for Facebook to operate under the First Amendment, which companies are,
[00:42:33.840 --> 00:42:42.160]   and moderate content in a way where things happen to make people feel bad or even
[00:42:42.160 --> 00:42:46.720]   in parallel mental health of people. I mean, five minutes of Fox News makes me insane. So
[00:42:46.720 --> 00:42:54.560]   maybe they should close. I should point out that not being illegal is not necessarily a problem for
[00:42:54.560 --> 00:42:59.280]   Congress, right? There are ways to make it illegal if it is legal right now.
[00:42:59.280 --> 00:43:03.520]   Well, no, we still have a constitution for that. We have for the First Amendment, but honestly,
[00:43:03.520 --> 00:43:09.280]   at this point, Facebook has annoyed the left for one reason, the right for another reason. At least
[00:43:09.280 --> 00:43:14.480]   they agree on something, which isn't been easy. That Facebook's an easy folk devil to have at
[00:43:14.480 --> 00:43:20.240]   the moral panic. And that's what I panic about. Yeah. Yeah. Let's take a little break. Go ahead,
[00:43:20.240 --> 00:43:25.280]   Dan. Final thought before we take a break. Go ahead. Sure. It's just, it's interesting that in
[00:43:25.280 --> 00:43:35.600]   all of this conversation, the among about remedies, the one that has not come up is antitrust. And
[00:43:37.440 --> 00:43:44.720]   also the some requirements that your data and conversations be portable and exportable,
[00:43:44.720 --> 00:43:51.600]   which would have much better effect, I think, than ordering Facebook to be the editor of the
[00:43:51.600 --> 00:43:58.560]   Internet. I wonder if Congress were smart enough to say we're going to create a Data Portability Act,
[00:43:58.560 --> 00:44:06.240]   for instance. Actually, there is one, isn't there? Didn't. I thought Ron Weiden introduced a data
[00:44:06.240 --> 00:44:10.800]   portability bill. I don't know what the status of that is. There's a whole bunch of bills that were
[00:44:10.800 --> 00:44:18.720]   submitted or clustered together. And that's part of it. It's more than portability. It's a,
[00:44:18.720 --> 00:44:27.600]   it goes into the category that Corey, Dr. Row and the EFF have been calling adversarial
[00:44:27.600 --> 00:44:35.280]   interoperability, which means basically that companies that oppose each other in lots of ways
[00:44:35.280 --> 00:44:45.120]   still be required to make the data in put it in formats that can be used in a variety of ways and
[00:44:45.120 --> 00:44:52.960]   interoperate with each other, that they can't lock down everything so that users would have much
[00:44:52.960 --> 00:44:59.760]   more and better choices. I think this is a really great concept. Although I'm not sure I'm looking
[00:44:59.760 --> 00:45:08.320]   forward to the federal Department of Interoperability. And let's be honest, it seems unlikely that
[00:45:08.320 --> 00:45:15.840]   anything is going to come out of Congress at all, let alone something as difficult as this to parse.
[00:45:15.840 --> 00:45:21.120]   But boy, it seems like that's a good idea. California will. California will do it. Sure.
[00:45:21.120 --> 00:45:26.880]   Sure. Or Europe. Yeah. Well, Europe might screw it up too.
[00:45:27.520 --> 00:45:32.000]   Or China. We'll talk about that in a second. China seems to have the right idea at this
[00:45:32.000 --> 00:45:38.800]   point. They don't have that first amendment getting in the way of regulating all this stuff.
[00:45:38.800 --> 00:45:44.400]   We got a great panel. Boy, do we have a great panel. Dan Gilmore is here. You can roast me later,
[00:45:44.400 --> 00:45:49.840]   Dan. I'll give you that opportunity. Dan Gilmore.com, great to have you from the Walter Cronkite
[00:45:49.840 --> 00:45:55.600]   School at Arizona State. We also have Jeff Jarvis from the Craig Newmark Graduate School of Journalism
[00:45:55.600 --> 00:46:00.960]   at the City University of New York. And we also have Steven Levy. Do you have any academic
[00:46:00.960 --> 00:46:05.520]   credentials you'd like to tout? We've got a master's degree in English literature.
[00:46:05.520 --> 00:46:12.400]   And I am very proud to have, and I wish it were a first edition, but a signed copy of
[00:46:12.400 --> 00:46:16.240]   Hackers, one of the greatest books ever written. And this Facebook book is really good too. You
[00:46:16.240 --> 00:46:20.960]   know, I feel bad because we had planned to interview you. Then COVID, when the book came out, then COVID
[00:46:20.960 --> 00:46:26.000]   hit and all of those things went by. I could have been in the studio. I know.
[00:46:26.000 --> 00:46:30.160]   Blue it. One of many places I could have been on my book. I could have. I could have would have
[00:46:30.160 --> 00:46:37.040]   should have that panel and that session in South by Southwest. Oh, man. Yeah.
[00:46:37.040 --> 00:46:43.280]   Si, our show today brought to you by Worldwide Technology in Cisco. This was actually the last
[00:46:43.280 --> 00:46:50.080]   trip I took was to St. Louis last year in March to visit their Advanced Technology Center. And it is,
[00:46:50.080 --> 00:46:54.080]   I'm glad I saw it. It's an amazing thing. And I look forward to going back out there.
[00:46:54.080 --> 00:47:00.480]   Worldwide Technology is a great partner for any business looking to use the latest technology.
[00:47:00.480 --> 00:47:07.680]   And the Advanced Technology Center is Worldwide Textway of trying the technologies, piloting
[00:47:07.680 --> 00:47:13.600]   programs, researching, testing compatibility. It's a research and testing lab that brings together
[00:47:13.600 --> 00:47:19.520]   technologies from leading OEMs like Cisco. There's more than half a billion dollars in equipment,
[00:47:19.520 --> 00:47:24.480]   invested in the lab. It started 10 years ago in one building. It's in four or five now,
[00:47:24.480 --> 00:47:31.200]   rack of rack on rack of amazing technology. By the way, I want to point out you can use the ATC.
[00:47:31.200 --> 00:47:35.280]   You can test out, do the same thing that worldwide tech engineers do.
[00:47:35.280 --> 00:47:39.920]   Products and solutions before you go to market, you get access. They're to technical articles,
[00:47:39.920 --> 00:47:44.800]   expert insights, demonstration videos, white papers, hands on labs, all the tools,
[00:47:44.800 --> 00:47:48.880]   a modern business needs to stay up to date with the latest technology.
[00:47:48.880 --> 00:47:54.080]   The thing about Worldwide Technology in Cisco, they're partners. They work with you. And because
[00:47:54.080 --> 00:48:02.640]   worldwide technology understands that your strategy, your business goals have to be informing your
[00:48:02.640 --> 00:48:07.680]   technology purchases. They're a great partner. They will work with you all the way through
[00:48:07.680 --> 00:48:14.080]   implementation to training and forward. I'll give you some examples, some case studies.
[00:48:14.080 --> 00:48:17.840]   You can find these on the Worldwide Tech page. There was a large design, we don't name names,
[00:48:17.840 --> 00:48:23.360]   just mention a large design and construction firm. Pandemic hit, they wanted to continue
[00:48:23.360 --> 00:48:27.840]   critical operations, but they also want to make sure their staff was safe. And when the staff
[00:48:27.840 --> 00:48:33.280]   was started to return into office, they wanted a safe return. WWT came in that consultants used
[00:48:33.280 --> 00:48:39.040]   expert knowledge, the Advanced Technology Center in-depth analysis to maximize existing IT investments
[00:48:39.040 --> 00:48:44.480]   to improve the employee experience. How about that? They said, "Well, you've already got some
[00:48:44.480 --> 00:48:50.960]   technology here. Why don't we do some customized training with the company's diverse employee base
[00:48:50.960 --> 00:48:56.800]   to help them use the existing technology and the new technology?" And that training made a huge
[00:48:56.800 --> 00:49:00.800]   difference. They worked with the state university to create new opportunities for students to connect
[00:49:00.800 --> 00:49:08.400]   with faculty online. WWT helped the university test and compare virtual collaboration solutions.
[00:49:08.400 --> 00:49:13.600]   That's what they use the ATC for, for instance. And then train and engage faculty and students
[00:49:13.600 --> 00:49:18.720]   to ensure strong adoption. This is what Worldwide Technology is famous for,
[00:49:18.720 --> 00:49:23.920]   their personal approach. They can not only identify the technologies you need to safely reopen,
[00:49:23.920 --> 00:49:28.960]   they can architect and implement a variety of solutions, things like, you know, fever screening
[00:49:28.960 --> 00:49:35.440]   and occupancy monitoring and contact-free conference rooms. CFWWT and Cisco can help bring clarity
[00:49:35.440 --> 00:49:43.040]   to your reopening plans and implement solutions that enable flexible working. Go to www.com/twit
[00:49:43.040 --> 00:49:51.440]   to get started and gain access to all their valuable resources. WWT.com/twit worldwide technology.
[00:49:51.440 --> 00:49:57.200]   Make a new world happen, we thank them so much for their support of this week in tech.
[00:49:57.200 --> 00:50:03.600]   So I'm going to give you a chance. China, think of all the things China has been able to do. They
[00:50:03.600 --> 00:50:11.360]   have been able to shut down and curtail this, you know, the ultra growth in some of their more
[00:50:11.360 --> 00:50:16.960]   consumer-focused technologies. They get kids to only video game three hours a week through
[00:50:16.960 --> 00:50:23.600]   Friday, Saturday and Sunday and holidays. Now they have said all cryptocurrency-related
[00:50:23.600 --> 00:50:30.400]   activities are illegal. Gee, wouldn't it be nice if we had a totalitarian government and we could just
[00:50:30.400 --> 00:50:34.320]   just come on in and say, "Facebook, this is going to be fixed."
[00:50:35.200 --> 00:50:45.120]   It would stop the Winkle-Horse twins. We actually talk about, obviously, I'm a little bit tongue
[00:50:45.120 --> 00:50:50.800]   in cheek. So you don't have to come down too hard on it. But it is interesting that
[00:50:50.800 --> 00:50:55.040]   they're doing a lot of the things that people say here in the United States. Well, exactly,
[00:50:55.040 --> 00:51:00.160]   beware. We can see where it goes. It goes toward China. I've been screaming that for years.
[00:51:01.440 --> 00:51:08.000]   So you're right. Some would like that level of authoritarianism. But that ain't my country.
[00:51:08.000 --> 00:51:16.080]   Yeah. I think, Jen, you probably follow this fairly closely given your interest in Asia.
[00:51:16.080 --> 00:51:23.440]   The question that I've heard a lot of people say is this because the Chinese, the CCP has decided
[00:51:23.440 --> 00:51:30.000]   to focus more on infrastructure technology and infrastructure and less on consumer technology?
[00:51:30.880 --> 00:51:41.440]   I don't know. I think there's a case that a couple of things are going on, including the
[00:51:41.440 --> 00:51:50.400]   regime's incredible zeal to be a dictatorship and to clamp down and control everything.
[00:51:50.400 --> 00:51:57.840]   A free and vibrant consumer technology sector is not helpful to that.
[00:51:57.840 --> 00:52:03.440]   Yeah. What's been amazing to see? I'm sorry, I did it down. I'm going to stop when you finish up.
[00:52:03.440 --> 00:52:08.880]   Well, there was just one other thing. On the clamp down on cryptocurrencies,
[00:52:08.880 --> 00:52:16.320]   I'm not sure that there's, let me reverse it. I think there's probably
[00:52:16.320 --> 00:52:26.000]   another mode of there in addition to just general control for inquiry and related to that because
[00:52:27.200 --> 00:52:39.440]   the economy and in particular real estate is grossly overheated in China. They're in a
[00:52:39.440 --> 00:52:50.560]   major bubble on property values and have totally overbuilt and have had companies that are wildly
[00:52:50.560 --> 00:53:00.640]   overleverged, owing hundreds of billions. It may be that on banning cryptocurrencies,
[00:53:00.640 --> 00:53:08.640]   they're trying to control or at least slow down the flight of capital that tends to happen from
[00:53:08.640 --> 00:53:17.280]   countries that are perhaps heading toward economic, really serious trouble. Of course,
[00:53:17.280 --> 00:53:23.120]   the whole world would be caught in that if it does happen. But that seemed pretty
[00:53:23.120 --> 00:53:31.440]   plausible to me. I don't remember where I read that, but that struck a chord as maybe that is part
[00:53:31.440 --> 00:53:38.000]   of the motivation to just prevent too much money from fleeing the country.
[00:53:38.000 --> 00:53:42.720]   But isn't it more cultural than that too? Isn't it a matter of control?
[00:53:45.520 --> 00:53:50.720]   If the regime could stay popular by everybody getting more money and growing and having bigger
[00:53:50.720 --> 00:53:55.440]   homes and buying more stuff, fine for the long that lasted. But then when trouble comes,
[00:53:55.440 --> 00:54:03.840]   they have to put the hammer down and we're almost headed to an economic cultural revolution.
[00:54:03.840 --> 00:54:05.920]   Is that going overboard?
[00:54:05.920 --> 00:54:10.400]   No, that makes sense. I think these are intertwined.
[00:54:13.440 --> 00:54:21.040]   It just, if we're looking for some specific thing, because I thought this cryptocurrency ban was very
[00:54:21.040 --> 00:54:30.400]   sudden. There were some things that happened that were perhaps in retrospect leading up to it.
[00:54:30.400 --> 00:54:41.040]   But this is a surprise to me. When we look in our own country and other countries about cryptocurrencies,
[00:54:41.920 --> 00:54:49.120]   a man, I think people who are speculating in those areas who are not the insiders, who are
[00:54:49.120 --> 00:54:54.320]   already profited and will stand to profit even more, be careful.
[00:54:54.320 --> 00:55:01.920]   I think there's a couple of things going on. There are great points about these real estate
[00:55:01.920 --> 00:55:07.200]   companies. People say this could be another subprime that affects the rest of the world.
[00:55:07.200 --> 00:55:14.480]   But in the last year, I've been really surprised to see how hard China is coming down against the
[00:55:14.480 --> 00:55:24.480]   entrepreneurs like Jack Ma, who were once celebrated as successes of the whole Chinese system.
[00:55:24.480 --> 00:55:32.080]   It's almost reminiscent of what Putin did to slam down the oligarchs in Russia.
[00:55:35.840 --> 00:55:41.920]   Maybe that's not the greatest way to build a global internet business, to take your most
[00:55:41.920 --> 00:55:51.040]   glory to entrepreneurs and founders and charge them with crimes or remove them. I think certainly,
[00:55:51.040 --> 00:55:59.760]   it shows that the control that China shows, it just can't be trusted as a global brand.
[00:55:59.760 --> 00:56:11.440]   You see, obviously, we don't trust Huawei. TikTok was sort of teetering in the Trump era.
[00:56:11.440 --> 00:56:17.600]   It's still the most popular download among social network apps.
[00:56:17.600 --> 00:56:21.680]   More engagement than YouTube, longer viewing times.
[00:56:24.640 --> 00:56:34.880]   But I would say that stands as an anomaly before the curtains come down on big private internet in
[00:56:34.880 --> 00:56:41.360]   China. They were the only companies that are so popular and so universal and necessary in China
[00:56:41.360 --> 00:56:45.280]   that didn't break the border. Isn't TikTok the only company that really did?
[00:56:45.280 --> 00:56:54.560]   Well, some people said that was going to be the dawn of this new era, but then you see what happened
[00:56:54.560 --> 00:57:01.840]   with Alibaba and Diddy now is under great pressure and China's clamped down on them.
[00:57:01.840 --> 00:57:08.000]   Huge success, the company that beat Uber, and it's not just in China, but
[00:57:08.000 --> 00:57:16.560]   the main presence and ride sharing in some other countries. It's really interesting to see how
[00:57:16.560 --> 00:57:23.600]   what looked like China's participation in a global internet by nurturing these companies has done
[00:57:23.600 --> 00:57:31.200]   180. China was even cracking down on WeChat. You were talking about these Chinese-only companies
[00:57:31.200 --> 00:57:38.240]   that are completely dominant in China. I don't know what's the status is today, but in last July,
[00:57:38.240 --> 00:57:44.560]   WeChat had stopped signing people up. Yeah, and there's another aspect to the clamp down
[00:57:44.560 --> 00:57:53.120]   on the social media type companies is that the China regime is basically saying,
[00:57:53.840 --> 00:58:02.480]   "Companies, corporations, you may not spy on everybody. We will." That's our job. The government,
[00:58:02.480 --> 00:58:10.480]   it's our job. You'll help us, but when it comes to who really is in control, it's us and don't
[00:58:10.480 --> 00:58:17.040]   forget that. I wonder if that's a subtext of the American government crackdown. Yep, I think so.
[00:58:17.040 --> 00:58:22.480]   I do have one thing to say about this rule that the kids can only play video games,
[00:58:22.480 --> 00:58:29.760]   for like three hours a week. If these kids have not managed to figure out the hacker way past that,
[00:58:29.760 --> 00:58:36.480]   then China really is dead. Maybe they're trying to create a hacker class. That's probably one good
[00:58:36.480 --> 00:58:42.160]   way to do it. Teach kids how to get around the government crackdown. That's gotta be. That's
[00:58:42.160 --> 00:58:51.440]   gotta hurt. Three hours a week. Wow. Here's an interesting story from our federal government
[00:58:51.440 --> 00:58:56.720]   protecting us. Once again, it turns out the Reville ransomware, remember
[00:58:56.720 --> 00:59:05.520]   Casaia, the company that was an IT support company that ended up being the pathway to hacking
[00:59:05.520 --> 00:59:12.160]   many of its customers for the Reville ransomware gang. It turns out the FBI
[00:59:13.600 --> 00:59:22.000]   had the key that could unlock these computers for three weeks, but told no one that they had it.
[00:59:22.000 --> 00:59:27.280]   According to the this story came out this week from the Washington Post,
[00:59:27.280 --> 00:59:35.440]   the key was obtained through access to the servers of the gang. And the FBI held it close to their
[00:59:35.440 --> 00:59:40.960]   vest because they were hoping with the agreement of other agencies to carry out an operation to
[00:59:40.960 --> 00:59:46.320]   disrupt Reville. The bureau didn't want them to know that they had the key, so they couldn't tell
[00:59:46.320 --> 00:59:53.120]   these companies, "Oh, don't pay the ransomware. We can help you decrypt the data." They said a
[00:59:53.120 --> 00:59:58.560]   government assessment found the harm was not as severe as initially feared. The plan takedown
[00:59:58.560 --> 01:00:03.920]   never occurred because Reville shut down before the feds could shut them down and the hackers
[01:00:03.920 --> 01:00:09.120]   disappeared. I have to feel like if you were one of the companies that had been ransomed
[01:00:09.920 --> 01:00:14.800]   and you knew the FBI had the keys but didn't tell you, you might feel a little reasonably
[01:00:14.800 --> 01:00:16.480]   a little bit miffed at this point.
[01:00:16.480 --> 01:00:23.120]   And what if you were in the hospital that couldn't treat you or had problems treating you because
[01:00:23.120 --> 01:00:28.640]   they couldn't get on their system? When I flew back from Tampa, it was yesterday,
[01:00:28.640 --> 01:00:34.080]   I went by in the pizza place and the Chick-fil-A, the Chick-fil-A was completely shut down. I thought,
[01:00:34.080 --> 01:00:38.480]   "Oh, they must have burned out their fryers or something." No, the system is down. So we can't cook
[01:00:38.480 --> 01:00:45.360]   anything. So what's the add-on effect of that in all the victims? What else couldn't happen?
[01:00:45.360 --> 01:00:53.200]   Who else was victimized? Don't you watch any movies? Don't you know that the FBI will always let
[01:00:53.200 --> 01:00:59.360]   the criminal gangs murder other people because their informants get away with this kind of stuff?
[01:00:59.360 --> 01:01:05.840]   We'll never, this is just mapping out FBI behavior to ransomware.
[01:01:05.840 --> 01:01:13.600]   Sure. It's like the British government not using the Enigma crypto because if they did,
[01:01:13.600 --> 01:01:20.080]   the Germans would know that they'd cracked it. The FBI finally did give Cassaya the key 19 days
[01:01:20.080 --> 01:01:25.280]   after it was hit Cassaya, created a decryption tool and released it the following day but
[01:01:25.280 --> 01:01:32.160]   it's too late for some victims. But it's a legitimate question and it's not
[01:01:35.040 --> 01:01:44.080]   obviously wrong for law enforcement to hold on to something if it really thinks and
[01:01:44.080 --> 01:01:50.640]   persuasively that it could shut down something much bigger. I'm not saying,
[01:01:50.640 --> 01:02:01.760]   I have a great sympathy for the victims that we're not told. But I think this is a trade-off
[01:02:01.760 --> 01:02:07.120]   that's not completely clear cut and it may turn out this was really a bad idea but
[01:02:07.120 --> 01:02:12.560]   it might not always be a bad idea. Well, if they had been able to arrest them and
[01:02:12.560 --> 01:02:17.680]   bring them to justice as they had planned, maybe everybody would say, "Yeah, you did the right thing."
[01:02:17.680 --> 01:02:24.080]   Unfortunately, somehow, Reevil got the, by the way, they're back. They left, but they're back.
[01:02:24.080 --> 01:02:33.040]   They're at it again. Maybe they'll get another chance.
[01:02:33.040 --> 01:02:39.360]   Yeah, there's a long, I guess there's a long-standing history of knowing this information but not
[01:02:39.360 --> 01:02:42.960]   being able to use it because it would give up your informants or that kind of thing.
[01:02:42.960 --> 01:02:49.040]   I'm not going to bring up the new, there's a new iPhone. Actually, it's an interesting story.
[01:02:49.040 --> 01:02:53.920]   Steven, you wrote a great book on the iPod, I think, right? The new next new thing.
[01:02:53.920 --> 01:02:57.520]   Yeah, you did a book on the Macintosh and then the iPod.
[01:02:57.520 --> 01:03:04.560]   Apple seems to, now I'll quote Brian X Chen. It's my opinion as well,
[01:03:04.560 --> 01:03:10.640]   but Brian X Chen's review of the iPhone 13 was pretty scathing in the New York Times.
[01:03:12.880 --> 01:03:21.920]   Let me see if I can get the exact, the most incremental upgrade ever, he said. The new iPhone is 10%
[01:03:21.920 --> 01:03:29.040]   faster than the last one and the photos are slightly better. In a word, huh? I'll agree with
[01:03:29.040 --> 01:03:33.520]   them. My wife insisted on getting it. I said, "I'm not going to buy it. I'm happy with an iPhone 12."
[01:03:33.520 --> 01:03:38.800]   And I took it out and I said, "There is very little improvement in this,
[01:03:39.440 --> 01:03:43.440]   except that I can't use the old case because they moved the camera over about a millimeter.
[01:03:43.440 --> 01:03:50.080]   Maybe the pictures are a little bit better." Apple's kind of got a problem, which is the iPhone
[01:03:50.080 --> 01:03:56.400]   is pretty close to the peak. It isn't the next new thing, by any means. It's the old thing.
[01:03:56.400 --> 01:04:03.360]   Well, I don't think Apple expects everyone that iPhone 12 to go to an iPhone 13. If you have an
[01:04:03.360 --> 01:04:12.800]   iPhone 6 and we're wondering, "Gee, should I upgrade?" You might figure, "Well, this is
[01:04:12.800 --> 01:04:18.480]   as good a time as any because there's a big leap between an iPhone 6 and an iPhone 13,
[01:04:18.480 --> 01:04:21.920]   particularly in battery life. The battery life is actually better than 10%.
[01:04:21.920 --> 01:04:23.760]   Yeah, no, it's huge. That's right.
[01:04:25.520 --> 01:04:35.040]   And a lot of the phone companies, the Verizon, AT&T, they're offering deals and a lot of people have
[01:04:35.040 --> 01:04:40.080]   deals where the upgrades come automatically, that people just like to have new ones,
[01:04:40.080 --> 01:04:47.200]   like some people just wanted to drive a new car every year. So Apple will saw a lot of these.
[01:04:47.200 --> 01:04:49.920]   They seem to have the chip supplies, which no one else has.
[01:04:52.720 --> 01:05:00.960]   But it's true that it's not an earth-shattering thing. And maybe we've reached the point where
[01:05:00.960 --> 01:05:08.000]   incremental upgrades are all you can do with that. And the next giant thing at Apple is not going to
[01:05:08.000 --> 01:05:13.840]   be like a phone which shatters our expectations of what a phone is, but something else.
[01:05:13.840 --> 01:05:20.000]   It's not just Apple. Microsoft has announced Windows 11, which is only a little bit better than
[01:05:20.000 --> 01:05:25.200]   Windows 10. Mostly it's cosmetically different. It's the biggest difference.
[01:05:25.200 --> 01:05:31.760]   And it seems to be the reason Microsoft's shipping Windows 11 is so that PC makers will have something
[01:05:31.760 --> 01:05:34.160]   new to sell in the fall. So it's very similar, isn't it?
[01:05:34.160 --> 01:05:39.520]   I once asked Bill Gates years ago, I think when he was releasing this stuff, I said,
[01:05:39.520 --> 01:05:44.320]   do you really think there's going to be a Windows 10? And he looked at me, well, of course,
[01:05:45.280 --> 01:05:51.200]   it has to be. There has to be. The Windows 11, yeah. Yeah. I mean, that's really the point is
[01:05:51.200 --> 01:05:55.280]   you don't release a new iPhone every year necessarily because everybody's going to upgrade
[01:05:55.280 --> 01:05:59.840]   every year, but you always have to have a new model just as there's always a new model of,
[01:05:59.840 --> 01:06:04.800]   you know, F-150 truck, not maybe a big difference. But this goes back to it becomes boring. And
[01:06:04.800 --> 01:06:10.560]   then we figure out what else we can do with it. That's why TikTok matters to me. TikTok said
[01:06:10.560 --> 01:06:14.880]   we're going to use these tools to collaborate in ways we couldn't have ever done before.
[01:06:14.880 --> 01:06:19.200]   And it wasn't really about the iPhone or Android either. It was just that the tool
[01:06:19.200 --> 01:06:26.880]   existed to do stuff with it or tensor of being in the Android phones, enabling immediate
[01:06:26.880 --> 01:06:33.520]   translation. Things we can't anticipate yet that may be done with these tools rather than the tools
[01:06:33.520 --> 01:06:42.320]   themselves being interested. The dumbest reviews of the new iPhones, which are sort of an annual
[01:06:43.600 --> 01:06:51.280]   dumb reviews for G8 is best new, best iPhone yet. Yes. Well, it damn well better be.
[01:06:51.280 --> 01:06:54.960]   People worse, you'd have to wonder what Apple has been doing all year.
[01:06:54.960 --> 01:07:06.800]   I will say exactly. Yeah. The pixel went downhill for a year after the 3A, which was until last week,
[01:07:06.800 --> 01:07:12.400]   something I had happily been using. Yeah. Which was the best. Until last week. What's the new
[01:07:12.400 --> 01:07:16.240]   leading? What are you using? I bought the five. I bought the five. It's you didn't wait for the
[01:07:16.240 --> 01:07:24.160]   six. No, I'm not going to spend. I partly one reason I bought it was so that I wouldn't be too
[01:07:24.160 --> 01:07:30.800]   simple. Too tempted to buy the six. Oh, this way. This way it was it was it was like taking the
[01:07:30.800 --> 01:07:37.280]   drug before you get the disease. I got it. Yeah. Right. This is my my ever. I was going to say is
[01:07:37.280 --> 01:07:43.200]   the is the pixel 5A the Ivermectin of smartphones. I think it might might that might be on a little
[01:07:43.200 --> 01:07:52.160]   too. But it's it's a wonderful phone and it is great. It's the best pixel yet. So fine. I'll have
[01:07:52.160 --> 01:08:04.080]   for all have this one for a month. No, this is it's a I like incremental. I like the fact that when
[01:08:04.080 --> 01:08:14.240]   you finally do decide to get something better. And one place where Apple is way better than
[01:08:14.240 --> 01:08:23.760]   Android is the longevity of its updates, especially security updates. They actually still offer iOS
[01:08:23.760 --> 01:08:30.800]   15 for as old a phone as the six S. Yeah, that's pretty amazing. And that is something to say for
[01:08:30.800 --> 01:08:39.120]   that makes a huge difference. Yeah. You know, to the ecosystem. When everyone's on the same page
[01:08:39.120 --> 01:08:45.760]   there. And that that's always been to me. The big flaw of Android is that, you know, people don't
[01:08:45.760 --> 01:08:51.440]   upgrade that the system isn't such that, you know, the upgrades come routinely. You know, you go to
[01:08:51.440 --> 01:08:58.000]   sleep in Europe to the new things. I still name them after candies. But yes desserts. Yes. Yeah.
[01:08:58.000 --> 01:09:03.280]   No, no, it's still a dessert. They don't make a big deal about it, but it's still a
[01:09:03.280 --> 01:09:06.400]   they don't make a little statue. They don't make a statue anymore.
[01:09:06.400 --> 01:09:09.760]   Yeah, but the no fun anymore.
[01:09:09.760 --> 01:09:16.480]   That really slows down the value of the Android system because, you know, developers,
[01:09:16.480 --> 01:09:22.320]   you know, aren't incentivized to come up with something to take advantage of the new system
[01:09:22.320 --> 01:09:29.120]   right away. And you know, the whole ecosystem suffers. I decided to forego the Pixel 5 because
[01:09:29.120 --> 01:09:36.480]   it was so close to the Pixel 4. I forgoing the iPhone 13. Go ahead, Daniel. Oh, oh, yeah, I'm not
[01:09:36.480 --> 01:09:42.000]   gonna buy it. Lisa's got it for five minutes. Well, you know what I'm gonna get instead,
[01:09:42.000 --> 01:09:48.240]   which I think is kind of interesting. Microsoft announced the duo to this week as well,
[01:09:49.040 --> 01:09:57.200]   which is their Android device with two screens. And I think is kind of interesting. I bought the
[01:09:57.200 --> 01:10:01.680]   duo last year, returned it after a couple of weeks because the software didn't live up to the
[01:10:01.680 --> 01:10:07.280]   potential of the hardware. But and it may happen again this week, but I love the idea. Not of a
[01:10:07.280 --> 01:10:11.840]   folding phone. Let me turn off the music so we don't get taken down, but of a phone with a hinge,
[01:10:11.840 --> 01:10:18.400]   two screens and a hinge just because of the real estate. A revolutionary hinge.
[01:10:19.040 --> 01:10:25.280]   How about that? It's pretty anyway. Microsoft invented the door.
[01:10:25.280 --> 01:10:28.320]   Looks like something from Terminator.
[01:10:28.320 --> 01:10:36.160]   Yeah, this is actually a real problem in the Android world and Google. I don't blame Google.
[01:10:36.160 --> 01:10:40.240]   I think the problem really with updates is that there are a lot of old Android phones
[01:10:40.240 --> 01:10:45.200]   because it is it was for a long time that it still is, I guess, the cheapest operating system
[01:10:45.200 --> 01:10:52.720]   you could put on a phone and and Google's sort of stuck with manufacturers that
[01:10:52.720 --> 01:10:59.680]   hold back the updates that it provides. That's right. That's right. And one reason Google keeps
[01:10:59.680 --> 01:11:06.400]   pulling more of the important functionality back into the central operating systems that
[01:11:06.400 --> 01:11:11.520]   and making more and more requirements on the manufacturers to do it. Google's way or not at all
[01:11:12.800 --> 01:11:18.560]   is because they realized they had to get a handle on this incredibly bad system.
[01:11:18.560 --> 01:11:24.480]   So I want to go back to your book, The Perfect Thing, Stephen, because this was in an era
[01:11:24.480 --> 01:11:30.720]   when Apple was totally dominant that the iPod kind of took over the marketplace. Apple followed
[01:11:30.720 --> 01:11:37.760]   that with the iPhone had the same kind of exact transition. Where does Apple go next?
[01:11:39.120 --> 01:11:45.040]   Is there the next perfect thing for Apple? That's a great question. People ask that about
[01:11:45.040 --> 01:11:49.680]   Tim Cook. I mentioned earlier about the Apple Silicon. And I think that really is
[01:11:49.680 --> 01:11:59.200]   the advance, the advantage that Apple has now in developing its products. But we're all still
[01:11:59.200 --> 01:12:05.120]   waiting. The watch turned out to be more successful than a lot of people thought. It was stumbled
[01:12:05.120 --> 01:12:12.960]   out of the gate because Apple tried to push it as a fashion item. And that was hard to do to charge
[01:12:12.960 --> 01:12:21.200]   these deluxe versions with silver, gold, or thousands of dollars when the thing got replaced in a year.
[01:12:21.200 --> 01:12:29.680]   But I think that people are waiting for the augmented reality glasses. And Apple supposedly
[01:12:29.680 --> 01:12:36.080]   is working on a car. We don't know whether it's going to do the whole thing or do a system for the car.
[01:12:36.080 --> 01:12:45.760]   And we're holding our breath to see whether there will be that new device that we didn't know
[01:12:45.760 --> 01:12:54.480]   we absolutely had to have. But now we do. And in both those markets, there's existing competition
[01:12:54.480 --> 01:13:02.240]   to make the new new thing in those realms. Facebook just came out with a pair of glasses, which don't
[01:13:02.240 --> 01:13:10.480]   really have augmented reality in them. But they take pictures. And other places are working on
[01:13:10.480 --> 01:13:15.680]   the glasses that really take the screen and put it right in front of your eyes.
[01:13:15.680 --> 01:13:19.600]   Aren't those Facebook glasses terrifying? I think that's a...
[01:13:20.800 --> 01:13:25.840]   People can barely tell there's a camera. They look like Ray. What happens when Robert Scobble uses them?
[01:13:25.840 --> 01:13:31.520]   Yeah. I don't like the idea of a camera. There's cameras everywhere. Where do you go?
[01:13:31.520 --> 01:13:37.760]   I guess you're right. I can go to... I can get a camera that replaces this button and you
[01:13:37.760 --> 01:13:45.280]   will know it. I think we've passed the point of no return, which is bad. And we need to have
[01:13:46.000 --> 01:13:53.840]   some laws that say you can't do that. But in the absence of that, we need countermeasures.
[01:13:53.840 --> 01:13:58.480]   And I'm not sure what those are going to be. We have norms too. We have norms that say...
[01:13:58.480 --> 01:14:05.360]   I remember having a conversation with a New York Times columnist, and I'll leave unnamed for the
[01:14:05.360 --> 01:14:10.160]   moment, worried about Scobble with Google Glass. Oh my God, they're going to go in the
[01:14:10.160 --> 01:14:15.920]   men's room. And I said, "Nobody wants a picture of your job?" Norm does.
[01:14:15.920 --> 01:14:32.400]   Norms are easier to enforce, put that in quotes. If violating them, it makes you known as someone
[01:14:32.400 --> 01:14:40.880]   who violated them when it becomes invisible and the violation of the norm becomes kind of default.
[01:14:40.880 --> 01:14:45.360]   That's the more reason. We're going to take a little break. When we come back,
[01:14:45.360 --> 01:14:51.600]   Peter Teal, the topic. Great panel. I feel like we should talk about the future of journalism.
[01:14:51.600 --> 01:14:55.840]   I don't know. Would that be a mistake at this point, Jeff? You can talk about the death of magazines.
[01:14:55.840 --> 01:15:01.600]   All right. We'll get to that. The death of magazines. As the person who works for a magazine,
[01:15:02.560 --> 01:15:08.080]   I do that again. I just ended up paying another five bucks to subscribe to your newsletter just
[01:15:08.080 --> 01:15:11.840]   so I could read your articles. It's worth it. As a subscriber to Wired.
[01:15:11.840 --> 01:15:22.400]   I'm old-fashioned. But notice, I did not pay for the delivered Wired in my mailbox version. I just
[01:15:22.400 --> 01:15:28.000]   want the digital version. I still get magazines, but they're mostly a pain in the ass. They're
[01:15:28.000 --> 01:15:32.800]   mostly like, "Oh, now I have to do something with this." Like read it? That's a bit terrible.
[01:15:32.800 --> 01:15:36.320]   I read it online. I get the New Yorker, but I guess I read it online. I get the Atlantic,
[01:15:36.320 --> 01:15:42.400]   but I read it online. I don't need the paper version. I used to buy them by the pound double
[01:15:42.400 --> 01:15:47.840]   bag, dead Hudson. I haven't bought a magazine. Oh, yeah. Wasn't that fun? Going to the newsstands.
[01:15:47.840 --> 01:15:55.040]   Buy it all starts a weird arcane magazine. You go on a flight. You buy three magazines.
[01:15:55.040 --> 01:16:00.880]   Everyone in the plane, they be thumbing through it. There's a vanity fair, so not my bedside table.
[01:16:00.880 --> 01:16:05.280]   It's been there for about two weeks. Just folded up into the article I was going to read.
[01:16:05.280 --> 01:16:11.280]   I just sit in there kind of sad, lost. You get to buy guilt before it is now. That's all it is.
[01:16:11.280 --> 01:16:16.800]   Wired. We don't call ourselves Wired magazine. We're Wired. You're Wired.
[01:16:16.800 --> 01:16:23.120]   Yeah, it's just Wired. I buy my guilt by the pound. Our show today brought to you by
[01:16:23.120 --> 01:16:28.080]   podium talking about changing times these days. If you're a business, remember in the,
[01:16:28.080 --> 01:16:32.080]   I don't know, 20 years ago, if you'd have an answering machine, what kind of business
[01:16:32.080 --> 01:16:36.240]   doesn't have an answering machine, then you had to have a email, then you had to have a website.
[01:16:36.240 --> 01:16:41.600]   Okay, you want to know what you need today? You need text messaging. Text messaging is the key
[01:16:41.600 --> 01:16:46.240]   these days to staying in touch with your clients, your customers. Why? Because
[01:16:47.680 --> 01:16:53.680]   after a year in pandemic, we've kind of just gotten used to the new way of doing things.
[01:16:53.680 --> 01:17:00.640]   Curbside pickup from your favorite restaurant. I did a Zoom call with my doctor last week.
[01:17:00.640 --> 01:17:04.480]   Customers have grown to expect simpler ways of doing business.
[01:17:04.480 --> 01:17:10.000]   And no matter what your product, no matter what your business, I want you to know about podium.
[01:17:10.000 --> 01:17:15.680]   More than 90,000 local businesses of all sizes have turned to podium. With one location or 1,000,
[01:17:15.680 --> 01:17:21.280]   it doesn't matter. podium can help you stay ahead because the open rate for text messages
[01:17:21.280 --> 01:17:27.040]   is through the roof compared to any other thing. And I can tell you as a customer, I far prefer
[01:17:27.040 --> 01:17:33.760]   getting a coupon via text message, getting a suggestion for a review via text message.
[01:17:33.760 --> 01:17:38.000]   podium makes doing business as easy as sending a text. And when text get open,
[01:17:38.000 --> 01:17:41.040]   business gets done. You know who else likes podium? Your employees,
[01:17:41.680 --> 01:17:48.400]   because they can handle all of the communications with your customers in a single text inbox,
[01:17:48.400 --> 01:17:52.400]   offering a smoother experience for your customers. If you want to answer questions,
[01:17:52.400 --> 01:17:57.360]   send a text. If you want to collect reviews, the other day I left a place and I got a little
[01:17:57.360 --> 01:18:01.840]   text pop up and said, "How'd you like the food? Leave a review for us and help." And I did,
[01:18:01.840 --> 01:18:07.920]   because it was easy. I was there. I was on the phone. That's what podium can do. If you want
[01:18:07.920 --> 01:18:13.280]   a schedule appointment or schedule delivery, send a text. You can even collect payments with podium
[01:18:13.280 --> 01:18:20.320]   via text. You know, if you are a contractor, a home service provider, you need podium.
[01:18:20.320 --> 01:18:26.800]   Because, and this happened to me the other day, we broke a window. So what did I do? I texted a
[01:18:26.800 --> 01:18:32.960]   bunch of different glaziers. People fixed the window. The person whose refers to reply is way
[01:18:32.960 --> 01:18:38.480]   more likely to get the job. If you're on the ball, you got podium. It's easy. You can sell
[01:18:38.480 --> 01:18:43.200]   a car dealership, sold a $50,000 truck, and four text messages, podium customer.
[01:18:43.200 --> 01:18:50.400]   Lots of dealerships running profitable service centers. I now schedule my appointments in text
[01:18:50.400 --> 01:18:56.080]   messages to get my car serviced. Retailers are increasing revenue by allowing customers to shop
[01:18:56.640 --> 01:19:03.520]   via text message. And there's a dentist in New York City who got behind in his collections,
[01:19:03.520 --> 01:19:08.960]   had a million dollars in overdue collections. He sent everyone a text, a payment request,
[01:19:08.960 --> 01:19:15.680]   collected $700,000 in two weeks, 70%. Because it's just easier for people. It's not
[01:19:15.680 --> 01:19:21.440]   they're trying to skip out. They're just easier for people. Today's customers expect on-demand
[01:19:21.440 --> 01:19:26.160]   everything, even from local businesses. Stay ahead of the competition. Look, you got to check out
[01:19:26.160 --> 01:19:31.520]   the website. Free plans for growing businesses plus all the power a growing business needs to
[01:19:31.520 --> 01:19:39.520]   scale as you get big and you will get started free today. podium p o d i u m.com slash twit.
[01:19:39.520 --> 01:19:47.760]   This is this is the future. Try a demo. See why podium is trusted by thousands of businesses all
[01:19:47.760 --> 01:19:56.080]   over the country. P O D I U M dot com slash twit. We had a big week this week on the shows,
[01:19:56.080 --> 01:20:01.520]   including the surface event, the apple event. Why don't we, why don't we roll that tape? You got a
[01:20:01.520 --> 01:20:07.200]   little, we got a little video to show you today. Amazon announced in limited edition,
[01:20:07.200 --> 01:20:14.000]   $200 at $29.99. Echo studio featuring Billy Eilish's cover art for happier than ever.
[01:20:14.000 --> 01:20:23.520]   Oh, gosh. Like, cheers. This is Stacy's pick of the week. It is my all-ree, the chihuahua Amazon
[01:20:23.520 --> 01:20:33.600]   Echo. Wow. How about that? Previously on twit. Twit news. So this is this is the pro version of
[01:20:33.600 --> 01:20:40.640]   the surface. This is a portable workstation. Oh, look at that. No surface pro. I'm liking that.
[01:20:40.640 --> 01:20:45.440]   This is a pull forward display. Tech news weekly. We've got a lot of fun stuff to talk about this
[01:20:45.440 --> 01:20:52.800]   week, including tiny flying microchips and the team behind them. So there are principles in
[01:20:52.800 --> 01:20:59.120]   aerodynamics that scale nicely down as you reduce the mentions. But at some point, if you make
[01:20:59.120 --> 01:21:05.200]   these structures too small, then that flight dynamics kind of disappears and everything behaves like
[01:21:05.200 --> 01:21:12.000]   a sphere, essentially. Hands on tech. Is it possible to make a do-it-yourself repairable laptop that
[01:21:12.000 --> 01:21:19.600]   you'd actually want to buy? It is. Next, the framework on hands on tech. Windows weekly.
[01:21:19.600 --> 01:21:24.960]   I really like the duo too. I can't even believe I'm saying that. Me too. I went in there so
[01:21:24.960 --> 01:21:28.720]   skeptical and I went up to the table and he goes, "What do you want out of duo too?" I said, "I
[01:21:28.720 --> 01:21:33.200]   want it to be good. I just pre-ordered it." Did you? I hit the button.
[01:21:33.200 --> 01:21:39.600]   Twit. I know. For help with the technology addiction problem, call 1-800-Twit.
[01:21:39.600 --> 01:21:46.800]   I wish there were such a number. Well, we learned a lot this week why bumblebees can't fly
[01:21:46.800 --> 01:21:53.200]   because they're just big spheres. And the framework laptop, you wanted to talk about that, Dan, right?
[01:21:53.200 --> 01:22:00.560]   Do you have it? Did you get one of those? Yeah, it's amazing. I agree. It blows me away.
[01:22:00.560 --> 01:22:10.560]   First of all, it puts total lie to this notion that making something thin and relatively light
[01:22:10.560 --> 01:22:17.520]   means that you have to solder everything to everything else and make it upgradable and
[01:22:17.520 --> 01:22:26.480]   unrepairable. This thing is upgradable and repairable. And I think they're early on to something.
[01:22:26.480 --> 01:22:31.520]   I hope this is going to be the start of a trend because
[01:22:31.520 --> 01:22:42.880]   one thing I should say, I've been buying for a long time after I left the Mac behind. I've been
[01:22:42.880 --> 01:22:52.240]   buying ThinkPads and putting Linux on them and very happy. And one thing that Lenovo does
[01:22:52.240 --> 01:22:59.840]   that almost no other company can match is that I have a plan where if something breaks wherever
[01:22:59.840 --> 01:23:06.320]   I am in the world, they'll send somebody to where I am and fix it. That's just unbeatable. But I
[01:23:06.320 --> 01:23:16.080]   don't travel that much anymore. And this thing is just a breakthrough in modularity and upgradability.
[01:23:16.080 --> 01:23:23.280]   I, Corey, Dr. wrote a wonderful piece on Medium about this. I recommend everyone look at it.
[01:23:23.280 --> 01:23:28.880]   Yeah, that's Corey. Dr. was the one who told me to get ThinkPads and put Linux on them and buy the
[01:23:30.240 --> 01:23:36.480]   on-site repair. And I did that for years too. I agree. It's been great. I'm not sure I'm going to
[01:23:36.480 --> 01:23:42.320]   stop. And I differ with Corey on a couple of points he made in his piece. In fact, I'm going
[01:23:42.320 --> 01:23:50.800]   to write something up about it. But this is the cutting edge of something that I think we should
[01:23:50.800 --> 01:24:00.640]   encourage like crazy, which is the notion of making the hardware less of a thing that you have to
[01:24:00.640 --> 01:24:08.720]   throw away or give away that we don't have to use as much materials as we used to just
[01:24:08.720 --> 01:24:13.600]   drop in a new processor. And you know, at some point, even a new motherboard, if that's what it
[01:24:13.600 --> 01:24:18.960]   takes, but everything is modular in this thing. I just I'm blown away.
[01:24:18.960 --> 01:24:23.040]   And it runs Linux beautifully. That's the first thing I did. Even the fingerprint reader works with
[01:24:23.040 --> 01:24:30.800]   the Monjero Linux, which is great. Yeah, it's the the further I don't know which Linux you're using,
[01:24:30.800 --> 01:24:34.400]   I use Ubuntu just because it's because it's because it's so scary. I think. Yeah.
[01:24:34.400 --> 01:24:40.960]   And the are coming, you know, I'm one of the people Corey talked into doing all this for a long time.
[01:24:41.600 --> 01:24:51.040]   But the one thing I don't like about this computer is that I love the ThinkPad keyboard.
[01:24:51.040 --> 01:25:02.240]   And if someone creates a keyboard or they create one themselves that has manual mechanical mouse
[01:25:02.240 --> 01:25:08.960]   buttons, then everything will be basically perfect. The keyboard is replaceable. That's really going
[01:25:08.960 --> 01:25:15.680]   to be the test of all of this is will people make compatible modules or will framework stick around
[01:25:15.680 --> 01:25:20.720]   and make more modules? Right. Because the keyboard, the screen, everything is held together with
[01:25:20.720 --> 01:25:25.040]   magnets practically. And it's very easy to take apart. And you know, I don't know about you. I
[01:25:25.040 --> 01:25:31.360]   got the DIY version. So I had installed a hard drive, the RAM, the Wi-Fi radio, easy peasy. That was
[01:25:31.360 --> 01:25:37.680]   great. Yeah, it comes with one little screwdriver. Yeah, that's that's the tools that you need to
[01:25:37.680 --> 01:25:45.200]   open it and add stuff and and repair stuff. It's a it's it's a remarkable piece of engineering. I'm
[01:25:45.200 --> 01:25:51.440]   so impressed with it. In theory, even the CPU is upgradeable and replaceable because the motherboard
[01:25:51.440 --> 01:25:56.400]   can be removed. And again, that's gonna, I think, depend on framework or somebody else. I don't
[01:25:56.400 --> 01:26:01.600]   know frameworks published the schematics. That would be the way to do it. Make to make something
[01:26:01.600 --> 01:26:06.240]   that would fit and be compatible. But I that's exciting. I don't know that answer to that. 10 out
[01:26:06.240 --> 01:26:15.920]   of 10. I fix it on repairability. So no glue. Even the battery can be pulled out with that on. I
[01:26:15.920 --> 01:26:21.920]   replaced the battery on my Pixel 5 and all this glue, you have to peel peel out and so forth.
[01:26:21.920 --> 01:26:28.800]   Yeah, I would like to see framework to a phone. That would be interesting. A repairable phone.
[01:26:28.800 --> 01:26:33.280]   What a thought. You already had to replace the battery on your Pixel 5? Yeah, it's well,
[01:26:33.280 --> 01:26:39.760]   it's swole up. You can all swoled up and started the backster to come off. And I was talking about
[01:26:39.760 --> 01:26:47.280]   it. People said, stop using it, stop charging it. You could blow up. So I boarded for my fix it.
[01:26:47.280 --> 01:26:52.640]   They sent a replacement battery and they sent a kit and there's a video and they show you how
[01:26:52.640 --> 01:26:55.920]   to do it. And I thought, I should do this. If I'm gonna stand up for the right to repair,
[01:26:55.920 --> 01:27:02.880]   then I should do it. And I did and it was easy and it was fine. And it didn't blow up anymore.
[01:27:02.880 --> 01:27:08.880]   Yeah, I didn't realize Corey had written an article and he's switched to framework. That's
[01:27:08.880 --> 01:27:13.520]   awesome. That's really great. He and I got ours at about the same time, I think.
[01:27:15.440 --> 01:27:20.320]   Peter Teal, the art of the Teal. Best headline this week. Thank you very much,
[01:27:20.320 --> 01:27:30.240]   Stephen Levy. You're reviewing a new book by Max Chafkin, the contrarian. What do you think?
[01:27:30.240 --> 01:27:41.680]   Well, Max, you oversells it a little by trying to play up Teal's influence on Silicon Valley,
[01:27:41.680 --> 01:27:48.080]   making bigger what it is. But by and large, it's a fascinating biography of a guy who is important
[01:27:48.080 --> 01:28:00.160]   and a little terrifying in some areas. But another area is revealing about that strain of Silicon
[01:28:00.160 --> 01:28:11.280]   Valley, the ultra libertarian whose real allegiance is towards just the monopolies and accumulation
[01:28:11.280 --> 01:28:20.400]   of money, really. Teal, it's interesting. He's been very, very active of late in defense
[01:28:20.400 --> 01:28:26.640]   technology, the places he funds. Do we need to go backwards and actually say who he is to begin
[01:28:26.640 --> 01:28:32.160]   with? I could say early investor, if you watched the social network movie, you know, he was the
[01:28:32.160 --> 01:28:36.080]   early investor who gave the seed money to Mark Zuckerberg so that Facebook could start. But he
[01:28:36.080 --> 01:28:45.760]   also found a palantier, which is kind of a notorious semi-evils spy company, basically.
[01:28:45.760 --> 01:28:52.320]   He actually got through on the PayPal. He was involved in PayPal mafia too.
[01:28:52.320 --> 01:28:59.440]   Yeah. He actually helped fire Elon Musk from PayPal, which is something not many people can say.
[01:28:59.440 --> 01:29:05.840]   That's a claim to fame. The thing I think is most interesting is that Teal is basically
[01:29:05.840 --> 01:29:12.640]   unapologetic about saying, "Look, my philosophy is a company should become monopolies because
[01:29:12.640 --> 01:29:17.520]   then you don't have to wear a competition. Make as much money as you can. I'm going to put my
[01:29:17.520 --> 01:29:23.600]   money where my mouth is." We was a big supporter of Donald Trump early in the campaign in 2016
[01:29:23.600 --> 01:29:29.040]   because I had gathered. He felt like this guy would be friendly to monopolies.
[01:29:30.480 --> 01:29:39.600]   Also, the founders fund, which is Teal's VC firm, and it's where Palantier came from,
[01:29:39.600 --> 01:29:47.280]   obviously Teal was very involved in Palantier. They have another defense company. One of them I
[01:29:47.280 --> 01:29:52.480]   wrote about for Wired with Palmer Lucky, the virtual reality guy who was very similar in
[01:29:52.480 --> 01:30:02.560]   his philosophy. He's not a Bond villain kind of guy. He's a fun lover.
[01:30:02.560 --> 01:30:10.000]   He has a whole room dedicated to candy. I know that. I once went on a road trip to him
[01:30:10.000 --> 01:30:17.120]   to the Texas border to look at one of his installations of his technology. The first thing we did,
[01:30:17.120 --> 01:30:21.200]   we got out of the plane in El Paso, was went to a water burger. He's a real kind of sewer
[01:30:21.200 --> 01:30:29.600]   fast food. It's interesting. Not just Teal, but these other people who say that they're
[01:30:29.600 --> 01:30:37.600]   like super patriotic, these other people in the Trump sphere. He really is disdainful of the
[01:30:37.600 --> 01:30:47.200]   people at Google for bouncing a contract to the government on AI. It seems to me that these
[01:30:47.200 --> 01:30:52.240]   people are so patriotic. Why don't they pay their taxes? Why do they keep thinking of imaginative
[01:30:52.240 --> 01:30:58.400]   ways to avoid paying the taxes that would help the United States defend itself and pay for this
[01:30:58.400 --> 01:31:03.440]   technology? They're selling the United States. Teal is famous and the book gets into this for
[01:31:03.440 --> 01:31:10.720]   having this multi-billion dollar Roth IRA. This is something that was done to help people,
[01:31:10.720 --> 01:31:16.560]   of modest means. There's little retirement accounts for their own use. He figured out a way to
[01:31:16.560 --> 01:31:22.800]   twist it legally, I guess, but to make it worth billions of billions of dollars, which was not
[01:31:22.800 --> 01:31:30.400]   being changed right now, right now. You know what? No, no, actually, the keyword is on the keyword.
[01:31:30.400 --> 01:31:37.280]   I actually told my daughter to immediately open a Roth IRA because she doesn't make enough money
[01:31:37.280 --> 01:31:44.000]   to be, I think you have to be a make under 144,000. But you could put money in there after tax money
[01:31:44.000 --> 01:31:49.920]   in there and any appreciation can be withdrawn at retirement without tax. That's the whole point
[01:31:49.920 --> 01:31:55.520]   of a Roth IRA. The interesting thing he did was, if the reason why he put his PayPal stock in there,
[01:31:55.520 --> 01:32:03.200]   $1,700 worth of PayPal stock that is now worth more than $17 billion, I think.
[01:32:03.200 --> 01:32:12.960]   But that was completely legal. Do you think he's evil? I mean,
[01:32:12.960 --> 01:32:16.320]   does he think he's like a Bond villain? He's like, oh, I'm just going to decide I'm going to go on
[01:32:16.320 --> 01:32:22.080]   the dark side? Well, he has a philosophical basis that says, you know, this makes sense.
[01:32:22.080 --> 01:32:27.520]   Why shouldn't people try to get as rich as they can? Well, I think he's most evil when he secretly
[01:32:27.520 --> 01:32:36.720]   funded the Gawker lawsuit for revenge, for writing about his, you know, that he was a gay person.
[01:32:36.720 --> 01:32:41.920]   For outing. Really, you know, we didn't, it wasn't really in a closet. You know, it was one of those
[01:32:41.920 --> 01:32:47.120]   things that people around him knew about it. Anyone could find out about it, but they
[01:32:47.120 --> 01:32:55.520]   publicized it and kind of made fun of it. And he never forgot that. And he couldn't sue them for
[01:32:55.520 --> 01:33:01.040]   what they wrote about him, but he saw the whole Cogan suit as it means to do it. And he funded
[01:33:01.040 --> 01:33:07.600]   some other people. And he did that secretly. And a lot of people feel that if the jury had known
[01:33:07.600 --> 01:33:13.520]   that some secret of billionaire was funding the suit to close down the publication,
[01:33:13.520 --> 01:33:17.120]   things might have gone the other way in that lawsuit.
[01:33:17.120 --> 01:33:23.360]   Virginia Heffernan's review has this great quote from the book about him and Musk. Peter thinks
[01:33:23.360 --> 01:33:26.880]   Musk is a fraud at a Braggart. Musk thinks Peter is a sociopath.
[01:33:26.880 --> 01:33:30.400]   Okay, not a lot of love lost.
[01:33:34.720 --> 01:33:38.800]   Not that we should point out nothing Peter Thiel has done as illegal, including the raw
[01:33:38.800 --> 01:33:43.120]   fire. That's a good summary though. But that's a really good summary of those guys. I like that.
[01:33:43.120 --> 01:33:55.760]   I, it's hard. It's hard to say, I'm the kind of person that I don't want to say he's an evil person.
[01:33:55.760 --> 01:34:02.000]   Nobody, everybody in their own mind thinks they're justified in their beliefs, right? Nobody says
[01:34:02.000 --> 01:34:07.600]   I'm going to do the bad thing, the wrong thing. Does the does the minority leader of the Senate think
[01:34:07.600 --> 01:34:13.440]   that? Yes, really? Absolutely. He believes he's doing the right thing for the country. Of course,
[01:34:13.440 --> 01:34:19.600]   he does. And I think after he closed down Walker, he said, this is the greatest public service I've
[01:34:19.600 --> 01:34:28.960]   ever done. Yeah. No, no one's a villain in their own story. So I'm just, and it's not like he's
[01:34:28.960 --> 01:34:35.120]   committed any crime. You know, we might say he's reprehensible, but he's not criminal.
[01:34:35.120 --> 01:34:42.720]   As Michael, it's your standard today. That's famously a long time ago. The scandal's not what's
[01:34:42.720 --> 01:34:50.480]   illegal. The scandals was legal. So that's a very good point. And if that Roth IRA loophole exists,
[01:34:50.480 --> 01:34:56.880]   I mean, to let's be fair, Thiel put a valueless asset in there because you can't put a super
[01:34:56.880 --> 01:35:02.160]   valuable asset in it. He must have thought, well, this is going to appreciate this would be a good
[01:35:02.160 --> 01:35:07.760]   place to stick it in case it does so I can get the money out without tax. But it was a completely
[01:35:07.760 --> 01:35:13.440]   legal somehow he was under the income cap. I guess he decided not to take any salary.
[01:35:13.440 --> 01:35:16.960]   That's what your standard is. Roth, the show today, you know, is well, it's not illegal.
[01:35:16.960 --> 01:35:21.280]   Well, that what that I guess to Dan's point about civics.
[01:35:22.640 --> 01:35:28.720]   If the real place to go, if this stuff is to say, let's, well, let's make it illegal then.
[01:35:28.720 --> 01:35:34.240]   We shouldn't have a computer tool that will have taxes. No, he's doing it. What his point of view is
[01:35:34.240 --> 01:35:40.640]   I'm going to do everything I can that's legal to maximize my profit. Yeah. I think it's a failure.
[01:35:40.640 --> 01:35:48.880]   It's a there's our failure in this country to get across and the behavior like that is not
[01:35:48.880 --> 01:35:56.480]   Patreon. It's anti social. Well, we had a president who basically
[01:35:56.480 --> 01:36:01.040]   bragged that he wasn't paying taxes while he complained and complained and complained
[01:36:01.040 --> 01:36:06.400]   we weren't spending enough money on defense. I feel that people should be shamed if they
[01:36:06.400 --> 01:36:10.880]   go to great. But Stephen, how do you do that then? So the shareholders of
[01:36:12.640 --> 01:36:20.640]   Twitter, say to Jack, we're going to we're going to you have a fiduciary duty to us
[01:36:20.640 --> 01:36:24.320]   to maximize your profit. And if you don't and you're not a public benefit corporation,
[01:36:24.320 --> 01:36:27.600]   and you just decide that you're going to pay more taxes because you want to,
[01:36:27.600 --> 01:36:32.960]   that doesn't wash in our current structure. Now you want to change capitalism, okay,
[01:36:32.960 --> 01:36:36.800]   but in the structure of where it exists, it is up to the risk. I think Leo's point is right.
[01:36:36.800 --> 01:36:42.400]   Don't blame the company, blame the politicians. And when it comes to these international deals,
[01:36:42.400 --> 01:36:49.680]   the double Dutch sandwiches, blame the diplomats. No, you know, you know, you know, full well,
[01:36:49.680 --> 01:36:56.880]   Jeff, the capitalism does not demand that the leaders of the company do anything possible.
[01:36:56.880 --> 01:37:01.600]   That's a theory that's gained traction. We all go to accountants and say, I don't want to pay
[01:37:01.600 --> 01:37:08.400]   more taxes than I have to. Everybody does that. Yeah, we don't hire lawyers to figure out ways
[01:37:08.400 --> 01:37:13.840]   where we could pay nothing for billions of dollars. Well, it's probably prudent also to point out
[01:37:13.840 --> 01:37:19.600]   the reason those laws exist is because the same people paid as much money as they could to Congress
[01:37:19.600 --> 01:37:26.000]   members. Exactly. To get those laws in place. That's where the the the
[01:37:26.000 --> 01:37:31.040]   maybe start reality, maybe start with campaign finance reform, maybe start with taking the money
[01:37:31.040 --> 01:37:37.840]   out of politics, because those laws exist for that entirely for that reason. The double Dutch
[01:37:37.840 --> 01:37:41.440]   sandwich doesn't exist. And there's nothing. Somebody says it'll be good for the country.
[01:37:41.440 --> 01:37:48.320]   It exists because we're not talking about it. Yeah, we're not talking about a company.
[01:37:48.320 --> 01:37:53.360]   We're talking about Peter Thiel and what he's done in the imaginative way. He's done, you know,
[01:37:53.360 --> 01:38:01.440]   to avoid paying billions of dollars in taxes at the same time. You know, he touts being a patriot
[01:38:02.800 --> 01:38:07.920]   for building up our defense capabilities and helping the government surveil people.
[01:38:07.920 --> 01:38:14.000]   Palmer, the thing that you visited that Palmer Lucky built was a surveillance system on the
[01:38:14.000 --> 01:38:19.920]   border, right? It was designed to support the wall. Yeah, it was a smart wall, so to speak.
[01:38:19.920 --> 01:38:27.200]   And I have to say, it was an unbelievably fun trip. It was almost like
[01:38:27.200 --> 01:38:33.920]   Hudders Thompson, going to Texas, right? Yeah, we went there. We went there when this ranch
[01:38:33.920 --> 01:38:39.840]   they had this amazing history where Texas Rangers had kind of a border war,
[01:38:39.840 --> 01:38:47.360]   you know, like background of the turn of the century. And, you know, how, you know,
[01:38:47.360 --> 01:38:52.080]   the great characters. And we were way in the middle of nowhere. I mean, the closest,
[01:38:52.080 --> 01:38:58.400]   you know, thing to where we were, what maybe about 40 miles away was this little Prada art
[01:38:58.400 --> 01:39:04.720]   installation from near Martha, you know, we posed and let's not forget a water burger.
[01:39:04.720 --> 01:39:10.880]   Well, that was on the way. Yeah. Yeah. Very important. We stayed the night in the little
[01:39:10.880 --> 01:39:17.440]   place called Van Horn, Texas. And I wound up there a couple months later watching a launch of Blue
[01:39:17.440 --> 01:39:23.520]   Origin. So I think I've probably been the only journalist ever to go to Van Horn, Texas, twice
[01:39:23.520 --> 01:39:30.800]   in three months, between different stories. Somebody, somebody you see a little shatter there.
[01:39:30.800 --> 01:39:38.320]   Go ahead, Dan. Somebody used the word shame in this conversation. That was me.
[01:39:38.320 --> 01:39:45.040]   Yeah, I was just thinking, you can't really shame people who don't have any shame.
[01:39:46.320 --> 01:39:53.840]   It's it's they're proud of the stuff that we think is shameful. They're actually,
[01:39:53.840 --> 01:40:02.480]   they're thinking, gotcha. That's that's their response to the idea you can't possible.
[01:40:02.480 --> 01:40:11.920]   Well, if they're if they're not, you know, greeted or, you know, snuff by the people around them,
[01:40:11.920 --> 01:40:17.360]   you know, that's different now, the people who say gotcha are surrounded by other people like that.
[01:40:17.360 --> 01:40:20.480]   I mean, we have to change the mentality of it. Things can't change.
[01:40:20.480 --> 01:40:24.160]   That's just normal setting. Yes. I mean, it's the same as saying I get people yelling at me when I
[01:40:24.160 --> 01:40:29.120]   say that it's time to shun and shame the anti-vaxxers. And we'll always try to convince them. No,
[01:40:29.120 --> 01:40:33.920]   we've given plenty of time to convince them. And and all people get mad at me. And I don't care.
[01:40:33.920 --> 01:40:38.640]   So that's that's how we set norms in society is by negotiating them. It is at some point
[01:40:38.640 --> 01:40:41.920]   by shunning and shaming people so that the price becomes too high.
[01:40:41.920 --> 01:40:47.600]   But there has to be for people like this, some sort of nihilism where they've decided everybody
[01:40:47.600 --> 01:40:52.560]   is pretending there's good and bad, but really everybody's out for themselves.
[01:40:52.560 --> 01:40:57.680]   And so I'm not doing anything everybody else is doing. There has to be some
[01:40:57.680 --> 01:41:03.280]   some sort of mental gymnastics that they're performing. So they have, I don't think they have
[01:41:03.280 --> 01:41:08.560]   shame. You know, I think it Donald Trump's a good example. I think it heard him deeply that the
[01:41:08.560 --> 01:41:14.320]   elites of New York never accepted him, but I don't think he was shamed by them. No,
[01:41:14.320 --> 01:41:19.040]   if he had been, I didn't see any modification to the behavior.
[01:41:19.040 --> 01:41:25.360]   I don't think he showed any shame. And I doubt Peter Thiel feels ashamed of anything.
[01:41:25.360 --> 01:41:31.840]   Well, the biography kind of gets into the early days. And if you want to play a cracker barrel
[01:41:31.840 --> 01:41:38.960]   psychologist, you could say that he was bullied as a kid because he was kind of like a weird kid
[01:41:38.960 --> 01:41:50.560]   just love chess. And probably the people around him picked up that he was gay. And
[01:41:50.560 --> 01:41:57.120]   were mean to him. They bullied him. And so he buried shame. He said, I'm not going to be
[01:41:57.120 --> 01:42:03.680]   ashamed of myself. You know, and then he goes to Stanford. And at Stanford, there's, you know,
[01:42:03.680 --> 01:42:09.200]   at the time he went, there was a group of people, it wasn't the majority, but it was enough of a
[01:42:09.200 --> 01:42:15.280]   community of of right wingers and right wingers who really enjoyed making, you know, owning liberals,
[01:42:15.280 --> 01:42:23.440]   let's say, you know, and baiting them that where he was accepted within that world there. So there
[01:42:23.440 --> 01:42:29.840]   you go. You know, so those tendencies is, you know, very right wing libertarianist
[01:42:29.840 --> 01:42:37.920]   kind of tendencies got rewarded from the people around him. And you know, and you want to say that
[01:42:37.920 --> 01:42:43.120]   helps explain it. I don't know. I mean, he's also incredibly brilliant person. I mean,
[01:42:43.120 --> 01:42:49.520]   I hadn't had much conversation with him, but I've met him a few times and super, super smart guy.
[01:42:49.520 --> 01:42:55.760]   What can you say? All I can say is I used to play a lot of chess, tournament chess at that age.
[01:42:55.760 --> 01:43:03.760]   And I was not shunned. Playing chess by itself is not necessarily shunning. Although I guess
[01:43:03.760 --> 01:43:07.920]   I gather he's pretty good. You talk about him playing blindfold chess at a founders conference,
[01:43:07.920 --> 01:43:14.880]   which is not. Yeah, playing against the calls and the co-founder of Stripe who with no slouch and
[01:43:15.920 --> 01:43:21.040]   intelligence himself. Yeah. I'll quote Haffron again for once a quick second. And some of your
[01:43:21.040 --> 01:43:27.680]   listeners may find this deeply offensive. Young Teal had the usual Dandruff club hobbies. He
[01:43:27.680 --> 01:43:35.360]   played Dungeons and Dragons, Red Tolkien and H to the SATs. The story of my life. But you don't
[01:43:35.360 --> 01:43:40.800]   have to be nihilist. Just because of that. I'm just saying, I think you can go in for right
[01:43:40.800 --> 01:43:44.800]   anyways. I'm not gay. So maybe that was maybe that was what put him over the top. I don't know.
[01:43:44.800 --> 01:43:48.560]   Maybe he was shunned. Where did he grow up? What was he grew up in Texas? Where did he grow up?
[01:43:48.560 --> 01:43:53.200]   Well, it was New Jersey, California, California.
[01:43:53.200 --> 01:43:56.720]   All right. Well, why do you want to get a problem with Jersey? Yeah. Zoomed the guys.
[01:43:56.720 --> 01:44:01.840]   Yeah. Well, I'm just saying, what is this? You got a problem? A lot of people grew up in
[01:44:01.840 --> 01:44:04.880]   Jersey. You're a little voice. I'm just saying. That explains everything.
[01:44:04.880 --> 01:44:08.960]   All right. Let's take it.
[01:44:08.960 --> 01:44:14.240]   It's interesting. At Facebook, there's this great contrast between Mark Zuckerberg, who
[01:44:14.240 --> 01:44:25.120]   among his peers, he could be fairly popular. He wasn't like the outcast you see in the social
[01:44:25.120 --> 01:44:33.760]   network, but not an overwhelmingly popular guy with charisma. And Chris Cox, who is one of the
[01:44:33.760 --> 01:44:40.000]   top executives of Facebook, who is a super smart guy, but with the life of the campus on Stanford,
[01:44:40.000 --> 01:44:45.680]   sort of like the anti-heal. He played in a reggae band.
[01:44:45.680 --> 01:44:59.200]   He was athletic. And just the charms, everyone. So he's like the person some people told me that
[01:44:59.200 --> 01:45:05.200]   like Mark would really like to be Chris Cox. Oh, that's interesting. Not anymore, right?
[01:45:05.200 --> 01:45:10.320]   Didn't Cox go up. No, no, he's back. Oh, yeah. He's back.
[01:45:10.320 --> 01:45:17.680]   Okay. They keep pulling me in, I think is the quote. Let's take a little break. We got a great
[01:45:17.680 --> 01:45:24.400]   panel. I still, I've got to find some way to get them to start talking though. They're so reserved.
[01:45:24.400 --> 01:45:31.600]   It's Dan Gilmore from Arizona State at the Walter Cronkite School. Great to have you,
[01:45:31.600 --> 01:45:36.960]   Stephen Levy, legendary slow journalist at editor at large at Wired.
[01:45:36.960 --> 01:45:42.080]   You're quite a slow. You said it. I remember at a food camp. You said,
[01:45:42.080 --> 01:45:48.400]   I do slow journalism. You're not that slow. You actually, you're writing a lot more than you
[01:45:48.400 --> 01:45:54.320]   used to. Not talking about intellect here. No, like slow food. I think it was like
[01:45:54.320 --> 01:45:59.520]   the idea was like slow food. I take my time. You're like a good, like a fine barbecue.
[01:45:59.520 --> 01:46:04.240]   Yeah. Yeah. Yeah. You got a big green egg out there.
[01:46:04.240 --> 01:46:10.800]   I love my big green egg. We could, let's, we'll talk about in the next segment is Barbies.
[01:46:10.800 --> 01:46:16.720]   Sure. Jeff Jarvis is also here. You know, Jeff from this week in Google, buzzmachine.com.
[01:46:16.720 --> 01:46:22.960]   And of course, the Craig Newmark, graduate school of journalism at the City University of New
[01:46:22.960 --> 01:46:27.200]   York. I showed it. I brought to you by another friend of the show, Kevin Rose,
[01:46:27.200 --> 01:46:33.360]   the dark tipper from Tech TV. And of course, Kevin is a smart investor. He founded Dig,
[01:46:33.360 --> 01:46:39.200]   invested early in Twitter and many other companies, worked at Google Ventures. He's now
[01:46:39.200 --> 01:46:44.480]   true ventures. This man knows finance. He also is a damn fine podcaster. You may remember
[01:46:44.480 --> 01:46:49.680]   Dig Nation, one of the most successful of all time, podcasts of all time. He's got to know what
[01:46:49.680 --> 01:46:55.280]   it's called, modern finance. The world of investments has changed Bitcoin, NFTs,
[01:46:55.280 --> 01:47:00.240]   robo investors at the tip of everyone's tongue. How do you know what's right for you? Modern
[01:47:00.240 --> 01:47:08.160]   finance helps to demystify crypto, decentralized finance and more. Kevin is a perfect guy to host
[01:47:08.160 --> 01:47:13.760]   this listed as a top 25 angel investor by Bloomberg, one of the top 25 most influential people on the
[01:47:13.760 --> 01:47:21.440]   web, according to Time Magazine. His job, demystify crypto, the world of NFTs without dumbing it down.
[01:47:21.440 --> 01:47:25.760]   He's so good at that. In fact, I didn't know anything about NFTs until it was actually their
[01:47:25.760 --> 01:47:32.640]   debut episode, which I think started at the beginning, where they explain NFTs. There's two
[01:47:32.640 --> 01:47:38.160]   shows on the feed for modern finance, the weekly consensus episodes that explore the weekly news,
[01:47:38.160 --> 01:47:43.760]   distill it into digestible information. And then the second show is deeper interviews with crypto
[01:47:43.760 --> 01:47:50.560]   founders, NFT artists, the top experts in this field, entrepreneurs. It's a great way to learn about
[01:47:50.560 --> 01:47:57.200]   it. Even traditional finance hacks, everything. Don't let your crypto guy friend be the life of the
[01:47:57.200 --> 01:48:01.120]   party, but listening to modern finance, you'll feel well equipped to discuss and understand the
[01:48:01.120 --> 01:48:06.240]   crypto and the NFT landscape. You'll feel informed about your investments. Don't miss out on the
[01:48:06.240 --> 01:48:12.480]   next big thing in crypto or NFTs. Join Kevin Rose on the modern finance podcast every week so you
[01:48:12.480 --> 01:48:17.680]   don't miss a beat. The financial landscape is harder than ever to navigate. You don't have to do
[01:48:17.680 --> 01:48:24.240]   it alone. Download and subscribe to modern finance wherever you listen to podcasts. Look at all
[01:48:24.240 --> 01:48:29.280]   these up. He's been just cranking him out so much stuff. I'm a little behind. I got to catch up.
[01:48:29.280 --> 01:48:34.960]   Modern finance, go to modern dot finance or subscribe wherever you listen to podcasts.
[01:48:35.520 --> 01:48:42.480]   Don't be the last person on the next train out. Listen to modern finance and get ahead of the
[01:48:42.480 --> 01:48:49.680]   future of finance. Kevin's great. He's also very entertaining. Love him. Thank you, Kevin. Modern
[01:48:49.680 --> 01:48:53.920]   finance. Everybody should listen to it, right? And we'll get Kevin back on Twitch soon. You're
[01:48:53.920 --> 01:48:58.080]   talking about Peter Thiel being outed. And I forgot that we, oh, and Thomas, the guy who was
[01:48:58.080 --> 01:49:03.600]   writing for Gawker when, when who outed Peter Thiel has been on the show many times. He's like,
[01:49:03.600 --> 01:49:09.920]   he's one of our contributors. Love him. Great guy. I don't, I don't know if he's happy about the
[01:49:09.920 --> 01:49:17.440]   fall of Gawker, although Gawker's back, isn't it? I don't know. Is it the same? No, no, no, no
[01:49:17.440 --> 01:49:24.160]   ownership. Are they still kind of, you know, not not as, you know, tough as the old Gawker.
[01:49:25.840 --> 01:49:33.760]   Oh, that's too bad. Although I see they have a column called Canole Angus. So I don't know what
[01:49:33.760 --> 01:49:39.760]   they'll they try. I'm too hard. They try a little too hard. This thing's terrible.
[01:49:39.760 --> 01:49:47.680]   Oh, here's one. Mayim Bialik is destroying jeopardy. You could have written that one, Jeff.
[01:49:51.920 --> 01:49:58.160]   Are you over her? Is she, is he full-time host now? No, no, she's going to share the hosting for
[01:49:58.160 --> 01:50:02.160]   a while while they figure out what to do, which should be to fire all the Saudi executives who
[01:50:02.160 --> 01:50:06.720]   screwed this up. Boy, did they screw it up? Boy, did they screw it up? But, you know,
[01:50:06.720 --> 01:50:12.800]   I think it's a testament to how good Alex Trebek was. That's, there's something about that show.
[01:50:12.800 --> 01:50:17.600]   It's a hard show to do. And he's very hard, very hard to replace. Somebody suggested,
[01:50:17.600 --> 01:50:22.880]   actually, this is from the Gawker story. And I agree, a comedian like Mark Marin would be perfect.
[01:50:22.880 --> 01:50:26.240]   Marin's just got that right attitude for the whole thing.
[01:50:26.240 --> 01:50:34.000]   I don't know. Yeah, my problem with her is she's doing the brain supplement commercials.
[01:50:34.000 --> 01:50:39.840]   And though she, she and her children did get the vaccination for COVID, she's been
[01:50:39.840 --> 01:50:46.480]   back skeptical otherwise. And so you have a show that is based on supposedly fact and knowledge.
[01:50:46.480 --> 01:50:50.240]   And this is, who are you going to have, or is it going to give me all kinds of trouble?
[01:50:50.240 --> 01:50:55.840]   You're going to get tons e million dollars. Well, she's beloved because of the Big Bang theory,
[01:50:55.840 --> 01:51:00.720]   right? She was, I liked her on the Big Bang theory, but as a spokesman for truth, not so much.
[01:51:00.720 --> 01:51:07.600]   You know, okay, she's studying neuroscience, but she's an actor. Let's face it. Yeah,
[01:51:07.600 --> 01:51:14.560]   that's, that's her real job, not neuroscience. You want to watch as a raven takes out a Google
[01:51:14.560 --> 01:51:18.240]   video? You want to put this up there? You want to see this? I know this is, this is Jeff's,
[01:51:18.240 --> 01:51:24.640]   this is Jeff's story. So Google has been forced to ground its home delivery service
[01:51:24.640 --> 01:51:30.160]   due to bird attacks. Here's an Australian raven,
[01:51:31.040 --> 01:51:40.160]   attacking a drone delivering coffee. This is, there's the drone. Somebody say, oh, look,
[01:51:40.160 --> 01:51:49.360]   cool. There's a Google drone delivering coffee and then wait for it. Suddenly out of the blue,
[01:51:49.360 --> 01:51:55.920]   ravens are scary. Here it comes. What does a raven think it's, he knows what the sound on to
[01:51:55.920 --> 01:52:04.560]   because I think the raven is battling with the rotor. Why, why raven? Oh, and there goes the coffee.
[01:52:04.560 --> 01:52:15.920]   According to ABC News Australia, we've identified some birds in the area demonstrating territorial
[01:52:15.920 --> 01:52:22.800]   behaviors and swooping at moving objects. So, you know, I always thought the whole idea of
[01:52:22.800 --> 01:52:27.920]   drone delivery was a little far-fetched. I think, I think when Jeff Bezos opened that door and
[01:52:27.920 --> 01:52:34.080]   Charlie Rose said, what? I think he was being taken for a ride and by a drone, apparently.
[01:52:34.080 --> 01:52:40.880]   Let's see. News consumption. One little, one little update here just, just found it, just put up.
[01:52:40.880 --> 01:52:45.200]   Yes. I don't care. You've been, I care, but at the bottom of the rundown. So Facebook now is
[01:52:45.200 --> 01:52:50.960]   putting up their answer to the Wall Street Journal. I haven't chance to go through this.
[01:52:51.760 --> 01:52:55.200]   Casey, you were asking this. They're tweeting it, right? Yeah.
[01:52:55.200 --> 01:53:05.040]   They did a post on it. It looks like that they've done their own cherry picking of the research to,
[01:53:05.040 --> 01:53:12.160]   you know, come out against the Wall Street Journal's cherry picking. And most of the replies to their,
[01:53:12.160 --> 01:53:18.720]   you know, the tweet announcing it, we're saying, well, why don't you just release all of it so
[01:53:18.720 --> 01:53:23.520]   we can just show exactly the moral of the story. Yeah. Exactly.
[01:53:23.520 --> 01:53:29.920]   So now I just wanted to just add that. Well, if you're Annie Facebook, you'll be glad to see this
[01:53:29.920 --> 01:53:36.480]   story from CNBC, which is by Alec Cantrowitz, who's also a regular on the show. Apple's power move
[01:53:36.480 --> 01:53:44.400]   to kneecap Facebook advertising is working. Of course, Apple added with iOS 14 point something,
[01:53:45.680 --> 01:53:50.240]   a little pop up that says, do you want to let this ad track you across this app,
[01:53:50.240 --> 01:53:56.000]   track you across other apps? And of course, everybody says no. Facebook, of course, the biggest
[01:53:56.000 --> 01:54:04.640]   victim of this. Alex interviewed a number of people who had been buying Facebook ads who are,
[01:54:04.640 --> 01:54:10.560]   well, he talks to a guy named Aaron Paul is a something brand new job description, a performance
[01:54:10.560 --> 01:54:18.080]   Facebook marketer. Whatever that is, Paul has a company called Carousel. He says,
[01:54:18.080 --> 01:54:22.800]   we've moved from spending millions of dollars every day on Facebook to just a few hundred thousand
[01:54:22.800 --> 01:54:29.840]   dollars, because we don't have any information about what we're buying anymore. We're just completely
[01:54:29.840 --> 01:54:38.320]   running blind, he said. Now, my book, making the job tougher for performance Facebook marketer
[01:54:38.320 --> 01:54:44.080]   seems like probably a pretty good idea. I mean, I could see why he might not be too happy about
[01:54:44.080 --> 01:54:50.960]   it. He's moved his ad budget elsewhere, according to Alex Snapchat and TikTok. But also, he says,
[01:54:50.960 --> 01:54:59.920]   silent killers like email. Oh, good more spam. On Twitter, Facebook marketers discussing Apple's
[01:54:59.920 --> 01:55:06.640]   changes almost unanimously agreed they're going to move off Facebook too. Could be a lot of money.
[01:55:07.520 --> 01:55:17.760]   Fleeing Facebook. Do you think Tim Cook, this was Tim Cook's plan? Oh, yeah. He didn't like Facebook,
[01:55:17.760 --> 01:55:24.320]   or he doesn't like spying. No, it was actually, it's part of it's no, it's also like Murdoch,
[01:55:24.320 --> 01:55:29.360]   when you fail at advertising, right, it's good for Apple. You find an alternative strategy,
[01:55:29.360 --> 01:55:33.040]   number one, and number two, you find whatever power you have to disadvantage your competitors,
[01:55:33.040 --> 01:55:38.320]   who still depend upon advertising, which both of them don't. And I'm not equating Cook to Murdoch,
[01:55:38.320 --> 01:55:44.160]   because Murdoch to me is the gross devil of all devils. But I am saying as a strategy,
[01:55:44.160 --> 01:55:47.840]   it's kind of the opposite of the feature as a bug, the failure as a feature.
[01:55:47.840 --> 01:55:55.200]   Cantrowitz quotes, the CEO of 365 Holdings, a company that owns e-commerce brands and
[01:55:55.200 --> 01:56:00.720]   advertises extensively online. Kelsey Leerich says, "I don't think Tim Cook is this benevolent
[01:56:00.720 --> 01:56:06.320]   privacy person. They're making strategic decisions Apple is that affect the market cap,
[01:56:06.320 --> 01:56:09.840]   not practical decisions that serve their customers or serve their users."
[01:56:09.840 --> 01:56:23.200]   I think you can make a pretty good argument that giving users of iOS devices a way to say no to
[01:56:23.200 --> 01:56:29.040]   being spied on, that's more than just strategy. Now the question I have is,
[01:56:29.040 --> 01:56:40.080]   how long Apple's purity on privacy? As we know, Tim Cook is going to live forever and never,
[01:56:40.080 --> 01:56:46.400]   ever change his mind. So what's the next crowd going to do?
[01:56:47.040 --> 01:56:53.520]   Apple's assembling one hell of a database about users of its ecosystem.
[01:56:53.520 --> 01:57:00.560]   And has gone into some advertising itself at this point.
[01:57:00.560 --> 01:57:06.160]   When I use Apple News, their product is laden with ads. Are those ads?
[01:57:06.160 --> 01:57:10.560]   Are they coming from the publishers? They're coming from Apple. I think Apple's selling ads.
[01:57:11.840 --> 01:57:21.440]   So I just think we should maybe say good idea for this, but the idea that users have the choice.
[01:57:21.440 --> 01:57:29.840]   But I think the notion that Apple is going to be pure for a long time to come is kind of unlikely.
[01:57:29.840 --> 01:57:37.520]   It's not a great idea to outsource our privacy enforcement to a two trillion dollar company.
[01:57:39.120 --> 01:57:42.640]   That's a good way to put it. Yes. That's a very good way to put it.
[01:57:42.640 --> 01:57:49.440]   Who should we outsource it to? Well, how about the people we elect to make laws?
[01:57:49.440 --> 01:57:55.200]   Government is the worst threat to privacy, not as great as protector.
[01:57:55.200 --> 01:58:03.120]   What is there anything? Assuming that both of you are right, is there anything an individual can do
[01:58:03.120 --> 01:58:09.680]   to protect their privacy themselves? Don't say it at some level. I know that's clear that I'm being
[01:58:09.680 --> 01:58:15.280]   smart ass. But at some level, if you put anything out there, once you give it up, I wrote a book
[01:58:15.280 --> 01:58:19.280]   about this. Does everybody plug your books? I don't plug mine. Nobody bought it. So what the hell?
[01:58:19.280 --> 01:58:24.960]   Called public parts where as soon as you tell someone something else, you have lost control of
[01:58:24.960 --> 01:58:29.120]   that. It's not yours anymore. You may think it's yours. But in that transaction of telling
[01:58:29.120 --> 01:58:33.120]   someone else, whether it's one person or whether it's the world on Facebook, you've lost control of
[01:58:33.120 --> 01:58:37.360]   it. And you now depend upon the ethics of that other person and how they treat it.
[01:58:37.360 --> 01:58:45.040]   The one thing that Facebook actually doesn't use is the content of stuff that you write in your
[01:58:45.040 --> 01:58:52.160]   comments on Facebook. They know what you look at on the web. They know what you look at at the
[01:58:52.160 --> 01:58:58.800]   newsfeed. If you stop something on the newsfeed, just for like a couple seconds, they know that
[01:58:58.800 --> 01:59:06.720]   person's isn't it? I mean, it's the stuff you do just doing stuff is what they collect. And that's
[01:59:06.720 --> 01:59:11.920]   why it's so dangerous. And the stuff you do not only inside of Facebook, but outside of Facebook.
[01:59:11.920 --> 01:59:20.000]   And it's not just Facebook doing that. One thing, and maybe we could segue into that New York Times
[01:59:20.000 --> 01:59:28.640]   story about how Facebook is promoting itself on Facebook. And then something at times is doing
[01:59:29.040 --> 01:59:36.720]   but you read these stories in the New York Times about how Facebook knows about its users. And then
[01:59:36.720 --> 01:59:40.800]   kind of like maybe the 17th paragraph of the story, there's a little parentheses saying the
[01:59:40.800 --> 01:59:47.680]   New York Times actually does this too. I love that. And they kind of go on. Yeah. Oh, by the way,
[01:59:47.680 --> 01:59:54.960]   we collect information and use it to advertise. But yeah, I'm. Yeah, there's the conflict of
[01:59:54.960 --> 02:00:00.960]   interest in big journalism in its coverage of technology that is
[02:00:00.960 --> 02:00:12.720]   mostly not disclosed. And when it is closed is in paragraph, you know, 1700 is a big problem. And
[02:00:12.720 --> 02:00:21.920]   the other problem, well, and other problem is that a lot of tech, a lot of journalism about
[02:00:21.920 --> 02:00:31.920]   technology in big media is not well informed about how technology works. So that's a second thing. And
[02:00:31.920 --> 02:00:36.960]   to answer a question, you just asked a minute ago, Leo, what can we do about it? Well, there's
[02:00:36.960 --> 02:00:45.440]   a fair amount. I mean, I've I locked down as much as I can in my browsers. I block trackers.
[02:00:46.640 --> 02:00:58.640]   I don't use apps if on the phone, if there's a mobile web version. And I use I do Facebook on
[02:00:58.640 --> 02:01:06.000]   my phone in a lockdown mobile browser. It's not perfect as Steven pointed out. That means that,
[02:01:06.000 --> 02:01:11.360]   you know, when I slow down and look at something, they know that and that sort of thing. But
[02:01:12.400 --> 02:01:21.520]   there are there are things we can do that are at least somewhat protective. And we just we need more
[02:01:21.520 --> 02:01:31.120]   countermeasures. And we need them to be available to us from these companies. I would
[02:01:31.120 --> 02:01:39.600]   I think that this is something Congress should work on is basically say, you got to provide
[02:01:40.160 --> 02:01:47.280]   opt out. And in fact, it should all be opt in. And we're going to be waiting a while. But this stuff
[02:01:47.280 --> 02:01:53.840]   is going to get worse and worse unless we do something. Yeah, Corey Doctor has called the use
[02:01:53.840 --> 02:02:00.720]   of ad blockers, the largest consumer boycott in history. I think the awareness of privacy tools
[02:02:00.720 --> 02:02:06.320]   has grown intensely. I mean, our audience, of course, you know, they're all over it. But I
[02:02:06.320 --> 02:02:12.640]   think even normal people are now using privacy, you know, protection in a lot of different ways.
[02:02:12.640 --> 02:02:16.560]   It's become a matter of course. I don't know how effective it is.
[02:02:16.560 --> 02:02:23.680]   Companies like Google are very good at doing an end around on all these browser fingerprinting
[02:02:23.680 --> 02:02:32.080]   and things like that are the ad tech industry's way of fighting back. But there it is an escalating
[02:02:32.080 --> 02:02:37.760]   war. My students, I ask them every every time I teach a media literacy course about what they're
[02:02:37.760 --> 02:02:46.080]   doing because I give them lots of tools or pointers. And every year, they're more savvy about what's
[02:02:46.080 --> 02:02:54.080]   happening before I start telling them things. And I think that's a heartening trend. Yeah.
[02:02:54.080 --> 02:03:00.080]   Yeah, I mean, I started a degree in engagement journalism, social journalism. And this year,
[02:03:00.080 --> 02:03:04.400]   more than ever, the students are more hostile to social media. But the conversation we've had
[02:03:04.400 --> 02:03:10.480]   is see the trees for the forest. You may you may dislike and find it dislike Facebook as a company
[02:03:10.480 --> 02:03:14.720]   or Twitter as a company or tuck tic-tock as a company. But the people who are there
[02:03:14.720 --> 02:03:22.800]   are the ones who you want to end up serving and you've got to go to where they are. And so
[02:03:23.760 --> 02:03:29.920]   turn your your aspect ratio around when it comes to how you deal with people who are
[02:03:29.920 --> 02:03:34.080]   those two billion people, you can ignore them all you can't. You've got to figure out a way to do it.
[02:03:34.080 --> 02:03:38.880]   You were talking, Stephen, this tweet probably summarizes what you were talking about from
[02:03:38.880 --> 02:03:45.280]   Daphne Keller from the Stanford Cyber Policy Center. You could write a dissertation on these
[02:03:45.280 --> 02:03:51.360]   two news stories alone. One, the New York Times covering Facebook's efforts to shore up its reputation.
[02:03:51.360 --> 02:03:57.600]   And then two, a press release from the New York Times on September 11th. They formed a new team
[02:03:57.600 --> 02:04:03.200]   to help ensure confidence in its journalism and broaden its reach behind beyond coastal hubs
[02:04:03.200 --> 02:04:08.720]   and across political lines to win the world. This always drives us crazy is is is why don't they
[02:04:08.720 --> 02:04:13.520]   trust us? We'll just explain more about how we work. You should trust us. You should trust us.
[02:04:16.800 --> 02:04:21.520]   Everybody advertises nothing. I don't have I mean, I'm I live on advertising. So I have
[02:04:21.520 --> 02:04:26.320]   any problem with that. You should all advertise more. If you want people to trust you, you should
[02:04:26.320 --> 02:04:31.200]   advertise on our shows. That's nice. Look, what do we say? Podcasts you love for people you trust.
[02:04:31.200 --> 02:04:36.160]   Look, you know, come on. People trust the times, don't they?
[02:04:36.160 --> 02:04:42.000]   No, it's the newspaper of record. Last thing I used to.
[02:04:42.000 --> 02:04:49.440]   Yeah, I guess. Yep. Yep. It's for their 230 coverage. Yeah. Google is buying a New York City
[02:04:49.440 --> 02:04:56.000]   office building for $2.1 billion, just as everybody's headed home. I guess they're not heading home.
[02:04:56.000 --> 02:05:03.520]   Google must know something we don't know. They need office space. Do you know where this property is,
[02:05:03.520 --> 02:05:07.840]   Jeff? It's on the West Side next to the river, but I'm not sure. This story.
[02:05:07.840 --> 02:05:15.600]   Yeah, it's down kind of towards canal stream on the West Side, that little area where Penguin
[02:05:15.600 --> 02:05:24.880]   used to be. Yeah, so it's maybe about a mile south of where the Chelsea headquarters is,
[02:05:24.880 --> 02:05:30.640]   the previous $2 billion building. Did they buy a whole bunch of stuff at the Hudson Yards too?
[02:05:30.640 --> 02:05:36.240]   Do they buy Facebook? Facebook. Oh, right. Facebook.
[02:05:36.240 --> 02:05:40.960]   What are the trends? This is a new building. It's being built. It's a new one. Yeah.
[02:05:40.960 --> 02:05:47.520]   So, but I'm curious what the office space trends are in New York. It had to have taken a big hit
[02:05:47.520 --> 02:05:54.240]   during the, absolutely, during 2020 and at least part of this year. I'm just wondering if
[02:05:55.520 --> 02:06:06.080]   it's underwater, what the overall? Well, I mean, it's greatly reduced. I literally live across
[02:06:06.080 --> 02:06:12.880]   the street from where Facebook is now. And I could look down to this giant room where they used to
[02:06:12.880 --> 02:06:18.800]   have their big meetings and no one's there. That's how you get your scoops.
[02:06:18.800 --> 02:06:25.360]   Oh, I know. A pair of binoculars and a parabolic microphone.
[02:06:25.360 --> 02:06:34.000]   Strong Wi-Fi, you know. Google says also cross stream AOL.
[02:06:34.000 --> 02:06:39.440]   Oh, you know, you're said. Nothing you want to know about that. No. Yeah. Yeah. But, you know,
[02:06:39.440 --> 02:06:45.600]   but I think it's a long-term bet. It shows they think they're going to be around through all their
[02:06:45.600 --> 02:06:54.320]   history. Google has had difficulty getting real estate for people, you know, who they have been
[02:06:54.320 --> 02:07:00.400]   hiring. And obviously at this moment, that's not a pressing need. They've got this giant headquarters
[02:07:00.400 --> 02:07:05.760]   that they've been building in Mountain View, which is going to take a long longer to fill.
[02:07:05.760 --> 02:07:11.280]   But they have utter confidence that in a few years, they'll be in that situation again.
[02:07:11.280 --> 02:07:18.560]   And they can drop $2 billion on a building in New York City. And sometime during this decade,
[02:07:18.560 --> 02:07:25.040]   maybe not until 2026, 2027, we'll be saying that building's packed. We need more space.
[02:07:25.040 --> 02:07:31.040]   Yeah. Google also says they'd like to own the space because they like to reconfigure it as needed.
[02:07:31.040 --> 02:07:39.040]   And remember the silly video that we showed of the inflatable privacy wall that took about half an
[02:07:39.040 --> 02:07:47.920]   hour to inflate. They're trying all sorts of things to see, you know, what works. But, and I think this
[02:07:47.920 --> 02:07:52.400]   is interesting because I don't think employees agree with this. But a lot of companies still have
[02:07:52.400 --> 02:07:56.960]   this notion that you got to have employees in the office to collaborate, to work together,
[02:07:56.960 --> 02:08:05.520]   to crack the whip over. And employees are going, yeah, no. There's a very, I think there's an
[02:08:05.520 --> 02:08:10.800]   interesting trend going on. Well, a perfect example, there's 70
[02:08:10.800 --> 02:08:17.680]   ships sitting outside a long beach right now that can't be unloaded because they're not enough
[02:08:17.680 --> 02:08:23.120]   longshoremen. They're not, they're not enough truck drivers. People are not going back to work.
[02:08:23.120 --> 02:08:27.520]   There's a strike in effect going on there, saying we're not going to work in those crap jobs anymore.
[02:08:27.520 --> 02:08:34.400]   I don't know. You left me for reading the book, The Box, which was all about how shipping changed.
[02:08:34.400 --> 02:08:38.400]   It's 70 container ships floating outside a long beach right now.
[02:08:38.400 --> 02:08:44.720]   It's crazy why we can't get on. It's more pleasant to work in a Google office and to move big boxes
[02:08:44.720 --> 02:08:49.600]   around. Well, that's true. Yeah, the downside of working in a Google office in California is a
[02:08:49.600 --> 02:08:56.640]   lot of people have to sit on a bus for an hour, hour and a half, you know, using the Wi-Fi,
[02:08:57.680 --> 02:09:04.400]   you have to go back and forth. But in New York City, most of the Google employees are probably
[02:09:04.400 --> 02:09:10.080]   short subway ride away. So I think the one up 12 was filling it out. It's actually kind of fun
[02:09:10.080 --> 02:09:13.920]   to work at Google if you don't have to handle it, hang it in the lab bag, commute.
[02:09:13.920 --> 02:09:19.360]   But there's a little bit of a play revolt going on, both at Google and at Apple,
[02:09:19.360 --> 02:09:24.720]   partly because of workplace issues as much as anything else.
[02:09:24.720 --> 02:09:31.920]   But and they offer in the Bay Area, they offer and I'm sure elsewhere, the most luxurious form
[02:09:31.920 --> 02:09:37.520]   of commuting there is, which is a bus. The buses have nice leather with Wi-Fi. I mean, it's like,
[02:09:37.520 --> 02:09:46.480]   unlike the rest of the commuters in the world who really, really love driving 45 minutes to an
[02:09:46.480 --> 02:09:52.800]   half-day way and getting nothing done except listening to bad radio. This is like,
[02:09:52.800 --> 02:09:58.640]   they miss this so much. It's been a while since you've communicated Dan, I think. I don't think
[02:09:58.640 --> 02:10:03.520]   this is the best way to go. I mean, I'm in long gray. I need a sarcasm emoji to go with.
[02:10:03.520 --> 02:10:08.080]   But Google only does that because they have to, right? Because they're trying to attract
[02:10:08.080 --> 02:10:13.520]   employees. I mean, I still think there's a move not to go back to work. I think a lot of people,
[02:10:13.520 --> 02:10:18.480]   you know, engineers, especially engineers, they can work at home. They don't want to...
[02:10:18.480 --> 02:10:22.880]   Child care is like an issue. Yeah. That's another shortage.
[02:10:22.880 --> 02:10:27.760]   Yeah. That's the one thing. Remember when Google tried to do their own,
[02:10:27.760 --> 02:10:36.240]   daycare? They wound up spending millions of dollars in this thing and hiring these
[02:10:38.080 --> 02:10:44.480]   child psychologist experts to be the teachers. And it was the Santa Cruz and it was a kind of
[02:10:44.480 --> 02:10:52.480]   a crazy situation that kind of blew up. Yeah. How long before the next evil genius says,
[02:10:52.480 --> 02:10:58.080]   "I was raised at Google Child Care?" That explains everything. That's all you need to know.
[02:10:58.080 --> 02:11:03.200]   It was a modest story. I'm going to take a break. We're going to wrap this up. If there's a story I
[02:11:03.200 --> 02:11:07.600]   missed, something you guys want to talk about, you want to share your... Something you're working on,
[02:11:07.600 --> 02:11:13.840]   please do. But first, I want to tell our fabulous audience about stamps.com.
[02:11:13.840 --> 02:11:19.920]   This is such a brilliant thing. Here's the thing. Here's the thing you can say,
[02:11:19.920 --> 02:11:23.200]   "I'm not going to do anymore. I'm not going to go to the post office anymore.
[02:11:23.200 --> 02:11:29.520]   I don't need to go to the post office anymore. I love the post office. I love the guys. But frankly,
[02:11:29.520 --> 02:11:36.000]   I got everything I need at my desk with stamps.com. Stamps.com lets you mail and ship
[02:11:36.560 --> 02:11:41.920]   right from your computer. You don't need a postage meter special ink or anything like that.
[02:11:41.920 --> 02:11:46.000]   The printer and the computer, you have all you need. You'll save time and you'll save money
[02:11:46.000 --> 02:11:52.960]   with stamps.com. And by the way, not just on US Postal Service packages letters, but on UPS as
[02:11:52.960 --> 02:11:58.480]   well. They've just added UPS. This is huge. Stamps.com has been around since 1998, an
[02:11:58.480 --> 02:12:03.360]   indispensable tool, nearly one million businesses, including ours. We've used them for almost a decade.
[02:12:04.800 --> 02:12:10.400]   We love stamps.com. Whether you're in office setting invoices, if you're an Etsy seller, an eBay or
[02:12:10.400 --> 02:12:15.760]   an Amazon seller, forget the wrapping it up with brown paper and twine and licking stamps and putting
[02:12:15.760 --> 02:12:22.800]   on the top. That does not project professional. Your packages can look so professional thanks to
[02:12:22.800 --> 02:12:28.000]   stamps.com. And you'll save time and money. You don't have to fill out any form. Stamps.com will
[02:12:28.000 --> 02:12:33.040]   do it for you automatically. You don't have to fill out the buyer's address. Stamps.com will pull
[02:12:33.040 --> 02:12:38.800]   that from whatever software you're using. You don't have to put your return address either.
[02:12:38.800 --> 02:12:43.200]   They'll print it on there nice, even on an envelope, but nice with the logo of your company and everything.
[02:12:43.200 --> 02:12:48.480]   Stamps.com is amazing. And it doesn't, you don't have to get anything. You can do it. You could
[02:12:48.480 --> 02:12:53.200]   before the show's over. Be up and running, printing official US postage for any letter,
[02:12:53.200 --> 02:12:58.000]   any package, anywhere you want to send. You'll get discounts. You cannot get at the post office
[02:12:58.000 --> 02:13:03.680]   on postage and shipping. You'll get discounts on UPS as well. Once your mail's ready, schedule a
[02:13:03.680 --> 02:13:08.640]   pickup. You could drop it off if you want. No traffic, no lines. It is amazing. Now, stamps.com
[02:13:08.640 --> 02:13:14.240]   has added the new rate advisor tool so that you can use it to compare shipping rates, to compare
[02:13:14.240 --> 02:13:18.320]   timelines, to find the best option. They've always been really good at saying, you know, this could
[02:13:18.320 --> 02:13:23.920]   be media mail. It's saving you money. This rate advisor tool is awesome. If you haven't tried
[02:13:23.920 --> 02:13:29.440]   them yet, I don't know why not. We've been customers and partners since 2012. I'm a big fan. We've got
[02:13:29.440 --> 02:13:34.640]   the USB scale. We have a really good offer. You save time and money with stamps.com. There's no
[02:13:34.640 --> 02:13:40.160]   risk. We've got a great promo code, TWIT. You get a special offer. It includes a four-week trial,
[02:13:40.160 --> 02:13:46.240]   free postage, a digital scale. There's no long-term commitment, no contract. Here's what you do.
[02:13:46.240 --> 02:13:52.800]   You go to stamps.com. Up in the right there, you'll see a microphone. Click that. Type in TWIT. I
[02:13:52.800 --> 02:13:56.000]   guess you can just type it right next to the microphone now. That's nice. Then,
[02:13:56.000 --> 02:14:05.920]   hit return. You'll get an amazing deal. $110 value. Stamps.com. Promo code TWIT. You're going to love it.
[02:14:05.920 --> 02:14:13.120]   Never go to the post office again. If you're not using it, I don't know why. It's a must. Stamps.com.
[02:14:17.120 --> 02:14:24.720]   CIA and NSA used ad blockers just to add to that conversation. This is a story from Vice and
[02:14:24.720 --> 02:14:30.800]   Motherboard. The intelligence community has deployed ad blocking technology according to a
[02:14:30.800 --> 02:14:37.680]   letter sent by Congress and shared with Motherboard. If it's good enough for the FBI, the DEA, the DHS,
[02:14:37.680 --> 02:14:44.160]   the DOD, and the CIA and NSA, it's good enough for me. Just don't block our ads.
[02:14:45.760 --> 02:14:52.160]   The part of the reason they do it is because of malware in the ads. These automated
[02:14:52.160 --> 02:15:00.080]   ad sales technologies aren't able to screen for malware. That's a good reason to block them.
[02:15:00.080 --> 02:15:06.000]   Anything else? I missed that we wanted to talk about. I eat it out like this one, but I found this
[02:15:06.000 --> 02:15:11.760]   just interesting. The Amazon high-tech hair salon. Yes. It opened in May. But if you've seen this
[02:15:11.760 --> 02:15:15.280]   reports from there, I had no idea. We talked about it when they opened it.
[02:15:15.280 --> 02:15:20.160]   It's a Paris or somewhere? I think it's London.
[02:15:20.160 --> 02:15:23.680]   That's like Paris, but in English.
[02:15:23.680 --> 02:15:32.400]   With no gas and nothing on the grocery shelves now. Here's an article. I went to Amazon's high-tech
[02:15:32.400 --> 02:15:38.080]   hair salon and virtually dyed my hair pink and then got the best haircut I've ever had.
[02:15:38.640 --> 02:15:46.080]   Rites Kate Duffy for Business Insider. $72. Well, okay. Exchange rate.
[02:15:46.080 --> 02:15:49.760]   Yeah, it's only five pounds. But there you go.
[02:15:49.760 --> 02:15:54.160]   Nonsurprisingly, it's using virtual stuff. So she was able to take a picture of herself
[02:15:54.160 --> 02:15:58.640]   and then see herself with pink hair. The real question is, why Amazon? Why?
[02:15:58.640 --> 02:16:00.400]   That's a black question.
[02:16:00.400 --> 02:16:04.960]   What is this a business that they want to start? No.
[02:16:06.720 --> 02:16:10.800]   I don't think. I think they're trying out things. She's sitting in the chair and the
[02:16:10.800 --> 02:16:17.040]   stylist is talking about products and she uses her finger to point at the products to learn about
[02:16:17.040 --> 02:16:22.960]   them. I think it's captive time too. It's an advertising opportunity. Oh, maybe.
[02:16:22.960 --> 02:16:32.400]   So I think a little bit cynically. Yeah. It's inscrutable. Jeff Bezos is inscrutable.
[02:16:34.320 --> 02:16:39.520]   But he's taking the other important story of the week. He's taking Captain Kirk into space.
[02:16:39.520 --> 02:16:44.640]   Oh, how much can you hate him this week? To boldly split and infinitive in space.
[02:16:44.640 --> 02:16:48.800]   Well, not space. Short, near space. Space adjacent. Space adjacent. Yeah. Yeah.
[02:16:48.800 --> 02:16:55.760]   Suburbs thereof. William Shatner will be the oldest man ever to go into near space. 90 years old.
[02:16:55.760 --> 02:17:01.360]   I don't know if he's paying for it. Apparently there is a documentary.
[02:17:03.440 --> 02:17:07.120]   Documentary team is paying for it. Or maybe Jeff said, you know, it's good for us to.
[02:17:07.120 --> 02:17:14.400]   Oh, yeah. It's good PR. So, you know, the last one, so the last launch, which I went to back to Van
[02:17:14.400 --> 02:17:21.040]   Horn for that, they have the oldest person ever to in space is great woman, Wally Funk. Yeah.
[02:17:21.040 --> 02:17:29.360]   And then the youngest person who is the son of a hedge fund guy who bought his son a ticket to
[02:17:29.360 --> 02:17:35.680]   space, right? Not not as heartwarming a story. But now's is they're going to top the oldest person.
[02:17:35.680 --> 02:17:39.920]   Now they got to find an even younger person. Oh, they put a baby in space, maybe. Eventually,
[02:17:39.920 --> 02:17:43.920]   they're going to get to that. Or Palmer Lucky, because he's kind of a man child.
[02:17:43.920 --> 02:17:48.960]   He could go. Did you wear a cowboy hat, Stephen? When you when you went to
[02:17:48.960 --> 02:17:54.640]   Fanhole? No, I didn't. No, I didn't. I'll let you mine. I have a really good. I want to picture that.
[02:17:55.520 --> 02:17:59.600]   Everybody in the capsule apparently brought their cowboy hats, which was very. They gave them
[02:17:59.600 --> 02:18:06.160]   out to Jeff Adam and then they were the little boots. Well, you another way that you can spy on
[02:18:06.160 --> 02:18:12.240]   Facebook or maybe Facebook and spy on you. There's the new portal, the new Facebook portal. This
[02:18:12.240 --> 02:18:19.520]   one's portable portal. The portable go $199. It's got a battery in it. So we didn't talk about the
[02:18:19.520 --> 02:18:26.880]   head of Facebook hardware. But it's going to replace shrimp, right? My drift.
[02:18:26.880 --> 02:18:33.280]   Shrimp is so yeah, tell us, you know the inside the ins and outs. So it is really interesting because
[02:18:33.280 --> 02:18:40.480]   Bos Andrew Bosworth was an early Facebook employee is sort of Facebook's utility man.
[02:18:40.480 --> 02:18:44.880]   When you know, there's a trouble area, he goes in there and he's very controversial character. He
[02:18:44.880 --> 02:18:51.920]   can be very like gruff and kind of a bull in a China shop and some of his offend people. He
[02:18:51.920 --> 02:18:57.920]   wrote this memo that talked about the ugly truth of Facebook is yeah, we might like, yeah,
[02:18:57.920 --> 02:19:02.640]   some people might die, but we're good for the world. And he said, the guy who said Facebook is a car.
[02:19:02.640 --> 02:19:08.400]   No, that was Adam Mosseri, the head of Instagram. He said, cars kill people. Facebook seems to like
[02:19:08.400 --> 02:19:12.960]   analogizing what they do to everyday household objects. Remember they had an ad that said
[02:19:12.960 --> 02:19:18.960]   Facebook is like a chair. Remember that? Yeah, yeah. Well, Facebook is like Facebook. We have to deal
[02:19:18.960 --> 02:19:25.440]   with that. But, uh, but Bos, you know, got the job when they were struggling with mobile. He took
[02:19:25.440 --> 02:19:30.080]   over the team that did mobile advertising was really successful. And he was about to go off on his
[02:19:30.080 --> 02:19:34.880]   honeymoon before he did that. And, you know, Zuckerberg talked him out of that and then, uh,
[02:19:34.880 --> 02:19:38.480]   talked him out of the honeymoon. Well, they postponed it for a year.
[02:19:39.760 --> 02:19:46.160]   And then he got when things after the polymer lucky thing of things were really in trouble,
[02:19:46.160 --> 02:19:51.600]   virtual reality of Facebook and, um, and the hardware division, he pulled that together. So,
[02:19:51.600 --> 02:20:01.040]   now he's got in control of that. And, you know, um, uh, the CTO who was in charge of all the AI, um,
[02:20:01.040 --> 02:20:07.200]   who very famously reveals the New York Times that he was often in tears with Facebook that,
[02:20:07.600 --> 02:20:15.120]   um, now he's getting out of dodge and, you know, it's poor Bos is going to have to, um, you know,
[02:20:15.120 --> 02:20:21.760]   ball the trail of tears into that office. Shrep is only 46, but I imagine he has acquired a little
[02:20:21.760 --> 02:20:27.120]   bit of filthy liquor. So he probably is just quitting to spend more time with his money. I would guess.
[02:20:27.120 --> 02:20:32.160]   Bos is, you know, pretty well off to let me tell you that's got to be hard. You know, when you got
[02:20:32.160 --> 02:20:38.080]   a bunch of millionaires to work in, you know, long hours to keep them, keep them in line.
[02:20:38.080 --> 02:20:43.840]   Um, all right. So yeah, thank you for the update on the palace intrigue. Shrep,
[02:20:43.840 --> 02:20:49.680]   Shrep as they call him will continue to advise the company in a part time senior fellow role.
[02:20:49.680 --> 02:20:55.840]   He'll be means he won't be leaking. He'll be eating lunch on the roof. The other senior fellows
[02:20:55.840 --> 02:21:00.560]   and, uh, yeah, won't be leaking. He'll be helping with recruiting technical talent
[02:21:00.560 --> 02:21:07.040]   and developing the company's artificial intelligence initiatives. Yeah. He's still under contract.
[02:21:07.040 --> 02:21:12.640]   He worked for Mozilla. I didn't know that before he went to Facebook. Any other stories I missed?
[02:21:12.640 --> 02:21:19.280]   Big stories. I want to put an applaud for something coming out tomorrow. All right. Um,
[02:21:19.280 --> 02:21:24.640]   you know, I've been doing a series of conversations with this guy named Larry Brilliant. There's an
[02:21:24.640 --> 02:21:30.400]   epidemiologist. Larry Brilliant. Yeah. Who helped eradicate smallpox many years ago. And he's one
[02:21:30.400 --> 02:21:36.240]   of the best people to talk about about COVID. The first conversation we had in March 2020 was
[02:21:36.240 --> 02:21:43.520]   the second most read story ever in Wired and was Condien S, most read story in 2020. We've had
[02:21:43.520 --> 02:21:50.480]   some subsequent conversations and we had another one. There it is. Um, out tomorrow, which I, uh,
[02:21:50.480 --> 02:21:57.600]   think, uh, people can benefit from reading. He's always, you know, right on the mark. I will read
[02:21:57.600 --> 02:22:02.240]   it. I'd be very interested. He is a, you know, a public health expert and he will be very
[02:22:02.240 --> 02:22:07.520]   interesting. I'm sure to hear. He was a consultant on the movie, uh, Contagion. That's right. Yeah.
[02:22:07.520 --> 02:22:13.360]   Is he optimistic or pessimistic at this point? Yeah. Give us a leak here. He's okay. I mean, he is
[02:22:13.360 --> 02:22:19.680]   ultimately, you know, he always sticks to his guns that we will get past this.
[02:22:19.680 --> 02:22:26.560]   But the frustration he has that we haven't been able to get past it and why, uh, is palpable. And
[02:22:26.560 --> 02:22:34.080]   my first question to him was, have we blown it? And his answer is, uh, we've blown it several times
[02:22:34.080 --> 02:22:39.760]   and we talk a little bit about how we're blowing it now. Yeah. Even in March 2020, he said we were
[02:22:39.760 --> 02:22:48.720]   blowing it. Well, that was, that was the, the, the Trump version. Yeah. Yeah. He said, we need
[02:22:48.720 --> 02:22:54.400]   lots more testing. Did we ever get all those tests? I don't think so. No. Whatever happened to that.
[02:22:54.400 --> 02:22:58.880]   I can't shut it, shut down manufacturing because we didn't think we needed. Oh, we don't need tests.
[02:22:58.880 --> 02:23:03.200]   So we don't need PPE. We don't need tests. We got the vaccinations. What do we need?
[02:23:03.760 --> 02:23:09.600]   You know, who would believe a cult of COVID would emerge? No kidding.
[02:23:09.600 --> 02:23:13.520]   Anything on per minute kidding. It's the IQ test we need more than the PCR tests.
[02:23:13.520 --> 02:23:17.520]   Barry Diller is going to buy Meredith.
[02:23:17.520 --> 02:23:24.320]   No, so this was my magazine reference. Personally, my, my world's collide.
[02:23:24.320 --> 02:23:28.480]   Entertainment Weekly, the magazine I started part of Meredith soon to be under Barry Diller.
[02:23:28.480 --> 02:23:31.280]   Brides, which I used to work with. Believe it or not, a cutting ass.
[02:23:31.840 --> 02:23:34.800]   He does such a great job with Newsweek. Oh, God.
[02:23:34.800 --> 02:23:35.200]   Exactly.
[02:23:35.200 --> 02:23:42.080]   About.com, which I worked with at the New York Times is under Diller and all comes together in a
[02:23:42.080 --> 02:23:48.720]   very weird amount. When Meredith bought Time Inc and then sold off parts of it, Time and
[02:23:48.720 --> 02:23:52.880]   Sports Illustrated and so on, but it was, they were the brilliant marketing company and they were
[02:23:52.880 --> 02:23:58.080]   going to be the future of magazines. And then not so much, $2.5 billion to Barry Diller. And
[02:23:58.080 --> 02:24:01.600]   then he'll do what he does to it. The magazine is kind of just go.
[02:24:01.600 --> 02:24:09.920]   It's like a, like an episode of Succession. It's like he's the old guy who hasn't figured
[02:24:09.920 --> 02:24:16.880]   out that magazines are dead yet. Except Wired, student support. Wired, great magazine. Love it.
[02:24:16.880 --> 02:24:24.960]   Online. It's not a magazine. It's Wired. It's Wired. It's Wired. Yes. We are brand.
[02:24:25.760 --> 02:24:32.880]   The new address for it. It's not a magazine. When I was at Conde, I tried to argue
[02:24:32.880 --> 02:24:39.280]   when they went through one other change. And I said, I actually wrote a memo suggesting that
[02:24:39.280 --> 02:24:47.680]   we re-title it, "Unwired." Wired is the last technology magazine still standing pretty much.
[02:24:47.680 --> 02:24:53.760]   Yeah. They've all disappeared. Actually, I have to say, Wired is doing pretty well. We've got a lot
[02:24:53.760 --> 02:25:00.000]   of readers. We picked up and we have a subscription business that does really well.
[02:25:00.000 --> 02:25:06.560]   You can't read. You don't get my newsletter, my weekly newsletter, unless you're a subscriber.
[02:25:06.560 --> 02:25:16.160]   That's right. And as an extra punishment, we often pay wallet. So if we go to the column,
[02:25:16.160 --> 02:25:20.480]   the newsletter, you get a little thing saying, "Well, you have to subscribe and you read it."
[02:25:20.480 --> 02:25:24.000]   But it's only $5 if you follow that link. For a whole year.
[02:25:24.000 --> 02:25:32.320]   For a year, including the newsletter, the print magazine, and unlimited content on the web.
[02:25:32.320 --> 02:25:35.040]   I keep forgetting and I subscribe every month because I feel like,
[02:25:35.040 --> 02:25:43.920]   it's only $5. It must be monthly. Yeah. That's like $1,12 or even less of a sub stack,
[02:25:43.920 --> 02:25:48.000]   of a single sub stack. Yeah. We charge $7 a month for Club Tuit.
[02:25:49.280 --> 02:25:54.560]   You're putting me to shame. Anything, Dan, anything I missed, anything you want to plug,
[02:25:54.560 --> 02:26:00.640]   what are you working on? I'm not working on anything particular, but I do think the
[02:26:00.640 --> 02:26:10.480]   something that is worth mentioning is the infamous NSO group, Pegasus Spyware,
[02:26:10.480 --> 02:26:15.440]   was found on the several phones of a Hungarian journal. So it just happened to be looking into
[02:26:16.000 --> 02:26:28.320]   the affairs of the leader of Hungary who's moving fast toward China level dictatorship.
[02:26:28.320 --> 02:26:39.040]   It's yet another issue that politicians, I think, actually like the fact that this stuff exists.
[02:26:39.040 --> 02:26:45.280]   I don't think that they really are against it. We have to find ways to fight back.
[02:26:46.240 --> 02:26:50.640]   Well, that's an excellent point. An NSO group claims they don't sell to
[02:26:50.640 --> 02:26:56.000]   totalitarian regimes, but as far as we can tell every single example of discovering
[02:26:56.000 --> 02:27:02.640]   their spyware and iPhones is for back reign, is for our Hungary, it's for totalitarian regimes.
[02:27:02.640 --> 02:27:08.880]   It's just a pure coincidence that it ends up on journalists and activists and human rights
[02:27:08.880 --> 02:27:13.840]   people's phones. It's just a total of them. It's not our intent. We didn't think so.
[02:27:14.720 --> 02:27:21.920]   We didn't plan it that way. Yeah, actually, Apple, right before iOS 15, last week, 14.8 came out
[02:27:21.920 --> 02:27:30.400]   to patch a Pegasus zero-click exploit that went right through the Apple Blastor that was supposed
[02:27:30.400 --> 02:27:37.920]   to keep those non-click acts away. So even Apple is scrambling to keep up with these guys.
[02:27:37.920 --> 02:27:43.200]   The iMessage architecture is kind of bad. They really have to fix that.
[02:27:43.280 --> 02:27:50.000]   Yeah. Thank you. It's so great to have all three of you. Really an honor and a privilege for me
[02:27:50.000 --> 02:27:56.320]   to be able to talk to all three of you. Dan Gilmore, thank you for being here. Arizona State
[02:27:56.320 --> 02:28:02.800]   University is lucky to have you at the Walter Cronkite School. DanKilmore.com. I'm going to have
[02:28:02.800 --> 02:28:07.440]   to go back and read my copy, read the media, and find out what you warned us about because it
[02:28:07.440 --> 02:28:12.160]   happened whatever it was. I think it happened. Remind me when you read it. I'm proud.
[02:28:12.640 --> 02:28:21.040]   I told you, people. Thank you for being here, Dan. Thank you, Stephen Levy. I've always been one
[02:28:21.040 --> 02:28:26.480]   of my heroes. I love every book you write. I read every book you write. I'm proud to have them.
[02:28:26.480 --> 02:28:31.280]   I even paid five bucks just to read you on Wired. Thank you. Editor at Large at Wired.
[02:28:31.280 --> 02:28:36.080]   Jeff Jarvis, of course, you'll be back. Will you be back on Thursday? Yes, I'll be back on Thursday.
[02:28:36.080 --> 02:28:40.720]   I'll be back on Thursday. Thursday, Wednesday. I'm sorry. Wednesday. Yes. She's got an old move.
[02:28:40.720 --> 02:28:44.320]   I didn't move this shit. I know where I can move you in Florida.
[02:28:44.320 --> 02:28:48.400]   I was just there. Good. Is it nice? The food good? Yeah. Yeah.
[02:28:48.400 --> 02:28:53.600]   They walk in. They walk in at every meal. That's nice. Okay. They have a happy hour once a week.
[02:28:53.600 --> 02:29:01.280]   Not long from now, I'm afraid. Tell me about it. It happens fast. Jeff Jarvis, Buzz Machine.
[02:29:01.280 --> 02:29:04.560]   Wait a minute. I'll do the whole thing. Director of the Townite Center for Entrepreneurial and
[02:29:04.560 --> 02:29:08.720]   Journalism at the Craig Newmark Graduate School of Journalism at City University of New York.
[02:29:08.720 --> 02:29:16.320]   Frank Sinatra called him a bum. He is, of course, the esteemed JJ. Thank you, Jeff.
[02:29:16.320 --> 02:29:21.680]   Thank you, everybody. Thank you, man. Thank you, Stephen. We do this week in tech. Rarely do we
[02:29:21.680 --> 02:29:27.120]   have such an esteemed panel. I have to say it was really fun. But we try every Tuesday,
[02:29:27.120 --> 02:29:32.960]   every Sunday, rather 2 p.m. Pacific, 5 p.m. Eastern time, 2100 UTC. Although I think,
[02:29:34.160 --> 02:29:39.680]   I wish we were in Samoa. They've abandoned daylight saving time. I don't know. When do we change
[02:29:39.680 --> 02:29:44.640]   after Halloween? We got another month. But I think summertime is ending in some jurisdictions.
[02:29:44.640 --> 02:29:50.400]   So we are currently at 2100 UTC. We'll just leave it for that. You can do the math.
[02:29:50.400 --> 02:29:54.640]   You can walk. The reason I mentioned the time we do the show is you can watch us live at YouTube.
[02:29:54.640 --> 02:30:00.000]   Well, I'll tell you what, best thing to do. We have all of the different live streams, YouTube,
[02:30:00.000 --> 02:30:06.640]   Twitch, YouTube stream at one place on our website, Twitch.tv/live. Choose the stream you want.
[02:30:06.640 --> 02:30:12.800]   There's also audio streams there, thanks to Spreaker and others. Twitch.tv/live. If you're
[02:30:12.800 --> 02:30:19.840]   watching live, chat live, IRC.tuit.tv. That's the free one. If you are a member of Club Twitch,
[02:30:19.840 --> 02:30:24.720]   we've got a great discord for you all. Club Twitch members pay seven bucks a month. They
[02:30:24.720 --> 02:30:30.640]   get ad-free versions of all our shows, access to the discord. Of course, the Club Twitch plus feed.
[02:30:30.640 --> 02:30:37.360]   All of that is available at Twitch.tv/clubtuit. This show also is on YouTube after the fact. So
[02:30:37.360 --> 02:30:43.040]   you can watch there. You can download episodes, audio, or video from our website at Twitch.tv.
[02:30:43.040 --> 02:30:47.440]   Best thing to do, be subscribe in your favorite podcast application. And if you do,
[02:30:47.440 --> 02:30:52.480]   and they allow reviews, do me a favor, would you? Do me a solid, as the kids say.
[02:30:53.600 --> 02:30:57.520]   Leave us a five. They don't say that anymore, do they? Leave us a five star review.
[02:30:57.520 --> 02:31:05.600]   And let the world know you listen to Twitch. Thank you everybody for joining us. We'll see you next
[02:31:05.600 --> 02:31:08.080]   time. Another Twitter is in the can.
[02:31:08.080 --> 02:31:19.120]   (music)

