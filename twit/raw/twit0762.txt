;FFMETADATA1
title=Synthetic Chris Evans
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=762
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.000]   It's time for Twit this week in tech.
[00:00:02.000 --> 00:00:04.900]   Very first thing we're going to do, go visit Italy.
[00:00:04.900 --> 00:00:07.480]   Robert Balissaire joins us from the Vatican,
[00:00:07.480 --> 00:00:10.140]   a check-in on how Father Robert's doing.
[00:00:10.140 --> 00:00:11.600]   And then our hosts,
[00:00:11.600 --> 00:00:14.400]   Marques Brownlee from MKBHD,
[00:00:14.400 --> 00:00:17.400]   YouTube's top star and Amy Webb.
[00:00:17.400 --> 00:00:21.800]   Everybody's favorite futurist will talk about the world ahead.
[00:00:21.800 --> 00:00:26.100]   Marques talks about his 8K production and the Escobar phone.
[00:00:26.100 --> 00:00:30.600]   We will talk also about why the future is bright,
[00:00:30.600 --> 00:00:33.200]   except for a few minor things.
[00:00:33.200 --> 00:00:35.400]   And New Year's Rockin' Eve,
[00:00:35.400 --> 00:00:37.200]   why 8K just won't fly.
[00:00:37.200 --> 00:00:40.100]   It's all coming up next on Twit.
[00:00:40.100 --> 00:00:43.400]   This week in tech comes to you from Twit's LastPass Studios.
[00:00:43.400 --> 00:00:47.100]   Stay in control when it comes to your company's access points and authentication.
[00:00:47.100 --> 00:00:50.700]   LastPass makes enterprise-level security simple.
[00:00:50.700 --> 00:00:53.600]   Check it out at LastPass.com/Twit.
[00:00:53.600 --> 00:00:56.000]   [MUSIC]
[00:00:56.000 --> 00:00:57.800]   Podcasts you love.
[00:00:57.800 --> 00:00:59.600]   From people you trust.
[00:00:59.600 --> 00:01:02.100]   This is Twit.
[00:01:02.100 --> 00:01:08.900]   [MUSIC]
[00:01:08.900 --> 00:01:11.200]   This is Twit this week in tech.
[00:01:11.200 --> 00:01:16.600]   Episode 762 recorded Sunday, March 15, 2020.
[00:01:16.600 --> 00:01:19.100]   Synthetic Chris Evans.
[00:01:19.100 --> 00:01:23.900]   This episode of This Week in Tech is brought to you by Worldwide Technology.
[00:01:23.900 --> 00:01:29.300]   Worldwide Technologies Advanced Technology Center is like no other testing and research lab.
[00:01:29.300 --> 00:01:31.700]   With more than half a billion dollars of equipment,
[00:01:31.700 --> 00:01:35.300]   including solutions from key partners like Intel Corporation.
[00:01:35.300 --> 00:01:38.900]   And it's virtual so you can access it 24/7.
[00:01:38.900 --> 00:01:42.100]   To learn more and get insights into all the ATC offers,
[00:01:42.100 --> 00:01:45.400]   go to www.wt.com/Twit.
[00:01:45.400 --> 00:01:48.600]   And by ZipRecruiter, hiring is challenging.
[00:01:48.600 --> 00:01:51.800]   But there's one place you can go where hiring is simple and smart.
[00:01:51.800 --> 00:01:56.800]   That place is ZipRecruiter where growing businesses connect to qualified candidates.
[00:01:56.800 --> 00:02:00.700]   Try it free at ziprecruiter.com/Twit.
[00:02:00.700 --> 00:02:02.700]   And by Casper.
[00:02:02.700 --> 00:02:08.600]   Casper is a sleep brand that makes expertly designed products to help you get your best rest.
[00:02:08.600 --> 00:02:09.900]   One night at a time.
[00:02:09.900 --> 00:02:15.300]   Get $100 towards select mattresses by visiting casper.com/Twit1
[00:02:15.300 --> 00:02:18.400]   and using the promo code TWIT1 at checkout.
[00:02:18.400 --> 00:02:20.800]   And by Zapier.
[00:02:20.800 --> 00:02:24.400]   Zapier connects all your business software and handles the work for you
[00:02:24.400 --> 00:02:26.700]   so you can focus on what matters most.
[00:02:26.700 --> 00:02:32.400]   Right now through the end of the month, go to zapier.com/Twit for your free 14-day trial.
[00:02:32.400 --> 00:02:41.300]   It's time for Twit this week at Tech.
[00:02:41.300 --> 00:02:43.800]   The show that covers the week's Tech News.
[00:02:43.800 --> 00:02:46.600]   Boy, do we have a great panel today joining us.
[00:02:46.600 --> 00:02:50.800]   10.2 million subscribers strong.
[00:02:50.800 --> 00:02:52.800]   MKBHD, Marques Brownlee.
[00:02:52.800 --> 00:02:54.800]   Great to have you on Twit.
[00:02:54.800 --> 00:02:56.300]   The star man.
[00:02:56.300 --> 00:02:58.400]   You are just a living legend.
[00:02:58.400 --> 00:03:00.400]   You just interviewed Bill Gates.
[00:03:00.400 --> 00:03:01.900]   My God.
[00:03:01.900 --> 00:03:02.900]   There you are.
[00:03:02.900 --> 00:03:04.400]   Now you're not in your new studio yet.
[00:03:04.400 --> 00:03:05.400]   Not yet.
[00:03:05.400 --> 00:03:08.400]   It's nearby but maybe a month away from that.
[00:03:08.400 --> 00:03:10.400]   So I built a couple of new studios.
[00:03:10.400 --> 00:03:12.800]   Something I deeply regret.
[00:03:12.800 --> 00:03:14.800]   How are you feeling about that?
[00:03:14.800 --> 00:03:19.200]   We have some experience with it so far.
[00:03:19.200 --> 00:03:22.200]   So it'll be a slow process but I'm excited about it.
[00:03:22.200 --> 00:03:23.200]   Yeah, it's nice.
[00:03:23.200 --> 00:03:25.200]   What are you going to get in the new studio?
[00:03:25.200 --> 00:03:27.200]   Is it more room or is it better facilities?
[00:03:27.200 --> 00:03:29.200]   A little bit of everything.
[00:03:29.200 --> 00:03:31.200]   So more space is the number one thing.
[00:03:31.200 --> 00:03:34.200]   We'll bring a lot of the stuff from here down to there.
[00:03:34.200 --> 00:03:38.200]   And then we'll probably add some things like equipment.
[00:03:38.200 --> 00:03:39.200]   Equipment.
[00:03:39.200 --> 00:03:40.200]   Equipment will be nice.
[00:03:40.200 --> 00:03:41.200]   Yeah.
[00:03:41.200 --> 00:03:42.200]   Equipment is always nice.
[00:03:42.200 --> 00:03:43.200]   Yeah.
[00:03:43.200 --> 00:03:45.000]   Amy Webb is also here.
[00:03:45.000 --> 00:03:46.000]   Our futurist.
[00:03:46.000 --> 00:03:47.680]   Oh, it's so good.
[00:03:47.680 --> 00:03:49.480]   I haven't seen you in so long, Amy.
[00:03:49.480 --> 00:03:50.480]   And you know, it's funny.
[00:03:50.480 --> 00:03:54.720]   We were just in St. Louis for an event with worldwide technology.
[00:03:54.720 --> 00:03:57.240]   We had a meetup before.
[00:03:57.240 --> 00:04:00.800]   Three different people independently came up to me and said, you know, I really like
[00:04:00.800 --> 00:04:01.800]   onto it.
[00:04:01.800 --> 00:04:02.800]   Amy Webb.
[00:04:02.800 --> 00:04:03.800]   Oh, that's nice.
[00:04:03.800 --> 00:04:04.800]   Thank you.
[00:04:04.800 --> 00:04:05.800]   I like to be here.
[00:04:05.800 --> 00:04:06.800]   I love being on the back channel.
[00:04:06.800 --> 00:04:07.800]   On IRC.
[00:04:07.800 --> 00:04:09.440]   You're so smart.
[00:04:09.440 --> 00:04:10.600]   Future Today Institute.
[00:04:10.600 --> 00:04:18.360]   She is a futurist, teaches a strategic foresight at NYU Stern School of Business, and the brand
[00:04:18.360 --> 00:04:22.080]   new deck of future stuff.
[00:04:22.080 --> 00:04:24.080]   What is a better name for it?
[00:04:24.080 --> 00:04:25.560]   What's it called?
[00:04:25.560 --> 00:04:29.000]   It's-- so my company is called the Future Today Institute.
[00:04:29.000 --> 00:04:32.560]   And every year, all of our research is free, open source.
[00:04:32.560 --> 00:04:35.240]   We give everything away to anybody who wants it.
[00:04:35.240 --> 00:04:39.800]   And we put out an annual report that normally launches at South By, which is where I would
[00:04:39.800 --> 00:04:44.280]   have been, if not for virus situation.
[00:04:44.280 --> 00:04:45.880]   It launches on the main stage there.
[00:04:45.880 --> 00:04:47.400]   So we still put it out.
[00:04:47.400 --> 00:04:50.240]   I actually launched a one-on-one text messaging service.
[00:04:50.240 --> 00:04:55.240]   We're doing all kinds of stuff because it's important to me that everybody thinks holistically
[00:04:55.240 --> 00:04:59.840]   about signals of disruption and thinks more critically about the future.
[00:04:59.840 --> 00:05:02.560]   So everybody who wants can get a copy of it for free.
[00:05:02.560 --> 00:05:07.080]   Now more than ever, futuretodayinstitute.com.
[00:05:07.080 --> 00:05:08.400]   Thank you for being here.
[00:05:08.400 --> 00:05:13.800]   And we thought between Marquez and Amy, we'd have plenty to talk about today.
[00:05:13.800 --> 00:05:19.680]   But last minute addition, just briefly, because we haven't heard from Father Robert Ballisare
[00:05:19.680 --> 00:05:20.680]   in a while.
[00:05:20.680 --> 00:05:24.400]   We know he's in Italy, which is a country in crisis right now.
[00:05:24.400 --> 00:05:25.720]   He's at the Vatican.
[00:05:25.720 --> 00:05:28.640]   And we thought we'd say, "Hi, and just check in to Father Robert.
[00:05:28.640 --> 00:05:29.640]   How are you?"
[00:05:29.640 --> 00:05:33.440]   Well, I'm in quarantine, like everyone else in the country.
[00:05:33.440 --> 00:05:35.400]   So it's a weird, weird time.
[00:05:35.400 --> 00:05:38.120]   But I think I'm more or less safe here.
[00:05:38.120 --> 00:05:39.120]   Good.
[00:05:39.120 --> 00:05:41.320]   Well, you're in the Vatican, my God, if you're not safe in the Vatican.
[00:05:41.320 --> 00:05:44.680]   I don't know where it would be safer.
[00:05:44.680 --> 00:05:48.400]   Although I will say this, because of our low population and the fact that there has
[00:05:48.400 --> 00:05:53.560]   been a confirmed case, our infection rate is now the highest in the world.
[00:05:53.560 --> 00:05:54.560]   Oh, geez.
[00:05:54.560 --> 00:05:57.400]   Yeah, it's a small country.
[00:05:57.400 --> 00:06:01.960]   But also, and this is serious, a lot of older priests are there.
[00:06:01.960 --> 00:06:03.960]   What's the average age of the Vatican?
[00:06:03.960 --> 00:06:05.840]   Well, I live in a community here.
[00:06:05.840 --> 00:06:08.680]   So our community is right next to St. Peter's.
[00:06:08.680 --> 00:06:11.280]   And we've got 140 Jesuits here.
[00:06:11.280 --> 00:06:15.720]   About 60% are either right at or over the age of 70.
[00:06:15.720 --> 00:06:17.960]   So it's a very at-risk community.
[00:06:17.960 --> 00:06:18.960]   Yeah.
[00:06:18.960 --> 00:06:20.240]   Well, stay well, stay healthy.
[00:06:20.240 --> 00:06:21.240]   We're glad to know.
[00:06:21.240 --> 00:06:26.040]   And you've been using, Robert built this streaming studio in the Vatican.
[00:06:26.040 --> 00:06:29.800]   You I guess your initial intent was to podcast from there, but apparently your timing was
[00:06:29.800 --> 00:06:30.800]   good.
[00:06:30.800 --> 00:06:34.880]   The timing was good because we are now getting a lot of news agencies who would like to
[00:06:34.880 --> 00:06:36.240]   speak to people.
[00:06:36.240 --> 00:06:41.680]   And unfortunately, because of the lockdown, it's difficult for people to get from here
[00:06:41.680 --> 00:06:44.560]   to even the media studios across the street.
[00:06:44.560 --> 00:06:47.200]   So this has been sort of the primary broadcast area.
[00:06:47.200 --> 00:06:52.240]   We've done what 14 different broadcasts from this room in the last three days.
[00:06:52.240 --> 00:06:54.480]   So it came up just at the right time.
[00:06:54.480 --> 00:06:58.800]   Just like you, I get the pains of building something and then realizing it's not going
[00:06:58.800 --> 00:07:00.520]   to do what I thought it was going to do.
[00:07:00.520 --> 00:07:02.160]   The timing couldn't be better.
[00:07:02.160 --> 00:07:04.640]   Actually, we're doing something on Thursday.
[00:07:04.640 --> 00:07:13.520]   There's a habad, which is Orthodox Jewish synagogue in the Petaluma area had invited
[00:07:13.520 --> 00:07:19.280]   a Holocaust survivor, a 93-year-old Holocaust survivor, step-sister Van Frank to speak on
[00:07:19.280 --> 00:07:20.520]   Thursday.
[00:07:20.520 --> 00:07:24.600]   But of course, all of these meetings are shut down.
[00:07:24.600 --> 00:07:27.960]   And they called us and said, could she stream it from your studio?
[00:07:27.960 --> 00:07:29.120]   And we said, absolutely.
[00:07:29.120 --> 00:07:32.560]   So Thursday, she and her interviewer are coming in, the rabbi's coming in, and they're going
[00:07:32.560 --> 00:07:34.400]   to do a private event.
[00:07:34.400 --> 00:07:37.920]   I'd invite you, but it's going to do an event for the ticket holders because there's a lot
[00:07:37.920 --> 00:07:39.840]   of people who wanted to see this.
[00:07:39.840 --> 00:07:41.960]   And it would be a shame if they didn't get a chance to.
[00:07:41.960 --> 00:07:48.120]   So I think everybody who has streaming skills at this point is a kind of a hot commodity.
[00:07:48.120 --> 00:07:50.640]   Are you helping the pope do streaming masses?
[00:07:50.640 --> 00:07:51.640]   Right?
[00:07:51.640 --> 00:07:52.880]   He's doing masses online.
[00:07:52.880 --> 00:07:53.880]   Correct.
[00:07:53.880 --> 00:07:54.880]   Yeah.
[00:07:54.880 --> 00:07:59.080]   So we've sort of pooled resources in the Vatican for all of these different events.
[00:07:59.080 --> 00:08:02.960]   Because people are starting to realize that when you're doing a webinar or when you're
[00:08:02.960 --> 00:08:07.760]   doing an actual professional video conference, not just something on your phone or your tablet,
[00:08:07.760 --> 00:08:11.640]   it takes a certain set up and it takes a certain set of skills.
[00:08:11.640 --> 00:08:15.800]   We're actually winnowing down the number of people who should get in front of the camera.
[00:08:15.800 --> 00:08:16.800]   And you know this.
[00:08:16.800 --> 00:08:19.360]   A lot of people think, oh, you just turn on the camera and you go.
[00:08:19.360 --> 00:08:20.360]   It's hard.
[00:08:20.360 --> 00:08:24.720]   A lot of professors and teachers are learning how hard online education is.
[00:08:24.720 --> 00:08:26.880]   They had no preparation for this.
[00:08:26.880 --> 00:08:29.680]   And it's not the same thing as standing in front of a classroom.
[00:08:29.680 --> 00:08:31.160]   Yeah, exactly.
[00:08:31.160 --> 00:08:32.160]   Yeah.
[00:08:32.160 --> 00:08:35.720]   I've been teaching, I've been giving people tips on how to work without that feedback.
[00:08:35.720 --> 00:08:38.760]   You know, if you're a professor and you're used to getting up in front of a class of
[00:08:38.760 --> 00:08:43.000]   120 students and now you have to do it in front of a camera and the only feedback you
[00:08:43.000 --> 00:08:44.000]   get is a chat room.
[00:08:44.000 --> 00:08:45.000]   Weirdly sign up.
[00:08:45.000 --> 00:08:46.000]   That's hard.
[00:08:46.000 --> 00:08:47.000]   Yeah.
[00:08:47.000 --> 00:08:50.640]   I've been watching like live with Regis and Kelly or whatever the new host is.
[00:08:50.640 --> 00:08:52.640]   I don't know that guy.
[00:08:52.640 --> 00:08:53.640]   Brian C.
[00:08:53.640 --> 00:08:54.640]   Oh, yeah.
[00:08:54.640 --> 00:08:55.640]   Yeah, I know.
[00:08:55.640 --> 00:08:56.800]   I don't know why I know that.
[00:08:56.800 --> 00:08:59.080]   I'm with Kelly and Ryan.
[00:08:59.080 --> 00:09:00.080]   They're not doing it with an audience.
[00:09:00.080 --> 00:09:05.680]   And it's a weird thing to be in a theater and not have anybody there.
[00:09:05.680 --> 00:09:06.880]   Mark has had people come to you?
[00:09:06.880 --> 00:09:09.160]   They know you have a streaming studio there.
[00:09:09.160 --> 00:09:11.600]   Are they asking your help?
[00:09:11.600 --> 00:09:12.600]   Not really.
[00:09:12.600 --> 00:09:16.000]   It's a little less intense here at the moment.
[00:09:16.000 --> 00:09:17.400]   I guess for better or worse.
[00:09:17.400 --> 00:09:18.400]   You're in New York.
[00:09:18.400 --> 00:09:19.400]   You're in New York.
[00:09:19.400 --> 00:09:20.400]   I'm right across the river.
[00:09:20.400 --> 00:09:27.560]   So I'm in New Jersey where there are some weird things, some heightened states of awareness,
[00:09:27.560 --> 00:09:30.200]   I guess, because there are nearby towns that have a bunch of cases.
[00:09:30.200 --> 00:09:34.080]   But other than that, it's been a business as usual.
[00:09:34.080 --> 00:09:37.800]   I mean, everyone's got the hand sanitizer and everything that you see now.
[00:09:37.800 --> 00:09:39.520]   But so far we've been all right.
[00:09:39.520 --> 00:09:43.040]   I think New Jersey just announced they're shutting everything down.
[00:09:43.040 --> 00:09:44.360]   So get ready.
[00:09:44.360 --> 00:09:46.440]   I'm just saying.
[00:09:46.440 --> 00:09:49.600]   It's kind of the way it's going all over the world.
[00:09:49.600 --> 00:09:50.880]   Apple announced.
[00:09:50.880 --> 00:09:51.880]   So here's a weird...
[00:09:51.880 --> 00:09:52.880]   Do you want to...
[00:09:52.880 --> 00:09:53.880]   Robert, do you want to take off?
[00:09:53.880 --> 00:09:55.360]   I know it's spaghetti night at the Vatican.
[00:09:55.360 --> 00:09:56.840]   Do you want to get out of here?
[00:09:56.840 --> 00:10:00.160]   Yeah, I just wanted to say hi and head on out.
[00:10:00.160 --> 00:10:04.000]   But I'll definitely come back for some Twitter program in the future now that I know this
[00:10:04.000 --> 00:10:05.000]   news.
[00:10:05.000 --> 00:10:06.000]   Yeah.
[00:10:06.000 --> 00:10:08.200]   So you hadn't used this yet to do a show?
[00:10:08.200 --> 00:10:09.200]   No.
[00:10:09.200 --> 00:10:10.200]   No.
[00:10:10.200 --> 00:10:14.520]   We've done a few broadcasts for BBC and one for CNN.
[00:10:14.520 --> 00:10:18.560]   But I haven't done my podcasting in my podcasting studio.
[00:10:18.560 --> 00:10:21.640]   What's the DJ for?
[00:10:21.640 --> 00:10:22.640]   Digital Jesuit.
[00:10:22.640 --> 00:10:23.640]   Oh, that's you.
[00:10:23.640 --> 00:10:24.640]   That's me.
[00:10:24.640 --> 00:10:27.640]   You take that down with the beeps in there though, right?
[00:10:27.640 --> 00:10:28.640]   Exactly.
[00:10:28.640 --> 00:10:31.560]   Well, I mean, you can see there's a lot of cues here from the Twitch studio.
[00:10:31.560 --> 00:10:35.920]   So everything from the avatars to the lighting set up to our switching board.
[00:10:35.920 --> 00:10:36.920]   It's what I took from my Twitter experience.
[00:10:36.920 --> 00:10:37.920]   Can you show us a little more?
[00:10:37.920 --> 00:10:39.960]   Do you have cameras set up anywhere else?
[00:10:39.960 --> 00:10:40.960]   Oh, yeah.
[00:10:40.960 --> 00:10:44.360]   So, I mean, you know, of course, I'm running everything off this laptop right now.
[00:10:44.360 --> 00:10:47.360]   But we do actually have a streaming setup over there.
[00:10:47.360 --> 00:10:50.040]   And I'm using the Blackmagic Switchers.
[00:10:50.040 --> 00:10:54.040]   On this particular studio, I'm just using this mini, but they all use the same console.
[00:10:54.040 --> 00:10:55.280]   So I can set up lower thirds.
[00:10:55.280 --> 00:10:56.720]   I can set up transitions.
[00:10:56.720 --> 00:10:58.320]   I've got it in just machine.
[00:10:58.320 --> 00:11:01.200]   I've got, you know, high definition recorders.
[00:11:01.200 --> 00:11:02.960]   And then I've got cameras all around the studio.
[00:11:02.960 --> 00:11:09.600]   I've only got these two piped in at the moment because I've been doing some work, but I'll
[00:11:09.600 --> 00:11:10.600]   have a camera outside.
[00:11:10.600 --> 00:11:14.240]   I have a camera looking down at the street and then I'll have a matrix switcher.
[00:11:14.240 --> 00:11:18.560]   So at any point, I can tie into any of the screens and cameras around the studio.
[00:11:18.560 --> 00:11:20.160]   That's nice.
[00:11:20.160 --> 00:11:24.680]   It's set up just like what a low price version of Twit would be.
[00:11:24.680 --> 00:11:26.840]   Well, that ATEM Mini is fantastic.
[00:11:26.840 --> 00:11:29.000]   It's an incredible device.
[00:11:29.000 --> 00:11:30.000]   Yeah.
[00:11:30.000 --> 00:11:35.200]   Seriously, anyone who has not bought hardware yet, if you're looking to start a podcasting
[00:11:35.200 --> 00:11:39.720]   studio, this ATEM Mini is there's nothing like it because it connects directly into
[00:11:39.720 --> 00:11:44.560]   your computer so it becomes your digitizing interface, then you get four inputs.
[00:11:44.560 --> 00:11:45.920]   Four HDMI inputs.
[00:11:45.920 --> 00:11:48.160]   And then you get also left, right audio.
[00:11:48.160 --> 00:11:50.960]   They have DIN plugs and they have USB.
[00:11:50.960 --> 00:11:51.960]   It's pretty impressive.
[00:11:51.960 --> 00:11:52.960]   I bought one.
[00:11:52.960 --> 00:11:56.120]   I don't know what I'm going to do with it, but I'm ready for, I'm ready to brought it.
[00:11:56.120 --> 00:11:58.040]   Honestly, I'm ready to broadcast from home.
[00:11:58.040 --> 00:12:00.600]   We've already thought about, well, we could set that up and I could do the whole thing
[00:12:00.600 --> 00:12:01.600]   at home if I had to.
[00:12:01.600 --> 00:12:05.320]   Well, I mean, Leo, it's perfect for when you're on the go because you're always carrying your
[00:12:05.320 --> 00:12:06.320]   camera.
[00:12:06.320 --> 00:12:07.320]   That's what I want to do.
[00:12:07.320 --> 00:12:08.320]   That's what I want to do.
[00:12:08.320 --> 00:12:11.520]   I want output from your computer so you've got something that you can switch to and you
[00:12:11.520 --> 00:12:17.000]   can carry a really small HDMI camera that can be sort of your over the shoulder shot
[00:12:17.000 --> 00:12:20.840]   and you can carry that everywhere in under four pounds.
[00:12:20.840 --> 00:12:21.840]   Nice.
[00:12:21.840 --> 00:12:22.840]   Robert, thank you.
[00:12:22.840 --> 00:12:25.040]   Stay well, stay healthy, sanitize.
[00:12:25.040 --> 00:12:26.040]   I will.
[00:12:26.040 --> 00:12:28.600]   And we'll, I hope to see you real soon.
[00:12:28.600 --> 00:12:29.920]   Have a great episode.
[00:12:29.920 --> 00:12:32.840]   Padre SJ on Twitter and he is tweeting actively.
[00:12:32.840 --> 00:12:35.200]   So that's how we knew you were okay.
[00:12:35.200 --> 00:12:36.400]   Take care, Father Robert.
[00:12:36.400 --> 00:12:37.400]   Take care.
[00:12:37.400 --> 00:12:38.640]   In the crisis center.
[00:12:38.640 --> 00:12:42.240]   I feel like when we talk about this stuff, Marquez is probably just going, yeah, right,
[00:12:42.240 --> 00:12:43.240]   you guys.
[00:12:43.240 --> 00:12:46.480]   You're shooting with black magic.
[00:12:46.480 --> 00:12:47.480]   What is it?
[00:12:47.480 --> 00:12:49.040]   Are they 8K or reds?
[00:12:49.040 --> 00:12:50.040]   What are you using?
[00:12:50.040 --> 00:12:54.800]   Oh, our video stuff is mostly red, red 8K, monstrosensors.
[00:12:54.800 --> 00:12:56.360]   Well, how do you edit?
[00:12:56.360 --> 00:12:57.360]   How do you edit?
[00:12:57.360 --> 00:13:00.320]   What's your workflow with 8K?
[00:13:00.320 --> 00:13:02.560]   It's got we got it kind of down to a science.
[00:13:02.560 --> 00:13:04.200]   We have the new Mac Pros.
[00:13:04.200 --> 00:13:05.200]   Wait a minute.
[00:13:05.200 --> 00:13:09.160]   You say that in plural?
[00:13:09.160 --> 00:13:10.160]   I have a couple.
[00:13:10.160 --> 00:13:14.240]   Well, so behind me, you can see there's a couple iMac Pros, which the guys who work
[00:13:14.240 --> 00:13:15.240]   with me have set up.
[00:13:15.240 --> 00:13:19.720]   But when we move to the new studio, we will set up the Mac Pros that they will also be
[00:13:19.720 --> 00:13:20.720]   upgrading to.
[00:13:20.720 --> 00:13:25.560]   How many Mac, how many Mac pros are you going to have?
[00:13:25.560 --> 00:13:26.560]   Four.
[00:13:26.560 --> 00:13:28.360]   Oh, four of us.
[00:13:28.360 --> 00:13:29.360]   Okay.
[00:13:29.360 --> 00:13:30.360]   But it's.
[00:13:30.360 --> 00:13:33.440]   I hope our editors are not listening.
[00:13:33.440 --> 00:13:38.360]   As you're not getting Mac Pros, don't even think about it.
[00:13:38.360 --> 00:13:39.360]   Holy cow.
[00:13:39.360 --> 00:13:45.720]   But we wouldn't need Mac Pros if we didn't shoot this crazy eye format stuff.
[00:13:45.720 --> 00:13:51.100]   But it's working with a K video and a Mac Pro about comparable to a normal, two or four
[00:13:51.100 --> 00:13:52.640]   K video?
[00:13:52.640 --> 00:13:56.120]   No, it's still pretty heavy.
[00:13:56.120 --> 00:14:00.600]   I've shot whenever we shoot 4K anything, any machine I want to use just cuts right
[00:14:00.600 --> 00:14:05.360]   through it, no problem, it's just because it's red code raw, that specific codec, it's
[00:14:05.360 --> 00:14:09.560]   not it's not just H.264, just 8K video, it's more than just the resolution.
[00:14:09.560 --> 00:14:14.200]   So when we get into that codec stuff and all that raw information, then it starts to
[00:14:14.200 --> 00:14:15.800]   really tax it.
[00:14:15.800 --> 00:14:20.200]   So give me, but why?
[00:14:20.200 --> 00:14:25.280]   It's definitely overkill, but it is a lot more about the fun of what we're able to make
[00:14:25.280 --> 00:14:29.640]   with that information than just like having more.
[00:14:29.640 --> 00:14:35.960]   And if all I did was point the camera at myself and talk to it, I wouldn't need much more
[00:14:35.960 --> 00:14:39.320]   than just like a typical DSLR.
[00:14:39.320 --> 00:14:43.600]   But because we do so much with motion graphics, that requires a lot more data points for tracking
[00:14:43.600 --> 00:14:45.840]   because we do a lot more with color correction.
[00:14:45.840 --> 00:14:50.480]   And you get a lot into tweaking the red code and not just the color temperature, but like
[00:14:50.480 --> 00:14:54.560]   when you throw LUTs on there, all the sort of stuff, it adds up over time.
[00:14:54.560 --> 00:14:59.880]   So the more cinema focused of a camera you have, the easier it becomes, but also the
[00:14:59.880 --> 00:15:01.520]   more taxing it becomes on the computer.
[00:15:01.520 --> 00:15:02.800]   So that's a little bit of a trade-off.
[00:15:02.800 --> 00:15:06.240]   It's a lot more work and a lot more skill involved.
[00:15:06.240 --> 00:15:08.480]   Are you doing motion tracking because you have virtual sets?
[00:15:08.480 --> 00:15:10.040]   What are you doing the motion tracking for?
[00:15:10.040 --> 00:15:12.640]   It's just for smaller graphics and stuff.
[00:15:12.640 --> 00:15:16.160]   Sometimes I'll just point out, hey, this camera on the back of this phone has this
[00:15:16.160 --> 00:15:20.280]   aperture and has OIS and I'll just have a little animation pop out to show you which
[00:15:20.280 --> 00:15:23.400]   ones which little stuff like that.
[00:15:23.400 --> 00:15:27.680]   You could do that with a lesser quality camera, but the better quality of the information going
[00:15:27.680 --> 00:15:31.160]   in, the better quality of the tracking, the better quality of the final product.
[00:15:31.160 --> 00:15:33.400]   And you do it because you can.
[00:15:33.400 --> 00:15:35.640]   I mean, do you think it helps?
[00:15:35.640 --> 00:15:37.800]   I mean, this is all for YouTube.
[00:15:37.800 --> 00:15:41.600]   You're not showing in major theaters around the country or anything.
[00:15:41.600 --> 00:15:43.880]   This is all for YouTube.
[00:15:43.880 --> 00:15:46.920]   But do you think that there's a benefit to it?
[00:15:46.920 --> 00:15:50.760]   One of the reasons you have 10 and 1/2 million subscribers is because of the quality?
[00:15:50.760 --> 00:15:56.760]   Yeah, it's not so you can use the word quality, but I think it's more about it's, I think
[00:15:56.760 --> 00:15:57.960]   I'd call it a depth.
[00:15:57.960 --> 00:16:03.560]   Like it's harder to replicate and it's harder to tie it in with all the rest.
[00:16:03.560 --> 00:16:05.640]   So there's a million people making tech videos now.
[00:16:05.640 --> 00:16:11.040]   Back when I started when I just had one camera and one laptop and a desk, there were seven
[00:16:11.040 --> 00:16:15.360]   of us and we all could do totally different things with our camera to talk about this
[00:16:15.360 --> 00:16:16.360]   new tech.
[00:16:16.360 --> 00:16:18.120]   But now a new Samsung phone comes out and there's what?
[00:16:18.120 --> 00:16:20.160]   70 videos at once.
[00:16:20.160 --> 00:16:21.160]   So which one are you going to watch?
[00:16:21.160 --> 00:16:25.600]   You're going to watch hopefully the best three before you've pretty much learned everything.
[00:16:25.600 --> 00:16:31.520]   So we try to do the best we can and a lot of that comes from pushing it to the limits
[00:16:31.520 --> 00:16:35.560]   and having those cool motion graphic effects and trying to be as precise as possible with
[00:16:35.560 --> 00:16:36.560]   our edits.
[00:16:36.560 --> 00:16:38.320]   So I think that's what it's turned into.
[00:16:38.320 --> 00:16:40.560]   Do you find it also drives your content?
[00:16:40.560 --> 00:16:44.480]   I'll give you as an example, you just did a piece which got a lot of attention on the
[00:16:44.480 --> 00:16:46.520]   Escobar phone.
[00:16:46.520 --> 00:16:47.520]   Right.
[00:16:47.520 --> 00:16:52.880]   Normally, you wouldn't cover the Escobar phone or would you?
[00:16:52.880 --> 00:16:54.120]   That one was a weird one.
[00:16:54.120 --> 00:16:59.880]   I feel like the way it happened, no, I would not have normally covered it.
[00:16:59.880 --> 00:17:05.720]   But then it just sort of actually the way I decided to make a video about it was just
[00:17:05.720 --> 00:17:08.160]   like, you know what screw it, people got to know.
[00:17:08.160 --> 00:17:09.720]   So I ended up making that video.
[00:17:09.720 --> 00:17:13.440]   But yeah, there's some ideas that just sort of come out of the blue.
[00:17:13.440 --> 00:17:15.640]   Let's just folks to put this in perspective.
[00:17:15.640 --> 00:17:20.640]   You put that video out five days ago, it has four and a half million views.
[00:17:20.640 --> 00:17:27.840]   So, and it is the case that the number of views directly impacts your revenue, right?
[00:17:27.840 --> 00:17:28.840]   More or less, yeah.
[00:17:28.840 --> 00:17:29.840]   More or less.
[00:17:29.840 --> 00:17:33.360]   It's the number of views on monetized clicks.
[00:17:33.360 --> 00:17:34.360]   Right.
[00:17:34.360 --> 00:17:35.360]   Well, everything you do is monetized.
[00:17:35.360 --> 00:17:39.640]   You know what they've recently demonetized anything that talks about COVID-19, which has
[00:17:39.640 --> 00:17:41.120]   put us in a little.
[00:17:41.120 --> 00:17:44.760]   Fortunately, we don't make the bulk of our funds don't come from YouTube, but I thought
[00:17:44.760 --> 00:17:46.560]   that's kind of a problem.
[00:17:46.560 --> 00:17:49.160]   If you're a YouTuber, you can't mention it.
[00:17:49.160 --> 00:17:50.160]   Yeah.
[00:17:50.160 --> 00:17:54.880]   Yeah, there's some creators that whose main source of income is the YouTube ad revenue.
[00:17:54.880 --> 00:17:59.720]   So those creators are sort of steered by what they're allowed to talk about and what won't
[00:17:59.720 --> 00:18:00.720]   get demonetized.
[00:18:00.720 --> 00:18:04.680]   Luckily, we're not sort of steered that way, but I have seen those stories.
[00:18:04.680 --> 00:18:06.480]   Yeah, that's bad news.
[00:18:06.480 --> 00:18:09.760]   So by your bottom line, don't buy the Escobar folding phone.
[00:18:09.760 --> 00:18:10.760]   Yeah, I don't.
[00:18:10.760 --> 00:18:12.880]   Don't even, yeah, don't try.
[00:18:12.880 --> 00:18:14.120]   The thumbnail says it all.
[00:18:14.120 --> 00:18:16.920]   He scrapes the back off the.
[00:18:16.920 --> 00:18:17.920]   Yeah.
[00:18:17.920 --> 00:18:20.560]   Here's my, here's my Escobar phone.
[00:18:20.560 --> 00:18:26.160]   If you must see it in person, but I would say if you bought one, don't expect to get
[00:18:26.160 --> 00:18:27.160]   anything.
[00:18:27.160 --> 00:18:29.160]   There you go.
[00:18:29.160 --> 00:18:32.880]   Amy actually wanted to ask you, we'll get to the news in a second, but it's so great
[00:18:32.880 --> 00:18:34.120]   to have both of you on.
[00:18:34.120 --> 00:18:37.800]   I love both of you and I love talking to both of you and I have so many questions.
[00:18:37.800 --> 00:18:43.800]   I've been thinking about you a lot, Amy, because in a way, what, and I know this is not where
[00:18:43.800 --> 00:18:47.120]   I should warn people at a time, we're not going to do a lot of stories about the virus.
[00:18:47.120 --> 00:18:48.640]   This isn't a virus show.
[00:18:48.640 --> 00:18:51.080]   You get plenty of that everywhere else.
[00:18:51.080 --> 00:18:55.720]   And God knows it's important to pay attention to it, but I feel like we can talk about other
[00:18:55.720 --> 00:18:58.800]   things here because we're just, you know, we're the toy store.
[00:18:58.800 --> 00:19:02.560]   But I have been thinking about you, Amy, because this is an inflection point.
[00:19:02.560 --> 00:19:04.640]   This is a paradigm shift.
[00:19:04.640 --> 00:19:09.160]   It's not completely unexpected, but it's the kind of left turn that must make it hard to
[00:19:09.160 --> 00:19:10.960]   predict the future.
[00:19:10.960 --> 00:19:11.960]   Yeah.
[00:19:11.960 --> 00:19:16.480]   Well, actually I can talk about that, but can I go back to that ridiculous phone for
[00:19:16.480 --> 00:19:17.480]   a moment?
[00:19:17.480 --> 00:19:18.480]   Yes, of course.
[00:19:18.480 --> 00:19:20.760]   See, everybody wants to know about the freaking Escobar phone.
[00:19:20.760 --> 00:19:23.840]   Let's talk about this ridiculous phone, but here's why.
[00:19:23.840 --> 00:19:25.640]   So we built this model.
[00:19:25.640 --> 00:19:32.520]   So a futurist, especially one who works with quantitative data like I do, quantitative
[00:19:32.520 --> 00:19:38.200]   and qualitative, but I'm a data driven futurist, we don't make predictions.
[00:19:38.200 --> 00:19:39.560]   The math doesn't work out.
[00:19:39.560 --> 00:19:40.880]   There's too many variables.
[00:19:40.880 --> 00:19:48.360]   So our job is not to predict, but rather to reduce uncertainty so that we're prepared.
[00:19:48.360 --> 00:19:52.360]   And so a lot of what we do is trying to figure out if X happens, then what?
[00:19:52.360 --> 00:19:56.160]   And we gather signal from lots, signal data from all different places and sort of start
[00:19:56.160 --> 00:19:58.200]   triangulating and figuring things out.
[00:19:58.200 --> 00:20:05.080]   Now, I bring this up because several years ago, I kept building models that pointed to
[00:20:05.080 --> 00:20:08.720]   what I saw as the beginning of the end of smartphones.
[00:20:08.720 --> 00:20:13.480]   And I remember telling a bunch of industry folks and tech journalists maybe four years
[00:20:13.480 --> 00:20:18.400]   ago, and that was still when a lot of the smartphones, new penetration rate was still
[00:20:18.400 --> 00:20:20.320]   climbing and people were still excited.
[00:20:20.320 --> 00:20:22.080]   They were still interesting cameras.
[00:20:22.080 --> 00:20:27.240]   And I kept saying, sometime around late 2019, if not earlier, we're going to start to see
[00:20:27.240 --> 00:20:29.360]   a decline.
[00:20:29.360 --> 00:20:32.800]   And here we are, the most exciting phones are...
[00:20:32.800 --> 00:20:38.560]   Is this ask of our ridiculous thing?
[00:20:38.560 --> 00:20:41.200]   And then there's the one that came out in China, which is the trifold.
[00:20:41.200 --> 00:20:42.200]   I forget.
[00:20:42.200 --> 00:20:43.200]   It's like a THC or T...
[00:20:43.200 --> 00:20:45.960]   Is it Xiaomi or ZTE maybe?
[00:20:45.960 --> 00:20:46.960]   TCL.
[00:20:46.960 --> 00:20:47.960]   TCL.
[00:20:47.960 --> 00:20:48.960]   That's right.
[00:20:48.960 --> 00:20:49.960]   TCL just did one.
[00:20:49.960 --> 00:20:50.960]   Yeah.
[00:20:50.960 --> 00:20:51.960]   Yeah.
[00:20:51.960 --> 00:20:56.520]   So what's happening is there's just not a lot more compute.
[00:20:56.520 --> 00:21:00.320]   There's not a lot more features and compute, compact into that single device.
[00:21:00.320 --> 00:21:01.320]   So if like...
[00:21:01.320 --> 00:21:02.320]   If you're...
[00:21:02.320 --> 00:21:05.400]   If you're going back in time, like get in a time machine and go back to the year like
[00:21:05.400 --> 00:21:12.400]   1999, you know, I know that I was at that point living in Japan and I had a Dokomo...
[00:21:12.400 --> 00:21:13.400]   And I'm...
[00:21:13.400 --> 00:21:18.080]   It was called an IMOD, which was connected to the internet, took photos, was a smartphone
[00:21:18.080 --> 00:21:24.320]   for that point in a world in which the Nokia analog phones were pretty popular.
[00:21:24.320 --> 00:21:25.320]   Yeah.
[00:21:25.320 --> 00:21:26.320]   Yeah.
[00:21:26.320 --> 00:21:27.920]   But I was carrying that.
[00:21:27.920 --> 00:21:32.720]   I had a Toshiba satellite pro that was 15 pounds and doubled as a self-defense weapon.
[00:21:32.720 --> 00:21:35.920]   I had a mini-disc player.
[00:21:35.920 --> 00:21:39.360]   I had a digital camera that still used to floppy.
[00:21:39.360 --> 00:21:41.920]   So we're carrying around all this stuff.
[00:21:41.920 --> 00:21:45.400]   And if you were to go back at that point and say, "Guess what?
[00:21:45.400 --> 00:21:47.840]   In about two decades, we're going to have this convergence.
[00:21:47.840 --> 00:21:51.280]   We're going to have all that compute, all that functionality, everything else in a single
[00:21:51.280 --> 00:21:53.320]   Star Trek device."
[00:21:53.320 --> 00:21:56.080]   Most people would have been like, "There's no way."
[00:21:56.080 --> 00:22:02.480]   Now, as I'm saying, listen, we've seen peak, we're heading down in the other direction.
[00:22:02.480 --> 00:22:07.680]   On the other side of this is another divergence where we have connected glasses and rings,
[00:22:07.680 --> 00:22:12.640]   and all these other things where more of the compute is starting to be done at the edge,
[00:22:12.640 --> 00:22:16.160]   some of it's at the cloud, but that phone is going to start retreating back.
[00:22:16.160 --> 00:22:23.160]   I get a lot of pushback on that, but we're starting to see some of that anyhow.
[00:22:23.160 --> 00:22:26.360]   And I think that's why I think we have folding phones.
[00:22:26.360 --> 00:22:32.400]   So you're not doing predictions, but I remember when you consulted the first, was it first
[00:22:32.400 --> 00:22:33.400]   man?
[00:22:33.400 --> 00:22:34.760]   Oh, yeah, yeah.
[00:22:34.760 --> 00:22:35.960]   So that's a little different.
[00:22:35.960 --> 00:22:37.760]   So the first, you mean the show?
[00:22:37.760 --> 00:22:38.760]   Yeah.
[00:22:38.760 --> 00:22:40.600]   They do a lot of different Hollywood shows.
[00:22:40.600 --> 00:22:42.800]   And so this is a show that's in the near future.
[00:22:42.800 --> 00:22:46.920]   They're going to Mars, and they had the glasses you described.
[00:22:46.920 --> 00:22:50.360]   In fact, they would share content.
[00:22:50.360 --> 00:22:53.720]   Let me show you something and they throw it over to the other person's glasses.
[00:22:53.720 --> 00:22:54.720]   So that's different.
[00:22:54.720 --> 00:22:56.960]   That is a prediction in a sense.
[00:22:56.960 --> 00:23:04.000]   No, actually that one's not either because one of the models that we built shows that,
[00:23:04.000 --> 00:23:10.760]   and again, like I know everybody loves to say no on this one, but we're looking at connected
[00:23:10.760 --> 00:23:13.120]   glasses as the thing that comes next.
[00:23:13.120 --> 00:23:18.600]   There's a bunch of reasons for that, and I wouldn't look at Google Glass 2, which was
[00:23:18.600 --> 00:23:21.920]   really never intended as a consumer device at scale.
[00:23:21.920 --> 00:23:27.920]   I wouldn't look at that as precedent for what comes next, but there's a couple of factors.
[00:23:27.920 --> 00:23:31.240]   One, there's a bunch of new eye tracking technology.
[00:23:31.240 --> 00:23:36.200]   I had the HoloLens 2 on a couple of weeks ago, a couple of months ago actually.
[00:23:36.200 --> 00:23:40.760]   And there's some significant developments in machine reading comprehension and sort of
[00:23:40.760 --> 00:23:46.080]   being able to track your eyes as they move so that there's this automated scrolling system
[00:23:46.080 --> 00:23:47.920]   that they built, which is pretty amazing.
[00:23:47.920 --> 00:23:50.480]   So stuff happening there.
[00:23:50.480 --> 00:23:55.880]   There's an accelerating factor because most people in America now need glasses.
[00:23:55.880 --> 00:24:00.600]   We're all nearsighted, and it's in part because we're looking near and far constantly.
[00:24:00.600 --> 00:24:05.440]   People may not be willing to admit it, but most people need glasses now.
[00:24:05.440 --> 00:24:10.760]   So we've got all these accelerating factors that point to a future in which glasses start
[00:24:10.760 --> 00:24:14.520]   to take more precedence over phones.
[00:24:14.520 --> 00:24:20.120]   And I think it's telling that Amazon's glasses don't actually have interactive lenses.
[00:24:20.120 --> 00:24:25.240]   So what are they called to Echo or I forget Amazon's with the name of the glasses?
[00:24:25.240 --> 00:24:28.760]   Sure, the word "ecos" in there are A-word is in there.
[00:24:28.760 --> 00:24:35.880]   Right, so those glasses are meant to allow you to talk to Alexa using an earpiece.
[00:24:35.880 --> 00:24:40.720]   If you remember when Glass came out, everybody was talking, calling the people who were them
[00:24:40.720 --> 00:24:46.640]   in Glassholes, and everybody was pretty upset about the idea of constantly being potentially
[00:24:46.640 --> 00:24:49.840]   videoed or photographed.
[00:24:49.840 --> 00:24:53.200]   Amazon has very much gone the opposite direction by saying these are actually glasses to help
[00:24:53.200 --> 00:24:55.520]   you hear or not see.
[00:24:55.520 --> 00:25:01.800]   And I think that's interesting because I think it will start to help pave the way for a very
[00:25:01.800 --> 00:25:08.480]   near future in which we're more comfortable with potentially being continuously surveilled
[00:25:08.480 --> 00:25:09.480]   by everybody else.
[00:25:09.480 --> 00:25:14.000]   Well, that's another thing the virus has brought us.
[00:25:14.000 --> 00:25:19.480]   Mark, do you, I mean, Mark, as if anybody, he is on top of the smartphone revolution.
[00:25:19.480 --> 00:25:20.600]   Do you think we've reached peak phone?
[00:25:20.600 --> 00:25:21.600]   You must.
[00:25:21.600 --> 00:25:24.840]   Yeah, so there's a lot in there.
[00:25:24.840 --> 00:25:28.680]   I made a video less than a month ago called "Are We at Peak Smart Phone?"
[00:25:28.680 --> 00:25:33.120]   And that sort of goes through that idea where, like you mentioned, like we had three or four
[00:25:33.120 --> 00:25:39.400]   or five separate devices to take pictures and to listen to the radio and to have all
[00:25:39.400 --> 00:25:40.400]   these different things.
[00:25:40.400 --> 00:25:41.400]   And then they all converged.
[00:25:41.400 --> 00:25:44.680]   And suddenly you have one device that can do all these things.
[00:25:44.680 --> 00:25:47.200]   And then they improve year over year over year.
[00:25:47.200 --> 00:25:48.240]   And looking back at that...
[00:25:48.240 --> 00:25:49.240]   They can improve incrementally.
[00:25:49.240 --> 00:25:50.240]   That's the problem, right?
[00:25:50.240 --> 00:25:51.240]   It's minor.
[00:25:51.240 --> 00:25:52.240]   And slower and slower.
[00:25:52.240 --> 00:25:56.040]   So you add first, the difference between the first camera and a smartphone and the second
[00:25:56.040 --> 00:25:58.480]   and third camera and smartphone was big.
[00:25:58.480 --> 00:26:02.320]   And now, you know, you're going from the iPhone 10 to the 11 and that difference is
[00:26:02.320 --> 00:26:03.400]   very, very small.
[00:26:03.400 --> 00:26:05.960]   It's still impressive that it's getting better at all.
[00:26:05.960 --> 00:26:09.640]   But now, like you mentioned, it's incremental.
[00:26:09.640 --> 00:26:15.400]   For maybe it's because I'm younger or just not very future looking, because I hear your
[00:26:15.400 --> 00:26:17.560]   perspective on the data.
[00:26:17.560 --> 00:26:25.320]   But I've always seen smartphones as like, as I guess an end product.
[00:26:25.320 --> 00:26:28.680]   I guess I don't really see a world where they start to recede yet.
[00:26:28.680 --> 00:26:33.040]   They just continue to get better and more prevalent and more available and more commoditized.
[00:26:33.040 --> 00:26:35.360]   Those are going both up and down at the same time.
[00:26:35.360 --> 00:26:39.000]   So they're sort of stratifying a bit so people can get in at a lower entry point.
[00:26:39.000 --> 00:26:42.720]   But now there's more leverage in between to get to the better smartphones and the tech
[00:26:42.720 --> 00:26:43.720]   of the bleeding edge.
[00:26:43.720 --> 00:26:44.720]   It gets better.
[00:26:44.720 --> 00:26:47.680]   You know, the whole thing keeps evolving year over year.
[00:26:47.680 --> 00:26:48.680]   And I keep seeing that.
[00:26:48.680 --> 00:26:53.280]   And the more I see that, the less I think about smartphones going away.
[00:26:53.280 --> 00:26:57.600]   Except that the all-bed data show that they are.
[00:26:57.600 --> 00:27:01.240]   Well, people, the sales have plateaued.
[00:27:01.240 --> 00:27:02.240]   But that's saturation.
[00:27:02.240 --> 00:27:04.240]   Everybody who wanted one has one.
[00:27:04.240 --> 00:27:06.960]   Yeah, so this is why I have to.
[00:27:06.960 --> 00:27:08.120]   Yeah.
[00:27:08.120 --> 00:27:15.440]   So again, this is where it's good to confront cherished beliefs.
[00:27:15.440 --> 00:27:19.680]   So the saturation rate has reached a particular point.
[00:27:19.680 --> 00:27:22.880]   People are still spending money, but they're spending money on different parts of the ecosystem.
[00:27:22.880 --> 00:27:29.680]   So, you know, the whole entire thing is starting to shift and change.
[00:27:29.680 --> 00:27:33.160]   And quite frankly, when Apple announced whenever it was that they're going to stop releasing
[00:27:33.160 --> 00:27:35.640]   their quarterly sales, you know, company doesn't.
[00:27:35.640 --> 00:27:40.520]   So again, like I work with big huge companies for a living.
[00:27:40.520 --> 00:27:46.360]   When a company announces that it's no longer going to release its quarterly sales figures,
[00:27:46.360 --> 00:27:51.080]   usually it's not because they're hiding the fact that they're beating, you know, analyst
[00:27:51.080 --> 00:27:52.400]   expectations.
[00:27:52.400 --> 00:28:00.640]   Well, data point, it's not just in phones, magically, but apparently for sale.
[00:28:00.640 --> 00:28:04.720]   They're looking for somebody to get them out of this as quickly as possible.
[00:28:04.720 --> 00:28:06.760]   Augmented realities, this is from Bloomberg.
[00:28:06.760 --> 00:28:10.280]   Augmented realities start up magically to explore a sale.
[00:28:10.280 --> 00:28:13.400]   They raise $2 billion.
[00:28:13.400 --> 00:28:17.080]   People think it might go for as much as $10 billion.
[00:28:17.080 --> 00:28:21.880]   But why would you seek a sale if things were still rosy?
[00:28:21.880 --> 00:28:26.800]   Well, there's a couple of other pieces of information that I think are relevant here.
[00:28:26.800 --> 00:28:33.000]   One, I think that JP Morgan now is holding their patents as collateral.
[00:28:33.000 --> 00:28:35.400]   Oh, that's interesting.
[00:28:35.400 --> 00:28:37.360]   Were they one of the investors?
[00:28:37.360 --> 00:28:41.400]   I don't know if they were one of the original investors, but somehow they got the patents.
[00:28:41.400 --> 00:28:42.640]   I've been down there.
[00:28:42.640 --> 00:28:43.640]   I visited them.
[00:28:43.640 --> 00:28:45.280]   I know you are a bullish.
[00:28:45.280 --> 00:28:47.360]   You have been always consistently bullish.
[00:28:47.360 --> 00:28:49.480]   You even told me it's not what you think it is.
[00:28:49.480 --> 00:28:52.880]   It's better than you think, because I tried the developer version.
[00:28:52.880 --> 00:28:55.440]   I thought, well, this isn't.
[00:28:55.440 --> 00:28:58.960]   When we're talking about the technology itself, I stand by that.
[00:28:58.960 --> 00:29:02.240]   The problem is, of course, you've got technology and then you have the business of running
[00:29:02.240 --> 00:29:03.680]   a company.
[00:29:03.680 --> 00:29:09.200]   What they're working on is it needs a very long runway.
[00:29:09.200 --> 00:29:11.040]   They have a consumer.
[00:29:11.040 --> 00:29:16.680]   The product that they have is nowhere near being ready for wide-scale use.
[00:29:16.680 --> 00:29:23.880]   When I compare leap to the HoloLens 2, which is very much ready for the enterprise and
[00:29:23.880 --> 00:29:27.880]   not intended as a consumer device, those things are different.
[00:29:27.880 --> 00:29:35.440]   The problem is when you're working on a groundbreaking technology that really, truly functions differently
[00:29:35.440 --> 00:29:40.560]   than is something new, it needs time.
[00:29:40.560 --> 00:29:43.400]   The markets doesn't allow time.
[00:29:43.400 --> 00:29:45.480]   The tech press doesn't allow time.
[00:29:45.480 --> 00:29:49.480]   This is a company that has had some financial and personnel issues as a result.
[00:29:49.480 --> 00:29:51.560]   It doesn't need a bit of a bad.
[00:29:51.560 --> 00:29:54.680]   It's more of a research project.
[00:29:54.680 --> 00:30:00.680]   One that, like many research projects, I would consider what they're doing basic research.
[00:30:00.680 --> 00:30:05.280]   In this country, we do not have a federal government really interested right now in
[00:30:05.280 --> 00:30:07.880]   funding basic research.
[00:30:07.880 --> 00:30:13.840]   The kinds of stuff they're working on, spatial computing, extended reality, using data at
[00:30:13.840 --> 00:30:17.760]   scale in ways we've really not seen before.
[00:30:17.760 --> 00:30:21.760]   It's tough to fund that if you've got investors who expect a quick return.
[00:30:21.760 --> 00:30:23.760]   You agree, Marcus?
[00:30:23.760 --> 00:30:24.760]   Yes.
[00:30:24.760 --> 00:30:28.120]   Every time you bring up investors, they always want the quickest return.
[00:30:28.120 --> 00:30:29.880]   A lot of times I compromise as the product.
[00:30:29.880 --> 00:30:31.480]   I'm always interested in the product.
[00:30:31.480 --> 00:30:36.040]   That's my big focus is make the product as good as possible and hopefully the rest will
[00:30:36.040 --> 00:30:37.960]   follow, but business is doing it as work that way.
[00:30:37.960 --> 00:30:41.760]   So you end up compromising the product in order to please investors and things like that.
[00:30:41.760 --> 00:30:43.040]   Furthermore, there's a risk.
[00:30:43.040 --> 00:30:45.000]   I think we saw that with Google Glass.
[00:30:45.000 --> 00:30:46.640]   We saw it with the Segway.
[00:30:46.640 --> 00:30:50.960]   I think we're seeing with folding phones that if the first products in a category don't
[00:30:50.960 --> 00:30:55.520]   live up to their hype, then people might write off the whole category.
[00:30:55.520 --> 00:31:01.280]   It's interesting you're defending wearable glasses by saying it's not Google Glass.
[00:31:01.280 --> 00:31:04.440]   I guess now we'll have to say it's not Magic Leap.
[00:31:04.440 --> 00:31:08.680]   But that can, in the mind of consumers, that can kill a product.
[00:31:08.680 --> 00:31:12.200]   Chris, the Segway, you look so stupid on that.
[00:31:12.200 --> 00:31:14.920]   It was over.
[00:31:14.920 --> 00:31:17.000]   The problem is we are conflating.
[00:31:17.000 --> 00:31:23.360]   If I hear or see one more, oh, I guess it'll be a while before we see conference schedules,
[00:31:23.360 --> 00:31:31.560]   but if I see one more time, AR/VR written together as though they're the same thing,
[00:31:31.560 --> 00:31:35.000]   augmented reality and virtual reality are fundamentally different.
[00:31:35.000 --> 00:31:39.400]   We have said that like crazy, Microsoft keeps saying mixed reality as if they're the same
[00:31:39.400 --> 00:31:40.400]   thing.
[00:31:40.400 --> 00:31:41.400]   They're not.
[00:31:41.400 --> 00:31:42.400]   No.
[00:31:42.400 --> 00:31:48.200]   That starts to change our understanding of things and certainly consumer expectations.
[00:31:48.200 --> 00:31:53.640]   Magic Leap is not a VR device.
[00:31:53.640 --> 00:31:56.960]   It doesn't do a lot right now.
[00:31:56.960 --> 00:31:59.600]   All of the compute is done on your body.
[00:31:59.600 --> 00:32:01.680]   HoloLens is something very, very different.
[00:32:01.680 --> 00:32:03.520]   These are all different types of devices.
[00:32:03.520 --> 00:32:08.320]   It just so happens that we put them on over our faces.
[00:32:08.320 --> 00:32:14.560]   But that, again, we have to start meshing our expectations with the reality of what's
[00:32:14.560 --> 00:32:16.560]   being built and how it's produced.
[00:32:16.560 --> 00:32:19.400]   Carson's introducing a new product we put on our faces.
[00:32:19.400 --> 00:32:23.000]   This is the new plague, Dr. Mask.
[00:32:23.000 --> 00:32:24.000]   What do you think?
[00:32:24.000 --> 00:32:25.000]   You like it?
[00:32:25.000 --> 00:32:27.920]   Carson made me this.
[00:32:27.920 --> 00:32:29.800]   My producer is insane.
[00:32:29.800 --> 00:32:34.000]   It is a lovely pleather mask.
[00:32:34.000 --> 00:32:37.560]   I chose not to wear it for the show today, but I just want to show you.
[00:32:37.560 --> 00:32:42.000]   Marcus, with the folding phones, everyone we've seen so far has been kind of a disappointment,
[00:32:42.000 --> 00:32:43.840]   not merely the Escobar.
[00:32:43.840 --> 00:32:46.040]   Did you like the Z Flip?
[00:32:46.040 --> 00:32:47.040]   Was there anything?
[00:32:47.040 --> 00:32:50.640]   Is this a category that's being made up by companies trying to find something different
[00:32:50.640 --> 00:32:54.000]   or are consumers demanding it?
[00:32:54.000 --> 00:32:55.720]   It's definitely closer to the first thing.
[00:32:55.720 --> 00:32:59.240]   I've tried maybe six or seven folding phones now.
[00:32:59.240 --> 00:33:05.040]   I think the Z Flip is the closest to one that you could conceive a regular person finding
[00:33:05.040 --> 00:33:06.880]   a good idea.
[00:33:06.880 --> 00:33:11.760]   But I think it is still coming from companies grasping at maybe there's something here.
[00:33:11.760 --> 00:33:16.720]   Maybe there's something to a bigger screen folding down into a smaller form factor.
[00:33:16.720 --> 00:33:20.440]   But then there's so many different ways to maybe do that.
[00:33:20.440 --> 00:33:27.880]   Folding in with an outside screen, folding out around a hinge, folding with a weird hinge
[00:33:27.880 --> 00:33:28.880]   in the center.
[00:33:28.880 --> 00:33:30.880]   There's a bunch of different experiments for all the...
[00:33:30.880 --> 00:33:34.280]   I think the duo and the Neo, these Microsoft dual screens with a hinge.
[00:33:34.280 --> 00:33:35.280]   Dual screen.
[00:33:35.280 --> 00:33:36.280]   Might be a way to do.
[00:33:36.280 --> 00:33:40.120]   I think part of the problem with everything I've seen so far is that bendable screens
[00:33:40.120 --> 00:33:42.040]   just really aren't very good.
[00:33:42.040 --> 00:33:44.120]   Yeah, those are super early.
[00:33:44.120 --> 00:33:45.120]   That's why...
[00:33:45.120 --> 00:33:46.120]   Go ahead, Marcus.
[00:33:46.120 --> 00:33:47.120]   Yeah.
[00:33:47.120 --> 00:33:49.000]   I'm really interested in seeing those when they come out.
[00:33:49.000 --> 00:33:50.440]   They say holiday 2020.
[00:33:50.440 --> 00:33:51.880]   We'll see if that actually happens.
[00:33:51.880 --> 00:33:57.520]   But those, since they don't rely on a flexible single display, they can do a lot more with
[00:33:57.520 --> 00:34:01.880]   a hinge in the middle, a battery on each side, and then software that sort of runs like dual
[00:34:01.880 --> 00:34:07.800]   screen software, which seems a lot easier to get right off the bat and actually offer
[00:34:07.800 --> 00:34:12.400]   an advantage than something totally new, like a screen folding in half.
[00:34:12.400 --> 00:34:14.400]   Google already has support for that in Android.
[00:34:14.400 --> 00:34:22.280]   Microsoft's doing a new Windows 10X that actually is really much more than just for a duo or
[00:34:22.280 --> 00:34:23.280]   Neo device.
[00:34:23.280 --> 00:34:27.320]   It's really about reinventing Windows, but they don't want to scare people.
[00:34:27.320 --> 00:34:30.440]   It's, in my opinion, we've been talking on Windows Weekly about this too with Paul and
[00:34:30.440 --> 00:34:36.080]   Mary Jo, that they're going to put it on the Neo, they say this Windows 10X, it's basically
[00:34:36.080 --> 00:34:39.440]   a containerized version of Windows, is only...
[00:34:39.440 --> 00:34:41.520]   We're making it for this new device.
[00:34:41.520 --> 00:34:46.720]   But ultimately, this is the future of Windows, which I think is kind of interesting.
[00:34:46.720 --> 00:34:50.960]   I like the idea of a book device.
[00:34:50.960 --> 00:34:52.120]   I don't know.
[00:34:52.120 --> 00:34:54.280]   What about one that's retractable?
[00:34:54.280 --> 00:34:55.280]   So...
[00:34:55.280 --> 00:34:57.080]   Where would it retract?
[00:34:57.080 --> 00:34:58.080]   So...
[00:34:58.080 --> 00:35:00.160]   Where's it going?
[00:35:00.160 --> 00:35:02.360]   So there's the...
[00:35:02.360 --> 00:35:03.360]   I've seen...
[00:35:03.360 --> 00:35:07.280]   Over the years, I've seen different prototypes in people playing with different types of
[00:35:07.280 --> 00:35:08.280]   phones.
[00:35:08.280 --> 00:35:12.040]   And one is sort of unfolding.
[00:35:12.040 --> 00:35:16.400]   The other one is having something embedded where you can extend that screen out.
[00:35:16.400 --> 00:35:19.400]   So sort of pull it out this way.
[00:35:19.400 --> 00:35:20.400]   Yeah.
[00:35:20.400 --> 00:35:27.320]   Again, my question is always, what is this additional real estate providing us?
[00:35:27.320 --> 00:35:29.600]   What is the solving for?
[00:35:29.600 --> 00:35:35.040]   Are we anticipating that people are going to somehow multitask and have a video, like
[00:35:35.040 --> 00:35:39.880]   a YouTube video on one screen and you're doing something on social or you're being productive
[00:35:39.880 --> 00:35:40.880]   on another screen?
[00:35:40.880 --> 00:35:45.440]   Or is it that people really desire much more real estate?
[00:35:45.440 --> 00:35:46.440]   I don't...
[00:35:46.440 --> 00:35:48.960]   Again, I just don't see that...
[00:35:48.960 --> 00:35:52.560]   I don't know that the answer to those questions are yes.
[00:35:52.560 --> 00:35:54.640]   That happens in this business, though.
[00:35:54.640 --> 00:35:58.880]   Things are sometimes driven by the market, but much more often driven by a company that
[00:35:58.880 --> 00:36:01.440]   has to find the next big thing.
[00:36:01.440 --> 00:36:06.400]   Yeah, sometimes you're sort of searching for it and find it without anyone asking for
[00:36:06.400 --> 00:36:07.400]   it.
[00:36:07.400 --> 00:36:13.800]   For me, it's always been fundamentally people generally like having a bigger screen to do
[00:36:13.800 --> 00:36:19.560]   more things, whether it's watching a video or typing, email, whatever it is.
[00:36:19.560 --> 00:36:23.680]   But the bigger a screen you have, the bigger of a device you have and the more difficult
[00:36:23.680 --> 00:36:29.640]   it is to hold and to putting your pocket and to put a case on and all that stuff.
[00:36:29.640 --> 00:36:34.840]   So fundamentally shrinking the size of it down when you're not using the big screen
[00:36:34.840 --> 00:36:38.440]   and then expanding it out when you need it seems like a good idea.
[00:36:38.440 --> 00:36:42.760]   But again, how you do it exactly is sort of up for grabs.
[00:36:42.760 --> 00:36:45.320]   Let's take a little break and there's lots more to talk about.
[00:36:45.320 --> 00:36:51.920]   Amy, I have your future today institutes Tech Trends report for 2020 in front of me, the
[00:36:51.920 --> 00:36:53.680]   13th annual edition.
[00:36:53.680 --> 00:36:56.840]   Maybe we go through some of the highlights.
[00:36:56.840 --> 00:37:02.360]   You have some basic, I think what is it, one, two, three, nine basic insights and maybe
[00:37:02.360 --> 00:37:03.960]   we'll go through some of those.
[00:37:03.960 --> 00:37:04.960]   Amy Webb is here.
[00:37:04.960 --> 00:37:09.880]   She's our futurist first met her when she came out with her.
[00:37:09.880 --> 00:37:11.320]   Was it your first book?
[00:37:11.320 --> 00:37:13.480]   Yeah, it must have been years ago.
[00:37:13.480 --> 00:37:15.440]   That was my second book actually.
[00:37:15.440 --> 00:37:17.840]   No, I didn't know you were your first book.
[00:37:17.840 --> 00:37:21.440]   But first book was about how I hacked a dating website.
[00:37:21.440 --> 00:37:23.280]   That was a book because I saw the TED talk.
[00:37:23.280 --> 00:37:24.280]   Oh, that's funny.
[00:37:24.280 --> 00:37:25.280]   Yeah, it was a play book.
[00:37:25.280 --> 00:37:26.280]   And now it's a movie.
[00:37:26.280 --> 00:37:27.280]   It's not going to be a movie.
[00:37:27.280 --> 00:37:28.280]   What?
[00:37:28.280 --> 00:37:29.280]   Yeah.
[00:37:29.280 --> 00:37:31.920]   So the first book I knew about was The Signals are Talking.
[00:37:31.920 --> 00:37:35.880]   But I see before that data, a love story, is that it?
[00:37:35.880 --> 00:37:36.880]   That is it.
[00:37:36.880 --> 00:37:43.720]   That is the story of how I manipulated the algorithms without breaking the terms of service on a
[00:37:43.720 --> 00:37:45.960]   dating website and that's how I met my husband.
[00:37:45.960 --> 00:37:46.960]   It worked.
[00:37:46.960 --> 00:37:47.960]   That's amazing.
[00:37:47.960 --> 00:37:49.440]   She takes a drink.
[00:37:49.440 --> 00:37:50.440]   It works.
[00:37:50.440 --> 00:37:53.960]   And that's my friends is how I met my husband.
[00:37:53.960 --> 00:37:54.960]   Drink.
[00:37:54.960 --> 00:37:56.960]   It worked.
[00:37:56.960 --> 00:37:58.120]   Data, a love story.
[00:37:58.120 --> 00:38:00.720]   Now I got to read that because I love everything else you've written.
[00:38:00.720 --> 00:38:04.560]   The Signals are Talking was the first book I knew you about.
[00:38:04.560 --> 00:38:10.280]   And of course, The Big Nine most recently, all about the batfangs or what are they called
[00:38:10.280 --> 00:38:11.280]   the?
[00:38:11.280 --> 00:38:12.280]   The G-Mafia.
[00:38:12.280 --> 00:38:13.280]   G-Mafia.
[00:38:13.280 --> 00:38:16.680]   I call them the batfangs.
[00:38:16.680 --> 00:38:22.160]   How tech titans and their thinking machines could warp humanity.
[00:38:22.160 --> 00:38:26.920]   So with this, as far as I'm concerned, the number one star on YouTube, you could take
[00:38:26.920 --> 00:38:34.320]   your PewDiePie's and smoke them because we got Marcus Brownley here, MKBHD.
[00:38:34.320 --> 00:38:36.320]   Kind of my hero.
[00:38:36.320 --> 00:38:38.200]   And you've done so well.
[00:38:38.200 --> 00:38:39.200]   It's so great.
[00:38:39.200 --> 00:38:42.640]   Have you ever played Segway Frisbee?
[00:38:42.640 --> 00:38:43.640]   Segway Frisbee.
[00:38:43.640 --> 00:38:48.240]   I'm making that up right out of nowhere because I know you're a championship Frisbee.
[00:38:48.240 --> 00:38:49.240]   What is it?
[00:38:49.240 --> 00:38:50.240]   Frisbee golf?
[00:38:50.240 --> 00:38:51.240]   What do you play?
[00:38:51.240 --> 00:38:52.240]   It was ultimate.
[00:38:52.240 --> 00:38:53.240]   That's right.
[00:38:53.240 --> 00:38:54.240]   Yeah.
[00:38:54.240 --> 00:38:56.760]   See, I think you could do that in Segways.
[00:38:56.760 --> 00:38:57.760]   Sounds incredible.
[00:38:57.760 --> 00:38:58.760]   As long as you don't crash.
[00:38:58.760 --> 00:39:00.560]   Oh, that's the fun of it.
[00:39:00.560 --> 00:39:02.360]   Oh, I see.
[00:39:02.360 --> 00:39:04.960]   Waz used to play Segway Polo.
[00:39:04.960 --> 00:39:07.960]   Same idea, except you had a hammer.
[00:39:07.960 --> 00:39:08.960]   Wow.
[00:39:08.960 --> 00:39:09.960]   Yeah.
[00:39:09.960 --> 00:39:11.760]   But that's for later.
[00:39:11.760 --> 00:39:15.200]   That's for your golden years.
[00:39:15.200 --> 00:39:16.400]   Save that.
[00:39:16.400 --> 00:39:18.120]   You can still run around pretty good.
[00:39:18.120 --> 00:39:20.360]   I showed today brought to you by Worldwide Tech.
[00:39:20.360 --> 00:39:21.360]   We were in St. Louis.
[00:39:21.360 --> 00:39:22.360]   We tried to get Amy to come out.
[00:39:22.360 --> 00:39:23.640]   She was booked.
[00:39:23.640 --> 00:39:25.880]   But this was such a fun event we did in St. Louis.
[00:39:25.880 --> 00:39:26.880]   I wanted to be there.
[00:39:26.880 --> 00:39:28.400]   Oh, it was so great.
[00:39:28.400 --> 00:39:30.440]   Well, next time, we'd love to have you.
[00:39:30.440 --> 00:39:31.440]   Yeah, sure.
[00:39:31.440 --> 00:39:33.960]   Worldwide Tech blew me away.
[00:39:33.960 --> 00:39:36.080]   So I was not.
[00:39:36.080 --> 00:39:39.000]   It was really dimly in my awareness.
[00:39:39.000 --> 00:39:41.480]   But then we went and we saw the Advanced Technology Center.
[00:39:41.480 --> 00:39:43.000]   This is, I thought, oh, that's nice.
[00:39:43.000 --> 00:39:47.480]   They probably have a room somewhere with no, this is like three buildings, more buildings
[00:39:47.480 --> 00:39:53.440]   all the time, rack after rack of the state of the art technology from the biggest tech
[00:39:53.440 --> 00:39:56.000]   companies and the littlest tech companies.
[00:39:56.000 --> 00:39:57.400]   It is amazing.
[00:39:57.400 --> 00:40:03.000]   Half a billion dollars in equipment, hundreds of OEMs, key partners ranging from high tech
[00:40:03.000 --> 00:40:11.080]   heavyweights like Intel, Dell EMC, HP Enterprise, Cisco, little guys too like Equinix.
[00:40:11.080 --> 00:40:13.240]   Equinix is getting to be a big guy too.
[00:40:13.240 --> 00:40:16.840]   But all, you know, titanium, all sorts of stuff.
[00:40:16.840 --> 00:40:18.200]   WWT is a trusted partner.
[00:40:18.200 --> 00:40:19.320]   They stay with you over the years.
[00:40:19.320 --> 00:40:23.680]   If you are an enterprise and you had to buy enterprise gear, you know about WWT.
[00:40:23.680 --> 00:40:25.680]   But they're not just some distributor.
[00:40:25.680 --> 00:40:27.440]   They help you from day one.
[00:40:27.440 --> 00:40:29.560]   In fact, that's why they built the ATC.
[00:40:29.560 --> 00:40:37.200]   Their engineers use the ATC to build pilots to test a new gear to see if the gear integrates
[00:40:37.200 --> 00:40:38.920]   with the old gear.
[00:40:38.920 --> 00:40:42.920]   What's so cool about the Advanced Technology Center is you can use it to go to their website
[00:40:42.920 --> 00:40:43.920]   and take a look.
[00:40:43.920 --> 00:40:49.440]   There's so much material there, articles, case studies, things that will help you plan
[00:40:49.440 --> 00:40:55.640]   your future in every aspect of enterprise technology.
[00:40:55.640 --> 00:40:57.760]   They even have on demand labs.
[00:40:57.760 --> 00:40:58.760]   You can schedule them.
[00:40:58.760 --> 00:41:03.520]   You don't have to be in St. Louis 24/7 from anywhere in the world representing the newest
[00:41:03.520 --> 00:41:07.400]   advances in multi-cloud architecture and artificial intelligence.
[00:41:07.400 --> 00:41:15.560]   IoT solutions built on Intel's platform like the world's only Intel FPGA acceleration lab.
[00:41:15.560 --> 00:41:20.840]   Intel Selects solution labs for technologies like VMware V-SAN, cutting-edge solutions
[00:41:20.840 --> 00:41:24.800]   based on Intel's second-generation Xeon scalable processors.
[00:41:24.800 --> 00:41:30.720]   And I've always, I guess they called it Crossfire at first rate, but when they announced Optane,
[00:41:30.720 --> 00:41:32.160]   I was so excited.
[00:41:32.160 --> 00:41:36.040]   The new tier of Optane data center persistent memories out and you can try it.
[00:41:36.040 --> 00:41:38.840]   You could test it at the lab.
[00:41:38.840 --> 00:41:40.680]   It is amazing.
[00:41:40.680 --> 00:41:42.720]   WWT's engineers work in these labs every day.
[00:41:42.720 --> 00:41:44.880]   If I can go in, it was so cool.
[00:41:44.880 --> 00:41:49.120]   And engineers going in and he said, "Leo, I'm in this lab because of you.
[00:41:49.120 --> 00:41:51.800]   I started watching the screensavers on tech TV.
[00:41:51.800 --> 00:41:54.440]   It made me a geek and now I'm here working in the lab.
[00:41:54.440 --> 00:41:56.480]   Met a lot of people in the labs.
[00:41:56.480 --> 00:41:57.480]   They're in their date.
[00:41:57.480 --> 00:41:58.960]   I said, "You have the best job in the world."
[00:41:58.960 --> 00:41:59.960]   They said, "Yeah."
[00:41:59.960 --> 00:42:06.000]   Beta testing edged to cloud solutions based on the latest and greatest Intel technologies.
[00:42:06.000 --> 00:42:07.720]   Building reference architectures.
[00:42:07.720 --> 00:42:13.840]   This is the new ATC ecosystem, a multiplier effect of knowledge, speed, and agility anytime,
[00:42:13.840 --> 00:42:17.440]   anywhere for you, the A-W-W-T customer.
[00:42:17.440 --> 00:42:18.440]   You're not a customer.
[00:42:18.440 --> 00:42:21.560]   You got to go right now to www.wwt.com/twit.
[00:42:21.560 --> 00:42:23.440]   Become a member of their growing community.
[00:42:23.440 --> 00:42:24.520]   Learn about the ATC.
[00:42:24.520 --> 00:42:26.760]   Get to use the labs.
[00:42:26.760 --> 00:42:28.000]   It's just brilliant.
[00:42:28.000 --> 00:42:30.320]   Go to www.wt.com/twit.
[00:42:30.320 --> 00:42:31.320]   Find out.
[00:42:31.320 --> 00:42:32.320]   It's amazing.
[00:42:32.320 --> 00:42:36.800]   www.wt.worldwide technology, delivering business and technology outcomes around the world.
[00:42:36.800 --> 00:42:38.000]   I'm a believer now, man.
[00:42:38.000 --> 00:42:41.360]   Once we went out there, it was mind-ball blowing.
[00:42:41.360 --> 00:42:43.200]   www.wt.com/twit.
[00:42:43.200 --> 00:42:47.840]   2020 Tech Trends Report.
[00:42:47.840 --> 00:42:49.440]   Actually, you didn't answer my question.
[00:42:49.440 --> 00:42:52.640]   I'm going to put it to you again, Amy Webb.
[00:42:52.640 --> 00:42:57.800]   When you talk about viruses like this, I mean, I guess it's been predictable that we have
[00:42:57.800 --> 00:43:01.000]   a pathogen that this would happen.
[00:43:01.000 --> 00:43:02.000]   But it changes everything.
[00:43:02.000 --> 00:43:05.800]   I'm thinking, people are learning how to work at home.
[00:43:05.800 --> 00:43:08.640]   They're learning how to teach online.
[00:43:08.640 --> 00:43:10.560]   They're getting new skills.
[00:43:10.560 --> 00:43:12.560]   They're learning.
[00:43:12.560 --> 00:43:15.480]   Some of this is, of course, we're all hunkering down.
[00:43:15.480 --> 00:43:19.480]   But I don't think the world's going to be the same when we come out of this.
[00:43:19.480 --> 00:43:21.680]   How can you talk about that?
[00:43:21.680 --> 00:43:23.480]   The world's never the same anyways.
[00:43:23.480 --> 00:43:30.480]   We talk about the future in this amorphous way, but really the future is always happening.
[00:43:30.480 --> 00:43:35.800]   The future is simultaneously five seconds, five minutes, five years, 50 years from now.
[00:43:35.800 --> 00:43:38.160]   Very Zen, but it's true.
[00:43:38.160 --> 00:43:44.160]   Well, and the difference here is how we deal with the accelerated rate of change.
[00:43:44.160 --> 00:43:47.400]   But change is always happening.
[00:43:47.400 --> 00:43:53.240]   In some ways, my job really hasn't changed at all from what I would normally be doing.
[00:43:53.240 --> 00:43:56.280]   I'm just considering extra factors.
[00:43:56.280 --> 00:44:01.960]   I think that would be super useful right now because I know everybody is feeling a crushing
[00:44:01.960 --> 00:44:06.160]   sense of anxiety and uncertainty.
[00:44:06.160 --> 00:44:07.160]   Everybody is.
[00:44:07.160 --> 00:44:10.880]   Even the people who seem like they're holding up and they're super strong, somewhere deep
[00:44:10.880 --> 00:44:14.520]   inside, people are wondering what's really going to happen.
[00:44:14.520 --> 00:44:16.120]   There's a lot of anxiety.
[00:44:16.120 --> 00:44:17.120]   Absolutely.
[00:44:17.120 --> 00:44:18.120]   Yeah.
[00:44:18.120 --> 00:44:19.120]   Right.
[00:44:19.120 --> 00:44:22.360]   I would love to share something that I don't really talk about publicly if you're up for
[00:44:22.360 --> 00:44:23.360]   it.
[00:44:23.360 --> 00:44:24.360]   Absolutely.
[00:44:24.360 --> 00:44:25.360]   Having to do with anxiety.
[00:44:25.360 --> 00:44:35.880]   My first night of college, my first class, I was a super huge Star Trek fan and I didn't
[00:44:35.880 --> 00:44:39.600]   realize once you got to college, you could enroll in these things called electives.
[00:44:39.600 --> 00:44:42.240]   I was like, "Oh, I get to take whatever I want.
[00:44:42.240 --> 00:44:43.240]   That's amazing."
[00:44:43.240 --> 00:44:47.960]   So I ran into the first cosmology class that I could find.
[00:44:47.960 --> 00:44:48.960]   I did the same thing.
[00:44:48.960 --> 00:44:54.160]   I did a college seminar because I wanted to know about the really big science.
[00:44:54.160 --> 00:44:58.920]   So like, amazing first night, my professor is showing us these unbelievable photos of
[00:44:58.920 --> 00:45:03.720]   the cosmos and he's trying to get us to think about the universe expanding.
[00:45:03.720 --> 00:45:08.040]   He's going through all of the math, which I didn't have a problem with.
[00:45:08.040 --> 00:45:11.880]   The part that I started to have a problem with was the implications of that math.
[00:45:11.880 --> 00:45:14.520]   Basically, he had lost half the class.
[00:45:14.520 --> 00:45:15.720]   He starts talking about...
[00:45:15.720 --> 00:45:16.720]   Me too.
[00:45:16.720 --> 00:45:21.760]   You never really seen those jelly bean jars where you do the estimation.
[00:45:21.760 --> 00:45:28.600]   He's explaining how cosmologists understand that the universe is expanding and how they
[00:45:28.600 --> 00:45:30.160]   do some of these estimations.
[00:45:30.160 --> 00:45:31.680]   He's going on and on and on.
[00:45:31.680 --> 00:45:37.880]   I'm just picturing literally billions of estimation jelly bean jars to the point at which I'm like,
[00:45:37.880 --> 00:45:48.360]   "Look, if there's 10 to 100 or so potentially billion galaxies, I started as I'm thinking
[00:45:48.360 --> 00:45:52.200]   about all of the stars and all the planets and all of the stuff and potentially all the
[00:45:52.200 --> 00:45:56.320]   other life forms and all of that information."
[00:45:56.320 --> 00:46:01.920]   It was as though within seconds everything was changing and I couldn't breathe.
[00:46:01.920 --> 00:46:02.920]   I started...
[00:46:02.920 --> 00:46:08.080]   My tongue started to go numb in the back of my throat and my pulse was racing and I thought
[00:46:08.080 --> 00:46:11.160]   I was having a heart attack and I was like, "I'm 18 years old.
[00:46:11.160 --> 00:46:15.080]   I'm going to die on my first day of college."
[00:46:15.080 --> 00:46:20.080]   And then I blacked out.
[00:46:20.080 --> 00:46:21.080]   Oh my God.
[00:46:21.080 --> 00:46:26.760]   When I came to, I was told that I had had a panic attack, which I had never had.
[00:46:26.760 --> 00:46:30.280]   For anybody who's ever had a panic attack and there are probably more people having them
[00:46:30.280 --> 00:46:36.880]   now than in the past, as much as it feels like you were going to die when it happens,
[00:46:36.880 --> 00:46:38.720]   that's actually not the worst part.
[00:46:38.720 --> 00:46:44.400]   The worst part is the aftermath because your brain sort of rewires itself and it starts
[00:46:44.400 --> 00:46:52.400]   looking for those patterns again and you start doing everything you can to avoid uncertainty.
[00:46:52.400 --> 00:46:56.840]   And cognitive behavioral science would tell us that that is not the right approach.
[00:46:56.840 --> 00:47:04.080]   When you are faced with deep uncertainty about the future, the better or just deep anxiety,
[00:47:04.080 --> 00:47:08.440]   you know, whatever it is, the better thing to do, although it feels wrong, like every
[00:47:08.440 --> 00:47:12.680]   cell in your body wants you not to do this, the better thing to do is to lean into that
[00:47:12.680 --> 00:47:19.040]   uncertainty and to observe it while it's happening and to look for patterns and to try to make
[00:47:19.040 --> 00:47:20.680]   sense of it.
[00:47:20.680 --> 00:47:27.560]   Do you think your career has in a sense been a response to that college panic attack?
[00:47:27.560 --> 00:47:28.560]   No.
[00:47:28.560 --> 00:47:34.040]   I actually showed up the following week for class and I went to apologize.
[00:47:34.040 --> 00:47:37.960]   And he, I remember him saying, "It's okay.
[00:47:37.960 --> 00:47:39.560]   You can stay in class.
[00:47:39.560 --> 00:47:42.520]   You probably shouldn't major in this."
[00:47:42.520 --> 00:47:47.280]   And then he went on to tell me that I was not the first person to have a panic attack
[00:47:47.280 --> 00:47:48.280]   the first night of the time.
[00:47:48.280 --> 00:47:53.840]   It's a little bit of a humble brag to say, "I passed out when I found out how big space
[00:47:53.840 --> 00:47:54.840]   was."
[00:47:54.840 --> 00:47:56.400]   Why is that a humble brag?
[00:47:56.400 --> 00:48:01.440]   Because it's like most people have anxiety attacks because the bridge is scary or, you
[00:48:01.440 --> 00:48:04.040]   know, there's a long way down.
[00:48:04.040 --> 00:48:08.040]   You tried to encompass all of space and that you fired your brain.
[00:48:08.040 --> 00:48:09.480]   I got both well and well here.
[00:48:09.480 --> 00:48:14.160]   But I think that what I went through is analogous to my, like to what I think a lot of people
[00:48:14.160 --> 00:48:16.360]   are going through.
[00:48:16.360 --> 00:48:18.120]   You know, I felt overwhelmed.
[00:48:18.120 --> 00:48:19.120]   Yeah.
[00:48:19.120 --> 00:48:23.400]   And I felt overwhelmed because I couldn't make sense of all of those data points.
[00:48:23.400 --> 00:48:24.400]   Right.
[00:48:24.400 --> 00:48:27.720]   And honestly, if we weren't talking about the virus right now, you know, we could be talking
[00:48:27.720 --> 00:48:35.080]   about Saudi Arabia and Russia going head to head in like putting their parts out.
[00:48:35.080 --> 00:48:37.120]   You know what I thought about?
[00:48:37.120 --> 00:48:39.520]   What I thought about is the watchman.
[00:48:39.520 --> 00:48:41.560]   Remember that comic and then there was a TV show?
[00:48:41.560 --> 00:48:42.560]   Do I remember that?
[00:48:42.560 --> 00:48:43.560]   Oh, you were the one.
[00:48:43.560 --> 00:48:44.560]   Yeah.
[00:48:44.560 --> 00:48:45.560]   Yeah.
[00:48:45.560 --> 00:48:46.960]   Oh, she has it in her hand.
[00:48:46.960 --> 00:48:50.320]   You were the one who told me it was one of your favorite novels of all time.
[00:48:50.320 --> 00:48:51.320]   Oh, it's very funny.
[00:48:51.320 --> 00:48:52.880]   And that's why I bought it and read it.
[00:48:52.880 --> 00:48:58.080]   And I don't have, I don't think it's a spoiler at this point to say this, but the world is
[00:48:58.080 --> 00:48:59.080]   at war.
[00:48:59.080 --> 00:49:01.400]   It's in the 80s and we're about to go to nuclear war.
[00:49:01.400 --> 00:49:03.920]   The tensions are heating up to the Soviet Union, the United States.
[00:49:03.920 --> 00:49:11.040]   He's afraid that we're going to have a nuclear war and Ozymandias, one of the superheroes
[00:49:11.040 --> 00:49:15.880]   in the watchman decides to save the world by simulating an alien attack on New York
[00:49:15.880 --> 00:49:17.180]   City.
[00:49:17.180 --> 00:49:24.560]   It kills half the population, but everybody focuses the mind amazingly and everybody's
[00:49:24.560 --> 00:49:29.760]   not thinking about nuclear bombs and started thinking about the aliens and the United.
[00:49:29.760 --> 00:49:31.560]   And it ended the war.
[00:49:31.560 --> 00:49:32.560]   It's a threat.
[00:49:32.560 --> 00:49:33.560]   Okay.
[00:49:33.560 --> 00:49:34.560]   So, but why?
[00:49:34.560 --> 00:49:39.160]   The reason is because in that scene and that part of the book, time is effectively slowed
[00:49:39.160 --> 00:49:40.160]   down.
[00:49:40.160 --> 00:49:42.920]   The reason I love that book is because I love Dr. Manhattan and I don't want to get totally
[00:49:42.920 --> 00:49:48.440]   off the rails here, but Dr. Manhattan experiences time because of a catastrophic chemical failure
[00:49:48.440 --> 00:49:49.720]   like in a different way.
[00:49:49.720 --> 00:49:50.720]   And he never.
[00:49:50.720 --> 00:49:52.720]   It all happens at once simultaneously.
[00:49:52.720 --> 00:49:53.720]   Right.
[00:49:53.720 --> 00:49:58.160]   He can sort of see the past, present and future simultaneously and then chooses not to act.
[00:49:58.160 --> 00:49:59.160]   I'm not that cynical.
[00:49:59.160 --> 00:50:01.520]   I believe we have some agency in what's coming.
[00:50:01.520 --> 00:50:06.560]   But what you do in the process when you are having a panic attack or you're concerned
[00:50:06.560 --> 00:50:11.600]   about having a panic attack again or you're feeling anxious, you know, the thing that you
[00:50:11.600 --> 00:50:16.800]   do is you observe what's happening and you sort of, you know, use a framework or a template
[00:50:16.800 --> 00:50:19.720]   or whatever to gather signals to make sense of things.
[00:50:19.720 --> 00:50:23.800]   And it doesn't mean that you can predict the future and that if you do these things,
[00:50:23.800 --> 00:50:26.320]   you won't have another a panic attack.
[00:50:26.320 --> 00:50:28.680]   It just means that you are slowing things down.
[00:50:28.680 --> 00:50:30.280]   That's what happened in the watchman.
[00:50:30.280 --> 00:50:31.280]   That's what I'm describing.
[00:50:31.280 --> 00:50:36.360]   And anybody who is feeling anxious right now, because there's lots of different things to
[00:50:36.360 --> 00:50:43.000]   be concerned about, the thing to do is to stop, observe what's happening and try to
[00:50:43.000 --> 00:50:47.160]   think about, you know, next order implications in a rational way.
[00:50:47.160 --> 00:50:48.160]   And it's totally possible.
[00:50:48.160 --> 00:50:52.640]   You just have to make a decision that you're willing to lean into uncertainty.
[00:50:52.640 --> 00:50:59.520]   If you allow yourself to lean into uncertainty and to ask, you know, to approach sort of
[00:50:59.520 --> 00:51:04.320]   complexity by asking deep questions, that's not only what gets you through, but it's what
[00:51:04.320 --> 00:51:06.080]   turns risk into opportunity.
[00:51:06.080 --> 00:51:07.800]   I like it.
[00:51:07.800 --> 00:51:10.920]   In fact, I think I've been doing that.
[00:51:10.920 --> 00:51:15.560]   That's how we all have ways of handling stressful situations, right?
[00:51:15.560 --> 00:51:19.520]   Sometimes it's just to watch more TV, you know, Gilligan's Island is great.
[00:51:19.520 --> 00:51:24.760]   But sometimes, or maybe to buy a new toy, you know, that's one of the things that tech
[00:51:24.760 --> 00:51:26.280]   people fall prey to.
[00:51:26.280 --> 00:51:28.280]   I just got to buy a new toy.
[00:51:28.280 --> 00:51:30.320]   Think about that for a while.
[00:51:30.320 --> 00:51:35.200]   But one of the things that I notice I've been doing is I've been, and maybe this is interesting
[00:51:35.200 --> 00:51:40.600]   that you say this, the way I've handled the virus anxieties by thinking out scenarios,
[00:51:40.600 --> 00:51:41.600]   thinking ahead.
[00:51:41.600 --> 00:51:42.600]   Yeah.
[00:51:42.600 --> 00:51:47.760]   So I just, so all of my research, it's free and open source and all of my tools are free
[00:51:47.760 --> 00:51:48.760]   and open source.
[00:51:48.760 --> 00:51:55.720]   And, you know, I'm seeing a lot of, again, just people, you know, confused, feeling anxious.
[00:51:55.720 --> 00:52:02.560]   So I published sort of a how to guide to use a core futurist tool which anybody can use.
[00:52:02.560 --> 00:52:04.240]   It doesn't predict the future.
[00:52:04.240 --> 00:52:09.280]   It helps you think through plausible future states and it's called the axes of uncertainty.
[00:52:09.280 --> 00:52:13.680]   See, people around me, when I do this out loud, it makes them anxious.
[00:52:13.680 --> 00:52:14.680]   Well, okay.
[00:52:14.680 --> 00:52:17.280]   Some people don't react well to this.
[00:52:17.280 --> 00:52:21.040]   They go, why are you thinking about all these scenarios, these doomsday scenarios?
[00:52:21.040 --> 00:52:22.400]   Are you nuts?
[00:52:22.400 --> 00:52:23.400]   Where would I find this?
[00:52:23.400 --> 00:52:26.080]   Where would I find this tool that you're talking about?
[00:52:26.080 --> 00:52:30.320]   So if you go to medium, I dropped it in the spreadsheet.
[00:52:30.320 --> 00:52:31.320]   Oh, okay.
[00:52:31.320 --> 00:52:35.480]   If you go to medium and look up, you know, it's, look up my name.
[00:52:35.480 --> 00:52:36.480]   Maybe you'll find it.
[00:52:36.480 --> 00:52:38.200]   I'll find it in the spreadsheet.
[00:52:38.200 --> 00:52:39.360]   Here's the thing to remember.
[00:52:39.360 --> 00:52:44.240]   So because basically what you do, it's super easy to use.
[00:52:44.240 --> 00:52:49.160]   You just come up with, before you get to the doomsday scenarios, come up with uncertainties.
[00:52:49.160 --> 00:52:50.160]   Right?
[00:52:50.160 --> 00:52:52.280]   I don't know if the labor force is going to shrink or grow.
[00:52:52.280 --> 00:52:56.720]   I don't know if Google is going to suddenly have, we're going to have different privacy
[00:52:56.720 --> 00:53:00.240]   in the United States because of the virus or not or whatever it might be.
[00:53:00.240 --> 00:53:02.760]   You come up with all these different things.
[00:53:02.760 --> 00:53:07.240]   You express them as opposites and then you plot them against each other on an X and Y axis
[00:53:07.240 --> 00:53:10.400]   and that results in four different quadrants.
[00:53:10.400 --> 00:53:15.280]   Each one of those quadrants sort of describes, well, if these two things happen, then what?
[00:53:15.280 --> 00:53:19.280]   And that then what is a headline that tells you something about the future?
[00:53:19.280 --> 00:53:23.120]   You know, even if it seems like it's existential risk, great.
[00:53:23.120 --> 00:53:24.240]   Now you've seen it.
[00:53:24.240 --> 00:53:29.840]   So what's our opportunity to mitigate that or to turn that risk into an opportunity somehow?
[00:53:29.840 --> 00:53:35.440]   I actually see a ton of, as bad as all of this is, I think that there's going to be a
[00:53:35.440 --> 00:53:40.800]   lot of good that comes on the other side of it that has to do with synthetic biology
[00:53:40.800 --> 00:53:45.760]   and faster getting to certain types of medications much faster.
[00:53:45.760 --> 00:53:51.040]   This could be, this all could clear the way for the FAA to start allowing drone deliveries
[00:53:51.040 --> 00:53:52.920]   because we're probably going to need them.
[00:53:52.920 --> 00:53:59.240]   You know, I mean, there's, it's not all horrifically bad if you allow yourself to confront your
[00:53:59.240 --> 00:54:02.760]   cherished beliefs and think through other plausible scenarios.
[00:54:02.760 --> 00:54:03.760]   This is really interesting.
[00:54:03.760 --> 00:54:11.160]   I'm looking at the article right now, how Futurist cope with uncertainty.
[00:54:11.160 --> 00:54:14.920]   So this is, this is how you would work anyway, but this could be...
[00:54:14.920 --> 00:54:19.480]   I mean, this is just, and this is, yeah, it's not to like replace the arduous and detailed
[00:54:19.480 --> 00:54:21.000]   process of writing scenarios.
[00:54:21.000 --> 00:54:22.000]   Oh, shoot.
[00:54:22.000 --> 00:54:23.000]   It's sort of like the beginning.
[00:54:23.000 --> 00:54:27.880]   Well, this is the, this is the, this is the every man's guide to Futurists.
[00:54:27.880 --> 00:54:30.760]   Yeah, I mean, listen, we use a ton of different tools.
[00:54:30.760 --> 00:54:34.280]   So if I was really doing this, I would need a lot more data, but this is a simple tool
[00:54:34.280 --> 00:54:38.240]   that anybody can use and it's beginning, it's a core tool that we use.
[00:54:38.240 --> 00:54:41.600]   It's a beginning part of our scenarios process.
[00:54:41.600 --> 00:54:44.120]   You know, and it's super useful whether you're trying to figure out what to do with your
[00:54:44.120 --> 00:54:46.840]   company or just, you know, in your personal life.
[00:54:46.840 --> 00:54:49.760]   It's a good way to get your focus off of just negative.
[00:54:49.760 --> 00:54:50.760]   Cool.
[00:54:50.760 --> 00:54:51.760]   Into other possibilities.
[00:54:51.760 --> 00:54:52.760]   Yeah.
[00:54:52.760 --> 00:54:54.000]   Oh, that's really cool.
[00:54:54.000 --> 00:54:57.000]   Or you can do like I do in Marquez do, we just buy a new phone.
[00:54:57.000 --> 00:54:58.480]   Yeah, you can do that too.
[00:54:58.480 --> 00:54:59.480]   Get the folded one.
[00:54:59.480 --> 00:55:02.560]   I saw your, I saw your phone drawer, Marquez.
[00:55:02.560 --> 00:55:04.080]   That is wild.
[00:55:04.080 --> 00:55:05.080]   Yeah.
[00:55:05.080 --> 00:55:07.240]   Everyone keeps some of it around.
[00:55:07.240 --> 00:55:10.080]   Everyone, why do you keep it around?
[00:55:10.080 --> 00:55:12.640]   I just have all of last year's phones.
[00:55:12.640 --> 00:55:15.560]   Oh, that drawer was just one year.
[00:55:15.560 --> 00:55:19.000]   It was this all, it's all this year and all of the year before.
[00:55:19.000 --> 00:55:27.400]   So like Pixel 4, 3A and 3 and Galaxy S10 and S10 plus and now S20, S20 Ultra.
[00:55:27.400 --> 00:55:28.400]   Yeah.
[00:55:28.400 --> 00:55:30.280]   Everyone makes 13 versions of every phone.
[00:55:30.280 --> 00:55:31.280]   Now they do.
[00:55:31.280 --> 00:55:35.880]   Is your daily driver that iPhone, you showed us the iPhone Pro Max?
[00:55:35.880 --> 00:55:37.920]   It is the Galaxy S20 Ultra.
[00:55:37.920 --> 00:55:38.920]   Ooh.
[00:55:38.920 --> 00:55:40.560]   The big one.
[00:55:40.560 --> 00:55:43.560]   That's just because it's the newest.
[00:55:43.560 --> 00:55:51.560]   It's, so I've been using my OnePlus 7T Pro up until this as my main phone and that's not
[00:55:51.560 --> 00:55:53.360]   the newest phone.
[00:55:53.360 --> 00:55:56.720]   It's less than a year old but still like eight, nine phones came out and I reviewed them in
[00:55:56.720 --> 00:55:57.720]   between those two.
[00:55:57.720 --> 00:56:04.000]   So I don't necessarily always just use the latest one but I did switch to the S20 Ultra.
[00:56:04.000 --> 00:56:08.280]   Do you think you'll go back to the OnePlus?
[00:56:08.280 --> 00:56:11.160]   Rumors of the OnePlus 8 look pretty promising.
[00:56:11.160 --> 00:56:14.120]   So there's a chance that phone takes me back.
[00:56:14.120 --> 00:56:16.920]   See Amy, this is what we nerds do to handle our anxiety.
[00:56:16.920 --> 00:56:18.920]   Hey, I've got plenty of...
[00:56:18.920 --> 00:56:19.920]   I know, I know.
[00:56:19.920 --> 00:56:24.360]   Anything else you can want.
[00:56:24.360 --> 00:56:28.280]   I've got a beam that can come in and we can have a little robot behind me and have a...
[00:56:28.280 --> 00:56:29.280]   What?
[00:56:29.280 --> 00:56:30.280]   He really wanted.
[00:56:30.280 --> 00:56:31.280]   Yeah.
[00:56:31.280 --> 00:56:32.280]   Telepresence bots.
[00:56:32.280 --> 00:56:33.280]   What?
[00:56:33.280 --> 00:56:34.840]   You have a telepresence bot in the room?
[00:56:34.840 --> 00:56:35.840]   I have a bunch.
[00:56:35.840 --> 00:56:36.840]   It's in the room behind me.
[00:56:36.840 --> 00:56:38.600]   I have a bunch of tele...
[00:56:38.600 --> 00:56:41.560]   C. Marquez, there is other stuff out there.
[00:56:41.560 --> 00:56:42.560]   There is one.
[00:56:42.560 --> 00:56:43.560]   There's phones.
[00:56:43.560 --> 00:56:45.280]   I mean, there's so many other things you could get.
[00:56:45.280 --> 00:56:49.800]   We had a telepresence, I don't know what, if you'd call it a bop, we had a thing you put
[00:56:49.800 --> 00:56:53.520]   an iPad in and then you could control the wheels.
[00:56:53.520 --> 00:56:57.080]   In fact, we let Dr. Mom and other people use it to visit our studio and wander around
[00:56:57.080 --> 00:56:58.080]   and say hi and stuff.
[00:56:58.080 --> 00:56:59.080]   You mean like that?
[00:56:59.080 --> 00:57:02.320]   Yes, and I think that is what should play Frisbee.
[00:57:02.320 --> 00:57:03.320]   Instead of you.
[00:57:03.320 --> 00:57:04.320]   Instead of your body.
[00:57:04.320 --> 00:57:05.320]   Yes.
[00:57:05.320 --> 00:57:06.320]   There you go.
[00:57:06.320 --> 00:57:08.360]   Actually, I think that that's a good example though.
[00:57:08.360 --> 00:57:13.480]   There will be technologies that will come to the forefront because of COVID-19 that we
[00:57:13.480 --> 00:57:15.560]   might not seem.
[00:57:15.560 --> 00:57:16.560]   That's a perfect example.
[00:57:16.560 --> 00:57:17.560]   Telepresence.
[00:57:17.560 --> 00:57:22.800]   Yeah, that and our telepresence has yet to really take off.
[00:57:22.800 --> 00:57:24.360]   I don't know why.
[00:57:24.360 --> 00:57:27.480]   I've been using it for a long time and I really like it.
[00:57:27.480 --> 00:57:29.720]   What do you use it for?
[00:57:29.720 --> 00:57:33.920]   So I travel a lot and I use it to follow my daughter.
[00:57:33.920 --> 00:57:36.080]   It's going to be such a weirdo.
[00:57:36.080 --> 00:57:37.680]   Yeah, I know.
[00:57:37.680 --> 00:57:38.680]   We're a bunch of girls.
[00:57:38.680 --> 00:57:39.680]   Hello, Mommy Robot.
[00:57:39.680 --> 00:57:42.840]   So I follow who are around the house.
[00:57:42.840 --> 00:57:43.840]   We have an elevator.
[00:57:43.840 --> 00:57:48.640]   I live in a very home in Baltimore is very, very old and so we've got an elevator and
[00:57:48.640 --> 00:57:51.080]   I can go up and down the stairs with her.
[00:57:51.080 --> 00:57:55.320]   Yeah, I mean if I it's a little different than her, you know, this way she can sort of
[00:57:55.320 --> 00:57:57.120]   live her life and do her normal stuff.
[00:57:57.120 --> 00:57:58.600]   How does she go around?
[00:57:58.600 --> 00:57:59.600]   What does she think about that?
[00:57:59.600 --> 00:58:00.760]   Is there a field to her?
[00:58:00.760 --> 00:58:05.880]   This is one thing I've been thinking about because we're all going to be a little isolated.
[00:58:05.880 --> 00:58:09.960]   My mom wanted more contact with me because she's alone in Rhode Island.
[00:58:09.960 --> 00:58:10.960]   She's 87.
[00:58:10.960 --> 00:58:15.680]   Say, Manages Ruth Bader Ginsburg, by the way, happy birthday RBG.
[00:58:15.680 --> 00:58:20.640]   And so I've been doing more FaceTime calls with her and she it's reassuring.
[00:58:20.640 --> 00:58:27.120]   In fact, I set up I set up the iPad in the kitchen while I was cooking chili and we cooked
[00:58:27.120 --> 00:58:28.120]   together.
[00:58:28.120 --> 00:58:33.240]   And I thought this is kind of what we would be doing if she lived in the area and it's
[00:58:33.240 --> 00:58:34.240]   a long as it's.
[00:58:34.240 --> 00:58:41.920]   So long as it's FaceTime, I have a friend who outfitted his 97 year old or however, 99
[00:58:41.920 --> 00:58:48.200]   year old father's entire house with cameras so that he can sort of one of these days that
[00:58:48.200 --> 00:58:51.760]   guy is going to have a heart attack because his son is going to just start talking.
[00:58:51.760 --> 00:58:52.760]   Hi dad.
[00:58:52.760 --> 00:58:53.760]   It's really funny.
[00:58:53.760 --> 00:58:54.760]   What's she doing?
[00:58:54.760 --> 00:58:57.720]   The last time I was there and he's like, you know, the dad doesn't want to be interrupted
[00:58:57.720 --> 00:58:58.720]   constantly.
[00:58:58.720 --> 00:58:59.720]   Hey dad.
[00:58:59.720 --> 00:59:00.720]   Yeah.
[00:59:00.720 --> 00:59:03.120]   Are you sure you should be eating that dad?
[00:59:03.120 --> 00:59:04.120]   Did you take your bills that?
[00:59:04.120 --> 00:59:06.080]   No, no, I don't do that.
[00:59:06.080 --> 00:59:07.280]   But I do I wonder.
[00:59:07.280 --> 00:59:08.280]   Little magic.
[00:59:08.280 --> 00:59:17.360]   Mark has do you do you use FaceTime or duo or Skype or do you do talk to people via video?
[00:59:17.360 --> 00:59:23.400]   Yeah, as a utility, it's a lot of time it's for just not not like a meeting but literally
[00:59:23.400 --> 00:59:28.360]   to like do a briefing on a new piece of tech if they can't bring the tech here to show
[00:59:28.360 --> 00:59:29.360]   it to me.
[00:59:29.360 --> 00:59:32.480]   But that was not what family or friends you don't use it that way.
[00:59:32.480 --> 00:59:33.480]   Not as much.
[00:59:33.480 --> 00:59:36.360]   I'll do with family sometimes just to catch up.
[00:59:36.360 --> 00:59:41.560]   But I do use it more for like just work, which is interesting.
[00:59:41.560 --> 00:59:45.000]   Well, in a way it might be the future of work.
[00:59:45.000 --> 00:59:47.280]   Google IO going to be remote.
[00:59:47.280 --> 00:59:50.240]   Apple just announced that we have a DC is going to be remote.
[00:59:50.240 --> 00:59:52.720]   Facebook FA canceled because of this.
[00:59:52.720 --> 00:59:59.400]   I think but my question is whether it's personal connection with family members or work going
[00:59:59.400 --> 01:00:06.000]   to virtual conferences, if it's as good as a face to face you were at CES.
[01:00:06.000 --> 01:00:07.000]   Did you get sick?
[01:00:07.000 --> 01:00:13.200]   No, I was only there for three days, I think, but I did not get sick at CES.
[01:00:13.200 --> 01:00:14.200]   Why?
[01:00:14.200 --> 01:00:15.200]   Typically I do.
[01:00:15.200 --> 01:00:16.880]   No, normally everybody gets sick.
[01:00:16.880 --> 01:00:17.880]   It's like a flu.
[01:00:17.880 --> 01:00:19.760]   Yeah, every it's the CES flu every year.
[01:00:19.760 --> 01:00:23.280]   It's oh man, how many days are you?
[01:00:23.280 --> 01:00:24.280]   Are you on the floor?
[01:00:24.280 --> 01:00:26.920]   Because that's I would drop in and out a couple days.
[01:00:26.920 --> 01:00:30.120]   Amy, you look like the kind of person that washes your hands.
[01:00:30.120 --> 01:00:31.120]   I do.
[01:00:31.120 --> 01:00:33.800]   Yeah, that was how I stopped getting sick.
[01:00:33.800 --> 01:00:39.560]   Yeah, CES for I mean, that was my seven CES, but CES for me often turns into shaking a
[01:00:39.560 --> 01:00:42.600]   lot of hands, which is the ideal way to get sick.
[01:00:42.600 --> 01:00:45.280]   So yeah, this was the first year I didn't get sick.
[01:00:45.280 --> 01:00:49.840]   But yeah, that's something that could be a lot easier with a telepresence robot to not
[01:00:49.840 --> 01:00:52.240]   have to get sick.
[01:00:52.240 --> 01:00:54.800]   You know, there is something I'm just sanitizing.
[01:00:54.800 --> 01:00:57.320]   Just mention of all the hair shaking.
[01:00:57.320 --> 01:01:00.280]   I had to break out the Bureau.
[01:01:00.280 --> 01:01:05.200]   I wonder though, because the thing that to me conferences, Amy, you're missing South
[01:01:05.200 --> 01:01:07.120]   by Southwest, that conference.
[01:01:07.120 --> 01:01:08.120]   Missing a lot.
[01:01:08.120 --> 01:01:14.720]   Yeah, that conference isn't so much about booths or presentations even although there
[01:01:14.720 --> 01:01:16.080]   are a lot of good presentations.
[01:01:16.080 --> 01:01:19.520]   It's about it's about face to face socializing.
[01:01:19.520 --> 01:01:28.680]   Yeah, I and the spring conference season is, infestible season is South by followed by
[01:01:28.680 --> 01:01:33.760]   some stuff that I do with the World Economic Forum and there's a lot.
[01:01:33.760 --> 01:01:39.760]   You can try to put some of the content online, but ultimately what people crave is each other.
[01:01:39.760 --> 01:01:40.760]   You know, we crave.
[01:01:40.760 --> 01:01:47.600]   And not just shaking hands, but I think we sort of craved a unifying shared experience.
[01:01:47.600 --> 01:01:52.280]   So I think that's one of the things that's really rough is in addition to all of the
[01:01:52.280 --> 01:01:57.120]   economic loss and all of the other stuff that's obvious, it's being in a place having
[01:01:57.120 --> 01:02:00.920]   a shared experience and having that as a touchstone going forward.
[01:02:00.920 --> 01:02:06.400]   I think that's going to be rough and that you can't really duplicate digitally.
[01:02:06.400 --> 01:02:10.120]   You know, when you say unified shared experience, you're absolutely right.
[01:02:10.120 --> 01:02:14.560]   I think about, this is the thing I think about waiting in line to buy an iPhone.
[01:02:14.560 --> 01:02:17.320]   And every time I did it, it was marvelous.
[01:02:17.320 --> 01:02:18.320]   There's a little suffering.
[01:02:18.320 --> 01:02:24.440]   You have to have a touch of suffering because it's got to be mutually shared suffering.
[01:02:24.440 --> 01:02:27.560]   But also a mutual goal and interest.
[01:02:27.560 --> 01:02:30.800]   Mark has, you've probably never waited in line for a phone.
[01:02:30.800 --> 01:02:38.760]   I'm thinking I have, but it was in college, I waited in line for Verizon's first Google
[01:02:38.760 --> 01:02:40.880]   phone, the Galaxy Nexus.
[01:02:40.880 --> 01:02:43.240]   Yes, which is a very nice one.
[01:02:43.240 --> 01:02:48.440]   Yeah, I missed my 9am class because I was waiting in line halfway across Hoboken at the Verizon
[01:02:48.440 --> 01:02:49.440]   store.
[01:02:49.440 --> 01:02:51.520]   I was like 10th in line for Android phone.
[01:02:51.520 --> 01:02:52.520]   Wow.
[01:02:52.520 --> 01:02:53.840]   Did you enjoy it?
[01:02:53.840 --> 01:02:54.840]   I love that phone.
[01:02:54.840 --> 01:02:56.120]   No, I mean the line.
[01:02:56.120 --> 01:02:57.120]   No, the line.
[01:02:57.120 --> 01:02:59.120]   Oh, the line.
[01:02:59.120 --> 01:03:01.080]   I don't remember the line very well.
[01:03:01.080 --> 01:03:03.400]   I remember thinking this is really weird.
[01:03:03.400 --> 01:03:08.680]   It's not an iPhone and I'm waiting in line outside, you know, before a store opens.
[01:03:08.680 --> 01:03:13.680]   So I thought that was sort of fascinating that this number of people shared this enthusiasm
[01:03:13.680 --> 01:03:15.600]   at this level.
[01:03:15.600 --> 01:03:16.960]   So I thought that was interesting.
[01:03:16.960 --> 01:03:20.960]   But I don't think I actually enjoyed the waiting in line part.
[01:03:20.960 --> 01:03:26.280]   And at that point, Mark has Brownlee said, you know, it'd be good to have a YouTube channel
[01:03:26.280 --> 01:03:27.280]   about this stuff.
[01:03:27.280 --> 01:03:28.960]   Oh, I was all right.
[01:03:28.960 --> 01:03:33.920]   This is the only reason I was waiting in line is because I got to get this first look.
[01:03:33.920 --> 01:03:35.480]   I got to check this phone out.
[01:03:35.480 --> 01:03:36.480]   Yeah.
[01:03:36.480 --> 01:03:37.480]   Yeah.
[01:03:37.480 --> 01:03:41.480]   I don't do loaner phones, so I have to buy them all.
[01:03:41.480 --> 01:03:45.680]   And that means a lot of line waiting.
[01:03:45.680 --> 01:03:49.440]   I don't have the friends that you have, unfortunately.
[01:03:49.440 --> 01:03:52.800]   Or actually I used to and I made enemies of them all probably.
[01:03:52.800 --> 01:03:57.560]   There is an interesting rumor afloat that there will be a new Mac book as early as this
[01:03:57.560 --> 01:03:59.360]   week.
[01:03:59.360 --> 01:04:05.520]   I think it's an interesting story because Apple has now closed all of its Apple stores,
[01:04:05.520 --> 01:04:11.040]   except in China, where they've reopened the Apple stores.
[01:04:11.040 --> 01:04:14.120]   They're calling it greater China now, just FYI.
[01:04:14.120 --> 01:04:18.160]   Greater China as opposed to what's less your China, Hong Kong and Taiwan.
[01:04:18.160 --> 01:04:22.240]   That's everybody's way of appeasing Beijing to include Taiwan.
[01:04:22.240 --> 01:04:23.240]   Right.
[01:04:23.240 --> 01:04:25.720]   So they don't want to piss off Taiwan by calling it China, China.
[01:04:25.720 --> 01:04:29.480]   They don't want to piss off Beijing by calling Taiwan, Taiwan.
[01:04:29.480 --> 01:04:30.480]   Anyhow.
[01:04:30.480 --> 01:04:33.680]   You can't win.
[01:04:33.680 --> 01:04:36.160]   But it is, never mind.
[01:04:36.160 --> 01:04:40.640]   Every time I get into this minefield, I screw it up.
[01:04:40.640 --> 01:04:43.520]   It is China.
[01:04:43.520 --> 01:04:44.840]   Greater China, whatever.
[01:04:44.840 --> 01:04:45.840]   I guess greater China.
[01:04:45.840 --> 01:04:47.880]   I don't want to fall for that.
[01:04:47.880 --> 01:04:49.200]   Make China great again.
[01:04:49.200 --> 01:04:52.640]   Is it not Taiwan, China, Hong Kong?
[01:04:52.640 --> 01:04:53.640]   Can I do that?
[01:04:53.640 --> 01:04:54.640]   Hong Kong is an essay.
[01:04:54.640 --> 01:04:57.640]   I used to live in Hong Kong, but I think Beijing would say.
[01:04:57.640 --> 01:04:59.880]   They'd say it's China now, baby.
[01:04:59.880 --> 01:05:00.880]   Yeah.
[01:05:00.880 --> 01:05:01.880]   You're China now, baby.
[01:05:01.880 --> 01:05:03.480]   And they have computers.
[01:05:03.480 --> 01:05:05.760]   They've got open stores.
[01:05:05.760 --> 01:05:09.760]   So it's weird because of course that's where COVID began, but apparently they've gotten
[01:05:09.760 --> 01:05:10.760]   over it.
[01:05:10.760 --> 01:05:13.120]   So they're opening their stores, although with lots of precautions, temperature checks
[01:05:13.120 --> 01:05:16.680]   before you go in, limited hours, limited number of people in the store.
[01:05:16.680 --> 01:05:20.640]   But they've closed all over the world every Apple store.
[01:05:20.640 --> 01:05:24.280]   And so I was thinking, and maybe, maybe, Mark, as you'd have some insight, it seems
[01:05:24.280 --> 01:05:28.000]   to me, on the one hand, you don't want to announce new products when people can't go
[01:05:28.000 --> 01:05:30.120]   to the store to try them.
[01:05:30.120 --> 01:05:34.240]   But on the other hand, closing the stores means a huge drop in revenue.
[01:05:34.240 --> 01:05:39.080]   Maybe you just say, well, buy it in those online store and maybe that'll help.
[01:05:39.080 --> 01:05:40.480]   What do you think?
[01:05:40.480 --> 01:05:41.880]   Yeah.
[01:05:41.880 --> 01:05:48.640]   There's also the rumor of that March event that is also now rumored to have been delayed
[01:05:48.640 --> 01:05:50.880]   or canceled.
[01:05:50.880 --> 01:05:56.040]   So yeah, I think at this point, the question is how important is this product?
[01:05:56.040 --> 01:06:03.600]   Is this 14-inch or 13-inch MacBook Pro upgrade as a product by itself enough to just push
[01:06:03.600 --> 01:06:04.600]   it out now?
[01:06:04.600 --> 01:06:10.160]   Or should we, if your Apple, delay it so that we can properly launch it in stores?
[01:06:10.160 --> 01:06:13.240]   But there was also rumors of a bunch of other Apple products potentially launching at the
[01:06:13.240 --> 01:06:14.240]   same time too.
[01:06:14.240 --> 01:06:19.200]   There's a new iPhone, rumored that SE2 or whatever we're going to call it.
[01:06:19.200 --> 01:06:21.280]   There's some other accessories, rumored.
[01:06:21.280 --> 01:06:24.760]   So those are all sort of looming over this as well.
[01:06:24.760 --> 01:06:29.200]   But I think if we're just talking about the laptop, I think they could quietly launch it
[01:06:29.200 --> 01:06:33.480]   and kill a 13-inch and not have to wait for stores to reopen.
[01:06:33.480 --> 01:06:36.000]   And then people would see it when the stores reopen.
[01:06:36.000 --> 01:06:40.320]   Yeah, I guess, I mean, it's challenging because I think there are a lot of people who say,
[01:06:40.320 --> 01:06:43.080]   well, I'm going to try it before I buy it, especially given the problems Apple's had
[01:06:43.080 --> 01:06:44.080]   with keyboards.
[01:06:44.080 --> 01:06:45.480]   That's what I was wondering.
[01:06:45.480 --> 01:06:47.040]   How many people do you think?
[01:06:47.040 --> 01:06:51.760]   How much of an escalation trigger is that for people need to try it before they buy it?
[01:06:51.760 --> 01:06:56.680]   I have to say, I bought the 16-inch with the new keyboard and it was improved.
[01:06:56.680 --> 01:06:58.120]   I really hated.
[01:06:58.120 --> 01:07:00.440]   I was one of the haters on the old keyboard.
[01:07:00.440 --> 01:07:01.440]   Of the keyboard?
[01:07:01.440 --> 01:07:02.440]   Yeah.
[01:07:02.440 --> 01:07:03.440]   But a flying keyboard.
[01:07:03.440 --> 01:07:04.440]   And the 16-inch is usable.
[01:07:04.440 --> 01:07:10.640]   Although then I just bought a Dell XPS 13, which is similarly thin and light, and it has
[01:07:10.640 --> 01:07:16.360]   a similarly short-traveled keyboard, but it's infinitely better and it kind of made me realize
[01:07:16.360 --> 01:07:19.880]   that even with the 16-inch, I'm sacrificing a little bit.
[01:07:19.880 --> 01:07:21.720]   So did anybody like that keyboard?
[01:07:21.720 --> 01:07:22.720]   I think so.
[01:07:22.720 --> 01:07:23.720]   Some people did.
[01:07:23.720 --> 01:07:25.600]   There's some old thin ones.
[01:07:25.600 --> 01:07:26.600]   Yeah.
[01:07:26.600 --> 01:07:28.600]   Think of the butterflies.
[01:07:28.600 --> 01:07:30.200]   Renee Ritchie says he liked it.
[01:07:30.200 --> 01:07:32.120]   I don't know why.
[01:07:32.120 --> 01:07:33.120]   All right.
[01:07:33.120 --> 01:07:38.560]   Ironically, he and his crew over there at Imore, I think they had three or four of them
[01:07:38.560 --> 01:07:40.840]   fail.
[01:07:40.840 --> 01:07:44.800]   So he may have liked it, but it didn't make them any more reliable.
[01:07:44.800 --> 01:07:50.840]   It's an anonymous tipster at Mac rumor who last year at Mac rumors was accurate in a
[01:07:50.840 --> 01:07:53.640]   tip about new product announcements.
[01:07:53.640 --> 01:07:58.040]   He says Apple plans to announce a new MacBook Air models this week.
[01:07:58.040 --> 01:08:04.760]   We've also heard rumors from some less, perhaps, reliable sources like Ming-Chi Kuo say that
[01:08:04.760 --> 01:08:13.480]   there will be new iPads and maybe new AirPods.
[01:08:13.480 --> 01:08:17.920]   I don't know.
[01:08:17.920 --> 01:08:23.680]   I actually really liked the MacBook Air, but I can't use it because that horrible keyboard.
[01:08:23.680 --> 01:08:28.320]   I think all the improvements with the rumored new MacBook Pro would be sort of parallel
[01:08:28.320 --> 01:08:30.280]   to what they did with the 16-inch MacBook Pro.
[01:08:30.280 --> 01:08:32.200]   So if it would be, yeah.
[01:08:32.200 --> 01:08:37.080]   So new keyboard, a little bit of a bigger display, smaller bezels, maybe better microphones
[01:08:37.080 --> 01:08:41.080]   and better speakers and the separate escape key and all sort of improvements they made
[01:08:41.080 --> 01:08:43.160]   already, just in the smaller one.
[01:08:43.160 --> 01:08:44.160]   That would be ideal for me.
[01:08:44.160 --> 01:08:45.160]   I hope they do that.
[01:08:45.160 --> 01:08:46.160]   Yep.
[01:08:46.160 --> 01:08:48.160]   I don't expect anything to get edit 8K video though.
[01:08:48.160 --> 01:08:49.160]   I'm just saying.
[01:08:49.160 --> 01:08:50.800]   No, definitely not.
[01:08:50.800 --> 01:08:53.760]   I stopped editing on my laptop entirely last year.
[01:08:53.760 --> 01:08:56.320]   I used to edit on laptops sometimes.
[01:08:56.320 --> 01:08:58.360]   I don't even try anymore.
[01:08:58.360 --> 01:09:05.120]   We're actually, sorry, we're making our editors go home and edit on the laptop.
[01:09:05.120 --> 01:09:08.040]   They're probably not loving us too heck of a lot.
[01:09:08.040 --> 01:09:11.760]   Actually what they're doing, because you're going to hate this, Marquez, but we gave up
[01:09:11.760 --> 01:09:18.840]   on Final Cut when Apple screwed us with a weird update and moved to PCs in Premiere.
[01:09:18.840 --> 01:09:20.800]   And so they have big Dell workstations.
[01:09:20.800 --> 01:09:23.920]   They're just going to remote into those big Dell workstations from my laptop.
[01:09:23.920 --> 01:09:24.920]   So maybe it won't matter.
[01:09:24.920 --> 01:09:25.920]   I don't know.
[01:09:25.920 --> 01:09:26.920]   Yeah.
[01:09:26.920 --> 01:09:27.920]   I wouldn't want it.
[01:09:27.920 --> 01:09:28.920]   I'm curious.
[01:09:28.920 --> 01:09:31.320]   Which final cut was that when they first went Final Cut X?
[01:09:31.320 --> 01:09:32.320]   Yeah.
[01:09:32.320 --> 01:09:33.640]   Like the initial, okay.
[01:09:33.640 --> 01:09:37.680]   And the reason was at the time there was a very practical reason.
[01:09:37.680 --> 01:09:43.600]   I mean, of course they completely hobbled it, but we used a SAN so we would record to a
[01:09:43.600 --> 01:09:49.320]   SAN via fiber from our board and then they would have immediate access to it.
[01:09:49.320 --> 01:09:50.840]   And it didn't support a SAN.
[01:09:50.840 --> 01:09:53.840]   It was like, you just broke it for us.
[01:09:53.840 --> 01:09:57.400]   And I have to say, having gone to Premiere, I don't think any of us.
[01:09:57.400 --> 01:10:00.640]   But we're not doing MKVHD.
[01:10:00.640 --> 01:10:06.000]   You know, best we put out a 720p and it's good enough and you're going to like it.
[01:10:06.000 --> 01:10:08.000]   So there.
[01:10:08.000 --> 01:10:09.000]   Huh?
[01:10:09.000 --> 01:10:14.000]   We're calling it HD because it is HD technically.
[01:10:14.000 --> 01:10:16.000]   It's HD technically.
[01:10:16.000 --> 01:10:19.560]   Nobody wants to see me in 8K.
[01:10:19.560 --> 01:10:21.360]   Trust me, Mark, as you just talking heads.
[01:10:21.360 --> 01:10:22.360]   There's nothing here.
[01:10:22.360 --> 01:10:25.840]   Nothing to see here.
[01:10:25.840 --> 01:10:29.520]   There were a spate of rumors on Tuesday.
[01:10:29.520 --> 01:10:30.680]   I mean, a ton of them.
[01:10:30.680 --> 01:10:35.800]   Marston had to cut and paste, cut and paste, cut and paste all morning before Mac break
[01:10:35.800 --> 01:10:40.440]   weekly because iOS 14 didn't drop.
[01:10:40.440 --> 01:10:47.120]   Somebody got a leaked beta from Apple that showed all sorts of new features, new over-the-ear
[01:10:47.120 --> 01:10:53.040]   headphones, you know, beat style headphones from Apple, blood, oxygen detection in the
[01:10:53.040 --> 01:10:56.000]   Apple Watch.
[01:10:56.000 --> 01:11:00.240]   And a kid's version.
[01:11:00.240 --> 01:11:01.240]   What do they call it?
[01:11:01.240 --> 01:11:02.240]   School time?
[01:11:02.240 --> 01:11:04.040]   Apple Watch for kids?
[01:11:04.040 --> 01:11:07.880]   What did your kid, let me ask you, Amy, does your kid have a smartphone and an Apple
[01:11:07.880 --> 01:11:09.920]   Watch probably, right?
[01:11:09.920 --> 01:11:12.040]   No, no, no.
[01:11:12.040 --> 01:11:15.680]   My kid has her own network that we built.
[01:11:15.680 --> 01:11:17.320]   I think I've talked about it.
[01:11:17.320 --> 01:11:18.320]   Yes, you did.
[01:11:18.320 --> 01:11:22.400]   And I'm still trying to get into your key base secret chat.
[01:11:22.400 --> 01:11:27.680]   I just actually launched a public key base chat for anybody who wants, who's a futurist
[01:11:27.680 --> 01:11:31.960]   or a futurist, a decent type, wants to talk about scenarios.
[01:11:31.960 --> 01:11:33.040]   It's just key base.
[01:11:33.040 --> 01:11:36.800]   It's called the team is Corona Futures, if you're interested.
[01:11:36.800 --> 01:11:43.360]   But yeah, we built her this network that she thinks she is totally in control of.
[01:11:43.360 --> 01:11:44.640]   And she's not.
[01:11:44.640 --> 01:11:47.240]   But she feels like she's got unfettered access.
[01:11:47.240 --> 01:11:51.240]   So after she's done a whole bunch of stuff during the day, she finally can unlock her
[01:11:51.240 --> 01:11:56.160]   iPad, which has no YouTube.
[01:11:56.160 --> 01:12:00.600]   It has very few offerings, but she has total control.
[01:12:00.600 --> 01:12:02.840]   We also don't tell her how to use anything.
[01:12:02.840 --> 01:12:04.520]   So she has to figure it all out.
[01:12:04.520 --> 01:12:06.960]   She's starting to feel so sorry for your daughter.
[01:12:06.960 --> 01:12:12.520]   She's got a robot mom and a crypto network.
[01:12:12.520 --> 01:12:13.920]   Yeah.
[01:12:13.920 --> 01:12:17.760]   And she's got some, she's got a digital wallet.
[01:12:17.760 --> 01:12:22.240]   So she can't buy anything on the Silk Road.
[01:12:22.240 --> 01:12:24.320]   But she understands the basis of crypto.
[01:12:24.320 --> 01:12:26.840]   When she has Bitcoin?
[01:12:26.840 --> 01:12:28.680]   I didn't say Bitcoin.
[01:12:28.680 --> 01:12:30.000]   Oh, she probably has that.
[01:12:30.000 --> 01:12:33.360]   What is the coin that they use on a key base?
[01:12:33.360 --> 01:12:35.760]   They have some, they have their own coin.
[01:12:35.760 --> 01:12:36.760]   Yeah.
[01:12:36.760 --> 01:12:37.760]   Yeah.
[01:12:37.760 --> 01:12:38.760]   I forget what it's called.
[01:12:38.760 --> 01:12:40.200]   Everybody basically has some that signed up for it.
[01:12:40.200 --> 01:12:44.600]   I mean, we created kind of like a digital trust fund for her.
[01:12:44.600 --> 01:12:47.200]   So she's got her names and everything else locked up.
[01:12:47.200 --> 01:12:50.040]   But she doesn't have the street smarts yet.
[01:12:50.040 --> 01:12:55.360]   You know, once she does, then, you know, she can start using things and...
[01:12:55.360 --> 01:12:58.200]   No, how long is she nine?
[01:12:58.200 --> 01:12:59.200]   She's nine.
[01:12:59.200 --> 01:13:00.200]   Yeah.
[01:13:00.200 --> 01:13:01.200]   Yeah.
[01:13:01.200 --> 01:13:02.880]   No, I mean, I am so glad my kids are grown.
[01:13:02.880 --> 01:13:04.640]   I would not want to be raising children.
[01:13:04.640 --> 01:13:05.640]   It's a hard time.
[01:13:05.640 --> 01:13:06.640]   Yeah.
[01:13:06.640 --> 01:13:07.640]   For sure.
[01:13:07.640 --> 01:13:08.640]   Holy cow.
[01:13:08.640 --> 01:13:09.640]   Marques, you don't have kids.
[01:13:09.640 --> 01:13:10.880]   Are you thinking about it?
[01:13:10.880 --> 01:13:11.880]   Nah, no.
[01:13:11.880 --> 01:13:12.880]   It's a little early.
[01:13:12.880 --> 01:13:13.880]   Yeah.
[01:13:13.880 --> 01:13:14.880]   But I agree.
[01:13:14.880 --> 01:13:16.680]   It probably would be...
[01:13:16.680 --> 01:13:17.880]   There's a lot of choices you have to make.
[01:13:17.880 --> 01:13:20.920]   Like the age when you get a smartphone.
[01:13:20.920 --> 01:13:21.920]   Right.
[01:13:21.920 --> 01:13:23.920]   When you get to use YouTube.
[01:13:23.920 --> 01:13:25.840]   Do you think about that at all?
[01:13:25.840 --> 01:13:26.840]   Or...
[01:13:26.840 --> 01:13:27.840]   Yeah.
[01:13:27.840 --> 01:13:28.840]   I mean, I have...
[01:13:28.840 --> 01:13:30.000]   So I have friends that are teachers.
[01:13:30.000 --> 01:13:33.240]   So it's always interesting hearing like, you know, the kids in their class are always
[01:13:33.240 --> 01:13:35.000]   on TikTok, but they're like...
[01:13:35.000 --> 01:13:36.000]   Oh, god.
[01:13:36.000 --> 01:13:37.000]   They're like 10 years old.
[01:13:37.000 --> 01:13:40.440]   So it's like, what are they even doing, you know?
[01:13:40.440 --> 01:13:41.440]   Yeah.
[01:13:41.440 --> 01:13:43.440]   I guess I think about that when I'm making...
[01:13:43.440 --> 01:13:46.560]   I make videos that are just on YouTube, but there's a separate YouTube for kids,
[01:13:46.560 --> 01:13:47.560]   and there's a separate YouTube for kids.
[01:13:47.560 --> 01:13:48.560]   And then there's a whole ecosystem there.
[01:13:48.560 --> 01:13:49.560]   And that's always making headlines when weird stuff happens with that.
[01:13:49.560 --> 01:13:50.560]   But yeah.
[01:13:50.560 --> 01:13:51.560]   Do you do anything for that?
[01:13:51.560 --> 01:13:52.560]   Have you ever thought about doing something for that?
[01:13:52.560 --> 01:13:54.400]   No, it's a different world.
[01:13:54.400 --> 01:13:59.560]   I see it a lot in just like people handing their kid an iPad.
[01:13:59.560 --> 01:14:00.560]   Just watch.
[01:14:00.560 --> 01:14:01.560]   Just go rogue.
[01:14:01.560 --> 01:14:04.560]   You can watch whatever's on this app and it'll be fine.
[01:14:04.560 --> 01:14:05.560]   And that's...
[01:14:05.560 --> 01:14:06.560]   I get...
[01:14:06.560 --> 01:14:07.560]   Yeah, sure.
[01:14:07.560 --> 01:14:10.560]   But eventually you do have to make decisions about like when to give them...
[01:14:10.560 --> 01:14:15.560]   You know, like, a lot of people who are like, "Oh, I'm just gonna go and do this."
[01:14:15.560 --> 01:14:19.160]   Or when to give them an account or when is Instagram appropriate?
[01:14:19.160 --> 01:14:20.560]   Or is TikTok even okay?
[01:14:20.560 --> 01:14:22.480]   Yeah, it's a lot.
[01:14:22.480 --> 01:14:23.920]   The answer to that is no.
[01:14:23.920 --> 01:14:24.920]   It is not.
[01:14:24.920 --> 01:14:25.920]   TikTok is...
[01:14:25.920 --> 01:14:26.920]   There's nothing...
[01:14:26.920 --> 01:14:27.920]   Well, I don't know.
[01:14:27.920 --> 01:14:31.560]   I don't watch it enough of it to say there's nothing bad on it.
[01:14:31.560 --> 01:14:32.560]   I'm not...
[01:14:32.560 --> 01:14:33.720]   No, no, the content is terrific.
[01:14:33.720 --> 01:14:34.720]   That's not my concern.
[01:14:34.720 --> 01:14:35.720]   My concern is...
[01:14:35.720 --> 01:14:36.720]   It's addictive as hell.
[01:14:36.720 --> 01:14:37.720]   Well...
[01:14:37.720 --> 01:14:40.880]   The parent company and the amount of data that's being scraped and collected, and if you're
[01:14:40.880 --> 01:14:42.880]   okay with that, then...
[01:14:42.880 --> 01:14:43.880]   Sure.
[01:14:43.880 --> 01:14:44.880]   Use it.
[01:14:44.880 --> 01:14:45.880]   Yeah, we just saw a story...
[01:14:45.880 --> 01:14:50.400]   I don't know how bad a big a deal it is, but I just saw a story that said, "TikTok, among
[01:14:50.400 --> 01:14:53.680]   others, lots of apps on the iPhone get the clipboard."
[01:14:53.680 --> 01:14:57.200]   And so if there's something on your clipboard, but that's how these systems work.
[01:14:57.200 --> 01:14:59.560]   I mean, that shouldn't be a surprise to anybody.
[01:14:59.560 --> 01:15:05.800]   How would you cut and paste between apps if the clipboard were in a global system thing?
[01:15:05.800 --> 01:15:11.880]   But nevertheless, if you have on your clipboard something important, you're sending it right
[01:15:11.880 --> 01:15:14.960]   to the Chinese company.
[01:15:14.960 --> 01:15:16.120]   I actually don't...
[01:15:16.120 --> 01:15:19.800]   That's not what bothers me so much about it.
[01:15:19.800 --> 01:15:21.120]   It's the addictive nature of it.
[01:15:21.120 --> 01:15:24.920]   And that's why I think Marquez, your friends, who are teachers, those kids have a hard time
[01:15:24.920 --> 01:15:25.920]   putting that down.
[01:15:25.920 --> 01:15:27.720]   They come into the classroom and they want it...
[01:15:27.720 --> 01:15:29.200]   They're still swiping.
[01:15:29.200 --> 01:15:30.200]   Yeah.
[01:15:30.200 --> 01:15:32.640]   And if you've ever used the TikTok app, it's...
[01:15:32.640 --> 01:15:39.080]   I mean, they all do this to an extent, but it's designed to encourage long-term behavior.
[01:15:39.080 --> 01:15:42.360]   So if you just keep swiping, it'll just keep showing you new stuff.
[01:15:42.360 --> 01:15:43.760]   That's why YouTube has a recommended section.
[01:15:43.760 --> 01:15:44.760]   That's the whole point.
[01:15:44.760 --> 01:15:48.640]   So, yeah, that sort of behavior has to be...
[01:15:48.640 --> 01:15:52.280]   Decisions have to be made about it pretty early to prevent it from becoming addictive
[01:15:52.280 --> 01:15:53.480]   in that way.
[01:15:53.480 --> 01:15:54.960]   Yeah.
[01:15:54.960 --> 01:15:57.520]   It's interesting.
[01:15:57.520 --> 01:15:58.520]   That would bother me more.
[01:15:58.520 --> 01:16:01.440]   I don't care if the Chinese get my clipboard, but I don't...
[01:16:01.440 --> 01:16:03.400]   I'll tell you.
[01:16:03.400 --> 01:16:04.400]   We have...
[01:16:04.400 --> 01:16:08.160]   So we've got all kinds of decommissioned phones and everything has been wiped.
[01:16:08.160 --> 01:16:14.720]   And so with our little network, she has the ability to experiment and test things out.
[01:16:14.720 --> 01:16:16.960]   That kid still would...
[01:16:16.960 --> 01:16:19.640]   She's got all this technology she could ever possibly want.
[01:16:19.640 --> 01:16:21.680]   She would still prefer to sit and read.
[01:16:21.680 --> 01:16:22.960]   Good for her.
[01:16:22.960 --> 01:16:23.960]   So...
[01:16:23.960 --> 01:16:25.200]   And I'm not saying like one thing is better.
[01:16:25.200 --> 01:16:26.720]   I'm not saying like every kid...
[01:16:26.720 --> 01:16:27.720]   I am.
[01:16:27.720 --> 01:16:28.720]   I am.
[01:16:28.720 --> 01:16:33.240]   If you had a choice with all due respect, Mark has mixed great videos.
[01:16:33.240 --> 01:16:38.320]   But if you had a nine-year-old named the choice between reading or watching YouTube videos,
[01:16:38.320 --> 01:16:40.680]   I think it'd be better to read.
[01:16:40.680 --> 01:16:41.680]   Now...
[01:16:41.680 --> 01:16:42.680]   Is that old...
[01:16:42.680 --> 01:16:44.480]   Is that old fashion of us, Mark, are we...
[01:16:44.480 --> 01:16:45.480]   Are we...
[01:16:45.480 --> 01:16:46.480]   Are you gonna say...
[01:16:46.480 --> 01:16:47.480]   I hate this funny...
[01:16:47.480 --> 01:16:48.480]   Okay, Boomer.
[01:16:48.480 --> 01:16:50.600]   No, YouTube is such a wide...
[01:16:50.600 --> 01:16:54.040]   There's such a gigantic variation in what is on YouTube.
[01:16:54.040 --> 01:16:55.400]   It's everything basically now.
[01:16:55.400 --> 01:17:00.040]   So on one hand, yeah, you're avoiding all the garbage that's on YouTube.
[01:17:00.040 --> 01:17:01.040]   You're avoiding all the...
[01:17:01.040 --> 01:17:02.040]   All the good stuff.
[01:17:02.040 --> 01:17:03.040]   I'm not using the YouTube technology content.
[01:17:03.040 --> 01:17:05.680]   But on the other hand, there is educational content.
[01:17:05.680 --> 01:17:07.640]   There's tutorials where you can learn to do stuff.
[01:17:07.640 --> 01:17:11.280]   The only reason I know how to make videos is because I learned everything I know about
[01:17:11.280 --> 01:17:16.520]   making videos by watching YouTube videos about how to do these things.
[01:17:16.520 --> 01:17:21.880]   So there's that whole section as well that you're missing out on by not having any YouTube.
[01:17:21.880 --> 01:17:26.760]   So it's hard to just paint it as this broad brush like YouTube is good or just wait to
[01:17:26.760 --> 01:17:28.320]   have YouTube.
[01:17:28.320 --> 01:17:31.000]   It's a little more nuanced than just the whole thing.
[01:17:31.000 --> 01:17:34.680]   But yeah, there's a lot of conversations about that.
[01:17:34.680 --> 01:17:36.280]   There's a ton of great science.
[01:17:36.280 --> 01:17:37.720]   You can learn so much.
[01:17:37.720 --> 01:17:39.680]   Oh, yeah.
[01:17:39.680 --> 01:17:42.920]   So it's a curation issue more than anything else.
[01:17:42.920 --> 01:17:45.760]   I think it's a time issue and a choice issue.
[01:17:45.760 --> 01:17:51.280]   So the challenge here is reminding not just kids, but like people.
[01:17:51.280 --> 01:17:53.680]   And I think everybody's gonna...
[01:17:53.680 --> 01:18:01.240]   The harsh reality of our quarantine is gonna get worse, not better in the near future.
[01:18:01.240 --> 01:18:07.840]   It is easier to be a passive consumer of information than an active one.
[01:18:07.840 --> 01:18:15.200]   And whether it is passively consuming whatever it might be, I would rather that we are all
[01:18:15.200 --> 01:18:17.680]   more active consumers when we can be.
[01:18:17.680 --> 01:18:26.000]   Which means if you're watching a YouTube video of any kind, sometimes it's fine to be passive,
[01:18:26.000 --> 01:18:28.080]   but it's not fine to be passive all the time.
[01:18:28.080 --> 01:18:35.760]   And my concern is this sort of growing passive viewing and passive consumption, I think that's
[01:18:35.760 --> 01:18:37.760]   the thing that's problematic for us, really.
[01:18:37.760 --> 01:18:43.360]   Well, but somebody like Markaz who's learning his whole business by tutorial videos on YouTube,
[01:18:43.360 --> 01:18:45.360]   this is incredible.
[01:18:45.360 --> 01:18:48.680]   Or a kid in Calcutto who's learning how to code.
[01:18:48.680 --> 01:18:50.640]   I mean, it's amazing.
[01:18:50.640 --> 01:18:51.800]   Or learning mathematics.
[01:18:51.800 --> 01:18:53.680]   Or I mean, it's...
[01:18:53.680 --> 01:18:59.960]   The active choosing to watch a certain thing, to learn something is awesome.
[01:18:59.960 --> 01:19:05.920]   I remember when I was struggling with chemistry in high school and I found myself needing things
[01:19:05.920 --> 01:19:07.920]   to be repeated, but the teacher didn't.
[01:19:07.920 --> 01:19:12.520]   I would go on YouTube and go find that same lesson by another professor in some college
[01:19:12.520 --> 01:19:15.440]   somewhere and just watch it myself at my own speed.
[01:19:15.440 --> 01:19:19.440]   And then suddenly that's more useful than anything I was getting anywhere else.
[01:19:19.440 --> 01:19:21.680]   So that was great.
[01:19:21.680 --> 01:19:25.280]   But there's also people who just like go to sleep with videos streaming in the background
[01:19:25.280 --> 01:19:31.080]   and people who just like have content constantly passively being like basically fed into their
[01:19:31.080 --> 01:19:32.320]   brain, which isn't great.
[01:19:32.320 --> 01:19:34.960]   We've always had that wallpaper music.
[01:19:34.960 --> 01:19:36.680]   We've always had that.
[01:19:36.680 --> 01:19:37.680]   That's a...
[01:19:37.680 --> 01:19:41.920]   There's some weird human need to have constant stuff going on in the background.
[01:19:41.920 --> 01:19:44.720]   But when I was growing up, lots of people, I always thought I was kind of shocking, but
[01:19:44.720 --> 01:19:48.720]   lots of people, I know lots of kids who had the TV on all the time.
[01:19:48.720 --> 01:19:50.720]   They'd sit down at dinner and the TV'd be on.
[01:19:50.720 --> 01:19:52.560]   You've seen that, right, Amy?
[01:19:52.560 --> 01:19:56.920]   So I think Amy, you've done something interesting because you've tried to craft an environment
[01:19:56.920 --> 01:20:04.720]   for your daughter that stimulates creativity and thought, doesn't feel deprived, but is
[01:20:04.720 --> 01:20:06.080]   also protected.
[01:20:06.080 --> 01:20:07.000]   Yeah.
[01:20:07.000 --> 01:20:10.320]   And it's not just us.
[01:20:10.320 --> 01:20:14.040]   So some of our closest friends are...
[01:20:14.040 --> 01:20:19.160]   We have an interesting friend group, so then they're all fairly highly technical.
[01:20:19.160 --> 01:20:23.160]   Everybody's indexing and everybody's sort of moving in this direction or in this direction,
[01:20:23.160 --> 01:20:26.480]   which is...
[01:20:26.480 --> 01:20:32.760]   We all want our kids to have technical skills and we all want our kids to be educated.
[01:20:32.760 --> 01:20:34.800]   Listen, there's plenty of funds.
[01:20:34.800 --> 01:20:44.240]   We don't want to not have fun, but we also recognize the response that our brains have
[01:20:44.240 --> 01:20:49.560]   to technology and the benefit there is to critical thinking and sometimes being more
[01:20:49.560 --> 01:20:50.760]   active versus passive.
[01:20:50.760 --> 01:20:56.480]   So I think the key here is just don't just do a thing.
[01:20:56.480 --> 01:20:58.080]   Make sure there's a diverse for everybody.
[01:20:58.080 --> 01:21:02.000]   And again, we're all going to be sitting in our homes a lot going forward.
[01:21:02.000 --> 01:21:09.200]   So find yourself a new podcast, find yourself a new book, get five sources of media that
[01:21:09.200 --> 01:21:16.160]   you don't normally engage with and flip between them so that you are getting a nice diverse
[01:21:16.160 --> 01:21:18.080]   outlook on life.
[01:21:18.080 --> 01:21:23.880]   I mean, there's immense opportunity, but also there's an immense amount of garbage.
[01:21:23.880 --> 01:21:24.880]   That's a tough...
[01:21:24.880 --> 01:21:25.880]   That's really...
[01:21:25.880 --> 01:21:29.360]   Again, I'm glad I'm not parenting in the 21st century.
[01:21:29.360 --> 01:21:30.360]   Holy...
[01:21:30.360 --> 01:21:31.920]   Listen, but there's a ton of opportunity.
[01:21:31.920 --> 01:21:39.600]   I mean, my God, I was trying to explain something related to the eyeball the other day.
[01:21:39.600 --> 01:21:43.600]   And we were able to go on YouTube and there's a video that had...
[01:21:43.600 --> 01:21:50.800]   There has never been a moment in history as rich and full of opportunity as there is
[01:21:50.800 --> 01:21:53.040]   today because of all of this media.
[01:21:53.040 --> 01:21:54.040]   It's kind of amazing.
[01:21:54.040 --> 01:21:55.600]   It's too much.
[01:21:55.600 --> 01:22:00.000]   Don't you sometimes feel like there's too much?
[01:22:00.000 --> 01:22:01.000]   I'm overwhelmed.
[01:22:01.000 --> 01:22:02.000]   I can't...
[01:22:02.000 --> 01:22:04.000]   I don't know if it's like walking into...
[01:22:04.000 --> 01:22:05.000]   Go ahead, Mark.
[01:22:05.000 --> 01:22:10.000]   It'd be like if you walked into a library for the first time, you just learned how to
[01:22:10.000 --> 01:22:15.600]   read and now you're in the biggest library in the world and there's 70 levels of shelves.
[01:22:15.600 --> 01:22:18.840]   It can seem like too much if you don't know what you're looking for, but I guess being
[01:22:18.840 --> 01:22:21.840]   able to search and find exactly what you need is a big part of that.
[01:22:21.840 --> 01:22:25.080]   Mark, guys, now that you're making so much YouTube video, do you have any time at all
[01:22:25.080 --> 01:22:28.160]   to watch any YouTube video?
[01:22:28.160 --> 01:22:29.160]   It's funny.
[01:22:29.160 --> 01:22:30.240]   I do watch a lot of YouTube.
[01:22:30.240 --> 01:22:35.680]   I don't watch much TV at all and the only TV I really watch is live sports, which at
[01:22:35.680 --> 01:22:37.120]   the moment doesn't happen much.
[01:22:37.120 --> 01:22:38.280]   Not much of that.
[01:22:38.280 --> 01:22:42.200]   Yeah, so I watch a lot of tech on YouTube, but I watch a lot of...
[01:22:42.200 --> 01:22:45.920]   Some of my favorite channels are actually science and education channels, smarter every
[01:22:45.920 --> 01:22:47.680]   day, very potassium, Vsauce.
[01:22:47.680 --> 01:22:48.680]   Love smart every day.
[01:22:48.680 --> 01:22:49.680]   All these guys.
[01:22:49.680 --> 01:22:50.680]   I love Vsauce.
[01:22:50.680 --> 01:22:53.040]   Incredible videos, so I watch a lot of YouTube too.
[01:22:53.040 --> 01:22:55.720]   You can get really smart if you just watch those three.
[01:22:55.720 --> 01:22:57.760]   You're right, I completely agree with you.
[01:22:57.760 --> 01:22:58.760]   Yeah.
[01:22:58.760 --> 01:23:01.080]   You're a kid, he's 25.
[01:23:01.080 --> 01:23:02.080]   How old are you?
[01:23:02.080 --> 01:23:03.080]   26.
[01:23:03.080 --> 01:23:04.080]   26.
[01:23:04.080 --> 01:23:05.080]   So he's a little younger than you.
[01:23:05.080 --> 01:23:06.800]   Yeah, he never watched TV.
[01:23:06.800 --> 01:23:08.280]   He didn't need to.
[01:23:08.280 --> 01:23:09.280]   Yeah.
[01:23:09.280 --> 01:23:10.280]   It was all YouTube.
[01:23:10.280 --> 01:23:12.520]   And by the way, he didn't listen to music.
[01:23:12.520 --> 01:23:14.120]   I mean, music was YouTube.
[01:23:14.120 --> 01:23:17.160]   Everything was YouTube for him.
[01:23:17.160 --> 01:23:19.600]   Except for sports, which I mean...
[01:23:19.600 --> 01:23:20.600]   You know, here's another...
[01:23:20.600 --> 01:23:21.600]   That's interesting.
[01:23:21.600 --> 01:23:22.600]   I wonder.
[01:23:22.600 --> 01:23:25.480]   I've been building new models, speaking of sports.
[01:23:25.480 --> 01:23:29.000]   I wonder if this is going to be the thing that finally gets esports to take off.
[01:23:29.000 --> 01:23:32.120]   The beginning of the end, although esports is also postponed.
[01:23:32.120 --> 01:23:37.480]   Right, but I just wonder if we're talking about a couple of months.
[01:23:37.480 --> 01:23:43.440]   I think there's an opportunity here for esports in some form to find its real audience at
[01:23:43.440 --> 01:23:45.720]   scale outside of Asia.
[01:23:45.720 --> 01:23:54.880]   You can't underestimate, I should say, the potential for change, even with a little hiatus.
[01:23:54.880 --> 01:23:58.760]   People may come back to the NBA and go, "Yeah, I don't really miss it."
[01:23:58.760 --> 01:24:00.320]   Or NHL, or "I don't really miss it."
[01:24:00.320 --> 01:24:03.720]   I remember the baseball strike was the end of the line for me in Major League Baseball.
[01:24:03.720 --> 01:24:05.480]   It was like, "Eh, I give up."
[01:24:05.480 --> 01:24:06.480]   Seriously?
[01:24:06.480 --> 01:24:07.480]   Yeah.
[01:24:07.480 --> 01:24:08.480]   You're no longer a baseball fan?
[01:24:08.480 --> 01:24:09.480]   Well, a little bit.
[01:24:09.480 --> 01:24:10.480]   But it really...
[01:24:10.480 --> 01:24:12.440]   I used to go to 40 or 50 games a year.
[01:24:12.440 --> 01:24:15.040]   It really cut into my enjoyment of the game.
[01:24:15.040 --> 01:24:20.920]   But it was also just a realization that, "Oh, I can live without it.
[01:24:20.920 --> 01:24:21.920]   I can do other things.
[01:24:21.920 --> 01:24:23.640]   There's other things to do."
[01:24:23.640 --> 01:24:30.120]   I think there's an opening here for esports, for multiplayer games, multiplayer games in
[01:24:30.120 --> 01:24:31.120]   VR.
[01:24:31.120 --> 01:24:36.280]   I think that there's going to be a lot of opportunity that maybe wasn't as prevalent
[01:24:36.280 --> 01:24:39.080]   because of what we're living through right now.
[01:24:39.080 --> 01:24:40.400]   Absolutely.
[01:24:40.400 --> 01:24:41.400]   Let's take a little break.
[01:24:41.400 --> 01:24:42.560]   Marquez Brownlee is here.
[01:24:42.560 --> 01:24:43.560]   MKBHD.
[01:24:43.560 --> 01:24:46.720]   Always a pleasure to talk to you, Marquez.
[01:24:46.720 --> 01:24:49.440]   It's just so impressive what you've done.
[01:24:49.440 --> 01:24:54.040]   I'm going to ask you about esports when we come back and what your game is.
[01:24:54.040 --> 01:24:55.040]   What's your game, Brownlee?
[01:24:55.040 --> 01:24:57.000]   What's your game, man?
[01:24:57.000 --> 01:24:59.000]   I'm also thrilled to have Amy Webb.
[01:24:59.000 --> 01:25:00.160]   We love having you on.
[01:25:00.160 --> 01:25:01.760]   I just wish you'd move out here.
[01:25:01.760 --> 01:25:02.760]   Forget Baltimore.
[01:25:02.760 --> 01:25:04.160]   Forget New York.
[01:25:04.160 --> 01:25:10.240]   Just come to Northern California and just be on every show all the time.
[01:25:10.240 --> 01:25:11.600]   Honestly, you're fantastic.
[01:25:11.600 --> 01:25:15.560]   We still have to get to your futures stuff, and we will in a bit.
[01:25:15.560 --> 01:25:19.200]   But I have to mention our sponsor, Zip-A-Cru-T-T-R.
[01:25:19.200 --> 01:25:23.640]   I was just going down the list with Lisa of the people we've hired using Zip-A-Cru-T-R.
[01:25:23.640 --> 01:25:27.040]   Honestly, some of our best employees.
[01:25:27.040 --> 01:25:33.920]   Zip-A-Cru-T-R is the modern state-of-the-art way to hire.
[01:25:33.920 --> 01:25:37.200]   The people you hire are the people that make or break your company.
[01:25:37.200 --> 01:25:39.360]   In fact, that's all a company is.
[01:25:39.360 --> 01:25:41.840]   It's the people.
[01:25:41.840 --> 01:25:47.560]   And getting the right people could take your company to the moon, getting the wrong people.
[01:25:47.560 --> 01:25:49.360]   Maybe that rocket won't lift off the pad.
[01:25:49.360 --> 01:25:51.440]   That's why you got to hire right.
[01:25:51.440 --> 01:25:53.480]   But of course, hiring is challenging.
[01:25:53.480 --> 01:25:57.120]   Zip-A-Cru-T-R makes hiring simple and smart.
[01:25:57.120 --> 01:26:04.520]   According to Zip-A-Cru-T-R research, 75% of employers have difficulty filling open positions, which
[01:26:04.520 --> 01:26:07.160]   is why employers are taking bold steps to hire.
[01:26:07.160 --> 01:26:08.960]   For instance, raising wages.
[01:26:08.960 --> 01:26:13.960]   68% of employers have raised the wages because it's so tough.
[01:26:13.960 --> 01:26:17.920]   23% have increased benefits.
[01:26:17.920 --> 01:26:19.640]   But there's another way, and you can still do that.
[01:26:19.640 --> 01:26:20.640]   I encourage you to do so.
[01:26:20.640 --> 01:26:21.640]   But there's another way.
[01:26:21.640 --> 01:26:25.520]   If you have a difficult role to fill, no matter what industry, hire with Zip-A-Cru-T-R.
[01:26:25.520 --> 01:26:27.160]   I'll tell you why Zip-A-Cru-T-R works.
[01:26:27.160 --> 01:26:30.240]   First of all, it casts the widest net.
[01:26:30.240 --> 01:26:34.800]   Zip-A-Cru-T-R, as soon as you post there, post to 100+ job sites.
[01:26:34.800 --> 01:26:38.880]   So assuming that the right person's out there, you're going to be in more places, more chances
[01:26:38.880 --> 01:26:42.320]   to get a bite, get the right person.
[01:26:42.320 --> 01:26:45.320]   But then they go beyond that, and this is the thing that's made a big difference for
[01:26:45.320 --> 01:26:46.320]   us.
[01:26:46.320 --> 01:26:50.880]   They use powerful matching technology to scan the resumes they have on file.
[01:26:50.880 --> 01:26:54.760]   I can't tell you how well that works.
[01:26:54.760 --> 01:26:58.800]   Four out of five employers who post on Zip-A-Cru-T-R get a quality candidate within the first
[01:26:58.800 --> 01:26:59.800]   day.
[01:26:59.800 --> 01:27:04.280]   We do typically within an hour or two, and I'm always, I love it because Lisa's like,
[01:27:04.280 --> 01:27:05.480]   "Oh, this one's good.
[01:27:05.480 --> 01:27:07.240]   Oh, this one's really good.
[01:27:07.240 --> 01:27:10.360]   The best part is it doesn't go in your mailbox, your inbox doesn't go in your phone
[01:27:10.360 --> 01:27:12.760]   system, no, they don't leave voicemails.
[01:27:12.760 --> 01:27:18.560]   All the resumes, all the applicants are filtered into the Zip-A-Cru-T-R interface, and they
[01:27:18.560 --> 01:27:20.120]   reformat the resumes.
[01:27:20.120 --> 01:27:24.080]   You can have screening questions, and they highlight the best candidates, so it's very
[01:27:24.080 --> 01:27:29.160]   easy to look at that interface and say, "Oh, here's the person."
[01:27:29.160 --> 01:27:31.280]   Zip-A-Cru-T-R, if you're not using it, you've got to try it.
[01:27:31.280 --> 01:27:35.080]   Go to zippercruiter.com/twit and try it for free right now.
[01:27:35.080 --> 01:27:40.720]   Zip-A-Cruiter.com/twit.
[01:27:40.720 --> 01:27:43.400]   It's the smartest way to hire, and I can't tell you, we've had such great results.
[01:27:43.400 --> 01:27:48.080]   zippercruiter.com/twit.
[01:27:48.080 --> 01:27:53.080]   Do we have, Kevin, a promo for the week?
[01:27:53.080 --> 01:27:55.600]   We have something even better than a promo.
[01:27:55.600 --> 01:27:57.440]   Carsten Bondi, my producer.
[01:27:57.440 --> 01:28:00.080]   We have a whole new show.
[01:28:00.080 --> 01:28:01.080]   What?
[01:28:01.080 --> 01:28:02.080]   Let's watch.
[01:28:02.080 --> 01:28:03.600]   This is Twit.
[01:28:03.600 --> 01:28:04.600]   [music]
[01:28:04.600 --> 01:28:12.600]   Hello, everybody.
[01:28:12.600 --> 01:28:15.000]   Welcome to a brand new show on the Twit Network.
[01:28:15.000 --> 01:28:20.720]   This is episode zero of "Home Hands on Mac."
[01:28:20.720 --> 01:28:22.160]   My name is Leo LaPorte.
[01:28:22.160 --> 01:28:25.880]   You may have seen me on such shows as The Screen Savers and Call for Help.
[01:28:25.880 --> 01:28:30.520]   I've been doing Mac Break Weekly for almost 15 years, but I wanted to do a short show,
[01:28:30.520 --> 01:28:35.440]   a five-minute program every week, that will cover my favorite Mac apps, my favorite Mac
[01:28:35.440 --> 01:28:40.480]   tips, getting deep into the terminal, using brew, all of the tools that people have been
[01:28:40.480 --> 01:28:46.360]   using Mac like me for years really love about this great operating system.
[01:28:46.360 --> 01:28:51.280]   One thing that's sure, Apple has not made Mac OS easier to use over the years, but it
[01:28:51.280 --> 01:28:53.200]   has made it more powerful.
[01:28:53.200 --> 01:28:57.400]   And I'm going to show you ways you can get the most out of your Macintosh.
[01:28:57.400 --> 01:28:58.960]   The show will come out every Friday.
[01:28:58.960 --> 01:29:03.200]   It's a quick hit you can watch or listen, but you got to subscribe.
[01:29:03.200 --> 01:29:07.680]   Go to your favorite podcast application or Stitcher or Slack or a Pocketcaster.
[01:29:07.680 --> 01:29:08.680]   You know the drill.
[01:29:08.680 --> 01:29:10.800]   Subscribe to Hands on Mac.
[01:29:10.800 --> 01:29:16.080]   We're also on YouTube and you can always get it from our website at twit.tv/hom.
[01:29:16.080 --> 01:29:18.120]   There's audio and there's video.
[01:29:18.120 --> 01:29:22.400]   Whichever way you subscribe, I will see you starting March 20th.
[01:29:22.400 --> 01:29:23.680]   That's one week from today.
[01:29:23.680 --> 01:29:26.560]   Our very first Hands on Mac.
[01:29:26.560 --> 01:29:27.560]   I'll see you then.
[01:29:27.560 --> 01:29:32.920]   I obviously recorded that on March 13th.
[01:29:32.920 --> 01:29:34.120]   So it's less than a week.
[01:29:34.120 --> 01:29:37.680]   It's coming Friday.
[01:29:37.680 --> 01:29:39.680]   Back to the show we go.
[01:29:39.680 --> 01:29:40.680]   Thank you for allowing me to.
[01:29:40.680 --> 01:29:41.680]   I love promo.
[01:29:41.680 --> 01:29:42.680]   Pardon me?
[01:29:42.680 --> 01:29:43.680]   You like that?
[01:29:43.680 --> 01:29:45.320]   I promo it made me feel very nostalgic.
[01:29:45.320 --> 01:29:47.240]   High quality 720p.
[01:29:47.240 --> 01:29:49.560]   It's amazing what you can do these days.
[01:29:49.560 --> 01:29:50.960]   It was cool.
[01:29:50.960 --> 01:29:56.680]   But kids, if you saw what we shoot our stuff on you would just.
[01:29:56.680 --> 01:29:57.960]   You know what's funny?
[01:29:57.960 --> 01:30:01.600]   I have a great 720p story.
[01:30:01.600 --> 01:30:05.160]   What's the ball drop show called at the New Year's?
[01:30:05.160 --> 01:30:06.160]   Yeah, Rockin' the Year's.
[01:30:06.160 --> 01:30:07.400]   The New Year's Rockin' Eve.
[01:30:07.400 --> 01:30:08.400]   Yeah.
[01:30:08.400 --> 01:30:12.000]   They wanted me to send in a clip for it to say hi.
[01:30:12.000 --> 01:30:13.000]   This is MKBHD.
[01:30:13.000 --> 01:30:14.000]   Happy New Year.
[01:30:14.000 --> 01:30:15.000]   Nice.
[01:30:15.000 --> 01:30:16.000]   That type of thing.
[01:30:16.000 --> 01:30:17.000]   Nice.
[01:30:17.000 --> 01:30:18.000]   And I was like, oh yeah, that's amazing.
[01:30:18.000 --> 01:30:19.000]   I'll do it.
[01:30:19.000 --> 01:30:20.000]   What do you need?
[01:30:20.000 --> 01:30:23.640]   And they were like, we just need the clip 20 seconds or less 720p.
[01:30:23.640 --> 01:30:24.640]   Of course.
[01:30:24.640 --> 01:30:25.640]   It's TV.
[01:30:25.640 --> 01:30:26.640]   Oh.
[01:30:26.640 --> 01:30:28.640]   Do I have anything that I can shoot?
[01:30:28.640 --> 01:30:31.360]   You didn't have anything you could shoot it on.
[01:30:31.360 --> 01:30:37.320]   So I shot it in 8K and I downscaled it all the way to 720p.
[01:30:37.320 --> 01:30:39.160]   And that was what went on broadcast TV.
[01:30:39.160 --> 01:30:40.160]   It was beautiful.
[01:30:40.160 --> 01:30:43.200]   And what didn't happen is you didn't say, oh we should do everything this way from now
[01:30:43.200 --> 01:30:44.200]   on.
[01:30:44.200 --> 01:30:45.200]   It's so cheesy.
[01:30:45.200 --> 01:30:46.200]   No, yeah.
[01:30:46.200 --> 01:30:47.200]   No.
[01:30:47.200 --> 01:30:48.920]   I mean it uploaded super fast.
[01:30:48.920 --> 01:30:49.920]   Yeah.
[01:30:49.920 --> 01:30:51.640]   Yeah, file size is much smaller.
[01:30:51.640 --> 01:30:52.840]   We actually changed.
[01:30:52.840 --> 01:30:58.120]   We were offering, and I apologize, this is going to break some people's hearts, but we
[01:30:58.120 --> 01:31:01.320]   were offering I think three different quality levels, right John?
[01:31:01.320 --> 01:31:03.480]   What was the lowest quality we offered?
[01:31:03.480 --> 01:31:04.480]   480?
[01:31:04.480 --> 01:31:08.160]   SD, 480p for bandwidth, you know, people with low bandwidth.
[01:31:08.160 --> 01:31:10.600]   And then we did a middle and a high.
[01:31:10.600 --> 01:31:14.480]   And honestly, and by the way, email me if this isn't the best thing.
[01:31:14.480 --> 01:31:17.840]   I know you're listening home grinding your gears.
[01:31:17.840 --> 01:31:20.200]   But we figured, why are we doing that?
[01:31:20.200 --> 01:31:21.640]   No one else does that.
[01:31:21.640 --> 01:31:24.200]   We're doing 720p for everything.
[01:31:24.200 --> 01:31:27.880]   But there are some people on limited bandwidth who might say, oh, I really like that 480.
[01:31:27.880 --> 01:31:28.920]   So let us know.
[01:31:28.920 --> 01:31:32.080]   But I think we're just going to go forward.
[01:31:32.080 --> 01:31:41.160]   We had a really ridiculous transcoding flowmark as we're, it was running an FFmpeg and 15 different
[01:31:41.160 --> 01:31:42.160]   things.
[01:31:42.160 --> 01:31:44.320]   And it was crazy.
[01:31:44.320 --> 01:31:47.760]   So we're going to make this a little simpler, just have one video format and one audio.
[01:31:47.760 --> 01:31:49.960]   No, we still do just one audio format.
[01:31:49.960 --> 01:31:50.960]   Yeah.
[01:31:50.960 --> 01:31:56.280]   And one show, Steve Gibson, our security show, still makes, he does it himself.
[01:31:56.280 --> 01:31:57.280]   We don't.
[01:31:57.280 --> 01:31:59.280]   A 16 kilobit audio version.
[01:31:59.280 --> 01:32:01.720]   It sounds like Rudy Valley.
[01:32:01.720 --> 01:32:05.120]   Let's talk about security.
[01:32:05.120 --> 01:32:09.480]   But there are people who just, you know, I want the smallest possible file.
[01:32:09.480 --> 01:32:13.960]   So, but if you're watching on YouTube, you can do anything you want because YouTube,
[01:32:13.960 --> 01:32:18.160]   it's actually, this must blow your mind when you think about it, Marquez.
[01:32:18.160 --> 01:32:23.720]   They take your video and they've transcoded into, I don't know, 15 different form, huge
[01:32:23.720 --> 01:32:24.960]   number of formats.
[01:32:24.960 --> 01:32:25.960]   Yeah.
[01:32:25.960 --> 01:32:26.960]   Yeah.
[01:32:26.960 --> 01:32:27.960]   I talked about this.
[01:32:27.960 --> 01:32:31.120]   I think last year was a video about just YouTube processing and just how it works.
[01:32:31.120 --> 01:32:36.200]   Because if you upload an 8K video, which I did for this, it's not just going to spit
[01:32:36.200 --> 01:32:40.560]   out that 8K video for all million people that want to play it back.
[01:32:40.560 --> 01:32:41.920]   Obviously that would suck.
[01:32:41.920 --> 01:32:49.320]   So they make a 144P version, a 240P version, a 360P version, a 480P version.
[01:32:49.320 --> 01:32:52.640]   And not only do they choose based on your internet connection, which one to play back
[01:32:52.640 --> 01:32:56.120]   for you, but they'll dynamically switch between them based on if they get a buffer big enough
[01:32:56.120 --> 01:32:57.880]   of the next highest resolution.
[01:32:57.880 --> 01:33:03.520]   So if you're at 480P and they realize they're fast enough to bump up to 720p HD midway through
[01:33:03.520 --> 01:33:06.480]   the stream, you'll notice it gets a little clearer, a little sharper.
[01:33:06.480 --> 01:33:07.480]   Yeah.
[01:33:07.480 --> 01:33:11.000]   Because YouTube just realized, so all this stuff is, it's beautiful that they do all
[01:33:11.000 --> 01:33:15.280]   of this at a rate, unspeakable amounts of data every day.
[01:33:15.280 --> 01:33:16.680]   They just have more bandwidth.
[01:33:16.680 --> 01:33:17.680]   Thank you.
[01:33:17.680 --> 01:33:18.680]   Yeah, thank you.
[01:33:18.680 --> 01:33:19.680]   Free.
[01:33:19.680 --> 01:33:20.680]   Yeah.
[01:33:20.680 --> 01:33:21.680]   Free.
[01:33:21.680 --> 01:33:23.960]   Your business couldn't exist if you had to pay for the bandwidth.
[01:33:23.960 --> 01:33:25.120]   No, yeah.
[01:33:25.120 --> 01:33:26.640]   That's the beauty of the platform.
[01:33:26.640 --> 01:33:28.040]   This is, yeah.
[01:33:28.040 --> 01:33:34.280]   If I'd, I've said I would pay for like a YouTube premium uploader account where you
[01:33:34.280 --> 01:33:37.160]   can like get priority processing.
[01:33:37.160 --> 01:33:39.760]   I was trying to give them ideas for making more money from creators.
[01:33:39.760 --> 01:33:42.760]   But this would honestly be something I'd pay for is if you could accelerate processing
[01:33:42.760 --> 01:33:47.440]   and choose, you know, some certain options that aren't available on the free tier, I
[01:33:47.440 --> 01:33:48.440]   would absolutely do that.
[01:33:48.440 --> 01:33:51.880]   How long do you wait before when you post a show before it's ready?
[01:33:51.880 --> 01:33:53.120]   It's available on YouTube.
[01:33:53.120 --> 01:33:54.120]   How long is it?
[01:33:54.120 --> 01:33:55.120]   Yeah.
[01:33:55.120 --> 01:33:56.120]   Okay.
[01:33:56.120 --> 01:33:57.120]   So it takes me, I get the finished file.
[01:33:57.120 --> 01:33:58.720]   It's maybe five to eight gigs usually.
[01:33:58.720 --> 01:34:02.320]   4K is what we upload in and I'll upload it.
[01:34:02.320 --> 01:34:05.440]   It'll take, you know, two, three minutes and then I'll watch it process.
[01:34:05.440 --> 01:34:06.680]   And YouTube always does the same thing.
[01:34:06.680 --> 01:34:08.520]   It'll start at zero percent.
[01:34:08.520 --> 01:34:12.640]   And it'll stay at zero percent processed for like 10 minutes.
[01:34:12.640 --> 01:34:19.000]   And then it'll snap to 95 percent, 96, 97, 98, 99, 100.
[01:34:19.000 --> 01:34:21.680]   And when it says 100, it's processed to 1080p.
[01:34:21.680 --> 01:34:27.080]   And I know I have to keep waiting another 15 minutes or so for the 1440p and 4K versions
[01:34:27.080 --> 01:34:31.880]   to process, which it doesn't notify me about, but I'll refresh and eventually I'll see it.
[01:34:31.880 --> 01:34:32.960]   And then it'll go live.
[01:34:32.960 --> 01:34:36.720]   So in total, maybe 20, 25 minutes of processing.
[01:34:36.720 --> 01:34:39.800]   That's not too bad, but you would like it faster.
[01:34:39.800 --> 01:34:43.840]   I would pay for it to be faster just because of how often I do it.
[01:34:43.840 --> 01:34:47.120]   You know, if I've uploaded, you know, what is it?
[01:34:47.120 --> 01:34:51.720]   A hundred videos last year, that would have been nice to save those hundred times, 25
[01:34:51.720 --> 01:34:52.720]   minutes.
[01:34:52.720 --> 01:34:53.720]   That's right.
[01:34:53.720 --> 01:34:56.280]   How many videos a day do you do or a week do you do?
[01:34:56.280 --> 01:34:58.320]   We are about twice a week.
[01:34:58.320 --> 01:35:04.280]   So last year, it ended up being about, I think almost exactly a hundred videos on the 52
[01:35:04.280 --> 01:35:05.280]   week years.
[01:35:05.280 --> 01:35:09.160]   I've been shown article, I think in the New York Times, it said, you'll do better if you
[01:35:09.160 --> 01:35:10.160]   upload daily.
[01:35:10.160 --> 01:35:11.160]   Oh, 100%.
[01:35:11.160 --> 01:35:13.920]   And we've, I've thought about it.
[01:35:13.920 --> 01:35:18.560]   If I uploaded every single day, the channel would absolutely no questions asked to be
[01:35:18.560 --> 01:35:21.000]   doing better by all metrics.
[01:35:21.000 --> 01:35:27.440]   But even if the content wasn't always great every time that that's the tradeoff is I am
[01:35:27.440 --> 01:35:31.640]   fully aware that the content would get significant, not significantly, but it would get worse.
[01:35:31.640 --> 01:35:32.640]   You run out of ideas.
[01:35:32.640 --> 01:35:34.200]   You start to rush things.
[01:35:34.200 --> 01:35:35.200]   The content gets worse.
[01:35:35.200 --> 01:35:39.560]   And part of what I think separates the channel in the first place and what I enjoy is really
[01:35:39.560 --> 01:35:44.800]   taking my time on videos and making them that extra step, spending an extra day on just
[01:35:44.800 --> 01:35:46.720]   the animations and the color and things like that.
[01:35:46.720 --> 01:35:53.360]   So we've made the quality over quantity choice at the expense of what the algorithm would
[01:35:53.360 --> 01:35:56.840]   probably favor, but I don't think it's, you know, ruining the channel or anything.
[01:35:56.840 --> 01:35:57.840]   Oh, I wouldn't say that.
[01:35:57.840 --> 01:35:59.840]   I think it's doing just fine.
[01:35:59.840 --> 01:36:00.840]   Thank you.
[01:36:00.840 --> 01:36:01.840]   Yeah.
[01:36:01.840 --> 01:36:02.840]   Yeah.
[01:36:02.840 --> 01:36:03.840]   You're pretty happy.
[01:36:03.840 --> 01:36:08.720]   We talked when you were still in school because we thought, boy, if we could just hire Mack
[01:36:08.720 --> 01:36:11.920]   has Brownlee, we would have a hit on our hands.
[01:36:11.920 --> 01:36:14.000]   And you said, I'm doing fine here.
[01:36:14.000 --> 01:36:18.760]   I'm just going to stay in school, finish my degree and then, you know, and of course you
[01:36:18.760 --> 01:36:19.760]   were absolutely right.
[01:36:19.760 --> 01:36:20.760]   You didn't need anybody.
[01:36:20.760 --> 01:36:22.360]   You were, you did it all by yourself.
[01:36:22.360 --> 01:36:24.880]   You're pretty happy with how it's worked out.
[01:36:24.880 --> 01:36:25.880]   Yeah.
[01:36:25.880 --> 01:36:27.480]   I mean, YouTube's changed a lot.
[01:36:27.480 --> 01:36:32.280]   The landscape of in online video has changed a lot.
[01:36:32.280 --> 01:36:35.400]   But I don't think I would change very much about how we've approached it in the past
[01:36:35.400 --> 01:36:37.600]   couple of years.
[01:36:37.600 --> 01:36:39.960]   You're a poster boy for this.
[01:36:39.960 --> 01:36:45.040]   I mean, you've really shown what can be done and do it in quality.
[01:36:45.040 --> 01:36:49.880]   You now attempted to move in with Logan Paul in the house and hang out and run another
[01:36:49.880 --> 01:36:50.880]   that.
[01:36:50.880 --> 01:36:53.880]   It would definitely make some very interesting videos.
[01:36:53.880 --> 01:36:55.280]   Well, you did this week.
[01:36:55.280 --> 01:36:57.280]   You did across promotion, right?
[01:36:57.280 --> 01:36:58.280]   Oh, yeah.
[01:36:58.280 --> 01:37:00.000]   We've done some collabs are always fun.
[01:37:00.000 --> 01:37:01.000]   Yeah.
[01:37:01.000 --> 01:37:04.080]   And Judner is also in New Jersey nearby.
[01:37:04.080 --> 01:37:08.960]   We did a collaborative review on the Galaxy S20 that I think will continue to do collaborations
[01:37:08.960 --> 01:37:09.960]   when it makes sense.
[01:37:09.960 --> 01:37:11.280]   We've also done the interview stuff.
[01:37:11.280 --> 01:37:15.640]   Those are a form of a collaboration in a way.
[01:37:15.640 --> 01:37:18.640]   But we also just, you can see the studio behind me.
[01:37:18.640 --> 01:37:22.840]   We're always constantly making stuff back here because tech just doesn't stop.
[01:37:22.840 --> 01:37:24.320]   Nice to have that opportunity.
[01:37:24.320 --> 01:37:26.560]   It's really nice to be able to do that.
[01:37:26.560 --> 01:37:28.480]   You know, I've been working in this business.
[01:37:28.480 --> 01:37:34.720]   By that, I mean, the tech journalism business since the late '70s.
[01:37:34.720 --> 01:37:36.480]   And it would start with magazines, right?
[01:37:36.480 --> 01:37:38.760]   And it's really been interesting to see how it's completely transformed.
[01:37:38.760 --> 01:37:41.880]   The magazines are gone, completely gone.
[01:37:41.880 --> 01:37:43.960]   They used to be so dominant.
[01:37:43.960 --> 01:37:48.560]   You know, people like Devorak, they had all the power in the world.
[01:37:48.560 --> 01:37:54.880]   When PC Magazine walked into Comdex or CES, that was, they were the king of the hill.
[01:37:54.880 --> 01:37:57.720]   You know, Bill Mcrono is the editor in chief.
[01:37:57.720 --> 01:37:59.360]   He was royalty.
[01:37:59.360 --> 01:38:01.280]   And that's completely flipped on its head.
[01:38:01.280 --> 01:38:06.440]   Now it's when Marcus Brownlee walks in and everybody goes, "Oh, quick."
[01:38:06.440 --> 01:38:11.360]   But you must have to fend those PR people off like crazy.
[01:38:11.360 --> 01:38:14.400]   We've got it pretty down to a science.
[01:38:14.400 --> 01:38:19.000]   I think we, because a lot of the PR people, it's either in, it's in two categories.
[01:38:19.000 --> 01:38:24.080]   It's all the smartphone agency experience type that I've worked with in the past.
[01:38:24.080 --> 01:38:27.920]   And they sort of have an experience workflow with YouTubers in general.
[01:38:27.920 --> 01:38:29.200]   They know what they're doing.
[01:38:29.200 --> 01:38:35.640]   Then there's people who've never worked with a creator before and are not confused, but
[01:38:35.640 --> 01:38:38.520]   they just don't know exactly what to expect.
[01:38:38.520 --> 01:38:39.760]   What's the process here?
[01:38:39.760 --> 01:38:43.360]   We've usually done it with, you know, like you said, newspapers and websites and journalists.
[01:38:43.360 --> 01:38:46.200]   How do we do this?
[01:38:46.200 --> 01:38:48.520]   So those are always a little more interesting to work with.
[01:38:48.520 --> 01:38:55.200]   But generally, you know, the LGs and apples and Samsungs of the world are actually, I
[01:38:55.200 --> 01:38:57.480]   think, on the right page right now.
[01:38:57.480 --> 01:39:02.480]   It was, okay, just a little thing that bugs me.
[01:39:02.480 --> 01:39:03.720]   So go for it.
[01:39:03.720 --> 01:39:04.720]   So I'm doing radio.
[01:39:04.720 --> 01:39:06.280]   I'm doing, I wasn't doing podcast.
[01:39:06.280 --> 01:39:07.280]   You have doing radio.
[01:39:07.280 --> 01:39:09.000]   And everybody, it was all print, right?
[01:39:09.000 --> 01:39:10.200]   They're all all over the print.
[01:39:10.200 --> 01:39:11.200]   I started doing podcasts.
[01:39:11.200 --> 01:39:12.200]   They're all over the print.
[01:39:12.200 --> 01:39:13.400]   Then they flipped to YouTube.
[01:39:13.400 --> 01:39:15.440]   They skipped right over radio and podcast.
[01:39:15.440 --> 01:39:17.520]   It was never at any point.
[01:39:17.520 --> 01:39:21.680]   They were saying, oh, we want to, we want you to cover our stuff.
[01:39:21.680 --> 01:39:23.200]   You know, in the long run, I'm happy.
[01:39:23.200 --> 01:39:24.840]   I don't want to talk to them anyway.
[01:39:24.840 --> 01:39:28.240]   But it was like, you guys took over from magazines.
[01:39:28.240 --> 01:39:29.720]   There was something in between.
[01:39:29.720 --> 01:39:31.240]   I'm just saying.
[01:39:31.240 --> 01:39:35.760]   Is the, they may just be following the audience more than the media.
[01:39:35.760 --> 01:39:36.760]   Oh, yeah.
[01:39:36.760 --> 01:39:37.760]   Thanks.
[01:39:37.760 --> 01:39:38.760]   There you go.
[01:39:38.760 --> 01:39:43.040]   So if you're trying to reach a certain demographic, no, but this is not just something we talked
[01:39:43.040 --> 01:39:44.040]   about a lot.
[01:39:44.040 --> 01:39:47.080]   I was just subtweeted by Marcus Brownley right there, right at that point.
[01:39:47.080 --> 01:39:48.840]   You're following the audience, Leo.
[01:39:48.840 --> 01:39:50.720]   Well, we talked about this a lot.
[01:39:50.720 --> 01:39:56.040]   I went to school for business and we had a lot of these conversations about like this
[01:39:56.040 --> 01:40:02.120]   unreachable demographic of like people who are cord cutting and don't necessarily, you
[01:40:02.120 --> 01:40:05.240]   know, they grow up and they don't listen to radio, but they also don't watch TV and
[01:40:05.240 --> 01:40:07.920]   they're just getting all their content on demand on YouTube.
[01:40:07.920 --> 01:40:14.920]   It ends up being like the only place an advertiser can go to reach this audience, which is kind
[01:40:14.920 --> 01:40:17.560]   of a bummer if that makes YouTube an monopoly in that way.
[01:40:17.560 --> 01:40:21.400]   But that's just what it is chasing now to get the customer.
[01:40:21.400 --> 01:40:22.400]   Yeah.
[01:40:22.400 --> 01:40:24.720]   No, they're media long enough to know that's exactly right.
[01:40:24.720 --> 01:40:25.720]   That's where they go.
[01:40:25.720 --> 01:40:28.920]   You go to where the audience is.
[01:40:28.920 --> 01:40:34.920]   Let's I want to take one more break and Amy, I promise the 13th annual Tech Trends report
[01:40:34.920 --> 01:40:37.040]   from the Today Institute.
[01:40:37.040 --> 01:40:39.640]   It's been sitting on my screen for the last hour.
[01:40:39.640 --> 01:40:43.360]   I really do want to go through these and give you a chance to address them.
[01:40:43.360 --> 01:40:46.400]   And Mark has just jumped right in with your thoughts on any of these.
[01:40:46.400 --> 01:40:52.440]   I don't want to leave you out at all because it's just great to have you both on and I'm
[01:40:52.440 --> 01:40:53.440]   quite enjoying it.
[01:40:53.440 --> 01:40:55.520]   Our show today brought to you.
[01:40:55.520 --> 01:40:57.640]   I want to say for some reason I want to say a D brand.
[01:40:57.640 --> 01:40:59.280]   No, it's not brought to you.
[01:40:59.280 --> 01:41:02.280]   Today it's brought to you by almost something almost as good.
[01:41:02.280 --> 01:41:04.760]   A great mattress, Casper.
[01:41:04.760 --> 01:41:10.280]   Casper is an online retailer premium mattresses for fraction of the cost.
[01:41:10.280 --> 01:41:13.600]   I just I fell in love with my first Casper.
[01:41:13.600 --> 01:41:15.800]   You never forget your first Casper.
[01:41:15.800 --> 01:41:18.320]   The original Casper mattress combined a multiple.
[01:41:18.320 --> 01:41:22.520]   It's still you can still get it, by the way, supportive memory foams for quality sleep
[01:41:22.520 --> 01:41:26.480]   service with the right amount of both sink and bounce.
[01:41:26.480 --> 01:41:27.480]   It's breathable.
[01:41:27.480 --> 01:41:30.280]   Let's you sleep cool, regulates your body temperatures throughout the night.
[01:41:30.280 --> 01:41:33.560]   It is beloved to 20,000 reviews.
[01:41:33.560 --> 01:41:37.640]   4.8 stars the average on Casper Amazon and Google.
[01:41:37.640 --> 01:41:39.560]   It's becoming the Internet's favorite mattress.
[01:41:39.560 --> 01:41:43.200]   They really this was one of the first direct to consumer brands where they said, you know,
[01:41:43.200 --> 01:41:46.840]   people are overpaying for mattresses because they're going to the mattress store.
[01:41:46.840 --> 01:41:51.440]   We could sell we could make these best mattresses in the world sell them for a lot less without
[01:41:51.440 --> 01:41:53.760]   that 100% markup from the mattress store.
[01:41:53.760 --> 01:41:57.600]   But they realized there's one little bitty problem there.
[01:41:57.600 --> 01:42:00.520]   People like to go to a mattress store and try a mattress before they buy it.
[01:42:00.520 --> 01:42:06.600]   Casper came up with the brilliant 100 night risk free sleep on a trial at any time in the
[01:42:06.600 --> 01:42:07.600]   first 100 nights.
[01:42:07.600 --> 01:42:08.600]   You're not happy.
[01:42:08.600 --> 01:42:11.240]   They'll come and get it refund you every penny.
[01:42:11.240 --> 01:42:12.240]   This is my brand new.
[01:42:12.240 --> 01:42:14.920]   I just got this Casper.
[01:42:14.920 --> 01:42:16.760]   This is the hybrid.
[01:42:16.760 --> 01:42:20.920]   This is a king size mattress comes in a box, but look at it.
[01:42:20.920 --> 01:42:25.480]   You take off the packaging and it goes, the other thing I love about Casper mattress is
[01:42:25.480 --> 01:42:26.480]   you don't have to air them out.
[01:42:26.480 --> 01:42:27.480]   They smell good.
[01:42:27.480 --> 01:42:28.480]   They are fresh.
[01:42:28.480 --> 01:42:34.040]   Boy, how comfortable that is that hybrid combines the pressure relief of the award winning
[01:42:34.040 --> 01:42:37.960]   foam, but also has durable yet gentle springs.
[01:42:37.960 --> 01:42:38.960]   There's the essential.
[01:42:38.960 --> 01:42:43.640]   If price is an issue, streamline design at a price that won't keep you up at night.
[01:42:43.640 --> 01:42:48.480]   That patent pending wave with a premium support system that mirrors the natural shape of
[01:42:48.480 --> 01:42:49.720]   your body.
[01:42:49.720 --> 01:42:53.600]   With that 100 night risk free sleep on a trial, you're never taking any chances.
[01:42:53.600 --> 01:42:56.800]   Free shipping, painless returns in the US and Canada.
[01:42:56.800 --> 01:42:57.960]   Get your Casper today.
[01:42:57.960 --> 01:43:00.000]   It's so nice.
[01:43:00.000 --> 01:43:01.960]   There's nothing better than a good night's sleep.
[01:43:01.960 --> 01:43:07.840]   Save $100 towards select mattresses by visiting casper.com/twit1.
[01:43:07.840 --> 01:43:13.080]   Our offer code Twit1, Twit in the number one will get you 100 bucks off select mattresses.
[01:43:13.080 --> 01:43:14.080]   We thank Casper.
[01:43:14.080 --> 01:43:15.360]   They've been supporting us for many years.
[01:43:15.360 --> 01:43:20.240]   We thank you for supporting us by going to that address, Casper.com/twit1 and the number
[01:43:20.240 --> 01:43:24.480]   one and the offer code Twit1 to check out terms and conditions of play.
[01:43:24.480 --> 01:43:28.200]   Did you see direct-to-consumer coming Amy Web?
[01:43:28.200 --> 01:43:29.560]   That's been an interesting change.
[01:43:29.560 --> 01:43:32.840]   I think podcasting has been a big part of the success of that.
[01:43:32.840 --> 01:43:39.840]   When we were tracking it, we were looking at a one-to-few model versus a one-to-many
[01:43:39.840 --> 01:43:41.840]   or many-to-many model.
[01:43:41.840 --> 01:43:46.840]   You were thinking of artisanal picklemakers versus...
[01:43:46.840 --> 01:43:48.840]   Picklemakers, yeah, sure.
[01:43:48.840 --> 01:43:51.840]   The new thing is custom.
[01:43:51.840 --> 01:43:55.640]   I bet you this is an area that's going to start to gain some traction because of what's
[01:43:55.640 --> 01:43:56.840]   happening now.
[01:43:56.840 --> 01:43:58.840]   But custom vitamin blends.
[01:43:58.840 --> 01:43:59.840]   Yes.
[01:43:59.840 --> 01:44:04.840]   We've been talking to people about that, yes.
[01:44:04.840 --> 01:44:06.840]   Custom neurotropics.
[01:44:06.840 --> 01:44:11.720]   I think there's going to be a lot more of that going forward for sure.
[01:44:11.720 --> 01:44:17.280]   The idea was Harry's was an early one where instead of these brands buying shelf space
[01:44:17.280 --> 01:44:21.840]   and stores and you buying it from a store after seeing TV ads, they would advertise
[01:44:21.840 --> 01:44:23.360]   on places like podcasting.
[01:44:23.360 --> 01:44:24.360]   We'll ship it direct to you.
[01:44:24.360 --> 01:44:26.760]   You buy your razor blades from us by subscription.
[01:44:26.760 --> 01:44:28.240]   There are a lot of them.
[01:44:28.240 --> 01:44:34.360]   That spawned the food box movement.
[01:44:34.360 --> 01:44:35.840]   Hello, fresh.
[01:44:35.840 --> 01:44:37.320]   There have been so many of those.
[01:44:37.320 --> 01:44:40.480]   We did Blue Apron for years.
[01:44:40.480 --> 01:44:44.800]   Most people don't have any idea how this actually works, but the way that groceries
[01:44:44.800 --> 01:44:52.720]   are placed in stores is this insane, crazy ass backwards process where the company that's
[01:44:52.720 --> 01:44:58.040]   leading in the category, if you're the number one serial brand, you have a lot of say over
[01:44:58.040 --> 01:45:00.280]   which serial gets placed where?
[01:45:00.280 --> 01:45:02.040]   You pay for it basically.
[01:45:02.040 --> 01:45:03.040]   It is.
[01:45:03.040 --> 01:45:04.040]   It is crazy.
[01:45:04.040 --> 01:45:06.680]   In fact, most of the revenue, I was talking to some of the most of the revenue in a grocery
[01:45:06.680 --> 01:45:08.400]   store doesn't come from the consumers.
[01:45:08.400 --> 01:45:10.400]   It comes from the brands.
[01:45:10.400 --> 01:45:11.400]   Yeah.
[01:45:11.400 --> 01:45:13.400]   So it's paid for placement.
[01:45:13.400 --> 01:45:14.400]   Yeah.
[01:45:14.400 --> 01:45:18.640]   Mark, is most of your revenue from YouTube ads that they sell or is it from ads that
[01:45:18.640 --> 01:45:22.000]   you sell or you do a little bit of both?
[01:45:22.000 --> 01:45:23.000]   I do both.
[01:45:23.000 --> 01:45:29.800]   I think the over 50% would still be ads that YouTube sells.
[01:45:29.800 --> 01:45:32.680]   But yeah, we can do our own ad placement.
[01:45:32.680 --> 01:45:36.200]   Like any rate we want on demand, we can choose not to have a placement for a video or we
[01:45:36.200 --> 01:45:37.720]   can in any video.
[01:45:37.720 --> 01:45:39.720]   So that is very important.
[01:45:39.720 --> 01:45:42.080]   Do you have a sales team or are you people selling for you?
[01:45:42.080 --> 01:45:43.080]   That would be me.
[01:45:43.080 --> 01:45:44.680]   You're the sales team?
[01:45:44.680 --> 01:45:45.680]   Me in the inbox.
[01:45:45.680 --> 01:45:46.880]   Yeah, that's the sales team.
[01:45:46.880 --> 01:45:49.480]   So it's very, very picky.
[01:45:49.480 --> 01:45:52.920]   And we don't have to, I mean, because we only do two a week.
[01:45:52.920 --> 01:45:56.880]   So if a video is sponsored, it's a whole ordeal.
[01:45:56.880 --> 01:46:01.320]   So yeah, the sales team just made.
[01:46:01.320 --> 01:46:03.320]   It's a whole ordeal.
[01:46:03.320 --> 01:46:04.800]   It's a lot.
[01:46:04.800 --> 01:46:06.680]   Trust me, I know.
[01:46:06.680 --> 01:46:10.840]   We don't, not only do we have a sales department, we have a continuity department because they
[01:46:10.840 --> 01:46:13.800]   have to check the ads, they have to make sure the copy's accurate, they have to make
[01:46:13.800 --> 01:46:16.000]   sure the right ad ran at the right time.
[01:46:16.000 --> 01:46:20.080]   It becomes a very elaborate process.
[01:46:20.080 --> 01:46:21.600]   But it's a little different for what we're doing.
[01:46:21.600 --> 01:46:23.360]   We're more like traditional broadcast.
[01:46:23.360 --> 01:46:27.640]   It's more like a radio show than a YouTube video.
[01:46:27.640 --> 01:46:31.920]   I'm just so, I'm always curious because I see, I don't, I pay for YouTube bread or premium
[01:46:31.920 --> 01:46:32.920]   now.
[01:46:32.920 --> 01:46:36.360]   So I don't see any of the ads.
[01:46:36.360 --> 01:46:42.560]   And then do you do interstitials in the video or, I mean, I see the ads in the below the video
[01:46:42.560 --> 01:46:44.560]   in the comments or whatever the.
[01:46:44.560 --> 01:46:48.440]   Oh, you're talking about the like the mid rolls that are that play.
[01:46:48.440 --> 01:46:53.200]   Yeah, you can do so you can choose to add mid rolls to videos that are greater than 10
[01:46:53.200 --> 01:46:54.240]   minutes long.
[01:46:54.240 --> 01:46:58.640]   So if we have a video that's long enough that we feel has a spot for a mid roll, we can add
[01:46:58.640 --> 01:47:01.680]   one, but not every video is over 10 minutes long.
[01:47:01.680 --> 01:47:02.680]   So not every video.
[01:47:02.680 --> 01:47:06.800]   And you don't do what we do the interstitial where you actually stop and do an ad and come
[01:47:06.800 --> 01:47:07.800]   back.
[01:47:07.800 --> 01:47:08.800]   Right.
[01:47:08.800 --> 01:47:10.040]   I have never done that.
[01:47:10.040 --> 01:47:12.000]   That's I've done post roll ads.
[01:47:12.000 --> 01:47:13.000]   Right.
[01:47:13.000 --> 01:47:17.720]   Like we finished the video that everyone came to watch and then we go right into the sponsor
[01:47:17.720 --> 01:47:18.920]   of the video.
[01:47:18.920 --> 01:47:23.080]   If we've done sort of more integrated stuff, it usually doesn't like stop and start the
[01:47:23.080 --> 01:47:24.480]   ad and then resume.
[01:47:24.480 --> 01:47:29.360]   It's not really as structured as that, but we have done.
[01:47:29.360 --> 01:47:33.960]   Do you think your audience would rebel if you started doing stuff like that?
[01:47:33.960 --> 01:47:35.160]   I don't know about rebel.
[01:47:35.160 --> 01:47:40.840]   I've sort of kept eyes on a lot of other channels and similar spaces that do start to do things
[01:47:40.840 --> 01:47:41.840]   like that.
[01:47:41.840 --> 01:47:45.600]   Do away the audience reacts and everyone does it differently too.
[01:47:45.600 --> 01:47:46.680]   Some do it really well.
[01:47:46.680 --> 01:47:48.960]   Some do it just like willy nilly.
[01:47:48.960 --> 01:47:52.560]   They'll do it for any, you know, whatever sponsor.
[01:47:52.560 --> 01:47:55.280]   We have a channel sponsor as well where it's like they.
[01:47:55.280 --> 01:47:56.760]   You got a D brand, right?
[01:47:56.760 --> 01:47:57.760]   Yeah, exactly.
[01:47:57.760 --> 01:47:59.120]   A C D brand is a channel sponsor.
[01:47:59.120 --> 01:48:03.760]   So they'll sponsor essentially a couple of videos during the year based on what makes
[01:48:03.760 --> 01:48:04.800]   sense for their brand.
[01:48:04.800 --> 01:48:09.400]   And so those are the closest we might get to like an interruption, but it's all seamless
[01:48:09.400 --> 01:48:10.560]   in the flow of the video.
[01:48:10.560 --> 01:48:13.600]   It usually doesn't feel like any reason to rebel.
[01:48:13.600 --> 01:48:14.600]   Right.
[01:48:14.600 --> 01:48:15.600]   Right.
[01:48:15.600 --> 01:48:17.080]   No, you're happy.
[01:48:17.080 --> 01:48:18.080]   Yeah.
[01:48:18.080 --> 01:48:19.080]   Yeah.
[01:48:19.080 --> 01:48:20.080]   Yeah.
[01:48:20.080 --> 01:48:21.080]   I could tell he's happy.
[01:48:21.080 --> 01:48:24.000]   He's got how many red cameras?
[01:48:24.000 --> 01:48:29.440]   More than we need.
[01:48:29.440 --> 01:48:30.440]   Send some over here.
[01:48:30.440 --> 01:48:31.440]   No, we don't.
[01:48:31.440 --> 01:48:32.440]   What would we do with them?
[01:48:32.440 --> 01:48:33.440]   We couldn't do it.
[01:48:33.440 --> 01:48:34.440]   We couldn't do it.
[01:48:34.440 --> 01:48:35.440]   We couldn't do it.
[01:48:35.440 --> 01:48:36.440]   We're in 720p.
[01:48:36.440 --> 01:48:37.440]   Yeah.
[01:48:37.440 --> 01:48:42.040]   I'll do a few shows in 8K that we then down sample.
[01:48:42.040 --> 01:48:45.160]   No, no, I'm not going to do it.
[01:48:45.160 --> 01:48:46.160]   Let's take a look.
[01:48:46.160 --> 01:48:52.240]   The you do this every year, 13 years running, Amy, the annual tech trends report.
[01:48:52.240 --> 01:48:54.160]   What's the by the way, people can get this.
[01:48:54.160 --> 01:48:57.360]   It's free online at the future today Institute.
[01:48:57.360 --> 01:48:59.680]   What's the purpose of this?
[01:48:59.680 --> 01:49:05.960]   So we track longitudinal trends for the purpose of trying to understand where there's going
[01:49:05.960 --> 01:49:10.760]   to be disruption in tech, where there's going to be disruption in every possible area that
[01:49:10.760 --> 01:49:11.760]   you could think of.
[01:49:11.760 --> 01:49:19.520]   The point of this is for us to do better research, for us to help our clients, et cetera.
[01:49:19.520 --> 01:49:20.920]   We're already doing the research.
[01:49:20.920 --> 01:49:25.280]   And 13 years ago, we started putting it into an annual report.
[01:49:25.280 --> 01:49:32.760]   So you make your businesses selling this information or consulting with people?
[01:49:32.760 --> 01:49:37.720]   So we're research and strategy groups.
[01:49:37.720 --> 01:49:40.280]   We give away our research for the most part.
[01:49:40.280 --> 01:49:45.920]   And our revenue comes from advising huge Fortune 100 companies and governments and stuff like
[01:49:45.920 --> 01:49:46.920]   that.
[01:49:46.920 --> 01:49:50.840]   So yeah, so we produce this report every year.
[01:49:50.840 --> 01:49:54.240]   Typically it launches on the main stage at South by Southwest.
[01:49:54.240 --> 01:49:59.840]   And as you know, this year it's not because there is no South by.
[01:49:59.840 --> 01:50:03.920]   It's available.
[01:50:03.920 --> 01:50:07.040]   There were some tremendously interesting findings this year that I think will be super interesting
[01:50:07.040 --> 01:50:12.920]   to everybody listening that ranges from, you know, arise in digital emissions.
[01:50:12.920 --> 01:50:15.600]   Like our homes are sort of shedding data.
[01:50:15.600 --> 01:50:17.440]   And that's, you know, interesting.
[01:50:17.440 --> 01:50:18.440]   It's good.
[01:50:18.440 --> 01:50:19.440]   It's bad.
[01:50:19.440 --> 01:50:22.480]   It's potentially problematic.
[01:50:22.480 --> 01:50:28.040]   There is a lot happening with a lot of the big technology firms getting into farming.
[01:50:28.040 --> 01:50:33.240]   So like big tech companies like Amazon and Microsoft are getting into food farming.
[01:50:33.240 --> 01:50:34.240]   Yeah.
[01:50:34.240 --> 01:50:35.240]   Yeah.
[01:50:35.240 --> 01:50:40.440]   Microsoft basically has fairly huge stakes now in two different farms.
[01:50:40.440 --> 01:50:41.440]   What?
[01:50:41.440 --> 01:50:42.440]   Yeah.
[01:50:42.440 --> 01:50:43.440]   What?
[01:50:43.440 --> 01:50:47.840]   So I remember Elon Musk's brother saying the next huge investment opportunity is food.
[01:50:47.840 --> 01:50:48.840]   Yeah.
[01:50:48.840 --> 01:50:51.120]   It's, well, and now we're seeing it.
[01:50:51.120 --> 01:50:52.720]   And people just aren't aware.
[01:50:52.720 --> 01:50:53.720]   So there's that.
[01:50:53.720 --> 01:50:57.520]   Is this, is bringing new technologies to food?
[01:50:57.520 --> 01:50:58.520]   Yeah.
[01:50:58.520 --> 01:51:06.280]   So it's, it's, you know, how can we use precision data mining and some robotics and 5G to try
[01:51:06.280 --> 01:51:09.040]   to get a better handle on.
[01:51:09.040 --> 01:51:15.120]   There's some crazy interesting experiments around mixing the food for cows in real time
[01:51:15.120 --> 01:51:21.120]   per each cow to help their overall nutrition level, you know, sort of get better and
[01:51:21.120 --> 01:51:22.720]   custom vitamins you were talking about.
[01:51:22.720 --> 01:51:23.720]   Yeah.
[01:51:23.720 --> 01:51:24.720]   Totally.
[01:51:24.720 --> 01:51:25.720]   It's not just for humans anymore.
[01:51:25.720 --> 01:51:28.280]   There you go.
[01:51:28.280 --> 01:51:29.280]   So there's that.
[01:51:29.280 --> 01:51:34.920]   We're tracking some really interesting movement in like AI in the cloud.
[01:51:34.920 --> 01:51:39.340]   Amazon's AWS Robo maker is probably going to go live sometime soon.
[01:51:39.340 --> 01:51:46.120]   And that's going to basically allow any business that wants to to have access to robots, you
[01:51:46.120 --> 01:51:51.040]   know, within reason, but that that will start to shift all kinds of things.
[01:51:51.040 --> 01:51:52.040]   It's super interesting.
[01:51:52.040 --> 01:51:56.520]   This is a huge year for off planet exploration.
[01:51:56.520 --> 01:52:02.120]   And even though today's SpaceX launch was thwarted, I don't think that necessarily means
[01:52:02.120 --> 01:52:05.040]   that, you know, we're in, we're in for a rough year.
[01:52:05.040 --> 01:52:08.880]   There's this is a huge year for off planet exploration.
[01:52:08.880 --> 01:52:14.560]   Yeah, because over the next 18 months, so we're always tracking space anyways, but over
[01:52:14.560 --> 01:52:18.920]   the next 18 months, there's a couple of launch windows to make it easier for us to get to
[01:52:18.920 --> 01:52:20.400]   Mars.
[01:52:20.400 --> 01:52:24.960]   So this is a huge important year for space related initiatives.
[01:52:24.960 --> 01:52:29.680]   Some of the initiatives involved humans, some of them are robots.
[01:52:29.680 --> 01:52:35.840]   There's some agriculture projects like space agriculture, you know, all kinds of microsatt
[01:52:35.840 --> 01:52:36.840]   launches.
[01:52:36.840 --> 01:52:40.400]   So Starlink was supposed to go up today and I'm excited about Starlink.
[01:52:40.400 --> 01:52:42.400]   I screw the amateur astronomers.
[01:52:42.400 --> 01:52:45.400]   That's going to be a problem.
[01:52:45.400 --> 01:52:46.400]   Yeah.
[01:52:46.400 --> 01:52:49.680]   Well, look, I'm not being facetious here.
[01:52:49.680 --> 01:52:50.680]   Yeah.
[01:52:50.680 --> 01:52:51.680]   Yeah, yeah.
[01:52:51.680 --> 01:52:56.680]   But the idea Elon has launched now what 120 and another 60 time.
[01:52:56.680 --> 01:52:58.160]   There's vaccines that are planned.
[01:52:58.160 --> 01:53:03.600]   They're planned 12,000 very low Earth orbit satellites.
[01:53:03.600 --> 01:53:08.760]   The idea is to give gigabit internet access to every corner of the globe.
[01:53:08.760 --> 01:53:11.680]   But they've been saying that this year they'll have it.
[01:53:11.680 --> 01:53:14.800]   They'll start going people start being able to use it.
[01:53:14.800 --> 01:53:19.760]   So again, it'll be interesting to see what happens because there are worldwide 5G.
[01:53:19.760 --> 01:53:22.600]   So 5G is obviously something else for tracking.
[01:53:22.600 --> 01:53:26.520]   There's some component, there's problems with 5G because of component accessibility.
[01:53:26.520 --> 01:53:28.720]   Yes, from Huawei.
[01:53:28.720 --> 01:53:29.720]   Right.
[01:53:29.720 --> 01:53:34.760]   And regulations that prohibit certain components from being used.
[01:53:34.760 --> 01:53:40.480]   The cable industry is in the process of launching its 10 gigabit network.
[01:53:40.480 --> 01:53:43.440]   So 10 gigabit speeds, very little lag.
[01:53:43.440 --> 01:53:45.280]   And we've got now space-based internet.
[01:53:45.280 --> 01:53:51.040]   So there's going to be a lot of development there over the next year to 18 months.
[01:53:51.040 --> 01:53:52.040]   We've moved.
[01:53:52.040 --> 01:53:56.480]   Our quantum and edge computing have been on our week signals list for a long time.
[01:53:56.480 --> 01:54:02.880]   And they finally jumped to the main trend list because of some developments that we've
[01:54:02.880 --> 01:54:03.880]   been seeing.
[01:54:03.880 --> 01:54:09.000]   And while I don't think quantum supremacy is knocking on our door next week, I do think
[01:54:09.000 --> 01:54:13.720]   that there's going to be some interesting commercial applications and research opportunities.
[01:54:13.720 --> 01:54:18.080]   So how many well of all people is selling a quantum computer?
[01:54:18.080 --> 01:54:19.080]   Yeah.
[01:54:19.080 --> 01:54:21.280]   Is that real?
[01:54:21.280 --> 01:54:23.280]   You know, it depends.
[01:54:23.280 --> 01:54:24.280]   Do you remember the D-Link?
[01:54:24.280 --> 01:54:28.920]   I mean, I guess it's still around the D-Link quantum system.
[01:54:28.920 --> 01:54:34.320]   I think it depends on your, I think it depends on how you find a quantum computer.
[01:54:34.320 --> 01:54:37.880]   So it's not really a quantum computer.
[01:54:37.880 --> 01:54:42.160]   It's kind of like AT&T's 5GE is not really 5G.
[01:54:42.160 --> 01:54:43.160]   Yeah.
[01:54:43.160 --> 01:54:44.160]   Here's what I would say.
[01:54:44.160 --> 01:54:49.280]   I think we are in a transition that's going to last a decade or so or more.
[01:54:49.280 --> 01:54:56.480]   And as we move through this transition, I don't think we will look back at this moment
[01:54:56.480 --> 01:55:03.080]   in time and say, oh, this 5G network was true 5G or oh, this quantum computer was really
[01:55:03.080 --> 01:55:05.840]   what we meant when we said quantum.
[01:55:05.840 --> 01:55:11.040]   I think there's a ton of technologies from artificial intelligence to synthetic biology
[01:55:11.040 --> 01:55:16.880]   and synthetic media, ambient computing, you know, these new network infrastructures that
[01:55:16.880 --> 01:55:22.080]   are all in the process of evolving and we're living through it right now.
[01:55:22.080 --> 01:55:25.160]   I'm still back at Microsoft's doing food.
[01:55:25.160 --> 01:55:32.880]   This is from Microsoft's Food Farmbeats page, AI, Edge and IoT for agriculture.
[01:55:32.880 --> 01:55:35.480]   But this is from 2015.
[01:55:35.480 --> 01:55:43.480]   So they're doing this more as a research project to be a product they could sell, right?
[01:55:43.480 --> 01:55:47.200]   They're not like buying farms because they want to be in the farm business.
[01:55:47.200 --> 01:55:53.720]   No, well, so I don't know that the answer to that is necessarily no.
[01:55:53.720 --> 01:56:00.520]   I can tell you that we're seeing a lot of research and a lot of investments in indoor
[01:56:00.520 --> 01:56:01.520]   plant factories.
[01:56:01.520 --> 01:56:03.840]   So think of a farm that's five.
[01:56:03.840 --> 01:56:06.960]   We saw some of those in CES, right, Marquez?
[01:56:06.960 --> 01:56:11.040]   There were, you could have like it in your house, you could have a plant factory.
[01:56:11.040 --> 01:56:12.040]   Yeah.
[01:56:12.040 --> 01:56:13.040]   So there's a lot?
[01:56:13.040 --> 01:56:15.520]   Yeah, yeah, well, that's right.
[01:56:15.520 --> 01:56:21.000]   But I mean, yeah, I think that the idea is it doesn't have to be a spread out farm.
[01:56:21.000 --> 01:56:23.880]   There's aquaponics, there's vertical farms.
[01:56:23.880 --> 01:56:28.800]   Aren't they growing stuff in salt mines, abandoned salt mines and things like that?
[01:56:28.800 --> 01:56:33.600]   And there's warehouses in London and Japan, you know, or just underneath office buildings
[01:56:33.600 --> 01:56:36.160]   where things are growing too.
[01:56:36.160 --> 01:56:41.120]   So again, I think this is all, it makes sense.
[01:56:41.120 --> 01:56:47.480]   You know, micro greens from Microsoft coming soon.
[01:56:47.480 --> 01:56:49.240]   Marquez, what excites you about it?
[01:56:49.240 --> 01:56:50.880]   Pick one of those technologies.
[01:56:50.880 --> 01:56:56.440]   Are you excited about Starlink or 5G or?
[01:56:56.440 --> 01:56:58.400]   Between those, I'm really interested in Starlink.
[01:56:58.400 --> 01:57:06.400]   I know it's got a long way to go, but generally fast internet is experiencing this.
[01:57:06.400 --> 01:57:08.920]   So in my position, exactly.
[01:57:08.920 --> 01:57:11.960]   And just generally like every corner of the globe having, you know, 5G is interesting
[01:57:11.960 --> 01:57:16.160]   just because it's super early and we're trying to see if we can build up the infrastructure
[01:57:16.160 --> 01:57:18.640]   in the smartest and fastest way possible.
[01:57:18.640 --> 01:57:20.560]   Without Chinese technology.
[01:57:20.560 --> 01:57:23.360]   Without being compromised.
[01:57:23.360 --> 01:57:25.080]   And you will get to this point.
[01:57:25.080 --> 01:57:26.280]   You're still young.
[01:57:26.280 --> 01:57:33.640]   But at some point you'll be wondering how can I do these shows somewhere besides Hoboken.
[01:57:33.640 --> 01:57:40.200]   And having Starlink to me, having the capability to do a mobile studio anywhere in the world
[01:57:40.200 --> 01:57:42.440]   is very intriguing.
[01:57:42.440 --> 01:57:46.640]   I wonder if that's going to, that, you know, for one thing, we're going to put the second
[01:57:46.640 --> 01:57:48.560]   half of the world's population online.
[01:57:48.560 --> 01:57:50.880]   So that by itself is huge.
[01:57:50.880 --> 01:57:58.000]   But the idea that they can all not just consume but create, that's very intriguing to me.
[01:57:58.000 --> 01:58:04.160]   Well, anybody can be anywhere and gain access to it in a way that feels more visceral than
[01:58:04.160 --> 01:58:06.240]   it ever has before, which is really exciting.
[01:58:06.240 --> 01:58:12.960]   Well, you pointed out with people now going home in schools closing, the haves and have
[01:58:12.960 --> 01:58:17.000]   nots, the internet haves and have nots are suddenly becoming very highlighted.
[01:58:17.000 --> 01:58:21.320]   And that you can't just say to a kid, go home, you can do those classes online.
[01:58:21.320 --> 01:58:22.520]   They don't have the technology.
[01:58:22.520 --> 01:58:25.560]   They may not have the internet.
[01:58:25.560 --> 01:58:28.880]   And what we're seeing now is this great gulf.
[01:58:28.880 --> 01:58:31.880]   Some of its economics, some of it's just geographic.
[01:58:31.880 --> 01:58:36.800]   There are millions of people living in rural areas that just can't get better internet.
[01:58:36.800 --> 01:58:37.800]   Yeah.
[01:58:37.800 --> 01:58:41.880]   And unfortunately, this is a highly politicized issue in the United States.
[01:58:41.880 --> 01:58:43.240]   It's not so much in other places.
[01:58:43.240 --> 01:58:47.480]   But there's a lot of back and forth around who should provide and build out the broadband
[01:58:47.480 --> 01:58:50.600]   networks and how much they should cost.
[01:58:50.600 --> 01:58:55.120]   And unfortunately, this is a bad time for us not to have come to some kind of decision.
[01:58:55.120 --> 01:58:56.120]   Yep.
[01:58:56.120 --> 01:58:57.120]   Whoops.
[01:58:57.120 --> 01:58:58.880]   Gee, if we'd only thought ahead.
[01:58:58.880 --> 01:58:59.880]   Yeah.
[01:58:59.880 --> 01:59:01.240]   Let's take a little break.
[01:59:01.240 --> 01:59:04.160]   And then we're going to wrap it up because I've been keeping you guys long enough.
[01:59:04.160 --> 01:59:07.880]   But boy, this is, I would go for hours if you would let me.
[01:59:07.880 --> 01:59:12.760]   I think honestly, one of the things we might do, John, I've been starting to do the show
[01:59:12.760 --> 01:59:15.640]   from my office, which is hermetically sealed.
[01:59:15.640 --> 01:59:18.320]   And I lock the door and no one can get in there.
[01:59:18.320 --> 01:59:22.920]   So I don't, you know, it's completely virus free unless I bring it in, but in that case,
[01:59:22.920 --> 01:59:24.240]   who cares?
[01:59:24.240 --> 01:59:29.000]   But I'm thinking, maybe we, this is the time to go live 24/7.
[01:59:29.000 --> 01:59:30.000]   You can watch me sleep.
[01:59:30.000 --> 01:59:33.720]   Apparently that's huge on TikTok.
[01:59:33.720 --> 01:59:35.960]   You can, I'll get up, brush my teeth.
[01:59:35.960 --> 01:59:36.960]   We could talk.
[01:59:36.960 --> 01:59:40.120]   It'll be like, we'll be keeping each other company.
[01:59:40.120 --> 01:59:42.720]   No, we'll do it out of my office.
[01:59:42.720 --> 01:59:45.280]   Yeah, here we got the bandwidth.
[01:59:45.280 --> 01:59:47.760]   Why waste it?
[01:59:47.760 --> 01:59:49.160]   Maybe not.
[01:59:49.160 --> 01:59:50.840]   Our show today brought to you by Zapier.
[01:59:50.840 --> 01:59:51.840]   Whoo.
[01:59:51.840 --> 01:59:52.840]   I mean, really brought to you by Zapier.
[01:59:52.840 --> 01:59:55.360]   We use Zapier like crazy.
[01:59:55.360 --> 01:59:58.120]   I have Zapier scripts to do all sorts of stuff.
[01:59:58.120 --> 02:00:04.640]   For instance, when I bookmark a story in my news reader, it automatically Zapier goes,
[02:00:04.640 --> 02:00:05.640]   yes, I'll take that.
[02:00:05.640 --> 02:00:08.080]   It sends it because they have multi-level zaps.
[02:00:08.080 --> 02:00:09.080]   It's so cool.
[02:00:09.080 --> 02:00:11.040]   It sends it immediately to pinboard.
[02:00:11.040 --> 02:00:12.440]   It sends it immediately to Twitter.
[02:00:12.440 --> 02:00:14.800]   I have special links for Twitter feed.
[02:00:14.800 --> 02:00:16.080]   It sends it immediately to my blog.
[02:00:16.080 --> 02:00:22.240]   It sends it immediately to a spreadsheet on Google Sheets, which Carson can use to make
[02:00:22.240 --> 02:00:24.160]   our show rundowns.
[02:00:24.160 --> 02:00:26.320]   It does all of this completely automatically.
[02:00:26.320 --> 02:00:31.080]   In fact, I get emails every month from Zapier saying, "We just saved you 40 hours."
[02:00:31.080 --> 02:00:32.080]   I love that.
[02:00:32.080 --> 02:00:34.280]   4.5 million people use Zapier.
[02:00:34.280 --> 02:00:38.720]   On average 40 hours a month they save with these automated technologies.
[02:00:38.720 --> 02:00:40.560]   It's the easiest way to automate your work.
[02:00:40.560 --> 02:00:44.560]   Zapier has over 2,000 apps now that it works with.
[02:00:44.560 --> 02:00:50.280]   What you do is you connect up, let's say you're in sales, you connect up your CRM program,
[02:00:50.280 --> 02:00:56.960]   your contacts, your Google Docs, you can engage leads instantly, you can automatically import
[02:00:56.960 --> 02:00:57.960]   new customers.
[02:00:57.960 --> 02:01:03.240]   You can notify your team about opportunities, connect up Slack, Teams, whatever you use.
[02:01:03.240 --> 02:01:04.920]   It's also more customizable.
[02:01:04.920 --> 02:01:09.680]   They support multi-step zaps so the possibilities are virtually endless.
[02:01:09.680 --> 02:01:13.200]   Now they've added paths, makes it even more powerful.
[02:01:13.200 --> 02:01:16.800]   You can do all this without being a coder, without being an engineer, without going to
[02:01:16.800 --> 02:01:18.040]   the devs.
[02:01:18.040 --> 02:01:20.720]   You can do it yourself.
[02:01:20.720 --> 02:01:24.320]   Zapier paths let you set rules creating new routes.
[02:01:24.320 --> 02:01:26.520]   If A happens in your first app, then do this.
[02:01:26.520 --> 02:01:29.360]   If B happens, then do something else.
[02:01:29.360 --> 02:01:30.520]   The power is endless.
[02:01:30.520 --> 02:01:37.560]   I have to say, for IoT, for business, everything I do, I'm always coming up in new ways to
[02:01:37.560 --> 02:01:39.040]   use Zapier.
[02:01:39.040 --> 02:01:45.320]   Social media too, Instagram, Facebook, TikTok, it's all in there, YouTube.
[02:01:45.320 --> 02:01:47.720]   I really think you ought to check it out.
[02:01:47.720 --> 02:01:50.920]   Make more time to grow your business, to do the things you want.
[02:01:50.920 --> 02:01:53.840]   Let the computer do the work.
[02:01:53.840 --> 02:01:56.200]   Zapier.com/twit.
[02:01:56.200 --> 02:02:00.160]   Connect the apps you use the most and let Zapier take it from there.
[02:02:00.160 --> 02:02:03.960]   Right now, through the end of the month, you can try Zapier free.
[02:02:03.960 --> 02:02:10.360]   For two weeks, zapir.com/twit, you'll come up with all sorts of really cool things.
[02:02:10.360 --> 02:02:12.120]   Look at all the apps.
[02:02:12.120 --> 02:02:15.840]   Zapier, zapir.com/twit.
[02:02:15.840 --> 02:02:18.480]   You're free 14-day trial awaits.
[02:02:18.480 --> 02:02:23.280]   Thank you, Zapier, for your support this week in tech.
[02:02:23.280 --> 02:02:28.360]   Thank you for supporting us by going to zapir.com/twit.
[02:02:28.360 --> 02:02:31.480]   Marquez Brownlee, Amy Webb.
[02:02:31.480 --> 02:02:33.000]   Here's one of the things you came up with.
[02:02:33.000 --> 02:02:34.520]   This is more dystopian.
[02:02:34.520 --> 02:02:39.440]   Everyone alive today is being scored.
[02:02:39.440 --> 02:02:40.680]   We're not just talking about China.
[02:02:40.680 --> 02:02:42.920]   This is data mining.
[02:02:42.920 --> 02:02:43.920]   Right.
[02:02:43.920 --> 02:02:50.080]   I think probably a lot of the listeners to this show are aware of the data that are
[02:02:50.080 --> 02:02:53.560]   being mined and refined.
[02:02:53.560 --> 02:02:56.760]   This is one of the tricky things about the future of technology.
[02:02:56.760 --> 02:03:00.160]   The data on their own aren't really worth anything.
[02:03:00.160 --> 02:03:02.960]   It's what we do with those data.
[02:03:02.960 --> 02:03:09.880]   A lot of our automated systems and all of the cool AI that excites us requires quantification
[02:03:09.880 --> 02:03:11.520]   in some way.
[02:03:11.520 --> 02:03:16.080]   The issue is a lot of our systems don't work without scoring us.
[02:03:16.080 --> 02:03:22.480]   However, we are constantly being scored and there is very little transparency.
[02:03:22.480 --> 02:03:27.080]   That will start leading us down different pathways.
[02:03:27.080 --> 02:03:34.520]   When people will start getting charged things differently for things, they may get denied.
[02:03:34.520 --> 02:03:39.440]   The ability to use things probably also means we're looking at regulation in the future.
[02:03:39.440 --> 02:03:45.200]   But it's a good reminder that tech on its own isn't good or bad necessarily, but we have
[02:03:45.200 --> 02:03:49.520]   to start really thinking through how we're using it all.
[02:03:49.520 --> 02:03:53.200]   Here's one Marquez is going to enjoy synthetic media.
[02:03:53.200 --> 02:03:57.120]   We've got a really, really good section this year.
[02:03:57.120 --> 02:03:58.640]   I'm super excited about it.
[02:03:58.640 --> 02:04:00.400]   On the future of synthetic media.
[02:04:00.400 --> 02:04:01.840]   What is synthetic media?
[02:04:01.840 --> 02:04:02.840]   What is that?
[02:04:02.840 --> 02:04:09.320]   Actually, we're actually calling 2020 the synthetic decade because there's a lot of emerging trends
[02:04:09.320 --> 02:04:14.520]   in synthetic media content, but also synthetic biology and synthetic data sets and synthetic
[02:04:14.520 --> 02:04:15.520]   food and beverage.
[02:04:15.520 --> 02:04:21.320]   When we're talking about content and media, that is content that's been generated using
[02:04:21.320 --> 02:04:31.040]   corpus of data, whether that's vocal recordings or your faces or whatever it might be.
[02:04:31.040 --> 02:04:35.960]   Maybe the easiest way to understand this is a deep fake.
[02:04:35.960 --> 02:04:43.920]   A deep fake would be the negative bad side as we've seen it so far of synthetic media.
[02:04:43.920 --> 02:04:51.000]   The real future that I'm excited about is all kinds of synthetic character development.
[02:04:51.000 --> 02:04:54.400]   There's plenty of problems, which I think everybody's heard a lot about.
[02:04:54.400 --> 02:05:02.360]   All the cool stuff is modulating voices, modulating faces, having all the YouTube content that
[02:05:02.360 --> 02:05:06.240]   you're interested in, but generated for you more specifically.
[02:05:06.240 --> 02:05:12.800]   How long before Marquez before you just can retire and let an artificial Marquez do the
[02:05:12.800 --> 02:05:13.800]   show?
[02:05:13.800 --> 02:05:14.800]   Before he's a synth?
[02:05:14.800 --> 02:05:15.800]   How's that about?
[02:05:15.800 --> 02:05:16.800]   I mean, for being honest.
[02:05:16.800 --> 02:05:22.320]   There's a YouTube channel called Ryan's Toy Reviews, which is this little kid who's,
[02:05:22.320 --> 02:05:25.880]   I'm sure you've heard of him, but he's very young.
[02:05:25.880 --> 02:05:30.680]   It's borderline strange that he's a YouTuber, but his parents have enabled him to have this
[02:05:30.680 --> 02:05:35.280]   whole empire where he takes toys out of the box and then he's millions, millions, eight
[02:05:35.280 --> 02:05:37.480]   million dollars last year.
[02:05:37.480 --> 02:05:42.720]   Yeah, an incredible success story, but the parents are very careful to not force this
[02:05:42.720 --> 02:05:46.840]   job on this kid and make him have to participate and make the video.
[02:05:46.840 --> 02:05:51.680]   So they've hired a team to make an animated version of him and a story time channel on
[02:05:51.680 --> 02:05:55.680]   these other things to make sure he doesn't constantly feel pressured to work.
[02:05:55.680 --> 02:06:02.480]   I'm curious if synthetic videos are not so far away where I don't have to make videos
[02:06:02.480 --> 02:06:03.480]   either.
[02:06:03.480 --> 02:06:09.200]   I just sit down, have an idea, type it in, and it becomes a video.
[02:06:09.200 --> 02:06:12.560]   You said a decade away, but that sounds incredible.
[02:06:12.560 --> 02:06:20.240]   I mean, so it depends on what your requirements are for fidelity, but there's already systems
[02:06:20.240 --> 02:06:21.560]   in place.
[02:06:21.560 --> 02:06:26.440]   You guys are in the recording business, so you've probably recorded a show or a podcast
[02:06:26.440 --> 02:06:29.920]   and you wish that you're guest or somebody had said something a little differently.
[02:06:29.920 --> 02:06:32.920]   You can't really go back and edit them cleanly.
[02:06:32.920 --> 02:06:39.680]   The idea here is using a Generate adversarial network and some other technologies and tools
[02:06:39.680 --> 02:06:45.120]   to sort of go back and reprogram what that person said.
[02:06:45.120 --> 02:06:47.120]   I'll give you a better example.
[02:06:47.120 --> 02:06:55.320]   So at South By this year, I was going to show everybody this brand new project from Reuters,
[02:06:55.320 --> 02:07:00.440]   which is an algorithmic, synthesized journalist.
[02:07:00.440 --> 02:07:06.800]   So it's like a guy who can use the structured data from Premier League football games and
[02:07:06.800 --> 02:07:11.920]   then give a sports report, which I find super boring on so many levels.
[02:07:11.920 --> 02:07:16.600]   But the reason they do it with sports is such a structured content.
[02:07:16.600 --> 02:07:20.560]   They've had artificial sports text writers for a long time.
[02:07:20.560 --> 02:07:21.560]   Right.
[02:07:21.560 --> 02:07:27.320]   So this is like a video version of a person in a convincing way who looks like a news anchor
[02:07:27.320 --> 02:07:30.480]   talking about that, which they've been doing in China for a little while.
[02:07:30.480 --> 02:07:31.480]   So it's not...
[02:07:31.480 --> 02:07:33.440]   They're using the synesthesia technology.
[02:07:33.440 --> 02:07:34.440]   Yeah.
[02:07:34.440 --> 02:07:39.920]   Now, I went over, by the way, to the synesthesia booth at CVS.
[02:07:39.920 --> 02:07:43.400]   And I asked the salient question, is there a human that looks like this?
[02:07:43.400 --> 02:07:45.840]   And they said, "Oh, yeah, this is just a captured human."
[02:07:45.840 --> 02:07:46.840]   Right.
[02:07:46.840 --> 02:07:47.840]   But it doesn't have...
[02:07:47.840 --> 02:07:49.000]   So that's just what they're doing.
[02:07:49.000 --> 02:07:50.840]   My point is it doesn't have to be.
[02:07:50.840 --> 02:07:52.040]   So it could be totally generated.
[02:07:52.040 --> 02:07:53.040]   It's what is synthetic.
[02:07:53.040 --> 02:07:54.040]   Wow.
[02:07:54.040 --> 02:07:55.320]   But now here's where it's interesting.
[02:07:55.320 --> 02:07:59.060]   So like, what could you do to make me care about soccer, which I care basically nothing
[02:07:59.060 --> 02:08:00.060]   at all about?
[02:08:00.060 --> 02:08:01.060]   Well, if that...
[02:08:01.060 --> 02:08:03.720]   This is going to make you care less about soccer.
[02:08:03.720 --> 02:08:04.720]   This is going to...
[02:08:04.720 --> 02:08:06.400]   I would suddenly care a lot more.
[02:08:06.400 --> 02:08:09.000]   So let's say that he looked like Chris Evans.
[02:08:09.000 --> 02:08:12.280]   Or let's say that Chris Evans...
[02:08:12.280 --> 02:08:18.820]   And let's say that Chris Evans was speaking with a slightly lower voice and talking directly
[02:08:18.820 --> 02:08:24.080]   to me about whatever blah, blah, blah sports.
[02:08:24.080 --> 02:08:26.680]   I would totally pay attention to that, right?
[02:08:26.680 --> 02:08:30.000]   And now if we take that out to the next level, what if that exact...
[02:08:30.000 --> 02:08:31.000]   And this is what I was going...
[02:08:31.000 --> 02:08:35.480]   I actually built this and was going to show this at Southby.
[02:08:35.480 --> 02:08:40.480]   What happens if synthetic Chris Evans talking to me about soccer wasn't actually talking
[02:08:40.480 --> 02:08:47.240]   to me about soccer, but rather about how to socially isolate and wash my hands and be
[02:08:47.240 --> 02:08:49.800]   a better citizen in the era of the virus?
[02:08:49.800 --> 02:08:50.800]   And better yes.
[02:08:50.800 --> 02:08:52.640]   He would know your name.
[02:08:52.640 --> 02:08:54.320]   He would call you Amy.
[02:08:54.320 --> 02:08:55.320]   He would know...
[02:08:55.320 --> 02:08:56.320]   He would...
[02:08:56.320 --> 02:08:57.320]   And I would listen.
[02:08:57.320 --> 02:08:58.320]   You would.
[02:08:58.320 --> 02:09:00.760]   You might even fall in love with synthetic Chris Evans.
[02:09:00.760 --> 02:09:01.760]   I might.
[02:09:01.760 --> 02:09:07.320]   Like walking Phoenix fell in love with Scarlett Johansson and her, right?
[02:09:07.320 --> 02:09:13.080]   Well, that was disembodied, but this is not far off and it doesn't have to be dystopian.
[02:09:13.080 --> 02:09:14.880]   I mean, that's kind of the interesting thing.
[02:09:14.880 --> 02:09:20.160]   I believe we still have some agency in deciding what comes next, but it's on us to track what's
[02:09:20.160 --> 02:09:25.360]   happening so that we make those incremental decisions as we go rather than getting to
[02:09:25.360 --> 02:09:29.480]   the future and deciding, "Holy hell, I wish it didn't look like this.
[02:09:29.480 --> 02:09:31.360]   I wish we could go back now the other direction."
[02:09:31.360 --> 02:09:32.800]   Well, good news.
[02:09:32.800 --> 02:09:35.040]   Westworld's on in about an hour and...
[02:09:35.040 --> 02:09:36.040]   Cannot wait.
[02:09:36.040 --> 02:09:40.440]   Synthetic Chris Evans awaits.
[02:09:40.440 --> 02:09:45.320]   The truth is, and it's not widely known, but they've been doing this in motion pictures
[02:09:45.320 --> 02:09:47.360]   for a long time.
[02:09:47.360 --> 02:09:48.360]   Yeah.
[02:09:48.360 --> 02:09:52.400]   Very frequently, the stars you see on screen are digitally altered.
[02:09:52.400 --> 02:09:57.080]   Maybe their voice is a little lower or maybe their skin's a little clearer or they have
[02:09:57.080 --> 02:09:58.920]   a little less fat on their bodies.
[02:09:58.920 --> 02:10:00.560]   It's commonly done now.
[02:10:00.560 --> 02:10:03.360]   In fact, it's often written in the movie contracts.
[02:10:03.360 --> 02:10:04.360]   Yeah.
[02:10:04.360 --> 02:10:09.760]   And again, like, and before that it was Photoshop in magazine covers and before that it was some
[02:10:09.760 --> 02:10:14.320]   super talented artist with an eraser and a pencil and some paint.
[02:10:14.320 --> 02:10:18.920]   We've always been trying to alter reality in a way that reflects our values, our hopes,
[02:10:18.920 --> 02:10:21.440]   our dreams and whatever they may be better.
[02:10:21.440 --> 02:10:25.640]   We're just getting closer to doing that in an automated way and fairly soon in a way that
[02:10:25.640 --> 02:10:29.920]   is where some of the cognitive functions are being done for us.
[02:10:29.920 --> 02:10:34.000]   Well, I mean, the trick was always, it's easy to do it in a movie because it's post-production
[02:10:34.000 --> 02:10:37.720]   and so you have all the time in the world to work on it.
[02:10:37.720 --> 02:10:40.320]   The trick is to do it in real time.
[02:10:40.320 --> 02:10:41.920]   Excuse me, real time.
[02:10:41.920 --> 02:10:48.960]   Carsten and I go way back because he used to make my hair spin when I was a virtual character
[02:10:48.960 --> 02:10:55.480]   on MSNBC and that was almost 20 years ago now.
[02:10:55.480 --> 02:10:59.200]   And that was in real time and that was what was unique about that because reboot had already
[02:10:59.200 --> 02:11:03.360]   been on which was a CGI cartoon.
[02:11:03.360 --> 02:11:08.160]   But it took weeks and days and weeks and months to make those whereas I would sit across from
[02:11:08.160 --> 02:11:11.760]   so that a Brian and talk to her as a virtual character.
[02:11:11.760 --> 02:11:15.640]   But here's, so one of the things that we've done in this year's, well, we always do this
[02:11:15.640 --> 02:11:19.000]   in our trend reports is we get real granular.
[02:11:19.000 --> 02:11:23.560]   So it's not enough to talk about deep fakes and sort of ambiguity.
[02:11:23.560 --> 02:11:29.480]   There's a lot of, like we explain what the different elements are because not every part
[02:11:29.480 --> 02:11:33.200]   of the synthetic media ecosystem is moving at the same rate.
[02:11:33.200 --> 02:11:36.680]   And there's a ton of trends in there and a ton of things to think about.
[02:11:36.680 --> 02:11:41.000]   And it's super interesting to think about the future of synthetic media alongside other
[02:11:41.000 --> 02:11:46.400]   trends like artificial intelligence and home automation and censorship, which unfortunately
[02:11:46.400 --> 02:11:52.000]   is a new topic this year, you know, in all kinds of other areas too.
[02:11:52.000 --> 02:11:56.440]   Synthetic Marques Brownlee, but he's perfect.
[02:11:56.440 --> 02:11:58.240]   Don't change a thing.
[02:11:58.240 --> 02:12:04.600]   You know that isn't Microsoft teams that has that eye leveler feature.
[02:12:04.600 --> 02:12:06.000]   Is that in the face time?
[02:12:06.000 --> 02:12:07.560]   It was a face time.
[02:12:07.560 --> 02:12:08.760]   It was very weird.
[02:12:08.760 --> 02:12:09.760]   Oh, I saw a demo.
[02:12:09.760 --> 02:12:10.760]   Yeah.
[02:12:10.760 --> 02:12:11.760]   Yeah.
[02:12:11.760 --> 02:12:12.760]   Microsoft didn't like to care.
[02:12:12.760 --> 02:12:14.600]   So you're looking because as with often as the case, you're looking down at the camera,
[02:12:14.600 --> 02:12:18.120]   but they made the eyes go up and yeah, Apple didn't it was in.
[02:12:18.120 --> 02:12:19.880]   Man, I am wrong, but I remember it was in Apple.
[02:12:19.880 --> 02:12:22.640]   It was in FaceTime and then they didn't do it.
[02:12:22.640 --> 02:12:23.640]   We tried it on iOS today.
[02:12:23.640 --> 02:12:25.320]   It was in FaceTime, yeah.
[02:12:25.320 --> 02:12:29.800]   But they didn't have talked about it since maybe because it has a kind of uncanny valley.
[02:12:29.800 --> 02:12:30.800]   Yeah.
[02:12:30.800 --> 02:12:31.800]   Wow.
[02:12:31.800 --> 02:12:32.800]   You're interesting.
[02:12:32.800 --> 02:12:33.800]   Are you looking at me?
[02:12:33.800 --> 02:12:35.240]   What's going on?
[02:12:35.240 --> 02:12:36.600]   What's going on?
[02:12:36.600 --> 02:12:39.520]   Marques, it's always a thrill to talk to you.
[02:12:39.520 --> 02:12:44.440]   I'm so happy for your success and I just watched those videos religiously.
[02:12:44.440 --> 02:12:46.280]   You're really doing a great job.
[02:12:46.280 --> 02:12:47.280]   You like the 20?
[02:12:47.280 --> 02:12:48.680]   You asked 20?
[02:12:48.680 --> 02:12:50.520]   I like the S20.
[02:12:50.520 --> 02:12:51.840]   I have the S20 Ultra.
[02:12:51.840 --> 02:12:54.520]   If you can stand a gigantic phone.
[02:12:54.520 --> 02:12:56.920]   It's tall too.
[02:12:56.920 --> 02:12:58.600]   I didn't realize how tall it was.
[02:12:58.600 --> 02:13:01.040]   Can you hold it up again?
[02:13:01.040 --> 02:13:02.720]   There's a camera bump.
[02:13:02.720 --> 02:13:04.720]   The size of a camel hump.
[02:13:04.720 --> 02:13:06.720]   6.9 inch screen.
[02:13:06.720 --> 02:13:10.160]   That used to be tablet sized back in the day.
[02:13:10.160 --> 02:13:12.080]   Now it's your phone.
[02:13:12.080 --> 02:13:14.640]   A lot of people complaining about the camera though.
[02:13:14.640 --> 02:13:17.920]   The camera, some people say it's not even as good as the S20.
[02:13:17.920 --> 02:13:21.400]   I went in depth with it in my review.
[02:13:21.400 --> 02:13:24.840]   There's a difference between the camera and the camera experience.
[02:13:24.840 --> 02:13:26.560]   The camera is very good.
[02:13:26.560 --> 02:13:30.960]   The camera experience, which almost matters more, is not very good.
[02:13:30.960 --> 02:13:32.520]   But software updates may help.
[02:13:32.520 --> 02:13:34.080]   Yeah, that they could fix.
[02:13:34.080 --> 02:13:35.640]   There's some over softening.
[02:13:35.640 --> 02:13:39.920]   Samsung's always been very aggressive in its post-processing.
[02:13:39.920 --> 02:13:41.440]   Not so happy about that.
[02:13:41.440 --> 02:13:43.680]   Well, Marques, good luck to you.
[02:13:43.680 --> 02:13:44.680]   Keep up the good work.
[02:13:44.680 --> 02:13:47.520]   Anytime you want to come on the show, you're more than welcome.
[02:13:47.520 --> 02:13:48.520]   I love having you on.
[02:13:48.520 --> 02:13:49.520]   I hope I'll see you soon.
[02:13:49.520 --> 02:13:50.520]   Thank you for having me.
[02:13:50.520 --> 02:13:51.520]   I appreciate it.
[02:13:51.520 --> 02:13:52.520]   KBHD.
[02:13:52.520 --> 02:13:56.680]   The poor guys only got 10 and 1/2 million followers.
[02:13:56.680 --> 02:13:59.000]   Can we just try to boost this up a little bit?
[02:13:59.000 --> 02:14:00.560]   Let's just everybody go.
[02:14:00.560 --> 02:14:02.000]   What does those YouTubers say?
[02:14:02.000 --> 02:14:04.480]   Hit the Bang the Red bell.
[02:14:04.480 --> 02:14:05.480]   What is it?
[02:14:05.480 --> 02:14:10.480]   Smash that big red subscribe button and hit that bell.
[02:14:10.480 --> 02:14:13.280]   I think Bang Red Bell is the name of the episode.
[02:14:13.280 --> 02:14:16.280]   I'm so un-hyped.
[02:14:16.280 --> 02:14:20.080]   Everybody, Bang the Red Bell.
[02:14:20.080 --> 02:14:21.440]   Thank you, Marques.
[02:14:21.440 --> 02:14:22.440]   Great to talk to you.
[02:14:22.440 --> 02:14:27.640]   Amy Webb, everybody should go to the Institute for the Future.com and download this.
[02:14:27.640 --> 02:14:28.800]   No, don't go the...
[02:14:28.800 --> 02:14:29.800]   That's a different company.
[02:14:29.800 --> 02:14:30.800]   Don't go to them.
[02:14:30.800 --> 02:14:34.000]   Sorry, the Future Today Institute.com.
[02:14:34.000 --> 02:14:35.000]   Doi.
[02:14:35.000 --> 02:14:37.000]   I'm an idiot.
[02:14:37.000 --> 02:14:38.500]   No, no.
[02:14:38.500 --> 02:14:40.360]   How come you guys have such similar names?
[02:14:40.360 --> 02:14:42.160]   FutureTodayInstitute.com.
[02:14:42.160 --> 02:14:43.960]   You can get the PDF version.
[02:14:43.960 --> 02:14:46.680]   You can get the short version and the long version.
[02:14:46.680 --> 02:14:47.680]   I am excited.
[02:14:47.680 --> 02:14:49.200]   You can also get the book and I've got the...
[02:14:49.200 --> 02:14:50.200]   She's sending me the book.
[02:14:50.200 --> 02:14:55.000]   I'm very excited about that because this is fun to have on your bookshelf.
[02:14:55.000 --> 02:14:58.560]   Just because in a couple of years, Amy, I'm going to look back and say, "Why's she got
[02:14:58.560 --> 02:14:59.560]   that right?"
[02:14:59.560 --> 02:15:01.120]   She got that right.
[02:15:01.120 --> 02:15:02.120]   It's all available.
[02:15:02.120 --> 02:15:05.440]   A lot of times I wish I didn't get things right, unfortunately.
[02:15:05.440 --> 02:15:06.920]   There you go.
[02:15:06.920 --> 02:15:12.400]   What's the one thing that you think will happen that you wish wouldn't?
[02:15:12.400 --> 02:15:15.640]   This is policy uncertainty.
[02:15:15.640 --> 02:15:18.840]   I know that doesn't sound like a tech trying to kind of is, but I think we're going to
[02:15:18.840 --> 02:15:27.760]   not have any collaboration, which is weird because if you ask any futurist or sci-fi nerd,
[02:15:27.760 --> 02:15:31.520]   what's the one thing everybody wishes for when things are bad and it's always an alien
[02:15:31.520 --> 02:15:32.520]   invasion?
[02:15:32.520 --> 02:15:35.720]   That's the one thing that brings everybody together.
[02:15:35.720 --> 02:15:39.760]   We totally have an alien invasion right now.
[02:15:39.760 --> 02:15:42.640]   This virus is malware for the source code humanity.
[02:15:42.640 --> 02:15:47.120]   Biological malware, yeah.
[02:15:47.120 --> 02:15:51.120]   I thought that this was going to be a thing that somehow brought us all together.
[02:15:51.120 --> 02:15:53.480]   I don't see that happening.
[02:15:53.480 --> 02:15:56.520]   I see a lot more policy uncertainty and a lot more confusion.
[02:15:56.520 --> 02:15:58.440]   I really wish that wasn't the case.
[02:15:58.440 --> 02:16:01.720]   Is it a political issue?
[02:16:01.720 --> 02:16:03.720]   I think it's a lot of things.
[02:16:03.720 --> 02:16:05.720]   We live in a very complicated age.
[02:16:05.720 --> 02:16:07.280]   The economy is complicated.
[02:16:07.280 --> 02:16:10.000]   We've got a lot of opposing viewpoints.
[02:16:10.000 --> 02:16:15.440]   Unfortunately, we have people all around the world who are in power.
[02:16:15.440 --> 02:16:21.280]   Some of them are great and some of them should have other jobs.
[02:16:21.280 --> 02:16:25.480]   We're going to have to deal with what comes next.
[02:16:25.480 --> 02:16:27.120]   I always come back to hope.
[02:16:27.120 --> 02:16:31.840]   I really do think we have an opportunity to make things better going forward.
[02:16:31.840 --> 02:16:35.800]   Honestly, I feel like our political team is going to be a part of the world.
[02:16:35.800 --> 02:16:41.520]   I feel like our political systems have been outstripped by the future that we're the present
[02:16:41.520 --> 02:16:43.520]   that we're living in.
[02:16:43.520 --> 02:16:49.600]   We're really essentially trying to run this country with 18th century technology.
[02:16:49.600 --> 02:16:50.600]   It's not working.
[02:16:50.600 --> 02:16:56.720]   I'm not talking specifically Republicans or Democrats or even Electoral College.
[02:16:56.720 --> 02:17:01.440]   It's not working because there's an impedance mismatch.
[02:17:01.440 --> 02:17:02.440]   That's right.
[02:17:02.440 --> 02:17:08.320]   The challenge is that our technology is moving faster than our ability to create policy for
[02:17:08.320 --> 02:17:09.320]   it.
[02:17:09.320 --> 02:17:13.320]   The way that we create policy is not really intended to shift and change as quickly as
[02:17:13.320 --> 02:17:14.320]   tech.
[02:17:14.320 --> 02:17:18.720]   We're probably going to have to come up with different structures going forward.
[02:17:18.720 --> 02:17:23.480]   That's going to take a lot of political will and long-term thinking.
[02:17:23.480 --> 02:17:27.720]   By design, our democratic structures are short-term.
[02:17:27.720 --> 02:17:32.480]   Worse than that, the incumbents have all the power.
[02:17:32.480 --> 02:17:36.680]   There's no desire to change something that's put somebody in power.
[02:17:36.680 --> 02:17:38.640]   Why would you change it?
[02:17:38.640 --> 02:17:40.400]   That's a crazy talk.
[02:17:40.400 --> 02:17:44.280]   By the way, if you go to futuretodayinstitute.com, they've got the fringe sketch.
[02:17:44.280 --> 02:17:46.000]   It's so much fun to play with their front page.
[02:17:46.000 --> 02:17:49.320]   Yeah, you can play and move around all the different signals that we're tracking and
[02:17:49.320 --> 02:17:51.640]   see what's connected to what.
[02:17:51.640 --> 02:17:54.440]   This will give you a panic attack, ladies and gentlemen.
[02:17:54.440 --> 02:17:56.400]   What's colorful?
[02:17:56.400 --> 02:17:57.400]   It's colorful.
[02:17:57.400 --> 02:18:03.800]   The first time I saw the internet, I was on the well, which was still around the message
[02:18:03.800 --> 02:18:08.440]   board, and you could drop out of the well software onto the public internet, which at
[02:18:08.440 --> 02:18:10.400]   the time was Archie go for things like that.
[02:18:10.400 --> 02:18:12.400]   There's no web.
[02:18:12.400 --> 02:18:19.840]   And even then, I almost had a panic attack because everybody, the whole world is...
[02:18:19.840 --> 02:18:21.360]   There are people here.
[02:18:21.360 --> 02:18:22.360]   Lots of them.
[02:18:22.360 --> 02:18:23.360]   Yeah.
[02:18:23.360 --> 02:18:27.920]   And I can only imagine what your sense of the galaxy must have been.
[02:18:27.920 --> 02:18:28.920]   Holy cow.
[02:18:28.920 --> 02:18:29.920]   I'll tell you something.
[02:18:29.920 --> 02:18:35.880]   It's good that I had the panic attack when I did because it set me up for a lifelong journey
[02:18:35.880 --> 02:18:38.520]   to dealing with uncertainty constantly.
[02:18:38.520 --> 02:18:39.520]   Yeah.
[02:18:39.520 --> 02:18:41.120]   It's a good life skill to have.
[02:18:41.120 --> 02:18:42.640]   Yeah, no kidding.
[02:18:42.640 --> 02:18:44.040]   Thank you so much, Amy.
[02:18:44.040 --> 02:18:45.040]   Yeah.
[02:18:45.040 --> 02:18:46.040]   Thank you all for being here.
[02:18:46.040 --> 02:18:48.400]   We do this week in tech every Sunday afternoon.
[02:18:48.400 --> 02:18:51.680]   It's really as fun or interesting, but still try.
[02:18:51.680 --> 02:18:54.320]   Don't buy anyway, just in case.
[02:18:54.320 --> 02:18:58.400]   Usually we get, get started around 230 Pacific 530 Eastern time.
[02:18:58.400 --> 02:19:02.600]   That's 2130 UTC.
[02:19:02.600 --> 02:19:05.040]   You can watch live at Twitter TV slash live.
[02:19:05.040 --> 02:19:07.080]   There's audio live there too.
[02:19:07.080 --> 02:19:11.360]   And of course, it's an on-demand show as well, so you can get it from our website, Twitter
[02:19:11.360 --> 02:19:12.360]   TV.
[02:19:12.360 --> 02:19:13.360]   Yes, we're on YouTube.
[02:19:13.360 --> 02:19:15.200]   Smash the red button, smash the red button, subscribe.
[02:19:15.200 --> 02:19:17.520]   In fact, the best thing to do is subscribe.
[02:19:17.520 --> 02:19:22.000]   However you like to watch or listen, subscribe in your favorite podcast client that we will
[02:19:22.000 --> 02:19:23.000]   get it all the time.
[02:19:23.000 --> 02:19:26.920]   The only place you can't do that, I wish you could, is on your voice assistant.
[02:19:26.920 --> 02:19:27.920]   But we are there.
[02:19:27.920 --> 02:19:32.040]   All you have to do is say, "Hey, Echo, I will play this week in tech podcast."
[02:19:32.040 --> 02:19:33.480]   You don't get the latest version.
[02:19:33.480 --> 02:19:36.760]   You can even do it with a Twit Live stream if you want to listen anytime.
[02:19:36.760 --> 02:19:38.200]   We're always around hanging out.
[02:19:38.200 --> 02:19:45.960]   If you need some company in these tough times, just go Echo Play Twit Live and we'll
[02:19:45.960 --> 02:19:47.000]   be here for you.
[02:19:47.000 --> 02:19:48.000]   Thanks everybody.
[02:19:48.000 --> 02:19:50.800]   Time to go home, watch Westworld.
[02:19:50.800 --> 02:19:52.280]   Another Twit is in the can.
[02:19:52.280 --> 02:19:53.280]   We'll see you next time.
[02:19:53.280 --> 02:19:54.280]   This is amazing.
[02:19:54.280 --> 02:19:54.280]   [music]
[02:19:54.280 --> 02:20:04.120]   [music]
[02:20:04.120 --> 02:20:06.360]   (clicking)

