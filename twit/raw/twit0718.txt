;FFMETADATA1
title=I'm Saving It for the Nursing Home
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=718
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:04.400]   It's time for Twit this week and take great panel for you from Fast Company, Mark Sullivan.
[00:00:04.400 --> 00:00:09.700]   And we brought the All About Androiders in here from All About Android Flow ION.
[00:00:09.700 --> 00:00:12.700]   And Jason Howell, we're going to talk about Google I/O, of course.
[00:00:12.700 --> 00:00:20.000]   Microsoft's build keynote, the sad demo that never happened at build, and an unpackaging.
[00:00:20.000 --> 00:00:24.400]   And unboxing, I think the kids call it, the Pixel 3A. It's all coming up next.
[00:00:24.400 --> 00:00:25.200]   On Twit.
[00:00:25.200 --> 00:00:29.200]   Netcast, you love.
[00:00:29.200 --> 00:00:31.200]   From people you trust.
[00:00:31.200 --> 00:00:36.400]   This is Twit.
[00:00:36.400 --> 00:00:47.000]   This is Twit this week in Tech.
[00:00:47.000 --> 00:00:52.000]   Episode 718 recorded Sunday, May 12, 2019.
[00:00:52.000 --> 00:00:54.000]   I'm saving it for the nursing home.
[00:00:54.000 --> 00:00:57.000]   This week in Tech is brought to you by WordPress.
[00:00:57.000 --> 00:01:01.600]   Turn your dreams into reality and launch your website at WordPress.com.
[00:01:01.600 --> 00:01:05.600]   Get 15% off any new plan at WordPress.com/Twit.
[00:01:05.600 --> 00:01:07.400]   And buy, Helm.
[00:01:07.400 --> 00:01:10.000]   Take back your email, files, and photos.
[00:01:10.000 --> 00:01:15.600]   Own your own data with Helm, a secure personal server that lets you own your online identity.
[00:01:15.600 --> 00:01:20.800]   Go to the helm.com/Twit and save $50 off the Helm personal server.
[00:01:20.800 --> 00:01:24.000]   And buy, Wasabi, hot cloud storage.
[00:01:24.000 --> 00:01:30.000]   Thinking about moving your data to the cloud, Wasabi is enterprise-class cloud storage
[00:01:30.000 --> 00:01:37.000]   at 1/5 the price of Amazon S3 and up to 6 times faster, with no hidden fees for egress or API requests.
[00:01:37.000 --> 00:01:43.000]   Calculate your savings and try Wasabi with free unlimited storage for a month at Wasabi.com.
[00:01:43.000 --> 00:01:45.000]   Code Twit.
[00:01:45.000 --> 00:01:47.000]   And buy, Helm.
[00:01:47.000 --> 00:01:49.000]   The number one app to help reduce your stress.
[00:01:49.000 --> 00:01:51.000]   Relax your mind and help you sleep.
[00:01:51.000 --> 00:01:57.000]   Get 25% off a calm premium subscription at calm.com/Twit.
[00:01:57.000 --> 00:02:04.000]   It's time for Twit, the show where we cover the week's tech news with whichever journalists
[00:02:04.000 --> 00:02:08.000]   we could get it to come in on a short notice on Mother's Day.
[00:02:08.000 --> 00:02:11.000]   So that would explain why Jason Howell is here.
[00:02:11.000 --> 00:02:13.000]   Oh yeah, only on Mother's Day to do it.
[00:02:13.000 --> 00:02:14.000]   I apologize.
[00:02:14.000 --> 00:02:16.000]   Your poor wife, who is a great mother.
[00:02:16.000 --> 00:02:18.000]   You know what, they're enjoying the beach right now.
[00:02:18.000 --> 00:02:19.000]   They're doing okay.
[00:02:19.000 --> 00:02:20.000]   They're doing alright.
[00:02:20.000 --> 00:02:23.000]   Jason, the host of All About Android and Tech News Weekly.
[00:02:23.000 --> 00:02:27.000]   He's here for a good reason, as is his co-host from All About Android.
[00:02:27.000 --> 00:02:28.000]   Florence Ion.
[00:02:28.000 --> 00:02:29.000]   Happy Mother's Day, Mom.
[00:02:29.000 --> 00:02:30.000]   I told you to watch this video.
[00:02:30.000 --> 00:02:32.000]   Oh, this is it right now.
[00:02:32.000 --> 00:02:33.000]   Yes.
[00:02:33.000 --> 00:02:36.000]   Florence is also a host of All About Android.
[00:02:36.000 --> 00:02:38.000]   And both of them were at Google I/O this week.
[00:02:38.000 --> 00:02:39.000]   Yes indeed.
[00:02:39.000 --> 00:02:43.000]   But we thought to balance the panel, we should also talk about Microsoft Build.
[00:02:43.000 --> 00:02:46.000]   So we have Mark Sullivan from Fast Company.
[00:02:46.000 --> 00:02:49.000]   Are you going to take the Microsoft side of the show for us?
[00:02:49.000 --> 00:02:50.000]   I'll try.
[00:02:50.000 --> 00:02:51.000]   I'll do it best.
[00:02:51.000 --> 00:02:52.000]   If you had a...
[00:02:52.000 --> 00:02:54.000]   By the way, we can get you a computer.
[00:02:54.000 --> 00:02:56.000]   I see you're using your iPhone to keep notes.
[00:02:56.000 --> 00:02:58.000]   If you'd like, we can provide you with a laptop.
[00:02:58.000 --> 00:02:59.000]   This was a big week this week.
[00:02:59.000 --> 00:03:00.000]   It's too much to remember.
[00:03:00.000 --> 00:03:01.000]   Oh, you're telling me.
[00:03:01.000 --> 00:03:02.000]   Whoa!
[00:03:02.000 --> 00:03:09.000]   So I had the misfortune of getting up early to cover Microsoft Build on Monday.
[00:03:09.000 --> 00:03:12.000]   We streamed the keynote.
[00:03:12.000 --> 00:03:15.000]   It was actually...
[00:03:15.000 --> 00:03:18.000]   It began in the most saddest way possible.
[00:03:18.000 --> 00:03:19.000]   Yeah.
[00:03:19.000 --> 00:03:22.000]   It was the worst demo fail I've ever seen.
[00:03:22.000 --> 00:03:25.000]   I've seen some really horrible demo fail.
[00:03:25.000 --> 00:03:26.000]   But I just...
[00:03:26.000 --> 00:03:27.000]   It broke my heart.
[00:03:27.000 --> 00:03:28.000]   Andrew Chiken was there.
[00:03:28.000 --> 00:03:31.000]   He wrote Man on the Moon, which was the story of the Apollo 11 landing.
[00:03:31.000 --> 00:03:33.000]   It is the 50th anniversary in July.
[00:03:33.000 --> 00:03:35.000]   John Knoll was there.
[00:03:35.000 --> 00:03:36.000]   He's a special effects at ILM.
[00:03:36.000 --> 00:03:40.000]   But before that, he invented Photoshop with his brother Thomas.
[00:03:40.000 --> 00:03:45.000]   And the great article in Variety, credit to Yanko Records for doing the research, I think
[00:03:45.000 --> 00:03:47.000]   Yanko thought, "Oh, this is going to be great because everybody will see the demo."
[00:03:47.000 --> 00:03:50.000]   And then want to know the story behind it.
[00:03:50.000 --> 00:03:52.000]   His story changed a little bit.
[00:03:52.000 --> 00:03:58.000]   But the story was that in 1999, John Knoll, who was at the time doing Star Wars special
[00:03:58.000 --> 00:04:04.000]   effects and Star Trek special effects, discovered he would always been an Apollo 11 fan as anybody
[00:04:04.000 --> 00:04:06.000]   of our generation was.
[00:04:06.000 --> 00:04:07.000]   He was seven.
[00:04:07.000 --> 00:04:09.000]   I was 12 when in 1969.
[00:04:09.000 --> 00:04:16.000]   And he found a treasure trove of telemetry data that NASA had and never published of the
[00:04:16.000 --> 00:04:22.000]   moonwalk of the landing on the moon, the actual numbers that go with all of this stuff.
[00:04:22.000 --> 00:04:29.000]   And he started a project, now 20 year project, to take that telemetry and image it, 3D imaging,
[00:04:29.000 --> 00:04:35.000]   to actually create a CGI of the moon landing.
[00:04:35.000 --> 00:04:38.000]   Along comes Microsoft and HoloLens.
[00:04:38.000 --> 00:04:41.000]   This was going to be a HoloLens 2 demo.
[00:04:41.000 --> 00:04:47.320]   And weirdly, Tim Sweeney of Epic Games, who used to hate Microsoft and has now completely
[00:04:47.320 --> 00:04:51.000]   come around, said, "You can use our Unreal Engine."
[00:04:51.000 --> 00:04:55.000]   And they created a HoloLens demo of the moon landing.
[00:04:55.000 --> 00:05:01.000]   Starting with the launch of the spacecraft, they explained how the stages worked.
[00:05:01.000 --> 00:05:03.000]   They followed it all the way to the moon.
[00:05:03.000 --> 00:05:07.000]   They showed the limb, the lunar module landing on the moon.
[00:05:07.000 --> 00:05:12.000]   And you can actually see it, fortunately, they taped the rehearsal.
[00:05:12.000 --> 00:05:20.000]   Because when it came time for the actual keynote, it's at 8.30 in the morning, Satya Nadella
[00:05:20.000 --> 00:05:22.000]   is standing off stage.
[00:05:22.000 --> 00:05:27.000]   And the show before it was a bunch of college science projects.
[00:05:27.000 --> 00:05:33.000]   The guy who was hosting the show was getting in his ear, stretch, stretch.
[00:05:33.000 --> 00:05:35.000]   He's stretched for 20 minutes.
[00:05:35.000 --> 00:05:39.000]   He took so long to get started, he stretched for 20 minutes.
[00:05:39.000 --> 00:05:41.000]   Because the demo wasn't working.
[00:05:41.000 --> 00:05:45.000]   Finally, according to records, he ran out of things to ask the college kids.
[00:05:45.000 --> 00:05:49.000]   So he said, "Now let's go to the keynote."
[00:05:49.000 --> 00:05:52.000]   Chiking comes on stage.
[00:05:52.000 --> 00:05:54.000]   Noel comes on stage.
[00:05:54.000 --> 00:05:57.000]   They're wearing the HoloLens 2.
[00:05:57.000 --> 00:06:00.000]   And they say, "Never mind."
[00:06:00.000 --> 00:06:03.000]   And they walk off the stage.
[00:06:03.000 --> 00:06:07.000]   And they say, "This just shows it's harder to do a HoloLens demo than the land on the moon."
[00:06:07.000 --> 00:06:09.000]   And it was just like horrible.
[00:06:09.000 --> 00:06:10.000]   That's not brutal.
[00:06:10.000 --> 00:06:11.000]   I don't know.
[00:06:11.000 --> 00:06:12.000]   That's pretty...
[00:06:12.000 --> 00:06:14.000]   It was like Michael Bay, the sample.
[00:06:14.000 --> 00:06:15.000]   Remember the Sanqui Note?
[00:06:15.000 --> 00:06:16.000]   Yes.
[00:06:16.000 --> 00:06:19.000]   The propter fails and Michael just goes...
[00:06:19.000 --> 00:06:23.000]   You felt that defeat with that moment.
[00:06:23.000 --> 00:06:24.000]   This was very much like that.
[00:06:24.000 --> 00:06:29.000]   Anyway, I only say that to refer people to the Variety article.
[00:06:29.000 --> 00:06:34.000]   There's a video there.
[00:06:34.000 --> 00:06:37.000]   You can also see it on YouTube.
[00:06:37.000 --> 00:06:40.000]   It's on the Epic Games YouTube channel of the actual demo as it was supposed to go out.
[00:06:40.000 --> 00:06:41.000]   And it was really good.
[00:06:41.000 --> 00:06:42.000]   At least they had a backup.
[00:06:42.000 --> 00:06:43.000]   At least.
[00:06:43.000 --> 00:06:44.000]   Yeah, right.
[00:06:44.000 --> 00:06:45.000]   Thank God they did this.
[00:06:45.000 --> 00:06:46.000]   Yeah.
[00:06:46.000 --> 00:06:49.000]   Man, after all that build up too, holding onto that data, having something very...
[00:06:49.000 --> 00:06:51.000]   20 years he'd been working on this.
[00:06:51.000 --> 00:06:54.000]   And for it to just basically be non-existent.
[00:06:54.000 --> 00:06:58.000]   So if it's doing the moon landing or they're also showing the green screen backdrop and
[00:06:58.000 --> 00:07:00.000]   the Hollywood, it was all fake.
[00:07:00.000 --> 00:07:01.000]   How they picked the fake the whole thing.
[00:07:01.000 --> 00:07:04.000]   And how they put the wind and the flag or whatever.
[00:07:04.000 --> 00:07:05.000]   There's no wind I think.
[00:07:05.000 --> 00:07:06.000]   Yeah, the telemetry of all that is there.
[00:07:06.000 --> 00:07:07.000]   Yes.
[00:07:07.000 --> 00:07:09.000]   That's where it came from.
[00:07:09.000 --> 00:07:11.000]   It was the script written by Stanley Cooper.
[00:07:11.000 --> 00:07:12.000]   Yeah, exactly.
[00:07:12.000 --> 00:07:15.000]   Didn't they say they thought Stanley Cooper helped with it, right?
[00:07:15.000 --> 00:07:16.000]   Help shoot it.
[00:07:16.000 --> 00:07:18.000]   Do you think that people still believe that?
[00:07:18.000 --> 00:07:19.000]   I think there are.
[00:07:19.000 --> 00:07:21.000]   There's a lot of people still believe that.
[00:07:21.000 --> 00:07:23.000]   They believe the earth is flat too because they started on YouTube.
[00:07:23.000 --> 00:07:24.000]   A few do, yeah.
[00:07:24.000 --> 00:07:25.000]   Yeah.
[00:07:25.000 --> 00:07:27.000]   The Venn diagram of those two people is probably...
[00:07:27.000 --> 00:07:28.000]   It's very...
[00:07:28.000 --> 00:07:29.000]   It's a related...
[00:07:29.000 --> 00:07:30.000]   Yeah.
[00:07:30.000 --> 00:07:32.000]   But yeah, it was weird.
[00:07:32.000 --> 00:07:36.000]   I mean, that demo was over before anybody even knew what was going on.
[00:07:36.000 --> 00:07:37.000]   Right.
[00:07:37.000 --> 00:07:38.000]   They bailed on it so quickly.
[00:07:38.000 --> 00:07:39.000]   They didn't waste any time.
[00:07:39.000 --> 00:07:40.000]   Yeah.
[00:07:40.000 --> 00:07:42.000]   It was kind of like, "Well, come on, try."
[00:07:42.000 --> 00:07:44.000]   At least boost the machine.
[00:07:44.000 --> 00:07:45.000]   But they...
[00:07:45.000 --> 00:07:47.000]   No, I think they knew that it wasn't going to work.
[00:07:47.000 --> 00:07:48.000]   Yeah.
[00:07:48.000 --> 00:07:52.000]   And it really was kind of a fitting kickoff for the worst keynote I've ever seen.
[00:07:52.000 --> 00:07:53.000]   Oh.
[00:07:53.000 --> 00:07:55.000]   You agree, Mark?
[00:07:55.000 --> 00:07:58.000]   I hadn't thought of that.
[00:07:58.000 --> 00:07:59.000]   [laughter]
[00:07:59.000 --> 00:08:01.000]   Okay, maybe that's hyperbole.
[00:08:01.000 --> 00:08:02.000]   That's overstating it.
[00:08:02.000 --> 00:08:05.000]   We have years of Samsung keynotes to pull from.
[00:08:05.000 --> 00:08:06.000]   It wasn't really bad.
[00:08:06.000 --> 00:08:07.000]   It wasn't Samsung bad.
[00:08:07.000 --> 00:08:09.000]   It wasn't bad in that way.
[00:08:09.000 --> 00:08:12.000]   It was just kind of lifeless and dull, I felt like.
[00:08:12.000 --> 00:08:13.000]   A lot of it was.
[00:08:13.000 --> 00:08:16.000]   I mean, I think it was very geeky, most of it.
[00:08:16.000 --> 00:08:17.000]   Yeah, which is good.
[00:08:17.000 --> 00:08:18.000]   It's a developer keynote.
[00:08:18.000 --> 00:08:19.000]   Yeah.
[00:08:19.000 --> 00:08:20.000]   That was...
[00:08:20.000 --> 00:08:21.000]   That was Microsoft's niche.
[00:08:21.000 --> 00:08:22.000]   Right.
[00:08:22.000 --> 00:08:23.000]   That's...
[00:08:23.000 --> 00:08:24.000]   I think that's...
[00:08:24.000 --> 00:08:25.000]   I think that somebody was writing.
[00:08:25.000 --> 00:08:26.000]   That's what they're trying to return to.
[00:08:26.000 --> 00:08:27.000]   They're trying to return from...
[00:08:27.000 --> 00:08:28.000]   The roots.
[00:08:28.000 --> 00:08:29.000]   Yeah.
[00:08:29.000 --> 00:08:33.000]   To Bill Gates and, hey, we're a bunch of nerds and we're going to make the best tools out
[00:08:33.000 --> 00:08:35.000]   there and you're going to love us for it.
[00:08:35.000 --> 00:08:37.000]   So I should give him a pass, maybe, because it isn't...
[00:08:37.000 --> 00:08:38.000]   It's not showbiz.
[00:08:38.000 --> 00:08:40.000]   You know, Steve Jobs...
[00:08:40.000 --> 00:08:41.000]   We've been trained.
[00:08:41.000 --> 00:08:42.000]   We've been trained.
[00:08:42.000 --> 00:08:43.000]   Yeah.
[00:08:43.000 --> 00:08:44.000]   Yeah.
[00:08:44.000 --> 00:08:46.000]   It was more like a pre-Steve Jobs idea of a keynote.
[00:08:46.000 --> 00:08:48.000]   And then given that it's developer conferences probably are right.
[00:08:48.000 --> 00:08:51.000]   They did make some very big announcements at Build.
[00:08:51.000 --> 00:08:59.000]   The one that I think is going to end up being the hand grenade, lobbed into Microsoft's business
[00:08:59.000 --> 00:09:06.000]   model, they're putting the Linux kernel into Windows.
[00:09:06.000 --> 00:09:08.000]   Anybody want to say anything?
[00:09:08.000 --> 00:09:14.000]   Well, it turns out this Chromebook that I have in front of me also has the Linux kernel on
[00:09:14.000 --> 00:09:15.000]   it.
[00:09:15.000 --> 00:09:16.000]   And if I wanted to, I could run a Windows app on it too.
[00:09:16.000 --> 00:09:17.000]   So it turns out the...
[00:09:17.000 --> 00:09:19.000]   And your Android device is running Linux.
[00:09:19.000 --> 00:09:22.000]   So it turns out really the year of desktop Linux happened.
[00:09:22.000 --> 00:09:28.000]   It's interesting because Microsoft has been trying to woo developers.
[00:09:28.000 --> 00:09:32.000]   And one of the ways they did it was with something called LSW, the Linux subsystem for Windows,
[00:09:32.000 --> 00:09:33.000]   which allowed you...
[00:09:33.000 --> 00:09:34.000]   It was an emulator though.
[00:09:34.000 --> 00:09:35.000]   It wasn't really Linux.
[00:09:35.000 --> 00:09:43.000]   It allowed you to run Linux binaries on Windows in a way that really honestly was not ideal.
[00:09:43.000 --> 00:09:47.000]   But it was to make developers feel better because they have their tools.
[00:09:47.000 --> 00:09:51.000]   But there were some real performance, significant performance issues.
[00:09:51.000 --> 00:09:57.000]   And I mean, I really gave it the benefit that I put on a very fast computer, really tried.
[00:09:57.000 --> 00:10:01.000]   And even with the most recent version of LSW, it was...
[00:10:01.000 --> 00:10:09.000]   Small file handling was so slow that you could just watch the grass grow while you were loading files
[00:10:09.000 --> 00:10:10.000]   or compiling things.
[00:10:10.000 --> 00:10:14.000]   All the things developers want to do, which is process small files.
[00:10:14.000 --> 00:10:17.000]   So I think Microsoft...
[00:10:17.000 --> 00:10:20.000]   I asked Christina Warren about this a couple of weeks ago on the show.
[00:10:20.000 --> 00:10:22.000]   She said, "Yeah, we know. We know it's a problem."
[00:10:22.000 --> 00:10:25.000]   And so the decision... She must have known this at the time.
[00:10:25.000 --> 00:10:26.000]   She was very cagey.
[00:10:26.000 --> 00:10:31.000]   The decision was, "Why do it in emulation? Why don't you just put Linux in Windows?"
[00:10:31.000 --> 00:10:33.000]   So it's a special version of the Linux kernel that...
[00:10:33.000 --> 00:10:39.000]   Actually, a fairly old version of the Linux kernel that Microsoft is going to modify to fit well within Windows.
[00:10:39.000 --> 00:10:42.000]   I'm going to go out on a limb.
[00:10:42.000 --> 00:10:45.000]   I think...
[00:10:45.000 --> 00:10:47.000]   Build 2025.
[00:10:47.000 --> 00:10:50.000]   Microsoft is just going to say...
[00:10:50.000 --> 00:10:52.000]   And now Windows is Linux.
[00:10:52.000 --> 00:10:55.000]   Honestly, they're just... Why not?
[00:10:55.000 --> 00:10:58.000]   Why not abandon the Microsoft kernel entirely?
[00:10:58.000 --> 00:11:00.000]   You've already got the Linux kernel in there.
[00:11:00.000 --> 00:11:01.000]   This is just the beginning of the end.
[00:11:01.000 --> 00:11:02.000]   Windows, what do you think?
[00:11:02.000 --> 00:11:05.000]   That's crazy, am I crazy?
[00:11:05.000 --> 00:11:08.000]   No, I don't think that's necessarily crazy.
[00:11:08.000 --> 00:11:11.000]   I think that's a possible future.
[00:11:11.000 --> 00:11:17.000]   I think what we saw at Build this year was really finally Microsoft saying it's not about Windows anymore.
[00:11:17.000 --> 00:11:19.000]   It's barely even about Office.
[00:11:19.000 --> 00:11:24.000]   It's about Office 365 and Microsoft Dynamics.
[00:11:24.000 --> 00:11:27.000]   It's about enterprise, about Azure. It's about the cloud.
[00:11:27.000 --> 00:11:32.000]   Yeah, I think that's where everything starts, is the intelligent edge.
[00:11:32.000 --> 00:11:37.000]   Azure is the center of the universe for Microsoft right now.
[00:11:37.000 --> 00:11:40.000]   And for years, Nadella would say things like, "Well, we want to be..."
[00:11:40.000 --> 00:11:43.000]   When they first announced the touch-first version of Office,
[00:11:43.000 --> 00:11:46.000]   it wasn't going to be on Windows. It was going to be in the iPad.
[00:11:46.000 --> 00:11:50.000]   What he said was, "Well, we want to be wherever our customers are."
[00:11:50.000 --> 00:11:53.000]   That might be iPad. They have great Android apps, right?
[00:11:53.000 --> 00:11:55.000]   I mean, Microsoft has some Android.
[00:11:55.000 --> 00:12:00.000]   Outlook is great on Android because they put a complete, but that's another story.
[00:12:00.000 --> 00:12:04.000]   He used to say, "But the best experience will be on Windows."
[00:12:04.000 --> 00:12:05.000]   He hasn't said that in a couple of years.
[00:12:05.000 --> 00:12:07.000]   He just says, "We want to be wherever our customers are."
[00:12:07.000 --> 00:12:10.000]   It's not just to him. I mean, everybody I talk to at Microsoft
[00:12:10.000 --> 00:12:16.000]   is kind of telling this story about openness and customer-friendliness
[00:12:16.000 --> 00:12:22.000]   and going where people are and not trying to leverage products
[00:12:22.000 --> 00:12:27.000]   and not trying to twist customers' arm to come to this platform
[00:12:27.000 --> 00:12:29.000]   and do away with that one.
[00:12:29.000 --> 00:12:33.000]   And I think that's part of Satya's thing.
[00:12:33.000 --> 00:12:35.000]   It might be why the build keynote isn't as exciting,
[00:12:35.000 --> 00:12:39.000]   because infrastructure is not as exciting as the things Google showed the next day, right?
[00:12:39.000 --> 00:12:41.000]   The surface stuff.
[00:12:41.000 --> 00:12:43.000]   Yeah. I mean, really, there wasn't.
[00:12:43.000 --> 00:12:44.000]   It was about plumbing.
[00:12:44.000 --> 00:12:48.000]   Yeah, it was. It was about developer-focused stuff
[00:12:48.000 --> 00:12:51.000]   and there was some consumer-facing things,
[00:12:51.000 --> 00:12:55.000]   but not terribly exciting things.
[00:12:55.000 --> 00:12:59.000]   And some of it was kind of future tense.
[00:12:59.000 --> 00:13:02.000]   There was a few interesting things.
[00:13:02.000 --> 00:13:06.000]   Like they're working on, we have spell check in Word,
[00:13:06.000 --> 00:13:10.000]   but they're going to build a tool.
[00:13:10.000 --> 00:13:14.000]   They're building a tool in there now that will correct your,
[00:13:14.000 --> 00:13:18.000]   I say, political correctness, but that's kind of a short hard way of doing that.
[00:13:18.000 --> 00:13:20.000]   Can you tell me you were on right-wing radio yesterday?
[00:13:20.000 --> 00:13:23.000]   I didn't do it. They asked me to do it.
[00:13:23.000 --> 00:13:28.000]   But it's, they'll check your writing for inclusiveness or gender-based.
[00:13:28.000 --> 00:13:33.000]   That's a much better way to say it, because I think politically correct is.
[00:13:33.000 --> 00:13:36.000]   Yeah, I probably shouldn't have done that.
[00:13:36.000 --> 00:13:38.000]   I probably shouldn't have had it.
[00:13:38.000 --> 00:13:39.000]   It's a new category.
[00:13:39.000 --> 00:13:43.000]   Yeah, I was hungry for clicks, so I did it.
[00:13:43.000 --> 00:13:45.000]   Finally, somebody admits it.
[00:13:45.000 --> 00:13:48.000]   Microsoft Word is getting politically correct.
[00:13:48.000 --> 00:13:50.000]   So it's not a grammar checker.
[00:13:50.000 --> 00:13:51.000]   It's not a spelling checker.
[00:13:51.000 --> 00:13:53.000]   It's way past that.
[00:13:53.000 --> 00:14:00.000]   I mean, they had a team of linguists and professors
[00:14:00.000 --> 00:14:07.000]   in to define these ten or eleven different ways of reading your writing for you
[00:14:07.000 --> 00:14:11.000]   and on inclusiveness and cultural differences.
[00:14:11.000 --> 00:14:17.000]   The thing is they're going to try to warn you against saying something
[00:14:17.000 --> 00:14:20.000]   that you don't know you're saying, because you're saying it incorrectly.
[00:14:20.000 --> 00:14:24.000]   And as an old guy, I often stumble into traps like that.
[00:14:24.000 --> 00:14:25.000]   Yeah, I have to.
[00:14:25.000 --> 00:14:31.000]   For instance, I have said in the past, let's hear from the distaff side.
[00:14:31.000 --> 00:14:34.000]   Let's hear from a female perspective.
[00:14:34.000 --> 00:14:36.000]   And then somebody said it rightly.
[00:14:36.000 --> 00:14:38.000]   So, you know where that phrase comes from.
[00:14:38.000 --> 00:14:41.000]   It's a dis on women and you shouldn't say that.
[00:14:41.000 --> 00:14:42.000]   And I went, "Oh my God."
[00:14:42.000 --> 00:14:46.000]   Because that's just a phrase that I grew up with in literature and stuff.
[00:14:46.000 --> 00:14:50.000]   And you give an example, Mike, in your column on Fast Companies,
[00:14:50.000 --> 00:14:53.000]   if you write, "We need to get some fresh blood in here."
[00:14:53.000 --> 00:14:57.000]   The microsoft will suggest new employees instead.
[00:14:57.000 --> 00:15:01.000]   And honestly, fresh blood, I mean, that's a common phrase,
[00:15:01.000 --> 00:15:02.000]   but you're right.
[00:15:02.000 --> 00:15:04.000]   If you really think about it, it's kind of disgusting.
[00:15:04.000 --> 00:15:05.000]   Yeah.
[00:15:05.000 --> 00:15:06.000]   Yeah.
[00:15:06.000 --> 00:15:07.000]   It's got a little brutality to it.
[00:15:07.000 --> 00:15:09.000]   You've got some fresh fruit in here, some pythons.
[00:15:09.000 --> 00:15:10.000]   Some luscious mangoes.
[00:15:10.000 --> 00:15:11.000]   It's like...
[00:15:11.000 --> 00:15:12.000]   I'm going to completely different direction now.
[00:15:12.000 --> 00:15:13.000]   There's probably a lot going on there.
[00:15:13.000 --> 00:15:14.000]   That's fair.
[00:15:14.000 --> 00:15:15.000]   Fair.
[00:15:15.000 --> 00:15:16.000]   Fair.
[00:15:16.000 --> 00:15:17.000]   It's delicious.
[00:15:17.000 --> 00:15:19.000]   Not allowed to say fresh fruit anymore.
[00:15:19.000 --> 00:15:20.000]   Okay.
[00:15:20.000 --> 00:15:21.000]   I mean, we're getting Congressman or Mailman.
[00:15:21.000 --> 00:15:23.000]   You should be replaced by Mailcare.
[00:15:23.000 --> 00:15:25.000]   Yeah, see, that's the gender bias.
[00:15:25.000 --> 00:15:26.000]   Mm-hmm.
[00:15:26.000 --> 00:15:30.000]   We're really getting more and more accustomed to allowing our computers to write for us,
[00:15:30.000 --> 00:15:31.000]   right?
[00:15:31.000 --> 00:15:32.000]   Like, this is not something that only Microsoft is doing.
[00:15:32.000 --> 00:15:33.000]   Hello, Grammarly.
[00:15:33.000 --> 00:15:35.000]   Well, absolutely sponsored by Mail.
[00:15:35.000 --> 00:15:36.000]   Yeah.
[00:15:36.000 --> 00:15:38.000]   Also, you know, Google has their smart replies.
[00:15:38.000 --> 00:15:43.000]   Like, these are things that I think when they announced it, I thought, at least as a result,
[00:15:43.000 --> 00:15:46.000]   you know, refers to Google's solution.
[00:15:46.000 --> 00:15:47.000]   That sounds neat.
[00:15:47.000 --> 00:15:49.000]   That's neat that computers can do that, but I'll never use it.
[00:15:49.000 --> 00:15:51.000]   I actually use it pretty reasonably.
[00:15:51.000 --> 00:15:52.000]   I use it all this time.
[00:15:52.000 --> 00:15:54.000]   And I almost don't want the person on the other end to know.
[00:15:54.000 --> 00:15:55.000]   You know what I mean?
[00:15:55.000 --> 00:15:56.000]   Oh, I know.
[00:15:56.000 --> 00:15:57.000]   It's dead on.
[00:15:57.000 --> 00:15:59.000]   I hope you don't know when I do it.
[00:15:59.000 --> 00:16:00.000]   I think I know when you do it.
[00:16:00.000 --> 00:16:03.000]   I think we know that we're doing it because we can show you.
[00:16:03.000 --> 00:16:04.000]   I don't actually say, "Okay sounds good."
[00:16:04.000 --> 00:16:07.000]   But Google tells me to respond, "Okay sounds good."
[00:16:07.000 --> 00:16:08.000]   Yeah.
[00:16:08.000 --> 00:16:09.000]   Because it sounds like a good plot.
[00:16:09.000 --> 00:16:10.000]   See, that's...
[00:16:10.000 --> 00:16:12.000]   This is an example of where Google has lapped Microsoft.
[00:16:12.000 --> 00:16:16.000]   Because they've gone from doing it correctly to doing it somewhat incorrectly.
[00:16:16.000 --> 00:16:19.000]   An English teacher would say, "Okay sounds good, is wrong, right?"
[00:16:19.000 --> 00:16:22.000]   Well, it's okay, comma sounds good.
[00:16:22.000 --> 00:16:25.000]   I just think Google's being very colloquial.
[00:16:25.000 --> 00:16:29.000]   And in a way, that's for what you're using it for, which is texting or email.
[00:16:29.000 --> 00:16:30.000]   That's better.
[00:16:30.000 --> 00:16:36.000]   You say, "Mike, if you describe in your prose disabled person, the AI says a person with a disability instead."
[00:16:36.000 --> 00:16:37.000]   I think actually...
[00:16:37.000 --> 00:16:38.000]   I didn't know that.
[00:16:38.000 --> 00:16:39.000]   I think that's good.
[00:16:39.000 --> 00:16:40.000]   Yeah.
[00:16:40.000 --> 00:16:43.000]   Because it's first person instead of a passive voice.
[00:16:43.000 --> 00:16:44.000]   Yeah.
[00:16:44.000 --> 00:16:48.000]   And it puts the person in front of the disability in the phrase.
[00:16:48.000 --> 00:16:49.000]   Yeah.
[00:16:49.000 --> 00:16:50.000]   Disabled qualifies person.
[00:16:50.000 --> 00:16:51.000]   Yeah.
[00:16:51.000 --> 00:16:52.000]   They're a person first.
[00:16:52.000 --> 00:16:53.000]   Yeah.
[00:16:53.000 --> 00:16:54.000]   I don't mind that.
[00:16:54.000 --> 00:16:55.000]   And I think that maybe...
[00:16:55.000 --> 00:16:57.000]   But maybe that's me because I'm pretty politically correct.
[00:16:57.000 --> 00:17:05.000]   It's a response to where society is going, new societal norms, and you know, a lot of us are learning a lot of new things now.
[00:17:05.000 --> 00:17:07.000]   I mean, I'm learning things I didn't know.
[00:17:07.000 --> 00:17:13.000]   It's not like I was born understanding... or being able to say the right vernacular.
[00:17:13.000 --> 00:17:25.000]   But I do appreciate that it's something Microsoft is taking into consideration because I think in tech, we often forget to put people first in an effort to whatever innovate, et cetera.
[00:17:25.000 --> 00:17:36.000]   But I think sometimes the innovation is as minor as making sure that, you know, everyone is referring to each other in a way that is not insulting or intimidating
[00:17:36.000 --> 00:17:42.000]   or I think it's important because those little things do contribute to a larger picture.
[00:17:42.000 --> 00:17:44.000]   So right now you'd have to be using Office.
[00:17:44.000 --> 00:17:45.000]   Right.
[00:17:45.000 --> 00:17:46.000]   Yeah.
[00:17:46.000 --> 00:17:48.000]   This is for Word Online.
[00:17:48.000 --> 00:17:49.000]   And I think for Online.
[00:17:49.000 --> 00:17:50.000]   Yeah.
[00:17:50.000 --> 00:17:54.000]   Not for the disk-based office.
[00:17:54.000 --> 00:17:55.000]   Right.
[00:17:55.000 --> 00:17:56.000]   Right.
[00:17:56.000 --> 00:17:57.000]   It may come to that.
[00:17:57.000 --> 00:17:58.000]   It's a service on top of it.
[00:17:58.000 --> 00:17:59.000]   Right.
[00:17:59.000 --> 00:18:01.000]   And they're just starting to test it out.
[00:18:01.000 --> 00:18:05.000]   And of course you could reject the suggestions as you can with Grammarly or any spell checker.
[00:18:05.000 --> 00:18:06.000]   You don't have to.
[00:18:06.000 --> 00:18:07.000]   No.
[00:18:07.000 --> 00:18:08.000]   Certainly not.
[00:18:08.000 --> 00:18:13.000]   I think the reason it kind of struck me as interesting is it's just that it's kind of what you were saying, Flo.
[00:18:13.000 --> 00:18:21.000]   I mean, this gets into some areas in linguistics and culture that are very much in flux right now.
[00:18:21.000 --> 00:18:25.000]   And we're learning to talk about things differently with different sensitivities.
[00:18:25.000 --> 00:18:29.000]   And because of that, these are things that people argue about.
[00:18:29.000 --> 00:18:32.000]   They're, you know, they're a bit controversial.
[00:18:32.000 --> 00:18:33.000]   It's not a given.
[00:18:33.000 --> 00:18:34.000]   Yeah.
[00:18:34.000 --> 00:18:37.640]   You know, the other day I was listening to a book or an interview or something.
[00:18:37.640 --> 00:18:41.000]   And somebody said the word retarded, which of course we don't use about people who are
[00:18:41.000 --> 00:18:42.400]   developmentally disabled.
[00:18:42.400 --> 00:18:44.920]   That's obviously wrong.
[00:18:44.920 --> 00:18:50.600]   But as it turned, and I so I kind of went, but then I thought about it.
[00:18:50.600 --> 00:18:56.160]   And actually they were using it in the original meaning of the word to retard somebody's progress
[00:18:56.160 --> 00:18:57.640]   to slow it down.
[00:18:57.640 --> 00:19:03.040]   And it was, you know, I think some of it comes back to intention and meaning.
[00:19:03.040 --> 00:19:07.360]   But there are times when you can, so it's not always obvious if it's politically incorrect.
[00:19:07.360 --> 00:19:09.440]   I think it's good though to think about the words you're using.
[00:19:09.440 --> 00:19:10.640]   I don't have a problem with that.
[00:19:10.640 --> 00:19:12.080]   It's intention versus impact.
[00:19:12.080 --> 00:19:14.880]   What are the, what is the impact of your intention?
[00:19:14.880 --> 00:19:17.040]   And if your intention hurts somebody, it's a bad impact.
[00:19:17.040 --> 00:19:20.520]   Then it doesn't matter what the intention was because it hurts somebody.
[00:19:20.520 --> 00:19:22.520]   That's something I live by.
[00:19:22.520 --> 00:19:27.520]   And yet I could also see, I mean, Facebook's kind of doing this.
[00:19:27.520 --> 00:19:29.320]   Word saying, well, that's fake news.
[00:19:29.320 --> 00:19:30.320]   Right.
[00:19:30.320 --> 00:19:31.320]   You asserted something.
[00:19:31.320 --> 00:19:32.880]   Oh, man didn't land on the mood.
[00:19:32.880 --> 00:19:33.880]   Well, that's fake news.
[00:19:33.880 --> 00:19:34.880]   It's the raises.
[00:19:34.880 --> 00:19:41.680]   At some point you don't want, I mean, I don't want any corporation to start asserting its
[00:19:41.680 --> 00:19:43.840]   cultural values on the culture.
[00:19:43.840 --> 00:19:44.840]   Do you?
[00:19:44.840 --> 00:19:46.520]   I mean, that's, that's exactly.
[00:19:46.520 --> 00:19:49.920]   We've gone too far making corporations people as it is, but now to have them assert their
[00:19:49.920 --> 00:19:50.920]   values.
[00:19:50.920 --> 00:19:56.160]   I think that's one of the things that's keeping Zuckerberg up at night right now is, you know,
[00:19:56.160 --> 00:20:00.920]   I think there's in some ways, Facebook, and I'm sympathetic to them about this, is I
[00:20:00.920 --> 00:20:04.440]   think they are being asked to devise a set of values.
[00:20:04.440 --> 00:20:05.440]   It's impossible.
[00:20:05.440 --> 00:20:06.440]   You can't.
[00:20:06.440 --> 00:20:07.440]   You can't.
[00:20:07.440 --> 00:20:08.440]   Especially not now.
[00:20:08.440 --> 00:20:09.840]   Not with the floodgates with how open they are.
[00:20:09.840 --> 00:20:12.280]   Well, and it's a global environment.
[00:20:12.280 --> 00:20:18.040]   So what we consider in the United States is a given, you know, women are equal.
[00:20:18.040 --> 00:20:21.080]   That's not, there's plenty of countries in Facebook where they would say, what are you
[00:20:21.080 --> 00:20:22.720]   talking about?
[00:20:22.720 --> 00:20:25.560]   So this isn't literally, I think, an impossible task.
[00:20:25.560 --> 00:20:29.400]   I think that's what he means when he says, I've got too much power, you know, but when
[00:20:29.400 --> 00:20:33.320]   he comes out and says that, you know, and that, and he calls for some kind of government
[00:20:33.320 --> 00:20:36.080]   help, that's part of what he means.
[00:20:36.080 --> 00:20:38.200]   Help protect me from myself, please.
[00:20:38.200 --> 00:20:43.840]   Well, it's interesting because he's not the only one saying he has too much power.
[00:20:43.840 --> 00:20:50.320]   His, his former college roommate, Facebook co-founder wrote an op ed piece, Chris Hughes,
[00:20:50.320 --> 00:20:56.520]   an op ed piece in the New York Times saying, in fact, Mark's a nice guy, but he has too
[00:20:56.520 --> 00:20:57.680]   much power.
[00:20:57.680 --> 00:20:58.680]   Yeah.
[00:20:58.680 --> 00:21:02.320]   Now, Chris Hughes's own story is somewhat checkered.
[00:21:02.320 --> 00:21:04.960]   I'm going to say who played him in the movie.
[00:21:04.960 --> 00:21:05.960]   I don't know.
[00:21:05.960 --> 00:21:06.960]   Was he in the movie?
[00:21:06.960 --> 00:21:08.440]   Look at these guys when they were.
[00:21:08.440 --> 00:21:09.440]   Wow.
[00:21:09.440 --> 00:21:11.720]   Yeah, he's had, he's had quite some hair over the years.
[00:21:11.720 --> 00:21:12.720]   He's a freshman.
[00:21:12.720 --> 00:21:15.080]   Um, my mark is so young.
[00:21:15.080 --> 00:21:19.840]   And by the way, he's wearing a t-shirt that says, my mom thinks I'm cool.
[00:21:19.840 --> 00:21:23.240]   That was a popular shirt at Hot Topic in that era.
[00:21:23.240 --> 00:21:24.800]   You think Mark's a hot topic?
[00:21:24.800 --> 00:21:26.760]   I was like a British woman Hot Topic.
[00:21:26.760 --> 00:21:27.760]   No, no, no.
[00:21:27.760 --> 00:21:28.760]   All did.
[00:21:28.760 --> 00:21:30.080]   Women's shop at Hot Topic.
[00:21:30.080 --> 00:21:31.080]   Oh, no, no, no.
[00:21:31.080 --> 00:21:32.080]   Guys go to Hot Topic.
[00:21:32.080 --> 00:21:33.080]   Oh, yeah.
[00:21:33.080 --> 00:21:34.080]   I would always go went.
[00:21:34.080 --> 00:21:35.080]   I don't know if still go.
[00:21:35.080 --> 00:21:36.080]   This is still.
[00:21:36.080 --> 00:21:37.080]   Well, now it's like the brands store.
[00:21:37.080 --> 00:21:41.920]   I would go to Litch next door to get a cap while the girls shop at Hot Topic.
[00:21:41.920 --> 00:21:42.920]   Yeah.
[00:21:42.920 --> 00:21:43.920]   There were players.
[00:21:43.920 --> 00:21:44.920]   Sometimes, Claire's.
[00:21:44.920 --> 00:21:45.920]   Oh, boys.
[00:21:45.920 --> 00:21:46.920]   We need video surveillance.
[00:21:46.920 --> 00:21:47.920]   I have no idea.
[00:21:47.920 --> 00:21:48.920]   I didn't know.
[00:21:48.920 --> 00:21:49.920]   Hot Topic.
[00:21:49.920 --> 00:21:50.920]   Mall culture is a completely negative.
[00:21:50.920 --> 00:21:52.400]   I also worked at the mall for a long time.
[00:21:52.400 --> 00:21:54.480]   So you know, I got you a number of graphics.
[00:21:54.480 --> 00:21:57.560]   So Mark has 60% of voting control.
[00:21:57.560 --> 00:22:01.640]   That is unprecedented for any publicly held company.
[00:22:01.640 --> 00:22:04.080]   It is a lot of power.
[00:22:04.080 --> 00:22:07.760]   Hughes writes, "Mark alone can decide how to configure Facebook's algorithms to determine
[00:22:07.760 --> 00:22:11.800]   what people see and their feeds, what privacy settings they can use, even which messages
[00:22:11.800 --> 00:22:12.800]   can be delivered.
[00:22:12.800 --> 00:22:17.280]   He sets the rules for how to distinguish violent speech from the merely offensive.
[00:22:17.280 --> 00:22:22.600]   He can choose to shut down a competitor by acquiring it, copying it, or blocking it."
[00:22:22.600 --> 00:22:23.760]   This is the thing I found interesting.
[00:22:23.760 --> 00:22:25.680]   Mark is a good kind person.
[00:22:25.680 --> 00:22:26.680]   Yes.
[00:22:26.680 --> 00:22:31.000]   But I'm angry that his focus on growth led him to sacrifice security and civility for
[00:22:31.000 --> 00:22:32.560]   clicks.
[00:22:32.560 --> 00:22:35.960]   A lot of people took shots at Chris Hughes saying, "Well, now that you're a billionaire,
[00:22:35.960 --> 00:22:39.600]   thanks to Mark, it's easy enough to say, 'Well, we should stop.'"
[00:22:39.600 --> 00:22:40.600]   Yeah.
[00:22:40.600 --> 00:22:41.600]   You know.
[00:22:41.600 --> 00:22:45.960]   And people attacked him because they said he was going to run for public office or his
[00:22:45.960 --> 00:22:48.680]   husband was going to run for public office.
[00:22:48.680 --> 00:22:51.400]   And that's why he did this.
[00:22:51.400 --> 00:22:53.520]   It maybe would have come better from somebody else.
[00:22:53.520 --> 00:22:57.240]   On the other hand, there's nobody more intimately connected with Facebook.
[00:22:57.240 --> 00:23:00.960]   He did not do any coding, but he was kind of the Biz Dev guy.
[00:23:00.960 --> 00:23:06.680]   They call him the social guy, the guy who knew what people wanted and helped inform
[00:23:06.680 --> 00:23:11.920]   the programmers who didn't know what people wanted about how to do Facebook.
[00:23:11.920 --> 00:23:14.840]   This wasn't merely just an article on New York Times either.
[00:23:14.840 --> 00:23:16.960]   It was a full-on media blitz.
[00:23:16.960 --> 00:23:18.440]   He had appearances.
[00:23:18.440 --> 00:23:20.440]   It was all timed perfectly.
[00:23:20.440 --> 00:23:21.920]   Well, that is a little suspect.
[00:23:21.920 --> 00:23:24.240]   And that's what kind of perked my ears a little bit.
[00:23:24.240 --> 00:23:27.280]   I was like, "Okay, I understand completely where he's coming from.
[00:23:27.280 --> 00:23:32.400]   And I think this message coming from someone like Hughes carries a little bit more weight
[00:23:32.400 --> 00:23:34.280]   considering he was a co-founder.
[00:23:34.280 --> 00:23:38.080]   But man, he really wanted everyone to know that he was talking right now."
[00:23:38.080 --> 00:23:40.120]   And that's a little suspect.
[00:23:40.120 --> 00:23:41.120]   Yeah.
[00:23:41.120 --> 00:23:43.400]   But maybe there's a reason for that, right?
[00:23:43.400 --> 00:23:49.200]   If this is a message, if this is what needs to be heard by the most people, then maybe
[00:23:49.200 --> 00:23:52.960]   he is the right person to spread that news because it really did get a lot of attention.
[00:23:52.960 --> 00:23:57.440]   He says that Facebook, he agrees with Elizabeth Warren and others that Facebook should be
[00:23:57.440 --> 00:23:59.760]   broken up.
[00:23:59.760 --> 00:24:03.920]   But a lot of people pointed out, Facebook is, and Facebook pointed this out immediately,
[00:24:03.920 --> 00:24:04.920]   we're not a monopoly.
[00:24:04.920 --> 00:24:06.920]   There's plenty of competition.
[00:24:06.920 --> 00:24:07.920]   [laughter]
[00:24:07.920 --> 00:24:12.080]   Many trust law does not apply if you're not a monopoly.
[00:24:12.080 --> 00:24:16.760]   There's no legitimate legal basis for the government to break up a company just because
[00:24:16.760 --> 00:24:18.640]   it's big and powerful.
[00:24:18.640 --> 00:24:25.960]   It has to be a trust, right?
[00:24:25.960 --> 00:24:27.720]   Can't you make the argument that they're a monopoly?
[00:24:27.720 --> 00:24:32.400]   I mean, do you know how hard it is, the barrier to entry to get into the social networking
[00:24:32.400 --> 00:24:33.400]   space?
[00:24:33.400 --> 00:24:34.400]   Nobody's ever done it.
[00:24:34.400 --> 00:24:35.400]   But what business are they a monopoly of?
[00:24:35.400 --> 00:24:36.400]   Do they have a monopoly in--
[00:24:36.400 --> 00:24:40.280]   Well, you can't say AT&T a monopoly in telephones.
[00:24:40.280 --> 00:24:44.360]   I mean, you know, Standard Oil had a monopoly in gas.
[00:24:44.360 --> 00:24:46.320]   What is Facebook's monopoly in?
[00:24:46.320 --> 00:24:48.960]   Well, it's a new kind of business.
[00:24:48.960 --> 00:24:49.960]   That's the problem.
[00:24:49.960 --> 00:24:52.480]   We don't have any way to describe it.
[00:24:52.480 --> 00:24:53.960]   They own the public square.
[00:24:53.960 --> 00:24:54.960]   But do they have--
[00:24:54.960 --> 00:24:55.960]   But do they have--
[00:24:55.960 --> 00:24:58.880]   I mean, doesn't the New York Times have something to do with the public square and
[00:24:58.880 --> 00:25:01.160]   Twitter and this show?
[00:25:01.160 --> 00:25:04.880]   I mean, isn't the public square really a much broader concept than Facebook?
[00:25:04.880 --> 00:25:08.560]   The public square is definitely Facebook when you think about the global impact.
[00:25:08.560 --> 00:25:09.560]   They're not a monopoly.
[00:25:09.560 --> 00:25:10.560]   They're powerful.
[00:25:10.560 --> 00:25:11.560]   I would grant you their power.
[00:25:11.560 --> 00:25:12.560]   Yeah, yeah.
[00:25:12.560 --> 00:25:14.040]   But they're not the only voice in the public square.
[00:25:14.040 --> 00:25:15.240]   It's not like Google.
[00:25:15.240 --> 00:25:16.240]   I mean, just to--
[00:25:16.240 --> 00:25:17.240]   Again, what--
[00:25:17.240 --> 00:25:18.240]   As a comparison.
[00:25:18.240 --> 00:25:21.840]   What Chris Hughes is saying and what Elizabeth Warren is saying, we should break them up,
[00:25:21.840 --> 00:25:25.120]   not because they're a monopoly, but because they're too powerful.
[00:25:25.120 --> 00:25:26.920]   And I don't know if there's any precedent for that.
[00:25:26.920 --> 00:25:27.920]   You could also--
[00:25:27.920 --> 00:25:33.920]   I mean, you can also look at it as, well, Facebook's really an advertising business.
[00:25:33.920 --> 00:25:35.720]   That's where they make their money.
[00:25:35.720 --> 00:25:41.120]   And when you look at that part of it, Facebook and Google are interduopoly.
[00:25:41.120 --> 00:25:48.480]   And the reason they're interduopoly is because they own the data that's used to target ads.
[00:25:48.480 --> 00:25:52.440]   And in that sense, there's some monopoly power there.
[00:25:52.440 --> 00:25:56.160]   Yeah, but it's not a monopoly because Google--
[00:25:56.160 --> 00:25:59.080]   As you say, as a duopoly, Google is co-equal.
[00:25:59.080 --> 00:26:02.960]   Google and Facebook together share 80% of all digital revenue.
[00:26:02.960 --> 00:26:06.480]   But digital is not all the ad space either.
[00:26:06.480 --> 00:26:11.240]   There's plenty of billions and billions of dollars in other spaces.
[00:26:11.240 --> 00:26:17.680]   Even we do digital advertising, but I don't think we worry about Facebook and Google eating
[00:26:17.680 --> 00:26:20.800]   our share because we do a different kind of digital advertising.
[00:26:20.800 --> 00:26:26.920]   I guess I don't know how narrowly you define monopoly in this sense.
[00:26:26.920 --> 00:26:29.640]   And I'm sure Congress can decide to do whatever they want.
[00:26:29.640 --> 00:26:30.640]   I guess.
[00:26:30.640 --> 00:26:32.480]   I know, maybe not.
[00:26:32.480 --> 00:26:36.440]   You know, maybe the courts would say, well, you can vote to break up Facebook, but they're
[00:26:36.440 --> 00:26:38.440]   going to say, there's no--
[00:26:38.440 --> 00:26:39.440]   You can't just--
[00:26:39.440 --> 00:26:42.800]   I think the courts would step in and say, well, for what?
[00:26:42.800 --> 00:26:45.800]   And there's this issue of the public good, too.
[00:26:45.800 --> 00:26:50.240]   Are they harming the public good by being as big as they are?
[00:26:50.240 --> 00:26:54.840]   Well, one way to harm the public good would be to say, hey, if you get too successful,
[00:26:54.840 --> 00:26:57.280]   we're going to nip you in the bud.
[00:26:57.280 --> 00:26:58.480]   And we'll decide what that line is.
[00:26:58.480 --> 00:27:00.760]   That would be a harm to public good as well, right?
[00:27:00.760 --> 00:27:01.720]   I mean, that's what some say.
[00:27:01.720 --> 00:27:02.840]   They break them up.
[00:27:02.840 --> 00:27:05.520]   You're saying a message to entrepreneurs, well, don't be too successful.
[00:27:05.520 --> 00:27:07.120]   Don't get too big.
[00:27:07.120 --> 00:27:08.120]   Yeah.
[00:27:08.120 --> 00:27:09.640]   Maybe is that a message you want to send?
[00:27:09.640 --> 00:27:11.200]   I don't know.
[00:27:11.200 --> 00:27:15.520]   This is really an intractable problem, because as you point out, Mark doesn't know how to
[00:27:15.520 --> 00:27:17.080]   solve this problem.
[00:27:17.080 --> 00:27:18.720]   There's no structural problem.
[00:27:18.720 --> 00:27:22.920]   Mark and Geeks in general say, well, the technology will fix it.
[00:27:22.920 --> 00:27:25.120]   We'll get AI to fix it.
[00:27:25.120 --> 00:27:26.920]   And we know that's not going to work.
[00:27:26.920 --> 00:27:27.920]   Right.
[00:27:27.920 --> 00:27:28.920]   Yeah.
[00:27:28.920 --> 00:27:31.200]   Government's not going to fix it, because I don't think there's even agreement within
[00:27:31.200 --> 00:27:33.760]   government that they should be broken up.
[00:27:33.760 --> 00:27:36.240]   That's worried about other stuff right now.
[00:27:36.240 --> 00:27:41.120]   Well, and there are those who say Shoshana Zuboff among them, the author of Surveillance
[00:27:41.120 --> 00:27:45.520]   Capitalism, government won't do that because they're working together.
[00:27:45.520 --> 00:27:46.520]   They're in effect.
[00:27:46.520 --> 00:27:50.280]   Facebook provides government with information and needs to surveillance.
[00:27:50.280 --> 00:27:51.280]   Like RoboCop.
[00:27:51.280 --> 00:27:52.280]   Yeah.
[00:27:52.280 --> 00:27:53.280]   It's just like RoboCop.
[00:27:53.280 --> 00:27:59.960]   It's like the OCP or whatever it's called with their robots that they subsidize the
[00:27:59.960 --> 00:28:04.960]   tortoise way.
[00:28:04.960 --> 00:28:06.680]   You know a lot about a movie you've never seen.
[00:28:06.680 --> 00:28:12.120]   I read a lot about it last night.
[00:28:12.120 --> 00:28:13.520]   That's happened to me in college.
[00:28:13.520 --> 00:28:15.600]   Everything was just like whatever I read last night.
[00:28:15.600 --> 00:28:16.600]   It's just like that.
[00:28:16.600 --> 00:28:19.200]   It is just like RoboCop.
[00:28:19.200 --> 00:28:20.200]   Absolutely.
[00:28:20.200 --> 00:28:27.000]   No, I think that somebody said you sure perseverate on this subject, but it is the, I think it's
[00:28:27.000 --> 00:28:29.040]   the number one problem in technology today.
[00:28:29.040 --> 00:28:31.040]   What's the big thing right now?
[00:28:31.040 --> 00:28:42.040]   It's clear that these big companies, Google, Facebook, Amazon, are so dominant that they
[00:28:42.040 --> 00:28:48.120]   are potentially harming society, but we have no idea, A, what the effect is, what the effect
[00:28:48.120 --> 00:28:51.800]   of changing that would be if there even is a way to change that.
[00:28:51.800 --> 00:28:57.600]   It's almost as if we're set on a road at full speed and have no way of changing direction
[00:28:57.600 --> 00:28:58.920]   at this point, right?
[00:28:58.920 --> 00:28:59.920]   That's what it feels like to me Mark.
[00:28:59.920 --> 00:29:00.920]   Do you feel like that?
[00:29:00.920 --> 00:29:03.160]   Yeah, I think it's been a long time coming.
[00:29:03.160 --> 00:29:07.560]   I mean, we have chosen a way that we're going to pay for web services.
[00:29:07.560 --> 00:29:08.560]   We like free settings.
[00:29:08.560 --> 00:29:09.560]   Yeah, this is how it works.
[00:29:09.560 --> 00:29:12.280]   And we have been on this track for a long time.
[00:29:12.280 --> 00:29:17.200]   And I'm, you know, it's not always going to be like this.
[00:29:17.200 --> 00:29:20.160]   We're going to have different interfaces in the future.
[00:29:20.160 --> 00:29:21.440]   Computing is going to be different.
[00:29:21.440 --> 00:29:24.520]   We might all be an AR world, you know?
[00:29:24.520 --> 00:29:26.440]   And all the lens when it works.
[00:29:26.440 --> 00:29:27.440]   Right.
[00:29:27.440 --> 00:29:32.440]   If that does happen, somebody was reminding me the other day, we might really screw this
[00:29:32.440 --> 00:29:33.440]   up.
[00:29:33.440 --> 00:29:37.440]   I mean, it might be just ads everywhere in virtual space.
[00:29:37.440 --> 00:29:39.360]   That's what Philip K Dick's thought, right?
[00:29:39.360 --> 00:29:43.560]   He said then in a short story where every surface of your life was covered.
[00:29:43.560 --> 00:29:44.560]   Right.
[00:29:44.560 --> 00:29:45.560]   Yeah.
[00:29:45.560 --> 00:29:46.560]   I'd say.
[00:29:46.560 --> 00:29:47.560]   Yeah, we're pretty close to that already.
[00:29:47.560 --> 00:29:52.640]   So not to get too far out, but that's, yeah, it's a business model that I think has
[00:29:52.640 --> 00:29:55.160]   come into serious question right now.
[00:29:55.160 --> 00:30:01.040]   And I think people are looking for ways out, like paying people with Bitcoin for viewing
[00:30:01.040 --> 00:30:02.720]   ads and things like that.
[00:30:02.720 --> 00:30:08.480]   But once you give away, once you give away something, it's really hard to start charging
[00:30:08.480 --> 00:30:09.480]   for it.
[00:30:09.480 --> 00:30:10.480]   You just really, you can't.
[00:30:10.480 --> 00:30:11.480]   Yeah.
[00:30:11.480 --> 00:30:16.640]   Hugh says it is, there is a window of opportunity right now to force Facebook to give up Instagram
[00:30:16.640 --> 00:30:17.640]   and WhatsApp.
[00:30:17.640 --> 00:30:22.480]   He said, until recently they were independent, but time is of the essence because Facebook
[00:30:22.480 --> 00:30:25.280]   is working probably because of this to quickly integrate.
[00:30:25.280 --> 00:30:26.760]   I thought that was interesting.
[00:30:26.760 --> 00:30:29.400]   Make it harder for the FTC to split them up.
[00:30:29.400 --> 00:30:34.720]   It wouldn't be so hard to reverse the mergers that I think the FTC could perhaps do.
[00:30:34.720 --> 00:30:38.600]   But if Facebook gets to a point to where these services are all merged and grouped together
[00:30:38.600 --> 00:30:41.480]   on a deeper level, how do you then pick it apart?
[00:30:41.480 --> 00:30:44.800]   It feels to me like you're just chipping off a little bit of Facebook, which if you
[00:30:44.800 --> 00:30:49.080]   chip off WhatsApp and Instagram, Facebook just creates those kinds of services internally.
[00:30:49.080 --> 00:30:50.080]   It's not a huge deal.
[00:30:50.080 --> 00:30:51.080]   It loves to do.
[00:30:51.080 --> 00:30:52.080]   And it's not a huge deal.
[00:30:52.080 --> 00:30:56.120]   But the blue Facebook is still the problem.
[00:30:56.120 --> 00:30:57.120]   Yeah.
[00:30:57.120 --> 00:31:03.200]   That's what confuses me about all the Warrens thing about breaking up Facebook.
[00:31:03.200 --> 00:31:07.800]   The idea I hear all the time is breaking off WhatsApp and Instagram.
[00:31:07.800 --> 00:31:13.240]   But the core business, the big public social network is still there.
[00:31:13.240 --> 00:31:14.240]   Yeah.
[00:31:14.240 --> 00:31:20.720]   And Zuckerberg has even said that the future of the business is not the core app.
[00:31:20.720 --> 00:31:24.520]   It is the private communications, the private messaging.
[00:31:24.520 --> 00:31:25.520]   Maybe that's to...
[00:31:25.520 --> 00:31:28.320]   Just like Chris Hughes, I feel like that's a message of opportunity.
[00:31:28.320 --> 00:31:30.120]   It's like, "Well, I wouldn't say this now."
[00:31:30.120 --> 00:31:31.120]   Yeah.
[00:31:31.120 --> 00:31:32.120]   Yeah.
[00:31:32.120 --> 00:31:33.120]   I'd love to...
[00:31:33.120 --> 00:31:34.120]   Do you think there's reality there?
[00:31:34.120 --> 00:31:35.120]   I mean, do you think there's...
[00:31:35.120 --> 00:31:40.080]   Maybe there's data suggesting that people are migrating to private rooms?
[00:31:40.080 --> 00:31:43.920]   I don't know if there's reality there, but I think that's a pretty convenient thing given
[00:31:43.920 --> 00:31:45.960]   what we're talking about right here.
[00:31:45.960 --> 00:31:52.280]   If there is a time where suddenly WhatsApp and Instagram or whatever are broken off, I
[00:31:52.280 --> 00:31:56.680]   think the big blue app is probably doing a heck of a lot better than what Zuckerberg
[00:31:56.680 --> 00:31:57.680]   is saying there.
[00:31:57.680 --> 00:32:02.400]   And there's potential, like you said, Leo, to build these things in anyways.
[00:32:02.400 --> 00:32:08.280]   Ultimately, I think a lot of people are aware that something is wrong, that there is something...
[00:32:08.280 --> 00:32:09.840]   I think everybody's over there.
[00:32:09.840 --> 00:32:11.080]   Exactly.
[00:32:11.080 --> 00:32:17.640]   And so maybe there isn't a reason, a specific reason, an antitrust reason to go and investigate
[00:32:17.640 --> 00:32:22.200]   and to do something, but we all agree that something needs to happen.
[00:32:22.200 --> 00:32:26.400]   And so I don't know what the solution is, but that's a really frustrating place to be.
[00:32:26.400 --> 00:32:30.640]   And one more thing Hughes says, "Just breaking up Facebook is not enough.
[00:32:30.640 --> 00:32:31.640]   We need it.
[00:32:31.640 --> 00:32:32.640]   This one really scares me."
[00:32:32.640 --> 00:32:38.280]   A new government agency empowered by Congress to regulate tech companies.
[00:32:38.280 --> 00:32:40.280]   It's first mandate should be to protect privacy.
[00:32:40.280 --> 00:32:41.280]   That's fine.
[00:32:41.280 --> 00:32:42.280]   That's GDPR.
[00:32:42.280 --> 00:32:43.280]   I don't have a huge problem with that.
[00:32:43.280 --> 00:32:48.520]   He mentions GDPR and says, "We should have a similar privacy bill that would specify
[00:32:48.520 --> 00:32:52.960]   what control Americans have over their digital information."
[00:32:52.960 --> 00:32:54.040]   This is the one that bothers me.
[00:32:54.040 --> 00:32:58.520]   The agencies should create guidelines for acceptable speech on social media.
[00:32:58.520 --> 00:33:02.600]   Well, what did people say before they formed the FCC?
[00:33:02.600 --> 00:33:04.160]   How is this any different from that?
[00:33:04.160 --> 00:33:05.800]   That's an interesting point.
[00:33:05.800 --> 00:33:10.720]   I mean, the First Amendment says government should make no law to a bridge speech.
[00:33:10.720 --> 00:33:15.720]   The FCC was able to because it was a tit for tat to broadcasters.
[00:33:15.720 --> 00:33:21.240]   In order to use the public airwaves, we are going to require you to be licensed and to
[00:33:21.240 --> 00:33:22.760]   act in the public interest.
[00:33:22.760 --> 00:33:28.760]   So radio stations and then later TV stations had certain requirements, things like public
[00:33:28.760 --> 00:33:33.960]   service announcements, but also keeping the seven bad words off, things like that, that
[00:33:33.960 --> 00:33:38.840]   were because, it's like our responsibilities on the highway because you're using the public
[00:33:38.840 --> 00:33:42.720]   infrastructure, the frequencies, we're going to limit you.
[00:33:42.720 --> 00:33:47.800]   But it didn't mean that the FCC could then say to a podcaster, for instance, who's not
[00:33:47.800 --> 00:33:52.200]   using any spectrum, "Hey, you can't say the seven bad words," and they never asserted
[00:33:52.200 --> 00:33:53.360]   that they could.
[00:33:53.360 --> 00:33:59.520]   So I'm going to say that the FCC is doing something like a highway patrol would do,
[00:33:59.520 --> 00:34:05.880]   but that isn't offending the First Amendment because you still have the ability to speak
[00:34:05.880 --> 00:34:06.880]   out.
[00:34:06.880 --> 00:34:11.560]   You just can't do it on the public airwaves in any way you choose.
[00:34:11.560 --> 00:34:13.360]   That's an interesting question.
[00:34:13.360 --> 00:34:16.840]   An agency that should create guidelines for acceptable speech on social media, I guess
[00:34:16.840 --> 00:34:20.560]   you could say, "Well, social media is the public's air..."
[00:34:20.560 --> 00:34:21.560]   I don't know.
[00:34:21.560 --> 00:34:26.040]   I guess that's kind of the argument that I was trying to make.
[00:34:26.040 --> 00:34:27.200]   Is there a similarity there?
[00:34:27.200 --> 00:34:32.200]   Are we just talking about the telephone system or broadcasting?
[00:34:32.200 --> 00:34:37.320]   Well, notice the FCC does not restrict what you can say on the phone.
[00:34:37.320 --> 00:34:40.240]   And if they did, that would be the end of the world.
[00:34:40.240 --> 00:34:46.960]   Even though terrorists can use phone calls to plot, we've never gone there.
[00:34:46.960 --> 00:34:49.920]   And I don't think we should ever go there, even though you could make the case, "Well,
[00:34:49.920 --> 00:34:53.840]   we know that people are using the phones to do terrible, terrible things.
[00:34:53.840 --> 00:34:55.440]   We should have some restriction on that."
[00:34:55.440 --> 00:34:56.440]   But we've never gone there.
[00:34:56.440 --> 00:34:59.680]   And I think that that's because of the respect for the First Amendment.
[00:34:59.680 --> 00:35:04.480]   But what the phone doesn't have in common with the TV or with the Internet is that it's,
[00:35:04.480 --> 00:35:06.600]   in essence, a private conversation.
[00:35:06.600 --> 00:35:09.520]   Person to person versus a wide broadcast.
[00:35:09.520 --> 00:35:10.520]   And it's ephemeral.
[00:35:10.520 --> 00:35:11.520]   Yeah, right.
[00:35:11.520 --> 00:35:13.520]   And as far as we know, yes.
[00:35:13.520 --> 00:35:16.600]   It's a place out there, it's gone forever.
[00:35:16.600 --> 00:35:18.800]   But like yelling fire, there are a few examples in here.
[00:35:18.800 --> 00:35:23.440]   Yelling fire in a crowded theater, child pornography, speech intended to provoke violence, and false
[00:35:23.440 --> 00:35:26.040]   statements to manipulate stock prices.
[00:35:26.040 --> 00:35:27.040]   There are limits.
[00:35:27.040 --> 00:35:29.000]   Language around these things.
[00:35:29.000 --> 00:35:34.200]   Like, in my mind, it's pretty relatively easy to identify a language that would fall
[00:35:34.200 --> 00:35:35.200]   into those categories.
[00:35:35.200 --> 00:35:36.200]   Really, though?
[00:35:36.200 --> 00:35:37.200]   Do you think you could go on the face and see something?
[00:35:37.200 --> 00:35:38.200]   Oh, that should be...
[00:35:38.200 --> 00:35:39.200]   No.
[00:35:39.200 --> 00:35:40.200]   And who's going to do that?
[00:35:40.200 --> 00:35:41.200]   Oh, that's a...
[00:35:41.200 --> 00:35:42.200]   No, no, that post has to go.
[00:35:42.200 --> 00:35:43.200]   Oh, that post has to go.
[00:35:43.200 --> 00:35:44.200]   No, no, no.
[00:35:44.200 --> 00:35:48.320]   What I'm saying is, yelling fire in a crowded theater, that's a pretty easy thing to say,
[00:35:48.320 --> 00:35:49.320]   "Don't do that."
[00:35:49.320 --> 00:35:52.080]   And we have a really good reason why you don't do that.
[00:35:52.080 --> 00:35:53.080]   You cause panic.
[00:35:53.080 --> 00:35:55.880]   So if you're yelling fire in a crowded theater, I can hear that and I can know that that's
[00:35:55.880 --> 00:35:56.880]   wrong.
[00:35:56.880 --> 00:36:00.920]   Cracking down on any of this stuff in a social media perspective, like I just don't know
[00:36:00.920 --> 00:36:03.320]   how you do it for exactly the reason that you're talking about.
[00:36:03.320 --> 00:36:08.840]   That language is like, what are the rules and ramifications and where do you even draw
[00:36:08.840 --> 00:36:09.840]   those lines?
[00:36:09.840 --> 00:36:10.840]   I don't even know if it's...
[00:36:10.840 --> 00:36:11.840]   I don't want a government agency.
[00:36:11.840 --> 00:36:12.840]   I don't even know if it's possible.
[00:36:12.840 --> 00:36:13.840]   Well, that's not a disabled person.
[00:36:13.840 --> 00:36:14.840]   That's a person with disabilities.
[00:36:14.840 --> 00:36:17.240]   I don't want a government agency doing that.
[00:36:17.240 --> 00:36:18.240]   You say I certainly...
[00:36:18.240 --> 00:36:21.200]   Maybe that's what this whole, the word document thing.
[00:36:21.200 --> 00:36:24.040]   Maybe that's what it's created for.
[00:36:24.040 --> 00:36:26.640]   It's going to make sure we don't say the wrong thing.
[00:36:26.640 --> 00:36:27.640]   Here's my hope.
[00:36:27.640 --> 00:36:33.360]   And this is in my mind the only possible and correct solution, which is that we turn our
[00:36:33.360 --> 00:36:40.640]   back, ultimately turn our back on these things, that we as people start to realize the destructiveness
[00:36:40.640 --> 00:36:43.840]   of these social media networks and start participating.
[00:36:43.840 --> 00:36:45.360]   I mean, that's all it would take.
[00:36:45.360 --> 00:36:47.480]   I want to bring my mother into this.
[00:36:47.480 --> 00:36:48.880]   Does she use Facebook?
[00:36:48.880 --> 00:36:49.960]   She sure does.
[00:36:49.960 --> 00:36:56.280]   And last time I was home, I really tried to talk her out of using it.
[00:36:56.280 --> 00:36:59.280]   Her argument for staying on it is really simple.
[00:36:59.280 --> 00:37:00.840]   It's just like, "This is my way.
[00:37:00.840 --> 00:37:01.840]   I'm an older person.
[00:37:01.840 --> 00:37:03.440]   This is where my family is."
[00:37:03.440 --> 00:37:04.440]   Yeah.
[00:37:04.440 --> 00:37:06.680]   This is my way of staying connected to this world.
[00:37:06.680 --> 00:37:07.680]   This is where the people are.
[00:37:07.680 --> 00:37:08.840]   This is where the people are.
[00:37:08.840 --> 00:37:10.800]   It's like, "What do I say to that?"
[00:37:10.800 --> 00:37:11.800]   I don't think it's the...
[00:37:11.800 --> 00:37:12.800]   How do you replace that?
[00:37:12.800 --> 00:37:14.160]   The tech that is in this...
[00:37:14.160 --> 00:37:16.960]   I mean, I think the tech has definitely contributed to the problem.
[00:37:16.960 --> 00:37:21.720]   I think Mark Zuckerberg was a young person who had a big idea and did not think about
[00:37:21.720 --> 00:37:24.360]   the social ramifications of what he was going to do.
[00:37:24.360 --> 00:37:27.800]   Any person who took an international relations class in college would have known the kind
[00:37:27.800 --> 00:37:34.920]   of gates that would have been open by connecting the world together, but not Mark.
[00:37:34.920 --> 00:37:39.640]   We've had all these problems in the world since humanity has been on Earth.
[00:37:39.640 --> 00:37:40.640]   We suck.
[00:37:40.640 --> 00:37:41.640]   We do.
[00:37:41.640 --> 00:37:42.640]   Humanity is terrible.
[00:37:42.640 --> 00:37:43.640]   We're awful to each other.
[00:37:43.640 --> 00:37:44.640]   And these are the users.
[00:37:44.640 --> 00:37:47.040]   The emotional networks just let us see that suckage.
[00:37:47.040 --> 00:37:48.040]   Yes.
[00:37:48.040 --> 00:37:49.040]   Absolutely.
[00:37:49.040 --> 00:37:50.040]   Absolutely.
[00:37:50.040 --> 00:37:51.040]   Let's all the people who suck.
[00:37:51.040 --> 00:37:52.040]   Connect with the other people who suck.
[00:37:52.040 --> 00:37:53.040]   I think your mother sucks.
[00:37:53.040 --> 00:37:54.040]   She's a very fun person.
[00:37:54.040 --> 00:37:59.440]   No, but she is using the tool that was given to her to be able to connect with people.
[00:37:59.440 --> 00:38:00.440]   We don't connect that way.
[00:38:00.440 --> 00:38:03.440]   But notice that people under 25 don't use Facebook, right?
[00:38:03.440 --> 00:38:04.440]   No, but they use TikTok.
[00:38:04.440 --> 00:38:05.440]   They use Instagram.
[00:38:05.440 --> 00:38:06.940]   They have Finstas.
[00:38:06.940 --> 00:38:10.040]   They have very different ways of communicating with each other.
[00:38:10.040 --> 00:38:12.240]   And that's going to evolve as they get older.
[00:38:12.240 --> 00:38:14.840]   And then they're going to have kids and that's going to be something new.
[00:38:14.840 --> 00:38:16.520]   But that'll end up breaking up the monopoly, right?
[00:38:16.520 --> 00:38:17.520]   Because they'll be the next thing in the next.
[00:38:17.520 --> 00:38:18.520]   Exactly.
[00:38:18.520 --> 00:38:23.760]   It'll be a new, we need to think about this is a societal humanity problem.
[00:38:23.760 --> 00:38:25.160]   Mark is not going to fix this.
[00:38:25.160 --> 00:38:26.160]   That's what I think.
[00:38:26.160 --> 00:38:31.200]   And also like America needs something against hate speech once and for all because of Germany
[00:38:31.200 --> 00:38:35.800]   has it where that you cannot talk about Germany has it.
[00:38:35.800 --> 00:38:39.160]   I don't understand why the United States doesn't.
[00:38:39.160 --> 00:38:41.680]   Because you can't, because it's very hard to define it.
[00:38:41.680 --> 00:38:45.160]   It's easier in Germany because you say, well, the hate speech is Nazis.
[00:38:45.160 --> 00:38:46.160]   Right.
[00:38:46.160 --> 00:38:47.160]   Because we have this history.
[00:38:47.160 --> 00:38:48.160]   Right.
[00:38:48.160 --> 00:38:49.160]   We are very ashamed of.
[00:38:49.160 --> 00:38:50.160]   Right.
[00:38:50.160 --> 00:38:52.160]   But America has a history too of colonization.
[00:38:52.160 --> 00:38:53.160]   Yeah, but we don't.
[00:38:53.160 --> 00:38:54.160]   We're not ashamed.
[00:38:54.160 --> 00:38:55.160]   We're not ashamed about it.
[00:38:55.160 --> 00:38:56.160]   We're proud of it.
[00:38:56.160 --> 00:38:57.160]   That's a unfortunate part of it.
[00:38:57.160 --> 00:38:58.160]   That's a hilly.
[00:38:58.160 --> 00:39:00.000]   He was a great general.
[00:39:00.000 --> 00:39:01.000]   Yeah.
[00:39:01.000 --> 00:39:02.000]   Christopher Columbus.
[00:39:02.000 --> 00:39:03.000]   Yeah.
[00:39:03.000 --> 00:39:05.840]   You know, I thought I was shocked to see the states are now having indigenous peoples
[00:39:05.840 --> 00:39:06.840]   day instead of Columbus day.
[00:39:06.840 --> 00:39:08.320]   I thought that would never happen.
[00:39:08.320 --> 00:39:09.320]   They should.
[00:39:09.320 --> 00:39:11.120]   Well, I'm not sure I disagree with it, but I just.
[00:39:11.120 --> 00:39:13.480]   I give the land back, but that's a, that's another show.
[00:39:13.480 --> 00:39:14.480]   We don't have to get it.
[00:39:14.480 --> 00:39:15.480]   I just surprised.
[00:39:15.480 --> 00:39:18.400]   I thought maybe we are making progress.
[00:39:18.400 --> 00:39:22.400]   Bit by bit, we have to because what also we're going to do on this earth.
[00:39:22.400 --> 00:39:25.040]   Sorry, that was very, I'm a very existential person.
[00:39:25.040 --> 00:39:26.040]   Are you an optimist?
[00:39:26.040 --> 00:39:27.040]   Are you an optimist?
[00:39:27.040 --> 00:39:30.880]   No, I'm a tourist.
[00:39:30.880 --> 00:39:34.000]   We should do something other than sucking all the time.
[00:39:34.000 --> 00:39:35.000]   I mean, we should find an alternative.
[00:39:35.000 --> 00:39:36.000]   We should find an alternative.
[00:39:36.000 --> 00:39:37.000]   We know how to do it.
[00:39:37.000 --> 00:39:38.000]   We could blow one.
[00:39:38.000 --> 00:39:40.880]   So, you know, and social media plays in this way too.
[00:39:40.880 --> 00:39:43.720]   Social media has brought together so many people and so many ideas.
[00:39:43.720 --> 00:39:48.160]   And it's, I think social media has contributed to why our conversation has become more progressive
[00:39:48.160 --> 00:39:52.520]   over the years because we do have people coming out and saying, Hey, I am a person
[00:39:52.520 --> 00:39:53.520]   with disabilities.
[00:39:53.520 --> 00:39:55.160]   This is how I would like to be.
[00:39:55.160 --> 00:39:58.880]   This is how you should refer to me because when you refer to me otherwise it insults
[00:39:58.880 --> 00:39:59.880]   me.
[00:39:59.880 --> 00:40:03.200]   I think these conversations we were not having because people were not listening and now
[00:40:03.200 --> 00:40:06.160]   it's like social media, that's it.
[00:40:06.160 --> 00:40:07.160]   Everybody and.
[00:40:07.160 --> 00:40:08.160]   But that's a good point.
[00:40:08.160 --> 00:40:09.160]   Is there is a value to that?
[00:40:09.160 --> 00:40:10.160]   Yeah, exactly.
[00:40:10.160 --> 00:40:11.160]   It is being.
[00:40:11.160 --> 00:40:12.160]   Yeah.
[00:40:12.160 --> 00:40:13.760]   And people, our eyes are being opened.
[00:40:13.760 --> 00:40:15.640]   They are being woke.
[00:40:15.640 --> 00:40:16.640]   So there's good things to.
[00:40:16.640 --> 00:40:17.640]   A woken.
[00:40:17.640 --> 00:40:18.640]   A woken.
[00:40:18.640 --> 00:40:19.640]   Woked.
[00:40:19.640 --> 00:40:20.640]   Woked.
[00:40:20.640 --> 00:40:21.640]   Woked.
[00:40:21.640 --> 00:40:22.640]   Not yoked.
[00:40:22.640 --> 00:40:24.400]   I mean, I used to be yoked too.
[00:40:24.400 --> 00:40:26.200]   You know, we had this.
[00:40:26.200 --> 00:40:27.200]   You like your kids?
[00:40:27.200 --> 00:40:28.200]   Well, it's good.
[00:40:28.200 --> 00:40:32.240]   Do you know how it is for me to put the luggage up in the overhead?
[00:40:32.240 --> 00:40:33.240]   Oh, interesting.
[00:40:33.240 --> 00:40:34.240]   Yeah.
[00:40:34.240 --> 00:40:37.840]   Well, next time I see you trying to do that, I'll help because Leo is yoked.
[00:40:37.840 --> 00:40:38.840]   I'm yoked.
[00:40:38.840 --> 00:40:41.520]   I'm yoked at the hip.
[00:40:41.520 --> 00:40:44.680]   It's an endless conversation, which we see.
[00:40:44.680 --> 00:40:45.680]   It is.
[00:40:45.680 --> 00:40:48.840]   We have a lot on our shows, but I just, this, again, it's come up one more time and then
[00:40:48.840 --> 00:40:50.720]   Chris Hughes piece really, I thought.
[00:40:50.720 --> 00:40:51.720]   Yeah.
[00:40:51.720 --> 00:40:53.440]   Brought it to the forefront, but I don't know.
[00:40:53.440 --> 00:40:54.440]   I don't know.
[00:40:54.440 --> 00:40:57.040]   There's no answer and it's just very difficult.
[00:40:57.040 --> 00:40:58.040]   Very difficult.
[00:40:58.040 --> 00:40:59.040]   I want to soapbox the New York Times.
[00:40:59.040 --> 00:41:00.760]   Facebook is going to get a big fine.
[00:41:00.760 --> 00:41:02.320]   They said three to five billion.
[00:41:02.320 --> 00:41:06.680]   I think now the Vegas odds are five billion dollars.
[00:41:06.680 --> 00:41:08.200]   Yeah, that's Google EU money.
[00:41:08.200 --> 00:41:09.200]   That's fine.
[00:41:09.200 --> 00:41:10.200]   They'll find a way to pay it.
[00:41:10.200 --> 00:41:13.600]   Well, that's what some legislators are saying that that's a bargain.
[00:41:13.600 --> 00:41:14.800]   A slap on the wrist.
[00:41:14.800 --> 00:41:15.800]   Exactly.
[00:41:15.800 --> 00:41:16.800]   It's a bargain.
[00:41:16.800 --> 00:41:23.960]   Richard Blumenthal and Josh Hawley are trying to pressure the FTC to increase the fight
[00:41:23.960 --> 00:41:30.480]   and more importantly, to hold Mark Zuckerberg personally responsible.
[00:41:30.480 --> 00:41:33.680]   Billions of dollars would be a bargain for companies, largest Facebook, say, Blumenthal
[00:41:33.680 --> 00:41:34.680]   and Hawley.
[00:41:34.680 --> 00:41:38.360]   By the way, Blumenthal, the Democrat, Hawley, the Republican from Missouri.
[00:41:38.360 --> 00:41:42.360]   The tech giant says it could be five billion.
[00:41:42.360 --> 00:41:45.720]   Lawmakers said even if finding the billions is simply a write down for the company.
[00:41:45.720 --> 00:41:46.720]   That's right.
[00:41:46.720 --> 00:41:47.720]   Just helps them find no taxes.
[00:41:47.720 --> 00:41:48.720]   Exactly.
[00:41:48.720 --> 00:41:50.880]   It's like Steve Jobs and I were harking in a right parking spot because he could just
[00:41:50.880 --> 00:41:51.880]   pay the ticket.
[00:41:51.880 --> 00:41:52.880]   Right.
[00:41:52.880 --> 00:41:54.840]   I think they already took the write down too.
[00:41:54.840 --> 00:41:56.760]   They did last three billion they took.
[00:41:56.760 --> 00:41:57.760]   Yeah.
[00:41:57.760 --> 00:41:58.760]   Yeah.
[00:41:58.760 --> 00:42:03.480]   Large penalties have done little to deter large tech firms.
[00:42:03.480 --> 00:42:06.640]   But what they want the FTC to do is limit data collection.
[00:42:06.640 --> 00:42:08.520]   I think that's actually not an unreasonable thing.
[00:42:08.520 --> 00:42:09.520]   I agree.
[00:42:09.520 --> 00:42:10.520]   Like, yeah.
[00:42:10.520 --> 00:42:13.240]   They want accountability targeting individual executives.
[00:42:13.240 --> 00:42:19.320]   In other words, Zuckerberg or Sandberg would be personally liable if any Facebook executive
[00:42:19.320 --> 00:42:25.680]   knowingly broke the law or its pledge to improve privacy practices which they told the FTC
[00:42:25.680 --> 00:42:27.720]   they would do eight years ago.
[00:42:27.720 --> 00:42:28.720]   Can you believe that?
[00:42:28.720 --> 00:42:30.720]   That was 2011.
[00:42:30.720 --> 00:42:31.720]   Hmm.
[00:42:31.720 --> 00:42:32.720]   I don't know.
[00:42:32.720 --> 00:42:40.240]   That consent degree was about just being transparent about what data they were collecting and they
[00:42:40.240 --> 00:42:41.240]   just didn't do it.
[00:42:41.240 --> 00:42:42.240]   They never did it.
[00:42:42.240 --> 00:42:43.240]   Yeah.
[00:42:43.240 --> 00:42:49.840]   But at least Facebook gives us plenty of controls to manage our data.
[00:42:49.840 --> 00:42:50.840]   Deactivate.
[00:42:50.840 --> 00:42:52.280]   Or I should do not say our data.
[00:42:52.280 --> 00:42:53.520]   I'm no longer on Facebook.
[00:42:53.520 --> 00:42:54.520]   So are you one?
[00:42:54.520 --> 00:42:55.520]   No.
[00:42:55.520 --> 00:42:56.520]   And you aren't.
[00:42:56.520 --> 00:42:57.520]   And I'm not.
[00:42:57.520 --> 00:43:00.240]   But I am on Instagram and speaking to a reporter.
[00:43:00.240 --> 00:43:01.240]   You are.
[00:43:01.240 --> 00:43:03.240]   You are yourself from this conversation.
[00:43:03.240 --> 00:43:05.840]   Well, we have private groups now and what's up?
[00:43:05.840 --> 00:43:07.640]   That's how we stay in touch with family.
[00:43:07.640 --> 00:43:09.920]   You realize it's still Facebook, right?
[00:43:09.920 --> 00:43:10.920]   Yes.
[00:43:10.920 --> 00:43:12.440]   But it's a little less noisy.
[00:43:12.440 --> 00:43:15.720]   I don't like I don't care about my own political opinions.
[00:43:15.720 --> 00:43:17.280]   Like I don't want to hear it.
[00:43:17.280 --> 00:43:18.280]   That's really honestly.
[00:43:18.280 --> 00:43:19.280]   That's really, honestly.
[00:43:19.280 --> 00:43:20.280]   Okay.
[00:43:20.280 --> 00:43:21.280]   Happier.
[00:43:21.280 --> 00:43:22.280]   It may not be enough.
[00:43:22.280 --> 00:43:26.400]   But I honestly think that people are getting wised up even your mom mark and ultimately will
[00:43:26.400 --> 00:43:29.720]   do what is better for them and which is ultimately better for society.
[00:43:29.720 --> 00:43:32.560]   And I just don't think that this is going to be a problem.
[00:43:32.560 --> 00:43:34.160]   Ten years from now, we're not going to be sitting here.
[00:43:34.160 --> 00:43:35.160]   It'll be in different problems.
[00:43:35.160 --> 00:43:36.160]   What do we do here?
[00:43:36.160 --> 00:43:37.160]   It'll be TikTok users.
[00:43:37.160 --> 00:43:38.160]   What do we do about TikTok?
[00:43:38.160 --> 00:43:42.120]   You know TikTok could even be around two years from now.
[00:43:42.120 --> 00:43:43.440]   TikTok, the next Facebook.
[00:43:43.440 --> 00:43:44.440]   I'm telling you, Leo.
[00:43:44.440 --> 00:43:45.440]   You're the next music player.
[00:43:45.440 --> 00:43:47.920]   I mean, it's just a lot of work to make a good TikTok.
[00:43:47.920 --> 00:43:51.920]   If we've learned something in the past however many years, we've learned that social media
[00:43:51.920 --> 00:43:55.640]   companies are really good at redefining themselves as they go down the line and going,
[00:43:55.640 --> 00:43:56.640]   "Hey, well, you know?"
[00:43:56.640 --> 00:43:57.640]   Snapchat, especially.
[00:43:57.640 --> 00:43:58.640]   Yeah.
[00:43:58.640 --> 00:44:00.640]   I'm failing compared to Instagram, right?
[00:44:00.640 --> 00:44:02.040]   Well, they came out with a new filter.
[00:44:02.040 --> 00:44:03.640]   I got everybody using it this weekend.
[00:44:03.640 --> 00:44:04.640]   What was the filter?
[00:44:04.640 --> 00:44:05.640]   It's a filter.
[00:44:05.640 --> 00:44:06.640]   No, unfortunately.
[00:44:06.640 --> 00:44:07.640]   I should have.
[00:44:07.640 --> 00:44:09.640]   No, but I did use the Pikachu AR on the Pixel.
[00:44:09.640 --> 00:44:11.120]   That's just really fun.
[00:44:11.120 --> 00:44:16.640]   No, it was a filter that shows you how you would look like the man or whoop.
[00:44:16.640 --> 00:44:18.320]   Oh, people were doing that to me.
[00:44:18.320 --> 00:44:20.240]   Yes, like super.
[00:44:20.240 --> 00:44:25.520]   Here's a guy who used the new Snapchat filter on Tinder and gets 1,650 likes and hundreds
[00:44:25.520 --> 00:44:26.520]   of matches.
[00:44:26.520 --> 00:44:27.520]   On Tinder?
[00:44:27.520 --> 00:44:28.520]   I didn't think going that far.
[00:44:28.520 --> 00:44:33.960]   There's the incredible Snapchat Tinder matchup we've been waiting for.
[00:44:33.960 --> 00:44:37.040]   So Jess is apparently a guy, but that's the filter.
[00:44:37.040 --> 00:44:38.200]   Oh, yeah, wow.
[00:44:38.200 --> 00:44:40.560]   Jess is really a guy.
[00:44:40.560 --> 00:44:43.720]   Jess is Manley, and this is the filter.
[00:44:43.720 --> 00:44:45.720]   I looked great as a man for his work.
[00:44:45.720 --> 00:44:46.720]   I looked very bulky.
[00:44:46.720 --> 00:44:48.720]   I looked very Romanian.
[00:44:48.720 --> 00:44:49.720]   I had a goatee.
[00:44:49.720 --> 00:44:52.320]   It was like a big eyebrows.
[00:44:52.320 --> 00:44:53.320]   Wow.
[00:44:53.320 --> 00:44:54.320]   Yeah.
[00:44:54.320 --> 00:44:55.320]   And I was like, "You know what?
[00:44:55.320 --> 00:44:56.320]   I could see that."
[00:44:56.320 --> 00:44:57.320]   I could.
[00:44:57.320 --> 00:44:58.320]   I'd make-- yeah.
[00:44:58.320 --> 00:45:04.280]   My husband's had a look at the kind of guy who just, you know, just goes through chicks.
[00:45:04.280 --> 00:45:05.280]   Did it make him not?
[00:45:05.280 --> 00:45:06.280]   For the good excitement.
[00:45:06.280 --> 00:45:07.280]   Yeah.
[00:45:07.280 --> 00:45:08.280]   Yeah.
[00:45:08.280 --> 00:45:09.280]   He looked great as a woman.
[00:45:09.280 --> 00:45:10.280]   But see Snapchat?
[00:45:10.280 --> 00:45:11.280]   That's the only--
[00:45:11.280 --> 00:45:12.280]   That's all they gotta go for themselves.
[00:45:12.280 --> 00:45:13.280]   Honestly, though.
[00:45:13.280 --> 00:45:19.360]   So everybody's gonna talk about it for three minutes and then back to Instagram.
[00:45:19.360 --> 00:45:20.360]   That's the world we live in.
[00:45:20.360 --> 00:45:21.360]   I know.
[00:45:21.360 --> 00:45:22.360]   That's why I'm not actually just--
[00:45:22.360 --> 00:45:23.360]   That's why you keep it installed.
[00:45:23.360 --> 00:45:24.360]   I think people just move on.
[00:45:24.360 --> 00:45:26.960]   Keep Snapchat installed and in your folder and when you need it.
[00:45:26.960 --> 00:45:32.240]   So I'm sitting, I'm watching Microsoft's thing and it was-- oh, you know, it's fine.
[00:45:32.240 --> 00:45:34.400]   If you're an enterprise person, it's great.
[00:45:34.400 --> 00:45:36.720]   But I'm thinking to myself, wait till tomorrow.
[00:45:36.720 --> 00:45:37.720]   Wait till Google I/O.
[00:45:37.720 --> 00:45:38.720]   Yeah.
[00:45:38.720 --> 00:45:41.920]   Because that's when Google's gonna show how to market to consumers.
[00:45:41.920 --> 00:45:43.960]   We're gonna just take a break and we'll talk about that.
[00:45:43.960 --> 00:45:45.560]   'Cause both of you were there.
[00:45:45.560 --> 00:45:46.560]   Oh, yes.
[00:45:46.560 --> 00:45:48.640]   In fact, you had a great show there.
[00:45:48.640 --> 00:45:49.640]   Yeah.
[00:45:49.640 --> 00:45:50.640]   Yeah, absolutely.
[00:45:50.640 --> 00:45:51.640]   All that I know.
[00:45:51.640 --> 00:45:52.640]   You had the woman who was showing--
[00:45:52.640 --> 00:45:53.640]   Steph Cuthbert's step.
[00:45:53.640 --> 00:45:58.120]   From the main keynote and Chet Haas from the developer keynote.
[00:45:58.120 --> 00:45:59.120]   Cool.
[00:45:59.120 --> 00:46:00.120]   Yeah, it was a great interview.
[00:46:00.120 --> 00:46:01.120]   Yeah.
[00:46:01.120 --> 00:46:02.120]   Yeah.
[00:46:02.120 --> 00:46:03.120]   And you can hear that on the "All About Android" feed.
[00:46:03.120 --> 00:46:04.120]   That's this week's episode of "All About Android."
[00:46:04.120 --> 00:46:05.120]   Twitter.tv/AA.
[00:46:05.120 --> 00:46:06.120]   Yeah.
[00:46:06.120 --> 00:46:08.960]   And I moderated a panel with Hiroshi Lockheimer.
[00:46:08.960 --> 00:46:09.960]   That's right.
[00:46:09.960 --> 00:46:10.960]   The head of Android.
[00:46:10.960 --> 00:46:11.960]   No big deal.
[00:46:11.960 --> 00:46:12.960]   No big deal.
[00:46:12.960 --> 00:46:13.960]   MBD.
[00:46:13.960 --> 00:46:14.960]   And how did that go?
[00:46:14.960 --> 00:46:15.960]   What do you think?
[00:46:15.960 --> 00:46:18.000]   I thought it was excellent.
[00:46:18.000 --> 00:46:20.360]   You even got a nugget about Fuchsia.
[00:46:20.360 --> 00:46:21.360]   I did.
[00:46:21.360 --> 00:46:23.600]   Oh, 'cause they didn't say-- they didn't say the F word.
[00:46:23.600 --> 00:46:25.200]   At all during the keynote.
[00:46:25.200 --> 00:46:26.200]   No.
[00:46:26.200 --> 00:46:27.200]   But Flo asked about it.
[00:46:27.200 --> 00:46:28.200]   I'm glad.
[00:46:28.200 --> 00:46:29.200]   I asked about Chrome's favorite color.
[00:46:29.200 --> 00:46:30.200]   Oh, standby.
[00:46:30.200 --> 00:46:31.200]   Standby.
[00:46:31.200 --> 00:46:33.200]   And by the way, it's closed.
[00:46:33.200 --> 00:46:34.200]   That's cool.
[00:46:34.200 --> 00:46:36.720]   Flo-- I know why I called you "Clo."
[00:46:36.720 --> 00:46:37.720]   Clover milk?
[00:46:37.720 --> 00:46:38.720]   'Cause we have clo--
[00:46:38.720 --> 00:46:41.120]   I don't know what the cow up here, the milk mascot.
[00:46:41.120 --> 00:46:42.120]   It's true.
[00:46:42.120 --> 00:46:44.880]   But Flo has a purple, or is that a Fuchsia?
[00:46:44.880 --> 00:46:45.880]   It's purple.
[00:46:45.880 --> 00:46:46.880]   It's purple.
[00:46:46.880 --> 00:46:47.880]   It's kind of Fuchsia-like.
[00:46:47.880 --> 00:46:48.880]   It could be.
[00:46:48.880 --> 00:46:49.880]   What's the difference with Fuchsia and purple?
[00:46:49.880 --> 00:46:50.880]   Fuchsia is more pinky.
[00:46:50.880 --> 00:46:53.120]   Purple is more like royal.
[00:46:53.120 --> 00:46:54.120]   And so she has a--
[00:46:54.120 --> 00:46:55.120]   Oh, that's Fuchsia.
[00:46:55.120 --> 00:46:57.120]   Things got a little fuchsia.
[00:46:57.120 --> 00:46:58.120]   Fuchsia-ish.
[00:46:58.120 --> 00:46:59.120]   Fuchsia lights.
[00:46:59.120 --> 00:47:00.120]   It's a little light.
[00:47:00.120 --> 00:47:01.120]   It's worth it.
[00:47:01.120 --> 00:47:02.120]   It's a little bit covered.
[00:47:02.120 --> 00:47:06.120]   She's got a Fuchsia-ish silicone straw for her kombucha.
[00:47:06.120 --> 00:47:07.120]   Yeah.
[00:47:07.120 --> 00:47:08.120]   Which is also fuchsia.
[00:47:08.120 --> 00:47:12.240]   It ain't nothing until you get her purple-ish 3A.
[00:47:12.240 --> 00:47:13.680]   We're gonna take a look at that too.
[00:47:13.680 --> 00:47:15.320]   Coming up in just a little bit.
[00:47:15.320 --> 00:47:16.320]   It's great to have you guys.
[00:47:16.320 --> 00:47:20.120]   The hosts of all about Android, Florence Ion and Jason Howell.
[00:47:20.120 --> 00:47:21.120]   Yeah, good to be here.
[00:47:21.120 --> 00:47:22.120]   Thank you.
[00:47:22.120 --> 00:47:25.360]   From Fast Company, Mark Sullivan, senior writer there.
[00:47:25.360 --> 00:47:27.000]   The Sullivan on Twitter.
[00:47:27.000 --> 00:47:28.000]   Yeah.
[00:47:28.000 --> 00:47:29.000]   It's good Ed's not here.
[00:47:29.000 --> 00:47:30.000]   Not even my mom.
[00:47:30.000 --> 00:47:31.000]   It's not even your mom.
[00:47:31.000 --> 00:47:33.000]   That's the same good thing Ed's not here.
[00:47:33.000 --> 00:47:35.800]   I showed you they brought to you by Wordpress.
[00:47:35.800 --> 00:47:37.680]   Actually, that's my blog host.
[00:47:37.680 --> 00:47:38.680]   I love Wordpress.
[00:47:38.680 --> 00:47:39.680]   I've been using--
[00:47:39.680 --> 00:47:40.680]   Of course it is.
[00:47:40.680 --> 00:47:41.680]   Everybody.
[00:47:41.680 --> 00:47:44.120]   33% of the internet is running on Wordpress.
[00:47:44.120 --> 00:47:48.680]   I remember when Matt Mullingway came out with Wordpress early days of blogging early 2000s.
[00:47:48.680 --> 00:47:52.040]   I'd been using, you know, blogger and stuff and I found Wordpress as a business.
[00:47:52.040 --> 00:47:53.440]   I'm here.
[00:47:53.440 --> 00:47:57.640]   I hosted it, self hosted at the time, but then Wordpress.com came along.
[00:47:57.640 --> 00:48:00.960]   I just got my 12 year chip from Wordpress.
[00:48:00.960 --> 00:48:02.360]   That's how long I've been on Wordpress.com.
[00:48:02.360 --> 00:48:04.920]   And I love it because they do all the hard stuff.
[00:48:04.920 --> 00:48:06.040]   They keep it secure.
[00:48:06.040 --> 00:48:07.040]   They keep it up to date.
[00:48:07.040 --> 00:48:12.280]   They have thousands of themes, all the powerful tools of Wordpress.
[00:48:12.280 --> 00:48:17.560]   And even better, they've got 24/7 support from actual Wordpress experts.
[00:48:17.560 --> 00:48:20.840]   People who use the platform every day and know it.
[00:48:20.840 --> 00:48:21.880]   That's the best kind of support.
[00:48:21.880 --> 00:48:24.160]   Wordpress.com is from Wordpress enthusiasts.
[00:48:24.160 --> 00:48:28.880]   Wordpress.com lets anyone pursue whatever it is they love by launching a site that's
[00:48:28.880 --> 00:48:31.800]   free to start and room to grow.
[00:48:31.800 --> 00:48:33.720]   I'm not talking two week trials.
[00:48:33.720 --> 00:48:34.720]   Nope.
[00:48:34.720 --> 00:48:35.800]   No hidden fees.
[00:48:35.800 --> 00:48:40.680]   And most importantly, the reason you want to have a website, you own your own content
[00:48:40.680 --> 00:48:41.980]   forever.
[00:48:41.980 --> 00:48:43.800]   It's not Mark Zuckerberg's.
[00:48:43.800 --> 00:48:45.480]   It's not Jack Dorsey's.
[00:48:45.480 --> 00:48:46.840]   It's yours.
[00:48:46.840 --> 00:48:52.160]   It's a pictures, video, music, text, whatever you want on your Wordpress page.
[00:48:52.160 --> 00:48:53.360]   You can upload it anytime.
[00:48:53.360 --> 00:48:54.920]   You can download it anytime.
[00:48:54.920 --> 00:48:57.080]   It is always there for you.
[00:48:57.080 --> 00:49:00.200]   Everybody needs a place on the internet that they say, "This is where I am.
[00:49:00.200 --> 00:49:01.200]   This is where I live."
[00:49:01.200 --> 00:49:04.440]   And it's not on Facebook, it's not on Twitter, it's on your own website.
[00:49:04.440 --> 00:49:08.080]   I tell this especially to teenagers who are just getting started in the world.
[00:49:08.080 --> 00:49:12.040]   Make that website, put your best stuff up there so that when people Google you, they
[00:49:12.040 --> 00:49:13.720]   find you.
[00:49:13.720 --> 00:49:16.040]   You control your image.
[00:49:16.040 --> 00:49:18.720]   Wordpress.com is the easiest place to do it.
[00:49:18.720 --> 00:49:21.360]   And as I said, great 24-hour support.
[00:49:21.360 --> 00:49:22.880]   A very flexible platform.
[00:49:22.880 --> 00:49:24.360]   So powerful, so flexible.
[00:49:24.360 --> 00:49:28.360]   A lot of big publications use Wordpress.
[00:49:28.360 --> 00:49:30.920]   Fortune.com is based on Wordpress.com on their VIP platform.
[00:49:30.920 --> 00:49:33.120]   So is Quartz.
[00:49:33.120 --> 00:49:37.240]   Millions of people use Wordpress.com every day to turn their dreams into reality.
[00:49:37.240 --> 00:49:39.200]   LeoLaport.com, that's a Wordpress site.
[00:49:39.200 --> 00:49:41.200]   What's your site, Florence?
[00:49:41.200 --> 00:49:42.760]   FlorenceLion.com.
[00:49:42.760 --> 00:49:44.600]   Clever name.
[00:49:44.600 --> 00:49:46.000]   Good idea.
[00:49:46.000 --> 00:49:47.000]   Wordpress.com/twit.
[00:49:47.000 --> 00:49:51.480]   If you go there right now, you'll get 15% off any new plan purchase.
[00:49:51.480 --> 00:49:53.920]   And you'll show them you heard it here, which we appreciate.
[00:49:53.920 --> 00:49:55.920]   Wordpress.com/twit.
[00:49:55.920 --> 00:49:57.240]   15% off.
[00:49:57.240 --> 00:50:01.160]   Thank you, Wordpress, for all that you do.
[00:50:01.160 --> 00:50:02.960]   We love Wordpress.
[00:50:02.960 --> 00:50:03.960]   Wordpress.com/twit.
[00:50:03.960 --> 00:50:10.720]   All right, let's go from Redmond.
[00:50:10.720 --> 00:50:12.880]   Let's head down the coast a bit.
[00:50:12.880 --> 00:50:15.360]   Beautiful ocean view of the Pacific highway.
[00:50:15.360 --> 00:50:16.920]   We get down to San Francisco.
[00:50:16.920 --> 00:50:19.200]   We keep going a little farther down Silicon Valley.
[00:50:19.200 --> 00:50:23.400]   We see the big blimp hangers of Moffat Field.
[00:50:23.400 --> 00:50:29.320]   And there it is, Shoreline Amphitheater, next door to the Google plex in Mountain View.
[00:50:29.320 --> 00:50:30.520]   And it's Google I/O time.
[00:50:30.520 --> 00:50:35.520]   Yeah, and by the way, next to around there, if you're there this year, you couldn't help
[00:50:35.520 --> 00:50:41.720]   but notice the new structure that Google is putting up is gigantic.
[00:50:41.720 --> 00:50:42.720]   It's like a garden, right?
[00:50:42.720 --> 00:50:43.720]   Yeah.
[00:50:43.720 --> 00:50:51.200]   It looks like a, just I don't know, acres huge, like circus tent made of metal.
[00:50:51.200 --> 00:50:52.200]   Yeah, exactly.
[00:50:52.200 --> 00:50:56.080]   It looks like the roof of an outdoor venue.
[00:50:56.080 --> 00:50:57.480]   Wow, and it's huge.
[00:50:57.480 --> 00:50:59.480]   It's really something.
[00:50:59.480 --> 00:51:04.720]   And I have a feeling that's why they stopped traffic from coming around there this year.
[00:51:04.720 --> 00:51:06.720]   They were saying, "Don't drive, weren't they?"
[00:51:06.720 --> 00:51:08.320]   They didn't want people to drive.
[00:51:08.320 --> 00:51:10.360]   They discouraged people from driving.
[00:51:10.360 --> 00:51:16.040]   We had to take a ride share and it was one of the ways that most people were getting
[00:51:16.040 --> 00:51:17.040]   in.
[00:51:17.040 --> 00:51:18.040]   This is out of date.
[00:51:18.040 --> 00:51:19.040]   This is back in November.
[00:51:19.040 --> 00:51:20.600]   So they must have been a little farther along.
[00:51:20.600 --> 00:51:24.080]   But the idea is it's going to be almost like a garden campus under a dome.
[00:51:24.080 --> 00:51:26.080]   Yeah, it's pretty.
[00:51:26.080 --> 00:51:27.080]   I mean, it's massive.
[00:51:27.080 --> 00:51:28.800]   It'll have its own climate.
[00:51:28.800 --> 00:51:29.800]   It's no apple spaceship.
[00:51:29.800 --> 00:51:30.800]   Its own presence.
[00:51:30.800 --> 00:51:33.040]   But it's pretty big.
[00:51:33.040 --> 00:51:34.040]   Walking by that.
[00:51:34.040 --> 00:51:35.040]   Wow.
[00:51:35.040 --> 00:51:36.040]   So will it be like the headquarters?
[00:51:36.040 --> 00:51:37.040]   Is it going to replace whatever?
[00:51:37.040 --> 00:51:42.400]   I'm not entirely sure exactly what's going on inside, to be honest.
[00:51:42.400 --> 00:51:45.240]   I feel like this is just Google going, "Oh, Apple's doing something big."
[00:51:45.240 --> 00:51:50.400]   Well, they don't have a big standing HQ.
[00:51:50.400 --> 00:51:52.800]   It's just like, "Here's a bunch of buildings we own."
[00:51:52.800 --> 00:51:53.800]   It's probably a campus.
[00:51:53.800 --> 00:51:54.800]   We're all across.
[00:51:54.800 --> 00:51:56.720]   And also we share it with these other people because I noticed.
[00:51:56.720 --> 00:52:00.520]   But that was always the, you know, it's like getting the cover of Sports Illustrated.
[00:52:00.520 --> 00:52:01.520]   It was always the line.
[00:52:01.520 --> 00:52:05.440]   There's the minute you build that giant new corporate headquarters.
[00:52:05.440 --> 00:52:07.000]   That's the peak.
[00:52:07.000 --> 00:52:10.240]   That's when you're at the top and now it's all downhill from here, right?
[00:52:10.240 --> 00:52:12.320]   I don't know if that's the case.
[00:52:12.320 --> 00:52:13.320]   Google did.
[00:52:13.320 --> 00:52:15.080]   I mean, their quarterly results were down a little bit, right?
[00:52:15.080 --> 00:52:16.520]   They didn't grow as fast.
[00:52:16.520 --> 00:52:18.320]   They only grow 16%.
[00:52:18.320 --> 00:52:19.920]   Oh, oh, please.
[00:52:19.920 --> 00:52:21.160]   Pft, pft.
[00:52:21.160 --> 00:52:22.640]   You call that growth.
[00:52:22.640 --> 00:52:25.400]   I'll show you a growth.
[00:52:25.400 --> 00:52:29.360]   Yes, you got a growth right here.
[00:52:29.360 --> 00:52:32.640]   So I thought they did a good job.
[00:52:32.640 --> 00:52:34.680]   The ending was a little weird.
[00:52:34.680 --> 00:52:36.000]   The ending of what, the keynote?
[00:52:36.000 --> 00:52:38.080]   Because soon to every pitch I never came back.
[00:52:38.080 --> 00:52:39.080]   No.
[00:52:39.080 --> 00:52:40.080]   He was like, I'm done.
[00:52:40.080 --> 00:52:41.080]   See ya.
[00:52:41.080 --> 00:52:42.080]   Yeah, he did the beginning.
[00:52:42.080 --> 00:52:43.800]   He's like, I got work today.
[00:52:43.800 --> 00:52:45.960]   And they had a nice momentum leading up to it.
[00:52:45.960 --> 00:52:49.000]   I mean, they showed some, I thought really cool stuff.
[00:52:49.000 --> 00:52:51.360]   They showed how Google's lens was.
[00:52:51.360 --> 00:52:54.000]   I mean, they had been showing Google lens for seems like for years.
[00:52:54.000 --> 00:52:55.000]   Yeah.
[00:52:55.000 --> 00:52:57.360]   But it's getting better and better now can read menus, translate menus.
[00:52:57.360 --> 00:53:03.400]   They had a really moving video of an Indian woman who was illiterate, but could use Google
[00:53:03.400 --> 00:53:05.760]   lens, the camera and her phone to read things for.
[00:53:05.760 --> 00:53:07.640]   She said, I don't have to ask anybody to read for me anymore.
[00:53:07.640 --> 00:53:08.640]   Yeah, that was.
[00:53:08.640 --> 00:53:09.640]   I could take the train.
[00:53:09.640 --> 00:53:12.040]   I could do stuff.
[00:53:12.040 --> 00:53:13.440]   It could translate foreign languages.
[00:53:13.440 --> 00:53:17.800]   It could read things out loud, which she needed.
[00:53:17.800 --> 00:53:20.440]   It can calculate the tip or even split the film.
[00:53:20.440 --> 00:53:24.720]   It can translate the sign into your language and then read that out loud to you.
[00:53:24.720 --> 00:53:25.720]   So what's new there?
[00:53:25.720 --> 00:53:26.720]   Reading it out loud?
[00:53:26.720 --> 00:53:29.120]   Because it's always been a, I mean, I've used lens.
[00:53:29.120 --> 00:53:30.280]   No, it's just like goggles.
[00:53:30.280 --> 00:53:32.400]   It's just like Google goggles before that.
[00:53:32.400 --> 00:53:33.400]   Yeah, I know.
[00:53:33.400 --> 00:53:34.480]   Translated this already.
[00:53:34.480 --> 00:53:37.240]   It's just now it's inside the camera app.
[00:53:37.240 --> 00:53:43.320]   So you just pop in there and you can use these AR, essentially abilities.
[00:53:43.320 --> 00:53:46.360]   I liked the, oh, and they shrunk it down.
[00:53:46.360 --> 00:53:47.960]   They shrunk it down all that.
[00:53:47.960 --> 00:53:48.960]   That was interesting.
[00:53:48.960 --> 00:53:50.200]   So real like technological feeds.
[00:53:50.200 --> 00:53:54.440]   They talked about machine learning the database from the machine learning being hundreds of
[00:53:54.440 --> 00:53:57.440]   gigabytes, which they could then shrink down a half a gigabyte.
[00:53:57.440 --> 00:53:58.440]   Kilobytes.
[00:53:58.440 --> 00:53:59.440]   Kilobytes.
[00:53:59.440 --> 00:54:00.440]   Get it on your phone.
[00:54:00.440 --> 00:54:01.440]   Kilobytes even.
[00:54:01.440 --> 00:54:02.440]   Yeah.
[00:54:02.440 --> 00:54:04.080]   Nice.
[00:54:04.080 --> 00:54:05.080]   That's pretty huge.
[00:54:05.080 --> 00:54:06.080]   Yeah.
[00:54:06.080 --> 00:54:08.720]   Did they at any point talk about how they didn't in the keynote, but maybe later talk about
[00:54:08.720 --> 00:54:09.720]   how?
[00:54:09.720 --> 00:54:11.520]   Talk about how they were shrinking those data sets.
[00:54:11.520 --> 00:54:12.960]   No, not, not necessarily.
[00:54:12.960 --> 00:54:16.920]   They just said they were able to compress with a lot of work down to a point to where
[00:54:16.920 --> 00:54:22.200]   they can move these onto phones and not just with the, you know, like language translation,
[00:54:22.200 --> 00:54:28.200]   but also they showed off an incredible demo, I thought, of assistant working entirely on
[00:54:28.200 --> 00:54:29.200]   device.
[00:54:29.200 --> 00:54:33.480]   That was the demo where the woman had the phone and she just rattled off command after command
[00:54:33.480 --> 00:54:36.000]   after command, like with no pause whatsoever.
[00:54:36.000 --> 00:54:40.200]   And I mean, she was able to do basically Bixby like controls over her phone because assistant
[00:54:40.200 --> 00:54:41.200]   has a dozen.
[00:54:41.200 --> 00:54:44.520]   And it's 10 times faster thanks to this shrinkage.
[00:54:44.520 --> 00:54:50.480]   And I think that that's what's going to be a big selling point of the Pixel 4.
[00:54:50.480 --> 00:54:55.520]   I think the Pixel 4 is going to hinge a lot on having the space and the computational
[00:54:55.520 --> 00:55:02.280]   power to manage a lot more in the ways of the machine learning tasks that they're showing
[00:55:02.280 --> 00:55:03.280]   off there.
[00:55:03.280 --> 00:55:06.560]   He's taking a page from Apple's playbook of, because Apple's always said we can do everything
[00:55:06.560 --> 00:55:08.720]   on the phone.
[00:55:08.720 --> 00:55:15.880]   It kind of is when I used to talk to Google people about this, they would always talk
[00:55:15.880 --> 00:55:19.240]   about, you know, the speed of the experience.
[00:55:19.240 --> 00:55:21.480]   If it ran on the device, it would be faster.
[00:55:21.480 --> 00:55:24.840]   But they are just to go out to the net, get the response, come back.
[00:55:24.840 --> 00:55:28.240]   But now they're definitely talking about the privacy aspect.
[00:55:28.240 --> 00:55:29.240]   Absolutely.
[00:55:29.240 --> 00:55:32.960]   It's not just because the speed is because this is your stuff on your phone and we have
[00:55:32.960 --> 00:55:33.960]   nothing to do with it.
[00:55:33.960 --> 00:55:39.320]   They even made points about anonomize that you could build the knowledge base.
[00:55:39.320 --> 00:55:44.840]   You could do more training, but you could do it in an anonymized fashion.
[00:55:44.840 --> 00:55:50.840]   But on the other hand, I think Google was particularly unapologetic at this event about,
[00:55:50.840 --> 00:55:55.400]   hey, we can do more because we know more about you.
[00:55:55.400 --> 00:56:00.200]   They almost took the opposite tack to Apple saying, yeah, you know, privacy is fine.
[00:56:00.200 --> 00:56:03.520]   But if you really want us to know what your favorite meal is, you're going to have to
[00:56:03.520 --> 00:56:04.520]   give us some information.
[00:56:04.520 --> 00:56:10.240]   Yeah, I think even at one point they mentioned, I had to check the quote exactly to see what
[00:56:10.240 --> 00:56:11.240]   they were saying.
[00:56:11.240 --> 00:56:15.000]   But my takeaway from it was, you know, we've been collecting your data for 20 years.
[00:56:15.000 --> 00:56:16.960]   Of course we could do great things with it.
[00:56:16.960 --> 00:56:18.920]   You know what I mean?
[00:56:18.920 --> 00:56:21.440]   We know everything there is to know about you.
[00:56:21.440 --> 00:56:27.560]   Which, you know, obviously if you're very privacy minded and living in, I don't know,
[00:56:27.560 --> 00:56:31.880]   2019, that kind of perspective is going to give you pause.
[00:56:31.880 --> 00:56:36.960]   But then at the same time as consumers, we ask a lot of our technology and have for a
[00:56:36.960 --> 00:56:37.960]   very long time.
[00:56:37.960 --> 00:56:40.600]   And some of this stuff requires access to that data.
[00:56:40.600 --> 00:56:44.400]   And I think Google going into this was just kind of saying, yes, okay, we've got a lot
[00:56:44.400 --> 00:56:46.840]   of your data, but look at all the wonderful things we can do with it.
[00:56:46.840 --> 00:56:52.960]   I think that's actually a smart tech because Apple series is just not very good.
[00:56:52.960 --> 00:56:56.800]   And whether that's Apple's fault for some other reason or just that they don't know
[00:56:56.800 --> 00:56:59.720]   much about you, the fact is the fact, right?
[00:56:59.720 --> 00:57:04.440]   So why not say, hey, look, you can choose not to give us any information.
[00:57:04.440 --> 00:57:09.100]   And by the way, and Pichai said, this is a quote from the talk, privacy cannot be a
[00:57:09.100 --> 00:57:14.040]   luxury good offered only to people who can afford to buy premium products and services.
[00:57:14.040 --> 00:57:16.040]   Privacy must be equally available to everyone in the world.
[00:57:16.040 --> 00:57:20.760]   They double down on that, but at the same time, I think it's a reasonable thing for them to
[00:57:20.760 --> 00:57:23.640]   say, look, we do know a lot about you.
[00:57:23.640 --> 00:57:28.640]   Sorry, we're going to give you the tools to delete it, which they have to with dashboard.
[00:57:28.640 --> 00:57:34.960]   We're going to, they change the setting in search that lets you delete information instead
[00:57:34.960 --> 00:57:36.680]   of keeping it forever.
[00:57:36.680 --> 00:57:41.840]   You can delete it after three months or what was the other year, 18 months or yeah, or
[00:57:41.840 --> 00:57:42.840]   keep it forever.
[00:57:42.840 --> 00:57:43.840]   Right.
[00:57:43.840 --> 00:57:48.880]   It's not the most grammar switch ever, but at least you can say to Google, okay, keep
[00:57:48.880 --> 00:57:50.000]   my data for three months.
[00:57:50.000 --> 00:57:53.720]   We need the data, but you only will get it for 90 days.
[00:57:53.720 --> 00:57:58.320]   So I think that that's a good thing to say, look, we'll give you control, but honestly,
[00:57:58.320 --> 00:58:01.960]   if you want us to do all this cool stuff we can do, you got to tell us some stuff.
[00:58:01.960 --> 00:58:03.120]   We got to see your schedule.
[00:58:03.120 --> 00:58:07.000]   Yeah, I think there, I was kind of impressed with that.
[00:58:07.000 --> 00:58:08.000]   That's the right thing.
[00:58:08.000 --> 00:58:09.000]   Approach.
[00:58:09.000 --> 00:58:10.000]   I mean, you have a choice.
[00:58:10.000 --> 00:58:12.160]   He was just very frank about it.
[00:58:12.160 --> 00:58:18.520]   And you know, I like this idea of, and this is kind of what you said, about personal data
[00:58:18.520 --> 00:58:24.200]   being a transactional thing between human being and big tech company.
[00:58:24.200 --> 00:58:30.120]   If I get more in return than I have given, and if they are honest with me about what they're
[00:58:30.120 --> 00:58:35.200]   taking and what they're giving me, then I'm kind of okay with that.
[00:58:35.200 --> 00:58:39.120]   And I'm not like, Facebook did the opposite.
[00:58:39.120 --> 00:58:40.120]   Exactly.
[00:58:40.120 --> 00:58:41.960]   And that's why I'm, that's why I quit Facebook.
[00:58:41.960 --> 00:58:42.960]   Yeah.
[00:58:42.960 --> 00:58:43.960]   It's mealymouth.
[00:58:43.960 --> 00:58:46.560]   Zuckerberg says, well, you're going to be private.
[00:58:46.560 --> 00:58:49.120]   But we still need all that information so we can make money.
[00:58:49.120 --> 00:58:50.120]   Yeah.
[00:58:50.120 --> 00:58:51.120]   Go go sing, look.
[00:58:51.120 --> 00:58:54.440]   Now, now notice there was no mention of advertising at all.
[00:58:54.440 --> 00:58:59.920]   I mean, honestly, that's their, that's their, that's their, yeah, that's what they get.
[00:58:59.920 --> 00:59:02.480]   I mean, yeah, we'll give you all this stuff, but we're going to take the big, which is
[00:59:02.480 --> 00:59:07.400]   all the advertising dollars that information lets us generate.
[00:59:07.400 --> 00:59:10.120]   I think he was asked about it.
[00:59:10.120 --> 00:59:15.280]   I don't remember where I read this, but he, he responded by saying, you know, it's only
[00:59:15.280 --> 00:59:20.320]   a small bit of the data that we collect that's even used for advertising.
[00:59:20.320 --> 00:59:25.280]   Most of the data we collect is for customizing services and personalizing services.
[00:59:25.280 --> 00:59:27.080]   See, that's mealymouth.
[00:59:27.080 --> 00:59:30.920]   I mean, even if it's true, he should just say, yeah.
[00:59:30.920 --> 00:59:31.920]   Yeah.
[00:59:31.920 --> 00:59:32.920]   Yeah.
[00:59:32.920 --> 00:59:34.000]   It's for teaching the machine.
[00:59:34.000 --> 00:59:38.200]   We think you want ads that reflect your interests.
[00:59:38.200 --> 00:59:39.360]   We do that.
[00:59:39.360 --> 00:59:41.680]   We give you switches to turn it off if you don't like it.
[00:59:41.680 --> 00:59:42.680]   Okay.
[00:59:42.680 --> 00:59:46.560]   But honestly, we can't do our job without getting all that information.
[00:59:46.560 --> 00:59:49.760]   I would love to see Google say, hey, if you don't like it, go to Apple.
[00:59:49.760 --> 00:59:50.760]   Honestly.
[00:59:50.760 --> 00:59:53.560]   I mean, they're right across the freeway.
[00:59:53.560 --> 00:59:54.680]   Consumers do have the choice, right?
[00:59:54.680 --> 00:59:56.600]   I mean, that choice is couldn't be more stark.
[00:59:56.600 --> 01:00:00.840]   Really, the question mark is Microsoft, which is not known for privacy, but it's starting
[01:00:00.840 --> 01:00:03.240]   to say, well, we want to be the privacy company too.
[01:00:03.240 --> 01:00:05.760]   It looks good for Apple, might be good for us.
[01:00:05.760 --> 01:00:08.640]   I think Google and Facebook might as well just say, look, you have a choice.
[01:00:08.640 --> 01:00:13.720]   You can go with Microsoft Apple or you can go with Google Facebook and you tell us which
[01:00:13.720 --> 01:00:14.720]   experience is better.
[01:00:14.720 --> 01:00:17.440]   Are you willing to pay that price?
[01:00:17.440 --> 01:00:18.760]   I think most people don't.
[01:00:18.760 --> 01:00:21.760]   I think what does your mom is she aware of that?
[01:00:21.760 --> 01:00:23.360]   Yeah, I think she is.
[01:00:23.360 --> 01:00:28.720]   I think she's one of these people that is asking, how exactly am I being hurt by this?
[01:00:28.720 --> 01:00:29.720]   Exactly.
[01:00:29.720 --> 01:00:31.160]   I think a lot of people would wonder that.
[01:00:31.160 --> 01:00:32.960]   And I think she's already made the calculus.
[01:00:32.960 --> 01:00:36.360]   If not explicitly, she's saying, no, look, my family and friends are on Facebook.
[01:00:36.360 --> 01:00:37.480]   I know she's not stupid.
[01:00:37.480 --> 01:00:42.640]   I know they collect information about me, but it's worth it because look what I'm getting.
[01:00:42.640 --> 01:00:44.160]   I think Google could do the same thing.
[01:00:44.160 --> 01:00:46.080]   Maybe that's foolish.
[01:00:46.080 --> 01:00:47.080]   Maybe you can't.
[01:00:47.080 --> 01:00:50.360]   I always wish people were honest in advertising.
[01:00:50.360 --> 01:00:54.360]   Google at Google I/O kind of went in both directions.
[01:00:54.360 --> 01:00:59.640]   Like on one hand, they were stressing the fact that, hey, look at all these cool things
[01:00:59.640 --> 01:01:01.880]   we can do with access to your data.
[01:01:01.880 --> 01:01:09.040]   On the other hand, they did lead the keynote, at least as far as the Android part was concerned,
[01:01:09.040 --> 01:01:14.720]   with a heavy emphasis on the fact that Android Q has privacy and security as one of its main
[01:01:14.720 --> 01:01:15.720]   focuses.
[01:01:15.720 --> 01:01:17.280]   So you think they can do that fairly?
[01:01:17.280 --> 01:01:19.880]   They can actually protect privacy and still do their--
[01:01:19.880 --> 01:01:20.880]   No, I don't.
[01:01:20.880 --> 01:01:22.880]   I don't think they can do that fairly.
[01:01:22.880 --> 01:01:27.080]   But I think that it's beneficial to them to be able to point out both sides because
[01:01:27.080 --> 01:01:33.800]   if you sit on one camp, you feel fine about the fact that your data is being used is basically
[01:01:33.800 --> 01:01:36.000]   your currency for all the wonderful things Google does.
[01:01:36.000 --> 01:01:41.440]   If you sit on the other camp, on the other side of the camp, then-- which camp are we
[01:01:41.440 --> 01:01:42.960]   at by the way?
[01:01:42.960 --> 01:01:44.760]   Then you've got controls within Android.
[01:01:44.760 --> 01:01:50.200]   It just is one example that are improving in Q to where you can button down on location
[01:01:50.200 --> 01:01:53.480]   sharing so that it's only running when you're inside of an app.
[01:01:53.480 --> 01:02:00.280]   They've moved privacy to its own front line item in the settings pane.
[01:02:00.280 --> 01:02:01.280]   So it's right there.
[01:02:01.280 --> 01:02:03.600]   When you go in there, there's ad controls immediately.
[01:02:03.600 --> 01:02:07.640]   They're making it a little more visible for you to know that, oh, hey, I can go in there
[01:02:07.640 --> 01:02:09.800]   and actually make some corrections here.
[01:02:09.800 --> 01:02:11.480]   And they know most people don't care.
[01:02:11.480 --> 01:02:13.840]   Most people probably are not going to even go in there and make a change.
[01:02:13.840 --> 01:02:18.640]   Which is a bummer because then you run the risk of having it not be totally user friendly
[01:02:18.640 --> 01:02:20.920]   and then people go, you know that was there.
[01:02:20.920 --> 01:02:22.720]   Yeah, well, they need to make it easy.
[01:02:22.720 --> 01:02:23.720]   But I think they can trust it.
[01:02:23.720 --> 01:02:24.720]   Most people just go, forget it.
[01:02:24.720 --> 01:02:25.720]   It's easy.
[01:02:25.720 --> 01:02:26.720]   It's easy.
[01:02:26.720 --> 01:02:27.720]   You have to go dig in there.
[01:02:27.720 --> 01:02:28.720]   But make it easy.
[01:02:28.720 --> 01:02:29.720]   Go all the way.
[01:02:29.720 --> 01:02:31.280]   Make it as easy as possible.
[01:02:31.280 --> 01:02:32.280]   People still not do it.
[01:02:32.280 --> 01:02:33.280]   They're not going to do it.
[01:02:33.280 --> 01:02:34.280]   That's true.
[01:02:34.280 --> 01:02:38.640]   But Google's still going to get the good pat on the back of like, okay, well, you're
[01:02:38.640 --> 01:02:39.640]   giving the options.
[01:02:39.640 --> 01:02:40.640]   Right.
[01:02:40.640 --> 01:02:41.640]   Give me options.
[01:02:41.640 --> 01:02:43.640]   Facebook also gives options, but they--
[01:02:43.640 --> 01:02:44.640]   They bury it.
[01:02:44.640 --> 01:02:45.640]   They bury it.
[01:02:45.640 --> 01:02:46.640]   And they make it--
[01:02:46.640 --> 01:02:47.640]   They change it every day.
[01:02:47.640 --> 01:02:48.640]   They're connected web and it's just very confusing.
[01:02:48.640 --> 01:02:52.600]   I feel like Google does a better job of that.
[01:02:52.600 --> 01:02:53.600]   Not perfect, but better.
[01:02:53.600 --> 01:02:57.920]   They, in a way, Pichai restated the mission statement of Google, which used to be.
[01:02:57.920 --> 01:02:59.320]   And he did put this up on the screen.
[01:02:59.320 --> 01:03:02.280]   Our mission is to organize the world's information.
[01:03:02.280 --> 01:03:04.760]   This is from Ben Thompson's "Stretecory" article.
[01:03:04.760 --> 01:03:08.040]   Organize the world's information and make it universally accessible and useful.
[01:03:08.040 --> 01:03:12.940]   But really, the new mission statement, I think, is, and much shorter, much sweeter, building
[01:03:12.940 --> 01:03:14.680]   a more helpful Google for everyone.
[01:03:14.680 --> 01:03:15.680]   Yeah.
[01:03:15.680 --> 01:03:17.320]   You want to be helpful.
[01:03:17.320 --> 01:03:20.320]   And Pichai says, when we say helpful, we mean giving you the tools to increase your
[01:03:20.320 --> 01:03:23.880]   knowledge, success, health, and happiness.
[01:03:23.880 --> 01:03:25.800]   And we're going to make a little money in advertising.
[01:03:25.800 --> 01:03:26.800]   Yeah.
[01:03:26.800 --> 01:03:27.800]   The deal.
[01:03:27.800 --> 01:03:30.160]   And yes, in order for it to be helpful, we do need access to your data.
[01:03:30.160 --> 01:03:36.440]   Because if it's going to be helpful to you, person, your data is going to inform what
[01:03:36.440 --> 01:03:38.080]   makes it specifically helpful for you.
[01:03:38.080 --> 01:03:43.200]   Ben Thompson uses the term he made up called strategy credit, which I really like.
[01:03:43.200 --> 01:03:44.200]   I like that too.
[01:03:44.200 --> 01:03:46.440]   Which is, it's a side effect.
[01:03:46.440 --> 01:03:49.800]   It's not, we're doing stuff.
[01:03:49.800 --> 01:03:54.840]   And as a side effect, we're going to make billions of dollars in advertising.
[01:03:54.840 --> 01:03:58.480]   It's a strategy credit.
[01:03:58.480 --> 01:03:59.960]   It's not a bad thing.
[01:03:59.960 --> 01:04:03.440]   Thompson writes, it's simply an observation that doing the right thing requires no trade
[01:04:03.440 --> 01:04:07.120]   offs when it comes to the company's core business model.
[01:04:07.120 --> 01:04:08.600]   Exactly.
[01:04:08.600 --> 01:04:09.600]   And I think that--
[01:04:09.600 --> 01:04:15.160]   And this is the idea that Apple can talk about privacy so loudly because there's no
[01:04:15.160 --> 01:04:16.160]   cost.
[01:04:16.160 --> 01:04:17.160]   Right.
[01:04:17.160 --> 01:04:19.000]   It doesn't hurt them to do that.
[01:04:19.000 --> 01:04:24.560]   Wall Street's not going to punish them for doing that.
[01:04:24.560 --> 01:04:27.920]   Google on the other hand, and I read this a couple of times because I wanted to understand
[01:04:27.920 --> 01:04:28.920]   what he was saying.
[01:04:28.920 --> 01:04:29.920]   Ben's tough.
[01:04:29.920 --> 01:04:30.920]   He's good.
[01:04:30.920 --> 01:04:31.920]   He's so good.
[01:04:31.920 --> 01:04:36.040]   But I think what he's saying is that it's just kind of built into Google's business model
[01:04:36.040 --> 01:04:41.120]   that they're going to try to reach as many people anywhere in the world as they possibly
[01:04:41.120 --> 01:04:44.240]   can regardless of their income.
[01:04:44.240 --> 01:04:46.520]   And that's just going to happen anyway.
[01:04:46.520 --> 01:04:53.120]   So why not go ahead and say-- or hit back at Tim Cook and say, your devices are meant
[01:04:53.120 --> 01:04:54.120]   for rich people?
[01:04:54.120 --> 01:04:56.880]   They said that, didn't they?
[01:04:56.880 --> 01:04:57.880]   Yeah.
[01:04:57.880 --> 01:05:02.120]   Our stuff is meant for everybody, and we're going to deliver privacy there too.
[01:05:02.120 --> 01:05:05.080]   And they showed a poor woman in India who's illiterate.
[01:05:05.080 --> 01:05:07.800]   They showed Demetri who I think is a Google engineer.
[01:05:07.800 --> 01:05:10.040]   He might as well work for Google.
[01:05:10.040 --> 01:05:13.120]   He's the guy with the Russian action and the speech impediment.
[01:05:13.120 --> 01:05:17.120]   And they showed him training the assistant that I could barely understand and the assistant
[01:05:17.120 --> 01:05:19.600]   could understand him easily.
[01:05:19.600 --> 01:05:24.720]   What they kind of mentioned was that it took 15,000 voice samples from Demetri.
[01:05:24.720 --> 01:05:29.280]   That's why I think he probably works at Google so that he could understand him.
[01:05:29.280 --> 01:05:30.280]   But I think that that's part--
[01:05:30.280 --> 01:05:31.280]   Euphonia.
[01:05:31.280 --> 01:05:32.280]   That was Project Euphonia.
[01:05:32.280 --> 01:05:34.520]   In fact, they even said we're looking for more people.
[01:05:34.520 --> 01:05:39.240]   So if you have a friend or a relative or-- you know, the assistant doesn't understand
[01:05:39.240 --> 01:05:41.880]   very well, g.co/ufonia.
[01:05:41.880 --> 01:05:47.160]   We want you to help us so we can make better speech recognition.
[01:05:47.160 --> 01:05:50.720]   Yeah, I think you've got to praise them for all of this.
[01:05:50.720 --> 01:05:51.720]   That's the only thing.
[01:05:51.720 --> 01:05:55.680]   I honestly don't think they're cynical about promoting this.
[01:05:55.680 --> 01:05:59.280]   I think they sincerely do want to be more helpful.
[01:05:59.280 --> 01:06:02.560]   And they understand that the engine that makes this all possible, the thing that pays for
[01:06:02.560 --> 01:06:09.120]   the moon shots and the research and the artificial intelligence is advertising.
[01:06:09.120 --> 01:06:11.840]   You know, we're advertising supported.
[01:06:11.840 --> 01:06:13.840]   The thing that pays for all of this is advertising.
[01:06:13.840 --> 01:06:14.840]   I don't think that's a sin.
[01:06:14.840 --> 01:06:17.280]   The career is advertising supported, really, when you think about it.
[01:06:17.280 --> 01:06:19.120]   Mine has been for 40 years.
[01:06:19.120 --> 01:06:20.360]   I've been always in free media.
[01:06:20.360 --> 01:06:24.080]   I've never charged for anything I've done because it's not supported.
[01:06:24.080 --> 01:06:26.160]   And I don't think that's a sin.
[01:06:26.160 --> 01:06:30.120]   I think lately it's been acted-- people have been acting like it's a sin.
[01:06:30.120 --> 01:06:32.400]   Well, because everything is charging now.
[01:06:32.400 --> 01:06:35.200]   Well, people don't like advertising.
[01:06:35.200 --> 01:06:38.280]   But honestly, I don't think you'd like the alternative.
[01:06:38.280 --> 01:06:42.240]   I hate it when I go to the Financial Times and I can't read it because I didn't pay the
[01:06:42.240 --> 01:06:43.240]   $50 or blew it.
[01:06:43.240 --> 01:06:44.240]   Just trying to learn.
[01:06:44.240 --> 01:06:46.240]   The one that pisses me off is Bloomberg.
[01:06:46.240 --> 01:06:48.200]   The $50 a month.
[01:06:48.200 --> 01:06:49.960]   Don't you make enough money on the terminal?
[01:06:49.960 --> 01:06:50.960]   Come on.
[01:06:50.960 --> 01:06:52.200]   You're rich already, Michael.
[01:06:52.200 --> 01:06:53.200]   No, no, it's fine.
[01:06:53.200 --> 01:06:54.200]   He can charge.
[01:06:54.200 --> 01:06:55.200]   It's a good point.
[01:06:55.200 --> 01:06:56.200]   He can charge.
[01:06:56.200 --> 01:06:57.320]   But I think we prefer an ad supported world.
[01:06:57.320 --> 01:07:03.160]   If ads would work, the problem the journalism has right now, I'm sure that fast companies
[01:07:03.160 --> 01:07:06.480]   facing this is that people are using ad blockers, ads aren't working.
[01:07:06.480 --> 01:07:10.920]   And so it's harder and harder to good journalism on an ad supported model.
[01:07:10.920 --> 01:07:13.880]   That's why I drink Nestle Quick.
[01:07:13.880 --> 01:07:15.680]   You should try sport team.
[01:07:15.680 --> 01:07:19.840]   You know what, when we do our ads, I pull out the blue paper.
[01:07:19.840 --> 01:07:21.600]   I say, here's an ad.
[01:07:21.600 --> 01:07:23.560]   I'm not embarrassed to do ads.
[01:07:23.560 --> 01:07:25.720]   We try to pick products that are good and all that stuff.
[01:07:25.720 --> 01:07:27.000]   I think that's a virtue.
[01:07:27.000 --> 01:07:32.280]   And it is unfortunate that advertising-- partly because ad tech has gotten such a bad rap.
[01:07:32.280 --> 01:07:34.560]   Facebook has done us a disservice, right?
[01:07:34.560 --> 01:07:35.560]   Yes.
[01:07:35.560 --> 01:07:39.800]   And you know, like you've skisily collecting information about us.
[01:07:39.800 --> 01:07:40.800]   I don't know.
[01:07:40.800 --> 01:07:43.160]   Adfron is a terrible problem too in programmatic.
[01:07:43.160 --> 01:07:44.880]   It's a big problem for Google, right?
[01:07:44.880 --> 01:07:46.640]   As fraudulent clicks.
[01:07:46.640 --> 01:07:47.640]   Yeah.
[01:07:47.640 --> 01:07:48.640]   Yeah.
[01:07:48.640 --> 01:07:49.640]   Thank God there's podcasting.
[01:07:49.640 --> 01:07:51.640]   What would we do without podcasting?
[01:07:51.640 --> 01:07:56.480]   Oh, speaking of podcasting, back to Google I/O, they had announced--
[01:07:56.480 --> 01:07:58.520]   It's out now.
[01:07:58.520 --> 01:08:02.920]   Well they had announced that they would bring live captions over to video and audio.
[01:08:02.920 --> 01:08:03.920]   Isn't that awesome?
[01:08:03.920 --> 01:08:08.000]   And once up closer to indexing, our precious podcasts--
[01:08:08.000 --> 01:08:09.000]   Yeah.
[01:08:09.000 --> 01:08:10.000]   --and Google Search.
[01:08:10.000 --> 01:08:12.200]   I think somebody says it's live now in Search.
[01:08:12.200 --> 01:08:16.400]   So podcast lists, playable podcasts and search results.
[01:08:16.400 --> 01:08:17.400]   Is that what you're talking about?
[01:08:17.400 --> 01:08:18.400]   Well, this is definitely--
[01:08:18.400 --> 01:08:19.400]   That was two days ago.
[01:08:19.400 --> 01:08:22.600]   --to, although I'm a little annoyed that I search for Twitch and I keep getting this
[01:08:22.600 --> 01:08:25.280]   week in Trump.
[01:08:25.280 --> 01:08:26.280]   That's not Twitch.
[01:08:26.280 --> 01:08:27.280]   Oh, boy.
[01:08:27.280 --> 01:08:28.280]   That one made me--
[01:08:28.280 --> 01:08:29.280]   Wow.
[01:08:29.280 --> 01:08:30.280]   That gave me a--
[01:08:30.280 --> 01:08:31.280]   Yeah.
[01:08:31.280 --> 01:08:37.680]   Yeah, they-- somebody told me it was live in Search now that if you search for content
[01:08:37.680 --> 01:08:38.840]   in a podcast, let me see.
[01:08:38.840 --> 01:08:40.560]   I'll do a different one.
[01:08:40.560 --> 01:08:41.560]   Security now.
[01:08:41.560 --> 01:08:42.560]   Security now.
[01:08:42.560 --> 01:08:43.560]   Security now.
[01:08:43.560 --> 01:08:46.040]   Also, this week in Tech and I get play buttons.
[01:08:46.040 --> 01:08:47.040]   I think the news was that--
[01:08:47.040 --> 01:08:49.000]   That's because I said Twitch probably, right?
[01:08:49.000 --> 01:08:52.840]   Yeah, I did this week in Tech and I was like, I'll get the last three episodes embedded
[01:08:52.840 --> 01:08:54.400]   with play buttons next to--
[01:08:54.400 --> 01:08:57.960]   So wouldn't that only be an Android Q?
[01:08:57.960 --> 01:08:58.960]   No, no, no.
[01:08:58.960 --> 01:09:03.960]   This is in their search product that they're bringing podcast indexing of some form.
[01:09:03.960 --> 01:09:06.320]   This is huge, by the way, for our service.
[01:09:06.320 --> 01:09:07.320]   Absolutely.
[01:09:07.320 --> 01:09:08.320]   Very, very big.
[01:09:08.320 --> 01:09:09.320]   Embedding in the search results.
[01:09:09.320 --> 01:09:15.040]   And I think there's a lot of crossover here between what you were talking about in Android
[01:09:15.040 --> 01:09:22.000]   Q with the live caption and the stuff you're seeing on YouTube with that auto captioning
[01:09:22.000 --> 01:09:24.040]   and the indexing of podcasts into search.
[01:09:24.040 --> 01:09:25.040]   This is just the beginning.
[01:09:25.040 --> 01:09:31.120]   At some point, it's going to be possible for you to plug in a search and to have the actual
[01:09:31.120 --> 01:09:36.520]   content of podcasts to be pulled back because that's easy for Google to index at that point,
[01:09:36.520 --> 01:09:37.520]   right?
[01:09:37.520 --> 01:09:38.520]   They can already do that.
[01:09:38.520 --> 01:09:39.520]   So you better believe they're working on these players.
[01:09:39.520 --> 01:09:42.520]   You call it just going to be a lot easier for your children, by the way.
[01:09:42.520 --> 01:09:45.720]   But I'm sad to say you're not a lot cheaper.
[01:09:45.720 --> 01:09:46.720]   Yes, exactly.
[01:09:46.720 --> 01:09:47.720]   They ever get there.
[01:09:47.720 --> 01:09:51.960]   My daughter graduates on Saturday and all I can think of is no more checks, no more
[01:09:51.960 --> 01:09:52.960]   checks.
[01:09:52.960 --> 01:09:53.960]   Congratulations.
[01:09:53.960 --> 01:09:57.480]   A lot of years writing checks, a lot of years.
[01:09:57.480 --> 01:09:58.960]   Both kids are in a college.
[01:09:58.960 --> 01:09:59.960]   Thank you.
[01:09:59.960 --> 01:10:00.960]   That's amazing.
[01:10:00.960 --> 01:10:02.800]   3D images will be popping up at search results.
[01:10:02.800 --> 01:10:05.800]   This is good for advertising because if you search for new balanced sneakers, you'll get
[01:10:05.800 --> 01:10:07.560]   an image of new balanced sneakers.
[01:10:07.560 --> 01:10:08.560]   Right.
[01:10:08.560 --> 01:10:10.640]   And then you can place it as they showed you.
[01:10:10.640 --> 01:10:12.880]   You hit the little button in your foot in AR mode.
[01:10:12.880 --> 01:10:14.840]   You place it on your bed next to your outfit.
[01:10:14.840 --> 01:10:15.840]   Yes.
[01:10:15.840 --> 01:10:16.840]   All that, the red match.
[01:10:16.840 --> 01:10:17.840]   Yes.
[01:10:17.840 --> 01:10:22.040]   That's what I do when I shop for things because I'm not just going to buy stuff to hoard into
[01:10:22.040 --> 01:10:25.880]   my home, I'm trying to buy things that go with what I have collected in my wardrobe
[01:10:25.880 --> 01:10:27.560]   because that is how I express myself.
[01:10:27.560 --> 01:10:33.040]   And so I like that use and I'm not going to shop at Amazon for it.
[01:10:33.040 --> 01:10:34.840]   But what if Amazon has that feature?
[01:10:34.840 --> 01:10:35.840]   They do.
[01:10:35.840 --> 01:10:38.800]   They do have that feature, but I don't like they don't.
[01:10:38.800 --> 01:10:39.960]   They always give you the bad brands.
[01:10:39.960 --> 01:10:44.160]   They always give you the cheap knockoff brands before they give you the Amazon brands.
[01:10:44.160 --> 01:10:45.160]   Yeah.
[01:10:45.160 --> 01:10:50.680]   They give you the Amazon brands and it's just like I'm not spending $17 for a wedding dress.
[01:10:50.680 --> 01:10:56.280]   I thought that was kind of an exciting moment in the Google thing, including the 3D and
[01:10:56.280 --> 01:11:03.520]   the AR stuff in search results because you know AR is kind of it's kind of like coming
[01:11:03.520 --> 01:11:04.520]   slowly.
[01:11:04.520 --> 01:11:07.240]   It's been kind of reduced to having Detective Pikachu in your images.
[01:11:07.240 --> 01:11:10.240]   Listen, it's a hit with my Instagram crowd.
[01:11:10.240 --> 01:11:11.240]   So.
[01:11:11.240 --> 01:11:13.440]   No, but I agree 100%.
[01:11:13.440 --> 01:11:16.360]   You know what the biggest one to me is going to be the AR walking directions when they
[01:11:16.360 --> 01:11:17.600]   were released that.
[01:11:17.600 --> 01:11:18.840]   I actually tested those.
[01:11:18.840 --> 01:11:19.840]   That's pretty cool.
[01:11:19.840 --> 01:11:20.840]   They had work.
[01:11:20.840 --> 01:11:21.840]   Where did you just them?
[01:11:21.840 --> 01:11:25.440]   They had a little thing and we did a little tour of downtown San Francisco and we were
[01:11:25.440 --> 01:11:26.440]   holding phones.
[01:11:26.440 --> 01:11:33.960]   But I want to see you test it at 7.30 in the morning on second street coming out of the
[01:11:33.960 --> 01:11:39.800]   BART station because I have I still use maps of this day even though I'm burying lived
[01:11:39.800 --> 01:11:40.800]   here my whole life.
[01:11:40.800 --> 01:11:43.480]   I still need a little help knowing which direction to go.
[01:11:43.480 --> 01:11:45.760]   And I've gotten bumped like for using my phone.
[01:11:45.760 --> 01:11:48.360]   I've gotten people say to me like, "Push your phone away!"
[01:11:48.360 --> 01:11:50.840]   Oh, when you're walking around the street like this.
[01:11:50.840 --> 01:11:54.240]   You know, and just like people are trying to get to work.
[01:11:54.240 --> 01:11:58.040]   They do not need you standing and being like, "Okay, Google says I should go this way."
[01:11:58.040 --> 01:11:59.880]   No, it's got to pass through camera.
[01:11:59.880 --> 01:12:00.880]   It's okay.
[01:12:00.880 --> 01:12:03.560]   I promise I'm not just reading Twitter.
[01:12:03.560 --> 01:12:04.560]   That's what I thought about.
[01:12:04.560 --> 01:12:08.720]   Just because I've had unfortunate experiences of pissing people off and downtown.
[01:12:08.720 --> 01:12:11.320]   And that's like their that's their number one use case too.
[01:12:11.320 --> 01:12:14.720]   It's like when you come up from out of the train, you know, like this thing's going to
[01:12:14.720 --> 01:12:16.480]   show you where you're actually at.
[01:12:16.480 --> 01:12:20.160]   And the little blue dot you could be totally.
[01:12:20.160 --> 01:12:24.680]   So one of the things you have to do is you come out of this BART station or whatever.
[01:12:24.680 --> 01:12:28.920]   And they want you to take pictures of the buildings first to orient it.
[01:12:28.920 --> 01:12:30.640]   Did they do this in your demo?
[01:12:30.640 --> 01:12:32.240]   No, we didn't take any pictures.
[01:12:32.240 --> 01:12:34.720]   We'll not take pictures but you have to hold it up.
[01:12:34.720 --> 01:12:35.720]   Like calibrating it.
[01:12:35.720 --> 01:12:36.720]   Yeah, calibrating it.
[01:12:36.720 --> 01:12:38.640]   Because it has to look around, right?
[01:12:38.640 --> 01:12:39.640]   Right.
[01:12:39.640 --> 01:12:40.640]   Right.
[01:12:40.640 --> 01:12:41.640]   Because you're doing that.
[01:12:41.640 --> 01:12:42.640]   Yeah.
[01:12:42.640 --> 01:12:44.080]   In the Google I/O app actually, they had a little preview of this.
[01:12:44.080 --> 01:12:48.160]   They had map terminals throughout the whole spread at Shoreline.
[01:12:48.160 --> 01:12:52.360]   And in order to orient it, it wasn't showing the actual layout because of course it was
[01:12:52.360 --> 01:12:55.080]   a temporary layout for just those three days.
[01:12:55.080 --> 01:12:57.560]   But you would go away assistant.
[01:12:57.560 --> 01:13:01.760]   You would point it at this almost like this, this, the sign that which had something that
[01:13:01.760 --> 01:13:04.240]   kind of looked like a QR code, but it wasn't really.
[01:13:04.240 --> 01:13:05.240]   Yeah.
[01:13:05.240 --> 01:13:06.400]   And that was how it oriented.
[01:13:06.400 --> 01:13:10.200]   And then when you lifted your camera up, all the tents and everything, you saw these
[01:13:10.200 --> 01:13:11.200]   little balloons popping out of them.
[01:13:11.200 --> 01:13:15.240]   They were popping out of them and said sandbox or live demo or whatever.
[01:13:15.240 --> 01:13:18.760]   And so that, you know, so that's in that true AR mode, you knew exactly where you
[01:13:18.760 --> 01:13:19.760]   were.
[01:13:19.760 --> 01:13:24.520]   That's the most forest style demon AR where it's popping up little informational bubbles.
[01:13:24.520 --> 01:13:25.520]   It was really neat.
[01:13:25.520 --> 01:13:26.520]   Over people.
[01:13:26.520 --> 01:13:27.520]   I love that.
[01:13:27.520 --> 01:13:30.560]   But I also love the idea that it says turn left here and shows the arrow on the sidewalk
[01:13:30.560 --> 01:13:32.360]   that says that way.
[01:13:32.360 --> 01:13:33.520]   I need that.
[01:13:33.520 --> 01:13:34.720]   It's only walking directions.
[01:13:34.720 --> 01:13:36.400]   It's not, you know, while you're driving.
[01:13:36.400 --> 01:13:38.360]   I mean, it's probably less useful.
[01:13:38.360 --> 01:13:41.160]   But whenever I'm using maps for walking, I always turn.
[01:13:41.160 --> 01:13:42.160]   And left, I should turn right.
[01:13:42.160 --> 01:13:43.160]   It's never obvious.
[01:13:43.160 --> 01:13:44.160]   Same, same, same.
[01:13:44.160 --> 01:13:46.120]   So having that arrow go that way, dummy.
[01:13:46.120 --> 01:13:48.640]   By the way, I found your $17 wedding dress.
[01:13:48.640 --> 01:13:51.480]   I've been searching.
[01:13:51.480 --> 01:13:53.480]   And thanks to Hello Beautiful.
[01:13:53.480 --> 01:13:55.040]   I'm Monica.
[01:13:55.040 --> 01:13:59.360]   This is, this is turning a $17 wedding dress in my dream.
[01:13:59.360 --> 01:14:01.320]   I do it.
[01:14:01.320 --> 01:14:03.160]   There's nothing you can't find on the internet.
[01:14:03.160 --> 01:14:06.920]   I'm just saying the vision, the execution.
[01:14:06.920 --> 01:14:07.920]   Yes.
[01:14:07.920 --> 01:14:08.920]   Yes.
[01:14:08.920 --> 01:14:09.920]   Yes.
[01:14:09.920 --> 01:14:10.920]   That's pretty good.
[01:14:10.920 --> 01:14:11.920]   That's pretty good.
[01:14:11.920 --> 01:14:12.920]   That's pretty good.
[01:14:12.920 --> 01:14:15.200]   That's a, that's an Instagram wedding.
[01:14:15.200 --> 01:14:16.360]   She's actually not really married.
[01:14:16.360 --> 01:14:18.240]   It's just, you know, I don't know.
[01:14:18.240 --> 01:14:19.240]   I don't know.
[01:14:19.240 --> 01:14:20.240]   I don't know Monica.
[01:14:20.240 --> 01:14:21.240]   I don't know.
[01:14:21.240 --> 01:14:23.640]   Monica, clearly she got some increase.
[01:14:23.640 --> 01:14:27.720]   I just want to point out all these pictures of the wedding dress do not include a groom
[01:14:27.720 --> 01:14:29.120]   in any of them.
[01:14:29.120 --> 01:14:35.760]   So I'm just, I'm just saying, you know, she doesn't actually say I got married in it.
[01:14:35.760 --> 01:14:38.160]   But she found the dress of her dreams for what it happens.
[01:14:38.160 --> 01:14:39.160]   And it was only seven.
[01:14:39.160 --> 01:14:40.160]   She's ready.
[01:14:40.160 --> 01:14:41.160]   She's going to hold on to that.
[01:14:41.160 --> 01:14:45.400]   Oh, there's a lot of pictures of her by herself on the beach.
[01:14:45.400 --> 01:14:47.360]   That's hashtag editing.
[01:14:47.360 --> 01:14:48.360]   Google I am.
[01:14:48.360 --> 01:14:50.360]   We'll do a little more in a second.
[01:14:50.360 --> 01:14:52.000]   I'm going to take a break.
[01:14:52.000 --> 01:15:01.200]   You know, one of the things people do, and I did is with Google is we're a little nervous
[01:15:01.200 --> 01:15:03.480]   about Google holding all of our mail.
[01:15:03.480 --> 01:15:06.800]   I finally got off Gmail.
[01:15:06.800 --> 01:15:10.240]   And the solution is difficult.
[01:15:10.240 --> 01:15:13.280]   You can go to another email provider, but then they've got all your mail.
[01:15:13.280 --> 01:15:15.040]   It's not that I don't trust Google particularly.
[01:15:15.040 --> 01:15:17.720]   It's just that no one should have all my mail.
[01:15:17.720 --> 01:15:21.280]   That's 12 years of my life.
[01:15:21.280 --> 01:15:23.160]   And I never delete anything on Gmail.
[01:15:23.160 --> 01:15:24.840]   I found something so cool.
[01:15:24.840 --> 01:15:27.920]   They actually came on the show on the screen saver show.
[01:15:27.920 --> 01:15:29.640]   This is called the helm.
[01:15:29.640 --> 01:15:33.000]   It is a personal, well, it starts as a personal email server.
[01:15:33.000 --> 01:15:37.600]   Actually, now they've added some new features that make it a file server and a photo server
[01:15:37.600 --> 01:15:38.600]   as well.
[01:15:38.600 --> 01:15:41.280]   So there's a real challenge to doing your own email.
[01:15:41.280 --> 01:15:42.280]   This is the helm.
[01:15:42.280 --> 01:15:43.280]   It looks really cool, by the way, doesn't it?
[01:15:43.280 --> 01:15:50.200]   It's a pyramid or a triangle shaped server, 128 gigs of storage SSD, very fast SSD, upgradable
[01:15:50.200 --> 01:15:53.000]   to five terabytes.
[01:15:53.000 --> 01:15:54.280]   Takes about five minutes to set up.
[01:15:54.280 --> 01:15:57.280]   It has Wi-Fi or ethernet.
[01:15:57.280 --> 01:15:59.880]   The challenge in doing your own email server though is complicated.
[01:15:59.880 --> 01:16:05.160]   First of all, almost certainly on a residential internet connection, you cannot send email.
[01:16:05.160 --> 01:16:06.160]   They block it.
[01:16:06.160 --> 01:16:07.160]   They will block it.
[01:16:07.160 --> 01:16:11.120]   And even if you could send out email, almost all email providers, including Google, reject
[01:16:11.120 --> 01:16:13.480]   it if it's coming from an IP address.
[01:16:13.480 --> 01:16:18.480]   That's a personal IP address because they're almost always in the black holes for spam.
[01:16:18.480 --> 01:16:21.400]   So what Helm does is very clever.
[01:16:21.400 --> 01:16:24.840]   Your mail is lives only on your server.
[01:16:24.840 --> 01:16:30.240]   In order to send it out, they route it through their own IP address at Amazon.
[01:16:30.240 --> 01:16:34.680]   The route it through in that IP address is a specially conditioned IP address so that
[01:16:34.680 --> 01:16:36.600]   your email will be accepted everywhere.
[01:16:36.600 --> 01:16:40.880]   They also use email authentication, the big three, DMARC, SPF, and DKIM.
[01:16:40.880 --> 01:16:47.320]   By the way, I just saw a study of the top 20 Democratic candidates for president.
[01:16:47.320 --> 01:16:50.760]   Only one of them is using email authentication.
[01:16:50.760 --> 01:16:52.360]   They all need a helm.
[01:16:52.360 --> 01:16:54.200]   DMARC, SPF, and DKIM.
[01:16:54.200 --> 01:16:58.800]   That helps your email get through because it says, yes, this is who sent it.
[01:16:58.800 --> 01:17:01.320]   The data is fully encrypted.
[01:17:01.320 --> 01:17:03.440]   Keys are stored on a secure enclave on the server.
[01:17:03.440 --> 01:17:06.480]   In fact, there's a really cool feature when you first set up your helm.
[01:17:06.480 --> 01:17:08.720]   They have a very cool looking USB key.
[01:17:08.720 --> 01:17:13.960]   You attach to the helm to copy your recovery keys off, put that somewhere safe.
[01:17:13.960 --> 01:17:18.680]   Even if you lose your server, if your house burns down, Helm is backing the encrypted
[01:17:18.680 --> 01:17:19.680]   data up.
[01:17:19.680 --> 01:17:21.000]   They never have access to your data.
[01:17:21.000 --> 01:17:25.920]   You can get all of your email and data back from the helm servers, but you'll need that
[01:17:25.920 --> 01:17:27.240]   recovery key.
[01:17:27.240 --> 01:17:28.240]   It's secure boot.
[01:17:28.240 --> 01:17:30.320]   No one can hack it.
[01:17:30.320 --> 01:17:33.000]   The authentication is proximity based.
[01:17:33.000 --> 01:17:34.360]   Two factor through the helm app.
[01:17:34.360 --> 01:17:35.920]   You put the helm app on your phone.
[01:17:35.920 --> 01:17:40.600]   You authenticate by standing next using Bluetooth LA, standing next to the helm server.
[01:17:40.600 --> 01:17:44.000]   That's how you create the account, create additional accounts.
[01:17:44.000 --> 01:17:47.360]   Unlimited email accounts.
[01:17:47.360 --> 01:17:54.640]   I set up my own domain for email, but you can have multiple domains.
[01:17:54.640 --> 01:17:58.040]   Micah leaded a great piece on the intercept, which I highly recommend.
[01:17:58.040 --> 01:18:04.600]   If you want to know more about the helm, Micah is an expert who taught, like journalists
[01:18:04.600 --> 01:18:10.680]   how to protect, the intercept is, of course, where Glenn Greenwald and Snowden stuff ended
[01:18:10.680 --> 01:18:11.680]   on.
[01:18:11.680 --> 01:18:14.320]   Micah has taught journalists how to protect themselves.
[01:18:14.320 --> 01:18:16.240]   He set up an helm server, helm server.
[01:18:16.240 --> 01:18:21.240]   He wrote all about it on the April 30th article about helm, so read it.
[01:18:21.240 --> 01:18:23.400]   It'll give you all the information at theintercept.com.
[01:18:23.400 --> 01:18:27.640]   If you want a more technical look at it, he really drilled down.
[01:18:27.640 --> 01:18:29.800]   Now they added next cloud.
[01:18:29.800 --> 01:18:30.800]   This is really good.
[01:18:30.800 --> 01:18:34.160]   Next cloud is the open source file server.
[01:18:34.160 --> 01:18:36.480]   You can get file sync, file sharing.
[01:18:36.480 --> 01:18:41.120]   You can back up all your photos to the helm, which means you can upload view and share your
[01:18:41.120 --> 01:18:43.200]   files and photos securely.
[01:18:43.200 --> 01:18:49.760]   This is a great replacement, not just now for your email, but for Google Drive, for Dropbox.
[01:18:49.760 --> 01:18:51.760]   I am just such a fan.
[01:18:51.760 --> 01:18:54.200]   Privacy is a right, not a setting.
[01:18:54.200 --> 01:18:55.840]   Protect what matters with helm.
[01:18:55.840 --> 01:19:00.440]   Right now we've got $50 off the helm personal server, the helm.com/twit.
[01:19:00.440 --> 01:19:05.000]   I only have one thing to say, though I see on the site.
[01:19:05.000 --> 01:19:07.560]   It says sold out.
[01:19:07.560 --> 01:19:08.560]   That's temporary.
[01:19:08.560 --> 01:19:10.200]   They're making them as fast as they can.
[01:19:10.200 --> 01:19:11.200]   These ads work too well.
[01:19:11.200 --> 01:19:12.680]   I apologize.
[01:19:12.680 --> 01:19:16.080]   But if you go right now, they're accepting deposits.
[01:19:16.080 --> 01:19:20.640]   The minute they get more shipped in, and actually you'll get the next generation, which is nice,
[01:19:20.640 --> 01:19:21.960]   the minute they're in stock you'll get yours.
[01:19:21.960 --> 01:19:23.760]   It won't be too long.
[01:19:23.760 --> 01:19:25.840]   This sometimes happens with our advertisers.
[01:19:25.840 --> 01:19:27.400]   They sell out.
[01:19:27.400 --> 01:19:29.440]   The helm.com/twit.
[01:19:29.440 --> 01:19:33.120]   I can totally vouch for it is what I'm using for my email now.
[01:19:33.120 --> 01:19:37.760]   By the way, it's good looking enough that you could actually put it on your coffee table
[01:19:37.760 --> 01:19:39.360]   in your living room.
[01:19:39.360 --> 01:19:41.600]   There's going to be more all the time they're adding to it.
[01:19:41.600 --> 01:19:44.960]   It has two Type-C connectors.
[01:19:44.960 --> 01:19:47.160]   There's really some extensibility built into this.
[01:19:47.160 --> 01:19:48.720]   These guys are really smart.
[01:19:48.720 --> 01:19:50.360]   Gary and his team did a great job.
[01:19:50.360 --> 01:19:54.320]   The helm.com/twit.
[01:19:54.320 --> 01:19:59.800]   If you're so inclined, and the intercept.com, if you want to read my because really, I thought
[01:19:59.800 --> 01:20:03.880]   a very good piece, a very balanced piece on the helm.
[01:20:03.880 --> 01:20:06.320]   You can see all the details.
[01:20:06.320 --> 01:20:09.200]   I was really pleased to read that.
[01:20:09.200 --> 01:20:11.800]   Hey, you got a phone at least.
[01:20:11.800 --> 01:20:15.120]   Google did not hand out new Pixel books because there aren't any.
[01:20:15.120 --> 01:20:16.120]   I'm sorry.
[01:20:16.120 --> 01:20:19.480]   I did not hand out new Galaxy Wear or not Galaxy.
[01:20:19.480 --> 01:20:20.920]   Android Wear watches because--
[01:20:20.920 --> 01:20:23.400]   Oh man, very little on the wearable.
[01:20:23.400 --> 01:20:25.720]   They're really beefed up Android Wear.
[01:20:25.720 --> 01:20:27.760]   I thought maybe they'd have a new watch, but no.
[01:20:27.760 --> 01:20:28.760]   No.
[01:20:28.760 --> 01:20:29.760]   But they did hand out phones.
[01:20:29.760 --> 01:20:30.760]   They did.
[01:20:30.760 --> 01:20:31.760]   This is the Pixel 3A.
[01:20:31.760 --> 01:20:35.560]   Which I'm literally unboxing as we talk about it.
[01:20:35.560 --> 01:20:36.560]   Oh, you haven't opened it yet.
[01:20:36.560 --> 01:20:38.400]   I haven't even-- I just took the seal off.
[01:20:38.400 --> 01:20:44.120]   I want to see it because you got the-- every year, Google does black white in a weird color.
[01:20:44.120 --> 01:20:45.600]   Last year, it was pinkish.
[01:20:45.600 --> 01:20:47.080]   No, it was not pink.
[01:20:47.080 --> 01:20:48.080]   Sorry.
[01:20:48.080 --> 01:20:49.080]   Not pink.
[01:20:49.080 --> 01:20:50.080]   Now it's purplish.
[01:20:50.080 --> 01:20:51.080]   And you got the purplish.
[01:20:51.080 --> 01:20:52.080]   Two tabs.
[01:20:52.080 --> 01:20:53.080]   Here's another one on the other side.
[01:20:53.080 --> 01:20:54.080]   Oh, oh, oh.
[01:20:54.080 --> 01:20:55.080]   That would make sense.
[01:20:55.080 --> 01:20:56.080]   Jason and I have both unboxing.
[01:20:56.080 --> 01:20:57.080]   We've got the same thing.
[01:20:57.080 --> 01:20:58.080]   And you got the big one, Jason, right?
[01:20:58.080 --> 01:20:59.080]   You got the--
[01:20:59.080 --> 01:21:01.240]   Yeah, I got the 3A XL, the 3-axle.
[01:21:01.240 --> 01:21:07.720]   So I took-- Carson and our producer bought one because he's a Verizon customer and he's
[01:21:07.720 --> 01:21:10.920]   been using an old OG Pixel.
[01:21:10.920 --> 01:21:11.920]   It was time.
[01:21:11.920 --> 01:21:13.960]   I thought it felt really good.
[01:21:13.960 --> 01:21:16.360]   It's a cheaper phone.
[01:21:16.360 --> 01:21:17.360]   What is it?
[01:21:17.360 --> 01:21:18.360]   $4.99?
[01:21:18.360 --> 01:21:19.360]   $3.99 starting.
[01:21:19.360 --> 01:21:20.960]   This one is $3.99 starting.
[01:21:20.960 --> 01:21:24.960]   So it's not budget price, but it's half as much.
[01:21:24.960 --> 01:21:29.560]   Oh, it's $500 less than the Pixel 3A XL to put next to it.
[01:21:29.560 --> 01:21:30.560]   It's got a cute little--
[01:21:30.560 --> 01:21:32.920]   Oh, you got not-- you got purplish, too.
[01:21:32.920 --> 01:21:33.920]   We did.
[01:21:33.920 --> 01:21:34.920]   We couldn't help but both--
[01:21:34.920 --> 01:21:35.920]   20.
[01:21:35.920 --> 01:21:36.920]   Yeah.
[01:21:36.920 --> 01:21:37.920]   Yeah.
[01:21:37.920 --> 01:21:39.920]   So that's a slightly bigger--
[01:21:39.920 --> 01:21:40.920]   It feels a little lighter.
[01:21:40.920 --> 01:21:42.400]   It feels a little lighter than the Pixel.
[01:21:42.400 --> 01:21:43.400]   Not as dense as the regular Pixel.
[01:21:43.400 --> 01:21:44.400]   They are a little lighter.
[01:21:44.400 --> 01:21:47.160]   Well, but you know, plastic isn't such a bad material.
[01:21:47.160 --> 01:21:48.800]   But it doesn't feel like a plastic phone.
[01:21:48.800 --> 01:21:49.800]   Oh, it's great.
[01:21:49.800 --> 01:21:52.280]   It feels the same as the material that's on the regular old--
[01:21:52.280 --> 01:21:53.280]   Now here's the key.
[01:21:53.280 --> 01:21:55.280]   It's the same lens on the back, right?
[01:21:55.280 --> 01:22:00.200]   Same camera, same software, but they did eliminate that special processor, the image
[01:22:00.200 --> 01:22:01.200]   processor.
[01:22:01.200 --> 01:22:04.800]   So they did some software enhancements to get the same--
[01:22:04.800 --> 01:22:06.280]   Are the images as good?
[01:22:06.280 --> 01:22:07.280]   Yeah.
[01:22:07.280 --> 01:22:08.280]   Yeah, the images are great.
[01:22:08.280 --> 01:22:10.280]   Everybody seems to agree that it might be a little slower because it didn't have the
[01:22:10.280 --> 01:22:11.280]   extra processor.
[01:22:11.280 --> 01:22:14.600]   This is a mid-ranger that you buy if camera is your top priority.
[01:22:14.600 --> 01:22:16.240]   It's the best camera for that price.
[01:22:16.240 --> 01:22:17.240]   As far as I've turned.
[01:22:17.240 --> 01:22:18.240]   Yes.
[01:22:18.240 --> 01:22:22.480]   For this price range, I mean, that I've seen that I know of, yeah.
[01:22:22.480 --> 01:22:24.480]   What's the OnePlus gonna cost, do you know?
[01:22:24.480 --> 01:22:26.880]   It's not gonna be this inexpensive.
[01:22:26.880 --> 01:22:28.880]   Well, the OnePlus is a flagship.
[01:22:28.880 --> 01:22:31.160]   The OnePlus 7 or the 7 Pro.
[01:22:31.160 --> 01:22:32.160]   I mean, we don't even have pricing.
[01:22:32.160 --> 01:22:33.160]   We don't even know.
[01:22:33.160 --> 01:22:34.160]   No.
[01:22:34.160 --> 01:22:35.160]   We're gonna find out on Tuesday.
[01:22:35.160 --> 01:22:36.160]   And that's a flagship.
[01:22:36.160 --> 01:22:38.400]   So this competes maybe with the Moto G7?
[01:22:38.400 --> 01:22:39.400]   Yes.
[01:22:39.400 --> 01:22:40.400]   Yes.
[01:22:40.400 --> 01:22:41.400]   More on that price range, I'd say.
[01:22:41.400 --> 01:22:42.400]   Okay.
[01:22:42.400 --> 01:22:43.400]   Much better camera.
[01:22:43.400 --> 01:22:44.400]   Pure Google.
[01:22:44.400 --> 01:22:46.640]   I mean, the Moto is pretty pure, but this is pure pure.
[01:22:46.640 --> 01:22:50.080]   It's so pure it's gonna get updates right on time.
[01:22:50.080 --> 01:22:55.640]   But the Moto G7 199 to 299, so this is maybe a little bit higher than that.
[01:22:55.640 --> 01:22:56.640]   But yeah.
[01:22:56.640 --> 01:22:57.640]   Ish, around that area.
[01:22:57.640 --> 01:22:59.880]   I mean, they're gonna discount these.
[01:22:59.880 --> 01:23:01.840]   You're gonna see these on sale for $300.
[01:23:01.840 --> 01:23:03.000]   I think you already are.
[01:23:03.000 --> 01:23:04.000]   It's not.
[01:23:04.000 --> 01:23:08.080]   It's not heard of, but it's rare for a company to announce a phone less than a year after
[01:23:08.080 --> 01:23:09.080]   it's most recent.
[01:23:09.080 --> 01:23:10.080]   Yeah.
[01:23:10.080 --> 01:23:11.080]   Phone.
[01:23:11.080 --> 01:23:12.080]   They announced the Google.
[01:23:12.080 --> 01:23:13.080]   It was much about so much.
[01:23:13.080 --> 01:23:14.080]   The Pixel 3.
[01:23:14.080 --> 01:23:18.360]   Well, I think that they made it to replace the Pixel 3 because it wasn't selling very
[01:23:18.360 --> 01:23:19.360]   well.
[01:23:19.360 --> 01:23:20.360]   It's my theory.
[01:23:20.360 --> 01:23:21.360]   Yeah.
[01:23:21.360 --> 01:23:25.040]   And I mean, this really, in my opinion, this place is a lot of pressure on Google to come
[01:23:25.040 --> 01:23:26.040]   out with a 4.
[01:23:26.040 --> 01:23:29.880]   That is much different than what we're used to seeing because the 1 through 3 all have
[01:23:29.880 --> 01:23:36.360]   the same design approach, all have kind of like a minimalist, you know, presence from
[01:23:36.360 --> 01:23:38.040]   Google as far as features are concerned.
[01:23:38.040 --> 01:23:43.600]   4 gigs of RAM on their flagship, you know, Pixel 3 always seemed like not enough RAM
[01:23:43.600 --> 01:23:45.240]   compared to other flagships.
[01:23:45.240 --> 01:23:48.640]   And then now, you know, they're showing that they could do 4 gigs of RAM and something
[01:23:48.640 --> 01:23:53.240]   that's half the cost with the same camera that everybody knows is why you buy a Pixel.
[01:23:53.240 --> 01:23:59.080]   There are a huge number of concessions in this compared to the Pixel 3, right?
[01:23:59.080 --> 01:24:00.800]   I mean, this is fairly close.
[01:24:00.800 --> 01:24:02.000]   Is the screen as good?
[01:24:02.000 --> 01:24:03.000]   Some said it was better.
[01:24:03.000 --> 01:24:04.000]   The display.
[01:24:04.000 --> 01:24:05.960]   So apparently it is a Samsung display.
[01:24:05.960 --> 01:24:06.960]   I like the display.
[01:24:06.960 --> 01:24:07.960]   It's a 1080 display.
[01:24:07.960 --> 01:24:12.720]   If you've got the smaller version, if you've got the regular 3, they're both 1080p displays.
[01:24:12.720 --> 01:24:17.480]   If you've got the 3 XL like I have, this is a higher res display than what you'll get
[01:24:17.480 --> 01:24:19.000]   on the 3A XL.
[01:24:19.000 --> 01:24:21.800]   But still, 1080p, it looks fantastic.
[01:24:21.800 --> 01:24:25.640]   Even on my Galaxy S10 Plus, I don't use the full resolution.
[01:24:25.640 --> 01:24:27.720]   I make it 1080p because it's better battery life.
[01:24:27.720 --> 01:24:28.720]   Better battery.
[01:24:28.720 --> 01:24:29.720]   It's better battery life.
[01:24:29.720 --> 01:24:30.720]   I don't use the same battery.
[01:24:30.720 --> 01:24:31.720]   I don't use the same battery.
[01:24:31.720 --> 01:24:32.720]   I don't use the same battery.
[01:24:32.720 --> 01:24:33.720]   I don't use the same battery.
[01:24:33.720 --> 01:24:34.720]   I don't use the same battery.
[01:24:34.720 --> 01:24:35.720]   I don't use the same battery.
[01:24:35.720 --> 01:24:36.720]   I don't use the same battery.
[01:24:36.720 --> 01:24:37.720]   I don't use the same battery.
[01:24:37.720 --> 01:24:38.720]   I don't use the same battery.
[01:24:38.720 --> 01:24:39.720]   I don't use the same battery.
[01:24:39.720 --> 01:24:40.720]   I don't use the same battery.
[01:24:40.720 --> 01:24:41.720]   I don't use the same battery.
[01:24:41.720 --> 01:24:42.720]   I don't use the same battery.
[01:24:42.720 --> 01:24:43.720]   I don't use the same battery.
[01:24:43.720 --> 01:24:44.720]   I don't use the same battery.
[01:24:44.720 --> 01:24:45.720]   I don't use the same battery.
[01:24:45.720 --> 01:24:46.720]   I don't use the same battery.
[01:24:46.720 --> 01:24:47.720]   I don't use the same battery.
[01:24:47.720 --> 01:24:48.720]   I don't use the same battery.
[01:24:48.720 --> 01:24:49.720]   I don't use the same battery.
[01:24:49.720 --> 01:24:50.720]   I don't use the same battery.
[01:24:50.720 --> 01:24:57.720]   I don't use the same battery.
[01:24:57.720 --> 01:25:00.720]   I don't use the same battery.
[01:25:00.720 --> 01:25:01.720]   I don't use the same battery.
[01:25:01.720 --> 01:25:02.720]   I don't use the same battery.
[01:25:02.720 --> 01:25:03.720]   I don't use the same battery.
[01:25:03.720 --> 01:25:04.720]   I don't use the same battery.
[01:25:04.720 --> 01:25:05.720]   I don't use the same battery.
[01:25:05.720 --> 01:25:06.720]   I don't use the same battery.
[01:25:06.720 --> 01:25:07.720]   I don't use the same battery.
[01:25:07.720 --> 01:25:08.720]   I don't use the same battery.
[01:25:08.720 --> 01:25:09.720]   I don't use the same battery.
[01:25:09.720 --> 01:25:10.720]   I don't use the same battery.
[01:25:10.720 --> 01:25:11.720]   I don't use the same battery.
[01:25:11.720 --> 01:25:12.720]   I don't use the same battery.
[01:25:12.720 --> 01:25:13.720]   I don't use the same battery.
[01:25:13.720 --> 01:25:14.720]   I don't use the same battery.
[01:25:14.720 --> 01:25:15.720]   I don't use the same battery.
[01:25:15.720 --> 01:25:16.720]   I don't use the same battery.
[01:25:16.720 --> 01:25:17.720]   I don't use the same battery.
[01:25:17.720 --> 01:25:18.720]   I don't use the same battery.
[01:25:18.720 --> 01:25:19.720]   I don't use the same battery.
[01:25:19.720 --> 01:25:20.720]   I don't use the same battery.
[01:25:20.720 --> 01:25:21.720]   I don't use the same battery.
[01:25:21.720 --> 01:25:22.720]   I don't use the same battery.
[01:25:22.720 --> 01:25:23.720]   I don't use the same battery.
[01:25:23.720 --> 01:25:24.720]   I don't use the same battery.
[01:25:24.720 --> 01:25:25.720]   I don't use the same battery.
[01:25:25.720 --> 01:25:26.720]   I don't use the same battery.
[01:25:26.720 --> 01:25:27.720]   I don't use the same battery.
[01:25:27.720 --> 01:25:28.720]   I don't use the same battery.
[01:25:28.720 --> 01:25:29.720]   I don't use the same battery.
[01:25:29.720 --> 01:25:30.720]   I don't use the same battery.
[01:25:30.720 --> 01:25:31.720]   I don't use the same battery.
[01:25:31.720 --> 01:25:32.720]   I don't use the same battery.
[01:25:32.720 --> 01:25:33.720]   I don't use the same battery.
[01:25:33.720 --> 01:25:34.720]   I don't use the same battery.
[01:25:34.720 --> 01:25:35.720]   I don't use the same battery.
[01:25:35.720 --> 01:25:36.720]   I don't use the same battery.
[01:25:36.720 --> 01:25:37.720]   I don't use the same battery.
[01:25:37.720 --> 01:25:38.720]   I don't use the same battery.
[01:25:38.720 --> 01:25:39.720]   I don't use the same battery.
[01:25:39.720 --> 01:25:40.720]   I don't use the same battery.
[01:25:40.720 --> 01:25:41.720]   I don't use the same battery.
[01:25:41.720 --> 01:25:42.720]   I don't use the same battery.
[01:25:42.720 --> 01:25:43.720]   I don't use the same battery.
[01:25:43.720 --> 01:25:44.720]   I don't use the same battery.
[01:25:44.720 --> 01:25:45.720]   I don't use the same battery.
[01:25:45.720 --> 01:25:46.720]   I don't use the same battery.
[01:25:46.720 --> 01:25:47.720]   I don't use the same battery.
[01:25:47.720 --> 01:25:48.720]   I don't use the same battery.
[01:25:48.720 --> 01:25:49.720]   I don't use the same battery.
[01:25:49.720 --> 01:25:50.720]   I don't use the same battery.
[01:25:50.720 --> 01:25:51.720]   I don't use the same battery.
[01:25:51.720 --> 01:25:52.720]   I don't use the same battery.
[01:25:52.720 --> 01:25:53.720]   I don't use the same battery.
[01:25:53.720 --> 01:25:54.720]   I don't use the same battery.
[01:25:54.720 --> 01:25:55.720]   I don't use the same battery.
[01:25:55.720 --> 01:25:56.720]   I don't use the same battery.
[01:25:56.720 --> 01:25:57.720]   I don't use the same battery.
[01:25:57.720 --> 01:25:58.720]   I don't use the same battery.
[01:25:58.720 --> 01:25:59.720]   I don't use the same battery.
[01:25:59.720 --> 01:26:00.720]   I don't use the same battery.
[01:26:00.720 --> 01:26:01.720]   I don't use the same battery.
[01:26:01.720 --> 01:26:02.720]   I don't use the same battery.
[01:26:02.720 --> 01:26:03.720]   I don't use the same battery.
[01:26:03.720 --> 01:26:04.720]   I don't use the same battery.
[01:26:04.720 --> 01:26:05.720]   I don't use the same battery.
[01:26:05.720 --> 01:26:06.720]   I don't use the same battery.
[01:26:06.720 --> 01:26:07.720]   I don't use the same battery.
[01:26:07.720 --> 01:26:08.720]   I don't use the same battery.
[01:26:08.720 --> 01:26:09.720]   I don't use the same battery.
[01:26:09.720 --> 01:26:10.720]   I don't use the same battery.
[01:26:10.720 --> 01:26:11.720]   I don't use the same battery.
[01:26:11.720 --> 01:26:12.720]   I don't use the same battery.
[01:26:12.720 --> 01:26:13.720]   I don't use the same battery.
[01:26:13.720 --> 01:26:14.720]   I don't use the same battery.
[01:26:14.720 --> 01:26:15.720]   I don't use the same battery.
[01:26:15.720 --> 01:26:16.720]   I don't use the same battery.
[01:26:16.720 --> 01:26:17.720]   I don't use the same battery.
[01:26:17.720 --> 01:26:18.720]   I don't use the same battery.
[01:26:18.720 --> 01:26:19.720]   I don't use the same battery.
[01:26:19.720 --> 01:26:20.720]   I don't use the same battery.
[01:26:20.720 --> 01:26:21.720]   I don't use the same battery.
[01:26:21.720 --> 01:26:22.720]   I don't use the same battery.
[01:26:22.720 --> 01:26:23.720]   I don't use the same battery.
[01:26:23.720 --> 01:26:24.720]   I don't use the same battery.
[01:26:24.720 --> 01:26:25.720]   I don't use the same battery.
[01:26:25.720 --> 01:26:26.720]   I don't use the same battery.
[01:26:26.720 --> 01:26:27.720]   I don't use the same battery.
[01:26:27.720 --> 01:26:28.720]   I don't use the same battery.
[01:26:28.720 --> 01:26:29.720]   I don't use the same battery.
[01:26:29.720 --> 01:26:30.720]   I don't use the same battery.
[01:26:30.720 --> 01:26:31.720]   I don't use the same battery.
[01:26:31.720 --> 01:26:32.720]   I don't use the same battery.
[01:26:32.720 --> 01:26:33.720]   I don't use the same battery.
[01:26:33.720 --> 01:26:34.720]   I don't use the same battery.
[01:26:34.720 --> 01:26:35.720]   I don't use the same battery.
[01:26:35.720 --> 01:26:36.720]   I don't use the same battery.
[01:26:36.720 --> 01:26:37.720]   I don't use the same battery.
[01:26:37.720 --> 01:26:38.720]   I don't use the same battery.
[01:26:38.720 --> 01:26:39.720]   I don't use the same battery.
[01:26:39.720 --> 01:26:40.720]   I don't use the same battery.
[01:26:40.720 --> 01:26:41.720]   I don't use the same battery.
[01:26:41.720 --> 01:26:42.720]   I don't use the same battery.
[01:26:42.720 --> 01:26:43.720]   I don't use the same battery.
[01:26:43.720 --> 01:26:44.720]   I don't use the same battery.
[01:26:44.720 --> 01:26:45.720]   I don't use the same battery.
[01:26:45.720 --> 01:26:46.720]   I don't use the same battery.
[01:26:46.720 --> 01:26:47.720]   I don't use the same battery.
[01:26:47.720 --> 01:26:48.720]   I don't use the same battery.
[01:26:48.720 --> 01:26:49.720]   I don't use the same battery.
[01:26:49.720 --> 01:26:50.720]   I don't use the same battery.
[01:26:50.720 --> 01:26:51.720]   I don't use the same battery.
[01:26:51.720 --> 01:26:52.720]   I don't use the same battery.
[01:26:52.720 --> 01:26:53.720]   I don't use the same battery.
[01:26:53.720 --> 01:26:54.720]   I don't use the same battery.
[01:26:54.720 --> 01:26:55.720]   I don't use the same battery.
[01:26:55.720 --> 01:26:56.720]   I don't use the same battery.
[01:26:56.720 --> 01:26:57.720]   I don't use the same battery.
[01:26:57.720 --> 01:26:58.720]   I don't use the same battery.
[01:26:58.720 --> 01:26:59.720]   I don't use the same battery.
[01:26:59.720 --> 01:27:00.720]   I don't use the same battery.
[01:27:00.720 --> 01:27:01.720]   I don't use the same battery.
[01:27:01.720 --> 01:27:02.720]   I don't use the same battery.
[01:27:02.720 --> 01:27:03.720]   I don't use the same battery.
[01:27:03.720 --> 01:27:04.720]   I don't use the same battery.
[01:27:04.720 --> 01:27:05.720]   I don't use the same battery.
[01:27:05.720 --> 01:27:06.720]   I don't use the same battery.
[01:27:06.720 --> 01:27:07.720]   I don't use the same battery.
[01:27:07.720 --> 01:27:08.720]   I don't use the same battery.
[01:27:08.720 --> 01:27:09.720]   I don't use the same battery.
[01:27:09.720 --> 01:27:10.720]   I don't use the same battery.
[01:27:10.720 --> 01:27:11.720]   I don't use the same battery.
[01:27:11.720 --> 01:27:12.720]   I don't use the same battery.
[01:27:12.720 --> 01:27:13.720]   I don't use the same battery.
[01:27:13.720 --> 01:27:14.720]   I don't use the same battery.
[01:27:14.720 --> 01:27:15.720]   I don't use the same battery.
[01:27:15.720 --> 01:27:16.720]   I don't use the same battery.
[01:27:16.720 --> 01:27:17.720]   I don't use the same battery.
[01:27:17.720 --> 01:27:18.720]   I don't use the same battery.
[01:27:18.720 --> 01:27:19.720]   I don't use the same battery.
[01:27:19.720 --> 01:27:20.720]   I don't use the same battery.
[01:27:20.720 --> 01:27:21.720]   I don't use the same battery.
[01:27:21.720 --> 01:27:22.720]   I don't use the same battery.
[01:27:22.720 --> 01:27:23.720]   I don't use the same battery.
[01:27:23.720 --> 01:27:24.720]   I don't use the same battery.
[01:27:24.720 --> 01:27:25.720]   I don't use the same battery.
[01:27:25.720 --> 01:27:26.720]   I don't use the same battery.
[01:27:26.720 --> 01:27:27.720]   I don't use the same battery.
[01:27:27.720 --> 01:27:28.720]   I don't use the same battery.
[01:27:28.720 --> 01:27:29.720]   I don't use the same battery.
[01:27:29.720 --> 01:27:30.720]   I don't use the same battery.
[01:27:30.720 --> 01:27:31.720]   I don't use the same battery.
[01:27:31.720 --> 01:27:32.720]   I don't use the same battery.
[01:27:32.720 --> 01:27:33.720]   I don't use the same battery.
[01:27:33.720 --> 01:27:34.720]   I don't use the same battery.
[01:27:34.720 --> 01:27:35.720]   I don't use the same battery.
[01:27:35.720 --> 01:27:36.720]   I don't use the same battery.
[01:27:36.720 --> 01:27:37.720]   I don't use the same battery.
[01:27:37.720 --> 01:27:38.720]   I don't use the same battery.
[01:27:38.720 --> 01:27:39.720]   I don't use the same battery.
[01:27:39.720 --> 01:27:40.720]   I don't use the same battery.
[01:27:40.720 --> 01:27:41.720]   I don't use the same battery.
[01:27:41.720 --> 01:27:42.720]   I don't use the same battery.
[01:27:42.720 --> 01:27:43.720]   I don't use the same battery.
[01:27:43.720 --> 01:27:44.720]   I don't use the same battery.
[01:27:44.720 --> 01:27:45.720]   I don't use the same battery.
[01:27:45.720 --> 01:27:46.720]   I don't use the same battery.
[01:27:46.720 --> 01:27:47.720]   I don't use the same battery.
[01:27:47.720 --> 01:27:48.720]   I don't use the same battery.
[01:27:48.720 --> 01:27:49.720]   I don't use the same battery.
[01:27:49.720 --> 01:27:50.720]   I don't use the same battery.
[01:27:50.720 --> 01:27:51.720]   I don't use the same battery.
[01:27:51.720 --> 01:27:52.720]   I don't use the same battery.
[01:27:52.720 --> 01:27:53.720]   I don't use the same battery.
[01:27:53.720 --> 01:27:54.720]   I don't use the same battery.
[01:27:54.720 --> 01:27:55.720]   I don't use the same battery.
[01:27:55.720 --> 01:27:56.720]   I don't use the same battery.
[01:27:56.720 --> 01:27:57.720]   I don't use the same battery.
[01:27:57.720 --> 01:27:58.720]   I don't use the same battery.
[01:27:58.720 --> 01:27:59.720]   I don't use the same battery.
[01:27:59.720 --> 01:28:00.720]   I don't use the same battery.
[01:28:00.720 --> 01:28:01.720]   I don't use the same battery.
[01:28:01.720 --> 01:28:02.720]   I don't use the same battery.
[01:28:02.720 --> 01:28:03.720]   I don't use the same battery.
[01:28:03.720 --> 01:28:04.720]   I don't use the same battery.
[01:28:04.720 --> 01:28:05.720]   I don't use the same battery.
[01:28:05.720 --> 01:28:06.720]   I don't use the same battery.
[01:28:06.720 --> 01:28:07.720]   I don't use the same battery.
[01:28:07.720 --> 01:28:08.720]   I don't use the same battery.
[01:28:08.720 --> 01:28:09.720]   I don't use the same battery.
[01:28:09.720 --> 01:28:10.720]   I don't use the same battery.
[01:28:10.720 --> 01:28:11.720]   I don't use the same battery.
[01:28:11.720 --> 01:28:12.720]   I don't use the same battery.
[01:28:12.720 --> 01:28:13.720]   I don't use the same battery.
[01:28:13.720 --> 01:28:14.720]   I don't use the same battery.
[01:28:14.720 --> 01:28:15.720]   I don't use the same battery.
[01:28:15.720 --> 01:28:16.720]   I don't use the same battery.
[01:28:16.720 --> 01:28:17.720]   I don't use the same battery.
[01:28:17.720 --> 01:28:18.720]   I don't use the same battery.
[01:28:18.720 --> 01:28:19.720]   I don't use the same battery.
[01:28:19.720 --> 01:28:20.720]   I don't use the same battery.
[01:28:20.720 --> 01:28:21.720]   I don't use the same battery.
[01:28:21.720 --> 01:28:22.720]   I don't use the same battery.
[01:28:22.720 --> 01:28:23.720]   I don't use the same battery.
[01:28:23.720 --> 01:28:24.720]   I don't use the same battery.
[01:28:24.720 --> 01:28:25.720]   I don't use the same battery.
[01:28:25.720 --> 01:28:26.720]   I don't use the same battery.
[01:28:26.720 --> 01:28:27.720]   I don't use the same battery.
[01:28:27.720 --> 01:28:28.720]   I don't use the same battery.
[01:28:28.720 --> 01:28:29.720]   I don't use the same battery.
[01:28:29.720 --> 01:28:30.720]   I don't use the same battery.
[01:28:30.720 --> 01:28:31.720]   I don't use the same battery.
[01:28:31.720 --> 01:28:32.720]   I don't use the same battery.
[01:28:32.720 --> 01:28:33.720]   I don't use the same battery.
[01:28:33.720 --> 01:28:34.720]   I don't use the same battery.
[01:28:34.720 --> 01:28:35.720]   I don't use the same battery.
[01:28:35.720 --> 01:28:36.720]   I don't use the same battery.
[01:28:36.720 --> 01:28:37.720]   I don't use the same battery.
[01:28:37.720 --> 01:28:38.720]   I don't use the same battery.
[01:28:38.720 --> 01:28:39.720]   I don't use the same battery.
[01:28:39.720 --> 01:28:40.720]   I don't use the same battery.
[01:28:40.720 --> 01:28:41.720]   I don't use the same battery.
[01:28:41.720 --> 01:28:42.720]   I don't use the same battery.
[01:28:42.720 --> 01:28:43.720]   I don't use the same battery.
[01:28:43.720 --> 01:28:44.720]   I don't use the same battery.
[01:28:44.720 --> 01:28:45.720]   I don't use the same battery.
[01:28:45.720 --> 01:28:46.720]   I don't use the same battery.
[01:28:46.720 --> 01:28:47.720]   I don't use the same battery.
[01:28:47.720 --> 01:28:48.720]   I don't use the same battery.
[01:28:48.720 --> 01:28:49.720]   I don't use the same battery.
[01:28:49.720 --> 01:28:50.720]   I don't use the same battery.
[01:28:50.720 --> 01:28:51.720]   I don't use the same battery.
[01:28:51.720 --> 01:28:52.720]   I don't use the same battery.
[01:28:52.720 --> 01:28:53.720]   I don't use the same battery.
[01:28:53.720 --> 01:28:54.720]   I don't use the same battery.
[01:28:54.720 --> 01:28:55.720]   I don't use the same battery.
[01:28:55.720 --> 01:28:56.720]   I don't use the same battery.
[01:28:56.720 --> 01:28:57.720]   I don't use the same battery.
[01:28:57.720 --> 01:28:58.720]   I don't use the same battery.
[01:28:58.720 --> 01:28:59.720]   I don't use the same battery.
[01:28:59.720 --> 01:29:01.720]   It feels to me like Google.
[01:29:01.720 --> 01:29:02.720]   You're right.
[01:29:02.720 --> 01:29:03.720]   They must have been working on this all along.
[01:29:03.720 --> 01:29:07.720]   It feels to me almost a desperation move like, "Oh God, we made this too expensive."
[01:29:07.720 --> 01:29:08.720]   No, no, no.
[01:29:08.720 --> 01:29:09.720]   I don't think so.
[01:29:09.720 --> 01:29:10.720]   You don't think so?
[01:29:10.720 --> 01:29:11.720]   I think.
[01:29:11.720 --> 01:29:13.720]   They all along planned to have kind of a high end and a mid-range phone.
[01:29:13.720 --> 01:29:17.920]   They needed this for the developer set as well because there was no way that they were
[01:29:17.920 --> 01:29:19.920]   going to have a phone that cost that much money for developers.
[01:29:19.920 --> 01:29:20.920]   That's what Nexus always was.
[01:29:20.920 --> 01:29:21.920]   That's what Nexus always was.
[01:29:21.920 --> 01:29:22.920]   That's what Nexus always was.
[01:29:22.920 --> 01:29:23.920]   It is.
[01:29:23.920 --> 01:29:26.440]   There were at least a couple of Googlers that I spoke to that I didn't have to mention
[01:29:26.440 --> 01:29:27.440]   Nexus.
[01:29:27.440 --> 01:29:28.440]   They were the ones that mentioned it.
[01:29:28.440 --> 01:29:29.440]   What is Nexus?
[01:29:29.440 --> 01:29:32.440]   No, because then it doesn't have consumer.
[01:29:32.440 --> 01:29:36.520]   Then it doesn't have consumer appeal because this one you put it.
[01:29:36.520 --> 01:29:37.520]   It's the pixel.
[01:29:37.520 --> 01:29:38.520]   It's the same pixel.
[01:29:38.520 --> 01:29:39.520]   You know that great camera.
[01:29:39.520 --> 01:29:40.520]   Look at the colors.
[01:29:40.520 --> 01:29:41.520]   Seriously.
[01:29:41.520 --> 01:29:45.200]   I've been using the 3A since Tuesday when we got them.
[01:29:45.200 --> 01:29:50.240]   I ended up with the same case as I have on my 3XL, right?
[01:29:50.240 --> 01:29:52.680]   My sims over here in the 3A.
[01:29:52.680 --> 01:29:54.560]   I really would not know the difference.
[01:29:54.560 --> 01:29:58.720]   In my daily use I've been using the 3A and it's very rarely that I'm like, "Oh yeah,
[01:29:58.720 --> 01:29:59.720]   that's right.
[01:29:59.720 --> 01:30:00.720]   I'm on the 3A.
[01:30:00.720 --> 01:30:01.720]   I still kind of think I'm using the same phone."
[01:30:01.720 --> 01:30:03.640]   Honestly, that's the problem with this.
[01:30:03.640 --> 01:30:04.640]   Yeah.
[01:30:04.640 --> 01:30:08.600]   Well, I think it's kind of interesting that they did that because in some ways they're
[01:30:08.600 --> 01:30:10.600]   shooting themselves in the foot on the right way.
[01:30:10.600 --> 01:30:11.600]   Why game war?
[01:30:11.600 --> 01:30:14.360]   At this point, most people are going to say, "Well, you get the camera."
[01:30:14.360 --> 01:30:19.280]   That's really, at the end of the day, that's the big selling point of pixel right now.
[01:30:19.280 --> 01:30:20.280]   Is that excellent camera?
[01:30:20.280 --> 01:30:21.280]   And the assistant.
[01:30:21.280 --> 01:30:22.880]   The integration of the assistant.
[01:30:22.880 --> 01:30:23.880]   Sure.
[01:30:23.880 --> 01:30:27.240]   Yeah, and the software, Google's dedication to top-grained software.
[01:30:27.240 --> 01:30:31.880]   You're getting the Google experience is what I mean versus Samsung's version versus OnePlus's
[01:30:31.880 --> 01:30:32.880]   version.
[01:30:32.880 --> 01:30:33.880]   Yeah.
[01:30:33.880 --> 01:30:35.120]   And for me, that was always a big day.
[01:30:35.120 --> 01:30:40.720]   I should point out, I have to say, that this quarter smartphone sales in North America
[01:30:40.720 --> 01:30:43.240]   fell more than ever in history.
[01:30:43.240 --> 01:30:44.240]   Oh, interesting.
[01:30:44.240 --> 01:30:45.840]   People are running out of money.
[01:30:45.840 --> 01:30:48.520]   People don't want to buy smartphones.
[01:30:48.520 --> 01:30:50.520]   Or their phones are good enough.
[01:30:50.520 --> 01:30:52.440]   It's Apple, but it's also Samsung.
[01:30:52.440 --> 01:30:56.080]   It's also all the other phones.
[01:30:56.080 --> 01:31:00.240]   Oh, my friends on Apple phones, they're using three-year-old, four-year-old iPhones because
[01:31:00.240 --> 01:31:03.520]   to them, they spent $1,000 on that thing.
[01:31:03.520 --> 01:31:05.680]   That's the problem when you make them that expensive.
[01:31:05.680 --> 01:31:06.680]   Okay.
[01:31:06.680 --> 01:31:08.280]   And don't give people a look at it.
[01:31:08.280 --> 01:31:10.080]   And they don't give you a compelling reason to upgrade.
[01:31:10.080 --> 01:31:11.840]   That's the other problem, right?
[01:31:11.840 --> 01:31:13.200]   So in fact, you started saying that.
[01:31:13.200 --> 01:31:18.600]   How are they going to, how's Google going to get people into the stores in this fall?
[01:31:18.600 --> 01:31:21.840]   What are they going to do with the Pixel 4 that's going to make people buy one?
[01:31:21.840 --> 01:31:22.840]   Well, yeah.
[01:31:22.840 --> 01:31:23.920]   I mean, I'm curious to find out.
[01:31:23.920 --> 01:31:28.240]   I think that they kind of hinted a little bit to what we'll see in the Pixel 4 in the
[01:31:28.240 --> 01:31:32.720]   keynote where they were talking about moving more of the machine language onto the device.
[01:31:32.720 --> 01:31:37.880]   That assistant demo from what I understand was done on a device that's still unidentified.
[01:31:37.880 --> 01:31:45.680]   And so I'm guessing that the 4 is going to hinge a lot more around speed along with the
[01:31:45.680 --> 01:31:48.560]   smarts of their software, their AI happening on device.
[01:31:48.560 --> 01:31:50.320]   So that you've got your mid-ranger.
[01:31:50.320 --> 01:31:51.760]   I can do a lot of really neat things.
[01:31:51.760 --> 01:31:54.480]   But if you get the premium one, you can do things faster.
[01:31:54.480 --> 01:31:56.360]   You can do things more securely.
[01:31:56.360 --> 01:31:58.520]   So much more of that is moved onto the device.
[01:31:58.520 --> 01:32:02.480]   And not to mention, they really need to, like this single camera approach has been awesome.
[01:32:02.480 --> 01:32:06.440]   I mean, they've done a lot with it because they have the software to back it up.
[01:32:06.440 --> 01:32:09.680]   But they need to get with the times and realize that, you know, these other phones that they're
[01:32:09.680 --> 01:32:12.120]   competing with do have multiple cameras.
[01:32:12.120 --> 01:32:13.960]   And those are actually in demand.
[01:32:13.960 --> 01:32:14.960]   People want a wide.
[01:32:14.960 --> 01:32:16.560]   People want an optical zoom.
[01:32:16.560 --> 01:32:21.240]   So take your software, your amazing image software and apply it to these multiple cameras.
[01:32:21.240 --> 01:32:22.240]   Take your machine.
[01:32:22.240 --> 01:32:25.640]   And then people have more of a reason to believe that Pixel is the phone camera.
[01:32:25.640 --> 01:32:27.960]   Is that going to be a 5G phone before?
[01:32:27.960 --> 01:32:29.280]   Oh, the 4?
[01:32:29.280 --> 01:32:30.720]   That's a good question.
[01:32:30.720 --> 01:32:31.720]   I don't know.
[01:32:31.720 --> 01:32:36.120]   I feel like right now if phones are 5G, it's like, oh, and we have this 5G model because
[01:32:36.120 --> 01:32:37.280]   5G is still nothing.
[01:32:37.280 --> 01:32:39.520]   I mean, Android Q will be like a pad wall.
[01:32:39.520 --> 01:32:42.080]   But yeah, that'll depend on...
[01:32:42.080 --> 01:32:43.080]   Do you think enough?
[01:32:43.080 --> 01:32:44.080]   Yeah.
[01:32:44.080 --> 01:32:47.480]   I think the phones will have 5G in 2020 that they'll...
[01:32:47.480 --> 01:32:48.680]   Not where it matters.
[01:32:48.680 --> 01:32:49.680]   Not where it matters.
[01:32:49.680 --> 01:32:50.680]   It's not.
[01:32:50.680 --> 01:32:52.880]   It's bullshit until 2021.
[01:32:52.880 --> 01:32:53.880]   Yeah.
[01:32:53.880 --> 01:32:59.920]   Actually, one analyst I saw, I don't remember who it was, said, by the year 2025, an entire
[01:32:59.920 --> 01:33:03.760]   30% of America will be able to get 5G.
[01:33:03.760 --> 01:33:06.320]   That's six years from now, 30%.
[01:33:06.320 --> 01:33:07.320]   So long game.
[01:33:07.320 --> 01:33:08.320]   I doubt very much Apple's...
[01:33:08.320 --> 01:33:12.400]   Meanwhile in Europe, Apple's probably not going to do a 5G phone next year, maybe not
[01:33:12.400 --> 01:33:15.160]   even for a few years.
[01:33:15.160 --> 01:33:16.160]   I doubt...
[01:33:16.160 --> 01:33:20.440]   I mean, maybe Apple will because there's some evidence that that's why they kicked the
[01:33:20.440 --> 01:33:22.960]   Intel to the curb and signed a deal with Qualcomm.
[01:33:22.960 --> 01:33:27.080]   We think it's going to be 2020 for the 5G iPhone.
[01:33:27.080 --> 01:33:29.920]   So not this year's phone, but the next year's phone.
[01:33:29.920 --> 01:33:30.920]   Yeah.
[01:33:30.920 --> 01:33:33.680]   But who's going to drive that if you can't get 5G?
[01:33:33.680 --> 01:33:34.680]   Verizon.
[01:33:34.680 --> 01:33:36.520]   Well, I think that was...
[01:33:36.520 --> 01:33:40.640]   That may have been part of the thing with the settlement with Qualcomm because Intel was
[01:33:40.640 --> 01:33:42.400]   failing in the delivery.
[01:33:42.400 --> 01:33:45.840]   No, it's pretty clear that's why Apple said finally, "Okay, fine."
[01:33:45.840 --> 01:33:46.840]   Yeah.
[01:33:46.840 --> 01:33:47.920]   And it's great that those...
[01:33:47.920 --> 01:33:52.440]   It's great that those two got together again because they really need each other.
[01:33:52.440 --> 01:33:54.360]   Well, it was only hurting each other.
[01:33:54.360 --> 01:33:55.360]   They were hurting each other.
[01:33:55.360 --> 01:33:56.360]   Yeah.
[01:33:56.360 --> 01:34:02.120]   And it got kind of ugly and there were egos involved and they're much better off now.
[01:34:02.120 --> 01:34:03.840]   So I think that might make up...
[01:34:03.840 --> 01:34:06.600]   You know, it might pave the way for the 2020 iPhone.
[01:34:06.600 --> 01:34:07.880]   I think that's what they wanted to do.
[01:34:07.880 --> 01:34:09.320]   Yeah, but again.
[01:34:09.320 --> 01:34:13.760]   So great, you got a 5G phone, but there's no carrier in your neighborhood that's carrying
[01:34:13.760 --> 01:34:14.760]   it doing 5G.
[01:34:14.760 --> 01:34:15.760]   What's the...
[01:34:15.760 --> 01:34:20.320]   And in fact, by the way, there's structural problems with 5G.
[01:34:20.320 --> 01:34:24.960]   You got to put in a hell of a lot more sites because it doesn't go very far.
[01:34:24.960 --> 01:34:28.880]   And there's not really much evidence that even when you do get 5G, it's not going to
[01:34:28.880 --> 01:34:31.160]   be necessarily even faster.
[01:34:31.160 --> 01:34:36.720]   So you're going to have to convince consumers there's a reason to pay for a 5G phone besides
[01:34:36.720 --> 01:34:37.960]   bragging rights.
[01:34:37.960 --> 01:34:38.960]   Yeah.
[01:34:38.960 --> 01:34:39.960]   I think that's...
[01:34:39.960 --> 01:34:47.680]   I think there's pressure on carriers right now to start getting some of the money back
[01:34:47.680 --> 01:34:53.160]   out of their investment in 5G because the equipment is expensive, the radio density
[01:34:53.160 --> 01:34:54.160]   is higher.
[01:34:54.160 --> 01:34:57.440]   And I think there's pressure from Wall Street on them to start.
[01:34:57.440 --> 01:35:01.600]   And I think that's why they're out there spreading the BS about 5G.
[01:35:01.600 --> 01:35:02.600]   5GE.
[01:35:02.600 --> 01:35:03.600]   Yeah.
[01:35:03.600 --> 01:35:05.080]   That's AT&T's fake 5G.
[01:35:05.080 --> 01:35:06.080]   Yeah.
[01:35:06.080 --> 01:35:07.080]   And...
[01:35:07.080 --> 01:35:08.080]   So maybe that's it.
[01:35:08.080 --> 01:35:11.200]   And they're not the only ones that are doing that either.
[01:35:11.200 --> 01:35:15.680]   So yeah, it's going to be...
[01:35:15.680 --> 01:35:20.920]   It's not going to be 2020 before it's fully ready to go.
[01:35:20.920 --> 01:35:24.960]   Unless you live in a major metropolitan area, you're not going to have access to 5G.
[01:35:24.960 --> 01:35:31.280]   And I predict even if you do, because of the cost of putting in enough 5G cell sites to
[01:35:31.280 --> 01:35:33.960]   make it faster, you won't even see faster.
[01:35:33.960 --> 01:35:35.960]   Maybe you'll see lower latency.
[01:35:35.960 --> 01:35:40.160]   But honestly, nowadays, if you've got LTE, you're probably as fast as you need to be.
[01:35:40.160 --> 01:35:43.560]   What are people doing that they need to be more than 20 or 30 megabits?
[01:35:43.560 --> 01:35:45.560]   Some of us like to stream.
[01:35:45.560 --> 01:35:46.560]   20...
[01:35:46.560 --> 01:35:48.960]   You can watch Netflix on your phone.
[01:35:48.960 --> 01:35:50.760]   Especially on the screen this big.
[01:35:50.760 --> 01:35:52.160]   Like you don't need to stream 4K.
[01:35:52.160 --> 01:35:54.480]   Or maybe you do.
[01:35:54.480 --> 01:35:55.480]   I don't know.
[01:35:55.480 --> 01:36:00.960]   I feel like we're being sold to a bill of goods with 5G, honestly.
[01:36:00.960 --> 01:36:01.960]   We mentioned EMMs.
[01:36:01.960 --> 01:36:07.920]   Actually, let's finish Google I/O, and then I'll talk about the sad story of the Tesla
[01:36:07.920 --> 01:36:11.760]   EMMC Media Control Unit.
[01:36:11.760 --> 01:36:14.960]   There's a tease that keeps nobody listening.
[01:36:14.960 --> 01:36:15.960]   Boom!
[01:36:15.960 --> 01:36:19.440]   I don't care.
[01:36:19.440 --> 01:36:20.440]   We mentioned Euphonia.
[01:36:20.440 --> 01:36:23.200]   We mentioned a smarter assistant.
[01:36:23.200 --> 01:36:29.400]   Interestingly, Google's going to add some privacy features, including the "I'm having an
[01:36:29.400 --> 01:36:33.400]   affair" mode.
[01:36:33.400 --> 01:36:34.400]   What is it?
[01:36:34.400 --> 01:36:36.040]   The Ashley Madison?
[01:36:36.040 --> 01:36:37.040]   Madison feature.
[01:36:37.040 --> 01:36:39.040]   The incognito mode in Maps.
[01:36:39.040 --> 01:36:40.040]   Maps.
[01:36:40.040 --> 01:36:41.040]   I don't know.
[01:36:41.040 --> 01:36:42.040]   I didn't go there.
[01:36:42.040 --> 01:36:44.040]   That was great.
[01:36:44.040 --> 01:36:45.040]   Maps and Search.
[01:36:45.040 --> 01:36:47.480]   The Addis Ashley Madison feature.
[01:36:47.480 --> 01:36:51.400]   I'm waiting for incognito mode on the OS level in Android.
[01:36:51.400 --> 01:36:52.400]   Yeah, that would be better.
[01:36:52.400 --> 01:36:53.400]   Throw it into my quick settings.
[01:36:53.400 --> 01:36:54.400]   Yeah, let's go for weird things.
[01:36:54.400 --> 01:36:58.920]   People overestimate the anonymity of incognito mode, by the way.
[01:36:58.920 --> 01:36:59.920]   Yeah, that's true.
[01:36:59.920 --> 01:37:00.920]   Yeah.
[01:37:00.920 --> 01:37:01.920]   It's not really incognito.
[01:37:01.920 --> 01:37:02.920]   Right.
[01:37:02.920 --> 01:37:06.120]   It's just really hiding your history from your spouse, I think.
[01:37:06.120 --> 01:37:07.120]   Mostly.
[01:37:07.120 --> 01:37:09.800]   Google knows where you are, your ISP knows where you are.
[01:37:09.800 --> 01:37:13.960]   The police know where you are.
[01:37:13.960 --> 01:37:14.960]   Let's see, what else?
[01:37:14.960 --> 01:37:17.040]   Oh, this is a surprise.
[01:37:17.040 --> 01:37:22.640]   Cross-site tracking is going to be blockable and Chrome.
[01:37:22.640 --> 01:37:24.440]   Google's really balancing this.
[01:37:24.440 --> 01:37:28.880]   What does AdTech need with what do consumers want?
[01:37:28.880 --> 01:37:30.760]   And so far, I kind of like the direction.
[01:37:30.760 --> 01:37:33.720]   They're moving a little bit more towards consumers.
[01:37:33.720 --> 01:37:38.200]   They're also solving this big problem with Android security by moving more and more
[01:37:38.200 --> 01:37:39.960]   components into the Play Store.
[01:37:39.960 --> 01:37:40.960]   Absolutely.
[01:37:40.960 --> 01:37:42.920]   You're talking about Project Mainline?
[01:37:42.920 --> 01:37:48.040]   Mainline, as far as like my walk away, one of the things I'm most excited about is Project
[01:37:48.040 --> 01:37:49.040]   Mainline.
[01:37:49.040 --> 01:37:55.360]   This is, I think it promises to be even more along the lines of what Project Tango started
[01:37:55.360 --> 01:37:56.840]   a couple of years ago as far as--
[01:37:56.840 --> 01:37:57.840]   Tri-
[01:37:57.840 --> 01:37:58.840]   Sorry, not Tango.
[01:37:58.840 --> 01:37:58.840]   Tri-
[01:37:58.840 --> 01:38:01.560]   Tango's long gone at this point.
[01:38:01.560 --> 01:38:04.440]   Too many projects that Google killed, by the way.
[01:38:04.440 --> 01:38:04.440]   Tri-
[01:38:04.440 --> 01:38:05.440]   Travel.
[01:38:05.440 --> 01:38:10.880]   Componentizing the OS, Mainline is further doing that and updating in the background.
[01:38:10.880 --> 01:38:17.120]   I just think as far as security updates, which has long been such a huge critical thing
[01:38:17.120 --> 01:38:22.720]   with Android, failing miserably at keeping phones updated when it comes to security.
[01:38:22.720 --> 01:38:29.520]   This has the potential to help because they worked with OEMs.
[01:38:29.520 --> 01:38:35.040]   Essentially, if an OEMs can install Q on the device, it has to be okay with the fact that
[01:38:35.040 --> 01:38:38.600]   this is happening underneath the scenes.
[01:38:38.600 --> 01:38:43.760]   If this was in place when stage fright happened, then Google could have easily pushed out an
[01:38:43.760 --> 01:38:47.360]   update to the media codec and it never would have been an issue.
[01:38:47.360 --> 01:38:48.840]   What have been a fright?
[01:38:48.840 --> 01:38:52.240]   But to play the other stage games.
[01:38:52.240 --> 01:38:53.840]   It starts with Q.
[01:38:53.840 --> 01:38:59.080]   So the vast majority of Android phones, which are still on Android 4, Android 3, Android
[01:38:59.080 --> 01:39:01.320]   5, Android 6, never will get updates.
[01:39:01.320 --> 01:39:04.080]   We don't know that site hasn't been updated in a while.
[01:39:04.080 --> 01:39:05.880]   No, it has actually now it has.
[01:39:05.880 --> 01:39:06.880]   They have updated.
[01:39:06.880 --> 01:39:09.560]   I've got a platform members that have updated.
[01:39:09.560 --> 01:39:11.120]   Yeah, they have updated for us.
[01:39:11.120 --> 01:39:15.000]   You know, in a way, I thought, oh, Treble and Mainline, the idea will be to get these
[01:39:15.000 --> 01:39:19.000]   old Android phones, at least up to snuff, then never be on this stuff.
[01:39:19.000 --> 01:39:20.000]   It's here forward.
[01:39:20.000 --> 01:39:22.640]   So it's kind of a trailing edge.
[01:39:22.640 --> 01:39:28.240]   You're going to, well, in a few years, phones sold from now on will be upgradable.
[01:39:28.240 --> 01:39:29.240]   Yeah, yeah.
[01:39:29.240 --> 01:39:30.240]   That's better than nothing.
[01:39:30.240 --> 01:39:31.240]   Better than nothing.
[01:39:31.240 --> 01:39:32.240]   You could do this.
[01:39:32.240 --> 01:39:34.520]   What happens when you have an open source iOS?
[01:39:34.520 --> 01:39:37.000]   There's nothing you can do about it.
[01:39:37.000 --> 01:39:38.520]   We're always living in the future.
[01:39:38.520 --> 01:39:40.320]   We're living for the future.
[01:39:40.320 --> 01:39:41.720]   Yeah, exactly.
[01:39:41.720 --> 01:39:44.800]   Living in a man.
[01:39:44.800 --> 01:39:45.800]   Anything else?
[01:39:45.800 --> 01:39:47.680]   Oh, this is a big story.
[01:39:47.680 --> 01:39:49.520]   And I didn't fully grasp this.
[01:39:49.520 --> 01:39:53.640]   I'm not hoping that maybe you can explain it.
[01:39:53.640 --> 01:39:55.880]   I thought this was just rebranding.
[01:39:55.880 --> 01:39:59.840]   Basically Nest is now Google Nest.
[01:39:59.840 --> 01:40:00.840]   Yes.
[01:40:00.840 --> 01:40:05.480]   But what is dying really is works with Nest.
[01:40:05.480 --> 01:40:06.480]   Yes.
[01:40:06.480 --> 01:40:08.760]   And the notion of IoT divide.
[01:40:08.760 --> 01:40:12.920]   For a long time, Google said Nest is going to, when they acquired it, it's an independent
[01:40:12.920 --> 01:40:16.040]   company, Tony Fidell, when he was still running Nest.
[01:40:16.040 --> 01:40:21.400]   Don't worry, we're never going to share the information from our cameras, our smart thermostats.
[01:40:21.400 --> 01:40:24.000]   We're never going to share that with Google.
[01:40:24.000 --> 01:40:27.040]   Last year, Google said, "Come here."
[01:40:27.040 --> 01:40:28.920]   And made Nest part of Google.
[01:40:28.920 --> 01:40:31.880]   This year, they're even basically saying they works with Nest.
[01:40:31.880 --> 01:40:32.880]   Thing is dead.
[01:40:32.880 --> 01:40:35.160]   It's all Google now.
[01:40:35.160 --> 01:40:39.240]   And I wonder if people are going to be aware of that.
[01:40:39.240 --> 01:40:44.840]   I mean, they're going to be aware of the very infelicitous naming, like the Nest X Yale
[01:40:44.840 --> 01:40:46.560]   lock with Google Nest Connect.
[01:40:46.560 --> 01:40:48.360]   Ah, just rolls off the tongue.
[01:40:48.360 --> 01:40:50.680]   Google Nest Hub Max.
[01:40:50.680 --> 01:40:52.360]   But more than that, I think that--
[01:40:52.360 --> 01:40:53.760]   Google Nest Cam I came out of it.
[01:40:53.760 --> 01:40:55.560]   Nest is gone, right?
[01:40:55.560 --> 01:40:59.200]   This is the beginning of the end for the idea of Nest as a separate company.
[01:40:59.200 --> 01:41:00.200]   Ish.
[01:41:00.200 --> 01:41:01.200]   Ish.
[01:41:01.200 --> 01:41:02.680]   It is the beginning of the end as a separate company.
[01:41:02.680 --> 01:41:06.760]   So I'm actually looking into this right now because the article--
[01:41:06.760 --> 01:41:10.360]   Ronald, Ronald, Mario said Nest's smart home platform is dead.
[01:41:10.360 --> 01:41:11.360]   Yes.
[01:41:11.360 --> 01:41:12.360]   So it's, OK, fine.
[01:41:12.360 --> 01:41:13.360]   Nest is dead.
[01:41:13.360 --> 01:41:14.800]   But it's not dead.
[01:41:14.800 --> 01:41:15.800]   It's still there.
[01:41:15.800 --> 01:41:16.800]   It's just Google Assistant now.
[01:41:16.800 --> 01:41:17.800]   It's not dead yet.
[01:41:17.800 --> 01:41:19.000]   It's not dead yet.
[01:41:19.000 --> 01:41:23.040]   It's just unifying these two different platforms to make it easier.
[01:41:23.040 --> 01:41:25.360]   First of all, for marketing, it's going to make it much easier.
[01:41:25.360 --> 01:41:30.600]   It's going to make it easier for smart home novices to kind of understand what works
[01:41:30.600 --> 01:41:32.240]   with their products.
[01:41:32.240 --> 01:41:37.400]   And it's also worth mentioning that the technology that's in this Nest Hub Max, which has a camera
[01:41:37.400 --> 01:41:41.960]   in it, is not at all like the technology that's inside a Nest security camera, which
[01:41:41.960 --> 01:41:43.000]   costs about the same.
[01:41:43.000 --> 01:41:47.080]   So I asked for some clarification on this and how it works.
[01:41:47.080 --> 01:41:49.160]   It's a completely different facial algorithm.
[01:41:49.160 --> 01:41:50.160]   Oh, interesting.
[01:41:50.160 --> 01:41:51.160]   So you actually--
[01:41:51.160 --> 01:41:52.880]   Because it sounded like a Nest camera built into the hub.
[01:41:52.880 --> 01:41:53.880]   It's not.
[01:41:53.880 --> 01:41:54.880]   I asked about that.
[01:41:54.880 --> 01:42:00.520]   I said, OK, so from what I understand is that you can go into the Nest app and view the
[01:42:00.520 --> 01:42:05.440]   camera feed just to have it there if your concern is security because you still have
[01:42:05.440 --> 01:42:06.440]   to ask that.
[01:42:06.440 --> 01:42:08.760]   And they did say it would recognize people like the Nest IQ does.
[01:42:08.760 --> 01:42:11.720]   Yes, but you have to-- but you have to have them.
[01:42:11.720 --> 01:42:13.440]   You have to record the face.
[01:42:13.440 --> 01:42:15.600]   So you have to teach it the faces in your house.
[01:42:15.600 --> 01:42:17.440]   Oh, it's all done on device.
[01:42:17.440 --> 01:42:18.440]   It's all onto it.
[01:42:18.440 --> 01:42:21.240]   So the Nest IQ-- and by the way, it never worked as far as I could tell, theoretically
[01:42:21.240 --> 01:42:24.160]   would start to recognize you after a while.
[01:42:24.160 --> 01:42:25.160]   It does work.
[01:42:25.160 --> 01:42:27.160]   It works very well with Nest Hello.
[01:42:27.160 --> 01:42:28.160]   There it is.
[01:42:28.160 --> 01:42:30.320]   And Nest Hello works particularly well.
[01:42:30.320 --> 01:42:31.320]   That's the doorbell.
[01:42:31.320 --> 01:42:35.360]   Yes, the doorbell, which is the same camera infrastructure.
[01:42:35.360 --> 01:42:37.640]   And you don't have to pay for this camera either.
[01:42:37.640 --> 01:42:41.240]   So you don't have to pay for Nest Aware if you want to keep any of this pretty minute.
[01:42:41.240 --> 01:42:44.560]   Nope, it's just completely the idea.
[01:42:44.560 --> 01:42:50.520]   So Mario says that works with Nest-- the website says works with Nest is winding down.
[01:42:50.520 --> 01:42:51.520]   Yes.
[01:42:51.520 --> 01:42:52.520]   Ecosystem.
[01:42:52.520 --> 01:42:53.520]   And this is the concern.
[01:42:53.520 --> 01:42:55.920]   We'll shut down August 31.
[01:42:55.920 --> 01:43:00.560]   Does that mean if you have works with Nest things like this IQ camera, it's going to stop
[01:43:00.560 --> 01:43:01.560]   working?
[01:43:01.560 --> 01:43:02.560]   No.
[01:43:02.560 --> 01:43:05.120]   They're going to transfer it over to Google.
[01:43:05.120 --> 01:43:07.800]   We need to get-- I'm working on getting clarification for that.
[01:43:07.800 --> 01:43:10.520]   I'm actually doing some independent reporting of my own right now.
[01:43:10.520 --> 01:43:13.280]   But everybody is very tired after the Google I/O.
[01:43:13.280 --> 01:43:17.280]   So we're giving them a break right now.
[01:43:17.280 --> 01:43:21.760]   But from what I understand is you're still going to have to pay for the aware subscription
[01:43:21.760 --> 01:43:24.600]   to be able to have those features.
[01:43:24.600 --> 01:43:27.400]   Because there's a security system to take into account.
[01:43:27.400 --> 01:43:28.760]   There's a thermostat.
[01:43:28.760 --> 01:43:32.080]   There are smoke detectors.
[01:43:32.080 --> 01:43:34.560]   It's a whole ecosystem of home things.
[01:43:34.560 --> 01:43:41.360]   But I think they're just bringing the Nest in because that brand loyalty exists everywhere
[01:43:41.360 --> 01:43:42.360]   now.
[01:43:42.360 --> 01:43:43.360]   People know Nest.
[01:43:43.360 --> 01:43:48.680]   They don't necessarily know maybe that Google is a big driving force behind it.
[01:43:48.680 --> 01:43:55.040]   So Lutron, which is a works with Nest Lite switch thing, sent a notice to its customers
[01:43:55.040 --> 01:44:00.360]   saying the ability to automate lighting function based on the Nest's home and away status.
[01:44:00.360 --> 01:44:04.400]   Smaller alerts from Nest cameras are smoking carbon monoxide detection from a next protect
[01:44:04.400 --> 01:44:06.640]   will be affected by the change.
[01:44:06.640 --> 01:44:12.160]   It will remove the ability to control the Nest that from within the Lutron app.
[01:44:12.160 --> 01:44:14.840]   This is Dan Seifert writing on the Verge.
[01:44:14.840 --> 01:44:19.280]   Echo won't be able to adjust the thermostat anymore after August 31 or display Nest Cam
[01:44:19.280 --> 01:44:20.480]   feeds.
[01:44:20.480 --> 01:44:23.080]   So this is that ecosystem, third-party ecosystem.
[01:44:23.080 --> 01:44:28.000]   Logitech Harmony remotes won't be able to change Nest alarm and home away modes.
[01:44:28.000 --> 01:44:31.960]   Few lights will not be able to change color when Nest protect detects smoke or carbon
[01:44:31.960 --> 01:44:32.960]   monoxide.
[01:44:32.960 --> 01:44:36.720]   These are things I didn't rely on, but I bet you a lot of people set up homes.
[01:44:36.720 --> 01:44:39.120]   I have to do all this.
[01:44:39.120 --> 01:44:40.880]   Are you concerned that everything's going to break?
[01:44:40.880 --> 01:44:41.880]   No.
[01:44:41.880 --> 01:44:44.080]   You think Google is going to come?
[01:44:44.080 --> 01:44:46.320]   We're going to get a second post from Google that says, Oh, don't worry.
[01:44:46.320 --> 01:44:47.600]   We're going to take over those features.
[01:44:47.600 --> 01:44:48.600]   Yes.
[01:44:48.600 --> 01:44:49.600]   Okay.
[01:44:49.600 --> 01:44:50.600]   Good.
[01:44:50.600 --> 01:44:52.360]   Because I from what I understand, it's like I have TTT.
[01:44:52.360 --> 01:44:56.640]   So a lot of these things that are mentioned are little IFTTT triggers.
[01:44:56.640 --> 01:45:03.320]   And that is going away because Nest is just going to go away, but they're going to replace
[01:45:03.320 --> 01:45:04.960]   it with the Google Assistant.
[01:45:04.960 --> 01:45:09.760]   So they have a Google in effect, a Google IFTTT inside.
[01:45:09.760 --> 01:45:11.520]   They already do with routines.
[01:45:11.520 --> 01:45:12.520]   Okay.
[01:45:12.520 --> 01:45:15.840]   But does that mean you're going to have to go through all of these devices instead of
[01:45:15.840 --> 01:45:16.840]   new triggers?
[01:45:16.840 --> 01:45:20.000]   That's what I want clarification on, but I'm going to think that probably yes, and I
[01:45:20.000 --> 01:45:26.200]   know that's annoying, but it makes it less fragmented for everybody across the board.
[01:45:26.200 --> 01:45:31.840]   But it is a pain point for people who, you know, look, home automation sucks.
[01:45:31.840 --> 01:45:36.680]   And there are people like you probably more because it's your career than because you
[01:45:36.680 --> 01:45:40.360]   really would do this if you didn't know, I find it very fun.
[01:45:40.360 --> 01:45:44.000]   People like you and Stacey Higginbotham just baffle me.
[01:45:44.000 --> 01:45:48.800]   I just like, I, you know, my nest, my hugh lights turn on when I walk by them.
[01:45:48.800 --> 01:45:51.400]   That's the complete extent of the integration.
[01:45:51.400 --> 01:45:52.400]   Oh, no.
[01:45:52.400 --> 01:45:53.640]   I've got moods.
[01:45:53.640 --> 01:45:56.800]   I've got situations and scenes.
[01:45:56.800 --> 01:46:01.160]   So people like you and we just don't know how many people like you there are.
[01:46:01.160 --> 01:46:06.840]   I know too, but you're going to kind of potentially you're going to be in a world of pain if
[01:46:06.840 --> 01:46:08.600]   you have to go back and set this all up again.
[01:46:08.600 --> 01:46:10.000]   It was bad the first time.
[01:46:10.000 --> 01:46:11.000]   No.
[01:46:11.000 --> 01:46:12.000]   No.
[01:46:12.000 --> 01:46:13.000]   No, because I did it all through the Google assistant.
[01:46:13.000 --> 01:46:14.000]   Okay.
[01:46:14.000 --> 01:46:15.000]   I did.
[01:46:15.000 --> 01:46:17.200]   I went in and I redid it with the Google assistant.
[01:46:17.200 --> 01:46:19.560]   I just linked everything through that.
[01:46:19.560 --> 01:46:22.360]   So that's where I have my routine now.
[01:46:22.360 --> 01:46:27.360]   There's, you, there's some weird gene that you and Stacey and people like you have.
[01:46:27.360 --> 01:46:28.360]   Am I wrong?
[01:46:28.360 --> 01:46:31.080]   I generally, well, because it's my, so I'm.
[01:46:31.080 --> 01:46:32.080]   You don't do this.
[01:46:32.080 --> 01:46:33.080]   Do you Jason?
[01:46:33.080 --> 01:46:34.080]   No, I don't, I don't really go nuts with me.
[01:46:34.080 --> 01:46:35.880]   You must find it very painful.
[01:46:35.880 --> 01:46:36.880]   It's painful.
[01:46:36.880 --> 01:46:38.320]   I'm a home body.
[01:46:38.320 --> 01:46:39.720]   I love to be at home.
[01:46:39.720 --> 01:46:41.720]   I love to work on my home.
[01:46:41.720 --> 01:46:42.720]   It's nesting.
[01:46:42.720 --> 01:46:43.720]   It is.
[01:46:43.720 --> 01:46:44.720]   Oh, whoa.
[01:46:44.720 --> 01:46:45.720]   Wait a minute.
[01:46:45.720 --> 01:46:46.720]   There's some, there's some cross over here.
[01:46:46.720 --> 01:46:49.320]   My Microsoft's word just told me I said a bad thing.
[01:46:49.320 --> 01:46:52.320]   Well, I'm also a tourist.
[01:46:52.320 --> 01:46:53.760]   So I love to sit around.
[01:46:53.760 --> 01:46:55.920]   Is it a kind of nesting do you think?
[01:46:55.920 --> 01:46:56.920]   Absolutely.
[01:46:56.920 --> 01:46:57.920]   Yeah.
[01:46:57.920 --> 01:47:03.560]   That's the entire, so my house, I have, I have set up how all the audio is.
[01:47:03.560 --> 01:47:06.440]   I have set up where there is audio, where there are lights.
[01:47:06.440 --> 01:47:12.160]   I have set up this whole grid in the house for automation because for me, it was another
[01:47:12.160 --> 01:47:18.400]   way to, to invest in my home and to kind of like make it this place that's mine.
[01:47:18.400 --> 01:47:19.400]   Yeah.
[01:47:19.400 --> 01:47:20.400]   That's B.
[01:47:20.400 --> 01:47:22.400]   I love to dance.
[01:47:22.400 --> 01:47:24.720]   It's the new nest.
[01:47:24.720 --> 01:47:27.360]   It's in my DNA.
[01:47:27.360 --> 01:47:30.040]   Do we learn anything about Alexa in this?
[01:47:30.040 --> 01:47:31.760]   I mean, as well.
[01:47:31.760 --> 01:47:32.760]   She's kind of at a lock.
[01:47:32.760 --> 01:47:34.360]   I mean, is she like losing her?
[01:47:34.360 --> 01:47:36.280]   No, it actually says in here.
[01:47:36.280 --> 01:47:38.280]   Where did I see that?
[01:47:38.280 --> 01:47:39.280]   Special treat.
[01:47:39.280 --> 01:47:40.280]   Let's call it Echo.
[01:47:40.280 --> 01:47:44.760]   Currently has two works with Nest skills that allowed to control Nestermostats and cameras.
[01:47:44.760 --> 01:47:48.000]   As a direct competitor, there's Dan C. Furt in the Verge writing.
[01:47:48.000 --> 01:47:51.360]   It's highly unlikely Google will offer support for Echo controls and the new works with
[01:47:51.360 --> 01:47:53.160]   Google Assistant program.
[01:47:53.160 --> 01:47:57.760]   Quote, Google spokesperson, "We're still working on ways for our customers to continue
[01:47:57.760 --> 01:48:01.800]   to use other systems with their Nest products after account migration and when the works
[01:48:01.800 --> 01:48:03.000]   with Nest service shuts down."
[01:48:03.000 --> 01:48:05.040]   In other words, they're equivocating.
[01:48:05.040 --> 01:48:07.000]   They're not saying.
[01:48:07.000 --> 01:48:11.280]   On the Nest support site, there is a page specifically for Amazon.
[01:48:11.280 --> 01:48:17.000]   It says, "We are working with Amazon to migrate the Nest skill on Amazon to ensure a smooth
[01:48:17.000 --> 01:48:18.000]   transition."
[01:48:18.000 --> 01:48:19.000]   Okay.
[01:48:19.000 --> 01:48:20.000]   That's your right.
[01:48:20.000 --> 01:48:21.000]   Prior to winding down the works of Nest for her.
[01:48:21.000 --> 01:48:23.120]   The Nest is undisturbed.
[01:48:23.120 --> 01:48:29.280]   You may continue to build if you have an Amazon.
[01:48:29.280 --> 01:48:30.720]   When you're done, is it depressing?
[01:48:30.720 --> 01:48:31.920]   Do you want to do more?
[01:48:31.920 --> 01:48:32.920]   Yeah.
[01:48:32.920 --> 01:48:33.920]   Yeah.
[01:48:33.920 --> 01:48:35.560]   So you get new stuff so you can nest with it.
[01:48:35.560 --> 01:48:36.560]   Yes.
[01:48:36.560 --> 01:48:39.000]   And because I'm a freelancer, I got to sell work.
[01:48:39.000 --> 01:48:40.000]   You got lots of time.
[01:48:40.000 --> 01:48:41.000]   Okay.
[01:48:41.000 --> 01:48:43.000]   So it's like a sort of business component.
[01:48:43.000 --> 01:48:44.000]   Yes.
[01:48:44.000 --> 01:48:48.240]   This is a business component, but I am a busy person.
[01:48:48.240 --> 01:48:51.120]   I do not have the money to hire help.
[01:48:51.120 --> 01:48:52.120]   I never understood it.
[01:48:52.120 --> 01:48:53.400]   So I invest in these things.
[01:48:53.400 --> 01:48:54.640]   I've never understood it.
[01:48:54.640 --> 01:48:57.040]   And I have bought all of this because I like you.
[01:48:57.040 --> 01:48:58.040]   Right.
[01:48:58.040 --> 01:49:00.920]   I'm trying to make a living doing this, but it's just, oh God.
[01:49:00.920 --> 01:49:04.640]   No, every day, my lights are always on in my bedroom when I need them to be after the
[01:49:04.640 --> 01:49:05.640]   sun has gone down.
[01:49:05.640 --> 01:49:09.960]   What is the thing called a switch that does that?
[01:49:09.960 --> 01:49:10.960]   Why have a switch?
[01:49:10.960 --> 01:49:11.960]   Well, I'm not in the room.
[01:49:11.960 --> 01:49:12.960]   So I walk in.
[01:49:12.960 --> 01:49:13.960]   I flip the switch now.
[01:49:13.960 --> 01:49:14.960]   Right.
[01:49:14.960 --> 01:49:19.240]   But when you're carrying two laundry baskets up the stairs and it is dark upstairs.
[01:49:19.240 --> 01:49:23.960]   That's why you need a motion detector though that when you walk into the room, it flips
[01:49:23.960 --> 01:49:26.880]   on and then when you walk out, it flips off.
[01:49:26.880 --> 01:49:27.880]   Then you save the energy.
[01:49:27.880 --> 01:49:28.880]   They don't like that.
[01:49:28.880 --> 01:49:29.880]   Unfortunately, they don't really work like that.
[01:49:29.880 --> 01:49:33.520]   Unfortunately, my lights just turn on at random times when we sit in the living room.
[01:49:33.520 --> 01:49:35.800]   I was in the lights like a once like, was that a cat?
[01:49:35.800 --> 01:49:36.800]   What happened?
[01:49:36.800 --> 01:49:38.200]   Something ghost walk through.
[01:49:38.200 --> 01:49:39.200]   What happened?
[01:49:39.200 --> 01:49:40.200]   All right.
[01:49:40.200 --> 01:49:41.800]   The ghost thing is.
[01:49:41.800 --> 01:49:42.800]   There are ghosts.
[01:49:42.800 --> 01:49:45.400]   I've been thinking about getting an echo locator.
[01:49:45.400 --> 01:49:47.200]   But anyway, that's there are ghosts.
[01:49:47.200 --> 01:49:48.200]   There are ghosts.
[01:49:48.200 --> 01:49:50.400]   I love to talk about that.
[01:49:50.400 --> 01:49:51.400]   Yes.
[01:49:51.400 --> 01:49:54.000]   Halloween special for later this year.
[01:49:54.000 --> 01:49:56.600]   Anybody here show a hands an Uber millionaire?
[01:49:56.600 --> 01:49:57.600]   Anybody?
[01:49:57.600 --> 01:49:58.840]   Anybody?
[01:49:58.840 --> 01:49:59.920]   There are a few.
[01:49:59.920 --> 01:50:02.440]   There are a few Uber billionaires too.
[01:50:02.440 --> 01:50:03.440]   Uber's IPO.
[01:50:03.440 --> 01:50:06.480]   We're going to talk about that in a second.
[01:50:06.480 --> 01:50:09.680]   You know who was a big investor early on in Uber?
[01:50:09.680 --> 01:50:14.760]   Gary Vaynerchuk and Jason Calicanis.
[01:50:14.760 --> 01:50:15.920]   They're doing all right right now.
[01:50:15.920 --> 01:50:21.280]   It almost makes me throw up in my mouth to think that Gary Vaynerchuk is now a billionaire
[01:50:21.280 --> 01:50:22.680]   because of Uber.
[01:50:22.680 --> 01:50:24.360]   It's just everything wrong with technology.
[01:50:24.360 --> 01:50:28.120]   And I like Gary, but that's just everything wrong with technology.
[01:50:28.120 --> 01:50:31.400]   Fomi, I were a billionaire for being an early adopter.
[01:50:31.400 --> 01:50:35.440]   Olivia Munn, she was an early investor in Uber too.
[01:50:35.440 --> 01:50:36.440]   Wow.
[01:50:36.440 --> 01:50:38.800]   Why did you get your money?
[01:50:38.800 --> 01:50:39.800]   Well, TV.
[01:50:39.800 --> 01:50:40.800]   That's the thing.
[01:50:40.800 --> 01:50:43.120]   You could be an early investor for $100,000.
[01:50:43.120 --> 01:50:44.120]   $100?
[01:50:44.120 --> 01:50:45.120]   No.
[01:50:45.120 --> 01:50:46.120]   No.
[01:50:46.120 --> 01:50:47.120]   No.
[01:50:47.120 --> 01:50:49.120]   No, sue for you.
[01:50:49.120 --> 01:50:51.280]   We'll talk about that.
[01:50:51.280 --> 01:50:52.280]   We will.
[01:50:52.280 --> 01:50:55.400]   It actually was the worst performing IPO in US stock history.
[01:50:55.400 --> 01:50:56.400]   That's the funniest thing.
[01:50:56.400 --> 01:51:00.000]   They lost $6 billion worth of value.
[01:51:00.000 --> 01:51:01.000]   In the first day.
[01:51:01.000 --> 01:51:02.000]   Yeah.
[01:51:02.000 --> 01:51:03.000]   Right?
[01:51:03.000 --> 01:51:04.000]   First five hours.
[01:51:04.000 --> 01:51:05.000]   Nice.
[01:51:05.000 --> 01:51:08.400]   And yet there's like a dozen people that are made billions off of this thing.
[01:51:08.400 --> 01:51:09.400]   Yeah.
[01:51:09.400 --> 01:51:11.560]   It's just something.
[01:51:11.560 --> 01:51:14.000]   There's something weird about this.
[01:51:14.000 --> 01:51:15.880]   Uber has never made money.
[01:51:15.880 --> 01:51:16.880]   Right?
[01:51:16.880 --> 01:51:17.880]   Ever.
[01:51:17.880 --> 01:51:19.880]   They've only lost hundreds of millions of dollars or more.
[01:51:19.880 --> 01:51:20.880]   They bleed it.
[01:51:20.880 --> 01:51:22.960]   They bleed money.
[01:51:22.960 --> 01:51:28.160]   And Jeff Bezos and Elon Musk and yet another Twitter feud.
[01:51:28.160 --> 01:51:29.680]   But first a word from Wasabi.
[01:51:29.680 --> 01:51:33.240]   Actually, before I do the Wasabi, I think we have a, do we have it?
[01:51:33.240 --> 01:51:35.480]   We have the, this is so exciting for me.
[01:51:35.480 --> 01:51:40.760]   We have made a small documentary film about the last few days here at Twit.
[01:51:40.760 --> 01:51:41.760]   Watch.
[01:51:41.760 --> 01:51:42.760]   Previously on Twit.
[01:51:42.760 --> 01:51:45.400]   So today I thought we would talk about memes.
[01:51:45.400 --> 01:51:46.400]   Memes.
[01:51:46.400 --> 01:51:48.520]   Since we're, we're young, we're hip.
[01:51:48.520 --> 01:51:49.520]   We're with it.
[01:51:49.520 --> 01:51:50.520]   We know what the kids are doing.
[01:51:50.520 --> 01:51:51.520]   We know the memes.
[01:51:51.520 --> 01:51:52.520]   Yolo FOMO FTW.
[01:51:52.520 --> 01:51:53.520]   Mm hmm.
[01:51:53.520 --> 01:51:54.520]   I stand for that.
[01:51:54.520 --> 01:51:56.520]   I stand for that.
[01:51:56.520 --> 01:51:58.520]   Twit Live specials.
[01:51:58.520 --> 01:52:04.360]   But what we're excited to announce today is that Edge will offer built in support for
[01:52:04.360 --> 01:52:05.360]   Internet Explorer.
[01:52:05.360 --> 01:52:06.360]   Wait a minute.
[01:52:06.360 --> 01:52:07.360]   50% event of services.
[01:52:07.360 --> 01:52:08.360]   Wait a minute.
[01:52:08.360 --> 01:52:09.360]   Is that inception?
[01:52:09.360 --> 01:52:14.600]   Edge will offer built in support for Internet Explorer.
[01:52:14.600 --> 01:52:18.240]   The site opens in the same window and in the same time.
[01:52:18.240 --> 01:52:20.800]   All of a sudden we're transported back to 1997.
[01:52:20.800 --> 01:52:27.160]   So no more jarring experiences when you hit an internal site that needs Internet Explorer.
[01:52:27.160 --> 01:52:28.160]   Pan John Tech.
[01:52:28.160 --> 01:52:32.160]   Hey, I'm Sam LaBoule-Samit, principal analyst with Navigan Research.
[01:52:32.160 --> 01:52:34.760]   Today we're taking a drive in the Kea Niro EV.
[01:52:34.760 --> 01:52:37.760]   We have plenty of room to use it as an everyday car.
[01:52:37.760 --> 01:52:40.960]   And especially when you consider all the standard features, especially the safety features
[01:52:40.960 --> 01:52:45.320]   like the adaptive cruise, the lane keeping, the blind spot monitor.
[01:52:45.320 --> 01:52:49.040]   This is actually a really good value for what you're getting.
[01:52:49.040 --> 01:52:50.040]   All about Android.
[01:52:50.040 --> 01:52:56.000]   Lauren Zion and I sit down with Steph Cuthbritson and Chet Haas, both from the Google Android
[01:52:56.000 --> 01:52:59.720]   team to talk all about the big announcements at Google I/O.
[01:52:59.720 --> 01:53:03.280]   We really want to give users transparency and control.
[01:53:03.280 --> 01:53:08.120]   You should be able to know who has my data, who can they share it with.
[01:53:08.120 --> 01:53:09.680]   We want to make that really easy.
[01:53:09.680 --> 01:53:10.680]   Twist.
[01:53:10.680 --> 01:53:14.840]   It keeps going and going and going.
[01:53:14.840 --> 01:53:16.640]   She's incredibly smart too.
[01:53:16.640 --> 01:53:17.640]   Is she?
[01:53:17.640 --> 01:53:18.640]   Yeah.
[01:53:18.640 --> 01:53:19.640]   Oh my God.
[01:53:19.640 --> 01:53:20.640]   I was impressed just with her presentation.
[01:53:20.640 --> 01:53:21.640]   Yeah.
[01:53:21.640 --> 01:53:22.640]   I'll have to watch the show.
[01:53:22.640 --> 01:53:23.640]   Yeah.
[01:53:23.640 --> 01:53:24.640]   And that's neat.
[01:53:24.640 --> 01:53:27.080]   By the way, the Niro Car of the Year, according to Part Bear Mechanics.
[01:53:27.080 --> 01:53:28.080]   Popular mechanics.
[01:53:28.080 --> 01:53:32.360]   Our show today brought to you by Hot Cloud Storage.
[01:53:32.360 --> 01:53:33.360]   It's so hot.
[01:53:33.360 --> 01:53:34.360]   It's Wasabi.
[01:53:34.360 --> 01:53:35.360]   Hot.
[01:53:35.360 --> 01:53:38.800]   If you, it's the best name.
[01:53:38.800 --> 01:53:41.200]   Actually, I have to say good friend, David Friend, who created this.
[01:53:41.200 --> 01:53:45.040]   He was the CEO of Carbonite, a serial entrepreneur.
[01:53:45.040 --> 01:53:50.240]   He created the ARPS synthesizer way back when he's really a neat guy.
[01:53:50.240 --> 01:53:56.120]   His CTO, Jeff Flowers invented and patented something at Carbonite that is huge.
[01:53:56.120 --> 01:54:03.760]   The ability to lay data on disks, not in blocks or sectors as your computer does, but sequentially.
[01:54:03.760 --> 01:54:11.160]   Which speeds things up about six times faster and 80% cheaper than the better known, oh,
[01:54:11.160 --> 01:54:13.680]   let's say at Amazon S3.
[01:54:13.680 --> 01:54:14.680]   Wasabi.
[01:54:14.680 --> 01:54:15.760]   People are moving to the cloud.
[01:54:15.760 --> 01:54:16.760]   I understand that.
[01:54:16.760 --> 01:54:21.160]   The cloud is the focus of so many businesses.
[01:54:21.160 --> 01:54:26.840]   According to the Gartner Group, by 2025, 80% of enterprises will have shut down the traditional
[01:54:26.840 --> 01:54:29.960]   data centers.
[01:54:29.960 --> 01:54:34.920]   That means they'll be migrating to the cloud because of cost savings, operational efficiencies,
[01:54:34.920 --> 01:54:36.720]   the ability to scale.
[01:54:36.720 --> 01:54:43.160]   I would submit that data in the cloud is often more secure than you're on-premises data.
[01:54:43.160 --> 01:54:45.560]   Well, especially if it's Wasabi.
[01:54:45.560 --> 01:54:48.120]   Let me talk about Wasabi.
[01:54:48.120 --> 01:54:52.520]   11.9 is a durability.
[01:54:52.520 --> 01:54:54.440]   They have something called immutable storage.
[01:54:54.440 --> 01:54:57.560]   You can say some of the data you've stored in Wasabi cannot be changed.
[01:54:57.560 --> 01:54:58.800]   It's immutable.
[01:54:58.800 --> 01:55:01.000]   It cannot be harmed by ransomware.
[01:55:01.000 --> 01:55:04.400]   It cannot be affected by fumble-fingered employees.
[01:55:04.400 --> 01:55:07.360]   They've got multiple data centers.
[01:55:07.360 --> 01:55:09.560]   It's as secure as can be.
[01:55:09.560 --> 01:55:14.120]   It's enterprise-class cloud storage that's 80% cheaper and six times faster than Amazon's
[01:55:14.120 --> 01:55:15.120]   S3.
[01:55:15.120 --> 01:55:17.320]   It uses the S3 API.
[01:55:17.320 --> 01:55:18.480]   It's just as easy to use.
[01:55:18.480 --> 01:55:21.480]   You already have all the tools you need.
[01:55:21.480 --> 01:55:25.320]   This is disruptive technology, but they've got a problem.
[01:55:25.320 --> 01:55:26.480]   People know Google Cloud.
[01:55:26.480 --> 01:55:27.480]   They know Azure.
[01:55:27.480 --> 01:55:28.880]   They know S3.
[01:55:28.880 --> 01:55:30.400]   I want the world to know about Wasabi.
[01:55:30.400 --> 01:55:35.120]   I know you're going to look at the other ones, but please add a fourth name to that list.
[01:55:35.120 --> 01:55:36.120]   Wasabi.
[01:55:36.120 --> 01:55:38.120]   W-A-S-A-B-I.com.
[01:55:38.120 --> 01:55:40.360]   HIPAA FINRA compliant.
[01:55:40.360 --> 01:55:43.080]   It's totally secure, totally reliable.
[01:55:43.080 --> 01:55:44.240]   The price is right.
[01:55:44.240 --> 01:55:46.280]   Not only is it less expensive.
[01:55:46.280 --> 01:55:48.520]   They don't charge for egress.
[01:55:48.520 --> 01:55:52.520]   It's much easier to plan because you know exactly how much it's going to cost and you
[01:55:52.520 --> 01:55:54.360]   have access to that data at no cost.
[01:55:54.360 --> 01:55:56.200]   egress is free.
[01:55:56.200 --> 01:55:57.760]   You've got to check it out.
[01:55:57.760 --> 01:55:59.320]   Calculate the savings for yourself.
[01:55:59.320 --> 01:56:01.560]   You could try it for free with unlimited storage.
[01:56:01.560 --> 01:56:05.600]   Normally, the trial is one terabyte per month, unlimited storage for a month when you go to
[01:56:05.600 --> 01:56:08.680]   Wasabi.com and use our free trial link.
[01:56:08.680 --> 01:56:11.800]   Use the offer code TWIT.
[01:56:11.800 --> 01:56:12.800]   Join the movement.
[01:56:12.800 --> 01:56:14.800]   Migrate your data to the cloud and do it with confidence.
[01:56:14.800 --> 01:56:17.520]   By the way, they make it even easier if you have petabytes of data.
[01:56:17.520 --> 01:56:20.080]   You can move petabytes at once with the Wasabi ball.
[01:56:20.080 --> 01:56:22.240]   I love the name.
[01:56:22.240 --> 01:56:24.760]   Get a nice hot ball of Wasabi.
[01:56:24.760 --> 01:56:26.040]   Put all the data on there.
[01:56:26.040 --> 01:56:27.040]   Mail it.
[01:56:27.040 --> 01:56:28.040]   It's amazing.
[01:56:28.040 --> 01:56:29.040]   Wasabi.com.
[01:56:29.040 --> 01:56:30.040]   You use the offer code TWIT.
[01:56:30.040 --> 01:56:31.720]   All I ask, all I ask is you try it out.
[01:56:31.720 --> 01:56:38.480]   Just consider the alternative Wasabi.
[01:56:38.480 --> 01:56:45.280]   A bit of a shock to some Tesla owners, Roadshow had this story today.
[01:56:45.280 --> 01:56:55.520]   Tesla uses an old friend in their media center, EMMC storage.
[01:56:55.520 --> 01:56:57.360]   There's a little bit of a problem.
[01:56:57.360 --> 01:57:07.960]   It turns out that EMMC's memory can only be written to a certain number of times.
[01:57:07.960 --> 01:57:11.840]   When it fails on the Tesla, you pretty much add a lock.
[01:57:11.840 --> 01:57:16.800]   It doesn't quite brick the car, but it makes it so that you can't really drive it.
[01:57:16.800 --> 01:57:19.760]   You can't really charge it.
[01:57:19.760 --> 01:57:20.760]   Here's the worst thing.
[01:57:20.760 --> 01:57:21.760]   It's not covered.
[01:57:21.760 --> 01:57:27.400]   If you're outside of warranty, Tesla does not stock the part nor will it service it.
[01:57:27.400 --> 01:57:28.400]   Wow.
[01:57:28.400 --> 01:57:29.400]   Wow.
[01:57:29.400 --> 01:57:31.520]   You should just get under there and do it yourself.
[01:57:31.520 --> 01:57:32.520]   There's a guy.
[01:57:32.520 --> 01:57:36.240]   There's a YouTube channel of a guy who does his own Tesla-like stuff.
[01:57:36.240 --> 01:57:40.880]   He's the only one who has figured out what you can do about this.
[01:57:40.880 --> 01:57:42.880]   It's kind of a problem.
[01:57:42.880 --> 01:57:47.560]   Yeah, I was just thinking about that on the way here with all the Teslas on the road because
[01:57:47.560 --> 01:57:48.560]   they're a lot.
[01:57:48.560 --> 01:57:53.120]   I was just thinking about, oh, yeah, I guess there's a huge team of people that are programming
[01:57:53.120 --> 01:57:54.120]   for these cars.
[01:57:54.120 --> 01:57:55.120]   This isn't a Achilles heel.
[01:57:55.120 --> 01:57:59.040]   Well, the funny thing is Tesla really locks it down.
[01:57:59.040 --> 01:58:05.840]   If you get known as somebody's doing this, they can literally disable your vehicle.
[01:58:05.840 --> 01:58:10.080]   And Elon is, he's been known to do things a little different.
[01:58:10.080 --> 01:58:12.720]   He's a bit of a hothead.
[01:58:12.720 --> 01:58:21.080]   So I don't know much more about it, but if you look at Roadshow, when the EMMC fails,
[01:58:21.080 --> 01:58:24.680]   your car will be limited on how fast it can go.
[01:58:24.680 --> 01:58:26.080]   Your climate control won't work.
[01:58:26.080 --> 01:58:31.520]   The charging could fail.
[01:58:31.520 --> 01:58:33.520]   And this can happen in a couple of years.
[01:58:33.520 --> 01:58:35.440]   I think you just buy a new Tesla at that point.
[01:58:35.440 --> 01:58:36.440]   This is the business model.
[01:58:36.440 --> 01:58:38.440]   I'm with the old and with the new.
[01:58:38.440 --> 01:58:41.640]   And I remember you should throw it at recycling and get it on.
[01:58:41.640 --> 01:58:43.840]   Literally a micro SD card in there.
[01:58:43.840 --> 01:58:44.840]   Yeah.
[01:58:44.840 --> 01:58:45.840]   Probably.
[01:58:45.840 --> 01:58:47.840]   And now it doesn't work anymore.
[01:58:47.840 --> 01:58:48.840]   Yeah.
[01:58:48.840 --> 01:58:49.840]   So Uber.
[01:58:49.840 --> 01:58:50.840]   Uber.
[01:58:50.840 --> 01:58:57.240]   I just congratulate the people who were in early and who made a lot of money.
[01:58:57.240 --> 01:58:58.640]   Please spend your money wisely.
[01:58:58.640 --> 01:59:07.520]   Uber had its IPO this week, got valued at $82.4 billion, which sounds like a lot.
[01:59:07.520 --> 01:59:13.240]   But remember that the day before the IPO and Wednesday, Uber drivers struck from, because
[01:59:13.240 --> 01:59:14.840]   they were underpaid.
[01:59:14.840 --> 01:59:15.840]   And Lyft drivers as well.
[01:59:15.840 --> 01:59:16.840]   Lyft drivers.
[01:59:16.840 --> 01:59:20.720]   There's been a lot of, of course, negative news about Uber for the last five years.
[01:59:20.720 --> 01:59:25.880]   They only asked $45 a share, which was at the bottom of their range.
[01:59:25.880 --> 01:59:30.280]   And it was down, what was it, 7% mark by the end of the day.
[01:59:30.280 --> 01:59:36.840]   It was the worst IPO in tech history in terms of first day losses.
[01:59:36.840 --> 01:59:39.080]   Congratulations.
[01:59:39.080 --> 01:59:40.080]   This is Kismoto.
[01:59:40.080 --> 01:59:41.080]   Little snark.
[01:59:41.080 --> 01:59:45.800]   Congratulations to Uber, the worst performing IPO in any of any sector.
[01:59:45.800 --> 01:59:47.040]   It's like getting a razzie.
[01:59:47.040 --> 01:59:48.040]   It's like getting a razzie.
[01:59:48.040 --> 01:59:50.040]   It is an honor in and of itself.
[01:59:50.040 --> 01:59:51.040]   Yeah.
[01:59:51.040 --> 01:59:55.600]   And I mean, if that's going to happen to any company, it makes sense that it would happen
[01:59:55.600 --> 01:59:56.600]   for Uber.
[01:59:56.600 --> 01:59:57.840]   Do you not take Uber's?
[01:59:57.840 --> 01:59:58.840]   I love Uber.
[01:59:58.840 --> 01:59:59.840]   I want Uber's ex-used.
[01:59:59.840 --> 02:00:00.840]   I just Lyft.
[02:00:00.840 --> 02:00:01.840]   Yeah, I usually use Lyft.
[02:00:01.840 --> 02:00:02.840]   But I don't do Uber's right share.
[02:00:02.840 --> 02:00:04.320]   I feel like they're interchangeable.
[02:00:04.320 --> 02:00:07.920]   So my daughter, okay, so my daughter graduating from college and Saturday, congratulations
[02:00:07.920 --> 02:00:08.920]   Abby.
[02:00:08.920 --> 02:00:14.760]   I hope you don't mind me telling this story, has had a few car accidents.
[02:00:14.760 --> 02:00:16.760]   None of them hurt anybody or was she hurt.
[02:00:16.760 --> 02:00:22.160]   But the most recent one was she drove into a parked car because she was texting.
[02:00:22.160 --> 02:00:26.720]   So I said, "You're not going to be driving anymore.
[02:00:26.720 --> 02:00:30.560]   I'm going to insist that you Uber everywhere because I think it will be cheaper."
[02:00:30.560 --> 02:00:31.560]   Yeah.
[02:00:31.560 --> 02:00:32.560]   And you can do texts at the same time.
[02:00:32.560 --> 02:00:33.800]   And you can do all the texting you watch.
[02:00:33.800 --> 02:00:35.440]   "Dad, I'll put the phone in the truck."
[02:00:35.440 --> 02:00:38.880]   "Let's try Uber for a while."
[02:00:38.880 --> 02:00:40.800]   And I think that this is not unusual.
[02:00:40.800 --> 02:00:47.280]   I think a lot of people, especially if you live in a city, are just not owning cars.
[02:00:47.280 --> 02:00:48.280]   Yeah.
[02:00:48.280 --> 02:00:49.280]   Well, how is she a car?
[02:00:49.280 --> 02:00:50.280]   But you have to-
[02:00:50.280 --> 02:00:51.280]   You live in the burbs.
[02:00:51.280 --> 02:00:52.280]   How is she doing?
[02:00:52.280 --> 02:00:56.760]   She's spending a lot of money on Uber and Lyft.
[02:00:56.760 --> 02:00:57.760]   I mean, it's got to be expensive.
[02:00:57.760 --> 02:01:00.600]   But from her point of view, Uber and Lyft are interchangeable.
[02:01:00.600 --> 02:01:01.880]   And I think that's probably true, right?
[02:01:01.880 --> 02:01:03.400]   You just use whatever is going to come.
[02:01:03.400 --> 02:01:05.320]   Well, Lyft takes PayPal.
[02:01:05.320 --> 02:01:09.080]   Well, she's got my credit card, so it doesn't really matter.
[02:01:09.080 --> 02:01:12.840]   For me, I have accounts where I'm like, "This account is for this and this account is for
[02:01:12.840 --> 02:01:13.840]   that."
[02:01:13.840 --> 02:01:18.560]   I think it's a remarkable deal because you're only paying Uber subsidized 41% of the cost
[02:01:18.560 --> 02:01:19.560]   of the ride.
[02:01:19.560 --> 02:01:20.560]   Dang.
[02:01:20.560 --> 02:01:23.560]   You're not paying anywhere near what it costs.
[02:01:23.560 --> 02:01:24.560]   That's why we're losing somebody money, right?
[02:01:24.560 --> 02:01:27.160]   I do use Uber and Romania.
[02:01:27.160 --> 02:01:28.160]   I rest my case.
[02:01:28.160 --> 02:01:29.160]   Why?
[02:01:29.160 --> 02:01:30.160]   Because that's all that works there.
[02:01:30.160 --> 02:01:31.160]   There's no Lyft there.
[02:01:31.160 --> 02:01:32.560]   No, but they also have Uber eats there.
[02:01:32.560 --> 02:01:36.560]   I've got to tell you, it's amazing how much the country has now.
[02:01:36.560 --> 02:01:41.760]   But anyway, I had everything delivered to my door, which was not possible when I was
[02:01:41.760 --> 02:01:42.760]   a kid.
[02:01:42.760 --> 02:01:43.760]   Yeah.
[02:01:43.760 --> 02:01:44.760]   I'm one of those people.
[02:01:44.760 --> 02:01:45.760]   I don't own a car.
[02:01:45.760 --> 02:01:46.760]   You don't?
[02:01:46.760 --> 02:01:48.320]   I use Uber and Lyft.
[02:01:48.320 --> 02:01:53.840]   During the delete Uber period, I've for a while thought about it.
[02:01:53.840 --> 02:01:57.680]   I feel like Calinic is gone.
[02:01:57.680 --> 02:02:00.520]   Kosro Shahi is, I think, a good person.
[02:02:00.520 --> 02:02:01.720]   Dara's a very good person.
[02:02:01.720 --> 02:02:02.720]   I'm your CEO.
[02:02:02.720 --> 02:02:06.600]   I think they're doing everything they can to change the company culture.
[02:02:06.600 --> 02:02:09.680]   I feel bad about the drivers, but after all, they're choosing it.
[02:02:09.680 --> 02:02:13.320]   If you don't use them, that's even worse, right?
[02:02:13.320 --> 02:02:14.320]   Do you feel guilty?
[02:02:14.320 --> 02:02:16.240]   I tip them.
[02:02:16.240 --> 02:02:21.120]   I feel a tiny bit guilty, but I don't know.
[02:02:21.120 --> 02:02:26.400]   It's just the industry that they're replacing or that they're revolutionizing or whatever
[02:02:26.400 --> 02:02:27.400]   you say.
[02:02:27.400 --> 02:02:28.400]   The cab industry.
[02:02:28.400 --> 02:02:29.400]   Yeah.
[02:02:29.400 --> 02:02:30.400]   That wasn't so hot.
[02:02:30.400 --> 02:02:31.400]   That isn't so hot.
[02:02:31.400 --> 02:02:33.480]   The cab being driving a cab is not much better.
[02:02:33.480 --> 02:02:34.480]   No.
[02:02:34.480 --> 02:02:35.480]   It's bad.
[02:02:35.480 --> 02:02:36.480]   It's bad.
[02:02:36.480 --> 02:02:38.320]   Taking a cab is also not much safer.
[02:02:38.320 --> 02:02:39.320]   Probably not.
[02:02:39.320 --> 02:02:40.320]   Yeah, I don't.
[02:02:40.320 --> 02:02:44.760]   See, my daughter, you'd think, well, you aren't you worried about her, but I don't think Uber
[02:02:44.760 --> 02:02:46.160]   drivers are bad people.
[02:02:46.160 --> 02:02:48.000]   I was kidnapped by a taxi once.
[02:02:48.000 --> 02:02:49.000]   In Romania.
[02:02:49.000 --> 02:02:51.440]   No, in San Francisco.
[02:02:51.440 --> 02:02:52.440]   What?
[02:02:52.440 --> 02:02:54.440]   What do you say?
[02:02:54.440 --> 02:02:55.760]   You're coming with me?
[02:02:55.760 --> 02:02:59.720]   He did not want to take us to the sunset because that's like a thing that taxi drivers
[02:02:59.720 --> 02:03:00.720]   do not do.
[02:03:00.720 --> 02:03:02.920]   Because you go out there and lose going to come back.
[02:03:02.920 --> 02:03:03.920]   I know.
[02:03:03.920 --> 02:03:04.920]   I know.
[02:03:04.920 --> 02:03:08.720]   But so instead of taking us instead of letting us out of the car, he just drove a man-man
[02:03:08.720 --> 02:03:14.280]   through like red stoplights and dropped us off in the tenderloin police department.
[02:03:14.280 --> 02:03:15.280]   What?
[02:03:15.280 --> 02:03:16.280]   That kidnapping?
[02:03:16.280 --> 02:03:17.280]   That's just...
[02:03:17.280 --> 02:03:19.200]   He wouldn't let us out of the car.
[02:03:19.200 --> 02:03:24.080]   He was purposefully driving forward to not allow any of us to get out of the car.
[02:03:24.080 --> 02:03:25.600]   But why did he drop you off at the police station?
[02:03:25.600 --> 02:03:26.840]   I have no idea.
[02:03:26.840 --> 02:03:29.040]   I think he was just having a really bad night.
[02:03:29.040 --> 02:03:30.760]   Sorry about that, Dave.
[02:03:30.760 --> 02:03:31.760]   But it was scary.
[02:03:31.760 --> 02:03:32.760]   Yeah.
[02:03:32.760 --> 02:03:36.960]   To say, "That would be scary to be in the car and to want to get out and not to be able
[02:03:36.960 --> 02:03:37.960]   to get out."
[02:03:37.960 --> 02:03:38.960]   Because the thing is, I used to take...
[02:03:38.960 --> 02:03:39.960]   Obviously.
[02:03:39.960 --> 02:03:44.040]   When I lived in the city and I was working, I worked at a coffee shop and we worked late.
[02:03:44.040 --> 02:03:49.120]   And I would like to maybe go out afterwards downtown and I would take a taxi cab, couple
[02:03:49.120 --> 02:03:51.400]   blocks just to go to the BART station.
[02:03:51.400 --> 02:03:56.320]   Like I would take money, put it aside just to do that.
[02:03:56.320 --> 02:03:59.200]   So anyway, I've had a lot of experiences with cabs.
[02:03:59.200 --> 02:04:00.200]   Yeah.
[02:04:00.200 --> 02:04:02.760]   But at least on an app you're tracked.
[02:04:02.760 --> 02:04:03.760]   That's cray-cray.
[02:04:03.760 --> 02:04:04.760]   Yeah.
[02:04:04.760 --> 02:04:12.800]   Jeff Bezos has unveiled the Blue Origin Moon Lander to which Elon Musk...
[02:04:12.800 --> 02:04:14.720]   Well, maybe you can explain this to me.
[02:04:14.720 --> 02:04:16.720]   Tweeted, "Oh, stop teasing, Jeff."
[02:04:16.720 --> 02:04:21.120]   Don't forget the winky emoji.
[02:04:21.120 --> 02:04:23.760]   They have a thing.
[02:04:23.760 --> 02:04:27.760]   I don't get it either.
[02:04:27.760 --> 02:04:28.760]   Okay.
[02:04:28.760 --> 02:04:30.160]   I think it's all good.
[02:04:30.160 --> 02:04:31.160]   Both of you.
[02:04:31.160 --> 02:04:32.160]   There's enough room for both of you.
[02:04:32.160 --> 02:04:36.360]   I mean, there's enough room for their money to drive the race to space.
[02:04:36.360 --> 02:04:37.360]   Sure.
[02:04:37.360 --> 02:04:38.360]   They're obviously bored.
[02:04:38.360 --> 02:04:40.160]   They have to be at something to focus on.
[02:04:40.160 --> 02:04:44.640]   I mentioned Daniel Suarez' book, "A Demon Earlier."
[02:04:44.640 --> 02:04:47.800]   I forgot to mention he's going to be on "Tranulation" on Friday.
[02:04:47.800 --> 02:04:51.480]   And he's going to be talking about his new book, "Delta V," which is about asteroid mining.
[02:04:51.480 --> 02:04:56.400]   I'm waiting for one of these guys to cotton on the fact that there's money in those asteroids.
[02:04:56.400 --> 02:04:57.400]   Go out there.
[02:04:57.400 --> 02:04:59.680]   Let's go out there and get them.
[02:04:59.680 --> 02:05:01.440]   Forget landing on the Moon or Mars.
[02:05:01.440 --> 02:05:02.440]   Asteroids.
[02:05:02.440 --> 02:05:03.440]   Land on an asteroid.
[02:05:03.440 --> 02:05:04.880]   It's probably hidden treasure on the asteroids.
[02:05:04.880 --> 02:05:05.880]   Oh, yeah.
[02:05:05.880 --> 02:05:08.640]   Even if it's just water, there's hidden treasure.
[02:05:08.640 --> 02:05:09.640]   And there may be more.
[02:05:09.640 --> 02:05:15.360]   I remember when I visited Blue Origin a couple of years ago, they said there's totally money
[02:05:15.360 --> 02:05:16.360]   to make in space.
[02:05:16.360 --> 02:05:20.880]   The only thing that makes it not viable is getting up there.
[02:05:20.880 --> 02:05:21.880]   So terrible stuff.
[02:05:21.880 --> 02:05:22.880]   Delta V.
[02:05:22.880 --> 02:05:27.680]   So that's the point of the book is the big cost is getting out of the Earth's gravitational
[02:05:27.680 --> 02:05:28.680]   force.
[02:05:28.680 --> 02:05:32.800]   That gravitational well is what costs you all the money.
[02:05:32.800 --> 02:05:37.280]   But once you get out there and mine the asteroid, and so, well, I don't want to spoil the book.
[02:05:37.280 --> 02:05:38.280]   It's a great book.
[02:05:38.280 --> 02:05:39.280]   Highly recommended.
[02:05:39.280 --> 02:05:44.760]   We'll talk about it with Daniel Suarez on Friday at 11.30 AM Pacific if you want to tune in
[02:05:44.760 --> 02:05:47.480]   for the next triangulation.
[02:05:47.480 --> 02:05:51.360]   But that's the point is that they don't bring it back.
[02:05:51.360 --> 02:05:52.920]   They go out, they mine the asteroids.
[02:05:52.920 --> 02:05:59.520]   And it becomes material for continued space exploration, including water and vital essential
[02:05:59.520 --> 02:06:00.520]   elements.
[02:06:00.520 --> 02:06:09.120]   Sorry, I brought it up.
[02:06:09.120 --> 02:06:17.560]   Amazon has decided that if Seattle is going to tax our high income wage earners, we're
[02:06:17.560 --> 02:06:21.680]   not going to hire any.
[02:06:21.680 --> 02:06:26.760]   The tax would benefit the homeless population, but Jeff Bezos really didn't want to pay that
[02:06:26.760 --> 02:06:27.760]   tax.
[02:06:27.760 --> 02:06:31.760]   Amazon spent a lot of money on the campaign against it.
[02:06:31.760 --> 02:06:40.240]   He says, I think we're not going to hire those 7,000 jobs.
[02:06:40.240 --> 02:06:42.640]   The tax is on high value employees.
[02:06:42.640 --> 02:06:48.760]   It'd be $500 per employee on companies that gross at least $20 million a year.
[02:06:48.760 --> 02:06:55.240]   And Amazon just says, you know, if they pass that, this is blackmail that has that we are
[02:06:55.240 --> 02:06:57.880]   not going to build those headquarters.
[02:06:57.880 --> 02:06:59.880]   We're not going to hire those people.
[02:06:59.880 --> 02:07:02.920]   It says Amazon is the same thing to New York, didn't they?
[02:07:02.920 --> 02:07:03.920]   Yeah.
[02:07:03.920 --> 02:07:04.920]   Long Island, yeah.
[02:07:04.920 --> 02:07:05.920]   Long Island, Long Island City.
[02:07:05.920 --> 02:07:07.680]   They step in, they step out.
[02:07:07.680 --> 02:07:08.680]   Good article on Vox.
[02:07:08.680 --> 02:07:09.680]   I don't know.
[02:07:09.680 --> 02:07:13.160]   It was a long piece on the history of Amazon Prime.
[02:07:13.160 --> 02:07:15.120]   But yeah, that wasn't really fast.
[02:07:15.120 --> 02:07:16.120]   Yeah, yeah, yeah.
[02:07:16.120 --> 02:07:17.120]   Absolutely.
[02:07:17.120 --> 02:07:20.320]   You tweeted, you don't tweet a lot of links these days and you even tweeted about that
[02:07:20.320 --> 02:07:21.320]   one.
[02:07:21.320 --> 02:07:24.720]   It was just, it was captivating, you know, it was, it was told really well.
[02:07:24.720 --> 02:07:28.640]   And you know, for an article to be written about something that I didn't know that I
[02:07:28.640 --> 02:07:30.840]   wanted to know the history of until I reached the end.
[02:07:30.840 --> 02:07:32.680]   I was like a really happy that I read that.
[02:07:32.680 --> 02:07:38.480]   The amazing thing, and I remember this from the Everything Store, the great, really great
[02:07:38.480 --> 02:07:43.040]   book about Amazon is no one knew what to charge for this.
[02:07:43.040 --> 02:07:45.800]   They just made it up because they didn't know what it would cost and they didn't know
[02:07:45.800 --> 02:07:46.800]   what the value would be.
[02:07:46.800 --> 02:07:49.240]   So they had no idea.
[02:07:49.240 --> 02:07:55.040]   And I think it was Bezos just said, well, just charge, you know, 76 bucks for it.
[02:07:55.040 --> 02:07:56.040]   We'll see.
[02:07:56.040 --> 02:07:57.600]   That's how I negotiate with editors.
[02:07:57.600 --> 02:07:59.120]   It turned out to be the right amount.
[02:07:59.120 --> 02:08:00.120]   Right.
[02:08:00.120 --> 02:08:01.120]   Now they've raised it.
[02:08:01.120 --> 02:08:02.120]   I think it's $99.
[02:08:02.120 --> 02:08:03.120]   Yeah.
[02:08:03.120 --> 02:08:04.640]   They keep adding value to that as well.
[02:08:04.640 --> 02:08:05.760]   Yeah, you get a lot for your money.
[02:08:05.760 --> 02:08:13.600]   I thought it was an interesting leap of faith to make to add in the music service when everybody
[02:08:13.600 --> 02:08:14.800]   else was charging for it.
[02:08:14.800 --> 02:08:18.640]   And that was one of Bezos's kind of decisions that everyone was like, wait a minute, why
[02:08:18.640 --> 02:08:20.920]   would you just include this in prime?
[02:08:20.920 --> 02:08:25.400]   You know what that, I mean, yeah, Amazon's music service has never been amazing compared
[02:08:25.400 --> 02:08:26.400]   to the competitors.
[02:08:26.400 --> 02:08:28.560]   But still it worked out all right.
[02:08:28.560 --> 02:08:31.520]   Somehow they're able to make those numbers work at scale.
[02:08:31.520 --> 02:08:35.040]   They quote one of the finance guys when they were coming up with a name, Jeff blurted out.
[02:08:35.040 --> 02:08:37.120]   He said, we'll call it prime.
[02:08:37.120 --> 02:08:39.200]   And that really says, I don't particularly love the name for me.
[02:08:39.200 --> 02:08:41.720]   I'd heard all you can eat premium shopping, call it prime.
[02:08:41.720 --> 02:08:43.280]   I was like prime rib.
[02:08:43.280 --> 02:08:45.920]   I remember I'm a finance guy.
[02:08:45.920 --> 02:08:49.400]   So they did a brand study, a full brand study.
[02:08:49.400 --> 02:08:52.320]   They put together a bunch of names, 20 names.
[02:08:52.320 --> 02:08:53.320]   Here's three names.
[02:08:53.320 --> 02:08:54.320]   You like better than prime.
[02:08:54.320 --> 02:08:55.480]   Jeff came in and he read the document.
[02:08:55.480 --> 02:08:57.000]   And he said, oh, okay, this is great.
[02:08:57.000 --> 02:08:58.000]   I agree.
[02:08:58.000 --> 02:08:59.000]   I like prime.
[02:08:59.000 --> 02:09:01.440]   And then laughed.
[02:09:01.440 --> 02:09:04.400]   Jeff Bezos is famous laugh.
[02:09:04.400 --> 02:09:05.400]   Couldn't imagine being any.
[02:09:05.400 --> 02:09:06.400]   And you know what?
[02:09:06.400 --> 02:09:07.400]   He was right.
[02:09:07.400 --> 02:09:12.000]   It's the most successful membership club of all time by far more than Costco much more
[02:09:12.000 --> 02:09:13.000]   than Costco.
[02:09:13.000 --> 02:09:16.080]   Didn't take off right away though.
[02:09:16.080 --> 02:09:22.560]   Really was slow, slow in the beginning, the beginning, always hard with the shipping video.
[02:09:22.560 --> 02:09:25.720]   When the video aspect was added, it started to move.
[02:09:25.720 --> 02:09:26.720]   Oh, interesting.
[02:09:26.720 --> 02:09:28.760]   Because I would have thought that that's just like a benefit.
[02:09:28.760 --> 02:09:29.760]   That's just gravy.
[02:09:29.760 --> 02:09:32.200]   Because I wanted the two day shipping.
[02:09:32.200 --> 02:09:35.440]   For me, that was like, wow.
[02:09:35.440 --> 02:09:36.440]   Now it's one day.
[02:09:36.440 --> 02:09:37.440]   Yeah, right.
[02:09:37.440 --> 02:09:38.440]   It's going to be one day.
[02:09:38.440 --> 02:09:42.360]   $800 million is going to cost them to do that.
[02:09:42.360 --> 02:09:48.840]   So there was a lack of, so Schweitzer says, I recall the state of it when I joined.
[02:09:48.840 --> 02:09:52.540]   When someone orders a $3 toothbrush and we send it to them two day delivery, they're
[02:09:52.540 --> 02:09:55.360]   like, there's no way we can make money on that.
[02:09:55.360 --> 02:09:58.660]   So that's why they created the add-ons where, and this always pisses me off.
[02:09:58.660 --> 02:10:01.960]   Well, we can't really ship that to you, but you got to order something else.
[02:10:01.960 --> 02:10:02.960]   Right.
[02:10:02.960 --> 02:10:06.040]   But that's why they do that.
[02:10:06.040 --> 02:10:09.300]   Here's the timeline.
[02:10:09.300 --> 02:10:13.840]   I kind of appreciate that though, because that makes the energy that went into backing
[02:10:13.840 --> 02:10:14.840]   that.
[02:10:14.840 --> 02:10:15.840]   Two or boxes.
[02:10:15.840 --> 02:10:16.840]   Less trucks.
[02:10:16.840 --> 02:10:17.840]   Yeah.
[02:10:17.840 --> 02:10:20.100]   Plus then I feel like, okay, well, if I'm ordering from Amazon, let me do things that
[02:10:20.100 --> 02:10:24.280]   I can't get at Target or that I can't get at Prick 'em Order down the street kind of
[02:10:24.280 --> 02:10:27.280]   thing.
[02:10:27.280 --> 02:10:31.240]   This is a reading through this also reminded me of just how much of a threat eBay seemed
[02:10:31.240 --> 02:10:33.840]   to be at the time that all of this was happening.
[02:10:33.840 --> 02:10:39.040]   And now things have just, you know, it's just interesting how the long, in the long term-
[02:10:39.040 --> 02:10:40.880]   You guys are going for old stuff.
[02:10:40.880 --> 02:10:41.880]   I don't even-
[02:10:41.880 --> 02:10:42.880]   I don't go to eat.
[02:10:42.880 --> 02:10:44.880]   Well, because I collect Pokemon cards.
[02:10:44.880 --> 02:10:45.880]   But I- Okay.
[02:10:45.880 --> 02:10:48.480]   Well- And that's- And they're really cards and that's where you can find them.
[02:10:48.480 --> 02:10:50.140]   Man, once upon a time, eBay was-
[02:10:50.140 --> 02:10:53.780]   It's very rare, Japanese fountain pen from 1976.
[02:10:53.780 --> 02:10:54.780]   eBay.
[02:10:54.780 --> 02:10:55.780]   eBay.
[02:10:55.780 --> 02:10:56.780]   Right.
[02:10:56.780 --> 02:10:57.780]   Where else are you gonna get it?
[02:10:57.780 --> 02:10:58.780]   Not Amazon Prime.
[02:10:58.780 --> 02:11:00.380]   And you know, I didn't get ripped off or anything.
[02:11:00.380 --> 02:11:02.140]   Despite all the ink on my hands.
[02:11:02.140 --> 02:11:06.580]   Go ahead and put that fancy pen in your white shirt.
[02:11:06.580 --> 02:11:07.580]   Yeah, exactly.
[02:11:07.580 --> 02:11:08.580]   No pocket protected.
[02:11:08.580 --> 02:11:11.460]   That's how much I trust eBay, right?
[02:11:11.460 --> 02:11:14.260]   That's how much I trust eBay.
[02:11:14.260 --> 02:11:19.920]   What about the post from Jeffrey Fowler, Washington Post?
[02:11:19.920 --> 02:11:22.960]   Oh, you know, I thought that was BS.
[02:11:22.960 --> 02:11:26.040]   Honestly, we all know that- Okay, go ahead.
[02:11:26.040 --> 02:11:27.040]   No, no, no, no.
[02:11:27.040 --> 02:11:33.520]   I mean, all it reminded me of is I don't have any Amazon Echoes in my home, but I do have
[02:11:33.520 --> 02:11:35.520]   plenty of Google homes.
[02:11:35.520 --> 02:11:41.620]   And I do know that I've visited the website, you know, the settings pane through Google
[02:11:41.620 --> 02:11:46.440]   associated to my account to listen to some of those recordings that have been inspired.
[02:11:46.440 --> 02:11:47.440]   And they're all there.
[02:11:47.440 --> 02:11:48.440]   So what?
[02:11:48.440 --> 02:11:49.440]   Yeah.
[02:11:49.440 --> 02:11:54.840]   Who knows what our friend Jeff Jarvis calls techno panic.
[02:11:54.840 --> 02:11:58.440]   And it is, you know, the piece was- And I guess it's an opinion piece.
[02:11:58.440 --> 02:11:59.440]   Or no, maybe not.
[02:11:59.440 --> 02:12:02.560]   It's a perspective piece.
[02:12:02.560 --> 02:12:03.920]   It's a perspective piece.
[02:12:03.920 --> 02:12:08.320]   Amazon says been eavesdropping on you this whole time.
[02:12:08.320 --> 02:12:09.480]   Well, come on.
[02:12:09.480 --> 02:12:11.440]   Of course it has.
[02:12:11.440 --> 02:12:13.540]   And he's not even saying it's listening to you all the time.
[02:12:13.540 --> 02:12:16.380]   Although he's kind of- That kind of implies it's always listening to you.
[02:12:16.380 --> 02:12:22.860]   What he's saying is whenever you send anything to your Echo, Amazon keeps a copy of it.
[02:12:22.860 --> 02:12:25.820]   As does Google, we know.
[02:12:25.820 --> 02:12:29.500]   And Siri, and this is how they train AI.
[02:12:29.500 --> 02:12:30.500]   Yep.
[02:12:30.500 --> 02:12:32.260]   What's his beef?
[02:12:32.260 --> 02:12:34.580]   I mean, does that- That they keep it too long?
[02:12:34.580 --> 02:12:37.100]   Is that what he's- Well, and that's one of the things Google's going to do, right?
[02:12:37.100 --> 02:12:39.780]   Is give you a chance to have them throw that out earlier.
[02:12:39.780 --> 02:12:40.780]   Right.
[02:12:40.780 --> 02:12:46.900]   It's like he just found the internet.
[02:12:46.900 --> 02:12:53.280]   Whenever I read stuff like this, maybe it's me because everybody doesn't know this.
[02:12:53.280 --> 02:12:56.060]   I was going to say, I feel like it's an awareness piece.
[02:12:56.060 --> 02:12:57.700]   Some people might not know that.
[02:12:57.700 --> 02:12:58.700]   I've known that.
[02:12:58.700 --> 02:13:02.900]   And when I saw this first kicking around online, I was like, "Okay, yeah, I feel like we've
[02:13:02.900 --> 02:13:04.260]   known this for a long time."
[02:13:04.260 --> 02:13:09.760]   But there's probably a whole lot of people that have echoes that don't know what exactly
[02:13:09.760 --> 02:13:13.160]   is happening to their voice data that it's actually being stored somewhere.
[02:13:13.160 --> 02:13:16.800]   They don't even think maybe they don't even know that it's sending it to a server in the
[02:13:16.800 --> 02:13:17.800]   cloud.
[02:13:17.800 --> 02:13:18.800]   Maybe they think it's all happening on the eyes.
[02:13:18.800 --> 02:13:23.880]   So he says that state legislatures and maybe even the feds should make a law that says,
[02:13:23.880 --> 02:13:28.440]   "If you keep these recordings, you have to get permission.
[02:13:28.440 --> 02:13:29.880]   You have to get consent first."
[02:13:29.880 --> 02:13:31.520]   Does that seem reasonable?
[02:13:31.520 --> 02:13:32.960]   I think that's not a hard thing to do.
[02:13:32.960 --> 02:13:35.520]   I don't think it's going to change anything because it's just going to be a checkbox.
[02:13:35.520 --> 02:13:36.520]   Right.
[02:13:36.520 --> 02:13:37.520]   Seems reasonable.
[02:13:37.520 --> 02:13:40.720]   Yeah, it's not too much to ask.
[02:13:40.720 --> 02:13:46.280]   I register my security alarm with the city every year because I test security systems
[02:13:46.280 --> 02:13:48.480]   for Tom's Guide.
[02:13:48.480 --> 02:13:56.440]   And honestly, I wouldn't mind some sort of program where I can sign up online and have
[02:13:56.440 --> 02:13:59.720]   that give access to that.
[02:13:59.720 --> 02:14:00.880]   Just ask me for it.
[02:14:00.880 --> 02:14:07.080]   I will manage the maintenance on my end because I want what that service is providing.
[02:14:07.080 --> 02:14:10.440]   Just an idea.
[02:14:10.440 --> 02:14:12.880]   And you might get something out of it on the back end, right?
[02:14:12.880 --> 02:14:13.880]   Exactly.
[02:14:13.880 --> 02:14:17.480]   If it's smarter because of your help, maybe that's not.
[02:14:17.480 --> 02:14:19.240]   Yeah, exactly.
[02:14:19.240 --> 02:14:23.840]   So I guess you should read the article if you didn't know that Amazon keeps the recordings.
[02:14:23.840 --> 02:14:30.960]   Well, it is a newspaper, WAPO, and these articles get done on newspapers often because...
[02:14:30.960 --> 02:14:31.960]   Yeah.
[02:14:31.960 --> 02:14:40.800]   I mean, I have been curious to go into my voice recording archive and do what Jeffrey did
[02:14:40.800 --> 02:14:42.320]   here, which is to play through them.
[02:14:42.320 --> 02:14:46.800]   I don't know if he played through every single one, but I'd be very curious to know what those
[02:14:46.800 --> 02:14:52.200]   random, few choice moments are that I've come across that are like, "Oh, that's just
[02:14:52.200 --> 02:14:53.680]   going to hang it out on the server."
[02:14:53.680 --> 02:14:54.680]   Great.
[02:14:54.680 --> 02:14:58.120]   Most of it's me saying, "F you, Siri."
[02:14:58.120 --> 02:14:59.120]   Probably.
[02:14:59.120 --> 02:15:00.120]   Yeah, a lot of it.
[02:15:00.120 --> 02:15:02.120]   I'm not talking to you, Google.
[02:15:02.120 --> 02:15:03.120]   It's not you.
[02:15:03.120 --> 02:15:04.360]   I say that a lot.
[02:15:04.360 --> 02:15:06.120]   I'm not talking to you.
[02:15:06.120 --> 02:15:07.800]   Oh, I'm sorry.
[02:15:07.800 --> 02:15:12.600]   I swear a lot at my devices, I'm afraid.
[02:15:12.600 --> 02:15:14.040]   That's all it's revealed to me.
[02:15:14.040 --> 02:15:15.040]   All right.
[02:15:15.040 --> 02:15:16.040]   Okay.
[02:15:16.040 --> 02:15:17.040]   I admit it.
[02:15:17.040 --> 02:15:18.040]   People probably don't know it.
[02:15:18.040 --> 02:15:19.040]   It's a good thing that he did.
[02:15:19.040 --> 02:15:20.800]   Here's a first.
[02:15:20.800 --> 02:15:26.760]   Hamas cyber attacks Israel.
[02:15:26.760 --> 02:15:30.240]   Israel responds with bombs.
[02:15:30.240 --> 02:15:35.360]   This is, to my knowledge, the first time there's been a physical bombing attack based on a
[02:15:35.360 --> 02:15:39.480]   cyberspace attack, a cyber attack.
[02:15:39.480 --> 02:15:40.480]   Dang.
[02:15:40.480 --> 02:15:44.760]   I don't know if you would consider that proportional, but get ready because this is the beginning.
[02:15:44.760 --> 02:15:45.760]   Yep.
[02:15:45.760 --> 02:15:46.760]   That's really worrisome to me.
[02:15:46.760 --> 02:15:55.360]   I mean, maybe it is proportional, but when somebody else bombs at you, that's very verifiable.
[02:15:55.360 --> 02:15:59.920]   You know, Israel could just say that there was a cyber attack.
[02:15:59.920 --> 02:16:01.160]   How do I know that?
[02:16:01.160 --> 02:16:04.320]   And it doesn't matter who the players are, by the way.
[02:16:04.320 --> 02:16:06.400]   You know, it's troubling.
[02:16:06.400 --> 02:16:11.720]   Now, the attack was against the people who made the cyber attack.
[02:16:11.720 --> 02:16:15.680]   It was against the Hamas cyber units headquarters.
[02:16:15.680 --> 02:16:18.120]   So the idea is, well, we're going to take those hackers out.
[02:16:18.120 --> 02:16:20.000]   And actually I was wrong.
[02:16:20.000 --> 02:16:23.040]   The US did it first in 2015.
[02:16:23.040 --> 02:16:27.760]   We sent a drone strike to kill Janae Hossein, who was a British citizen in charge of ISIL's
[02:16:27.760 --> 02:16:29.920]   hacker groups.
[02:16:29.920 --> 02:16:35.360]   He had dumped personal details of military forces online via Twitter.
[02:16:35.360 --> 02:16:38.160]   So we took him out with a drone.
[02:16:38.160 --> 02:16:43.000]   So it isn't the first time that we've used force or anybody's used force to counter hacking
[02:16:43.000 --> 02:16:44.200]   attacks.
[02:16:44.200 --> 02:16:49.840]   It really worries me that we're going to see that.
[02:16:49.840 --> 02:16:54.320]   I mean, it's worrisome too, because we've already been attacked.
[02:16:54.320 --> 02:16:59.760]   You know, the United States has been attacked many times by the Chinese and the Koreans and
[02:16:59.760 --> 02:17:00.760]   the Russians.
[02:17:00.760 --> 02:17:01.760]   It's nonstop.
[02:17:01.760 --> 02:17:07.680]   If we get into a habit of this reaction with overwhelming physical force in response, that's
[02:17:07.680 --> 02:17:11.360]   a bad rule to have in place.
[02:17:11.360 --> 02:17:12.360]   That's a bad precedent.
[02:17:12.360 --> 02:17:18.440]   It could make the world a lot more dangerous.
[02:17:18.440 --> 02:17:19.440]   Let's see.
[02:17:19.440 --> 02:17:26.200]   The US Justice Department has indicted a group of Chinese hackers for, among other things,
[02:17:26.200 --> 02:17:28.080]   the Anthem attack.
[02:17:28.080 --> 02:17:31.920]   You know how I didn't realize this, but now the way we know that it's a nation state,
[02:17:31.920 --> 02:17:36.160]   particularly the Chinese government doing these hacks, is when the information doesn't
[02:17:36.160 --> 02:17:37.880]   get on the dark web.
[02:17:37.880 --> 02:17:44.240]   So if a normal hacker attacks an insurance company and gets a lot of information, they
[02:17:44.240 --> 02:17:46.760]   would sell it on the dark web.
[02:17:46.760 --> 02:17:49.360]   When a nation state gets it, they're getting it for other reasons.
[02:17:49.360 --> 02:17:50.960]   They're not getting it for financial gain.
[02:17:50.960 --> 02:17:56.040]   In the case of China, they're apparently collecting information about US military, about Chinese
[02:17:56.040 --> 02:17:58.280]   citizens abroad.
[02:17:58.280 --> 02:18:00.280]   And medical research.
[02:18:00.280 --> 02:18:02.720]   There's lots of reasons for them to do it.
[02:18:02.720 --> 02:18:08.600]   So the Anthem attack, which I think we suspected was, in fact, I think the US government had
[02:18:08.600 --> 02:18:16.280]   said was a Chinese effort, is now, according to the DOJ, there's now an indictment.
[02:18:16.280 --> 02:18:23.280]   What was the number of 78 million records from Anthem, which is a big US insurer, 78.8
[02:18:23.280 --> 02:18:27.720]   million records, including names, health identification numbers, dates of birth, social security
[02:18:27.720 --> 02:18:32.720]   numbers, addresses, telephone numbers, email addresses, employment information, and income
[02:18:32.720 --> 02:18:33.720]   data.
[02:18:33.720 --> 02:18:34.720]   That's the kind of stuff.
[02:18:34.720 --> 02:18:36.960]   If you were a spy group, that would be gold.
[02:18:36.960 --> 02:18:41.840]   So glad to pay all that money to my health insurance provider just to have my data not
[02:18:41.840 --> 02:18:42.840]   being encrypted.
[02:18:42.840 --> 02:18:43.840]   Anthem Blue Cross.
[02:18:43.840 --> 02:18:44.840]   They're everybody.
[02:18:44.840 --> 02:18:48.600]   The giant behemoth of the US.
[02:18:48.600 --> 02:18:53.560]   Well, apparently, the same thing with the Marriott hack, the Starwood backpack.
[02:18:53.560 --> 02:18:59.560]   It was government's Chinese hackers who wanted information about travels of US intelligence.
[02:18:59.560 --> 02:19:01.120]   You want to talk about Monopoly?
[02:19:01.120 --> 02:19:02.120]   Yeah.
[02:19:02.120 --> 02:19:03.120]   Yeah.
[02:19:03.120 --> 02:19:04.120]   Starwood.
[02:19:04.120 --> 02:19:07.400]   It's like, I don't know if this will pass a federal law being proposed that would ban
[02:19:07.400 --> 02:19:10.280]   loot boxes.
[02:19:10.280 --> 02:19:12.160]   Josh Hawley added again, this guy's young.
[02:19:12.160 --> 02:19:14.400]   He must know about technology.
[02:19:14.400 --> 02:19:19.720]   He wants to prevent a prohibit video game loot boxes.
[02:19:19.720 --> 02:19:23.240]   For you olds, that's a randomized assortment of digital weapons, clothing, and other items
[02:19:23.240 --> 02:19:25.400]   that can be purchased for a fee.
[02:19:25.400 --> 02:19:27.680]   It's gambling, and it's kids.
[02:19:27.680 --> 02:19:31.680]   His bill is the Protecting Children from Abusive Games Act.
[02:19:31.680 --> 02:19:34.320]   I mean, I get it.
[02:19:34.320 --> 02:19:36.480]   Yeah, I think it should be illegal.
[02:19:36.480 --> 02:19:37.480]   Yeah.
[02:19:37.480 --> 02:19:39.920]   If you're under 18, basically it's gambling.
[02:19:39.920 --> 02:19:43.400]   And I know because my 16-year-old spends a lot of money on loot boxes.
[02:19:43.400 --> 02:19:46.360]   I always see it on my iTunes bill.
[02:19:46.360 --> 02:19:50.440]   You pay, and then you end up with some sort of collection of something.
[02:19:50.440 --> 02:19:51.440]   Yes.
[02:19:51.440 --> 02:19:54.480]   I mean, that just reminds me of the blind bag toys, right?
[02:19:54.480 --> 02:19:55.720]   We pay for those toys.
[02:19:55.720 --> 02:19:56.720]   They're wrapped up.
[02:19:56.720 --> 02:19:57.720]   You don't know what you're going to get inside.
[02:19:57.720 --> 02:19:58.720]   You open it.
[02:19:58.720 --> 02:20:01.480]   You want the collectible, and then you open it up.
[02:20:01.480 --> 02:20:03.160]   You get the third of the same thing.
[02:20:03.160 --> 02:20:04.160]   Yep.
[02:20:04.160 --> 02:20:05.920]   That's gambling with my money for my kids.
[02:20:05.920 --> 02:20:12.640]   Hawley pointed to Candy Crush, a popular free smartphone puzzle app for you olds, that
[02:20:12.640 --> 02:20:15.800]   allows-- actually, it's the young people that don't know what Candy Crush is.
[02:20:15.800 --> 02:20:16.800]   I was just saying.
[02:20:16.800 --> 02:20:17.800]   I don't think it's the old--
[02:20:17.800 --> 02:20:25.920]   That allows users to spend $150 on a bundle of goods, including virtual currency and other
[02:20:25.920 --> 02:20:28.000]   items that make the game easy to play.
[02:20:28.000 --> 02:20:29.000]   Yeah.
[02:20:29.000 --> 02:20:30.000]   I've got to confess.
[02:20:30.000 --> 02:20:31.000]   I've probably spent a few hundred bucks on poker.
[02:20:31.000 --> 02:20:33.440]   Oh, I've spent so much money on Animal Crossing.
[02:20:33.440 --> 02:20:36.440]   Nintendo, I've given them so much money.
[02:20:36.440 --> 02:20:38.600]   I have $300 in Simpsons donuts.
[02:20:38.600 --> 02:20:41.840]   I'm willing to trade for anything.
[02:20:41.840 --> 02:20:42.840]   It's gambling.
[02:20:42.840 --> 02:20:45.720]   It is gambling when you think about it that way.
[02:20:45.720 --> 02:20:48.240]   I mean, because I would just throw that money away in Vegas.
[02:20:48.240 --> 02:20:49.960]   No problem, just to have fun.
[02:20:49.960 --> 02:20:51.760]   It's bad.
[02:20:51.760 --> 02:20:55.080]   Samsung has announced it's next-- you guys will be interested in this.
[02:20:55.080 --> 02:20:57.920]   It's next camera sensor will be 64 megapixels.
[02:20:57.920 --> 02:20:58.920]   And it'll fold.
[02:20:58.920 --> 02:21:00.920]   Yeah, we'll see about that.
[02:21:00.920 --> 02:21:01.920]   Maybe it won't fold.
[02:21:01.920 --> 02:21:03.560]   They may say it'll fold.
[02:21:03.560 --> 02:21:08.320]   It sounds like a lot except that the current cameras, which are-- these are 12 megapixels,
[02:21:08.320 --> 02:21:13.560]   they're actually 48, so they use pixel doubling or quadrupling, I guess, to give you more
[02:21:13.560 --> 02:21:18.960]   light and give you in-plane focusing, things like that.
[02:21:18.960 --> 02:21:22.080]   But 64 will mean, what if I divide by 4, what is that?
[02:21:22.080 --> 02:21:23.760]   18 megapixel cameras.
[02:21:23.760 --> 02:21:26.920]   Now, so big improvement in cameras if Samsung makes them.
[02:21:26.920 --> 02:21:31.800]   I think most companies are using Sony sensors.
[02:21:31.800 --> 02:21:32.800]   A lot of them.
[02:21:32.800 --> 02:21:39.040]   Yeah, but Samsung, of course, is using its own and I expect other companies will be buying
[02:21:39.040 --> 02:21:40.040]   those as well.
[02:21:40.040 --> 02:21:44.640]   And maybe if Sony follows suit, we'll see 18 megapixels as the standard in our shooters.
[02:21:44.640 --> 02:21:45.640]   Who knows?
[02:21:45.640 --> 02:21:47.720]   Maybe they'll have five cameras on the back.
[02:21:47.720 --> 02:21:51.600]   They're still going to over process everything that you're going to take.
[02:21:51.600 --> 02:21:52.600]   Like Apple.
[02:21:52.600 --> 02:21:53.600]   All right.
[02:21:53.600 --> 02:21:57.680]   One more ad and then we will give you some final-- the seeds and the stems, the shape,
[02:21:57.680 --> 02:21:59.440]   the stuff that's fallen to the bottom.
[02:21:59.440 --> 02:22:02.600]   It's a very California reference to you.
[02:22:02.600 --> 02:22:04.720]   Of our news shoebox.
[02:22:04.720 --> 02:22:05.720]   Shake.
[02:22:05.720 --> 02:22:06.720]   Shake.
[02:22:06.720 --> 02:22:09.560]   Shake rattling roll.
[02:22:09.560 --> 02:22:13.840]   Our show today brought to you by the calming influence of calm.
[02:22:13.840 --> 02:22:14.840]   I love calm.
[02:22:14.840 --> 02:22:15.840]   Dot-com.
[02:22:15.840 --> 02:22:16.840]   Isn't calm awesome?
[02:22:16.840 --> 02:22:18.760]   I just bought it for my wife for Mother's Day.
[02:22:18.760 --> 02:22:20.600]   Oh, that's a good-- that's a good guess.
[02:22:20.600 --> 02:22:22.280]   It's not too late.
[02:22:22.280 --> 02:22:27.760]   If you're listening to this and it's 11.59pm on Sunday, quick.
[02:22:27.760 --> 02:22:35.360]   Go to calm and get 25% off a calm premium subscription, c-a-l-m.com/twit.
[02:22:35.360 --> 02:22:37.880]   I love calm.
[02:22:37.880 --> 02:22:41.840]   It's not just meditation, although this first thing you think of is meditation.
[02:22:41.840 --> 02:22:48.960]   And they do have kind of a daily calm, which is kind of a daily meditation exercise.
[02:22:48.960 --> 02:22:50.320]   But there's so much more.
[02:22:50.320 --> 02:22:51.320]   There's sleep stories.
[02:22:51.320 --> 02:22:52.320]   We've talked about these before.
[02:22:52.320 --> 02:22:56.960]   You can have Matthew McConaughey reading you a bedtime story.
[02:22:56.960 --> 02:23:00.920]   And then I think-- I hope they don't take this the wrong way.
[02:23:00.920 --> 02:23:07.600]   The nice thing about the sleep stories is they're so inconsequential that you don't
[02:23:07.600 --> 02:23:09.000]   mind falling asleep.
[02:23:09.000 --> 02:23:10.000]   Exactly.
[02:23:10.000 --> 02:23:11.000]   Right.
[02:23:11.000 --> 02:23:14.160]   See, if I listen to my audiobooks, then I fall asleep and I miss a chapter.
[02:23:14.160 --> 02:23:15.560]   I'd be like, oh, man.
[02:23:15.560 --> 02:23:17.200]   There's no cliffhanger in the sleep stories.
[02:23:17.200 --> 02:23:21.080]   But I couldn't care less if Matthew drones on--
[02:23:21.080 --> 02:23:23.080]   About the Lincoln Navigator?
[02:23:23.080 --> 02:23:24.080]   Yeah.
[02:23:24.080 --> 02:23:25.080]   I know.
[02:23:25.080 --> 02:23:28.840]   It's very much the mysteries of the universe.
[02:23:28.840 --> 02:23:29.840]   Before we begin--
[02:23:29.840 --> 02:23:30.840]   It's very relaxing.
[02:23:30.840 --> 02:23:34.320]   --as you settle in under the covers with your head easing into the pillow and your
[02:23:34.320 --> 02:23:35.320]   cover is--
[02:23:35.320 --> 02:23:36.320]   I'm already sleeping in the mattress.
[02:23:36.320 --> 02:23:37.320]   His, like, whistling--
[02:23:37.320 --> 02:23:39.640]   The essence really helps with it.
[02:23:39.640 --> 02:23:41.440]   Matthew's asleep under the covers.
[02:23:41.440 --> 02:23:42.440]   I'm not following a sleep.
[02:23:42.440 --> 02:23:44.440]   Let's ask the question.
[02:23:44.440 --> 02:23:48.280]   How often do we ponder the depth of the present moment?
[02:23:48.280 --> 02:23:49.280]   It is the--
[02:23:49.280 --> 02:23:50.440]   I'm not kidding you.
[02:23:50.440 --> 02:23:55.000]   I say this with absolute love, the best way to fall asleep.
[02:23:55.000 --> 02:23:56.000]   And I--
[02:23:56.000 --> 02:24:01.080]   I mean, they have the Game of Thrones guy, Braun, the Cell Sword.
[02:24:01.080 --> 02:24:02.080]   Jerome, what's his name?
[02:24:02.080 --> 02:24:03.380]   Jerome Flynn.
[02:24:03.380 --> 02:24:04.380]   He does one.
[02:24:04.380 --> 02:24:05.840]   That's awesome about New Zealand.
[02:24:05.840 --> 02:24:07.720]   I learned all about New Zealand.
[02:24:07.720 --> 02:24:08.920]   Let me play a little bit.
[02:24:08.920 --> 02:24:10.600]   Let me see if I can find that for you.
[02:24:10.600 --> 02:24:11.600]   This is so great.
[02:24:11.600 --> 02:24:12.600]   Steven Frye.
[02:24:12.600 --> 02:24:13.600]   Mm-hmm.
[02:24:13.600 --> 02:24:15.400]   What a great voice he has.
[02:24:15.400 --> 02:24:16.400]   So there's a lot of them.
[02:24:16.400 --> 02:24:17.840]   So you can pick the one you want.
[02:24:17.840 --> 02:24:20.360]   And again, they've got kids' books, Rapunzel.
[02:24:20.360 --> 02:24:22.200]   They've got the velveteen rabbit.
[02:24:22.200 --> 02:24:25.160]   You don't really mind if you kind of--
[02:24:25.160 --> 02:24:26.160]   Bob Ross.
[02:24:26.160 --> 02:24:27.520]   Bob Ross doing a little painting.
[02:24:27.520 --> 02:24:28.720]   Oh, I was just going to ask.
[02:24:28.720 --> 02:24:30.000]   That's how I fall asleep today.
[02:24:30.000 --> 02:24:31.000]   Oh, you'd love this.
[02:24:31.000 --> 02:24:32.280]   Yeah, I love his voice.
[02:24:32.280 --> 02:24:34.280]   Yeah.
[02:24:34.280 --> 02:24:35.760]   I can't find Jerome.
[02:24:35.760 --> 02:24:39.320]   Anyway, they've got Christmas stories.
[02:24:39.320 --> 02:24:41.400]   Sierra Nevada Stream.
[02:24:41.400 --> 02:24:44.160]   Oh, yeah, they also have environmental sounds.
[02:24:44.160 --> 02:24:45.600]   You want to see her in Nevada Stream?
[02:24:45.600 --> 02:24:46.360]   Let's listen.
[02:24:46.360 --> 02:24:47.400]   43 minutes.
[02:24:47.400 --> 02:24:52.160]   Plenty of time to get you fast asleep with a serrated
[02:24:52.160 --> 02:24:53.640]   dress dream.
[02:24:53.640 --> 02:24:55.800]   200,000 five-star reviews.
[02:24:55.800 --> 02:24:56.640]   People love calm.
[02:24:56.640 --> 02:24:57.760]   I love calm.
[02:24:57.760 --> 02:25:00.320]   So you get the meditations.
[02:25:00.320 --> 02:25:02.320]   Oh, yeah, that sounds like Sierra Nevada Stream.
[02:25:02.320 --> 02:25:04.200]   There are master classes, too.
[02:25:04.200 --> 02:25:07.520]   So you can learn in parenting, conscious parenting,
[02:25:07.520 --> 02:25:09.360]   gratitude, discovering happiness.
[02:25:09.360 --> 02:25:11.040]   I think gratitude's important.
[02:25:11.040 --> 02:25:12.880]   I always think I should be more grateful.
[02:25:12.880 --> 02:25:13.520]   Practice.
[02:25:13.520 --> 02:25:14.000]   Yeah, it is.
[02:25:14.000 --> 02:25:14.760]   Got to practice it.
[02:25:14.760 --> 02:25:15.240]   Yep.
[02:25:15.240 --> 02:25:16.880]   Rethinking depression.
[02:25:16.880 --> 02:25:20.760]   Somebody wants to know if they have Sam Kennison to fall asleep
[02:25:20.760 --> 02:25:20.960]   to--
[02:25:20.960 --> 02:25:21.960]   Go to sleep.
[02:25:21.960 --> 02:25:22.960]   Oh, go to sleep.
[02:25:22.960 --> 02:25:23.960]   Oh, no.
[02:25:23.960 --> 02:25:24.960]   Oh.
[02:25:24.960 --> 02:25:27.240]   No, they do not.
[02:25:27.240 --> 02:25:29.240]   In fact, I'm sorry I just woke you all up,
[02:25:29.240 --> 02:25:30.600]   but if you're driving, that's probably because--
[02:25:30.600 --> 02:25:32.560]   OK, there's more show for the Elizabeth.
[02:25:32.560 --> 02:25:35.200]   Don't go to sleep quite yet.
[02:25:35.200 --> 02:25:37.560]   Elizabeth Gilbert, I love her.
[02:25:37.560 --> 02:25:39.000]   Creative Living Beyond Fear.
[02:25:39.000 --> 02:25:40.400]   You guys, you had a whole book about that.
[02:25:40.400 --> 02:25:41.000]   You pray love.
[02:25:41.000 --> 02:25:43.000]   She's the-- you pray love, lady.
[02:25:43.000 --> 02:25:46.640]   So a whole class on this.
[02:25:46.640 --> 02:25:48.040]   And we're still-- by the way, this is nice.
[02:25:48.040 --> 02:25:50.920]   You can browse around Wall listening to the Sierra Nevada.
[02:25:50.920 --> 02:25:52.920]   It's a stream.
[02:25:52.920 --> 02:25:55.200]   Ah, there's Jerome.
[02:25:55.200 --> 02:25:57.480]   There's Jerome Flynn.
[02:25:57.480 --> 02:26:02.480]   "Brawn the Cell Sword, meandering down the Oxford Canal."
[02:26:02.480 --> 02:26:03.400]   It's got a great voice.
[02:26:03.400 --> 02:26:07.360]   And tonight, we'll be taking a relaxing boat ride
[02:26:07.360 --> 02:26:10.920]   through England's picturesque waterways.
[02:26:10.920 --> 02:26:12.920]   It's very supperific.
[02:26:12.920 --> 02:26:15.440]   Take a moment to cozy up and get--
[02:26:15.440 --> 02:26:17.320]   Moby has his new album on--
[02:26:17.320 --> 02:26:18.600]   This blew me away.
[02:26:18.600 --> 02:26:23.560]   Moby released his album anywhere except on calm.com.
[02:26:23.560 --> 02:26:25.680]   I'm a huge Moby fan.
[02:26:25.680 --> 02:26:27.360]   Here's Moby's ambience.
[02:26:27.360 --> 02:26:28.600]   Long ambience, too.
[02:26:28.600 --> 02:26:30.360]   It's all Moby, all new Moby.
[02:26:30.360 --> 02:26:33.560]   It's ambient music.
[02:26:33.560 --> 02:26:34.800]   And it's perfect.
[02:26:34.800 --> 02:26:36.680]   This is not just for sleeping.
[02:26:36.680 --> 02:26:38.560]   This is great if you work, if you're riding--
[02:26:38.560 --> 02:26:39.120]   It's focus.
[02:26:39.120 --> 02:26:41.440]   --or you're coding and you want to focus.
[02:26:41.440 --> 02:26:44.520]   And anytime there's lyrics, it distracts me.
[02:26:44.520 --> 02:26:46.560]   I like hearing something, though, in the background.
[02:26:46.560 --> 02:26:47.840]   This is so great.
[02:26:47.840 --> 02:26:49.000]   Calm.
[02:26:49.000 --> 02:26:51.680]   A great mindful app for beginners,
[02:26:51.680 --> 02:26:53.440]   if you want to learn meditation,
[02:26:53.440 --> 02:26:56.000]   hundreds of programs for intermediate and advanced users,
[02:26:56.000 --> 02:26:58.560]   find your inner piece, increase your focus,
[02:26:58.560 --> 02:27:01.920]   learn to manage your emotions, invest in your personal growth.
[02:27:01.920 --> 02:27:03.360]   It is the best money you've ever spent.
[02:27:03.360 --> 02:27:06.920]   Carsten, what a great Mother's Day gift for your wife.
[02:27:06.920 --> 02:27:07.600]   I think that's great.
[02:27:07.600 --> 02:27:10.040]   Kimmy's just going to love that.
[02:27:10.040 --> 02:27:13.640]   Moby's, you're getting calm.
[02:27:13.640 --> 02:27:16.320]   I actually give it to my daughter, calm.com/tripp,
[02:27:16.320 --> 02:27:17.880]   but now maybe I should give it to mom.
[02:27:17.880 --> 02:27:20.800]   Get 25% off a calm premium subscription,
[02:27:20.800 --> 02:27:25.840]   but you have to go to calm.com/tripp.
[02:27:25.840 --> 02:27:29.480]   Get calm and stop stressing.
[02:27:29.480 --> 02:27:31.240]   Calm.
[02:27:31.240 --> 02:27:32.840]   Calm/tripp.
[02:27:32.840 --> 02:27:35.080]   See, I like to do that at the end of the show.
[02:27:35.080 --> 02:27:36.080]   Thanks, guys.
[02:27:36.080 --> 02:27:38.120]   It's a stressful show.
[02:27:38.120 --> 02:27:40.120]   People will get upset.
[02:27:40.120 --> 02:27:43.600]   And now we feel better.
[02:27:43.600 --> 02:27:48.600]   So Singapore, which is not known as the most open-minded,
[02:27:48.600 --> 02:27:54.600]   democratic republic, has banned fake news.
[02:27:54.600 --> 02:27:59.600]   And they are going to police private chats.
[02:27:59.600 --> 02:28:02.600]   They're going to police social media.
[02:28:02.600 --> 02:28:06.600]   The protection from online falsehoods and manipulation, Bill.
[02:28:06.600 --> 02:28:11.600]   I almost feel like this is what we want to have here in the US.
[02:28:11.600 --> 02:28:12.600]   Hmm.
[02:28:12.600 --> 02:28:13.600]   Crickets.
[02:28:13.600 --> 02:28:16.600]   Penalties of up to a million dollars in a jail term of up to 10 years
[02:28:16.600 --> 02:28:21.600]   for spreading fake news with fake accounts or bots.
[02:28:21.600 --> 02:28:25.600]   So policing content in encrypted apps.
[02:28:25.600 --> 02:28:27.600]   Like how-- Well, if it's encrypted, obviously.
[02:28:27.600 --> 02:28:29.600]   I mean, that's their claim.
[02:28:29.600 --> 02:28:31.600]   Oh, they say they're going to do it even in encryption?
[02:28:31.600 --> 02:28:32.600]   Yeah.
[02:28:32.600 --> 02:28:33.600]   Oops.
[02:28:33.600 --> 02:28:34.600]   I mean, that might be hard to do.
[02:28:34.600 --> 02:28:36.600]   This might just be promising a little too much.
[02:28:36.600 --> 02:28:37.600]   Yeah.
[02:28:37.600 --> 02:28:39.600]   Well, we've seen governments do this before,
[02:28:39.600 --> 02:28:43.760]   but to my knowledge, WhatsApp, Signal, Apple, none of these
[02:28:43.760 --> 02:28:45.600]   companies are offering backdoors to--
[02:28:45.600 --> 02:28:46.600]   Right.
[02:28:46.600 --> 02:28:48.600]   Hey, Game of Thrones.
[02:28:48.600 --> 02:28:49.600]   We're talking about Game of Thrones.
[02:28:49.600 --> 02:28:53.600]   Maisie has a-- Maisie Williams has an app.
[02:28:53.600 --> 02:28:56.600]   I think this is a good way to capitalize on your basically
[02:28:56.600 --> 02:28:57.600]   ending fame now, right?
[02:28:57.600 --> 02:28:58.600]   Because it's over.
[02:28:58.600 --> 02:28:59.600]   Oh, one more--
[02:28:59.600 --> 02:29:00.600]   She'll find something else.
[02:29:00.600 --> 02:29:01.600]   She's really great.
[02:29:01.600 --> 02:29:02.600]   Yeah.
[02:29:02.600 --> 02:29:03.600]   It's called Daisy.
[02:29:03.600 --> 02:29:05.600]   It's a community to help artists grow in their careers.
[02:29:05.600 --> 02:29:06.600]   Oh.
[02:29:06.600 --> 02:29:10.600]   She did it with her film producer friend Dom Santri,
[02:29:10.600 --> 02:29:14.600]   and they launched on Wednesday, Daisy, from Maisie.
[02:29:14.600 --> 02:29:15.600]   Aw.
[02:29:15.600 --> 02:29:18.600]   You go to Daisy's website, create a profile.
[02:29:18.600 --> 02:29:20.600]   See, there is hope for social networks.
[02:29:20.600 --> 02:29:21.600]   Gen Z is the future.
[02:29:21.600 --> 02:29:23.600]   Gen Z is the future.
[02:29:23.600 --> 02:29:26.600]   Should I watch Game of Thrones?
[02:29:26.600 --> 02:29:27.600]   No.
[02:29:27.600 --> 02:29:28.600]   [LAUGHTER]
[02:29:28.600 --> 02:29:29.600]   [LAUGHTER]
[02:29:29.600 --> 02:29:30.600]   Yeah.
[02:29:30.600 --> 02:29:31.600]   Probably.
[02:29:31.600 --> 02:29:32.600]   Yeah.
[02:29:32.600 --> 02:29:33.600]   It's like, why was the Battle Star Galactica?
[02:29:33.600 --> 02:29:34.600]   That was a good show.
[02:29:34.600 --> 02:29:36.600]   I've been waiting for the series to end.
[02:29:36.600 --> 02:29:38.600]   No, I'll watch it.
[02:29:38.600 --> 02:29:40.600]   It's like how I need to watch Robocop.
[02:29:40.600 --> 02:29:41.600]   Yeah.
[02:29:41.600 --> 02:29:42.600]   It's part of the cultural vernacular.
[02:29:42.600 --> 02:29:43.600]   Yeah, but it's kind of the same thing.
[02:29:43.600 --> 02:29:45.600]   It's a little more of a commitment.
[02:29:45.600 --> 02:29:46.600]   Robocop's two hours.
[02:29:46.600 --> 02:29:47.600]   Little bit.
[02:29:47.600 --> 02:29:49.600]   Game of Thrones 62 hours.
[02:29:49.600 --> 02:29:50.600]   Yeah.
[02:29:50.600 --> 02:29:51.600]   It's a long time.
[02:29:51.600 --> 02:29:53.600]   I don't know how long at this point in my life it would take me
[02:29:53.600 --> 02:29:54.600]   to get through that many answers.
[02:29:54.600 --> 02:29:55.600]   If I could do Lost, I'd do all six seasons of Lost.
[02:29:55.600 --> 02:29:56.600]   Yeah.
[02:29:56.600 --> 02:29:57.600]   You can do Game of Thrones.
[02:29:57.600 --> 02:29:58.600]   Okay.
[02:29:58.600 --> 02:30:00.600]   I did all episodes of Lost as well, so you're right.
[02:30:00.600 --> 02:30:02.600]   I came to Lost after it was on TV.
[02:30:02.600 --> 02:30:03.600]   Okay.
[02:30:03.600 --> 02:30:04.600]   I have never seen Lost.
[02:30:04.600 --> 02:30:06.600]   I'm saving it for the nursing home.
[02:30:06.600 --> 02:30:08.600]   There's certain shows I want to have something to watch in the
[02:30:08.600 --> 02:30:09.600]   nursing home.
[02:30:09.600 --> 02:30:12.600]   And by then, I won't matter that it's confusing and never
[02:30:12.600 --> 02:30:14.600]   resolves because everything is.
[02:30:14.600 --> 02:30:15.600]   Because I can just keep watching.
[02:30:15.600 --> 02:30:18.600]   Everybody thinks everything else.
[02:30:18.600 --> 02:30:21.600]   There's a helium shortage.
[02:30:21.600 --> 02:30:22.600]   Oh, yes.
[02:30:22.600 --> 02:30:25.600]   Oh, by the way, I totally ran into this in Vegas a couple
[02:30:25.600 --> 02:30:26.600]   of weeks ago.
[02:30:26.600 --> 02:30:27.600]   No balloons.
[02:30:27.600 --> 02:30:30.600]   We were trying to get balloons for my friends' Bachelorette party.
[02:30:30.600 --> 02:30:32.600]   We bought some love balloons.
[02:30:32.600 --> 02:30:34.600]   As you do.
[02:30:34.600 --> 02:30:37.600]   And we went through to three stores and there was a
[02:30:37.600 --> 02:30:39.600]   helium shortage in Vegas.
[02:30:39.600 --> 02:30:42.600]   A global helium shortage.
[02:30:42.600 --> 02:30:46.600]   By the way, helium is also used for mixes for deep-sea
[02:30:46.600 --> 02:30:47.600]   divers.
[02:30:47.600 --> 02:30:49.600]   It's used in airbags.
[02:30:49.600 --> 02:30:54.600]   It's used in rocket fuel MRI machines, fiber optics
[02:30:54.600 --> 02:30:56.600]   and semiconductors.
[02:30:56.600 --> 02:30:59.600]   The shortage of helium is not going to get better.
[02:30:59.600 --> 02:31:02.600]   It's used in the production of the Chipmunks series.
[02:31:02.600 --> 02:31:03.600]   Yes.
[02:31:03.600 --> 02:31:04.600]   No, they don't.
[02:31:04.600 --> 02:31:05.600]   No, no.
[02:31:05.600 --> 02:31:07.600]   So party city.
[02:31:07.600 --> 02:31:11.600]   And it's going to shut down 45 stores this year.
[02:31:11.600 --> 02:31:13.600]   Oh, like casualty.
[02:31:13.600 --> 02:31:16.600]   I don't know if that's related to the helium.
[02:31:16.600 --> 02:31:18.600]   It is because that's the whole reason people went to
[02:31:18.600 --> 02:31:20.600]   Party City because the dollar tree won't do it unless you
[02:31:20.600 --> 02:31:22.600]   buy balloons from them.
[02:31:22.600 --> 02:31:23.600]   Oh, yeah.
[02:31:23.600 --> 02:31:24.600]   You got some knowledge.
[02:31:24.600 --> 02:31:27.600]   Listen, we went to a lot of places to get these.
[02:31:27.600 --> 02:31:28.600]   Party City.
[02:31:28.600 --> 02:31:31.600]   She is the queen of $17 wedding dresses and balloons you
[02:31:31.600 --> 02:31:32.600]   don't have to buy.
[02:31:32.600 --> 02:31:34.600]   I'm really good at throwing a theme party.
[02:31:34.600 --> 02:31:36.600]   So that's why I'm...
[02:31:36.600 --> 02:31:40.600]   Goodyear blimps operation not currently affected by
[02:31:40.600 --> 02:31:42.600]   the helium shortage.
[02:31:42.600 --> 02:31:44.600]   That's a relief.
[02:31:44.600 --> 02:31:46.600]   They could just fly a plane.
[02:31:46.600 --> 02:31:50.600]   Wow, they're closing 45 stores because of a helium
[02:31:50.600 --> 02:31:51.600]   shortage.
[02:31:51.600 --> 02:31:52.600]   This is serious.
[02:31:52.600 --> 02:31:53.600]   Yeah.
[02:31:53.600 --> 02:31:54.600]   Why would you buy anything in Party City when you could
[02:31:54.600 --> 02:31:57.600]   just order ahead of time from LA Express for like a fraction
[02:31:57.600 --> 02:31:58.600]   of the price.
[02:31:58.600 --> 02:31:59.600]   Because it's balloons.
[02:31:59.600 --> 02:32:00.600]   You don't order balloons by mail?
[02:32:00.600 --> 02:32:02.600]   Yeah, you do for Amazon.
[02:32:02.600 --> 02:32:03.600]   Inflated?
[02:32:03.600 --> 02:32:06.600]   No, but you inflate them after you get them.
[02:32:06.600 --> 02:32:08.600]   But there's no helium.
[02:32:08.600 --> 02:32:11.600]   But you have air in your lungs.
[02:32:11.600 --> 02:32:12.600]   You could just stick them to the wall.
[02:32:12.600 --> 02:32:14.600]   You could just stick them to the wall with scotch tape.
[02:32:14.600 --> 02:32:15.600]   That's from the end of doing that.
[02:32:15.600 --> 02:32:22.600]   So did you know that we have a National Helium Reserve?
[02:32:22.600 --> 02:32:25.600]   Yeah, but they're shutting it down in 20 with 21.
[02:32:25.600 --> 02:32:26.600]   Yeah, we had...
[02:32:26.600 --> 02:32:27.600]   Where is it?
[02:32:27.600 --> 02:32:29.600]   I don't know.
[02:32:29.600 --> 02:32:31.600]   It's floating up there.
[02:32:31.600 --> 02:32:34.600]   Helium is extracted from natural gas mining and from
[02:32:34.600 --> 02:32:36.600]   the National Helium Reserve.
[02:32:36.600 --> 02:32:38.600]   It's mostly kept in caves.
[02:32:38.600 --> 02:32:42.600]   Helium is a non-renewable resource that current
[02:32:42.600 --> 02:32:45.600]   consumption rates has been estimated that...
[02:32:45.600 --> 02:32:47.600]   Well, we've got some time left.
[02:32:47.600 --> 02:32:49.600]   200 years will be out.
[02:32:49.600 --> 02:32:52.600]   Some of us are urging the recycling of helium.
[02:32:52.600 --> 02:32:54.600]   This is hard to do.
[02:32:54.600 --> 02:32:55.600]   Yeah, no.
[02:32:55.600 --> 02:32:58.600]   I bet you they could make helium.
[02:32:58.600 --> 02:33:03.600]   All the helium that there ever has been was created in the Big Bang.
[02:33:03.600 --> 02:33:04.600]   That's it.
[02:33:04.600 --> 02:33:06.600]   You can't come on.
[02:33:06.600 --> 02:33:07.600]   You can't make helium.
[02:33:07.600 --> 02:33:09.600]   With fission you could make helium.
[02:33:09.600 --> 02:33:10.600]   No.
[02:33:10.600 --> 02:33:11.600]   No?
[02:33:11.600 --> 02:33:12.600]   No.
[02:33:12.600 --> 02:33:13.600]   You could do it with fusion.
[02:33:13.600 --> 02:33:14.600]   With fusion you can make helium.
[02:33:14.600 --> 02:33:17.600]   Okay, well, we fused some hydrogen atoms.
[02:33:17.600 --> 02:33:18.600]   We got helium.
[02:33:18.600 --> 02:33:20.600]   What's so hard about that?
[02:33:20.600 --> 02:33:21.600]   That's so expensive.
[02:33:21.600 --> 02:33:23.600]   What's so hard about that?
[02:33:23.600 --> 02:33:24.600]   It's so expensive.
[02:33:24.600 --> 02:33:27.600]   By the way, I started watching Chernobyl last night.
[02:33:27.600 --> 02:33:28.600]   Oh, yeah?
[02:33:28.600 --> 02:33:29.600]   Is it hard to watch?
[02:33:29.600 --> 02:33:30.600]   Yeah.
[02:33:30.600 --> 02:33:31.600]   Yeah.
[02:33:31.600 --> 02:33:32.600]   And that's what I'm afraid of.
[02:33:32.600 --> 02:33:33.600]   Yeah, but it's powerful.
[02:33:33.600 --> 02:33:34.600]   Yeah.
[02:33:34.600 --> 02:33:35.600]   Yeah.
[02:33:35.600 --> 02:33:38.600]   I think that that was the shakes.
[02:33:38.600 --> 02:33:39.600]   Those were the seeds.
[02:33:39.600 --> 02:33:42.600]   The stems and the seeds and everything else.
[02:33:42.600 --> 02:33:44.600]   And I'm sorry about the spoiler.
[02:33:44.600 --> 02:33:46.600]   God, I feel terrible.
[02:33:46.600 --> 02:33:48.600]   It's like the worst thing I've ever done.
[02:33:48.600 --> 02:33:49.600]   That'll be beeped.
[02:33:49.600 --> 02:33:50.600]   I just blurbed it out.
[02:33:50.600 --> 02:33:51.600]   It just came out.
[02:33:51.600 --> 02:33:52.600]   I apologize.
[02:33:52.600 --> 02:33:53.600]   Sorry, Leo.
[02:33:53.600 --> 02:34:03.600]   The sun converts four heliums into four million tons of -- four hydrogens into four million tons of helium every second.
[02:34:03.600 --> 02:34:05.600]   So there is plenty of helium.
[02:34:05.600 --> 02:34:06.600]   Sorry.
[02:34:06.600 --> 02:34:07.600]   Sorry.
[02:34:07.600 --> 02:34:08.600]   You're right.
[02:34:08.600 --> 02:34:09.600]   We just have to go to the sun and make helium.
[02:34:09.600 --> 02:34:15.600]   You can't make hydrogen because it's one atom, but you can -- helium's two or three.
[02:34:15.600 --> 02:34:16.600]   Right?
[02:34:16.600 --> 02:34:21.600]   Are we running out of hydrogen?
[02:34:21.600 --> 02:34:27.600]   No, that's still the most plentiful element in the universe.
[02:34:27.600 --> 02:34:31.600]   I feel like we didn't think about this as humans.
[02:34:31.600 --> 02:34:32.600]   We didn't plan our helium.
[02:34:32.600 --> 02:34:35.600]   Do you really plan like things are going to run out?
[02:34:35.600 --> 02:34:36.600]   We did not think about that.
[02:34:36.600 --> 02:34:37.600]   We're not good at that, actually.
[02:34:37.600 --> 02:34:38.600]   We did not.
[02:34:38.600 --> 02:34:41.600]   Party sitting and not putting that into its business contingency plan.
[02:34:41.600 --> 02:34:43.600]   They have 45 stores.
[02:34:43.600 --> 02:34:46.600]   They're just closing down for helium wax.
[02:34:46.600 --> 02:34:48.600]   There is really no reason to go to Party City.
[02:34:48.600 --> 02:34:51.600]   Diso has way better decorations.
[02:34:51.600 --> 02:34:53.600]   Is there a Party City around here?
[02:34:53.600 --> 02:34:54.600]   I don't know.
[02:34:54.600 --> 02:34:56.600]   There is one going in.
[02:34:56.600 --> 02:35:00.600]   Not in the middle, but a couple of miles away, actually.
[02:35:00.600 --> 02:35:01.600]   Over by Safeway.
[02:35:01.600 --> 02:35:03.600]   Probably not going to be able to get helium there.
[02:35:03.600 --> 02:35:05.600]   Apparently, maybe they're not going to end up hoping.
[02:35:05.600 --> 02:35:06.600]   No balloons for you.
[02:35:06.600 --> 02:35:07.600]   Mark, I apologize.
[02:35:07.600 --> 02:35:09.600]   I know we told you this was a serious show.
[02:35:09.600 --> 02:35:12.600]   By the end it falls apart.
[02:35:12.600 --> 02:35:15.600]   We are so glad you came.
[02:35:15.600 --> 02:35:17.600]   Mark Sullivan, please come back anytime.
[02:35:17.600 --> 02:35:22.600]   Mark is a senior writer at the fabulous Fast Company, Fast Company.com.
[02:35:22.600 --> 02:35:24.600]   On the Twitter at the Sullivan.
[02:35:24.600 --> 02:35:25.600]   Anything you want to plug?
[02:35:25.600 --> 02:35:26.600]   No.
[02:35:26.600 --> 02:35:27.600]   Nothing.
[02:35:27.600 --> 02:35:28.600]   Really, thanks for having me.
[02:35:28.600 --> 02:35:29.600]   That's great to have you.
[02:35:29.600 --> 02:35:30.600]   I feel so bad.
[02:35:30.600 --> 02:35:32.600]   Here we all have big computers and stuff.
[02:35:32.600 --> 02:35:34.600]   He's sitting there with an iPhone.
[02:35:34.600 --> 02:35:36.600]   This is above all your needs.
[02:35:36.600 --> 02:35:39.600]   I mean, I'm barely taught at the screen.
[02:35:39.600 --> 02:35:42.600]   Yes, I'm an overachiever with my 30-inch Windows
[02:35:42.600 --> 02:35:43.600]   Surface Studio.
[02:35:43.600 --> 02:35:44.600]   I'll bring mine next time.
[02:35:44.600 --> 02:35:45.600]   Yes, next time bring yours.
[02:35:45.600 --> 02:35:46.600]   That's it.
[02:35:46.600 --> 02:35:49.600]   Florence Ion, all about Android.
[02:35:49.600 --> 02:35:54.600]   Every Tuesday, 5 p.m. Pacific, 8 p.m. Eastern, Twit.tv/AA.
[02:35:54.600 --> 02:35:56.600]   Oh, that flow on the Twitter.
[02:35:56.600 --> 02:36:00.600]   Is there anything you want to talk about?
[02:36:00.600 --> 02:36:01.600]   Yes, actually.
[02:36:01.600 --> 02:36:04.600]   If you head over to Life Hacker, I've got an article up there
[02:36:04.600 --> 02:36:10.600]   about what's new in Android Q and working on some reporting
[02:36:10.600 --> 02:36:12.600]   on the side to figure out what's going on with Nest.
[02:36:12.600 --> 02:36:13.600]   So stay tuned.
[02:36:13.600 --> 02:36:16.600]   Yes, it's really important because it's clear that it's unclear.
[02:36:16.600 --> 02:36:17.600]   We need to know more.
[02:36:17.600 --> 02:36:18.600]   It's time to know.
[02:36:18.600 --> 02:36:19.600]   We're waiting.
[02:36:19.600 --> 02:36:20.600]   So that's exciting.
[02:36:20.600 --> 02:36:21.600]   Thank you, Flo.
[02:36:21.600 --> 02:36:23.600]   All about Android.
[02:36:23.600 --> 02:36:26.600]   Also, Mr. Jason Howell also tech news weekly.
[02:36:26.600 --> 02:36:29.600]   You'll find on Twitter at Jason Howell.
[02:36:29.600 --> 02:36:31.600]   Do you have any podcasts you'd like to plug?
[02:36:31.600 --> 02:36:33.600]   Well, all about Android.
[02:36:33.600 --> 02:36:36.600]   You're not working for relay FM or anything.
[02:36:36.600 --> 02:36:39.600]   No, I think this is about it.
[02:36:39.600 --> 02:36:40.600]   This is all you.
[02:36:40.600 --> 02:36:41.600]   This is what I do.
[02:36:41.600 --> 02:36:42.600]   I know you do.
[02:36:42.600 --> 02:36:45.600]   With Andy and Aco, the fabulous material podcast.
[02:36:45.600 --> 02:36:46.600]   Yes, indeed.
[02:36:46.600 --> 02:36:47.600]   I was giving you a chance.
[02:36:47.600 --> 02:36:48.600]   I was giving you a chance.
[02:36:48.600 --> 02:36:49.600]   I know.
[02:36:49.600 --> 02:36:50.600]   I always have Andy plug it too.
[02:36:50.600 --> 02:36:51.600]   I know.
[02:36:51.600 --> 02:36:53.600]   He's really good about plugging everything.
[02:36:53.600 --> 02:36:54.600]   I'm a little more.
[02:36:54.600 --> 02:36:55.600]   I'm terrible.
[02:36:55.600 --> 02:36:57.600]   I gotta get into a better habit of...
[02:36:57.600 --> 02:37:00.600]   I am so bad at marketing of any kind.
[02:37:00.600 --> 02:37:01.600]   I do.
[02:37:01.600 --> 02:37:05.600]   I feel like I just want to be, you know, the best kept secret in podcasting.
[02:37:05.600 --> 02:37:07.600]   And good news.
[02:37:07.600 --> 02:37:09.600]   We're winning.
[02:37:09.600 --> 02:37:10.600]   Winning.
[02:37:10.600 --> 02:37:12.600]   We thank you all for being here.
[02:37:12.600 --> 02:37:14.600]   We had a great studio audience from all over the world.
[02:37:14.600 --> 02:37:15.600]   Yeah.
[02:37:15.600 --> 02:37:17.600]   If you want to be in the studio, we'd love to have you.
[02:37:17.600 --> 02:37:21.600]   All you have to do is email tickets at twitter.tv.
[02:37:21.600 --> 02:37:24.600]   And we will be glad to put a chair out for you.
[02:37:24.600 --> 02:37:26.600]   Thank you all for being here.
[02:37:26.600 --> 02:37:28.600]   You can also participate on our livestream.
[02:37:28.600 --> 02:37:32.600]   That's twitter.tv/liveaudio or video there.
[02:37:32.600 --> 02:37:34.600]   And if you do that, join us in the chat room.
[02:37:34.600 --> 02:37:35.600]   I'm in there.
[02:37:35.600 --> 02:37:36.600]   Everybody's in there.
[02:37:36.600 --> 02:37:38.600]   All about...
[02:37:38.600 --> 02:37:40.600]   No, what's the name of the chat room?
[02:37:40.600 --> 02:37:41.600]   Twit.
[02:37:41.600 --> 02:37:44.600]   IRC.twit.tv.
[02:37:44.600 --> 02:37:47.600]   But if you want to say all about Android again, that's fine.
[02:37:47.600 --> 02:37:48.600]   All about Android.
[02:37:48.600 --> 02:37:49.600]   All right.
[02:37:49.600 --> 02:37:50.600]   Twit.tv.
[02:37:50.600 --> 02:37:52.600]   Get the word out there.
[02:37:52.600 --> 02:37:55.600]   We also give you on-demand versions of everything we do.
[02:37:55.600 --> 02:37:58.600]   Because that's what a podcast is.
[02:37:58.600 --> 02:38:00.600]   So you can listen or watch at your convenience.
[02:38:00.600 --> 02:38:01.600]   Yeah, we do have audio and video.
[02:38:01.600 --> 02:38:03.600]   That's not what a podcast is.
[02:38:03.600 --> 02:38:04.600]   How do you like those new buttons?
[02:38:04.600 --> 02:38:05.600]   I like those.
[02:38:05.600 --> 02:38:08.600]   You can go right to the website, twit.tv.
[02:38:08.600 --> 02:38:13.600]   And easy to subscribe if you want to do so in the pocketcast
[02:38:13.600 --> 02:38:16.600]   or Apple Podcasts or Google Podcasts or Spotify or YouTube.
[02:38:16.600 --> 02:38:18.600]   We even give you a plain RSS feed.
[02:38:18.600 --> 02:38:21.600]   You can paste into most podcatchers overcast.
[02:38:21.600 --> 02:38:23.600]   Whatever you use, make sure you subscribe that way.
[02:38:23.600 --> 02:38:26.600]   You'll get the latest version of Twit the minute it's available.
[02:38:26.600 --> 02:38:29.600]   You can also listen on your voice activated device.
[02:38:29.600 --> 02:38:31.600]   You could say two things.
[02:38:31.600 --> 02:38:33.600]   You could say echo.
[02:38:33.600 --> 02:38:34.600]   Listen to play Twit Live.
[02:38:34.600 --> 02:38:36.600]   And then you'll hear whatever we're doing live.
[02:38:36.600 --> 02:38:37.600]   Or echo.
[02:38:37.600 --> 02:38:38.600]   Play.
[02:38:38.600 --> 02:38:39.600]   This week in Tech Podcasts.
[02:38:39.600 --> 02:38:41.600]   It'll play the most recent version of the podcast.
[02:38:41.600 --> 02:38:43.600]   Or all about Android or Material or whatever it is.
[02:38:43.600 --> 02:38:45.600]   I love that about these assistants.
[02:38:45.600 --> 02:38:47.600]   It's making it so easy to listen to podcasts.
[02:38:47.600 --> 02:38:48.600]   Thanks everybody.
[02:38:48.600 --> 02:38:49.600]   We'll see you soon.
[02:38:49.600 --> 02:38:50.600]   Another Twit.
[02:38:50.600 --> 02:38:51.600]   It's in the can.
[02:38:51.600 --> 02:38:52.600]   It's easy.
[02:38:52.600 --> 02:38:55.180]   (upbeat music)
[02:38:55.180 --> 02:38:56.020]   - Do on the Twit
[02:38:56.020 --> 02:38:56.860]   - Do on the Twit
[02:38:56.860 --> 02:38:57.860]   - All right
[02:38:57.860 --> 02:38:59.440]   - Do on the Twit, baby
[02:38:59.440 --> 02:39:00.600]   - Do on the Twit
[02:39:00.600 --> 02:39:01.600]   - All right

