;FFMETADATA1
title=Zoom Dating
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=813
genre=Podcast
comment=https://twit.tv/twit
copyright=These podcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2021
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.560]   It's time for Twit this week in tech.
[00:00:02.560 --> 00:00:05.000]   Return of Will Harris, our old friend from London.
[00:00:05.000 --> 00:00:08.440]   He'll be visiting with Lisa Schmeiser from ITPro today.
[00:00:08.440 --> 00:00:11.480]   And of course, Alex Lindsey of Mac Break Weekly.
[00:00:11.480 --> 00:00:13.440]   Office Hours in 090 Media.
[00:00:13.440 --> 00:00:15.400]   We've got a lot to talk about.
[00:00:15.400 --> 00:00:17.720]   Fighting Zoom Fatigue.
[00:00:17.720 --> 00:00:20.400]   We'll talk about the huge Microsoft hack
[00:00:20.400 --> 00:00:24.480]   that's putting 60,000 organizations at risk.
[00:00:24.480 --> 00:00:28.440]   And then what Google's doing to eliminate third party browser
[00:00:28.440 --> 00:00:31.240]   cookies, is it really for the public good?
[00:00:31.240 --> 00:00:35.080]   It's all coming up next on Twit.
[00:00:35.080 --> 00:00:39.800]   Podcasts you love from people you trust.
[00:00:39.800 --> 00:00:41.200]   This is Twit.
[00:00:41.200 --> 00:00:51.080]   This is Twit this weekend tech.
[00:00:51.080 --> 00:00:56.880]   Episode 813 recorded Sunday, March 7, 2021.
[00:00:56.880 --> 00:00:58.920]   Zoom Dating.
[00:00:58.920 --> 00:01:02.160]   This week, attack is brought to you by ExtraHop.
[00:01:02.160 --> 00:01:05.440]   When cyber criminals get past your business's defenses,
[00:01:05.440 --> 00:01:08.160]   you need a plan for detection and response.
[00:01:08.160 --> 00:01:10.020]   Learn more about how ExtraHop stops
[00:01:10.020 --> 00:01:14.200]   preaches 84% faster and explore the interactive demo
[00:01:14.200 --> 00:01:17.600]   at extrahop.com/twit.
[00:01:17.600 --> 00:01:21.120]   And by ZipRecruiter, hiring is challenging,
[00:01:21.120 --> 00:01:23.720]   especially with everything else you have to consider today.
[00:01:23.720 --> 00:01:26.600]   But there's one place where hiring is simple, fast,
[00:01:26.600 --> 00:01:27.600]   and smart.
[00:01:27.600 --> 00:01:29.440]   That place is ZipRecruiter.
[00:01:29.440 --> 00:01:32.640]   Try ZipRecruiter for free at zipprecruiter.com/twit.
[00:01:32.640 --> 00:01:36.000]   ZipRecruiter, the smartest way to hire.
[00:01:36.000 --> 00:01:38.200]   And by Barracuda.
[00:01:38.200 --> 00:01:40.520]   Hackers are always looking for the weakest link
[00:01:40.520 --> 00:01:43.480]   in your security configuration, especially
[00:01:43.480 --> 00:01:45.040]   in your email security.
[00:01:45.040 --> 00:01:47.240]   Barracuda's new threat analyzer tool
[00:01:47.240 --> 00:01:51.080]   helps you gain visibility into your particular vulnerabilities.
[00:01:51.080 --> 00:01:51.840]   It's easy.
[00:01:51.840 --> 00:01:55.160]   Visit barracuda.com/twit.
[00:01:55.160 --> 00:01:57.920]   And by Uber for Business.
[00:01:57.920 --> 00:02:00.760]   Right now, for a limited time, receive a $50 voucher
[00:02:00.760 --> 00:02:02.600]   when you create your first voucher's campaign
[00:02:02.600 --> 00:02:04.040]   and spend $200.
[00:02:04.040 --> 00:02:07.080]   Go to uber.com/twit to learn more.
[00:02:07.080 --> 00:02:09.400]   [MUSIC PLAYING]
[00:02:09.400 --> 00:02:15.480]   It's time for "Twit This Week in Tech,"
[00:02:15.480 --> 00:02:19.560]   the show we cover the week's tech news.
[00:02:19.560 --> 00:02:22.400]   Oh, I'm going to have a fun time on this panel.
[00:02:22.400 --> 00:02:26.400]   Alex Lindsey is here schooling us on how to do this.
[00:02:26.400 --> 00:02:26.900]   Hello.
[00:02:26.900 --> 00:02:30.880]   He's the king of office hours, 090.media.
[00:02:30.880 --> 00:02:35.760]   And also on Zoom today, which looks kind of a lot better
[00:02:35.760 --> 00:02:36.720]   than Skype does.
[00:02:36.720 --> 00:02:38.800]   And sounds fantastic.
[00:02:38.800 --> 00:02:41.600]   Yeah, Zoom's put a lot of pretty great tools
[00:02:41.600 --> 00:02:43.240]   into their audio.
[00:02:43.240 --> 00:02:45.520]   So I think it's come a long way.
[00:02:45.520 --> 00:02:47.040]   It was way behind Skype.
[00:02:47.040 --> 00:02:48.360]   And then I think it kind of lasted.
[00:02:48.360 --> 00:02:50.040]   Skype is kind of--
[00:02:50.040 --> 00:02:51.520]   we've been using Skype for 15 years.
[00:02:51.520 --> 00:02:53.480]   You know who knows that well, better than anybody?
[00:02:53.480 --> 00:02:56.800]   This guy right here, Will Harris, who is back on.
[00:02:56.800 --> 00:02:59.480]   You've been with us for as long as almost anybody.
[00:02:59.480 --> 00:03:01.760]   It's great to see you, Will.
[00:03:01.760 --> 00:03:02.840]   Good evening, Leo.
[00:03:02.840 --> 00:03:04.840]   It's great to be here, great to be back.
[00:03:04.840 --> 00:03:07.360]   It's been a while, but it's also been--
[00:03:07.360 --> 00:03:09.440]   yeah, I remember when we were first
[00:03:09.440 --> 00:03:11.600]   trying to cobble this Skype stuff together.
[00:03:11.600 --> 00:03:12.040]   Yeah.
[00:03:12.040 --> 00:03:13.800]   A decade and a half ago or something.
[00:03:13.800 --> 00:03:14.280]   It's all scratchy.
[00:03:14.280 --> 00:03:15.760]   So we come a long way.
[00:03:15.760 --> 00:03:16.600]   A long way.
[00:03:16.600 --> 00:03:18.480]   Or not at all, depending on how you look at it.
[00:03:18.480 --> 00:03:22.720]   Alex and Will go back to the cottage days.
[00:03:22.720 --> 00:03:27.200]   So Will, you're in the city, the real city, London.
[00:03:27.200 --> 00:03:29.000]   I am in the real city of London.
[00:03:29.000 --> 00:03:31.840]   The real city where it's about 10 at night.
[00:03:31.840 --> 00:03:34.320]   So thank you for staying up with us a little bit.
[00:03:34.320 --> 00:03:35.640]   That's always a pleasure.
[00:03:35.640 --> 00:03:36.760]   Will's got a new startup.
[00:03:36.760 --> 00:03:40.480]   Every time you hear you have a new startup.
[00:03:40.480 --> 00:03:41.280]   This one's cool.
[00:03:41.280 --> 00:03:44.520]   Intel, E-N-T-A-L-E.com.
[00:03:44.520 --> 00:03:45.200]   It's a--
[00:03:45.200 --> 00:03:47.720]   Yeah, it's a very cool way of listening to your podcasts.
[00:03:47.720 --> 00:03:50.960]   That delivers some contextual information
[00:03:50.960 --> 00:03:54.640]   with some very neat AI that we've developed during the pandemic.
[00:03:54.640 --> 00:03:56.960]   We've been heads down and just coding away
[00:03:56.960 --> 00:03:58.800]   whilst the world carries on around us.
[00:03:58.800 --> 00:04:00.480]   That's cool.
[00:04:00.480 --> 00:04:03.040]   Are you always going to have a new company like is that?
[00:04:03.040 --> 00:04:05.160]   That was a war.
[00:04:05.160 --> 00:04:05.800]   I mean, you love doing it.
[00:04:05.800 --> 00:04:10.000]   Well, yeah, I love new things.
[00:04:10.000 --> 00:04:11.160]   Love anything exciting.
[00:04:11.160 --> 00:04:13.040]   And podcasts have always been--
[00:04:13.040 --> 00:04:14.680]   as you know, close to my heart.
[00:04:14.680 --> 00:04:19.120]   So always about trying to improve that experience.
[00:04:19.120 --> 00:04:23.600]   Also with us, because it is International Woman's Month.
[00:04:23.600 --> 00:04:24.920]   We have a woman.
[00:04:24.920 --> 00:04:26.200]   Ladies and gentlemen.
[00:04:26.200 --> 00:04:28.160]   [LAUGHTER]
[00:04:28.160 --> 00:04:29.160]   Hello, Lisa Schmeiser.
[00:04:29.160 --> 00:04:29.760]   Great to see you.
[00:04:29.760 --> 00:04:30.360]   See you.
[00:04:30.360 --> 00:04:33.720]   Now senior editor at IT Pro today.
[00:04:33.720 --> 00:04:35.280]   Tomorrow is International Woman's Day.
[00:04:35.280 --> 00:04:38.800]   I was just informed by the women in my life.
[00:04:38.800 --> 00:04:39.320]   Yes.
[00:04:39.320 --> 00:04:42.240]   Well, I'd like to hope I'm on the show for reasons other than--
[00:04:42.240 --> 00:04:43.240]   No.
[00:04:43.240 --> 00:04:45.640]   --I mean, I'm not going to say DNA makeup, but--
[00:04:45.640 --> 00:04:47.720]   I totally--
[00:04:47.720 --> 00:04:52.560]   I mean, I think it's important, I guess, that we do some--
[00:04:52.560 --> 00:04:56.960]   pay attention to that and do some diversity stuff.
[00:04:56.960 --> 00:04:59.280]   But I don't want to pick people just for their gender
[00:04:59.280 --> 00:05:01.960]   or race or cut, creed or whatever.
[00:05:01.960 --> 00:05:03.840]   I mean, I feel like we pick--
[00:05:03.840 --> 00:05:07.680]   you're here because you're a tech journalist, a smart person.
[00:05:07.680 --> 00:05:08.560]   Well, thank you.
[00:05:08.560 --> 00:05:10.960]   Because we all share a love of Zoom fatigue.
[00:05:10.960 --> 00:05:11.480]   Well, actually--
[00:05:11.480 --> 00:05:12.680]   --he apparently we do.
[00:05:12.680 --> 00:05:16.280]   You represent the ginger segment of our audience.
[00:05:16.280 --> 00:05:17.600]   [LAUGHTER]
[00:05:17.600 --> 00:05:19.440]   Have you always been this much of a redhead?
[00:05:19.440 --> 00:05:22.800]   Or is this finally we're getting a decent picture this time?
[00:05:22.800 --> 00:05:25.840]   I think maybe the internet connection is a little bit better.
[00:05:25.840 --> 00:05:28.600]   But also, lockdown has brought out a little bit of the energy.
[00:05:28.600 --> 00:05:31.240]   Ginger, I love it, the energy.
[00:05:31.240 --> 00:05:32.920]   Yeah, actually, we might as well-- you know what?
[00:05:32.920 --> 00:05:37.360]   Alex Lindsey last week said, I have to get onto it
[00:05:37.360 --> 00:05:40.440]   because I read this ridiculous press release
[00:05:40.440 --> 00:05:44.320]   from Stanford about Zoom fatigue and why we get it.
[00:05:44.320 --> 00:05:46.160]   And I have to debunk it.
[00:05:46.160 --> 00:05:48.840]   And then what's funny is we put it in the rundown.
[00:05:48.840 --> 00:05:49.640]   It's not high up.
[00:05:49.640 --> 00:05:51.120]   It's kind of low down on the rundown.
[00:05:51.120 --> 00:05:53.440]   But we'll just spontaneously, as he signed in,
[00:05:53.440 --> 00:05:56.320]   said, I've got to talk about Zoom.
[00:05:56.320 --> 00:05:58.600]   And then Lisa said, yeah, I just wrote an article
[00:05:58.600 --> 00:05:59.600]   about Zoom fatigue.
[00:05:59.600 --> 00:06:03.320]   So we have three experts on Zoom fatigue.
[00:06:03.320 --> 00:06:04.720]   Let me tell you what Stanford said,
[00:06:04.720 --> 00:06:07.520]   and then you guys can weigh in.
[00:06:07.520 --> 00:06:11.360]   Stanford, this is the headline from Stanford Press release,
[00:06:11.360 --> 00:06:13.000]   stanford.edu.
[00:06:13.000 --> 00:06:17.360]   Stanford researchers identify four causes for Zoom fatigue,
[00:06:17.360 --> 00:06:20.520]   and then they offer simple fixes.
[00:06:20.520 --> 00:06:23.680]   It's not just-- already Lisa's laughing.
[00:06:23.680 --> 00:06:24.800]   It's not just Zoom.
[00:06:24.800 --> 00:06:27.400]   Popular video chat platforms have design flaws
[00:06:27.400 --> 00:06:30.160]   that exhaust the human mind and body,
[00:06:30.160 --> 00:06:32.880]   but there are easy ways to mitigate the effects.
[00:06:32.880 --> 00:06:34.040]   Here are the four reasons.
[00:06:34.040 --> 00:06:37.960]   Too much close up eye contact.
[00:06:37.960 --> 00:06:43.040]   It's overly intimate because the size of the face on the screens
[00:06:43.040 --> 00:06:46.400]   is abnormally large, and on Zoom calls everyone's
[00:06:46.400 --> 00:06:49.400]   looking at everyone all the time.
[00:06:49.400 --> 00:06:51.680]   There's just too much eye contact.
[00:06:51.680 --> 00:06:56.240]   So they're quoting in this report,
[00:06:56.240 --> 00:06:59.480]   a journal technology, mind, and behavior.
[00:06:59.480 --> 00:07:02.320]   It's the first peer reviewed article that systematically
[00:07:02.320 --> 00:07:07.520]   deconstructs Zoom fatigue by Professor Jeremy Balenson.
[00:07:07.520 --> 00:07:10.960]   And Balenson says, the fix for this
[00:07:10.960 --> 00:07:13.240]   is take Zoom off the full screen option,
[00:07:13.240 --> 00:07:14.680]   reduce the size of the Zoom window.
[00:07:14.680 --> 00:07:15.960]   I always watch it in a grid mode.
[00:07:15.960 --> 00:07:17.280]   I don't know what's wrong with that.
[00:07:17.280 --> 00:07:19.520]   Relative to the monitor minimize face size.
[00:07:19.520 --> 00:07:22.640]   And use an external keyboard to allow an increase
[00:07:22.640 --> 00:07:24.600]   in the personal space bubble.
[00:07:24.600 --> 00:07:25.880]   I'm going to move back.
[00:07:25.880 --> 00:07:29.520]   Let me increase the space bubble between myself and the grid.
[00:07:29.520 --> 00:07:33.640]   Number two, seeing yourself during video chats constantly
[00:07:33.640 --> 00:07:35.200]   in real time is fatiguing.
[00:07:35.200 --> 00:07:40.440]   And of course, the fix for that is just hide your own view.
[00:07:40.440 --> 00:07:44.520]   Third, video chats dramatically reduce our usual mobility.
[00:07:44.520 --> 00:07:45.000]   That's true.
[00:07:45.000 --> 00:07:47.240]   And when I'm on the phone a lot of times, I will walk around.
[00:07:47.240 --> 00:07:49.920]   I find myself-- I look up and suddenly I'm outdoors.
[00:07:49.920 --> 00:07:52.680]   I don't know how that happened.
[00:07:52.680 --> 00:07:56.720]   So I don't know what the fix is except to move the camera farther
[00:07:56.720 --> 00:07:58.880]   away so that you can move around.
[00:07:58.880 --> 00:08:01.840]   Maybe he says pace and doodle.
[00:08:01.840 --> 00:08:06.520]   And finally, the cognitive load is much higher in video chats.
[00:08:06.520 --> 00:08:09.400]   During long stretch of media is give yourself an audio only
[00:08:09.400 --> 00:08:13.640]   break, turn off your camera so you don't
[00:08:13.640 --> 00:08:15.720]   have to be non-verbally active.
[00:08:15.720 --> 00:08:16.360]   That is true.
[00:08:16.360 --> 00:08:20.320]   I've seen-- I saw a TikTok where a woman was on a Zoom
[00:08:20.320 --> 00:08:22.640]   meeting very lively and so essentially close to it.
[00:08:22.640 --> 00:08:26.160]   It was like, oh, I'm so dumb.
[00:08:26.160 --> 00:08:27.360]   What's wrong with this, Alex?
[00:08:27.360 --> 00:08:30.360]   Well, I mean, I think that fundamentally--
[00:08:30.360 --> 00:08:33.120]   and to be fair to the researchers,
[00:08:33.120 --> 00:08:36.200]   that he does say in there that this is theoretical.
[00:08:36.200 --> 00:08:38.200]   This isn't like they did a bunch of research.
[00:08:38.200 --> 00:08:40.440]   I mean, they didn't do the research at a full level.
[00:08:40.440 --> 00:08:42.440]   Most of this isn't peer-reviewed.
[00:08:42.440 --> 00:08:44.480]   This is a bunch of ideas.
[00:08:44.480 --> 00:08:48.840]   He designed what he calls the Zeph scale, the Zoom exhaustion
[00:08:48.840 --> 00:08:50.080]   and fatigue scale.
[00:08:50.080 --> 00:08:51.080]   Right.
[00:08:51.080 --> 00:08:53.800]   And when I talk about bias confirmation,
[00:08:53.800 --> 00:08:55.880]   this is like a textbook of bias confirmation.
[00:08:55.880 --> 00:08:58.120]   How much do you hate your Zoom meetings?
[00:08:58.120 --> 00:08:58.640]   Yeah, yeah.
[00:08:58.640 --> 00:08:59.360]   Like it's all like--
[00:08:59.360 --> 00:09:00.360]   Feel out this questionnaire.
[00:09:00.360 --> 00:09:01.040]   Yeah.
[00:09:01.040 --> 00:09:02.320]   It's just insane.
[00:09:02.320 --> 00:09:05.800]   Anyway, so the problem really is
[00:09:05.800 --> 00:09:07.800]   is that some of my background is
[00:09:07.800 --> 00:09:09.760]   that we've done in the last decade,
[00:09:09.760 --> 00:09:12.120]   we've done over 2,000 events, over 1,000 of them
[00:09:12.120 --> 00:09:14.280]   for Google doing Hangouts in the early days.
[00:09:14.280 --> 00:09:15.960]   Almost all video, right?
[00:09:15.960 --> 00:09:16.600]   All video.
[00:09:16.600 --> 00:09:18.840]   No, all we've done is--
[00:09:18.840 --> 00:09:20.240]   I mean, I've done a lot of other things.
[00:09:20.240 --> 00:09:23.240]   We've streamed IO and Facebook, F8 and stuff like that.
[00:09:23.240 --> 00:09:30.280]   But the vast majority of the work that I work on
[00:09:30.280 --> 00:09:34.440]   is only using online tools, whether it's Skype or Zoom
[00:09:34.440 --> 00:09:37.400]   or Hangouts before that and all these other things,
[00:09:37.400 --> 00:09:40.440]   is using these tools to allow people to build these meetings
[00:09:40.440 --> 00:09:41.600]   that occur all over the world.
[00:09:41.600 --> 00:09:43.600]   They're global, what we call, centerless events.
[00:09:43.600 --> 00:09:44.640]   They don't have any--
[00:09:44.640 --> 00:09:45.640]   there's nobody anywhere.
[00:09:45.640 --> 00:09:47.280]   The speakers are somewhere in the world.
[00:09:47.280 --> 00:09:48.680]   I think that's part of the team.
[00:09:48.680 --> 00:09:49.680]   You are somewhere in the world.
[00:09:49.680 --> 00:09:50.840]   And is this kind of--
[00:09:50.840 --> 00:09:53.280]   decoupled from the Earth feeling?
[00:09:53.280 --> 00:09:57.280]   Well, we look at it as not being constrained by time and space.
[00:09:57.280 --> 00:09:58.120]   So--
[00:09:58.120 --> 00:09:59.960]   [LAUGHTER]
[00:09:59.960 --> 00:10:01.040]   That's another way to say it.
[00:10:01.040 --> 00:10:02.040]   Yeah.
[00:10:02.040 --> 00:10:02.840]   So--
[00:10:02.840 --> 00:10:04.120]   [INTERPOSING VOICES]
[00:10:04.120 --> 00:10:05.720]   Framing is a very powerful place for--
[00:10:05.720 --> 00:10:06.720]   I mean--
[00:10:06.720 --> 00:10:11.320]   Well, but I mean, as someone who's worked on virtual events
[00:10:11.320 --> 00:10:14.400]   and physical events for the last two decades,
[00:10:14.400 --> 00:10:16.120]   physical events are really exhausting.
[00:10:16.120 --> 00:10:17.960]   I'm starting to love these virtual events.
[00:10:17.960 --> 00:10:20.800]   Yeah, I mean, just to ask, do a questionnaire after CES?
[00:10:20.800 --> 00:10:22.000]   Well, talk about the tea.
[00:10:22.000 --> 00:10:23.800]   Yeah, exactly.
[00:10:23.800 --> 00:10:25.400]   That's exhausting.
[00:10:25.400 --> 00:10:27.200]   And the thing is that what--
[00:10:27.200 --> 00:10:29.720]   so we've prepped over 6,000 participants.
[00:10:29.720 --> 00:10:31.640]   And I mean that means that those are the people that are
[00:10:31.640 --> 00:10:33.840]   actually talking, interacting with each other.
[00:10:33.840 --> 00:10:36.280]   And so a lot of the stuff that they're talking about here
[00:10:36.280 --> 00:10:37.080]   is kind of absurd.
[00:10:37.080 --> 00:10:39.400]   And so from someone who actually does it,
[00:10:39.400 --> 00:10:41.360]   not someone who has a bunch of good ideas based on things
[00:10:41.360 --> 00:10:42.680]   that they thought.
[00:10:42.680 --> 00:10:43.680]   And so--
[00:10:43.680 --> 00:10:44.680]   [LAUGHTER]
[00:10:44.680 --> 00:10:45.200]   You saw--
[00:10:45.200 --> 00:10:45.720]   I'm sorry, doctor.
[00:10:45.720 --> 00:10:46.400]   Sorry, doctor.
[00:10:46.400 --> 00:10:47.160]   But I want some--
[00:10:47.160 --> 00:10:47.680]   I'm sorry.
[00:10:47.680 --> 00:10:48.600]   I know they have a strong--
[00:10:48.600 --> 00:10:51.120]   I know they have a pretty diploma.
[00:10:51.120 --> 00:10:54.720]   But the thing is that there's actual field work
[00:10:54.720 --> 00:10:55.600]   that's actually useful.
[00:10:55.600 --> 00:10:59.040]   And so from the field work, the biggest thing
[00:10:59.040 --> 00:11:00.320]   is solving a bunch of--
[00:11:00.320 --> 00:11:03.280]   there are etiquette issues of how you manage a room
[00:11:03.280 --> 00:11:04.480]   and so on and so forth.
[00:11:04.480 --> 00:11:08.600]   But the primary things that change the comfort of Zoom--
[00:11:08.600 --> 00:11:10.800]   the Zoom experience is your technical setup.
[00:11:10.800 --> 00:11:16.440]   So if people in the room improve their audio first,
[00:11:16.440 --> 00:11:17.960]   they just don't sound bad.
[00:11:17.960 --> 00:11:19.040]   Don't sound echo-y.
[00:11:19.040 --> 00:11:20.400]   Don't sound far away.
[00:11:20.400 --> 00:11:21.840]   And that's like a $30 fix.
[00:11:21.840 --> 00:11:23.280]   There's like $30 mics.
[00:11:23.280 --> 00:11:24.720]   And you want-- it's like 80% of it.
[00:11:24.720 --> 00:11:26.640]   We'll just get fixed.
[00:11:26.640 --> 00:11:30.440]   Then internet-- like Wi-Fi is the devil for this kind of thing.
[00:11:30.440 --> 00:11:31.960]   Wi-Fi was not built for this.
[00:11:31.960 --> 00:11:34.880]   So as you know, the first thing you do when you get somebody on,
[00:11:34.880 --> 00:11:36.480]   it's like, let's get them off a Wi-Fi.
[00:11:36.480 --> 00:11:37.760]   Because you have an internet.
[00:11:37.760 --> 00:11:39.320]   When we're prepping people, we're like, hey,
[00:11:39.320 --> 00:11:40.320]   how far away is your router?
[00:11:40.320 --> 00:11:41.680]   And they're like, oh, it's 75 feet.
[00:11:41.680 --> 00:11:43.960]   And we're like, OK, we'll send you a cable.
[00:11:43.960 --> 00:11:48.320]   And so because Wi-Fi affects it, then after that,
[00:11:48.320 --> 00:11:50.560]   lighting and then video and then their environment.
[00:11:50.560 --> 00:11:52.520]   And when you start to fix those things-- and most of those
[00:11:52.520 --> 00:11:55.240]   are not particularly complex fixes.
[00:11:55.240 --> 00:11:55.760]   They can be.
[00:11:55.760 --> 00:11:57.000]   I mean, my fix is complex.
[00:11:57.000 --> 00:12:02.840]   But for the small kits that we send out, probably 50 to 60
[00:12:02.840 --> 00:12:04.040]   kits a week--
[00:12:04.040 --> 00:12:07.640]   I'm sorry, a month-- 50 to 60 kits a month.
[00:12:07.640 --> 00:12:09.040]   They're relatively small fixes.
[00:12:09.040 --> 00:12:11.080]   And what happens is suddenly people--
[00:12:11.080 --> 00:12:12.360]   they look good.
[00:12:12.360 --> 00:12:14.120]   People get tired of looking at themselves
[00:12:14.120 --> 00:12:15.920]   because it's like their worst self.
[00:12:15.920 --> 00:12:19.320]   It's down below them, looking up their nose with bad lighting.
[00:12:19.320 --> 00:12:21.200]   Of course, you don't want to look at that all day.
[00:12:21.200 --> 00:12:23.880]   But when you're well lit, I probably
[00:12:23.880 --> 00:12:25.680]   look two or three times better on Zoom
[00:12:25.680 --> 00:12:28.200]   than I do in real life.
[00:12:28.200 --> 00:12:32.200]   So when you're set up that way, you
[00:12:32.200 --> 00:12:35.560]   don't necessarily want to give that up.
[00:12:35.560 --> 00:12:36.880]   So I think that that's the issue.
[00:12:36.880 --> 00:12:37.920]   So if you're going to-- in other words,
[00:12:37.920 --> 00:12:39.720]   if you're going to couple yourself from space and time,
[00:12:39.720 --> 00:12:42.160]   you might as well look good while you're doing it.
[00:12:42.160 --> 00:12:44.520]   But again, what happens is that you get a lot more
[00:12:44.520 --> 00:12:45.360]   comfortable with it.
[00:12:45.360 --> 00:12:46.920]   You have good audio.
[00:12:46.920 --> 00:12:47.920]   You have good video.
[00:12:47.920 --> 00:12:50.920]   And you actually have better audio and video.
[00:12:50.920 --> 00:12:54.320]   The fatigue comes from the low quality of the signal.
[00:12:54.320 --> 00:12:57.040]   Well, I'm going to say that there is that.
[00:12:57.040 --> 00:13:00.280]   But I think there is an element of Zoom fatigue
[00:13:00.280 --> 00:13:03.000]   that the article has really kind of missed in its--
[00:13:03.000 --> 00:13:05.160]   it's looking at--
[00:13:05.160 --> 00:13:06.720]   it's great to look at the quality.
[00:13:06.720 --> 00:13:08.480]   And I agree with everything Alex said.
[00:13:08.480 --> 00:13:11.040]   My life improved drastically when I got a camera that I
[00:13:11.040 --> 00:13:13.400]   would look straight into rather than a web camera that
[00:13:13.400 --> 00:13:13.880]   was--
[00:13:13.880 --> 00:13:16.200]   Which by the way is exactly what they tell you not to do.
[00:13:16.200 --> 00:13:20.360]   You don't want to have the hide eye content--
[00:13:20.360 --> 00:13:21.360]   No eye content.
[00:13:21.360 --> 00:13:21.860]   Yeah.
[00:13:21.860 --> 00:13:24.320]   And I'm like, we spent thousands of dollars
[00:13:24.320 --> 00:13:25.960]   on making sure that you can do that.
[00:13:25.960 --> 00:13:26.680]   Yeah.
[00:13:26.680 --> 00:13:27.200]   Yeah.
[00:13:27.200 --> 00:13:30.440]   So I think the problem that I've found with Zoom fatigue,
[00:13:30.440 --> 00:13:33.880]   which this article completely misses, which is again,
[00:13:33.880 --> 00:13:35.720]   to Alex's point, the danger of doing things
[00:13:35.720 --> 00:13:37.640]   theoretically rather than practically,
[00:13:37.640 --> 00:13:41.520]   is that in a world where video is kind of your only form
[00:13:41.520 --> 00:13:43.760]   of communication, then every problem
[00:13:43.760 --> 00:13:45.880]   is fixed with a video meeting.
[00:13:45.880 --> 00:13:51.120]   And the problem is that we have become completely
[00:13:51.120 --> 00:13:55.040]   subservant to this idea that every single interaction we
[00:13:55.040 --> 00:13:57.520]   need to have ends up being a Zoom meeting.
[00:13:57.520 --> 00:13:58.360]   And if you went--
[00:13:58.360 --> 00:14:01.200]   I know from working in an office,
[00:14:01.200 --> 00:14:03.280]   when you get to talk to your coworkers,
[00:14:03.280 --> 00:14:06.000]   you have an interaction that is walking past each other
[00:14:06.000 --> 00:14:07.080]   in the corridor.
[00:14:07.080 --> 00:14:09.600]   And you have an interaction that's over hearing somebody
[00:14:09.600 --> 00:14:11.040]   and then yelling at them across the room
[00:14:11.040 --> 00:14:12.200]   and asking what's going on inside.
[00:14:12.200 --> 00:14:13.760]   There's variety.
[00:14:13.760 --> 00:14:14.280]   Yeah.
[00:14:14.280 --> 00:14:15.680]   There's this huge variety.
[00:14:15.680 --> 00:14:18.840]   But when all you've got is a Zoom call,
[00:14:18.840 --> 00:14:22.080]   then suddenly everything that you do becomes a Zoom call.
[00:14:22.080 --> 00:14:24.920]   And so you completely lack any variety.
[00:14:24.920 --> 00:14:28.480]   And so I will find that in an average day in the office,
[00:14:28.480 --> 00:14:30.880]   I might have a chat with someone sat next to me,
[00:14:30.880 --> 00:14:32.600]   a yell with someone across the room,
[00:14:32.600 --> 00:14:35.680]   stand and work something out over by the coffee machine
[00:14:35.680 --> 00:14:37.000]   and lunch with somebody.
[00:14:37.000 --> 00:14:40.760]   Whereas when I'm sat in pandemic times with Zoom fatigue,
[00:14:40.760 --> 00:14:43.720]   it's like, I've got a 30-minute meeting with this person on Zoom,
[00:14:43.720 --> 00:14:46.040]   followed by a 20-minute meeting with this person on Zoom,
[00:14:46.040 --> 00:14:48.680]   followed by a one-hour meeting with this person on Zoom.
[00:14:48.680 --> 00:14:49.920]   And it's like every--
[00:14:49.920 --> 00:14:52.080]   when all you've got is a hammer, everything
[00:14:52.080 --> 00:14:53.600]   looks like a nail.
[00:14:53.600 --> 00:14:56.000]   And I think that, for me, is definitely
[00:14:56.000 --> 00:14:59.640]   being the real kind of Zoom fatigue issue.
[00:14:59.640 --> 00:15:03.160]   I think we'll bring up a good point, however inadvertently,
[00:15:03.160 --> 00:15:05.240]   because when you start talking about Zoom,
[00:15:05.240 --> 00:15:09.200]   there's a cognitive load that goes along with having
[00:15:09.200 --> 00:15:11.000]   to schedule all of your interactions
[00:15:11.000 --> 00:15:12.440]   or having to set up the Zoom meeting
[00:15:12.440 --> 00:15:15.080]   and then go through the Kabuki ritual of,
[00:15:15.080 --> 00:15:17.360]   is your camera on or are you not on?
[00:15:17.360 --> 00:15:19.880]   Whereas when you have spontaneous interactions
[00:15:19.880 --> 00:15:21.240]   with a coworker in an office, you
[00:15:21.240 --> 00:15:22.920]   don't have to do that amount of work
[00:15:22.920 --> 00:15:24.960]   just to have a conversation with them.
[00:15:24.960 --> 00:15:27.200]   Of course, for me, yeah.
[00:15:27.200 --> 00:15:28.000]   For me, too.
[00:15:28.000 --> 00:15:29.200]   And that's part--
[00:15:29.200 --> 00:15:29.700]   Go ahead.
[00:15:29.700 --> 00:15:30.200]   Go ahead.
[00:15:30.200 --> 00:15:32.240]   That's part of it, too, is when you're in an office,
[00:15:32.240 --> 00:15:34.320]   like you said, there's a lot more shouting across
[00:15:34.320 --> 00:15:35.800]   when somebody's working or not working.
[00:15:35.800 --> 00:15:37.680]   It's a little bit more interstitial.
[00:15:37.680 --> 00:15:41.840]   You don't have the work associated with having--
[00:15:41.840 --> 00:15:43.520]   you don't have the work associated with.
[00:15:43.520 --> 00:15:45.400]   We've now gotten to point to having a conversation.
[00:15:45.400 --> 00:15:48.680]   And then there's more work paid to that conversation, too.
[00:15:48.680 --> 00:15:53.640]   Microsoft Research released some preliminary findings
[00:15:53.640 --> 00:15:56.000]   last summer-- this is in their research lab--
[00:15:56.000 --> 00:15:58.800]   where they found out that people's attention span
[00:15:58.800 --> 00:16:03.200]   in Microsoft Teams meetings tended to flag at about the 35-minute
[00:16:03.200 --> 00:16:03.960]   mark.
[00:16:03.960 --> 00:16:07.840]   And they had done brain scans and other things
[00:16:07.840 --> 00:16:09.040]   to figure out why this is the case.
[00:16:09.040 --> 00:16:10.720]   And they said, it's cognitive overload,
[00:16:10.720 --> 00:16:13.360]   because even when you have people on grids,
[00:16:13.360 --> 00:16:16.480]   you're still habituated to looking for signals
[00:16:16.480 --> 00:16:19.120]   like eye contact or who's talking.
[00:16:19.120 --> 00:16:22.400]   And the research has been foundational to some of the ways
[00:16:22.400 --> 00:16:24.560]   they've rushed up the team's experience since.
[00:16:24.560 --> 00:16:28.000]   But I've thought a whole lot about how, over the past six
[00:16:28.000 --> 00:16:29.920]   months, Microsoft's been paying a lot of attention
[00:16:29.920 --> 00:16:33.200]   to the cognitive load that goes along with video meetings.
[00:16:33.200 --> 00:16:36.880]   And what are the tech steps to change that versus some
[00:16:36.880 --> 00:16:39.080]   of the things I found when I interviewed people who are like,
[00:16:39.080 --> 00:16:41.240]   the answer is to make your meeting shorter
[00:16:41.240 --> 00:16:43.880]   and then to get up and move around and do things
[00:16:43.880 --> 00:16:46.160]   between those meetings so that you don't feel as if you're
[00:16:46.160 --> 00:16:49.120]   just a pair of eyes staring at a screen for 10 hours a day
[00:16:49.120 --> 00:16:49.880]   every day.
[00:16:49.880 --> 00:16:54.760]   Speaking of somebody who's been doing this for 15 years--
[00:16:54.760 --> 00:16:56.400]   you get used to it.
[00:16:56.400 --> 00:16:57.400]   I--
[00:16:57.400 --> 00:16:58.560]   the other thing is--
[00:16:58.560 --> 00:17:24.820]   like team cross-
[00:17:24.820 --> 00:17:28.480]   so for instance, there's a bunch of eye tracking
[00:17:28.480 --> 00:17:29.320]   research in this one.
[00:17:29.320 --> 00:17:29.680]   Did you?
[00:17:29.680 --> 00:17:30.200]   Wow.
[00:17:30.200 --> 00:17:30.680]   Or--
[00:17:30.680 --> 00:17:31.180]   Yeah.
[00:17:31.180 --> 00:17:32.440]   This is a decade ago.
[00:17:32.440 --> 00:17:34.480]   So we were looking at training.
[00:17:34.480 --> 00:17:36.400]   And when people start paying attention--
[00:17:36.400 --> 00:17:39.480]   and these are in these very early webex and so on and so forth.
[00:17:39.480 --> 00:17:42.680]   And one of the things that we found
[00:17:42.680 --> 00:17:45.840]   is that if you talk straight for six and a half minutes
[00:17:45.840 --> 00:17:47.280]   about six and a half minutes, people
[00:17:47.280 --> 00:17:48.160]   stop paying attention.
[00:17:48.160 --> 00:17:49.160]   Yeah, that's about right.
[00:17:49.160 --> 00:17:49.660]   Yeah.
[00:17:49.660 --> 00:17:50.240]   They don't leave.
[00:17:50.240 --> 00:17:51.360]   They just start looking around.
[00:17:51.360 --> 00:17:52.720]   Yeah, they zoned out.
[00:17:52.720 --> 00:17:53.720]   You start sounding like--
[00:17:53.720 --> 00:17:54.220]   That's really--
[00:17:54.220 --> 00:17:55.720]   the teacher in a peanut butter.
[00:17:55.720 --> 00:17:56.720]   It gets better.
[00:17:56.720 --> 00:18:00.000]   [MUSIC PLAYING]
[00:18:00.000 --> 00:18:02.960]   If you put up a slide, it's 60 to 90 seconds.
[00:18:02.960 --> 00:18:04.600]   Yikes, they stop paying attention.
[00:18:04.600 --> 00:18:08.280]   And so we learned very quickly to get rid of the slides
[00:18:08.280 --> 00:18:11.240]   because they were just destroying people's view time.
[00:18:11.240 --> 00:18:14.720]   And you were getting put into passive mode almost immediately.
[00:18:14.720 --> 00:18:16.920]   The thing is that one of the things--
[00:18:16.920 --> 00:18:19.000]   it's a matter of how people are engaged.
[00:18:19.000 --> 00:18:21.160]   So one of the things that we--
[00:18:21.160 --> 00:18:25.120]   we have a meeting every morning, seven days a week,
[00:18:25.120 --> 00:18:27.960]   that lasts anywhere from two to five hours.
[00:18:27.960 --> 00:18:30.440]   Is this office hours or is this another meeting?
[00:18:30.440 --> 00:18:31.480]   No, it's office hours.
[00:18:31.480 --> 00:18:32.600]   So office hours.
[00:18:32.600 --> 00:18:36.440]   There's two to 300 people that show up for at least two hours.
[00:18:36.440 --> 00:18:39.360]   I mean, our average view time is 82 minutes.
[00:18:39.360 --> 00:18:42.880]   The energy at the end of the meeting
[00:18:42.880 --> 00:18:45.240]   is generally as high or higher than the beginning
[00:18:45.240 --> 00:18:48.440]   of the meeting after two hours, the official meeting.
[00:18:48.440 --> 00:18:49.760]   And then there's two hours before that.
[00:18:49.760 --> 00:18:50.840]   That's the unofficial meeting.
[00:18:50.840 --> 00:18:53.040]   And one hour after that, that's another official meeting
[00:18:53.040 --> 00:18:55.000]   where people keep talking.
[00:18:55.000 --> 00:18:59.360]   And so when I hear the whole 35-minute thing, it's cute.
[00:18:59.360 --> 00:19:02.560]   But it's like we do this for a long period of time.
[00:19:02.560 --> 00:19:04.280]   And we do it every single day.
[00:19:04.280 --> 00:19:06.080]   And people are engaged.
[00:19:06.080 --> 00:19:07.200]   You're experienced--
[00:19:07.200 --> 00:19:09.400]   After that, we did eight hours straight.
[00:19:09.400 --> 00:19:10.600]   You're just nuts.
[00:19:10.600 --> 00:19:12.600]   But you're just nuts.
[00:19:12.600 --> 00:19:14.160]   But your experience is a little different, too,
[00:19:14.160 --> 00:19:17.280]   because from your point of view, you're doing a show.
[00:19:17.280 --> 00:19:18.840]   You feel like you're doing a show.
[00:19:18.840 --> 00:19:20.400]   Like you're hosting--
[00:19:20.400 --> 00:19:23.120]   Like I'm doing a show right now.
[00:19:23.120 --> 00:19:25.360]   But it's a different experience.
[00:19:25.360 --> 00:19:27.040]   But that's a completely different experience
[00:19:27.040 --> 00:19:31.320]   sitting in a Zoom meeting, which is absolutely draining.
[00:19:31.320 --> 00:19:35.960]   Well, it's how you structure that Zoom meeting.
[00:19:35.960 --> 00:19:39.400]   So one of the things we do is we do almost no--
[00:19:39.400 --> 00:19:40.520]   there's almost no lecturing.
[00:19:40.520 --> 00:19:41.520]   There's no long talking.
[00:19:41.520 --> 00:19:42.800]   There's no presentations.
[00:19:42.800 --> 00:19:44.200]   We deliver that ahead of time.
[00:19:44.200 --> 00:19:51.800]   Like you get that ahead of time, and then you discuss it.
[00:19:51.800 --> 00:19:53.680]   So everything's about discussion.
[00:19:53.680 --> 00:19:58.960]   And that's what you're doing is significantly different, though.
[00:19:58.960 --> 00:20:02.560]   Then the Zoom calls that most people have, the work calls
[00:20:02.560 --> 00:20:03.040]   they have--
[00:20:03.040 --> 00:20:07.520]   Let me tell you the absolute worst Zoom experience Leo
[00:20:07.520 --> 00:20:10.600]   is having done this, as I think probably possibly
[00:20:10.600 --> 00:20:14.560]   the only person who might experience this, is Zoom dating.
[00:20:14.560 --> 00:20:16.000]   Oh, don't do Zoom dating.
[00:20:16.000 --> 00:20:18.800]   Really, you've done Zoom dating?
[00:20:18.800 --> 00:20:21.880]   I tell you what, never has that 40-minute limit
[00:20:21.880 --> 00:20:25.920]   on free Zoom connections been more useful than the--
[00:20:25.920 --> 00:20:26.960]   Oh, no, sorry.
[00:20:26.960 --> 00:20:28.520]   It's like our call is about to end.
[00:20:28.520 --> 00:20:29.520]   Oh, my God.
[00:20:29.520 --> 00:20:30.720]   You're telling me--
[00:20:30.720 --> 00:20:31.360]   Wait a minute.
[00:20:31.360 --> 00:20:32.280]   Explain this to me.
[00:20:32.280 --> 00:20:33.680]   That sounds great, actually.
[00:20:33.680 --> 00:20:34.200]   Yeah.
[00:20:34.200 --> 00:20:35.960]   Because you have a built-in exit.
[00:20:35.960 --> 00:20:40.840]   It's like those speed dating or a coffee date, which is really
[00:20:40.840 --> 00:20:44.040]   designed to kind of let's see if this is going to even be close.
[00:20:44.040 --> 00:20:45.800]   But so tell me how this works.
[00:20:45.800 --> 00:20:48.760]   How do you meet the person you're going to Zoom date?
[00:20:48.760 --> 00:20:51.000]   So you use this sort of traditional--
[00:20:51.000 --> 00:20:54.000]   Oh, my God, I can't believe this is my life.
[00:20:54.000 --> 00:20:57.120]   You can use one of the more traditional dating apps,
[00:20:57.120 --> 00:20:59.720]   where you're liking people and looking at their interests.
[00:20:59.720 --> 00:21:00.720]   OK.
[00:21:00.720 --> 00:21:02.040]   And you have a little bit of a chat.
[00:21:02.040 --> 00:21:03.400]   So then you say meet up on Zoom.
[00:21:03.400 --> 00:21:04.520]   And then there's usually a--
[00:21:04.520 --> 00:21:07.360]   Yeah, and then it's like, do you want to have a Zoom drink
[00:21:07.360 --> 00:21:08.400]   or a Zoom coffee?
[00:21:08.400 --> 00:21:10.360]   Is this pretty common?
[00:21:10.360 --> 00:21:10.840]   Yes.
[00:21:10.840 --> 00:21:13.280]   This is how people do it now.
[00:21:13.280 --> 00:21:16.800]   It is, unfortunately, the way we have been reduced.
[00:21:16.800 --> 00:21:19.600]   I feel like Jane Goodall watching the Apes.
[00:21:19.600 --> 00:21:21.600]   I'm trying to understand your culture.
[00:21:21.600 --> 00:21:23.600]   [LAUGHTER]
[00:21:23.600 --> 00:21:25.240]   I mean, it is.
[00:21:25.240 --> 00:21:27.440]   As single people during the pandemic,
[00:21:27.440 --> 00:21:30.920]   you're, A, looking for anybody to talk to you that isn't a co-worker
[00:21:30.920 --> 00:21:33.520]   or a member of your family.
[00:21:33.520 --> 00:21:37.560]   But it definitely gets weird when your--
[00:21:37.560 --> 00:21:41.080]   the Zoom fatigue gets really weird when you are trying to--
[00:21:41.080 --> 00:21:44.440]   the whole thing about the date is make eye contact.
[00:21:44.440 --> 00:21:46.240]   Look at the other person.
[00:21:46.240 --> 00:21:47.960]   But then you look like an absolute creeper
[00:21:47.960 --> 00:21:50.080]   void if you're just doing that the whole time on Zoom.
[00:21:50.080 --> 00:21:53.600]   It takes all the worst elements of a first date.
[00:21:53.600 --> 00:21:57.200]   And just amplifies all the worst bits and takes away--
[00:21:57.200 --> 00:21:58.320]   Boils it down.
[00:21:58.320 --> 00:22:02.000]   There's no-- what's the word?
[00:22:02.000 --> 00:22:03.720]   There's no body language.
[00:22:03.720 --> 00:22:08.240]   You can't get a sense of anybody's kind of like zen.
[00:22:08.240 --> 00:22:10.160]   It's all the worst bits combined together.
[00:22:10.160 --> 00:22:12.440]   So that is the absolute Zoom worse.
[00:22:12.440 --> 00:22:15.800]   So Alex, until you've fixed that for me, I'm afraid--
[00:22:15.800 --> 00:22:17.000]   I'm still going to be--
[00:22:17.000 --> 00:22:19.800]   I haven't had to date for a long time.
[00:22:19.800 --> 00:22:20.800]   So I don't know.
[00:22:20.800 --> 00:22:23.080]   As Alex and I are just watching--
[00:22:23.080 --> 00:22:26.440]   Can you set up some sort of super Zoom
[00:22:26.440 --> 00:22:29.680]   room for really high-quality dating connections?
[00:22:29.680 --> 00:22:30.880]   Well, I mean, I think that--
[00:22:30.880 --> 00:22:33.320]   First thing is, it times out in 10 minutes.
[00:22:33.320 --> 00:22:35.000]   That's the first thing we do.
[00:22:35.000 --> 00:22:38.120]   I mean, on the other side of it, one of the things
[00:22:38.120 --> 00:22:39.920]   that makes our art discussion so interesting, though,
[00:22:39.920 --> 00:22:42.760]   is that we have basically-- we represent five or six
[00:22:42.760 --> 00:22:44.600]   continents every day.
[00:22:44.600 --> 00:22:51.160]   It is 25 people basically talking with--
[00:22:51.160 --> 00:22:54.080]   or in front of 200 to 300 people.
[00:22:54.080 --> 00:22:57.840]   And it's a meeting that could not happen in the physical world.
[00:22:57.840 --> 00:22:59.600]   It's impossible to have it.
[00:22:59.600 --> 00:23:01.320]   And that's what's coming.
[00:23:01.320 --> 00:23:03.560]   It's not that physical is going to go away.
[00:23:03.560 --> 00:23:05.880]   It's just that telling people to do things
[00:23:05.880 --> 00:23:07.520]   like turn off your camera.
[00:23:07.520 --> 00:23:09.800]   Look, we can decide whether that's good or bad.
[00:23:09.800 --> 00:23:12.000]   But it's kind of-- when you turn off your camera
[00:23:12.000 --> 00:23:14.320]   in the middle of a meeting, it's kind
[00:23:14.320 --> 00:23:16.280]   of a slap in the face for everybody else.
[00:23:16.280 --> 00:23:20.160]   And whether you mean it that way or not,
[00:23:20.160 --> 00:23:22.000]   that's how it occurs.
[00:23:22.000 --> 00:23:25.200]   And so the thing is, is that telling people to do things
[00:23:25.200 --> 00:23:27.120]   that, of course, is better for their personal space
[00:23:27.120 --> 00:23:28.200]   and all that other stuff.
[00:23:28.200 --> 00:23:30.440]   But you do have to pay attention to how you--
[00:23:30.440 --> 00:23:31.840]   There's a culture.
[00:23:31.840 --> 00:23:35.280]   There's a culture that you're telling people to go against
[00:23:35.280 --> 00:23:36.560]   that isn't going to change.
[00:23:36.560 --> 00:23:39.600]   That culture is not going to adjust itself.
[00:23:39.600 --> 00:23:41.000]   It's not going to just be OK.
[00:23:41.000 --> 00:23:42.360]   It is, especially--
[00:23:42.360 --> 00:23:45.320]   I was going to ask if this is a generational thing.
[00:23:45.320 --> 00:23:48.840]   Because I've noticed, just from a lot of firsthand observation,
[00:23:48.840 --> 00:23:53.320]   that the young people, children and teenagers,
[00:23:53.320 --> 00:23:55.000]   have a very different relationship
[00:23:55.000 --> 00:23:58.760]   to Zoom and physical representation in avatars.
[00:23:58.760 --> 00:24:02.880]   And I would argue that schoolwork is the same as going
[00:24:02.880 --> 00:24:03.760]   to an office for us.
[00:24:03.760 --> 00:24:05.400]   It's someplace where they're expected to be
[00:24:05.400 --> 00:24:07.040]   and to turn in a high level of performance every day.
[00:24:07.040 --> 00:24:09.840]   But these social expectations and the conventions
[00:24:09.840 --> 00:24:11.640]   seem to be very different.
[00:24:11.640 --> 00:24:14.400]   And it's been really interesting seeing how few of them
[00:24:14.400 --> 00:24:18.160]   will pop on camera unless they're absolutely required to.
[00:24:18.160 --> 00:24:20.080]   What grade is your daughter in?
[00:24:20.080 --> 00:24:25.200]   She's in fourth, and my nephews are 10th and 12th.
[00:24:25.200 --> 00:24:30.960]   It's got to be really hard for a grade schooler to do Zoom.
[00:24:30.960 --> 00:24:31.480]   Oh, Lord.
[00:24:31.480 --> 00:24:32.800]   Zoom fatigue is real in this house.
[00:24:32.800 --> 00:24:34.960]   But I have to say, my 18-year-old who's a high school
[00:24:34.960 --> 00:24:37.080]   senior is--
[00:24:37.080 --> 00:24:38.920]   Petaloma has announced that they're
[00:24:38.920 --> 00:24:40.640]   going to be able to go back into the classroom
[00:24:40.640 --> 00:24:43.080]   in a limited fashion next month that doesn't want to do it.
[00:24:43.080 --> 00:24:43.920]   He said, what's the point?
[00:24:43.920 --> 00:24:45.320]   I'm graduating in May.
[00:24:45.320 --> 00:24:47.680]   What do I need to go to class in April 4?
[00:24:47.680 --> 00:24:49.120]   So he's completely comfortable.
[00:24:49.120 --> 00:24:51.360]   I mean, this is for some reason.
[00:24:51.360 --> 00:24:52.640]   He doesn't--
[00:24:52.640 --> 00:24:53.140]   Yeah.
[00:24:53.140 --> 00:24:54.600]   I think different--
[00:24:54.600 --> 00:24:56.600]   I'm just wondering what the relationship might be like
[00:24:56.600 --> 00:25:00.160]   for those of us who came of age in an in-person professional
[00:25:00.160 --> 00:25:03.000]   environment versus people who have already shifted
[00:25:03.000 --> 00:25:07.040]   the bulk of their socializing to a computer mediated environment
[00:25:07.040 --> 00:25:10.480]   if maybe that will affect their biases towards
[00:25:10.480 --> 00:25:11.320]   or against camera control.
[00:25:11.320 --> 00:25:15.120]   I think the thing, Alex, is that there are those of us--
[00:25:15.120 --> 00:25:16.760]   and I shouldn't include myself-- but there are people
[00:25:16.760 --> 00:25:19.040]   who are doing this because they have to because of COVID.
[00:25:19.040 --> 00:25:20.600]   And they can't wait till it's over--
[00:25:20.600 --> 00:25:24.000]   school kids, people who are working from home.
[00:25:24.000 --> 00:25:25.640]   And then there's people like you and me, Alex,
[00:25:25.640 --> 00:25:27.760]   who do this for a living.
[00:25:27.760 --> 00:25:28.440]   Well--
[00:25:28.440 --> 00:25:31.000]   And for us, this is just broadcasting.
[00:25:31.000 --> 00:25:32.760]   This is our way of life.
[00:25:32.760 --> 00:25:34.440]   And so it's a very different experience.
[00:25:34.440 --> 00:25:37.160]   I think there are a lot of people who say, well, of course,
[00:25:37.160 --> 00:25:40.440]   now I have to say I'm looking at Dr. Bailenson's survey.
[00:25:40.440 --> 00:25:43.840]   And the questions are things like, how much do you dread
[00:25:43.840 --> 00:25:46.880]   having to do things after video conferencing?
[00:25:46.880 --> 00:25:49.280]   How often do you feel like doing nothing?
[00:25:49.280 --> 00:25:49.720]   Confirmation bias.
[00:25:49.720 --> 00:25:52.200]   Yeah, talk about how much do you need time by yourself
[00:25:52.200 --> 00:25:54.480]   after video conferencing?
[00:25:54.480 --> 00:25:57.120]   It's a little-- I mean, it's a little--
[00:25:57.120 --> 00:25:59.520]   again, a textbook of confirmation bias
[00:25:59.520 --> 00:26:00.800]   to go down that path.
[00:26:00.800 --> 00:26:03.320]   But I do think that people who don't do this for a living
[00:26:03.320 --> 00:26:04.960]   who are-- I mean, we have other reasons
[00:26:04.960 --> 00:26:07.640]   that make this palatable for us.
[00:26:07.640 --> 00:26:12.920]   But I think for kids and for people who have to go to meetings
[00:26:12.920 --> 00:26:15.400]   and just don't want to, or they want to be in the office,
[00:26:15.400 --> 00:26:20.800]   this is-- Zoom is inextricably allied with the pandemic.
[00:26:20.800 --> 00:26:22.040]   Well, but I think that also--
[00:26:22.040 --> 00:26:23.760]   I think that there is--
[00:26:23.760 --> 00:26:25.920]   it's kind of like everybody got pushed out into the ski slopes
[00:26:25.920 --> 00:26:27.480]   and there's a bunch of people that aren't going to get a ski.
[00:26:27.480 --> 00:26:28.720]   And they're like, well, this stinks.
[00:26:28.720 --> 00:26:29.280]   This is horrible.
[00:26:29.280 --> 00:26:30.280]   It's cold at a point.
[00:26:30.280 --> 00:26:33.640]   And I'm kind of like, you know, if you get some lessons
[00:26:33.640 --> 00:26:36.640]   and you wear some good clothes, it's actually pretty fun.
[00:26:36.640 --> 00:26:37.960]   You know, skiing is not that bad.
[00:26:37.960 --> 00:26:39.680]   And they're like, wow, what I'm cold and I'm wet.
[00:26:39.680 --> 00:26:40.840]   And I keep on falling down.
[00:26:40.840 --> 00:26:41.680]   And I've got a headache.
[00:26:41.680 --> 00:26:42.760]   And I'm tired.
[00:26:42.760 --> 00:26:44.000]   And of course it is.
[00:26:44.000 --> 00:26:45.040]   When you don't have the good tools
[00:26:45.040 --> 00:26:46.920]   and you don't understand how to use it, everything's hard.
[00:26:46.920 --> 00:26:48.960]   And nothing's fun.
[00:26:48.960 --> 00:26:50.680]   And I think that we're very good at it
[00:26:50.680 --> 00:26:52.040]   because we've done it for a long time.
[00:26:52.040 --> 00:26:55.680]   And my job is-- but what we see every day when we send kits out
[00:26:55.680 --> 00:26:56.960]   is people go, oh, I've already done this.
[00:26:56.960 --> 00:26:58.280]   I know how to do this.
[00:26:58.280 --> 00:27:00.280]   They turn the lights on that we send them.
[00:27:00.280 --> 00:27:01.360]   And they take the mic.
[00:27:01.360 --> 00:27:03.560]   And they have a good camera.
[00:27:03.560 --> 00:27:05.280]   And they're like, oh, wow.
[00:27:05.280 --> 00:27:06.880]   That's looking pretty good.
[00:27:06.880 --> 00:27:08.400]   They're happy.
[00:27:08.400 --> 00:27:11.880]   And then there's a, hey, do I get to keep this kit?
[00:27:11.880 --> 00:27:13.600]   And then there's calls.
[00:27:13.600 --> 00:27:15.840]   Like we had a friend of mine had a--
[00:27:15.840 --> 00:27:16.400]   they do the same.
[00:27:16.400 --> 00:27:17.360]   They do events.
[00:27:17.360 --> 00:27:21.480]   And they come in on A7Ss, like these really nice cameras.
[00:27:21.480 --> 00:27:21.880]   And--
[00:27:21.880 --> 00:27:23.080]   And Sony DSLR's.
[00:27:23.080 --> 00:27:26.200]   And they look like a-- like they make me look very bad.
[00:27:26.200 --> 00:27:27.200]   Yeah.
[00:27:27.200 --> 00:27:29.880]   They just look like they look like--
[00:27:29.880 --> 00:27:31.160]   Actually, I stopped doing that.
[00:27:31.160 --> 00:27:34.200]   So I have a very good camera that I can send video.
[00:27:34.200 --> 00:27:35.800]   And it looks too good.
[00:27:35.800 --> 00:27:37.440]   It's moody.
[00:27:37.440 --> 00:27:38.520]   It's dark.
[00:27:38.520 --> 00:27:39.920]   It looks like a movie.
[00:27:39.920 --> 00:27:41.120]   And so I stopped using it.
[00:27:41.120 --> 00:27:43.360]   I went back to the camera on the computer.
[00:27:43.360 --> 00:27:46.360]   Because there is a weird disconnect.
[00:27:46.360 --> 00:27:48.640]   It's like you don't fit in with the Zoom meeting.
[00:27:48.640 --> 00:27:50.040]   You're like--
[00:27:50.040 --> 00:27:50.800]   But it's like--
[00:27:50.800 --> 00:27:53.160]   It's like wearing a three-piece suit to a--
[00:27:53.160 --> 00:27:55.360]   Well, it is, but it's also--
[00:27:55.360 --> 00:27:56.400]   It's also like--
[00:27:56.400 --> 00:27:57.720]   Look at that.
[00:27:57.720 --> 00:28:00.200]   As a guy, it's like being a six-foot-two model.
[00:28:00.200 --> 00:28:01.200]   That's right.
[00:28:01.200 --> 00:28:02.520]   You just walk in there--
[00:28:02.520 --> 00:28:04.680]   Everyone would naturally better looking.
[00:28:04.680 --> 00:28:05.840]   Some of them get to be born with that,
[00:28:05.840 --> 00:28:08.600]   but we do it with cameras and lights and Zoom.
[00:28:08.600 --> 00:28:10.120]   And so the thing is that--
[00:28:10.120 --> 00:28:11.640]   But anyway, they were talking to executive.
[00:28:11.640 --> 00:28:13.080]   Executive was like, I have to have that.
[00:28:13.080 --> 00:28:16.760]   And then they got-- they're getting them for all their C-suite.
[00:28:16.760 --> 00:28:17.840]   Because they're like--
[00:28:17.840 --> 00:28:19.440]   What people are learning very quickly
[00:28:19.440 --> 00:28:22.720]   is whether you like it or not, and whether it's fair or not.
[00:28:22.720 --> 00:28:24.960]   What you look like and how you sound on Zoom
[00:28:24.960 --> 00:28:27.160]   gives you perceived authority in that meeting.
[00:28:27.160 --> 00:28:28.120]   If you're the boss--
[00:28:28.120 --> 00:28:29.120]   Yeah.
[00:28:29.120 --> 00:28:29.620]   Yeah.
[00:28:29.620 --> 00:28:31.960]   And even if you're not the boss, you make them wear makeup.
[00:28:31.960 --> 00:28:35.120]   Do you have them put on makeup?
[00:28:35.120 --> 00:28:38.240]   Well, for the high-end kits that we send out,
[00:28:38.240 --> 00:28:39.640]   we send out mattifying.
[00:28:39.640 --> 00:28:40.120]   But that's--
[00:28:40.120 --> 00:28:41.360]   So there's no shine.
[00:28:41.360 --> 00:28:42.200]   Yeah, yeah.
[00:28:42.200 --> 00:28:43.640]   Yeah, we do-- so it's an anti-shine.
[00:28:43.640 --> 00:28:44.560]   Those are the big kits, though.
[00:28:44.560 --> 00:28:47.320]   Those are the kits that we send out that are like 6K cameras.
[00:28:47.320 --> 00:28:49.960]   Those are the little ones we don't do then.
[00:28:49.960 --> 00:28:51.040]   Yeah.
[00:28:51.040 --> 00:28:53.400]   Well, Zoom's earnings-- this is a related story--
[00:28:53.400 --> 00:28:55.200]   came out at the end of January.
[00:28:55.200 --> 00:28:58.000]   They're fourth fiscal quarter.
[00:28:58.000 --> 00:29:03.880]   369% growth in revenue year over year.
[00:29:03.880 --> 00:29:09.840]   369%-- gross margins went from--
[00:29:09.840 --> 00:29:10.800]   they'll down a little bit.
[00:29:10.800 --> 00:29:11.720]   But that gets--
[00:29:11.720 --> 00:29:15.440]   because they lost fewer customers
[00:29:15.440 --> 00:29:19.640]   than they expected as the pandemic starts to wind down.
[00:29:19.640 --> 00:29:25.200]   In other words, it was a very successful pandemic for Zoom.
[00:29:25.200 --> 00:29:27.720]   They were probably the single company that did the best.
[00:29:27.720 --> 00:29:30.360]   I'm curious why you guys think that Zoom--
[00:29:30.360 --> 00:29:33.440]   I mean, you write about Microsoft, Lisa.
[00:29:33.440 --> 00:29:35.960]   Why wasn't Teams the big winner?
[00:29:35.960 --> 00:29:38.520]   Why are we talking about Zoom?
[00:29:38.520 --> 00:29:40.320]   There's a few reasons for that.
[00:29:40.320 --> 00:29:44.520]   One, Teams is tied into Microsoft 365 and Office 365.
[00:29:44.520 --> 00:29:46.600]   So you had to be an existing customer.
[00:29:46.600 --> 00:29:47.520]   I know that--
[00:29:47.520 --> 00:29:50.640]   I know Microsoft did have some Zoom envy, though, right?
[00:29:50.640 --> 00:29:50.960]   I mean--
[00:29:50.960 --> 00:29:52.080]   Oh, my gosh.
[00:29:52.080 --> 00:29:55.120]   I wouldn't be surprised if they had made overtures.
[00:29:55.120 --> 00:29:57.480]   But--
[00:29:57.480 --> 00:29:58.480]   Skype?
[00:29:58.480 --> 00:29:59.840]   They could have done Skype.
[00:29:59.840 --> 00:30:01.760]   Skype could have been the Zoom--
[00:30:01.760 --> 00:30:02.760]   I mean, but--
[00:30:02.760 --> 00:30:06.400]   Zoom to Office because it had a low barrier of entry
[00:30:06.400 --> 00:30:10.200]   relative to having to get yourself set up as a Microsoft
[00:30:10.200 --> 00:30:13.160]   365 customer and then wave through the four
[00:30:13.160 --> 00:30:15.080]   trillions upon four trillions of features that
[00:30:15.080 --> 00:30:16.320]   are meant to make your life better.
[00:30:16.320 --> 00:30:17.320]   I would guess, though.
[00:30:17.320 --> 00:30:19.680]   I would be willing to bet more people had Skype accounts
[00:30:19.680 --> 00:30:23.200]   before the pandemic than Zoom accounts.
[00:30:23.200 --> 00:30:26.200]   It is super easy to get started on Zoom.
[00:30:26.200 --> 00:30:29.800]   We're not talking about a constituency
[00:30:29.800 --> 00:30:31.680]   that likes to spend a lot of time
[00:30:31.680 --> 00:30:33.640]   monkeying around with tech features
[00:30:33.640 --> 00:30:34.840]   to find the ones that like best.
[00:30:34.840 --> 00:30:37.840]   You know who really probably fumbled it is Google,
[00:30:37.840 --> 00:30:39.640]   because they had me.
[00:30:39.640 --> 00:30:40.480]   Oh, no.
[00:30:40.480 --> 00:30:44.160]   I mean, it's kind of baffling that Google did not immediately
[00:30:44.160 --> 00:30:46.680]   scale up their stuff, especially to appeal
[00:30:46.680 --> 00:30:50.000]   to the educational districts, because if you look at how
[00:30:50.000 --> 00:30:54.360]   fast Zoom managed to get itself embedded, right?
[00:30:54.360 --> 00:30:57.640]   In virtually every school system in the United States,
[00:30:57.640 --> 00:31:00.560]   and they managed to do so in a matter of weeks.
[00:31:00.560 --> 00:31:04.320]   And this is-- it was an amazing market opportunity for them.
[00:31:04.320 --> 00:31:06.240]   And the thing is, is that Google already
[00:31:06.240 --> 00:31:08.480]   had tremendous incursions in US education
[00:31:08.480 --> 00:31:12.200]   between the Chromebooks that are cheap and accessible
[00:31:12.200 --> 00:31:14.720]   and something that you can outfit an entire school
[00:31:14.720 --> 00:31:16.520]   district with, or Google Classroom, which
[00:31:16.520 --> 00:31:18.720]   is what a lot of school districts use anyway
[00:31:18.720 --> 00:31:22.520]   to do assignments and collaborate with.
[00:31:22.520 --> 00:31:24.920]   So it's a little baffling to me,
[00:31:24.920 --> 00:31:27.000]   but Zoom just happened to be in the right place
[00:31:27.000 --> 00:31:27.800]   at the right time.
[00:31:27.800 --> 00:31:29.400]   It's easy to get started.
[00:31:29.400 --> 00:31:32.120]   And what a lot of people needed last March
[00:31:32.120 --> 00:31:36.480]   was something where all they had to do was click and go.
[00:31:36.480 --> 00:31:40.320]   The irony, of course, is that the reason Google is so far
[00:31:40.320 --> 00:31:43.800]   behind is because they wanted to make it easier to get started.
[00:31:43.800 --> 00:31:45.400]   So they basically--
[00:31:45.400 --> 00:31:49.960]   so Zoom-- Hangouts was very basic in 2011, then got built up.
[00:31:49.960 --> 00:31:52.480]   And they kept on adding more features.
[00:31:52.480 --> 00:31:53.480]   They had an API.
[00:31:53.480 --> 00:31:55.880]   We built tools that actually tied into it.
[00:31:55.880 --> 00:31:58.080]   So we had tools that took over the Hangout
[00:31:58.080 --> 00:32:00.080]   and turned it into an entirely different thing,
[00:32:00.080 --> 00:32:03.960]   much like Zoom has with things like ZoomOSC.
[00:32:03.960 --> 00:32:08.360]   But then what happened was Google decided
[00:32:08.360 --> 00:32:10.560]   they made a shift after they closed G+,
[00:32:10.560 --> 00:32:13.480]   they basically just gutted Hangouts.
[00:32:13.480 --> 00:32:15.720]   They just ripped everything out of it.
[00:32:15.720 --> 00:32:17.440]   Oh, yeah, it's insanely bad.
[00:32:17.440 --> 00:32:19.840]   But that was five or six years ago.
[00:32:19.840 --> 00:32:22.840]   But they were so far ahead.
[00:32:22.840 --> 00:32:25.240]   And they spent incredible amounts of money
[00:32:25.240 --> 00:32:26.600]   going down that path.
[00:32:26.600 --> 00:32:28.920]   And all they had to do was keep going that direction.
[00:32:28.920 --> 00:32:33.640]   There was a lot of us that were doing a lot of Hangouts,
[00:32:33.640 --> 00:32:36.200]   three to five a week for different companies.
[00:32:36.200 --> 00:32:39.560]   And we were just like, this is what you need to do.
[00:32:39.560 --> 00:32:40.280]   You need to build this.
[00:32:40.280 --> 00:32:40.960]   You need to build this.
[00:32:40.960 --> 00:32:41.760]   This is how you do it.
[00:32:41.760 --> 00:32:42.960]   You can take over the world.
[00:32:42.960 --> 00:32:46.000]   And they just completely went the other direction and gutted it.
[00:32:46.000 --> 00:32:48.120]   So when it happened, the real issue is
[00:32:48.120 --> 00:32:49.880]   is that they didn't have things like the grid view.
[00:32:49.880 --> 00:32:52.000]   And they didn't have all the back end tools
[00:32:52.000 --> 00:32:53.400]   that they had had in the past.
[00:32:53.400 --> 00:32:57.120]   But the thing about Zoom is that it's really, really easy
[00:32:57.120 --> 00:32:59.920]   to get started, but it is deep.
[00:32:59.920 --> 00:33:04.360]   If you go into, when you go as an administrator of Zoom,
[00:33:04.360 --> 00:33:08.640]   when you go into the settings, you have so much control.
[00:33:08.640 --> 00:33:12.080]   And you can turn intricate control of what people can do
[00:33:12.080 --> 00:33:13.360]   and what they can and how they do it,
[00:33:13.360 --> 00:33:14.960]   and whether it's what's being recorded
[00:33:14.960 --> 00:33:17.160]   and what's not being recorded and how it's being put together.
[00:33:17.160 --> 00:33:20.960]   So what they've done really well is they have this situation
[00:33:20.960 --> 00:33:23.320]   on the surface that's like, I can just turn it on and go.
[00:33:23.320 --> 00:33:25.080]   And I can send someone a link and they can just go.
[00:33:25.080 --> 00:33:27.040]   And everything just happens really easily.
[00:33:27.040 --> 00:33:30.640]   But when you want to turn up all the quality knobs,
[00:33:30.640 --> 00:33:33.560]   turn up all the other bits and pieces, you can.
[00:33:33.560 --> 00:33:35.280]   And that's what you can't do in Teams.
[00:33:35.280 --> 00:33:39.520]   You can't do it in Hangouts or Meet.
[00:33:39.520 --> 00:33:41.360]   You can't-- and those are the only ones that really matter, right?
[00:33:41.360 --> 00:33:43.640]   The rest of them are just-- they miss the boat.
[00:33:43.640 --> 00:33:47.560]   I mean, like go to meeting in WebEx and chime.
[00:33:47.560 --> 00:33:48.680]   Sorry, sorry.
[00:33:48.680 --> 00:33:50.480]   Oh my god, you know, these guys--
[00:33:50.480 --> 00:33:53.840]   I mean, WebEx owned the corporate building marketplace
[00:33:53.840 --> 00:33:54.640]   even more than Zoom.
[00:33:54.640 --> 00:33:56.600]   Well, how come they didn't?
[00:33:56.600 --> 00:33:59.320]   You know, it's always hard for an incumbent to keep up.
[00:33:59.320 --> 00:34:01.240]   They're not thinking-- they have a way of thinking.
[00:34:01.240 --> 00:34:02.640]   And they just do it perfectly.
[00:34:02.640 --> 00:34:05.840]   They just play this opportunity perfectly.
[00:34:05.840 --> 00:34:06.200]   No, in fact--
[00:34:06.200 --> 00:34:07.800]   No, and it's far from perfect.
[00:34:07.800 --> 00:34:08.300]   Yeah.
[00:34:08.300 --> 00:34:09.120]   And it's not a--
[00:34:09.120 --> 00:34:10.400]   You know, there were lots of things about it
[00:34:10.400 --> 00:34:12.160]   that are great at-- that are a poor experience.
[00:34:12.160 --> 00:34:16.640]   But the one thing that you can do is one click, join a meeting
[00:34:16.640 --> 00:34:19.040]   from somebody saying you were linked in a chat.
[00:34:19.040 --> 00:34:19.480]   Yeah.
[00:34:19.480 --> 00:34:22.040]   And that is like the most basic thing in the world
[00:34:22.040 --> 00:34:23.640]   that you could want to do.
[00:34:23.640 --> 00:34:24.160]   And--
[00:34:24.160 --> 00:34:26.600]   As it turns out, that's something everybody wanted to do.
[00:34:26.600 --> 00:34:28.640]   As it turns out, that's something that everybody need.
[00:34:28.640 --> 00:34:28.840]   Well--
[00:34:28.840 --> 00:34:29.600]   And there were lots--
[00:34:29.600 --> 00:34:33.440]   And like lots of companies for whom tech is a completely
[00:34:33.440 --> 00:34:35.400]   secondary function, who--
[00:34:35.400 --> 00:34:37.640]   if it's a function at all that suddenly needed
[00:34:37.640 --> 00:34:39.640]   to get good at video conferencing.
[00:34:39.640 --> 00:34:42.800]   And this was like literally the simplest way to--
[00:34:42.800 --> 00:34:45.320]   with one click, somebody who knows something
[00:34:45.320 --> 00:34:46.560]   can set up a meeting.
[00:34:46.560 --> 00:34:48.560]   And everybody else can join it in a click.
[00:34:48.560 --> 00:34:49.160]   And that's it.
[00:34:49.160 --> 00:34:53.800]   Well, our 40 minutes is up and this call is going to end now.
[00:34:53.800 --> 00:34:56.080]   [LAUGHTER]
[00:34:56.080 --> 00:34:57.600]   Leo, are you going to ghost me now?
[00:34:57.600 --> 00:34:59.040]   What, we know for you further?
[00:34:59.040 --> 00:35:00.040]   Send me your number.
[00:35:00.040 --> 00:35:01.720]   All the-- what are you--
[00:35:01.720 --> 00:35:04.200]   So I'm still, by the way, I'm still intrigued
[00:35:04.200 --> 00:35:06.120]   by this whole dating thing.
[00:35:06.120 --> 00:35:09.160]   Is this just you or is this something horrible?
[00:35:09.160 --> 00:35:10.680]   All your peers are doing this.
[00:35:10.680 --> 00:35:11.320]   Is this like how--
[00:35:11.320 --> 00:35:13.320]   Well, me, if it was just me, it wouldn't be much dating,
[00:35:13.320 --> 00:35:14.400]   would it?
[00:35:14.400 --> 00:35:14.880]   That's true.
[00:35:14.880 --> 00:35:16.800]   It takes you to Zoom date.
[00:35:16.800 --> 00:35:18.320]   Takes you to-- takes you to Zoom.
[00:35:18.320 --> 00:35:20.320]   Zoom out.
[00:35:20.320 --> 00:35:21.520]   Dating in the mist.
[00:35:21.520 --> 00:35:26.680]   What?
[00:35:26.680 --> 00:35:27.920]   OK.
[00:35:27.920 --> 00:35:31.520]   And so has any-- have any of your Zoom dates gone--
[00:35:31.520 --> 00:35:35.880]   I mean, what's the next step, a longer call?
[00:35:35.880 --> 00:35:37.560]   Generally, the next step in London
[00:35:37.560 --> 00:35:38.840]   is a walk in a park.
[00:35:38.840 --> 00:35:40.200]   A walk in the park.
[00:35:40.200 --> 00:35:41.120]   Is that a euphemism?
[00:35:41.120 --> 00:35:43.360]   Which is very, very Jane Austen-esque.
[00:35:43.360 --> 00:35:43.880]   It is.
[00:35:43.880 --> 00:35:46.080]   You sort of walk sort of two meters apart.
[00:35:46.080 --> 00:35:48.280]   Do you have a chaperone walking behind you?
[00:35:48.280 --> 00:35:49.560]   Do you ever have your hands like this?
[00:35:49.560 --> 00:35:53.480]   You have no sort of physical interaction.
[00:35:53.480 --> 00:35:55.440]   I feel sorry for anybody who's single during this.
[00:35:55.440 --> 00:35:56.640]   This is a nightmare.
[00:35:56.640 --> 00:35:58.520]   [LAUGHTER]
[00:35:58.520 --> 00:36:00.400]   God.
[00:36:00.400 --> 00:36:03.440]   Not as much of a nightmare as buying a 27-inch iMac
[00:36:03.440 --> 00:36:04.920]   and finding out that it's bugging from it.
[00:36:04.920 --> 00:36:06.360]   Oh, we'll get to that.
[00:36:06.360 --> 00:36:08.760]   Yeah, we'll get to that.
[00:36:08.760 --> 00:36:10.280]   We're going to take a little break.
[00:36:10.280 --> 00:36:11.680]   It is fun to have you guys here.
[00:36:11.680 --> 00:36:13.640]   We didn't-- I mean, this isn't the biggest story of the week
[00:36:13.640 --> 00:36:16.000]   by any means, but since all three of you
[00:36:16.000 --> 00:36:17.760]   had real strong opinions--
[00:36:17.760 --> 00:36:18.760]   I thought, well, why not?
[00:36:18.760 --> 00:36:20.720]   You know, let's play to our strength.
[00:36:20.720 --> 00:36:23.000]   Something we do know a little bit about Alex Lindsey.
[00:36:23.000 --> 00:36:27.240]   His office hours are on youtube.com/AlexLindsey.
[00:36:27.240 --> 00:36:30.480]   You can watch recordings of it, but the best way
[00:36:30.480 --> 00:36:32.480]   to participate live with-- guess what?
[00:36:32.480 --> 00:36:33.760]   Zoom.
[00:36:33.760 --> 00:36:36.960]   The Zoom link is on the YouTube comments area.
[00:36:36.960 --> 00:36:37.760]   It's--
[00:36:37.760 --> 00:36:40.760]   there's a couple hundred of them on YouTube.
[00:36:40.760 --> 00:36:42.280]   So you can watch a couple of them.
[00:36:42.280 --> 00:36:43.280]   You get a sense of it.
[00:36:43.280 --> 00:36:43.960]   That's right.
[00:36:43.960 --> 00:36:43.960]   Yeah.
[00:36:43.960 --> 00:36:45.640]   You get a sense of it.
[00:36:45.640 --> 00:36:46.760]   Lisa Schmeiser is here.
[00:36:46.760 --> 00:36:49.640]   She writes about this stuff at ITPro today.
[00:36:49.640 --> 00:36:51.280]   Always a pleasure to see you.
[00:36:51.280 --> 00:36:53.640]   Is it Girl Scout Cookies time?
[00:36:53.640 --> 00:36:54.400]   It is.
[00:36:54.400 --> 00:36:56.240]   It is, in fact, Girl Scout Cookies season.
[00:36:56.240 --> 00:36:57.240]   How old is your daughter doing?
[00:36:57.240 --> 00:36:59.160]   It's extended to March 31st.
[00:36:59.160 --> 00:37:01.160]   I always-- for some reason, associate you
[00:37:01.160 --> 00:37:02.480]   with Girl Scout Cookies.
[00:37:02.480 --> 00:37:04.840]   You should, because I used to bring boxes onto the show.
[00:37:04.840 --> 00:37:07.000]   And I had to say to four of us from your producers.
[00:37:07.000 --> 00:37:08.200]   Oh my god.
[00:37:08.200 --> 00:37:10.280]   Another thing lost in the pandemic.
[00:37:10.280 --> 00:37:11.120]   Always be closeted.
[00:37:11.120 --> 00:37:13.720]   So we are selling 100% online this year.
[00:37:13.720 --> 00:37:14.200]   Wow.
[00:37:14.200 --> 00:37:16.840]   And we've actually sold more cookies this year
[00:37:16.840 --> 00:37:19.600]   than we did the previous year, because I think people just
[00:37:19.600 --> 00:37:21.280]   really wanted--
[00:37:21.280 --> 00:37:23.440]   I think people just really wanted to take advantage of click,
[00:37:23.440 --> 00:37:24.120]   click, click, click.
[00:37:24.120 --> 00:37:26.560]   We're eating more cookies, too, as it turns out.
[00:37:26.560 --> 00:37:27.080]   Oh, yes.
[00:37:27.080 --> 00:37:27.360]   Yes.
[00:37:27.360 --> 00:37:29.080]   No.
[00:37:29.080 --> 00:37:33.240]   We have sold approximately 15% more cookies this year
[00:37:33.240 --> 00:37:36.640]   with a sales force that shrunk by 30%.
[00:37:36.640 --> 00:37:38.720]   So it's been pretty amazing.
[00:37:38.720 --> 00:37:42.160]   Does each council have its own site?
[00:37:42.160 --> 00:37:44.360]   Each troop now has its own site.
[00:37:44.360 --> 00:37:45.280]   And the--
[00:37:45.280 --> 00:37:47.000]   Oh, wow.
[00:37:47.000 --> 00:37:48.760]   The Girl Scouts-- well, girls have the options
[00:37:48.760 --> 00:37:51.800]   to do individual sites on their own.
[00:37:51.800 --> 00:37:53.720]   And then the troop itself has a site.
[00:37:53.720 --> 00:37:57.560]   So the sales get split among all of the girls.
[00:37:57.560 --> 00:38:01.120]   And this year, the Girl Scouts of Northern California
[00:38:01.120 --> 00:38:03.760]   introduced an option they teamed up with a--
[00:38:03.760 --> 00:38:06.160]   so you could say, I'll do the finding Girl Scout Cookies.
[00:38:06.160 --> 00:38:07.480]   That's dangerous.
[00:38:07.480 --> 00:38:09.760]   And they would tell you which troops near you
[00:38:09.760 --> 00:38:13.040]   were selling cookies and who you could contact to buy some.
[00:38:13.040 --> 00:38:16.120]   That was-- whoever thought that up deserves a bonus.
[00:38:16.120 --> 00:38:16.600]   That's a pretty--
[00:38:16.600 --> 00:38:17.360]   Oh, my gosh.
[00:38:17.360 --> 00:38:18.360]   Yeah.
[00:38:18.360 --> 00:38:22.360]   So yes, and the sales normally stopped the first week of March.
[00:38:22.360 --> 00:38:24.880]   But because of the extraordinary circumstances
[00:38:24.880 --> 00:38:26.720]   of the past year, they're going to be going all the way
[00:38:26.720 --> 00:38:27.840]   through to the end of March.
[00:38:27.840 --> 00:38:30.880]   So the Girl Scouts have definitely got this down.
[00:38:30.880 --> 00:38:31.760]   I went to their site.
[00:38:31.760 --> 00:38:35.240]   You can go to girlsgirlscoutcookies.org,
[00:38:35.240 --> 00:38:36.720]   which is their cookie finder.
[00:38:36.720 --> 00:38:38.480]   You can ask a Girl Scout to share a link
[00:38:38.480 --> 00:38:40.560]   to her virtual cookie booth.
[00:38:40.560 --> 00:38:43.760]   You can text cookies to 59618.
[00:38:43.760 --> 00:38:47.440]   You could download the Girl Scout Cookie Finder app.
[00:38:47.440 --> 00:38:51.800]   But my favorite is, hey, Echo, where can I get Girl Scout cookies
[00:38:51.800 --> 00:38:52.600]   near me?
[00:38:52.600 --> 00:38:53.760]   I love that.
[00:38:53.760 --> 00:38:55.000]   Brilliant.
[00:38:55.000 --> 00:38:57.000]   Well, I'm glad it's going well, because I know that's important.
[00:38:57.000 --> 00:38:59.680]   The best type of online cookies going.
[00:38:59.680 --> 00:39:02.520]   Where do you have Girl Scout cookies in the UK?
[00:39:02.520 --> 00:39:03.720]   They'd be Girl Guides, right?
[00:39:03.720 --> 00:39:04.200]   Ooh.
[00:39:04.200 --> 00:39:04.880]   No.
[00:39:04.880 --> 00:39:07.000]   Yeah, they don't really exist in the same way.
[00:39:07.000 --> 00:39:09.200]   We only have Google cookies, and those are going away, too,
[00:39:09.200 --> 00:39:09.640]   you say.
[00:39:09.640 --> 00:39:12.480]   Oh, that's another story we'll be getting to.
[00:39:12.480 --> 00:39:13.480]   Well done.
[00:39:13.480 --> 00:39:15.560]   [LAUGHTER]
[00:39:15.560 --> 00:39:15.920]   Actually--
[00:39:15.920 --> 00:39:16.840]   I'm doing this a while, Leo.
[00:39:16.840 --> 00:39:18.120]   I think you have.
[00:39:18.120 --> 00:39:20.120]   You're very good at this.
[00:39:20.120 --> 00:39:20.920]   That's Will Harris.
[00:39:20.920 --> 00:39:21.960]   It's great to have Will here.
[00:39:21.960 --> 00:39:26.960]   His new business is entail, E-N-T-A-L-E.com.
[00:39:26.960 --> 00:39:29.880]   And I just downloaded the entail player on my iPhone.
[00:39:29.880 --> 00:39:31.760]   I can't wait to try it and start
[00:39:31.760 --> 00:39:34.760]   listening to shows with all that additional material.
[00:39:34.760 --> 00:39:36.240]   That's going to be cool.
[00:39:36.240 --> 00:39:38.400]   Our show today brought to you by ExtraHop.
[00:39:38.400 --> 00:39:46.120]   First, there was SolarWinds, the sunburst attack, a real wake-up
[00:39:46.120 --> 00:39:49.080]   call to a changing threat landscape.
[00:39:49.080 --> 00:39:54.800]   Then on Tuesday, Microsoft announced four, zero days,
[00:39:54.800 --> 00:39:56.240]   attacking exchange server.
[00:39:56.240 --> 00:39:59.480]   In fact, Microsoft is now admitting
[00:39:59.480 --> 00:40:01.640]   that about 30,000 organizations were
[00:40:01.640 --> 00:40:03.640]   hacked by, according to Brian Krebs,
[00:40:03.640 --> 00:40:09.120]   particularly aggressive Chinese espionage agency.
[00:40:09.120 --> 00:40:11.800]   But the worst thing you can imagine--
[00:40:11.800 --> 00:40:15.040]   and unfortunately, this may be the circumstance you're in--
[00:40:15.040 --> 00:40:19.560]   is an advanced threat actor who's already inside the network
[00:40:19.560 --> 00:40:22.600]   and has been sitting there for a long time.
[00:40:22.600 --> 00:40:24.400]   When criminals get past your defenses,
[00:40:24.400 --> 00:40:27.360]   businesses need a plan for detection and response,
[00:40:27.360 --> 00:40:30.600]   that old model of protection and prevention alone
[00:40:30.600 --> 00:40:31.720]   is no longer enough.
[00:40:31.720 --> 00:40:34.400]   They're inside the house.
[00:40:34.400 --> 00:40:36.520]   Fortunately, there's ExtraHop Reveal X.
[00:40:36.520 --> 00:40:38.720]   It's the only solution that shows you not just where
[00:40:38.720 --> 00:40:41.120]   intruders are going, but where they've been.
[00:40:41.120 --> 00:40:43.880]   So you can investigate incidents and prevent them
[00:40:43.880 --> 00:40:47.600]   from turning into full blown breaches.
[00:40:47.600 --> 00:40:48.960]   When cyber attacks make the news,
[00:40:48.960 --> 00:40:52.200]   the first question security teams need to answer is,
[00:40:52.200 --> 00:40:53.240]   have we been compromised?
[00:40:53.240 --> 00:40:56.280]   Right now, there are a lot of people
[00:40:56.280 --> 00:40:59.520]   running exchange servers who are dying to know.
[00:40:59.520 --> 00:41:02.800]   And actually, I think Krebs said, the chances
[00:41:02.800 --> 00:41:04.320]   are if you were running exchange server
[00:41:04.320 --> 00:41:07.240]   and you didn't get patched on Tuesday, you are compromised.
[00:41:07.240 --> 00:41:09.640]   Now you need ExtraHop Reveal X.
[00:41:09.640 --> 00:41:12.080]   It makes it super simple to find out
[00:41:12.080 --> 00:41:15.600]   if you've been compromised 90 days of record look back
[00:41:15.600 --> 00:41:18.560]   and complete network visibility across the data center,
[00:41:18.560 --> 00:41:21.680]   but also through the cloud and all the way to the device edge,
[00:41:21.680 --> 00:41:25.160]   which lets your security team get to real answers fast.
[00:41:25.160 --> 00:41:27.520]   In a post-compromised world, your greatest chance
[00:41:27.520 --> 00:41:31.080]   at stopping advanced threats is with ExtraHop Network Detection
[00:41:31.080 --> 00:41:33.120]   and Response, NDR.
[00:41:33.120 --> 00:41:35.160]   ExtraHop is an amazing tool.
[00:41:35.160 --> 00:41:36.520]   I want you to go to the website.
[00:41:36.520 --> 00:41:37.960]   There's an interactive demo.
[00:41:37.960 --> 00:41:40.360]   Then you can see what ExtraHop looks like.
[00:41:40.360 --> 00:41:43.360]   Part of the reason it looks so good is because
[00:41:43.360 --> 00:41:45.400]   you'll be able to respond faster if you can
[00:41:45.400 --> 00:41:47.000]   grok the information faster.
[00:41:47.000 --> 00:41:49.720]   And that's exactly what ExtraHop does.
[00:41:49.720 --> 00:41:52.880]   ExtraHop.com/twit.
[00:41:52.880 --> 00:41:54.440]   Stop advanced threats.
[00:41:54.440 --> 00:41:56.840]   Take a look at the amazing, interactive demo
[00:41:56.840 --> 00:42:00.400]   and find out how ExtraHop stops breaches 84% faster
[00:42:00.400 --> 00:42:04.000]   and helps you figure out who's inside the house.
[00:42:04.000 --> 00:42:06.360]   ExtraHop.com/twit.
[00:42:06.360 --> 00:42:10.480]   We thank ExtraHop so much for supporting this week.
[00:42:10.480 --> 00:42:11.880]   In tech, we thank you for supporting it
[00:42:11.880 --> 00:42:15.920]   by going to that site, extrahop.com/twit.
[00:42:15.920 --> 00:42:20.920]   We should talk about this Microsoft zero day.
[00:42:20.920 --> 00:42:22.960]   What terrible news.
[00:42:22.960 --> 00:42:26.640]   I'm sure Lisa, your day was kind of busy on Tuesday.
[00:42:26.640 --> 00:42:28.840]   You're covering this.
[00:42:28.840 --> 00:42:32.080]   It was also, it landed during Microsoft Ignite.
[00:42:32.080 --> 00:42:33.440]   Yeah, nice timing, huh?
[00:42:33.440 --> 00:42:35.520]   They do that too.
[00:42:35.520 --> 00:42:41.240]   And it wasn't surprising.
[00:42:41.240 --> 00:42:43.880]   Honestly, nothing would be surprising with this threat
[00:42:43.880 --> 00:42:46.720]   landscape at all.
[00:42:46.720 --> 00:42:50.920]   So Brian Krebs had a good article in which he said his sources
[00:42:50.920 --> 00:42:56.520]   said that there were 30,000 organizations compromised.
[00:42:56.520 --> 00:42:58.120]   That's not-- Oh, no, 60,000.
[00:42:58.120 --> 00:42:59.040]   It's up to 60,000.
[00:42:59.040 --> 00:43:02.360]   It's up to 60, holy cow.
[00:43:02.360 --> 00:43:06.160]   Four zero day flaws in exchange server
[00:43:06.160 --> 00:43:10.200]   running from 2013 through 2019.
[00:43:10.200 --> 00:43:14.040]   Microsoft credit researchers at Villexity, Villexity's president,
[00:43:14.040 --> 00:43:19.280]   Stephen Adair said, "These flaws are very easy to exploit.
[00:43:19.280 --> 00:43:21.600]   You don't need any special knowledge.
[00:43:21.600 --> 00:43:24.040]   You just show up and say, I would like to break in
[00:43:24.040 --> 00:43:25.720]   and read all their email.
[00:43:25.720 --> 00:43:29.080]   That's all there is to it."
[00:43:29.080 --> 00:43:32.360]   Microsoft says it's a Chinese espionage group that's
[00:43:32.360 --> 00:43:35.440]   been dubbed Haphneum.
[00:43:35.440 --> 00:43:40.000]   And Krebs says, "Very aggressive."
[00:43:40.000 --> 00:43:42.960]   Yeah, I mean, initially they went for high value targets,
[00:43:42.960 --> 00:43:47.440]   as they call them, governments or financial institutions.
[00:43:47.440 --> 00:43:50.880]   And then the hack widened considerably.
[00:43:50.880 --> 00:43:53.560]   And it just appears at this point, it's a matter of,
[00:43:53.560 --> 00:43:55.600]   we can get in, so we will.
[00:43:55.600 --> 00:43:58.680]   And we'll get the data and we'll see if it's useful later.
[00:43:58.680 --> 00:44:00.360]   It doesn't look like cyber warfare.
[00:44:00.360 --> 00:44:03.160]   It's not the hacking where you're trying to make money
[00:44:03.160 --> 00:44:07.160]   by ransomware or malware or by stealing secrets.
[00:44:07.160 --> 00:44:11.440]   It's not the hack where you're trying to cyber warfare
[00:44:11.440 --> 00:44:14.160]   hack the nation's state might try to bring down a grid.
[00:44:14.160 --> 00:44:20.560]   It really looks like kind of dog food espionage,
[00:44:20.560 --> 00:44:23.800]   like just getting in, let's find out what's going on
[00:44:23.800 --> 00:44:25.320]   and maybe we can use it, that kind of thing.
[00:44:25.320 --> 00:44:28.440]   Well, there's two ways in which this hack is super useful.
[00:44:28.440 --> 00:44:31.160]   And the first is yes, it was an information gathering
[00:44:31.160 --> 00:44:32.000]   expedition.
[00:44:32.000 --> 00:44:35.560]   It was a great way to figure out what works and how
[00:44:35.560 --> 00:44:36.880]   and what the skill and scope is.
[00:44:36.880 --> 00:44:42.320]   So they now know a whole lot more about the global digital
[00:44:42.320 --> 00:44:45.080]   landscape than they did before they successfully hacked it.
[00:44:45.080 --> 00:44:48.000]   And the second way it's useful is it's wearing down
[00:44:48.000 --> 00:44:52.120]   the resources and the energy and the attention that people
[00:44:52.120 --> 00:44:54.240]   who fight hacking are going to have.
[00:44:54.240 --> 00:44:56.560]   Because we've had so many major breaches.
[00:44:56.560 --> 00:44:57.460]   So many major
[00:44:57.460 --> 00:44:59.480]   - Still busy trying to figure out if solar winds hit you.
[00:44:59.480 --> 00:45:01.120]   Now all of a sudden your exchange.
[00:45:01.120 --> 00:45:04.080]   Here's a, here's a Krebs quote, quote, one source.
[00:45:04.080 --> 00:45:07.720]   It's police departments, hospitals, tons of city and state
[00:45:07.720 --> 00:45:09.440]   governments and credit unions.
[00:45:09.440 --> 00:45:12.560]   Just this is the quote that scares the hell out of me.
[00:45:12.560 --> 00:45:15.800]   Just about everyone who's running self-hosted outlook
[00:45:15.800 --> 00:45:17.000]   web access.
[00:45:17.000 --> 00:45:20.880]   And didn't get patched on Tuesday, has been hit with a
[00:45:20.880 --> 00:45:22.240]   zero day attack.
[00:45:22.240 --> 00:45:24.520]   And the chances are what they do is they put a little web
[00:45:24.520 --> 00:45:26.440]   server on your system.
[00:45:26.440 --> 00:45:29.440]   And the chances are it's there.
[00:45:29.440 --> 00:45:31.240]   - Yeah.
[00:45:31.240 --> 00:45:33.560]   And you can't just run the patch.
[00:45:33.560 --> 00:45:35.360]   The thing is, is you're going to have to go through.
[00:45:35.360 --> 00:45:36.200]   - Too late.
[00:45:36.200 --> 00:45:37.040]   You're compromised.
[00:45:37.040 --> 00:45:39.200]   - Well, not just that, but even if you were to patch it now,
[00:45:39.200 --> 00:45:41.080]   you're going to have to go through and rebuild your system
[00:45:41.080 --> 00:45:43.200]   from the ground up.
[00:45:43.200 --> 00:45:46.000]   Because you just don't know what got injected.
[00:45:46.000 --> 00:45:47.600]   You don't know what's logging what.
[00:45:47.600 --> 00:45:51.360]   And you don't know what other vulnerabilities you have.
[00:45:51.360 --> 00:45:55.440]   And the thing that honestly scares me a little bit more is
[00:45:55.440 --> 00:45:56.800]   they've automated the attacks.
[00:45:56.800 --> 00:45:59.840]   This is not just a bank of people who are looking cool
[00:45:59.840 --> 00:46:02.200]   and cackling and ha ha ha, I'm into the system.
[00:46:02.200 --> 00:46:09.200]   Like they've written bots that can now perpetuate these
[00:46:09.200 --> 00:46:12.160]   huge attacks on a scale that we haven't seen before.
[00:46:12.160 --> 00:46:20.760]   And again, if you're on this, I were like, oh, this is interesting.
[00:46:20.760 --> 00:46:23.520]   It's a great way to wear down someone's defenses over time.
[00:46:23.520 --> 00:46:27.440]   Because even if you find and block or find and stop these bugs,
[00:46:27.440 --> 00:46:29.720]   it's like the Velociraptors in Jurassic Park.
[00:46:29.720 --> 00:46:31.360]   They're just testing the fence for weakness.
[00:46:31.360 --> 00:46:35.560]   And sooner or later, they're going to find a spot that--
[00:46:35.560 --> 00:46:36.960]   - Well, it's also--
[00:46:36.960 --> 00:46:39.160]   - The fence only holds for so long.
[00:46:39.160 --> 00:46:39.520]   - Right.
[00:46:39.520 --> 00:46:42.040]   I mean, also being able to build the interconnections
[00:46:42.040 --> 00:46:43.520]   for spearfishing is really useful.
[00:46:43.520 --> 00:46:45.760]   So if you have all that data, you now know how people
[00:46:45.760 --> 00:46:46.480]   are interrelated to it.
[00:46:46.480 --> 00:46:48.000]   - Oh, that's a good point.
[00:46:48.000 --> 00:46:49.600]   - And so when you--
[00:46:49.600 --> 00:46:55.760]   So now it's why, like, when people at schools send me emails
[00:46:55.760 --> 00:46:59.040]   to all the parents without a blind CC,
[00:46:59.040 --> 00:47:01.240]   you get the email back from me like, hey, that wouldn't be a good--
[00:47:01.240 --> 00:47:01.880]   we should avoid that.
[00:47:01.880 --> 00:47:02.840]   - Oh my god, yeah.
[00:47:02.840 --> 00:47:05.560]   - That is because that connection now is made.
[00:47:05.560 --> 00:47:09.200]   So now someone can go, hey, this is Judy from the school.
[00:47:09.200 --> 00:47:12.640]   And so now they're-- because almost all hacking is really--
[00:47:12.640 --> 00:47:13.560]   - Social hacking.
[00:47:13.560 --> 00:47:14.120]   - Yeah.
[00:47:14.120 --> 00:47:15.120]   - It's all social hacking.
[00:47:15.120 --> 00:47:15.800]   You know, it's--
[00:47:15.800 --> 00:47:17.600]   - A lot of it is, yeah.
[00:47:17.600 --> 00:47:21.160]   - It's all organic firewall failure.
[00:47:21.160 --> 00:47:27.320]   And so the-- you know, knowing how people are interrelated
[00:47:27.320 --> 00:47:29.640]   and knowing what they think is OK and what they--
[00:47:29.640 --> 00:47:32.400]   and coming to them from something that seems familiar
[00:47:32.400 --> 00:47:35.760]   is a big piece of how this gets--
[00:47:35.760 --> 00:47:37.720]   how you get into a company later.
[00:47:37.720 --> 00:47:38.960]   And you may not know what that is,
[00:47:38.960 --> 00:47:41.880]   but 30,000 millions of people and knowing how they're
[00:47:41.880 --> 00:47:45.320]   interrelated is a treasure trove.
[00:47:45.320 --> 00:47:46.320]   You know, of doing that.
[00:47:46.320 --> 00:47:46.880]   - It's really nice.
[00:47:46.880 --> 00:47:47.360]   - Yeah.
[00:47:47.360 --> 00:47:48.480]   Wow.
[00:47:48.480 --> 00:47:50.280]   - The other thing I'd like to point out with this
[00:47:50.280 --> 00:47:53.360]   is Microsoft's messaging upfront was--
[00:47:53.360 --> 00:47:55.000]   they've had a couple good points--
[00:47:55.000 --> 00:47:57.240]   not a couple good points, but what's--
[00:47:57.240 --> 00:47:58.360]   that seems like editorializing.
[00:47:58.360 --> 00:47:59.840]   I'm not trying to internalize here.
[00:47:59.840 --> 00:48:02.480]   They've had a couple--
[00:48:02.480 --> 00:48:04.880]   they've tried to stick with just the facts--
[00:48:04.880 --> 00:48:06.960]   just a facts approach, which is refreshing,
[00:48:06.960 --> 00:48:09.240]   because they're not obfuscating too much on it.
[00:48:09.240 --> 00:48:11.520]   But one of the things I do think is notable
[00:48:11.520 --> 00:48:13.720]   is they are very much in the-- oh, by the way,
[00:48:13.720 --> 00:48:16.080]   if you have any of our cloud-based services,
[00:48:16.080 --> 00:48:18.960]   you're absolutely not affected.
[00:48:18.960 --> 00:48:22.160]   I was like, oh, you've got to respect the hustle.
[00:48:22.160 --> 00:48:24.640]   - You've got to get the sales pitch in there.
[00:48:24.640 --> 00:48:29.040]   Gee, if you were only running Microsoft 365--
[00:48:29.040 --> 00:48:30.080]   - This wouldn't be a problem.
[00:48:30.080 --> 00:48:31.640]   - You'd be home by now.
[00:48:31.640 --> 00:48:33.800]   - But one of the things this does point out
[00:48:33.800 --> 00:48:36.560]   that I don't think a lot of people in the US
[00:48:36.560 --> 00:48:40.120]   really think about is a lot of our infrastructure,
[00:48:40.120 --> 00:48:43.200]   everything from transit to utilities to hospitals
[00:48:43.200 --> 00:48:46.640]   to, like you said, local governments to school districts.
[00:48:46.640 --> 00:48:50.960]   All of those places have tiny IT budgets comparatively speaking.
[00:48:50.960 --> 00:48:53.400]   And they don't have a whole lot of money
[00:48:53.400 --> 00:48:56.360]   to be perpetually upgrading to the latest or greatest things.
[00:48:56.360 --> 00:48:59.520]   And so a lot of our country is running on systems
[00:48:59.520 --> 00:49:03.160]   that are not updated as often as vendors would recommend
[00:49:03.160 --> 00:49:07.160]   and do not enjoy the level of technical support.
[00:49:07.160 --> 00:49:09.200]   That would seem prudent.
[00:49:09.200 --> 00:49:11.560]   We're looking at a real infrastructure,
[00:49:11.560 --> 00:49:13.880]   tech infrastructure issue here in terms of funding
[00:49:13.880 --> 00:49:14.800]   and deployment.
[00:49:14.800 --> 00:49:18.480]   So for all, this is a Microsoft bug.
[00:49:18.480 --> 00:49:21.480]   This is also a tech funding issue.
[00:49:21.480 --> 00:49:24.040]   - I think your social graph point is really interesting,
[00:49:24.040 --> 00:49:28.480]   Alex, but it makes me think one of the complaints
[00:49:28.480 --> 00:49:32.240]   people had about Clubhouse was it was unusually aggressive
[00:49:32.240 --> 00:49:33.960]   at going through your contacts.
[00:49:33.960 --> 00:49:35.520]   In fact, come to think of it.
[00:49:35.520 --> 00:49:37.720]   That's one of the place people have about almost all
[00:49:37.720 --> 00:49:39.800]   of these apps.
[00:49:39.800 --> 00:49:42.440]   They immediately ask for access to your contact list.
[00:49:42.440 --> 00:49:44.840]   We just want to let you know when somebody you know
[00:49:44.840 --> 00:49:46.960]   is on Clubhouse or is joining Clubhouse.
[00:49:46.960 --> 00:49:48.640]   We just want to, it's for you.
[00:49:48.640 --> 00:49:52.360]   But remember the Clubhouse is back in as a Chinese company.
[00:49:52.360 --> 00:49:54.160]   I would guess that by now,
[00:49:54.160 --> 00:49:58.200]   - And those are adversaries have a full social graph
[00:49:58.200 --> 00:50:00.120]   of every single human on the planet.
[00:50:00.120 --> 00:50:02.600]   - Well, it's the issue you're right.
[00:50:02.600 --> 00:50:06.360]   The issue the emails provide is context.
[00:50:06.360 --> 00:50:07.600]   So you know how people are connected,
[00:50:07.600 --> 00:50:09.560]   but you also know the discussions that they're having.
[00:50:09.560 --> 00:50:13.400]   So you can reply to someone based on another conversation,
[00:50:13.400 --> 00:50:15.800]   literally referring back to something
[00:50:15.800 --> 00:50:17.320]   that is going to look familiar to them.
[00:50:17.320 --> 00:50:21.040]   - The only saving graces, if they've hacked 60,000
[00:50:21.040 --> 00:50:23.960]   organizations, they must have millions of emails.
[00:50:23.960 --> 00:50:25.960]   It's like a giant data dump.
[00:50:25.960 --> 00:50:28.200]   I'm hoping that they can't handle it all or,
[00:50:28.200 --> 00:50:29.120]   I don't know, do they?
[00:50:29.120 --> 00:50:29.960]   - They can handle it all.
[00:50:29.960 --> 00:50:30.960]   - They can't handle it?
[00:50:30.960 --> 00:50:32.360]   - That's not hard.
[00:50:32.360 --> 00:50:34.360]   It's a little AI here.
[00:50:34.360 --> 00:50:35.440]   Because they don't need all of it.
[00:50:35.440 --> 00:50:36.280]   They don't need all of it.
[00:50:36.280 --> 00:50:38.240]   They, because everyone's doing it in text,
[00:50:38.240 --> 00:50:39.160]   it's super convenient.
[00:50:39.160 --> 00:50:40.040]   And the,
[00:50:40.040 --> 00:50:40.880]   - Oh, geez.
[00:50:40.880 --> 00:50:42.440]   (laughing)
[00:50:42.440 --> 00:50:44.120]   - So it's, you know, it's,
[00:50:44.120 --> 00:50:48.360]   we had to, we were a target of state actors last year.
[00:50:48.360 --> 00:50:50.040]   So we just got a lot of education in this area
[00:50:50.040 --> 00:50:51.520]   because we just have to be careful of everything.
[00:50:51.520 --> 00:50:54.120]   We would send each other, you know, people test emails
[00:50:54.120 --> 00:50:55.200]   and so on and so on.
[00:50:55.200 --> 00:50:56.040]   And so,
[00:50:58.360 --> 00:51:00.720]   so the thing is, is that you have to be careful
[00:51:00.720 --> 00:51:02.040]   because all that contextual stuff,
[00:51:02.040 --> 00:51:05.700]   someone's gonna insert information into,
[00:51:05.700 --> 00:51:08.920]   they're gonna insert information that you're familiar with.
[00:51:08.920 --> 00:51:09.960]   They know that you're there
[00:51:09.960 --> 00:51:11.520]   and you're much more likely to click on something.
[00:51:11.520 --> 00:51:12.360]   'Cause oh, that's from,
[00:51:12.360 --> 00:51:13.360]   - That's from the boss.
[00:51:13.360 --> 00:51:14.200]   - Like, you know,
[00:51:14.200 --> 00:51:16.160]   and it's not just that it's from the boss,
[00:51:16.160 --> 00:51:17.600]   that it's set in the right language,
[00:51:17.600 --> 00:51:19.360]   with the right context, with the right.
[00:51:19.360 --> 00:51:21.520]   There's no reason for you to look at it and go,
[00:51:21.520 --> 00:51:23.320]   well, that isn't correct,
[00:51:23.320 --> 00:51:25.360]   you know, and then you click on it and then you're done.
[00:51:25.360 --> 00:51:26.600]   You know, and so that's the,
[00:51:26.600 --> 00:51:28.480]   and then it's in and, you know,
[00:51:28.480 --> 00:51:30.280]   so that's the, it's just,
[00:51:30.280 --> 00:51:31.880]   it's an enormous amount of information.
[00:51:31.880 --> 00:51:34.440]   I mean, and extremely valuable information,
[00:51:34.440 --> 00:51:36.560]   again, for to do the social hacking
[00:51:36.560 --> 00:51:38.200]   that's required to do the real hacking.
[00:51:38.200 --> 00:51:39.800]   - Is it time to give up?
[00:51:39.800 --> 00:51:42.280]   - Surrender Dorothy?
[00:51:42.280 --> 00:51:43.880]   I mean, what do we do about this?
[00:51:43.880 --> 00:51:45.200]   Stop using email.
[00:51:45.200 --> 00:51:46.600]   - Stop using email.
[00:51:46.600 --> 00:51:48.800]   - Yeah, we'll do everything on a Zoom call.
[00:51:48.800 --> 00:51:49.960]   Nevermind the Zoom call.
[00:51:49.960 --> 00:51:52.680]   - Yeah, it's on Z and encrypted, it's on a Zoom call.
[00:51:52.680 --> 00:51:55.000]   - No, I feel like we should just go to TikTok.
[00:51:55.000 --> 00:51:55.840]   (laughs)
[00:51:55.840 --> 00:51:56.680]   - It's all about TikTok.
[00:51:56.680 --> 00:51:57.520]   - TikTok, we just do the whole--
[00:51:57.520 --> 00:51:59.320]   - You can communicate everything on 42nd soundbites
[00:51:59.320 --> 00:52:00.600]   with a soundtrack.
[00:52:00.600 --> 00:52:01.600]   - Exactly, exactly.
[00:52:01.600 --> 00:52:03.440]   No, I, you know, I think that there's not,
[00:52:03.440 --> 00:52:05.800]   in some cases there's not a lot we can do, but I mean,
[00:52:05.800 --> 00:52:09.120]   definitely we shift over to more secure--
[00:52:09.120 --> 00:52:11.640]   - Do you signal or something like that?
[00:52:11.640 --> 00:52:12.600]   - Yeah, you signal a lot.
[00:52:12.600 --> 00:52:13.440]   - Okay.
[00:52:13.440 --> 00:52:14.360]   So there you go.
[00:52:14.360 --> 00:52:16.520]   I mean, you might still get the metadata,
[00:52:16.520 --> 00:52:19.200]   well, I guess you wouldn't get metadata from signal.
[00:52:19.200 --> 00:52:21.320]   - Yeah, it's not, nothing's perfect.
[00:52:21.320 --> 00:52:24.040]   - I mean, you have to know that, I mean, everything is,
[00:52:25.600 --> 00:52:28.200]   to some level at risk.
[00:52:28.200 --> 00:52:30.760]   I mean, there's no perfectly safe thing,
[00:52:30.760 --> 00:52:33.080]   so you just have to, most people aren't hacked
[00:52:33.080 --> 00:52:34.400]   because they're not interesting.
[00:52:34.400 --> 00:52:35.320]   So, you know, like they're not--
[00:52:35.320 --> 00:52:36.600]   - Yeah, that's the good news.
[00:52:36.600 --> 00:52:37.440]   That's the good news.
[00:52:37.440 --> 00:52:40.320]   I always tell the, my radio audience that is,
[00:52:40.320 --> 00:52:41.360]   yeah, you hear about all this stuff,
[00:52:41.360 --> 00:52:43.560]   but don't worry, nobody's interested in you.
[00:52:43.560 --> 00:52:44.360]   - Well, the key is to be,
[00:52:44.360 --> 00:52:46.080]   the key that we have to keep on thinking about
[00:52:46.080 --> 00:52:47.720]   is that there is nothing protected online,
[00:52:47.720 --> 00:52:48.960]   and so being interesting,
[00:52:48.960 --> 00:52:51.240]   and then also, you just really wanna be careful
[00:52:51.240 --> 00:52:54.200]   of what you do online,
[00:52:54.200 --> 00:52:56.000]   and never think that you're safe.
[00:52:56.000 --> 00:52:57.920]   Like, you should just assume that anything you're doing online
[00:52:57.920 --> 00:53:00.200]   is gonna be put out into the public.
[00:53:00.200 --> 00:53:03.080]   - We did a panel with Bruce Schneier,
[00:53:03.080 --> 00:53:06.240]   and we had Brian Chi, and we had,
[00:53:06.240 --> 00:53:10.400]   actually it was a red team, blue team exercise,
[00:53:10.400 --> 00:53:13.360]   where Chebert and Father Robert Ballis there
[00:53:13.360 --> 00:53:15.440]   were the bad guys, the red team, the hackers,
[00:53:15.440 --> 00:53:17.240]   and then we had Bruce Schneier
[00:53:17.240 --> 00:53:20.040]   and Jerry Bucelt to see so at Blog Me In,
[00:53:20.040 --> 00:53:23.040]   as the defenders, and it was really interesting to hear
[00:53:23.040 --> 00:53:26.040]   these two groups who are very well schooled
[00:53:26.040 --> 00:53:28.400]   in the methodology and so forth
[00:53:28.400 --> 00:53:30.860]   basically say, there's nothing you can do,
[00:53:30.860 --> 00:53:35.480]   and you just do the best you can,
[00:53:35.480 --> 00:53:37.480]   you have layered security,
[00:53:37.480 --> 00:53:40.240]   but you pretty much assume that you're under attack
[00:53:40.240 --> 00:53:42.640]   all the time and you may even be compromised.
[00:53:42.640 --> 00:53:45.760]   It sounds awful, to be honest with you.
[00:53:45.760 --> 00:53:47.280]   Is encryption a solution?
[00:53:47.280 --> 00:53:50.480]   - It's part of it.
[00:53:50.480 --> 00:53:51.560]   - Yeah. - You know, definitely,
[00:53:51.560 --> 00:53:53.680]   encrypting what needs to be. - Being paranoid?
[00:53:53.680 --> 00:53:56.040]   - You should just assume that the emails
[00:53:56.040 --> 00:53:59.120]   that you're getting are adversarial
[00:53:59.120 --> 00:54:00.600]   until to prove and otherwise.
[00:54:00.600 --> 00:54:03.320]   That's the zero trust architecture
[00:54:03.320 --> 00:54:05.600]   that Google uses and others promote.
[00:54:05.600 --> 00:54:08.200]   The idea, just assume everything's hostile,
[00:54:08.200 --> 00:54:09.480]   to prove and otherwise.
[00:54:09.480 --> 00:54:14.120]   - Yeah, don't plug your USB devices into things.
[00:54:14.120 --> 00:54:14.960]   - Yeah. - Into things
[00:54:14.960 --> 00:54:16.200]   at the airport. - Superglue
[00:54:16.200 --> 00:54:18.560]   in all of USB devices. - Oh my God.
[00:54:18.560 --> 00:54:19.440]   - Yeah.
[00:54:19.440 --> 00:54:21.640]   - Well, people do that though, that's the thing.
[00:54:21.640 --> 00:54:23.920]   Fortunately, the people who do that
[00:54:23.920 --> 00:54:25.320]   probably are not a target.
[00:54:25.320 --> 00:54:27.680]   - They aren't, but again,
[00:54:27.680 --> 00:54:30.960]   it's whether you provide ancillary information back
[00:54:30.960 --> 00:54:32.120]   that would allow you to,
[00:54:32.120 --> 00:54:35.840]   I mean, so it gets back into why everyone wears masks
[00:54:35.840 --> 00:54:37.880]   even though people are getting vaccines.
[00:54:37.880 --> 00:54:40.880]   It's a matter of if everyone is more careful,
[00:54:40.880 --> 00:54:43.840]   it slows down the effectiveness of it.
[00:54:43.840 --> 00:54:45.840]   It doesn't mean that anything will stop it,
[00:54:45.840 --> 00:54:49.200]   but it does mean that you are going to slow
[00:54:49.200 --> 00:54:50.920]   the propagation.
[00:54:50.920 --> 00:54:54.680]   - This is a kind of topic I hate.
[00:54:54.680 --> 00:54:56.600]   Let me find something more cheery.
[00:54:56.600 --> 00:54:59.160]   Oh, how about this?
[00:54:59.160 --> 00:55:03.000]   Grimes made $5.5 million in under 20 minutes
[00:55:03.000 --> 00:55:04.720]   selling crypto-based artwork.
[00:55:04.720 --> 00:55:07.400]   We've been talking a lot about NFTs.
[00:55:07.400 --> 00:55:09.800]   In fact, my friend Trey Radcliffe,
[00:55:09.800 --> 00:55:12.480]   the photographer is going to join this week in Google
[00:55:12.480 --> 00:55:15.440]   on Wednesday 'cause he's selling some of his works
[00:55:15.440 --> 00:55:16.920]   via NFTs.
[00:55:16.920 --> 00:55:18.640]   He even gave me one.
[00:55:18.640 --> 00:55:23.640]   And I thought I'd have him explain what's going on with this.
[00:55:23.640 --> 00:55:25.000]   We also covered it on Thursday.
[00:55:25.000 --> 00:55:29.360]   - And of course, even better is as well as Grimes selling
[00:55:29.360 --> 00:55:30.920]   what, $5.8 million.
[00:55:30.920 --> 00:55:34.920]   I think Jack Dorsey just put his first ever tweet up
[00:55:34.920 --> 00:55:37.480]   and is that something like $3 million already?
[00:55:37.480 --> 00:55:38.320]   - Yeah, that's crazy.
[00:55:38.320 --> 00:55:40.360]   - By the NFT of Jack Dorsey's first tweet.
[00:55:40.360 --> 00:55:42.200]   - So his first tweet,
[00:55:42.200 --> 00:55:45.120]   which is something like setting up Twitter, T-W-T-T-R,
[00:55:45.120 --> 00:55:47.280]   which is what it was called in those days,
[00:55:48.400 --> 00:55:51.000]   is still online at Twitter.
[00:55:51.000 --> 00:55:52.200]   You can read it.
[00:55:52.200 --> 00:55:55.880]   It doesn't take it off and give it to you.
[00:55:55.880 --> 00:55:59.400]   Can you explain this?
[00:55:59.400 --> 00:56:02.600]   You're hip and with it, Mr. Will Harris.
[00:56:02.600 --> 00:56:03.500]   What the hell?
[00:56:03.500 --> 00:56:06.240]   That's my question.
[00:56:06.240 --> 00:56:07.080]   What the hell?
[00:56:07.080 --> 00:56:10.600]   - I want 100% cannot explain this.
[00:56:10.600 --> 00:56:13.240]   But as far as I'm aware,
[00:56:13.240 --> 00:56:16.280]   I've seen some incredible stuff go.
[00:56:16.280 --> 00:56:21.280]   The original GIF of the Nyan Cat,
[00:56:21.280 --> 00:56:25.160]   I think it went for $600,000 in Ethereum.
[00:56:25.160 --> 00:56:27.640]   - Now, clearly the people are spending this money,
[00:56:27.640 --> 00:56:29.160]   they're not getting anything.
[00:56:29.160 --> 00:56:31.400]   You can print a copy of Jack Dorsey's tweet,
[00:56:31.400 --> 00:56:33.560]   anybody can or of the Nyan Cat,
[00:56:33.560 --> 00:56:35.160]   or even of Grimes artwork.
[00:56:35.160 --> 00:56:37.600]   It's digital, so it's perfectly copyable.
[00:56:37.600 --> 00:56:39.160]   You can have a copy of it.
[00:56:39.160 --> 00:56:40.400]   That's not what they're getting.
[00:56:40.400 --> 00:56:44.160]   They're getting a certificate signed by the original author
[00:56:44.160 --> 00:56:47.080]   that says, "We were sort of saying that you own that thing."
[00:56:47.080 --> 00:56:47.920]   - You own it.
[00:56:47.920 --> 00:56:49.360]   - You are actually owning.
[00:56:49.360 --> 00:56:51.480]   - But really what they're buying is speculative.
[00:56:51.480 --> 00:56:54.000]   They're assuming that whatever this thing is,
[00:56:54.000 --> 00:56:56.040]   this blockchain entry I have is,
[00:56:56.040 --> 00:56:58.400]   I will be able to sell for a higher price down the road,
[00:56:58.400 --> 00:56:59.240]   right?
[00:56:59.240 --> 00:57:00.800]   'Cause there's no pride of ownership.
[00:57:00.800 --> 00:57:02.360]   I'm not hanging it on the wall.
[00:57:02.360 --> 00:57:04.160]   - Well, you might do.
[00:57:04.160 --> 00:57:05.080]   You might hang it on the road.
[00:57:05.080 --> 00:57:06.160]   You might print a package.
[00:57:06.160 --> 00:57:07.720]   - Even when you tweet and say like,
[00:57:07.720 --> 00:57:10.240]   "I own this tweet," you know.
[00:57:10.240 --> 00:57:12.440]   - I'm sure I can print it a bunch of times,
[00:57:12.440 --> 00:57:14.440]   but I can literally prove that I own it.
[00:57:14.440 --> 00:57:17.080]   And it's this really interesting shift.
[00:57:17.080 --> 00:57:19.320]   In a way, it's kind of like the inverse
[00:57:19.320 --> 00:57:21.520]   of what we've seen across the rest of media,
[00:57:21.520 --> 00:57:24.480]   which is when you subscribe to Spotify
[00:57:24.480 --> 00:57:25.920]   or when you subscribe to Apple Music,
[00:57:25.920 --> 00:57:28.880]   or even if you buy tracks from Apple, right?
[00:57:28.880 --> 00:57:31.600]   You never actually get to own those tracks.
[00:57:31.600 --> 00:57:33.640]   You only ever have, it's like that thing
[00:57:33.640 --> 00:57:36.600]   of what happens to my iTunes account when I die.
[00:57:36.600 --> 00:57:38.280]   Nobody can inherit my music
[00:57:38.280 --> 00:57:40.800]   in the way that they can inherit my CDs.
[00:57:40.800 --> 00:57:43.680]   So in a way, what people are doing now with NFTs
[00:57:43.680 --> 00:57:45.720]   is flipping that on its head and saying,
[00:57:45.720 --> 00:57:48.240]   "Yeah, okay, the thing might be infinitely copyable
[00:57:48.240 --> 00:57:51.800]   because it's digital, but actually you can own
[00:57:51.800 --> 00:57:54.960]   the actual thing and pass it on."
[00:57:54.960 --> 00:57:57.040]   And I think that links into,
[00:57:57.040 --> 00:58:00.240]   I think the NFT piece from Jack Dorsey at Twitter
[00:58:00.240 --> 00:58:04.600]   links really neatly into the fact that Square this week
[00:58:04.600 --> 00:58:07.560]   announced that it was buying title, the Jay-Z
[00:58:07.560 --> 00:58:09.240]   and Beyonce's music.
[00:58:09.240 --> 00:58:13.240]   Which looks like a really, really, really weird thing
[00:58:13.240 --> 00:58:16.680]   for a payments processor to do until you think,
[00:58:16.680 --> 00:58:19.120]   "Okay, well, how are artists going to make money
[00:58:19.120 --> 00:58:21.160]   in the future when Turing is restricted
[00:58:21.160 --> 00:58:22.880]   and streaming roles are minor?"
[00:58:22.880 --> 00:58:24.560]   They're looking at Patreon and saying
[00:58:24.560 --> 00:58:27.600]   we could be the Patreon for the music industry.
[00:58:27.600 --> 00:58:32.600]   Whoa, look, Grimes has just sold $6 million worth of art.
[00:58:34.960 --> 00:58:39.960]   Or any band in the world can sell the copy of a track
[00:58:39.960 --> 00:58:44.640]   or the copy, you can sell your actual music.
[00:58:44.640 --> 00:58:48.800]   And so I think that the whole Square title thing
[00:58:48.800 --> 00:58:53.320]   is a whole play for an extension of music
[00:58:53.320 --> 00:58:55.920]   beyond what we think of music being right now.
[00:58:55.920 --> 00:59:00.920]   The NBA has sold $200 million worth of highlights.
[00:59:02.000 --> 00:59:04.520]   Yeah, the top cup.
[00:59:04.520 --> 00:59:06.120]   Top shot, yeah.
[00:59:06.120 --> 00:59:09.040]   And I think that the other thing is
[00:59:09.040 --> 00:59:10.880]   there's limited editions, it doesn't have to be,
[00:59:10.880 --> 00:59:13.680]   you could theoretically not have a be the only one
[00:59:13.680 --> 00:59:15.520]   that you're selling, that's for $5 million or whatever.
[00:59:15.520 --> 00:59:20.720]   But what if you're able to sell a limited edition album
[00:59:20.720 --> 00:59:23.520]   for title where people have the limited edition,
[00:59:23.520 --> 00:59:24.560]   it might be a collector's item,
[00:59:24.560 --> 00:59:26.360]   there's only $1,500 printed or a thousand,
[00:59:26.360 --> 00:59:29.160]   or printed, quote unquote, digitally printed.
[00:59:29.160 --> 00:59:32.720]   And I'm not a collector, so it's not really something
[00:59:32.720 --> 00:59:34.880]   that sinks into me, I barely keep the stuff I should keep,
[00:59:34.880 --> 00:59:37.640]   let alone the one stuff that doesn't have any.
[00:59:37.640 --> 00:59:39.400]   I don't think these people are collecting.
[00:59:39.400 --> 00:59:40.800]   I think they're speculators.
[00:59:40.800 --> 00:59:41.640]   I think it's--
[00:59:41.640 --> 00:59:43.960]   Well, it gets into art though, right?
[00:59:43.960 --> 00:59:47.440]   Because you can buy the original of a Damien Hurst
[00:59:47.440 --> 00:59:50.680]   for, say, half a million quid.
[00:59:50.680 --> 00:59:55.040]   You can buy a limited edition print of a Damien Hurst,
[00:59:55.040 --> 01:00:00.040]   signed by Damien Hurst for, say, 10,000 pounds.
[01:00:00.040 --> 01:00:03.280]   I could take a photo of a Damien Hurst in a gallery
[01:00:03.280 --> 01:00:05.040]   for nothing, but which is--
[01:00:05.040 --> 01:00:07.080]   Well, I mean, you can get a poster of the Mona Lisa.
[01:00:07.080 --> 01:00:08.880]   You can get a poster of the Mona Lisa,
[01:00:08.880 --> 01:00:10.520]   for X amount of money and put it on your wall,
[01:00:10.520 --> 01:00:13.920]   and you have most of the experience of having it.
[01:00:13.920 --> 01:00:15.240]   Of having it in the Mona Lisa.
[01:00:15.240 --> 01:00:18.520]   Well, there is a value of saying
[01:00:18.520 --> 01:00:20.000]   when somebody comes in your house,
[01:00:20.000 --> 01:00:21.800]   that's the real Mona Lisa.
[01:00:22.720 --> 01:00:24.720]   So I think what we're saying-- It's intangible.
[01:00:24.720 --> 01:00:27.000]   Digital age is in the digital age.
[01:00:27.000 --> 01:00:30.000]   It's like, okay, we're starting to experiment
[01:00:30.000 --> 01:00:33.480]   with what does real digital ownership look like.
[01:00:33.480 --> 01:00:35.400]   Like as Alex says, you can buy as many posters
[01:00:35.400 --> 01:00:36.400]   of the Mona Lisa as you want.
[01:00:36.400 --> 01:00:39.360]   There's value in having the actual one.
[01:00:39.360 --> 01:00:43.280]   Well, what if, you know, I can listen to as many
[01:00:43.280 --> 01:00:47.720]   Grimes songs as I want, but I own the original master?
[01:00:47.720 --> 01:00:48.640]   You know-- But you don't.
[01:00:48.640 --> 01:00:49.800]   You don't own it.
[01:00:49.800 --> 01:00:50.880]   That's not what's being sold.
[01:00:50.880 --> 01:00:51.880]   It's not the master.
[01:00:51.880 --> 01:00:56.880]   It's this kind of intangible thing that I own the NFT.
[01:00:56.880 --> 01:01:00.440]   It's not, it's very odd.
[01:01:00.440 --> 01:01:01.880]   And I think it's purely speculative.
[01:01:01.880 --> 01:01:04.240]   Seth Coughton makes a very good point in his blog.
[01:01:04.240 --> 01:01:07.720]   He says NFTs are a dangerous trap,
[01:01:07.720 --> 01:01:09.840]   like most traps they're mysterious,
[01:01:09.840 --> 01:01:12.360]   then appealing and then it's too late.
[01:01:12.360 --> 01:01:16.320]   And his argument is not that it's silly or it's foolish,
[01:01:16.320 --> 01:01:19.720]   but because it's based on blockchain,
[01:01:19.720 --> 01:01:23.640]   it is a horrendous and really kind of at this point,
[01:01:23.640 --> 01:01:27.160]   given climate change, untenable use of energy
[01:01:27.160 --> 01:01:29.240]   for absolutely nothing.
[01:01:29.240 --> 01:01:34.400]   Well, that's only if you argue that art is nothing.
[01:01:34.400 --> 01:01:36.040]   And I think that's pretty--
[01:01:36.040 --> 01:01:37.480]   The rest of us are gonna pay for--
[01:01:37.480 --> 01:01:38.960]   That's the forgot that's pretty close to the bottom.
[01:01:38.960 --> 01:01:40.800]   No, but you're not, no, the art was made.
[01:01:40.800 --> 01:01:42.800]   The art's independent of the NFT.
[01:01:42.800 --> 01:01:44.840]   He says the rest of us are gonna pay for NFTs
[01:01:44.840 --> 01:01:46.200]   for a very long time.
[01:01:46.200 --> 01:01:48.160]   They use an astonishing amount.
[01:01:48.160 --> 01:01:50.160]   This is the NFT, not the artwork.
[01:01:50.160 --> 01:01:54.360]   An astonishing amount of electricity to create and to trade.
[01:01:54.360 --> 01:01:56.600]   Together, they're already using more than is consumed
[01:01:56.600 --> 01:01:58.680]   by some states in the United States.
[01:01:58.680 --> 01:02:00.880]   Imagine building a giant new power plant
[01:02:00.880 --> 01:02:05.080]   just to make Christie's or the Basil Art Fair function.
[01:02:05.080 --> 01:02:07.080]   And the amount of power wasted will go up,
[01:02:07.080 --> 01:02:09.400]   commensurate with their popularity and value,
[01:02:09.400 --> 01:02:11.680]   because that's how it's designed.
[01:02:11.680 --> 01:02:13.760]   The short version is that for the foreseeable future,
[01:02:13.760 --> 01:02:16.480]   the method that's used to verify the blockchain
[01:02:16.480 --> 01:02:18.080]   and to create new digital coins,
[01:02:18.080 --> 01:02:21.560]   is deliberately energy intensive and inefficient.
[01:02:21.560 --> 01:02:25.600]   It's on purpose, the energy use will go up and not down.
[01:02:25.600 --> 01:02:28.480]   And that's, I have to say, he's got a very good point.
[01:02:28.480 --> 01:02:31.040]   Societally, I don't know if, you know,
[01:02:31.040 --> 01:02:32.440]   this is such a great idea.
[01:02:32.440 --> 01:02:34.520]   But then you make a good point against blockchain, right?
[01:02:34.520 --> 01:02:36.240]   You might as well say-- Yeah, it is.
[01:02:36.240 --> 01:02:38.880]   Bitcoin is-- Yeah, it's equally dumb.
[01:02:38.880 --> 01:02:39.760]   It's all completely unethical.
[01:02:39.760 --> 01:02:41.960]   It's like, well, you know, how much do we spend printing money
[01:02:41.960 --> 01:02:43.840]   that ends up in people's pockets
[01:02:43.840 --> 01:02:45.400]   and just running around doing nothing?
[01:02:45.400 --> 01:02:48.480]   So once a dollar bill is printed, it takes no more money.
[01:02:48.480 --> 01:02:52.000]   But when every single time a Bitcoin is exchanged,
[01:02:52.000 --> 01:02:54.880]   it requires a significant amount of energy
[01:02:54.880 --> 01:02:57.360]   to record that in the blockchain.
[01:02:57.360 --> 01:02:59.040]   Well, for no good reason--
[01:02:59.040 --> 01:03:00.560]   Better get that green, better get that green,
[01:03:00.560 --> 01:03:02.400]   you deal past pretty quickly then, guys.
[01:03:02.400 --> 01:03:03.800]   (laughing)
[01:03:03.800 --> 01:03:05.360]   Yeah, I mean, there's a couple,
[01:03:05.360 --> 01:03:06.200]   I mean, a couple of other things.
[01:03:06.200 --> 01:03:08.560]   One is that's assuming that energy is going to be
[01:03:08.560 --> 01:03:11.760]   a constrained resource forever, which it probably won't be.
[01:03:11.760 --> 01:03:14.680]   Well, that's the only potential positive outcome of this is,
[01:03:14.680 --> 01:03:19.080]   will be required to figure out a solution to the energy problem
[01:03:19.080 --> 01:03:20.760]   so that we can get renewable energy
[01:03:20.760 --> 01:03:23.160]   into the system as quickly as possible.
[01:03:23.160 --> 01:03:26.720]   Well, I think that we're moving that direction
[01:03:26.720 --> 01:03:30.440]   at an incredible pace, given the level of infrastructure
[01:03:30.440 --> 01:03:31.640]   required-- It's might, it's accelerated.
[01:03:31.640 --> 01:03:33.520]   Yeah, it could, it could, but I think that,
[01:03:33.520 --> 01:03:35.080]   and I think that, I mean, right now,
[01:03:35.080 --> 01:03:36.120]   I can't get my head around it.
[01:03:36.120 --> 01:03:37.680]   I mean, I'm with everybody else,
[01:03:37.680 --> 01:03:40.240]   it's like, I don't understand why I would pay money for that.
[01:03:40.240 --> 01:03:45.240]   But I, like, it's, it's, it feels absurd at the moment.
[01:03:45.240 --> 01:03:47.560]   I know that we're going to come back to this episode
[01:03:47.560 --> 01:03:49.440]   a year from now and be like, I can't believe we said that.
[01:03:49.440 --> 01:03:51.320]   But, you know, like, this was, of course, the future,
[01:03:51.320 --> 01:03:52.640]   but I can't see it because I don't,
[01:03:52.640 --> 01:03:54.120]   but I, of course, I don't, I would never buy a beanie.
[01:03:54.120 --> 01:03:56.160]   It feels like the early days of Bitcoin,
[01:03:56.160 --> 01:03:57.600]   it feels like the early days of Bitcoin
[01:03:57.600 --> 01:04:00.160]   where you're trying to explain to someone what Bitcoin is
[01:04:00.160 --> 01:04:02.520]   and what it represents and why it exists.
[01:04:02.520 --> 01:04:03.720]   And nobody can really do it,
[01:04:03.720 --> 01:04:06.080]   apart from like any sort of money,
[01:04:06.080 --> 01:04:08.400]   everybody's agreed that it's got a value
[01:04:08.400 --> 01:04:10.560]   and maybe you can do something with it.
[01:04:10.560 --> 01:04:11.720]   And I think in a year's time,
[01:04:11.720 --> 01:04:13.760]   we'll be looking back at NFTs in the same way
[01:04:13.760 --> 01:04:16.520]   that we look at Bitcoin, you know, from five years ago ago.
[01:04:16.520 --> 01:04:19.400]   Oh yeah, of course, that's going to mean something.
[01:04:19.400 --> 01:04:22.480]   But we just can't quite see it yet.
[01:04:22.480 --> 01:04:23.320]   - And I think it's great.
[01:04:23.320 --> 01:04:25.160]   People are definitely grappling with how do we,
[01:04:25.160 --> 01:04:27.560]   since, you know, we are moving towards a society
[01:04:27.560 --> 01:04:30.840]   that is going to buy less things, buy less physical things.
[01:04:30.840 --> 01:04:33.440]   So while we're talking about the energy impact of NFT
[01:04:33.440 --> 01:04:37.120]   or all these other things, we are going to buy less things.
[01:04:37.120 --> 01:04:38.240]   We are buying more things for it.
[01:04:38.240 --> 01:04:41.960]   We're spending more of our flexible income
[01:04:41.960 --> 01:04:44.960]   on things that are on our phones, that are media,
[01:04:44.960 --> 01:04:46.640]   that are, you know, all that money's going
[01:04:46.640 --> 01:04:48.120]   to things that are intangible.
[01:04:48.120 --> 01:04:50.120]   And so I think that there is a, you know,
[01:04:50.120 --> 01:04:52.760]   that's already kind of happening.
[01:04:52.760 --> 01:04:57.200]   The interesting thing is, is that then you have artists
[01:04:57.200 --> 01:04:58.520]   and people making things, gotta figure out
[01:04:58.520 --> 01:04:59.760]   how you get into that market.
[01:04:59.760 --> 01:05:00.580]   (laughs)
[01:05:00.580 --> 01:05:03.080]   How do I become part of that market if I, you know,
[01:05:03.080 --> 01:05:05.280]   and to some point, I think the fine art market
[01:05:05.280 --> 01:05:07.000]   has always been a little bit of a scam, right?
[01:05:07.000 --> 01:05:09.240]   I mean, what makes it best to be a conversation?
[01:05:09.240 --> 01:05:10.080]   - All conversation.
[01:05:10.080 --> 01:05:11.440]   - A hundred million dollars.
[01:05:11.440 --> 01:05:14.360]   - It's also just connections and, yeah.
[01:05:14.360 --> 01:05:17.920]   - I mean, the value of everything that's, you know,
[01:05:17.920 --> 01:05:22.320]   30 or 40% more than the hard goods is a conversation.
[01:05:22.320 --> 01:05:25.000]   You know, like it's a, you know, anything over that
[01:05:25.000 --> 01:05:27.640]   is just because we have some perceived value
[01:05:27.640 --> 01:05:29.520]   because of some kind of story.
[01:05:29.520 --> 01:05:31.200]   So whether it's the kind of car we, you know,
[01:05:31.200 --> 01:05:34.240]   the kind of car we buy or the, you know,
[01:05:34.240 --> 01:05:36.400]   the dinner we go out to or all those things
[01:05:36.400 --> 01:05:40.680]   are perceived value based on a conversation.
[01:05:40.680 --> 01:05:42.920]   And so it's, you know, the dollar,
[01:05:42.920 --> 01:05:44.600]   the US dollar is just a conversation.
[01:05:44.600 --> 01:05:45.520]   It's not based on-- - Oh, I agree.
[01:05:45.520 --> 01:05:48.720]   - And I think a lot of people, and I think back to the,
[01:05:48.720 --> 01:05:51.080]   you know, the generational thing,
[01:05:51.080 --> 01:05:54.760]   a lot of younger people are used to buying stuff
[01:05:54.760 --> 01:05:56.560]   that is completely intangible.
[01:05:56.560 --> 01:05:57.840]   You know, they've grown up in, you know,
[01:05:57.840 --> 01:06:02.080]   one of the things that, that Seth Godin actually notes
[01:06:02.080 --> 01:06:05.280]   in his blog is that, you know, it says pointless
[01:06:05.280 --> 01:06:07.160]   as Pokemon cards and it's like, oh, sorry,
[01:06:07.160 --> 01:06:12.000]   we all grew up buying some of us grew up buying Pokemon cards
[01:06:12.000 --> 01:06:13.440]   and they're still worth the crap of money.
[01:06:13.440 --> 01:06:15.080]   - Tell my kid my daughter. - Yeah, so--
[01:06:15.080 --> 01:06:16.440]   - My daughter spends-- - Yeah.
[01:06:16.440 --> 01:06:17.760]   - My daughter spends most of her money on Rob--
[01:06:17.760 --> 01:06:19.200]   - So far away to tell me. - Right.
[01:06:19.200 --> 01:06:20.280]   - Yeah, exactly.
[01:06:20.280 --> 01:06:21.800]   - Roblox is even less tangible.
[01:06:21.800 --> 01:06:23.320]   It's not even physical.
[01:06:23.320 --> 01:06:24.920]   - Because when you're buying Pokemon cards,
[01:06:24.920 --> 01:06:26.320]   when you're buying Pokemon cards
[01:06:26.320 --> 01:06:28.320]   or you're buying things in Animal Crossing
[01:06:28.320 --> 01:06:30.600]   or any one of the other games,
[01:06:30.600 --> 01:06:32.280]   you're not buying something so much
[01:06:32.280 --> 01:06:35.000]   as you're basically paying for the idea
[01:06:35.000 --> 01:06:36.400]   of the experience you're having
[01:06:36.400 --> 01:06:38.080]   or you're paying for the satisfaction
[01:06:38.080 --> 01:06:40.080]   of a finishing collection or things like that.
[01:06:40.080 --> 01:06:42.080]   Like, there's a whole constellation
[01:06:42.080 --> 01:06:43.480]   of meaning around any purchase.
[01:06:43.480 --> 01:06:46.400]   And this NFT stuff just comes back to--
[01:06:46.400 --> 01:06:49.880]   - You can argue that every time you put down 20 bucks
[01:06:49.880 --> 01:06:53.040]   at a blackjack table, you're paying for an experience.
[01:06:53.040 --> 01:06:53.880]   - Oh, yeah, no, you're not.
[01:06:53.880 --> 01:06:56.360]   - And the chance that you might win some money, but--
[01:06:56.360 --> 01:06:58.000]   - Yeah, that's all gambling is,
[01:06:58.000 --> 01:07:00.520]   you're basically paying for an experience.
[01:07:00.520 --> 01:07:03.200]   And if you make money, hooray, it's an side effect.
[01:07:03.200 --> 01:07:05.680]   But no one spends money on gambling
[01:07:05.680 --> 01:07:07.200]   because they expect to win.
[01:07:07.200 --> 01:07:08.200]   Or I should say-- - Well, somebody who--
[01:07:08.200 --> 01:07:10.000]   - They call that an addiction.
[01:07:10.000 --> 01:07:10.840]   (both laughing)
[01:07:10.840 --> 01:07:12.400]   - Exactly, yeah.
[01:07:12.400 --> 01:07:15.920]   But, you know, like, to go back to the generation thing,
[01:07:15.920 --> 01:07:19.200]   if you're growing up as somebody
[01:07:19.200 --> 01:07:23.760]   where your social life is in computer-mediated environments
[01:07:23.760 --> 01:07:25.680]   and you've been gaming and you're used to being able
[01:07:25.680 --> 01:07:29.800]   to customize your environment and it's cheaper and easier
[01:07:29.800 --> 01:07:31.360]   than customizing your physical space.
[01:07:31.360 --> 01:07:33.160]   Like, why wouldn't you?
[01:07:33.160 --> 01:07:35.800]   Why wouldn't you concentrate the bulk
[01:07:35.800 --> 01:07:37.320]   of your economic activity there?
[01:07:37.320 --> 01:07:38.400]   - Right.
[01:07:38.400 --> 01:07:39.240]   - Absolutely.
[01:07:39.240 --> 01:07:44.720]   And I have to say, I had three God children,
[01:07:44.720 --> 01:07:48.000]   who I guess are under the age of 13.
[01:07:48.000 --> 01:07:53.000]   And for Christmas, the oldest one wanted Minecraft bucks,
[01:07:54.840 --> 01:07:57.320]   the middle one wanted Roblox bucks
[01:07:57.320 --> 01:07:59.120]   and the other one wanted V-Bucks.
[01:07:59.120 --> 01:07:59.960]   - Right.
[01:07:59.960 --> 01:08:02.080]   - And you're like, that's, you know,
[01:08:02.080 --> 01:08:04.200]   it's all about buying intangible things.
[01:08:04.200 --> 01:08:07.160]   So I think we're just, we're on a giant path
[01:08:07.160 --> 01:08:08.800]   towards everything.
[01:08:08.800 --> 01:08:10.080]   Everything is more intangible
[01:08:10.080 --> 01:08:13.000]   and we're all gonna be extinct before we get it.
[01:08:13.000 --> 01:08:14.440]   - In a couple of years, Uncle Wilk
[01:08:14.440 --> 01:08:16.440]   and show him how to zoom Dayton,
[01:08:16.440 --> 01:08:17.440]   this is what we're like.
[01:08:17.440 --> 01:08:18.280]   (both laughing)
[01:08:18.280 --> 01:08:20.160]   - Exactly. - Will be complete.
[01:08:20.160 --> 01:08:22.960]   - Our show today brought to you by Zip Recruiter.
[01:08:22.960 --> 01:08:24.120]   I hope you're hiring.
[01:08:24.120 --> 01:08:26.240]   I think the world is coming back.
[01:08:26.240 --> 01:08:28.560]   The job market is improving.
[01:08:28.560 --> 01:08:31.440]   We had job growth this last quarter.
[01:08:31.440 --> 01:08:33.440]   If you're one of those people doing hiring,
[01:08:33.440 --> 01:08:35.480]   hey, thank you, bully for you.
[01:08:35.480 --> 01:08:38.600]   And I wanna tell you about the best way to hire
[01:08:38.600 --> 01:08:39.440]   at Zip Recruiter.
[01:08:39.440 --> 01:08:42.040]   We, back in the day when we hired,
[01:08:42.040 --> 01:08:44.400]   we used to use Zip Recruiter and loved it.
[01:08:44.400 --> 01:08:46.680]   Finding great candidates is tough,
[01:08:46.680 --> 01:08:48.800]   but I would argue it's the most important thing you do
[01:08:48.800 --> 01:08:49.920]   in a business.
[01:08:49.920 --> 01:08:52.160]   A business, a company, a corporation,
[01:08:52.160 --> 01:08:54.760]   is just, it's made up of the people who work there.
[01:08:54.760 --> 01:08:56.760]   And a great employee can take you to the moon
[01:08:56.760 --> 01:08:59.120]   and a bad employee can drag you right down.
[01:08:59.120 --> 01:09:02.440]   You could post that opening on a job board
[01:09:02.440 --> 01:09:05.200]   and then hope the right person comes along
[01:09:05.200 --> 01:09:08.560]   or you could go to Zip Recruiter.
[01:09:08.560 --> 01:09:12.360]   Try it for free at zipprecruiter.com/twit.
[01:09:12.360 --> 01:09:14.480]   Immediately when you post that job on Zip Recruiter,
[01:09:14.480 --> 01:09:17.360]   it gets sent out to over 100 top job sites,
[01:09:17.360 --> 01:09:18.760]   just one click of the mouse.
[01:09:18.760 --> 01:09:20.800]   So you're casting a broader net,
[01:09:20.800 --> 01:09:22.120]   but it doesn't stop there.
[01:09:22.120 --> 01:09:24.560]   Zip Recruiter's matching technology finds people
[01:09:24.560 --> 01:09:28.040]   with the right skills and experience for your job,
[01:09:28.040 --> 01:09:31.040]   then actively invites them to apply.
[01:09:31.040 --> 01:09:33.480]   So while other services may overwhelm you
[01:09:33.480 --> 01:09:35.320]   with applications to sift through,
[01:09:35.320 --> 01:09:37.640]   Zip Recruiter actually finds what you're looking for.
[01:09:37.640 --> 01:09:39.360]   The needle in the haystack,
[01:09:39.360 --> 01:09:42.880]   again, makes it easy to scan, rate,
[01:09:42.880 --> 01:09:45.440]   rank and hire the right person.
[01:09:45.440 --> 01:09:47.920]   So effective, the four out of five employers
[01:09:47.920 --> 01:09:50.400]   who post in Zip Recruiter get a quality candidate
[01:09:50.400 --> 01:09:52.000]   through the site within the first day,
[01:09:52.000 --> 01:09:54.680]   took us just hours when we used it.
[01:09:54.680 --> 01:09:58.080]   It was almost shocking to see these candidates
[01:09:58.080 --> 01:09:59.440]   start rolling in.
[01:09:59.440 --> 01:10:01.120]   Right now you can try Zip Recruiter free
[01:10:01.120 --> 01:10:03.960]   at zipprecruiter.com/twit.
[01:10:03.960 --> 01:10:06.960]   If you're hiring, God bless you, thank you.
[01:10:06.960 --> 01:10:08.520]   And you might as well do it the right way,
[01:10:08.520 --> 01:10:12.360]   the easy way, zipprecruiter.com/twit.
[01:10:12.360 --> 01:10:17.880]   Zip Recruiter is the smartest way to hire.
[01:10:17.880 --> 01:10:20.520]   Zip Recruiter.com/twit.
[01:10:20.520 --> 01:10:22.680]   Thank you, Zip Recruiter for supporting.
[01:10:22.680 --> 01:10:24.400]   And so we can tech, thank you for supporting us,
[01:10:24.400 --> 01:10:27.880]   dear listener, by using that special URL.
[01:10:27.880 --> 01:10:29.440]   By the way, we're gonna be selling NFTs
[01:10:29.440 --> 01:10:32.000]   for all my ad reads at the end of the show.
[01:10:32.000 --> 01:10:34.440]   So line up, right?
[01:10:34.440 --> 01:10:35.480]   Doesn't it, don't you feel like,
[01:10:35.480 --> 01:10:38.880]   gosh, I wish I could figure out a way to capitalize on this.
[01:10:38.880 --> 01:10:42.000]   I mean, it just seems hit or miss.
[01:10:42.000 --> 01:10:44.280]   It seems weird, I don't get it.
[01:10:44.280 --> 01:10:47.120]   One thing you won't be buying will
[01:10:47.120 --> 01:10:50.200]   is a 27-inch iMac, right?
[01:10:50.200 --> 01:10:53.080]   Or at least the pro one, right?
[01:10:53.080 --> 01:10:56.240]   Mac iMac Pro, yeah, I have one on my desk.
[01:10:56.240 --> 01:10:59.800]   Apple has confirmed it's been discontinued
[01:10:59.800 --> 01:11:02.800]   when supplies run out, they're gonna stop selling it.
[01:11:02.800 --> 01:11:04.080]   Now there are two ways to look at that.
[01:11:04.080 --> 01:11:07.280]   One is, in fact, they're pointing people
[01:11:07.280 --> 01:11:10.720]   to the latest 27-inch iMac that the non-pro iMacs
[01:11:10.720 --> 01:11:12.840]   are so good you don't need an iMac Pro.
[01:11:12.840 --> 01:11:16.280]   I choose to interpret it
[01:11:16.280 --> 01:11:20.360]   that Apple's gonna do a M1 or something version
[01:11:20.360 --> 01:11:22.840]   of the iMac Pro sooner than later.
[01:11:22.840 --> 01:11:24.680]   You think, Alex?
[01:11:24.680 --> 01:11:26.040]   Yeah.
[01:11:26.040 --> 01:11:26.880]   Thank you.
[01:11:26.880 --> 01:11:29.800]   (laughing)
[01:11:29.800 --> 01:11:34.800]   I mean, I think that Apple's the M series chips
[01:11:34.800 --> 01:11:38.800]   and the entire infrastructure is so advanced
[01:11:38.800 --> 01:11:40.560]   that there is not any reason for them.
[01:11:40.560 --> 01:11:42.120]   I think that they just need to,
[01:11:42.120 --> 01:11:43.640]   I mean, they're obviously gonna have to decide
[01:11:43.640 --> 01:11:46.120]   as they, how they're turning all these things.
[01:11:46.120 --> 01:11:49.120]   They're gonna be a little bit down in that process,
[01:11:49.120 --> 01:11:52.000]   but they're no longer trying to kind of clump together
[01:11:52.000 --> 01:11:54.240]   this kind of hodgepodge of hardware
[01:11:54.240 --> 01:11:56.640]   to make it as good as they can.
[01:11:56.640 --> 01:11:59.400]   I think that there's going to be something
[01:11:59.400 --> 01:12:01.280]   that has a screen, probably another,
[01:12:01.280 --> 01:12:04.280]   next iMac will most likely just be way more powerful
[01:12:04.280 --> 01:12:06.480]   than the iMac Pro, whenever that comes out,
[01:12:06.480 --> 01:12:07.560]   whether it's--
[01:12:07.560 --> 01:12:09.440]   I think that's part of the problem, isn't it?
[01:12:09.440 --> 01:12:11.320]   That you might be getting, you know,
[01:12:11.320 --> 01:12:12.920]   on a Mac Mini that's more powerful
[01:12:12.920 --> 01:12:15.480]   than the $6,000 iMac Pro
[01:12:15.480 --> 01:12:16.800]   a lot of people years ago.
[01:12:16.800 --> 01:12:17.760]   We have a bunch of Mac Mini's
[01:12:17.760 --> 01:12:19.520]   and they are just screaming.
[01:12:19.520 --> 01:12:21.320]   Yeah. Like the M1s, they're just so fast.
[01:12:21.320 --> 01:12:22.160]   I'm really--
[01:12:22.160 --> 01:12:23.120]   I just can't believe what you bought.
[01:12:23.120 --> 01:12:26.080]   I'm starting to think at all in one is not a good idea
[01:12:26.080 --> 01:12:28.600]   because one of the problems I have with my iMac Pro
[01:12:28.600 --> 01:12:30.040]   is that I'm stuck with that screen,
[01:12:30.040 --> 01:12:31.960]   which is fine, it was fine in 2017.
[01:12:31.960 --> 01:12:33.160]   It's a very good screen,
[01:12:33.160 --> 01:12:35.560]   but there are other form factors I'd like to look at.
[01:12:35.560 --> 01:12:40.000]   I'd like to look at a 59 inch curved wide screen, perhaps.
[01:12:40.000 --> 01:12:42.080]   Well, that's why we invest in the Mac Mini's
[01:12:42.080 --> 01:12:45.200]   is because you have so much capability in them
[01:12:45.200 --> 01:12:46.800]   and we can put any kind of monitors
[01:12:46.800 --> 01:12:50.360]   and or any sets of, you know, at least two monitors easily.
[01:12:50.360 --> 01:12:52.600]   Six of you get really creative,
[01:12:52.600 --> 01:12:56.720]   but you, it makes it really, really easy.
[01:12:56.720 --> 01:12:58.440]   That said, I really do like the fact
[01:12:58.440 --> 01:12:59.640]   that I can just pick up a whole computer
[01:12:59.640 --> 01:13:01.600]   and set it somewhere or hang it somewhere.
[01:13:01.600 --> 01:13:03.400]   And it's just the whole thing is all there
[01:13:03.400 --> 01:13:05.560]   and I don't have to figure out how I'm gonna wire it all together.
[01:13:05.560 --> 01:13:07.960]   So I think there's an advantage to having a screen
[01:13:07.960 --> 01:13:10.080]   that has a computer in it as well.
[01:13:10.080 --> 01:13:12.560]   Not if it's a long-term hold for you, yes.
[01:13:12.560 --> 01:13:15.720]   Definitely, yeah, there's definitely something,
[01:13:15.720 --> 01:13:18.520]   you know, the all-in-one form factor that Apple has now pioneered
[01:13:18.520 --> 01:13:20.880]   for years since the original-
[01:13:20.880 --> 01:13:21.680]   The original iMac.
[01:13:21.680 --> 01:13:22.520]   Wow, yeah.
[01:13:22.520 --> 01:13:27.000]   Is, you know, is clearly incredibly convenient,
[01:13:27.000 --> 01:13:32.000]   but it's definitely got a usage cap, right?
[01:13:32.000 --> 01:13:35.680]   So one of the things that I notice,
[01:13:35.680 --> 01:13:38.720]   particularly where I work,
[01:13:38.720 --> 01:13:41.000]   where we're in a shared working space
[01:13:41.000 --> 01:13:42.920]   where everybody's a startup,
[01:13:42.920 --> 01:13:47.920]   is not a single desktop computer, like in the building.
[01:13:47.920 --> 01:13:52.080]   Because everybody has a 27-inch model,
[01:13:52.080 --> 01:13:56.640]   you know, 4K monitor on their desk and an Apple laptop.
[01:13:56.640 --> 01:13:58.760]   I mean, also nobody else wins laptops,
[01:13:58.760 --> 01:14:03.400]   but you know, you have a MacBook Air or a MacBook Pro
[01:14:03.400 --> 01:14:06.120]   and a monitor and a keyboard
[01:14:06.120 --> 01:14:08.920]   and you pick it up and take it between wherever you want.
[01:14:08.920 --> 01:14:11.880]   And that is sort of the ultimate all-in-one form factor.
[01:14:11.880 --> 01:14:15.280]   And what I'm, you know, I think what a lot of pros are looking for
[01:14:15.280 --> 01:14:18.560]   is not an iMac Pro with an M1.
[01:14:18.560 --> 01:14:22.120]   It's the Mega MacBook Pro with an M1, you know,
[01:14:22.120 --> 01:14:25.880]   and I've got the 16-inch MacBook Pro at the moment,
[01:14:25.880 --> 01:14:28.720]   and it's such a beautiful and fantastic machine,
[01:14:28.720 --> 01:14:31.720]   but with an M1, it would just be like unstoppable.
[01:14:31.720 --> 01:14:33.720]   So that's what I'm holding out, I hope for.
[01:14:33.720 --> 01:14:37.200]   I'm hoping this year, would Alex, am I going to get one this year?
[01:14:37.200 --> 01:14:38.040]   I have no idea.
[01:14:38.040 --> 01:14:40.760]   I have no idea when the, I think our chances are pretty good.
[01:14:40.760 --> 01:14:43.480]   I think our chances are pretty good for the MacBook Pros.
[01:14:43.480 --> 01:14:46.000]   I mean, I think that we're probably not going to see the Mac Pros
[01:14:46.000 --> 01:14:48.160]   until next year, but I think that the other machines
[01:14:48.160 --> 01:14:50.440]   most likely by the end of the year, I wouldn't be surprised.
[01:14:50.440 --> 01:14:52.240]   I don't have any, you know, I mean, I,
[01:14:52.240 --> 01:14:55.680]   the interesting thing will be to see where they take the chips.
[01:14:55.680 --> 01:14:59.560]   Is it going to be an M1X or M2 or, you know, those types of things?
[01:14:59.560 --> 01:15:03.160]   And because some of the rumors are the bigger chips
[01:15:03.160 --> 01:15:04.840]   have a lot of cores.
[01:15:04.840 --> 01:15:08.280]   I just, I just want to know if I'm going to need new wheels
[01:15:08.280 --> 01:15:11.280]   for an M1 computer, how much do I have to pay for extra M1
[01:15:11.280 --> 01:15:12.960]   and two wheels?
[01:15:12.960 --> 01:15:13.600]   Yeah, exactly.
[01:15:13.600 --> 01:15:16.480]   I think, I want a Mac mini.
[01:15:16.480 --> 01:15:17.960]   I want to, and I bet you do too, Alex.
[01:15:17.960 --> 01:15:19.920]   I want a beefed up Mac mini.
[01:15:19.920 --> 01:15:22.920]   The one they're selling is great, but I'd like one with more RAM,
[01:15:22.920 --> 01:15:26.840]   more power, more processors, more connectivity.
[01:15:26.840 --> 01:15:29.000]   Yeah, I mean, I think the way I use Mac minis,
[01:15:29.000 --> 01:15:32.840]   because I use them so much as glue, that they're like, it's fine.
[01:15:32.840 --> 01:15:34.000]   Like it does what it needs to do.
[01:15:34.000 --> 01:15:35.000]   It's really fast.
[01:15:35.000 --> 01:15:37.760]   I put on, I have an eight, I have a whole bunch of the eight gig ones
[01:15:37.760 --> 01:15:41.120]   because we use them for camera controllers for our remote kits.
[01:15:41.120 --> 01:15:44.520]   So I have like, so I put on resolve to see what they would do.
[01:15:44.520 --> 01:15:45.360]   I didn't really expect to.
[01:15:45.360 --> 01:15:47.600]   They're really appliances for you.
[01:15:47.600 --> 01:15:50.400]   Yeah, I mean, we just use them as little, because we use the smaller version
[01:15:50.400 --> 01:15:54.280]   of that as like the B-Link, B-Link, these little PCs that we use that are like tiny,
[01:15:54.280 --> 01:15:56.320]   little boxes.
[01:15:56.320 --> 01:16:00.920]   And so like, we have lots of little glue that we use to tie things together.
[01:16:00.920 --> 01:16:06.920]   And in their space, the M1s are really powerful.
[01:16:06.920 --> 01:16:11.440]   And I think that the difference between 16 and 18, because I don't mean 16,
[01:16:11.440 --> 01:16:16.720]   I'm sorry, eight and 16, for the kind of thing I do doesn't really mean anything to me,
[01:16:16.720 --> 01:16:19.480]   because I'm not really using them for that heavy horsepower.
[01:16:19.480 --> 01:16:26.120]   But I think that I am interested to see if they upgrade those at some point to a 32 gig,
[01:16:26.120 --> 01:16:29.600]   you know, Mac mini, when they release the bigger ones or whatever,
[01:16:29.600 --> 01:16:33.360]   that form factor, as long as it stays in the one you form factor,
[01:16:33.360 --> 01:16:36.960]   you know, or a, you know, because we can put two of those in a rack.
[01:16:36.960 --> 01:16:41.760]   That's kind of what we look at as we take the two Mac minis and they fit into a rack.
[01:16:41.760 --> 01:16:45.480]   They have, and Sonnet makes these enclosures and put them in there and stick it through.
[01:16:45.480 --> 01:16:47.320]   And so those are the kind of things that we worry about.
[01:16:47.320 --> 01:16:53.160]   Here's my speculation on this discontinuation of their $5,000.
[01:16:53.160 --> 01:16:54.320]   That's the starting point.
[01:16:54.320 --> 01:17:00.960]   I'm a pro, which I have again on my desk with a Z on W processor and 64 gigs of ramenalls.
[01:17:00.960 --> 01:17:06.200]   You know, I mean, this thing is a beast is they don't want to sell this and be embarrassed
[01:17:06.200 --> 01:17:10.200]   when the bench wants to come out for the next Mac book.
[01:17:10.200 --> 01:17:12.600]   People are going to say it's 10 times faster.
[01:17:12.600 --> 01:17:15.600]   Even if you're not going to, even if you're not going to like it's there, they're signaling
[01:17:15.600 --> 01:17:17.280]   to everyone that this is what you're going to get.
[01:17:17.280 --> 01:17:20.560]   And if it comes out this fall or whatever, that what they don't want, I mean, they don't
[01:17:20.560 --> 01:17:21.560]   need the money.
[01:17:21.560 --> 01:17:22.560]   I mean, they don't.
[01:17:22.560 --> 01:17:23.560]   I mean, they don't.
[01:17:23.560 --> 01:17:24.560]   They like the money.
[01:17:24.560 --> 01:17:25.560]   They like the money.
[01:17:25.560 --> 01:17:28.440]   I mean, the thing is what I mean, at this point, they're spending most of their money
[01:17:28.440 --> 01:17:30.160]   giving it back to investors.
[01:17:30.160 --> 01:17:36.120]   And so the thing is, is that they, the I'm at sales are such a small part of their, I
[01:17:36.120 --> 01:17:42.040]   mean, it's just a tiny little sliver of income that they can afford to just do it as a, from
[01:17:42.040 --> 01:17:46.800]   a point of view of we don't want people to be upset that they bought something that it,
[01:17:46.800 --> 01:17:50.320]   I think it does signal to us that they think the next I'm at will be considerably faster
[01:17:50.320 --> 01:17:51.880]   than the I'm at pro is today.
[01:17:51.880 --> 01:17:52.880]   Yeah.
[01:17:52.880 --> 01:17:56.600]   And then that's a pretty good signal that they don't want you to keep buying that thinking
[01:17:56.600 --> 01:18:00.040]   it's a pro and spending a ton of money when one's going to come out for $3,000 that is
[01:18:00.040 --> 01:18:03.240]   screaming, I mean, like 10 times faster or five times faster or whatever.
[01:18:03.240 --> 01:18:04.240]   Yeah.
[01:18:04.240 --> 01:18:12.080]   So I mean, according to everywhere that I welcome to the verge, actually, it looks like
[01:18:12.080 --> 01:18:14.080]   max sales in total.
[01:18:14.080 --> 01:18:19.480]   So all max, including laptops were just under 10% of Apple's revenue.
[01:18:19.480 --> 01:18:20.480]   It looks like in 2020.
[01:18:20.480 --> 01:18:21.480]   Wow.
[01:18:21.480 --> 01:18:25.600]   And that was up a lot from the year before.
[01:18:25.600 --> 01:18:30.320]   So well, and also that's the vast majority of those are portable, like the vast majority
[01:18:30.320 --> 01:18:33.440]   of sales are max our laptops.
[01:18:33.440 --> 01:18:34.440]   Yeah.
[01:18:34.440 --> 01:18:35.440]   Okay.
[01:18:35.440 --> 01:18:38.880]   Just trying to get some hopeful news in here.
[01:18:38.880 --> 01:18:42.280]   Bad news, according to the MIT tick.
[01:18:42.280 --> 01:18:44.080]   Where are you laughing?
[01:18:44.080 --> 01:18:45.640]   I want some hopeful news.
[01:18:45.640 --> 01:18:46.760]   I just want some upbeat stuff.
[01:18:46.760 --> 01:18:52.760]   But all I got is stuff like this, according to the MIT technology review, Apple's walled
[01:18:52.760 --> 01:18:55.560]   garden actually is bad for security.
[01:18:55.560 --> 01:18:58.920]   Yes, it makes it hard to get in.
[01:18:58.920 --> 01:19:04.120]   But once you're in, it makes it really hard for security researchers to find out who's
[01:19:04.120 --> 01:19:07.480]   in there and what they're doing.
[01:19:07.480 --> 01:19:16.400]   The lockdown system can backfire because security researchers have no idea what's going
[01:19:16.400 --> 01:19:17.400]   on.
[01:19:17.400 --> 01:19:22.000]   Well, that links really interestingly as well to the, you can call this good news or bad
[01:19:22.000 --> 01:19:27.640]   news, depending on your point of view, the fact that my home GAF in the UK has just opened
[01:19:27.640 --> 01:19:31.440]   up an antitrust probe into the facts.
[01:19:31.440 --> 01:19:37.720]   The app store is a completely closed wall garden and you can't do anything with it,
[01:19:37.720 --> 01:19:40.400]   which is going to be a big thing over here.
[01:19:40.400 --> 01:19:46.880]   The UK has now announced antitrust probes into competition for both Google and Apple
[01:19:46.880 --> 01:19:48.920]   in the last six months now.
[01:19:48.920 --> 01:19:54.320]   So it definitely locks to examine.
[01:19:54.320 --> 01:19:56.880]   There's an interesting two different ways of looking at it.
[01:19:56.880 --> 01:20:01.360]   So as a percentage of all devices sold, I think iPhones were what?
[01:20:01.360 --> 01:20:04.640]   16% of all mobile devices sold last year.
[01:20:04.640 --> 01:20:09.400]   So it's really easy to walk to a competition regulator and say, well, actually, there's
[01:20:09.400 --> 01:20:11.160]   no competition problem here.
[01:20:11.160 --> 01:20:12.160]   We're at 16%.
[01:20:12.160 --> 01:20:13.960]   Hey, you want an open app store.
[01:20:13.960 --> 01:20:16.080]   There's 84% of all the devices in the world.
[01:20:16.080 --> 01:20:18.160]   You can go and have an open app store on.
[01:20:18.160 --> 01:20:22.600]   But of course, they are the app store for 100% of Apple devices.
[01:20:22.600 --> 01:20:23.600]   Right.
[01:20:23.600 --> 01:20:27.280]   So that's just like a bit of a monopoly.
[01:20:27.280 --> 01:20:29.120]   I think that's going to be the United States.
[01:20:29.120 --> 01:20:33.320]   It doesn't have a chance, but in the, you know, it's like it will never go anywhere, but
[01:20:33.320 --> 01:20:36.440]   in the UK and the EU, it might, you know, and because they have a much different set
[01:20:36.440 --> 01:20:41.520]   of rules that are, you know, the United States, if you don't, separating the iPhone from
[01:20:41.520 --> 01:20:44.760]   phones is going to be very hard in the United States.
[01:20:44.760 --> 01:20:46.160]   You know, they look the same.
[01:20:46.160 --> 01:20:48.280]   They largely operate the same.
[01:20:48.280 --> 01:20:54.240]   It's going to be hard to get a octarian to think that they're two different things.
[01:20:54.240 --> 01:20:58.360]   And so, so I think that there's, that's going to be the real challenge in the US, but I
[01:20:58.360 --> 01:21:03.800]   do think that the Apple, and I do think Apple's biggest market risk for the next decade is
[01:21:03.800 --> 01:21:06.280]   antitrust because they're pulling away.
[01:21:06.280 --> 01:21:08.720]   Like they're just pulling away in a stunning fashion.
[01:21:08.720 --> 01:21:13.080]   I mean, if you look at the M1, if you look at the, the, the, while the store is a minority
[01:21:13.080 --> 01:21:19.240]   of the, and this is where people will start pushing back is that the store is a, is a,
[01:21:19.240 --> 01:21:23.520]   a very small minority of all the sales, but it's a huge majority of all the purchases.
[01:21:23.520 --> 01:21:25.800]   You know, like all the money spent is in the store.
[01:21:25.800 --> 01:21:30.080]   And so, so it's, it's, it has a different, you know, impact there.
[01:21:30.080 --> 01:21:35.040]   But in all, in all areas, you know, Apple seems to be running, you know, at all cylinders,
[01:21:35.040 --> 01:21:40.560]   you know, and they have the, they're, they're moving ahead like you would as a startup,
[01:21:40.560 --> 01:21:43.400]   but they have the size of one of the largest companies in the world.
[01:21:43.400 --> 01:21:45.560]   And that's eventually that's going to catch up with them.
[01:21:45.560 --> 01:21:47.560]   You know, like it's going to be a problem.
[01:21:47.560 --> 01:21:48.560]   Of course you got the point.
[01:21:48.560 --> 01:21:53.960]   Yeah, you got to look at the fact that it was a, there is a, as well as the UK antitrust
[01:21:53.960 --> 01:21:59.080]   probe, which kicked off this week, there is an existing EU antitrust probe, which,
[01:21:59.080 --> 01:22:00.080]   kicked off last year.
[01:22:00.080 --> 01:22:04.760]   And you've got to look back at the history of, you know, you, you know, you got to look
[01:22:04.760 --> 01:22:12.280]   at micro, the Microsoft precedent and say, look, how hard was it to say, you know, you,
[01:22:12.280 --> 01:22:18.000]   you can explore, you can install any internet browser on a, on a Microsoft computer, but
[01:22:18.000 --> 01:22:21.680]   the web browser is inextricably linked to the Microsoft experience.
[01:22:21.680 --> 01:22:26.120]   Well, the EU didn't mind sort of ripping that out whenever that was 20 years ago.
[01:22:26.120 --> 01:22:30.760]   So you've got to wonder if the, you know, and that led the, leave the door open for everybody
[01:22:30.760 --> 01:22:31.760]   else to come in.
[01:22:31.760 --> 01:22:34.800]   So you've got to wonder if if we're going to be feeding itself.
[01:22:34.800 --> 01:22:40.720]   Mark, Mark, read the vestige is the chief, she's been the EU's chief enforcer and the
[01:22:40.720 --> 01:22:45.840]   person who's been crafting a lot of the antitrust seats, especially with Google.
[01:22:45.840 --> 01:22:52.720]   And I believe she's already been successful in uncoupling Google and the Google search
[01:22:52.720 --> 01:22:57.080]   engine from Google Chrome by arguing that you can't have those two inextricably linked.
[01:22:57.080 --> 01:23:02.200]   It was, it was a ruling that was very, very similar to arguing that you had to uncouple
[01:23:02.200 --> 01:23:04.400]   internet explorer from Microsoft windows.
[01:23:04.400 --> 01:23:10.040]   So looks like the US is going to be getting its own kind of margarita vestige because
[01:23:10.040 --> 01:23:16.000]   Tim Wu, who is a leading critic of big tech has now been invited to join the National
[01:23:16.000 --> 01:23:21.840]   Economic Council where he will serve as president Biden's special assistant for technology
[01:23:21.840 --> 01:23:23.560]   and competition policy.
[01:23:23.560 --> 01:23:26.640]   Wu's probably pretty well known to many of our audience members.
[01:23:26.640 --> 01:23:27.640]   He wrote the kill switch.
[01:23:27.640 --> 01:23:30.320]   And his last book was The Curse of Bigness.
[01:23:30.320 --> 01:23:33.840]   And he trusts in the new gilded age.
[01:23:33.840 --> 01:23:38.600]   It is widely thought that this is a signal from the White House that they're going to
[01:23:38.600 --> 01:23:42.000]   take antitrust actions very seriously.
[01:23:42.000 --> 01:23:47.600]   Wu has not only been an antitrust advocate, he's actually advocated the breakup of both
[01:23:47.600 --> 01:23:50.000]   Google and Facebook.
[01:23:50.000 --> 01:23:56.800]   So I think if I'm in the headquarters at Google or Facebook or Amazon, I'd be a little bit
[01:23:56.800 --> 01:23:59.600]   nervous about this move.
[01:23:59.600 --> 01:24:01.440]   This has been coming for years though.
[01:24:01.440 --> 01:24:03.840]   Go ahead, Lisa.
[01:24:03.840 --> 01:24:10.600]   Yeah, this has been coming for years though because you've the last 18 months in Congress,
[01:24:10.600 --> 01:24:16.620]   you've had these CEOs repeatedly called up before Congress to explain everything from
[01:24:16.620 --> 01:24:21.980]   how they collect data to what kind of speech they allow on their platforms to.
[01:24:21.980 --> 01:24:24.180]   Are they not concerned?
[01:24:24.180 --> 01:24:27.540]   Are you concerned that you're too big for the market, which no CEO in the right mind
[01:24:27.540 --> 01:24:31.460]   is going to say, yeah, I really do think about that a lot.
[01:24:31.460 --> 01:24:39.540]   And there has been a narrative developing in Washington that has been aided and abetted
[01:24:39.540 --> 01:24:42.380]   by books like Tim Wu's, which is a good book.
[01:24:42.380 --> 01:24:45.980]   I've read the book.
[01:24:45.980 --> 01:24:51.220]   And the narrative that is being shaped is along the lines of we love the tech companies
[01:24:51.220 --> 01:24:55.460]   because they've been the engine of the engines for the US stock markets.
[01:24:55.460 --> 01:24:57.540]   People get rich off the tech companies.
[01:24:57.540 --> 01:25:01.100]   But what have the trade offs been?
[01:25:01.100 --> 01:25:06.420]   And are these tech companies actually making people's lives worse in ways that translate
[01:25:06.420 --> 01:25:08.580]   to their bottom line, to their paycheck?
[01:25:08.580 --> 01:25:13.660]   And there is a growing body of evidence.
[01:25:13.660 --> 01:25:19.900]   This is, yes, these tech companies do act in ways that can significantly affect how people
[01:25:19.900 --> 01:25:21.540]   make money.
[01:25:21.540 --> 01:25:24.260]   And you're going to have enough Congress people who are like, yes, this is a populist cause.
[01:25:24.260 --> 01:25:25.980]   Let's go for it.
[01:25:25.980 --> 01:25:27.940]   I think that for Facebook and Google, it's more challenging.
[01:25:27.940 --> 01:25:31.540]   I think that it's more challenging for Facebook and Google for Apple.
[01:25:31.540 --> 01:25:35.100]   I think the problem is that Apple now is essentially pushing money back to its shareholders.
[01:25:35.100 --> 01:25:38.780]   And those shareholders are not just Warren Buffett.
[01:25:38.780 --> 01:25:41.260]   These are a lot of members of Congress probably.
[01:25:41.260 --> 01:25:42.820]   Well, it ought to like that.
[01:25:42.820 --> 01:25:47.500]   Well, it's an awful lot of my uncle-in-law has, I don't know how many shares of Apple
[01:25:47.500 --> 01:25:49.140]   that you bought in the late '90s.
[01:25:49.140 --> 01:25:51.140]   Oh, that's everybody's 401Ks.
[01:25:51.140 --> 01:25:52.140]   Yeah.
[01:25:52.140 --> 01:25:59.220]   And they're 401Ks and all the Apple employees that are in the stock distribution.
[01:25:59.220 --> 01:26:02.180]   And there's millions and millions of people that are affected by that.
[01:26:02.180 --> 01:26:07.620]   And if things start to become something more tense, because Apple is literally putting,
[01:26:07.620 --> 01:26:14.180]   it's not that, it's not that, oh, you're riding that stock, Apple is actively giving out dividends.
[01:26:14.180 --> 01:26:18.300]   And I mean, hundreds of billions of dollars back to their shareholders.
[01:26:18.300 --> 01:26:22.460]   So they really, more than probably any company in the history of the world, represent their
[01:26:22.460 --> 01:26:23.460]   stockholders.
[01:26:23.460 --> 01:26:28.500]   They're pushing money out away because they already have enough cash.
[01:26:28.500 --> 01:26:33.700]   And so that's a big reason that a company does that is employee retention.
[01:26:33.700 --> 01:26:34.700]   You've got to keep that stock.
[01:26:34.700 --> 01:26:35.700]   Sure.
[01:26:35.700 --> 01:26:36.700]   You increase the value of your stock.
[01:26:36.700 --> 01:26:37.700]   Yeah.
[01:26:37.700 --> 01:26:40.620]   Because you're buying it back, it increases the value of each share.
[01:26:40.620 --> 01:26:42.100]   So it's going to be tricky.
[01:26:42.100 --> 01:26:44.700]   I mean, it may seem like a popular thing until they start doing it.
[01:26:44.700 --> 01:26:47.300]   And then I think there's going to be a lot of people that are sending emails.
[01:26:47.300 --> 01:26:49.940]   I think Facebook is going to be your sacrificial lamb.
[01:26:49.940 --> 01:26:50.940]   Yeah.
[01:26:50.940 --> 01:27:03.060]   It's going to be super easy to set up Facebook as a company that's being run for the 1% or
[01:27:03.060 --> 01:27:07.940]   a company that's not being held accountable or a company that goes against American values.
[01:27:07.940 --> 01:27:13.740]   And to make the case that when you have Facebook and Instagram, that will constitute some sort
[01:27:13.740 --> 01:27:16.780]   of social media ecosystem that has to be broken down.
[01:27:16.780 --> 01:27:18.500]   You see you're exactly right.
[01:27:18.500 --> 01:27:23.940]   Lisa, you're exactly right because the reason Facebook looks like the easiest sacrificial
[01:27:23.940 --> 01:27:27.740]   lamb is because it's literally the easiest to break up.
[01:27:27.740 --> 01:27:30.780]   Like if you look at Apple, you go, well, what am I going to take?
[01:27:30.780 --> 01:27:35.860]   Am I going to stop them selling iPhones and computers or am I going to sell them selling
[01:27:35.860 --> 01:27:37.140]   apps on the phone?
[01:27:37.140 --> 01:27:41.980]   If you look at Google, you go, OK, well, maybe I can try and make Chrome not the default thing.
[01:27:41.980 --> 01:27:46.140]   But actually, if you stop Chrome, if you stop Google search being the default, you kill
[01:27:46.140 --> 01:27:50.740]   Firefox and then that kills competition in that market.
[01:27:50.740 --> 01:27:54.780]   Whereas actually if you look at Facebook, you just go, oh, Facebook is Facebook, Instagram
[01:27:54.780 --> 01:27:55.780]   and WhatsApp.
[01:27:55.780 --> 01:27:57.740]   Oh, let's just make, they were three companies.
[01:27:57.740 --> 01:27:59.100]   Let's just make them three companies again.
[01:27:59.100 --> 01:28:00.100]   So it can't be.
[01:28:00.100 --> 01:28:03.060]   It looks like a really easy way to break up something enormous.
[01:28:03.060 --> 01:28:04.060]   Yeah.
[01:28:04.060 --> 01:28:07.580]   I mean, the thing I'd like to see them try in all honesty is Amazon.
[01:28:07.580 --> 01:28:08.580]   Yeah.
[01:28:08.580 --> 01:28:10.980]   Well, so here's an interesting data point.
[01:28:10.980 --> 01:28:15.860]   Wu was in the Obama administration in the antitrust era.
[01:28:15.860 --> 01:28:23.340]   And he says perhaps we were too lenient on these big companies, which means he has a
[01:28:23.340 --> 01:28:25.300]   he wants to do over now.
[01:28:25.300 --> 01:28:30.700]   And maybe they shouldn't have been so welcoming of these mergers.
[01:28:30.700 --> 01:28:36.980]   I do feel with you, at least that Amazon is perhaps the one you most want to break up.
[01:28:36.980 --> 01:28:41.060]   But I think it's a lot harder because so many of us are fans, right?
[01:28:41.060 --> 01:28:43.460]   We use it nonstop, maybe not fans.
[01:28:43.460 --> 01:28:45.380]   Biden, it was interesting.
[01:28:45.380 --> 01:28:52.660]   I thought actually encourage the unionization efforts in Alabama for Facebook.
[01:28:52.660 --> 01:28:53.660]   Or Amazon.
[01:28:53.660 --> 01:28:59.060]   The thing I find interesting about Amazon is Amazon Web Services is the economic engine
[01:28:59.060 --> 01:29:00.260]   for that company.
[01:29:00.260 --> 01:29:01.260]   Yeah.
[01:29:01.260 --> 01:29:02.700]   And everything runs on it.
[01:29:02.700 --> 01:29:03.700]   Go ahead and try it.
[01:29:03.700 --> 01:29:05.180]   It's the economic engine for everybody.
[01:29:05.180 --> 01:29:06.180]   For the work.
[01:29:06.180 --> 01:29:07.180]   Exactly.
[01:29:07.180 --> 01:29:11.620]   I mean, it's clearly it has such a first first market advantage in the clouds.
[01:29:11.620 --> 01:29:12.860]   I was compiling a data.
[01:29:12.860 --> 01:29:19.620]   I was trying to compile a table recently to gauge the relative economic impact and customer
[01:29:19.620 --> 01:29:23.460]   base for the major cloud services providers in the US.
[01:29:23.460 --> 01:29:27.460]   And Amazon is just so far ahead of everybody else because they were first and they defined
[01:29:27.460 --> 01:29:28.460]   the market.
[01:29:28.460 --> 01:29:30.140]   You think that's why Bezos left.
[01:29:30.140 --> 01:29:34.100]   He wanted to get out before the stuff gets the fan.
[01:29:34.100 --> 01:29:38.500]   Before somebody has to start thinking about, okay, how do I maintain this crazy growth?
[01:29:38.500 --> 01:29:42.340]   And how do I make sure that my company doesn't get split up into a retail arm?
[01:29:42.340 --> 01:29:45.460]   The new CEO is the former CEO of AWS.
[01:29:45.460 --> 01:29:47.140]   So maybe this is the guy who knows.
[01:29:47.140 --> 01:29:48.140]   Yeah.
[01:29:48.140 --> 01:29:51.260]   I think there's a really interesting argument around Amazon's.
[01:29:51.260 --> 01:29:53.660]   I mean, there's a couple of really interesting arguments around Amazon.
[01:29:53.660 --> 01:29:58.620]   One is Amazon could be the only company that increased in market value if you split it
[01:29:58.620 --> 01:29:59.620]   up.
[01:29:59.620 --> 01:30:08.060]   So if you took AWS out of Amazon as a business, it would be one of the top 10 NASDAQ companies
[01:30:08.060 --> 01:30:09.060]   on its own.
[01:30:09.060 --> 01:30:14.380]   And you go, actually, that could be a situation where like one plus one actually equals three
[01:30:14.380 --> 01:30:18.700]   because I've suddenly got two mega growth businesses rather than one that's kind of being hidden
[01:30:18.700 --> 01:30:20.220]   within another.
[01:30:20.220 --> 01:30:26.340]   And then I think if you look at the case for Amazon antitrust in general, you've got two
[01:30:26.340 --> 01:30:30.060]   different ways of back to the framing question we came back to earlier, right?
[01:30:30.060 --> 01:30:31.060]   Which is it?
[01:30:31.060 --> 01:30:37.380]   So Amazon has about 40% of e-commerce, which obviously looks enormous, but about 10% of
[01:30:37.380 --> 01:30:44.140]   retail compared to Walmart, Costco, any other retailer in Britain, globally.
[01:30:44.140 --> 01:30:45.820]   So it's a case of like, well, which is it?
[01:30:45.820 --> 01:30:49.140]   Is it a 40% player or is it a 10% player?
[01:30:49.140 --> 01:30:54.300]   And then you go, well, actually, it owns something like 85% of book sales.
[01:30:54.300 --> 01:30:59.380]   You go, well, do I stop Amazon selling books, but let it sell everything else like fashion
[01:30:59.380 --> 01:31:02.900]   where it's got almost no foot old whatsoever.
[01:31:02.900 --> 01:31:09.540]   So where you would Amazon can clearly be split into a retail and non retail business, but
[01:31:09.540 --> 01:31:15.700]   how you regulate the retail part of the business looks really interesting given the way that
[01:31:15.700 --> 01:31:19.300]   you frame it, it can be either enormous or tiny.
[01:31:19.300 --> 01:31:22.540]   And depending on what sector you're looking at, it's got completely different shares across
[01:31:22.540 --> 01:31:23.900]   all these different things.
[01:31:23.900 --> 01:31:28.180]   Well, and also, we have to also acknowledge that some of the efficiencies that we have
[01:31:28.180 --> 01:31:33.140]   and some of what we have here is because of the size, because of the efficiencies that
[01:31:33.140 --> 01:31:36.700]   are there in these large companies, they are going to get to a point where we need to do
[01:31:36.700 --> 01:31:37.780]   something about it.
[01:31:37.780 --> 01:31:41.820]   And so we're trying to figure that out, but we also have to get that part of what makes
[01:31:41.820 --> 01:31:46.020]   this work is that there aren't a thousand players doing it a thousand different ways.
[01:31:46.020 --> 01:31:52.780]   When we, like the breakup of the bells didn't really help us very much, it seemed like it
[01:31:52.780 --> 01:31:53.780]   would.
[01:31:53.780 --> 01:31:55.220]   They just created chaos at a certain time.
[01:31:55.220 --> 01:31:57.340]   And now it's just AT&T and Verizon.
[01:31:57.340 --> 01:32:01.620]   All the baby bells are back into two big companies that are actually bigger as a group than they
[01:32:01.620 --> 01:32:02.780]   were before.
[01:32:02.780 --> 01:32:10.100]   And their success in that area has basically slowed down, retarded the entire growth of
[01:32:10.100 --> 01:32:15.900]   broadband and wireless and everything else has actually damaged in a lot of ways.
[01:32:15.900 --> 01:32:20.700]   And it's unclear that it would have happened in the same way had they been kind of a big
[01:32:20.700 --> 01:32:23.260]   oh, kind of continuing to move through the 80s.
[01:32:23.260 --> 01:32:26.020]   I'm sure Tim Wu would have something to say about that because that's a lot of what the
[01:32:26.020 --> 01:32:29.020]   kill switch was about.
[01:32:29.020 --> 01:32:34.940]   And I would bet he thinks that the breakup of the baby bills was positive, but I don't,
[01:32:34.940 --> 01:32:35.940]   but I'd like to hear those.
[01:32:35.940 --> 01:32:38.580]   There are big companies and they're doing a lot of obstruction.
[01:32:38.580 --> 01:32:42.500]   I mean, the reason that we have such bad internet in the United States because of those two
[01:32:42.500 --> 01:32:44.380]   companies, you know, like let's be clear.
[01:32:44.380 --> 01:32:47.980]   Well, throw in Comcast and it's like pole access is the thing.
[01:32:47.980 --> 01:32:53.220]   Like, you know, and, and so that's the, that's the part that we, you know, just just getting
[01:32:53.220 --> 01:32:54.220]   pole access and we will.
[01:32:54.220 --> 01:33:00.020]   Oh, as it turns out, Wu has an entire section in his book, The Curse of Bigness on the baby
[01:33:00.020 --> 01:33:01.020]   bell.
[01:33:01.020 --> 01:33:03.460]   Oh, and do you remember what his take was on that?
[01:33:03.460 --> 01:33:06.380]   I've just, I'll tell you what, let me take a break.
[01:33:06.380 --> 01:33:12.260]   You can, you can find that book and read us the salient passages.
[01:33:12.260 --> 01:33:13.260]   Yes, please.
[01:33:13.260 --> 01:33:16.700]   As Lisa Schmeiser, she is now senior editor at ITPro today.
[01:33:16.700 --> 01:33:18.180]   Great to have you.
[01:33:18.180 --> 01:33:21.500]   Lisa Will Harris, his new company is entail.
[01:33:21.500 --> 01:33:28.260]   It's a new podcast player with a very clever hook at ENTLE.com.
[01:33:28.260 --> 01:33:35.980]   And of course, from office hours and 090 media, Alex Lindsey.
[01:33:35.980 --> 01:33:40.500]   It's interesting that at least two of the four sponsors in the show today are security
[01:33:40.500 --> 01:33:41.500]   companies.
[01:33:41.500 --> 01:33:45.220]   I want to talk a little bit about Barracuda.
[01:33:45.220 --> 01:33:49.260]   That's a name everybody knows for enterprise security.
[01:33:49.260 --> 01:33:50.460]   Hackers are always looking.
[01:33:50.460 --> 01:33:54.460]   We were just talking about this for the weakest link in your security configuration.
[01:33:54.460 --> 01:33:57.660]   And often that turns out to be your email security.
[01:33:57.660 --> 01:33:58.660]   You know, it's funny.
[01:33:58.660 --> 01:34:03.780]   I've been talking about this for months, then all of a sudden here's this zero day in,
[01:34:03.780 --> 01:34:07.340]   in Outlook Web Access.
[01:34:07.340 --> 01:34:08.340]   Here's the thing.
[01:34:08.340 --> 01:34:11.740]   If you can find those vulnerabilities, you can defend against cyber attacks.
[01:34:11.740 --> 01:34:17.180]   That's why Barracuda has created a new tool they call the threat analyzer tool.
[01:34:17.180 --> 01:34:22.420]   From traditional malware to the latest spearfishing account takeover and conversation hijacking,
[01:34:22.420 --> 01:34:29.220]   Barracuda has identified 13 types of email threats.
[01:34:29.220 --> 01:34:32.740]   And by the way, any one of them can take you down.
[01:34:32.740 --> 01:34:36.380]   It takes several different layers of security working together to protect you effectively
[01:34:36.380 --> 01:34:40.900]   against all 13 threat types.
[01:34:40.900 --> 01:34:47.060]   And if there's even one gap, the crooks are going to find out where you're vulnerable.
[01:34:47.060 --> 01:34:50.100]   It's literally what they spend their entire day on.
[01:34:50.100 --> 01:34:51.740]   And some of them nights too.
[01:34:51.740 --> 01:34:54.700]   When they find that gap in your security, they just need to choose the right type of
[01:34:54.700 --> 01:34:59.860]   threat, customize it, get it into your system, and cost you millions of dollars, your reputation
[01:34:59.860 --> 01:35:01.420]   in the market.
[01:35:01.420 --> 01:35:04.740]   Here's where it gets hard, with hundreds of highly targeted personalized threat variants
[01:35:04.740 --> 01:35:09.780]   emerging daily, including those zero days we saw this week, and many different kinds
[01:35:09.780 --> 01:35:13.860]   of on-prem and cloud-based email systems, they can be really challenging to identify
[01:35:13.860 --> 01:35:16.620]   your specific gaps or vulnerabilities.
[01:35:16.620 --> 01:35:20.860]   Don't just look over there and say, "Oh, those exchange guys, wow, I'm glad that it
[01:35:20.860 --> 01:35:22.060]   didn't happen to me."
[01:35:22.060 --> 01:35:23.540]   You're next.
[01:35:23.540 --> 01:35:25.860]   That's why you need the Barracuda threat analyzer.
[01:35:25.860 --> 01:35:33.740]   It's incredibly simple and fast to use.
[01:35:33.740 --> 01:35:36.420]   If you go to Barracuda, B-A-R-R-A, C-U-D-A, Barracuda.com/twit, you'll answer a few simple multi-choice questions
[01:35:36.420 --> 01:35:38.220]   about your email security setup.
[01:35:38.220 --> 01:35:40.260]   It'll only take a couple of minutes.
[01:35:40.260 --> 01:35:43.900]   Barracuda's threat analyzer tool will provide a customer report telling you what threat
[01:35:43.900 --> 01:35:45.300]   types you're most vulnerable to.
[01:35:45.300 --> 01:35:49.380]   And I guarantee you, it's been updated in the last couple of days.
[01:35:49.380 --> 01:35:53.820]   You'll get custom recommendations on how to strengthen your defenses against those attacks.
[01:35:53.820 --> 01:35:54.820]   It's free.
[01:35:54.820 --> 01:35:59.180]   So, I think you really want to check this out.
[01:35:59.180 --> 01:36:02.820]   Turns out, and this is from a December's Barracuda spearfishing report.
[01:36:02.820 --> 01:36:06.460]   12% of all spearfishing attacks are business email compromised.
[01:36:06.460 --> 01:36:09.180]   And that's going up dramatically.
[01:36:09.180 --> 01:36:11.760]   That's almost doubled since 2019.
[01:36:11.760 --> 01:36:13.580]   That shows you these attacks work.
[01:36:13.580 --> 01:36:16.660]   That's why they're being more and more happening.
[01:36:16.660 --> 01:36:22.260]   According to the FBI's most recent internet crime report, business email compromise led
[01:36:22.260 --> 01:36:26.140]   to over $3.5 billion in losses last year.
[01:36:26.140 --> 01:36:30.580]   As an example, government of Puerto Rico lost $2.6 million in a single attack.
[01:36:30.580 --> 01:36:34.220]   You might remember Shark Tank's Barbara Corcoran.
[01:36:34.220 --> 01:36:36.420]   This is a really common attack.
[01:36:36.420 --> 01:36:39.340]   Her employees fell for an impersonation attack.
[01:36:39.340 --> 01:36:46.400]   They got a fake invoice and paid it wiring a $400,000 out to the bad guys.
[01:36:46.400 --> 01:36:47.660]   They realized what they'd done in time.
[01:36:47.660 --> 01:36:48.660]   They got the money back.
[01:36:48.660 --> 01:36:53.740]   I wish I could say the same for a school district in Texas, which made fraudulent payments over
[01:36:53.740 --> 01:36:58.580]   a period of weeks losing $2.3 million before the attack was discovered.
[01:36:58.580 --> 01:37:01.460]   Money they'll never get back.
[01:37:01.460 --> 01:37:02.620]   Don't let this happen to you.
[01:37:02.620 --> 01:37:06.740]   If your email security is not protecting you, you're vulnerable.
[01:37:06.740 --> 01:37:09.140]   And I bet you there are areas you're vulnerable.
[01:37:09.140 --> 01:37:10.140]   You need this.
[01:37:10.140 --> 01:37:11.140]   Try it.
[01:37:11.140 --> 01:37:12.140]   Barracuda threat analyzer.
[01:37:12.140 --> 01:37:13.140]   Get a full report.
[01:37:13.140 --> 01:37:14.140]   It's free.
[01:37:14.140 --> 01:37:16.980]   It'll show you exactly what you need to do to secure your email.
[01:37:16.980 --> 01:37:20.820]   Get us new threat analyzer at barracuda.com/twit.
[01:37:20.820 --> 01:37:24.020]   Barracuda.com/twit.
[01:37:24.020 --> 01:37:27.940]   We thank you so much for their support of Twit.
[01:37:27.940 --> 01:37:29.740]   We had a fun week on This Week in Tech.
[01:37:29.740 --> 01:37:31.500]   Talked about NFTs and a lot more.
[01:37:31.500 --> 01:37:32.500]   Watch.
[01:37:32.500 --> 01:37:34.340]   We got a little video for you.
[01:37:34.340 --> 01:37:35.340]   Solar wins.
[01:37:35.340 --> 01:37:39.340]   It's going to be a while before we really get some giving.
[01:37:39.340 --> 01:37:51.020]   It may have all started when an intern set an important password to SolarWinds123, adding
[01:37:51.020 --> 01:37:52.820]   insult to an injury.
[01:37:52.820 --> 01:37:56.820]   The intern posted it on GitHub.
[01:37:56.820 --> 01:38:00.140]   I love it.
[01:38:00.140 --> 01:38:03.140]   Previously on Twit.
[01:38:03.140 --> 01:38:04.140]   Twit news.
[01:38:04.140 --> 01:38:05.140]   Hello, everybody.
[01:38:05.140 --> 01:38:12.540]   SolarPort here, the very first Twit news live event of 2021 and it's Microsoft Ignite
[01:38:12.540 --> 01:38:14.260]   keynote.
[01:38:14.260 --> 01:38:16.020]   Tech News Weekly.
[01:38:16.020 --> 01:38:22.420]   You may have seen or heard something about NFT, those three letters together.
[01:38:22.420 --> 01:38:28.820]   What if digital art could have intrinsic value because it's considered one of a kind or
[01:38:28.820 --> 01:38:31.420]   one of five and that's it.
[01:38:31.420 --> 01:38:34.220]   So it becomes rare.
[01:38:34.220 --> 01:38:35.860]   This week in Google.
[01:38:35.860 --> 01:38:42.820]   The Techast is a summary of the past few years where we have this really strong and
[01:38:42.820 --> 01:38:49.180]   widespread negative reaction to the growing power and influence of Big Tech specifically
[01:38:49.180 --> 01:38:51.820]   the large companies here in Silicon Valley.
[01:38:51.820 --> 01:38:52.820]   Twit.
[01:38:52.820 --> 01:38:56.900]   It's where your brain and tech meet.
[01:38:56.900 --> 01:38:58.540]   And then sometimes collide.
[01:38:58.540 --> 01:39:03.220]   I hope you've enjoyed this week and I hope you will be with us next week.
[01:39:03.220 --> 01:39:04.980]   We've got a lot of great shows planned.
[01:39:04.980 --> 01:39:09.180]   Okay, we gave you as much time as we could Lisa Schmeiser to look up.
[01:39:09.180 --> 01:39:13.660]   What does Tim will think of the breakup of the baby bells?
[01:39:13.660 --> 01:39:14.980]   It's part of a larger passage.
[01:39:14.980 --> 01:39:18.660]   He writes about what he calls the age of oligopoly.
[01:39:18.660 --> 01:39:19.660]   Oligopoly.
[01:39:19.660 --> 01:39:20.660]   Yeah.
[01:39:20.660 --> 01:39:24.660]   You know, that flows so much more smoothly on my mental narrative in supposed to the actual
[01:39:24.660 --> 01:39:25.660]   physical one.
[01:39:25.660 --> 01:39:32.740]   But he notes that a full 75% of industries witnessed increased concentration from the
[01:39:32.740 --> 01:39:36.460]   years 1997 to 2012.
[01:39:36.460 --> 01:39:40.740]   And that's the way he says work, right?
[01:39:40.740 --> 01:39:46.100]   This is apparently the highest number of consolidations since the original trust era.
[01:39:46.100 --> 01:39:48.740]   So we're back in that kind of golden age.
[01:39:48.740 --> 01:39:50.220]   We're back to the guess.
[01:39:50.220 --> 01:39:55.340]   This is why he used the words Gilded Age in the book title, I would guess.
[01:39:55.340 --> 01:39:59.900]   And he points out the AT&T monopoly had been forced to divide into eight pieces and was
[01:39:59.900 --> 01:40:05.140]   allowed over the 2000s to reconstitute itself into Verizon and AT&T.
[01:40:05.140 --> 01:40:09.500]   Later AT&T bought direct TV and then time Warner to return close to the size it was
[01:40:09.500 --> 01:40:11.060]   in the 1980s.
[01:40:11.060 --> 01:40:15.580]   And then he adds the idea of allowing AT&T to come back in such a fashion was shocking
[01:40:15.580 --> 01:40:18.900]   to those who thought the breakup was important to competition.
[01:40:18.900 --> 01:40:23.100]   So the failure was not the breakup, but the failure was to allow them to re-align the
[01:40:23.100 --> 01:40:24.100]   constitute.
[01:40:24.100 --> 01:40:29.300]   And I have to say, there's a whole lit day by pointing out that many of these combinations
[01:40:29.300 --> 01:40:31.740]   actually happened during the Obama administration.
[01:40:31.740 --> 01:40:32.740]   That's right.
[01:40:32.740 --> 01:40:35.860]   And he was in office and he was there.
[01:40:35.860 --> 01:40:39.700]   And I wonder if he's going to try to fix it this time around.
[01:40:39.700 --> 01:40:46.860]   I mean, the thing that bothers me the most is the giant mergers between content companies
[01:40:46.860 --> 01:40:51.300]   and delivery companies where Comcast owns NBC, Universal.
[01:40:51.300 --> 01:40:56.860]   It's really pretty much every news organization is owned by a big organization that is a delivery
[01:40:56.860 --> 01:40:57.860]   company.
[01:40:57.860 --> 01:41:02.020]   And for me, is the worst kind of monopoly.
[01:41:02.020 --> 01:41:05.820]   And I think we're seeing it and I think we're seeing the results of it, frankly.
[01:41:05.820 --> 01:41:07.860]   It's not very good.
[01:41:07.860 --> 01:41:09.860]   Can we talk about Ignite, Lisa?
[01:41:09.860 --> 01:41:10.860]   Sure, sure.
[01:41:10.860 --> 01:41:12.100]   What would you like to talk about?
[01:41:12.100 --> 01:41:13.900]   Alex Kippman.
[01:41:13.900 --> 01:41:18.820]   And Guy La Libriarte.
[01:41:18.820 --> 01:41:27.180]   And this was the end of the Ignite keynote where they showed what life in the mesh is
[01:41:27.180 --> 01:41:29.220]   going to look like.
[01:41:29.220 --> 01:41:33.860]   And by the way, they ended the keynote with this.
[01:41:33.860 --> 01:41:37.340]   Those people who are making popping sounds and are having hearts coming out of the head
[01:41:37.340 --> 01:41:40.260]   are actually in the audience.
[01:41:40.260 --> 01:41:45.620]   This unfortunately was the part of Ignite the public saw.
[01:41:45.620 --> 01:41:55.220]   And I think the reaction of the public to this weird burning man was, huh?
[01:41:55.220 --> 01:42:00.180]   Is this really, did Microsoft make a mistake here?
[01:42:00.180 --> 01:42:03.980]   This is literally how they ended.
[01:42:03.980 --> 01:42:06.060]   Such in the Dell of the CEO began this keynote.
[01:42:06.060 --> 01:42:10.540]   Alex Kippman, the inventor of HoloLens, he invented Connector before it or developed Connect
[01:42:10.540 --> 01:42:15.740]   before it, showing what the future of Microsoft mesh was.
[01:42:15.740 --> 01:42:18.780]   HoloLens getting together in virtual world.
[01:42:18.780 --> 01:42:26.460]   If you get a headache from Zoom, wait till you go there with no arms and no legs dancing
[01:42:26.460 --> 01:42:27.700]   around a digital fire.
[01:42:27.700 --> 01:42:29.500]   I don't know.
[01:42:29.500 --> 01:42:32.500]   Maybe it's just so I feel like the demo is dumb.
[01:42:32.500 --> 01:42:36.220]   Defend you're going to defend the technology.
[01:42:36.220 --> 01:42:37.980]   I'm going to defend the technology.
[01:42:37.980 --> 01:42:40.220]   And I think I've talked about this before on your show.
[01:42:40.220 --> 01:42:44.700]   I've been fortunate enough to do some HoloLens demos.
[01:42:44.700 --> 01:42:55.980]   And the thing that struck me was how it's going to, it's going to, it's just, I had,
[01:42:55.980 --> 01:43:00.540]   Leo, I had to hide it because all I could do, I kept flashing about to like 1995 virtual
[01:43:00.540 --> 01:43:02.700]   environments when I was, it's a research.
[01:43:02.700 --> 01:43:03.700]   It is a full second city-ish.
[01:43:03.700 --> 01:43:05.700]   It's second city meets burning man.
[01:43:05.700 --> 01:43:06.700]   I'm just like, second life.
[01:43:06.700 --> 01:43:07.700]   No, I second life.
[01:43:07.700 --> 01:43:08.700]   Second life.
[01:43:08.700 --> 01:43:09.700]   Second life.
[01:43:09.700 --> 01:43:10.700]   Second city would be amazing.
[01:43:10.700 --> 01:43:11.700]   No, that would be incredible.
[01:43:11.700 --> 01:43:17.140]   Because you'd have like improv, which is what this demo clearly needs.
[01:43:17.140 --> 01:43:21.060]   But the thing that's great, the thing that I find really interesting about HoloLens is
[01:43:21.060 --> 01:43:25.020]   it's really going to enhance edge computing.
[01:43:25.020 --> 01:43:29.780]   And it's going to get Microsoft into places where desktop computing and networks don't
[01:43:29.780 --> 01:43:32.020]   necessarily go.
[01:43:32.020 --> 01:43:37.460]   And the reason I think this is a dumb demo is because you could do something so much
[01:43:37.460 --> 01:43:43.100]   cooler like have somebody at the bottom of a lake being given instructions on how to
[01:43:43.100 --> 01:43:46.540]   disassemble something that's down there simply by using that.
[01:43:46.540 --> 01:43:51.740]   And to be fair, they showed a lot of that and other night sessions and even in the Nadella's
[01:43:51.740 --> 01:43:53.220]   keynote and so forth.
[01:43:53.220 --> 01:43:57.020]   I think it was maybe a strategic error to highlight the-
[01:43:57.020 --> 01:43:59.820]   Like I think it's in my grip.
[01:43:59.820 --> 01:44:01.420]   There's so many better ways.
[01:44:01.420 --> 01:44:02.420]   Sorry, he says.
[01:44:02.420 --> 01:44:03.420]   No, no, it's okay.
[01:44:03.420 --> 01:44:04.420]   Go ahead.
[01:44:04.420 --> 01:44:10.300]   I was going to say there are just so many better ways of doing virtual environments.
[01:44:10.300 --> 01:44:15.940]   If the point is to show that during this, we can all be remotely connected.
[01:44:15.940 --> 01:44:20.780]   I have a pretty regular pop-up golf VR, VR static with time.
[01:44:20.780 --> 01:44:21.780]   Do you really?
[01:44:21.780 --> 01:44:22.780]   My friend.
[01:44:22.780 --> 01:44:27.500]   And that is, we hang out and we keep the sh*t from here and we play a little bit of golf
[01:44:27.500 --> 01:44:29.460]   in Oculus.
[01:44:29.460 --> 01:44:33.580]   And it's like a lot less weird than whatever that was.
[01:44:33.580 --> 01:44:36.380]   And I'm pretty sure that technology is a lot cooler.
[01:44:36.380 --> 01:44:39.260]   So it seems like they just made the worst of all worlds.
[01:44:39.260 --> 01:44:41.100]   They're purely from a consumer point of view.
[01:44:41.100 --> 01:44:44.940]   Please, I'm sure it has some very good stuff behind it.
[01:44:44.940 --> 01:44:49.940]   The HoloLens technology itself is stunningly good.
[01:44:49.940 --> 01:44:50.940]   Is it really?
[01:44:50.940 --> 01:44:51.940]   Yeah, it is.
[01:44:51.940 --> 01:44:53.100]   Okay, I'll take that.
[01:44:53.100 --> 01:44:54.380]   I'll take that for that.
[01:44:54.380 --> 01:45:00.420]   You know, it is like, I've seen a lot of it applied to stuff like, you know, AEC and other
[01:45:00.420 --> 01:45:05.700]   things that are much more driven by need and play people that are willing to put those
[01:45:05.700 --> 01:45:07.900]   goggles on and everything else.
[01:45:07.900 --> 01:45:11.500]   And when you see it working, it's just kind of amazing.
[01:45:11.500 --> 01:45:13.020]   It's the best one out there right now.
[01:45:13.020 --> 01:45:15.020]   Do you imagine the things you're doing?
[01:45:15.020 --> 01:45:20.660]   You do right now in Zoom being kind of a merge, become more of these virtual meeting
[01:45:20.660 --> 01:45:21.660]   things that they're--
[01:45:21.660 --> 01:45:24.140]   Maybe, I think someday, but not that.
[01:45:24.140 --> 01:45:29.500]   The problem is that, is that, like one of the problems with the standards, the talk of
[01:45:29.500 --> 01:45:33.820]   the Stanford article for a second to tie it back into that, they were talking about,
[01:45:33.820 --> 01:45:37.940]   they're referring back to old studies that they've done where they said, "Okay, well,
[01:45:37.940 --> 01:45:39.900]   we put avatars and people looked at the avatars."
[01:45:39.900 --> 01:45:43.260]   And as soon as they said that, I stopped reading like that part, because I was like,
[01:45:43.260 --> 01:45:44.700]   avatars don't mean anything.
[01:45:44.700 --> 01:45:49.060]   Because the reason is, is that there is so much going on, if you look at, if you want
[01:45:49.060 --> 01:45:54.740]   to kind of get an idea of how far away we are with all the money we have when you look
[01:45:54.740 --> 01:46:03.820]   at the digital doubles inside of some of the Star Wars sequels, where they have the general
[01:46:03.820 --> 01:46:09.380]   or the even Princess Leia, they are so close.
[01:46:09.380 --> 01:46:10.940]   And still, it's like, "Oh, that's weird."
[01:46:10.940 --> 01:46:12.260]   They're still like in any valley.
[01:46:12.260 --> 01:46:13.260]   They're really--
[01:46:13.260 --> 01:46:17.460]   Well, but the thing is, is that, but that is with incredible amounts of resources and
[01:46:17.460 --> 01:46:21.060]   all the time in the world to render and getting to look at it over and over again, doing that
[01:46:21.060 --> 01:46:23.020]   live, we'll see.
[01:46:23.020 --> 01:46:28.100]   I mean, and again, it is like the unreal work that's being done right now with Metahumans
[01:46:28.100 --> 01:46:30.460]   is amazing.
[01:46:30.460 --> 01:46:35.820]   But I don't want to have an avatar of me trying to be like that, because I know that
[01:46:35.820 --> 01:46:41.340]   submillimeter movement in my eyes makes a difference to the person on the other side.
[01:46:41.340 --> 01:46:47.340]   And that's why a lot of these kind of second life things don't work as well as just video
[01:46:47.340 --> 01:46:54.220]   for the time being, because it's just every little thing that we do with our face.
[01:46:54.220 --> 01:46:58.460]   We spend our entire life looking at other people's faces and making decisions by little
[01:46:58.460 --> 01:47:01.900]   things they did with their eyebrows and the way that they did it and again, how often
[01:47:01.900 --> 01:47:02.900]   they blinked.
[01:47:02.900 --> 01:47:06.540]   And just when I squeeze my eyes just a little bit, that means something.
[01:47:06.540 --> 01:47:11.780]   And so that, when we dumb that down, yeah, it's a dehumanizing experience.
[01:47:11.780 --> 01:47:16.660]   And it's going to be until we crush it and we are not going to crush it for another
[01:47:16.660 --> 01:47:17.660]   decade at least.
[01:47:17.660 --> 01:47:21.980]   We're not going to get to that point where there'll be outliers that go, "Okay, this
[01:47:21.980 --> 01:47:22.980]   is really cool."
[01:47:22.980 --> 01:47:27.060]   So people are still using second life and there's a coolness to it.
[01:47:27.060 --> 01:47:28.980]   There is, but I agree.
[01:47:28.980 --> 01:47:34.500]   But it's going to be hard to overcome authentic communication to people that we can see.
[01:47:34.500 --> 01:47:40.900]   So I think that especially what we see in our office hours was that there's a big jump
[01:47:40.900 --> 01:47:41.900]   when we went to 1080p.
[01:47:41.900 --> 01:47:42.900]   You see everybody.
[01:47:42.900 --> 01:47:43.900]   Interesting.
[01:47:43.900 --> 01:47:44.900]   Really.
[01:47:44.900 --> 01:47:49.900]   So there was a difference in energy just based on the fact that now the people at the far
[01:47:49.900 --> 01:47:55.300]   end of the webinar are not looking at 640x360.
[01:47:55.300 --> 01:48:00.260]   And so I think that there is, we're going to get there.
[01:48:00.260 --> 01:48:02.660]   I'm not saying that we're not because we absolutely are.
[01:48:02.660 --> 01:48:06.660]   But we knew that we were going to get the video too in the 50s with the Jetsons.
[01:48:06.660 --> 01:48:08.460]   We knew that this eventually would happen.
[01:48:08.460 --> 01:48:12.740]   It just took us a long time to, our imagination takes a little while to fulfill.
[01:48:12.740 --> 01:48:19.900]   Well, you know, anybody who has followed technology for a while kind of should be used to this.
[01:48:19.900 --> 01:48:22.740]   First attempts are often rough and unimpressed.
[01:48:22.740 --> 01:48:24.940]   But it's better kept under wraps.
[01:48:24.940 --> 01:48:25.940]   That's all I may be doing.
[01:48:25.940 --> 01:48:26.940]   It's secret.
[01:48:26.940 --> 01:48:31.140]   You know, like the, the Vite Gila Libertte of Cirque du Soleil to do.
[01:48:31.140 --> 01:48:32.540]   What they, what they did.
[01:48:32.540 --> 01:48:33.540]   But they did.
[01:48:33.540 --> 01:48:36.900]   So, I mean, everybody wants to be cool like Apple so much that they just want to put on
[01:48:36.900 --> 01:48:40.980]   a great demo and they like, how do we create that imagination?
[01:48:40.980 --> 01:48:42.860]   And Apple's pretty conservative about how they do that.
[01:48:42.860 --> 01:48:47.900]   And they, you know, they, they do it inside of a little, a little box that, that keeps,
[01:48:47.900 --> 01:48:49.460]   that's pretty safe.
[01:48:49.460 --> 01:48:54.420]   And the problem is that, unfortunate thing is, is that Microsoft's HoloLens is, is just
[01:48:54.420 --> 01:48:56.020]   an amazing technology.
[01:48:56.020 --> 01:48:59.180]   But it's really in the kind of enterprise world.
[01:48:59.180 --> 01:49:01.340]   And it should stay there until it's really ready to come out.
[01:49:01.340 --> 01:49:04.860]   And it was not, was not ready for that, for that meeting.
[01:49:04.860 --> 01:49:05.860]   Also.
[01:49:05.860 --> 01:49:08.820]   And there's nothing wrong with Microsoft being an enterprise to focus company.
[01:49:08.820 --> 01:49:09.820]   Oh, absolutely.
[01:49:09.820 --> 01:49:15.100]   I feel like the thing you should actually pay attention to with Microsoft's keynotes is
[01:49:15.100 --> 01:49:20.540]   they are uncommonly transparent in laying out what their product roadmap is going to
[01:49:20.540 --> 01:49:24.300]   be and where they're going to be pushing their customers.
[01:49:24.300 --> 01:49:27.180]   And like Nadella always just like lays it right out there.
[01:49:27.180 --> 01:49:31.580]   And then all you have to do is watch the company execute like over the next one or two years
[01:49:31.580 --> 01:49:32.940]   after every keynote.
[01:49:32.940 --> 01:49:39.020]   And you'll see that he basically says, okay, in, in 2015, he said, we're mobile first, we're
[01:49:39.020 --> 01:49:40.540]   cloud first, that's it.
[01:49:40.540 --> 01:49:45.580]   And you can basically pinpoint that moment to when the company put the pedal to the metal
[01:49:45.580 --> 01:49:46.900]   on Azure.
[01:49:46.900 --> 01:49:51.820]   And although they rolled out Windows 10 that year, it was also effectively the end of Microsoft
[01:49:51.820 --> 01:49:56.740]   as a desktop computing operating system company because they went to continuous operating system
[01:49:56.740 --> 01:50:00.060]   updates as opposed to really big events.
[01:50:00.060 --> 01:50:05.260]   And they also started moving away from the computer as the hub of your work experience.
[01:50:05.260 --> 01:50:09.340]   And towards the idea that your cloud of data and how you manipulate it is your computing
[01:50:09.340 --> 01:50:10.340]   experience.
[01:50:10.340 --> 01:50:12.460]   And then they double down that with digital transformation.
[01:50:12.460 --> 01:50:18.660]   And then they're doing it again this year with the big statements they make about ubiquitous
[01:50:18.660 --> 01:50:19.660]   decentralized computing.
[01:50:19.660 --> 01:50:23.660]   Like this is them saying, we're going to own the edge and they're going to do it with
[01:50:23.660 --> 01:50:26.100]   a lot of the technology aimed at first line workers.
[01:50:26.100 --> 01:50:28.180]   They're going to do with HoloLens.
[01:50:28.180 --> 01:50:32.580]   This also goes into their plan to capitalize on ambient intelligence.
[01:50:32.580 --> 01:50:38.780]   And I just really love how Nadella finished his comments by taking direct aim at like
[01:50:38.780 --> 01:50:42.180]   both Amazon and Facebook without saying a word either.
[01:50:42.180 --> 01:50:46.820]   Like if the company would just be like, this is what we do, we don't need to be cool.
[01:50:46.820 --> 01:50:51.780]   We wouldn't have the need to just cringe with second hand embarrassment when burning man
[01:50:51.780 --> 01:50:53.900]   beat second life in the desert.
[01:50:53.900 --> 01:50:59.140]   Well, he said, okay, so next time we do this, I want you to join us because I watch these
[01:50:59.140 --> 01:51:03.540]   Nadella things and it's fine and hard to grab anything concrete.
[01:51:03.540 --> 01:51:08.060]   But I did, there were three words he used that I thought were interesting.
[01:51:08.060 --> 01:51:13.500]   He mentioned privacy and obviously I think privacy is increasingly on everybody's mind.
[01:51:13.500 --> 01:51:15.220]   So that's sensible.
[01:51:15.220 --> 01:51:17.780]   He talked about sovereignty.
[01:51:17.780 --> 01:51:23.300]   And now, tell me what he means in this context about sovereignty.
[01:51:23.300 --> 01:51:26.620]   Does he mean respecting national borders?
[01:51:26.620 --> 01:51:28.460]   So that it's compliance.
[01:51:28.460 --> 01:51:35.700]   It's basically, yeah, it's basically them saying that although they're going to leave
[01:51:35.700 --> 01:51:41.300]   with privacy saying, listen, our data tools don't expose you and whatever data analysis
[01:51:41.300 --> 01:51:43.700]   we do is anonymized and so on and so forth.
[01:51:43.700 --> 01:51:48.140]   What he's also saying when he talks about data sovereignty is he saying, if you store
[01:51:48.140 --> 01:51:55.580]   your data in the specific region of the country, a world actually, then we're going to argue
[01:51:55.580 --> 01:52:00.820]   that it's only subject to the laws in that region and the laws you're trying to enforce
[01:52:00.820 --> 01:52:01.940]   in another part of the world.
[01:52:01.940 --> 01:52:06.140]   It almost seems like sovereignty and privacy are in conflict because, well, certainly in
[01:52:06.140 --> 01:52:11.300]   the US or China, if you are adhering to the laws of those countries, you're not going
[01:52:11.300 --> 01:52:12.780]   to have much privacy.
[01:52:12.780 --> 01:52:14.780]   If my data is on a...
[01:52:14.780 --> 01:52:19.460]   Microsoft's been battling the US on this for years because the US kept trying to download
[01:52:19.460 --> 01:52:24.220]   data that was in an Irish data center and Microsoft kept saying, no, the data lives
[01:52:24.220 --> 01:52:28.180]   in Ireland, therefore it's Irish data just because we're an American company doesn't
[01:52:28.180 --> 01:52:31.780]   mean that we can draw the data to be American.
[01:52:31.780 --> 01:52:35.060]   Then the third word he used, which I thought it was very important and maybe a challenge
[01:52:35.060 --> 01:52:39.820]   for Microsoft but is clearly what Microsoft needs to do is trust.
[01:52:39.820 --> 01:52:44.980]   They really need to establish that people can trust them.
[01:52:44.980 --> 01:52:49.060]   I'm not just talking about security flaws, although that's certainly part of it.
[01:52:49.060 --> 01:52:50.740]   Apple's doing something similar.
[01:52:50.740 --> 01:52:55.500]   I don't think they have the sovereignty piece, but they talk about privacy and they talk
[01:52:55.500 --> 01:52:57.460]   about trust.
[01:52:57.460 --> 01:53:03.460]   I think that if you're going to compete against Amazon, Google, and Facebook, that's a pretty
[01:53:03.460 --> 01:53:07.140]   good place to compete from privacy and trust.
[01:53:07.140 --> 01:53:14.700]   The quote, because what the context is when he brought up his big trust by design point,
[01:53:14.700 --> 01:53:18.580]   as he said, fundamentally, a technology provider should succeed only when it helps the world
[01:53:18.580 --> 01:53:20.060]   around it succeed.
[01:53:20.060 --> 01:53:24.300]   No customer wants to be dependent on a vendor who sells some technology on one end and competes
[01:53:24.300 --> 01:53:26.180]   with them on the other.
[01:53:26.180 --> 01:53:35.620]   I thought that his use of the word trust was also a pretty interesting signal into the way
[01:53:35.620 --> 01:53:39.820]   the company's positioning itself as we're not just a tech company.
[01:53:39.820 --> 01:53:43.940]   We recognize that we're part of a larger global society and we're aware that our actions
[01:53:43.940 --> 01:53:46.020]   have an impact on the society.
[01:53:46.020 --> 01:53:50.980]   You can trust that when we roll out our products, of course, we're thinking about that.
[01:53:50.980 --> 01:53:55.100]   Whether or not this is true is a completely different issue than how they're positioning
[01:53:55.100 --> 01:53:56.100]   it.
[01:53:56.100 --> 01:54:01.340]   I think it's been interesting that Satya Nadella has consistently talked about how he sees
[01:54:01.340 --> 01:54:08.460]   a tech company rising or falling based on how well they place themselves into the context
[01:54:08.460 --> 01:54:11.140]   of a global society and what a global society needs.
[01:54:11.140 --> 01:54:13.740]   Do you think is interesting, Lisa?
[01:54:13.740 --> 01:54:19.660]   Because when I think about the trust issue and particularly when it comes to Microsoft,
[01:54:19.660 --> 01:54:24.860]   vis-a-vis, as you say, Leo, let's compare it to how far do we think about trust compared
[01:54:24.860 --> 01:54:27.620]   to Google or Facebook.
[01:54:27.620 --> 01:54:35.460]   I find it really interesting that of the four big CEOs, so Sunda Pichai at Google, Zuckerberg,
[01:54:35.460 --> 01:54:39.860]   at Facebook, Satya and Microsoft and Tim Cook at Apple.
[01:54:39.860 --> 01:54:42.940]   Satya is the only one that's written a book.
[01:54:42.940 --> 01:54:50.260]   Is the only one that's actually put on paper anything like a manifesto as to what he thinks
[01:54:50.260 --> 01:54:51.780]   and what he stands for?
[01:54:51.780 --> 01:54:55.820]   There's something really interesting in that idea of the fact that in a sense he's being,
[01:54:55.820 --> 01:54:58.140]   I'm sure you've read his book.
[01:54:58.140 --> 01:55:02.860]   It's an absolutely fantastic read, whether you're working a big company or trying to.
[01:55:02.860 --> 01:55:08.940]   It's absolutely for a Microsoft book transformed our Think About Startups.
[01:55:08.940 --> 01:55:12.980]   It's fascinating that he's the only person that's been that transparent and is the one
[01:55:12.980 --> 01:55:18.340]   person that's harping on about trust in a world where you don't really know anything
[01:55:18.340 --> 01:55:25.980]   about Zuckerberg or Sunda or a little bit about Tim Cook, but there's not even a biography
[01:55:25.980 --> 01:55:28.140]   really of Tim Cook.
[01:55:28.140 --> 01:55:30.260]   It is a Microsoft tradition.
[01:55:30.260 --> 01:55:33.180]   Remember Bill Gates wrote a number of these kind of manifestos?
[01:55:33.180 --> 01:55:35.700]   I don't think Palmer did.
[01:55:35.700 --> 01:55:40.900]   And in Brent Smith, who's Microsoft's Chief Legal Counsel has also written a pretty good
[01:55:40.900 --> 01:55:45.820]   book about what he perceives the upcoming legal and technological challenges in the
[01:55:45.820 --> 01:55:55.940]   next few years is to address the point, what makes Nadella stand apart from the other CEOs.
[01:55:55.940 --> 01:55:59.860]   Part of me wonders how much of it, because I don't know, I don't know how much of it
[01:55:59.860 --> 01:56:03.900]   is character, simply this is who he is, and how much of it is.
[01:56:03.900 --> 01:56:09.980]   This is a really smart market positioning strategy because you don't have a lot of other big
[01:56:09.980 --> 01:56:10.980]   enterprise companies.
[01:56:10.980 --> 01:56:16.100]   I sit through a lot of keynotes from a lot of big vendor conferences and big tech conferences
[01:56:16.100 --> 01:56:17.460]   every year.
[01:56:17.460 --> 01:56:22.460]   And although you can practically set up the Bingo card with transform the world, change
[01:56:22.460 --> 01:56:26.820]   the world for the better, there's like all of these phrases where it's always technology
[01:56:26.820 --> 01:56:28.260]   is the solution to the problem.
[01:56:28.260 --> 01:56:30.100]   We see this.
[01:56:30.100 --> 01:56:35.740]   But what I find really interesting is how Nadella consistently comes back to themes like we need
[01:56:35.740 --> 01:56:42.260]   to make sure that there's economic opportunity for all, that tech doesn't just continue to
[01:56:42.260 --> 01:56:44.740]   concentrate wealth in some areas in some countries.
[01:56:44.740 --> 01:56:46.860]   And he comes back to that over and over again.
[01:56:46.860 --> 01:56:53.900]   And then he talks about how he wants to see tech as something that empowers people as
[01:56:53.900 --> 01:56:56.340]   a tool in greater social transformation.
[01:56:56.340 --> 01:57:03.460]   And so part of me is like, is this just a really canny CEO who sees which way the wins
[01:57:03.460 --> 01:57:08.540]   are blowing with regards to how governments all around the world are looking at tech companies
[01:57:08.540 --> 01:57:12.540]   and going, maybe we should start taking a look at how well our laws are serving us
[01:57:12.540 --> 01:57:16.740]   regarding the way these guys do business and how it impacts the rest of our markets.
[01:57:16.740 --> 01:57:19.140]   You could almost say the same thing about Tim Cook.
[01:57:19.140 --> 01:57:20.140]   Yeah.
[01:57:20.140 --> 01:57:24.260]   Where you look at it, you go, this looks like a man of integrity and honesty.
[01:57:24.260 --> 01:57:26.060]   It could just be a marketing stance.
[01:57:26.060 --> 01:57:28.940]   But I think there's a lot of similarity between it.
[01:57:28.940 --> 01:57:33.340]   And I think there's a lot of similarity because they also had the unenviable task of trying
[01:57:33.340 --> 01:57:34.340]   to keep a company.
[01:57:34.340 --> 01:57:40.340]   Yeah, at the second day after following behind people who were, yeah.
[01:57:40.340 --> 01:57:43.260]   And although people will say, well, they'll receive bomber, bomber was like, bomber was
[01:57:43.260 --> 01:57:46.180]   basically one of the Bill Gates apparatus.
[01:57:46.180 --> 01:57:47.180]   Right.
[01:57:47.180 --> 01:57:49.620]   Nadella is the first one to arguably come into the country.
[01:57:49.620 --> 01:57:53.020]   And he's done a great job as is to go actually.
[01:57:53.020 --> 01:57:54.020]   Exactly.
[01:57:54.020 --> 01:57:55.020]   Yeah.
[01:57:55.020 --> 01:57:58.820]   I think for all of these companies, their public persona is going to become more and more important
[01:57:58.820 --> 01:58:05.940]   and probably for every company, your public persona, how you're seen by your users, by
[01:58:05.940 --> 01:58:09.020]   the governments, whether you're making a positive impact on the world.
[01:58:09.020 --> 01:58:15.260]   I think that there was a belief a decade ago that all you have to do is make good products.
[01:58:15.260 --> 01:58:17.100]   Like your products serve the world.
[01:58:17.100 --> 01:58:18.860]   That's Steve Jobs point of view.
[01:58:18.860 --> 01:58:19.860]   Yeah.
[01:58:19.860 --> 01:58:23.940]   And Oracle, Allison was kind of as purported that as well.
[01:58:23.940 --> 01:58:25.580]   And that's their job.
[01:58:25.580 --> 01:58:29.100]   And I think that now a lot of companies are going to have to figure out ways to do more.
[01:58:29.100 --> 01:58:33.660]   And that might be what they do as far as a public citizen, what they support.
[01:58:33.660 --> 01:58:37.060]   Apple spent is spending $100 million on diversity.
[01:58:37.060 --> 01:58:40.540]   They could spend more and they probably will.
[01:58:40.540 --> 01:58:46.140]   And so, but moving the world forward, and I think that they need to do a lot more of
[01:58:46.140 --> 01:58:53.420]   that because that will, if they do it in a way that at least feels authentic, even in
[01:58:53.420 --> 01:58:55.420]   authentic, will help them.
[01:58:55.420 --> 01:58:59.620]   But like, I mean, you look at like, it's different in the United States, Coca-Cola is
[01:58:59.620 --> 01:59:00.620]   not that big of a deal.
[01:59:00.620 --> 01:59:01.620]   I mean, it is.
[01:59:01.620 --> 01:59:07.180]   I mean, it's a big company, but it's not like a brand that you wear on a sweatshirt.
[01:59:07.180 --> 01:59:10.180]   You know, like that you wear, you know, like most people wouldn't wear like a nice fleece
[01:59:10.180 --> 01:59:11.180]   with a Coca-Cola.
[01:59:11.180 --> 01:59:13.540]   But Coca-Cola is seen that way in Africa.
[01:59:13.540 --> 01:59:18.100]   When I'm in Africa, Coca-Cola provides water and they provide signs and they provide, they
[01:59:18.100 --> 01:59:21.540]   do all the stuff that is part of the community.
[01:59:21.540 --> 01:59:25.700]   And people, like I asked someone like, they had a really nice fleece and a pretty wealthy
[01:59:25.700 --> 01:59:28.620]   person is in Bob way.
[01:59:28.620 --> 01:59:30.340]   And I said, so do you work for Coca-Cola?
[01:59:30.340 --> 01:59:33.700]   And he like, no, like why would I work for Coca-Cola?
[01:59:33.700 --> 01:59:37.300]   But he has a nice sweater and it's nice.
[01:59:37.300 --> 01:59:41.500]   But he had, they did, but we don't, but their brand doesn't feel that way anymore.
[01:59:41.500 --> 01:59:46.060]   And I think that more and more brands have to think about how do we get to that point?
[01:59:46.060 --> 01:59:49.740]   Because especially in the age of increased scrutiny and regulation.
[01:59:49.740 --> 01:59:53.340]   And also in age that kind of defends you against some of that.
[01:59:53.340 --> 01:59:56.660]   Well, and I think that I think that also in an age where advertising is going to be less
[01:59:56.660 --> 01:59:57.740]   and less effective.
[01:59:57.740 --> 01:59:58.740]   Yes.
[01:59:58.740 --> 02:00:00.620]   So, so advertising is going, so they have to figure out a way.
[02:00:00.620 --> 02:00:06.180]   And I think that the move that we're talking about of a community-based marketing, community-based
[02:00:06.180 --> 02:00:08.900]   sales is going to be more and more and more important.
[02:00:08.900 --> 02:00:13.220]   You have to get people into a community and have them part of, of what you're doing.
[02:00:13.220 --> 02:00:17.900]   And you have to figure out how you serve that community effectively to, you know, to, to
[02:00:17.900 --> 02:00:18.900]   get to the next step.
[02:00:18.900 --> 02:00:22.180]   And I think that people are starting to talk about that a little bit more than they used
[02:00:22.180 --> 02:00:23.180]   to.
[02:00:23.180 --> 02:00:24.540]   And I think that we'll see a lot more in that area.
[02:00:24.540 --> 02:00:26.420]   As George Burns said, sincerity.
[02:00:26.420 --> 02:00:30.340]   If you could fake that, you got it made.
[02:00:30.340 --> 02:00:34.260]   Thanks to Red Con and our chat room for that one.
[02:00:34.260 --> 02:00:37.100]   We're going to take a little break and then the seeds in the stems.
[02:00:37.100 --> 02:00:41.900]   All the stuff that's sifted to the bottom of the rundown on the show today.
[02:00:41.900 --> 02:00:44.140]   Will Harris, it's great to have you here.
[02:00:44.140 --> 02:00:47.020]   Is twin any different these days you think?
[02:00:47.020 --> 02:00:51.060]   Do you feel like it's coming home to a show that you know or do you feel like it's a
[02:00:51.060 --> 02:00:52.700]   little different these days?
[02:00:52.700 --> 02:00:53.700]   I'm just curious.
[02:00:53.700 --> 02:00:54.700]   You'll be honest.
[02:00:54.700 --> 02:00:58.340]   It's definitely better organized than when it was just you.
[02:00:58.340 --> 02:00:59.340]   Thanks.
[02:00:59.340 --> 02:01:00.340]   That's fair.
[02:01:00.340 --> 02:01:05.580]   You know, there's a producer and they get a rundown and there's a document and it's
[02:01:05.580 --> 02:01:07.020]   very well organized.
[02:01:07.020 --> 02:01:11.180]   And I definitely remember us winning it a few times back in the day.
[02:01:11.180 --> 02:01:14.140]   So it's a pretty cool way.
[02:01:14.140 --> 02:01:18.260]   In all other ways, it feels very much like just getting together with a bunch of old
[02:01:18.260 --> 02:01:21.060]   friends, which is exactly what a podcast should feel like.
[02:01:21.060 --> 02:01:23.540]   Whether you're in it or listening to it, shouldn't it?
[02:01:23.540 --> 02:01:27.180]   If only we could have a little bit of beer between us I would be.
[02:01:27.180 --> 02:01:28.180]   It would be perfect.
[02:01:28.180 --> 02:01:29.980]   It's a dream.
[02:01:29.980 --> 02:01:31.140]   Yeah, it's great to have you.
[02:01:31.140 --> 02:01:32.140]   Well, it's good to see you again.
[02:01:32.140 --> 02:01:34.860]   And of course, my old friend Alex Lindsey, who never left.
[02:01:34.860 --> 02:01:37.460]   In fact, he's going to be back on Tuesday for a Mac break weekly.
[02:01:37.460 --> 02:01:39.660]   I'm so glad we got you back on the show.
[02:01:39.660 --> 02:01:41.340]   Yeah, it's going to be back.
[02:01:41.340 --> 02:01:42.340]   Yeah, absolutely.
[02:01:42.340 --> 02:01:43.340]   I don't know how you find time.
[02:01:43.340 --> 02:01:45.340]   You're on the air pretty much all the time now.
[02:01:45.340 --> 02:01:46.340]   Yeah, it's fun.
[02:01:46.340 --> 02:01:52.180]   You do eight hours of office hours and you do a couple hours of Mac break weekly.
[02:01:52.180 --> 02:01:53.180]   I don't know.
[02:01:53.180 --> 02:01:54.620]   Have you time for work?
[02:01:54.620 --> 02:01:55.620]   It's pre-existing.
[02:01:55.620 --> 02:01:57.060]   You know, I was like, I already do this.
[02:01:57.060 --> 02:01:58.580]   I work most of the rest of the time.
[02:01:58.580 --> 02:01:59.580]   You do it.
[02:01:59.580 --> 02:02:00.580]   You're just working the whole.
[02:02:00.580 --> 02:02:01.580]   It's all work.
[02:02:01.580 --> 02:02:02.580]   It does all work.
[02:02:02.580 --> 02:02:03.580]   So yeah, it's long day.
[02:02:03.580 --> 02:02:08.340]   Lisa Schmeiser, the only thing I regret is that you couldn't bring us Girl Scout cookies.
[02:02:08.340 --> 02:02:09.340]   Me too.
[02:02:09.340 --> 02:02:12.900]   We will get you back in the studio as soon as possible.
[02:02:12.900 --> 02:02:14.580]   We're working on it.
[02:02:14.580 --> 02:02:15.580]   It's really great.
[02:02:15.580 --> 02:02:16.580]   I did buy some.
[02:02:16.580 --> 02:02:17.580]   I couldn't help it.
[02:02:17.580 --> 02:02:18.580]   Did you?
[02:02:18.580 --> 02:02:19.580]   I was like, you can order girls that cookies?
[02:02:19.580 --> 02:02:21.580]   I'm just going to, I just ordered them from my local troop.
[02:02:21.580 --> 02:02:23.580]   I was like, I'm so glad to hear that.
[02:02:23.580 --> 02:02:24.580]   That's great.
[02:02:24.580 --> 02:02:25.580]   Everybody should do that.
[02:02:25.580 --> 02:02:26.580]   I want some mint cookies.
[02:02:26.580 --> 02:02:27.580]   I haven't had mint cookies in like a decade.
[02:02:27.580 --> 02:02:30.300]   I was like, my kids have probably never had them in their whole life.
[02:02:30.300 --> 02:02:31.740]   I put them in the fridge first.
[02:02:31.740 --> 02:02:32.740]   They're amazing.
[02:02:32.740 --> 02:02:33.740]   They're amazing.
[02:02:33.740 --> 02:02:34.740]   They're amazing when they're cold.
[02:02:34.740 --> 02:02:35.740]   Yes.
[02:02:35.740 --> 02:02:36.740]   Oh, yes.
[02:02:36.740 --> 02:02:37.740]   I like the Samoas myself.
[02:02:37.740 --> 02:02:38.740]   I'm kind of one of those two.
[02:02:38.740 --> 02:02:39.740]   Yeah.
[02:02:39.740 --> 02:02:40.740]   Those are awfully good.
[02:02:40.740 --> 02:02:41.740]   There you go.
[02:02:41.740 --> 02:02:42.740]   Good tasting cookies.
[02:02:42.740 --> 02:02:43.740]   What is the number one seller?
[02:02:43.740 --> 02:02:44.740]   Is it the Thin Mints?
[02:02:44.740 --> 02:02:45.740]   It must be Thin Mints.
[02:02:45.740 --> 02:02:46.740]   Oh, it's got to be Thin Mints.
[02:02:46.740 --> 02:02:47.740]   Yeah.
[02:02:47.740 --> 02:02:48.740]   It's got to be.
[02:02:48.740 --> 02:02:50.740]   Now I'm really hungry.
[02:02:50.740 --> 02:02:53.140]   Well, you know what?
[02:02:53.140 --> 02:02:55.940]   It's perfect time to talk about Uber for business.
[02:02:55.940 --> 02:02:59.740]   Now, I know you know about Uber and rideshare, but Uber is more than that.
[02:02:59.740 --> 02:03:05.140]   In fact, Uber for business is a great way for your business to stand out with your customers
[02:03:05.140 --> 02:03:08.540]   or to make employees feel extra valued.
[02:03:08.540 --> 02:03:14.900]   You can use Uber for business to set up vouchers so that you can say, for instance,
[02:03:14.900 --> 02:03:19.940]   to your employees, "Hey, let me buy you lunch today," since you all came into work or you're
[02:03:19.940 --> 02:03:22.780]   working at home and you all came to the Zoom meeting.
[02:03:22.780 --> 02:03:28.060]   You could use Uber for business to give them a ride if you want to have them come in to
[02:03:28.060 --> 02:03:29.060]   work.
[02:03:29.060 --> 02:03:33.420]   It's a great way to request rides and order meals from the restaurants you love.
[02:03:33.420 --> 02:03:37.740]   It always has been, but Uber for business makes it possible for your company to do that
[02:03:37.740 --> 02:03:39.540]   for your customers and employees.
[02:03:39.540 --> 02:03:44.980]   160,000 companies now use Uber for business to improve customer and employee satisfaction.
[02:03:44.980 --> 02:03:50.380]   A great way to get people to show up or stay engaged in virtual team meetings or events.
[02:03:50.380 --> 02:03:55.140]   With vouchers from Uber for business, you can add $20 to their personal Uber accounts.
[02:03:55.140 --> 02:03:57.700]   They can order meals through Uber Eats before the meeting.
[02:03:57.700 --> 02:03:59.900]   You can buy them a cup of coffee.
[02:03:59.900 --> 02:04:03.980]   If you want to make your customers love your business even more, you offer them a voucher
[02:04:03.980 --> 02:04:07.940]   for a free ride when they make the first purchase or spend a certain amount.
[02:04:07.940 --> 02:04:10.260]   It's easy, by the way, and this is the best part.
[02:04:10.260 --> 02:04:15.100]   You can sign up for free and immediately start delivering extra value to the people who matter
[02:04:15.100 --> 02:04:17.020]   most to your business.
[02:04:17.020 --> 02:04:18.700]   Vouchers are simple to send.
[02:04:18.700 --> 02:04:21.060]   They're easy for your customers to redeem.
[02:04:21.060 --> 02:04:25.420]   You get total control over, not only who gets it, but when they expire, even what portion
[02:04:25.420 --> 02:04:28.060]   of the ride or meal you want to cover.
[02:04:28.060 --> 02:04:30.380]   You share them via email or text.
[02:04:30.380 --> 02:04:31.380]   Redemption is easy.
[02:04:31.380 --> 02:04:33.060]   You get a single tap.
[02:04:33.060 --> 02:04:35.060]   Best of all, you only pay for rides.
[02:04:35.060 --> 02:04:39.940]   They take or meals they order, which is a great, great thing.
[02:04:39.940 --> 02:04:41.860]   Zoom uses them.
[02:04:41.860 --> 02:04:44.020]   Coca-Cola uses them.
[02:04:44.020 --> 02:04:48.460]   That's a great way to spiff your employees to thank your customers.
[02:04:48.460 --> 02:04:52.740]   Right now for a limited time, you get a $50 voucher when you create your first vouchers
[02:04:52.740 --> 02:04:55.060]   campaign and spend $200 or more.
[02:04:55.060 --> 02:04:56.860]   Go to uber.com/twit.
[02:04:56.860 --> 02:05:21.300]   Uber for business has been an absolute lifesaver for Intel through the pandemic.
[02:05:21.300 --> 02:05:22.300]   You use it?
[02:05:22.300 --> 02:05:24.340]   Yeah, we've been absolutely loving it.
[02:05:24.340 --> 02:05:27.820]   So for the few occasions that we've had to do in-person meetings where we have to do
[02:05:27.820 --> 02:05:31.220]   socially decent meetings, we can get Uber's for the team in.
[02:05:31.220 --> 02:05:35.420]   We used to go to the pub for lunch every week, but now all the employees can get Uber eats
[02:05:35.420 --> 02:05:36.420]   delivered on our business.
[02:05:36.420 --> 02:05:37.420]   That's great.
[02:05:37.420 --> 02:05:40.460]   And we have a virtual lunch.
[02:05:40.460 --> 02:05:45.140]   So I can give you a little bit of a customer recommendation on the Uber for business.
[02:05:45.140 --> 02:05:47.180]   It makes life a lot easier.
[02:05:47.180 --> 02:05:53.940]   I'm thinking Girl Scouts for Business, where you have cookies sent before the Zoom meeting
[02:05:53.940 --> 02:05:54.940]   with me.
[02:05:54.940 --> 02:05:55.940]   Can we do a team up?
[02:05:55.940 --> 02:05:57.940]   Can we get the Girl Scouts on Uber eats?
[02:05:57.940 --> 02:05:59.540]   That would be good.
[02:05:59.540 --> 02:06:02.220]   I need Samoas and I need him now.
[02:06:02.220 --> 02:06:05.820]   Actually, we're talking about Microsoft and AWS.
[02:06:05.820 --> 02:06:07.980]   I saw a story, kind of a shock.
[02:06:07.980 --> 02:06:14.620]   The Pentagon is now so pissed over Amazon suing Microsoft over that $10 billion Jedi
[02:06:14.620 --> 02:06:16.540]   program.
[02:06:16.540 --> 02:06:21.500]   They know that this lawsuit is going to go on for years, putting everything on hold.
[02:06:21.500 --> 02:06:26.860]   They are at the point of just dropping the whole thing entirely.
[02:06:26.860 --> 02:06:28.620]   Which mates Jeff Bezos very happy.
[02:06:28.620 --> 02:06:31.580]   He said, "If it can't be mine, it can't be yours Microsoft."
[02:06:31.580 --> 02:06:34.460]   Well, Oracle's probably also cackling a little bit over that.
[02:06:34.460 --> 02:06:36.380]   Yeah, Oracle was in the running.
[02:06:36.380 --> 02:06:38.740]   This was a big contract, a billion dollars a year.
[02:06:38.740 --> 02:06:45.900]   For 10 years, it was to provide a Department of Defense Cloud, secure cloud for the Department
[02:06:45.900 --> 02:06:48.900]   of Defense.
[02:06:48.900 --> 02:06:57.020]   And I think Amazon felt like the president at the time, President Trump, didn't think
[02:06:57.020 --> 02:07:00.500]   that Amazon should get it and kind of pushed it toward Microsoft.
[02:07:00.500 --> 02:07:02.420]   That was the basis of their lawsuit.
[02:07:02.420 --> 02:07:03.580]   Who knows?
[02:07:03.580 --> 02:07:09.020]   It might not even matter.
[02:07:09.020 --> 02:07:13.060]   It's probably that a rebid will take less time than a legal executive.
[02:07:13.060 --> 02:07:16.340]   You basically force everybody back in the start of a row and start redoing.
[02:07:16.340 --> 02:07:20.340]   They'll probably be like, "Well, this will take five years to litigate or two or three
[02:07:20.340 --> 02:07:21.340]   years to get it."
[02:07:21.340 --> 02:07:24.500]   Yeah, it's like four to five years before this is over.
[02:07:24.500 --> 02:07:25.940]   We didn't mention this from Ignite.
[02:07:25.940 --> 02:07:28.340]   And actually, I didn't know what a big deal it is.
[02:07:28.340 --> 02:07:32.660]   But I've heard from a lot of people, they, Microsoft announced that Power Automate Desktop
[02:07:32.660 --> 02:07:35.100]   is free for all Windows 10 users.
[02:07:35.100 --> 02:07:39.180]   Is that a big deal, Lisa?
[02:07:39.180 --> 02:07:40.180]   You're putting me on the spot here.
[02:07:40.180 --> 02:07:41.180]   It's a low code.
[02:07:41.180 --> 02:07:42.180]   It's a low code.
[02:07:42.180 --> 02:07:43.180]   No code.
[02:07:43.180 --> 02:07:44.180]   It's a low code.
[02:07:44.180 --> 02:07:55.060]   The reason I would argue it's a big deal is because it amplifies one of the points that
[02:07:55.060 --> 02:08:02.420]   Nadella did make in his keynote, which is that he fully expects within five years.
[02:08:02.420 --> 02:08:06.940]   You will not need to have coders so much because you will have tools that can do the
[02:08:06.940 --> 02:08:08.180]   coding for you.
[02:08:08.180 --> 02:08:11.700]   It's kind of a drag and drop in your face.
[02:08:11.700 --> 02:08:15.620]   You're not really writing code, but you can automate a lot of the things you do.
[02:08:15.620 --> 02:08:17.860]   It was at least 15 bucks a month.
[02:08:17.860 --> 02:08:23.020]   A lot of people, I was surprised, wrote me or texted me or chatted me saying, "This
[02:08:23.020 --> 02:08:24.620]   is fantastic.
[02:08:24.620 --> 02:08:26.900]   We're so excited about Power Automate."
[02:08:26.900 --> 02:08:29.940]   It lets you automate a lot of business processes.
[02:08:29.940 --> 02:08:36.300]   So you can have people who run reports and they're either not dependent on getting developers
[02:08:36.300 --> 02:08:41.380]   to build them the tools to do it or having somebody whose job is just to figure out how
[02:08:41.380 --> 02:08:43.700]   to run the reports.
[02:08:43.700 --> 02:08:51.500]   In a way, this flattens out and democratizes the ability to analyze data and to come up
[02:08:51.500 --> 02:08:55.740]   with new ways to mine insights and then act on them.
[02:08:55.740 --> 02:08:57.100]   That's great.
[02:08:57.100 --> 02:09:03.580]   I still think the biggest thing to get out of this is that it will have the same effect
[02:09:03.580 --> 02:09:08.940]   on the market for coding jobs that WYSIWYG HTML editors had on the market for quote,
[02:09:08.940 --> 02:09:11.060]   "web editors" and "web developers."
[02:09:11.060 --> 02:09:15.500]   Because you remember for a while there was a period of maybe three years where if you
[02:09:15.500 --> 02:09:21.180]   were really good at HTML and style sheets, you could hand code beautiful websites and
[02:09:21.180 --> 02:09:23.180]   beautiful web templates and so on and so forth.
[02:09:23.180 --> 02:09:27.220]   And then everybody developed decent WYSIWY editors and all of a sudden you didn't have
[02:09:27.220 --> 02:09:31.140]   to have somebody who knew how to use headings tags.
[02:09:31.140 --> 02:09:35.180]   You could just do it yourself in Dreamweaver or whatever.
[02:09:35.180 --> 02:09:38.380]   And I think we're about to see that happen with coding because it's getting to the point
[02:09:38.380 --> 02:09:44.260]   since all coding is based on a really strict grammar in any artificial computer language
[02:09:44.260 --> 02:09:48.420]   and the functions that you can enact with that grammar, it's not going to be that hard
[02:09:48.420 --> 02:09:51.900]   to completely automate that process.
[02:09:51.900 --> 02:09:58.940]   I think the wrong, but the name just makes me think of Microsoft Power Tools for Windows
[02:09:58.940 --> 02:09:59.940]   95.
[02:09:59.940 --> 02:10:00.940]   No, no, that's completely.
[02:10:00.940 --> 02:10:04.500]   I saw this headline and I was like, "What can I automate the changing of my screensays?"
[02:10:04.500 --> 02:10:05.500]   Where is this?
[02:10:05.500 --> 02:10:06.500]   You could actually.
[02:10:06.500 --> 02:10:10.100]   Let's just imagine like a sentient drill where all of a sudden it's like, "No, no, I'm going
[02:10:10.100 --> 02:10:13.100]   to put up your pictures for it."
[02:10:13.100 --> 02:10:18.900]   I think that the thing is that there's such a strong demand for coders and such a lack
[02:10:18.900 --> 02:10:20.940]   of supply.
[02:10:20.940 --> 02:10:23.860]   It's going to take a long time to get that going.
[02:10:23.860 --> 02:10:28.020]   And from what I understand, I don't understand the power automated as well, but it looks
[02:10:28.020 --> 02:10:33.860]   a lot like Salesforce automation that you're dragging, dropping.
[02:10:33.860 --> 02:10:39.100]   So it's for processing data, sure, for actually building the tools.
[02:10:39.100 --> 02:10:41.380]   I'm not like to put an app out somewhere.
[02:10:41.380 --> 02:10:42.380]   Just doesn't like hand-coating.
[02:10:42.380 --> 02:10:43.380]   Sure.
[02:10:43.380 --> 02:10:44.380]   No, I'm sorry.
[02:10:44.380 --> 02:10:51.300]   But I think that for instance, Apple I think is missing a huge opportunity between the basic
[02:10:51.300 --> 02:10:54.540]   automation that you get with the, I can't think of the tool right now.
[02:10:54.540 --> 02:10:55.540]   Automator?
[02:10:55.540 --> 02:10:58.900]   No, well, Automator, but the one that's on the, they bought.
[02:10:58.900 --> 02:10:59.900]   Oh, shortcuts.
[02:10:59.900 --> 02:11:00.900]   Yeah, yeah.
[02:11:00.900 --> 02:11:01.900]   Shortcuts.
[02:11:01.900 --> 02:11:04.820]   Shortcuts on one side, then you have Swift on the other and once we're missing right in
[02:11:04.820 --> 02:11:10.860]   the middle, is a nodal coding platform that you can sit there and just say, "Now, does
[02:11:10.860 --> 02:11:12.620]   it do everything that the code does?"
[02:11:12.620 --> 02:11:17.260]   No, you would still need to write it, but what you, we did this with a compositing app
[02:11:17.260 --> 02:11:20.420]   where you could build these things that's very much like code.
[02:11:20.420 --> 02:11:24.460]   It's how I'm going to handle all the process, all these images, but you could open up a
[02:11:24.460 --> 02:11:26.540]   node and just put code in.
[02:11:26.540 --> 02:11:28.020]   You just drop code in.
[02:11:28.020 --> 02:11:29.380]   I don't have to write all the rest of this.
[02:11:29.380 --> 02:11:33.340]   I only have to write this one piece that there's no node for.
[02:11:33.340 --> 02:11:37.540]   And so if I think that if Apple did that or other people did more of that, that kind
[02:11:37.540 --> 02:11:41.140]   of programming interface, you'd end up with a lot more people developing.
[02:11:41.140 --> 02:11:42.420]   And I think this is good.
[02:11:42.420 --> 02:11:45.860]   I mean, when I look at it, of what it is from the surface, I think it looks good.
[02:11:45.860 --> 02:11:49.020]   It's not, but I don't think it'll replace many coders.
[02:11:49.020 --> 02:11:52.740]   It'll make it easier to do a lot more with the data, which is incredibly powerful.
[02:11:52.740 --> 02:11:53.740]   Will you make a huge?
[02:11:53.740 --> 02:11:55.460]   Do you have in-house coders?
[02:11:55.460 --> 02:11:58.860]   I mean, you've got front end because you've got an iOS application, but you also have
[02:11:58.860 --> 02:12:02.020]   some, I'm sure, a lot of backend coding that you have to do.
[02:12:02.020 --> 02:12:03.220]   Yeah, we do everything.
[02:12:03.220 --> 02:12:04.220]   We do everything in-house.
[02:12:04.220 --> 02:12:11.140]   Obviously, we write the iOS app in script in Swift.
[02:12:11.140 --> 02:12:16.780]   Everything runs on AWS in the backend, I have to say, back to our earlier point.
[02:12:16.780 --> 02:12:24.100]   But for me, the thing about Power Automate, it kind of feels a little bit analogous to
[02:12:24.100 --> 02:12:30.660]   me as when you first got the ability to do really interesting macros in Excel.
[02:12:30.660 --> 02:12:31.660]   Yeah.
[02:12:31.660 --> 02:12:36.940]   And suddenly, you could automate really stuff that was really complex and required in saying
[02:12:36.940 --> 02:12:37.940]   levels of coding.
[02:12:37.940 --> 02:12:42.220]   It's like, "Oh, I can write a macro that just builds a pivot table that does that now."
[02:12:42.220 --> 02:12:44.940]   And it feels like it kind of exploding that up to a bigger level.
[02:12:44.940 --> 02:12:45.940]   You're actually not sorry.
[02:12:45.940 --> 02:12:46.940]   You're not running.
[02:12:46.940 --> 02:12:53.940]   And that's not taking a coders job, so much as making it easier for, you know, a lot
[02:12:53.940 --> 02:12:59.740]   of people, somebody who already has a job to do something like way quicker or to-
[02:12:59.740 --> 02:13:01.460]   That's exactly what it's targeting.
[02:13:01.460 --> 02:13:04.620]   Suddenly, it suddenly increased, you know, 10x the amount that you can do.
[02:13:04.620 --> 02:13:07.860]   I think my yourself said it, it actually is for the people who are using Excel right
[02:13:07.860 --> 02:13:09.860]   now to do that code.
[02:13:09.860 --> 02:13:12.740]   I mean, I know a lot of people do things tomorrow.
[02:13:12.740 --> 02:13:13.740]   Yeah, yeah.
[02:13:13.740 --> 02:13:17.500]   I'm not saying coding job every week on tomorrow, I'm just saying that they're being in that.
[02:13:17.500 --> 02:13:18.500]   Yeah.
[02:13:18.500 --> 02:13:19.500]   Oh, yeah.
[02:13:19.500 --> 02:13:20.500]   It's a broader scope.
[02:13:20.500 --> 02:13:21.500]   I mean-
[02:13:21.500 --> 02:13:22.500]   It's a broader trend.
[02:13:22.500 --> 02:13:23.500]   Yeah.
[02:13:23.500 --> 02:13:30.620]   I'm habituating people to the idea that, "Hey, I too can write the logical process and I know
[02:13:30.620 --> 02:13:35.180]   how to categorize this data so I know I want done with it."
[02:13:35.180 --> 02:13:37.940]   Let's see.
[02:13:37.940 --> 02:13:41.380]   Oh, there's a lot of little stories here.
[02:13:41.380 --> 02:13:44.980]   I'm a fan of the Brave browser.
[02:13:44.980 --> 02:13:51.820]   It's an interesting take on taking Google's Chrome browser, taking out the privacy invasion
[02:13:51.820 --> 02:13:56.100]   material, but using the Chromium engine and then making a privacy first browser.
[02:13:56.100 --> 02:13:57.980]   They're taking another byte out of the Google Apple.
[02:13:57.980 --> 02:14:00.300]   They just bought a search engine.
[02:14:00.300 --> 02:14:05.340]   I don't know how good it will be, but their goal is to create a no-tracking, no profiling,
[02:14:05.340 --> 02:14:13.620]   perhaps even a paid-for, no-adversion of a search engine to run in the Brave browser.
[02:14:13.620 --> 02:14:20.820]   It bought it from clicks, CLIQZ, which was another privacy-focused browser shut down
[02:14:20.820 --> 02:14:22.780]   last year.
[02:14:22.780 --> 02:14:25.100]   You mentioned this at the beginning of the show.
[02:14:25.100 --> 02:14:26.140]   I didn't want to get to it.
[02:14:26.140 --> 02:14:31.060]   I don't know exactly what it means, but Google has announced that they're going to make
[02:14:31.060 --> 02:14:34.460]   third-party cookies obsolete.
[02:14:34.460 --> 02:14:36.460]   You mentioned this, Will.
[02:14:36.460 --> 02:14:40.140]   Yeah, this is fascinating.
[02:14:40.140 --> 02:14:43.500]   We all know the kind of the cookies that follow us.
[02:14:43.500 --> 02:14:49.380]   You shop for one thing online and suddenly that follows you around the web.
[02:14:49.380 --> 02:14:55.220]   So there are an awful lot of third-party advertisers that rely on, effectively, buying
[02:14:55.220 --> 02:15:01.180]   your data out of Google and retargeting you.
[02:15:01.180 --> 02:15:05.660]   What Google has announced, basically, is that they're going to stop people doing that
[02:15:05.660 --> 02:15:13.140]   and stop other people effectively doing this market of trading personal information where
[02:15:13.140 --> 02:15:15.900]   one advertising company does a deal with another advertising company.
[02:15:15.900 --> 02:15:21.260]   You link up their cookies and those cookies then all track you and you get these massive
[02:15:21.260 --> 02:15:23.220]   advertising networks.
[02:15:23.220 --> 02:15:29.700]   Google is playing this really cleverly because they're playing it as a nod to privacy and
[02:15:29.700 --> 02:15:34.400]   saying that actually what we're doing is stopping so much of this tracking that happens
[02:15:34.400 --> 02:15:35.400]   around the web.
[02:15:35.400 --> 02:15:39.940]   Of course, Apple already does that with its mobile browsers for Safari, for example, already
[02:15:39.940 --> 02:15:46.460]   stops third-party cookies, but of course the incidental and completely coincidental side
[02:15:46.460 --> 02:15:53.000]   effect of enforcing this kind of new privacy-focused rule is that it puts an awful lot of emphasis
[02:15:53.000 --> 02:15:58.660]   on first-party cookies, i.e. spending money with the people who actually have your data,
[02:15:58.660 --> 02:15:59.660]   i.e.
[02:15:59.660 --> 02:16:00.660]   Google.
[02:16:00.660 --> 02:16:07.940]   So suddenly, I don't need to buy somebody's Google search history and then retarget them
[02:16:07.940 --> 02:16:09.380]   using a third-party advertiser.
[02:16:09.380 --> 02:16:13.740]   If I want to do that, I've got to go directly to Google because that's privacy.
[02:16:13.740 --> 02:16:14.740]   Yeah.
[02:16:14.740 --> 02:16:21.340]   But it also looks an awful lot more like Google reigning in other people on its customers.
[02:16:21.340 --> 02:16:23.300]   Very good point.
[02:16:23.300 --> 02:16:26.900]   I think I was suspicious, but I didn't know why I was suspicious.
[02:16:26.900 --> 02:16:27.900]   Now I understand.
[02:16:27.900 --> 02:16:34.380]   One of the interesting side effects is that of course Google has been accused of killing
[02:16:34.380 --> 02:16:41.340]   the media industry in many, many ways, but if first-party cookies are one of the only
[02:16:41.340 --> 02:16:45.820]   types of cookies that are going to be allowed, so you can only be tracked by the site that
[02:16:45.820 --> 02:16:53.060]   you're on and not have that tracking follow you elsewhere, that makes destination places
[02:16:53.060 --> 02:16:54.060]   extremely valuable.
[02:16:54.060 --> 02:16:59.340]   So suddenly, new sites where you, you know, media sites where you turn up regularly,
[02:16:59.340 --> 02:17:01.660]   those cookies get an awful lot more valuable.
[02:17:01.660 --> 02:17:07.180]   So for example, we know, I know from historical experience, we'd have people that wanted advertisers
[02:17:07.180 --> 02:17:15.340]   that wanted to buy campaigns with magazines that I've worked at in the past and they'd
[02:17:15.340 --> 02:17:20.420]   buy a small portion of that audience and then use that to drop a cookie that they could
[02:17:20.420 --> 02:17:23.220]   then retarget on one of the cheaper advertising networks.
[02:17:23.220 --> 02:17:24.220]   Oh, that's a bit fair.
[02:17:24.220 --> 02:17:28.860]   And so you could buy a high quality customer and then target them on cheaper sites all
[02:17:28.860 --> 02:17:30.260]   across the web.
[02:17:30.260 --> 02:17:34.060]   So of course, what that means now is that that data won't be accessible and that they'll
[02:17:34.060 --> 02:17:39.820]   have to only buy with the quality publication that they're after or Google.
[02:17:39.820 --> 02:17:44.540]   So as much as Google is, you know, being accused, lots of killing the media industry,
[02:17:44.540 --> 02:17:50.500]   this might end up being a bit of a win for media companies that run their own operations.
[02:17:50.500 --> 02:17:52.340]   Interesting.
[02:17:52.340 --> 02:17:58.060]   Californians are not leaving the state en masse, this article.
[02:17:58.060 --> 02:18:01.420]   A little bit of Schadenfreude from the LA Times.
[02:18:01.420 --> 02:18:05.660]   Californians aren't leaving the state en masse, but they are leaving San Francisco.
[02:18:05.660 --> 02:18:14.660]   Study says LA Times just a little too happy over that.
[02:18:14.660 --> 02:18:19.980]   Apparently a great number of people are leaving San Francisco, but instead of moving out of
[02:18:19.980 --> 02:18:25.580]   state, they're moving to the snow, to the Sierra counties so they can ski more.
[02:18:25.580 --> 02:18:28.380]   And I think they'll probably be coming back this summer.
[02:18:28.380 --> 02:18:34.820]   Net domestic area exits from the Bay Area have increased 178% during the pandemic, a
[02:18:34.820 --> 02:18:39.260]   9% increase in departures and a 21% decrease in entrances.
[02:18:39.260 --> 02:18:45.140]   So far more people are leaving than coming back.
[02:18:45.140 --> 02:18:48.100]   But they tend not to be leaving California.
[02:18:48.100 --> 02:18:50.260]   It's about the same as it ever was.
[02:18:50.260 --> 02:18:56.140]   So the rumors of people leaving the Golden State are greatly exaggerated.
[02:18:56.140 --> 02:18:57.380]   And when they do leave, by the way, they don't...
[02:18:57.380 --> 02:18:58.820]   Goldgate bridge less so.
[02:18:58.820 --> 02:18:59.820]   Yeah, right.
[02:18:59.820 --> 02:19:00.820]   It's not actually gold.
[02:19:00.820 --> 02:19:02.620]   I just want everybody to know ahead of time.
[02:19:02.620 --> 02:19:05.380]   I don't want you to be disappointed when you get here.
[02:19:05.380 --> 02:19:08.740]   Well, and it's so expensive in San Francisco.
[02:19:08.740 --> 02:19:09.820]   I know, I understand why people are running.
[02:19:09.820 --> 02:19:12.700]   I moved out because I was just like, "Wow, I can't."
[02:19:12.700 --> 02:19:19.780]   My apartment that I had in Nob Hill, the tiny little, really tiny little apartment, I
[02:19:19.780 --> 02:19:22.820]   think that I had it at $1,600 a month.
[02:19:22.820 --> 02:19:23.820]   And I think that the...
[02:19:23.820 --> 02:19:25.740]   For some reason, I was...
[02:19:25.740 --> 02:19:28.900]   $1,600 a month and it was like a little two bedroom...
[02:19:28.900 --> 02:19:32.780]   Sorry, one bedroom, one bedroom in Nob Hill, nice little area.
[02:19:32.780 --> 02:19:34.700]   But now it's like $5,600 a month.
[02:19:34.700 --> 02:19:40.700]   I saw it come up in $5,600 a month.
[02:19:40.700 --> 02:19:43.980]   It's barely a one bedroom.
[02:19:43.980 --> 02:19:45.820]   It's like a glorified studio.
[02:19:45.820 --> 02:19:50.460]   It's got some doors that close between the bedroom and the living room area.
[02:19:50.460 --> 02:19:52.180]   But it's all one long room.
[02:19:52.180 --> 02:19:57.180]   Now I will admit, top floor and you can go up on the roof and it's really cool.
[02:19:57.180 --> 02:19:59.980]   But it is $5,600 a month.
[02:19:59.980 --> 02:20:00.980]   I should check to see...
[02:20:00.980 --> 02:20:06.380]   Oh, my old studio apartment, it was up on Telegraph Hill.
[02:20:06.380 --> 02:20:10.940]   I bet you, it was $1,000 in 1994.
[02:20:10.940 --> 02:20:14.620]   I don't want to know what it is now.
[02:20:14.620 --> 02:20:18.220]   Yeah, at that time, I remember thinking, "I don't know if I can afford that."
[02:20:18.220 --> 02:20:19.220]   Oh, it was a lot.
[02:20:19.220 --> 02:20:20.860]   It was only because my wife and I could afford it.
[02:20:20.860 --> 02:20:21.860]   Yeah.
[02:20:21.860 --> 02:20:23.700]   And that was the whole thing, is that we could have $1,600.
[02:20:23.700 --> 02:20:26.380]   And this is like, I don't know, 10 years, 12 years ago.
[02:20:26.380 --> 02:20:27.380]   But it was...
[02:20:27.380 --> 02:20:33.260]   Nintendo's planning a switch for Christmas with a bigger Samsung OLED display.
[02:20:33.260 --> 02:20:36.860]   Can't wait to play Animal Crossing on that.
[02:20:36.860 --> 02:20:39.140]   4K output.
[02:20:39.140 --> 02:20:40.980]   4K output.
[02:20:40.980 --> 02:20:41.980]   So this is the most...
[02:20:41.980 --> 02:20:46.220]   I think I'm the only person in the world that plays their switch more on the big screen
[02:20:46.220 --> 02:20:47.220]   than handheld.
[02:20:47.220 --> 02:20:49.020]   No, I'm with you.
[02:20:49.020 --> 02:20:51.420]   I like really dislike playing that thing handheld.
[02:20:51.420 --> 02:20:54.180]   I got the dock and I'm on this.
[02:20:54.180 --> 02:20:59.780]   Unfortunately, I have the pandemic Animal Crossing addiction, which is not unusual.
[02:20:59.780 --> 02:21:05.140]   But it looks so much nicer on the 4K screen and I could sit on the couch and use the controller.
[02:21:05.140 --> 02:21:08.900]   Use the nice controller, the Pro Controller, which I think is still the best controller.
[02:21:08.900 --> 02:21:11.180]   Possibly the PS5 DualSense is now better.
[02:21:11.180 --> 02:21:12.180]   But I'm really excited.
[02:21:12.180 --> 02:21:19.060]   The idea of a 4K, getting 4K Mario or something is really exciting.
[02:21:19.060 --> 02:21:23.460]   I just wonder if they'll finally take the opportunity to put Netflix on that thing.
[02:21:23.460 --> 02:21:25.020]   Because you still can't watch Netflix on the Switch.
[02:21:25.020 --> 02:21:26.020]   It's the weirdest thing.
[02:21:26.020 --> 02:21:28.100]   Yeah, that's crazy.
[02:21:28.100 --> 02:21:29.100]   Yeah.
[02:21:29.100 --> 02:21:39.740]   John McAfee accused of $13 million in a scalping fraud and money laundering with cryptocurrency.
[02:21:39.740 --> 02:21:44.820]   The guy who created McAfee Antivirus sold it long time ago.
[02:21:44.820 --> 02:21:47.700]   I can't figure out whether that guy's a genius or just crazy.
[02:21:47.700 --> 02:21:48.700]   Just insane.
[02:21:48.700 --> 02:21:49.700]   Maybe a little boat.
[02:21:49.700 --> 02:21:50.700]   He's a character.
[02:21:50.700 --> 02:21:51.700]   He's a character.
[02:21:51.700 --> 02:21:52.700]   Wow.
[02:21:52.700 --> 02:21:53.700]   Yeah.
[02:21:53.700 --> 02:21:55.220]   That's all I gotta say.
[02:21:55.220 --> 02:21:56.220]   Yeah.
[02:21:56.220 --> 02:22:00.740]   Just thought I'd give you an update for those of you wondering, whatever happened to John
[02:22:00.740 --> 02:22:01.740]   McAfee.
[02:22:01.740 --> 02:22:05.260]   I just want to give you the...
[02:22:05.260 --> 02:22:15.220]   That was the famous joke about Paul Othilini, the late great CEO of Intel, who bewilderingly
[02:22:15.220 --> 02:22:17.420]   bought McAfee the company.
[02:22:17.420 --> 02:22:18.420]   Yeah.
[02:22:18.420 --> 02:22:24.620]   And the joke in journalism circles when I was in that world was always that, you know,
[02:22:24.620 --> 02:22:28.820]   Othilini yelled at his secretary and said, "Somebody get me McAfee Antivirus."
[02:22:28.820 --> 02:22:32.940]   He came back the whole company.
[02:22:32.940 --> 02:22:33.940]   We've got it for you, sir.
[02:22:33.940 --> 02:22:34.940]   It cost you however many.
[02:22:34.940 --> 02:22:37.940]   And he was like, "No, I'm in for my computer!"
[02:22:37.940 --> 02:22:42.260]   Because nobody could work out why you bought it at the time.
[02:22:42.260 --> 02:22:43.260]   Oh, no.
[02:22:43.260 --> 02:22:44.260]   And they sold it on.
[02:22:44.260 --> 02:22:45.580]   I think they lost a pretty penny on that.
[02:22:45.580 --> 02:22:47.300]   They sold it on.
[02:22:47.300 --> 02:22:49.300]   Yeah.
[02:22:49.300 --> 02:22:50.820]   I think we could wrap this up.
[02:22:50.820 --> 02:22:52.140]   I don't know about you.
[02:22:52.140 --> 02:22:57.060]   I'm excited I got to run home and see the last season ender of WandaVision.
[02:22:57.060 --> 02:22:58.060]   Ah.
[02:22:58.060 --> 02:23:00.140]   Well, we won't spoil it for you then.
[02:23:00.140 --> 02:23:01.780]   No, don't spoil it.
[02:23:01.780 --> 02:23:02.780]   Was it good, John?
[02:23:02.780 --> 02:23:03.780]   John's gone crazy.
[02:23:03.780 --> 02:23:04.780]   Pushing me to watch this.
[02:23:04.780 --> 02:23:07.460]   I had to sit through the first episode.
[02:23:07.460 --> 02:23:08.460]   What was it?
[02:23:08.460 --> 02:23:09.460]   Dick Van Dyke clone.
[02:23:09.460 --> 02:23:12.860]   And then the second episode was like, "This is awful."
[02:23:12.860 --> 02:23:15.900]   He did all the one thing to say.
[02:23:15.900 --> 02:23:16.900]   E.O.
[02:23:16.900 --> 02:23:17.900]   Ship of thesis.
[02:23:17.900 --> 02:23:18.900]   See again?
[02:23:18.900 --> 02:23:19.900]   Ship of thesis.
[02:23:19.900 --> 02:23:22.100]   No, no, no, no, no, no, no, no, John, don't say it.
[02:23:22.100 --> 02:23:23.100]   Don't say it.
[02:23:23.100 --> 02:23:24.340]   I don't know what that means, so you're safe.
[02:23:24.340 --> 02:23:25.820]   No, you'll get there.
[02:23:25.820 --> 02:23:26.820]   You'll get there.
[02:23:26.820 --> 02:23:29.540]   Also, you can go home and the, the Oztarg Games on tonight.
[02:23:29.540 --> 02:23:30.540]   I'm going to be staying.
[02:23:30.540 --> 02:23:32.540]   I'm staying up after this and watching the Oztarg Game.
[02:23:32.540 --> 02:23:34.300]   You're an NBA fan?
[02:23:34.300 --> 02:23:35.300]   Yeah.
[02:23:35.300 --> 02:23:37.580]   I didn't realize that.
[02:23:37.580 --> 02:23:41.020]   I've got, I've got some, I've got some money, some money riding on this.
[02:23:41.020 --> 02:23:42.580]   So this is going to be an exciting day.
[02:23:42.580 --> 02:23:44.580]   Team LeBron versus Team Durant.
[02:23:44.580 --> 02:23:49.260]   Well, it's not really Team Durant because Duran is not playing.
[02:23:49.260 --> 02:23:50.260]   Oh.
[02:23:50.260 --> 02:23:52.860]   And two people just got COVID it out this morning.
[02:23:52.860 --> 02:23:53.860]   Oh, wow.
[02:23:53.860 --> 02:23:56.700]   So, so it's going to be an interesting game for sure.
[02:23:56.700 --> 02:23:59.060]   Well, we know what you and I will be doing tonight.
[02:23:59.060 --> 02:24:01.340]   What about you, Lisa Schmeiser?
[02:24:01.340 --> 02:24:03.300]   Do you have anything on the agenda?
[02:24:03.300 --> 02:24:04.540]   Family dinner.
[02:24:04.540 --> 02:24:05.540]   That's about it.
[02:24:05.540 --> 02:24:08.380]   We usually try to have a family dinner in games on Sunday night as a way to wrap up
[02:24:08.380 --> 02:24:10.540]   the weekend and transition into a week.
[02:24:10.540 --> 02:24:12.740]   You're going to be watching the Megan and Harry interview?
[02:24:12.740 --> 02:24:13.740]   No.
[02:24:13.740 --> 02:24:14.740]   Oh my gosh.
[02:24:14.740 --> 02:24:15.740]   No.
[02:24:15.740 --> 02:24:19.260]   I'm going to wait for some site to do 10 things you should have seen in the Megan and Harry
[02:24:19.260 --> 02:24:23.380]   interview and it will take me 30 seconds to read the salient talking points and I will
[02:24:23.380 --> 02:24:24.380]   have.
[02:24:24.380 --> 02:24:25.380]   But it's Oprah.
[02:24:25.380 --> 02:24:26.380]   It's Oprah.
[02:24:26.380 --> 02:24:29.020]   I'm just teasing you.
[02:24:29.020 --> 02:24:33.580]   Alex, Alex, Lindsey, you're probably just going to do another three hours on office hours tonight.
[02:24:33.580 --> 02:24:35.260]   I thought I crossed my mind.
[02:24:35.260 --> 02:24:36.260]   Yeah.
[02:24:36.260 --> 02:24:37.260]   That's until tomorrow.
[02:24:37.260 --> 02:24:39.420]   We do do.
[02:24:39.420 --> 02:24:43.340]   We do Monday nights as well as the Monday mornings and then we do Wednesday.
[02:24:43.340 --> 02:24:49.100]   We do clubhouse as a test like we're playing with clubhouse and so it's so we've been trying
[02:24:49.100 --> 02:24:50.100]   that.
[02:24:50.100 --> 02:24:54.500]   But yeah, no tonight I during the commercial breaks I made bread.
[02:24:54.500 --> 02:24:55.500]   What?
[02:24:55.500 --> 02:24:57.900]   I saw you getting up.
[02:24:57.900 --> 02:25:01.620]   I was well I had to I had to need it a couple of times to get it to get it to where it needed
[02:25:01.620 --> 02:25:03.140]   to be so that we could have pizza.
[02:25:03.140 --> 02:25:04.540]   So so oh my God.
[02:25:04.540 --> 02:25:05.540]   That's awesome.
[02:25:05.540 --> 02:25:07.300]   I just was like I got to pull it out.
[02:25:07.300 --> 02:25:08.300]   I got it.
[02:25:08.300 --> 02:25:11.180]   Well, I had to I had to analyze it and then I had to do the fucking it was like I figured
[02:25:11.180 --> 02:25:13.180]   I got two minutes while Leo was talking to do it.
[02:25:13.180 --> 02:25:14.180]   This whole time.
[02:25:14.180 --> 02:25:17.340]   This is the COVID Alex has been punching his dough down the whole time.
[02:25:17.340 --> 02:25:21.940]   This is how Alex avoid zoom fatigue is he's making pizza in the middle of the way.
[02:25:21.940 --> 02:25:22.940]   That's the way.
[02:25:22.940 --> 02:25:25.140]   I think we need to study that.
[02:25:25.140 --> 02:25:31.580]   But I was my my wife reminded me that that is that she needed bread for this pizza right
[02:25:31.580 --> 02:25:36.220]   your turn to show and I was like, yeah, like it takes two and a half hours to rise and
[02:25:36.220 --> 02:25:40.900]   if I don't do it right now, there'll be a thing and that do you fancy pizza oven?
[02:25:40.900 --> 02:25:41.900]   I do.
[02:25:41.900 --> 02:25:42.900]   I have the uni.
[02:25:42.900 --> 02:25:45.540]   Oh, I got one too.
[02:25:45.540 --> 02:25:46.540]   Those are great.
[02:25:46.540 --> 02:25:47.900]   It uses pellets, right?
[02:25:47.900 --> 02:25:50.460]   No, no, I have the one that uses gas gas.
[02:25:50.460 --> 02:25:51.460]   Gas.
[02:25:51.460 --> 02:25:55.100]   Yes, I had the I had the one that made pellets and then they I love the pellet.
[02:25:55.100 --> 02:25:57.780]   When I get to 850 degrees, yeah.
[02:25:57.780 --> 02:25:58.780]   So does the gas one.
[02:25:58.780 --> 02:26:00.020]   It just but you just turn on little things.
[02:26:00.020 --> 02:26:01.500]   It's a little easier to just goes there.
[02:26:01.500 --> 02:26:02.500]   Yeah.
[02:26:02.500 --> 02:26:06.140]   So it's but yeah, so that but my wife makes ones that are kind of pan pizza that she makes
[02:26:06.140 --> 02:26:07.620]   that don't need.
[02:26:07.620 --> 02:26:10.700]   I make those ones, but she just makes these ones a different kind of it's a different
[02:26:10.700 --> 02:26:11.700]   kind of dough Leo.
[02:26:11.700 --> 02:26:14.460]   I make the this dough is for her pizzas.
[02:26:14.460 --> 02:26:16.420]   My dough is a lighter more Neopolitan.
[02:26:16.420 --> 02:26:21.900]   This is the this is the COVID reality is is the get really good at baking.
[02:26:21.900 --> 02:26:23.140]   Yeah, I know.
[02:26:23.140 --> 02:26:28.180]   I finally put my sourdough in the freezer and said no, in fact, I joined noom, you know,
[02:26:28.180 --> 02:26:29.180]   that diet program.
[02:26:29.180 --> 02:26:30.180]   It's not zoom.
[02:26:30.180 --> 02:26:33.460]   It's noom, but it's got the same fatigue.
[02:26:33.460 --> 02:26:38.180]   So because I have all the I have the COVID 20.
[02:26:38.180 --> 02:26:43.260]   We have gotten rid of I have to admit that we've gotten so good at cooking as a family.
[02:26:43.260 --> 02:26:44.260]   It's good.
[02:26:44.260 --> 02:26:45.260]   It's kind of it.
[02:26:45.260 --> 02:26:51.380]   Yeah, I don't think I don't I'm really interested to see how this all turns out in the future,
[02:26:51.380 --> 02:26:53.980]   because I just don't see us going out very often.
[02:26:53.980 --> 02:26:56.060]   Yeah, like I don't least this is it that last night.
[02:26:56.060 --> 02:26:57.700]   She said we haven't been eating that.
[02:26:57.700 --> 02:27:01.580]   It was take out, but we haven't been doing take out because we cook and it's fun.
[02:27:01.580 --> 02:27:02.580]   It's fun.
[02:27:02.580 --> 02:27:06.740]   And you know, we have a glass of wine and you have it make it and you talk about the day.
[02:27:06.740 --> 02:27:09.140]   And it's it's what everyone tells you know, you should learn.
[02:27:09.140 --> 02:27:13.900]   And the thing is, is that I cook a fair bit, but my wife didn't barely cook at all.
[02:27:13.900 --> 02:27:15.220]   And now she's really good.
[02:27:15.220 --> 02:27:16.300]   She's much better than I am.
[02:27:16.300 --> 02:27:19.140]   And so and so she so that's been the big turn.
[02:27:19.140 --> 02:27:21.140]   It's much better than I am cooking.
[02:27:21.140 --> 02:27:22.140]   Wow.
[02:27:22.140 --> 02:27:23.140]   So this is the gas uni.
[02:27:23.140 --> 02:27:24.780]   I have to take a look at that.
[02:27:24.780 --> 02:27:26.580]   Oh man, I have the pellet uni.
[02:27:26.580 --> 02:27:28.860]   Oh man, it's magical.
[02:27:28.860 --> 02:27:30.220]   It cooks it in a minute.
[02:27:30.220 --> 02:27:31.540]   Yeah, it's like a minute.
[02:27:31.540 --> 02:27:33.540]   Yeah, because it's so hot.
[02:27:33.540 --> 02:27:34.980]   Yeah, it's the best.
[02:27:34.980 --> 02:27:36.620]   It's so good.
[02:27:36.620 --> 02:27:41.660]   I have to get though, the mouth of that is a little too narrow for my pizza peel.
[02:27:41.660 --> 02:27:43.860]   You know, the thing is slide the pizza in.
[02:27:43.860 --> 02:27:46.260]   So I don't have to get a special narrow.
[02:27:46.260 --> 02:27:50.940]   Well, the other the other big thing though, Leo, is if you're so V, you can you can get
[02:27:50.940 --> 02:27:55.180]   that thing up to 900 degrees and take your steak and you can add a metal one.
[02:27:55.180 --> 02:27:56.180]   They have a metal one.
[02:27:56.180 --> 02:28:00.020]   You leave it in there for like an hour or not an hour, but like 20 minutes, 30 minutes
[02:28:00.020 --> 02:28:03.580]   while you're in right at the end of the sous vide, you just drop it on that pan.
[02:28:03.580 --> 02:28:07.580]   It sizzles and you push it in and just and again, a minute and a half and it's like
[02:28:07.580 --> 02:28:08.580]   that last night.
[02:28:08.580 --> 02:28:12.100]   Yeah, it's fired up the green egg though to do the final.
[02:28:12.100 --> 02:28:15.820]   Well, I used to do the great thing is that I realized how far I've come because that's
[02:28:15.820 --> 02:28:17.660]   what I was using before that was the big green egg.
[02:28:17.660 --> 02:28:20.860]   But the thing is, is now I've got this little gas thing that just does it really, really
[02:28:20.860 --> 02:28:21.860]   have to upgrade.
[02:28:21.860 --> 02:28:23.860]   Yeah, it's just I'm pretty easy.
[02:28:23.860 --> 02:28:27.780]   Yeah, it's it's like I can see a new show on the Twitter network.
[02:28:27.780 --> 02:28:28.780]   Oh, yeah.
[02:28:28.780 --> 02:28:29.780]   Every time we get together.
[02:28:29.780 --> 02:28:31.980]   Yeah, pandemic cooking baking.
[02:28:31.980 --> 02:28:32.980]   Yeah.
[02:28:32.980 --> 02:28:33.980]   Thank you, Alex.
[02:28:33.980 --> 02:28:35.980]   Thank you, oh, my gosh.
[02:28:35.980 --> 02:28:36.980]   Make weekly.
[02:28:36.980 --> 02:28:37.980]   Oh, my God.
[02:28:37.980 --> 02:28:38.980]   Oh, oh, quick.
[02:28:38.980 --> 02:28:39.980]   Get the URL.
[02:28:39.980 --> 02:28:40.980]   Yeah, exactly.
[02:28:40.980 --> 02:28:41.980]   I was before we just said it out loud.
[02:28:41.980 --> 02:28:42.980]   One and a half.
[02:28:42.980 --> 02:28:43.980]   Damn.
[02:28:43.980 --> 02:28:44.980]   Damn.
[02:28:44.980 --> 02:28:45.980]   One and a more about office hours.
[02:28:45.980 --> 02:28:46.980]   Go to YouTube.
[02:28:46.980 --> 02:28:51.980]  com/AlexLindsaylyndsay.
[02:28:51.980 --> 02:28:57.980]   There's a zoom link hidden there in the in the comments, but you can watch previous office
[02:28:57.980 --> 02:28:58.980]   hours.
[02:28:58.980 --> 02:29:01.780]   He only records one third of the total show.
[02:29:01.780 --> 02:29:05.380]   So if you started five, that's the pre pre show.
[02:29:05.380 --> 02:29:06.380]   Pacific time.
[02:29:06.380 --> 02:29:07.380]   Five a.m.
[02:29:07.380 --> 02:29:10.180]   The pre pre show and then there's six is the pre show and then seven to nine is the show
[02:29:10.180 --> 02:29:11.700]   that you see on YouTube.
[02:29:11.700 --> 02:29:13.140]   And then there's the post show that goes on.
[02:29:13.140 --> 02:29:16.820]   I usually just say hi to everybody and then they talk for hours.
[02:29:16.820 --> 02:29:17.820]   It's just amazing.
[02:29:17.820 --> 02:29:21.700]   It's mostly about production.
[02:29:21.700 --> 02:29:23.220]   But you have a band now.
[02:29:23.220 --> 02:29:25.220]   It's really kind of.
[02:29:25.220 --> 02:29:32.020]   We did three, three and a half hours or almost four hours of the band breaking down how they
[02:29:32.020 --> 02:29:33.020]   made the song.
[02:29:33.020 --> 02:29:35.780]   These are people that have never met the met each other.
[02:29:35.780 --> 02:29:36.780]   Amazing musicians.
[02:29:36.780 --> 02:29:42.740]   Like someone who professionally arranged the whole the whole piece and then there was,
[02:29:42.740 --> 02:29:48.340]   you know, saxophone and keyboard and drums and and and all kinds of instruments, you
[02:29:48.340 --> 02:29:50.100]   know, guitar, bass, everything.
[02:29:50.100 --> 02:29:53.820]   And they recorded it all separately and they brought it all back into logic and we had
[02:29:53.820 --> 02:29:59.100]   this incredible, you know, someone really mixed it up very professional mix.
[02:29:59.100 --> 02:30:00.700]   It sounds great.
[02:30:00.700 --> 02:30:01.700]   It sounds great.
[02:30:01.700 --> 02:30:05.460]   And then and then they, but then the best part is then they edited a video.
[02:30:05.460 --> 02:30:10.420]   They shot all shot a video and then it went to it got edited incredibly in final cut and
[02:30:10.420 --> 02:30:15.860]   then sent to resolve and then colored, you know, color corrected and resolved, you know,
[02:30:15.860 --> 02:30:18.460]   full quality.
[02:30:18.460 --> 02:30:19.660]   It's quite a thing to see.
[02:30:19.660 --> 02:30:22.740]   And so we're we're I'm just kind of amazed.
[02:30:22.740 --> 02:30:27.580]   The band just kind of literally just came out of the, you know, the ether, you know,
[02:30:27.580 --> 02:30:35.100]   there was a there was a couple of couple of folks, Grant and Victor did a Christmas song
[02:30:35.100 --> 02:30:37.940]   and then we were like, you know, we need a band and then they just made it, you know,
[02:30:37.940 --> 02:30:42.180]   now they're working on the next song and we've got, you know, other artists now talking
[02:30:42.180 --> 02:30:43.980]   about joining the band.
[02:30:43.980 --> 02:30:47.860]   So like, you know, like, you know, and so it's it's going to keep growing.
[02:30:47.860 --> 02:30:51.500]   It's cool because in order to do this, you also have to solve some significant technical
[02:30:51.500 --> 02:30:54.860]   issues to play simultaneously together and all that stuff.
[02:30:54.860 --> 02:30:58.460]   Well, they're not, you know, they're playing all the thing is is that they're incredible
[02:30:58.460 --> 02:31:00.300]   musicians, but they're also very technical.
[02:31:00.300 --> 02:31:04.820]   I mean, that's why they're in our group, you know, it's and so so it's it wasn't like,
[02:31:04.820 --> 02:31:09.220]   you know, they were trying to figure out how to do this, and then you everybody was doing
[02:31:09.220 --> 02:31:12.900]   something that was well within within their wheelhouse and they still had a lot to learn.
[02:31:12.900 --> 02:31:14.900]   But it's worth it.
[02:31:14.900 --> 02:31:19.660]   That is up on YouTube, I think, from from from yesterday and they went they spent like
[02:31:19.660 --> 02:31:23.940]   three and a half hours and then a week before they spent just an hour talking about it.
[02:31:23.940 --> 02:31:26.820]   But it amazing production process.
[02:31:26.820 --> 02:31:28.300]   And so it's it's an exciting.
[02:31:28.300 --> 02:31:30.620]   I don't know what it's a kind of a crazy community.
[02:31:30.620 --> 02:31:31.620]   There's 3000 people.
[02:31:31.620 --> 02:31:35.860]   There's a thousand people on on Discord and now again, between two and three hundred people
[02:31:35.860 --> 02:31:36.860]   show up every day.
[02:31:36.860 --> 02:31:37.860]   It's kind of a real party.
[02:31:37.860 --> 02:31:39.100]   I don't even know what to do with it.
[02:31:39.100 --> 02:31:40.100]   Yeah.
[02:31:40.100 --> 02:31:41.260]   YouTube.com/AlexLindsay.
[02:31:41.260 --> 02:31:44.700]   It pro today.
[02:31:44.700 --> 02:31:50.340]   I want to say magazine, but it's really it's a website used to used to be a magazine.
[02:31:50.340 --> 02:31:56.140]   I don't know if it feel like I had a glossy it pro today at some point, but I may be
[02:31:56.140 --> 02:31:57.140]   not be.
[02:31:57.140 --> 02:32:01.140]   No, no, Lisa, Lisa is senior editor there, Lisa Schmeiser.
[02:32:01.140 --> 02:32:05.300]   Do you want to plug the Girl Scout cookie cider and anything like that?
[02:32:05.300 --> 02:32:07.460]   You know, you could.
[02:32:07.460 --> 02:32:09.860]   I don't because I'd rather just plug the technology.
[02:32:09.860 --> 02:32:13.500]   I would have told everybody to go look for a cookie finder and support your local troop.
[02:32:13.500 --> 02:32:14.500]   There you go.
[02:32:14.500 --> 02:32:15.500]   Support your local troop.
[02:32:15.500 --> 02:32:17.340]   Lisa, great having you.
[02:32:17.340 --> 02:32:18.940]   So nice to see you.
[02:32:18.940 --> 02:32:23.980]   And my old buddy, Will Harris, I'll never forget the time Lisa and I were visiting London
[02:32:23.980 --> 02:32:30.860]   and we just ran into you like on the street, like no plan just ran into you.
[02:32:30.860 --> 02:32:33.900]   Like I know one guy lives in London and I met him.
[02:32:33.900 --> 02:32:35.420]   It's always a pleasure to see you.
[02:32:35.420 --> 02:32:38.380]   Intel, E-N-T-L-A-L-E is the new app.
[02:32:38.380 --> 02:32:39.380]   I've got it right here.
[02:32:39.380 --> 02:32:41.500]   I cannot wait to listen to it on the way home.
[02:32:41.500 --> 02:32:42.500]   Thank you.
[02:32:42.500 --> 02:32:45.820]   Give it a go and let me know what you think and love to hear from Twitter listeners.
[02:32:45.820 --> 02:32:50.740]   Just hit me up on @willharris with one L on Twitter and let me know what you think.
[02:32:50.740 --> 02:32:52.820]   Would love to hear some stories.
[02:32:52.820 --> 02:32:56.140]   ntail.com if you want to know more.
[02:32:56.140 --> 02:32:57.140]   Thank you for being here.
[02:32:57.140 --> 02:32:58.340]   Well, it's great to see you again.
[02:32:58.340 --> 02:32:59.340]   Thanks for having me.
[02:32:59.340 --> 02:33:06.100]   To this show every Sunday afternoon, round about 230 Pacific that's 530 Eastern.
[02:33:06.100 --> 02:33:11.600]   It's currently 2230, but we spring forward in a week.
[02:33:11.600 --> 02:33:17.980]   So that means we will set the clock forward so the UTC will go backward.
[02:33:17.980 --> 02:33:21.380]   That makes any sense to you than you're a better person than I.
[02:33:21.380 --> 02:33:25.020]   2100 UTC starting next week.
[02:33:25.020 --> 02:33:27.820]   That's only if you want to watch live and that really you don't have to do the math
[02:33:27.820 --> 02:33:29.060]   if you don't want to watch live.
[02:33:29.060 --> 02:33:32.660]   But the live stream is a Twit.tv/live.
[02:33:32.660 --> 02:33:33.660]   There is live audio.
[02:33:33.660 --> 02:33:35.340]   There's live video.
[02:33:35.340 --> 02:33:41.540]   If you're watching live chat with us live IRC.twit.tv after the fact, of course, at your own time
[02:33:41.540 --> 02:33:44.580]   in your own time frame, you can listen to the show anytime you want.
[02:33:44.580 --> 02:33:48.860]   We put all of our shows up on the website, Twit.tv so you can download audio or video
[02:33:48.860 --> 02:33:49.860]   there.
[02:33:49.860 --> 02:33:52.060]   There is a YouTube channel devoted to this week in tech.
[02:33:52.060 --> 02:33:57.780]   In fact, if you go to youtube.com/twit, you can find all of the shows we put up on YouTube.
[02:33:57.780 --> 02:34:01.860]   Including Twit Bits and Twit News events, our coverage of the Ignite Conference and so
[02:34:01.860 --> 02:34:04.380]   forth.
[02:34:04.380 --> 02:34:09.620]   But then the best way is to find a podcast application and subscribe that way.
[02:34:09.620 --> 02:34:10.620]   You will get it automatically.
[02:34:10.620 --> 02:34:15.300]   It's available after we finish editing at this evening.
[02:34:15.300 --> 02:34:17.900]   Download, subscribe and vote.
[02:34:17.900 --> 02:34:20.740]   Actually leave a review if your platform supports it.
[02:34:20.740 --> 02:34:22.740]   That's always great for us.
[02:34:22.740 --> 02:34:24.180]   Thank you all for being here.
[02:34:24.180 --> 02:34:25.180]   We'll see you next time.
[02:34:25.180 --> 02:34:31.220]   Another Twit.
[02:34:31.220 --> 02:34:37.260]   Alright.
[02:34:37.260 --> 02:34:59.820]   * Trusting that we don't have to worry about this*

