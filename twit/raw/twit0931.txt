;FFMETADATA1
title=Pork Pie For Your Ears
artist=Leo Laporte, Nicole Wakelin, Roberto Baldwin, Sam Abuelsamid
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2023-06-12
track=931
language=English
genre=Podcast
comment=<p>Apple Vision Pro, Reddit API fallout, Tesla Autopilot casualties, UFOs</p>\

encoded_by=Uniblab 5.3
date=2023
encoder=Lavf60.3.100

[00:00:00.000 --> 00:00:02.800]   It's time for "Twit This Week at Tech."
[00:00:02.800 --> 00:00:05.700]   And this week, it's a wheel bearings takeover.
[00:00:05.700 --> 00:00:09.100]   Sam Mabool Sam had has brought his co-host from the Wheel bearings podcast,
[00:00:09.100 --> 00:00:12.200]   Nicole Wakeland and Robbie Baldwin.
[00:00:12.200 --> 00:00:14.000]   And we have lots to talk about.
[00:00:14.000 --> 00:00:15.000]   Not just cars either.
[00:00:15.000 --> 00:00:17.800]   We're going to talk about Apple's Vision Pro headset
[00:00:17.800 --> 00:00:22.600]   and whether it really is the future, what's happening at Reddit, it's kind of shocking.
[00:00:22.600 --> 00:00:24.400]   There is some car news too though.
[00:00:24.400 --> 00:00:29.700]   Tesla's autopilot seems to be even more dangerous than Elon Musk admits.
[00:00:29.700 --> 00:00:33.900]   And is Elon about to take over EV charging nationwide?
[00:00:33.900 --> 00:00:35.000]   All of that and more.
[00:00:35.000 --> 00:00:37.500]   Coming up next on "Twit."
[00:00:37.500 --> 00:00:42.000]   Podcasts you love.
[00:00:42.000 --> 00:00:44.000]   From people you trust.
[00:00:44.000 --> 00:00:46.600]   This is "Twit."
[00:00:46.600 --> 00:00:55.000]   This is "Twit This Week at Tech."
[00:00:55.000 --> 00:01:00.700]   Episode 931 recorded Sunday, June 11, 2023.
[00:01:00.700 --> 00:01:02.700]   A pork pie for your ears.
[00:01:02.700 --> 00:01:07.600]   This episode of "Twit This Week in Tech" is brought to you by decisions.
[00:01:07.600 --> 00:01:10.100]   Don't let complexity block your company's growth.
[00:01:10.100 --> 00:01:13.300]   Decisions rules-based process automation software
[00:01:13.300 --> 00:01:16.300]   allows you to manage a complex digital landscape.
[00:01:16.300 --> 00:01:19.400]   Build custom workflows, business rules software,
[00:01:19.400 --> 00:01:21.500]   modernize legacy systems,
[00:01:21.500 --> 00:01:26.600]   and improve customer experiences in decisions unified, no-code platform.
[00:01:26.600 --> 00:01:33.000]   Visit decisions.com/twit to learn how automating anything can change everything.
[00:01:33.000 --> 00:01:36.700]   And by "ZIP Recruiter."
[00:01:36.700 --> 00:01:40.500]   Did you know that hiring can take up to 11 weeks on average?
[00:01:40.500 --> 00:01:42.600]   You have that time to wait a course not.
[00:01:42.600 --> 00:01:45.600]   Stop waiting and start using "ZIP Recruiter."
[00:01:45.600 --> 00:01:49.800]   "ZIP Recruiter" helps you find qualified candidates for all your roles fast.
[00:01:49.800 --> 00:01:54.800]   And right now you can try it free at zipprecruiter.com/twit.
[00:01:54.800 --> 00:01:57.400]   And by "Miro."
[00:01:57.400 --> 00:02:03.500]   "Miro" is your team's online workspace to connect, collaborate, and create together.
[00:02:03.500 --> 00:02:07.900]   Tap into a way to map processes, systems, and plans with the whole team.
[00:02:07.900 --> 00:02:12.000]   And get your first three boards for free to start creating your best work yet
[00:02:12.000 --> 00:02:15.500]   at "Miro.com/podcast."
[00:02:15.500 --> 00:02:18.300]   And by "Lookout."
[00:02:18.300 --> 00:02:23.600]   Whether on a device or in the cloud, your business data is always on the move.
[00:02:23.600 --> 00:02:30.100]   Minimize risk, increase visibility, and ensure compliance with "Lookout's Unified Platform."
[00:02:30.100 --> 00:02:32.800]   Visit lookout.com today.
[00:02:32.800 --> 00:02:41.600]   It's time for "Twit" this week in Tech.
[00:02:41.600 --> 00:02:46.300]   Shall we get together with my favorite tech journalist to talk about the weeks?
[00:02:46.300 --> 00:02:51.700]   Tech News, what a week it has been, and what a week to have a takeover.
[00:02:51.700 --> 00:02:58.300]   This week we are being taken over by the "Wheel bearings Podcast" at wheelbearings.media.
[00:02:58.300 --> 00:03:01.600]   Now you know Samable Samad because Sam's on all the time.
[00:03:01.600 --> 00:03:05.000]   He is a principal analyst at "Guide House Insights."
[00:03:05.000 --> 00:03:10.000]   He is the host of "Wheel bearings Podcast" and is a regular on all of our shows.
[00:03:10.000 --> 00:03:15.000]   Sam, introduce your co-hosts.
[00:03:15.000 --> 00:03:19.000]   Well, joining us today, Leo, is Nicole Wakeland.
[00:03:19.000 --> 00:03:20.500]   Hi, Nicole.
[00:03:20.500 --> 00:03:21.500]   Hey, Leo.
[00:03:21.500 --> 00:03:22.500]   How you doing?
[00:03:22.500 --> 00:03:23.500]   In New Hampshire.
[00:03:23.500 --> 00:03:24.500]   In New Hampshire.
[00:03:24.500 --> 00:03:25.500]   All right.
[00:03:25.500 --> 00:03:30.600]   Nicole is one of the co-hosts of "Wheel bearings" and a freelance automotive journalist
[00:03:30.600 --> 00:03:33.000]   so you can find your buy line all over the place.
[00:03:33.000 --> 00:03:39.000]   And also is Roberto Baldwin, who the audience probably already knows.
[00:03:39.000 --> 00:03:40.000]   We know Roberto.
[00:03:40.000 --> 00:03:41.300]   I need no need for introduction.
[00:03:41.300 --> 00:03:44.800]   The only reason I'm doing the takeover is because I've been trying to get
[00:03:44.800 --> 00:03:48.800]   Roberto back on the show for probably 10 years.
[00:03:48.800 --> 00:03:53.800]   And I finally figured out how I get your co-horts to strong army into it.
[00:03:53.800 --> 00:03:55.600]   Yeah, I'm sorry.
[00:03:55.600 --> 00:03:57.300]   Roberto, it's great to see you.
[00:03:57.300 --> 00:03:58.300]   No, you're not sorry.
[00:03:58.300 --> 00:03:59.300]   It's fine.
[00:03:59.300 --> 00:04:00.300]   It's great to see you.
[00:04:00.300 --> 00:04:02.800]   We used to have Roberto on when he was gamefully employed.
[00:04:02.800 --> 00:04:04.800]   But then once you became freelance, you had to work.
[00:04:04.800 --> 00:04:05.800]   You had to freelance it.
[00:04:05.800 --> 00:04:09.800]   Every weekend's your work.
[00:04:09.800 --> 00:04:10.800]   Yeah.
[00:04:10.800 --> 00:04:11.800]   You're working.
[00:04:11.800 --> 00:04:12.800]   Yeah.
[00:04:12.800 --> 00:04:13.800]   Not to mention he's got five, count them five cover bands.
[00:04:13.800 --> 00:04:14.800]   Five cover bands.
[00:04:14.800 --> 00:04:16.800]   What are your cover bands?
[00:04:16.800 --> 00:04:18.800]   I have five bands.
[00:04:18.800 --> 00:04:20.800]   I have a daff punk thing.
[00:04:20.800 --> 00:04:24.800]   Yeah, I think your helmet's over there on your left if you ever want to put that on.
[00:04:24.800 --> 00:04:26.800]   There's an old helmet.
[00:04:26.800 --> 00:04:27.800]   That's like the Mark II.
[00:04:27.800 --> 00:04:29.800]   It's paper mache.
[00:04:29.800 --> 00:04:32.800]   So it's sort of collapsing upon itself.
[00:04:32.800 --> 00:04:35.800]   The new ones have like, are you a thing in resin?
[00:04:35.800 --> 00:04:36.800]   It's a whole one.
[00:04:36.800 --> 00:04:37.800]   You should come on on.
[00:04:37.800 --> 00:04:39.800]   At some point you need to just wear it.
[00:04:39.800 --> 00:04:40.800]   Okay.
[00:04:40.800 --> 00:04:41.800]   So there's the daffy.
[00:04:41.800 --> 00:04:42.800]   There's the daffy.
[00:04:42.800 --> 00:04:43.800]   The daffy on the car band.
[00:04:43.800 --> 00:04:44.800]   Yeah.
[00:04:44.800 --> 00:04:45.800]   There's the Divo band.
[00:04:45.800 --> 00:04:46.800]   Divo.
[00:04:46.800 --> 00:04:47.800]   Urban robot.
[00:04:47.800 --> 00:04:48.800]   Do you have flower pots for that?
[00:04:48.800 --> 00:04:50.800]   Yeah, you can see it up on the shelf.
[00:04:50.800 --> 00:04:52.800]   You only do bands that wear hats?
[00:04:52.800 --> 00:04:54.600]   I don't wear hats.
[00:04:54.600 --> 00:04:55.800]   That's the weird thing.
[00:04:55.800 --> 00:04:56.800]   I don't want.
[00:04:56.800 --> 00:04:57.800]   Okay.
[00:04:57.800 --> 00:05:01.800]   There is the newest band, which is the Becky Boys.
[00:05:01.800 --> 00:05:07.800]   The Becky is a Beck/Bisty Boys cover band.
[00:05:07.800 --> 00:05:12.480]   Because the Venn diagram of people who like Beck and the Bisty Boys is essentially a circle.
[00:05:12.480 --> 00:05:17.720]   And then there's the big band, the one that everyone actually gives us money for.
[00:05:17.720 --> 00:05:18.720]   North American Scum.
[00:05:18.720 --> 00:05:23.720]   And that's the Talking Heads and/or LCD Sound System cover band.
[00:05:23.720 --> 00:05:25.400]   Oh my God.
[00:05:25.400 --> 00:05:31.600]   And then finally, number five is Drastic Cats, which is an original band.
[00:05:31.600 --> 00:05:35.680]   It's a chaos band, is what me and the other person who are in it, because it's just pure
[00:05:35.680 --> 00:05:36.680]   chaos.
[00:05:36.680 --> 00:05:38.120]   And you can just look at DrasticCats.com.
[00:05:38.120 --> 00:05:39.480]   We're on Bandcamp.
[00:05:39.480 --> 00:05:41.600]   And every song is a different genre.
[00:05:41.600 --> 00:05:43.920]   It's all chaos.
[00:05:43.920 --> 00:05:46.760]   We write and record songs in about an hour.
[00:05:46.760 --> 00:05:47.760]   Do you?
[00:05:47.760 --> 00:05:48.760]   Wow.
[00:05:48.760 --> 00:05:49.760]   And you're the singer in these bands.
[00:05:49.760 --> 00:05:52.000]   Do you play an instrument?
[00:05:52.000 --> 00:05:55.600]   I play bass, guitar, drums.
[00:05:55.600 --> 00:05:58.040]   Oh, you're a man of many talents.
[00:05:58.040 --> 00:06:00.280]   I play all those things.
[00:06:00.280 --> 00:06:02.280]   I'm not good at them.
[00:06:02.280 --> 00:06:04.560]   Play poorly.
[00:06:04.560 --> 00:06:05.560]   Okay.
[00:06:05.560 --> 00:06:07.440]   I collect musicians like other people.
[00:06:07.440 --> 00:06:08.840]   It's like most modern bands.
[00:06:08.840 --> 00:06:09.840]   Yeah.
[00:06:09.840 --> 00:06:12.040]   I collect really good musicians.
[00:06:12.040 --> 00:06:13.040]   That's what I'm really good at.
[00:06:13.040 --> 00:06:16.000]   I'm really good at collecting musicians like their Pokemon.
[00:06:16.000 --> 00:06:17.840]   Like I just got to catch them all.
[00:06:17.840 --> 00:06:19.600]   And then I force them into my bands.
[00:06:19.600 --> 00:06:20.600]   Perfect.
[00:06:20.600 --> 00:06:21.600]   For a slaver.
[00:06:21.600 --> 00:06:22.600]   Perfect.
[00:06:22.600 --> 00:06:27.520]   It's actually cool because Roberto, he's kind of like a Renaissance man for our times
[00:06:27.520 --> 00:06:31.840]   because you used to write for TMZ doing celebrity gossip, right?
[00:06:31.840 --> 00:06:33.160]   He did not.
[00:06:33.160 --> 00:06:34.160]   Did you really?
[00:06:34.160 --> 00:06:35.160]   Yeah.
[00:06:35.160 --> 00:06:36.160]   I didn't know that.
[00:06:36.160 --> 00:06:38.160]   I was an employee like number four.
[00:06:38.160 --> 00:06:39.160]   Wow.
[00:06:39.160 --> 00:06:40.160]   I'm sorry.
[00:06:40.160 --> 00:06:42.680]   I didn't mean to have you.
[00:06:42.680 --> 00:06:45.680]   I didn't realize it was a secret.
[00:06:45.680 --> 00:06:46.680]   And then you...
[00:06:46.680 --> 00:06:47.680]   I heard that one before.
[00:06:47.680 --> 00:06:48.680]   Yeah.
[00:06:48.680 --> 00:06:50.840]   And you started to talk on our show because you were a tech writer.
[00:06:50.840 --> 00:06:57.720]   But you focus now on cars and all three of you drive different cars pretty much every
[00:06:57.720 --> 00:06:58.720]   week.
[00:06:58.720 --> 00:07:01.400]   What are you driving today, Nicole?
[00:07:01.400 --> 00:07:06.120]   I have a linking Corsair plug-in hybrid.
[00:07:06.120 --> 00:07:07.120]   Nice.
[00:07:07.120 --> 00:07:08.120]   Yeah.
[00:07:08.120 --> 00:07:09.120]   I like a new pants car.
[00:07:09.120 --> 00:07:10.120]   I do.
[00:07:10.120 --> 00:07:11.120]   I like plug-in hybrids.
[00:07:11.120 --> 00:07:12.120]   I think they're the good, happy medium.
[00:07:12.120 --> 00:07:15.480]   If you're like afraid of EVs and you don't want to have a gas car.
[00:07:15.480 --> 00:07:18.600]   And I like the Lincoln's all fancy.
[00:07:18.600 --> 00:07:22.920]   They have an adjustable seat and there's a separate thing for each of your thighs.
[00:07:22.920 --> 00:07:25.480]   Like you want your left side of your right side.
[00:07:25.480 --> 00:07:26.480]   You can plan.
[00:07:26.480 --> 00:07:27.480]   I'm like, who does that?
[00:07:27.480 --> 00:07:29.280]   Each side has its own seat.
[00:07:29.280 --> 00:07:32.440]   It each has its own little adjustable thing.
[00:07:32.440 --> 00:07:36.880]   So your thigh support can be like, I want my right leg, like a centimeter higher than
[00:07:36.880 --> 00:07:37.880]   my left leg.
[00:07:37.880 --> 00:07:41.560]   I don't, I play with them like this just feels weird, but in the same.
[00:07:41.560 --> 00:07:42.880]   Nobody has a symmetrical body.
[00:07:42.880 --> 00:07:44.560]   So you have to have asymmetrical.
[00:07:44.560 --> 00:07:45.560]   Yeah.
[00:07:45.560 --> 00:07:47.800]   I guess, but I don't mean like you ever just did.
[00:07:47.800 --> 00:07:50.320]   I've never seen a car with separate thigh seats before.
[00:07:50.320 --> 00:07:53.760]   It's like separate, so while you need to go find yourself a Lincoln Corsair plug-in hybrid.
[00:07:53.760 --> 00:07:55.240]   And then you can put it with a value.
[00:07:55.240 --> 00:07:58.720]   And yeah, if you're in New Hampshire and it's cold, I think a plug-in hybrid probably is
[00:07:58.720 --> 00:08:02.280]   a good idea because your range varies with the temperature.
[00:08:02.280 --> 00:08:04.560]   And this way you know you're not going to get stranded.
[00:08:04.560 --> 00:08:05.560]   Right.
[00:08:05.560 --> 00:08:09.120]   And it does even with that, I can see it come way down as soon as it's chilly out.
[00:08:09.120 --> 00:08:12.360]   But it's not a big deal because there's that gas engine is back up.
[00:08:12.360 --> 00:08:14.240]   So you don't have a panic attack.
[00:08:14.240 --> 00:08:15.240]   What about you, Sam?
[00:08:15.240 --> 00:08:16.240]   What are you driving?
[00:08:16.240 --> 00:08:20.600]   I currently have a Ford Maverick tremor in the driveway.
[00:08:20.600 --> 00:08:23.960]   That seems like the downside of being an auto-turtle.
[00:08:23.960 --> 00:08:27.840]   Actually, I all of us really love the Maverick.
[00:08:27.840 --> 00:08:32.560]   It is like, yeah, it is actually the perfect truck for most people.
[00:08:32.560 --> 00:08:36.160]   Okay, most people do not belong in a full-size pickup.
[00:08:36.160 --> 00:08:39.360]   You know, they want something to offer mulch every once in a while.
[00:08:39.360 --> 00:08:46.600]   I see people downtown San Francisco driving an eight-foot-tall four-wheel truck with a
[00:08:46.600 --> 00:08:48.000]   snorkel.
[00:08:48.000 --> 00:08:52.560]   And I'm thinking, dude, you're going to work in back from Daily City.
[00:08:52.560 --> 00:08:53.560]   What do you do?
[00:08:53.560 --> 00:08:55.840]   What is they driving to the Bay by accident?
[00:08:55.840 --> 00:08:56.840]   It's true.
[00:08:56.840 --> 00:08:57.840]   They don't know.
[00:08:57.840 --> 00:08:58.840]   They don't know.
[00:08:58.840 --> 00:08:59.840]   They don't know.
[00:08:59.840 --> 00:09:00.840]   That's true.
[00:09:00.840 --> 00:09:02.840]   I think if you want to just bring some anti-taxle.
[00:09:02.840 --> 00:09:04.960]   It's a little compact truck.
[00:09:04.960 --> 00:09:08.840]   It's got a big enough bed for most of the stuff you're ever going to want to do.
[00:09:08.840 --> 00:09:12.480]   It's got room for room in the cab for four people.
[00:09:12.480 --> 00:09:15.840]   And you can get really ridiculously cheap.
[00:09:15.840 --> 00:09:21.760]   The Bay's Maverick now starts at $22,000 for a hybrid that gets 40 miles per gallon.
[00:09:21.760 --> 00:09:22.760]   Wow.
[00:09:22.760 --> 00:09:23.760]   See that's...
[00:09:23.760 --> 00:09:24.760]   My next door neighbors have one.
[00:09:24.760 --> 00:09:25.760]   They love it.
[00:09:25.760 --> 00:09:26.760]   It's smart.
[00:09:26.760 --> 00:09:27.760]   Yeah.
[00:09:27.760 --> 00:09:28.760]   Smart.
[00:09:28.760 --> 00:09:32.880]   My Igor says that your next band should be called Thigh Support.
[00:09:32.880 --> 00:09:33.880]   Which I think is Thigh Support.
[00:09:33.880 --> 00:09:34.880]   It's really true.
[00:09:34.880 --> 00:09:36.440]   They'll always play as air supply.
[00:09:36.440 --> 00:09:37.440]   Yeah.
[00:09:37.440 --> 00:09:38.440]   Thigh Support.
[00:09:38.440 --> 00:09:39.440]   There you go.
[00:09:39.440 --> 00:09:40.480]   Now I saved the best for last.
[00:09:40.480 --> 00:09:42.000]   Robbie, what are you driving?
[00:09:42.000 --> 00:09:45.120]   Which one am I the best or is the car the best?
[00:09:45.120 --> 00:09:46.840]   You're the best, baby.
[00:09:46.840 --> 00:09:48.520]   Yeah.
[00:09:48.520 --> 00:09:52.720]   I am driving a Lamborghini Huracan Technica.
[00:09:52.720 --> 00:09:53.720]   Oh, yeah.
[00:09:53.720 --> 00:09:54.720]   Which is...
[00:09:54.720 --> 00:09:58.720]   It's pretty much just like the Lincoln, you know, of course, here.
[00:09:58.720 --> 00:09:59.720]   Exactly the same.
[00:09:59.720 --> 00:10:00.880]   There's almost no difference.
[00:10:00.880 --> 00:10:01.880]   No difference.
[00:10:01.880 --> 00:10:02.880]   They both have steering wheels.
[00:10:02.880 --> 00:10:03.880]   Yeah.
[00:10:03.880 --> 00:10:04.880]   They both have four wheels and tires.
[00:10:04.880 --> 00:10:05.880]   Do you have...
[00:10:05.880 --> 00:10:06.880]   Does yours have Thigh Support?
[00:10:06.880 --> 00:10:07.880]   Yeah.
[00:10:07.880 --> 00:10:08.880]   No, no.
[00:10:08.880 --> 00:10:09.880]   Oh, wow.
[00:10:09.880 --> 00:10:11.280]   It doesn't have sport seats that are built for something.
[00:10:11.280 --> 00:10:12.280]   What color is it?
[00:10:12.280 --> 00:10:13.280]   Lime green.
[00:10:13.280 --> 00:10:14.280]   What color is it?
[00:10:14.280 --> 00:10:16.080]   It's a matte gray.
[00:10:16.080 --> 00:10:17.080]   Oh.
[00:10:17.080 --> 00:10:18.080]   It's...
[00:10:18.080 --> 00:10:21.920]   Which is nice because I can hide it between my two cars in my driveway when people drive
[00:10:21.920 --> 00:10:24.720]   by so they're not like, "Whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa,
[00:10:24.720 --> 00:10:25.920]   what's going on in the house?
[00:10:25.920 --> 00:10:28.680]   Are you having a midlife crisis or what?
[00:10:28.680 --> 00:10:33.760]   I mean, if you got to park your Lamborghini outside in the driveway, you definitely want
[00:10:33.760 --> 00:10:36.320]   something that's not going to attract too much attention.
[00:10:36.320 --> 00:10:37.320]   Yeah.
[00:10:37.320 --> 00:10:38.320]   That's probably...
[00:10:38.320 --> 00:10:39.320]   That's the auto writer's special color.
[00:10:39.320 --> 00:10:40.320]   Yeah.
[00:10:40.320 --> 00:10:42.000]   Neutral gray.
[00:10:42.000 --> 00:10:47.160]   So while there are many car stories, and we will get to those a little bit because I
[00:10:47.160 --> 00:10:51.960]   got the wheel bearings folks here, I think probably there are two big stories of the
[00:10:51.960 --> 00:10:54.320]   week that have nothing to do with automotive technology.
[00:10:54.320 --> 00:11:00.120]   One is Apple's WWDC was on Monday and they finally announced the Mac Pro.
[00:11:00.120 --> 00:11:01.120]   No, no.
[00:11:01.120 --> 00:11:03.560]   Well, actually they did finally announce the Mac Pro, but nobody paid anything.
[00:11:03.560 --> 00:11:06.360]   Basically it's a giant case with a little Mac mini in that one.
[00:11:06.360 --> 00:11:08.280]   Yeah, it could be a Mac mini basically.
[00:11:08.280 --> 00:11:11.800]   But they announced their nerd goggles.
[00:11:11.800 --> 00:11:14.000]   They call it the Vision Pro.
[00:11:14.000 --> 00:11:17.520]   The operating system is the Vision OS.
[00:11:17.520 --> 00:11:22.960]   Although we had heard all these wild trademarks that they were, including, I think everybody
[00:11:22.960 --> 00:11:25.600]   thought it was going to be XROS and it turns out in one of the...
[00:11:25.600 --> 00:11:26.600]   A reality OS.
[00:11:26.600 --> 00:11:27.600]   A reality OS.
[00:11:27.600 --> 00:11:33.640]   One of the breakouts actually, all the slides said XROS and the presenter said XR.
[00:11:33.640 --> 00:11:36.160]   So that must have been the internal code name.
[00:11:36.160 --> 00:11:38.920]   But Vision OS is the final name.
[00:11:38.920 --> 00:11:43.360]   And you know, the bottom line, which you probably already know because everybody's been talking
[00:11:43.360 --> 00:11:49.840]   about it, is it's $3500 and it won't be available to early next year.
[00:11:49.840 --> 00:11:53.280]   In other words, it's a ways off.
[00:11:53.280 --> 00:11:55.160]   But I would be interested in your thoughts.
[00:11:55.160 --> 00:11:56.800]   Nicole, why don't you kick it off?
[00:11:56.800 --> 00:11:58.640]   I don't know if this isn't your normal beat.
[00:11:58.640 --> 00:11:59.640]   I know.
[00:11:59.640 --> 00:12:03.840]   Okay, so I look at this and the first thing I see are goggles for going when you're skiing.
[00:12:03.840 --> 00:12:05.520]   They look like ski goggles.
[00:12:05.520 --> 00:12:06.520]   They look like ski goggles.
[00:12:06.520 --> 00:12:07.520]   You're right.
[00:12:07.520 --> 00:12:11.240]   That's what they look like, which I would never want to wear unless I was actually skiing
[00:12:11.240 --> 00:12:14.400]   because I feel like they'd be weird intrusive.
[00:12:14.400 --> 00:12:19.800]   That is kind of the test is like, would you wear ski goggles around the house or in...
[00:12:19.800 --> 00:12:24.160]   I don't generally, generally when I'm not skiing, they are not out in the snow.
[00:12:24.160 --> 00:12:25.160]   I don't wear ski goggles.
[00:12:25.160 --> 00:12:31.600]   I mean, really they're, yay, they're cool and nerdy, but $3500 for fancy ski goggles is
[00:12:31.600 --> 00:12:33.040]   not going to be my thing.
[00:12:33.040 --> 00:12:37.800]   And one thing ski goggles don't have is a wire off the back to a battery in your butt.
[00:12:37.800 --> 00:12:38.800]   And really...
[00:12:38.800 --> 00:12:39.800]   Did they start the battery?
[00:12:39.800 --> 00:12:43.080]   Well, wherever you put it, you can put it anywhere.
[00:12:43.080 --> 00:12:44.080]   You want it.
[00:12:44.080 --> 00:12:45.080]   You put it in your pocket, Rosie.
[00:12:45.080 --> 00:12:46.080]   I don't know.
[00:12:46.080 --> 00:12:47.080]   I've got the presentation.
[00:12:47.080 --> 00:12:51.480]   Remember that portion of the presentation at all.
[00:12:51.480 --> 00:12:52.480]   The other...
[00:12:52.480 --> 00:12:54.360]   Well, the wire always goes behind.
[00:12:54.360 --> 00:12:55.360]   I don't know why.
[00:12:55.360 --> 00:13:00.280]   I guess they just, they want you to have it back there somewhere in your hip pocket.
[00:13:00.280 --> 00:13:01.280]   But then the other thing that your goggles...
[00:13:01.280 --> 00:13:03.360]   You don't want you to get your hands tangled up in it.
[00:13:03.360 --> 00:13:04.600]   Oh, that's why.
[00:13:04.600 --> 00:13:05.600]   Sure.
[00:13:05.600 --> 00:13:06.600]   Okay, that makes sense.
[00:13:06.600 --> 00:13:07.600]   It's like a tail.
[00:13:07.600 --> 00:13:13.720]   And the other thing, and I swear to God, I think this is creepy is these eyes in the
[00:13:13.720 --> 00:13:14.720]   front.
[00:13:14.720 --> 00:13:16.640]   They're weird.
[00:13:16.640 --> 00:13:20.120]   I just don't like them.
[00:13:20.120 --> 00:13:24.560]   They're using lenticular screens.
[00:13:24.560 --> 00:13:30.080]   So when they record your eyes, or when they model your eyes, because these aren't...
[00:13:30.080 --> 00:13:32.320]   This isn't exactly a picture of your eyes.
[00:13:32.320 --> 00:13:34.280]   They have cameras facing you.
[00:13:34.280 --> 00:13:37.600]   But it is somehow modeled.
[00:13:37.600 --> 00:13:41.000]   They record a variety of angles.
[00:13:41.000 --> 00:13:44.880]   And then depending on how you're viewing these, you'll get a different angle up to 16 different
[00:13:44.880 --> 00:13:47.160]   angles of these eyes.
[00:13:47.160 --> 00:13:51.800]   And the eyes do mirror whether you're blinking or whatever else you do with your eyes.
[00:13:51.800 --> 00:13:52.800]   They mirror that.
[00:13:52.800 --> 00:13:55.000]   But I don't think it's a direct image from your eyes.
[00:13:55.000 --> 00:13:57.120]   I think it's generated somehow.
[00:13:57.120 --> 00:14:06.040]   I think they use the internal cameras to track where you're looking and what your expression
[00:14:06.040 --> 00:14:07.040]   is.
[00:14:07.040 --> 00:14:09.640]   And then replicate that in the screen.
[00:14:09.640 --> 00:14:15.640]   And using those lenticular lenses, try to make it look as if your eyes are actually back
[00:14:15.640 --> 00:14:19.840]   at the level of your face rather than on the outer surface of the goggles.
[00:14:19.840 --> 00:14:20.840]   Yes.
[00:14:20.840 --> 00:14:21.840]   There's this depth.
[00:14:21.840 --> 00:14:22.840]   Because that would look even weirder.
[00:14:22.840 --> 00:14:23.840]   It's weird anyway.
[00:14:23.840 --> 00:14:24.840]   Yeah.
[00:14:24.840 --> 00:14:30.320]   I wonder if you end up with that weird 50 yard or 1000 yard stare from the Polar Express
[00:14:30.320 --> 00:14:31.320]   movies.
[00:14:31.320 --> 00:14:32.320]   Yeah.
[00:14:32.320 --> 00:14:33.320]   It's uncanny valley.
[00:14:33.320 --> 00:14:34.320]   Yeah.
[00:14:34.320 --> 00:14:35.320]   You can't tell where the person is.
[00:14:35.320 --> 00:14:36.320]   Oh, look at how big that is in the back.
[00:14:36.320 --> 00:14:37.320]   I didn't even catch it.
[00:14:37.320 --> 00:14:38.560]   It's not even a fit.
[00:14:38.560 --> 00:14:40.320]   It's a huge band in the back.
[00:14:40.320 --> 00:14:43.680]   That's so you don't get dense in your hair, I guess.
[00:14:43.680 --> 00:14:44.680]   I don't know.
[00:14:44.680 --> 00:14:46.480]   There's also and they never showed it.
[00:14:46.480 --> 00:14:48.480]   They're trying to spread out the load.
[00:14:48.480 --> 00:14:49.480]   Yes.
[00:14:49.480 --> 00:14:50.480]   There's spread out the load.
[00:14:50.480 --> 00:14:53.080]   It's basically like separate thigh support.
[00:14:53.080 --> 00:14:55.920]   And then like one thigh other thigh.
[00:14:55.920 --> 00:14:58.560]   And then actually this would fit your thigh quite nicely.
[00:14:58.560 --> 00:15:00.800]   And then they're and they never showed it.
[00:15:00.800 --> 00:15:06.200]   There's another strap goes over the top, which a number of this optional on for instance,
[00:15:06.200 --> 00:15:09.920]   the Oculus pros to relieve some of the weight.
[00:15:09.920 --> 00:15:14.440]   These weigh about a pound, I'm told although Apple did not say.
[00:15:14.440 --> 00:15:17.440]   But that's not an insignificant amount of weight.
[00:15:17.440 --> 00:15:20.680]   If your ski goal was weight of pound, you would not like them.
[00:15:20.680 --> 00:15:22.000]   You would not like for your ski goal.
[00:15:22.000 --> 00:15:24.360]   You want them to be as light as they possibly can be.
[00:15:24.360 --> 00:15:25.360]   Yeah.
[00:15:25.360 --> 00:15:29.480]   This is, this is, there's another like, I feel like it's not making me think of a CPAP machine
[00:15:29.480 --> 00:15:31.200]   where it's like you're all strapped in.
[00:15:31.200 --> 00:15:32.200]   Yeah.
[00:15:32.200 --> 00:15:33.200]   But you'll never snore again.
[00:15:33.200 --> 00:15:34.200]   You'll never snore again.
[00:15:34.200 --> 00:15:40.000]   Or, or because of the way you look, no one's ever going to be where they can hear you.
[00:15:40.000 --> 00:15:41.000]   That's true.
[00:15:41.000 --> 00:15:42.000]   You will be sleeping alone.
[00:15:42.000 --> 00:15:43.000]   Yeah.
[00:15:43.000 --> 00:15:44.000]   Forever.
[00:15:44.000 --> 00:15:47.640]   A lot of divorce papers filed right after this just hits the market.
[00:15:47.640 --> 00:15:50.000]   Like no, no, that's not what I signed up for.
[00:15:50.000 --> 00:15:51.000]   I'm sorry.
[00:15:51.000 --> 00:15:52.600]   I don't care better where we're sold on.
[00:15:52.600 --> 00:15:55.360]   I do, do any of you thirst for these?
[00:15:55.360 --> 00:15:56.360]   Is this something?
[00:15:56.360 --> 00:15:57.360]   No.
[00:15:57.360 --> 00:15:58.360]   No.
[00:15:58.360 --> 00:15:59.360]   No.
[00:15:59.360 --> 00:16:01.000]   I don't want a hot computer on my face.
[00:16:01.000 --> 00:16:03.800]   I'm not, I'm not a fan of hot things on my face.
[00:16:03.800 --> 00:16:05.520]   That's okay because there's a fan in there.
[00:16:05.520 --> 00:16:08.720]   Apparently, Apple again is not revealing it, but there's, there are openings.
[00:16:08.720 --> 00:16:10.440]   They talk about cooling openings.
[00:16:10.440 --> 00:16:13.480]   I think there has to be a fan in it, but again, no one's.
[00:16:13.480 --> 00:16:17.040]   No, they've said there, there is definitely a fan in there.
[00:16:17.040 --> 00:16:18.040]   Okay.
[00:16:18.040 --> 00:16:19.040]   All right.
[00:16:19.040 --> 00:16:22.520]   And the fan, I guess the intakes are on the bottom of the goggles and then it blows the
[00:16:22.520 --> 00:16:23.520]   hot air out the top.
[00:16:23.520 --> 00:16:24.520]   The fan is great.
[00:16:24.520 --> 00:16:27.080]   So is your hair going to be like blowing a little bit in the wind?
[00:16:27.080 --> 00:16:28.080]   Yeah, a little bit.
[00:16:28.080 --> 00:16:29.080]   Yeah.
[00:16:29.080 --> 00:16:30.080]   Actually, that's not a bad idea.
[00:16:30.080 --> 00:16:31.080]   Then I sexy look.
[00:16:31.080 --> 00:16:32.080]   Like you wind blown?
[00:16:32.080 --> 00:16:33.080]   Yeah.
[00:16:33.080 --> 00:16:36.120]   So there are, you know, Robbie needs this.
[00:16:36.120 --> 00:16:37.760]   I have to wear for the Daft Punk thing.
[00:16:37.760 --> 00:16:40.800]   I end up wearing like wearable, like a wearable monitor.
[00:16:40.800 --> 00:16:45.680]   This could be, I'm wearing like goggles like, like that, but I don't like it.
[00:16:45.680 --> 00:16:49.440]   It's just that I can't see out of the helmet because it has LEDs in the front.
[00:16:49.440 --> 00:16:50.640]   So I can't see anything.
[00:16:50.640 --> 00:16:53.320]   So all I see is the computer screen for the DJ.
[00:16:53.320 --> 00:16:54.920]   So I can DJ.
[00:16:54.920 --> 00:16:58.200]   I knew that the tech press.
[00:16:58.200 --> 00:17:05.480]   Well, first of all, when they announced these, they did it at the Apple campus.
[00:17:05.480 --> 00:17:08.360]   Mycocargent was there, Jason, Snowlumber of our criterias.
[00:17:08.360 --> 00:17:11.920]   I, of course, do not get invited to Apple Vents, but that's okay.
[00:17:11.920 --> 00:17:13.800]   I didn't get to go.
[00:17:13.800 --> 00:17:18.480]   But when they announced it and they started talking about it, as usual, you know, you
[00:17:18.480 --> 00:17:22.800]   get a lot of ooze and aze at these Apple events.
[00:17:22.800 --> 00:17:26.600]   But then they mentioned the price.
[00:17:26.600 --> 00:17:34.360]   And let me, let me play for you because I have audio of this, the reaction.
[00:17:34.360 --> 00:17:36.000]   This is somebody tweeted this.
[00:17:36.000 --> 00:17:38.040]   Apple Vision Pro starts at $34.90.
[00:17:38.040 --> 00:17:40.400]   It will be available.
[00:17:40.400 --> 00:17:44.040]   That's not what you expect from the...
[00:17:44.040 --> 00:17:49.280]   Can you imagine the way Steve Jobs would have responded if he was standing on stage, making
[00:17:49.280 --> 00:17:52.120]   that announcement and the audience did that?
[00:17:52.120 --> 00:17:53.120]   Oh, gosh.
[00:17:53.120 --> 00:17:54.280]   What would he have done?
[00:17:54.280 --> 00:17:55.280]   What would he have done?
[00:17:55.280 --> 00:17:57.280]   He said, "Everybody out, out!"
[00:17:57.280 --> 00:17:58.280]   "You're out."
[00:17:58.280 --> 00:17:59.280]   "Lady Bitti"
[00:17:59.280 --> 00:18:04.280]   I was at the event where they had to give us all umm...
[00:18:04.280 --> 00:18:07.880]   Uppers for our phones because they were like, "You're holding it wrong."
[00:18:07.880 --> 00:18:09.480]   "Oh yeah, the bumpers."
[00:18:09.480 --> 00:18:10.480]   "The bumpers."
[00:18:10.480 --> 00:18:11.480]   "The bumpers."
[00:18:11.480 --> 00:18:12.480]   "The 4s."
[00:18:12.480 --> 00:18:16.280]   Steve Jobs was so irritated, that entire event.
[00:18:16.280 --> 00:18:18.080]   It was my favorite Apple event.
[00:18:18.080 --> 00:18:21.600]   It was in that little "Eddie Bitti" theater that they used to have.
[00:18:21.600 --> 00:18:24.800]   That was Barnum, my favorite Apple event I've ever been to.
[00:18:24.800 --> 00:18:26.400]   Anything else after that didn't matter.
[00:18:26.400 --> 00:18:31.440]   You have to understand the whole time I'm giggling to myself writing my articles.
[00:18:31.440 --> 00:18:36.200]   We called this antenna gate because when you held the 4s, the antenna was that metal
[00:18:36.200 --> 00:18:37.360]   bar around it.
[00:18:37.360 --> 00:18:40.520]   It would actually watch the signal disappear as you held it.
[00:18:40.520 --> 00:18:43.600]   If you've cut down a zero, it would cut off your calls.
[00:18:43.600 --> 00:18:50.400]   Steve Jobs and his entire family were in Kona, Hawaii, at Kona Village vacationing when it
[00:18:50.400 --> 00:18:51.800]   came out.
[00:18:51.800 --> 00:18:56.680]   He was so pissed off, he had to fly back and solve this problem.
[00:18:56.680 --> 00:18:59.840]   You remember what his reaction was, "You're holding it wrong."
[00:18:59.840 --> 00:19:02.840]   "Holding it wrong?"
[00:19:02.840 --> 00:19:03.840]   He was just here.
[00:19:03.840 --> 00:19:04.840]   He was here.
[00:19:04.840 --> 00:19:05.840]   He was here.
[00:19:05.840 --> 00:19:11.240]   He made a 13-cent rubber bumper that basically insulated the metal strip from your hand.
[00:19:11.240 --> 00:19:15.920]   That was their solution and they gave it away for free to everybody who was stuck with this
[00:19:15.920 --> 00:19:16.920]   phone.
[00:19:16.920 --> 00:19:19.720]   They used to be able to see the signal on the phone.
[00:19:19.720 --> 00:19:24.160]   You get it in a diagnostic mode and see the signal on the phone.
[00:19:24.160 --> 00:19:25.480]   You could see when you held it.
[00:19:25.480 --> 00:19:28.960]   But what was funny is I had some people bring over some Android phones and I put those in
[00:19:28.960 --> 00:19:29.960]   diagnostic mode.
[00:19:29.960 --> 00:19:30.960]   You could do the same thing.
[00:19:30.960 --> 00:19:31.960]   All phones.
[00:19:31.960 --> 00:19:32.960]   Pretty much your hand.
[00:19:32.960 --> 00:19:35.240]   All phones did the exact same thing.
[00:19:35.240 --> 00:19:38.000]   As soon as you grabbed it, you could see the signal go down.
[00:19:38.000 --> 00:19:40.440]   They're like, "Oh, we're just horrible, horrible."
[00:19:40.440 --> 00:19:41.440]   That was another solution.
[00:19:41.440 --> 00:19:43.120]   For the anti-cell tower.
[00:19:43.120 --> 00:19:46.120]   Which was not a promoted quiz much we talked about it.
[00:19:46.120 --> 00:19:52.720]   They changed the algorithm that showed the bars to show more bars so that you wouldn't
[00:19:52.720 --> 00:19:54.520]   know that you had lost signal.
[00:19:54.520 --> 00:19:56.520]   I like that fix.
[00:19:56.520 --> 00:19:58.120]   Just recalculating the gauge.
[00:19:58.120 --> 00:20:00.280]   They got rid of diagnostic mode.
[00:20:00.280 --> 00:20:01.280]   You couldn't look at it.
[00:20:01.280 --> 00:20:02.280]   You could see the actual digital difference.
[00:20:02.280 --> 00:20:03.280]   They got business.
[00:20:03.280 --> 00:20:05.720]   Oh, get out of there.
[00:20:05.720 --> 00:20:13.480]   Anyway, the Protect Press in general was fairly fawning over the Vision Pro when it came out.
[00:20:13.480 --> 00:20:15.480]   Absolutely the people who got to put them on.
[00:20:15.480 --> 00:20:17.120]   The special few.
[00:20:17.120 --> 00:20:18.120]   The proud.
[00:20:18.120 --> 00:20:23.680]   The several hundred journalists and YouTubers who got to put them on.
[00:20:23.680 --> 00:20:27.000]   I knew there would be a certain amount of, because I've seen this before with other VR
[00:20:27.000 --> 00:20:28.160]   headsets.
[00:20:28.160 --> 00:20:31.560]   When you first wear these, they're like, "Wow, this is amazing."
[00:20:31.560 --> 00:20:36.240]   There's that Walk the Planck game where you can't step out on the Planck because you're
[00:20:36.240 --> 00:20:40.400]   thinking you're going to die except you know you're standing on your carpet.
[00:20:40.400 --> 00:20:41.840]   You go crazy.
[00:20:41.840 --> 00:20:45.200]   Then five minutes later, reality sets in and you never wear them again.
[00:20:45.200 --> 00:20:47.160]   They gather dust.
[00:20:47.160 --> 00:20:48.960]   I knew that this would happen with Apple too.
[00:20:48.960 --> 00:20:53.320]   There was this wave of rhapsodic reporting.
[00:20:53.320 --> 00:21:02.320]   Then now we're starting to see stories come out like the Wired story where Kate Nibbs,
[00:21:02.320 --> 00:21:05.200]   I think that's how you pronounce it, K-N-I-B-B-S.
[00:21:05.200 --> 00:21:09.560]   It could be Kate Knibbs writes, "Apple's Vision Pro isn't the future.
[00:21:09.560 --> 00:21:13.320]   The new mixed reality headset is an alarming misfire.
[00:21:13.320 --> 00:21:20.160]   Has Apple lost its innovation mojo?"
[00:21:20.160 --> 00:21:24.880]   I am not bullish on this.
[00:21:24.880 --> 00:21:30.720]   I don't have any, you know, there's no consequences to me saying that speaking the truth here.
[00:21:30.720 --> 00:21:34.080]   I feel the worst I can do, not invite you to their facts.
[00:21:34.080 --> 00:21:35.080]   Exactly, man.
[00:21:35.080 --> 00:21:36.080]   That'll show you.
[00:21:36.080 --> 00:21:38.160]   I don't understand it.
[00:21:38.160 --> 00:21:42.560]   I feel like almost Apple just said, "Well, we spent 10 years developing this and untold
[00:21:42.560 --> 00:21:44.080]   billions of dollars.
[00:21:44.080 --> 00:21:46.680]   We just have to release it."
[00:21:46.680 --> 00:21:51.360]   I think $3,500 probably is pretty close to the cost of making it, right?
[00:21:51.360 --> 00:21:53.240]   I don't think they're making money on them.
[00:21:53.240 --> 00:21:54.240]   Well, yeah.
[00:21:54.240 --> 00:21:58.800]   I mean, given two 4K displays in there plus the fans and--
[00:21:58.800 --> 00:22:00.800]   There's 12 total processors.
[00:22:00.800 --> 00:22:01.800]   Yeah, cameras.
[00:22:01.800 --> 00:22:02.800]   There's--
[00:22:02.800 --> 00:22:03.800]   And there's, by the way--
[00:22:03.800 --> 00:22:04.800]   You get 12 cameras and get a LiDAR sensor.
[00:22:04.800 --> 00:22:08.880]   And there's a lot of things on the front, which by the-- I think personally, that's the first
[00:22:08.880 --> 00:22:09.880]   thing.
[00:22:09.880 --> 00:22:11.040]   That's not-- they're not going to ship with that.
[00:22:11.040 --> 00:22:12.040]   That's too creepy.
[00:22:12.040 --> 00:22:13.040]   Can you make it not show that?
[00:22:13.040 --> 00:22:14.040]   Can you make this move not?
[00:22:14.040 --> 00:22:15.040]   Yeah.
[00:22:15.040 --> 00:22:18.520]   It shows a plasma-- no, no, no.
[00:22:18.520 --> 00:22:22.040]   So you can only hide your eyes by hiding your view.
[00:22:22.040 --> 00:22:24.040]   So the eyes show when you can see the room.
[00:22:24.040 --> 00:22:27.200]   And there is a little crown, a digital crown, and you can say, "I don't want to see the
[00:22:27.200 --> 00:22:28.200]   room."
[00:22:28.200 --> 00:22:30.640]   And then your eyes turn into a plasma blob.
[00:22:30.640 --> 00:22:35.720]   But if you're seeing the room, I think they want to show your eyes because they want people
[00:22:35.720 --> 00:22:36.720]   to know you're looking.
[00:22:36.720 --> 00:22:37.720]   Oh.
[00:22:37.720 --> 00:22:39.720]   So I don't think you're going to disable that.
[00:22:39.720 --> 00:22:40.720]   Yeah.
[00:22:40.720 --> 00:22:43.040]   So it's not like the Google Glass where you can't tell where they're looking at you or
[00:22:43.040 --> 00:22:44.800]   they're looking at their Google Glass stuff.
[00:22:44.800 --> 00:22:50.480]   Well, and the creepiest thing in the demo was that when they showed the father at the
[00:22:50.480 --> 00:22:57.480]   birthday party wearing these recording amazing 3D video of my kid blowing out the candles.
[00:22:57.480 --> 00:23:05.360]   Can you imagine wearing these with daddy's creepy eyes during the birthday party?
[00:23:05.360 --> 00:23:12.240]   Compared to somebody wearing these goggles to record some event, having a parent wearing
[00:23:12.240 --> 00:23:15.040]   Google Glass would have been nothing.
[00:23:15.040 --> 00:23:16.040]   Yeah.
[00:23:16.040 --> 00:23:20.080]   I mean, those are relatively unobtrusive in comparison to this.
[00:23:20.080 --> 00:23:21.080]   You can actually see--
[00:23:21.080 --> 00:23:22.920]   And look at what happened to Glass.
[00:23:22.920 --> 00:23:23.920]   Realize.
[00:23:23.920 --> 00:23:25.080]   People reacted so negatively to Glass.
[00:23:25.080 --> 00:23:26.880]   It basically killed it.
[00:23:26.880 --> 00:23:28.480]   It took them a while.
[00:23:28.480 --> 00:23:30.840]   The press loved it and it will not mean--
[00:23:30.840 --> 00:23:31.840]   I didn't love it.
[00:23:31.840 --> 00:23:32.840]   I didn't love it.
[00:23:32.840 --> 00:23:36.160]   I have just like riff it apart right from the beginning and I'm like, "You're being mean."
[00:23:36.160 --> 00:23:38.560]   I'm like, "No, I'm not."
[00:23:38.560 --> 00:23:44.000]   We called them-- we called the wares of Google Glass Glass holes.
[00:23:44.000 --> 00:23:45.000]   Glass holes.
[00:23:45.000 --> 00:23:46.000]   Yeah.
[00:23:46.000 --> 00:23:47.000]   I mean, right there.
[00:23:47.000 --> 00:23:48.000]   That tells you something.
[00:23:48.000 --> 00:23:50.160]   It's a problem.
[00:23:50.160 --> 00:23:56.800]   Can you imagine sitting across from your lovely wife and she's smiling at you?
[00:23:56.800 --> 00:23:59.000]   And staring deep into your eyes with her--
[00:23:59.000 --> 00:24:00.000]   That's so creepy.
[00:24:00.000 --> 00:24:01.000]   --lendicular--
[00:24:01.000 --> 00:24:02.000]   It's so creepy.
[00:24:02.000 --> 00:24:03.000]   Creepy eyes?
[00:24:03.000 --> 00:24:04.000]   No.
[00:24:04.000 --> 00:24:05.000]   No.
[00:24:05.000 --> 00:24:06.000]   That is--
[00:24:06.000 --> 00:24:07.000]   Why is she wearing those?
[00:24:07.000 --> 00:24:08.000]   She's talking to her husband.
[00:24:08.000 --> 00:24:09.520]   Why is she wearing those?
[00:24:09.520 --> 00:24:11.720]   Take those off, dear.
[00:24:11.720 --> 00:24:12.720]   I'm recording you.
[00:24:12.720 --> 00:24:13.720]   You're the creepiest thing.
[00:24:13.720 --> 00:24:14.720]   I'm--
[00:24:14.720 --> 00:24:15.720]   I'm--
[00:24:15.720 --> 00:24:16.720]   I thought this was a good idea.
[00:24:16.720 --> 00:24:17.720]   Who thought this was a good idea?
[00:24:17.720 --> 00:24:23.680]   It's VR and it's been-- and AR and they've been trying to make it happen.
[00:24:23.680 --> 00:24:24.680]   It's like fetch.
[00:24:24.680 --> 00:24:27.920]   And you just don't make fetch happen.
[00:24:27.920 --> 00:24:29.120]   They keep trying and trying.
[00:24:29.120 --> 00:24:30.680]   And it has its uses.
[00:24:30.680 --> 00:24:32.240]   It has a very niche market.
[00:24:32.240 --> 00:24:34.440]   Like gamers love it.
[00:24:34.440 --> 00:24:37.840]   But I don't think the general public cares.
[00:24:37.840 --> 00:24:38.840]   I just--
[00:24:38.840 --> 00:24:39.840]   I was--
[00:24:39.840 --> 00:24:41.840]   I have a VR headset somewhere in my office.
[00:24:41.840 --> 00:24:42.840]   Yeah, so do I.
[00:24:42.840 --> 00:24:44.840]   Won't take back.
[00:24:44.840 --> 00:24:48.360]   And I've had it for about three years now.
[00:24:48.360 --> 00:24:49.360]   And I--
[00:24:49.360 --> 00:24:50.360]   Yeah.
[00:24:50.360 --> 00:24:51.360]   I--
[00:24:51.360 --> 00:24:52.360]   I--
[00:24:52.360 --> 00:24:53.920]   I've been on like a few months ago to like test something out for the band.
[00:24:53.920 --> 00:24:54.920]   And I'm like, oh, this won't work for that.
[00:24:54.920 --> 00:24:55.920]   And never mind.
[00:24:55.920 --> 00:24:58.160]   I bought every one of them.
[00:24:58.160 --> 00:24:59.320]   Bought them.
[00:24:59.320 --> 00:25:01.640]   I contributed to the Oculus Rift Kickstarter.
[00:25:01.640 --> 00:25:02.640]   Bought it.
[00:25:02.640 --> 00:25:03.640]   They got you.
[00:25:03.640 --> 00:25:04.640]   They got me.
[00:25:04.640 --> 00:25:08.400]   I just bought the Oculus Pro, the Quest Pro, MetacuS Pro for six.
[00:25:08.400 --> 00:25:11.720]   If I piped $1,500 for it, you can now get over $1,000.
[00:25:11.720 --> 00:25:13.680]   And it's just sitting in my office on a stand.
[00:25:13.680 --> 00:25:14.680]   It looks nice.
[00:25:14.680 --> 00:25:15.680]   Collecting dust.
[00:25:15.680 --> 00:25:16.680]   Doing nothing.
[00:25:16.680 --> 00:25:17.680]   But is it just--
[00:25:17.680 --> 00:25:18.680]   There are some--
[00:25:18.680 --> 00:25:19.680]   So this is the thing.
[00:25:19.680 --> 00:25:20.680]   I want to know.
[00:25:20.680 --> 00:25:21.680]   Is it just me or--
[00:25:21.680 --> 00:25:22.680]   It's--
[00:25:22.680 --> 00:25:23.680]   Certainly you can come up.
[00:25:23.680 --> 00:25:26.400]   There are people who are going Twitter.
[00:25:26.400 --> 00:25:28.080]   There are people going crazy about this thing.
[00:25:28.080 --> 00:25:29.080]   I think there are--
[00:25:29.080 --> 00:25:32.000]   Are there many people going crazy?
[00:25:32.000 --> 00:25:33.600]   There are realistic applications.
[00:25:33.600 --> 00:25:36.240]   Like, for example, in a design studio.
[00:25:36.240 --> 00:25:41.720]   The first time I tried VR goggles was actually in a Ford design studio.
[00:25:41.720 --> 00:25:48.640]   And walking around a virtual model of a vehicle before you invest in building that thing.
[00:25:48.640 --> 00:25:54.760]   Being able to see all the pieces in order, in this 3D environment actually works really
[00:25:54.760 --> 00:25:55.760]   well.
[00:25:55.760 --> 00:26:00.600]   But I think those kinds of applications are few and far between.
[00:26:00.600 --> 00:26:07.920]   And for average people, the idea of wearing these glasses all day and trying to type and
[00:26:07.920 --> 00:26:12.080]   do my job in that kind of environment, it's absurd.
[00:26:12.080 --> 00:26:18.960]   Yeah, when Google Glass was first announced, I talked to an AR researcher.
[00:26:18.960 --> 00:26:22.080]   And his first thing was, we don't even really know what these are good for.
[00:26:22.080 --> 00:26:27.360]   Beyond like industrial uses, like helping people fix things because you can see through
[00:26:27.360 --> 00:26:29.680]   the glasses, you can see, oh, put this here, put this there.
[00:26:29.680 --> 00:26:31.080]   I mean, it's wonderful for that.
[00:26:31.080 --> 00:26:32.840]   Like if you go to a car and it says, hey, this is--
[00:26:32.840 --> 00:26:35.040]   You need to take this bolt, this bolt, this bolt, and this bolt out.
[00:26:35.040 --> 00:26:36.040]   And you're like, oh, that's great.
[00:26:36.040 --> 00:26:37.040]   And you take them out.
[00:26:37.040 --> 00:26:43.920]   But around town and-- I don't know.
[00:26:43.920 --> 00:26:46.120]   I feel like you're still really bulky.
[00:26:46.120 --> 00:26:47.640]   I think it's like a segue.
[00:26:47.640 --> 00:26:49.520]   You know how segue was going to change the entire world?
[00:26:49.520 --> 00:26:51.520]   We're not going to be riding these beautiful segues everywhere.
[00:26:51.520 --> 00:26:53.720]   And now the only people who use them are like mall cops.
[00:26:53.720 --> 00:26:56.800]   I feel like there's like a limited number of applications for things.
[00:26:56.800 --> 00:26:58.000]   That's a good point.
[00:26:58.000 --> 00:26:59.000]   That's a good point.
[00:26:59.000 --> 00:27:01.200]   There are some people who use segues.
[00:27:01.200 --> 00:27:07.840]   A segue to me is a good example that was widely lauded when it was introduced.
[00:27:07.840 --> 00:27:11.200]   Remember Bill Gates said it's going to change the way we design cities.
[00:27:11.200 --> 00:27:14.160]   I mean, people thought this-- remember Project Ginger?
[00:27:14.160 --> 00:27:16.640]   It was going to change everything.
[00:27:16.640 --> 00:27:20.040]   But then people got on them and they're nine feet tall.
[00:27:20.040 --> 00:27:22.240]   And they look pretty stupid riding them.
[00:27:22.240 --> 00:27:24.040]   I know because we have two of them.
[00:27:24.040 --> 00:27:26.040]   And the original thing you do--
[00:27:26.040 --> 00:27:27.040]   Oh, my gosh.
[00:27:27.040 --> 00:27:29.640]   And you-- OK, I'll trade you one Lamborghini for--
[00:27:29.640 --> 00:27:30.640]   [LAUGHTER]
[00:27:30.640 --> 00:27:31.640]   Well, wait.
[00:27:31.640 --> 00:27:32.640]   There's more.
[00:27:32.640 --> 00:27:33.640]   But wait.
[00:27:33.640 --> 00:27:36.120]   But I think that the dork factor was some of this.
[00:27:36.120 --> 00:27:38.640]   And this is why I pay attention to the creepy eyes.
[00:27:38.640 --> 00:27:41.480]   Because I think-- and it's the same thing with glass.
[00:27:41.480 --> 00:27:46.520]   There's a certain-- if people mock you when you're using a technology, you pretty quickly
[00:27:46.520 --> 00:27:47.520]   put it aside.
[00:27:47.520 --> 00:27:50.120]   Most normal people go, eh, I don't want to be mocked.
[00:27:50.120 --> 00:27:51.840]   And I think that's what happened to segue.
[00:27:51.840 --> 00:27:57.760]   So we have-- we bought two of the original $7,000 segues.
[00:27:57.760 --> 00:27:58.760]   Oh, my gosh.
[00:27:58.760 --> 00:28:00.800]   We had a lot of fun with them.
[00:28:00.800 --> 00:28:02.760]   The kids loved him.
[00:28:02.760 --> 00:28:11.280]   Our son, when he was about 12 and his other boyfriends, were jousting with them.
[00:28:11.280 --> 00:28:13.680]   So they got pieces of old splintered wood.
[00:28:13.680 --> 00:28:14.680]   [LAUGHTER]
[00:28:14.680 --> 00:28:17.840]   And they carried it under their arm.
[00:28:17.840 --> 00:28:19.920]   And they segue jousted until I caught them.
[00:28:19.920 --> 00:28:21.560]   And I said, what are you doing?
[00:28:21.560 --> 00:28:24.200]   You're going to bail each other.
[00:28:24.200 --> 00:28:26.560]   We had them in the garage for a while.
[00:28:26.560 --> 00:28:29.080]   The batteries finally died about a year ago.
[00:28:29.080 --> 00:28:31.160]   It couldn't charge-- it wouldn't take a charge anymore.
[00:28:31.160 --> 00:28:36.560]   And I looked into it, and it would have cost another $3,500 each for new batteries.
[00:28:36.560 --> 00:28:37.560]   Wow.
[00:28:37.560 --> 00:28:38.560]   So--
[00:28:38.560 --> 00:28:41.280]   I don't remember-- they were up here because they were based in New Hampshire.
[00:28:41.280 --> 00:28:42.280]   Yeah.
[00:28:42.280 --> 00:28:45.360]   So there was-- where they were in the mill buildings-- say these old mill buildings, and
[00:28:45.360 --> 00:28:48.120]   they would-- you'd be like just walking into the building to whatever business and like,
[00:28:48.120 --> 00:28:49.520]   zoom, zoom, zoom, segues were everywhere.
[00:28:49.520 --> 00:28:51.960]   And I remember thinking, I've almost been killed by these things 20 times.
[00:28:51.960 --> 00:28:52.960]   Yeah.
[00:28:52.960 --> 00:28:53.960]   And I was like, look out, look out.
[00:28:53.960 --> 00:28:55.440]   I'm like, this is not going to make my life better.
[00:28:55.440 --> 00:28:56.440]   Steve Watson--
[00:28:56.440 --> 00:28:57.440]   This is going to come by accident.
[00:28:57.440 --> 00:29:01.280]   --20 years ago brought segues to the screen savers, and we had-- because he was in the
[00:29:01.280 --> 00:29:03.360]   segue polo, by the way.
[00:29:03.360 --> 00:29:04.360]   That was insane.
[00:29:04.360 --> 00:29:05.360]   That was a thing.
[00:29:05.360 --> 00:29:06.360]   That was a thing.
[00:29:06.360 --> 00:29:07.360]   That was a thing.
[00:29:07.360 --> 00:29:08.360]   That was a thing.
[00:29:08.360 --> 00:29:09.360]   Oh, my gosh.
[00:29:09.360 --> 00:29:10.360]   And he had many of them, and we all got to play with them.
[00:29:10.360 --> 00:29:11.360]   But that was 20 years ago.
[00:29:11.360 --> 00:29:17.920]   Anyway, that was a famous example of something that has some real use and some merit.
[00:29:17.920 --> 00:29:20.440]   You still see them in tours around the cities all the time.
[00:29:20.440 --> 00:29:21.440]   You do.
[00:29:21.440 --> 00:29:29.240]   I think the idea that they had around segues changing the way cities are built, that idea
[00:29:29.240 --> 00:29:31.560]   was actually directionally correct.
[00:29:31.560 --> 00:29:33.080]   But it was ahead of its time.
[00:29:33.080 --> 00:29:38.360]   And I think the segue itself in the form that they built it was the wrong vehicle.
[00:29:38.360 --> 00:29:44.520]   Because what we've seen in recent years is that same idea of changing the way we move
[00:29:44.520 --> 00:29:50.520]   around cities coming to us in the form of modern micro-mobility with electric scooters,
[00:29:50.520 --> 00:29:52.440]   e-bikes, things like that.
[00:29:52.440 --> 00:29:57.000]   And particularly during the course of the pandemic, in the early days when there was
[00:29:57.000 --> 00:30:01.880]   very little traffic, we actually saw a lot of cities use that opportunity to go in and
[00:30:01.880 --> 00:30:08.360]   install permanent protected bike lanes and access lanes for bikes and scooters and so
[00:30:08.360 --> 00:30:09.360]   on.
[00:30:09.360 --> 00:30:11.040]   So they weren't on the sidewalks.
[00:30:11.040 --> 00:30:17.000]   And in fact, the idea of changing the way cities are built, it's just a little idea.
[00:30:17.000 --> 00:30:18.600]   It's starting to come to fruition.
[00:30:18.600 --> 00:30:19.600]   Yeah.
[00:30:19.600 --> 00:30:25.760]   For Sam, you're showing me some electric mobility devices designed for cities.
[00:30:25.760 --> 00:30:26.760]   Was that from General Motors?
[00:30:26.760 --> 00:30:27.760]   I can't remember.
[00:30:27.760 --> 00:30:28.760]   Oh, at CES?
[00:30:28.760 --> 00:30:29.760]   At CES.
[00:30:29.760 --> 00:30:30.760]   Yeah, the Envies.
[00:30:30.760 --> 00:30:31.760]   The Envies.
[00:30:31.760 --> 00:30:32.760]   The Envies.
[00:30:32.760 --> 00:30:33.760]   The little autonomous pods.
[00:30:33.760 --> 00:30:34.760]   They were really cool.
[00:30:34.760 --> 00:30:36.360]   And those were actually built on segue platforms.
[00:30:36.360 --> 00:30:37.360]   Oh, interesting.
[00:30:37.360 --> 00:30:38.360]   Yeah, there were two weeks.
[00:30:38.360 --> 00:30:39.360]   Yeah.
[00:30:39.360 --> 00:30:40.360]   Yeah.
[00:30:40.360 --> 00:30:45.000]   So the segue was the idea was correct, but the e-bike is the correct form.
[00:30:45.000 --> 00:30:47.120]   I agree with you 100%, exactly.
[00:30:47.120 --> 00:30:49.400]   So that's what's going to happen.
[00:30:49.400 --> 00:30:52.880]   These vision goggles, vision pro with the idea is correct.
[00:30:52.880 --> 00:30:56.280]   But what we're going to end up with is something that we might miss in 20 years.
[00:30:56.280 --> 00:30:59.920]   Something we've seen from BMW where it has augmented reality in the car.
[00:30:59.920 --> 00:31:01.920]   It can, like, the windshield is essentially augmented.
[00:31:01.920 --> 00:31:02.920]   Yeah, that makes sense.
[00:31:02.920 --> 00:31:04.640]   And it's like, oh, you need to go over here.
[00:31:04.640 --> 00:31:05.640]   You need to go over here.
[00:31:05.640 --> 00:31:06.640]   I think that's the...
[00:31:06.640 --> 00:31:12.160]   Yeah, there's already augmented reality heads up displays in some cars that, you know,
[00:31:12.160 --> 00:31:15.880]   traditional heads up displays display the information in a single plane that looks like
[00:31:15.880 --> 00:31:22.520]   it's floating over the front edge of your hood, maybe three, four feet in front of you.
[00:31:22.520 --> 00:31:27.480]   These AR heads actually are multi-plane displays.
[00:31:27.480 --> 00:31:31.160]   Mercedes has them in the S-Class and the EQS and some other models.
[00:31:31.160 --> 00:31:33.960]   And it's coming to other vehicles.
[00:31:33.960 --> 00:31:39.600]   You actually see the information floating at multiple distances away from you.
[00:31:39.600 --> 00:31:45.160]   So when you're driving down the road with navigation, it actually looks like it's overlaying
[00:31:45.160 --> 00:31:47.480]   the directions right on the road.
[00:31:47.480 --> 00:31:49.200]   Or it's floating above everything.
[00:31:49.200 --> 00:31:50.200]   Yeah, yeah, yeah.
[00:31:50.200 --> 00:31:52.200]   Yeah, you have an arrow floating above the intersection where you're supposed to turn.
[00:31:52.200 --> 00:31:53.480]   But it doesn't look like it's reflected to it.
[00:31:53.480 --> 00:31:54.840]   It's reflected off the windshield.
[00:31:54.840 --> 00:31:56.480]   It actually looks like it's on the road.
[00:31:56.480 --> 00:31:58.760]   Yeah, it looks like it's further out in the distance.
[00:31:58.760 --> 00:32:01.760]   So the focal distance is different.
[00:32:01.760 --> 00:32:07.040]   And you see different bits of information at different locations in your field of view,
[00:32:07.040 --> 00:32:08.040]   different distances.
[00:32:08.040 --> 00:32:09.720]   So I think that's brilliant.
[00:32:09.720 --> 00:32:14.920]   The turning props look like they're floating over the intersection and they're stuck there,
[00:32:14.920 --> 00:32:15.920]   over that intersection.
[00:32:15.920 --> 00:32:19.520]   So as you get closer, it looks like it's getting closer to you and says, "Here's where you're
[00:32:19.520 --> 00:32:21.000]   supposed to turn."
[00:32:21.000 --> 00:32:24.680]   And I think that sort of thing actually really works.
[00:32:24.680 --> 00:32:33.320]   And if you can do that in something like you talked about in the form of traditional eyeglasses,
[00:32:33.320 --> 00:32:40.200]   so it looks like you're just wearing glasses, that's still a long ways away.
[00:32:40.200 --> 00:32:43.720]   But it's interesting that you can get it today in an automobile.
[00:32:43.720 --> 00:32:44.720]   Is that...
[00:32:44.720 --> 00:32:47.720]   Well, because it's a much larger device.
[00:32:47.720 --> 00:32:48.720]   It's a big heavy device.
[00:32:48.720 --> 00:32:51.320]   It's not something you can wear on your face.
[00:32:51.320 --> 00:32:53.880]   And it's not to track your eyes in order for it to work correctly.
[00:32:53.880 --> 00:32:57.360]   So in the Mercedes-Benz, there's actually eye trackers in the dash.
[00:32:57.360 --> 00:32:58.800]   They're tracking your eyes.
[00:32:58.800 --> 00:32:59.800]   So that's...
[00:32:59.800 --> 00:33:00.800]   So that's...
[00:33:00.800 --> 00:33:04.840]   It'll project the arrows and the information to tell you to go left or right or whatever.
[00:33:04.840 --> 00:33:07.000]   That kind of makes more sense.
[00:33:07.000 --> 00:33:10.480]   That's a very good use of AR.
[00:33:10.480 --> 00:33:13.640]   Also the technology to shrink that down to your spectacles is not...
[00:33:13.640 --> 00:33:15.200]   I don't think it even exists yet.
[00:33:15.200 --> 00:33:17.240]   No, it doesn't.
[00:33:17.240 --> 00:33:19.480]   But it does exist in cars.
[00:33:19.480 --> 00:33:24.040]   It's funny that they're not getting more attention for that, but Apple's getting all
[00:33:24.040 --> 00:33:28.280]   his attention for basically what's a computer strapped to your forehead.
[00:33:28.280 --> 00:33:30.400]   Which is not appealing.
[00:33:30.400 --> 00:33:32.920]   Because everyone's been waiting for Apple to do this.
[00:33:32.920 --> 00:33:34.560]   It's like the Apple car.
[00:33:34.560 --> 00:33:39.120]   Like when the Apple car comes out, if or when it ever comes out, it's going to be a huge
[00:33:39.120 --> 00:33:40.320]   deal.
[00:33:40.320 --> 00:33:44.520]   Meanwhile, all these other automotive startups have been doing this and traditional automakers
[00:33:44.520 --> 00:33:46.680]   have been doing this.
[00:33:46.680 --> 00:33:51.480]   It's because Apple, the hype machine around Apple and the fact that we've known that they've
[00:33:51.480 --> 00:33:53.600]   been working on it for years.
[00:33:53.600 --> 00:33:59.680]   Well, and plus, Apple, they created the iPod, the iPhone, the iPad.
[00:33:59.680 --> 00:34:02.080]   And these were all devices that had been done before.
[00:34:02.080 --> 00:34:03.320]   We'd had MP3 players.
[00:34:03.320 --> 00:34:04.320]   We had smartphones.
[00:34:04.320 --> 00:34:06.880]   We had tablet computers.
[00:34:06.880 --> 00:34:11.400]   But when Apple did it, they really executed it correctly.
[00:34:11.400 --> 00:34:18.320]   And so the assumption was when Apple finally did this headset, that it would be the one
[00:34:18.320 --> 00:34:24.120]   that finally breaks through and fixes all the problems with all the ones that came before.
[00:34:24.120 --> 00:34:27.640]   And I don't think that they're there yet.
[00:34:27.640 --> 00:34:31.000]   So I mean, I could be wrong because I've never, obviously I've never actually had one of these
[00:34:31.000 --> 00:34:32.000]   on my face.
[00:34:32.000 --> 00:34:33.000]   Right.
[00:34:33.000 --> 00:34:34.560]   But I've remained dubious.
[00:34:34.560 --> 00:34:36.680]   Yeah, I'm dubious.
[00:34:36.680 --> 00:34:41.920]   Well, although maybe this, the whole point of this, you said something interesting, Robbie,
[00:34:41.920 --> 00:34:46.880]   is to gather information about how it would be used, what works and what doesn't work
[00:34:46.880 --> 00:34:50.200]   for an Apple car, for instance.
[00:34:50.200 --> 00:34:56.360]   Maybe this is a stealth product because they surely don't expect to sell many at $3,500.
[00:34:56.360 --> 00:34:58.360]   No, they couldn't.
[00:34:58.360 --> 00:35:00.920]   No, not that many people are going to buy into it.
[00:35:00.920 --> 00:35:01.920]   It's a niche product.
[00:35:01.920 --> 00:35:03.240]   They had it like put it like we have it.
[00:35:03.240 --> 00:35:04.240]   We've been working on it.
[00:35:04.240 --> 00:35:05.240]   Let's put it out.
[00:35:05.240 --> 00:35:06.240]   It's a niche product.
[00:35:06.240 --> 00:35:11.840]   It's a niche product because they've always been a niche product up until this point.
[00:35:11.840 --> 00:35:13.160]   So let's put it out there.
[00:35:13.160 --> 00:35:14.880]   Let's get some information about it.
[00:35:14.880 --> 00:35:19.720]   Maybe 10 years from now we'll have actual just regular glasses that have this.
[00:35:19.720 --> 00:35:21.040]   Would you be interested in this?
[00:35:21.040 --> 00:35:25.520]   One of the things they're pushing is the idea that you can wear this and have giant screens.
[00:35:25.520 --> 00:35:26.840]   You don't need monitors anymore.
[00:35:26.840 --> 00:35:33.080]   Your computer display can be huge and spread out like minority reports spread out across
[00:35:33.080 --> 00:35:34.600]   your field of view.
[00:35:34.600 --> 00:35:35.600]   Is that appeal?
[00:35:35.600 --> 00:35:36.600]   No.
[00:35:36.600 --> 00:35:39.160]   I already have a 35 inch monitor.
[00:35:39.160 --> 00:35:42.360]   Like monitors are super cheap.
[00:35:42.360 --> 00:35:46.680]   I don't why would I need to wear them in my face.
[00:35:46.680 --> 00:35:50.200]   And like you know my dogs come in, my cats are here, you know, I'm like trying to type
[00:35:50.200 --> 00:35:52.680]   and also the cats walking on something like what's going on.
[00:35:52.680 --> 00:35:53.680]   It's chaos.
[00:35:53.680 --> 00:35:54.680]   I know the cats there.
[00:35:54.680 --> 00:35:56.640]   Geez, you can't see it because you got this thing on your face.
[00:35:56.640 --> 00:36:01.680]   Also wearing this thing on your head for hours on end like the death punk thing we wear
[00:36:01.680 --> 00:36:05.160]   these helmets for the set list is about an hour and 20 minutes.
[00:36:05.160 --> 00:36:09.640]   But after about 45 minutes, I'm just like, I'm just begging for this set to end.
[00:36:09.640 --> 00:36:11.600]   It's just like it's heavy.
[00:36:11.600 --> 00:36:15.440]   Do you think that's why death punk retired is that just couldn't do it?
[00:36:15.440 --> 00:36:16.440]   Just couldn't do it anymore.
[00:36:16.440 --> 00:36:20.080]   Well, they don't they just have like a helmet on, but maybe maybe that that I always thought
[00:36:20.080 --> 00:36:22.720]   that was more like the dread pirate Roberts of musicians.
[00:36:22.720 --> 00:36:24.280]   There's 20 different people.
[00:36:24.280 --> 00:36:27.680]   They create all the music, but then they just send some random dudes.
[00:36:27.680 --> 00:36:28.680]   You're like, hey, go.
[00:36:28.680 --> 00:36:29.680]   Could be anyone.
[00:36:29.680 --> 00:36:30.680]   How would you know?
[00:36:30.680 --> 00:36:31.680]   Yeah, I never know.
[00:36:31.680 --> 00:36:34.280]   Just and they're not really doing anything.
[00:36:34.280 --> 00:36:37.280]   Just because they're push it's a they're DJs, right?
[00:36:37.280 --> 00:36:39.160]   So they don't they don't really actually.
[00:36:39.160 --> 00:36:46.800]   This day they actually they actually do some there's a there's a there was a really great
[00:36:46.800 --> 00:36:49.800]   live stream they did right when they said they were breaking up of them before they had
[00:36:49.800 --> 00:36:53.160]   their helmets and they're actually playing all these instruments.
[00:36:53.160 --> 00:36:58.400]   You know, and and for me, I have to like I actually have to trigger every single sound
[00:36:58.400 --> 00:36:59.560]   that's happening in the show.
[00:36:59.560 --> 00:37:02.000]   It's it's not just push play.
[00:37:02.000 --> 00:37:04.080]   How do you see in the thing?
[00:37:04.080 --> 00:37:05.720]   Because I have that monitor on.
[00:37:05.720 --> 00:37:09.640]   Oh, literally all I can see when that's stupid.
[00:37:09.640 --> 00:37:14.600]   You are actually the only person I know who actually wears one of these all the time.
[00:37:14.600 --> 00:37:16.760]   This might be made for Roberta Baldwin.
[00:37:16.760 --> 00:37:17.760]   Yeah, it's too.
[00:37:17.760 --> 00:37:18.760]   Just for you, Roberta.
[00:37:18.760 --> 00:37:21.960]   That's all I need is all I need to be able to see is the monitor of my computer.
[00:37:21.960 --> 00:37:29.100]   I don't need to see anything else and so how do you feed the you have a camera or or
[00:37:29.100 --> 00:37:33.240]   a DMI like so the computer is feeding your your helmet.
[00:37:33.240 --> 00:37:35.920]   Yeah, the helmet is actually it's it's actually a monitor.
[00:37:35.920 --> 00:37:37.840]   It's actually a wearable monitor.
[00:37:37.840 --> 00:37:40.920]   And so it has HDMI input HDMI into my computer.
[00:37:40.920 --> 00:37:44.800]   We used to have this whole thing where we were assets, you know, we were we were using
[00:37:44.800 --> 00:37:50.040]   a Wi-Fi network and we were like SSH in into two different computers and I had a mixer
[00:37:50.040 --> 00:37:52.160]   and this whole crazy thing.
[00:37:52.160 --> 00:37:55.520]   And then I have a little camera like out of the mouth hole where I could couldn't really
[00:37:55.520 --> 00:37:58.600]   see anything because the camera is so low.
[00:37:58.600 --> 00:38:00.300]   It was incredibly complex.
[00:38:00.300 --> 00:38:04.140]   Like every time something happened, I couldn't see what was going on and it turns out that
[00:38:04.140 --> 00:38:11.300]   the monitor couldn't handle the ProRes like like I don't know who you are, but you all
[00:38:11.300 --> 00:38:13.300]   look like potatoes.
[00:38:13.300 --> 00:38:21.380]   Yeah, it always like so it's a dark club and all I see is like little round blob dancing
[00:38:21.380 --> 00:38:22.860]   of like, well, this is no good.
[00:38:22.860 --> 00:38:29.860]   And then like one of my computers, my MacBook Air, my current at MacBook Air, the resolution
[00:38:29.860 --> 00:38:33.600]   is so dense that it was too dense for the monitor.
[00:38:33.600 --> 00:38:38.260]   So the cursor was so tiny, I couldn't find it.
[00:38:38.260 --> 00:38:42.500]   So I have to move the cursor up to the top right hand corner and then slowly move it
[00:38:42.500 --> 00:38:46.020]   down to trigger the next section.
[00:38:46.020 --> 00:38:48.220]   And I'm just like on stage and I'm freaking out.
[00:38:48.220 --> 00:38:52.140]   I'm just like, oh my God, this is the worst thing that ever happened because you have
[00:38:52.140 --> 00:38:55.620]   to trigger it like at the right time, you know, you have to keep time.
[00:38:55.620 --> 00:38:58.460]   If you trigger the wrong time, it sounds weird and messes it up.
[00:38:58.460 --> 00:39:00.660]   You trigger the wrong section.
[00:39:00.660 --> 00:39:04.980]   And then I would go back to my 2015 MacBook Air and it'd be fine because, you know, the
[00:39:04.980 --> 00:39:06.300]   resolution density isn't as high.
[00:39:06.300 --> 00:39:10.540]   I'll have to show you how you make your mouse cursor bigger on the Mac because you can do
[00:39:10.540 --> 00:39:13.180]   that and I feel really bad for you.
[00:39:13.180 --> 00:39:16.820]   So, well, I didn't know it until I was on stage.
[00:39:16.820 --> 00:39:21.580]   Now, now I just use one computer and it has this like every time the music changes, it's
[00:39:21.580 --> 00:39:24.740]   a new scene and it's like 300 scenes.
[00:39:24.740 --> 00:39:30.580]   It's just it's a video anywhere of the what is it called?
[00:39:30.580 --> 00:39:32.140]   I use Ableton Live.
[00:39:32.140 --> 00:39:34.580]   No, but no, I mean, what's the band called?
[00:39:34.580 --> 00:39:36.580]   Oh, robots after all.
[00:39:36.580 --> 00:39:37.980]   Robots after all.
[00:39:37.980 --> 00:39:42.180]   Is there any is there anywhere we can go with see you somewhere?
[00:39:42.180 --> 00:39:44.260]   See this is crazy.
[00:39:44.260 --> 00:39:47.820]   Well, like from the audience, it looks cool.
[00:39:47.820 --> 00:39:50.660]   But on stage, I'm having like a little suffering.
[00:39:50.660 --> 00:39:53.140]   You're paying for your can't see the band.
[00:39:53.140 --> 00:39:58.620]   I got under the other guy and the band passed out at a show because he got so hot and overheated.
[00:39:58.620 --> 00:40:01.180]   And you know what?
[00:40:01.180 --> 00:40:02.180]   I didn't know.
[00:40:02.180 --> 00:40:09.460]   You were in a helmet and he couldn't see because I use these in your monitors.
[00:40:09.460 --> 00:40:14.540]   So all I can hear is the music that I'm playing and all I can see is the computer.
[00:40:14.540 --> 00:40:15.540]   And that's it.
[00:40:15.540 --> 00:40:17.380]   And I can see like right below me right here.
[00:40:17.380 --> 00:40:19.660]   So I can see like my MIDI controller and there it is.
[00:40:19.660 --> 00:40:21.260]   Yeah, there's the band.
[00:40:21.260 --> 00:40:22.260]   I'm so sorry.
[00:40:22.260 --> 00:40:27.460]   Some poor guys like lying on the stage and you're still like going along.
[00:40:27.460 --> 00:40:30.780]   Like he sat down and then he just fell over and I didn't know.
[00:40:30.780 --> 00:40:34.380]   And I looked at the video later and like someone from the audience was like, that guy fell
[00:40:34.380 --> 00:40:38.220]   down and like all these people came up behind me into the video, into the DJ booth and were
[00:40:38.220 --> 00:40:40.020]   helping him and taking his helmet off.
[00:40:40.020 --> 00:40:42.660]   And they took him off stage and I'm still here.
[00:40:42.660 --> 00:40:44.660]   So there you have it.
[00:40:44.660 --> 00:40:50.500]   And so people in the audience you think either A, the show most go on.
[00:40:50.500 --> 00:40:51.500]   He's a trooper or B.
[00:40:51.500 --> 00:40:54.660]   I'm the world's biggest jerk.
[00:40:54.660 --> 00:40:57.820]   I'm just trying to find my mask or it's a leave below.
[00:40:57.820 --> 00:41:00.620]   I can't find it.
[00:41:00.620 --> 00:41:01.620]   Wow.
[00:41:01.620 --> 00:41:05.580]   I am I'm impressed by your perseverance.
[00:41:05.580 --> 00:41:06.580]   Well done.
[00:41:06.580 --> 00:41:08.660]   Roberta Baldwin.
[00:41:08.660 --> 00:41:13.580]   And here is a guy who pretty much has experienced the vision pro and there is his own.
[00:41:13.580 --> 00:41:17.820]   He built his own is unbiased review.
[00:41:17.820 --> 00:41:18.820]   Wow.
[00:41:18.820 --> 00:41:20.780]   It's a wheel bearings takeover.
[00:41:20.780 --> 00:41:22.980]   The wheel bearings crew is with us.
[00:41:22.980 --> 00:41:23.980]   It's great to have you.
[00:41:23.980 --> 00:41:25.980]   Nicole Wakefield, Roberto Baldwin.
[00:41:25.980 --> 00:41:26.980]   Is that a wrong?
[00:41:26.980 --> 00:41:33.420]   I'm going to start making a different game for you.
[00:41:33.420 --> 00:41:34.420]   Wakey, wakey.
[00:41:34.420 --> 00:41:35.420]   Nicole Wakey, wakey.
[00:41:35.420 --> 00:41:36.420]   Sorry.
[00:41:36.420 --> 00:41:37.420]   I know.
[00:41:37.420 --> 00:41:39.420]   I don't know why I have Wakefield in my.
[00:41:39.420 --> 00:41:40.420]   That's okay.
[00:41:40.420 --> 00:41:41.820]   I know somebody named Wakefield.
[00:41:41.820 --> 00:41:42.820]   That's why.
[00:41:42.820 --> 00:41:43.820]   Yeah.
[00:41:43.820 --> 00:41:44.820]   Okay.
[00:41:44.820 --> 00:41:45.820]   Nicole Wakeland.
[00:41:45.820 --> 00:41:46.820]   Right.
[00:41:46.820 --> 00:41:47.820]   Roberta Baldwin.
[00:41:47.820 --> 00:41:53.860]   And of course, Sam Ables, Sam and we will have more with our fabulous crew.
[00:41:53.860 --> 00:41:56.500]   I can see why this is I can see why your show is so good.
[00:41:56.500 --> 00:41:58.340]   You guys are great.
[00:41:58.340 --> 00:41:59.500]   We'll have more in just a bit.
[00:41:59.500 --> 00:42:03.620]   But first a word from our sponsor.
[00:42:03.620 --> 00:42:04.620]   Decisions.
[00:42:04.620 --> 00:42:10.020]   I love the name decisions and today's digital landscape businesses are faced with an overwhelming
[00:42:10.020 --> 00:42:12.340]   number of tools and systems.
[00:42:12.340 --> 00:42:16.740]   You got to have them right to operate effectively, but managing all these disparate tools and
[00:42:16.740 --> 00:42:18.980]   ensuring they work together seamlessly.
[00:42:18.980 --> 00:42:21.300]   That ends up being the biggest part of the job, right?
[00:42:21.300 --> 00:42:24.660]   That's where decisions is fantastic.
[00:42:24.660 --> 00:42:32.580]   It can change your life decisions is the ultimate orchestrator for IT and industry experts providing
[00:42:32.580 --> 00:42:37.860]   a unified platform for businesses to manage their digital infrastructure by automating
[00:42:37.860 --> 00:42:41.820]   routine tasks and customizing workflows.
[00:42:41.820 --> 00:42:48.860]   Decisions helps businesses reduce operational costs, improve customer service and streamline
[00:42:48.860 --> 00:42:50.980]   the overall process.
[00:42:50.980 --> 00:42:53.100]   It's incredible.
[00:42:53.100 --> 00:43:01.340]   These days business relies completely on digital technology, right?
[00:43:01.340 --> 00:43:03.700]   But it's constantly changing.
[00:43:03.700 --> 00:43:06.860]   Things happen on the fringe.
[00:43:06.860 --> 00:43:09.900]   Adaptability though is critical to stay ahead of the game.
[00:43:09.900 --> 00:43:13.940]   Decisions is a no-code platform that allows both developers and business users.
[00:43:13.940 --> 00:43:15.700]   You don't have to be a coder.
[00:43:15.700 --> 00:43:21.300]   But people with the knowledge that they're trying to encapsulate can build applications
[00:43:21.300 --> 00:43:22.340]   and automations.
[00:43:22.340 --> 00:43:24.380]   No coding involved at all.
[00:43:24.380 --> 00:43:28.340]   With decisions your team can collaborate to build and adjust workflows.
[00:43:28.340 --> 00:43:29.660]   You can do dynamic forms.
[00:43:29.660 --> 00:43:33.420]   You can do decision making processes that fit your unique business needs.
[00:43:33.420 --> 00:43:34.860]   I'll give you a really good example.
[00:43:34.860 --> 00:43:38.620]   When COVID first started, remember the PPM loans, the government decided we're going
[00:43:38.620 --> 00:43:42.340]   to land loan money to industry to keep those people employed.
[00:43:42.340 --> 00:43:44.140]   They did it very quickly.
[00:43:44.140 --> 00:43:49.260]   All of a sudden banks were in the position to make those loans, but it was a complicated
[00:43:49.260 --> 00:43:50.260]   process.
[00:43:50.260 --> 00:43:57.460]   There's one bank, used decisions to create an app on your iPhone that allowed you within
[00:43:57.460 --> 00:44:01.300]   a few days of the PPM loans that allowed you to apply for a loan.
[00:44:01.300 --> 00:44:05.260]   They got the lion's share PPM loans for the first few weeks because they were the first
[00:44:05.260 --> 00:44:11.220]   people to market with it all because decisions let them write that app to write that code,
[00:44:11.220 --> 00:44:16.060]   write that website quickly and easily with no code at all.
[00:44:16.060 --> 00:44:18.860]   Decisions has a very powerful workflow engine.
[00:44:18.860 --> 00:44:20.300]   You can define your own rules.
[00:44:20.300 --> 00:44:25.580]   Of course, they've got integrations that let you connect any legacy system via an API.
[00:44:25.580 --> 00:44:30.180]   Otis elevators has thousands of elevators all over the world.
[00:44:30.180 --> 00:44:32.340]   They all have different systems running them.
[00:44:32.340 --> 00:44:34.980]   It's not just one big unified platform.
[00:44:34.980 --> 00:44:41.340]   They were able to use decisions to create, again, no code, a system to check every elevator
[00:44:41.340 --> 00:44:43.260]   in the world every single day.
[00:44:43.260 --> 00:44:47.140]   Couldn't have done it without decisions.
[00:44:47.140 --> 00:44:49.900]   A simple drag and drop visual interface designer.
[00:44:49.900 --> 00:44:55.260]   The person who has the knowledge domain is able to create the tool and that is very powerful.
[00:44:55.260 --> 00:44:56.580]   Knowledgeier does this.
[00:44:56.580 --> 00:45:00.940]   They manage portfolios and investment activity for family accounting offices, investment
[00:45:00.940 --> 00:45:07.500]   firms, complicated digital landscape, lots of inputs, lots of knowledge flowing around.
[00:45:07.500 --> 00:45:11.860]   With decisions, they could completely integrate.
[00:45:11.860 --> 00:45:16.940]   They set it up so that knowledgeier could pull data from any database, communicate with
[00:45:16.940 --> 00:45:25.340]   every system and application in the process, and create a simplified, unified view, a pain-free
[00:45:25.340 --> 00:45:30.780]   solution to managing their portfolios, to streamlining operations, to improving their
[00:45:30.780 --> 00:45:32.260]   customer experience.
[00:45:32.260 --> 00:45:34.820]   That puts them ahead in the financial industry.
[00:45:34.820 --> 00:45:35.940]   There are so many great stories.
[00:45:35.940 --> 00:45:41.260]   If you go to the website, decisions.com/twit, look at some of the case studies.
[00:45:41.260 --> 00:45:42.780]   Look at some of the people who are using decisions.
[00:45:42.780 --> 00:45:47.460]   You'll see what an amazing thing decisions can be.
[00:45:47.460 --> 00:45:52.900]   Automating these little decisions, creating these rule-based flows, frees up valuable
[00:45:52.900 --> 00:45:55.380]   time for your team to focus on the bigger decisions.
[00:45:55.380 --> 00:46:01.380]   The ones that really need your brain to solve with decisions you can customize workflows
[00:46:01.380 --> 00:46:08.140]   to automate routine tasks, to reduce operational costs, and to serve your customers better.
[00:46:08.140 --> 00:46:12.380]   I think these days, the complicated digital landscape really needs something like decisions.
[00:46:12.380 --> 00:46:17.340]   A powerful, no-code solution that unifies business practices and makes managing your
[00:46:17.340 --> 00:46:19.900]   digital landscape used whenever before.
[00:46:19.900 --> 00:46:21.340]   Discover the power of decisions.
[00:46:21.340 --> 00:46:22.340]   Check that free demo.
[00:46:22.340 --> 00:46:23.740]   We're just showing you the form.
[00:46:23.740 --> 00:46:26.100]   You fill that out at decisions.com/twit.
[00:46:26.100 --> 00:46:28.140]   You can try it for yourself.
[00:46:28.140 --> 00:46:34.300]   Today's constantly changing digital landscape, the ability to manage all these tools, all
[00:46:34.300 --> 00:46:42.860]   these disparate sources of information, put them together in one simple interface is huge.
[00:46:42.860 --> 00:46:45.140]   You've got to be able to do this.
[00:46:45.140 --> 00:46:50.060]   Decisions, no-code automation software really simplifies the complexity of managing multiple
[00:46:50.060 --> 00:46:53.140]   systems, which means you can unify your operations.
[00:46:53.140 --> 00:46:54.540]   You can reduce your operational costs.
[00:46:54.540 --> 00:46:55.540]   You could drive company growth.
[00:46:55.540 --> 00:47:01.700]   To learn more about decisions and their no-code automation platform, it's really mind-boggling.
[00:47:01.700 --> 00:47:04.300]   Claim your free demo at decisions.com/twit.
[00:47:04.300 --> 00:47:08.700]   Again, decisions, just like the word decisions, you've got a lot of them to make.
[00:47:08.700 --> 00:47:10.300]   This is an easy one.
[00:47:10.300 --> 00:47:11.300]   Decisions.com/twit.
[00:47:11.300 --> 00:47:14.460]   We thank you so much for their support.
[00:47:14.460 --> 00:47:22.420]   This week in tech and our wheel bearings takeover, the other big stories, there were
[00:47:22.420 --> 00:47:24.660]   two really big stories this week.
[00:47:24.660 --> 00:47:28.380]   The other one I think affects us all.
[00:47:28.380 --> 00:47:30.660]   This is what's happening at Reddit.
[00:47:30.660 --> 00:47:32.420]   I imagine you pay attention to this.
[00:47:32.420 --> 00:47:35.860]   I'm a big Reddit user.
[00:47:35.860 --> 00:47:38.820]   It all started when Reddit decided, first of all, it really all started.
[00:47:38.820 --> 00:47:42.980]   The truth is it really all started when Reddit decided to go public, to do an IPO.
[00:47:42.980 --> 00:47:45.500]   Reddit was purchased by Conde Nast.
[00:47:45.500 --> 00:47:49.300]   They spun it out as a standalone company, but they still have the majority holder.
[00:47:49.300 --> 00:47:51.660]   They decided to have an IPO.
[00:47:51.660 --> 00:47:54.580]   Of course, when the problem is Reddit's never made any money.
[00:47:54.580 --> 00:47:56.140]   It's only lost money.
[00:47:56.140 --> 00:47:57.980]   Before you do an IPO, you want to figure out a way.
[00:47:57.980 --> 00:48:02.740]   How can we show people that we are going to make a nice, tidy profit?
[00:48:02.740 --> 00:48:05.420]   Well, the first thing you do is you look over at Elon Musk.
[00:48:05.420 --> 00:48:08.060]   What's he doing over at Twitter?
[00:48:08.060 --> 00:48:11.340]   Maybe not the best idea, but anyway, that's what they did.
[00:48:11.340 --> 00:48:12.900]   They said, "Oh, look what Elon did.
[00:48:12.900 --> 00:48:17.380]   He started charging for the API.
[00:48:17.380 --> 00:48:19.700]   Started charging a lot for the API."
[00:48:19.700 --> 00:48:24.300]   Reddit announced that all third-party apps, anything they integrated with Reddit that wasn't
[00:48:24.300 --> 00:48:28.620]   company property, would pay these fees.
[00:48:28.620 --> 00:48:34.220]   Really the battle began when the creator of Apollo, which is an excellent iOS third-party
[00:48:34.220 --> 00:48:37.020]   app for Reddit, the one I use on my iPhone and iPad.
[00:48:37.020 --> 00:48:39.460]   I love Apollo.
[00:48:39.460 --> 00:48:46.060]   And a Selig posted, "Hey, I've talked to Reddit about this API, and based on my number of
[00:48:46.060 --> 00:48:53.020]   users, it's going to cost me $20 million a year to continue to run Apollo."
[00:48:53.020 --> 00:48:56.220]   He since announced that June 30th, Apollo goes away.
[00:48:56.220 --> 00:48:57.220]   It's gone.
[00:48:57.220 --> 00:48:58.220]   Why?
[00:48:58.220 --> 00:49:00.140]   He doesn't want to pay $20 million a year.
[00:49:00.140 --> 00:49:01.140]   Yeah.
[00:49:01.140 --> 00:49:02.140]   What?
[00:49:02.140 --> 00:49:04.340]   What kind of fool are you?
[00:49:04.340 --> 00:49:06.500]   It's only $20 million.
[00:49:06.500 --> 00:49:09.060]   It is fun, RIF also going away.
[00:49:09.060 --> 00:49:11.980]   A number of third-party apps have decided to go away.
[00:49:11.980 --> 00:49:18.580]   A number of subreddits, the Reddit communities have announced they are going dark starting
[00:49:18.580 --> 00:49:19.580]   tomorrow.
[00:49:19.580 --> 00:49:21.060]   A little boycott.
[00:49:21.060 --> 00:49:24.980]   One iPhone says, "We're going dark forever."
[00:49:24.980 --> 00:49:27.860]   Then CEO Steve Hoffman says, "Let's have an AMA.
[00:49:27.860 --> 00:49:30.340]   I can solve this."
[00:49:30.340 --> 00:49:31.740]   Doesn't answer a lot of questions.
[00:49:31.740 --> 00:49:37.020]   I think the last time I saw his karma was down below $100,000.
[00:49:37.020 --> 00:49:45.060]   As bad as you can get, the moderators of /R videos wrote that Huffman's AMA performance
[00:49:45.060 --> 00:49:51.820]   was a collage of inappropriate responses.
[00:49:51.820 --> 00:49:57.580]   He also kind of implied that a Selig, the creator of Apollo, was lying, Selig said,
[00:49:57.580 --> 00:50:02.380]   "You know, it just turns out I live in Canada, a one-party country.
[00:50:02.380 --> 00:50:08.700]   I recorded all our conversations, Steve, and he posted them and showed that in fact,
[00:50:08.700 --> 00:50:14.060]   Huffman was misrepresenting the conversation completely."
[00:50:14.060 --> 00:50:17.220]   Huffman at that point in the AMA said, "Well, we're just not going to do business with this
[00:50:17.220 --> 00:50:19.260]   Apollo guy."
[00:50:19.260 --> 00:50:21.340]   There is a nasty battle of brewing.
[00:50:21.340 --> 00:50:26.420]   I wonder how this is going to affect Reddit because I tell you what, I can get away with,
[00:50:26.420 --> 00:50:29.860]   I can lose Twitter, not happy about it, but I can lose Twitter.
[00:50:29.860 --> 00:50:31.260]   I don't want to lose Reddit.
[00:50:31.260 --> 00:50:35.780]   It looks like it's almost as if users have finally realized, "Hey, you know what?
[00:50:35.780 --> 00:50:37.460]   We have the power here."
[00:50:37.460 --> 00:50:41.860]   What do you think, Sam?
[00:50:41.860 --> 00:50:46.180]   Obviously, Reddit does need to make money.
[00:50:46.180 --> 00:50:51.140]   There is a cost associated with providing these APIs just as Twitter and every other
[00:50:51.140 --> 00:50:58.580]   company that does APIs like Google and Microsoft and Facebook and everybody else.
[00:50:58.580 --> 00:51:01.060]   There's a cost associated with that.
[00:51:01.060 --> 00:51:08.100]   It's not unreasonable to charge some amount of money to cover those costs.
[00:51:08.100 --> 00:51:10.260]   It's the way business works.
[00:51:10.260 --> 00:51:12.860]   I don't know Reddit's financings.
[00:51:12.860 --> 00:51:19.060]   I don't know how much it actually would cost them to provide these APIs, but I'm guessing
[00:51:19.060 --> 00:51:27.500]   that it's a lot less than $20 million a year for the amount of hits that they would get
[00:51:27.500 --> 00:51:30.380]   from somebody like Apollo.
[00:51:30.380 --> 00:51:39.220]   I don't know what Reddit's financial, what their costs are, but I think if there were
[00:51:39.220 --> 00:51:44.540]   a reasonable cost for access to those APIs, I think that would be perfectly fair.
[00:51:44.540 --> 00:51:47.380]   It's legitimate.
[00:51:47.380 --> 00:51:53.940]   If you're building your business on top of somebody else's platform, it's not unreasonable
[00:51:53.940 --> 00:52:01.020]   to expect to be paid or to expect to pay some amount for access to that platform.
[00:52:01.020 --> 00:52:03.140]   It's just a question of fairness.
[00:52:03.140 --> 00:52:10.500]   How much is actually fair based on the real cost and what people are willing, what your
[00:52:10.500 --> 00:52:13.780]   downstream customers are willing to pay?
[00:52:13.780 --> 00:52:17.780]   When Reddit announced this, my initial reaction is, well, at least they gave you notice.
[00:52:17.780 --> 00:52:19.620]   Twitter just pulled the plug.
[00:52:19.620 --> 00:52:21.220]   Yeah, very true.
[00:52:21.220 --> 00:52:22.900]   One day everything just stopped working.
[00:52:22.900 --> 00:52:23.900]   Stopped working.
[00:52:23.900 --> 00:52:26.100]   Then they said, "What are you talking about?"
[00:52:26.100 --> 00:52:34.260]   Then they said, "Oh no, these third party apps have broken our rules."
[00:52:34.260 --> 00:52:35.260]   That's it.
[00:52:35.260 --> 00:52:36.260]   They broke our rules.
[00:52:36.260 --> 00:52:38.620]   Then the creator of TapBot said, "What are you talking about?
[00:52:38.620 --> 00:52:40.020]   We've been doing this for 15 years.
[00:52:40.020 --> 00:52:41.500]   What rules do we break?"
[00:52:41.500 --> 00:52:45.540]   Then Reddit said, "These rules, the ones we just wrote."
[00:52:45.540 --> 00:52:46.540]   I mean, not Reddit.
[00:52:46.540 --> 00:52:51.300]   Twitter said, "These rules, the ones we just wrote, it was terribly handled."
[00:52:51.300 --> 00:52:54.100]   I thought, "Oh, Reddit, at least they announced it.
[00:52:54.100 --> 00:52:56.500]   They gave you time.
[00:52:56.500 --> 00:52:57.500]   You're right, Sam.
[00:52:57.500 --> 00:53:01.100]   They have a right to make money on this if they're losing money and others third parties
[00:53:01.100 --> 00:53:04.460]   are making money, sharing the proceeds.
[00:53:04.460 --> 00:53:07.460]   Of course, 20 millions a little.
[00:53:07.460 --> 00:53:08.460]   That's I'm sure more than Apollo makes.
[00:53:08.460 --> 00:53:14.620]   Seems a bit disingenuous that it cost them 20 million to host, to have these APIs going
[00:53:14.620 --> 00:53:15.620]   for this one app.
[00:53:15.620 --> 00:53:19.780]   I'm like, "I think you would have collapsed years ago if that was the case."
[00:53:19.780 --> 00:53:24.660]   I think that was Christian's point is, "Look, I understand I'm willing to give you some
[00:53:24.660 --> 00:53:33.580]   of my money, but you're asking for much, much more than it's costing you."
[00:53:33.580 --> 00:53:38.420]   This is the thing that he then said, "Look, if you say that I'm costing you 20 million,
[00:53:38.420 --> 00:53:39.980]   why don't you buy a pile?
[00:53:39.980 --> 00:53:43.220]   I'll sell it to you for 10 and you're going to make money.
[00:53:43.220 --> 00:53:45.220]   You're going to make money."
[00:53:45.220 --> 00:53:46.220]   You're going to make money.
[00:53:46.220 --> 00:53:57.340]   My guess is that Reddit doesn't see a whole lot of potential revenue streams.
[00:53:57.340 --> 00:54:00.820]   They've got a lot of costs across a lot of different things that they can't necessarily
[00:54:00.820 --> 00:54:05.380]   directly recover revenue on that.
[00:54:05.380 --> 00:54:10.140]   They look at the APIs and say, "Well, that's one place where we can pull in some money.
[00:54:10.140 --> 00:54:15.180]   Let's use that to cover the cost of all this other stuff that we have to do."
[00:54:15.180 --> 00:54:20.300]   Anybody using those APIs is getting disproportionately hit by those costs.
[00:54:20.300 --> 00:54:25.340]   Remember, if you're using a third-party app, you may not be seeing the ads, the Reddit
[00:54:25.340 --> 00:54:26.540]   posts on the...
[00:54:26.540 --> 00:54:28.060]   Reddit, by the way, has apps.
[00:54:28.060 --> 00:54:29.340]   They're not very good.
[00:54:29.340 --> 00:54:30.860]   That's why people use the third-party apps.
[00:54:30.860 --> 00:54:37.580]   Of course, they have a website where you would see the ads or as I do pay for Reddit so that
[00:54:37.580 --> 00:54:39.940]   I don't see the ads.
[00:54:39.940 --> 00:54:44.340]   I guess just like the Twitter third-party apps, Reddit's feeling like, "Well, you're
[00:54:44.340 --> 00:54:48.660]   hiding our ads, so you're costing us money and you're not letting us recoup that money."
[00:54:48.660 --> 00:54:49.660]   That's not...
[00:54:49.660 --> 00:54:52.980]   I feel like there could have been a resolution that included adshare revenue.
[00:54:52.980 --> 00:54:53.980]   Yeah.
[00:54:53.980 --> 00:54:58.980]   Ad revenue sharing is between the applications and Reddit.
[00:54:58.980 --> 00:55:04.140]   There's a lot of ways that Reddit could have figured out how to do this, but instead they
[00:55:04.140 --> 00:55:05.900]   just went full hammer.
[00:55:05.900 --> 00:55:11.100]   We're just charged for APIs because we saw that worked out so well for Twitter.
[00:55:11.100 --> 00:55:12.900]   It's such a weird choice.
[00:55:12.900 --> 00:55:16.060]   Even if they do that, isn't somewhere there's some bean counter?
[00:55:16.060 --> 00:55:19.300]   He's like, "Well, if we charge X and the break even, we'll lose these guys if we go
[00:55:19.300 --> 00:55:22.300]   this high and we'll keep these guys if we go this low."
[00:55:22.300 --> 00:55:26.300]   You feel like somebody should have crunched some numbers back there and said, "20 million
[00:55:26.300 --> 00:55:28.220]   dollars is going to be unreasonable.
[00:55:28.220 --> 00:55:31.020]   We will make absolutely nothing on that."
[00:55:31.020 --> 00:55:32.380]   It feels like somebody...
[00:55:32.380 --> 00:55:33.780]   They forget to check with an account.
[00:55:33.780 --> 00:55:35.100]   That's a good point.
[00:55:35.100 --> 00:55:38.540]   You priced it so high, you lost the sale, in effect.
[00:55:38.540 --> 00:55:40.580]   That's a very good point.
[00:55:40.580 --> 00:55:47.060]   Tomorrow, according to the BBC, 3500 subreddits will go dark.
[00:55:47.060 --> 00:55:52.700]   Most for two days, although as I said, our /iPhone and our /Music, two of the biggest
[00:55:52.700 --> 00:55:57.420]   subreddits are going to go dark, they say forever.
[00:55:57.420 --> 00:56:00.380]   I think there's going to be some people that leave Reddit.
[00:56:00.380 --> 00:56:03.900]   The problem is there is really no good alternative.
[00:56:03.900 --> 00:56:07.060]   It's not like Twitter where there are lots of places you could go.
[00:56:07.060 --> 00:56:08.700]   There is a Fed of Dig...
[00:56:08.700 --> 00:56:09.700]   Oh, no, never mind.
[00:56:09.700 --> 00:56:10.700]   Dig.
[00:56:10.700 --> 00:56:11.700]   Dig.
[00:56:11.700 --> 00:56:12.700]   Never?
[00:56:12.700 --> 00:56:16.940]   Actually, Reddit Discord is a copy dig, didn't it?
[00:56:16.940 --> 00:56:19.900]   I think Discord is a place that a lot of people are going to start ending up for some of
[00:56:19.900 --> 00:56:22.300]   these very niche communities.
[00:56:22.300 --> 00:56:26.340]   You can just start a Discord server and you can have people on there.
[00:56:26.340 --> 00:56:30.060]   If you're on Discord and you want a better experience, you can pay a little bit more
[00:56:30.060 --> 00:56:32.460]   to get Nitro or you can pay.
[00:56:32.460 --> 00:56:37.860]   You have enough people in your community here paying for Nitro and in your paying a little
[00:56:37.860 --> 00:56:40.260]   extra so you can do more things with your community.
[00:56:40.260 --> 00:56:44.820]   Discord seems to have figured out a way to make money doing this.
[00:56:44.820 --> 00:56:45.980]   That's what iPhone is doing.
[00:56:45.980 --> 00:56:54.100]   If they say if you go to the /iPhone, they'll say join our Reddit Discord and here it is.
[00:56:54.100 --> 00:56:56.340]   12,000 members now.
[00:56:56.340 --> 00:57:01.660]   1,687 people actually actively online.
[00:57:01.660 --> 00:57:03.020]   Maybe they have found an alternative.
[00:57:03.020 --> 00:57:06.220]   For me, I'm a Reddit lurker.
[00:57:06.220 --> 00:57:09.100]   I confess I don't contribute as much as I auto.
[00:57:09.100 --> 00:57:10.860]   I've done AMAs and stuff.
[00:57:10.860 --> 00:57:15.980]   Mostly, I'm a read-only Reddit user.
[00:57:15.980 --> 00:57:19.660]   That's a big loss to lose the content on Reddit.
[00:57:19.660 --> 00:57:25.420]   Frankly, Reddit is so useful that a lot of people instead of searching Google, they search
[00:57:25.420 --> 00:57:31.020]   Reddit.com for answers to questions like, "What's the best car?
[00:57:31.020 --> 00:57:32.860]   What's the best EV?
[00:57:32.860 --> 00:57:35.140]   It's a much better place to search than Google."
[00:57:35.140 --> 00:57:37.220]   Not just because of Will Baronksal.
[00:57:37.220 --> 00:57:39.460]   Best place to be going to Will Baronksal, obviously.
[00:57:39.460 --> 00:57:41.460]   You just hassle one of us on the internet.
[00:57:41.460 --> 00:57:42.460]   No, we'll tell you.
[00:57:42.460 --> 00:57:43.460]   That's what I do.
[00:57:43.460 --> 00:57:44.460]   I ask Sam.
[00:57:44.460 --> 00:57:45.460]   He was a good old hustle.
[00:57:45.460 --> 00:57:49.220]   I can't buy it till I talk to my expert years.
[00:57:49.220 --> 00:57:53.980]   Sam, I'm kind of mourning the loss of Twitter.
[00:57:53.980 --> 00:57:58.100]   I know you guys still use it, but I feel like Twitter has turned into something that it
[00:57:58.100 --> 00:57:59.100]   wasn't.
[00:57:59.100 --> 00:58:00.700]   I don't use it anymore.
[00:58:00.700 --> 00:58:01.860]   You stop.
[00:58:01.860 --> 00:58:05.700]   I'm on it because I have friends who are still on it and they refuse to move to mask
[00:58:05.700 --> 00:58:07.420]   the Donner blue sky or whatever.
[00:58:07.420 --> 00:58:09.300]   The other 50 things that are out there right now.
[00:58:09.300 --> 00:58:11.820]   I have a lot of friends who are still on it saying things.
[00:58:11.820 --> 00:58:13.540]   I haven't left.
[00:58:13.540 --> 00:58:15.700]   It's never been good for traffic.
[00:58:15.700 --> 00:58:19.540]   It's never, if you've ever worked at any website and you've known anything about the analytics
[00:58:19.540 --> 00:58:23.700]   of that website, you know that Twitter traffic to your site is nothing.
[00:58:23.700 --> 00:58:24.700]   It's really nothing.
[00:58:24.700 --> 00:58:27.060]   It's mostly just a place where everyone just goes and hangs out and like, "Hey, look at
[00:58:27.060 --> 00:58:28.060]   this thing."
[00:58:28.060 --> 00:58:30.020]   Five people look at it.
[00:58:30.020 --> 00:58:39.020]   There is a fetaverse version of Reddit named Lemme of all things.
[00:58:39.020 --> 00:58:40.820]   I don't know if it's named after Lemme.
[00:58:40.820 --> 00:58:41.820]   Like the base player?
[00:58:41.820 --> 00:58:42.820]   Like the...
[00:58:42.820 --> 00:58:43.820]   I don't know if it's named from Motorhead?
[00:58:43.820 --> 00:58:44.820]   Yeah.
[00:58:44.820 --> 00:58:45.820]   I don't know if it's named from Lemme or what?
[00:58:45.820 --> 00:58:46.820]   I'm on...
[00:58:46.820 --> 00:58:47.820]   So it's federated.
[00:58:47.820 --> 00:58:53.020]   This is the one I'm on Lemme.world, which is the biggest instance right now.
[00:58:53.020 --> 00:58:54.420]   It's like a few weeks old.
[00:58:54.420 --> 00:58:59.620]   If you go to the communities, they throw slowly.
[00:58:59.620 --> 00:59:00.700]   Communities are there sub-read.
[00:59:00.700 --> 00:59:05.380]   It's basically they're slowly creating a bunch of sub-readits.
[00:59:05.380 --> 00:59:08.700]   It's nowhere near the volume of traffic.
[00:59:08.700 --> 00:59:13.140]   Ironically, because this all started because third-party apps didn't want to pay the
[00:59:13.140 --> 00:59:14.140]   API.
[00:59:14.140 --> 00:59:18.220]   As far as I know, no Lemme third-party iOS or Android apps.
[00:59:18.220 --> 00:59:20.220]   There's no mobile apps.
[00:59:20.220 --> 00:59:24.020]   So I don't know if Lemme is going to be a reasonable alternative.
[00:59:24.020 --> 00:59:25.580]   I just don't know.
[00:59:25.580 --> 00:59:28.780]   I don't think there's anywhere like Reddit in the world.
[00:59:28.780 --> 00:59:31.940]   There's a wealth of knowledge on there.
[00:59:31.940 --> 00:59:40.020]   That's sadly going to be either decimated or it's going to disappear in five, ten years
[00:59:40.020 --> 00:59:44.220]   because they've blown it over Reddit because they keep driving people away and then they
[00:59:44.220 --> 00:59:49.460]   just delete everything or people are going to contribute into it anymore.
[00:59:49.460 --> 00:59:54.900]   So all the information, any new information is going to be contributed to all these other
[00:59:54.900 --> 00:59:55.900]   sites.
[00:59:55.900 --> 01:00:00.460]   So you sort of lose that one central spot where you can find out about who played the
[01:00:00.460 --> 01:00:06.180]   dog in Gremlins or how do I hard reset an iPhone 11 or whatever people are looking
[01:00:06.180 --> 01:00:07.580]   for on Reddit.
[01:00:07.580 --> 01:00:10.260]   That's sort of the thing.
[01:00:10.260 --> 01:00:11.820]   It's like trying to figure out what it's going to be.
[01:00:11.820 --> 01:00:16.060]   If there was one clear like, well, instead of Reddit here, but there's not, you have
[01:00:16.060 --> 01:00:17.780]   no idea what's going to take over for it.
[01:00:17.780 --> 01:00:21.820]   So if there's a bunch of little things that pop up like Lemme and other things that are
[01:00:21.820 --> 01:00:26.740]   all sort of substitute Reddit's, in the time it takes to figure out which one's going to
[01:00:26.740 --> 01:00:30.620]   win, you've got your information scattered all over the place.
[01:00:30.620 --> 01:00:34.940]   I think the ownership is thinking, well, this too shall pass.
[01:00:34.940 --> 01:00:39.020]   There's been an enormous revolts on Reddit in the past.
[01:00:39.020 --> 01:00:46.460]   But I also think there's a lesson to be learned from Twitter that users are starting to understand
[01:00:46.460 --> 01:00:50.980]   that they are the, they are the, they're what brings the value to these social platforms
[01:00:50.980 --> 01:00:51.980]   without.
[01:00:51.980 --> 01:00:52.980]   You're the content.
[01:00:52.980 --> 01:00:56.460]   You're creating what, why these things are worth anything.
[01:00:56.460 --> 01:00:57.460]   It's you.
[01:00:57.460 --> 01:00:59.180]   You're the reason why Twitter is good.
[01:00:59.180 --> 01:01:01.580]   It's not because Twitter was ever run really well.
[01:01:01.580 --> 01:01:02.580]   It's never been run well.
[01:01:02.580 --> 01:01:05.140]   It's just run horribly.
[01:01:05.140 --> 01:01:09.580]   But the only reason Twitter exists and Twitter is thrived is because of the people who are
[01:01:09.580 --> 01:01:13.060]   on Twitter, not because of the corporate overlords.
[01:01:13.060 --> 01:01:14.060]   Exactly.
[01:01:14.060 --> 01:01:17.820]   And it's the same thing for Reddit.
[01:01:17.820 --> 01:01:22.860]   I wonder if it's just, I mean, there are people saying, I'm going to delete all my content
[01:01:22.860 --> 01:01:23.860]   and I'm leaving.
[01:01:23.860 --> 01:01:24.860]   I will never post again.
[01:01:24.860 --> 01:01:28.780]   There are at least two major subreddits who are saying we're closing.
[01:01:28.780 --> 01:01:30.500]   We're gone.
[01:01:30.500 --> 01:01:34.340]   I hope this isn't just a, it feels a little, I can't decide.
[01:01:34.340 --> 01:01:37.100]   Is it a temper tantrum by the users?
[01:01:37.100 --> 01:01:44.100]   Are they feeling empowered by the social media spring and are they revolting and maybe they're
[01:01:44.100 --> 01:01:49.540]   going to break something irreparably that never will be recreated?
[01:01:49.540 --> 01:01:51.820]   Should we just put up with this?
[01:01:51.820 --> 01:01:58.580]   I mean, honestly, yeah, it's sad for Christian and other third party app developers.
[01:01:58.580 --> 01:02:04.980]   But is that a good enough reason to abandon Reddit?
[01:02:04.980 --> 01:02:05.980]   Something of such a...
[01:02:05.980 --> 01:02:10.060]   Is it trying to make things, I mean, is that the sacrifice sort of that needs to be done
[01:02:10.060 --> 01:02:11.060]   for the greater good?
[01:02:11.060 --> 01:02:15.860]   Like, do you need to sacrifice now and get rid of some of these big things that are leaving
[01:02:15.860 --> 01:02:16.860]   Reddit?
[01:02:16.860 --> 01:02:17.860]   They're saying that's it.
[01:02:17.860 --> 01:02:18.860]   We're shutting down.
[01:02:18.860 --> 01:02:22.220]   We're done so that whatever comes next needs to have the situation.
[01:02:22.220 --> 01:02:23.220]   I feel like it's a little...
[01:02:23.220 --> 01:02:28.140]   I don't want to say this, but I feel like it's a little childish on the part of Redditors
[01:02:28.140 --> 01:02:30.020]   who are saying, "Well, darn it, that's it.
[01:02:30.020 --> 01:02:31.020]   I'm out of here."
[01:02:31.020 --> 01:02:36.340]   I mean, look, I don't think Steve Huffman's doing the right thing by any means.
[01:02:36.340 --> 01:02:39.180]   Are the Reddit owners doing the right thing?
[01:02:39.180 --> 01:02:41.020]   They have the right to do that.
[01:02:41.020 --> 01:02:47.260]   But what other recourse do you have to make as a community member to making your voice
[01:02:47.260 --> 01:02:48.260]   heard?
[01:02:48.260 --> 01:02:49.260]   Right.
[01:02:49.260 --> 01:02:57.900]   If these third party apps make the Reddit experience so much better and Reddit is effectively
[01:02:57.900 --> 01:03:04.620]   killing off those apps, and they are worsening your user experience on that site, on that
[01:03:04.620 --> 01:03:10.140]   platform, how well, aside from saying, "I'm going to leave," or "We're going to shut
[01:03:10.140 --> 01:03:13.580]   down the subreddit," what other means do you...
[01:03:13.580 --> 01:03:17.460]   I mean, you can send a tweet to Steve Huffman or send him an email complaining.
[01:03:17.460 --> 01:03:18.460]   No, you're right.
[01:03:18.460 --> 01:03:19.460]   Yeah.
[01:03:19.460 --> 01:03:25.180]   But I also have to say, "Huffman is acting like I don't care what you do.
[01:03:25.180 --> 01:03:26.660]   This is happening."
[01:03:26.660 --> 01:03:29.060]   He's not showing any flexibility.
[01:03:29.060 --> 01:03:33.140]   I thought initially once he sees this reaction, he's going to back down.
[01:03:33.140 --> 01:03:34.660]   They're going to adjust the pricing.
[01:03:34.660 --> 01:03:39.540]   They're going to do something to keep Apollo and Riff and all the apps going.
[01:03:39.540 --> 01:03:46.180]   Somebody's saying in our IRC, and it's really true, that if you try to use Reddit on mobile,
[01:03:46.180 --> 01:03:49.540]   you have to use a third party app because the Reddit apps are terrible.
[01:03:49.540 --> 01:03:50.540]   That's horrible.
[01:03:50.540 --> 01:03:51.540]   Yeah.
[01:03:51.540 --> 01:03:53.140]   On the web, Reddit's all right.
[01:03:53.140 --> 01:03:54.140]   No.
[01:03:54.140 --> 01:03:55.140]   Yeah.
[01:03:55.140 --> 01:03:56.140]   I won't.
[01:03:56.140 --> 01:03:57.740]   Apollo is so much better.
[01:03:57.740 --> 01:03:59.700]   I use Joey on Android.
[01:03:59.700 --> 01:04:05.740]   It's so much better than the native Reddit apps, which are really terrible.
[01:04:05.740 --> 01:04:09.300]   But I don't want to lose a Reddit.
[01:04:09.300 --> 01:04:12.220]   I think this is a huge loss to the internet.
[01:04:12.220 --> 01:04:16.620]   Do you think maybe as we're recording this and as this is all happening, the behind the
[01:04:16.620 --> 01:04:18.300]   scenes, someone's saying, "Wait, we can't let this happen.
[01:04:18.300 --> 01:04:19.300]   We're going to take some changes."
[01:04:19.300 --> 01:04:21.660]   I think there's conversations happening.
[01:04:21.660 --> 01:04:22.660]   Yeah.
[01:04:22.660 --> 01:04:24.100]   That's seriously what I thought was going to happen.
[01:04:24.100 --> 01:04:25.100]   That's what I said earlier this week.
[01:04:25.100 --> 01:04:30.580]   I said, "Well, with this kind of action from its users, Reddit's got to back down."
[01:04:30.580 --> 01:04:32.580]   But I see no signs of that.
[01:04:32.580 --> 01:04:33.940]   And the AMA is all right.
[01:04:33.940 --> 01:04:34.940]   Monday morning.
[01:04:34.940 --> 01:04:36.740]   Monday, everything will change.
[01:04:36.740 --> 01:04:37.740]   Oh, you're...
[01:04:37.740 --> 01:04:38.740]   Something is like, "Oh, we..."
[01:04:38.740 --> 01:04:42.620]   Isn't it called the optimist of the wheel bearings crowd?
[01:04:42.620 --> 01:04:44.660]   I think so.
[01:04:44.660 --> 01:04:45.660]   Maybe I'm trying.
[01:04:45.660 --> 01:04:46.660]   I'm trying.
[01:04:46.660 --> 01:04:47.660]   I don't want to see Reddit disappear.
[01:04:47.660 --> 01:04:48.660]   I'm going to try and be optimistic.
[01:04:48.660 --> 01:04:49.660]   It's going to be all right.
[01:04:49.660 --> 01:04:50.660]   The world's going to persevere.
[01:04:50.660 --> 01:04:51.660]   It's going to be okay.
[01:04:51.660 --> 01:04:52.660]   It's going to be all right.
[01:04:52.660 --> 01:04:53.660]   It's going to be okay.
[01:04:53.660 --> 01:04:54.660]   It's going to be okay, Leo.
[01:04:54.660 --> 01:04:55.660]   Thank you.
[01:04:55.660 --> 01:04:58.900]   Somebody's got to counteract the cranky old guys.
[01:04:58.900 --> 01:05:03.620]   Sometimes people just buy things and they don't know how to run them.
[01:05:03.620 --> 01:05:05.900]   A lot of places that have bought publications.
[01:05:05.900 --> 01:05:09.180]   They just don't understand how these businesses work.
[01:05:09.180 --> 01:05:13.380]   I'm just going to lay everyone off and get, I don't know, AI to write things.
[01:05:13.380 --> 01:05:16.740]   You're like, "Oh, no, that's not how..."
[01:05:16.740 --> 01:05:17.740]   Okay.
[01:05:17.740 --> 01:05:21.180]   You've just destroyed 20 decades of reputation.
[01:05:21.180 --> 01:05:24.940]   But sure, you saved $500,000 last year.
[01:05:24.940 --> 01:05:25.940]   Good job.
[01:05:25.940 --> 01:05:26.940]   Good job.
[01:05:26.940 --> 01:05:28.700]   I do understand Christian's point of view.
[01:05:28.700 --> 01:05:32.580]   I think he's being a little cranky about it, but I understand his point of view.
[01:05:32.580 --> 01:05:34.900]   There's no way he can run that app.
[01:05:34.900 --> 01:05:40.420]   I don't know how much he makes, but I doubt it's $20 million a year.
[01:05:40.420 --> 01:05:44.460]   There's no way he can continue, so he has to close it down.
[01:05:44.460 --> 01:05:48.500]   I think it's on Reddit to save it.
[01:05:48.500 --> 01:05:49.500]   They might.
[01:05:49.500 --> 01:05:51.340]   Positivity Leo, they might.
[01:05:51.340 --> 01:05:54.460]   They might be right now trying to figure out they have created a disaster.
[01:05:54.460 --> 01:05:55.380]   They've created a mess.
[01:05:55.380 --> 01:05:57.540]   They've killed their killing Reddit.
[01:05:57.540 --> 01:05:58.540]   How do you save it?
[01:05:58.540 --> 01:06:00.900]   You have to backtrack on some of this.
[01:06:00.900 --> 01:06:04.020]   That's really the only way to save a little bit of it.
[01:06:04.020 --> 01:06:05.540]   Otherwise, it's going to be a problem.
[01:06:05.540 --> 01:06:06.540]   You have to backtrack it.
[01:06:06.540 --> 01:06:09.100]   The CEO more interested in saving Reddit or saving face.
[01:06:09.100 --> 01:06:10.100]   That's where you're really coming.
[01:06:10.100 --> 01:06:11.100]   It's a good...
[01:06:11.100 --> 01:06:15.820]   A lot of CEOs are very much like, "I can't be the guy who was brought down by the guy
[01:06:15.820 --> 01:06:17.620]   who makes that one app."
[01:06:17.620 --> 01:06:21.860]   Or you the guy who's going to bring down all the Reddit because you wouldn't change what
[01:06:21.860 --> 01:06:23.500]   you're doing, which is worse.
[01:06:23.500 --> 01:06:27.980]   Well, this thing, as a CEO, you just get another job that pays you a lot of money.
[01:06:27.980 --> 01:06:33.060]   Well, the interesting thing about Steve Huffman is he's one of the original founders.
[01:06:33.060 --> 01:06:35.300]   He and Alexis O'Haney and founded Reddit.
[01:06:35.300 --> 01:06:36.540]   Steve wrote the original code.
[01:06:36.540 --> 01:06:38.820]   He wrote it in commonless.
[01:06:38.820 --> 01:06:43.700]   I've interviewed him and Alexis in the past on triangulation.
[01:06:43.700 --> 01:06:51.380]   I have to think Steve has some deep-rooted love for the platform he created.
[01:06:51.380 --> 01:06:55.340]   I can't imagine he wants it to go away.
[01:06:55.340 --> 01:07:02.820]   He, of course, has a board and he has Conde Nast breathing down his throat and share other
[01:07:02.820 --> 01:07:04.500]   shareholders.
[01:07:04.500 --> 01:07:07.460]   He may not be free to do whatever he wants.
[01:07:07.460 --> 01:07:17.460]   Christian Selig says he has 50,000 subscribers to Apollo, so he would have to charge them
[01:07:17.460 --> 01:07:20.860]   a lot of money to make $20 million.
[01:07:20.860 --> 01:07:22.340]   To make $20 million.
[01:07:22.340 --> 01:07:29.940]   It's not like he's got that kind of income.
[01:07:29.940 --> 01:07:30.940]   Going from...
[01:07:30.940 --> 01:07:31.940]   He wrote...
[01:07:31.940 --> 01:07:32.940]   That's only 400 bucks a year.
[01:07:32.940 --> 01:07:34.940]   Yeah, it's only 400 bucks a year.
[01:07:34.940 --> 01:07:35.940]   We're both doing math.
[01:07:35.940 --> 01:07:36.940]   Hold on, man.
[01:07:36.940 --> 01:07:37.940]   I know that's really good I take out.
[01:07:37.940 --> 01:07:40.940]   It's not really quiet while everyone is doing calculator.
[01:07:40.940 --> 01:07:41.940]   They were all mathing.
[01:07:41.940 --> 01:07:44.860]   You can pay 400 bucks for the information.
[01:07:44.860 --> 01:07:47.580]   You can pay 400 bucks for a Reddit, right?
[01:07:47.580 --> 01:07:48.580]   Come on.
[01:07:48.580 --> 01:07:51.620]   It's up to you, users.
[01:07:51.620 --> 01:07:52.780]   Hony up.
[01:07:52.780 --> 01:07:54.620]   I think Reddit's got to give on this.
[01:07:54.620 --> 01:07:57.100]   I pray that Reddit gives.
[01:07:57.100 --> 01:08:02.340]   I would say users stop being so cranky, but it's too late.
[01:08:02.340 --> 01:08:03.340]   Somebody in the Discord...
[01:08:03.340 --> 01:08:04.340]   Crankers happened.
[01:08:04.340 --> 01:08:05.340]   Crankers happened.
[01:08:05.340 --> 01:08:08.660]   Somebody in the Discord says, "Once you cut off your nose and spite your face, it's kind
[01:08:08.660 --> 01:08:13.620]   of hard to put it back."
[01:08:13.620 --> 01:08:20.020]   But I don't think that either Steve or Christian can pray that the Redditors will solve this.
[01:08:20.020 --> 01:08:22.140]   It's up to you, Steve.
[01:08:22.140 --> 01:08:27.900]   Please fix this.
[01:08:27.900 --> 01:08:29.020]   You can still make money.
[01:08:29.020 --> 01:08:31.420]   I understand why you need to make money.
[01:08:31.420 --> 01:08:32.900]   Absolutely.
[01:08:32.900 --> 01:08:36.940]   But you can't make that much money.
[01:08:36.940 --> 01:08:39.780]   By the way, you're going to kill the goose that late.
[01:08:39.780 --> 01:08:40.780]   Make a little less.
[01:08:40.780 --> 01:08:41.780]   You're not going to make it...
[01:08:41.780 --> 01:08:43.100]   You nailed it Nicole.
[01:08:43.100 --> 01:08:46.420]   By charging so much more, they're going to actually kill the product.
[01:08:46.420 --> 01:08:47.420]   They're going to lose everything.
[01:08:47.420 --> 01:08:50.900]   And also, I don't know, figure out another way to make money.
[01:08:50.900 --> 01:08:51.900]   How about that?
[01:08:51.900 --> 01:08:52.900]   How about you, your brains?
[01:08:52.900 --> 01:08:53.900]   Well, they have advertising.
[01:08:53.900 --> 01:08:57.500]   How about just like, "Well, Elon Musk did it."
[01:08:57.500 --> 01:08:58.500]   That's not a great...
[01:08:58.500 --> 01:08:59.500]   That's...
[01:08:59.500 --> 01:09:00.500]   No.
[01:09:00.500 --> 01:09:05.220]   By the way, I have to say, this is one side effect of Elon's...
[01:09:05.220 --> 01:09:08.060]   What do you call what happened to Twitter?
[01:09:08.060 --> 01:09:09.060]   No one knows.
[01:09:09.060 --> 01:09:10.060]   No one knows.
[01:09:10.060 --> 01:09:11.060]   No one knows.
[01:09:11.060 --> 01:09:12.060]   One side effect.
[01:09:12.060 --> 01:09:13.060]   I think decimation is a good description.
[01:09:13.060 --> 01:09:14.060]   Yeah.
[01:09:14.060 --> 01:09:19.020]   Executives are looking what Elon's doing and some of them are emulating him.
[01:09:19.020 --> 01:09:21.380]   Say, "Oh, we can make people come back to work.
[01:09:21.380 --> 01:09:22.620]   Elon did it.
[01:09:22.620 --> 01:09:23.940]   We don't have to pay rent.
[01:09:23.940 --> 01:09:26.180]   Look, Elon doesn't."
[01:09:26.180 --> 01:09:27.180]   I think this is...
[01:09:27.180 --> 01:09:28.380]   You can call this a pair of Google Cloud builds.
[01:09:28.380 --> 01:09:29.380]   Yeah.
[01:09:29.380 --> 01:09:33.340]   There's a lot of bad behavior among CEOs.
[01:09:33.340 --> 01:09:37.900]   We all think their Steve Jobs, but none of them are Steve Jobs.
[01:09:37.900 --> 01:09:40.620]   I think kind of a jerk can get people to do things.
[01:09:40.620 --> 01:09:42.060]   I'm like, "Yeah, but you're not smart."
[01:09:42.060 --> 01:09:43.060]   Let me take a little break.
[01:09:43.060 --> 01:09:44.420]   I'm going to find out the hard way.
[01:09:44.420 --> 01:09:45.660]   Let's talk about Tesla.
[01:09:45.660 --> 01:09:46.660]   Since you guys...
[01:09:46.660 --> 01:09:47.660]   I mean, you cover it.
[01:09:47.660 --> 01:09:49.260]   Let's talk about Tesla.
[01:09:49.260 --> 01:09:52.100]   There's actually some Tesla news, quite a bit of it.
[01:09:52.100 --> 01:09:57.340]   When we come back with our wheel bearings takeover on this week in tech, we're finally
[01:09:57.340 --> 01:09:59.060]   going to talk about cars.
[01:09:59.060 --> 01:10:00.060]   How about that?
[01:10:00.060 --> 01:10:01.060]   Woo-hoo.
[01:10:01.060 --> 01:10:02.060]   Woo-hoo.
[01:10:02.060 --> 01:10:03.540]   But first a word from ZipRecruiter.
[01:10:03.540 --> 01:10:05.300]   Let's talk about Jobs.
[01:10:05.300 --> 01:10:12.380]   If you're a business owner, at least I have this small business called Twit, you know
[01:10:12.380 --> 01:10:16.060]   it is hard when somebody leaves or you have jobs you need to fill.
[01:10:16.060 --> 01:10:21.660]   On average, it could take 11 weeks to hire for an open position.
[01:10:21.660 --> 01:10:26.580]   That's 11 weeks where you're working double time, filling the hole that's left behind
[01:10:26.580 --> 01:10:32.340]   by the empty position, but also doing all the work it takes to hire somebody to fill it.
[01:10:32.340 --> 01:10:35.220]   That's two and a half months down the tubes.
[01:10:35.220 --> 01:10:37.060]   Do you have that time?
[01:10:37.060 --> 01:10:38.780]   If you're listening, I've got some advice to you.
[01:10:38.780 --> 01:10:40.660]   Do what we do.
[01:10:40.660 --> 01:10:42.780]   Stop waiting and start using ZipRecruiter.
[01:10:42.780 --> 01:10:46.500]   I have to tell you, it's always hard when an employee says, "You know, I got another job
[01:10:46.500 --> 01:10:50.460]   or I'm going to go back to school or whatever."
[01:10:50.460 --> 01:10:51.460]   We hate that.
[01:10:51.460 --> 01:10:53.620]   We love our employees, but they've got a life to live.
[01:10:53.620 --> 01:10:56.100]   Now we've got a job to fill.
[01:10:56.100 --> 01:10:59.780]   What Lisa does is go to ZipRecruiter.
[01:10:59.780 --> 01:11:04.220]   ZipRecruiter can help you find qualified candidates for whatever role you have fast.
[01:11:04.220 --> 01:11:06.820]   It's not just for podcasters, believe me.
[01:11:06.820 --> 01:11:10.740]   Right now you can try it for free if you want ziprecruiter.com/twit.
[01:11:10.740 --> 01:11:13.220]   Usually, it's breakfast.
[01:11:13.220 --> 01:11:16.700]   Lisa says, "All right, I'm going to fill this job."
[01:11:16.700 --> 01:11:20.980]   Most recently, Ashley and our continuity department decided to get a job closer to home, so she
[01:11:20.980 --> 01:11:21.980]   didn't have such a long commute.
[01:11:21.980 --> 01:11:22.980]   Good for her.
[01:11:22.980 --> 01:11:26.100]   But that meant we've got an empty seat in our continuity department.
[01:11:26.100 --> 01:11:28.380]   We've really got to fill it.
[01:11:28.380 --> 01:11:32.620]   Lisa posted on ZipRecruiter that morning for breakfast.
[01:11:32.620 --> 01:11:36.500]   Before lunch, in fact, within an hour or two, I'm worried because I'm going, "Oh, this
[01:11:36.500 --> 01:11:38.260]   means more work for all."
[01:11:38.260 --> 01:11:40.460]   Lisa says, "Oh, look, here's a great kid.
[01:11:40.460 --> 01:11:41.980]   Oh, here's another great kid.
[01:11:41.980 --> 01:11:45.860]   We had three or four great candidates before lunch.
[01:11:45.860 --> 01:11:47.420]   How does ZipRecruiter do it?"
[01:11:47.420 --> 01:11:50.340]   Well, they use powerful matching technology.
[01:11:50.340 --> 01:11:52.580]   They have more than a million current resumes.
[01:11:52.580 --> 01:11:54.740]   People come to ZipRecruiter looking for work.
[01:11:54.740 --> 01:11:59.420]   They will go through those resumes and find the most qualified people for that role.
[01:11:59.420 --> 01:12:00.420]   They know what you're looking for.
[01:12:00.420 --> 01:12:03.300]   They say, "Oh, look, here's three people that fit this role perfectly."
[01:12:03.300 --> 01:12:04.940]   Now, they don't invite them to apply.
[01:12:04.940 --> 01:12:07.500]   They send them to you and you can look at them.
[01:12:07.500 --> 01:12:08.500]   Check them out.
[01:12:08.500 --> 01:12:10.900]   And if you like one or two, you can invite them to apply.
[01:12:10.900 --> 01:12:13.300]   With one click, just button this is click.
[01:12:13.300 --> 01:12:15.460]   Yeah, ask this person to apply.
[01:12:15.460 --> 01:12:19.580]   And I got to tell you, when you ask somebody to apply for a job, they respond quickly.
[01:12:19.580 --> 01:12:20.780]   It's so flattered.
[01:12:20.780 --> 01:12:21.980]   They go to the interview.
[01:12:21.980 --> 01:12:23.740]   They go through the process.
[01:12:23.740 --> 01:12:27.820]   That's a great way to start a relationship with a new employee.
[01:12:27.820 --> 01:12:28.820]   It works so well.
[01:12:28.820 --> 01:12:34.100]   Four out of five employers who post on ZipRecruiter get a qualified candidate within the first
[01:12:34.100 --> 01:12:35.100]   day.
[01:12:35.100 --> 01:12:36.100]   That's been our experience.
[01:12:36.100 --> 01:12:38.100]   That's why we use ZipRecruiter.
[01:12:38.100 --> 01:12:39.100]   That's how we got Viva.
[01:12:39.100 --> 01:12:41.580]   It was great because we had three or four people to choose from.
[01:12:41.580 --> 01:12:42.580]   We interviewed them.
[01:12:42.580 --> 01:12:45.260]   The nice thing about ZipRecruiter, you might say, "Well, I don't know.
[01:12:45.260 --> 01:12:47.860]   I don't want hundreds of people applying for my job.
[01:12:47.860 --> 01:12:49.060]   I just need that one.
[01:12:49.060 --> 01:12:50.060]   Don't worry.
[01:12:50.060 --> 01:12:51.540]   They all go into the ZipRecruiter interface.
[01:12:51.540 --> 01:12:54.020]   They reformat the resume so you can scan them quickly.
[01:12:54.020 --> 01:12:55.980]   They give you screen questions.
[01:12:55.980 --> 01:12:58.940]   Yes, no true/false multiple choice.
[01:12:58.940 --> 01:13:03.180]   Even essay questions that make it very easy to screen out people who just don't have the
[01:13:03.180 --> 01:13:05.980]   qualifications.
[01:13:05.980 --> 01:13:11.820]   They allow you to put little tags on there like remote work okay or offering training.
[01:13:11.820 --> 01:13:18.220]   That helps bring your listing to the top for a lot of people.
[01:13:18.220 --> 01:13:21.340]   And then you can quickly go through them.
[01:13:21.340 --> 01:13:22.340]   You don't get emails.
[01:13:22.340 --> 01:13:23.340]   You don't get phone calls.
[01:13:23.340 --> 01:13:26.460]   It all goes in the ZipRecruiter interface and hire the right one fast.
[01:13:26.460 --> 01:13:30.220]   It really is a system that works so well.
[01:13:30.220 --> 01:13:31.660]   We've been very happy with it.
[01:13:31.660 --> 01:13:34.660]   Speed up your hiring process with ZipRecruiter.
[01:13:34.660 --> 01:13:40.300]   3.8 million businesses have come to ZipRecruiter for their hiring needs just like us.
[01:13:40.300 --> 01:13:44.700]   Try it for free when you go to ziprecruiter.com/twit.
[01:13:44.700 --> 01:13:50.980]   Try it the next time you need to do some hiring you will be blown away.
[01:13:50.980 --> 01:13:52.660]   It is the smartest way to hire.
[01:13:52.660 --> 01:13:54.460]   I will vouch for that.
[01:13:54.460 --> 01:13:55.460]   ZipRecruiter.com/twit.
[01:13:55.460 --> 01:14:03.140]   I thank them so much for their support of this week in tech.
[01:14:03.140 --> 01:14:07.260]   I mentioned to Sam earlier.
[01:14:07.260 --> 01:14:09.820]   I think I actually told all of you.
[01:14:09.820 --> 01:14:14.100]   I have the Maki with Blue Cruise.
[01:14:14.100 --> 01:14:16.860]   So it is hands off.
[01:14:16.860 --> 01:14:21.820]   Only in certain areas it goes blue and I don't have to have my hands on the wheel.
[01:14:21.820 --> 01:14:23.300]   I really like that.
[01:14:23.300 --> 01:14:29.460]   I mentioned earlier that I put down in a deposit to pre-order the new BMW i5 which comes out
[01:14:29.460 --> 01:14:30.620]   later this year.
[01:14:30.620 --> 01:14:33.820]   They say on that, "You got that on."
[01:14:33.820 --> 01:14:37.380]   And if you just look at the side mirrors it will change lanes for you.
[01:14:37.380 --> 01:14:40.020]   I thought, "Well, I'm not going to turn that on."
[01:14:40.020 --> 01:14:42.180]   That's a terrible idea.
[01:14:42.180 --> 01:14:44.180]   I remember it.
[01:14:44.180 --> 01:14:46.180]   What could possibly go wrong?
[01:14:46.180 --> 01:14:52.460]   I think what they say is it will only change lanes if there is nobody behind you and you
[01:14:52.460 --> 01:14:55.460]   are being slowed down by traffic in front.
[01:14:55.460 --> 01:15:05.660]   Yeah, currently if you have to tap the turn signal stock left or right and then the sensors
[01:15:05.660 --> 01:15:10.260]   will check and if the adjacent lane in the direction you pointed is clear then it will
[01:15:10.260 --> 01:15:11.900]   execute the lane change.
[01:15:11.900 --> 01:15:14.820]   Now it is doing that when you look at the mirror.
[01:15:14.820 --> 01:15:17.220]   I'm not sure all the details of exactly that.
[01:15:17.220 --> 01:15:18.740]   I'll tell you when I get it.
[01:15:18.740 --> 01:15:19.740]   I'll let you know.
[01:15:19.740 --> 01:15:23.380]   There is going to be a time where you can't just be like glancing.
[01:15:23.380 --> 01:15:24.380]   You're like, "Whoa!"
[01:15:24.380 --> 01:15:27.380]   "Oh, it's a new change lane."
[01:15:27.380 --> 01:15:30.180]   You're checking behind you the cars going back and forth left lane.
[01:15:30.180 --> 01:15:31.180]   Don't be scanning your mirrors.
[01:15:31.180 --> 01:15:36.100]   Because I drive, I scan my mirrors all the time as I'm driving.
[01:15:36.100 --> 01:15:37.740]   It seems like a bad idea anyway.
[01:15:37.740 --> 01:15:38.740]   We'll see.
[01:15:38.740 --> 01:15:45.780]   I did have the change lanes when you do the blinker on the Model X when I had a Tesla.
[01:15:45.780 --> 01:15:48.740]   It was a much more aggressive than I was.
[01:15:48.740 --> 01:15:51.020]   It's supposed to wait until you have clear.
[01:15:51.020 --> 01:15:55.060]   It would change lanes in front of a car that was a lot closer than I would have changed
[01:15:55.060 --> 01:15:56.060]   lanes.
[01:15:56.060 --> 01:15:57.060]   Maybe it was safer.
[01:15:57.060 --> 01:15:58.060]   Maybe you're just nervous.
[01:15:58.060 --> 01:15:59.060]   Maybe you're just a little bit of a driver.
[01:15:59.060 --> 01:16:01.060]   I'm just a scared driver.
[01:16:01.060 --> 01:16:03.180]   The Mach-E has that now.
[01:16:03.180 --> 01:16:07.940]   If you have the version 1.2 of Blue Cruise, you can do that when you tap the turn signal
[01:16:07.940 --> 01:16:08.940]   stock.
[01:16:08.940 --> 01:16:10.300]   It's pretty conservative.
[01:16:10.300 --> 01:16:16.020]   I was just driving a Mach-E over the past week to test the new version of Blue Cruise.
[01:16:16.020 --> 01:16:21.220]   The same thing goes for the new Nissan Aria and Super Cruise.
[01:16:21.220 --> 01:16:23.860]   They're all fairly conservative.
[01:16:23.860 --> 01:16:27.740]   They're not going to try and squeeze into a little gap in the traffic.
[01:16:27.740 --> 01:16:30.460]   They'll wait until it's really genuinely clear.
[01:16:30.460 --> 01:16:38.020]   I bring this up because the Washington Post did a little data digging and came up with
[01:16:38.020 --> 01:16:39.700]   a scary headline.
[01:16:39.700 --> 01:16:47.820]   17 fatalities, 736 crashes, the shocking toll of Tesla's autopilot.
[01:16:47.820 --> 01:16:55.660]   They say autopilot has been involved in far more crashes than previously reported.
[01:16:55.660 --> 01:17:05.420]   They did that by digging into the NHTSA's data.
[01:17:05.420 --> 01:17:10.780]   What do you think of this story?
[01:17:10.780 --> 01:17:13.100]   Is it reliable and then is that a large number?
[01:17:13.100 --> 01:17:15.060]   I guess I should ask.
[01:17:15.060 --> 01:17:24.020]   Yeah, it is reliable because what they're doing last year or the year before, the National
[01:17:24.020 --> 01:17:29.900]   Highway Traffic Safety Administration issued a standing general order for all automakers
[01:17:29.900 --> 01:17:33.380]   and all companies developing automated driving systems.
[01:17:33.380 --> 01:17:38.420]   Any crash that occurs while the system is either active or if it's been active within
[01:17:38.420 --> 01:17:42.540]   30 seconds prior to the crash at any point in that phase.
[01:17:42.540 --> 01:17:47.900]   One of the things that we've seen now that this data is available is that a lot of the
[01:17:47.900 --> 01:17:54.940]   Tesla crashes happen shortly after autopilot decides to deactivate for whatever reason.
[01:17:54.940 --> 01:17:58.660]   The driver has not realized it and gets rid of the crash.
[01:17:58.660 --> 01:18:01.940]   They thought it was active and it wasn't.
[01:18:01.940 --> 01:18:02.940]   That's interesting.
[01:18:02.940 --> 01:18:05.020]   Or you could deactivate it.
[01:18:05.020 --> 01:18:09.700]   All of these systems, if it's starting to steer into a wall, you can take the wheel.
[01:18:09.700 --> 01:18:12.460]   Maybe it's too late in this process.
[01:18:12.460 --> 01:18:13.460]   It hit the brakes.
[01:18:13.460 --> 01:18:14.900]   Yeah, there's a lot of things that can happen.
[01:18:14.900 --> 01:18:17.060]   That's contributory to a crash as well.
[01:18:17.060 --> 01:18:20.540]   But you're saying that when grabs the wheel of your car and points you towards a
[01:18:20.540 --> 01:18:21.540]   Yeah, that's contributory.
[01:18:21.540 --> 01:18:24.140]   And you go to turn it the last minute.
[01:18:24.140 --> 01:18:25.140]   Yeah, it's their fault.
[01:18:25.140 --> 01:18:28.140]   It's not your fault you hit the wall.
[01:18:28.140 --> 01:18:29.140]   Right.
[01:18:29.140 --> 01:18:30.860]   But you're saying that's interesting.
[01:18:30.860 --> 01:18:37.620]   You're saying that Tesla's consciously disabling automatically or what?
[01:18:37.620 --> 01:18:40.780]   Yeah, I mean, all of these systems have.
[01:18:40.780 --> 01:18:43.260]   They will disable where when and where they can function.
[01:18:43.260 --> 01:18:44.260]   Right.
[01:18:44.260 --> 01:18:48.740]   So there are situations where the systems just can't function.
[01:18:48.740 --> 01:18:52.260]   Like I'm sure if you've used blue crews, you've noticed that there are times when the
[01:18:52.260 --> 01:18:54.500]   system will ask you to put your hands back on the wheel.
[01:18:54.500 --> 01:18:55.500]   Which is fine.
[01:18:55.500 --> 01:18:59.100]   If you're going down the highway and it hits a curve that it can't, doesn't think it can
[01:18:59.100 --> 01:19:01.820]   handle, it'll ask you to put your hands back on the wheel.
[01:19:01.820 --> 01:19:07.820]   Here in California, lines sometimes weirdly just disappear and there's no lines.
[01:19:07.820 --> 01:19:08.820]   Right.
[01:19:08.820 --> 01:19:11.420]   So then the car says, you know, I think you better take over because I don't know where
[01:19:11.420 --> 01:19:12.700]   I am.
[01:19:12.700 --> 01:19:13.700]   That's fine.
[01:19:13.700 --> 01:19:18.580]   But the key thing is that the vehicle has to make it really clear to the driver.
[01:19:18.580 --> 01:19:21.980]   I need you to put your hands back on the wheel and take control now.
[01:19:21.980 --> 01:19:22.980]   Yeah.
[01:19:22.980 --> 01:19:24.700]   The fourteenth piece that he's loudly at me.
[01:19:24.700 --> 01:19:25.700]   Yeah.
[01:19:25.700 --> 01:19:32.700]   And this is one of the issues that, you know, with Tesla, it's not always obvious, you know,
[01:19:32.700 --> 01:19:37.580]   with their HMI, their human machine interface, when the driver is actually supposed to take
[01:19:37.580 --> 01:19:40.300]   control or that it's changing modes.
[01:19:40.300 --> 01:19:45.780]   And so a lot of drivers get confused because, you know, they think they're in one mode
[01:19:45.780 --> 01:19:49.820]   when the vehicle has actually transitioned and they haven't taken back control yet.
[01:19:49.820 --> 01:19:50.820]   Yeah.
[01:19:50.820 --> 01:19:51.820]   That's the thing.
[01:19:51.820 --> 01:19:52.820]   I mean, some of this might be human error.
[01:19:52.820 --> 01:19:59.540]   Like, okay, you were driving along and then the Tesla said, well, I can't keep driving.
[01:19:59.540 --> 01:20:00.540]   So it's your turn.
[01:20:00.540 --> 01:20:01.540]   Take over.
[01:20:01.540 --> 01:20:07.020]   And you ignore that or you don't notice and it plows into something.
[01:20:07.020 --> 01:20:09.300]   That's kind of more your fault, isn't it?
[01:20:09.300 --> 01:20:11.900]   Well, it's it is in my issue.
[01:20:11.900 --> 01:20:12.900]   Yeah.
[01:20:12.900 --> 01:20:16.020]   Like, if you don't know, like if they're not like one of the things that's great about
[01:20:16.020 --> 01:20:21.060]   Super Cruise, Mercedes and BMWs that on the steering wheel, there are lights that tell
[01:20:21.060 --> 01:20:22.460]   you what mode you're in.
[01:20:22.460 --> 01:20:25.460]   Ah, it reduces mode confusion.
[01:20:25.460 --> 01:20:32.740]   If you don't have any sort of like very just blatant warning that tells you, hey, you're
[01:20:32.740 --> 01:20:37.660]   not in this mode anymore, you are in charge, then it's it's, who's fault is it?
[01:20:37.660 --> 01:20:40.780]   Is it Tesla's fault because they just built a bad system?
[01:20:40.780 --> 01:20:44.260]   Or is it your fault because you didn't notice until it's too late.
[01:20:44.260 --> 01:20:49.620]   How does the Tesla tell you that it's like the guy who grabs the wheel of your car and
[01:20:49.620 --> 01:20:51.380]   steals you towards the wall.
[01:20:51.380 --> 01:20:54.140]   And then you, and then suddenly it turns off and you have to grab the last minute in turn.
[01:20:54.140 --> 01:20:58.220]   Is it your fault that you ran the wall because you didn't realize in that case, no, pretty
[01:20:58.220 --> 01:20:59.220]   clearly.
[01:20:59.220 --> 01:21:00.740]   How does the Tesla, I don't even remember.
[01:21:00.740 --> 01:21:01.740]   How does it warn you?
[01:21:01.740 --> 01:21:05.140]   I think it buzzes at you and bleeps.
[01:21:05.140 --> 01:21:10.700]   I remember at one point, my Tesla said, I'm not going to, I'm not going to drive anymore.
[01:21:10.700 --> 01:21:13.980]   You're not paying attention and turned off.
[01:21:13.980 --> 01:21:19.020]   And I couldn't continue to use autopilot until I started a new ride.
[01:21:19.020 --> 01:21:20.020]   Yeah.
[01:21:20.020 --> 01:21:25.460]   And, you know, especially on the model three and the model Y, which are, you know, that's
[01:21:25.460 --> 01:21:28.420]   the vast majority of their volume.
[01:21:28.420 --> 01:21:31.100]   Those vehicles don't have an instrument cluster in front of you.
[01:21:31.100 --> 01:21:33.660]   They only have that center screen.
[01:21:33.660 --> 01:21:37.900]   And, you know, the kind of the left hand strip of that screen is where they have control
[01:21:37.900 --> 01:21:38.900]   information.
[01:21:38.900 --> 01:21:43.540]   The rest of it is maps and audio interface and things like that.
[01:21:43.540 --> 01:21:48.740]   And you know, when I went for a drive and a friends model three with their full self
[01:21:48.740 --> 01:21:54.100]   driving beta to try that out, you know, it had, you know, all it showed, you know, there
[01:21:54.100 --> 01:21:59.860]   was a little icon of a steering wheel with hands, I think, in the top left hand corner.
[01:21:59.860 --> 01:22:05.420]   So it was kind of often my peripheral vision, but it wasn't particularly obvious when it
[01:22:05.420 --> 01:22:07.260]   wanted you to take control.
[01:22:07.260 --> 01:22:09.620]   And I pretty sure it didn't make any sounds.
[01:22:09.620 --> 01:22:14.820]   It might have made us a slight sound, but it was not at all obvious.
[01:22:14.820 --> 01:22:17.020]   And this has been one of my complaints.
[01:22:17.020 --> 01:22:22.340]   You know, if you're going to have a system where, you know, any sort of automated system
[01:22:22.340 --> 01:22:28.180]   where you expect somebody, a human to supervise, first of all, that's a, I think, a fundamentally
[01:22:28.180 --> 01:22:31.940]   problematic idea because humans are terrible at supervising.
[01:22:31.940 --> 01:22:34.580]   Especially when you call it auto pilot, that implies.
[01:22:34.580 --> 01:22:35.580]   Right.
[01:22:35.580 --> 01:22:39.060]   And if it works, if it works most of the time, you are going to get complacent.
[01:22:39.060 --> 01:22:46.380]   That is a known reality of the way humans behave, which is why, as Robbie mentioned,
[01:22:46.380 --> 01:22:53.380]   Tesla or GM and BMW and Mercedes and others use, you know, very obvious interface devices
[01:22:53.380 --> 01:22:58.780]   like a light bar in the steering wheel, you know, or Nissan with their cluster and heads
[01:22:58.780 --> 01:23:04.220]   up display that completely changes the color scheme, is changing modes.
[01:23:04.220 --> 01:23:10.180]   Though, you know, as an engineer, it's your responsibility to anticipate the way things
[01:23:10.180 --> 01:23:16.900]   could go wrong and do everything reasonable, you know, to mitigate that, you know, to mitigate
[01:23:16.900 --> 01:23:23.340]   the consequences of that, to try to avoid anything bad happening when things inevitably
[01:23:23.340 --> 01:23:24.340]   do go wrong.
[01:23:24.340 --> 01:23:27.180]   I remember this is where I think Tesla has done it wrong.
[01:23:27.180 --> 01:23:30.820]   I remember a couple of years ago when you took me for a ride in that Cadillac, what is
[01:23:30.820 --> 01:23:31.820]   it?
[01:23:31.820 --> 01:23:32.820]   The CTS?
[01:23:32.820 --> 01:23:33.820]   CTS?
[01:23:33.820 --> 01:23:34.820]   CTS.
[01:23:34.820 --> 01:23:35.820]   Which had a camera.
[01:23:35.820 --> 01:23:38.100]   This was the first experience I had this.
[01:23:38.100 --> 01:23:42.940]   My Ford now has is monitoring my eyes and you made me.
[01:23:42.940 --> 01:23:44.740]   It wasn't easy.
[01:23:44.740 --> 01:23:45.740]   You said, "Don't look at the road."
[01:23:45.740 --> 01:23:47.140]   I said, "I have to look at the road.
[01:23:47.140 --> 01:23:48.140]   It's driving."
[01:23:48.140 --> 01:23:49.140]   No, no, no, look at the road.
[01:23:49.140 --> 01:23:50.820]   So I went like this.
[01:23:50.820 --> 01:23:54.260]   I put my hands from eyes, but I peaked.
[01:23:54.260 --> 01:23:57.300]   And it shook the seat.
[01:23:57.300 --> 01:23:58.660]   It buzzed.
[01:23:58.660 --> 01:24:00.860]   It was like, "Wake up, wake up, wake up."
[01:24:00.860 --> 01:24:02.860]   It was very aggressive.
[01:24:02.860 --> 01:24:06.700]   And it, you know, it started ramped up and it got more and more aggressive as I continued
[01:24:06.700 --> 01:24:09.860]   to peek through my eyes.
[01:24:09.860 --> 01:24:10.860]   That was good.
[01:24:10.860 --> 01:24:13.340]   That was a system that really did make me pay attention.
[01:24:13.340 --> 01:24:14.340]   No question about it.
[01:24:14.340 --> 01:24:18.260]   I think part of the challenge too though, there are so many, excuse me, there's so many
[01:24:18.260 --> 01:24:24.380]   things that your car now warns you about that you don't always know what is beeping,
[01:24:24.380 --> 01:24:25.380]   dinging.
[01:24:25.380 --> 01:24:26.380]   Yes.
[01:24:26.380 --> 01:24:27.380]   Like, you hear it.
[01:24:27.380 --> 01:24:28.700]   You're like, "What does that tone mean?
[01:24:28.700 --> 01:24:29.700]   What is it in my day?"
[01:24:29.700 --> 01:24:31.780]   There's a mystery beeping my Hyundai.
[01:24:31.780 --> 01:24:33.540]   I have no idea what it does.
[01:24:33.540 --> 01:24:36.060]   I'm like, "I don't know what that is.
[01:24:36.060 --> 01:24:37.060]   Is that a warning?"
[01:24:37.060 --> 01:24:38.060]   You don't understand.
[01:24:38.060 --> 01:24:39.060]   I'm like, "You don't understand."
[01:24:39.060 --> 01:24:42.540]   It's like, "I don't know what that beep is for."
[01:24:42.540 --> 01:24:44.380]   Literally, my job is to know.
[01:24:44.380 --> 01:24:45.380]   I don't know.
[01:24:45.380 --> 01:24:48.220]   My Ford does that when the tailgate goes.
[01:24:48.220 --> 01:24:51.260]   Half the time it beeps twice for some reason.
[01:24:51.260 --> 01:24:52.260]   I don't know why.
[01:24:52.260 --> 01:24:53.260]   You don't know why.
[01:24:53.260 --> 01:24:54.260]   Like, that's the thing.
[01:24:54.260 --> 01:24:57.740]   There's so many beeps and bells and whistles and whatever.
[01:24:57.740 --> 01:24:58.740]   You're like, "I don't..."
[01:24:58.740 --> 01:25:01.100]   And you look at your car and you're thinking, "I think I'm doing everything right.
[01:25:01.100 --> 01:25:02.100]   I'm in my lane.
[01:25:02.100 --> 01:25:03.100]   I'm doing the speed limit.
[01:25:03.100 --> 01:25:04.900]   No one's about to hit me that I witnessed.
[01:25:04.900 --> 01:25:05.900]   Why are you beeping at me?"
[01:25:05.900 --> 01:25:06.900]   What's happening?
[01:25:06.900 --> 01:25:07.900]   There's a confusion.
[01:25:07.900 --> 01:25:08.900]   Yeah.
[01:25:08.900 --> 01:25:09.900]   Is there a murderer in the backseat?
[01:25:09.900 --> 01:25:10.900]   Like, what are you telling me?
[01:25:10.900 --> 01:25:11.900]   What am I missing?
[01:25:11.900 --> 01:25:14.900]   It's like trying to talk to Lassie, but Lassie's really bad at communicating.
[01:25:14.900 --> 01:25:17.420]   And like, they beep when you just turn... like, I hate it.
[01:25:17.420 --> 01:25:19.140]   You turn on a car and you're in a parking space.
[01:25:19.140 --> 01:25:20.700]   You haven't done anything and it's beeping at you.
[01:25:20.700 --> 01:25:21.700]   Then you put it in reverse.
[01:25:21.700 --> 01:25:23.820]   You're like, "I'm not even going forward.
[01:25:23.820 --> 01:25:27.100]   Why are you beeping at me that there's something too close to my front bumper?
[01:25:27.100 --> 01:25:30.020]   I'm literally in reverse going the other direction.
[01:25:30.020 --> 01:25:31.020]   The beeping is too much."
[01:25:31.020 --> 01:25:35.340]   So it shouldn't be a surprise that we ignore our cars.
[01:25:35.340 --> 01:25:40.860]   Elon, of course, the Washington Post says, "Tesla CEO Elon Musk has said cars operating
[01:25:40.860 --> 01:25:48.420]   in autopilot mode are safer than those piloted solely by human drivers, citing crash rates
[01:25:48.420 --> 01:25:51.260]   when the modes of driving are compared."
[01:25:51.260 --> 01:25:57.740]   So earlier today when we recorded the new episode of Wheel Bering, we talked about a
[01:25:57.740 --> 01:26:01.500]   story that came out the other day.
[01:26:01.500 --> 01:26:05.500]   Money.com, Money.com, Money Magazine did a review of Tesla auto insurance.
[01:26:05.500 --> 01:26:08.700]   I don't know if you know, but a couple of years ago, Tesla actually started selling their
[01:26:08.700 --> 01:26:10.700]   own auto insurance.
[01:26:10.700 --> 01:26:14.540]   They're now in 12 states because a lot of insurance companies were charging Tesla owners
[01:26:14.540 --> 01:26:18.540]   more for insurance than for other vehicles.
[01:26:18.540 --> 01:26:24.740]   And that's because their cars are more expensive to repair, also that they had more claims.
[01:26:24.740 --> 01:26:29.900]   But one of the interesting details about the Tesla auto insurance, because the vehicles
[01:26:29.900 --> 01:26:36.300]   are connected, they have access to all the data about how you drive.
[01:26:36.300 --> 01:26:41.980]   Most auto insurance, every six months you get a bill to pay for your insurance.
[01:26:41.980 --> 01:26:46.060]   At six months, they may have adjusted up or down, usually only up, but sometimes it
[01:26:46.060 --> 01:26:47.060]   goes down.
[01:26:47.060 --> 01:26:48.060]   Never goes down.
[01:26:48.060 --> 01:26:49.060]   Never goes down.
[01:26:49.060 --> 01:26:54.700]   What Tesla does is they have dynamic pricing so that they are constantly monitoring your
[01:26:54.700 --> 01:26:59.300]   driving behavior and calculating a safety score based on how hard you accelerate and break
[01:26:59.300 --> 01:27:01.980]   and steer and so on.
[01:27:01.980 --> 01:27:07.620]   And if your safety score goes down, the next month, your insurance bill will go up and vice
[01:27:07.620 --> 01:27:08.620]   versa.
[01:27:08.620 --> 01:27:12.940]   If your score goes up, your insurance premium goes down.
[01:27:12.940 --> 01:27:20.780]   One of the factors that they include is actually your use of autopilot.
[01:27:20.780 --> 01:27:26.540]   If you use autopilot, you will pay more for Tesla insurance.
[01:27:26.540 --> 01:27:31.180]   So it could only be like, it's supposed to be safer yet if you have it, Tesla's own insurance
[01:27:31.180 --> 01:27:32.780]   charges, you more for it.
[01:27:32.780 --> 01:27:33.780]   Yeah.
[01:27:33.780 --> 01:27:36.260]   So clearly they don't believe their own rhetoric.
[01:27:36.260 --> 01:27:37.260]   That's hysterical.
[01:27:37.260 --> 01:27:39.460]   Or their insurance company doesn't.
[01:27:39.460 --> 01:27:45.580]   Well, I remember when I first got a Model X, I called our insurance company, it was
[01:27:45.580 --> 01:27:46.580]   Geico.
[01:27:46.580 --> 01:27:51.500]   And they said, oh, and they're a lot more.
[01:27:51.500 --> 01:27:54.940]   I don't know if because it was an expensive car because of the autopilot, but I have a
[01:27:54.940 --> 01:27:57.780]   feeling it was the autopilot.
[01:27:57.780 --> 01:28:02.100]   So this is what the Washington Post's analysis said.
[01:28:02.100 --> 01:28:07.500]   Tesla's 17 fatal crashes reveal distinct patterns, the post found.
[01:28:07.500 --> 01:28:10.140]   Four involved a motorcycle.
[01:28:10.140 --> 01:28:12.340]   That's a quarter of them.
[01:28:12.340 --> 01:28:14.180]   Another involved emergency vehicle.
[01:28:14.180 --> 01:28:15.180]   Ooh.
[01:28:15.180 --> 01:28:19.180]   Meanwhile, some of Musk's decisions such as widely expanding the availability of the
[01:28:19.180 --> 01:28:20.620]   features.
[01:28:20.620 --> 01:28:22.220]   And we've talked about this a little bit.
[01:28:22.220 --> 01:28:27.140]   Sam stripping the vehicles of radar sensors, he thinks that all you really need is cameras.
[01:28:27.140 --> 01:28:29.100]   You don't need radar or radar.
[01:28:29.100 --> 01:28:32.500]   A pair to have contributed to the reported uptick in incidents, according to experts
[01:28:32.500 --> 01:28:35.020]   who spoke with the post.
[01:28:35.020 --> 01:28:38.180]   Tesla and the Alonded Not report respond to a request for.
[01:28:38.180 --> 01:28:43.020]   Oh, by the way, Tesla is soon going to be adding a radar sensor back into the cars,
[01:28:43.020 --> 01:28:44.860]   but it's a different data rate.
[01:28:44.860 --> 01:28:47.460]   A tacit admission that maybe that was the one.
[01:28:47.460 --> 01:28:48.460]   Yes.
[01:28:48.460 --> 01:28:49.460]   Yeah.
[01:28:49.460 --> 01:28:50.460]   Whoops.
[01:28:50.460 --> 01:28:51.460]   Oopsie.
[01:28:51.460 --> 01:28:57.940]   NHTSA said a report of a crash involving driver assistance does not of itself imply that technology
[01:28:57.940 --> 01:28:58.940]   was the cause.
[01:28:58.940 --> 01:29:01.540]   That's what we were just talking about.
[01:29:01.540 --> 01:29:08.180]   NHTSA does have an active investigation into Tesla autopilot, including full self-driving.
[01:29:08.180 --> 01:29:12.660]   NHTSA reminds the public that all advanced driver assistance systems require the human
[01:29:12.660 --> 01:29:19.140]   driver to be in control and fully engaged in the driving task at all times.
[01:29:19.140 --> 01:29:28.300]   All state laws hold the human driver responsible for the operation of their vehicles.
[01:29:28.300 --> 01:29:32.340]   I don't care what you got going.
[01:29:32.340 --> 01:29:33.340]   So what do you think?
[01:29:33.340 --> 01:29:38.260]   I mean, a fatal crash is that's pretty serious.
[01:29:38.260 --> 01:29:41.300]   Four of them with motorcycles, one of them with an emergency vehicle.
[01:29:41.300 --> 01:29:49.060]   We've seen reports that sometimes Teslas don't notice fire trucks that are stopped.
[01:29:49.060 --> 01:29:50.060]   Frequently.
[01:29:50.060 --> 01:29:53.060]   Frequently.
[01:29:53.060 --> 01:29:54.060]   Crash is evolving.
[01:29:54.060 --> 01:29:57.500]   Tesla's driver assistance system have grown, but so is Tesla sales.
[01:29:57.500 --> 01:29:59.140]   I wouldn't be surprised.
[01:29:59.140 --> 01:30:06.060]   I can't decide if this is legitimate or kind of over the top hit piece almost.
[01:30:06.060 --> 01:30:08.460]   No, it is legitimate.
[01:30:08.460 --> 01:30:12.900]   The data from this Standing General Order, NHTSA publishes it.
[01:30:12.900 --> 01:30:15.860]   You can download an Excel spreadsheet.
[01:30:15.860 --> 01:30:19.300]   They update it every month with the new reports that have come in.
[01:30:19.300 --> 01:30:24.260]   And all automakers are obligated to submit their data.
[01:30:24.260 --> 01:30:30.140]   And you can go through and you can see how many crashes there have been where level two
[01:30:30.140 --> 01:30:33.140]   or above systems were active.
[01:30:33.140 --> 01:30:39.700]   And you compare the number of crashes with Tesla vehicles versus the population of Tesla
[01:30:39.700 --> 01:30:44.420]   vehicles and the number of crashes with vehicles from other manufacturers.
[01:30:44.420 --> 01:30:52.980]   And the numbers are disproportionately Tesla in terms of the number of crashes that those
[01:30:52.980 --> 01:30:54.140]   vehicles had.
[01:30:54.140 --> 01:31:02.780]   Now, it's also important when you look through the data in detail, which I have done as part
[01:31:02.780 --> 01:31:13.700]   of my job, what you'll also find is that because of the way the requirement was written,
[01:31:13.700 --> 01:31:20.100]   any crash where the driver system was active at the time of the crash or up to 30 seconds
[01:31:20.100 --> 01:31:23.820]   before, they have to submit it.
[01:31:23.820 --> 01:31:27.100]   Even if that system had nothing to do with the crash.
[01:31:27.100 --> 01:31:32.300]   So for example, in that data, there are two crashes involving Honda vehicles.
[01:31:32.300 --> 01:31:34.420]   I think the only two crashes.
[01:31:34.420 --> 01:31:43.460]   One of them involved the vehicle was the driver was using the system, which technically isn't
[01:31:43.460 --> 01:31:46.540]   even really a level two system and probably shouldn't have even been reported.
[01:31:46.540 --> 01:31:54.260]   But Honda was being overly aggressive, I would say, in reporting, not to leave anything out.
[01:31:54.260 --> 01:32:00.820]   And in that particular instance, the vehicle was going through intersection legally and
[01:32:00.820 --> 01:32:03.380]   was t-boned by somebody who ran a stop sign in the other direction.
[01:32:03.380 --> 01:32:06.660]   That's not the fault of the system.
[01:32:06.660 --> 01:32:11.260]   So if you look at the Tesla data, it's not those kinds of crashes.
[01:32:11.260 --> 01:32:18.060]   And the other one at 736 crashes under auto pilot.
[01:32:18.060 --> 01:32:22.260]   The number two worst car was Subaru with 23.
[01:32:22.260 --> 01:32:23.260]   Right.
[01:32:23.260 --> 01:32:25.260]   That's a significant difference.
[01:32:25.260 --> 01:32:29.260]   Now there's a lot more Teslas out there, but there's also not that many more.
[01:32:29.260 --> 01:32:31.460]   There's a lot of Subarus on the road.
[01:32:31.460 --> 01:32:32.460]   Okay.
[01:32:32.460 --> 01:32:38.060]   There's a lot of Tesla because they almost look at that data based on EV sold.
[01:32:38.060 --> 01:32:41.340]   Yeah, there's way more Tesla EVs in the world than anything else.
[01:32:41.340 --> 01:32:46.380]   But when you look at actual auto sales, there's a lot of, yeah, there's a lot of Subarus.
[01:32:46.380 --> 01:32:53.980]   The post says the enormous golf probably reflects wider deployment and use of automation across
[01:32:53.980 --> 01:32:59.420]   Tesla's fleet of vehicles, as well as a wider range of circumstances in which Tesla drivers
[01:32:59.420 --> 01:33:02.140]   are encouraged to use autopilot.
[01:33:02.140 --> 01:33:07.980]   For one, I can't use autopilot anywhere, but mapped highways in my Ford.
[01:33:07.980 --> 01:33:11.740]   You can use it on city streets in a Tesla.
[01:33:11.740 --> 01:33:13.420]   That seems problematic.
[01:33:13.420 --> 01:33:14.420]   Yeah.
[01:33:14.420 --> 01:33:17.500]   No, it absolutely is.
[01:33:17.500 --> 01:33:23.860]   And you know, as what you were saying, what Rob was saying, you know, the number of vehicles,
[01:33:23.860 --> 01:33:30.500]   excuse me, from Tesla and other manufacturers that have these kinds of systems is not necessarily
[01:33:30.500 --> 01:33:31.500]   that different.
[01:33:31.500 --> 01:33:36.140]   It's not like Tesla has dramatically more vehicles with autopilot on the road than some of the
[01:33:36.140 --> 01:33:40.860]   other systems that would qualify under this regulation.
[01:33:40.860 --> 01:33:46.380]   But I think that Tesla drivers are far more likely to be using those systems.
[01:33:46.380 --> 01:33:47.380]   Yes.
[01:33:47.380 --> 01:33:51.020]   And because they are not restricted in any way, they're more likely to be using them in
[01:33:51.020 --> 01:33:55.460]   systems and scenarios where they probably shouldn't.
[01:33:55.460 --> 01:33:59.300]   And then that's when you end up with more crashes.
[01:33:59.300 --> 01:34:04.100]   And they wonder about that because so many Tesla folks are sort of, you know, were early
[01:34:04.100 --> 01:34:07.940]   adopters of EVs and they're sort of people who are willing to give tech a chance at maybe
[01:34:07.940 --> 01:34:11.060]   other people and how many people have self-driving stuff.
[01:34:11.060 --> 01:34:12.860]   We're not really self-driving driver assistance.
[01:34:12.860 --> 01:34:15.340]   Everyone will call it on their vehicles that are non-Tesla's.
[01:34:15.340 --> 01:34:17.180]   They're just like, I'm just not using that.
[01:34:17.180 --> 01:34:21.620]   So it doesn't seem like there's as much happening because they just don't use it as often.
[01:34:21.620 --> 01:34:26.980]   Three months ago, Tesla claimed full self-driving crashes are five times lower than vehicles
[01:34:26.980 --> 01:34:32.740]   in normal driving based on the number of miles driven per collision.
[01:34:32.740 --> 01:34:37.420]   The problem is Tesla is very selective about what data they publish.
[01:34:37.420 --> 01:34:46.460]   And they don't really tell us what the context of that data is.
[01:34:46.460 --> 01:34:48.100]   You know, compared to what?
[01:34:48.100 --> 01:34:50.540]   Tesla even almost certainly comparing...
[01:34:50.540 --> 01:34:54.820]   Tesla even forces NHTSA to redact what kind of software is this.
[01:34:54.820 --> 01:34:56.780]   That's another one of my complaints.
[01:34:56.780 --> 01:35:02.540]   But, you know, as far as, you know, that five times fewer crashes, they are almost certainly
[01:35:02.540 --> 01:35:09.660]   comparing, you know, their vehicles, which are like 80% of their vehicles, 90% of their
[01:35:09.660 --> 01:35:11.740]   vehicles are less than five years old.
[01:35:11.740 --> 01:35:18.780]   They're comparing their vehicles to the entire population of 290 million registered vehicles
[01:35:18.780 --> 01:35:23.580]   in the United States, most of which are much older and don't have these kinds of systems
[01:35:23.580 --> 01:35:25.340]   on them.
[01:35:25.340 --> 01:35:29.540]   Because, you know, the average age of vehicles in the US is 12 and a half years.
[01:35:29.540 --> 01:35:31.940]   Those vehicles are 12 and a half years and over.
[01:35:31.940 --> 01:35:33.980]   They don't have these kinds of systems on them.
[01:35:33.980 --> 01:35:34.980]   So they're comparing...
[01:35:34.980 --> 01:35:40.500]   If you were to compare, you know, Tesla, a premium vehicle with, you know, a lot of
[01:35:40.500 --> 01:35:47.300]   stuff on it to only two other five years or younger premium vehicles, you know, so you
[01:35:47.300 --> 01:35:50.140]   had a real valid comparison base.
[01:35:50.140 --> 01:35:56.420]   I would guess that the numbers are probably very, very different and probably not better
[01:35:56.420 --> 01:36:03.500]   and very likely worse than the rest of that population of vehicles.
[01:36:03.500 --> 01:36:09.340]   And one expert said, and if you're a motorcycle, stay away from Tesla.
[01:36:09.340 --> 01:36:10.940]   It's gonna say they don't see...
[01:36:10.940 --> 01:36:15.580]   As someone who rides a motorcycle, I get very, very concerned riding around Tesla because
[01:36:15.580 --> 01:36:20.620]   I know people like because the selling point is EV autopilot.
[01:36:20.620 --> 01:36:22.620]   That's the things that sell to Tesla.
[01:36:22.620 --> 01:36:27.660]   And I just don't feel comfortable driving by someone who has a Tesla who is clearly
[01:36:27.660 --> 01:36:32.000]   not paying attention because the selling point for their vehicle was autopilot.
[01:36:32.000 --> 01:36:34.980]   And they were just like, "I'm just gonna go over here."
[01:36:34.980 --> 01:36:35.980]   So...
[01:36:35.980 --> 01:36:36.980]   No, no, no, no.
[01:36:36.980 --> 01:36:38.180]   Get around from this person.
[01:36:38.180 --> 01:36:52.820]   So what's the answer here?
[01:36:52.820 --> 01:36:57.420]   I think there's a point at which a car will be able to do it better than a human overall.
[01:36:57.420 --> 01:37:00.340]   I mean, there's still gonna be accidents even when it's the car.
[01:37:00.340 --> 01:37:04.620]   You know, nothing's ever gonna be perfect, but I just don't think we're quite there yet.
[01:37:04.620 --> 01:37:08.100]   So this is sort of showing me the growing pains of it.
[01:37:08.100 --> 01:37:09.100]   Pretty dangerous.
[01:37:09.100 --> 01:37:11.580]   Are you implying that our ride the other night was less than perfect?
[01:37:11.580 --> 01:37:13.700]   Our ride the other night was not quite entirely perfect.
[01:37:13.700 --> 01:37:14.700]   Wait a minute.
[01:37:14.700 --> 01:37:15.700]   So now tell me about that.
[01:37:15.700 --> 01:37:16.700]   You were on a cruise?
[01:37:16.700 --> 01:37:18.740]   What were you in?
[01:37:18.740 --> 01:37:21.980]   We went for a robo-taxi ride in Austin.
[01:37:21.980 --> 01:37:24.580]   What did you want to say?
[01:37:24.580 --> 01:37:25.580]   Who's?
[01:37:25.580 --> 01:37:26.580]   Yeah, it was Cruz.
[01:37:26.580 --> 01:37:27.580]   It was Cruz.
[01:37:27.580 --> 01:37:28.580]   Yes, it was Cruz.
[01:37:28.580 --> 01:37:34.380]   And it was a comedy of errors from the minute we hailed the silly thing.
[01:37:34.380 --> 01:37:38.300]   It was we were in a certain zone, like there's a certain area of Austin where you can hail
[01:37:38.300 --> 01:37:41.860]   these and Sam hails it and says it's gonna be right there right next to you.
[01:37:41.860 --> 01:37:44.500]   And then this is we have arrived and we're both looking like they haven't.
[01:37:44.500 --> 01:37:48.540]   We're everywhere and you can't miss these because they got all sorts of sensors all
[01:37:48.540 --> 01:37:53.100]   around them and they got things on the top, the lighter spinning and stuff everywhere.
[01:37:53.100 --> 01:37:54.300]   Like there's no mistaking.
[01:37:54.300 --> 01:37:56.820]   Like maybe that's my no, that's not that's a normal car.
[01:37:56.820 --> 01:37:59.820]   Here's mine with a million things sticking off the roof and we're both sitting there
[01:37:59.820 --> 01:38:04.340]   going it's it's not here and it was saying it was there but it was really two blocks away.
[01:38:04.340 --> 01:38:09.020]   So we walk the two blocks and we're trying to get to it by the time we get there.
[01:38:09.020 --> 01:38:10.020]   It's already left.
[01:38:10.020 --> 01:38:14.660]   It's like you took too long and then we held another one and it's like no, we got to walk
[01:38:14.660 --> 01:38:15.660]   another two blocks.
[01:38:15.660 --> 01:38:20.460]   I think we walked like six blocks to hail this stupid robo taxi.
[01:38:20.460 --> 01:38:24.740]   So and then just kept going from there and nothing like horrific but just these like
[01:38:24.740 --> 01:38:25.820]   this is not right.
[01:38:25.820 --> 01:38:27.580]   This is not making my life easier.
[01:38:27.580 --> 01:38:29.100]   This is making my life harder.
[01:38:29.100 --> 01:38:35.340]   You guys posted a video on their wheel bearings YouTube channel of your experiences.
[01:38:35.340 --> 01:38:38.340]   If anybody wants to see this in action.
[01:38:38.340 --> 01:38:42.340]   I got the entire the entire ride is in there from from the time we got in the vehicle.
[01:38:42.340 --> 01:38:43.340]   Yeah.
[01:38:43.340 --> 01:38:44.340]   Did it drive?
[01:38:44.340 --> 01:38:45.340]   Okay.
[01:38:45.340 --> 01:38:50.220]   Once you was there a safety driver or was it no, no, keep running for a second.
[01:38:50.220 --> 01:38:52.540]   You'll see there's there's nobody in the front seat.
[01:38:52.540 --> 01:38:53.540]   That's a little creepy.
[01:38:53.540 --> 01:38:55.180]   It was just the two of us in the back.
[01:38:55.180 --> 01:38:56.180]   It was creepy.
[01:38:56.180 --> 01:38:57.180]   Yeah.
[01:38:57.180 --> 01:38:59.100]   And it wasn't ever scary like dangerous.
[01:38:59.100 --> 01:39:01.300]   They're scary like one point.
[01:39:01.300 --> 01:39:02.580]   It was going very, very slowly.
[01:39:02.580 --> 01:39:05.500]   We didn't know why I'm thinking what's happening.
[01:39:05.500 --> 01:39:07.420]   Like what what is it doing?
[01:39:07.420 --> 01:39:11.260]   Where you just at least it makes it feel a little bit like you're driving that really
[01:39:11.260 --> 01:39:15.100]   nervous driver who either doesn't know what they're doing or maybe you're not from this
[01:39:15.100 --> 01:39:16.100]   town.
[01:39:16.100 --> 01:39:20.100]   You have no idea where Elm Street is and you're desperately trying to find Elm Street.
[01:39:20.100 --> 01:39:23.060]   So you're driving like past every road and kind of pausing.
[01:39:23.060 --> 01:39:25.820]   That's kind of how it felt for a good bit of the drop.
[01:39:25.820 --> 01:39:28.940]   It was it was a little cautious.
[01:39:28.940 --> 01:39:30.220]   It was a little cautious.
[01:39:30.220 --> 01:39:34.900]   And then then we had our cruise robot taxi honking its horn at another cruise.
[01:39:34.900 --> 01:39:37.780]   Yeah, they'll honk at each other, which is kind of fun.
[01:39:37.780 --> 01:39:39.740]   Why do they honk at each other?
[01:39:39.740 --> 01:39:41.420]   Because the one was confused.
[01:39:41.420 --> 01:39:43.900]   It thought it was going to hit a car even though it wasn't.
[01:39:43.900 --> 01:39:46.260]   And so it decided to back up, but we were behind it.
[01:39:46.260 --> 01:39:48.100]   So as soon as it started back.
[01:39:48.100 --> 01:39:49.100]   Oh my God.
[01:39:49.100 --> 01:39:52.100]   Ours, which by the name was by the way was named Alcatraz, which I felt right there.
[01:39:52.100 --> 01:39:53.100]   I told you.
[01:39:53.100 --> 01:39:54.100]   You just have to get an R.
[01:39:54.100 --> 01:39:55.460]   Like we're riding in a prison.
[01:39:55.460 --> 01:39:57.060]   I don't like the federal like this.
[01:39:57.060 --> 01:39:58.060]   I like this.
[01:39:58.060 --> 01:39:59.620]   Were you was yours called Leavenworths?
[01:39:59.620 --> 01:40:00.620]   That would have been funny.
[01:40:00.620 --> 01:40:01.620]   Yeah.
[01:40:01.620 --> 01:40:02.620]   No, we were in Alcatraz.
[01:40:02.620 --> 01:40:03.620]   We were in Alcatraz.
[01:40:03.620 --> 01:40:04.620]   We were in Alcatraz.
[01:40:04.620 --> 01:40:05.620]   We were in Alcatraz.
[01:40:05.620 --> 01:40:06.620]   Famous federal prisons.
[01:40:06.620 --> 01:40:08.300]   That's just the way it is.
[01:40:08.300 --> 01:40:09.300]   Yeah, right.
[01:40:09.300 --> 01:40:12.740]   They have all kind of they're all they all have names on them so that you can identify
[01:40:12.740 --> 01:40:13.740]   them.
[01:40:13.740 --> 01:40:17.500]   So in the app when when it pulls up, you know, it tells you, you know, Alcatraz is a
[01:40:17.500 --> 01:40:18.500]   running a runner's arriving.
[01:40:18.500 --> 01:40:19.500]   Seems like a terrible idea.
[01:40:19.500 --> 01:40:20.500]   Yeah.
[01:40:20.500 --> 01:40:21.500]   Yeah.
[01:40:21.500 --> 01:40:22.500]   Find the right one.
[01:40:22.500 --> 01:40:23.500]   Was it so was it.
[01:40:23.500 --> 01:40:26.820]   Nicole, was this your first time in a robo taxi?
[01:40:26.820 --> 01:40:28.100]   The first time in a robo taxi.
[01:40:28.100 --> 01:40:31.340]   I'd written in things where there was an engineer like sitting there with a keyboard
[01:40:31.340 --> 01:40:35.020]   frantically typing in the passenger seat up front and another guy just behind the steering
[01:40:35.020 --> 01:40:36.380]   wheel just in case.
[01:40:36.380 --> 01:40:39.860]   This is the first time there was absolutely no one in front.
[01:40:39.860 --> 01:40:43.260]   So if things had gone wrong, Sam and I would have died a terrible death.
[01:40:43.260 --> 01:40:45.180]   Like there was nothing anybody could do.
[01:40:45.180 --> 01:40:47.180]   That would help us.
[01:40:47.180 --> 01:40:48.180]   There was an incident.
[01:40:48.180 --> 01:40:49.180]   No one.
[01:40:49.180 --> 01:40:53.260]   You know, we had a mass shooting in San Francisco a couple of nights ago in the mission.
[01:40:53.260 --> 01:41:03.540]   And one of the stories was that a cruise blocked safety crews responding to the shooting.
[01:41:03.540 --> 01:41:10.460]   That it just here's the video that was posted on Twitter.
[01:41:10.460 --> 01:41:15.060]   The car stopped in the middle of the road on 24th and fulsome.
[01:41:15.060 --> 01:41:17.300]   It's probably confused by emergency vehicles.
[01:41:17.300 --> 01:41:21.900]   It's just stuck there and gotten the way of the response.
[01:41:21.900 --> 01:41:29.260]   Well, they do have these vehicles and the WAMO vehicles at least and I think some others.
[01:41:29.260 --> 01:41:33.780]   One of the things they have on their microphones on the outside of the vehicle to listen for
[01:41:33.780 --> 01:41:34.780]   emergency vehicles.
[01:41:34.780 --> 01:41:40.700]   So if they hear a siren, they're supposed to pull over and stop just like we do.
[01:41:40.700 --> 01:41:46.780]   And so there's, it may have heard the sirens and...
[01:41:46.780 --> 01:41:47.780]   It didn't know where it was.
[01:41:47.780 --> 01:41:48.780]   I'm just gonna stop right here.
[01:41:48.780 --> 01:41:49.780]   I'm just gonna stop.
[01:41:49.780 --> 01:41:50.780]   I'm just gonna stop.
[01:41:50.780 --> 01:41:52.540]   This is probably the safest thing to do.
[01:41:52.540 --> 01:41:56.500]   But that's the issue with self-driving cars is that getting them to go from here to here
[01:41:56.500 --> 01:41:59.500]   in a straight line where on a highway is easy.
[01:41:59.500 --> 01:42:03.220]   But when you have the context of, you know, you've been driving a car for decades, you
[01:42:03.220 --> 01:42:04.780]   understand, oh, I'm in an area.
[01:42:04.780 --> 01:42:06.460]   Yes, there are sirens going on.
[01:42:06.460 --> 01:42:08.700]   But I definitely need to get out of this area.
[01:42:08.700 --> 01:42:10.500]   I'm in the way or I'm doing this.
[01:42:10.500 --> 01:42:12.980]   And the driverless car doesn't know that.
[01:42:12.980 --> 01:42:13.980]   It doesn't understand that.
[01:42:13.980 --> 01:42:16.060]   It doesn't understand edge cases.
[01:42:16.060 --> 01:42:19.700]   And so you can keep throwing edge cases at it and keep throwing edge cases at it.
[01:42:19.700 --> 01:42:26.780]   It's still, it's a very, it's very difficult for a car to react like a human who understands
[01:42:26.780 --> 01:42:31.620]   the entire world and the context of what is happening in the environment there and at
[01:42:31.620 --> 01:42:32.620]   that moment.
[01:42:32.620 --> 01:42:36.140]   Like if that cruise had pulled up and there'd be a bunch of, let's say, sheep, a bunch of
[01:42:36.140 --> 01:42:37.540]   sheep got out.
[01:42:37.540 --> 01:42:40.340]   You would know, oh, okay, I can just sit here, I wait till the sheep go by.
[01:42:40.340 --> 01:42:41.540]   There's a sheep herd or whatever.
[01:42:41.540 --> 01:42:43.420]   Like, oh, this is my let's shoot video.
[01:42:43.420 --> 01:42:45.220]   The car doesn't know what's going on.
[01:42:45.220 --> 01:42:46.980]   All knows is there's a bunch of dogs.
[01:42:46.980 --> 01:42:48.980]   And now it's completely confused.
[01:42:48.980 --> 01:42:50.900]   It's just like little itty-bitty things.
[01:42:50.900 --> 01:42:53.460]   Like, you know, someone throws a firework on the road.
[01:42:53.460 --> 01:42:54.460]   The car doesn't know what's going on.
[01:42:54.460 --> 01:42:55.460]   You know what's going on.
[01:42:55.460 --> 01:43:01.580]   And so it's like all the edge cases is the reason why self-driving cars are still, I
[01:43:01.580 --> 01:43:04.100]   mean, to be honest, pretty far out.
[01:43:04.100 --> 01:43:09.300]   In a way that we think that a self-driving car will be, when you get in the car, it drives
[01:43:09.300 --> 01:43:13.820]   you from your house to your office without you interacting at all.
[01:43:13.820 --> 01:43:14.820]   I mean, surface streets.
[01:43:14.820 --> 01:43:19.980]   It means the highway that means, you know, with construction zones, with weird traffic
[01:43:19.980 --> 01:43:23.300]   patterns, like that's still pretty far off.
[01:43:23.300 --> 01:43:31.220]   Well, if we've learned anything, almost autonomous is worse than no autonomy at all,
[01:43:31.220 --> 01:43:32.860]   right?
[01:43:32.860 --> 01:43:37.460]   The impression of autonomy is terrible, you know, if they're not going to.
[01:43:37.460 --> 01:43:41.580]   And by the way, this is also the lesson we're learning in general about AI.
[01:43:41.580 --> 01:43:42.980]   It doesn't think.
[01:43:42.980 --> 01:43:43.980]   It's not thinking.
[01:43:43.980 --> 01:43:46.180]   It doesn't actually have understanding.
[01:43:46.180 --> 01:43:47.180]   Yeah.
[01:43:47.180 --> 01:43:48.180]   It doesn't know what's going on.
[01:43:48.180 --> 01:43:49.700]   It's just processing the information.
[01:43:49.700 --> 01:43:52.140]   And the first time it gets information, it hasn't hit before.
[01:43:52.140 --> 01:43:53.140]   Right.
[01:43:53.140 --> 01:43:54.380]   Suddenly, it doesn't know what to do.
[01:43:54.380 --> 01:43:58.220]   And that's a problem when you got emergency vehicles trying to get by a car.
[01:43:58.220 --> 01:44:00.580]   And yet we seem to be moving full speed ahead.
[01:44:00.580 --> 01:44:06.900]   Mercedes just got approval in California to sell hands-free, eyes-off automated driving
[01:44:06.900 --> 01:44:07.900]   vehicles.
[01:44:07.900 --> 01:44:12.980]   But that's still on like it's on mapped roads.
[01:44:12.980 --> 01:44:14.340]   It's only on the highway.
[01:44:14.340 --> 01:44:22.580]   It's only at the certain speeds and the amount of like they have these super high quality
[01:44:22.580 --> 01:44:27.540]   GPS sensor that tells you within like a few centimeters of where the vehicle is.
[01:44:27.540 --> 01:44:30.420]   I mean, there's a lot that goes on to this vehicle.
[01:44:30.420 --> 01:44:36.020]   Essentially so if you're stuck in traffic, if you're stuck in gridlock, you can do something
[01:44:36.020 --> 01:44:37.020]   else.
[01:44:37.020 --> 01:44:39.540]   That's really what it's for.
[01:44:39.540 --> 01:44:46.220]   Their level three system is really for if you're stuck and you're not going above a certain
[01:44:46.220 --> 01:44:47.780]   speed.
[01:44:47.780 --> 01:44:50.500]   It's literally just like I'm stuck in traffic.
[01:44:50.500 --> 01:44:54.620]   I'm not getting off the freeway for the next 20, 30 minutes.
[01:44:54.620 --> 01:44:56.180]   So I guess I'll watch a movie.
[01:44:56.180 --> 01:44:58.780]   You could watch it also doesn't work at night or in the rain.
[01:44:58.780 --> 01:44:59.780]   Oh yeah.
[01:44:59.780 --> 01:45:00.780]   It also doesn't work at night in the rain.
[01:45:00.780 --> 01:45:02.260]   And they're very like, they're very forthcoming.
[01:45:02.260 --> 01:45:06.620]   Like, yeah, there's sensors here just in the wheel wells, just in case the other sensors
[01:45:06.620 --> 01:45:07.940]   don't know it's raining.
[01:45:07.940 --> 01:45:11.380]   There's a moisture sensor in the wheel well.
[01:45:11.380 --> 01:45:14.060]   So they'll have this redundant sensor to tell them when it's raining.
[01:45:14.060 --> 01:45:15.060]   Nope, nope.
[01:45:15.060 --> 01:45:16.060]   We're not working anymore.
[01:45:16.060 --> 01:45:17.060]   We're done.
[01:45:17.060 --> 01:45:19.580]   This is maybe what Tesla should be doing.
[01:45:19.580 --> 01:45:24.580]   The drive pilot system has both LiDAR, radar and cameras.
[01:45:24.580 --> 01:45:29.900]   It's only available at speeds up to 40 miles an hour during daylight hours on certain highways.
[01:45:29.900 --> 01:45:34.780]   It will not engage on city or county roads in construction zones during heavy rain, heavy
[01:45:34.780 --> 01:45:40.180]   fog on flooded roads during weather conditions, determined impact performance on the system,
[01:45:40.180 --> 01:45:42.660]   or when there are sheep in the road.
[01:45:42.660 --> 01:45:44.140]   None of those situations.
[01:45:44.140 --> 01:45:45.900]   No sheep in the road.
[01:45:45.900 --> 01:45:48.860]   So there's so five minutes of your one hour commute.
[01:45:48.860 --> 01:45:49.860]   Can you actually use this?
[01:45:49.860 --> 01:45:52.580]   So this is really for stopping go traffic in.
[01:45:52.580 --> 01:45:53.580]   It's literally LA.
[01:45:53.580 --> 01:45:56.340]   It's the LA for the 405 or the 101.
[01:45:56.340 --> 01:45:58.180]   It is definitely built for LA.
[01:45:58.180 --> 01:46:03.220]   And when I've done a bunch of demos in this vehicle and one of the demos was in LA.
[01:46:03.220 --> 01:46:07.220]   They're like, we're going to LA because of course we're going to do this.
[01:46:07.220 --> 01:46:08.220]   We're also.
[01:46:08.220 --> 01:46:11.340]   Yeah, there's never a time in LA where there isn't a traffic jam.
[01:46:11.340 --> 01:46:13.300]   It's always bad.
[01:46:13.300 --> 01:46:15.060]   And it's usually not cheap.
[01:46:15.060 --> 01:46:16.060]   Yeah.
[01:46:16.060 --> 01:46:17.060]   I just should.
[01:46:17.060 --> 01:46:18.060]   Usually.
[01:46:18.060 --> 01:46:19.060]   Usually.
[01:46:19.060 --> 01:46:20.060]   Yeah.
[01:46:20.060 --> 01:46:24.860]   I want to address something you mentioned earlier about how bad human drivers are.
[01:46:24.860 --> 01:46:30.580]   And granted, 40,000 people a year dying on the roads in the US is a million worldwide.
[01:46:30.580 --> 01:46:31.580]   I mean, it's terrible.
[01:46:31.580 --> 01:46:32.580]   Yeah.
[01:46:32.580 --> 01:46:34.100]   And we absolutely need to do something about that.
[01:46:34.100 --> 01:46:38.460]   But you actually you have to look at it from the other side as well.
[01:46:38.460 --> 01:46:41.780]   You know, it's this is a classic case of tell me which side of the argument you're on and
[01:46:41.780 --> 01:46:43.740]   I'll give you statistics to prove you're right.
[01:46:43.740 --> 01:46:47.380]   You often hear 94% of crashes are caused by human error.
[01:46:47.380 --> 01:46:48.740]   That's only partly true.
[01:46:48.740 --> 01:46:53.260]   Human error is a factor in those, but it's not it's almost never the only factor.
[01:46:53.260 --> 01:46:57.620]   And when you consider how much we actually drive.
[01:46:57.620 --> 01:47:00.900]   We drive in the US, we drive about 3.2 trillion miles a year.
[01:47:00.900 --> 01:47:01.900]   Wow.
[01:47:01.900 --> 01:47:02.900]   That's trillion with a T.
[01:47:02.900 --> 01:47:03.900]   Wow.
[01:47:03.900 --> 01:47:05.260]   And we have about 6.5 million crashes.
[01:47:05.260 --> 01:47:07.260]   So that works out to about one crash.
[01:47:07.260 --> 01:47:08.260]   And this is not fatal crashes.
[01:47:08.260 --> 01:47:13.140]   This is all crashes, you know, even fender benders, but one crash every half a million
[01:47:13.140 --> 01:47:16.900]   miles is the average person drives 15,000 miles a year.
[01:47:16.900 --> 01:47:21.620]   That's you're going to crash your your odds of crashing about once every 30 years.
[01:47:21.620 --> 01:47:22.620]   That's about right.
[01:47:22.620 --> 01:47:23.620]   Yeah.
[01:47:23.620 --> 01:47:30.660]   So, you know, that's that's actually a remarkably high threshold or an automated system to overcome.
[01:47:30.660 --> 01:47:31.660]   Yeah.
[01:47:31.660 --> 01:47:33.060]   And they have not done that yet.
[01:47:33.060 --> 01:47:34.060]   Yeah.
[01:47:34.060 --> 01:47:38.500]   You know, one crash every every 30 years, every half a million miles.
[01:47:38.500 --> 01:47:39.860]   We've still got a ways to go.
[01:47:39.860 --> 01:47:44.180]   And that's that's those those human crashes under all conditions.
[01:47:44.180 --> 01:47:45.180]   That's in blizzards.
[01:47:45.180 --> 01:47:48.940]   And you know, monsoons and dust storms at night.
[01:47:48.940 --> 01:47:51.620]   And that includes drunk drivers and everything else.
[01:47:51.620 --> 01:47:58.700]   So, you know, it's actually really, really hard to make an automated system that is better
[01:47:58.700 --> 01:48:00.300]   than a human driver.
[01:48:00.300 --> 01:48:02.740]   Boy, that's such a strong point.
[01:48:02.740 --> 01:48:03.660]   I'm glad you said that.
[01:48:03.660 --> 01:48:06.260]   I did not know that.
[01:48:06.260 --> 01:48:07.620]   It would be difficult, wouldn't it?
[01:48:07.620 --> 01:48:08.620]   Yeah.
[01:48:08.620 --> 01:48:09.620]   Yeah.
[01:48:09.620 --> 01:48:13.580]   It boggles my mind when I'm driving to think about I just drove with all these thousands
[01:48:13.580 --> 01:48:16.140]   of other people from this place to another place.
[01:48:16.140 --> 01:48:17.700]   And we're all doing all these different things.
[01:48:17.700 --> 01:48:18.700]   It's amazing.
[01:48:18.700 --> 01:48:21.180]   There's all these lights and there's all these stop signs and there's all these things
[01:48:21.180 --> 01:48:24.300]   that happened and there's construction and people walking in the road and again, the
[01:48:24.300 --> 01:48:26.700]   sheep and you know, all these things are going on.
[01:48:26.700 --> 01:48:29.900]   And we just, yeah, I'm doing my thing.
[01:48:29.900 --> 01:48:30.900]   I always think that...
[01:48:30.900 --> 01:48:31.900]   Or if you're in Michigan, it's deer.
[01:48:31.900 --> 01:48:32.900]   Yeah.
[01:48:32.900 --> 01:48:37.820]   I always think that when I watch the fifth element, you know, it's Bruce Willis is the
[01:48:37.820 --> 01:48:39.420]   flying cab driver.
[01:48:39.420 --> 01:48:45.660]   And he zips into the flying cab and he's driving around and I'm thinking, you know, as impossible
[01:48:45.660 --> 01:48:52.100]   as it seems, probably that's not that much different from us driving around day to day
[01:48:52.100 --> 01:48:53.940]   and are, we're just used to it.
[01:48:53.940 --> 01:48:54.940]   That's all.
[01:48:54.940 --> 01:48:55.940]   Yeah.
[01:48:55.940 --> 01:49:01.500]   And it's probably, you know, in the sometime in the future with flying cars, I always thought
[01:49:01.500 --> 01:49:03.740]   we wouldn't have flying cars until we had full autonomy.
[01:49:03.740 --> 01:49:07.740]   That's the only way, because if a flying car crashes, he falls on your head.
[01:49:07.740 --> 01:49:08.740]   It's not a...
[01:49:08.740 --> 01:49:09.740]   Well, that's the problem.
[01:49:09.740 --> 01:49:11.540]   The car is falling out of the sky.
[01:49:11.540 --> 01:49:12.740]   It's not a worry about that.
[01:49:12.740 --> 01:49:13.740]   A good look.
[01:49:13.740 --> 01:49:14.740]   Yeah.
[01:49:14.740 --> 01:49:15.740]   And then speaking of which...
[01:49:15.740 --> 01:49:16.740]   Sort of a bad idea.
[01:49:16.740 --> 01:49:17.740]   Yeah.
[01:49:17.740 --> 01:49:21.620]   You know, that's something else, you know, probably the first regulation we need to have
[01:49:21.620 --> 01:49:25.860]   because we don't actually have any regulations at a federal level around automated driving.
[01:49:25.860 --> 01:49:30.460]   The first thing we actually need to have is a change in the rules that if the vehicle
[01:49:30.460 --> 01:49:35.500]   is in an automated driving mode where the human is not required to watch the road, so
[01:49:35.500 --> 01:49:41.860]   level three and above, the manufacturer must be liable if something happens while you're
[01:49:41.860 --> 01:49:42.860]   in that mode.
[01:49:42.860 --> 01:49:44.700]   The human should not be liable.
[01:49:44.700 --> 01:49:46.900]   That would shut you on up fast.
[01:49:46.900 --> 01:49:47.900]   Yeah.
[01:49:47.900 --> 01:49:51.700]   Well, Mercedes and Volvo, and I think BMW have all said that they will be...
[01:49:51.700 --> 01:49:52.700]   Yeah.
[01:49:52.700 --> 01:49:57.700]   Most automakers have said at least off the record they haven't necessarily declared it publicly,
[01:49:57.700 --> 01:49:59.620]   but they said that, yeah, that's their intention.
[01:49:59.620 --> 01:50:00.620]   That's fair.
[01:50:00.620 --> 01:50:05.220]   If the human is not supervising, then they're responsible.
[01:50:05.220 --> 01:50:07.620]   The only one that has never said that is Tesla.
[01:50:07.620 --> 01:50:10.620]   Yeah, that's the last thing they'd want.
[01:50:10.620 --> 01:50:13.420]   Is there a chance Congress could ever pass something like that?
[01:50:13.420 --> 01:50:14.940]   Or was it NHTSA that would have to do that?
[01:50:14.940 --> 01:50:15.940]   I don't know that...
[01:50:15.940 --> 01:50:17.500]   I don't know if Congress necessarily has to.
[01:50:17.500 --> 01:50:18.500]   It could just be an...
[01:50:18.500 --> 01:50:21.100]   Probably NHTSA or maybe the FTC.
[01:50:21.100 --> 01:50:22.100]   Yeah.
[01:50:22.100 --> 01:50:23.100]   Yeah.
[01:50:23.100 --> 01:50:24.100]   Interesting.
[01:50:24.100 --> 01:50:26.940]   Well, at some point the courts would test it because...
[01:50:26.940 --> 01:50:27.940]   Yeah.
[01:50:27.940 --> 01:50:30.220]   Yeah, Elon would say, "Wait a minute.
[01:50:30.220 --> 01:50:31.220]   I'm not liable."
[01:50:31.220 --> 01:50:33.180]   All right, let's take a little break.
[01:50:33.180 --> 01:50:37.980]   Lots more to come with our Wheel Bering's takeover from wheelbering.media Samable Sammett.
[01:50:37.980 --> 01:50:41.420]   He's also a regular and asked the tech guy and on Twitch.
[01:50:41.420 --> 01:50:43.060]   Many of other shows, great to have you.
[01:50:43.060 --> 01:50:44.860]   Sam, you were on Ask the Tech Guy.
[01:50:44.860 --> 01:50:51.500]   Earlier today, we talked about Elon's imminent takeover of the entire EV charging infrastructure
[01:50:51.500 --> 01:50:52.500]   in the United States.
[01:50:52.500 --> 01:50:56.060]   You should probably should talk about that again on this show.
[01:50:56.060 --> 01:50:58.940]   Give Robbie and Nicole a chance to respond.
[01:50:58.940 --> 01:51:04.060]   Robbie, Roberto Baldwin, as he's known to his enemies.
[01:51:04.060 --> 01:51:12.340]   Freelance, journalist, dude, leader of many cover bands, wearer of the daft punk helmet,
[01:51:12.340 --> 01:51:14.700]   and Nicole Wakelin.
[01:51:14.700 --> 01:51:15.700]   Wakelin.
[01:51:15.700 --> 01:51:16.700]   Wakelin.
[01:51:16.700 --> 01:51:17.700]   Wakelin.
[01:51:17.700 --> 01:51:21.420]   Automotive journalist from New Hampshire.
[01:51:21.420 --> 01:51:23.580]   Are you a native of New Hampshire, Nicole?
[01:51:23.580 --> 01:51:24.580]   Pretty much.
[01:51:24.580 --> 01:51:26.140]   I moved here when I was like two.
[01:51:26.140 --> 01:51:27.140]   So I would say...
[01:51:27.140 --> 01:51:28.140]   That counts.
[01:51:28.140 --> 01:51:29.140]   Yeah, that counts.
[01:51:29.140 --> 01:51:31.140]   I grew up in Rhode Island.
[01:51:31.140 --> 01:51:33.500]   But I lost the accent when I moved.
[01:51:33.500 --> 01:51:36.620]   But you don't have any New Hampshire accent.
[01:51:36.620 --> 01:51:38.540]   You can't get that from me.
[01:51:38.540 --> 01:51:42.020]   No, my mom was from Pennsylvania and she hated the New England accent.
[01:51:42.020 --> 01:51:47.620]   So she corrected every time I said "Fire instead of fire and water instead of water."
[01:51:47.620 --> 01:51:50.340]   She corrected me my whole life and drove me nuts.
[01:51:50.340 --> 01:51:52.340]   But now, thanks, mom.
[01:51:52.340 --> 01:51:53.340]   Yeah.
[01:51:53.340 --> 01:51:56.340]   Yeah, I guess I owe it to my mom too that I never got the Cranston accent.
[01:51:56.340 --> 01:51:57.340]   She still lives in Cranston.
[01:51:57.340 --> 01:51:59.300]   That is the worst doing with accent.
[01:51:59.300 --> 01:52:01.300]   If you want to pick one, it's Cranston.
[01:52:01.300 --> 01:52:02.300]   Cranston, do you have one?
[01:52:02.300 --> 01:52:03.540]   Yeah, is that the one?
[01:52:03.540 --> 01:52:04.540]   Some nasal.
[01:52:04.540 --> 01:52:05.540]   Some nasal.
[01:52:05.540 --> 01:52:06.540]   Are showing...
[01:52:06.540 --> 01:52:08.020]   You're not doing this accent, so good.
[01:52:08.020 --> 01:52:09.460]   I think some of them are great.
[01:52:09.460 --> 01:52:12.420]   Yeah, I love the Boston accent as does Hollywood.
[01:52:12.420 --> 01:52:14.220]   So there you go.
[01:52:14.220 --> 01:52:17.940]   Our show today brought to you by Miro.
[01:52:17.940 --> 01:52:23.780]   You know, I always struggle with Miro because I don't know how to describe it because it
[01:52:23.780 --> 01:52:26.460]   could be anything you need it to be.
[01:52:26.460 --> 01:52:32.500]   It is a workspace for you and your team to get the job done, to brainstorm, to share
[01:52:32.500 --> 01:52:34.060]   ideas.
[01:52:34.060 --> 01:52:38.460]   If you and your team are still going from tab to tab and tool to tool, you know, every
[01:52:38.460 --> 01:52:41.020]   time we switch context like that, you lose ideas.
[01:52:41.020 --> 01:52:43.420]   You forget where you are, right?
[01:52:43.420 --> 01:52:45.460]   Important information just drifts away with Miro.
[01:52:45.460 --> 01:52:46.940]   You don't have to do that.
[01:52:46.940 --> 01:52:52.980]   Miro is a collaborative visual platform that brings all your great work together no matter
[01:52:52.980 --> 01:52:59.540]   where you are, no matter what you use because it integrates with all the tools you use today.
[01:52:59.540 --> 01:53:05.060]   And even if you're not in the same time zone with your team, you all can work together
[01:53:05.060 --> 01:53:08.740]   in one workspace online.
[01:53:08.740 --> 01:53:11.620]   It really is the best way to collaborate.
[01:53:11.620 --> 01:53:14.820]   It democratizes collaboration and input.
[01:53:14.820 --> 01:53:16.420]   Everybody's on an equal playing field.
[01:53:16.420 --> 01:53:17.900]   There's one source of truth.
[01:53:17.900 --> 01:53:22.100]   You can zoom in if you want to see the details, zoom out if you want to see the overview.
[01:53:22.100 --> 01:53:27.260]   Miro's infinite shared boards give product teams a perpetual space where they can drag
[01:53:27.260 --> 01:53:29.380]   and drop insights and data.
[01:53:29.380 --> 01:53:30.820]   Nothing is lost.
[01:53:30.820 --> 01:53:32.340]   It can be a vision board.
[01:53:32.340 --> 01:53:33.980]   It can be a can-band board.
[01:53:33.980 --> 01:53:35.860]   It could be a swim lane chart.
[01:53:35.860 --> 01:53:38.540]   Miro covers a breadth of use cases.
[01:53:38.540 --> 01:53:39.940]   You can build visual assets.
[01:53:39.940 --> 01:53:41.100]   You can present findings.
[01:53:41.100 --> 01:53:43.980]   You can run brainstorms with cross-functional teams.
[01:53:43.980 --> 01:53:47.300]   The product designers can sketch out an idea.
[01:53:47.300 --> 01:53:50.260]   The engineers can come in and build it out.
[01:53:50.260 --> 01:53:53.260]   Your executives can come in and say, "How do we market this?"
[01:53:53.260 --> 01:53:58.980]   You can build out your product vision by brainstorming on a Miro board with sticky notes, with comments,
[01:53:58.980 --> 01:54:00.500]   with live reactions.
[01:54:00.500 --> 01:54:02.420]   There's a voting tool which is very useful.
[01:54:02.420 --> 01:54:05.260]   There's a timer great for online meetings.
[01:54:05.260 --> 01:54:07.820]   So you come to consensus quickly.
[01:54:07.820 --> 01:54:11.180]   You can express yourself in creative ways, bring the whole group together around one
[01:54:11.180 --> 01:54:12.180]   idea.
[01:54:12.180 --> 01:54:15.020]   It's so hard for me to describe because it'd be so many things.
[01:54:15.020 --> 01:54:16.020]   Here's what you do.
[01:54:16.020 --> 01:54:19.780]   You go to mirror.com/podcast, sign up for your free account.
[01:54:19.780 --> 01:54:24.140]   Your first three boards are free so you can start working right now and really get an
[01:54:24.140 --> 01:54:25.660]   idea of what it can do.
[01:54:25.660 --> 01:54:30.900]   You can also, and this is fantastic, click the button on the left.
[01:54:30.900 --> 01:54:32.220]   It says Miroverse.
[01:54:32.220 --> 01:54:36.740]   This is a whole bunch of templates created by Miro users donated to you.
[01:54:36.740 --> 01:54:40.860]   You can use them yourself, but it's a great idea to get a sense of what you can do with
[01:54:40.860 --> 01:54:41.860]   Miro.
[01:54:41.860 --> 01:54:49.020]   It is incredibly creative, whether it's a wireframe or a sketch or images collaged from other
[01:54:49.020 --> 01:54:50.140]   sources.
[01:54:50.140 --> 01:54:58.460]   You can drag in your data from all the tools that you use, Google Docs and Drive and Zoom.
[01:54:58.460 --> 01:55:03.620]   Miro users say they save up to 80 hours per user per year by streamlining conversations,
[01:55:03.620 --> 01:55:04.620]   cutting down meetings.
[01:55:04.620 --> 01:55:06.420]   It works with Zapier.
[01:55:06.420 --> 01:55:10.660]   So you can actually bring data into Miro automatically.
[01:55:10.660 --> 01:55:16.260]   It's a great way for any team to stay connected to real-time information no matter where they
[01:55:16.260 --> 01:55:19.580]   are, no matter what time zone they're in.
[01:55:19.580 --> 01:55:24.060]   It gives project managers and product leads a bird's eye view of the whole project so
[01:55:24.060 --> 01:55:26.060]   nothing slips through the cracks.
[01:55:26.060 --> 01:55:28.860]   Don't wonder a million people use Miro every month.
[01:55:28.860 --> 01:55:33.900]   A million people use Miro every month.
[01:55:33.900 --> 01:55:34.900]   I want you to try it.
[01:55:34.900 --> 01:55:35.900]   You can for free.
[01:55:35.900 --> 01:55:36.900]   Three boards free.
[01:55:36.900 --> 01:55:44.220]   You're creating your best work yet, MiroMiro.com/podcast.
[01:55:44.220 --> 01:55:46.100]   I can't tell you what you could do with it.
[01:55:46.100 --> 01:55:48.220]   You got to try it and you will see.
[01:55:48.220 --> 01:55:49.220]   It's really amazing.
[01:55:49.220 --> 01:55:51.580]   Miro.com/podcast.
[01:55:51.580 --> 01:55:59.980]   We thank them so much for their support of this week in tech and our big wheel bearings
[01:55:59.980 --> 01:56:02.020]   takeover.
[01:56:02.020 --> 01:56:05.460]   Wheel bearings dot media.
[01:56:05.460 --> 01:56:07.460]   Do we want to talk about the...
[01:56:07.460 --> 01:56:10.660]   I'm a little worried that Elon is going to...
[01:56:10.660 --> 01:56:11.660]   All the car...
[01:56:11.660 --> 01:56:15.860]   Well, Ford and GM at least, but I think if once Ford and GM do it, probably others will
[01:56:15.860 --> 01:56:23.540]   as well are saying we're going to support the Tesla Supercharger.
[01:56:23.540 --> 01:56:28.740]   And Sam, you said this will ultimately be in replacing the fast charging system that
[01:56:28.740 --> 01:56:31.220]   we use today.
[01:56:31.220 --> 01:56:32.220]   I think it will be.
[01:56:32.220 --> 01:56:37.180]   I think it's the Supercharger connector, the so-called North American charging standard
[01:56:37.180 --> 01:56:43.820]   connector, which Tesla just rebranded a few months ago from...
[01:56:43.820 --> 01:56:45.700]   It previously didn't really have a name now.
[01:56:45.700 --> 01:56:49.580]   It's NACS.
[01:56:49.580 --> 01:56:55.180]   That is going to become the standard and CCS is eventually just going to fade away much
[01:56:55.180 --> 01:56:58.340]   like HD DVD is so popular today.
[01:56:58.340 --> 01:56:59.340]   What?
[01:56:59.340 --> 01:57:11.260]   Earlier today, I said it was like the VHS Betamax battle back in the '80s or '70s.
[01:57:11.260 --> 01:57:13.460]   But this time Betamax won.
[01:57:13.460 --> 01:57:14.460]   The proprietary...
[01:57:14.460 --> 01:57:15.460]   Is it better?
[01:57:15.460 --> 01:57:16.460]   It's better.
[01:57:16.460 --> 01:57:18.620]   Betamax was always better, right?
[01:57:18.620 --> 01:57:20.500]   It was better.
[01:57:20.500 --> 01:57:23.260]   It was better.
[01:57:23.260 --> 01:57:25.660]   These charging companies, they've had time.
[01:57:25.660 --> 01:57:31.140]   They've had time to build a nice, robust, reliable network and they've not built a reliable
[01:57:31.140 --> 01:57:32.140]   network.
[01:57:32.140 --> 01:57:33.460]   Explain to me why not.
[01:57:33.460 --> 01:57:35.460]   This is the thing that puzzles me.
[01:57:35.460 --> 01:57:36.460]   I...
[01:57:36.460 --> 01:57:39.260]   You know, as somebody who drives an EV day in day out, I agree with you.
[01:57:39.260 --> 01:57:42.620]   I mean, half the time you pull up to a charger, it's out of order.
[01:57:42.620 --> 01:57:43.620]   Why is that?
[01:57:43.620 --> 01:57:45.100]   They have a million reasons.
[01:57:45.100 --> 01:57:48.820]   Like, when you talk to them, I did a road trip from Disneyland to Disney World in an
[01:57:48.820 --> 01:57:50.580]   EV to see how...
[01:57:50.580 --> 01:57:51.580]   Wow.
[01:57:51.580 --> 01:57:52.580]   Yeah, I was insane.
[01:57:52.580 --> 01:57:53.580]   So I did this.
[01:57:53.580 --> 01:57:58.620]   And it was to see like, just, okay, if you just did it and you just stop at charging stations,
[01:57:58.620 --> 01:58:00.700]   how hard is it to do and how long will it take?
[01:58:00.700 --> 01:58:01.700]   And they just...
[01:58:01.700 --> 01:58:02.700]   They didn't work.
[01:58:02.700 --> 01:58:05.260]   And then when I talked to them after the fact, like, well, you know, when we installed these,
[01:58:05.260 --> 01:58:09.020]   we were trying to get them out really quick and we were limited to where we could put them.
[01:58:09.020 --> 01:58:11.660]   We were limited by the infrastructure.
[01:58:11.660 --> 01:58:13.780]   And it was just a million different excuses.
[01:58:13.780 --> 01:58:16.460]   So I was like, we're really doing our best and we're making it better.
[01:58:16.460 --> 01:58:18.060]   I'm like, but it stinks.
[01:58:18.060 --> 01:58:19.060]   It was terrible.
[01:58:19.060 --> 01:58:24.020]   Like, I would not having... just having things you walk up, it's like, oh, I'm gonna super...
[01:58:24.020 --> 01:58:25.820]   I should be getting tons of power.
[01:58:25.820 --> 01:58:26.820]   Seven kilowatts.
[01:58:26.820 --> 01:58:29.460]   I'm gonna be living at this charger now for the next five hours.
[01:58:29.460 --> 01:58:30.820]   Like, it was just...
[01:58:30.820 --> 01:58:31.820]   It was ridiculous.
[01:58:31.820 --> 01:58:32.820]   And they just...
[01:58:32.820 --> 01:58:34.820]   There's never any kind of...
[01:58:34.820 --> 01:58:36.260]   We messed up and this is why.
[01:58:36.260 --> 01:58:39.580]   It was like, well, all these things made it impossible for us to do better.
[01:58:39.580 --> 01:58:40.580]   We just couldn't.
[01:58:40.580 --> 01:58:41.580]   We couldn't.
[01:58:41.580 --> 01:58:43.580]   I mean, while Tesla had done it, like, ten years or...
[01:58:43.580 --> 01:58:44.580]   Exactly.
[01:58:44.580 --> 01:58:45.580]   I'm like, well, Tesla did it.
[01:58:45.580 --> 01:58:46.580]   I'm coming and can't do it.
[01:58:46.580 --> 01:58:49.940]   You don't want Elon to have a monopoly.
[01:58:49.940 --> 01:58:50.940]   One more thing.
[01:58:50.940 --> 01:58:55.380]   I mean, Elon is gonna own the solar panels.
[01:58:55.380 --> 01:58:57.540]   He's gonna own the EVs.
[01:58:57.540 --> 01:59:00.820]   He's gonna own the charging infrastructure.
[01:59:00.820 --> 01:59:02.620]   I think that's a bad thing.
[01:59:02.620 --> 01:59:03.820]   I mean, you need choice.
[01:59:03.820 --> 01:59:08.940]   Oh, it's a horrible thing because if I have a problem with electrified America, I can contact
[01:59:08.940 --> 01:59:09.940]   someone electrified America.
[01:59:09.940 --> 01:59:12.420]   There's an 800 number printed right on the charger.
[01:59:12.420 --> 01:59:14.540]   Yeah, and they pick up right away and they're very helpful, actually.
[01:59:14.540 --> 01:59:16.140]   If I have a problem with the degree that I can't help...
[01:59:16.140 --> 01:59:20.940]   And I email them, I'll probably get a poop emoji like the way you few email about Twitter.
[01:59:20.940 --> 01:59:23.020]   It's like, well, we don't have to talk to you.
[01:59:23.020 --> 01:59:27.940]   And so it's not an ideal situation.
[01:59:27.940 --> 01:59:31.500]   But if someone that comes up to me and says, "I want to drive an EV across country," what's
[01:59:31.500 --> 01:59:35.980]   the best way to do it, my immediate answer is, and even though I don't want this vehicle,
[01:59:35.980 --> 01:59:41.260]   I wouldn't recommend anyone buying this vehicle other than this situation, buy a Model 3.
[01:59:41.260 --> 01:59:43.020]   It is one of the reasons I bought a Model X.
[01:59:43.020 --> 01:59:47.900]   Actually, my first electric vehicle was a Tesla Model X, and I didn't buy it until they put
[01:59:47.900 --> 01:59:52.340]   a supercharger just down the road in Petaloma.
[01:59:52.340 --> 01:59:55.220]   Because I, in my mind, I think it's probably true, a lot of people who have never owned
[01:59:55.220 --> 01:59:58.740]   EVs thought, "Oh, I need to have a supercharger."
[01:59:58.740 --> 02:00:02.580]   And what I didn't realize is 99.9% of the time I charge at home.
[02:00:02.580 --> 02:00:03.580]   You never...
[02:00:03.580 --> 02:00:04.940]   I have a gas station in my house.
[02:00:04.940 --> 02:00:10.220]   Yeah, I have all this free charging credit with electric fire America for a Hyundai...
[02:00:10.220 --> 02:00:11.220]   Me too.
[02:00:11.220 --> 02:00:14.540]   So, we used it the first two times we charged.
[02:00:14.540 --> 02:00:16.700]   It's been like two years.
[02:00:16.700 --> 02:00:17.700]   We have to use these...
[02:00:17.700 --> 02:00:24.860]   I have a quarter million models for my Ford Maki, and I've used EA once.
[02:00:24.860 --> 02:00:26.260]   Yeah, you just don't need it.
[02:00:26.260 --> 02:00:27.260]   I don't need it.
[02:00:27.260 --> 02:00:28.260]   I get it at home.
[02:00:28.260 --> 02:00:29.260]   And I'm like, "We have to figure out...
[02:00:29.260 --> 02:00:30.500]   We have to use it somehow."
[02:00:30.500 --> 02:00:35.420]   My wife went on one road trip to San Joaquin Valley and used it then.
[02:00:35.420 --> 02:00:38.740]   There's still probably 225 free kilowatt hours.
[02:00:38.740 --> 02:00:41.740]   If you do the road trip, it's the road trip thing.
[02:00:41.740 --> 02:00:46.620]   If you drive long distances, you go out of your little circle of comfort where you know
[02:00:46.620 --> 02:00:47.620]   we're chargers.
[02:00:47.620 --> 02:00:48.620]   Then something you want to use it.
[02:00:48.620 --> 02:00:49.620]   No, not going to do it.
[02:00:49.620 --> 02:00:50.620]   I like my circle of comfort.
[02:00:50.620 --> 02:00:52.620]   You're just staying in your circle.
[02:00:52.620 --> 02:00:53.620]   That's it.
[02:00:53.620 --> 02:00:54.620]   Okay.
[02:00:54.620 --> 02:00:55.620]   But you need to worry about it, Leo.
[02:00:55.620 --> 02:00:58.620]   That's the crazy thing is that Americans think they take way more road trips than they
[02:00:58.620 --> 02:00:59.620]   actually do.
[02:00:59.620 --> 02:01:03.300]   They all remember as kids because flight is so incredibly expensive.
[02:01:03.300 --> 02:01:05.020]   We spend one with kids.
[02:01:05.020 --> 02:01:11.220]   Everyone drove everywhere, but now you can get a flight for 50 bucks to LA from San
[02:01:11.220 --> 02:01:12.220]   Francisco.
[02:01:12.220 --> 02:01:14.660]   You don't have to spend three days in the car with your kids.
[02:01:14.660 --> 02:01:19.700]   Yeah, we're taking Michael to Green Bay to see the Packers because somehow I don't understand
[02:01:19.700 --> 02:01:23.300]   how this kid grew up in the Bay Area as a Packers fan.
[02:01:23.300 --> 02:01:24.300]   Genetic mutation.
[02:01:24.300 --> 02:01:28.180]   But we're sure as hell not driving to Wisconsin, that would be insane.
[02:01:28.180 --> 02:01:29.900]   But in the 70s and 80s, you would.
[02:01:29.900 --> 02:01:34.000]   And so all the kids who have grown up, now we all think we're doing all these crazy road
[02:01:34.000 --> 02:01:35.000]   trips.
[02:01:35.000 --> 02:01:36.080]   The reality is we're not.
[02:01:36.080 --> 02:01:39.480]   And when you drive into work, you feel like you're driving so much further than you actually
[02:01:39.480 --> 02:01:41.240]   are because you're stuck in traffic.
[02:01:41.240 --> 02:01:43.400]   It takes an hour to go 20 miles.
[02:01:43.400 --> 02:01:44.400]   Yeah.
[02:01:44.400 --> 02:01:45.400]   Yeah.
[02:01:45.400 --> 02:01:52.560]   So there's this huge mental block within the American psyche when it comes to driving that
[02:01:52.560 --> 02:01:54.560]   no, I need to have a supercharger.
[02:01:54.560 --> 02:01:59.080]   I need to be able to drive from here, from San Francisco to Philadelphia at a moment.
[02:01:59.080 --> 02:02:00.680]   You never know.
[02:02:00.680 --> 02:02:01.680]   You could have it.
[02:02:01.680 --> 02:02:02.680]   You never know.
[02:02:02.680 --> 02:02:03.680]   You never know.
[02:02:03.680 --> 02:02:04.680]   It's going to happen.
[02:02:04.680 --> 02:02:08.920]   And even though every morning you get up and your car is full of gas, if you have an
[02:02:08.920 --> 02:02:12.720]   EV, the tank is full of electricity every morning.
[02:02:12.720 --> 02:02:13.720]   You never have to go to the gas station.
[02:02:13.720 --> 02:02:16.400]   You have to deal with that junk ever again.
[02:02:16.400 --> 02:02:22.920]   If you're just cruising around town, mostly what we do, we are still stuck in that mindset
[02:02:22.920 --> 02:02:26.480]   that we're always driving hundreds and hundreds of miles every week.
[02:02:26.480 --> 02:02:27.480]   We all think.
[02:02:27.480 --> 02:02:29.320]   So we're the blues brothers.
[02:02:29.320 --> 02:02:30.320]   Flipside.
[02:02:30.320 --> 02:02:31.320]   Yeah.
[02:02:31.320 --> 02:02:33.560]   Let me give you the flip side of what Robbie just said.
[02:02:33.560 --> 02:02:34.560]   Not the blues.
[02:02:34.560 --> 02:02:35.560]   Yeah.
[02:02:35.560 --> 02:02:41.560]   So he's absolutely right that most people rarely, if ever, take long road trips.
[02:02:41.560 --> 02:02:46.360]   And 85% of daily driving is less than 40 miles a day.
[02:02:46.360 --> 02:02:51.520]   So the vast majority of people could get along just fine with an EV that has a 200 mile
[02:02:51.520 --> 02:02:52.680]   range.
[02:02:52.680 --> 02:02:58.560]   And at, I mean, or 110 mile range, as Lisa has found out.
[02:02:58.560 --> 02:03:04.080]   And by the way, that's a good day with the wind in your back and her many coopers.
[02:03:04.080 --> 02:03:06.080]   She's just like 80 miles.
[02:03:06.080 --> 02:03:07.840]   But you know what, that's fine.
[02:03:07.840 --> 02:03:10.000]   Because she drives us to working back.
[02:03:10.000 --> 02:03:11.440]   She drives it around town.
[02:03:11.440 --> 02:03:12.440]   That's plenty.
[02:03:12.440 --> 02:03:13.440]   Right.
[02:03:13.440 --> 02:03:18.000]   But what you said, Leo, about, you know, you charge it at home almost all the time, send
[02:03:18.000 --> 02:03:19.840]   for Robbie.
[02:03:19.840 --> 02:03:24.760]   And you know, when you look at the people that are buying EVs today, that is absolutely
[02:03:24.760 --> 02:03:25.760]   true.
[02:03:25.760 --> 02:03:29.120]   But ask majority of them to do most of their charging at home.
[02:03:29.120 --> 02:03:33.760]   You know, and but the reality is most people don't buy new cars.
[02:03:33.760 --> 02:03:37.000]   We saw three and a half times as many used cars in the United States every year.
[02:03:37.000 --> 02:03:38.280]   Because most people are smart.
[02:03:38.280 --> 02:03:42.800]   I'm the only idiot lying in a car that's going to depreciate 50% the day I drive it
[02:03:42.800 --> 02:03:43.800]   off.
[02:03:43.800 --> 02:03:44.800]   Why?
[02:03:44.800 --> 02:03:45.800]   But that new car smell though.
[02:03:45.800 --> 02:03:47.040]   Oh, it's worth it, isn't it?
[02:03:47.040 --> 02:03:48.040]   Right.
[02:03:48.040 --> 02:03:49.760]   That's all you guys ever smell.
[02:03:49.760 --> 02:03:50.760]   You're like the queen.
[02:03:50.760 --> 02:03:54.120]   They say the queen of England only everything smelled like fresh paint to the queen of England
[02:03:54.120 --> 02:03:57.360]   because she never went anywhere that didn't just been freshly painted for her visit.
[02:03:57.360 --> 02:03:58.360]   Yeah.
[02:03:58.360 --> 02:04:00.040]   You guys think all cars smell really good.
[02:04:00.040 --> 02:04:01.840]   Oh, cars smell like new cars though.
[02:04:01.840 --> 02:04:03.960]   These are only driven new cars.
[02:04:03.960 --> 02:04:05.600]   So it's glorious.
[02:04:05.600 --> 02:04:11.080]   So, you know, the reality is, you know, that people that actually can afford to buy new
[02:04:11.080 --> 02:04:15.560]   cars are much more likely to live in a single family home with off street parking and they
[02:04:15.560 --> 02:04:17.320]   will charge at home.
[02:04:17.320 --> 02:04:22.200]   But as as EVs struck to filter into the used car market, people buy people in apartments
[02:04:22.200 --> 02:04:24.000]   and 15 year old cars.
[02:04:24.000 --> 02:04:25.000]   Yeah.
[02:04:25.000 --> 02:04:29.600]   You have a much higher proportion, you know, probably half of those people that don't
[02:04:29.600 --> 02:04:31.920]   live somewhere where they have off street parking.
[02:04:31.920 --> 02:04:34.560]   Those people are going to be dependent on public charging infrastructure.
[02:04:34.560 --> 02:04:35.560]   That's a very good one.
[02:04:35.560 --> 02:04:37.800]   A lot of which is going to be DC fast charging.
[02:04:37.800 --> 02:04:43.160]   So it is critical that we actually make this stuff reliable because even though we may
[02:04:43.160 --> 02:04:50.080]   not use it as much as you think today, 10 years from now, we'll be a lot of people will
[02:04:50.080 --> 02:04:53.240]   be much more reliant on those public chargers.
[02:04:53.240 --> 02:05:00.840]   And so, you know, going to Tesla today and which will put economic pressure on the electrify
[02:05:00.840 --> 02:05:08.320]   Americas and EV goes and charge points of the world to get their act together and improve
[02:05:08.320 --> 02:05:12.240]   their charging network reliability is I think is really important.
[02:05:12.240 --> 02:05:16.000]   Yeah, I don't want I don't want Tesla to have a monopoly and I don't think they will.
[02:05:16.000 --> 02:05:17.600]   I think that the competitive pressure.
[02:05:17.600 --> 02:05:24.800]   You told me on the Aztetecas, he is in effect open sourced the NCAS charger.
[02:05:24.800 --> 02:05:30.000]   Yeah, the connectors open source because GM and Ford both confirmed to me in the last
[02:05:30.000 --> 02:05:33.480]   couple of days that no, they don't have to panning royalty.
[02:05:33.480 --> 02:05:35.160]   They would never have a free charge.
[02:05:35.160 --> 02:05:37.680]   Have you talked to it if they'd had to be Elon?
[02:05:37.680 --> 02:05:38.680]   Yeah.
[02:05:38.680 --> 02:05:39.680]   Okay.
[02:05:39.680 --> 02:05:40.680]   Okay.
[02:05:40.680 --> 02:05:44.760]   Because that's the last thing we'd want to see which is I mean, Elon's bad enough, but
[02:05:44.760 --> 02:05:49.920]   if he owned every effectively, every gas station in America, he'd really be insufferable.
[02:05:49.920 --> 02:05:51.360]   I mean, we'd be.
[02:05:51.360 --> 02:05:52.720]   Because he's not now.
[02:05:52.720 --> 02:05:54.720]   Imagine, right?
[02:05:54.720 --> 02:05:58.720]   Well, how do we feel about Mr. Bean?
[02:05:58.720 --> 02:06:00.480]   That's the question.
[02:06:00.480 --> 02:06:03.240]   Rowan Atkinson, right in the Guardian.
[02:06:03.240 --> 02:06:10.480]   I love electric vehicles and was an early adopter, but increasingly I feel duped.
[02:06:10.480 --> 02:06:15.160]   Now, you might wonder why you would listen to Mr. Bean about anything, but he points
[02:06:15.160 --> 02:06:20.280]   out that he in fact got his university degree in electrical and electronic engineering and
[02:06:20.280 --> 02:06:21.920]   a master's in control system.
[02:06:21.920 --> 02:06:23.000]   So I guess I didn't know this.
[02:06:23.000 --> 02:06:26.920]   He was an engineer before he became famous for being stupid.
[02:06:26.920 --> 02:06:32.760]   That's the most after the description of Mr. Bean.
[02:06:32.760 --> 02:06:34.760]   Famous for Bean's stupid.
[02:06:34.760 --> 02:06:35.760]   Okay.
[02:06:35.760 --> 02:06:36.760]   Yeah.
[02:06:36.760 --> 02:06:37.760]   Yeah.
[02:06:37.760 --> 02:06:40.200]   He says, when you drill into the facts, electric motoring doesn't seem to be quite the
[02:06:40.200 --> 02:06:43.680]   environmental panacea, it is claimed to be now.
[02:06:43.680 --> 02:06:49.680]   We've heard this before from the gas vehicle industry that, oh, and anybody who doesn't
[02:06:49.680 --> 02:06:56.200]   like electric cars, which is most people who own ice cars, oh, you know, those emissions
[02:06:56.200 --> 02:07:02.040]   in the making of the electric cars are so high and the usage of, you know, rare earth
[02:07:02.040 --> 02:07:07.520]   elements and lithium is so bad for the environment.
[02:07:07.520 --> 02:07:09.600]   Is that true?
[02:07:09.600 --> 02:07:10.600]   Not entirely.
[02:07:10.600 --> 02:07:11.600]   It does.
[02:07:11.600 --> 02:07:16.440]   It does take more energy and there's more emissions associated with producing batteries
[02:07:16.440 --> 02:07:20.400]   and EVs than it is with internal combustion cars.
[02:07:20.400 --> 02:07:24.720]   He says Volvo released figures at greenhouse gas emissions during production of electric
[02:07:24.720 --> 02:07:29.680]   car are 70% higher than for manufacturing a petrol one.
[02:07:29.680 --> 02:07:30.680]   Is that right?
[02:07:30.680 --> 02:07:36.440]   That is, that is absolutely correct based on the way that we make batteries today, which
[02:07:36.440 --> 02:07:41.520]   means mining lithium and nickel and cobalt, you know, out of the ground and shipping
[02:07:41.520 --> 02:07:46.840]   it to China, you know, from South America or Indonesia and processing it there and shipping
[02:07:46.840 --> 02:07:51.320]   it to North to a Volvo factory in Sweden.
[02:07:51.320 --> 02:07:53.880]   So yes, that is correct.
[02:07:53.880 --> 02:07:57.400]   And so as far as it goes, but it's not the whole story.
[02:07:57.400 --> 02:08:03.360]   Once that vehicle is in use and it's not emitting anything or at least it's not directly
[02:08:03.360 --> 02:08:08.320]   emitting anything, even when you factor in power plant emissions, the crossover point
[02:08:08.320 --> 02:08:14.120]   is on average is usually somewhere around three to four years after three to four years
[02:08:14.120 --> 02:08:15.680]   in use.
[02:08:15.680 --> 02:08:21.760]   From that point on, the EV will have less lifecycle emissions over its entire use in
[02:08:21.760 --> 02:08:22.760]   the life.
[02:08:22.760 --> 02:08:23.760]   No gas.
[02:08:23.760 --> 02:08:24.760]   Right.
[02:08:24.760 --> 02:08:29.080]   Because you're not adding any or you're adding very much less in terms of power plant emissions.
[02:08:29.080 --> 02:08:35.080]   And that is taking to account like the drilling for oil, transporting oil, getting a boat
[02:08:35.080 --> 02:08:39.760]   for oil, this other thing for oil, doing all these things that have, you know, the oil
[02:08:39.760 --> 02:08:43.920]   industrial complex, all the things that are going on, that's not even taking any of that
[02:08:43.920 --> 02:08:44.920]   into account.
[02:08:44.920 --> 02:08:48.080]   Well, at the same time they're taking into account the mining of lithium.
[02:08:48.080 --> 02:08:51.840]   They're not taking into account the, you know, drilling for oil.
[02:08:51.840 --> 02:08:58.640]   And when when that battery reaches its end of life after 150, 200,000 miles, we can recycle
[02:08:58.640 --> 02:08:59.640]   that battery.
[02:08:59.640 --> 02:09:01.400]   We can't do that with oil.
[02:09:01.400 --> 02:09:06.240]   And when you recycle, when you take a lithium ion battery and you recycle it, and then you
[02:09:06.240 --> 02:09:10.400]   take those minerals instead of mining them and processing them, you can put them right
[02:09:10.400 --> 02:09:16.040]   back into new battery production at a tiny fraction of the total energy cost and emissions
[02:09:16.040 --> 02:09:18.040]   of building that new battery.
[02:09:18.040 --> 02:09:24.560]   So that 70% number is only true for the first time of the original battery being made from
[02:09:24.560 --> 02:09:26.280]   virgin materials.
[02:09:26.280 --> 02:09:28.880]   After that, those numbers start to go way down.
[02:09:28.880 --> 02:09:34.440]   So it's, it's only true as far as it goes, which is not very far.
[02:09:34.440 --> 02:09:47.920]   Mr. Bean says, Mr. Bean, Mr. Bean, Mr. Bean says, black adder says we should look at hydrogen
[02:09:47.920 --> 02:09:50.920]   molecules and synthetic fuels.
[02:09:50.920 --> 02:09:54.840]   Well, synthetic fuel are still fuels and hydrogen.
[02:09:54.840 --> 02:09:58.000]   There's no infrastructure and you still have to make hydrogen.
[02:09:58.000 --> 02:10:03.000]   Right now, the green hydrogen is a misnomer.
[02:10:03.000 --> 02:10:05.000]   The hydrogen is not green yet.
[02:10:05.000 --> 02:10:09.960]   It's like green hydrogen, but there's only a tiny amount of being made, making it by
[02:10:09.960 --> 02:10:13.200]   splitting water using renewable energy.
[02:10:13.200 --> 02:10:15.320]   Yeah, it's green hydrogen.
[02:10:15.320 --> 02:10:17.440]   There's zero emissions associated with that.
[02:10:17.440 --> 02:10:18.440]   Right.
[02:10:18.440 --> 02:10:22.240]   But, you know, there is only a tiny fraction of what we would actually need is produced
[02:10:22.240 --> 02:10:23.560]   that way today.
[02:10:23.560 --> 02:10:26.040]   Someday, hopefully that will change today.
[02:10:26.040 --> 02:10:27.360]   That's not the case.
[02:10:27.360 --> 02:10:33.280]   Formula One says that by 2026, they're going to go to synthetic fuels that they hope will
[02:10:33.280 --> 02:10:38.320]   be net, net zero impact on carbon emissions.
[02:10:38.320 --> 02:10:39.840]   Is that possible?
[02:10:39.840 --> 02:10:40.840]   Yeah.
[02:10:40.840 --> 02:10:45.520]   There's, there's work being done on, you know, so-called e-fuels or synthetic fuels.
[02:10:45.520 --> 02:10:50.760]   I feel very guilty because I love Formula One and I'm looking at it and not, not, not
[02:10:50.760 --> 02:10:54.640]   just the cars, they're all taking private jets all over the world.
[02:10:54.640 --> 02:10:55.800]   23 weeks a year.
[02:10:55.800 --> 02:10:58.120]   I mean, there's a huge carbon footprint.
[02:10:58.120 --> 02:11:00.120]   But they're getting rid of tire warmers next year, so that'll-
[02:11:00.120 --> 02:11:01.320]   Oh, that'll help it.
[02:11:01.320 --> 02:11:02.320]   Thank goodness.
[02:11:02.320 --> 02:11:03.320]   Yeah.
[02:11:03.320 --> 02:11:08.320]   The problem with those synthetic fuels, you know, they're using, they're taking CO2
[02:11:08.320 --> 02:11:09.320]   from the atmosphere.
[02:11:09.320 --> 02:11:10.320]   What are they made from?
[02:11:10.320 --> 02:11:11.320]   What are they?
[02:11:11.320 --> 02:11:16.200]   They use CO2 from the atmosphere and some other stuff and they run it through a process
[02:11:16.200 --> 02:11:20.720]   that generates a liquid hydrocarbon fuel that can be a drop-in replacement for it.
[02:11:20.720 --> 02:11:21.720]   Gasoline.
[02:11:21.720 --> 02:11:25.760]   And then when you burn it, does it put carbon back into the air?
[02:11:25.760 --> 02:11:26.760]   Yes.
[02:11:26.760 --> 02:11:27.760]   But at the same time-
[02:11:27.760 --> 02:11:29.200]   But the environment it took out of the air in the first place.
[02:11:29.200 --> 02:11:30.200]   Yeah.
[02:11:30.200 --> 02:11:33.160]   So it's effectively a net zero process.
[02:11:33.160 --> 02:11:38.440]   But it's, it's a process that has not yet been scaled up to anything that would be useful
[02:11:38.440 --> 02:11:45.000]   for, you know, the amount of fuel that we actually use for ground transportation or aviation.
[02:11:45.000 --> 02:11:51.040]   And it's also much more expensive than producing fuels from crude oil.
[02:11:51.040 --> 02:11:54.400]   Well that's fine for Formula One, but probably not for your, your Corolla.
[02:11:54.400 --> 02:11:55.400]   Yeah.
[02:11:55.400 --> 02:11:58.000]   It's great for Formula One because they're already spending billions and billions and
[02:11:58.000 --> 02:11:59.000]   billions of dollars.
[02:11:59.000 --> 02:12:00.000]   Yeah, right.
[02:12:00.000 --> 02:12:02.920]   So we can get that Netflix series every year.
[02:12:02.920 --> 02:12:06.040]   I literally ignore all of Formula One just so I can watch the Netflix series.
[02:12:06.040 --> 02:12:09.680]   I tried to watch Formula One as much more fun if you just watch the drives.
[02:12:09.680 --> 02:12:10.680]   But I was just like, you know what?
[02:12:10.680 --> 02:12:11.680]   No.
[02:12:11.680 --> 02:12:12.680]   They really wins.
[02:12:12.680 --> 02:12:17.360]   The most season, none of that matters to me.
[02:12:17.360 --> 02:12:19.000]   All my friends are always talking about Formula One.
[02:12:19.000 --> 02:12:21.000]   I'm like, la, la, la, la, la, la, la.
[02:12:21.000 --> 02:12:22.000]   Really?
[02:12:22.000 --> 02:12:23.000]   All right.
[02:12:23.000 --> 02:12:26.040]   I don't want to know who won because I want to see it on Netflix in a year.
[02:12:26.040 --> 02:12:27.040]   Exactly.
[02:12:27.040 --> 02:12:28.040]   Okay.
[02:12:28.040 --> 02:12:29.040]   That's a good policy.
[02:12:29.040 --> 02:12:30.040]   Yeah.
[02:12:30.040 --> 02:12:31.040]   Weller alert.
[02:12:31.040 --> 02:12:32.040]   It was Max.
[02:12:32.040 --> 02:12:33.040]   Max.
[02:12:33.040 --> 02:12:34.040]   Yeah.
[02:12:34.040 --> 02:12:35.040]   It's all Max.
[02:12:35.040 --> 02:12:37.480]   All right.
[02:12:37.480 --> 02:12:46.400]   I think actually I'm intrigued by the idea of making hydrogen with wind power or some of
[02:12:46.400 --> 02:12:47.920]   your
[02:12:47.920 --> 02:12:47.920]   our
[02:12:47.920 --> 02:12:48.920]   I'm a nuclear engineer.
[02:12:48.920 --> 02:12:49.920]   You can make it with nuclear power.
[02:12:49.920 --> 02:12:50.920]   Yeah.
[02:12:50.920 --> 02:12:51.920]   Yeah.
[02:12:51.920 --> 02:12:53.600]   Any source of electricity will work.
[02:12:53.600 --> 02:12:54.600]   So maybe that's it.
[02:12:54.600 --> 02:12:55.760]   Does it use a lot of electric?
[02:12:55.760 --> 02:12:57.600]   It's pretty heavy use of electricity.
[02:12:57.600 --> 02:12:59.120]   It uses a fair amount.
[02:12:59.120 --> 02:13:03.000]   But you know, I mean, if you're if you're doing it at scale, you know, if you make large
[02:13:03.000 --> 02:13:07.440]   wind farms or solar farms or nuclear plant, you can generate a lot of hydrogen.
[02:13:07.440 --> 02:13:09.600]   From water.
[02:13:09.600 --> 02:13:14.560]   And you know, the other thing, if you do it in coastal areas, you can use that nuclear
[02:13:14.560 --> 02:13:20.240]   plant to drive a desalination plant that you can then take that water and you make
[02:13:20.240 --> 02:13:21.560]   potable water.
[02:13:21.560 --> 02:13:25.600]   And you can also take some of that and split it to produce hydrogen.
[02:13:25.600 --> 02:13:29.680]   And you know, there's, you know, because we're going to need those desalination plants
[02:13:29.680 --> 02:13:30.680]   real soon.
[02:13:30.680 --> 02:13:35.200]   You want the fact that we the fact that there aren't any yet along the West coast is
[02:13:35.200 --> 02:13:36.680]   probably like remarkable to me.
[02:13:36.680 --> 02:13:38.960]   Be building those.
[02:13:38.960 --> 02:13:41.960]   And let Mr. Bean have his gas vehicle.
[02:13:41.960 --> 02:13:48.800]   Somebody in the park, somebody in the chat did make an interesting point though, about
[02:13:48.800 --> 02:13:50.400]   tire emissions.
[02:13:50.400 --> 02:13:57.240]   You know, over the last, you know, decade or so, as particularly missions from diesel
[02:13:57.240 --> 02:14:02.440]   engines, you know, the soot that used to be the biggest source of particular emissions
[02:14:02.440 --> 02:14:08.320]   has largely gone away because of particulate filters on diesel engines.
[02:14:08.320 --> 02:14:12.800]   The biggest source of particulate emissions now is tires.
[02:14:12.800 --> 02:14:18.040]   I know because I see on the Formula One racetrack, there's just tire debris all over there.
[02:14:18.040 --> 02:14:21.720]   And you get, you know, from road, you know, from regular road tires, you get a lot of airborne
[02:14:21.720 --> 02:14:22.720]   particulates.
[02:14:22.720 --> 02:14:23.720]   That's right.
[02:14:23.720 --> 02:14:26.500]   Because, you know, when your tires wear out, I mean, that stuff doesn't just magically
[02:14:26.500 --> 02:14:27.500]   vaporize.
[02:14:27.500 --> 02:14:28.500]   Yeah.
[02:14:28.500 --> 02:14:31.200]   Those little chunks of rubber, they end up floating in the air.
[02:14:31.200 --> 02:14:32.200]   And stuff, with that rubber.
[02:14:32.200 --> 02:14:33.200]   Oh, yeah.
[02:14:33.200 --> 02:14:34.200]   It's very bad for you.
[02:14:34.200 --> 02:14:35.200]   Yes.
[02:14:35.200 --> 02:14:41.120]   So we live with our companies are working on trying to reduce that, you know, and make
[02:14:41.120 --> 02:14:47.200]   tires that and be and EVs because they're heavier and also have, you know, that instantaneous
[02:14:47.200 --> 02:14:49.440]   torque, they put more stress on the tires.
[02:14:49.440 --> 02:14:53.480]   So they do EV tires do wear out faster.
[02:14:53.480 --> 02:15:00.600]   And so tire manufacturers are working on new tire formulations to try to reduce that impact.
[02:15:00.600 --> 02:15:04.160]   We live about 200 feet from highway 101.
[02:15:04.160 --> 02:15:06.040]   So that means I'm breathing that.
[02:15:06.040 --> 02:15:07.040]   Yes.
[02:15:07.040 --> 02:15:08.680]   It's not going to be the aerosol.
[02:15:08.680 --> 02:15:10.560]   We're holding these companies.
[02:15:10.560 --> 02:15:14.520]   These companies accountable for what they've been adding to the environment, which before
[02:15:14.520 --> 02:15:18.840]   we weren't really, you know, well, we're just driving, you know, javelins and chargers
[02:15:18.840 --> 02:15:23.720]   everywhere and peeling out and, you know, using leaded gasoline.
[02:15:23.720 --> 02:15:27.160]   And so over the decades, we started holding these companies accountable and they have
[02:15:27.160 --> 02:15:32.520]   to make changes in order to make the world an easier place to breathe and live.
[02:15:32.520 --> 02:15:34.600]   So I mean, it's an important point.
[02:15:34.600 --> 02:15:41.080]   The price we pay for stuff does not reflect the total cost of that stuff.
[02:15:41.080 --> 02:15:42.080]   Yeah.
[02:15:42.080 --> 02:15:43.080]   And the rest of it.
[02:15:43.080 --> 02:15:44.080]   Yeah.
[02:15:44.080 --> 02:15:49.240]   Those externalities are subsidized either by the government or by us or by our lungs.
[02:15:49.240 --> 02:15:54.200]   And that really should be part of the total cause, you know, 33 cents of gallon gasoline
[02:15:54.200 --> 02:16:01.320]   for decades in my use really cost a lot more than 33 sets of gallon in the long run.
[02:16:01.320 --> 02:16:07.240]   And if you, and if you live in, are you getting any of the smoke from Canada in New Hampshire?
[02:16:07.240 --> 02:16:08.240]   Is it?
[02:16:08.240 --> 02:16:09.240]   We did.
[02:16:09.240 --> 02:16:10.240]   We did.
[02:16:10.240 --> 02:16:11.240]   It's gone now.
[02:16:11.240 --> 02:16:12.560]   But for a while, it was actually pretty bad.
[02:16:12.560 --> 02:16:14.880]   You could, you couldn't smell it, but you could see it.
[02:16:14.880 --> 02:16:17.080]   We have that weird sort of orange hazy tattoo.
[02:16:17.080 --> 02:16:20.320]   You look to the sky for about two days.
[02:16:20.320 --> 02:16:21.320]   Um, yeah.
[02:16:21.320 --> 02:16:24.160]   And then, you know, everybody who, anybody who had any kind of breathing issue, you
[02:16:24.160 --> 02:16:25.160]   noticed it.
[02:16:25.160 --> 02:16:27.080]   So yeah, we did have that from the fires for a bit.
[02:16:27.080 --> 02:16:31.400]   That's a Tuesday, Wednesday, the air quality index around here was about around two 50.
[02:16:31.400 --> 02:16:32.400]   Oh, yeah.
[02:16:32.400 --> 02:16:34.480]   In New York, well over 400.
[02:16:34.480 --> 02:16:36.000]   That's terrible.
[02:16:36.000 --> 02:16:37.720]   Just a terrible, terrible thing.
[02:16:37.720 --> 02:16:40.840]   And I think they said it's going to continue for a while.
[02:16:40.840 --> 02:16:44.960]   Uh, cause those fires, you can often on warnings like they're like, today's bad.
[02:16:44.960 --> 02:16:47.960]   Tomorrow's not like you got to look at the weather for day to day at this point.
[02:16:47.960 --> 02:16:53.680]   And honestly, that is also the cost of 33 cents a gallon gasoline and a bunch of four
[02:16:53.680 --> 02:16:55.680]   gallon a mile.
[02:16:55.680 --> 02:16:59.280]   Gas guzzlers for decades.
[02:16:59.280 --> 02:17:00.720]   That's part of the cost.
[02:17:00.720 --> 02:17:02.200]   Mm hmm.
[02:17:02.200 --> 02:17:06.360]   And the, the, the thought process is like, well, EVs aren't going to solve it all.
[02:17:06.360 --> 02:17:08.120]   I'm like, yes, it's, it's a part.
[02:17:08.120 --> 02:17:09.520]   It's a part of a solution.
[02:17:09.520 --> 02:17:12.960]   And it's like, you know, we, we just thought that we got a lot of solving to do.
[02:17:12.960 --> 02:17:13.960]   Let's get that one.
[02:17:13.960 --> 02:17:14.960]   We got a lot of solving to do.
[02:17:14.960 --> 02:17:18.200]   We, you know, we need a, we need a more robust public transportation system.
[02:17:18.200 --> 02:17:21.560]   We need more, you know, more protected bike lanes for people to ride their bikes who
[02:17:21.560 --> 02:17:23.520]   don't have, you don't need to drive your car everywhere.
[02:17:23.520 --> 02:17:24.880]   You can have a nice bike riding.
[02:17:24.880 --> 02:17:28.000]   We want to go somewhere, you know, there's, you know, we have to change.
[02:17:28.000 --> 02:17:32.520]   We try to get rid of all the, you know, those high emission peakers on the grid, try to
[02:17:32.520 --> 02:17:36.440]   get rid of coal fires and all these things are changing, but mostly they're changing
[02:17:36.440 --> 02:17:41.840]   because of, for monetary reasons, like it's cheaper to have batteries next to a power
[02:17:41.840 --> 02:17:47.240]   plant than it is to, to, to fire up a coal burning or diesel burning peaker on, on the
[02:17:47.240 --> 02:17:48.240]   grid.
[02:17:48.240 --> 02:17:52.400]   It's not because the, you know, the, the utilities feel better about making us feel better.
[02:17:52.400 --> 02:17:54.360]   It's because, oh, it's cheaper to do this.
[02:17:54.360 --> 02:17:56.120]   It's also cleaner, but it's cheaper.
[02:17:56.120 --> 02:17:58.760]   You know, I don't care what their incentives are.
[02:17:58.760 --> 02:18:02.320]   As long as they do the right thing, please do the right thing.
[02:18:02.320 --> 02:18:05.520]   Uh, yeah, because it doesn't, it doesn't, it's not looking good.
[02:18:05.520 --> 02:18:06.920]   I got to say.
[02:18:06.920 --> 02:18:11.920]   Meanwhile, the US government wants you to believe in UFOs.
[02:18:11.920 --> 02:18:14.560]   I don't you.
[02:18:14.560 --> 02:18:19.480]   Uh, you say that as if you don't believe in you.
[02:18:19.480 --> 02:18:27.720]   I don't believe in UFOs, but there's a lot of people very excited about a alien visitors.
[02:18:27.720 --> 02:18:36.640]   Uh, apparently, uh, lately what's been going on is a former national security professional
[02:18:36.640 --> 02:18:43.080]   who was assigned to the unidentified aerial phenomenon task force for three years now
[02:18:43.080 --> 02:18:46.560]   says he's seen things.
[02:18:46.560 --> 02:18:51.600]   You believe I've seen things.
[02:18:51.600 --> 02:18:57.160]   He's seen parts of alien craft and he's seen alien bodies.
[02:18:57.160 --> 02:18:59.520]   Apparently, uh, that the government is.
[02:18:59.520 --> 02:19:00.520]   Oh, Bob Lazar.
[02:19:00.520 --> 02:19:01.520]   Are we talking about Bob Lazar?
[02:19:01.520 --> 02:19:04.280]   No, no, no, that's a, that Bob Lazar has been discredited.
[02:19:04.280 --> 02:19:05.280]   I think, right?
[02:19:05.280 --> 02:19:06.280]   Okay.
[02:19:06.280 --> 02:19:07.280]   That was, that was back in the 80s.
[02:19:07.280 --> 02:19:09.280]   I see maybe you don't believe him, but you never know.
[02:19:09.280 --> 02:19:11.280]   It was all part of the government scheme.
[02:19:11.280 --> 02:19:13.360]   Anyway, no, this is a new guy.
[02:19:13.360 --> 02:19:14.960]   Uh, Dave Groosh.
[02:19:14.960 --> 02:19:23.440]   Uh, who, uh, I don't know what he's seen, but he says he's seen, he's seen things you
[02:19:23.440 --> 02:19:24.440]   wouldn't believe.
[02:19:24.440 --> 02:19:29.840]   And this is an interesting editorial in the New York Times from a Rust-U-Tat who says,
[02:19:29.840 --> 02:19:33.720]   okay, why is this guy who is actually credible?
[02:19:33.720 --> 02:19:35.440]   He's still working in the US government.
[02:19:35.440 --> 02:19:40.080]   He's operating through national, normal national security channels, making this report.
[02:19:40.080 --> 02:19:43.600]   Why is this guy all of a sudden surfacing?
[02:19:43.600 --> 02:19:49.560]   He says, he actually thinks it's the US government doing this.
[02:19:49.560 --> 02:19:53.560]   He says there may not be alien spacecraft, but they're clearly now as a faction within
[02:19:53.560 --> 02:20:00.440]   the national security complex that wants Americans to think there might be alien spacecraft.
[02:20:00.440 --> 02:20:01.440]   Why?
[02:20:01.440 --> 02:20:02.440]   What would be?
[02:20:02.440 --> 02:20:04.400]   Well, there's a, there's a couple of reasons.
[02:20:04.400 --> 02:20:09.000]   A, um, if they do know and eventually it's going to get out, eventually someone's going
[02:20:09.000 --> 02:20:13.080]   to get, because we all have cameras on our, with us at all times.
[02:20:13.080 --> 02:20:15.560]   Eventually someone's going to get real credible evidence.
[02:20:15.560 --> 02:20:18.920]   And if we've already like accepted it, then it's fine.
[02:20:18.920 --> 02:20:24.000]   B, they're doing some crazy stuff with planes and technology.
[02:20:24.000 --> 02:20:27.000]   And it's super easy to just pretend like it was a US.
[02:20:27.000 --> 02:20:28.000]   Hey, no attention.
[02:20:28.000 --> 02:20:29.000]   That's not our vehicle.
[02:20:29.000 --> 02:20:30.000]   That's an alien.
[02:20:30.000 --> 02:20:31.000]   Must have been a U of four.
[02:20:31.000 --> 02:20:32.000]   Right.
[02:20:32.000 --> 02:20:35.240]   It's a crazy excuse for hiding all sorts of, of super secret stuff.
[02:20:35.240 --> 02:20:36.240]   It was an alien.
[02:20:36.240 --> 02:20:38.240]   That's actually, you know what it really is.
[02:20:38.240 --> 02:20:41.880]   It's all those companies doing urban air mobility craft, you know, those.
[02:20:41.880 --> 02:20:45.520]   Yeah, EV tools that are crashing.
[02:20:45.520 --> 02:20:47.880]   That's what he's actually been seeing is the crashed V-Talls.
[02:20:47.880 --> 02:20:51.400]   They don't want, they don't want to upset the investors.
[02:20:51.400 --> 02:20:57.840]   So the, the, the, the military has been collecting these, these crashes, crash vehicles and hiding
[02:20:57.840 --> 02:21:01.440]   them away so that nobody knows that these things are inherently unsafe.
[02:21:01.440 --> 02:21:08.160]   He says this is why there was all that attention to military shootdowns of balloons earlier
[02:21:08.160 --> 02:21:09.160]   this year.
[02:21:09.160 --> 02:21:11.600]   Uh, see, see.
[02:21:11.600 --> 02:21:16.320]   It also includes, according to Dutat examples of other credentialed figures like the Stanford
[02:21:16.320 --> 02:21:21.880]   pathology professor Gary Nolan, who claimed they're being handed evidence of extraterrestrial
[02:21:21.880 --> 02:21:23.960]   contact.
[02:21:23.960 --> 02:21:26.880]   Writers are being fed strange stories.
[02:21:26.880 --> 02:21:31.840]   Strange, strange stories.
[02:21:31.840 --> 02:21:40.320]   Um, now I have to say the, the, the, the mere thought that somebody would have the skills,
[02:21:40.320 --> 02:21:46.960]   the faster than speed of light vehicles, the ability to transit huge distances to come here
[02:21:46.960 --> 02:21:49.400]   and then just crash seems unlikely.
[02:21:49.400 --> 02:21:55.200]   Well, you know what they have, they had autopilot on and they're like, like, because most of
[02:21:55.200 --> 02:21:56.200]   time it's fine.
[02:21:56.200 --> 02:21:57.200]   And then it's right.
[02:21:57.200 --> 02:22:00.120]   It's like the highway driving and then we got it.
[02:22:00.120 --> 02:22:01.280]   We got to the four and five.
[02:22:01.280 --> 02:22:03.280]   And of course we crashed.
[02:22:03.280 --> 02:22:08.160]   It was the planet earth is like a, like a flock of sheep in the room.
[02:22:08.160 --> 02:22:11.480]   A giant pile of sheep, one giant sheep.
[02:22:11.480 --> 02:22:13.960]   I read Project Hail Mary while I was on vacation.
[02:22:13.960 --> 02:22:14.960]   Great book.
[02:22:14.960 --> 02:22:15.960]   Yeah.
[02:22:15.960 --> 02:22:17.520]   It's clear that you can, you can do all of that stuff.
[02:22:17.520 --> 02:22:18.720]   And they have just come here.
[02:22:18.720 --> 02:22:22.420]   I mean, we get how many times they've very nearly crashed in that book.
[02:22:22.420 --> 02:22:23.420]   That's true.
[02:22:23.420 --> 02:22:27.520]   So I think I think Lillian is entirely, no better than Mr. Bean.
[02:22:27.520 --> 02:22:32.600]   Once they get here, anything, anything, anything could happen.
[02:22:32.600 --> 02:22:38.080]   Um, my dad, um, worked for the military and he would go to area 51 occasionally to work
[02:22:38.080 --> 02:22:39.080]   on planes.
[02:22:39.080 --> 02:22:42.800]   Um, he had top secret clearance and he would not say, tell me, God damn.
[02:22:42.800 --> 02:22:43.800]   He knew.
[02:22:43.800 --> 02:22:46.200]   So I become very, I became very obsessed.
[02:22:46.200 --> 02:22:51.400]   And so in the nineties, I ended up finding a bunch of, uh, of information online, like
[02:22:51.400 --> 02:22:54.960]   this big book about how you knew that Bob was.
[02:22:54.960 --> 02:22:55.960]   So that's, yeah.
[02:22:55.960 --> 02:22:57.440]   He's part of it.
[02:22:57.440 --> 02:22:58.440]   He's part of it.
[02:22:58.440 --> 02:23:01.640]   Robbie's part of the writers being willing to fed weird science.
[02:23:01.640 --> 02:23:03.200]   So Robbie, what is you?
[02:23:03.200 --> 02:23:04.560]   You know, you've done the research.
[02:23:04.560 --> 02:23:06.160]   What's your thinking on this?
[02:23:06.160 --> 02:23:07.160]   We all have phones.
[02:23:07.160 --> 02:23:08.760]   How come we don't see anything?
[02:23:08.760 --> 02:23:14.560]   It's like Bigfoot, Yeti, all the things that we were like, Oh, well, we had a picture,
[02:23:14.560 --> 02:23:16.120]   but you know, you don't always have a phone.
[02:23:16.120 --> 02:23:18.720]   Now everyone's walk around and locked nest with phones in their pocket.
[02:23:18.720 --> 02:23:22.040]   We're all in the woods because, you know, we love the hike.
[02:23:22.040 --> 02:23:25.400]   There's a whole, you know, there's REI, there's sports basement.
[02:23:25.400 --> 02:23:28.760]   There's all these companies that are just go out in the woods and wander around.
[02:23:28.760 --> 02:23:30.680]   And we have, we have phones with us there.
[02:23:30.680 --> 02:23:33.560]   We have cameras for everything.
[02:23:33.560 --> 02:23:34.760]   And we just don't have anything.
[02:23:34.760 --> 02:23:37.240]   See, the aliens are cagey.
[02:23:37.240 --> 02:23:38.800]   Robbie was indoctrinated by his father.
[02:23:38.800 --> 02:23:40.560]   So he's clearly part of this conspiracy.
[02:23:40.560 --> 02:23:41.560]   That's true.
[02:23:41.560 --> 02:23:43.200]   Let's think about it.
[02:23:43.200 --> 02:23:48.040]   With all of the image processing that we have on our phones, do you really think that if
[02:23:48.040 --> 02:23:52.080]   we even if we did see something, then our phones would actually allow us to capture that information?
[02:23:52.080 --> 02:23:53.080]   Oh, that's another good thing.
[02:23:53.080 --> 02:23:54.080]   That's clearly been programmed.
[02:23:54.080 --> 02:23:56.080]   They have cloaking devices like Klingons.
[02:23:56.080 --> 02:23:59.240]   And the men in black guys, when you see it, they do the little pew pew pew pew.
[02:23:59.240 --> 02:24:00.240]   And that's it.
[02:24:00.240 --> 02:24:01.240]   Now poof, you don't know anything.
[02:24:01.240 --> 02:24:03.080]   You took the video, you deleted it poof.
[02:24:03.080 --> 02:24:04.080]   Now you've forgotten.
[02:24:04.080 --> 02:24:09.000]   I think the very clear evidence there is no such thing as if there were Donald Trump would
[02:24:09.000 --> 02:24:10.880]   have accidentally revealed it long.
[02:24:10.880 --> 02:24:14.000]   Yeah, you probably read this.
[02:24:14.000 --> 02:24:15.000]   That's true.
[02:24:15.000 --> 02:24:16.000]   He would have just tweeted it.
[02:24:16.000 --> 02:24:17.000]   No, the aliens.
[02:24:17.000 --> 02:24:18.000]   The audience.
[02:24:18.000 --> 02:24:19.000]   The whole redacted says it.
[02:24:19.000 --> 02:24:20.520]   It's all in Trump's bathroom.
[02:24:20.520 --> 02:24:21.520]   Yeah.
[02:24:21.520 --> 02:24:22.520]   You know that.
[02:24:22.520 --> 02:24:23.520]   All right, let's take a little break.
[02:24:23.520 --> 02:24:24.520]   We've got a few more stories.
[02:24:24.520 --> 02:24:26.000]   We can wrap it up soon.
[02:24:26.000 --> 02:24:27.400]   You guys are fantastic.
[02:24:27.400 --> 02:24:31.760]   The wheel bearings takeover has been a massive success.
[02:24:31.760 --> 02:24:35.640]   Thanks to thanks to you three, Nicole and Robbie and Sam.
[02:24:35.640 --> 02:24:38.640]   It's great to have all three of you on the show this week.
[02:24:38.640 --> 02:24:40.640]   We really appreciate it.
[02:24:40.640 --> 02:24:43.040]   Our show today brought to you by lookout.
[02:24:43.040 --> 02:24:44.200]   Look out.
[02:24:44.200 --> 02:24:46.000]   You aliens.
[02:24:46.000 --> 02:24:47.240]   You're on the 405.
[02:24:47.240 --> 02:24:49.040]   They're sheep.
[02:24:49.040 --> 02:24:53.000]   Not that kind of look at different kind of look at business has changed forever.
[02:24:53.000 --> 02:24:58.840]   Boundaries to where we work, even how we work seem to have just vanished in the haze.
[02:24:58.840 --> 02:25:02.080]   Just means your data now is always on the move.
[02:25:02.080 --> 02:25:03.240]   It could be anywhere, right?
[02:25:03.240 --> 02:25:08.280]   Whether on a device, in the cloud, across networks, down at the local coffee shop.
[02:25:08.280 --> 02:25:09.280]   Great for your workforce.
[02:25:09.280 --> 02:25:12.000]   A little bit of a challenge for your IT security.
[02:25:12.000 --> 02:25:14.120]   That's why you need lookout.
[02:25:14.120 --> 02:25:15.120]   Look out.
[02:25:15.120 --> 02:25:18.520]   Helps you control your data and free your workspace.
[02:25:18.520 --> 02:25:21.720]   Lick out gives you complete visibility into everything.
[02:25:21.720 --> 02:25:22.720]   All your data.
[02:25:22.720 --> 02:25:27.040]   So you can minimize risk from internal and external threats.
[02:25:27.040 --> 02:25:28.920]   You can ensure compliance.
[02:25:28.920 --> 02:25:34.520]   By seamlessly securing hybrid work, your organization doesn't have to give up productivity for
[02:25:34.520 --> 02:25:35.520]   security.
[02:25:35.520 --> 02:25:36.520]   Look out.
[02:25:36.520 --> 02:25:37.520]   Makes IT security a lot simpler.
[02:25:37.520 --> 02:25:41.400]   Working with multiple point solutions and legacy tools in today's environment.
[02:25:41.400 --> 02:25:42.960]   That's just too complex.
[02:25:42.960 --> 02:25:47.960]   Look out gives you a single unified platform that reduces IT complexity.
[02:25:47.960 --> 02:25:51.000]   Gives you more time to focus on whatever else comes your way.
[02:25:51.000 --> 02:25:52.100]   IT loves it.
[02:25:52.100 --> 02:25:53.440]   Your users will love it.
[02:25:53.440 --> 02:25:54.800]   You'll love the security.
[02:25:54.800 --> 02:25:59.000]   The truth is good data protection shouldn't be a cage.
[02:25:59.000 --> 02:26:03.600]   It should be a springboard so that you and your organization can leap forward into the
[02:26:03.600 --> 02:26:04.960]   future if you're making.
[02:26:04.960 --> 02:26:12.160]   Visit lookout.com today to learn how to safeguard data, secure hybrid work, reduce IT complexity.
[02:26:12.160 --> 02:26:13.160]   Look out.
[02:26:13.160 --> 02:26:14.160]   Look out.
[02:26:14.160 --> 02:26:15.160]   L-O-O-K-O-U-T.
[02:26:15.160 --> 02:26:16.160]   Look out.com.
[02:26:16.160 --> 02:26:19.840]   We thank you so much for supporting Twitch.
[02:26:19.840 --> 02:26:21.920]   You support Twitch by using that address.
[02:26:21.920 --> 02:26:25.280]   They know you saw it here.
[02:26:25.280 --> 02:26:26.520]   Look out.com.
[02:26:26.520 --> 02:26:32.880]   Now look out because we had a great week this week and I've made a little video so that
[02:26:32.880 --> 02:26:35.640]   you can enjoy all the highlights.
[02:26:35.640 --> 02:26:43.080]   It's already been a big day, but we do have one more thing.
[02:26:43.080 --> 02:26:44.080]   Say it everybody.
[02:26:44.080 --> 02:26:45.080]   Yeah.
[02:26:45.080 --> 02:26:50.080]   You're watching our live coverage of the Apple 2023 WWDC keynote.
[02:26:50.080 --> 02:26:51.080]   Look.
[02:26:51.080 --> 02:26:52.080]   What's up?
[02:26:52.080 --> 02:26:54.360]   Previously on Twitch.
[02:26:54.360 --> 02:26:56.160]   Tech News Weekly.
[02:26:56.160 --> 02:27:00.920]   What is it like to see through the Apple Vision Pro like actually on your face looking through
[02:27:00.920 --> 02:27:02.400]   it with your own eyes?
[02:27:02.400 --> 02:27:05.440]   Well, Jason Snell from Six Colors.
[02:27:05.440 --> 02:27:07.240]   He can actually tell us.
[02:27:07.240 --> 02:27:08.600]   They really nailed the interactions.
[02:27:08.600 --> 02:27:13.760]   I mean, you could tell that this is Apple, human interaction designers working for years
[02:27:13.760 --> 02:27:20.160]   to try to find the right way to get this thing to feel natural and also use kind of our tapping
[02:27:20.160 --> 02:27:23.720]   and swiping skills that we picked up over the last 15 years with the iPhone.
[02:27:23.720 --> 02:27:24.720]   All about Android.
[02:27:24.720 --> 02:27:28.120]   I've got a review of the Pixel 7A.
[02:27:28.120 --> 02:27:33.080]   The A series obviously occupies a different category of phone.
[02:27:33.080 --> 02:27:39.080]   It's not the premium top of the line, you know, flagship model.
[02:27:39.080 --> 02:27:40.840]   Like it's really close.
[02:27:40.840 --> 02:27:42.740]   It's really close to the 7.
[02:27:42.740 --> 02:27:44.440]   This week in AI, I mean Google.
[02:27:44.440 --> 02:27:49.640]   I think we need a bell that goes off on the show whenever a new member joins.
[02:27:49.640 --> 02:27:50.640]   I could do that.
[02:27:50.640 --> 02:27:52.600]   What about the punch Leo thing?
[02:27:52.600 --> 02:27:54.360]   That would be perfect.
[02:27:54.360 --> 02:27:55.960]   Just give me the signal.
[02:27:55.960 --> 02:27:56.960]   Just give me the signal.
[02:27:56.960 --> 02:27:57.960]   Oh yeah, you got it now.
[02:27:57.960 --> 02:27:58.960]   I really want the button.
[02:27:58.960 --> 02:28:03.360]   So if I have a button that vibrates like, oh, I do have a clear.
[02:28:03.360 --> 02:28:05.960]   Oh, that's pretty good.
[02:28:05.960 --> 02:28:07.840]   It's a little latent, but.
[02:28:07.840 --> 02:28:08.840]   Twit.
[02:28:08.840 --> 02:28:12.160]   I think I'm suffering some brain.
[02:28:12.160 --> 02:28:14.120]   Nice.
[02:28:14.120 --> 02:28:19.600]   We also want to thank all of our club twit members for making this show a little bit of fun.
[02:28:19.600 --> 02:28:22.920]   So it's possible in all of our shows club twit is seven bucks a month.
[02:28:22.920 --> 02:28:27.640]   You get a lot of benefits, including ad free versions of everything we do.
[02:28:27.640 --> 02:28:32.720]   You wouldn't even hear this ad for club twit in the club twit feed and shows we don't
[02:28:32.720 --> 02:28:37.400]   put out anywhere else like home theater geeks with Scott Wilkinson hands on Mac with Michael
[02:28:37.400 --> 02:28:38.400]   Sergeant.
[02:28:38.400 --> 02:28:41.240]   There's some great shows just for the club.
[02:28:41.240 --> 02:28:43.040]   We use the club to launch new programming.
[02:28:43.040 --> 02:28:48.480]   That's where this week in space came from because club members subsidize it.
[02:28:48.480 --> 02:28:51.160]   They help us do this stuff on the air.
[02:28:51.160 --> 02:28:55.360]   So if you're not a member of club twit, you want to get ad free versions of the shows.
[02:28:55.360 --> 02:28:56.520]   You want to see those other shows.
[02:28:56.520 --> 02:29:00.480]   Oh, and by the way, you want to get in the discord, which is a wonderful hang.
[02:29:00.480 --> 02:29:06.840]   It is it is the future of social twit.tv/clubtwit seven bucks a month, $84 a year.
[02:29:06.840 --> 02:29:08.280]   Tell your spouse.
[02:29:08.280 --> 02:29:09.280]   We don't want to.
[02:29:09.280 --> 02:29:10.800]   We don't need chargebacks.
[02:29:10.800 --> 02:29:13.760]   We got a couple of chargebacks.
[02:29:13.760 --> 02:29:20.240]   I think almost all of our chargebacks come from geeks who bought a year long subscription
[02:29:20.240 --> 02:29:26.200]   and then their wives or husbands their spouses noticed this and said, what's this?
[02:29:26.200 --> 02:29:28.480]   And said, that's fraudulent.
[02:29:28.480 --> 02:29:30.040]   Now we have to pay them back.
[02:29:30.040 --> 02:29:31.040]   Come please.
[02:29:31.040 --> 02:29:33.760]   Does that happen on your patreon?
[02:29:33.760 --> 02:29:36.400]   Does that ever happen to you guys?
[02:29:36.400 --> 02:29:41.480]   That must be a unique thing that's just us.
[02:29:41.480 --> 02:29:44.480]   I don't know why that is and chargebacks.
[02:29:44.480 --> 02:29:45.640]   You know this are terrible.
[02:29:45.640 --> 02:29:51.280]   I mean, all of a sudden at some point, Stripe is going to say you can't use this anymore.
[02:29:51.280 --> 02:29:53.640]   So please tell your spouse.
[02:29:53.640 --> 02:29:59.720]   Okay, that's a coin base and Binance getting cracked out.
[02:29:59.720 --> 02:30:01.920]   Is it over for crypto?
[02:30:01.920 --> 02:30:02.920]   A coin base.
[02:30:02.920 --> 02:30:06.920]   No, never going to die.
[02:30:06.920 --> 02:30:08.840]   Never going away ever ever.
[02:30:08.840 --> 02:30:10.040]   It's going to be around forever.
[02:30:10.040 --> 02:30:11.040]   It's the more thing.
[02:30:11.040 --> 02:30:12.680]   It's a religion now.
[02:30:12.680 --> 02:30:19.160]   The security exchange commission says Coinbase and Binance are unregistered security exchanges
[02:30:19.160 --> 02:30:22.320]   that crypto is a security.
[02:30:22.320 --> 02:30:28.600]   And Coinbase said, well, you should have told us that the rules weren't clear.
[02:30:28.600 --> 02:30:35.720]   We like many other crypto entities, they've been asking for regulation, asking for clarity.
[02:30:35.720 --> 02:30:40.680]   Paul Greewall, Coinbase's chief legal officer, said the solutions legislation that allows
[02:30:40.680 --> 02:30:47.800]   fair rules for the road to be developed transparently and applied equally, not litigation.
[02:30:47.800 --> 02:30:58.440]   So SEC is now sued Binance, the world's largest crypto trading platform and now coin base.
[02:30:58.440 --> 02:31:02.720]   Oh, I don't think it's the SEC that should be regulated in crypto, but the Nevada Gaming
[02:31:02.720 --> 02:31:03.720]   Commission.
[02:31:03.720 --> 02:31:04.720]   Yeah.
[02:31:04.720 --> 02:31:07.360]   It's kind of a gamble.
[02:31:07.360 --> 02:31:08.960]   Is that what you're saying?
[02:31:08.960 --> 02:31:10.880]   Yeah, a little.
[02:31:10.880 --> 02:31:12.160]   And the house always wins.
[02:31:12.160 --> 02:31:13.880]   It does seem to fall in between the cracks.
[02:31:13.880 --> 02:31:15.040]   Is it money?
[02:31:15.040 --> 02:31:18.000]   Is it speculation?
[02:31:18.000 --> 02:31:19.480]   Is it security?
[02:31:19.480 --> 02:31:21.360]   I don't it is.
[02:31:21.360 --> 02:31:23.320]   It's something new that doesn't exist.
[02:31:23.320 --> 02:31:25.680]   They've never existed before.
[02:31:25.680 --> 02:31:30.440]   In any event, Robin Hood has announced they're going to stop letting you buy crypto at the
[02:31:30.440 --> 02:31:32.480]   end of the month.
[02:31:32.480 --> 02:31:34.600]   I wonder if it's the end of the line for crypto.
[02:31:34.600 --> 02:31:36.480]   No, I don't think it's going to keep going.
[02:31:36.480 --> 02:31:37.680]   I think it's just going to hang on there.
[02:31:37.680 --> 02:31:38.680]   It's going to keep changing.
[02:31:38.680 --> 02:31:39.680]   Never going away.
[02:31:39.680 --> 02:31:42.640]   The SEC is going to sue one guy and then another guy is going to come up and they're
[02:31:42.640 --> 02:31:44.480]   going to have to like whack a mole.
[02:31:44.480 --> 02:31:45.880]   Yeah, like whack a mole.
[02:31:45.880 --> 02:31:48.680]   And then the next guy, pop, pop, pop, and they're going to keep you out going after
[02:31:48.680 --> 02:31:49.680]   them.
[02:31:49.680 --> 02:31:59.320]   It is 10 years since Edward Snowden and his revelations changed our world.
[02:31:59.320 --> 02:32:03.760]   Snowden says, you know, thanks to me, end to end to end encryption is everywhere.
[02:32:03.760 --> 02:32:13.320]   We now understand what the governments are learning about us and we are more aware of
[02:32:13.320 --> 02:32:15.040]   privacy.
[02:32:15.040 --> 02:32:22.480]   I also think it's a little weird that he is now a Russian citizen.
[02:32:22.480 --> 02:32:26.560]   He's been living in Moscow for the past 10 years, but that's mostly because the US wouldn't
[02:32:26.560 --> 02:32:27.840]   let him live anywhere else.
[02:32:27.840 --> 02:32:28.840]   He wasn't Hong Kong.
[02:32:28.840 --> 02:32:30.720]   They chased him out of Hong Kong.
[02:32:30.720 --> 02:32:35.200]   He had planned to go to Ecuador until he was told, you can't go there.
[02:32:35.200 --> 02:32:36.360]   So now he's a Russian citizen.
[02:32:36.360 --> 02:32:42.960]   The good news is you can't be extradited if you're a Russian citizen.
[02:32:42.960 --> 02:32:46.040]   I am so up in the air on this one.
[02:32:46.040 --> 02:32:48.280]   I just, I don't.
[02:32:48.280 --> 02:32:52.720]   Yeah, I think it's a saying like, on one hand, you're like, okay, he brought a lot of horrible
[02:32:52.720 --> 02:32:54.520]   things that are going on to light.
[02:32:54.520 --> 02:32:59.280]   And he did, you know, he did for the public to understand privacy and encryption is a
[02:32:59.280 --> 02:33:00.280]   huge deal.
[02:33:00.280 --> 02:33:05.280]   But at the same time, he jeopardized national security.
[02:33:05.280 --> 02:33:07.320]   Keith Alexander, who was an NSA director.
[02:33:07.320 --> 02:33:11.040]   Well, he also trusted Glenn Greenwald, which is another mistake.
[02:33:11.040 --> 02:33:12.040]   Another mistake.
[02:33:12.040 --> 02:33:14.120]   And that right there is the biggest mistake you made.
[02:33:14.120 --> 02:33:19.720]   It wasn't like that it was like, I'm going to trust the biggest idiot in journalists.
[02:33:19.720 --> 02:33:27.320]   I think what the way Snowden did it, you know, I think his intentions were good, you know,
[02:33:27.320 --> 02:33:31.360]   and you know, trying to pick somebody to work with and make sure everything stayed encrypted
[02:33:31.360 --> 02:33:36.320]   and, you know, review everything and not just like WikiLeaks just published the whole thing.
[02:33:36.320 --> 02:33:37.560]   You know, he tried to do it.
[02:33:37.560 --> 02:33:40.080]   No, he went to a bunch of journalists.
[02:33:40.080 --> 02:33:42.440]   He let them vet the information.
[02:33:42.440 --> 02:33:43.440]   Right.
[02:33:43.440 --> 02:33:45.480]   And do it in a, try to do it in a responsible way.
[02:33:45.480 --> 02:33:48.040]   He said I went to Robbie's point, Glenn Greenwald.
[02:33:48.040 --> 02:33:49.040]   Right.
[02:33:49.040 --> 02:33:52.680]   Well, but you know, at the time we might not have known, you know, that Glenn was what
[02:33:52.680 --> 02:33:54.120]   he was to become.
[02:33:54.120 --> 02:34:01.560]   But honestly, he says, Snowden says, I tried, whistleblowing.
[02:34:01.560 --> 02:34:02.560]   It didn't work.
[02:34:02.560 --> 02:34:03.560]   They wouldn't listen to me.
[02:34:03.560 --> 02:34:05.400]   I had to do this.
[02:34:05.400 --> 02:34:10.040]   And certainly we've learned a lot from him about, you know, NSL scooping up everyone's
[02:34:10.040 --> 02:34:19.080]   records in, in 2015, Congress wrote the USA Freedom Act, which made that illegal.
[02:34:19.080 --> 02:34:20.120]   Rightly so.
[02:34:20.120 --> 02:34:24.640]   So there, there've been some shifts and benefits.
[02:34:24.640 --> 02:34:31.960]   This is terrible, but I feel like he should have done what reality winner did, what Chelsea
[02:34:31.960 --> 02:34:34.600]   did, Chelsea Manning.
[02:34:34.600 --> 02:34:40.360]   He should have done what he did and then stood up and, and, and taking the charges.
[02:34:40.360 --> 02:34:42.360]   But in response, you know, said, I'm responsible.
[02:34:42.360 --> 02:34:44.400]   Look, I think this is important.
[02:34:44.400 --> 02:34:45.400]   I will go to court.
[02:34:45.400 --> 02:34:46.400]   I will, I will be tried.
[02:34:46.400 --> 02:34:49.480]   And if you put me in jail, you put me in jail going to Russia.
[02:34:49.480 --> 02:34:51.120]   It's a little bit.
[02:34:51.120 --> 02:34:52.120]   Yeah, it does.
[02:34:52.120 --> 02:34:56.080]   It taints it a lot because, you know, he, he can't say any, you know, how, how do you
[02:34:56.080 --> 02:34:58.480]   feel about the Ukraine war, Edwards, no one?
[02:34:58.480 --> 02:35:03.240]   You're never going to hear about that because he says I'm, he says according to the, to
[02:35:03.240 --> 02:35:04.240]   NPR.
[02:35:04.240 --> 02:35:08.040]   I'm not criticizing the Russian government's policy, the Russian government's human rights
[02:35:08.040 --> 02:35:11.200]   record, even the Russian president by name.
[02:35:11.200 --> 02:35:13.040]   I think he's not doing it really loudly.
[02:35:13.040 --> 02:35:14.040]   I think he's criticizing.
[02:35:14.040 --> 02:35:15.040]   Yeah.
[02:35:15.040 --> 02:35:16.040]   He's criticizing.
[02:35:16.040 --> 02:35:17.040]   Yeah.
[02:35:17.040 --> 02:35:18.040]   He's criticizing.
[02:35:18.040 --> 02:35:19.040]   Yeah.
[02:35:19.040 --> 02:35:20.040]   He's criticizing.
[02:35:20.040 --> 02:35:21.040]   Yeah.
[02:35:21.040 --> 02:35:22.040]   He's criticizing.
[02:35:22.040 --> 02:35:23.040]   He's criticizing the Russian government's policy, the Russian government's human rights record,
[02:35:23.040 --> 02:35:24.040]   even the Russian president by name.
[02:35:24.040 --> 02:35:25.040]   I think he's not doing it really loudly.
[02:35:25.040 --> 02:35:26.040]   I think he's criticizing.
[02:35:26.040 --> 02:35:27.040]   Yeah.
[02:35:27.040 --> 02:35:28.040]   He's criticizing.
[02:35:28.040 --> 02:35:29.040]   Yeah.
[02:35:29.040 --> 02:35:30.040]   He's criticizing.
[02:35:30.040 --> 02:35:31.040]   Yeah.
[02:35:31.040 --> 02:35:32.040]   He's criticizing.
[02:35:32.040 --> 02:35:33.040]   Yeah.
[02:35:33.040 --> 02:35:34.040]   He's criticizing.
[02:35:34.040 --> 02:35:38.740]   I mean, the thing that happens to happen a lot in Russia, yeah, then yeah, I understand,
[02:35:38.740 --> 02:35:40.040]   but it also, it's a better railings.
[02:35:40.040 --> 02:35:41.040]   Sir, I don't know.
[02:35:41.040 --> 02:35:42.440]   I need better railings, better windows.
[02:35:42.440 --> 02:35:46.540]   I don't know what the situation is with Russia and windows, but the people just falling
[02:35:46.540 --> 02:35:50.840]   out of them and they always seem to be people who Putin are angry with.
[02:35:50.840 --> 02:35:53.240]   Maybe they're just so sad because Putin is not happy with them.
[02:35:53.240 --> 02:35:56.240]   They're just leaning on the windows, smoking a cigarette.
[02:35:56.240 --> 02:36:00.640]   Oh, who put play a tonne, I mean my tea.
[02:36:00.640 --> 02:36:03.040]   Yeah, what?
[02:36:03.040 --> 02:36:04.040]   It's crazy.
[02:36:04.040 --> 02:36:09.240]   How did people, how did I get poisoned just because I was critical of the president?
[02:36:09.240 --> 02:36:14.760]   I actually like how quippy, quint in our discord chat put it.
[02:36:14.760 --> 02:36:18.040]   He did the right thing in the wrong way.
[02:36:18.040 --> 02:36:19.040]   Yeah.
[02:36:19.040 --> 02:36:20.040]   That's kind of how I feel.
[02:36:20.040 --> 02:36:21.040]   Yeah.
[02:36:21.040 --> 02:36:22.840]   I think a lot of people feel that way.
[02:36:22.840 --> 02:36:25.720]   He was trying to do a good thing, but he just did a good thing bad.
[02:36:25.720 --> 02:36:26.920]   He is still charged.
[02:36:26.920 --> 02:36:29.760]   If he were to come back, he would face charges.
[02:36:29.760 --> 02:36:32.240]   He's got a family and children now in Russia.
[02:36:32.240 --> 02:36:34.240]   He's not coming back.
[02:36:34.240 --> 02:36:35.240]   He's not coming back.
[02:36:35.240 --> 02:36:36.240]   He's not coming back.
[02:36:36.240 --> 02:36:38.560]   I'm grateful to him for what he did.
[02:36:38.560 --> 02:36:39.560]   I really am.
[02:36:39.560 --> 02:36:41.160]   I think it was important.
[02:36:41.160 --> 02:36:42.160]   Yeah.
[02:36:42.160 --> 02:36:43.160]   I don't know.
[02:36:43.160 --> 02:36:52.520]   I think if you're going to do something so honorable, so important, it's hard, but you
[02:36:52.520 --> 02:36:55.680]   got to stand up and take the face.
[02:36:55.680 --> 02:36:58.080]   Don't do the crime if you can't do the time in the words.
[02:36:58.080 --> 02:36:59.080]   You have the courage.
[02:36:59.080 --> 02:37:00.080]   You've been the crime in the words.
[02:37:00.080 --> 02:37:01.080]   You've been the crime in the words.
[02:37:01.080 --> 02:37:03.720]   If you're going to do that and you're going to go out there and you're going to do something
[02:37:03.720 --> 02:37:07.200]   you know as iffy for a good reason, then I go, "Okay, I believe in it so much.
[02:37:07.200 --> 02:37:10.840]   I will take the heat for whatever I have done in the interest of getting this information
[02:37:10.840 --> 02:37:11.840]   out there."
[02:37:11.840 --> 02:37:14.960]   And then the trial, it's just even in discovery for the trial.
[02:37:14.960 --> 02:37:19.160]   They would have been able to uncover more things that had been going on.
[02:37:19.160 --> 02:37:24.840]   There's a lot of, and even if it gets convicted, there's going to be, there'll always be people
[02:37:24.840 --> 02:37:27.200]   who are like, "Oh, well, what he did is just wrong.
[02:37:27.200 --> 02:37:28.200]   Top to bottom."
[02:37:28.200 --> 02:37:33.760]   All right, but I think a majority of people understand what he did and what that means
[02:37:33.760 --> 02:37:38.720]   for us, privacy and encryption wise, was a benefit.
[02:37:38.720 --> 02:37:42.400]   And I think at some point a president would be like, "You know what?
[02:37:42.400 --> 02:37:44.440]   Just go home and wherever you're from."
[02:37:44.440 --> 02:37:45.440]   I don't know where that's going.
[02:37:45.440 --> 02:37:46.440]   I don't know where it's going.
[02:37:46.440 --> 02:37:47.440]   Chelsea Manning, right?
[02:37:47.440 --> 02:37:48.440]   Yeah.
[02:37:48.440 --> 02:37:50.440]   Obama commuted and I heard something.
[02:37:50.440 --> 02:37:51.440]   Yeah, I understand.
[02:37:51.440 --> 02:37:53.240]   You're like, "You did a bad thing."
[02:37:53.240 --> 02:37:55.560]   You did a bad thing for a good reason.
[02:37:55.560 --> 02:37:56.560]   For a good reason.
[02:37:56.560 --> 02:37:57.560]   Exactly.
[02:37:57.560 --> 02:37:58.560]   And I think it's others.
[02:37:58.560 --> 02:38:00.640]   So in the country in general.
[02:38:00.640 --> 02:38:04.600]   Anyway, hey, I'm so glad you guys were here.
[02:38:04.600 --> 02:38:08.880]   What a great time to spend some time with a wheel bearings crew.
[02:38:08.880 --> 02:38:10.960]   Sam suggested this and I was glad you did.
[02:38:10.960 --> 02:38:16.560]   We've done some takeovers with other podcasts and it's really fun because you have a relationship.
[02:38:16.560 --> 02:38:21.840]   You work well together and I'm glad you could let me be part of that team.
[02:38:21.840 --> 02:38:22.840]   Thank you.
[02:38:22.840 --> 02:38:23.840]   It was fun.
[02:38:23.840 --> 02:38:24.840]   Thank you.
[02:38:24.840 --> 02:38:25.840]   This was fun.
[02:38:25.840 --> 02:38:32.080]   The wheel bearings, mostly you talk about the cars you're driving, right?
[02:38:32.080 --> 02:38:37.640]   We also talk about some of the transportation news of the week.
[02:38:37.640 --> 02:38:44.800]   We do interviews with people in the industry from time to time while we're on vacation.
[02:38:44.800 --> 02:38:49.320]   A couple of weeks back, we actually published a whole episode that was just interviews that
[02:38:49.320 --> 02:38:50.880]   we did at the New York Auto Show.
[02:38:50.880 --> 02:38:52.440]   I listened to that one.
[02:38:52.440 --> 02:38:55.320]   With executives from a bunch of different companies.
[02:38:55.320 --> 02:38:56.320]   Yeah.
[02:38:56.320 --> 02:38:58.920]   And we answered listener questions as well.
[02:38:58.920 --> 02:39:04.560]   So if you want to send us questions about what you should buy or if you have comments
[02:39:04.560 --> 02:39:11.840]   about some topic related to vehicles, feedback at wheel bearings.media, you can send it there.
[02:39:11.840 --> 02:39:14.680]   We've got a Discord as well.
[02:39:14.680 --> 02:39:18.440]   We welcome the input from listeners.
[02:39:18.440 --> 02:39:21.920]   And they talk about cars and they talk about how cars hold cookies because I like cookies.
[02:39:21.920 --> 02:39:25.840]   So there's always an element of where the best place to store cookies are in a car because
[02:39:25.840 --> 02:39:26.840]   treats are important.
[02:39:26.840 --> 02:39:31.440]   It is interesting how for so many years cars didn't have cup holders.
[02:39:31.440 --> 02:39:32.440]   Then they had dozens.
[02:39:32.440 --> 02:39:33.440]   No, see?
[02:39:33.440 --> 02:39:34.440]   Yeah.
[02:39:34.440 --> 02:39:35.440]   These are important things.
[02:39:35.440 --> 02:39:38.280]   You have to, you have to talk about the stuff, real people want to, I don't care about
[02:39:38.280 --> 02:39:39.280]   the horsepower and the torque.
[02:39:39.280 --> 02:39:41.280]   Like where am I going to put my coffee?
[02:39:41.280 --> 02:39:43.320]   Perkini does not have a cup holder.
[02:39:43.320 --> 02:39:44.320]   What?
[02:39:44.320 --> 02:39:45.320]   Right.
[02:39:45.320 --> 02:39:46.320]   It does not have the Lamborghini does not have a cup holder.
[02:39:46.320 --> 02:39:47.320]   Does it have a cookie holder?
[02:39:47.320 --> 02:39:48.320]   It's home for your phone.
[02:39:48.320 --> 02:39:49.320]   Okay.
[02:39:49.320 --> 02:39:50.720]   There's room for maybe another phone.
[02:39:50.720 --> 02:39:51.720]   And that's it.
[02:39:51.720 --> 02:39:52.720]   Really?
[02:39:52.720 --> 02:39:53.720]   That's it.
[02:39:53.720 --> 02:39:54.720]   It is just, yeah, that's it.
[02:39:54.720 --> 02:39:59.560]   Or you can put something in the glove compartment, but the little shelf behind you, there's a fire
[02:39:59.560 --> 02:40:03.320]   extinguisher because you know you're in a car.
[02:40:03.320 --> 02:40:04.920]   So yeah, there's like, yeah.
[02:40:04.920 --> 02:40:08.480]   I think every car should have a fire extinguisher just to remind you.
[02:40:08.480 --> 02:40:10.040]   That's actually not a bad idea.
[02:40:10.040 --> 02:40:11.040]   Just in case.
[02:40:11.040 --> 02:40:12.800]   You never know what could happen.
[02:40:12.800 --> 02:40:13.800]   Wow.
[02:40:13.800 --> 02:40:15.200]   Important to be safe.
[02:40:15.200 --> 02:40:18.640]   It's an interesting statement by Lamborghini.
[02:40:18.640 --> 02:40:19.640]   You never know what's going to happen.
[02:40:19.640 --> 02:40:20.640]   Where's you going on a track?
[02:40:20.640 --> 02:40:23.360]   If you're going on a track, you have to have a fire extinguisher anyway.
[02:40:23.360 --> 02:40:24.360]   It's a race car.
[02:40:24.360 --> 02:40:27.560]   You have a race car and you're driving on the street with it.
[02:40:27.560 --> 02:40:29.320]   What could possibly go wrong?
[02:40:29.320 --> 02:40:30.400]   I'm more worried about the cookies.
[02:40:30.400 --> 02:40:31.400]   The car can catch fire.
[02:40:31.400 --> 02:40:32.400]   I want to spot for my cookies.
[02:40:32.400 --> 02:40:34.240]   Where do you put your cookies?
[02:40:34.240 --> 02:40:35.600]   It depends on the car.
[02:40:35.600 --> 02:40:37.240]   Sometimes you have a little spot on the center console.
[02:40:37.240 --> 02:40:42.440]   They have this whole table in the F-150 that like flips out and you can like fit like
[02:40:42.440 --> 02:40:43.440]   the car.
[02:40:43.440 --> 02:40:44.640]   F-150 you can get a kitchen built in, right?
[02:40:44.640 --> 02:40:45.640]   Yeah.
[02:40:45.640 --> 02:40:46.640]   Well, that's what I want.
[02:40:46.640 --> 02:40:48.320]   You have like, you can put, I did a video of it.
[02:40:48.320 --> 02:40:51.840]   I had it on, I have a site, The Road Reflected and I do another podcast and I did a whole
[02:40:51.840 --> 02:40:56.520]   thing about the cookie table that Ford calls a work table and it's a misnomer.
[02:40:56.520 --> 02:40:57.520]   It's a cookie table.
[02:40:57.520 --> 02:40:58.520]   It's a burrito table.
[02:40:58.520 --> 02:41:00.920]   It's a perfect four box of crumble cookies.
[02:41:00.920 --> 02:41:01.920]   It is.
[02:41:01.920 --> 02:41:03.120]   It holds a box of crumble cookies.
[02:41:03.120 --> 02:41:04.120]   These are cookies.
[02:41:04.120 --> 02:41:05.120]   These are cookies.
[02:41:05.120 --> 02:41:06.120]   West Coast Grumps.
[02:41:06.120 --> 02:41:07.120]   Yeah.
[02:41:07.120 --> 02:41:08.920]   That's how that's how it breaks down.
[02:41:08.920 --> 02:41:12.160]   Like somewhere, I guess in Colorado, it probably is where the split is.
[02:41:12.160 --> 02:41:14.920]   Do you find that the cookie taco split is?
[02:41:14.920 --> 02:41:17.840]   Is it more expensive the vehicle?
[02:41:17.840 --> 02:41:21.920]   The more likely it will have a cookie table or is it the other way around?
[02:41:21.920 --> 02:41:24.160]   More expensive vehicles have more storage spots.
[02:41:24.160 --> 02:41:28.760]   They do like on things like tables and like little nooks and crannies and little shelves
[02:41:28.760 --> 02:41:30.800]   and things where you can put cookies.
[02:41:30.800 --> 02:41:34.960]   Every single episode of The Road Reflected has food in the title.
[02:41:34.960 --> 02:41:35.960]   It does.
[02:41:35.960 --> 02:41:36.960]   There's always something.
[02:41:36.960 --> 02:41:38.600]   Turkish food or some game cookies donuts.
[02:41:38.600 --> 02:41:39.600]   There's always.
[02:41:39.600 --> 02:41:40.600]   It's like car food.
[02:41:40.600 --> 02:41:41.600]   Can you put pie?
[02:41:41.600 --> 02:41:42.600]   Yeah.
[02:41:42.600 --> 02:41:45.200]   So is it a car podcast or a food podcast?
[02:41:45.200 --> 02:41:47.440]   It's a car podcast but at the end there's a treat.
[02:41:47.440 --> 02:41:52.240]   At the end there's a lot of food because everyone wants to write off all of her treats.
[02:41:52.240 --> 02:41:53.240]   This is what she wants.
[02:41:53.240 --> 02:41:55.560]   She wants to try you right off for all of her snacking.
[02:41:55.560 --> 02:41:56.560]   This is a very last fall.
[02:41:56.560 --> 02:41:57.560]   This is very last fall.
[02:41:57.560 --> 02:41:59.600]   Very high concept podcast.
[02:41:59.600 --> 02:42:00.600]   It is.
[02:42:00.600 --> 02:42:04.360]   When food is importantly, you're lying.
[02:42:04.360 --> 02:42:07.760]   If you don't say you think about the food you take on your road trip and you do.
[02:42:07.760 --> 02:42:11.440]   I think that at all the time last fall we went to Montana to drive the Jeep Grand Ragon
[02:42:11.440 --> 02:42:12.440]   Ear L.
[02:42:12.440 --> 02:42:13.440]   Yes.
[02:42:13.440 --> 02:42:19.360]   And we drove out the drive route to a place where we stopped for lunch and on the way
[02:42:19.360 --> 02:42:25.840]   back we grabbed Jim Morrison who's the head of not the one from the doors but he's the
[02:42:25.840 --> 02:42:29.040]   head of Jeep North America.
[02:42:29.040 --> 02:42:35.360]   Because we were doing an interview with him in the car and the SUV while we were driving.
[02:42:35.360 --> 02:42:39.760]   And of course rather than going straight back to the hotel like we were supposed to,
[02:42:39.760 --> 02:42:46.240]   we did a little diversion.
[02:42:46.240 --> 02:43:05.240]   And then at the New York Auto Show I was interviewing Jim and Christian Munier who is the head of
[02:43:05.240 --> 02:43:08.720]   Jeep Global, the CEO of the Jeep brand.
[02:43:08.720 --> 02:43:11.320]   And Nicole, we had a scheduling conflict.
[02:43:11.320 --> 02:43:15.680]   So Nicole was interviewing somebody else at the same time and they said, "Where's Nicole?"
[02:43:15.680 --> 02:43:17.080]   And Jim said, "Where's Nicole?"
[02:43:17.080 --> 02:43:18.880]   He said, "I've got cookies for her."
[02:43:18.880 --> 02:43:19.880]   Oh my God.
[02:43:19.880 --> 02:43:21.880]   Do you have to go find Jim later in?
[02:43:21.880 --> 02:43:22.880]   He actually had cookies for us.
[02:43:22.880 --> 02:43:23.880]   He had a box of cookies.
[02:43:23.880 --> 02:43:26.320]   He brought them over to me and boxed a really yummy cookie.
[02:43:26.320 --> 02:43:27.320]   That's a good reputation.
[02:43:27.320 --> 02:43:28.320]   I like this reputation.
[02:43:28.320 --> 02:43:33.440]   Are you so far north of New Hampshire that you're close to the Canadian border?
[02:43:33.440 --> 02:43:34.440]   Not super close.
[02:43:34.440 --> 02:43:37.040]   I'm thinking about five hours from Montreal.
[02:43:37.040 --> 02:43:39.040]   That's quite a drive.
[02:43:39.040 --> 02:43:42.280]   Close enough to probably Canadian pork pie?
[02:43:42.280 --> 02:43:48.720]   Yeah, because there's all sorts of French Canadians in Nashua, in the town that's near
[02:43:48.720 --> 02:43:49.720]   me.
[02:43:49.720 --> 02:43:54.440]   So New Hampshire has lots of very large Canadian population and all the, what do they always
[02:43:54.440 --> 02:43:55.440]   call them, the Mares?
[02:43:55.440 --> 02:43:56.760]   They're grandmothers.
[02:43:56.760 --> 02:43:58.640]   They always make Canadian pork pie.
[02:43:58.640 --> 02:44:00.480]   And you can get it at some places.
[02:44:00.480 --> 02:44:02.280]   It's good stuff if you never had it.
[02:44:02.280 --> 02:44:04.080]   I'm suddenly really, really good.
[02:44:04.080 --> 02:44:07.120]   I don't know if you noticed, but my name is Leo La Part.
[02:44:07.120 --> 02:44:09.880]   I am French Canadians from Montreal.
[02:44:09.880 --> 02:44:10.880]   Well, I feel...
[02:44:10.880 --> 02:44:15.640]   And I grew up in Rhode Island, which was, there were 21 Leo La Portes in the phone book when
[02:44:15.640 --> 02:44:16.880]   I was a kid.
[02:44:16.880 --> 02:44:19.200]   It's a very big place for Canucks.
[02:44:19.200 --> 02:44:20.200]   Okay.
[02:44:20.200 --> 02:44:23.920]   And I am one, I are one, but I've never had Canadian pork pie.
[02:44:23.920 --> 02:44:27.600]   So now I'm feeling like my national heritage requires...
[02:44:27.600 --> 02:44:29.680]   I like my local bakery has them.
[02:44:29.680 --> 02:44:31.680]   Like you can get them in the bakery in town.
[02:44:31.680 --> 02:44:33.680]   They have that you can still in the local place.
[02:44:33.680 --> 02:44:34.680]   I don't know.
[02:44:34.680 --> 02:44:36.680]   They probably use back bacon.
[02:44:36.680 --> 02:44:38.680]   Oh, there you go.
[02:44:38.680 --> 02:44:40.480]   It's not Canadian bacon.
[02:44:40.480 --> 02:44:41.480]   It's back bacon.
[02:44:41.480 --> 02:44:42.480]   Back bacon.
[02:44:42.480 --> 02:44:43.480]   It's blessed by a mountain.
[02:44:43.480 --> 02:44:44.480]   I don't know what that says.
[02:44:44.480 --> 02:44:45.480]   I always call it.
[02:44:45.480 --> 02:44:46.480]   They call it Canadian pork pie.
[02:44:46.480 --> 02:44:47.480]   And you find it on the menu.
[02:44:47.480 --> 02:44:50.600]   See, I buy any car that had a Canadian pork pie hatch.
[02:44:50.600 --> 02:44:51.600]   That would be good.
[02:44:51.600 --> 02:44:53.600]   What's in there?
[02:44:53.600 --> 02:44:54.600]   Pork pie.
[02:44:54.600 --> 02:44:55.600]   Oh boy.
[02:44:55.600 --> 02:44:56.600]   I find that in a lot of pie.
[02:44:56.600 --> 02:44:58.680]   Yeah, that would work.
[02:44:58.680 --> 02:45:01.480]   Robbie, I haven't seen you in so long.
[02:45:01.480 --> 02:45:07.560]   Roberto Baldwin writes about cars for a variety of publications, but better than that, if
[02:45:07.560 --> 02:45:12.320]   you're in the East Bay area or anywhere in the Bay area and you get a chance to see Robbie
[02:45:12.320 --> 02:45:20.640]   performing is either robots are real or what are some of the other band names?
[02:45:20.640 --> 02:45:22.200]   Let's get all the band names out here.
[02:45:22.200 --> 02:45:23.640]   So there's robots after all.
[02:45:23.640 --> 02:45:24.640]   That's the deaf-pump.
[02:45:24.640 --> 02:45:25.640]   After all.
[02:45:25.640 --> 02:45:27.000]   As opposed to humans after all, which is...
[02:45:27.000 --> 02:45:28.000]   Yeah.
[02:45:28.000 --> 02:45:29.000]   Yeah.
[02:45:29.000 --> 02:45:33.200]   And there's suburban robots, which is the Divo band.
[02:45:33.200 --> 02:45:34.800]   Oh, they're all robots.
[02:45:34.800 --> 02:45:36.080]   Oh, okay.
[02:45:36.080 --> 02:45:41.360]   There's North American Scum, which is the LCD sound system and Talking Heads band.
[02:45:41.360 --> 02:45:42.360]   Yeah.
[02:45:42.360 --> 02:45:45.200]   And then there is the Becky Boys, which is the...
[02:45:45.200 --> 02:45:46.200]   Basty Boys.
[02:45:46.200 --> 02:45:48.160]   And Basty Boys Band.
[02:45:48.160 --> 02:45:52.520]   And then finally there is Dressedic Cats, which is the original's band, which is just
[02:45:52.520 --> 02:45:54.000]   Chaos.
[02:45:54.000 --> 02:45:56.600]   And go buy the Dressedic Cats album because it's Chaos.
[02:45:56.600 --> 02:45:57.600]   It's on-jade chaos.
[02:45:57.600 --> 02:45:58.600]   Yeah.
[02:45:58.600 --> 02:46:04.480]   If you want to hear songs that sound like it was written and recorded in an hour because
[02:46:04.480 --> 02:46:06.480]   they were going to...
[02:46:06.480 --> 02:46:12.040]   It is the most broken and recorded a few songs.
[02:46:12.040 --> 02:46:13.040]   But wait a minute.
[02:46:13.040 --> 02:46:16.680]   So it's the Bestie Boys, but it's Basty Boys and...
[02:46:16.680 --> 02:46:18.680]   The Becky Boys.
[02:46:18.680 --> 02:46:19.680]   The Becky Boys.
[02:46:19.680 --> 02:46:20.680]   The Basty Boys.
[02:46:20.680 --> 02:46:22.160]   The Last Train to a...
[02:46:22.160 --> 02:46:24.720]   I'm a loser baby or something like that.
[02:46:24.720 --> 02:46:25.720]   Sort of.
[02:46:25.720 --> 02:46:26.720]   Yeah.
[02:46:26.720 --> 02:46:27.720]   Yeah.
[02:46:27.720 --> 02:46:29.880]   Playing back is really fun.
[02:46:29.880 --> 02:46:33.560]   I mostly play bass and sing on that.
[02:46:33.560 --> 02:46:34.920]   Rapping is really tough.
[02:46:34.920 --> 02:46:35.920]   It's hard.
[02:46:35.920 --> 02:46:37.480]   That's what we were learning in this band.
[02:46:37.480 --> 02:46:38.480]   That's good.
[02:46:38.480 --> 02:46:40.040]   How tough it is to rap.
[02:46:40.040 --> 02:46:41.800]   So there's a bunch of shows that are coming up.
[02:46:41.800 --> 02:46:42.800]   Just look up those names.
[02:46:42.800 --> 02:46:43.800]   You'll find them.
[02:46:43.800 --> 02:46:46.680]   Well, I'm so glad we could get you on, Rob.
[02:46:46.680 --> 02:46:49.400]   I miss having you on the show more often.
[02:46:49.400 --> 02:46:54.640]   But I understand you're a busy person with your many pursuits, but you're always...
[02:46:54.640 --> 02:46:55.640]   My 50 bands.
[02:46:55.640 --> 02:46:57.200]   You're always welcome.
[02:46:57.200 --> 02:46:58.200]   You're a twit.
[02:46:58.200 --> 02:46:59.920]   Next time, drive the Lambo up.
[02:46:59.920 --> 02:47:00.920]   That's what I want.
[02:47:00.920 --> 02:47:01.920]   Yeah.
[02:47:01.920 --> 02:47:04.920]   Next time I get a good car, I'll hit you up for...
[02:47:04.920 --> 02:47:10.840]   And Nicole, next time you get a good pork pie, would you fly out and bring me a piece of
[02:47:10.840 --> 02:47:11.840]   that?
[02:47:11.840 --> 02:47:12.840]   Oh, that one looks like...
[02:47:12.840 --> 02:47:13.840]   That's what it looks like.
[02:47:13.840 --> 02:47:14.840]   Is that what it looks like?
[02:47:14.840 --> 02:47:15.840]   No, I don't...
[02:47:15.840 --> 02:47:19.040]   That looks different than what I get as a local bakery.
[02:47:19.040 --> 02:47:20.040]   I don't know what this is.
[02:47:20.040 --> 02:47:21.040]   I'll eat that though.
[02:47:21.040 --> 02:47:22.040]   That's different.
[02:47:22.040 --> 02:47:23.040]   Yeah.
[02:47:23.040 --> 02:47:24.040]   That looks good, but that's not what I...
[02:47:24.040 --> 02:47:25.040]   Yeah.
[02:47:25.040 --> 02:47:26.040]   It's good stuff.
[02:47:26.040 --> 02:47:28.720]   You had me at pork.
[02:47:28.720 --> 02:47:29.720]   And pork.
[02:47:29.720 --> 02:47:32.560]   Sam Apple, Sam-ed.
[02:47:32.560 --> 02:47:38.000]   Principal Analystic Guidehouse Insights, where he writes about cars and a lot of other
[02:47:38.000 --> 02:47:39.000]   stuff.
[02:47:39.000 --> 02:47:45.120]   He's also the host, the producer of Wheel Bering's at Wheel Bering's.media and joins us on a
[02:47:45.120 --> 02:47:46.280]   regular basis.
[02:47:46.280 --> 02:47:48.960]   Thank you, Sam, for bringing the gang together for us.
[02:47:48.960 --> 02:47:49.960]   I appreciate it.
[02:47:49.960 --> 02:47:50.960]   Thank you for having us, Leo.
[02:47:50.960 --> 02:47:52.280]   This has been a blast.
[02:47:52.280 --> 02:47:53.280]   Always fun.
[02:47:53.280 --> 02:47:54.280]   Always fun.
[02:47:54.280 --> 02:48:00.400]   I do a Twitter every Sunday, 2 p.m. Pacific, 5 p.m. Eastern, 2100 UTC.
[02:48:00.400 --> 02:48:04.800]   Now I only mention that because normally people download it, but if you wanted to watch it
[02:48:04.800 --> 02:48:06.480]   happen live, you could.
[02:48:06.480 --> 02:48:12.640]   That's the time and the way you would watch is going to the website, twit.tv/live.
[02:48:12.640 --> 02:48:17.160]   There's audio and video there for your enjoyment.
[02:48:17.160 --> 02:48:22.800]   If you're watching live, you might as well chat live with the folks who chat as they watch,
[02:48:22.800 --> 02:48:26.120]   either on our IRC at IRC.twit.tv.
[02:48:26.120 --> 02:48:31.120]   All you need is a web browser, although you can use an IRC client because it's real IRC,
[02:48:31.120 --> 02:48:36.000]   or if you're a club twit member and you want animated gifts, you should probably go and
[02:48:36.000 --> 02:48:37.560]   sign up for Club Twit.
[02:48:37.560 --> 02:48:39.560]   There's a discord associated with it.
[02:48:39.560 --> 02:48:43.760]   Oh, look here is from New England.com, a website.
[02:48:43.760 --> 02:48:46.960]   Thank you, Joe, to the Canadian.
[02:48:46.960 --> 02:48:48.960]   See, I'm not crazy.
[02:48:48.960 --> 02:48:50.120]   Oh, that's good.
[02:48:50.120 --> 02:48:56.440]   Oh, Mayor's Rousseau's tortilla.
[02:48:56.440 --> 02:48:59.080]   That looks like I might have to go to New Hampshire just for a while.
[02:48:59.080 --> 02:49:00.680]   Let's do the show in New Hampshire.
[02:49:00.680 --> 02:49:02.440]   I never thought I'd say that.
[02:49:02.440 --> 02:49:04.600]   I never thought I'd say that.
[02:49:04.600 --> 02:49:07.600]   Let's go to the Hampshire.
[02:49:07.600 --> 02:49:12.920]   After you watch, if you watch, you can download copies of the show, whether you watch or not,
[02:49:12.920 --> 02:49:14.480]   actually, that's the whole idea.
[02:49:14.480 --> 02:49:15.480]   It's a podcast.
[02:49:15.480 --> 02:49:17.920]   So go to twit.tv, download it there.
[02:49:17.920 --> 02:49:20.520]   There's a YouTube channel dedicated to the show.
[02:49:20.520 --> 02:49:22.480]   Takes us a couple of hours to edit it later tonight.
[02:49:22.480 --> 02:49:23.680]   It'll be up there.
[02:49:23.680 --> 02:49:27.320]   Actually, the best thing to do, so you don't even have to think about that.
[02:49:27.320 --> 02:49:33.800]   Find a great podcast client overcast, pocketcast, Apple Podcast, Google, whatever you use.
[02:49:33.800 --> 02:49:35.160]   Subscribe.
[02:49:35.160 --> 02:49:37.520]   That way you'll get the show the minute it's available.
[02:49:37.520 --> 02:49:38.520]   You don't have to think about it.
[02:49:38.520 --> 02:49:42.360]   You'll have it tomorrow for your commute or whatever, whenever you like to listen to
[02:49:42.360 --> 02:49:43.360]   it.
[02:49:43.360 --> 02:49:46.400]   There's even, by the way, there's special feeds like all the twit shows.
[02:49:46.400 --> 02:49:48.360]   If you search for a twit, you find that.
[02:49:48.360 --> 02:49:49.840]   Subscribe, you get them all.
[02:49:49.840 --> 02:49:52.440]   Then you've got this wonderful potpourri.
[02:49:52.440 --> 02:49:54.960]   It's like a pork pie for your ears.
[02:49:54.960 --> 02:49:55.960]   Ooh.
[02:49:55.960 --> 02:49:57.960]   Yes, of stuff.
[02:49:57.960 --> 02:50:00.760]   Just listen at your leisure when you're in the mood.
[02:50:00.760 --> 02:50:04.120]   How about that?
[02:50:04.120 --> 02:50:07.120]   And wheel bearings is now available in YouTube music podcasts.
[02:50:07.120 --> 02:50:10.360]   If for some reason you feel like you have to listen to podcasts and YouTube videos.
[02:50:10.360 --> 02:50:11.840]   Are we available in YouTube music?
[02:50:11.840 --> 02:50:13.520]   I guess we probably are.
[02:50:13.520 --> 02:50:14.520]   Yeah.
[02:50:14.520 --> 02:50:15.520]   That's cool.
[02:50:15.520 --> 02:50:20.400]   You have to make a playlist and tag it as a podcast in YouTube studio.
[02:50:20.400 --> 02:50:22.440]   And then it'll become a podcast in YouTube music.
[02:50:22.440 --> 02:50:25.160]   Well, if we aren't already, we're going to be by the end of this week.
[02:50:25.160 --> 02:50:27.880]   I can tell you right now.
[02:50:27.880 --> 02:50:28.880]   Thank you, Sam.
[02:50:28.880 --> 02:50:29.880]   Thank you, Nicole.
[02:50:29.880 --> 02:50:30.880]   Thank you, Robbie.
[02:50:30.880 --> 02:50:32.880]   Thanks to all of you who watch.
[02:50:32.880 --> 02:50:35.120]   I hope you enjoyed the show.
[02:50:35.120 --> 02:50:37.320]   We'll see you next time.
[02:50:37.320 --> 02:50:39.680]   Another twit is in the can.
[02:50:39.680 --> 02:50:40.680]   Bye-bye.
[02:50:40.680 --> 02:50:41.680]   Bye.
[02:50:41.680 --> 02:50:42.680]   Bye.
[02:50:42.680 --> 02:50:43.680]   Bye.
[02:50:43.680 --> 02:50:44.680]   Bye.
[02:50:44.680 --> 02:50:45.680]   Bye.
[02:50:45.680 --> 02:50:46.680]   Bye.
[02:50:46.680 --> 02:50:47.680]   Bye.
[02:50:47.680 --> 02:50:48.680]   Bye.
[02:50:48.680 --> 02:50:49.680]   Bye.
[02:50:49.680 --> 02:50:50.680]   Bye.
[02:50:50.680 --> 02:50:51.680]   Bye.
[02:50:51.680 --> 02:50:52.680]   Bye.

