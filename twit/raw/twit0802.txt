;FFMETADATA1
title=The Year in Review
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=802
genre=Podcast
comment=https://twit.tv/twit
copyright=These podcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:18.000]   It's time for Twit this week in Tech. It's a very special end of the year episode Steve Gibson, Paul Therat, Jeff Jarvis and I will take a look back at the top 10 stories of 2020 and look ahead to 2021 next on Twit.
[00:00:18.000 --> 00:00:37.000]   This week in Tech comes to you from Twit's LastPass Studios. Securing every access point in your company doesn't have to be a challenge. LastPass unifies access and authentication to make securing your employees simple and secure. Even when they're working remotely, check out lastpass.com/twit to learn more.
[00:00:37.000 --> 00:00:43.000]   Podcasts you love from people you trust.
[00:00:43.000 --> 00:00:46.000]   This is Twit.
[00:00:46.000 --> 00:01:02.000]   This is Twit, this week in Tech, Episode 802, recorded Sunday, December 20, 2020. The year in review.
[00:01:02.000 --> 00:01:08.000]   This episode of This Week in Tech is brought to you by ExpressVPN.
[00:01:08.000 --> 00:01:20.000]   ExpressVPN is the world's number one rated VPN by CNET, Wired and the Verge. For three extra months free with a one year package go to expressvpn.com/twit.
[00:01:20.000 --> 00:01:32.000]   And by CashFly. Give your users the seamless online experience they want. Power your site or app with CashFly's CDN and be 30% faster than the competition.
[00:01:32.000 --> 00:01:36.000]   Learn more at twit.cashfly.com
[00:01:37.000 --> 00:01:53.000]   And by ZenDesk. ZenDesk makes software for better customer service. They help empower support agents and give them the right tools. You could say they're champions of customer service. Visit zendesk.com/twit to learn more.
[00:01:54.000 --> 00:02:13.000]   By 4-word networks, 4-word networks reduces business risk by revolutionizing the way large networks are managed. Their advanced software delivers a digital twin of the network, a completely accurate mathematical model in software. Get a demo at 4-word networks.com/twit.
[00:02:20.000 --> 00:02:31.000]   It's time for Twit this week in Tech. Show where we cover the week's tech news. In this case the year's tech news. It's our last show of the year. Next week it's going to be a Twit best step.
[00:02:31.000 --> 00:02:39.000]   We like to do on our holiday episode. Always like to do something special. This week we thought this year we thought we'd bring in the OG Twits.
[00:02:39.000 --> 00:02:48.000]   People who have been with our shows practically since the very beginning. Paul Therrata, I hear you laughing.
[00:02:48.000 --> 00:03:01.000]   I feel old. You're an original gangster Paul. Just accept that OG. Windows Weekly started on this network when I have to go look and see Windows Week 2006.
[00:03:02.000 --> 00:03:13.000]   Oh gosh, you don't deserve to be here. You're practically a young. It's only been 14 years. We've only recorded 700 episodes. Amazing.
[00:03:13.000 --> 00:03:24.000]   Amazing. Paul Chris, the host of Windows Weekly. Really nice to have you. You're in the Lower Macungee Township in Pennsylvania where you are. How many feet of snow?
[00:03:24.000 --> 00:03:30.000]   We only got maybe 9 or 10 inches. They got more in New York. Mary Jo got more.
[00:03:30.000 --> 00:03:35.000]   Yeah, and it might rain on Christmas Eve or that's a ruin. Oh, that's awful.
[00:03:35.000 --> 00:03:49.000]   Also with us, I think he's the longest running Twit host. Security now started on August 2005. Steve Gibson. Old timer.
[00:03:49.000 --> 00:03:54.000]   Hi, Steve. Everybody, great to be with you all for this holiday episode. Yeah. Be fun.
[00:03:54.000 --> 00:04:05.000]   From Orange County where I think all the ICU's are full, so Steve, don't fall or stumble or anything.
[00:04:05.000 --> 00:04:13.000]   And the youngest member of our team, the host of this week in Google since August 1, 2009.
[00:04:13.000 --> 00:04:22.000]   Look at that kid. 2009. Why that? I'm so happy to be at the grownups table at last. Paul, can you pass the cranberry sauce, please?
[00:04:22.000 --> 00:04:28.000]   I should have brought to Turkey or something, but I figured you Turkey's would be enough for this show.
[00:04:28.000 --> 00:04:34.000]   We're going to do this year. Every year we kind of do this. We look back at the year gone by.
[00:04:34.000 --> 00:04:40.000]   And I think you three are actually perfect for that because between security now, Windows Weekly and this week in Google,
[00:04:40.000 --> 00:04:46.000]   I think you guys cover the waterfront. But what I've decided to do and Jason Howell helped me out.
[00:04:46.000 --> 00:04:50.000]   Thank you, Jason. He's been, he worked, pulled an all-nighter, getting this all together.
[00:04:50.000 --> 00:04:58.000]   Is we just go through what I consider kind of the top 10 stories of the year and get your thoughts on it.
[00:04:58.000 --> 00:05:07.000]   Kicking it off with ironically, I think this happened last year. The biggest story of the year this year is the story that just broke a week ago,
[00:05:07.000 --> 00:05:13.000]   the hack of the Commerce Department, the Treasury Department, the Department of Homeland Security,
[00:05:13.000 --> 00:05:22.000]   the Department of Energy, yes, the Department of Controls are nuclear arsenal. Many localities, including the City of Austin, Texas,
[00:05:22.000 --> 00:05:31.000]   has many as 18,000 enterprises. The SolarWinds hack. This is a brand new story, so we probably don't have all the details.
[00:05:31.000 --> 00:05:36.000]   I know we don't. There's a lot more to come out of this. But over the last week and a half, it's really developed very rapidly.
[00:05:36.000 --> 00:05:47.000]   Steve, you spent security now talking about SolarWinds. But even since Tuesday, we've learned more importantly, maybe we've learned how widespread this hack is.
[00:05:47.000 --> 00:05:50.000]   This is how bad is it?
[00:05:50.000 --> 00:06:02.000]   Well, everyone is calling it the worst hack in history. And of course, they're using the term in the popular press of an attack,
[00:06:02.000 --> 00:06:15.000]   but it's much more properly described as cyber espionage. And it was bad because it was clearly by design.
[00:06:15.000 --> 00:06:28.000]   So it's being attributed to Russia, and there are so-called indications of compromise, IOCs, which strongly suggest that they're behind it,
[00:06:28.000 --> 00:06:45.000]   that Russian state-sponsored cyber groups are there. I'm sure that there is much less publicly known than is now known in the depths of the NSA and the CIA.
[00:06:45.000 --> 00:07:06.000]   The very recent news is that there are some indications that SolarWinds was not the only point of entry. That is, they have found some commonality of indications of compromise on systems that did not have the SolarWinds Orion system in it,
[00:07:06.000 --> 00:07:19.000]   leading them to believe either that there was some lateral movement that was initiated through SolarWinds, compromised networks, or that there was some other way in that has not been determined yet.
[00:07:19.000 --> 00:07:32.000]   Brian Krebs quotes sources saying, "It might have been VMware that was a vector, whether related to the SolarWinds DLL hack of their Orion product or not.
[00:07:32.000 --> 00:07:43.000]   And the NSA warned, way back in December 7th, that VMware, we talked about this, I think on security now, was being used to impersonate authorized users on the victim networks.
[00:07:43.000 --> 00:07:48.000]   So the authentication part of VMware was being used, VMware access and under-view manager.
[00:07:48.000 --> 00:08:00.000]   So I think really the takeaway, one of the themes that we often discuss on the Security Now podcast is the truth that security is porous.
[00:08:00.000 --> 00:08:06.000]   It's got porosity for lack of a better term. I haven't ever come up with one.
[00:08:06.000 --> 00:08:17.000]   And the degree of porousness would be how hard you have to press in order to get yourself through a barrier.
[00:08:17.000 --> 00:08:24.000]   And so there are things that are easy to do, low-hanging fruit is the common term, and things that are much more difficult.
[00:08:24.000 --> 00:08:36.000]   This was a high finesse attack where presumably Russians somehow got themselves into the SolarWinds network.
[00:08:36.000 --> 00:08:48.000]   They got access to the source code repository, that is, on servers, there is source code for this Orion IT management software.
[00:08:48.000 --> 00:09:08.000]   They inserted their Trojan code, merged it in with the existing source code, knowing that the next time the SolarWinds guys made some incidental tweak to their Orion system,
[00:09:08.000 --> 00:09:21.000]   and then rebuilt the software that that Trojan would be incorporated into the rebuild, which would then automatically go out to all the Orion customers.
[00:09:21.000 --> 00:09:36.000]   Once upon a time, there was a page on the SolarWinds site bragging about everyone who was using their stuff, and probably it listed all of the US government agencies that they counted as proud customers.
[00:09:36.000 --> 00:09:39.000]   Well that page is gone now.
[00:09:39.000 --> 00:09:50.000]   So consequently, when all of these customers updated their copies of the Orion IT management software, they all acquired the Trojan.
[00:09:50.000 --> 00:10:02.000]   The Trojan then stayed quiet deliberately for a while, and then it reached out to a deliberately arranged local IP, that is,
[00:10:02.000 --> 00:10:17.000]   that the Russians also set up VPN endpoints around the world so that the Trojan wouldn't be seen making an outreach out of the country, but to somewhere local.
[00:10:17.000 --> 00:10:28.000]   So the point is that at every step of the way, this was not easy to do, but highly skilled hackers did it.
[00:10:28.000 --> 00:10:36.000]   And the code they inserted, the Actor code, was actually 4,000 lines. It was not a trivial thing.
[00:10:36.000 --> 00:10:45.000]   How could SolarWinds not have noticed a commit to their repository of 4,000 lines of malicious code, and then built the update?
[00:10:45.000 --> 00:10:50.000]   As a fraction of the total SolarWinds code, it was still minuscule.
[00:10:50.000 --> 00:10:53.000]   So it was super tiny.
[00:10:53.000 --> 00:10:57.000]   And how do we think it's Russia? Secretary of State Mike Pompeo said it was Russia.
[00:10:57.000 --> 00:11:00.000]   The president has notably said it's China.
[00:11:00.000 --> 00:11:03.000]   Leo, I'm afraid I can tell it's Russia.
[00:11:03.000 --> 00:11:10.000]   Look at the map that Microsoft published, and notice that the only major country on it that hasn't been hacked is Russia.
[00:11:10.000 --> 00:11:11.000]   There you go.
[00:11:11.000 --> 00:11:14.000]   Well Russia and Greenland, I guess.
[00:11:14.000 --> 00:11:15.000]   Even countries in Africa.
[00:11:15.000 --> 00:11:21.000]   The one other really important point I think to make is that we only know about this.
[00:11:21.000 --> 00:11:31.000]   Remember, this began the first instance had a signed a SolarWind security certificate signed on March 24th of 2020.
[00:11:31.000 --> 00:11:43.000]   We only found out about this because about 10 days ago, the Russians made their first mistake and did something that tripped an alarm at fire eye
[00:11:43.000 --> 00:11:47.000]   that then caused fire eye to say, "Whoa, what?"
[00:11:47.000 --> 00:11:50.000]   And how do people get in?
[00:11:50.000 --> 00:11:53.000]   And that's the only reason we know.
[00:11:53.000 --> 00:12:05.000]   This would still be going on this kind of pervasive penetration into our highest levels of government networks,
[00:12:05.000 --> 00:12:10.000]   unless that mistake had been made, something tripped an alarm.
[00:12:10.000 --> 00:12:16.000]   And they probably did all of the other things they wanted to do before they decided,
[00:12:16.000 --> 00:12:21.000]   "Well, let's go hope we can creep into fire eye and nobody will see us."
[00:12:21.000 --> 00:12:24.000]   They were probably looking for hacking tools that fire eye had.
[00:12:24.000 --> 00:12:27.000]   In fact, they think there was some evidence those were exfiltrated.
[00:12:27.000 --> 00:12:30.000]   Here's the map you were talking about, Paul, from Microsoft.
[00:12:30.000 --> 00:12:33.000]   It's either Russia or Burkina Faso.
[00:12:33.000 --> 00:12:37.000]   Could be pretty much the right Madagascar is a little suspicious.
[00:12:37.000 --> 00:12:42.000]   But there's a little purple, I guess, where there are some outbreaks.
[00:12:42.000 --> 00:12:45.000]   And it is pretty much everywhere.
[00:12:45.000 --> 00:12:51.000]   And very notably, there's this big landmass called Russia that has not, but nor has Scandinavia.
[00:12:51.000 --> 00:12:55.000]   I don't think the Finns are hacking our systems, though.
[00:12:55.000 --> 00:12:58.000]   China was hacked.
[00:12:58.000 --> 00:13:02.000]   The president says China, Pompeo says it's Russia.
[00:13:02.000 --> 00:13:06.000]   It's hard, isn't it notoriously hard to source these?
[00:13:06.000 --> 00:13:07.000]   Yes.
[00:13:07.000 --> 00:13:09.000]   So you can't be sure.
[00:13:09.000 --> 00:13:10.000]   Right.
[00:13:10.000 --> 00:13:18.000]   And it's also possible to set up fakeouts where you deliberately leave some information that is elsewhere.
[00:13:18.000 --> 00:13:22.000]   This happened when the North Koreans supposedly hacked Sony.
[00:13:22.000 --> 00:13:25.000]   The federal government said it's the North Koreans.
[00:13:25.000 --> 00:13:30.000]   You and I said, "Well, how do you know?" and they said, "We know, trust us, but we're not going to tell you how we know."
[00:13:30.000 --> 00:13:32.000]   And this is the same kind of thing.
[00:13:32.000 --> 00:13:34.000]   They're not revealing the information.
[00:13:34.000 --> 00:13:37.000]   But apparently, Cozy Bear's fingerprints are all over it.
[00:13:37.000 --> 00:13:44.000]   And what's really interesting, too, is if we assume that our intelligence, like we have hackers, too,
[00:13:44.000 --> 00:13:51.000]   we know that, unfortunately, from the public disclosures that we've had a lot of time discussing,
[00:13:51.000 --> 00:13:59.000]   it's interesting that our penetrations into Russian networks apparently did not pick up the fact
[00:13:59.000 --> 00:14:01.000]   that they had penetrated ours.
[00:14:01.000 --> 00:14:10.000]   That is, they're clearly keeping their cyber espionage deliberately separate from the rest of Russia.
[00:14:10.000 --> 00:14:17.000]   Otherwise, we would have seen, because it would have appeared in their networks, stuff that they shouldn't have from ours,
[00:14:17.000 --> 00:14:19.000]   and that would have raised the alarm, too.
[00:14:19.000 --> 00:14:20.000]   But that didn't happen.
[00:14:20.000 --> 00:14:22.000]   Well, it's like the Enigma.
[00:14:22.000 --> 00:14:27.000]   When we cracked the Enigma machine, the British had to be very careful about the use of that intelligence,
[00:14:27.000 --> 00:14:31.000]   because that would have told the Nazis we knew their codes, and we were able to break it.
[00:14:31.000 --> 00:14:37.000]   So presumably, the Russians have the same limitations on what they could do with the intelligence that they gain.
[00:14:37.000 --> 00:14:42.000]   So, Steve, I'm delighted to be here with the expert of experts.
[00:14:42.000 --> 00:14:47.000]   How does the forensic analysis of what's been compromised work?
[00:14:47.000 --> 00:14:51.000]   How do you ever really know what has been seen?
[00:14:51.000 --> 00:14:53.000]   Is there any way to know that?
[00:14:53.000 --> 00:14:54.000]   No.
[00:14:54.000 --> 00:14:58.000]   Well, okay, maybe, but not necessarily.
[00:14:58.000 --> 00:15:06.000]   One of the things these guys have done is they've, and even the non-experts are repeating what the experts are saying,
[00:15:06.000 --> 00:15:18.000]   which is these hackers have demonstrated the highest level of skill, which is to say, you know, they're as good as anybody.
[00:15:18.000 --> 00:15:24.000]   And it is notoriously possible to cover your tracks.
[00:15:24.000 --> 00:15:30.000]   Sometimes backup snapshots from like, will capture old logs.
[00:15:30.000 --> 00:15:38.000]   Right now, you can imagine that there is scrambling going on retroactively looking at like,
[00:15:38.000 --> 00:15:41.000]   for traces that weren't appreciated at the time.
[00:15:41.000 --> 00:15:47.000]   So there's rumors, you know, there were stories that we, there were rumblings about this back in October.
[00:15:47.000 --> 00:15:51.000]   You know, they got in in March, we think.
[00:15:51.000 --> 00:15:57.000]   There were signs in October, but it wasn't until FireEye got hacked that we were sure.
[00:15:57.000 --> 00:16:07.000]   So, part of the problem is that these guys have been, have had six or seven months to just wander around unobserved.
[00:16:07.000 --> 00:16:09.000]   They could have exfiltrated stuff.
[00:16:09.000 --> 00:16:11.000]   They've been able to cover their tracks.
[00:16:11.000 --> 00:16:17.000]   And I think even there's even a larger issue of what other payloads have they injected.
[00:16:17.000 --> 00:16:23.000]   And there's 18,000 potential sites, each with millions of endpoints.
[00:16:23.000 --> 00:16:25.000]   This is going to be almost a pot.
[00:16:25.000 --> 00:16:27.000]   It's like cockroaches.
[00:16:27.000 --> 00:16:29.000]   You can't eradicate it, right?
[00:16:29.000 --> 00:16:37.000]   And so to answer Jeff's question, you know, the famous hacker approach is you get into a system,
[00:16:37.000 --> 00:16:45.000]   you do a bunch of things, then you delete your own, you delete the logs that demonstrate what it was you just did
[00:16:45.000 --> 00:16:51.000]   and hopefully get out undetected so that even somebody who's looking at the logs says, "Yeah, look, there's nothing here.
[00:16:51.000 --> 00:16:52.000]   Nothing happened."
[00:16:52.000 --> 00:16:56.000]   Because it is all digital and it is all digital forensics.
[00:16:56.000 --> 00:16:58.000]   And it's not backed up.
[00:16:58.000 --> 00:17:01.000]   You don't, you don't offload your logs so you have a...
[00:17:01.000 --> 00:17:02.000]   Oh, you might.
[00:17:02.000 --> 00:17:03.000]   You might.
[00:17:03.000 --> 00:17:04.000]   That's, I guess...
[00:17:04.000 --> 00:17:05.000]   Right.
[00:17:05.000 --> 00:17:12.000]   So it might be that a snapshot of a server in the past would be able to show something.
[00:17:12.000 --> 00:17:13.000]   I mean, it's a...
[00:17:13.000 --> 00:17:14.000]   It is.
[00:17:14.000 --> 00:17:20.000]   You know, you could imagine a lot of people's Christmas holidays, a lot of IT Christmas holidays just got wrecked.
[00:17:20.000 --> 00:17:22.000]   There's...
[00:17:22.000 --> 00:17:31.000]   You know, and if with the Sony hack, they exfiltrated, they downloaded movies, you know, terabytes' worth of data.
[00:17:31.000 --> 00:17:34.000]   So I guess you might see unusual traffic, but it sounds like these guys were pretty...
[00:17:34.000 --> 00:17:40.000]   We're so savvy that if they did anything, they did it very carefully and probably were able to...
[00:17:40.000 --> 00:17:45.000]   You really want to be surgical because they recognized they had...
[00:17:45.000 --> 00:17:49.000]   They managed to establish an incredible advantage.
[00:17:49.000 --> 00:17:56.000]   So the last thing they would want to do, for example, is to shoot terabytes of data out of some network connection.
[00:17:56.000 --> 00:17:59.000]   That's the kind of thing that would immediately trigger alarms.
[00:17:59.000 --> 00:18:03.000]   And, you know, we do have cyber intrusion stuff.
[00:18:03.000 --> 00:18:04.000]   And it's...
[00:18:04.000 --> 00:18:11.000]   You know, Einstein is the system that we've heard of that our federal government uses specifically to keep this from happening.
[00:18:11.000 --> 00:18:13.000]   And it just, you know, the Russians know about it.
[00:18:13.000 --> 00:18:16.000]   And so they said, "Okay, let's, you know, not trip Einstein up."
[00:18:16.000 --> 00:18:22.000]   Well, the other problem is that it's notoriously difficult to catch what are called supply chain hacks.
[00:18:22.000 --> 00:18:28.000]   So true or not, there was that Bloomberg story last year or two years ago, I guess, now,
[00:18:28.000 --> 00:18:36.000]   about the Super Micro motherboards that had rice, kernel size chips added to them in this...
[00:18:36.000 --> 00:18:40.000]   As it went down the supply chain to put spy devices on there.
[00:18:40.000 --> 00:18:41.000]   Never found any proof of that.
[00:18:41.000 --> 00:18:42.000]   Bloomberg never retracted it.
[00:18:42.000 --> 00:18:45.000]   We really will never know what the truth is there.
[00:18:45.000 --> 00:18:48.000]   But that was a warning at the time.
[00:18:48.000 --> 00:18:50.000]   You got to be careful about your supply chain.
[00:18:50.000 --> 00:18:57.000]   You cannot assume that those updates coming from this, you know, signed updates coming from a trusted security company
[00:18:57.000 --> 00:18:59.000]   are legit.
[00:18:59.000 --> 00:19:08.000]   And I do hope this becomes a warning to be more careful, but everybody I've seen talking about this says,
[00:19:08.000 --> 00:19:10.000]   "This is really hard.
[00:19:10.000 --> 00:19:13.000]   A supply chain hack is about the hardest to avoid."
[00:19:13.000 --> 00:19:19.000]   So was the Huawei, paranoia, legit, or politics?
[00:19:19.000 --> 00:19:21.000]   Steve?
[00:19:21.000 --> 00:19:24.000]   I have no first-hand knowledge.
[00:19:24.000 --> 00:19:26.000]   And I'm...
[00:19:26.000 --> 00:19:33.000]   Again, to Leo's point about that motherboard hack, even if it didn't happen, we know it could hack.
[00:19:33.000 --> 00:19:35.000]   You know, there have been proof of concepts.
[00:19:35.000 --> 00:19:43.000]   You can bury a little microprocessor in the LAN network connector now so that you don't even...
[00:19:43.000 --> 00:19:50.000]   You know, it's under the little metal shell that protects it from RF radiation.
[00:19:50.000 --> 00:19:54.000]   And you just... you look at it, looks just fine.
[00:19:54.000 --> 00:19:56.000]   But there's something squirreled away in there.
[00:19:56.000 --> 00:19:58.000]   I mean, this is the world we're in today.
[00:19:58.000 --> 00:20:01.000]   There's nobody that makes all their own hardware and software.
[00:20:01.000 --> 00:20:03.000]   So everybody has a supply chain.
[00:20:03.000 --> 00:20:05.000]   They have external suppliers.
[00:20:05.000 --> 00:20:09.000]   And I guess to some degree you need to trust them.
[00:20:09.000 --> 00:20:16.000]   Although Google has been promoting this zero-knowledge architecture where you trust no one inside or outside the perimeter.
[00:20:16.000 --> 00:20:24.000]   But I don't... you know, the word the GSA had done a survey a couple of months ago because they were concerned about this.
[00:20:24.000 --> 00:20:27.000]   This is not really a surprise to some.
[00:20:27.000 --> 00:20:36.000]   And they found that government agencies had done very few, if any, of the proactive protections that the GSA had recommended.
[00:20:36.000 --> 00:20:44.000]   These guys, not only were not doing zero-knowledge architectures, they weren't even checking for malware.
[00:20:44.000 --> 00:20:47.000]   They were just assuming the best.
[00:20:47.000 --> 00:20:50.000]   And so we were wide open to this.
[00:20:50.000 --> 00:20:56.000]   Now the question is, maybe I don't know if anybody knows this, but are we doing the same thing to them?
[00:20:56.000 --> 00:21:00.000]   And if not, why not?
[00:21:00.000 --> 00:21:13.000]   Given the Snowden leaks and the WikiLeaks revelations, we really got a surprise with clear evidence of the extent to which our intelligence agencies
[00:21:13.000 --> 00:21:19.000]   have very actively developed espionage capabilities.
[00:21:19.000 --> 00:21:22.000]   And that was some time ago.
[00:21:22.000 --> 00:21:28.000]   So it's hard to imagine that we're not every bit as good as they are.
[00:21:28.000 --> 00:21:40.000]   And that, in fact, it's second hand, but I heard someone say that Michael Hayden was asked about this whole issue of cyber espionage.
[00:21:40.000 --> 00:21:45.000]   And he said, former director of the NSA, right?
[00:21:45.000 --> 00:21:51.000]   He said, we are so deep into Russians' networks.
[00:21:51.000 --> 00:21:56.000]   I'm just hoping they're not as deeply into ours.
[00:21:56.000 --> 00:22:00.000]   Is that Braggadocio, or do you believe that?
[00:22:00.000 --> 00:22:03.000]   Maybe Prashins.
[00:22:03.000 --> 00:22:06.000]   And Michael's a fan of this network, by the way.
[00:22:06.000 --> 00:22:10.000]   Oh, really? We have to be nicer to him.
[00:22:10.000 --> 00:22:14.000]   We've said some mean things about him, I believe Steve.
[00:22:14.000 --> 00:22:23.000]   So, no, I think that the problem is that cyber, this is the new form of warfare, right?
[00:22:23.000 --> 00:22:25.000]   It's not conventional warfare.
[00:22:25.000 --> 00:22:26.000]   It's not nuclear weapons.
[00:22:26.000 --> 00:22:29.000]   It's not armies marching and invading other countries.
[00:22:29.000 --> 00:22:32.000]   It's cyber warfare.
[00:22:32.000 --> 00:22:42.000]   And perhaps the saving grace is, just as there was with nuclear warfare, there has to be some notion of mutually assured destruction.
[00:22:42.000 --> 00:22:49.000]   That's what kept us from destroying the planet, was the knowledge that, well, if you fire nukes at us, we're going to fire nukes back at you and there'll be nothing left.
[00:22:49.000 --> 00:23:01.000]   If we are doing the same thing to them, maybe that's the only thing that's keeping them from doing things like, you know, I have to presume, if they're that deep inside our networks, they could screw with our financial markets, for instance.
[00:23:01.000 --> 00:23:04.000]   Or the electrical grid, right, Steve?
[00:23:04.000 --> 00:23:06.000]   They may have capability.
[00:23:06.000 --> 00:23:09.000]   We've seen that they've been in the electrical grid for some years.
[00:23:09.000 --> 00:23:20.000]   They did a trial power outage in the Ukraine, in Ukraine, I'm sorry, I know the Ukraine a couple of years ago, and we think that that was a test of capabilities.
[00:23:20.000 --> 00:23:26.000]   Maybe the only thing keeping them from doing these kinds of acts of war is that we could do the same thing back.
[00:23:26.000 --> 00:23:27.000]   Yeah.
[00:23:27.000 --> 00:23:28.000]   I hope.
[00:23:28.000 --> 00:23:30.000]   I don't know.
[00:23:30.000 --> 00:23:40.000]   What about what about non-governmental bodies, and mafia's terrorists, bad companies, bad people, bond villains?
[00:23:40.000 --> 00:23:43.000]   Is it possible to be that good?
[00:23:43.000 --> 00:23:46.000]   Or do you need so many resources to be this good?
[00:23:46.000 --> 00:23:48.000]   It's only major.
[00:23:48.000 --> 00:23:58.000]   We see evidence that we discuss every week on the podcast of individual hackers who are really gifted.
[00:23:58.000 --> 00:24:06.000]   So, I wouldn't say it's impossible for it to not be nation state.
[00:24:06.000 --> 00:24:21.000]   You can imagine that there was some desire to sell this as requiring the elitist of the elite, just so there isn't a sense of like, "Oh yeah, anybody could have done this."
[00:24:21.000 --> 00:24:23.000]   It's like, "Oh, we're going to Jersey basement."
[00:24:23.000 --> 00:24:24.000]   We don't want to think that.
[00:24:24.000 --> 00:24:33.000]   Well, there is a kind of a perrito principle that most of the hacks, 80% or 90% of the hacks are performed by script kitties who really don't have elite skills, no matter what they say.
[00:24:33.000 --> 00:24:35.000]   They're running scripts they got from elsewhere.
[00:24:35.000 --> 00:24:40.000]   We've talked on the show about ransomware as a service.
[00:24:40.000 --> 00:24:48.000]   There are a number of companies, I guess you call them companies, that offer ransomware service that you could subscribe to.
[00:24:48.000 --> 00:24:53.000]   There are a number of companies that offer DDoS attacks as a service.
[00:24:53.000 --> 00:24:59.000]   There are a lot of little low level script kitties around using this stuff.
[00:24:59.000 --> 00:25:07.000]   I guess though there are enough elite hackers around that any country that wants to could hire enough of them to be a threat, right?
[00:25:07.000 --> 00:25:11.000]   The other problem is the inside man problem.
[00:25:11.000 --> 00:25:17.000]   We don't know, for example, that it wasn't a programmer at solar winds.
[00:25:17.000 --> 00:25:18.000]   I'm just making this up.
[00:25:18.000 --> 00:25:33.000]   We know evidence of this. But who is in serious financial trouble due to gambling and was approached by someone who said, "Look, you're really in trouble. We've got plenty of cash.
[00:25:33.000 --> 00:25:42.000]   We need you to add this module and we'll solve your problems."
[00:25:42.000 --> 00:25:54.000]   A couple of months ago in October, you and I and Bruce Schneier and LastPass's Cso, Jerry Bucelt did a really great, along with Red versus Blue attack panel.
[00:25:54.000 --> 00:26:00.000]   Actually, you weren't on that one, Steve. It was Father Robert and Shebert where they attacked, they defended.
[00:26:00.000 --> 00:26:11.000]   I think Schneier had the seminal quote from that event, which you should all watch if you haven't seen it, which is, "There is no such thing as perfect security.
[00:26:11.000 --> 00:26:23.000]   You can layer it. You could do the best you can." But ultimately, nobody is impervious, especially if the attacker has unlimited, limitless resources and limitless desire to get in.
[00:26:23.000 --> 00:26:25.000]   Would you say that's fair, Steve?
[00:26:25.000 --> 00:26:29.000]   I think that's absolutely right, which is why I use the term "porus."
[00:26:29.000 --> 00:26:37.000]   There is no wall, which is impenetrable. It's just varying degrees of effort required to penetrate.
[00:26:37.000 --> 00:26:51.000]   At this point, I feel like it's no longer almost not a tech story anymore. At this point, it's a political story because the next stage is diplomatic, is political, is our government and their government coming to some sort of detente.
[00:26:51.000 --> 00:26:57.000]   We've got the weapons, you've got the weapons. I don't think there's a technical solution to this. They're in there. They're going to be in there forever.
[00:26:57.000 --> 00:27:03.000]   I don't think you could ever say with any certainty they've been eradicated from the networks, right?
[00:27:03.000 --> 00:27:21.000]   Well, yes. We know of a growing number of high-profile government entities, which have been penetrated because we do have really good people there who are now able to look in and go, "Ooh, shoot!"
[00:27:21.000 --> 00:27:36.000]   But we know that 18,000-somethings downloaded the update and that update then did a phone home within a couple weeks of being downloaded.
[00:27:36.000 --> 00:27:49.000]   So within those 18,000, there are thousands of smaller organizations that are like, "Oh, do we have anything here? Oh, we turned our logs off. Well, we don't really know, but yeah, probably not. Everything seems fine."
[00:27:49.000 --> 00:27:59.000]   It's going to be a fun 2021 on security now. I'm going to move on. It really is funny because that is a story we would have been doing on any Twitch.
[00:27:59.000 --> 00:28:05.000]   This is probably the biggest tech story of the year, so we brought it up here and it's a developing story.
[00:28:05.000 --> 00:28:11.000]   And it's fresh. And I think next year we'll be spending time talking about this. I might imagine we will continue.
[00:28:11.000 --> 00:28:22.000]   We're not going to be the Steve Gibson show, though. We have other topics. Paul Therat. It's great to have you, Jeff Jarvis and Steve Gibson. It's the original Gangsta Twits.
[00:28:22.000 --> 00:28:32.000]   The old guys. The old guys. The old guys. Oh, geez. They're old. I think those movies were like "Aging Holiday." "Hollywood Stars" are in a movie together and they go to Vegas.
[00:28:32.000 --> 00:28:40.000]   It's "Oceans Three." Yeah, it's going to be great. Can't wait to watch it. We're going to a table read, lots of ages and jokes.
[00:28:40.000 --> 00:28:44.000]   No, none of that will happen. We're going to talk about some of these.
[00:28:44.000 --> 00:28:54.000]   The top 10 stories of 2020 as we continue. Ironically, the number one story, I think clearly of 2020 is this solar wind story, but we have more to talk about in just a second.
[00:28:54.000 --> 00:29:09.000]   Our show today brought to you by ExpressVPN. You may not be able to prevent a supply chain attack, but you probably can prevent the spying from your Internet service provider logging the sites you visit, the searches you make.
[00:29:09.000 --> 00:29:15.000]   A lot of people say when we talk about privacy, "Hey, if you got nothing to hide, I got nothing to hide. No big deal."
[00:29:15.000 --> 00:29:23.000]   But I met those same people close the bathroom door behind them. You don't want random passers-by checking in on you.
[00:29:23.000 --> 00:29:32.000]   So why would you let people look in on you while you go online? ExpressVPN protects your privacy, protects your security, and it does it better than anyone else.
[00:29:32.000 --> 00:29:41.000]   I think by now, anybody who has listened to our shows knows they want a VPN both at home and abroad, but the question is, which VPN?
[00:29:41.000 --> 00:29:46.000]   Because really, you've got to trust the VPN. That's why I recommend and use ExpressVPN.
[00:29:46.000 --> 00:29:57.000]   First of all, they are thoroughly audited. They use PricewaterhouseCooper. They vetted their privacy policy and they said, "Yep, ExpressVPN does not log. That's exactly right."
[00:29:57.000 --> 00:30:10.000]   They even vetted the trusted server technology that ExpressVPN uses. They're so committed to not tracking you that when you use an ExpressVPN server, it spins up in RAM.
[00:30:10.000 --> 00:30:20.000]   Just for you, it's dedicated to you. You use it as soon as you leave, it goes away, cannot write to the hard drive. It's sandboxed.
[00:30:20.000 --> 00:30:29.000]   So they couldn't log if they wanted to. And by the way, PricewaterhouseCooper verified that that does work exactly as stated.
[00:30:29.000 --> 00:30:38.000]   ExpressVPN is fast, fast enough that you can use it to watch Netflix in the UK, even if you're in the US. It's secure and it's totally private.
[00:30:38.000 --> 00:30:47.000]   That's why I use it. It's also very affordable. ExpressVPN is the number one rated VPN, according to CNET, according to Wired, according to the Verge.
[00:30:47.000 --> 00:30:58.000]   They trust it. I trust it. Roughly $7 a month. Now, you might say, "Well, I can get a free VPN." Yeah, good luck because if you're not paying for the VPN, they're paying for it somehow.
[00:30:58.000 --> 00:31:13.000]   So I suggest you want to pay a reasonable amount for the VPN. I think that's very, very fair. If you're like me and you believe your online activity is your business, you should secure yourself by visiting expressvpn.com/twit today.
[00:31:13.000 --> 00:31:21.000]   We've got a special deal for you 15 months for the price of 12 when you go to eXPRESVpn.com/twit.
[00:31:21.000 --> 00:31:33.000]   3 extra months free. ExpressVPN.com/twit. I trust them. And I think that's really the most important thing. They're a good company.
[00:31:33.000 --> 00:31:48.000]   And we thank them so much for supporting us all through 2020. We're talking about the top 10 stories of 2020. It's not a tech story exactly, except that there are tech elements to it. Of course, COVID-19.
[00:31:48.000 --> 00:31:58.000]   It's so funny. I was thinking back. It was you and me, Paul, we were talking about CES. That seems like a hundred years ago back in January.
[00:31:58.000 --> 00:32:05.000]   Different world. It was a different world. You didn't go to know what none of you went to CES this year.
[00:32:05.000 --> 00:32:16.000]   I did. And I feel like I'm super spreader. I could have been dodged one. I did dodge one. Yeah. In fact, it could have been a really bad thing.
[00:32:16.000 --> 00:32:26.000]   We knew that some people at CES did have COVID-19, but it did not. I think it was a late 2019 event in Boston, like a biotech event.
[00:32:26.000 --> 00:32:30.000]   That's the one. That was a super spreader. Yeah. Yeah.
[00:32:30.000 --> 00:32:34.000]   There were 300,000 cases. I think Paul would have been... Yeah, that had been attributed to this.
[00:32:34.000 --> 00:32:44.000]   From one relatively small conference in Boston. And ironically, in a conference that probably should have been a little better.
[00:32:44.000 --> 00:32:54.000]   Yeah, exactly. So I think really the first kind of tremors from the point of view of the tech industry anyway, were when conferences started canceling.
[00:32:54.000 --> 00:33:03.000]   I think the first was Mobile World Congress in March. Yeah. A bunch of companies begged out first. And then the conference followed.
[00:33:03.000 --> 00:33:09.000]   And that's when it... For us in the United States, it started to get weird, I think. That's when we knew it was serious.
[00:33:09.000 --> 00:33:15.000]   Apple started shutting down its stores in China. Ironically, here we are almost a year later.
[00:33:15.000 --> 00:33:20.000]   And Apple is once again closing down all its California stores.
[00:33:20.000 --> 00:33:29.000]   The Tokyo Olympics was called off. Tony Awards called off. Burning Man. Burning Man called off.
[00:33:29.000 --> 00:33:31.000]   But in a way...
[00:33:31.000 --> 00:33:33.000]   It's not my first event. Very, very last minute.
[00:33:33.000 --> 00:33:41.000]   That was a big deal, right? Because South by did not want to cancel in Austin. That's in April in Austin.
[00:33:41.000 --> 00:33:49.000]   April. And I think Austin said, "No, you better cancel." But this was a huge economic hit to the city of Austin.
[00:33:49.000 --> 00:33:54.000]   Lots of people come to town, stay in hotels. They're all booked up. Restaurants are booked up.
[00:33:54.000 --> 00:33:59.000]   It's not just the tech festival, the interactive festival. It's also the music and film festival.
[00:33:59.000 --> 00:34:05.000]   That was a huge loss to Austin. But again, it all seemed so long ago.
[00:34:05.000 --> 00:34:10.000]   The distant past now, because it just got worse and worse and worse.
[00:34:10.000 --> 00:34:15.000]   And yet, coronavirus, COVID-19, was kind of a boon for some companies.
[00:34:15.000 --> 00:34:19.000]   The richest people in America made more money.
[00:34:19.000 --> 00:34:26.000]   Well, in the companies that we all cover, Google, Microsoft, Apple, all the video game companies, is a big year.
[00:34:26.000 --> 00:34:33.000]   Yeah. Zoom. Zoom. Nobody really even knew about Zoom in 2019 unless you used it for work.
[00:34:33.000 --> 00:34:40.000]   And you probably didn't think twice about it. All of a sudden, it became a generic noun for getting online with people.
[00:34:40.000 --> 00:34:46.000]   Used by schools, used by pretty much families, by everybody. Zoom's...
[00:34:46.000 --> 00:34:53.000]   And they had a bit of a trial by fire also at the beginning, because the rush to popularity brought the hackers,
[00:34:53.000 --> 00:34:58.000]   who put a lot more pressure on the Zoom security than it had been subjected to before.
[00:34:58.000 --> 00:35:02.000]   And they stumbled a bit, but they've survived.
[00:35:02.000 --> 00:35:04.000]   Remember Zoom bombing?
[00:35:04.000 --> 00:35:05.000]   Yeah.
[00:35:05.000 --> 00:35:14.000]   They were very smart to hire Alex Day most quickly, and they apparently listened to him and made a fair number of changes.
[00:35:14.000 --> 00:35:22.000]   It's funny, because we got used to Zoom and Zoom-like interaction on TV shows even.
[00:35:22.000 --> 00:35:30.000]   Apple TV's Mythic Quest, the game show, came back, Apple sent them all iPhones and FaceTime,
[00:35:30.000 --> 00:35:34.000]   and they came back and did a... they concluded their season already.
[00:35:34.000 --> 00:35:37.000]   They did an extra episode that was all on FaceTime.
[00:35:37.000 --> 00:35:43.000]   Saturday Night Live did a Zoom version of Saturday Night Live.
[00:35:43.000 --> 00:35:44.000]   Right.
[00:35:44.000 --> 00:35:50.000]   And the quality of all the talking head shows has just fallen down ridiculously.
[00:35:50.000 --> 00:35:57.000]   It's now just common for people to freeze on screen, and then the commentators says, "Oh, well, they just froze."
[00:35:57.000 --> 00:35:59.000]   And the times like us, just like...
[00:35:59.000 --> 00:36:03.000]   Could we please take credit for being pioneers in this area?
[00:36:03.000 --> 00:36:05.000]   Yeah, I think it's the first.
[00:36:05.000 --> 00:36:07.000]   We froze before anybody else.
[00:36:07.000 --> 00:36:09.000]   Yeah, I've been freezing for the last 20 years.
[00:36:09.000 --> 00:36:10.000]   It's kind of...
[00:36:10.000 --> 00:36:15.000]   We learned early on not to use those iPhone headphones as microphones,
[00:36:15.000 --> 00:36:18.000]   and I still see that on CNN and MSNBC's screen.
[00:36:18.000 --> 00:36:22.000]   But Steve, I'm also really happy about two things.
[00:36:22.000 --> 00:36:25.000]   One is they're finally getting some new voices,
[00:36:25.000 --> 00:36:28.000]   and people don't have to go to the studio and that doesn't make it limiting.
[00:36:28.000 --> 00:36:34.000]   And two, we get to see their homes, and that gives us rape by Skype Room, which makes me really happy.
[00:36:34.000 --> 00:36:44.000]   Jeff is happy about this, because he is one of the few to get 10 out of 10 on the Skype Room radar on Twitter.
[00:36:44.000 --> 00:36:47.000]   I wasn't door there, Leo, but thank you for mentioning that.
[00:36:47.000 --> 00:36:54.000]   This has been the most fun on Twitter of all, I think, is following a rape by Skype Room.
[00:36:54.000 --> 00:37:01.000]   In fact, sometimes you recognize obscure hosts by their background.
[00:37:01.000 --> 00:37:06.000]   It's like, "Oh, I remember that guy. He's got the weird bookcase."
[00:37:06.000 --> 00:37:07.000]   It's like, "Oh, okay, yeah."
[00:37:07.000 --> 00:37:10.000]   Oh, the guy with the speak and say in the background, Steve?
[00:37:10.000 --> 00:37:16.000]   Or the blink and lights in the background?
[00:37:16.000 --> 00:37:17.000]   Yeah.
[00:37:17.000 --> 00:37:24.000]   And this is something you always celebrate, Jeff, about the Internet.
[00:37:24.000 --> 00:37:31.000]   It is democratizing, because everybody's got a TV studio now in their house for better or for worse.
[00:37:31.000 --> 00:37:35.000]   Which I think it's generally better for TV.
[00:37:35.000 --> 00:37:39.000]   The other part of this story that I talked about on Twig,
[00:37:39.000 --> 00:37:46.000]   that I think is my favorite story of the year, is how science and medicine adapted to this open information ecosystem.
[00:37:46.000 --> 00:37:53.000]   Yes, at first we were getting a lot of preprints and bad info kind of treated as if it had been peer reviewed.
[00:37:53.000 --> 00:37:55.000]   But we learned, didn't we?
[00:37:55.000 --> 00:38:02.000]   Well, now the people I follow, and I have a COVID Twitter list, bit me slash COVID Twitter list, if you're interested,
[00:38:02.000 --> 00:38:07.000]   where I have 600 experts and they peer review papers on Twitter.
[00:38:07.000 --> 00:38:08.000]   Wow.
[00:38:08.000 --> 00:38:09.000]   What do you do?
[00:38:09.000 --> 00:38:14.000]   And top experts who I trust immensely go on there.
[00:38:14.000 --> 00:38:23.000]   So today there was a controversy where various privileged white male journalist armed chair epidemiologist were criticizing
[00:38:23.000 --> 00:38:26.000]   CDC proposals for who should go next.
[00:38:26.000 --> 00:38:37.000]   And Dr. Gregg Consolvus, who's a top Yale epidemiologist, comes on and says why they're wrong and how, with a lot of SNARK too, which I enjoy.
[00:38:37.000 --> 00:38:48.000]   And I'm looking for what's happening in the UK with the variants now in the genome of the virus and is it really a problem or not?
[00:38:48.000 --> 00:38:55.000]   I go immediately to my Twitter list and this woman named Emma Hoddcroft, who's been studying this out of Switzerland, who's brilliant about it,
[00:38:55.000 --> 00:38:57.000]   who says well here's what we know and here's what we don't know.
[00:38:57.000 --> 00:39:03.000]   Science is coming directly to the people thanks to believe it or not, Twitter.
[00:39:03.000 --> 00:39:07.000]   Which you have two COVID list, COVID community and COVID.
[00:39:07.000 --> 00:39:09.000]   It's COVID.
[00:39:09.000 --> 00:39:12.000]   Or the easiest one is Bitly slash COVID Twitter.
[00:39:12.000 --> 00:39:13.000]   Right.
[00:39:13.000 --> 00:39:18.000]   632 people and these are all people you've vetted as somebody reliable or trustworthy.
[00:39:18.000 --> 00:39:27.000]   Yeah, sometimes people go off the list, but I trust the people I trust and it's interesting how it was not that difficult to get out, maybe two runs.
[00:39:27.000 --> 00:39:28.000]   I stopped there.
[00:39:28.000 --> 00:39:30.000]   There's Emma Hoddcroft right there.
[00:39:30.000 --> 00:39:35.000]   All of the criticism I give and others give social media.
[00:39:35.000 --> 00:39:46.000]   This is a really interesting example of how the internet can organize information and make it useful kind of autonomous.
[00:39:46.000 --> 00:39:48.000]   The way we thought it was going to be?
[00:39:48.000 --> 00:39:49.000]   Yeah.
[00:39:49.000 --> 00:39:59.000]   Well, it used to be you have editors and curators and people would self designate, but somehow this is self organized in a way that's actually become a great and useful ecosystem.
[00:39:59.000 --> 00:40:04.000]   Unfortunately, it's gone both ways because there's also QAnon and anti-vaxxers and all sorts of other.
[00:40:04.000 --> 00:40:19.000]   We're trying to invent new institutions of credibility, but I talked to one to a Columbia virologist, Angela Rasmussen, who said that during the SARS COVID, the last SARS outbreak, papers took a year to get out because of peer review.
[00:40:19.000 --> 00:40:20.000]   Right.
[00:40:20.000 --> 00:40:22.000]   And we couldn't afford that now.
[00:40:22.000 --> 00:40:28.000]   Imagine the speed with which the science and the data passed around and the reviews of it.
[00:40:28.000 --> 00:40:31.000]   It's been critical to learning more.
[00:40:31.000 --> 00:40:39.000]   One of the concerns early on was that people with money were escaping.
[00:40:39.000 --> 00:40:41.000]   In fact, there was the article.
[00:40:41.000 --> 00:40:45.000]   I think we talked about it from Douglas Rushkoff at the end of the summer.
[00:40:45.000 --> 00:40:49.000]   The privileged have entered their escaped pods.
[00:40:49.000 --> 00:40:51.000]   Is that still the case?
[00:40:51.000 --> 00:40:55.000]   It seems like there's nowhere you can go that's completely safe.
[00:40:55.000 --> 00:40:58.000]   Now they're going to buy their shots probably.
[00:40:58.000 --> 00:41:01.000]   Yeah, well, that's also a possibility.
[00:41:01.000 --> 00:41:05.000]   Preppers and survivalists said, "See?
[00:41:05.000 --> 00:41:07.000]   We told you.
[00:41:07.000 --> 00:41:08.000]   I'll see.
[00:41:08.000 --> 00:41:09.000]   I'll go."
[00:41:09.000 --> 00:41:14.000]   Just because the disaster happened doesn't mean extremism works.
[00:41:14.000 --> 00:41:21.000]   But there are people we've talked about for a long time.
[00:41:21.000 --> 00:41:33.000]   Decommissioned nuclear missile silos that people had turned into escaped pods, little small underground
[00:41:33.000 --> 00:41:36.800]   apartment complexes that you'd pay millions of dollars to get into that would have their
[00:41:36.800 --> 00:41:38.520]   own private guard service.
[00:41:38.520 --> 00:41:44.000]   And I think there were some people actually moved to these silos.
[00:41:44.000 --> 00:41:46.000]   I was Peter Teal these days.
[00:41:46.000 --> 00:41:47.000]   Yeah.
[00:41:47.000 --> 00:41:49.000]   But I think they're out of there by now.
[00:41:49.000 --> 00:41:53.000]   And it turned out most people just went to Barbados.
[00:41:53.000 --> 00:41:55.000]   If you want to do it cheaply, just move to Vermont.
[00:41:55.000 --> 00:41:56.000]   Or Vermont.
[00:41:56.000 --> 00:41:58.000]   Vermont's a little chilly right now.
[00:41:58.000 --> 00:41:59.000]   I prefer Barbados.
[00:41:59.000 --> 00:42:01.600]   It's also a little safe.
[00:42:01.600 --> 00:42:08.800]   One of the things though that did definitely happen because of the virus is that the social
[00:42:08.800 --> 00:42:14.920]   contract kind of fractured and the fault lines that have been here all along really showed
[00:42:14.920 --> 00:42:20.800]   up, the difference in the haves and the have-nots, the kids who had fast internet and had laptop
[00:42:20.800 --> 00:42:27.160]   computers and the kids who were forced to take beat up old Android devices to the Taco
[00:42:27.160 --> 00:42:32.160]   Bell parking lot to use their free Wi-Fi so that they could go to school.
[00:42:32.160 --> 00:42:34.800]   That became very clear.
[00:42:34.800 --> 00:42:38.200]   And I'm hoping that the result of that will be that we'll do something about it instead
[00:42:38.200 --> 00:42:43.360]   of just muddle through until it's over and then go back to the same old, same old.
[00:42:43.360 --> 00:42:50.480]   You know Leo, it strikes me that the latest cruel paradox is that as we all know now,
[00:42:50.480 --> 00:42:57.400]   and too late, African-Americans, people of color, Latinos are the worst hit by this pandemic.
[00:42:57.400 --> 00:43:03.200]   Yet when it comes time to stand in line for the vaccine, when maybe the political will
[00:43:03.200 --> 00:43:08.240]   would finally give them the first shot, of course having been so distrustful for a good
[00:43:08.240 --> 00:43:10.960]   reason, they're going to lose out again.
[00:43:10.960 --> 00:43:11.960]   Yeah.
[00:43:11.960 --> 00:43:17.400]   And it's just the systemic racism just hits you from every which way.
[00:43:17.400 --> 00:43:24.520]   Well, and it goes back to the Tuskegee Project, Tuskegee Project where thousands of black
[00:43:24.520 --> 00:43:28.920]   men or hundreds of black men were not treated for syphilis and not told they were not being
[00:43:28.920 --> 00:43:32.160]   treated for syphilis so we could see what would happen.
[00:43:32.160 --> 00:43:34.920]   And it continued into the 70s.
[00:43:34.920 --> 00:43:40.720]   And so as a result, I think a lot of blacks and other people of color are very reluctant
[00:43:40.720 --> 00:43:46.600]   to trust public health when maybe now's the time to do it.
[00:43:46.600 --> 00:43:51.360]   If there's anything good that came out of it, you could say, "Quibi, the failure of
[00:43:51.360 --> 00:43:52.360]   Quibi."
[00:43:52.360 --> 00:43:57.800]   Quibi was an attempt.
[00:43:57.800 --> 00:43:58.800]   It's overwhelming.
[00:43:58.800 --> 00:44:02.280]   It will be a punchline for a long time, won't it?
[00:44:02.280 --> 00:44:06.240]   It's like, just say, "Quibi, you know, like so many things, the pandemic accelerates
[00:44:06.240 --> 00:44:07.240]   things."
[00:44:07.240 --> 00:44:09.320]   And that's one of the things that accelerated was Quibi failing.
[00:44:09.320 --> 00:44:11.080]   The failure of Quibi.
[00:44:11.080 --> 00:44:14.240]   I wonder, there's been a lot of talk about the end of cities.
[00:44:14.240 --> 00:44:21.560]   And after or during COVID oracle, Tesla, a number of companies moved to Texas out of
[00:44:21.560 --> 00:44:23.920]   California.
[00:44:23.920 --> 00:44:28.320]   There was, remember the article saying New York is over?
[00:44:28.320 --> 00:44:30.520]   People were leaving the city and never going to come back.
[00:44:30.520 --> 00:44:31.520]   Not true, is it?
[00:44:31.520 --> 00:44:32.520]   No.
[00:44:32.520 --> 00:44:33.520]   Mr. New Yorker.
[00:44:33.520 --> 00:44:34.520]   Wait a minute, you're living in the burbs.
[00:44:34.520 --> 00:44:35.520]   You're living in New Jersey.
[00:44:35.520 --> 00:44:36.520]   No, I don't listen to me.
[00:44:36.520 --> 00:44:38.520]   I'm out here at the woods.
[00:44:38.520 --> 00:44:44.680]   But I think that it's clear that the world will be different when we come out of this
[00:44:44.680 --> 00:44:46.360]   whenever we come out of this.
[00:44:46.360 --> 00:44:52.280]   I wonder if people will move back to San Francisco and New York City or if these exoduses are
[00:44:52.280 --> 00:44:55.040]   permanent and at the beginning of something even larger.
[00:44:55.040 --> 00:44:57.520]   But isn't it more than cities, isn't it offices?
[00:44:57.520 --> 00:44:58.520]   Yeah.
[00:44:58.520 --> 00:45:04.680]   Well, Google has said now, "Not only do you not have to come back to the fall of 2021,
[00:45:04.680 --> 00:45:09.680]   but a good portion of your work can be done remotely, even if you do come back."
[00:45:09.680 --> 00:45:14.040]   Twitter said you never have to come back.
[00:45:14.040 --> 00:45:19.960]   One of the things that we talk about on security now often is the great power of inertia.
[00:45:19.960 --> 00:45:28.120]   And I think if nothing else, this shook things and forced people to see whether they could,
[00:45:28.120 --> 00:45:34.480]   for example, need to go into, you know, spend hours a day on the freeway commuting to go
[00:45:34.480 --> 00:45:37.480]   to the office or if they couldn't get the job done at home.
[00:45:37.480 --> 00:45:44.240]   And so before this horrible pandemic, people were doing things that they had always been
[00:45:44.240 --> 00:45:46.360]   doing for a long time.
[00:45:46.360 --> 00:45:51.120]   In some cases, retailers were still in business just because they had been in business the
[00:45:51.120 --> 00:45:53.520]   year before and the year before that.
[00:45:53.520 --> 00:45:58.160]   But there wasn't any real reason for them to remain in business except inertia.
[00:45:58.160 --> 00:46:00.160]   So this has sort of shaken everything.
[00:46:00.160 --> 00:46:05.080]   And it'll be interesting to see it as you say, Leo, my guess is we will not be returning
[00:46:05.080 --> 00:46:06.480]   to where we were.
[00:46:06.480 --> 00:46:13.600]   We'll be returning to where we need to be after the pressure to change has been lifted.
[00:46:13.600 --> 00:46:17.880]   We'll be somewhere else and actually probably better.
[00:46:17.880 --> 00:46:21.280]   Certainly the big tech leapt into the fray by April.
[00:46:21.280 --> 00:46:27.400]   Apple and Google announced an API for COVID tracking that they were going to build into
[00:46:27.400 --> 00:46:30.160]   iOS and Android a few months later.
[00:46:30.160 --> 00:46:31.680]   It did in fact ship.
[00:46:31.680 --> 00:46:36.080]   Initially, they said it'll be designed to support the apps that government and health
[00:46:36.080 --> 00:46:39.560]   officials might want to make for COVID tracking.
[00:46:39.560 --> 00:46:45.560]   But now, at least in some places here in California, the Apple system works without an app.
[00:46:45.560 --> 00:46:50.800]   But I put works in their quotes because it doesn't seem to do anything at all as far
[00:46:50.800 --> 00:46:53.000]   as I can tell.
[00:46:53.000 --> 00:46:57.280]   And a lot of people were very suspicious of Apple and Google and the idea that they might
[00:46:57.280 --> 00:46:58.960]   put tracking into a phone.
[00:46:58.960 --> 00:47:05.760]   Do you think that big tech is using or has used COVID as an excuse to enhance their or
[00:47:05.760 --> 00:47:10.440]   government for that matter, enhance the tracking of people to spy more?
[00:47:10.440 --> 00:47:14.200]   And do you think that will go back to normal after this over?
[00:47:14.200 --> 00:47:16.280]   Or will they say now that they're in the phones?
[00:47:16.280 --> 00:47:17.280]   Oh, good.
[00:47:17.280 --> 00:47:18.280]   We're going to stay here.
[00:47:18.280 --> 00:47:19.840]   There's definitely been concern among some people.
[00:47:19.840 --> 00:47:23.840]   I know, Jeff, you probably don't a crappy job of it so far.
[00:47:23.840 --> 00:47:24.840]   I know.
[00:47:24.840 --> 00:47:25.840]   Yeah.
[00:47:25.840 --> 00:47:30.480]   I think I remember it was in our best of on why COVID trackers won't work.
[00:47:30.480 --> 00:47:31.800]   Can't wait.
[00:47:31.800 --> 00:47:39.280]   And I guess my feeling is that the technology is now in iOS and Android and it may be good
[00:47:39.280 --> 00:47:45.840]   for us to have it for next time because all of the people who know this stuff are looking
[00:47:45.840 --> 00:47:53.160]   at the intervals between these sorts of epidemic outbreaks and they're noticing that the intervals
[00:47:53.160 --> 00:47:54.720]   are decreasing.
[00:47:54.720 --> 00:47:56.520]   These are happening more frequently.
[00:47:56.520 --> 00:47:59.280]   We keep hearing this will not be the last one.
[00:47:59.280 --> 00:48:07.400]   So I think if nothing else, you know, this is proven to be horrible, but not the end
[00:48:07.400 --> 00:48:11.360]   of humankind, we'd like to prevent the end of humankind.
[00:48:11.360 --> 00:48:17.920]   So I would say we're in far better condition for preparedness next time.
[00:48:17.920 --> 00:48:19.480]   This all got everybody's attention.
[00:48:19.480 --> 00:48:25.360]   In fact, that you got to wear a mask wherever you go outside and even among your own family
[00:48:25.360 --> 00:48:27.400]   members, that's a wake up call.
[00:48:27.400 --> 00:48:32.920]   It does feel like maybe we've gotten used to it and maybe we've made some progress.
[00:48:32.920 --> 00:48:35.960]   This was a rehearsal and we'll be ready next time.
[00:48:35.960 --> 00:48:42.680]   At the same time, don't you think Paul, if Apple and Google leave these APIs turned on,
[00:48:42.680 --> 00:48:47.280]   they'll be a hue and cry in six months, people saying, why is it still on the phone?
[00:48:47.280 --> 00:48:48.920]   Yeah, of course.
[00:48:48.920 --> 00:48:52.440]   But I've had the same experience.
[00:48:52.440 --> 00:48:56.240]   I mean, you kind of take a little survey every couple of days on your phone for some
[00:48:56.240 --> 00:48:57.240]   reason.
[00:48:57.240 --> 00:48:58.240]   It doesn't seem to do anything.
[00:48:58.240 --> 00:48:59.240]   So I don't quite...
[00:48:59.240 --> 00:49:01.920]   I turned on the California version.
[00:49:01.920 --> 00:49:02.920]   I haven't gotten any more.
[00:49:02.920 --> 00:49:05.800]   Yeah, the efficacy of this is not clear.
[00:49:05.800 --> 00:49:10.160]   But yeah, I mean, there are always going to be people who trust and just think this is
[00:49:10.160 --> 00:49:12.920]   a good thing and don't worry about it, just like they don't worry about their own privacy
[00:49:12.920 --> 00:49:13.920]   online.
[00:49:13.920 --> 00:49:18.840]   And then there are going to be the people who won't trust anything at any time.
[00:49:18.840 --> 00:49:19.840]   I don't know.
[00:49:19.840 --> 00:49:23.920]   It's a basic trust, but verify situation, I think.
[00:49:23.920 --> 00:49:28.560]   The other, I think, big technology story around COVID is the mRNA vaccines.
[00:49:28.560 --> 00:49:31.480]   These are very advanced high-tech vaccines.
[00:49:31.480 --> 00:49:38.600]   In fact, I think a number of AIs were early on assigned the project of figuring out how
[00:49:38.600 --> 00:49:43.280]   to create a synthetic vaccine against COVID-19.
[00:49:43.280 --> 00:49:45.160]   And it worked.
[00:49:45.160 --> 00:49:48.120]   It worked.
[00:49:48.120 --> 00:49:49.720]   I really want to address that.
[00:49:49.720 --> 00:49:53.240]   I know none of you are biotech, guys.
[00:49:53.240 --> 00:49:54.240]   But this is a great...
[00:49:54.240 --> 00:49:56.560]   Not at all, but I think it's important.
[00:49:56.560 --> 00:49:59.920]   There's been suspicion that Jesus happened so quickly.
[00:49:59.920 --> 00:50:06.200]   But again, I think that the internet had an impact there, where there was AI, there was
[00:50:06.200 --> 00:50:10.760]   data, there was preparation, but it was also easier to put together the tests.
[00:50:10.760 --> 00:50:15.360]   The actual testing was still to spec from everything I can see, but everything else
[00:50:15.360 --> 00:50:17.520]   got truncated around it.
[00:50:17.520 --> 00:50:22.000]   Well, also, the fact that it really didn't happen quickly, it took more than a decade
[00:50:22.000 --> 00:50:26.880]   because the vaccines that we're using now from Moderna and Pfizer are based on vaccines
[00:50:26.880 --> 00:50:32.480]   for the original SARS epidemic that were created in the early 2000s.
[00:50:32.480 --> 00:50:35.760]   This was a technology that they've been working on ever since.
[00:50:35.760 --> 00:50:40.720]   So in a way, we're kind of lucked out that SARS happened, which is a very closely related
[00:50:40.720 --> 00:50:43.160]   virus.
[00:50:43.160 --> 00:50:46.320]   And the mRNA vaccines development began then.
[00:50:46.320 --> 00:50:53.200]   In fact, credit to the researcher who came up with the notion and was demoted at her
[00:50:53.200 --> 00:50:55.800]   university because they said, "Oh, that'll never work."
[00:50:55.800 --> 00:51:04.200]   I'm going to see if I can find her name because here it is.
[00:51:04.200 --> 00:51:11.240]   This is from STAT, the story of mRNA, how a once dismissed idea became a leading technology
[00:51:11.240 --> 00:51:15.320]   in the COVID vaccine race.
[00:51:15.320 --> 00:51:21.120]   And the both vaccines come from research that was done many years ago.
[00:51:21.120 --> 00:51:23.320]   Let me see if I can find her name.
[00:51:23.320 --> 00:51:29.440]   Katalin Karikou spent the '90s collecting rejections, her work attempting to harness
[00:51:29.440 --> 00:51:35.040]   the power of messenger RNA to fight disease was too far fetched for government grants,
[00:51:35.040 --> 00:51:41.920]   corporate funding, even support from her own colleagues.
[00:51:41.920 --> 00:51:47.160]   She did not give up, even though after six years in the faculty of various events of
[00:51:47.160 --> 00:51:50.080]   Pennsylvania, she was demoted in 1995.
[00:51:50.080 --> 00:51:54.080]   She'd been on the path to full professorship, but with no money coming into support or work
[00:51:54.080 --> 00:51:58.680]   on mRNA, her boss is so no point in pressing on.
[00:51:58.680 --> 00:52:04.800]   She was back to the lower rungs of the scientific academy.
[00:52:04.800 --> 00:52:06.840]   She kept working on it.
[00:52:06.840 --> 00:52:14.040]   And in fact, it was her research that eventually made its way to Pfizer and Moderna.
[00:52:14.040 --> 00:52:19.200]   Key discovery, Karikou and Weismann figured out if you incorporate modified nucleosides
[00:52:19.200 --> 00:52:22.400]   into mRNA, you can kill two birds with one stone.
[00:52:22.400 --> 00:52:28.520]   That research paper came out in 2005, so she'd been working on it for 25 years.
[00:52:28.520 --> 00:52:31.000]   The pioneers always get the arrows in their back.
[00:52:31.000 --> 00:52:32.000]   Yeah.
[00:52:32.000 --> 00:52:35.040]   Especially in Revan.
[00:52:35.040 --> 00:52:39.160]   There's some talk that they both deserve a Nobel Prize in Chemistry, or maybe medicine.
[00:52:39.160 --> 00:52:42.840]   I wouldn't be surprised if they did.
[00:52:42.840 --> 00:52:48.120]   So yeah, it seems like it happened really fast, but yes, as always, there was some researcher
[00:52:48.120 --> 00:52:54.320]   in a closet somewhere at the University of Pennsylvania had been working on it since 1995.
[00:52:54.320 --> 00:52:58.000]   But again, that's technology, that's science, and it's pretty amazing.
[00:52:58.000 --> 00:53:03.560]   There was early on a lot of news about, of course, Black Lives Matter and the death of
[00:53:03.560 --> 00:53:05.600]   George Floyd was this year.
[00:53:05.600 --> 00:53:13.920]   And the protests in Minnesota, violent protests, according to boy genius report, Minnesota
[00:53:13.920 --> 00:53:21.520]   was using contact tracing to track protesters as the Minnesota protests escalated.
[00:53:21.520 --> 00:53:28.960]   We didn't hear much more about that, but nobody had the darn tracking app, so it probably
[00:53:28.960 --> 00:53:30.760]   didn't work very well.
[00:53:30.760 --> 00:53:32.260]   Right.
[00:53:32.260 --> 00:53:35.160]   Maybe that was it.
[00:53:35.160 --> 00:53:37.280]   All right.
[00:53:37.280 --> 00:53:38.280]   Enough of COVID.
[00:53:38.280 --> 00:53:39.280]   We've had enough.
[00:53:39.280 --> 00:53:40.280]   2021.
[00:53:40.280 --> 00:53:42.200]   It's a good story of 2020.
[00:53:42.200 --> 00:53:48.440]   It's not been really, it's not been good news has it?
[00:53:48.440 --> 00:53:51.320]   Work from home, certainly because of COVID, we learned how to work from home.
[00:53:51.320 --> 00:53:53.320]   And that might end up being good news.
[00:53:53.320 --> 00:53:56.440]   That might change the way we think of work.
[00:53:56.440 --> 00:54:03.820]   Certainly for us at Twit, we sent all our employees home late February, early March.
[00:54:03.820 --> 00:54:08.480]   They haven't come back except for the absolutely essential engineers who have to push the buttons
[00:54:08.480 --> 00:54:10.780]   and run the machinery.
[00:54:10.780 --> 00:54:12.780]   And that's worked out all right.
[00:54:12.780 --> 00:54:14.700]   It's not been perfect.
[00:54:14.700 --> 00:54:16.220]   You guys all work so many ways.
[00:54:16.220 --> 00:54:17.220]   So yeah, right.
[00:54:17.220 --> 00:54:19.260]   I've been working from home for 25 years.
[00:54:19.260 --> 00:54:24.140]   I mean, I, it's been interesting to watch the rest of the world kind of go through these
[00:54:24.140 --> 00:54:27.620]   issues that I kind of dealt with a long time ago.
[00:54:27.620 --> 00:54:29.540]   And some people can and some people can't.
[00:54:29.540 --> 00:54:30.540]   Some people prefer it.
[00:54:30.540 --> 00:54:31.640]   Some people won't.
[00:54:31.640 --> 00:54:35.340]   I think like Steve said, you know, the future is going to look different, but it's going
[00:54:35.340 --> 00:54:38.420]   to be a hybrid work world, I think.
[00:54:38.420 --> 00:54:43.020]   And I think the Google schedule is particularly interesting for people who can do that where
[00:54:43.020 --> 00:54:46.420]   you don't have to come in the office every day, but maybe you come in once a week or once
[00:54:46.420 --> 00:54:48.100]   every two weeks or whatever it is.
[00:54:48.100 --> 00:54:51.340]   Jeff, you're teaching remotely, right?
[00:54:51.340 --> 00:54:52.840]   You could do that.
[00:54:52.840 --> 00:54:56.540]   So you have, you do your classes from the house and zoom.
[00:54:56.540 --> 00:54:58.220]   How's that been?
[00:54:58.220 --> 00:55:02.220]   I actually think that it's generally okay that the problems the students have don't have
[00:55:02.220 --> 00:55:03.540]   to do with the classroom time.
[00:55:03.540 --> 00:55:05.860]   They have to do, you know, they're, they're journalists.
[00:55:05.860 --> 00:55:09.460]   So they wanted to be out on the street and we teach them to go and show up and be with
[00:55:09.460 --> 00:55:10.460]   people.
[00:55:10.460 --> 00:55:12.460]   And now we say, no, don't show up.
[00:55:12.460 --> 00:55:13.460]   Maybe not.
[00:55:13.460 --> 00:55:14.460]   Stay home.
[00:55:14.460 --> 00:55:15.460]   Yeah.
[00:55:15.460 --> 00:55:20.580]   You know, for, for, you know, running a, having helped start a program in social journalism,
[00:55:20.580 --> 00:55:26.840]   this is its time because finding people online and connecting with them through social media,
[00:55:26.840 --> 00:55:28.600]   that's what you have to do.
[00:55:28.600 --> 00:55:30.640]   So they leave with a greater expertise in that.
[00:55:30.640 --> 00:55:33.000]   So I, I've told them all, they had some rough times.
[00:55:33.000 --> 00:55:37.040]   They had some tender moments, but I've told them all they're going to end up just being
[00:55:37.040 --> 00:55:42.760]   so darn resilient from this that they're going to be able to face lots of things in
[00:55:42.760 --> 00:55:43.760]   life.
[00:55:43.760 --> 00:55:45.840]   You're teaching older students, graduate students.
[00:55:45.840 --> 00:55:49.640]   Do you think they're better or worse able to do this?
[00:55:49.640 --> 00:55:51.540]   Well, I think, I think probably better.
[00:55:51.540 --> 00:55:52.540]   Yeah.
[00:55:52.540 --> 00:55:53.540]   Cause they're all.
[00:55:53.540 --> 00:55:56.220]   My daughter is in graduate school in Canada from upstairs.
[00:55:56.220 --> 00:56:00.480]   And you know, shh, shh, I think it would have been an undergrad for her that would have
[00:56:00.480 --> 00:56:01.480]   been a lot rougher.
[00:56:01.480 --> 00:56:02.480]   This is the structures different.
[00:56:02.480 --> 00:56:03.480]   The expectations.
[00:56:03.480 --> 00:56:05.660]   A lot of what college sells is not education.
[00:56:05.660 --> 00:56:06.660]   It's socialization.
[00:56:06.660 --> 00:56:07.660]   It's city up.
[00:56:07.660 --> 00:56:08.660]   It's an experience.
[00:56:08.660 --> 00:56:11.780]   It's a halfway house for teenagers, basically.
[00:56:11.780 --> 00:56:12.780]   It's no rose.
[00:56:12.780 --> 00:56:13.780]   No rose.
[00:56:13.780 --> 00:56:14.780]   No rose.
[00:56:14.780 --> 00:56:15.780]   No rose.
[00:56:15.780 --> 00:56:16.780]   No rose.
[00:56:16.780 --> 00:56:17.780]   No rose.
[00:56:17.780 --> 00:56:18.780]   It's one of those.
[00:56:18.780 --> 00:56:19.780]   Yeah.
[00:56:19.780 --> 00:56:21.520]   But she's going to school, which is interesting.
[00:56:21.520 --> 00:56:22.520]   Yeah.
[00:56:22.520 --> 00:56:23.520]   Yeah.
[00:56:23.520 --> 00:56:27.820]   So she actually just flew home today for the break and you know, she's only had one
[00:56:27.820 --> 00:56:29.800]   class this past semester that was in person.
[00:56:29.800 --> 00:56:31.160]   It was a lab class.
[00:56:31.160 --> 00:56:37.880]   So she went to UNC and stayed on campus but was doing the classes remotely anyway.
[00:56:37.880 --> 00:56:38.880]   Right.
[00:56:38.880 --> 00:56:39.880]   But you know what?
[00:56:39.880 --> 00:56:45.080]   From our perspective as her parents, we still wanted that for her because there's still
[00:56:45.080 --> 00:56:50.300]   things she can do that she can socialize with people that the people she lives with,
[00:56:50.300 --> 00:56:54.780]   you know, the people on campus and she still gets, it's kind of like a starter college
[00:56:54.780 --> 00:56:55.780]   experience.
[00:56:55.780 --> 00:56:58.020]   And then when things open up, you know, she'll get more of the normal.
[00:56:58.020 --> 00:56:59.220]   Is she a freshman?
[00:56:59.220 --> 00:57:00.220]   Yeah.
[00:57:00.220 --> 00:57:02.820]   So this, she had no other experience of college anyway.
[00:57:02.820 --> 00:57:03.820]   Yeah.
[00:57:03.820 --> 00:57:05.580]   I mean, she didn't have a real graduation.
[00:57:05.580 --> 00:57:06.580]   She didn't have a prom.
[00:57:06.580 --> 00:57:07.580]   She didn't have a prom.
[00:57:07.580 --> 00:57:11.820]   Her start of college was delayed by two, three weeks, I guess.
[00:57:11.820 --> 00:57:12.820]   How did she fly?
[00:57:12.820 --> 00:57:14.920]   It was just, we just wanted it to work, you know?
[00:57:14.920 --> 00:57:15.920]   Yeah.
[00:57:15.920 --> 00:57:17.320]   How does she like what she's doing?
[00:57:17.320 --> 00:57:18.320]   I mean, is it okay?
[00:57:18.320 --> 00:57:19.320]   She loves it.
[00:57:19.320 --> 00:57:20.320]   She loves it.
[00:57:20.320 --> 00:57:21.320]   Yeah, it worked out.
[00:57:21.320 --> 00:57:24.980]   So you think about this, I mean, she's in a dorm where there's two bedrooms that would
[00:57:24.980 --> 00:57:29.180]   normally have two kids in each and an extra room in a bathroom and everything.
[00:57:29.180 --> 00:57:30.940]   And there's just two of them in there.
[00:57:30.940 --> 00:57:32.460]   And so she has a room to herself.
[00:57:32.460 --> 00:57:34.100]   Her roommate has a room to herself.
[00:57:34.100 --> 00:57:35.100]   She's so spoiled.
[00:57:35.100 --> 00:57:36.100]   You're living in a light.
[00:57:36.100 --> 00:57:38.980]   Yeah, it's a luxury situation that's not going to be duplicated next year.
[00:57:38.980 --> 00:57:40.620]   She's going to hate it next year.
[00:57:40.620 --> 00:57:41.620]   I know.
[00:57:41.620 --> 00:57:42.620]   I know.
[00:57:42.620 --> 00:57:45.520]   I have to get an apartment off campus.
[00:57:45.520 --> 00:57:46.520]   Yeah.
[00:57:46.520 --> 00:57:48.920]   I think that was the beginning of the end of my college experience.
[00:57:48.920 --> 00:57:51.120]   As soon as I realized I could live off campus, that was it.
[00:57:51.120 --> 00:57:52.120]   It was over.
[00:57:52.120 --> 00:57:53.120]   Exactly.
[00:57:53.120 --> 00:57:55.520]   But I think that on campus experience is important.
[00:57:55.520 --> 00:58:00.320]   And I think there's a reason why so many colleges require it, right?
[00:58:00.320 --> 00:58:04.120]   Of, I'd say, you know, you can't have an apartment the first year in any cases.
[00:58:04.120 --> 00:58:05.120]   And that's true.
[00:58:05.120 --> 00:58:06.120]   And that's true.
[00:58:06.120 --> 00:58:07.120]   Yeah.
[00:58:07.120 --> 00:58:12.320]   Do you, did the three of you think that fall will start to look like normal?
[00:58:12.320 --> 00:58:14.320]   Will be back in things like classes and offices?
[00:58:14.320 --> 00:58:22.420]   I can only quote my hero, Dr. Fauci, who says, will be enjoying NFL games in the fall.
[00:58:22.420 --> 00:58:23.820]   So he thinks.
[00:58:23.820 --> 00:58:26.220]   You have Mark Cuban, who owns the...
[00:58:26.220 --> 00:58:27.220]   He might own drugs.
[00:58:27.220 --> 00:58:28.220]   ...of the NBA team.
[00:58:28.220 --> 00:58:29.220]   Yeah.
[00:58:29.220 --> 00:58:30.220]   Really?
[00:58:30.220 --> 00:58:31.220]   I actually think he's a really smart guy.
[00:58:31.220 --> 00:58:35.320]   But he was saying that his, and he talks to experts, he reads up on everything.
[00:58:35.320 --> 00:58:41.020]   And his view of this coming NBA season is that they're going to start the season with
[00:58:41.020 --> 00:58:42.620]   empty stadiums.
[00:58:42.620 --> 00:58:47.020]   And that there's going to be some kind of inflection point in March or April.
[00:58:47.020 --> 00:58:48.940]   And they'll be able to start letting people back in.
[00:58:48.940 --> 00:58:52.260]   And he's not saying they'll be full exactly, but by the time the season ends, probably
[00:58:52.260 --> 00:58:58.620]   mid-summer next year, we're going to be approaching normal, you know, between vaccinations and
[00:58:58.620 --> 00:59:00.120]   whatever else.
[00:59:00.120 --> 00:59:01.120]   So, you know, we'll see.
[00:59:01.120 --> 00:59:02.120]   What do you think?
[00:59:02.120 --> 00:59:04.660]   There's been such an anti-vax movement.
[00:59:04.660 --> 00:59:09.340]   There were people, there were conspiracy theories who said the vaccine was Bill Gates' attempt
[00:59:09.340 --> 00:59:14.220]   to inject some sort of device in your body so he could track you.
[00:59:14.220 --> 00:59:15.220]   I mean, they're crazy.
[00:59:15.220 --> 00:59:18.140]   You thought he was all good now.
[00:59:18.140 --> 00:59:19.140]   He's not.
[00:59:19.140 --> 00:59:20.140]   It's the same old Bill Gates.
[00:59:20.140 --> 00:59:24.300]   Do you think people will change their tune and get vaccinated?
[00:59:24.300 --> 00:59:25.300]   Yes.
[00:59:25.300 --> 00:59:26.300]   I think so too.
[00:59:26.300 --> 00:59:27.300]   I hope it's good.
[00:59:27.300 --> 00:59:28.300]   I do.
[00:59:28.300 --> 00:59:29.300]   I hope it's good.
[00:59:29.300 --> 00:59:30.300]   Yeah.
[00:59:30.300 --> 00:59:31.300]   Yeah.
[00:59:31.300 --> 00:59:32.500]   No, because when push comes to shove, you can have...
[00:59:32.500 --> 00:59:34.860]   I mean, there'll always be some percentage, obviously.
[00:59:34.860 --> 00:59:41.180]   But, you know, vaccination is what's standing between you and normal.
[00:59:41.180 --> 00:59:42.940]   It's such a small price to pay.
[00:59:42.940 --> 00:59:43.940]   It's not even price-
[00:59:43.940 --> 00:59:47.740]   These members of Congress who've been doubtful were rushing to get it.
[00:59:47.740 --> 00:59:48.740]   Yeah.
[00:59:48.740 --> 00:59:49.740]   Oh, yeah, yeah.
[00:59:49.740 --> 00:59:53.340]   The hypocrites are the first in line all the time.
[00:59:53.340 --> 00:59:55.340]   Yeah.
[00:59:55.340 --> 00:59:56.340]   It's...
[00:59:56.340 --> 01:00:00.660]   Public health says it's roughly 70 to 80 percent of the population has to get immunity
[01:00:00.660 --> 01:00:05.140]   of some kind vaccinated or somehow for it to work.
[01:00:05.140 --> 01:00:06.780]   Yeah.
[01:00:06.780 --> 01:00:07.780]   You know what?
[01:00:07.780 --> 01:00:09.220]   I bet you 70 percent...
[01:00:09.220 --> 01:00:11.020]   I bet you get the vaccine.
[01:00:11.020 --> 01:00:12.100]   I think when it comes down to...
[01:00:12.100 --> 01:00:17.060]   It's easy and abstract to say, "I'm not going to let Bill Gates track me in my arm."
[01:00:17.060 --> 01:00:22.060]   Unfortunately, the one thing you saw during the pandemic, and probably all that personal
[01:00:22.060 --> 01:00:24.500]   experience with this is the people who didn't...
[01:00:24.500 --> 01:00:26.420]   There were people who didn't believe this was a pandemic.
[01:00:26.420 --> 01:00:28.580]   There were people who didn't believe this was real.
[01:00:28.580 --> 01:00:29.580]   And what happens is...
[01:00:29.580 --> 01:00:33.340]   Oddly, there still are, and I don't understand what we're living in.
[01:00:33.340 --> 01:00:39.500]   But when people you know die from this or you are impacted by it, all of a sudden the
[01:00:39.500 --> 01:00:40.740]   switch flips.
[01:00:40.740 --> 01:00:46.740]   And I think, unfortunately, because of the way things are going, more and more people
[01:00:46.740 --> 01:00:47.900]   are being impacted.
[01:00:47.900 --> 01:00:53.140]   And it's become apparent, I think, to at least a large segment of the population.
[01:00:53.140 --> 01:00:54.740]   So is it a plot against the president?
[01:00:54.740 --> 01:00:56.460]   It's not a China thing.
[01:00:56.460 --> 01:00:58.460]   It's real.
[01:00:58.460 --> 01:01:01.380]   It's a pandemic.
[01:01:01.380 --> 01:01:04.980]   It shouldn't be going to a gem not wearing a mask, just a thought.
[01:01:04.980 --> 01:01:05.980]   Yeah.
[01:01:05.980 --> 01:01:09.300]   Well, that's what I think will be interesting to see is if people will get vaccinated and
[01:01:09.300 --> 01:01:13.900]   then stop wearing masks, which, of course, public health officials say that's not the
[01:01:13.900 --> 01:01:17.220]   thing to do.
[01:01:17.220 --> 01:01:21.660]   It's going to be an interesting few months, quarters, years.
[01:01:21.660 --> 01:01:22.660]   I don't know.
[01:01:22.660 --> 01:01:23.660]   But better...
[01:01:23.660 --> 01:01:26.460]   Do we all think that next year will be better?
[01:01:26.460 --> 01:01:27.460]   Yes.
[01:01:27.460 --> 01:01:28.620]   It can't be any worse, Paul.
[01:01:28.620 --> 01:01:29.620]   It's a low bar.
[01:01:29.620 --> 01:01:31.860]   Well, don't tempt that.
[01:01:31.860 --> 01:01:32.860]   Don't say that.
[01:01:32.860 --> 01:01:34.980]   There could be a comment.
[01:01:34.980 --> 01:01:35.980]   I understand.
[01:01:35.980 --> 01:01:36.980]   It could be a mutation.
[01:01:36.980 --> 01:01:38.540]   There could be some kinds of things.
[01:01:38.540 --> 01:01:39.540]   Yeah, I guess you're right.
[01:01:39.540 --> 01:01:40.540]   There could be a...
[01:01:40.540 --> 01:01:41.540]   It's also...
[01:01:41.540 --> 01:01:42.540]   Go ahead.
[01:01:42.540 --> 01:01:47.500]   It's also worth remembering that for a while, we were thinking, "Well, you know, you get
[01:01:47.500 --> 01:01:52.100]   it and if you're healthy and your vitamin D status is good, you'll recover and then
[01:01:52.100 --> 01:01:54.140]   you'll be fine and you'll have immunity."
[01:01:54.140 --> 01:02:00.500]   What we're learning is that this thing leaves people worse off often than they were before.
[01:02:00.500 --> 01:02:05.060]   It's not like a common cold that you get over and you're fine.
[01:02:05.060 --> 01:02:06.060]   There can be...
[01:02:06.060 --> 01:02:08.700]   They call it long-hauler syndrome.
[01:02:08.700 --> 01:02:10.700]   Lots of weird things that it does to you.
[01:02:10.700 --> 01:02:15.500]   So, you know, at this point where we have a vaccine probably a few months away, especially
[01:02:15.500 --> 01:02:23.020]   for those of us in the OG group who may have some priority over the youngsters, it really
[01:02:23.020 --> 01:02:26.540]   does make sense not to get it and to get vaccinated.
[01:02:26.540 --> 01:02:27.540]   Yeah.
[01:02:27.540 --> 01:02:32.620]   Well, this is like a new benefit of AARP, you know, getting light early.
[01:02:32.620 --> 01:02:34.420]   The vaccination story.
[01:02:34.420 --> 01:02:36.260]   Paul, join us.
[01:02:36.260 --> 01:02:38.260]   I embrace...
[01:02:38.260 --> 01:02:39.940]   Embrace my elderly nature.
[01:02:39.940 --> 01:02:42.020]   Your elderly nature, yes.
[01:02:42.020 --> 01:02:46.740]   Actually, Dr. Mom was telling me they might be raising it from 65 to 75.
[01:02:46.740 --> 01:02:47.740]   So...
[01:02:47.740 --> 01:02:48.740]   That's what the latest is.
[01:02:48.740 --> 01:02:50.220]   We're going to do 75-op.
[01:02:50.220 --> 01:02:51.220]   Yeah.
[01:02:51.220 --> 01:02:53.260]   And then there are groups three now, all of a sudden.
[01:02:53.260 --> 01:02:55.900]   But we're going to get grandfathered in, right?
[01:02:55.900 --> 01:02:56.900]   Yeah.
[01:02:56.900 --> 01:02:57.900]   Sure, grandfathered.
[01:02:57.900 --> 01:02:59.900]   It's a bit of a terrible thing to do to me now.
[01:02:59.900 --> 01:03:00.900]   The term "grandfathered."
[01:03:00.900 --> 01:03:04.060]   All right, we're going to take a break.
[01:03:04.060 --> 01:03:07.500]   We're covering the top 10 stories of tech stories of 2021.
[01:03:07.500 --> 01:03:11.220]   Although, already you can see the intersection between real life and technology.
[01:03:11.220 --> 01:03:16.780]   In some ways, that's kind of the big story is that what was 10 years ago when we first...
[01:03:16.780 --> 01:03:23.900]   The three of us started working and doing shows on Twitter, was really kind of a subculture
[01:03:23.900 --> 01:03:28.500]   technology is now mainstream in every possible way.
[01:03:28.500 --> 01:03:31.020]   It packs everything.
[01:03:31.020 --> 01:03:34.740]   And the biggest stories of the day are tech stories as much as anything else.
[01:03:34.740 --> 01:03:37.140]   One tech upset some people.
[01:03:37.140 --> 01:03:41.180]   Like you and me, we get in the fight every time I say the F word.
[01:03:41.180 --> 01:03:42.180]   You're all right.
[01:03:42.180 --> 01:03:43.980]   I'm not going to say the F word.
[01:03:43.980 --> 01:03:44.980]   Is he everywhere?
[01:03:44.980 --> 01:03:45.980]   Facebook?
[01:03:45.980 --> 01:03:46.980]   Yes.
[01:03:46.980 --> 01:03:47.980]   Okay.
[01:03:47.980 --> 01:03:49.740]   No, we have something in common.
[01:03:49.740 --> 01:03:50.980]   We've reached a taunt.
[01:03:50.980 --> 01:03:53.420]   Jeff says, "If you stop bringing it up, I won't yell at you."
[01:03:53.420 --> 01:03:54.900]   I said, "Okay, fine.
[01:03:54.900 --> 01:03:55.900]   Fine."
[01:03:55.900 --> 01:03:57.900]   Oh, well, we'll do your commercial.
[01:03:57.900 --> 01:04:01.220]   I got some Facebook stories coming up a little bit.
[01:04:01.220 --> 01:04:05.580]   Our show today brought to you literally, quite literally, by CashFly.
[01:04:05.580 --> 01:04:09.860]   All year long, CashFly has been our content delivery network.
[01:04:09.860 --> 01:04:15.660]   I remember in the early days, back when Steve Gibson had hair and Paul Therat wasn't quite
[01:04:15.660 --> 01:04:24.100]   so gray and Jeff looked exactly the same, we were trying to distribute this by web downloads.
[01:04:24.100 --> 01:04:28.260]   I remember going to people saying, "Please seed our bit torrent so more people can listen
[01:04:28.260 --> 01:04:29.260]   to the show."
[01:04:29.260 --> 01:04:32.940]   That's when Matt Levine at CashFly called me and said, "Leo, can we help?
[01:04:32.940 --> 01:04:34.820]   This is ridiculous."
[01:04:34.820 --> 01:04:40.660]   I at the time didn't really know what CDN did, but boy, was I glad to find out.
[01:04:40.660 --> 01:04:47.140]   CashFly has servers all over the world, servers that will cash your content, bringing it closer
[01:04:47.140 --> 01:04:55.980]   to your end users, whether it's a podcast like ours or a game, a video stream, software.
[01:04:55.980 --> 01:05:00.380]   By doing that, it's five times faster.
[01:05:00.380 --> 01:05:07.220]   It's more reliable that CashFly has a 100% uptime SLA guarantee and industry leading
[01:05:07.220 --> 01:05:10.620]   global performance, and that's really benefited us.
[01:05:10.620 --> 01:05:12.580]   We are big fans of CashFly.
[01:05:12.580 --> 01:05:16.780]   Early on, we discovered something CashFly now is offering everybody.
[01:05:16.780 --> 01:05:21.380]   They call it SOS, storage optimization system.
[01:05:21.380 --> 01:05:27.620]   The issue with a CDN is it's great once your content is cached on their servers all over
[01:05:27.620 --> 01:05:28.740]   the world.
[01:05:28.740 --> 01:05:33.340]   At the first time somebody requests your download from their local server, it has to go out
[01:05:33.340 --> 01:05:39.100]   to your origins, in our case it was S3 or wherever it is, get it, then put it on the
[01:05:39.100 --> 01:05:43.260]   server and then offer it to the customer, which means it's going to be slow.
[01:05:43.260 --> 01:05:47.540]   It's going to cost you money because you're going to have origin traffic.
[01:05:47.540 --> 01:05:51.380]   You're suddenly reliant on the public internet.
[01:05:51.380 --> 01:05:53.460]   What you don't want is a cash miss.
[01:05:53.460 --> 01:05:54.540]   That's what SOS does.
[01:05:54.540 --> 01:06:02.140]   It guarantees no cash misses, which increases download speeds, eliminates buffering, and
[01:06:02.140 --> 01:06:05.300]   can save you a lot of money and data transfer out fees.
[01:06:05.300 --> 01:06:10.300]   We've been using it, it turns out, for years, we've stored our content on CashFly.
[01:06:10.300 --> 01:06:15.500]   The first thing we do when we upload a podcast, we upload it to CashFly so that when their
[01:06:15.500 --> 01:06:19.140]   caching servers, their points of presence, need the content, they get it directly from
[01:06:19.140 --> 01:06:26.460]   CashFly itself through their own peering, which means five times faster than the origin,
[01:06:26.460 --> 01:06:30.140]   hyper-fast downloads, low latency, highly scalable.
[01:06:30.140 --> 01:06:31.140]   That's good news.
[01:06:31.140 --> 01:06:34.900]   Now you can do it to SOS is available to everybody.
[01:06:34.900 --> 01:06:37.460]   The other good news is CashFly is expanding rapidly.
[01:06:37.460 --> 01:06:43.060]   They just added six new points of presence, POPS in South America.
[01:06:43.060 --> 01:06:47.780]   What's great is they're serving 10 times the traffic in Latin America over the last year,
[01:06:47.780 --> 01:06:50.660]   and not only have they maintained, but they've drastically improved their performance in
[01:06:50.660 --> 01:06:54.820]   the region while taking on a much higher traffic load.
[01:06:54.820 --> 01:06:55.980]   This is why I love CashFly.
[01:06:55.980 --> 01:06:59.940]   We have listeners all over the world where ever your end users are, North America, Latin
[01:06:59.940 --> 01:07:03.900]   America, the Caribbean, Europe, the Middle East, Asia, Pacific.
[01:07:03.900 --> 01:07:09.860]   Your content will be delivered quickly and reliably with 100% uptime.
[01:07:09.860 --> 01:07:11.460]   They guarantee it.
[01:07:11.460 --> 01:07:13.900]   So check out CashFly.
[01:07:13.900 --> 01:07:18.140]   CashFly is giving away a complimentary detailed analysis of your current CDN bill and usage
[01:07:18.140 --> 01:07:19.140]   trends.
[01:07:19.140 --> 01:07:22.220]   Chances are you're spending 20% more than you have to.
[01:07:22.220 --> 01:07:24.540]   Twit.cashfly.com.
[01:07:24.540 --> 01:07:28.020]   Bring your CDN bill or your usage trends.
[01:07:28.020 --> 01:07:29.660]   See how much CashFly can save.
[01:07:29.660 --> 01:07:32.260]   See how much better CashFly can be.
[01:07:32.260 --> 01:07:35.740]   By the way, thanks to CashFly during this crisis, they've been helping the world's central
[01:07:35.740 --> 01:07:37.980]   kitchen deliver warm meals.
[01:07:37.980 --> 01:07:43.860]   They've donated over $50,000 to serve 300,000 warm meals to people who are struggling.
[01:07:43.860 --> 01:07:51.140]   CashFly is a great company, great people, and they've done so much for us to get rid
[01:07:51.140 --> 01:07:53.540]   of the pain of getting our content out to you.
[01:07:53.540 --> 01:07:56.300]   You should find out what CashFly can do for you.
[01:07:56.300 --> 01:07:58.020]   twit.cashfly.com.
[01:07:58.020 --> 01:07:59.020]   Thank you, CashFly.
[01:07:59.020 --> 01:08:00.300]   It's been a great 2020.
[01:08:00.300 --> 01:08:04.020]   Here's to 2021 together.
[01:08:04.020 --> 01:08:11.500]   We've got the OG Twits on the line here talking about the top stories of the year.
[01:08:11.500 --> 01:08:17.380]   I guess we have to talk about TikTok, the gift that just kept on giving.
[01:08:17.380 --> 01:08:27.460]   If I look at the TikTok and I'm going to throw into this Huawei WeChat, all of the concern
[01:08:27.460 --> 01:08:34.380]   about the Chinese apps that might be spying on you, and I compare that to what the Russians
[01:08:34.380 --> 01:08:40.020]   have been doing all along with solar winds, the TikTok story isn't just a side show.
[01:08:40.020 --> 01:08:46.420]   It almost seems like misdirection at this point.
[01:08:46.420 --> 01:08:47.420]   Thoughts?
[01:08:47.420 --> 01:08:48.420]   I agree.
[01:08:48.420 --> 01:08:53.620]   Let's move on.
[01:08:53.620 --> 01:08:55.820]   The president wanted to ban TikTok.
[01:08:55.820 --> 01:08:58.020]   As far as we know, that ban is still in effect.
[01:08:58.020 --> 01:09:01.740]   They gave them a reprieve for a while.
[01:09:01.740 --> 01:09:02.980]   Microsoft was going to buy it.
[01:09:02.980 --> 01:09:07.980]   We had Chris Capicello, the CTO of Microsoft, on this week on Windows Weekly.
[01:09:07.980 --> 01:09:08.980]   You asked him.
[01:09:08.980 --> 01:09:15.180]   He said something very interesting about this, which was that he was not part of the group
[01:09:15.180 --> 01:09:17.100]   that was discussing this.
[01:09:17.100 --> 01:09:21.740]   He implied that he wasn't necessarily a fan of this idea and that there were many in
[01:09:21.740 --> 01:09:22.740]   the country that I've come from.
[01:09:22.740 --> 01:09:25.340]   We should point out, Chris is on the leadership team.
[01:09:25.340 --> 01:09:29.820]   He goes in those meetings with Sachin Adela and all the, he's the chief marketing officer.
[01:09:29.820 --> 01:09:32.780]   He's one of the top executives.
[01:09:32.780 --> 01:09:33.940]   Here's how I interpreted that poll.
[01:09:33.940 --> 01:09:36.300]   I thought that was really interesting too.
[01:09:36.300 --> 01:09:41.700]   To me, that was Chris saying this was never an effort.
[01:09:41.700 --> 01:09:42.700]   Just in saying himself.
[01:09:42.700 --> 01:09:47.740]   Yeah, this was not a agreed upon effort by the leadership team.
[01:09:47.740 --> 01:09:48.940]   This is something we want.
[01:09:48.940 --> 01:09:49.940]   He gave reasons.
[01:09:49.940 --> 01:09:50.940]   Yeah, it's good.
[01:09:50.940 --> 01:09:55.420]   It's always good to acquire more users, get a strong user base, blah, blah, blah.
[01:09:55.420 --> 01:10:00.020]   I'm putting words in his mouth here, but my interpretation reading between the lines
[01:10:00.020 --> 01:10:01.540]   was, "You know what?
[01:10:01.540 --> 01:10:06.060]   This was a phone call from Sachin Adela and the president.
[01:10:06.060 --> 01:10:09.620]   The president said, "Would you be interested in buying them?
[01:10:09.620 --> 01:10:12.580]   If you do, will you give me $5 million?"
[01:10:12.580 --> 01:10:15.140]   Nadella, seriously, I'm not joking.
[01:10:15.140 --> 01:10:16.300]   I'm not joking.
[01:10:16.300 --> 01:10:17.300]   I am not joking.
[01:10:17.300 --> 01:10:18.780]   It's so ludicrous.
[01:10:18.780 --> 01:10:22.900]   Politically said, "Yeah, of course."
[01:10:22.900 --> 01:10:26.140]   Well, I'll mention it.
[01:10:26.140 --> 01:10:27.140]   I guess.
[01:10:27.140 --> 01:10:28.140]   Okay.
[01:10:28.140 --> 01:10:29.140]   Right.
[01:10:29.140 --> 01:10:31.220]   Because they didn't tell the leadership team.
[01:10:31.220 --> 01:10:34.380]   They didn't go to the board and say, "Hey, we'd like to buy TikTok.
[01:10:34.380 --> 01:10:35.860]   What do you think?"
[01:10:35.860 --> 01:10:36.860]   It was never...
[01:10:36.860 --> 01:10:37.860]   My assessment...
[01:10:37.860 --> 01:10:40.300]   Everyone on the board would have been like, "You want to buy what?"
[01:10:40.300 --> 01:10:41.300]   What?
[01:10:41.300 --> 01:10:42.300]   My assessment...
[01:10:42.300 --> 01:10:45.540]   Is it never rose to that level of seriousness or they would have told the board, they would
[01:10:45.540 --> 01:10:46.940]   have told the leadership team.
[01:10:46.940 --> 01:10:48.180]   This was politics.
[01:10:48.180 --> 01:10:51.620]   This had nothing to do with Microsoft and their intent to do anything.
[01:10:51.620 --> 01:10:55.620]   It's just very hard if you were a CEO of a publicly held company in the United States
[01:10:55.620 --> 01:11:01.460]   to say no to the president when he calls and says, "Would you do me a favor?"
[01:11:01.460 --> 01:11:04.140]   Of course, Larry Ellison has agreed to do that favor.
[01:11:04.140 --> 01:11:06.140]   Larry Ayer is a different character.
[01:11:06.140 --> 01:11:09.620]   Yes, some people are just pursuing the ring.
[01:11:09.620 --> 01:11:15.140]   But I think honestly, Nadella and maybe even Ellison and Walmart, all of whom have been
[01:11:15.140 --> 01:11:19.780]   named as potential buyers of TikTok, had the same reaction, which is it's never going
[01:11:19.780 --> 01:11:20.780]   to happen.
[01:11:20.780 --> 01:11:22.140]   Go ahead and say yes.
[01:11:22.140 --> 01:11:23.140]   Yeah.
[01:11:23.140 --> 01:11:24.140]   Well.
[01:11:24.140 --> 01:11:26.580]   Because it isn't going to happen at this point, right?
[01:11:26.580 --> 01:11:27.580]   No.
[01:11:27.580 --> 01:11:28.580]   No.
[01:11:28.580 --> 01:11:33.700]   I mean, I don't know what we're going to do about the security problem that is TikTok,
[01:11:33.700 --> 01:11:34.700]   I guess.
[01:11:34.700 --> 01:11:35.700]   Is it though?
[01:11:35.700 --> 01:11:40.340]   I mean, you look at what happened with SolarWinds and then you look at, "Well, TikTok might
[01:11:40.340 --> 01:11:47.620]   be spying on people through their location on their cell phone.
[01:11:47.620 --> 01:11:49.820]   It doesn't rise to the same level of...
[01:11:49.820 --> 01:11:51.460]   It really doesn't, yeah.
[01:11:51.460 --> 01:11:52.460]   Problem.
[01:11:52.460 --> 01:11:54.420]   And I just want to say this about TikTok.
[01:11:54.420 --> 01:11:57.060]   I mean, an OG.
[01:11:57.060 --> 01:11:59.260]   I looked at it at first and said, "Huh?"
[01:11:59.260 --> 01:12:00.260]   Exactly.
[01:12:00.260 --> 01:12:04.500]   But I love what it does for collaboration.
[01:12:04.500 --> 01:12:11.900]   I think it's a step ahead of the rest of platforms and that you can put up a piece
[01:12:11.900 --> 01:12:13.340]   of audio and people can build on it.
[01:12:13.340 --> 01:12:16.140]   You can put up a video and people respond to it.
[01:12:16.140 --> 01:12:24.640]   You can create ratatouille, the musical, entirely on TikTok with choreography and costumes
[01:12:24.640 --> 01:12:26.960]   and songs and scripts.
[01:12:26.960 --> 01:12:29.080]   And to me, it begins.
[01:12:29.080 --> 01:12:35.640]   It just begins to crack what I think is the true nature of the net, which is collaboration.
[01:12:35.640 --> 01:12:37.880]   Which is not to say that there are not potential issues.
[01:12:37.880 --> 01:12:45.640]   I mean, the Congress has just banned the DJI drones again because they work with the Chinese
[01:12:45.640 --> 01:12:51.720]   government to monitor Uighurs in concentration camps.
[01:12:51.720 --> 01:12:58.060]   Any company that is a Chinese company is going to be potentially complicit in some
[01:12:58.060 --> 01:13:03.240]   potentially, but doesn't seem rather arbitrary, which they've randomly, not necessarily,
[01:13:03.240 --> 01:13:06.680]   but they've gone after a handful of very specific companies.
[01:13:06.680 --> 01:13:07.920]   It feels political.
[01:13:07.920 --> 01:13:08.920]   Yeah.
[01:13:08.920 --> 01:13:11.280]   There's no doubt about it.
[01:13:11.280 --> 01:13:17.000]   Well, and we talk about on the podcast the fact that all of our IoT devices are connecting
[01:13:17.000 --> 01:13:23.040]   back to server infrastructure in China to control our plugs and light bulbs and all
[01:13:23.040 --> 01:13:24.160]   this other stuff.
[01:13:24.160 --> 01:13:33.320]   So, I mean, the reality of this exposure to global threats is real.
[01:13:33.320 --> 01:13:38.200]   And most of it just gets ignored until something bad happens.
[01:13:38.200 --> 01:13:42.760]   It's, I mean, you could say, I mean, the prudent thing to do would be to have no business
[01:13:42.760 --> 01:13:47.960]   with any other country in the world and seal our borders, but that's not practical.
[01:13:47.960 --> 01:13:49.880]   It's not doable.
[01:13:49.880 --> 01:13:57.000]   And so the proper response it seems to me is to weigh the risks to deal with the most,
[01:13:57.000 --> 01:14:00.120]   the most serious risks and certainly be aware of.
[01:14:00.120 --> 01:14:04.360]   And I think they're diplomatic routes, the political routes that you could use to encourage
[01:14:04.360 --> 01:14:05.760]   China to do the right thing.
[01:14:05.760 --> 01:14:07.560]   I would hope we would use those.
[01:14:07.560 --> 01:14:09.760]   So, Steve, what's your latest?
[01:14:09.760 --> 01:14:14.600]   I know you've talked about it a lot on the show, on your show, but just is there anything
[01:14:14.600 --> 01:14:19.280]   new or current in terms of your view of the risks of TikTok?
[01:14:19.280 --> 01:14:20.360]   I didn't hear the last.
[01:14:20.360 --> 01:14:22.080]   It's the risk, Steve.
[01:14:22.080 --> 01:14:23.440]   What's the threat from TikTok?
[01:14:23.440 --> 01:14:24.920]   Of TikTok, specifically.
[01:14:24.920 --> 01:14:26.680]   I have no idea.
[01:14:26.680 --> 01:14:30.400]   Well, that can be covered.
[01:14:30.400 --> 01:14:34.840]   One of the things that I know you are focused on, Jeff, is because I listened to you on this
[01:14:34.840 --> 01:14:46.400]   week in Google, is the changing feeling about privacy as a function of age, where young
[01:14:46.400 --> 01:14:49.440]   kids are just like, "Oh, yeah, we don't care.
[01:14:49.440 --> 01:14:52.720]   We're just putting it all online and letting it hang out there."
[01:14:52.720 --> 01:14:56.880]   Whereas these OGs here are like, "Wait a minute.
[01:14:56.880 --> 01:14:58.480]   You gave them your what?"
[01:14:58.480 --> 01:15:06.320]   So I think it is a function of where you come from and how new this is to you.
[01:15:06.320 --> 01:15:08.600]   Well, of course, one of the stories this week...
[01:15:08.600 --> 01:15:09.600]   You're also talking about TikTok, too.
[01:15:09.600 --> 01:15:10.600]   Go ahead.
[01:15:10.600 --> 01:15:11.600]   Well, just one quick point.
[01:15:11.600 --> 01:15:13.840]   I think it's a really good point, Steve.
[01:15:13.840 --> 01:15:19.360]   And it also goes to, I think one of the great talents of young people online and other communities
[01:15:19.360 --> 01:15:23.320]   online is that they create their own languages.
[01:15:23.320 --> 01:15:26.280]   They don't find privacy the way we do.
[01:15:26.280 --> 01:15:30.440]   They hide in plain sight the things that they do.
[01:15:30.440 --> 01:15:32.040]   And it's true of young people.
[01:15:32.040 --> 01:15:34.200]   Dana Boyd has done great research on this.
[01:15:34.200 --> 01:15:39.840]   And I just read a book by Andre Brock Jr. on Black culture on Twitter.
[01:15:39.840 --> 01:15:44.240]   And there is the creation of languages and structures and understandings that if you're
[01:15:44.240 --> 01:15:46.920]   not inside the community, you're not going to get.
[01:15:46.920 --> 01:15:52.280]   And it's in plain sight view, which is a really interesting strategy then for how to
[01:15:52.280 --> 01:15:53.800]   deal with the internet.
[01:15:53.800 --> 01:15:55.600]   TikTok was very savvy, too.
[01:15:55.600 --> 01:16:01.040]   They went to the courts to fight the Trump declaration.
[01:16:01.040 --> 01:16:06.120]   But they did it by getting people who make money, influencers on TikTok to sue because
[01:16:06.120 --> 01:16:08.400]   they had the standing, right?
[01:16:08.400 --> 01:16:11.320]   And in fact, in two different court cases, it worked.
[01:16:11.320 --> 01:16:17.360]   The judge ruled that shutting TikTok down would be a significant penalty to these influencers.
[01:16:17.360 --> 01:16:19.880]   The first was a First Amendment case, too.
[01:16:19.880 --> 01:16:25.120]   This is the printing press of the people.
[01:16:25.120 --> 01:16:28.240]   And so it really is a First Amendment case.
[01:16:28.240 --> 01:16:32.920]   And whether it's in China or not, people are using it to be able to talk to the public
[01:16:32.920 --> 01:16:34.440]   and to have their voice.
[01:16:34.440 --> 01:16:37.280]   And you try to shut that off from government.
[01:16:37.280 --> 01:16:39.280]   That's a violation of the First Amendment.
[01:16:39.280 --> 01:16:40.840]   I think it's pretty clear.
[01:16:40.840 --> 01:16:44.600]   Now, don't yell at me, Jeff.
[01:16:44.600 --> 01:16:45.600]   I don't yell at you.
[01:16:45.600 --> 01:16:46.600]   You're the one who yells at me.
[01:16:46.600 --> 01:16:47.600]   Oh, I'm sorry.
[01:16:47.600 --> 01:16:48.600]   I'm yelling at you.
[01:16:48.600 --> 01:16:51.440]   I'm not going to be saying this.
[01:16:51.440 --> 01:16:56.240]   This was actually a story this week because Apple changed its privacy reporting with the
[01:16:56.240 --> 01:16:58.400]   most recent version of iOS.
[01:16:58.400 --> 01:17:06.920]   And there was a very long, several screens long reveal of all of the things Facebook
[01:17:06.920 --> 01:17:14.120]   potentially was collecting from you on your iOS app, at which point Facebook took out full
[01:17:14.120 --> 01:17:20.360]   page ads in the New York Times, the Wall Street Journal, and the Washington Post saying,
[01:17:20.360 --> 01:17:21.760]   "It's not us.
[01:17:21.760 --> 01:17:26.040]   Think of the small business people who are going to suffer if you tell them what we're
[01:17:26.040 --> 01:17:27.040]   collecting."
[01:17:27.040 --> 01:17:30.200]   Apple said, "Look, we're not saying you can't collect it, Facebook.
[01:17:30.200 --> 01:17:34.280]   We're just telling people they have the right to say no."
[01:17:34.280 --> 01:17:35.880]   And Facebook was up in arms.
[01:17:35.880 --> 01:17:42.520]   And I guess my point is Facebook is doing and admittedly doing more probably than TikTok
[01:17:42.520 --> 01:17:43.520]   is.
[01:17:43.520 --> 01:17:49.000]   It's the only difference that Facebook is doing it as their American company and TikTok's
[01:17:49.000 --> 01:17:50.000]   a Chinese company.
[01:17:50.000 --> 01:17:51.000]   Is that the difference?
[01:17:51.000 --> 01:17:53.440]   TikTok, there's a fear they might have do something.
[01:17:53.440 --> 01:17:55.760]   With Facebook, they literally are doing it.
[01:17:55.760 --> 01:17:56.840]   That's one thing.
[01:17:56.840 --> 01:18:01.560]   But also, this Facebook protection of small businesses is like the mob claiming that if
[01:18:01.560 --> 01:18:06.640]   you take them down, no one will protect the small businesses on the street because we're
[01:18:06.640 --> 01:18:07.640]   collecting money.
[01:18:07.640 --> 01:18:09.880]   Shave books would happen to that nice bakery of yours.
[01:18:09.880 --> 01:18:10.880]   Yeah.
[01:18:10.880 --> 01:18:12.760]   I don't have to see anything happening in your small business.
[01:18:12.760 --> 01:18:17.600]   Cara Swisher's opinion piece in the New York Times said, "Facebook's tone deaf attack
[01:18:17.600 --> 01:18:18.960]   on Apple.
[01:18:18.960 --> 01:18:20.680]   The company declared a newspaper ads.
[01:18:20.680 --> 01:18:22.080]   It was standing up to Apple.
[01:18:22.080 --> 01:18:26.920]   It's a desperate ploy that's unlikely to work."
[01:18:26.920 --> 01:18:31.520]   She says, "Casting itself as a protector of small businesses in full page ads in irony
[01:18:31.520 --> 01:18:33.880]   alert, big newspapers.
[01:18:33.880 --> 01:18:38.240]   Facebook is criticizing Apple for planning to give users of its popular devices more control
[01:18:38.240 --> 01:18:41.720]   over the data they share with third party apps."
[01:18:41.720 --> 01:18:43.520]   Think of the small businesses.
[01:18:43.520 --> 01:18:45.680]   That's a new kind of moral panic, isn't it, Jeff?
[01:18:45.680 --> 01:18:48.160]   So just to be clear here, I agree with you on this story.
[01:18:48.160 --> 01:18:50.320]   It was the other story you brought that told me.
[01:18:50.320 --> 01:18:51.320]   Okay.
[01:18:51.320 --> 01:18:52.320]   Okay.
[01:18:52.320 --> 01:18:53.320]   Okay.
[01:18:53.320 --> 01:18:54.720]   It doomsday machine that I had a little problem with.
[01:18:54.720 --> 01:18:55.960]   This story, I agree with.
[01:18:55.960 --> 01:18:56.960]   Facebook is tone deaf.
[01:18:56.960 --> 01:18:57.960]   Yeah.
[01:18:57.960 --> 01:19:00.040]   They do all kinds of things that don't make sense.
[01:19:00.040 --> 01:19:01.040]   Yeah.
[01:19:01.040 --> 01:19:04.600]   They don't have my biggest complaint about them is they don't operate with a North Star.
[01:19:04.600 --> 01:19:05.600]   You can test them against.
[01:19:05.600 --> 01:19:10.320]   To say, "Why do you exist and we're going to test your behavior against that?"
[01:19:10.320 --> 01:19:12.960]   Instead, they have a book of statutes.
[01:19:12.960 --> 01:19:18.520]   You can't show a female breast unless it's attached to a kid, but why?
[01:19:18.520 --> 01:19:22.720]   What's the higher view of why you exist besides we're going to connect people?
[01:19:22.720 --> 01:19:27.080]   And that's where I've been urging them publicly on this show and in my writing to do and they
[01:19:27.080 --> 01:19:30.000]   don't.
[01:19:30.000 --> 01:19:33.960]   In any event, I guess the reason I bring it up in conjunction with TikTok is they're
[01:19:33.960 --> 01:19:38.640]   both doing somewhat similar things and there's always the threat that TikTok could be used
[01:19:38.640 --> 01:19:45.160]   somehow to propagandize American public or, and you could say the same thing for Facebook.
[01:19:45.160 --> 01:19:50.120]   In fact, I think you could say Facebook has been used that way in Myanmar and the Philippines
[01:19:50.120 --> 01:19:54.400]   and other dictatorships.
[01:19:54.400 --> 01:20:00.280]   So is the president trying to shut down Facebook as well as TikTok or is it just that it's
[01:20:00.280 --> 01:20:01.280]   a Chinese company?
[01:20:01.280 --> 01:20:02.280]   230.
[01:20:02.280 --> 01:20:03.920]   No, that's where 230 comes in.
[01:20:03.920 --> 01:20:06.720]   That's where his insistence on trying to kill 230.
[01:20:06.720 --> 01:20:10.320]   That's where I think that's going to be the battleground for next year and where odd
[01:20:10.320 --> 01:20:15.600]   bedfellows come together because of the, pardon me, moral panic about the internet that what
[01:20:15.600 --> 01:20:18.440]   suffers in the end is all of our speech.
[01:20:18.440 --> 01:20:19.440]   Yes.
[01:20:19.440 --> 01:20:20.440]   It's not about Facebook.
[01:20:20.440 --> 01:20:21.440]   I'll back you up.
[01:20:21.440 --> 01:20:22.440]   It's not about Twitter.
[01:20:22.440 --> 01:20:23.440]   It's not about TikTok.
[01:20:23.440 --> 01:20:27.920]   It's about our rights online and what's going to happen there because of this panic that
[01:20:27.920 --> 01:20:28.920]   goes on.
[01:20:28.920 --> 01:20:32.160]   And 230 is going to be the target next year.
[01:20:32.160 --> 01:20:33.160]   Well let's take a little break.
[01:20:33.160 --> 01:20:34.160]   Come back.
[01:20:34.160 --> 01:20:37.800]   Let's talk about that social media, section 230 of the communications.
[01:20:37.800 --> 01:20:38.800]   Encryption.
[01:20:38.800 --> 01:20:39.800]   Decency act.
[01:20:39.800 --> 01:20:42.600]   Let's talk about the attack on encryption.
[01:20:42.600 --> 01:20:48.840]   There is a lot more to talk about as we go through some of the top 10 stories of 2020
[01:20:48.840 --> 01:20:55.480]   with my top three buddies on Twitch, Steve Gibson of security now and the creator of
[01:20:55.480 --> 01:20:56.480]   Spinrite.
[01:20:56.480 --> 01:21:00.640]   I'll give you a plug, the world's finest hard drive recovery and maintenance utility.
[01:21:00.640 --> 01:21:05.560]   And by the way, you said that by the time we come back, the next week for all three
[01:21:05.560 --> 01:21:10.440]   shows, Windows Weekly Security now, this week in Google will be doing best-ups.
[01:21:10.440 --> 01:21:12.640]   We won't be back to the following.
[01:21:12.640 --> 01:21:16.920]   You said we might have some Spinrite news, Steve, you think?
[01:21:16.920 --> 01:21:17.920]   Yep.
[01:21:17.920 --> 01:21:18.920]   Well, we will.
[01:21:18.920 --> 01:21:25.080]   We're at the final release candidate for the benchmark, not for Spinrite, but for the
[01:21:25.080 --> 01:21:31.520]   benchmark that is the testing platform for all the new hardware drivers that spin right
[01:21:31.520 --> 01:21:32.840]   with that inherit.
[01:21:32.840 --> 01:21:38.920]   So this allows it to get a lot more rigorous testing so that when we do launch it in Spinrite,
[01:21:38.920 --> 01:21:41.120]   it'll just come out working.
[01:21:41.120 --> 01:21:42.840]   GRC.com.
[01:21:42.840 --> 01:21:46.560]   If you buy Spinrite now, you'll be in on all the beta testing and you'll get a free copy
[01:21:46.560 --> 01:21:51.240]   of 6.1 when it comes out soon.
[01:21:51.240 --> 01:21:54.680]   It sounds like Steve Gibson security now.
[01:21:54.680 --> 01:21:56.280]   It was Weekly host Paul Therat.
[01:21:56.280 --> 01:21:57.280]   It's great to have you.
[01:21:57.280 --> 01:22:04.400]   Therat.com is his website, his book, the field guide to Windows 10 is at leanpub.com.
[01:22:04.400 --> 01:22:06.160]   I'm giving people plugs now, Paul.
[01:22:06.160 --> 01:22:07.160]   What happened to you?
[01:22:07.160 --> 01:22:08.160]   Wait a minute.
[01:22:08.160 --> 01:22:10.520]   I'm looking over your left shoulder, your Xbox is gone.
[01:22:10.520 --> 01:22:11.520]   Where'd it go?
[01:22:11.520 --> 01:22:13.280]   Well, the, let's see, which side?
[01:22:13.280 --> 01:22:15.000]   The old Xbox is up there.
[01:22:15.000 --> 01:22:16.000]   Okay.
[01:22:16.000 --> 01:22:18.920]   The series, the series X used to be over your left shoulder.
[01:22:18.920 --> 01:22:20.320]   Well, it was just the box.
[01:22:20.320 --> 01:22:21.320]   The series X is on the desk.
[01:22:21.320 --> 01:22:22.320]   Oh, but just the box.
[01:22:22.320 --> 01:22:23.320]   Never mind.
[01:22:23.320 --> 01:22:24.320]   The box is gone.
[01:22:24.320 --> 01:22:25.320]   I'm trying to be seen.
[01:22:25.320 --> 01:22:26.320]   Take it away.
[01:22:26.320 --> 01:22:28.160]   You robbed me of my sense of reality.
[01:22:28.160 --> 01:22:33.600]   The new Xbox is so last month.
[01:22:33.600 --> 01:22:34.600]   Call of Duty.
[01:22:34.600 --> 01:22:35.600]   You still playing on that?
[01:22:35.600 --> 01:22:37.600]   I know series X.
[01:22:37.600 --> 01:22:41.600]   I am, but I'm going to be moving on pretty soon.
[01:22:41.600 --> 01:22:44.920]   I'm not happy with that.
[01:22:44.920 --> 01:22:49.600]   It won't be part of our top 10, I don't think, but one of the big stories this week was this
[01:22:49.600 --> 01:22:50.600]   maybe not surprising.
[01:22:50.600 --> 01:22:56.040]   It seems to be the way it is these days in AAA game releases, but the abject failure
[01:22:56.040 --> 01:23:00.800]   of Cyberpunk 2077 refunds being offered by Sony.
[01:23:00.800 --> 01:23:04.840]   It apparently does not work well on PlayStation 4 or the Xbox one.
[01:23:04.840 --> 01:23:05.840]   Yep.
[01:23:05.840 --> 01:23:07.520]   Like not well, like not at all.
[01:23:07.520 --> 01:23:12.920]   Yeah, the most hyped game of 2020 somehow bombed immediately upon release.
[01:23:12.920 --> 01:23:15.600]   That seems to be the case more often than not.
[01:23:15.600 --> 01:23:17.560]   These days with AAA release.
[01:23:17.560 --> 01:23:18.560]   It's crazy.
[01:23:18.560 --> 01:23:21.000]   The games bogged down, the game won't work.
[01:23:21.000 --> 01:23:25.240]   On the other hand, on Google Stadia, it's playing fine on GeForce Now.
[01:23:25.240 --> 01:23:26.240]   It's playing fine.
[01:23:26.240 --> 01:23:31.480]   It seems like the best way to run these games is to not be running them, but to be-
[01:23:31.480 --> 01:23:34.000]   That's how you get people to move to the cloud.
[01:23:34.000 --> 01:23:35.000]   Oh.
[01:23:35.000 --> 01:23:36.600]   Do you think-
[01:23:36.600 --> 01:23:37.760]   It's a plot.
[01:23:37.760 --> 01:23:38.760]   It's a conspiracy.
[01:23:38.760 --> 01:23:40.960]   Red Project is a Polish company.
[01:23:40.960 --> 01:23:43.760]   Do you think this is a conspiracy?
[01:23:43.760 --> 01:23:45.160]   Follow the money, Leo.
[01:23:45.160 --> 01:23:47.880]   I don't even know what I'm talking about.
[01:23:47.880 --> 01:23:51.040]   There are one plays, so plays us all.
[01:23:51.040 --> 01:23:52.040]   Yeah.
[01:23:52.040 --> 01:23:53.040]   Yeah.
[01:23:53.040 --> 01:23:54.040]   Yeah.
[01:23:54.040 --> 01:23:58.640]   I actually really- It's a fun game, but I haven't played it on a device because I couldn't get
[01:23:58.640 --> 01:24:03.640]   a PlayStation 5 or Xbox Series X.
[01:24:03.640 --> 01:24:07.440]   Do you think people are taking the refund?
[01:24:07.440 --> 01:24:08.440]   Yeah.
[01:24:08.440 --> 01:24:12.080]   Sony, you know, infamously pulled the game from the store and is offering refunds.
[01:24:12.080 --> 01:24:15.400]   Microsoft is also offering refunds, but they're not pulling it from the store.
[01:24:15.400 --> 01:24:16.400]   Wow.
[01:24:16.400 --> 01:24:23.240]   I don't know any movement on the PC side that I'm aware of, but yeah, I bet people have.
[01:24:23.240 --> 01:24:28.520]   I remember every time in the last few years, a big massively online game comes out.
[01:24:28.520 --> 01:24:31.920]   The servers crash and there's all sorts of issues, but this is the first time I can
[01:24:31.920 --> 01:24:34.200]   remember it being pulled from the store.
[01:24:34.200 --> 01:24:35.200]   Yeah, for the store.
[01:24:35.200 --> 01:24:36.200]   I can't think of it.
[01:24:36.200 --> 01:24:37.200]   Even Duke Nukem Forever wasn't pulled.
[01:24:37.200 --> 01:24:39.960]   I think it was terrible.
[01:24:39.960 --> 01:24:41.760]   Wow.
[01:24:41.760 --> 01:24:46.480]   Wow, that's a- So we'll talk about that when we come back in a couple of weeks on Windows
[01:24:46.480 --> 01:24:48.360]   Weekly because I think that is a big story.
[01:24:48.360 --> 01:24:50.840]   That probably doesn't rise the top 10 years.
[01:24:50.840 --> 01:24:51.840]   No, it's not quite yet.
[01:24:51.840 --> 01:24:52.840]   Not quite top 10.
[01:24:52.840 --> 01:24:53.840]   Yeah, such a big story.
[01:24:53.840 --> 01:24:59.480]   And of course, Jeff Jarvis is here this week in Google, which really is no longer about
[01:24:59.480 --> 01:25:03.520]   Google at all, but mostly just about me and Jeff fighting and-
[01:25:03.520 --> 01:25:06.760]   No, we don't all like to love each other.
[01:25:06.760 --> 01:25:07.760]   And Stacy and-
[01:25:07.760 --> 01:25:08.760]   You're dating me and Stacy and Nuke.
[01:25:08.760 --> 01:25:10.760]   And Stacy and Nuke, you're dating me and Stacy and Nuke for the race of the Internet, but
[01:25:10.760 --> 01:25:12.760]   you're up and beyond that.
[01:25:12.760 --> 01:25:14.360]   I just like to bait you.
[01:25:14.360 --> 01:25:15.360]   That's all you know.
[01:25:15.360 --> 01:25:17.960]   I like to poke the bear.
[01:25:17.960 --> 01:25:18.960]   Anything you want to plug?
[01:25:18.960 --> 01:25:21.760]   Should I give Craig Newmark his weekly plug?
[01:25:21.760 --> 01:25:22.760]   Oh sure.
[01:25:22.760 --> 01:25:23.760]   Yeah.
[01:25:23.760 --> 01:25:27.160]   Jeff is the Leonard Taap Professor for journalistic innovation at the Craig-
[01:25:27.160 --> 01:25:28.160]   Craig Newmark.
[01:25:28.160 --> 01:25:29.160]   Newmark.
[01:25:29.160 --> 01:25:33.960]   Graduate School of Journalism at the City University of New York.
[01:25:33.960 --> 01:25:34.960]   How's Craig doing?
[01:25:34.960 --> 01:25:35.960]   Craig's doing great.
[01:25:35.960 --> 01:25:36.960]   Craig was the creative craiceless.
[01:25:36.960 --> 01:25:39.080]   You've given away a lot of money.
[01:25:39.080 --> 01:25:45.840]   He's extended his philanthropy from journalism and women in code and veterans.
[01:25:45.840 --> 01:25:47.520]   He's also worried about hunger now.
[01:25:47.520 --> 01:25:48.520]   Good for him.
[01:25:48.520 --> 01:25:51.000]   Is he still involved with Craig's list?
[01:25:51.000 --> 01:25:53.200]   Does he still do that?
[01:25:53.200 --> 01:25:54.960]   Or do he sell it or what's going on?
[01:25:54.960 --> 01:25:56.120]   Craig's so great about this.
[01:25:56.120 --> 01:26:00.280]   He said long, long, long ago he realized what a bad energy he was.
[01:26:00.280 --> 01:26:05.600]   And so he hired a CEO and he cares about the company, but he used to do customer service
[01:26:05.600 --> 01:26:06.600]   a lot.
[01:26:06.600 --> 01:26:07.600]   I think he might still do some.
[01:26:07.600 --> 01:26:08.600]   That's cute.
[01:26:08.600 --> 01:26:09.600]   That's a great company.
[01:26:09.600 --> 01:26:13.520]   Jim Buckmaster has been the CEO for ages and done a good job with it.
[01:26:13.520 --> 01:26:16.880]   So Craig just takes the checks and that's about it.
[01:26:16.880 --> 01:26:22.760]   Craig cares and Craig, you know, the great thing about about craiceless is that it hasn't
[01:26:22.760 --> 01:26:23.760]   changed.
[01:26:23.760 --> 01:26:24.760]   Right?
[01:26:24.760 --> 01:26:28.560]   I mean, it's, it's, while the internet went, when crazy all around it, craiceless has been
[01:26:28.560 --> 01:26:29.560]   a rock.
[01:26:29.560 --> 01:26:31.200]   It is what it is.
[01:26:31.200 --> 01:26:33.920]   Pridefully, redesigned.
[01:26:33.920 --> 01:26:42.400]   Really perhaps one of the top 10 stories we should have covered is, is the benefactors,
[01:26:42.400 --> 01:26:47.200]   the gifts people like Craig, Jeff Bezos is X.
[01:26:47.200 --> 01:26:56.000]   Mackenzie, Lorraine Jobs.
[01:26:56.000 --> 01:27:06.440]   These very wealthy tech benefactors have really put a lot of money, Bill Gates, into, into
[01:27:06.440 --> 01:27:07.520]   good causes.
[01:27:07.520 --> 01:27:09.960]   That seems to be more and more.
[01:27:09.960 --> 01:27:14.720]   For a long time, Silicon Valley was very much criticized for not participating, for not being
[01:27:14.720 --> 01:27:15.720]   charitable.
[01:27:15.720 --> 01:27:19.440]   Steve Jobs famously said, I'm too busy.
[01:27:19.440 --> 01:27:23.280]   We don't want to, I think secretly he might have been donating.
[01:27:23.280 --> 01:27:30.760]   But now Apple is very much in the forefront of, of gifts and, and charity.
[01:27:30.760 --> 01:27:33.960]   So that's probably a big story too for 2020.
[01:27:33.960 --> 01:27:37.400]   How much did Mackenzie Scott give away?
[01:27:37.400 --> 01:27:40.400]   Four billion, I thought it was four million million.
[01:27:40.400 --> 01:27:43.360]   She, and that is one of the big stories.
[01:27:43.360 --> 01:27:53.440]   She like her ex, Jeff Bezos, benefited amazingly from COVID-19.
[01:27:53.440 --> 01:27:55.360]   Scott's the third richest woman in the world.
[01:27:55.360 --> 01:28:02.960]   She got $37 billion in her divorce, but it's now worth $62 billion thanks to the run-up
[01:28:02.960 --> 01:28:08.520]   in Amazon stock due primarily to COVID over the last nine months.
[01:28:08.520 --> 01:28:10.520]   And so she decided to give a lot of it away.
[01:28:10.520 --> 01:28:17.680]   Which was, sorry, I got money in the disinformation thing with my school from Facebook, which almost
[01:28:17.680 --> 01:28:19.080]   all of them we gave away.
[01:28:19.080 --> 01:28:26.120]   So I was, you know, kind of a short term for about 10 minutes philanthropist of sorts, right?
[01:28:26.120 --> 01:28:28.760]   A, a, a grand tour and sort of a grand tee.
[01:28:28.760 --> 01:28:30.080]   And it's hard.
[01:28:30.080 --> 01:28:33.720]   It's very hard work, oddly, to give away money.
[01:28:33.720 --> 01:28:37.520]   Because everybody's going to come after you and you need some sense of what impact you're
[01:28:37.520 --> 01:28:40.320]   going to have and some sense of data around it.
[01:28:40.320 --> 01:28:42.680]   And, you know, I didn't know how to do it.
[01:28:42.680 --> 01:28:46.920]   And we hired people who did, but it's, it's amazing to watch how that works.
[01:28:46.920 --> 01:28:48.240]   This is not easy.
[01:28:48.240 --> 01:28:49.240]   Yeah, very famously.
[01:28:49.240 --> 01:28:51.560]   Easy to be rich, but it's hard to get it away.
[01:28:51.560 --> 01:28:58.800]   Yeah, very famously, Mark Zuckerberg gave $100 million to creating an education founder,
[01:28:58.800 --> 01:29:02.840]   found a foundation in Newark that was just kind of a flop.
[01:29:02.840 --> 01:29:10.240]   Yep, that two other philanthropists matched the grant $200 million.
[01:29:10.240 --> 01:29:16.120]   And as far as anybody can tell, it just, it closes the store for five years and with
[01:29:16.120 --> 01:29:18.840]   very little impact on Newark schools.
[01:29:18.840 --> 01:29:20.480]   So it's hard.
[01:29:20.480 --> 01:29:21.480]   It is hard.
[01:29:21.480 --> 01:29:25.440]   Bill Gates always said, I'm not going to give away money until I have the time to do it
[01:29:25.440 --> 01:29:27.160]   right.
[01:29:27.160 --> 01:29:30.680]   He started a little bit before his retirement, but I think Melinda had a lot to do with that
[01:29:30.680 --> 01:29:34.840]   in the bill on Melinda Gates Foundation has since his retirement, not only given away
[01:29:34.840 --> 01:29:37.280]   a lot of money, but really done a lot of good in the world.
[01:29:37.280 --> 01:29:38.280]   The leaders.
[01:29:38.280 --> 01:29:39.680]   Yeah, it really been leaders.
[01:29:39.680 --> 01:29:41.320]   So that's a good story.
[01:29:41.320 --> 01:29:42.960]   That's a nice story.
[01:29:42.960 --> 01:29:47.400]   People like Mackenzie Scott, Bill Gates.
[01:29:47.400 --> 01:29:53.560]   Zuckerberg's an interesting story because the Zuckerberg and Priscilla Chan, his wife's
[01:29:53.560 --> 01:30:00.600]   foundation has been more politic in its giving, if you will.
[01:30:00.600 --> 01:30:04.040]   I think that's a story perhaps for 2021.
[01:30:04.040 --> 01:30:08.040]   Our show today brought to you by Zendesk.
[01:30:08.040 --> 01:30:09.720]   Customer service is everything, isn't it?
[01:30:09.720 --> 01:30:15.520]   I mean, that's the best run companies in the world are the ones that treat their customers
[01:30:15.520 --> 01:30:17.880]   like what they are, the most important part of the business.
[01:30:17.880 --> 01:30:23.880]   And how many of us, I guarantee you, every one of us has a customer service horror story
[01:30:23.880 --> 01:30:26.720]   to tell.
[01:30:26.720 --> 01:30:31.360]   Customer service is job one if you have customers.
[01:30:31.360 --> 01:30:36.000]   And how many times have you been on the phone and just hung up in fury or been kept on hold
[01:30:36.000 --> 01:30:37.320]   for hours?
[01:30:37.320 --> 01:30:42.200]   Even the best teams can struggle to make their customers feel taken care of.
[01:30:42.200 --> 01:30:50.160]   Zendesk does award winning support sales and customer engagement software that helps businesses
[01:30:50.160 --> 01:30:54.080]   give good customer service at scale because that's the problem.
[01:30:54.080 --> 01:30:59.320]   It's easy when your company's small and you have a few customers, but as that customer
[01:30:59.320 --> 01:31:04.560]   list grows, it can get harder and harder to give authentic customer service.
[01:31:04.560 --> 01:31:06.360]   That's what Zendesk helps you do.
[01:31:06.360 --> 01:31:12.640]   It's a conversational, authentic experiences that keep customers happy.
[01:31:12.640 --> 01:31:17.560]   And you know this, when a customer, I know this, when I have a bad experience, I tweet
[01:31:17.560 --> 01:31:18.560]   about it.
[01:31:18.560 --> 01:31:24.760]   I tell the world, those guys kept me on hold for 14 hours.
[01:31:24.760 --> 01:31:28.760]   People will say when they have a bad experience, but similarly, I think people will tell others
[01:31:28.760 --> 01:31:30.960]   when they have a good experience.
[01:31:30.960 --> 01:31:34.560]   Zendesk gives businesses what they need to stay connected with customers, communicates
[01:31:34.560 --> 01:31:37.240]   seamlessly across every channel.
[01:31:37.240 --> 01:31:39.600]   And that's important too, because we all have different ways.
[01:31:39.600 --> 01:31:45.800]   We want to communicate email, phone, chat, messenger, community forums, help centers,
[01:31:45.800 --> 01:31:47.280]   social media.
[01:31:47.280 --> 01:31:55.280]   Zendesk uses that phrase conversational experience connected, ongoing, natural customer interactions.
[01:31:55.280 --> 01:31:58.520]   You don't want customers feeling like they're talking to a robot.
[01:31:58.520 --> 01:32:02.520]   You want them feeling like they're getting heard by humans.
[01:32:02.520 --> 01:32:06.800]   And that's made possible with Zendesk's complete customer profile.
[01:32:06.800 --> 01:32:13.040]   So when your customer service reps are talking to a customer, they know what's going on.
[01:32:13.040 --> 01:32:18.480]   The worst thing in the world is to be on hold for an hour with some, let's not say names,
[01:32:18.480 --> 01:32:20.160]   cable company.
[01:32:20.160 --> 01:32:25.560]   And they say, oh, oh, well, I have to transfer you to somebody else for that particular problem.
[01:32:25.560 --> 01:32:28.200]   And you have to start all over again.
[01:32:28.200 --> 01:32:32.640]   Zendesks make sure that each customer service reps knows what's going on.
[01:32:32.640 --> 01:32:36.920]   They've got a unified set of tools that give them the context they need to deliver great
[01:32:36.920 --> 01:32:38.920]   service in every conversation.
[01:32:38.920 --> 01:32:40.360]   Know who are you?
[01:32:40.360 --> 01:32:41.360]   What's your problem?
[01:32:41.360 --> 01:32:42.800]   I just told you.
[01:32:42.800 --> 01:32:45.960]   Most support software requires expensive consultants.
[01:32:45.960 --> 01:32:48.120]   Months of setup, you'll love it with Zendesk.
[01:32:48.120 --> 01:32:54.440]   It hours, you're up and running, but Zendesk has the capability to scale and change with
[01:32:54.440 --> 01:32:56.080]   your needs.
[01:32:56.080 --> 01:33:01.800]   So it's a perfect blend of easy to set up, easy to use, but powerful enough to be flexible
[01:33:01.800 --> 01:33:06.400]   enough to be customized to fit exactly what you want.
[01:33:06.400 --> 01:33:10.720]   Zendesk gives organizations a flexibility to move quickly, to focus on innovation, to
[01:33:10.720 --> 01:33:12.320]   adapt to growth.
[01:33:12.320 --> 01:33:13.320]   It's not a surprise.
[01:33:13.320 --> 01:33:15.600]   150,000 paid customers.
[01:33:15.600 --> 01:33:19.720]   And over a decade of experience, they're pretty good at customer service themselves.
[01:33:19.720 --> 01:33:24.840]   No matter what you need in business, Zendesk products are flexible enough to pave the path
[01:33:24.840 --> 01:33:27.520]   that's best for your organization.
[01:33:27.520 --> 01:33:42.680]   See for yourself, whether best customer service experiences are built with Zendesk.com/twitzendesk.com/twit.
[01:33:42.680 --> 01:33:47.760]   We're talking the top stories of 2020.
[01:33:47.760 --> 01:33:57.200]   I guess we can't forget when Apple, Amazon, Facebook and Google all came to testify well,
[01:33:57.200 --> 01:33:58.200]   they didn't come anywhere.
[01:33:58.200 --> 01:34:00.080]   They didn't fly their big corporate jets.
[01:34:00.080 --> 01:34:07.920]   They just sat down in a Zoom room to talk to the House Antitrust Subcommittee.
[01:34:07.920 --> 01:34:09.280]   That was quite the experience.
[01:34:09.280 --> 01:34:19.920]   And then again, later, a strangely bearded Twitter CEO and a strangely un-bearded, in
[01:34:19.920 --> 01:34:24.680]   fact, somebody who looks like he had never had any facial hair at all, Mark Zuckerberg
[01:34:24.680 --> 01:34:27.880]   testified to the Senate.
[01:34:27.880 --> 01:34:35.000]   Big Tech is being investigated by Washington, D.C. and of course it ended up with a trust
[01:34:35.000 --> 01:34:40.920]   antitrust suit filed against Google and antitrust suit filed against Facebook.
[01:34:40.920 --> 01:34:46.040]   In fact, the only company really left out of all this scrutiny was Microsoft, Paul.
[01:34:46.040 --> 01:34:52.320]   What did they suffer their penance 20 years ago and now they're in the clear?
[01:34:52.320 --> 01:34:55.560]   They're just not as public facing as these other companies.
[01:34:55.560 --> 01:35:00.680]   I mean, they're just as big as all of them, bigger than most.
[01:35:00.680 --> 01:35:06.200]   You know, writing about technology, this kind of thing is fascinating to me.
[01:35:06.200 --> 01:35:11.200]   And of course with the Microsoft case here in the US and the UK as well as a backdrop,
[01:35:11.200 --> 01:35:15.760]   it's the parallels are just obvious in many.
[01:35:15.760 --> 01:35:20.960]   You and I, and I think Jeff and I talked about the Facebook complaint and I thought how well
[01:35:20.960 --> 01:35:26.360]   written, thoughtful and well documented it was.
[01:35:26.360 --> 01:35:31.720]   This is the FTC's complaint backed by 46 states, D.C. and Guam.
[01:35:31.720 --> 01:35:34.080]   I think more states are going to sign on as well.
[01:35:34.080 --> 01:35:35.920]   California, I think, was about to sign.
[01:35:35.920 --> 01:35:41.600]   So by the way, I've had that reaction to a few of these, the Google case, the quality
[01:35:41.600 --> 01:35:42.600]   of the writing.
[01:35:42.600 --> 01:35:47.040]   It's such a weird thing to say about government, but especially our government today.
[01:35:47.040 --> 01:35:49.600]   But I actually pointed it out to my wife.
[01:35:49.600 --> 01:35:55.040]   I said, if you ever doubt that our government is incapable of intelligent acts, you get
[01:35:55.040 --> 01:35:56.040]   to read this paper.
[01:35:56.040 --> 01:35:58.160]   It's crazy.
[01:35:58.160 --> 01:36:01.120]   I think that's, I found that to be very striking.
[01:36:01.120 --> 01:36:05.000]   It contrasts so, here's why it's striking.
[01:36:05.000 --> 01:36:06.640]   It's so well written, so well thought out.
[01:36:06.640 --> 01:36:12.440]   And then you get Jim Jordan with his sleeves rolled up going, and it doesn't, it doesn't,
[01:36:12.440 --> 01:36:13.920]   the two don't seem to be related.
[01:36:13.920 --> 01:36:15.920]   Two different planets.
[01:36:15.920 --> 01:36:25.000]   So there's on the one hand this kind of visceral hatred of social media by the president
[01:36:25.000 --> 01:36:30.600]   and Republicans because the social media dares to say, well, that's not right, or that's
[01:36:30.600 --> 01:36:35.520]   not true, or, you know, and then there's this, I think fairly well thought out and maybe
[01:36:35.520 --> 01:36:43.320]   even justified probably written entirely by staffers in Congress indictment of how big
[01:36:43.320 --> 01:36:47.560]   tech has gotten, how influential it's gotten, and really how predatory, really the issue
[01:36:47.560 --> 01:36:50.160]   is how predatory it's gotten with the monopoly.
[01:36:50.160 --> 01:36:53.600]   The social media thing is kind of, I'm sorry, I got it.
[01:36:53.600 --> 01:36:59.160]   I was just gonna say, I really agree with Paul in his sense of the deja vu that we're feeling.
[01:36:59.160 --> 01:37:06.000]   Those of us who were present during the whole Microsoft antitrust stuff, when you're hearing
[01:37:06.000 --> 01:37:09.880]   this about Facebook and listening to it, it's like, oh, does that sound?
[01:37:09.880 --> 01:37:10.880]   On there.
[01:37:10.880 --> 01:37:11.880]   Oh, yeah, I remember that.
[01:37:11.880 --> 01:37:12.880]   Oh, yeah.
[01:37:12.880 --> 01:37:16.640]   I mean, it really is just exactly the same abuse of power.
[01:37:16.640 --> 01:37:22.440]   I've asked this on several shows, but I want to ask you guys, it's my sense that, you know,
[01:37:22.440 --> 01:37:26.560]   I mean, the Microsoft thing dragged on for years, almost 10 years.
[01:37:26.560 --> 01:37:28.320]   Eventually, it never did settle.
[01:37:28.320 --> 01:37:29.560]   There was a consent decree.
[01:37:29.560 --> 01:37:34.080]   Microsoft said, all right, all right, we'll let an ombudsman come and watch what we do.
[01:37:34.080 --> 01:37:36.320]   We'll agree not to do this again, this again.
[01:37:36.320 --> 01:37:37.600]   The same thing happened in Europe.
[01:37:37.600 --> 01:37:40.760]   They had the browser ballot and various disconnect IE.
[01:37:40.760 --> 01:37:41.760]   Yeah.
[01:37:41.760 --> 01:37:42.760]   Things.
[01:37:42.760 --> 01:37:48.040]   But my sense of it is the real success of the case against Microsoft was that it just
[01:37:48.040 --> 01:37:53.320]   made them think twice before they did some of them more predatory practices that they
[01:37:53.320 --> 01:37:54.320]   have done on their built-in.
[01:37:54.320 --> 01:37:57.360]   The consent decree is what led to the rise of the companies we're not worried about,
[01:37:57.360 --> 01:37:58.360]   actually.
[01:37:58.360 --> 01:37:59.360]   Google.
[01:37:59.360 --> 01:38:00.360]   I mean, in Facebook.
[01:38:00.360 --> 01:38:01.360]   Yeah, I think so.
[01:38:01.360 --> 01:38:06.120]   A lot of people said Google wouldn't exist if Microsoft had continued its practices within
[01:38:06.120 --> 01:38:07.120]   the Internet.
[01:38:07.120 --> 01:38:08.120]   All of these companies.
[01:38:08.120 --> 01:38:09.120]   Say more about that, Paul, please.
[01:38:09.120 --> 01:38:13.800]   I'm curious to hear more about the connection to the rise.
[01:38:13.800 --> 01:38:21.360]   No, because when I entered the industry, I sort of think of myself as someone who covers
[01:38:21.360 --> 01:38:23.240]   personal technology.
[01:38:23.240 --> 01:38:27.080]   Most people that know about me think of me as someone who covers Microsoft because when
[01:38:27.080 --> 01:38:29.440]   I came in, Microsoft was personal technology.
[01:38:29.440 --> 01:38:32.600]   It was 100% of it.
[01:38:32.600 --> 01:38:36.080]   The Internet and mobile and a lot of other things have changed that.
[01:38:36.080 --> 01:38:43.920]   Microsoft might have done to a nascent Google or a read nascent, if that's a word, Apple
[01:38:43.920 --> 01:38:50.000]   in the early 2000s or a Facebook, what it had done previously to word perfect and Netscape
[01:38:50.000 --> 01:38:52.840]   and Lotus and so many others.
[01:38:52.840 --> 01:38:55.760]   But they were shackled.
[01:38:55.760 --> 01:39:00.960]   And Bill Gates in that time frame said that Microsoft would not be distracted.
[01:39:00.960 --> 01:39:04.160]   If you talked about it now, he says, "Oh, yeah, we were distracted."
[01:39:04.160 --> 01:39:05.160]   Yeah.
[01:39:05.160 --> 01:39:09.120]   And I have to think it wasn't just Microsoft, but other companies who said, "Hmm, let's
[01:39:09.120 --> 01:39:12.000]   not do that because we don't want to..."
[01:39:12.000 --> 01:39:14.480]   Microsoft could just say, "Oh, yeah, we're going to do that thing."
[01:39:14.480 --> 01:39:17.000]   And then the business would just disappear.
[01:39:17.000 --> 01:39:20.040]   What do you think Microsoft never came out with anything?
[01:39:20.040 --> 01:39:24.600]   What might they have gone into if they hadn't been shackled or they've won the case?
[01:39:24.600 --> 01:39:29.200]   Well, I mean, what you could look at is what has happened, right?
[01:39:29.200 --> 01:39:35.480]   So is there a company on Earth that could have built a search engine to rival what Google
[01:39:35.480 --> 01:39:36.480]   did?
[01:39:36.480 --> 01:39:37.480]   Yes, that company is Microsoft.
[01:39:37.480 --> 01:39:42.920]   Is there a company that already had an incredible successful for the day mobile platform that
[01:39:42.920 --> 01:39:44.120]   could have taken the iPhone?
[01:39:44.120 --> 01:39:47.160]   Yes, that company was Microsoft.
[01:39:47.160 --> 01:39:54.960]   Microsoft was 100% of the world, with my world, certainly, until it wasn't.
[01:39:54.960 --> 01:39:55.960]   Until 1998.
[01:39:55.960 --> 01:40:01.800]   Yeah, and by the way, I think it's a good thing overall.
[01:40:01.800 --> 01:40:05.040]   I felt very strongly at the time that Microsoft should have been broken up.
[01:40:05.040 --> 01:40:08.520]   I was horrified by what I saw in all the testimony.
[01:40:08.520 --> 01:40:12.560]   In fact, one of the most horrible experiences of my life was sitting through.
[01:40:12.560 --> 01:40:17.000]   I actually requested anyone in any journalist could have gotten this as the...
[01:40:17.000 --> 01:40:18.840]   I don't remember how many it was.
[01:40:18.840 --> 01:40:23.120]   21 tape, like literally VHS tapes of the Bill Gates deposition.
[01:40:23.120 --> 01:40:24.120]   If you...
[01:40:24.120 --> 01:40:25.120]   Oh, my God.
[01:40:25.120 --> 01:40:28.160]   I think it's hard to watch the entire Godfather trilogy at once.
[01:40:28.160 --> 01:40:30.880]   I would challenge you to watch any of this.
[01:40:30.880 --> 01:40:32.600]   It is the hardest thing to watch.
[01:40:32.600 --> 01:40:33.600]   Sitelating, he ate.
[01:40:33.600 --> 01:40:35.400]   Oh, it is awful.
[01:40:35.400 --> 01:40:43.240]   And if there are lessons to be learned by Google today and Apple and Amazon and Facebook,
[01:40:43.240 --> 01:40:44.240]   there it is.
[01:40:44.240 --> 01:40:46.080]   Don't do that.
[01:40:46.080 --> 01:40:54.240]   So, do you think we'll have the same salubrious effect, the suits against Facebook and Google?
[01:40:54.240 --> 01:40:55.240]   You know what?
[01:40:55.240 --> 01:40:59.000]   The big commonality here is that all of those companies, the four we're talking about today
[01:40:59.000 --> 01:41:03.280]   and Microsoft, are what they call gatekeepers.
[01:41:03.280 --> 01:41:06.120]   This is the challenge.
[01:41:06.120 --> 01:41:11.800]   I think you'll see because of so much antitrust action right now, legal action against these
[01:41:11.800 --> 01:41:12.800]   companies.
[01:41:12.800 --> 01:41:17.880]   Even Apple, which is in many ways very belligerent about this kind of stuff, has taken steps
[01:41:17.880 --> 01:41:21.840]   this year to scale back from the cliff a little bit with regards to their relationship
[01:41:21.840 --> 01:41:24.320]   with developers, for example.
[01:41:24.320 --> 01:41:29.320]   So I think in some cases you'll see companies make changes voluntarily.
[01:41:29.320 --> 01:41:30.760]   I think you will see stalling.
[01:41:30.760 --> 01:41:32.880]   Some of these things are going to take years and years and years.
[01:41:32.880 --> 01:41:38.000]   But yeah, the hope is that the impact, however it comes about, it will be similar to what
[01:41:38.000 --> 01:41:39.240]   happened to Microsoft.
[01:41:39.240 --> 01:41:44.480]   Which by the way today is literally right the second is probably the second biggest company
[01:41:44.480 --> 01:41:45.680]   in the world.
[01:41:45.680 --> 01:41:50.600]   So it's not like they, you know, it was good for Microsoft in the long run, right?
[01:41:50.600 --> 01:41:51.600]   That's right.
[01:41:51.600 --> 01:41:56.720]   Sometimes you need to go through a little bit of pain to get to the other side and to a
[01:41:56.720 --> 01:41:57.840]   better place.
[01:41:57.840 --> 01:42:02.880]   And Microsoft that was forced on them, this is not something they would have done voluntarily.
[01:42:02.880 --> 01:42:07.840]   And we'll see, you know, how these companies, they're all going to react in their own unique
[01:42:07.840 --> 01:42:08.840]   way, I guess.
[01:42:08.840 --> 01:42:14.000]   So there's this kind of thoughtful attempt to figure out what's going on and what to
[01:42:14.000 --> 01:42:16.040]   do about it on the one hand.
[01:42:16.040 --> 01:42:21.520]   And on the other hand, there's a lot of frothing at the mouth and threats against section
[01:42:21.520 --> 01:42:22.520]   230.
[01:42:22.520 --> 01:42:25.800]   What is section 230, Jeff?
[01:42:25.800 --> 01:42:33.000]   Section 230 says that a platform or publisher is not responsible for the actions of others
[01:42:33.000 --> 01:42:39.680]   on their platform or publishing or publishing platform so that we would encourage conversation
[01:42:39.680 --> 01:42:45.280]   that creates a safe harbor of sorts and moderate the sword and moderation, right?
[01:42:45.280 --> 01:42:46.280]   Yes.
[01:42:46.280 --> 01:42:47.280]   Yes.
[01:42:47.280 --> 01:42:49.880]   It gives them the sword, which says you can choose to take down stuff.
[01:42:49.880 --> 01:42:53.760]   And if you missed stuff, which was the problem with case law before, you will be in more
[01:42:53.760 --> 01:42:54.760]   trouble for trying.
[01:42:54.760 --> 01:42:56.260]   So please try.
[01:42:56.260 --> 01:42:59.800]   And you can allow conversation to happen without getting in trouble.
[01:42:59.800 --> 01:43:05.240]   So it gives you both the opportunity because Congress in its last smart act knew that this
[01:43:05.240 --> 01:43:07.880]   internet was going to be a platform for conversation.
[01:43:07.880 --> 01:43:12.440]   And without this, if everyone reliable for anything everyone did on their platform, they
[01:43:12.440 --> 01:43:17.400]   would allow nothing to happen on their platform to be stuck with mass media still.
[01:43:17.400 --> 01:43:23.760]   And honestly, it isn't section 230 that is the problem for the president.
[01:43:23.760 --> 01:43:25.960]   That has nothing to do with section 230.
[01:43:25.960 --> 01:43:32.720]   He's upset, of course, because first Twitter and then Facebook started to label some of
[01:43:32.720 --> 01:43:37.400]   his tweets and posts with fact checking.
[01:43:37.400 --> 01:43:41.520]   This is where we're stuck in the paradox is the left goes after the platform saying,
[01:43:41.520 --> 01:43:42.520]   take down hate speech.
[01:43:42.520 --> 01:43:46.280]   And they take down the hate speech and then the right says, hey, that was my speech.
[01:43:46.280 --> 01:43:48.160]   And that's what Trump is basically saying.
[01:43:48.160 --> 01:43:53.560]   By the way, if Twitter labeled one of your tweets as misinformation, would that cause
[01:43:53.560 --> 01:43:55.040]   some self reflection?
[01:43:55.040 --> 01:44:02.280]   I mean, I think most people confronted by that would pause and think, maybe I'm not
[01:44:02.280 --> 01:44:03.640]   doing the right thing here.
[01:44:03.640 --> 01:44:07.800]   They've done it so much in the last month, but I have to point out they only started
[01:44:07.800 --> 01:44:10.120]   doing that a couple of months ago.
[01:44:10.120 --> 01:44:11.120]   That's right.
[01:44:11.120 --> 01:44:13.040]   Yeah, I finally grew some for four years.
[01:44:13.040 --> 01:44:21.040]   For four years, anything he or others posted, regardless of its absurdity was just, you
[01:44:21.040 --> 01:44:23.800]   know, got the sluft hanging up hanging.
[01:44:23.800 --> 01:44:27.360]   And it was only when they started to fact check and say, you know, this might not be
[01:44:27.360 --> 01:44:28.360]   true.
[01:44:28.360 --> 01:44:33.600]   You might want to look at other sources as benign, a kind of a, it wasn't as even a slap on
[01:44:33.600 --> 01:44:38.000]   the wrist, a nudge as one could imagine that he really started to say, all right, we've
[01:44:38.000 --> 01:44:40.040]   got to do something about these platforms.
[01:44:40.040 --> 01:44:43.200]   It's, we're going to do something about that, not about what I'm doing.
[01:44:43.200 --> 01:44:44.200]   Yeah.
[01:44:44.200 --> 01:44:46.160]   Like, this is not the right approach to a pro.
[01:44:46.160 --> 01:44:50.640]   And they aren't, by the way, to this day, they are still, you know, he's still tweeting
[01:44:50.640 --> 01:44:53.840]   stuff that they are still fact checking.
[01:44:53.840 --> 01:44:54.840]   Even now.
[01:44:54.840 --> 01:44:59.160]   Well, the latest, so much fun is that when he says that he won, now Twitter just started
[01:44:59.160 --> 01:45:04.640]   saying, yeah, authorities say weeks, weeks, yeah, yeah.
[01:45:04.640 --> 01:45:05.640]   Yeah.
[01:45:05.640 --> 01:45:09.640]   Well, it happened perhaps because of the electoral college voting.
[01:45:09.640 --> 01:45:16.240]   That was the, but I think this is kind of a very specific issue about a very specific
[01:45:16.240 --> 01:45:17.680]   person in some ways.
[01:45:17.680 --> 01:45:25.040]   I don't think that I don't see social media being anti-right, you know, or republic and
[01:45:25.040 --> 01:45:26.160]   or whatever.
[01:45:26.160 --> 01:45:30.440]   If anything, they've, they've allowed this to happen for years.
[01:45:30.440 --> 01:45:31.440]   Right.
[01:45:31.440 --> 01:45:34.000]   They've been very accommodating.
[01:45:34.000 --> 01:45:35.960]   The president is making a lot of money from it.
[01:45:35.960 --> 01:45:36.960]   The president is a, yeah.
[01:45:36.960 --> 01:45:38.160]   Well, that's another point.
[01:45:38.160 --> 01:45:39.440]   The president is a lame duck.
[01:45:39.440 --> 01:45:43.440]   We're one month away from the inauguration of president.
[01:45:43.440 --> 01:45:44.440]   Why are we limping?
[01:45:44.440 --> 01:45:48.160]   You were limping home.
[01:45:48.160 --> 01:45:53.960]   But do you think in the month's remaining that he did threaten to veto the defense spending
[01:45:53.960 --> 01:45:54.960]   bill?
[01:45:54.960 --> 01:45:57.720]   I don't, it was passed with a veto proof margin.
[01:45:57.720 --> 01:45:59.000]   It would be a very interesting thing.
[01:45:59.000 --> 01:46:03.560]   He still has not vetoed it if he me vetoed it and forced Republican members of Congress
[01:46:03.560 --> 01:46:06.400]   then to vote against him.
[01:46:06.400 --> 01:46:09.680]   That would be an interesting contract, Tom.
[01:46:09.680 --> 01:46:14.040]   Do you think that anything will happen to 230 between now and January 20th?
[01:46:14.040 --> 01:46:17.320]   And then the next question, maybe that's for the end of the show, but the next question
[01:46:17.320 --> 01:46:23.080]   is Biden himself has said he doesn't think 230 is such a good idea.
[01:46:23.080 --> 01:46:24.920]   Will it continue to be under assault?
[01:46:24.920 --> 01:46:25.920]   Yes.
[01:46:25.920 --> 01:46:27.160]   That's my story for next year.
[01:46:27.160 --> 01:46:28.160]   Oh, yes.
[01:46:28.160 --> 01:46:29.440]   Just like when you steal my numbers on twig.
[01:46:29.440 --> 01:46:31.040]   I just stole your story.
[01:46:31.040 --> 01:46:33.560]   So we'll talk about, all right, hold that thought then we won't talk about.
[01:46:33.560 --> 01:46:36.760]   We'll save that because that's an interesting, an interesting question.
[01:46:36.760 --> 01:46:38.440]   I like the dynamic you two have.
[01:46:38.440 --> 01:46:39.440]   I know.
[01:46:39.440 --> 01:46:41.640]   That's good.
[01:46:41.640 --> 01:46:45.920]   Brothers from different mother.
[01:46:45.920 --> 01:46:46.920]   Let's see.
[01:46:46.920 --> 01:46:47.920]   What other stories are you?
[01:46:47.920 --> 01:46:48.920]   I'm powering you.
[01:46:48.920 --> 01:46:49.920]   Oh, I know.
[01:46:49.920 --> 01:46:50.920]   I know a big story.
[01:46:50.920 --> 01:46:51.920]   He was.
[01:46:51.920 --> 01:46:54.520]   I know a big story.
[01:46:54.520 --> 01:47:00.400]   Let me play a little video that will lead into our next story.
[01:47:00.400 --> 01:47:05.040]   This came from the Apple event announcing the new iPhones.
[01:47:05.040 --> 01:47:07.680]   of a new era for iPhone.
[01:47:07.680 --> 01:47:11.120]   Today we're bringing 5G to iPhone.
[01:47:11.120 --> 01:47:14.460]   5G, 5G, 5G, 5G.
[01:47:14.460 --> 01:47:24.900]   5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, or 5G, 5G, 5G, 5G,
[01:47:24.900 --> 01:47:30.560]   5G, 5G, 5G, 5G, 5G.
[01:47:30.560 --> 01:47:38.400]   iPhone 12 with 5G. 5G, 5G, 5G, 5G. 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G, 5G.
[01:47:38.400 --> 01:47:45.500]   This is more 5G than the world! This isn't the funny thing and this is the keynote! This wasn't an ad!
[01:47:45.500 --> 01:47:48.900]   This was the announcement of the new iPhones.
[01:47:48.900 --> 01:47:54.740]   5G - 5G, 5G, 5G, 5G, 5G... Yes, you're right. It's a long board.
[01:47:54.740 --> 01:48:01.740]   Thank you for joining us. Stay safe and have a great day.
[01:48:01.740 --> 01:48:06.740]   So here's the question. How has 5G transformed your lives today?
[01:48:06.740 --> 01:48:10.740]   Oh, I test this regularly, Leo. My phone now says 5G.
[01:48:10.740 --> 01:48:15.740]   Yeah? That's what changed. Because I'm going to tell you, the speeds are not any different.
[01:48:15.740 --> 01:48:20.740]   In fact, they might be worse. Jeff, at least you're in a metro.
[01:48:20.740 --> 01:48:25.740]   A millimeter wave 5G from Verizon? 5. What? Huh?
[01:48:25.740 --> 01:48:33.740]   Huh? Huh? The only story that I know that was of any import about 5G this year was the burning of the 5G towers
[01:48:33.740 --> 01:48:36.740]   because some people thought it caused coronavirus.
[01:48:36.740 --> 01:48:42.740]   That is probably in a year of incredible stupidity and raging dumbness.
[01:48:42.740 --> 01:48:48.740]   That may have been the dumbest thing to happen in 2020 and that's saying a lot.
[01:48:48.740 --> 01:48:50.740]   Yeah. I'm not saying an awful lot.
[01:48:50.740 --> 01:48:54.740]   Yeah. I agree. So, Steve, you're a system.
[01:48:54.740 --> 01:48:58.740]   No, I was just nodding in agreement with all this.
[01:48:58.740 --> 01:49:02.740]   The whole 5G thing never made that much sense to me.
[01:49:02.740 --> 01:49:09.740]   It seemed like a total buzz. Just a buzz word and it's like, "Okay, we're going to have that too."
[01:49:09.740 --> 01:49:12.740]   What are we going to do when it works?
[01:49:12.740 --> 01:49:17.740]   No one has truly unlimited data. What if I can download a season of shows on Netflix and 10, so...
[01:49:17.740 --> 01:49:22.740]   That's it. You've used up your... I'll kill my months worth of data and that's it. 17 seconds.
[01:49:22.740 --> 01:49:24.740]   Uh-huh. That's a good point.
[01:49:24.740 --> 01:49:28.740]   And I'm not feeling any lack of bandwidth on my 4G.
[01:49:28.740 --> 01:49:30.740]   Right. I've got enough Gs as it is.
[01:49:30.740 --> 01:49:35.740]   You know, look, there is a technology. There are several technologies that make up 5G.
[01:49:35.740 --> 01:49:38.740]   They're real. They're not made up.
[01:49:38.740 --> 01:49:46.740]   But the problem is by overhyping it, overmarketing it, buying, I don't know, what Verizon paid Apple to inject the word 5G on it.
[01:49:46.740 --> 01:49:49.740]   It's a hundred times into their keynote.
[01:49:49.740 --> 01:49:50.740]   But that has actually done...
[01:49:50.740 --> 01:49:51.740]   There's more than 5 zeros in it.
[01:49:51.740 --> 01:49:57.740]   That's done more harm to 5G. That's just created a whole nation of people going, "Yeah, so what? 5, who cares?"
[01:49:57.740 --> 01:50:04.740]   Right? I mean, eventually 5G could be something...
[01:50:04.740 --> 01:50:12.740]   This is my wish for humanity is that COVID never happened this year and 5G would be what we were complaining about this year.
[01:50:12.740 --> 01:50:13.740]   Yeah.
[01:50:13.740 --> 01:50:16.740]   That would have been great.
[01:50:16.740 --> 01:50:22.740]   It is hard to get... I rate about anything when you've got COVID.
[01:50:22.740 --> 01:50:26.740]   You don't cut it. You put it in perspective. It's like, "Well, 5G is stupid."
[01:50:26.740 --> 01:50:27.740]   Yeah.
[01:50:27.740 --> 01:50:33.740]   Okay. That's it. That's the story. 5G. 5G. 5G. 5G.
[01:50:33.740 --> 01:50:38.740]   The other story, the gift that kept on giving in a weird way is Elon Musk.
[01:50:41.740 --> 01:50:51.740]   There are so many... So on the one hand, Elon Musk has single-handedly revived our aspirations to go into space.
[01:50:51.740 --> 01:50:52.740]   Yeah.
[01:50:52.740 --> 01:51:00.740]   With amazing launches and technological superiority and the landing of the twin landing of the rocket...
[01:51:00.740 --> 01:51:02.740]   Was that this year, John? That was this year.
[01:51:02.740 --> 01:51:05.740]   The recovery...
[01:51:05.740 --> 01:51:10.740]   I almost come to tears when I watch a rocket come down from space and land on a platform.
[01:51:10.740 --> 01:51:15.740]   It is the most mesmerizing and amazing, awe-inspiring event.
[01:51:15.740 --> 01:51:20.740]   But the thing is, there's something about Elon Musk. I can't stand it.
[01:51:20.740 --> 01:51:22.740]   I can't put my phone on.
[01:51:22.740 --> 01:51:24.740]   Would you ride in his rocket ship, Paul? Would you ride in his...
[01:51:24.740 --> 01:51:26.740]   Would I ride in his... No.
[01:51:26.740 --> 01:51:29.740]   I went to the top of the Stratosphere in Vegas one time and launched up,
[01:51:29.740 --> 01:51:32.740]   and I realized in that moment I can't be an astronaut.
[01:51:32.740 --> 01:51:33.740]   So, no.
[01:51:33.740 --> 01:51:38.740]   This is the ride that you want to take. This is the Falcon boosters.
[01:51:38.740 --> 01:51:44.740]   Having been used to launch your rocket coming in to land.
[01:51:44.740 --> 01:51:46.740]   That's just... Just land.
[01:51:46.740 --> 01:51:47.740]   And they're gonna touch them down.
[01:51:47.740 --> 01:51:51.740]   It's like the first time you saw the space shuttle land like an airplane.
[01:51:51.740 --> 01:51:54.740]   And it's just... You can't believe you're seeing this happen.
[01:51:54.740 --> 01:51:58.740]   So this is a miracle... Nobody gave me any crap for one of them blowing up recently.
[01:51:58.740 --> 01:52:00.740]   That was... No, no, because...
[01:52:00.740 --> 01:52:04.740]   But, you know, that's the funny thing. We see those things blowing up and the challenger goes in.
[01:52:04.740 --> 01:52:07.740]   But everybody agreed. No, it was a massive success.
[01:52:07.740 --> 01:52:11.740]   The bringing back of the booster was a minor.
[01:52:11.740 --> 01:52:12.740]   That wasn't really what they were testing.
[01:52:12.740 --> 01:52:17.740]   This was, by the way, the rocket that's going to bring humans to Mars.
[01:52:17.740 --> 01:52:18.740]   Right.
[01:52:18.740 --> 01:52:22.740]   So, Elon, I mean, look at that. Those beautiful rockets landing in Cinchrony.
[01:52:22.740 --> 01:52:27.740]   Like, it's like... It's like... Ballet.
[01:52:27.740 --> 01:52:30.740]   On the one hand is doing these amazing things.
[01:52:30.740 --> 01:52:38.740]   On the other hand is saying, "Free America now. There's no COVID. Let my workers go back to work."
[01:52:38.740 --> 01:52:39.740]   I know.
[01:52:39.740 --> 01:52:41.740]   It's hard to reconcile.
[01:52:41.740 --> 01:52:48.740]   He and Grimes named their new Baby X-A-E-A-12 or something.
[01:52:48.740 --> 01:52:50.740]   It's a Star Wars character, isn't it? What does that mean?
[01:52:50.740 --> 01:52:51.740]   I don't know what it is.
[01:52:51.740 --> 01:52:52.740]   It's crazy.
[01:52:52.740 --> 01:52:56.740]   And yet SpaceX launched two NASA astronauts.
[01:52:56.740 --> 01:52:57.740]   Yeah.
[01:52:57.740 --> 01:52:58.740]   Somehow he spilled those smart things.
[01:52:58.740 --> 01:53:05.740]   The Japanese astronaut who wrote in the most recent crude dragon said it was the best ride.
[01:53:05.740 --> 01:53:07.740]   He's been on three shuttle launches.
[01:53:07.740 --> 01:53:09.740]   It's the best ride he's ever had.
[01:53:09.740 --> 01:53:15.740]   They used Baby Yoda as a zero gravity monitor.
[01:53:15.740 --> 01:53:20.740]   He's also, by the way, the second richest man in the world now.
[01:53:20.740 --> 01:53:21.740]   Oh, boy.
[01:53:21.740 --> 01:53:26.740]   So, I just think Elon is the gift that keeps on giving.
[01:53:26.740 --> 01:53:32.740]   This is Elon Musk. Maybe he's PT Barnum. I don't know what he is.
[01:53:32.740 --> 01:53:33.740]   He's unique.
[01:53:33.740 --> 01:53:36.740]   He's unique, yeah.
[01:53:36.740 --> 01:53:42.740]   And I'm glad he's around, but I'm not going to buy another Tesla.
[01:53:42.740 --> 01:53:53.740]   He also announced, demonstrated how a neural link could control live pigs.
[01:53:53.740 --> 01:53:57.740]   He described it as a fit bit in your skull.
[01:53:57.740 --> 01:54:00.740]   It's animal farm come to life.
[01:54:00.740 --> 01:54:02.740]   It's the strangest thing ever.
[01:54:02.740 --> 01:54:10.740]   They inserted a device in a pig's brain, a live pig, and then showed the pig doing something
[01:54:10.740 --> 01:54:13.740]   because humans told it to.
[01:54:13.740 --> 01:54:17.740]   It's, again, the gift that just keeps on giving.
[01:54:17.740 --> 01:54:20.740]   I don't know what he's smoking, but I'll have some of that.
[01:54:20.740 --> 01:54:22.740]   Oh, I think we know what he's smoking.
[01:54:22.740 --> 01:54:26.740]   We know, don't we?
[01:54:26.740 --> 01:54:28.740]   We do.
[01:54:28.740 --> 01:54:29.740]   We do.
[01:54:29.740 --> 01:54:34.740]   This was not a good year for self-driving cars, was it?
[01:54:34.740 --> 01:54:37.740]   Apple seems to have pulled back.
[01:54:37.740 --> 01:54:44.740]   Uber sold its self-driving car division.
[01:54:44.740 --> 01:54:50.740]   A former Google and Uber self-driving car engineered, pleaded guilty to trade secret theft and was
[01:54:50.740 --> 01:54:57.740]   fined kind of an unimaginably large amount to which he promptly declared bankruptcy.
[01:54:57.740 --> 01:55:02.740]   Talking about Anthony Levin-Dowski.
[01:55:02.740 --> 01:55:08.740]   Let me ask you, Steve, because you're the most geekiest of the bunch here.
[01:55:08.740 --> 01:55:12.740]   Is it harder to do a self-driving car than we knew?
[01:55:12.740 --> 01:55:15.740]   I remember in the very earliest days of the DARPA challenge.
[01:55:15.740 --> 01:55:16.740]   Remember this?
[01:55:16.740 --> 01:55:19.740]   They wanted autonomous vehicles to drive in the desert.
[01:55:19.740 --> 01:55:25.740]   And for the first five years, the cars would go two feet and go co-raining off the road.
[01:55:25.740 --> 01:55:27.740]   It was humorous.
[01:55:27.740 --> 01:55:31.740]   And then all of a sudden, not only are they completing the DARPA challenge, but they're
[01:55:31.740 --> 01:55:36.740]   putting people in these cars and they're driving around Phoenix and other parts of the country.
[01:55:36.740 --> 01:55:39.740]   And then a self-driving car kills somebody.
[01:55:39.740 --> 01:55:43.740]   And then Tesla seemed to keep running into things.
[01:55:43.740 --> 01:55:46.740]   Is it easier or harder or both to do a self-driving vehicle?
[01:55:46.740 --> 01:55:52.740]   It's completely insanely impossible to even think that this should be done for a good thing.
[01:55:52.740 --> 01:55:57.740]   I mean, I'm on record years ago on the podcast saying, "What?
[01:55:57.740 --> 01:55:59.740]   They're going to drive themselves?"
[01:55:59.740 --> 01:56:00.740]   No!
[01:56:00.740 --> 01:56:03.740]   Clearly, crazy.
[01:56:03.740 --> 01:56:11.740]   I mean, it's been a good learning experience of, okay, so way, way back.
[01:56:11.740 --> 01:56:17.740]   I worked for several years at Stanford University's AI Lab.
[01:56:17.740 --> 01:56:20.740]   And this was in the early '70s.
[01:56:20.740 --> 01:56:25.740]   And we thought we were going to, like, there was a cart project.
[01:56:25.740 --> 01:56:31.740]   It was a completely computer-controlled robot cart in 1970.
[01:56:31.740 --> 01:56:37.740]   And the thing we learned was that this was impossible.
[01:56:37.740 --> 01:56:40.740]   I mean, it was like, you know, back in the early days of AI.
[01:56:40.740 --> 01:56:44.740]   Oh, yeah, we're going to make smart computers that are going to be intelligent.
[01:56:44.740 --> 01:56:52.740]   Well, it is amazing that we have lost jeopardy to an automated machine.
[01:56:52.740 --> 01:56:55.740]   That's astonishing.
[01:56:55.740 --> 01:57:00.740]   But what these exercises in attempting to solve these problems always do
[01:57:00.740 --> 01:57:07.740]   is teach the people who are trying to solve them actually how hard they are to solve.
[01:57:07.740 --> 01:57:15.740]   And there's just so much that we take for granted about what we see in our visual field
[01:57:15.740 --> 01:57:23.740]   and how we interpret it, you know, from the millions of years of evolving to be able to do this
[01:57:23.740 --> 01:57:29.740]   for a reason of our own survival, that what you learn when you try to do it with a machine
[01:57:29.740 --> 01:57:35.740]   is how much you take what is natural to you for granted.
[01:57:35.740 --> 01:57:41.740]   So, you know, and we've talked about all kinds of games that you can play with the car driving AI,
[01:57:41.740 --> 01:57:50.740]   where you paint some weird stripes on the road and the car just stops because, you know, it thinks there's a wall there.
[01:57:50.740 --> 01:57:54.740]   But no, there's just some particularly shaped paint on the road.
[01:57:54.740 --> 01:57:58.740]   If it's a white truck and the road, it might plow straight into it.
[01:57:58.740 --> 01:58:01.740]   Because it thought it could fit under.
[01:58:01.740 --> 01:58:03.740]   But, no, miscalculate that a little bit.
[01:58:03.740 --> 01:58:11.740]   It's funny, this is not unusual, but especially common when computers try to emulate things humans can do.
[01:58:11.740 --> 01:58:14.740]   That it's simultaneously easier than you think and harder than you think.
[01:58:14.740 --> 01:58:23.740]   A two-year-old can recognize his mother, but a computer has a hard time, you know, figuring out if that black person committed a crime
[01:58:23.740 --> 01:58:26.740]   or is a Supreme Court justice.
[01:58:26.740 --> 01:58:30.740]   It's both harder and easier than it seems.
[01:58:30.740 --> 01:58:38.740]   And we're kind of caught in that middle ground now where it works, but it doesn't work.
[01:58:38.740 --> 01:58:47.740]   This really is the OG show that was interesting because we're all kind of the voice of caution, like, yeah, kids, go ahead and try it.
[01:58:47.740 --> 01:58:48.740]   Try it, you know.
[01:58:48.740 --> 01:58:49.740]   I'm not getting that car though.
[01:58:49.740 --> 01:58:50.740]   Tick tock big.
[01:58:50.740 --> 01:58:51.740]   I don't know.
[01:58:51.740 --> 01:58:53.740]   Get off of my lawn, Tick tock.
[01:58:53.740 --> 01:58:58.740]   Getting in a car and not paying attention is the dumbest thing anyone does.
[01:58:58.740 --> 01:59:01.740]   And yet, yeah, that's where we're all.
[01:59:01.740 --> 01:59:10.740]   I, we don't have one now, but we, most of the cars I've owned as an adult have been stick shifts and part of the rationale there is you have to, you can't...
[01:59:10.740 --> 01:59:11.740]   You have to drive.
[01:59:11.740 --> 01:59:12.740]   You have to drive.
[01:59:12.740 --> 01:59:14.740]   Yeah, you have to actually have to pay attention to what you're doing.
[01:59:14.740 --> 01:59:15.740]   That's a good point.
[01:59:15.740 --> 01:59:16.740]   And I think there's some merit to that.
[01:59:16.740 --> 01:59:20.740]   It's really hard to text while you're shifting into fourth gear.
[01:59:20.740 --> 01:59:21.740]   Yeah, exactly.
[01:59:21.740 --> 01:59:24.740]   I have a key that I have to turn to start my engine.
[01:59:24.740 --> 01:59:25.740]   What?
[01:59:25.740 --> 01:59:26.740]   Just, you know, FYI.
[01:59:26.740 --> 01:59:27.740]   You're making an explicit action.
[01:59:27.740 --> 01:59:28.740]   It's nice.
[01:59:28.740 --> 01:59:37.740]   It's funny because my Tesla could parallel park perfectly, but it would try to pull into the median strip every time I went around a particular curve.
[01:59:37.740 --> 01:59:43.740]   It was just, it's, it's simultaneously amazing and incredibly stupid.
[01:59:43.740 --> 01:59:45.740]   And that's one of the nicest examples.
[01:59:45.740 --> 01:59:55.740]   One of the nicest examples of a compromise that I've used it a lot because I think it's so cool was the Palm Pilots idea of asking you to do it.
[01:59:55.740 --> 01:59:57.740]   And I think it's really fun to do it.
[01:59:57.740 --> 01:59:58.740]   And I think it's really fun to do it.
[01:59:58.740 --> 01:59:59.740]   And I think it's really fun to do it.
[01:59:59.740 --> 02:00:00.740]   And I think it's really fun to do it.
[02:00:00.740 --> 02:00:01.740]   And I think it's really fun to do it.
[02:00:01.740 --> 02:00:02.740]   And I think it's really fun to do it.
[02:00:02.740 --> 02:00:03.740]   And I think it's really fun to do it.
[02:00:03.740 --> 02:00:04.740]   And I think it's really fun to do it.
[02:00:04.740 --> 02:00:05.740]   And I think it's really fun to do it.
[02:00:05.740 --> 02:00:06.740]   And I think it's really fun to do it.
[02:00:06.740 --> 02:00:07.740]   And I think it's really fun to do it.
[02:00:07.740 --> 02:00:08.740]   And I think it's really fun to do it.
[02:00:08.740 --> 02:00:09.740]   And I think it's really fun to do it.
[02:00:09.740 --> 02:00:10.740]   And I think it's really fun to do it.
[02:00:10.740 --> 02:00:11.740]   And I think it's really fun to do it.
[02:00:11.740 --> 02:00:12.740]   And I think it's really fun to do it.
[02:00:12.740 --> 02:00:18.740]   And I think it's really fun to do it.
[02:00:18.740 --> 02:00:25.740]   And I think it's really fun to do it.
[02:00:25.740 --> 02:00:26.740]   And I think it's really fun to do it.
[02:00:26.740 --> 02:00:27.740]   And I think it's really fun to do it.
[02:00:27.740 --> 02:00:28.740]   And I think it's really fun to do it.
[02:00:28.740 --> 02:00:29.740]   And I think it's really fun to do it.
[02:00:29.740 --> 02:00:30.740]   And I think it's really fun to do it.
[02:00:30.740 --> 02:00:31.740]   And I think it's really fun to do it.
[02:00:31.740 --> 02:00:32.740]   And I think it's really fun to do it.
[02:00:32.740 --> 02:00:33.740]   And I think it's really fun to do it.
[02:00:33.740 --> 02:00:34.740]   And I think it's really fun to do it.
[02:00:34.740 --> 02:00:35.740]   And I think it's really fun to do it.
[02:00:35.740 --> 02:00:36.740]   And I think it's really fun to do it.
[02:00:36.740 --> 02:00:37.740]   And I think it's really fun to do it.
[02:00:37.740 --> 02:00:38.740]   And I think it's really fun to do it.
[02:00:38.740 --> 02:00:39.740]   And I think it's really fun to do it.
[02:00:39.740 --> 02:00:42.740]   And I think it's really fun to do it.
[02:00:42.740 --> 02:00:43.740]   And I think it's really fun to do it.
[02:00:43.740 --> 02:00:44.740]   And I think it's really fun to do it.
[02:00:44.740 --> 02:00:45.740]   And I think it's really fun to do it.
[02:00:45.740 --> 02:00:46.740]   And I think it's really fun to do it.
[02:00:46.740 --> 02:00:47.740]   And I think it's really fun to do it.
[02:00:47.740 --> 02:00:48.740]   And I think it's really fun to do it.
[02:00:48.740 --> 02:00:49.740]   And I think it's really fun to do it.
[02:00:49.740 --> 02:00:50.740]   And I think it's really fun to do it.
[02:00:50.740 --> 02:00:51.740]   And I think it's really fun to do it.
[02:00:51.740 --> 02:00:52.740]   And I think it's really fun to do it.
[02:00:52.740 --> 02:00:53.740]   And I think it's really fun to do it.
[02:00:53.740 --> 02:00:54.740]   And I think it's really fun to do it.
[02:00:54.740 --> 02:00:55.740]   And I think it's really fun to do it.
[02:00:55.740 --> 02:00:56.740]   And I think it's really fun to do it.
[02:00:56.740 --> 02:00:57.740]   And I think it's really fun to do it.
[02:00:57.740 --> 02:01:03.740]   And I think it's really fun to do it.
[02:01:03.740 --> 02:01:04.740]   And I think it's really fun to do it.
[02:01:04.740 --> 02:01:05.740]   And I think it's really fun to do it.
[02:01:05.740 --> 02:01:06.740]   And I think it's really fun to do it.
[02:01:06.740 --> 02:01:07.740]   And I think it's really fun to do it.
[02:01:07.740 --> 02:01:08.740]   And I think it's really fun to do it.
[02:01:08.740 --> 02:01:09.740]   And I think it's really fun to do it.
[02:01:09.740 --> 02:01:10.740]   And I think it's really fun to do it.
[02:01:10.740 --> 02:01:11.740]   And I think it's really fun to do it.
[02:01:11.740 --> 02:01:12.740]   And I think it's really fun to do it.
[02:01:12.740 --> 02:01:13.740]   And I think it's really fun to do it.
[02:01:13.740 --> 02:01:14.740]   And I think it's really fun to do it.
[02:01:14.740 --> 02:01:15.740]   And I think it's really fun to do it.
[02:01:15.740 --> 02:01:16.740]   And I think it's really fun to do it.
[02:01:16.740 --> 02:01:17.740]   And I think it's really fun to do it.
[02:01:17.740 --> 02:01:18.740]   And I think it's really fun to do it.
[02:01:18.740 --> 02:01:25.740]   And I think it's really fun to do it.
[02:01:25.740 --> 02:01:26.740]   And I think it's really fun to do it.
[02:01:26.740 --> 02:01:27.740]   And I think it's really fun to do it.
[02:01:27.740 --> 02:01:28.740]   And I think it's really fun to do it.
[02:01:28.740 --> 02:01:29.740]   And I think it's really fun to do it.
[02:01:29.740 --> 02:01:30.740]   And I think it's really fun to do it.
[02:01:30.740 --> 02:01:31.740]   And I think it's really fun to do it.
[02:01:31.740 --> 02:01:32.740]   And I think it's really fun to do it.
[02:01:32.740 --> 02:01:33.740]   And I think it's really fun to do it.
[02:01:33.740 --> 02:01:34.740]   And I think it's really fun to do it.
[02:01:34.740 --> 02:01:35.740]   And I think it's really fun to do it.
[02:01:35.740 --> 02:01:36.740]   And I think it's really fun to do it.
[02:01:36.740 --> 02:01:37.740]   And I think it's really fun to do it.
[02:01:37.740 --> 02:01:38.740]   And I think it's really fun to do it.
[02:01:38.740 --> 02:01:39.740]   And I think it's really fun to do it.
[02:01:39.740 --> 02:01:40.740]   And I think it's really fun to do it.
[02:01:40.740 --> 02:01:47.740]   And I think it's really fun to do it.
[02:01:47.740 --> 02:01:54.740]   And I think it's really fun to do it.
[02:01:54.740 --> 02:02:01.740]   And I think it's really fun to do it.
[02:02:01.740 --> 02:02:08.740]   And I think it's really fun to do it.
[02:02:08.740 --> 02:02:13.740]   And I think it's really fun to do it.
[02:02:13.740 --> 02:02:18.740]   And I think it's really fun to do it.
[02:02:18.740 --> 02:02:23.740]   And I think it's really fun to do it.
[02:02:23.740 --> 02:02:27.740]   And I think it's really fun to do it.
[02:02:27.740 --> 02:02:34.740]   And I think it's really fun to do it.
[02:02:34.740 --> 02:02:39.740]   And I think it's really fun to do it.
[02:02:39.740 --> 02:02:44.740]   And I think it's really fun to do it.
[02:02:44.740 --> 02:02:49.740]   And I think it's really fun to do it.
[02:02:49.740 --> 02:02:54.740]   And I think it's really fun to do it.
[02:02:54.740 --> 02:02:59.740]   And I think it's really fun to do it.
[02:02:59.740 --> 02:03:03.740]   And I think it's really fun to do it.
[02:03:03.740 --> 02:03:08.740]   And I think it's really fun to do it.
[02:03:08.740 --> 02:03:13.740]   And I think it's really fun to do it.
[02:03:13.740 --> 02:03:18.740]   And I think it's really fun to do it.
[02:03:18.740 --> 02:03:23.740]   And I think it's really fun to do it.
[02:03:23.740 --> 02:03:28.740]   And I think it's really fun to do it.
[02:03:28.740 --> 02:03:33.740]   And I think it's really fun to do it.
[02:03:33.740 --> 02:03:38.740]   And I think it's really fun to do it.
[02:03:38.740 --> 02:03:43.740]   And I think it's really fun to do it.
[02:03:43.740 --> 02:03:48.740]   And I think it's really fun to do it.
[02:03:48.740 --> 02:03:53.740]   And I think it's really fun to do it.
[02:03:53.740 --> 02:03:57.740]   And I think it's really fun to do it.
[02:03:57.740 --> 02:04:02.740]   And I think it's really fun to do it.
[02:04:02.740 --> 02:04:07.740]   And I think it's really fun to do it.
[02:04:07.740 --> 02:04:12.740]   And I think it's really fun to do it.
[02:04:12.740 --> 02:04:17.740]   And I think it's really fun to do it.
[02:04:17.740 --> 02:04:22.740]   And I think it's really fun to do it.
[02:04:22.740 --> 02:04:27.740]   And I think it's really fun to do it.
[02:04:27.740 --> 02:04:32.740]   And I think it's really fun to do it.
[02:04:32.740 --> 02:04:37.740]   And I think it's really fun to do it.
[02:04:37.740 --> 02:04:42.740]   And I think it's really fun to do it.
[02:04:42.740 --> 02:04:47.740]   And I think it's really fun to do it.
[02:04:47.740 --> 02:04:51.740]   And I think it's really fun to do it.
[02:04:51.740 --> 02:04:56.740]   And I think it's really fun to do it.
[02:04:56.740 --> 02:05:01.740]   And I think it's really fun to do it.
[02:05:01.740 --> 02:05:06.740]   And I think it's really fun to do it.
[02:05:06.740 --> 02:05:11.740]   And I think it's really fun to do it.
[02:05:11.740 --> 02:05:16.740]   And I think it's really fun to do it.
[02:05:16.740 --> 02:05:21.740]   And I think it's really fun to do it.
[02:05:21.740 --> 02:05:26.740]   And I think it's really fun to do it.
[02:05:26.740 --> 02:05:31.740]   And I think it's really fun to do it.
[02:05:31.740 --> 02:05:36.740]   And I think it's really fun to do it.
[02:05:36.740 --> 02:05:41.740]   And I think it's really fun to do it.
[02:05:41.740 --> 02:05:45.740]   And I think it's really fun to do it.
[02:05:45.740 --> 02:05:50.740]   And I think it's really fun to do it.
[02:05:50.740 --> 02:05:55.740]   And I think it's really fun to do it.
[02:05:55.740 --> 02:06:00.740]   And I think it's really fun to do it.
[02:06:00.740 --> 02:06:05.740]   And I think it's really fun to do it.
[02:06:05.740 --> 02:06:10.740]   And I think it's really fun to do it.
[02:06:10.740 --> 02:06:15.740]   And I think it's really fun to do it.
[02:06:15.740 --> 02:06:20.740]   And I think it's really fun to do it.
[02:06:20.740 --> 02:06:25.740]   And I think it's really fun to do it.
[02:06:25.740 --> 02:06:30.740]   And I think it's really fun to do it.
[02:06:30.740 --> 02:06:35.740]   And I think it's really fun to do it.
[02:06:35.740 --> 02:06:39.740]   And I think it's really fun to do it.
[02:06:39.740 --> 02:06:44.740]   And I think it's really fun to do it.
[02:06:44.740 --> 02:06:49.740]   And I think it's really fun to do it.
[02:06:49.740 --> 02:06:54.740]   And I think it's really fun to do it.
[02:06:54.740 --> 02:06:59.740]   And I think it's really fun to do it.
[02:06:59.740 --> 02:07:04.740]   And I think it's really fun to do it.
[02:07:04.740 --> 02:07:08.740]   And I think it's really fun to do it.
[02:07:08.740 --> 02:07:12.740]   But Thompson calls their integrated model, where they would build the fabs,
[02:07:12.740 --> 02:07:15.740]   they would design the chips, build the fabs.
[02:07:15.740 --> 02:07:20.740]   They integrated both design and manufacture.
[02:07:20.740 --> 02:07:27.740]   And for 35 years, profit, it was incredibly successful for them.
[02:07:27.740 --> 02:07:30.740]   But there was success of this integrated model.
[02:07:30.740 --> 02:07:36.740]   Ended up blinding them to model that ARM and TSMC and others were following.
[02:07:36.740 --> 02:07:41.740]   ARM would design the chips, TSMC would manufacture the chips.
[02:07:41.740 --> 02:07:46.740]   And so by separating this out, they were able to, they were more nimble.
[02:07:46.740 --> 02:07:49.740]   They were, it was less capital intensive.
[02:07:49.740 --> 02:07:51.740]   They were able to do better designs.
[02:07:51.740 --> 02:07:55.740]   And ultimately, by focusing on manufacture, only TSMC got down.
[02:07:55.740 --> 02:07:57.740]   They're now at five nanometers.
[02:07:57.740 --> 02:07:59.740]   The M1 is a five nanometer chip.
[02:07:59.740 --> 02:08:01.740]   And they're talking about three nanometer chips.
[02:08:01.740 --> 02:08:03.740]   While Intel still stuck at 10.
[02:08:03.740 --> 02:08:07.740]   It's a story told as old as time, at least as old as the tech industry,
[02:08:07.740 --> 02:08:11.740]   of being too successful and then being tied into your model.
[02:08:11.740 --> 02:08:15.740]   That's, we just talked about Microsoft and the impact of the antitrust stuff.
[02:08:15.740 --> 02:08:19.740]   You know, Intel is the hardware equivalent of Microsoft and they didn't change,
[02:08:19.740 --> 02:08:21.740]   like Microsoft did, right?
[02:08:21.740 --> 02:08:27.740]   So also the other way to look at it is, you know, I talked about Microsoft being 100%
[02:08:27.740 --> 02:08:29.740]   of the market back in the day from a software perspective.
[02:08:29.740 --> 02:08:30.740]   That's true.
[02:08:30.740 --> 02:08:33.740]   From a hardware perspective, it was basically Intel.
[02:08:33.740 --> 02:08:36.740]   Today, Intel is the biggest fish in the smallest pond.
[02:08:36.740 --> 02:08:39.740]   You know, mobile is much, much bigger than the PC.
[02:08:39.740 --> 02:08:40.740]   It's not wild.
[02:08:40.740 --> 02:08:41.740]   It's not wild.
[02:08:41.740 --> 02:08:47.740]   265, 275 million computers are going to be sold this year to something billion-ish mobile,
[02:08:47.740 --> 02:08:49.740]   you know, smartphones will be sold this year.
[02:08:49.740 --> 02:08:53.740]   It's not exponentially bigger, but it's dramatically bigger.
[02:08:53.740 --> 02:08:59.740]   And year after year after year, Intel hasn't been the biggest microprocessor
[02:08:59.740 --> 02:09:01.740]   company arguably in years.
[02:09:01.740 --> 02:09:03.740]   And they could never make mobile.
[02:09:03.740 --> 02:09:06.740]   They tried and they just couldn't figure out how to do mobile.
[02:09:06.740 --> 02:09:08.740]   Well, what markets have the exit in recent years, right?
[02:09:08.740 --> 02:09:09.740]   Mobile, 5G.
[02:09:09.740 --> 02:09:15.740]   You know, I mean, they, you know, pick everything important and they've walked away from it.
[02:09:15.740 --> 02:09:19.740]   Now, here's the funny story and this isn't really, this is just the button on the whole thing.
[02:09:19.740 --> 02:09:25.740]   Every time Apple does something, it seems like Microsoft says, oh, we can do that.
[02:09:25.740 --> 02:09:30.740]   Apple came out with a touch screen and they had the surface, I remember what they call it,
[02:09:30.740 --> 02:09:31.740]   the surface table.
[02:09:31.740 --> 02:09:32.740]   Surface.
[02:09:32.740 --> 02:09:33.740]   They said you.
[02:09:33.740 --> 02:09:35.740]   We've got that.
[02:09:35.740 --> 02:09:37.740]   Apple comes out with the M1 chip.
[02:09:37.740 --> 02:09:43.740]   Microsoft, according to Tom Warren, writing the Verge is now working on designing its own
[02:09:43.740 --> 02:09:47.740]   ARM-based chips for surfers and surface PCs.
[02:09:47.740 --> 02:09:51.740]   Well, I don't actually think this is a reaction to the M1.
[02:09:51.740 --> 02:09:56.740]   This is, Microsoft has for years been partnering with other companies to design specialty chips.
[02:09:56.740 --> 02:10:00.740]   Microsoft has for years been making its own chips for use inside its computer.
[02:10:00.740 --> 02:10:05.740]   It's not the CPUs, but other special chips and also in their data centers.
[02:10:05.740 --> 02:10:11.740]   So, I mean, I think Microsoft has tried to do what it's always done, which is partner with other
[02:10:11.740 --> 02:10:15.740]   companies and that it's seeing the limitations of this and that this didn't just happen.
[02:10:15.740 --> 02:10:16.740]   You know, the story just came up.
[02:10:16.740 --> 02:10:17.740]   No, I agree.
[02:10:17.740 --> 02:10:18.740]   You don't just start a chip.
[02:10:18.740 --> 02:10:20.740]   They've been moving in this direction, right?
[02:10:20.740 --> 02:10:21.740]   Yeah.
[02:10:21.740 --> 02:10:26.740]   And I have to say the tensions between Intel and Microsoft are age old.
[02:10:26.740 --> 02:10:27.740]   Oh, yeah.
[02:10:27.740 --> 02:10:32.740]   You know, I remember Andy Grove saying, "Oh, if Microsoft would just do a 32-bit operating
[02:10:32.740 --> 02:10:34.740]   system, we make these 32-bit chips.
[02:10:34.740 --> 02:10:35.740]   What are they thinking?"
[02:10:35.740 --> 02:10:38.740]   And it, you know, it's just been forever.
[02:10:38.740 --> 02:10:43.740]   And I think maybe that's the real key to Apple's success here is total integration.
[02:10:43.740 --> 02:10:45.740]   We'll do the software and the hardware.
[02:10:45.740 --> 02:10:48.740]   We'll build everything ourselves or get somebody to build it for us.
[02:10:48.740 --> 02:10:50.740]   How would you like to be an Apple partner today?
[02:10:50.740 --> 02:10:51.740]   Yeah.
[02:10:51.740 --> 02:10:53.740]   What's left that Apple doesn't make?
[02:10:53.740 --> 02:10:54.740]   5G chips, I guess.
[02:10:54.740 --> 02:10:55.740]   Those, you know, they're doing that.
[02:10:55.740 --> 02:10:57.740]   No, they say they're designing those too.
[02:10:57.740 --> 02:10:58.740]   Yeah.
[02:10:58.740 --> 02:10:59.740]   Yeah, they're going to replace everything.
[02:10:59.740 --> 02:11:00.740]   Yeah.
[02:11:00.740 --> 02:11:03.740]   And actually, that's why I thought Microsoft would be hard for Microsoft to do their own
[02:11:03.740 --> 02:11:10.740]   chips because how many OEMs are there that make Intel-based Windows hardware?
[02:11:10.740 --> 02:11:12.740]   If Microsoft doesn't sell those chips to those guys.
[02:11:12.740 --> 02:11:15.740]   Yeah, but you know, everyone's looking for diversity.
[02:11:15.740 --> 02:11:20.740]   When Microsoft started making Surface PCs, every PC maker on Earth started making Chromebooks.
[02:11:20.740 --> 02:11:25.740]   Every PC maker on Earth now has AMD-based PCs as well as Intel-based PCs.
[02:11:25.740 --> 02:11:30.740]   Some of them have, most of the big ones have Qualcomm-based PCs as well.
[02:11:30.740 --> 02:11:33.740]   Everyone is kind of hedging their bets.
[02:11:33.740 --> 02:11:36.740]   But that's the problem with the ecosystem and also the strength.
[02:11:36.740 --> 02:11:40.740]   But part of the problem, you know, Apple just goes all in on one thing.
[02:11:40.740 --> 02:11:43.740]   On the PC side of the fence, Microsoft side.
[02:11:43.740 --> 02:11:45.740]   Everyone's, you know, trying different things.
[02:11:45.740 --> 02:11:47.740]   But that's the strength of the PC industry.
[02:11:47.740 --> 02:11:48.740]   There's diversity.
[02:11:48.740 --> 02:11:50.740]   Yeah, but it's also the problem, you know.
[02:11:50.740 --> 02:11:51.740]   It's simultaneous.
[02:11:51.740 --> 02:11:52.740]   It's a two-edged sword.
[02:11:52.740 --> 02:11:54.740]   All right, we're going to take our last break.
[02:11:54.740 --> 02:11:57.740]   I want a couple of things we're going to run down.
[02:11:57.740 --> 02:12:00.740]   Jason Hal's done such a great job with the show putting together the top 10 listed.
[02:12:00.740 --> 02:12:01.740]   Yeah.
[02:12:01.740 --> 02:12:04.740]   He also ran down some of the most important products of the year.
[02:12:04.740 --> 02:12:07.740]   So we'll just, any thoughts you guys have, we can just run through those.
[02:12:07.740 --> 02:12:12.740]   And then, of course, I'll let you guys tell us what we're, what the stories of 2021 will
[02:12:12.740 --> 02:12:13.740]   be.
[02:12:13.740 --> 02:12:17.740]   Jeff Jarvis, you get to, you get to talk about it.
[02:12:17.740 --> 02:12:19.740]   We're by crystal ball.
[02:12:19.740 --> 02:12:20.740]   Go get it.
[02:12:20.740 --> 02:12:21.740]   Who's going to get it?
[02:12:21.740 --> 02:12:22.740]   Oh, get it.
[02:12:22.740 --> 02:12:24.740]   The OG Twits are here.
[02:12:24.740 --> 02:12:28.740]   And one of the reasons you guys have been such an important part of this network for more
[02:12:28.740 --> 02:12:33.740]   than 10 years, all three of you, some of you, as long as 15 years, is because not only
[02:12:33.740 --> 02:12:38.740]   are you great, nice, fun, interesting people to hang with, but your insights are so great.
[02:12:38.740 --> 02:12:41.740]   It's what, uh, Twit wouldn't exist without you three.
[02:12:41.740 --> 02:12:46.740]   So I just, I certainly would exist without you boss and without Lisa and without your team,
[02:12:46.740 --> 02:12:47.740]   which is great.
[02:12:47.740 --> 02:12:52.740]   We try to pull together some of the best people we can and I'm, like, I'm so happy.
[02:12:52.740 --> 02:12:57.740]   And of course, the shows that continue are the ones with the smartest folk.
[02:12:57.740 --> 02:13:01.740]   So I appreciate all you've done over the last years.
[02:13:01.740 --> 02:13:03.740]   Our show today brought to you by Forward Networks.
[02:13:03.740 --> 02:13:06.740]   This is looking forward to the future.
[02:13:06.740 --> 02:13:12.740]   Forward Networks, I talked to these guys, was founded by four Stanford PhD students, graduate
[02:13:12.740 --> 02:13:14.740]   students, seven years ago.
[02:13:14.740 --> 02:13:19.740]   They were looking at the pain network operators suffered by not knowing what was going on
[02:13:19.740 --> 02:13:20.740]   in the network.
[02:13:20.740 --> 02:13:24.740]   You know, that puffy little cloud we call the, the, the internet.
[02:13:24.740 --> 02:13:28.740]   It's cute to us, but you know what network engineers see?
[02:13:28.740 --> 02:13:30.740]   A complete fog.
[02:13:30.740 --> 02:13:32.740]   I don't know what's going on in there.
[02:13:32.740 --> 02:13:36.740]   Forward Networks developed some empathy for these network operators.
[02:13:36.740 --> 02:13:43.740]   They said, what if, and this was their PhD project, we could develop a software only model,
[02:13:43.740 --> 02:13:50.740]   a mathematically identical model of the network that you could use to reduce network outages,
[02:13:50.740 --> 02:13:53.740]   to improve troubleshooting, to eliminate errors.
[02:13:53.740 --> 02:13:59.740]   So what Forward Networks does, their advanced software, it delivers a digital twin, a mathematically
[02:13:59.740 --> 02:14:03.740]   accurate model of your network.
[02:14:03.740 --> 02:14:06.740]   It does it in software and it gives you, this is the dashboard.
[02:14:06.740 --> 02:14:08.740]   If you're looking at the video, that's the dashboard.
[02:14:08.740 --> 02:14:11.740]   It gives you a single source of truth for the network.
[02:14:11.740 --> 02:14:13.740]   This is, this is amazing.
[02:14:13.740 --> 02:14:17.740]   This is what you as a network engineer have been dying for.
[02:14:17.740 --> 02:14:20.740]   You can verify that your network is configured correctly.
[02:14:20.740 --> 02:14:24.740]   It's in compliance with policies, it's behaving as you intend.
[02:14:24.740 --> 02:14:25.740]   And here's the best part.
[02:14:25.740 --> 02:14:27.740]   You're ready to make a change to the network.
[02:14:27.740 --> 02:14:31.740]   There's something called behavior diffs that allows side by side comparisons.
[02:14:31.740 --> 02:14:38.740]   In one view of the current network and configuration changes and what that's going to do to your
[02:14:38.740 --> 02:14:39.740]   network.
[02:14:39.740 --> 02:14:42.740]   No more do you have to try it and then roll it back because everything broke.
[02:14:42.740 --> 02:14:45.740]   You will know ahead of time.
[02:14:45.740 --> 02:14:51.740]   Forward Networks can accurately predict the impact of a proposed change across every possible traffic path.
[02:14:51.740 --> 02:14:54.740]   So network operators can roll out changes with confidence.
[02:14:54.740 --> 02:14:57.740]   Make sure that your network is healthy is agile.
[02:14:57.740 --> 02:15:01.740]   You'll get insights with visualizations that you can easily understand.
[02:15:01.740 --> 02:15:03.740]   You can export, you can show others.
[02:15:03.740 --> 02:15:08.740]   You can automatically create an always accurate network diagram with full details about the
[02:15:08.740 --> 02:15:09.740]   topology of your network.
[02:15:09.740 --> 02:15:11.740]   PayPal used this.
[02:15:11.740 --> 02:15:18.740]   They were, you know, as many big companies, they had lots of endpoints, lots of network
[02:15:18.740 --> 02:15:20.740]   stuff all over the world.
[02:15:20.740 --> 02:15:23.740]   And they realized they didn't know what was going on.
[02:15:23.740 --> 02:15:26.740]   They were about to build something they found forward networks.
[02:15:26.740 --> 02:15:27.740]   And they said, this is it.
[02:15:27.740 --> 02:15:29.740]   This is the software we've needed.
[02:15:29.740 --> 02:15:34.740]   Any time there's a change in the network, it's immediately reflected in the forward networks mathematical
[02:15:34.740 --> 02:15:35.740]   model.
[02:15:35.740 --> 02:15:36.740]   It saved them time and money.
[02:15:36.740 --> 02:15:38.740]   Goldman Sachs, same thing.
[02:15:38.740 --> 02:15:41.740]   We can't figure out our network.
[02:15:41.740 --> 02:15:43.740]   We don't know what's wrong.
[02:15:43.740 --> 02:15:44.740]   We're going to make changes.
[02:15:44.740 --> 02:15:45.740]   We don't know what the impact will be.
[02:15:45.740 --> 02:15:46.740]   They found forward networks.
[02:15:46.740 --> 02:15:52.740]   Now, by the way, they're the lead on their C funding round, their series C funding round.
[02:15:52.740 --> 02:15:57.740]   Goldman Sachs, Mark Andreessen and Andreessen Horowitz, also huge fan.
[02:15:57.740 --> 02:16:00.740]   People saw this is something the world needs.
[02:16:00.740 --> 02:16:03.740]   50% faster resolution of trouble tickets.
[02:16:03.740 --> 02:16:06.740]   90% faster fixes related to audit processes.
[02:16:06.740 --> 02:16:13.740]   But the most important one is 33% reduction in aborted network updates due to identified
[02:16:13.740 --> 02:16:14.740]   errors.
[02:16:14.740 --> 02:16:19.140]   And if you're having problems, imagine just searching your network, just like you would
[02:16:19.140 --> 02:16:22.140]   search with Google for what's causing problems.
[02:16:22.140 --> 02:16:24.140]   That's what forward networks let you do.
[02:16:24.140 --> 02:16:25.860]   This, you need this.
[02:16:25.860 --> 02:16:27.220]   You got to get this.
[02:16:27.220 --> 02:16:32.540]   Get network automation and verification for your intent-based network with forward networks.
[02:16:32.540 --> 02:16:34.060]   Your business may depend on it.
[02:16:34.060 --> 02:16:35.060]   You can get a demo.
[02:16:35.060 --> 02:16:42.260]   It's a really cool demo at forwardnetworks.com/twitforwardnetworks.com/twit.
[02:16:42.260 --> 02:16:44.460]   I was so inspired when I talked to these guys.
[02:16:44.460 --> 02:16:49.460]   You even have a podcast, if you want to listen, called Seeking Truth in Networking.
[02:16:49.460 --> 02:16:51.620]   I love that name.
[02:16:51.620 --> 02:16:54.300]   You can download it wherever you get your podcasts.
[02:16:54.300 --> 02:17:00.860]   And I encourage you, if you're responsible for a network or you know someone who is,
[02:17:00.860 --> 02:17:03.020]   stop tearing your hair out.
[02:17:03.020 --> 02:17:05.740]   Forwardnetworks.com/twit, no more mystery.
[02:17:05.740 --> 02:17:12.220]   Forwardnetworks.com/twit, and we thank forward networks for supporting this week in tech.
[02:17:12.220 --> 02:17:16.780]   Thank you for supporting us by going there forwardnetworks.com/twit.
[02:17:16.780 --> 02:17:20.100]   Now John, press that magic trycaster button.
[02:17:20.100 --> 02:17:23.780]   If you missed anything this week, we've made a little movie for you.
[02:17:23.780 --> 02:17:25.740]   The best of this week in TwitWatch.
[02:17:25.740 --> 02:17:27.740]   It's like Mary Jo got you where we're-
[02:17:27.740 --> 02:17:29.740]   This is a Microsoft Paint and Ugly Sweater.
[02:17:29.740 --> 02:17:33.020]   Yes, we got the Paint Dog we Sweater this year.
[02:17:33.020 --> 02:17:35.180]   Next year you know what has to happen, right?
[02:17:35.180 --> 02:17:36.180]   What?
[02:17:36.180 --> 02:17:37.180]   I think notepad.
[02:17:37.180 --> 02:17:38.180]   Oh, Mary Jo.
[02:17:38.180 --> 02:17:40.020]   I think notepad also.
[02:17:40.020 --> 02:17:41.740]   Mary Jo's happy.
[02:17:41.740 --> 02:17:44.540]   Previously on Twit.
[02:17:44.540 --> 02:17:45.540]   Tech News Weekly.
[02:17:45.540 --> 02:17:51.340]   Seesness said I think yesterday that everyone should delete solar winds from their networks.
[02:17:51.340 --> 02:17:55.380]   The only way to make sure that you're secure is to take your network and burn it down to
[02:17:55.380 --> 02:17:57.140]   the ground and be able to scratch.
[02:17:57.140 --> 02:17:59.500]   God no one wants to do that.
[02:17:59.500 --> 02:18:00.740]   Hands on tech.
[02:18:00.740 --> 02:18:05.060]   The Oculus Quest 2 is a pretty remarkable VR platform.
[02:18:05.060 --> 02:18:09.620]   But there's just one very large asterisk and I'm going to give you my full review.
[02:18:09.620 --> 02:18:11.260]   I know what that asterisk is.
[02:18:11.260 --> 02:18:12.260]   It's the last two.
[02:18:12.260 --> 02:18:13.260]   Windows Weekly.
[02:18:13.260 --> 02:18:18.260]   When you guys put the consoles on sale, you didn't have enough.
[02:18:18.260 --> 02:18:22.220]   And I'm curious if that was a strategy like to create more demand?
[02:18:22.220 --> 02:18:24.700]   The reality is if we had great confidence-
[02:18:24.700 --> 02:18:25.700]   Right.
[02:18:25.700 --> 02:18:28.060]   That we could tell you the date.
[02:18:28.060 --> 02:18:29.960]   Then we would.
[02:18:29.960 --> 02:18:33.300]   And it's a great thing for us to aspire to do much better.
[02:18:33.300 --> 02:18:34.300]   iOS Today.
[02:18:34.300 --> 02:18:36.540]   Should we do a little dance?
[02:18:36.540 --> 02:18:37.900]   Yeah, let's do a preview.
[02:18:37.900 --> 02:18:39.140]   Oh yeah, let's do it.
[02:18:39.140 --> 02:18:40.140]   Let's do it.
[02:18:40.140 --> 02:18:42.140]   Here we go.
[02:18:42.140 --> 02:18:43.140]   That's what goes to me.
[02:18:43.140 --> 02:18:44.300]   Oh wow, he's really doing it now.
[02:18:44.300 --> 02:18:45.300]   To it.
[02:18:45.300 --> 02:18:46.300]   You think this is easy?
[02:18:46.300 --> 02:18:50.260]   Just try to run a network and work out on a Pilates reformer.
[02:18:50.260 --> 02:18:52.380]   How did you know?
[02:18:52.380 --> 02:18:58.060]   Oh, I have to thank the great Jim Cutler, his wonderful partner, Adon, because all year
[02:18:58.060 --> 02:19:02.100]   long, Jim Pro Bono, he's the voice of ESPN.
[02:19:02.100 --> 02:19:04.860]   He's the voice of many TV and radio stations all over the country.
[02:19:04.860 --> 02:19:09.900]   He's a commercial voice over guy who I couldn't come close to affording.
[02:19:09.900 --> 02:19:11.580]   30 seconds of his time.
[02:19:11.580 --> 02:19:18.140]   But for the last, I don't know, how many years Jim and Don have provided us with announcing
[02:19:18.140 --> 02:19:21.940]   especially those promos and the funny little comments at the end.
[02:19:21.940 --> 02:19:22.940]   That's amazing.
[02:19:22.940 --> 02:19:26.460]   He is a great friend of the network.
[02:19:26.460 --> 02:19:30.220]   Twit really wouldn't exist without people like Jim and you guys.
[02:19:30.220 --> 02:19:31.540]   It's really a group effort.
[02:19:31.540 --> 02:19:35.700]   So from the bottom of my heart, I'm absolutely sincere.
[02:19:35.700 --> 02:19:37.740]   Thank you.
[02:19:37.740 --> 02:19:45.340]   I'm just very, incredibly fortunate to know you guys and to be able to do this.
[02:19:45.340 --> 02:19:46.340]   It's a real privilege.
[02:19:46.340 --> 02:19:47.340]   So thank you.
[02:19:47.340 --> 02:19:53.620]   I don't even know if we want to go through all of the things that came out this year.
[02:19:53.620 --> 02:20:00.580]   The iPad Pro, the MacBook Air, the M1 chip, the iPhone SE Apple announced a new cheaper
[02:20:00.580 --> 02:20:05.660]   version of the Apple Watch along with a more expensive version of the Apple Watch and an
[02:20:05.660 --> 02:20:07.500]   Apple Watch for seniors.
[02:20:07.500 --> 02:20:15.580]   There were a number of surf-assie, the Surface Go 2, Surface Book 3, Surface Headphones 2,
[02:20:15.580 --> 02:20:17.900]   the Surface Earbuds.
[02:20:17.900 --> 02:20:23.980]   You know, this was actually the year of the overpriced headphone earbud combination,
[02:20:23.980 --> 02:20:24.980]   right?
[02:20:24.980 --> 02:20:28.380]   God, they were also expensive.
[02:20:28.380 --> 02:20:29.780]   And of course, you know why?
[02:20:29.780 --> 02:20:35.420]   Because you can't put a wired headphone, a cheap skull candy.
[02:20:35.420 --> 02:20:40.700]   You bought it at the five and dime store headphone in any of these phones anymore.
[02:20:40.700 --> 02:20:43.180]   Mac OS 11 Big Sur came out.
[02:20:43.180 --> 02:20:51.060]   The Galaxy Note 20 Ultra, the Pixel 4A, which I think widely considered to be maybe the
[02:20:51.060 --> 02:20:53.060]   best phone of the year.
[02:20:53.060 --> 02:20:57.660]   The most expensive phone of the year, which I have one and I don't know what I'm going
[02:20:57.660 --> 02:21:02.660]   to do with it, the Galaxy Fold Z2.
[02:21:02.660 --> 02:21:04.660]   Don't laugh at me in my $2,000 phone.
[02:21:04.660 --> 02:21:06.780]   Oh, yeah, yeah, yeah.
[02:21:06.780 --> 02:21:09.940]   I did buy a Surface Duo and I was able to return that.
[02:21:09.940 --> 02:21:10.940]   You know what?
[02:21:10.940 --> 02:21:14.380]   I think the both the Surface Duo and the Fold 2 are going to be around for a long, the
[02:21:14.380 --> 02:21:17.820]   Fold will be around for a long time, so will the Duo.
[02:21:17.820 --> 02:21:19.380]   There's something going on there, right, Paul?
[02:21:19.380 --> 02:21:21.820]   There's some value in that.
[02:21:21.820 --> 02:21:22.820]   Yeah.
[02:21:22.820 --> 02:21:26.900]   I don't think we've latched on to what the real value is.
[02:21:26.900 --> 02:21:30.180]   Microsoft pushes this notion that when you have two different things on two different
[02:21:30.180 --> 02:21:34.900]   displays, you something clicks and you become more productive or you become more creative.
[02:21:34.900 --> 02:21:36.700]   I don't think that's it.
[02:21:36.700 --> 02:21:41.420]   I actually, since we're all the OG tweets, I think we can all realize, you know, we all
[02:21:41.420 --> 02:21:45.780]   agree looking at a phone, it's a little tough at this age and having a bigger screen is
[02:21:45.780 --> 02:21:46.780]   nice.
[02:21:46.780 --> 02:21:47.780]   I love that.
[02:21:47.780 --> 02:21:48.780]   Yeah.
[02:21:48.780 --> 02:21:49.780]   The Fold is great.
[02:21:49.780 --> 02:21:51.500]   It's nice if you're using it from apps in a car, it's nice if you're watching a movie,
[02:21:51.500 --> 02:21:52.500]   whatever.
[02:21:52.500 --> 02:21:53.500]   It's not even a lot of games.
[02:21:53.500 --> 02:21:57.820]   I could play a cyberpunk on the Fold or, and it really, it's nice to have a little bit.
[02:21:57.820 --> 02:21:58.820]   It's not huge.
[02:21:58.820 --> 02:21:59.820]   It's just a little bit more.
[02:21:59.820 --> 02:22:02.060]   It's nice that you can put your pocket, but then you open it up and that's a bigger
[02:22:02.060 --> 02:22:04.180]   display.
[02:22:04.180 --> 02:22:09.420]   So far, nothing that Steve Gibson wants to put in his freezer for future, right?
[02:22:09.420 --> 02:22:10.420]   Nope.
[02:22:10.420 --> 02:22:13.100]   I still have my Palm Pilots in there.
[02:22:13.100 --> 02:22:16.300]   There's still seven Palm Pilots in there.
[02:22:16.300 --> 02:22:17.300]   All right.
[02:22:17.300 --> 02:22:18.820]   You need to explain what's going on.
[02:22:18.820 --> 02:22:20.500]   Do you want to explain, Steve?
[02:22:20.500 --> 02:22:21.940]   Back at the time.
[02:22:21.940 --> 02:22:29.460]   So it's been my experience that sometimes the world moves on past the perfect solution.
[02:22:29.460 --> 02:22:31.620]   It doesn't just settle on the perfect solution.
[02:22:31.620 --> 02:22:34.260]   For example, I happen to have here within reach.
[02:22:34.260 --> 02:22:36.460]   It was not set up ahead of time.
[02:22:36.460 --> 02:22:39.620]   The most perfect calculators that were ever created.
[02:22:39.620 --> 02:22:41.420]   No, I have my man.
[02:22:41.420 --> 02:22:42.620]   He's got the, what is it?
[02:22:42.620 --> 02:22:45.620]   The HP, what, 35?
[02:22:45.620 --> 02:22:49.780]   So one is the hex calculator because I'm a programmer, the 16C and I was using it earlier
[02:22:49.780 --> 02:22:50.780]   this morning.
[02:22:50.780 --> 02:22:54.980]   And the other is the 15C, which is the scientific calculator.
[02:22:54.980 --> 02:22:55.980]   Nice.
[02:22:55.980 --> 02:22:56.980]   And they're gone now.
[02:22:56.980 --> 02:23:04.020]   I have about 20 of these because it's the, I don't ever want to be without this calculator.
[02:23:04.020 --> 02:23:06.380]   You know, we're going to make a TV show about you.
[02:23:06.380 --> 02:23:08.100]   The best one ever created.
[02:23:08.100 --> 02:23:09.500]   It's called Horters Do.
[02:23:09.500 --> 02:23:10.500]   Yeah, Tech Hoarders.
[02:23:10.500 --> 02:23:14.420]   Now, as it happens, I was wrong about the Palm Tungsten.
[02:23:14.420 --> 02:23:19.420]   I have several of those in the freezer and I don't think I'm going to ever thaw them
[02:23:19.420 --> 02:23:23.020]   out because, you know, I explained a poll.
[02:23:23.020 --> 02:23:25.620]   Why you put them in the freezer?
[02:23:25.620 --> 02:23:30.900]   Well, well, because the battery chemistry needs to be kept cold.
[02:23:30.900 --> 02:23:33.060]   So that it does not matter for it.
[02:23:33.060 --> 02:23:34.220]   No, right.
[02:23:34.220 --> 02:23:38.220]   Literally in the freezer.
[02:23:38.220 --> 02:23:40.460]   Do you have to worry about freezer burn?
[02:23:40.460 --> 02:23:45.700]   I think they're in the refrigerator because you don't want to freeze a lithium polymer
[02:23:45.700 --> 02:23:49.300]   scale, but you do want to cool it off in order to slow things down.
[02:23:49.300 --> 02:23:50.300]   Yeah.
[02:23:50.300 --> 02:23:53.700]   And yet it is possible to actually get, you know, fresh replacement batteries.
[02:23:53.700 --> 02:23:57.860]   But again, in that instance, I will not be going back to there.
[02:23:57.860 --> 02:24:02.060]   I used to read books, my, you know, ebooks on my little Palm pilot.
[02:24:02.060 --> 02:24:03.060]   That was wonderful.
[02:24:03.060 --> 02:24:06.180]   But, but, you know, we now have iPhones.
[02:24:06.180 --> 02:24:07.180]   That's the right solution.
[02:24:07.180 --> 02:24:12.780]   But we have no calculators that are equivalent to the fantastic HPs.
[02:24:12.780 --> 02:24:15.940]   Steve dreams in reverse Polish notation.
[02:24:15.940 --> 02:24:16.940]   Yeah.
[02:24:16.940 --> 02:24:18.940]   I bet he actually does.
[02:24:18.940 --> 02:24:22.700]   I bet occasionally he wakes up and does.
[02:24:22.700 --> 02:24:29.460]   When I was at Cal, my best friend and roommate used to say, you know, when you talk in your
[02:24:29.460 --> 02:24:31.460]   sleep, it sounds real.
[02:24:31.460 --> 02:24:33.860]   I have no idea what you're talking about.
[02:24:33.860 --> 02:24:37.500]   But I always wanted him to write it, you know, like recorded or something, but that
[02:24:37.500 --> 02:24:38.500]   never happened.
[02:24:38.500 --> 02:24:39.500]   A lot of peaks and pups.
[02:24:39.500 --> 02:24:41.260]   So Steve pushes and pops.
[02:24:41.260 --> 02:24:45.460]   You write a lot of assembly language, which is Intel.
[02:24:45.460 --> 02:24:46.460]   100%.
[02:24:46.460 --> 02:24:47.460]   Yeah.
[02:24:47.460 --> 02:24:48.460]   So do you have any.
[02:24:48.460 --> 02:24:49.460]   Okay.
[02:24:49.460 --> 02:24:55.260]   So I mean, do you have any fears about, you know, some shift away from the x86 platform?
[02:24:55.260 --> 02:24:56.260]   Yes.
[02:24:56.260 --> 02:24:59.060]   As a matter of fact, that it's going to be a problem for me.
[02:24:59.060 --> 02:25:04.140]   I'm not sure what I'm going to do because everything I'm doing is x86 and we're clearly
[02:25:04.140 --> 02:25:07.780]   seeing the world moving away from that architecture.
[02:25:07.780 --> 02:25:13.300]   So, you know, maybe the arm will be able to emulate x86 and then it'll only be, you
[02:25:13.300 --> 02:25:18.300]   know, how I'll have to create drivers for non-intel based systems.
[02:25:18.300 --> 02:25:27.260]   Hopefully I'm old enough that that the last long enough to move me out of a point where
[02:25:27.260 --> 02:25:28.500]   I want to be profitable.
[02:25:28.500 --> 02:25:32.980]   I remember moving from 68,000, which is a very nice assembly language.
[02:25:32.980 --> 02:25:34.780]   Oh, beautiful design.
[02:25:34.780 --> 02:25:39.860]   And the memory architecture was, you know, flat, all orthogonal instruction set and then
[02:25:39.860 --> 02:25:42.500]   going to X, well, I guess was X 16.
[02:25:42.500 --> 02:25:46.100]   I don't know what it was, but going to the Intel platform and its segment 86.
[02:25:46.100 --> 02:25:48.540]   Maybe it was written by the insane person.
[02:25:48.540 --> 02:25:49.540]   Oh my God.
[02:25:49.540 --> 02:25:51.300]   And it's not any better.
[02:25:51.300 --> 02:25:53.940]   So you know what, you might actually embrace risk.
[02:25:53.940 --> 02:25:59.580]   You might say the promise you probably have a hundred a thousand macros written in x86
[02:25:59.580 --> 02:26:01.740]   that you're going to have to rewrite or something.
[02:26:01.740 --> 02:26:02.740]   I imagine.
[02:26:02.740 --> 02:26:06.460]   The thing to do would be to move to a higher level language.
[02:26:06.460 --> 02:26:08.140]   I would just go to see.
[02:26:08.140 --> 02:26:11.580]   I would make the smallest step above assembler.
[02:26:11.580 --> 02:26:14.100]   And that would give me some machine independence.
[02:26:14.100 --> 02:26:18.780]   Actually, there was one product I remember Steve was very excited about.
[02:26:18.780 --> 02:26:24.380]   The ring drone security camera that flies around.
[02:26:24.380 --> 02:26:25.380]   That seems like his kind of product.
[02:26:25.380 --> 02:26:26.900]   I bet he's got 20 of those.
[02:26:26.900 --> 02:26:27.900]   Yeah.
[02:26:27.900 --> 02:26:29.060]   It's not out yet.
[02:26:29.060 --> 02:26:33.300]   But I think Steve, you said you're going to get one right away, right?
[02:26:33.300 --> 02:26:38.980]   No, I must have been thinking of somebody else.
[02:26:38.980 --> 02:26:42.820]   You know what an autonomous drone camera flying around inside your house when you got
[02:26:42.820 --> 02:26:43.820]   a home.
[02:26:43.820 --> 02:26:48.620]   Oh, in fact, we had fun with it saying what could possibly go wrong.
[02:26:48.620 --> 02:26:49.620]   Right.
[02:26:49.620 --> 02:26:54.900]   It's allowed China to be steering your camera around your house while you're not home.
[02:26:54.900 --> 02:26:56.900]   That just really sounds like a bad idea.
[02:26:56.900 --> 02:26:59.020]   I think that was the most interesting product.
[02:26:59.020 --> 02:27:00.740]   There was also the Amazon Halo.
[02:27:00.740 --> 02:27:03.260]   Amazon really came out with some very interesting stuff.
[02:27:03.260 --> 02:27:07.820]   The wristband that listens to you as you talk and tells you if you're a little too grumpy.
[02:27:07.820 --> 02:27:09.420]   Yeah, I tried that.
[02:27:09.420 --> 02:27:10.820]   I was grumpy a lot.
[02:27:10.820 --> 02:27:13.940]   It was making me a lot grumpier.
[02:27:13.940 --> 02:27:16.140]   Mine sitting on my dresser.
[02:27:16.140 --> 02:27:20.860]   I couldn't bring myself to strip naked for it because apparently that was also part of
[02:27:20.860 --> 02:27:21.860]   the functionality.
[02:27:21.860 --> 02:27:27.980]   It did the it assessed your body fat by taking naked pictures of you and uploading to Amazon.
[02:27:27.980 --> 02:27:31.860]   Again, what could possibly go wrong?
[02:27:31.860 --> 02:27:34.580]   I feel like you don't.
[02:27:34.580 --> 02:27:36.340]   I do remember.
[02:27:36.340 --> 02:27:40.540]   I do remember of that flying camera that there was some concern that the thing was going to
[02:27:40.540 --> 02:27:41.540]   sneak up on you.
[02:27:41.540 --> 02:27:46.300]   And I remember saying, have you heard any of those drones with small props?
[02:27:46.300 --> 02:27:48.300]   That means the world.
[02:27:48.300 --> 02:27:49.300]   Oh, yeah.
[02:27:49.300 --> 02:27:51.820]   Yeah, loud loud loud loud loud.
[02:27:51.820 --> 02:27:55.180]   When they make a quiet drone, that's when we should all be worried.
[02:27:55.180 --> 02:28:00.220]   I'm sad to say Boston Dynamics got sold to another company, the robotic dog.
[02:28:00.220 --> 02:28:03.540]   Now that would have been a product that came out this year that maybe I wouldn't have
[02:28:03.540 --> 02:28:05.900]   a mind having around the studio.
[02:28:05.900 --> 02:28:10.060]   No, well, it's COVID safe.
[02:28:10.060 --> 02:28:15.020]   Well, you need that to protect you against that little Amazon drone thing.
[02:28:15.020 --> 02:28:18.020]   My dog is fighting my drone.
[02:28:18.020 --> 02:28:20.300]   My dog took down the drone.
[02:28:20.300 --> 02:28:22.340]   Oh, yeah.
[02:28:22.340 --> 02:28:27.100]   I think probably the PlayStation 5 and the Xbox Series X would be viewed as one of the
[02:28:27.100 --> 02:28:28.700]   most important products of the year.
[02:28:28.700 --> 02:28:38.300]   If you could just buy one in both cases, and I guess we should throw in some of the newer
[02:28:38.300 --> 02:28:46.020]   Nvidia graphics cards, these things sold out probably to scalpers so quickly that nobody,
[02:28:46.020 --> 02:28:49.300]   there will be a lot of unhappy children coming down next day.
[02:28:49.300 --> 02:28:51.540]   Nice projection, but 2021, right?
[02:28:51.540 --> 02:28:52.540]   I mean, it'll do well.
[02:28:52.540 --> 02:28:54.700]   These products will all be more readily available.
[02:28:54.700 --> 02:28:55.700]   Will they?
[02:28:55.700 --> 02:28:56.700]   Next year.
[02:28:56.700 --> 02:28:57.700]   Yeah.
[02:28:57.700 --> 02:28:58.700]   Oh, yeah.
[02:28:58.700 --> 02:28:59.700]   Yeah.
[02:28:59.700 --> 02:29:00.700]   Okay.
[02:29:00.700 --> 02:29:02.340]   I'm from your mouth to Chris Capacella's ear.
[02:29:02.340 --> 02:29:06.740]   Well, I mean, you know, in the sense that they'll make more of a time and eventually the
[02:29:06.740 --> 02:29:09.820]   available market will be satisfied.
[02:29:09.820 --> 02:29:10.820]   Someday.
[02:29:10.820 --> 02:29:11.820]   You think it'll be 2021?
[02:29:11.820 --> 02:29:19.700]   In fact, let's start with your predictions for a wonderful 2021 Paul Therat.
[02:29:19.700 --> 02:29:21.780]   What kind of world are we headed into?
[02:29:21.780 --> 02:29:22.780]   Yeah.
[02:29:22.780 --> 02:29:27.740]   Well, I mean, the post-COVID world is going to be a lot like the COVID world in some ways,
[02:29:27.740 --> 02:29:28.740]   right?
[02:29:28.740 --> 02:29:32.740]   More working from home, more, you know, a thousand new Microsoft Teams features by the
[02:29:32.740 --> 02:29:33.740]   end of 2021.
[02:29:33.740 --> 02:29:34.740]   I'm sure.
[02:29:34.740 --> 02:29:37.420]   I should have mentioned Teams is the product of the year.
[02:29:37.420 --> 02:29:38.420]   Yeah.
[02:29:38.420 --> 02:29:40.300]   Well, I mean, it's, you know, in the Microsoft space, certainly.
[02:29:40.300 --> 02:29:45.300]   I mean, I think Zoom was a bigger deal, but, you know, for Microsoft, it's the next big
[02:29:45.300 --> 02:29:46.300]   platform.
[02:29:46.300 --> 02:29:47.300]   So it's big.
[02:29:47.300 --> 02:29:48.300]   I don't know.
[02:29:48.300 --> 02:29:52.700]   To me, I, one of the things I want to see more of that was really good this year and
[02:29:52.700 --> 02:29:57.660]   there weren't that many things that were really good, but low cost kind of high value
[02:29:57.660 --> 02:30:03.900]   smartphones, you know, the iPhone SE, the Pixel 4A, like you said, of the Galaxy S20
[02:30:03.900 --> 02:30:06.740]   FE.
[02:30:06.740 --> 02:30:11.540]   Our low-cost phones that aren't terrible, you know, and I think that's an important
[02:30:11.540 --> 02:30:15.780]   trend, especially with all the uncertainty and the fact that people are holding onto their
[02:30:15.780 --> 02:30:21.380]   phones longer and so forth, it's nice to see phones in the $350 to $700 range.
[02:30:21.380 --> 02:30:24.020]   I think we're going to see more of that next year as well.
[02:30:24.020 --> 02:30:30.140]   And maybe, we had a theory on Twig that Google's latest, they just kind of pulled back.
[02:30:30.140 --> 02:30:32.700]   This is not the time when people just had a lot of money on this stuff.
[02:30:32.700 --> 02:30:33.700]   Right.
[02:30:33.700 --> 02:30:34.700]   Right.
[02:30:34.700 --> 02:30:35.700]   Yeah.
[02:30:35.700 --> 02:30:37.060]   I didn't notice I didn't mention the Pixel 5, which would have normally been one of
[02:30:37.060 --> 02:30:41.980]   the big releases of 2020, but Google acted as if, you know, they were taking a nap and
[02:30:41.980 --> 02:30:46.420]   they had this phone and maybe you'd be interested, but maybe not.
[02:30:46.420 --> 02:30:47.420]   Yeah.
[02:30:47.420 --> 02:30:49.500]   But you know what, like the 4A 5G, I think is great.
[02:30:49.500 --> 02:30:50.500]   Those are great.
[02:30:50.500 --> 02:30:51.500]   I think it's sold out.
[02:30:51.500 --> 02:30:52.500]   Well, that, yeah.
[02:30:52.500 --> 02:30:54.620]   I mean, they made 17 or eight of them.
[02:30:54.620 --> 02:30:55.620]   Yeah.
[02:30:55.620 --> 02:30:57.100]   I think the 4A was a great phone.
[02:30:57.100 --> 02:31:02.180]   The 4A was the phone probably we deserved last year.
[02:31:02.180 --> 02:31:03.980]   I don't know what Google's going to be.
[02:31:03.980 --> 02:31:04.980]   You know what?
[02:31:04.980 --> 02:31:11.020]   Google, Google should have been one of the top 10 stories, just Google wandering off,
[02:31:11.020 --> 02:31:12.820]   losing interest in life.
[02:31:12.820 --> 02:31:13.820]   But they do this all the time.
[02:31:13.820 --> 02:31:14.820]   Just drifting away.
[02:31:14.820 --> 02:31:21.540]   So how does it, I mean, I find it weird from being outside every fall, Google will announce
[02:31:21.540 --> 02:31:25.020]   some smart home products and they have, you know, five or six of them.
[02:31:25.020 --> 02:31:29.740]   And then this week in September where Amazon unleashes about 1100 different smart home
[02:31:29.740 --> 02:31:32.660]   products, you featured a couple of them.
[02:31:32.660 --> 02:31:35.300]   I mean, how do you, how does anyone compete with that?
[02:31:35.300 --> 02:31:36.300]   Yeah.
[02:31:36.300 --> 02:31:40.660]   We did get the Blob Opera though from Google.
[02:31:40.660 --> 02:31:42.060]   Blob Opera, you enjoyed that.
[02:31:42.060 --> 02:31:43.060]   Yes.
[02:31:43.060 --> 02:31:44.060]   Yes.
[02:31:44.060 --> 02:31:45.060]   Of the Blob Opera.
[02:31:45.060 --> 02:31:47.940]   I insisted it was the lead story on Twig.
[02:31:47.940 --> 02:31:48.940]   You made it the lead story.
[02:31:48.940 --> 02:31:50.380]   You're trying to avoid me.
[02:31:50.380 --> 02:31:53.060]   He said it's not a democracy, but I held a real question.
[02:31:53.060 --> 02:31:54.060]   You won.
[02:31:54.060 --> 02:31:55.060]   You won the Blob Opera.
[02:31:55.060 --> 02:31:56.660]   You won all the top of it.
[02:31:56.660 --> 02:31:59.740]   It may not be a democracy, but you chop my head off.
[02:31:59.740 --> 02:32:01.700]   That's, that's clear.
[02:32:01.700 --> 02:32:03.020]   The Blob Opera.
[02:32:03.020 --> 02:32:04.500]   The Blob Opera.
[02:32:04.500 --> 02:32:06.060]   What about you, Steve?
[02:32:06.060 --> 02:32:10.460]   We didn't even mention ransomware gone wild in 2020.
[02:32:10.460 --> 02:32:16.260]   I, I think a safe prediction for 2021 is more of the same in that regard.
[02:32:16.260 --> 02:32:18.260]   I think that's clear.
[02:32:18.260 --> 02:32:25.620]   For me, the, the, and we talk about this constantly on the podcast, the, the most interesting issue
[02:32:25.620 --> 02:32:32.660]   is this fundamental tension that exists between governments and encryption.
[02:32:32.660 --> 02:32:38.620]   And you know, our right to privacy, the, and the fact that in the US, you know, privacy
[02:32:38.620 --> 02:32:40.420]   is not an absolute.
[02:32:40.420 --> 02:32:48.860]   You have privacy and, and, and a right to have it, except if a court will give a warrant
[02:32:48.860 --> 02:32:54.740]   saying it's in the public interest to, for some particular target to sacrifice some aspect
[02:32:54.740 --> 02:32:59.020]   of their privacy for a specific purpose.
[02:32:59.020 --> 02:33:03.620]   You know, we talk about encryptions and back doors and all that.
[02:33:03.620 --> 02:33:08.780]   My, my feeling is that there's a different way to solve the problem.
[02:33:08.780 --> 02:33:12.380]   And it's going to be interesting to see next year, maybe it's going to be the year after,
[02:33:12.380 --> 02:33:14.340]   you know, how this gets resolved.
[02:33:14.340 --> 02:33:20.100]   It's not necessary to weaken encryption if we, because first of all, we can't, you know,
[02:33:20.100 --> 02:33:22.780]   that math has already escaped.
[02:33:22.780 --> 02:33:29.100]   So you can do perfect encryption, but we forget that on the opposite ends of that encrypted
[02:33:29.100 --> 02:33:31.860]   tunnel, the data is not encrypted.
[02:33:31.860 --> 02:33:39.540]   So it would be entirely possible for the government to legislate that, that high volume consumer
[02:33:39.540 --> 02:33:46.020]   products like pixel phones and iOS devices have to be warrant compatible.
[02:33:46.020 --> 02:33:52.420]   That is they have to be that by like by law, they have to be subject to a search warrant.
[02:33:52.420 --> 02:33:58.700]   And all that means is that you, you get the data either before it's encrypted or after
[02:33:58.700 --> 02:34:02.740]   it's decrypted under some sort of constraint.
[02:34:02.740 --> 02:34:08.140]   So I think the problem can be solved without weakening encryption, but just by recognizing
[02:34:08.140 --> 02:34:14.180]   it that there are times when encryption isn't present and you can snatch it at that point.
[02:34:14.180 --> 02:34:20.300]   But, but to me, that's one of the big issues that we as a society, we haven't yet come
[02:34:20.300 --> 02:34:25.140]   to grips with and, you know, maybe next year.
[02:34:25.140 --> 02:34:29.100]   That's a scary thought.
[02:34:29.100 --> 02:34:34.180]   And the thing that scares me is the only, as usual, the only people disadvantaged by that
[02:34:34.180 --> 02:34:40.660]   are the less sophisticated because hackers, bad guys and you and I will always have encryption.
[02:34:40.660 --> 02:34:41.820]   The math is out there.
[02:34:41.820 --> 02:34:43.860]   There's nothing anybody can do about it.
[02:34:43.860 --> 02:34:48.540]   It's just people, normal people use iPhones and other phones will lose it.
[02:34:48.540 --> 02:34:50.040]   Right.
[02:34:50.040 --> 02:34:52.540]   So the bad guys aren't going to be disadvantaged.
[02:34:52.540 --> 02:35:01.460]   Well, if your phone itself is able to be tapped at the keyboard and the screen, then any encryption
[02:35:01.460 --> 02:35:07.700]   that you apply within the phone can be snatched ahead of time.
[02:35:07.700 --> 02:35:13.900]   Now, if you want to like send documents back and forth, then you could, you know, create
[02:35:13.900 --> 02:35:19.420]   a document, do offline your own offline encryption and then mail it and there's nothing any
[02:35:19.420 --> 02:35:22.180]   anyone can do in order to crack that.
[02:35:22.180 --> 02:35:26.860]   But for mass market products, I can see that, you know, the government might well say,
[02:35:26.860 --> 02:35:34.420]   "Look, you've enjoyed this honeymoon period, but, you know, we have to have warrant compatible
[02:35:34.420 --> 02:35:36.660]   access to these devices."
[02:35:36.660 --> 02:35:40.260]   There's a jump from that, though, to we've got a back door and we're watching you at
[02:35:40.260 --> 02:35:41.260]   all times.
[02:35:41.260 --> 02:35:42.260]   Right.
[02:35:42.260 --> 02:35:44.540]   I doubt that's going to happen.
[02:35:44.540 --> 02:35:50.340]   First of all, that's a lot of bandwidth, a lot of storage and a lot of people watching
[02:35:50.340 --> 02:35:55.540]   what you're doing, it's much more likely that they just say, "But at any point, if we should
[02:35:55.540 --> 02:35:59.900]   decide we want your phone or we want your account, we can go and get it and see what's
[02:35:59.900 --> 02:36:00.900]   on there."
[02:36:00.900 --> 02:36:01.900]   Exactly.
[02:36:01.900 --> 02:36:02.900]   Yeah.
[02:36:02.900 --> 02:36:08.380]   But I think things like encrypted messaging platforms and so forth are probably going to
[02:36:08.380 --> 02:36:09.380]   continue on.
[02:36:09.380 --> 02:36:12.500]   I don't see how they can stop signal.
[02:36:12.500 --> 02:36:13.500]   I don't know.
[02:36:13.500 --> 02:36:14.500]   This is, you're right.
[02:36:14.500 --> 02:36:15.980]   This will be a big story in 2021.
[02:36:15.980 --> 02:36:16.980]   I agree with you.
[02:36:16.980 --> 02:36:20.500]   Jeff Jarvis, your big story for 2021.
[02:36:20.500 --> 02:36:24.100]   That's going to drive me nuts and I'll be screaming on the show and having a fix to
[02:36:24.100 --> 02:36:28.020]   calm me down and give me drugs, but it's going to be regulation.
[02:36:28.020 --> 02:36:29.020]   Regulation, I agree.
[02:36:29.020 --> 02:36:38.580]   You think Biden will continue to pursue, really, Congress initiated it, so Congress is clearly
[02:36:38.580 --> 02:36:39.580]   going to pursue those.
[02:36:39.580 --> 02:36:43.820]   Well, this is interesting to think, because one, I know he's getting advice to say, "Hold
[02:36:43.820 --> 02:36:44.820]   on.
[02:36:44.820 --> 02:36:47.180]   Oh, gee, hold on.
[02:36:47.180 --> 02:36:54.340]   There may be other ways to look at this, but there's a pincer movement against tech.
[02:36:54.340 --> 02:36:57.620]   The problem is I think what's going to happen is at some point the progressives are going
[02:36:57.620 --> 02:37:01.840]   to wake up and look and realize that they're on the same side as some of this as the Trump
[02:37:01.840 --> 02:37:05.340]   is and that's not going to be a comfortable place to be.
[02:37:05.340 --> 02:37:10.060]   And freedom of expression for communities too long, not hurt in mass media is what I
[02:37:10.060 --> 02:37:11.060]   care about most.
[02:37:11.060 --> 02:37:14.260]   We've got 230 here in the EU.
[02:37:14.260 --> 02:37:20.980]   We have the Digital Services Act and the Digital Markets Act, which are going to come in,
[02:37:20.980 --> 02:37:31.060]   along with UK regulation on antitrust and also on digital harms is coming up.
[02:37:31.060 --> 02:37:34.380]   Australia has its Murdoch law, trying to go after them.
[02:37:34.380 --> 02:37:38.620]   We have all kinds of things that are going to be happening in the next year.
[02:37:38.620 --> 02:37:49.380]   And the platforms, my problem is that they're the ones who need to defend the internet and
[02:37:49.380 --> 02:37:51.140]   they're the worst defenders of the internet.
[02:37:51.140 --> 02:37:52.860]   That's what bothers me.
[02:37:52.860 --> 02:37:54.860]   Yeah.
[02:37:54.860 --> 02:37:58.020]   Right now it's a politically volatile situation.
[02:37:58.020 --> 02:38:03.300]   Maybe that'll get less so in January.
[02:38:03.300 --> 02:38:08.900]   And then maybe calmer heads can prevail, but I think that the investigations, the FTC and
[02:38:08.900 --> 02:38:11.980]   Congress have initiated, those are not going away.
[02:38:11.980 --> 02:38:16.980]   The EU, Margarit Vestiger has become more and more aggressive.
[02:38:16.980 --> 02:38:18.460]   Those aren't going to go away.
[02:38:18.460 --> 02:38:21.180]   So yeah, this is going to be the year of reckoning for big tech.
[02:38:21.180 --> 02:38:22.620]   There's a book coming out in March.
[02:38:22.620 --> 02:38:29.220]   I just read for blurbing purposes by a near it, Weiss Blatt, who's a researcher at I think
[02:38:29.220 --> 02:38:33.460]   at USC or UCLA, I said they forget which one.
[02:38:33.460 --> 02:38:36.940]   And about the tech clash and when it started.
[02:38:36.940 --> 02:38:38.980]   And we'll talk about it when the book comes out.
[02:38:38.980 --> 02:38:41.260]   But it's a fact and we want to have Iran.
[02:38:41.260 --> 02:38:47.780]   It's a fascinating bit of data as to when media just suddenly did a 180.
[02:38:47.780 --> 02:38:50.060]   And it wasn't what I expected.
[02:38:50.060 --> 02:38:54.140]   My story for next year that I think is going to be interesting is one that's been developing
[02:38:54.140 --> 02:38:58.580]   this year, but I think it's going to take off next year, which is the advent of streaming.
[02:38:58.580 --> 02:39:03.340]   Of course, this was the year streaming gaming got pressed.
[02:39:03.340 --> 02:39:10.820]   In fact, Cyberpunk 2077 seems to be only played playable streaming services like GeForce
[02:39:10.820 --> 02:39:13.420]   Now and Stadia.
[02:39:13.420 --> 02:39:17.820]   Google Engineer has said we have ported Stadia to iOS.
[02:39:17.820 --> 02:39:24.700]   So they've gotten around Apple's restriction on streaming gaming by just making it work
[02:39:24.700 --> 02:39:26.340]   in the browser.
[02:39:26.340 --> 02:39:27.500]   And apparently work quite well.
[02:39:27.500 --> 02:39:33.380]   This is Thumper, which is working in Safari on the new version of iOS in beta and working
[02:39:33.380 --> 02:39:34.780]   in real time.
[02:39:34.780 --> 02:39:36.940]   But it isn't about gaming in the long run.
[02:39:36.940 --> 02:39:39.620]   It's about things like Windows Virtual Desktop.
[02:39:39.620 --> 02:39:45.780]   I suspect that more and more of our computing will be done with a thin client.
[02:39:45.780 --> 02:39:50.100]   Maybe that's why the Fold is so interesting because that could be your thin client, not
[02:39:50.100 --> 02:39:54.020]   just for gaming, but for Windows, for your operating system.
[02:39:54.020 --> 02:39:57.140]   Amazon has put Mac minis on AWS.
[02:39:57.140 --> 02:40:01.460]   Soon you'll be able to use a Mac and Mac OS over the cloud.
[02:40:01.460 --> 02:40:05.300]   I think that's going to be a big trend in 2021.
[02:40:05.300 --> 02:40:09.380]   And it's going to very much change how we think of computing and desktop computing in
[02:40:09.380 --> 02:40:10.380]   particular.
[02:40:10.380 --> 02:40:11.380]   And I'm hopeful, Steve.
[02:40:11.380 --> 02:40:14.860]   I think one of the things that's driving this is ransomware and security.
[02:40:14.860 --> 02:40:20.700]   I'm hopeful that these professionally managed operating systems in the cloud will be more
[02:40:20.700 --> 02:40:25.980]   reliable and more secure than they'll do a better job than we have been doing on our
[02:40:25.980 --> 02:40:27.500]   systems at home.
[02:40:27.500 --> 02:40:28.500]   Plus 5G.
[02:40:28.500 --> 02:40:32.060]   Don't forget 5G is going to make it all possible.
[02:40:32.060 --> 02:40:39.740]   This show is brought to you by the magic of 5G.
[02:40:39.740 --> 02:40:42.860]   Is the year of I'm not leaving 3G.
[02:40:42.860 --> 02:40:44.580]   You're on your own.
[02:40:44.580 --> 02:40:46.220]   What's wrong with it?
[02:40:46.220 --> 02:40:47.500]   I love for me.
[02:40:47.500 --> 02:40:48.500]   I like.
[02:40:48.500 --> 02:40:55.940]   And of course, it's the year of the Linux desktop.
[02:40:55.940 --> 02:40:56.940]   2020.
[02:40:56.940 --> 02:40:57.940]   Yes.
[02:40:57.940 --> 02:40:58.940]   Very important.
[02:40:58.940 --> 02:41:02.540]   I want to do Chromebook from Google.
[02:41:02.540 --> 02:41:03.780]   You want the real one?
[02:41:03.780 --> 02:41:04.780]   Yeah.
[02:41:04.780 --> 02:41:05.780]   Yeah.
[02:41:05.780 --> 02:41:06.780]   Yeah.
[02:41:06.780 --> 02:41:07.780]   I don't blame you.
[02:41:07.780 --> 02:41:11.260]   Paul Therat, thank you so much for being a part of our family for being here today to
[02:41:11.260 --> 02:41:13.620]   end the year.
[02:41:13.620 --> 02:41:20.740]   This week on Wednesday will be our best episode at I will see you in, I guess it won't be
[02:41:20.740 --> 02:41:21.740]   the new year.
[02:41:21.740 --> 02:41:27.340]   I'll see you for one last show on January 30th, I mean December 30th.
[02:41:27.340 --> 02:41:32.260]   We'll do our wrap up of the year you and Mary just don't go on too late Paul because
[02:41:32.260 --> 02:41:33.260]   it delays us.
[02:41:33.260 --> 02:41:34.260]   Okay.
[02:41:34.260 --> 02:41:41.740]   I wanted to apologize publicly for what you probably would.
[02:41:41.740 --> 02:41:42.740]   Sorry.
[02:41:42.740 --> 02:41:43.740]   They're on the beer.
[02:41:43.740 --> 02:41:44.740]   Yes.
[02:41:44.740 --> 02:41:47.260]   You know, when we hit beer, it's time for you.
[02:41:47.260 --> 02:41:48.260]   Jeff Jarvis.
[02:41:48.260 --> 02:41:49.260]   I'm ready to drink.
[02:41:49.260 --> 02:41:50.260]   Yeah.
[02:41:50.260 --> 02:41:53.900]   Post this week, Google along with Aunt Pruitt and Stacey Higginbotham.
[02:41:53.900 --> 02:41:58.780]   One of my, I always continue one of my best friends that I never get to see in real life,
[02:41:58.780 --> 02:41:59.780]   but it's always a pleasure to see you.
[02:41:59.780 --> 02:42:01.060]   I know we're going to change that.
[02:42:01.060 --> 02:42:05.060]   Every Wednesday on this week in Google, thank you for all you do.
[02:42:05.060 --> 02:42:08.220]   And for keeping me honest and spanking me from time to time.
[02:42:08.220 --> 02:42:09.220]   And you me.
[02:42:09.220 --> 02:42:12.220]   And this sounds like an S&M show, but we're going to go off this.
[02:42:12.220 --> 02:42:14.220]   We're going to stop that.
[02:42:14.220 --> 02:42:16.940]   And Steve, we have an interesting dynamic and that's what it is.
[02:42:16.940 --> 02:42:18.340]   Now I'm even more interested.
[02:42:18.340 --> 02:42:20.740]   Let it be an interesting dynamic.
[02:42:20.740 --> 02:42:21.740]   I'll get the paddle.
[02:42:21.740 --> 02:42:22.740]   You get the straps.
[02:42:22.740 --> 02:42:25.340]   And then whoa, I don't know.
[02:42:25.340 --> 02:42:27.940]   It got weird at the end there.
[02:42:27.940 --> 02:42:31.340]   And actually somebody I've known longer than almost anybody.
[02:42:31.340 --> 02:42:35.140]   The OG of OG of OG God of gods, the expert of experts.
[02:42:35.140 --> 02:42:40.580]   Steve Gibson, who I first met in the late 90s, who is of course our host at security now
[02:42:40.580 --> 02:42:44.940]   and also I think for all of us a mentor and an inspiration.
[02:42:44.940 --> 02:42:48.100]   The guy who keeps us safe.
[02:42:48.100 --> 02:42:49.100]   Yes.
[02:42:49.100 --> 02:42:52.420]   When 300 BOD was the speed at which we telecommuted.
[02:42:52.420 --> 02:42:54.100]   God, that's right.
[02:42:54.100 --> 02:42:56.340]   No one needs more than 300 BOD.
[02:42:56.340 --> 02:42:59.580]   You can't type that fast.
[02:42:59.580 --> 02:43:03.260]   You know, it can keep up the type of type of type you need.
[02:43:03.260 --> 02:43:04.860]   You guys are the greatest.
[02:43:04.860 --> 02:43:07.460]   Thank you for making Twit what it is.
[02:43:07.460 --> 02:43:13.500]   Thank you, dear listeners and dear viewers because there'd be no point in the chat room.
[02:43:13.500 --> 02:43:16.380]   There'd be no point in doing this if you didn't watch and listen.
[02:43:16.380 --> 02:43:17.620]   We're very, very grateful.
[02:43:17.620 --> 02:43:20.060]   I know it's been a hard year for all of us.
[02:43:20.060 --> 02:43:22.380]   Thank you for hanging in there with us.
[02:43:22.380 --> 02:43:29.140]   I think 2021 is going to be a better year as the boy as the who said in Tommy.
[02:43:29.140 --> 02:43:34.140]   I got a feeling 21 is going to be a good year, but we got to see it in together.
[02:43:34.140 --> 02:43:36.020]   Thanks for joining us.
[02:43:36.020 --> 02:43:39.460]   The Twit is in the camp.
[02:43:39.460 --> 02:43:41.460]   Do the Twit.
[02:43:41.460 --> 02:43:42.460]   Do the Twit.
[02:43:42.460 --> 02:43:43.460]   All right.
[02:43:43.460 --> 02:43:44.460]   Do the Twit, baby.
[02:43:44.460 --> 02:43:45.460]   Do the Twit.
[02:43:45.460 --> 02:43:46.460]   All right.
[02:43:46.460 --> 02:43:46.460]   Do the Twit.
[02:43:46.460 --> 02:43:53.000]   to it.

