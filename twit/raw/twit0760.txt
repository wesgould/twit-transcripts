;FFMETADATA1
title=A Perfect Time to Panic
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=760
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.560]   It's time for Twit this weekend tech.
[00:00:02.560 --> 00:00:03.640]   We got a great panel for you.
[00:00:03.640 --> 00:00:05.800]   Christina Warren is here.
[00:00:05.800 --> 00:00:07.680]   Bill Detweiler from Tech Republic.
[00:00:07.680 --> 00:00:10.320]   Michael Munoz from Ford, we're gonna talk about
[00:00:10.320 --> 00:00:13.240]   the impact on tech from the Corona virus.
[00:00:13.240 --> 00:00:17.920]   Apple loses a big battle against a patent troll.
[00:00:17.920 --> 00:00:22.320]   And we'll go inside the Amazon grab-and-go grocery store.
[00:00:22.320 --> 00:00:23.440]   Christina likes it.
[00:00:23.440 --> 00:00:25.600]   It's all coming up next on Twit.
[00:00:25.600 --> 00:00:29.200]   This weekend tech comes to you from Twit's LastPass Studios.
[00:00:29.200 --> 00:00:32.040]   Stay in control when it comes to your company's access points
[00:00:32.040 --> 00:00:33.120]   and authentication.
[00:00:33.120 --> 00:00:36.560]   LastPass makes enterprise-level security simple.
[00:00:36.560 --> 00:00:41.600]   Check out lastpass.com/twit to learn more.
[00:00:41.600 --> 00:00:46.480]   Podcasts you love from people you trust.
[00:00:46.480 --> 00:00:47.840]   This is Twit.
[00:00:47.840 --> 00:00:56.680]   This is Twit.
[00:00:56.680 --> 00:01:01.320]   This weekend tech, Episode 760, recorded Sunday, March 1st,
[00:01:01.320 --> 00:01:05.440]   2020, a perfect time to panic.
[00:01:05.440 --> 00:01:08.600]   This weekend tech is brought to you by ZipRecruiter.
[00:01:08.600 --> 00:01:10.280]   Hiring is challenging.
[00:01:10.280 --> 00:01:13.480]   But there is one place you can go where hiring is simple and smart.
[00:01:13.480 --> 00:01:16.640]   That place is ZipRecruiter, where growing businesses
[00:01:16.640 --> 00:01:18.480]   connect to qualified candidates.
[00:01:18.480 --> 00:01:22.640]   Try it free at ziprecruiter.com/twit.
[00:01:22.640 --> 00:01:25.040]   And by privacy.com.
[00:01:25.040 --> 00:01:28.360]   Privacy lets you make purchases online using virtual cards
[00:01:28.360 --> 00:01:29.440]   instead of real ones.
[00:01:29.440 --> 00:01:32.760]   Protecting your identity and bank information on the internet.
[00:01:32.760 --> 00:01:35.960]   New customers get $5 to spend on their first purchase.
[00:01:35.960 --> 00:01:40.080]   Go to privacy.com/twit to sign up now.
[00:01:40.080 --> 00:01:44.000]   And by Captera, the website millions of people
[00:01:44.000 --> 00:01:47.160]   use monthly to find software for their team or business.
[00:01:47.160 --> 00:01:52.480]   Visit capterasfreewebsite@captera.com/twit.
[00:01:52.480 --> 00:01:54.560]   And by Masterclass.
[00:01:54.560 --> 00:01:58.120]   Online classes taught by the world's greatest minds.
[00:01:58.120 --> 00:02:00.760]   Get unlimited access to every Masterclass.
[00:02:00.760 --> 00:02:05.200]   And as a listener, you'll get 15% off the annual All Access Pass.
[00:02:05.200 --> 00:02:08.040]   Go to masterclass.com/twit.
[00:02:08.040 --> 00:02:21.320]   It's time for Twit this week in Tech, the show we cover the week's tech news.
[00:02:21.320 --> 00:02:25.280]   I have gathered together a fine panel for your enjoyment today.
[00:02:25.280 --> 00:02:27.240]   Christina Warren's back in the house.
[00:02:27.240 --> 00:02:29.920]   Thanks to the government of Switzerland.
[00:02:29.920 --> 00:02:34.280]   She has developed relations at Microsoft and was on her way to Zurich.
[00:02:34.280 --> 00:02:35.680]   When? Yesterday?
[00:02:35.680 --> 00:02:38.240]   Well, I was actually supposed to first, I was going to go to London
[00:02:38.240 --> 00:02:41.040]   for the weekend because it was actually significantly less
[00:02:41.040 --> 00:02:43.680]   expensive to fly to London and then fly to Zurich.
[00:02:43.680 --> 00:02:48.160]   And on Friday morning, as I was about to leave for the airport,
[00:02:48.160 --> 00:02:53.040]   the government of Switzerland said that all events with more than 1,000 people
[00:02:53.040 --> 00:02:56.000]   would be canceled and that included our events.
[00:02:56.000 --> 00:02:58.400]   So we had to immediately cancel.
[00:02:58.400 --> 00:03:02.520]   And so I am here instead of in Southern Switzerland.
[00:03:02.520 --> 00:03:08.040]   It's just as I've always said, Christina is the Mona Lisa of Tech.
[00:03:08.040 --> 00:03:08.960]   You know why I say that?
[00:03:08.960 --> 00:03:11.520]   Because the Louvre was also closed.
[00:03:11.520 --> 00:03:12.640]   The Louvre was also closed.
[00:03:12.640 --> 00:03:16.600]   Yeah, they said that it was just going to be because they were having a meeting.
[00:03:16.600 --> 00:03:18.600]   And then they were like, no, no, no, it's closed.
[00:03:18.600 --> 00:03:19.600]   It's closed.
[00:03:19.600 --> 00:03:20.720]   Bye bye.
[00:03:20.720 --> 00:03:22.280]   Bye bye Mona Lisa.
[00:03:22.280 --> 00:03:24.280]   You get the weekend off.
[00:03:24.280 --> 00:03:25.240]   Yeah.
[00:03:25.240 --> 00:03:28.200]   Also joining us is great to see Michael Nunez again.
[00:03:28.200 --> 00:03:30.160]   Last time, I think you were popular science now.
[00:03:30.160 --> 00:03:32.480]   He's associate editor at Forbes.
[00:03:32.480 --> 00:03:34.160]   I think there were a few stops in between.
[00:03:34.160 --> 00:03:35.520]   I'm Michael.
[00:03:35.520 --> 00:03:36.600]   Hey, great to see you, Leo.
[00:03:36.600 --> 00:03:39.240]   I love your New York Yankees cap.
[00:03:39.240 --> 00:03:40.160]   Thank you.
[00:03:40.160 --> 00:03:42.560]   From what you could see on this terrible webcam.
[00:03:42.560 --> 00:03:44.440]   This is actually a bit of vintage history.
[00:03:44.440 --> 00:03:51.480]   You're using a 20, 2010 eyesight, a 10-year-old eyesight, which was bad even 10 years ago,
[00:03:51.480 --> 00:03:52.480]   to be honest.
[00:03:52.480 --> 00:03:53.480]   Yeah, yeah.
[00:03:53.480 --> 00:03:55.520]   I apologize for the quality of the video.
[00:03:55.520 --> 00:03:56.520]   I don't care.
[00:03:56.520 --> 00:03:57.520]   No, it's great.
[00:03:57.520 --> 00:03:58.520]   It's a store bag.
[00:03:58.520 --> 00:03:59.520]   It's vintage.
[00:03:59.520 --> 00:04:05.000]   Yeah, just like the Van Gogh behind you, this is the expressionist Michael Nunez.
[00:04:05.000 --> 00:04:06.000]   That's right.
[00:04:06.000 --> 00:04:09.520]   Yes, I made you with my thumb.
[00:04:09.520 --> 00:04:14.640]   I'm a new visitor to our studios, but from a venerable and long-beloved publication,
[00:04:14.640 --> 00:04:18.640]   the new editor-in-chief at Tech Republic, Jason Heinrich's replacement, Bill Detweiler's
[00:04:18.640 --> 00:04:19.640]   here.
[00:04:19.640 --> 00:04:20.640]   Hi, Bill.
[00:04:20.640 --> 00:04:21.640]   Hey, Leo.
[00:04:21.640 --> 00:04:22.640]   Thanks for having me.
[00:04:22.640 --> 00:04:25.600]   I've been reading your stuff for a long, long time.
[00:04:25.600 --> 00:04:30.200]   I think you're almost as old as that Macintosh behind you there.
[00:04:30.200 --> 00:04:31.840]   Almost, almost.
[00:04:31.840 --> 00:04:33.080]   You know, we were talking before the show.
[00:04:33.080 --> 00:04:35.440]   It's been 20 years that I've been at Tech Republic.
[00:04:35.440 --> 00:04:36.440]   Wow.
[00:04:36.440 --> 00:04:37.440]   So that's a long time.
[00:04:37.440 --> 00:04:39.040]   That's actually a testament to Tech Republic, really.
[00:04:39.040 --> 00:04:40.040]   I mean, that's fantastic.
[00:04:40.040 --> 00:04:41.040]   And to you.
[00:04:41.040 --> 00:04:42.040]   And to you.
[00:04:42.040 --> 00:04:43.040]   Yeah, thank you.
[00:04:43.040 --> 00:04:45.560]   It's an amazing place, an amazing site.
[00:04:45.560 --> 00:04:47.720]   And you know, we have an amazing group of readers.
[00:04:47.720 --> 00:04:50.280]   So hopefully, you know, it'll be another 20 years.
[00:04:50.280 --> 00:04:54.040]   This is the longest I've ever worked anywhere, and it's only because I own the place.
[00:04:54.040 --> 00:04:56.240]   I can't fire me.
[00:04:56.240 --> 00:05:00.480]   Although I thought about it a couple of times, I got to say that, Leo, I tell you, he's
[00:05:00.480 --> 00:05:01.480]   trouble.
[00:05:01.480 --> 00:05:03.240]   Coronavirus is, well, let's do Coronavirus.
[00:05:03.240 --> 00:05:07.480]   We've started every show for the last two weeks talking about coronavirus, but it is
[00:05:07.480 --> 00:05:08.480]   a big deal.
[00:05:08.480 --> 00:05:12.400]   F8, the Facebook Developers Conference was just canceled.
[00:05:12.400 --> 00:05:19.640]   The GDC, the Game Developers Conference postponed till the summer.
[00:05:19.640 --> 00:05:20.640]   Microsoft had pulled out.
[00:05:20.640 --> 00:05:23.640]   A lot of companies had pulled out.
[00:05:23.640 --> 00:05:24.640]   Wow.
[00:05:24.640 --> 00:05:28.720]   Actually, I have this is how fast it moves.
[00:05:28.720 --> 00:05:33.320]   I have a story here on our rundown saying, "GDC moving forward is planned."
[00:05:33.320 --> 00:05:34.320]   Wow.
[00:05:34.320 --> 00:05:40.720]   And it really is hard to keep up with the cancellations, the postponements.
[00:05:40.720 --> 00:05:43.600]   We had someone at RSA just last week.
[00:05:43.600 --> 00:05:46.880]   So it's really changing on a day by day basis.
[00:05:46.880 --> 00:05:49.840]   We went to RSA.
[00:05:49.840 --> 00:05:55.760]   I felt like it was a life, it was a death-defying act actually, but I don't know if it's hard.
[00:05:55.760 --> 00:05:57.400]   This is the problem.
[00:05:57.400 --> 00:05:58.400]   Everybody seems fine.
[00:05:58.400 --> 00:05:59.400]   It doesn't seem.
[00:05:59.400 --> 00:06:01.600]   I mean, there are some people very sick.
[00:06:01.600 --> 00:06:02.600]   Right.
[00:06:02.600 --> 00:06:09.120]   Paula died in Washington, San Hamos, our first United States fatality due to coronavirus.
[00:06:09.120 --> 00:06:14.960]   But then we're also hearing people like Bill Gates say that this might be the once-in-a-century
[00:06:14.960 --> 00:06:16.800]   pathogen we've been waiting for.
[00:06:16.800 --> 00:06:19.400]   He wrote that in the New England Journal of Medicine.
[00:06:19.400 --> 00:06:23.360]   Well, it is interesting too, because at this point, this is why I get frustrated with,
[00:06:23.360 --> 00:06:24.800]   I mean, I understand the cancellations.
[00:06:24.800 --> 00:06:28.440]   I understand people are wanting to be safe and I support that.
[00:06:28.440 --> 00:06:34.600]   However, as someone who with disclosure has traveled, basically for the last six weeks,
[00:06:34.600 --> 00:06:37.440]   I've been international almost every week.
[00:06:37.440 --> 00:06:38.440]   I've had a couple of trips.
[00:06:38.440 --> 00:06:44.160]   I had my trip to Singapore was canceled, although I still ended up transiting through.
[00:06:44.160 --> 00:06:45.600]   My Zurich trip was just canceled.
[00:06:45.600 --> 00:06:50.560]   So I've been in a lot of airports and I don't want to minimize anything with what's happening.
[00:06:50.560 --> 00:06:55.520]   However, because we now see that it is spreading beyond people who've just had direct contact
[00:06:55.520 --> 00:06:57.000]   with people who've traveled.
[00:06:57.000 --> 00:07:01.560]   To me, it seems like at this point, the whole containment strategy has failed.
[00:07:01.560 --> 00:07:02.560]   Thanks a lot, Italy.
[00:07:02.560 --> 00:07:04.280]   I'm going to actually blame Italy for this.
[00:07:04.280 --> 00:07:05.840]   You're blaming Italy for this?
[00:07:05.840 --> 00:07:09.560]   Well, I'm going to blame them for the containment issue.
[00:07:09.560 --> 00:07:15.080]   They did not, when they had their first patient, they did not follow any standard protocols
[00:07:15.080 --> 00:07:17.640]   at all for protecting the hospital or anything else.
[00:07:17.640 --> 00:07:21.040]   And in fact, some of the illnesses in the US are from Italy.
[00:07:21.040 --> 00:07:22.040]   Right.
[00:07:22.040 --> 00:07:26.440]   Well, what happens is because Italy is in the EU and it's in the Shenzhen zone, you don't
[00:07:26.440 --> 00:07:30.320]   have to cross and across borders is much, much easier.
[00:07:30.320 --> 00:07:31.320]   Right.
[00:07:31.320 --> 00:07:34.200]   So at this point, I'm not a doctor.
[00:07:34.200 --> 00:07:37.680]   People can disagree with me, but I feel like the containment thing we've failed, it is
[00:07:37.680 --> 00:07:38.840]   not contained.
[00:07:38.840 --> 00:07:42.840]   So part of me, I'm kind of looking at, okay, no matter where you are, unless you want to
[00:07:42.840 --> 00:07:50.040]   stay as a hermit inside your home and not have any contact with anyone, the likelihood
[00:07:50.040 --> 00:07:54.760]   like I live in King County, Washington, where we now have six cases and the first US fatality,
[00:07:54.760 --> 00:08:01.000]   it's like, am I any safer in terms of exposure if I stay at home or if I travel someplace,
[00:08:01.000 --> 00:08:02.000]   right?
[00:08:02.000 --> 00:08:08.160]   Like at this point, I feel like the containment is, it's been breached.
[00:08:08.160 --> 00:08:12.920]   So I don't know, there are, I understand, you know, cutting down some of the travel stuff,
[00:08:12.920 --> 00:08:16.160]   but at the same time, it seems like this is just going to get worse and worse.
[00:08:16.160 --> 00:08:20.520]   And we've, we've passed the point where simply limiting people from traveling is going to
[00:08:20.520 --> 00:08:22.440]   really do anything to stop this.
[00:08:22.440 --> 00:08:29.960]   Oh, this is, the other problem, of course, is that the epicenter of this China is where
[00:08:29.960 --> 00:08:33.080]   everything we use is made.
[00:08:33.080 --> 00:08:35.480]   So factory closings have affected.
[00:08:35.480 --> 00:08:39.960]   In fact, I've heard people say, if you're going to buy a computer, a smartphone, if
[00:08:39.960 --> 00:08:41.760]   you're going to buy anything, get it now.
[00:08:41.760 --> 00:08:42.760]   Right.
[00:08:42.760 --> 00:08:44.560]   Because there's going to be shortage.
[00:08:44.560 --> 00:08:45.560]   I don't know.
[00:08:45.560 --> 00:08:47.400]   But the problem is we just, it doesn't seem like we know.
[00:08:47.400 --> 00:08:50.160]   It's all kind of a mystery.
[00:08:50.160 --> 00:08:54.640]   That's the hard part, you know, I was listening to the radio on the way in and they were talking
[00:08:54.640 --> 00:09:00.040]   about the community spread here in the US and they were trying to link people that have
[00:09:00.040 --> 00:09:05.920]   been tested positive for the disease to each other or to places they've been.
[00:09:05.920 --> 00:09:11.760]   And that's proving hard to do because several of them now don't have direct connection to
[00:09:11.760 --> 00:09:13.840]   travel internationally.
[00:09:13.840 --> 00:09:15.960]   So I think there's just a lot we don't know.
[00:09:15.960 --> 00:09:20.800]   So like you were talking about earlier, Leo with Bill Gates, it could be something that
[00:09:20.800 --> 00:09:24.680]   is like a SARS, a MERS, or a BOLA.
[00:09:24.680 --> 00:09:28.000]   Bill's comparing it to the 1918 flu pandemic.
[00:09:28.000 --> 00:09:29.760]   Or it could be that.
[00:09:29.760 --> 00:09:35.480]   There isn't enough data, I think, in terms of, because, you know, like you said, the numbers
[00:09:35.480 --> 00:09:38.080]   out of China can be maybe a little bit unreliable.
[00:09:38.080 --> 00:09:41.640]   So we don't know actually how the death rate is.
[00:09:41.640 --> 00:09:46.760]   We don't know necessarily how high, you know, the infection rate is, how many people recover.
[00:09:46.760 --> 00:09:49.160]   So it's too early.
[00:09:49.160 --> 00:09:52.360]   There's so much uncertainty to kind of know how bad it's going to get.
[00:09:52.360 --> 00:09:54.120]   And you know, it's not just computers.
[00:09:54.120 --> 00:09:55.360]   It's not just iPhones.
[00:09:55.360 --> 00:09:57.320]   It's not just electronics.
[00:09:57.320 --> 00:09:59.880]   Lots of things are made in China.
[00:09:59.880 --> 00:10:05.480]   Medications, you know, medical devices, like the mask shortages that, you know, everybody
[00:10:05.480 --> 00:10:08.800]   has talked a lot about a lot of that's made in China too.
[00:10:08.800 --> 00:10:09.800]   Yeah.
[00:10:09.800 --> 00:10:14.280]   Actually, the, the surgeon general tweeted, this is how we're getting our information.
[00:10:14.280 --> 00:10:19.560]   Now, folks, the surgeon general tweeted, for God's sake, stop buying masks.
[00:10:19.560 --> 00:10:24.800]   He literally said, the masks aren't going to help you from, keep you from getting it.
[00:10:24.800 --> 00:10:29.960]   And by, by, by buying all these masks, we're keeping it from important medical personnel
[00:10:29.960 --> 00:10:33.920]   who do need the masks when they're dealing with coronavirus patients.
[00:10:33.920 --> 00:10:39.760]   So, so, the word has gone forth from the Twitter.
[00:10:39.760 --> 00:10:40.760]   I'm not buying masks.
[00:10:40.760 --> 00:10:43.000]   I want to opportunity to reach in the people.
[00:10:43.000 --> 00:10:44.000]   Say again?
[00:10:44.000 --> 00:10:45.920]   You know, I've gone into full, proper mode.
[00:10:45.920 --> 00:10:49.560]   So I feel a lot different than everyone else here.
[00:10:49.560 --> 00:10:51.200]   I'm avoiding large crowds.
[00:10:51.200 --> 00:10:53.360]   I'm trying not to take the subway.
[00:10:53.360 --> 00:10:56.080]   I have stocked up on food this weekend.
[00:10:56.080 --> 00:10:58.600]   And just this morning, you know, you mentioned the Spanish flu.
[00:10:58.600 --> 00:11:04.240]   I read an interesting data point about how the Spanish flu mortality rate was at about
[00:11:04.240 --> 00:11:09.320]   2%, which is roughly the same as what they're estimating for the coronavirus.
[00:11:09.320 --> 00:11:13.760]   And in one situation, you know, people were ignoring, you know, people were saying that
[00:11:13.760 --> 00:11:19.680]   that they wanted to avoid hysteria and that they wanted to go about their lives in a regular
[00:11:19.680 --> 00:11:20.980]   manner.
[00:11:20.980 --> 00:11:24.480]   And so people in Philadelphia attended, I think, a parade.
[00:11:24.480 --> 00:11:30.160]   And what ended up happening at this, at this public event, I believe it was a parade, you
[00:11:30.160 --> 00:11:36.440]   know, was that like 12,000, 12,500 people ended up contracting the Spanish flu.
[00:11:36.440 --> 00:11:38.680]   You know, many of those people.
[00:11:38.680 --> 00:11:41.080]   And 2%, right?
[00:11:41.080 --> 00:11:42.080]   2%, right?
[00:11:42.080 --> 00:11:43.920]   And 2%, that's one 50.
[00:11:43.920 --> 00:11:48.360]   Yeah, I guess when I read that this morning, I decided that it was time to start buying
[00:11:48.360 --> 00:11:49.360]   some non-perishable goods.
[00:11:49.360 --> 00:11:51.680]   And not go to any parades.
[00:11:51.680 --> 00:11:55.400]   Well, and I mean, in New York, it's hard to avoid crowds, right?
[00:11:55.400 --> 00:11:56.400]   Yeah, right.
[00:11:56.400 --> 00:11:57.400]   So, you know, say Patrick's Day's coming up.
[00:11:57.400 --> 00:11:59.280]   You think they'll be a parade?
[00:11:59.280 --> 00:12:02.040]   I know I'm not going to it.
[00:12:02.040 --> 00:12:07.960]   And, you know, I haven't bought a medical mask yet, but I do think that there is reason
[00:12:07.960 --> 00:12:13.160]   for concern because, you know, I just don't trust that the government is actually testing
[00:12:13.160 --> 00:12:14.160]   people at this point.
[00:12:14.160 --> 00:12:17.800]   I don't feel like there's a real urgency to test people.
[00:12:17.800 --> 00:12:20.440]   And we don't have enough tests.
[00:12:20.440 --> 00:12:21.440]   That's another problem.
[00:12:21.440 --> 00:12:23.480]   CDC screwed up the tests.
[00:12:23.480 --> 00:12:24.480]   They screwed up.
[00:12:24.480 --> 00:12:25.480]   They didn't do it.
[00:12:25.480 --> 00:12:29.840]   Yeah, they didn't work on it and they had the opportunity to collaborate with other
[00:12:29.840 --> 00:12:30.840]   countries.
[00:12:30.840 --> 00:12:31.840]   We got this ourselves.
[00:12:31.840 --> 00:12:34.600]   We got this ourselves and then are behind because...
[00:12:34.600 --> 00:12:36.280]   Are you a prepper, Michael?
[00:12:36.280 --> 00:12:37.800]   No, in most cases...
[00:12:37.800 --> 00:12:38.800]   What's a prepper?
[00:12:38.800 --> 00:12:40.160]   Tell everybody what a prepper is.
[00:12:40.160 --> 00:12:46.120]   A prepper is, I guess, someone that anticipates apocalyptic doom or is kind of as preparing
[00:12:46.120 --> 00:12:47.560]   for the worst.
[00:12:47.560 --> 00:12:52.560]   And, you know, usually when you say prepper, it's someone that expects the world to end
[00:12:52.560 --> 00:12:55.120]   imminently or for there to be, you know, abandoned...
[00:12:55.120 --> 00:12:58.120]   The zombie apocalypse starts tomorrow.
[00:12:58.120 --> 00:12:59.120]   Exactly.
[00:12:59.120 --> 00:13:00.120]   Exactly.
[00:13:00.120 --> 00:13:04.480]   So in this case, you know, I'm not a prepper in the traditional sense.
[00:13:04.480 --> 00:13:10.520]   I don't think that we're on the verge of war or anything like that.
[00:13:10.520 --> 00:13:14.520]   But I do think that the coronavirus spread is a real concern.
[00:13:14.520 --> 00:13:19.360]   I think that all leading experts say that it's only a matter of time before cases start
[00:13:19.360 --> 00:13:20.360]   showing up in the U.S.
[00:13:20.360 --> 00:13:21.360]   I feel like we're getting there.
[00:13:21.360 --> 00:13:22.360]   Yeah, we're getting there.
[00:13:22.360 --> 00:13:25.120]   Community infections happening.
[00:13:25.120 --> 00:13:26.120]   Yeah.
[00:13:26.120 --> 00:13:28.720]   And this is a tech issue.
[00:13:28.720 --> 00:13:35.600]   And unfortunately, you know, there isn't enough testing being done.
[00:13:35.600 --> 00:13:41.280]   So it's up to the onus is on each individual to take the necessary precautions.
[00:13:41.280 --> 00:13:46.160]   So for me, that meant buying non perishable goods, making sure that I'm ready for, you
[00:13:46.160 --> 00:13:50.360]   know, I don't necessarily think that there will be a lockdown in New York, but I want
[00:13:50.360 --> 00:13:51.360]   to be...
[00:13:51.360 --> 00:13:52.760]   Ooh, I wouldn't want to be in Brooklyn right now.
[00:13:52.760 --> 00:13:53.760]   I think that...
[00:13:53.760 --> 00:13:56.560]   Yeah, I could see them closing the bridge.
[00:13:56.560 --> 00:13:57.560]   Right?
[00:13:57.560 --> 00:14:04.560]   No, I don't think that will happen, but you know, but why not?
[00:14:04.560 --> 00:14:08.960]   Well, you look at what happened in China, but we're a completely different system here,
[00:14:08.960 --> 00:14:09.960]   right?
[00:14:09.960 --> 00:14:10.960]   Exactly.
[00:14:10.960 --> 00:14:14.800]   You know, in China, they locked down cities larger than New York and basically turned
[00:14:14.800 --> 00:14:16.520]   the streets into ghost towns.
[00:14:16.520 --> 00:14:20.760]   It's interesting because we were able to see what the authoritarian regime in China
[00:14:20.760 --> 00:14:24.160]   was able to do with the help of technology very early on here.
[00:14:24.160 --> 00:14:27.920]   They were able to do things...nobody's been able to do it before.
[00:14:27.920 --> 00:14:30.640]   Things like put an app on your phone that says if you've been exposed because they know
[00:14:30.640 --> 00:14:32.840]   where you've been and everybody else has.
[00:14:32.840 --> 00:14:33.840]   Yeah, you're right.
[00:14:33.840 --> 00:14:34.840]   We're not China, Bill.
[00:14:34.840 --> 00:14:35.840]   No, we're not.
[00:14:35.840 --> 00:14:36.840]   Thank goodness.
[00:14:36.840 --> 00:14:41.180]   I mean, and in fairness, I don't know if we actually can say because China has been
[00:14:41.180 --> 00:14:48.640]   so opaque about this, if those actions have actually, you know, stopped the spread, right?
[00:14:48.640 --> 00:14:53.520]   Like because China is not going to be transparent about what the situation is actually on the
[00:14:53.520 --> 00:14:54.520]   ground.
[00:14:54.520 --> 00:14:57.960]   I think you could look at places like Singapore and potentially like South Korea and you could
[00:14:57.960 --> 00:15:03.000]   say Singapore especially is a place where they are also going to be a little bit more,
[00:15:03.000 --> 00:15:10.120]   shall we say, totalitarian and also are fairly transparent, especially given what happened
[00:15:10.120 --> 00:15:11.600]   with them in SARS.
[00:15:11.600 --> 00:15:15.840]   They've been very transparent about the cases and I have a lot more trust in the information
[00:15:15.840 --> 00:15:17.800]   they're releasing versus what China is.
[00:15:17.800 --> 00:15:21.600]   But again, I mean, it's like you could make the argument, okay, this is stopping the spread
[00:15:21.600 --> 00:15:24.280]   and this is stopping kind of the contagion.
[00:15:24.280 --> 00:15:28.280]   At the same time, that's not the country we live in and I'm glad for that.
[00:15:28.280 --> 00:15:29.280]   So unless-
[00:15:29.280 --> 00:15:30.280]   It's also probably too late.
[00:15:30.280 --> 00:15:32.000]   Well, this is my point.
[00:15:32.000 --> 00:15:35.040]   It's like, okay, so I live in Washington state.
[00:15:35.040 --> 00:15:36.680]   I live in King County, which is where-
[00:15:36.680 --> 00:15:39.640]   Is it snow home in King County?
[00:15:39.640 --> 00:15:41.480]   It is very close.
[00:15:41.480 --> 00:15:42.960]   It is actually, I think it is.
[00:15:42.960 --> 00:15:43.960]   I believe it is.
[00:15:43.960 --> 00:15:44.960]   So like one of my colleagues-
[00:15:44.960 --> 00:15:45.960]   My first fatality was-
[00:15:45.960 --> 00:15:46.960]   Yes.
[00:15:46.960 --> 00:15:51.000]   And like one of my colleagues lives in snow home.
[00:15:51.000 --> 00:15:52.000]   And like a good friend of mine.
[00:15:52.000 --> 00:15:57.680]   Like it's a lot of people who live there commute to Redmond or to Seattle or whatever.
[00:15:57.680 --> 00:16:01.320]   So I live where more cases are getting discovered, right?
[00:16:01.320 --> 00:16:02.320]   This is the reality.
[00:16:02.320 --> 00:16:05.920]   The reality is, is that also like we live like the city that I live in there, lots of
[00:16:05.920 --> 00:16:08.880]   people who work at Amazon and Microsoft and Google and Facebook.
[00:16:08.880 --> 00:16:09.880]   And they're all traveling.
[00:16:09.880 --> 00:16:10.880]   At least-
[00:16:10.880 --> 00:16:11.880]   And they're all traveling.
[00:16:11.880 --> 00:16:12.880]   Amazon and Google have both cut down on international travel.
[00:16:12.880 --> 00:16:14.880]   Apparently so is Microsoft.
[00:16:14.880 --> 00:16:21.200]   Well we've cut down on non-essential to China and to Iran and to I believe South Korea
[00:16:21.200 --> 00:16:23.360]   for other places so far.
[00:16:23.360 --> 00:16:24.800]   And maybe Italy is now joined the list.
[00:16:24.800 --> 00:16:25.800]   I don't know.
[00:16:25.800 --> 00:16:28.080]   Other places it hasn't.
[00:16:28.080 --> 00:16:34.120]   But any places that have like if there's like a government ban or something, then we're
[00:16:34.120 --> 00:16:36.040]   not going there unless it's, you know, essential.
[00:16:36.040 --> 00:16:38.760]   But the thing is, is because this can persist.
[00:16:38.760 --> 00:16:42.800]   They were saying two weeks, although a genome test that the New York Times reported today
[00:16:42.800 --> 00:16:49.280]   tracked the, I think that the teenager in King County in Mill Creek who got the virus,
[00:16:49.280 --> 00:16:53.520]   they said that it looked like, you know, it existed for a week so it's possible that,
[00:16:53.520 --> 00:16:54.520]   you know, might have actually-
[00:16:54.520 --> 00:16:55.520]   Just going around.
[00:16:55.520 --> 00:17:00.240]   Go back to six weeks which would mean that this is, you know, maybe lasting longer than
[00:17:00.240 --> 00:17:01.240]   we thought.
[00:17:01.240 --> 00:17:05.640]   Just to put this in perspective, we have about 200,000 people listening to this show.
[00:17:05.640 --> 00:17:09.280]   If every one of them, let's say only half of them got it.
[00:17:09.280 --> 00:17:13.120]   That means that 2,000 people would die who are listening right now.
[00:17:13.120 --> 00:17:15.400]   That's a staggering number.
[00:17:15.400 --> 00:17:21.920]   It's 2% sounds small, but if you put it in that perspective, if we lost 2,000 listeners,
[00:17:21.920 --> 00:17:22.920]   that's horrific.
[00:17:22.920 --> 00:17:23.920]   That's awful.
[00:17:23.920 --> 00:17:24.920]   No, it's terrible.
[00:17:24.920 --> 00:17:30.560]   And you extrapolate that out to 350 million, 330 million in the US and the global population.
[00:17:30.560 --> 00:17:32.840]   It really is a staggering number of people.
[00:17:32.840 --> 00:17:33.840]   Right.
[00:17:33.840 --> 00:17:34.840]   No, I mean, if you're in, if you're a Samsung, you can-
[00:17:34.840 --> 00:17:36.640]   I just don't know.
[00:17:36.640 --> 00:17:37.640]   I just don't know.
[00:17:37.640 --> 00:17:39.120]   Like, is it too late, right?
[00:17:39.120 --> 00:17:41.280]   Because my point is like, it's already spreading.
[00:17:41.280 --> 00:17:46.320]   And for me personally, I'm like, okay, my likelihood of getting, like, exposed to this
[00:17:46.320 --> 00:17:49.760]   is the same if I go into the office or if I get on an airplane.
[00:17:49.760 --> 00:17:50.760]   Right, so forget it.
[00:17:50.760 --> 00:17:53.440]   But I mean, the same thing if you're in New York City, it's like, okay, you're-
[00:17:53.440 --> 00:17:54.760]   I think it's not time to panic.
[00:17:54.760 --> 00:17:55.760]   It's not a good time to panic.
[00:17:55.760 --> 00:17:58.040]   Well, I think it depends on some of us-
[00:17:58.040 --> 00:18:01.760]   I think this is a perfectly fine time to panic.
[00:18:01.760 --> 00:18:02.760]   We know that-
[00:18:02.760 --> 00:18:03.760]   You're a prepper!
[00:18:03.760 --> 00:18:04.760]   I read just spreading.
[00:18:04.760 --> 00:18:07.360]   Wouldn't you like to be a prepper too?
[00:18:07.360 --> 00:18:10.040]   It exists in a few different cities in the US.
[00:18:10.040 --> 00:18:12.200]   I think it's a perfectly fine time to panic.
[00:18:12.200 --> 00:18:15.240]   I think that, you know, you don't have to-
[00:18:15.240 --> 00:18:19.080]   I don't think you have to take necessarily, like, extreme measures, but just like general
[00:18:19.080 --> 00:18:21.160]   precautions washing your hands off and-
[00:18:21.160 --> 00:18:26.240]   The good news is people listen to it almost universally do it all alone.
[00:18:26.240 --> 00:18:27.240]   Right.
[00:18:27.240 --> 00:18:33.280]   If you're not in the studio with me, you're often your little Skype-isolated boxes.
[00:18:33.280 --> 00:18:35.280]   This podcast-
[00:18:35.280 --> 00:18:36.280]   Yeah, I think-
[00:18:36.280 --> 00:18:37.600]   And you listeners will survive.
[00:18:37.600 --> 00:18:39.480]   The rest of the world may be gone.
[00:18:39.480 --> 00:18:43.920]   You know, I think that's another part of the technology debate around events like this,
[00:18:43.920 --> 00:18:44.920]   right?
[00:18:44.920 --> 00:18:47.680]   Because you have technology like video teleconferencing.
[00:18:47.680 --> 00:18:48.680]   Yeah.
[00:18:48.680 --> 00:18:49.680]   Tools for collaboration.
[00:18:49.680 --> 00:18:50.680]   People will be working at home.
[00:18:50.680 --> 00:18:51.680]   Why not?
[00:18:51.680 --> 00:18:57.720]   A lot more companies allowing people to telecommute or relaxing the work from home rules without
[00:18:57.720 --> 00:19:00.120]   having to lose a ton of productivity.
[00:19:00.120 --> 00:19:02.120]   So I think we're actually-
[00:19:02.120 --> 00:19:04.920]   The future of work was changing already.
[00:19:04.920 --> 00:19:05.920]   I'm-
[00:19:05.920 --> 00:19:08.440]   You know, it's not sort of morbid fascination.
[00:19:08.440 --> 00:19:13.480]   I'm really curious to see how an event like this maybe accelerates that.
[00:19:13.480 --> 00:19:19.920]   That change to more working from home, a change to collaboration across distances.
[00:19:19.920 --> 00:19:22.760]   How does that affect corporate real estate?
[00:19:22.760 --> 00:19:25.520]   The real estate market do companies need to have large offices?
[00:19:25.520 --> 00:19:27.640]   If more and more people work from home?
[00:19:27.640 --> 00:19:30.400]   What happens to transportation infrastructure?
[00:19:30.400 --> 00:19:34.240]   There's all these kinds of questions that we just don't know the answer to because we
[00:19:34.240 --> 00:19:37.560]   haven't had a big event in recent history like this.
[00:19:37.560 --> 00:19:38.560]   Yeah.
[00:19:38.560 --> 00:19:41.320]   There are other people who might benefit from this.
[00:19:41.320 --> 00:19:43.480]   This seems like a little creepy, but I'm going to talk about it.
[00:19:43.480 --> 00:19:44.480]   Who's going to benefit?
[00:19:44.480 --> 00:19:52.680]   Samsung is our- They're blaming the coronavirus for the crap sales numbers for the S20.
[00:19:52.680 --> 00:19:55.000]   It's not the fact that it starts at $1,000.
[00:19:55.000 --> 00:19:56.000]   Yeah.
[00:19:56.000 --> 00:19:57.320]   Apparently they've sold $7.
[00:19:57.320 --> 00:20:01.520]   70,000 units in the first day according to 9 to 5.
[00:20:01.520 --> 00:20:05.880]   That's half what they sold of the S10 in the first day.
[00:20:05.880 --> 00:20:09.520]   And Samsung says, "Oh, yeah, it's a virus, man.
[00:20:09.520 --> 00:20:10.680]   It's a virus."
[00:20:10.680 --> 00:20:15.200]   If our numbers go down over the next six months, I'm blaming the virus.
[00:20:15.200 --> 00:20:17.320]   Who else benefits from this?
[00:20:17.320 --> 00:20:19.160]   Work at home companies, right?
[00:20:19.160 --> 00:20:21.800]   I mean, I know the stock market's tanking.
[00:20:21.800 --> 00:20:27.280]   Is there an opportunity here to buy some stocks right now that would benefit from isolation
[00:20:27.280 --> 00:20:32.280]   and world-m
[00:20:32.280 --> 00:20:37.040]   The go-bag makers, they're going to do great, right?
[00:20:37.040 --> 00:20:42.840]   Face mask manufacturers, pharmaceutical companies.
[00:20:42.840 --> 00:20:46.560]   The maker of Clorox bleach.
[00:20:46.560 --> 00:20:47.560]   Oh, yeah.
[00:20:47.560 --> 00:20:49.640]   I went out and bought my Clorox wipes.
[00:20:49.640 --> 00:20:50.640]   I bought a bunch of them.
[00:20:50.640 --> 00:20:51.640]   Yeah, you're well.
[00:20:51.640 --> 00:20:52.640]   Things.
[00:20:52.640 --> 00:20:53.640]   Well, that was the thing, right?
[00:20:53.640 --> 00:20:56.720]   Every time I get on an airplane, anyway, I always go like full Naomi Campbell and I wipe
[00:20:56.720 --> 00:21:01.280]   the seat in the whole area with the Clorox wipes and whatnot.
[00:21:01.280 --> 00:21:03.120]   I do that anyway.
[00:21:03.120 --> 00:21:06.040]   And if anything, this is a good thing.
[00:21:06.040 --> 00:21:08.720]   Mike was saying, "Wash your hands."
[00:21:08.720 --> 00:21:09.720]   We should all be doing that.
[00:21:09.720 --> 00:21:12.360]   Wish we should be doing, yeah, regarding 20 seconds.
[00:21:12.360 --> 00:21:13.360]   20 seconds.
[00:21:13.360 --> 00:21:15.160]   Yes, for 20 seconds, do it the right way.
[00:21:15.160 --> 00:21:16.160]   Dry your hands.
[00:21:16.160 --> 00:21:17.160]   I didn't know this.
[00:21:17.160 --> 00:21:20.480]   I always thought that the dryer hands thing was just kind of like whatever.
[00:21:20.480 --> 00:21:23.200]   No, that wet hands bread bacteria more.
[00:21:23.200 --> 00:21:25.520]   Or it can incubate the bacteria more.
[00:21:25.520 --> 00:21:26.520]   So you should dry your hands.
[00:21:26.520 --> 00:21:27.520]   So I was like, "Okay."
[00:21:27.520 --> 00:21:30.400]   So wash your hands 20 seconds, do the full thing.
[00:21:30.400 --> 00:21:31.400]   I have.
[00:21:31.400 --> 00:21:33.560]   Making sure that if you are sick.
[00:21:33.560 --> 00:21:38.600]   British National Health Service, a poster I'm going to put on the wall here on hand washing
[00:21:38.600 --> 00:21:40.240]   technique.
[00:21:40.240 --> 00:21:41.240]   It's ridiculous.
[00:21:41.240 --> 00:21:43.480]   No, I think this is great.
[00:21:43.480 --> 00:21:46.320]   Most people don't, most people forget step four.
[00:21:46.320 --> 00:21:47.320]   Get between the fingers.
[00:21:47.320 --> 00:21:48.320]   Yes.
[00:21:48.320 --> 00:21:49.320]   You've got to get in the fingers there.
[00:21:49.320 --> 00:21:50.480]   Wet hands with water applying.
[00:21:50.480 --> 00:21:51.480]   No, I, I, I, this is amazing.
[00:21:51.480 --> 00:21:52.480]   Rub hands, palm the palm.
[00:21:52.480 --> 00:21:53.480]   This is amazing.
[00:21:53.480 --> 00:21:55.080]   Rub back of each hand with Europe Prepper.
[00:21:55.080 --> 00:21:56.080]   That's why.
[00:21:56.080 --> 00:21:57.080]   You're a little bit of other hand with fingers.
[00:21:57.080 --> 00:21:58.760]   You're a, you're, you're worse.
[00:21:58.760 --> 00:21:59.760]   You're worse, Michael.
[00:21:59.760 --> 00:22:01.560]   You're a crypto prepper.
[00:22:01.560 --> 00:22:03.400]   Rub palm to palm with fingers interlaced.
[00:22:03.400 --> 00:22:04.400]   Run.
[00:22:04.400 --> 00:22:07.400]   Actually, the best coronavirus piece I have.
[00:22:07.400 --> 00:22:16.920]   It's in the same notebook in my health notebook is from the prepper's website, theprepared.com.
[00:22:16.920 --> 00:22:23.440]   And it tells you all the things you should do if you want to be a coronavirus prepper.
[00:22:23.440 --> 00:22:26.880]   Oh, I am definitely visiting this after the show.
[00:22:26.880 --> 00:22:27.880]   Yes.
[00:22:27.880 --> 00:22:29.280]   Wait, so may I read one, um, stat from you?
[00:22:29.280 --> 00:22:31.320]   I found this, the story I was reading earlier.
[00:22:31.320 --> 00:22:37.600]   The Spanish flu ultimately killed 50 million people worldwide, including 675,000 people
[00:22:37.600 --> 00:22:39.280]   in the United States.
[00:22:39.280 --> 00:22:40.520]   That is shocking.
[00:22:40.520 --> 00:22:41.880]   And it's not.
[00:22:41.880 --> 00:22:45.600]   And just because this happened in 1918 doesn't mean that it can't happen in 2020.
[00:22:45.600 --> 00:22:46.600]   No, these things can spread.
[00:22:46.600 --> 00:22:48.600]   Especially when we're not testing.
[00:22:48.600 --> 00:22:49.600]   That's what we're saying.
[00:22:49.600 --> 00:22:51.760]   That's the hundred year, uh, fate.
[00:22:51.760 --> 00:22:53.920]   You know, uh, what do you call it?
[00:22:53.920 --> 00:22:54.920]   Pathogen.
[00:22:54.920 --> 00:22:57.480]   Um, we've been waiting.
[00:22:57.480 --> 00:23:00.600]   It's like we're waiting in the Bay Area for the hundred year earthquake.
[00:23:00.600 --> 00:23:02.080]   Uh, we're overdue.
[00:23:02.080 --> 00:23:03.080]   Yeah.
[00:23:03.080 --> 00:23:04.080]   And let me be clear.
[00:23:04.080 --> 00:23:05.560]   I hope that that is not the case.
[00:23:05.560 --> 00:23:12.320]   I hope I'm wrong about this, but I feel like it makes, at least for me, I feel most, um,
[00:23:12.320 --> 00:23:17.200]   at peace knowing that I'm kind of preparing for the worst rather than assuming the best.
[00:23:17.200 --> 00:23:18.200]   Right.
[00:23:18.200 --> 00:23:21.520]   It's funny because we have more medical technology.
[00:23:21.520 --> 00:23:24.720]   But at the same time, maybe it's not like we only have a hundred thousand ventilators
[00:23:24.720 --> 00:23:26.080]   in the United States.
[00:23:26.080 --> 00:23:31.520]   And so if it's spread like wildfire, we would not be able to put enough people on ventilators.
[00:23:31.520 --> 00:23:32.520]   We have antibiotics.
[00:23:32.520 --> 00:23:34.680]   They didn't have those in 1918.
[00:23:34.680 --> 00:23:36.080]   We also have air travel.
[00:23:36.080 --> 00:23:39.400]   You know, one of the reasons it's spread in 1918 is because troops are coming home from
[00:23:39.400 --> 00:23:43.120]   World War one, but nowadays everybody's everywhere.
[00:23:43.120 --> 00:23:46.640]   And that's, uh, I mean, that's, that's why it's spreading so fast.
[00:23:46.640 --> 00:23:50.960]   So, uh, I mean, this is not a show that we're not medical doctors.
[00:23:50.960 --> 00:23:52.960]   And this is not a show that coronavirus really.
[00:23:52.960 --> 00:23:53.960]   Right.
[00:23:53.960 --> 00:23:57.200]   And people should travel, you know, I'm, I'm, I'm, I'm pro open borders and I hope that
[00:23:57.200 --> 00:23:58.200]   people continue to travel.
[00:23:58.200 --> 00:24:01.520]   And, but it's just like, just don't be a dummy, right?
[00:24:01.520 --> 00:24:07.440]   Like know that this is out there and do your best to stay informed because we have no idea
[00:24:07.440 --> 00:24:10.640]   how many cases of this exists in the US right now.
[00:24:10.640 --> 00:24:15.000]   And I think that's what concerns me the most that we're not using the technology.
[00:24:15.000 --> 00:24:19.680]   We're not using, you know, all of the advances that have been made since 1918 aren't really
[00:24:19.680 --> 00:24:22.320]   being put to use in this specific case.
[00:24:22.320 --> 00:24:24.720]   Nobody wants to prepare for disaster.
[00:24:24.720 --> 00:24:26.960]   No, well, wash your damn hands.
[00:24:26.960 --> 00:24:29.600]   Figure flu shots, vaccinate your kids.
[00:24:29.600 --> 00:24:33.120]   Like these are going to stop coronavirus, but these all are going long way.
[00:24:33.120 --> 00:24:35.120]   It's called public health.
[00:24:35.120 --> 00:24:38.240]   Genuinely, one of the things we haven't talked about is the reason why this, this could be
[00:24:38.240 --> 00:24:44.800]   more pervasive is that over the last 20, 25 years, there's been this whole war on vaccinations,
[00:24:44.800 --> 00:24:50.440]   which has left people with lower immunities and with things like being able to mutate
[00:24:50.440 --> 00:24:52.080]   in ways and impact stuff.
[00:24:52.080 --> 00:24:56.600]   And if you think that that doesn't have an impact on people being susceptible to certain
[00:24:56.600 --> 00:24:59.320]   types of infections or not, you're kidding yourself.
[00:24:59.320 --> 00:25:03.520]   Like, to me, this is just another sign is like, vaccinate your kids, get your flu shot
[00:25:03.520 --> 00:25:05.640]   unless you have this sort of condition.
[00:25:05.640 --> 00:25:09.400]   There are some people who do have conditions where they can't have a flu shot, get that.
[00:25:09.400 --> 00:25:10.800]   Get your flu shot if you can.
[00:25:10.800 --> 00:25:12.040]   Wash your damn hands.
[00:25:12.040 --> 00:25:13.320]   Get vaccinated.
[00:25:13.320 --> 00:25:17.920]   And like, if you are sick, don't go into work, you know, and that's one of the big things,
[00:25:17.920 --> 00:25:19.400]   too, whether it's a cold or something else.
[00:25:19.400 --> 00:25:22.400]   If you're coughing and sneezing, like, don't go in.
[00:25:22.400 --> 00:25:27.600]   I asked Dr. Mom, my personal physician via the chat room, although she's never given me
[00:25:27.600 --> 00:25:30.560]   an exam, but I call her my personal physician.
[00:25:30.560 --> 00:25:32.640]   I said, what are the symptoms?
[00:25:32.640 --> 00:25:39.120]   She said, a low grade fever and a feeling of malaise said, that's how I feel every
[00:25:39.120 --> 00:25:40.120]   morning.
[00:25:40.120 --> 00:25:41.120]   What are you talking about?
[00:25:41.120 --> 00:25:44.520]   How am I going to know?
[00:25:44.520 --> 00:25:50.040]   Do not get your coronavirus information from the Plague Inc app.
[00:25:50.040 --> 00:25:53.280]   The folks at Plague Inc said, please, it's just a game.
[00:25:53.280 --> 00:25:55.040]   This is not how it works.
[00:25:55.040 --> 00:25:59.560]   However, the Chinese app stores have removed it.
[00:25:59.560 --> 00:26:04.360]   Apple and Xiaomi have removed Plague Inc, which is a great game about a plague eating
[00:26:04.360 --> 00:26:05.760]   the world.
[00:26:05.760 --> 00:26:11.760]   And your goal, by the way, is to eat the world and then, you know, survive as the plague.
[00:26:11.760 --> 00:26:16.360]   It's a fun game, old game, been around for almost 10 years, I think, but can't get in
[00:26:16.360 --> 00:26:18.160]   China anymore.
[00:26:18.160 --> 00:26:19.760]   Weird, right?
[00:26:19.760 --> 00:26:21.200]   Because that'll stop it.
[00:26:21.200 --> 00:26:23.200]   That'll fix it.
[00:26:23.200 --> 00:26:24.680]   Oh, my God.
[00:26:24.680 --> 00:26:31.080]   This reminds me of that of this, you know, I remember hearing that there was a movie on
[00:26:31.080 --> 00:26:32.080]   Netflix.
[00:26:32.080 --> 00:26:34.760]   I forgot what it was called, but it's about a plague.
[00:26:34.760 --> 00:26:35.760]   It's about contagion.
[00:26:35.760 --> 00:26:38.360]   Yeah, more people started watching it.
[00:26:38.360 --> 00:26:42.920]   I'm looking at my iTunes store and it's got all of the current movies.
[00:26:42.920 --> 00:26:44.680]   And number two movie is contagion.
[00:26:44.680 --> 00:26:49.160]   It came out 2002 or something.
[00:26:49.160 --> 00:26:50.160]   And I watched it.
[00:26:50.160 --> 00:26:51.160]   There's no way that's a good movie, right?
[00:26:51.160 --> 00:26:52.160]   It's got a terrible movie.
[00:26:52.160 --> 00:26:53.160]   I'm assuming.
[00:26:53.160 --> 00:26:57.080]   It's terrible, but you know, we're trying to get information wherever we can.
[00:26:57.080 --> 00:27:01.040]   So we're watching old movies.
[00:27:01.040 --> 00:27:04.720]   And that's the scary part too is sometimes you don't know if you can trust the information
[00:27:04.720 --> 00:27:05.720]   you're getting.
[00:27:05.720 --> 00:27:09.280]   We were talking about China earlier, but things changed so rapidly.
[00:27:09.280 --> 00:27:10.800]   There was a lot of controversy.
[00:27:10.800 --> 00:27:16.160]   If you watched press conference from the White House yesterday about whether the officials
[00:27:16.160 --> 00:27:19.080]   from the CDC or the NIH were being muzzled.
[00:27:19.080 --> 00:27:20.080]   They said they weren't.
[00:27:20.080 --> 00:27:21.080]   So that's good.
[00:27:21.080 --> 00:27:24.000]   But you know, a lot of people are just scrambling for information.
[00:27:24.000 --> 00:27:27.400]   And I think they're trying to get anywhere they can, even if it's from a video game and
[00:27:27.400 --> 00:27:29.400]   a bad movie.
[00:27:29.400 --> 00:27:36.920]   It is, that's a testament to how little we know and how scared we are.
[00:27:36.920 --> 00:27:41.880]   So I do think that, you know, obviously it's hit the financial markets.
[00:27:41.880 --> 00:27:47.560]   I do think it's going to hit the technology markets pretty clearly, right?
[00:27:47.560 --> 00:27:49.880]   I was talking with Sam Ebel-Samad, our car guy.
[00:27:49.880 --> 00:27:54.640]   He said, "There isn't an issue yet in the automotive markets, but there in time might
[00:27:54.640 --> 00:27:59.200]   well be because many cars do have parts made in China."
[00:27:59.200 --> 00:28:04.880]   So this is, we're going to feel it one way or the other over the next few months.
[00:28:04.880 --> 00:28:09.640]   I'm flying to St. Louis on Wednesday for a WWT event.
[00:28:09.640 --> 00:28:13.920]   We're going to actually, if you're a WWT customer, ask your rep because we're going to do a panel
[00:28:13.920 --> 00:28:17.280]   on the future of the cloud on Thursday, but it's only for WWT customers.
[00:28:17.280 --> 00:28:23.280]   We are doing, I should mention, meet up if you're in St. Louis, Tuesday, 730 p.m. at
[00:28:23.280 --> 00:28:28.480]   the appropriately named Trainwreck Cafe.
[00:28:28.480 --> 00:28:30.040]   The Portholt Station.
[00:28:30.040 --> 00:28:33.840]   So come to the Trainwreck Cafe, it's no host, but I'll be there and at least he'll be there
[00:28:33.840 --> 00:28:36.720]   and we're going to have a good time meeting everybody.
[00:28:36.720 --> 00:28:38.360]   So I just thought I'd throw that in.
[00:28:38.360 --> 00:28:39.360]   Let's take a break.
[00:28:39.360 --> 00:28:41.360]   I don't want to talk about viruses anymore.
[00:28:41.360 --> 00:28:42.920]   It's depressing.
[00:28:42.920 --> 00:28:45.200]   I hope you all are staying healthy.
[00:28:45.200 --> 00:28:51.080]   You're washing your damn hands, as Kristina says, and stay well because we can't afford
[00:28:51.080 --> 00:28:54.480]   to lose 2% of our audience.
[00:28:54.480 --> 00:28:56.880]   That would be bad, wouldn't it?
[00:28:56.880 --> 00:28:59.480]   All right, let's talk a little bit about our sponsors.
[00:28:59.480 --> 00:29:00.960]   Zip Recruiter got a great panel.
[00:29:00.960 --> 00:29:03.280]   Kristina Warren is here from Microsoft.
[00:29:03.280 --> 00:29:04.880]   Bill Detweiler from Tech Republic.
[00:29:04.880 --> 00:29:07.480]   Michael Nunez from Forbes.
[00:29:07.480 --> 00:29:09.160]   Zip Recruiter is how we do our hiring.
[00:29:09.160 --> 00:29:14.480]   I'm just thinking of how many of our members of our staff came to us from Zip Recruiter.
[00:29:14.480 --> 00:29:16.800]   I know Ashley did.
[00:29:16.800 --> 00:29:18.280]   So here's the issue.
[00:29:18.280 --> 00:29:22.360]   When you are down a person, it's kind of like hockey.
[00:29:22.360 --> 00:29:26.840]   When you got a guy in the penalty box, the whole team suffers.
[00:29:26.840 --> 00:29:32.760]   And if you're the person doing the hiring, in this case, Lisa, she's working double
[00:29:32.760 --> 00:29:36.360]   time and trying to hire, you need a good partner.
[00:29:36.360 --> 00:29:38.040]   You need Zip Recruiter.
[00:29:38.040 --> 00:29:39.040]   That's what we use.
[00:29:39.040 --> 00:29:42.280]   And boy, has it been a great thing for us.
[00:29:42.280 --> 00:29:48.120]   No more multiple job sites, no more stacks of resume, no more confusing reviews.
[00:29:48.120 --> 00:29:52.800]   Hiring can be easy and you just go to zipprecruiter.com/twit to do it immediately.
[00:29:52.800 --> 00:29:56.800]   When you post on zipprecruiter.com/twit, your job goes to 100 of the world's best.
[00:29:56.800 --> 00:29:57.800]   The world's best job sites.
[00:29:57.800 --> 00:30:03.360]   But it doesn't stop there because Zip Recruiter has millions of current resumes on file.
[00:30:03.360 --> 00:30:05.280]   People go to Zip Recruiter looking for work.
[00:30:05.280 --> 00:30:09.480]   And what they'll do is they'll use their powerful matching technology to look at those
[00:30:09.480 --> 00:30:13.680]   resumes, look at your job, and then they will go out and actually invite people who qualify
[00:30:13.680 --> 00:30:19.520]   for your job, which means you're going to get responses, in most cases, four out of five
[00:30:19.520 --> 00:30:23.480]   employers get responses, quality candidates within the first day.
[00:30:23.480 --> 00:30:26.120]   And that's been our experience.
[00:30:26.120 --> 00:30:29.560]   And our bookkeeper quit gave us two weeks notice.
[00:30:29.560 --> 00:30:32.720]   I remember vividly at breakfast, Lisa says, "Oh, no.
[00:30:32.720 --> 00:30:36.360]   I'm going to have to start doing the books again."
[00:30:36.360 --> 00:30:37.640]   And I said, "Zipprecruiter, Zipprecruiter."
[00:30:37.640 --> 00:30:39.880]   She posted it at the breakfast by lunch.
[00:30:39.880 --> 00:30:40.880]   She was great.
[00:30:40.880 --> 00:30:42.120]   She was looking at her computer.
[00:30:42.120 --> 00:30:43.880]   "Oh, oh, this person's great.
[00:30:43.880 --> 00:30:45.720]   Oh, oh, here's another great.
[00:30:45.720 --> 00:30:46.920]   It's amazing."
[00:30:46.920 --> 00:30:51.080]   You can even add screening questions to your job listings so you can filter candidates.
[00:30:51.080 --> 00:30:54.880]   And all of the resumes, all the applicants, don't come to your phone or your inbox.
[00:30:54.880 --> 00:30:56.640]   They go into the Zipprecruiter interface.
[00:30:56.640 --> 00:30:59.600]   They reformat the resumes so you can scan them quickly.
[00:30:59.600 --> 00:31:03.040]   They highlight the best candidates so you don't miss a good candidate.
[00:31:03.040 --> 00:31:04.480]   So you're not overwhelmed.
[00:31:04.480 --> 00:31:09.880]   It makes it very easy for you to look at your applicants and pick the right one fast.
[00:31:09.880 --> 00:31:11.000]   I want you to try this.
[00:31:11.000 --> 00:31:12.000]   It's really the best.
[00:31:12.000 --> 00:31:13.680]   It's been a lifesaver for us.
[00:31:13.680 --> 00:31:19.880]   Zipprecruiter.com/twitzipprecruiter.com/twitzipprecruiter.
[00:31:19.880 --> 00:31:23.000]   The smartest way to hire.
[00:31:23.000 --> 00:31:26.480]   So you can find the best candidates for you to hire.
[00:31:26.480 --> 00:31:29.280]   And you can find them at Zipprecruiter.com/twitzipprecruiter.
[00:31:29.280 --> 00:31:30.280]   This is from the Atlantic.
[00:31:30.280 --> 00:31:31.280]   Your AirPods will die soon.
[00:31:31.280 --> 00:31:36.240]   Actually, this is last year, but I just wanted to reiterate this as we get a new series of
[00:31:36.240 --> 00:31:38.240]   AirPods, AirPods Pro.
[00:31:38.240 --> 00:31:44.320]   This is so depressing because they don't have any way to make these last.
[00:31:44.320 --> 00:31:50.360]   So if you bought AirPods about two years ago, they've been out since 2016.
[00:31:50.360 --> 00:31:53.200]   Yeah, end of December 2016.
[00:31:53.200 --> 00:31:55.280]   If you bought them a couple of years ago, they're going to die.
[00:31:55.280 --> 00:31:56.280]   What do you do, Christina?
[00:31:56.280 --> 00:31:58.720]   You just buy another pair of throw them in the trash?
[00:31:58.720 --> 00:31:59.720]   Yeah.
[00:31:59.720 --> 00:32:00.720]   Okay.
[00:32:00.720 --> 00:32:01.720]   So I didn't throw them in the trash.
[00:32:01.720 --> 00:32:03.440]   How many pairs do you already own?
[00:32:03.440 --> 00:32:04.440]   I have four.
[00:32:04.440 --> 00:32:05.440]   This is fair.
[00:32:05.440 --> 00:32:06.440]   Yeah.
[00:32:06.440 --> 00:32:07.440]   I was going to say.
[00:32:07.440 --> 00:32:08.440]   Let's say he waste.
[00:32:08.440 --> 00:32:09.440]   He waste.
[00:32:09.440 --> 00:32:10.440]   Don't throw them in the trash.
[00:32:10.440 --> 00:32:14.800]   I gave my OG pair to my husband, and I don't know how good the battery is, but their
[00:32:14.800 --> 00:32:15.800]   husband?
[00:32:15.800 --> 00:32:18.320]   No, I gave my OG pair of AirPods.
[00:32:18.320 --> 00:32:20.960]   The ones I got in December of 2016.
[00:32:20.960 --> 00:32:23.240]   Your husband is not original gangster?
[00:32:23.240 --> 00:32:25.680]   He is not, unfortunately, for him.
[00:32:25.680 --> 00:32:31.760]   So I gave him my original pair, and I bought the AirPods to the ones that had the wireless
[00:32:31.760 --> 00:32:33.320]   charger.
[00:32:33.320 --> 00:32:38.440]   Those were then immediately upgraded, or I guess I got the AirPods Pro as soon as those
[00:32:38.440 --> 00:32:39.440]   went up for release.
[00:32:39.440 --> 00:32:42.240]   So I only had that second pair for a few months.
[00:32:42.240 --> 00:32:45.280]   So they're my backups, and then I used the AirPods Pro's.
[00:32:45.280 --> 00:32:49.720]   The original pair, the battery life is probably not great, but I mean, Grant didn't pay for
[00:32:49.720 --> 00:32:51.360]   them so he can't complain.
[00:32:51.360 --> 00:32:59.000]   So whenever they cease working, I guess that's when you know, you recycle or whatever.
[00:32:59.000 --> 00:33:03.920]   They're so small that I guess, I mean, couldn't they make it that you could maybe not yourself
[00:33:03.920 --> 00:33:04.920]   bring to the Apple Store.
[00:33:04.920 --> 00:33:07.640]   They pry it open with little tweezers and put in a new battery.
[00:33:07.640 --> 00:33:08.640]   Couldn't they do that?
[00:33:08.640 --> 00:33:09.640]   I don't know.
[00:33:09.640 --> 00:33:13.160]   I mean, my thought would be that they could do a thing where they send them off to wherever
[00:33:13.160 --> 00:33:17.400]   they send things off and they could do a repair that way similar to, I guess, what they used
[00:33:17.400 --> 00:33:19.360]   to do with, you know, iPods.
[00:33:19.360 --> 00:33:24.360]   So you could bring them in, pay a fee exchange for a new pair that has like,
[00:33:24.360 --> 00:33:26.600]   then Liam could take them apart and recycle them.
[00:33:26.600 --> 00:33:27.840]   Right, exactly.
[00:33:27.840 --> 00:33:31.040]   They're robot or you could make them out of cornstarch.
[00:33:31.040 --> 00:33:32.040]   Hmm.
[00:33:32.040 --> 00:33:40.040]   The reason I bring this is shame though, that they do, they can't do that with them.
[00:33:40.040 --> 00:33:44.440]   They do it with hearing aids, they do it with other devices, but it's just, you know, a
[00:33:44.440 --> 00:33:48.040]   shame in our man, modern manufacturing process.
[00:33:48.040 --> 00:33:49.600]   It's just cheaper to not do that.
[00:33:49.600 --> 00:33:50.840]   I mean, let's, let's be honest.
[00:33:50.840 --> 00:33:52.440]   I mean, yes, that's good.
[00:33:52.440 --> 00:33:54.000]   The aesthetics is good.
[00:33:54.000 --> 00:33:58.120]   They have, you know, sealed devices have a higher IP rating.
[00:33:58.120 --> 00:34:01.840]   So there have less chance of getting dust, water, all kinds of gunk in them, things
[00:34:01.840 --> 00:34:02.840]   like that.
[00:34:02.840 --> 00:34:03.840]   But it's just cheaper.
[00:34:03.840 --> 00:34:08.360]   And when you're manufacturing millions of these small devices, if you can save a cent,
[00:34:08.360 --> 00:34:12.720]   two cents, half a cent, you're going to do that.
[00:34:12.720 --> 00:34:18.120]   So now I would love to see us be able to replace the batteries in them and use them
[00:34:18.120 --> 00:34:22.720]   longer or at the very least, like you said, Leo, at least ship them back and have someone
[00:34:22.720 --> 00:34:25.640]   else give them a second life.
[00:34:25.640 --> 00:34:31.760]   Well the reason I bring this up, tech radar got a leaked EU document.
[00:34:31.760 --> 00:34:40.400]   Over the EU just passed regulation suggesting that all chargers should be uniform to eliminate
[00:34:40.400 --> 00:34:41.400]   waste.
[00:34:41.400 --> 00:34:47.760]   Apparently an elite EU doc suggests legislation that would force all new phones to have
[00:34:47.760 --> 00:34:48.760]   removable batteries.
[00:34:48.760 --> 00:34:50.640]   Yeah, good luck with that.
[00:34:50.640 --> 00:34:51.640]   I'm behind it.
[00:34:51.640 --> 00:34:53.200]   That's a great thing.
[00:34:53.200 --> 00:34:55.200]   I mean, I'm not opposed.
[00:34:55.200 --> 00:34:57.800]   I just say good luck with that.
[00:34:57.800 --> 00:34:59.840]   You know, I mean, because it's absolutely hard.
[00:34:59.840 --> 00:35:03.920]   Can't they say you can't sell if they could say you can't sell the phone in the U.F.
[00:35:03.920 --> 00:35:05.560]   You don't have a replaceable battery.
[00:35:05.560 --> 00:35:06.560]   Right.
[00:35:06.560 --> 00:35:09.920]   So then every single phone that is made today, literally every single phone is not able
[00:35:09.920 --> 00:35:13.440]   to be sold like they might their constituents might get upset.
[00:35:13.440 --> 00:35:14.440]   Is that what you're saying?
[00:35:14.440 --> 00:35:15.440]   That's what I'm saying.
[00:35:15.440 --> 00:35:19.280]   What I'm saying is that the lobbying groups and the other things that trade people might
[00:35:19.280 --> 00:35:22.480]   are I'm saying this isn't going to happen, Leo.
[00:35:22.480 --> 00:35:26.160]   I'm saying that I can't think of one phone that's made today by a major manufacturer that
[00:35:26.160 --> 00:35:28.960]   has a replaceable battery.
[00:35:28.960 --> 00:35:34.720]   But don't you think consumers would like this and don't you think it's better for the environment?
[00:35:34.720 --> 00:35:36.680]   This should be the law.
[00:35:36.680 --> 00:35:37.680]   No, why not?
[00:35:37.680 --> 00:35:39.600]   I don't think consumers care.
[00:35:39.600 --> 00:35:43.640]   No, I think consumers would rather have a bigger battery that lasts longer than when
[00:35:43.640 --> 00:35:45.880]   they have to pull out and replace themselves.
[00:35:45.880 --> 00:35:50.440]   I used to when I buy the old days of the Samsung Galaxy's, I would buy the phone in two
[00:35:50.440 --> 00:35:52.160]   batteries.
[00:35:52.160 --> 00:35:56.800]   And then if I was traveling or whatever, I didn't have to have a mophie case or a charger.
[00:35:56.800 --> 00:36:00.080]   I just take a have swap out the battery.
[00:36:00.080 --> 00:36:01.400]   I think that's a great feature.
[00:36:01.400 --> 00:36:02.800]   I think consumers would like that.
[00:36:02.800 --> 00:36:06.800]   By the way, those phones weren't noticeably thicker or heavier.
[00:36:06.800 --> 00:36:07.800]   It wasn't a decent.
[00:36:07.800 --> 00:36:09.640]   Yeah, but they weren't waterproof or they weren't dust.
[00:36:09.640 --> 00:36:10.640]   It weren't they more.
[00:36:10.640 --> 00:36:11.640]   No, that's true.
[00:36:11.640 --> 00:36:14.200]   But which is more likely you're going to drop your phone in the toilet or you're going to
[00:36:14.200 --> 00:36:15.200]   run out of juice.
[00:36:15.200 --> 00:36:18.200]   Well, I like having.
[00:36:18.200 --> 00:36:25.040]   But also the way they change batteries is part of the reason that they're sealed is
[00:36:25.040 --> 00:36:28.600]   that you can put them in funky shapes and you can get more battery life.
[00:36:28.600 --> 00:36:31.800]   I think that if the alternative is, okay, I have this battery that's replaceable, granted,
[00:36:31.800 --> 00:36:33.280]   but it's not going to last as long or a half.
[00:36:33.280 --> 00:36:34.280]   It's not just funky shapes.
[00:36:34.280 --> 00:36:35.280]   You don't have to package them.
[00:36:35.280 --> 00:36:38.200]   If you're going to package them so that somebody can hold it, that's different than
[00:36:38.200 --> 00:36:41.440]   if you're just going to build it into a fluid, into a phone.
[00:36:41.440 --> 00:36:42.440]   Right.
[00:36:42.440 --> 00:36:48.680]   Well, then it's going to depend on what batteries to you know, I've since started going to Apple
[00:36:48.680 --> 00:36:54.440]   about every year, year and a half to get my iPhone battery replaced because it does prolong
[00:36:54.440 --> 00:36:55.440]   the life of my phone.
[00:36:55.440 --> 00:37:00.760]   And typically I don't need a new one, but it costs like, I don't know, 120 bucks, I think.
[00:37:00.760 --> 00:37:04.360]   And so I just feel like that process should be cheaper.
[00:37:04.360 --> 00:37:05.360]   That's worth it.
[00:37:05.360 --> 00:37:06.360]   I think they've actually dropped it.
[00:37:06.360 --> 00:37:08.680]   I think it's under 100 bucks now, depending on the iPhone.
[00:37:08.680 --> 00:37:10.160]   Yeah, it's been a while.
[00:37:10.160 --> 00:37:12.000]   It's like getting a refreshed phone, new phone.
[00:37:12.000 --> 00:37:13.000]   I think that's great.
[00:37:13.000 --> 00:37:18.280]   I think that's the other problem is that we in the tech reportage business, we're getting
[00:37:18.280 --> 00:37:23.400]   new phones every six months, every two months, every so we don't ever experience this.
[00:37:23.400 --> 00:37:25.920]   Normal people don't want to buy a new phone every couple of years.
[00:37:25.920 --> 00:37:27.920]   They want to keep it longer.
[00:37:27.920 --> 00:37:30.200]   Well, I think Apple addressed some of this, right?
[00:37:30.200 --> 00:37:32.720]   I mean, with their trading programs.
[00:37:32.720 --> 00:37:38.200]   And I think like you were talking about Leo with consumers, I don't not sure that my
[00:37:38.200 --> 00:37:44.880]   daughter and her age core cohort, you know, what they're going to want when they start
[00:37:44.880 --> 00:37:46.280]   buying their own phones.
[00:37:46.280 --> 00:37:47.280]   Thank goodness.
[00:37:47.280 --> 00:37:48.280]   When dad's not buying it.
[00:37:48.280 --> 00:37:52.720]   By the way, can I just say something, Bill, to warn you, my daughter is 28, my son's
[00:37:52.720 --> 00:37:54.480]   26, I still buy their phones.
[00:37:54.480 --> 00:37:56.920]   In fact, I still pay for their cell service.
[00:37:56.920 --> 00:37:57.920]   Oh, that's okay.
[00:37:57.920 --> 00:38:01.080]   I mean, I was on my father's plan until last year.
[00:38:01.080 --> 00:38:03.080]   So I'm going to say anything.
[00:38:03.080 --> 00:38:04.680]   I'm on a family plate.
[00:38:04.680 --> 00:38:08.080]   Yeah, I know gray in the beard and I'm still on my dad's plan.
[00:38:08.080 --> 00:38:09.080]   That's nice.
[00:38:09.080 --> 00:38:10.080]   It's depressing.
[00:38:10.080 --> 00:38:12.760]   Oh my God, I'm going to be seriously forever.
[00:38:12.760 --> 00:38:15.640]   You wonder what consumers are really going to want.
[00:38:15.640 --> 00:38:20.680]   So are they going to want a phone that maybe has a lower ecological imprint, you know,
[00:38:20.680 --> 00:38:25.080]   that is more eco-friendly, has some of these features like a replaceable battery that
[00:38:25.080 --> 00:38:26.840]   they, a battery that they see is more eco-friendly.
[00:38:26.840 --> 00:38:30.600]   I just don't know me right now for the people that are buying phones.
[00:38:30.600 --> 00:38:31.600]   They like the shapes.
[00:38:31.600 --> 00:38:32.600]   They like the sizes.
[00:38:32.600 --> 00:38:36.080]   They, you know, if they can take it into Apple and get a refreshed battery for 50 bucks
[00:38:36.080 --> 00:38:38.000]   every couple of years, that's great.
[00:38:38.000 --> 00:38:39.680]   So I don't know.
[00:38:39.680 --> 00:38:40.680]   But I am with you, Leo.
[00:38:40.680 --> 00:38:45.120]   I miss the days when you could pop out a battery and put in a new battery.
[00:38:45.120 --> 00:38:46.120]   Yeah.
[00:38:46.120 --> 00:38:47.400]   You know, I'm going to take it on tech or public.
[00:38:47.400 --> 00:38:50.120]   I've been taking these things apart for a long time.
[00:38:50.120 --> 00:38:55.680]   You know, we do a series on tech or public and our sibling site, CNET, Cracking Open.
[00:38:55.680 --> 00:39:01.280]   And you know, it's from my perspective, I also, you know, in a previous life as an engineer.
[00:39:01.280 --> 00:39:06.800]   So, you know, it is possible to create thin devices.
[00:39:06.800 --> 00:39:07.800]   Are they going to be as thin?
[00:39:07.800 --> 00:39:08.800]   No.
[00:39:08.800 --> 00:39:09.960]   Are they going to be maybe as sleek looking?
[00:39:09.960 --> 00:39:10.960]   No.
[00:39:10.960 --> 00:39:12.360]   But it is possible to do it.
[00:39:12.360 --> 00:39:15.280]   It's just not as cost-effective.
[00:39:15.280 --> 00:39:22.480]   I did not know about Cracking Open.
[00:39:22.480 --> 00:39:25.960]   I am going to become a regular visitor.
[00:39:25.960 --> 00:39:28.120]   Techrepublic.com/crackingopen.
[00:39:28.120 --> 00:39:29.120]   This is great.
[00:39:29.120 --> 00:39:31.120]   You cracked open a Roomba and you do this.
[00:39:31.120 --> 00:39:34.120]   You know, you're going to take it on any gas.
[00:39:34.120 --> 00:39:35.120]   A Polaroid snap.
[00:39:35.120 --> 00:39:36.120]   Yeah.
[00:39:36.120 --> 00:39:39.120]   We took apart some old tech, some vintage tech, some new tech.
[00:39:39.120 --> 00:39:41.120]   And we usually, so I can usually get things back together.
[00:39:41.120 --> 00:39:42.120]   Oh.
[00:39:42.120 --> 00:39:44.760]   That's one of the things that we try to do is to tear it down or we put it back together,
[00:39:44.760 --> 00:39:45.760]   right?
[00:39:45.760 --> 00:39:49.040]   I'm not one of those ones that just puts it in a blender and shreds it or takes it apart
[00:39:49.040 --> 00:39:50.040]   and wants to see if it's working.
[00:39:50.040 --> 00:39:52.760]   I have broken a few things, but, you know, I'm all with you.
[00:39:52.760 --> 00:39:58.720]   I mean, I wish devices had replaceable batteries, especially the AirPods.
[00:39:58.720 --> 00:40:00.680]   You know, I love my AirPods.
[00:40:00.680 --> 00:40:05.080]   My daughter loves her AirPods, but I hate the idea that you paid a couple hundred bucks.
[00:40:05.080 --> 00:40:06.080]   I know.
[00:40:06.080 --> 00:40:08.440]   And then in two years, they're just going to go into a landfill.
[00:40:08.440 --> 00:40:09.440]   That's what I hate.
[00:40:09.440 --> 00:40:12.440]   And I'll be e-wasted or something, but still.
[00:40:12.440 --> 00:40:15.400]   I hate plastic toothbrush.
[00:40:15.400 --> 00:40:21.360]   You and everybody else has ever bought lives in a landfill now completely intact.
[00:40:21.360 --> 00:40:23.320]   Archaeologists in a thousand years will dig them up.
[00:40:23.320 --> 00:40:24.840]   So what were they doing with these?
[00:40:24.840 --> 00:40:26.960]   Why are there so many of them?
[00:40:26.960 --> 00:40:30.480]   Wasn't it the old George Carlin joke?
[00:40:30.480 --> 00:40:34.080]   Maybe that the only reason humans are around is so that the earth can have plastic?
[00:40:34.080 --> 00:40:36.120]   I mean, that's what it wanted all along.
[00:40:36.120 --> 00:40:38.200]   It's just us as the plastic producers.
[00:40:38.200 --> 00:40:39.440]   Oh, that's interesting.
[00:40:39.440 --> 00:40:40.440]   There's a thought.
[00:40:40.440 --> 00:40:41.440]   I like that.
[00:40:41.440 --> 00:40:43.480]   I wonder if somebody is going to come along.
[00:40:43.480 --> 00:40:46.880]   Nobody's tried this yet and make an eco-friendly smartphone.
[00:40:46.880 --> 00:40:52.520]   There's also issues with the metals in the phone, the battery and so forth.
[00:40:52.520 --> 00:40:57.080]   It'd be nice to get, you know, instead of a blood phone to get a nice phone.
[00:40:57.080 --> 00:40:59.600]   I wonder if somebody would do that.
[00:40:59.600 --> 00:41:04.800]   You think they'd make money or, Christina, you're a, you don't believe in people, do you?
[00:41:04.800 --> 00:41:06.440]   I believe in people.
[00:41:06.440 --> 00:41:08.440]   I don't believe in people.
[00:41:08.440 --> 00:41:10.440]   I don't believe in people.
[00:41:10.440 --> 00:41:14.800]   You think people would just be like, I don't care.
[00:41:14.800 --> 00:41:15.800]   I want the thinnest phone.
[00:41:15.800 --> 00:41:16.800]   I don't care.
[00:41:16.800 --> 00:41:17.800]   Yes.
[00:41:17.800 --> 00:41:18.800]   Yeah.
[00:41:18.800 --> 00:41:19.800]   Yeah, that absolutely.
[00:41:19.800 --> 00:41:24.000]   No, I mean, I think that, okay, the amount of money that would cost to like have like a
[00:41:24.000 --> 00:41:29.400]   sustainable type of device, there would be some people who would do it, sure, and it could
[00:41:29.400 --> 00:41:31.520]   maybe become a status symbol of sorts.
[00:41:31.520 --> 00:41:34.520]   But the average person, no, come on.
[00:41:34.520 --> 00:41:36.200]   A green phone, man.
[00:41:36.200 --> 00:41:37.200]   Come on.
[00:41:37.200 --> 00:41:41.360]   I mean, it's nice in theory, I guess, and it's not that improbable.
[00:41:41.360 --> 00:41:48.320]   You know, I know that in the fashion world, right now, one of the big trends is like eco
[00:41:48.320 --> 00:41:53.760]   consciousness and climate change, you know, like wearing climate change and so fashion
[00:41:53.760 --> 00:41:55.040]   magazines have embraced that.
[00:41:55.040 --> 00:41:59.760]   A lot of fashion brands have embraced that Nike, I believe, just released their Olympic
[00:41:59.760 --> 00:42:00.760]   US Olympic.
[00:42:00.760 --> 00:42:01.760]   Yeah.
[00:42:01.760 --> 00:42:04.920]   They have the other recyclable shoes.
[00:42:04.920 --> 00:42:06.240]   Here's where that falls apart.
[00:42:06.240 --> 00:42:10.800]   If you're asked, if you're told, okay, this is now going to cost twice as much and be
[00:42:10.800 --> 00:42:17.040]   less powerful and you're going to still have to get a new one every couple of years, maybe
[00:42:17.040 --> 00:42:20.040]   even more frequently because it is less powerful.
[00:42:20.040 --> 00:42:25.080]   I think that the number of people who would actively spend more on less just because of
[00:42:25.080 --> 00:42:28.840]   the eco argument, yeah, Leo is right.
[00:42:28.840 --> 00:42:30.200]   I don't have faith in people there.
[00:42:30.200 --> 00:42:31.200]   I don't.
[00:42:31.200 --> 00:42:34.520]   I think that you could maybe have a small niche for the fashion thing, but Leo is that
[00:42:34.520 --> 00:42:36.520]   probably, no, I don't.
[00:42:36.520 --> 00:42:40.240]   It has to be a statement, you know, it has to turn into a statement piece because I think
[00:42:40.240 --> 00:42:43.160]   like people, people are easily persuadable too.
[00:42:43.160 --> 00:42:47.920]   And so if you have the right people holding this, this, you know, this hypothetical device,
[00:42:47.920 --> 00:42:52.880]   I guess, the right people, they'll do it for the ad, right?
[00:42:52.880 --> 00:42:56.680]   But then you're just going to see them with their iPhone 11 pro max or iPhone, you know,
[00:42:56.680 --> 00:43:01.760]   15 or whatever, like on Instagram, like the next day, like, okay, they'll, they'll do
[00:43:01.760 --> 00:43:03.760]   the runway show is, but you know what I mean?
[00:43:03.760 --> 00:43:04.760]   They're not going to.
[00:43:04.760 --> 00:43:05.760]   Yeah.
[00:43:05.760 --> 00:43:08.160]   Actually use a hand crank phone or whatever.
[00:43:08.160 --> 00:43:09.160]   Yeah.
[00:43:09.160 --> 00:43:10.760]   No, I mean, I hear you.
[00:43:10.760 --> 00:43:15.720]   And the truth is, you know, it's, it's improbable that this will happen because the device relies
[00:43:15.720 --> 00:43:22.160]   on so many rare metals and so, you know, it just by virtue of existing cell phones are
[00:43:22.160 --> 00:43:25.960]   kind of, you know, they just have a negative impact on the environment.
[00:43:25.960 --> 00:43:27.640]   I don't know how you solve that.
[00:43:27.640 --> 00:43:31.280]   They're plastic and metal and, and, and rare metals.
[00:43:31.280 --> 00:43:32.280]   I wonder.
[00:43:32.280 --> 00:43:33.280]   Battery.
[00:43:33.280 --> 00:43:38.800]   Though, I mean, it'd be great sci fi point to have people who scavenge the landfill looking
[00:43:38.800 --> 00:43:43.680]   for these now long lost materials to recover them so we can make more phones.
[00:43:43.680 --> 00:43:44.680]   Right?
[00:43:44.680 --> 00:43:47.040]   At some point, we're going to need to do that.
[00:43:47.040 --> 00:43:48.040]   Yeah.
[00:43:48.040 --> 00:43:49.840]   It's like, it sounds like Wally or something.
[00:43:49.840 --> 00:43:50.840]   Yeah.
[00:43:50.840 --> 00:43:51.840]   It is Wally.
[00:43:51.840 --> 00:43:52.840]   I already wrote it.
[00:43:52.840 --> 00:43:57.440]   Well, and all you have some other kind of, you have some other kind of global event, not
[00:43:57.440 --> 00:44:02.120]   to go back to what we were talking about earlier, that starts to put a cramp on global
[00:44:02.120 --> 00:44:03.120]   trade.
[00:44:03.120 --> 00:44:04.120]   Right?
[00:44:04.120 --> 00:44:07.960]   I mean, these, you know, not all of these minerals exist in areas where these phones
[00:44:07.960 --> 00:44:08.960]   are manufactured.
[00:44:08.960 --> 00:44:11.440]   You know, you, you mentioned it with blood phones, Leo.
[00:44:11.440 --> 00:44:16.640]   You know, these minerals have to come from places that are susceptible to disruptions,
[00:44:16.640 --> 00:44:23.040]   whether they're pandemics or, you know, political or, you know, just other events that are unforeseen.
[00:44:23.040 --> 00:44:28.240]   So, you know, there's a lot that, you know, goes into making these kind of phones that
[00:44:28.240 --> 00:44:30.520]   are, you know, most people don't kind of see, right?
[00:44:30.520 --> 00:44:31.600]   And can be disruptive.
[00:44:31.600 --> 00:44:36.400]   So you know, maybe, maybe like you said, Leo, maybe it's the science, you fiction story
[00:44:36.400 --> 00:44:40.800]   where you'll eventually have to mind the, you know, mind the garbage dumps to recycle
[00:44:40.800 --> 00:44:41.800]   these phones.
[00:44:41.800 --> 00:44:43.440]   And hopefully that's why I say e-waste the devices, right?
[00:44:43.440 --> 00:44:49.120]   E-waste your, you know, your air pods and hopefully every bit of gold, every bit of
[00:44:49.120 --> 00:44:53.480]   neodymium, every bit of the precious metals, heavy metals that are in these things, you
[00:44:53.480 --> 00:44:57.360]   know, it's stuff that doesn't have to be dug back up out of the ground.
[00:44:57.360 --> 00:45:02.200]   That's actually, maybe future generations will thank us for so thoughtfully taking all
[00:45:02.200 --> 00:45:04.560]   our phones and putting them in a landfill.
[00:45:04.560 --> 00:45:05.560]   Yeah.
[00:45:05.560 --> 00:45:08.040]   Wow, they were really thinking ahead.
[00:45:08.040 --> 00:45:12.440]   They knew we'd want a single place to go to find all that box site.
[00:45:12.440 --> 00:45:13.440]   That's nice.
[00:45:13.440 --> 00:45:14.440]   Thank you.
[00:45:14.440 --> 00:45:15.440]   Here's Wally.
[00:45:15.440 --> 00:45:23.880]   Oh, by the way, just data point.
[00:45:23.880 --> 00:45:24.960]   Don't know if it means anything.
[00:45:24.960 --> 00:45:31.240]   Apple now has $207 billion in cash on hand.
[00:45:31.240 --> 00:45:33.280]   So they could do something.
[00:45:33.280 --> 00:45:37.880]   I don't know what could you do with $206 billion, $207 billion.
[00:45:37.880 --> 00:45:38.880]   Actually I am sorry.
[00:45:38.880 --> 00:45:44.120]   It's $207.06 billion.
[00:45:44.120 --> 00:45:46.120]   I left off $600,000.
[00:45:46.120 --> 00:45:47.120]   Okay.
[00:45:47.120 --> 00:45:53.280]   Let's take a little break and talk more with our great panel bill debt Weiler from Tech
[00:45:53.280 --> 00:45:54.280]   Republic.
[00:45:54.280 --> 00:45:56.960]   Great to have you for your first time and you're fantastic.
[00:45:56.960 --> 00:45:58.120]   You're coming back.
[00:45:58.120 --> 00:46:00.000]   I just it's great to have you on.
[00:46:00.000 --> 00:46:04.200]   Is that the BB-8 you took apart sitting over your right shoulder there?
[00:46:04.200 --> 00:46:08.840]   Actually no, that is one of the BB-8s that we got to take apart.
[00:46:08.840 --> 00:46:13.720]   But unfortunately, the BB-8 that we took apart did not survive.
[00:46:13.720 --> 00:46:14.720]   You killed it.
[00:46:14.720 --> 00:46:21.800]   We killed the BB-8, the brave little droid sacrificed itself for one of our cracking
[00:46:21.800 --> 00:46:23.520]   opens.
[00:46:23.520 --> 00:46:28.280]   Unfortunately, the only way to take those apart is with a Dremel.
[00:46:28.280 --> 00:46:31.800]   So yeah, usually that's spelled the last one.
[00:46:31.800 --> 00:46:32.800]   You got the last one.
[00:46:32.800 --> 00:46:33.800]   That's kind of the yes.
[00:46:33.800 --> 00:46:35.000]   It's hard to unravel.
[00:46:35.000 --> 00:46:36.000]   Yeah.
[00:46:36.000 --> 00:46:38.360]   Also, great to have Michael Nunez back.
[00:46:38.360 --> 00:46:39.680]   He is now at Forbes.
[00:46:39.680 --> 00:46:41.880]   He is associate editor there.
[00:46:41.880 --> 00:46:45.360]   And yes, for those of you just joining us, this is the point-a-list version of Michael
[00:46:45.360 --> 00:46:46.360]   Nunez.
[00:46:46.360 --> 00:46:49.360]   It's lovely.
[00:46:49.360 --> 00:46:50.360]   It's lovely.
[00:46:50.360 --> 00:46:51.360]   I think it's great.
[00:46:51.360 --> 00:46:55.160]   For some reason, everything looks a little blurry except for your New York Yankees cap.
[00:46:55.160 --> 00:46:56.160]   Must be a major.
[00:46:56.160 --> 00:46:57.160]   That's why I wore it.
[00:46:57.160 --> 00:47:00.760]   It's like the one distinguishable thing that I could get to work on.
[00:47:00.760 --> 00:47:04.160]   It's Steinbrenner paid to upgrade that part of the screen.
[00:47:04.160 --> 00:47:08.080]   Christina Warren is also here from Microsoft.
[00:47:08.080 --> 00:47:09.360]   She does developer relations.
[00:47:09.360 --> 00:47:10.880]   She'd be in Zurich right now.
[00:47:10.880 --> 00:47:16.680]   So we thank the coronavirus for letting us have you for this show today.
[00:47:16.680 --> 00:47:18.640]   Our show brought to you by privacy.
[00:47:18.640 --> 00:47:19.640]   It is a brilliant idea.
[00:47:19.640 --> 00:47:21.320]   In fact, a lot of credit card companies used to.
[00:47:21.320 --> 00:47:24.960]   They stopped doing it for some reason, offer one time only numbers.
[00:47:24.960 --> 00:47:27.320]   Privacy takes it one step further.
[00:47:27.320 --> 00:47:34.600]   With privacy.com, I can create a credit card that is either for one use only, stops working
[00:47:34.600 --> 00:47:37.880]   after one use, or is locked into the merchant.
[00:47:37.880 --> 00:47:42.840]   So for instance, I have an Amazon card and only Amazon can use that card.
[00:47:42.840 --> 00:47:44.000]   I love this.
[00:47:44.000 --> 00:47:50.080]   Whenever I buy anything online these days, I use privacy.com because I know it's impossible
[00:47:50.080 --> 00:47:54.360]   for somebody to get my credit card number and use it somewhere else.
[00:47:54.360 --> 00:47:55.360]   They just can't.
[00:47:55.360 --> 00:47:57.160]   You can also set a limit on it.
[00:47:57.160 --> 00:47:59.680]   So privacy saves me money by eliminating fraud.
[00:47:59.680 --> 00:48:01.360]   It lets me take control of my finances.
[00:48:01.360 --> 00:48:03.960]   I can set a spending limit.
[00:48:03.960 --> 00:48:07.840]   If you do subscriptions or recurring payments, how many times have you forgotten?
[00:48:07.840 --> 00:48:11.040]   Or such a pain to cancel, you just let it go.
[00:48:11.040 --> 00:48:13.320]   With privacy, pause the card.
[00:48:13.320 --> 00:48:14.320]   That's it.
[00:48:14.320 --> 00:48:15.320]   They can't get any more money out of you.
[00:48:15.320 --> 00:48:17.080]   Just pause the card.
[00:48:17.080 --> 00:48:20.080]   They have a new card sharing feature, which is really great.
[00:48:20.080 --> 00:48:24.600]   If you have a family or you work on a team, you can easily and safely send someone a privacy
[00:48:24.600 --> 00:48:28.360]   card from the dashboard in just a few clicks.
[00:48:28.360 --> 00:48:31.480]   Completely securely, no copying, no pasting, no screenshots.
[00:48:31.480 --> 00:48:34.400]   They don't even need a privacy account to use the shared card.
[00:48:34.400 --> 00:48:36.680]   You just click the share button when you view a card.
[00:48:36.680 --> 00:48:38.480]   Enter an email address to share it to.
[00:48:38.480 --> 00:48:39.480]   Privacy does the rest.
[00:48:39.480 --> 00:48:41.840]   PCI DSS compliant.
[00:48:41.840 --> 00:48:43.840]   Same security standards as your bank.
[00:48:43.840 --> 00:48:45.640]   It's secured with strong encryption.
[00:48:45.640 --> 00:48:50.840]   Your information at privacy is encrypted and then they use split key encryption.
[00:48:50.840 --> 00:48:53.160]   So different employees hold different parts of the key.
[00:48:53.160 --> 00:48:56.440]   So no one employee can unlock it.
[00:48:56.440 --> 00:48:59.360]   All that server information is absolutely secure.
[00:48:59.360 --> 00:49:04.840]   Plus privacy doesn't sell your data and you can hide your data from the merchant because
[00:49:04.840 --> 00:49:09.080]   privacy lets you use any name, any address, any zip code.
[00:49:09.080 --> 00:49:10.360]   They don't care.
[00:49:10.360 --> 00:49:13.720]   So you can buy something completely anonymously with privacy.
[00:49:13.720 --> 00:49:17.440]   You connect privacy to your debit account or your checking account.
[00:49:17.440 --> 00:49:20.120]   Now normally, I was using the free plan.
[00:49:20.120 --> 00:49:24.240]   The free personal plan, you get 12 cards a month, secure merchant locked, single use,
[00:49:24.240 --> 00:49:25.920]   all those features.
[00:49:25.920 --> 00:49:26.920]   That's a great deal.
[00:49:26.920 --> 00:49:28.600]   But then I found out about the pro plan.
[00:49:28.600 --> 00:49:30.720]   I pay 10 bucks a month.
[00:49:30.720 --> 00:49:35.080]   I get everything in the free plan, but I also get 36 cards a month.
[00:49:35.080 --> 00:49:36.080]   That's more than enough.
[00:49:36.080 --> 00:49:38.000]   And I get 1% cash back.
[00:49:38.000 --> 00:49:41.080]   And I use privacy so much that's always more than the $10 a month.
[00:49:41.080 --> 00:49:43.160]   So I make money that way.
[00:49:43.160 --> 00:49:44.880]   When I found out about that, I said, oh, that's obvious.
[00:49:44.880 --> 00:49:46.680]   I'm doing the pro account.
[00:49:46.680 --> 00:49:51.360]   If you have a business or you have a team, the team's option, $25 a month, you get 60
[00:49:51.360 --> 00:49:52.680]   cards a month.
[00:49:52.680 --> 00:49:56.400]   You also get a dedicated account manager and transaction limits tailored to your business
[00:49:56.400 --> 00:49:57.400]   needs.
[00:49:57.400 --> 00:49:59.720]   I like it that they have these tiers.
[00:49:59.720 --> 00:50:01.640]   It's how they make money.
[00:50:01.640 --> 00:50:05.640]   And it means there's no temptation for them to sell or information or do anything else.
[00:50:05.640 --> 00:50:10.280]   This is a really great company doing a great product, which I have been using for two years
[00:50:10.280 --> 00:50:11.840]   nonstop.
[00:50:11.840 --> 00:50:14.280]   I have hundreds of privacy cards.
[00:50:14.280 --> 00:50:16.000]   Head to privacy.com/twits.
[00:50:16.000 --> 00:50:17.400]   Sign up for an account.
[00:50:17.400 --> 00:50:20.240]   We're going to give you five bucks so that you use that address.
[00:50:20.240 --> 00:50:21.560]   You can spend it on your first purchase.
[00:50:21.560 --> 00:50:24.960]   This is for a limited time, but it's just a little thank you for telling them you saw
[00:50:24.960 --> 00:50:26.320]   it on our show.
[00:50:26.320 --> 00:50:29.240]   privacy.com/twit.
[00:50:29.240 --> 00:50:30.240]   Thank you, privacy.
[00:50:30.240 --> 00:50:31.920]   They've created a great product.
[00:50:31.920 --> 00:50:33.760]   I use it all the time.
[00:50:33.760 --> 00:50:34.960]   And I think you'll like it.
[00:50:34.960 --> 00:50:35.960]   privacy.com/twit.
[00:50:35.960 --> 00:50:37.600]   They browser extensions.
[00:50:37.600 --> 00:50:40.400]   I have one on Firefox, one on Chrome.
[00:50:40.400 --> 00:50:48.720]   Works on Brave or you can use the website or the app privacy.com/twit.
[00:50:48.720 --> 00:50:54.720]   Let's keep this on Apple for a little bit longer because they sent a shockwave through
[00:50:54.720 --> 00:51:03.560]   the web community by announcing that Safari is no longer going to consider certs valid
[00:51:03.560 --> 00:51:05.640]   if they're long-term certs.
[00:51:05.640 --> 00:51:12.720]   Anything more than 13 months will be considered invalid after September 1st.
[00:51:12.720 --> 00:51:16.560]   I use two-year certs because I don't want to have to redo the certs all the time.
[00:51:16.560 --> 00:51:21.840]   Those will no longer be valid when they expire after September 1st.
[00:51:21.840 --> 00:51:31.760]   This was a proposal that was voted down some months ago at the CA Forum, the certification
[00:51:31.760 --> 00:51:34.800]   Authority browser forum.
[00:51:34.800 --> 00:51:37.120]   But Apple decided to do it unilaterally.
[00:51:37.120 --> 00:51:38.800]   Now Bill, you probably covered this a little bit.
[00:51:38.800 --> 00:51:41.640]   This is kind of an enterprise issue.
[00:51:41.640 --> 00:51:44.680]   What it means is you're going to have to start using short-term certs and you're probably
[00:51:44.680 --> 00:51:48.000]   going to want to use automation to automatically renew those certs.
[00:51:48.000 --> 00:51:50.360]   We've seen many times people forgetting.
[00:51:50.360 --> 00:51:54.040]   In a company like Microsoft, just forget it.
[00:51:54.040 --> 00:51:55.640]   Yeah, that happened.
[00:51:55.640 --> 00:51:57.640]   Teams went down.
[00:51:57.640 --> 00:52:01.600]   Because somebody, you know, oh crap.
[00:52:01.600 --> 00:52:02.960]   Is it the 1st of March?
[00:52:02.960 --> 00:52:03.960]   Oh crap.
[00:52:03.960 --> 00:52:04.960]   And then they had to go.
[00:52:04.960 --> 00:52:08.560]   Honestly, even when you have it.
[00:52:08.560 --> 00:52:09.560]   Most people do have it.
[00:52:09.560 --> 00:52:13.840]   Even when you have it automated, if one cert someplace isn't part of that automation flow,
[00:52:13.840 --> 00:52:17.160]   when you're, you know, I mean, this is, and this is true for anything that's automated.
[00:52:17.160 --> 00:52:23.000]   You see this with key rotation a lot to where a key won't get rotated because if one thing
[00:52:23.000 --> 00:52:26.040]   isn't input in the automation string, the automation.
[00:52:26.040 --> 00:52:29.400]   It's embarrassing when, you know, it's actually goes down because it's certain.
[00:52:29.400 --> 00:52:30.400]   Yeah.
[00:52:30.400 --> 00:52:34.080]   It makes it worse because you assume that it's automatically going to be like renewed.
[00:52:34.080 --> 00:52:39.360]   And if you forgot one thing, you know, it catches you off guard because you just expect
[00:52:39.360 --> 00:52:40.600]   that it's always going to get renewed.
[00:52:40.600 --> 00:52:43.920]   So Bill, are you hearing from people on this?
[00:52:43.920 --> 00:52:48.880]   You know, it's funny, enterprise IT is always been a complex process.
[00:52:48.880 --> 00:52:52.280]   You know, automation makes some of it a little bit easier.
[00:52:52.280 --> 00:52:57.880]   But you know, it is easy to forget about sort of these dates when you think everything
[00:52:57.880 --> 00:52:58.880]   is automated.
[00:52:58.880 --> 00:53:03.760]   I haven't heard anything specifically other than, you know, from from our readers, other
[00:53:03.760 --> 00:53:08.960]   than really that, you know, the certificate process is pretty kind of, you know, it's
[00:53:08.960 --> 00:53:11.600]   like forgetting to buy your domain name.
[00:53:11.600 --> 00:53:14.680]   If you're someone famous, if you're a website, oh, you forgot your registration is going
[00:53:14.680 --> 00:53:15.680]   to expire.
[00:53:15.680 --> 00:53:19.760]   It's one of those things that your users expect to happen on a regular basis.
[00:53:19.760 --> 00:53:24.840]   So if you're in enterprise IT and you don't do that and it, you know, something fails,
[00:53:24.840 --> 00:53:25.840]   it's very embarrassing.
[00:53:25.840 --> 00:53:29.600]   Everybody, everybody uses two years to happen.
[00:53:29.600 --> 00:53:32.200]   I mean, everyone uses two year certificates, right?
[00:53:32.200 --> 00:53:36.160]   I mean, so because you don't want to have to be doing this on a regular basis, like security
[00:53:36.160 --> 00:53:40.160]   patches and updates, but you forget, oh, you think, oh, it's really easy.
[00:53:40.160 --> 00:53:44.520]   It's one certificate for no, I mean, all these systems are interconnected.
[00:53:44.520 --> 00:53:48.240]   So you might have multiple systems that are connected together.
[00:53:48.240 --> 00:53:49.920]   One point of failure comes down.
[00:53:49.920 --> 00:53:55.080]   So you know, now I'll be interested to see, let's be honest here about Safari isn't the
[00:53:55.080 --> 00:54:01.240]   most used browser on the desktop, but what's really more important here are all the mobile
[00:54:01.240 --> 00:54:06.840]   devices, all the iOS devices that this could affect, right?
[00:54:06.840 --> 00:54:12.440]   So, you know, Chrome users, edge users, you know, people that aren't using Safari, you
[00:54:12.440 --> 00:54:16.440]   know, be okay, but all those mobile devices, all those iPhones, iPads, everything like that,
[00:54:16.440 --> 00:54:17.800]   that's going to be affected by this.
[00:54:17.800 --> 00:54:20.360]   So I'll be interested to see where this really kind of goes.
[00:54:20.360 --> 00:54:25.160]   If Apple has that kind of clout, the kind of, you know, force people to start going
[00:54:25.160 --> 00:54:27.160]   to 13 month search.
[00:54:27.160 --> 00:54:32.080]   Safari has more than 50% market share on mobile because of iOS.
[00:54:32.080 --> 00:54:34.560]   I think it's only 17% on desktop.
[00:54:34.560 --> 00:54:35.560]   Right.
[00:54:35.560 --> 00:54:38.040]   It says, well, we'll just, we don't need those 17%.
[00:54:38.040 --> 00:54:39.040]   Right.
[00:54:39.040 --> 00:54:40.880]   You just throw out those people.
[00:54:40.880 --> 00:54:45.920]   Well, and to Bill's point, I mean, makes me think about the MDM space, you know, so
[00:54:45.920 --> 00:54:50.220]   like the, you know, mobile device management space, because even if you are saying like
[00:54:50.220 --> 00:54:54.480]   from an enterprise perspective, even if your users aren't using Safari on the desktop,
[00:54:54.480 --> 00:54:57.640]   if this could be the sort of thing where I would think that it would violate a lot of
[00:54:57.640 --> 00:55:02.920]   policies to say, okay, if our website or other things are going to not have, you know, a
[00:55:02.920 --> 00:55:08.560]   certificate that expires at this point, then there could potentially be like, okay, that
[00:55:08.560 --> 00:55:13.240]   Safari itself might let you still access something even if it says this is unsecure, but you
[00:55:13.240 --> 00:55:16.400]   might have some policy on your mobile device that might say, oh, no, we're not going to
[00:55:16.400 --> 00:55:20.960]   allow you to access, you know, insecure websites.
[00:55:20.960 --> 00:55:22.800]   So I don't know.
[00:55:22.800 --> 00:55:26.480]   This opens up interesting questions to see, I guess, how people will deal with this.
[00:55:26.480 --> 00:55:31.520]   I mean, it's interesting that they made this move even though the other groups said, no,
[00:55:31.520 --> 00:55:33.520]   we want longer term certs.
[00:55:33.520 --> 00:55:34.520]   Yeah.
[00:55:34.520 --> 00:55:38.160]   So there is a good security reason for this.
[00:55:38.160 --> 00:55:45.280]   The problem is there's no effective certificate revocation process.
[00:55:45.280 --> 00:55:51.680]   So if a cert, and this has happened, if somehow somebody gets a cert, said it says IBM, but
[00:55:51.680 --> 00:55:58.000]   it's a hacker, you can't easily say to all the certificate authorities, to all the browsers,
[00:55:58.000 --> 00:56:02.720]   oh, don't honor that one, it's not really IBM, there's no way to revoke that cert.
[00:56:02.720 --> 00:56:04.760]   You have to wait until it expires.
[00:56:04.760 --> 00:56:08.120]   So it used to be you could get certs for 10 years.
[00:56:08.120 --> 00:56:09.520]   That would be kind of untenable.
[00:56:09.520 --> 00:56:12.160]   Now it's two years is the longest.
[00:56:12.160 --> 00:56:14.360]   It's going to be less than a year soon.
[00:56:14.360 --> 00:56:17.400]   And I think ultimately they'd like to make it even shorter and shorter.
[00:56:17.400 --> 00:56:19.800]   But understanding how much pain was involved.
[00:56:19.800 --> 00:56:24.440]   The CA browser folks said, yeah, we don't, we don't want to, we don't want to do this
[00:56:24.440 --> 00:56:25.940]   just yet.
[00:56:25.940 --> 00:56:27.740]   I talked to Steve Gibson about it on security.
[00:56:27.740 --> 00:56:31.060]   Now he said, there is a way you could do revocation.
[00:56:31.060 --> 00:56:36.220]   It's just that, but Google and Firefox Mozilla and others just won't do this.
[00:56:36.220 --> 00:56:40.500]   The certificate certification comes from OCSP.
[00:56:40.500 --> 00:56:46.300]   And the way it would work normally is every time you go to a site, your browser would
[00:56:46.300 --> 00:56:51.180]   check OCSP to see if that cert was legit, if it had been revoked, if it was a, if it
[00:56:51.180 --> 00:56:52.380]   was a good cert.
[00:56:52.380 --> 00:56:54.820]   OCSP would respond back saying, yes, it's a good cert.
[00:56:54.820 --> 00:56:56.020]   You'd go to the site.
[00:56:56.020 --> 00:57:00.660]   But even if this adds a second or two to loading a site, this is problematic.
[00:57:00.660 --> 00:57:02.500]   No browser wants to do it.
[00:57:02.500 --> 00:57:10.300]   A technology was invented called stapling OCSP stapling where the browser would periodically
[00:57:10.300 --> 00:57:14.500]   go out, even if you weren't going to that site and just update the search, check all
[00:57:14.500 --> 00:57:21.460]   the certs just to make sure that would eliminate that, that latency of going to the site, but
[00:57:21.460 --> 00:57:24.060]   it would involve more internet traffic.
[00:57:24.060 --> 00:57:29.540]   I'm not sure why Mozilla and Google and others aren't going along with OCSP stapling.
[00:57:29.540 --> 00:57:32.180]   Steve's of the opinion it would have solved this problem.
[00:57:32.180 --> 00:57:35.500]   Here's, I have a very weird conspiracy theory.
[00:57:35.500 --> 00:57:41.500]   I think Google and Mozilla Safari, I think the people who do this all wanted to shorten
[00:57:41.500 --> 00:57:43.340]   the length because it's problem.
[00:57:43.340 --> 00:57:47.740]   If you've got a hacker cert, there's no way to say, don't trust that cert.
[00:57:47.740 --> 00:57:50.580]   You got to wait until it expires.
[00:57:50.580 --> 00:57:54.040]   So I think they all wanted to do this, but nobody wanted to take the heat for it.
[00:57:54.040 --> 00:57:55.040]   So here's what I think.
[00:57:55.040 --> 00:57:59.300]   They all got together in a parking garage and they drew straws.
[00:57:59.300 --> 00:58:00.900]   Oh, it's a short straw.
[00:58:00.900 --> 00:58:03.980]   Short straw is going to do this unilaterally.
[00:58:03.980 --> 00:58:07.100]   We can all go, oh my God, that's a terrible idea.
[00:58:07.100 --> 00:58:08.900]   And then everybody does it.
[00:58:08.900 --> 00:58:11.740]   And I think Apple got the short straw.
[00:58:11.740 --> 00:58:12.740]   I love it.
[00:58:12.740 --> 00:58:16.540]   Because every, everybody says, look, if you're not going to do OCSP stapling, you got to
[00:58:16.540 --> 00:58:17.540]   shorten the term.
[00:58:17.540 --> 00:58:18.540]   You just have to.
[00:58:18.540 --> 00:58:21.380]   And eventually it's all going to be let's encrypt three month terms.
[00:58:21.380 --> 00:58:22.380]   It'll be big.
[00:58:22.380 --> 00:58:23.380]   Yeah, everything 90 days.
[00:58:23.380 --> 00:58:27.520]   That's still too long for a hacker cert to be good though.
[00:58:27.520 --> 00:58:28.520]   They should do stapling.
[00:58:28.520 --> 00:58:29.520]   I don't know why they don't.
[00:58:29.520 --> 00:58:32.680]   There must be a technical reason for not doing that.
[00:58:32.680 --> 00:58:33.680]   I don't know.
[00:58:33.680 --> 00:58:34.680]   I'm sure that's not the case.
[00:58:34.680 --> 00:58:35.680]   I just love the idea of them all.
[00:58:35.680 --> 00:58:36.680]   I love that too.
[00:58:36.680 --> 00:58:38.380]   Trust me.
[00:58:38.380 --> 00:58:42.640]   You would like to think, I would like to think that they're all a little altruistic
[00:58:42.640 --> 00:58:47.840]   enough to do that and that they all kind of, it's not so Machiavellian that they want to
[00:58:47.840 --> 00:58:52.160]   do that, but it's kind of like, this is the good thing for the good of the group.
[00:58:52.160 --> 00:58:56.780]   One of us will take the, you know, I'll take all the bad will for a while.
[00:58:56.780 --> 00:58:58.220]   You know, I'm kind of with you, Leo.
[00:58:58.220 --> 00:59:01.860]   You know, I'd like to think that I'm not, I'm probably sure that's not what happened,
[00:59:01.860 --> 00:59:03.220]   but still I want to think it did.
[00:59:03.220 --> 00:59:04.220]   He can hope.
[00:59:04.220 --> 00:59:05.220]   That's right.
[00:59:05.220 --> 00:59:06.220]   And it wouldn't have been straws.
[00:59:06.220 --> 00:59:11.340]   It'll probably be a randomized Excel spreadsheet or something, but I'm sure there'd be a, no,
[00:59:11.340 --> 00:59:14.620]   you don't want to do a pseudo number, random number generator, Apple to figure out a way
[00:59:14.620 --> 00:59:15.620]   to get around that one.
[00:59:15.620 --> 00:59:18.340]   Google would actually, maybe that's why Apple got it.
[00:59:18.340 --> 00:59:20.060]   Maybe Google did figure it out.
[00:59:20.060 --> 00:59:22.020]   Supreme Court has rejected apples appeal.
[00:59:22.020 --> 00:59:28.920]   They got, they lost a judgment against, I'm going to call them, I don't want to get in
[00:59:28.920 --> 00:59:29.920]   trouble.
[00:59:29.920 --> 00:59:33.080]   Let's call them a non practicing entity.
[00:59:33.080 --> 00:59:34.920]   Vernette X, there's an.
[00:59:34.920 --> 00:59:37.200]   Some might call some might call them a patent role.
[00:59:37.200 --> 00:59:38.680]   I would never do that.
[00:59:38.680 --> 00:59:39.680]   But some might.
[00:59:39.680 --> 00:59:40.680]   No, no, some might.
[00:59:40.680 --> 00:59:41.680]   Some might.
[00:59:41.680 --> 00:59:42.680]   Some might.
[00:59:42.680 --> 00:59:43.680]   Vernette X never used the patent.
[00:59:43.680 --> 00:59:45.680]   They bought the patent and they sued Apple.
[00:59:45.680 --> 00:59:48.920]   It's been going back to 2010.
[00:59:48.920 --> 00:59:54.840]   And this is the giveaway, the Eastern District of Texas, accusing Apple of infringing four
[00:59:54.840 --> 00:59:59.560]   patents for VPNs and secure communication links.
[00:59:59.560 --> 01:00:05.540]   Verte, Verte, neck X said Apple infringed with its FaceTime and VPN on demand features
[01:00:05.540 --> 01:00:08.440]   and iPhone and iPad.
[01:00:08.440 --> 01:00:15.900]   Apple lost was hit with a $440 million damage suit.
[01:00:15.900 --> 01:00:18.140]   They appealed, went all the way up to the Supreme Court.
[01:00:18.140 --> 01:00:21.740]   The Supreme Court has now rejected Apple's appeal.
[01:00:21.740 --> 01:00:28.620]   So I guess they're going to have to dig into that $207 billion kitty, pull out a half
[01:00:28.620 --> 01:00:31.740]   billion for Vernette X.
[01:00:31.740 --> 01:00:33.900]   Oh well.
[01:00:33.900 --> 01:00:35.900]   That's the.
[01:00:35.900 --> 01:00:37.380]   Oh well.
[01:00:37.380 --> 01:00:38.380]   Unbelievable.
[01:00:38.380 --> 01:00:41.540]   It's unbelievable that this, that this type of thing is still happening.
[01:00:41.540 --> 01:00:42.540]   It's a jury, right?
[01:00:42.540 --> 01:00:44.060]   You go to Texas.
[01:00:44.060 --> 01:00:51.380]   The juries are very pro little guy, anti big business, especially deep pocket big business.
[01:00:51.380 --> 01:00:56.700]   You put your, you throw yourself on the mercy of the jury and you win.
[01:00:56.700 --> 01:01:01.300]   And you know, I think it speaks though to the state of sort of patents in the US and
[01:01:01.300 --> 01:01:02.700]   you know, I'm not a lawyer.
[01:01:02.700 --> 01:01:08.500]   I don't, you know, I can't, you know, I can't comment on it on specific, this specific case
[01:01:08.500 --> 01:01:10.060]   or anything on the merits of it.
[01:01:10.060 --> 01:01:12.900]   But you know, I did read about this.
[01:01:12.900 --> 01:01:18.180]   And so I guess during the litigation, Apple had asked for a tribunal from the US Patent
[01:01:18.180 --> 01:01:23.820]   and Trademark Office to actually sort of review some of the patents that were in question
[01:01:23.820 --> 01:01:24.820]   here.
[01:01:24.820 --> 01:01:29.660]   And I think the tribunal actually ruled them as invalid or said that, you know, some of
[01:01:29.660 --> 01:01:30.660]   them are invalid.
[01:01:30.660 --> 01:01:33.860]   So the Apple went back to the courts and said, well, hey, what, by the way, that's
[01:01:33.860 --> 01:01:34.860]   victory.
[01:01:34.860 --> 01:01:38.860]   We were told when there was a patent troll going after podcasters and we sat down, we
[01:01:38.860 --> 01:01:44.140]   hired a council and they said, well, there is a thing you can do called, I think it's
[01:01:44.140 --> 01:01:48.700]   an inter partase appeal where you go to the US Patent and Trademark Office and say, would
[01:01:48.700 --> 01:01:50.780]   you please reexamine this patent?
[01:01:50.780 --> 01:01:51.780]   Right.
[01:01:51.780 --> 01:01:54.060]   And they said, here's the risk.
[01:01:54.060 --> 01:01:56.860]   If they reexamine it and affirm it, you're screwed.
[01:01:56.860 --> 01:02:02.780]   Because then the lawyer tells the jury and not only that, but these clowns went to the
[01:02:02.780 --> 01:02:06.100]   Patent and Trademark Office said, you're, get rid of this patent and the Patent and
[01:02:06.100 --> 01:02:08.220]   Trademark Office said, no, no, it's a good patent.
[01:02:08.220 --> 01:02:09.340]   You're really lose then.
[01:02:09.340 --> 01:02:10.820]   So we decided not to do it.
[01:02:10.820 --> 01:02:16.420]   Fortunately, the Electronic Frontier Foundation did and they were able to successfully overturn
[01:02:16.420 --> 01:02:19.900]   the patent trolls podcast patent.
[01:02:19.900 --> 01:02:23.180]   In this case, Apple won.
[01:02:23.180 --> 01:02:28.260]   As you point out, the patents were overturned, but then the Federal Circuit of Court set
[01:02:28.260 --> 01:02:30.460]   aside the rulings.
[01:02:30.460 --> 01:02:33.340]   They said, yeah.
[01:02:33.340 --> 01:02:37.300]   Those people at the US Patent and Trademark Office, they don't know anything about patents.
[01:02:37.300 --> 01:02:38.300]   We're the courts.
[01:02:38.300 --> 01:02:39.300]   We know better.
[01:02:39.300 --> 01:02:46.380]   So again, I think that just speaks to the state of patent litigation in the US.
[01:02:46.380 --> 01:02:47.380]   Yeah.
[01:02:47.380 --> 01:02:51.340]   And then Apple can afford it, but it's just, it is a scary thing.
[01:02:51.340 --> 01:02:54.820]   Well, the president, sure, Apple can afford it, but the precedent of what this means for
[01:02:54.820 --> 01:02:58.300]   people who can't is really what troubles me.
[01:02:58.300 --> 01:03:02.220]   I mean, okay, so no one's going to cry that Apple has to pay the settlement, but I'm much
[01:03:02.220 --> 01:03:07.620]   more concerned about anyone else who might fall afoul of this who can then be strong
[01:03:07.620 --> 01:03:17.140]   armed into pain to some company that doesn't even operate other than suing people for allegedly
[01:03:17.140 --> 01:03:20.220]   using their patents.
[01:03:20.220 --> 01:03:25.820]   So I don't know if you remember two years ago, Walter Wong, an Apple engineer, very proud
[01:03:25.820 --> 01:03:27.860]   of his Model X Tesla.
[01:03:27.860 --> 01:03:31.340]   He loved his car very tragically.
[01:03:31.340 --> 01:03:38.620]   The car he was driving with autopilot on, it drove into a guardrail and he died in a fiery
[01:03:38.620 --> 01:03:41.980]   accident, his family suing over it.
[01:03:41.980 --> 01:03:46.300]   The NTSB finally came back with their rulings this week.
[01:03:46.300 --> 01:03:55.300]   They said A, the autopilot was on, but B, Wong never touched the steering wheel or hit the
[01:03:55.300 --> 01:04:01.220]   brake as the car sped up and headed straight for the divider.
[01:04:01.220 --> 01:04:06.780]   They blamed a little bit the California Transportation Authority's Caltrans because there had been
[01:04:06.780 --> 01:04:08.180]   an accident two weeks earlier.
[01:04:08.180 --> 01:04:13.340]   A Prius hit the guardrail at 75 miles an hour and the guy walked away with minor injuries
[01:04:13.340 --> 01:04:19.780]   because there was a crash absorber and a tenuator on it, but the attenuator was damaged with
[01:04:19.780 --> 01:04:23.020]   the prior crash and removed and never replaced.
[01:04:23.020 --> 01:04:28.140]   And so Wong did not have the, you know, he hit that concrete at 71 miles an hour, did
[01:04:28.140 --> 01:04:29.620]   not have a chance.
[01:04:29.620 --> 01:04:35.460]   Apple was also blamed by the NTSB because the iPhone, it turned out Wong was playing
[01:04:35.460 --> 01:04:37.780]   a game on his iPhone.
[01:04:37.780 --> 01:04:43.700]   That's why I didn't notice the car plowing into the divider and the NTSB said Apple
[01:04:43.700 --> 01:04:46.420]   should have a phone use driving policy.
[01:04:46.420 --> 01:04:48.460]   There was a lot of blame to go around.
[01:04:48.460 --> 01:04:54.660]   I honestly, I think the real problem is Tesla selling its autopilot as autopilot, not as
[01:04:54.660 --> 01:04:56.060]   driver assist.
[01:04:56.060 --> 01:05:00.020]   Although I have to say having a hat of Model X for three years, it gets mad at you.
[01:05:00.020 --> 01:05:02.500]   If you don't keep your hands on the wheel, it says, "Come on, pay attention.
[01:05:02.500 --> 01:05:04.380]   Come on."
[01:05:04.380 --> 01:05:07.140]   But a little inattention.
[01:05:07.140 --> 01:05:12.020]   By the way, the driver was using an Apple supplied phone.
[01:05:12.020 --> 01:05:18.100]   So Apple was also dinged because here's a company phone and you really should have a
[01:05:18.100 --> 01:05:21.100]   policy preventing cell phone you swallow at driving.
[01:05:21.100 --> 01:05:26.900]   But I mean, it's hard to determine if you're the one operating the car of someone else's.
[01:05:26.900 --> 01:05:29.820]   Oh, that's a good point.
[01:05:29.820 --> 01:05:33.300]   Right, because I don't drive for instance, right?
[01:05:33.300 --> 01:05:37.860]   Like I don't have a driver's license, but when I use Waze, it'll come up and it'll say,
[01:05:37.860 --> 01:05:39.300]   "Oh, I see you're in a car."
[01:05:39.300 --> 01:05:42.660]   And then you have to tap a thing that says, "I'm not the one driving."
[01:05:42.660 --> 01:05:44.380]   Same thing with Pokemon Go.
[01:05:44.380 --> 01:05:45.380]   Exactly.
[01:05:45.380 --> 01:05:48.820]   So what I do is I hold it between my legs while I have the steering wheel on and then
[01:05:48.820 --> 01:05:49.820]   I...
[01:05:49.820 --> 01:05:50.820]   No.
[01:05:50.820 --> 01:05:52.820]   No, I wouldn't do that.
[01:05:52.820 --> 01:05:53.820]   I'm not this.
[01:05:53.820 --> 01:05:55.980]   But you know what I mean?
[01:05:55.980 --> 01:05:56.980]   So that's the thing.
[01:05:56.980 --> 01:06:00.780]   It's like, okay, you can have that model, but if the user overrides it, like, and how
[01:06:00.780 --> 01:06:01.780]   do you know?
[01:06:01.780 --> 01:06:06.220]   Because the car doesn't have any determination if I'm sitting behind the driver's seat or
[01:06:06.220 --> 01:06:10.580]   if I'm sitting right next to it or if I'm in the back seat, like, the app doesn't know.
[01:06:10.580 --> 01:06:11.580]   Yeah.
[01:06:11.580 --> 01:06:14.420]   It can determine if I'm in a moving vehicle, but it can't determine if I'm the one operating
[01:06:14.420 --> 01:06:15.420]   the vehicle.
[01:06:15.420 --> 01:06:21.180]   It is a real tragedy and I feel bad for a Wong's family.
[01:06:21.180 --> 01:06:22.540]   He loved his Model X.
[01:06:22.540 --> 01:06:24.340]   I know I remember how much I love my Model X.
[01:06:24.340 --> 01:06:27.300]   I have to say though, I never trusted it.
[01:06:27.300 --> 01:06:28.660]   Lisa always said, "It's good."
[01:06:28.660 --> 01:06:29.660]   Right?
[01:06:29.660 --> 01:06:32.780]   Remember, we'd go around this one curve and you'd say, "It's pulling, it's heading for
[01:06:32.780 --> 01:06:35.060]   the divider and I have to disengage."
[01:06:35.060 --> 01:06:37.700]   We disengaged all the time on that autopilot.
[01:06:37.700 --> 01:06:40.500]   And so it is a big mistake to assume it's an autopilot.
[01:06:40.500 --> 01:06:44.820]   It tends to bear some blame for overselling that feature, I think.
[01:06:44.820 --> 01:06:48.940]   You know, I think if they just use a different name, if they hadn't called it autopilot because
[01:06:48.940 --> 01:06:55.740]   you expect autopilot on an airplane to actually be able to, you know, pilot the plane without
[01:06:55.740 --> 01:07:00.300]   human intervention, but here, like you said, Leo, if they just called it driver assist,
[01:07:00.300 --> 01:07:04.100]   I think that would have been given people the right expectation.
[01:07:04.100 --> 01:07:08.260]   You know, of course, then we wouldn't have all these videos of people sleeping in their
[01:07:08.260 --> 01:07:12.740]   auto drive autopilot cars to entertain us on YouTube.
[01:07:12.740 --> 01:07:19.500]   But still, you know, when you see the real world, real life implications of people either,
[01:07:19.500 --> 01:07:25.660]   you know, failing to use the systems as they were intended or, you know, texting or driving
[01:07:25.660 --> 01:07:28.260]   distracted, you know, it's a real shame.
[01:07:28.260 --> 01:07:31.980]   I mean, I honestly can't wait until I love to drive.
[01:07:31.980 --> 01:07:33.860]   I've always been a sports car kind of person.
[01:07:33.860 --> 01:07:41.100]   So I love cars, but I really, for my daily commute, cannot wait until I can just get
[01:07:41.100 --> 01:07:43.940]   into a car and don't have to think about it.
[01:07:43.940 --> 01:07:45.900]   Now I would love to use public transportation.
[01:07:45.900 --> 01:07:49.900]   Unfortunately, where I live, the public transportation is kind of lackluster.
[01:07:49.900 --> 01:07:55.740]   So it's, you know, I understand why people want to use it, but you know, we're just not
[01:07:55.740 --> 01:07:57.300]   there yet.
[01:07:57.300 --> 01:08:04.140]   And you know, if ever and until every car, a majority of cars have a type of autopilot
[01:08:04.140 --> 01:08:08.260]   feature, have autonomous driving, then, you know, you're still going to have people do
[01:08:08.260 --> 01:08:11.820]   bad things in their cars or, you know, make mistakes.
[01:08:11.820 --> 01:08:15.620]   Well, people do bad things all the time with it without autopilot.
[01:08:15.620 --> 01:08:16.620]   Yes.
[01:08:16.620 --> 01:08:19.060]   Lisa and I were driving the other day.
[01:08:19.060 --> 01:08:25.100]   We're in the diamond lane and I see somebody stick her arm out the window and go like this.
[01:08:25.100 --> 01:08:28.540]   The universal signal for I want to get over in your lane.
[01:08:28.540 --> 01:08:30.460]   So I slow down.
[01:08:30.460 --> 01:08:31.620]   Nothing happens.
[01:08:31.620 --> 01:08:32.620]   I wait.
[01:08:32.620 --> 01:08:34.420]   I finally give up and kind of go ahead.
[01:08:34.420 --> 01:08:35.540]   I look in there.
[01:08:35.540 --> 01:08:40.020]   It turns out she was cleaning while driving her car, cleaning her hairbrush and putting
[01:08:40.020 --> 01:08:42.020]   the hair out the window.
[01:08:42.020 --> 01:08:44.020]   I thought she was signaling me.
[01:08:44.020 --> 01:08:45.940]   She's, you know, just clean your brush.
[01:08:45.940 --> 01:08:47.260]   That's all.
[01:08:47.260 --> 01:08:50.020]   So people, I mean, that's all the time you see that.
[01:08:50.020 --> 01:08:52.420]   If you drive, it's terrifying out there, to be honest with you.
[01:08:52.420 --> 01:08:55.260]   I can't wait till we get real self-driving vehicles.
[01:08:55.260 --> 01:09:00.460]   But as the NTSB was at great pains to point out that you cannot today buy a self-driving
[01:09:00.460 --> 01:09:01.460]   vehicle.
[01:09:01.460 --> 01:09:04.980]   So please keep your hands on the wheel and your eyes on the road.
[01:09:04.980 --> 01:09:06.260]   You got a job.
[01:09:06.260 --> 01:09:14.580]   I feel like Tesla, the autopilot and my Tesla made me safer because I was always paying
[01:09:14.580 --> 01:09:20.020]   attention, but it just helped me keep distance appropriately.
[01:09:20.020 --> 01:09:23.900]   You know, because it was the auto adaptive cruise control, it would let me know if I was
[01:09:23.900 --> 01:09:24.900]   going out of a lane.
[01:09:24.900 --> 01:09:26.940]   I never would let it change lanes by itself.
[01:09:26.940 --> 01:09:30.860]   So many times when I first tried it, it didn't pay any attention to the car in the other
[01:09:30.860 --> 01:09:31.860]   lane.
[01:09:31.860 --> 01:09:32.860]   So I never let it do that.
[01:09:32.860 --> 01:09:34.620]   But I feel like I was a better driver.
[01:09:34.620 --> 01:09:39.100]   I was less likely to get an erect from falling asleep or something.
[01:09:39.100 --> 01:09:42.300]   So those, I think they're good features, in other words.
[01:09:42.300 --> 01:09:44.420]   But please, folks, drive.
[01:09:44.420 --> 01:09:45.420]   Don't worry.
[01:09:45.420 --> 01:09:47.700]   Well, and they're less and less unique, right?
[01:09:47.700 --> 01:09:52.700]   I mean, like more and more cars are getting a lot of these crash prevention driver assist
[01:09:52.700 --> 01:09:53.700]   features.
[01:09:53.700 --> 01:10:00.460]   And I think Bill said just a few minutes ago, autopilot by definition is automatic pilot.
[01:10:00.460 --> 01:10:07.900]   So basically, you know, the driver is-- you can't blame a driver for presuming that this
[01:10:07.900 --> 01:10:11.940]   feature is able to take control of the car and get you from point A to point B because
[01:10:11.940 --> 01:10:14.660]   that's essentially how it's marketed.
[01:10:14.660 --> 01:10:16.500]   I'm surprised they're still allowed to do it.
[01:10:16.500 --> 01:10:21.060]   I mean, this is-- I feel like almost every time I've been on this show, there's been a new
[01:10:21.060 --> 01:10:28.580]   instance of someone crashing in a new way or in a new state because of this feature.
[01:10:28.580 --> 01:10:34.020]   And even though I'm excited-- I obviously love Tesla as a car maker.
[01:10:34.020 --> 01:10:35.940]   Their cars are really awesome.
[01:10:35.940 --> 01:10:39.460]   And a lot of these features are really exciting.
[01:10:39.460 --> 01:10:46.460]   Any partially self-driving car that I've been in or tested or driven has been awesome.
[01:10:46.460 --> 01:10:53.420]   And I do think there's a real opportunity to save lives and to help people drive safely
[01:10:53.420 --> 01:10:56.100]   and prevent crashes.
[01:10:56.100 --> 01:10:59.660]   But you know, I'm just so tired of hearing about the same accident happening over and
[01:10:59.660 --> 01:11:00.660]   over again.
[01:11:00.660 --> 01:11:06.500]   The fact that people are taking their eyes off the road because of this feature called
[01:11:06.500 --> 01:11:10.060]   autopilot, which is not at all autopilot.
[01:11:10.060 --> 01:11:14.300]   It is a driver assist feature rather than an automatic--
[01:11:14.300 --> 01:11:18.860]   By the way, I won't buy another car that doesn't have adaptive cruise control and lane keeping.
[01:11:18.860 --> 01:11:19.860]   That's really what it is.
[01:11:19.860 --> 01:11:20.860]   And I like that.
[01:11:20.860 --> 01:11:21.860]   Right.
[01:11:21.860 --> 01:11:25.580]   I'm going to get the new Ford Mustang Mach-E when it comes out this fall.
[01:11:25.580 --> 01:11:30.500]   And the first thing I check, adaptive cruise control not only means it sets a speed, but
[01:11:30.500 --> 01:11:32.500]   it slows down at the car in front of you, slows down.
[01:11:32.500 --> 01:11:34.380]   It can even come to a stop.
[01:11:34.380 --> 01:11:36.820]   So it's great for stop and go traffic.
[01:11:36.820 --> 01:11:38.860]   And then it starts up again after the car goes.
[01:11:38.860 --> 01:11:41.860]   So you don't have to keep your foot on the accelerator going up and down.
[01:11:41.860 --> 01:11:43.740]   And lane keeping is really great.
[01:11:43.740 --> 01:11:47.820]   I mean, if you start to drift out of the lane, it lets you know.
[01:11:47.820 --> 01:11:52.820]   All of those things are, I think, much safer as long as they're used properly, that's all.
[01:11:52.820 --> 01:11:54.300]   I don't want them to go away.
[01:11:54.300 --> 01:11:55.300]   No, no.
[01:11:55.300 --> 01:11:58.140]   I think the big difference is, as people are saying, it's the branding, right?
[01:11:58.140 --> 01:12:05.220]   It's that, OK, you could call adaptive cruise control and keeping people in lane.
[01:12:05.220 --> 01:12:06.900]   That is a part of autopilot.
[01:12:06.900 --> 01:12:10.300]   But when you use that name, autopilot, it has a completely different connotation.
[01:12:10.300 --> 01:12:12.860]   It's worse than that because Elon's always talking about you.
[01:12:12.860 --> 01:12:18.780]   He said it last year, oh, yeah, by 2020, anybody who owns a Tesla will be able to lease it out
[01:12:18.780 --> 01:12:21.980]   as a self-driving vehicle and it'll come back to you.
[01:12:21.980 --> 01:12:25.260]   And I mean, none of this is going to happen anywhere near that time frame.
[01:12:25.260 --> 01:12:26.620]   That's nuts.
[01:12:26.620 --> 01:12:28.820]   He just likes, I think he's a hype monster.
[01:12:28.820 --> 01:12:29.820]   Yeah.
[01:12:29.820 --> 01:12:30.820]   Oh, yeah.
[01:12:30.820 --> 01:12:31.820]   And he's great at it.
[01:12:31.820 --> 01:12:36.180]   But the truth is that all of the features that were unique to Tesla in the beginning
[01:12:36.180 --> 01:12:38.780]   a few years ago are being commodified.
[01:12:38.780 --> 01:12:39.780]   Yeah.
[01:12:39.780 --> 01:12:42.180]   I mean, you're seeing them in every single new car.
[01:12:42.180 --> 01:12:44.860]   Credit, by the way, credit to Tesla.
[01:12:44.860 --> 01:12:49.340]   Because they made electric vehicles cool.
[01:12:49.340 --> 01:12:53.020]   And we wouldn't see so many great electric vehicles now if it weren't for Tesla paving
[01:12:53.020 --> 01:12:54.020]   the way.
[01:12:54.020 --> 01:12:56.420]   So he gets deserves all credit.
[01:12:56.420 --> 01:12:57.420]   Definitely.
[01:12:57.420 --> 01:12:58.860]   And they're still very cool cars.
[01:12:58.860 --> 01:12:59.860]   I mean, don't get me wrong.
[01:12:59.860 --> 01:13:04.700]   I would love a Tesla S. It's an awesome car.
[01:13:04.700 --> 01:13:09.420]   But I just think that, you know, it's kind of, I just think it's a little irresponsible
[01:13:09.420 --> 01:13:14.780]   on his part to argue for that type of marketing and to continue it when people are losing
[01:13:14.780 --> 01:13:17.180]   their lives.
[01:13:17.180 --> 01:13:18.180]   Let's take a little break.
[01:13:18.180 --> 01:13:19.540]   There are still a lot more to talk about.
[01:13:19.540 --> 01:13:22.620]   Have you been to the new Amazon grocery in Seattle, Christina?
[01:13:22.620 --> 01:13:24.140]   Yes, I have.
[01:13:24.140 --> 01:13:25.780]   I want to talk to you about that.
[01:13:25.780 --> 01:13:27.180]   What an interesting idea.
[01:13:27.180 --> 01:13:31.860]   Speaking of self-driving grocery stores.
[01:13:31.860 --> 01:13:35.340]   And something's going on with Twitter.
[01:13:35.340 --> 01:13:41.900]   A activist investor has apparently bought a large stake in Twitter and is trying to get
[01:13:41.900 --> 01:13:44.180]   out, get jacked or see out.
[01:13:44.180 --> 01:13:47.380]   There's some evidence.
[01:13:47.380 --> 01:13:52.020]   He's a Republican mega donor and a Trump fan and maybe is trying to turn Twitter into
[01:13:52.020 --> 01:13:53.020]   something else.
[01:13:53.020 --> 01:13:54.020]   We'll see.
[01:13:54.020 --> 01:13:55.660]   We'll talk about that in just a bit.
[01:13:55.660 --> 01:13:59.500]   First, if you missed anything this week, we had a wonderful week of shows.
[01:13:59.500 --> 01:14:00.660]   I slept through most of them.
[01:14:00.660 --> 01:14:02.300]   So we, we have to do this.
[01:14:02.300 --> 01:14:05.780]   We prepared a little video to keep me up on what's going on on Twitter.
[01:14:05.780 --> 01:14:08.380]   Previously on Twitter.
[01:14:08.380 --> 01:14:11.380]   If you've ever called a GIF a GIF, we forgive you, it says.
[01:14:11.380 --> 01:14:17.540]   This is a 40 ounce jar, a two pound eight ounce jar of GIF peanut butter.
[01:14:17.540 --> 01:14:18.540]   I'm mad.
[01:14:18.540 --> 01:14:19.540]   I'm happy.
[01:14:19.540 --> 01:14:21.380]   Tech News Weekly.
[01:14:21.380 --> 01:14:25.740]   After putting out a bunch of other smaller Amazon Go stores throughout the nation and
[01:14:25.740 --> 01:14:29.140]   now in Seattle, they've come up with Amazon Go grocery.
[01:14:29.140 --> 01:14:32.980]   As a tech site, we would love for Amazon to call us and say, this is the breakdown.
[01:14:32.980 --> 01:14:35.140]   This is what we did in our first wave of stores.
[01:14:35.140 --> 01:14:36.860]   Here's what we changed in our second wave.
[01:14:36.860 --> 01:14:37.860]   We don't get that luxury.
[01:14:37.860 --> 01:14:41.460]   So instead I have to go in like a jackass and just act like a fool and figure out what
[01:14:41.460 --> 01:14:44.500]   I can do to trick the system.
[01:14:44.500 --> 01:14:45.500]   Windows Weekly.
[01:14:45.500 --> 01:14:48.700]   People were shocked that I said, I can't wait to see the duo and the Neo.
[01:14:48.700 --> 01:14:50.340]   But I like this dual screen thing.
[01:14:50.340 --> 01:14:55.420]   That gesture of half opening the screen is a, is a, I think too much.
[01:14:55.420 --> 01:14:59.700]   You're not opening it up and being rude, but even if you open it halfway, it's still,
[01:14:59.700 --> 01:15:03.660]   you can see someone's peaking in their, it's worse.
[01:15:03.660 --> 01:15:08.100]   This week in Google, Damon Reel and Noah Reuben, their musicians.
[01:15:08.100 --> 01:15:10.940]   And they wanted to do a good thing for the public domain.
[01:15:10.940 --> 01:15:15.660]   So they generated every possible melody.
[01:15:15.660 --> 01:15:16.980]   It's like brute forcing it.
[01:15:16.980 --> 01:15:20.380]   And then they turned around and they put it in the creative commons.
[01:15:20.380 --> 01:15:21.380]   To it.
[01:15:21.380 --> 01:15:23.580]   Technology for your eyes and ear holes.
[01:15:24.580 --> 01:15:27.580]   I bet half those melodies are horrible.
[01:15:27.580 --> 01:15:31.700]   By the way, Sam Escobich stole a banana.
[01:15:31.700 --> 01:15:33.180]   Apparently this is his stick.
[01:15:33.180 --> 01:15:37.100]   This is not the first time he's tried to steal a banana from an Amazon ghost story.
[01:15:37.100 --> 01:15:39.500]   So I'm going to find out what Christina did.
[01:15:39.500 --> 01:15:40.860]   But that's coming up just a bit.
[01:15:40.860 --> 01:15:43.060]   First a word from our sponsor.
[01:15:43.060 --> 01:15:46.180]   He's going to be known, Sam's going to be known as the banana stealing guy.
[01:15:46.180 --> 01:15:49.540]   Like that's going to be your careful, Sam.
[01:15:49.540 --> 01:15:50.540]   Just careful.
[01:15:50.540 --> 01:15:53.260]   And you don't want to go down in history as the banana stealing guy.
[01:15:53.260 --> 01:15:56.420]   Here's a show that they brought to you by Kaptera.
[01:15:56.420 --> 01:15:58.140]   Oh man, everybody.
[01:15:58.140 --> 01:16:00.900]   I know, you know, I have such sympathy.
[01:16:00.900 --> 01:16:04.100]   We were the longest time in business.
[01:16:04.100 --> 01:16:07.180]   You know, you get a program and you run your business on it.
[01:16:07.180 --> 01:16:12.140]   Oftentimes a program was written by, you know, the boss's nephew who is home from college.
[01:16:12.140 --> 01:16:13.140]   Then he went off.
[01:16:13.140 --> 01:16:14.140]   He disappeared.
[01:16:14.140 --> 01:16:15.220]   He's living in Guatemala.
[01:16:15.220 --> 01:16:20.780]   And you're stuck with this broken ass piece of software that nobody likes.
[01:16:20.780 --> 01:16:22.900]   Fortunately, Kaptera exists.
[01:16:22.900 --> 01:16:23.900]   He went to Kaptera.
[01:16:23.900 --> 01:16:27.540]   It is the world's largest best directory of business software.
[01:16:27.540 --> 01:16:30.140]   Millions of people use it every month.
[01:16:30.140 --> 01:16:32.380]   Kaptera is a business ally.
[01:16:32.380 --> 01:16:36.420]   An online resource that helps you find the best software solution for your business.
[01:16:36.420 --> 01:16:41.700]   Whether it's CRM or video management, maybe you run a yoga studio.
[01:16:41.700 --> 01:16:43.980]   Yeah, they got a line of business software, a dog, grimer.
[01:16:43.980 --> 01:16:44.980]   It's all in there.
[01:16:44.980 --> 01:16:47.860]   700 categories of software.
[01:16:47.860 --> 01:16:51.940]   Every possible program, thousands of programs.
[01:16:51.940 --> 01:16:53.900]   The best part about Kaptera.
[01:16:53.900 --> 01:16:57.380]   There's over a million reviews of products from actual verified users.
[01:16:57.380 --> 01:16:59.220]   Kaptera vets everyone.
[01:16:59.220 --> 01:17:01.020]   And that means, look, here's brewery software.
[01:17:01.020 --> 01:17:02.540]   You want to start a brewery.
[01:17:02.540 --> 01:17:06.500]   So you're looking for a software program you can run.
[01:17:06.500 --> 01:17:10.860]   When you pick the category, the filter list is specific to that category.
[01:17:10.860 --> 01:17:13.740]   All of that stuff is in there and you can check the things you want.
[01:17:13.740 --> 01:17:15.820]   You could say, you know, I want it to be free.
[01:17:15.820 --> 01:17:16.820]   I want it to be on-prem.
[01:17:16.820 --> 01:17:17.820]   I want it to be in the cloud.
[01:17:17.820 --> 01:17:20.580]   I want it to, you know, all the features narrow it down.
[01:17:20.580 --> 01:17:23.140]   Then you can do a side-by-side comparison.
[01:17:23.140 --> 01:17:31.100]   There are, by the way, there are a lot of brewery programs out there to run breweries.
[01:17:31.100 --> 01:17:33.940]   And then, but then you go and you look at the reviews and that's where you're really
[01:17:33.940 --> 01:17:37.740]   going to get this amazing, unique, valuable resource.
[01:17:37.740 --> 01:17:39.500]   Millions of people use Kaptera every month.
[01:17:39.500 --> 01:17:41.820]   Oh, I left out the most important part.
[01:17:41.820 --> 01:17:43.460]   It's free.
[01:17:43.460 --> 01:17:44.540]   No charge.
[01:17:44.540 --> 01:17:46.040]   Not free-meum.
[01:17:46.040 --> 01:17:48.820]   No charge ever costs you nothing.
[01:17:48.820 --> 01:17:51.620]   And I think that's why there's so many reviews because I think people want to pay it forward.
[01:17:51.620 --> 01:17:53.660]   They get this great free resource.
[01:17:53.660 --> 01:17:54.820]   They use the reviews.
[01:17:54.820 --> 01:17:58.660]   They found great software and they want to tell people about it so they leave reviews
[01:17:58.660 --> 01:18:00.500]   or they want to tell people, don't use this.
[01:18:00.500 --> 01:18:01.500]   It's terrible.
[01:18:01.500 --> 01:18:02.860]   So they leave the review.
[01:18:02.860 --> 01:18:04.780]   That's what makes Kaptera special.
[01:18:04.780 --> 01:18:06.300]   You can do it right now for free.
[01:18:06.300 --> 01:18:08.060]   There's no special offer.
[01:18:08.060 --> 01:18:09.780]   I can't give you 20% off.
[01:18:09.780 --> 01:18:10.780]   It's free.
[01:18:10.780 --> 01:18:15.060]   But if you do me a favor, go to kaptera.com/twit, at least I'll know you saw it here.
[01:18:15.060 --> 01:18:20.060]   C-A-P-T-E-T-E-R-A, capterra.com/twit
[01:18:20.060 --> 01:18:24.340]   C-A-P-T-E-W-R-A.com/twit.
[01:18:24.340 --> 01:18:29.340]   Capterra is Software Selection Simplified.
[01:18:29.340 --> 01:18:32.780]   So you went to the, so this is not like
[01:18:32.780 --> 01:18:34.500]   the little convenience store.
[01:18:34.500 --> 01:18:37.300]   This is a 7,000 square foot grocery store.
[01:18:37.300 --> 01:18:41.200]   - Yeah, so this is more, I would say to like a trader Joes.
[01:18:41.200 --> 01:18:44.300]   So it's not as big as like a full size,
[01:18:44.300 --> 01:18:45.740]   like massive grocery store.
[01:18:45.740 --> 01:18:50.540]   And so it is literally across the street from where I live.
[01:18:50.540 --> 01:18:51.380]   So it's-
[01:18:51.380 --> 01:18:52.220]   - Oh, MG.
[01:18:52.220 --> 01:18:54.180]   So this could be your store.
[01:18:54.180 --> 01:18:55.020]   It's like-
[01:18:55.020 --> 01:18:55.860]   - It's going to be my store.
[01:18:55.860 --> 01:18:57.100]   - It's kind of like a sci-fi novel.
[01:18:57.100 --> 01:18:58.740]   There's nobody there.
[01:18:58.740 --> 01:18:59.940]   - Well, except there are.
[01:18:59.940 --> 01:19:00.820]   It was kind of bizarre.
[01:19:00.820 --> 01:19:02.460]   So I went, I didn't go the first day.
[01:19:02.460 --> 01:19:06.460]   I went the second day and it was packed, which I expected.
[01:19:06.460 --> 01:19:07.860]   There were a number of employees there.
[01:19:07.860 --> 01:19:08.860]   - There has to be.
[01:19:08.860 --> 01:19:10.500]   I mean, they have to stock it, right?
[01:19:10.500 --> 01:19:11.340]   I mean, it's not like-
[01:19:11.340 --> 01:19:12.180]   - It's stock it.
[01:19:12.180 --> 01:19:14.780]   - Also there was a thing because it was new.
[01:19:14.780 --> 01:19:16.100]   There was a bunch of kind of explanation
[01:19:16.100 --> 01:19:17.100]   for how people get in.
[01:19:17.100 --> 01:19:19.260]   So you have to have an app on your phone.
[01:19:19.260 --> 01:19:21.780]   You scan a QR code before you enter.
[01:19:21.780 --> 01:19:24.660]   And then you can go in.
[01:19:24.660 --> 01:19:28.060]   They have reusable bags where that you can fill up,
[01:19:28.060 --> 01:19:29.060]   walk around and-
[01:19:29.060 --> 01:19:32.140]   - It says grab a cart, bag is you shop,
[01:19:32.140 --> 01:19:34.180]   because you're not going to take them out of the bag.
[01:19:34.180 --> 01:19:35.940]   You're just going to walk out the door.
[01:19:35.940 --> 01:19:37.180]   - Exactly, exactly.
[01:19:37.180 --> 01:19:39.980]   - And the reason you could do that is look at the ceiling.
[01:19:39.980 --> 01:19:40.820]   - Yeah.
[01:19:40.820 --> 01:19:42.340]   - There's nothing but camera rays.
[01:19:42.340 --> 01:19:44.660]   - Cameras everywhere.
[01:19:44.660 --> 01:19:46.300]   - No, I thought it was great.
[01:19:46.300 --> 01:19:48.420]   So in my neighborhood, there is a QFC
[01:19:48.420 --> 01:19:51.740]   that's about 800 feet further away,
[01:19:51.740 --> 01:19:55.900]   which is usually pretty busy and has a mixed selection.
[01:19:55.900 --> 01:19:59.060]   There's also some kind of convenience stores and other things.
[01:19:59.060 --> 01:20:02.220]   This is genuinely like 200 feet from where I live.
[01:20:02.220 --> 01:20:04.780]   So this is going to be my new kind of go-to place.
[01:20:04.780 --> 01:20:06.340]   - So do you love it?
[01:20:06.340 --> 01:20:07.340]   I mean, you just-
[01:20:07.340 --> 01:20:08.180]   - I love it.
[01:20:08.180 --> 01:20:09.020]   - 'Cause you don't, it's like you walk in,
[01:20:09.020 --> 01:20:10.740]   you take it off the shelf and you leave.
[01:20:10.740 --> 01:20:11.580]   - Yeah.
[01:20:11.580 --> 01:20:13.900]   I mean, this is what I really liked about it.
[01:20:13.900 --> 01:20:15.700]   It was packed because so many people were there,
[01:20:15.700 --> 01:20:16.700]   I think, for the novelty of it.
[01:20:16.700 --> 01:20:18.060]   - But it won't be that way for them.
[01:20:18.060 --> 01:20:18.900]   - Yeah.
[01:20:18.900 --> 01:20:20.020]   - No, but this is what I liked.
[01:20:20.020 --> 01:20:21.260]   Even though it was packed, I mean,
[01:20:21.260 --> 01:20:24.020]   I just literally walked around, filled up what I wanted,
[01:20:24.020 --> 01:20:24.860]   and then walked out.
[01:20:24.860 --> 01:20:26.620]   I didn't have to wait in line, you know,
[01:20:26.620 --> 01:20:30.500]   like I would if I were at Trader Joe's or the QFC or whatever.
[01:20:30.500 --> 01:20:33.700]   - This is what life's going to be like after the zombie apocalypse.
[01:20:33.700 --> 01:20:36.060]   It's just going to be just going and you take what you want.
[01:20:36.060 --> 01:20:36.900]   - I do it.
[01:20:36.900 --> 01:20:37.780]   (laughing)
[01:20:37.780 --> 01:20:38.980]   - Yeah, which is imminent.
[01:20:38.980 --> 01:20:39.820]   Love you remind you.
[01:20:39.820 --> 01:20:41.580]   - Yeah, right, Mr. Prepper.
[01:20:41.580 --> 01:20:42.420]   - I have a question.
[01:20:42.420 --> 01:20:43.820]   What's the quality of the produce?
[01:20:43.820 --> 01:20:44.660]   Is it actually?
[01:20:44.660 --> 01:20:45.500]   - It's pretty good.
[01:20:45.500 --> 01:20:46.340]   - It's good.
[01:20:46.340 --> 01:20:47.180]   - You can eat it, is it?
[01:20:47.180 --> 01:20:48.020]   - Yes.
[01:20:48.020 --> 01:20:48.860]   - Is it?
[01:20:48.860 --> 01:20:49.700]   - It's a compromise.
[01:20:49.700 --> 01:20:50.540]   - It's a whole few foods.
[01:20:50.540 --> 01:20:52.380]   - Yes, this is what I was shocked by.
[01:20:52.380 --> 01:20:55.020]   So it's basically like a Trader Joe's but with name brand stuff.
[01:20:55.020 --> 01:20:58.020]   So, you know, I had like all of the, you know,
[01:20:58.020 --> 01:21:00.460]   like junk food that I would want,
[01:21:00.460 --> 01:21:02.580]   but then the produce was really good.
[01:21:02.580 --> 01:21:05.700]   - All the Swedish fish and gummy bears you can eat.
[01:21:05.700 --> 01:21:06.540]   Plus.
[01:21:06.540 --> 01:21:07.380]   - Yes, they did have Haribo, they did.
[01:21:07.380 --> 01:21:08.220]   - Oh boy.
[01:21:08.220 --> 01:21:11.740]   - They did have a little bit of my Doritos and cookie dough
[01:21:11.740 --> 01:21:12.860]   and things like that.
[01:21:12.860 --> 01:21:14.300]   But then the produce looked really good.
[01:21:14.300 --> 01:21:18.060]   The meat is kind of prepack, you know,
[01:21:18.060 --> 01:21:19.380]   it's sealed or whatever.
[01:21:19.380 --> 01:21:22.740]   Like they don't have a, obviously they don't have a butcher
[01:21:22.740 --> 01:21:23.580]   on site.
[01:21:23.580 --> 01:21:24.420]   But it looked good.
[01:21:24.420 --> 01:21:25.260]   It looked good.
[01:21:25.260 --> 01:21:27.700]   The produce was fresh and this was the second day.
[01:21:27.700 --> 01:21:29.340]   So I mean, we'll have to see how it holds up.
[01:21:29.340 --> 01:21:31.540]   But no, I mean, it was in good condition.
[01:21:31.540 --> 01:21:34.700]   They were already out of Cheez-Its, which I thought it was funny.
[01:21:34.700 --> 01:21:35.540]   - Of course.
[01:21:35.540 --> 01:21:37.060]   - Well, no, they had other varieties of Cheez-Its,
[01:21:37.060 --> 01:21:37.900]   but the original Cheez-Its,
[01:21:37.900 --> 01:21:39.340]   they were already sold out.
[01:21:39.340 --> 01:21:43.460]   So I'm interested to see like what the process will be
[01:21:43.460 --> 01:21:44.540]   of restocking.
[01:21:44.540 --> 01:21:46.780]   There was a bakery, like they don't obviously
[01:21:46.780 --> 01:21:48.900]   have a bakery on site, but they do have a bakery.
[01:21:48.900 --> 01:21:49.740]   - That looked cool.
[01:21:49.740 --> 01:21:50.580]   - Like the drainage.
[01:21:50.580 --> 01:21:52.100]   Do they, and they like put them in from behind.
[01:21:52.100 --> 01:21:53.700]   It's like an automat almost, right?
[01:21:53.700 --> 01:21:54.540]   - Yeah, yeah, yeah.
[01:21:54.540 --> 01:21:56.300]   So the donuts looked really good.
[01:21:56.300 --> 01:21:57.140]   I almost got one.
[01:21:57.140 --> 01:21:58.380]   I didn't.
[01:21:58.380 --> 01:21:59.220]   - Why not?
[01:21:59.220 --> 01:22:01.900]   You're having Doritos, gummy bears and Cheetos.
[01:22:01.900 --> 01:22:02.900]   Have a donut.
[01:22:02.900 --> 01:22:03.900]   (laughing)
[01:22:03.900 --> 01:22:06.340]   - I'll go back.
[01:22:06.340 --> 01:22:07.180]   - Please.
[01:22:07.180 --> 01:22:08.020]   - I mean, these are the things.
[01:22:08.020 --> 01:22:10.380]   This is literally gonna be, I mean, but I walk.
[01:22:10.380 --> 01:22:12.340]   No, when I walked back home, I was like,
[01:22:12.340 --> 01:22:14.380]   okay, this is my new grocery store.
[01:22:14.380 --> 01:22:15.740]   - Is this expensive?
[01:22:15.740 --> 01:22:17.940]   - No, you know, 'cause like Whole Foods has the--
[01:22:17.940 --> 01:22:20.060]   - Oh, no, see, this is the thing.
[01:22:20.060 --> 01:22:22.460]   And this is where right now knock on wood this last.
[01:22:22.460 --> 01:22:24.340]   It was cheaper.
[01:22:24.340 --> 01:22:26.900]   It was cheaper than anything.
[01:22:26.900 --> 01:22:28.900]   Like it was very inexpensive.
[01:22:28.900 --> 01:22:31.620]   Like I got like a bag of Doritos.
[01:22:31.620 --> 01:22:35.140]   I got some cupcakes, 'cause it was my husband's birthday.
[01:22:35.140 --> 01:22:38.100]   And I got something else.
[01:22:38.100 --> 01:22:39.900]   - I know why you like it.
[01:22:39.900 --> 01:22:43.900]   There's no clerk to go, oh, Doritos and Cheetos.
[01:22:43.900 --> 01:22:45.060]   (laughing)
[01:22:45.060 --> 01:22:46.500]   There's nobody judging you.
[01:22:46.500 --> 01:22:47.340]   Nobody judging you.
[01:22:47.340 --> 01:22:50.540]   - And studies have shown that we have self-service kiosks
[01:22:50.540 --> 01:22:52.260]   and fast food restaurants.
[01:22:52.260 --> 01:22:53.860]   That's exactly what happens.
[01:22:53.860 --> 01:22:58.180]   People actually buy more when they're just doing it
[01:22:58.180 --> 01:23:00.580]   from themselves and they think no one else is looking.
[01:23:00.580 --> 01:23:01.700]   - Wow. - Are they saving
[01:23:01.700 --> 01:23:02.860]   so much money though?
[01:23:02.860 --> 01:23:04.940]   I mean, how much does it cost to have?
[01:23:04.940 --> 01:23:06.500]   - Checkers.
[01:23:06.500 --> 01:23:08.340]   - Oh, I don't know if they're saving any money.
[01:23:08.340 --> 01:23:10.900]   - So it's not cheaper because it's cheaper to do this.
[01:23:10.900 --> 01:23:14.060]   - No, I think it's cheaper because they are competing
[01:23:14.060 --> 01:23:15.740]   with the other options in the neighborhood.
[01:23:15.740 --> 01:23:19.260]   And I mean, frankly, look, I order from Amazon Prime now
[01:23:19.260 --> 01:23:21.740]   way too often.
[01:23:21.740 --> 01:23:25.540]   And so this is now going to be more convenient than that
[01:23:25.540 --> 01:23:26.540]   or actually-- - Well, you know why else
[01:23:26.540 --> 01:23:30.300]   is cheaper because you're paying for it more than money.
[01:23:30.300 --> 01:23:31.300]   The data. - Yeah, oh yeah.
[01:23:31.300 --> 01:23:32.300]   They get all my information.
[01:23:32.300 --> 01:23:34.020]   - The data. - Totally.
[01:23:34.020 --> 01:23:39.020]   Just imagine if you're Nabisco and Amazon comes to you and says,
[01:23:39.020 --> 01:23:40.860]   I can tell you what percentage of customers
[01:23:40.860 --> 01:23:42.620]   look at your box, put it back on the shelf,
[01:23:42.620 --> 01:23:44.180]   what percentage of customers are reading,
[01:23:44.180 --> 01:23:46.540]   the ingredients put it back on the shelf.
[01:23:46.540 --> 01:23:50.700]   I could tell you a lot more about why you're not getting sales
[01:23:50.700 --> 01:23:52.900]   or why you are getting sales.
[01:23:52.900 --> 01:23:54.260]   - Oh, totally, without a doubt.
[01:23:54.260 --> 01:23:57.220]   And the thing is, look, I can understand the arguments
[01:23:57.220 --> 01:23:58.500]   for why this is problematic.
[01:23:58.500 --> 01:24:00.500]   I would say that, A, some of that information,
[01:24:00.500 --> 01:24:01.780]   the grocery stores are already getting.
[01:24:01.780 --> 01:24:02.940]   They might have-- - They've got cameras
[01:24:02.940 --> 01:24:05.020]   and every grocery store in the world.
[01:24:05.020 --> 01:24:06.860]   - They've been doing that for a long time.
[01:24:06.860 --> 01:24:10.020]   For more than 20 years, loyalty cards have a track
[01:24:10.020 --> 01:24:12.260]   of everything you buy based in these companies.
[01:24:12.260 --> 01:24:15.540]   So on one hand, plus I buy a lot of stuff from Amazon,
[01:24:15.540 --> 01:24:17.660]   either Amazon Fresh or Prime Now anyway,
[01:24:17.660 --> 01:24:20.180]   so they already had this stuff on me.
[01:24:20.180 --> 01:24:23.740]   But the convenience was there, I liked the store.
[01:24:23.740 --> 01:24:25.900]   The store is well laid out.
[01:24:25.900 --> 01:24:27.660]   They had a good question.
[01:24:27.660 --> 01:24:29.620]   Like, I'm really happy that it's there.
[01:24:29.620 --> 01:24:31.100]   I mean, it was funny.
[01:24:31.100 --> 01:24:34.100]   I saw the thing on GeekWire,
[01:24:34.100 --> 01:24:35.980]   and I saw the neighborhood, I was like, wait a minute.
[01:24:35.980 --> 01:24:37.700]   - Where is this? - That's Pike Street,
[01:24:37.700 --> 01:24:39.020]   right across from me.
[01:24:39.020 --> 01:24:41.540]   - And then I looked, I was like, holy crap.
[01:24:41.540 --> 01:24:45.300]   Because the thing is, is that this space had been,
[01:24:45.300 --> 01:24:46.860]   I guess, under construction for a while,
[01:24:46.860 --> 01:24:48.460]   what we didn't know, but it was.
[01:24:48.460 --> 01:24:50.980]   And so I genuinely had no idea what was going in there.
[01:24:50.980 --> 01:24:52.260]   - I would show you what-- - I would show you here.
[01:24:52.260 --> 01:24:53.420]   - I would show you here. - So it was the day
[01:24:53.420 --> 01:24:56.060]   that it launched was when we found out, like,
[01:24:56.060 --> 01:24:57.620]   oh, that's what's in the neighborhood.
[01:24:57.620 --> 01:24:59.620]   - And you know what, you don't need loyalty cards.
[01:24:59.620 --> 01:25:00.540]   You already have one.
[01:25:00.540 --> 01:25:01.780]   It's an Amazon customer.
[01:25:01.780 --> 01:25:03.780]   You have this, you've scanned the QR code
[01:25:03.780 --> 01:25:04.700]   when they come in the door.
[01:25:04.700 --> 01:25:08.820]   So you should get a little bit of a deal for that.
[01:25:08.820 --> 01:25:10.780]   - Probably. - Do we worry about,
[01:25:10.780 --> 01:25:12.940]   I mean, at least here in Petaluma,
[01:25:12.940 --> 01:25:14.660]   most of the baggers are high school kids.
[01:25:14.660 --> 01:25:16.220]   A lot of them I know, I'll see them.
[01:25:16.220 --> 01:25:19.260]   And it's an entry-level job for a lot of kids
[01:25:19.260 --> 01:25:21.700]   that those clerk jobs of people at the Petaluma market,
[01:25:21.700 --> 01:25:23.340]   they've been there for years.
[01:25:23.340 --> 01:25:25.780]   Those people are all gonna be out of work.
[01:25:25.780 --> 01:25:26.860]   - Yeah, it's interesting.
[01:25:26.860 --> 01:25:28.940]   So there were a lot of employees.
[01:25:28.940 --> 01:25:31.620]   One for, I think, just kind of looking around,
[01:25:31.620 --> 01:25:33.900]   maybe restocking things, making sure
[01:25:33.900 --> 01:25:36.460]   that when people do enter, they are using
[01:25:36.460 --> 01:25:37.660]   their QR code or whatever.
[01:25:37.660 --> 01:25:40.780]   But they also have a wine area and an alcohol area.
[01:25:40.780 --> 01:25:42.660]   And also, so if you wanna get NyQuil or a alcohol--
[01:25:42.660 --> 01:25:43.740]   - How do you get alcohol?
[01:25:43.740 --> 01:25:45.260]   You have to have a person for that, right?
[01:25:45.260 --> 01:25:46.100]   - Yes. - Yeah.
[01:25:46.100 --> 01:25:47.340]   - So there is a person who's in an area.
[01:25:47.340 --> 01:25:49.900]   It's kind of like a Costco where you have a little,
[01:25:49.900 --> 01:25:51.780]   like you have kind of a little area where you go up
[01:25:51.780 --> 01:25:55.420]   and you show them, like you're getting NyQuil,
[01:25:55.420 --> 01:25:56.500]   like you tell them that you want,
[01:25:56.500 --> 01:25:58.180]   you give them kind of a card, they give it for you,
[01:25:58.180 --> 01:26:01.700]   or you choose what wine or what other alcohol you want.
[01:26:01.700 --> 01:26:03.900]   So that is made by a human.
[01:26:03.900 --> 01:26:05.460]   Again, you're not doing the checkout,
[01:26:05.460 --> 01:26:07.260]   but that is human man.
[01:26:07.260 --> 01:26:10.660]   So there are people who work there, it's just less.
[01:26:10.660 --> 01:26:13.220]   And it is a valid question to say,
[01:26:13.220 --> 01:26:15.700]   what impact does this have on cashiers?
[01:26:15.700 --> 01:26:16.660]   The one thing I would say is,
[01:26:16.660 --> 01:26:19.980]   I think by the time this becomes mainstream enough
[01:26:19.980 --> 01:26:21.620]   and affordable enough where this can happen,
[01:26:21.620 --> 01:26:23.860]   'cause right now, I have to think that the infrastructure
[01:26:23.860 --> 01:26:26.100]   and the cost involved just in setting this up
[01:26:26.100 --> 01:26:29.260]   would be prohibitive for a lot of places to use.
[01:26:29.260 --> 01:26:31.460]   - This is not a plan to put 2,000 of these
[01:26:31.460 --> 01:26:33.460]   across the country, that's not what they're doing.
[01:26:33.460 --> 01:26:34.300]   - Right.
[01:26:34.300 --> 01:26:35.660]   - So hopefully at that point,
[01:26:35.660 --> 01:26:38.140]   we are in a better position with maybe upscaling workers
[01:26:38.140 --> 01:26:40.460]   and having other systems in place
[01:26:40.460 --> 01:26:43.580]   so that the jobs that are displaced,
[01:26:43.580 --> 01:26:45.700]   we have other things for people.
[01:26:45.700 --> 01:26:47.540]   Because it is a real concern.
[01:26:47.540 --> 01:26:50.580]   I just, I think that it's a longer term concern
[01:26:50.580 --> 01:26:52.300]   rather than something that's gonna happen immediately
[01:26:52.300 --> 01:26:55.660]   because this is not an inexpensive thing to put together.
[01:26:55.660 --> 01:26:56.860]   And I would think that most places,
[01:26:56.860 --> 01:26:58.300]   even like major grocery chains,
[01:26:58.300 --> 01:27:00.580]   the Kroger's and the Walmart's of the world,
[01:27:00.580 --> 01:27:02.540]   they'd have to look at, okay, how much would it cost
[01:27:02.540 --> 01:27:05.580]   for them to build that out and would it be worth,
[01:27:05.580 --> 01:27:08.500]   project how long would it be before it paid off,
[01:27:08.500 --> 01:27:09.900]   the hourly workers?
[01:27:09.900 --> 01:27:12.300]   - I'm looking at the Diet Coke ad
[01:27:12.300 --> 01:27:15.300]   next to the wine beer and spirits and it's so Seattle
[01:27:15.300 --> 01:27:18.740]   because you're living your best life.
[01:27:18.740 --> 01:27:19.820]   (laughs)
[01:27:19.820 --> 01:27:24.820]   - It was hilarious 'cause they had the good,
[01:27:24.820 --> 01:27:28.060]   what I call the cheap name brand kind of snacks
[01:27:28.060 --> 01:27:30.060]   and then they had the organic ones too
[01:27:30.060 --> 01:27:30.900]   for the candies and stuff.
[01:27:30.900 --> 01:27:34.140]   They had Reese's but then they had the super,
[01:27:34.140 --> 01:27:36.740]   the more expensive peanut butter cups.
[01:27:36.740 --> 01:27:37.860]   I'm like, who's gonna buy that?
[01:27:37.860 --> 01:27:39.300]   - You have to think that a lot of this,
[01:27:39.300 --> 01:27:42.220]   they learn from buying whole foods.
[01:27:42.220 --> 01:27:43.220]   - Totally.
[01:27:43.220 --> 01:27:45.420]   - This is a whole foodsy looking experience
[01:27:45.420 --> 01:27:48.900]   even if that's a wild, caught responsibly farmed organic
[01:27:48.900 --> 01:27:50.020]   poultry. - Again, like I said,
[01:27:50.020 --> 01:27:51.580]   it's very much like Trader Joe's
[01:27:51.580 --> 01:27:53.980]   is what I would compare it to more than Whole Foods.
[01:27:53.980 --> 01:27:55.860]   But with the exception being rather than having
[01:27:55.860 --> 01:27:57.500]   the Trader Joe's house brand,
[01:27:57.500 --> 01:27:59.940]   you have your craft and your, you know,
[01:27:59.940 --> 01:28:01.300]   - Don't let it.
[01:28:01.300 --> 01:28:02.940]   And how long before they have robots
[01:28:02.940 --> 01:28:05.340]   stocking the shelves, forget humans entirely.
[01:28:05.340 --> 01:28:06.940]   Just have a robot do it all.
[01:28:06.940 --> 01:28:08.940]   - That's a good question.
[01:28:08.940 --> 01:28:09.780]   - Yeah.
[01:28:09.780 --> 01:28:11.780]   - Well, you've already seen the other chains
[01:28:11.780 --> 01:28:14.300]   start to roll out similar.
[01:28:14.300 --> 01:28:16.660]   You were talking about, Christina was talking about Kroger.
[01:28:16.660 --> 01:28:20.860]   So the Kroger's in my areas most have the scanners
[01:28:20.860 --> 01:28:22.500]   that you can walk in, pick up.
[01:28:22.500 --> 01:28:23.340]   - Yeah, yes.
[01:28:23.340 --> 01:28:24.540]   - And you use those?
[01:28:24.540 --> 01:28:26.500]   - I actually use them.
[01:28:26.500 --> 01:28:29.140]   They tend to work because I hate putting everything
[01:28:29.140 --> 01:28:32.260]   in the cart and then getting everything out of the cart.
[01:28:32.260 --> 01:28:33.100]   - Yeah, right.
[01:28:33.100 --> 01:28:34.060]   - You know, at the checkout counter.
[01:28:34.060 --> 01:28:37.820]   So I will scan as I go along, leave everything in the cart,
[01:28:37.820 --> 01:28:39.740]   but you still have to go to the checkout,
[01:28:39.740 --> 01:28:41.820]   hit the thing and then pay.
[01:28:41.820 --> 01:28:45.980]   So, you know, I think this is the way most retail chains,
[01:28:45.980 --> 01:28:47.900]   like grocery stores will eventually go.
[01:28:47.900 --> 01:28:49.780]   You know, how long will it be before Amazon puts this
[01:28:49.780 --> 01:28:51.420]   in all the Whole Foods?
[01:28:51.420 --> 01:28:53.340]   - Except for certain areas, right?
[01:28:53.340 --> 01:28:54.580]   Yeah, it's going to be expensive,
[01:28:54.580 --> 01:28:56.180]   but as the cost comes down,
[01:28:56.180 --> 01:28:59.580]   I mean, they've got to be thinking about that.
[01:28:59.580 --> 01:29:00.940]   And then you have other retailers,
[01:29:00.940 --> 01:29:04.060]   whether it's Walmart or whether Kroger,
[01:29:04.060 --> 01:29:06.940]   looking at convenience, other convenience options.
[01:29:06.940 --> 01:29:10.260]   So Kroger has, you know, you can buy online
[01:29:10.260 --> 01:29:11.940]   and then either have it delivered.
[01:29:11.940 --> 01:29:12.780]   - And then schedule the delivery.
[01:29:12.780 --> 01:29:13.900]   - Or pick it up, right?
[01:29:13.900 --> 01:29:14.740]   Or pick it up.
[01:29:14.740 --> 01:29:16.300]   And so does Costco does that?
[01:29:16.300 --> 01:29:17.340]   Walmart's got Walmart plus.
[01:29:17.340 --> 01:29:18.180]   - That's the few things.
[01:29:18.180 --> 01:29:19.020]   - Yeah.
[01:29:19.020 --> 01:29:20.020]   - There's fewer and fewer people.
[01:29:20.020 --> 01:29:23.060]   - I feel like I'm in kind of a cranky mood this week,
[01:29:23.060 --> 01:29:25.460]   but I just feel like I'm a little tired
[01:29:25.460 --> 01:29:29.420]   of the dehumanization of these big, like grocery stores,
[01:29:29.420 --> 01:29:31.940]   airports, you know, fast food.
[01:29:31.940 --> 01:29:34.100]   Everything is being dehumanized.
[01:29:34.100 --> 01:29:37.580]   And I'm just confronted with iPads and tablets.
[01:29:37.580 --> 01:29:38.420]   - I agree with you.
[01:29:38.420 --> 01:29:39.260]   - I agree with you.
[01:29:39.260 --> 01:29:41.220]   - Okay, but Mike, are you saying seriously,
[01:29:41.220 --> 01:29:43.060]   genuinely you don't use Fresh Direct?
[01:29:43.060 --> 01:29:45.980]   - No, of course I occasionally use it.
[01:29:45.980 --> 01:29:48.020]   I try not to try to go to the co-op.
[01:29:49.020 --> 01:29:50.620]   - You know, and that's not the worst thing.
[01:29:50.620 --> 01:29:53.260]   - You're the guy who brings the cloth sack
[01:29:53.260 --> 01:29:56.100]   and does the bulk rice and the thing.
[01:29:56.100 --> 01:29:56.940]   - Oh, definitely.
[01:29:56.940 --> 01:29:58.260]   And now we have to, you know,
[01:29:58.260 --> 01:30:00.620]   they got rid of plastic bags across New York.
[01:30:00.620 --> 01:30:01.700]   - You got a little paper bags,
[01:30:01.700 --> 01:30:03.740]   get a little paper bag, you put your mocha on.
[01:30:03.740 --> 01:30:04.580]   - What I'm happy about.
[01:30:04.580 --> 01:30:05.780]   - It was like, okay,
[01:30:05.780 --> 01:30:06.820]   'cause like my grocery store,
[01:30:06.820 --> 01:30:08.420]   when I lived in Brooklyn, was terrible.
[01:30:08.420 --> 01:30:09.540]   Like it was awful.
[01:30:09.540 --> 01:30:12.460]   So I used Fresh Direct A, I lived on the third floor
[01:30:12.460 --> 01:30:14.420]   and I didn't want to have to climb up three stairs,
[01:30:14.420 --> 01:30:15.420]   three flights of stairs,
[01:30:15.420 --> 01:30:16.900]   every time I'd go to the grocery store,
[01:30:16.900 --> 01:30:18.500]   if I had to take a, you know,
[01:30:18.500 --> 01:30:20.460]   the subway or whatever to Whole Foods.
[01:30:20.460 --> 01:30:22.580]   So like, I used Fresh Direct.
[01:30:22.580 --> 01:30:25.540]   - Are you ready for a spine chilling fact?
[01:30:25.540 --> 01:30:31.220]   The day that store opened in Seattle and you went in
[01:30:31.220 --> 01:30:32.740]   and said, "Oh, it's like a Trader Joe's."
[01:30:32.740 --> 01:30:35.260]   The original Trader Joe passed away.
[01:30:35.260 --> 01:30:36.100]   - I saw that.
[01:30:36.100 --> 01:30:41.100]   - Joe Colum, that's age 89, passed away February 28th.
[01:30:41.100 --> 01:30:42.220]   He was the guy who founded it.
[01:30:42.220 --> 01:30:44.100]   There was a Trader Joe, it was Joe.
[01:30:44.100 --> 01:30:45.460]   Joe Colum, co-op.
[01:30:45.460 --> 01:30:47.220]   Thanks for Chubuk Chuk, Joe.
[01:30:47.220 --> 01:30:48.940]   - Thanks for Chubuk Chuk.
[01:30:48.940 --> 01:30:50.940]   Now that actually was Chuck Harrison
[01:30:50.940 --> 01:30:52.740]   who invented that one.
[01:30:52.740 --> 01:30:53.580]   No, I don't know.
[01:30:53.580 --> 01:30:54.580]   Yeah, anyway--
[01:30:54.580 --> 01:30:56.060]   - No, Chubuk Chuk was because they would have
[01:30:56.060 --> 01:30:57.940]   like the cheap wine at Trader Joe's.
[01:30:57.940 --> 01:30:58.780]   - No, I know.
[01:30:58.780 --> 01:31:00.340]   - Charles Shaw, I got a lot.
[01:31:00.340 --> 01:31:04.340]   - I had bought quite a bit of Chubuk Chuk in my job.
[01:31:04.340 --> 01:31:06.820]   - Well, you know, I think Michael brings up a really good
[01:31:06.820 --> 01:31:10.980]   point about the dehumanization of our lives in general.
[01:31:10.980 --> 01:31:14.380]   Not just from like you said with kids and jobs
[01:31:14.380 --> 01:31:19.100]   and filling those kind of low skill entry level positions.
[01:31:19.100 --> 01:31:22.500]   But also there are a lot of people who are elderly,
[01:31:22.500 --> 01:31:26.180]   people who don't work, people who don't come into contact
[01:31:26.180 --> 01:31:29.140]   with a lot of other people on a face-to-face basis
[01:31:29.140 --> 01:31:32.260]   on a regular basis.
[01:31:32.260 --> 01:31:34.340]   And so going to the grocery store
[01:31:34.340 --> 01:31:36.420]   and talking to someone at the checkout,
[01:31:36.420 --> 01:31:39.980]   interacting with someone at a fast food restaurant,
[01:31:39.980 --> 01:31:42.220]   fast casual, whatever, coffee shop,
[01:31:42.220 --> 01:31:44.940]   that may be their only chance to actually interact
[01:31:44.940 --> 01:31:46.060]   with a human.
[01:31:46.060 --> 01:31:48.460]   And as we remove those people, you know,
[01:31:48.460 --> 01:31:51.420]   the checkout people, the waiters, whatever,
[01:31:51.420 --> 01:31:54.140]   it continues to sort of isolate people.
[01:31:54.140 --> 01:31:57.940]   And I do really worry, maybe not next year,
[01:31:57.940 --> 01:31:59.820]   maybe not five years, 10 years,
[01:31:59.820 --> 01:32:02.740]   but as you get 20, 30, 40 years, you know,
[01:32:02.740 --> 01:32:05.740]   that isolation that sort of people feel becomes greater
[01:32:05.740 --> 01:32:07.620]   and greater because, you know,
[01:32:07.620 --> 01:32:09.500]   the machines do everything for us.
[01:32:09.500 --> 01:32:10.580]   - It's funny that you should talk,
[01:32:10.580 --> 01:32:12.140]   I've been thinking a lot about that lady.
[01:32:12.140 --> 01:32:13.300]   I think it's the disease,
[01:32:13.300 --> 01:32:15.220]   and it's not the disease of the 21st century,
[01:32:15.220 --> 01:32:17.020]   it's the disease of the last century,
[01:32:17.020 --> 01:32:18.580]   where people have been spread out,
[01:32:18.580 --> 01:32:21.380]   we no longer live in tribal communities,
[01:32:21.380 --> 01:32:23.460]   families are spread out all over the country.
[01:32:23.460 --> 01:32:26.540]   Your family's not near Seattle, right, Christina?
[01:32:26.540 --> 01:32:27.380]   - No, they're in Atlanta.
[01:32:27.380 --> 01:32:30.620]   - Yeah, and we don't have church,
[01:32:30.620 --> 01:32:33.340]   we don't have a social group anymore,
[01:32:33.340 --> 01:32:35.540]   and more and more, we're working at home,
[01:32:35.540 --> 01:32:37.500]   we're shopping in an empty store.
[01:32:37.500 --> 01:32:39.100]   I do feel like we're kind of moving,
[01:32:39.100 --> 01:32:41.380]   and this is not how our biology is designed.
[01:32:41.380 --> 01:32:43.940]   We're gregarious animals, we're social animals.
[01:32:43.940 --> 01:32:48.060]   And I don't think Facebook and Twitter is a replacement for that.
[01:32:48.060 --> 01:32:52.140]   - No, and furthermore, like we're diving deeper and deeper
[01:32:52.140 --> 01:32:53.540]   into these digital lives,
[01:32:53.540 --> 01:32:55.980]   so things like Fortnite and Minecraft,
[01:32:55.980 --> 01:32:57.940]   soon virtual reality, you know,
[01:32:57.940 --> 01:33:01.540]   we're going to be socializing in digital spaces,
[01:33:01.540 --> 01:33:05.380]   and I think there will be fewer and fewer human interactions,
[01:33:05.380 --> 01:33:09.540]   and so, you know, again, I sound so cranky,
[01:33:09.540 --> 01:33:13.020]   and typically I'm one to advocate for technology,
[01:33:13.020 --> 01:33:15.500]   and I generally have an optimistic view of these things,
[01:33:15.500 --> 01:33:17.460]   and of course, you know, the convenience of
[01:33:17.460 --> 01:33:19.780]   walking into a grocery store and walking out with my groceries
[01:33:19.780 --> 01:33:24.140]   is great, but I can't help but think about
[01:33:24.140 --> 01:33:27.700]   the societal change that's happening right before us,
[01:33:27.700 --> 01:33:30.180]   you know, there are, you know,
[01:33:30.180 --> 01:33:35.020]   I grew up working class and I feel like I just identify
[01:33:35.020 --> 01:33:39.420]   with those types of workers, and I think, you know,
[01:33:39.420 --> 01:33:42.460]   I'm a little bit worried about, you know,
[01:33:42.460 --> 01:33:46.260]   I think right now, you know, this grocery store is not going to
[01:33:46.260 --> 01:33:49.140]   like, you know, I don't think it'll have a huge impact,
[01:33:49.140 --> 01:33:51.300]   but, and there's no way to stop this either, right?
[01:33:51.300 --> 01:33:53.940]   If Amazon's not doing this, you know, McDonald's or Starbucks
[01:33:53.940 --> 01:33:57.940]   or some other company will find a way to implement
[01:33:57.940 --> 01:34:00.860]   this type of technology, so I think, you know,
[01:34:00.860 --> 01:34:04.060]   Amazon ushering in this change is just kind of indicative
[01:34:04.060 --> 01:34:06.620]   of like the time that we're in, but I just,
[01:34:06.620 --> 01:34:11.260]   I worry about the thousands or millions of workers
[01:34:11.260 --> 01:34:14.140]   and people that, you know, find meaning in their life
[01:34:14.140 --> 01:34:17.060]   through social interaction and through their work,
[01:34:17.060 --> 01:34:19.980]   and like, you know, a grocery bagging is,
[01:34:19.980 --> 01:34:23.380]   or working at the local grocery store is,
[01:34:23.380 --> 01:34:27.180]   has long been part of just like a traditional American life
[01:34:27.180 --> 01:34:29.140]   or like a traditional working class life,
[01:34:29.140 --> 01:34:32.820]   and I think that as that goes away, like, you know,
[01:34:32.820 --> 01:34:35.660]   I worry about what happens to those people
[01:34:35.660 --> 01:34:38.300]   and how we integrate them into society,
[01:34:38.300 --> 01:34:40.860]   because often those people are the ones that are,
[01:34:40.860 --> 01:34:42.340]   you know, while we sit here and talk about
[01:34:42.340 --> 01:34:47.340]   all of this technology, Teslas and iOS and all of these,
[01:34:47.340 --> 01:34:51.220]   and AirPods, you know, I often try to remind myself
[01:34:51.220 --> 01:34:53.780]   that there's a huge swath of Americans
[01:34:53.780 --> 01:34:55.900]   and then an even bigger swath of the world
[01:34:55.900 --> 01:34:58.060]   that doesn't have access to that technology.
[01:34:58.060 --> 01:35:00.340]   - So that's why we're bringing them to the internet,
[01:35:00.340 --> 01:35:02.980]   so they too can be isolated alone and sad.
[01:35:04.260 --> 01:35:05.940]   That's our mission.
[01:35:05.940 --> 01:35:07.620]   - Yeah, yeah, exactly.
[01:35:07.620 --> 01:35:10.140]   - Yeah, I mean, well, and I try to remember that.
[01:35:10.140 --> 01:35:12.220]   - I feel more sad for us than the rest of the world
[01:35:12.220 --> 01:35:14.900]   that isn't so plugged in sometimes, you know?
[01:35:14.900 --> 01:35:17.100]   - So connected, I know, you know, it comes in waves.
[01:35:17.100 --> 01:35:19.220]   Like, no, no, I mean, obviously it's awesome.
[01:35:19.220 --> 01:35:22.660]   The technology's great, and I'm really happy for all the--
[01:35:22.660 --> 01:35:23.900]   - It's a mixed bag.
[01:35:23.900 --> 01:35:26.420]   It's not universally bad, it's not universally good.
[01:35:26.420 --> 01:35:29.260]   I think that's always the conclusion we come to,
[01:35:29.260 --> 01:35:31.100]   but I do think we are suffering a little bit
[01:35:31.100 --> 01:35:33.380]   as a society from this.
[01:35:33.380 --> 01:35:34.980]   - I'm just saying, I'm just really glad
[01:35:34.980 --> 01:35:36.540]   that I have a good grocery store in the neighborhood.
[01:35:36.540 --> 01:35:38.100]   (laughing)
[01:35:38.100 --> 01:35:39.940]   - Is it a talking about data?
[01:35:39.940 --> 01:35:42.220]   - Is it, are people, you know,
[01:35:42.220 --> 01:35:44.100]   is there any sort of backlash or the protests
[01:35:44.100 --> 01:35:46.260]   or are people excited about this?
[01:35:46.260 --> 01:35:47.260]   - I mean, it was packed.
[01:35:47.260 --> 01:35:49.500]   I mean, look, it's Seattle, I'm sure that there's backlash
[01:35:49.500 --> 01:35:52.660]   and there's protest, but also even though it's Capitol Hill,
[01:35:52.660 --> 01:35:54.580]   that's an area that has changed tremendously
[01:35:54.580 --> 01:35:58.380]   over the last few years, and I'm definitely one of the people
[01:35:58.380 --> 01:36:00.740]   who is to blame for that.
[01:36:00.740 --> 01:36:02.780]   So, I mean, yeah.
[01:36:02.780 --> 01:36:04.860]   - You're at, what do they call them?
[01:36:04.860 --> 01:36:07.260]   Yuppies, no, dinks, you're a dink.
[01:36:07.260 --> 01:36:10.020]   - Yeah, I totally get total dink, no kid.
[01:36:10.020 --> 01:36:12.300]   And, you know, but I'm a tech worker
[01:36:12.300 --> 01:36:15.100]   and as are most of my neighbors,
[01:36:15.100 --> 01:36:18.140]   and yeah, we're completely to blame for the fall
[01:36:18.140 --> 01:36:21.500]   of kind of, you know, the Capitol Hill part of,
[01:36:21.500 --> 01:36:23.700]   you know, kind of the historical part of it.
[01:36:23.700 --> 01:36:24.540]   - It's just modern times.
[01:36:24.540 --> 01:36:25.380]   - It's just as what it is.
[01:36:25.380 --> 01:36:26.900]   - I did it to Brooklyn, I'm doing it to Seattle.
[01:36:26.900 --> 01:36:27.740]   - Thank you.
[01:36:27.740 --> 01:36:28.580]   - Oh, you're the--
[01:36:28.580 --> 01:36:30.340]   - I accept my blame in this role,
[01:36:30.340 --> 01:36:31.220]   but-- - The typhoid Mary
[01:36:31.220 --> 01:36:32.740]   of gentrification, that's you.
[01:36:32.740 --> 01:36:35.260]   - Basically, I mean, and it's not that I don't have,
[01:36:35.260 --> 01:36:37.300]   like, I feel guilt, I felt more guilt and, okay,
[01:36:37.300 --> 01:36:39.100]   here's the deal, I felt a way more guilt
[01:36:39.100 --> 01:36:42.220]   about my gentrification in Brooklyn than I do in Seattle.
[01:36:42.220 --> 01:36:45.460]   Seattle, I'm like, this was already on the way,
[01:36:45.460 --> 01:36:48.180]   whereas my prospect heights, I definitely felt
[01:36:48.180 --> 01:36:49.780]   like I was patient zero, but--
[01:36:49.780 --> 01:36:51.340]   (laughing)
[01:36:51.340 --> 01:36:54.260]   - Oh, no, no, no, there's other people in the world
[01:36:54.260 --> 01:36:55.100]   who are-- - Well, that's too large.
[01:36:55.100 --> 01:36:56.740]   - You can't take all the, all the--
[01:36:56.740 --> 01:36:58.660]   - I'm just saying, but it is interesting,
[01:36:58.660 --> 01:37:00.020]   I haven't really heard much backlash,
[01:37:00.020 --> 01:37:01.380]   and then there were tons of people there,
[01:37:01.380 --> 01:37:04.220]   and I will say, it's not like this is the only place
[01:37:04.220 --> 01:37:06.460]   the neighborhood you can go, you can go more places,
[01:37:06.460 --> 01:37:10.140]   this just is particularly convenient for me,
[01:37:10.140 --> 01:37:11.780]   so I'm happy about that.
[01:37:11.780 --> 01:37:14.540]   And it's strange to me that you said
[01:37:14.540 --> 01:37:16.260]   they quietly built this thing, you know,
[01:37:16.260 --> 01:37:17.580]   this was a construction site--
[01:37:17.580 --> 01:37:18.420]   - Isn't that interesting?
[01:37:18.420 --> 01:37:19.340]   - They didn't really know it was gonna be there.
[01:37:19.340 --> 01:37:22.340]   - Why do you think they did that so anonymously, right?
[01:37:22.340 --> 01:37:24.300]   - It rubs me the wrong way a little bit,
[01:37:24.300 --> 01:37:27.980]   'cause, you know, there's no transparency to the neighbors,
[01:37:27.980 --> 01:37:29.620]   you know, what if you didn't like this thing,
[01:37:29.620 --> 01:37:31.060]   and what if it was a disaster?
[01:37:31.060 --> 01:37:33.340]   - I'm sure that if you, I'm sure that if I looked
[01:37:33.340 --> 01:37:37.980]   into the records and maybe query the--
[01:37:37.980 --> 01:37:40.620]   - But normally, you know, they put a big banner up,
[01:37:40.620 --> 01:37:43.260]   coming soon, Amazon go, grocery store,
[01:37:43.260 --> 01:37:44.980]   they don't wanna do that, yeah.
[01:37:44.980 --> 01:37:46.740]   They don't wanna track the attention.
[01:37:46.740 --> 01:37:48.380]   - Right, I was gonna say, I think that that was more
[01:37:48.380 --> 01:37:50.860]   of a nada, we're afraid of the backlash,
[01:37:50.860 --> 01:37:54.420]   because the reality is, it's like, the building that I live in,
[01:37:54.420 --> 01:37:56.940]   I would say the majority of the people
[01:37:56.940 --> 01:37:59.060]   who live there probably work at Amazon,
[01:37:59.060 --> 01:38:01.980]   and then the rest of people either work at Microsoft
[01:38:01.980 --> 01:38:05.220]   or at Google, but, and it's, I'm mean serious
[01:38:05.220 --> 01:38:07.940]   when I say that probably 95% of the people
[01:38:07.940 --> 01:38:10.620]   who live in my building work at one of those three companies,
[01:38:10.620 --> 01:38:13.020]   and so, and we're across the street,
[01:38:13.020 --> 01:38:14.500]   and we're not the only apartment complex,
[01:38:14.500 --> 01:38:17.100]   there are a bunch of other high rises in the area too,
[01:38:17.100 --> 01:38:22.060]   so you have a lot of those employees very close by,
[01:38:22.060 --> 01:38:24.100]   so I don't think that it was,
[01:38:24.100 --> 01:38:26.740]   we're not wanting to get the backlash,
[01:38:26.740 --> 01:38:28.300]   I think it was, this is a--
[01:38:28.300 --> 01:38:29.140]   - It's just like part of the culture.
[01:38:29.140 --> 01:38:30.500]   - The height, you know, we wanna be able to just,
[01:38:30.500 --> 01:38:32.300]   exactly we wanna be able to just drop the bonds,
[01:38:32.300 --> 01:38:34.100]   and say, hey, and this thing is available now,
[01:38:34.100 --> 01:38:35.580]   and you can come in and shop.
[01:38:35.580 --> 01:38:37.580]   - Coming soon, but don't apply for a job
[01:38:37.580 --> 01:38:39.020]   'cause there aren't none.
[01:38:39.020 --> 01:38:40.540]   (laughing)
[01:38:40.540 --> 01:38:42.180]   - Like I said, there were a lot of employees working,
[01:38:42.180 --> 01:38:43.460]   I don't know how often they're,
[01:38:43.460 --> 01:38:44.620]   what their shifts things will be,
[01:38:44.620 --> 01:38:46.900]   but I was actually shocked by the number of employees
[01:38:46.900 --> 01:38:48.780]   who were in the store, it was the second day,
[01:38:48.780 --> 01:38:50.580]   but that's what I'm gonna kinda keep an eye on
[01:38:50.580 --> 01:38:52.620]   as I go in more frequently is what,
[01:38:52.620 --> 01:38:53.900]   how many employees are working,
[01:38:53.900 --> 01:38:56.380]   because I will say, there were certainly,
[01:38:57.300 --> 01:38:58.780]   fewer employees than you would have,
[01:38:58.780 --> 01:39:01.940]   I guess if you had full checkout counters,
[01:39:01.940 --> 01:39:04.420]   although sometimes I'll go to the bigger grocery stores,
[01:39:04.420 --> 01:39:07.300]   and it's not as if the checkout lands are all open anyway,
[01:39:07.300 --> 01:39:08.620]   so, you know.
[01:39:08.620 --> 01:39:09.460]   - Right, right.
[01:39:09.460 --> 01:39:11.140]   - Rain's 15. - Yeah, I mean,
[01:39:11.140 --> 01:39:13.140]   it's interesting to me that to one,
[01:39:13.140 --> 01:39:15.060]   where Amazon and other companies choose
[01:39:15.060 --> 01:39:16.980]   to run these experiments,
[01:39:16.980 --> 01:39:19.420]   and two, how different cities react,
[01:39:19.420 --> 01:39:21.940]   or how cities react to them differently.
[01:39:21.940 --> 01:39:24.980]   So I wonder if Amazon tried to open a grocery store
[01:39:24.980 --> 01:39:26.580]   like this in New York,
[01:39:26.580 --> 01:39:29.420]   my guess is that there would be a little bit of a,
[01:39:29.420 --> 01:39:30.620]   - Depending on the neighborhood, totally,
[01:39:30.620 --> 01:39:31.780]   because you have bodega, right?
[01:39:31.780 --> 01:39:33.140]   Like you have those systems,
[01:39:33.140 --> 01:39:35.540]   like we have a bodega that's not that far,
[01:39:35.540 --> 01:39:36.660]   that's close to the convention center,
[01:39:36.660 --> 01:39:39.220]   and it's fine, but like it closes fairly early,
[01:39:39.220 --> 01:39:41.300]   and it doesn't have a lot of things,
[01:39:41.300 --> 01:39:43.580]   so really most people are going to a QFC,
[01:39:43.580 --> 01:39:46.220]   which is owned by Kroger, a Whole Foods,
[01:39:46.220 --> 01:39:48.500]   or a Trader Joe's, those are your options,
[01:39:48.500 --> 01:39:49.620]   or you're going a little bit further
[01:39:49.620 --> 01:39:50.820]   and going to a safe way.
[01:39:50.820 --> 01:39:52.820]   So, you know, to me, it's like,
[01:39:52.820 --> 01:39:54.820]   I don't have a local option,
[01:39:54.820 --> 01:39:57.140]   but this is smaller and close.
[01:39:57.140 --> 01:40:00.780]   - And Seattle is like, it's well acquainted
[01:40:00.780 --> 01:40:02.060]   with all these big tech companies
[01:40:02.060 --> 01:40:03.540]   and all of their different experiments, right?
[01:40:03.540 --> 01:40:05.540]   Like you said, like, you know, given your,
[01:40:05.540 --> 01:40:06.900]   the building that you live in,
[01:40:06.900 --> 01:40:09.900]   and I think just even in terms of number of people employed
[01:40:09.900 --> 01:40:11.700]   by big tech in Seattle,
[01:40:11.700 --> 01:40:16.700]   my guess is that people have more favorable opinions
[01:40:16.700 --> 01:40:20.220]   than like, you know, Amazon in particular in New York
[01:40:20.220 --> 01:40:23.220]   is still kind of--
[01:40:23.220 --> 01:40:26.100]   - Oh yeah, we have an Seattle too, it's just different.
[01:40:26.100 --> 01:40:27.100]   It's just different.
[01:40:27.100 --> 01:40:29.540]   It's a weird thing where they're a big employer,
[01:40:29.540 --> 01:40:31.860]   but there is still a very vocal contingent of people
[01:40:31.860 --> 01:40:35.060]   who are unhappy with the role of big tech.
[01:40:35.060 --> 01:40:37.300]   It's just, it's a weird dichotomy
[01:40:37.300 --> 01:40:38.420]   where you have a lot of people
[01:40:38.420 --> 01:40:40.020]   who are very vocally against it,
[01:40:40.020 --> 01:40:43.020]   who are also in some ways directly or indirectly
[01:40:43.020 --> 01:40:44.180]   employed by these places.
[01:40:44.180 --> 01:40:45.740]   It's an interesting difference,
[01:40:45.740 --> 01:40:47.260]   but you're right, I think in New York,
[01:40:47.260 --> 01:40:48.460]   this would be harder.
[01:40:48.460 --> 01:40:49.660]   Not to say that it wouldn't happen,
[01:40:49.660 --> 01:40:51.740]   and I do think that in some parts of Manhattan,
[01:40:51.740 --> 01:40:53.980]   in particular, it would be easier in Manhattan.
[01:40:53.980 --> 01:40:55.340]   I think this would be hard in Queens.
[01:40:55.340 --> 01:40:57.100]   I think this would be hard in Brooklyn.
[01:40:57.100 --> 01:40:58.620]   I think this would be hard in the Bronx,
[01:40:58.620 --> 01:41:00.180]   but I think in Manhattan,
[01:41:00.180 --> 01:41:02.660]   this would be something with especially certain parts,
[01:41:02.660 --> 01:41:05.900]   like Chelsea, I don't think you would get a lot of backlash.
[01:41:05.900 --> 01:41:07.340]   - I totally agree with you there.
[01:41:07.340 --> 01:41:08.180]   I totally agree.
[01:41:08.180 --> 01:41:11.980]   And that's near where they decided to run Amazon Go,
[01:41:11.980 --> 01:41:13.140]   the smaller version of this.
[01:41:13.140 --> 01:41:15.540]   So you're totally right.
[01:41:15.540 --> 01:41:17.540]   And I don't know, yeah, I'm serious.
[01:41:17.540 --> 01:41:19.820]   I would absolutely shop there if I had the opportunity.
[01:41:19.820 --> 01:41:21.020]   - For all the negatives,
[01:41:21.020 --> 01:41:22.580]   I would love to have one.
[01:41:22.580 --> 01:41:23.420]   (laughing)
[01:41:23.420 --> 01:41:24.260]   - I know, yeah, exactly.
[01:41:24.260 --> 01:41:25.340]   That's exactly how I feel.
[01:41:25.340 --> 01:41:28.100]   - I would wait in line and pay for this,
[01:41:28.100 --> 01:41:29.860]   like if it was a traditional checkout thing,
[01:41:29.860 --> 01:41:31.140]   I still would want to shop here.
[01:41:31.140 --> 01:41:32.340]   Like that was the thing I took away.
[01:41:32.340 --> 01:41:34.740]   I was like, this is a well laid out grocery store
[01:41:34.740 --> 01:41:36.900]   that has all my brands, it has good prices
[01:41:36.900 --> 01:41:38.580]   that is convenient to where I live.
[01:41:38.580 --> 01:41:40.620]   I would wait in line and pay, like to me,
[01:41:40.620 --> 01:41:44.100]   it's just this added like benefit that I can just walk out.
[01:41:44.100 --> 01:41:46.020]   So I'm--
[01:41:46.020 --> 01:41:47.700]   - What's the worst part of a grocery store?
[01:41:47.700 --> 01:41:48.780]   For me, it's not the lines.
[01:41:48.780 --> 01:41:50.620]   For me, it's finding the things that I want.
[01:41:50.620 --> 01:41:52.020]   I can never-- - You go to the wrong grocery store.
[01:41:52.020 --> 01:41:52.860]   - Actually having a terrible line.
[01:41:52.860 --> 01:41:54.980]   - It's terrible at our grocery store.
[01:41:54.980 --> 01:41:56.780]   - Oh, I've never had issues with the lines.
[01:41:56.780 --> 01:41:58.820]   So I don't-- - You shopping, nine AM.
[01:41:58.820 --> 01:42:01.940]   - No, no, I shop in the evenings, you know that's fine.
[01:42:01.940 --> 01:42:04.820]   - Yeah, that's when everybody's there, buying dinner.
[01:42:04.820 --> 01:42:06.060]   (laughing)
[01:42:06.060 --> 01:42:07.340]   - With me, with me.
[01:42:07.340 --> 01:42:08.180]   - Yeah, with you.
[01:42:08.180 --> 01:42:09.740]   - And also, I'm a very patient person,
[01:42:09.740 --> 01:42:11.220]   so I'm happy to wait in a line.
[01:42:11.220 --> 01:42:12.900]   You know, I'm listening to my music.
[01:42:12.900 --> 01:42:14.980]   - To put it perspective, I mean, clearly Amazon's goal
[01:42:14.980 --> 01:42:17.540]   is not because we want to reinvent grocery shopping.
[01:42:17.540 --> 01:42:19.460]   That seems like a very kind of small goal
[01:42:19.460 --> 01:42:21.020]   for somebody like Jeff Bezos.
[01:42:21.020 --> 01:42:22.220]   It's about the data.
[01:42:22.220 --> 01:42:23.980]   And to put that in perspective,
[01:42:23.980 --> 01:42:26.740]   big, big acquisition this week,
[01:42:26.740 --> 01:42:29.740]   Intuit bought Credit Karma, an app.
[01:42:29.740 --> 01:42:30.580]   - It's a billion.
[01:42:30.580 --> 01:42:33.780]   - For seven billion dollars.
[01:42:33.780 --> 01:42:36.020]   Now, what Credit Karma's app, it's a free app,
[01:42:36.020 --> 01:42:37.580]   so there's not a lot of money to be made.
[01:42:37.580 --> 01:42:39.900]   You're not gonna make seven billion back.
[01:42:39.900 --> 01:42:42.460]   Credit Karma makes its money by offering you
[01:42:42.460 --> 01:42:44.860]   credit card numbers, credit card offers,
[01:42:44.860 --> 01:42:47.740]   things like that, that they get some affiliate fees from.
[01:42:47.740 --> 01:42:51.860]   But what Credit Karma does have is a lot of financial data.
[01:42:51.860 --> 01:42:53.940]   You go to Credit Karma, you put in your financial data,
[01:42:53.940 --> 01:42:55.900]   they give you your credit score,
[01:42:55.900 --> 01:43:00.180]   they have 110 million users,
[01:43:00.180 --> 01:43:03.380]   and they know all of their financial information.
[01:43:03.380 --> 01:43:07.020]   And that's, to me, what's worth seven billion dollars.
[01:43:07.020 --> 01:43:08.780]   In fact, in a way, I like to do this.
[01:43:08.780 --> 01:43:10.100]   - And they do tax stuff.
[01:43:10.100 --> 01:43:11.180]   - And they do taxes.
[01:43:11.180 --> 01:43:13.580]   And of course, Intuit has TurboTax,
[01:43:13.580 --> 01:43:15.820]   and they don't want a free tax program.
[01:43:15.820 --> 01:43:18.420]   - Yeah, I was gonna say, I think that might be the big thing.
[01:43:18.420 --> 01:43:20.740]   - Even then, you don't spend seven billion dollars
[01:43:20.740 --> 01:43:23.820]   to put a competitor's tax program out of business.
[01:43:23.820 --> 01:43:24.660]   - That's true.
[01:43:24.660 --> 01:43:25.500]   - They've got it.
[01:43:25.500 --> 01:43:27.260]   It's like Microsoft buying LinkedIn.
[01:43:27.260 --> 01:43:29.340]   The value is in the data.
[01:43:29.340 --> 01:43:32.020]   And it tells you that the data that with 100 million users,
[01:43:32.020 --> 01:43:34.780]   it's 70 bucks a user that this company is worth.
[01:43:34.780 --> 01:43:37.220]   It gives you some idea of what your data is worth.
[01:43:37.220 --> 01:43:41.140]   - And data has basically become coin of the realm
[01:43:41.140 --> 01:43:43.060]   in enterprise IT, right?
[01:43:43.060 --> 01:43:46.540]   So if you don't have first party data,
[01:43:46.540 --> 01:43:48.380]   data you've collected yourself,
[01:43:48.380 --> 01:43:51.260]   not that you're partnering with someone else,
[01:43:51.260 --> 01:43:52.860]   then you're really at a disadvantage
[01:43:52.860 --> 01:43:55.340]   to the companies that do have first party data.
[01:43:55.340 --> 01:43:58.700]   So both in, whether you're in retail
[01:43:58.700 --> 01:44:01.340]   or whether you are in finance
[01:44:01.340 --> 01:44:03.060]   or whether you're in the media business.
[01:44:03.060 --> 01:44:06.340]   I mean, being able to have data about your customers
[01:44:06.340 --> 01:44:07.340]   that you collect directly,
[01:44:07.340 --> 01:44:09.140]   just like we were talking about with Amazon
[01:44:09.140 --> 01:44:10.620]   and grocery stores,
[01:44:10.620 --> 01:44:14.700]   and translate that into and monetize that,
[01:44:14.700 --> 01:44:17.180]   either for yourself or for,
[01:44:17.180 --> 01:44:18.500]   through a third party,
[01:44:18.500 --> 01:44:21.420]   is just, that's the real value anymore.
[01:44:21.420 --> 01:44:23.100]   It's not the physical thing.
[01:44:23.100 --> 01:44:25.220]   It's the data that you can collect.
[01:44:25.220 --> 01:44:29.420]   And you were talking about the value per customer
[01:44:29.420 --> 01:44:31.020]   for the acquisition there.
[01:44:31.020 --> 01:44:35.060]   That's a lot more than most people think their data is worth.
[01:44:35.060 --> 01:44:38.100]   I've seen surveys that say people would gladly
[01:44:38.100 --> 01:44:39.940]   trade their data to Facebook for $5.
[01:44:39.940 --> 01:44:43.340]   Right, so clearly they're underselling
[01:44:43.340 --> 01:44:45.700]   the value of their own data.
[01:44:45.700 --> 01:44:47.020]   Yeah, well, that's what,
[01:44:47.020 --> 01:44:48.620]   isn't that what Tim Berners-Lee is doing?
[01:44:48.620 --> 01:44:50.500]   In fact, he started something called Solid.
[01:44:50.500 --> 01:44:52.020]   The idea is you have a data vault
[01:44:52.020 --> 01:44:54.380]   and you can then control your data
[01:44:54.380 --> 01:44:56.260]   and sell it at an appropriate price.
[01:44:56.260 --> 01:44:58.140]   If you wanna use Facebook, Facebook says,
[01:44:58.140 --> 01:44:59.460]   "Well, we'll give you free Facebook,
[01:44:59.460 --> 01:45:00.740]   but you gotta give us some data."
[01:45:00.740 --> 01:45:01.580]   You'll control it.
[01:45:01.580 --> 01:45:03.460]   It'll be explicit transaction
[01:45:03.460 --> 01:45:05.260]   instead of one of these implicit transactions.
[01:45:05.260 --> 01:45:07.940]   Bruce Schneider just went to work for InRupt,
[01:45:07.940 --> 01:45:10.980]   which is a company that's gonna use this solid technology.
[01:45:10.980 --> 01:45:13.100]   I don't think this is ever gonna happen, by the way.
[01:45:13.100 --> 01:45:14.820]   We're too entrenched and just,
[01:45:14.820 --> 01:45:16.260]   "I'll give you anything, whatever.
[01:45:16.260 --> 01:45:18.380]   I just want free email."
[01:45:18.380 --> 01:45:20.020]   But I think it's a great idea anyway.
[01:45:20.020 --> 01:45:20.860]   I hope it happens.
[01:45:20.860 --> 01:45:22.660]   - Well, and the laws don't protect it, right?
[01:45:22.660 --> 01:45:25.060]   The laws and the regulations aren't there.
[01:45:25.060 --> 01:45:28.420]   Think about a photographer.
[01:45:28.420 --> 01:45:31.460]   The law protects the person that takes the photo,
[01:45:31.460 --> 01:45:34.500]   in most cases, not the person in the photo.
[01:45:34.500 --> 01:45:35.340]   So this is the same.
[01:45:35.340 --> 01:45:38.060]   The law is set up to protect the company
[01:45:38.060 --> 01:45:39.540]   that collects the data.
[01:45:39.540 --> 01:45:41.940]   They're the ones that owns that work,
[01:45:41.940 --> 01:45:44.820]   not you who have given over the data, right?
[01:45:44.820 --> 01:45:45.820]   So there's a reason, Bill,
[01:45:45.820 --> 01:45:47.940]   it's because companies knew the value of the data
[01:45:47.940 --> 01:45:50.020]   long before we did as individuals.
[01:45:50.020 --> 01:45:51.180]   So we never thought it.
[01:45:51.180 --> 01:45:52.460]   We never said anything about it.
[01:45:52.460 --> 01:45:54.540]   The only people who wanted it was the companies.
[01:45:54.540 --> 01:45:56.300]   - Well, and it wasn't possible, right?
[01:45:56.300 --> 01:45:57.340]   It was all hidden.
[01:45:57.340 --> 01:46:00.100]   Imagine if you wanted to collect this type of data
[01:46:00.100 --> 01:46:01.060]   a hundred years ago.
[01:46:01.060 --> 01:46:04.060]   And people did, you know, you had to go to public records.
[01:46:04.060 --> 01:46:05.860]   You had to send college students.
[01:46:05.860 --> 01:46:08.100]   You had to send people that you would hire
[01:46:08.100 --> 01:46:10.260]   and pay an alleyways to go to the courthouse
[01:46:10.260 --> 01:46:12.220]   and physically collect this data
[01:46:12.220 --> 01:46:13.420]   or look for other ways to get it.
[01:46:13.420 --> 01:46:16.380]   So this is, companies have been collecting data since,
[01:46:16.380 --> 01:46:18.780]   you know, there were catalogs and there were records,
[01:46:18.780 --> 01:46:21.540]   but now it's just become so much easier
[01:46:21.540 --> 01:46:23.460]   that P and the technology has allowed people
[01:46:23.460 --> 01:46:26.620]   just to give up their data without even knowing it, right?
[01:46:26.620 --> 01:46:28.540]   So, oh yeah, get that free email
[01:46:28.540 --> 01:46:30.580]   and we'll just scan all the text in it
[01:46:30.580 --> 01:46:32.020]   and find out what keywords are in there.
[01:46:32.020 --> 01:46:33.540]   Hey, that sounds great to me.
[01:46:33.540 --> 01:46:34.900]   - Right.
[01:46:34.900 --> 01:46:36.660]   - Well, in many cases, I feel like these companies
[01:46:36.660 --> 01:46:38.540]   don't even understand the value of the data
[01:46:38.540 --> 01:46:39.380]   until they have it.
[01:46:39.380 --> 01:46:41.660]   So it's really just collecting as much as possible
[01:46:41.660 --> 01:46:44.580]   and then finding the value of the data
[01:46:44.580 --> 01:46:45.980]   after it's collected, right?
[01:46:45.980 --> 01:46:48.940]   So it's like allowing artificial intelligence
[01:46:48.940 --> 01:46:51.220]   and other computer algorithms, you know,
[01:46:51.220 --> 01:46:54.820]   to detect patterns and to find value within the data
[01:46:54.820 --> 01:46:57.220]   that people are just kind of like willingly giving up.
[01:46:57.220 --> 01:47:02.060]   I think, you know, the value of the stuff escapes most people
[01:47:02.060 --> 01:47:04.460]   beyond like a few computer scientists
[01:47:04.460 --> 01:47:06.020]   and even the leading experts
[01:47:06.020 --> 01:47:07.820]   don't fully understand the value of the data
[01:47:07.820 --> 01:47:08.660]   that they're collecting.
[01:47:08.660 --> 01:47:10.900]   They trust the models that they create, right?
[01:47:10.900 --> 01:47:12.980]   And so, I don't know.
[01:47:12.980 --> 01:47:14.860]   I feel like people still, you know,
[01:47:14.860 --> 01:47:16.820]   even though we're all sitting here saying like,
[01:47:16.820 --> 01:47:18.180]   yes, data is really valuable.
[01:47:18.180 --> 01:47:21.380]   I think the true value escapes even people
[01:47:21.380 --> 01:47:23.740]   as well educated on this as us
[01:47:23.740 --> 01:47:26.020]   and even leading experts in the field.
[01:47:26.020 --> 01:47:27.780]   - I wonder though, now that people are starting to know,
[01:47:27.780 --> 01:47:29.820]   and I think people are much more aware of it now,
[01:47:29.820 --> 01:47:31.180]   if they're gonna start fighting for it.
[01:47:31.180 --> 01:47:33.100]   Maybe that's why there's a chance
[01:47:33.100 --> 01:47:35.300]   that solid could actually happen
[01:47:35.300 --> 01:47:38.180]   because people are gonna care suddenly or do care, I think.
[01:47:38.180 --> 01:47:40.220]   People are much more privacy-aware than they used to be,
[01:47:40.220 --> 01:47:41.060]   don't you think?
[01:47:41.060 --> 01:47:43.300]   - I don't know.
[01:47:43.300 --> 01:47:47.100]   Sometimes, I don't, I think the media is.
[01:47:47.100 --> 01:47:49.820]   I think that people covering this stuff
[01:47:49.820 --> 01:47:51.580]   are following this a lot more closely,
[01:47:51.580 --> 01:47:55.220]   but like, you know, delete Facebook, that campaign.
[01:47:55.220 --> 01:47:57.260]   - Yeah, but I really heard Facebook.
[01:47:57.260 --> 01:47:58.460]   - Ooh, almost.
[01:47:58.460 --> 01:48:00.620]   - Well, I think there's a big difference between
[01:48:00.620 --> 01:48:02.540]   expecting people to delete Facebook
[01:48:02.540 --> 01:48:07.060]   and saying, are you aware of what these companies
[01:48:07.060 --> 01:48:07.900]   are doing now?
[01:48:07.900 --> 01:48:09.020]   I do think that people are more aware
[01:48:09.020 --> 01:48:11.620]   whether they're taking the actions to limit
[01:48:11.620 --> 01:48:13.540]   what companies have access to.
[01:48:13.540 --> 01:48:15.060]   I think it's a different question,
[01:48:15.060 --> 01:48:17.380]   but I do think that people are more aware than they were.
[01:48:17.380 --> 01:48:19.220]   And in Caramoure, and are more concerned,
[01:48:19.220 --> 01:48:21.180]   and they were even a couple of years ago.
[01:48:21.180 --> 01:48:23.140]   I do think that's true.
[01:48:23.140 --> 01:48:26.980]   - Bob Iger suddenly, suddenly retires,
[01:48:26.980 --> 01:48:30.180]   quits a CEO of Disney,
[01:48:30.180 --> 01:48:33.340]   and I know where he's going.
[01:48:33.340 --> 01:48:34.580]   He's going to Masterclass,
[01:48:34.580 --> 01:48:36.540]   our sponsor for this portion of the show,
[01:48:36.540 --> 01:48:40.380]   Masterclass, learn the business secrets of,
[01:48:40.380 --> 01:48:43.420]   I guess now I have to say, former Disney CEO, Bob Iger,
[01:48:43.420 --> 01:48:48.420]   he's one of the many, many teachers at masterclass.com/twit.
[01:48:48.420 --> 01:48:52.540]   I've been a Masterclass subscriber for a couple of years.
[01:48:52.540 --> 01:48:56.060]   I mean, imagine learning screenwriting
[01:48:56.060 --> 01:48:57.460]   from Aaron Sorkin.
[01:48:57.460 --> 01:49:00.860]   I mean, honest, that like,
[01:49:00.860 --> 01:49:03.260]   at learning acting from Samuel L. Jackson,
[01:49:03.260 --> 01:49:05.780]   I've mentioned this before, his Pulp Fiction Workshop.
[01:49:05.780 --> 01:49:08.620]   By the way, there's many lessons in all of this,
[01:49:08.620 --> 01:49:11.420]   21 lessons in all from Samuel L. Jackson.
[01:49:11.420 --> 01:49:13.620]   His Pulp Fiction Workshop is so amazing,
[01:49:13.620 --> 01:49:16.140]   he breaks down the script
[01:49:16.140 --> 01:49:18.340]   at the beginning of Pulp Fiction with acting students
[01:49:18.340 --> 01:49:20.580]   and says, talks his way through it.
[01:49:20.580 --> 01:49:24.820]   And I mean, this is like getting an acting class
[01:49:24.820 --> 01:49:27.620]   from one of the best actors ever.
[01:49:27.620 --> 01:49:30.260]   'Cause imagine that, I mean, that's incredible.
[01:49:30.260 --> 01:49:32.100]   Or maybe you'd like to learn,
[01:49:32.100 --> 01:49:35.100]   I know Christina, you always wanted to be a ballerina.
[01:49:35.100 --> 01:49:38.700]   Maybe you'd like to learn how a bar technique
[01:49:38.700 --> 01:49:41.540]   from a principal ballerina
[01:49:41.540 --> 01:49:44.460]   at the American Ballet Theater, Misty Copeland.
[01:49:44.460 --> 01:49:45.580]   Wouldn't that be cool?
[01:49:45.580 --> 01:49:51.180]   Learn comedy from Jove Apatow or my friend Steve Martin.
[01:49:51.180 --> 01:49:52.820]   It goes on and on, Thomas Keller,
[01:49:52.820 --> 01:49:55.020]   teaching you how to cook Gary Kasparov,
[01:49:55.020 --> 01:49:57.180]   world champion six times,
[01:49:57.180 --> 01:49:59.820]   Grandmaster teaching you chess.
[01:49:59.820 --> 01:50:04.700]   Steve, just, I think masterclass alone is worth it
[01:50:04.700 --> 01:50:08.580]   for Steve Martin, how to tell funnier stories.
[01:50:08.580 --> 01:50:10.260]   You will love masterclass,
[01:50:10.260 --> 01:50:13.420]   75 different instructors across every category.
[01:50:13.420 --> 01:50:16.540]   Learn Mexican cooking from a Gabrielle Camara,
[01:50:16.540 --> 01:50:18.700]   business strategy from Bob Iger,
[01:50:18.700 --> 01:50:21.860]   presidential history from Doris Kearns Goodwin.
[01:50:21.860 --> 01:50:24.220]   The lessons are beautifully shot,
[01:50:24.220 --> 01:50:28.940]   a crafted so beautifully so that you can enjoy,
[01:50:28.940 --> 01:50:32.300]   you can watch sit down and watch them on your big screen TV
[01:50:32.300 --> 01:50:33.900]   and it would be entertaining, it'd be fun,
[01:50:33.900 --> 01:50:35.540]   but you would also learn.
[01:50:35.540 --> 01:50:37.700]   Your phone, the web, the Apple TV,
[01:50:37.700 --> 01:50:40.420]   they all have masterclass on a variety of topics,
[01:50:40.420 --> 01:50:44.220]   always taught by the best person who could possibly
[01:50:44.220 --> 01:50:47.500]   teach a photography from any labor vets for crying out loud.
[01:50:47.500 --> 01:50:50.140]   Gordon Ramsay's essential list of kitchen tools
[01:50:50.140 --> 01:50:51.540]   for crying out loud.
[01:50:51.540 --> 01:50:52.860]   I don't know how they get these people,
[01:50:52.860 --> 01:50:56.500]   but man, they break them down into 10 to 15 minute segments,
[01:50:56.500 --> 01:50:58.500]   which makes it nice, you can watch it on the subway,
[01:50:58.500 --> 01:51:00.620]   you can watch it at home.
[01:51:00.620 --> 01:51:02.100]   Ron Howard teaching you how to direct,
[01:51:02.100 --> 01:51:05.940]   he actually walks through a scene, it's unbelievable.
[01:51:05.940 --> 01:51:08.660]   They get, I don't know how they get these people.
[01:51:08.660 --> 01:51:13.780]   Users give masterclass an average of 4.7 out of five stars,
[01:51:13.780 --> 01:51:15.460]   but of course, if you're not satisfied,
[01:51:15.460 --> 01:51:16.580]   I don't know why you wouldn't be,
[01:51:16.580 --> 01:51:19.220]   but you can, there's a 30 day money back guarantee.
[01:51:19.220 --> 01:51:20.980]   Get, you know what the best deal is?
[01:51:20.980 --> 01:51:23.220]   Get the all, I am making some stuff tonight
[01:51:23.220 --> 01:51:25.060]   from Gabriella, this amazing.
[01:51:25.060 --> 01:51:28.760]   Get the annual all access pass, okay?
[01:51:28.760 --> 01:51:32.220]   Masterclass.com/twit by the way,
[01:51:32.220 --> 01:51:33.180]   because you listen to Twit,
[01:51:33.180 --> 01:51:35.900]   you're gonna get 15% off the annual all access pass,
[01:51:35.900 --> 01:51:38.620]   15% off, that's a great deal.
[01:51:38.620 --> 01:51:44.500]   Martin Scorsese, masterclass.com/twit.
[01:51:44.500 --> 01:51:46.980]   I think you're gonna enjoy this.
[01:51:47.940 --> 01:51:50.140]   I think you're really gonna enjoy this.
[01:51:50.140 --> 01:51:51.860]   What a great gift too, by the way.
[01:51:51.860 --> 01:51:55.300]   And you know, a couple of months to graduation,
[01:51:55.300 --> 01:51:57.340]   I gave this to my son for,
[01:51:57.340 --> 01:51:58.620]   actually I wanted to give it to my son
[01:51:58.620 --> 01:52:00.100]   for high school graduation.
[01:52:00.100 --> 01:52:01.700]   He said, I already have it that.
[01:52:01.700 --> 01:52:06.260]   Okay, RuPaul on self expression and authenticity.
[01:52:06.260 --> 01:52:07.580]   (laughs)
[01:52:07.580 --> 01:52:10.700]   You gotta love it, you gotta love it.
[01:52:10.700 --> 01:52:15.700]   Masterclass, masterclass.com/twit.
[01:52:16.180 --> 01:52:18.860]   Learn from the best.
[01:52:18.860 --> 01:52:23.340]   So I don't know what to make of this story,
[01:52:23.340 --> 01:52:26.080]   but I thought I'd ask you guys, you're very smart.
[01:52:26.080 --> 01:52:29.860]   It hasn't gotten a lot of attention,
[01:52:29.860 --> 01:52:33.300]   but I feel like it could be a really important story.
[01:52:33.300 --> 01:52:37.460]   There's an activist investment firm called Elliot Management.
[01:52:37.460 --> 01:52:39.660]   And according to Bloomberg,
[01:52:39.660 --> 01:52:42.580]   they've just taken a sizable stake in Twitter.
[01:52:42.580 --> 01:52:45.340]   No one knows what that sizable stake is,
[01:52:45.340 --> 01:52:48.300]   but I should point out that Elliot Management
[01:52:48.300 --> 01:52:51.340]   is run by Paul Singer.
[01:52:51.340 --> 01:52:54.340]   He is a Republican mega donor.
[01:52:54.340 --> 01:52:56.660]   He was a never-trumper at the beginning,
[01:52:56.660 --> 01:52:59.220]   but he has since become a Trump fan.
[01:52:59.220 --> 01:53:00.660]   Of course, Donald Trump, the president,
[01:53:00.660 --> 01:53:03.660]   uses Twitter to great effect.
[01:53:03.660 --> 01:53:06.660]   And I have to wonder if this isn't
[01:53:06.660 --> 01:53:09.540]   kind of an interesting campaign contribution,
[01:53:09.540 --> 01:53:12.340]   because apparently Elliot is demanding
[01:53:12.340 --> 01:53:14.780]   that Twitter CEO Jack Dorsey leave
[01:53:14.780 --> 01:53:17.140]   and that they get four seats on the board.
[01:53:17.140 --> 01:53:18.860]   And you have to wonder if it has something to do
[01:53:18.860 --> 01:53:22.060]   with Twitter's decision not to take political advertising.
[01:53:22.060 --> 01:53:26.380]   Is this gonna be a sea change for Twitter?
[01:53:26.380 --> 01:53:28.340]   What do you think?
[01:53:28.340 --> 01:53:32.340]   - Well, they've done this before, right?
[01:53:32.340 --> 01:53:36.780]   Like this guy is made--
[01:53:36.780 --> 01:53:37.860]   - Paul Singer.
[01:53:37.860 --> 01:53:39.220]   - Paul Singer, he's made these attempts before.
[01:53:39.220 --> 01:53:42.820]   I know that Samsung, he bought a big share of--
[01:53:42.820 --> 01:53:45.180]   - He's a typical activist investor.
[01:53:45.180 --> 01:53:46.020]   They come in.
[01:53:46.020 --> 01:53:49.300]   - And he also did do stuff with Yahoo,
[01:53:49.300 --> 01:53:50.540]   was he the Yahoo guy?
[01:53:50.540 --> 01:53:51.380]   - Maybe, maybe, yeah.
[01:53:51.380 --> 01:53:52.620]   - I believe so.
[01:53:52.620 --> 01:53:56.420]   So it's interesting, definitely,
[01:53:56.420 --> 01:54:00.140]   this is their MO, this is kind of their playbook.
[01:54:00.140 --> 01:54:03.660]   Apparently, I think because of how much he's accomplished,
[01:54:03.660 --> 01:54:07.020]   he says he, I guess he can put in three board seats
[01:54:07.020 --> 01:54:09.220]   and which are, I guess, due to be up.
[01:54:09.220 --> 01:54:10.900]   He wants to fill the board with four slots,
[01:54:10.900 --> 01:54:12.660]   but only three are going to be open.
[01:54:12.660 --> 01:54:13.500]   - Right.
[01:54:13.500 --> 01:54:15.340]   - The big question would be, would that be enough
[01:54:15.340 --> 01:54:18.260]   for him to be able to force a CEO change?
[01:54:18.260 --> 01:54:22.420]   Something tells me that is gonna be much harder,
[01:54:22.420 --> 01:54:27.420]   but certainly if he could get the other votes on the board
[01:54:27.420 --> 01:54:31.620]   and make an argument that says that the Dorsey
[01:54:31.620 --> 01:54:36.220]   has been a poor CEO because of his split duties
[01:54:36.220 --> 01:54:40.500]   between Square and Twitter, that is interesting.
[01:54:40.500 --> 01:54:42.780]   I think that it would be difficult
[01:54:42.780 --> 01:54:45.180]   just given the Twitter's overall performance
[01:54:45.180 --> 01:54:47.660]   in the last few years, it's actually improved.
[01:54:47.660 --> 01:54:51.780]   So I think that's a hard argument to make.
[01:54:51.780 --> 01:54:56.700]   - I'd hate to see Twitter become an arm of a political party,
[01:54:56.700 --> 01:54:58.380]   a publicity arm for a political party.
[01:54:58.380 --> 01:55:00.500]   That would be devastating.
[01:55:00.500 --> 01:55:01.340]   - Definitely.
[01:55:01.340 --> 01:55:04.820]   - He's not rich enough to, I mean, he's only worth only,
[01:55:04.820 --> 01:55:07.220]   3.2 billion dollars.
[01:55:07.220 --> 01:55:09.380]   I mean, he's not a Bloomberg, for instance.
[01:55:09.380 --> 01:55:10.220]   - Right.
[01:55:10.220 --> 01:55:12.060]   - He was worth 62 billion.
[01:55:12.060 --> 01:55:16.540]   He's not a Bill Gates, but I guess 3.2 is enough.
[01:55:16.540 --> 01:55:18.060]   Twitter's not that valuable.
[01:55:18.060 --> 01:55:22.220]   - But it should serve to remind Twitter users,
[01:55:22.220 --> 01:55:24.620]   the public in general, that these platforms
[01:55:24.620 --> 01:55:26.980]   are not public services, right?
[01:55:26.980 --> 01:55:30.060]   They are private companies or public companies.
[01:55:30.060 --> 01:55:33.980]   And so they do, they may have rules, they may have guidelines,
[01:55:33.980 --> 01:55:36.420]   they may have operating philosophies,
[01:55:36.420 --> 01:55:38.620]   but those philosophies can change over time
[01:55:38.620 --> 01:55:40.500]   depending on who owns the companies.
[01:55:40.500 --> 01:55:43.620]   And so if the management changes,
[01:55:43.620 --> 01:55:45.340]   we were just talking about data,
[01:55:45.340 --> 01:55:47.940]   how the company uses your data can change,
[01:55:47.940 --> 01:55:50.940]   what you're allowed to say or what direction the company goes,
[01:55:50.940 --> 01:55:51.980]   can change.
[01:55:51.980 --> 01:55:55.100]   And so I think it is kind of maybe a rude awakening
[01:55:55.100 --> 01:55:58.140]   to some people who treat these platforms,
[01:55:58.140 --> 01:56:01.020]   whether it's Twitter or Facebook or,
[01:56:01.020 --> 01:56:03.740]   Michael and I in the media industry,
[01:56:03.740 --> 01:56:07.420]   those platforms, these are all private entities, right?
[01:56:07.420 --> 01:56:11.220]   And so while different entities have different values,
[01:56:11.220 --> 01:56:13.060]   it'll be interesting to see what happens
[01:56:13.060 --> 01:56:15.420]   with a platform like Twitter.
[01:56:15.420 --> 01:56:18.300]   Think about a platform like Reddit as well, right?
[01:56:18.300 --> 01:56:23.300]   So people, if the owners want to take the company
[01:56:23.300 --> 01:56:26.220]   in a different direction, they can't.
[01:56:26.220 --> 01:56:27.900]   - They're not a public service.
[01:56:27.900 --> 01:56:29.020]   They're not a public service.
[01:56:29.020 --> 01:56:31.380]   - And yet they have so much importance
[01:56:31.380 --> 01:56:35.040]   especially Twitter in the public conversation Facebook.
[01:56:36.700 --> 01:56:40.020]   In fact, some have said they should be public services.
[01:56:40.020 --> 01:56:42.500]   They shouldn't be run for profit.
[01:56:42.500 --> 01:56:44.220]   I don't know if I agree with that, but.
[01:56:44.220 --> 01:56:46.420]   - Well, I think honestly, like you said,
[01:56:46.420 --> 01:56:49.300]   Leo, I'm not sure I would agree in turning any of these,
[01:56:49.300 --> 01:56:52.660]   you know, private companies into public services,
[01:56:52.660 --> 01:56:57.460]   but it does remind us of what we get out of things
[01:56:57.460 --> 01:57:00.900]   like roads or publicly managed utilities,
[01:57:00.900 --> 01:57:03.460]   even if they're private companies or public companies, right?
[01:57:03.460 --> 01:57:06.020]   Or the water company and the power companies,
[01:57:06.020 --> 01:57:10.020]   those public services that we really sort of value.
[01:57:10.020 --> 01:57:13.820]   And in our everyday lives, you know,
[01:57:13.820 --> 01:57:15.940]   there are now these digital services
[01:57:15.940 --> 01:57:20.220]   that used to maybe have been created by the government
[01:57:20.220 --> 01:57:22.060]   but are now private companies.
[01:57:22.060 --> 01:57:23.580]   And so, you know, like you,
[01:57:23.580 --> 01:57:27.780]   I wouldn't advocate taking away any of these companies
[01:57:27.780 --> 01:57:29.100]   and putting them in the public sector,
[01:57:29.100 --> 01:57:32.060]   but it does maybe remind us maybe there's a place
[01:57:32.060 --> 01:57:34.500]   for a public version of some of these
[01:57:34.500 --> 01:57:36.540]   that can't be taken away.
[01:57:36.540 --> 01:57:38.580]   We have public television in the United States.
[01:57:38.580 --> 01:57:41.580]   - I wouldn't want Twitter to become a Fox News anymore
[01:57:41.580 --> 01:57:43.420]   than I'd want them to become an MSNBC.
[01:57:43.420 --> 01:57:44.860]   And actually so-- - No, totally.
[01:57:44.860 --> 01:57:45.780]   - They've done a good job
[01:57:45.780 --> 01:57:47.740]   because I think everybody hates them.
[01:57:47.740 --> 01:57:50.500]   - So, yeah, I feel like they already are those things.
[01:57:50.500 --> 01:57:51.900]   You know, it's so polarized.
[01:57:51.900 --> 01:57:55.140]   And, you know, I don't know much about this activist investor,
[01:57:55.140 --> 01:57:58.460]   to be honest, but I do know a lot about Jack Dorsey.
[01:57:58.460 --> 01:58:00.700]   And I feel like he has failed time and time again.
[01:58:00.700 --> 01:58:02.700]   I think I saw in the past week
[01:58:02.700 --> 01:58:07.700]   that a 17-year-old high schooler was able to
[01:58:07.700 --> 01:58:11.340]   get a fake Twitter profile and get it verified.
[01:58:11.340 --> 01:58:13.140]   - You get a blue check mark.
[01:58:13.140 --> 01:58:14.180]   - He got a blue check mark.
[01:58:14.180 --> 01:58:16.620]   - He pretended he was what a member of Congress--
[01:58:16.620 --> 01:58:17.700]   - He was running for Congress.
[01:58:17.700 --> 01:58:19.700]   - He was running for office.
[01:58:19.700 --> 01:58:22.700]   Because they will verify.
[01:58:22.700 --> 01:58:25.100]   Right, no, I mean, look,
[01:58:25.100 --> 01:58:26.980]   there are plenty of things to criticize Twitter on.
[01:58:26.980 --> 01:58:29.620]   I think this activist, I mean, this is kind of his MO.
[01:58:29.620 --> 01:58:31.500]   We tried to do this with AT&T.
[01:58:31.500 --> 01:58:34.020]   I think the success here is probably gonna be overblown,
[01:58:34.020 --> 01:58:35.620]   like, no matter how much--
[01:58:35.620 --> 01:58:36.780]   - So nothing to worry about.
[01:58:36.780 --> 01:58:38.100]   - The company, yeah.
[01:58:38.100 --> 01:58:41.060]   - I think it would be hard just because even if he did get
[01:58:41.060 --> 01:58:44.380]   all those board seats, which would be difficult
[01:58:44.380 --> 01:58:46.180]   if he were to get his people involved,
[01:58:46.180 --> 01:58:48.780]   because the other board members have to agree as well,
[01:58:48.780 --> 01:58:51.540]   you know, you're supposed to have ultimately a fiduciary,
[01:58:51.540 --> 01:58:53.060]   you know, responsibility with the shareholders.
[01:58:53.060 --> 01:58:56.420]   And think that there could be, you know, larger revolts
[01:58:56.420 --> 01:58:58.660]   if those sorts of changes were happening.
[01:58:58.660 --> 01:59:03.660]   Also think, frankly, this doesn't in any way disagree
[01:59:03.660 --> 01:59:06.500]   with like you and Bill's statements that maybe we need to have,
[01:59:06.500 --> 01:59:09.100]   we need to at least be aware of how these companies
[01:59:09.100 --> 01:59:12.020]   are controlled and that they are businesses
[01:59:12.020 --> 01:59:13.340]   at the end of the day and that it's not kind of
[01:59:13.340 --> 01:59:14.300]   a public square.
[01:59:14.300 --> 01:59:16.100]   But I do think that if there was a significant
[01:59:16.100 --> 01:59:18.660]   management shakeup, then you would see a massive amount
[01:59:18.660 --> 01:59:22.900]   of talent just leave, which in turn would completely
[01:59:22.900 --> 01:59:25.340]   drop the value of the service, right?
[01:59:25.340 --> 01:59:26.180]   - That's really true, yeah.
[01:59:26.180 --> 01:59:27.020]   - That's really true.
[01:59:27.020 --> 01:59:28.340]   - I mean, that's the thing you think you have to keep in mind,
[01:59:28.340 --> 01:59:30.340]   you can put in engineers and they're prickly.
[01:59:30.340 --> 01:59:31.180]   - You need engineers.
[01:59:31.180 --> 01:59:32.180]   - And they're in demand.
[01:59:32.180 --> 01:59:34.140]   There's nothing keeping them anywhere.
[01:59:34.140 --> 01:59:37.580]   They're flocks because everybody wants a good engineer.
[01:59:37.580 --> 01:59:38.420]   - Right.
[01:59:38.420 --> 01:59:39.660]   And if you really did want to say, okay,
[01:59:39.660 --> 01:59:42.100]   we could restart Twitter and have a different
[01:59:42.100 --> 01:59:43.660]   of a Twitter and migrate people over,
[01:59:43.660 --> 01:59:47.140]   the surest way to do that would be to ruin the management
[01:59:47.140 --> 01:59:48.580]   and then have everybody just be like, okay,
[01:59:48.580 --> 01:59:50.380]   we're going to get funding and build our own.
[01:59:50.380 --> 01:59:51.220]   - Good point.
[01:59:51.220 --> 01:59:53.100]   Then there's TikTok.
[01:59:53.100 --> 01:59:54.060]   Do you use TikTok?
[01:59:54.060 --> 01:59:57.700]   I think you're hip, you're young, you're with it, you're cool.
[01:59:57.700 --> 01:59:58.540]   - I love TikTok.
[01:59:58.540 --> 01:59:59.460]   I'm not on TikTok.
[01:59:59.460 --> 02:00:00.860]   I mean, I don't like make my own TikToks.
[02:00:00.860 --> 02:00:02.980]   I'm not that cool, but I love TikTok.
[02:00:02.980 --> 02:00:05.540]   - According to Steve Huffman, the CEO of Reddit,
[02:00:05.540 --> 02:00:08.260]   Guy wrote the software originally in Lisp.
[02:00:08.260 --> 02:00:11.140]   TikTok is fundamentally parasitic.
[02:00:11.140 --> 02:00:12.900]   - She's wrong.
[02:00:12.900 --> 02:00:14.140]   - TikTok said, no.
[02:00:14.140 --> 02:00:18.020]   He was speaking at an appearance
[02:00:18.020 --> 02:00:21.380]   at the Social 2030 Venture Capital Conference.
[02:00:21.380 --> 02:00:25.100]   He says, Steve says, "Maybe I'm going to regret this,
[02:00:25.100 --> 02:00:27.020]   but I can't even get to that level of thinking
[02:00:27.020 --> 02:00:28.660]   with TikTok because I look at that app
[02:00:28.660 --> 02:00:32.060]   as so fundamentally parasitic that it's always listening.
[02:00:32.060 --> 02:00:35.340]   The fingerprinting technology they use is truly terrifying.
[02:00:35.340 --> 02:00:38.340]   I could not bring myself to install an app like that
[02:00:38.340 --> 02:00:41.060]   on my phone,
[02:00:41.060 --> 02:00:43.540]   bite dance, the owners of TikTok said,
[02:00:43.540 --> 02:00:45.900]   what is he talking about?
[02:00:45.900 --> 02:00:47.460]   There's no evidence of that.
[02:00:47.460 --> 02:00:50.700]   Steve did not offer any evidence.
[02:00:50.700 --> 02:00:52.860]   On the other hand, I think there's probably a lot of people
[02:00:52.860 --> 02:00:54.380]   who go, yeah, that makes sense.
[02:00:54.380 --> 02:00:56.580]   That's probably the case.
[02:00:56.580 --> 02:00:59.060]   It is owned by a Chinese company.
[02:00:59.060 --> 02:00:59.900]   Right?
[02:00:59.900 --> 02:01:04.300]   - I think it's parasitic and how it very clearly
[02:01:04.300 --> 02:01:06.780]   preys on young users and underage users
[02:01:06.780 --> 02:01:09.060]   in a way that even Snapchat wasn't that brazen.
[02:01:09.060 --> 02:01:10.340]   Snapchat was pretty brazen.
[02:01:10.340 --> 02:01:12.220]   And TikTok is even worse.
[02:01:12.220 --> 02:01:15.180]   I think that's problematic, but I do enjoy the memes.
[02:01:15.180 --> 02:01:17.660]   (both laughing)
[02:01:17.660 --> 02:01:18.500]   - Come for the memes.
[02:01:18.500 --> 02:01:20.260]   Stay for the data.
[02:01:20.260 --> 02:01:22.380]   - All social media is parasitic.
[02:01:22.380 --> 02:01:24.620]   I think that this is making a discrepancy
[02:01:24.620 --> 02:01:27.500]   between different types of cigarettes,
[02:01:27.500 --> 02:01:28.500]   new portraits of something.
[02:01:28.500 --> 02:01:29.820]   - They all give you cancer.
[02:01:29.820 --> 02:01:30.660]   - Yeah.
[02:01:30.660 --> 02:01:32.780]   - Yeah, they all have the same adverse effects.
[02:01:32.780 --> 02:01:34.780]   I think they're all built to do the same thing,
[02:01:34.780 --> 02:01:36.940]   which is to keep you engaged
[02:01:36.940 --> 02:01:39.180]   or keep you addicted to the service.
[02:01:39.180 --> 02:01:43.580]   And I'd be lying if I said that I didn't enjoy TikTok.
[02:01:43.580 --> 02:01:47.260]   I think it's fun, but use it responsibly.
[02:01:47.260 --> 02:01:51.780]   Like a lot of other things in my life, I guess.
[02:01:51.780 --> 02:01:56.100]   And yeah, he's not wrong, but it's not that different
[02:01:56.100 --> 02:01:58.140]   than Reddit or Twitter or Facebook
[02:01:58.140 --> 02:02:00.580]   or any of these other apps, in my opinion.
[02:02:00.580 --> 02:02:04.980]   - I think it's a good time to call it a day.
[02:02:04.980 --> 02:02:07.020]   We've gone for a nice two hours
[02:02:07.020 --> 02:02:09.060]   and you guys are so great and so smart.
[02:02:09.060 --> 02:02:11.340]   I don't wanna wear you out, Bill Detweiler.
[02:02:11.340 --> 02:02:12.180]   How was it?
[02:02:12.180 --> 02:02:14.380]   Your first time on the Twit panel,
[02:02:14.380 --> 02:02:16.620]   I think you did very, very well.
[02:02:16.620 --> 02:02:17.460]   - Well, thank you.
[02:02:17.460 --> 02:02:18.300]   It was fantastic.
[02:02:18.300 --> 02:02:19.140]   - You have fun?
[02:02:19.140 --> 02:02:20.540]   - I had a great time.
[02:02:20.540 --> 02:02:23.100]   I've been watching for a long time,
[02:02:23.100 --> 02:02:26.140]   way back 20 years in the old days,
[02:02:26.140 --> 02:02:28.020]   watching you on the regular television.
[02:02:28.020 --> 02:02:31.460]   And I would always watch Jason on Twit
[02:02:31.460 --> 02:02:32.620]   when he was at Tech Republic.
[02:02:32.620 --> 02:02:35.540]   So I'm honored to be on today, had a wonderful time.
[02:02:35.540 --> 02:02:36.940]   Hope you guys won't invite me back.
[02:02:36.940 --> 02:02:40.540]   - Oh, you're a worthy successor to Jason Heiner.
[02:02:40.540 --> 02:02:42.340]   Editor in chief at the Tech Republic.
[02:02:42.340 --> 02:02:44.660]   He's the guy who does the cracking open.
[02:02:44.660 --> 02:02:46.820]   And now this is gonna be my new best thing.
[02:02:46.820 --> 02:02:49.220]   I'm so excited of it to find that.
[02:02:49.220 --> 02:02:51.300]   And we will see you again very soon.
[02:02:51.300 --> 02:02:53.180]   What's your Twitter handle, Bill?
[02:02:53.180 --> 02:02:54.380]   - @Bill Detweiler.
[02:02:54.380 --> 02:02:55.220]   - Very simple.
[02:02:55.220 --> 02:02:58.380]   - D-E-T-W-I-L-E-R.
[02:02:58.380 --> 02:02:59.580]   - Thanks, Bill.
[02:02:59.580 --> 02:03:01.300]   It's great to see you again, Michael Nunez
[02:03:01.300 --> 02:03:02.740]   at your new gig at Forbes,
[02:03:02.740 --> 02:03:04.820]   where he is an associate editor.
[02:03:04.820 --> 02:03:06.580]   You having fun?
[02:03:06.580 --> 02:03:07.420]   - I am, yeah.
[02:03:07.420 --> 02:03:08.660]   Thank you so much for having me on today.
[02:03:08.660 --> 02:03:09.700]   This panel was great.
[02:03:09.700 --> 02:03:10.540]   - Wasn't it?
[02:03:10.540 --> 02:03:11.380]   - It's been awesome.
[02:03:11.380 --> 02:03:14.220]   Bill and Christina, two very insightful,
[02:03:14.220 --> 02:03:15.540]   very fun people to talk to you.
[02:03:15.540 --> 02:03:17.540]   So, I'm just happy to be back.
[02:03:17.540 --> 02:03:18.460]   - Yeah, yeah.
[02:03:18.460 --> 02:03:19.300]   - Yeah, thanks so much.
[02:03:19.300 --> 02:03:20.420]   - We'll get you back real soon.
[02:03:20.420 --> 02:03:23.340]   And we'll also get you a better camera next time.
[02:03:23.340 --> 02:03:24.660]   (laughs)
[02:03:24.660 --> 02:03:25.500]   I apologize.
[02:03:25.500 --> 02:03:26.340]   - Sorry about that.
[02:03:26.340 --> 02:03:27.180]   - It's funny.
[02:03:27.180 --> 02:03:31.340]   I mean, the eyesight for its day was considered a great camera,
[02:03:31.340 --> 02:03:34.820]   but 10 years, fast forward 10 years, and it's not.
[02:03:34.820 --> 02:03:37.740]   - I know, sometimes I forget how old this computer is.
[02:03:37.740 --> 02:03:39.660]   I've hauled onto it because the keyboard's good.
[02:03:39.660 --> 02:03:42.660]   It's still running relatively well.
[02:03:42.660 --> 02:03:44.940]   But then I turned on the webcam and realized
[02:03:44.940 --> 02:03:47.180]   it's been a while since I've upgraded.
[02:03:47.180 --> 02:03:50.220]   So, that's on the to-do list for 2020.
[02:03:50.220 --> 02:03:52.900]   So, next time I come back, hopefully I'll have a,
[02:03:52.900 --> 02:03:54.700]   you'll be able to see me in HD or 4K.
[02:03:54.700 --> 02:03:56.580]   - Hannah, Christina's way you could just take one off
[02:03:56.580 --> 02:03:58.980]   the shelf of the Amazon ghost store.
[02:03:58.980 --> 02:04:00.420]   - That's exactly it.
[02:04:00.420 --> 02:04:01.500]   That's exactly it, Mike.
[02:04:01.500 --> 02:04:03.860]   Just ask you to pick one up for your opening to you.
[02:04:03.860 --> 02:04:05.820]   But I'm in New York in two weeks.
[02:04:05.820 --> 02:04:08.260]   - Christina Warren, developer relations at Microsoft.
[02:04:08.260 --> 02:04:11.540]   I'm so glad the coronavirus kept you home.
[02:04:11.540 --> 02:04:12.380]   You weren't in Zurich.
[02:04:12.380 --> 02:04:14.020]   It was fun to have you on.
[02:04:14.020 --> 02:04:14.860]   - Well, thank you for having me.
[02:04:14.860 --> 02:04:16.180]   I was planning on doing it from Zurich.
[02:04:16.180 --> 02:04:17.100]   I had good internet.
[02:04:17.100 --> 02:04:18.660]   I was like very excited.
[02:04:18.660 --> 02:04:21.580]   But I'm still glad to be able to be on anyway.
[02:04:21.580 --> 02:04:23.660]   And always good to see you.
[02:04:23.660 --> 02:04:24.740]   Nice to meet you, Bill.
[02:04:24.740 --> 02:04:28.820]   And good to see my old coworker, Mike,
[02:04:28.820 --> 02:04:30.580]   even with his retro camera.
[02:04:30.580 --> 02:04:32.820]   - That's right, Mike was imaginable, wasn't he?
[02:04:32.820 --> 02:04:34.500]   - It used a national, we worked together at Gizmo.
[02:04:34.500 --> 02:04:35.500]   - Well, we worked together at Gizmo.
[02:04:35.500 --> 02:04:36.660]   - His mode, yeah.
[02:04:36.660 --> 02:04:37.500]   - Wow.
[02:04:37.500 --> 02:04:39.660]   - Yeah, so, yeah.
[02:04:39.660 --> 02:04:41.660]   And then Christina moved across the country.
[02:04:41.660 --> 02:04:43.340]   And I'm still mad at her about that.
[02:04:43.340 --> 02:04:44.380]   - And got hit by a bus.
[02:04:44.380 --> 02:04:45.380]   So the whole thing.
[02:04:45.380 --> 02:04:47.060]   - It did, it was the whole thing.
[02:04:47.060 --> 02:04:48.380]   - Oh my God, I forgot that.
[02:04:48.380 --> 02:04:50.460]   - You're fully recovered from that, I should point out.
[02:04:50.460 --> 02:04:52.540]   - Fully recovered from the bus accident, yeah.
[02:04:52.540 --> 02:04:53.620]   - It's great to have all three of you.
[02:04:53.620 --> 02:04:54.460]   - Wasn't hit by the bus,
[02:04:54.460 --> 02:04:56.300]   it was hit by the SUV and thrown under the bus.
[02:04:56.300 --> 02:04:57.140]   But yeah, it's sick.
[02:04:57.140 --> 02:04:57.980]   - Oh, much better.
[02:04:57.980 --> 02:04:58.820]   - Much better.
[02:04:58.820 --> 02:05:00.300]   - Much better.
[02:05:00.300 --> 02:05:02.860]   Thrown under a bus in Seattle.
[02:05:02.860 --> 02:05:06.180]   We do this week in Twitch, this week in tech,
[02:05:06.180 --> 02:05:09.900]   every Sunday afternoon, usually about 130 Pacific,
[02:05:09.900 --> 02:05:12.420]   no, 230 Pacific, 430.
[02:05:12.420 --> 02:05:13.660]   I'm sorry, let me start over.
[02:05:13.660 --> 02:05:15.980]   We do it every Sunday afternoon
[02:05:15.980 --> 02:05:19.100]   at 230 Pacific, 530 Eastern time.
[02:05:19.100 --> 02:05:20.060]   Am I right, Karsten?
[02:05:20.060 --> 02:05:21.980]   Can you do the math you went to Harvard?
[02:05:21.980 --> 02:05:23.660]   Five, yes, is that right?
[02:05:23.660 --> 02:05:26.060]   2230 UTC, you can zoom in on the website.
[02:05:26.060 --> 02:05:28.100]   That's where it is.
[02:05:28.100 --> 02:05:30.700]   If you wanna watch live, we do live audio and video streams
[02:05:30.700 --> 02:05:33.020]   at twit.tv/live.
[02:05:33.020 --> 02:05:34.740]   You can also watch us in the studio.
[02:05:34.740 --> 02:05:38.260]   We briefly considered closing the studio
[02:05:38.260 --> 02:05:39.980]   for, you know, 'cause of the virus and stuff.
[02:05:39.980 --> 02:05:42.260]   And I asked the employees, I said, I don't care,
[02:05:42.260 --> 02:05:43.340]   but would you?
[02:05:43.340 --> 02:05:45.540]   And they said, no, we like having people here.
[02:05:45.540 --> 02:05:49.060]   So don't come sick, but if you feel all right,
[02:05:49.060 --> 02:05:51.620]   come just email tickets at twit.tv.
[02:05:51.620 --> 02:05:54.980]   We'll put a sanitized chair out for you.
[02:05:54.980 --> 02:05:55.980]   Just wash your hands.
[02:05:55.980 --> 02:05:57.780]   And wash your hands, don't forget.
[02:05:57.780 --> 02:06:01.180]   But please don't attempt to go through the glass barrier
[02:06:01.180 --> 02:06:04.140]   because it's sterile in here.
[02:06:04.140 --> 02:06:06.580]   No, it's great to have you.
[02:06:06.580 --> 02:06:08.220]   If you wanna watch the show on demand,
[02:06:08.220 --> 02:06:09.580]   you can watch it at your convenience.
[02:06:09.580 --> 02:06:12.460]   There are copies of it at the website, twit.tv,
[02:06:12.460 --> 02:06:13.740]   also on YouTube.
[02:06:13.740 --> 02:06:15.860]   Honestly, the best way to do it is to subscribe
[02:06:15.860 --> 02:06:17.540]   in your podcast client.
[02:06:17.540 --> 02:06:19.580]   Whatever one you use, you'll get it automatically,
[02:06:19.580 --> 02:06:21.900]   audio or video, and it'll be there for your Monday morning.
[02:06:21.900 --> 02:06:24.140]   You don't have to think about it.
[02:06:24.140 --> 02:06:26.660]   But I don't want you to miss a single episode.
[02:06:26.660 --> 02:06:28.860]   If you're gonna be in St. Louis,
[02:06:28.860 --> 02:06:31.980]   Tuesday night, come over to the train wreck saloon
[02:06:31.980 --> 02:06:33.900]   in the portal area.
[02:06:33.900 --> 02:06:36.740]   We're gonna have a little meetup, no host bar,
[02:06:36.740 --> 02:06:39.180]   at 7.30 p.m. at the train wreck saloon.
[02:06:39.180 --> 02:06:40.740]   They said, I'll be there.
[02:06:40.740 --> 02:06:43.580]   If you're a WWT customer, come to the panel event.
[02:06:43.580 --> 02:06:44.780]   We're doing the next day.
[02:06:44.780 --> 02:06:46.620]   The future of cloud computing.
[02:06:46.620 --> 02:06:48.180]   Mary Jo Foley will be there.
[02:06:48.180 --> 02:06:51.460]   Alex Lindsey will be on the panel.
[02:06:51.460 --> 02:06:52.980]   It's gonna be a very interesting panel.
[02:06:52.980 --> 02:06:54.500]   We will make a broadcast out of it.
[02:06:54.500 --> 02:06:57.020]   You get a chance to see it after the fact
[02:06:57.020 --> 02:06:59.700]   on the Twit specials stream.
[02:06:59.700 --> 02:07:01.140]   Thanks everybody for joining us.
[02:07:01.140 --> 02:07:02.340]   We'll see you next time.
[02:07:02.340 --> 02:07:04.100]   Another twin.
[02:07:04.100 --> 02:07:05.260]   This is amazing.
[02:07:05.260 --> 02:07:06.100]   Bye bye.
[02:07:06.100 --> 02:07:08.680]   (upbeat music)
[02:07:08.680 --> 02:07:09.520]   ♪ Do it the twit ♪
[02:07:09.520 --> 02:07:10.680]   ♪ All right ♪
[02:07:10.680 --> 02:07:12.540]   ♪ Do it the twit, baby ♪
[02:07:12.540 --> 02:07:13.380]   Do it the twist.
[02:07:13.380 --> 02:07:14.220]   All right.
[02:07:14.220 --> 02:07:15.220]   Do it the twist.
[02:07:15.220 --> 02:07:17.220]   Don't forget to subscribe!

