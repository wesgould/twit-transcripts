;FFMETADATA1
title=Warm Tushie Tech
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=664
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:06.520]   Coming up on Twit, Leo's not here, but we have a great show for you with issues like
[00:00:06.520 --> 00:00:13.440]   what the Sprint T-Mobile merger means for your cell phone bill, why an open-source DNA database
[00:00:13.440 --> 00:00:20.080]   is a lot like taking a Facebook quiz, and what technology makes you truly happy.
[00:00:20.080 --> 00:00:25.520]   I'll give you a hint, it's not these Snapchat spectacles I'm putting on right now.
[00:00:25.520 --> 00:00:30.800]   NetCasts you love.
[00:00:30.800 --> 00:00:32.520]   From people you trust.
[00:00:32.520 --> 00:00:38.360]   This is Twit.
[00:00:38.360 --> 00:00:44.960]   Bandwidth for this weekend tech is provided by CashFly at CACHEFLY.com.
[00:00:50.400 --> 00:00:57.280]   This is Twit, Episode 664 recorded April 29th, 2018.
[00:00:57.280 --> 00:01:01.320]   Warm Tushy Tech.
[00:01:01.320 --> 00:01:04.480]   This weekend tech is brought to you by MOVESoft.
[00:01:04.480 --> 00:01:07.360]   Reduce IT alerts and tickets by up to 99%.
[00:01:07.360 --> 00:01:12.400]   Visit MOVESoft.com to learn more and sign up for a demo.
[00:01:12.400 --> 00:01:13.880]   And by Quip.
[00:01:13.880 --> 00:01:17.240]   Make a fresh start this year with a Quip Electric Toothbrush.
[00:01:17.240 --> 00:01:20.760]   It cleans like a premium electric toothbrush at a fraction of the cost.
[00:01:20.760 --> 00:01:26.240]   Visit getquip.com/twit to get your first refill pack free when you purchase any Quip
[00:01:26.240 --> 00:01:28.320]   electric toothbrush.
[00:01:28.320 --> 00:01:30.880]   And by Stamps.com.
[00:01:30.880 --> 00:01:34.840]   Buy and print real U.S. postage the instant you need it right from your desk.
[00:01:34.840 --> 00:01:40.600]   For our special offer go to Stamps.com, click on the microphone and enter Twit.
[00:01:40.600 --> 00:01:42.560]   And by Aptiv.
[00:01:42.560 --> 00:01:47.960]   Aptiv produces audio based workouts created by certified personal trainers through a mobile
[00:01:47.960 --> 00:01:53.320]   app with great music to get 30% off new annual memberships when you visit Aptiv.
[00:01:53.320 --> 00:01:55.840]   A-A-P-T-I-V.com/twit.
[00:01:55.840 --> 00:02:01.000]   It's time for Twit.
[00:02:01.000 --> 00:02:06.240]   This is the show where we unpack the week's tech headlines with thoughtful dialogue, one
[00:02:06.240 --> 00:02:11.160]   hopes, and many thoughtful guests who are in the tech world.
[00:02:11.160 --> 00:02:16.320]   I'm Becky Worley filling in for Leo LaPorte who is on vacation.
[00:02:16.320 --> 00:02:18.480]   We believe in Japan.
[00:02:18.480 --> 00:02:19.480]   Okay.
[00:02:19.480 --> 00:02:20.480]   Hello Kitty.
[00:02:20.480 --> 00:02:22.960]   Pencil Boxes for everyone when he comes back.
[00:02:22.960 --> 00:02:31.640]   I am abandoning my regular Good Morning America post as technology and consumer correspondent
[00:02:31.640 --> 00:02:34.000]   to be here for Uncle Leo.
[00:02:34.000 --> 00:02:39.080]   But luckily I am joined by some real pros, interesting folks, mostly from the East Coast,
[00:02:39.080 --> 00:02:41.080]   but we'll forgive them that.
[00:02:41.080 --> 00:02:44.720]   And we start with a Canadian, which is always a good thing.
[00:02:44.720 --> 00:02:47.600]   Georgia Dow is here with us.
[00:02:47.600 --> 00:02:54.160]   She is a senior editor at iMore and also hosts anxiety-videos.com.
[00:02:54.160 --> 00:02:56.320]   That's your site because she's also a therapist.
[00:02:56.320 --> 00:02:57.320]   Welcome Georgia.
[00:02:57.320 --> 00:03:01.560]   How did you bring these two worlds together?
[00:03:01.560 --> 00:03:04.200]   It was just one of those weird things.
[00:03:04.200 --> 00:03:09.720]   Tech causes a lot of anxiety and so I figure I'll fix that and did a little bit of both.
[00:03:09.720 --> 00:03:10.720]   I love technology.
[00:03:10.720 --> 00:03:16.400]   Technology is just so much fun and I like helping people so it's a good mix in between both.
[00:03:16.400 --> 00:03:19.280]   But I'm really excited to be here today.
[00:03:19.280 --> 00:03:21.200]   You'll find out why as the show goes on.
[00:03:21.200 --> 00:03:22.760]   Ooh, this sounds like that's a good tease.
[00:03:22.760 --> 00:03:24.320]   That's what we call the business a good tease.
[00:03:24.320 --> 00:03:28.840]   So I will go from that to Ben Brock Johnson.
[00:03:28.840 --> 00:03:31.080]   He is joining us from Boston.
[00:03:31.080 --> 00:03:33.000]   WBUR is his home.
[00:03:33.000 --> 00:03:35.640]   He's a tech correspondent for Here and Now.
[00:03:35.640 --> 00:03:39.680]   And he has a great podcast on all things Reddit.
[00:03:39.680 --> 00:03:40.840]   EndlessThread.
[00:03:40.840 --> 00:03:44.920]   You can find it at www.org/endlessthread.
[00:03:44.920 --> 00:03:51.720]   I would imagine Ben that having Reddit as the bucket you can pull from, there's constant
[00:03:51.720 --> 00:03:54.840]   content there for you, isn't there?
[00:03:54.840 --> 00:03:56.560]   Pretty much anything.
[00:03:56.560 --> 00:04:01.840]   It's like having your beat be the internet, which is, you know, that's what I'm used to
[00:04:01.840 --> 00:04:02.840]   anyway.
[00:04:02.840 --> 00:04:03.840]   So I love it.
[00:04:03.840 --> 00:04:04.840]   It's amazing.
[00:04:04.840 --> 00:04:09.280]   We find amazing stories and like really interesting users and talk to them.
[00:04:09.280 --> 00:04:10.400]   And it's a lot of fun.
[00:04:10.400 --> 00:04:15.880]   I mean, Reddit can be a scary place, but we find a lot of like non scary stories to tell
[00:04:15.880 --> 00:04:17.560]   and some scary ones too.
[00:04:17.560 --> 00:04:19.600]   But it's a lot of fun.
[00:04:19.600 --> 00:04:24.640]   What are some of the elements that make for a great podcast around a Reddit thread?
[00:04:24.640 --> 00:04:29.640]   Like, what does it have to have that makes it ideal for discussing in podcast form?
[00:04:29.640 --> 00:04:31.960]   That's a great question.
[00:04:31.960 --> 00:04:39.440]   I guess I would say mystery, a little bit of mystery, a little bit of stakes, hopefully
[00:04:39.440 --> 00:04:48.040]   high stakes in some way or interesting stakes, hopefully diverse voices, interesting different
[00:04:48.040 --> 00:04:53.880]   kinds of people from different walks of life talking and something that we can tell in
[00:04:53.880 --> 00:04:54.880]   a narrative way.
[00:04:54.880 --> 00:04:59.960]   So it's a narrative podcast, you know, think something like this American life or reply
[00:04:59.960 --> 00:05:02.520]   all or something like that.
[00:05:02.520 --> 00:05:07.840]   And so as long as it's like a good story and we can tell it, it's good.
[00:05:07.840 --> 00:05:12.600]   The more things change, the more storytelling is just the basis of everything that we do
[00:05:12.600 --> 00:05:13.600]   in entertainment.
[00:05:13.600 --> 00:05:14.600]   I love it.
[00:05:14.600 --> 00:05:17.280]   Also joining us for Massachusetts is Brianna Wu.
[00:05:17.280 --> 00:05:24.440]   She is a game developer, podcaster and running for Congress for Massachusetts 8th district,
[00:05:24.440 --> 00:05:29.040]   again, a varied and diverse set of qualifications.
[00:05:29.040 --> 00:05:34.040]   How does one go from game developer to potential congressional representative?
[00:05:34.040 --> 00:05:37.560]   Well, I think it's important to remember I worked as an investigative journalist for
[00:05:37.560 --> 00:05:38.560]   many years.
[00:05:38.560 --> 00:05:43.200]   You know, I've worked for, you know, all different branches of political campaigns.
[00:05:43.200 --> 00:05:44.840]   I've done constituent services.
[00:05:44.840 --> 00:05:49.800]   So for me, it was like the sum of my lifetime of experience.
[00:05:49.800 --> 00:05:54.520]   You know, one of the things that really brought me to national recognition was gamergate,
[00:05:54.520 --> 00:05:59.960]   a subject that was covered quite a bit on Reddit, I believe, not always a glowing terms towards
[00:05:59.960 --> 00:06:00.960]   me.
[00:06:00.960 --> 00:06:06.680]   You know, basically it was a rash of threats on women in the game industry.
[00:06:06.680 --> 00:06:12.040]   We had two meetings with the Obama White House asking them to act on threats on my life and
[00:06:12.040 --> 00:06:14.760]   life of other women in the game industry.
[00:06:14.760 --> 00:06:17.280]   And they chose to do nothing.
[00:06:17.280 --> 00:06:19.640]   Law enforcement really failed women.
[00:06:19.640 --> 00:06:24.240]   And from gamergate, we kind of saw the birth of the alt-right and it kind of led to the
[00:06:24.240 --> 00:06:26.800]   political dynamics we're seeing in our country today.
[00:06:26.800 --> 00:06:31.840]   So I think every woman in America should look at our current state of government and ask
[00:06:31.840 --> 00:06:34.640]   yourself what's holding you back from running yourself.
[00:06:34.640 --> 00:06:40.840]   If that doesn't indicate more need for women and technologists in government, we can also
[00:06:40.840 --> 00:06:46.160]   look back just two weeks to Mark Zuckerberg's testimony and how useless that was given the
[00:06:46.160 --> 00:06:48.200]   lack of understanding from our representatives.
[00:06:48.200 --> 00:06:49.760]   So it was really a bear.
[00:06:49.760 --> 00:06:50.760]   It was really a bear.
[00:06:50.760 --> 00:06:51.760]   Technologist and government is better.
[00:06:51.760 --> 00:06:52.760]   So good luck to you.
[00:06:52.760 --> 00:06:54.800]   You know, I want to start the show today.
[00:06:54.800 --> 00:06:57.400]   This so rarely happens on Twitter.
[00:06:57.400 --> 00:07:00.760]   There was actually big news that broke this morning.
[00:07:00.760 --> 00:07:08.240]   And that is in a conference call, T-Mobile CEO John Leger, Crazy Man, Genius, definitely
[00:07:08.240 --> 00:07:14.000]   colorful character, announced that T-Mobile and Sprint are going to combine into one company.
[00:07:14.000 --> 00:07:18.880]   This is a $26.5 billion merger all stock.
[00:07:18.880 --> 00:07:21.400]   The goal is to better compete with AT&T and Verizon.
[00:07:21.400 --> 00:07:27.400]   So we're taking the third and the fourth largest carriers, combining them to a company that
[00:07:27.400 --> 00:07:34.040]   would be worth $146 billion to then catapult them into second place.
[00:07:34.040 --> 00:07:39.120]   So I think, I was trying to think about this.
[00:07:39.120 --> 00:07:41.560]   Good or bad for consumers.
[00:07:41.560 --> 00:07:46.800]   You know, Georgie, you live in Canada and probably the best analog for this is that we
[00:07:46.800 --> 00:07:53.160]   saw the aggregation of Canadian carriers down to what is it?
[00:07:53.160 --> 00:07:57.240]   Bell, Tellis, Rogers, and not much more.
[00:07:57.240 --> 00:08:00.080]   And the competition has shrunk.
[00:08:00.080 --> 00:08:03.560]   Is this a good analog for what you think might happen here in the US?
[00:08:03.560 --> 00:08:05.520]   That hasn't been great for consumers, right?
[00:08:05.520 --> 00:08:07.840]   No, it rarely is.
[00:08:07.840 --> 00:08:09.800]   So we ended up with less choice.
[00:08:09.800 --> 00:08:11.240]   Even they kept the company names.
[00:08:11.240 --> 00:08:14.560]   So like Fido and Rogers are now one.
[00:08:14.560 --> 00:08:17.000]   But in the end, it's just there's less choice for consumers.
[00:08:17.000 --> 00:08:20.800]   It's great for on a company standpoint, I can completely understand why they would want
[00:08:20.800 --> 00:08:21.960]   to do that.
[00:08:21.960 --> 00:08:23.720]   And for shareholders, that's wonderful.
[00:08:23.720 --> 00:08:27.320]   But for consumers, we end up with much less choice.
[00:08:27.320 --> 00:08:29.800]   We have a really horrible system in Canada.
[00:08:29.800 --> 00:08:33.200]   We pay through the teeth for very little.
[00:08:33.200 --> 00:08:35.280]   And now we have even less.
[00:08:35.280 --> 00:08:40.800]   Do you guys think, Annig totally in your own experiences, are you paying less overall
[00:08:40.800 --> 00:08:44.400]   for phone costs than you were, say, four years ago?
[00:08:44.400 --> 00:08:50.080]   I mean, one thing I have noticed is that it seems like phone turnover is slower.
[00:08:50.080 --> 00:08:55.000]   It's more like three years instead of every two for your average consumer.
[00:08:55.000 --> 00:08:58.640]   There's more bundling options for families, more unlimited data plans.
[00:08:58.640 --> 00:09:04.160]   But it's really difficult when comparing prices to see if people's overall costs have
[00:09:04.160 --> 00:09:05.160]   come down.
[00:09:05.160 --> 00:09:07.360]   Do you have a sense of that personally?
[00:09:07.360 --> 00:09:09.800]   I pay way more than I used to.
[00:09:09.800 --> 00:09:10.800]   Sorry, go ahead.
[00:09:10.800 --> 00:09:11.800]   Is that more data?
[00:09:11.800 --> 00:09:13.400]   Yeah, no, but I want more data.
[00:09:13.400 --> 00:09:14.960]   So we want more data.
[00:09:14.960 --> 00:09:16.520]   Our phones do more things.
[00:09:16.520 --> 00:09:18.600]   We do more things on them.
[00:09:18.600 --> 00:09:22.240]   And so they end up, I'm getting more for it.
[00:09:22.240 --> 00:09:24.960]   But really, I'm just paying more in the long term.
[00:09:24.960 --> 00:09:28.400]   And they really have a difficult, like we try to get family plans because there's four
[00:09:28.400 --> 00:09:29.800]   in our family.
[00:09:29.800 --> 00:09:35.160]   And they really make it difficult to be able to get your money's worth out of your plan.
[00:09:35.160 --> 00:09:38.120]   So for us, we pay more than we used to.
[00:09:38.120 --> 00:09:40.280]   And you were emphatic that you're paying more.
[00:09:40.280 --> 00:09:42.280]   What makes you say that?
[00:09:42.280 --> 00:09:47.200]   Well, I use Google Project Fi.
[00:09:47.200 --> 00:09:52.040]   And it is like, even though it's like a way more honorable setup, in my opinion, in terms
[00:09:52.040 --> 00:09:55.600]   of like how the bill is set up and how you understand your bill, how you pay, things
[00:09:55.600 --> 00:09:56.680]   like that.
[00:09:56.680 --> 00:10:01.600]   I just, I'm a data hog and I pay a lot for the data that I use.
[00:10:01.600 --> 00:10:06.000]   I mean, they, you know, I don't have an unlimited data plan through them.
[00:10:06.000 --> 00:10:11.440]   And I think I used to have an unlimited data plan through Sprint.
[00:10:11.440 --> 00:10:15.240]   And you know, and that was, you know, I don't know, maybe 30 bucks cheaper than it is now
[00:10:15.240 --> 00:10:17.560]   20 or 30 bucks.
[00:10:17.560 --> 00:10:23.300]   But I think that this is like really, I clearly this is bad for options for, you know, having
[00:10:23.300 --> 00:10:24.440]   more options.
[00:10:24.440 --> 00:10:28.200]   And I think that just ends up being bad for consumers always.
[00:10:28.200 --> 00:10:37.240]   I mean, if our broadband, you know, options as Americans are any indication, then our wireless
[00:10:37.240 --> 00:10:43.600]   options as Americans, the fewer they become the worse it gets for us, I think, both in
[00:10:43.600 --> 00:10:45.880]   terms of price and just service generally.
[00:10:45.880 --> 00:10:49.200]   I just don't think it's probably not a great sign for consumers.
[00:10:49.200 --> 00:10:54.240]   Briana, the idea of these big telecom mergers has been floated for a while.
[00:10:54.240 --> 00:10:59.080]   And in fact, one was floated during the Obama administration and they gave a pretty serious
[00:10:59.080 --> 00:11:04.000]   beat down because they felt like it really created a lack of competition that Ben and
[00:11:04.000 --> 00:11:05.920]   George are talking about.
[00:11:05.920 --> 00:11:11.600]   But we're in a really different regulatory environment right now where Masayoshi Sun,
[00:11:11.600 --> 00:11:18.680]   who's got an 80% ownership stake of Sprint, met with President Trump last year.
[00:11:18.680 --> 00:11:26.880]   We seem to be in a generally positive, less regulation type of an administration.
[00:11:26.880 --> 00:11:34.760]   But the telecom, you know, you look at the time Warner merger, that's hitting some roadblocks.
[00:11:34.760 --> 00:11:37.560]   So what's your sense of this?
[00:11:37.560 --> 00:11:40.720]   Anything from sort of the government side of whether you think this will actually go through
[00:11:40.720 --> 00:11:41.720]   and get approved?
[00:11:41.720 --> 00:11:46.000]   Well, one of the things we did from the very beginning of my campaign is we said we are
[00:11:46.000 --> 00:11:51.240]   not going to take money from telecoms, which is very popular in Congress.
[00:11:51.240 --> 00:11:57.120]   Like look at who Verizon has donated to and it's going to be a lot of people.
[00:11:57.120 --> 00:12:00.920]   The reason for that is it's, as you say, like there's a lot of pressure there from the
[00:12:00.920 --> 00:12:04.000]   government side to kind of bring all of these together.
[00:12:04.000 --> 00:12:10.360]   And they are taking advantage of basically the Republican takeover of all three houses,
[00:12:10.360 --> 00:12:13.840]   branches of government to basically get this put through.
[00:12:13.840 --> 00:12:14.840]   I agree with you, Ben.
[00:12:14.840 --> 00:12:18.120]   I think this is ridiculously consumer hostile.
[00:12:18.120 --> 00:12:22.200]   I understand there's a bandwidth argument going along with it that they're using as kind
[00:12:22.200 --> 00:12:23.680]   of a pretext.
[00:12:23.680 --> 00:12:28.240]   But even going beyond the consumer argument, I think there's an innovation argument that's
[00:12:28.240 --> 00:12:30.760]   really worth talking about here.
[00:12:30.760 --> 00:12:36.680]   When you have three companies, there's really not an incentive to innovate, not with the
[00:12:36.680 --> 00:12:40.960]   services for your phone, not from a cybersecurity perspective.
[00:12:40.960 --> 00:12:46.240]   And I really worry that that lack of competition is really going to make America just simply
[00:12:46.240 --> 00:12:47.920]   less competitive.
[00:12:47.920 --> 00:12:53.000]   It's going to add to this environment where you can't even have new companies coming along
[00:12:53.000 --> 00:12:58.640]   and getting market share in an environment like this.
[00:12:58.640 --> 00:13:00.400]   So I'm 100% against it.
[00:13:00.400 --> 00:13:01.960]   I don't think it's good for consumers.
[00:13:01.960 --> 00:13:04.640]   I don't think it's good for the economy.
[00:13:04.640 --> 00:13:07.040]   And I would definitely vote against you if I were able to.
[00:13:07.040 --> 00:13:09.240]   I agree with you, Brie.
[00:13:09.240 --> 00:13:12.920]   Actually, that's what happened in Canada as well, is that they fought against having new
[00:13:12.920 --> 00:13:15.520]   companies come in to use through the infrastructure.
[00:13:15.520 --> 00:13:19.760]   They were against it, even though we all pay through our taxes for the infrastructure and
[00:13:19.760 --> 00:13:21.160]   being able to take care of it.
[00:13:21.160 --> 00:13:24.760]   But they've actually stopped new companies and competition from coming in, which then
[00:13:24.760 --> 00:13:27.920]   again, hurts the consumer as well.
[00:13:27.920 --> 00:13:33.200]   To play the opposite side of the coin, one of the things that Sprint and T-Mobile are touting
[00:13:33.200 --> 00:13:36.160]   is that they'll have increased coverage.
[00:13:36.160 --> 00:13:42.480]   Android Central has a pretty good map showing the combined coverage of both T-Mobile and
[00:13:42.480 --> 00:13:43.480]   Sprint.
[00:13:43.480 --> 00:13:46.400]   And it does really widen it out.
[00:13:46.400 --> 00:13:51.840]   And the second thing they talk about is fixed broadband in terms of creating more infrastructure
[00:13:51.840 --> 00:14:00.320]   for 5G internet coverage in places where there isn't enough population density to have fixed
[00:14:00.320 --> 00:14:01.320]   lines.
[00:14:01.320 --> 00:14:06.320]   So they say that that's providing a public service and that that's the innovation they
[00:14:06.320 --> 00:14:10.680]   can bring by bringing the companies together.
[00:14:10.680 --> 00:14:16.160]   And to your point, Brie, about Spectrum, one of the reasons why they're doing this is because
[00:14:16.160 --> 00:14:22.320]   Sprint owns a ton of Spectrum that T-Mobile wants to get their hands on.
[00:14:22.320 --> 00:14:28.920]   Sprint's going down in terms of their overall customer base while T-Mobile doubled theirs
[00:14:28.920 --> 00:14:30.200]   last year.
[00:14:30.200 --> 00:14:35.800]   So the T-Mobile brand is working, but Sprint has all that Spectrum and they see themselves
[00:14:35.800 --> 00:14:41.480]   as creating more competition in the marketplace by having three strong companies as opposed
[00:14:41.480 --> 00:14:48.960]   to AT&T and Verizon dominating while then you have a sub-tier of Sprint and Verizon and
[00:14:48.960 --> 00:14:51.240]   then you go down into the regional carriers.
[00:14:51.240 --> 00:14:53.640]   And I understand that argument.
[00:14:53.640 --> 00:14:56.480]   I think those are valid concerns.
[00:14:56.480 --> 00:15:01.040]   There are many ways to get there and address those concerns that aren't creating, like,
[00:15:01.040 --> 00:15:06.840]   limiting our choices as consumers from four companies to three companies.
[00:15:06.840 --> 00:15:10.480]   You have Sprint selling T-Mobile bandwidth or lending it.
[00:15:10.480 --> 00:15:14.960]   You could talk to the FCC and allocate more bandwidth for these different companies.
[00:15:14.960 --> 00:15:19.920]   If you're talking about more coverage, we could create an environment where people could
[00:15:19.920 --> 00:15:24.880]   lease basically broadcast towers from other self-providers.
[00:15:24.880 --> 00:15:29.000]   There are a lot of ways to get there that aren't so consumer hostile.
[00:15:29.000 --> 00:15:36.200]   The bottom line is, Verizon, AT&T, T-Mobile, they have lobbyists, they have lawyers on your
[00:15:36.200 --> 00:15:37.720]   side, on their side.
[00:15:37.720 --> 00:15:42.480]   The only people they're advocating for you is the United States Congress.
[00:15:42.480 --> 00:15:48.200]   And I think when they are so eager to give these telecom companies exactly what they're
[00:15:48.200 --> 00:15:53.960]   asking for down to letting them draft the legislation, I just think it leads to nobody
[00:15:53.960 --> 00:15:55.960]   really looking out for you.
[00:15:55.960 --> 00:15:58.760]   I think these companies are people-free.
[00:15:58.760 --> 00:16:00.000]   I'm sorry.
[00:16:00.000 --> 00:16:01.920]   These companies are people, though.
[00:16:01.920 --> 00:16:03.880]   So, come see this as United.
[00:16:03.880 --> 00:16:04.880]   Yes.
[00:16:04.880 --> 00:16:10.200]   I also think it's interesting to think about just the argument that companies like this
[00:16:10.200 --> 00:16:17.600]   make for doing mergers like this that essentially, "Oh, it'll allow us to build more infrastructure
[00:16:17.600 --> 00:16:19.280]   to underserved areas."
[00:16:19.280 --> 00:16:29.080]   I think that that's a popular argument to make by companies when they make a push like this.
[00:16:29.080 --> 00:16:33.280]   But I don't think it's one, and obviously someone correct me if I'm wrong, I don't
[00:16:33.280 --> 00:16:36.880]   think it's one that usually plays out in reality.
[00:16:36.880 --> 00:16:45.480]   If we look at the history of telecom and look at examples of way, way, way back in the day,
[00:16:45.480 --> 00:16:52.280]   they'll completely leaving out farming communities and just not building infrastructure.
[00:16:52.280 --> 00:16:58.280]   And farmers having to create party lines themselves with electric fences and things
[00:16:58.280 --> 00:16:59.280]   like that.
[00:16:59.280 --> 00:17:04.160]   I think you look at the history of this and you just basically, these companies, sure,
[00:17:04.160 --> 00:17:07.480]   they'll build infrastructure if it actually means that they're going to make more money
[00:17:07.480 --> 00:17:11.040]   and it impacts their bottom line.
[00:17:11.040 --> 00:17:16.440]   But making the argument that gaining more capital through this kind of merger is going
[00:17:16.440 --> 00:17:22.920]   to give a bunch of areas that don't have good service, good service in the future, or better
[00:17:22.920 --> 00:17:24.480]   5G or something like that.
[00:17:24.480 --> 00:17:29.200]   I mean, I do think that this could be good for 5G because of the spectrum ownership of
[00:17:29.200 --> 00:17:35.280]   both companies and how they might build that out as 5G comes.
[00:17:35.280 --> 00:17:42.320]   But again, it's not like 5G is not going to come if this merger doesn't happen.
[00:17:42.320 --> 00:17:46.320]   And it's not like these companies are going to actually build infrastructure to underserved
[00:17:46.320 --> 00:17:49.000]   areas just because this merger happens.
[00:17:49.000 --> 00:17:52.120]   So I think it's good to think about that stuff too.
[00:17:52.120 --> 00:17:58.000]   One of the counter arguments here was that the cell phone industry and selling service
[00:17:58.000 --> 00:18:02.320]   has been so commoditized basically in terms of phones are sort of predictable.
[00:18:02.320 --> 00:18:05.040]   There's no huge innovation going on here.
[00:18:05.040 --> 00:18:08.120]   For a little settling in the industry is to be expected.
[00:18:08.120 --> 00:18:11.480]   Do you feel that's true or do you still feel like there's tons more innovation to happen
[00:18:11.480 --> 00:18:14.000]   in this space?
[00:18:14.000 --> 00:18:18.160]   I think we're going to cover some stories later on in the show about Apple and their
[00:18:18.160 --> 00:18:20.000]   plans for AR and VR.
[00:18:20.000 --> 00:18:24.160]   I do agree that a current mobile phone idea is kind of plateaued.
[00:18:24.160 --> 00:18:31.160]   I love my iPhone X, but it's not a huge evolution from what I do with my iPhone 8.
[00:18:31.160 --> 00:18:36.640]   But I think like coming back to that innovation argument, this is what I would say.
[00:18:36.640 --> 00:18:43.480]   We are not going to move towards the future if we aren't really investing in new ideas.
[00:18:43.480 --> 00:18:48.120]   One of my economic plans is Congress is I do want to work more closely with the venture
[00:18:48.120 --> 00:18:49.440]   capital community.
[00:18:49.440 --> 00:18:55.840]   I think that a lot of the regulations they work under were really put in place before
[00:18:55.840 --> 00:19:00.880]   we were really, we had our tech industry the way it is today.
[00:19:00.880 --> 00:19:07.040]   That system works because it's a lot of people fiercely competing against each other.
[00:19:07.040 --> 00:19:11.480]   It's worth going back in time and looking at Apple, introduce the iPhone, they had to
[00:19:11.480 --> 00:19:16.480]   really fight this status quo in the telecom industry and the cellular industry to get
[00:19:16.480 --> 00:19:21.400]   that phone out with patches and data and like texting protocols.
[00:19:21.400 --> 00:19:25.280]   They really had to go to war to get those things done.
[00:19:25.280 --> 00:19:29.040]   I would argue that settling in the industry, it's not a good thing.
[00:19:29.040 --> 00:19:33.280]   It's just going to stop us from getting to that next level of innovation.
[00:19:33.280 --> 00:19:35.160]   Roland in the chatroom makes a really good point.
[00:19:35.160 --> 00:19:39.880]   He says you usually need eight companies and no dominant company of those eight to get
[00:19:39.880 --> 00:19:45.320]   an effective market that's more consumer surplus and less producer surplus.
[00:19:45.320 --> 00:19:49.400]   Kind of interesting to think about what does it really take to have competition in these
[00:19:49.400 --> 00:19:52.320]   markets.
[00:19:52.320 --> 00:19:56.320]   It's just so nice to have breaking news on a Sunday that I had to start with this story.
[00:19:56.320 --> 00:20:01.880]   We have a huge, huge bit of news to talk about with Amazon.
[00:20:01.880 --> 00:20:04.240]   What a crazy week they had.
[00:20:04.240 --> 00:20:06.600]   Let me take a quick break.
[00:20:06.600 --> 00:20:09.480]   Have Leo tell you about one of our great sponsors and then we're going to come back
[00:20:09.480 --> 00:20:14.040]   and ask, will you be buying an Amazon robot for your home?
[00:20:14.040 --> 00:20:15.040]   Excuse me.
[00:20:15.040 --> 00:20:16.840]   I want to interrupt this fine program.
[00:20:16.840 --> 00:20:23.960]   Hello, Leo here in Japan where I'm very calm and relaxed because I'm not being bugged
[00:20:23.960 --> 00:20:27.120]   by IT alerts are sponsored today.
[00:20:27.120 --> 00:20:32.200]   Mughsof specializes in reducing IT alerts, giving you just the alerts you need so there's
[00:20:32.200 --> 00:20:34.080]   an actionable thing you can do.
[00:20:34.080 --> 00:20:35.080]   Look at this.
[00:20:35.080 --> 00:20:39.080]   Wouldn't you love to be here relaxed, enjoying scenery, enjoying life?
[00:20:39.080 --> 00:20:43.760]   IT people know how it is when you get those alerts and those tickets and they're lighting
[00:20:43.760 --> 00:20:46.320]   up your monitor like a Christmas tree.
[00:20:46.320 --> 00:20:48.960]   You're not being productive, you're just being stressed out.
[00:20:48.960 --> 00:20:53.200]   No more mortal can analyze all those alerts and respond to all those tickets.
[00:20:53.200 --> 00:21:00.000]   Well good news, you can immediately reduce the noise with Mughsoft, M-double-o-g-s-o-f-t,
[00:21:00.000 --> 00:21:01.640]   Mughsoft-a-i-ops.
[00:21:01.640 --> 00:21:06.680]   Mughsoft-a-i-ops is an algorithmic IT ops platform that reduces IT alerts and tickets
[00:21:06.680 --> 00:21:08.840]   by up to 99% guaranteed.
[00:21:08.840 --> 00:21:09.840]   Imagine that.
[00:21:09.840 --> 00:21:12.640]   It doesn't mean you don't get those tickets, it doesn't mean you don't get the alerts
[00:21:12.640 --> 00:21:14.320]   but you get the ones that count.
[00:21:14.320 --> 00:21:18.560]   Mughsoft's AI ops platform integrates with all your existing IT tools.
[00:21:18.560 --> 00:21:20.800]   It's patented technology correlates events.
[00:21:20.800 --> 00:21:23.680]   This is the key into actionable work items.
[00:21:23.680 --> 00:21:25.480]   They call them situations.
[00:21:25.480 --> 00:21:29.520]   So you focus on the situation, on tackling the stuff that matters instead of ping, ping,
[00:21:29.520 --> 00:21:31.640]   ping, ping, ping.
[00:21:31.640 --> 00:21:36.360]   Let me tell you about one company that uses Mughsoft-a-i-ops, HCL Technologies.
[00:21:36.360 --> 00:21:41.040]   They're a global IT managed service provider and they build Mughsoft-a-i-ops into their
[00:21:41.040 --> 00:21:45.800]   event management layer right within their award-winning driest platform.
[00:21:45.800 --> 00:21:46.800]   What does that do?
[00:21:46.800 --> 00:21:52.400]   It's helped its clients streamline operational workflows reduce time in the quote "detect
[00:21:52.400 --> 00:21:55.200]   to correct life cycle of incident tickets."
[00:21:55.200 --> 00:22:01.480]   HCL has experienced a one-third reduction in mean time to restore.
[00:22:01.480 --> 00:22:03.200]   That lets them support more customers.
[00:22:03.200 --> 00:22:04.960]   This is a quote from HCL.
[00:22:04.960 --> 00:22:09.440]   More customers with service quality while keeping operational costs low, efficiency high.
[00:22:09.440 --> 00:22:10.760]   You want this.
[00:22:10.760 --> 00:22:13.480]   Reduce IT alerts and tickets by up to 99%.
[00:22:13.480 --> 00:22:17.560]   Visit Mughsoft.com to learn more and sign up for a demo.
[00:22:17.560 --> 00:22:23.480]   That means life could be Pacific once again.
[00:22:23.480 --> 00:22:24.480]   Thank you Mughsoft.
[00:22:24.480 --> 00:22:26.520]   Find out more at Mughsoft.
[00:22:26.520 --> 00:22:28.760]   M-W-O-G-S-O-F-T.
[00:22:28.760 --> 00:22:29.760]   Mughsoft.com.
[00:22:29.760 --> 00:22:33.760]   And we thank Mughsoft for their support of this week in tech.
[00:22:33.760 --> 00:22:37.000]   Now, back to the show.
[00:22:37.000 --> 00:22:39.000]   Peace and quiet.
[00:22:39.000 --> 00:22:40.000]   Imagine.
[00:22:40.000 --> 00:22:45.320]   Ah, I'm not doing this on TV.
[00:22:45.320 --> 00:22:46.720]   Back to the show.
[00:22:46.720 --> 00:22:48.200]   This week in tech.
[00:22:48.200 --> 00:22:51.120]   Okay, we're not doing the show in Japanese.
[00:22:51.120 --> 00:22:53.720]   He's only in Japan.
[00:22:53.720 --> 00:22:55.240]   I had to.
[00:22:55.240 --> 00:22:56.240]   Come on.
[00:22:56.240 --> 00:23:00.840]   You don't take two years of Japanese in college to not take advantage of that show.
[00:23:00.840 --> 00:23:01.840]   That was pretty impressive.
[00:23:01.840 --> 00:23:02.840]   Come on.
[00:23:02.840 --> 00:23:03.840]   That was very good.
[00:23:03.840 --> 00:23:04.840]   That was a good one.
[00:23:04.840 --> 00:23:05.840]   A good one.
[00:23:05.840 --> 00:23:06.840]   Hi.
[00:23:06.840 --> 00:23:07.840]   I used to wait for me.
[00:23:07.840 --> 00:23:10.600]   I used to wait just at a Japanese restaurant.
[00:23:10.600 --> 00:23:14.960]   And so I figured that by taking my language elective in Japanese, I could make better
[00:23:14.960 --> 00:23:15.960]   tips.
[00:23:15.960 --> 00:23:17.960]   Did it work?
[00:23:17.960 --> 00:23:19.840]   It did work.
[00:23:19.840 --> 00:23:25.920]   You know, I would go up to these sleepy hungover Japanese businessmen who were there for breakfast.
[00:23:25.920 --> 00:23:30.720]   It was in the Japanese hotel and I would say, "Oh, I'm going to go to the house and they
[00:23:30.720 --> 00:23:32.720]   would have their newspaper up."
[00:23:32.720 --> 00:23:39.720]   And then they'd bring their newspaper down and they'd see me and they'd go, "Eh."
[00:23:39.720 --> 00:23:41.720]   That's great.
[00:23:41.720 --> 00:23:42.720]   That's awesome.
[00:23:42.720 --> 00:23:44.560]   Yeah, that was good.
[00:23:44.560 --> 00:23:48.920]   When I graduated from college, I got recruited for my Japanese strangely enough.
[00:23:48.920 --> 00:23:55.640]   The options were the CIA and Escort Service in Kyoto.
[00:23:55.640 --> 00:23:57.520]   I chose neither.
[00:23:57.520 --> 00:23:58.840]   Here I am, a tech reporter.
[00:23:58.840 --> 00:24:00.920]   You could have gone into game translation.
[00:24:00.920 --> 00:24:02.360]   You could have had an awesome...
[00:24:02.360 --> 00:24:04.600]   You could have translated a final fantasy game.
[00:24:04.600 --> 00:24:05.600]   I know, I know.
[00:24:05.600 --> 00:24:08.880]   I'm thinking Go CIA, but that's just...
[00:24:08.880 --> 00:24:14.480]   I didn't know which one was sort of morally more questionable.
[00:24:14.480 --> 00:24:17.280]   I would assume that they were combined, but that's...
[00:24:17.280 --> 00:24:20.960]   I mean, if you watched the homeland, you would think they are, right?
[00:24:20.960 --> 00:24:23.400]   It seems they're very commingled, right?
[00:24:23.400 --> 00:24:24.400]   Okay.
[00:24:24.400 --> 00:24:27.880]   This is a tech podcast, my bad.
[00:24:27.880 --> 00:24:34.080]   Big week in tech, it was earnings week for pretty much everybody but Apple.
[00:24:34.080 --> 00:24:35.080]   It was just...
[00:24:35.080 --> 00:24:42.040]   I don't think I've ever seen a week like this where profits were so good beating the street
[00:24:42.040 --> 00:24:43.040]   in expectations.
[00:24:43.040 --> 00:24:48.640]   That didn't always mean that the stock prices went up commensurately, but let's start with
[00:24:48.640 --> 00:24:52.840]   Amazon because sales were up 43 percent.
[00:24:52.840 --> 00:25:01.280]   Their profit more than doubled, they have 100 million prime members.
[00:25:01.280 --> 00:25:06.880]   So just to put that in perspective, I always, whenever I think about prime, I think about
[00:25:06.880 --> 00:25:14.960]   Jeff Bezos sitting down with the CEO of Costco who was one of his mentors, and that was
[00:25:14.960 --> 00:25:21.480]   really the goal is to create a Costco-sized online shopping community, and they have now
[00:25:21.480 --> 00:25:22.480]   beaten Costco.
[00:25:22.480 --> 00:25:28.320]   Costco has 90 million members, and Amazon Prime now has over 100.
[00:25:28.320 --> 00:25:34.800]   So I mean, anything that you guys want to say on just Amazon slaying profits and just
[00:25:34.800 --> 00:25:36.600]   owning online shopping?
[00:25:36.600 --> 00:25:39.840]   Well, I'll say my story.
[00:25:39.840 --> 00:25:43.480]   So I never used Prime before, and then I took...
[00:25:43.480 --> 00:25:48.480]   I made the mistake of kind of taking Amazon's gateway drug, which is the free 30 days.
[00:25:48.480 --> 00:25:49.560]   I kind of did it by mistake.
[00:25:49.560 --> 00:25:54.640]   I clicked on something improperly, and then I was kind of signed up for the free month.
[00:25:54.640 --> 00:26:01.200]   And then I got the next day, you know, prime delivery, and I went, "That was awesome."
[00:26:01.200 --> 00:26:04.080]   And then I did it again, and I went, "Oh, this is amazing."
[00:26:04.080 --> 00:26:08.080]   Then I started going through, and it's free, and I'm like, "Oh, this is great."
[00:26:08.080 --> 00:26:09.240]   They deliver it to my door.
[00:26:09.240 --> 00:26:10.600]   They just drop it off.
[00:26:10.600 --> 00:26:15.680]   And then my month was coming up to an end, and my husband's like, "Do you want to...
[00:26:15.680 --> 00:26:16.920]   We should cancel it now."
[00:26:16.920 --> 00:26:20.080]   And I went, "Maybe let's just keep it for the year."
[00:26:20.080 --> 00:26:21.080]   And that was it.
[00:26:21.080 --> 00:26:22.080]   That was it.
[00:26:22.080 --> 00:26:24.320]   Now I am one of the hundred million.
[00:26:24.320 --> 00:26:27.000]   And I got in right before they increased the price.
[00:26:27.000 --> 00:26:29.800]   So that's great, because now it's like 119 Americans.
[00:26:29.800 --> 00:26:30.800]   So it's like...
[00:26:30.800 --> 00:26:31.800]   Yes.
[00:26:31.800 --> 00:26:32.800]   Made it.
[00:26:32.800 --> 00:26:35.200]   And I'm still really happy about it.
[00:26:35.200 --> 00:26:36.200]   I know how much I sell it.
[00:26:36.200 --> 00:26:38.000]   Are they about to increase the price again?
[00:26:38.000 --> 00:26:39.000]   Yeah, they just...
[00:26:39.000 --> 00:26:40.480]   Are they about to do it again a couple of bucks?
[00:26:40.480 --> 00:26:41.480]   They just...
[00:26:41.480 --> 00:26:45.000]   They're going to May 15th me.
[00:26:45.000 --> 00:26:48.640]   Yeah, they're bumping it up, but I thought everybody got bumped up.
[00:26:48.640 --> 00:26:51.120]   That you didn't get grandfathered in.
[00:26:51.120 --> 00:26:52.360]   I don't know if we paid...
[00:26:52.360 --> 00:26:54.560]   We're paying monthly or if we paid an alump sum.
[00:26:54.560 --> 00:26:55.800]   I have no clue.
[00:26:55.800 --> 00:26:57.360]   I think that was...
[00:26:57.360 --> 00:26:58.360]   I don't know.
[00:26:58.360 --> 00:27:01.680]   I'm not sure, but either way, I'm still staying.
[00:27:01.680 --> 00:27:09.280]   Just they said that they're bumping up the cost of prime to $119 a year because so many
[00:27:09.280 --> 00:27:15.080]   people are shopping with prime that they have to do that to cover the shipping costs.
[00:27:15.080 --> 00:27:16.080]   What?
[00:27:16.080 --> 00:27:17.080]   Give me a break.
[00:27:17.080 --> 00:27:18.080]   Give me a break.
[00:27:18.080 --> 00:27:19.880]   People are part of it.
[00:27:19.880 --> 00:27:22.640]   I don't know if I buy that.
[00:27:22.640 --> 00:27:23.640]   I'm still staying it.
[00:27:23.640 --> 00:27:24.640]   I don't care.
[00:27:24.640 --> 00:27:25.640]   Go ahead, Bree.
[00:27:25.640 --> 00:27:29.840]   No, I was just going to say, I am part of the problem.
[00:27:29.840 --> 00:27:36.080]   Right now Amazon accounts for, by some estimates, $0.44 of every dollar spent on the web.
[00:27:36.080 --> 00:27:40.200]   There's a huge, huge, huge part of the profits.
[00:27:40.200 --> 00:27:44.920]   What's more concerning to me, places like JET, which have an alliance of Walmart, have
[00:27:44.920 --> 00:27:49.080]   tried to compete and they found themselves unable to.
[00:27:49.080 --> 00:27:50.080]   I love prime.
[00:27:50.080 --> 00:27:52.680]   When a new game comes out, I just have it sent to my door.
[00:27:52.680 --> 00:27:54.240]   My groceries are prime.
[00:27:54.240 --> 00:27:56.520]   I am absolutely part of the problem.
[00:27:56.520 --> 00:28:02.400]   I do think it's worth saying this monopoly is something that should give all of us pause.
[00:28:02.400 --> 00:28:09.360]   What's a barrier in this story was AWS accounting for a large portion of that profit.
[00:28:09.360 --> 00:28:11.480]   I think that's very, very interesting.
[00:28:11.480 --> 00:28:18.960]   The service we use to facilitate my campaign and all of our data and our fundraising nation
[00:28:18.960 --> 00:28:26.880]   builder, they had a failure two weeks ago and they moved all their services over to AWS.
[00:28:26.880 --> 00:28:28.680]   That's not the only one.
[00:28:28.680 --> 00:28:34.960]   I feel like there's a good story here with seeing how successful AWS has been.
[00:28:34.960 --> 00:28:41.200]   But there's a cautionary tale in seeing what a behemoth Amazon is and how really no one
[00:28:41.200 --> 00:28:45.800]   else in the industry can seems to be able to stand up.
[00:28:45.800 --> 00:28:50.280]   One thought on that around, I'm going to take AWS out of the equation and just talk
[00:28:50.280 --> 00:28:55.600]   about shopping for a second because when you think about all of the third party sellers
[00:28:55.600 --> 00:29:04.840]   that are involved in Amazon and also at Walmart, it really puts Amazon's ecosystem in a different
[00:29:04.840 --> 00:29:06.200]   perspective to me.
[00:29:06.200 --> 00:29:12.280]   I think Amazon is as the internet was when it first started.
[00:29:12.280 --> 00:29:15.280]   Amazon is online shopping of the future.
[00:29:15.280 --> 00:29:22.240]   They're so good at fulfillment and the entire process and they have a patent on one click
[00:29:22.240 --> 00:29:28.880]   shopping, so I feel like that is the future of internet shopping and that we're almost
[00:29:28.880 --> 00:29:34.160]   fighting against that just consolidation in a way because they're just doing it better
[00:29:34.160 --> 00:29:35.520]   than everyone else.
[00:29:35.520 --> 00:29:39.360]   I do think Walmart is competitive because they are just stealing from the same playbook
[00:29:39.360 --> 00:29:42.800]   and trying to do the same thing at scale.
[00:29:42.800 --> 00:29:48.760]   There is at least one competitor there, but I kind of feel like the train is barreling
[00:29:48.760 --> 00:29:53.320]   down the tracks and there's very little chance of stopping it.
[00:29:53.320 --> 00:29:59.400]   I would agree with that, but I also think I guess I would also agree with Brianna just
[00:29:59.400 --> 00:30:04.760]   in terms of we all need to be thinking about this even though maybe we'll raise your hand
[00:30:04.760 --> 00:30:08.320]   if you're part of the problem, which maybe we all are.
[00:30:08.320 --> 00:30:17.880]   I do think that this company is really starting to become the thing that we've always joked.
[00:30:17.880 --> 00:30:20.920]   It will become, which is this massive company.
[00:30:20.920 --> 00:30:22.440]   The nation's state.
[00:30:22.440 --> 00:30:23.840]   Well, something like that.
[00:30:23.840 --> 00:30:28.200]   A lot of those AWS contracts or government or US government contracts, which is an whole
[00:30:28.200 --> 00:30:36.800]   other thing, but I think that we were just talking about choice and telecom.
[00:30:36.800 --> 00:30:39.760]   Again, we all use this service.
[00:30:39.760 --> 00:30:44.680]   It's really the most effective service and it's wonderful and it's great.
[00:30:44.680 --> 00:30:48.720]   When you buy stuff online really easily and it comes to your door, that's wonderful.
[00:30:48.720 --> 00:30:54.280]   But again, we're getting to this place where when Amazon says, "Oh, I'm just going to charge
[00:30:54.280 --> 00:30:58.080]   more for Prime because it costs a little bit more for us to ship."
[00:30:58.080 --> 00:31:03.720]   I think that starts to get scary because you're like, "Oh, you can just do that and
[00:31:03.720 --> 00:31:08.360]   I have to now pay for that and I don't have other options."
[00:31:08.360 --> 00:31:12.560]   I also think, at least for me, a lot of this stuff that I was seeing in my feeds this week
[00:31:12.560 --> 00:31:23.480]   was the comment or the headline that Amazon has paid zero income taxes as a company.
[00:31:23.480 --> 00:31:30.520]   I think that we also have to think about the benefits that the company gets or has gotten
[00:31:30.520 --> 00:31:33.640]   as it sort of become this behemoth.
[00:31:33.640 --> 00:31:40.600]   I don't know what that means for the future of commerce online, at least in the US.
[00:31:40.600 --> 00:31:44.280]   We haven't talked about Alibaba, but I don't know.
[00:31:44.280 --> 00:31:52.960]   It starts to concern me, I guess, when I look at the headlines about the company all week
[00:31:52.960 --> 00:31:55.120]   and just how big it's become, finally.
[00:31:55.120 --> 00:31:57.520]   That's not just Amazon, right?
[00:31:57.520 --> 00:31:58.520]   Sorry.
[00:31:58.520 --> 00:31:59.520]   Say again, Georgia.
[00:31:59.520 --> 00:32:01.640]   Well, it's not just Amazon.
[00:32:01.640 --> 00:32:04.960]   What's happening with companies is they're becoming almost too large to fail.
[00:32:04.960 --> 00:32:11.400]   So powerful that we kind of need them to be apart, the government, they send so much
[00:32:11.400 --> 00:32:16.320]   money towards the government because they're allowed to do that, that in the end they have
[00:32:16.320 --> 00:32:18.680]   kind of the government inside of their pocket.
[00:32:18.680 --> 00:32:22.760]   I think that there's a huge problem with the fact that there are other options.
[00:32:22.760 --> 00:32:25.960]   You could go out and go and buy your stuff.
[00:32:25.960 --> 00:32:28.640]   The thing is we're lazy by nature, we're not going to do that.
[00:32:28.640 --> 00:32:33.300]   If we don't have an oversight by a government that actually has knowledge of this and an
[00:32:33.300 --> 00:32:38.520]   understanding of how this works, these companies are going to get bigger and bigger and at
[00:32:38.520 --> 00:32:42.360]   some point we're going to be so reliant on them that really almost anything that they
[00:32:42.360 --> 00:32:44.880]   ask we're going to be kind of beholden to.
[00:32:44.880 --> 00:32:46.400]   That's really a scary thought.
[00:32:46.400 --> 00:32:50.720]   I think that that's the way that they're going and the government has not yet really
[00:32:50.720 --> 00:32:53.360]   looked in on what are they going to do about it.
[00:32:53.360 --> 00:32:58.880]   Taxes are one thing, but that, again, people want to keep Amazon there in the end.
[00:32:58.880 --> 00:33:05.620]   Amazon will move to wherever it is most profitable for them to be able to do business.
[00:33:05.620 --> 00:33:07.780]   I was just going to add on a discussion.
[00:33:07.780 --> 00:33:10.660]   I agree with everything you just said, Georgia.
[00:33:10.660 --> 00:33:17.820]   There is a precedent for how Amazon behaves when it is a monopoly.
[00:33:17.820 --> 00:33:20.900]   That is looking at the way that they've treated authors.
[00:33:20.900 --> 00:33:25.300]   I think if you talk to anyone in the book industry about the trends in that field over
[00:33:25.300 --> 00:33:31.360]   the last 10, 15 years, they're not going to have a lot that's positive to say.
[00:33:31.360 --> 00:33:36.360]   We talked a lot when the App Store came out and Apple decided to take 30% of every single
[00:33:36.360 --> 00:33:38.360]   purchase.
[00:33:38.360 --> 00:33:44.520]   Amazon takes 70% of the purchases when it comes to books through Kindle, which is functionally
[00:33:44.520 --> 00:33:46.000]   a monopoly.
[00:33:46.000 --> 00:33:52.060]   Even more disturbing to me personally is some of their behavior that they've engaged with
[00:33:52.060 --> 00:34:00.060]   as far as basically getting writers under certain deals and giving them more money than private
[00:34:00.060 --> 00:34:03.460]   publishers can to get exclusives on their platform.
[00:34:03.460 --> 00:34:07.140]   I think you've seen them act a very anti-competitive way.
[00:34:07.140 --> 00:34:10.780]   If I were fortunate enough to serve in Congress, I like Amazon.
[00:34:10.780 --> 00:34:16.480]   I use Amazon, but I am very disturbed by some of their behavior.
[00:34:16.480 --> 00:34:21.760]   I do think that my job in the job of ending a government official is to make a playing
[00:34:21.760 --> 00:34:26.600]   field that's even, a playing field that's fair, where other companies can come through
[00:34:26.600 --> 00:34:29.240]   and offer new products.
[00:34:29.240 --> 00:34:34.080]   Circling back and my consumer reporter duties here, CompTR is helping me in the chat room.
[00:34:34.080 --> 00:34:40.000]   He says they will, for current prime customers, they won't raise rates until mid-June if
[00:34:40.000 --> 00:34:42.000]   you are a prime subscriber.
[00:34:42.000 --> 00:34:45.000]   I guess at least you got that going for you.
[00:34:45.000 --> 00:34:48.520]   There are a couple other pieces of Amazon news.
[00:34:48.520 --> 00:34:56.640]   Early in the week, Mark Gurman at Bloomberg reported that Amazon, out of their lab 126,
[00:34:56.640 --> 00:35:03.600]   listed jobs for software engineer robotics, principal sensors engineer.
[00:35:03.600 --> 00:35:06.760]   The idea is that they have something called Project Vesta.
[00:35:06.760 --> 00:35:14.120]   Again, this is not confirmed by Amazon, but reported by Mark Gurman, which is a home robot
[00:35:14.120 --> 00:35:16.840]   which could come to consumers as early as 2019.
[00:35:16.840 --> 00:35:21.440]   Now, he says this is not in conjunction with their warehouse robotics division.
[00:35:21.440 --> 00:35:25.720]   You remember, they bought Kiva Systems back in 2012.
[00:35:25.720 --> 00:35:29.280]   This is really the way that it's been sort of bandied about.
[00:35:29.280 --> 00:35:34.240]   It's like Alexa following you around your house on wheels.
[00:35:34.240 --> 00:35:37.400]   The speculation around what would it do?
[00:35:37.400 --> 00:35:38.800]   Why would you need it?
[00:35:38.800 --> 00:35:40.200]   And would you buy it?
[00:35:40.200 --> 00:35:42.320]   Raises some interesting questions.
[00:35:42.320 --> 00:35:49.720]   You've seen some pretty huge home robot fails from Sony to various and sundry others.
[00:35:49.720 --> 00:35:53.000]   Anyone thinking that Amazon's going to crack this nut?
[00:35:53.000 --> 00:35:56.600]   I don't think so anytime soon.
[00:35:56.600 --> 00:35:58.600]   I'm all in for a home robot.
[00:35:58.600 --> 00:36:04.440]   I have robot Vax in the past, and I really want a robot, but I'd want a robot that could
[00:36:04.440 --> 00:36:05.440]   do something.
[00:36:05.440 --> 00:36:11.600]   I don't know if I would be trusting to have Amazon in my home following me around.
[00:36:11.600 --> 00:36:13.800]   So that might be the area that I deal with.
[00:36:13.800 --> 00:36:18.000]   Though I love the little Toyota Japanese robot, but I see Becky, you could get it because
[00:36:18.000 --> 00:36:23.160]   he was cute and adorable and would talk to you, but I don't speak Japanese because I
[00:36:23.160 --> 00:36:24.760]   would totally have bought it.
[00:36:24.760 --> 00:36:27.360]   I might learn Japanese just so I could get.
[00:36:27.360 --> 00:36:28.360]   He's so cute.
[00:36:28.360 --> 00:36:29.360]   That's what I want.
[00:36:29.360 --> 00:36:33.880]   I want something that's warm and fuzzy, and I know it's scary and I should probably be
[00:36:33.880 --> 00:36:36.160]   completely against it because I'm a psychotherapist.
[00:36:36.160 --> 00:36:37.160]   I should know better.
[00:36:37.160 --> 00:36:39.200]   But I'm all in for a home robot.
[00:36:39.200 --> 00:36:40.200]   I really am.
[00:36:40.200 --> 00:36:44.640]   But, Bree, tell them how bad I am for that.
[00:36:44.640 --> 00:36:45.640]   No, no, no.
[00:36:45.640 --> 00:36:46.640]   Well, Georgie, let's be honest.
[00:36:46.640 --> 00:36:51.120]   If Amazon put out a Rob, any ass Rob robot, you'd have 10 in your home.
[00:36:51.120 --> 00:36:52.120]   Just a minute.
[00:36:52.120 --> 00:36:53.120]   I have 10.
[00:36:53.120 --> 00:36:54.120]   Yeah.
[00:36:54.120 --> 00:36:55.120]   It's true.
[00:36:55.120 --> 00:36:56.120]   It's true.
[00:36:56.120 --> 00:36:57.120]   I will give in so quickly.
[00:36:57.120 --> 00:37:01.960]   I'm just trying to figure out what this thing would do in your home because everyone's
[00:37:01.960 --> 00:37:03.480]   talking about, oh, it'll be, you know, it's not.
[00:37:03.480 --> 00:37:07.000]   We're not talking about the key of the systems robots, which will like go grab things in
[00:37:07.000 --> 00:37:08.000]   your home.
[00:37:08.000 --> 00:37:12.880]   If you've ever been in a warehouse where everything's clearly marked and labeled and
[00:37:12.880 --> 00:37:20.040]   there are big wide open passageways, that's a place where robots can manage the environment.
[00:37:20.040 --> 00:37:25.600]   My home with two 10-year-old children and the slob that I am and a chihuahua and a
[00:37:25.600 --> 00:37:30.440]   dog, another big dog, that robot's going to make it about two feet before it's tangled
[00:37:30.440 --> 00:37:31.440]   in something.
[00:37:31.440 --> 00:37:36.320]   So I don't, I mean, I kind of can see the two scenarios I can see is that you have a speaker
[00:37:36.320 --> 00:37:40.720]   and an Alexa following you around if you want the music to go with you in different rooms
[00:37:40.720 --> 00:37:43.000]   or a security system.
[00:37:43.000 --> 00:37:49.120]   I like the idea of sort of a perimeter security and Amazon did strangely enough list security
[00:37:49.120 --> 00:37:53.880]   services on their website this week as one of their service options.
[00:37:53.880 --> 00:37:56.960]   But those are about the only scenarios I can think of Ben.
[00:37:56.960 --> 00:37:58.960]   Anything I'm missing?
[00:37:58.960 --> 00:37:59.960]   I have.
[00:37:59.960 --> 00:38:00.960]   I actually have a home robot.
[00:38:00.960 --> 00:38:01.960]   It is amazing.
[00:38:01.960 --> 00:38:04.520]   I've been wanting to get one for a really, really long time.
[00:38:04.520 --> 00:38:09.760]   And I, you know, I saved up and I went and I picked it out and I finally got it.
[00:38:09.760 --> 00:38:16.520]   And it's a dishwasher and it's just, it does everything that I need and it's amazing.
[00:38:16.520 --> 00:38:22.920]   No, I think, I think, I don't think that this is going to happen convincingly for another
[00:38:22.920 --> 00:38:28.280]   decade personally, at least in terms of like actual hardware that does something that you
[00:38:28.280 --> 00:38:36.080]   want it to do to me, the connectivity issue is really the issue in my mind.
[00:38:36.080 --> 00:38:40.080]   Just what are the things in your house connected to?
[00:38:40.080 --> 00:38:44.320]   Are they connected to the actual internet or are they connected to an ethernet or a
[00:38:44.320 --> 00:38:47.280]   sort of a local network?
[00:38:47.280 --> 00:38:55.240]   And for me, like I don't have a smart speaker in my house because I'm a little bit skeptical
[00:38:55.240 --> 00:38:59.480]   of what that speaker actually does for me.
[00:38:59.480 --> 00:39:02.280]   I guess, I mean, I guess I do in my phone, right?
[00:39:02.280 --> 00:39:08.020]   But in terms of the hardware of a robot, I don't think that that's going to be like
[00:39:08.020 --> 00:39:12.080]   convincing and amazing anytime immediately.
[00:39:12.080 --> 00:39:16.000]   Although obviously, you know, if Amazon's starting now, maybe in 10 years, they'll have
[00:39:16.000 --> 00:39:17.400]   this incredible robot.
[00:39:17.400 --> 00:39:23.440]   But again, like to me, it's about its connection to the internet and what it actually does.
[00:39:23.440 --> 00:39:28.600]   If it's sort of like a local machine that interacts with your smart home in a localized
[00:39:28.600 --> 00:39:34.080]   way and isn't trying to like sell you new Bronny paper towels every time your kids spill
[00:39:34.080 --> 00:39:40.040]   something while it's following you around, you know, then like, okay, but yeah, I don't
[00:39:40.040 --> 00:39:41.040]   know.
[00:39:41.040 --> 00:39:42.040]   That's my take.
[00:39:42.040 --> 00:39:45.880]   Then I have to say, I'm really surprised you would give that take because we're both
[00:39:45.880 --> 00:39:46.880]   Bostonians.
[00:39:46.880 --> 00:39:51.280]   I mean, you know, we have our robot that's here.
[00:39:51.280 --> 00:39:55.880]   They can't even hire enough engineers over there to build the products that they want
[00:39:55.880 --> 00:39:56.880]   to build.
[00:39:56.880 --> 00:39:59.920]   That's part of the Massachusetts tech pipeline problem.
[00:39:59.920 --> 00:40:01.280]   We have Boston dynamic.
[00:40:01.280 --> 00:40:04.960]   So when the terminators come to life, like Ben and I are going to be the first ones to
[00:40:04.960 --> 00:40:09.280]   have, like, I'm trying to hear in our town, the killer dog robots.
[00:40:09.280 --> 00:40:12.320]   You send me a taxi when they come for you.
[00:40:12.320 --> 00:40:13.320]   I will.
[00:40:13.320 --> 00:40:14.960]   I will let you know.
[00:40:14.960 --> 00:40:21.240]   And also, yeah, if you go over to MIT, yeah, I'm not going to say like things I see.
[00:40:21.240 --> 00:40:26.240]   Over there, but you have students building some truly amazing things for robotics over
[00:40:26.240 --> 00:40:27.720]   there.
[00:40:27.720 --> 00:40:32.000]   So like if you're saying 10, 15 years to a pipeline to new things coming out, I really
[00:40:32.000 --> 00:40:33.120]   don't agree with that.
[00:40:33.120 --> 00:40:34.120]   They have.
[00:40:34.120 --> 00:40:36.720]   Well, I'm talking about consumer for the consumer.
[00:40:36.720 --> 00:40:38.920]   To me, that's like, that's what I'm imagining.
[00:40:38.920 --> 00:40:42.240]   I'm imagining something that I can actually afford.
[00:40:42.240 --> 00:40:44.200]   I don't think I can afford the big robot.
[00:40:44.200 --> 00:40:46.760]   So I don't that I guess that's what I mean.
[00:40:46.760 --> 00:40:48.960]   Guys, laundry folding robot.
[00:40:48.960 --> 00:40:49.960]   Yeah.
[00:40:49.960 --> 00:40:53.680]   Bring me that robot tomorrow.
[00:40:53.680 --> 00:40:55.280]   I don't care how much it costs.
[00:40:55.280 --> 00:40:56.280]   We are buying that.
[00:40:56.280 --> 00:40:58.920]   You know, it is the functionality issues.
[00:40:58.920 --> 00:41:04.080]   I love my, I have the Nido vacuum robot and that thing is incredible.
[00:41:04.080 --> 00:41:08.840]   I need to find that because I used to have the, the Roomba, but I kept on breaking down.
[00:41:08.840 --> 00:41:10.080]   No, Nido is great.
[00:41:10.080 --> 00:41:12.040]   But Megan also likes it.
[00:41:12.040 --> 00:41:15.640]   It's good, especially if you have quite a bit of carpet, because it's a little bit more
[00:41:15.640 --> 00:41:17.800]   of a vacuum than a sweeper.
[00:41:17.800 --> 00:41:22.000]   So I'm bullish on the, on the robotic vacuums.
[00:41:22.000 --> 00:41:26.280]   Although I don't know who it was in the chat room who said that robotic vacuums are made
[00:41:26.280 --> 00:41:30.640]   to vacuum money out of your bank account because they are ridiculously expensive.
[00:41:30.640 --> 00:41:36.480]   You know, another little note in this battle for the home that came out this week that's,
[00:41:36.480 --> 00:41:38.320]   that's really interesting.
[00:41:38.320 --> 00:41:44.440]   Alphabet, Google's home, Google's parent company announced its earnings.
[00:41:44.440 --> 00:41:47.560]   They did very well also.
[00:41:47.560 --> 00:41:48.560]   Sales were up.
[00:41:48.560 --> 00:41:56.080]   Let's see, operating income came in at $7 billion versus 6.6 in 2017 for what that's
[00:41:56.080 --> 00:41:57.080]   worth.
[00:41:57.080 --> 00:42:02.480]   But one of the little tidbits that came out of their report, Nest, they're desperately
[00:42:02.480 --> 00:42:10.360]   trying to get Nest to compete with and get, get a real foothold in the home.
[00:42:10.360 --> 00:42:17.520]   It made about $726 million in revenue, but it cost them $621 million.
[00:42:17.520 --> 00:42:22.560]   So I mean, they're spending more than half a billion dollars to get Nest into the home
[00:42:22.560 --> 00:42:27.920]   with security cameras, alarm system, video doorbells.
[00:42:27.920 --> 00:42:34.120]   They know that this is the next frontier for owning the ecosystem.
[00:42:34.120 --> 00:42:39.160]   And I'm not quite sure where that battle is going to end up, but I feel like Google
[00:42:39.160 --> 00:42:43.680]   is losing the home because Alexa just dominates the speaker category.
[00:42:43.680 --> 00:42:44.680]   Yeah.
[00:42:44.680 --> 00:42:49.840]   I mean, you know, I have an entire range of Nest products.
[00:42:49.840 --> 00:42:53.880]   Last time I was on the show, you know, Twitter was sponsored by competitor to a Nest product.
[00:42:53.880 --> 00:42:59.560]   It was vastly superior because Nest products, like they're, they're out their camera.
[00:42:59.560 --> 00:43:03.880]   If you don't have an outdoor camera, you have to go on to Amazon and buy like an outdoor
[00:43:03.880 --> 00:43:09.040]   jacket for it with the heat sink, like the glue on the back of the camera.
[00:43:09.040 --> 00:43:14.560]   If you live in hot weather to like just see stuff outside, their thermostat is kind of
[00:43:14.560 --> 00:43:16.120]   a nightmare to work with.
[00:43:16.120 --> 00:43:20.520]   And what really worries me is I'm not seeing them update the software.
[00:43:20.520 --> 00:43:21.520]   I'm not.
[00:43:21.520 --> 00:43:26.200]   It's the exact same today as it was like three years ago when I bought it and I don't see
[00:43:26.200 --> 00:43:28.080]   them up in security either.
[00:43:28.080 --> 00:43:34.200]   So I do think that Google kind of has to play in this space if they're going to be
[00:43:34.200 --> 00:43:35.200]   competitive.
[00:43:35.200 --> 00:43:39.520]   So many years from now, smart home is going to be the norm.
[00:43:39.520 --> 00:43:43.840]   And I see Apple making kind of mediocre moves in the space.
[00:43:43.840 --> 00:43:44.840]   Amazon is when there is a.
[00:43:44.840 --> 00:43:45.840]   Fill off a cliff.
[00:43:45.840 --> 00:43:49.120]   I'm definitely not not in roads there.
[00:43:49.120 --> 00:43:50.840]   See, I love my home pod.
[00:43:50.840 --> 00:43:51.840]   I love it.
[00:43:51.840 --> 00:43:57.360]   Like series series, you know, she's a fickle creature, but I love my home pod.
[00:43:57.360 --> 00:44:01.800]   And the thing is, is I would never trust having Amazon or Google in my house.
[00:44:01.800 --> 00:44:05.520]   I just their privacy is, you know, it's a Swiss cheese.
[00:44:05.520 --> 00:44:11.040]   Like there's, there's really more air than there is security for us on our end.
[00:44:11.040 --> 00:44:15.000]   And so anything where I am the product, I don't want to have inside of my home and
[00:44:15.000 --> 00:44:16.000]   I'm with my kids.
[00:44:16.000 --> 00:44:20.920]   Well, I think that great point on kids aspect too, because with home pod, it's
[00:44:20.920 --> 00:44:22.480]   349 bucks.
[00:44:22.480 --> 00:44:25.560]   So it's way too expensive to go into a kids room.
[00:44:25.560 --> 00:44:31.680]   But this week, Amazon announces Echo Kids.
[00:44:31.680 --> 00:44:35.200]   Echo, it's an echo dot that's 30 bucks more than your standard echo.
[00:44:35.200 --> 00:44:38.400]   But they say it has a lot of kid features, Georgia.
[00:44:38.400 --> 00:44:43.040]   They say it has no shopping, no ordering, Uber's.
[00:44:43.040 --> 00:44:45.040]   That's good kids.
[00:44:45.040 --> 00:44:51.440]   It can block explicit songs, but interestingly enough, Amazon's music doesn't have clean
[00:44:51.440 --> 00:44:56.080]   versions, the way that Apple music has clean versions.
[00:44:56.080 --> 00:45:01.520]   You can turn it off at certain times and it comes with a colorful prime colors, only
[00:45:01.520 --> 00:45:09.960]   very Lego, rubber case, and they'll replace it if you damage it within two years.
[00:45:09.960 --> 00:45:13.680]   They also have this free time unlimited service that I do love.
[00:45:13.680 --> 00:45:18.960]   It's unlimited audio books and books that you can listen to for kids, which is a nice
[00:45:18.960 --> 00:45:20.120]   element of it.
[00:45:20.120 --> 00:45:27.840]   But this is the thing I realized this week when my kids said to echo in our kitchen,
[00:45:27.840 --> 00:45:30.040]   "Echo, what's six times seven?"
[00:45:30.040 --> 00:45:32.040]   I went, "Oh no."
[00:45:32.040 --> 00:45:33.040]   Right.
[00:45:33.040 --> 00:45:39.120]   What they're selling right is like a babysitter, a free babysitter for your kids.
[00:45:39.120 --> 00:45:42.280]   I think that for a lot of parents, that would be salient.
[00:45:42.280 --> 00:45:46.880]   But, you know, I don't know, I want my kids to be able to be bored, to have to struggle
[00:45:46.880 --> 00:45:47.880]   with things.
[00:45:47.880 --> 00:45:55.000]   I want them to suddenly always be being read to and cared for by their Amazon Echo.
[00:45:55.000 --> 00:45:59.440]   And I think that they don't go through how, you know, with the information that they get
[00:45:59.440 --> 00:46:01.800]   from your child is going to be used towards.
[00:46:01.800 --> 00:46:03.760]   And I think that that's a really big deal.
[00:46:03.760 --> 00:46:06.840]   And I think that now we're talking about privacy and how that's important.
[00:46:06.840 --> 00:46:10.600]   I think that people have been a little late to the game and a little bit too trusting of
[00:46:10.600 --> 00:46:15.680]   these really large companies to be able to police themselves, which no company, no person
[00:46:15.680 --> 00:46:17.040]   really, we can't police ourselves.
[00:46:17.040 --> 00:46:18.040]   They're horrible at that.
[00:46:18.040 --> 00:46:22.040]   Companies are always going to keep their company's interest first.
[00:46:22.040 --> 00:46:26.120]   But there was one feature that kind of did make me go, "Oh, that's kind of cool," which
[00:46:26.120 --> 00:46:27.600]   was the intercom feature.
[00:46:27.600 --> 00:46:29.880]   So I could be like, "Oh, come downstairs now.
[00:46:29.880 --> 00:46:31.160]   I need you to do something."
[00:46:31.160 --> 00:46:33.920]   I went, "Oh, I do like that."
[00:46:33.920 --> 00:46:34.920]   First 70s.
[00:46:34.920 --> 00:46:35.920]   Remember those intercoms?
[00:46:35.920 --> 00:46:36.920]   I did.
[00:46:36.920 --> 00:46:37.920]   I know.
[00:46:37.920 --> 00:46:38.920]   That was in it.
[00:46:38.920 --> 00:46:39.920]   Was there how those?
[00:46:39.920 --> 00:46:40.920]   I wanted to get out.
[00:46:40.920 --> 00:46:42.960]   I'd love to ask you though.
[00:46:42.960 --> 00:46:45.600]   And I'm coming at this as a non-parent.
[00:46:45.600 --> 00:46:50.960]   But the only reason I'm able to run for office today is because social media did not exist
[00:46:50.960 --> 00:46:52.560]   when I was a teenager.
[00:46:52.560 --> 00:46:58.600]   Doesn't it give you pause that if you look at the way Amazon's echoes constructed, there's
[00:46:58.600 --> 00:47:02.720]   not end-to-end encryption like there is with Siri, there's no differential privacy like
[00:47:02.720 --> 00:47:05.200]   there is with an Apple product.
[00:47:05.200 --> 00:47:14.280]   Doesn't it give you pause that you're asking your child to start their life with everything
[00:47:14.280 --> 00:47:21.080]   they think, say, or do being quantified by a system that is designed to pick up an uncomfortable
[00:47:21.080 --> 00:47:23.040]   amount of data on them?
[00:47:23.040 --> 00:47:26.240]   The Wall Street Journal had a story about this recently.
[00:47:26.240 --> 00:47:28.080]   It was aimed more at Apple.
[00:47:28.080 --> 00:47:34.040]   But it was like showing all the data you get just from an evening of ordering a pizza
[00:47:34.040 --> 00:47:37.160]   and taking some pictures and posting it to social media.
[00:47:37.160 --> 00:47:39.800]   It's going to be that much worse on an Amazon product.
[00:47:39.800 --> 00:47:44.480]   Does that give you pause or am I just out of touch?
[00:47:44.480 --> 00:47:45.920]   For me, yeah.
[00:47:45.920 --> 00:47:47.760]   I don't have my kids on social media.
[00:47:47.760 --> 00:47:49.680]   They're not allowed.
[00:47:49.680 --> 00:47:52.040]   And I monitor how much-- I do.
[00:47:52.040 --> 00:47:53.040]   I love tech everywhere.
[00:47:53.040 --> 00:47:56.360]   If you take a look at my house, it's like a tech.
[00:47:56.360 --> 00:47:58.160]   You sell stuff.
[00:47:58.160 --> 00:48:00.560]   I could run it out of my garage with the amount of tech that I have.
[00:48:00.560 --> 00:48:02.360]   But my kids aren't on tech.
[00:48:02.360 --> 00:48:04.800]   They end up paying for the time that they are on technology.
[00:48:04.800 --> 00:48:07.280]   They're not allowed to have social media accounts.
[00:48:07.280 --> 00:48:09.320]   I don't want them messaging and chatting with things.
[00:48:09.320 --> 00:48:09.960]   But it's funny.
[00:48:09.960 --> 00:48:12.080]   I tried to put all these restrictions.
[00:48:12.080 --> 00:48:14.360]   And then the school has a Google account.
[00:48:14.360 --> 00:48:17.960]   And they have to hook up to hangouts to do this project or that project.
[00:48:17.960 --> 00:48:23.920]   And so it's interesting, even though I really do try to delay their involvement in technology
[00:48:23.920 --> 00:48:24.960]   for as long as you can.
[00:48:24.960 --> 00:48:28.840]   Because if there was social media when I was a child with all of the stupid things
[00:48:28.840 --> 00:48:31.840]   that I did, I would never be able to be a psychotherapist.
[00:48:31.840 --> 00:48:33.080]   It would be horrible.
[00:48:33.080 --> 00:48:36.240]   No one would go to see me.
[00:48:36.240 --> 00:48:38.000]   Bree and I did a show together.
[00:48:38.000 --> 00:48:41.920]   Just you know what that I was like, oh God, some of the stuff that we put to.
[00:48:41.920 --> 00:48:44.200]   I just live in for the attack ads, Georgia.
[00:48:44.200 --> 00:48:45.200]   Those are coming.
[00:48:45.200 --> 00:48:48.200]   Yeah, it is a dilemma, isn't it?
[00:48:48.200 --> 00:48:50.320]   The whole of your kids, Georgia?
[00:48:50.320 --> 00:48:51.840]   They're 12 and 9.
[00:48:51.840 --> 00:48:52.840]   Oh, yeah.
[00:48:52.840 --> 00:48:54.040]   You're in prime time coming up on.
[00:48:54.040 --> 00:48:55.040]   Yes.
[00:48:55.040 --> 00:48:56.040]   How old are yours, Becky?
[00:48:56.040 --> 00:48:58.760]   I have a boy, girl, 10-year-old twins.
[00:48:58.760 --> 00:49:00.440]   And they have...
[00:49:00.440 --> 00:49:01.440]   Twins.
[00:49:01.440 --> 00:49:03.880]   Our policy is, luckily we do this for a living.
[00:49:03.880 --> 00:49:09.040]   So we have the opportunity to be nuanced in the way that we think about it.
[00:49:09.040 --> 00:49:13.280]   And so my policy with my kids, they don't have a phone or an iPad or anything like that.
[00:49:13.280 --> 00:49:17.400]   And that's actually why I like Amazon because it's a way for them to get music without screen
[00:49:17.400 --> 00:49:18.400]   access.
[00:49:18.400 --> 00:49:21.840]   Because otherwise, what are we listening to old CDs?
[00:49:21.840 --> 00:49:24.680]   It's really difficult if you don't have a device.
[00:49:24.680 --> 00:49:25.680]   8-track.
[00:49:25.680 --> 00:49:26.680]   8-track.
[00:49:26.680 --> 00:49:27.680]   Yeah, yeah.
[00:49:27.680 --> 00:49:32.960]   So that's one of the only ways that they can get music is through Amazon, which is connected
[00:49:32.960 --> 00:49:36.040]   to Sonos through various parts of our house.
[00:49:36.040 --> 00:49:38.400]   But my policy is a little different.
[00:49:38.400 --> 00:49:40.000]   It's not about the specific gadget.
[00:49:40.000 --> 00:49:41.520]   They don't get any screen time.
[00:49:41.520 --> 00:49:42.960]   What they get is tool time.
[00:49:42.960 --> 00:49:47.080]   If they want to use GarageBand to make music, if they want to use...
[00:49:47.080 --> 00:49:50.740]   As my daughter, when she was much smaller, used to say, "Mommy, can I use microscopic
[00:49:50.740 --> 00:49:51.740]   word?
[00:49:51.740 --> 00:49:53.480]   I want to write."
[00:49:53.480 --> 00:49:58.760]   So anything they want that's tools for creative work, they can have as much time as they want,
[00:49:58.760 --> 00:50:00.360]   but they get no toy time.
[00:50:00.360 --> 00:50:02.940]   They can't treat technology as a toy.
[00:50:02.940 --> 00:50:06.600]   So they don't get games or YouTube or any of that.
[00:50:06.600 --> 00:50:08.360]   I know I heard that gasp, Brianna.
[00:50:08.360 --> 00:50:09.360]   Sorry.
[00:50:09.360 --> 00:50:10.360]   Sorry.
[00:50:10.360 --> 00:50:11.360]   That's hard to work.
[00:50:11.360 --> 00:50:12.360]   Sorry.
[00:50:12.360 --> 00:50:14.920]   I was having flashbacks to when my parents had this conversation with me in the 80s.
[00:50:14.920 --> 00:50:15.920]   I know.
[00:50:15.920 --> 00:50:17.840]   I won't even let my kids play Minecraft.
[00:50:17.840 --> 00:50:19.000]   That's how hardcore I am.
[00:50:19.000 --> 00:50:21.080]   I'm like quasi-wall-dorf in this.
[00:50:21.080 --> 00:50:22.080]   So bear with me.
[00:50:22.080 --> 00:50:23.880]   We're going to get to the lobby later.
[00:50:23.880 --> 00:50:26.880]   I do have to say, I feel like I grew up and my parents are like, "You're never going
[00:50:26.880 --> 00:50:30.200]   to make anything in yourself, Brianna, if you don't get off that Nintendo."
[00:50:30.200 --> 00:50:35.660]   Here I am on one of the best known game developers in the industry.
[00:50:35.660 --> 00:50:36.660]   No.
[00:50:36.660 --> 00:50:40.460]   You know, the parents never know it's the unintended consequences.
[00:50:40.460 --> 00:50:46.380]   Now on that note, the one other thing I want to mention about the Echo Kids, it rewards
[00:50:46.380 --> 00:50:48.540]   kids for politeness.
[00:50:48.540 --> 00:50:49.540]   So Wayne, let's say--
[00:50:49.540 --> 00:50:50.540]   The same thing, yeah.
[00:50:50.540 --> 00:50:51.540]   This is crazy.
[00:50:51.540 --> 00:50:52.540]   Please.
[00:50:52.540 --> 00:50:56.420]   It will come back to you later and say, "Hey, thanks for saying please."
[00:50:56.420 --> 00:51:01.420]   And I have just noticed this with myself and with my kids, and we've been talking about
[00:51:01.420 --> 00:51:06.100]   the fact that we're really rude to artificial assistants.
[00:51:06.100 --> 00:51:07.640]   And so we've been working on it.
[00:51:07.640 --> 00:51:10.080]   Do you think that'll make a difference?
[00:51:10.080 --> 00:51:13.240]   But it doesn't-- it still replies if you don't say please.
[00:51:13.240 --> 00:51:14.240]   True.
[00:51:14.240 --> 00:51:19.000]   I think that for kids, it's like a reward is like it's saying thank you.
[00:51:19.000 --> 00:51:22.640]   They won't notice if your children are naturally rude to assistant.
[00:51:22.640 --> 00:51:26.500]   They'll never know that it would reward them for saying please and thank you.
[00:51:26.500 --> 00:51:30.820]   I would be much happier if it forced them to be able to say-- or all of us to be able
[00:51:30.820 --> 00:51:33.500]   to say please and thank you because it does become a habit.
[00:51:33.500 --> 00:51:38.340]   If you say please and thank you enough, even if by force, you will end up doing it as Canadian
[00:51:38.340 --> 00:51:41.700]   as I am, even when you don't want to.
[00:51:41.700 --> 00:51:42.700]   It's so true.
[00:51:42.700 --> 00:51:44.200]   Then what do you--
[00:51:44.200 --> 00:51:46.860]   Georgia, I think that's weirder though.
[00:51:46.860 --> 00:51:49.540]   That creeps me out a little bit more, I feel like.
[00:51:49.540 --> 00:51:55.720]   If a robot is changing my behavior, even if it's for the better or if an AI is telling
[00:51:55.720 --> 00:51:57.480]   me how to behave, I don't know.
[00:51:57.480 --> 00:51:58.920]   That creeps me out too.
[00:51:58.920 --> 00:51:59.920]   I don't know why.
[00:51:59.920 --> 00:52:01.440]   Even if it's pleasing thank you.
[00:52:01.440 --> 00:52:02.440]   It makes me more like--
[00:52:02.440 --> 00:52:06.080]   Canadian robots are bad is what you're saying.
[00:52:06.080 --> 00:52:07.520]   All right.
[00:52:07.520 --> 00:52:09.520]   That's the same.
[00:52:09.520 --> 00:52:14.920]   We can't get into a cross-border AI battle in this moment, but I do have one last Amazon
[00:52:14.920 --> 00:52:17.520]   thing I want to ask you guys about.
[00:52:17.520 --> 00:52:26.320]   We have seen Amazon using delivery folks who go into your home using digital keys to put
[00:52:26.320 --> 00:52:28.580]   your deliveries inside the door.
[00:52:28.580 --> 00:52:34.780]   This week they started rolling out delivery to the trunk of your car.
[00:52:34.780 --> 00:52:36.180]   Would you feel more comfortable?
[00:52:36.180 --> 00:52:42.740]   This is using on-star technology, so it's all remote and the delivery person is monitored
[00:52:42.740 --> 00:52:44.420]   by the on-star folks in a way.
[00:52:44.420 --> 00:52:46.780]   They go in, they put it in the trunk.
[00:52:46.780 --> 00:52:47.780]   They close it.
[00:52:47.780 --> 00:52:51.480]   The on-star person confirms with them that the trunk is closed and that the items have
[00:52:51.480 --> 00:52:53.160]   been delivered.
[00:52:53.160 --> 00:52:57.560]   Right now I think it only works with some GMs and Volvos.
[00:52:57.560 --> 00:53:01.620]   Actually I was doing a story on the home delivery and the delivery guy was beta testing it
[00:53:01.620 --> 00:53:05.160]   and he said people love it because they get things delivered to the trunk of their cars
[00:53:05.160 --> 00:53:07.400]   when they're at work.
[00:53:07.400 --> 00:53:12.220]   Would you feel more comfortable letting an Amazon delivery person put things into the
[00:53:12.220 --> 00:53:15.640]   trunk of your car or inside the front door of your home?
[00:53:15.640 --> 00:53:16.640]   What do you think?
[00:53:16.640 --> 00:53:19.880]   I have a Porsche, so good luck with that.
[00:53:19.880 --> 00:53:25.560]   Remember those tick tacks and how they're like, "Yeah, thank you."
[00:53:25.560 --> 00:53:29.880]   I appreciate just put the box of tick tacks back there.
[00:53:29.880 --> 00:53:30.880]   I don't know.
[00:53:30.880 --> 00:53:36.160]   For my particular use case, I'm not home enough to guarantee when my home is going to be there.
[00:53:36.160 --> 00:53:37.640]   My car is going to be there.
[00:53:37.640 --> 00:53:39.920]   I have no issue laying people into my home.
[00:53:39.920 --> 00:53:41.920]   It's so wired up.
[00:53:41.920 --> 00:53:45.320]   I personally wouldn't feel bad about that.
[00:53:45.320 --> 00:53:48.240]   I know Georgie, you feel very differently.
[00:53:48.240 --> 00:53:49.240]   You know what?
[00:53:49.240 --> 00:53:52.320]   I actually love this idea.
[00:53:52.320 --> 00:53:54.600]   It's funny because I don't like Amazon, the thought of Amazon.
[00:53:54.600 --> 00:53:59.240]   I would never hook up Amazon, which we've heard the myriad of problems with the doors
[00:53:59.240 --> 00:54:00.240]   not being locked.
[00:54:00.240 --> 00:54:03.560]   People are walking the wrong doors and coming in.
[00:54:03.560 --> 00:54:04.640]   That gives me the creeps.
[00:54:04.640 --> 00:54:09.480]   I wouldn't want to have them come inside of my house because I would be worried about
[00:54:09.480 --> 00:54:12.520]   just safety when I'm sleeping and it would bother me.
[00:54:12.520 --> 00:54:16.120]   But for my car, I feel really, I don't know, I think that that would be a great idea.
[00:54:16.120 --> 00:54:18.520]   If you were moving, you could be able to deal with that.
[00:54:18.520 --> 00:54:23.400]   If you have something that you need to pick up or even if you are homeless for a period
[00:54:23.400 --> 00:54:28.000]   of time and you don't have an actual place of residence or you're in a hotel, you could
[00:54:28.000 --> 00:54:32.240]   still get your deliveries brought to you because there's a certain radius of where you're located
[00:54:32.240 --> 00:54:34.000]   that you can have your car at.
[00:54:34.000 --> 00:54:36.880]   I think in that way it's really wonderful.
[00:54:36.880 --> 00:54:41.520]   From my car, there's only so much you can take from my car besides the car.
[00:54:41.520 --> 00:54:49.400]   I don't know if someone steals your car because they say that they're not going to leave until
[00:54:49.400 --> 00:54:55.000]   it's actually locked and they're not even going to get to see the next delivery until
[00:54:55.000 --> 00:54:58.800]   there's a security measure in place that the car has been locked.
[00:54:58.800 --> 00:55:02.200]   But I wonder the only thing is if something does happen, it's not locked.
[00:55:02.200 --> 00:55:04.120]   They thought it was in the car gets stolen.
[00:55:04.120 --> 00:55:05.120]   Who covers that?
[00:55:05.120 --> 00:55:06.800]   I would assume Amazon.
[00:55:06.800 --> 00:55:11.760]   I think that there's a lot of use cases of separation you're getting a divorce.
[00:55:11.760 --> 00:55:16.800]   You might need to have something delivered to you that is private.
[00:55:16.800 --> 00:55:20.600]   I think that there's a lot of use cases that this might be beneficial.
[00:55:20.600 --> 00:55:25.280]   If Amazon leaves it usually outside on my doorsteps, that's a little bit less secure
[00:55:25.280 --> 00:55:29.920]   than opening up my car trunk and closing my car trunk afterwards.
[00:55:29.920 --> 00:55:32.080]   It's harder to steal if there's something that's really expensive.
[00:55:32.080 --> 00:55:34.360]   I would feel safe for putting it in my car.
[00:55:34.360 --> 00:55:35.360]   All right.
[00:55:35.360 --> 00:55:38.800]   Well, on that note, we are going to take a quick break.
[00:55:38.800 --> 00:55:41.920]   Big week for Facebook also.
[00:55:41.920 --> 00:55:45.760]   Surprising results after all the brew ha ha.
[00:55:45.760 --> 00:55:48.200]   When the numbers come in, nobody cares.
[00:55:48.200 --> 00:55:50.720]   But we're going to find out about that after the break.
[00:55:50.720 --> 00:55:52.560]   Our show today brought to you by my Fresh Breath.
[00:55:52.560 --> 00:55:56.360]   Actually, you can't smell my Fresh Breath, but it is.
[00:55:56.360 --> 00:55:57.360]   I assure you.
[00:55:57.360 --> 00:55:58.600]   Actually, it's brought to you by Quip.
[00:55:58.600 --> 00:56:00.400]   I love this toothbrush.
[00:56:00.400 --> 00:56:01.600]   I was so proud of my daughter.
[00:56:01.600 --> 00:56:02.600]   She's 26.
[00:56:02.600 --> 00:56:04.280]   Call me a couple of weeks ago.
[00:56:04.280 --> 00:56:08.440]   She said, "Dad, because I've been trying to get her to use Quip for a long time."
[00:56:08.440 --> 00:56:11.240]   Actually, I've been just trying to get her to use any electric toothbrush.
[00:56:11.240 --> 00:56:17.160]   She was a manual brusher, which meant she brushed it sometimes and she brushed it a
[00:56:17.160 --> 00:56:19.920]   little bit, maybe not as long as she should have all of that stuff.
[00:56:19.920 --> 00:56:25.720]   It's hard when you're just doing it by hand and do it for 30 seconds for every quadrant,
[00:56:25.720 --> 00:56:29.360]   two minutes brushing and do it right in the right motion.
[00:56:29.360 --> 00:56:30.360]   It's hard.
[00:56:30.360 --> 00:56:32.000]   It really is.
[00:56:32.000 --> 00:56:34.160]   People just don't do it.
[00:56:34.160 --> 00:56:37.560]   I don't know what it was, but she called me the other day and she said, "All right, Dad,
[00:56:37.560 --> 00:56:38.560]   I'm ready.
[00:56:38.560 --> 00:56:39.840]   I need an electric toothbrush.
[00:56:39.840 --> 00:56:41.000]   My wrist is killing me."
[00:56:41.000 --> 00:56:43.160]   I said, "Oh, honey, thank you."
[00:56:43.160 --> 00:56:45.040]   I got her a Quip.
[00:56:45.040 --> 00:56:46.040]   We've had Quip for some time.
[00:56:46.040 --> 00:56:47.040]   Quip is so cool.
[00:56:47.040 --> 00:56:52.840]   It is the best electric toothbrush, brand new, just the right amount of vibration into a
[00:56:52.840 --> 00:56:53.840]   slimmer design.
[00:56:53.840 --> 00:56:55.000]   It's a fraction of the cost.
[00:56:55.000 --> 00:56:56.760]   I mean, really is.
[00:56:56.760 --> 00:56:59.280]   I love it because it's battery powered, so there's no wires.
[00:56:59.280 --> 00:57:01.240]   There's no charger.
[00:57:01.240 --> 00:57:02.400]   It just takes a AAA battery.
[00:57:02.400 --> 00:57:03.400]   You put it in there.
[00:57:03.400 --> 00:57:04.480]   That lasts a long time.
[00:57:04.480 --> 00:57:09.160]   I haven't changed it in more than a month, so I mean a long time.
[00:57:09.160 --> 00:57:13.800]   The Quip holder has a little adhesive pad on the back, and this is what I do.
[00:57:13.800 --> 00:57:15.080]   Put it right on the mirror.
[00:57:15.080 --> 00:57:16.840]   It's right there.
[00:57:16.840 --> 00:57:20.560]   It's perfect for travel, by the way, because there's no charger, so it's light, easy to
[00:57:20.560 --> 00:57:21.560]   carry.
[00:57:21.560 --> 00:57:27.520]   I brought three quips to Japan, one for me, one for Lisa, one for Michael.
[00:57:27.520 --> 00:57:30.080]   When it comes to your teeth, brushing your teeth, one of the most important parts of
[00:57:30.080 --> 00:57:31.080]   your day.
[00:57:31.080 --> 00:57:32.760]   I think you should do it at least twice a day.
[00:57:32.760 --> 00:57:37.000]   I guess Dennis say after every meal with Quip, it's so affordable, you could have one
[00:57:37.000 --> 00:57:40.440]   at work and have one at home.
[00:57:40.440 --> 00:57:43.320]   Quip makes it the best way to brush.
[00:57:43.320 --> 00:57:46.440]   They have 30 second guiding pulses, so they go in between.
[00:57:46.440 --> 00:57:52.360]   So you brush for 30 seconds, lower left, upper left, upper right, lower right.
[00:57:52.360 --> 00:57:54.480]   They have a little booklet tells you all of this stuff.
[00:57:54.480 --> 00:57:56.080]   So you get exactly the right amount of brushing.
[00:57:56.080 --> 00:57:58.240]   They tell you how to brush.
[00:57:58.240 --> 00:57:59.240]   It's compact.
[00:57:59.240 --> 00:58:00.240]   It's light.
[00:58:00.240 --> 00:58:04.840]   Always clean, because after all the thing you put in your mouth should be clean, because
[00:58:04.840 --> 00:58:08.840]   you get a subscription plan just as the Dennis recommends delivering new brush heads every
[00:58:08.840 --> 00:58:13.560]   three months and it's just $5 and that's free shipping.
[00:58:13.560 --> 00:58:16.840]   If you want, you get the quip toothpaste too, so you don't even have to think about supplies,
[00:58:16.840 --> 00:58:18.840]   you're just ready to go.
[00:58:18.840 --> 00:58:21.840]   Quip is backed by a network of over 10,000 dental professionals.
[00:58:21.840 --> 00:58:27.560]   These are Dennis, dental hygienists who recommend and use Quip.
[00:58:27.560 --> 00:58:31.680]   You even, like I said, you get this booklet with tips on oral care.
[00:58:31.680 --> 00:58:33.720]   I'm here I am.
[00:58:33.720 --> 00:58:38.880]   I've been brushing for a long time, like 60 years.
[00:58:38.880 --> 00:58:41.880]   I never knew that you're not supposed to rinse after you brush, that the fluoride in
[00:58:41.880 --> 00:58:44.600]   the toothpaste sinks in and you don't want to rinse it out yet.
[00:58:44.600 --> 00:58:45.680]   You want to wait a little bit.
[00:58:45.680 --> 00:58:46.680]   I didn't know that.
[00:58:46.680 --> 00:58:47.680]   I know it now.
[00:58:47.680 --> 00:58:49.160]   I never rinse anymore after I brush.
[00:58:49.160 --> 00:58:50.160]   I wait a little bit.
[00:58:50.160 --> 00:58:54.440]   It took me a while to get used to that, but this is the kind of you learn how to do it.
[00:58:54.440 --> 00:58:58.360]   By the way, you won't mind so much quips, quips toothpaste is delicious, fresh, minty
[00:58:58.360 --> 00:59:03.280]   fresh, strengthens your teeth, gives your mouth the perfect clean feeling.
[00:59:03.280 --> 00:59:09.440]   No wonder Time Magazine named Quip the best, one of the best inventions of the year.
[00:59:09.440 --> 00:59:11.840]   I don't think any other toothbrushes got that.
[00:59:11.840 --> 00:59:14.080]   Quip, it starts at get this.
[00:59:14.080 --> 00:59:16.600]   I don't even want to tell you what I paid for my last electric toothbrush.
[00:59:16.600 --> 00:59:18.480]   I've always used electric toothbrushes.
[00:59:18.480 --> 00:59:20.040]   My desk highly recommends it.
[00:59:20.040 --> 00:59:23.800]   I recommend it just because it's easier for you and it does a better job and you're more
[00:59:23.800 --> 00:59:26.600]   likely to brush, frankly.
[00:59:26.600 --> 00:59:31.960]   I've been using one for years, but the last one I bought was more than $100.
[00:59:31.960 --> 00:59:35.200]   Quip $25.
[00:59:35.200 --> 00:59:37.160]   $25.
[00:59:37.160 --> 00:59:41.600]   If you go to getquip.com/twit right now, you'll get your first refill pack free when you purchase
[00:59:41.600 --> 00:59:44.640]   any Quip Electric toothbrush.
[00:59:44.640 --> 00:59:47.640]   It is a great deal.
[00:59:47.640 --> 00:59:52.280]   We actually got a couple of extra because when kids come for sleepovers, they never bring
[00:59:52.280 --> 00:59:54.800]   toothbrushes for some reason.
[00:59:54.800 --> 00:59:57.800]   But now we got them and we got enough heads so each one has their own head with a little
[00:59:57.800 --> 00:59:59.320]   label on it.
[00:59:59.320 --> 01:00:05.440]   Get your first refill pack free, getquip.com/twit, G-E-T-Q-U-I-P.com/twit.
[01:00:05.440 --> 01:00:07.360]   I highly recommend this one.
[01:00:07.360 --> 01:00:08.360]   Really do.
[01:00:08.360 --> 01:00:10.520]   Now back to Twit.
[01:00:10.520 --> 01:00:12.440]   Thank you, Leo, who is on vacation.
[01:00:12.440 --> 01:00:20.120]   Becky Worley here from Good Morning America, ABC News joined by three East Coasters, one
[01:00:20.120 --> 01:00:27.160]   in Canada, George Dow of iMore.com and anxiety-videos.com.
[01:00:27.160 --> 01:00:29.160]   Thanks for joining us.
[01:00:29.160 --> 01:00:32.160]   In Boston, we have Brianna Wu-- oh, we have Ben Johnson.
[01:00:32.160 --> 01:00:33.160]   That's not great.
[01:00:33.160 --> 01:00:34.160]   There you are.
[01:00:34.160 --> 01:00:35.160]   Hi there.
[01:00:35.160 --> 01:00:40.360]   He is at WBUR and hosts a great podcast on Reddit.
[01:00:40.360 --> 01:00:45.760]   And then Brianna Wu, who is also from Boston running for the 8th District for Congress,
[01:00:45.760 --> 01:00:48.320]   Game Developer, Technologists in general.
[01:00:48.320 --> 01:00:51.840]   Hey, you know, Ben, I have a quick question for you.
[01:00:51.840 --> 01:00:53.360]   Why is it WBUR?
[01:00:53.360 --> 01:00:58.560]   As someone who went to school in Vermont and knows the whole Burlington scene, I would
[01:00:58.560 --> 01:01:01.600]   always think the WBUR would be the Burlington station.
[01:01:01.600 --> 01:01:05.000]   Why is a Boston station BUR?
[01:01:05.000 --> 01:01:07.680]   I have no idea.
[01:01:07.680 --> 01:01:11.480]   But, you know, I have a hat.
[01:01:11.480 --> 01:01:12.480]   Okay.
[01:01:12.480 --> 01:01:13.920]   So I hope that counts for something.
[01:01:13.920 --> 01:01:14.920]   Well, you know--
[01:01:14.920 --> 01:01:15.920]   I haven't been there long enough.
[01:01:15.920 --> 01:01:19.960]   I think it could have something to do with the fact that GBH is also in Boston and, I don't
[01:01:19.960 --> 01:01:23.120]   know, some early days call signs.
[01:01:23.120 --> 01:01:24.120]   I have no idea.
[01:01:24.120 --> 01:01:25.120]   Right.
[01:01:25.120 --> 01:01:28.320]   That's all the whole-- you know, the W's are all in terms of broadcasting all the--
[01:01:28.320 --> 01:01:29.320]   Well, Boston University.
[01:01:29.320 --> 01:01:30.320]   Well, that makes sense.
[01:01:30.320 --> 01:01:37.680]   And even if it's a W is east of the Mississippi and anything that's a K is west of the Mississippi,
[01:01:37.680 --> 01:01:42.720]   anything that's-- if you're east of the Mississippi, it's called Hellman's Manet's.
[01:01:42.720 --> 01:01:45.880]   If you're west of the Mississippi, it's called Best Foods Manet's.
[01:01:45.880 --> 01:01:50.200]   Did you know these arcane things about the Mississippi and the east west divide?
[01:01:50.200 --> 01:01:51.200]   Yes.
[01:01:51.200 --> 01:01:52.200]   Important lines.
[01:01:52.200 --> 01:01:55.120]   I think it's probably just Boston University radio.
[01:01:55.120 --> 01:01:56.120]   That's probably what they stand for.
[01:01:56.120 --> 01:01:58.960]   And, you know, I mean, it's-- it happens to you.
[01:01:58.960 --> 01:01:59.960]   So, yeah.
[01:01:59.960 --> 01:02:00.960]   Now I'm with you.
[01:02:00.960 --> 01:02:01.960]   That's it.
[01:02:01.960 --> 01:02:02.960]   That's it.
[01:02:02.960 --> 01:02:03.960]   Genius.
[01:02:03.960 --> 01:02:04.960]   Yeah.
[01:02:04.960 --> 01:02:05.960]   All right, let's get on to the Facebook.
[01:02:05.960 --> 01:02:10.880]   The Facebook is basically printing money right now is what we learned this week and
[01:02:10.880 --> 01:02:15.120]   that nobody cares that they're eating your privacy alive.
[01:02:15.120 --> 01:02:20.520]   Now, granted, this is sort of a trailing indicator as opposed to a leading indicator
[01:02:20.520 --> 01:02:23.760]   as we look at their earnings that came out this week.
[01:02:23.760 --> 01:02:31.680]   2.2 billion monthly active users, almost 1.5 billion people using the site every day.
[01:02:31.680 --> 01:02:35.960]   That's-- both those numbers are up 13% from last year at this time.
[01:02:35.960 --> 01:02:37.760]   This is the one that kills me.
[01:02:37.760 --> 01:02:39.440]   Profits are up 63%.
[01:02:39.440 --> 01:02:47.360]   And so, if you're working at a company that made $100 last year, they just made $163.
[01:02:47.360 --> 01:02:50.300]   That's a huge jump in profits.
[01:02:50.300 --> 01:02:54.160]   I don't-- you know, normally these profits and earnings reports are like, "Rrrr!"
[01:02:54.160 --> 01:02:58.960]   But this one's interesting because the timing-- where it's-- where it's falling-- Wired
[01:02:58.960 --> 01:03:04.880]   Magazine did a-- a little bit of investigative work where they called out to some of the
[01:03:04.880 --> 01:03:12.440]   digital ad agencies to see if any of their clients were shying away from Facebook.
[01:03:12.440 --> 01:03:17.240]   And if anything, these agencies said their clients love Facebook more because they now
[01:03:17.240 --> 01:03:21.800]   have a better understanding of how detailed the targeting is.
[01:03:21.800 --> 01:03:23.800]   So, in the--
[01:03:23.800 --> 01:03:28.880]   >> Becky, Becky, I have a lot to say about this because it's like, I've actually spent
[01:03:28.880 --> 01:03:30.480]   ever since Zuckerberg testified.
[01:03:30.480 --> 01:03:37.560]   I spent the last three weeks raising money by running anti-Facebook ads on Facebook for
[01:03:37.560 --> 01:03:38.560]   my campaign.
[01:03:38.560 --> 01:03:39.560]   >> [LAUGH]
[01:03:39.560 --> 01:03:40.560]   >> And-- >> [LAUGH]
[01:03:40.560 --> 01:03:45.400]   >> --and it took a few tries for us to get it passed, though, when we finally succeeded.
[01:03:45.400 --> 01:03:47.800]   >> They didn't-- he didn't stop you.
[01:03:47.800 --> 01:03:49.280]   >> Just daddy, the mad at it.
[01:03:49.280 --> 01:03:51.080]   >> No, I'm sorry, what was that, Georgia?
[01:03:51.080 --> 01:03:52.080]   >> They didn't even care.
[01:03:52.080 --> 01:03:53.800]   They're like, "Yes, give us your money."
[01:03:53.800 --> 01:03:55.280]   >> That's the-- give me the money.
[01:03:55.280 --> 01:03:56.280]   Give me the money.
[01:03:56.280 --> 01:04:02.880]   >> So, look, the truth is, you cannot run a modern political campaign and not be on Google
[01:04:02.880 --> 01:04:04.560]   and Facebook and Twitter.
[01:04:04.560 --> 01:04:06.240]   It's just a freaking fact.
[01:04:06.240 --> 01:04:12.760]   So, expecting like this magical future where consumers are not going to walk away from
[01:04:12.760 --> 01:04:17.160]   Facebook and all of their friends, it's just not reasonable.
[01:04:17.160 --> 01:04:22.560]   And expecting businesses to not continue operating in this, you know, duopoly client
[01:04:22.560 --> 01:04:25.120]   that we have, it's just not reasonable.
[01:04:25.120 --> 01:04:32.400]   So again, this comes down to, I feel like the mood from this is like, "Oh, nobody cares,
[01:04:32.400 --> 01:04:35.200]   Facebook is going to get away with it end of story."
[01:04:35.200 --> 01:04:40.320]   It's not the end of story, because it's the role of regulators and people running for
[01:04:40.320 --> 01:04:45.080]   Congress like me to actually step in and regulate this and do the right thing.
[01:04:45.080 --> 01:04:51.000]   I don't expect Ben, your grandpa, to like, you know, understand this and quit Facebook.
[01:04:51.000 --> 01:04:53.240]   I don't expect normal people to do that.
[01:04:53.240 --> 01:04:56.440]   As technologists, it's everyone here.
[01:04:56.440 --> 01:05:00.440]   This is our role to like fix this and put reasonable regulations into place.
[01:05:00.440 --> 01:05:04.720]   >> Can I just stop you for one second, because you just did something truly amazing that
[01:05:04.720 --> 01:05:08.560]   only happens when there are three women and a man on a panel.
[01:05:08.560 --> 01:05:12.120]   You didn't just say, "I don't expect your mom to quit Facebook."
[01:05:12.120 --> 01:05:13.360]   >> Yes, yes, yes.
[01:05:13.360 --> 01:05:16.400]   >> You just said, "I don't expect your grandpa to quit Facebook."
[01:05:16.400 --> 01:05:17.400]   That was remarkable.
[01:05:17.400 --> 01:05:18.400]   So, I'm just--
[01:05:18.400 --> 01:05:19.400]   >> There you go.
[01:05:19.400 --> 01:05:20.400]   >> Acknowledge that.
[01:05:20.400 --> 01:05:24.640]   >> I have neither, but my mother is much more tech-savvy than my father is.
[01:05:24.640 --> 01:05:25.640]   So, I'm--
[01:05:25.640 --> 01:05:26.640]   >> There we go.
[01:05:26.640 --> 01:05:27.640]   >> There we go.
[01:05:27.640 --> 01:05:28.640]   >> There we go.
[01:05:28.640 --> 01:05:35.320]   >> I don't think anybody that is in-- you know, I have on Facebook, I have the technology
[01:05:35.320 --> 01:05:39.720]   folks, I have my media folks, and then I have a lot of my family, which are central New
[01:05:39.720 --> 01:05:47.040]   York and Massachusetts, and they could care less, have mentioned nothing about this, and
[01:05:47.040 --> 01:05:49.640]   it doesn't seem to be on their radar whatsoever.
[01:05:49.640 --> 01:05:54.440]   So, Joe Q Public, my read on this is not registering.
[01:05:54.440 --> 01:05:58.520]   That being said, Brianna, it is a policy issue if we care.
[01:05:58.520 --> 01:06:04.080]   But what was so scary about the testimony that was given is they think they should care,
[01:06:04.080 --> 01:06:06.560]   but they don't understand how to care.
[01:06:06.560 --> 01:06:07.560]   Does that make sense?
[01:06:07.560 --> 01:06:12.560]   >> I will say they're going to have a funny beforehand to help them be able to swallow
[01:06:12.560 --> 01:06:13.560]   that pill.
[01:06:13.560 --> 01:06:17.200]   They got a whole bunch of honey to be able to swallow that pill a little bit more easily,
[01:06:17.200 --> 01:06:18.800]   and it worked really well.
[01:06:18.800 --> 01:06:24.880]   And I think I'm the same way, Becky, most of the people that I know that are not really,
[01:06:24.880 --> 01:06:29.960]   you know, highly into tech, like just regular users, not only do they not care, many of
[01:06:29.960 --> 01:06:31.400]   them don't know at all.
[01:06:31.400 --> 01:06:35.160]   They have never heard of Cambridge Analytica, they don't read tech stories.
[01:06:35.160 --> 01:06:39.000]   I think that a lot of people find tech really scary.
[01:06:39.000 --> 01:06:44.880]   And so, they have no clue that this is even happening, no clue what information Facebook
[01:06:44.880 --> 01:06:48.720]   has been garnering for them, and they don't even know that this is a movement that's happening
[01:06:48.720 --> 01:06:49.720]   to them.
[01:06:49.720 --> 01:06:53.640]   So, we've started talking about it, but I think Breeze absolutely right, where she says, we
[01:06:53.640 --> 01:06:57.800]   really do need to have the government step in and to be able to, you know, people, we
[01:06:57.800 --> 01:07:02.600]   need to put people in place that understand tech so that they can make sure that we are
[01:07:02.600 --> 01:07:03.600]   protected.
[01:07:03.600 --> 01:07:04.600]   >> Meanwhile, in a moving tool-
[01:07:04.600 --> 01:07:07.960]   >> I think there's like another group of people that also don't think that they, I think
[01:07:07.960 --> 01:07:12.520]   there's another group of people that also like actually don't think it impacts them.
[01:07:12.520 --> 01:07:18.480]   And it's not necessarily about not caring, but it's like, you know, I use Facebook
[01:07:18.480 --> 01:07:20.360]   it basically is the white pages.
[01:07:20.360 --> 01:07:22.520]   That's how I use Facebook.
[01:07:22.520 --> 01:07:26.680]   And you know, I'm never on there.
[01:07:26.680 --> 01:07:30.320]   I'm literally never scrolling Facebook, right?
[01:07:30.320 --> 01:07:34.720]   I go on Facebook if I need to contact someone and that's the best way for me to contact
[01:07:34.720 --> 01:07:35.960]   them.
[01:07:35.960 --> 01:07:37.560]   And so, I am also one of those people.
[01:07:37.560 --> 01:07:41.200]   I'm one of those people who's like, eh, I'm not going to, I don't need to worry about
[01:07:41.200 --> 01:07:47.680]   the ads because I'm not behaving, I'm not really, I mean, I am a Facebook user, but
[01:07:47.680 --> 01:07:50.720]   I don't have a lot of behavior on Facebook.
[01:07:50.720 --> 01:07:52.440]   I haven't downloaded my data yet.
[01:07:52.440 --> 01:07:56.560]   I thought that piece in the Times was really interesting.
[01:07:56.560 --> 01:08:02.000]   But I do think that there's a large portion of people here that just, that literally don't
[01:08:02.000 --> 01:08:04.920]   think that this impacts them.
[01:08:04.920 --> 01:08:10.400]   And I feel like we need to talk about that too, as the country, as the US and I guess
[01:08:10.400 --> 01:08:18.320]   Europe and obviously Canada as well talk about data and these services.
[01:08:18.320 --> 01:08:24.600]   In a mid to avoid regulation, one thing that we're seeing coming out this week is that
[01:08:24.600 --> 01:08:29.200]   Facebook is articulating what its community guidelines are.
[01:08:29.200 --> 01:08:33.360]   I think they care because they don't want to see any flight from the site.
[01:08:33.360 --> 01:08:37.520]   I'm going to hit a couple of the highlights here and get your take on it.
[01:08:37.520 --> 01:08:41.560]   First of all, hate speech, they say we define hate speech as a direct attack on people based
[01:08:41.560 --> 01:08:46.640]   on what we call protected characteristics, race, ethnicity, national origin, religious
[01:08:46.640 --> 01:08:53.560]   affiliation, sexual orientation, sex, gender, gender identity, serious disability.
[01:08:53.560 --> 01:08:57.880]   We provide some protection for immigration status.
[01:08:57.880 --> 01:08:59.120]   That was interesting to me.
[01:08:59.120 --> 01:09:04.160]   And then the next one that was of the most interest was fake news, although they call
[01:09:04.160 --> 01:09:05.880]   it false news.
[01:09:05.880 --> 01:09:12.680]   We want to help people stay informed without stifling productive public discourse.
[01:09:12.680 --> 01:09:16.600]   There is also a fine line between false news and satire or opinion.
[01:09:16.600 --> 01:09:23.440]   For these reasons, we don't remove false news from Facebook, but instead significantly reduce
[01:09:23.440 --> 01:09:27.120]   its distribution by showing it lower in the news feed.
[01:09:27.120 --> 01:09:33.440]   That line is at the crux of this element of the Facebook problem to me.
[01:09:33.440 --> 01:09:36.600]   They don't know where they stand on this, in my opinion.
[01:09:36.600 --> 01:09:37.600]   Yeah.
[01:09:37.600 --> 01:09:42.420]   I have to say, unfortunately, I have the equivalent of 17 PhDs in hate speech after a gamer in
[01:09:42.420 --> 01:09:43.420]   Kate.
[01:09:43.420 --> 01:09:49.400]   So I'm unfortunately very familiar with Facebook and the efficacy of these exact policies that
[01:09:49.400 --> 01:09:51.040]   they're claiming to delineate.
[01:09:51.040 --> 01:09:53.160]   I wish I had nicer things to say.
[01:09:53.160 --> 01:09:54.880]   I don't.
[01:09:54.880 --> 01:09:58.320]   What they're saying on hate speech there is not true.
[01:09:58.320 --> 01:09:59.320]   It's not true.
[01:09:59.320 --> 01:10:02.520]   This week from events I've personally seen.
[01:10:02.520 --> 01:10:05.760]   You can go on Facebook.
[01:10:05.760 --> 01:10:07.400]   You can out transgender women.
[01:10:07.400 --> 01:10:14.120]   You can go after black people in really personal ways and they're not going to do anything.
[01:10:14.120 --> 01:10:19.720]   So that may be their policy, but the actual enforcement arm of that is non-existent.
[01:10:19.720 --> 01:10:23.680]   Reddit, Ben, you cover Reddit quite a bit.
[01:10:23.680 --> 01:10:27.440]   Their hate speech policies are even worse.
[01:10:27.440 --> 01:10:32.160]   Google is actively still having this issue of ranking because people love to click on
[01:10:32.160 --> 01:10:37.680]   dirt and it just rises to the top while valid sources of news go down.
[01:10:37.680 --> 01:10:41.800]   So Facebook can put out a piece of paper claiming what their policies are.
[01:10:41.800 --> 01:10:43.280]   It doesn't mean it's the outcome.
[01:10:43.280 --> 01:10:47.240]   And this is the first time that they are actually making public the guidelines with
[01:10:47.240 --> 01:10:53.640]   which their community group polices all of these flagged items.
[01:10:53.640 --> 01:10:58.480]   And what was fascinating to me in this is they say there are 10,000 actual humans that
[01:10:58.480 --> 01:11:04.640]   are doing the work of policing these posts that violate their community guidelines.
[01:11:04.640 --> 01:11:08.080]   I had no idea there were that many people working on this.
[01:11:08.080 --> 01:11:11.720]   And that seems shocking to me given how ineffective.
[01:11:11.720 --> 01:11:15.200]   As you say, Breonna, most people think the policing is.
[01:11:15.200 --> 01:11:16.200]   Yeah.
[01:11:16.200 --> 01:11:20.960]   I think community safety is one of the most understaffed areas of tech companies.
[01:11:20.960 --> 01:11:27.720]   Like community safety, your average tech company employs a very small number of these
[01:11:27.720 --> 01:11:31.880]   types of people who do this kind of work that is really important.
[01:11:31.880 --> 01:11:40.640]   And especially at the large tech company level, Google, Facebook, Instagram, WhatsApp, Telegram,
[01:11:40.640 --> 01:11:45.600]   any of these companies, or Reddit, any of these companies that deal in communication and can
[01:11:45.600 --> 01:11:53.440]   be considered social media at some level, employ probably too few people when it comes
[01:11:53.440 --> 01:11:54.440]   to community safety.
[01:11:54.440 --> 01:11:58.360]   And when you think about the fact that there's whatever, how many billion people on Facebook
[01:11:58.360 --> 01:12:05.440]   now, 10,000 people doing that work and doing it in shifts is a drop in the bucket.
[01:12:05.440 --> 01:12:12.040]   And what's interesting is a lot of the founders of these companies think that it's a tech
[01:12:12.040 --> 01:12:14.080]   issue that they can solve.
[01:12:14.080 --> 01:12:15.080]   And it's actually not.
[01:12:15.080 --> 01:12:16.800]   It's a human issue.
[01:12:16.800 --> 01:12:19.080]   And it's a human staffing issue, in my opinion.
[01:12:19.080 --> 01:12:27.000]   I don't think you can build an AI that protects people from harassment and a lot of the really
[01:12:27.000 --> 01:12:29.840]   bad stuff that happens on these platforms.
[01:12:29.840 --> 01:12:33.160]   You actually have to have human beings making those choices.
[01:12:33.160 --> 01:12:34.840]   And that's a big part of this too.
[01:12:34.840 --> 01:12:38.400]   It's like, I think these tech companies think it's a tech issue and that they're figuring
[01:12:38.400 --> 01:12:40.360]   it out and they can figure it out.
[01:12:40.360 --> 01:12:42.800]   But you have to actually hire humans to do this work.
[01:12:42.800 --> 01:12:47.720]   I want to get back to that specifically with the false news aspect with Facebook.
[01:12:47.720 --> 01:12:51.920]   One other development that came out this week around exactly what you're talking about,
[01:12:51.920 --> 01:12:55.480]   Ben, is YouTube released its community standards.
[01:12:55.480 --> 01:13:01.280]   And they had a point around artificial intelligence and how much they're using it.
[01:13:01.280 --> 01:13:02.280]   Listen to this.
[01:13:02.280 --> 01:13:06.960]   They say we removed over 8 million videos from YouTube during the last 12 months, or
[01:13:06.960 --> 01:13:12.320]   I'm not sure if it's 12 months, but when they instituted this new AI, the majority of
[01:13:12.320 --> 01:13:17.520]   these 8 million videos were mostly spam or people attempting to upload adult content.
[01:13:17.520 --> 01:13:24.400]   6.7 million of those were first flagged for review by machines rather than humans.
[01:13:24.400 --> 01:13:29.960]   Of those 6.7 million videos, 76% were removed before they received a single view.
[01:13:29.960 --> 01:13:33.840]   So you know when your video is processing, that's what's going on.
[01:13:33.840 --> 01:13:37.160]   I had no idea that that was the element of processing.
[01:13:37.160 --> 01:13:40.400]   I thought they were just like transcoding it or something.
[01:13:40.400 --> 01:13:46.640]   So, and they probably are, but also doing AI review on the content, but that's a pretty
[01:13:46.640 --> 01:13:48.360]   amazing number.
[01:13:48.360 --> 01:13:54.880]   76% of the videos were removed before they received a single view because they violated
[01:13:54.880 --> 01:13:56.040]   those community standards.
[01:13:56.040 --> 01:14:05.920]   So I do see a case for both AI and human intervention and community flagging, but it's
[01:14:05.920 --> 01:14:06.960]   just so nascent.
[01:14:06.960 --> 01:14:10.360]   I mean, to your point, Ben, it's like we got to have real humans in there, right?
[01:14:10.360 --> 01:14:17.600]   Yeah, I mean, it's definitely something that I think can happen in concert, right?
[01:14:17.600 --> 01:14:25.040]   And these systems that these companies build are kind of incredible in terms of how they
[01:14:25.040 --> 01:14:27.920]   identify things that might be problematic.
[01:14:27.920 --> 01:14:31.560]   I remember one of my favorite stories from, I don't know, it must have been like four
[01:14:31.560 --> 01:14:36.560]   years ago now is Google's ad fraud tool.
[01:14:36.560 --> 01:14:41.840]   This was even before Google got booted from China was picking up all of these like weird
[01:14:41.840 --> 01:14:48.320]   photos that were from users that ended up stealing cars.
[01:14:48.320 --> 01:14:53.680]   So it was almost like a weird AI precog thing where this AI that they built to crack down
[01:14:53.680 --> 01:14:59.200]   on ad fraud was identifying car theft before it happened.
[01:14:59.200 --> 01:15:04.840]   So there is like some amazing stuff that happens with, and AI is obviously a simplistic way
[01:15:04.840 --> 01:15:09.320]   of describing this, but machine learning algorithms that are doing this work to flag
[01:15:09.320 --> 01:15:14.240]   some of this stuff, but it absolutely has to be, it is nascent and it absolutely has
[01:15:14.240 --> 01:15:16.600]   to involve humans at a certain level.
[01:15:16.600 --> 01:15:19.880]   And I think tech companies are starting to learn that slowly, but surely.
[01:15:19.880 --> 01:15:26.120]   Yeah, the computers are great with copyright images or songs that are copyrights.
[01:15:26.120 --> 01:15:30.640]   They're great at protecting that, but they're not great at dealing with hate speech because
[01:15:30.640 --> 01:15:33.640]   you have to be able to go through and actually listen to it.
[01:15:33.640 --> 01:15:38.440]   And I think that really what Facebook and YouTube, what all of these companies are doing is pretty
[01:15:38.440 --> 01:15:41.040]   much saying, listen, we can regulate ourselves.
[01:15:41.040 --> 01:15:42.720]   Please don't regulate us.
[01:15:42.720 --> 01:15:47.280]   And so they're doing the minimal amount possible to try to put people at ease that we're actually
[01:15:47.280 --> 01:15:49.080]   going to take care of this problem.
[01:15:49.080 --> 01:15:50.160]   It's not really a problem.
[01:15:50.160 --> 01:15:54.600]   It's going to go away, but they're not really taking care of people and computers don't
[01:15:54.600 --> 01:15:55.720]   do a great job of that.
[01:15:55.720 --> 01:16:00.680]   Now, I want to go back to the fake news issue too, because this really bugs me as a journalist,
[01:16:00.680 --> 01:16:05.960]   which is we're just going to down rank the fake news, but we're not going to get rid
[01:16:05.960 --> 01:16:06.960]   of it.
[01:16:06.960 --> 01:16:08.040]   So what is it?
[01:16:08.040 --> 01:16:12.360]   Is it you're either all in or you're all out, in my opinion, on this.
[01:16:12.360 --> 01:16:17.400]   You're either completely uncensored or you're doing something about it.
[01:16:17.400 --> 01:16:22.600]   And so it just bothers me because I feel like they do have a moral responsibility to
[01:16:22.600 --> 01:16:29.320]   have some journalistic ethics in here around what's being propagated, agree or disagree.
[01:16:29.320 --> 01:16:31.360]   Is that just too slippery or slow?
[01:16:31.360 --> 01:16:37.360]   I just think, you know, I'm a former journalist personally and I'm very sympathetic to the
[01:16:37.360 --> 01:16:41.840]   argument there, but I actually think this is kind of perfect compromise.
[01:16:41.840 --> 01:16:46.240]   You know, for me, I've had a lot of talk with Google and this is before I was writing
[01:16:46.240 --> 01:16:50.320]   for office, like when you become a public figure, I realized you're in a different category,
[01:16:50.320 --> 01:16:55.560]   but just Brianna, we have the citizen back in 2016 was having a lot of talks with Google
[01:16:55.560 --> 01:17:01.600]   about how you'd have people that would basically use SEO to manipulate certain stories that
[01:17:01.600 --> 01:17:06.800]   didn't come from credible sources to go very high in my Google results.
[01:17:06.800 --> 01:17:10.640]   You know, my argument with them is let's rank the New York Times, let's rank Wall Street
[01:17:10.640 --> 01:17:13.400]   Journal, let's rank the Boston Globe higher.
[01:17:13.400 --> 01:17:16.320]   I don't want this to be banished from the search results.
[01:17:16.320 --> 01:17:20.400]   Let's just put stuff that's credible higher up to me.
[01:17:20.400 --> 01:17:27.360]   I think if you got Facebook into the daily business of saying, okay, this thing that
[01:17:27.360 --> 01:17:32.080]   they said from Red State or, you know, think progress isn't quite true.
[01:17:32.080 --> 01:17:34.000]   So we're just going to delete that.
[01:17:34.000 --> 01:17:38.400]   That is a slog that I just don't think Facebook can win.
[01:17:38.400 --> 01:17:44.400]   But if you're down ranking things from these, you know, spam pages like, you know, the 99%
[01:17:44.400 --> 01:17:49.480]   would be a left-wing one on Facebook or, you know, some of the more extreme right-wing
[01:17:49.480 --> 01:17:52.480]   ones, I think that has value.
[01:17:52.480 --> 01:17:55.120]   So I actually think this is a really good compromise.
[01:17:55.120 --> 01:18:01.520]   But isn't the analog for that taking an untrue statement or article and putting it on the
[01:18:01.520 --> 01:18:03.000]   back page of the newspaper?
[01:18:03.000 --> 01:18:04.000]   It's still in the newspaper.
[01:18:04.000 --> 01:18:07.560]   But what happens about what is fake news, right?
[01:18:07.560 --> 01:18:08.560]   Yeah.
[01:18:08.560 --> 01:18:11.040]   Like, how do we actually say what's fake?
[01:18:11.040 --> 01:18:16.240]   And I think that that becomes really difficult because, you know, I tell a story that's my
[01:18:16.240 --> 01:18:18.840]   story and then the government says, well, that's not true.
[01:18:18.840 --> 01:18:21.680]   And now my story doesn't get to go out there.
[01:18:21.680 --> 01:18:27.800]   And so though I don't like to hear stories that are being propagated because of them
[01:18:27.800 --> 01:18:32.120]   being extreme, and I think that extremism really does lead to us being on two different
[01:18:32.120 --> 01:18:35.160]   sides and fighting a battle that we need to fight together.
[01:18:35.160 --> 01:18:39.480]   But if you just get rid of it, who chooses what is fake and by what standards?
[01:18:39.480 --> 01:18:43.160]   I think that one is it would take a momentous amount of information.
[01:18:43.160 --> 01:18:47.720]   And I think that areas that maybe you could like, you know, overall scope of like, you
[01:18:47.720 --> 01:18:52.800]   know, like, you know, dealing with things that are hateful or that are trying to, you
[01:18:52.800 --> 01:18:55.160]   know, cause extremism you could take a look at.
[01:18:55.160 --> 01:18:59.240]   But it just becomes a really difficult piece of what is fake and what is not fake and
[01:18:59.240 --> 01:19:03.560]   what if a site that brings out a lot of fake news then gives a story that's true, then
[01:19:03.560 --> 01:19:07.120]   you're kind of giving a blanket statement for all of them.
[01:19:07.120 --> 01:19:12.160]   But in that instance, I agree with both of them.
[01:19:12.160 --> 01:19:20.000]   Like I think that I, you know, I just think this type of thing can go south in a really
[01:19:20.000 --> 01:19:24.320]   bad way in some dystopian future if we're not careful.
[01:19:24.320 --> 01:19:31.560]   So like, it's tough because you definitely want users to understand the content that
[01:19:31.560 --> 01:19:38.200]   they're seeing and understand the quality of it, you know, but it's yeah, I think once
[01:19:38.200 --> 01:19:45.800]   you start basically erasing things or deep-sickening them so far that they get erased as a tech
[01:19:45.800 --> 01:19:51.160]   company, I think that becomes problematic really quickly when it comes to fake news at
[01:19:51.160 --> 01:19:56.120]   least and deciding what can and can't exist on the platform.
[01:19:56.120 --> 01:19:57.120]   I see that.
[01:19:57.120 --> 01:19:58.760]   It would take a lot of the first, right?
[01:19:58.760 --> 01:20:00.320]   Like you'd have to have people, right?
[01:20:00.320 --> 01:20:02.160]   Becky to be able to do that.
[01:20:02.160 --> 01:20:07.720]   So then a story would what be put on hold while a human actually vets its truth and
[01:20:07.720 --> 01:20:11.480]   then we're waiting for that and the chatroom by the way supports you, Becky, they're going
[01:20:11.480 --> 01:20:14.320]   wild saying, "Fake is so easy, Georgia.
[01:20:14.320 --> 01:20:15.400]   What color is your hair?
[01:20:15.400 --> 01:20:16.400]   Is it blonde?
[01:20:16.400 --> 01:20:18.480]   Yes or no, this would be easy to do."
[01:20:18.480 --> 01:20:20.200]   But you would have to have a human do that.
[01:20:20.200 --> 01:20:24.760]   Well, I guess that's why I'm so adamant about this is because that's what I have to do every
[01:20:24.760 --> 01:20:26.080]   day in my job.
[01:20:26.080 --> 01:20:30.600]   I mean, when you work for a big, you know, I work for a network that's held accountable
[01:20:30.600 --> 01:20:36.280]   to this where people lose their jobs if they don't get it 100% right or if we include stuff
[01:20:36.280 --> 01:20:40.400]   that's so fringe that it's not a good representation of the truth.
[01:20:40.400 --> 01:20:45.240]   So I feel like this is the business that I'm in and we have this incredible overarching
[01:20:45.240 --> 01:20:52.720]   standards and legal department that oversees everything we do and I feel so much constraint
[01:20:52.720 --> 01:20:59.720]   to get it right in this instance that it chaps me that Facebook doesn't have that same
[01:20:59.720 --> 01:21:00.720]   constraint.
[01:21:00.720 --> 01:21:07.200]   Now, that being said, if I put something on my own Facebook page and I went back and Facebook
[01:21:07.200 --> 01:21:11.040]   had deleted it, I'd say I'd be infinitely more chapped.
[01:21:11.040 --> 01:21:14.760]   So I, this is a tough one.
[01:21:14.760 --> 01:21:15.760]   I can see it.
[01:21:15.760 --> 01:21:16.760]   It's a tough one.
[01:21:16.760 --> 01:21:17.760]   But I do.
[01:21:17.760 --> 01:21:21.160]   It would be wonderful if everything that went out onto the internet were things that
[01:21:21.160 --> 01:21:28.240]   were true or fact based, but then people's opinions get like it becomes, it just, I think
[01:21:28.240 --> 01:21:29.840]   it becomes so muddy.
[01:21:29.840 --> 01:21:30.840]   It's not that easy.
[01:21:30.840 --> 01:21:35.080]   I think that some things are easier than others to deal with.
[01:21:35.080 --> 01:21:39.400]   At some point we as a society are going to have to wrestle with the fact that it's not
[01:21:39.400 --> 01:21:45.880]   necessarily good for everyone in America to be reading different sources of news all the
[01:21:45.880 --> 01:21:46.880]   time.
[01:21:46.880 --> 01:21:49.720]   It just plays really hard into confirmation bias.
[01:21:49.720 --> 01:21:55.880]   As bad as I remember, like network television being 20 years ago, it's just that much worse
[01:21:55.880 --> 01:21:56.880]   now.
[01:21:56.880 --> 01:22:02.800]   And, you know, for me, even as I'm conducting a political campaign, it disturbs me that
[01:22:02.800 --> 01:22:09.080]   when I put ads out on Facebook and Twitter and Google AdSense, there's nothing there
[01:22:09.080 --> 01:22:14.680]   checking anything I'm doing, seeing if it's true, holding me accountable, or even telling
[01:22:14.680 --> 01:22:17.160]   people who's sending the ad.
[01:22:17.160 --> 01:22:22.600]   We do that because we want to get the extra mile and hold ourselves to high standards.
[01:22:22.600 --> 01:22:24.040]   But it does bother me.
[01:22:24.040 --> 01:22:30.200]   At some point we as a society are going to have to really think about this issue.
[01:22:30.200 --> 01:22:35.280]   Personally, if I were in charge of Facebook, I think they should alter the ratio a bit and
[01:22:35.280 --> 01:22:40.240]   make the American public eat their vegetables a little bit more and rank the New York Times
[01:22:40.240 --> 01:22:45.440]   and the Washington Post and like real sources of news higher because we need to be reading
[01:22:45.440 --> 01:22:48.400]   about things that aren't cat and dog pictures.
[01:22:48.400 --> 01:22:51.520]   We need to be reading about the USDA regulation.
[01:22:51.520 --> 01:22:55.600]   We need to be reading about what's going on with Wall Street deregulation.
[01:22:55.600 --> 01:22:59.160]   These are things that we need to be thinking about and we just don't anymore in the Facebook
[01:22:59.160 --> 01:23:00.160]   era.
[01:23:00.160 --> 01:23:03.440]   You know, as you're talking about something interesting that just popped into my head,
[01:23:03.440 --> 01:23:08.320]   at least I think it's interesting, is that I read the New York Times and the Wall Street
[01:23:08.320 --> 01:23:12.360]   Journal every day and I pay for both.
[01:23:12.360 --> 01:23:17.760]   And I do it so that I can hear both sides in a measured way.
[01:23:17.760 --> 01:23:22.040]   And I think it's really important for me to read the Wall Street Journal in that respect.
[01:23:22.040 --> 01:23:26.680]   And the fact that it's behind a paywall is actually a problem because it's one of the
[01:23:26.680 --> 01:23:32.120]   most moderate conservative leaning journalistic sources.
[01:23:32.120 --> 01:23:38.400]   And the paywall is preventing people from reading moderate leaning a little bit right
[01:23:38.400 --> 01:23:39.400]   journalism.
[01:23:39.400 --> 01:23:43.800]   And it's just suddenly dawned on me that, wow, that's a problem.
[01:23:43.800 --> 01:23:48.400]   There is, if you are, God, how do I say this?
[01:23:48.400 --> 01:23:53.040]   When you are in circles of political power talking to people about things, you kind of
[01:23:53.040 --> 01:23:56.800]   have to be the kind of person that reads the Wall Street Journal or the New York Times.
[01:23:56.800 --> 01:24:01.480]   It's kind of an unconscious level, like language of power.
[01:24:01.480 --> 01:24:07.800]   And what I think we've moved to is that informing yourself is something only the very richest
[01:24:07.800 --> 01:24:09.680]   Americans can do, right?
[01:24:09.680 --> 01:24:13.920]   Like there's a certain amount of privilege for me, subscribing to New York Times, Washington
[01:24:13.920 --> 01:24:17.360]   Post, Wall Street Journal, Boston Globe.
[01:24:17.360 --> 01:24:19.320]   I don't think that's good.
[01:24:19.320 --> 01:24:23.000]   And I think at some point we're going to have to wrestle with the fact that the new media
[01:24:23.000 --> 01:24:26.000]   ad model is not sustainable.
[01:24:26.000 --> 01:24:33.640]   Subscriptions and community supported media really seems to be the only supported model
[01:24:33.640 --> 01:24:35.080]   for media funding itself.
[01:24:35.080 --> 01:24:38.920]   Well, we are going to take a break right now, but we're going to come back and talk about
[01:24:38.920 --> 01:24:43.960]   a story that was broken by my local newspaper, the East Bay Times.
[01:24:43.960 --> 01:24:45.960]   So I'm very excited to give them a plug.
[01:24:45.960 --> 01:24:49.320]   When I started in journalism, I had to decide if I was going to be a general assignment
[01:24:49.320 --> 01:24:55.520]   reporter, which means you cover everything and a lot of crime, or a niche reporter like
[01:24:55.520 --> 01:24:57.040]   Business and Tech.
[01:24:57.040 --> 01:25:01.880]   And I went on a couple of big general assignment stories, one of which was a crime story.
[01:25:01.880 --> 01:25:06.120]   And I ended up such an emotional wreck for days that I became a tech reporter because
[01:25:06.120 --> 01:25:08.400]   I couldn't handle the crime stories.
[01:25:08.400 --> 01:25:13.680]   But we are going to come back and talk about an absolutely fascinating intersection of crime,
[01:25:13.680 --> 01:25:15.600]   technology and ethics.
[01:25:15.600 --> 01:25:16.600]   So stick around.
[01:25:16.600 --> 01:25:17.600]   We'll be right back.
[01:25:17.600 --> 01:25:18.600]   Excuse me.
[01:25:18.600 --> 01:25:19.600]   Part me, it's Leo.
[01:25:19.600 --> 01:25:22.680]   I'm just corning in here because I want to tell you about something I've used for so
[01:25:22.680 --> 01:25:23.680]   long.
[01:25:23.680 --> 01:25:25.800]   I'm kind of the expert on it around here.
[01:25:25.800 --> 01:25:26.800]   Stamps.com.
[01:25:26.800 --> 01:25:30.040]   They've been advertising with us.
[01:25:30.040 --> 01:25:31.480]   I think it's been a decade.
[01:25:31.480 --> 01:25:33.080]   You've been using it for a decade.
[01:25:33.080 --> 01:25:34.080]   Stamps.com.
[01:25:34.080 --> 01:25:39.320]   In fact, I remember my first kind of acquaintance with Stamps.com because I got to have this
[01:25:39.320 --> 01:25:42.720]   thing where you could print stamps with your picture on it.
[01:25:42.720 --> 01:25:44.440]   I thought, "Oh, that's kind of fun."
[01:25:44.440 --> 01:25:48.760]   So I was sending out a fan mail with my picture stamp on it.
[01:25:48.760 --> 01:25:50.640]   But then I found out about all the services they offer.
[01:25:50.640 --> 01:25:52.360]   I love Stamps.com.
[01:25:52.360 --> 01:25:56.880]   Basically it gives you all the amazing services of the post office right at your desk.
[01:25:56.880 --> 01:25:58.560]   You never have to get up from your desk.
[01:25:58.560 --> 01:26:01.440]   Anytime you need it, whenever it's convenient, you can buy and print.
[01:26:01.440 --> 01:26:04.480]   It's an official US postage.
[01:26:04.480 --> 01:26:09.720]   For any package, any letter, any class of mail, you don't need any special ink.
[01:26:09.720 --> 01:26:10.960]   You don't need a postage meter.
[01:26:10.960 --> 01:26:13.360]   You just need your computer, your printer.
[01:26:13.360 --> 01:26:14.600]   That's it.
[01:26:14.600 --> 01:26:16.920]   The mail carrier will come and get it.
[01:26:16.920 --> 01:26:19.600]   So you probably don't even have to get up from your desk at all.
[01:26:19.600 --> 01:26:21.880]   I would recommend getting up from your desk once in a while.
[01:26:21.880 --> 01:26:24.000]   But you don't have to do it for this.
[01:26:24.000 --> 01:26:25.640]   Create your Stamps account in minutes.
[01:26:25.640 --> 01:26:26.640]   It's all online.
[01:26:26.640 --> 01:26:27.640]   You don't need any equipment.
[01:26:27.640 --> 01:26:28.640]   Nothing at least.
[01:26:28.640 --> 01:26:30.480]   No long-term commitments.
[01:26:30.480 --> 01:26:35.480]   They do have a pretty good offer though, which includes a digital scale, which I love.
[01:26:35.480 --> 01:26:36.480]   It's a USB scale.
[01:26:36.480 --> 01:26:40.480]   You plug it in and automatically figures out the right postage and then feeds it into Stamps.com.
[01:26:40.480 --> 01:26:43.520]   So that couldn't be better.
[01:26:43.520 --> 01:26:47.040]   You don't have to never again will you put extra stamps on a package just to make sure
[01:26:47.040 --> 01:26:49.160]   it's not postage due.
[01:26:49.160 --> 01:26:54.480]   They even help you decide if there's a more affordable class of mail.
[01:26:54.480 --> 01:26:57.240]   You could be sending this media mail, things like that.
[01:26:57.240 --> 01:27:00.200]   Click Print Mail and you're done.
[01:27:00.200 --> 01:27:01.200]   It could not be easier.
[01:27:01.200 --> 01:27:03.160]   It could not be more affordable.
[01:27:03.160 --> 01:27:04.480]   I am a huge fan.
[01:27:04.480 --> 01:27:06.560]   I love Stamps.com.
[01:27:06.560 --> 01:27:09.640]   Right now you too can enjoy the Stamps.com service.
[01:27:09.640 --> 01:27:11.720]   They've got a very nice special offer.
[01:27:11.720 --> 01:27:16.000]   If you just go to Stamps.com, click on the microphone right at the top there in the upper
[01:27:16.000 --> 01:27:21.400]   right and then when it asks you for the offer code TWIT, if you will, that gives you up
[01:27:21.400 --> 01:27:25.640]   to $55 free postage, the digital scale of four-week trial.
[01:27:25.640 --> 01:27:26.640]   Stamps.com.
[01:27:26.640 --> 01:27:30.160]   Click the mic right up on the upper right there and your Twitch.
[01:27:30.160 --> 01:27:31.160]   Stamps.com.
[01:27:31.160 --> 01:27:36.160]   Really, if you're not using Stamps.com, you're missing the boat.
[01:27:36.160 --> 01:27:37.840]   You've got to try it.
[01:27:37.840 --> 01:27:39.680]   Now I'm with the show.
[01:27:39.680 --> 01:27:40.840]   Thank you, Leo.
[01:27:40.840 --> 01:27:42.080]   Quick correction.
[01:27:42.080 --> 01:27:44.320]   Thank God for the chat room.
[01:27:44.320 --> 01:27:47.920]   KDKA is the station.
[01:27:47.920 --> 01:27:54.880]   It's a CBS station in Pittsburgh, Pennsylvania with a K and that is not west of the Mississippi.
[01:27:54.880 --> 01:27:58.440]   I just couldn't have handled the feedback if that had come back to you.
[01:27:58.440 --> 01:27:59.440]   Is it Mason Dixon?
[01:27:59.440 --> 01:28:00.440]   What's the line?
[01:28:00.440 --> 01:28:04.080]   I don't know what the actual line is.
[01:28:04.080 --> 01:28:08.600]   It's primarily west of the Mississippi, but it looks like there are some exceptions.
[01:28:08.600 --> 01:28:11.600]   I'm going to have to do some research on this.
[01:28:11.600 --> 01:28:13.160]   Fake news.
[01:28:13.160 --> 01:28:14.160]   Fake news.
[01:28:14.160 --> 01:28:15.160]   Fake news.
[01:28:15.160 --> 01:28:16.160]   Gang, fake news.
[01:28:16.160 --> 01:28:17.160]   I'm downrated.
[01:28:17.160 --> 01:28:18.160]   Okay.
[01:28:18.160 --> 01:28:23.720]   This was one of the most interesting stories of the week to me.
[01:28:23.720 --> 01:28:28.400]   We had the arrest of the Golden State killer, serial killer from the '70s, '80s and up into
[01:28:28.400 --> 01:28:31.600]   the '90s here in California.
[01:28:31.600 --> 01:28:39.240]   The break in the case came when a detective who was assigned to the case, he was a cold
[01:28:39.240 --> 01:28:47.960]   case expert, decided to use some of the DNA from one of the crime scenes and created a
[01:28:47.960 --> 01:28:54.600]   fake account at a DNA, online DNA site called GED Match.
[01:28:54.600 --> 01:29:03.480]   It's an open source DNA website and it looks to me like it's primarily used to find relatives
[01:29:03.480 --> 01:29:10.720]   for people who've been adopted or in some cases people who want to find long lost relatives.
[01:29:10.720 --> 01:29:12.680]   You upload your DNA.
[01:29:12.680 --> 01:29:16.560]   They have a full disclosure that it's open source that other people are going to be matching
[01:29:16.560 --> 01:29:22.960]   against you and they can't control how your DNA is used and what results come back.
[01:29:22.960 --> 01:29:31.400]   From this came a narrowing of the pool of potential families that the DNA from the crime
[01:29:31.400 --> 01:29:33.360]   scene matched.
[01:29:33.360 --> 01:29:38.560]   With that, instead of having millions of people to try and cross reference, it ended up being
[01:29:38.560 --> 01:29:46.040]   that the detectives were able to narrow it down to a few family groups and just a few
[01:29:46.040 --> 01:29:49.080]   thousand people and that's how they found the killer.
[01:29:49.080 --> 01:29:56.920]   They ended up narrowing it down to one suspect in that familial group whose profile matched
[01:29:56.920 --> 01:30:03.080]   and then they picked up discarded DNA which sounds to me like they went through as trash
[01:30:03.080 --> 01:30:05.880]   and ran DNA tests to see if there was a match.
[01:30:05.880 --> 01:30:12.360]   There was and this was the person who was arrested and has been charged as the killer.
[01:30:12.360 --> 01:30:15.560]   So, open source DNA database.
[01:30:15.560 --> 01:30:19.720]   Best black mirror episode ending ever.
[01:30:19.720 --> 01:30:23.760]   Ending on a happy note.
[01:30:23.760 --> 01:30:25.880]   That's right.
[01:30:25.880 --> 01:30:28.760]   Lots of ethical questions here.
[01:30:28.760 --> 01:30:35.760]   It appears that this is legal given that people have willingly uploaded their DNA and that
[01:30:35.760 --> 01:30:42.200]   the match came from a third or fourth cousin of the man who was arrested.
[01:30:42.200 --> 01:30:47.320]   Thoughts, you're opening up a can of worms when you do this.
[01:30:47.320 --> 01:30:53.040]   To be clear, this wasn't 23 and me or any of the other big sites who say they only respond
[01:30:53.040 --> 01:30:57.240]   to police warrants or subpoenas to have access to things like this.
[01:30:57.240 --> 01:31:00.200]   This was an open source database.
[01:31:00.200 --> 01:31:08.200]   The reason that people do this is because so if you were on say ancestry, it wasn't that.
[01:31:08.200 --> 01:31:13.760]   Let's say you're on ancestry, you will only be marked by other people that have gone on
[01:31:13.760 --> 01:31:14.760]   ancestry.
[01:31:14.760 --> 01:31:21.920]   So by putting it online to an open source, all of the other people from other DNA sites
[01:31:21.920 --> 01:31:24.400]   can check to see what your genealogy may be.
[01:31:24.400 --> 01:31:26.360]   So you end up with a bigger set of data.
[01:31:26.360 --> 01:31:30.600]   So it's very for people that are interested in finding out their genealogy.
[01:31:30.600 --> 01:31:32.600]   That's a good idea for them.
[01:31:32.600 --> 01:31:39.320]   But the problem is that you're not just giving up your data to a company that has a privacy
[01:31:39.320 --> 01:31:44.440]   policy who knows if they're actually enforcing that, but you're now letting anyone be able
[01:31:44.440 --> 01:31:47.080]   to access your information.
[01:31:47.080 --> 01:31:52.600]   Yeah, there's a pattern throughout history where we discover new technology and then
[01:31:52.600 --> 01:31:56.240]   we find out what the consequences of it are.
[01:31:56.240 --> 01:31:58.800]   And like with this, it's very mixed.
[01:31:58.800 --> 01:32:04.360]   Personally, for me, I'm adopted and eventually one of these days I'm going to go get in touch
[01:32:04.360 --> 01:32:05.360]   with my birthmote.
[01:32:05.360 --> 01:32:06.360]   I'm going to meet her.
[01:32:06.360 --> 01:32:07.640]   I turned 40 this year.
[01:32:07.640 --> 01:32:11.160]   There's probably not a lot of time left to do that.
[01:32:11.160 --> 01:32:18.360]   But here you have something very clearly could be used for a lot of really dark purposes,
[01:32:18.360 --> 01:32:25.760]   not just overreach of law enforcement, not just like the idea of open sourcing your DNA.
[01:32:25.760 --> 01:32:32.240]   I think you'd have to be really careless to agree to that.
[01:32:32.240 --> 01:32:37.680]   It really speaks to the need for regulatory environment with people that understand these
[01:32:37.680 --> 01:32:42.240]   issues and are willing to educate themselves on it.
[01:32:42.240 --> 01:32:44.760]   So yeah, it's both scary and good.
[01:32:44.760 --> 01:32:47.400]   I totally agree with that on the regulatory part of this.
[01:32:47.400 --> 01:32:52.920]   I mean, I think this is strangely connected for me at least to the Cambridge Analytica
[01:32:52.920 --> 01:32:59.280]   conversation, which is we're talking about personal data and how it gets used.
[01:32:59.280 --> 01:33:03.560]   And we're also talking about this idea, at least in this case, that once you put your
[01:33:03.560 --> 01:33:08.720]   information out on the internet, it doesn't go away.
[01:33:08.720 --> 01:33:16.480]   And there have been all sorts of problems with this at the state level.
[01:33:16.480 --> 01:33:23.200]   And people getting things on their record as a minor and having that data be collected
[01:33:23.200 --> 01:33:24.200]   by this.
[01:33:24.200 --> 01:33:30.440]   That information be sold by the state as part of a larger data package to a data-broke
[01:33:30.440 --> 01:33:32.480]   or a data broker company.
[01:33:32.480 --> 01:33:38.280]   And then when they become an adult, their record at the state level gets expunged.
[01:33:38.280 --> 01:33:43.880]   But this data that the state has now sold to another company is still floating around.
[01:33:43.880 --> 01:33:50.880]   And so I think, I know this, maybe this all sounds a little weird and vague, but I do
[01:33:50.880 --> 01:33:56.840]   really think that we need regulation when it comes to your personal data.
[01:33:56.840 --> 01:34:01.680]   And the FTC, I think, is at least in my mind, is the best place to start to think about
[01:34:01.680 --> 01:34:02.680]   that.
[01:34:02.680 --> 01:34:08.920]   But users, I mean, and eventually this will happen anyway, I think users just need to
[01:34:08.920 --> 01:34:15.360]   be super informed about the kind of data that they put out as an internet user.
[01:34:15.360 --> 01:34:19.840]   And I think that they need to be in more control of it.
[01:34:19.840 --> 01:34:26.360]   And I think that government is basically the intermediary to make that happen and to regulate
[01:34:26.360 --> 01:34:31.520]   so that people can be more in control of their information.
[01:34:31.520 --> 01:34:39.240]   Obviously, this was a good story for solving the crime potentially, and there are a lot
[01:34:39.240 --> 01:34:42.000]   of good things about this particular headline in the news.
[01:34:42.000 --> 01:34:49.600]   But I do think it connects to this larger issue of data ownership and government regulation
[01:34:49.600 --> 01:34:54.480]   that helps individual users get that data ownership.
[01:34:54.480 --> 01:35:00.360]   I think there might be another area as well that we need to increase media or literacy.
[01:35:00.360 --> 01:35:05.400]   And the ideas of privacy policies, and I think that it should be taught to children in school,
[01:35:05.400 --> 01:35:09.760]   because we've all seen we're all in the tech industry and we all try to get information
[01:35:09.760 --> 01:35:14.840]   out, yet Becky and I both know people that have no clue about what Facebook was dealing
[01:35:14.840 --> 01:35:17.440]   with and why and how that's important.
[01:35:17.440 --> 01:35:20.720]   And I think that it starts with the same thing even with fake news.
[01:35:20.720 --> 01:35:26.200]   If we taught kids at a young age, what is media literacy, what are hook lines, what
[01:35:26.200 --> 01:35:31.280]   are people trying to deal with our emotions, what are we signing up for, what are privacy
[01:35:31.280 --> 01:35:35.120]   and you lose, what do they mean, what should we look out for.
[01:35:35.120 --> 01:35:38.760]   Then we have something to go against because we have an educated group of people to be
[01:35:38.760 --> 01:35:41.920]   able to deal with this and technology is no longer so scary.
[01:35:41.920 --> 01:35:43.840]   They also know what their rights are.
[01:35:43.840 --> 01:35:49.960]   But just getting out the media out there without having it put in place as education, I don't
[01:35:49.960 --> 01:35:51.280]   think that that's going to work.
[01:35:51.280 --> 01:35:53.160]   At least it hasn't so far.
[01:35:53.160 --> 01:35:58.000]   What do you guys think about the issue of this when you come back to the crime issue
[01:35:58.000 --> 01:36:04.680]   and law enforcement reaching out to these companies like 23andMe that source your helix
[01:36:04.680 --> 01:36:10.440]   or any of the others that take a look at your DNA and sequence it.
[01:36:10.440 --> 01:36:13.280]   Is that an overreach issue?
[01:36:13.280 --> 01:36:14.800]   Where do we draw the line?
[01:36:14.800 --> 01:36:20.600]   How much of this is just modern science and technology biting people in the butt?
[01:36:20.600 --> 01:36:24.120]   The chat room is asking why is this an issue for this particular criminal and the issue
[01:36:24.120 --> 01:36:26.200]   is he didn't upload his data.
[01:36:26.200 --> 01:36:31.720]   His third cousin uploaded his DNA data and that's how he got caught.
[01:36:31.720 --> 01:36:32.720]   He had no idea.
[01:36:32.720 --> 01:36:34.600]   It is an analog to the Facebook thing.
[01:36:34.600 --> 01:36:35.840]   It's not that you did the quiz.
[01:36:35.840 --> 01:36:38.600]   It's that your buddy did the quiz.
[01:36:38.600 --> 01:36:44.400]   The issue of overreach on this when it comes to DNA I think is the fear people have always
[01:36:44.400 --> 01:36:48.360]   had about, if you've got your tin foil hat on and you're covering, you're getting your
[01:36:48.360 --> 01:36:52.600]   fillings out, this story confirms everything for you.
[01:36:52.600 --> 01:37:00.520]   Well, I want to say I don't think it's tin foil to be concerned about this at all.
[01:37:00.520 --> 01:37:05.760]   We have seen a lot of stories in America this year about and last year about how black
[01:37:05.760 --> 01:37:07.720]   people are treated by police.
[01:37:07.720 --> 01:37:12.080]   I think it is true that you can see law enforcement overreach here.
[01:37:12.080 --> 01:37:19.320]   I think for us the question is where does the Fourth Amendment apply here?
[01:37:19.320 --> 01:37:20.600]   Is a judge involved?
[01:37:20.600 --> 01:37:22.680]   Is there probable cause?
[01:37:22.680 --> 01:37:28.440]   What I think is really fantastic here is I have no doubt that as this case is being adjudicated,
[01:37:28.440 --> 01:37:32.560]   you're going to have a defense lawyer that's going to argue all of these points that we're
[01:37:32.560 --> 01:37:34.200]   mentioning right here.
[01:37:34.200 --> 01:37:35.200]   It will go to appeal.
[01:37:35.200 --> 01:37:36.200]   I have no doubt.
[01:37:36.200 --> 01:37:41.280]   It will go to an appellate court and we will start to form jurisprudence around this issue,
[01:37:41.280 --> 01:37:45.680]   like a legal framework for us to be discussing it.
[01:37:45.680 --> 01:37:47.440]   I think that is going to happen.
[01:37:47.440 --> 01:37:48.440]   That's good.
[01:37:48.440 --> 01:37:52.040]   I think that Congress really has a role to play.
[01:37:52.040 --> 01:37:53.000]   Then I want to disagree with you.
[01:37:53.000 --> 01:37:55.560]   I don't think the FTC is the place to do this.
[01:37:55.560 --> 01:38:01.120]   I think it's really more of the role of the technology subcommittee to do this particularly
[01:38:01.120 --> 01:38:07.360]   of records because you have a lot of control over the way formats are used by that subcommittee.
[01:38:07.360 --> 01:38:10.280]   I just think it would be a more direct way to address it.
[01:38:10.280 --> 01:38:12.280]   Also, CR1 in the end.
[01:38:12.280 --> 01:38:13.280]   I'm happy.
[01:38:13.280 --> 01:38:15.280]   Say that again, Ben?
[01:38:15.280 --> 01:38:18.280]   I said as long as somebody freaking does it, I'm happy.
[01:38:18.280 --> 01:38:23.280]   CR1 in the chat rooms also adds note to self.
[01:38:23.280 --> 01:38:27.280]   Remember not to take a Facebook quiz titled, "Am I a serial killer?"
[01:38:27.280 --> 01:38:29.280]   That's the combining.
[01:38:29.280 --> 01:38:30.280]   It's good.
[01:38:30.280 --> 01:38:33.280]   No, you probably already know.
[01:38:33.280 --> 01:38:34.280]   Right.
[01:38:34.280 --> 01:38:36.920]   I mean, you might.
[01:38:36.920 --> 01:38:42.280]   This is one aspect of this story that is kind of the horse has already left the barn.
[01:38:42.280 --> 01:38:47.000]   There are 900,000 DNA files on this GED match database.
[01:38:47.000 --> 01:38:51.080]   Almost a million DNA records have already been uploaded.
[01:38:51.080 --> 01:38:55.920]   If you think about the relatives of those million people, it's out there.
[01:38:55.920 --> 01:39:02.200]   The web that that creates is already in the public domain.
[01:39:02.200 --> 01:39:06.240]   This is already long established as being now a tool.
[01:39:06.240 --> 01:39:12.640]   You're going to see cold case experts from around the country creating these fake accounts
[01:39:12.640 --> 01:39:17.400]   and going in and trying to figure out how to narrow down their suspects.
[01:39:17.400 --> 01:39:18.400]   How does this differ?
[01:39:18.400 --> 01:39:20.280]   I was thinking about it.
[01:39:20.280 --> 01:39:22.480]   People are saying, "Oh, this violates people's rights.
[01:39:22.480 --> 01:39:23.800]   They've been exposed."
[01:39:23.800 --> 01:39:30.480]   How does this differ from saying looking for clues in a public space?
[01:39:30.480 --> 01:39:32.280]   You're looking at every human.
[01:39:32.280 --> 01:39:37.320]   Those people didn't ask to be looked at, but you're looking.
[01:39:37.320 --> 01:39:40.240]   There is an aspect of, "Hey, this is just good policing."
[01:39:40.240 --> 01:39:41.240]   Right?
[01:39:41.240 --> 01:39:43.400]   Yeah, they put it out there.
[01:39:43.400 --> 01:39:44.560]   Yeah, it's open.
[01:39:44.560 --> 01:39:46.280]   It was open sourced.
[01:39:46.280 --> 01:39:50.280]   People put it out there and then the police used that information.
[01:39:50.280 --> 01:39:56.120]   I don't really think that we really have that right to privacy once we've put something
[01:39:56.120 --> 01:40:00.880]   out there and maybe in the future we'll need to because the reach is going to be so far.
[01:40:00.880 --> 01:40:05.720]   Every little privacy will really exist anymore, but I don't really have an issue with it
[01:40:05.720 --> 01:40:06.720]   on that part.
[01:40:06.720 --> 01:40:07.720]   Yeah.
[01:40:07.720 --> 01:40:10.560]   There's probable cause here to go look at this person's history.
[01:40:10.560 --> 01:40:15.360]   There's probable cause to go through his trash and go to his DNA.
[01:40:15.360 --> 01:40:18.600]   I don't see anything here that's problematic at all.
[01:40:18.600 --> 01:40:19.920]   All right.
[01:40:19.920 --> 01:40:22.440]   Technology solving crime.
[01:40:22.440 --> 01:40:28.440]   We will not be discussing crime or really much more serious stuff when we come back.
[01:40:28.440 --> 01:40:32.120]   We're going to talk about snaps, spectacles.
[01:40:32.120 --> 01:40:34.200]   We're going to talk about the Nintendo Lobo.
[01:40:34.200 --> 01:40:37.840]   We're going to talk about technology that truly makes you happy.
[01:40:37.840 --> 01:40:39.760]   Stick around.
[01:40:39.760 --> 01:40:43.680]   If I may interrupt just briefly to talk about something I've been using for some time and
[01:40:43.680 --> 01:40:48.560]   I'm so excited that they're a sponsor, it's called AAP-TIV.
[01:40:48.560 --> 01:40:52.320]   AAP is an app.
[01:40:52.320 --> 01:40:58.400]   It's actually, if you look at my smartphone, it's right on the front.
[01:40:58.400 --> 01:41:03.120]   I page of my app, my phone right here cause I use it all the time.
[01:41:03.120 --> 01:41:04.120]   It's an app.
[01:41:04.120 --> 01:41:07.040]   It's an audio based trainer.
[01:41:07.040 --> 01:41:11.040]   Audio based workouts created by certified personal trainers in the mobile app and all
[01:41:11.040 --> 01:41:12.560]   kinds of categories.
[01:41:12.560 --> 01:41:15.800]   Outdoor running, treadmill, elliptical.
[01:41:15.800 --> 01:41:22.320]   If you do elliptical workouts, they're great for you, but you probably have the experience
[01:41:22.320 --> 01:41:24.720]   of boredom because it's the same.
[01:41:24.720 --> 01:41:32.320]   If you get Jessica Munster in your ear doing some hip hop music while you're on the elliptical,
[01:41:32.320 --> 01:41:39.200]   doing intervals, you're going to work out so much harder and so much better.
[01:41:39.200 --> 01:41:40.200]   I love Jessica by the way.
[01:41:40.200 --> 01:41:41.280]   She's one of my favorite trainers.
[01:41:41.280 --> 01:41:43.080]   You'll get favorites.
[01:41:43.080 --> 01:41:45.840]   There are 25, actually let me pause you.
[01:41:45.840 --> 01:41:47.400]   Sorry.
[01:41:47.400 --> 01:41:49.520]   She's in your ear.
[01:41:49.520 --> 01:41:54.800]   I actually went out and I got those great headphones that I've been talking about.
[01:41:54.800 --> 01:41:59.160]   A seal in the ear there for workouts from Jabra.
[01:41:59.160 --> 01:42:00.320]   Perfect for this.
[01:42:00.320 --> 01:42:01.320]   They work with AirPods.
[01:42:01.320 --> 01:42:02.560]   They work with wired headphones.
[01:42:02.560 --> 01:42:06.040]   Look at 30 minutes front, 30 minutes back.
[01:42:06.040 --> 01:42:07.840]   This is just elliptical.
[01:42:07.840 --> 01:42:10.120]   Jamie McFadden, Kelly Chase.
[01:42:10.120 --> 01:42:13.160]   There are 30 new classes every week.
[01:42:13.160 --> 01:42:16.600]   They have really excellent trainers.
[01:42:16.600 --> 01:42:19.920]   Recycling, rowing, stair climber.
[01:42:19.920 --> 01:42:24.600]   I love the workouts where you can filter them by duration.
[01:42:24.600 --> 01:42:27.920]   You can go from a little short one to a longer one.
[01:42:27.920 --> 01:42:32.120]   You choose the trainers that you like and you can just narrow them down.
[01:42:32.120 --> 01:42:33.920]   You can choose the genre of music.
[01:42:33.920 --> 01:42:36.120]   You like the music's great by the way.
[01:42:36.120 --> 01:42:38.040]   The music's great.
[01:42:38.040 --> 01:42:40.440]   Here's a full body strength training workout.
[01:42:40.440 --> 01:42:41.440]   13 minutes.
[01:42:41.440 --> 01:42:43.640]   A kem is on that one.
[01:42:43.640 --> 01:42:44.880]   Saved by the kettlebell.
[01:42:44.880 --> 01:42:47.400]   I love that.
[01:42:47.400 --> 01:42:48.400]   This is so cool.
[01:42:48.400 --> 01:42:51.320]   I have one that's a medicine ball workout that I use all the time.
[01:42:51.320 --> 01:42:53.120]   I love it.
[01:42:53.120 --> 01:42:54.120]   Strength training.
[01:42:54.120 --> 01:42:57.680]   You can do body weight stretching.
[01:42:57.680 --> 01:43:02.240]   How often do you stretch?
[01:43:02.240 --> 01:43:08.120]   This is nice because they walk you through the training, which is fantastic.
[01:43:08.120 --> 01:43:09.480]   Workouts for weight loss, ab workouts.
[01:43:09.480 --> 01:43:11.240]   I can go on and on.
[01:43:11.240 --> 01:43:13.000]   You can do a full program with them too.
[01:43:13.000 --> 01:43:16.000]   Run a mile with Jamie.
[01:43:16.000 --> 01:43:17.800]   Touch your toes in 20 days.
[01:43:17.800 --> 01:43:19.640]   I could use that one.
[01:43:19.640 --> 01:43:24.720]   Increase mobility and flexibility for all range of athletes.
[01:43:24.720 --> 01:43:26.640]   It's like having a personal trainer in your pocket.
[01:43:26.640 --> 01:43:31.880]   They even have yoga and meditation.
[01:43:31.880 --> 01:43:34.120]   A maternity program.
[01:43:34.120 --> 01:43:35.160]   This is so great.
[01:43:35.160 --> 01:43:37.400]   Find a workout you love every time.
[01:43:37.400 --> 01:43:40.080]   Never repeat if you don't want to, but if you've got a trainer you like you can do
[01:43:40.080 --> 01:43:45.600]   or have her on every day, it's got a great support of community of active members of
[01:43:45.600 --> 01:43:46.760]   all levels.
[01:43:46.760 --> 01:43:50.040]   They're reaching their fitness goals along with you.
[01:43:50.040 --> 01:43:51.920]   I love active.
[01:43:51.920 --> 01:43:55.280]   Subscriptions started $14.99 build monthly.
[01:43:55.280 --> 01:43:58.160]   I just went ahead and got the annual membership for $100.
[01:43:58.160 --> 01:44:02.520]   Less than two training sessions.
[01:44:02.520 --> 01:44:05.520]   By the way, these are the best trainers in the country.
[01:44:05.520 --> 01:44:06.520]   They're awesome.
[01:44:06.520 --> 01:44:07.520]   They're really fun.
[01:44:07.520 --> 01:44:10.520]   Oh, look at how they, okay, you want high intensity?
[01:44:10.520 --> 01:44:11.520]   You want technical?
[01:44:11.520 --> 01:44:13.560]   You know, working on form and stuff like that.
[01:44:13.560 --> 01:44:16.360]   Fun and supportive.
[01:44:16.360 --> 01:44:18.360]   I want the fun and supportive trainers.
[01:44:18.360 --> 01:44:21.760]   Maybe that's why I like Jen so much.
[01:44:21.760 --> 01:44:22.760]   And the community is great.
[01:44:22.760 --> 01:44:26.320]   It'll keep you working, keep you exercising.
[01:44:26.320 --> 01:44:29.120]   It is really, really fun.
[01:44:29.120 --> 01:44:34.520]   AAPtiv.com/twit.
[01:44:34.520 --> 01:44:38.560]   And you can even get some guest passes to share them with your friends too.
[01:44:38.560 --> 01:44:40.720]   AAPtiv or family.
[01:44:40.720 --> 01:44:45.160]   Maybe you've got family members who you think maybe you ought to be doing a little bit of
[01:44:45.160 --> 01:44:46.320]   AAPtiv.
[01:44:46.320 --> 01:44:47.320]   What's my fitness goal?
[01:44:47.320 --> 01:44:48.320]   Get healthy?
[01:44:48.320 --> 01:44:49.320]   Yeah.
[01:44:49.320 --> 01:44:53.760]   I'm a pretty regular exerciser.
[01:44:53.760 --> 01:44:57.440]   I want to do these, by the way, look where you can choose at the gym at home or outside.
[01:44:57.440 --> 01:44:59.240]   Take this to the gym.
[01:44:59.240 --> 01:45:01.080]   You don't need to pay a trainer to work at the gym.
[01:45:01.080 --> 01:45:02.840]   You can take these to the gym.
[01:45:02.840 --> 01:45:07.000]   AAPtiv.com/twit.
[01:45:07.000 --> 01:45:08.840]   We're going to tell you what, I want you to do this.
[01:45:08.840 --> 01:45:10.440]   This is so good for you.
[01:45:10.440 --> 01:45:12.240]   And I like it so much.
[01:45:12.240 --> 01:45:13.920]   We got a deal for you.
[01:45:13.920 --> 01:45:16.040]   As I said, a hundred bucks for an annual membership.
[01:45:16.040 --> 01:45:18.560]   We'll give you 30% off right now.
[01:45:18.560 --> 01:45:22.200]   How about 70 bucks for a whole year of unlimited workouts?
[01:45:22.200 --> 01:45:24.240]   That's like an hour of training time.
[01:45:24.240 --> 01:45:26.400]   But you get it all year long.
[01:45:26.400 --> 01:45:30.040]   AAPtiv.com/twit.
[01:45:30.040 --> 01:45:35.000]   For 30% off new annual memberships, I am so high on this.
[01:45:35.000 --> 01:45:36.000]   I'm really glad.
[01:45:36.000 --> 01:45:38.880]   We actually, I've been using this.
[01:45:38.880 --> 01:45:40.400]   I talked about it on iOS today.
[01:45:40.400 --> 01:45:41.400]   And I got Megan.
[01:45:41.400 --> 01:45:42.400]   I got Megan doing it.
[01:45:42.400 --> 01:45:44.040]   She's doing it too.
[01:45:44.040 --> 01:45:46.840]   And then they said, hey, maybe we should do advertisements.
[01:45:46.840 --> 01:45:47.840]   AAPtiv.
[01:45:47.840 --> 01:45:49.320]   Yes, you should.
[01:45:49.320 --> 01:45:53.880]   AAPtiv.com/twit for 30% off right now.
[01:45:53.880 --> 01:45:59.960]   Now we go back to the sedentary lifestyle of this week in tech.
[01:45:59.960 --> 01:46:03.960]   Sorry, guys.
[01:46:03.960 --> 01:46:04.960]   Sedentary?
[01:46:04.960 --> 01:46:05.960]   What?
[01:46:05.960 --> 01:46:07.760]   I think we've been working it.
[01:46:07.760 --> 01:46:08.760]   We've been working it.
[01:46:08.760 --> 01:46:09.760]   I work out.
[01:46:09.760 --> 01:46:10.760]   I've been working it.
[01:46:10.760 --> 01:46:13.120]   I'm going to turn this into an exercise video in about two shakes.
[01:46:13.120 --> 01:46:14.640]   So just do weight.
[01:46:14.640 --> 01:46:20.680]   But first, Leo has been on vacation and doesn't realize what an active week it has been on
[01:46:20.680 --> 01:46:21.880]   the twit.
[01:46:21.880 --> 01:46:24.120]   So take a look at this last week in tech.
[01:46:24.120 --> 01:46:25.120]   Sleevesly on twit.
[01:46:25.120 --> 01:46:28.960]   When we were kind of getting set up to start the show, I went to sit down on this chair
[01:46:28.960 --> 01:46:30.960]   and I almost sat on a turtle.
[01:46:30.960 --> 01:46:33.280]   And normally that's not weird.
[01:46:33.280 --> 01:46:39.920]   This is a turtle that if you ask Google's Inception V3 network, it will say with really
[01:46:39.920 --> 01:46:42.880]   high confidence that this is actually a rifle.
[01:46:42.880 --> 01:46:44.080]   Security now.
[01:46:44.080 --> 01:46:47.960]   The Microsoft Research Group are able to do good things.
[01:46:47.960 --> 01:46:58.480]   What they have done with Azure Sphere is design a complete front-to-back, soup-to-nuts,
[01:46:58.480 --> 01:47:05.360]   open free ecosystem for securing IoT devices.
[01:47:05.360 --> 01:47:07.280]   The new screen savers.
[01:47:07.280 --> 01:47:10.320]   Everyone is doing it except for Apple.
[01:47:10.320 --> 01:47:15.480]   We're going to touch base with an MIT student who has figured out how to turn a MacBook
[01:47:15.480 --> 01:47:20.520]   Pro into a touchscreen Mac with a little device that costs a dollar.
[01:47:20.520 --> 01:47:24.560]   So Apple, next MacBook comes out with a touchscreen is life over.
[01:47:24.560 --> 01:47:25.560]   What's the deal?
[01:47:25.560 --> 01:47:27.560]   Well, I just think I'm out of the dollar.
[01:47:27.560 --> 01:47:28.560]   Oh no.
[01:47:28.560 --> 01:47:29.560]   Twit.
[01:47:29.560 --> 01:47:30.560]   Bring your brain.
[01:47:30.560 --> 01:47:32.560]   We'll do the rest.
[01:47:32.560 --> 01:47:39.640]   All I know is that if Mary Jo could play Call of Duty in 4K and HDR, then she would
[01:47:39.640 --> 01:47:40.640]   become a gamer.
[01:47:40.640 --> 01:47:41.640]   My life would be changed.
[01:47:41.640 --> 01:47:51.720]   I do feel like Mary Jo could answer the Call of Duty.
[01:47:51.720 --> 01:47:54.080]   We are answering the Call of Duty right here.
[01:47:54.080 --> 01:47:55.480]   This is this week in tech.
[01:47:55.480 --> 01:47:56.480]   I'm back here early.
[01:47:56.480 --> 01:48:00.480]   I am mastering the segue here.
[01:48:00.480 --> 01:48:05.240]   We've hit so many serious topics all show long that we really need to just lighten this
[01:48:05.240 --> 01:48:09.360]   situation up right now and slag off on some company.
[01:48:09.360 --> 01:48:11.640]   So I've chosen Snapchat.
[01:48:11.640 --> 01:48:19.600]   They released their next generation of spectacles this last week, wearable camera in the fabulous
[01:48:19.600 --> 01:48:20.600]   goggles.
[01:48:20.600 --> 01:48:24.840]   They cost $150, $20 more than the previous model.
[01:48:24.840 --> 01:48:27.280]   And I think they are so incredibly stupid.
[01:48:27.280 --> 01:48:29.480]   So please talk me out of that.
[01:48:29.480 --> 01:48:30.480]   Believe.
[01:48:30.480 --> 01:48:31.480]   No, you're wrong.
[01:48:31.480 --> 01:48:32.480]   You're dead on your right.
[01:48:32.480 --> 01:48:33.480]   With you.
[01:48:33.480 --> 01:48:34.480]   I've never doubt yourself.
[01:48:34.480 --> 01:48:35.480]   Obens.
[01:48:35.480 --> 01:48:37.480]   You've got them.
[01:48:37.480 --> 01:48:42.120]   Oh no, Ben is wearing these spectacles right now and it's in idyllic.
[01:48:42.120 --> 01:48:43.120]   Kawaii.
[01:48:43.120 --> 01:48:44.120]   Selfie pose.
[01:48:44.120 --> 01:48:45.120]   Cute.
[01:48:45.120 --> 01:48:46.120]   There's a big Becky.
[01:48:46.120 --> 01:48:48.120]   When did you guys run?
[01:48:48.120 --> 01:48:51.360]   If you saw someone with these spectals coming up to you, wouldn't you run away?
[01:48:51.360 --> 01:48:54.160]   A grown man like Ben possibly has.
[01:48:54.160 --> 01:48:55.160]   Oh my God.
[01:48:55.160 --> 01:48:56.160]   Hey, come on.
[01:48:56.160 --> 01:49:00.720]   It's like you're an eight year old from the 1980s wearing those.
[01:49:00.720 --> 01:49:02.880]   Like, oh my God.
[01:49:02.880 --> 01:49:05.160]   Give me the play devil's advocate here, Ben.
[01:49:05.160 --> 01:49:06.160]   Come on.
[01:49:06.160 --> 01:49:07.160]   Lay it out there.
[01:49:07.160 --> 01:49:10.800]   I haven't taken them out of the closet in months, I will admit.
[01:49:10.800 --> 01:49:14.400]   But mostly because they're really hard to charge and they didn't connect very well to
[01:49:14.400 --> 01:49:15.720]   my phone.
[01:49:15.720 --> 01:49:18.480]   So like, I actually, I got them for reporting.
[01:49:18.480 --> 01:49:23.200]   I just went out and bought them to report on it when it, when they, the first set of
[01:49:23.200 --> 01:49:25.520]   spectacles came out.
[01:49:25.520 --> 01:49:31.760]   And I have to say like, you know, the technology, it just didn't work that well.
[01:49:31.760 --> 01:49:35.200]   I mean, they didn't connect with my phone very well.
[01:49:35.200 --> 01:49:41.120]   The connectivity was bad and, but the videos I loved, like it, they were truly, it was
[01:49:41.120 --> 01:49:42.120]   really nice.
[01:49:42.120 --> 01:49:46.920]   I wore them skiing once and that was really fun.
[01:49:46.920 --> 01:49:50.680]   I admit that they're, you know, they have that Google Glass thing going on where they
[01:49:50.680 --> 01:49:55.200]   have like the creep, the potential creep factor happening.
[01:49:55.200 --> 01:50:00.600]   They are very clear about sort of showing when they're recording and you have to hit
[01:50:00.600 --> 01:50:02.960]   the button obviously.
[01:50:02.960 --> 01:50:04.200]   But I don't know.
[01:50:04.200 --> 01:50:06.480]   I mean, I just, I think it was kind of a flop.
[01:50:06.480 --> 01:50:10.760]   So I'm surprised that they're putting out another version.
[01:50:10.760 --> 01:50:13.960]   And these were expensive as heck.
[01:50:13.960 --> 01:50:19.600]   So I don't understand how they're going to like, you know, reach a better crowd with
[01:50:19.600 --> 01:50:21.080]   a more expensive hair.
[01:50:21.080 --> 01:50:22.080]   That seems crazy.
[01:50:22.080 --> 01:50:23.320]   It was a flop.
[01:50:23.320 --> 01:50:29.200]   They sold about 150,000 pairs, but they took a $40 million right down on the whole thing
[01:50:29.200 --> 01:50:32.360]   because there were that many more that they didn't sell.
[01:50:32.360 --> 01:50:33.360]   So I don't get it.
[01:50:33.360 --> 01:50:37.320]   I mean, I actually like the GoPro use case that you just set up.
[01:50:37.320 --> 01:50:39.640]   But Brianna, did you see any use for this?
[01:50:39.640 --> 01:50:44.760]   So you know, I knew something was really wrong with Snapchat spectacles when I ordered a pair
[01:50:44.760 --> 01:50:48.960]   and I wrote them back and I got, yeah, you gave me the wrong color.
[01:50:48.960 --> 01:50:51.640]   And then they just mailed me two extra versions of it.
[01:50:51.640 --> 01:50:53.400]   Here you go.
[01:50:53.400 --> 01:50:55.840]   Take it off her hands.
[01:50:55.840 --> 01:50:56.840]   It's fine.
[01:50:56.840 --> 01:51:02.840]   One of the things I agree with you, the video function of it wasn't that great.
[01:51:02.840 --> 01:51:07.960]   But what's amazing to me is this generation two that they're putting out.
[01:51:07.960 --> 01:51:11.280]   They don't fix any of the fundamental problems with the product.
[01:51:11.280 --> 01:51:14.040]   I don't see anything there about connectivity.
[01:51:14.040 --> 01:51:16.880]   I don't see a serious plan to up the image quality.
[01:51:16.880 --> 01:51:21.560]   I don't see a serious plan to up the amount that you're recording.
[01:51:21.560 --> 01:51:27.520]   And the biggest thing, I'm like, okay, for Gen 1, it can look like you got it at Wendy's
[01:51:27.520 --> 01:51:28.960]   in the 1980s.
[01:51:28.960 --> 01:51:29.960]   That's fine.
[01:51:29.960 --> 01:51:34.120]   But Gen 2, they'll come back and they'll bring some good styles or at least some alternate
[01:51:34.120 --> 01:51:35.120]   styles.
[01:51:35.120 --> 01:51:38.000]   And no, we're just going to make it thinner.
[01:51:38.000 --> 01:51:43.040]   And what a way to not learn anything from losing $50 million.
[01:51:43.040 --> 01:51:44.040]   That is impressive.
[01:51:44.040 --> 01:51:46.760]   Isn't this like these?
[01:51:46.760 --> 01:51:52.040]   These glasses to me are symbolic of everything that's wrong with our society.
[01:51:52.040 --> 01:51:53.720]   They're creepy.
[01:51:53.720 --> 01:51:55.560]   They don't work well.
[01:51:55.560 --> 01:51:58.480]   I would really, someone was wearing those and I went to a part.
[01:51:58.480 --> 01:52:01.440]   I think that it's a cute idea to be able to go skiing.
[01:52:01.440 --> 01:52:02.440]   To go skiing.
[01:52:02.440 --> 01:52:05.000]   I'll just wear them.
[01:52:05.000 --> 01:52:06.840]   I'll keep wearing them for you guys.
[01:52:06.840 --> 01:52:07.840]   Right.
[01:52:07.840 --> 01:52:08.840]   I like it.
[01:52:08.840 --> 01:52:11.320]   You can talk about how they suck and I'll keep wearing them.
[01:52:11.320 --> 01:52:15.520]   The funniest thing is I'm talking about it being creepy as I'm doing this podcast.
[01:52:15.520 --> 01:52:18.280]   I can't rap, but I've chosen to.
[01:52:18.280 --> 01:52:20.600]   I put makeup on and straightened my hair.
[01:52:20.600 --> 01:52:24.640]   It's different if I'm just chilling out at the park and someone comes up with these glasses
[01:52:24.640 --> 01:52:30.680]   or for my children is walking down the road and someone's wearing these glasses.
[01:52:30.680 --> 01:52:32.560]   This would be really irk me.
[01:52:32.560 --> 01:52:33.560]   I would be irked.
[01:52:33.560 --> 01:52:36.320]   Have you ever seen them in the wild though?
[01:52:36.320 --> 01:52:37.320]   I have never.
[01:52:37.320 --> 01:52:39.040]   That is a good point, Becky.
[01:52:39.040 --> 01:52:40.040]   Nope.
[01:52:40.040 --> 01:52:41.040]   Never.
[01:52:41.040 --> 01:52:42.040]   At least Google Glass.
[01:52:42.040 --> 01:52:44.280]   I saw it like South by Southwest every once in a while.
[01:52:44.280 --> 01:52:47.760]   I did, but that's because we hang out in text circles.
[01:52:47.760 --> 01:52:49.760]   These aren't even cool to text.
[01:52:49.760 --> 01:52:53.320]   I even know 14-year-old girls and I haven't seen them.
[01:52:53.320 --> 01:52:54.520]   I mean, I coach soccer.
[01:52:54.520 --> 01:52:56.000]   I've never seen them there.
[01:52:56.000 --> 01:52:58.800]   It's just not happening.
[01:52:58.800 --> 01:53:03.000]   Maybe the one thing that they got wrong is that they're made for the narcissism generation,
[01:53:03.000 --> 01:53:05.120]   but you can't take a picture of yourself.
[01:53:05.120 --> 01:53:06.720]   Maybe that's why they flop so badly.
[01:53:06.720 --> 01:53:09.800]   They had a mirror that projected back.
[01:53:09.800 --> 01:53:11.760]   These would probably be huge hits.
[01:53:11.760 --> 01:53:12.760]   You've solved their problem.
[01:53:12.760 --> 01:53:14.240]   I hope they send you a big check.
[01:53:14.240 --> 01:53:15.240]   Right?
[01:53:15.240 --> 01:53:16.240]   I nailed it.
[01:53:16.240 --> 01:53:17.240]   Yeah.
[01:53:17.240 --> 01:53:18.240]   Yeah.
[01:53:18.240 --> 01:53:19.240]   I do.
[01:53:19.240 --> 01:53:20.240]   More hardware news.
[01:53:20.240 --> 01:53:21.240]   There you go.
[01:53:21.240 --> 01:53:22.240]   Backwards, Ben.
[01:53:22.240 --> 01:53:23.240]   That's genius.
[01:53:23.240 --> 01:53:24.240]   That's genius.
[01:53:24.240 --> 01:53:25.160]   You need to stick them on your hat with duct tape.
[01:53:25.160 --> 01:53:26.160]   More hardware news here.
[01:53:26.160 --> 01:53:27.160]   Apple, reportedly.
[01:53:27.160 --> 01:53:28.160]   This is all rumors.
[01:53:28.160 --> 01:53:33.800]   Working on a wireless headset for both AR and VR.
[01:53:33.800 --> 01:53:36.760]   Do we think that this is going to be the revolutionary?
[01:53:36.760 --> 01:53:40.320]   Apple jumps into the game and now it's really going to happen?
[01:53:40.320 --> 01:53:45.480]   Or is this one of those Apple late to the party and nobody's going to really care except
[01:53:45.480 --> 01:53:48.960]   for when they come out and then they'll fade away?
[01:53:48.960 --> 01:53:52.560]   No offense to Georgia, but if the HomePod is any indication.
[01:53:52.560 --> 01:53:56.480]   Oh my goodness.
[01:53:56.480 --> 01:54:01.360]   This is one of my expertise in the game industry is graphical subsystems.
[01:54:01.360 --> 01:54:08.000]   Something it doesn't get talked about enough is Apple's very weak APIs with 3D tech knowledge.
[01:54:08.000 --> 01:54:10.520]   They've been showing those up lately.
[01:54:10.520 --> 01:54:16.920]   I saw the story come out and I can kind of see where they're going with it.
[01:54:16.920 --> 01:54:22.680]   I agree with Adi Robertson's view on the verge that she expressed with this that if this
[01:54:22.680 --> 01:54:26.800]   is what Apple's putting out, it's not really ambitious enough.
[01:54:26.800 --> 01:54:33.520]   VR passed through with AR basically having a camera on the outside to take a picture of
[01:54:33.520 --> 01:54:36.720]   what's outside and putting it in front of you.
[01:54:36.720 --> 01:54:39.280]   She's like a lag no matter what you do.
[01:54:39.280 --> 01:54:40.280]   It's low res.
[01:54:40.280 --> 01:54:41.280]   It's weird.
[01:54:41.280 --> 01:54:42.280]   It's bad.
[01:54:42.280 --> 01:54:44.280]   It's terrible.
[01:54:44.280 --> 01:54:49.520]   I think from the product they're describing it's not going to work for two reasons.
[01:54:49.520 --> 01:54:55.520]   It's not ambitious enough and they don't have the developer ecosystem to really put out 3D
[01:54:55.520 --> 01:54:56.520]   stuff.
[01:54:56.520 --> 01:55:00.560]   If they're holding off and it is smaller and thinner and lighter and doesn't look like
[01:55:00.560 --> 01:55:04.360]   Snapchat spectacles, I could see it working.
[01:55:04.360 --> 01:55:09.600]   But I think it's always, I think you're generally unwise to count out Apple.
[01:55:09.600 --> 01:55:15.360]   We are going to have a little bit of a technology roundtable here as we talk about, this is the
[01:55:15.360 --> 01:55:18.160]   plan is technology that makes you happy.
[01:55:18.160 --> 01:55:19.960]   That's the next little subject.
[01:55:19.960 --> 01:55:23.160]   But before we do, John just brought me a pair of the Snapchat spectacles.
[01:55:23.160 --> 01:55:24.160]   Oh no.
[01:55:24.160 --> 01:55:28.880]   So what I think we should do, Ben, is I'll take a picture of you if you'll take a picture
[01:55:28.880 --> 01:55:36.120]   of me and then we will fully complete this channel of Snapchat narcissism right here.
[01:55:36.120 --> 01:55:37.560]   Then we'll disappear in the later.
[01:55:37.560 --> 01:55:38.560]   Okay, good.
[01:55:38.560 --> 01:55:39.560]   We got this.
[01:55:39.560 --> 01:55:40.560]   Done.
[01:55:40.560 --> 01:55:41.560]   But I can't see.
[01:55:41.560 --> 01:55:42.560]   I can't.
[01:55:42.560 --> 01:55:43.560]   This is the problem.
[01:55:43.560 --> 01:55:44.720]   It's not, they're not charged because I haven't.
[01:55:44.720 --> 01:55:45.720]   See?
[01:55:45.720 --> 01:55:47.280]   I haven't touched them in months.
[01:55:47.280 --> 01:55:48.280]   Yeah.
[01:55:48.280 --> 01:55:49.280]   That's the thing.
[01:55:49.280 --> 01:55:50.280]   Dead tech.
[01:55:50.280 --> 01:55:55.240]   So Georgia, I'm going to start with you since you are a therapist and I have been telling
[01:55:55.240 --> 01:55:59.880]   people lately as we talk about Facebook and Facebook fatigue and social media fatigue
[01:55:59.880 --> 01:56:05.120]   and all the other things that we're asking ourselves about, are we using our phones too
[01:56:05.120 --> 01:56:06.200]   much?
[01:56:06.200 --> 01:56:08.320]   Does gaming make you happy?
[01:56:08.320 --> 01:56:14.720]   I asked people to hold a device, not unlike, do you remember that book about the magic
[01:56:14.720 --> 01:56:16.560]   of tidying up the Japanese book?
[01:56:16.560 --> 01:56:17.560]   Yes.
[01:56:17.560 --> 01:56:18.560]   Yes.
[01:56:18.560 --> 01:56:19.560]   The magic of tidying.
[01:56:19.560 --> 01:56:20.560]   She says, yes.
[01:56:20.560 --> 01:56:24.000]   She says, hold the object that you're thinking about getting rid of.
[01:56:24.000 --> 01:56:26.120]   It doesn't bring you joy.
[01:56:26.120 --> 01:56:29.360]   And so I now ask people, if they say, you know, do you think I should quit Facebook?
[01:56:29.360 --> 01:56:34.080]   I say, use Facebook for a few minutes, do what you would normally do and then hold your
[01:56:34.080 --> 01:56:38.120]   phone and ask yourself, did that just bring me joy?
[01:56:38.120 --> 01:56:42.680]   Or does it just make me mad or did it make me feel compulsive or whatever?
[01:56:42.680 --> 01:56:48.240]   So is there, what is your advice to people about technology and happiness and determining
[01:56:48.240 --> 01:56:51.680]   what makes you happy and what you're being reactive to?
[01:56:51.680 --> 01:56:54.600]   Yeah, I think that less is usually more.
[01:56:54.600 --> 01:56:57.600]   And I always say, you know, think of yourself at 80.
[01:56:57.600 --> 01:57:01.680]   Are you going to look back on your life and say, I wish I spent more time on Facebook,
[01:57:01.680 --> 01:57:06.840]   or I wish I spent more time on social media, or would it be doing something with your family?
[01:57:06.840 --> 01:57:12.440]   Now that being said, there are some tech devices that I can look back on and say, yeah,
[01:57:12.440 --> 01:57:14.040]   this brings me joy.
[01:57:14.040 --> 01:57:15.040]   Okay.
[01:57:15.040 --> 01:57:16.040]   Examples.
[01:57:16.040 --> 01:57:22.840]   Okay, so I have two and they are really truly and literally the opposite ends of the spectrum.
[01:57:22.840 --> 01:57:28.080]   So one, and I'll go with Brie on this one is my VR headset.
[01:57:28.080 --> 01:57:30.160]   I love the HTC Vive and Oculus.
[01:57:30.160 --> 01:57:31.960]   I love it playing Skyrim.
[01:57:31.960 --> 01:57:32.960]   It's amazing.
[01:57:32.960 --> 01:57:35.120]   And we have it hooked up to the ceiling for the wires.
[01:57:35.120 --> 01:57:36.360]   I'll talk to you about it later, Brie.
[01:57:36.360 --> 01:57:37.360]   It's amazing.
[01:57:37.360 --> 01:57:38.360]   And so I love that.
[01:57:38.360 --> 01:57:40.320]   And it's fun and exciting.
[01:57:40.320 --> 01:57:46.120]   And then the other one is my heated seated toilet seat.
[01:57:46.120 --> 01:57:47.480]   I know.
[01:57:47.480 --> 01:57:48.480]   I know.
[01:57:48.480 --> 01:57:52.200]   But really, toilets haven't changed in 120 years.
[01:57:52.200 --> 01:57:58.120]   And having a heated toilet seat, and it has a day option, it has an air dryer, a deodorizer.
[01:57:58.120 --> 01:57:59.640]   Oh, you have the total.
[01:57:59.640 --> 01:58:00.640]   Oh, I have the total.
[01:58:00.640 --> 01:58:02.640]   Oh, oh, I went.
[01:58:02.640 --> 01:58:04.080]   Oh, yeah.
[01:58:04.080 --> 01:58:09.800]   It has a control so you can actually have your own personal settings as you want.
[01:58:09.800 --> 01:58:11.560]   All kinds of amazing features.
[01:58:11.560 --> 01:58:14.240]   It just doesn't flush, which I would be sad if it flushed.
[01:58:14.240 --> 01:58:16.520]   It would be completely done for me.
[01:58:16.520 --> 01:58:17.920]   But it's amazing.
[01:58:17.920 --> 01:58:19.160]   And I would never live without it.
[01:58:19.160 --> 01:58:24.000]   I almost like I go to somewhere else or someone else's house and I sit on the cold seat and
[01:58:24.000 --> 01:58:26.840]   then I'm shocked and I slam the toilet seat down.
[01:58:26.840 --> 01:58:29.640]   And I like I'm like, where's the enough toilet paper?
[01:58:29.640 --> 01:58:31.520]   And this is, and it's sadness.
[01:58:31.520 --> 01:58:33.000]   So this is a perk at Google.
[01:58:33.000 --> 01:58:36.760]   They have the warm seats on the toilets at Google in the office.
[01:58:36.760 --> 01:58:38.560]   Why don't you use that?
[01:58:38.560 --> 01:58:39.560]   You can't go back.
[01:58:39.560 --> 01:58:40.560]   Sorry, a warm tushie.
[01:58:40.560 --> 01:58:41.560]   I live in Canada.
[01:58:41.560 --> 01:58:43.040]   It's freezing cold here.
[01:58:43.040 --> 01:58:46.880]   You get up in the middle of the night and to have a little light that lights your way
[01:58:46.880 --> 01:58:50.360]   so that you're not going to miss, it also lets you not fall into the toilet seat for
[01:58:50.360 --> 01:58:51.360]   women.
[01:58:51.360 --> 01:58:52.360]   Right?
[01:58:52.360 --> 01:58:53.360]   It's a chance it could happen.
[01:58:53.360 --> 01:58:57.760]   So you don't fall into the toilet seat because you know and then it just takes care of everything.
[01:58:57.760 --> 01:58:58.760]   Air dry.
[01:58:58.760 --> 01:59:00.520]   You're just good to go after.
[01:59:00.520 --> 01:59:02.440]   Virtual reality and warm tushie tech.
[01:59:02.440 --> 01:59:03.440]   I got it.
[01:59:03.440 --> 01:59:04.440]   Okay.
[01:59:04.440 --> 01:59:05.440]   All right.
[01:59:05.440 --> 01:59:09.200]   Brianna, what do you think is on your list of tech that makes you truly happy?
[01:59:09.200 --> 01:59:10.200]   I can't.
[01:59:10.200 --> 01:59:14.240]   I'm going to wrap Georgia out before I answer this and say she loves VR so much.
[01:59:14.240 --> 01:59:19.720]   She actually bought a new house to have more VR, to have more room for VR.
[01:59:19.720 --> 01:59:22.120]   It's like cut to Georgia.
[01:59:22.120 --> 01:59:23.360]   She's completely guilty.
[01:59:23.360 --> 01:59:26.120]   See that look on her face?
[01:59:26.120 --> 01:59:27.920]   That's the look of the guilty woman.
[01:59:27.920 --> 01:59:28.920]   So, yes.
[01:59:28.920 --> 01:59:32.320]   Technology brings me joy.
[01:59:32.320 --> 01:59:33.560]   We're going to talk about it later.
[01:59:33.560 --> 01:59:36.600]   I love Nintendo Lappo.
[01:59:36.600 --> 01:59:39.440]   It is joy in a box.
[01:59:39.440 --> 01:59:41.080]   It is fun to put together.
[01:59:41.080 --> 01:59:43.000]   I'm going to hold this up right here.
[01:59:43.000 --> 01:59:45.040]   Can you give us the big picture?
[01:59:45.040 --> 01:59:47.480]   What is this and why is it different?
[01:59:47.480 --> 01:59:49.640]   So this is Nintendo Lappo.
[01:59:49.640 --> 01:59:55.680]   Basically, what they did is they got a bunch of engineers to make toys that you could build
[01:59:55.680 --> 01:59:57.600]   out of cardboard.
[01:59:57.600 --> 02:00:03.080]   So the variety pack is $60, $70, $80 or something like that.
[02:00:03.080 --> 02:00:05.800]   And it comes with a bunch of different toys that you can build.
[02:00:05.800 --> 02:00:06.800]   You can build a bunch of things.
[02:00:06.800 --> 02:00:07.800]   You can build a bunch of things.
[02:00:07.800 --> 02:00:08.800]   You can build a bunch of things.
[02:00:08.800 --> 02:00:09.800]   You can build a bunch of things.
[02:00:09.800 --> 02:00:10.800]   You can build a bunch of things.
[02:00:10.800 --> 02:00:11.800]   You can build a bunch of things.
[02:00:11.800 --> 02:00:12.800]   You can build a bunch of things.
[02:00:12.800 --> 02:00:13.800]   You can build a bunch of things.
[02:00:13.800 --> 02:00:14.800]   You can build a bunch of things.
[02:00:14.800 --> 02:00:15.800]   You can build a bunch of things.
[02:00:15.800 --> 02:00:16.800]   You can build a bunch of things.
[02:00:16.800 --> 02:00:17.800]   You can build a bunch of things.
[02:00:17.800 --> 02:00:18.800]   You can build a bunch of things.
[02:00:18.800 --> 02:00:19.800]   You can build a bunch of things.
[02:00:19.800 --> 02:00:20.800]   You can build a bunch of things.
[02:00:20.800 --> 02:00:21.800]   You can build a bunch of things.
[02:00:21.800 --> 02:00:22.800]   You can build a bunch of things.
[02:00:22.800 --> 02:00:23.800]   You can build a bunch of things.
[02:00:23.800 --> 02:00:24.800]   You can build a bunch of things.
[02:00:24.800 --> 02:00:25.800]   You can build a bunch of things.
[02:00:25.800 --> 02:00:26.800]   You can build a bunch of things.
[02:00:26.800 --> 02:00:27.800]   You can build a bunch of things.
[02:00:27.800 --> 02:00:28.800]   You can build a bunch of things.
[02:00:28.800 --> 02:00:29.800]   You can build a bunch of things.
[02:00:29.800 --> 02:00:30.800]   You can build a bunch of things.
[02:00:30.800 --> 02:00:31.800]   You can build a bunch of things.
[02:00:31.800 --> 02:00:32.800]   You can build a bunch of things.
[02:00:32.800 --> 02:00:33.800]   You can build a bunch of things.
[02:00:33.800 --> 02:00:34.800]   You can build a bunch of things.
[02:00:34.800 --> 02:00:35.800]   You can build a bunch of things.
[02:00:35.800 --> 02:00:36.800]   You can build a bunch of things.
[02:00:36.800 --> 02:00:37.800]   You can build a bunch of things.
[02:00:37.800 --> 02:00:38.800]   You can build a bunch of things.
[02:00:38.800 --> 02:00:39.800]   You can build a bunch of things.
[02:00:39.800 --> 02:00:40.800]   You can build a bunch of things.
[02:00:40.800 --> 02:00:41.800]   You can build a bunch of things.
[02:00:41.800 --> 02:00:42.800]   You can build a bunch of things.
[02:00:42.800 --> 02:00:43.800]   You can build a bunch of things.
[02:00:43.800 --> 02:00:44.800]   You can build a bunch of things.
[02:00:44.800 --> 02:00:45.800]   You can build a bunch of things.
[02:00:45.800 --> 02:00:46.800]   You can build a bunch of things.
[02:00:46.800 --> 02:00:47.800]   You can build a bunch of things.
[02:00:47.800 --> 02:00:48.800]   You can build a bunch of things.
[02:00:48.800 --> 02:00:49.800]   You can build a bunch of things.
[02:00:49.800 --> 02:00:50.800]   You can build a bunch of things.
[02:00:50.800 --> 02:00:51.800]   You can build a bunch of things.
[02:00:51.800 --> 02:00:52.800]   You can build a bunch of things.
[02:00:52.800 --> 02:00:53.800]   You can build a bunch of things.
[02:00:53.800 --> 02:00:54.800]   You can build a bunch of things.
[02:00:54.800 --> 02:00:55.800]   You can build a bunch of things.
[02:00:55.800 --> 02:00:56.800]   You can build a bunch of things.
[02:00:56.800 --> 02:00:57.800]   You can build a bunch of things.
[02:00:57.800 --> 02:00:58.800]   You can build a bunch of things.
[02:00:58.800 --> 02:00:59.800]   You can build a bunch of things.
[02:00:59.800 --> 02:01:00.800]   You can build a bunch of things.
[02:01:00.800 --> 02:01:01.800]   You can build a bunch of things.
[02:01:01.800 --> 02:01:02.800]   You can build a bunch of things.
[02:01:02.800 --> 02:01:03.800]   You can build a bunch of things.
[02:01:03.800 --> 02:01:04.800]   You can build a bunch of things.
[02:01:04.800 --> 02:01:05.800]   You can build a bunch of things.
[02:01:05.800 --> 02:01:06.800]   You can build a bunch of things.
[02:01:06.800 --> 02:01:07.800]   You can build a bunch of things.
[02:01:07.800 --> 02:01:08.800]   You can build a bunch of things.
[02:01:08.800 --> 02:01:09.800]   You can build a bunch of things.
[02:01:09.800 --> 02:01:10.800]   You can build a bunch of things.
[02:01:10.800 --> 02:01:11.800]   You can build a bunch of things.
[02:01:11.800 --> 02:01:13.800]   You can build a bunch of things.
[02:01:13.800 --> 02:01:14.800]   You can build a bunch of things.
[02:01:14.800 --> 02:01:15.800]   You can build a bunch of things.
[02:01:15.800 --> 02:01:16.800]   You can build a bunch of things.
[02:01:16.800 --> 02:01:17.800]   You can build a bunch of things.
[02:01:17.800 --> 02:01:18.800]   You can build a bunch of things.
[02:01:18.800 --> 02:01:19.800]   You can build a bunch of things.
[02:01:19.800 --> 02:01:20.800]   You can build a bunch of things.
[02:01:20.800 --> 02:01:21.800]   You can build a bunch of things.
[02:01:21.800 --> 02:01:22.800]   You can build a bunch of things.
[02:01:22.800 --> 02:01:23.800]   You can build a bunch of things.
[02:01:23.800 --> 02:01:24.800]   You can build a bunch of things.
[02:01:24.800 --> 02:01:25.800]   You can build a bunch of things.
[02:01:25.800 --> 02:01:26.800]   You can build a bunch of things.
[02:01:26.800 --> 02:01:27.800]   You can build a bunch of things.
[02:01:27.800 --> 02:01:28.800]   You can build a bunch of things.
[02:01:28.800 --> 02:01:29.800]   You can build a bunch of things.
[02:01:29.800 --> 02:01:30.800]   You can build a bunch of things.
[02:01:30.800 --> 02:01:31.800]   You can build a bunch of things.
[02:01:31.800 --> 02:01:32.800]   You can build a bunch of things.
[02:01:32.800 --> 02:01:33.800]   You can build a bunch of things.
[02:01:33.800 --> 02:01:34.800]   You can build a bunch of things.
[02:01:34.800 --> 02:01:35.800]   You can build a bunch of things.
[02:01:35.800 --> 02:01:36.800]   You can build a bunch of things.
[02:01:36.800 --> 02:01:37.800]   You can build a bunch of things.
[02:01:37.800 --> 02:01:38.800]   You can build a bunch of things.
[02:01:38.800 --> 02:01:39.800]   You can build a bunch of things.
[02:01:39.800 --> 02:01:40.800]   You can build a bunch of things.
[02:01:40.800 --> 02:01:41.800]   You can build a bunch of things.
[02:01:41.800 --> 02:01:42.800]   You can build a bunch of things.
[02:01:42.800 --> 02:01:43.800]   You can build a bunch of things.
[02:01:43.800 --> 02:01:44.800]   You can build a bunch of things.
[02:01:44.800 --> 02:01:45.800]   You can build a bunch of things.
[02:01:45.800 --> 02:01:46.800]   You can build a bunch of things.
[02:01:46.800 --> 02:01:47.800]   You can build a bunch of things.
[02:01:47.800 --> 02:01:48.800]   You can build a bunch of things.
[02:01:48.800 --> 02:01:49.800]   You can build a bunch of things.
[02:01:49.800 --> 02:01:50.800]   You can build a bunch of things.
[02:01:50.800 --> 02:01:51.800]   You can build a bunch of things.
[02:01:51.800 --> 02:01:52.800]   You can build a bunch of things.
[02:01:52.800 --> 02:01:53.800]   You can build a bunch of things.
[02:01:53.800 --> 02:01:54.800]   You can build a bunch of things.
[02:01:54.800 --> 02:01:55.800]   You can build a bunch of things.
[02:01:55.800 --> 02:01:56.800]   You can build a bunch of things.
[02:01:56.800 --> 02:01:57.800]   You can build a bunch of things.
[02:01:57.800 --> 02:01:58.800]   You can build a bunch of things.
[02:01:58.800 --> 02:01:59.800]   You can build a bunch of things.
[02:01:59.800 --> 02:02:00.800]   You can build a bunch of things.
[02:02:00.800 --> 02:02:01.800]   You can build a bunch of things.
[02:02:01.800 --> 02:02:02.800]   You can build a bunch of things.
[02:02:02.800 --> 02:02:03.800]   You can build a bunch of things.
[02:02:03.800 --> 02:02:04.800]   You can build a bunch of things.
[02:02:04.800 --> 02:02:05.800]   You can build a bunch of things.
[02:02:05.800 --> 02:02:06.800]   You can build a bunch of things.
[02:02:06.800 --> 02:02:07.800]   You can build a bunch of things.
[02:02:07.800 --> 02:02:08.800]   You can build a bunch of things.
[02:02:08.800 --> 02:02:09.800]   You can build a bunch of things.
[02:02:09.800 --> 02:02:10.800]   You can build a bunch of things.
[02:02:10.800 --> 02:02:11.800]   You can build a bunch of things.
[02:02:11.800 --> 02:02:12.800]   You can build a bunch of things.
[02:02:12.800 --> 02:02:13.800]   You can build a bunch of things.
[02:02:13.800 --> 02:02:14.800]   You can build a bunch of things.
[02:02:14.800 --> 02:02:15.800]   You can build a bunch of things.
[02:02:15.800 --> 02:02:16.800]   You can build a bunch of things.
[02:02:16.800 --> 02:02:17.800]   You can build a bunch of things.
[02:02:17.800 --> 02:02:18.800]   You can build a bunch of things.
[02:02:18.800 --> 02:02:20.800]   You can build a bunch of things.
[02:02:20.800 --> 02:02:21.800]   You can build a bunch of things.
[02:02:21.800 --> 02:02:22.800]   You can build a bunch of things.
[02:02:22.800 --> 02:02:23.800]   You can build a bunch of things.
[02:02:23.800 --> 02:02:24.800]   You can build a bunch of things.
[02:02:24.800 --> 02:02:25.800]   You can build a bunch of things.
[02:02:25.800 --> 02:02:26.800]   You can build a bunch of things.
[02:02:26.800 --> 02:02:27.800]   You can build a bunch of things.
[02:02:27.800 --> 02:02:28.800]   You can build a bunch of things.
[02:02:28.800 --> 02:02:29.800]   You can build a bunch of things.
[02:02:29.800 --> 02:02:30.800]   You can build a bunch of things.
[02:02:30.800 --> 02:02:31.800]   You can build a bunch of things.
[02:02:31.800 --> 02:02:32.800]   You can build a bunch of things.
[02:02:32.800 --> 02:02:33.800]   You can build a bunch of things.
[02:02:33.800 --> 02:02:34.800]   You can build a bunch of things.
[02:02:34.800 --> 02:02:35.800]   You can build a bunch of things.
[02:02:35.800 --> 02:02:36.800]   You can build a bunch of things.
[02:02:36.800 --> 02:02:37.800]   You can build a bunch of things.
[02:02:37.800 --> 02:02:38.800]   You can build a bunch of things.
[02:02:38.800 --> 02:02:39.800]   You can build a bunch of things.
[02:02:39.800 --> 02:02:40.800]   You can build a bunch of things.
[02:02:40.800 --> 02:02:41.800]   You can build a bunch of things.
[02:02:41.800 --> 02:02:43.800]   You can build a bunch of things.
[02:02:43.800 --> 02:02:44.800]   You can build a bunch of things.
[02:02:44.800 --> 02:02:45.800]   You can build a bunch of things.
[02:02:45.800 --> 02:02:46.800]   You can build a bunch of things.
[02:02:46.800 --> 02:02:47.800]   You can build a bunch of things.
[02:02:47.800 --> 02:02:48.800]   You can build a bunch of things.
[02:02:48.800 --> 02:02:49.800]   You can build a bunch of things.
[02:02:49.800 --> 02:02:50.800]   You can build a bunch of things.
[02:02:50.800 --> 02:02:51.800]   You can build a bunch of things.
[02:02:51.800 --> 02:02:52.800]   You can build a bunch of things.
[02:02:52.800 --> 02:02:53.800]   You can build a bunch of things.
[02:02:53.800 --> 02:02:54.800]   You can build a bunch of things.
[02:02:54.800 --> 02:02:55.800]   You can build a bunch of things.
[02:02:55.800 --> 02:02:56.800]   You can build a bunch of things.
[02:02:56.800 --> 02:02:57.800]   You can build a bunch of things.
[02:02:57.800 --> 02:02:58.800]   You can build a bunch of things.
[02:02:58.800 --> 02:02:59.800]   You can build a bunch of things.
[02:02:59.800 --> 02:03:00.800]   You can build a bunch of things.
[02:03:00.800 --> 02:03:01.800]   You can build a bunch of things.
[02:03:01.800 --> 02:03:02.800]   You can build a bunch of things.
[02:03:02.800 --> 02:03:03.800]   You can build a bunch of things.
[02:03:03.800 --> 02:03:04.800]   You can build a bunch of things.
[02:03:04.800 --> 02:03:05.800]   You can build a bunch of things.
[02:03:05.800 --> 02:03:06.800]   You can build a bunch of things.
[02:03:06.800 --> 02:03:07.800]   You can build a bunch of things.
[02:03:07.800 --> 02:03:08.800]   You can build a bunch of things.
[02:03:08.800 --> 02:03:09.800]   You can build a bunch of things.
[02:03:09.800 --> 02:03:10.800]   You can build a bunch of things.
[02:03:10.800 --> 02:03:11.800]   You can build a bunch of things.
[02:03:11.800 --> 02:03:12.800]   You can build a bunch of things.
[02:03:12.800 --> 02:03:13.800]   You can build a bunch of things.
[02:03:13.800 --> 02:03:14.800]   You can build a bunch of things.
[02:03:14.800 --> 02:03:15.800]   You can build a bunch of things.
[02:03:15.800 --> 02:03:16.800]   You can build a bunch of things.
[02:03:16.800 --> 02:03:17.800]   You can build a bunch of things.
[02:03:17.800 --> 02:03:18.800]   You can build a bunch of things.
[02:03:18.800 --> 02:03:19.800]   You can build a bunch of things.
[02:03:19.800 --> 02:03:20.800]   You can build a bunch of things.
[02:03:20.800 --> 02:03:21.800]   You can build a bunch of things.
[02:03:21.800 --> 02:03:22.800]   You can build a bunch of things.
[02:03:22.800 --> 02:03:23.800]   You can build a bunch of things.
[02:03:23.800 --> 02:03:24.800]   You can build a bunch of things.
[02:03:24.800 --> 02:03:25.800]   You can build a bunch of things.
[02:03:25.800 --> 02:03:26.800]   You can build a bunch of things.
[02:03:26.800 --> 02:03:27.800]   You can build a bunch of things.
[02:03:27.800 --> 02:03:28.800]   You can build a bunch of things.
[02:03:28.800 --> 02:03:29.800]   You can build a bunch of things.
[02:03:29.800 --> 02:03:30.800]   You can build a bunch of things.
[02:03:30.800 --> 02:03:31.800]   You can build a bunch of things.
[02:03:31.800 --> 02:03:32.800]   You can build a bunch of things.
[02:03:32.800 --> 02:03:33.800]   You can build a bunch of things.
[02:03:33.800 --> 02:03:34.800]   You can build a bunch of things.
[02:03:34.800 --> 02:03:35.800]   You can build a bunch of things.
[02:03:35.800 --> 02:03:36.800]   You can build a bunch of things.
[02:03:36.800 --> 02:03:37.800]   You can build a bunch of things.
[02:03:37.800 --> 02:03:38.800]   You can build a bunch of things.
[02:03:38.800 --> 02:03:39.800]   You can build a bunch of things.
[02:03:39.800 --> 02:03:40.800]   You can build a bunch of things.
[02:03:40.800 --> 02:03:41.800]   You can build a bunch of things.
[02:03:41.800 --> 02:03:42.800]   You can build a bunch of things.
[02:03:42.800 --> 02:03:43.800]   You can build a bunch of things.
[02:03:43.800 --> 02:03:44.800]   You can build a bunch of things.
[02:03:44.800 --> 02:03:45.800]   You can build a bunch of things.
[02:03:45.800 --> 02:03:46.800]   You can build a bunch of things.
[02:03:46.800 --> 02:03:47.800]   You can build a bunch of things.
[02:03:47.800 --> 02:03:48.800]   You can build a bunch of things.
[02:03:48.800 --> 02:03:50.800]   You can build a bunch of things.
[02:03:50.800 --> 02:03:51.800]   You can build a bunch of things.
[02:03:51.800 --> 02:03:52.800]   You can build a bunch of things.
[02:03:52.800 --> 02:03:53.800]   You can build a bunch of things.
[02:03:53.800 --> 02:03:54.800]   You can build a bunch of things.
[02:03:54.800 --> 02:03:55.800]   You can build a bunch of things.
[02:03:55.800 --> 02:03:56.800]   You can build a bunch of things.
[02:03:56.800 --> 02:03:57.800]   You can build a bunch of things.
[02:03:57.800 --> 02:03:58.800]   You can build a bunch of things.
[02:03:58.800 --> 02:03:59.800]   You can build a bunch of things.
[02:03:59.800 --> 02:04:00.800]   You can build a bunch of things.
[02:04:00.800 --> 02:04:01.800]   You can build a bunch of things.
[02:04:01.800 --> 02:04:02.800]   You can build a bunch of things.
[02:04:02.800 --> 02:04:03.800]   You can build a bunch of things.
[02:04:03.800 --> 02:04:04.800]   You can build a bunch of things.
[02:04:04.800 --> 02:04:05.800]   You can build a bunch of things.
[02:04:05.800 --> 02:04:06.800]   You can build a bunch of things.
[02:04:06.800 --> 02:04:07.800]   You can build a bunch of things.
[02:04:07.800 --> 02:04:08.800]   You can build a bunch of things.
[02:04:08.800 --> 02:04:09.800]   You can build a bunch of things.
[02:04:09.800 --> 02:04:10.800]   You can build a bunch of things.
[02:04:10.800 --> 02:04:11.800]   You can build a bunch of things.
[02:04:11.800 --> 02:04:12.800]   You can build a bunch of things.
[02:04:12.800 --> 02:04:13.800]   You can build a bunch of things.
[02:04:13.800 --> 02:04:14.800]   You can build a bunch of things.
[02:04:14.800 --> 02:04:15.800]   You can build a bunch of things.
[02:04:15.800 --> 02:04:16.800]   You can build a bunch of things.
[02:04:16.800 --> 02:04:17.800]   You can build a bunch of things.
[02:04:17.800 --> 02:04:18.800]   You can build a bunch of things.
[02:04:18.800 --> 02:04:19.800]   You can build a bunch of things.
[02:04:19.800 --> 02:04:20.800]   You can build a bunch of things.
[02:04:20.800 --> 02:04:21.800]   You can build a bunch of things.
[02:04:21.800 --> 02:04:22.800]   You can build a bunch of things.
[02:04:22.800 --> 02:04:23.800]   You can build a bunch of things.
[02:04:23.800 --> 02:04:24.800]   You can build a bunch of things.
[02:04:24.800 --> 02:04:25.800]   You can build a bunch of things.
[02:04:25.800 --> 02:04:26.800]   You can build a bunch of things.
[02:04:26.800 --> 02:04:27.800]   You can build a bunch of things.
[02:04:27.800 --> 02:04:28.800]   You can build a bunch of things.
[02:04:28.800 --> 02:04:29.800]   You can build a bunch of things.
[02:04:29.800 --> 02:04:30.800]   You can build a bunch of things.
[02:04:30.800 --> 02:04:31.800]   You can build a bunch of things.
[02:04:31.800 --> 02:04:32.800]   You can build a bunch of things.
[02:04:32.800 --> 02:04:33.800]   You can build a bunch of things.
[02:04:33.800 --> 02:04:35.800]   You can build a bunch of things.
[02:04:35.800 --> 02:04:36.800]   You can build a bunch of things.
[02:04:36.800 --> 02:04:37.800]   You can build a bunch of things.
[02:04:37.800 --> 02:04:38.800]   You can build a bunch of things.
[02:04:38.800 --> 02:04:39.800]   You can build a bunch of things.
[02:04:39.800 --> 02:04:40.800]   You can build a bunch of things.
[02:04:40.800 --> 02:04:41.800]   You can build a bunch of things.
[02:04:41.800 --> 02:04:42.800]   You can build a bunch of things.
[02:04:42.800 --> 02:04:43.800]   You can build a bunch of things.
[02:04:43.800 --> 02:04:44.800]   You can build a bunch of things.
[02:04:44.800 --> 02:04:45.800]   You can build a bunch of things.
[02:04:45.800 --> 02:04:46.800]   You can build a bunch of things.
[02:04:46.800 --> 02:04:47.800]   You can build a bunch of things.
[02:04:47.800 --> 02:04:48.800]   You can build a bunch of things.
[02:04:48.800 --> 02:04:49.800]   You can build a bunch of things.
[02:04:49.800 --> 02:04:50.800]   You can build a bunch of things.
[02:04:50.800 --> 02:04:51.800]   You can build a bunch of things.
[02:04:51.800 --> 02:04:52.800]   You can build a bunch of things.
[02:04:52.800 --> 02:04:53.800]   You can build a bunch of things.
[02:04:53.800 --> 02:04:54.800]   You can build a bunch of things.
[02:04:54.800 --> 02:04:55.800]   You can build a bunch of things.
[02:04:55.800 --> 02:04:56.800]   You can build a bunch of things.
[02:04:56.800 --> 02:04:57.800]   You can build a bunch of things.
[02:04:57.800 --> 02:04:58.800]   You can build a bunch of things.
[02:04:58.800 --> 02:04:59.800]   You can build a bunch of things.
[02:04:59.800 --> 02:05:00.800]   You can build a bunch of things.
[02:05:00.800 --> 02:05:01.800]   You can build a bunch of things.
[02:05:01.800 --> 02:05:02.800]   You can build a bunch of things.
[02:05:02.800 --> 02:05:03.800]   You can build a bunch of things.
[02:05:03.800 --> 02:05:04.800]   You can build a bunch of things.
[02:05:04.800 --> 02:05:05.800]   You can build a bunch of things.
[02:05:05.800 --> 02:05:06.800]   You can build a bunch of things.
[02:05:06.800 --> 02:05:07.800]   You can build a bunch of things.
[02:05:07.800 --> 02:05:08.800]   You can build a bunch of things.
[02:05:08.800 --> 02:05:09.800]   You can build a bunch of things.
[02:05:09.800 --> 02:05:10.800]   You can build a bunch of things.
[02:05:10.800 --> 02:05:11.800]   You can build a bunch of things.
[02:05:11.800 --> 02:05:12.800]   You can build a bunch of things.
[02:05:12.800 --> 02:05:13.800]   You can build a bunch of things.
[02:05:13.800 --> 02:05:14.800]   You can build a bunch of things.
[02:05:14.800 --> 02:05:15.800]   You can build a bunch of things.
[02:05:15.800 --> 02:05:16.800]   You can build a bunch of things.
[02:05:16.800 --> 02:05:17.800]   You can build a bunch of things.
[02:05:17.800 --> 02:05:18.800]   You can build a bunch of things.
[02:05:18.800 --> 02:05:19.800]   You can build a bunch of things.
[02:05:19.800 --> 02:05:20.800]   You can build a bunch of things.
[02:05:20.800 --> 02:05:21.800]   You can build a bunch of things.
[02:05:21.800 --> 02:05:22.800]   You can build a bunch of things.
[02:05:22.800 --> 02:05:23.800]   You can build a bunch of things.
[02:05:23.800 --> 02:05:24.800]   You can build a bunch of things.
[02:05:24.800 --> 02:05:25.800]   You can build a bunch of things.
[02:05:25.800 --> 02:05:26.800]   You can build a bunch of things.
[02:05:26.800 --> 02:05:27.800]   You can build a bunch of things.
[02:05:27.800 --> 02:05:28.800]   You can build a bunch of things.
[02:05:28.800 --> 02:05:29.800]   You can build a bunch of things.
[02:05:29.800 --> 02:05:30.800]   You can build a bunch of things.
[02:05:30.800 --> 02:05:31.800]   You can build a bunch of things.
[02:05:31.800 --> 02:05:32.800]   You can build a bunch of things.
[02:05:32.800 --> 02:05:33.800]   You can build a bunch of things.
[02:05:33.800 --> 02:05:34.800]   You can build a bunch of things.
[02:05:34.800 --> 02:05:35.800]   You can build a bunch of things.
[02:05:35.800 --> 02:05:36.800]   You can build a bunch of things.
[02:05:36.800 --> 02:05:37.800]   You can build a bunch of things.
[02:05:37.800 --> 02:05:38.800]   You can build a bunch of things.
[02:05:38.800 --> 02:05:39.800]   You can build a bunch of things.
[02:05:39.800 --> 02:05:40.800]   You can build a bunch of things.
[02:05:40.800 --> 02:05:42.800]   You can build a bunch of things.
[02:05:42.800 --> 02:05:43.800]   You can build a bunch of things.
[02:05:43.800 --> 02:05:44.800]   You can build a bunch of things.
[02:05:44.800 --> 02:05:45.800]   You can build a bunch of things.
[02:05:45.800 --> 02:05:46.800]   You can build a bunch of things.
[02:05:46.800 --> 02:05:47.800]   You can build a bunch of things.
[02:05:47.800 --> 02:05:48.800]   You can build a bunch of things.
[02:05:48.800 --> 02:05:49.800]   You can build a bunch of things.
[02:05:49.800 --> 02:05:50.800]   You can build a bunch of things.
[02:05:50.800 --> 02:05:51.800]   You can build a bunch of things.
[02:05:51.800 --> 02:05:52.800]   You can build a bunch of things.
[02:05:52.800 --> 02:05:53.800]   You can build a bunch of things.
[02:05:53.800 --> 02:05:54.800]   You can build a bunch of things.
[02:05:54.800 --> 02:05:55.800]   You can build a bunch of things.
[02:05:55.800 --> 02:05:56.800]   You can build a bunch of things.
[02:05:56.800 --> 02:05:57.800]   You can build a bunch of things.
[02:05:57.800 --> 02:05:58.800]   You can build a bunch of things.
[02:05:58.800 --> 02:05:59.800]   You can build a bunch of things.
[02:05:59.800 --> 02:06:00.800]   You can build a bunch of things.
[02:06:00.800 --> 02:06:01.800]   You can build a bunch of things.
[02:06:01.800 --> 02:06:02.800]   You can build a bunch of things.
[02:06:02.800 --> 02:06:03.800]   You can build a bunch of things.
[02:06:03.800 --> 02:06:04.800]   You can build a bunch of things.
[02:06:04.800 --> 02:06:05.800]   You can build a bunch of things.
[02:06:05.800 --> 02:06:06.800]   You can build a bunch of things.
[02:06:06.800 --> 02:06:07.800]   You can build a bunch of things.
[02:06:07.800 --> 02:06:08.800]   You can build a bunch of things.
[02:06:08.800 --> 02:06:09.800]   You can build a bunch of things.
[02:06:09.800 --> 02:06:10.800]   You can build a bunch of things.
[02:06:10.800 --> 02:06:11.800]   You can build a bunch of things.
[02:06:11.800 --> 02:06:12.800]   You can build a bunch of things.
[02:06:12.800 --> 02:06:13.800]   You can build a bunch of things.
[02:06:13.800 --> 02:06:14.800]   You can build a bunch of things.
[02:06:14.800 --> 02:06:15.800]   You can build a bunch of things.
[02:06:15.800 --> 02:06:16.800]   You can build a bunch of things.
[02:06:16.800 --> 02:06:17.800]   You can build a bunch of things.
[02:06:17.800 --> 02:06:18.800]   You can build a bunch of things.
[02:06:18.800 --> 02:06:19.800]   You can build a bunch of things.
[02:06:19.800 --> 02:06:20.800]   You can build a bunch of things.
[02:06:20.800 --> 02:06:21.800]   You can build a bunch of things.
[02:06:21.800 --> 02:06:22.800]   You can build a bunch of things.
[02:06:22.800 --> 02:06:23.800]   You can build a bunch of things.
[02:06:23.800 --> 02:06:24.800]   You can build a bunch of things.
[02:06:24.800 --> 02:06:25.800]   You can build a bunch of things.
[02:06:25.800 --> 02:06:27.800]   You can build a bunch of things.
[02:06:27.800 --> 02:06:28.800]   You can build a bunch of things.
[02:06:28.800 --> 02:06:29.800]   You can build a bunch of things.
[02:06:29.800 --> 02:06:30.800]   You can build a bunch of things.
[02:06:30.800 --> 02:06:31.800]   You can build a bunch of things.
[02:06:31.800 --> 02:06:32.800]   You can build a bunch of things.
[02:06:32.800 --> 02:06:33.800]   You can build a bunch of things.
[02:06:33.800 --> 02:06:34.800]   You can build a bunch of things.
[02:06:34.800 --> 02:06:35.800]   You can build a bunch of things.
[02:06:35.800 --> 02:06:36.800]   You can build a bunch of things.
[02:06:36.800 --> 02:06:37.800]   You can build a bunch of things.
[02:06:37.800 --> 02:06:38.800]   You can build a bunch of things.
[02:06:38.800 --> 02:06:39.800]   You can build a bunch of things.
[02:06:39.800 --> 02:06:40.800]   You can build a bunch of things.
[02:06:40.800 --> 02:06:41.800]   You can build a bunch of things.
[02:06:41.800 --> 02:06:42.800]   You can build a bunch of things.
[02:06:42.800 --> 02:06:43.800]   You can build a bunch of things.
[02:06:43.800 --> 02:06:44.800]   You can build a bunch of things.
[02:06:44.800 --> 02:06:45.800]   You can build a bunch of things.
[02:06:45.800 --> 02:06:46.800]   You can build a bunch of things.
[02:06:46.800 --> 02:06:47.800]   You can build a bunch of things.
[02:06:47.800 --> 02:06:48.800]   You can build a bunch of things.
[02:06:48.800 --> 02:06:49.800]   You can build a bunch of things.
[02:06:49.800 --> 02:06:50.800]   You can build a bunch of things.
[02:06:50.800 --> 02:06:51.800]   You can build a bunch of things.
[02:06:51.800 --> 02:06:52.800]   You can build a bunch of things.
[02:06:52.800 --> 02:06:53.800]   You can build a bunch of things.
[02:06:53.800 --> 02:06:54.800]   You can build a bunch of things.
[02:06:54.800 --> 02:06:55.800]   You can build a bunch of things.
[02:06:55.800 --> 02:06:56.800]   You can build a bunch of things.
[02:06:56.800 --> 02:06:57.800]   You can build a bunch of things.
[02:06:57.800 --> 02:06:58.800]   You can build a bunch of things.
[02:06:58.800 --> 02:06:59.800]   You can build a bunch of things.
[02:06:59.800 --> 02:07:00.800]   You can build a bunch of things.
[02:07:00.800 --> 02:07:01.800]   You can build a bunch of things.
[02:07:01.800 --> 02:07:02.800]   You can build a bunch of things.
[02:07:02.800 --> 02:07:03.800]   You can build a bunch of things.
[02:07:03.800 --> 02:07:04.800]   You can build a bunch of things.
[02:07:04.800 --> 02:07:05.800]   You can build a bunch of things.
[02:07:05.800 --> 02:07:06.800]   You can build a bunch of things.
[02:07:06.800 --> 02:07:07.800]   You can build a bunch of things.
[02:07:07.800 --> 02:07:08.800]   You can build a bunch of things.
[02:07:08.800 --> 02:07:09.800]   You can build a bunch of things.
[02:07:09.800 --> 02:07:10.800]   You can build a bunch of things.
[02:07:10.800 --> 02:07:11.800]   You can build a bunch of things.
[02:07:11.800 --> 02:07:12.800]   You can build a bunch of things.
[02:07:12.800 --> 02:07:13.800]   You can build a bunch of things.
[02:07:13.800 --> 02:07:14.800]   You can build a bunch of things.
[02:07:14.800 --> 02:07:15.800]   You can build a bunch of things.
[02:07:15.800 --> 02:07:16.800]   You can build a bunch of things.
[02:07:16.800 --> 02:07:17.800]   You can build a bunch of things.
[02:07:17.800 --> 02:07:18.800]   You can build a bunch of things.
[02:07:18.800 --> 02:07:19.800]   You can build a bunch of things.
[02:07:19.800 --> 02:07:20.800]   You can build a bunch of things.
[02:07:20.800 --> 02:07:21.800]   You can build a bunch of things.
[02:07:21.800 --> 02:07:22.800]   You can build a bunch of things.
[02:07:22.800 --> 02:07:23.800]   You can build a bunch of things.
[02:07:23.800 --> 02:07:24.800]   You can build a bunch of things.
[02:07:24.800 --> 02:07:25.800]   You can build a bunch of things.
[02:07:25.800 --> 02:07:26.800]   You can build a bunch of things.
[02:07:26.800 --> 02:07:27.800]   You can build a bunch of things.
[02:07:27.800 --> 02:07:28.800]   You can build a bunch of things.
[02:07:28.800 --> 02:07:29.800]   You can build a bunch of things.
[02:07:29.800 --> 02:07:30.800]   You can build a bunch of things.
[02:07:30.800 --> 02:07:31.800]   You can build a bunch of things.
[02:07:31.800 --> 02:07:32.800]   You can build a bunch of things.
[02:07:32.800 --> 02:07:34.800]   You can build a bunch of things.
[02:07:34.800 --> 02:07:35.800]   You can build a bunch of things.
[02:07:35.800 --> 02:07:36.800]   You can build a bunch of things.
[02:07:36.800 --> 02:07:37.800]   You can build a bunch of things.
[02:07:37.800 --> 02:07:38.800]   You can build a bunch of things.
[02:07:38.800 --> 02:07:39.800]   You can build a bunch of things.
[02:07:39.800 --> 02:07:40.800]   You can build a bunch of things.
[02:07:40.800 --> 02:07:41.800]   You can build a bunch of things.
[02:07:41.800 --> 02:07:42.800]   You can build a bunch of things.
[02:07:42.800 --> 02:07:43.800]   You can build a bunch of things.
[02:07:43.800 --> 02:07:44.800]   You can build a bunch of things.
[02:07:44.800 --> 02:07:45.800]   You can build a bunch of things.
[02:07:45.800 --> 02:07:46.800]   You can build a bunch of things.
[02:07:46.800 --> 02:07:47.800]   You can build a bunch of things.
[02:07:47.800 --> 02:07:48.800]   You can build a bunch of things.
[02:07:48.800 --> 02:07:49.800]   You can build a bunch of things.
[02:07:49.800 --> 02:07:50.800]   You can build a bunch of things.
[02:07:50.800 --> 02:07:51.800]   You can build a bunch of things.
[02:07:51.800 --> 02:07:52.800]   You can build a bunch of things.
[02:07:52.800 --> 02:07:53.800]   You can build a bunch of things.
[02:07:53.800 --> 02:07:54.800]   You can build a bunch of things.
[02:07:54.800 --> 02:07:55.800]   You can build a bunch of things.
[02:07:55.800 --> 02:07:56.800]   You can build a bunch of things.
[02:07:56.800 --> 02:07:57.800]   You can build a bunch of things.
[02:07:57.800 --> 02:07:58.800]   You can build a bunch of things.
[02:07:58.800 --> 02:07:59.800]   You can build a bunch of things.
[02:07:59.800 --> 02:08:00.800]   You can build a bunch of things.
[02:08:00.800 --> 02:08:01.800]   You can build a bunch of things.
[02:08:01.800 --> 02:08:02.800]   You can build a bunch of things.
[02:08:02.800 --> 02:08:03.800]   You can build a bunch of things.
[02:08:03.800 --> 02:08:04.800]   You can build a bunch of things.
[02:08:04.800 --> 02:08:05.800]   You can build a bunch of things.
[02:08:05.800 --> 02:08:06.800]   You can build a bunch of things.
[02:08:06.800 --> 02:08:07.800]   You can build a bunch of things.
[02:08:07.800 --> 02:08:08.800]   You can build a bunch of things.
[02:08:08.800 --> 02:08:09.800]   You can build a bunch of things.
[02:08:09.800 --> 02:08:10.800]   You can build a bunch of things.
[02:08:10.800 --> 02:08:11.800]   You can build a bunch of things.
[02:08:11.800 --> 02:08:12.800]   You can build a bunch of things.
[02:08:12.800 --> 02:08:13.800]   You can build a bunch of things.
[02:08:13.800 --> 02:08:14.800]   You can build a bunch of things.
[02:08:14.800 --> 02:08:15.800]   You can build a bunch of things.
[02:08:15.800 --> 02:08:16.800]   You can build a bunch of things.
[02:08:16.800 --> 02:08:17.800]   You can build a bunch of things.
[02:08:17.800 --> 02:08:18.800]   You can build a bunch of things.
[02:08:18.800 --> 02:08:19.800]   You can build a bunch of things.
[02:08:19.800 --> 02:08:20.800]   You can build a bunch of things.
[02:08:20.800 --> 02:08:21.800]   You can build a bunch of things.
[02:08:21.800 --> 02:08:22.800]   You can build a bunch of things.
[02:08:22.800 --> 02:08:23.800]   You can build a bunch of things.
[02:08:23.800 --> 02:08:24.800]   You can build a bunch of things.
[02:08:24.800 --> 02:08:25.800]   You can build a bunch of things.
[02:08:25.800 --> 02:08:26.800]   You can build a bunch of things.
[02:08:26.800 --> 02:08:27.800]   You can build a bunch of things.
[02:08:27.800 --> 02:08:28.800]   You can build a bunch of things.
[02:08:28.800 --> 02:08:29.800]   You can build a bunch of things.
[02:08:29.800 --> 02:08:30.800]   You can build a bunch of things.
[02:08:30.800 --> 02:08:31.800]   You can build a bunch of things.
[02:08:31.800 --> 02:08:32.800]   You can build a bunch of things.
[02:08:32.800 --> 02:08:33.800]   You can build a bunch of things.
[02:08:33.800 --> 02:08:34.800]   You can build a bunch of things.
[02:08:34.800 --> 02:08:35.800]   You can build a bunch of things.
[02:08:35.800 --> 02:08:36.800]   You can build a bunch of things.
[02:08:36.800 --> 02:08:37.800]   You can build a bunch of things.
[02:08:37.800 --> 02:08:38.800]   You can build a bunch of things.
[02:08:38.800 --> 02:08:39.800]   You can build a bunch of things.
[02:08:39.800 --> 02:08:41.800]   You can build a bunch of things.
[02:08:41.800 --> 02:08:42.800]   You can build a bunch of things.
[02:08:42.800 --> 02:08:43.800]   You can build a bunch of things.
[02:08:43.800 --> 02:08:44.800]   You can build a bunch of things.
[02:08:44.800 --> 02:08:45.800]   You can build a bunch of things.
[02:08:45.800 --> 02:08:46.800]   You can build a bunch of things.
[02:08:46.800 --> 02:08:47.800]   You can build a bunch of things.
[02:08:47.800 --> 02:08:48.800]   You can build a bunch of things.
[02:08:48.800 --> 02:08:49.800]   You can build a bunch of things.
[02:08:49.800 --> 02:08:50.800]   You can build a bunch of things.
[02:08:50.800 --> 02:08:51.800]   You can build a bunch of things.
[02:08:51.800 --> 02:08:52.800]   You can build a bunch of things.
[02:08:52.800 --> 02:08:53.800]   You can build a bunch of things.
[02:08:53.800 --> 02:08:54.800]   You can build a bunch of things.
[02:08:54.800 --> 02:08:55.800]   You can build a bunch of things.
[02:08:55.800 --> 02:08:56.800]   You can build a bunch of things.
[02:08:56.800 --> 02:08:57.800]   You can build a bunch of things.
[02:08:57.800 --> 02:08:58.800]   You can build a bunch of things.
[02:08:58.800 --> 02:08:59.800]   You can build a bunch of things.
[02:08:59.800 --> 02:09:00.800]   You can build a bunch of things.
[02:09:00.800 --> 02:09:01.800]   You can build a bunch of things.
[02:09:01.800 --> 02:09:02.800]   You can build a bunch of things.
[02:09:02.800 --> 02:09:03.800]   You can build a bunch of things.
[02:09:03.800 --> 02:09:04.800]   You can build a bunch of things.
[02:09:04.800 --> 02:09:05.800]   You can build a bunch of things.
[02:09:05.800 --> 02:09:06.800]   You can build a bunch of things.
[02:09:06.800 --> 02:09:07.800]   You can build a bunch of things.
[02:09:07.800 --> 02:09:08.800]   You can build a bunch of things.
[02:09:08.800 --> 02:09:09.800]   You can build a bunch of things.
[02:09:09.800 --> 02:09:10.800]   You can build a bunch of things.
[02:09:10.800 --> 02:09:11.800]   You can build a bunch of things.
[02:09:11.800 --> 02:09:12.800]   You can build a bunch of things.
[02:09:12.800 --> 02:09:13.800]   You can build a bunch of things.
[02:09:13.800 --> 02:09:14.800]   You can build a bunch of things.
[02:09:14.800 --> 02:09:15.800]   You can build a bunch of things.
[02:09:15.800 --> 02:09:16.800]   You can build a bunch of things.
[02:09:16.800 --> 02:09:17.800]   You can build a bunch of things.
[02:09:17.800 --> 02:09:18.800]   You can build a bunch of things.
[02:09:18.800 --> 02:09:19.800]   You can build a bunch of things.
[02:09:19.800 --> 02:09:20.800]   You can build a bunch of things.
[02:09:20.800 --> 02:09:21.800]   You can build a bunch of things.
[02:09:21.800 --> 02:09:22.800]   You can build a bunch of things.
[02:09:22.800 --> 02:09:23.800]   You can build a bunch of things.
[02:09:23.800 --> 02:09:24.800]   You can build a bunch of things.
[02:09:24.800 --> 02:09:25.800]   You can build a bunch of things.
[02:09:25.800 --> 02:09:26.800]   You can build a bunch of things.
[02:09:26.800 --> 02:09:27.800]   You can build a bunch of things.
[02:09:27.800 --> 02:09:28.800]   You can build a bunch of things.
[02:09:28.800 --> 02:09:29.800]   You can build a bunch of things.
[02:09:29.800 --> 02:09:30.800]   You can build a bunch of things.
[02:09:30.800 --> 02:09:31.800]   You can build a bunch of things.
[02:09:31.800 --> 02:09:32.800]   You can build a bunch of things.
[02:09:32.800 --> 02:09:33.800]   You can build a bunch of things.
[02:09:33.800 --> 02:09:34.800]   You can build a bunch of things.
[02:09:34.800 --> 02:09:35.800]   You can build a bunch of things.
[02:09:35.800 --> 02:09:36.800]   You can build a bunch of things.
[02:09:36.800 --> 02:09:37.800]   You can build a bunch of things.
[02:09:37.800 --> 02:09:38.800]   You can build a bunch of things.
[02:09:38.800 --> 02:09:39.800]   You can build a bunch of things.
[02:09:39.800 --> 02:09:40.800]   You can build a bunch of things.
[02:09:40.800 --> 02:09:41.800]   You can build a bunch of things.
[02:09:41.800 --> 02:09:42.800]   You can build a bunch of things.
[02:09:42.800 --> 02:09:43.800]   You can build a bunch of things.
[02:09:43.800 --> 02:09:44.800]   You can build a bunch of things.
[02:09:44.800 --> 02:09:45.800]   You can build a bunch of things.
[02:09:45.800 --> 02:09:46.800]   You can build a bunch of things.
[02:09:46.800 --> 02:09:47.800]   You can build a bunch of things.
[02:09:47.800 --> 02:09:48.800]   You can build a bunch of things.
[02:09:48.800 --> 02:09:49.800]   You can build a bunch of things.
[02:09:49.800 --> 02:09:50.800]   You can build a bunch of things.
[02:09:50.800 --> 02:09:51.800]   You can build a bunch of things.
[02:09:51.800 --> 02:09:52.800]   You can build a bunch of things.
[02:09:52.800 --> 02:09:53.800]   You can build a bunch of things.
[02:09:53.800 --> 02:09:54.800]   You can build a bunch of things.
[02:09:54.800 --> 02:09:55.800]   You can build a bunch of things.
[02:09:55.800 --> 02:09:56.800]   You can build a bunch of things.
[02:09:56.800 --> 02:09:57.800]   You can build a bunch of things.
[02:09:57.800 --> 02:09:58.800]   You can build a bunch of things.
[02:09:58.800 --> 02:09:59.800]   You can build a bunch of things.
[02:09:59.800 --> 02:10:00.800]   You can build a bunch of things.
[02:10:00.800 --> 02:10:01.800]   You can build a bunch of things.
[02:10:01.800 --> 02:10:02.800]   You can build a bunch of things.

