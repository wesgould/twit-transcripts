;FFMETADATA1
title=Emotional Support Ham
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=685
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.800]   It's time for Twit this week in Tech.
[00:00:02.800 --> 00:00:04.360]   I am back.
[00:00:04.360 --> 00:00:05.920]   But there's a lot of tech news I missed.
[00:00:05.920 --> 00:00:10.360]   We're going to ask our panel, Amy Webb of the Future Today Institute and Mike Elgin
[00:00:10.360 --> 00:00:12.560]   of Gastronomad.net.
[00:00:12.560 --> 00:00:13.960]   What I missed.
[00:00:13.960 --> 00:00:18.680]   Lots of stories this week, including the latest about the Apple iPhone, Apple Watch,
[00:00:18.680 --> 00:00:20.760]   Google's Play in China and a whole lot more.
[00:00:20.760 --> 00:00:21.760]   Stay tuned.
[00:00:21.760 --> 00:00:22.760]   Twit is next.
[00:00:22.760 --> 00:00:41.120]   Netcast you love.
[00:00:41.120 --> 00:00:44.080]   This is Twit this week in Tech.
[00:00:44.080 --> 00:00:49.320]   Episode 685 recorded Sunday, September 23, 2018.
[00:00:49.320 --> 00:00:52.600]   Emotional Support Am.
[00:00:52.600 --> 00:00:55.320]   This week in Tech is brought to you by Blue Apron.
[00:00:55.320 --> 00:00:58.520]   Blue Apron makes cooking fun and easy.
[00:00:58.520 --> 00:01:05.000]   Check out this week's menu and get your first three meals free at Blue Apron.com/Twit.
[00:01:05.000 --> 00:01:07.000]   And by WordPress.
[00:01:07.000 --> 00:01:11.440]   Reach more customers when you build your business website on WordPress.com.
[00:01:11.440 --> 00:01:19.080]   Plan started just $4 a month and get 15% off any new plan purchase at WordPress.com/Twit.
[00:01:19.080 --> 00:01:22.400]   And by Rocket Mortgage from Quick and Loans.
[00:01:22.400 --> 00:01:25.560]   Introducing rate shield approval if you're in the market to buy a home.
[00:01:25.560 --> 00:01:29.280]   Rate shield approval locks up your rate for up to 90 days while you shop.
[00:01:29.280 --> 00:01:30.680]   It's a real game changer.
[00:01:30.680 --> 00:01:37.880]   Learn more and get started at Rocket Mortgage.com/TwitTube.
[00:01:37.880 --> 00:01:41.640]   It's time for Twit this week in Tech to show what we cover the week's Tech News.
[00:01:41.640 --> 00:01:42.800]   I'm Leo LaPorte.
[00:01:42.800 --> 00:01:43.800]   You may have heard of me.
[00:01:43.800 --> 00:01:46.240]   I used to work here.
[00:01:46.240 --> 00:01:49.240]   For many years.
[00:01:49.240 --> 00:01:50.560]   And then I took a long vacation.
[00:01:50.560 --> 00:01:53.920]   Longest I've ever taken thanks to Becky Worley who filled in.
[00:01:53.920 --> 00:01:54.920]   Who else filled in?
[00:01:54.920 --> 00:01:55.920]   Was Jason?
[00:01:55.920 --> 00:01:59.080]   Ian Thompson.
[00:01:59.080 --> 00:02:00.480]   Thank you guys for doing the show.
[00:02:00.480 --> 00:02:02.680]   How many shows did I miss, Karsten?
[00:02:02.680 --> 00:02:04.280]   Three.
[00:02:04.280 --> 00:02:06.280]   Did anything happen at all while I was going?
[00:02:06.280 --> 00:02:07.280]   Nothing.
[00:02:07.280 --> 00:02:08.280]   That's what I thought.
[00:02:08.280 --> 00:02:09.280]   I got back.
[00:02:09.280 --> 00:02:11.440]   It's exactly the same.
[00:02:11.440 --> 00:02:12.800]   Joining us from the future.
[00:02:12.800 --> 00:02:15.880]   Amy Webb, she's written the book called The Signals Are Talking.
[00:02:15.880 --> 00:02:19.360]   She's at the Future Now Institute and is just fantastic.
[00:02:19.360 --> 00:02:22.280]   We always love having Amy on the show.
[00:02:22.280 --> 00:02:28.120]   She actually introduced me not only to the future but to Japan, which is a little bit
[00:02:28.120 --> 00:02:29.120]   of the future.
[00:02:29.120 --> 00:02:31.480]   A little bit.
[00:02:31.480 --> 00:02:32.480]   Thank you for being here.
[00:02:32.480 --> 00:02:35.080]   Amy has got a little cold.
[00:02:35.080 --> 00:02:36.880]   Did I say the future now?
[00:02:36.880 --> 00:02:38.320]   It's the Future Today Institute.
[00:02:38.320 --> 00:02:39.320]   I'm sorry.
[00:02:39.320 --> 00:02:40.320]   It's today.
[00:02:40.320 --> 00:02:41.320]   It's now.
[00:02:41.320 --> 00:02:42.320]   It's with it.
[00:02:42.320 --> 00:02:43.320]   It's FutureTodayInstitute.com.
[00:02:43.320 --> 00:02:44.320]   Yeah.
[00:02:44.320 --> 00:02:45.320]   Yeah.
[00:02:45.320 --> 00:02:46.880]   It's the Future Now.
[00:02:46.880 --> 00:02:52.560]   Also with us, Mr. Michael Elgin, who is a world traveler and so understands when I say
[00:02:52.560 --> 00:02:53.560]   I'm a little jet-lagged.
[00:02:53.560 --> 00:02:54.560]   Jet-lagged, yeah.
[00:02:54.560 --> 00:02:56.560]   I'm from the present, not the future.
[00:02:56.560 --> 00:02:57.960]   I'm from the way of the year.
[00:02:57.960 --> 00:02:58.960]   I'm from the way of the year.
[00:02:58.960 --> 00:02:59.960]   Welcome back to reality.
[00:02:59.960 --> 00:03:00.960]   Thank you.
[00:03:00.960 --> 00:03:01.960]   We missed you.
[00:03:01.960 --> 00:03:02.960]   No, you didn't.
[00:03:02.960 --> 00:03:03.960]   But anyway, I'm glad to be here.
[00:03:03.960 --> 00:03:04.960]   I would say I missed you guys.
[00:03:04.960 --> 00:03:06.200]   And I did a little bit.
[00:03:06.200 --> 00:03:07.200]   Lukewarm.
[00:03:07.200 --> 00:03:09.960]   You know, it was great not having, you know, we were on a boat.
[00:03:09.960 --> 00:03:11.400]   So there was a great little internet.
[00:03:11.400 --> 00:03:17.120]   And the T-Mobile and Google Firework pretty well to get the internet when you're in port.
[00:03:17.120 --> 00:03:21.200]   But I wasn't actually anxious to find out what was going on.
[00:03:21.200 --> 00:03:23.040]   I hear there was an Apple event.
[00:03:23.040 --> 00:03:28.200]   It's two years in a row now that I've managed to be out of town during an Apple event.
[00:03:28.200 --> 00:03:30.120]   I'm going to keep that up.
[00:03:30.120 --> 00:03:35.080]   Long story short, the best phones Apple has ever made.
[00:03:35.080 --> 00:03:36.280]   I have the new watch.
[00:03:36.280 --> 00:03:40.440]   I'm wearing the new watch and I'm pairing it right now and we'll look at that new face.
[00:03:40.440 --> 00:03:44.160]   And then I also have an excess.
[00:03:44.160 --> 00:03:46.160]   I'm going to call it the excess.
[00:03:46.160 --> 00:03:47.240]   I'm sorry.
[00:03:47.240 --> 00:03:49.920]   The excess Max coming tomorrow.
[00:03:49.920 --> 00:03:52.640]   But I was a little perturbed because I saw the excess Max.
[00:03:52.640 --> 00:03:54.440]   First of all, it looks a little stretched out.
[00:03:54.440 --> 00:03:56.080]   Like a little tall, right?
[00:03:56.080 --> 00:04:00.960]   Kind of like the iPhone 6s when it, 6s when it, or 6 plus did when it first came out.
[00:04:00.960 --> 00:04:05.040]   But then I was a little perturbed because I still noticed six lines of icons, six rows
[00:04:05.040 --> 00:04:06.040]   of icons.
[00:04:06.040 --> 00:04:07.880]   And I thought, well, they just made it the icons bigger.
[00:04:07.880 --> 00:04:08.880]   It's not more.
[00:04:08.880 --> 00:04:11.800]   It's a little more screw in real estate and we have a demonstration.
[00:04:11.800 --> 00:04:17.960]   This is the iPhone XS and this is the iPhone XS Max.
[00:04:17.960 --> 00:04:18.960]   Wow.
[00:04:18.960 --> 00:04:19.960]   That's amazing.
[00:04:19.960 --> 00:04:22.400]   So, Mike, an extra quarter inch.
[00:04:22.400 --> 00:04:23.400]   Mike pointed it.
[00:04:23.400 --> 00:04:27.760]   According to somebody in our audience, Jim, who's a developer, he said it's about 13%
[00:04:27.760 --> 00:04:28.760]   more.
[00:04:28.760 --> 00:04:29.760]   But this isn't Safari.
[00:04:29.760 --> 00:04:31.960]   You're seeing a little more of the page.
[00:04:31.960 --> 00:04:34.160]   Mike likes us because you see the Arthur's byline.
[00:04:34.160 --> 00:04:35.160]   Yes.
[00:04:35.160 --> 00:04:41.000]   But for a lot of things, it'd be my guess that it won't give you more screen real estate.
[00:04:41.000 --> 00:04:42.480]   You just get bigger icons.
[00:04:42.480 --> 00:04:43.480]   Yeah.
[00:04:43.480 --> 00:04:47.640]   I mean, to a large extent, it'll be up to the developers and how they want to use it,
[00:04:47.640 --> 00:04:49.440]   whether they want different versions and so on.
[00:04:49.440 --> 00:04:53.080]   But I also think, you know, part of this is just keeping a certain level of consistency
[00:04:53.080 --> 00:04:54.800]   among their different phones.
[00:04:54.800 --> 00:04:55.800]   Now they have a...
[00:04:55.800 --> 00:05:00.120]   Why do a bigger phone if you can't, if somebody can't take advantage of it?
[00:05:00.120 --> 00:05:01.120]   Is this just the phone?
[00:05:01.120 --> 00:05:02.120]   China.
[00:05:02.120 --> 00:05:03.120]   For old eyes?
[00:05:03.120 --> 00:05:04.120]   China.
[00:05:04.120 --> 00:05:05.120]   China loves the big phones.
[00:05:05.120 --> 00:05:10.520]   And they love gold and they love status symbols like iPhones.
[00:05:10.520 --> 00:05:12.800]   And that's one big reason.
[00:05:12.800 --> 00:05:16.520]   And the other big reason is the aging population in the United States.
[00:05:16.520 --> 00:05:18.520]   So those phones were not built for...
[00:05:18.520 --> 00:05:19.520]   It's the Ulster for...
[00:05:19.520 --> 00:05:21.000]   Well, I mean, it is...
[00:05:21.000 --> 00:05:27.040]   They were not built for Donald Trump because they are enormous, hard to hold in one hand.
[00:05:27.040 --> 00:05:29.800]   And they were not built for younger people.
[00:05:29.800 --> 00:05:31.600]   These are phones for people with...
[00:05:31.600 --> 00:05:34.000]   Is that because these little hands, is that the...
[00:05:34.000 --> 00:05:35.000]   It's a bad eyesight.
[00:05:35.000 --> 00:05:36.000]   I'm not sure.
[00:05:36.000 --> 00:05:37.000]   I'm not sure.
[00:05:37.000 --> 00:05:38.000]   I need a quantitative data on this.
[00:05:38.000 --> 00:05:44.000]   Actually, the president, as I remember, unless he's updated, uses a fairly old phone still.
[00:05:44.000 --> 00:05:45.840]   Lately he's been tweeting with an iPhone.
[00:05:45.840 --> 00:05:46.840]   Member for a long time.
[00:05:46.840 --> 00:05:47.840]   It's a Samsung.
[00:05:47.840 --> 00:05:48.840]   It's a Samsung.
[00:05:48.840 --> 00:05:49.840]   Right.
[00:05:49.840 --> 00:05:51.760]   Now he's on an iPhone, but I don't think it's the latest iPhone.
[00:05:51.760 --> 00:05:55.520]   Let's just hope whatever it is has actually been locked down in some way.
[00:05:55.520 --> 00:05:57.560]   But this bigger phone, I think, is...
[00:05:57.560 --> 00:05:59.040]   It's for old phones.
[00:05:59.040 --> 00:06:01.760]   It's for China and it's for a certain demographic in the US.
[00:06:01.760 --> 00:06:03.880]   I actually was impressed by the XR, which we don't have yet.
[00:06:03.880 --> 00:06:04.880]   It won't be out until next month.
[00:06:04.880 --> 00:06:09.760]   But the XR, which is an LCD based, not OLED based, looks actually like the iPhone, like
[00:06:09.760 --> 00:06:12.560]   the iPhone that was for many years.
[00:06:12.560 --> 00:06:16.560]   The other thing is that Apple slowly...
[00:06:16.560 --> 00:06:21.680]   Now that we're definitely in the post Steve Jobs world, they're slouching toward becoming
[00:06:21.680 --> 00:06:23.240]   an ordinary company.
[00:06:23.240 --> 00:06:26.960]   Under Steve Jobs, Steve Jobs was like, "This is the phone.
[00:06:26.960 --> 00:06:28.460]   There's only one phone.
[00:06:28.460 --> 00:06:30.680]   We make it and this is it and you have to buy it."
[00:06:30.680 --> 00:06:34.040]   Now they're becoming like a regular company.
[00:06:34.040 --> 00:06:36.600]   Samsung will be an extreme version of that where it's like, "Well, we have a phone for
[00:06:36.600 --> 00:06:40.920]   kids and we have a phone for people with big hands and we have a phone for people with
[00:06:40.920 --> 00:06:42.880]   horrible eyes and we have this phone and that phone."
[00:06:42.880 --> 00:06:48.480]   So 10 years from now, Apple probably have 15 phones, a big lineup because they'll be
[00:06:48.480 --> 00:06:49.680]   more of an ordinary company.
[00:06:49.680 --> 00:06:56.400]   Now, as my understanding, but again, I was in a distant land where no news penetrated,
[00:06:56.400 --> 00:07:01.680]   but they kept the 7 and the 8 as well as the iPhone 10 as well as the 10s.
[00:07:01.680 --> 00:07:06.120]   Well, one of the most interesting things about the announcement was that they had someone
[00:07:06.120 --> 00:07:10.880]   come on stage and talk about their environmental initiatives and they looked pretty serious
[00:07:10.880 --> 00:07:14.560]   and they announced some pretty serious things like getting away from rare earth metals and
[00:07:14.560 --> 00:07:15.560]   things like that.
[00:07:15.560 --> 00:07:19.760]   But one of the things they emphasized was they made the point, which I've made in a column,
[00:07:19.760 --> 00:07:28.600]   lots of people have made in the past, the only phone that is environmentally friendly is
[00:07:28.600 --> 00:07:30.920]   a phone that's never manufactured.
[00:07:30.920 --> 00:07:34.280]   And the way you don't manufacture phones is you get a lot more use out of them.
[00:07:34.280 --> 00:07:35.480]   They say they're planning to do that.
[00:07:35.480 --> 00:07:37.920]   They want their phones to last for years and years and years.
[00:07:37.920 --> 00:07:41.600]   So I think they're working on some plan to have their lower end phones actually be older
[00:07:41.600 --> 00:07:43.560]   phones that are refurbished and so on.
[00:07:43.560 --> 00:07:44.560]   Even more than they do today.
[00:07:44.560 --> 00:07:45.560]   They do that to the person.
[00:07:45.560 --> 00:07:46.560]   I think it's great.
[00:07:46.560 --> 00:07:47.560]   I think it's great news.
[00:07:47.560 --> 00:07:50.640]   It's hope that that is in fact the case that they make these indestructible phones that
[00:07:50.640 --> 00:07:54.160]   are in use for 12 years and that's their low end phone.
[00:07:54.160 --> 00:07:56.240]   But Apple's a hardware company.
[00:07:56.240 --> 00:08:00.400]   So that they're going to have like what's the business model in a charge three thousand
[00:08:00.400 --> 00:08:02.720]   dollars phone that's they're heading there clearly.
[00:08:02.720 --> 00:08:08.320]   Well, part of the model is expand the universe of people buying phones, right?
[00:08:08.320 --> 00:08:12.680]   Instead of saying you got to buy a new one, find people who haven't bought an iPhone yet.
[00:08:12.680 --> 00:08:14.120]   There's still plenty of room for expansion.
[00:08:14.120 --> 00:08:15.120]   Isn't there in India?
[00:08:15.120 --> 00:08:16.120]   For about 10 years.
[00:08:16.120 --> 00:08:19.840]   Yeah, I mean there's a number of C's and I mean we're at the beginning of the end.
[00:08:19.840 --> 00:08:23.560]   So this is the beginning of the end of smartphones.
[00:08:23.560 --> 00:08:24.560]   Yeah.
[00:08:24.560 --> 00:08:26.960]   You know, so I know that they've had a great.
[00:08:26.960 --> 00:08:31.000]   I know you want to talk about the beginning of the end and what is next after smartphones
[00:08:31.000 --> 00:08:32.000]   because Amy has.
[00:08:32.000 --> 00:08:34.000]   Oh, well, she's already tied to them.
[00:08:34.000 --> 00:08:35.800]   No, it's not that I'm tired.
[00:08:35.800 --> 00:08:36.800]   Save that.
[00:08:36.800 --> 00:08:42.560]   Okay, but like, you know, but so everybody's very, very excited about the Apple launch.
[00:08:42.560 --> 00:08:48.200]   And again, like what are what are the significant changes between the current phones and the
[00:08:48.200 --> 00:08:50.000]   previous phones?
[00:08:50.000 --> 00:08:56.560]   What is the measurable discernible difference that would cause somebody who is not a hardcore,
[00:08:56.560 --> 00:09:01.280]   you know, tech aficionado to go out and purchase a more expensive phone?
[00:09:01.280 --> 00:09:02.280]   Right.
[00:09:02.280 --> 00:09:08.280]   I mean, there's there's very, very little difference between what came out and what already existed.
[00:09:08.280 --> 00:09:13.080]   So we're seeing negligible new developments.
[00:09:13.080 --> 00:09:15.120]   And at the same time, there are all kinds of peripherals.
[00:09:15.120 --> 00:09:17.960]   So Leo, you've got a brand new I watch.
[00:09:17.960 --> 00:09:18.960]   Mike's got an I watch.
[00:09:18.960 --> 00:09:23.920]   If you have a certain amount of disposable income, you're probably not going to go and
[00:09:23.920 --> 00:09:27.640]   continue on that two year brand new phone cycle.
[00:09:27.640 --> 00:09:30.640]   You're probably going to buy a peripheral and there's more and more, you know, smart
[00:09:30.640 --> 00:09:33.280]   peripherals that are coming to market.
[00:09:33.280 --> 00:09:37.600]   And so, you know, we're only seeing incremental differences in these phones.
[00:09:37.600 --> 00:09:40.320]   We're going to probably see less.
[00:09:40.320 --> 00:09:44.720]   Well, we know we're going to see less phones and more other kinds of devices.
[00:09:44.720 --> 00:09:48.000]   Less differentiation between the phones that come out.
[00:09:48.000 --> 00:09:49.000]   Right.
[00:09:49.000 --> 00:09:50.000]   That's right.
[00:09:50.000 --> 00:09:51.000]   It's hard to find a differentiator these days.
[00:09:51.000 --> 00:09:52.000]   Yeah.
[00:09:52.000 --> 00:09:55.960]   You know, that's why Apple's probably doubling down on things like security and privacy,
[00:09:55.960 --> 00:10:01.160]   because that's one thing Apple can say is a differentiator in Apple's products.
[00:10:01.160 --> 00:10:08.440]   Apple's either going to plateau as a company and start declining or they're going to launch
[00:10:08.440 --> 00:10:16.040]   into entirely new businesses that are only tangentially related to phones and computers
[00:10:16.040 --> 00:10:17.040]   and things like that.
[00:10:17.040 --> 00:10:19.720]   It's the classic though, the innovators dilemma.
[00:10:19.720 --> 00:10:21.800]   This is the classic problem for a successful company.
[00:10:21.800 --> 00:10:25.240]   Especially a company with a big hit like the iPhone.
[00:10:25.240 --> 00:10:29.080]   It's a big problem for the most successful company because how much are they going to
[00:10:29.080 --> 00:10:31.280]   become a $3 billion company?
[00:10:31.280 --> 00:10:35.280]   I mean, what are they going to do to keep the growth and they'll try.
[00:10:35.280 --> 00:10:36.280]   Right.
[00:10:36.280 --> 00:10:38.480]   And I think I'm still a believer in the Apple car.
[00:10:38.480 --> 00:10:41.880]   I'll tell you where the iPhone is a big hit.
[00:10:41.880 --> 00:10:42.880]   Thieves.
[00:10:42.880 --> 00:10:44.400]   Oh, they love them.
[00:10:44.400 --> 00:10:49.240]   Our Santa Rosa Apple store was hit at the end of the month, last month.
[00:10:49.240 --> 00:10:52.400]   And Megan Moroni was in there this afternoon picking up her iPhone.
[00:10:52.400 --> 00:10:56.960]   She just tweeted, I was mining my own business, waiting for my Apple watch when some dudes
[00:10:56.960 --> 00:10:58.520]   robbed the Santa Rosa Apple store.
[00:10:58.520 --> 00:11:00.400]   The same store that was robbed a week ago.
[00:11:00.400 --> 00:11:01.400]   Wow.
[00:11:01.400 --> 00:11:03.480]   Last time they took $35,000 in stuff.
[00:11:03.480 --> 00:11:06.000]   So great that they did that and made it into the show.
[00:11:06.000 --> 00:11:07.000]   Isn't everything locked down?
[00:11:07.000 --> 00:11:08.000]   How did they do that?
[00:11:08.000 --> 00:11:09.000]   Well, I think, I don't know.
[00:11:09.000 --> 00:11:14.200]   And I certainly don't want to spread the word, but I suspect their lockdown with cuttable
[00:11:14.200 --> 00:11:16.640]   cables would be my guess.
[00:11:16.640 --> 00:11:17.720]   And thieves must know this.
[00:11:17.720 --> 00:11:22.720]   And when it actually shows also as the success of the kill switch because Apple was concerned
[00:11:22.720 --> 00:11:27.240]   about how many iPhones were being stolen out of people's hands out of their pockets and
[00:11:27.240 --> 00:11:31.800]   put it, made it impossible for a thief to take your phone and reuse it.
[00:11:31.800 --> 00:11:34.400]   So now they're stealing them brand new from the Apple store.
[00:11:34.400 --> 00:11:38.480]   I imagine off trucks, anywhere you can get a phone before it's activated.
[00:11:38.480 --> 00:11:39.480]   Yeah.
[00:11:39.480 --> 00:11:40.480]   And there's a lot of this.
[00:11:40.480 --> 00:11:43.520]   This is this one store has been hit twice.
[00:11:43.520 --> 00:11:44.520]   Yeah.
[00:11:44.520 --> 00:11:47.960]   But this in this area in the greater sort of Northern California area, I think there've
[00:11:47.960 --> 00:11:51.960]   been something like 10 or 12 in the last six months or something like that.
[00:11:51.960 --> 00:11:54.480]   It's really become a big deal.
[00:11:54.480 --> 00:11:56.000]   And you know, freaks out the customers.
[00:11:56.000 --> 00:11:59.000]   Apple's got to do something with those phones that are on display.
[00:11:59.000 --> 00:12:01.160]   It doesn't seem like that heart of a problem.
[00:12:01.160 --> 00:12:03.320]   You know, so I haven't heard about this happening on the East.
[00:12:03.320 --> 00:12:04.320]   I'm on the East Coast.
[00:12:04.320 --> 00:12:07.880]   I haven't heard about Apple stores getting hit like in New York or the East Coast is
[00:12:07.880 --> 00:12:08.880]   always behind on technology.
[00:12:08.880 --> 00:12:12.280]   You'll catch up to the stealing stuff on the Apple store thing.
[00:12:12.280 --> 00:12:13.760]   Sizzle.
[00:12:13.760 --> 00:12:21.120]   Well, already just my watch just woke up already see one difference in the extra two millimeters.
[00:12:21.120 --> 00:12:25.960]   The text at the bottom of the screen is now curved around the watch face and set straight.
[00:12:25.960 --> 00:12:26.960]   Definitely worth $500.
[00:12:26.960 --> 00:12:27.960]   I am.
[00:12:27.960 --> 00:12:31.400]   So this is this is part of the frustration I have with the Apple watch too is you don't
[00:12:31.400 --> 00:12:35.320]   think of a watch as something you're going to buy a new one of every year or do you?
[00:12:35.320 --> 00:12:36.320]   I don't know.
[00:12:36.320 --> 00:12:37.320]   Do now.
[00:12:37.320 --> 00:12:42.080]   Well, I mean, we're habituated to waiting for this is the problem quite frankly that I
[00:12:42.080 --> 00:12:45.400]   have with America versus China in America.
[00:12:45.400 --> 00:12:49.560]   We become habituated to the idea that everything must perfectly must work perfectly out of
[00:12:49.560 --> 00:12:52.560]   the box regardless of how new the technology is.
[00:12:52.560 --> 00:12:58.280]   And if a company isn't on some kind of annual product launch cycle, then they've somehow
[00:12:58.280 --> 00:12:59.280]   failed.
[00:12:59.280 --> 00:13:04.520]   I would rather, you know, like Apple's now real everybody's releasing a new, you know,
[00:13:04.520 --> 00:13:08.520]   Apple's releasing a new set of products basically now annually.
[00:13:08.520 --> 00:13:09.520]   And I mean,
[00:13:09.520 --> 00:13:11.120]   This is the Silicon Valley story.
[00:13:11.120 --> 00:13:15.960]   If you don't double every year in growth, if you don't find, you know, this is this
[00:13:15.960 --> 00:13:21.120]   is what and the Silicon Valley brought this upon itself by by such success that the market,
[00:13:21.120 --> 00:13:26.120]   the stock market and consumers and we have the press demand is now.
[00:13:26.120 --> 00:13:30.080]   But if you stop and apply like logic, right, which I know the market doesn't love.
[00:13:30.080 --> 00:13:31.080]   It's unsustainable.
[00:13:31.080 --> 00:13:38.400]   I mean, you know, so listen, I'm like the new app, the new iPhones are such a non that
[00:13:38.400 --> 00:13:40.320]   to me that was the least interesting news.
[00:13:40.320 --> 00:13:41.320]   I agree 100%.
[00:13:41.320 --> 00:13:42.320]   I agree 100%.
[00:13:42.320 --> 00:13:44.640]   In fact, I didn't even mean to get into the subject.
[00:13:44.640 --> 00:13:46.920]   I thought I'd leave it to our Apple shows.
[00:13:46.920 --> 00:13:49.440]   We have Mac break weekly iOS today.
[00:13:49.440 --> 00:13:50.440]   You cannot.
[00:13:50.440 --> 00:13:52.880]   You cannot talk about it.
[00:13:52.880 --> 00:13:54.120]   One that the phones are arriving.
[00:13:54.120 --> 00:13:56.240]   We're starting people started getting their phones yesterday.
[00:13:56.240 --> 00:13:59.200]   Yeah, Friday rather and watches same thing.
[00:13:59.200 --> 00:14:04.600]   The biggest news I thought around the iPhone was that reviewers are saying that the camera
[00:14:04.600 --> 00:14:08.360]   in the iPhone XS.
[00:14:08.360 --> 00:14:09.360]   I love that.
[00:14:09.360 --> 00:14:10.360]   I'm going to use that.
[00:14:10.360 --> 00:14:11.360]   That's hilarious.
[00:14:11.360 --> 00:14:12.840]   They should have a special Johnny Ives.
[00:14:12.840 --> 00:14:14.400]   The XS I've anyway.
[00:14:14.400 --> 00:14:20.800]   So the camera is better than the 10, but not as good as the Pixel 2.
[00:14:20.800 --> 00:14:21.800]   Two.
[00:14:21.800 --> 00:14:22.800]   Last year's Pixel.
[00:14:22.800 --> 00:14:23.800]   Yes.
[00:14:23.800 --> 00:14:28.160]   And in about a week, a month, there's not even that long.
[00:14:28.160 --> 00:14:30.240]   October 9th, there's going to be Pixel 3.
[00:14:30.240 --> 00:14:34.040]   How did Google make a better phone than Apple a year ago?
[00:14:34.040 --> 00:14:37.880]   In general, now I haven't personally, this is not my experience because I haven't tried
[00:14:37.880 --> 00:14:39.880]   it yet, but I love the Pixel 2 camera.
[00:14:39.880 --> 00:14:45.720]   It took a lot of my trip photos with that, but you saw Vlad Savov of the Verge and many
[00:14:45.720 --> 00:14:48.080]   others, Neil I Patel also have the Verge.
[00:14:48.080 --> 00:14:50.720]   Many agreed that it's good.
[00:14:50.720 --> 00:14:51.720]   It's an improvement.
[00:14:51.720 --> 00:14:52.720]   It's a big improvement.
[00:14:52.720 --> 00:14:57.600]   I can see I've seen some pictures that blow me away from the new XS.
[00:14:57.600 --> 00:14:59.360]   The 10s.
[00:14:59.360 --> 00:15:04.800]   But they're doing something that the Pixel did last year, which is take multiple images,
[00:15:04.800 --> 00:15:07.960]   stack them and create HDRs out of them.
[00:15:07.960 --> 00:15:12.000]   And I'm really excited for the upcoming Pixel phones because maybe they'll have a really
[00:15:12.000 --> 00:15:13.000]   amazing camera.
[00:15:13.000 --> 00:15:16.320]   And Google has shown that you'd only need one lens.
[00:15:16.320 --> 00:15:18.320]   Apple's part of their selling point is multiple lenses.
[00:15:18.320 --> 00:15:19.920]   I don't know what the...
[00:15:19.920 --> 00:15:22.200]   Apparently, everything about the Pixel 3 is already leaked out.
[00:15:22.200 --> 00:15:23.200]   Does it have more than one lens?
[00:15:23.200 --> 00:15:24.440]   I think it still has one lens, right?
[00:15:24.440 --> 00:15:25.440]   I can't remember.
[00:15:25.440 --> 00:15:26.440]   I think so.
[00:15:26.440 --> 00:15:27.440]   I think so.
[00:15:27.440 --> 00:15:28.440]   You live in the future.
[00:15:28.440 --> 00:15:29.440]   You probably have one.
[00:15:29.440 --> 00:15:31.440]   What is it going to be next year?
[00:15:31.440 --> 00:15:33.240]   Well, can I just talk...
[00:15:33.240 --> 00:15:38.200]   For me, the biggest news from the Apple announcement was the double SIM card in China.
[00:15:38.200 --> 00:15:43.040]   And here's why I thought that was important because that is a significant form factor
[00:15:43.040 --> 00:15:48.320]   change that's a different kind of engineering that they've basically created a phone specifically
[00:15:48.320 --> 00:15:51.320]   for China's market, which tells us two things.
[00:15:51.320 --> 00:15:56.440]   One, it tells us that China is a big enough economic force that it can compel a company
[00:15:56.440 --> 00:16:02.360]   like Apple now to create an entirely different phone, which is sort of antithetical to Apple's
[00:16:02.360 --> 00:16:04.720]   culture and what it's done all of these years.
[00:16:04.720 --> 00:16:10.200]   But the other thing is that set in the context of the trade war and all of the different
[00:16:10.200 --> 00:16:17.200]   tariffs that are being thrown around, what's so interesting to me is that Apple essentially
[00:16:17.200 --> 00:16:18.960]   is large enough now that it can operate.
[00:16:18.960 --> 00:16:22.160]   It's got enough power and capital.
[00:16:22.160 --> 00:16:24.680]   It effectively operates like its own nation state.
[00:16:24.680 --> 00:16:32.960]   And so Apple has managed to keep itself in China and outside of the skirmishes that are
[00:16:32.960 --> 00:16:38.720]   happening between Beijing and Washington, DC with a phone that's been created specifically
[00:16:38.720 --> 00:16:39.720]   for that market.
[00:16:39.720 --> 00:16:45.200]   So that tells us a bunch of things about what Apple sees as its growth potential for the
[00:16:45.200 --> 00:16:46.200]   future.
[00:16:46.200 --> 00:16:49.800]   It tells us something about China's influence and Apple's influence.
[00:16:49.800 --> 00:16:53.000]   To me, that was like the big story that didn't get enough attention.
[00:16:53.000 --> 00:16:54.800]   Yeah.
[00:16:54.800 --> 00:16:58.520]   And of course you're doing it in an interesting way, unlike other dual sim phones.
[00:16:58.520 --> 00:17:01.320]   Is it only the Chinese model or is it all models that have this?
[00:17:01.320 --> 00:17:03.600]   Yeah, no, it's just the China.
[00:17:03.600 --> 00:17:04.600]   Yeah.
[00:17:04.600 --> 00:17:06.240]   And there's, so I lived in China.
[00:17:06.240 --> 00:17:07.240]   Mike, did you live in China?
[00:17:07.240 --> 00:17:08.240]   I feel like you've lived in China.
[00:17:08.240 --> 00:17:09.800]   I've been there, but haven't.
[00:17:09.800 --> 00:17:14.720]   So there's a lot of people who have two different phone numbers and two different phones for
[00:17:14.720 --> 00:17:15.720]   many different reasons.
[00:17:15.720 --> 00:17:19.720]   And dual sim phones are very popular and a lot of times it's because that's our only
[00:17:19.720 --> 00:17:20.720]   computer.
[00:17:20.720 --> 00:17:21.720]   That phone is their whole business.
[00:17:21.720 --> 00:17:25.320]   But also their regions, not just in China but in India and other places where it's not
[00:17:25.320 --> 00:17:29.000]   uncommon to go from one carrier to another even in a short trip.
[00:17:29.000 --> 00:17:31.280]   So having multiple sims is practical.
[00:17:31.280 --> 00:17:36.340]   I would love one because I would love to have Google Fi in one of the sim cards and
[00:17:36.340 --> 00:17:38.800]   then the regular Apple sim thing and the other.
[00:17:38.800 --> 00:17:39.800]   Yeah.
[00:17:39.800 --> 00:17:40.800]   That'd be great.
[00:17:40.800 --> 00:17:41.800]   I'd love that.
[00:17:41.800 --> 00:17:42.800]   The chance of Google Fi supporting an iPhone.
[00:17:42.800 --> 00:17:44.640]   I'm going to go to China and buy one small.
[00:17:44.640 --> 00:17:45.640]   Yeah.
[00:17:45.640 --> 00:17:47.680]   Well, you can put a card into it.
[00:17:47.680 --> 00:17:48.680]   It becomes a T-Mobile phone.
[00:17:48.680 --> 00:17:49.680]   It basically experiences.
[00:17:49.680 --> 00:17:50.680]   Right.
[00:17:50.680 --> 00:17:51.680]   It's the same.
[00:17:51.680 --> 00:17:52.680]   I believe it's the same.
[00:17:52.680 --> 00:17:53.680]   It's the same.
[00:17:53.680 --> 00:17:57.720]   You don't get the multiple carrier thing in the US if you put a Google Fi sim into an
[00:17:57.720 --> 00:17:58.720]   Apple device.
[00:17:58.720 --> 00:18:01.000]   But if you're abroad, I think you get most of the benefits.
[00:18:01.000 --> 00:18:04.080]   That is something I can report back on by the way from my travels.
[00:18:04.080 --> 00:18:05.680]   You probably already experienced this.
[00:18:05.680 --> 00:18:07.120]   But it's really different.
[00:18:07.120 --> 00:18:11.720]   What's happened with Internet access, for instance, Europe now has the law that makes
[00:18:11.720 --> 00:18:15.280]   roaming universal throughout the EU.
[00:18:15.280 --> 00:18:16.640]   So one sim does it all.
[00:18:16.640 --> 00:18:19.840]   In fact, I was talking something from the UK which is I think Brexiting at the moment.
[00:18:19.840 --> 00:18:23.960]   But even then they could buy a sim from three or somebody in the UK that works everywhere
[00:18:23.960 --> 00:18:25.200]   in Europe without roaming.
[00:18:25.200 --> 00:18:26.200]   In effect.
[00:18:26.200 --> 00:18:27.200]   It's active.
[00:18:27.200 --> 00:18:29.520]   And that's what our Google Fi sim does.
[00:18:29.520 --> 00:18:31.320]   It's just local.
[00:18:31.320 --> 00:18:34.920]   And I used, by the way, I used so much Google Fi as always traveling.
[00:18:34.920 --> 00:18:39.620]   I got to that six gigabit limit where they say, "Okay, we're going to stop billing you
[00:18:39.620 --> 00:18:40.620]   now."
[00:18:40.620 --> 00:18:41.620]   Which is great.
[00:18:41.620 --> 00:18:43.320]   I used a lot of data.
[00:18:43.320 --> 00:18:45.520]   I don't know if it was super fast, but it was fast enough.
[00:18:45.520 --> 00:18:47.520]   Don't you love that message they give you?
[00:18:47.520 --> 00:18:48.520]   They're like, "You know what?
[00:18:48.520 --> 00:18:50.400]   I used up all the things, so the rest of it is on us.
[00:18:50.400 --> 00:18:51.400]   So you're going to pay for all of it."
[00:18:51.400 --> 00:18:54.920]   So it never goes more than 60 bucks a month for unlimited data.
[00:18:54.920 --> 00:18:56.880]   Plus 20 for the monthly amounts.
[00:18:56.880 --> 00:18:58.040]   So say 80 bucks?
[00:18:58.040 --> 00:18:59.040]   Yeah.
[00:18:59.040 --> 00:19:05.400]   I also use T-Mobile and I pay for T-Mobile has an international plan which gives you 256
[00:19:05.400 --> 00:19:08.200]   kilobits per second instead of 120 kilobits per second.
[00:19:08.200 --> 00:19:10.200]   It's a difference.
[00:19:10.200 --> 00:19:14.240]   But actually it's a difference and it's enough that it's pretty usable.
[00:19:14.240 --> 00:19:17.760]   And even, this was a fairly, a cruise ship that had been built in the last two years.
[00:19:17.760 --> 00:19:22.000]   And it had pretty much better in it than I experienced in the older ships.
[00:19:22.000 --> 00:19:29.360]   So it's getting, as you travel, ubiquitous internet is becoming more and more the thing
[00:19:29.360 --> 00:19:31.240]   at a reasonable price.
[00:19:31.240 --> 00:19:32.240]   That's a nice improvement in general.
[00:19:32.240 --> 00:19:33.640]   I want to take a little break.
[00:19:33.640 --> 00:19:37.200]   When we come back, I've been gone a long time.
[00:19:37.200 --> 00:19:38.600]   I don't know what the hell happened.
[00:19:38.600 --> 00:19:45.360]   So I have charged both Amy and Mike to tell me the big stories of the last three weeks.
[00:19:45.360 --> 00:19:46.720]   Amy's got two, Mike's got one.
[00:19:46.720 --> 00:19:49.400]   What were the stories that I missed?
[00:19:49.400 --> 00:19:53.360]   And then Carson's pulled a few stories and I even found a few, including one from a heart
[00:19:53.360 --> 00:19:57.240]   doctor that says, "If you trust your life to the Apple Watch, you're nuts."
[00:19:57.240 --> 00:20:00.640]   We'll get to that in just a second.
[00:20:00.640 --> 00:20:05.960]   I have a little problem because I'm going to go home after the show and I know my family's
[00:20:05.960 --> 00:20:07.360]   going to say, "What's for dinner?"
[00:20:07.360 --> 00:20:09.640]   So I haven't gone three weeks.
[00:20:09.640 --> 00:20:12.120]   Thank goodness there's a blue apron awaiting me.
[00:20:12.120 --> 00:20:21.360]   Blue apron is the number one meal delivery service in the nation.
[00:20:21.360 --> 00:20:26.680]   They deliver fresh, seasonally inspired, pre-portion ingredients with the recipe.
[00:20:26.680 --> 00:20:27.680]   So you don't have to shop.
[00:20:27.680 --> 00:20:28.680]   You don't have to menu plan.
[00:20:28.680 --> 00:20:30.120]   You don't have to meal plan.
[00:20:30.120 --> 00:20:31.440]   They're seasonally inspired.
[00:20:31.440 --> 00:20:32.440]   They're always fresh.
[00:20:32.440 --> 00:20:34.400]   They're delicious.
[00:20:34.400 --> 00:20:35.880]   And what a range of recipes.
[00:20:35.880 --> 00:20:39.320]   I've been now, one of the things they're doing, which I really love.
[00:20:39.320 --> 00:20:43.080]   They have celebrity chefs, celebrity recipes.
[00:20:43.080 --> 00:20:44.560]   I was doing some Chrissy Teigen.
[00:20:44.560 --> 00:20:46.880]   I mean, she's a good cook.
[00:20:46.880 --> 00:20:50.400]   Whether you're looking for quick and easy meals or a full culinary cooking experience,
[00:20:50.400 --> 00:20:54.000]   blue apron, let's you choose from a range of recipe options.
[00:20:54.000 --> 00:21:00.840]   I know our audience will love the Bob's burger inspired recipe collection.
[00:21:00.840 --> 00:21:01.840]   Crazy.
[00:21:01.840 --> 00:21:02.840]   These are great.
[00:21:02.840 --> 00:21:05.200]   And the whole 30 approved recipes.
[00:21:05.200 --> 00:21:07.120]   How about crispy chicken tenders tonight?
[00:21:07.120 --> 00:21:09.920]   Mashed potatoes with butter, lettuce, and ranch dressing.
[00:21:09.920 --> 00:21:10.920]   Okay.
[00:21:10.920 --> 00:21:13.440]   Or they always have vegetarian options too.
[00:21:13.440 --> 00:21:16.800]   Posten creamy tomato sauce with summer vegetables.
[00:21:16.800 --> 00:21:18.560]   Blue apron's really awesome.
[00:21:18.560 --> 00:21:22.480]   Every week we go, we pick because you get a bunch to choose from.
[00:21:22.480 --> 00:21:24.000]   The recipes don't repeat very often.
[00:21:24.000 --> 00:21:27.880]   I think once a year at most, so you can always get something new and different and exciting.
[00:21:27.880 --> 00:21:33.880]   You're going to learn how to cook things like sweet and spicy oodon noodles or cool.
[00:21:33.880 --> 00:21:34.880]   What is it?
[00:21:34.880 --> 00:21:35.880]   Oh, look at that.
[00:21:35.880 --> 00:21:36.880]   What's the other one next to that?
[00:21:36.880 --> 00:21:40.920]   Codd and coconut in a curry bowl.
[00:21:40.920 --> 00:21:41.920]   Oh man.
[00:21:41.920 --> 00:21:44.200]   See, if you want to go exotic, you can.
[00:21:44.200 --> 00:21:45.200]   That's the nice thing.
[00:21:45.200 --> 00:21:46.480]   This is, it's your choice.
[00:21:46.480 --> 00:21:50.060]   You get to, they have kid friendly recipes for the family plan.
[00:21:50.060 --> 00:21:52.720]   Check out this week's menu and you'll get your first three meals free when you go to
[00:21:52.720 --> 00:21:54.280]   blue apron.com/twit.
[00:21:54.280 --> 00:21:58.080]   Very, see this is those the step by step instructions.
[00:21:58.080 --> 00:21:59.040]   Very easy to do.
[00:21:59.040 --> 00:22:01.320]   Blue apron.com/twit.
[00:22:01.320 --> 00:22:05.120]   Your first three meals on us.
[00:22:05.120 --> 00:22:07.120]   That's the best way to get started.
[00:22:07.120 --> 00:22:11.360]   And check out the, even if, you know, you just want to go and look at it, check out
[00:22:11.360 --> 00:22:15.360]   the recipes, the celebrity recipes, the Bob's Burger inspired recipes.
[00:22:15.360 --> 00:22:17.480]   That's so much fun.
[00:22:17.480 --> 00:22:18.480]   Blue apron.com/twit.
[00:22:18.480 --> 00:22:21.560]   I haven't decided what I'm cooking tonight, but I don't have to worry about it because
[00:22:21.560 --> 00:22:22.560]   I get home.
[00:22:22.560 --> 00:22:23.560]   It's all there.
[00:22:23.560 --> 00:22:24.560]   It's all ready.
[00:22:24.560 --> 00:22:26.560]   It's much better than the family guy inspired recipes.
[00:22:26.560 --> 00:22:29.560]   In the Sims terrible, yeah, the Sims insides.
[00:22:29.560 --> 00:22:30.560]   American cheese.
[00:22:30.560 --> 00:22:35.080]   It's kind of funny that Bob's burgers has recipes.
[00:22:35.080 --> 00:22:36.080]   And they're great.
[00:22:36.080 --> 00:22:37.080]   They're hysterical to burgers.
[00:22:37.080 --> 00:22:40.120]   Some of those Bob's burgers recipes on the show look really good.
[00:22:40.120 --> 00:22:41.120]   Don't they?
[00:22:41.120 --> 00:22:42.120]   Yeah.
[00:22:42.120 --> 00:22:43.120]   Yeah.
[00:22:43.120 --> 00:22:44.120]   Crazy.
[00:22:44.120 --> 00:22:45.120]   Yeah, I'd eat some of those burgers.
[00:22:45.120 --> 00:22:46.120]   Yeah, for sure.
[00:22:46.120 --> 00:22:47.120]   Okay.
[00:22:47.120 --> 00:22:48.120]   Okay.
[00:22:48.120 --> 00:22:49.120]   I'll just mention this.
[00:22:49.120 --> 00:22:53.000]   I'm a heart doctor and wary of the new Apple Watch because I mentioned it going in and
[00:22:53.000 --> 00:22:56.920]   we're going to get your stories that I may have missed.
[00:22:56.920 --> 00:22:58.600]   This is actually an interesting point.
[00:22:58.600 --> 00:23:03.240]   We talk a lot about Apple and their reality distortion field, their amazing marketing.
[00:23:03.240 --> 00:23:04.760]   And I celebrate that.
[00:23:04.760 --> 00:23:05.760]   Every company has to market.
[00:23:05.760 --> 00:23:06.760]   We have to market.
[00:23:06.760 --> 00:23:07.920]   That's fine.
[00:23:07.920 --> 00:23:13.760]   Where it gets problematic is where Apple starts to market to the detriment of people's health.
[00:23:13.760 --> 00:23:18.080]   Now, I think it's very interesting that one of the things Apple's doing in these new
[00:23:18.080 --> 00:23:25.280]   watches is you can do the AFib style EKG that Cardia and other companies are doing.
[00:23:25.280 --> 00:23:29.240]   It's FDA approved, but it's two terminals, right?
[00:23:29.240 --> 00:23:34.160]   One terminal is your wrist, one terminal is the knob as opposed to a 12 terminal full
[00:23:34.160 --> 00:23:36.440]   EKG that you would get in the hospital.
[00:23:36.440 --> 00:23:42.160]   That means it is not as accurate, but more importantly, this physician he's writing on
[00:23:42.160 --> 00:23:54.760]   medium, Dr. Joe Mandrola says, even with the 12 sensor EKGs, we get about 10% false positives.
[00:23:54.760 --> 00:24:01.080]   And that's an issue because that means 10% of the time in irregular rhythm, which is normal,
[00:24:01.080 --> 00:24:09.920]   everybody, people have irregular rhythms, are falsely labeled as AFib, which means medication,
[00:24:09.920 --> 00:24:12.400]   means treatment, means serious.
[00:24:12.400 --> 00:24:17.680]   He has an issue, and I think a lot of physicians do, with testing a healthy population, just
[00:24:17.680 --> 00:24:24.080]   testing everybody without indication that something should be tested.
[00:24:24.080 --> 00:24:25.080]   So he's wrong.
[00:24:25.080 --> 00:24:26.080]   He's wrong.
[00:24:26.080 --> 00:24:27.080]   He's wrong.
[00:24:27.080 --> 00:24:29.240]   But that also cuts into a lot of...
[00:24:29.240 --> 00:24:34.440]   He says when you endeavor to make healthy people healthier, you always risk making them
[00:24:34.440 --> 00:24:35.440]   worse.
[00:24:35.440 --> 00:24:36.720]   Here's the thing though.
[00:24:36.720 --> 00:24:42.120]   You cannot in the United States request diagnostics on your own.
[00:24:42.120 --> 00:24:43.920]   So I'm married to an eye doctor.
[00:24:43.920 --> 00:24:49.840]   So one of the ways that every doctor, because of how our billing system is set up in the
[00:24:49.840 --> 00:24:53.760]   US, the way that they earn a living is through some of those diagnostics.
[00:24:53.760 --> 00:24:58.880]   Now at the moment, you could make an argument that way too much data is not a good thing
[00:24:58.880 --> 00:25:00.560]   because there's no way to interpret it.
[00:25:00.560 --> 00:25:04.880]   On the other hand, if we don't continue...
[00:25:04.880 --> 00:25:06.360]   The more...
[00:25:06.360 --> 00:25:09.920]   Those diagnostics are important to do when you're healthy, not just when you're having
[00:25:09.920 --> 00:25:15.280]   a crisis, because it helps you set baseline, you can track trends over time.
[00:25:15.280 --> 00:25:18.320]   We don't have a system set up in the United States to do that without going into your
[00:25:18.320 --> 00:25:19.320]   doctor.
[00:25:19.320 --> 00:25:20.320]   The thing is that it's...
[00:25:20.320 --> 00:25:22.760]   It's a huge opening.
[00:25:22.760 --> 00:25:28.200]   But there is a difference here because now a consumer device is pretending or even accurately
[00:25:28.200 --> 00:25:32.120]   saying, "We're going to do some diagnostics here."
[00:25:32.120 --> 00:25:35.320]   That means many millions more people will now get these tests.
[00:25:35.320 --> 00:25:36.720]   But there's no harm in it.
[00:25:36.720 --> 00:25:37.720]   The reason is that...
[00:25:37.720 --> 00:25:38.720]   Well that's the question, isn't there?
[00:25:38.720 --> 00:25:44.640]   There isn't because basically, first of all, my heart doesn't belong to my doctor, belongs
[00:25:44.640 --> 00:25:45.640]   my wife.
[00:25:45.640 --> 00:25:48.560]   That's a good point.
[00:25:48.560 --> 00:25:54.880]   If I want some help because I'm a geek to make the decision about whether I go to the doctor
[00:25:54.880 --> 00:25:55.880]   and say, "You know what?
[00:25:55.880 --> 00:25:57.040]   I'm concerned about my heart."
[00:25:57.040 --> 00:25:58.520]   This is what this is for.
[00:25:58.520 --> 00:26:02.800]   Nobody's going to prescribe medication or treatment based on the Apple Watch.
[00:26:02.800 --> 00:26:03.800]   Nobody.
[00:26:03.800 --> 00:26:07.320]   You still get hooked up to the big EKG.
[00:26:07.320 --> 00:26:08.400]   That's why there's no harm.
[00:26:08.400 --> 00:26:14.920]   It's simply a decision-making tool for people to decide whether to choose to go to the doctor
[00:26:14.920 --> 00:26:16.280]   or not go to the doctor.
[00:26:16.280 --> 00:26:19.120]   In some cases, choose to go to the emergency room or not.
[00:26:19.120 --> 00:26:21.880]   I don't see the harm that.
[00:26:21.880 --> 00:26:22.880]   It seems to me that...
[00:26:22.880 --> 00:26:27.960]   So you're saying in a way, this is the medical industry saying, "We want to protect our monopoly."
[00:26:27.960 --> 00:26:29.880]   That's what I'm saying.
[00:26:29.880 --> 00:26:31.120]   They suffer a lot.
[00:26:31.120 --> 00:26:35.280]   Doctors, the medical profession, suffers a lot from people self-diagnosing.
[00:26:35.280 --> 00:26:36.960]   Going on to WebMD and saying, "You know what?
[00:26:36.960 --> 00:26:41.000]   I think I have a wooden leg or something."
[00:26:41.000 --> 00:26:44.560]   Whatever it is that the people decide that they have, and then they argue with the...
[00:26:44.560 --> 00:26:45.560]   I saw it on the internet.
[00:26:45.560 --> 00:26:48.040]   This is definitely a wooden leg.
[00:26:48.040 --> 00:26:49.040]   Exactly.
[00:26:49.040 --> 00:26:55.960]   There are legitimate reasons to not want all of that testing because, again, our system
[00:26:55.960 --> 00:26:59.440]   in the United States is not really set up to deal with all that data.
[00:26:59.440 --> 00:27:04.080]   On the other hand, we really only work on diagnostics in this country when people are
[00:27:04.080 --> 00:27:05.080]   sick.
[00:27:05.080 --> 00:27:06.080]   Yeah.
[00:27:06.080 --> 00:27:08.200]   And then we're really only dealing with...
[00:27:08.200 --> 00:27:10.200]   It's a very small percentage of the population.
[00:27:10.200 --> 00:27:14.840]   So the bigger picture that I think everybody's missing is what this portends.
[00:27:14.840 --> 00:27:21.080]   I mean, Apple is launching a clinic somewhere in all of the big nine.
[00:27:21.080 --> 00:27:27.480]   It's all of the Apple, Amazon, Google.
[00:27:27.480 --> 00:27:28.880]   They're all getting into the health space.
[00:27:28.880 --> 00:27:30.640]   They're all launching different products.
[00:27:30.640 --> 00:27:37.960]   It's very, very likely that we are moving into a future in which we have a single record
[00:27:37.960 --> 00:27:42.760]   that's probably owned by one of these companies that includes our health data, which has a
[00:27:42.760 --> 00:27:48.560]   lot of promise and will improve our lives in a lot of ways.
[00:27:48.560 --> 00:27:53.800]   But it also means that there's going to be cataclysmic change in the health and medical
[00:27:53.800 --> 00:27:56.040]   and pharmaceutical industries.
[00:27:56.040 --> 00:28:03.160]   It's a certainty that consumer devices will actually be connected in various ways to the
[00:28:03.160 --> 00:28:07.920]   medical system in a more reliable way that's super...
[00:28:07.920 --> 00:28:09.680]   We're going to apply AI to that.
[00:28:09.680 --> 00:28:13.920]   That's going to be the biggest step forward for health where AI will be able to say, "You
[00:28:13.920 --> 00:28:14.920]   know what?
[00:28:14.920 --> 00:28:19.120]   This ECG passes all the tests, but you know what?
[00:28:19.120 --> 00:28:25.160]   Based on this AI analysis, we determined that 45% of people who have this exact same pattern
[00:28:25.160 --> 00:28:28.840]   end up doing XYZ, it's going to be really fantastic."
[00:28:28.840 --> 00:28:34.400]   So this is basically just a baby step toward that inevitable future when we are going to
[00:28:34.400 --> 00:28:35.520]   be wired all the time.
[00:28:35.520 --> 00:28:41.440]   And this data will be available to our doctors and there will be relying on it a lot more.
[00:28:41.440 --> 00:28:44.800]   It might be five years, it might be 25 years, but we're going to get there.
[00:28:44.800 --> 00:28:47.720]   Well, it's going to be closer to the man.
[00:28:47.720 --> 00:28:48.720]   We already...
[00:28:48.720 --> 00:28:54.600]   All of the big companies have flooded the patent and trademark office with many, many
[00:28:54.600 --> 00:29:02.040]   different patents that describe earbble devices, hearing devices that also collect biometrics,
[00:29:02.040 --> 00:29:05.920]   thin films that you would wear that also transmit information.
[00:29:05.920 --> 00:29:10.760]   We're quickly on our path in that direction.
[00:29:10.760 --> 00:29:19.040]   The real challenge is that LabCorp, we're not really set up for the innovations that are
[00:29:19.040 --> 00:29:20.040]   coming.
[00:29:20.040 --> 00:29:22.520]   The future is not evenly distributed.
[00:29:22.520 --> 00:29:28.080]   Only a tiny percentage can afford or are aware of these devices.
[00:29:28.080 --> 00:29:29.480]   You mentioned, what is it?
[00:29:29.480 --> 00:29:32.120]   It's a Vic and Dottra's company.
[00:29:32.120 --> 00:29:33.120]   What is it?
[00:29:33.120 --> 00:29:34.120]   Cardia.
[00:29:34.120 --> 00:29:35.120]   Yeah, Cardia.
[00:29:35.120 --> 00:29:36.120]   K-A-R-D-I-N.
[00:29:36.120 --> 00:29:40.320]   You could go out in Petaluma and accost people on the street and ask them if they've ever
[00:29:40.320 --> 00:29:43.600]   heard of that product, guaranteed that 99% of them have never heard of it.
[00:29:43.600 --> 00:29:48.600]   You know who uses one is somebody who has been diagnosed with AFib, which is Jeff Jarvis.
[00:29:48.600 --> 00:29:51.840]   And he went out and bought it from a live core, a livecore.com.
[00:29:51.840 --> 00:29:53.320]   Went out and bought it.
[00:29:53.320 --> 00:29:56.760]   It basically works the same way the Apple Watch does, except that you have a separate
[00:29:56.760 --> 00:29:59.560]   set of pads that can work with an Android device as well.
[00:29:59.560 --> 00:30:04.440]   And from his point of view, it's a lifesaver because if he feels an irregularity or he
[00:30:04.440 --> 00:30:09.720]   wants to just make sure he's okay, if he's feeling poorly, he can at least get a quick
[00:30:09.720 --> 00:30:13.200]   diagnosis that allows him then to send that to the doctor.
[00:30:13.200 --> 00:30:17.760]   And I have to say, if you've already been diagnosed, I can see the real value of that.
[00:30:17.760 --> 00:30:22.680]   But I also see the point that this heart doctor is making that now millions of people, it's
[00:30:22.680 --> 00:30:24.360]   a hypochondriac stream.
[00:30:24.360 --> 00:30:26.520]   Well, or also the cure.
[00:30:26.520 --> 00:30:29.840]   I mean, a lot of people think, well, I think I either had a heart attack or it's the in
[00:30:29.840 --> 00:30:31.000]   an outburger at just eight.
[00:30:31.000 --> 00:30:32.000]   I'm not sure.
[00:30:32.000 --> 00:30:33.000]   And then, you know, it can.
[00:30:33.000 --> 00:30:34.920]   If I could just ask Siri.
[00:30:34.920 --> 00:30:35.920]   Yeah, exactly.
[00:30:35.920 --> 00:30:40.760]   By the way, I am pissed off and I don't know if this is true or not.
[00:30:40.760 --> 00:30:46.760]   But the NFL, I was watching the Niners game this morning and the NFL ran an ad that said,
[00:30:46.760 --> 00:30:49.440]   hey, slow mo.
[00:30:49.440 --> 00:30:51.680]   What are the scores in the NFL today?
[00:30:51.680 --> 00:30:59.440]   And my home hub, I went off and talked for five minutes about the scores and I was miffed.
[00:30:59.440 --> 00:31:00.440]   That should be illegal.
[00:31:00.440 --> 00:31:01.440]   Yeah.
[00:31:01.440 --> 00:31:02.440]   Wow.
[00:31:02.440 --> 00:31:03.440]   I thought that that what they weren't doing.
[00:31:03.440 --> 00:31:04.440]   I thought that was an FCC.
[00:31:04.440 --> 00:31:06.400]   It could be.
[00:31:06.400 --> 00:31:07.400]   Yeah.
[00:31:07.400 --> 00:31:12.000]   We have diagnostic devices in our homes that at one point were just as controversial as
[00:31:12.000 --> 00:31:14.680]   the Apple Watch thermometers.
[00:31:14.680 --> 00:31:17.520]   I had that's a good point.
[00:31:17.520 --> 00:31:22.520]   The first came out, you know, like.
[00:31:22.520 --> 00:31:26.640]   People should not be able to find out what their temperature is.
[00:31:26.640 --> 00:31:28.880]   It's just going to cause more calls.
[00:31:28.880 --> 00:31:30.640]   No, but it was the same.
[00:31:30.640 --> 00:31:34.080]   I mean, obviously not at that point, but it was the same sentiment.
[00:31:34.080 --> 00:31:42.640]   So what we're butting up here against is change that puts that empowers the masses and,
[00:31:42.640 --> 00:31:50.080]   you know, takes away some of the purview of a small group of people, you know, previously,
[00:31:50.080 --> 00:31:53.920]   who were the only ones allowed to get and gather that information.
[00:31:53.920 --> 00:31:56.880]   So which is for another period of transition.
[00:31:56.880 --> 00:32:02.440]   But every like, like, we can certainly talk about the watch and about AFib and everything
[00:32:02.440 --> 00:32:03.440]   else.
[00:32:03.440 --> 00:32:04.440]   But this is a tiny sliver.
[00:32:04.440 --> 00:32:08.800]   I mean, every like every company now is working on a suite of products, including Apple, the
[00:32:08.800 --> 00:32:10.800]   watch is just a tiny piece of it.
[00:32:10.800 --> 00:32:11.800]   Yeah.
[00:32:11.800 --> 00:32:14.800]   I want a device that measures the caffeine content in my bloodstream.
[00:32:14.800 --> 00:32:17.760]   So I know, oh, I better better have another.
[00:32:17.760 --> 00:32:20.840]   I can't talk about it yet, but I think soon I'll be able to talk about this ring, which
[00:32:20.840 --> 00:32:24.240]   I were in the whole trip that does do a lot of diagnostic stuff.
[00:32:24.240 --> 00:32:25.240]   You used a word.
[00:32:25.240 --> 00:32:26.240]   I like this word.
[00:32:26.240 --> 00:32:27.240]   Did you coin the word?
[00:32:27.240 --> 00:32:28.240]   Irrible.
[00:32:28.240 --> 00:32:29.840]   I think I did, but.
[00:32:29.840 --> 00:32:30.840]   Irrible or terrible?
[00:32:30.840 --> 00:32:31.840]   It's not a wearable.
[00:32:31.840 --> 00:32:32.840]   I say, you're a ball.
[00:32:32.840 --> 00:32:35.840]   Now this is something that you put in here.
[00:32:35.840 --> 00:32:36.840]   Yeah.
[00:32:36.840 --> 00:32:37.840]   Yeah.
[00:32:37.840 --> 00:32:38.840]   Yeah.
[00:32:38.840 --> 00:32:43.880]   I've got right now a response, so I've got a very awesome set of wireless Bluetooth headphones
[00:32:43.880 --> 00:32:47.800]   that respond to gesture, touch and speech.
[00:32:47.800 --> 00:32:52.760]   So I can, you know, but the all everything that I've seen that's coming also collects
[00:32:52.760 --> 00:32:59.640]   your biometric data for transmission to something like a health kit or, you know, Google's
[00:32:59.640 --> 00:33:00.640]   talk about whatever.
[00:33:00.640 --> 00:33:01.640]   Yeah.
[00:33:01.640 --> 00:33:05.000]   Well, this goes to health kit, but also this is interesting.
[00:33:05.000 --> 00:33:06.000]   I haven't seen this before.
[00:33:06.000 --> 00:33:07.000]   Is it two-way street?
[00:33:07.000 --> 00:33:08.680]   It takes from health kit as well.
[00:33:08.680 --> 00:33:13.680]   So I can't talk about it yet because the guy who's selling these created this said we're
[00:33:13.680 --> 00:33:17.800]   not ready yet, but I'll be doing a review, but it gives you your, it says my readiness
[00:33:17.800 --> 00:33:18.800]   is low.
[00:33:18.800 --> 00:33:19.800]   Thank you.
[00:33:19.800 --> 00:33:20.800]   The show?
[00:33:20.800 --> 00:33:21.800]   Ready for what?
[00:33:21.800 --> 00:33:22.800]   Readiness low.
[00:33:22.800 --> 00:33:23.800]   Ready for everything.
[00:33:23.800 --> 00:33:24.800]   Yeah.
[00:33:24.800 --> 00:33:27.240]   What are you not ready for?
[00:33:27.240 --> 00:33:28.240]   Anything.
[00:33:28.240 --> 00:33:29.240]   That's a good question.
[00:33:29.240 --> 00:33:31.000]   He's not ready for the data.
[00:33:31.000 --> 00:33:32.720]   Yesterday, it was take it easy.
[00:33:32.720 --> 00:33:35.240]   The day before great work by readiness was high.
[00:33:35.240 --> 00:33:36.240]   Wow.
[00:33:36.240 --> 00:33:37.760]   The day before take it slow.
[00:33:37.760 --> 00:33:39.520]   The day before balance is key.
[00:33:39.520 --> 00:33:40.840]   That's when you were on the camel.
[00:33:40.840 --> 00:33:41.840]   That's the camel.
[00:33:41.840 --> 00:33:42.840]   You saw the camel.
[00:33:42.840 --> 00:33:43.840]   So there's digital whispering.
[00:33:43.840 --> 00:33:49.440]   What it's doing, I think what it's measuring is heart rate variability, which is a, I told
[00:33:49.440 --> 00:33:50.520]   a key indicator.
[00:33:50.520 --> 00:33:55.880]   You were having fun and the rest of us were struggling in the digital information minds.
[00:33:55.880 --> 00:34:03.200]   Did you hear that, that Jack Dorsey published his heart rate through his based on Twitter?
[00:34:03.200 --> 00:34:04.200]   Yeah.
[00:34:04.200 --> 00:34:07.280]   While he was in the center hearings, he said, well, here's this question.
[00:34:07.280 --> 00:34:08.280]   Look at my heart.
[00:34:08.280 --> 00:34:09.280]   Oh, that's hysterical.
[00:34:09.280 --> 00:34:10.280]   Isn't that amazing?
[00:34:10.280 --> 00:34:13.760]   No, the hysterical part is that his resting heart rate like matches Lance Armstrong's.
[00:34:13.760 --> 00:34:16.920]   He's got like one beat, one and a half beats per minute.
[00:34:16.920 --> 00:34:19.080]   It's like a ridiculously low number.
[00:34:19.080 --> 00:34:20.080]   Yeah.
[00:34:20.080 --> 00:34:21.680]   Well, he looks like a meditator type guy.
[00:34:21.680 --> 00:34:29.480]   I think when we should plot income against heart, resting heart rate, because I guarantee
[00:34:29.480 --> 00:34:33.160]   you the more money you have, the better your resting heart rate is.
[00:34:33.160 --> 00:34:36.600]   I don't know why, but I just feel like there is a correlation.
[00:34:36.600 --> 00:34:40.040]   It feels like the rich are in better shape than the rest of us.
[00:34:40.040 --> 00:34:43.000]   I also wanted to see Alex Jones's heart rate.
[00:34:43.000 --> 00:34:44.880]   He does not look healthy.
[00:34:44.880 --> 00:34:45.880]   He does not look healthy.
[00:34:45.880 --> 00:34:46.880]   No, he does not.
[00:34:46.880 --> 00:34:48.960]   But maybe he's because he's apoplectically read all the time.
[00:34:48.960 --> 00:34:50.480]   I don't know, but he does not look healthy.
[00:34:50.480 --> 00:34:51.960]   Did you watch to say something?
[00:34:51.960 --> 00:34:53.360]   I think you're watching somebody.
[00:34:53.360 --> 00:34:54.360]   I think I heard something.
[00:34:54.360 --> 00:34:55.720]   It was Alex Jones.
[00:34:55.720 --> 00:34:58.880]   People are talking all the time now in my house everywhere I go.
[00:34:58.880 --> 00:35:01.880]   My poor wife, she said, there was something talking in your office.
[00:35:01.880 --> 00:35:02.880]   And I tried everything.
[00:35:02.880 --> 00:35:04.840]   I said, hey, well, hey Amazon.
[00:35:04.840 --> 00:35:09.600]   I couldn't figure out which device was giving me that information.
[00:35:09.600 --> 00:35:14.520]   All right, I said, and I want to do this, I said, I would ask you guys, what did I miss?
[00:35:14.520 --> 00:35:16.160]   This should be a new feature.
[00:35:16.160 --> 00:35:18.360]   I'm going to make this every week.
[00:35:18.360 --> 00:35:20.600]   Carson, let's do this every week.
[00:35:20.600 --> 00:35:22.560]   So now I don't have to read the tech news anymore.
[00:35:22.560 --> 00:35:24.200]   What did I miss this week?
[00:35:24.200 --> 00:35:25.200]   Mike Elgin.
[00:35:25.200 --> 00:35:31.520]   Okay, so Elon Musk is going to launch a Japanese punk rock billionaire into space.
[00:35:31.520 --> 00:35:32.920]   I saw that.
[00:35:32.920 --> 00:35:34.520]   And the, I didn't know it was a punk rocker.
[00:35:34.520 --> 00:35:36.200]   He was a, he's a punk rocker.
[00:35:36.200 --> 00:35:38.040]   He actually had a successful punk rock band.
[00:35:38.040 --> 00:35:39.040]   Wow.
[00:35:39.040 --> 00:35:42.240]   Before he was a billionaire, then he launched a clothing, digital clothing company.
[00:35:42.240 --> 00:35:43.240]   Yeah.
[00:35:43.240 --> 00:35:44.960]   You, you, Saku, Maizawa.
[00:35:44.960 --> 00:35:45.960]   Is that right?
[00:35:45.960 --> 00:35:46.960]   That's right.
[00:35:46.960 --> 00:35:47.960]   Yeah.
[00:35:47.960 --> 00:35:48.960]   I know.
[00:35:48.960 --> 00:35:49.960]   Saku, Maizawa.
[00:35:49.960 --> 00:35:57.080]   Anyway, so he's, it's interesting because we, we, if you look back at the things we thought
[00:35:57.080 --> 00:36:02.600]   were important from like 15 years ago, oh my God, the Palm Pilot is the most, you know,
[00:36:02.600 --> 00:36:03.760]   they weren't that important.
[00:36:03.760 --> 00:36:10.400]   But launching tourists into space, this is a big change for what human beings do.
[00:36:10.400 --> 00:36:11.400]   Yeah.
[00:36:11.400 --> 00:36:13.960]   And by the way, just by one seat, he bought the whole rocket.
[00:36:13.960 --> 00:36:14.960]   He's an art fan.
[00:36:14.960 --> 00:36:19.920]   He's going to bring a bunch of artists, which, you know, into space, which, you know, I guess
[00:36:19.920 --> 00:36:23.160]   they're pleasant enough people, artists.
[00:36:23.160 --> 00:36:27.120]   But what was funny about during the press conference is that Elon Musk is like, he
[00:36:27.120 --> 00:36:28.200]   knows it's dangerous.
[00:36:28.200 --> 00:36:30.120]   He knows he's probably going to die.
[00:36:30.120 --> 00:36:31.120]   And he came to us with him.
[00:36:31.120 --> 00:36:32.120]   He got to him.
[00:36:32.120 --> 00:36:33.120]   He came to us.
[00:36:33.120 --> 00:36:34.120]   He's probably going to die.
[00:36:34.120 --> 00:36:35.120]   I didn't hear that.
[00:36:35.120 --> 00:36:37.320]   No, I'm exaggerating for comic effect.
[00:36:37.320 --> 00:36:41.320]   Basically, Elon Musk goes, he knows this is a very dangerous thing he's doing.
[00:36:41.320 --> 00:36:42.320]   He could die.
[00:36:42.320 --> 00:36:43.320]   Right.
[00:36:43.320 --> 00:36:44.320]   Yeah.
[00:36:44.320 --> 00:36:45.320]   Well, still cash is checked, but he could die.
[00:36:45.320 --> 00:36:47.640]   He could take all the artists with him.
[00:36:47.640 --> 00:36:53.760]   But, but to me, the, the, the idea, the, the ambition for a private company to, you know,
[00:36:53.760 --> 00:36:57.800]   we've crept up to this moment because this guy's face acts and blue horizon stuff.
[00:36:57.800 --> 00:37:01.880]   He bought a, he bought a Basquiat painting for $110 million.
[00:37:01.880 --> 00:37:03.760]   Yeah, he's swimming in a record.
[00:37:03.760 --> 00:37:12.480]   But, but the idea of, of launching tourists into lunar orbit is just a, it's might be
[00:37:12.480 --> 00:37:16.320]   the second biggest thing humanity's done other than landing on the moon and walking around
[00:37:16.320 --> 00:37:17.320]   playing golf.
[00:37:17.320 --> 00:37:18.840]   I mean, it's a big, big deal.
[00:37:18.840 --> 00:37:24.120]   And I think that's the biggest general news story of the week that you may or may not
[00:37:24.120 --> 00:37:25.120]   have missed.
[00:37:25.120 --> 00:37:26.120]   All right.
[00:37:26.120 --> 00:37:27.120]   Yes.
[00:37:27.120 --> 00:37:28.120]   And I hope, I hope he's.
[00:37:28.120 --> 00:37:29.120]   There was other Elon Musk news.
[00:37:29.120 --> 00:37:30.120]   Yeah.
[00:37:30.120 --> 00:37:31.120]   I'm sure.
[00:37:31.120 --> 00:37:32.120]   He's like, you're gone.
[00:37:32.120 --> 00:37:33.600]   I think there's a lawsuit.
[00:37:33.600 --> 00:37:34.960]   There's all sorts of stuff going on.
[00:37:34.960 --> 00:37:37.520]   But by the way, why don't we get weed and whiskey on the show?
[00:37:37.520 --> 00:37:39.120]   It's like, yeah, what was that?
[00:37:39.120 --> 00:37:42.400]   He went on Joe Rogan show and toked up.
[00:37:42.400 --> 00:37:44.160]   I think it was peer pressure.
[00:37:44.160 --> 00:37:46.160]   You didn't want to look like a not cool guy.
[00:37:46.160 --> 00:37:51.080]   I just want to say we have never pressured anybody to smoke marijuana on this show.
[00:37:51.080 --> 00:37:52.080]   Yeah.
[00:37:52.080 --> 00:37:53.440]   It's mostly edibles, right?
[00:37:53.440 --> 00:37:59.920]   So we do offer a wide range of edibles in the, in the commissary, but to you who didn't
[00:37:59.920 --> 00:38:03.680]   like that segment are the people who were fired from Tesla because they didn't pass
[00:38:03.680 --> 00:38:04.680]   a good point.
[00:38:04.680 --> 00:38:05.680]   Oh, that's a good point.
[00:38:05.680 --> 00:38:06.680]   They did not like that.
[00:38:06.680 --> 00:38:07.680]   That's actually really good.
[00:38:07.680 --> 00:38:09.320]   And I think the shareholders maybe didn't like it so much either.
[00:38:09.320 --> 00:38:10.320]   Yeah.
[00:38:10.320 --> 00:38:11.880]   Was there a little bit of a pushback?
[00:38:11.880 --> 00:38:13.920]   It was a bit tiny, tiny bit of a dump.
[00:38:13.920 --> 00:38:15.680]   Yeah, there was a, there was a drop.
[00:38:15.680 --> 00:38:16.680]   Yeah.
[00:38:16.680 --> 00:38:17.680]   Yeah.
[00:38:17.680 --> 00:38:21.320]   There's a, there was a reverse correlation between how low the stock is and how high
[00:38:21.320 --> 00:38:22.320]   you like this story.
[00:38:22.320 --> 00:38:23.720]   Funding secured.
[00:38:23.720 --> 00:38:28.880]   That was Elon's tweet about buying, taking Tesla private may become the two costliest
[00:38:28.880 --> 00:38:30.520]   words ever.
[00:38:30.520 --> 00:38:31.960]   I don't know.
[00:38:31.960 --> 00:38:33.440]   I don't know if there's precedent for that.
[00:38:33.440 --> 00:38:34.840]   He tweeted it.
[00:38:34.840 --> 00:38:38.800]   It's not, I mean, how, this goes back to like, how are we tweeting?
[00:38:38.800 --> 00:38:45.840]   How are we treating Twitter as a platform because it can't be in only some case, like
[00:38:45.840 --> 00:38:50.600]   it can't be as far as the FCC is concerned.
[00:38:50.600 --> 00:38:55.000]   Certain tweets are held to a higher level of scrutiny, but as far as other federal agencies
[00:38:55.000 --> 00:38:56.680]   are concerned, they're not.
[00:38:56.680 --> 00:39:00.160]   So I demonstrated that the tweet changed the stock price.
[00:39:00.160 --> 00:39:01.160]   Yeah.
[00:39:01.160 --> 00:39:02.160]   I think that's the problem.
[00:39:02.160 --> 00:39:03.160]   Yeah.
[00:39:03.160 --> 00:39:04.160]   And by the way, this is a criminal probe.
[00:39:04.160 --> 00:39:06.080]   This is not just some slap on the wrist.
[00:39:06.080 --> 00:39:07.080]   Yeah.
[00:39:07.080 --> 00:39:08.400]   I don't know what's going on with Elon.
[00:39:08.400 --> 00:39:11.460]   There's something, something is going on behind the scenes.
[00:39:11.460 --> 00:39:12.820]   Everybody should get off Twitter.
[00:39:12.820 --> 00:39:13.820]   That's number one.
[00:39:13.820 --> 00:39:16.440]   I know you two both love the Twitter, but.
[00:39:16.440 --> 00:39:17.440]   No, no, no, wait.
[00:39:17.440 --> 00:39:19.080]   I don't love the Twitter.
[00:39:19.080 --> 00:39:22.240]   Twitter is a utility that I, I use for certain things.
[00:39:22.240 --> 00:39:26.320]   I see as an occupational necessity because it's basically just a journal of talking to
[00:39:26.320 --> 00:39:27.320]   it.
[00:39:27.320 --> 00:39:28.320]   Yeah.
[00:39:28.320 --> 00:39:30.320]   But then there are others who really are not doing themselves any favor.
[00:39:30.320 --> 00:39:32.160]   The president, Elon Musk.
[00:39:32.160 --> 00:39:35.200]   Well, I think the Twitter has been very good for the president.
[00:39:35.200 --> 00:39:36.200]   Oh, yeah.
[00:39:36.200 --> 00:39:40.560]   You make the argument that that's until his tweets are evidence in the, in the, in the
[00:39:40.560 --> 00:39:41.560]   questions.
[00:39:41.560 --> 00:39:42.560]   All right.
[00:39:42.560 --> 00:39:43.560]   That was your story.
[00:39:43.560 --> 00:39:44.560]   You're going to stick with it.
[00:39:44.560 --> 00:39:45.560]   I'm going to stick with it.
[00:39:45.560 --> 00:39:51.200]   Amy, as Amy bed before the show that she would not overlap with you, and I think Amy is
[00:39:51.200 --> 00:39:52.760]   not going to overlap with you.
[00:39:52.760 --> 00:39:55.080]   What did I miss this week?
[00:39:55.080 --> 00:39:59.440]   So well, actually I've changed my other thing because it relates to what Mike said.
[00:39:59.440 --> 00:40:01.120]   You have too many.
[00:40:01.120 --> 00:40:03.280]   Well, you could do more than one if you want, Amy.
[00:40:03.280 --> 00:40:04.280]   It's okay.
[00:40:04.280 --> 00:40:05.280]   All right.
[00:40:05.280 --> 00:40:10.240]   So the quick thing is a really wonderful show called the first, which is just launched
[00:40:10.240 --> 00:40:11.240]   on Hulu.
[00:40:11.240 --> 00:40:16.720]   It's by Bo Willemann, who was the show runner for House of Cards, the first couple seasons.
[00:40:16.720 --> 00:40:21.360]   It's about, it's set in the year 2031 and it's about the first group of people ever to try
[00:40:21.360 --> 00:40:22.360]   to get to Mars.
[00:40:22.360 --> 00:40:28.440]   So it's not space tourism, but it is 100% space related and it's about just the challenges
[00:40:28.440 --> 00:40:32.400]   that humans face trying to achieve these huge feats in space.
[00:40:32.400 --> 00:40:33.400]   Okay.
[00:40:33.400 --> 00:40:36.880]   You had me until I saw that it stars Sean Penn.
[00:40:36.880 --> 00:40:37.880]   Sean Penn.
[00:40:37.880 --> 00:40:38.880]   Yeah.
[00:40:38.880 --> 00:40:40.040]   He's, you know, he's good in it.
[00:40:40.040 --> 00:40:41.040]   The show is terrific.
[00:40:41.040 --> 00:40:42.120]   I worked on it.
[00:40:42.120 --> 00:40:43.120]   So I.
[00:40:43.120 --> 00:40:44.800]   Well, this is the one you were the consultant on.
[00:40:44.800 --> 00:40:45.800]   Yeah.
[00:40:45.800 --> 00:40:46.800]   Yeah.
[00:40:46.800 --> 00:40:47.800]   So I created the year 2031.
[00:40:47.800 --> 00:40:52.040]   Anything that keeps Sean Penn from writing any more novels, I think it's a good thing.
[00:40:52.040 --> 00:40:53.320]   You know, he's a fine actor.
[00:40:53.320 --> 00:41:00.880]   So, and I'm glad, you know, I paid for Hulu because of, you know, the handmaid's tail.
[00:41:00.880 --> 00:41:01.880]   And I forgot to cancel.
[00:41:01.880 --> 00:41:03.680]   So I'm glad now that I have that.
[00:41:03.680 --> 00:41:04.680]   Yeah.
[00:41:04.680 --> 00:41:05.760]   Because I'll be able to watch this.
[00:41:05.760 --> 00:41:06.760]   Did it launch?
[00:41:06.760 --> 00:41:07.760]   Is it launching now?
[00:41:07.760 --> 00:41:08.760]   Yeah.
[00:41:08.760 --> 00:41:11.360]   And it was the first time they put all the episodes out at once because it's been worthy.
[00:41:11.360 --> 00:41:12.840]   But I will say this.
[00:41:12.840 --> 00:41:13.840]   I will say this.
[00:41:13.840 --> 00:41:19.000]   A lot of people got confused and think that it actually takes place on Mars and it doesn't.
[00:41:19.000 --> 00:41:23.560]   It takes place in the year 2031 and it's the all everything that leads up to everybody
[00:41:23.560 --> 00:41:25.880]   trying to get to Mars for the first time.
[00:41:25.880 --> 00:41:30.320]   And in fact, it's the series, which is eight episodes ends as they're about to make the
[00:41:30.320 --> 00:41:31.320]   launch.
[00:41:31.320 --> 00:41:32.320]   Yeah.
[00:41:32.320 --> 00:41:34.080]   I hope that's not a spoiler.
[00:41:34.080 --> 00:41:35.080]   It's not.
[00:41:35.080 --> 00:41:36.080]   It's not.
[00:41:36.080 --> 00:41:37.080]   It's good.
[00:41:37.080 --> 00:41:38.080]   It's really good.
[00:41:38.080 --> 00:41:39.080]   I will watch it tonight.
[00:41:39.080 --> 00:41:40.080]   I was looking.
[00:41:40.080 --> 00:41:41.080]   I've thought I haven't watched TV in three weeks.
[00:41:41.080 --> 00:41:42.080]   What should I watch?
[00:41:42.080 --> 00:41:43.080]   So now I have some.
[00:41:43.080 --> 00:41:48.000]   It is not like a super fast paced Jack Ryan sort of it's a slower moving.
[00:41:48.000 --> 00:41:53.760]   So Mike's excellent point about what it means to go to space for different reasons than
[00:41:53.760 --> 00:41:56.360]   we've gone before.
[00:41:56.360 --> 00:41:59.440]   You know, and what that implies and it's really interesting stuff.
[00:41:59.440 --> 00:42:06.080]   So my actual most important story of the week was Amazon.
[00:42:06.080 --> 00:42:11.120]   Amazon launched a whole bunch of different products and services.
[00:42:11.120 --> 00:42:15.880]   Everybody is very fixated on this microwave and somehow everybody has lost the site of
[00:42:15.880 --> 00:42:16.880]   the bigger picture.
[00:42:16.880 --> 00:42:17.880]   The clock.
[00:42:17.880 --> 00:42:22.160]   Well, if you look at all the other things that Amazon has engaged in, which has to do with
[00:42:22.160 --> 00:42:28.800]   AWS and securing larger government contracts for various things, you know, it is crystal
[00:42:28.800 --> 00:42:36.640]   clear that we are quickly moving into a near future scenario where we are living in an
[00:42:36.640 --> 00:42:40.840]   Amazon home, a Google home or an Apple home and the Amazon.
[00:42:40.840 --> 00:42:44.200]   Take your pick because you can't mix.
[00:42:44.200 --> 00:42:46.800]   That's correct because they're not interoperable.
[00:42:46.800 --> 00:42:53.640]   And from my vantage point, the Amazon home is likely to be most closely connected with
[00:42:53.640 --> 00:42:55.880]   government services.
[00:42:55.880 --> 00:42:58.840]   And so for people who can't afford certain things, absolutely.
[00:42:58.840 --> 00:43:01.880]   Why do you say this is not a bad thing?
[00:43:01.880 --> 00:43:06.920]   But I think it's highly likely that why would government pick a winner?
[00:43:06.920 --> 00:43:08.080]   Pardon me.
[00:43:08.080 --> 00:43:11.600]   Why would government pick a winner in this race?
[00:43:11.600 --> 00:43:17.720]   Because the government at the moment can't manage, I mean, literally cannot manage.
[00:43:17.720 --> 00:43:22.320]   Have you heard all the not so stories about housing or human services?
[00:43:22.320 --> 00:43:25.480]   No, as I said, I've been off the grid for three weeks.
[00:43:25.480 --> 00:43:29.400]   I'm starting to really appreciate it, by the way.
[00:43:29.400 --> 00:43:35.960]   But it's like very, very clear to me that the three companies are vying not just to own
[00:43:35.960 --> 00:43:42.200]   our living room, but to power our lives and our lives as they, if you treat the home as
[00:43:42.200 --> 00:43:48.640]   a sort of gigantic spatial computing environment, and we are a part of that, the road ahead
[00:43:48.640 --> 00:43:50.520]   to me is very, very clear.
[00:43:50.520 --> 00:43:53.080]   And so the microwave is sort of silly, but cool.
[00:43:53.080 --> 00:43:56.760]   The clocks on the walls are silly, but interesting or whatever.
[00:43:56.760 --> 00:44:00.480]   And everybody needs to, it's fine to acknowledge these individual developments.
[00:44:00.480 --> 00:44:06.840]   But if we take, if we'd like look from a 40,000 foot perspective, you know, like the pieces
[00:44:06.840 --> 00:44:10.200]   are coming, starting to come together now.
[00:44:10.200 --> 00:44:15.360]   Now, what I saw was the CNBC report saying Amazon was going to announce it.
[00:44:15.360 --> 00:44:16.360]   Did they announce it?
[00:44:16.360 --> 00:44:20.280]   Yeah, they announced lots and lots of products and services.
[00:44:20.280 --> 00:44:24.880]   So there's a device now that you can turn any car into a skeleton powered.
[00:44:24.880 --> 00:44:33.480]   Well, I've had that row of from, but this is one that's officially, what I find interesting
[00:44:33.480 --> 00:44:39.960]   is that Amazon has decided to make their own as opposed to license because it looked like
[00:44:39.960 --> 00:44:44.040]   for a while their strategy was going to be, we're just going to put out, echo every, I
[00:44:44.040 --> 00:44:48.920]   won't say the A word, but echo everywhere by licensing it and making it very easy for
[00:44:48.920 --> 00:44:50.000]   somebody to build something.
[00:44:50.000 --> 00:44:59.120]   They're also doing that, but they're producing, I mean, it is to me, I think everybody's,
[00:44:59.120 --> 00:45:02.080]   when we think about the future and who's really building the future and who's really
[00:45:02.080 --> 00:45:09.800]   thinking, Elon Musk has certainly done some interesting and wonderful things, right?
[00:45:09.800 --> 00:45:15.280]   But for my money, Jeff, or not Jeff, Jeff Bezos.
[00:45:15.280 --> 00:45:16.720]   Jeff Bezos, yeah.
[00:45:16.720 --> 00:45:23.160]   For my money, if I think of who alive today is the most visionary is thinking the most
[00:45:23.160 --> 00:45:28.320]   long term, not 10 years into the future, but 80 years into the future, Bezos is at the
[00:45:28.320 --> 00:45:29.920]   very, very top of my list.
[00:45:29.920 --> 00:45:32.360]   Just everybody with their own space program.
[00:45:32.360 --> 00:45:34.080]   So that's Musk, that's Bezos.
[00:45:34.080 --> 00:45:36.920]   Right, and they've got the space program, you're thinking about the future.
[00:45:36.920 --> 00:45:40.760]   By the way, I saw a really horrible movie last night that had an interesting point to
[00:45:40.760 --> 00:45:41.760]   it.
[00:45:41.760 --> 00:45:42.760]   It was Fahrenheit 451, the new one.
[00:45:42.760 --> 00:45:43.760]   Yeah.
[00:45:43.760 --> 00:45:44.760]   And it was a great book.
[00:45:44.760 --> 00:45:45.760]   Awful movie.
[00:45:45.760 --> 00:45:46.760]   It was a very very book.
[00:45:46.760 --> 00:45:47.760]   The original movie was good, too.
[00:45:47.760 --> 00:45:48.760]   The original movie was pretty good.
[00:45:48.760 --> 00:45:49.760]   Yeah.
[00:45:49.760 --> 00:45:52.760]   This movie, not so much, but what was interesting about it is they modernized it, in part by
[00:45:52.760 --> 00:45:57.160]   saying that the whole world as constructed, which is that everybody's happy because we
[00:45:57.160 --> 00:45:59.520]   burn all the books and get rid of all the hard drives.
[00:45:59.520 --> 00:46:00.520]   Thinking is always bad for you.
[00:46:00.520 --> 00:46:03.480]   That this began with the tech companies of that era.
[00:46:03.480 --> 00:46:06.320]   They said that the tech companies of that era partnered with the government to create
[00:46:06.320 --> 00:46:07.320]   this world.
[00:46:07.320 --> 00:46:10.520]   So essentially, what you're talking about, Amy, is where we're going to be living in
[00:46:10.520 --> 00:46:14.040]   this Amazon world, this Apple world, or this Google world.
[00:46:14.040 --> 00:46:16.040]   This is the world of era.
[00:46:16.040 --> 00:46:20.840]   This has always been the stuff though, science fiction was as a corporate governance basically.
[00:46:20.840 --> 00:46:24.400]   Giant corporations governing running the world.
[00:46:24.400 --> 00:46:27.360]   It's not an actuality, at least in defactment.
[00:46:27.360 --> 00:46:29.840]   I mean, it's good and it's bad, right?
[00:46:29.840 --> 00:46:33.320]   There's a way to look at this in an optimistic framing, and there's a way to look at this
[00:46:33.320 --> 00:46:37.240]   in a catastrophic framing.
[00:46:37.240 --> 00:46:42.480]   If we do not do something in the United States sometime very soon to bridge the divide, the
[00:46:42.480 --> 00:46:50.080]   wealth divide that our technology is creating, we're going to wind up in a really bad spot.
[00:46:50.080 --> 00:46:54.800]   The government itself is not going to subsidize the technology or the development of it in
[00:46:54.800 --> 00:46:55.800]   a lot of ways.
[00:46:55.800 --> 00:47:02.120]   If you live in an Amazon home or a Google home, and some of those devices are in the
[00:47:02.120 --> 00:47:07.840]   services are being subsidized, subsidized through the collection of your data and the
[00:47:07.840 --> 00:47:11.280]   mining and refining of your data, that's a tradeoff.
[00:47:11.280 --> 00:47:13.120]   For some people, that may not be a big deal.
[00:47:13.120 --> 00:47:14.920]   For other people, that may be too much.
[00:47:14.920 --> 00:47:21.600]   Are you familiar with this book by Anandji, Jiridhar, Radas, winner take all?
[00:47:21.600 --> 00:47:22.600]   It's his thesis.
[00:47:22.600 --> 00:47:27.480]   I haven't read it yet because it came out just before I left, but his thesis is that
[00:47:27.480 --> 00:47:34.800]   this is exactly what we've done, which is say, "Look, governments failed us.
[00:47:34.800 --> 00:47:38.880]   Let's turn to the elite and especially the big tech companies and let them solve all
[00:47:38.880 --> 00:47:40.520]   the problems of the world."
[00:47:40.520 --> 00:47:45.120]   I think we already have enough evidence that that's not going to work.
[00:47:45.120 --> 00:47:47.040]   He says that's kind of what's happening.
[00:47:47.040 --> 00:47:51.800]   He even says, "The election of President Trump is actually manifestation of that because
[00:47:51.800 --> 00:47:56.320]   it's a business leader could probably solve our problems."
[00:47:56.320 --> 00:47:59.160]   It's cyclical, though.
[00:47:59.160 --> 00:48:01.080]   He's doing a great job proving that it's true.
[00:48:01.080 --> 00:48:02.840]   This has happened before.
[00:48:02.840 --> 00:48:03.840]   Sure.
[00:48:03.840 --> 00:48:10.440]   In the 1910s to 1930s, we had big tech companies partnering with the government to develop
[00:48:10.440 --> 00:48:15.440]   computers and weapons.
[00:48:15.440 --> 00:48:17.320]   This is the opposite, though.
[00:48:17.320 --> 00:48:21.280]   He says, "All around us, the winners in our highly inequitable status quo."
[00:48:21.280 --> 00:48:24.320]   He's talking about the gulf between haves and have-nots.
[00:48:24.320 --> 00:48:26.640]   "To clear themselves, partisans have changed.
[00:48:26.640 --> 00:48:29.120]   They know the problem and they want to be part of the solution."
[00:48:29.120 --> 00:48:33.600]   Actually, they want to lead the search for solutions and they believe their solutions
[00:48:33.600 --> 00:48:35.600]   deserve to be at the forefront of social change.
[00:48:35.600 --> 00:48:38.080]   You could say that with Mark Zuckerberg.
[00:48:38.080 --> 00:48:41.320]   You could say that with Larry Page and Sergey Brin at Google.
[00:48:41.320 --> 00:48:43.120]   You could say it with Jeff Bezos.
[00:48:43.120 --> 00:48:46.200]   I think Bezos is the least political of all of them.
[00:48:46.200 --> 00:48:47.600]   Oh, I disagree.
[00:48:47.600 --> 00:48:54.440]   I think he's just not in public as much.
[00:48:54.440 --> 00:48:59.200]   He's extraordinarily disciplined about what he does in public.
[00:48:59.200 --> 00:49:00.680]   We don't really know what he's up to.
[00:49:00.680 --> 00:49:05.160]   It seems to me that a great number of societies have collapsed because of huge and growing
[00:49:05.160 --> 00:49:08.640]   inequality between the haves and have-nots.
[00:49:08.640 --> 00:49:13.560]   I could be wrong about that, but I think most of the major civilizations that have existed.
[00:49:13.560 --> 00:49:14.880]   I think that it ...
[00:49:14.880 --> 00:49:19.760]   Yeah, I guess you could say the merchants of Venice, for instance, declared themselves
[00:49:19.760 --> 00:49:24.360]   because they had great wealth, declared themselves to be the future of the world or the Romans
[00:49:24.360 --> 00:49:25.360]   or the Greek.
[00:49:25.360 --> 00:49:29.080]   I mean, if you look at even ancient Sparta, which the Spartan system that we know was
[00:49:29.080 --> 00:49:33.800]   essentially found now, we're really off the rails, was essentially a revolution that
[00:49:33.800 --> 00:49:37.080]   made everyone equal who was a citizen.
[00:49:37.080 --> 00:49:42.240]   And then over the next 700-900 years, they evolved to the point where there was more
[00:49:42.240 --> 00:49:43.240]   and more inequality.
[00:49:43.240 --> 00:49:46.040]   And then the system fell apart because there was inequality.
[00:49:46.040 --> 00:49:51.840]   It was a direct result of they couldn't raise an army because you had to be wealthy to be
[00:49:51.840 --> 00:49:52.840]   in the army.
[00:49:52.840 --> 00:49:54.360]   And there was only 30 wealthy people left.
[00:49:54.360 --> 00:49:55.360]   It's a small army.
[00:49:55.360 --> 00:49:56.640]   And they were really wealthy.
[00:49:56.640 --> 00:49:58.800]   But that's a small army and they just kind of fizzled out.
[00:49:58.800 --> 00:49:59.800]   So getting back to it.
[00:49:59.800 --> 00:50:02.000]   This is totally ... It's relevant to tech, though.
[00:50:02.000 --> 00:50:03.000]   It's relevant to technology.
[00:50:03.000 --> 00:50:03.520]   Totally.
[00:50:03.520 --> 00:50:04.520]   Because ...
[00:50:04.520 --> 00:50:10.560]   Well, these are the elite that want to run the world now or the tech elite.
[00:50:10.560 --> 00:50:11.560]   Right.
[00:50:11.560 --> 00:50:15.520]   And so, again, the big nine ... So my upcoming book is called The Big Nine, but there's nine
[00:50:15.520 --> 00:50:17.600]   companies that control the future of AI.
[00:50:17.600 --> 00:50:19.040]   Six are in the United States.
[00:50:19.040 --> 00:50:20.600]   Three are in China.
[00:50:20.600 --> 00:50:21.600]   China's three.
[00:50:21.600 --> 00:50:25.600]   The Baidu, Alibaba, and Tencent are very closely aligned with the government.
[00:50:25.600 --> 00:50:30.360]   And part of what's happening in China and why we see these tectotic shifts happening
[00:50:30.360 --> 00:50:36.640]   is because China is about to go through social mobility at a scale that's never been seen
[00:50:36.640 --> 00:50:41.560]   before in the existence of humanity.
[00:50:41.560 --> 00:50:46.760]   The number of people in the middle class is going to balloon over the next decade.
[00:50:46.760 --> 00:50:48.240]   And they're going to move up.
[00:50:48.240 --> 00:50:52.920]   And so, part of the reason that China is in Africa is because China doesn't have enough
[00:50:52.920 --> 00:50:58.400]   wood to make this red-colored wood that's very popular there.
[00:50:58.400 --> 00:51:05.520]   They don't have enough wood to build the furniture that the newly wealthy people want to buy.
[00:51:05.520 --> 00:51:06.920]   So you get problems on both ends.
[00:51:06.920 --> 00:51:09.760]   You have problems when there's massive inequality.
[00:51:09.760 --> 00:51:13.840]   And then you also have problems when there's massive shifts in social mobility that all
[00:51:13.840 --> 00:51:15.840]   happen at the same time.
[00:51:15.840 --> 00:51:18.880]   And all of this involves the big tech companies.
[00:51:18.880 --> 00:51:19.960]   All of it does.
[00:51:19.960 --> 00:51:20.960]   So it's ...
[00:51:20.960 --> 00:51:25.440]   To me, the connection with technology is that the Bezos' and other billionaires like
[00:51:25.440 --> 00:51:32.320]   him, although he's currently the world's richest person, it's the use of technology and algorithms
[00:51:32.320 --> 00:51:34.960]   and AI and stuff to sort of take over everything.
[00:51:34.960 --> 00:51:40.480]   I mean, if you look at the rise of Amazon, he's used AI or something that could be considered
[00:51:40.480 --> 00:51:43.640]   precursor to AI, essentially crushes competition.
[00:51:43.640 --> 00:51:50.120]   Famous diaper.com thing where he was underpricing their diapers like in real time until they
[00:51:50.120 --> 00:51:51.560]   had no valuation than he bought.
[00:51:51.560 --> 00:51:52.560]   And then he bought.
[00:51:52.560 --> 00:51:59.160]   That's an example of how ... That's a direct link between somebody who's worth $130 billion
[00:51:59.160 --> 00:52:02.240]   or whatever it is now, and technology.
[00:52:02.240 --> 00:52:06.480]   It's using technology to create this gap, this wealth gap.
[00:52:06.480 --> 00:52:08.560]   So New Echo, I'm just looking now at the announcement.
[00:52:08.560 --> 00:52:11.920]   This was just a couple of days ago, was on the 20th.
[00:52:11.920 --> 00:52:16.560]   You can go to Amazon now and pre-order some of these New Echo Dot, which sounds better,
[00:52:16.560 --> 00:52:19.040]   I guess, and is covered with fabric.
[00:52:19.040 --> 00:52:20.040]   So ...
[00:52:20.040 --> 00:52:21.040]   Fabric was a big deal.
[00:52:21.040 --> 00:52:22.040]   It's got that going for it.
[00:52:22.040 --> 00:52:23.040]   It's huge.
[00:52:23.040 --> 00:52:30.600]   There's also New Echo Plus, again, better sound fabric.
[00:52:30.600 --> 00:52:34.480]   They're finally ... They're doing a 10-inch Echo show.
[00:52:34.480 --> 00:52:35.480]   I really like the Echo Show.
[00:52:35.480 --> 00:52:38.160]   Everybody hated it, said it was ugly.
[00:52:38.160 --> 00:52:40.600]   You mentioned the microwave.
[00:52:40.600 --> 00:52:43.400]   Right, which is voice activated.
[00:52:43.400 --> 00:52:47.240]   I mean, you can't say ... I don't really have a lot of ...
[00:52:47.240 --> 00:52:48.800]   Take a potato out of my refrigerator.
[00:52:48.800 --> 00:52:54.200]   Put something in the microwave, press it a button and it goes on.
[00:52:54.200 --> 00:52:56.920]   It doesn't seem like that big of a deal.
[00:52:56.920 --> 00:52:59.400]   Why do I need to talk to my microwave?
[00:52:59.400 --> 00:53:00.400]   Again, like ...
[00:53:00.400 --> 00:53:03.720]   They said the user interface for the microwave is stuck in the 70s.
[00:53:03.720 --> 00:53:04.720]   Yeah?
[00:53:04.720 --> 00:53:07.000]   So it depends on how much microwaving do you do.
[00:53:07.000 --> 00:53:12.360]   This is a totally legit ... Like, microwaves have become overly complicated.
[00:53:12.360 --> 00:53:15.440]   The microwave and my mother-in-law's home, in-law is just moved.
[00:53:15.440 --> 00:53:17.680]   They've got new technology in their house.
[00:53:17.680 --> 00:53:20.040]   I can't even ... The microwave's way over complicated.
[00:53:20.040 --> 00:53:22.240]   There's too many questions.
[00:53:22.240 --> 00:53:24.720]   Just like I want to nuke something for two minutes and be done with it.
[00:53:24.720 --> 00:53:29.040]   Maybe I have an old one because I have one where you put something in your closet door
[00:53:29.040 --> 00:53:32.800]   and you press the number one through nine, it zaps it for that many minutes.
[00:53:32.800 --> 00:53:35.280]   And generally, that's all I need.
[00:53:35.280 --> 00:53:38.240]   That's correct, but they've overcomplicated a lot.
[00:53:38.240 --> 00:53:39.240]   They have more now.
[00:53:39.240 --> 00:53:42.600]   Oh, yeah, because they're trying to say, "Well, is that a broccoli you just put in there?"
[00:53:42.600 --> 00:53:44.720]   Well, I can cook broccoli in 12 different ways.
[00:53:44.720 --> 00:53:45.720]   Yeah, I don't want that.
[00:53:45.720 --> 00:53:48.400]   Because that's what Echo's going to do, too, right?
[00:53:48.400 --> 00:53:50.360]   Or is it incremental benefits?
[00:53:50.360 --> 00:53:52.600]   So you're a microwave manufacturer.
[00:53:52.600 --> 00:53:57.440]   What do you do to keep buying your microwave?
[00:53:57.440 --> 00:54:00.240]   And there's some other issues like tactile functions.
[00:54:00.240 --> 00:54:05.840]   If you're in a situation that's easier for you to speak than to push the buttons, you
[00:54:05.840 --> 00:54:06.840]   know.
[00:54:06.840 --> 00:54:12.200]   Yeah, I have the wrong idea to talk to because I bought that $1,500 internet connected toaster
[00:54:12.200 --> 00:54:14.320]   oven.
[00:54:14.320 --> 00:54:16.920]   But I can't talk to it either.
[00:54:16.920 --> 00:54:26.400]   All right, so there's also the Echo Auto, which you talked about a little bit.
[00:54:26.400 --> 00:54:30.280]   There's a smart plug, $25 Echo Smart Plug.
[00:54:30.280 --> 00:54:33.880]   A lot of these are just Amazon crushing little companies that are making things like
[00:54:33.880 --> 00:54:34.880]   tablet plugs.
[00:54:34.880 --> 00:54:39.000]   Yeah, the wall clock can be used set timers another time based Echo test, which is what
[00:54:39.000 --> 00:54:40.000]   I already do.
[00:54:40.000 --> 00:54:43.080]   I have the use of an Amazon is in the kitchen to set timers.
[00:54:43.080 --> 00:54:44.680]   And so it actually becomes a Wow.
[00:54:44.680 --> 00:54:47.720]   You never have to worry about daylight savings time.
[00:54:47.720 --> 00:54:49.880]   The motor will automatically chain.
[00:54:49.880 --> 00:54:51.120]   Isn't that pretty common?
[00:54:51.120 --> 00:54:52.120]   There's a motor.
[00:54:52.120 --> 00:54:55.880]   Bezos is pretty obsessed with clocks in general and time.
[00:54:55.880 --> 00:54:58.160]   This has got to be a personal obsession.
[00:54:58.160 --> 00:55:07.280]   By the way, just so you know, the new budget eliminates WWV, the automatic time station,
[00:55:07.280 --> 00:55:11.640]   and the ability to have these automatic clocks set themselves to WWV.
[00:55:11.640 --> 00:55:14.120]   It signals going away as well.
[00:55:14.120 --> 00:55:18.800]   So when you say new budget, what are you talking about?
[00:55:18.800 --> 00:55:23.520]   The budget for NIST has been vastly cut.
[00:55:23.520 --> 00:55:29.760]   And among other things, as the other things, but as a result, they're killing WWV next
[00:55:29.760 --> 00:55:33.800]   year, which is, I mean, I have a lot of clocks that are supposed to set themselves to the
[00:55:33.800 --> 00:55:34.800]   WWV.
[00:55:34.800 --> 00:55:35.800]   We did too.
[00:55:35.800 --> 00:55:36.800]   Do that anymore.
[00:55:36.800 --> 00:55:40.560]   I don't know what will happen with this Echo wall clock, but it does have a motor.
[00:55:40.560 --> 00:55:42.360]   I'm just trying to see.
[00:55:42.360 --> 00:55:43.640]   You'll never have to worry.
[00:55:43.640 --> 00:55:45.600]   The motor will automatically change.
[00:55:45.600 --> 00:55:47.600]   That some guy named Limp.
[00:55:47.600 --> 00:55:49.920]   I guess he was at the event.
[00:55:49.920 --> 00:55:52.440]   I don't know.
[00:55:52.440 --> 00:55:54.680]   He's also the guy who said the microwave was stuck in the 70s.
[00:55:54.680 --> 00:55:58.480]   I got to find out how this Limp fella is because he's insightful.
[00:55:58.480 --> 00:56:01.640]   Another thing that's really interesting that Amazon announced is an easy setup.
[00:56:01.640 --> 00:56:06.080]   Now you appreciate this because you went through before the show with your Apple Watch, the
[00:56:06.080 --> 00:56:07.080]   setup.
[00:56:07.080 --> 00:56:13.320]   But now, basically, it sounds like a great system where you bring in a new device, your
[00:56:13.320 --> 00:56:17.400]   device number 21 into your home that supports the A word.
[00:56:17.400 --> 00:56:22.800]   And it just sort of like authenticates it and puts it online very quickly and easily.
[00:56:22.800 --> 00:56:28.400]   I think that's going to be a major thing from Amazon that everyone's going to copy.
[00:56:28.400 --> 00:56:30.960]   There's a new guard mode, which is kind of interesting.
[00:56:30.960 --> 00:56:31.960]   Yeah.
[00:56:31.960 --> 00:56:32.960]   A lot of this is also--
[00:56:32.960 --> 00:56:35.400]   All your devices into a security mode, if you say--
[00:56:35.400 --> 00:56:42.240]   A lot of this is about nudging us to a different behavioral paradigm for the near future in
[00:56:42.240 --> 00:56:46.840]   which we are talking to-- we are talking rather than typing.
[00:56:46.840 --> 00:56:52.760]   And the-- like there's many millions of autonomous decisions being made on our behalf through
[00:56:52.760 --> 00:56:53.760]   those conversations.
[00:56:53.760 --> 00:56:54.760]   And it's ubiquitous.
[00:56:54.760 --> 00:56:57.800]   I think-- I have a different vision of all this.
[00:56:57.800 --> 00:57:03.560]   I think you guys are acting like this is all a clever plan.
[00:57:03.560 --> 00:57:05.800]   And I think they released the echo and--
[00:57:05.800 --> 00:57:07.800]   Whoa, people bought it.
[00:57:07.800 --> 00:57:11.000]   So let's do 50 more echoes and see what people will buy.
[00:57:11.000 --> 00:57:12.000]   I don't know how--
[00:57:12.000 --> 00:57:13.360]   I would believe that if it was Google.
[00:57:13.360 --> 00:57:14.360]   I don't believe that with Amazon.
[00:57:14.360 --> 00:57:15.360]   I think that--
[00:57:15.360 --> 00:57:16.360]   I think Jeff has a secret plan.
[00:57:16.360 --> 00:57:20.080]   I mean, listen, he's not in the public so much.
[00:57:20.080 --> 00:57:22.200]   People don't know his personality so much.
[00:57:22.200 --> 00:57:24.400]   You don't see Jeff Bezos tweeting.
[00:57:24.400 --> 00:57:25.400]   You don't.
[00:57:25.400 --> 00:57:29.160]   And I will tell you, yeah, do I believe that there is a grand plan and he has a singular
[00:57:29.160 --> 00:57:35.560]   vision that is flexible on the details, but he is marching toward a future that he sees.
[00:57:35.560 --> 00:57:36.560]   That seems like that doesn't--
[00:57:36.560 --> 00:57:37.560]   Absolutely.
[00:57:37.560 --> 00:57:38.560]   Absolutely.
[00:57:38.560 --> 00:57:44.800]   And I very-- that's why with all of these sort of seemingly disparate devices, it may
[00:57:44.800 --> 00:57:49.520]   seem like, oh, the echo show was a hit.
[00:57:49.520 --> 00:57:52.720]   Therefore, the smart speakers are in right now and that's where they're making for that.
[00:57:52.720 --> 00:57:53.720]   Oh, they're fabric.
[00:57:53.720 --> 00:57:54.720]   Yeah.
[00:57:54.720 --> 00:57:55.720]   Right.
[00:57:55.720 --> 00:57:56.720]   I don't think that's what's going on.
[00:57:56.720 --> 00:57:59.480]   Maybe what's going on with Google, for example.
[00:57:59.480 --> 00:58:02.200]   I do not at all for a moment think that's what's going on with Amazon.
[00:58:02.200 --> 00:58:03.920]   I think that they have a strategic plan.
[00:58:03.920 --> 00:58:08.000]   It was obvious that the Amazon Echo was going to launch a revolution.
[00:58:08.000 --> 00:58:09.000]   Super obvious.
[00:58:09.000 --> 00:58:12.480]   The week that that launched, I wrote a column detailing exactly what would happen in the
[00:58:12.480 --> 00:58:13.480]   next few years.
[00:58:13.480 --> 00:58:15.600]   Exactly what happened.
[00:58:15.600 --> 00:58:17.080]   We're moving to this paradigm you talked about.
[00:58:17.080 --> 00:58:20.280]   But I keep hearing these stories like, well, Amazon Web Services, they didn't really--
[00:58:20.280 --> 00:58:21.480]   we have some extra computer time.
[00:58:21.480 --> 00:58:22.480]   Let's throw them.
[00:58:22.480 --> 00:58:23.880]   Let's see what Amazon Prime-- what do we charge?
[00:58:23.880 --> 00:58:24.880]   I don't know.
[00:58:24.880 --> 00:58:25.880]   Let's just try and see what happens.
[00:58:25.880 --> 00:58:30.440]   Amazon Echo, you think that that's a disinformation strategy by Jeff Bezos?
[00:58:30.440 --> 00:58:31.440]   Pretend he doesn't know what he's doing.
[00:58:31.440 --> 00:58:35.160]   As a member of the press, I know that when you approach them, they're a very different
[00:58:35.160 --> 00:58:39.440]   company to work with from their PR standpoint.
[00:58:39.440 --> 00:58:44.520]   I go to Amazon and say, hey, I'd love to talk to the person in charge of this initiative.
[00:58:44.520 --> 00:58:47.040]   I want to find out what your plans are, Blah, blah, blah.
[00:58:47.040 --> 00:58:48.520]   They're the most locked down.
[00:58:48.520 --> 00:58:51.880]   It's like talking to Kim Jong Un or something.
[00:58:51.880 --> 00:58:52.880]   Smart.
[00:58:52.880 --> 00:58:53.880]   Super-shelving.
[00:58:53.880 --> 00:58:54.880]   Super-self-serving.
[00:58:54.880 --> 00:58:59.080]   I was in Seattle a couple of weeks ago at Spheres.
[00:58:59.080 --> 00:59:06.280]   These are the somewhat contested, beautiful-- it's part of their headquarters in Seattle.
[00:59:06.280 --> 00:59:11.320]   Big Spheres with-- covered with inside with different 40,000 different species of plants.
[00:59:11.320 --> 00:59:12.320]   Lots of fabric.
[00:59:12.320 --> 00:59:13.320]   No, no.
[00:59:13.320 --> 00:59:14.320]   Sorry.
[00:59:14.320 --> 00:59:15.320]   Organic fabric.
[00:59:15.320 --> 00:59:16.320]   Again, I--
[00:59:16.320 --> 00:59:18.880]   This is part of Amazon's downtown effort.
[00:59:18.880 --> 00:59:22.560]   They want to put their campus in the middle of Seattle as opposed to Apple's campus, which
[00:59:22.560 --> 00:59:23.560]   is a fortress.
[00:59:23.560 --> 00:59:24.560]   It's a town.
[00:59:24.560 --> 00:59:25.560]   Yeah.
[00:59:25.560 --> 00:59:26.560]   Yeah.
[00:59:26.560 --> 00:59:27.560]   Can't go anywhere.
[00:59:27.560 --> 00:59:29.080]   That's just a lounge space.
[00:59:29.080 --> 00:59:32.360]   You cannot go anywhere in that-- first of all, you can't even get into it unless you
[00:59:32.360 --> 00:59:34.400]   know somebody, which I do.
[00:59:34.400 --> 00:59:36.160]   And that's what the announcement was.
[00:59:36.160 --> 00:59:40.520]   You have to be tethered to that person, otherwise you-- and they wouldn't check.
[00:59:40.520 --> 00:59:44.000]   When students tour Amazon greenhouse, better not get left behind, right?
[00:59:44.000 --> 00:59:46.520]   They count the kids on their way out and make sure that--
[00:59:46.520 --> 00:59:48.160]   They actually do.
[00:59:48.160 --> 00:59:51.000]   They have an inventory system with their tags.
[00:59:51.000 --> 00:59:52.000]   Yeah.
[00:59:52.000 --> 00:59:53.000]   And they do count.
[00:59:53.000 --> 00:59:54.000]   Oh, sure.
[00:59:54.000 --> 00:59:56.440]   It seems like a humid place to have a meeting there, isn't it?
[00:59:56.440 --> 00:59:57.560]   Can I sneak in?
[00:59:57.560 --> 00:59:59.360]   I would live in that place.
[00:59:59.360 --> 01:00:00.360]   Are you kidding me?
[01:00:00.360 --> 01:00:03.440]   It's like a warmest greenhouse with perfect weather all the time.
[01:00:03.440 --> 01:00:04.440]   It's the bio?
[01:00:04.440 --> 01:00:05.440]   It's the bio?
[01:00:05.440 --> 01:00:06.440]   Oh, yeah.
[01:00:06.440 --> 01:00:07.440]   Is it the bio dome?
[01:00:07.440 --> 01:00:08.440]   I mean, kind of.
[01:00:08.440 --> 01:00:10.520]   I mean, they have good coffee inside.
[01:00:10.520 --> 01:00:11.520]   I mean--
[01:00:11.520 --> 01:00:13.640]   That was what they-- there's where they went wrong.
[01:00:13.640 --> 01:00:18.360]   They should have coffee plantations instead of all coffee and stuff.
[01:00:18.360 --> 01:00:20.720]   So other things happen in the world of AI.
[01:00:20.720 --> 01:00:21.720]   That was really interesting.
[01:00:21.720 --> 01:00:25.680]   One that's not getting a whole lot of play is that Salesforce came out with an AI voice
[01:00:25.680 --> 01:00:28.400]   first solution for Salesforce.
[01:00:28.400 --> 01:00:29.400]   It's going to come out.
[01:00:29.400 --> 01:00:30.400]   They didn't launch it.
[01:00:30.400 --> 01:00:32.400]   How do we know that's just not a me too kind of--
[01:00:32.400 --> 01:00:33.400]   Well, I think it seemed--
[01:00:33.400 --> 01:00:34.400]   Everybody's got one.
[01:00:34.400 --> 01:00:35.760]   --fruity ambitious, actually.
[01:00:35.760 --> 01:00:40.640]   It's got sort of Google Now style preemption where it'll say, hey, you know, you really
[01:00:40.640 --> 01:00:43.000]   need to call these customers because they're being neglected.
[01:00:43.000 --> 01:00:44.240]   That's actually a good idea.
[01:00:44.240 --> 01:00:48.960]   It's basically, you know, Salesforce is essentially a spreadsheet or a database.
[01:00:48.960 --> 01:00:54.960]   And they focused on taking natural language communication and parsing it into the correct
[01:00:54.960 --> 01:00:58.080]   fields and then having preemption and communication.
[01:00:58.080 --> 01:01:02.640]   So you can say, hey, tell the group, blah, blah, blah, and it'll go and send them the
[01:01:02.640 --> 01:01:04.680]   resources they need.
[01:01:04.680 --> 01:01:09.840]   From what they've promised, it sounds significantly more visionary, I think, in terms of how
[01:01:09.840 --> 01:01:12.120]   the world will work in the future than the Amazon stuff.
[01:01:12.120 --> 01:01:17.160]   The Amazon stuff is like, oh, you can talk to the A word and you find out the weather
[01:01:17.160 --> 01:01:18.360]   and get a set of timer.
[01:01:18.360 --> 01:01:21.760]   This is like, OK, I'm partnering now with AI.
[01:01:21.760 --> 01:01:25.480]   When Elon Musk was baked out of his mind on the Joe Rogan podcast--
[01:01:25.480 --> 01:01:26.920]   He had one puff.
[01:01:26.920 --> 01:01:29.440]   Do you see the size of that?
[01:01:29.440 --> 01:01:30.440]   Anyway.
[01:01:30.440 --> 01:01:31.440]   He barely inhaled.
[01:01:31.440 --> 01:01:32.440]   Yeah.
[01:01:32.440 --> 01:01:33.440]   So he started--
[01:01:33.440 --> 01:01:35.680]   Which is why the whole fallout is so bad, by the way.
[01:01:35.680 --> 01:01:36.680]   He made the point that--
[01:01:36.680 --> 01:01:37.680]   Is he inhaled?
[01:01:37.680 --> 01:01:38.680]   It would have been OK?
[01:01:38.680 --> 01:01:39.680]   No, yeah.
[01:01:39.680 --> 01:01:43.280]   If he would have actually smoked a bowl, that would have been one thing.
[01:01:43.280 --> 01:01:44.920]   He barely took any--
[01:01:44.920 --> 01:01:45.920]   Everyone's a critic.
[01:01:45.920 --> 01:01:46.920]   Everyone's a critic.
[01:01:46.920 --> 01:01:51.680]   Anyway, so he was basically saying that what a corporation is is a cybernetic organism
[01:01:51.680 --> 01:01:54.920]   between human intelligence and artificial intelligence.
[01:01:54.920 --> 01:01:58.160]   And the percentage of the artificial intelligence will only increase.
[01:01:58.160 --> 01:02:01.000]   He was talking about his whole anxiety about AI and all that kind of stuff.
[01:02:01.000 --> 01:02:02.640]   But anyway, it was an interesting perspective.
[01:02:02.640 --> 01:02:08.040]   And he said, the only thing that's preventing us from being much more closely aligned and
[01:02:08.040 --> 01:02:11.360]   partnered with this growing AI is the interface.
[01:02:11.360 --> 01:02:12.720]   And voice is a major interface.
[01:02:12.720 --> 01:02:18.360]   So this for Salesforce, this is like an example of corporations eventually turning into these
[01:02:18.360 --> 01:02:21.200]   cybernetic organisms with this great interface.
[01:02:21.200 --> 01:02:22.200]   It's a great interface.
[01:02:22.200 --> 01:02:23.200]   I would just--
[01:02:23.200 --> 01:02:24.200]   Yes.
[01:02:24.200 --> 01:02:29.000]   That's all-- we built models showing that most of our conversation-- 50% in the industrialized
[01:02:29.000 --> 01:02:32.200]   world of conversations that we have with machines.
[01:02:32.200 --> 01:02:39.040]   50% of the interactions that we have with machines by the year 2022 will be with our
[01:02:39.040 --> 01:02:40.040]   voices.
[01:02:40.040 --> 01:02:44.920]   So Salesforce is just like the next company to jump on.
[01:02:44.920 --> 01:02:46.280]   It's not really a bandwagon.
[01:02:46.280 --> 01:02:47.280]   It's a transition.
[01:02:47.280 --> 01:02:51.760]   I just want to go back to the Elon Musk thing with AI for a moment.
[01:02:51.760 --> 01:02:54.680]   So artificial intelligence is the third era of computing.
[01:02:54.680 --> 01:02:57.920]   It's not some other thing.
[01:02:57.920 --> 01:03:01.440]   And I think that Elon Musk is an incredibly smart person.
[01:03:01.440 --> 01:03:04.040]   And I think he's probably a very good engineer.
[01:03:04.040 --> 01:03:09.800]   I also don't think he fully understands AI given what I've heard from-- like when he's
[01:03:09.800 --> 01:03:11.920]   talked about it.
[01:03:11.920 --> 01:03:21.040]   So-- and his, you know, abject, alarmist interpretations of AI, I think, are not good
[01:03:21.040 --> 01:03:22.040]   for us all.
[01:03:22.040 --> 01:03:23.040]   So I just want to--
[01:03:23.040 --> 01:03:25.040]   And you're writing the book, the big nine.
[01:03:25.040 --> 01:03:26.680]   And I wrote the book.
[01:03:26.680 --> 01:03:27.680]   It's in.
[01:03:27.680 --> 01:03:28.680]   It comes out in a couple months.
[01:03:28.680 --> 01:03:29.680]   Oh, how exciting.
[01:03:29.680 --> 01:03:30.680]   I'll send you a galley.
[01:03:30.680 --> 01:03:34.040]   Well, you'll be on the show and we'll talk, of course, about it.
[01:03:34.040 --> 01:03:35.360]   But is it just those nine though?
[01:03:35.360 --> 01:03:39.600]   I mean, can a company like Salesforce be a player?
[01:03:39.600 --> 01:03:40.600]   Salesforce is a player.
[01:03:40.600 --> 01:03:41.600]   Uber is a player.
[01:03:41.600 --> 01:03:43.720]   But they are not building out the ecosystem.
[01:03:43.720 --> 01:03:44.720]   So--
[01:03:44.720 --> 01:03:47.080]   I'll use other people's stuff.
[01:03:47.080 --> 01:03:48.080]   That's right.
[01:03:48.080 --> 01:03:57.680]   So, you know, they are locked into-- in the United States, Amazon, Google, Apple, Microsoft,
[01:03:57.680 --> 01:03:59.680]   IBM, and Facebook.
[01:03:59.680 --> 01:04:02.120]   And I think that pool will shrink over time.
[01:04:02.120 --> 01:04:03.400]   And in China, it's the bat.
[01:04:03.400 --> 01:04:05.080]   It's a Baidu Alibaba and Tencent.
[01:04:05.080 --> 01:04:10.440]   I personally think the most interesting company in AI is Apple because they use AI for the
[01:04:10.440 --> 01:04:12.240]   most trivial things.
[01:04:12.240 --> 01:04:19.320]   I mean, the way that AirPods work, they use an AI to sync up the-- so that the AirPods
[01:04:19.320 --> 01:04:22.360]   know if they're being held in your hand or they're in your ear or whether there's one
[01:04:22.360 --> 01:04:28.040]   in them or two, and should they have stereo or-- it's like they use AI for the most miniscule
[01:04:28.040 --> 01:04:29.040]   little things.
[01:04:29.040 --> 01:04:30.040]   And I think that's so interesting.
[01:04:30.040 --> 01:04:31.880]   But that's not that remarkable.
[01:04:31.880 --> 01:04:38.400]   Again, this is just-- AI is not like a-- that's just an example of autonomous decision-making
[01:04:38.400 --> 01:04:39.760]   for singular purposes.
[01:04:39.760 --> 01:04:40.760]   So like, every--
[01:04:40.760 --> 01:04:41.760]   Yes.
[01:04:41.760 --> 01:04:42.760]   Like, it's not like--
[01:04:42.760 --> 01:04:43.760]   Isn't even autonomous.
[01:04:43.760 --> 01:04:48.760]   I mean, it's really just an algorithm saying, well, based on these three inputs you're holding
[01:04:48.760 --> 01:04:49.760]   in your hand.
[01:04:49.760 --> 01:04:51.760]   What's interesting about it, how intelligent is that?
[01:04:51.760 --> 01:04:54.040]   Yeah, it's not going to give us levitating cars and stuff like that.
[01:04:54.040 --> 01:05:00.040]   But what's interesting is every little thing is using some sort of something that could
[01:05:00.040 --> 01:05:01.040]   be considered AI.
[01:05:01.040 --> 01:05:02.040]   I'm very interested.
[01:05:02.040 --> 01:05:03.040]   Leo just said something--
[01:05:03.040 --> 01:05:08.040]   I'd like to hear your definition, Amy, because I think a lot of stuff we call AI is just algorithm.
[01:05:08.040 --> 01:05:09.040]   What is--
[01:05:09.040 --> 01:05:10.880]   And this is the-- yeah.
[01:05:10.880 --> 01:05:14.040]   So Leo just said something really, really smart, which is--
[01:05:14.040 --> 01:05:15.040]   What?
[01:05:15.040 --> 01:05:16.040]   Wait a minute.
[01:05:16.040 --> 01:05:17.040]   I know, right?
[01:05:17.040 --> 01:05:18.040]   It's crazy.
[01:05:18.040 --> 01:05:19.040]   Check your watch.
[01:05:19.040 --> 01:05:20.040]   I'm repeating.
[01:05:20.040 --> 01:05:27.040]   So since we had-- you know, AI has been in some form of development for 400 years and
[01:05:27.040 --> 01:05:28.040]   in the modern era--
[01:05:28.040 --> 01:05:29.040]   Leave it.
[01:05:29.040 --> 01:05:30.040]   Wait a minute.
[01:05:30.040 --> 01:05:31.040]   Wait a minute.
[01:05:31.040 --> 01:05:32.040]   How could it be 400 years?
[01:05:32.040 --> 01:05:33.040]   I mean, before computing?
[01:05:33.040 --> 01:05:38.040]   Because if you go all the way back, there is a-- and you could even go further back than
[01:05:38.040 --> 01:05:39.040]   that.
[01:05:39.040 --> 01:05:44.280]   There's always been a connection between mine and machine and the notion of making decisions
[01:05:44.280 --> 01:05:46.240]   and performing tasks.
[01:05:46.240 --> 01:05:52.600]   And all of-- you know, you can sort of draw a squiggly, but pretty consistent line between
[01:05:52.600 --> 01:06:02.600]   Descartes and Hobbes and Jan LeCunne, right, and the work that he's working on on a Facebook.
[01:06:02.600 --> 01:06:03.600]   But here's the thing.
[01:06:03.600 --> 01:06:10.080]   So throughout this entire process, every time something that is within the umbrella
[01:06:10.080 --> 01:06:16.280]   of artificial narrow intelligence becomes so routine and part of our everyday lives, we
[01:06:16.280 --> 01:06:19.560]   no longer think of it as intelligent, right?
[01:06:19.560 --> 01:06:28.760]   At the heart of it, all AI really is a series of-- you know, a system using data to make
[01:06:28.760 --> 01:06:29.760]   decisions.
[01:06:29.760 --> 01:06:33.720]   I mean, that's like the most basic explanation.
[01:06:33.720 --> 01:06:39.080]   And so the-- obviously, the world of AI is far more sophisticated than that, but that's
[01:06:39.080 --> 01:06:40.360]   what we're really talking about.
[01:06:40.360 --> 01:06:46.760]   And it's the ways in which that data is used, the types of data, and the kinds of decisions
[01:06:46.760 --> 01:06:49.920]   that are being made and the actions that result.
[01:06:49.920 --> 01:06:50.920]   So--
[01:06:50.920 --> 01:06:51.920]   OK.
[01:06:51.920 --> 01:06:58.600]   And so for that reason, again, I think Amazon is the company-- if you're watching AI, Apple
[01:06:58.600 --> 01:07:04.840]   is-- for me, Amazon is the company to watch, probably followed by Google.
[01:07:04.840 --> 01:07:09.760]   And then there's a drop off.
[01:07:09.760 --> 01:07:15.960]   You have something I covet, and I want you to show us in a little bit.
[01:07:15.960 --> 01:07:18.280]   And you have an email web.
[01:07:18.280 --> 01:07:23.480]   She spent some money to get something fancy, and it's not an Apple Watch or an Apple iPhone.
[01:07:23.480 --> 01:07:24.480]   Mike Algin is here.
[01:07:24.480 --> 01:07:30.320]   Digital-- by the way, I turned a lot of people on during our trip to Digital Nomad.
[01:07:30.320 --> 01:07:31.320]   Wonderful.
[01:07:31.320 --> 01:07:32.320]   Thank you.
[01:07:32.320 --> 01:07:34.640]   Because this is real travel.
[01:07:34.640 --> 01:07:35.640]   Gastronomad.net?
[01:07:35.640 --> 01:07:37.200]   That's it, not Digital Nomad.
[01:07:37.200 --> 01:07:38.200]   Gastronomad.
[01:07:38.200 --> 01:07:39.200]   I always get it wrong.
[01:07:39.200 --> 01:07:40.200]   Gastronomad.net.
[01:07:40.200 --> 01:07:41.200]   That's right.
[01:07:41.200 --> 01:07:46.600]   Mike and his wife are putting together travel experiences around food.
[01:07:46.600 --> 01:07:53.600]   If you click the experiences button at gastronomad.net, you'll see some of the experiences.
[01:07:53.600 --> 01:07:55.080]   Your next one is--
[01:07:55.080 --> 01:07:56.080]   We're doing Prosecco Hills.
[01:07:56.080 --> 01:07:57.080]   We're doing Prosecco Hills.
[01:07:57.080 --> 01:07:58.080]   We're second Prosecco experience--
[01:07:58.080 --> 01:07:59.080]   In Italy.
[01:07:59.080 --> 01:08:00.080]   --next month.
[01:08:00.080 --> 01:08:01.080]   It's sold out.
[01:08:01.080 --> 01:08:03.520]   We still have a couple of slots left from Mexico City for New Year's Eve.
[01:08:03.520 --> 01:08:05.360]   That's going to be completely crazy.
[01:08:05.360 --> 01:08:07.000]   Oh, I would love to do that.
[01:08:07.000 --> 01:08:10.760]   And Morocco experience, another Prosecco experience, and then Provence.
[01:08:10.760 --> 01:08:12.520]   And these are starting to fill up pretty quick.
[01:08:12.520 --> 01:08:14.000]   Maybe it's the people on your butt.
[01:08:14.000 --> 01:08:15.000]   That's good.
[01:08:15.000 --> 01:08:17.120]   But these are fantastic experiences.
[01:08:17.120 --> 01:08:19.120]   We do the opposite of tourism.
[01:08:19.120 --> 01:08:24.280]   Everything we do is exclusive to us and our group.
[01:08:24.280 --> 01:08:25.280]   And we get in there.
[01:08:25.280 --> 01:08:26.640]   We don't just taste wine.
[01:08:26.640 --> 01:08:27.640]   We make wine.
[01:08:27.640 --> 01:08:29.000]   And we taste it.
[01:08:29.000 --> 01:08:30.600]   We go to the homes of the winemakers.
[01:08:30.600 --> 01:08:35.000]   It's a very personal, very fun, it's constant fun.
[01:08:35.000 --> 01:08:36.000]   And--
[01:08:36.000 --> 01:08:37.000]   That's such a great idea.
[01:08:37.000 --> 01:08:39.800]   And I'm thrilled that it's really taken off.
[01:08:39.800 --> 01:08:40.720]   It really is.
[01:08:40.720 --> 01:08:42.280]   Are you a repeat people?
[01:08:42.280 --> 01:08:43.280]   A few.
[01:08:43.280 --> 01:08:45.280]   We had some people who signed up and meet halfway through
[01:08:45.280 --> 01:08:47.680]   and experienced this kind of the next one.
[01:08:47.680 --> 01:08:50.920]   So we're increasing the number of people who are repeats.
[01:08:50.920 --> 01:08:52.880]   We have somebody who signed up for three in a row.
[01:08:52.880 --> 01:08:54.400]   Just boom, boom, boom.
[01:08:54.400 --> 01:08:55.400]   It's really--
[01:08:55.400 --> 01:08:56.560]   I better get on the list quick.
[01:08:56.560 --> 01:08:57.560]   It's really resonating.
[01:08:57.560 --> 01:08:59.160]   How big is each group?
[01:08:59.160 --> 01:09:00.080]   6 to 10 people.
[01:09:00.080 --> 01:09:01.560]   They're small, which is what I love.
[01:09:01.560 --> 01:09:03.120]   Prosecco Hills is only 6 because we're
[01:09:03.120 --> 01:09:05.320]   in this 400-year-old farmhouse.
[01:09:05.320 --> 01:09:07.520]   They built it with the very first artificial intelligence
[01:09:07.520 --> 01:09:09.720]   400 years ago.
[01:09:09.720 --> 01:09:10.920]   You know what it was?
[01:09:10.920 --> 01:09:13.720]   They put the livestock on the bottom floor.
[01:09:13.720 --> 01:09:14.720]   That's right.
[01:09:14.720 --> 01:09:16.120]   And the heat rises and heats the entire building.
[01:09:16.120 --> 01:09:18.120]   So does the odor, but--
[01:09:18.120 --> 01:09:19.120]   You're warm.
[01:09:19.120 --> 01:09:21.120]   You know, so that's better than nothing.
[01:09:21.120 --> 01:09:26.520]   So a biggest one was Provence, which we had 10 people.
[01:09:26.520 --> 01:09:27.520]   But it's really small.
[01:09:27.520 --> 01:09:28.720]   They're all very small.
[01:09:28.720 --> 01:09:29.720]   Very small.
[01:09:29.720 --> 01:09:30.720]   It's highly curated.
[01:09:30.720 --> 01:09:31.720]   Yes, highly curated.
[01:09:31.720 --> 01:09:32.720]   What fun.
[01:09:32.720 --> 01:09:34.520]   It's all food all the time.
[01:09:34.520 --> 01:09:37.520]   And my wife is just genius at finding these people
[01:09:37.520 --> 01:09:38.520]   and these visionaries.
[01:09:38.520 --> 01:09:40.520]   And I don't like this fantastic--
[01:09:40.520 --> 01:09:42.320]   If you want to check it out, just check out the website
[01:09:42.320 --> 01:09:43.920]   and everything is explained there.
[01:09:43.920 --> 01:09:45.920]   Do you arrange all the travel and everything?
[01:09:45.920 --> 01:09:47.520]   People arrange their own airfare.
[01:09:47.520 --> 01:09:48.720]   We pick them up the airport.
[01:09:48.720 --> 01:09:51.720]   And between them, pick up and drop off, we take care of everything.
[01:09:51.720 --> 01:09:52.720]   We're in charge.
[01:09:52.720 --> 01:09:55.720]   And the funny thing is that it's just like,
[01:09:55.720 --> 01:09:57.120]   this is what we love to do.
[01:09:57.120 --> 01:10:01.520]   It's like we can't believe that we get to do this every time.
[01:10:01.520 --> 01:10:02.520]   Yeah.
[01:10:02.520 --> 01:10:03.520]   It's just so much fun for us.
[01:10:03.520 --> 01:10:04.920]   This is an example of somebody's fans--
[01:10:04.920 --> 01:10:06.920]   You know, something that they love to do and found a way
[01:10:06.920 --> 01:10:08.920]   to make a living doing this.
[01:10:08.920 --> 01:10:11.920]   And it's got to be challenging, because you're all over the world.
[01:10:11.920 --> 01:10:12.920]   I mean, it's impressive.
[01:10:12.920 --> 01:10:13.920]   It's challenging for my wife.
[01:10:13.920 --> 01:10:15.920]   Yeah, me neither has a brilliant cook.
[01:10:15.920 --> 01:10:16.920]   Yeah, me neither has a mess cooks.
[01:10:16.920 --> 01:10:17.920]   I've ever had the pleasure.
[01:10:17.920 --> 01:10:20.920]   But we've got to a place, and it should be there for months,
[01:10:20.920 --> 01:10:21.920]   planning these things.
[01:10:21.920 --> 01:10:22.920]   Yeah.
[01:10:22.920 --> 01:10:23.920]   And then the thing is a week.
[01:10:23.920 --> 01:10:24.920]   And so we really can condense it.
[01:10:24.920 --> 01:10:26.920]   But she does almost all the planning.
[01:10:26.920 --> 01:10:27.920]   Yeah.
[01:10:27.920 --> 01:10:28.920]   And I do almost all the--
[01:10:28.920 --> 01:10:29.920]   All the eating and drinking.
[01:10:29.920 --> 01:10:30.920]   --and drinking.
[01:10:30.920 --> 01:10:31.920]   So, Division of Labor.
[01:10:31.920 --> 01:10:32.920]   Amy Webb is also here.
[01:10:32.920 --> 01:10:34.920]   Her previous book, The Signals Are Talking
[01:10:34.920 --> 01:10:37.920]   is available on Amazon and everywhere.
[01:10:37.920 --> 01:10:39.920]   About becoming a futurist.
[01:10:39.920 --> 01:10:40.920]   Her new book is on AI.
[01:10:40.920 --> 01:10:42.920]   It comes out-- you said in a couple of months, I'm excited.
[01:10:42.920 --> 01:10:43.920]   That's great.
[01:10:43.920 --> 01:10:46.920]   It comes out on March 5th and then launches at South By.
[01:10:46.920 --> 01:10:47.920]   Southwest.
[01:10:47.920 --> 01:10:50.920]   You can find out more about Amy and what she does at Future
[01:10:50.920 --> 01:10:51.920]   Today Institute.
[01:10:51.920 --> 01:10:56.920]   In fact, they put out a report every year of what the future is
[01:10:56.920 --> 01:10:57.920]   or something.
[01:10:57.920 --> 01:10:59.920]   Yeah, we have an annual report.
[01:10:59.920 --> 01:11:01.920]   It's an 11th year.
[01:11:01.920 --> 01:11:03.920]   On all the emerging tech trends, you need to pay attention
[01:11:03.920 --> 01:11:05.920]   to for the following year.
[01:11:05.920 --> 01:11:08.920]   Last year, we had like 175.
[01:11:08.920 --> 01:11:11.920]   We've already started putting together Next Year's Report,
[01:11:11.920 --> 01:11:18.920]   which is-- I'm being told by the company that prints the books,
[01:11:18.920 --> 01:11:20.920]   that it is larger than they would like for it to be.
[01:11:20.920 --> 01:11:21.920]   [LAUGHTER]
[01:11:21.920 --> 01:11:24.920]   I'm sorry, but the future's not getting smaller.
[01:11:24.920 --> 01:11:25.920]   It's not.
[01:11:25.920 --> 01:11:26.920]   The tech trends.
[01:11:26.920 --> 01:11:30.920]   So you can get the 2018 tech trends now at FutureTodayInstitute.com
[01:11:30.920 --> 01:11:32.920]   and you can, of course--
[01:11:32.920 --> 01:11:34.920]   keep an eye on Amy.
[01:11:34.920 --> 01:11:38.920]   And I have to say that definitely I'm looking forward to the next book,
[01:11:38.920 --> 01:11:40.920]   but everybody should definitely read the last book.
[01:11:40.920 --> 01:11:41.920]   Signals are talking.
[01:11:41.920 --> 01:11:42.920]   It's very good.
[01:11:42.920 --> 01:11:43.920]   Love how you start.
[01:11:43.920 --> 01:11:45.920]   It has this sort of like, "neuromancer feel."
[01:11:45.920 --> 01:11:46.920]   Yeah, not how I--
[01:11:46.920 --> 01:11:48.920]   Sky was the color of television.
[01:11:48.920 --> 01:11:49.920]   [LAUGHTER]
[01:11:49.920 --> 01:11:50.920]   I don't know.
[01:11:50.920 --> 01:11:51.920]   I shouldn't say that.
[01:11:51.920 --> 01:11:53.920]   But yeah, it's a very, very good book everyone really should read it.
[01:11:53.920 --> 01:11:54.920]   Thank you.
[01:11:54.920 --> 01:11:55.920]   Thanks.
[01:11:55.920 --> 01:11:56.920]   Highly recommend it.
[01:11:56.920 --> 01:12:00.920]   And there is an audio version that I did not read, which is good.
[01:12:00.920 --> 01:12:01.920]   [LAUGHTER]
[01:12:01.920 --> 01:12:03.920]   Get it on Audible, yeah.
[01:12:03.920 --> 01:12:06.920]   Our show today brought to you by WordPress.
[01:12:06.920 --> 01:12:08.920]   So I think I mentioned this.
[01:12:08.920 --> 01:12:09.920]   I certainly blogged it.
[01:12:09.920 --> 01:12:15.920]   I have discontinued my use of the evil trio, Facebook, Twitter,
[01:12:15.920 --> 01:12:20.920]   and Instagram, preferring instead to mail postcards.
[01:12:20.920 --> 01:12:22.920]   I think that's so cool.
[01:12:22.920 --> 01:12:23.920]   Oh, it was so much fun.
[01:12:23.920 --> 01:12:24.920]   It was really do.
[01:12:24.920 --> 01:12:26.920]   Bill Atkinson's a photocard app.
[01:12:26.920 --> 01:12:29.920]   And I mailed it to family and friends, but what I realized is
[01:12:29.920 --> 01:12:32.920]   that this also makes an excellent blog piece.
[01:12:32.920 --> 01:12:35.920]   So I'm putting my stuff on my WordPress blog.
[01:12:35.920 --> 01:12:36.920]   I love WordPress.com.
[01:12:36.920 --> 01:12:39.920]   It's made it very easy for me.
[01:12:39.920 --> 01:12:42.920]   As easy to post to WordPress as it would be to put up a picture on
[01:12:42.920 --> 01:12:44.920]   Instagram or to even to tweet.
[01:12:44.920 --> 01:12:48.920]   It made it very easy for me to share my life and my travels.
[01:12:48.920 --> 01:12:50.920]   These are some pictures from Barcelona.
[01:12:50.920 --> 01:12:52.920]   There's my beautiful wife.
[01:12:52.920 --> 01:12:54.920]   We had so much fun.
[01:12:54.920 --> 01:12:55.920]   There's my pants.
[01:12:55.920 --> 01:12:59.920]   And I'm putting the postcards up too.
[01:12:59.920 --> 01:13:06.920]   WordPress is a great place to not only to host them, but to post them.
[01:13:06.920 --> 01:13:09.920]   And I really like the idea of, you know, you can keep your social media.
[01:13:09.920 --> 01:13:12.920]   I'm not saying get rid of your social media, but you ought to have a
[01:13:12.920 --> 01:13:15.920]   place on the internet that's your home.
[01:13:15.920 --> 01:13:17.920]   I find it easier to follow you now.
[01:13:17.920 --> 01:13:18.920]   I think so.
[01:13:18.920 --> 01:13:19.920]   Because I get it via email.
[01:13:19.920 --> 01:13:20.920]   And it gets right to the news.
[01:13:20.920 --> 01:13:21.920]   You can subscribe to it.
[01:13:21.920 --> 01:13:22.920]   You asked that on one of the comments.
[01:13:22.920 --> 01:13:23.920]   Yeah.
[01:13:23.920 --> 01:13:27.920]   And I did not reply, but there is a subscription link somewhere on there.
[01:13:27.920 --> 01:13:28.920]   It's fantastic.
[01:13:28.920 --> 01:13:30.920]   That's one of the things I like about WordPress.
[01:13:30.920 --> 01:13:33.920]   I was able to post this with very limited bandwidth from the ship.
[01:13:33.920 --> 01:13:38.920]   From a boat, probably using cell phone and get it out there.
[01:13:38.920 --> 01:13:39.920]   I publish it.
[01:13:39.920 --> 01:13:42.920]   And that was really, really a lot of fun.
[01:13:42.920 --> 01:13:43.920]   I am such a fan.
[01:13:43.920 --> 01:13:44.920]   WordPress.com.
[01:13:44.920 --> 01:13:49.920]   If you're a business, if you're an individual, you really need to have your
[01:13:49.920 --> 01:13:52.920]   place, the place on the web that is you.
[01:13:52.920 --> 01:13:56.920]   Yeah, it's good to have a Facebook page or a Twitter account or an Instagram.
[01:13:56.920 --> 01:13:58.920]   You should probably do all of that.
[01:13:58.920 --> 01:14:01.920]   But it should all link back to your domain.
[01:14:01.920 --> 01:14:05.920]   That's what Google is going to show when somebody searches for your name, your
[01:14:05.920 --> 01:14:06.920]   business name.
[01:14:06.920 --> 01:14:07.920]   And it's so easy.
[01:14:07.920 --> 01:14:11.920]   WordPress takes care of the hosting, the security, the software updates.
[01:14:11.920 --> 01:14:13.920]   You focus on the content.
[01:14:13.920 --> 01:14:19.920]   And I was using, I use the WordPress apps on my iPhone or my iPad, which made it even
[01:14:19.920 --> 01:14:20.920]   easier.
[01:14:20.920 --> 01:14:23.920]   The great app was so simple to post this.
[01:14:23.920 --> 01:14:24.920]   It's just fantastic.
[01:14:24.920 --> 01:14:26.920]   Upload images, video, audio.
[01:14:26.920 --> 01:14:31.920]   And by the way, of course, you can link to YouTube or Twitter or Facebook.
[01:14:31.920 --> 01:14:33.920]   When you put the images on your site, you own them.
[01:14:33.920 --> 01:14:34.920]   They're yours.
[01:14:34.920 --> 01:14:37.920]   You never going to lose them.
[01:14:37.920 --> 01:14:42.920]   If Twitter closes down or closes your account, this lives on.
[01:14:42.920 --> 01:14:46.920]   And by the way, very easy to get data into and out of WordPress.
[01:14:46.920 --> 01:14:48.920]   I really like that.
[01:14:48.920 --> 01:14:51.920]   Grow your audience and reach new customers with built-in search engine
[01:14:51.920 --> 01:14:53.920]   optimization, social media features.
[01:14:53.920 --> 01:14:58.920]   For instance, people can share my pictures on their Instagram or their Twitter or their
[01:14:58.920 --> 01:14:59.920]   Facebook.
[01:14:59.920 --> 01:15:01.920]   It's very easy with a simple button push.
[01:15:01.920 --> 01:15:06.920]   That way the world is helping you promote yourself.
[01:15:06.920 --> 01:15:11.920]   And you're going to get help from WordPress 24/7 support, the best support team in the
[01:15:11.920 --> 01:15:12.920]   world.
[01:15:12.920 --> 01:15:15.920]   WordPress plans started $4 a month.
[01:15:15.920 --> 01:15:21.920]   And there's a good reason 31% of all websites, including mine, run on WordPress 31%.
[01:15:21.920 --> 01:15:22.920]   It's the best.
[01:15:22.920 --> 01:15:24.920]   Right now, get 15% off any new plan purchase.
[01:15:24.920 --> 01:15:28.920]   Go to WordPress.com/twit to create your website.
[01:15:28.920 --> 01:15:31.920]   WordPress.com/twit.
[01:15:31.920 --> 01:15:33.920]   WordPress.com/twit.
[01:15:33.920 --> 01:15:37.920]   It was funny because these postcards are being mailed, right?
[01:15:37.920 --> 01:15:39.920]   And so there's four, I think, still to come.
[01:15:39.920 --> 01:15:40.920]   Can I see one of those?
[01:15:40.920 --> 01:15:42.920]   They haven't arrived yet.
[01:15:42.920 --> 01:15:46.320]   At first, I was putting them up on the WordPress blog and I realized, well, that's not fair
[01:15:46.320 --> 01:15:47.680]   to the people I'm mailing them to.
[01:15:47.680 --> 01:15:49.800]   So I have to wait till they arrive.
[01:15:49.800 --> 01:15:52.920]   And then I will post the remaining postcards on the blog.
[01:15:52.920 --> 01:15:54.520]   What service did you use?
[01:15:54.520 --> 01:15:59.160]   So this is Bill Atkinson, the guy who created HyperCard and most of the Macintosh software.
[01:15:59.160 --> 01:16:04.280]   He has, and I don't worry because I think nobody's, people aren't using this.
[01:16:04.280 --> 01:16:05.920]   Bill said, yeah, it's a lot of work.
[01:16:05.920 --> 01:16:09.600]   And it's just not generating the traffic, I thought, but it's called PhotoCard.
[01:16:09.600 --> 01:16:11.520]   It's an iOS app.
[01:16:11.520 --> 01:16:14.120]   And it makes these laminated, large laminated cards.
[01:16:14.120 --> 01:16:15.120]   It mails them too.
[01:16:15.120 --> 01:16:19.120]   So I'm in Europe and I don't have to, it got mailed from the US.
[01:16:19.120 --> 01:16:22.120]   It costs about a buck 50, that includes the postage.
[01:16:22.120 --> 01:16:23.320]   These are really good quality.
[01:16:23.320 --> 01:16:24.520]   Yeah, super high quality.
[01:16:24.520 --> 01:16:27.520]   So you could frame them or whatever.
[01:16:27.520 --> 01:16:32.920]   I just, I said it to my mom, my kids, Lisa's parents, Lisa's sister.
[01:16:32.920 --> 01:16:35.720]   I said, wanted to work.
[01:16:35.720 --> 01:16:40.880]   Just as a way to kind of say, in the past I've put it on Instagram and I don't, I think
[01:16:40.880 --> 01:16:41.880]   this is actually better.
[01:16:41.880 --> 01:16:44.480]   Yeah, it gets lost in the mix on Instagram and here.
[01:16:44.480 --> 01:16:45.480]   Those are frameable.
[01:16:45.480 --> 01:16:46.480]   Those are really nice.
[01:16:46.480 --> 01:16:48.240]   I know the quality is really good.
[01:16:48.240 --> 01:16:51.160]   And you know, you write on the back, you write a little stuff.
[01:16:51.160 --> 01:16:54.000]   I put it in a handwriting font, so it looks like I'm actually writing.
[01:16:54.000 --> 01:16:58.200]   Now you have to import the photos into your iPhone and then you see up there.
[01:16:58.200 --> 01:16:59.200]   Okay.
[01:16:59.200 --> 01:17:02.440]   So what the camera I use, and most cameras will do this, Canon does this, Panasonic does
[01:17:02.440 --> 01:17:07.040]   it, but the Sony software, it's really weird software, but it will import from the camera
[01:17:07.040 --> 01:17:08.040]   via Wi-Fi.
[01:17:08.040 --> 01:17:09.880]   So every night I'd get home.
[01:17:09.880 --> 01:17:13.560]   I'd copy everything over to the iPad, so I had all the access to all that stuff.
[01:17:13.560 --> 01:17:17.240]   But and I, even though I had Lightroom, I didn't bother editing these yet.
[01:17:17.240 --> 01:17:18.240]   Yeah.
[01:17:18.240 --> 01:17:19.240]   But yeah, you know what?
[01:17:19.240 --> 01:17:21.520]   A good lens makes a lot, all the difference in the world.
[01:17:21.520 --> 01:17:26.280]   This is a really superb lens on a 42 megapixel full frame.
[01:17:26.280 --> 01:17:29.640]   Do you ever play around with any of those lenses for mobile?
[01:17:29.640 --> 01:17:31.760]   Do you think those are worth it?
[01:17:31.760 --> 01:17:35.920]   Well, so what happens when you start doing all that stuff is it degrades the image a
[01:17:35.920 --> 01:17:37.160]   little bit.
[01:17:37.160 --> 01:17:41.120]   So, you know, because they're going to always opt for fat speed.
[01:17:41.120 --> 01:17:45.760]   It also ruins the whole point of using your phone, which is whip it out, take a picture,
[01:17:45.760 --> 01:17:46.760]   put it back in your pocket.
[01:17:46.760 --> 01:17:48.920]   If you have to take it out, like mount a lens.
[01:17:48.920 --> 01:17:52.560]   That's what I find as I have all, oh, you mean the physical lenses you're talking about?
[01:17:52.560 --> 01:17:53.560]   Yeah, I'm talking about the physical.
[01:17:53.560 --> 01:17:54.560]   Oh, yeah, those are.
[01:17:54.560 --> 01:17:55.560]   I've had those.
[01:17:55.560 --> 01:17:57.560]   And this is what's a point, you know?
[01:17:57.560 --> 01:17:59.760]   Yeah, there are some more expensive ones that are good.
[01:17:59.760 --> 01:18:00.760]   Yeah, what's the point?
[01:18:00.760 --> 01:18:01.760]   Yeah.
[01:18:01.760 --> 01:18:04.760]   And, but I have to say, none of these were iPhone pictures.
[01:18:04.760 --> 01:18:11.480]   There are a few iPhone pictures on here, but almost all of these are with a good camera.
[01:18:11.480 --> 01:18:14.360]   And it's funny because I only brought one lens.
[01:18:14.360 --> 01:18:19.280]   So if I needed something a little more panoramic, I would actually whip out the pixel or the
[01:18:19.280 --> 01:18:20.280]   iPhone.
[01:18:20.280 --> 01:18:24.400]   But anyway, it's a lot of fun, a lot of fun.
[01:18:24.400 --> 01:18:31.000]   And I don't miss Instagram, Lisa posted Instagram, but so I'm putting these postcards.
[01:18:31.000 --> 01:18:34.080]   It's nice that his program lets you save an image of the postcards.
[01:18:34.080 --> 01:18:38.200]   So I saved the image and then post that as a blog post is a blog post.
[01:18:38.200 --> 01:18:41.240]   But when I now it's not editable text or anything.
[01:18:41.240 --> 01:18:45.440]   So that's the next thing I'm going to do is make it more accessible by putting the text
[01:18:45.440 --> 01:18:48.040]   as the, you know, hover over to get the stamp and everything.
[01:18:48.040 --> 01:18:51.040]   Yeah, you know, the other thing he does is he lets you do custom stamps.
[01:18:51.040 --> 01:18:59.080]   So I use the like that's called this is, I'll zoom in on a little bit here, that's Columbus.
[01:18:59.080 --> 01:19:04.520]   So the city fathers of this is in the civil cathedral.
[01:19:04.520 --> 01:19:08.960]   The city fathers of Seville were really terrified of Columbus, especially the king because he
[01:19:08.960 --> 01:19:13.240]   was became so powerful after he came back to Spain and in rich Spain and made it one
[01:19:13.240 --> 01:19:15.240]   of the great world powers.
[01:19:15.240 --> 01:19:16.760]   He was so powerful.
[01:19:16.760 --> 01:19:17.760]   They were terrified of him.
[01:19:17.760 --> 01:19:23.360]   So when they when he died, they shipped his body back to the new world.
[01:19:23.360 --> 01:19:24.640]   He was for a long time.
[01:19:24.640 --> 01:19:29.360]   He was in the in the Caribbean and they finally brought him back a couple hundred years ago
[01:19:29.360 --> 01:19:31.760]   and they have a they have a is coffin.
[01:19:31.760 --> 01:19:32.920]   And but people were worried.
[01:19:32.920 --> 01:19:33.920]   Is it really Columbus?
[01:19:33.920 --> 01:19:38.440]   I mean, his the corpse has been the bones have been rattled around all over the world.
[01:19:38.440 --> 01:19:43.800]   So a couple of years ago, they did a DNA analysis and it is a couple of people still
[01:19:43.800 --> 01:19:48.000]   alive that are descendants of his and they were able to verify that those are actually
[01:19:48.000 --> 01:19:49.560]   Christopher Columbus's bones.
[01:19:49.560 --> 01:19:50.560]   Huh.
[01:19:50.560 --> 01:19:51.720]   Now they're on your postcard.
[01:19:51.720 --> 01:19:52.720]   And now they're on my.
[01:19:52.720 --> 01:19:53.720]   It's a new world.
[01:19:53.720 --> 01:19:56.120]   And then the Saville Cathedral is the largest cathedral in the world.
[01:19:56.120 --> 01:19:57.120]   I haven't.
[01:19:57.120 --> 01:19:58.560]   It's a made in studying.
[01:19:58.560 --> 01:20:02.400]   You've been every been since the bill is so so I loved to go.
[01:20:02.400 --> 01:20:03.400]   So great.
[01:20:03.400 --> 01:20:08.160]   And and it's they have a thing called the Saville festival to week or two weeks of just the
[01:20:08.160 --> 01:20:12.120]   most intense overpowering Spanishness in your face all day.
[01:20:12.120 --> 01:20:15.400]   All the way as long as there's him on the barreco.
[01:20:15.400 --> 01:20:16.960]   I don't care.
[01:20:16.960 --> 01:20:19.840]   And it's it's but that's a great city.
[01:20:19.840 --> 01:20:23.000]   If you're vegetarian, I apologize for that image because it's actually physically.
[01:20:23.000 --> 01:20:24.000]   Do they?
[01:20:24.000 --> 01:20:25.000]   Does it all taste different?
[01:20:25.000 --> 01:20:26.280]   I mean, are they the different?
[01:20:26.280 --> 01:20:27.440]   I've never eaten it before.
[01:20:27.440 --> 01:20:28.440]   So is it?
[01:20:28.440 --> 01:20:30.440]   Yeah, it's all pretty darn good.
[01:20:30.440 --> 01:20:33.520]   The different the thing that makes a difference that pigs eat acorns.
[01:20:33.520 --> 01:20:35.920]   Yeah, they're acorns.
[01:20:35.920 --> 01:20:41.400]   The in general, the the the flesh that you consume in both Spain, Italy and France is
[01:20:41.400 --> 01:20:44.560]   similar significantly better than anywhere else.
[01:20:44.560 --> 01:20:48.720]   I think like the beef in France for some reason is just so good.
[01:20:48.720 --> 01:20:49.720]   Oh, man.
[01:20:49.720 --> 01:20:51.480]   But yeah, don't get me started.
[01:20:51.480 --> 01:20:55.600]   One of these days, my dream Leo is to walk onto an airplane with one of those haunches,
[01:20:55.600 --> 01:20:59.600]   you know, with the leg with the I wanted to take it away.
[01:20:59.600 --> 01:21:01.000]   I wanted to take one.
[01:21:01.000 --> 01:21:02.200]   It's your support animal.
[01:21:02.200 --> 01:21:03.400]   Yeah, exactly.
[01:21:03.400 --> 01:21:04.400]   That's brilliant.
[01:21:04.400 --> 01:21:05.400]   That's right.
[01:21:05.400 --> 01:21:07.240]   It's my emotional support.
[01:21:07.240 --> 01:21:15.040]   I can't fly without a ham in the seat next to me.
[01:21:15.040 --> 01:21:16.040]   Genius.
[01:21:16.040 --> 01:21:17.040]   Wow.
[01:21:17.040 --> 01:21:23.000]   And like dare them to tell you that if somebody can bring on a peacock, which is alive, that
[01:21:23.000 --> 01:21:26.120]   a dead animal is somehow worse.
[01:21:26.120 --> 01:21:27.600]   I think you can bring it on the plane.
[01:21:27.600 --> 01:21:28.600]   I don't think it's the plane.
[01:21:28.600 --> 01:21:29.600]   This problem.
[01:21:29.600 --> 01:21:31.200]   I think it's it's the customs and border patrol.
[01:21:31.200 --> 01:21:34.600]   By the way, it is easy to get in the United States.
[01:21:34.600 --> 01:21:38.080]   If you're an old white man, oh, yeah, it's a snap.
[01:21:38.080 --> 01:21:39.840]   They just say, come on back.
[01:21:39.840 --> 01:21:40.840]   Welcome back.
[01:21:40.840 --> 01:21:42.880]   I just went through like that.
[01:21:42.880 --> 01:21:45.560]   I was all prepared to erase all my data and all that stuff.
[01:21:45.560 --> 01:21:47.360]   They said, now Leo, you're an old white man.
[01:21:47.360 --> 01:21:48.360]   Come on in.
[01:21:48.360 --> 01:21:49.360]   A lot of people don't know this.
[01:21:49.360 --> 01:21:50.360]   Your iPhone and excess.
[01:21:50.360 --> 01:21:53.720]   A lot of people don't know this, but you can legally bring tons of cheese into the
[01:21:53.720 --> 01:21:54.720]   US.
[01:21:54.720 --> 01:21:55.720]   You can't bring cheese.
[01:21:55.720 --> 01:21:56.720]   Cheese.
[01:21:56.720 --> 01:21:57.720]   Leo, it has to be.
[01:21:57.720 --> 01:21:58.720]   Oh, I'd bring cheese.
[01:21:58.720 --> 01:21:59.720]   It has to be vacuum sealed.
[01:21:59.720 --> 01:22:02.800]   You can just yield cheese with a clear conscience.
[01:22:02.800 --> 01:22:06.520]   Just bring huge wheels with Parmesan and like, I guess the cheese lobby wasn't as good as
[01:22:06.520 --> 01:22:08.320]   the beef flop.
[01:22:08.320 --> 01:22:09.520]   Exactly.
[01:22:09.520 --> 01:22:10.800]   By the way, happy birthday.
[01:22:10.800 --> 01:22:16.160]   Today is the 10th anniversary of the announcement of this.
[01:22:16.160 --> 01:22:20.600]   Remember when the iPhone came out in 2007?
[01:22:20.600 --> 01:22:24.400]   Google does because they had an Android phone ready to ship that just didn't look like an
[01:22:24.400 --> 01:22:25.400]   iPhone.
[01:22:25.400 --> 01:22:30.240]   They went crazy and went back to the drawing board and created this thing.
[01:22:30.240 --> 01:22:31.240]   This is the G1.
[01:22:31.240 --> 01:22:32.960]   It was on T-Mobile.
[01:22:32.960 --> 01:22:34.800]   I bought it right away.
[01:22:34.800 --> 01:22:40.760]   I remember Colleen Kelly, our engineering manager at the time, she was a Google fanatic.
[01:22:40.760 --> 01:22:45.200]   When that Google phone comes out, forget the iPhone.
[01:22:45.200 --> 01:22:47.040]   No, it was really underpowered.
[01:22:47.040 --> 01:22:50.200]   It had, look at that, those snaps up and had a keyboard.
[01:22:50.200 --> 01:22:51.400]   But it was the first Android phone.
[01:22:51.400 --> 01:22:56.080]   I think it was running cupcake, I think.
[01:22:56.080 --> 01:22:57.080]   Was it?
[01:22:57.080 --> 01:22:58.080]   Yeah, cupcake.
[01:22:58.080 --> 01:22:59.760]   That was the era of the sidekick.
[01:22:59.760 --> 01:23:00.760]   The sidekick's personal popcorn.
[01:23:00.760 --> 01:23:04.280]   The screen is not significantly larger than the one on your wrist.
[01:23:04.280 --> 01:23:08.240]   No, but there's one thing that Google was really prescient on.
[01:23:08.240 --> 01:23:10.400]   There's no headphone jack on this.
[01:23:10.400 --> 01:23:12.160]   They saw the culture.
[01:23:12.160 --> 01:23:13.640]   They called it.
[01:23:13.640 --> 01:23:15.240]   They called it.
[01:23:15.240 --> 01:23:16.240]   They were the first.
[01:23:16.240 --> 01:23:18.240]   Oh my God.
[01:23:18.240 --> 01:23:21.840]   Pixel 3 will be coming out October 9th.
[01:23:21.840 --> 01:23:23.720]   Does it not have a jack?
[01:23:23.720 --> 01:23:24.720]   Does not have a jack.
[01:23:24.720 --> 01:23:25.720]   For real?
[01:23:25.720 --> 01:23:27.760]   Did the Pixel 2 didn't have a jack?
[01:23:27.760 --> 01:23:28.760]   No.
[01:23:28.760 --> 01:23:32.440]   That's just to me, slavish copying of Apple.
[01:23:32.440 --> 01:23:36.520]   By the way, it doesn't have a jack and it does have a notch.
[01:23:36.520 --> 01:23:38.520]   That I cannot understand.
[01:23:38.520 --> 01:23:39.520]   I understand the notch.
[01:23:39.520 --> 01:23:41.440]   Actually, I'm the other way around.
[01:23:41.440 --> 01:23:46.400]   I understand the notch because you don't want any bezel and you've got to put some cameras
[01:23:46.400 --> 01:23:47.400]   there.
[01:23:47.400 --> 01:23:48.400]   That's fine.
[01:23:48.400 --> 01:23:49.400]   I can live with the notch.
[01:23:49.400 --> 01:23:50.640]   I don't understand the lack of a headphone jack.
[01:23:50.640 --> 01:23:53.000]   I think that that's insane.
[01:23:53.000 --> 01:23:55.960]   But I have to live with it.
[01:23:55.960 --> 01:23:57.840]   And everybody seems to be doing it.
[01:23:57.840 --> 01:24:07.600]   Apparently, according to Kas von Dinter, there is a fourth color in the source code.
[01:24:07.600 --> 01:24:11.160]   There's a line you only hear on geek shows.
[01:24:11.160 --> 01:24:15.120]   There's a fourth color in the source code, pink.
[01:24:15.120 --> 01:24:16.120]   Pink.
[01:24:16.120 --> 01:24:19.440]   For the Google Pixel 3, it will also be available in pink.
[01:24:19.440 --> 01:24:21.440]   What does it matter?
[01:24:21.440 --> 01:24:25.400]   Nobody can own a phone that doesn't have a case on it because they shatter a few.
[01:24:25.400 --> 01:24:26.400]   Exactly.
[01:24:26.400 --> 01:24:28.120]   What does it matter with color the phone is?
[01:24:28.120 --> 01:24:30.760]   You're like my wife because I said, "What color do you watch this on?
[01:24:30.760 --> 01:24:31.760]   I don't care.
[01:24:31.760 --> 01:24:34.120]   It's a perfect case."
[01:24:34.120 --> 01:24:35.960]   You guys have cases on your phones, right?
[01:24:35.960 --> 01:24:36.960]   Yeah.
[01:24:36.960 --> 01:24:37.960]   You know what?
[01:24:37.960 --> 01:24:40.120]   Before I got the phone, I got the case.
[01:24:40.120 --> 01:24:42.760]   It always comes first and it gets me all excited.
[01:24:42.760 --> 01:24:45.160]   There's a package from Apple on your desk, Leo.
[01:24:45.160 --> 01:24:46.160]   Oh, great.
[01:24:46.160 --> 01:24:47.160]   It's a case.
[01:24:47.160 --> 01:24:51.880]   Wow, that's exciting.
[01:24:51.880 --> 01:24:52.880]   Let's see.
[01:24:52.880 --> 01:24:54.200]   Oh, Google has suppressed a memo.
[01:24:54.200 --> 01:24:57.560]   This is according to the Intercept.
[01:24:57.560 --> 01:25:03.120]   Revealing plans to closely track search users in China.
[01:25:03.120 --> 01:25:08.680]   Basically the search tool would be associated with a phone number so that the Chinese government
[01:25:08.680 --> 01:25:10.600]   can know exactly who's searching for what.
[01:25:10.600 --> 01:25:12.200]   Yeah, this isn't Google.
[01:25:12.200 --> 01:25:14.160]   Google doesn't care.
[01:25:14.160 --> 01:25:15.760]   They're doing this for the Chinese.
[01:25:15.760 --> 01:25:16.760]   Yes.
[01:25:16.760 --> 01:25:20.560]   Apparently, and this is part of the controversy which caused some of the...
[01:25:20.560 --> 01:25:22.680]   Which is more commonly than never, but they're movements.
[01:25:22.680 --> 01:25:23.680]   Exactly.
[01:25:23.680 --> 01:25:29.160]   This is a great tool for China's alarmingly growing surveillance state.
[01:25:29.160 --> 01:25:34.080]   Everyone is really on the forefront of using advanced technology to surveil and monitor
[01:25:34.080 --> 01:25:37.320]   the population and control them and stuff like that.
[01:25:37.320 --> 01:25:39.640]   This would be another example of that.
[01:25:39.640 --> 01:25:43.000]   Everyone is disappointed in this because Google is the one company you could point to that
[01:25:43.000 --> 01:25:47.320]   said, "Look, they left China on principle because they were hacked by the Chinese government
[01:25:47.320 --> 01:25:50.120]   because the Chinese government wanted them to censor," etc.
[01:25:50.120 --> 01:25:51.840]   They left and said, "Oh, wow.
[01:25:51.840 --> 01:25:55.240]   Google's a little bit better than other companies."
[01:25:55.240 --> 01:25:58.560]   This report seems to indicate that maybe they've changed their tune and they don't want
[01:25:58.560 --> 01:25:59.760]   to be better than other companies.
[01:25:59.760 --> 01:26:02.240]   Google did not respond to the intercept story.
[01:26:02.240 --> 01:26:06.880]   Amy, last time you were on, we talked about Chinese, the Chinese social credit system.
[01:26:06.880 --> 01:26:07.880]   Sure.
[01:26:07.880 --> 01:26:12.600]   Again, none of this should come as a shock to anybody.
[01:26:12.600 --> 01:26:15.360]   Well, it's no shock that China wants to do it.
[01:26:15.360 --> 01:26:18.960]   It's a little disappointing that Google is helping them.
[01:26:18.960 --> 01:26:19.960]   Right.
[01:26:19.960 --> 01:26:27.080]   Google has had a presence in China for a very long time as have Apple and Microsoft.
[01:26:27.080 --> 01:26:36.720]   Again, from my vantage point, a lot of this work in technology and the partnerships that
[01:26:36.720 --> 01:26:43.480]   we're trying to see and skirting around the government in different ways, all of this
[01:26:43.480 --> 01:26:48.640]   plays very neatly into Xi Jinping's new world order, plans for a new world order in which
[01:26:48.640 --> 01:26:53.680]   China and China's special brand of communism has spread.
[01:26:53.680 --> 01:27:00.280]   All of these technologies and all of these devices and search, and the problem is that
[01:27:00.280 --> 01:27:01.720]   China is too lucrative.
[01:27:01.720 --> 01:27:11.080]   There's 780 million people who are wired and that population is growing and their social
[01:27:11.080 --> 01:27:15.120]   mobility is growing and their economics are growing.
[01:27:15.120 --> 01:27:18.040]   It's too big for companies to ignore.
[01:27:18.040 --> 01:27:30.200]   If you're a big tech titan, you want to capture part of that economy.
[01:27:30.200 --> 01:27:37.160]   I guess it's completely Pollyanna-ish of me to say, "Well, gosh, I wish American
[01:27:37.160 --> 01:27:41.600]   companies would stand up to authoritarian companies and say we just aren't going to
[01:27:41.600 --> 01:27:45.080]   do business there because we believe in freedom."
[01:27:45.080 --> 01:27:46.160]   Is that too much to ask?
[01:27:46.160 --> 01:27:47.160]   It's not too much.
[01:27:47.160 --> 01:27:50.320]   The problem is that it's not a black and white issue.
[01:27:50.320 --> 01:27:51.600]   There's a line somewhere.
[01:27:51.600 --> 01:27:52.600]   There is a line.
[01:27:52.600 --> 01:27:56.840]   If the Chinese government said to Apple, "Okay, in order for you to sell iPhones here,
[01:27:56.840 --> 01:28:00.200]   you have to execute prisoners for us in a stadium."
[01:28:00.200 --> 01:28:03.560]   That's all line we're not going to cross, obviously.
[01:28:03.560 --> 01:28:08.040]   There are other things like Apple's willing to eliminate certain apps from the app store
[01:28:08.040 --> 01:28:11.640]   that the Chinese government, that's on the other end of the spectrum, a little bit more
[01:28:11.640 --> 01:28:12.640]   innocent.
[01:28:12.640 --> 01:28:15.000]   Where is the line that's acceptable?
[01:28:15.000 --> 01:28:17.360]   There's a line there somewhere that's acceptable and unacceptable.
[01:28:17.360 --> 01:28:18.560]   Well, here's the problem.
[01:28:18.560 --> 01:28:23.000]   As soon as you say, "Well, we're going to do business in this country," then you are
[01:28:23.000 --> 01:28:28.360]   saying, "And whatever the laws are of that country, we're going to adhere to them.
[01:28:28.360 --> 01:28:30.080]   Otherwise, we can't do business."
[01:28:30.080 --> 01:28:36.320]   That's why we celebrated Google's decision some years ago to essentially leave China.
[01:28:36.320 --> 01:28:38.040]   But they didn't leave China.
[01:28:38.040 --> 01:28:44.960]   I mean, they said if censoring search as China requested, they moved search off of China
[01:28:44.960 --> 01:28:47.120]   off short of Hong Kong.
[01:28:47.120 --> 01:28:49.200]   There was no Google search in China.
[01:28:49.200 --> 01:28:56.560]   Yeah, admittedly they had other stuff going on in China.
[01:28:56.560 --> 01:29:00.080]   We also ought not to be so Pollyanna-ish about our own government.
[01:29:00.080 --> 01:29:09.440]   Listen, most people aren't plugged into what all the governments of the world are doing.
[01:29:09.440 --> 01:29:18.120]   We're heading into UN week, which is a lot that's happening right now.
[01:29:18.120 --> 01:29:23.520]   In order for the geopolitical balance to remain as it is right now, which has Americans feeling
[01:29:23.520 --> 01:29:29.000]   comfortable, we need certain kinds of technology.
[01:29:29.000 --> 01:29:32.400]   There have to be certain partnerships.
[01:29:32.400 --> 01:29:38.600]   The thing for me that's concerning about China specifically is that the surveillance is a
[01:29:38.600 --> 01:29:44.040]   piece of this, but the surveillance in effort for what?
[01:29:44.040 --> 01:29:45.040]   What is the surveillance for?
[01:29:45.040 --> 01:29:48.240]   The surveillance is not just to keep people in line.
[01:29:48.240 --> 01:29:58.680]   It's to help usher in this bigger idea of China's brand of communism in the year 2049.
[01:29:58.680 --> 01:30:00.080]   That's the 100-year anniversary.
[01:30:00.080 --> 01:30:04.920]   There's a lot of plans and strategic initiatives that are leading up to that.
[01:30:04.920 --> 01:30:08.160]   They're all kinds of allies that they're building all around the world.
[01:30:08.160 --> 01:30:16.120]   But data collection has a lot to do with seeing that new world order come to fruition.
[01:30:16.120 --> 01:30:21.120]   We may like this or not like it, but the big nine are all part of this.
[01:30:21.120 --> 01:30:27.960]   Just to be clear though, the word communism is a loaded term historically.
[01:30:27.960 --> 01:30:32.320]   It's really the Chinese Communist Party that enables this social control, but they're not
[01:30:32.320 --> 01:30:34.680]   actually that communist.
[01:30:34.680 --> 01:30:39.000]   They're also not exporting their brand of communism in the way that Soviet Union used
[01:30:39.000 --> 01:30:40.000]   to do.
[01:30:40.000 --> 01:30:41.920]   It's a different thing.
[01:30:41.920 --> 01:30:48.360]   They're dominating and exploiting economically, but they're not trying to get countries to
[01:30:48.360 --> 01:30:52.480]   have a Chinese style for the most part.
[01:30:52.480 --> 01:30:54.480]   I disagree.
[01:30:54.480 --> 01:30:55.480]   They have 68.
[01:30:55.480 --> 01:30:56.480]   Yeah, the largest family.
[01:30:56.480 --> 01:30:57.480]   I don't want to finish.
[01:30:57.480 --> 01:30:58.480]   Go ahead.
[01:30:58.480 --> 01:30:59.480]   Finish the army.
[01:30:59.480 --> 01:31:00.480]   Go ahead.
[01:31:00.480 --> 01:31:03.320]   They're 68 countries right now that are signed on to a pilot program.
[01:31:03.320 --> 01:31:05.960]   That's part of a...
[01:31:05.960 --> 01:31:08.880]   This is very much about a very, very long-term plan.
[01:31:08.880 --> 01:31:13.000]   This is something the United States has done for years.
[01:31:13.000 --> 01:31:16.880]   There was a book John Dvorak used to love to talk about the confessions of an economic
[01:31:16.880 --> 01:31:21.920]   hit man that talked about US companies and US government with the help of the US government
[01:31:21.920 --> 01:31:27.600]   going into nations and essentially destroying them, particularly in South America, by exporting
[01:31:27.600 --> 01:31:31.840]   American capitalism to these countries.
[01:31:31.840 --> 01:31:37.120]   That's exactly what China is doing, but there are reasons China is doing it beyond ideologies.
[01:31:37.120 --> 01:31:39.560]   It's not an ideological.
[01:31:39.560 --> 01:31:40.880]   I actually think part of it is.
[01:31:40.880 --> 01:31:43.680]   I think that they are.
[01:31:43.680 --> 01:31:45.280]   They very much see...
[01:31:45.280 --> 01:31:48.160]   This hasn't changed since I lived there.
[01:31:48.160 --> 01:31:56.840]   In Beijing, the CCP sees the United States and our democracy is counter to their interests.
[01:31:56.840 --> 01:32:00.720]   They see us as a viable economic partner, so we need each other.
[01:32:00.720 --> 01:32:06.000]   This is about China spreading its geopolitical... geopolitical influence.
[01:32:06.000 --> 01:32:13.360]   They are monkeying around in the oceans that separate the mainland and Japan.
[01:32:13.360 --> 01:32:14.360]   They're building islands.
[01:32:14.360 --> 01:32:15.360]   They're slowly carving out.
[01:32:15.360 --> 01:32:16.360]   The territory, etc.
[01:32:16.360 --> 01:32:20.600]   I mean, back to the technology, though, I think one of the interesting things about
[01:32:20.600 --> 01:32:25.720]   it is that in many cases, the tech companies who sell their souls to do business in China,
[01:32:25.720 --> 01:32:30.000]   because there are so many consumers, etc., are ultimately disappointed.
[01:32:30.000 --> 01:32:32.840]   There's a few American companies who have done very well.
[01:32:32.840 --> 01:32:35.160]   KFC, for example, is doing very well in China.
[01:32:35.160 --> 01:32:36.160]   I know.
[01:32:36.160 --> 01:32:38.400]   Boy, everywhere you go in Beijing, there's a Kentucky Fried Chicken.
[01:32:38.400 --> 01:32:40.000]   And Apple is doing very well.
[01:32:40.000 --> 01:32:43.400]   I don't think Google will do all that well in China.
[01:32:43.400 --> 01:32:45.440]   Because there's Baidu.
[01:32:45.440 --> 01:32:46.440]   Exactly.
[01:32:46.440 --> 01:32:51.400]   There are Chinese versions that no matter how much Google sacrifices for the Chinese government.
[01:32:51.400 --> 01:32:54.040]   But Google doesn't need to do super well in China.
[01:32:54.040 --> 01:32:56.720]   Google doesn't need to beat Baidu in order...
[01:32:56.720 --> 01:33:02.240]   A small gain in market share in China translates to a windfall of profit.
[01:33:02.240 --> 01:33:04.240]   So they don't need to dominate the government.
[01:33:04.240 --> 01:33:09.320]   Look, if this intercept story is true, and Google is building in this kind of tracking
[01:33:09.320 --> 01:33:14.320]   capability for the Chinese government into search, are they not, in effect, doing exactly
[01:33:14.320 --> 01:33:15.960]   where you said we should draw the line?
[01:33:15.960 --> 01:33:20.960]   Are they not helping the Chinese government, for instance, detect, follow, arrest, and
[01:33:20.960 --> 01:33:22.880]   eventually perhaps execute dissidents?
[01:33:22.880 --> 01:33:25.720]   And if that's the kit, well, yes, mostly...
[01:33:25.720 --> 01:33:26.720]   We saw that happen with Yahoo!
[01:33:26.720 --> 01:33:27.720]   But there are lots of...
[01:33:27.720 --> 01:33:28.720]   Cisco is doing that.
[01:33:28.720 --> 01:33:30.720]   Lots of companies are doing that in China.
[01:33:30.720 --> 01:33:31.720]   I know.
[01:33:31.720 --> 01:33:32.720]   Well, should we be doing that?
[01:33:32.720 --> 01:33:34.720]   Personally, I think not.
[01:33:34.720 --> 01:33:40.120]   And back to the point of whether it's worth it, I think the thing that Google should be
[01:33:40.120 --> 01:33:47.000]   more concerned about is losing business in the US, in Europe, and Japan, and other places
[01:33:47.000 --> 01:33:50.360]   that are going to be really horrified by them doing this kind of thing in China.
[01:33:50.360 --> 01:33:52.880]   Oh, I don't think it's going to move the needle at all.
[01:33:52.880 --> 01:33:55.280]   I don't think it could be Europe.
[01:33:55.280 --> 01:33:59.200]   We are maybe individual consumers will temporarily protest.
[01:33:59.200 --> 01:34:06.720]   I'm telling you, we are too tethered at the moment to Amazon, Apple, and Google for big
[01:34:06.720 --> 01:34:10.240]   companies...
[01:34:10.240 --> 01:34:11.520]   We're too tethered to them.
[01:34:11.520 --> 01:34:15.240]   They control too much of the ecosystem that we all plug into.
[01:34:15.240 --> 01:34:20.160]   So it would be very, very difficult for a big company on principle to decide that they
[01:34:20.160 --> 01:34:25.640]   no longer want to work with Google as a result of Google's building something maybe or maybe
[01:34:25.640 --> 01:34:27.080]   not for China.
[01:34:27.080 --> 01:34:31.600]   And quite frankly, I don't think people care that much here in the United States.
[01:34:31.600 --> 01:34:33.320]   It's not a knock on Americans.
[01:34:33.320 --> 01:34:36.920]   I just think we are focused on other things right now.
[01:34:36.920 --> 01:34:43.720]   Speaking of other things, didn't you promise that she was going to reveal some crazy...
[01:34:43.720 --> 01:34:44.720]   Let's see.
[01:34:44.720 --> 01:34:46.640]   Amy Webb has something I'm very jealous for.
[01:34:46.640 --> 01:34:48.040]   She's going to take out for glasses.
[01:34:48.040 --> 01:34:54.280]   She's your husband, the ophthalmologist, approve of what you're about to do.
[01:34:54.280 --> 01:35:02.280]   So yes, let me preface this by saying, I have for a very long time been talking about this
[01:35:02.280 --> 01:35:05.960]   is the beginning of the end of smartphones this year and we're transitioning into what
[01:35:05.960 --> 01:35:07.320]   comes next.
[01:35:07.320 --> 01:35:09.560]   I believe what's next are smart glasses.
[01:35:09.560 --> 01:35:10.920]   I totally agree.
[01:35:10.920 --> 01:35:11.920]   And everybody who says...
[01:35:11.920 --> 01:35:14.360]   This guy was a glass hole before anybody else.
[01:35:14.360 --> 01:35:16.480]   I was the biggest glass hole.
[01:35:16.480 --> 01:35:18.480]   So for everybody...
[01:35:18.480 --> 01:35:23.280]   You know, so anyhow, for people who say I would never wear glasses, all of the data,
[01:35:23.280 --> 01:35:26.800]   there's all these studies out showing how quickly we are all becoming nearsighted because
[01:35:26.800 --> 01:35:29.000]   of the screens.
[01:35:29.000 --> 01:35:30.720]   And so with that being said...
[01:35:30.720 --> 01:35:32.800]   That's by the way, my apple is introduced.
[01:35:32.800 --> 01:35:34.280]   The iPhone XS Max.
[01:35:34.280 --> 01:35:35.280]   I'm going to put on...
[01:35:35.280 --> 01:35:38.240]   Yeah, that's part of the reason why.
[01:35:38.240 --> 01:35:45.000]   So this headset, I've experimented with lots of different wearable devices and I had glass.
[01:35:45.000 --> 01:35:48.240]   I've had lots of different smart glasses.
[01:35:48.240 --> 01:35:50.800]   I've tried Helolens.
[01:35:50.800 --> 01:35:56.280]   The only other experience that I can compare to the first time that I put on Magic Leap,
[01:35:56.280 --> 01:36:01.080]   which is what I'm about to do, was when I was living in Japan and I was in Akihabara
[01:36:01.080 --> 01:36:04.920]   and I saw a prototype phone that was connected to the internet.
[01:36:04.920 --> 01:36:09.320]   And I mean, seeing it was not that exciting, but from the interface...
[01:36:09.320 --> 01:36:11.120]   You saw what it meant.
[01:36:11.120 --> 01:36:12.120]   Yeah.
[01:36:12.120 --> 01:36:13.400]   I mean, it changed everything.
[01:36:13.400 --> 01:36:15.200]   And so when I put these on...
[01:36:15.200 --> 01:36:16.200]   This is remarkable.
[01:36:16.200 --> 01:36:17.200]   This is remarkable.
[01:36:17.200 --> 01:36:18.200]   Yeah.
[01:36:18.200 --> 01:36:19.200]   Now Magic Leap, I was really...
[01:36:19.200 --> 01:36:25.400]   I maybe still am a little torn between classifying Magic Leap as the next big thing or as Theranos.
[01:36:25.400 --> 01:36:28.280]   I think that they have really...
[01:36:28.280 --> 01:36:29.520]   But now they've got a product.
[01:36:29.520 --> 01:36:30.520]   No, listen.
[01:36:30.520 --> 01:36:34.080]   So this goes back to what I was saying earlier.
[01:36:34.080 --> 01:36:37.200]   This technology is so sophisticated.
[01:36:37.200 --> 01:36:38.200]   It is...
[01:36:38.200 --> 01:36:42.400]   So for those who don't know, these are augmented reality glasses mixed real...
[01:36:42.400 --> 01:36:43.400]   They're not.
[01:36:43.400 --> 01:36:44.400]   They're mixed.
[01:36:44.400 --> 01:36:45.400]   No.
[01:36:45.400 --> 01:36:46.760]   So this is the other thing.
[01:36:46.760 --> 01:36:53.120]   The founders, I think, have done some stupid things like promising to speak at a TED event
[01:36:53.120 --> 01:36:56.160]   and they probably just didn't have something ready to show or talk about.
[01:36:56.160 --> 01:36:59.480]   So instead they showed up in spacesuits and dance around for like seven minutes to freaky
[01:36:59.480 --> 01:37:00.480]   sounding music.
[01:37:00.480 --> 01:37:06.240]   Well, and their website makes a promise that it might be a little hard to deliver on.
[01:37:06.240 --> 01:37:08.240]   I disagree.
[01:37:08.240 --> 01:37:10.200]   The experience that I have now...
[01:37:10.200 --> 01:37:17.640]   I mean, at the moment, they don't do a ton, but what they can do has completely blown
[01:37:17.640 --> 01:37:18.640]   me away.
[01:37:18.640 --> 01:37:20.640]   And this is why I'm asking you, because I trust you.
[01:37:20.640 --> 01:37:21.640]   Yes, what does it do?
[01:37:21.640 --> 01:37:23.040]   You've used HoloLens, right?
[01:37:23.040 --> 01:37:24.040]   This is...
[01:37:24.040 --> 01:37:25.040]   Yes.
[01:37:25.040 --> 01:37:26.040]   Okay.
[01:37:26.040 --> 01:37:27.040]   The difference is...
[01:37:27.040 --> 01:37:29.200]   That's Microsoft's version of this.
[01:37:29.200 --> 01:37:30.200]   Right.
[01:37:30.200 --> 01:37:31.200]   This turns the...
[01:37:31.200 --> 01:37:36.840]   Any space that you're in in seconds into a spatial computing environment.
[01:37:36.840 --> 01:37:38.920]   So you do have to put the glasses on.
[01:37:38.920 --> 01:37:41.040]   They are not going to look like this forever.
[01:37:41.040 --> 01:37:44.120]   You are not going to have to carry a heavy pack around forever.
[01:37:44.120 --> 01:37:47.560]   So that works completely untethered.
[01:37:47.560 --> 01:37:48.560]   You can use these without being...
[01:37:48.560 --> 01:37:49.560]   Correct.
[01:37:49.560 --> 01:37:50.560]   Well, I mean, you're tethered here, but the...
[01:37:50.560 --> 01:37:51.560]   To a clock.
[01:37:51.560 --> 01:37:52.560]   But the food is happening in the cloud.
[01:37:52.560 --> 01:37:53.560]   Yeah.
[01:37:53.560 --> 01:37:54.560]   Or some of it.
[01:37:54.560 --> 01:37:55.560]   So...
[01:37:55.560 --> 01:37:59.640]   But, you know, I map, for example, the room that I'm in and the entire room then has
[01:37:59.640 --> 01:38:03.240]   turned into a spatial computing environment where for the moment...
[01:38:03.240 --> 01:38:05.800]   So I can see everybody just fine.
[01:38:05.800 --> 01:38:12.280]   I can connect to people in other cities and I can see them in the space where I'm in.
[01:38:12.280 --> 01:38:14.920]   Now, why do you say this is not augmented reality?
[01:38:14.920 --> 01:38:15.920]   What's the difference in that?
[01:38:15.920 --> 01:38:16.920]   Because from my...
[01:38:16.920 --> 01:38:23.720]   Because AR is more of a two-dimensional, it's overlaying somebody else's images onto
[01:38:23.720 --> 01:38:26.800]   an existing space.
[01:38:26.800 --> 01:38:29.360]   This is interactive.
[01:38:29.360 --> 01:38:30.360]   So if I...
[01:38:30.360 --> 01:38:34.360]   Because it responds to gesture, it responds to other elements.
[01:38:34.360 --> 01:38:37.040]   So if I...
[01:38:37.040 --> 01:38:42.560]   You can have little creatures and fish like I turn my office into an aquarium for fun.
[01:38:42.560 --> 01:38:45.560]   And you can sort of push the fish out of the way and you're moving around and you can
[01:38:45.560 --> 01:38:46.560]   bring other people in.
[01:38:46.560 --> 01:38:47.560]   You can touch them.
[01:38:47.560 --> 01:38:49.360]   I mean, you don't feel it when your fingers...
[01:38:49.360 --> 01:38:50.360]   No, but it does.
[01:38:50.360 --> 01:38:53.320]   But when you move your hand in that space, it interacts with the thing.
[01:38:53.320 --> 01:38:54.320]   Correct.
[01:38:54.320 --> 01:38:55.320]   And there's no lag.
[01:38:55.320 --> 01:38:57.320]   So there's a cognitive...
[01:38:57.320 --> 01:39:01.920]   So it's doing hand tracking.
[01:39:01.920 --> 01:39:02.920]   It's...
[01:39:02.920 --> 01:39:03.920]   It must be.
[01:39:03.920 --> 01:39:04.920]   It is, yeah.
[01:39:04.920 --> 01:39:05.920]   It is.
[01:39:05.920 --> 01:39:06.920]   It is.
[01:39:06.920 --> 01:39:07.920]   Wow.
[01:39:07.920 --> 01:39:10.200]   So, but what's happening is, you know, your brain gets tricked.
[01:39:10.200 --> 01:39:15.960]   I put these on my husband who we put a hole in the ground, a virtual hole.
[01:39:15.960 --> 01:39:20.800]   And he, you know, he knew that it was not real, but it looks real.
[01:39:20.800 --> 01:39:21.800]   Yeah.
[01:39:21.800 --> 01:39:23.480]   And he had a hard time walking toward it.
[01:39:23.480 --> 01:39:24.480]   Yeah.
[01:39:24.480 --> 01:39:25.480]   I've had that experience with virtual reality as well.
[01:39:25.480 --> 01:39:26.480]   I mean, that's not...
[01:39:26.480 --> 01:39:28.560]   So anyhow, here's what I would say.
[01:39:28.560 --> 01:39:35.480]   It is abundantly clear to me that, you know, this is quickly progressing.
[01:39:35.480 --> 01:39:40.480]   This headset, which is big and clunky right now, is the form factor is going to look more
[01:39:40.480 --> 01:39:43.160]   like glasses at some point.
[01:39:43.160 --> 01:39:46.960]   Well, this is actually a light years ahead of the Google Glass experience.
[01:39:46.960 --> 01:39:47.960]   Look at the...
[01:39:47.960 --> 01:39:50.560]   And even if you look at the history of the development of this, the original one was
[01:39:50.560 --> 01:39:52.640]   the size of a car, basically.
[01:39:52.640 --> 01:39:54.600]   But are they doing that...
[01:39:54.600 --> 01:39:57.880]   Whatever that was that they wanted to do initially, that ray tracing thing, that this
[01:39:57.880 --> 01:39:58.880]   is...
[01:39:58.880 --> 01:40:00.680]   Or is this more like just two screens?
[01:40:00.680 --> 01:40:01.680]   I mean...
[01:40:01.680 --> 01:40:02.680]   No, no, no.
[01:40:02.680 --> 01:40:03.680]   Well, it's...
[01:40:03.680 --> 01:40:05.480]   They were actually talking about retinal projection at some point.
[01:40:05.480 --> 01:40:06.480]   That's what I meant.
[01:40:06.480 --> 01:40:07.480]   Yeah.
[01:40:07.480 --> 01:40:08.480]   So this is right.
[01:40:08.480 --> 01:40:09.480]   So, but here's what I would say.
[01:40:09.480 --> 01:40:10.480]   Nobody...
[01:40:10.480 --> 01:40:12.200]   We have to give these guys time.
[01:40:12.200 --> 01:40:14.680]   And I have no horse in this race at all.
[01:40:14.680 --> 01:40:15.680]   I'm not an investor.
[01:40:15.680 --> 01:40:17.240]   I don't know them personally.
[01:40:17.240 --> 01:40:22.720]   I'm just telling you that what I have currently seen absolutely blew me away.
[01:40:22.720 --> 01:40:26.160]   And I very rarely get blown away by new technology.
[01:40:26.160 --> 01:40:30.840]   And my concern is that if they don't suddenly have a bunch of apps and products and market
[01:40:30.840 --> 01:40:35.240]   and they don't have a consumer product right away, everybody's going to call them a failure.
[01:40:35.240 --> 01:40:39.280]   This technology is still a decade...
[01:40:39.280 --> 01:40:42.480]   For it to really hit the mainstream and do things that are more than just playing games
[01:40:42.480 --> 01:40:43.480]   like what you're seeing right now.
[01:40:43.480 --> 01:40:44.480]   Yeah.
[01:40:44.480 --> 01:40:45.480]   I hate these demos.
[01:40:45.480 --> 01:40:49.480]   Do you think like import your grandmother into your living room and have a conversation with
[01:40:49.480 --> 01:40:52.080]   her or see real-time data?
[01:40:52.080 --> 01:40:54.480]   Like, here's a great implementation.
[01:40:54.480 --> 01:41:00.840]   Like during the next debate or congressional hearing, I've got my glasses on.
[01:41:00.840 --> 01:41:05.160]   And every single time somebody speaks, I can see what packs they've donated to.
[01:41:05.160 --> 01:41:07.120]   I can see who they have financial ties to.
[01:41:07.120 --> 01:41:11.200]   I mean, all of that stuff is on our near horizon, but we've got to give these guys
[01:41:11.200 --> 01:41:13.440]   times some time to work.
[01:41:13.440 --> 01:41:16.360]   And that's actually an augmented reality feature.
[01:41:16.360 --> 01:41:18.200]   But overall, it's not...
[01:41:18.200 --> 01:41:19.200]   But you've been to it.
[01:41:19.200 --> 01:41:20.560]   It's augmented reality is one of the things you can do.
[01:41:20.560 --> 01:41:21.560]   But one of the things...
[01:41:21.560 --> 01:41:22.560]   For skeptics out there...
[01:41:22.560 --> 01:41:23.560]   I'm a skeptic.
[01:41:23.560 --> 01:41:24.560]   Okay.
[01:41:24.560 --> 01:41:25.560]   For skeptics.
[01:41:25.560 --> 01:41:26.560]   So you like regular...
[01:41:26.560 --> 01:41:27.560]   Look at this screen here.
[01:41:27.560 --> 01:41:28.560]   You have this big screen.
[01:41:28.560 --> 01:41:29.560]   It's beautiful.
[01:41:29.560 --> 01:41:30.560]   It's physical.
[01:41:30.560 --> 01:41:31.560]   It's there.
[01:41:31.560 --> 01:41:32.560]   Okay.
[01:41:32.560 --> 01:41:36.640]   The most banal usage for Magic Leap is one that we can all relate to.
[01:41:36.640 --> 01:41:41.840]   Imagine a world where screens of any size were free.
[01:41:41.840 --> 01:41:43.120]   How many would you have?
[01:41:43.120 --> 01:41:44.120]   Where would you put them?
[01:41:44.120 --> 01:41:45.120]   Well, look at my office.
[01:41:45.120 --> 01:41:46.120]   I have about 20.
[01:41:46.120 --> 01:41:47.120]   Right.
[01:41:47.120 --> 01:41:48.120]   But they weren't free.
[01:41:48.120 --> 01:41:49.120]   They were expensive.
[01:41:49.120 --> 01:41:51.280]   And right now, I actually put six screens.
[01:41:51.280 --> 01:41:53.760]   So I have a vertical one on one side.
[01:41:53.760 --> 01:41:54.760]   Yeah.
[01:41:54.760 --> 01:41:55.760]   And a horizontal monitor.
[01:41:55.760 --> 01:41:56.760]   There's a huge difference.
[01:41:56.760 --> 01:41:57.760]   There's a difference.
[01:41:57.760 --> 01:41:58.760]   There's a difference.
[01:41:58.760 --> 01:42:05.360]   Those screens are outside your sensarium and you move around independently of them.
[01:42:05.360 --> 01:42:06.840]   You put them on your face.
[01:42:06.840 --> 01:42:13.520]   To me, this is an under-virtual reality experience where people got excited about virtual reality
[01:42:13.520 --> 01:42:15.040]   until they did it for any length of time.
[01:42:15.040 --> 01:42:18.440]   The difference is if you put it on the wall and then you leave the room, it stays in the
[01:42:18.440 --> 01:42:20.560]   room behind you just like a physical screen.
[01:42:20.560 --> 01:42:21.920]   It's there when you come back in the room.
[01:42:21.920 --> 01:42:23.920]   It just gives me a headache.
[01:42:23.920 --> 01:42:30.920]   VR should give you a headache because the technology has not progressed enough so that
[01:42:30.920 --> 01:42:32.720]   we've solved for lag.
[01:42:32.720 --> 01:42:36.800]   VR has very, very, very limited use cases.
[01:42:36.800 --> 01:42:44.400]   So VR works for games and it works for certain types of storytelling, like a movie.
[01:42:44.400 --> 01:42:47.000]   It does not work for most other things.
[01:42:47.000 --> 01:42:51.560]   It's got a therapeutic use, but it came to market first.
[01:42:51.560 --> 01:42:56.720]   And so the problem is that we've conflated and we've had, the first AR apps came out
[01:42:56.720 --> 01:42:58.800]   immediately after the first iPhone launched.
[01:42:58.800 --> 01:43:03.040]   So there was something called Retour which was an early days AR app to help you get around
[01:43:03.040 --> 01:43:04.960]   the city of Paris.
[01:43:04.960 --> 01:43:09.440]   So and then Google Glass came out and it should never have been marketed as a consumer device
[01:43:09.440 --> 01:43:12.760]   and they had all kinds of PR problems.
[01:43:12.760 --> 01:43:16.480]   The underlying technology was interesting.
[01:43:16.480 --> 01:43:17.480]   But they're different things.
[01:43:17.480 --> 01:43:18.480]   They're different things.
[01:43:18.480 --> 01:43:23.000]   One of the things that this technology will do is it'll bring us back to a world of superstition
[01:43:23.000 --> 01:43:28.760]   and ghosts and things like that because there's already a company in Japan where you can
[01:43:28.760 --> 01:43:33.440]   have a virtual version of the people at the grave site or potentially at the place where
[01:43:33.440 --> 01:43:36.880]   they were killed in a highway or something where you put on the goggles, you see them
[01:43:36.880 --> 01:43:41.840]   standing there waving, the different psychologically between that and a ghost is zero.
[01:43:41.840 --> 01:43:43.760]   That's essentially what a ghost is.
[01:43:43.760 --> 01:43:45.560]   In Japan, there's a different company.
[01:43:45.560 --> 01:43:48.400]   I haven't heard of what you're talking about, but there is another company that has built
[01:43:48.400 --> 01:43:50.800]   an interactive horror experience.
[01:43:50.800 --> 01:43:57.880]   So if you're really into like haunted houses and scary movies, it turns wherever you are
[01:43:57.880 --> 01:44:01.440]   into a spatial computing environment with, and there's sensory and haptic.
[01:44:01.440 --> 01:44:09.880]   I feel like the Sony CSL is a piece of this, but it puts the horror all around you.
[01:44:09.880 --> 01:44:11.600]   So there are some entertainment purposes.
[01:44:11.600 --> 01:44:21.920]   I'm telling you, I can see these being a productivity element if you're a manager in an office and
[01:44:21.920 --> 01:44:26.840]   being able to sort of create a visual map very clearly of whatever it is that you're
[01:44:26.840 --> 01:44:27.760]   trying to track.
[01:44:27.760 --> 01:44:32.640]   I mean, I cannot say enough.
[01:44:32.640 --> 01:44:36.000]   This headset is hard to wear.
[01:44:36.000 --> 01:44:38.080]   It kind of sort of comes in and out.
[01:44:38.080 --> 01:44:43.400]   I've got pretty bad vision, so sometimes it autocorrects me, sometimes it doesn't.
[01:44:43.400 --> 01:44:47.480]   And at the moment, there's not a ton that you can do, but what I can do, I can clearly
[01:44:47.480 --> 01:44:48.760]   see the future.
[01:44:48.760 --> 01:44:52.880]   And if everybody would just give these guys a break and let them work, stop at the future.
[01:44:52.880 --> 01:44:53.880]   Well, let's talk about the future.
[01:44:53.880 --> 01:44:54.880]   Stop expecting a product.
[01:44:54.880 --> 01:44:56.600]   Five years from now, this technology will be mainstream.
[01:44:56.600 --> 01:44:59.120]   There'll be two or three basic kinds.
[01:44:59.120 --> 01:45:04.560]   There'll be the Magic Leap HoloLens types, which will be for work or for high-end entertainment
[01:45:04.560 --> 01:45:08.560]   or for serious uses, kind of like how we use high-end PCs now.
[01:45:08.560 --> 01:45:11.680]   We can use them for high-end gaming, high-end business, whatever.
[01:45:11.680 --> 01:45:15.280]   It will be the glasses that will look just like the glasses that Amy is wearing right
[01:45:15.280 --> 01:45:20.720]   now, which won't be detectable as AR glasses, but the AR will walk around.
[01:45:20.720 --> 01:45:21.720]   We'll see little screens.
[01:45:21.720 --> 01:45:22.720]   There'll be 2D.
[01:45:22.720 --> 01:45:25.520]   We won't have mapping to the walls right away.
[01:45:25.520 --> 01:45:28.240]   And then the third type, which is already available, which is I think kind of cool as
[01:45:28.240 --> 01:45:33.000]   bone conduction audio where you talk to the A word or you talk to Siri, whatever.
[01:45:33.000 --> 01:45:34.560]   But you do that all day.
[01:45:34.560 --> 01:45:38.680]   The benefit of that is 2, 3, 4-day battery life and also you don't have things in your
[01:45:38.680 --> 01:45:40.440]   ears all the time.
[01:45:40.440 --> 01:45:42.440]   But this is happening imminently.
[01:45:42.440 --> 01:45:46.440]   I think this kind of thing is going to be super mainstream.
[01:45:46.440 --> 01:45:47.720]   I think that's a little aggressive.
[01:45:47.720 --> 01:45:54.200]   The glasses are definitely a decade out just for a variety of reasons.
[01:45:54.200 --> 01:45:56.880]   You can actually see that they play a big role in the first.
[01:45:56.880 --> 01:46:01.600]   So if you watch that show, you'll see everybody wearing the glasses that we're talking about.
[01:46:01.600 --> 01:46:06.760]   And some kind of earbud or bone conducting device so that they can talk.
[01:46:06.760 --> 01:46:07.760]   I can see.
[01:46:07.760 --> 01:46:08.840]   Rio, you should try them.
[01:46:08.840 --> 01:46:09.840]   You should try.
[01:46:09.840 --> 01:46:10.840]   Have you?
[01:46:10.840 --> 01:46:11.840]   I almost bought them.
[01:46:11.840 --> 01:46:12.840]   But then I thought, oh, Amy, you'll buy them.
[01:46:12.840 --> 01:46:14.280]   Well, you're not going to use them.
[01:46:14.280 --> 01:46:15.840]   There's no reason to buy them right now.
[01:46:15.840 --> 01:46:19.440]   There's more than 2,500 bucks, right?
[01:46:19.440 --> 01:46:20.440]   They're expensive.
[01:46:20.440 --> 01:46:23.480]   And unless you're building stuff and trying to...
[01:46:23.480 --> 01:46:24.480]   You need them.
[01:46:24.480 --> 01:46:25.480]   You need them.
[01:46:25.480 --> 01:46:28.200]   But nobody else should buy them at the moment because you can't do very much.
[01:46:28.200 --> 01:46:30.080]   But you should at least put a set on.
[01:46:30.080 --> 01:46:32.640]   I'm willing to stipulate that somebody...
[01:46:32.640 --> 01:46:34.920]   I can't remember who.
[01:46:34.920 --> 01:46:36.240]   Maybe any of that goes.
[01:46:36.240 --> 01:46:41.840]   Look, remember when you first got the Atari Video Console system and how primitive those
[01:46:41.840 --> 01:46:42.840]   games are.
[01:46:42.840 --> 01:46:43.840]   We're at that stage.
[01:46:43.840 --> 01:46:44.840]   And I'm willing to stipulate that.
[01:46:44.840 --> 01:46:47.680]   We're at a very, very early stage.
[01:46:47.680 --> 01:46:52.240]   And what you see today is primitive.
[01:46:52.240 --> 01:46:55.720]   I think though there's a more fun...
[01:46:55.720 --> 01:46:59.040]   And I have in the past said, oh, it'd be really great to have reputation scores over people's
[01:46:59.040 --> 01:47:01.960]   heads or...
[01:47:01.960 --> 01:47:05.560]   I'm not convinced.
[01:47:05.560 --> 01:47:08.680]   I mean, you could have said, well, before the echo came out, well, you're never going
[01:47:08.680 --> 01:47:09.680]   to talk.
[01:47:09.680 --> 01:47:10.880]   Would you ever talk to your house?
[01:47:10.880 --> 01:47:12.480]   No, that's silly.
[01:47:12.480 --> 01:47:14.240]   But I've found some use cases for that.
[01:47:14.240 --> 01:47:16.000]   Eventually you get hooked on it and you have to have it.
[01:47:16.000 --> 01:47:18.240]   And I guess that that's the case with this.
[01:47:18.240 --> 01:47:22.680]   But it's hard for me to imagine a scenario where this would be a must have technology,
[01:47:22.680 --> 01:47:23.680]   I guess.
[01:47:23.680 --> 01:47:27.200]   But it's easier to imagine that it'd be addictive.
[01:47:27.200 --> 01:47:28.360]   Yeah, I could see it being addictive.
[01:47:28.360 --> 01:47:32.760]   But I mean, being able to talk to my grandma, I mean, I can do that with face time.
[01:47:32.760 --> 01:47:33.760]   There's a couple of accelerants.
[01:47:33.760 --> 01:47:36.080]   There's a couple of accelerants that are...
[01:47:36.080 --> 01:47:41.360]   First of all, over the next couple of decades, everybody in an industrialized nation is going
[01:47:41.360 --> 01:47:46.320]   to need glasses much sooner and at a greater scale than we've ever needed before.
[01:47:46.320 --> 01:47:48.320]   And your husband is happy.
[01:47:48.320 --> 01:47:49.320]   Of course he's happy.
[01:47:49.320 --> 01:47:50.320]   Of course he's happy.
[01:47:50.320 --> 01:47:51.320]   Of course he's happy.
[01:47:51.320 --> 01:47:59.400]   But so that's an accelerant that will cause the adoption rate to spike because we've already
[01:47:59.400 --> 01:48:00.400]   got something out of it.
[01:48:00.400 --> 01:48:01.600]   Well, I already wear spectacles all the time.
[01:48:01.600 --> 01:48:03.480]   So that's not a big deal for me.
[01:48:03.480 --> 01:48:04.480]   Right.
[01:48:04.480 --> 01:48:05.480]   That's not an issue.
[01:48:05.480 --> 01:48:06.480]   That wasn't a disadvantage.
[01:48:06.480 --> 01:48:07.480]   You wear spectacles.
[01:48:07.480 --> 01:48:11.000]   But so I'm willing to say, yeah, people get used to that.
[01:48:11.000 --> 01:48:12.000]   Right.
[01:48:12.000 --> 01:48:17.120]   So now if you go back to, let's say, 10 years ago, I know a ton of people who would have
[01:48:17.120 --> 01:48:19.960]   said, I don't want to see somebody when I talk to the phone.
[01:48:19.960 --> 01:48:22.800]   When I talk to them on the phone, I don't want to see them.
[01:48:22.800 --> 01:48:24.680]   It's just voice is fine.
[01:48:24.680 --> 01:48:28.880]   I feel weird seeing video.
[01:48:28.880 --> 01:48:30.680]   And our adoption rate changed.
[01:48:30.680 --> 01:48:32.720]   It took a while for that.
[01:48:32.720 --> 01:48:33.720]   But yeah.
[01:48:33.720 --> 01:48:34.920]   It took a little while.
[01:48:34.920 --> 01:48:35.920]   But there is...
[01:48:35.920 --> 01:48:40.840]   I think that one of the things that's fundamental to human nature regardless of where in the
[01:48:40.840 --> 01:48:46.360]   world we live or what nationality we are, culture, gender, anything else is a need for
[01:48:46.360 --> 01:48:47.440]   intimacy.
[01:48:47.440 --> 01:48:53.960]   And part of why we adopt certain technologies faster has to do with fulfilling that need
[01:48:53.960 --> 01:48:57.240]   for intimacy that we have and that feeling of closeness.
[01:48:57.240 --> 01:49:00.360]   So just as an example, when VR...
[01:49:00.360 --> 01:49:04.800]   We've been hearing about social isolationism for a very long time and how all this new
[01:49:04.800 --> 01:49:09.760]   technology VR, AI is going to spread us all apart.
[01:49:09.760 --> 01:49:13.160]   We're actually seeing the opposite happening in lots of different places.
[01:49:13.160 --> 01:49:15.960]   So video game arcades are back.
[01:49:15.960 --> 01:49:20.840]   They are popping up all over the place because they're mixed reality and VR arcades where
[01:49:20.840 --> 01:49:25.040]   you can go in and wire into stuff that you couldn't afford on your own.
[01:49:25.040 --> 01:49:26.360]   We're seeing silent discos.
[01:49:26.360 --> 01:49:28.320]   Have you gotten to be guys?
[01:49:28.320 --> 01:49:29.320]   Yeah.
[01:49:29.320 --> 01:49:31.120]   They're hilarious.
[01:49:31.120 --> 01:49:37.000]   So you have headphones on and there's four different DJs all playing at the same time.
[01:49:37.000 --> 01:49:41.000]   And you can be with other people in the same place having an experience that's good for
[01:49:41.000 --> 01:49:43.320]   you but you still have that level of intimacy.
[01:49:43.320 --> 01:49:44.320]   So funny because...
[01:49:44.320 --> 01:49:45.320]   Two headsets.
[01:49:45.320 --> 01:49:48.800]   Everything you just described to me is a faux intimacy.
[01:49:48.800 --> 01:49:52.240]   And I think some of the backlash against social media is we thought that that was going to
[01:49:52.240 --> 01:49:54.760]   be intimacy and that was going to satisfy that.
[01:49:54.760 --> 01:50:01.160]   And it's a faux intimacy that is actually fake sugar poisoning our systems.
[01:50:01.160 --> 01:50:02.640]   Or is it fake or is it different?
[01:50:02.640 --> 01:50:03.640]   It's not different sugars.
[01:50:03.640 --> 01:50:05.040]   Well, that's a good question, Amy.
[01:50:05.040 --> 01:50:08.120]   Maybe my kids will consider it real intimacy.
[01:50:08.120 --> 01:50:09.120]   But...
[01:50:09.120 --> 01:50:13.240]   Well, no, because like just for the going back to the club thing for a minute, like I don't
[01:50:13.240 --> 01:50:14.240]   like...
[01:50:14.240 --> 01:50:16.120]   I used to go out when I lived in...
[01:50:16.120 --> 01:50:18.080]   I used to when I was younger in my youth.
[01:50:18.080 --> 01:50:20.960]   I used to go out to clubs and go dancing.
[01:50:20.960 --> 01:50:25.000]   I usually hated the music that was being played and I sort of forced myself because I wanted
[01:50:25.000 --> 01:50:26.000]   to hang out with my friends.
[01:50:26.000 --> 01:50:30.680]   But are you hanging out with your friends when you got headphones on?
[01:50:30.680 --> 01:50:32.680]   Everybody's got headphones on and the cool thing isn't a lot of...
[01:50:32.680 --> 01:50:34.520]   We're not talking or interacting with your friends.
[01:50:34.520 --> 01:50:39.080]   Well, if you're dancing with people, you can't hear them anyways.
[01:50:39.080 --> 01:50:45.120]   But you can see they're color banded, so depending on which DJ you're tuned to, you can find
[01:50:45.120 --> 01:50:46.680]   your tribe.
[01:50:46.680 --> 01:50:50.360]   I think it's intimacy expressed in a different way.
[01:50:50.360 --> 01:50:51.600]   I think there's plenty of...
[01:50:51.600 --> 01:50:56.600]   To your excellent point, there are like plenty of ways this goes bad and it's faux intimacy.
[01:50:56.600 --> 01:50:59.160]   But I think some of this has just changed.
[01:50:59.160 --> 01:51:01.600]   No, I understand that.
[01:51:01.600 --> 01:51:02.600]   And what we consider...
[01:51:02.600 --> 01:51:06.720]   An old people like me considering MSC is different than you young people.
[01:51:06.720 --> 01:51:13.320]   But I think when you talk about biological needs, those things are hardwired.
[01:51:13.320 --> 01:51:14.640]   Those aren't going to change.
[01:51:14.640 --> 01:51:17.040]   And that real intimacy is hardwired.
[01:51:17.040 --> 01:51:21.160]   I don't think you can say technology is going to create a new form of intimacy.
[01:51:21.160 --> 01:51:22.960]   It's either intimacy or it's not.
[01:51:22.960 --> 01:51:23.960]   Yeah.
[01:51:23.960 --> 01:51:25.920]   So we don't know.
[01:51:25.920 --> 01:51:30.240]   And I acknowledge it could be different.
[01:51:30.240 --> 01:51:31.840]   This is a subtle driver.
[01:51:31.840 --> 01:51:36.640]   I mean, if you look at just podcasting, why is podcasting better than television or radio?
[01:51:36.640 --> 01:51:38.600]   No offense because I know you also do radio.
[01:51:38.600 --> 01:51:39.760]   But it is radio.
[01:51:39.760 --> 01:51:40.760]   That's the funniest.
[01:51:40.760 --> 01:51:41.760]   Yeah.
[01:51:41.760 --> 01:51:42.760]   This is radio.
[01:51:42.760 --> 01:51:43.760]   But in general podcasting...
[01:51:43.760 --> 01:51:45.480]   This is actually a medium that started in the 20s.
[01:51:45.480 --> 01:51:47.480]   But in general podcasting, it's different.
[01:51:47.480 --> 01:51:48.480]   But the difference is that it's time shifting.
[01:51:48.480 --> 01:51:49.480]   It's different.
[01:51:49.480 --> 01:51:50.480]   It's more intimate than right from...
[01:51:50.480 --> 01:51:51.480]   You can time shift it.
[01:51:51.480 --> 01:51:56.520]   Well, but that's important because that is for me, that is a way to make this experience.
[01:51:56.520 --> 01:51:58.240]   I'm having...
[01:51:58.240 --> 01:51:59.880]   It's a way to personalize that experience.
[01:51:59.880 --> 01:52:04.840]   I think we have a world that's being invented by introverts, for introverts.
[01:52:04.840 --> 01:52:06.760]   As an introvert, I think that's fantastic.
[01:52:06.760 --> 01:52:09.800]   I think the three of us are introverts and are all going, "This is great."
[01:52:09.800 --> 01:52:13.280]   This works out very well for us.
[01:52:13.280 --> 01:52:17.080]   But maybe not necessarily biologically a trend.
[01:52:17.080 --> 01:52:21.280]   I may have a different viewpoint on this because I lived by myself overseas for many, many,
[01:52:21.280 --> 01:52:22.280]   many years.
[01:52:22.280 --> 01:52:23.280]   And if I...
[01:52:23.280 --> 01:52:24.280]   You missed your grandma.
[01:52:24.280 --> 01:52:26.240]   If I were to do that, pardon me?
[01:52:26.240 --> 01:52:27.240]   You missed your grandma.
[01:52:27.240 --> 01:52:28.240]   It'd been great to have a home.
[01:52:28.240 --> 01:52:32.120]   I missed a lot of things.
[01:52:32.120 --> 01:52:36.200]   If I had the opportunity to be in my house and have on a pair of something like a magic
[01:52:36.200 --> 01:52:43.400]   leap and have a conversation with two or three of my friends and be able to see them moving
[01:52:43.400 --> 01:52:51.440]   around versus just squares on a two-dimensional screen, I think for me that gives me a better...
[01:52:51.440 --> 01:52:58.440]   Like when I've played a multiplayer game with leap, you do have this...
[01:52:58.440 --> 01:53:04.600]   I mean, Mike, you nailed it talking about ghosts, but it's a ghost in a different way.
[01:53:04.600 --> 01:53:05.600]   You do feel more...
[01:53:05.600 --> 01:53:10.080]   I felt more connected because I don't know.
[01:53:10.080 --> 01:53:12.240]   There's an additional element of movement.
[01:53:12.240 --> 01:53:17.120]   So that's the real question, is I think ultimately is going to be, is that satisfying?
[01:53:17.120 --> 01:53:18.720]   Is it real intimacy?
[01:53:18.720 --> 01:53:25.000]   Or is it tricking our mind into thinking we're not alone when we really are alone?
[01:53:25.000 --> 01:53:27.120]   And that'll be interesting to watch that play out.
[01:53:27.120 --> 01:53:28.320]   I don't know what that's interesting.
[01:53:28.320 --> 01:53:34.320]   That word alone is a good word because you don't feel as alone.
[01:53:34.320 --> 01:53:39.320]   Even though you're the only person in that space and you can see everything, you just
[01:53:39.320 --> 01:53:40.320]   also...
[01:53:40.320 --> 01:53:45.680]   Because you're in a spatial-computing environment, you see other stuff.
[01:53:45.680 --> 01:53:46.680]   It's really...
[01:53:46.680 --> 01:53:50.120]   I keep bumping into the microphone because I'm so excited.
[01:53:50.120 --> 01:53:54.920]   It's really interesting and Leo, you should at least try them on at some point.
[01:53:54.920 --> 01:53:59.760]   I don't know when I went from being somebody who braced off and everything new to a Luddite,
[01:53:59.760 --> 01:54:00.760]   but...
[01:54:00.760 --> 01:54:02.800]   I don't embrace anything.
[01:54:02.800 --> 01:54:05.320]   Almost this new stuff and I'm like this iPhone.
[01:54:05.320 --> 01:54:07.320]   A little skeptical.
[01:54:07.320 --> 01:54:08.320]   Yeah.
[01:54:08.320 --> 01:54:14.640]   Again, like this headset is you're not going to buy and do anything with it, but this is
[01:54:14.640 --> 01:54:15.640]   not what I'm excited about.
[01:54:15.640 --> 01:54:16.640]   What I'm excited is...
[01:54:16.640 --> 01:54:17.640]   Yeah, I understand.
[01:54:17.640 --> 01:54:22.440]   And that's why I want everybody to just leave them alone and let them...
[01:54:22.440 --> 01:54:27.240]   Let's curb our expectations here for an annual product launch, just let them do their work.
[01:54:27.240 --> 01:54:28.240]   It's really hard stuff.
[01:54:28.240 --> 01:54:29.240]   Well, the only...
[01:54:29.240 --> 01:54:31.280]   But for people you have to convince that of is their investors.
[01:54:31.280 --> 01:54:32.840]   And I think that they're investors.
[01:54:32.840 --> 01:54:38.200]   It's actually been a fascinating story because the journalists like Kevin Kelly and the investors
[01:54:38.200 --> 01:54:44.400]   who have seen this before anybody else has are completely sold on it.
[01:54:44.400 --> 01:54:49.280]   And the rest of the world like me is saying, "Well, really?"
[01:54:49.280 --> 01:54:53.440]   But magically, as much time as investors want to give it, right?
[01:54:53.440 --> 01:54:54.440]   But they're colored by...
[01:54:54.440 --> 01:55:01.760]   And this is true of any technology that the tech journalists and part of being...
[01:55:01.760 --> 01:55:05.920]   Social media has, I think, forced some of this, but there's an awful lot of snark.
[01:55:05.920 --> 01:55:10.120]   I know very few tech journalists who can talk about magic leap in any way without also
[01:55:10.120 --> 01:55:13.720]   feeling an obligation to be snarky about it.
[01:55:13.720 --> 01:55:20.120]   And they are building something that we have not seen before.
[01:55:20.120 --> 01:55:27.840]   Again, there's plenty of magic also happening at Google and at Amazon and at...
[01:55:27.840 --> 01:55:28.840]   Well, it's a sales force.
[01:55:28.840 --> 01:55:29.840]   Lots of different places.
[01:55:29.840 --> 01:55:35.160]   We just have to somehow extract ourselves from this idea that there must be a product
[01:55:35.160 --> 01:55:38.000]   that conforms to a 12-month calendar.
[01:55:38.000 --> 01:55:40.200]   Otherwise, they have failed.
[01:55:40.200 --> 01:55:43.480]   There is a very American thing to do.
[01:55:43.480 --> 01:55:47.840]   There's a distinction between snark and skepticism.
[01:55:47.840 --> 01:55:51.440]   And I would hope that I'm not snarky, but I'm skeptical about...
[01:55:51.440 --> 01:55:52.440]   Yeah, totally.
[01:55:52.440 --> 01:55:53.440]   I'm just...
[01:55:53.440 --> 01:55:54.440]   No, but you're right.
[01:55:54.440 --> 01:55:55.440]   No, I think you're right.
[01:55:55.440 --> 01:55:56.440]   I think there is intense pressure.
[01:55:56.440 --> 01:56:00.480]   And it is also from the markets and from investors to produce.
[01:56:00.480 --> 01:56:03.840]   A lot of tech journalists get confused about what they're covering, whether they're covering
[01:56:03.840 --> 01:56:07.480]   the stock market or whether they're covering the actual hardware and software.
[01:56:07.480 --> 01:56:12.680]   And the thing that Amy and I both, if we have one thing in common, is that we are obsessed
[01:56:12.680 --> 01:56:16.120]   with the cultural effects of technology, which is everything.
[01:56:16.120 --> 01:56:19.640]   And the technology itself is really not that important, at least to me.
[01:56:19.640 --> 01:56:23.200]   And so when you're snarky about Magic Leap, essentially you're getting confused about
[01:56:23.200 --> 01:56:25.960]   what's happening.
[01:56:25.960 --> 01:56:29.320]   What you should be focused on is how is this going to change human life?
[01:56:29.320 --> 01:56:33.000]   Not like, "Oh, this isn't that much better than the HoloLens thing I saw a year ago.
[01:56:33.000 --> 01:56:35.120]   That doesn't matter how much better it is than it was."
[01:56:35.120 --> 01:56:36.120]   It doesn't matter.
[01:56:36.120 --> 01:56:38.960]   That's an inconsequential observation.
[01:56:38.960 --> 01:56:42.280]   It's an interesting problem also because companies have to decide what they're going
[01:56:42.280 --> 01:56:43.280]   to work on.
[01:56:43.280 --> 01:56:46.080]   Individuals, people, entrepreneurs have to decide what they're going to work on.
[01:56:46.080 --> 01:56:48.000]   And they're, of course, very much influenced.
[01:56:48.000 --> 01:56:51.880]   They can't help it, but the environment around them.
[01:56:51.880 --> 01:56:56.960]   The snarky tech press, the science fiction that they read is no accident that almost
[01:56:56.960 --> 01:57:01.560]   everything new and exciting is basically science fiction.
[01:57:01.560 --> 01:57:02.560]   People are making it.
[01:57:02.560 --> 01:57:07.800]   Again, that's why, and if you guys, honestly, some of the best sci-fi that I've ever read
[01:57:07.800 --> 01:57:10.160]   was not sci-fi.
[01:57:10.160 --> 01:57:12.240]   And hopefully it's not fie at all.
[01:57:12.240 --> 01:57:14.720]   It's the patents.
[01:57:14.720 --> 01:57:22.560]   There are several magically patents that describe, in a William Gibson-esque sort of way, what
[01:57:22.560 --> 01:57:24.360]   this technology ultimately becomes.
[01:57:24.360 --> 01:57:25.680]   They are fascinating.
[01:57:25.680 --> 01:57:33.560]   Anybody that wants to can go on to the USPTO.gov website, just type in keyword "magicleap"
[01:57:33.560 --> 01:57:34.560]   and just start looking.
[01:57:34.560 --> 01:57:37.440]   I mean, a lot of the patents are very long.
[01:57:37.440 --> 01:57:44.000]   Obviously, they're technical in nature, but in many of them, there are chunks where it
[01:57:44.000 --> 01:57:47.080]   reads like a science fiction novel.
[01:57:47.080 --> 01:57:53.320]   And it doesn't, just because they've described it, doesn't mean that it necessarily happens
[01:57:53.320 --> 01:57:57.520]   or it happens on a timeframe that you agree with.
[01:57:57.520 --> 01:57:59.880]   But it is totally worth your time.
[01:57:59.880 --> 01:58:04.080]   It's worth an hour of your time to just go through the USPTO.
[01:58:04.080 --> 01:58:09.240]   Well, and also it would behoove me to point out that there are reasons, many reasons,
[01:58:09.240 --> 01:58:13.240]   people make patent applications, and one of them is preemptively the hope that they're
[01:58:13.240 --> 01:58:17.120]   going to patent something that somebody someday is going to invent so they can sue them.
[01:58:17.120 --> 01:58:20.800]   There's also an irony about reading about the future on our website that looks like
[01:58:20.800 --> 01:58:21.800]   it's from the '90s.
[01:58:21.800 --> 01:58:22.800]   I know.
[01:58:22.800 --> 01:58:23.800]   Oh my God, that website.
[01:58:23.800 --> 01:58:25.640]   I wish they would do something about that.
[01:58:25.640 --> 01:58:28.800]   Oh, oh, only Amy Webb is doing this.
[01:58:28.800 --> 01:58:30.800]   Let me peruse the USPTO.
[01:58:30.800 --> 01:58:35.880]   Anybody who's interested in the future, honestly, you can put a couple of keyword searches in
[01:58:35.880 --> 01:58:36.880]   the future.
[01:58:36.880 --> 01:58:37.880]   Oh, it's easy to do this.
[01:58:37.880 --> 01:58:38.880]   Yeah.
[01:58:38.880 --> 01:58:41.280]   And they'll send you emails of any new patent that's been filed that mentions whatever
[01:58:41.280 --> 01:58:42.280]   it is.
[01:58:42.280 --> 01:58:44.200]   It's just a good way to stay on top of things.
[01:58:44.200 --> 01:58:48.080]   How about a mixed reality system with virtual content warping?
[01:58:48.080 --> 01:58:53.840]   I want one of those and a method of generating virtual content using same techniques for
[01:58:53.840 --> 01:58:56.760]   improving a fiber scanning system.
[01:58:56.760 --> 01:58:59.240]   These are all magically patents.
[01:58:59.240 --> 01:59:02.800]   And I know investors look at these and just count them and go, "That's good.
[01:59:02.800 --> 01:59:04.120]   I'm going to buy this company."
[01:59:04.120 --> 01:59:05.720]   Worst case scenario, we sell the patents.
[01:59:05.720 --> 01:59:06.720]   That's right.
[01:59:06.720 --> 01:59:08.080]   They got 132 patents.
[01:59:08.080 --> 01:59:09.720]   All right.
[01:59:09.720 --> 01:59:12.160]   Let's take a break.
[01:59:12.160 --> 01:59:18.960]   I actually have the stories that made my eyeballs go, "What?" when I came back, and I'm
[01:59:18.960 --> 01:59:21.360]   going to give you a few of those.
[01:59:21.360 --> 01:59:24.360]   But first, I would like to tell you about a new show that we're...
[01:59:24.360 --> 01:59:27.200]   That's not a new show, but a new edition of a show.
[01:59:27.200 --> 01:59:28.440]   We've been doing it for a long time called Know.
[01:59:28.440 --> 01:59:34.400]   And when Father Robert left, we decided we were going to take turns doing Know How.
[01:59:34.400 --> 01:59:39.440]   Meghan Moroney did a whole series with Florence Ion on IoT, and we've got a new series coming
[01:59:39.440 --> 01:59:40.920]   up with Jason Halberd.
[01:59:40.920 --> 01:59:42.680]   I'll let him tell you all about it.
[01:59:42.680 --> 01:59:49.320]   Hey, I'm Jason Hal, and I'm here to tell you all about the next season of Know How.
[01:59:49.320 --> 01:59:52.840]   You already know Meghan Moroney and Florence Ion are wrapping up their excellent season
[01:59:52.840 --> 01:59:53.960]   on the Internet of Things.
[01:59:53.960 --> 01:59:57.880]   And now, it's going to be my turn to spend a few months focused on an entirely different
[01:59:57.880 --> 02:00:02.680]   facet of technology, and I figured, if given the choice, why not choose something really
[02:00:02.680 --> 02:00:03.680]   fun?
[02:00:03.680 --> 02:00:06.680]   And that's exactly what we've done with Know How Gaming.
[02:00:06.680 --> 02:00:10.480]   The always-awesome Samusco, which is from Marsh Technica, will join me each week as we
[02:00:10.480 --> 02:00:15.760]   dive into a number of important gaming topics, including console tips and tricks, virtual
[02:00:15.760 --> 02:00:22.920]   reality, live broadcasting gameplay, mobile gaming, classic gaming, console hacking, and
[02:00:22.920 --> 02:00:25.880]   even a holiday gift guide.
[02:00:25.880 --> 02:00:29.040]   We're covering it all, leading up to the new year, and we hope you'll be along for the
[02:00:29.040 --> 02:00:30.040]   ride.
[02:00:30.040 --> 02:00:34.240]   Subscribe to Know How if You Haven't Already at Twit.tv, and you'll get the gaming season
[02:00:34.240 --> 02:00:39.120]   delivered automatically each and every week, starting Thursday, September 27.
[02:00:39.120 --> 02:00:40.120]   We'll see you then.
[02:00:40.120 --> 02:00:41.120]   Jason Hal, Twit.tv/KH.
[02:00:41.120 --> 02:00:43.280]   That looks awesome.
[02:00:43.280 --> 02:00:47.880]   Twit.tv/KH to subscribe to Know How the Gaming Edition.
[02:00:47.880 --> 02:00:51.960]   I showed it a brought to you by Rocket Mortgage from Quick and Loans.
[02:00:51.960 --> 02:00:54.240]   Let's talk about the future.
[02:00:54.240 --> 02:00:57.120]   The future is interest rates are going up, aren't they?
[02:00:57.120 --> 02:01:01.440]   And that means when you go out to buy that new home, you're going to be paying a little
[02:01:01.440 --> 02:01:03.960]   bit more, maybe not right up front, but over time.
[02:01:03.960 --> 02:01:07.840]   In fact, a quarter point in interest rates going up thousands of dollars, maybe tens
[02:01:07.840 --> 02:01:09.880]   of thousands of dollars over the 30-year loan.
[02:01:09.880 --> 02:01:14.560]   That's why Rocket Mortgage has decided to do something special to take some of the anxiety
[02:01:14.560 --> 02:01:16.200]   out of home shopping.
[02:01:16.200 --> 02:01:18.640]   They call it the power buying process.
[02:01:18.640 --> 02:01:22.800]   Three steps that will make home buying a pleasure.
[02:01:22.800 --> 02:01:27.520]   First of all, go to Rocket Mortgage.com/Twit2.
[02:01:27.520 --> 02:01:29.520]   That's Twit the number two.
[02:01:29.520 --> 02:01:30.520]   And answer a few questions.
[02:01:30.520 --> 02:01:31.520]   You can do this, by the way.
[02:01:31.520 --> 02:01:32.520]   It's so easy to do.
[02:01:32.520 --> 02:01:36.200]   You can do this not only on your home computer, but on your phone while you're in an open
[02:01:36.200 --> 02:01:37.200]   house.
[02:01:37.200 --> 02:01:38.200]   Or just do it now.
[02:01:38.200 --> 02:01:39.200]   Set up the account.
[02:01:39.200 --> 02:01:40.400]   Answer a few simple questions.
[02:01:40.400 --> 02:01:42.800]   They'll check your credit for pre-qualified approval.
[02:01:42.800 --> 02:01:45.320]   They'll do that within just a few minutes.
[02:01:45.320 --> 02:01:47.280]   That's enough to get you started.
[02:01:47.280 --> 02:01:52.640]   Within 24 hours though, they will then verify your income, your assets, and your credit.
[02:01:52.640 --> 02:01:57.320]   All of this without any effort on your part, no 20-page application, no going to the
[02:01:57.320 --> 02:01:58.560]   attic to find paperwork.
[02:01:58.560 --> 02:02:01.080]   They'll do it all for you and give you a verified approval.
[02:02:01.080 --> 02:02:04.800]   Within 24 hours, that means you have the strength of a cash buyer.
[02:02:04.800 --> 02:02:07.120]   When you're buying that house, you're good for it.
[02:02:07.120 --> 02:02:08.120]   You're good for the money.
[02:02:08.120 --> 02:02:09.120]   The seller loves that.
[02:02:09.120 --> 02:02:10.120]   They say, "Oh, good.
[02:02:10.120 --> 02:02:11.120]   They got the loan approved."
[02:02:11.120 --> 02:02:13.320]   In fact, you can even get a nice little approval letter.
[02:02:13.320 --> 02:02:15.360]   You can print out if you want to show them.
[02:02:15.360 --> 02:02:16.440]   It makes a big difference.
[02:02:16.440 --> 02:02:17.920]   But here's the best part.
[02:02:17.920 --> 02:02:22.600]   Once you're verified, you qualify for their all-new exclusive rate shield approval.
[02:02:22.600 --> 02:02:25.320]   This is one of the things that really takes the anxiety out.
[02:02:25.320 --> 02:02:30.120]   With rate shield approval, they'll lock up your rate for up to 90 days while you shop.
[02:02:30.120 --> 02:02:33.440]   If the rates go up, nope, your rate stays the same.
[02:02:33.440 --> 02:02:35.200]   If rates go down, your rate will drop.
[02:02:35.200 --> 02:02:36.640]   But either way, you win.
[02:02:36.640 --> 02:02:41.200]   It's exactly what you'd expect from a company that's focused on its customers.
[02:02:41.200 --> 02:02:44.960]   Number one in customer satisfaction, eight years in a row, according to JD Power, it's
[02:02:44.960 --> 02:02:46.960]   quick and loans and rocket mortgage.
[02:02:46.960 --> 02:02:49.960]   To get started, go to rocketmortgage.com/twit2.
[02:02:49.960 --> 02:02:51.960]   It's enough.
[02:02:51.960 --> 02:02:53.120]   You're writing a big check.
[02:02:53.120 --> 02:02:54.120]   You're buying a house.
[02:02:54.120 --> 02:02:55.440]   It's a big deal as it is.
[02:02:55.440 --> 02:02:58.520]   Let's not make it any more anxiety-ridden.
[02:02:58.520 --> 02:03:03.480]   Go to rocketmortgage.com/twit2 for rate shield approval.
[02:03:03.480 --> 02:03:07.880]   Only valid and certain 30-year purchase transactions, additional conditions or exclusions may apply
[02:03:07.880 --> 02:03:11.560]   based on quick and loans data in comparison to public data records.
[02:03:11.560 --> 02:03:16.120]   Equal housing lender, licensed in all 50 states, nmlsconsumeraccess.org.
[02:03:16.120 --> 02:03:21.120]   Number 30-30.
[02:03:21.120 --> 02:03:22.400]   It's rocketmortgage.com/twit2.
[02:03:22.400 --> 02:03:28.200]   We thank Rocket Mortgage for being such a great supporter throughout the year.
[02:03:28.200 --> 02:03:29.200]   They're coming back next year.
[02:03:29.200 --> 02:03:30.200]   We're glad to hear that too.
[02:03:30.200 --> 02:03:33.040]   We're going to get back to the tech news in a minute.
[02:03:33.040 --> 02:03:35.640]   Of course, while I was away, the shows go on.
[02:03:35.640 --> 02:03:37.120]   Thanks to our great hosts.
[02:03:37.120 --> 02:03:39.800]   If you missed anything as I did, I'm looking forward to watching this.
[02:03:39.800 --> 02:03:43.800]   We've got a little movie talking about this week on Twit.
[02:03:43.800 --> 02:03:45.520]   Previously on Twit.
[02:03:45.520 --> 02:03:48.320]   We're filling in for Leo one more day.
[02:03:48.320 --> 02:03:51.720]   My fear is that Leo is literally going to come into the studio while I'm on with the
[02:03:51.720 --> 02:03:55.560]   last hour of the tech guy and just literally grab the microphone for me.
[02:03:55.560 --> 02:03:57.240]   This is the dream I've been having at night.
[02:03:57.240 --> 02:03:58.240]   It's like the nightmare.
[02:03:58.240 --> 02:03:59.400]   Maybe that might actually happen.
[02:03:59.400 --> 02:04:01.400]   Now that you've put it out into the world.
[02:04:01.400 --> 02:04:02.400]   Let me see.
[02:04:02.400 --> 02:04:05.000]   As you mentioned, I will be kicking you out.
[02:04:05.000 --> 02:04:06.480]   Mac Break Weekly.
[02:04:06.480 --> 02:04:11.960]   Someone posted stats to show that the iPhone processors now are about as fast as some of
[02:04:11.960 --> 02:04:18.000]   the bottom end MacBooks.
[02:04:18.000 --> 02:04:25.640]   You're looking at stats there and speeds and capacity that is starting to the MacBook
[02:04:25.640 --> 02:04:30.280]   Pro 13 not being possibly that much more powerful.
[02:04:30.280 --> 02:04:32.080]   Probably by A13, A14.
[02:04:32.080 --> 02:04:36.520]   We're probably going to see a point where you are buying a computer.
[02:04:36.520 --> 02:04:37.680]   This week in Google.
[02:04:37.680 --> 02:04:42.360]   So Smart Replies looks at all these responses and makes up a response that you should give
[02:04:42.360 --> 02:04:45.280]   an email and I've talked about how I feel guilty using it.
[02:04:45.280 --> 02:04:47.280]   AI goes off our behavior.
[02:04:47.280 --> 02:04:51.960]   So guess what Smart Reply tried to get people to say often.
[02:04:51.960 --> 02:04:54.200]   I love you.
[02:04:54.200 --> 02:04:55.200]   I'm down with that.
[02:04:55.200 --> 02:04:56.200]   Yeah.
[02:04:56.200 --> 02:04:59.240]   You know, this hate going around in this world plant that we'll see the power of that.
[02:04:59.240 --> 02:05:01.160]   I totally dig that.
[02:05:01.160 --> 02:05:02.160]   Twit.
[02:05:02.160 --> 02:05:04.160]   We love you.
[02:05:04.160 --> 02:05:09.400]   Don't tell rich that I have put a kick him out in the last hour.
[02:05:09.400 --> 02:05:11.920]   Now that you put it out in the world, it's probably going to happen.
[02:05:11.920 --> 02:05:13.720]   Well then I'd also like a million dollars.
[02:05:13.720 --> 02:05:14.720]   Okay, good.
[02:05:14.720 --> 02:05:16.320]   That was important to fit that in there.
[02:05:16.320 --> 02:05:18.880]   Let's put that one out there in the world.
[02:05:18.880 --> 02:05:23.680]   Twit continues the return of Leo after three weeks.
[02:05:23.680 --> 02:05:26.120]   Mike Elgin and Amy Webb with me today.
[02:05:26.120 --> 02:05:31.160]   You mentioned the new Jason Howell gaming know-how.
[02:05:31.160 --> 02:05:34.200]   You didn't mention Valley of Genius, which I think is a podcast.
[02:05:34.200 --> 02:05:35.520]   I feel a lot fantastic.
[02:05:35.520 --> 02:05:36.520]   So good.
[02:05:36.520 --> 02:05:37.520]   So good.
[02:05:37.520 --> 02:05:38.520]   That's a great idea.
[02:05:38.520 --> 02:05:41.200]   That is a new show too and I didn't really publicize that as much as I should have.
[02:05:41.200 --> 02:05:42.200]   It's audio only.
[02:05:42.200 --> 02:05:48.600]   It started because we interviewed the author of the book Valley of Genius and on triangulation.
[02:05:48.600 --> 02:05:49.600]   I'm sitting up talking to him.
[02:05:49.600 --> 02:05:51.240]   It's a great book.
[02:05:51.240 --> 02:05:57.160]   Adam Fisher talks to hundreds of people who made Silicon Valley what it is.
[02:05:57.160 --> 02:05:58.720]   And I mean hundreds.
[02:05:58.720 --> 02:06:24.440]   And at the end of the conversation, Trang
[02:06:24.440 --> 02:06:32.640]   talks about Sergey Brin and Larry Page.
[02:06:32.640 --> 02:06:37.920]   He was a graduate student at Stanford who had been assigned.
[02:06:37.920 --> 02:06:40.480]   He was the only programmer in the computer lab.
[02:06:40.480 --> 02:06:45.200]   He was assigned to the graduate students that are trying to write their thesis to code
[02:06:45.200 --> 02:06:47.520]   up the thing their thesis about.
[02:06:47.520 --> 02:06:51.400]   Larry and Sergey were just trying to get their doctorate.
[02:06:51.400 --> 02:06:55.200]   So this whole thing has sons writing the code for it.
[02:06:55.200 --> 02:06:57.160]   So that's one of the interviews.
[02:06:57.160 --> 02:06:58.800]   There's Nolan Bushnell.
[02:06:58.800 --> 02:07:02.040]   He even followed Tony Fidell, the guy who worked on the iPod.
[02:07:02.040 --> 02:07:05.440]   He was originally a general magic.
[02:07:05.440 --> 02:07:09.440]   Great story there about how he got the job at General Magic as a kid straight out of
[02:07:09.440 --> 02:07:10.440]   college.
[02:07:10.440 --> 02:07:14.040]   He then went to help design the iPod and the iPhone.
[02:07:14.040 --> 02:07:18.000]   Fidell is now in Paris as anybody would be with his money.
[02:07:18.000 --> 02:07:19.000]   That's where I would be.
[02:07:19.000 --> 02:07:21.320]   And actually he's helping entrepreneurs.
[02:07:21.320 --> 02:07:22.400]   He's doing VC stuff.
[02:07:22.400 --> 02:07:27.680]   So the great story Adam gets on a motorcycle or a bicycle I guess because they're bicycling
[02:07:27.680 --> 02:07:28.680]   across Paris.
[02:07:28.680 --> 02:07:31.920]   He's following Fidell across this interview.
[02:07:31.920 --> 02:07:33.760]   What do you hear at the audio is fantastic.
[02:07:33.760 --> 02:07:35.360]   So he has audio of all of this stuff.
[02:07:35.360 --> 02:07:36.520]   I said, Adam, come in.
[02:07:36.520 --> 02:07:37.600]   Let's do a podcast.
[02:07:37.600 --> 02:07:40.880]   So that's Valley of Genius, twit.tv/vog.
[02:07:40.880 --> 02:07:44.240]   It is only audio because there's no, what do you need video?
[02:07:44.240 --> 02:07:48.400]   We could put new episodes at every Monday.
[02:07:48.400 --> 02:07:49.840]   And this could go on for a long time.
[02:07:49.840 --> 02:07:52.840]   If somebody came to you and said, I'm going to interview this guy, I'm going to interview
[02:07:52.840 --> 02:07:53.840]   that guy.
[02:07:53.840 --> 02:07:54.840]   You'd be like, sure you will.
[02:07:54.840 --> 02:07:56.080]   You got everybody.
[02:07:56.080 --> 02:07:57.080]   It's unbelievable.
[02:07:57.080 --> 02:07:58.920]   And they're not performances.
[02:07:58.920 --> 02:07:59.920]   No.
[02:07:59.920 --> 02:08:02.000]   And this is the great thing as a journalist, you interview people and the interviews are
[02:08:02.000 --> 02:08:05.320]   actually great but you usually don't get to, nobody hears them.
[02:08:05.320 --> 02:08:06.320]   Right.
[02:08:06.320 --> 02:08:07.320]   Yeah, it's basically nice.
[02:08:07.320 --> 02:08:09.600]   You need to go back and ask everybody if it was okay.
[02:08:09.600 --> 02:08:10.600]   But he...
[02:08:10.600 --> 02:08:11.600]   Well I asked him that.
[02:08:11.600 --> 02:08:13.400]   He said, well there's this thing called the First Amendment.
[02:08:13.400 --> 02:08:14.400]   I don't know what he said.
[02:08:14.400 --> 02:08:15.600]   He said, basically, no.
[02:08:15.600 --> 02:08:20.760]   Why was this was on the record of interviews that we were doing for a book?
[02:08:20.760 --> 02:08:23.160]   Didn't, you know, yeah, I own them.
[02:08:23.160 --> 02:08:24.680]   He's interviewing Waz.
[02:08:24.680 --> 02:08:26.200]   What's the name of it?
[02:08:26.200 --> 02:08:27.200]   The Chuck Wagon?
[02:08:27.200 --> 02:08:28.680]   Waz loves this place.
[02:08:28.680 --> 02:08:29.680]   The barbecue place, right?
[02:08:29.680 --> 02:08:30.680]   Yeah, it loves this place.
[02:08:30.680 --> 02:08:31.680]   It's a Silicon Valley.
[02:08:31.680 --> 02:08:32.680]   What's it called?
[02:08:32.680 --> 02:08:33.680]   The Hickory Pit.
[02:08:33.680 --> 02:08:34.680]   Hickory Pit, right.
[02:08:34.680 --> 02:08:36.640]   I like the Chuck Wagon better.
[02:08:36.640 --> 02:08:38.480]   Are you sure it's not the Chuck Wagon?
[02:08:38.480 --> 02:08:42.320]   Anyway, the Hickory Pit's a chain but I think there's anyway.
[02:08:42.320 --> 02:08:47.560]   Here was lip smacking and there's clanking additions.
[02:08:47.560 --> 02:08:49.800]   It's really fun.
[02:08:49.800 --> 02:08:50.640]   So yes.
[02:08:50.640 --> 02:08:52.640]   No, he didn't.
[02:08:52.640 --> 02:08:55.000]   He says, no, I said you have permission.
[02:08:55.000 --> 02:08:58.600]   He says, oh yeah, these are all on the record interviews I have permission to use these.
[02:08:58.600 --> 02:09:01.040]   So a podcast was born.
[02:09:01.040 --> 02:09:02.040]   Brilliant.
[02:09:02.040 --> 02:09:03.120]   Yeah, I love it.
[02:09:03.120 --> 02:09:05.040]   If you haven't heard it, Twitter.tv/vog.
[02:09:05.040 --> 02:09:08.680]   And I think we've only got a few episodes, right?
[02:09:08.680 --> 02:09:10.320]   Carson, how many are out?
[02:09:10.320 --> 02:09:11.320]   Two are out so far.
[02:09:11.320 --> 02:09:14.880]   One more comes out tomorrow with Nolan Bushnell.
[02:09:14.880 --> 02:09:16.960]   Oh, that'll be fun.
[02:09:16.960 --> 02:09:21.640]   Nolan's the guy who hired a young Steve Jobs to work at Atari.
[02:09:21.640 --> 02:09:22.640]   Yep.
[02:09:22.640 --> 02:09:25.480]   Any of those Venus's women?
[02:09:25.480 --> 02:09:26.480]   Yes, indeed.
[02:09:26.480 --> 02:09:27.480]   Are they?
[02:09:27.480 --> 02:09:28.480]   Good.
[02:09:28.480 --> 02:09:29.480]   It's mostly guys.
[02:09:29.480 --> 02:09:30.480]   Yeah.
[02:09:30.480 --> 02:09:32.240]   It's mostly guys.
[02:09:32.240 --> 02:09:35.840]   There are a few people who are very interested.
[02:09:35.840 --> 02:09:36.840]   Interesting.
[02:09:36.840 --> 02:09:43.160]   We really loved, we did an interview on triangulation on the making of General Magic.
[02:09:43.160 --> 02:09:48.040]   And Megan Smith, who eventually became a Google Vice President and the CTO of the United
[02:09:48.040 --> 02:09:55.360]   States, was a young engineer who was tasked with building the prototypes for the magic
[02:09:55.360 --> 02:10:01.160]   leap, not magic leap, general magic device and magic link, they call it.
[02:10:01.160 --> 02:10:02.640]   And she's great.
[02:10:02.640 --> 02:10:05.600]   She's just her energy and enthusiasm.
[02:10:05.600 --> 02:10:09.680]   And she's the kind of woman you see and any girl watching this will go, "Yeah, I want
[02:10:09.680 --> 02:10:10.760]   to do that.
[02:10:10.760 --> 02:10:12.080]   I could do that."
[02:10:12.080 --> 02:10:13.920]   So we should get more of those interviews.
[02:10:13.920 --> 02:10:15.520]   I'd love to see more of those.
[02:10:15.520 --> 02:10:18.240]   So you were going to surprise us with the thing that...
[02:10:18.240 --> 02:10:19.240]   Yeah.
[02:10:19.240 --> 02:10:20.640]   I got four stories.
[02:10:20.640 --> 02:10:22.680]   You didn't even mention.
[02:10:22.680 --> 02:10:27.600]   John Hancock has announced it's going to stop underwriting traditional life insurance
[02:10:27.600 --> 02:10:32.440]   and sell only policies that track fitness and health data through wearable devices and
[02:10:32.440 --> 02:10:33.440]   smartphones.
[02:10:33.440 --> 02:10:34.440]   Okay.
[02:10:34.440 --> 02:10:38.720]   So the bigger story there is that they're trying to rename that building in my hometown of
[02:10:38.720 --> 02:10:39.720]   Chicago.
[02:10:39.720 --> 02:10:43.280]   The Hancock building is no longer the Hancock building.
[02:10:43.280 --> 02:10:46.600]   That's the landmark building with the glass war.
[02:10:46.600 --> 02:10:48.360]   That's the Fitbit building.
[02:10:48.360 --> 02:10:49.360]   So bad.
[02:10:49.360 --> 02:10:50.360]   Is it the Fitbit building?
[02:10:50.360 --> 02:10:51.360]   I don't know what it is.
[02:10:51.360 --> 02:10:53.160]   I hope to God, Nod.
[02:10:53.160 --> 02:10:54.160]   You know what?
[02:10:54.160 --> 02:10:55.160]   It'll always be the Sears Tower.
[02:10:55.160 --> 02:10:56.440]   It'll always be Grant Park.
[02:10:56.440 --> 02:10:57.440]   Yeah.
[02:10:57.440 --> 02:10:58.440]   Yeah.
[02:10:58.440 --> 02:11:01.080]   Oh, by the way, I didn't know you were a Chicagoan.
[02:11:01.080 --> 02:11:02.080]   I am a Chicagoan.
[02:11:02.080 --> 02:11:07.080]   It'll be on the airplane.
[02:11:07.080 --> 02:11:10.080]   It's called 85.
[02:11:10.080 --> 02:11:13.080]   The story of the 1985 Chicago Bears.
[02:11:13.080 --> 02:11:14.080]   Oh, the Super Bowl.
[02:11:14.080 --> 02:11:15.080]   It's there.
[02:11:15.080 --> 02:11:16.080]   The Super Bowl shovel.
[02:11:16.080 --> 02:11:17.080]   Did you really recorded that after only 12 games?
[02:11:17.080 --> 02:11:18.080]   I would not doubt that.
[02:11:18.080 --> 02:11:20.080]   That was a remarkable year.
[02:11:20.080 --> 02:11:21.080]   And it was...
[02:11:21.080 --> 02:11:22.080]   They had to go in the day after they...
[02:11:22.080 --> 02:11:23.080]   What lost one game that season?
[02:11:23.080 --> 02:11:24.080]   The Miami Dolphins.
[02:11:24.080 --> 02:11:27.080]   They had it recorded the day after they lost the Miami Dolphins.
[02:11:27.080 --> 02:11:28.080]   That was peaceful.
[02:11:28.080 --> 02:11:29.080]   That's cocky.
[02:11:29.080 --> 02:11:31.880]   It's somewhere on YouTube and it's totally worth watching.
[02:11:31.880 --> 02:11:32.880]   Oh, it's so bad.
[02:11:32.880 --> 02:11:33.880]   If we don't know what we're talking about, yeah.
[02:11:33.880 --> 02:11:34.880]   It's so bad.
[02:11:34.880 --> 02:11:43.880]   But the Fridge William refrigerator, Perry, of course, amazing running back Walter Payton's
[02:11:43.880 --> 02:11:44.880]   sweetness.
[02:11:44.880 --> 02:11:45.880]   It's a really great...
[02:11:45.880 --> 02:11:47.880]   And John, what was his name?
[02:11:47.880 --> 02:11:49.880]   It was a little young for the successful...
[02:11:49.880 --> 02:11:51.880]   Oh, the guy with the headband's McMahon.
[02:11:51.880 --> 02:11:53.880]   Jim McMahon, the quarterback.
[02:11:53.880 --> 02:11:55.880]   Jim McMahon, thank you, baby.
[02:11:55.880 --> 02:11:56.880]   Yeah.
[02:11:56.880 --> 02:11:57.880]   Yeah.
[02:11:57.880 --> 02:12:00.880]   And by the way, in this movie, woo-hoo, he's still...
[02:12:00.880 --> 02:12:02.600]   He's a character and a half.
[02:12:02.600 --> 02:12:03.600]   It's a great...
[02:12:03.600 --> 02:12:04.600]   And of course, Mike Dica...
[02:12:04.600 --> 02:12:10.480]   Mike Rama, you wrote a plane once with Mike Dica and she chatted his head off all the
[02:12:10.480 --> 02:12:12.000]   way to wherever they were flying.
[02:12:12.000 --> 02:12:13.000]   Oh, I bet.
[02:12:13.000 --> 02:12:14.000]   I bet.
[02:12:14.000 --> 02:12:16.600]   Anyway, as a Chicagoan, you must see.
[02:12:16.600 --> 02:12:17.600]   I will.
[02:12:17.600 --> 02:12:18.600]   I didn't know it was...
[02:12:18.600 --> 02:12:19.600]   I will definitely do.
[02:12:19.600 --> 02:12:20.840]   Yeah, 85.
[02:12:20.840 --> 02:12:21.840]   So that's one.
[02:12:21.840 --> 02:12:24.400]   John Hancock, I don't know what they're doing with a building name, but that's...
[02:12:24.400 --> 02:12:30.520]   We'd always said that this is the thing that scared people about all this privacy and
[02:12:30.520 --> 02:12:31.520]   all...
[02:12:31.520 --> 02:12:36.200]   Is that at some point insurance companies would start to say, "Well, did you work out yesterday?"
[02:12:36.200 --> 02:12:37.200]   Right.
[02:12:37.200 --> 02:12:39.360]   Now they are.
[02:12:39.360 --> 02:12:41.040]   Another one.
[02:12:41.040 --> 02:12:49.240]   A coding error sent several hundred Subaru ascents to the car crusher.
[02:12:49.240 --> 02:12:50.240]   They...
[02:12:50.240 --> 02:12:54.160]   Now, we've heard before of coding errors in the firmware of the car and that you just
[02:12:54.160 --> 02:12:55.320]   fixed the firmware.
[02:12:55.320 --> 02:12:58.800]   This coding error was in the robot arm that did the spot welds.
[02:12:58.800 --> 02:13:00.800]   It's a spot weld.
[02:13:00.800 --> 02:13:04.000]   When they put the thing together, they weld the metal together, right?
[02:13:04.000 --> 02:13:07.680]   And the robot arms that are doing that, they need to hit all the spots.
[02:13:07.680 --> 02:13:13.600]   Apparently, the software was buggy and missed some critical spot welds, making it unsafe
[02:13:13.600 --> 02:13:18.360]   to drive those cars because they could just fall apart.
[02:13:18.360 --> 02:13:20.280]   No physical remedy was available.
[02:13:20.280 --> 02:13:28.680]   Therefore, Subaru is destroying the vehicles because of bad code.
[02:13:28.680 --> 02:13:31.240]   And finally, we were talking about Salesforce, but I didn't know this.
[02:13:31.240 --> 02:13:36.440]   Mark Benioff of Salesforce, he must have a little Jeff Bezos envy because Bezos, of
[02:13:36.440 --> 02:13:39.040]   course, personally bought the Washington Post.
[02:13:39.040 --> 02:13:41.280]   Benioff is personally buying Time Magazine.
[02:13:41.280 --> 02:13:46.560]   He and his wife together have decided to become moguls and I think that's great, actually.
[02:13:46.560 --> 02:13:49.320]   I think distressed media properties are the new black.
[02:13:49.320 --> 02:13:52.200]   Yeah, well, look, I mean, you named the price.
[02:13:52.200 --> 02:13:55.560]   This was purchased in 2017 for like 2.something billion.
[02:13:55.560 --> 02:13:56.560]   Yeah.
[02:13:56.560 --> 02:14:01.640]   I remember when Meredith bought a bunch of the flagship, you know, Time Warner stuff,
[02:14:01.640 --> 02:14:04.960]   including Time Magazine, $2.8 billion.
[02:14:04.960 --> 02:14:06.160]   But that was just one of the titles.
[02:14:06.160 --> 02:14:07.760]   I think there was other stuff there.
[02:14:07.760 --> 02:14:09.920]   There's sports illustrated, there's fortune and money.
[02:14:09.920 --> 02:14:12.440]   Apparently, Meredith says this was a bad investment.
[02:14:12.440 --> 02:14:14.760]   Nobody's buying magazines.
[02:14:14.760 --> 02:14:15.760]   Duh.
[02:14:15.760 --> 02:14:17.200]   Well, Mark Benioff is.
[02:14:17.200 --> 02:14:19.400]   Time Magazine was the original internet.
[02:14:19.400 --> 02:14:24.480]   I mean, the original Time Magazine just had like little tiny blurbs of everything he
[02:14:24.480 --> 02:14:25.720]   missed last week.
[02:14:25.720 --> 02:14:28.280]   Well, years ago, you're too young to remember this.
[02:14:28.280 --> 02:14:29.280]   Maybe Mike does.
[02:14:29.280 --> 02:14:33.640]   But when I was a kid, you either got time or Newsweek.
[02:14:33.640 --> 02:14:36.560]   Newsweek was a little bit more left leaning.
[02:14:36.560 --> 02:14:43.400]   Time had a really a singularly bad journalistic habit of writing everything as if it was first
[02:14:43.400 --> 02:14:45.680]   person happening right now.
[02:14:45.680 --> 02:14:46.680]   Like you were in the room.
[02:14:46.680 --> 02:14:48.360]   It was fly on the wall journalism.
[02:14:48.360 --> 02:14:52.320]   And it was terrible because the impression you got was, oh, they must have been there.
[02:14:52.320 --> 02:14:54.000]   But no, that was just a style.
[02:14:54.000 --> 02:14:55.000]   Yeah.
[02:14:55.000 --> 02:14:57.000]   Work for Newsweek.
[02:14:57.000 --> 02:14:59.040]   Newsweek's a really sad story.
[02:14:59.040 --> 02:15:00.480]   In the, no kidding.
[02:15:00.480 --> 02:15:04.280]   I was at Newsweek and what I like to call the way before time.
[02:15:04.280 --> 02:15:07.080]   But, uh, well, we were a Newsweek family.
[02:15:07.080 --> 02:15:08.520]   You'll be glad to know.
[02:15:08.520 --> 02:15:14.440]   Farhad was my, that's when Farhad was, or not Farhad when my brain is just totally
[02:15:14.440 --> 02:15:15.440]   messed up tonight.
[02:15:15.440 --> 02:15:17.960]   You got your, you're, she's high on lots of balls soup.
[02:15:17.960 --> 02:15:19.520]   I am high on a suit of it.
[02:15:19.520 --> 02:15:22.360]   I've got my annual cold at any rate.
[02:15:22.360 --> 02:15:24.520]   Who is Newsweek now?
[02:15:24.520 --> 02:15:27.320]   Some terrible Chinese company, right?
[02:15:27.320 --> 02:15:28.560]   I B C. Yeah.
[02:15:28.560 --> 02:15:29.560]   Yeah.
[02:15:29.560 --> 02:15:30.560]   They're not.
[02:15:30.560 --> 02:15:31.560]   It's a religious.
[02:15:31.560 --> 02:15:32.560]   It's a religious.
[02:15:32.560 --> 02:15:33.560]   I don't know.
[02:15:33.560 --> 02:15:34.560]   Is it, is it that religious group?
[02:15:34.560 --> 02:15:35.560]   Yeah.
[02:15:35.560 --> 02:15:39.200]   Washington Post sold it to Sydney Harmon of Harmon Park for a dollar.
[02:15:39.200 --> 02:15:40.200]   But that happened.
[02:15:40.200 --> 02:15:41.200]   Right.
[02:15:41.200 --> 02:15:47.480]   And then it merged with the Daily Beast forming the Newsweek Daily Beast Company, which even
[02:15:47.480 --> 02:15:50.840]   a futurist really couldn't predict that that would be the name of the company.
[02:15:50.840 --> 02:15:53.120]   The Daily News Beast would have been a better name.
[02:15:53.120 --> 02:15:54.640]   That was Tina Brown.
[02:15:54.640 --> 02:15:56.480]   Tina Brown, that's exactly right.
[02:15:56.480 --> 02:15:58.920]   It just, it, it's just spiraled.
[02:15:58.920 --> 02:16:02.920]   It's now owned by IBT Media, which uses it basically as a.
[02:16:02.920 --> 02:16:03.920]   Right.
[02:16:03.920 --> 02:16:04.920]   It's a.
[02:16:04.920 --> 02:16:06.560]   It's own personal company.
[02:16:06.560 --> 02:16:07.560]   Yeah.
[02:16:07.560 --> 02:16:13.200]   No, in fact, in fact, if you remember when Newsweek relaunched in print, their cover story.
[02:16:13.200 --> 02:16:15.200]   Well, we do remember Satoshi.
[02:16:15.200 --> 02:16:17.200]   Yeah, we found him.
[02:16:17.200 --> 02:16:21.920]   And I, I read that interview and I'm a fluent Japanese speaker.
[02:16:21.920 --> 02:16:27.040]   And like the way that that, if he was speaking English, no Japanese speaks English in the
[02:16:27.040 --> 02:16:28.520]   way that that person is quoted.
[02:16:28.520 --> 02:16:30.680]   Oh, that's interesting.
[02:16:30.680 --> 02:16:31.680]   The whole thing was a.
[02:16:31.680 --> 02:16:32.680]   They never did.
[02:16:32.680 --> 02:16:36.320]   Did they ever say, oh, no, that was wrong.
[02:16:36.320 --> 02:16:40.320]   Because they claimed that some poor Japanese guy in LA names.
[02:16:40.320 --> 02:16:42.480]   Yeah, they just heard this guy's life.
[02:16:42.480 --> 02:16:43.480]   Yeah.
[02:16:43.480 --> 02:16:45.160]   I mean, was the creator of Bitcoin and it was wrong.
[02:16:45.160 --> 02:16:48.320]   I mean, it was, it was, it was wrong.
[02:16:48.320 --> 02:16:49.920]   The minute you read the article, you knew.
[02:16:49.920 --> 02:16:51.520]   Oh, this is completely wrong.
[02:16:51.520 --> 02:16:55.600]   Did they ever apologize or retract it or anything?
[02:16:55.600 --> 02:16:58.000]   And what does it matter now if you retract something?
[02:16:58.000 --> 02:16:59.000]   It's already out there.
[02:16:59.000 --> 02:17:00.360]   You know what I mean?
[02:17:00.360 --> 02:17:01.840]   Anyway, I don't know.
[02:17:01.840 --> 02:17:07.680]   I honestly don't know if Mark Benioff and his wife will be good stewards of Time Magazine.
[02:17:07.680 --> 02:17:11.840]   Somehow I doubt it.
[02:17:11.840 --> 02:17:16.800]   Hopefully they invest in it and then do what Bezos did, which is yeah, give the editorial
[02:17:16.800 --> 02:17:18.320]   freedom, put money into it.
[02:17:18.320 --> 02:17:20.320]   Because frankly, it looks like these businesses are money.
[02:17:20.320 --> 02:17:22.480]   Time Magazine right now is just awful.
[02:17:22.480 --> 02:17:24.920]   It's just a terrible publication.
[02:17:24.920 --> 02:17:25.920]   Yeah.
[02:17:25.920 --> 02:17:32.320]   Hopefully they give them runway and they give them engineers and they don't insist on.
[02:17:32.320 --> 02:17:36.800]   And the problem with somebody from outside of news, you know, it's a double edged sword.
[02:17:36.800 --> 02:17:40.760]   You kind of need somebody from the outside with a radically different business model
[02:17:40.760 --> 02:17:44.800]   to, you know, run the publication.
[02:17:44.800 --> 02:17:48.320]   But you also, because that's the current business models don't work.
[02:17:48.320 --> 02:17:54.600]   On the other hand, if you don't grok news, like what it costs to produce news and what
[02:17:54.600 --> 02:17:59.120]   the, you know, you wind up with problems.
[02:17:59.120 --> 02:18:00.920]   You also need respect for journalism.
[02:18:00.920 --> 02:18:01.920]   Yeah.
[02:18:01.920 --> 02:18:04.680]   Which is very old school.
[02:18:04.680 --> 02:18:06.560]   But I think without that, you've got nothing.
[02:18:06.560 --> 02:18:09.800]   And it looks like that's exactly, you kind of nailed what Bezos did.
[02:18:09.800 --> 02:18:12.000]   He gave them the technological wear with all of them.
[02:18:12.000 --> 02:18:13.000]   That's right.
[02:18:13.000 --> 02:18:15.120]   And the editorial, right, continue.
[02:18:15.120 --> 02:18:16.120]   That's right.
[02:18:16.120 --> 02:18:17.120]   And the post is killing it.
[02:18:17.120 --> 02:18:18.120]   He hired Marty Barron away.
[02:18:18.120 --> 02:18:19.120]   I mean, the post is like.
[02:18:19.120 --> 02:18:20.120]   Yeah, Marty Barron, good example.
[02:18:20.120 --> 02:18:21.120]   Yeah.
[02:18:21.120 --> 02:18:24.480]   The post is killing it, but there, there's a pretty, you know, church and state.
[02:18:24.480 --> 02:18:25.480]   There's a big wall.
[02:18:25.480 --> 02:18:28.360]   Who came up with democracy dies in darkness?
[02:18:28.360 --> 02:18:30.360]   Because that's the worst slogan.
[02:18:30.360 --> 02:18:31.360]   Yeah.
[02:18:31.360 --> 02:18:32.360]   Yeah.
[02:18:32.360 --> 02:18:33.360]   Is that Marty?
[02:18:33.360 --> 02:18:34.360]   I hope it was a Marty.
[02:18:34.360 --> 02:18:35.360]   I know.
[02:18:35.360 --> 02:18:36.360]   I don't know if it was Marty himself.
[02:18:36.360 --> 02:18:38.840]   That was like a, yeah.
[02:18:38.840 --> 02:18:45.720]   Finally, we've said over and over that Equifax never paid for the breach.
[02:18:45.720 --> 02:18:47.520]   That they never, they got away with murder.
[02:18:47.520 --> 02:18:54.480]   Remember 140 million records, everybody's social, everything leaked to the bad guys and
[02:18:54.480 --> 02:18:58.480]   Equifax executives never suffered for that.
[02:18:58.480 --> 02:18:59.480]   There was no fine.
[02:18:59.480 --> 02:19:00.480]   There was no punishment.
[02:19:00.480 --> 02:19:01.880]   Well, there is now.
[02:19:01.880 --> 02:19:06.960]   I'm very happy to say public floggings, almost public floggings, a new federal law that was
[02:19:06.960 --> 02:19:11.720]   passed on Friday now allows you to freeze and unfreeze your credit in every state of
[02:19:11.720 --> 02:19:13.880]   the union for free.
[02:19:13.880 --> 02:19:15.400]   The price of this has varied.
[02:19:15.400 --> 02:19:20.600]   In some states, it was free, but in many states, it was as much as $12 per bureau.
[02:19:20.600 --> 02:19:21.600]   Time?
[02:19:21.600 --> 02:19:22.600]   Per freeze, yes.
[02:19:22.600 --> 02:19:23.600]   That's ridiculous.
[02:19:23.600 --> 02:19:24.600]   It was ridiculous.
[02:19:24.600 --> 02:19:25.680]   I didn't know that.
[02:19:25.680 --> 02:19:30.760]   So the federal law now says that you can freeze and unfreeze your credit without being charged.
[02:19:30.760 --> 02:19:36.600]   They also increased the length of a fraud alert, which is so credit freezes the most draconian
[02:19:36.600 --> 02:19:37.600]   thing you can do.
[02:19:37.600 --> 02:19:40.600]   You say, don't give anybody any credit information.
[02:19:40.600 --> 02:19:41.880]   This is the thing the credit bureau is.
[02:19:41.880 --> 02:19:42.880]   This is why it's a punishment.
[02:19:42.880 --> 02:19:46.880]   Hate because they can't make any money off of you because they're basically told no.
[02:19:46.880 --> 02:19:48.560]   No one can ask for my credit report.
[02:19:48.560 --> 02:19:49.800]   That's a credit freeze.
[02:19:49.800 --> 02:19:53.920]   A fraud alert is a little bit less severe.
[02:19:53.920 --> 02:19:57.560]   It tells lenders that your personal data might have been compromised and you should really
[02:19:57.560 --> 02:20:00.560]   verify identity was before approving credit.
[02:20:00.560 --> 02:20:02.160]   But those only lasted three days.
[02:20:02.160 --> 02:20:04.800]   Now they last a year thanks to this new law.
[02:20:04.800 --> 02:20:08.200]   So this is really good news.
[02:20:08.200 --> 02:20:13.640]   If you don't like these credit reporting agencies and you want to stick it to them or
[02:20:13.640 --> 02:20:17.960]   if you're concerned, you should investigate both fraud alerts and--
[02:20:17.960 --> 02:20:20.040]   Where does law come from?
[02:20:20.040 --> 02:20:21.040]   That's a really good question.
[02:20:21.040 --> 02:20:22.040]   I want to give--
[02:20:22.040 --> 02:20:23.880]   Where does the deserve a lot of credit?
[02:20:23.880 --> 02:20:24.880]   Yeah.
[02:20:24.880 --> 02:20:27.120]   And this is for Equifax, Experian and TransUnion.
[02:20:27.120 --> 02:20:28.560]   It's for all three.
[02:20:28.560 --> 02:20:32.720]   I have a USA Today article you should probably search for that came out a couple of days
[02:20:32.720 --> 02:20:33.720]   ago.
[02:20:33.720 --> 02:20:35.920]   And you can search freezing your credit is now free.
[02:20:35.920 --> 02:20:39.440]   Search for that because it has the links and the step by step on how to do this.
[02:20:39.440 --> 02:20:41.000]   You can do this online.
[02:20:41.000 --> 02:20:42.000]   And--
[02:20:42.000 --> 02:20:44.000]   And so they'll find some other way to screw us.
[02:20:44.000 --> 02:20:45.000]   I think this is the damage.
[02:20:45.000 --> 02:20:49.040]   I think there's a lot of money they were making from that-- the three companies were
[02:20:49.040 --> 02:20:55.640]   making per-- I wonder if that was a big line item in their budget of revenue from the freezing
[02:20:55.640 --> 02:20:56.640]   and unfreezing that we would have to have.
[02:20:56.640 --> 02:20:57.640]   Oh, yeah.
[02:20:57.640 --> 02:20:59.360]   I wonder how much this cuts into their bottom line.
[02:20:59.360 --> 02:21:02.080]   There were some states where the state law said no, you can't do.
[02:21:02.080 --> 02:21:03.080]   That's ridiculous.
[02:21:03.080 --> 02:21:07.400]   The states like California was a very expensive process that kept people essentially from
[02:21:07.400 --> 02:21:12.040]   doing it because if you wanted to buy a house or buy a car, you had to unfreeze it.
[02:21:12.040 --> 02:21:14.520]   They would charge you to do that and freeze it again.
[02:21:14.520 --> 02:21:15.640]   They would charge you to do that.
[02:21:15.640 --> 02:21:16.640]   Now it's free.
[02:21:16.640 --> 02:21:18.480]   And I don't know who passed that law.
[02:21:18.480 --> 02:21:20.000]   I don't even know what the law is.
[02:21:20.000 --> 02:21:22.760]   It's kind of a pain in the neck to freeze your credit though.
[02:21:22.760 --> 02:21:23.760]   I mean, it's--
[02:21:23.760 --> 02:21:26.200]   Well, it's easier than a used to be.
[02:21:26.200 --> 02:21:27.440]   It's easier than it used to be.
[02:21:27.440 --> 02:21:29.680]   You can actually go to these sites.
[02:21:29.680 --> 02:21:32.520]   You do have to type in your name, social, date of--
[02:21:32.520 --> 02:21:34.440]   It's pretty interesting that it's not frozen.
[02:21:34.440 --> 02:21:35.440]   It should be the other way around.
[02:21:35.440 --> 02:21:39.160]   It should be frozen until we need to unfreeze it for something specific.
[02:21:39.160 --> 02:21:43.760]   Well, except for the fact that the only reason that experienced Equifax and trans-unia exist
[02:21:43.760 --> 02:21:45.000]   is to sell that data.
[02:21:45.000 --> 02:21:46.000]   Yeah.
[02:21:46.000 --> 02:21:47.880]   That's how they make a living.
[02:21:47.880 --> 02:21:52.600]   So the credit freezes-- that's why I call this a punishment.
[02:21:52.600 --> 02:21:54.080]   And it's not just a punishment.
[02:21:54.080 --> 02:21:57.920]   Equifax is a punishment to all the credit bureaus because really, this is saying no,
[02:21:57.920 --> 02:21:58.920]   you can't--
[02:21:58.920 --> 02:21:59.920]   Well, something had to be done.
[02:21:59.920 --> 02:22:00.920]   You can't profit off my data.
[02:22:00.920 --> 02:22:01.920]   Right.
[02:22:01.920 --> 02:22:02.920]   Yeah.
[02:22:02.920 --> 02:22:06.920]   Yeah, you should learn the differences if you're going to take advantage of this, folks,
[02:22:06.920 --> 02:22:08.680]   between a freeze and a fraud alert.
[02:22:08.680 --> 02:22:11.000]   They may not be appropriate for everybody in every situation.
[02:22:11.000 --> 02:22:14.120]   If you're a young person and you're applying for credit cards and buying cars and buying
[02:22:14.120 --> 02:22:16.360]   houses, a credit freeze is a bad idea.
[02:22:16.360 --> 02:22:20.400]   Somebody like me who no longer does any of that.
[02:22:20.400 --> 02:22:25.440]   We should call for there to be-- so Facebook frees our personal data.
[02:22:25.440 --> 02:22:26.840]   Well, you know, in a similar way.
[02:22:26.840 --> 02:22:27.840]   That's what I do.
[02:22:27.840 --> 02:22:28.840]   I like that idea.
[02:22:28.840 --> 02:22:29.840]   That's called deactivating your Facebook.
[02:22:29.840 --> 02:22:30.840]   Oh, deactivating.
[02:22:30.840 --> 02:22:35.200]   And actually, what I did is my calendar, I have set it so that-- because at Twitter,
[02:22:35.200 --> 02:22:41.960]   you have to reactivate in a year or they'll-- so I'm on my birthday every year.
[02:22:41.960 --> 02:22:43.720]   I'm going to react-- or no, maybe Christmas.
[02:22:43.720 --> 02:22:44.720]   I'll make a Christmas.
[02:22:44.720 --> 02:22:50.080]   On Christmas every year, I'm going to reactivate all three accounts for a week.
[02:22:50.080 --> 02:22:52.400]   Then deactivate them again.
[02:22:52.400 --> 02:22:54.440]   And then my account will never go away.
[02:22:54.440 --> 02:22:58.040]   My name will be protected.
[02:22:58.040 --> 02:22:59.040]   That's like a credit freeze.
[02:22:59.040 --> 02:23:00.040]   Give yourself a Christmas, President.
[02:23:00.040 --> 02:23:01.040]   That's a Facebook freeze.
[02:23:01.040 --> 02:23:02.040]   Yeah.
[02:23:02.040 --> 02:23:04.960]   There's better than freeze your head.
[02:23:04.960 --> 02:23:07.320]   That to me, those are the stories that I wanted to say.
[02:23:07.320 --> 02:23:10.960]   I am so glad you guys were here though to fill me in on what really happened in technology.
[02:23:10.960 --> 02:23:19.320]   Amy Webb is a futurist from the Future Today Institute at futuretodayinstitute.com or amewept.io.
[02:23:19.320 --> 02:23:23.440]   If you want to go to her personal website, check out her books.
[02:23:23.440 --> 02:23:31.560]   She is always very welcome and always insightful and smart.
[02:23:31.560 --> 02:23:33.360]   I'm really glad you were here.
[02:23:33.360 --> 02:23:36.120]   You didn't really have to put your Harvard diploma up on the wall behind you though.
[02:23:36.120 --> 02:23:37.120]   I just want to say--
[02:23:37.120 --> 02:23:38.120]   Oh, this is my home office.
[02:23:38.120 --> 02:23:39.120]   It's a hologram.
[02:23:39.120 --> 02:23:40.120]   We know you're smart.
[02:23:40.120 --> 02:23:41.120]   It's a hologram, yeah.
[02:23:41.120 --> 02:23:42.120]   I'm a hologram.
[02:23:42.120 --> 02:23:47.000]   I'm just jealous because I got nothing like that to put on my-- I got my high school diploma.
[02:23:47.000 --> 02:23:48.840]   Can I put that on?
[02:23:48.840 --> 02:23:50.080]   Santa Cruz High, man.
[02:23:50.080 --> 02:23:51.080]   There's an institution.
[02:23:51.080 --> 02:23:52.080]   You got a Santa Cruz High.
[02:23:52.080 --> 02:23:53.080]   I did.
[02:23:53.080 --> 02:23:55.880]   I even graduated from Santa Cruz High.
[02:23:55.880 --> 02:23:57.360]   Somewhere, I got one of those.
[02:23:57.360 --> 02:23:59.360]   Heard of people being high in Santa Cruz, but not Santa Cruz.
[02:23:59.360 --> 02:24:01.960]   Yeah, no, we were.
[02:24:01.960 --> 02:24:04.880]   Just like Joe Rogan and Neil on Musk.
[02:24:04.880 --> 02:24:07.520]   Mike Elgin, he is a Gastronomad.
[02:24:07.520 --> 02:24:10.520]   And go to Elgin.com to subscribe to his newsletter.
[02:24:10.520 --> 02:24:11.520]   Please do.
[02:24:11.520 --> 02:24:12.520]   Mike Schlis is great.
[02:24:12.520 --> 02:24:14.760]   A weekly read that is must.
[02:24:14.760 --> 02:24:18.440]   That's the best way to keep up on all the cool stuff that happened.
[02:24:18.440 --> 02:24:21.840]   And don't forget those Gastronomad trips.
[02:24:21.840 --> 02:24:22.840]   Join us.
[02:24:22.840 --> 02:24:23.840]   He sounds amazing.
[02:24:23.840 --> 02:24:25.840]   Don't they sound great?
[02:24:25.840 --> 02:24:26.840]   Yeah, they sound really great.
[02:24:26.840 --> 02:24:27.840]   You should join us, Amy.
[02:24:27.840 --> 02:24:28.840]   You and your husband.
[02:24:28.840 --> 02:24:30.480]   He's in the eyeball business.
[02:24:30.480 --> 02:24:31.480]   You know, he's got--
[02:24:31.480 --> 02:24:32.480]   We'll do it virtually.
[02:24:32.480 --> 02:24:33.480]   Yeah, there you go.
[02:24:33.480 --> 02:24:35.840]   It's just a matter of time.
[02:24:35.840 --> 02:24:39.720]   Now see, that's faux intimacy, right?
[02:24:39.720 --> 02:24:42.040]   I think I'm in Prosecco, but really--
[02:24:42.040 --> 02:24:43.840]   And the Prosecco doesn't quite taste that.
[02:24:43.840 --> 02:24:45.960]   I'm literally in the Prosecco.
[02:24:45.960 --> 02:24:46.960]   Yes, right.
[02:24:46.960 --> 02:24:47.960]   Swimming.
[02:24:47.960 --> 02:24:51.280]   With digital fish and little robots.
[02:24:51.280 --> 02:24:54.120]   So Santa Cruz High is that where Jeff Spakoli went?
[02:24:54.120 --> 02:24:56.040]   Yeah, fast times at Santa Cruz High.
[02:24:56.040 --> 02:24:57.600]   You saw the movie.
[02:24:57.600 --> 02:24:59.600]   That was me.
[02:24:59.600 --> 02:25:03.400]   Hey, it's been great to come back and see you all.
[02:25:03.400 --> 02:25:06.440]   I promise not to leave for so long ever again.
[02:25:06.440 --> 02:25:08.640]   That was really too long.
[02:25:08.640 --> 02:25:09.640]   Was it?
[02:25:09.640 --> 02:25:10.640]   No, not really.
[02:25:10.640 --> 02:25:13.600]   No, it wasn't three weeks.
[02:25:13.600 --> 02:25:15.880]   That was the longest time I've ever taken off.
[02:25:15.880 --> 02:25:18.880]   It was almost a month.
[02:25:18.880 --> 02:25:23.480]   It was a long time to be gone from your fans who missed you.
[02:25:23.480 --> 02:25:24.520]   It's not so much that.
[02:25:24.520 --> 02:25:28.120]   [LAUGHTER]
[02:25:28.120 --> 02:25:29.200]   Anyway, no I do.
[02:25:29.200 --> 02:25:30.200]   I missed you all.
[02:25:30.200 --> 02:25:31.200]   Thank you for being here.
[02:25:31.200 --> 02:25:32.800]   We do Twitter every Sunday afternoon.
[02:25:32.800 --> 02:25:35.840]   And thanks also to Ian Thompson and Becky Warley who
[02:25:35.840 --> 02:25:36.920]   filled in for me.
[02:25:36.920 --> 02:25:37.760]   Who else am I missing?
[02:25:37.760 --> 02:25:38.360]   Jason?
[02:25:38.360 --> 02:25:38.880]   Jason.
[02:25:38.880 --> 02:25:39.080]   No.
[02:25:39.080 --> 02:25:39.680]   Jason Howell.
[02:25:39.680 --> 02:25:40.200]   Snell.
[02:25:40.200 --> 02:25:40.200]   Snell.
[02:25:40.200 --> 02:25:40.680]   Snell.
[02:25:40.680 --> 02:25:40.680]   That's right.
[02:25:40.680 --> 02:25:41.180]   Snell.
[02:25:41.180 --> 02:25:42.280]   Mark Snell.
[02:25:42.280 --> 02:25:43.800]   He did the first one.
[02:25:43.800 --> 02:25:45.640]   Thanks to them for filling in for me.
[02:25:45.640 --> 02:25:47.720]   I really appreciate that.
[02:25:47.720 --> 02:25:51.720]   I should also thank the guy who did the radio show.
[02:25:51.720 --> 02:25:52.220]   Rich.
[02:25:52.220 --> 02:25:52.720]   What's his name?
[02:25:52.720 --> 02:25:53.720]   Rich D'Miro.
[02:25:53.720 --> 02:25:56.640]   [LAUGHTER]
[02:25:56.640 --> 02:25:59.080]   He's on TV in Los Angeles.
[02:25:59.080 --> 02:26:00.280]   Rich D'Miro.
[02:26:00.280 --> 02:26:01.160]   Rich D'Miro.
[02:26:01.160 --> 02:26:03.080]   I don't know why I blank his name out.
[02:26:03.080 --> 02:26:04.840]   Probably because I'm worried.
[02:26:04.840 --> 02:26:05.360]   He's young.
[02:26:05.360 --> 02:26:05.960]   He's good looking.
[02:26:05.960 --> 02:26:07.040]   He's smarter than I am.
[02:26:07.040 --> 02:26:09.000]   It's like D'Niro with an M.
[02:26:09.000 --> 02:26:10.520]   Yeah, Rich D'Niro.
[02:26:10.520 --> 02:26:11.240]   That's his name.
[02:26:11.240 --> 02:26:11.800]   That's it?
[02:26:11.800 --> 02:26:12.720]   D'Niro.
[02:26:12.720 --> 02:26:14.200]   [LAUGHTER]
[02:26:14.200 --> 02:26:15.760]   They have a little punchy.
[02:26:15.760 --> 02:26:18.920]   Because it's like 4 in the morning in Barcelona.
[02:26:18.920 --> 02:26:21.360]   Thank you so much for being here.
[02:26:21.360 --> 02:26:23.480]   We do Twitter every Sunday afternoon, 3 p.m.
[02:26:23.480 --> 02:26:23.920]   Pacific.
[02:26:23.920 --> 02:26:25.240]   If you want to be in our studio audience,
[02:26:25.240 --> 02:26:26.720]   we had a great studio audience today.
[02:26:26.720 --> 02:26:27.480]   Thank you all for coming.
[02:26:27.480 --> 02:26:29.600]   Just email tickets@twit.tv.
[02:26:29.600 --> 02:26:32.160]   We'll put a chair out for you.
[02:26:32.160 --> 02:26:33.760]   And I'll add you to my postcard list.
[02:26:33.760 --> 02:26:36.720]   [LAUGHTER]
[02:26:36.720 --> 02:26:39.120]   You can get some postcards.
[02:26:39.120 --> 02:26:40.320]   Tickets@twit.tv.
[02:26:40.320 --> 02:26:44.400]   We also stream it live at Twit.tv/live.
[02:26:44.400 --> 02:26:45.280]   So you can watch there.
[02:26:45.280 --> 02:26:47.560]   3 p.m. Pacific, 6 p.m. Eastern.
[02:26:47.560 --> 02:26:51.160]   That's 2,200 UTC.
[02:26:51.160 --> 02:26:53.800]   If you can't watch live, you can't be here live.
[02:26:53.800 --> 02:26:57.920]   Well, I guess you could always watch or listen to our podcast,
[02:26:57.920 --> 02:27:01.760]   the on-demand version available at your convenience.
[02:27:01.760 --> 02:27:04.800]   Just go to twit.tv, our website for any of our shows,
[02:27:04.800 --> 02:27:07.920]   or subscribe in your favorite podcast program,
[02:27:07.920 --> 02:27:09.480]   because we're there.
[02:27:09.480 --> 02:27:12.200]   And that way you'll get it each week as soon as we're done.
[02:27:12.200 --> 02:27:13.520]   Thanks so much for joining us.
[02:27:13.520 --> 02:27:14.200]   We'll see you next time.
[02:27:14.200 --> 02:27:15.040]   Another Twit.
[02:27:15.040 --> 02:27:16.040]   This is the game.
[02:27:16.040 --> 02:27:17.040]   Easy.
[02:27:17.040 --> 02:27:19.840]   [MUSIC PLAYING]
[02:27:19.840 --> 02:27:21.840]   [MUSIC PLAYING]
[02:27:21.840 --> 02:27:24.740]   Do the tweet, baby. Do the tweet.
[02:27:24.740 --> 02:27:26.580]   Alright. Do the tweet.

