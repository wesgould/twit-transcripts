;FFMETADATA1
title=17 Years... 10,000 Mistakes
artist=Leo Laporte, Brian McCullough, Harry McCracken, Alex Lindsay
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2022-04-18
track=871
language=English
genre=Podcast
comment=Elon Musk, Bill Gates' Metaverse, Zuckerberg security detail
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:04.080]   It's time for Twith This Week in Tech. We got a great team here for you, Brian McCullough,
[00:00:04.080 --> 00:00:10.280]   from Tech meme, Ryan, right home podcast, the technologizer, Harry McCracken is here,
[00:00:10.280 --> 00:00:18.040]   and Alex Lindsey for Mac Break Weekly in office hours.global would celebrate 17 years of podcasting
[00:00:18.040 --> 00:00:22.920]   together, our 17th anniversary, and we're going to have a fun one. We could talk about
[00:00:22.920 --> 00:00:30.920]   Elon Musk, how Bill Gates kind of introduced AR and VR in the future in 1996, Mark Zuckerberg's
[00:00:30.920 --> 00:00:35.960]   huge security bill, and a whole lot more this week in Tech.
[00:00:35.960 --> 00:01:00.760]   This is next. This is Twith. This Week in Tech, Episode 871, recorded April 17, 2022, 17
[00:01:00.760 --> 00:01:08.840]   years, 10,000 mistakes. This Week in Tech is brought to you by Checkout.com. Modern businesses
[00:01:08.840 --> 00:01:15.120]   need flexible payment systems that can help them adapt to change, grow, and scale fast.
[00:01:15.120 --> 00:01:24.440]   Discover how Checkout.com can help your business thrive at checkout.com/twith. And by ZipRecruiter.
[00:01:24.440 --> 00:01:30.120]   According to research, 90% of employers plan to enhance their employee experiences here,
[00:01:30.120 --> 00:01:34.880]   and if you need to add more employees, there's ZipRecruiter. ZipRecruiter's technology finds
[00:01:34.880 --> 00:01:40.240]   qualified candidates for your job, and you can invite your top choices to apply. Try
[00:01:40.240 --> 00:01:50.760]   ZipRecruiter free today at zipprecruiter.com/twith. And by 8 sleep. Good sleep is the ultimate
[00:01:50.760 --> 00:01:57.960]   game changer, and nature's best medicine. Go to 8sleep.com/twith to check out the Pod
[00:01:57.960 --> 00:02:03.880]   Pro cover, and save $150 at checkout. 8 sleep currently ships within the US, Canada, and
[00:02:03.880 --> 00:02:11.760]   the UK. And by Blue Land. Stop wasting water and throwing out more plastic. Get Blue Land's
[00:02:11.760 --> 00:02:17.200]   revolutionary refill cleaning system instead. Right now you can get 20% off your first order
[00:02:17.200 --> 00:02:27.480]   when you go to blueland.com/twith.
[00:02:27.480 --> 00:02:33.000]   It's time for Twits. This week at Tech, the show we cover the week's Tech News. We have
[00:02:33.000 --> 00:02:40.600]   wrought Harry McCracken into the studio, braving danger to come in maskless. Good to see you,
[00:02:40.600 --> 00:02:45.040]   Aaron. Good to see you, Leo. Leading back. You forgot how uncomfortable his chairs are.
[00:02:45.040 --> 00:02:51.040]   Well, it's at this point, it's so good, uncomfortable. It's a good uncomfortable, just to be any way I know.
[00:02:51.040 --> 00:02:55.920]   It's so great to see you. Harry is a global technology editor at Fast Company, long-time
[00:02:55.920 --> 00:03:00.160]   technology designer. We were just thinking back, because this is today, technically, the
[00:03:00.160 --> 00:03:04.680]   17th anniversary of Twit. And we're thinking back to when you first appeared and we actually
[00:03:04.680 --> 00:03:11.080]   found it, it was 2008. It was 14 years ago. Almost 14 years ago.
[00:03:11.080 --> 00:03:17.480]   Your very first time I have 2008. Isn't that cool? Right after I left PC World. Yeah, actually
[00:03:17.480 --> 00:03:23.520]   you left PC World because they had taken down an article about not liking Apple or something
[00:03:23.520 --> 00:03:28.440]   like that. I left and I came back and I left again and that was at the point at which show.
[00:03:28.440 --> 00:03:36.480]   You were nice enough to ask me on. It was Twit 148. S-Porn, I don't know what the topic
[00:03:36.480 --> 00:03:43.400]   was, was you, John C. Devorek and Will Harris, and it was audio only. Wither Jerry Yang and
[00:03:43.400 --> 00:03:51.600]   Yahoo. 114 executives are left since 2007. I guess I was when Jerry Yang was back. Yeah,
[00:03:51.600 --> 00:03:57.840]   yeah. In fact, Devorek's leave Jerry alone, let him manage Yahoo. Microsoft without Gates,
[00:03:57.840 --> 00:04:02.680]   because Gates was retiring. Yeah. Or become chairman or whatever. I think he actually,
[00:04:02.680 --> 00:04:06.920]   2008, I think that was the one where they made the video of him packing up all his stuff
[00:04:06.920 --> 00:04:16.800]   and getting in his Buick to leave. Ice discovered on Mars. I wonder how that's worked out. Firefox
[00:04:16.800 --> 00:04:23.080]   was huge. Oh, that's Firefox 3. Tapped 8 million downloads in a day. Golden Age of Mozilla.
[00:04:23.080 --> 00:04:29.840]   And Nvidia released their hot new graphics card, the GTX 280. We're now at the 2080.
[00:04:29.840 --> 00:04:35.280]   So a thousand cards ago. You recommended Flock, which I really loved when I was around.
[00:04:35.280 --> 00:04:44.200]   Remember Flock? Flock? So we have a web browser. And WebKit and Fox Marks, Pickland's Handbrake.
[00:04:44.200 --> 00:04:50.960]   Handbrake's still around? Handbrake's still around, yeah, of the bunch. Wow. WebKit is
[00:04:50.960 --> 00:04:56.840]   still around. Yeah. It's been 17 years, 14 since your first appearance. Alex Lindsey,
[00:04:56.840 --> 00:05:01.160]   you probably go back even farther, I'm guessing. I think so. I think so. I think I got a little
[00:05:01.160 --> 00:05:05.160]   more than a million. And Office Hours. Global Alex and I started working together with Mac
[00:05:05.160 --> 00:05:10.720]   Brake. Well, with screen savers. I think that's what I mean. Yeah, I mean, call for help.
[00:05:10.720 --> 00:05:16.840]   Yeah, you were on tech TV in the day, but podcast. I think it was on Twitter before Mac Brake
[00:05:16.840 --> 00:05:21.560]   started. I think it was because we started doing the video ones. Remember those? The
[00:05:21.560 --> 00:05:24.160]   first one was a whole bunch of different cameras. And I told Leo that I could do it.
[00:05:24.160 --> 00:05:28.720]   I was like, we can do a multi-camera. I never done a multi-camera. So I shot them all at
[00:05:28.720 --> 00:05:40.040]   that at at Orleans. And I remember I am internally grateful to you because of you. We did a 3D
[00:05:40.040 --> 00:05:48.760]   remember the Ozo camera? Oh, yeah. Shoot of Mac Brake in 3D. And what I'm really happy
[00:05:48.760 --> 00:05:55.200]   about is that is the best record still around of the old Brickhouse studio. Because it really
[00:05:55.200 --> 00:05:59.920]   yes, if you look at it, if you watch the show, yeah, yeah, but you wouldn't. There you are.
[00:05:59.920 --> 00:06:05.880]   And we can we can we can see the whole studio, the operation and how things were working and
[00:06:05.880 --> 00:06:09.000]   have to admit, I forgot I even did that. You can even see what's going on in the street
[00:06:09.000 --> 00:06:15.240]   outside. Yeah. Thank you for doing that. There's Renee. It was a lot of phylics. Yeah. Andy,
[00:06:15.240 --> 00:06:20.360]   and you know what? That was episode five. We had a cake. The Ozo is a pretty good camera.
[00:06:20.360 --> 00:06:25.840]   It was fun. It was fun camera. No cake for today because it's only 17 and prime numbers
[00:06:25.840 --> 00:06:31.280]   do not deserve cakes. But I'm pretty special. But Ashley in our market department said,
[00:06:31.280 --> 00:06:36.240]   what are you going to do? I said, well, nothing. She says 17th. There's no podcasts are 17
[00:06:36.240 --> 00:06:42.680]   years old. Call me on my 20th when we get 20. 18 is fairly bad. 18 might be made. But
[00:06:42.680 --> 00:06:48.760]   this is all it was. If prime number you shouldn't do it. Also here with us relatively newcomer.
[00:06:48.760 --> 00:06:54.520]   He's been our show many times, but but he started late later than these two, Brian McCullough
[00:06:54.520 --> 00:07:00.680]   from Tech meme ride home. Probably my I've been coming on for four years now. So yes,
[00:07:00.680 --> 00:07:08.200]   I'm nothing a child. Complete new. It's hard to believe 17 years. So many great people have
[00:07:08.200 --> 00:07:14.720]   come and gone. Oh, here comes the imma memorial. But like a fish. Yeah, we should do that. I
[00:07:14.720 --> 00:07:21.960]   could sing a song. Let me say, try to remember that time and say I could just do the whole
[00:07:21.960 --> 00:07:27.720]   thing. But I'm not going to do that. I could do that. It's funny to look back though on
[00:07:27.720 --> 00:07:32.520]   these older shows on the stories that we were talking about. If in my wildest imagination,
[00:07:32.520 --> 00:07:36.360]   you know, Harry said, do you think in 2005 when you started to it, you'd think you'd
[00:07:36.360 --> 00:07:40.160]   be doing this? Maybe. But I never would have thought some guy named Elon Musk would have
[00:07:40.160 --> 00:07:47.080]   been trying to buy a thing called Twitter. But we're still a year off at that point.
[00:07:47.080 --> 00:07:52.560]   Twitter hadn't happened yet. Elon Musk was actually found a PayPal was his first right
[00:07:52.560 --> 00:07:59.560]   well, I found a 1999 profile of Elon from salon the other day, which is still a good read.
[00:07:59.560 --> 00:08:06.600]   Oh, and predicts that he will go on to do big things. And it was when he was doing X,
[00:08:06.600 --> 00:08:11.400]   which maybe merged with PayPal. He had another payment system that was there was. So it was
[00:08:11.400 --> 00:08:16.800]   even like pre PayPal. And his first Leo, his first startup was zip to zip.
[00:08:16.800 --> 00:08:25.880]   He was a big success at that point. And that was also a whole founded X. Then X there's
[00:08:25.880 --> 00:08:31.000]   there's a book that just came out a couple months ago that is all about the PayPal story,
[00:08:31.000 --> 00:08:37.280]   not even the PayPal mafia, but like just the story of PayPal. Because it you think Twitter's
[00:08:37.280 --> 00:08:40.980]   situation was crazy. You know, people were there were boardroom coups. There were all
[00:08:40.980 --> 00:08:46.240]   sorts of shenanigans going on. Here is the article from 1999 and salon. It's still online.
[00:08:46.240 --> 00:08:52.040]   Elon Musk is poised to become Silicon Valley's next big thing. Oh, they had no idea. Did they
[00:08:52.040 --> 00:08:58.400]   what put him in the driver's seat driver's seat get it pre Tesla. Yeah, it's pre Tesla.
[00:08:58.400 --> 00:09:04.560]   He didn't start Tesla, by the way, bought Tesla. He was a advisor and investor. Yeah.
[00:09:04.560 --> 00:09:10.680]   X dot com. So let's see. Musk who is 28 at the time of this article was driving a McLaren
[00:09:10.680 --> 00:09:18.520]   F1 because he'd sold his one internet company, zip to a creator of online city guides. Compaq
[00:09:18.520 --> 00:09:28.760]   bought it. Compaq. For 307 million in cash. He and his brother Kimball held about 12% of
[00:09:28.760 --> 00:09:33.720]   the company and made out with tens of millions. Now he's starting salon says X dot com, which
[00:09:33.720 --> 00:09:38.640]   may be the hottest company in Silicon Valley you've never heard of and probably still haven't
[00:09:38.640 --> 00:09:43.960]   ever heard of. So funny, there's no way you can predict any of this stuff. There's no
[00:09:43.960 --> 00:09:50.160]   way, although hey, at least salon was and Mark Gimmeon or Gimmeon who wrote this was
[00:09:50.160 --> 00:09:54.840]   savvy enough to know Elon had a good future ahead of him. The author can certainly take
[00:09:54.840 --> 00:10:01.560]   some credit for identifying him as an intriguing person. Yeah. And he was right. Now Elon is
[00:10:01.560 --> 00:10:05.920]   doing, I don't know why I think honestly, I'm curious what you guys think. This sounds
[00:10:05.920 --> 00:10:10.720]   like a classic pump and dump scam to me. So you know the timeline we've been talking
[00:10:10.720 --> 00:10:14.840]   about it for a couple of weeks, Elon secretly over the first three months of the year, buying
[00:10:14.840 --> 00:10:19.680]   up bits of Twitter, finally coming out and saying I have a controlling interest by the
[00:10:19.680 --> 00:10:25.160]   way, weeks after he was supposed to violation number one. He hid the fact that he was buying
[00:10:25.160 --> 00:10:29.560]   it up even after he crossed the 5% threshold. There is already a shareholder lawsuit over
[00:10:29.560 --> 00:10:34.480]   that because since he didn't announce it, he could continue to buy it up at lower prices.
[00:10:34.480 --> 00:10:40.240]   He finally does announce it. He has 9.2% about $3 billion investment in Twitter. The stock
[00:10:40.240 --> 00:10:44.720]   price goes up 27% on the announcement. Now that would have been a good time to sell,
[00:10:44.720 --> 00:10:50.520]   make a cool billion, but no, no, he gets offered a board seat. We don't know if he turned it
[00:10:50.520 --> 00:10:53.720]   down. This was last week. Did he turn it down? Did they decide not to give him the board
[00:10:53.720 --> 00:10:59.160]   seat? My thinking was at the time, this is, this is Twitter saying, be on the board, then
[00:10:59.160 --> 00:11:04.440]   you can only have 15% we're safe. You can't do a hostile takeover. If you're on the board,
[00:11:04.440 --> 00:11:10.880]   I think Elon said, "Yeah, thanks." But no, thanks. After all sorts of ridiculous tweets,
[00:11:10.880 --> 00:11:17.480]   which he has since deleted, including proposing that they rename Twitter, "Titter." That's
[00:11:17.480 --> 00:11:27.080]   funny, Elon. Then announces this week $43 billion, I want the whole thing. An unsolicited bid,
[00:11:27.080 --> 00:11:33.400]   i.e. hostile takeover. But what's interesting, I think he thought at that time offering $54
[00:11:33.400 --> 00:11:38.680]   a share, which is about $6 more than it was going for, that he probably thought, "Oh,
[00:11:38.680 --> 00:11:41.760]   this will boost it up a little more than I can sell it all." See, that's my theory.
[00:11:41.760 --> 00:11:47.400]   What do you think, Harry? I mean, it's Elon Musk's source, "Hurt to know." It's interesting
[00:11:47.400 --> 00:11:51.080]   that so many people are so confident they know what he's thinking or know what Twitter
[00:11:51.080 --> 00:11:56.080]   would be like. I don't. If he took charge, some people think it would be fantastic for
[00:11:56.080 --> 00:11:59.720]   him to take over. I think it would be the end of a democracy. I don't think it would
[00:11:59.720 --> 00:12:04.960]   be that bad. Well, somebody said that. Or maybe not the end of democracy, but destructive
[00:12:04.960 --> 00:12:10.640]   to democracy. I think it's just really hard to say. My instinct, which might or might not
[00:12:10.640 --> 00:12:15.400]   be right, is that he is just sort of yanking their chain and it's fun to make it work.
[00:12:15.400 --> 00:12:19.280]   We know that. At least that. There was this brief moment where they said he's going to
[00:12:19.280 --> 00:12:22.960]   be on the board and that's wonderful. He leads with his heart. We're going to do great things
[00:12:22.960 --> 00:12:27.360]   together. That collapsed. He was supposed to do an AMA with the Twitter
[00:12:27.360 --> 00:12:33.520]   staff that was some at least concerned about his ownership and then that got canceled.
[00:12:33.520 --> 00:12:36.760]   Now they had an AMA with the Twitter staff explaining what they're going to do about
[00:12:36.760 --> 00:12:41.280]   Elon Musk. I mean, Ray, he can't live. Either he is finding a key to the chain or he takes
[00:12:41.280 --> 00:12:47.600]   control. Brian, you're going to say something. I cut you off. What do you think?
[00:12:47.600 --> 00:12:54.160]   Well, here in New York, I'm friendly with finance and Wall Street world folks. They've
[00:12:54.160 --> 00:13:00.560]   been taking it not very seriously until the rumors that various private equity folks were
[00:13:00.560 --> 00:13:04.680]   going to get together to help them with this bid. There's still extremely skeptical of
[00:13:04.680 --> 00:13:11.960]   it for the deal actually happening because one thing we haven't talked about is billionaires
[00:13:11.960 --> 00:13:17.000]   have most of their money tied up in the stock that makes them billionaires. He would have
[00:13:17.000 --> 00:13:22.400]   to sell a huge, I think it's like a fifth of his Tesla stock if he wanted to buy it
[00:13:22.400 --> 00:13:31.200]   all himself and that's not going to help Tesla. Number two, if he were to get say a private
[00:13:31.200 --> 00:13:38.080]   equity firm to go cowboy with him and let's do this, they're going to want him to transform
[00:13:38.080 --> 00:13:43.400]   the business. They're not going to want to do necessarily what he seems to want to do,
[00:13:43.400 --> 00:13:50.440]   which is mess with all of Twitter's operations and rules. He's talking about free speech
[00:13:50.440 --> 00:13:56.320]   and all these things. The reason that the people on Wall Street that I've talked to remain skeptical
[00:13:56.320 --> 00:14:02.000]   for the most part is that they don't think that anybody with enough money or reputable
[00:14:02.000 --> 00:14:07.920]   enough will sign off on this because they won't believe that Elon will make it a better
[00:14:07.920 --> 00:14:13.360]   business. He might make Twitter into the Twitter he wants it to be, but they're going to want
[00:14:13.360 --> 00:14:18.400]   him to four or five X Twitter and I don't know that no one could do that. I don't know
[00:14:18.400 --> 00:14:24.120]   that anyone can do that and I especially think that no one believes that Elon would do that.
[00:14:24.120 --> 00:14:28.400]   Well, and we know that if you look at the stock market because if you offer six bucks
[00:14:28.400 --> 00:14:32.960]   above the current going rate of a stock, that would normally increase the value of the stock.
[00:14:32.960 --> 00:14:37.200]   The fact that the stock market didn't do anything tells you that as a whole, the stock market
[00:14:37.200 --> 00:14:43.800]   said, "Yeah, he's not going to pull this off." That's the stock market saying.
[00:14:43.800 --> 00:14:47.360]   The real thing that the finance people have told me is that this puts Twitter in play.
[00:14:47.360 --> 00:14:51.440]   That's the bigger issue. That's the bigger issue. Yeah, Twitter's been in play before
[00:14:51.440 --> 00:14:55.640]   Bill Gross tried to buy it some years ago, I remember.
[00:14:55.640 --> 00:15:00.040]   I just don't think it'd be hard to consider buying it. Yeah.
[00:15:00.040 --> 00:15:05.160]   I think it'd just be hard to move the needle. I think that's the issue of its value. I think
[00:15:05.160 --> 00:15:09.440]   Twitter, all of these social networks are kind of, they're a little long in the tooth.
[00:15:09.440 --> 00:15:13.080]   They were really cool ideas when they started, but that's 15 years ago. There's a lot of
[00:15:13.080 --> 00:15:19.960]   technical debt, a lot of established mentalities. I think that they're big. Hard to move, hard
[00:15:19.960 --> 00:15:25.000]   to turn. They have a big ship now. I think that it would be very difficult to make a
[00:15:25.000 --> 00:15:29.720]   dramatic change in the financial future of Twitter. It is what it is.
[00:15:29.720 --> 00:15:34.320]   Even Elon and Ted talk, or Ted interview with Chris Anderson this week, said, "I don't
[00:15:34.320 --> 00:15:40.760]   know if I can do this." Right. Then of course, it puts Twitter in play.
[00:15:40.760 --> 00:15:45.560]   Now they're thinking maybe Oracle, Larry Ellison, and others might step in and try to acquire
[00:15:45.560 --> 00:15:49.960]   another hostile takeover. And of course, Twitter, Twitter board has adopted what they
[00:15:49.960 --> 00:15:55.800]   call a poison pill strategy. I'll let you describe that, Brian.
[00:15:55.800 --> 00:16:02.120]   Essentially, you make it really, really expensive to continue the buyout. Let me give you one
[00:16:02.120 --> 00:16:08.320]   more conspiracy theory that I've heard because it sort of lines up with the tick-tock of
[00:16:08.320 --> 00:16:15.200]   how this has happened. Elon is still technically, remember when he did the 420 thing? There's
[00:16:15.200 --> 00:16:20.080]   all sorts of things with the SEC. Yeah, he got fined $20 million. Tesla got fined $20
[00:16:20.080 --> 00:16:23.760]   million with the SEC. Still wide open. It's not resolved yet.
[00:16:23.760 --> 00:16:28.200]   No, he's now saying, "I'm not going to adhere to the agreement." It was wrong. I'm going
[00:16:28.200 --> 00:16:33.440]   to try to get that overturned. The way one of the things he agreed to is have a lawyer
[00:16:33.440 --> 00:16:38.720]   vet every one of his tweets, which he obviously has not been doing.
[00:16:38.720 --> 00:16:42.560]   This is the theory that really what he wants to do is get out from under the thumb of this,
[00:16:42.560 --> 00:16:46.880]   of the lawyers, of the SEC. He wants to be able to say whatever he wants and not have
[00:16:46.880 --> 00:16:52.320]   to worry about there being any repercussions. So, okay, I'll become Twitter's biggest shareholder
[00:16:52.320 --> 00:16:57.280]   and then maybe no one can tell me what I can and can't tweet. Okay, I'll go on the board.
[00:16:57.280 --> 00:17:00.760]   If I'm a board member, no one can tell me what I can and can't tweet. And every step
[00:17:00.760 --> 00:17:06.280]   of the way he's found out, "Oh, no, but the SEC is still going to come for you. Oh, no,
[00:17:06.280 --> 00:17:11.080]   the lawyers. In fact, if you're on the board, the lawyers are going to be worse." So, I
[00:17:11.080 --> 00:17:15.640]   don't know that this is an Occam's razor theory, but it does sort of make it line up with the
[00:17:15.640 --> 00:17:21.040]   timeline of how this has happened. He just wants the freedom. And again, that gets into
[00:17:21.040 --> 00:17:24.600]   what I'm saying about it. He doesn't necessarily want to make it a better business. He just
[00:17:24.600 --> 00:17:29.840]   wants the freedom. Like Matt Levine says, the thing that's keeping him from the freedom
[00:17:29.840 --> 00:17:35.440]   is not Twitter. It's SEC. Right. Which would I think would have a different... I don't
[00:17:35.440 --> 00:17:38.240]   know what the rules are specifically, but I believe the SEC would have less leverage
[00:17:38.240 --> 00:17:43.480]   if it was a private company, privately held company. Ah, no, because I guarantee you not,
[00:17:43.480 --> 00:17:48.600]   because he's making tweets about a publicly held company. So, it doesn't matter what the
[00:17:48.600 --> 00:17:55.560]   platform is that you announce fallaciously that you're going to buy this stock, take
[00:17:55.560 --> 00:18:01.000]   this company private for 420 bucks. If you announce it in public and then make money
[00:18:01.000 --> 00:18:06.040]   on it, that is pumping dump and that is illegal and the SEC find him. By the way, somebody
[00:18:06.040 --> 00:18:11.640]   did the math. If Elon Musk's net worth is $270 billion, that's the estimate according
[00:18:11.640 --> 00:18:18.400]   to Forbes. And the median net worth for an American is $110,000. That 20 million find
[00:18:18.400 --> 00:18:24.520]   the Elon is equivalent of a small fry at McDonald's to the rest of us. In other words, I don't
[00:18:24.520 --> 00:18:28.440]   even think he cares. He's much more concerned. I think you're right, Brian, about being
[00:18:28.440 --> 00:18:31.680]   told what to say than he's about the money. I think he wants the lawyers off his back.
[00:18:31.680 --> 00:18:36.840]   Yeah. Let's get out of my life. Matt Levine's... Go away. What did Matt Levine say? And then
[00:18:36.840 --> 00:18:39.560]   go ahead and go ahead and go ahead. His overarching theory is that you're the richest
[00:18:39.560 --> 00:18:44.480]   person in the world. You play a game that's your favorite game to play. And so, you want
[00:18:44.480 --> 00:18:47.920]   the rules to be... You want the game to run the way that you want to run it. And you wake
[00:18:47.920 --> 00:18:51.440]   up one day and you realize, "Hey, I'm the richest man in the world, so why don't I just
[00:18:51.440 --> 00:18:55.680]   buy the game and change the rules to suit me?" And that's... Because you're the richest
[00:18:55.680 --> 00:18:59.360]   man in the world, that's way too much work. You still got SpaceX and Tesla and other things.
[00:18:59.360 --> 00:19:03.320]   The boring company. You got flame-fowers to sell. Who ain't got... You don't have time
[00:19:03.320 --> 00:19:10.160]   for Twitter. I think this is totally Elon, just typical trolling, right? Go ahead, Alex.
[00:19:10.160 --> 00:19:13.840]   It might be, but I think that he may actually think that Twitter's broken. Like, I think
[00:19:13.840 --> 00:19:16.960]   that maybe it's connected to the fact that he can't do what he wants. But what does he
[00:19:16.960 --> 00:19:23.120]   say? Oh, because Twitter is influential. It's an influential platform. He does use it.
[00:19:23.120 --> 00:19:28.360]   And he may decide... He may have a bigger picture of this of this is really a broken
[00:19:28.360 --> 00:19:32.840]   system that needs to be fixed. And he thinks he might be able to be the one that fixes
[00:19:32.840 --> 00:19:35.920]   it. And he's particularly aware of it because of what he's been told what he can and can't
[00:19:35.920 --> 00:19:40.960]   do. But I don't know if it's as simple as he wants to say what he wants to say and closer
[00:19:40.960 --> 00:19:45.320]   to... I'm being affected by this, but a lot of other people are being affected by it.
[00:19:45.320 --> 00:19:51.720]   And it needs to be adjusted. And I can do that. He's still arrogant. He's still arrogant.
[00:19:51.720 --> 00:19:57.680]   But is that what it's there? He's a libertarian. He thinks more free speech is better. I have
[00:19:57.680 --> 00:20:03.800]   no reason to think that isn't a sincere aspect of why he's interested in it. I feel like Twitter
[00:20:03.800 --> 00:20:10.520]   has an overblown importance in society, though, partly because there's so many journalists
[00:20:10.520 --> 00:20:14.120]   on it and everything that gets said on Twitter gets amplified by these journalists. I mean,
[00:20:14.120 --> 00:20:20.520]   the average American is not on Twitter. It's not Facebook. Nobody's trying to buy Facebook.
[00:20:20.520 --> 00:20:25.800]   It's that a lot of... I mean, I don't know how everyone... I talk to folks that are in the press.
[00:20:25.800 --> 00:20:30.840]   A lot of people have Twitter open a lot. But it is us. It is the press that...
[00:20:30.840 --> 00:20:36.440]   Right. It amplifies it. Yeah, because it's a quick way to get... You see trends coming through.
[00:20:36.440 --> 00:20:43.160]   Yeah. To me, the two biggest ones for that actually is Twitter and Tech meme.
[00:20:43.160 --> 00:20:46.760]   Right. You know, things like flashing through the system and you're constantly...
[00:20:46.760 --> 00:20:51.320]   I mean, I know of a CEO that just keeps up... Tech meme open on one screen all the time.
[00:20:51.320 --> 00:21:00.520]   Tech means legit. That's a news source. Tech meme used to be algorithmic, right, Brian?
[00:21:00.520 --> 00:21:05.320]   And now it is... You have editors. But it used to be based on tweets?
[00:21:05.320 --> 00:21:11.720]   Well, it launched before Twitter. Oh, okay. But there was some algorithm.
[00:21:12.600 --> 00:21:18.360]   Yeah. I don't know how much Gabe wants me to tell you, but yeah, it was essentially an algorithm
[00:21:18.360 --> 00:21:22.920]   that then Gabe spent all day with his sort of finger on the dials.
[00:21:22.920 --> 00:21:29.800]   And so essentially what happens now is there's 24/7. I'm on the Tech meme slack right now,
[00:21:29.800 --> 00:21:34.760]   and there's editors. There's an editor working in India right now. So 24/7,
[00:21:34.760 --> 00:21:41.320]   there are people monitoring the algorithm and then adjusting and writing the headlines and
[00:21:41.320 --> 00:21:47.960]   things like that. So a lot of what they do now is they take the sort of lead from the algorithm
[00:21:47.960 --> 00:21:52.680]   and then decide how and in which ways to sort of craft it onto the page which
[00:21:52.680 --> 00:21:57.240]   we need to include and things like that. Clearly, I mean, if you go to Tech meme, and by the way,
[00:21:57.240 --> 00:22:02.920]   we all use this, I certainly use it, if you go to Tech meme, you'll see references to people
[00:22:02.920 --> 00:22:06.440]   writing an article, but then you'll see a lot of tweets. I mean, clearly Twitter,
[00:22:07.240 --> 00:22:15.160]   Tech meme is to some degree much like, what was it, what was it used to use all the time that was
[00:22:15.160 --> 00:22:21.880]   all tweets all the time that they bought and the buying. The algorithm gives the signal of what
[00:22:21.880 --> 00:22:27.880]   is important and what has landed at the top, and then they decide how and whether it's worth
[00:22:27.880 --> 00:22:32.120]   covering or not. Yeah, because you don't want, you know, the Kardashians living at the top there,
[00:22:32.120 --> 00:22:37.640]   you've really got to make sure that it sticks to the hues to the tech topics.
[00:22:37.640 --> 00:22:47.000]   Nevertheless, I think it's safe to say, well, I don't know, is it? I mean, when Trump was tweeting,
[00:22:47.000 --> 00:22:53.160]   it was a bully pulpit for a guy who theoretically has the bully pulpit.
[00:22:53.160 --> 00:22:57.080]   If you get it, if you get enough followers, I mean, it does have an impact.
[00:22:58.120 --> 00:23:04.280]   So it's, I mean, you definitely have, it definitely has an impact. I have a meager number of followers,
[00:23:04.280 --> 00:23:07.560]   but like every once in a while, I'll do something with Justine and Justine tweets something out,
[00:23:07.560 --> 00:23:12.440]   and you realize she lives in an entirely different world than I do. It's like, it's like suddenly,
[00:23:12.440 --> 00:23:16.440]   there's just this huge focus of things that all happen. So if you have a lot of followers,
[00:23:16.440 --> 00:23:23.320]   you know, it's, it's a, it has a big impact. It moves a lot of people. It sells a lot of products.
[00:23:23.320 --> 00:23:27.720]   It moves, you know, people think about things because you're out in front of them, and it's a
[00:23:27.720 --> 00:23:31.640]   different world because it used to be all controlled by people who it was three networks,
[00:23:31.640 --> 00:23:36.760]   who told us what to, what was happening. And then the cable networks spread it out and social
[00:23:36.760 --> 00:23:40.920]   networks spread it out somewhere. Yeah. So it's, it's, you know, it's just a, it's a, it's a, it's a
[00:23:40.920 --> 00:23:45.000]   progression from that. It's closer to being a town square than anything else. And people keep
[00:23:45.000 --> 00:23:50.280]   thinking they can create their own Twitter like thing. And it basically never works,
[00:23:50.280 --> 00:23:54.920]   which is why Donald Trump even has his own Twitter clone, which he's not
[00:23:56.600 --> 00:24:01.320]   posting on because it has no critical mass. Even Fox News created a cat this week,
[00:24:01.320 --> 00:24:05.320]   which wasn't Fox News. There was a verified Fox News account, which turned out not to be
[00:24:05.320 --> 00:24:09.880]   created by Fox News on Truth Social. And I think if you, if you created Twitter today, it wouldn't
[00:24:09.880 --> 00:24:14.360]   work. Like it, it works because it's big, you know, like there's a lot of people that use it.
[00:24:14.360 --> 00:24:19.800]   Yeah. And it's simple. I mean, it's relatively simple. You know, I, I like the, I very much enjoy
[00:24:19.800 --> 00:24:25.560]   the haiku of Twitter is the only thing I really post on. And I like the haiku of fitting into that,
[00:24:25.560 --> 00:24:30.920]   that word limit, you know, that, and figuring out how to say what you want to say in a, in those,
[00:24:30.920 --> 00:24:32.040]   in that number of characters.
[00:24:32.040 --> 00:24:33.000]   So it's a,
[00:24:33.000 --> 00:24:36.120]   Cool. This week in the Atlantic, which I recommend to everybody, it's a little long
[00:24:36.120 --> 00:24:41.960]   by Jonathan Haidt, who I've had on triangulation. He's a professor of, I think sociology.
[00:24:41.960 --> 00:24:49.080]   And I think NYU, he's written a great book about the right and left. Why the past 10 years of
[00:24:49.080 --> 00:24:54.760]   American life have been uniquely stupid. And he puts the finger square on Facebook and Twitter,
[00:24:54.760 --> 00:25:01.320]   social media. And he's got a good argument, which I won't recreate, but he's got a very strong
[00:25:01.320 --> 00:25:07.000]   argument for how social media drives us to the corners, and drives us to the extremes.
[00:25:07.000 --> 00:25:13.000]   That America is essentially politically in the, the vast center, center, a very centrist.
[00:25:13.000 --> 00:25:18.120]   But the problem is thanks to these amplification systems, these amplification algorithms,
[00:25:18.120 --> 00:25:22.520]   the extreme left and extreme right have, have outsized power.
[00:25:23.480 --> 00:25:27.960]   I would, I would argue that, I mean, they made it, they may have accelerated it, but they didn't
[00:25:27.960 --> 00:25:30.920]   start it. As Billy Joel said, they didn't start the fire. Right.
[00:25:30.920 --> 00:25:34.680]   You know the fire. And, and I think that the fire, if we start looking at the fire,
[00:25:34.680 --> 00:25:38.680]   I think we, we'd probably go back to Lee at Warner. So, so the thing is, is that there was an
[00:25:38.680 --> 00:25:43.160]   assumption in the eighties and the late eighties that, you know, or he came across this idea that,
[00:25:43.160 --> 00:25:47.160]   that Karl Rove picked up speed on later in the nineties, which was that you don't have to pay
[00:25:47.160 --> 00:25:52.840]   attention to the center. You do the social, the core, the social, social politics gets the core,
[00:25:52.840 --> 00:25:59.000]   the base. Well, it's not get the, yeah, either side, get the core energized and get the opposition
[00:25:59.000 --> 00:26:03.400]   not to show up. And that's all you have to do to win. And he proved that he could do that.
[00:26:03.400 --> 00:26:06.760]   Karl Rove proved that he could do that. And both sides employ it now.
[00:26:06.760 --> 00:26:11.240]   Is that you get the cord to show up and there's an incredible amount of energy spent on that.
[00:26:11.240 --> 00:26:15.320]   I will agree with the motivation was there, but in the past, they've had advertising and things
[00:26:15.320 --> 00:26:19.480]   like that. Now they have a, a weapon, a super weapon. Oh, yeah, can name from space.
[00:26:19.480 --> 00:26:24.680]   But I'm saying it didn't start there. It didn't start with you. It is that there was this,
[00:26:24.680 --> 00:26:29.640]   but we saw this in the nineties where we were going, oh, no, like this is what they're going to,
[00:26:29.640 --> 00:26:34.280]   this is what's happening to politics started, started splitting in the nineties because the
[00:26:34.280 --> 00:26:37.800]   campaign started splitting, you know, like they, they started in the eighties, but it really started
[00:26:37.800 --> 00:26:42.440]   splitting the campaign start. And then then it started taking over, you know, because you just
[00:26:42.440 --> 00:26:46.520]   realized you could win that way, you know, and I, and I think that that's the, I mean, that's it.
[00:26:46.520 --> 00:26:50.200]   And then all of this stuff gets accelerated. And I think that there's a lot of good points in that
[00:26:50.200 --> 00:26:54.360]   article. One of the things of verified users, only verified users get amplified.
[00:26:54.360 --> 00:26:58.200]   Things are really good idea. You know, I think that there's a wish. The real issue is, is not
[00:26:58.200 --> 00:27:03.800]   allowing machines to, the biggest problem, I think in almost all of these things is not allowing
[00:27:03.800 --> 00:27:09.560]   machines to post, you know, like it has to be a person to post it. And because the thing is, is
[00:27:09.560 --> 00:27:15.800]   that the, I had a, I did some tweet. I remember years ago, I did, I did a tweet. And I have no
[00:27:15.800 --> 00:27:21.560]   idea why it got so many. It was running for months. It was getting huge numbers of read,
[00:27:21.560 --> 00:27:26.360]   you know, of stuff. Some bot like latched onto it. Was not, I looked at it. It was like an innocuous
[00:27:26.360 --> 00:27:34.360]   tweet, but it fulfilled some model of disinformation that was, and I deleted it. I was like, I don't
[00:27:34.360 --> 00:27:38.120]   know why I don't know why this is being used, but I don't want to be used. And I just took it out,
[00:27:38.120 --> 00:27:43.560]   you know, but, but it was, because I kept on watching it was just one tweet. And that was,
[00:27:43.560 --> 00:27:48.120]   again, very, very, like, I don't like ABC TV or something. I don't like this show. It was like
[00:27:48.120 --> 00:27:53.640]   something like that. It was a hype who, by the way, wrote a fantastic book called The Righteous Mind,
[00:27:53.640 --> 00:27:58.440]   which I highly recommend, why good people are divided by politics and religion, which talks about
[00:27:58.440 --> 00:28:03.080]   that kind of trend that the atwater rove trend that you were talking about. But in this article,
[00:28:03.080 --> 00:28:09.640]   on which he's kind of, it's kind of eulogizing America, he says things change in 2009 when
[00:28:09.640 --> 00:28:15.320]   Facebook offered users the like button and Twitter offered the retweet button. Those
[00:28:15.320 --> 00:28:20.040]   amplification mechanisms are exactly what you're talking about, whether it's wielded by humans or
[00:28:20.040 --> 00:28:24.760]   bots. Of course, I think as part of the problem with Twitter, how, I mean, I know they try to get
[00:28:24.760 --> 00:28:30.920]   rid of bots, but I often have the feeling that at least half of my followers are bots. They're
[00:28:30.920 --> 00:28:36.680]   not humans. Remember when retweeting was something you did in annually? Yeah, by hand,
[00:28:36.680 --> 00:28:42.440]   in pasting and the might in some ways almost have been a better way to go about it, to put a little
[00:28:42.440 --> 00:28:46.680]   friction into the process. On tweet deck, I could turn off retweets I do, and it is a very different
[00:28:46.680 --> 00:28:53.880]   Twitter, but the way without the viral amplification retweeting. I block so many things in Twitter,
[00:28:53.880 --> 00:28:59.400]   and then I follow, I have like 110 term, anytime I see a term, I go, I don't like that tweet, I look
[00:28:59.400 --> 00:29:02.600]   at it, I look at a word in there that makes it unique, and then I go into the word block,
[00:29:02.600 --> 00:29:06.600]   and I say block all the tweets like that. And then I have all these great people that I
[00:29:06.600 --> 00:29:10.600]   follow that are everything coders and sound designers and all this. I have a great Twitter. I mean,
[00:29:10.600 --> 00:29:13.880]   I have to admit, whenever it complains about it, I'm like, I don't understand what everyone's
[00:29:13.880 --> 00:29:18.040]   so upset about because mine is great. I agree. I have a great Reddit. There's awful stuff on
[00:29:18.040 --> 00:29:23.880]   Reddit, but I don't follow it. You don't have to worry about it. And you can do the same thing
[00:29:23.880 --> 00:29:29.640]   with Twitter. I don't know if that makes Twitter a better place for everybody or just for you.
[00:29:29.640 --> 00:29:33.800]   No, it doesn't. I'm just saying it doesn't have to be if you're, if you're, if you're
[00:29:35.160 --> 00:29:39.960]   I find going to Twitter to be enjoyable and fun because I've gotten rid of almost everything I
[00:29:39.960 --> 00:29:44.040]   didn't want that makes me stressed. Like I just, I was like, I'm not here. I'm not here to,
[00:29:44.040 --> 00:29:49.560]   Twitter is not a good source of news, you know, like it is, you know, so, so I took, you know,
[00:29:49.560 --> 00:29:53.240]   things out that I don't care whether it's news or not. I go to other things like Tech
[00:29:53.240 --> 00:29:57.800]   Meme, like regular, you know, bunch of other news news organizations to get news and Twitter,
[00:29:57.800 --> 00:30:01.720]   Twitter, I go to have fun. Hang out. Yeah. You know, see interesting things. Yeah.
[00:30:02.600 --> 00:30:08.200]   Twitter, I just go to see who died because if you're trending, chances are you're dead.
[00:30:08.200 --> 00:30:17.000]   What I've been asking people all week is let's say Elon does take over Twitter. Let's say he brings
[00:30:17.000 --> 00:30:24.760]   in a whole new regime and how things are done. Is there something that he could do that would
[00:30:24.760 --> 00:30:29.080]   kill Twitter for you? And, and, and because I've been asking people like, you know,
[00:30:30.280 --> 00:30:34.920]   Twitter has been famous for not iterating on its product, but I feel like they know
[00:30:34.920 --> 00:30:41.480]   that it's so delicate that they don't want to do it. So if he comes in there and stops around and
[00:30:41.480 --> 00:30:45.800]   changes a whole bunch of stuff, would it be certain people like the people that you love
[00:30:45.800 --> 00:30:50.440]   following leaving like what would be the thing for any of you that would make you be like, well,
[00:30:50.440 --> 00:30:54.440]   Twitter used to be great, but I just don't do it anymore. That's a really good longer,
[00:30:54.440 --> 00:30:56.040]   higher character count.
[00:30:57.240 --> 00:31:01.240]   Did it get worse for you when they went to 280? No, no, no, no. I think I think the current number
[00:31:01.240 --> 00:31:06.120]   is great. But, but I think it's great. I think that 140 was a little like, little cramped.
[00:31:06.120 --> 00:31:09.640]   I think the current number is really good, but I think that if we made it longer than that,
[00:31:09.640 --> 00:31:13.400]   I stopped using it because it would just be, oh my gosh, like if I see an article that's too long,
[00:31:13.400 --> 00:31:19.400]   like, okay, that's a lot of words. And so the, so I think that that, you know, the longer that,
[00:31:19.400 --> 00:31:22.760]   that would probably, I think the biggest problem is that they're just going to get a lot of regulation.
[00:31:22.760 --> 00:31:25.800]   Like if he does a bunch of, he can say whatever, maybe he can say whatever he wants,
[00:31:25.800 --> 00:31:29.720]   but Twitter is going to be in all kinds of hot water if it starts to, you know,
[00:31:29.720 --> 00:31:34.760]   dramatically change in a direction that makes countries concerned, you know. And so I think
[00:31:34.760 --> 00:31:38.360]   that that's more of what puts it under pressure. There's some evidence that they're working on.
[00:31:38.360 --> 00:31:42.040]   And I want to say it's called something like Twitter articles, but maybe not,
[00:31:42.040 --> 00:31:46.440]   not extending the character count, but letting you attach something longer,
[00:31:46.440 --> 00:31:49.400]   which people of course always do just by putting in screenshots.
[00:31:49.400 --> 00:31:53.800]   But that might be a, which I, which I certainly ignore. Yeah, I agree. I think,
[00:31:54.440 --> 00:31:58.520]   you know, I don't like Twitter threads either where you put a blog post 15 Twitter posts that
[00:31:58.520 --> 00:32:03.720]   bothers me to hate that. The top article thing, which is part of Twitter blue is Twitter's kind of
[00:32:03.720 --> 00:32:10.680]   way of, of doing that. Yeah. I'm always like, get a, get a blog. Like if you're going to write
[00:32:10.680 --> 00:32:14.680]   something longer than Twitter characters. Yeah. Yeah. But yeah, that's what our blue feature,
[00:32:14.680 --> 00:32:20.200]   which is sort of their repackaged version of the idea behind Nuzzle. Nuzzle. That was what I was
[00:32:20.200 --> 00:32:24.920]   trying to remember in the past. Nuzzle was an early Twitter driven. Yeah. I loved Nuzzle.
[00:32:24.920 --> 00:32:31.480]   Jonathan Abrams, the guy who created Friendster last act and Twitter bought it and they kind of
[00:32:31.480 --> 00:32:36.920]   turned this into top articles, acknowledging that they are in fact a good place to get signals about
[00:32:36.920 --> 00:32:41.880]   what the zeitgeist is. I think that they, you know, a lot of times they just have a hard time
[00:32:41.880 --> 00:32:45.640]   doing it. Like everybody, all these companies have, they're not very good at many things. They're
[00:32:45.640 --> 00:32:48.920]   good at one thing that pays for everything. The Twitter's got a good fee. You know, Google has
[00:32:48.920 --> 00:32:53.080]   Google AdWords and display ads. Everything else isn't, you know, they do the best they can.
[00:32:53.080 --> 00:32:56.760]   Mail. Mail turned out well and YouTube turned out well, but they bought that. But the, but most
[00:32:56.760 --> 00:33:00.680]   of it is, you know, like most of their ideas, you know, kind of go all over the place. And then
[00:33:00.680 --> 00:33:05.080]   Twitter, like they put out live streaming. I'm a live streaming. So I think about this. It's the
[00:33:05.080 --> 00:33:10.760]   worst platform for it. And you're like, it wouldn't be very hard to fix, but they, you know, they
[00:33:10.760 --> 00:33:13.640]   don't. They don't. They don't. Bunkled that a lot. Remember they had, they bought mine and
[00:33:13.640 --> 00:33:20.280]   killed it. What does Twitter call it? It's not reels. What do they call it? Spaces. Spaces.
[00:33:20.280 --> 00:33:25.720]   Yeah, it's like their clubhouse. Fleeights. That failed, right?
[00:33:25.720 --> 00:33:29.160]   Twitter Spaces is fun. We've a fast company. We've been doing Twitter Spaces and
[00:33:29.160 --> 00:33:35.480]   actually pretty cool. We record all of our interview episodes on Spaces now, because it's
[00:33:35.480 --> 00:33:40.920]   just so much. It's so easy to, we've done it. We've been, we've done Spaces where like KVON
[00:33:40.920 --> 00:33:45.320]   Bakepour of Twitter comes on because we're talking about Twitter product. And so he'll pop in and
[00:33:45.320 --> 00:33:50.120]   it's really great for if you're talking about a topic and then somebody involved in that topic
[00:33:50.120 --> 00:33:55.240]   happens by and you say, well, come up on stage and then, you know, that's clubhouse, right?
[00:33:55.240 --> 00:33:59.240]   That's what it is clubhouse, but it's for, for podcasting purposes, it's amazing.
[00:33:59.240 --> 00:34:03.720]   And it makes a lot of sense for it to be part of a Twitter. If you already are part of a community
[00:34:03.720 --> 00:34:09.400]   there versus having to become part of a community on class with that already.
[00:34:09.400 --> 00:34:17.400]   Are people still using clubhouse? Yeah. It is at the number one download of the app store, but
[00:34:17.400 --> 00:34:20.760]   people still get really excited about it for a while. We did a bunch of clubhouse stuff and
[00:34:20.760 --> 00:34:26.200]   then really, why don't, so this is my Twitter feed. Why don't I see Spaces? They're used to
[00:34:26.200 --> 00:34:31.080]   see it at the time. Because it's only mobile. It's, it's only, I think you can maybe you can
[00:34:31.080 --> 00:34:35.080]   listen online, but in order to participate, you need to be on a phone. You can't even do it on an
[00:34:35.080 --> 00:34:36.840]   iPad at this point. Wow.
[00:34:36.840 --> 00:34:39.080]   Yeah, it's a big attempt to level things out. I hope it's a level of things out.
[00:34:39.080 --> 00:34:43.000]   I hope it's a level of things out. You also, if you're one of the speakers,
[00:34:43.000 --> 00:34:48.440]   you only get in at the same time your audience does. So a lot of the time, the first couple of
[00:34:48.440 --> 00:34:53.320]   minutes, sort of the speakers kind of getting together and realizing they need to be on a phone,
[00:34:53.320 --> 00:34:57.960]   and it would be much nicer if you would kind of get come in five minutes early and get yourself
[00:34:57.960 --> 00:35:03.800]   out. Don't tell anyone that's in here. What do you do? What do you do? Brian?
[00:35:04.440 --> 00:35:08.040]   I was going to say, don't tell anyone that's how Twit works too, that we talk for 20 minutes
[00:35:08.040 --> 00:35:11.240]   before we answer. Yeah, exactly. What? And you didn't tell me?
[00:35:11.240 --> 00:35:16.360]   So we did figure out how to hack that, that, that problem.
[00:35:16.360 --> 00:35:21.240]   Oh, yes. There's getting their wits about them. Yeah. So what you do is there's a,
[00:35:21.240 --> 00:35:25.000]   there's a little box by a company called Studio Technologies. It's a, I can't remember what,
[00:35:25.000 --> 00:35:29.240]   which number is I have it around here somewhere, but it's a, it's what's called a Dante to Bluetooth.
[00:35:29.240 --> 00:35:33.320]   So what it does is it, it's a little, it just has an ethernet that pops in the back. Dante is a,
[00:35:33.320 --> 00:35:40.440]   is an audio patching system that we use in events. And it looks like a headphone to the phone,
[00:35:40.440 --> 00:35:44.840]   right? So it shows up as a blue, it says, I'm a Bluetooth headphone, but what it does is it
[00:35:44.840 --> 00:35:51.000]   connects it to your, your entire audio system. So now, so I have it like this mic and everything
[00:35:51.000 --> 00:35:56.840]   else can be inside of spaces or, or clubhouse, but then you can run the whole show if you want to,
[00:35:56.840 --> 00:36:01.240]   from somewhere else. Because we, we just didn't like the audio quality. So we were like, and we
[00:36:01.240 --> 00:36:05.240]   didn't like not be able to do pre-show and everything else. And so we just, we did this
[00:36:05.240 --> 00:36:08.200]   all up with clubhouse, but it would work with spaces as well, where you just have, you can have
[00:36:08.200 --> 00:36:11.240]   the whole conversation. We actually were doing the conversation over Zoom and then pumping it back
[00:36:11.240 --> 00:36:17.000]   into, into, into clubhouse. Then everything sounds good. And we have all of our back channels and
[00:36:17.000 --> 00:36:19.240]   everything else that we like to have for sure. Do you know about people know about Twitter?
[00:36:19.240 --> 00:36:23.240]   I mean, I know they see it on TV and they know about them. I don't think they actually,
[00:36:23.240 --> 00:36:28.840]   they don't use it. They're watching all these TV shows that are 50% showing tweets.
[00:36:28.840 --> 00:36:33.400]   Right. Yeah, my, my parents know about Twitter, but they don't read it. They would ever join it or
[00:36:33.400 --> 00:36:38.200]   use it. I think most of my family doesn't actually read it. That's the biggest problem for Twitter,
[00:36:38.200 --> 00:36:43.160]   right? They only have 350 million active users and, you know, it's, and that's global.
[00:36:43.160 --> 00:36:47.800]   That's the biggest problem right there. It turned out it's probably not something a billion people
[00:36:47.800 --> 00:36:51.080]   are going to use. It's a niche product compared to Facebook anyway. I mean, I think it's a,
[00:36:51.080 --> 00:36:57.160]   it's a sad commentary on some ways on the tech business that you can have that many people
[00:36:57.160 --> 00:37:01.160]   on your service. And it's a disappointment. Yeah.
[00:37:01.160 --> 00:37:05.400]   Yeah. It's a good day's of magazines, whether, you know, oh, if you had 350 million subscribers
[00:37:05.400 --> 00:37:10.120]   to Time Magazine, if you had a, you'd be done at PC world. We had 1.25 million.
[00:37:10.120 --> 00:37:13.240]   That was astonishing at the time. Yeah. That's a huge number. Yeah.
[00:37:13.240 --> 00:37:18.760]   I wish there was more of a place for things that like Twitter that were quite large,
[00:37:18.760 --> 00:37:23.480]   but not one to two billion people. I don't mind. We're niche, Twitch's niche.
[00:37:24.440 --> 00:37:28.280]   Podcasting is for the most part, niche, unless it's call or data, you're Joe Rogan.
[00:37:28.280 --> 00:37:32.840]   I think it's going to say, Leo, like the argument for Twitter is that it's a smaller
[00:37:32.840 --> 00:37:36.520]   audience, but maybe it's more valuable audience. I mean, that hasn't been proven out by their
[00:37:36.520 --> 00:37:41.320]   revenue numbers. But again, that gets back to the beginning of this argument, which is, well,
[00:37:41.320 --> 00:37:45.640]   this is where the journalists and the famous people in that, like, this is where the.
[00:37:45.640 --> 00:37:49.560]   That's kind of what you want to be, right? The influencer, the one that.
[00:37:49.560 --> 00:37:51.640]   That was the word that I was trying to.
[00:37:51.640 --> 00:37:54.120]   Seised. Wait. Oh, sorry. I made you use that.
[00:37:54.120 --> 00:37:57.720]   All right. I'm going to take a break because I'm done with Twitter.
[00:37:57.720 --> 00:38:02.600]   I quit Twitter on a regular basis. We're going to take a little break, come back.
[00:38:02.600 --> 00:38:05.560]   There is more tech news. There's other stuff to talk about. So let's do it.
[00:38:05.560 --> 00:38:11.320]   We've got a great panel. Brian McCullough is here from Tech meme ride home every single day,
[00:38:11.320 --> 00:38:16.200]   sometimes even on weekends. He is the galactic host, it says. So congratulations.
[00:38:16.200 --> 00:38:21.560]   We decided to give you a title because he was jealous because Harry McCracken is now the
[00:38:21.560 --> 00:38:27.640]   global technology editor at Fast Company. Congratulations on that. And of course,
[00:38:27.640 --> 00:38:33.000]   normally we see him on Tuesdays on Mac break weekly. And of course, every day on office hours,
[00:38:33.000 --> 00:38:42.120]   Doc Global Alex Lindsey is here. Our show today brought to you by checkout.com. Tech should be,
[00:38:42.120 --> 00:38:45.240]   I think we can agree groundbreaking should promote innovation.
[00:38:45.240 --> 00:38:50.680]   That's not something you normally say about traditional payment systems. They're layered,
[00:38:50.680 --> 00:38:55.640]   they're disconnected, they're often perceived as a cost center to your business. Modern businesses
[00:38:55.640 --> 00:39:02.200]   need flexible payment systems that can help them adapt to change, to grow and scale fast.
[00:39:02.200 --> 00:39:06.440]   And it's not going to break the bank. I recently came across a company with tech that approaches
[00:39:06.440 --> 00:39:12.440]   payments through a new lens. And I'm really pleased to share it with you checkout.com. Now,
[00:39:12.440 --> 00:39:18.280]   you've seen checkout. If you buy things on she and the Chinese multi-billion dollar
[00:39:18.280 --> 00:39:24.360]   clothing conglomerate, they use checkout.com. So does grab Sony electronics, wise,
[00:39:24.360 --> 00:39:30.760]   Henkel. Check out.com is the leading global payment solutions provider. Their flexible payments
[00:39:30.760 --> 00:39:37.160]   platform is purpose built with performance, scalability and speed in mind. Imagine how many
[00:39:37.160 --> 00:39:43.720]   transactions a second she in has to process. I mean, it's mind boggling. That's why checkout
[00:39:43.720 --> 00:39:48.200]   works for my deal for any business looking to seamlessly integrate better payment solutions.
[00:39:48.200 --> 00:39:54.680]   Globally, with a dedicated team of local experts spanning 19 offices in five continents, they're
[00:39:54.680 --> 00:39:59.960]   there for you. Check out.com offers a strategic partnership to help businesses improve their
[00:39:59.960 --> 00:40:05.640]   acceptance rates, optimize their payments, their performance to grow their business globally,
[00:40:05.640 --> 00:40:11.400]   enable your business and your community to thrive in the digital economy. Check out.com
[00:40:11.400 --> 00:40:15.720]   delivers innovative payment solutions that flex to your needs, valuable insights to help you get
[00:40:15.720 --> 00:40:20.360]   smart about your payments performance and expertise you can count on as you navigate the complexities
[00:40:20.360 --> 00:40:25.160]   of an ever shifting digital world. It's nice to have a company that treats you as a partner
[00:40:25.160 --> 00:40:32.360]   and helps you make this work with checkout.com. You get global optimization. They provide local
[00:40:32.360 --> 00:40:38.440]   acquiring and multiple geographies, improving authorization rates, lowering costs. And after
[00:40:38.440 --> 00:40:44.520]   all, I think your customers appreciate having a local checkout solution, not someone outside
[00:40:44.520 --> 00:40:49.080]   your country. And with the in depth reporting they offer, you get visibility no matter where you
[00:40:49.080 --> 00:40:53.880]   operate. But that local expertise is so important. They're dedicated local teams bring regional,
[00:40:53.880 --> 00:41:00.840]   international. And yeah, it's important to regulatory expertise along, allowing you to navigate market
[00:41:00.840 --> 00:41:05.960]   complexities with confidence. And of course, they are a partner. They take a collaborative,
[00:41:05.960 --> 00:41:11.880]   personalized approach to solving complex problems for their merchants and their ecosystems.
[00:41:12.920 --> 00:41:17.720]   I think I've given you about 12 reasons why you should be checking out checkout.com.
[00:41:17.720 --> 00:41:24.520]   Discover out checkout.com can help your business thrive. Go to checkout.com/twit.
[00:41:24.520 --> 00:41:27.720]   Check out.com/twit. Please use that address so they know you saw it here.
[00:41:27.720 --> 00:41:37.240]   Check out.com/twit. All right, let's get back to the week's tech news. We've done the Elon Musk
[00:41:37.240 --> 00:41:41.080]   beat. We'll be doing that for weeks to come, I'm sure. That's one thing you got to love
[00:41:41.080 --> 00:41:44.920]   somebody has given you more headlines, right? Brian, did you spend every episode of Tech
[00:41:44.920 --> 00:41:47.880]   Meme Right Home this week talking about probably did talking about Elon?
[00:41:47.880 --> 00:41:53.640]   I opened one show apologizing saying, listen, sometimes even when I don't want to talk about it,
[00:41:53.640 --> 00:41:57.960]   there's nothing I can do. It's the top story that everybody's talking about. So even though
[00:41:57.960 --> 00:42:01.080]   we've done this four days in a row, guess what? Guess what? We go again. Yep.
[00:42:01.080 --> 00:42:08.680]   Yep. Let's see. We could talk about Ukraine. Of course, that's the eternal story. If you watch
[00:42:08.680 --> 00:42:15.560]   cable news, but there is a tech story. You may remember back in 2015, and this concerned me,
[00:42:15.560 --> 00:42:22.920]   I remember this, Ukraine grid went down for a number of hours under attack. We thought from
[00:42:22.920 --> 00:42:33.640]   nation-state actors probably Russia. At that time, that was a malware used by, they found out,
[00:42:33.640 --> 00:42:42.040]   Samworm in 2016, which is the, one of the names for the GRU's, the Russian military intelligence
[00:42:42.040 --> 00:42:47.320]   hacking group. I think it's Fancy Bear, Cozy Bear. They have all the cute little name,
[00:42:47.320 --> 00:42:55.320]   Samworm. They were using in destroyer. Well, this is the problem when you reuse malware.
[00:42:55.320 --> 00:43:00.840]   ESET and Microsoft say they stopped an attack this week on the Ukraine grid,
[00:43:02.040 --> 00:43:09.240]   discovering a new variant of the same old worm that they used back in 2016. The
[00:43:09.240 --> 00:43:15.720]   Ukraine Governmental Computer Emergency Response Team said the attack went after several
[00:43:15.720 --> 00:43:20.920]   infrastructure elements, including high voltage electrical substations, computers at the facility,
[00:43:20.920 --> 00:43:28.040]   network equipment, and server equipment running Linux. Two waves of attack, the initial compromise,
[00:43:28.040 --> 00:43:34.600]   had happened back in February, and then they triggered it Friday, April 8th. They triggered it in the
[00:43:34.600 --> 00:43:47.720]   evening, but ESET and Microsoft saw it and stopped it. So the good news is we have talked a lot
[00:43:47.720 --> 00:43:54.840]   about cyber warfare being one of the consequences of the Ukraine war invasion, and even the U.S.
[00:43:54.840 --> 00:44:01.080]   might be victims of this. But the problem, of course, is you can't use these tools more than once.
[00:44:01.080 --> 00:44:08.200]   You kind of have to save your powder, I guess, until the time is right.
[00:44:08.200 --> 00:44:12.760]   And I've been wondering why haven't we seen more attacks? Well, here's one reason.
[00:44:12.760 --> 00:44:19.000]   They were ready. I keep wanting to ask that question, and I'm so afraid that I'm going to
[00:44:19.000 --> 00:44:25.080]   jinx as soon as I say that. Yeah, I know. Knock on wood, right? But I think certain the U.S.
[00:44:25.080 --> 00:44:32.600]   has been very active in protecting, and SISA have been very active in going to the electrical
[00:44:32.600 --> 00:44:37.080]   grid providers, for instance, in the U.S. and saying, "Hey, watch out. Here's what to be watching
[00:44:37.080 --> 00:44:40.760]   for." Helping them, they've been spending money to help them lock down their network.
[00:44:40.760 --> 00:44:44.920]   And yeah, knock on wood. We haven't seen anything yet. Maybe we won't.
[00:44:46.200 --> 00:44:50.440]   You know, the hard part with when you do any kind of attack, you got to make sure that it's going to
[00:44:50.440 --> 00:44:55.960]   be effective because you're showing something. This is what you can see here, right? They showed it
[00:44:55.960 --> 00:44:59.240]   back a couple years ago, and then when they try to do it again, it's hard to do it again.
[00:44:59.240 --> 00:45:03.320]   And that's why you want to keep your powder dry in this area. So unless they feel like they're
[00:45:03.320 --> 00:45:08.040]   really going to be able to succeed, and Russia has not proven that they can succeed at many things.
[00:45:08.040 --> 00:45:15.160]   Yeah. So I think that using just firing off on attack, they have to really feel like they can,
[00:45:15.160 --> 00:45:19.160]   they're going to achieve the result, or it's not worth using up whatever secret that they
[00:45:19.160 --> 00:45:25.560]   figured out. Exactly. And maybe the Russian military isn't quite as advanced as we thought.
[00:45:25.560 --> 00:45:30.360]   You saw this. I don't know if you did, maybe the drone. The drone. Oh my gosh.
[00:45:30.360 --> 00:45:36.200]   Ukraine soldier tears down. Russian drone finds a cannon rebel camera inside.
[00:45:36.200 --> 00:45:40.200]   With the leaves at least a mark to. That's all I'm saying.
[00:45:40.920 --> 00:45:49.640]   It's one. And they had glued down the photo dial, so it couldn't accidentally go into manual mode
[00:45:49.640 --> 00:45:54.760]   or anything like that. I mean, to put it in perspective, DJI's camera is nicer than
[00:45:54.760 --> 00:46:00.600]   camera camera. This is a drone, a Russian military drone that apparently costs like $80,000.
[00:46:00.600 --> 00:46:05.800]   Which is nothing, by the way. Like it's a cheap one. That's really cheap.
[00:46:06.760 --> 00:46:13.640]   I think cars are more $100 per copy. This is the breakdown, Ukraine soldier.
[00:46:13.640 --> 00:46:18.920]   The funny thing is a number of people say this is really not so different from the radio controlled
[00:46:18.920 --> 00:46:25.000]   hobbyist drones. You might see people have built. There was even like a bottle cap used as a dial,
[00:46:25.000 --> 00:46:30.040]   glued in. I guess if you don't open it up, you don't know how
[00:46:31.400 --> 00:46:42.120]   unimpressive the technology is. Again, a lot of it has to do with just our little recon drones
[00:46:42.120 --> 00:46:47.640]   are like 35,000 each. These are like do nothing. They're like tiny little cute little, a little
[00:46:47.640 --> 00:46:51.880]   big in that. But once you start talking about reapers and so on and so forth, you're talking
[00:46:51.880 --> 00:46:56.920]   about tens or hundreds of million reapers and global hawks are like tens or hundreds of millions
[00:46:56.920 --> 00:47:03.960]   of dollars that we put into this. I keep doing stories about how it's Turkey that supplies
[00:47:03.960 --> 00:47:11.640]   everybody with drones. What is Turkey done? How come there the go-to source for drone folks all
[00:47:11.640 --> 00:47:15.800]   around? I don't know actually why Turkey is it, except that they probably decided that they make
[00:47:15.800 --> 00:47:21.640]   it a business. They're willing to give you military grade drones. The United States
[00:47:21.640 --> 00:47:26.760]   frowns on that. We don't. It's really hard unless you're the United States military. There's a real
[00:47:26.920 --> 00:47:31.000]   concern of people weaponizing their drones. It's not a great place to do that.
[00:47:31.000 --> 00:47:38.520]   I'm sure they'd love to use DJI, but they're from China. That's another probably place you're
[00:47:38.520 --> 00:47:43.160]   not going to go. I think China stayed away. They have their own military with their own drones.
[00:47:43.160 --> 00:47:48.600]   I think that most countries that have drones don't want to proliferate that because really,
[00:47:48.600 --> 00:47:54.040]   there is a future where if you see even just the effectiveness that the Ukrainian military has
[00:47:54.040 --> 00:47:58.600]   had with some of the drones that they got from us and some of the drones that they got from
[00:47:58.600 --> 00:48:08.120]   Turkey is that they're able to kill tanks with these drones. They drop munitions on these tanks.
[00:48:08.120 --> 00:48:13.640]   Again, the other problem is that if you're getting good at drones, you start building actually
[00:48:13.640 --> 00:48:17.160]   capable ones. You've got a lot of electronics in there and the drone is going to get shot down
[00:48:17.160 --> 00:48:21.080]   and you don't want to give it up. The United States doesn't want to have their drone. They'll
[00:48:21.080 --> 00:48:25.320]   send people in to go get those because they have a bunch of stuff in them that they don't want
[00:48:25.320 --> 00:48:29.480]   other people to copy because drones are very, very-- it's a very destructive technology.
[00:48:29.480 --> 00:48:38.120]   I worked at an A-Life company in the early '90s that it could learn. It had an
[00:48:38.120 --> 00:48:42.200]   computing organism that could learn. We ended up putting it in a low game,
[00:48:42.200 --> 00:48:46.680]   but the military wanted to spend a lot of money on it. The owners, the founders,
[00:48:46.680 --> 00:48:51.960]   wouldn't sell it to them. What they were talking about was firing many, many, many small missiles,
[00:48:51.960 --> 00:48:56.520]   and as you shoot them down, they're figuring out how to get around you. You just fire lots of them.
[00:48:56.520 --> 00:48:59.800]   You have to shoot them down. They're big enough and then the missiles just keep getting bigger
[00:48:59.800 --> 00:49:04.760]   as they start to learn what your defenses are. That was 30 years ago.
[00:49:04.760 --> 00:49:11.880]   So the thing is that there's a capability of using these drones. If you have a lot of them,
[00:49:11.880 --> 00:49:17.640]   even if they're small, that you can't ignore them. As you shoot at them, you are giving away your
[00:49:17.640 --> 00:49:26.600]   position. We're seeing a little bit of that here, but definitely that was used pretty heavily in
[00:49:26.600 --> 00:49:34.040]   Afghanistan. I do worry every time Vladimir Putin tries to dissuade the west from getting
[00:49:34.040 --> 00:49:41.720]   involved by saying that we're running the risk of bringing on scenarios that we've never known
[00:49:41.720 --> 00:49:46.280]   in the past, whether he's talking about theoretically devastating cyber attacks.
[00:49:46.280 --> 00:49:50.680]   Of course, you might also just be talking about nuclear attacks, but...
[00:49:50.680 --> 00:49:55.320]   He'd like to keep it vague just in case. But I wonder if he is saving his powder for a
[00:49:55.320 --> 00:50:02.920]   scenario like that? I think the only thing he has is nukes. He has lots of devastating stuff,
[00:50:02.920 --> 00:50:08.360]   but the only thing he has that's decisive are nukes. I mean, he may be able to do some cyber
[00:50:08.360 --> 00:50:13.880]   attack, but I feel very confident the United States could probably shut most of Russia's
[00:50:13.880 --> 00:50:17.880]   infrastructure down if they wanted to. They just aren't going to do it unless they have to.
[00:50:17.880 --> 00:50:24.360]   We've been very careful not to show any cards about what we know and what we have.
[00:50:24.360 --> 00:50:29.880]   But of knowing what we have and what we could do, there's no reason to do it until you have to.
[00:50:29.880 --> 00:50:35.080]   So if they shut down our infrastructure, we'd probably do the same thing. The other thing you have,
[00:50:35.880 --> 00:50:40.280]   the other thing is, is we spend a lot of time trying not to shoot the nukes.
[00:50:40.280 --> 00:50:42.840]   There's a rumor that of course Russia has the dead switch.
[00:50:42.840 --> 00:50:47.000]   If you shut everything down, it just starts firing nukes.
[00:50:47.000 --> 00:50:51.800]   What a world we live in.
[00:50:51.800 --> 00:50:55.640]   Let's see.
[00:50:55.640 --> 00:51:04.200]   California is banning gas cars. That'll be interesting. At least they're proposing it.
[00:51:05.400 --> 00:51:10.440]   The governor of California some months ago said we should get rid of gas vehicles by 2035,
[00:51:10.440 --> 00:51:16.680]   a scant 13 years from now. Now California's Clean Air Resources Board has unveiled its plan
[00:51:16.680 --> 00:51:22.840]   to phase out gas powered vehicles. There will be a 45 day public comment period. That should be
[00:51:22.840 --> 00:51:30.120]   fascinating. A June 9th public hearing, I hope they stream that. That'll be fun to watch
[00:51:30.120 --> 00:51:36.200]   and a vote in August. It phases it out and it just means that new car sales will have to be electric
[00:51:36.200 --> 00:51:42.040]   not or zero emission, I should say. Not necessarily electric. And that used cars can continue to be
[00:51:42.040 --> 00:51:46.280]   gas cars and of course they're not going to take your car off the road if it's a gas cuzzler.
[00:51:46.280 --> 00:51:51.320]   What do you think? Is this seems like something we should do, we might need to do.
[00:51:51.320 --> 00:51:53.080]   Is it doable?
[00:51:53.080 --> 00:51:56.920]   Also how much is it on the rest of the country given?
[00:51:57.720 --> 00:52:01.480]   Well, obviously California's got to be a big market. California's not so much in the past to shape
[00:52:01.480 --> 00:52:05.720]   our emissions standards changed America's emissions standards.
[00:52:05.720 --> 00:52:08.200]   So this might be a big deal just in general.
[00:52:08.200 --> 00:52:13.160]   I just think it's interesting. They took they're setting up regulations, but they're taking away
[00:52:13.160 --> 00:52:16.840]   a lot of our incentives or they took a lot of them away. So how much off you get
[00:52:16.840 --> 00:52:21.880]   providing electric car and most importantly, the sticker for the hovling. That was for a long
[00:52:21.880 --> 00:52:26.360]   time. I was looking at the sticker. You don't get the sticker all the time. It was a certain number.
[00:52:26.360 --> 00:52:29.000]   Oh, yeah, the only issue is certain number every year. Yeah. Yeah.
[00:52:29.000 --> 00:52:33.800]   I think that like I'm you can encourage people to just do it because the hovling is very valuable
[00:52:33.800 --> 00:52:39.080]   more valuable than money to me. Yeah. Like so it's yeah. Yeah. The high occupancy vehicle,
[00:52:39.080 --> 00:52:43.880]   AKA electric vehicle. Yeah. I see a lot of cars with those stickers. I don't have them on mine.
[00:52:43.880 --> 00:52:49.080]   They stop. Yeah. They stop issuing them. They had to be a certain kind and everything else.
[00:52:49.080 --> 00:52:52.840]   Right. Right. But but I think that that was a I know I was looking at I'm still I've still
[00:52:52.840 --> 00:52:55.720]   decided I'm not buying another car until I buy electric because I just I just don't like going to
[00:52:55.720 --> 00:53:00.120]   the gas station and has nothing. That's the I just I love it. I haven't been at a gas station in a
[00:53:00.120 --> 00:53:06.040]   long time. Although, you know, we had Lisa's car. She has an electric mini in the shop again.
[00:53:06.040 --> 00:53:11.560]   And so they gave her a light a gas loner and I had to drive it down to pick up the car.
[00:53:11.560 --> 00:53:19.640]   And I forgot how I was you poor people. You push on the pedal and it goes, okay,
[00:53:19.640 --> 00:53:23.000]   I think I can go faster electric car. It's like that.
[00:53:23.960 --> 00:53:27.720]   Right. My neighbor has two Teslas, a Tesla roof and two Tesla batteries.
[00:53:27.720 --> 00:53:33.000]   And and he has a totally live, you know, it's totally closed system. Yeah.
[00:53:33.000 --> 00:53:38.520]   So we have big solar panels. We have the Tesla power walls, electric all electric vehicles.
[00:53:38.520 --> 00:53:43.080]   It's nice not to go to the gas station. And I don't, you know, honestly, you really want to solve
[00:53:43.080 --> 00:53:48.520]   the climate problems and a lot of other problems. You get rid of personal ownership of vehicles
[00:53:48.520 --> 00:53:53.480]   entirely. I hope that day comes at some point because I'm getting older and I'd like to get
[00:53:53.480 --> 00:53:58.280]   an Uber for the rest of my life or a self driving something for the rest of my life.
[00:53:58.280 --> 00:54:02.360]   It seems like a good idea. Like I thought about that a lot until until COVID and then after COVID,
[00:54:02.360 --> 00:54:06.040]   now I don't want to get it. Yeah, no, right. It's like, I need a car because I can't get
[00:54:06.040 --> 00:54:11.640]   anywhere because Uber takes a third. It takes 30 minutes to get to get to get a, you know,
[00:54:11.640 --> 00:54:16.680]   haven't you heard COVID's over? I wonder, everyone left and didn't come back.
[00:54:16.680 --> 00:54:23.560]   Electric car will cost by 2035 because there are so many people who cost as a big factor.
[00:54:23.560 --> 00:54:29.480]   And I mean, I'm not even sure how much I decent used electric car costs at the moment, but it's
[00:54:29.480 --> 00:54:33.320]   not within the reach of everybody who needs transportation. Although with gas prices,
[00:54:33.320 --> 00:54:38.600]   at least in California hitting five bucks, electric cars start to look maybe a lot of it.
[00:54:38.600 --> 00:54:43.000]   Where can you get a peel? Where can you get gas in California for five? What is it? I want to know.
[00:54:43.000 --> 00:54:48.040]   It's in the six. It's over $6. Yeah, I just filled up a couple days ago. I was like, what the what?
[00:54:48.040 --> 00:54:52.280]   Yeah. Oh man. You see, I don't know what that
[00:54:52.280 --> 00:54:55.720]   off. I don't know what the price of milk is either. I just, I live in a different world.
[00:54:55.720 --> 00:55:02.680]   Wow. I didn't realize it was six. Yeah. So that's got to make this effect, maybe carb weighted
[00:55:02.680 --> 00:55:07.880]   until $6 bucks a gallon in California. And then they thought that would be a good time.
[00:55:07.880 --> 00:55:10.680]   Let's try it. But you know, people are going to freak out.
[00:55:12.200 --> 00:55:16.040]   Well, the problem is, is that if in California has to fix its electrical system before they
[00:55:16.040 --> 00:55:18.120]   that's a big problem. I agree.
[00:55:18.120 --> 00:55:22.120]   We all have everywhere I live now. When the electricity goes out, we're all prepared. Now,
[00:55:22.120 --> 00:55:25.720]   we all have generators. You hear all these gas generators all turning on
[00:55:25.720 --> 00:55:33.080]   through the hills. Unless you get the new Ford F-150 Lightning, one of the selling points is when
[00:55:33.080 --> 00:55:37.640]   the power goes out and you might have seen these ads, you plug your truck into the house and then
[00:55:37.640 --> 00:55:42.040]   the truck runs the house, which I think is a good idea for how long I guess.
[00:55:42.040 --> 00:55:45.880]   Yeah. Well, it's a pretty big battery. It might get you through the night.
[00:55:45.880 --> 00:55:52.520]   Let's see what else. Muting your mic. This is an interesting story. We won't know the real story
[00:55:52.520 --> 00:55:57.000]   until this report comes out. University of Washington,
[00:55:57.000 --> 00:56:04.920]   sorry, University of Wisconsin, Madison tested, quote, many popular apps to see if the video
[00:56:04.920 --> 00:56:11.240]   conferencing apps continue to capture audio when you press the mute button. And apparently many of them
[00:56:11.240 --> 00:56:18.600]   do. We won't know which until the 2022 privacy enhancing technology symposium. That's when the
[00:56:18.600 --> 00:56:27.640]   paper will be published this June. But the report says all of the apps they tested
[00:56:27.640 --> 00:56:33.720]   occasionally gather raw audio data while mute is activated. One popular app, I'm pretty sure it's
[00:56:33.720 --> 00:56:37.400]   Zoom. I'm just going to say, because Zoom's had this problem before,
[00:56:37.400 --> 00:56:42.440]   continue to gather data to the audio to its server at the same rate regardless of whether
[00:56:42.440 --> 00:56:47.960]   the microphone is muted or not. Now it's your Zoom expert. This does not surprise me.
[00:56:47.960 --> 00:56:54.920]   That mute button on Zoom is mostly just saying don't send my audio to everybody in the conference.
[00:56:54.920 --> 00:57:02.280]   Yeah, I will say that it may inadvertently do that. I will say that Zoom worries about,
[00:57:02.280 --> 00:57:07.960]   I mean, especially after what happened in 2020, security is really important to them. So I think
[00:57:07.960 --> 00:57:14.760]   that if they see something like that, it's probably a very, very big, serious thing for them to get
[00:57:14.760 --> 00:57:19.960]   rid of. I don't know if it's a very popular, there are a bunch of very popular ones that are
[00:57:19.960 --> 00:57:25.080]   less technologically advanced than Zoom. So if you look at WebEx and go to meeting and meet and
[00:57:25.080 --> 00:57:31.160]   teams, and to be honest with you, I'd be more likely to think it was teams than Zoom, because
[00:57:31.160 --> 00:57:35.400]   Zoom has got a laser folk. Teams is very complicated. It's just connected to a lot of things.
[00:57:35.400 --> 00:57:42.520]   Zoom is focused on one thing. And the security now in Zoom, if you turn all the dials up,
[00:57:42.520 --> 00:57:47.560]   it's pretty secure. You know, like it's, and so you can inadvertently open it all the time,
[00:57:47.560 --> 00:57:50.440]   though. That's the problem is that it's, you know, I have a physical mute right here.
[00:57:50.440 --> 00:57:54.840]   Yeah, that's the thing. I think that's if you're going to take a moral from this article,
[00:57:54.840 --> 00:58:01.960]   is get a physical mute button. But also what he was just saying is, you'd worry more about a
[00:58:01.960 --> 00:58:07.800]   company that's focused on things like AI and things like that, because like what does Zoom care
[00:58:07.800 --> 00:58:12.120]   about your audio, they don't have other business lines that they're going to turn that into
[00:58:12.120 --> 00:58:17.000]   something else, at least that we know of. But a Google might, you know, a Microsoft might be
[00:58:17.000 --> 00:58:25.880]   using that to train data sets and things like that. Yeah, it's, yeah, I think that it's,
[00:58:25.880 --> 00:58:30.920]   we see a lot of people in office hours, of course, is all in Zoom. And so we have a lot of people
[00:58:30.920 --> 00:58:34.360]   inadvertently muting themselves around muting. So one of the most popular things in any Zoom
[00:58:34.360 --> 00:58:41.320]   meeting is we can't hear you, you know, muted. And so, you know, so it's, and so inadvertently turning
[00:58:41.320 --> 00:58:45.960]   it on and off is a pretty common thing. I think that they're not, I think that, and I think that
[00:58:45.960 --> 00:58:50.680]   most of these companies, I mean, it's, it definitely could be a problem. I think most of these companies
[00:58:50.680 --> 00:58:56.760]   are, they consider holding on to that information without telling you to be hot potato. You know,
[00:58:56.760 --> 00:59:01.000]   like that's not something that they, that they really want because they know it'll, you know,
[00:59:01.000 --> 00:59:06.200]   it's a lot of crypto night there. So the other thing you'll notice if you, if you've seen pictures
[00:59:06.200 --> 00:59:11.480]   sometimes of some business leaders, you'll notice that they have a headphone jack, a little thing
[00:59:11.480 --> 00:59:15.080]   that pops in their headphone jack that tells it at the headphone, but there's no mic to it. And
[00:59:15.080 --> 00:59:20.200]   they have their, their, usually their webcam taped off. Almost all of us do that have worked in this.
[00:59:20.200 --> 00:59:25.320]   This might, minds off. You know, I have another camera and minds, my webcams all get taped. And
[00:59:25.320 --> 00:59:31.560]   then I get, and then, and even like, if you look at Apple, if you do anything that asks for permission
[00:59:31.560 --> 00:59:35.960]   of that webcam, like to, to talk to it, like webcam settings or whatever, you have to restart
[00:59:35.960 --> 00:59:39.640]   your computer to use it. Like it's just Apple just immediately turns it off. So, so I think that
[00:59:39.640 --> 00:59:44.840]   there's, there's a lot of sensitivity to it. But, but even then you, again, you have business
[00:59:44.840 --> 00:59:49.400]   leaders and world leaders that will put things into it, make it to full the hardware to not
[00:59:49.400 --> 00:59:55.160]   take anything in. I have a little physical, this is a Lenovo has a little physical switch
[00:59:55.160 --> 01:00:00.120]   that I can see. Those are not mechanically going over the camera. My framework laptop has that.
[01:00:00.120 --> 01:00:05.320]   The microphone is more problematic. There's, you know, you'd have to trust it that it's
[01:00:05.320 --> 01:00:09.000]   cutting off the microphone. And again, that's why I have, I mean, I do it for convenience because I,
[01:00:09.000 --> 01:00:13.160]   I turn mine on, on and off all the time. Like, I, you know, because again, because of this mic,
[01:00:13.160 --> 01:00:16.040]   I'm constantly turning it off so I can like take a sip of tea or whatever.
[01:00:16.040 --> 01:00:21.000]   Right. Right. How about this? Companies are starting to use AI to monitor your mood
[01:00:21.000 --> 01:00:29.800]   during sales calls. This is a new kind of AI software that detects emotion. Companies like
[01:00:29.800 --> 01:00:38.440]   Unifor and Sibyl, good name, are building products that use AI. Zoom wants to do this as well.
[01:00:38.440 --> 01:00:44.440]   They've announced the plans to do this in the future to analyze the voice people's moods,
[01:00:44.440 --> 01:00:49.800]   their body language during a call to know if, you know, are they interested? Are they going to buy?
[01:00:49.800 --> 01:00:54.520]   Are they not going to buy? Sitting alongside someone's image on a camera during a virtual
[01:00:54.520 --> 01:01:00.600]   meeting, the queue for sales application, visualize, visualize emotion through a fluctuating gauge.
[01:01:00.600 --> 01:01:06.120]   You can see indicating detected levels of sentiment and engagement, kind of like those
[01:01:06.120 --> 01:01:12.440]   queue dials, TV companies used to measure your popularity based on the system's combined
[01:01:12.440 --> 01:01:18.520]   interpretation of their satisfaction, happiness, engagement, surprise, anger, disgust, fear, or sadness.
[01:01:18.520 --> 01:01:24.280]   Now, the good news is you have to turn on this video call as being recorded.
[01:01:24.280 --> 01:01:31.240]   So that would be a protection against that. What do you think? This is like a lie detector
[01:01:31.240 --> 01:01:35.800]   built in the software, Harry. I mean, at first blush, it feels like it should pretty much be
[01:01:35.800 --> 01:01:39.880]   like a no-go zone. Yeah. Particularly if this is something that
[01:01:39.880 --> 01:01:46.920]   the people doing the selling can do to us and we have no ability to do the same thing, to see how
[01:01:46.920 --> 01:01:52.920]   they're feeling and if we might be able to cut a deal or whatever. Yeah, I think that,
[01:01:52.920 --> 01:01:58.920]   particularly if it's being done without us knowing specifically that this is being done rather than
[01:01:58.920 --> 01:02:04.520]   just we're being recorded, it just sounds terrible. The Zoom one sounds slightly less bad because
[01:02:04.520 --> 01:02:11.000]   it's not real time. They're taking video afterwards and an aggregate analyzing it,
[01:02:11.000 --> 01:02:15.960]   which I also don't like, but it's not quite as terrifying. It integrates into Salesforce.
[01:02:15.960 --> 01:02:20.840]   You're going to have to have new Salesforce settings. I think about something like buying a car where
[01:02:20.840 --> 01:02:24.520]   you know all the law forever. When people have been trying to sell you a car, they're trying to
[01:02:24.520 --> 01:02:27.800]   read you and trying to figure out. Well, that's the problem. You can't read that body language
[01:02:27.800 --> 01:02:33.960]   on a Zoom call very well. Like, you know, is this person going to walk if I don't give them a better
[01:02:33.960 --> 01:02:40.520]   price? The idea they might use technology to gauge that is awful. A product from Kogato,
[01:02:40.520 --> 01:02:45.560]   this is from an article in Protocol, uses in-call voice analysis to analyze the emotional
[01:02:45.560 --> 01:02:50.840]   state of callers or service reps during customer service calls. An alert, as an example shown,
[01:02:50.840 --> 01:02:59.240]   says, "Frestration detected show empathy." The hard part is, is when people do this kind of like
[01:02:59.240 --> 01:03:04.920]   sales by numbers, it usually comes across, because the people who use it are usually people who are
[01:03:04.920 --> 01:03:09.640]   not very empathetic. So they're not very good at it. So that's why you're turning on the autopilot
[01:03:09.640 --> 01:03:12.040]   is because you don't have to do it yourself. Yeah, they work good. They would need it.
[01:03:12.040 --> 01:03:17.800]   Yeah. Exactly. We already have all these people who are, you know, when you call a service provider,
[01:03:17.800 --> 01:03:22.600]   they spend too much time telling you how much they care about your problem and how invested they
[01:03:22.600 --> 01:03:26.600]   are in solving it for you. Just solve it, please. Which has nothing to do with them actually solving
[01:03:26.600 --> 01:03:29.240]   right. Right. Right. Yeah, I agree.
[01:03:29.240 --> 01:03:35.080]   Let's add this to podcasting though, Brian. Wouldn't that be useful if you had a little button,
[01:03:35.080 --> 01:03:42.680]   boredom detected, show empathy? Well, there's a lot of areas in my life with people not caring
[01:03:42.680 --> 01:03:50.120]   what I say or what I'm talking about. I'd like to know that. But you can always, any system like
[01:03:50.120 --> 01:03:57.400]   this, they already have that for the calls to customer service because dropping F bombs and
[01:03:57.400 --> 01:04:03.240]   or saying manager, manager, manager, like, they already have the escalation stuff in terms of like,
[01:04:03.240 --> 01:04:08.280]   you know, just like, does that work? If you go manager, manager, manager, I saw a video
[01:04:08.280 --> 01:04:12.040]   a couple of times for me. It works. You just say representative. I usually just go, I pick it up.
[01:04:12.040 --> 01:04:14.520]   It's just like here, a computer, I'm like representative representative representative.
[01:04:14.520 --> 01:04:17.960]   Just keep saying until someone shows up. Push zero until something.
[01:04:18.680 --> 01:04:22.840]   Yeah, operator, operator. All right. I mean, the thing is, is that we've been doing this for,
[01:04:22.840 --> 01:04:27.000]   I mean, I know for the last 20 years, we've had eye tracking, which you do eye tracking against
[01:04:27.000 --> 01:04:32.200]   random samples. Yeah. And we did some 10 years ago, and it was the problem. It was, you know,
[01:04:32.200 --> 01:04:36.280]   you think you know what you're doing, and then you do eye tracking and it just devastated us.
[01:04:36.280 --> 01:04:39.960]   Like it was like all of the information that we thought we had. Like, for instance,
[01:04:39.960 --> 01:04:44.760]   if you talk for if you're in a presentation with someone, we did this with with folks watching a
[01:04:44.760 --> 01:04:49.560]   stream, we were doing live streaming tests. If they, we found out that if we talk from
[01:04:49.560 --> 01:04:54.920]   more than five to six minutes straight, and it, you know, as a sales call, they stop, they stop
[01:04:54.920 --> 01:04:59.880]   actively listening. They're just looking, they're doing something else. And, and if we put a slide
[01:04:59.880 --> 01:05:03.160]   up, this is, this is the worst one. If you put a slide up, you have 60 to 90 seconds before they
[01:05:03.160 --> 01:05:08.760]   stop listening to you. Wow. And, and it's like, and every time I see people putting up presentation
[01:05:08.760 --> 01:05:13.240]   slides, I'm, I'm, you know, we have all this data that we generated from it. And we just go,
[01:05:13.800 --> 01:05:18.600]   oh, they're not going to get, and I noticed myself doing it. I, someone puts up a slide in a presentation
[01:05:18.600 --> 01:05:22.280]   for more than 60, 90 seconds. I'm checking my email. I'm, I'm looking at other things. And I
[01:05:22.280 --> 01:05:25.240]   didn't think about it until I did that. And I realized I do that in person too. I mean, like,
[01:05:25.240 --> 01:05:29.960]   I'm at a seminar, slide up too long. I'll start doing other things. But it was, it was really
[01:05:29.960 --> 01:05:34.600]   interesting that data was super valuable. And we do that, we did that all through the aughts,
[01:05:34.600 --> 01:05:40.760]   you know, with ads, you know, print ads, websites, the design of websites, we would look at,
[01:05:40.760 --> 01:05:45.000]   you get 200 random samples in there, you know, random people, and it turns out they,
[01:05:45.000 --> 01:05:48.840]   the lower brain does a lot of things really fast. You could put an ad in a certain place in a page,
[01:05:48.840 --> 01:05:52.120]   and no one would even see it. And so, you know, that you just learn where, you know,
[01:05:52.120 --> 01:05:56.280]   if there's certain colors and certain things, the brain, the eyes are going to go where they're,
[01:05:56.280 --> 01:06:01.240]   you know, they're going to go a certain way and very few people will vary from that. And, and so,
[01:06:01.240 --> 01:06:05.480]   but so it was used in web design, ad design, video ad design, you know, it's, there's a lot of,
[01:06:05.480 --> 01:06:10.360]   you know, eye tracking is a, is a real thing. And that not as a certain person, because it turns
[01:06:10.360 --> 01:06:17.800]   out you don't need to, the eye tracking is pretty, you know, certain designs and colors and objects.
[01:06:17.800 --> 01:06:21.960]   We'll take the lower brain and just have a look at things, you know, and so you just got to figure
[01:06:21.960 --> 01:06:26.760]   out what that is. So it's, that's what you're doing. You're gaming the eye tracking. Look at me,
[01:06:26.760 --> 01:06:30.680]   look at me, look at me. Oh, look at what I want you to look at, absolutely. And, you know, filmmakers
[01:06:30.680 --> 01:06:37.240]   have been doing that for a century. I'm going to take this focus. When I worked on film, we would
[01:06:37.240 --> 01:06:40.840]   take things, we would take objects out of the background to make sure that you didn't, that you
[01:06:40.840 --> 01:06:44.840]   were always watching, you know, or put them back in because we want you to look over there. But,
[01:06:44.840 --> 01:06:49.240]   you know, so it's, but, but before it was all guessing, and then it became in like the early
[01:06:49.240 --> 01:06:54.360]   2000s, it became like an application that would do it. And now it used to be, it used to be a piece
[01:06:54.360 --> 01:06:58.680]   of hardware we used to use for that. And then it just became, you know, now you can get it,
[01:06:58.680 --> 01:07:05.320]   you know, with a webcam. I know how to get people's attention back. A cute fuzzy dog picture will do
[01:07:05.320 --> 01:07:11.560]   it. This tweet just is from Elon Musk. Happy Easter. Now the problem with poor Elon, now he can't just
[01:07:11.560 --> 01:07:17.000]   post a picture of a dog in a bunny outfit with Easter eggs before somebody says, well, wait a minute,
[01:07:17.000 --> 01:07:23.560]   isn't that a Shiba Inu? Is he promoting Dogecoin? What's going on? But actually that's his Shiba
[01:07:23.560 --> 01:07:28.680]   Inu, floki. And I don't know what's inside those eggs. It does look a little bit like some sort of
[01:07:28.680 --> 01:07:35.640]   crypto, but well, we'll never know. So happy Easter, everybody. Happy Passover Ramadan also.
[01:07:35.640 --> 01:07:41.080]   We are going to have more in just a moment. I can watch your eyes glazing over right now, as I say,
[01:07:41.080 --> 01:07:48.760]   it's time for a commercial. Thank you, Alex Lindsey, Brian McCullough, and Mr. Harry McCracken for being
[01:07:48.760 --> 01:07:54.440]   here. Thank you for being here our our 17th anniversary episode, no cupcakes, no balloons,
[01:07:54.440 --> 01:08:00.200]   because it's a prime number. We don't celebrate on prime number holidays. This week in tech brought
[01:08:00.200 --> 01:08:06.200]   to you today by zip recruiter. You know, there is a good trend in employment, and employment these
[01:08:06.200 --> 01:08:12.440]   days. Employers are desperate to get you back to work into the office. So according to research
[01:08:12.440 --> 01:08:18.840]   from zip recruiter, 90% of employers are making enhancing your experiences and employee a top
[01:08:18.840 --> 01:08:25.320]   priority this year. We even did it. We've we've we have now four day work weeks for all our
[01:08:25.320 --> 01:08:31.560]   employees. You can make your employees happier by considering their opinion. What is it? What
[01:08:31.560 --> 01:08:37.720]   thought focusing on company culture, offering more learning opportunities, allow for flexibility
[01:08:37.720 --> 01:08:43.480]   and work schedules, show more empathy, make time to connect. After all, a happy workplace is key
[01:08:44.120 --> 01:08:50.360]   to attracting and keeping great employees. And when you need to add more employees to your team,
[01:08:50.360 --> 01:08:58.200]   don't forget zip recruiter. Right now you can try zip recruiter free at zip recruiter.com/tuit.
[01:08:58.200 --> 01:09:04.440]   It's what we use when we need to hire. And I have to say it really works for a number of reasons.
[01:09:04.440 --> 01:09:10.280]   You post to the broadest possible audience. That's fantastic. And zip recruiters technology actually
[01:09:10.280 --> 01:09:15.240]   finds the right candidates for your job and then proactively presents them to you.
[01:09:15.240 --> 01:09:21.400]   So you you post your job in zip recruiter within minutes is going to say, hey, there's 10 people.
[01:09:21.400 --> 01:09:25.640]   We have who I know would be great for you. Would you be interested in asking them and
[01:09:25.640 --> 01:09:31.240]   where you can easily review those candidates, invite the top choices to apply. And by the way,
[01:09:31.240 --> 01:09:35.480]   when you get invited to apply for a job, you apply faster. You're more likely to take that job.
[01:09:35.480 --> 01:09:41.320]   You just feel better about that employer. It really works. No wonder zip recruiter is the number one
[01:09:41.320 --> 01:09:47.960]   rated hiring site in the US based on G2 ratings. I want you to try it. We've had such great success.
[01:09:47.960 --> 01:09:52.600]   Some of our best employees came to us through zip recruiter. Hire the right employees with zip
[01:09:52.600 --> 01:10:01.000]   recruiter. Try it free. Our exclusive address, zip recruiter.com/tuit. Zip recruiter. Z-I-P-R-E-C
[01:10:01.000 --> 01:10:08.680]   R-U-I-T-E-R, zip recruiter.com/t-W-I-T. Thank you, zip recruiter for supporting
[01:10:08.680 --> 01:10:17.720]   TWIT. Thank you for supporting it by using that very special address, zip recruiter.com/twit.
[01:10:17.720 --> 01:10:26.840]   Let's see. It's kind of was it was it a slow week, Brian? Do you notice when weeks are slow,
[01:10:26.840 --> 01:10:32.520]   you have to do news every day? Yeah, and those are the worst days because those are the days that
[01:10:32.520 --> 01:10:38.200]   it takes me the longest to put a show together. Our longest shows are when there's nothing to say
[01:10:38.200 --> 01:10:44.760]   for some reason. Alex will fouch for that on Mac break weekly. We just go into the rat hole
[01:10:44.760 --> 01:10:47.400]   and then end up in a rat cave and... Yeah, keeps on going.
[01:10:47.400 --> 01:10:56.120]   I was going to bring up... I'm just going through some of the stories.
[01:10:56.120 --> 01:10:59.080]   There's kind of it's kind of all a potpourri right now.
[01:10:59.080 --> 01:11:06.600]   A bunch of different little tidbits, TikTok launching its own AR development platform.
[01:11:06.600 --> 01:11:13.800]   Do we need AR and TikTok? I think not. Well, they already have a lot of effects. I mean,
[01:11:13.800 --> 01:11:17.080]   TikTok already has a lot of video effects they've already been doing and people use it as part of
[01:11:17.080 --> 01:11:23.160]   their kind of narratives when they build videos. It's called effect house. It would allow creators
[01:11:23.160 --> 01:11:28.680]   to build AR effects for use in the video. It's officially live now. Oh, I didn't misread that.
[01:11:28.680 --> 01:11:33.720]   So if it's actually letting developers do it, then it's more exciting because they actually...
[01:11:33.720 --> 01:11:36.760]   Oh, wouldn't that be cool? Maybe I'll just...
[01:11:36.760 --> 01:11:37.800]   So they're not just stuck with what they have.
[01:11:37.800 --> 01:11:42.440]   Create your own filters and even maybe sell them.
[01:11:42.440 --> 01:11:47.160]   Most people do, I think. Oh, good.
[01:11:47.880 --> 01:11:53.560]   Oh, I was going to say... I was moving on. Do you want to do that? I found that whole piece about
[01:11:53.560 --> 01:11:58.600]   Meta's AR and VR. As long as we're talking AR. Time table. Yeah.
[01:11:58.600 --> 01:12:04.120]   Yeah. This is from the Verge. Mark Zuckerberg's augmented reality.
[01:12:04.120 --> 01:12:11.880]   I'm actually curious what y'all think. Is Meta saying, yeah, this Facebook thing is not working out.
[01:12:11.880 --> 01:12:16.280]   So let's get this AR thing going as fast as possible.
[01:12:16.280 --> 01:12:21.640]   According to Alex Heath writing for the Verge, Meta's racing to release his first AR glasses
[01:12:21.640 --> 01:12:29.320]   in 2024. That isn't that fast a pivot, I guess maybe in the greater scheme of things two years.
[01:12:29.320 --> 01:12:33.800]   Well, in theory, Apple's whatever headset would at least be announced before.
[01:12:33.800 --> 01:12:35.880]   This year. Yeah, it might be this year.
[01:12:35.880 --> 01:12:43.240]   But I mean, we know they're spending $10 billion a year and there's 20,000 employees
[01:12:43.240 --> 01:12:47.160]   on this team or whatever the Metaverse team is.
[01:12:47.160 --> 01:12:52.920]   So it certainly sounds like this is the real deal in Zuck's mind.
[01:12:52.920 --> 01:12:57.800]   Hannah, this is from Heath again animating the push for AR and Facebook's rebranding as
[01:12:57.800 --> 01:13:01.400]   a desire by Zuckerberg to cast the company he found as innovative once again.
[01:13:01.400 --> 01:13:08.040]   People familiar with his thinking say, i.e. insiders. The social networks reputation has been
[01:13:08.040 --> 01:13:13.720]   stained by a series of privacy and content moderation scandals, which has been hurting
[01:13:13.720 --> 01:13:19.720]   employee morale and faith in leadership. So if you don't, I don't think it's good, Brian.
[01:13:19.720 --> 01:13:23.800]   Oh, I'm sorry. I'll stop because I keep cutting you off. It's good. Alex, I apologize.
[01:13:23.800 --> 01:13:28.760]   It's just zoom. It's fine. Yeah. Yeah. If you read that whole piece, it is,
[01:13:28.760 --> 01:13:36.040]   it sort of is making the same argument that we've heard people put into Apple's mouth about
[01:13:36.040 --> 01:13:42.120]   how they believe that there's a line in there that Zuck wants this to be his iPhone moment that
[01:13:42.120 --> 01:13:47.480]   they really do believe by the end of the decade that they can be selling hundreds of millions of
[01:13:47.480 --> 01:13:56.120]   these a year or whatever. So obviously Meta's overarching motivation for this is to get out
[01:13:56.120 --> 01:14:01.720]   from under the thumb of Google and Apple. But it is interesting. What I found fascinating
[01:14:01.720 --> 01:14:07.960]   about the piece is laying out the timeline where they'll have a really high end one at the beginning
[01:14:07.960 --> 01:14:14.200]   2024 is what they're claiming. And then iteration, iteration, iteration, and it's not till 2028 and
[01:14:14.200 --> 01:14:19.000]   into the next decade that they're feeling like, okay, now this will be mass adoption. So if you're
[01:14:19.000 --> 01:14:24.040]   Meta, if you're a Meta investor and they're spending $10 billion a year on this already now,
[01:14:24.040 --> 01:14:30.600]   you're looking out all the time and money and effort, you better hope that they're right at the
[01:14:30.600 --> 01:14:34.920]   end of the decade that this is the next big guy. It's bold. I mean, if you had three and a half
[01:14:34.920 --> 01:14:40.040]   billion users and you are raking and money with advertising, even with Apple's, you know,
[01:14:40.040 --> 01:14:45.480]   ATT, you're still making a ton of money and advertising. It's pretty bold to say, yeah,
[01:14:45.480 --> 01:14:51.080]   we're going to abandon this successful business and put all our money on the, you know, all our
[01:14:51.080 --> 01:14:56.440]   chips on something that is unproven that no one has really shown there's even a market for, let alone
[01:14:57.240 --> 01:15:02.040]   a successful business bond. The verge piece is great. And I actually yesterday wrote a piece
[01:15:02.040 --> 01:15:09.000]   spinning out of what Alex Heath did specifically about this idea that this is Meta wanting to
[01:15:09.000 --> 01:15:15.320]   create a iPhone moment. The next big thing. There have hardly been any iPhone moments other than the
[01:15:15.320 --> 01:15:22.600]   iPhone in tech history. B, this really speaks to something deep, I think, in Mark Zuckerberg,
[01:15:22.600 --> 01:15:28.440]   which is not just me psychoanalyzing him. It's also based on the fact that in 2015, I did a big
[01:15:28.440 --> 01:15:36.200]   story on what was then Facebook. And he told me that like one of his few disappointments was that
[01:15:36.200 --> 01:15:40.120]   Facebook never got to have its own mobile operating system.
[01:15:40.120 --> 01:15:44.680]   Operating system. So it always said Facebook phone.
[01:15:44.680 --> 01:15:50.120]   Facebook always said is a layer on top of the iPhone or an Android phone.
[01:15:50.760 --> 01:15:56.920]   And so as successful as Facebook is, it is not successful enough to match Mark's ambition.
[01:15:56.920 --> 01:16:01.640]   Right. And also, the problem is with it not controlling an operating system
[01:16:01.640 --> 01:16:09.800]   really came to four last year when Apple rolled out the application tracking transparency,
[01:16:09.800 --> 01:16:15.480]   which lets the user say, yes, it's okay for this app to track me or no, they're not allowed to track
[01:16:15.480 --> 01:16:21.560]   me. And then, you know, Metas has us going to lose billions and billions of dollars this year,
[01:16:21.560 --> 01:16:25.560]   because Apple has made it extremely easy for users.
[01:16:25.560 --> 01:16:26.760]   Yeah, 10 billion this year.
[01:16:26.760 --> 01:16:28.600]   At least that much that year. Yeah.
[01:16:28.600 --> 01:16:35.640]   Back in 2015, his concerns were extremely reasonable from his standpoint. And the downside of not
[01:16:35.640 --> 01:16:41.800]   controlling your own platform is still playing out for them. And there's a pretty decent chance
[01:16:41.800 --> 01:16:48.280]   that if AR does become something big, it will become a battle between whatever Apple comes up with
[01:16:48.280 --> 01:16:52.440]   and whatever Meta comes up with. And if you were Mark Zuckerberg, wouldn't you be deeply
[01:16:52.440 --> 01:16:58.200]   concerned by the possibility that Apple will have the iPhone moment of AR and he might be
[01:16:58.200 --> 01:17:03.720]   stuck in the same situation. He has been all these years of having to do things the way Apple
[01:17:03.720 --> 01:17:04.680]   wants him to do them.
[01:17:04.680 --> 01:17:10.200]   I it's extremely bold. He, you know, obviously he's a smart fella. He knows about the innovators
[01:17:10.200 --> 01:17:15.240]   dilemma. And normally a company like Meta would rest on its laurels and try to kind of
[01:17:15.240 --> 01:17:19.400]   dribble out something that might be your next thing, but still continue to support the current
[01:17:19.400 --> 01:17:23.880]   thing. He sounds like he's saying, I'm going to cut through that. And I am going to take a massive
[01:17:23.880 --> 01:17:31.400]   gamble. I'm going all in on AR, even though it's going to take me years 10 billion a year,
[01:17:31.400 --> 01:17:35.080]   18,000 employees. And it's an
[01:17:35.080 --> 01:17:39.720]   untrue thing. I remember this is the whole metaverse. Yeah, you're you're giving it short
[01:17:39.720 --> 01:17:44.680]   trip by just saying AR. Remember that. Well, but the primary technology that has to work is
[01:17:44.680 --> 01:17:47.800]   is AR VR, right? If that doesn't work, you got nothing.
[01:17:47.800 --> 01:17:53.320]   It's a it's a really hard problem. It's also a really hard problem. I mean,
[01:17:53.320 --> 01:18:02.200]   I think that that Zuckerberg's history with this is pro is related to reading ready player one.
[01:18:03.080 --> 01:18:06.760]   And well, remember those bought on those rifts for a lot of money about
[01:18:06.760 --> 01:18:11.080]   Oculus. Right. But I'm saying he read ready player one. I think he saw I think that he has
[01:18:11.080 --> 01:18:17.400]   he may have seen a future that Facebook could really be part of, you know, like that that it's
[01:18:17.400 --> 01:18:22.760]   an all encompassing experience of a different world. And then bought Oculus because it's the
[01:18:22.760 --> 01:18:28.920]   closest thing to what was going on. And you know, it's it's a it's a really hard problem to
[01:18:28.920 --> 01:18:33.960]   a lot of it has to do with there's a bunch of problems with it. I worked in full disclosure.
[01:18:33.960 --> 01:18:40.120]   I mean, I did a lot of the initial 360 video stuff for Facebook. So I'm I'm
[01:18:40.120 --> 01:18:48.600]   thought about this a lot. And the the thing is is that the 360 video that's when we were doing,
[01:18:48.600 --> 01:18:52.280]   you know, that that ozo that I brought to your house to your office. That's what I was doing.
[01:18:52.280 --> 01:18:56.920]   We were doing a lot of the early stuff in that area. And the hard part, the first really hard
[01:18:56.920 --> 01:19:01.240]   part is is resolution resolution and frame rate. So you have to get that resolution and takes
[01:19:01.240 --> 01:19:07.480]   an enormous amount of data to do that well. You know, so we were playing with 4k 30, but you really
[01:19:07.480 --> 01:19:13.240]   need to get to 8k 120 to really have it do what it needs to do. And that would require a lot of
[01:19:13.240 --> 01:19:19.480]   chip like an M1 chip just to do that, you know, and so so anyway, so it's a it's a
[01:19:19.480 --> 01:19:23.080]   it's a problem. Do that on your head. Do that on your head and probably it'd be very hard.
[01:19:23.080 --> 01:19:27.400]   It does kind of explain why Apple's gone all in on this low power high efficiency.
[01:19:27.400 --> 01:19:31.960]   She makes a lot of sense. Yeah. Yeah. And so that if you're going to make a advisor work.
[01:19:31.960 --> 01:19:38.680]   This I like the I did a story recently too that said, and I'm breaking my promise not to interrupt
[01:19:38.680 --> 01:19:43.480]   you that. Okay. Even if you saw it's a better show if we all interrupt each other. Trust me.
[01:19:43.480 --> 01:19:50.280]   If you if you solve the hardware and the the compute stuff, you know, on the user,
[01:19:51.400 --> 01:19:57.400]   I did a story maybe was a couple months ago that said someone was pointing out that we don't have
[01:19:57.400 --> 01:20:05.320]   the infrastructure to beam all of the stuff that is required to do sort of like a really immersive
[01:20:05.320 --> 01:20:11.480]   a really convincing metaverse because even if you saw all of the local hardware and compute problems,
[01:20:11.480 --> 01:20:17.720]   we don't have it's it's it's so far beyond what 5g or 8g or anything could do that that even if
[01:20:17.720 --> 01:20:21.080]   you solve this problem by the end of the decade, you might not have the infrastructure in place
[01:20:21.080 --> 01:20:26.200]   to make it real. Yeah, kind of. I mean, so if you're doing video, absolutely, if you're doing so,
[01:20:26.200 --> 01:20:29.960]   if you're if you're taking it, I want to do servers offsite or whatever, because you really are,
[01:20:29.960 --> 01:20:34.760]   like if you're doing 8k 120 per eye, you're talking hundreds of megabits per second that need to be
[01:20:34.760 --> 01:20:39.640]   delivered to you. But but the geometry, if you send the geometry to it, that doesn't you know,
[01:20:39.640 --> 01:20:43.640]   you can send very high resolution geometry for an entire world. And maybe that takes a little bit
[01:20:43.640 --> 01:20:48.520]   of time. But then once there, what you need is GPU and CPU power to render it. So if you're
[01:20:48.520 --> 01:20:52.040]   rendering it remotely, you're absolutely right. If you're rendering it locally, it doesn't it can
[01:20:52.040 --> 01:20:56.360]   be a lot of geometry that it has to manage, but it might be 3040, maybe 100 million polygons or
[01:20:56.360 --> 01:21:00.040]   something like that. And you can you can work inside of that. And then what you do is we we take
[01:21:00.040 --> 01:21:05.000]   level what we call level of detail LODs. And so basically things off in the distance don't have
[01:21:05.000 --> 01:21:09.320]   very much geometry things and close to you have a lot of geometry and better textures and all
[01:21:09.320 --> 01:21:13.080]   those other things. And so that you can kind of wander around in them. The bigger problem than all
[01:21:13.080 --> 01:21:17.400]   of the technical problems is the difference between what people feel what they think they're
[01:21:17.400 --> 01:21:21.080]   experiencing and what they feel that they're experiencing. So there's like a frontal lobe
[01:21:21.080 --> 01:21:25.000]   lower brain problem, which is that if they feel like they're in something that is
[01:21:25.000 --> 01:21:29.160]   that is real and then their lower brain says, I'm not getting what I need, the delta between those
[01:21:29.160 --> 01:21:33.560]   two is depression. You know, and that's what we see in life. Yeah. You know, so so basically,
[01:21:33.560 --> 01:21:37.960]   people get their their they're basically filling their their their
[01:21:37.960 --> 01:21:44.920]   saying VR makes you sad. Well, social media makes you sad. So you think you're you think you're in
[01:21:44.920 --> 01:21:49.000]   a community, but you're not. And so what happens is you get depressed. Because you're
[01:21:49.000 --> 01:21:52.760]   feel you keep on going to Twitter and Facebook looking for this is where my friends are going to
[01:21:52.760 --> 01:21:56.520]   be. And you keep on pulling it all in. But there's no fulfillment. It's kind of like, you know,
[01:21:56.520 --> 01:22:01.160]   the easiest way to kill ants is to feed them a splenda. You just put sugar out and you slowly
[01:22:01.160 --> 01:22:04.680]   cut it with splenda and they can't tell the difference and they just start to death. And so the so the
[01:22:04.680 --> 01:22:11.720]   yeah, go ahead. One more thing though, like, okay, we're we're talking about like all of this money
[01:22:11.720 --> 01:22:16.280]   spent in and Leo said this is a bold bet. It is a bold bet. And maybe it's something that they
[01:22:16.280 --> 01:22:22.120]   have to do because maybe social media is a thing that's on the downturn. But aside from will the
[01:22:22.120 --> 01:22:27.320]   technology work out? Will it be adapted? Will the infrastructure be there? There's one more big thing
[01:22:27.320 --> 01:22:33.400]   is will people want it from Mark Zuckerberg? Like that to me, no, that's a huge biggest risk.
[01:22:33.400 --> 01:22:38.840]   Yeah, but what choice does Mark have? I mean, it's he's he's Mark Zuckerberg. He is Mark Zuckerberg.
[01:22:38.840 --> 01:22:44.840]   So he can't really, you know, I mean, I think actually this may be you. Alex Heath makes a very
[01:22:44.840 --> 01:22:49.400]   good argument for this being the boldest bet we've ever seen in technology. Apple with all of its
[01:22:49.400 --> 01:22:55.560]   investment in AR and they're all in on it is still selling the iPhone. That's still their main business.
[01:22:55.560 --> 01:23:02.360]   This is this is really a I think unprecedented willingness to take a giant risk. And I have to
[01:23:02.360 --> 01:23:07.480]   praise Zuckerberg for that. And yeah, he's stuck with himself. There's nothing he could do about
[01:23:07.480 --> 01:23:13.480]   it. He's got to be people will get over that. If it's a good if it's a good enough technology,
[01:23:13.480 --> 01:23:17.000]   if it's really good, people will get over that. Don't know.
[01:23:17.000 --> 01:23:24.120]   Oculus is an interesting case study because, you know, by any standard, it is the dominant VR platform.
[01:23:24.120 --> 01:23:28.360]   The quest right now is number one. They sold a lot. They have 78% of the market. Yeah,
[01:23:28.360 --> 01:23:34.840]   it's done really well. And yet it hasn't really had an iPhone moment. If that means that like
[01:23:34.840 --> 01:23:38.520]   practically everybody has one, VR is still really far from that.
[01:23:38.520 --> 01:23:42.520]   Despite all the other things. There's also a problem with the quest, which is that it's set a
[01:23:42.520 --> 01:23:47.880]   price point of $2.99. It's going to be very hard for him to create something anywhere near that
[01:23:47.880 --> 01:23:52.200]   price point. They're putting some incredibly pricey technology into these AR headsets.
[01:23:52.200 --> 01:23:57.000]   Yeah, I think that the other issue is just content is hard to make. Like there's not that
[01:23:57.000 --> 01:24:03.480]   many compelling things to do. I have a quest, of course, and I just thought that much to play.
[01:24:03.480 --> 01:24:07.960]   And then the other big problem for the quest, this is a really interesting problem is the
[01:24:07.960 --> 01:24:13.880]   quest doesn't have a diopter. You can't change the focus on it. And the old Samsung gears did.
[01:24:13.880 --> 01:24:20.600]   A lot of us that would use the quest wear glasses. So the problem is that you have to either ruin
[01:24:20.600 --> 01:24:25.400]   your glasses or you have to get the special things for them to, you know, the lenses for them to
[01:24:25.400 --> 01:24:30.200]   work. And then someone else has to pop out other lenses. The ability not, I stopped using it,
[01:24:30.200 --> 01:24:35.880]   like my kids use it. I just was like, I'm tired of dealing with this. And so I barely use the
[01:24:35.880 --> 01:24:42.040]   quest. But I think that there's a huge crossover of geeks and glasses. And so I think that's
[01:24:42.040 --> 01:24:44.520]   something they're running up against. It'll be interesting to see how people handle it.
[01:24:44.520 --> 01:24:47.960]   Because I know that I would always prefer to use the gear because I could take my glasses,
[01:24:47.960 --> 01:24:51.080]   I'll throw it on and just scroll a little wheel until everything was in focus.
[01:24:51.080 --> 01:24:53.800]   My glasses don't fit inside the quest too.
[01:24:53.800 --> 01:24:59.160]   Yeah, not comfortably. And if you have nice glasses, it'll destroy them. It just destroys their
[01:24:59.160 --> 01:25:03.560]   glasses slowly. Your glasses slowly. So you have to put the lenses in or you have to destroy,
[01:25:03.560 --> 01:25:07.880]   have a glass, basically cheap glasses you buy out of, you know, some online thing that you wear.
[01:25:07.880 --> 01:25:15.400]   This is one of dozens of problems with a RVR. It makes people nauseous, not the least of which.
[01:25:15.400 --> 01:25:18.760]   Well, so how are we going to overcome all that?
[01:25:18.760 --> 01:25:25.640]   Well, the, the, the, the, the, the, but that's again why I think Apple is probably spending more time.
[01:25:26.200 --> 01:25:31.400]   Apple has a tendency to be a lot more methodical about the process. And so, and they are, I mean,
[01:25:31.400 --> 01:25:36.520]   the, I'm clearly what Facebook's plan is just to throw as much money and manpower against it.
[01:25:36.520 --> 01:25:40.600]   And I don't think having 18,000 people working on it is going to give you any heads start
[01:25:40.600 --> 01:25:46.120]   compared to anybody else. But you have my hurt. But like you see, a lot of the upgrades that
[01:25:46.120 --> 01:25:51.320]   Apple's doing to Final Cut and Motion are not for video. They are for AR and VR. Yeah. You know,
[01:25:51.320 --> 01:25:55.640]   there are 360 solutions in there. They're building those. Well, Apple's doing an incremental thing,
[01:25:55.640 --> 01:25:59.720]   which is very interesting, right? Everything Apple does is building towards, it looks like
[01:25:59.720 --> 01:26:03.960]   building towards this kind of a future. I guess you could kind of stay with the acquisition of Oculus
[01:26:03.960 --> 01:26:09.880]   with the release of the Facebook Raybank glasses with the release of the Quest Apple.
[01:26:09.880 --> 01:26:13.560]   I mean, Mike, I've met is slowly moving in that direction, but not, it doesn't feel like the
[01:26:13.560 --> 01:26:17.720]   same kind of incrementalism as Apple. Apple has a different approach to this. They're not
[01:26:17.720 --> 01:26:23.640]   betting the farm on this. The Raybans, it did not sell as well as anybody expected.
[01:26:23.640 --> 01:26:28.840]   Yeah. I mean, the marketplace has said again and again, we don't want this, I think.
[01:26:28.840 --> 01:26:35.000]   Well, what Alex said about content is actually the key because they don't need an iPhone moment.
[01:26:35.000 --> 01:26:41.880]   They need a Fortnite moment. Like they need something like that that is a real killer app.
[01:26:41.880 --> 01:26:43.240]   A killer app. Right. Yeah.
[01:26:43.240 --> 01:26:47.080]   And I'm reinventing the wheel. Yeah. Yeah.
[01:26:47.080 --> 01:26:51.800]   And what's funny is the killer app before this was still from Epic Games, it was Robo Recall.
[01:26:51.800 --> 01:26:54.840]   Robo Recall is probably still one of the best games that was built for Oculus.
[01:26:54.840 --> 01:27:00.680]   And it was really immersive and really fun to play. And they haven't really reproduced that
[01:27:00.680 --> 01:27:04.920]   again. You know, like it was like, okay, once you beat it, it's kind of like, okay, now what do I do?
[01:27:04.920 --> 01:27:08.600]   But because you go out and play other games and they just weren't as good. And so, and they
[01:27:08.600 --> 01:27:12.680]   commissioned that. I mean, Oculus commissioned that from Epic or whatever. And so, so it was a
[01:27:12.680 --> 01:27:18.680]   great, it was basically a first person shooter with robots and really, really, really well-made
[01:27:18.680 --> 01:27:20.840]   game. So, and so yeah.
[01:27:20.840 --> 01:27:28.120]   God. When we celebrate our 27th anniversary doing 10 years from now, Brian, what's your
[01:27:28.120 --> 01:27:35.560]   prediction? Will AR from Meta be the hot new thing? Will we be doing this show in a Metaverse?
[01:27:35.560 --> 01:27:40.360]   What's the date you're saying? Oh, I don't know. 10 years out. You can, you can choose an arbitrary
[01:27:40.360 --> 01:27:43.080]   year. 20, 2032. Okay. Yeah.
[01:27:44.440 --> 01:27:48.360]   Which sounds like the future. But as we know, it'll be here any minute.
[01:27:48.360 --> 01:27:52.200]   Okay. So let's imagine that instead of us being on screens, we're all sitting around the table.
[01:27:52.200 --> 01:27:57.560]   And then every listener slash viewer is seated at a chair with us so they can look around at our
[01:27:57.560 --> 01:28:02.760]   face. I love that. Is that going to be real 10 years from now? Yeah. I don't know. Is it?
[01:28:02.760 --> 01:28:11.080]   I don't think so. Okay. But Alex would know better than me. And certainly Harry maybe has.
[01:28:11.080 --> 01:28:14.360]   Well, there's a, we don't know if the technology's there. We don't know if it'll be Facebook doing
[01:28:14.360 --> 01:28:20.600]   it. We don't know. There's a lot we don't know, but predictions. The worst part is that it's
[01:28:20.600 --> 01:28:24.360]   much hard. It'll get it'll get worse before it gets better because right now nothing looks real.
[01:28:24.360 --> 01:28:29.640]   When we get to the uncanny valley, it's going to be ugly. You know, like it's going to be that
[01:28:29.640 --> 01:28:34.280]   uncanny. It's really hard to get through. I'll end with millions and millions of dollars still
[01:28:34.280 --> 01:28:39.480]   can't do Princess Leia. And that's not in real time. That's just in all of the, I think Facebook
[01:28:39.480 --> 01:28:44.440]   knows this or meta knows this because in all of their samples, the people are kind of ghostly.
[01:28:44.440 --> 01:28:49.000]   They're faded out to avoid that uncanny valley experience. But they don't have legs. You know,
[01:28:49.000 --> 01:28:53.720]   that you it's very clear. They're not trying to be human. Maybe we'll have cartoon avatars.
[01:28:53.720 --> 01:28:57.320]   It is. But the problem is, is that there is so much that goes on in our, I mean,
[01:28:57.320 --> 01:29:01.640]   someone who I've done, you know, hours and hours of facial animation for projects,
[01:29:01.640 --> 01:29:07.000]   there is so much a human face does, but that is so complex. And I think that the problem is when
[01:29:07.000 --> 01:29:11.880]   you don't have all of that information, it's kind of soul sucking, you know, to always be looking at
[01:29:11.880 --> 01:29:16.200]   something that is a rough facsimile of the real thing. It's part of why I think people get zoom
[01:29:16.200 --> 01:29:20.040]   fatigues because they have good cameras. They don't have good audio. So they're looking at these
[01:29:20.040 --> 01:29:24.600]   hazy faces and their brain is doing, there's all this cognitive load of the brain sitting there
[01:29:24.600 --> 01:29:27.880]   trying to figure out what it's looking at and what it's hearing because people have bad audio
[01:29:27.880 --> 01:29:31.720]   and bad video on office hours. We stay on for hours. It doesn't bother us at all because
[01:29:31.720 --> 01:29:35.560]   everybody's got a good mic and a good camera. So, the thing is, is that go ahead.
[01:29:36.120 --> 01:29:42.040]   How do you solve the problem of, you know, I think Zuck's sort of killer app is you put it on and
[01:29:42.040 --> 01:29:47.320]   you can talk to grandma and it feels like grandma is sitting on the couch across from you. I kind of
[01:29:47.320 --> 01:29:53.400]   have that with FaceTime right now. But how would you map grandma's face? I know that all of these
[01:29:53.400 --> 01:29:59.080]   cameras have like, like if we did, if we did Leo's thing for 10 years from now, we could be,
[01:29:59.080 --> 01:30:03.800]   have, you know, studios and cameras pointed at us. And I know that that all sorts of these headsets
[01:30:03.800 --> 01:30:09.320]   now have outward facing cameras and all these things. And but like, how do you solve the problem of
[01:30:09.320 --> 01:30:13.400]   if I'm really going, the uncanny value of if I'm really going to feel like I'm talking to grandma
[01:30:13.400 --> 01:30:18.280]   sitting across from me, how do you map what her face is doing in real time if she's got a headset
[01:30:18.280 --> 01:30:22.200]   on? You're making assumptions based on what you're seeing the rest of the face and it won't be
[01:30:22.200 --> 01:30:26.040]   accurate and it'll feel really weird. It's going to feel really weird. Like it's not going to,
[01:30:26.040 --> 01:30:29.400]   you know, and it's going to take a long time to get that right, which is why Apple smartly keeps
[01:30:29.400 --> 01:30:33.320]   on talking about AR because AR is adding things to the world that you already have. It's not
[01:30:33.800 --> 01:30:39.640]   well, how long does Harry, how long does meta have? They do they have 10 years? That's if they're
[01:30:39.640 --> 01:30:45.160]   spending that much money every year, well, theoretically, they have a really long runway because they
[01:30:45.160 --> 01:30:52.120]   are have historically gushed money, but they can't be sure that will go on forever. If
[01:30:52.120 --> 01:30:58.120]   if their conventional business starts to collapse, they might have a much more limited ability to
[01:30:58.120 --> 01:31:04.280]   they have 10 years stuff. And I still really feel like if if this kind of AR and the metaverse really
[01:31:04.280 --> 01:31:08.840]   is real in the 2030s and we're sitting around talking about it, it's there's a very high chance
[01:31:08.840 --> 01:31:14.520]   that companies won't we'll be talking about are not meta or Apple or even any company that exists
[01:31:14.520 --> 01:31:20.280]   right now. Historically, it's been pretty rare for the second street to work that way. Apple has
[01:31:20.280 --> 01:31:24.920]   been like one of the the few really big exceptions that they've been able to ride more than one wave.
[01:31:26.200 --> 01:31:31.880]   There's not would not be a lot of precedent if if meta can go from social networking in its
[01:31:31.880 --> 01:31:36.840]   historic form, the kind of stuff we're talking about now. And I can assure you, Mark Zuckerberg
[01:31:36.840 --> 01:31:43.400]   knows everything we've just said, absolutely, and is still putting his money right out there and
[01:31:43.400 --> 01:31:48.280]   saying we're going to do it anyway. And we'll either make it or there will be no meta in 10 years,
[01:31:48.280 --> 01:31:52.920]   but we're going to do it. We're going to try. But but but with his revenue, 10 billion dollars a
[01:31:52.920 --> 01:31:57.880]   year is not a minute. It's not putting it's not going all in. It's like one chip off the pile,
[01:31:57.880 --> 01:32:02.360]   you know, to do this. And so I think that they can continue to work on a lot of different business
[01:32:02.360 --> 01:32:05.320]   models because they've got a lot of revenue coming in. And I don't think that's going to go anywhere.
[01:32:05.320 --> 01:32:11.240]   It's the social media is a pretty I mean, Facebook's a pretty sticky thing. And even with some of the
[01:32:11.240 --> 01:32:16.280]   search stuff not working and costing them some money, it is when you do Facebook advertising,
[01:32:16.280 --> 01:32:20.760]   it is like looking into this both Facebook and Google, it's like looking into the sun. I mean,
[01:32:20.760 --> 01:32:25.560]   it is there is so much when you have meetings when you're meetings with folks, they're like,
[01:32:25.560 --> 01:32:29.240]   so what's your multiplier and multiplier is how much? How many dollars do you bring in versus
[01:32:29.240 --> 01:32:32.760]   the dollar you put into the Facebook and it's usually like, you know, three, four, six, yeah,
[01:32:32.760 --> 01:32:36.760]   we used to say our line now it's multiplier, which give you some but it's a multiple. It's not 30%.
[01:32:36.760 --> 01:32:43.320]   So so if you if you if you understand how to, you know, and that's why all those that's why
[01:32:43.320 --> 01:32:47.800]   all those tracking bits are important because it shows the effectiveness, the ad and you know,
[01:32:47.800 --> 01:32:52.600]   it's not trying to track you to do things and so in how how can the the ad do I'm glad you brought
[01:32:52.600 --> 01:32:58.200]   this up, Brian, because I this is a I think Alex Heath discerns a lot of credit. He clearly did a ton
[01:32:58.200 --> 01:33:04.120]   of research and digging on this and it is a fascinating story in the verge Mark Zuckerberg's
[01:33:04.120 --> 01:33:12.360]   augmented reality. And I think it really is a big question. And I I applaud Zucks willingness
[01:33:12.360 --> 01:33:16.520]   to take a big chance. You're right. It's not gonna. I guess it's not make a break for meta.
[01:33:17.240 --> 01:33:23.560]   Feels like it feels like they're willing to kind of ignore their core business to some extent to
[01:33:23.560 --> 01:33:27.960]   make it. I don't think you're ignoring it. I mean, yeah, no Cheryl's doing that. We got
[01:33:27.960 --> 01:33:31.960]   sure a lot of people take care of it. And that line that you read Leo about
[01:33:31.960 --> 01:33:39.160]   seeming relevant and attracting talent. That's the immediate they need to keep the engineers
[01:33:39.160 --> 01:33:44.920]   exactly flowing. Yeah. That's a huge issue, isn't it? Well, and that's that's when you've seen the
[01:33:44.920 --> 01:33:49.800]   dance with with the Google, Facebook, Apple, all habits are dancing around this kind of work from
[01:33:49.800 --> 01:33:54.120]   home problem because a lot of the folks that I know that work in those companies, they're like,
[01:33:54.120 --> 01:33:58.360]   if I have to go back to work, I'm not going to quit, but I am going to make sure my my LinkedIn is
[01:33:58.360 --> 01:34:04.440]   really shiny. You know, so yeah, up to date and ready to go because it's making them all that
[01:34:04.440 --> 01:34:09.160]   seems to be right now. The big thing is is whether they get to whether they have to go into the office
[01:34:09.160 --> 01:34:16.440]   all the time. And that's a fascinating shift in the labor workforce that is unprecedented,
[01:34:16.440 --> 01:34:21.320]   I think, which you can Henry Ford didn't have to fight off.
[01:34:21.320 --> 01:34:28.840]   Engineers who said, hey, you do what we say or we're walking off the floor.
[01:34:28.840 --> 01:34:34.200]   Well, there's a constraint supply of engineers. That's the that I mean, that's the real issue.
[01:34:34.200 --> 01:34:41.640]   And it's a highly, highly skilled occupation, right? But it's also it takes years to develop it.
[01:34:41.640 --> 01:34:46.040]   That's why you have things like grow with Google is like, we need more people faster.
[01:34:46.040 --> 01:34:53.400]   And I firmly believe I may be wrong that there is a small percentage of engineers who can get all
[01:34:53.400 --> 01:35:01.480]   that training and still be the top talent, right? To design a new chip or design at AR headset
[01:35:01.480 --> 01:35:07.160]   that's lightweight and works in battery life is all day, that you could train a thousand people
[01:35:07.160 --> 01:35:10.440]   and you might only get one or two that are really capable of that, right?
[01:35:10.440 --> 01:35:16.120]   I feel very certain that if there's all these big companies in FANG, there's probably 100 people
[01:35:16.120 --> 01:35:20.360]   that if you pull them out of the company would collapse. Yeah. Like, you know, we tend to refer
[01:35:20.360 --> 01:35:24.280]   to them as linchpins. Right. Oh, that's persons a linchpin. Yeah, I totally like that. Like you
[01:35:24.280 --> 01:35:27.880]   pay attention to that person because they're a linchpin to the company because, you know, they
[01:35:28.680 --> 01:35:33.960]   a lot of them tend to have very nebulous jobs and they just kind of are in a lot of teams kind of
[01:35:33.960 --> 01:35:39.960]   just gluing things together and and they get a lot of stuff. They get a lot of stuff.
[01:35:39.960 --> 01:35:46.680]   So, so, you know, to the golden the golden handcuffs are very thick. Sometimes they call it and some
[01:35:46.680 --> 01:35:53.160]   say it's a myth that 10x programmer attacks, which is why I have an 18,000 people. Doesn't mean anything.
[01:35:53.160 --> 01:35:55.720]   Yeah. Maybe the mythical man months. Yeah.
[01:35:57.160 --> 01:36:00.280]   There aren't a lot of you. You have a lot of you. You have a higher, no matter how much money you
[01:36:00.280 --> 01:36:06.040]   have. Yeah. But you don't want to lose the five or 10 and you've got to inspire them with the
[01:36:06.040 --> 01:36:11.560]   company's vision and this is probably a part of that. And Meta has had an issue with losing some
[01:36:11.560 --> 01:36:16.040]   of its brain power. I mean, a lot of good people have left for obvious reasons. Alex, you have,
[01:36:16.040 --> 01:36:22.600]   you have people, you know, people are still at Meta. We won't name names. Do they seem satisfied
[01:36:22.600 --> 01:36:26.120]   with the direction the company's taking or are they just kind of sitting on their options and
[01:36:26.760 --> 01:36:33.080]   hoping to catch up? The folks that I know it at Meta seem pretty, they get to work on fun things.
[01:36:33.080 --> 01:36:37.560]   Yeah. They don't really, they don't think about, I have to admit, they don't, I don't get the
[01:36:37.560 --> 01:36:41.000]   impression that they're thinking about the big picture of Meta or Facebook or anything else.
[01:36:41.000 --> 01:36:45.080]   No, they like their job. Yeah. When they get up every morning, they get to work on something
[01:36:45.080 --> 01:36:48.680]   really cool and occasionally they have to deal with the politics of a big company.
[01:36:48.680 --> 01:36:51.960]   And then they get to go back to working on something really cool where they get paid a lot of money
[01:36:51.960 --> 01:36:55.960]   to do something that's really fun. And that's what they care about. They don't think, you know, and so,
[01:36:55.960 --> 01:37:02.120]   you know, I met a guy is in the release to production department and he just loves it.
[01:37:02.120 --> 01:37:05.800]   He doesn't care. It's not none of that stuff is an issue because he gets to work with new stuff
[01:37:05.800 --> 01:37:10.760]   and get it ready and release to production. And that's for him, the dream job. So he is not thinking.
[01:37:10.760 --> 01:37:16.200]   But I mean, I mean, if you're in the R&D in the R&D, most of the folks I know are doing R&D is fun.
[01:37:16.200 --> 01:37:19.960]   You get to order, you get to order whatever you want, you get to play, you know, do whatever you
[01:37:19.960 --> 01:37:24.040]   will. And I've compensated that you're not, you know, 10 to move on.
[01:37:24.040 --> 01:37:27.160]   The company buys all the things that you would have bought for yourself.
[01:37:27.160 --> 01:37:30.680]   So they buy them so that you can keep on because the people who are working in that area are so
[01:37:30.680 --> 01:37:34.360]   passionate about what they're doing. They just love the fact that they can go out and, you know,
[01:37:34.360 --> 01:37:37.240]   order, oh, I'm going to order an $80,000 camera so we can see if this will work.
[01:37:37.240 --> 01:37:41.640]   Like, you know, I have a city in my apartment, you know, like, like, so I can figure out like
[01:37:41.640 --> 01:37:45.480]   whether this is and, you know, and all of that stuff is happening right now. And, you know,
[01:37:45.480 --> 01:37:49.480]   and so that's a lot of really so we think of it as a big number, but it's a big, there are a lot
[01:37:49.480 --> 01:37:53.320]   of people that are really passionate about what they're doing and they're in some really cool areas,
[01:37:53.320 --> 01:37:55.880]   you know, to do it. They're not doing the grind or dealing with the customers.
[01:37:55.880 --> 01:38:01.080]   Yeah, I agree. And they're not thinking about all these other issues. The Francis Hogg and
[01:38:01.080 --> 01:38:04.440]   Whistleblower and all that stuff. It's not an issue. Yeah. Yeah. They're not, they're not
[01:38:04.440 --> 01:38:09.720]   thinking about it all. It's very hard for us, me, not you, because you work with these companies.
[01:38:09.720 --> 01:38:13.560]   But for journalists on the outside of Harry, I'm sure you kind of have this experience
[01:38:13.560 --> 01:38:17.560]   to really understand how, what it's like inside a company like that. I'm sure you do a lot of
[01:38:17.560 --> 01:38:23.800]   interviews. You try to understand. I think about Microsoft, Google, Apple, Facebook, these companies
[01:38:23.800 --> 01:38:30.600]   we cover day in, day out. It's hard to know. We, I think we often anthropomorphize them
[01:38:30.600 --> 01:38:35.640]   and act like they're act like they're humans. They're not. They're very different from that.
[01:38:35.640 --> 01:38:40.040]   They're enormous. And a lot of them, we just don't see, you certainly won't see them if you just go
[01:38:40.040 --> 01:38:44.840]   through the official channels, which is why it's valuable to run into people who work at companies
[01:38:44.840 --> 01:38:51.160]   who have not been presented to you by the PR department or the company in question.
[01:38:51.160 --> 01:38:56.440]   I still want an RTP sticker. I'm, I'll put it on my laptop. I'm just saying. Brian, you,
[01:38:56.440 --> 01:39:01.960]   do you have that same experience? That this is journalists in tech covering it from the outside.
[01:39:01.960 --> 01:39:06.840]   We, I think sometimes we forget what's, whether it's like to be on the inside.
[01:39:06.840 --> 01:39:12.920]   Well, and then one of the things that we haven't touched on is also the generational thing,
[01:39:12.920 --> 01:39:17.560]   which all of these companies are very attuned to as well, where, you know,
[01:39:17.560 --> 01:39:23.640]   not just generational. Oh, what are, what is a 19 year old interested in? But, you know, look,
[01:39:23.640 --> 01:39:29.400]   all the crypto stuff and, and things like that. Like, if you're not the exciting place that people
[01:39:29.400 --> 01:39:36.200]   want to work at when the next big thing happens, that's also the thing that they're deathly afraid
[01:39:36.200 --> 01:39:40.840]   of and, and reputationally. And that's where the zuck quote about like, you know, being relevant
[01:39:40.840 --> 01:39:47.720]   again and things like. So that if, if what zuck wants to do is he wants to go find the hottest
[01:39:47.720 --> 01:39:51.400]   engineer or the hottest talent in the NFT space and be like, well, by the way,
[01:39:51.400 --> 01:39:55.720]   NFTs are going to be a part of the metaverse and a part of what we're doing in AR and B2.
[01:39:55.720 --> 01:40:00.520]   So why don't you lead that team? He needs to, he needs to, when he makes that offer to whoever that
[01:40:00.520 --> 01:40:07.480]   person is, he needs her to be like, yeah, I want to work with you. I want to, I want to build this
[01:40:07.480 --> 01:40:12.280]   for meta as opposed to, well, I could build it for Apple or I could start my own company. That's
[01:40:12.280 --> 01:40:15.880]   always what they're starting your own company. Right. That's if you're coming out of school.
[01:40:15.880 --> 01:40:20.120]   That's the first thing you would think of. I would. Well, the big thing though is that it's easier to
[01:40:20.120 --> 01:40:23.800]   start your own company once you've worked at one of the big companies. You know, you come out of,
[01:40:23.800 --> 01:40:27.880]   you know, oh, I worked at Apple for two years or whatever. That's right. It goes a long way.
[01:40:27.880 --> 01:40:32.600]   And I think, yeah. Yeah. And, and the interesting thing though is that you're seeing now these
[01:40:32.600 --> 01:40:37.160]   companies getting more aggressive. So Grow with Google is a sleeper, but it is a big deal. Like,
[01:40:37.160 --> 01:40:40.840]   they are saying they're basically telling the company, they're telling universities,
[01:40:40.840 --> 01:40:45.720]   you are not producing enough product that we need. So we're going to go around you, you know,
[01:40:45.720 --> 01:40:49.240]   like we are going to educate the people and what we need because those are the, what they're
[01:40:49.240 --> 01:40:53.960]   educating them in is the first, first line of defense jobs that grow into all these other things.
[01:40:53.960 --> 01:40:57.320]   And so, and they, and they're not, they don't have a lot of age requirements to do the Grow with.
[01:40:57.320 --> 01:41:03.320]   I wonder how long before companies like Google Apple, Microsoft, the things start having high schools
[01:41:04.280 --> 01:41:07.880]   and middle schools, you know, it's the, well, these aren't have to own the school. It's,
[01:41:07.880 --> 01:41:11.400]   it's interacting. I mean, the government's been doing this for a long, long time. It's called ROTC.
[01:41:11.400 --> 01:41:17.960]   You know, and so ROTC is a feeder system. And our sports teams have Little League and, you know,
[01:41:17.960 --> 01:41:22.280]   Warner, you know, pop Warner and all those other things. So is it the first competition? What do
[01:41:22.280 --> 01:41:26.360]   we have? What is our little league for Google? It's good with Google. It's good with Google.
[01:41:26.360 --> 01:41:30.520]   And one of the things that they used to have to solve this problem, they don't have any more,
[01:41:30.520 --> 01:41:35.720]   which is acquisitions, because you could just buy up the hottest talent to do the aqua higher thing.
[01:41:35.720 --> 01:41:40.760]   And it's so much harder for them to do that. And for sure, with Lena Khan at FTC, it's going to get
[01:41:40.760 --> 01:41:45.080]   harder. Well, and again, and Apple's doing the same thing with the Swift Playgrounds. I mean,
[01:41:45.080 --> 01:41:50.760]   they are, you know, that's a smart game. Yes. It's a, but and that's getting kids in early into
[01:41:50.760 --> 01:41:55.160]   Swift. So more important even than getting them to, you know, sometimes I think the Apple and
[01:41:55.160 --> 01:42:00.920]   Microsoft's, you know, outreach to education is so that people get used to using office
[01:42:00.920 --> 01:42:06.040]   so that when they get a office job, they'll use office. It isn't now, is it? It's to get them used to
[01:42:06.040 --> 01:42:13.240]   programming Swift. We need coders. We need coders. They're just, they're horribly short on this
[01:42:13.240 --> 01:42:18.280]   apply of coders. That's interesting. You know, and so they're there and it's different, you know,
[01:42:18.280 --> 01:42:21.720]   and they want to get them in early because the big thing is, is that your brain is so much,
[01:42:21.720 --> 01:42:26.040]   so much more, so much absorbs so much more information when you're young. Well,
[01:42:26.040 --> 01:42:30.920]   and so you want coders to start when they're early. It's a little fast. But I'm also kind of a
[01:42:30.920 --> 01:42:38.440]   believer in Malcolm Gladwell's 10,000 hours. I really do think it takes a while. He's told that.
[01:42:38.440 --> 01:42:43.640]   Oh, of course. He steals a lot of things. But in Zen, but I think Zen Zen Buddhism,
[01:42:43.640 --> 01:42:49.800]   it's referred to as 10,000 mistakes that the difference between the beginner, the beginner and
[01:42:49.800 --> 01:42:54.840]   the master, 10,000 mistakes, not 10,000 hours. He switched it. I mean, so he stole it and then
[01:42:54.840 --> 01:42:59.640]   switched it. So it's his, I guess. Same idea though. He did enough change, but it's 10. You hear
[01:42:59.640 --> 01:43:03.720]   this more accurate mistakes. I know I've made that way more. Yeah. You just want to keep on
[01:43:03.720 --> 01:43:10.200]   making more than a 10,000 more than one mistake an hour. So I exactly see you can do it so much faster
[01:43:10.200 --> 01:43:17.480]   if you're reckless. So anyway, but that's the, but yeah, you want, but it's hard. Like I could
[01:43:17.480 --> 01:43:23.000]   never have done, I could have never done what I did when I was 26. I was at Lucasfilm working
[01:43:23.000 --> 01:43:26.600]   on Star Wars. I wouldn't have done that starting at 18. Yeah. I did that when I, because I started
[01:43:26.600 --> 01:43:30.840]   programming when I was nine, right? You know, and that's the, I mean, that's what you have to get
[01:43:30.840 --> 01:43:35.400]   kids into early. Love it. Let's take a little break. I love this panel. Brian McCullough is here.
[01:43:35.400 --> 01:43:40.440]   Tech meme, right? Home host, Internet, historian and Time Magazine cover collector.
[01:43:41.400 --> 01:43:49.720]   You want to know how to stop making mistakes, get better sleep. Oh, you must have eight sleep
[01:43:49.720 --> 01:43:59.400]   as a sponsor too. Also, Eric McCracken, the technologizer, Alex Lindsey from office hours.global.
[01:43:59.400 --> 01:44:05.240]   Do you have a eight sleep cover by any chance, Brian? I do not. Oh, I'm going to get you to get
[01:44:05.240 --> 01:44:10.360]   one. Let me tell you, yes, Kevin Rose told me about this on a twit some time ago. Amy Webb was
[01:44:10.360 --> 01:44:15.080]   on that twit. She got one. Then she said, this is the greatest sleep. We finally got one a few
[01:44:15.080 --> 01:44:20.760]   months ago. I love this. Now for a long time, we had electric blanket to keep us warm at night.
[01:44:20.760 --> 01:44:25.400]   And then we got electric instead of got electric mattress pad warmth coming up. But the problem
[01:44:25.400 --> 01:44:33.640]   is that's a one way trip to sweaty sleep. The eight sleep is amazing. It not only gets warmer,
[01:44:33.640 --> 01:44:41.880]   it gets cooler. We have the eight sleep pod pro cover. It can go down to 55 degrees or as hot as
[01:44:41.880 --> 01:44:45.560]   110 degrees. I can't wait till a hot summer night because it's going to be air conditioning in my
[01:44:45.560 --> 01:44:51.160]   bed. But it's amazing. And if you know, if you think a little bit, and I've read some evolutionary
[01:44:51.160 --> 01:44:55.960]   scientists who have said, if you think about how we sleep, they know that we sleep better when
[01:44:55.960 --> 01:45:02.600]   it's cool, not hot when it's cool. But what you really want is to get in bed. It's nice and toasty.
[01:45:02.600 --> 01:45:06.200]   And then it gets cooled off in the middle of the night, you get the deepest sleep then. And then
[01:45:06.200 --> 01:45:11.640]   to wake up, you warm yourself up again. And that's exactly what my eight sleep pod pro cover does.
[01:45:11.640 --> 01:45:16.120]   I'm going to do something a little risky here. I'm going to open up my eight sleep app.
[01:45:16.120 --> 01:45:22.440]   Just to see what my sleep score was, I have to say before eight sleep, I'm in the 60s. I'm in
[01:45:22.440 --> 01:45:29.800]   the 50s. Oh, I didn't have a very good night last night. It was only 84% sleep fitness. I have to tell
[01:45:29.800 --> 01:45:36.120]   you it normally it's up in the 90s. Last time I showed it was 98. I think I've gotten to 100%
[01:45:36.120 --> 01:45:42.840]   which I don't think I experienced when I was an infant. This is the app is monitoring your sleep.
[01:45:42.840 --> 01:45:48.120]   It the cover actually monitors your restlessness, your heart rate, your breathing,
[01:45:48.120 --> 01:45:54.760]   and then adjusts the temperature according to how you're sleeping. They have something called
[01:45:54.760 --> 01:46:01.080]   autopilot. I have a temperature schedule update from autopilot. This is my temperature update.
[01:46:01.080 --> 01:46:06.040]   It says at bedtime, I'm going to be plus four. Then it's go to go down plus two plus two plus five.
[01:46:06.040 --> 01:46:12.120]   And by the way, it gets hotter over because it also is checking the room temperature.
[01:46:12.120 --> 01:46:19.800]   This will modify itself automatically. It is amazing. It is absolutely transformative.
[01:46:20.520 --> 01:46:25.640]   And you're right, Brian. Good sleep is a game changer for alertness. But not just for that,
[01:46:25.640 --> 01:46:31.640]   for health, research shows good sleep can decrease the risk of heart disease. It can lower your
[01:46:31.640 --> 01:46:36.360]   blood pressure. Did you see my rest and heart rate? It's pretty good. Thank you, 8 sleep. More
[01:46:36.360 --> 01:46:41.640]   than 30% of Americans struggle with sleep temperature. One of the main causes of poor sleep. The
[01:46:41.640 --> 01:46:49.880]   solution, 8 sleep, EIGHT sleep and the pod pro cover. Now what's nice is of course, Lisa has
[01:46:49.880 --> 01:46:55.160]   different, my wife has different sleep needs. So the temperature of the cover adjusts each side
[01:46:55.160 --> 01:47:00.440]   of the bed. It's looking at sleep stages, biometrics, bed, red temperature reacts intelligently.
[01:47:00.440 --> 01:47:07.160]   Her settings are completely different from mine. 8 sleep users fall asleep up to 32% faster.
[01:47:07.160 --> 01:47:16.680]   Reduce sleep interruptions by 40%. And overall, get a more restful sleep. And I can absolutely
[01:47:16.680 --> 01:47:23.000]   vouch for that. Let me just see. Last night, it was 88%. Friday night. Oh, look,
[01:47:23.000 --> 01:47:30.760]   Thursday, I got 99%. And I tell you, the other stats are fantastic. Time to fall asleep was one
[01:47:30.760 --> 01:47:36.360]   minute. That's because it was so cozy. Time to get up six minutes. It wakes me up by heating up.
[01:47:36.360 --> 01:47:42.520]   And I jump out of bed. It's fantastic. You can see your sleep stages, your tosses and turns.
[01:47:42.520 --> 01:47:48.920]   Your sleeping heart rate, which for me got down to 62. This is I love you, 8 sleep. I just want to
[01:47:48.920 --> 01:47:55.560]   say this. I love you deeply with 30% more deep sleep. I feel like my mind and body are moving through
[01:47:55.560 --> 01:48:02.040]   the restorative sleep stages, vital for physical recovery, hormone regulation,
[01:48:02.040 --> 01:48:07.400]   mental clarity. When I work out and I know, you know, my resting heart rate is down low.
[01:48:07.400 --> 01:48:13.160]   My heart rate variability is high. I just feel better. Powered by eight sleep, I can show up as
[01:48:13.160 --> 01:48:21.080]   the best partner parent and podcaster. So that's why Brian McCullough, you have to get eight sleep,
[01:48:21.080 --> 01:48:26.520]   eight sleep.com slash twit. We're going to save you $150 at checkout on the pod pro cover. They
[01:48:26.520 --> 01:48:30.840]   also have a mattress. Eight sleep currently ships within the US, Canada and the UK.
[01:48:31.560 --> 01:48:40.280]   $150 off when you go to eight sleep, E-I-G-H-T sleep.com slash twit. All right, I'm going to
[01:48:40.280 --> 01:48:44.520]   stop raving about this, but I have to say it's the best night sleep I've ever had. And
[01:48:44.520 --> 01:48:48.600]   Lisa and I are both saying, this is going to be great on those hot summer nights when it's
[01:48:48.600 --> 01:48:53.240]   sweating, you're hot, you can't cool off. You got the we get the fan on and it's like, oh,
[01:48:53.240 --> 01:48:57.000]   you're dying. I don't have to worry about it. It's just going to cool. It's going to be so nice.
[01:48:57.000 --> 01:49:01.160]   I can't wait. So great. Eight sleep. And it's been great during the cold winter nights too.
[01:49:01.160 --> 01:49:08.840]   Eight sleep.com slash twit. Talking about VR, Harry McCracken. I've heard of him, fast company.
[01:49:08.840 --> 01:49:15.240]   Earlier this month we're on an article what the 1994 Bill Gates keynote tells us about the
[01:49:15.240 --> 01:49:20.440]   metaverse. Did Bill know about the metaverse in 1994? He didn't, but he spent a lot of time
[01:49:20.440 --> 01:49:24.280]   talking about what the next 10 years of technology would be like at that point,
[01:49:24.280 --> 01:49:30.040]   which were about the information superhighway. So let me think of this was Windows 3-1-1.
[01:49:30.920 --> 01:49:37.560]   It was a free Windows 95. Yeah. Yeah. And he at the time he did these keynotes at Comdex,
[01:49:37.560 --> 01:49:42.360]   which was the big video show. Yeah, this was the big keynote you'd get up early at 8 a.m.
[01:49:42.360 --> 01:49:47.000]   to see the keynote the day before the show began. Devorak once edited all of Bill Gates'
[01:49:47.000 --> 01:49:52.040]   keynotes into Galps and just had a long, like half an hour of him going,
[01:49:55.800 --> 01:50:00.920]   it was funny, but he actually took out all the meat. So what was the meat in this one?
[01:50:00.920 --> 01:50:06.600]   Well, he did this in 1994. He did this particularly elaborate one, which involved him on stage,
[01:50:06.600 --> 01:50:12.760]   but also this pretty lavish movie that Microsoft had made set in 2005, which,
[01:50:12.760 --> 01:50:17.160]   Oh, I remember that. At this point, that was a decade in the future. Isn't that funny?
[01:50:17.160 --> 01:50:21.560]   And it showed all the technology we'd be using then. We'd all be using wallet PCs,
[01:50:21.560 --> 01:50:28.440]   which were not smartphones, but they were rather smartphone-like. And along with giving you access
[01:50:28.440 --> 01:50:34.040]   to data wherever you were, people would use them like to control larger screens. So you'd be sitting
[01:50:34.040 --> 01:50:40.680]   in front of your TV and you'd use your wallet PC as kind of a remote control. This was the
[01:50:40.680 --> 01:50:46.040]   information at your fingertips. He showed that we all be getting video on demand and we'd be able
[01:50:46.040 --> 01:50:52.360]   to binge. Look at that looks just like my Tesla. Yes. Wow. Essentially, he got a lot of the broad
[01:50:52.360 --> 01:50:58.600]   brushstrokes pretty well. Pretty you got pretty close on the broad brushstrokes. And this was
[01:50:58.600 --> 01:51:03.480]   before the famous internet memo, right? Or was it right around? I think it roughly the same time.
[01:51:03.480 --> 01:51:07.960]   Okay, because for a long time, he did not think the internet was going to be the internet and
[01:51:07.960 --> 01:51:14.200]   the web only come up a little bit in this discussion. He doesn't completely ignore them, but at this
[01:51:14.200 --> 01:51:18.280]   point it wasn't clear whether it would be the internet that would give us the information
[01:51:18.280 --> 01:51:26.040]   superhighway or it might be cable TV. Let's go into the home of 2005, which again then was 10
[01:51:26.040 --> 01:51:35.800]   years in the future. It's a nice looking house. There's no room. Oh, I remember this. The movie is
[01:51:35.800 --> 01:51:42.040]   about this kid who gets... Wait a minute. I have to go ahead. I thought that was that was the
[01:51:42.040 --> 01:51:46.280]   they was watching the TV. I didn't realize I thought there was a background noise.
[01:51:46.280 --> 01:51:51.240]   He's watching the news on his iPad.
[01:51:51.240 --> 01:52:03.560]   At this point, even flat screens were kind of futuristic. Really? Yeah. Yeah. I remember they
[01:52:03.560 --> 01:52:11.720]   were so big this time. The CRT's. Okay, she just picked up her Alexa. Good morning,
[01:52:11.720 --> 01:52:18.840]   mom. Oh, there's her E-COB smart thermostat. She's setting the...
[01:52:18.840 --> 01:52:24.280]   She's about to watch the TV. Now, she was wrong on this interactive TV. Never did take off.
[01:52:24.280 --> 01:52:27.000]   Have a great evening. Thanks for watching. Good night, everybody.
[01:52:27.000 --> 01:52:32.040]   She's watching last night's... Now, this was a big deal in '95, last night's Letterman.
[01:52:32.040 --> 01:52:35.960]   This is pre-T though. Yeah. And there's all her shows.
[01:52:37.640 --> 01:52:43.400]   I guess this isn't actually far off from streaming. No, I mean, we do this today, although not in
[01:52:43.400 --> 01:52:47.960]   exactly the way that... The interface showed it took a little bit longer for it to become...
[01:52:47.960 --> 01:52:50.040]   And Oprah's no longer on, so that's another.
[01:52:50.040 --> 01:52:55.000]   Today, partners in cyberspace meet face-to-face...
[01:52:55.000 --> 01:52:57.720]   And we don't call it cyberspace anymore, thank God.
[01:52:57.720 --> 01:53:02.920]   All right, let me skip ahead a little bit. What else are we going to look for in our...
[01:53:03.800 --> 01:53:06.840]   If you've been trying the wallet PCs, that was a big part of this moving.
[01:53:06.840 --> 01:53:13.240]   Yeah, let me jump ahead. The kid also does this amazing multimedia presentation at school,
[01:53:13.240 --> 01:53:16.760]   which today would not be particularly exciting. This is when...
[01:53:16.760 --> 01:53:26.520]   Microsoft spent millions with pro actors and all sorts of stuff on these videos.
[01:53:26.520 --> 01:53:31.960]   I kind of miss these keynotes, Kinehote's... Oh, I mean, people still spend millions on their...
[01:53:31.960 --> 01:53:35.160]   Do they? Oh, here's the wallet. Here's the wallet PC. The kids got it.
[01:53:35.160 --> 01:53:41.160]   All right, let's go back here. She's still watching. Mom's still watching Oprah, as mom does.
[01:53:41.160 --> 01:53:44.440]   It's a little sexist.
[01:53:44.440 --> 01:53:52.520]   Mom is not a CEO at a major fortune 500 company apparently. She didn't have a Zoom to watch
[01:53:52.520 --> 01:53:56.600]   TV at the beginning. Yeah. She watches a lot of TV.
[01:53:56.600 --> 01:53:58.200]   All right.
[01:54:00.200 --> 01:54:02.520]   Okay, let's skip ahead. Where's the wallet?
[01:54:02.520 --> 01:54:06.280]   We're based on the transition at the White House. We're going to be taking a close look at the
[01:54:06.280 --> 01:54:09.880]   president-elect's plans for the nation. Oh, who's the president in 2005?
[01:54:09.880 --> 01:54:11.800]   She says, "Eat, eat, eat." Oh, that's just a woman.
[01:54:11.800 --> 01:54:17.480]   Yeah, no, sorry. All right, here's the... Wait a minute, this is a cop show now.
[01:54:17.480 --> 01:54:20.680]   There's a murder mystery that's part of this. Oh, boy.
[01:54:20.680 --> 01:54:28.280]   There's a plot. There's a plot to this. Do you remember Harry sitting in the audience and seeing
[01:54:28.280 --> 01:54:32.600]   this? No, I made a point of not going to Bill Gates. You know, so that's a good point.
[01:54:32.600 --> 01:54:36.840]   Although now I wish I wish that I wish. Wish you had. The only reason to go at the time really was
[01:54:36.840 --> 01:54:42.680]   these movies. But I discovered this one so it came up on YouTube. Yeah. Well, tell me about the
[01:54:42.680 --> 01:54:46.840]   wallet PC. Is it like a smartphone? No. It's a small screen you put in your pocket. I mean,
[01:54:46.840 --> 01:54:51.720]   this is Microsoft talking so they think of it as being a PC. But apparently you do not make phone
[01:54:51.720 --> 01:54:58.200]   calls on it. Touch screens are not part of this vision at all. If I remember correctly,
[01:54:58.200 --> 01:55:04.520]   is there any AR VR at all? No, I don't think so. So his idea of the metaverse is still
[01:55:04.520 --> 01:55:09.160]   at arms, kind of arms and legs. Yeah. And to be fair, they're trying to do stuff that's
[01:55:09.160 --> 01:55:16.520]   out there, but not incredibly out there. I think he was trying to pretty much figure out what the
[01:55:16.520 --> 01:55:23.560]   next things would be. And I thought of this again coming back to Mark Zuckerberg. He's somebody who
[01:55:23.560 --> 01:55:27.320]   now is making these pretty elaborate videos showing life in the metaverse. That's right.
[01:55:27.320 --> 01:55:33.080]   Which are really in a lot of ways reminiscent to this. And I think the lesson is A,
[01:55:33.080 --> 01:55:39.880]   if you're really smart, you might get some of the broad picture right. But that doesn't mean you
[01:55:39.880 --> 01:55:47.320]   can predict the little details. And B, when the stuff did come along, again, kind of a little bit
[01:55:47.320 --> 01:55:54.920]   more like 2007, 2008, moving forward rather than 2005. The fact that Bill Gates was pretty good at
[01:55:54.920 --> 01:56:00.520]   anticipating what would happen did not mean that Microsoft dominated all the stuff that came.
[01:56:00.520 --> 01:56:01.400]   Very good point.
[01:56:01.400 --> 01:56:05.480]   Instead, Microsoft released a lot of things that weren't terribly successful. They did not
[01:56:05.480 --> 01:56:10.120]   dominate smartphones. They had a video on the meta-
[01:56:10.120 --> 01:56:11.320]   Holy crap. What?
[01:56:12.040 --> 01:56:19.400]   Harry, I just did the math. When this video happened, Gates was 39. Today, Mark Zuckerberg is 38.
[01:56:19.400 --> 01:56:24.920]   Uh-huh. That probably makes sense. That's when you kind of are at your peak mastery of the universe.
[01:56:24.920 --> 01:56:28.680]   And probably when you start to worry about the future, maybe running away from you and
[01:56:28.680 --> 01:56:35.080]   somebody else determining that. So the fact that Microsoft, even though it was quite good
[01:56:35.080 --> 01:56:39.880]   in predicting the future, was not really able to leverage that partially because it had this big
[01:56:39.880 --> 01:56:45.720]   business in Windows, which defined how it saw the world, I think has some lessons for us when we
[01:56:45.720 --> 01:56:50.200]   look at that. Well, as I said, I think Mark has learned that innovators dilemma
[01:56:50.200 --> 01:56:57.880]   message and is willing to- that's why I think he's willing to risk meta in order to achieve
[01:56:57.880 --> 01:57:02.280]   this vision. But you make an excellent point just because you can see this. We can see it.
[01:57:02.280 --> 01:57:06.840]   Doesn't mean we're going to be instrumental in the next 10, 20 years.
[01:57:06.840 --> 01:57:10.760]   And Microsoft never bet everything on something else. Instead, it's everything has been an
[01:57:10.760 --> 01:57:15.640]   extension of Windows, which in most cases did not really work out that way.
[01:57:15.640 --> 01:57:20.040]   I think that that's one thing you could say. Mark is not saying this. Oh, the metaverse was
[01:57:20.040 --> 01:57:23.880]   Facebook extended. I mean, he does certainly have a social aspect. That's part of it. I mean,
[01:57:23.880 --> 01:57:27.480]   I think the idea is you will still want to hang out with your friends in the metaverse.
[01:57:27.480 --> 01:57:31.240]   Yeah, the graph that Facebook has of people and their connected and how they're connected to
[01:57:31.240 --> 01:57:36.440]   other people is very advantageous for a virtual world. And again, I think that that's an interesting
[01:57:36.440 --> 01:57:39.560]   puzzle where you see Apple not going down that path. They're not trying to build that out.
[01:57:39.560 --> 01:57:43.320]   They're trying to augment what you already have. They're not worried about social at all.
[01:57:43.320 --> 01:57:49.960]   Not yet. Not yet. Apple's only assays into social where historic flops.
[01:57:49.960 --> 01:57:55.320]   Yeah, because they don't think that way. They think so much about privacy and about the individual.
[01:57:55.320 --> 01:58:00.200]   I think they have a hard time getting even when you look at pages and numbers, which I love,
[01:58:00.200 --> 01:58:04.680]   by the way, but the interaction between other people like sharing your pages or
[01:58:04.680 --> 01:58:09.080]   keynote is a great way to just not have it work anymore. So it doesn't work at all.
[01:58:09.080 --> 01:58:17.240]   They did pain with iTunes, which was a didn't flop. Then remember that they were early on
[01:58:17.240 --> 01:58:25.560]   in dial up networking. They had a little e world and you'd wander through this town.
[01:58:25.560 --> 01:58:32.280]   I think the Apple was interoperable with aim back in the day to right. Like that was a big
[01:58:32.280 --> 01:58:36.520]   seller for so they learned a couple of things. One never be never interoperate.
[01:58:36.520 --> 01:58:40.680]   I think lately they've done a better job. I mean, both FaceTime and iMessage
[01:58:40.680 --> 01:58:45.000]   are looking like social platforms and have a ton of people using them.
[01:58:45.000 --> 01:58:54.680]   Here was the e world interface, which it was like AOL social networks. So you would go in and
[01:58:54.680 --> 01:59:02.200]   get your email. It kind of looks like a metaverse. If you could only put on a headset and be
[01:59:02.200 --> 01:59:06.920]   there. What year was that again? That was I'm not sure if that was. I feel like that was roughly
[01:59:06.920 --> 01:59:13.480]   the same time as that Bill Gates keynote. 1996 it was closed in 1996. So I'm
[01:59:13.480 --> 01:59:22.120]   I'm not sure if that was Scully or Spindler or Emilio, but yeah, but it was not Steve. No.
[01:59:22.120 --> 01:59:30.120]   Yeah, maybe Apple learned learn to lessen and said, "Nah, social's not it." But and honestly,
[01:59:30.120 --> 01:59:34.360]   I think Apple wouldn't care if you used whatever hardware they made in the meta
[01:59:34.360 --> 01:59:39.640]   metaverse. That's that's not their business. They go ahead and use it with Facebook's.
[01:59:39.640 --> 01:59:43.800]   Yeah, they might be fine with you using somebody else's metaverse platform for Apple hardware.
[01:59:43.800 --> 01:59:47.560]   Of course, what they Facebook wants to avoid is the 30% search charge.
[01:59:47.560 --> 01:59:50.040]   Apple's like, sure, you can use our hardware.
[01:59:50.040 --> 01:59:54.520]   So I'm still going to be. Apple's actually getting a little a little fun out of Facebook's
[01:59:54.520 --> 02:00:01.320]   announcement that they're going to charge 47.5% on metaverse items. Apple says, this shows
[02:00:01.320 --> 02:00:09.240]   Facebook's hypocrisy because of course Facebook's been complaining about Apple's 30% big.
[02:00:09.240 --> 02:00:15.720]   47.5%. Well, because because because isn't it something like I know I did the story,
[02:00:15.720 --> 02:00:19.960]   but I don't remember a certain percentage goes to the Oculus platform.
[02:00:19.960 --> 02:00:22.760]   Right. And then a certain percentage. Where does the other one go?
[02:00:22.760 --> 02:00:31.800]   So for every item sold in Horizon Worlds, which is Facebook's social VR platform, a 30% goes to
[02:00:31.800 --> 02:00:41.720]   meta via the Oculus platform, 25% goes to the meta app store. 25% of the 70% goes to the meta
[02:00:41.720 --> 02:00:45.080]   app store. They can say, look, our app store only takes 25%.
[02:00:45.080 --> 02:00:52.600]   I mentioned all in some not to mention that for 98% of the developers, Apple takes 15.
[02:00:53.400 --> 02:01:00.920]   So, so it's. Yeah. Yeah. Somebody tweets, the future of work is giving meta 47.5% of your salary,
[02:01:00.920 --> 02:01:07.000]   apparently. And no one has the latest. I think with all these, I think with all these percentages,
[02:01:07.000 --> 02:01:11.720]   though, people are forgetting that, you know, the gap is buying shirts for $4 and selling them to us
[02:01:11.720 --> 02:01:19.800]   for 40. Right. I mean, Mark has a lot of addition. A lot of margin in a lot of things. And so we
[02:01:19.800 --> 02:01:23.720]   have this thing like, we know that oh, 47 is really high. Well, do we? I mean, you know, like,
[02:01:23.720 --> 02:01:27.880]   that there's a lot of when they cut when they cut it off at a at a at a at a garment store for
[02:01:27.880 --> 02:01:31.240]   half off, they're still making margin. Yeah. But is that true? They were before.
[02:01:31.240 --> 02:01:39.640]   Is that true in a platform economy where I have to make my margins on top of your margins on top
[02:01:39.640 --> 02:01:44.840]   of someone else's margins? You know what I mean? Like, it is. It is. It is. Yeah. Yeah. Yeah.
[02:01:46.040 --> 02:01:49.720]   It's complicated. Sometimes it's worth it and sometimes it's not.
[02:01:49.720 --> 02:01:55.000]   Right. I don't think Netflix should have to pay Apple 30%. But if you've developed a game,
[02:01:55.000 --> 02:02:00.840]   like Fortnite, I think that's appropriate. So I don't know. And you know, requires Apple's
[02:02:00.840 --> 02:02:06.680]   platforms. I don't know. We have these conversations on Mac break weekly, weekly, as a matter.
[02:02:06.680 --> 02:02:14.120]   That's a matter. Yeah. Yeah. Yeah. Big tech is pouring money into something that doesn't exist
[02:02:14.120 --> 02:02:21.320]   yet. This article from the Atlantic about carbon removal, Google and Facebook, nearly a billion
[02:02:21.320 --> 02:02:30.840]   dollars into a technology to zero out emissions. But there is no technology yet. The theory is,
[02:02:30.840 --> 02:02:37.320]   if we pour money into it, maybe that technology will be invented. And there is a history that might
[02:02:37.320 --> 02:02:43.240]   confirm that in 2010, a set of donors committed one and a half billion dollars to buy a vaccine
[02:02:43.240 --> 02:02:49.720]   for streptococcus pneumonia before it had been invented. But that advanced market commitment
[02:02:49.720 --> 02:02:54.600]   spurred the rapid innovation and deployment of a newococcal vaccine, which has saved
[02:02:54.600 --> 02:02:59.800]   some of the COVID as well. Yeah. I mean, you know, we figured out how to make a vaccine really fast
[02:02:59.800 --> 02:03:03.080]   with a lot an enormous amount of money that no one wants to talk about. Right. Like how much
[02:03:03.080 --> 02:03:07.640]   money they spent. Well, but we've been working on mRNA vaccines for a decade, trying to get them
[02:03:07.640 --> 02:03:13.640]   to work, right? And then the time came in, and we needed them and they did work. I think that's
[02:03:13.640 --> 02:03:18.120]   a worthwhile expenditure. Are you saying it was too much money, Alex? No, not at all. Okay.
[02:03:18.120 --> 02:03:22.360]   I'm saying that we were able to make it work. Yeah. You know, like we were, we were able to make
[02:03:22.360 --> 02:03:26.760]   it work. By pre-invested. By putting in pre-investing and then putting an enormous amount of money when
[02:03:26.760 --> 02:03:32.200]   it was needed. Yeah. And we may have to do that with carbon, you know, sequester. All those a lot
[02:03:32.200 --> 02:03:37.640]   of easier ways to do it in a lot of, there's things, those trees and mangroves, all kinds of stuff that
[02:03:37.640 --> 02:03:41.400]   have we planted more of would probably, that works now, works today. Yeah.
[02:03:41.400 --> 02:03:48.760]   So it's, it's, they're putting money, $925 million into a new company owned by Stripe
[02:03:48.760 --> 02:03:58.360]   called Frontier. Frontier has investments in 17 different, or from, sorry, 14 different carbon
[02:03:59.320 --> 02:04:04.760]   removal startups. One called Carbon Built is trying to sequester carbon trying,
[02:04:04.760 --> 02:04:10.840]   is the operative word so far, to sequester carbon by capturing it in concrete. The future forest
[02:04:10.840 --> 02:04:17.640]   company wants to accelerate the natural process of rock weathering. I somehow that helps. Project
[02:04:17.640 --> 02:04:24.600]   Vesta wants to line beaches with a carbon capturing mineral called olivine. Rock weathering, by the
[02:04:24.600 --> 02:04:30.840]   way, is the natural, that's how the globe, when, when, when plate tectonics goes under, like,
[02:04:30.840 --> 02:04:36.600]   that's how most of the carbon gets sequestered by just getting sucked under the crust. That's the
[02:04:36.600 --> 02:04:42.280]   natural process of removing carbon from, yeah. I like their motto, un-effing the future.
[02:04:42.280 --> 02:04:54.520]   That's interesting. Okay. You know what? I'm not, in fact, is that all 925
[02:04:54.520 --> 02:04:58.520]   million, can we put a little more in, please? Yeah. I mean, that's like,
[02:04:58.520 --> 02:05:04.920]   that's like, the bill off the outside of your role. Yeah. Yeah. Yeah. Yeah. Yeah. They're saying
[02:05:04.920 --> 02:05:09.000]   it's still a thousand times shorter than the market we need by 2050. But also, the market here
[02:05:09.000 --> 02:05:15.640]   is there, it's similar to the mRNA stuff, which is they're assuming the governments of the world
[02:05:15.640 --> 02:05:21.560]   are going to pay for this. Right. Because if who's, who, who would be motivated to get the,
[02:05:22.920 --> 02:05:27.800]   who could pay for getting the carbon out of the atmosphere. So they're assuming, I'm looking
[02:05:27.800 --> 02:05:33.640]   right here, the carbon removal market will probably need to reach $1 trillion a year for it to work
[02:05:33.640 --> 02:05:39.000]   out. But who would pay for that would be the world's, they're just moving the technology forward.
[02:05:39.000 --> 02:05:47.560]   Yeah. Yeah. Intel says they're going to have a net zero carbon emission, their goal though,
[02:05:47.560 --> 02:05:57.720]   not till 2040. And they've only really got ideas for the, for two of the three scopes that are commonly
[02:05:57.720 --> 02:06:05.560]   causing carbon emissions. Scope one is raw material. Scope two is manufacturing. But of course,
[02:06:05.560 --> 02:06:13.960]   creating microprocessors uses a lot of nasty chemicals. And they're only going to rely on
[02:06:13.960 --> 02:06:20.600]   offsets for the hardest to reduce emissions, the ones involved in making things like perfluor
[02:06:20.600 --> 02:06:28.520]   carbons, which warm the planet 1000 times more than carbon dioxide. So chip making is a nasty,
[02:06:28.520 --> 02:06:34.680]   nasty process. And Intel says, well, by 2040, it's going to be less nasty, I guess would be the,
[02:06:34.680 --> 02:06:42.600]   the phrase, not so nasty. Houston Astros stadium using Amazon's walk out technology,
[02:06:42.600 --> 02:06:47.560]   the first major league baseball stadium. That should go well. I want to just take a hot dog and
[02:06:47.560 --> 02:06:50.680]   go out and watch the ball game.
[02:06:50.680 --> 02:06:57.000]   Astros have teamed up with Amazon to install just walk out systems in two concession stores
[02:06:57.000 --> 02:07:02.280]   in Minute Mate Park, the 19th hole or market. So if you're in a, in the Houston area,
[02:07:02.280 --> 02:07:06.920]   get your snacks and souvenirs. You insert your credit card at the entry gate,
[02:07:06.920 --> 02:07:09.640]   you grab things off the shelf and you leave when you're done.
[02:07:10.920 --> 02:07:14.040]   Don't you always feel like I buy a lot of stuff at the app when I buy stuff at the Apple Store,
[02:07:14.040 --> 02:07:17.160]   I don't buy a lot of stuff. I don't get there very often. But when I go there, I buy it usually
[02:07:17.160 --> 02:07:21.240]   with my phone. I just open up the app store and Apple store and I just take a picture of it and
[02:07:21.240 --> 02:07:25.000]   then it charges me and then I walk out and I feel like I'm stealing like I was going to stop me.
[02:07:25.000 --> 02:07:26.680]   Yeah. No, no, I paid for this.
[02:07:26.680 --> 02:07:37.880]   Amazon is working also with Starbucks on this automated checkout and there's a Amazon
[02:07:37.880 --> 02:07:41.560]   ghost store. I go to a lot in San Francisco. Do you use it? Yeah, I do. But I'm making
[02:07:41.560 --> 02:07:47.000]   you nervous. I'm using it. Not, not anymore. But I am interested in the fact that I'm usually the
[02:07:47.000 --> 02:07:52.120]   only person there and I kind of wonder whether maybe the future of this technology is not Amazon
[02:07:52.120 --> 02:07:55.800]   opening up lots of stores that offer it so much as these partnerships. Yeah.
[02:07:55.800 --> 02:08:02.600]   Yeah, Harry, haven't you heard that they're sort of pulling back a bit? Like they're taking their
[02:08:02.600 --> 02:08:08.120]   foot off the pedal a little bit on this sort of stuff. Maybe retail, generally they're retail.
[02:08:08.120 --> 02:08:14.680]   They've shut down a lot of their retail. They should put stores. The Amazon ghost stores,
[02:08:14.680 --> 02:08:19.240]   at least the ones I go to cut way back on the number of products they sell. I think they were
[02:08:19.240 --> 02:08:23.240]   unfortunate enough to be trying to ramp them up right before the pandemic started and there's
[02:08:23.240 --> 02:08:27.960]   just less need for convenience stores, at least in San Francisco, than there once was.
[02:08:30.200 --> 02:08:36.360]   Well, I think especially in San Francisco, just walk out is a recipe for trouble. I think people
[02:08:36.360 --> 02:08:41.880]   have already started that in many stores in San Francisco. Well, at the Amazon ghost starts,
[02:08:41.880 --> 02:08:46.920]   you can just walk out, but just walking in as a bit of a challenge because you need to
[02:08:46.920 --> 02:08:52.280]   get your Amazon app. Yeah. It used to be that there was an Amazon Go app that was pretty convenient,
[02:08:52.280 --> 02:08:56.440]   but now they make you use the Amazon app and you have to scroll through to find this barcode,
[02:08:56.440 --> 02:09:00.680]   which it generates on the fly and time. Sometimes it doesn't work very well.
[02:09:00.680 --> 02:09:04.360]   They want me to scan my phone and I start playing with it. I'll forget it. I'll just pay
[02:09:04.360 --> 02:09:12.440]   the whole food. That has a problem where the QR code doesn't come up very fast. It takes a
[02:09:12.440 --> 02:09:16.920]   long time, but the Amazon one goes really fast. So it just pops right up. You get used to it after
[02:09:16.920 --> 02:09:20.360]   one. Should I use the Amazon app instead of the whole food? Well, what's nice about it is,
[02:09:20.360 --> 02:09:24.440]   if I ever can't remember what I bought that I liked, they know what it is.
[02:09:24.440 --> 02:09:30.040]   And so the hard part for me is that I would actually like checking out without talking
[02:09:30.040 --> 02:09:35.320]   anybody, but the problem is that in Whole Foods, I really only shop the edges. I don't really buy
[02:09:35.320 --> 02:09:40.840]   products and boxes. So the problem is that that becomes really difficult. I always said I was
[02:09:40.840 --> 02:09:45.640]   never going to be that person that just has a pile of raw materials. It takes forever to get
[02:09:45.640 --> 02:09:49.080]   through the... I was always behind it. But you are now. Oh my God. Now I am. It's all the way.
[02:09:49.080 --> 02:09:53.000]   It's the way to shop. So the problem is you can't go through the... Trying to go through the
[02:09:53.000 --> 02:09:59.000]   automated thing with lettuce and asparagus and stuff like that is not trivial. It takes a long
[02:09:59.000 --> 02:10:04.840]   time. I'd rather just have somebody scan. You bought asparagus. You bought ruda bagu.
[02:10:04.840 --> 02:10:09.960]   You can't roll over. You have to weigh it. So you set it down and I'm just like, oh, I can't.
[02:10:09.960 --> 02:10:14.040]   I think we're all going to be begging for the return of cashiers any minute now.
[02:10:14.040 --> 02:10:18.440]   Hey, I want to take a little break before we wrap things up. We're getting towards the end of the
[02:10:18.440 --> 02:10:24.440]   show. But I do want to show you this. This is Blue Land. We were talking about being environmentally
[02:10:24.440 --> 02:10:29.160]   conscious. The number one thing we're trying to do at home is eliminate single-use plastics,
[02:10:29.160 --> 02:10:37.160]   plastic bags, plastic bottles. It's a huge problem. Every year, 5 billion, 5 billion with a B plastic
[02:10:37.160 --> 02:10:43.880]   hand soap and cleaning bottles are thrown away. And when you buy those bottles, they're mostly water.
[02:10:43.880 --> 02:10:51.320]   You're paying trucks to ship water, 90% water around the country. It's bad for the planet,
[02:10:51.320 --> 02:10:57.080]   bad for your wallet. I've got a better way. It's Blue Land and I am a huge fan. I wanted to do a
[02:10:57.080 --> 02:11:00.760]   little science experiment because I've talked about Blue Land a lot. This is the Blue Land
[02:11:00.760 --> 02:11:06.840]   foaming hand soap. So this is designed never to be thrown out. It's a beautiful, heavy glass
[02:11:06.840 --> 02:11:12.520]   container. I filled it with water. So that didn't have to be shipped anywhere up to the fill line.
[02:11:12.520 --> 02:11:18.920]   And then I'm going to add the, let's see, what flavor is this? Iris agave, the foaming hand soap,
[02:11:18.920 --> 02:11:24.920]   this is the little tablet. And you subscribe and they send you the tablet in the mail. So you never
[02:11:24.920 --> 02:11:30.840]   run out. It makes the best hand soap ever. And I don't throw away plastics, but it's not just
[02:11:30.840 --> 02:11:35.240]   hand soap. Get in there. There we go. We're going to make some hand soap. By the time the commercial
[02:11:35.240 --> 02:11:41.720]   is done, we will have some fun. Harry, you can wash your hands with my Iris agave foaming hand soap.
[02:11:41.720 --> 02:11:45.800]   Actually, they have lots of flavors, sometimes special flavors for Christmas. I got gingerbread.
[02:11:45.800 --> 02:11:52.120]   So I smell like gingerbread whenever I wash my hands. Here's the kinds of bottles. This is the,
[02:11:52.120 --> 02:11:57.400]   let's see, it says multi surface cleaner. Same thing, fill it with water. You get the tablet.
[02:11:57.400 --> 02:12:03.400]   We use their powder for our dishwasher, which works every bit as well, if not better,
[02:12:03.400 --> 02:12:09.560]   than the plastic pods we use to use. Same thing for our washing machine. They've got cleaners.
[02:12:09.560 --> 02:12:14.440]   The toilet tablets are fantastic. And by the way, these sell out every time they've gotten. They've
[02:12:14.440 --> 02:12:19.080]   got some more in stock. The Blue Land toilet tablet cleaner. You just pop in the toilet,
[02:12:19.080 --> 02:12:22.760]   walk away, finish your house cleaning, scrub the toilet with a little brush. You're done.
[02:12:22.760 --> 02:12:27.080]   It's going to sell out again. I know from the best selling clean essentials kit to their
[02:12:27.080 --> 02:12:33.320]   hand soap duo, to their plastic free laundry and dishwasher tablets. I'm just a huge fan.
[02:12:33.320 --> 02:12:39.880]   Blue Land has something for every inch of your home. I love Blue Land. Their high quality forever
[02:12:39.880 --> 02:12:45.080]   bottles started just $10 when you buy a kit. They're meant to be reused forever. No more plastics in
[02:12:45.080 --> 02:12:50.680]   the landfill. And the money saving refill tablets, it's just two bucks. So you just pop those in
[02:12:50.680 --> 02:12:58.200]   and you never run out of hand soap or cleaning solutions or laundry detergent. I think it's a
[02:12:58.200 --> 02:13:03.560]   great way to eliminate waste. And these are not you're not sacrificing anything. These are great
[02:13:03.560 --> 02:13:08.840]   cleaners. They really work. At least I actually did an experiment with our dishwashing soap and
[02:13:08.840 --> 02:13:13.880]   our laundry detergent. We replaced them with Blue Land. And she said, Can you tell the difference?
[02:13:13.880 --> 02:13:19.960]   I said, No, it is great. Love Blue Land. Beautiful bottles, beautiful solutions.
[02:13:19.960 --> 02:13:25.800]   Oh, that smells. That smells so good. Iris agave, Perine, Lemon, Lavender, Eucalyptus.
[02:13:26.840 --> 02:13:33.240]   Right now 20% off your first order. Go to blueland.com/twit.
[02:13:33.240 --> 02:13:40.200]   Blueland.com/twit. Right now you can get 20% off your first order. Get your Blue Land products,
[02:13:40.200 --> 02:13:44.680]   Blue Land.com/twit. I won't make you wash your hands, Harry. But this I have to tell you, it's the
[02:13:44.680 --> 02:13:50.520]   best. I have every bathroom in our house has Blue Land foaming hand soap. It's still dissolving. When
[02:13:50.520 --> 02:13:57.640]   it's done, we can all wash our hands of this show. Thank you. Blue Land. We love you. Blueland.com/twit.
[02:13:57.640 --> 02:14:04.920]   Thank you for your support of This Week in Tech, our first science project on the show, John. It's good.
[02:14:04.920 --> 02:14:11.640]   Hey, we had a great week this week at Twitter and we have a wonderful little mini movie.
[02:14:11.640 --> 02:14:15.720]   Our talented staff, I think Victor made this just for your Delectation and Joy.
[02:14:16.760 --> 02:14:22.600]   Today we're going to do a fireside chat with the man that most of you all know is the angry one on
[02:14:22.600 --> 02:14:29.720]   just acting Google. Hey, hey, hey. Who's angry here? Previously on Twit.
[02:14:29.720 --> 02:14:36.680]   Hands on photography. I challenged you. You stepped up for the challenge. Yep, we're talking about the
[02:14:36.680 --> 02:14:41.560]   moon photography challenge. You guys sent in a bunch of different images. I'm only going to show
[02:14:41.560 --> 02:14:47.320]   your hand full of them. Tech News Weekly. So what does an NFT of a tweet mean? I don't know, but
[02:14:47.320 --> 02:14:56.280]   Astave paid $2.9 million for it. The punchline is that he is now trying to sell it and the best
[02:14:56.280 --> 02:15:03.880]   offer he got was actually $10,000. For $10,000, do you find value in Dorsey's original tweet?
[02:15:03.880 --> 02:15:08.840]   I think I would pay $2.80. Okay, nice. Nice.
[02:15:11.000 --> 02:15:18.040]   This week in Google, Gilbert Godfried passed away at the young age of 67 way too young.
[02:15:18.040 --> 02:15:23.880]   Yeah, very disturbing. Here's the real Gilbert Godfried playing Microsoft's
[02:15:23.880 --> 02:15:31.080]   favorite mascot. Orphish XP, yeah? Well, we'll just see about this. Hey, you,
[02:15:31.080 --> 02:15:36.200]   it looks like you're writing your letter. Would you like? Beat it. Twit. Hey, you.
[02:15:39.720 --> 02:15:44.040]   Stop right there. They didn't want my full Gilbert Godfried impression. Okay, I understand that.
[02:15:44.040 --> 02:15:47.960]   By the way, Owen Thomas, who was on Tech News Weekly there will be joining us next week, I think,
[02:15:47.960 --> 02:15:53.880]   on a Twit. Hope you enjoyed the show. That interview with Jeff Jarvis, I don't want to
[02:15:53.880 --> 02:15:58.200]   disappoint you, but that's for club Twit members. It appears on the Twit Plus feed,
[02:15:58.200 --> 02:16:03.240]   a little plug for club Twit. Add free versions of all the shows. You don't get the science experiments.
[02:16:03.240 --> 02:16:09.400]   You just get the content. Plus, you get access to the Discord, which is so much fun. We love our
[02:16:09.720 --> 02:16:16.200]   club Twit Discord. It's my personal favorite social network of all time. And the Twit Plus feed,
[02:16:16.200 --> 02:16:21.480]   we have so many shows that are only in club Twit now, Stacey's book club. That's part of the
[02:16:21.480 --> 02:16:27.080]   Twit Plus feed, the untitled Linux show, the Gizfiz with Dicty Bartolo. And we are launching more
[02:16:27.080 --> 02:16:32.600]   shows. Some of those shows, thanks to members, we are able to then put into the regular feed like
[02:16:32.600 --> 02:16:36.840]   this week in space with Rod Pylen, Tark Malik, which we just launched in our regular feeds,
[02:16:36.840 --> 02:16:42.760]   our newest show on the Twit Network. Thanks to the support of our club Twit members. I think it's a
[02:16:42.760 --> 02:16:50.120]   pretty good deal for seven bucks a month. Twit.tv/clubtwit. Thank you very much. We're talking about
[02:16:50.120 --> 02:16:58.040]   Mark Zuckerberg. He has very good security. He has the most expensive security in Silicon Valley,
[02:16:58.600 --> 02:17:07.400]   $25.2 million a year to protect Zuck, Shale Samberg, $9 million, Sundar Pichai, only $4.3.
[02:17:07.400 --> 02:17:12.920]   For some reason, Evan Spiegel of chat really thinks he's at risk. He's got $2.3 million.
[02:17:12.920 --> 02:17:19.160]   More than Larry Ellison, $2.2. Jeff Bezos, a mere $1.6 million to protect Jeff. But that's
[02:17:19.160 --> 02:17:26.840]   because he's so buff. He could protect himself. Warren Buffett, just $2.73,000. And the CEO,
[02:17:26.840 --> 02:17:35.240]   the new CEO of Twitter, Paregg, Agroll Wall, $63.8,000. But no number on Elon Musk. I wonder how much
[02:17:35.240 --> 02:17:43.240]   he doesn't want to talk about it. What's the number on you, Leo? By security. I don't know.
[02:17:43.240 --> 02:17:45.640]   We should have some. I don't want to talk about it.
[02:17:45.640 --> 02:17:52.120]   Right. Well, we laid them on. That's right. No one really knows what Burke's background is.
[02:17:52.680 --> 02:17:58.280]   Leo keeps that top secret. They just think he's the cook, but he's not. He's a kickboxing.
[02:17:58.280 --> 02:18:05.160]   Yes. No, we actually had a guard at the front desk. The great Mo loved him. Ex-Marine
[02:18:05.160 --> 02:18:11.560]   carried a he was licensed to carry and had a you know, was greeted everyone coming in the
[02:18:11.560 --> 02:18:18.520]   door with a stern expression. But when COVID hit, nobody came to the door anymore. So we
[02:18:18.520 --> 02:18:22.840]   hadn't lay him off. But most a great guy. He got another job. I'm glad to say it.
[02:18:22.840 --> 02:18:28.200]   I guess maybe someday we'll bring him back. I'm still nervous about having people in studio.
[02:18:28.200 --> 02:18:32.680]   I don't know. You're okay, Harry. I checked you out. Yeah, but I'm the only person here.
[02:18:32.680 --> 02:18:38.680]   Yeah. Other than the gang. Yeah. He said that and looked right at Harry when I was there.
[02:18:38.680 --> 02:18:42.680]   When was the last time you had an actual audience in here?
[02:18:44.120 --> 02:18:50.360]   I think it would probably be February 2020. Yeah. Nobody's come in since we closed the studio a
[02:18:50.360 --> 02:18:55.800]   little bit before the state of California shut down on St. Patrick's Day, March 17th.
[02:18:55.800 --> 02:19:00.920]   But we decided to mostly to protect. I asked the employees. I said, how do you feel about
[02:19:00.920 --> 02:19:05.640]   letting people come in? And a number of them said, you know, we don't feel safe with that. So we
[02:19:05.640 --> 02:19:10.200]   shut it down earlier. I don't remember the date. Do you remember John? No, I think it was early March.
[02:19:11.160 --> 02:19:15.960]   Maybe for your 18th anniversary, you can bring them back. I'm thinking 20th. I don't know.
[02:19:15.960 --> 02:19:22.120]   Sometimes, someday. We'd have to bring Mo back too, because I've got to have security. I do.
[02:19:22.120 --> 02:19:25.640]   What do you think they get for 20? You would know this. Alex, you seem like a
[02:19:25.640 --> 02:19:29.880]   guy would know what you get for $25 million in security.
[02:19:29.880 --> 02:19:36.680]   You know, a lot of it has to do with the function of how much you travel.
[02:19:36.680 --> 02:19:40.520]   So a lot of that expense. And then also how it's just budgeted by the company.
[02:19:40.520 --> 02:19:44.040]   Because the private jets expensive, right? I mean, that's well, but that doesn't count.
[02:19:44.040 --> 02:19:49.320]   The executive has that. So it doesn't cost more to put someone in. I mean,
[02:19:49.320 --> 02:19:53.240]   all the only differences, little sandwiches. You know, so the, so the, you got to have a taste.
[02:19:53.240 --> 02:19:56.520]   They're expensive. They're expensive. We'll say the sandwiches are really good. Anyway, so
[02:19:56.520 --> 02:20:00.440]   remarkably good. Like you're like, how did they get really?
[02:20:00.440 --> 02:20:03.720]   Really? So I've never been in a private jet.
[02:20:03.720 --> 02:20:08.440]   Yeah, I had to do a bunch of tests in a G4. And so it was, it was fun because I just
[02:20:08.440 --> 02:20:11.560]   had to do it. We just got to fly around trying to stream out of a G4, which doesn't work in case
[02:20:11.560 --> 02:20:17.800]   you're wondering. Oh, really? So like somebody was saying, our executive wants to do a show,
[02:20:17.800 --> 02:20:23.400]   no, as an event for an event for a G4. They wanted to shoot the eclipse from a G4.
[02:20:23.400 --> 02:20:29.640]   Oh, well, that's cool. So they wanted to stream 160 miles off the coast of, of, of, of, of,
[02:20:29.640 --> 02:20:33.960]   Oregon, which means you can't shoot down because you can't, you know, so that's how, you know,
[02:20:33.960 --> 02:20:38.040]   and you can't, and then it didn't have an up point, satellite dish. And so you couldn't,
[02:20:38.040 --> 02:20:41.320]   so we were, we told them isn't going to work. I'm not going to say who it was. We told them it
[02:20:41.320 --> 02:20:43.640]   wasn't going to work, but they still wanted, they were committed to doing it. And I was like,
[02:20:43.640 --> 02:20:45.880]   well, if you want me to go up and test it, I will test it for you.
[02:20:45.880 --> 02:20:49.320]   I'm going to eat sandwiches is what you said. But well, they just, they just, they just rented
[02:20:49.320 --> 02:20:53.240]   a G4 and it comes with the sandwiches and someone who serves them. So anyway,
[02:20:53.240 --> 02:20:59.160]   so it's just, it's just, it's just garbage. So, and they're really nice. They're really good
[02:20:59.160 --> 02:21:04.600]   sandwiches. Anyway, so they come, but the Air Force one, however, can stream, I should say.
[02:21:04.600 --> 02:21:08.440]   Yeah, yeah, exactly. So, so, you know, with security though, I mean, so a lot of some,
[02:21:08.440 --> 02:21:13.320]   someone at that level is typically pulling people out of soft, you know, special operations,
[02:21:13.320 --> 02:21:17.960]   and as well as SAS. I mean, those are the two. And the problem is, is that the issue that you have
[02:21:17.960 --> 02:21:21.720]   with it is that they have to be good at what they do. And these are usually people who are
[02:21:21.720 --> 02:21:28.200]   really good at what they do. And they also have to be public facing. So there's a lot of people
[02:21:28.200 --> 02:21:31.720]   who are really good at looking. Well, they can't have face tats.
[02:21:32.440 --> 02:21:38.040]   And not gruff and not, you know, like, not like respond, you know, respond badly.
[02:21:38.040 --> 02:21:41.880]   So, so the thing is, is that there's, you know, so there's a big percentage of the people who aren't
[02:21:41.880 --> 02:21:47.240]   public facing end up at Blackwater and the people who are public facing end up in security.
[02:21:47.240 --> 02:21:51.480]   Yeah. And but you are competing with Blackwater salaries, which are like 300,000 a year.
[02:21:51.480 --> 02:21:56.440]   So, so you know, you get a group of people that have to take care of someone, then you end up with,
[02:21:56.440 --> 02:22:00.360]   you know, six to eight of folks there. That's your base. Then you have to travel them around.
[02:22:00.360 --> 02:22:04.840]   Then you have to, you know, then you have, you know, all their hotels. And anytime you go anywhere,
[02:22:04.840 --> 02:22:08.200]   there's a group of these people that are that are wandering around and making sure that everything's
[02:22:08.200 --> 02:22:13.160]   working. So you have, you know, the person travels a lot. So, you know, my guess is it's heavily
[02:22:13.160 --> 02:22:18.840]   related to how much an executive travels is how much in Mark, you know, we would assume gets around.
[02:22:18.840 --> 02:22:25.560]   And so the other thing is you'd have to pay me a lot of money to be willing to take a bullet for
[02:22:25.560 --> 02:22:30.520]   Mark. You know, I'm saying, he's people, people who live in, he's a good guy.
[02:22:30.520 --> 02:22:37.160]   This really is the experience of encountering his security. Oh, really? Yes. Well, didn't he buy
[02:22:37.160 --> 02:22:42.040]   all the houses around his house? I believe so. Yeah. And in Hawaii, I'm going to move the microphone
[02:22:42.040 --> 02:22:48.840]   closer to you because it's monitoring you. And in Hawaii, he bought all the land around. In fact,
[02:22:48.840 --> 02:22:53.880]   that's a big controversy because he brought lots of land and he tried to keep people off the beaches
[02:22:53.880 --> 02:22:58.680]   where they are. Well, and is that is, is he traveling? I've, I did a story on that. Like, he's been going
[02:22:58.680 --> 02:23:03.800]   back and forth to, I think Hawaii and LA a lot. Like maybe it is the travel just back and forth
[02:23:03.800 --> 02:23:10.680]   between his like remote work. And this is the other thing. He only gets a dollar a year compensation.
[02:23:10.680 --> 02:23:13.960]   He's doing okay. I'm sure he's not.
[02:23:13.960 --> 02:23:18.040]   What does he have to sell stock a little bit at a time just to pay for the
[02:23:18.040 --> 02:23:21.880]   a lot of so a lot of executive. How do you pay for the dog walker?
[02:23:21.880 --> 02:23:25.720]   So a lot of executives have a set schedule to sell their stock.
[02:23:25.720 --> 02:23:30.120]   Right. So to, you know, you don't want to have any surges because if you start selling a lot of
[02:23:30.120 --> 02:23:33.800]   it all at one time, someone's just bad. Something happened. And so you set up a schedule and so
[02:23:33.800 --> 02:23:37.640]   it's just turning that, turning it over and generating revenue from it. But then if you decide you want
[02:23:37.640 --> 02:23:44.040]   to buy Twitter, that's everything. You need to, that's a lot of. Well, the other thing they do is
[02:23:44.040 --> 02:23:48.120]   they borrow against, they borrow against their stock. Right. And then they, and then that that's
[02:23:48.120 --> 02:23:51.240]   tax free, you know, so making a dollar just means you're not paying.
[02:23:51.240 --> 02:23:57.000]   You probably doing a lot of stories. I'm sure Brian on NFTs, cryptocurrency.
[02:23:57.000 --> 02:24:03.400]   There've been a lot of ripoffs and scams lately. I thought I'd do a positive story
[02:24:03.400 --> 02:24:09.320]   about crypto. The board apes are getting a movie trilogy.
[02:24:09.320 --> 02:24:13.000]   I did this one, yeah. Yeah. Yeah.
[02:24:14.280 --> 02:24:22.760]   Coinbase is producing a trio of films. But wait, stop Leo. Coinbase is producing not
[02:24:22.760 --> 02:24:26.840]   paramount. Not Hollywood. Coinbase. I'm sure that'll turn out great.
[02:24:26.840 --> 02:24:31.800]   The hard part, the hard part there is, again, talent. Like the streaming companies have taken
[02:24:31.800 --> 02:24:36.600]   up like everybody's busy. You know, so if you're not doing it with a big studio, you're going to
[02:24:36.600 --> 02:24:41.720]   have to set the table. And then there's, I want to tell you the most interesting thing about this.
[02:24:41.720 --> 02:24:47.000]   Okay. The first three installments for the series of animated shorts
[02:24:47.000 --> 02:24:51.880]   called the Degan trilogy. I'm sure there's a meaning to that. We'll premiere.
[02:24:51.880 --> 02:24:55.480]   No, Degen, like Degen like Degen. Oh, Degen.
[02:24:55.480 --> 02:25:01.880]   Generative because they're board apes. So they're degenerative. We'll premiere at NFT NYC
[02:25:01.880 --> 02:25:09.320]   in June with the NFT community of apes and non apes alike having a say in the film's plot.
[02:25:09.320 --> 02:25:15.320]   Oh, it goes downhill. It goes downhill. So what's the story?
[02:25:15.320 --> 02:25:21.000]   Well, so not only is it plot by committee, but also one of the interesting things,
[02:25:21.000 --> 02:25:26.920]   at least I've been told, but we'll see how this actually plays out. But you own the IP of the ape
[02:25:26.920 --> 02:25:33.480]   that you own. That's like what they put into the Dow. So you're the most interesting thing to me was
[02:25:34.360 --> 02:25:40.280]   everyone is allowed to audition their ape to be in the show.
[02:25:40.280 --> 02:25:46.920]   Or how do you audition an NFT? Well, but that's, I mean, this is what's interesting.
[02:25:46.920 --> 02:25:52.360]   You have to apply and be like, look, my ape is the coolest. He's got a sort of
[02:25:52.360 --> 02:25:55.800]   remember Leonardo from the Teenage Mutant Ninja Turtles. He's got like that sort of,
[02:25:55.800 --> 02:26:00.040]   he's a rebel, but he's cool vibe. I don't know.
[02:26:00.040 --> 02:26:03.640]   You will not be able to see the videos unless you have a Coinbase wallet.
[02:26:03.640 --> 02:26:10.040]   Okay. I think they're, I think to be fair, I think they're going to debut it.
[02:26:10.040 --> 02:26:15.240]   And God, listen, God knows, if it was popular, you'll see it in a multiplex.
[02:26:15.240 --> 02:26:19.960]   That's right. But then eventually sort of like Disney used to do with, you know,
[02:26:19.960 --> 02:26:24.520]   Snow White, they'll put it in a vault and only certain people can see it.
[02:26:24.520 --> 02:26:29.720]   Did you ever go to the board A.P. Yacht Club themed pop-up burger restaurant in Long Beach?
[02:26:31.960 --> 02:26:37.480]   Oh my God. What do we think of all these? We think of all these things as crazy,
[02:26:37.480 --> 02:26:40.840]   but the reality is the art world has been crazy for a long time. You know, like it's,
[02:26:40.840 --> 02:26:44.120]   it's not, there's nothing like someone sold a banana for hundred, any five dollars.
[02:26:44.120 --> 02:26:46.840]   And so sure. So it's, you know, it's not any like NFTs.
[02:26:46.840 --> 02:26:49.800]   It's like artwork, Basel, Art World Basel or something like that, right?
[02:26:49.800 --> 02:26:54.120]   One of the greatest pieces of art of all time is Duchamp's urinal,
[02:26:54.120 --> 02:26:58.440]   right, which he called Fountain, which was a urinal, but he called it a fountain.
[02:26:58.440 --> 02:26:59.880]   On a wall. And he put it on the wall. Yeah.
[02:27:01.240 --> 02:27:06.120]   Yeah. Isn't that funny? Ha ha. No, you're right. Or the banana, which apparently,
[02:27:06.120 --> 02:27:09.160]   but, but, you know, I was talking to someone about NFTs and the best thing that ever,
[02:27:09.160 --> 02:27:13.960]   someone ever said, when I clicked for me about NFTs was, was when he said, when he said, it was
[02:27:13.960 --> 02:27:21.320]   basically Babe Ruth's, you know, 1927 card, the paper is worth nothing. Like the paper,
[02:27:21.320 --> 02:27:26.280]   the paper of the card is worth nothing. It's because we have provenance and we say it's valuable.
[02:27:26.280 --> 02:27:30.360]   Like that is it. Like, you know, and, and the blockchain gives it provenance and then we just
[02:27:30.360 --> 02:27:34.760]   start saying it's bad. So what went wrong with Jack Dorsey's first tweet?
[02:27:34.760 --> 02:27:40.680]   It's absurd. It was an absurd idea. Like, it's a lot of, there's a lot of art that gets bought,
[02:27:40.680 --> 02:27:45.320]   and then it's not worth anything. Yeah. It's like, are you where, are you where the fact that
[02:27:45.320 --> 02:27:52.120]   I'm pretty sure no one has been able to disprove this? I, I made an NFT of a podcast episode.
[02:27:52.120 --> 02:27:56.920]   I think it was January of last year. It's, see if you can find it. It's on rarerable.
[02:27:56.920 --> 02:28:04.120]   Look for a tech meme right home on rarerable. But I might, I've only sold eight of the 10,
[02:28:04.120 --> 02:28:10.600]   but I'm pretty sure it's the first NFT of a podcast episode. So you get to try to,
[02:28:10.600 --> 02:28:13.960]   try to place in that respect. That's what I'm trying to say. Here it is.
[02:28:13.960 --> 02:28:18.600]   That's the interview with Gary Tan from February 6th of last year.
[02:28:18.600 --> 02:28:23.800]   Yep. Titled bonus office hours with, did you, was there some reason Gary Tan?
[02:28:25.320 --> 02:28:30.440]   No, I just, we were talking about NFTs. Could have been me. I agree. I, I missed the opportunity
[02:28:30.440 --> 02:28:34.120]   to be a pioneer in this space. The point we're trying to make is there's two left,
[02:28:34.120 --> 02:28:37.000]   and it's the first one. That's the point we're trying to make. The current highest bid.
[02:28:37.000 --> 02:28:44.040]   No, there's eight left. There's eight left. I meant to this one. You made it to a two or gone.
[02:28:44.040 --> 02:28:48.920]   The most important thing is Christmas. Yeah. I sold two Christmas.
[02:28:48.920 --> 02:28:55.480]   I bought one, which is nice. I sold two and I lost money because the gas fees,
[02:28:55.480 --> 02:29:00.520]   gas fees, actually make the sale happen cost more than I got in the.
[02:29:00.520 --> 02:29:09.160]   So you sold it for less than $100. I had a tax bill this year for crypto for the first time in
[02:29:09.160 --> 02:29:15.800]   my life because of this. That's funny. Well, somebody's getting rich. And as usual,
[02:29:15.800 --> 02:29:21.480]   it's the behind the scenes people who provide the highest bit, .04 e.
[02:29:21.480 --> 02:29:27.720]   Now let's get that up there, people. Come on. 122 bucks for one edition. Come on.
[02:29:27.720 --> 02:29:32.840]   First one. Although the first, if the first tweet as I, I, I, I hijacked that,
[02:29:32.840 --> 02:29:36.440]   if the first tweet isn't going to do it, I don't know that the first, well, I mean,
[02:29:36.440 --> 02:29:41.960]   still going for 10,000. That wasn't 29 million. I kind of feel bad for the guy who spent the 29
[02:29:41.960 --> 02:29:47.160]   million until I realized he probably didn't spend 29 million dollars. He's probably spent some
[02:29:47.160 --> 02:29:52.360]   Bitcoin he had lying around or something. Yeah. No, I'm a lot of this. I think it's driven by
[02:29:52.360 --> 02:29:55.640]   people who made a lot of money and a lot of money and they're not, they're not the kind of people
[02:29:55.640 --> 02:29:58.600]   that want to want something on the wall. They want something electronic and so it provides
[02:29:58.600 --> 02:30:02.520]   something like, trynnek and you know, they, that's right. It's also art is also a great way to,
[02:30:02.520 --> 02:30:09.080]   you know, launder money. Yeah. Ladies, gentlemen, rarerable.com. Go on and get your tech meme
[02:30:09.080 --> 02:30:15.000]   ride home podcast. The very first, as far as we know podcast NFT.
[02:30:15.000 --> 02:30:19.720]   No one's been able to disprove it yet. And people have been talking about it.
[02:30:19.720 --> 02:30:25.000]   That's awesome. Congratulations. You're a historic figure.
[02:30:25.000 --> 02:30:30.680]   Exactly. That's very good. That's Brian McCullough, Tech meme ride home. It's easy to find. You just go
[02:30:30.680 --> 02:30:35.320]   to tech meme.com. It's on the front page there. Well, but of course you probably should subscribe
[02:30:35.320 --> 02:30:39.480]   in your favorite podcast player. So you don't have to think about going anywhere. It just arrives
[02:30:39.480 --> 02:30:45.880]   magically. Are you doing anything else? Or is that a, that's probably a full time gig, I would
[02:30:45.880 --> 02:30:52.840]   imagine. It is, although the podcast, sorry to say, raised a venture fund. Wait a minute, what?
[02:30:52.840 --> 02:31:02.680]   Yes. You don't have an NFT, but you have a venture fund? Yeah. It started in October. All of the LPs
[02:31:02.680 --> 02:31:07.960]   are listeners of the show. It's a tiny, tiny fund. It's only an early stage.
[02:31:07.960 --> 02:31:14.360]   You're like a king of the new finance. Three mil, but it's a rolling fund.
[02:31:14.360 --> 02:31:23.800]   And so that could go up too, because any credit an investor could invest. But it's been beautiful
[02:31:23.800 --> 02:31:28.840]   because we're running it open kimono style. Every company we invest in, we have them come on the
[02:31:28.840 --> 02:31:34.600]   show, talk about what they're doing. So even if you're not an investor in the podcast, hopefully,
[02:31:34.600 --> 02:31:39.960]   or in the fund, sorry, all of the listeners of the podcast will become fans of you.
[02:31:39.960 --> 02:31:43.880]   You're quite the innovator. Ridehomefund.com.
[02:31:43.880 --> 02:31:49.320]   That is true. You're quite, when you say three million, is that like people have given you
[02:31:49.320 --> 02:31:56.040]   three million dollars to invest? As of this moment, three million dollars. Now, it's a rolling fund.
[02:31:56.040 --> 02:31:58.840]   So next year, we'll see how many people re-up.
[02:31:58.840 --> 02:32:04.200]   And have you invested anything yet? Yes, 18 companies.
[02:32:04.200 --> 02:32:10.200]   Of which only four are on there because, again, we're leveraging the show.
[02:32:10.200 --> 02:32:18.440]   We don't want to announce it until it's useful to the companies. And so when you come on and say,
[02:32:18.440 --> 02:32:23.640]   hey, here's what we're doing. We want to be introduced to this company, or we're hiring in
[02:32:23.640 --> 02:32:29.560]   this area. So we've invested in 18 companies, but we'll see how long it takes.
[02:32:29.560 --> 02:32:32.040]   Brian, I'm guessing that you're 39.
[02:32:32.040 --> 02:32:35.080]   39? Why do you say that?
[02:32:35.080 --> 02:32:40.520]   Because that's when people really kick into gear like Bill Gates and exactly Zuckerberg.
[02:32:40.520 --> 02:32:42.840]   And I think you're kicking into gear, my friend.
[02:32:42.840 --> 02:32:44.520]   Sadly, I'm 44.
[02:32:44.520 --> 02:32:45.800]   Oh, well, you're a little late.
[02:32:45.800 --> 02:32:48.200]   That's okay. It's close enough. That's close enough.
[02:32:48.200 --> 02:32:50.360]   You probably had the idea for this when you were 39.
[02:32:52.440 --> 02:32:58.120]   No, but listen, the fact that you can do this through AngelList,
[02:32:58.120 --> 02:33:01.400]   etc. Listen, I derailed everything. I apologize.
[02:33:01.400 --> 02:33:06.600]   No, this is I'm asking you for your plug. And this is it. This is great. In fact,
[02:33:06.600 --> 02:33:09.480]   I'm blown away. Ride home fund.
[02:33:09.480 --> 02:33:10.840]   Tech me ride home.
[02:33:10.840 --> 02:33:12.200]   You think the podcast.
[02:33:12.200 --> 02:33:18.440]   Yes. Not only that, and by the way, it's early stage, right? So these are really,
[02:33:18.440 --> 02:33:22.280]   these are like ground floor, getting in on the ground floor of these companies.
[02:33:22.280 --> 02:33:25.560]   Which is, which is Leo, why I think it works is that like, look, no one.
[02:33:25.560 --> 02:33:26.200]   You have to deal flow.
[02:33:26.200 --> 02:33:31.960]   Well, but no one that is raising a hundred million dollars series B or C needs me.
[02:33:31.960 --> 02:33:32.520]   Right.
[02:33:32.520 --> 02:33:38.840]   But a certain type of company that wants to reach tens of thousands of people that work in tech
[02:33:38.840 --> 02:33:43.480]   might just kick myself. I didn't think of this. That's all.
[02:33:43.480 --> 02:33:46.040]   You can do it.
[02:33:46.040 --> 02:33:46.280]   No.
[02:33:47.080 --> 02:33:50.040]   No, am I going to offer an NFT?
[02:33:50.040 --> 02:33:53.960]   But we might have cupcakes on our 20th anniversary show.
[02:33:53.960 --> 02:33:56.120]   I'm just saying, hang in there for that.
[02:33:56.120 --> 02:33:58.600]   Ride home fund.com. I love it.
[02:33:58.600 --> 02:33:59.960]   That's great. That's great.
[02:33:59.960 --> 02:34:04.200]   And don't forget, rarerable for your chance to get in.
[02:34:04.200 --> 02:34:08.280]   You know, if the NFT goes high enough, then forget the fun.
[02:34:08.280 --> 02:34:15.400]   Yeah, because you don't get to keep the three million, but you get to keep the point zero for
[02:34:15.400 --> 02:34:18.760]   Eath. I'm just, I'm a river to my people as they say.
[02:34:18.760 --> 02:34:19.560]   That's exactly right.
[02:34:19.560 --> 02:34:19.800]   Yep.
[02:34:19.800 --> 02:34:22.440]   Harry McCrack and the technologizer.
[02:34:22.440 --> 02:34:29.560]   Did you think back in 1996, we'd be sitting here doing this global technology editor at fast
[02:34:29.560 --> 02:34:30.840]   company?
[02:34:30.840 --> 02:34:32.600]   And look what you're using.
[02:34:32.600 --> 02:34:33.480]   An iPad mini.
[02:34:33.480 --> 02:34:35.880]   I mean, iPad Pro.
[02:34:35.880 --> 02:34:37.800]   It's the small iPad Pro.
[02:34:37.800 --> 02:34:39.480]   Oh, it's the 11 inch iPad Pro.
[02:34:39.480 --> 02:34:39.960]   I love it.
[02:34:39.960 --> 02:34:41.160]   The size is just perfect.
[02:34:41.160 --> 02:34:41.240]   Yeah.
[02:34:41.240 --> 02:34:41.720]   Yeah.
[02:34:41.720 --> 02:34:42.760]   That's your computer.
[02:34:42.760 --> 02:34:44.120]   Is that your main computer?
[02:34:44.120 --> 02:34:47.480]   My main computer and I'm much happier than when I use the larger one just because it's more portable
[02:34:47.480 --> 02:34:49.560]   and it works much better as a tablet than the larger one.
[02:34:49.560 --> 02:34:51.960]   You write all those great articles and fast company event thing?
[02:34:51.960 --> 02:34:57.880]   98% of the stuff I've written since 2011, I've written on an iPad.
[02:34:57.880 --> 02:34:58.040]   Wow.
[02:34:58.040 --> 02:34:59.320]   Wow.
[02:34:59.320 --> 02:35:03.000]   That's, I feel like Carpal Tunnel is in your future.
[02:35:03.000 --> 02:35:03.320]   I don't know.
[02:35:03.320 --> 02:35:03.720]   Help not.
[02:35:03.720 --> 02:35:04.840]   I just feel pretty good at that.
[02:35:04.840 --> 02:35:05.320]   Do they?
[02:35:05.320 --> 02:35:05.800]   Okay.
[02:35:05.800 --> 02:35:07.320]   Because there's no travel on that, right?
[02:35:07.320 --> 02:35:11.160]   No travel, but I never liked travel on keyboards.
[02:35:11.160 --> 02:35:12.920]   I've never met a keyboard snob at all.
[02:35:12.920 --> 02:35:13.400]   Nice.
[02:35:13.400 --> 02:35:14.440]   I'm so glad you came up.
[02:35:14.440 --> 02:35:14.760]   Thank you.
[02:35:14.760 --> 02:35:15.400]   It's been great.
[02:35:15.400 --> 02:35:16.360]   It's wonderful to see you.
[02:35:16.360 --> 02:35:19.720]   Let's hope that you continue to have people in the studio.
[02:35:19.720 --> 02:35:20.280]   Gradually.
[02:35:20.280 --> 02:35:21.080]   Inch by inch.
[02:35:21.080 --> 02:35:21.560]   We're working.
[02:35:21.560 --> 02:35:22.440]   Inch crossed?
[02:35:22.440 --> 02:35:22.680]   Yeah.
[02:35:22.680 --> 02:35:26.040]   Really nice to see you Harry.
[02:35:26.040 --> 02:35:28.600]   And of course, Alex, Lindsay, I'll see you on Tuesday.
[02:35:28.600 --> 02:35:33.880]   If you want to hire Alex to test your G5 satellite capabilities.
[02:35:33.880 --> 02:35:34.360]   I'm there.
[02:35:34.360 --> 02:35:34.760]   I'm there.
[02:35:34.760 --> 02:35:36.200]   He's there for us to have sandwiches.
[02:35:36.200 --> 02:35:36.360]   Oh.
[02:35:36.360 --> 02:35:38.360]   Came in sandwiches.
[02:35:38.360 --> 02:35:38.920]   Oh, nine.
[02:35:38.920 --> 02:35:39.560]   Oh, no.
[02:35:39.560 --> 02:35:41.800]   I sure he actually wants real dollars.
[02:35:41.800 --> 02:35:44.600]   Oh, nine. Oh, dot media is his business.
[02:35:44.600 --> 02:35:48.840]   But of course, the thing that he's doing that is also groundbreaking.
[02:35:48.840 --> 02:35:55.320]   Office hours dot global soon to be seen on the six megahertz band of satellite.
[02:35:55.320 --> 02:35:55.880]   Or something.
[02:35:55.880 --> 02:35:56.520]   Working on it.
[02:35:56.520 --> 02:35:57.320]   Yeah.
[02:35:57.320 --> 02:35:59.240]   Right now though, you go to office hours dot global.
[02:35:59.240 --> 02:36:00.760]   You can watch the YouTube videos.
[02:36:00.760 --> 02:36:02.360]   You can join the Zoom conversation.
[02:36:02.360 --> 02:36:04.840]   Fill out a form, get an invitation.
[02:36:04.840 --> 02:36:06.200]   All sorts of stuff.
[02:36:06.200 --> 02:36:09.080]   Even things like cooking on the weekends.
[02:36:10.200 --> 02:36:11.560]   Except is it the geekiest cooking?
[02:36:11.560 --> 02:36:14.040]   Because people cooking from their home, but they have a multi-cam setup.
[02:36:14.040 --> 02:36:17.640]   So everybody's talking to each other is like, let me show you the close up of what I'm doing here.
[02:36:17.640 --> 02:36:19.000]   And I don't understand how to do this.
[02:36:19.000 --> 02:36:23.720]   And so it's it's yeah, we take it to a different I take everything a little over.
[02:36:23.720 --> 02:36:24.840]   Honestly, that's kind of right.
[02:36:24.840 --> 02:36:29.240]   This is the most innovative thing going on in in the internet media right now.
[02:36:29.240 --> 02:36:30.920]   It's really fascinating what you're doing with it.
[02:36:30.920 --> 02:36:33.240]   Office hours dot global.
[02:36:33.240 --> 02:36:35.400]   And it's pretty much all the time.
[02:36:35.400 --> 02:36:36.360]   It's like 24.
[02:36:36.360 --> 02:36:36.760]   24.
[02:36:36.760 --> 02:36:38.040]   I'm coming out of this.
[02:36:38.040 --> 02:36:39.480]   I'm just going to go hang out with everybody.
[02:36:39.480 --> 02:36:41.960]   It's like the it's 24 hours a day.
[02:36:41.960 --> 02:36:44.360]   There's like a there's basically the most geeky water cooler.
[02:36:44.360 --> 02:36:47.880]   He can possibly imagine as you just sit there and yeah.
[02:36:47.880 --> 02:36:50.200]   It's great to have you Alex.
[02:36:50.200 --> 02:36:52.440]   I'm looking forward to seeing you on Tuesday.
[02:36:52.440 --> 02:36:53.240]   Well, some things.
[02:36:53.240 --> 02:36:54.200]   Always fun about.
[02:36:54.200 --> 02:36:59.640]   I love Apple and I love Mac break, but it's really fun to be on Twitch because it's just it's not quite as focused.
[02:36:59.640 --> 02:37:02.200]   Yeah, it's definitely not focused today.
[02:37:02.200 --> 02:37:03.480]   It's a little blurry.
[02:37:03.480 --> 02:37:04.840]   Oh, exactly.
[02:37:07.000 --> 02:37:10.920]   Thank you all for listening and watching.
[02:37:10.920 --> 02:37:13.000]   We do it live on the stream.
[02:37:13.000 --> 02:37:19.720]   If you want to watch us do it live every Sunday about 230 Pacific 530 Eastern 2130 UTC.
[02:37:19.720 --> 02:37:21.400]   You can go to live dot twit.tv.
[02:37:21.400 --> 02:37:24.040]   There's live audio and video streams there.
[02:37:24.040 --> 02:37:27.720]   Now, if you're watching live, you might want to, you know,
[02:37:27.720 --> 02:37:31.800]   explain what the hell is this to other people who are also watching live.
[02:37:31.800 --> 02:37:35.000]   That's what the IRC is for IRC dot twit.tv.
[02:37:35.000 --> 02:37:37.960]   You could join with a web browser or an IRC client.
[02:37:37.960 --> 02:37:44.200]   Of course, club twit members also can yell at the clouds in our beautiful discord server.
[02:37:44.200 --> 02:37:47.080]   So we'd love to see you in either of those places.
[02:37:47.080 --> 02:37:53.480]   After the fact on demand versions of the show are available on the web at our website, twit.tv.
[02:37:53.480 --> 02:37:59.320]   I think all 17 years worth of episodes, all 871 episodes are there.
[02:37:59.320 --> 02:38:02.440]   So you can download go back in time if you want to download any one of those,
[02:38:02.440 --> 02:38:04.680]   including Harry's first appearance in 2008.
[02:38:05.560 --> 02:38:09.400]   You can also go to the YouTube channel where not all the episodes,
[02:38:09.400 --> 02:38:13.480]   but almost all the video episodes live and watch there.
[02:38:13.480 --> 02:38:18.440]   Best thing to do though, if you want to listen to the latest is subscribe in your favorite podcast
[02:38:18.440 --> 02:38:20.120]   client. That way you'll get it automatically.
[02:38:20.120 --> 02:38:24.520]   As soon as it's done, the editors are going to get ahold of it, cut out all the cuss words
[02:38:24.520 --> 02:38:28.120]   and put it up on the on the internet via RSS.
[02:38:28.120 --> 02:38:31.400]   If you subscribe in your podcast player and they allow for reviews,
[02:38:31.960 --> 02:38:35.240]   do leave us a five star review. We would really appreciate that.
[02:38:35.240 --> 02:38:37.560]   It's hard to believe, but after 17 years in the business,
[02:38:37.560 --> 02:38:39.800]   there's still one or two people who've never heard of twit.
[02:38:39.800 --> 02:38:41.320]   So spread the good news.
[02:38:41.320 --> 02:38:43.400]   Thanks for being here. We'll see you next time.
[02:38:43.400 --> 02:38:44.200]   Another twit.
[02:38:44.280 --> 02:38:45.640]   This is amazing.
[02:38:45.640 --> 02:38:57.640]   See you next time.

