;FFMETADATA1
title=Go Dung Beetles!
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=674
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:03.840]   It's time for Twit this weekend tech. We have a great panel for you Ian Thompson from the
[00:00:03.840 --> 00:00:10.980]   registers here. Lisa Schmeiser from ITPro today. And also our great friend from Tech
[00:00:10.980 --> 00:00:14.520]   Republic, the man who may be the president of the internet, Jason Heiner. We're going
[00:00:14.520 --> 00:00:20.520]   to talk a lot about where the billionaires will go when everything goes to pieces and
[00:00:20.520 --> 00:00:24.760]   why it might not be such a good idea. Why the future actually is pretty bright and we're
[00:00:24.760 --> 00:00:29.840]   going to help a young man named Logan find work. It's all coming up next on Twit.
[00:00:29.840 --> 00:00:35.720]   Netcast you love from people you trust.
[00:00:35.720 --> 00:00:49.960]   This is Twit. Bandwidth for this weekend tech is provided by CashFly at CACHEFLY.com.
[00:00:49.960 --> 00:01:06.560]   This is Twit this weekend tech episode 674 recorded Sunday July 8th 2018. Go dung beetles.
[00:01:06.560 --> 00:01:10.720]   This weekend tech is brought to you by WordPress reach more customers when you build your business
[00:01:10.720 --> 00:01:16.840]   website at WordPress.com. Plan started just $4 a month and you can get 15% off any new
[00:01:16.840 --> 00:01:24.640]   plan at WordPress.com/Twit. And by the Ring Video Doorbell stop crime before it happens
[00:01:24.640 --> 00:01:30.920]   and help make your neighborhood safer with Ring. Go to Ring.com/Twit and get up to $150
[00:01:30.920 --> 00:01:37.800]   off a Ring of Security kit. And by Uber. Read about all the ways Uber is moving forward
[00:01:37.800 --> 00:01:45.440]   by going to uber.com/movingforward. And by Slack. Slack is a collaboration hub for work
[00:01:45.440 --> 00:01:50.040]   to make sure the right people on your team are always in the loop and key information
[00:01:50.040 --> 00:01:56.320]   is always at their fingertips. Learn more at slack.com.
[00:01:56.320 --> 00:02:01.360]   It's time for Twit this weekend tech show where we cover the weeks. Tech news I have
[00:02:01.360 --> 00:02:07.160]   gathered together once again a fine panel of tech journalists starting with Ian Thompson
[00:02:07.160 --> 00:02:13.400]   from the register.co.uk where he is news editor. Always welcome here. It was fun.
[00:02:13.400 --> 00:02:19.720]   Your beat is pretty widespread. You cover everything from hacking to hacking election
[00:02:19.720 --> 00:02:28.880]   devices. Oh election medical. Some space stuff as well. We allow roving beats. Also from
[00:02:28.880 --> 00:02:35.080]   ITPro. Ladies and gentlemen Lisa Schweizer, ITPro today. She's the editor there. Hi Lisa.
[00:02:35.080 --> 00:02:40.800]   Hi I'm an editor there. I do have a boss. I always get the article wrong with you.
[00:02:40.800 --> 00:02:47.280]   The editor. The editor at Tech Republic is here. Jason Heiner from CBS Interactive editor
[00:02:47.280 --> 00:02:53.400]   in chief even. Pleasure to be here as ever. Do you like ever are you ever tempted to say
[00:02:53.400 --> 00:03:00.800]   great Caesar's ghost or things like that? Copy. Get in here.
[00:03:00.800 --> 00:03:06.800]   Yeah. You know Lisa was looking at our rundown today of stories and it all seems like tech
[00:03:06.800 --> 00:03:12.480]   gone wrong and I hate to kind of focus on that. Did Elon Musk build the kid size submarine
[00:03:12.480 --> 00:03:17.320]   to rescue the soccer team in the Thailand cave? He did but they didn't end up needing
[00:03:17.320 --> 00:03:22.080]   it. They didn't need it. Yeah they brought them out with two experienced divers on short
[00:03:22.080 --> 00:03:25.840]   cables with it between them. They got them all out. Well so last time I heard it was
[00:03:25.840 --> 00:03:31.280]   six kids out. Okay. It looks like it's a viable. I was human skill and experience actually
[00:03:31.280 --> 00:03:36.480]   trumped a technological. I think a kid size submarine. So it's very neat. Yeah. All right.
[00:03:36.480 --> 00:03:40.680]   Well I would have liked one as an eight year old. Yeah. This is what I love Elon Musk because
[00:03:40.680 --> 00:03:44.760]   it's like oh I know. Although have you ever been in a submarine they're actually pretty
[00:03:44.760 --> 00:03:49.440]   kid sized already? Right. Yeah. It's true. No. I thought it was going to be like bore
[00:03:49.440 --> 00:03:53.880]   through the top of the mountain or something. Yeah. Yeah. I was one of the giant drills.
[00:03:53.880 --> 00:03:59.720]   Apparently it's like cool. It's like half kilometer down and really unpleasant drilling
[00:03:59.720 --> 00:04:05.240]   material but it just you feel for the port. I mean being down there that long. Yeah. No.
[00:04:05.240 --> 00:04:09.760]   It was supposed to be a fun nature hike or sort of fun hike for a birthday or something.
[00:04:09.760 --> 00:04:14.520]   It was just and thank God so many professional divers just rushed in from around the world
[00:04:14.520 --> 00:04:19.720]   and help. If you've ever been caving you know how dangerous it is. Right. There it is. It's
[00:04:19.720 --> 00:04:25.480]   really more of a tube. Yeah. Four air oxygen ports front and rear front. You know that's
[00:04:25.480 --> 00:04:30.680]   kind of this is right. You got to kind of honor Elon for just being like well let's just do
[00:04:30.680 --> 00:04:35.240]   this. Yeah. Let's just solve it. Hold my beer. Hold my beer. I'm going to make a small
[00:04:35.240 --> 00:04:41.720]   child-sized submarine. Hold my kale smoothie with it. Yeah. Yeah. Yeah. Speaking of Elon
[00:04:41.720 --> 00:04:45.560]   there was a good article we were all talking about it before the show by Douglas Rushkoff
[00:04:45.560 --> 00:04:53.720]   on billionaires and how they've basically given up. They feel like it's over. I know you're
[00:04:53.720 --> 00:05:01.480]   all looking for it so my it's over. We're going to we're going to you know human-
[00:05:01.480 --> 00:05:06.120]   The event is like cool. The event is going to happen. Yeah. This is an article he wrote
[00:05:06.120 --> 00:05:11.880]   in Medium called Survival of the Richest. The wealthy are plotting to leave us behind.
[00:05:11.880 --> 00:05:21.320]   He was he was giving a keynote speech to investment bankers and he did it because he was being
[00:05:21.320 --> 00:05:27.240]   offered about half his annual professor's salary and it was going to be on the future of technology
[00:05:27.240 --> 00:05:32.680]   but the Q&A ended up being so what are you going to do when the event happens. The event could be
[00:05:32.680 --> 00:05:38.440]   anything from global warming finally crashing down around her heads to a zombie apocalypse and it
[00:05:38.440 --> 00:05:43.880]   turns out nuclear warhead of course. Yeah. Yeah. The traditional. Which is ironic because many of them
[00:05:43.880 --> 00:05:49.240]   apparently are retreating to condos built in former nuclear silos. Yeah. You want to survive
[00:05:49.240 --> 00:05:54.600]   nuclear tech? Go to a nuclear silo. Well it's it's interesting that they're looking at one event.
[00:05:54.600 --> 00:05:59.000]   How many of you guys have read William Gibson's The Peripheral? Yes. Yeah. I have it in my list.
[00:05:59.000 --> 00:06:03.160]   I haven't read yet. I haven't either. So one of the one of the contentions it's it's a book
[00:06:03.160 --> 00:06:07.640]   and involves time travel and but one of his contentions is that instead of one event it's just going to be a
[00:06:07.640 --> 00:06:12.920]   series of small events that if taken individually and with collective action could have been shaken
[00:06:12.920 --> 00:06:19.000]   off but because they happen in serial every landslide is a series of small events exactly.
[00:06:19.000 --> 00:06:23.080]   Yeah. I end up bearing you in mud. So you know even when you have this kind of thinking like oh the
[00:06:23.080 --> 00:06:27.560]   big event will happen and all that will be left were the billionaires and the Kansas Nuke condos.
[00:06:27.560 --> 00:06:34.360]   That's I find it to be a very limited and blinkered vision of the future because if and honestly if
[00:06:34.360 --> 00:06:38.280]   I had billion or billion type resources and money I think I'd bet on a different model.
[00:06:38.280 --> 00:06:41.720]   Yeah. Trying to sort out the problems before they start getting. Exactly. Well.
[00:06:41.720 --> 00:06:46.840]   Rashkoff says that they have already concluded there's no point in doing that because the
[00:06:46.840 --> 00:06:51.240]   the end is nigh but they've sold themselves this fantasy that they can somehow survive
[00:06:51.240 --> 00:06:56.120]   and emerge into a new high tech society where all the poor people have been got rid of and it's
[00:06:56.120 --> 00:07:00.680]   just you know this core thing and will build this utopia. It's them enough heard of wild horses.
[00:07:00.680 --> 00:07:05.640]   Yeah. You know I mean. Rashkoff said when when the hedge funders asked me the best way to
[00:07:05.640 --> 00:07:09.800]   maintain authority over the security forces after the event because that's one of the concerns.
[00:07:09.800 --> 00:07:14.040]   Yeah. You're barricaded in. You got a billion as an 100 security guards guess who's going to be
[00:07:14.040 --> 00:07:17.400]   ruling the roost. Yeah. You're going to eat that corn in the cup because I could.
[00:07:17.400 --> 00:07:23.800]   She said he said I suggested their best bet would be to treat those people really well right now.
[00:07:23.800 --> 00:07:31.160]   They were like. They were they were amused. He writes they were amused by my optimism but they
[00:07:31.160 --> 00:07:36.200]   didn't really buy it. They weren't interested in how to avoid calamity. We're too far gone.
[00:07:36.200 --> 00:07:39.880]   They're convinced for all their wealth and power they don't believe they can affect the future.
[00:07:39.880 --> 00:07:44.440]   They're accepting the darkest of all scenarios and then bringing whatever money and technology
[00:07:44.440 --> 00:07:47.720]   they can employ to insolent themselves. If they can't get a seat on the rocket to Mars.
[00:07:47.720 --> 00:07:52.680]   Now I do. Main reason I brought this up is his last sentence. He's writing I guess he's working on
[00:07:52.680 --> 00:07:57.560]   a book called Team Human which will be out early next year but his last line is really the most
[00:07:57.560 --> 00:08:04.920]   important line. Being human is not about individual survival or escape. It's a team sport. Whatever
[00:08:04.920 --> 00:08:09.160]   future humans have it will be together. I like that. But that's spoken as somebody who doesn't
[00:08:09.160 --> 00:08:14.920]   have enough money to buy the silo. Some of the stuff they were talking about was completely
[00:08:14.920 --> 00:08:18.520]   bonkers like putting shock collars on your security guard so you got control on them.
[00:08:18.520 --> 00:08:23.560]   Oh my god. Getting robot security guards. So if you are the if you are the person with the skill
[00:08:23.560 --> 00:08:27.400]   who will in theory keep someone safe if they come to you and say I'm going to put this shock
[00:08:27.400 --> 00:08:33.400]   collar on you. Yeah. Yeah. Are you really going to say? Definitely not. Yeah. I mean it makes even
[00:08:33.400 --> 00:08:38.440]   the worst HR department today. You'll get to live with me in the survival condo though.
[00:08:38.440 --> 00:08:43.240]   Well as you're slave with a shock collar better that than out there with the zombies.
[00:08:43.240 --> 00:08:47.160]   Dude if he's got the kind of skills to be security he could be running the zombie horde.
[00:08:47.160 --> 00:08:52.360]   I mean a lot of these guys with the security props and chops are going to be like why would I bother
[00:08:52.360 --> 00:08:57.800]   helping a hedge funder have a cushy life when I can become you know thinking of the proud boys.
[00:08:57.800 --> 00:09:03.080]   One less mouth to figure out. I think it's far enough down the line. You totally think that and
[00:09:03.080 --> 00:09:07.160]   you say yeah put the collar on because you just later you'll take it off and then kill the guy.
[00:09:07.160 --> 00:09:11.400]   So you know it's just a way that it's just the it's the entry price. But you don't think that's
[00:09:11.400 --> 00:09:17.400]   going to last forever. Plus somebody has to maintain those colors. So you have to subvert them too.
[00:09:17.400 --> 00:09:23.800]   I mean the problem with the problem with this whole premise is if money is irrelevant because
[00:09:23.800 --> 00:09:29.160]   again after you have people what is your inducement because oh you know you get to survive in a bunker
[00:09:29.160 --> 00:09:33.400]   with a shock collar or again you get to become head of the proud boys out on the on the planes.
[00:09:33.960 --> 00:09:39.480]   You know so the sulfur spray paintings have them sign up. Well but you see we've seen this in history
[00:09:39.480 --> 00:09:44.760]   many many times. I mean the Praetorian guard owned the Roman the Roman Empire for the last
[00:09:44.760 --> 00:09:49.800]   couple of centuries of so I've even sold it off on one stage to a third party. You know it's an
[00:09:49.800 --> 00:09:53.800]   easy high lights. You know it lies ahead. I mean there's a reason they kept sending the Vikings out
[00:09:53.800 --> 00:09:58.280]   on raiding parties is because if you had these guys out there they weren't home threatening trouble.
[00:09:58.280 --> 00:10:03.880]   Exactly. So is that why human beings are just built for fear and no.
[00:10:03.880 --> 00:10:08.680]   It's time. Well and there was also a famine in Scandinavia at the time. So we got lots of people
[00:10:08.680 --> 00:10:12.440]   with with time on their hands. That in place there was somebody staying at home while the Vikings
[00:10:12.440 --> 00:10:15.720]   were going out going thank God we got rid of those dudes. They were the chiefs. The chiefs
[00:10:15.720 --> 00:10:20.280]   would keep with the skulls. Yeah yeah yeah but they would maintain the systems of logs.
[00:10:20.280 --> 00:10:23.880]   I got to read up on my Viking history apparently. Actually if you if you fancy Google there's a
[00:10:23.880 --> 00:10:28.120]   very good show on Netflix called the Normans which is I think it's a Norwegian competition.
[00:10:28.120 --> 00:10:33.560]   The Norsemen. Yes it's hysterical. The Normans is a different show about a people like people named
[00:10:33.560 --> 00:10:39.320]   Norman. Well it's about hapless French soldiers. But this is just as a wonderful moment in the
[00:10:39.320 --> 00:10:44.120]   first episode where a slave is complaining about being enslaved and the guy just the
[00:10:44.120 --> 00:10:48.840]   Viking just walks up to him punches him in the face and then walks back up to his boss and he goes
[00:10:48.840 --> 00:10:52.280]   I'm unhappy with this force-based management system we have been interested in.
[00:10:53.800 --> 00:10:59.160]   I guess the question the last question I have about the the Rushkoff piece though is he's talking
[00:10:59.160 --> 00:11:03.000]   this is a bunch of hedge funders who are like nah it's all terrible. Right. And I just wonder if
[00:11:03.000 --> 00:11:08.760]   this is some sort of occupational mindset whereas if he were to sit in a room with five people who
[00:11:08.760 --> 00:11:13.800]   had loads of money from technology or five people who had loads of money from biotech or something
[00:11:13.800 --> 00:11:17.480]   else if their mindset would be different. It's true almost by definition hedge fund managers are
[00:11:17.480 --> 00:11:21.960]   looking for the worst right. Right. That's what they're there to but I mean musculos doing important
[00:11:21.960 --> 00:11:29.080]   stuff with his money. Yeah but but but musk. Seems to be thinking of Mars is the escape hatch right.
[00:11:29.080 --> 00:11:33.240]   Well I think muskers as identified as a set I mean he's a big science fiction nut and one of
[00:11:33.240 --> 00:11:37.800]   the central problems identified in science fiction is you cannot build a long-term civilization on
[00:11:37.800 --> 00:11:41.400]   one planet because sooner or later we're going to get hit by an asteroid or we're going to get
[00:11:41.400 --> 00:11:46.040]   really bad volcanism or something. It's happened many times in the past and entire species have
[00:11:46.040 --> 00:11:51.000]   been wiped out. So if you can get a self-support yeah it's kind of like your data backup. If you
[00:11:51.000 --> 00:11:56.440]   if you can get a self-supporting colony on Mars that can reseed the earth then we've got a chance
[00:11:56.440 --> 00:12:00.360]   of building a proper long-term civilization otherwise we're just going to be going through the same
[00:12:00.360 --> 00:12:05.560]   thing again and again to the big asteroids. Just to be computing his cloud. It's moving humanity of
[00:12:05.560 --> 00:12:10.760]   the cloud. John Varley wrote about this in his sci-fi in the 1970s. He wrote a whole series of
[00:12:10.760 --> 00:12:15.080]   short stories about it where the premise was that an alien race decided that humans were doing a
[00:12:15.080 --> 00:12:19.720]   terrible job with resources and they preferred the dolphins and they tried to kill off humanity
[00:12:19.720 --> 00:12:24.120]   and so all of humanity ends up on the moon and then colonizes the planets from there
[00:12:24.120 --> 00:12:28.440]   and the only reason it works according to the short stories is because they already had a small
[00:12:28.440 --> 00:12:33.640]   colony of people there who could then build into that. So I can completely get behind
[00:12:33.640 --> 00:12:37.720]   Musk's contention that yeah we need to have distributed we need to distribute society centers
[00:12:37.720 --> 00:12:43.400]   across more than one planet because Bill Gates' initiatives to try and sort things out here.
[00:12:43.400 --> 00:12:47.800]   You know he's an optimist. He's an optimist. He's an optimist. He's an optimist. He's an
[00:12:47.800 --> 00:12:54.760]   economic disparity. He loves Stephen Pinker who has written two books now saying we are much less
[00:12:54.760 --> 00:12:59.880]   violent civilization than we've ever been in the history of humankind. Oh by far. By the data.
[00:12:59.880 --> 00:13:05.240]   In terms of the data. Why all this pessimism? Because it sells stories.
[00:13:05.240 --> 00:13:09.320]   No but there's definitely a pessimistic streak going on. Because people like to think they'll
[00:13:09.320 --> 00:13:13.880]   be winning at the end of it. This is a way to try to. Is it the human? I guess you know when I said
[00:13:13.880 --> 00:13:19.800]   the end is nigh that kind of harkens back to millennial thinkers for the last 2000 years who
[00:13:19.800 --> 00:13:24.600]   said well you know tomorrow. Look in a dystopic fiction almost all of them are written from the
[00:13:24.600 --> 00:13:29.480]   perspective of somebody who's surviving it or has survived it. You never see it's really rare to
[00:13:29.480 --> 00:13:34.600]   to read one where the protagonist is going to die in the world changing event. Emily Mandel,
[00:13:34.600 --> 00:13:38.680]   St. John's Station 11 is the only one I can think of where a protagonist does die.
[00:13:38.680 --> 00:13:44.520]   So as a result of it. Things are built for fear. Shouldn't it be my mission or mission to say no
[00:13:44.520 --> 00:13:48.920]   really let's be honest things are better than they ever have been. There's obviously problems.
[00:13:48.920 --> 00:13:55.720]   Let's work to make them better. But really the future is bright. So there's a great post on this
[00:13:55.720 --> 00:14:02.920]   Melinda Gates retweeted it. It was from their age. I think Bill and Melinda have actually kind of
[00:14:04.120 --> 00:14:09.720]   in person and personalize this whole point of view that let's make things better.
[00:14:09.720 --> 00:14:12.280]   Yeah. Yeah. Yeah. Yeah. Let's buy a condo in Kansas.
[00:14:12.280 --> 00:14:14.040]   Should thank Wornbuss. It's for a lot of that because it's from
[00:14:14.040 --> 00:14:21.000]   it's from July 2nd. The post is by Max Roser who posts data all the time about you know
[00:14:21.000 --> 00:14:26.680]   the real data about what's sort of happening in the world. So he has memorizing these three
[00:14:26.680 --> 00:14:33.240]   statistics will help you understand the world. And the three are the first one actually is child
[00:14:33.240 --> 00:14:41.800]   deaths globally. In 1950 there were an average of 20 million a year that's now down close to 5
[00:14:41.800 --> 00:14:46.360]   million. Yeah. That's amazing. Right. I mean each individual one is still a tragedy for the family
[00:14:46.360 --> 00:14:52.360]   but in the aggregate it really is a remarkable. And the next one was the children per women is
[00:14:52.360 --> 00:14:59.080]   has halved since 1950. So that whole notion that we're over populating the world. We still have birth
[00:14:59.080 --> 00:15:04.920]   rate issues on a regional scale in pockets but it's not where it was.
[00:15:04.920 --> 00:15:09.880]   Basically once you get closer to what in my generation we called ZPG zero
[00:15:09.880 --> 00:15:14.280]   population growth. Yes. Is that true globally or just in developed societies? That's globally.
[00:15:14.280 --> 00:15:17.720]   Yeah. That is a globally. I mean basically once you industrialize or once you educate and
[00:15:17.720 --> 00:15:24.040]   we'll give women access to education and reproductive control once one's culturally speaking a
[00:15:24.040 --> 00:15:28.200]   culture embraces the idea that the woman it has the right to have charge of her fertility.
[00:15:28.200 --> 00:15:34.760]   Then you see a lot of net growth in economics education and even in resource management there's
[00:15:34.760 --> 00:15:41.640]   some. Yeah. It's generally better for the environment. And the last one is the world population living
[00:15:41.640 --> 00:15:48.120]   in extreme poverty. In 1820 it was like almost 95% of the world you see this chart on this.
[00:15:48.120 --> 00:15:52.680]   I have the chart right here. Yeah. And you look at now you know it has dropped
[00:15:52.680 --> 00:15:58.600]   precipitously since about 1970 to the point that it's lower than it was in 1820.
[00:15:58.600 --> 00:16:07.080]   Yeah. Even though the population is exploded. Exactly. So even though there are now 7 billion
[00:16:07.080 --> 00:16:12.440]   people and more than 7 billion people in the world there are fewer people in poverty than there were
[00:16:12.440 --> 00:16:17.560]   when there were 2 billion people in the world 1 billion. I wonder if the challenge for some people
[00:16:17.560 --> 00:16:23.080]   is to be able to hold two seemingly conflicting ideas where poverty has gone down but we still
[00:16:23.080 --> 00:16:27.320]   have to address it as a problem. It hasn't been solved yet. So we can be like hooray there's less
[00:16:27.320 --> 00:16:32.120]   extreme global poverty while also saying there are still an unconscionable number of people in the
[00:16:32.120 --> 00:16:36.600]   world who are suffering needlessly. And it's hard for people to reconcile this. I really but I also
[00:16:36.600 --> 00:16:42.040]   say as as members of the media do we not have an obligation I think we've focused for a long time
[00:16:42.040 --> 00:16:47.480]   on the negative. And maybe maybe we have an obligation at least let's say one time in five
[00:16:47.480 --> 00:16:51.320]   to mention the things are in fact better than ever before. Oh yeah. And to a great degree it's
[00:16:51.320 --> 00:16:55.720]   technology that propels that. Yeah. It's the narrative right. The narrative is that it's getting
[00:16:55.720 --> 00:17:01.240]   worse and worse and worse. If you if you read the if you read the news you know you study these
[00:17:01.240 --> 00:17:05.480]   things that's the narrative that you feel whereas you look at the data and the data tells you a
[00:17:05.480 --> 00:17:10.520]   different story that it's actually getting better and better and better. So the point we still have
[00:17:10.520 --> 00:17:15.800]   a lot of work to do it doesn't mean that we don't have a lot of work to do like we have a ton of
[00:17:15.800 --> 00:17:19.880]   problems that we still need to solve. Yeah. I mean I can find other graphs on this site. This is
[00:17:19.880 --> 00:17:27.800]   the our world in data.org for instance global plastics production. Skyrocketing. I mean you're
[00:17:27.800 --> 00:17:31.880]   talking about narratives though and another thing we've got to consider is you look at audiences
[00:17:31.880 --> 00:17:38.280]   today and they have so many more ways of getting stories and then constructing their own narratives
[00:17:38.280 --> 00:17:42.680]   based on primary sources. Isn't that kind of part of the problem is you can always cherry pick any
[00:17:42.680 --> 00:17:48.520]   fact to support any belief. Sure. And now it's become easier than ever to have a belief. A prior
[00:17:48.520 --> 00:17:53.800]   I have a belief and then find all the evidence to prove you're right. Well one of the things I
[00:17:53.800 --> 00:17:58.200]   that we're probably going to have to address in a systemic way either in education or otherwise
[00:17:58.200 --> 00:18:05.720]   is teaching people how to discern narratives. How to how to learn how to trust sources or ask
[00:18:05.720 --> 00:18:10.440]   why are they telling me this story what benefit is to them is there for telling me this story.
[00:18:10.440 --> 00:18:13.880]   You know audiences are going to have to solve the motive critical thinking. And they didn't
[00:18:13.880 --> 00:18:19.560]   used to have to because there were not that many outlets and. You trusted the outlet provided to
[00:18:19.560 --> 00:18:23.960]   actually. There's still our motives. Yeah. Oh no no. Well there were but. My melt history teacher
[00:18:23.960 --> 00:18:28.280]   gave me one of the most if I learn anything from school it was this it was my ultimate teacher
[00:18:28.280 --> 00:18:32.760]   said if you read any historical document. It's a you've got to ask yourself three questions.
[00:18:32.760 --> 00:18:38.040]   Who wrote it. Why did they write it and who paid for it to be written. Once you've got the
[00:18:38.040 --> 00:18:42.360]   other the answer to those three questions. You know you can actually take it seriously.
[00:18:42.360 --> 00:18:49.720]   I'm going to take a place to start at least as we talk about bad news to make sure we balance
[00:18:49.720 --> 00:18:55.480]   it with goodness. Although it's going to be a challenge in today's right. But it's been a
[00:18:55.480 --> 00:19:00.440]   weird week because you've had traitors day this week. So things sort of slow down. Wait a minute.
[00:19:00.440 --> 00:19:06.120]   No we call that Independence Day where I live. We call it ungrateful colonial day. Are you
[00:19:06.120 --> 00:19:10.760]   saying make America great Britain again. Is that what you're saying. Hey listen give it another
[00:19:10.760 --> 00:19:17.400]   two years you guys might be asking for the queen back here. Well anyway. I'm a big fan of Liz.
[00:19:17.400 --> 00:19:23.480]   Yeah an already a son though is. Yeah. Yeah maybe you're idiot. No he's not an idiot. He's
[00:19:23.480 --> 00:19:27.640]   nice. Just because somebody's here to stick out. Two sharp planks two sharp planks.
[00:19:27.640 --> 00:19:33.080]   Yeah I'm sorry. Prince Charles has these weird ideas about ruling the country
[00:19:33.080 --> 00:19:37.000]   rather than just being what he's supposed to be. Which is the figurehead. Although he may be
[00:19:37.000 --> 00:19:42.200]   you know right in with the times. That seems to be the way she's two more authoritarian. Another
[00:19:42.200 --> 00:19:47.480]   stat is that of especially in the past decade you know democracy receding in lots of parts of the
[00:19:47.480 --> 00:19:53.160]   world. Yeah rapidly. And freedom of the press also receding in many parts of the world. So.
[00:19:53.720 --> 00:20:00.520]   Is there a correlation or are there stats on a wealth gap that may or may not be trending at
[00:20:00.520 --> 00:20:04.200]   the same time because that's another thing that's been happening to is you've had stagnant wages
[00:20:04.200 --> 00:20:11.320]   especially in the US. So any quality leads to authoritarianism. I'm wondering if anybody is
[00:20:11.320 --> 00:20:16.920]   tracking that and I'm wondering if there is a if there is if there is any sort of correlation
[00:20:16.920 --> 00:20:20.760]   to that. I mean there's some interesting research about the Brexit vote where they would try to find
[00:20:20.760 --> 00:20:25.960]   out where people would vote against their own economic self-interest. And it basically came down
[00:20:25.960 --> 00:20:30.600]   to wages have been falling in the UK for the last 10 years. It's the Great Recession. And when a
[00:20:30.600 --> 00:20:35.320]   politician stands up and says oh you can't possibly leave the EU otherwise it's going to get really
[00:20:35.320 --> 00:20:40.760]   bad economically. It's already been beaten for the last decade. What are they going to do? Say well
[00:20:40.760 --> 00:20:45.480]   do I trust this guy who screwed me over for the last decade or do I trust the guy who's who's got
[00:20:45.480 --> 00:20:50.600]   a glib turn of phrase and some nice Facebook ads. It's just you know there's there's a definite
[00:20:50.600 --> 00:20:54.120]   correlation I can't out feeling but I would like to see some research. Yeah I'd like to see
[00:20:54.120 --> 00:21:02.120]   numbers to support or not support but the differential between a workers average wage and a CEOs has
[00:21:02.120 --> 00:21:06.840]   never been bigger. Yeah for example. In this country particularly. In this country especially.
[00:21:06.840 --> 00:21:11.960]   And you take a look at it. You guys are bringing it right back down. Well you take a look at the
[00:21:11.960 --> 00:21:16.120]   shrinking middle class and how jobs are jobs are sifting themselves out either into higher
[00:21:16.120 --> 00:21:22.680]   and lower areas. And that kind of economic inequality. When people feel as if there's no
[00:21:22.680 --> 00:21:28.120]   social safety net and there's no mobility. So go to Denmark go to Finland go to Sweden.
[00:21:28.120 --> 00:21:32.760]   These are countries where inequalities at least and people are happiest. You know you don't wake
[00:21:32.760 --> 00:21:36.760]   up in the morning thinking if I get sick am I going to get bankrupt or can I afford my children's
[00:21:36.760 --> 00:21:41.720]   university education. But they have they have solid social safety nets and I and it makes a big
[00:21:41.720 --> 00:21:47.640]   difference in terms of in terms of how people feel about the society they live in and the people
[00:21:47.640 --> 00:21:52.280]   they share it with. They also little upward mobility though at the same time. To prove our exact point
[00:21:52.280 --> 00:22:01.320]   I have found a graph that shows the democracy the blue line is on the rise while autocracy is falling.
[00:22:01.320 --> 00:22:07.640]   Do they break that down by region? I have no idea. Then who is who what's the source? Stop it.
[00:22:07.640 --> 00:22:13.080]   No seriously what's the source how what's the source what is the matter center for systemic
[00:22:13.080 --> 00:22:17.720]   peace. How do they define how to define the Virginia evaluates the level of democracy for
[00:22:17.720 --> 00:22:23.000]   each country on a scale of negative 10 which denotes a tyranny like North Korea and 10
[00:22:23.000 --> 00:22:28.600]   which is a politically free society like don't spit your your tea out the United Kingdom.
[00:22:29.320 --> 00:22:33.960]   No we're politically quite free. Yeah most countries fall somewhere in between
[00:22:33.960 --> 00:22:43.160]   in 2017 we were in eight on the scale. France was a nine. I don't know I think scoring. Yeah there
[00:22:43.160 --> 00:22:47.960]   are so many variables in there. How do you I'd like to see the score the scorecard they kept for
[00:22:47.960 --> 00:22:52.440]   example. I'm just pointing out that whatever you want to believe. So you know how I just talked
[00:22:52.440 --> 00:22:56.040]   about the proof. Oh you know how I talked about interrogating the narrative. I think another thing
[00:22:56.040 --> 00:22:59.560]   that we're going to have to start talking about especially with tech and AI is interrogating the
[00:22:59.560 --> 00:23:04.600]   data and finding out how is it collected. Who decided how to sort it. Who decided what was
[00:23:04.600 --> 00:23:09.400]   worth collecting and what was not. Why did they decide that. What is the point and for things like
[00:23:09.400 --> 00:23:15.400]   this. Particularly as you move from sort of single use AI to general AI. Yeah that's the data sets
[00:23:15.400 --> 00:23:18.920]   be used behind that and the motivation of the programmers are going to be absolutely vital to
[00:23:18.920 --> 00:23:22.840]   see how that develops. And if you've got AI in government it absolutely has to be transparent
[00:23:22.840 --> 00:23:27.400]   where the data comes from. Because what's policy that's policy that shapes people's lives. And you
[00:23:27.400 --> 00:23:31.640]   know if your government is. You guys though I'll talk about AI as if it's real like it's going to
[00:23:31.640 --> 00:23:36.920]   happen. Do you have I mean is going to happen. Yes is it. Yeah. Do you have any evidence of that.
[00:23:36.920 --> 00:23:41.000]   It's already happening in your office suites. This is actually how there are I wouldn't say they.
[00:23:41.000 --> 00:23:45.560]   I wouldn't call my office suite intelligent in any respect. At the moment you see we're talking
[00:23:45.560 --> 00:23:51.640]   about single use intelligence. The crossover comes when you go into general AI. Yes. We build a
[00:23:51.640 --> 00:23:55.800]   general AI system which can learn to do a lot of things. This has been my contention is that
[00:23:55.800 --> 00:24:03.000]   what we call single use intelligence is indistinguishable from algorithmic solutions. It's programming.
[00:24:03.000 --> 00:24:08.520]   Which is not artificial intelligence. It's algorithms. We used to just call code code.
[00:24:08.520 --> 00:24:16.120]   And it's become the fashion to say everything is AI. We see machine learning and forming some
[00:24:16.120 --> 00:24:21.960]   processes. That's for sure. I don't know if you call that intelligence. That's just that you can
[00:24:21.960 --> 00:24:28.040]   that a machine can in a way create its own code from a data set. Right. So that's a step. But I
[00:24:28.040 --> 00:24:31.480]   wonder I think there's a quite a big leap between that and general artificial intelligence.
[00:24:31.480 --> 00:24:36.600]   There's a lot of so I cover this a lot because of in you know covering business technology.
[00:24:36.600 --> 00:24:42.440]   And talk to a lot of people that are working on AI. And their frustration is not that it's
[00:24:42.440 --> 00:24:48.280]   too smart. It's that it's so dumb and they cannot get it to do the things that they wanted to do.
[00:24:48.280 --> 00:24:52.600]   That doesn't mean that we shouldn't take the leap of like it will get better. The data will get
[00:24:52.600 --> 00:24:58.840]   better. One of the biggest problems is if you want to have AI you have to have a really great set of
[00:24:58.840 --> 00:25:07.240]   disciplines and organization around your data. Because that's what and most of the world doesn't
[00:25:07.240 --> 00:25:13.480]   have that. Well to that point I often think that we have fetishized the notion of AI to the point
[00:25:13.480 --> 00:25:19.160]   where we're starting to trust so-called AI to do things that they can't do. Face recognition.
[00:25:19.160 --> 00:25:25.400]   There's a story. Oh yeah. I'm so sorry about this. Well the face recognition thing is interesting
[00:25:25.400 --> 00:25:29.720]   too because there's parameters a Microsoft recently had to come out with a blog post.
[00:25:29.720 --> 00:25:34.920]   We're like yes by the way we now recognize white people. Well there's a big black black
[00:25:34.920 --> 00:25:39.400]   people there saying they're now recognized. I've always been able to recognize white people. Sorry I completely
[00:25:39.400 --> 00:25:44.120]   wow I spoke there. But that's not but they were like is that because they trained it.
[00:25:44.120 --> 00:25:47.560]   Oh I'm sorry. Well I think the data sets they were using were largely on white people.
[00:25:47.560 --> 00:25:52.840]   Oh yeah. So it's good at that. But the fact is is the people who built that in didn't notice that.
[00:25:52.840 --> 00:25:56.600]   Like they just had an inherent bias and this is why we're going to have to start looking at all
[00:25:56.600 --> 00:26:01.400]   of these data sets and asking what's being left out and why. Here's the. What is the possibility
[00:26:01.400 --> 00:26:05.240]   that if you're trying to build a specific kind of AI you would deliberately limit the data sets
[00:26:05.240 --> 00:26:09.400]   that you use to get the result that you want. Okay to get back to your weapons of math
[00:26:09.400 --> 00:26:13.080]   destruct to get back to the algorithm could be used because it always comes back to sci-fi.
[00:26:13.080 --> 00:26:19.160]   There's an author named Dennis Danvers who wrote a book and I can email you some.
[00:26:19.160 --> 00:26:24.280]   Because he does really because a lot of his earlier books dealt with what happens when people
[00:26:24.280 --> 00:26:27.480]   can upload themselves into the worldwide well what happens to the physical world. I'm really
[00:26:27.480 --> 00:26:33.080]   looking forward to that. But in one of the books Dennis Danvers writes people who are planning on
[00:26:33.080 --> 00:26:38.440]   colonizing Mars actually do create a deeply racist AI to help them out and the challenge
[00:26:38.440 --> 00:26:43.080]   of one of the protagonists. His name was Zoe. It was a girl and the challenge and the challenge
[00:26:43.080 --> 00:26:47.560]   of one of the protagonists was to try to reason with this AI and explain to them why their data
[00:26:47.560 --> 00:26:51.480]   set was flawed when they asked like no you don't understand I'm an AI much smarter than you anyway.
[00:26:52.040 --> 00:26:58.440]   And it took up a good portion of the novel is fascinating. Is the independent a reasonable
[00:26:58.440 --> 00:27:03.560]   independent UK and large choice? It used to be a broad sheet it's now online only and it's
[00:27:03.560 --> 00:27:07.480]   largely reasonable. It's in between the Guardian and Daily Mail is the independent.
[00:27:07.480 --> 00:27:12.920]   Kind of yes although I put the Daily Mail so far on the egregious end of the scale.
[00:27:12.920 --> 00:27:17.960]   In between the Washington Post and the National Inquirer the one advantage of the Daily Mail is
[00:27:17.960 --> 00:27:24.840]   very absorbent but apart from that useful for a spill. So the independent has this story.
[00:27:24.840 --> 00:27:32.360]   Scotland Yard yeah we covered this as well and it's just it's painful. They were doing a pilot at
[00:27:32.360 --> 00:27:37.880]   least you know that's to their credit this was a test this wasn't rolling out but as we know the
[00:27:37.880 --> 00:27:42.520]   UK has security cameras everywhere right oh you can't walk around London without one of the most
[00:27:42.520 --> 00:27:47.400]   if you all don't have a good okay if you're a geek and you'll have a good time in London
[00:27:47.400 --> 00:27:51.960]   just stand there in the middle of a street and look rad and count how many cameras you can
[00:27:51.960 --> 00:27:57.080]   you can find and if you can find less than five you're really trying that's amazing yeah they even
[00:27:57.080 --> 00:28:03.800]   have telephone you know light poles with microphones on them. So the the Metro Pollent Police that's
[00:28:03.800 --> 00:28:07.240]   the same as Scotland Yard Metro Pollent Police is London's own police force.
[00:28:07.240 --> 00:28:16.440]   So confused they they have been doing a trial over a few months across six locations in London
[00:28:16.440 --> 00:28:20.600]   and hasn't it been successful. They have been using face recognition what they have is a
[00:28:20.600 --> 00:28:25.720]   database of violent offenders we're only going to use violent offenders we are going to scan all
[00:28:25.720 --> 00:28:30.360]   the faces of people who walk past the cameras and search for those violent offenders we've got
[00:28:30.360 --> 00:28:36.680]   lots of safeguards if the technology generates an alert to signal a match police officers on the
[00:28:36.680 --> 00:28:40.920]   ground review the alert and carry out further checks to confirm the identity make sure that's
[00:28:40.920 --> 00:28:45.720]   not a false positive all alerts against the watch list will be deleted after 30 days
[00:28:45.720 --> 00:28:49.720]   faces in the database that did not generate an alert are deleted immediately they're not keeping
[00:28:49.720 --> 00:28:57.480]   it. The success rate was zero actually two percent well well okay 98 percent false positive which
[00:28:57.480 --> 00:29:02.920]   let's face it is worse than rising yeah you know only one person according to observers was
[00:29:02.920 --> 00:29:07.800]   stopped after being identified of course it was an African-American male that wasn't African-American
[00:29:07.800 --> 00:29:13.480]   black male it's in England. I know yeah right uh San Fr. Gabriel in North Africa African old
[00:29:13.480 --> 00:29:17.800]   but we don't know what works to use you place it you're black but you're a darker person
[00:29:17.800 --> 00:29:22.360]   which we know face recognition doesn't work very well uh with
[00:29:22.360 --> 00:29:30.440]   so the man took his rucksack off as pockets turned out by police he handed over shocking an oyster
[00:29:30.440 --> 00:29:38.520]   transport card for use on the met on the underground the officers talked to the man said no he's not
[00:29:38.520 --> 00:29:43.960]   your guy and they let him go but the police said they were perfectly fine with this and really if
[00:29:43.960 --> 00:29:49.080]   you were walking down the road you get dragged off to one side as has happened to me on one occasion
[00:29:49.080 --> 00:29:54.040]   yeah you know and basically searched by the side of the road this was terribly embarrassing I was
[00:29:54.040 --> 00:29:57.880]   coming out of Paul Street station and a police dog jumped at me because it thought I was carrying
[00:29:57.880 --> 00:30:03.240]   drugs oh dear we're on our way to meet my wife's friends for the first time so I'm pulled off to
[00:30:03.240 --> 00:30:07.080]   the side standing there like that being patted down and my wife goes and meets a friend so where's
[00:30:07.080 --> 00:30:11.400]   Ian oh he's over there being patted down by the policeman you know total false positive but
[00:30:11.400 --> 00:30:17.160]   this is even worse than facial stuff the the Mets say that he was given a leaflet oh that makes it
[00:30:17.160 --> 00:30:29.400]   perfectly all right so zero arrests yep which maybe means that no bad guys walked by the cameras
[00:30:29.400 --> 00:30:33.400]   yeah or it could mean that the software is so bad I mean the Chinese are apparently doing very you
[00:30:33.400 --> 00:30:38.520]   know very intensive stuff on this oh because it's racially racially more uniform the Chinese
[00:30:38.520 --> 00:30:42.360]   face of recognition works better I don't know the city ins and outs of it but I'd be curious to
[00:30:42.360 --> 00:30:46.440]   know what the panel you know whatever there's a number of different ethnic groups across China
[00:30:46.440 --> 00:30:49.560]   yeah so they've got their own they've got they're gonna have their own challenges and yeah they've
[00:30:49.560 --> 00:30:55.800]   got the my girls and yeah definitely but it's okay if we arrest a weager because they're Muslim
[00:30:55.800 --> 00:31:01.400]   yeah so I don't know I mean and I don't think any statistics coming out of China are to be
[00:31:01.400 --> 00:31:07.640]   trusted anyway no but I mean the UK the old Soviet yeah stats padding yeah yeah but they do claim
[00:31:07.640 --> 00:31:12.680]   several arrests using face recognition software but I mean this is a lot of jaywalkers apprehended
[00:31:12.680 --> 00:31:17.080]   to maybe that's just a very effective PR move too because if you convince people the tools work
[00:31:17.080 --> 00:31:21.560]   exactly consequence then it doesn't matter whether or not they actually do self-sucking becomes the
[00:31:21.560 --> 00:31:25.720]   normal yeah yep well I do have some good news we're gonna take a break and then we come back
[00:31:25.720 --> 00:31:31.000]   we're gonna share everybody but first a word from our sponsor bringing you the good news since
[00:31:31.000 --> 00:31:36.600]   the early 2000s WordPress calm everybody you know what's great about WordPress whenever I talk
[00:31:36.600 --> 00:31:40.840]   about my blog we all report comments on WordPress my kids blogs we've set them up down there on
[00:31:40.840 --> 00:31:46.120]   WordPress every time I talk people go oh I love WordPress it's just universal it's probably why
[00:31:46.120 --> 00:31:53.320]   30% of the whole internet 30% of the web worldwide is running on WordPress calm they're oh oh this
[00:31:53.320 --> 00:32:00.600]   just in 31% now I just want to say when we started doing these ads it was 29% so if something's
[00:32:00.600 --> 00:32:06.360]   going on something's going on WordPress is the best place to create your website whether it's a
[00:32:06.360 --> 00:32:13.240]   business your personal site it's easy it will look like you it'll share your voice it'll be your
[00:32:13.240 --> 00:32:18.520]   work your way if you don't have your own website you don't control your presence on the internet
[00:32:18.520 --> 00:32:22.760]   you've got to have at least that and WordPress makes it easy you don't need to do any coding no
[00:32:22.760 --> 00:32:27.880]   design WordPress gives you all the tools you need to get your site up and running their customer
[00:32:27.880 --> 00:32:33.080]   support team is there WordPress offers powerfully commerce options ranging from a simple and effective
[00:32:33.080 --> 00:32:37.720]   buy button to a complete online store so it's great for e-commerce and it's very affordable you
[00:32:37.720 --> 00:32:43.480]   start at four dollars a month and as you I have the business plan because you get a lot of additional
[00:32:43.480 --> 00:32:49.480]   features built in SEO social sharing so people can spread the word about your business on their
[00:32:49.480 --> 00:32:54.840]   social sites on their Twitter and Facebook there's also specialized plugins hundreds of them I use
[00:32:54.840 --> 00:32:59.800]   for instance the Google amp plug-in which means my site loads lickety split on mobile I use there
[00:32:59.800 --> 00:33:05.800]   they have the best anti-comment spam engine in the world a kismet it is really it's mature it's
[00:33:05.800 --> 00:33:11.640]   been there it's good stuff WordPress.com/twit if you go there right now you'll get 15% off any
[00:33:11.640 --> 00:33:24.040]   new plan purchase WordPress.com/twit 15% off 31% of the net runs on WordPress wow congratulations they
[00:33:24.040 --> 00:33:29.960]   keep going that's a good sign when that's going up. Thank you for following up Leo.
[00:33:29.960 --> 00:33:36.280]   Yes to the more bad news this was not bad news you know one place that computer vision if we want
[00:33:36.280 --> 00:33:45.720]   to call it that and and AI is working or in the early prototypes Amazon go right and so one of
[00:33:45.720 --> 00:33:52.920]   the stories that we're looking at covering is Amazon announced or not announced but the word is
[00:33:52.920 --> 00:33:58.440]   that they're about to open a second automated store in Seattle right where you go in I love these
[00:33:58.440 --> 00:34:05.000]   stores you don't have to you know exactly no check out you go and use this I haven't but obviously
[00:34:05.000 --> 00:34:11.320]   we've covered it we've set reporters and it's worked well you go in you have to identify I'm here
[00:34:11.320 --> 00:34:16.600]   it's me you have my information right yeah once you're in there whatever is in your basket whatever
[00:34:16.600 --> 00:34:23.400]   is in your cart it scans it also knows oh you got that macaroni and cheese and then you put it back
[00:34:23.400 --> 00:34:29.480]   so now it's gonna send you ads for macaroni and cheese but you know that's pretty smart right so
[00:34:29.480 --> 00:34:37.240]   ultimately this is a place where the sort of machine learning and the the algorithms are good
[00:34:37.240 --> 00:34:44.280]   enough that Amazon is moving forward with the the report was that they eventually that they
[00:34:44.280 --> 00:34:50.200]   originally had over 200 stores in the US planned they only have one so far this will be the second
[00:34:50.200 --> 00:34:55.720]   this one's bigger I want to go to this but yeah I had Sam Moschkovich on from ours Technica he went
[00:34:55.720 --> 00:35:03.400]   in yeah he actually tried to shoplift no but it like I admire his mochsie yeah it seems like you
[00:35:03.400 --> 00:35:08.200]   want to see how easy it's still though it's totally like a old wall off and put it under his coat and
[00:35:08.200 --> 00:35:13.240]   they they charge him for it so here's something I'm curious about because if you assume that this
[00:35:13.240 --> 00:35:19.800]   model takes off how does it change people's conception of money and how they spend it
[00:35:19.800 --> 00:35:24.200]   well isn't that a problem when you're not being charged it doesn't feel like you
[00:35:24.200 --> 00:35:28.600]   say well exactly so you just walk out the door it's you know just I'm that for you spend more right
[00:35:28.600 --> 00:35:34.520]   well I'm reminded for example of when I was in college my student ID also doubled as my dining
[00:35:34.520 --> 00:35:39.240]   hall pass and I had so many dollars that I could spend per week on meals and every time we
[00:35:39.240 --> 00:35:44.120]   swiped it you'd see how much money you had left and so you do the the calculations in your head
[00:35:44.120 --> 00:35:50.280]   and but it felt much different and I was inclined to be more careless especially on weekends
[00:35:50.280 --> 00:35:56.440]   than if I had to actually hand over cash no I'd stayed off credit cards for a long time after
[00:35:56.440 --> 00:36:00.680]   getting a massive bill after getting the first time thinking this is great like getting stuff
[00:36:00.680 --> 00:36:05.400]   free what I'm really curious about and I'm sure they're collecting the date and I'm sure amazon's
[00:36:05.400 --> 00:36:09.880]   collecting the data that they won't share but what I'm really curious about is how people's
[00:36:09.880 --> 00:36:14.760]   shopping habits would alter in a post currency world or in a post currency retail environment
[00:36:14.760 --> 00:36:18.280]   I'm not sure that it would change that much honestly because you're going to get that alert
[00:36:18.280 --> 00:36:24.760]   right away you know you were just charged you know $37.92 for your order yeah and so in some
[00:36:24.760 --> 00:36:31.640]   sense you may be more hyper connected to it or less if you look at it or you swipe it and dismiss it
[00:36:31.640 --> 00:36:37.160]   but you could also it also you know these systems are smart enough to now to automatically budget
[00:36:37.160 --> 00:36:41.880]   for you and show you spent this much on food this month you spent that much last month you're up
[00:36:41.880 --> 00:36:46.440]   50 percent like you need to and then you're like oh whatever I shouldn't have gotten those
[00:36:46.440 --> 00:36:50.680]   whatever at some point do you have party so if I were amazon at some point I'm looking to buy mint
[00:36:50.680 --> 00:36:55.960]   or something similar so that you can offer a one-stop shop where it's like hey we offer a way for
[00:36:55.960 --> 00:37:01.240]   you to monitor your spending will make suggestions on how to spend smarter they'll tie it into proprietary
[00:37:01.240 --> 00:37:05.320]   amazon and whole food only specials where you're like look you can save 20 percent of your grocery
[00:37:05.320 --> 00:37:09.640]   bill this month hear your trends here's how you can save 20 percent just by using amazon
[00:37:09.640 --> 00:37:13.400]   subscribe and save an amazon grocery so some of these mobile first banks you know there's some
[00:37:13.400 --> 00:37:17.880]   of these ones that are they're completely mobile right you you literally don't have access to even
[00:37:17.880 --> 00:37:26.120]   go into the the bank and as a matter of fact Chase just opened one it's called Fin we wrote about it
[00:37:27.000 --> 00:37:31.880]   this week on this past week and it's doing some of this some of this exact same stuff it's going to
[00:37:31.880 --> 00:37:37.240]   help you save right so and it's also going to help you budget and those kinds of things so
[00:37:37.240 --> 00:37:42.360]   so I do think that because the ultimate deal is being accountable to it right being accountable
[00:37:42.360 --> 00:37:48.920]   to yourself being accountable to whatever your your budget is and there's a there is the opportunity
[00:37:48.920 --> 00:37:54.360]   that digital tools could make it better yeah yeah yeah but that's a smart though goose that
[00:37:54.360 --> 00:37:58.120]   the goose that experience for perceived benefits I mean the whole point to Amazon Prime for example
[00:37:58.120 --> 00:38:03.960]   is they like to hammer home how much you're saving yeah by spending $120 a year for the privilege of
[00:38:03.960 --> 00:38:07.640]   shopping a whole lot and watching streaming videos and so this would be great way can I point out
[00:38:07.640 --> 00:38:12.680]   one thing though this whole conversation about Amazon go doesn't we never once mentioned
[00:38:12.680 --> 00:38:18.520]   all the people who'll be out of work because of this yeah this is if you're talking about AI and
[00:38:18.520 --> 00:38:24.920]   people's jobs being replaced by AI is the rub this is it yeah what what they say and there's some
[00:38:24.920 --> 00:38:32.760]   truth to this um is that they will their plan is anyway and part of this is PR because they know
[00:38:32.760 --> 00:38:38.760]   that this is you know bad mojo um their plan is that they're going to take those people and not
[00:38:38.760 --> 00:38:44.520]   get rid of the cashiers but they're going to make more uh because there are areas that are rising
[00:38:44.520 --> 00:38:49.720]   in demand like um pre-prepared meals and things like that they're going to do more of that
[00:38:49.720 --> 00:38:54.280]   because they have higher margins on that and so you have somebody working on that they make better
[00:38:54.280 --> 00:38:58.680]   margin it's uh they're going to take those people they would have employed as cashiers
[00:38:58.680 --> 00:39:02.760]   they're going to have them they still have to stock things right they still have to they want to
[00:39:02.760 --> 00:39:08.760]   do more it's like it's still the robots coming I wonder if it'll be a net zero it is the question
[00:39:08.760 --> 00:39:14.440]   is it an end zero frankly there there aren't many entry-level jobs for kids getting into the workforce
[00:39:14.440 --> 00:39:18.840]   bagging groceries is one of the used to be flipping burgers we were talking about this a few weeks ago
[00:39:18.840 --> 00:39:23.960]   that's where I started a lot of people started but now no no that's teenagers don't get those jobs
[00:39:23.960 --> 00:39:29.400]   anymore but I see a lot of teenagers bagging groceries uh that's gone my first job as a shelf
[00:39:29.400 --> 00:39:35.400]   stacker in the in the local uh gateway and Amazon's notorious for being a great employer either right
[00:39:35.400 --> 00:39:39.640]   true well no this is the sick thing about their stores though because they pay their some of their
[00:39:39.640 --> 00:39:43.400]   warehouse staff so poorly that they have to get food stamps to survive which means we're
[00:39:43.400 --> 00:39:49.480]   subsidizing Amazon and then they cannot use the same food stamps in Amazon's own stores it's just
[00:39:49.480 --> 00:39:55.080]   it's a massive two fingers to their own stuff but now of course if if this technology is it gonna
[00:39:55.080 --> 00:40:00.840]   all be Amazon owned or will they sell this technology to other companies that's the question right
[00:40:00.840 --> 00:40:05.400]   because others are saying that they're gonna do it one one sure wants to do this one of the one of
[00:40:05.400 --> 00:40:09.800]   the one of the one of the classic revenue streams for any companies when they license their technology
[00:40:09.800 --> 00:40:15.000]   and then sell support for licensees and on the other hand at some point Amazon's gonna want to do that
[00:40:15.000 --> 00:40:21.480]   Amazon's traditional mode of operation is not doing that but just swallowing everybody whole
[00:40:21.480 --> 00:40:26.360]   and making it all Amazon right not necessarily look at AWS right they took it's they make more
[00:40:26.360 --> 00:40:30.920]   money they are really still Amazon it's they're not licensing it to somebody else but they're
[00:40:30.920 --> 00:40:35.800]   licensing they're empowering other people yeah a lot of what they've learned in e-commerce they
[00:40:35.800 --> 00:40:41.880]   now license you think this would work in whole food in Amazon go they said no um whole food is a
[00:40:41.880 --> 00:40:46.120]   premium experience yeah he just said the words which is this is a customer who expects a really
[00:40:46.120 --> 00:40:50.680]   high touch high needs high touch high needs environment in fact if anything you make whole
[00:40:50.680 --> 00:40:55.880]   foods less of a grocery store more of an experience well you make it like Nordstrom except with kale
[00:40:55.880 --> 00:41:01.800]   classes yeah that's why they make it so you make it like Nordstrom except with kale exactly
[00:41:01.800 --> 00:41:08.680]   it is i'm sorry sir that kale it's not right for you maybe i can get a a shade of red well this is
[00:41:08.680 --> 00:41:14.600]   the engine with um the retail sector that deals with home goods and things like that
[00:41:14.600 --> 00:41:20.680]   a servo top has actually made a name for itself by offering classes and skills workshops and things
[00:41:20.680 --> 00:41:25.880]   like that and i remember i remember taking a couple of those and they do a really nice really smooth
[00:41:25.880 --> 00:41:31.160]   upsell at the end of the night too where once you're done learning your your your knife skills or
[00:41:31.160 --> 00:41:35.640]   once you're done cooking with an editor from Cooks Illustrated both which are classes i took
[00:41:35.640 --> 00:41:41.080]   they hand you a coupon for 10-25 off good for just that night and they let you wander about an empty
[00:41:41.080 --> 00:41:45.880]   store i've taken those classes yeah and it's it's a luxurious experience so this is a big part of
[00:41:45.880 --> 00:41:51.240]   the future of retail so we did a special report for by z and tikka public we just released last week
[00:41:51.240 --> 00:41:56.440]   on the future of retail and sort of how data um ai and iot are going to play a big part of it
[00:41:56.440 --> 00:42:05.480]   and and it is a lot of these kinds of things that are transforming retail from a sort of experience
[00:42:05.480 --> 00:42:12.680]   where you're just there to buy the thing you want to sort of embracing show rooming to embracing a
[00:42:12.680 --> 00:42:16.840]   experience like when you go to the amazon home page and it knows the kind of things that you want
[00:42:16.840 --> 00:42:22.840]   and it presents them to you retail is doing a lot of um the same things uh so you can find that on
[00:42:22.840 --> 00:42:28.600]   on zdnet uh you can also download the it is a pdf the report if you're interested on tikka public
[00:42:28.600 --> 00:42:33.400]   we've been actually talking about i i write about you know as you see amazon first is
[00:42:33.400 --> 00:42:38.040]   this intermediate and closed bookstores all over the country yeah and then uh you know you see this
[00:42:38.760 --> 00:42:43.080]   incremental loss of brick and mortar business we've been talking a lot about that how the
[00:42:43.080 --> 00:42:47.800]   downtowns can be revitalized by experiential shopping you have to i mean if somebody just wants
[00:42:47.800 --> 00:42:53.080]   something you just do it online so there's got to be some reason to go into a store movie theaters
[00:42:53.080 --> 00:42:58.040]   have exactly the same issue movie ticket sales are down year after year after year after year
[00:42:58.040 --> 00:43:02.920]   thing on this about toy stores of all things toy stores there's an interesting story there are
[00:43:02.920 --> 00:43:09.480]   some toy stores which are and now deliberately building you know it's not just yeah you can get
[00:43:09.480 --> 00:43:14.920]   a bigger range of toys on amazon but you can't get people explaining your hands onto the kids
[00:43:14.920 --> 00:43:19.960]   talking to them to discern which kind of toys and games they might like so i'm down my downtown
[00:43:19.960 --> 00:43:26.280]   has several different retailers which should be by all risk getting murdered and the toys so the
[00:43:26.280 --> 00:43:31.480]   toy store that we have um they they will actually buy back toys which makes some popular parents
[00:43:31.480 --> 00:43:35.400]   but they have a library of toys out in front of the store for children to play with yeah
[00:43:35.400 --> 00:43:40.440]   which has made it great for people slow down and foot traffic and foot traffic has over the
[00:43:40.440 --> 00:43:46.280]   internet yeah i mean i studied the baby supplies store in town they the baby supply store in town
[00:43:46.280 --> 00:43:51.160]   has workshops they do on family on on family legal matters for example here's how to set up your
[00:43:51.160 --> 00:43:57.080]   state they will do free car seat installations for you they'll help you set up and the bookstore
[00:43:57.080 --> 00:44:01.640]   that we have has events all the time where they've got authors who come in or they'll have reading
[00:44:01.640 --> 00:44:05.640]   groups come in where you can knit and read at the same time and things like that yeah and it's
[00:44:05.640 --> 00:44:09.640]   bringing in this really social aspect and making people feel like they're not just shopping they're
[00:44:09.640 --> 00:44:13.960]   having an experience or they're not just shopping they're doing something interesting that's really
[00:44:13.960 --> 00:44:18.040]   gone a long way towards keeping it perfect now we live in northern california three of us Jason
[00:44:18.040 --> 00:44:23.560]   you live in luva al-kintechia i'm just wondering if this this kind of precious little store is a
[00:44:23.560 --> 00:44:29.080]   northern california phenomenon or is this global is this ever or a natural yet if you if you look at
[00:44:29.080 --> 00:44:34.120]   the data so Larry Dignon znetz written a lot about this and retail has actually not been doing
[00:44:34.120 --> 00:44:42.440]   bad as a as a um as a sector what's doing in and why there's so many places going under is not that
[00:44:42.440 --> 00:44:47.800]   that the retail is evolving it's got a long way to go there were too many stores in america what I
[00:44:47.800 --> 00:44:51.240]   thought was the problem with our two it's actually no there were too many brick and mortar outlets
[00:44:51.240 --> 00:44:55.320]   and too many stores it's not for them there's also too many restaurants there's too many hospitals
[00:44:55.320 --> 00:45:01.160]   and we've got to get rid of all these costs it is the store's over built but the biggest problem
[00:45:01.160 --> 00:45:07.800]   actually is debt so yes this is the past ten years that's where you see that yeah over the past ten
[00:45:07.800 --> 00:45:14.920]   years private equities bought a lot of these um stores like seers and uh you know Burlington coat
[00:45:14.920 --> 00:45:19.400]   factory uh there's a whole bunch of examples even in my industry this year because of the
[00:45:19.400 --> 00:45:24.280]   debt that's whatever the clear channel clear channel yeah borrowed heavily to buy every radio
[00:45:24.280 --> 00:45:28.920]   station in the country yeah sure now they have every radio station but they also own 20 billion
[00:45:28.920 --> 00:45:32.920]   dollars in debt and they do really shady things yeah they put all this debt on these companies and
[00:45:32.920 --> 00:45:38.600]   then like in in the uh some of these cases what they'll do is they'll take the the assets um one of
[00:45:38.600 --> 00:45:43.160]   their assets because assets is actually the real estate they own right they'll take those uh the
[00:45:43.160 --> 00:45:47.960]   real estate they'll spin it off as a separate company which holding company which now they own
[00:45:47.960 --> 00:45:53.160]   and they'll rent it back to that company right so now that company which wasn't paying anything
[00:45:53.160 --> 00:45:59.160]   because it owned the building is now paying exorbitant amount in uh in rent and the company goes under
[00:45:59.160 --> 00:46:06.280]   and you know they're incented to to start closing these stores and then rent them out to others yeah
[00:46:06.280 --> 00:46:11.240]   I hate to say this but it sounds like this is a this is a structural problem with the way we do
[00:46:11.240 --> 00:46:17.160]   finance in the United States oh it is it and it sounds related to the crash of 2008 the way we
[00:46:17.160 --> 00:46:23.720]   were no I mean I'm so related to the 80s junk bond but it seems like that's really the problem
[00:46:23.720 --> 00:46:29.080]   in this country is financiers and the way they're doing business and regulation hasn't caught up to
[00:46:29.080 --> 00:46:34.040]   it well regulations go on the other direction but them all in the survival bunkers restart
[00:46:34.040 --> 00:46:40.200]   they have all the money wow you see it didn't used to be like this in the u.s i mean teddy
[00:46:40.200 --> 00:46:45.320]   roosevelt broke up you know some of the some of the major trust yeah yeah i understand it all got
[00:46:45.320 --> 00:46:49.560]   broken up yeah there was another move in the 1930s it's not trust though that's the problem it's not
[00:46:49.560 --> 00:46:55.240]   monopolies it's junk bonds it's a lack of financial regulation yeah it is the lack of financial
[00:46:55.240 --> 00:46:59.560]   regulation it is we've gone through this thing of we must go for a totally regulation free market
[00:46:59.560 --> 00:47:05.000]   and markets only work through regulation because otherwise people cheat and you know it's we're
[00:47:05.000 --> 00:47:09.480]   seeing this again is our us perfect example and a lot of people say oh toys it was doing fine
[00:47:09.480 --> 00:47:14.120]   it was killed by amazon it wasn't killed by amazon it was doing fine they had billions in
[00:47:14.120 --> 00:47:18.840]   dollars in debt and where did all that debt come from just over expansion well no because they
[00:47:18.840 --> 00:47:24.040]   the people that bought them out well never with debt to supply them out then paid themselves
[00:47:24.040 --> 00:47:29.240]   fat management fees on top of that and just destroyed the company but hey they made a profit
[00:47:29.240 --> 00:47:33.000]   at the end of the day so what are they they came out smelling like rosus and they killed
[00:47:33.000 --> 00:47:37.800]   a company that was actually doing pretty well iconic american company as well yeah and you're
[00:47:37.800 --> 00:47:44.520]   seeing this happen again and again so while retail has a lot to figure out um and they are
[00:47:44.520 --> 00:47:50.280]   actually moving um pretty well and they're still in demand and they're still doing uh they're still
[00:47:50.280 --> 00:47:56.600]   doing good stuff and and they are still building an experience for the 21st century that a lot of
[00:47:56.600 --> 00:48:04.760]   consumers are still responding to um even in the face of amazon yeah but uh it's it's a lot of this
[00:48:04.760 --> 00:48:09.320]   fundamental kind of financial stuff that's actually doing them in yeah these kind of shenanigans are
[00:48:09.320 --> 00:48:14.200]   really bringing a lot of healthy companies low and yes it makes for a small number of people
[00:48:14.200 --> 00:48:18.760]   a quite a lot of quite a lot of money but at the end of the day you know that pension funds get
[00:48:18.760 --> 00:48:22.840]   raided people are unemployed so we've got to pay for them they either way they allow you wages so
[00:48:22.840 --> 00:48:26.360]   we've got to pay more in terms of food stamps is it wall street versus main street
[00:48:26.360 --> 00:48:32.760]   as it's typically versus everyone it's the best way of putting it is it's wall street
[00:48:32.760 --> 00:48:38.120]   and again it comes back to that long that long future mindset versus short-term profit where the
[00:48:38.120 --> 00:48:43.000]   the moral and as far as these companies and people who make money for a living are concerned
[00:48:43.000 --> 00:48:47.480]   their moral imperative is to get the greatest shareholder value for the dollar yeah yeah and
[00:48:47.480 --> 00:48:54.120]   they have deliberately decoupled profit making from a larger infrastructure economic or social
[00:48:54.120 --> 00:48:58.760]   context because that doesn't serve what they consider their their greatest value to be there
[00:48:58.760 --> 00:49:03.720]   was a marvelous cartoon i think it was last year a man in a very ragged business suit sitting around
[00:49:03.720 --> 00:49:08.600]   a campfire in a cave surrounded by children going well yes society collapsed but for many years
[00:49:08.600 --> 00:49:15.160]   we created great shareholder value yes and that's but that's that's pretty much a yeah yeah wow
[00:49:15.800 --> 00:49:21.560]   it's just misaligned priorities right it's when and when you have sort of the sort of people
[00:49:21.560 --> 00:49:30.600]   consumers workers you know best interest misaligned with you know the uh shareholders and that that's
[00:49:30.600 --> 00:49:38.280]   when you have these these disconnects which are by large hurting working class people just technology
[00:49:38.280 --> 00:49:43.880]   have a role good or bad to play here can technology helps solve this or is it amazon going to pick
[00:49:43.880 --> 00:49:48.680]   off the the ball and pick the bones and well traditionally technology has never really been
[00:49:48.680 --> 00:49:52.920]   that great a job creator yeah i mean when you think when micros at when the first office suites
[00:49:52.920 --> 00:49:57.880]   came out the 70s and 80s that decimated an entire class of secretarial workers who were no longer
[00:49:57.880 --> 00:50:01.800]   needed because management were expected to type their own letters at the same time it's been in
[00:50:01.800 --> 00:50:08.200]   by the way that has not been an improvement okay well historically speaking almost anytime any
[00:50:08.200 --> 00:50:14.040]   technologies introduced there's going to be a job loss category there's the story where
[00:50:14.040 --> 00:50:17.720]   reportedly somebody came up with a knitting machine during queen Elizabeth's time and she
[00:50:17.720 --> 00:50:22.120]   actually prohibited it right being built in use to serve the knitters yeah she wanted to make
[00:50:22.120 --> 00:50:25.720]   sure the knitters still had their yeah it still had their never works in the long term this is
[00:50:25.720 --> 00:50:29.880]   the problem you know technology always advances and then technologists would say yes but we create
[00:50:29.880 --> 00:50:34.680]   jobs in new sectors well they still haven't figured out how to solve the problem of persuading people
[00:50:34.680 --> 00:50:40.120]   or or offering people who lost their jobs as a safe to compare old combiner are you going to be
[00:50:40.120 --> 00:50:43.880]   able to trade in his web design so there's been the and the thing is as you mentioned coal miners
[00:50:43.880 --> 00:50:48.680]   and that's a great example because there were federal job retraining programs in place and
[00:50:48.680 --> 00:50:53.080]   their the participation rates have been incredibly low because as far as the miners are concerned
[00:50:53.080 --> 00:50:56.680]   they don't want to do anything else they want their old jobs back they want their old jobs and
[00:50:56.680 --> 00:51:03.320]   their old wages back and they don't want to have to start in a new division in a new skill set at entry
[00:51:03.320 --> 00:51:10.600]   the language analysis of the 2016 election that both candidates lied one candidate said we're
[00:51:10.600 --> 00:51:15.560]   going to give you your jobs back one candidate said we're good news we're going to retrain you
[00:51:15.560 --> 00:51:21.400]   you're going to get better jobs and in both cases they were lies yeah but one was more palatable
[00:51:21.400 --> 00:51:27.480]   than the other and I guess that's kind of true because the coal industry as far as I can see is
[00:51:27.480 --> 00:51:31.320]   not coming back oh it's dying on his back side you know I mean it's just like trembling about
[00:51:31.320 --> 00:51:37.400]   the steam agents these things do create new jobs so it is important to remember the solar industry
[00:51:37.400 --> 00:51:41.080]   is now growing but what but we've been even this way like at a fundamental level it's different
[00:51:41.080 --> 00:51:47.960]   people so somebody's out of work well sometimes in in AI for example take it what AI relies on is
[00:51:47.960 --> 00:51:53.000]   big data right one of the dirty little seekers about big data is that the companies that are
[00:51:53.000 --> 00:52:00.360]   spending the most on it Amazon Microsoft IBM the data to the point of like the that the algorithms
[00:52:00.360 --> 00:52:07.640]   aren't smart enough to handle gray areas and ambiguities right so they're hiring armies of people to
[00:52:07.640 --> 00:52:13.800]   actually sort I thought Amazon's mechanical mechanical trick was was for pennies you could
[00:52:13.800 --> 00:52:19.560]   teach the AI how to identify different things how to label things how to resort data and all of
[00:52:19.560 --> 00:52:24.600]   that thing so it's created this new this demand for new kinds of labor now there are problems with
[00:52:24.600 --> 00:52:30.200]   that labor uh to we've written a story about that a long form an investigative piece on it some of
[00:52:30.200 --> 00:52:35.160]   these people are treated pretty badly and um there there's problems with it but the bottom line is
[00:52:35.160 --> 00:52:39.800]   you some people are calling them the blue collar jobs of the digital age right you can pick up
[00:52:39.800 --> 00:52:45.240]   be trained very quickly and and start learning how to whatever at least you don't have to leave
[00:52:45.240 --> 00:52:48.680]   the house and you don't have to leave the house I mean the downside is you're talking to the
[00:52:48.680 --> 00:52:52.200]   blue collar jobs you don't have union protection like blue collar jobs the one of the big ones
[00:52:52.200 --> 00:52:57.080]   that people work at Amazon warehouses I mean yeah there's a lot of bad jobs they've created a
[00:52:57.080 --> 00:53:03.160]   lot of badger yeah but now Logan's sitting here how old are you Logan 11 so in 10 years Logan's
[00:53:03.160 --> 00:53:09.880]   gonna hit the workforce pretty impossible to predict what 10 years from now yeah I'd say computer
[00:53:09.880 --> 00:53:14.680]   security is a pretty solid train and computer security Logan yeah yeah really I mean what do you
[00:53:14.680 --> 00:53:19.560]   what advice do you give kids I mean you're 80 percent of the jobs in like 2025 haven't been
[00:53:19.560 --> 00:53:24.680]   created yet yeah that was a recent study so what are you gonna train for right it's well we shouldn't
[00:53:24.680 --> 00:53:31.640]   be training people for specific you know roles of things we should teach them how to you know
[00:53:31.640 --> 00:53:37.080]   critical thinking you have to do the skill to you have to teach the sort of more uber skills which
[00:53:37.080 --> 00:53:43.800]   is actually likely to create a demand for the liberal arts education that we just have to figure
[00:53:43.800 --> 00:53:48.760]   out how to fund it yeah I would say even more important than that meta skills like how to live
[00:53:48.760 --> 00:53:53.720]   in an economy where the jobs change every five years so I have a friend in higher education and
[00:53:53.720 --> 00:53:57.880]   he said that recently they had a lead a workshop where somebody came in and said what you need to
[00:53:57.880 --> 00:54:02.840]   start telling your undergraduates is so far as we can forecast the future is going to be volatile
[00:54:02.840 --> 00:54:10.680]   uncertain complex and ambiguous so what you need so what you need to do is you need to develop
[00:54:10.680 --> 00:54:17.240]   the skills but you need to develop the skills to deal with extremely complex and ambiguous situations
[00:54:17.240 --> 00:54:24.440]   all the time what's interesting is that our raising kids like Logan with our mindset of how
[00:54:24.440 --> 00:54:29.480]   things were what we did and that's not what the world is going to be a second example of this
[00:54:29.480 --> 00:54:33.880]   on the way into the world same thing all I'm telling her now is the only constant you're ever
[00:54:33.880 --> 00:54:39.080]   going to have is that things will change so your job is to figure out how to cope with change and
[00:54:39.080 --> 00:54:44.120]   how to how to anticipate it how to react to it play more video games spend more time on twitter and
[00:54:44.120 --> 00:54:49.640]   but 19 year old and 11 year old and similar yeah more slap chat yeah I mean I saw a classic
[00:54:49.640 --> 00:54:54.520]   example of this on I was walking to work on Thursday morning and just watched the young girls
[00:54:54.520 --> 00:55:01.000]   hopes and dreams get crushed on the street because he was a door Louise a door of a little four or
[00:55:01.000 --> 00:55:06.120]   five year old walking with a dad presumably to school and we were standing at the traffic
[00:55:06.120 --> 00:55:09.880]   lights waiting for them to change and he was like so what do you want to be when you grow up and
[00:55:09.880 --> 00:55:15.240]   shoot I want to be one of those I want to be a driver and he went oh well no when you grow up
[00:55:15.240 --> 00:55:21.080]   there won't be drivers just getting the car and say and say her face just fell and it was one of
[00:55:21.080 --> 00:55:28.120]   us heart-racing things at a time for truth dad now my daughter says she wants to figure out how to
[00:55:28.120 --> 00:55:32.120]   get rid of the great pacific garbage patch and I was like hey that's a great point but my love
[00:55:32.120 --> 00:55:37.560]   yeah because I guarantee you 10 years from now that will be around yeah it's like that's a problem
[00:55:37.560 --> 00:55:41.560]   to be solved so pick a problem solve it my kids are supposed to get out of college and
[00:55:41.560 --> 00:55:48.040]   it's a it's even now which is less changed than it will be when Logan gets out of college I
[00:55:48.040 --> 00:55:53.800]   wonder should kids be even taught to go to college I mean is that a reasonable don't listen to me
[00:55:53.800 --> 00:56:00.520]   Logan's is that a reasonable ambition now for one thing I've told my niece who is a
[00:56:00.520 --> 00:56:04.280]   sophomore college sophomore going to college junior is that college is a very safe place to
[00:56:04.280 --> 00:56:09.640]   experiment and fail good hmm also very expensive place to vary it's a very it's a it's an
[00:56:09.640 --> 00:56:13.640]   I'm saying that from a position of privilege and I would say if you have to borrow to do it don't
[00:56:13.640 --> 00:56:19.640]   yeah yeah because I see people with crushing death pick parents yes I was lucky I came from a
[00:56:19.640 --> 00:56:24.760]   a socialist country where the government paid me to go to university and cover my tuition fees so
[00:56:24.760 --> 00:56:28.440]   you know and it paid off in the long run because people got better paying jobs and they paid back
[00:56:28.440 --> 00:56:32.760]   into the state but over here I've got friends who got a hundred thousand dollars a student debt
[00:56:32.760 --> 00:56:37.720]   some modern day symptom it's just because the interest is so high you cannot get it
[00:56:37.720 --> 00:56:42.360]   the Wall Street Journal once referred to it as a reverse dowry yeah it's actually affected people's
[00:56:42.360 --> 00:56:47.560]   personal lives where once they find out that what their perspective partner has in terms of student
[00:56:47.560 --> 00:56:52.680]   loans they'll rethink the relationship so I do know some 20 year olds be cool stay in school
[00:56:52.680 --> 00:57:00.520]   what do you want to do yeah card is huh that will you know there'll be no drivers though so you
[00:57:00.520 --> 00:57:04.680]   can eliminate the steering wheel pass pedal the brake that you don't need to yeah but then you
[00:57:04.680 --> 00:57:08.520]   say well that weight you get a much snappy actually you know Logan there's going to be a real demand
[00:57:08.520 --> 00:57:13.160]   for figuring out how to design autonomous vehicles for adverse conditions like under-maintained
[00:57:13.160 --> 00:57:16.840]   rural roads you're going to be a living room designer Logan that's what you're going to be a living
[00:57:16.840 --> 00:57:20.360]   room design you could figure out you could you could figure out a set of conditions to design
[00:57:20.360 --> 00:57:25.080]   your vehicles for like I'm going to design vehicles that are self-driving that handle rural roads
[00:57:25.080 --> 00:57:28.520]   well I think there's a lot to be said for you know I mean one of the things one of the areas
[00:57:28.520 --> 00:57:33.240]   which actually he's going to hold up quite well is going to be the trades the plumbing the
[00:57:33.240 --> 00:57:37.880]   electricians I mean I've got a friend who's a welder another friend who's a plumber and they
[00:57:37.880 --> 00:57:44.280]   meet serious money my stepfather has a master's in education and he's also a master electrician
[00:57:44.280 --> 00:57:50.440]   and he found that a lot more fulfilling than teaching and he's he's actually he's technically
[00:57:50.440 --> 00:57:54.600]   retired but he's always finding projects to monkey around well the demand for these jobs the
[00:57:54.600 --> 00:58:01.160]   demand for trade jobs in all over the country of course but in yeah in the where where I live in
[00:58:01.160 --> 00:58:06.920]   the Midwest you know it's really high because so many people have gone university education and
[00:58:06.920 --> 00:58:14.120]   the public universities is is cheap and so there's just a lot of people with liberal arts degrees
[00:58:14.120 --> 00:58:19.720]   that yeah there there's not enough jobs yeah right there aren't enough jobs now that doesn't mean I
[00:58:19.720 --> 00:58:24.440]   do think in the long run a lot of what they learn you know how to think and learn and critical thinking
[00:58:24.440 --> 00:58:30.920]   all that will come in handy but there the still the bottom line is to your point in is just that
[00:58:30.920 --> 00:58:39.720]   there's so many of those jobs open for for skilled trades that because they haven't been viewed as
[00:58:39.720 --> 00:58:45.160]   the kinds of jobs that people you know tell kids to go and think about right for for a couple decades
[00:58:45.160 --> 00:58:51.000]   now and so there's such a dearth of people they can do them and so the the demand for them is way
[00:58:51.000 --> 00:58:56.920]   up right so that so the uh the compensation is also is also way up as a result I would love to see
[00:58:56.920 --> 00:59:02.040]   a national infrastructure you know how we have the WP in the 1930s yeah I would love to see a similar
[00:59:02.040 --> 00:59:06.520]   national infrastructure initiative like that now where we could train people in the trades yeah
[00:59:06.520 --> 00:59:12.040]   and have them work on bolstering our infrastructure on learning plumbing I guess you'll always need
[00:59:12.040 --> 00:59:19.080]   plumbers and carpenters and electricians 100 yeah uh and if we had a job training core that built
[00:59:19.080 --> 00:59:24.520]   these skills out and it was regionally distributed then you wouldn't have areas skilled machinists
[00:59:24.520 --> 00:59:29.560]   yep coders will we always need coders maybe that's not a good job no no because eventually
[00:59:29.560 --> 00:59:33.240]   you're going to teach the machines how to code themselves all code is is a is a artificial
[00:59:33.240 --> 00:59:38.520]   is a set of rules that you are operating within and should you be looking for jobs that can't be
[00:59:38.520 --> 00:59:44.520]   done by automation I guess you should if you're 11 yeah yeah yeah it's difficult so no one knows
[00:59:44.520 --> 00:59:51.080]   gonna be though it is any job that requires standardized consistent results across a
[00:59:51.080 --> 00:59:55.240]   discrete data set is going to be automated so what you need to do is learn how no what you need
[00:59:55.240 --> 01:00:01.080]   to do is learn how to critically even a doctor and a lawyer yeah radiologists are are right
[01:00:01.080 --> 01:00:05.160]   to be replaced yeah right yep because I mean do you remember when being a linguist was a golden
[01:00:05.160 --> 01:00:09.240]   career because you're gonna make so much money automatic trades out five minutes five years from
[01:00:09.640 --> 01:00:14.840]   yeah I think there's still tax preparation anything where you have to understand context
[01:00:14.840 --> 01:00:22.840]   nuance history yeah ambiguity sort through those things those are the areas that humans are better
[01:00:22.840 --> 01:00:27.720]   than machines and likely will always be better than machines can everybody do that though or I
[01:00:27.720 --> 01:00:32.520]   mean I know it's you have to teach people how to think and you've actually managed to hit one of
[01:00:32.520 --> 01:00:37.160]   the challenges that we have in our modern education is that we're so underfunded with such big classes
[01:00:37.160 --> 01:00:41.960]   and we've relied on standardized tests as a benchmark for learning instead of having smaller
[01:00:41.960 --> 01:00:47.560]   better funding class training robots for an era that we won't need one thing we don't need is robots
[01:00:47.560 --> 01:00:53.320]   people who memorize who got plenty of yeah no there's a huge difference it's the blooms tax
[01:00:53.320 --> 01:00:57.240]   on me of learning where memorizations at the bottom and being able to synthesize and create
[01:00:57.240 --> 01:01:03.000]   something in the aggregate is is yeah yeah yeah yeah yeah hey I want to take a little break we're
[01:01:03.000 --> 01:01:09.560]   gonna come back with more Lisa Schmeiser is here from IT Pro today it's so great to have you she is
[01:01:09.560 --> 01:01:16.200]   and editor yes Jason Heiner I can guess where you work Jason it looks like you work at CDOT
[01:01:16.200 --> 01:01:24.920]   CDOT TWIT CDOT I gotta compete I gotta say that his like
[01:01:24.920 --> 01:01:30.280]   slightly clausier but it looks a lot better everybody anybody who is just casually tuning in
[01:01:30.280 --> 01:01:34.120]   might think this is a cnet podcast sorry about that that's okay I don't mind at all
[01:01:34.120 --> 01:01:39.080]   it just makes me want that it's his laptop cover for those of you listening at home
[01:01:39.080 --> 01:01:44.440]   Jason is the editor in chief of tech republic which is a CBS internet interactive publication
[01:01:44.440 --> 01:01:48.440]   launch as a straight you don't actually work at cnet that's right well so these are all of our
[01:01:48.440 --> 01:01:52.120]   tech brands that I have on here so I've got cnet and then I've got tech republic jason
[01:01:52.120 --> 01:01:56.920]   net and then can I have a word with you that calm that cnet's awfully big I can't even read the
[01:01:56.920 --> 01:02:05.240]   red covers the whole that's the skin oh you added stickers yeah yeah it's the big it's the big one
[01:02:05.240 --> 01:02:11.720]   obviously right we have we have four tech brands cnet is is the granddaddy it's of the mall it's
[01:02:11.720 --> 01:02:17.640]   the oldest it's also the one that's focused on the consumer so it's has the largest audience
[01:02:17.640 --> 01:02:21.800]   the other third employee fourth employee of cnet did you know I remember yeah I remember oh you know
[01:02:21.800 --> 01:02:28.920]   I wrote it into your biography exactly actually let's let's also give a plug for that fine
[01:02:28.920 --> 01:02:34.600]   book thank you where the where the geeks are follow the geeks although where the geeks are
[01:02:34.600 --> 01:02:42.200]   be a great movie follows the geeks I am chapter 10 not chapter nine chapter nine yes and uh
[01:02:42.200 --> 01:02:48.440]   it's actually a great book a biography a story of many many wonderful geeks it's available on
[01:02:48.440 --> 01:02:53.560]   amazon and uh you can go to follow the geeks yeah Jason reads it as matter of fact the sample
[01:02:53.560 --> 01:02:58.440]   chapter is the beginning of the chapter on you yeah you might even hear about cnet
[01:02:58.440 --> 01:03:04.600]   thank you for being here Jason and Lisa and of course Ian Thompson always a pleasure
[01:03:04.600 --> 01:03:10.200]   congratulations on england's stunning victory I was absolutely gobsmacked and I have to say
[01:03:10.200 --> 01:03:15.400]   that there wasn't there were very few sober people in england on on saster I mean and I'm still
[01:03:15.400 --> 01:03:20.440]   kicking myself because it was at seven because of the bay area time differences seven a.m.
[01:03:20.440 --> 01:03:26.280]   yeah and I was like I can't really be asked to drag myself down to the pub at seven p-
[01:03:26.280 --> 01:03:32.200]   seven a.m. to watch the game I just I lay in bed and I've regretted it ever since because
[01:03:32.200 --> 01:03:37.000]   you didn't go see it oh you you didn't see it the pub which no no I didn't say I didn't say
[01:03:37.000 --> 01:03:40.760]   the pub I fold it on twitter because I mean I had to be up early for the grand pretty this morning
[01:03:40.760 --> 01:03:45.160]   so yeah it was and the good news is Swedish people are depressed anyway so
[01:03:45.160 --> 01:03:49.720]   the Swedes I thought they were going to be just like reddit and stepchildren I mean they've been
[01:03:49.720 --> 01:03:55.160]   playing very well throughout the throughout the game and it was it was quite a shocker that
[01:03:55.160 --> 01:04:00.040]   we beat them to know but when that second goal went in it was just I almost heard the screams
[01:04:00.040 --> 01:04:04.760]   from London it's funny Americans couldn't care less about soccer at once every four years yeah
[01:04:05.640 --> 01:04:10.680]   we we follow the Portland thorns in my house mister the Portland thorns yes yes there's the
[01:04:10.680 --> 01:04:18.680]   problem right there it's Rose City oh it's the Rose City and the Rose City and there and the MLS
[01:04:18.680 --> 01:04:22.840]   soccer team are the Portland timbers because of course though the rich fish in the Pacific Northwest
[01:04:22.840 --> 01:04:28.200]   are divorced again I'm a fan of the Dunne Beatles and the women's soccer team is the Portland thorns
[01:04:28.200 --> 01:04:31.480]   actually why is there a Dunne Fills there they're really good with their feet
[01:04:32.680 --> 01:04:37.720]   they work with balls all the time there really should be a soccer team competition can you imagine
[01:04:37.720 --> 01:04:42.920]   like the mascot you can learn oh my gosh you'd have somebody the giant foam Dunne Ville costume
[01:04:42.920 --> 01:04:47.400]   I'll tell you I'm gonna start the pedal limit Dunne Ville
[01:04:47.400 --> 01:04:54.040]   yeah absolutely yeah absolutely yeah hey I'm just glad that you know croix should be Russia
[01:04:54.040 --> 01:04:58.280]   because if Britain was playing Russia in the semifinals they'd have to watch what they were
[01:04:58.280 --> 01:05:03.080]   eating and drinking so carefully yeah no I think the team will be out with radiation poisoning it
[01:05:03.080 --> 01:05:08.920]   would give them superpowers well I hear Putin says it's not over yet yeah so watch watch with
[01:05:08.920 --> 01:05:15.720]   interest Ian of course with the registered dot code UK where he's chief of snark actually there's
[01:05:15.720 --> 01:05:22.040]   a strong strong competition for that side actually I almost said and Ian Thompson he is with
[01:05:22.040 --> 01:05:27.880]   Dye Techie scum because that's what your laptop says oh well you know I've picked up a lot of
[01:05:27.880 --> 01:05:33.160]   I mean it also says hacker inside and there's a tux on there and I see a twit logo there's a
[01:05:33.160 --> 01:05:38.920]   twit logo there's also a nigma make route great again James old space telescope and Sparky the
[01:05:38.920 --> 01:05:44.360]   Penguin and besides an Android so I like and a Defcon sticker author I like it our show today
[01:05:44.360 --> 01:05:49.080]   brought to you by Ring there's a there's a company that's you know it's so funny Jamie Simmonoff
[01:05:49.080 --> 01:05:56.200]   who created Ring got to have a little victory tour because he went on I want to call it Shark Week
[01:05:56.200 --> 01:06:03.000]   Shark Tank yeah and some weeks something else yeah pitched an early product is not quite the
[01:06:03.000 --> 01:06:08.520]   Ring video doorbell but something similar and the sharks said ah you got no no no no Harper in the
[01:06:08.520 --> 01:06:14.120]   world subsequently he sold his company for the biggest turnaround any companies ever had that
[01:06:14.120 --> 01:06:19.320]   appeared whether they got invested in or not on Shark Tank one billion dollars to Amazon so
[01:06:19.320 --> 01:06:23.640]   James did they offer him and he's like no that's not enough oh he ain't offer him enough okay and
[01:06:23.640 --> 01:06:27.960]   so he's like I can do better on that but I'm gonna do it by myself and he was right you know and
[01:06:27.960 --> 01:06:32.920]   as you know you go on Shark Tank they take a huge chunk of your business oh yeah good decision on
[01:06:32.920 --> 01:06:37.640]   Jamie's part he created the Ring video doorbell which you know I use and love and I've had it on my
[01:06:37.640 --> 01:06:42.920]   door for a couple of years this was an easy replacement for our old thing donger worked in fact because
[01:06:42.920 --> 01:06:47.160]   we had a wired doorbell just exactly the same way well with a little different somebody comes up
[01:06:47.160 --> 01:06:53.400]   pushes the button chime rings in my house but I also see a high-def video of them I can talk to
[01:06:53.400 --> 01:06:58.200]   them they can talk to me it is the greatest also as a motion sensor so they don't even have to ring
[01:06:58.200 --> 01:07:02.600]   the doorbell if they just come up onto my porch I know they're there and I've got video to show
[01:07:02.600 --> 01:07:07.720]   Ring has now a neighborhood feature where you can share if you wish with other Ring doorbell owners
[01:07:07.720 --> 01:07:13.160]   in your neighborhood just kind of a neighborhood watch a digital neighborhood watch it really works
[01:07:13.160 --> 01:07:19.880]   they tried it in a Southern California town they cut crime by almost 50% and and that's the point
[01:07:19.880 --> 01:07:24.600]   you know as soon as people see that Ring doorbell they go I'm going to somebody else's house
[01:07:24.600 --> 01:07:31.160]   Ring has of course expanded their line we now have the Ring floodlight cam this is actually a real
[01:07:31.160 --> 01:07:36.680]   I put these around the house too these are LED you've seen floodlights motion activated floodlights
[01:07:36.680 --> 01:07:40.120]   right now so that's very common these are better because they're brighter they're our LED you never
[01:07:40.120 --> 01:07:47.000]   after place the bulb and they have the ring camera attached high-def video of what's going on plus
[01:07:47.000 --> 01:07:51.640]   of course the same speaker and microphone setup so you could say hey what are you doing what are
[01:07:51.640 --> 01:07:57.640]   you doing there there's even a 110 decibel alarm that you can trigger if it's not enough to just
[01:07:57.640 --> 01:08:01.560]   say hey what are you doing there sometimes raccoons just to give you an idea this is from the ring
[01:08:02.200 --> 01:08:08.600]   twitter feed these guys had been robbed twice here's a guy just came and took the look at this
[01:08:08.600 --> 01:08:13.160]   he just took the weed wacker so wait a minute I gotta play this again this is a circle the guy
[01:08:13.160 --> 01:08:16.920]   just walks up you know I like that weed wacker I think I'll just take that
[01:08:16.920 --> 01:08:24.360]   damn sir I see you whoops he turns around and puts it down
[01:08:26.200 --> 01:08:33.800]   yeah yeah gets no weed wacker for you oh she sounded me alarm too oh better close that back
[01:08:33.800 --> 01:08:42.520]   door and run dude I got your license plate on video yeah I love the ring twitter feed twitter.com/ring
[01:08:42.520 --> 01:08:47.720]   and I love the ring floodlight cam the ring doorbell they now have home security systems too
[01:08:48.360 --> 01:08:56.360]   ring.com/twit you can choose from one of three ring of security kits you get the ring video
[01:08:56.360 --> 01:09:00.600]   doorbell in your choice of either one two or three floodlight cams connect your doorbell with
[01:09:00.600 --> 01:09:04.760]   your favorite smart locks and hubs for added convenience monitoring and security and you can
[01:09:04.760 --> 01:09:12.200]   get up to a hundred fifty dollars off as well ring.com/twit stop crime before it happens help make your
[01:09:12.200 --> 01:09:16.600]   neighborhood safer too with ring save up to a hundred fifty dollars on a ring of security kit
[01:09:16.600 --> 01:09:21.560]   when you go to ring.com/twit put that down sir I see you.
[01:09:21.560 --> 01:09:29.800]   You know it is cool though we cover smart cities a lot and cities are really working hard
[01:09:29.800 --> 01:09:35.880]   struggling a little bit trying to figure out right how to become forward facing in security
[01:09:35.880 --> 01:09:42.920]   because like anything like a big IT project by the time they plan it you know decide what to do
[01:09:43.480 --> 01:09:47.320]   it's two years right and whatever they plan to do is almost completely obsolete
[01:09:47.320 --> 01:09:51.640]   but a lot of them have bought in communities are buying into these sort of
[01:09:51.640 --> 01:09:59.160]   these rings. Small scale. Small scale. Great and ring it has made this thing with neighborhoods
[01:09:59.160 --> 01:10:04.200]   where it will attach cams together and if something happens then it can it can
[01:10:04.200 --> 01:10:08.920]   complete video right you've got complete video because if you have enough of these in a neighborhood
[01:10:08.920 --> 01:10:14.040]   then all of a sudden you know you can you know it's essentially the same thing. We just have
[01:10:14.040 --> 01:10:19.560]   the same thing in the UK there was a terrible child killing last week and the police would just
[01:10:19.560 --> 01:10:25.000]   like check your video doorbells check your dash cams send us the footage if you can please and
[01:10:25.000 --> 01:10:29.880]   they managed to catch the person within about six to eight hours. Really and I think it's better
[01:10:29.880 --> 01:10:34.520]   maybe I'm wrong we talked earlier about how there's cameras everywhere in London but I think it's
[01:10:34.520 --> 01:10:39.080]   better to have a decentralized system where I'm monitoring my property your monitoring your property
[01:10:39.080 --> 01:10:43.160]   instead of the government monitoring all of us. I think David Brun wrote about that for
[01:10:43.160 --> 01:10:47.240]   Wired back in the 90s and he was and at the time I remember there being a huge backlash
[01:10:47.240 --> 01:10:53.400]   against the idea because how dare you be monitored but the argument was well if everybody yeah
[01:10:53.400 --> 01:10:59.800]   the idea was surveillance is the de facto standard and like you said it's decentralized then right
[01:10:59.800 --> 01:11:05.080]   yeah. There's no big brother collecting it all. Dealing with HOA's in this country I would hell
[01:11:05.080 --> 01:11:10.520]   hate to have the thought of an HOA having control over the internet work never network. Yeah that's a
[01:11:10.520 --> 01:11:18.040]   good point. It rings out. Thank you for your support. Jamie good work. He was right to turn
[01:11:18.040 --> 01:11:23.080]   down the sharks. Well speaking of turning down larger ones of cash you heard about Matt Blay's this
[01:11:23.080 --> 01:11:27.560]   week. No who's Matt Blay's and what are they? Matt Blay's famous security researcher he's been
[01:11:27.560 --> 01:11:34.520]   hanging on to the crypto.com domain since 1993 as part of a personal critic crusade to actually
[01:11:34.520 --> 01:11:40.600]   remind people that crypto doesn't mean crypto means crypto good thing not everything else and he
[01:11:40.600 --> 01:11:45.000]   finally sold this week to a cryptocurrency firm. He's not saying how much for but I think it was
[01:11:45.000 --> 01:11:50.120]   just like wow what the hell it's time to get the retirement fund sorted out but so in fact he sold
[01:11:50.120 --> 01:11:57.080]   out his dream because well cryptocurrency. I know but honestly Matt Blay's has done more for
[01:11:57.080 --> 01:12:04.200]   computer security than almost anyone else on the planet. I kind of dumped the grudge in but when
[01:12:04.200 --> 01:12:08.440]   it comes to selling out you'd be able to you know. So you remember the sex got the dot com guy?
[01:12:08.440 --> 01:12:16.120]   You know he read the thing forever. Well he got stolen from him and at the point where they got
[01:12:16.120 --> 01:12:19.880]   the court got it back it was making something like two million dollars a month in advertising.
[01:12:19.880 --> 01:12:25.640]   One of our reporters wrote a story about it a wrote a novel about it which is about to be filmed
[01:12:25.640 --> 01:12:32.200]   but the whole sex.com saga was just because back then all this fraudster had to do was right to the
[01:12:32.200 --> 01:12:37.400]   registrar and say yeah this was given to me it's been sold to me. Please give me a transfer to me
[01:12:37.400 --> 01:12:40.520]   fax it across them and they did it without question a simpler time.
[01:12:40.520 --> 01:12:47.080]   Well and we thought at the time I remember very well that these generic names these generic
[01:12:47.080 --> 01:12:51.640]   outcomes would be the most valuable properties and they turned out not to be a co-worker at Wired
[01:12:51.640 --> 01:12:56.840]   who went through with an he wrote an automatic registry bot. Oh dear. And a dictionary program
[01:12:56.840 --> 01:13:02.120]   and through. Oh registered everywhere. He registered a couple hundred domains and then would just sell
[01:13:02.120 --> 01:13:07.080]   them off anytime he wanted to make vacation. Oh yeah. Oh really. Any time he wanted a vacation he
[01:13:07.080 --> 01:13:11.960]   would just sell a domain or two when he wanted to dump him in a house. There was one time where
[01:13:11.960 --> 01:13:17.560]   he sold a domain to the lip balm company Softlips and they actually paid him in lip balm instead of
[01:13:17.560 --> 01:13:25.240]   registered softlips.com. I believe so. Or it was a domain that they wanted where it was like
[01:13:25.240 --> 01:13:28.760]   softlipped adjacent. Well there's a famous story in the UK. There's just the brute force
[01:13:28.760 --> 01:13:35.720]   obligation. Yeah a British lawyer who registered 21st century Fox.com in 1999 or something on the
[01:13:35.720 --> 01:13:39.960]   principle this was going to be my retirement fund and I don't think it quite worked out for him but
[01:13:39.960 --> 01:13:44.760]   you got to admire that kind of forward thinking. And so many of these domains were wide open until
[01:13:44.760 --> 01:13:51.640]   '94, '95, '96. Yeah. Well this is what amazed me about Twitter for a while was when Twitter first
[01:13:51.640 --> 01:13:58.200]   started up you'd have all these people who would tweet as Disney characters or comic characters.
[01:13:58.200 --> 01:14:06.200]   Well I always wondered why Disney for example didn't lock it down and go scouting for the names of
[01:14:06.200 --> 01:14:13.240]   their characters and lock down those accounts. These are your intellectual property and they're
[01:14:13.240 --> 01:14:17.720]   in the hands of who knows who doing all sorts of stuff. Well there's a huge story about that this
[01:14:17.720 --> 01:14:25.400]   week in the New York Times talking about the new domain squatting, Instagram squatting. Let me see
[01:14:25.400 --> 01:14:33.320]   if I can find it. I think the number was the top 10 Instagram stars have more than a thousand phony
[01:14:33.320 --> 01:14:40.920]   accounts parroting them claiming to be them and it's become a big issue. I'm glad I'm not one of
[01:14:40.920 --> 01:14:48.040]   the top 10 Instagram stars. Well I mean I find a lot of these parody accounts are in fact more
[01:14:48.040 --> 01:14:51.240]   entertaining than the actual one. I don't think they're all parodies. I think mostly they're trying
[01:14:51.240 --> 01:14:55.800]   to impersonate. They're trying to. Yeah. No one of my favorite parody Twitter, I guess it's a parody
[01:14:55.800 --> 01:15:00.920]   Twitter account it's J. Jonah Jameson. Oh no. Where he tweets basically in all caps and every
[01:15:00.920 --> 01:15:06.840]   through and mispray features prominently but I used to follow that one just because
[01:15:07.560 --> 01:15:12.920]   it was delightful. Is that a person I should know who that is? He is Spider-Man society. He's Peter Parker's
[01:15:12.920 --> 01:15:18.440]   assignee editor at the Daily Bugle. Okay yeah my sarcastic rover is mine. It's the sarcastic curiosity
[01:15:18.440 --> 01:15:23.880]   rover. Swift on security is my favorite. Oh yes. Well where it's like Taylor Swift as a security
[01:15:23.880 --> 01:15:28.840]   as a expert. Yeah. So obviously I know who the founder of that was and we have to keep on. Yeah
[01:15:28.840 --> 01:15:34.040]   you do know who it is? For example for example. You can never actually say it's now it's done by
[01:15:34.040 --> 01:15:40.520]   multiple people but the original guy that did it is just yeah I mean that's that's a work of genius.
[01:15:40.520 --> 01:15:47.000]   So this is the Times article came out this Sunday. Their analysis of the 9,000 top Instagram
[01:15:47.000 --> 01:15:54.440]   accounts are impersonating a mere 10 people. So they use as an example. Kip Moore who's a country
[01:15:54.440 --> 01:16:00.680]   music singer, songwriter very famous. 28 accounts are impersonating on Facebook at least 61 on
[01:16:00.680 --> 01:16:05.480]   Instagram. Here's the thing many of the accounts send messages to fans asking for love,
[01:16:05.480 --> 01:16:12.040]   promising love, asking for money, promising money, asking for love and people fall for this.
[01:16:12.040 --> 01:16:19.400]   Last year in Australia 42 year old man was charged with 900 sex offenses for impersonating Justin
[01:16:19.400 --> 01:16:25.800]   Bieber on Facebook just to solicit nude photos from minors. And of course it worked of course.
[01:16:26.920 --> 01:16:30.760]   Last year Oprah Winfrey posted a video saying somebody out there is trying to scam me using
[01:16:30.760 --> 01:16:35.720]   my name and avatar on social media asking for money. First of all what kind of idiot do you have to be
[01:16:35.720 --> 01:16:42.840]   to believe Oprah's show that Oprah's asking you for money and then giving it to her. Hi this is
[01:16:42.840 --> 01:16:48.520]   Oprah. I'm a little short right now. Could you give me a thousand bucks? I'm down to my last billion
[01:16:48.520 --> 01:16:53.400]   it's just not good. You can't hit up Dr. Hollis. He's not taking your calls anymore.
[01:16:53.400 --> 01:16:57.800]   Not taking the calls. New York Times Commission analysis to tally the number of impersonators
[01:16:57.800 --> 01:17:04.360]   for the 10 most followed people on Instagram Beyonce Taylor Swift. The analysis conducted by
[01:17:04.360 --> 01:17:11.720]   social imposter. This is a business. They protect celebrity names online found nearly 9,000 accounts
[01:17:11.720 --> 01:17:16.440]   on Facebook, Instagram and Twitter pretending to be those 10 people name are is number one the
[01:17:16.440 --> 01:17:23.240]   Brazilian soccer star. Okay 1,676 impersonators. Selena Gomez number two.
[01:17:23.240 --> 01:17:32.120]   Beyonce 714 Miss Taylor Swift 233. She had the least among the group. You know why? She's got an
[01:17:32.120 --> 01:17:39.000]   active real her son on Twitter right? Oh no she's I mean she will actually yeah she'll actually
[01:17:39.000 --> 01:17:43.960]   pull in fans sort of super people know Twitter right yeah and pull them in and give them
[01:17:43.960 --> 01:17:48.680]   pre screenings of the next album or something like that. She has used social media in a very
[01:17:48.680 --> 01:17:53.560]   intelligent way. Very sharp yeah. I think she's tiring of it now though. I think she's retiring.
[01:17:53.560 --> 01:17:59.240]   She's got enough money. Yeah. Wouldn't you if you were Taylor Swift? No. I mean she's not a
[01:17:59.240 --> 01:18:04.280]   concert to her. This is actually something so this is an interesting thing that I'll tease it
[01:18:04.280 --> 01:18:09.560]   because that Dan Patterson and I are working on Dan and Patterson also regular. If go go go tour
[01:18:09.560 --> 01:18:15.560]   on it. But social media fatigue right? If you look at a lot of the people who've been on social
[01:18:15.560 --> 01:18:22.520]   media for a decade now right? Yeah. I'm the poster boy for social media. Exactly all of us.
[01:18:22.520 --> 01:18:30.280]   You get to a point where it gets to be more of a burden than a joy and so you look at a lot of
[01:18:30.280 --> 01:18:36.520]   those folks they're now sort of either limiting their activity or focusing on maybe they'll work
[01:18:36.520 --> 01:18:43.800]   on one platform and show up sporadically on others. Whereas you look at the sort of mass of people
[01:18:43.800 --> 01:18:50.680]   that joined social media and a lot of the people that are active on it now and that drove a lot of
[01:18:50.680 --> 01:18:58.120]   what happened in the 2016 election for example on social media. It was really 2012, 2013 when they
[01:18:58.120 --> 01:19:03.720]   sort of got into social media. That's when it went mass media. Facebook, Twitter, others.
[01:19:04.680 --> 01:19:09.880]   When it went to the masses. And so they're at the sort of five year kind of peak right?
[01:19:09.880 --> 01:19:14.440]   So what's going to happen when they get to the sort of 10 year and social media,
[01:19:14.440 --> 01:19:18.520]   Mark and social media becomes more of a burden. That's one of the things that
[01:19:18.520 --> 01:19:26.280]   that Dan and I are going to explore a little bit is this idea of what does that mean for one public
[01:19:26.280 --> 01:19:29.720]   dialogue for a lot of things. I think it's nothing but good.
[01:19:31.320 --> 01:19:36.040]   Nate, do you really think there's some benefit to being active in social media?
[01:19:36.040 --> 01:19:39.640]   I think it's it's introduced. It's introduced me to some interesting
[01:19:39.640 --> 01:19:43.080]   one of the things I like about it. There's no good that comes of social media.
[01:19:43.080 --> 01:19:47.640]   No, no, no. I mean, there are there are a lot of I mean, okay, I'm limited in social media. I
[01:19:47.640 --> 01:19:51.640]   don't have an Instagram account. I just stick to Facebook and Twitter because I can't be
[01:19:51.640 --> 01:19:58.600]   aid to to to cover that. Instagram's the many most around this. It's just nice pictures.
[01:19:58.600 --> 01:20:01.080]   But it's just nice pictures and I don't take that many pictures.
[01:20:01.080 --> 01:20:01.560]   Right. Yeah.
[01:20:01.560 --> 01:20:05.320]   When I first got on to Twitter, I was kind of disappointed because you were expecting like,
[01:20:05.320 --> 01:20:09.320]   okay, you've got 140 characters. It'll be full of elkantly crafted haiku.
[01:20:09.320 --> 01:20:10.040]   That's true. Yes.
[01:20:10.040 --> 01:20:11.160]   But oh my gosh.
[01:20:11.160 --> 01:20:14.600]   Summer cloud rage upset insult. Yeah.
[01:20:14.600 --> 01:20:19.400]   It's an engine for this stuff. And frankly, my advice or general guidelines, for example,
[01:20:19.400 --> 01:20:23.320]   what I've noticed is I generally go off Twitter at five o'clock on Friday and I don't go back
[01:20:23.320 --> 01:20:24.520]   on until about June on Monday.
[01:20:24.520 --> 01:20:26.360]   If you have to make that rule, you have a problem.
[01:20:26.360 --> 01:20:28.680]   It's not a rule. I just noticed it was a thing I was doing.
[01:20:28.680 --> 01:20:31.400]   Get off Twitter. This is my new slogan.
[01:20:31.400 --> 01:20:32.200]   This is my new.
[01:20:32.200 --> 01:20:34.040]   Just get off. Here's an example.
[01:20:34.040 --> 01:20:37.640]   If I'm traveling, I'm never on social media, for example, because I would rather just.
[01:20:37.640 --> 01:20:38.600]   And you're happier for it.
[01:20:38.600 --> 01:20:41.160]   Oh yeah. No, I just got back from a week at last in volcanic.
[01:20:41.160 --> 01:20:42.520]   Do an experiment this week.
[01:20:42.520 --> 01:20:43.560]   I'm watching the grown-free others.
[01:20:43.560 --> 01:20:44.680]   Just seeing with people on Twitter.
[01:20:44.680 --> 01:20:46.520]   See how you feel after you get off Twitter.
[01:20:46.520 --> 01:20:46.920]   Mm-hmm.
[01:20:46.920 --> 01:20:48.760]   Just for the next five, six days.
[01:20:48.760 --> 01:20:49.480]   Yeah.
[01:20:49.480 --> 01:20:51.560]   Just do a little check in after you get off Twitter.
[01:20:51.560 --> 01:20:54.200]   I'm like wondering if maybe I should treat Twitter like I treat Bill Pang,
[01:20:54.200 --> 01:20:56.600]   or I'm like, okay, I schedule time every month where I do it.
[01:20:56.600 --> 01:20:58.120]   You should treat heroin.
[01:20:58.120 --> 01:21:00.120]   Well, I think it's more of a day.
[01:21:00.120 --> 01:21:01.640]   It's not in Twitter for me.
[01:21:01.640 --> 01:21:06.680]   Like Facebook, I don't show up much, especially since about the 2016 election,
[01:21:06.680 --> 01:21:09.960]   where now everything is like, we got to sort you into buckets.
[01:21:09.960 --> 01:21:12.520]   I've deactivated Facebook.
[01:21:12.520 --> 01:21:14.840]   I didn't delete it because everyone saw I can activate it.
[01:21:14.840 --> 01:21:16.280]   See what's going on in deactivated.
[01:21:16.280 --> 01:21:16.760]   Okay.
[01:21:16.760 --> 01:21:18.200]   But I deactivated Twitter.
[01:21:18.200 --> 01:21:21.400]   I have an account, but I think
[01:21:22.760 --> 01:21:24.280]   people get in trouble on Twitter.
[01:21:24.280 --> 01:21:30.360]   And I see nice, normal people get on Twitter and get a little bitchy Twitter fights
[01:21:30.360 --> 01:21:32.040]   that ends up hurting them.
[01:21:32.040 --> 01:21:32.760]   It's, I've done it.
[01:21:32.760 --> 01:21:33.720]   I've seen a lot of people do it.
[01:21:33.720 --> 01:21:34.840]   Here's an example.
[01:21:34.840 --> 01:21:38.360]   This is two developers on Game War or Guild Wars, right?
[01:21:38.360 --> 01:21:39.400]   Oh, that's story.
[01:21:39.400 --> 01:21:39.800]   Yeah.
[01:21:39.800 --> 01:21:43.720]   But I think people are going to say, oh, poor Jessica and Peter.
[01:21:43.720 --> 01:21:46.200]   So Jessica Price is a narrative designer.
[01:21:46.200 --> 01:21:48.680]   She designs narratives for Guild Wars.
[01:21:48.680 --> 01:21:51.560]   On July 3rd, this is four days ago.
[01:21:52.280 --> 01:21:56.200]   She tweeted a 29 tweet thread talking about the challenges of
[01:21:56.200 --> 01:21:58.040]   writing players in an MMORPG.
[01:21:58.040 --> 01:22:02.200]   Some guy, some streamer goes on Twitter.
[01:22:02.200 --> 01:22:03.960]   It says really interesting thread to read,
[01:22:03.960 --> 01:22:06.600]   however, allow me to disagree slightly.
[01:22:06.600 --> 01:22:11.560]   And then tweets three tweets about how narrative design influences player expression,
[01:22:11.560 --> 01:22:12.600]   etc, etc.
[01:22:12.600 --> 01:22:15.400]   Price is insulted.
[01:22:15.400 --> 01:22:17.720]   She says, thanks for mansplaining.
[01:22:17.720 --> 01:22:21.000]   He comes back and forth.
[01:22:21.960 --> 01:22:22.360]   This is.
[01:22:22.360 --> 01:22:25.480]   So Twitter is a terrible place to have conversation.
[01:22:25.480 --> 01:22:30.440]   So, by the way, another guy who works with Jessica Price,
[01:22:30.440 --> 01:22:31.800]   Peter Freeze weighs in.
[01:22:31.800 --> 01:22:33.880]   They both get fired.
[01:22:33.880 --> 01:22:37.720]   Jessica's last tweet is, if Reddit wants you fired,
[01:22:37.720 --> 01:22:40.760]   they're fired you because, of course, a Reddit storm occurred.
[01:22:40.760 --> 01:22:42.600]   Another place that really isn't worth it.
[01:22:42.600 --> 01:22:44.280]   Well, just you should never drink and drive.
[01:22:44.280 --> 01:22:45.720]   You should never tweet while emotional.
[01:22:45.720 --> 01:22:46.760]   You should never tweet.
[01:22:46.760 --> 01:22:50.280]   Like you should never go on social media when you're not feeling 100%
[01:22:50.280 --> 01:22:51.800]   home and centered.
[01:22:51.800 --> 01:22:54.360]   And before you hit send, take two minutes.
[01:22:54.360 --> 01:22:55.240]   Go have a cup of tea.
[01:22:55.240 --> 01:22:56.840]   Allow me to disagree slightly.
[01:22:56.840 --> 01:22:58.200]   I started to dock on that.
[01:22:58.200 --> 01:22:59.320]   I started to dock on that.
[01:22:59.320 --> 01:23:02.120]   All the tweets I never sent, but I never posted.
[01:23:02.120 --> 01:23:03.960]   Because things that I wanted to tweet and I went,
[01:23:03.960 --> 01:23:05.160]   no, I thought better of it.
[01:23:05.160 --> 01:23:07.320]   It's like the one else was fun to all the girls I love.
[01:23:07.320 --> 01:23:10.600]   If we do our traditional Friday night,
[01:23:10.600 --> 01:23:12.040]   go out to the pub and get one good thing.
[01:23:12.040 --> 01:23:13.480]   Then the phone stays in the pocket.
[01:23:13.480 --> 01:23:17.240]   I mean, any tweet is drunk tweeting, whether you're sober or not.
[01:23:17.240 --> 01:23:18.840]   Twitter's still great for us.
[01:23:18.840 --> 01:23:20.760]   News. I use it as a news feed.
[01:23:20.760 --> 01:23:21.800]   I love it as a news feed.
[01:23:21.800 --> 01:23:25.080]   I when people follow, people that do tweet storms,
[01:23:25.080 --> 01:23:29.720]   almost always get either blocked or muted or, I mean, unfollowed or muted.
[01:23:29.720 --> 01:23:33.880]   But I still find it the best place to go.
[01:23:33.880 --> 01:23:36.840]   If something's happening and it's like, oh no, what's going on?
[01:23:36.840 --> 01:23:38.280]   First place I go.
[01:23:38.280 --> 01:23:40.600]   There are some people where I will follow their Twitter threads
[01:23:40.600 --> 01:23:44.680]   because I know that they're thoughtful and careful and considerate.
[01:23:44.680 --> 01:23:46.760]   But when you have someone who starts with, okay,
[01:23:46.760 --> 01:23:48.280]   it's time for some game theory.
[01:23:48.280 --> 01:23:49.480]   You block on top.
[01:23:49.480 --> 01:23:53.560]   So I don't think Jessica Price did anything wrong.
[01:23:53.560 --> 01:23:54.200]   Yeah, sure.
[01:23:54.200 --> 01:23:54.920]   I feel bad for her.
[01:23:54.920 --> 01:23:56.760]   She should not be expressed an opinion.
[01:23:56.760 --> 01:23:57.400]   Accept.
[01:23:57.400 --> 01:24:00.440]   Twitter and anything.
[01:24:00.440 --> 01:24:01.960]   This is inevitable.
[01:24:01.960 --> 01:24:05.000]   But I think you can play the platform for it.
[01:24:05.000 --> 01:24:08.280]   I think you better employees for being so spineless as to cavents.
[01:24:08.280 --> 01:24:11.880]   This is what I was about to say though, is here's one of the minefields
[01:24:11.880 --> 01:24:14.200]   that we ran into at a former employer of mine.
[01:24:14.200 --> 01:24:16.360]   I was on the social media task force.
[01:24:16.360 --> 01:24:19.880]   And they wanted to mandate that every writer in the organization
[01:24:19.880 --> 01:24:26.120]   get a social media feed and dedicate it solely to promoting the organization's work.
[01:24:26.120 --> 01:24:30.200]   And about half of the writers already have their own personal Twitter feeds.
[01:24:30.200 --> 01:24:32.600]   And the question I brought up was, so what do we do?
[01:24:32.600 --> 01:24:35.080]   Do we just start separate accounts for promoting our work?
[01:24:35.080 --> 01:24:36.600]   And they said, no, no, you've already got followers.
[01:24:36.600 --> 01:24:40.360]   Of course, we're just going to require you to start promoting your stories on your personal feed.
[01:24:40.360 --> 01:24:41.720]   It goes stuff it so far.
[01:24:41.720 --> 01:24:46.280]   Which is pretty much what I said was, why are you expecting someone else?
[01:24:46.280 --> 01:24:48.200]   Who's done all the work to build an audience?
[01:24:48.200 --> 01:24:49.400]   Why are you expecting that?
[01:24:49.400 --> 01:24:50.600]   That is suddenly your asset.
[01:24:50.600 --> 01:24:56.200]   And I think part of the thing that we're still working out now in terms of social media as corporate asset
[01:24:56.200 --> 01:25:01.080]   is you cannot hire somebody who has their own independent following
[01:25:01.080 --> 01:25:04.200]   and expect that to become a corporate asset you can control.
[01:25:04.200 --> 01:25:09.000]   And the companies who do that are hurting themselves more than they're hurting the people they fire
[01:25:09.000 --> 01:25:14.200]   because they're going to get the reputation for being the ones that are stealing someone's
[01:25:14.200 --> 01:25:16.680]   work or reputation and trying to pass it off as their own.
[01:25:16.680 --> 01:25:20.520]   That's well said because what you can expect when you hire somebody now,
[01:25:20.520 --> 01:25:26.520]   and this goes in journalism a lot and tech journalism especially,
[01:25:26.520 --> 01:25:30.680]   if you hire somebody that already has a following, that already has a presence,
[01:25:30.680 --> 01:25:36.520]   you have an understanding that you're hopefully getting some of that,
[01:25:36.520 --> 01:25:39.560]   their mojo as part of your brand.
[01:25:39.560 --> 01:25:43.560]   And at the same time, if you have a big brand, you're giving some of the brands mojo to them.
[01:25:44.360 --> 01:25:45.320]   As part of it.
[01:25:45.320 --> 01:25:49.480]   But you can't think of it as an ownership relationship, right?
[01:25:49.480 --> 01:25:51.080]   Like it's a partnership relationship.
[01:25:51.080 --> 01:25:55.400]   No, I'm sorry, employer buys your skills for a certain set period of time a week for a set period of
[01:25:55.400 --> 01:25:58.760]   fun. They don't buy your reputation. They don't buy what you do outside of work.
[01:25:58.760 --> 01:26:04.120]   And the other thing that really worried me this week about this was you heard about this
[01:26:04.120 --> 01:26:09.720]   pull past Pete guy, like the another person who called cops on a black farming and swimming pool.
[01:26:09.720 --> 01:26:11.240]   Someone for being black in public.
[01:26:11.240 --> 01:26:15.640]   Yeah, well, but you see, we've now had what three of these in the last four weeks,
[01:26:15.640 --> 01:26:19.160]   and sooner or later, Twitter's going to get it wrong.
[01:26:19.160 --> 01:26:21.960]   And they're going to get the wrong person. They're going to get the wrong person fired and ruined
[01:26:21.960 --> 01:26:27.960]   their life. And I just think we need to step back a bit and this, it's turning into a mob.
[01:26:27.960 --> 01:26:29.800]   Yeah, it's turning into.
[01:26:29.800 --> 01:26:32.520]   Well, okay, you've been at the rough end of the week.
[01:26:32.520 --> 01:26:35.800]   Just like you don't get in a car after you've been drinking, you dunk on social media if you're
[01:26:35.800 --> 01:26:38.040]   feeling things, like feel your feelings.
[01:26:38.040 --> 01:26:39.480]   So only go off your robot.
[01:26:40.360 --> 01:26:41.560]   Price writes the most.
[01:26:41.560 --> 01:26:43.560]   Before your coffee's kicked into your just kind of.
[01:26:43.560 --> 01:26:44.360]   She's out of work.
[01:26:44.360 --> 01:26:48.920]   She says the message is very clear, especially women at the company, Guild Wars,
[01:26:48.920 --> 01:26:51.080]   if Reddit wants you fired, we'll fire you.
[01:26:51.080 --> 01:26:53.320]   The quality of your work doesn't matter.
[01:26:53.320 --> 01:26:56.840]   Your personal space, your personal social media is not yours.
[01:26:56.840 --> 01:26:59.320]   You are on the clock 100% of the time we own you.
[01:26:59.320 --> 01:27:00.760]   You're not allowed to be yourself.
[01:27:00.760 --> 01:27:02.040]   You're not allowed to get frustrated.
[01:27:02.040 --> 01:27:04.280]   You're not allowed to have your own space to breathe.
[01:27:04.280 --> 01:27:07.400]   Get out there, make sure the players have a good time, make sure you smile
[01:27:07.400 --> 01:27:09.000]   while they hit you.
[01:27:09.000 --> 01:27:14.600]   I feel terrible for her, but I honestly think using Twitter is where, you know,
[01:27:14.600 --> 01:27:17.000]   it was a blog post.
[01:27:17.000 --> 01:27:17.880]   It was an article.
[01:27:17.880 --> 01:27:18.840]   It was an article.
[01:27:18.840 --> 01:27:19.960]   No, it should have been.
[01:27:19.960 --> 01:27:21.560]   It should have been an article.
[01:27:21.560 --> 01:27:23.240]   I think the chat, yeah.
[01:27:23.240 --> 01:27:26.360]   I think people put stuff on Twitter because they kind of.
[01:27:26.360 --> 01:27:28.840]   I think you put more incendiary stuff on Twitter.
[01:27:28.840 --> 01:27:32.840]   I think people put those threads on Twitter because they want the dopamine hits of people
[01:27:32.840 --> 01:27:34.680]   liking or retweeting or reacting.
[01:27:34.680 --> 01:27:37.240]   And since nobody bothers with blog comments.
[01:27:37.240 --> 01:27:40.840]   If she had ignored the response, by the way, one of the ways I make Twitter better is I
[01:27:40.840 --> 01:27:43.560]   don't look at that replies period at all.
[01:27:43.560 --> 01:27:47.720]   I mean, if I, if you cultivate a good feed with good quality content,
[01:27:47.720 --> 01:27:52.120]   I use tweet deck to eliminate retweets, which by the way, eliminates a lot of the
[01:27:52.120 --> 01:27:54.440]   viral and cindy-ary stuff.
[01:27:54.440 --> 01:27:57.800]   So I'm only reading, reading original content from good people.
[01:27:57.800 --> 01:28:01.160]   And I don't look at anything that anybody says to me, it's okay.
[01:28:01.160 --> 01:28:06.600]   I also don't tweet because there have been a couple of times I've tweeted and I've regretted.
[01:28:06.600 --> 01:28:07.480]   It was been a mistake.
[01:28:07.480 --> 01:28:09.560]   And so I just, I think it's a dangerous place.
[01:28:09.560 --> 01:28:14.840]   All right, let's stop and move on to something else.
[01:28:14.840 --> 01:28:18.280]   Don't post on Twitter while emotional while while human.
[01:28:18.280 --> 01:28:19.720]   Don't post on Twitter while human.
[01:28:19.720 --> 01:28:21.960]   Only do it when you're a robot.
[01:28:21.960 --> 01:28:27.640]   By the way, if you, if you imagine if Twitter just became nothing but bots tweeting and adding
[01:28:27.640 --> 01:28:28.120]   each other.
[01:28:28.120 --> 01:28:31.080]   If you, if you look at my feed, it's just a bot.
[01:28:31.080 --> 01:28:32.520]   It's just saying Leo's about to do a show.
[01:28:32.520 --> 01:28:33.720]   Leo's about to do a show.
[01:28:33.720 --> 01:28:36.920]   And if you live in Uganda, and I, I think this is appalling.
[01:28:36.920 --> 01:28:38.840]   I defend people's rights to use Twitter.
[01:28:38.840 --> 01:28:42.840]   But the president of Uganda is charging people a tax.
[01:28:42.840 --> 01:28:51.160]   If you want to use Twitter, Facebook, WhatsApp, Google Hangouts, YouTube, Skype, Yahoo Messenger,
[01:28:51.160 --> 01:28:56.120]   any social media, a nickel a day, which sounds like not much, but it is Uganda.
[01:28:56.120 --> 01:28:58.680]   Freedom of the press belongs to them what owns the press.
[01:28:58.680 --> 01:28:59.160]   Yeah.
[01:28:59.160 --> 01:28:59.480]   Yeah.
[01:28:59.480 --> 01:29:03.240]   It's not I'm curious to know how they're actually going to institute this because the payment
[01:29:03.240 --> 01:29:04.440]   systems alone would be.
[01:29:04.440 --> 01:29:06.840]   It goes with your, uh, goes with your mobile,
[01:29:06.840 --> 01:29:09.160]   charges, your mobile phone bill.
[01:29:09.160 --> 01:29:12.280]   Yeah, I guess landlines are so rather than everyone's on mobile.
[01:29:12.280 --> 01:29:14.920]   It's also your bank typically like it.
[01:29:14.920 --> 01:29:19.080]   And you know, because there's a lot of smaller mobile only banks there.
[01:29:19.080 --> 01:29:19.240]   Yeah.
[01:29:19.240 --> 01:29:19.320]   Yeah.
[01:29:19.320 --> 01:29:19.800]   Yeah.
[01:29:19.800 --> 01:29:21.480]   This is social media.
[01:29:21.480 --> 01:29:24.200]   This is a president, Yohari Musaveni.
[01:29:24.200 --> 01:29:28.440]   Social media is a luxury by those who are enjoying themselves or those who are malicious.
[01:29:28.440 --> 01:29:30.920]   All the moral reasons are in favor of that tax.
[01:29:30.920 --> 01:29:32.920]   I'm not, I'm not, I'm not disagreeing with the guy.
[01:29:33.240 --> 01:29:38.440]   He said, Ugandan social media users are endlessly donating money to foreign telephone
[01:29:38.440 --> 01:29:47.080]   companies through chatting or even lying, uh, the response, of course, from a, a, a, a, a, a,
[01:29:47.080 --> 01:29:48.680]   a compiler based charity worker.
[01:29:48.680 --> 01:29:51.640]   The taxes and absolute insult to Ugandans.
[01:29:51.640 --> 01:29:53.400]   We already buy data, which the government taxes.
[01:29:53.400 --> 01:29:57.480]   Why should we again have to pay this money to the government to access these platforms?
[01:29:57.480 --> 01:30:02.200]   Amnesty International, Kaudland, the Ugandan government to scrap the tax,
[01:30:02.200 --> 01:30:06.760]   which is, uh, they call it an attempt to smother dissent disguised as a measure to raise revenue.
[01:30:06.760 --> 01:30:09.400]   I'm not sure which is more important raising.
[01:30:09.400 --> 01:30:12.280]   Well, I mean, this reminds me of the Chris Rock bit where he said, you know,
[01:30:12.280 --> 01:30:14.760]   find, make guns accessible, just charge a lot for bullets.
[01:30:14.760 --> 01:30:15.800]   Make the bullets expensive.
[01:30:15.800 --> 01:30:18.600]   And, and the punchline, of course, is somebody's looking over a bullet,
[01:30:18.600 --> 01:30:19.080]   rublic horse.
[01:30:19.080 --> 01:30:21.240]   Like they must have really hated this.
[01:30:21.240 --> 01:30:25.560]   But yeah, I mean, you can't just got some strange rules, just something that
[01:30:25.560 --> 01:30:26.680]   goes on homosexuality.
[01:30:26.680 --> 01:30:26.680]   Yeah.
[01:30:26.680 --> 01:30:27.880]   But I mean, it's,
[01:30:27.880 --> 01:30:30.040]   Tennessee has licensing bloggers.
[01:30:30.040 --> 01:30:30.440]   Really?
[01:30:30.440 --> 01:30:30.680]   Yeah.
[01:30:30.680 --> 01:30:33.000]   You got to be, you got to pay a lot of money to be a blogger.
[01:30:33.000 --> 01:30:34.200]   Oh, good grief.
[01:30:34.200 --> 01:30:35.320]   So I think this is it.
[01:30:35.320 --> 01:30:37.560]   That's an anti-free speech move, but maybe not going to be a student.
[01:30:37.560 --> 01:30:37.560]   Yeah.
[01:30:37.560 --> 01:30:38.600]   Well, you know, this is it.
[01:30:38.600 --> 01:30:41.720]   It's all about cutting down the amount of people on the platform and, you know,
[01:30:41.720 --> 01:30:42.200]   trying to live there.
[01:30:42.200 --> 01:30:45.080]   So how long until somebody starts trying to charge for Instagram as in,
[01:30:45.080 --> 01:30:49.400]   you can't Instagram our country unless you, you, because if you geoteck,
[01:30:49.400 --> 01:30:52.200]   we'll find you in charging money for exploiting our natural resources.
[01:30:52.200 --> 01:30:55.480]   I'm sure there's lawyers who will be happy to set up systems to do that.
[01:30:55.480 --> 01:30:58.840]   I mean, there was that piece a couple of weeks ago about how hotels and the Maldives
[01:30:58.840 --> 01:31:03.320]   are getting very, very tired of influencers trying to scan them out of a free stay
[01:31:03.320 --> 01:31:05.320]   at a $12,000 a week resort.
[01:31:05.320 --> 01:31:05.640]   Yeah.
[01:31:05.640 --> 01:31:05.960]   Really?
[01:31:05.960 --> 01:31:08.360]   Because I wonder that's all on my Instagram.
[01:31:08.360 --> 01:31:08.760]   Yeah.
[01:31:08.760 --> 01:31:13.080]   Is attractive young women and Skippy Bikini's at a lovely luxury resort hotel.
[01:31:13.080 --> 01:31:17.800]   You think I'm following, but I follow travel blogs, and that's when I see a lot of.
[01:31:17.800 --> 01:31:21.880]   And Instagram makes it easy now because they can do a hashtag travel blogger or whatever,
[01:31:21.880 --> 01:31:22.760]   and you'll follow along.
[01:31:22.760 --> 01:31:26.520]   Yeah, $900 a year to be a blogger in Tanzania.
[01:31:26.520 --> 01:31:27.160]   Yeah.
[01:31:27.160 --> 01:31:29.960]   So the minute I heard someone who you described themselves as an influencer,
[01:31:29.960 --> 01:31:32.280]   it's just like you're such a prat.
[01:31:32.280 --> 01:31:35.160]   Have you ever heard somebody describe themselves as a thought leader in the wild?
[01:31:35.160 --> 01:31:35.640]   Oh, no.
[01:31:35.640 --> 01:31:37.640]   Because I've had that happen.
[01:31:37.640 --> 01:31:41.160]   Let's charge $10,000 to be an influencer or a thought leader.
[01:31:41.160 --> 01:31:41.640]   Yeah.
[01:31:41.640 --> 01:31:42.680]   To use that.
[01:31:42.680 --> 01:31:43.720]   To use that.
[01:31:43.720 --> 01:31:44.520]   I'm for that.
[01:31:44.520 --> 01:31:44.680]   Yeah.
[01:31:44.680 --> 01:31:45.400]   I'm for that.
[01:31:45.400 --> 01:31:46.280]   Hey, we're going to take a little break.
[01:31:46.280 --> 01:31:47.640]   We come back more news.
[01:31:47.640 --> 01:31:48.920]   I'm going to get to some good news.
[01:31:48.920 --> 01:31:52.680]   I swear to God, but first let's talk a little bit about our sponsor, Uber.
[01:31:53.240 --> 01:31:56.040]   Read about all the way.
[01:31:56.040 --> 01:31:59.720]   Uber's moving forward by going to uber.com/movingforward a new site.
[01:31:59.720 --> 01:32:02.920]   But I have to say, first of all, I use Uber.
[01:32:02.920 --> 01:32:04.520]   And I'm happy to.
[01:32:04.520 --> 01:32:05.880]   I happily use Uber.
[01:32:05.880 --> 01:32:06.840]   My kids use Uber.
[01:32:06.840 --> 01:32:09.160]   Uber is an empowering technology for my mom.
[01:32:09.160 --> 01:32:12.760]   I set up an Uber account for her because she's 86.
[01:32:12.760 --> 01:32:13.880]   Doesn't drive.
[01:32:13.880 --> 01:32:15.720]   My sister can't always get it to the doctor.
[01:32:15.720 --> 01:32:16.680]   Go to the grocery store.
[01:32:16.680 --> 01:32:19.080]   So it's great because I put it on my charge card.
[01:32:19.080 --> 01:32:21.160]   So I see the $8 Uber charge.
[01:32:21.160 --> 01:32:23.720]   And I know moms getting out, which is great.
[01:32:23.720 --> 01:32:25.400]   It looks like you know where your kids are as well.
[01:32:25.400 --> 01:32:26.760]   And I know where my kids are.
[01:32:26.760 --> 01:32:27.240]   Yeah.
[01:32:27.240 --> 01:32:29.960]   Uber is working really hard to move forward.
[01:32:29.960 --> 01:32:33.400]   In fact, they've got a site uber.com/movingforward.
[01:32:33.400 --> 01:32:35.800]   They want to re-earn your trust.
[01:32:35.800 --> 01:32:39.080]   They're determined to improve the ride sharing experience,
[01:32:39.080 --> 01:32:41.320]   both for drivers and for riders.
[01:32:41.320 --> 01:32:43.880]   And a lot of this goes to Dara, coastal Shahib.
[01:32:43.880 --> 01:32:46.120]   Dara is an amazing new CEO.
[01:32:46.120 --> 01:32:50.280]   And he really is, I think, committed to making Uber.
[01:32:50.280 --> 01:32:53.080]   Everything Uber was supposed to be in the first place.
[01:32:53.080 --> 01:32:55.000]   A great place to get a great ride.
[01:32:55.000 --> 01:32:57.800]   A great job for people who want to work in the gig economy.
[01:32:57.800 --> 01:33:00.840]   They're putting new features in their app to take the stress out of your pickup.
[01:33:00.840 --> 01:33:03.640]   For instance, when you get an Uber ride now,
[01:33:03.640 --> 01:33:05.800]   they can verify the details of your ride,
[01:33:05.800 --> 01:33:08.280]   see your driver's name, its car, its license.
[01:33:08.280 --> 01:33:11.000]   Make sure you get in the right car every time.
[01:33:11.000 --> 01:33:12.920]   They want you to have a better trip.
[01:33:12.920 --> 01:33:15.400]   They're continuously working on ways to keep you better protected
[01:33:15.400 --> 01:33:16.760]   and connected throughout your ride.
[01:33:17.320 --> 01:33:20.120]   Uber is putting people first by changing the company from within
[01:33:20.120 --> 01:33:23.240]   new executive leadership and new company norms.
[01:33:23.240 --> 01:33:26.520]   I want to give these guys a second chance,
[01:33:26.520 --> 01:33:31.320]   because I really appreciate Uber and I use Uber all the time.
[01:33:31.320 --> 01:33:35.800]   When I'm in a town, I don't know, having that Uber app
[01:33:35.800 --> 01:33:38.840]   and the ability to get a ride is huge for me.
[01:33:38.840 --> 01:33:39.960]   Don't just take my word for it.
[01:33:39.960 --> 01:33:40.840]   You can see the improvements.
[01:33:40.840 --> 01:33:43.720]   Just install the Uber app if you haven't already.
[01:33:43.720 --> 01:33:44.600]   Check it out.
[01:33:44.600 --> 01:33:47.000]   And I always, by the way, I always tip.
[01:33:47.000 --> 01:33:48.360]   And I love it, they put the tip in.
[01:33:48.360 --> 01:33:49.160]   I always tip.
[01:33:49.160 --> 01:33:50.760]   I told my daughter that.
[01:33:50.760 --> 01:33:51.640]   She said, "Do I have to tip?"
[01:33:51.640 --> 01:33:53.880]   I said, "Abby, always tip."
[01:33:53.880 --> 01:33:56.680]   Give them some cash or press that button that gives them a tip.
[01:33:56.680 --> 01:33:59.240]   You can read about all the ways Uber is moving forward by going to
[01:33:59.240 --> 01:34:02.840]   uber.com/movingforward.
[01:34:02.840 --> 01:34:05.640]   Uber.com/movingforward.
[01:34:05.640 --> 01:34:06.920]   Uber eats.
[01:34:06.920 --> 01:34:09.640]   I've tried lately and I've been pretty impressed with it.
[01:34:09.640 --> 01:34:13.400]   In fact, I was in Madrid and it was there.
[01:34:13.400 --> 01:34:15.800]   I used Uber in Madrid because it's the only...
[01:34:16.600 --> 01:34:19.880]   Yeah, the only one there of the US ones.
[01:34:19.880 --> 01:34:20.840]   And then I used...
[01:34:20.840 --> 01:34:22.840]   I was sick for a couple of days while I was there,
[01:34:22.840 --> 01:34:24.840]   which is the worst when you're sick, when you're traveling.
[01:34:24.840 --> 01:34:25.400]   Yes.
[01:34:25.400 --> 01:34:26.920]   And I was like...
[01:34:26.920 --> 01:34:28.520]   And then I got in my Uber.
[01:34:28.520 --> 01:34:31.480]   I just got in the ride back to the hotel with Uber.
[01:34:31.480 --> 01:34:33.240]   And then it popped up this little thing and said,
[01:34:33.240 --> 01:34:34.520]   "Do you want to try Uber eats?"
[01:34:34.520 --> 01:34:37.800]   And I was like, "Yes, please, send me food."
[01:34:37.800 --> 01:34:38.840]   Amen.
[01:34:38.840 --> 01:34:41.480]   And they had it there in like 10 minutes.
[01:34:41.480 --> 01:34:42.120]   Yeah.
[01:34:42.120 --> 01:34:43.640]   It was unbelievable.
[01:34:43.640 --> 01:34:45.000]   And it was actually pretty reasonable.
[01:34:45.000 --> 01:34:46.040]   There wasn't a huge fee.
[01:34:46.040 --> 01:34:47.240]   So I was like, "I was impressed."
[01:34:47.240 --> 01:34:50.680]   You can take out food in Spain as the equivalent to just like...
[01:34:50.680 --> 01:34:51.800]   What are you thinking?
[01:34:51.800 --> 01:34:52.280]   Sick.
[01:34:52.280 --> 01:34:53.240]   What are you going to do?
[01:34:53.240 --> 01:34:53.960]   Yeah.
[01:34:53.960 --> 01:34:56.120]   But it was just a stack of 20 tiny plates.
[01:34:56.120 --> 01:34:58.600]   We travel a lot though and I have to say,
[01:34:58.600 --> 01:35:02.200]   almost anywhere you go, you can take an Uber except London.
[01:35:02.200 --> 01:35:03.000]   You can take, right?
[01:35:03.000 --> 01:35:03.400]   London?
[01:35:03.400 --> 01:35:04.040]   Yeah.
[01:35:04.040 --> 01:35:07.640]   Uber's license was temporarily withdrawn,
[01:35:07.640 --> 01:35:09.080]   but I think they're now back there.
[01:35:09.080 --> 01:35:09.880]   They're strictly legal again.
[01:35:09.880 --> 01:35:11.800]   I first used Uber when they launched in Paris.
[01:35:11.800 --> 01:35:15.480]   This was at the little web about five, six, maybe eight years ago.
[01:35:15.480 --> 01:35:16.600]   That was my first experience.
[01:35:16.600 --> 01:35:17.560]   It was a great experience.
[01:35:17.560 --> 01:35:19.080]   And as a traveler,
[01:35:19.080 --> 01:35:21.160]   knowing what you're going to get is a huge thing.
[01:35:21.160 --> 01:35:24.280]   I can understand why they broke big in San Francisco initially,
[01:35:24.280 --> 01:35:25.880]   because San Francisco is taxi service.
[01:35:25.880 --> 01:35:26.600]   Oh, it's terrible.
[01:35:26.600 --> 01:35:27.160]   It's awful.
[01:35:27.160 --> 01:35:28.120]   Absolutely awful.
[01:35:28.120 --> 01:35:29.800]   Particularly if you've got a foreign accident.
[01:35:29.800 --> 01:35:32.600]   It's also terrible to be a driver in San Francisco too.
[01:35:32.600 --> 01:35:33.160]   Yeah.
[01:35:33.160 --> 01:35:36.600]   So, and Muni is just a dreadful public transit system as well.
[01:35:36.600 --> 01:35:37.800]   So if you can bounce on...
[01:35:37.800 --> 01:35:39.960]   Like in Paris and to the rest of the US though,
[01:35:39.960 --> 01:35:40.520]   the Bay Area is good.
[01:35:40.520 --> 01:35:41.800]   It has the public transit system,
[01:35:41.800 --> 01:35:45.000]   which is leaps and bounds ahead of a lot of other US cities.
[01:35:45.000 --> 01:35:46.360]   But it's tremendously.
[01:35:46.360 --> 01:35:48.120]   I can see the appeal of a road share service,
[01:35:48.120 --> 01:35:50.920]   because it's really frustrating to move around San Francisco.
[01:35:50.920 --> 01:35:52.520]   Yeah, to go from San Francisco to the East Bay,
[01:35:52.520 --> 01:35:55.480]   there is one bus an hour after 1230,
[01:35:55.480 --> 01:35:57.640]   and that's the only way apart from private drives.
[01:35:57.640 --> 01:35:58.200]   Yeah.
[01:35:58.200 --> 01:35:59.800]   And take a boat.
[01:35:59.800 --> 01:36:03.000]   In Louisville, the taxis were just...
[01:36:03.000 --> 01:36:04.840]   They've been so bad for so long,
[01:36:04.840 --> 01:36:06.200]   and Uber and Lyft came in,
[01:36:06.200 --> 01:36:08.920]   and it's made just a huge difference.
[01:36:08.920 --> 01:36:09.560]   Yeah.
[01:36:09.560 --> 01:36:10.040]   And it's...
[01:36:10.040 --> 01:36:11.480]   Competition's not a bad thing.
[01:36:11.480 --> 01:36:12.040]   Yeah.
[01:36:12.040 --> 01:36:14.440]   I think the taxi commissions and the medallions,
[01:36:14.440 --> 01:36:17.000]   and the taxi industries had a free ride,
[01:36:17.000 --> 01:36:19.160]   so to speak, for a long time.
[01:36:19.160 --> 01:36:19.480]   Yeah.
[01:36:19.480 --> 01:36:20.440]   Like in a lot of areas.
[01:36:20.440 --> 01:36:22.200]   That's had this entire discussion.
[01:36:22.200 --> 01:36:24.760]   I just spent a week up in Shasta County, California,
[01:36:24.760 --> 01:36:27.560]   which is where Las Involcanic National Park is.
[01:36:27.560 --> 01:36:28.200]   Yeah.
[01:36:28.200 --> 01:36:28.680]   Cool.
[01:36:28.680 --> 01:36:29.800]   Isn't that beautiful?
[01:36:29.800 --> 01:36:30.920]   Isn't that gorgeous?
[01:36:30.920 --> 01:36:31.640]   It is stunning.
[01:36:31.640 --> 01:36:33.320]   It's one of my favorite national parks,
[01:36:33.320 --> 01:36:36.600]   but I had almost no cell phone service the whole time I was there.
[01:36:36.600 --> 01:36:39.960]   And the broadband in the neighborhood went out when people next door...
[01:36:39.960 --> 01:36:43.640]   We had a group of 20-somethings at the cabin next door.
[01:36:43.640 --> 01:36:45.640]   And they literally slept on the broadband for like three days.
[01:36:45.640 --> 01:36:47.240]   They were all snap chatting all the time.
[01:36:47.240 --> 01:36:47.720]   They were.
[01:36:47.720 --> 01:36:48.200]   They were.
[01:36:48.200 --> 01:36:48.680]   They were.
[01:36:48.680 --> 01:36:49.320]   Well, because they had...
[01:36:49.320 --> 01:36:50.520]   They figured out a way to get...
[01:36:50.520 --> 01:36:53.000]   They gave the deer that were roaming around potato chips
[01:36:53.000 --> 01:36:54.440]   and snap-chatted the whole experience.
[01:36:54.440 --> 01:36:55.000]   Oh, for good.
[01:36:55.000 --> 01:36:55.640]   I know.
[01:36:55.640 --> 01:36:59.000]   But what I was thinking while I was there in between...
[01:36:59.000 --> 01:37:00.840]   Jame and don't ever be a millennial, okay?
[01:37:00.840 --> 01:37:06.120]   And in between going on hikes and swimming in pristine alpine lakes and so on and so forth,
[01:37:06.120 --> 01:37:07.080]   what I was thinking was,
[01:37:07.080 --> 01:37:12.280]   we talk a lot about technology in terms of like Uber Eats and Uber and ride-ture services
[01:37:12.280 --> 01:37:13.480]   and e-commerce.
[01:37:13.480 --> 01:37:19.400]   And there are whole swaths of the US or the world where the technology challenges
[01:37:19.400 --> 01:37:22.360]   are going to be much different because the conditions are much different.
[01:37:22.360 --> 01:37:26.760]   We always forget those of us in the internet saturated areas,
[01:37:26.760 --> 01:37:30.920]   what it's like to live in a rural area and have very little, if any, internet.
[01:37:30.920 --> 01:37:35.960]   And I would love to see more if you're walking around in a meadow in the last and national park.
[01:37:35.960 --> 01:37:36.520]   Yeah.
[01:37:36.520 --> 01:37:38.040]   It's not a good way to get a job.
[01:37:38.040 --> 01:37:39.000]   It's not a good way to...
[01:37:39.000 --> 01:37:39.480]   Yeah.
[01:37:39.480 --> 01:37:41.400]   Well, because this is the thing is I was thinking...
[01:37:41.400 --> 01:37:45.720]   We have an economy that's increasingly networked and increasingly global.
[01:37:45.720 --> 01:37:50.760]   And the question is, is how do you build out an infrastructure to serve people
[01:37:50.760 --> 01:37:52.120]   without altering the character?
[01:37:52.120 --> 01:37:55.000]   Or more importantly, how do you build an infrastructure that solves
[01:37:55.000 --> 01:37:56.360]   region-specific problems?
[01:37:56.360 --> 01:38:00.200]   I was talking to one of the guys I was talking to up there.
[01:38:00.200 --> 01:38:07.240]   He mentioned that in order for senior citizens to get medical care in dire emergencies,
[01:38:07.240 --> 01:38:11.080]   they often have to pay for a helicopter to medivac them out and down to a hospital.
[01:38:11.640 --> 01:38:17.400]   And I was thinking, well, you know, is there anybody who's going to work on telemedicine
[01:38:17.400 --> 01:38:19.800]   in a way that's real and meaningful for this population?
[01:38:19.800 --> 01:38:22.520]   Because you do have a lot of people who plan to retire to the mountains,
[01:38:22.520 --> 01:38:23.960]   and it works fine until your health goes.
[01:38:23.960 --> 01:38:25.720]   You can kind of blame them for it.
[01:38:25.720 --> 01:38:26.760]   Well, but the thing is...
[01:38:26.760 --> 01:38:30.760]   I mean, I'm thinking about retiring at some point and absolutely not going to retire
[01:38:30.760 --> 01:38:33.720]   somewhere where there's no medical care.
[01:38:33.720 --> 01:38:36.280]   But if you have a really small retirement fund...
[01:38:36.280 --> 01:38:37.400]   You don't have a choice?
[01:38:37.400 --> 01:38:37.800]   Yeah.
[01:38:37.800 --> 01:38:40.680]   Because you get priced out of more expensive places with...
[01:38:40.680 --> 01:38:41.320]   Yeah.
[01:38:41.320 --> 01:38:43.240]   With more robust infrastructure.
[01:38:43.240 --> 01:38:44.280]   Okay, all right.
[01:38:44.280 --> 01:38:47.960]   When we're talking about tech, there's one thing to talk about consumer-facing tech
[01:38:47.960 --> 01:38:50.760]   that thrives in really heavily populated areas.
[01:38:50.760 --> 01:38:54.120]   But this most recent trip to last time, I started thinking,
[01:38:54.120 --> 01:38:58.520]   what kind of tech challenges or infrastructure are we not anticipating
[01:38:58.520 --> 01:39:01.480]   for populations that are getting pushed out of these areas,
[01:39:01.480 --> 01:39:02.760]   either by choice or not?
[01:39:02.760 --> 01:39:04.840]   It's spreading a lot faster than we think.
[01:39:04.840 --> 01:39:11.080]   I did a story earlier this week about a stalk that got mugged for its SIM card.
[01:39:11.080 --> 01:39:15.000]   This was a stalk?
[01:39:15.000 --> 01:39:15.560]   Yeah.
[01:39:15.560 --> 01:39:17.480]   Like a flying bird that delivers babies.
[01:39:17.480 --> 01:39:18.040]   Exactly.
[01:39:18.040 --> 01:39:18.280]   Yeah.
[01:39:18.280 --> 01:39:20.600]   That had a SIM card and it got mugged.
[01:39:20.600 --> 01:39:25.640]   We see researchers are now tracking migration patterns of stalks.
[01:39:25.640 --> 01:39:27.480]   And because the mobile network is...
[01:39:27.480 --> 01:39:28.680]   They're giving them cell phones.
[01:39:28.680 --> 01:39:31.800]   Well, basically, they're strapping a little transponder onto the birds back
[01:39:31.800 --> 01:39:34.200]   with a GPS transmitter and a SIM card in it.
[01:39:34.200 --> 01:39:38.040]   And the mobile network is so broad, because these things migrate from Poland
[01:39:38.040 --> 01:39:43.320]   down to Southern Africa, that every time they pass within range of a mobile network,
[01:39:43.320 --> 01:39:46.200]   SIM card could immediately burst out its GPS data.
[01:39:46.200 --> 01:39:49.000]   And the bird was migrating back up to Poland,
[01:39:49.000 --> 01:39:52.200]   was carrying on, got to the Great Nile Valley,
[01:39:52.200 --> 01:39:54.200]   stopped dead for...
[01:39:54.200 --> 01:39:57.240]   Well, it presumes dead for 15 days and then took a
[01:39:57.240 --> 01:39:59.800]   secure 26-mile route to the nearest town.
[01:39:59.800 --> 01:40:01.400]   It was up at a pub.
[01:40:01.400 --> 01:40:07.000]   And the charity then got a $10,000, sorry, $2,500 bill,
[01:40:07.000 --> 01:40:10.600]   where someone had taken the SIM card out and used it to phone around the world.
[01:40:10.600 --> 01:40:14.440]   I mean, the store has better connectivity than 33% of the US.
[01:40:14.440 --> 01:40:14.840]   Exactly.
[01:40:14.840 --> 01:40:16.120]   So you can't blame it, you know?
[01:40:16.120 --> 01:40:16.600]   Yeah.
[01:40:16.600 --> 01:40:19.160]   But it is remarkable how much in the US is not covered.
[01:40:19.160 --> 01:40:21.960]   I mean, I don't know if it's driving through death valley and not getting signal.
[01:40:21.960 --> 01:40:23.640]   I'm thinking, if there's anywhere you want to talk about.
[01:40:23.640 --> 01:40:26.040]   Well, this is why I keep a paper outlist in my car.
[01:40:26.040 --> 01:40:27.240]   It's because I do a lot of...
[01:40:27.240 --> 01:40:27.720]   You never know.
[01:40:27.720 --> 01:40:30.600]   I do a lot of camping and hiking, especially in Northern California,
[01:40:30.600 --> 01:40:31.960]   and coverage is thin.
[01:40:31.960 --> 01:40:35.800]   And the last thing you want is to be stuck without a map or GPS.
[01:40:35.800 --> 01:40:36.280]   Yeah.
[01:40:36.280 --> 01:40:39.160]   And dead tree never runs out of battery as a low as it is.
[01:40:39.160 --> 01:40:39.560]   Exactly.
[01:40:39.560 --> 01:40:39.800]   Yeah.
[01:40:39.800 --> 01:40:44.920]   There's a big story on this, just yesterday, actually, in, I think,
[01:40:44.920 --> 01:40:49.560]   progress, which is a left-leaning publication, but does some interesting stuff.
[01:40:49.560 --> 01:40:54.520]   That this one was called in rural Kentucky, a battle to provide reliable internet,
[01:40:54.520 --> 01:40:56.760]   a story that I found on Twitter, by the way.
[01:40:56.760 --> 01:40:57.720]   [laughter]
[01:40:57.720 --> 01:41:03.400]   But the idea was there are people in parts of rural Kentucky,
[01:41:03.400 --> 01:41:08.440]   which is a very cold-centric county, a country, part of the country.
[01:41:08.440 --> 01:41:11.640]   And they have people that were retraining.
[01:41:11.640 --> 01:41:16.360]   And one of the things that they're retraining is there are these companies now
[01:41:16.360 --> 01:41:19.320]   that will let you do customer service work.
[01:41:19.320 --> 01:41:27.160]   But you do it from home, but you have to have at least 10 megabits down,
[01:41:27.160 --> 01:41:28.920]   which sounds like nothing, right?
[01:41:28.920 --> 01:41:32.680]   It sounds like most of us would be dying if we had 10 megabits.
[01:41:32.680 --> 01:41:35.320]   But in some parts of the country, it's just part of part.
[01:41:35.320 --> 01:41:36.920]   You're showing your internet privilege.
[01:41:36.920 --> 01:41:37.640]   Oh, yes.
[01:41:37.640 --> 01:41:38.120]   Totally.
[01:41:38.120 --> 01:41:39.720]   There's plenty of people on DSL.
[01:41:39.720 --> 01:41:41.240]   There's 6, 5, 4.
[01:41:41.240 --> 01:41:41.720]   Right.
[01:41:41.720 --> 01:41:42.280]   Exactly.
[01:41:42.280 --> 01:41:48.120]   That's my point, is that if you're in a major metropolitan area,
[01:41:48.120 --> 01:41:52.360]   which 50% of the US is, but if you're in the other 50%,
[01:41:53.160 --> 01:41:59.720]   a lot of times you're struggling for just what we would have thought of as a decent connection
[01:41:59.720 --> 01:42:00.760]   five, 10 years ago.
[01:42:00.760 --> 01:42:07.560]   And in this case, to your point, Leo, earlier, it matters for economic activity,
[01:42:07.560 --> 01:42:10.440]   for economic viability, and for being able to get a job.
[01:42:10.440 --> 01:42:13.000]   Because this is a person that essentially training this job,
[01:42:13.000 --> 01:42:13.720]   wants to do the job.
[01:42:13.720 --> 01:42:17.480]   And he's talking about sometimes he basically has to go to McDonald's to get Wi-Fi
[01:42:17.480 --> 01:42:21.800]   and are sitting at gas stations to check his email.
[01:42:21.800 --> 01:42:22.280]   Yeah.
[01:42:22.280 --> 01:42:25.000]   So this also creates huge educational gaps, too.
[01:42:25.000 --> 01:42:25.400]   Yes.
[01:42:25.400 --> 01:42:28.440]   This is why we put Starbucks on every corner.
[01:42:28.440 --> 01:42:29.000]   Yeah.
[01:42:29.000 --> 01:42:31.400]   I did a story about 10 years ago where I was
[01:42:31.400 --> 01:42:34.280]   where the question I wanted to answer was,
[01:42:34.280 --> 01:42:41.400]   we used the TVA and got all of America electricity and indoor plumbing.
[01:42:41.400 --> 01:42:42.680]   You just love the depression.
[01:42:42.680 --> 01:42:45.160]   But don't stop it.
[01:42:45.160 --> 01:42:48.040]   Well, it was a transformative event for the country.
[01:42:48.040 --> 01:42:51.640]   So-- And we decided at that time, I actually bring this up all the time,
[01:42:51.640 --> 01:42:55.240]   in terms of rural electrification, we decided that the rural areas in this country
[01:42:55.240 --> 01:42:56.120]   had to have electricity.
[01:42:56.120 --> 01:42:57.000]   They had to be on that.
[01:42:57.000 --> 01:42:59.320]   They had to have the same level playing field as--
[01:42:59.320 --> 01:43:03.800]   And so the question I was posing to different think tanks and people who study this stuff
[01:43:03.800 --> 01:43:05.720]   is, why don't we do that with broadband?
[01:43:05.720 --> 01:43:05.880]   Yeah.
[01:43:05.880 --> 01:43:08.920]   Why don't we ensure internet access the same way we--
[01:43:08.920 --> 01:43:11.720]   Why don't we treat it like utility, the same way we do telephone access?
[01:43:11.720 --> 01:43:15.960]   Instead, you have companies like Verizon and Comcast lobbying against--
[01:43:15.960 --> 01:43:17.720]   Well, the answer I got from the internet.
[01:43:17.720 --> 01:43:21.480]   The answer I got from a right-wing think tank and also the FCC just struck down--
[01:43:21.480 --> 01:43:23.720]   Actually, is--
[01:43:23.720 --> 01:43:24.680]   The municipal, yeah.
[01:43:24.680 --> 01:43:28.680]   Tip pulling funding for municipal internet for American Indian reservations.
[01:43:28.680 --> 01:43:29.640]   Yep.
[01:43:29.640 --> 01:43:33.640]   But the answer I got from a right-wing think tank was, well, internet speeds keep accelerating.
[01:43:33.640 --> 01:43:37.240]   Why should we bother investing in any internet infrastructure whatsoever
[01:43:37.240 --> 01:43:39.240]   when it's just going to be obsolete in a few years anyway?
[01:43:39.240 --> 01:43:44.760]   So I'll play devil's advocate with them for a minute because knowing some of the people
[01:43:44.760 --> 01:43:48.760]   that are working on municipal and are ready to invest and all of that, and they're like--
[01:43:48.760 --> 01:43:54.520]   Then they look at what's happening in 5G, which is moving a lot faster than we expected.
[01:43:54.520 --> 01:43:58.200]   And it's kind of like, by the time we build this thing out, we're going to be--
[01:43:58.200 --> 01:43:58.840]   Yeah, we're going to be--
[01:43:58.840 --> 01:44:06.120]   We're going to get leapfrogs so quickly that it's a tough argument to make to invest there.
[01:44:06.120 --> 01:44:11.320]   So I understand it from that perspective, but it's one of those things that we have to
[01:44:11.320 --> 01:44:12.200]   figure out a way.
[01:44:12.200 --> 01:44:12.840]   I think to--
[01:44:12.840 --> 01:44:16.360]   Good news, because in 20 states, municipal internet is outlawed.
[01:44:16.360 --> 01:44:20.920]   Thanks to lobbying efforts by the big internet service providers.
[01:44:20.920 --> 01:44:22.520]   We just anti-competitive right in.
[01:44:22.520 --> 01:44:23.080]   Exactly.
[01:44:23.080 --> 01:44:25.080]   It's the other thing that I heard.
[01:44:25.080 --> 01:44:28.600]   It started in the Keystone state because that's where Comcast is.
[01:44:28.600 --> 01:44:32.520]   And what's interesting is in the states where a lot of this is outlawed, those are heavy ag states,
[01:44:32.520 --> 01:44:38.680]   and agriculture is depending increasingly on big data, especially for weather, especially for
[01:44:38.680 --> 01:44:42.040]   planting, especially for when to allocate water resources.
[01:44:42.040 --> 01:44:44.120]   There are tractors that have this stuff built in there.
[01:44:44.120 --> 01:44:45.240]   Oh, yeah, most of them do.
[01:44:45.240 --> 01:44:45.720]   Yeah.
[01:44:45.720 --> 01:44:47.640]   You're native state Tennessee.
[01:44:47.640 --> 01:44:52.680]   Chattanooga, very famously, had a public infrastructure, public internet's infrastructure.
[01:44:52.680 --> 01:44:56.040]   And as a result, you have the worst laws of all.
[01:44:56.040 --> 01:44:57.800]   That's not-- I'm in Kentucky.
[01:44:57.800 --> 01:44:58.360]   Kentucky?
[01:44:58.360 --> 01:44:59.240]   All right, Tennessee.
[01:44:59.240 --> 01:44:59.720]   Kentucky.
[01:44:59.720 --> 01:45:01.240]   Oh my god, that's a fight and words.
[01:45:01.240 --> 01:45:06.520]   But I mean, I'm not from Kentucky, but I live in Louisville, Kentucky, which is a great place.
[01:45:06.520 --> 01:45:08.520]   I was thinking you're a friend of mine.
[01:45:08.520 --> 01:45:12.120]   I was the first time for DerbyCon last year, and it was a fantastic place to live.
[01:45:12.120 --> 01:45:14.280]   Yeah, DerbyCon, very big there.
[01:45:14.280 --> 01:45:16.920]   Yeah, and it's shocking to me that Virginia is on the list.
[01:45:16.920 --> 01:45:21.880]   But it is, to the point you and I were just saying, it's anti-competitive.
[01:45:21.880 --> 01:45:26.920]   If you want competition, and if a metro area like Chattanooga wants to build its own internet,
[01:45:26.920 --> 01:45:30.600]   because a bunch of fibers have been laid there, there's a bunch of dark fibers sitting around,
[01:45:30.600 --> 01:45:33.160]   then by all means, they should be able to do it.
[01:45:33.160 --> 01:45:38.040]   I think that the argument is that, well, if they do it, then they can give themselves
[01:45:38.040 --> 01:45:40.040]   breaks and they can cut the price.
[01:45:40.040 --> 01:45:43.960]   Because the major telcos receive no subsidies whatsoever.
[01:45:43.960 --> 01:45:45.800]   Right.
[01:45:45.800 --> 01:45:48.920]   And so it's different kinds of anti-competitive, right?
[01:45:48.920 --> 01:45:50.440]   It is what we're arguing.
[01:45:50.440 --> 01:45:56.280]   I'm also slightly worried about the 5G spreading faster argument, because I've seen this with 4G when--
[01:45:56.280 --> 01:45:56.760]   Yeah.
[01:45:56.760 --> 01:45:58.360]   You remember the 4G standards came up?
[01:45:58.360 --> 01:46:00.840]   It was going to be, well, it's LTE, but it's also Ymax.
[01:46:00.840 --> 01:46:02.600]   It's also enhanced through G.
[01:46:02.600 --> 01:46:07.240]   And with the first round of 5G things we're coming look at, it's not true 5G.
[01:46:07.240 --> 01:46:10.360]   It's basically just slightly enhanced for G.
[01:46:10.360 --> 01:46:13.720]   And the telcos are using this and go, well, you can get wireless.
[01:46:13.720 --> 01:46:16.040]   So why do we need to put lines in?
[01:46:16.040 --> 01:46:20.680]   At the end of the day, it comes down to the National Highways Project or something like that.
[01:46:20.680 --> 01:46:24.920]   When you look at countries like Korea and Finland and other countries around the world,
[01:46:24.920 --> 01:46:27.560]   which basically the government said, look, this is coming.
[01:46:27.560 --> 01:46:31.800]   We'll pay to put some fiber in there, and you can have open competition over that.
[01:46:31.800 --> 01:46:34.040]   And this is what Google Fiber was originally about.
[01:46:34.040 --> 01:46:39.800]   And it's just being slowly and remorselessly shut down by the big players, because they don't
[01:46:39.800 --> 01:46:40.520]   want competition.
[01:46:40.520 --> 01:46:48.920]   With the US being so big, though, it's tough and so spread out, you know, and less dense.
[01:46:48.920 --> 01:46:51.400]   It does create as a big part of a problem.
[01:46:51.400 --> 01:46:54.120]   I think in 100 years from now, it's going to be academic.
[01:46:55.160 --> 01:47:01.720]   But it is tough because it's so unprofitable to lay that fiber.
[01:47:01.720 --> 01:47:08.920]   It's more profitable, though, to lay fiber, run fiber, a bunch of fiber lines, to sell towers,
[01:47:08.920 --> 01:47:10.040]   obviously, than it is.
[01:47:10.040 --> 01:47:13.560]   But the thing you have to remember, and I was schooled in this by Stacey Higginbotham,
[01:47:13.560 --> 01:47:17.880]   is if 5G, at least the 5G technologies we're talking about right now,
[01:47:17.880 --> 01:47:20.040]   require lots more sites and lots more back.
[01:47:20.040 --> 01:47:20.760]   Yeah.
[01:47:20.760 --> 01:47:21.560]   So in fact--
[01:47:21.560 --> 01:47:22.600]   They don't go as far.
[01:47:22.600 --> 01:47:23.160]   They don't go as far.
[01:47:23.160 --> 01:47:27.720]   So there is, in fact, a much bigger demand for fiber in the ground.
[01:47:27.720 --> 01:47:29.560]   So this is interesting.
[01:47:29.560 --> 01:47:34.120]   I've had an interesting conversation with some wireless engineers about this,
[01:47:34.120 --> 01:47:36.440]   because I think that they've designed it.
[01:47:36.440 --> 01:47:38.040]   This is only a theory.
[01:47:38.040 --> 01:47:41.800]   I think they've designed it in one sense, that it's not just physics involved,
[01:47:41.800 --> 01:47:45.160]   but they've also designed it in one sense to have to have more--
[01:47:45.160 --> 01:47:45.960]   Or meshes.
[01:47:45.960 --> 01:47:49.080]   --more sites for one, for backup.
[01:47:49.080 --> 01:47:52.840]   Also, too, because you're going to have so many more devices on those towers, right?
[01:47:52.840 --> 01:47:53.160]   Yeah.
[01:47:53.160 --> 01:47:54.440]   You're just not going to be able to put--
[01:47:54.440 --> 01:47:55.400]   But that's the number.
[01:47:55.400 --> 01:48:00.520]   That's exactly the problem, which is the telcos design for dense urban areas.
[01:48:00.520 --> 01:48:02.760]   They don't design for rural areas.
[01:48:02.760 --> 01:48:05.400]   So that means, of course, San Francisco's going to get a 5G,
[01:48:05.400 --> 01:48:08.680]   but last in National Park is not going to ever get 5G.
[01:48:08.680 --> 01:48:13.000]   So that really is the argument that you've got to allow municipalities,
[01:48:13.000 --> 01:48:15.640]   underserved municipalities to do their own--
[01:48:15.640 --> 01:48:17.480]   Look, Craig, if I'm wrong, I mean, I wasn't--
[01:48:17.480 --> 01:48:18.680]   Can't wait for 5G.
[01:48:18.680 --> 01:48:19.400]   It's not coming to work.
[01:48:19.400 --> 01:48:23.400]   In the mid '90s, didn't the major telcos get a massive government tax--
[01:48:23.400 --> 01:48:25.080]   Oh, yeah, that's right, offshore.
[01:48:25.080 --> 01:48:26.040]   '96.
[01:48:26.040 --> 01:48:27.240]   --to fiber up the country.
[01:48:27.240 --> 01:48:27.960]   Yeah.
[01:48:27.960 --> 01:48:29.480]   I think we're still waiting on that one.
[01:48:29.480 --> 01:48:33.000]   Well, there's a lot of that fiber that got laid and has still not been used.
[01:48:33.000 --> 01:48:33.960]   There's a lot of dark fiber.
[01:48:33.960 --> 01:48:36.680]   So that could work in our favor for 5G, right?
[01:48:36.680 --> 01:48:39.560]   Because a lot of that fiber was put in the ground.
[01:48:39.560 --> 01:48:39.960]   In case--
[01:48:39.960 --> 01:48:43.240]   And serving densely popular areas, though, for the most part, right?
[01:48:43.240 --> 01:48:43.800]   Right.
[01:48:43.800 --> 01:48:44.600]   And so--
[01:48:44.600 --> 01:48:46.440]   We built the Transpacific Railroach.
[01:48:46.440 --> 01:48:47.440]   Right, right, right.
[01:48:47.440 --> 01:48:49.280]   Surely we can get the Transpacific--
[01:48:49.280 --> 01:48:52.200]   The Share I believe was immigrants that built the Transpacific Railroads.
[01:48:52.200 --> 01:48:53.040]   So we're at it.
[01:48:53.040 --> 01:48:53.240]   We're at it.
[01:48:53.240 --> 01:48:54.240]   We're at it.
[01:48:54.240 --> 01:48:55.240]   [LAUGHTER]
[01:48:55.240 --> 01:48:56.240]   Let's--
[01:48:56.240 --> 01:48:57.240]   [LAUGHTER]
[01:48:57.240 --> 01:48:58.240]   Sorry to keep up with this.
[01:48:58.240 --> 01:49:00.720]   Well, these days, you know, I promise you good news,
[01:49:00.720 --> 01:49:02.120]   and I will have it when we come back.
[01:49:02.120 --> 01:49:04.440]   But first a word--
[01:49:04.440 --> 01:49:05.440]   Wow.
[01:49:05.440 --> 01:49:06.760]   --from Slack.
[01:49:06.760 --> 01:49:07.720]   Slack!
[01:49:07.720 --> 01:49:08.520]   I love Slack.
[01:49:08.520 --> 01:49:09.400]   Who doesn't love Slack?
[01:49:09.400 --> 01:49:13.160]   It's funny because Stuart Butterfield, who created Flickr--
[01:49:13.160 --> 01:49:16.320]   remember, it was originally going to be a massively online game.
[01:49:16.320 --> 01:49:17.880]   They pivoted the Flickr.
[01:49:17.880 --> 01:49:19.320]   Created Flickr, sold the Yahoo!
[01:49:19.320 --> 01:49:20.640]   Stuart realized quickly Yahoo!
[01:49:20.640 --> 01:49:22.080]   was not going to be a good home.
[01:49:22.080 --> 01:49:22.920]   Went off.
[01:49:22.920 --> 01:49:28.560]   Created Slack, created something that is completely viral in business.
[01:49:28.560 --> 01:49:32.440]   Once a business started using Slack, everybody wants to use it.
[01:49:32.440 --> 01:49:35.880]   It's because it keeps the right people in your team in the loop.
[01:49:35.880 --> 01:49:38.480]   The information you need is always at your fingertips.
[01:49:38.480 --> 01:49:40.160]   It's fun to use.
[01:49:40.160 --> 01:49:43.320]   It really fosters teamwork.
[01:49:43.320 --> 01:49:46.160]   And the channels let you organize conversations
[01:49:46.160 --> 01:49:49.320]   and information around projects, around offices, around teams.
[01:49:49.320 --> 01:49:51.440]   Everything you need to work on is in one place.
[01:49:51.440 --> 01:49:53.360]   It's faster and easier to get things done.
[01:49:53.360 --> 01:49:57.040]   It integrates with every possible technology
[01:49:57.040 --> 01:50:00.640]   that you're using in your company, whether it's Salesforce, or Zendesk,
[01:50:00.640 --> 01:50:02.480]   or Jira, or Google Drive.
[01:50:02.480 --> 01:50:05.120]   Dragon dropped files right into Slack.
[01:50:05.120 --> 01:50:08.240]   Slack will work with more than 1,000 apps.
[01:50:08.240 --> 01:50:10.840]   And that number goes up all the time because, guess what?
[01:50:10.840 --> 01:50:12.400]   Slack's got a great API.
[01:50:12.400 --> 01:50:14.000]   Developers love Slack.
[01:50:14.000 --> 01:50:16.240]   They make sure it works.
[01:50:16.240 --> 01:50:20.040]   I mean, I remember our Jeopardy, Alex Trebek Slack bot.
[01:50:20.040 --> 01:50:21.000]   He was great fun.
[01:50:21.000 --> 01:50:24.120]   You could always ask him and he'd give you a question.
[01:50:24.120 --> 01:50:25.880]   Slack's fun as well as productive.
[01:50:25.880 --> 01:50:27.160]   Reduce emails.
[01:50:27.160 --> 01:50:28.080]   Get rid of emails.
[01:50:28.080 --> 01:50:30.600]   Streamlining your team's communication with Slack.
[01:50:30.600 --> 01:50:33.360]   It connects the tools and services you need into one place.
[01:50:33.360 --> 01:50:36.480]   Organize your team with real-time messaging, video, or voice calls.
[01:50:36.480 --> 01:50:38.240]   Yeah, they got voice calls too now.
[01:50:38.240 --> 01:50:40.360]   Group files sharing, searchable archives.
[01:50:40.360 --> 01:50:42.320]   That's one other thing is your corporate history
[01:50:42.320 --> 01:50:43.120]   is never lost.
[01:50:43.120 --> 01:50:45.200]   It's all in there.
[01:50:45.200 --> 01:50:47.360]   With Slack, your team is better connected.
[01:50:47.360 --> 01:50:50.000]   And of course, with mobile apps on iOS and Android, desktop apps
[01:50:50.000 --> 01:50:51.720]   do, everything syncs seamlessly.
[01:50:51.720 --> 01:50:55.240]   You pick up where you left off no matter where you are.
[01:50:55.240 --> 01:50:57.640]   Slack is 100% secure.
[01:50:57.640 --> 01:50:59.400]   So privacy guaranteed.
[01:50:59.400 --> 01:51:00.480]   SLACK.
[01:51:00.480 --> 01:51:02.200]   You know, get it.
[01:51:02.200 --> 01:51:05.280]   Slack.com.
[01:51:05.280 --> 01:51:07.400]   Look at all the companies that work with Slack.
[01:51:07.400 --> 01:51:09.120]   You Slack.
[01:51:09.120 --> 01:51:11.320]   Everybody uses Slack.
[01:51:11.320 --> 01:51:12.320]   So it's--
[01:51:12.320 --> 01:51:13.320]   Well, we do.
[01:51:13.320 --> 01:51:14.160]   Do you use Slack?
[01:51:14.160 --> 01:51:14.680]   Yes.
[01:51:14.680 --> 01:51:15.200]   Yes.
[01:51:15.200 --> 01:51:16.200]   Love it.
[01:51:16.200 --> 01:51:16.880]   Slack.com.
[01:51:16.880 --> 01:51:18.680]   Love the Slack.
[01:51:18.680 --> 01:51:22.080]   It's astonishing quite how late it took some company--
[01:51:22.080 --> 01:51:23.560]   I worked with my previous employer.
[01:51:23.560 --> 01:51:25.160]   They were still using Yahoo! Messenger.
[01:51:25.160 --> 01:51:26.040]   Oh, good Lord.
[01:51:26.040 --> 01:51:26.560]   Wow.
[01:51:26.560 --> 01:51:28.200]   It's like the 1990s again.
[01:51:28.200 --> 01:51:29.840]   You know.
[01:51:29.840 --> 01:51:30.440]   Somebody has built, though.
[01:51:30.440 --> 01:51:32.800]   All of the promise of tech, none of the disappointments.
[01:51:32.800 --> 01:51:33.600]   Oh, I know.
[01:51:33.600 --> 01:51:35.440]   It was such a simpler time.
[01:51:35.440 --> 01:51:37.760]   We read the Hacker Manifesto now, and it just looks like it's
[01:51:37.760 --> 01:51:40.200]   so hopelessly optimistic in some areas.
[01:51:40.200 --> 01:51:42.800]   Have you ever revisited Neil Stivensen's
[01:51:42.800 --> 01:51:44.400]   in the future?
[01:51:44.400 --> 01:51:45.720]   In the beginning was the command line?
[01:51:45.720 --> 01:51:46.720]   Oh, yes.
[01:51:46.720 --> 01:51:48.360]   It was classic.
[01:51:48.360 --> 01:51:52.960]   Somebody has created a AM server.
[01:51:52.960 --> 01:51:56.920]   You have to download the old AOL Instant Messenger client.
[01:51:56.920 --> 01:51:57.920]   You can log out of the server.
[01:51:57.920 --> 01:51:59.520]   It's got the old interface.
[01:51:59.520 --> 01:52:00.880]   It doesn't preserve your account,
[01:52:00.880 --> 01:52:02.640]   but you can log into it, create an instant.
[01:52:02.640 --> 01:52:05.600]   I think it's not Slack.
[01:52:05.600 --> 01:52:06.120]   No.
[01:52:06.120 --> 01:52:08.880]   But if you have some nostalgia for keywords--
[01:52:08.880 --> 01:52:11.000]   Oh, my favorite nostalgia.
[01:52:11.000 --> 01:52:12.200]   I'm trying to find it now.
[01:52:12.200 --> 01:52:14.120]   Yeah, here we are.
[01:52:14.120 --> 01:52:19.080]   This is a guy who's running FileMaker Pro Server version 3,
[01:52:19.080 --> 01:52:23.520]   running on Mac OS 9.0.4, which is running on a PowerMac
[01:52:23.520 --> 01:52:26.640]   emulator, which is running on a CentOS 4.5, which
[01:52:26.640 --> 01:52:28.640]   is running on a VMware virtual machine.
[01:52:28.640 --> 01:52:30.920]   It's like the ultimate Russian doll of software.
[01:52:30.920 --> 01:52:31.960]   And you love it to be.
[01:52:31.960 --> 01:52:34.520]   It's probably faster than FileMaker was me.
[01:52:34.520 --> 01:52:36.520]   I know.
[01:52:36.520 --> 01:52:37.800]   Amazon Prime Day.
[01:52:37.800 --> 01:52:38.800]   Here's the good news.
[01:52:38.800 --> 01:52:40.760]   It's coming July 16.
[01:52:40.760 --> 01:52:42.400]   Are you excited?
[01:52:42.400 --> 01:52:45.680]   Oh, yet another marketing house.
[01:52:45.680 --> 01:52:46.960]   It's interesting how--
[01:52:46.960 --> 01:52:48.960]   Was it with Black Friday and Amazon Prime?
[01:52:48.960 --> 01:52:50.680]   When did these days kick off in this country?
[01:52:50.680 --> 01:52:52.480]   Well, I've noticed something.
[01:52:52.480 --> 01:52:54.320]   Everybody's having sales in July now.
[01:52:54.320 --> 01:52:56.880]   I think we have a new sale period.
[01:52:56.880 --> 01:52:57.840]   It's July, right?
[01:52:57.840 --> 01:52:58.760]   Fourth of July.
[01:52:58.760 --> 01:53:02.920]   The National Retail Federation tracks sales trends.
[01:53:02.920 --> 01:53:04.480]   That's basically what they do, right?
[01:53:04.480 --> 01:53:08.000]   And back to school, used to be this big, spiky period
[01:53:08.000 --> 01:53:09.560]   towards the end of the--
[01:53:09.560 --> 01:53:12.640]   And what they found is actually thanks to Prime Day
[01:53:12.640 --> 01:53:14.880]   and all of the other retailers who are trying to draft
[01:53:14.880 --> 01:53:17.480]   on that energy, the back to school period
[01:53:17.480 --> 01:53:20.520]   has actually moved to the point where people are basically
[01:53:20.520 --> 01:53:21.560]   like their kids get out of school.
[01:53:21.560 --> 01:53:22.920]   They clean up the backpack.
[01:53:22.920 --> 01:53:23.880]   They start looking.
[01:53:23.880 --> 01:53:24.400]   Start now.
[01:53:24.400 --> 01:53:26.120]   And one of the drivers of that is technology,
[01:53:26.120 --> 01:53:29.000]   because more and more children are being expected
[01:53:29.000 --> 01:53:31.200]   to have computers or tablets.
[01:53:31.200 --> 01:53:32.200]   And when you go to college, you're
[01:53:32.200 --> 01:53:33.720]   usually expected to buy a machine.
[01:53:33.720 --> 01:53:36.840]   And so these sales in the middle of the summer
[01:53:36.840 --> 01:53:39.280]   are how a lot of budget conscious parents manage
[01:53:39.280 --> 01:53:42.520]   to hit the school supply lists by the machines that their kids
[01:53:42.520 --> 01:53:44.840]   need and stock up for the school year.
[01:53:44.840 --> 01:53:47.160]   I'm more slightly suspicious about some of these things,
[01:53:47.160 --> 01:53:49.080]   because it does seem that some stores in particular
[01:53:49.080 --> 01:53:50.640]   will jack their prices up for a month
[01:53:50.640 --> 01:53:52.800]   and then dramatically cut them one than the sale.
[01:53:52.800 --> 01:53:53.160]   Oh, yeah.
[01:53:53.160 --> 01:53:55.600]   It's a tried and true American retail.
[01:53:55.600 --> 01:53:57.680]   Well, the same thing happens in the UK, to be honest,
[01:53:57.680 --> 01:53:58.760]   but we just have fewer sales.
[01:53:58.760 --> 01:54:00.960]   We have the New Year's Day of Sales, and that's really it.
[01:54:00.960 --> 01:54:01.560]   Boxing Day?
[01:54:01.560 --> 01:54:02.760]   Do you still have a sale today?
[01:54:02.760 --> 01:54:04.080]   It's shifted to Boxing Day.
[01:54:04.080 --> 01:54:05.880]   It used to be that people would queue up
[01:54:05.880 --> 01:54:09.200]   camp outside shops like Harrods for two days
[01:54:09.200 --> 01:54:11.160]   before the New Year's Day of Sales came in.
[01:54:11.160 --> 01:54:15.040]   And their intents and their British were getting
[01:54:15.040 --> 01:54:17.960]   through this boiling tea on a thermos type thing.
[01:54:17.960 --> 01:54:21.000]   It was a tremendously encouraging ritual,
[01:54:21.000 --> 01:54:25.760]   but now the Black Tuesday seems to be moving over to the US.
[01:54:25.760 --> 01:54:30.240]   But it's just a bit Black Tuesday.
[01:54:30.240 --> 01:54:31.240]   What do you call it?
[01:54:31.240 --> 01:54:31.960]   Black Tuesday.
[01:54:31.960 --> 01:54:33.000]   So there's Black Friday.
[01:54:33.000 --> 01:54:34.160]   There's Cyber Monday.
[01:54:34.160 --> 01:54:36.200]   There's now Giving Tuesday.
[01:54:36.200 --> 01:54:37.040]   Giving Tuesday.
[01:54:37.040 --> 01:54:37.560]   When's that?
[01:54:37.560 --> 01:54:38.560]   There's Giving Tuesday.
[01:54:38.560 --> 01:54:40.000]   Is that after Cyber Monday?
[01:54:40.000 --> 01:54:40.560]   Yes.
[01:54:40.560 --> 01:54:42.520]   And there's Cyber Monday.
[01:54:42.520 --> 01:54:43.360]   There's Giving Tuesday.
[01:54:43.360 --> 01:54:46.080]   There's a green shopping day now that--
[01:54:46.080 --> 01:54:49.200]   And every single day, the number one shopping day of the year.
[01:54:49.200 --> 01:54:50.480]   Thanks to China.
[01:54:50.480 --> 01:54:51.480]   Yes, true.
[01:54:51.480 --> 01:54:56.760]   It's been interesting because there's been a rise in events
[01:54:56.760 --> 01:54:58.040]   like we just talked about with this.
[01:54:58.040 --> 01:55:00.200]   And then more and more brands are rolling things out, too.
[01:55:00.200 --> 01:55:03.120]   And the example J. Crew called March 31st Stripes Day.
[01:55:03.120 --> 01:55:06.280]   And aggressively promoted its striped stuff.
[01:55:06.280 --> 01:55:07.280]   But much of this is a desperation.
[01:55:07.280 --> 01:55:09.360]   Wayfair has done wayday.
[01:55:09.360 --> 01:55:13.280]   Is it desperation or is it actually good marketing?
[01:55:13.280 --> 01:55:13.880]   I don't know.
[01:55:13.880 --> 01:55:14.360]   Yeah.
[01:55:14.360 --> 01:55:16.400]   I went on a bit of a Twitter rant about this today
[01:55:16.400 --> 01:55:18.760]   because obviously when you go into the Twitter front page,
[01:55:18.760 --> 01:55:21.600]   you see the trending articles of the thing.
[01:55:21.600 --> 01:55:26.480]   And it seems like every day is now a something-something day.
[01:55:26.480 --> 01:55:26.920]   So it was--
[01:55:26.920 --> 01:55:27.200]   Oh, yeah.
[01:55:27.200 --> 01:55:28.400]   Why are you on Twitter?
[01:55:28.400 --> 01:55:29.720]   I've been telling you.
[01:55:29.720 --> 01:55:33.160]   But also, for example, yeah, July 6th was National Fried Chicken
[01:55:33.160 --> 01:55:35.920]   Day, but also International Kissing Day,
[01:55:35.920 --> 01:55:37.520]   to which her responder, they can kiss me up.
[01:55:37.520 --> 01:55:37.800]   Oh, I missed it.
[01:55:37.800 --> 01:55:38.320]   I missed it.
[01:55:38.320 --> 01:55:38.720]   Well, there you go.
[01:55:38.720 --> 01:55:41.280]   Delicious chicken skin.
[01:55:41.280 --> 01:55:43.000]   What's it with fried chicken in this country?
[01:55:43.000 --> 01:55:43.560]   It's just--
[01:55:43.560 --> 01:55:44.560]   It's the skin.
[01:55:44.560 --> 01:55:46.760]   The chicken itself, I could honestly care less of up in this.
[01:55:46.760 --> 01:55:48.520]   I know, because you get this great skin,
[01:55:48.520 --> 01:55:51.240]   but it's over to dry, chewy chicken.
[01:55:51.240 --> 01:55:52.680]   You have to burn the chicken first.
[01:55:52.680 --> 01:55:54.800]   You have to soak it in buttermilk for at least 24 hours.
[01:55:54.800 --> 01:55:56.280]   And that way, you look up.
[01:55:56.280 --> 01:55:57.800]   Wow, not brining it buttermilk.
[01:55:57.800 --> 01:55:58.320]   Yeah.
[01:55:58.320 --> 01:55:59.040]   Interesting.
[01:55:59.040 --> 01:56:00.040]   Never done that one.
[01:56:00.040 --> 01:56:01.360]   Yeah, soak it in buttermilk for 24 hours first.
[01:56:01.360 --> 01:56:04.160]   Then you dredge it in flour, then you dip it in eggs,
[01:56:04.160 --> 01:56:05.240]   and then you dredge it again.
[01:56:05.240 --> 01:56:06.000]   You double dredge.
[01:56:06.000 --> 01:56:06.840]   Are you a double dredger?
[01:56:06.840 --> 01:56:08.360]   Yes, and don't forget the spices, too.
[01:56:08.360 --> 01:56:09.520]   You don't just do flour.
[01:56:09.520 --> 01:56:11.720]   21 herbs and spices.
[01:56:11.720 --> 01:56:16.040]   Didn't you love that when the KFC Twitter feed
[01:56:16.040 --> 01:56:16.800]   was followed by--
[01:56:16.800 --> 01:56:17.720]   Oh, yes.
[01:56:17.720 --> 01:56:19.120]   They were following exactly the herb.
[01:56:19.120 --> 01:56:20.200]   21 people named--
[01:56:20.200 --> 01:56:20.840]   I was very--
[01:56:20.840 --> 01:56:22.760]   --in social media, my love to sing.
[01:56:22.760 --> 01:56:24.920]   That was really quite good.
[01:56:24.920 --> 01:56:27.960]   So Netflix at its last shareholders event.
[01:56:27.960 --> 01:56:28.760]   Oh, this is--
[01:56:28.760 --> 01:56:30.960]   Said we're going to spend $8 billion on new content.
[01:56:30.960 --> 01:56:31.280]   Yeah.
[01:56:31.280 --> 01:56:33.000]   And started, by the way, a bidding war.
[01:56:33.000 --> 01:56:34.760]   Apple said, no, we're going to spend a billion--
[01:56:34.760 --> 01:56:36.360]   and everybody's trying to buy stuff.
[01:56:36.360 --> 01:56:39.160]   Amazon bought Lord of the Rings for almost a billion dollars.
[01:56:39.160 --> 01:56:40.000]   Just the rights.
[01:56:40.000 --> 01:56:40.360]   Yeah.
[01:56:40.360 --> 01:56:42.040]   Who put the cost of making?
[01:56:42.040 --> 01:56:45.360]   Amazon-- I mean, Netflix has now said their budget for 2018
[01:56:45.360 --> 01:56:49.360]   is $13 billion.
[01:56:49.360 --> 01:56:52.240]   That's a 62% bloat over what they promised.
[01:56:52.240 --> 01:56:52.680]   It's worth--
[01:56:52.680 --> 01:56:55.040]   Well, do you think they're doing more stuff?
[01:56:55.040 --> 01:56:56.720]   Or do you think it just cost more?
[01:56:56.720 --> 01:56:59.920]   There's never been a better time to be a content producer
[01:56:59.920 --> 01:57:00.920]   in the Hollywood.
[01:57:00.920 --> 01:57:04.120]   I mean, people that are writers there
[01:57:04.120 --> 01:57:08.280]   that used to just be dying to find anybody to do their idea,
[01:57:08.280 --> 01:57:12.120]   I mean, they will literally say an idea to a producer,
[01:57:12.120 --> 01:57:13.800]   and they're like, oh, just write it down.
[01:57:13.800 --> 01:57:14.480]   Let me get my checkbook.
[01:57:14.480 --> 01:57:15.400]   Yeah, write it down.
[01:57:15.400 --> 01:57:16.760]   And it emails send it to me.
[01:57:16.760 --> 01:57:17.760]   It's catty-shot me.
[01:57:17.760 --> 01:57:18.600]   It meets handmaids.
[01:57:18.600 --> 01:57:20.280]   Yeah, exactly.
[01:57:20.280 --> 01:57:21.480]   So they've got three four--
[01:57:21.480 --> 01:57:24.080]   their next three four five ideas already sold
[01:57:24.080 --> 01:57:26.480]   before they've even written the scripts and everything.
[01:57:26.480 --> 01:57:29.720]   So look, you've learned to be a script writer.
[01:57:29.720 --> 01:57:31.120]   Well, it'll be gone by that time.
[01:57:31.120 --> 01:57:31.960]   The paragraph--
[01:57:31.960 --> 01:57:33.120]   It'll be over the all the money that's going to be over by that.
[01:57:33.120 --> 01:57:35.280]   So the paragraph in this story I want to call out
[01:57:35.280 --> 01:57:36.640]   is they talk about Netflix is going
[01:57:36.640 --> 01:57:41.800]   to be releasing 82 films this year compared to the 23 Warner
[01:57:41.800 --> 01:57:44.960]   Brothers just putting out and the 10 Disney films it's putting out.
[01:57:44.960 --> 01:57:47.320]   What they don't say in here with this
[01:57:47.320 --> 01:57:49.480]   is that they're not making it with Warner Brothers
[01:57:49.480 --> 01:57:51.320]   or Disney-style budgets.
[01:57:51.320 --> 01:57:54.000]   But there has been something that screenwriters have actually
[01:57:54.000 --> 01:57:56.040]   talked about in the Hollywood Reporter for the last few years
[01:57:56.040 --> 01:57:58.880]   about how the middle market of movies has been squeezed out
[01:57:58.880 --> 01:58:01.000]   thanks to the demand for blockbusters.
[01:58:01.000 --> 01:58:04.000]   And what Netflix is doing is it's basically giving filmmakers
[01:58:04.000 --> 01:58:06.920]   a space to make those mid-market movies that we used to all
[01:58:06.920 --> 01:58:09.600]   see in the '80s and '90s that had been pushed out
[01:58:09.600 --> 01:58:12.480]   of the box office in recent years.
[01:58:12.480 --> 01:58:14.760]   We were watching The Princess Bride this last week.
[01:58:14.760 --> 01:58:15.520]   And I was like--
[01:58:15.520 --> 01:58:16.480]   Classic.
[01:58:16.480 --> 01:58:17.440]   But you look at that.
[01:58:17.440 --> 01:58:19.120]   It was a fairly low budget movie.
[01:58:19.120 --> 01:58:22.960]   And it would not be made by a major studio today
[01:58:22.960 --> 01:58:25.000]   because it just wouldn't.
[01:58:25.000 --> 01:58:28.480]   I'm just hoping this blockbuster trend that we've seen
[01:58:28.480 --> 01:58:30.480]   is actually going to be on the way out.
[01:58:30.480 --> 01:58:33.040]   I mean, we've seen solo diners backside.
[01:58:33.040 --> 01:58:34.880]   I wasn't that impressed with the last Marvel,
[01:58:34.880 --> 01:58:36.640]   the last Avengers film.
[01:58:36.640 --> 01:58:40.840]   Maybe we could get back to those kind of mid-budget,
[01:58:40.840 --> 01:58:44.120]   intelligently written, not relying on the massive marketing
[01:58:44.120 --> 01:58:44.640]   budget.
[01:58:44.640 --> 01:58:45.680]   Those will be in Netflix.
[01:58:45.680 --> 01:58:46.760]   Yeah, but those will be in Netflix.
[01:58:46.760 --> 01:58:47.280]   Yeah, that's where that's--
[01:58:47.280 --> 01:58:50.240]   You have to have some spectacle where people aren't going to go, right?
[01:58:50.240 --> 01:58:52.560]   George Lucas said about 10 years ago he was like,
[01:58:52.560 --> 01:58:55.280]   it's not going to be unreasonable to spend $50 from movie
[01:58:55.280 --> 01:58:59.240]   ticket because you're going to be buying the immersive full-on--
[01:58:59.240 --> 01:59:04.120]   you know, surround screen, massive sound system, premium energy.
[01:59:04.120 --> 01:59:05.880]   He's like, this is what Broadway musicals are now.
[01:59:05.880 --> 01:59:06.240]   It's just--
[01:59:06.240 --> 01:59:10.240]   And also increasingly, I mean, our local cinema now
[01:59:10.240 --> 01:59:13.440]   has comfy seats, drinks service, and food service.
[01:59:13.440 --> 01:59:15.320]   And I think that's the way cinemas are going to go.
[01:59:15.320 --> 01:59:18.280]   Because it's just sitting there, crabting,
[01:59:18.280 --> 01:59:19.680]   watching a tiny screen at the end of it.
[01:59:19.680 --> 01:59:21.120]   I can do that my laptop.
[01:59:21.120 --> 01:59:23.720]   You know, why not go to the cinema and have a drink, have a nice meal,
[01:59:23.720 --> 01:59:25.520]   and watch a film in full immersive reality?
[01:59:25.520 --> 01:59:28.320]   This is where my SFB privilege shows because our local--
[01:59:28.320 --> 01:59:30.040]   our local and our locally owned theater
[01:59:30.040 --> 01:59:33.200]   does like a 1980s series where like every Tuesday night,
[01:59:33.200 --> 01:59:35.280]   they show a different 1980s film,
[01:59:35.280 --> 01:59:37.520]   and they have an MC come out and do trivia,
[01:59:37.520 --> 01:59:39.040]   and they give away posters.
[01:59:39.040 --> 01:59:43.320]   And they've turned it into a whole social event.
[01:59:43.320 --> 01:59:44.400]   Yeah, how's it in Kentucky?
[01:59:44.400 --> 01:59:44.800]   I mean, it's--
[01:59:44.800 --> 01:59:45.560]   Yeah, in Louisville.
[01:59:45.560 --> 01:59:47.000]   So it's the same way.
[01:59:47.000 --> 01:59:49.080]   It's interesting because there's a bunch of different kinds
[01:59:49.080 --> 01:59:49.600]   of theaters.
[01:59:49.600 --> 01:59:52.880]   There's like-- some theaters have ripped out the 300 seat
[01:59:52.880 --> 01:59:56.400]   theaters and put in 75 seats, you know, comfortable seats.
[01:59:56.400 --> 01:59:58.600]   That's what's happened here, all the theaters today.
[01:59:58.600 --> 01:59:59.680]   Yeah, pretty much.
[01:59:59.680 --> 02:00:02.400]   So the big-- the ones that had the blockbusters
[02:00:02.400 --> 02:00:03.600]   have all done that.
[02:00:03.600 --> 02:00:04.120]   Only different--
[02:00:04.120 --> 02:00:04.680]   That's interesting.
[02:00:04.680 --> 02:00:05.520]   That's not just here.
[02:00:05.520 --> 02:00:06.200]   Yeah, yeah.
[02:00:06.200 --> 02:00:08.720]   And then there's other ones that have gone the way of--
[02:00:08.720 --> 02:00:12.160]   they show more indie films, and they make it more of an experience.
[02:00:12.160 --> 02:00:13.600]   They bring people--
[02:00:13.600 --> 02:00:15.880]   they bring like guest speakers in.
[02:00:15.880 --> 02:00:16.320]   And then--
[02:00:16.320 --> 02:00:16.880]   I'll call it that.
[02:00:16.880 --> 02:00:17.240]   And then they--
[02:00:17.240 --> 02:00:18.240]   Next the Alamo draft house.
[02:00:18.240 --> 02:00:19.560]   They're like, sperbing there.
[02:00:19.560 --> 02:00:20.680]   The steps are best.
[02:00:20.680 --> 02:00:21.200]   Yeah.
[02:00:21.200 --> 02:00:24.360]   Yeah, so they've definitely--
[02:00:24.360 --> 02:00:27.000]   you can't find in Louisville any of the old school
[02:00:27.000 --> 02:00:28.120]   theaters, which is like--
[02:00:28.120 --> 02:00:29.400]   Those were the cineplexes.
[02:00:29.400 --> 02:00:30.480]   That was a terrible issue.
[02:00:30.480 --> 02:00:32.720]   But you know, look at how people are habituated to watching
[02:00:32.720 --> 02:00:33.520]   movies now.
[02:00:33.520 --> 02:00:35.560]   Anyway, I mean, your kids are older than mine,
[02:00:35.560 --> 02:00:38.440]   but the first time my daughter realized that in a theater,
[02:00:38.440 --> 02:00:39.760]   she couldn't just pause the movie.
[02:00:39.760 --> 02:00:41.320]   She was legitimately shocked.
[02:00:41.320 --> 02:00:42.800]   [LAUGHTER]
[02:00:42.800 --> 02:00:43.440]   Because--
[02:00:43.440 --> 02:00:43.920]   How does she feel?
[02:00:43.920 --> 02:00:44.360]   She's seven.
[02:00:44.360 --> 02:00:45.680]   How does she feel about going to the movies?
[02:00:45.680 --> 02:00:46.920]   Or she'd rather stay home and watch?
[02:00:46.920 --> 02:00:50.240]   She likes the event around it, because she likes that we buy--
[02:00:50.240 --> 02:00:51.000]   Get in a car.
[02:00:51.000 --> 02:00:52.080]   You get the popcorn.
[02:00:52.080 --> 02:00:53.720]   We walk because we're only a mile and a half from it.
[02:00:53.720 --> 02:00:55.080]   But she likes that we get--
[02:00:55.080 --> 02:00:56.000]   A mile and a half.
[02:00:56.000 --> 02:00:57.000]   Yeah.
[02:00:57.000 --> 02:00:58.520]   Alameda is a very small island.
[02:00:58.520 --> 02:00:59.600]   That's a long way.
[02:00:59.600 --> 02:01:02.040]   You make your daughter walk a mile and a half?
[02:01:02.040 --> 02:01:04.000]   You make you sound like a little ninja this day.
[02:01:04.000 --> 02:01:05.000]   Yeah.
[02:01:05.000 --> 02:01:06.000]   [LAUGHTER]
[02:01:06.000 --> 02:01:07.880]   Yeah, but you know, we get the popcorn
[02:01:07.880 --> 02:01:10.880]   and shake on the Reese's pieces and mix it all up.
[02:01:10.880 --> 02:01:12.640]   What does fake butter stuff--
[02:01:12.640 --> 02:01:14.640]   Because someone tried to give me a thing of popcorn
[02:01:14.640 --> 02:01:15.680]   with fake butter.
[02:01:15.680 --> 02:01:18.120]   And it just let some more theater in the pool.
[02:01:18.120 --> 02:01:18.120]   Yeah.
[02:01:18.120 --> 02:01:19.160]   It has real butter.
[02:01:19.160 --> 02:01:19.660]   Yeah.
[02:01:19.660 --> 02:01:21.000]   At least they call it real butter.
[02:01:21.000 --> 02:01:23.240]   I notice it's real butter registered trademark,
[02:01:23.240 --> 02:01:24.320]   and it's bright yellow.
[02:01:24.320 --> 02:01:25.880]   Yeah.
[02:01:25.880 --> 02:01:27.320]   But they call it real butter anyway.
[02:01:27.320 --> 02:01:31.880]   But she likes the ritual, and she likes the experience behind it.
[02:01:31.880 --> 02:01:32.400]   Yeah.
[02:01:32.400 --> 02:01:33.680]   That's what the theater was.
[02:01:33.680 --> 02:01:35.200]   My kids don't love going to the movies.
[02:01:35.200 --> 02:01:38.960]   Like my wife and I ended up going without them most of the time.
[02:01:38.960 --> 02:01:42.760]   Because if you want to go, see whatever it is with this black panther,
[02:01:42.760 --> 02:01:44.760]   or whatever, they're like, eh, we'll wait for the video.
[02:01:44.760 --> 02:01:46.560]   I think black panther, they did want to go see,
[02:01:46.560 --> 02:01:47.760]   and they liked that one.
[02:01:47.760 --> 02:01:51.520]   But a lot of the other ones, they're just kind of like--
[02:01:51.520 --> 02:01:54.760]   even the cartoons are like, that's kid stuff.
[02:01:54.760 --> 02:01:56.560]   The adults go to see the Incredibles.
[02:01:56.560 --> 02:01:57.840]   The kids are like-- actually, they
[02:01:57.840 --> 02:01:59.080]   did want to see that one too.
[02:01:59.080 --> 02:02:00.320]   But most of the ones they don't.
[02:02:00.320 --> 02:02:01.920]   The thing that drives her bananas is she
[02:02:01.920 --> 02:02:03.600]   can't ask questions in the theater because I don't
[02:02:03.600 --> 02:02:05.080]   want to talk in the theater.
[02:02:05.080 --> 02:02:06.760]   But when we watch movies at home--
[02:02:06.760 --> 02:02:08.080]   She can't Snapchat either.
[02:02:08.080 --> 02:02:10.360]   She can talk to us, and she can ask things.
[02:02:10.360 --> 02:02:14.600]   And I think she likes-- I think when she wants to dig into a movie,
[02:02:14.600 --> 02:02:17.280]   and ask questions, she would prefer to watch it at home.
[02:02:17.280 --> 02:02:19.160]   And there have been times when I've seen her in the theater,
[02:02:19.160 --> 02:02:21.320]   and she's just visibly restraining herself from asking.
[02:02:21.320 --> 02:02:23.440]   If you were a fan of Infinity War,
[02:02:23.440 --> 02:02:26.920]   you might be in the subreddit.
[02:02:26.920 --> 02:02:30.280]   The Reddit dot com--
[02:02:30.280 --> 02:02:31.320]   Google signed up for us.
[02:02:31.320 --> 02:02:36.760]   /r/thanos did nothing wrong.
[02:02:36.760 --> 02:02:42.680]   Josh Brolin, aka Thanos, has a message for you.
[02:02:42.680 --> 02:02:44.280]   Here we go, Reddit users.
[02:02:44.280 --> 02:02:49.520]   Tomorrow.
[02:02:49.520 --> 02:02:52.680]   By the way, notice Josh Brolin, half of his clothes went away
[02:02:52.680 --> 02:02:54.040]   when he snapped his fingers.
[02:02:54.040 --> 02:02:55.560]   Let's say, if you've got a chest like that,
[02:02:55.560 --> 02:02:58.920]   I'd be looking around so close to the side as well.
[02:02:58.920 --> 02:03:03.560]   Tomorrow, July 9, at 9--
[02:03:03.560 --> 02:03:04.760]   actually, we don't know what time.
[02:03:04.760 --> 02:03:08.840]   Sometime during the day, exactly one half
[02:03:08.840 --> 02:03:14.680]   of all of the subscribers to the Thanos has a message for you--
[02:03:14.680 --> 02:03:17.720]   I'm sorry, to the Thanos did nothing wrong.
[02:03:17.720 --> 02:03:19.800]   Subreddit will be banned.
[02:03:19.800 --> 02:03:21.320]   So everybody needs to sign up.
[02:03:21.320 --> 02:03:23.560]   I noticed that the number has gone up a lot.
[02:03:23.560 --> 02:03:25.600]   Since this article--
[02:03:25.600 --> 02:03:27.520]   was it CNET?
[02:03:27.520 --> 02:03:29.680]   557,000 subscribers now.
[02:03:29.680 --> 02:03:31.840]   It's more than doubled.
[02:03:31.840 --> 02:03:34.640]   And we're going to do more to get that increased.
[02:03:34.640 --> 02:03:35.520]   It's going up fast.
[02:03:35.520 --> 02:03:37.280]   It's probably doubled again since it was on the show.
[02:03:37.280 --> 02:03:41.520]   Yeah, because everybody wants to be banned by Thanos.
[02:03:41.520 --> 02:03:44.800]   So we'll get back to you next time
[02:03:44.800 --> 02:03:46.840]   and tell you how that went.
[02:03:46.840 --> 02:03:47.960]   I joined immediately.
[02:03:47.960 --> 02:03:49.680]   You have to not only subscribe--
[02:03:49.680 --> 02:03:51.200]   Carsten, who somehow knows all this,
[02:03:51.200 --> 02:03:53.480]   says you also have to say something.
[02:03:53.480 --> 02:03:56.320]   And Carsten told me that what I should say is,
[02:03:56.320 --> 02:03:58.720]   I don't feel so good, right?
[02:03:58.720 --> 02:04:00.800]   Is that the canonical Thanos?
[02:04:00.800 --> 02:04:03.760]   That is a good thing to say in any situation.
[02:04:03.760 --> 02:04:06.920]   I don't-- you guys don't watch "Sportball."
[02:04:06.920 --> 02:04:08.680]   I don't get the comic book movies.
[02:04:08.680 --> 02:04:09.240]   It's just--
[02:04:09.240 --> 02:04:11.640]   No, I mean, it's--
[02:04:11.640 --> 02:04:13.120]   the whole Marvel things were sort of--
[02:04:13.120 --> 02:04:14.640]   I mean, OK, they were fun for a while.
[02:04:14.640 --> 02:04:16.040]   And occasionally, they're quite good.
[02:04:16.040 --> 02:04:18.160]   But mainly, it's kind of brain candy.
[02:04:18.160 --> 02:04:19.760]   You go in.
[02:04:19.760 --> 02:04:21.160]   Ant-Man was really good.
[02:04:21.160 --> 02:04:22.320]   Yeah, I hear that's funny.
[02:04:22.320 --> 02:04:27.600]   I feel like a very weird pathology during the big battle
[02:04:27.600 --> 02:04:27.800]   scenes.
[02:04:27.800 --> 02:04:28.800]   Now, they're so overwhelming.
[02:04:28.800 --> 02:04:30.880]   It started with Black Panther and Happen in Infinity War
[02:04:30.880 --> 02:04:33.880]   during those massive chaotic battle scenes.
[02:04:33.880 --> 02:04:35.120]   I fell asleep.
[02:04:35.120 --> 02:04:35.640]   Yeah.
[02:04:35.640 --> 02:04:37.640]   I don't love that stuff either.
[02:04:37.640 --> 02:04:39.560]   It's not like, oh, I'm bored.
[02:04:39.560 --> 02:04:43.320]   I literally just fall asleep and then wake up when they're over.
[02:04:43.320 --> 02:04:43.800]   So--
[02:04:43.800 --> 02:04:44.640]   And I said, who won?
[02:04:44.640 --> 02:04:47.960]   I podcast on "The Encomparable" with Jason Snow and Matt
[02:04:47.960 --> 02:04:48.640]   Crew.
[02:04:48.640 --> 02:04:51.680]   And we're doing a Marvel summer where we rewatch
[02:04:51.680 --> 02:04:52.600]   and analyze the movies.
[02:04:52.600 --> 02:04:55.480]   And I'm on next week for "Avengers 1, Avengers 2"
[02:04:55.480 --> 02:04:57.880]   and "Captain America Civil War."
[02:04:57.880 --> 02:04:59.000]   And it's been really interesting.
[02:04:59.000 --> 02:05:01.080]   Can we do a DC summer next year?
[02:05:01.080 --> 02:05:02.440]   If they make decent movies, sure.
[02:05:02.440 --> 02:05:02.960]   And then--
[02:05:02.960 --> 02:05:03.960]   Oh!
[02:05:03.960 --> 02:05:06.360]   Don't hold your breath, but now it's--
[02:05:06.360 --> 02:05:07.360]   Oh!
[02:05:07.360 --> 02:05:09.160]   All right, that's it.
[02:05:09.160 --> 02:05:11.440]   We're done here, ladies and gentlemen.
[02:05:11.440 --> 02:05:12.280]   We thank you so much for--
[02:05:12.280 --> 02:05:13.200]   It's about to turn ugly.
[02:05:13.200 --> 02:05:15.200]   That's kicking off.
[02:05:15.200 --> 02:05:17.280]   It's the Encomparable.com.
[02:05:17.280 --> 02:05:19.320]   UK, always a pleasure to have you.
[02:05:19.320 --> 02:05:20.720]   Great fun to be here as emcere.
[02:05:20.720 --> 02:05:22.320]   Coming by Schmeiser.
[02:05:22.320 --> 02:05:22.840]   Yeah.
[02:05:22.840 --> 02:05:25.080]   Tell us the name of that "Encomparable."
[02:05:25.080 --> 02:05:26.040]   Is it "The Encomparable"?
[02:05:26.040 --> 02:05:26.920]   It's "The Encomparable."
[02:05:26.920 --> 02:05:27.920]   Where can we find that?
[02:05:27.920 --> 02:05:29.520]   You know, I'm Googling it now.
[02:05:29.520 --> 02:05:31.680]   I think it's the Encomparable.com.
[02:05:31.680 --> 02:05:33.720]   Yes, it's the Encomparable.com.
[02:05:33.720 --> 02:05:39.000]   So, Jason in England right now for Michael Hurley's wedding.
[02:05:39.000 --> 02:05:39.840]   Yes.
[02:05:39.840 --> 02:05:43.200]   So Hurley of the 5x5--
[02:05:43.200 --> 02:05:45.040]   No, is he 5x5?
[02:05:45.040 --> 02:05:45.960]   He's relay FM.
[02:05:45.960 --> 02:05:46.640]   Yeah, relay FM.
[02:05:46.640 --> 02:05:47.840]   Dan is 5x5.
[02:05:47.840 --> 02:05:49.480]   Hurt Mike Hurley of the 5x5 network.
[02:05:49.480 --> 02:05:50.360]   Getting got married.
[02:05:50.360 --> 02:05:51.400]   Congratulations, Mike.
[02:05:51.400 --> 02:05:54.840]   And a lot of the 5x5 folks are in England right now.
[02:05:54.840 --> 02:05:56.240]   Jolly old.
[02:05:56.240 --> 02:05:58.960]   And of course, you can finally set where she is an editor
[02:05:58.960 --> 02:06:01.400]   at ITProToday.com.
[02:06:01.400 --> 02:06:02.640]   So nice to have you on.
[02:06:02.640 --> 02:06:03.160]   Thank you.
[02:06:03.160 --> 02:06:04.160]   Appreciate it.
[02:06:04.160 --> 02:06:04.760]   Thank you for asking.
[02:06:04.760 --> 02:06:05.600]   Well, we love having you.
[02:06:05.600 --> 02:06:07.240]   And same with you, Jason Heiner.
[02:06:07.240 --> 02:06:09.160]   What brings you out to the West Coast?
[02:06:09.160 --> 02:06:12.320]   Yeah, just working with my team in San Francisco
[02:06:12.320 --> 02:06:16.720]   and spending some quality time working
[02:06:16.720 --> 02:06:20.800]   on the next generation of stuff that we're working on.
[02:06:20.800 --> 02:06:22.920]   Like Dan Harrison and the--
[02:06:22.920 --> 02:06:23.720]   Yeah.
[02:06:23.720 --> 02:06:25.440]   --the social media burnouts.
[02:06:25.440 --> 02:06:26.600]   Yeah, social media fatigue.
[02:06:26.600 --> 02:06:29.320]   Yeah, Dan, that's a good little tease.
[02:06:29.320 --> 02:06:32.320]   You heard it here first that Dan and I
[02:06:32.320 --> 02:06:34.120]   are working on a little something on that.
[02:06:34.120 --> 02:06:36.960]   And that'll be on Tech Republic or--
[02:06:36.960 --> 02:06:42.120]   That will be probably across multiple CVS interactive brands
[02:06:42.120 --> 02:06:43.000]   to be determined.
[02:06:43.000 --> 02:06:45.040]   Jason is editor and chief of Tech Republic.
[02:06:45.040 --> 02:06:46.320]   Thank you all for being here.
[02:06:46.320 --> 02:06:48.800]   We had a nice studio audience, including poor Logan,
[02:06:48.800 --> 02:06:51.160]   who was the butt of a few of our jokes.
[02:06:51.160 --> 02:06:54.920]   Thank you, Logan and family from Galesburg, Illinois,
[02:06:54.920 --> 02:06:57.800]   and Patrick from Tampa and Jacob from Walnut Creek.
[02:06:57.800 --> 02:06:59.680]   And if you want to be in our studio audience,
[02:06:59.680 --> 02:07:00.680]   we'd be glad to have you.
[02:07:00.680 --> 02:07:01.880]   There's no charge.
[02:07:01.880 --> 02:07:05.240]   Just email tickets@twit.tv so we know you're coming.
[02:07:05.240 --> 02:07:06.600]   We'll put a chair up where you can also
[02:07:06.600 --> 02:07:08.720]   watch our live stream wherever you are anywhere in the world
[02:07:08.720 --> 02:07:10.760]   at twit.tv/live.
[02:07:10.760 --> 02:07:13.600]   If you want to watch us do Twit, that's 3 PM Pacific Sunday,
[02:07:13.600 --> 02:07:17.360]   6 PM Eastern time 2,200 UTC.
[02:07:17.360 --> 02:07:18.960]   If you're in the live stream--
[02:07:18.960 --> 02:07:21.280]   watching the live stream, please join us in the chatroom,
[02:07:21.280 --> 02:07:22.760]   IRC.twit.tv.
[02:07:22.760 --> 02:07:25.520]   That's where all the cool kids are hanging out,
[02:07:25.520 --> 02:07:27.960]   including Jason, who's very brave to go in there.
[02:07:27.960 --> 02:07:28.920]   Prude was in there.
[02:07:28.920 --> 02:07:33.360]   I saw Father Robert Ballisare join us for a moment or two.
[02:07:33.360 --> 02:07:33.840]   I hope so.
[02:07:33.840 --> 02:07:36.120]   Well, my highlights are signing into the Twit channel,
[02:07:36.120 --> 02:07:38.400]   and you just let them say hello, and everyone's very friendly.
[02:07:38.400 --> 02:07:39.520]   They love to see you there.
[02:07:39.520 --> 02:07:41.360]   We're actually very proud of our--
[02:07:41.360 --> 02:07:43.520]   Well, somebody did insult the food content of bangers
[02:07:43.520 --> 02:07:45.960]   and mash, and we'll be having words on that one later.
[02:07:45.960 --> 02:07:48.040]   Is it the bangers he doesn't like or the mash?
[02:07:48.040 --> 02:07:48.880]   I don't know.
[02:07:48.880 --> 02:07:50.480]   The two are just so--
[02:07:50.480 --> 02:07:51.880]   you can't have one without the other.
[02:07:51.880 --> 02:07:53.400]   It's like bubble and sweet.
[02:07:53.400 --> 02:07:55.120]   With the thick covering of onion gravey.
[02:07:55.120 --> 02:07:56.200]   It's like spotted dick.
[02:07:56.200 --> 02:07:56.960]   It's just--
[02:07:56.960 --> 02:07:58.400]   You've got a hamster right now.
[02:07:58.400 --> 02:07:59.200]   Oh, my gosh.
[02:07:59.200 --> 02:08:01.880]   If you can't--
[02:08:01.880 --> 02:08:03.360]   There's a British pub on the way down to San Francisco.
[02:08:03.360 --> 02:08:03.800]   Is there--
[02:08:03.800 --> 02:08:05.040]   Which one do you go to?
[02:08:05.040 --> 02:08:06.560]   There's the Mayflower in San Rafael.
[02:08:06.560 --> 02:08:07.720]   That would be a good one to go--
[02:08:07.720 --> 02:08:08.640]   you know who works there.
[02:08:08.640 --> 02:08:09.680]   Isn't that where--
[02:08:09.680 --> 02:08:11.240]   I think Kim Shaffer works there.
[02:08:11.240 --> 02:08:13.480]   She was bomoting the fact she had to get up at 6 in the morning
[02:08:13.480 --> 02:08:16.360]   for those stupid matches.
[02:08:16.360 --> 02:08:18.120]   But she has shown me some great video.
[02:08:18.120 --> 02:08:19.800]   It would be a great place to watch England.
[02:08:19.800 --> 02:08:20.680]   Oh, yeah.
[02:08:20.680 --> 02:08:21.680]   Yeah.
[02:08:21.680 --> 02:08:24.960]   If you can't watch live, maybe you're busy doing something else.
[02:08:24.960 --> 02:08:25.320]   Don't worry.
[02:08:25.320 --> 02:08:27.000]   On demand, audio, and video.
[02:08:27.000 --> 02:08:29.760]   Everything we do on the network is available at our website.
[02:08:29.760 --> 02:08:31.960]   Twit.tv.
[02:08:31.960 --> 02:08:34.200]   And if you don't want to just download it,
[02:08:34.200 --> 02:08:35.200]   you can always subscribe.
[02:08:35.200 --> 02:08:37.760]   Every podcast application has Twit.
[02:08:37.760 --> 02:08:40.840]   Of course, one of the oldest podcasts in the world,
[02:08:40.840 --> 02:08:42.240]   all you have to do is search for Twit.
[02:08:42.240 --> 02:08:43.960]   And you can get this in all of our other shows.
[02:08:43.960 --> 02:08:47.520]   And they'll appear on your phone automatically.
[02:08:47.520 --> 02:08:49.720]   You'll also use those voice activated devices.
[02:08:49.720 --> 02:08:53.480]   And almost every case, all you have to do is say, listen to Twit.
[02:08:53.480 --> 02:08:56.120]   Sometimes you have to say, listen to Twit on TuneIn.
[02:08:56.120 --> 02:08:57.400]   It depends on the device.
[02:08:57.400 --> 02:09:00.600]   But you can hear us on the latest versions of all of our shows
[02:09:00.600 --> 02:09:03.880]   on Echo, Google Home, even Siri.
[02:09:03.880 --> 02:09:04.920]   Thanks for being here.
[02:09:04.920 --> 02:09:05.840]   We appreciate it.
[02:09:05.840 --> 02:09:06.600]   We'll see you next time.
[02:09:06.600 --> 02:09:08.440]   Another Twit is in the can.
[02:09:08.440 --> 02:09:11.400]   [MUSIC PLAYING]
[02:09:11.400 --> 02:09:13.400]   Do on the Twit.
[02:09:13.400 --> 02:09:14.400]   All right.
[02:09:14.400 --> 02:09:16.360]   Do on the Twit, baby.
[02:09:16.360 --> 02:09:17.160]   Do on the Twit.
[02:09:17.160 --> 02:09:18.160]   All right.

