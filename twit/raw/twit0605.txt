;FFMETADATA1
title=Think of the Koalas
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=605
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:02.320]   It's Divertuit this week in tech.
[00:00:02.320 --> 00:00:04.000]   We've got a big show for you.
[00:00:04.000 --> 00:00:08.520]   Baratunde Thurston, Ashley Esquetha from CNET, and Mike
[00:00:08.520 --> 00:00:09.120]   Elgin.
[00:00:09.120 --> 00:00:12.840]   And we're going to talk about the big dump of CIA hacks
[00:00:12.840 --> 00:00:15.880]   and what it all means, South by Southwest,
[00:00:15.880 --> 00:00:17.600]   and why Uber isn't there.
[00:00:17.600 --> 00:00:20.680]   We'll even take a look at a very funny video that's
[00:00:20.680 --> 00:00:23.160]   making the rounds these days and break it down.
[00:00:23.160 --> 00:00:24.840]   It's all coming up next.
[00:00:24.840 --> 00:00:25.840]   That's it.
[00:00:25.840 --> 00:00:28.800]   [MUSIC PLAYING]
[00:00:28.800 --> 00:00:30.880]   NetCasts you love.
[00:00:30.880 --> 00:00:32.240]   From people you trust.
[00:00:32.240 --> 00:00:38.400]   This is Twit.
[00:00:38.400 --> 00:00:41.760]   Bandwidth for this week in tech is provided by CashFly
[00:00:41.760 --> 00:00:44.440]   at C-A-C-H-E-F-L-Y.com.
[00:00:44.440 --> 00:00:54.280]   This is Twit, this week in tech, episode 605,
[00:00:54.280 --> 00:00:57.400]   recorded Sunday, March 12, 2017.
[00:00:57.400 --> 00:00:58.480]   Think of the koalas.
[00:00:58.480 --> 00:01:04.600]   This week, attack is brought to you by Casper,
[00:01:04.600 --> 00:01:06.760]   an online retailer of premium mattresses
[00:01:06.760 --> 00:01:09.560]   for a fraction of the price, because everyone deserves
[00:01:09.560 --> 00:01:10.760]   a great night's sleep.
[00:01:10.760 --> 00:01:13.100]   Get $50 off any mattress purchased by visiting
[00:01:13.100 --> 00:01:19.560]   casper.com/twit and entering the promo code Twit.
[00:01:19.560 --> 00:01:22.880]   And by Tracker, a coin-sized tracking device
[00:01:22.880 --> 00:01:24.680]   that pairs with your smartphone and keeps you
[00:01:24.680 --> 00:01:26.760]   from losing your most valued possessions.
[00:01:26.760 --> 00:01:29.600]   Visit the tracker.com right now and enter the promo code Twit
[00:01:29.600 --> 00:01:32.880]   to receive a free tracker bravo with any purchase.
[00:01:32.880 --> 00:01:34.440]   And by Texture.
[00:01:34.440 --> 00:01:36.400]   Access the world's most popular magazines
[00:01:36.400 --> 00:01:39.280]   anytime, anywhere, using your smartphone or tablet.
[00:01:39.280 --> 00:01:44.080]   Try it free for 14 days at texture.com/twit.
[00:01:44.080 --> 00:01:46.120]   And by WordPress.
[00:01:46.120 --> 00:01:48.800]   WordPress salutes all the small businesses out there,
[00:01:48.800 --> 00:01:50.640]   making a big difference.
[00:01:50.640 --> 00:01:52.400]   Create your small business website
[00:01:52.400 --> 00:01:56.720]   and get 15% off any new planned purchase at WordPress.com.
[00:01:56.960 --> 00:01:57.720]   Slash Twit.
[00:01:57.720 --> 00:02:02.920]   It's time for Twit this week.
[00:02:02.920 --> 00:02:06.320]   And attack the show where we cover the week's tech news.
[00:02:06.320 --> 00:02:08.760]   And a big week this was.
[00:02:08.760 --> 00:02:11.960]   But fortunately, we've got the big brains on the show today.
[00:02:11.960 --> 00:02:14.680]   Mike Elgin's here in studio with me.
[00:02:14.680 --> 00:02:15.520]   The biggest of the brains.
[00:02:15.520 --> 00:02:16.680]   The biggest of the brains.
[00:02:16.680 --> 00:02:20.560]   Elgin.com being nomadic.com, coming nomad.
[00:02:20.560 --> 00:02:22.840]   You know, that's an interesting story, Leo,
[00:02:22.840 --> 00:02:23.880]   that we might want to talk about.
[00:02:23.880 --> 00:02:25.240]   It's now Gastronomad.
[00:02:25.240 --> 00:02:26.280]   Not met.
[00:02:26.280 --> 00:02:27.720]   You're not leaving, that's why.
[00:02:27.720 --> 00:02:29.320]   We're stuck here because you have a granddaughter.
[00:02:29.320 --> 00:02:30.320]   You can't leave.
[00:02:30.320 --> 00:02:30.920]   We're all leaving.
[00:02:30.920 --> 00:02:32.160]   We're taking all these people with us.
[00:02:32.160 --> 00:02:32.480]   Oh, good.
[00:02:32.480 --> 00:02:32.960]   I like that.
[00:02:32.960 --> 00:02:34.000]   So I want to tell you about that.
[00:02:34.000 --> 00:02:34.880]   OK.
[00:02:34.880 --> 00:02:35.840]   I'd like to.
[00:02:35.840 --> 00:02:37.440]   That sounds like there's food involved.
[00:02:37.440 --> 00:02:37.920]   Tons.
[00:02:37.920 --> 00:02:39.240]   And I like that.
[00:02:39.240 --> 00:02:40.120]   Also joining us.
[00:02:40.120 --> 00:02:42.520]   Baratunde Thurston, it's great to have you.
[00:02:42.520 --> 00:02:44.480]   He is an internet person.
[00:02:44.480 --> 00:02:45.560]   Yes, I am.
[00:02:45.560 --> 00:02:46.800]   I've been back.
[00:02:46.800 --> 00:02:47.840]   I missed Twit.
[00:02:47.840 --> 00:02:51.640]   Yeah, we always love having you on from Brooklyn.
[00:02:51.640 --> 00:02:54.280]   Anything big in your world these days?
[00:02:54.280 --> 00:02:55.560]   What are you up to?
[00:02:55.560 --> 00:02:58.880]   I revised my website at baratunde.com.
[00:02:58.880 --> 00:02:59.880]   Good.
[00:02:59.880 --> 00:03:01.880]   And I've rebooted my email list.
[00:03:01.880 --> 00:03:04.880]   I actually send messages to my email list now.
[00:03:04.880 --> 00:03:07.720]   So it's a revolution in email where I press send.
[00:03:07.720 --> 00:03:08.280]   Subscribe.
[00:03:08.280 --> 00:03:09.040]   And then I used to.
[00:03:09.040 --> 00:03:10.480]   So subscribe to that.
[00:03:10.480 --> 00:03:12.040]   There's a little bar at the top of my site.
[00:03:12.040 --> 00:03:13.600]   People can get that on.
[00:03:13.600 --> 00:03:16.600]   And I've been just engaging in active democracy
[00:03:16.600 --> 00:03:18.280]   and using internet tools to help me do it.
[00:03:18.280 --> 00:03:20.440]   So when does your run from Congress begin?
[00:03:20.440 --> 00:03:21.360]   That's what I want to know.
[00:03:21.360 --> 00:03:22.800]   Because I will vote for you.
[00:03:22.800 --> 00:03:24.560]   Right now, I'm just putting pressure on Congress.
[00:03:24.560 --> 00:03:27.680]   I've been doing Facebook lives pretty much every Tuesday
[00:03:27.680 --> 00:03:29.040]   of my calls to Congress.
[00:03:29.040 --> 00:03:29.560]   Nice.
[00:03:29.560 --> 00:03:31.680]   And I play Hamilton music in the background.
[00:03:31.680 --> 00:03:32.200]   Nice.
[00:03:32.200 --> 00:03:35.840]   And we try to make it more fun than engaging in congressional
[00:03:35.840 --> 00:03:38.200]   calls generally is.
[00:03:38.200 --> 00:03:40.400]   I'll give you a full credit comic.
[00:03:40.400 --> 00:03:44.640]   You worked at The Onion for Years, producer at The Daily Show
[00:03:44.640 --> 00:03:46.520]   with Trevor Noah.
[00:03:46.520 --> 00:03:49.160]   And according to your website, you advise the Obama White
[00:03:49.160 --> 00:03:52.680]   House and cleaned bathrooms to pay for your Harvard education.
[00:03:52.680 --> 00:03:53.880]   These are all true facts.
[00:03:53.880 --> 00:03:56.000]   Still doing about race, right?
[00:03:56.000 --> 00:04:00.000]   No, actually, my podcasting days, at least temporarily,
[00:04:00.000 --> 00:04:01.840]   have seceded.
[00:04:01.840 --> 00:04:02.200]   Oh, good.
[00:04:02.200 --> 00:04:04.400]   Does that mean we'll see more of you here?
[00:04:04.400 --> 00:04:05.360]   It could mean that.
[00:04:05.360 --> 00:04:07.320]   It could very well mean that it would be nice.
[00:04:07.320 --> 00:04:08.080]   I like it here.
[00:04:08.080 --> 00:04:09.080]   Good.
[00:04:09.080 --> 00:04:11.680]   And I want to introduce a newcomer, not new to Twitch.
[00:04:11.680 --> 00:04:14.080]   She's been on tech news today many times.
[00:04:14.080 --> 00:04:16.960]   And of course, we all know Ashley very well, Ashley.
[00:04:16.960 --> 00:04:19.160]   And I've instructed how to pronounce her name.
[00:04:19.160 --> 00:04:21.320]   And I've been saying it wrong all this time.
[00:04:21.320 --> 00:04:23.120]   Esquetha.
[00:04:23.120 --> 00:04:24.240]   Oh, you were so close.
[00:04:24.240 --> 00:04:25.000]   It's so close.
[00:04:25.000 --> 00:04:27.360]   Esquetha, together.
[00:04:27.360 --> 00:04:28.360]   Esquetha.
[00:04:28.360 --> 00:04:30.160]   OK, I'll get it right one day.
[00:04:30.160 --> 00:04:30.880]   Not today.
[00:04:30.880 --> 00:04:31.520]   It's all good.
[00:04:31.520 --> 00:04:32.040]   It's all good.
[00:04:32.040 --> 00:04:34.440]   It's all good.
[00:04:34.440 --> 00:04:36.240]   Do other people know how to pronounce your name?
[00:04:36.240 --> 00:04:36.720]   Am I?
[00:04:36.720 --> 00:04:37.240]   No.
[00:04:37.240 --> 00:04:37.760]   No, OK.
[00:04:37.760 --> 00:04:42.480]   I'm not somebody actually guessed Cessedia, which is kind of racist.
[00:04:42.480 --> 00:04:43.520]   I think they're just hungry.
[00:04:43.520 --> 00:04:44.280]   That's weird.
[00:04:44.280 --> 00:04:45.920]   Yeah, maybe they were just really hungry.
[00:04:45.920 --> 00:04:47.200]   It wasn't a Taco Bell.
[00:04:47.200 --> 00:04:47.680]   It totally--
[00:04:47.680 --> 00:04:49.440]   Oh, like Ashley, Cessedia.
[00:04:49.440 --> 00:04:51.000]   I'm like, I'm sorry you said that,
[00:04:51.000 --> 00:04:52.720]   because you may end up accidentally.
[00:04:52.720 --> 00:04:54.320]   Because I'm an old man.
[00:04:54.320 --> 00:04:57.280]   Look, I'm down for cool nicknames and Cessedias are delicious.
[00:04:57.280 --> 00:04:58.760]   So that's fine with me.
[00:04:58.760 --> 00:05:01.000]   Ashley is a senior editor at CNET.
[00:05:01.000 --> 00:05:02.160]   And we're really glad to have you.
[00:05:02.160 --> 00:05:05.320]   This is, of course, the week that we could talk about nothing
[00:05:05.320 --> 00:05:13.680]   else but Vault 7, the big dump, 8,000 plus pages of hacks
[00:05:13.680 --> 00:05:14.480]   purportedly.
[00:05:14.480 --> 00:05:18.680]   I want to say purportedly, allegedly, from the CIA.
[00:05:18.680 --> 00:05:20.880]   Julian Assange and WikiLeaks dumped them all.
[00:05:20.880 --> 00:05:24.200]   And they said in their press release
[00:05:24.200 --> 00:05:27.680]   that they only have put out a part of this trove, which
[00:05:27.680 --> 00:05:29.880]   has more pages than the Snowden leak.
[00:05:29.880 --> 00:05:31.880]   Yeah.
[00:05:31.880 --> 00:05:34.960]   Now, I got to say it seems credible.
[00:05:34.960 --> 00:05:37.040]   When you read it, there's certainly enough detail in there.
[00:05:37.040 --> 00:05:39.400]   There'd be hard-- you'd be hard pressed for somebody
[00:05:39.400 --> 00:05:41.880]   to put this together as a fake.
[00:05:41.880 --> 00:05:42.360]   Yeah.
[00:05:42.360 --> 00:05:45.160]   And there'd be no reason to.
[00:05:45.160 --> 00:05:49.400]   What this essentially says is that this CIA, big surprise,
[00:05:49.400 --> 00:05:53.000]   collects and develops methods for hacking.
[00:05:53.000 --> 00:05:53.640]   What?
[00:05:53.640 --> 00:05:55.760]   And spying on people's prior organization.
[00:05:55.760 --> 00:05:56.480]   I am shocked.
[00:05:56.480 --> 00:05:57.720]   They have a lot of money.
[00:05:57.720 --> 00:06:00.560]   Cambling is occurring on these premises.
[00:06:00.560 --> 00:06:03.640]   And so the idea that this might be fake information
[00:06:03.640 --> 00:06:06.760]   is ridiculous because if those are real hacks,
[00:06:06.760 --> 00:06:08.280]   the CIA now has them.
[00:06:08.280 --> 00:06:10.360]   And we'll now use them because if they're any good,
[00:06:10.360 --> 00:06:11.120]   they use them.
[00:06:11.120 --> 00:06:12.800]   The fact is they're kind of old.
[00:06:12.800 --> 00:06:14.920]   They're a little dated, two or three years old
[00:06:14.920 --> 00:06:16.240]   at the newest.
[00:06:16.240 --> 00:06:19.960]   And people are freaking out more than they should.
[00:06:19.960 --> 00:06:21.760]   A lot of hair on fire.
[00:06:21.760 --> 00:06:24.440]   And a lot of that caused by mainstream media, which kind of,
[00:06:24.440 --> 00:06:27.360]   I think, blew this out of proportion, right?
[00:06:27.360 --> 00:06:28.760]   Ashley, we've never had--
[00:06:28.760 --> 00:06:32.400]   Yeah, they always get freaked out.
[00:06:32.400 --> 00:06:37.120]   It's so hard sometimes, especially with tech security
[00:06:37.120 --> 00:06:40.840]   to keep people calm because, of course, there's always
[00:06:40.840 --> 00:06:43.800]   the question of your privacy and your data.
[00:06:43.800 --> 00:06:46.400]   And people are very protective of those things,
[00:06:46.400 --> 00:06:47.720]   and they should be.
[00:06:47.720 --> 00:06:49.880]   But then you have a lot of journalists
[00:06:49.880 --> 00:06:52.280]   who are not technology journalists,
[00:06:52.280 --> 00:06:55.640]   or maybe don't have either access to or don't talk
[00:06:55.640 --> 00:06:58.320]   to a lot of security experts a lot.
[00:06:58.320 --> 00:07:01.560]   And so they kind of take it at face value and say, oh, my gosh,
[00:07:01.560 --> 00:07:03.360]   like, we think this is what it means.
[00:07:03.360 --> 00:07:06.400]   And then people kind of take that as gospel.
[00:07:06.400 --> 00:07:08.280]   And that's probably not the best thing.
[00:07:08.280 --> 00:07:10.520]   I think a lot of the press just basically
[00:07:10.520 --> 00:07:13.240]   worked off of the press release that WikiLeaks--
[00:07:13.240 --> 00:07:13.600]   Right.
[00:07:13.600 --> 00:07:15.080]   --said the cover page.
[00:07:15.080 --> 00:07:18.200]   And this was one line that I think fooled them.
[00:07:18.200 --> 00:07:20.800]   These techniques permit the CIA to bypass
[00:07:20.800 --> 00:07:23.160]   the encryption of WhatsApp signal,
[00:07:23.160 --> 00:07:26.440]   Telegram, Y-Bo, confide, and cloakman.
[00:07:26.440 --> 00:07:27.760]   And they stopped at the end of there.
[00:07:27.760 --> 00:07:28.520]   Which is false.
[00:07:28.520 --> 00:07:30.680]   And they went and they immediately wrote that story.
[00:07:30.680 --> 00:07:33.360]   But without reading the rest, by hacking the smartphones
[00:07:33.360 --> 00:07:36.480]   they run on and collecting audio and message traffic
[00:07:36.480 --> 00:07:38.480]   before encryption is applied.
[00:07:38.480 --> 00:07:43.920]   So what that means is that I can fool a bank's vault
[00:07:43.920 --> 00:07:45.640]   by mugging you on the way to the bank.
[00:07:45.640 --> 00:07:46.240]   Right.
[00:07:46.240 --> 00:07:47.240]   The vault doesn't work.
[00:07:47.240 --> 00:07:47.240]   Exactly.
[00:07:47.240 --> 00:07:48.680]   The vault is horrible.
[00:07:48.680 --> 00:07:51.440]   The vault is broken.
[00:07:51.440 --> 00:07:52.400]   So let's say that--
[00:07:52.400 --> 00:07:54.760]   Or I can rob you after you've taken your money out of the bank.
[00:07:54.760 --> 00:07:56.280]   And that also means the vault is bad.
[00:07:56.280 --> 00:07:56.760]   Exactly.
[00:07:56.760 --> 00:07:59.680]   The bank is very insecure for letting you get robbed after that.
[00:07:59.680 --> 00:08:00.520]   So dare they.
[00:08:00.520 --> 00:08:04.440]   Open whisper systems, which creates signal, of course,
[00:08:04.440 --> 00:08:07.960]   immediately jumped on this and said,
[00:08:07.960 --> 00:08:10.040]   the CIA WikiLeaks story-- this is on Twitter--
[00:08:10.040 --> 00:08:11.960]   is about getting malware onto phones.
[00:08:11.960 --> 00:08:15.640]   None of the exploits are in signal or break signal protocol
[00:08:15.640 --> 00:08:17.600]   encryption or any of those others.
[00:08:17.600 --> 00:08:18.920]   But I do like what they said.
[00:08:18.920 --> 00:08:21.200]   The story isn't about signal or WhatsApp.
[00:08:21.200 --> 00:08:24.920]   But to the extent that it is, we see it as confirmation
[00:08:24.920 --> 00:08:28.240]   that what we're doing, our encryption is working.
[00:08:28.240 --> 00:08:31.440]   Ubiquitous end-to-end encryption is pushing intelligence
[00:08:31.440 --> 00:08:36.880]   agencies from undetectable mass surveillance
[00:08:36.880 --> 00:08:40.120]   to expensive high-risk targeted attacks.
[00:08:40.120 --> 00:08:43.840]   And that's the key here-- expensive high-risk targeted
[00:08:43.840 --> 00:08:45.480]   attacks.
[00:08:45.480 --> 00:08:48.600]   And that's basically what we're seeing in this vault.
[00:08:48.600 --> 00:08:50.560]   It's not surprisingly-- as you say, Mike,
[00:08:50.560 --> 00:08:52.000]   that's the CIA would have these.
[00:08:52.000 --> 00:08:52.600]   Exactly.
[00:08:52.600 --> 00:08:54.720]   I mean, if you think about a CIA scenario,
[00:08:54.720 --> 00:08:56.520]   they've got somebody on their radar.
[00:08:56.520 --> 00:09:00.320]   They think it's a terrorist suspect in Pakistan.
[00:09:00.320 --> 00:09:02.560]   And they want to listen in on conversations
[00:09:02.560 --> 00:09:04.160]   that person is having somewhere else.
[00:09:04.160 --> 00:09:05.640]   So they say, OK, can we plan a buck?
[00:09:05.640 --> 00:09:06.800]   Well, no, we can't do that.
[00:09:06.800 --> 00:09:07.800]   Well, can we tap the phone?
[00:09:07.800 --> 00:09:09.600]   Well, that's problematic for XYZ.
[00:09:09.600 --> 00:09:12.280]   Do they have a Samsung TV?
[00:09:12.280 --> 00:09:13.200]   Oh, OK, great.
[00:09:13.200 --> 00:09:15.440]   So they want a laundry list of ways
[00:09:15.440 --> 00:09:17.960]   to get access to a specific target.
[00:09:17.960 --> 00:09:20.920]   This is very, very different from the controversy
[00:09:20.920 --> 00:09:23.400]   around the NSA, which is about mass surveillance
[00:09:23.400 --> 00:09:25.080]   and phishing expeditions, where they're
[00:09:25.080 --> 00:09:26.880]   listening to everything looking for keywords
[00:09:26.880 --> 00:09:29.520]   and essentially trying to find out who's a criminal.
[00:09:29.520 --> 00:09:31.360]   In this case, they've already got somebody in mind,
[00:09:31.360 --> 00:09:33.000]   the CIA, most likely.
[00:09:33.000 --> 00:09:35.200]   And they have a bunch of tools at their disposal.
[00:09:35.200 --> 00:09:37.240]   Nothing is surprising about that.
[00:09:37.240 --> 00:09:39.120]   Expensive because you have to make them.
[00:09:39.120 --> 00:09:41.520]   High risk because it's easy to get caught.
[00:09:41.520 --> 00:09:43.200]   You put a bug on a Samsung TV.
[00:09:43.200 --> 00:09:44.600]   There's a potential of getting caught.
[00:09:44.600 --> 00:09:48.200]   Targeted-- in other words, aimed at specific individual attacks.
[00:09:48.200 --> 00:09:50.000]   That's a very different kind of attack.
[00:09:50.000 --> 00:09:51.720]   The CIA is a spy organization.
[00:09:51.720 --> 00:09:54.560]   Their primary mission is to steal secrets.
[00:09:54.560 --> 00:09:58.520]   And the controversial aspects, the genuinely controversial
[00:09:58.520 --> 00:10:01.080]   aspects of the CIA are when they veer from that,
[00:10:01.080 --> 00:10:03.680]   when they're targeted assassinations, things like that.
[00:10:03.680 --> 00:10:05.880]   Those are the things we should be really concerned about.
[00:10:05.880 --> 00:10:09.120]   When they're just doing their job and gaining the capability
[00:10:09.120 --> 00:10:13.040]   to steal secrets, then that's our tax dollars at work.
[00:10:13.040 --> 00:10:15.200]   And we want them to do that, as long as they do it
[00:10:15.200 --> 00:10:17.200]   against them.
[00:10:17.200 --> 00:10:20.640]   Isn't it so weird, very tiny, isn't it weird that now from the left,
[00:10:20.640 --> 00:10:23.240]   we are defending the CIA?
[00:10:23.240 --> 00:10:27.720]   No, it's as a black American, as a left-leaning liberal American
[00:10:27.720 --> 00:10:32.920]   to be somehow cheerleading the CIA is at minimum awkward.
[00:10:32.920 --> 00:10:36.600]   And I think Mike's point is super clear.
[00:10:36.600 --> 00:10:39.400]   And the distinction from what Snowden did and what he released
[00:10:39.400 --> 00:10:42.560]   was a massive level of unconstitutional behavior
[00:10:42.560 --> 00:10:46.240]   with domestic spying on millions and millions of people,
[00:10:46.240 --> 00:10:51.000]   just a dragnet of surveillance by Americans
[00:10:51.000 --> 00:10:52.400]   against other Americans.
[00:10:52.400 --> 00:10:55.160]   This is more targeted and thus seemingly better.
[00:10:55.160 --> 00:10:57.040]   I think if there's a surprise in this,
[00:10:57.040 --> 00:11:00.080]   it's not the revelations.
[00:11:00.080 --> 00:11:03.160]   How WikiLeaks has changed in the public mind
[00:11:03.160 --> 00:11:05.640]   and in its focus over the past several years.
[00:11:05.640 --> 00:11:10.000]   This started as a seemingly more journalistic,
[00:11:10.000 --> 00:11:14.880]   more high integrity effort to shine a light on these dark areas
[00:11:14.880 --> 00:11:17.200]   of our democracy that weren't so democratic.
[00:11:17.200 --> 00:11:19.200]   Now it's much more propaganda.
[00:11:19.200 --> 00:11:22.520]   The timing, the correlation, if you look at this in a broader
[00:11:22.520 --> 00:11:24.200]   sweep of what's happening in national politics,
[00:11:24.200 --> 00:11:25.680]   this isn't a politics show, of course,
[00:11:25.680 --> 00:11:28.240]   but I think it's impossible to ignore
[00:11:28.240 --> 00:11:30.560]   that we have a new president who's seemingly at war
[00:11:30.560 --> 00:11:32.160]   with the intelligence community.
[00:11:32.160 --> 00:11:35.440]   And this is a perfect time to undermine the credibility
[00:11:35.440 --> 00:11:38.160]   of the intelligence community when they have been leaking
[00:11:38.160 --> 00:11:41.160]   and raising doubts about how he even ascended to power.
[00:11:41.160 --> 00:11:44.360]   So that's the strongest sort of threat that comes out of this
[00:11:44.360 --> 00:11:47.560]   isn't about like my Alexis snitching on me,
[00:11:47.560 --> 00:11:50.800]   but it's more about my president maybe not upholding
[00:11:50.800 --> 00:11:54.240]   the constitution in the way that he's oath bound to do.
[00:11:54.240 --> 00:11:57.080]   - In other words, WikiLeaks used to look out for the little guy.
[00:11:57.080 --> 00:11:59.120]   Now they look out for the Russian guy.
[00:11:59.120 --> 00:12:01.840]   - Very big guys, at least, yeah.
[00:12:01.840 --> 00:12:05.240]   - The contrast this to how Snowden released his material.
[00:12:05.240 --> 00:12:09.560]   So Snowden had a similar large trove of NSA exploits.
[00:12:09.560 --> 00:12:11.880]   Instead of dumping it on WikiLeaks,
[00:12:11.880 --> 00:12:15.200]   which Assange must have wanted,
[00:12:15.200 --> 00:12:19.680]   he decided instead to contact journalists
[00:12:19.680 --> 00:12:23.240]   and independent and associated with the Washington Post
[00:12:23.240 --> 00:12:25.440]   and the Guardian and the New York Times,
[00:12:25.440 --> 00:12:27.600]   and said, "Here's the trove.
[00:12:27.600 --> 00:12:30.320]   "As journalists, what I'd like you to do is vet this
[00:12:30.320 --> 00:12:32.120]   "and release it safely."
[00:12:32.120 --> 00:12:35.480]   He also strategically did the right thing
[00:12:35.480 --> 00:12:36.840]   because it took a long time.
[00:12:36.840 --> 00:12:38.680]   It took several years for all the material to release.
[00:12:38.680 --> 00:12:41.040]   So it kept our attention for a longer period of time.
[00:12:41.040 --> 00:12:44.360]   It seems likely that by dumping this on WikiLeaks,
[00:12:44.360 --> 00:12:47.200]   it's gonna make a big splash
[00:12:47.200 --> 00:12:49.480]   and then we'll forget it in a month.
[00:12:49.480 --> 00:12:51.800]   - I think we're already almost ready to forget it
[00:12:51.800 --> 00:12:54.880]   because the fact is that these are capabilities,
[00:12:54.880 --> 00:12:56.920]   not things that have actually happened.
[00:12:56.920 --> 00:13:00.760]   It's about individual legitimate surveillance
[00:13:00.760 --> 00:13:03.600]   instead of mass surveillance that's unconstitutional,
[00:13:03.600 --> 00:13:05.680]   theoretically, I mean, they could use it, I guess,
[00:13:05.680 --> 00:13:06.920]   unconstitutionally.
[00:13:06.920 --> 00:13:09.840]   But really, this was designed for impact.
[00:13:09.840 --> 00:13:13.000]   The WikiLeaks seems to have had an agenda
[00:13:13.000 --> 00:13:15.960]   to impact the political conversation.
[00:13:15.960 --> 00:13:18.560]   And whereas the agenda with Snowden
[00:13:18.560 --> 00:13:21.840]   was public understanding of what's really happening.
[00:13:21.840 --> 00:13:24.760]   And so that's really a big difference in how it was leaked
[00:13:24.760 --> 00:13:28.000]   and I think, again, this really harms the reputation
[00:13:28.000 --> 00:13:30.680]   of WikiLeaks among, I think, the majority of people
[00:13:30.680 --> 00:13:31.680]   who are really paying attention.
[00:13:31.680 --> 00:13:33.560]   - There are a couple of issues, though,
[00:13:33.560 --> 00:13:37.680]   that maybe don't reflect well on the CIA.
[00:13:37.680 --> 00:13:41.000]   One, of course, is how long they've known
[00:13:41.000 --> 00:13:43.520]   that these tools have been leaked out.
[00:13:43.520 --> 00:13:47.320]   And, of course, almost all these tools involve exploits
[00:13:47.320 --> 00:13:51.760]   of security flaws that have been previously unreleased
[00:13:51.760 --> 00:13:55.400]   in Google devices and Apple devices,
[00:13:55.400 --> 00:13:58.520]   Microsoft devices, Samsung TVs.
[00:13:58.520 --> 00:14:00.480]   If, for instance, we don't know,
[00:14:00.480 --> 00:14:02.800]   but if the CIA knew about this a year ago,
[00:14:02.800 --> 00:14:05.840]   wouldn't they have a responsibility to tell those companies?
[00:14:05.840 --> 00:14:08.360]   And I'm gonna, well, but I'm gonna, you know,
[00:14:08.360 --> 00:14:10.240]   this is not unprecedented.
[00:14:10.240 --> 00:14:11.680]   - Now, Leo's hilarious.
[00:14:11.680 --> 00:14:13.160]   - I know, I don't expect them to.
[00:14:13.160 --> 00:14:14.640]   One of the reasons they don't, of course,
[00:14:14.640 --> 00:14:15.960]   is 'cause if they let people know,
[00:14:15.960 --> 00:14:17.840]   then they'll patch the holes.
[00:14:17.840 --> 00:14:20.080]   And then if they patch the holes,
[00:14:20.080 --> 00:14:21.920]   they won't be able to use these anymore.
[00:14:21.920 --> 00:14:23.520]   But there is this problem.
[00:14:23.520 --> 00:14:27.320]   Believe it or not, President Obama created a process.
[00:14:27.320 --> 00:14:29.680]   It's called the Equitable, what is it?
[00:14:29.680 --> 00:14:32.320]   The Equitable, I've got it right here.
[00:14:32.320 --> 00:14:33.640]   I can't remember the exact name.
[00:14:33.640 --> 00:14:37.680]   The Vulnerability Equities Process, or VEP.
[00:14:37.680 --> 00:14:40.440]   And this happened a year ago
[00:14:40.440 --> 00:14:43.640]   when a bunch of stuff belonging to the NSA
[00:14:43.640 --> 00:14:45.760]   was leaked out by somebody called the Shadow Brokers.
[00:14:45.760 --> 00:14:48.240]   There were 15 exploits, including, remember,
[00:14:48.240 --> 00:14:52.840]   the Cisco Juniper, Fortinet, Zero Days.
[00:14:52.840 --> 00:14:57.000]   And the question was, should the NSA have warned Cisco
[00:14:57.000 --> 00:14:58.840]   once they knew this stuff was released?
[00:14:58.840 --> 00:15:03.120]   As a result, in January of 2014, President Obama
[00:15:03.120 --> 00:15:05.560]   made it government policy, a policy, by the way,
[00:15:05.560 --> 00:15:07.880]   that's probably been honored more by ignoring it
[00:15:07.880 --> 00:15:09.400]   than by doing it.
[00:15:09.400 --> 00:15:11.920]   But a government policy disclosed by default
[00:15:11.920 --> 00:15:13.800]   any new vulnerability.
[00:15:13.800 --> 00:15:16.760]   If an agency finds a zero day,
[00:15:16.760 --> 00:15:18.240]   they have to believe it or not.
[00:15:18.240 --> 00:15:20.560]   And you're right, laugh, Berit, don't they?
[00:15:20.560 --> 00:15:21.560]   But this is the policy.
[00:15:21.560 --> 00:15:22.840]   They have to argue their case
[00:15:22.840 --> 00:15:25.720]   through the Vulnerability Equities Process
[00:15:25.720 --> 00:15:27.280]   to an Equities Review Board,
[00:15:27.280 --> 00:15:30.240]   chaired by the National Security Council,
[00:15:30.240 --> 00:15:32.560]   and attended by representatives of other agencies.
[00:15:32.560 --> 00:15:35.280]   The whole idea being, you've got to justify
[00:15:35.280 --> 00:15:37.280]   keeping this a secret,
[00:15:37.280 --> 00:15:39.640]   because there's a risk to the American people
[00:15:39.640 --> 00:15:41.720]   that these vulnerabilities would be used against them.
[00:15:41.720 --> 00:15:45.600]   What a concept to actually protect the American people
[00:15:45.600 --> 00:15:48.120]   above and beyond the protection of the aims
[00:15:48.120 --> 00:15:50.760]   and struggles of one's own organization.
[00:15:50.760 --> 00:15:54.040]   And this is, I think that this is one of the biggest issues
[00:15:54.040 --> 00:15:55.920]   that we should be talking about in all this leaks.
[00:15:55.920 --> 00:15:59.680]   What is the responsibility of federal agencies
[00:15:59.680 --> 00:16:02.200]   in protecting the American people from espionage?
[00:16:02.200 --> 00:16:03.560]   I mean, if you think about the relationship
[00:16:03.560 --> 00:16:05.920]   that technology has had with China,
[00:16:05.920 --> 00:16:08.200]   it's been, to a very large extent,
[00:16:08.200 --> 00:16:11.040]   a question of the Chinese government
[00:16:11.040 --> 00:16:13.500]   systematically stealing US tech secrets,
[00:16:13.500 --> 00:16:16.740]   everything from spy planes to chip technologies,
[00:16:16.740 --> 00:16:21.740]   and it's just a wholesale theft of all kinds of trade secrets.
[00:16:21.740 --> 00:16:25.560]   So what has the government done
[00:16:25.560 --> 00:16:27.040]   to protect the American people
[00:16:27.040 --> 00:16:29.720]   and the American economy from this theft?
[00:16:29.720 --> 00:16:31.120]   Very little, I think.
[00:16:31.120 --> 00:16:34.180]   And that should be a big controversial point.
[00:16:34.180 --> 00:16:36.720]   - One of the things that I think is the biggest issue
[00:16:36.720 --> 00:16:39.860]   towards that end is that a lot of our politicians
[00:16:39.860 --> 00:16:42.300]   in this country are Luddites.
[00:16:42.300 --> 00:16:45.000]   They don't use technology, they don't like it,
[00:16:45.000 --> 00:16:48.560]   they have their AIDS use technology,
[00:16:48.560 --> 00:16:50.100]   they run their Twitter accounts for them,
[00:16:50.100 --> 00:16:52.800]   they don't really have an understanding
[00:16:52.800 --> 00:16:55.160]   of a lot of the technology that surrounds them
[00:16:55.160 --> 00:16:56.120]   on a daily basis.
[00:16:56.120 --> 00:16:58.880]   And the people that end up shaping that policy
[00:16:58.880 --> 00:17:01.480]   are people who give them money to then,
[00:17:01.480 --> 00:17:04.760]   for their campaigns, for good or bad.
[00:17:04.760 --> 00:17:07.080]   And they end up saying, well, this is how really
[00:17:07.080 --> 00:17:07.920]   we should do it.
[00:17:07.920 --> 00:17:11.320]   - And that's why Baratunde is gonna run for the Senate.
[00:17:11.320 --> 00:17:15.020]   How Franken did it, funny people can run for the Senate.
[00:17:15.020 --> 00:17:16.340]   - Funny people do it every day,
[00:17:16.340 --> 00:17:18.340]   but they're not funny on purpose.
[00:17:18.340 --> 00:17:23.100]   The tag team on both Mike and Ashley,
[00:17:23.100 --> 00:17:26.620]   I think if you take the alarmism
[00:17:26.620 --> 00:17:29.740]   around the Muslim ban, the travel ban,
[00:17:29.740 --> 00:17:32.260]   and this alleged effort to protect the American people
[00:17:32.260 --> 00:17:33.380]   using your language, Mike,
[00:17:33.380 --> 00:17:36.020]   and also the language of the Constitution conveniently,
[00:17:36.020 --> 00:17:39.700]   if we were serious about protecting US citizens,
[00:17:39.700 --> 00:17:42.060]   US residents, people within the contiguous United States
[00:17:42.060 --> 00:17:43.620]   plus Hawaii and Alaska,
[00:17:43.620 --> 00:17:47.820]   we would take these threats of the cyber far more seriously.
[00:17:47.820 --> 00:17:52.420]   And it would be second nature and non-controversial
[00:17:52.420 --> 00:17:55.300]   and obvious to alert the public,
[00:17:55.300 --> 00:17:57.880]   to alert companies to make sure we are safe
[00:17:57.880 --> 00:18:00.820]   because the actual damages, loss of life,
[00:18:00.820 --> 00:18:03.260]   financial impact, negative financial impact,
[00:18:03.260 --> 00:18:06.620]   from tech-based attacks is much higher
[00:18:06.620 --> 00:18:09.100]   than bombs in public spaces.
[00:18:09.100 --> 00:18:11.660]   And this idea that we're gonna block people
[00:18:11.660 --> 00:18:13.660]   from six or seven majority Muslim countries
[00:18:13.660 --> 00:18:16.420]   to keep us safe, meanwhile,
[00:18:16.420 --> 00:18:19.020]   we are allowing exploits in our tech infrastructure
[00:18:19.020 --> 00:18:21.500]   to allow trade secrets, personal information,
[00:18:21.500 --> 00:18:25.180]   doxing, blackmail, and whatever else is going on,
[00:18:25.180 --> 00:18:28.900]   unfettered reveals the lie of what it means
[00:18:28.900 --> 00:18:31.860]   to have the priority of the executive defense
[00:18:31.860 --> 00:18:32.860]   of the American people.
[00:18:32.860 --> 00:18:35.260]   So I think they're connected
[00:18:35.260 --> 00:18:37.580]   and a true defense of the republic
[00:18:37.580 --> 00:18:40.300]   would be a tech defense, a cyber defense,
[00:18:40.300 --> 00:18:41.660]   and that's not what's happening
[00:18:41.660 --> 00:18:43.180]   if we're sitting on these exploits
[00:18:43.180 --> 00:18:45.060]   and not informing people how to protect themselves.
[00:18:45.060 --> 00:18:46.460]   - 2012, there to me.
[00:18:46.460 --> 00:18:48.500]   - Do you think that, well,
[00:18:48.500 --> 00:18:50.540]   I guess this goes to everybody.
[00:18:50.540 --> 00:18:51.940]   Do you think that the question is like,
[00:18:51.940 --> 00:18:56.180]   do tech companies need to have or work with our government
[00:18:56.180 --> 00:18:58.700]   to have a small team, let's say,
[00:18:58.700 --> 00:19:01.540]   of security experts that have clearance
[00:19:01.540 --> 00:19:04.580]   that can then interact with them
[00:19:04.580 --> 00:19:07.380]   and be able to get information without,
[00:19:07.380 --> 00:19:09.180]   but then it's so hard because it's like,
[00:19:09.180 --> 00:19:10.820]   and then you have to worry about like,
[00:19:10.820 --> 00:19:14.820]   well, our company's giving away certain pieces of data
[00:19:14.820 --> 00:19:15.940]   that they feel is okay.
[00:19:15.940 --> 00:19:18.620]   It's like this really strange kind of gray area
[00:19:18.620 --> 00:19:19.660]   that we haven't figured out yet,
[00:19:19.660 --> 00:19:22.860]   but do you think tech companies should have some role
[00:19:22.860 --> 00:19:25.340]   in those intelligence communities
[00:19:25.340 --> 00:19:28.020]   that's a little bit different and a little bit more,
[00:19:28.020 --> 00:19:33.020]   I guess, direct and transparent than what we have now?
[00:19:33.020 --> 00:19:34.700]   - More transparent, yes.
[00:19:34.700 --> 00:19:37.100]   More direct, very skeptical
[00:19:37.100 --> 00:19:38.340]   because the tech companies,
[00:19:38.340 --> 00:19:39.900]   they don't have a lot of credibility
[00:19:39.900 --> 00:19:42.420]   when it comes to their first priority,
[00:19:42.420 --> 00:19:45.860]   which is us as customers and citizens and consumers,
[00:19:45.860 --> 00:19:48.140]   and they abuse our data constantly.
[00:19:48.140 --> 00:19:50.300]   They're selling our stuff up and downstream,
[00:19:50.300 --> 00:19:52.420]   the data brokers, the building profiles
[00:19:52.420 --> 00:19:54.420]   on people who never joined their social networks
[00:19:54.420 --> 00:19:58.660]   to begin with, so they lack a certain moral authority
[00:19:58.660 --> 00:20:02.820]   to fully claim to defend us when they're selling us out,
[00:20:02.820 --> 00:20:04.700]   in both directions, constantly,
[00:20:04.700 --> 00:20:07.420]   because of the ad-based model, like it's all,
[00:20:07.420 --> 00:20:09.180]   I have to tell like a bit of a conspiracy theory,
[00:20:09.180 --> 00:20:11.100]   but I think it's just their business model essentially
[00:20:11.100 --> 00:20:14.660]   forces them to not respect our data
[00:20:14.660 --> 00:20:17.900]   as the basic premise of their profit-making entity.
[00:20:17.900 --> 00:20:19.540]   So it's hard to talk out of the other side of your mouth
[00:20:19.540 --> 00:20:22.380]   about how much you care about consumer privacy and data
[00:20:22.380 --> 00:20:25.660]   when your business model means you sell us out.
[00:20:25.660 --> 00:20:26.660]   - Yeah, that's true.
[00:20:26.660 --> 00:20:29.020]   - One thing we did learn though
[00:20:29.020 --> 00:20:31.700]   is that the CIA has much better codenames than the NSA.
[00:20:31.700 --> 00:20:32.540]   - That's awesome.
[00:20:32.540 --> 00:20:33.380]   (laughs)
[00:20:33.380 --> 00:20:34.220]   - So much better.
[00:20:34.220 --> 00:20:35.340]   - We're being angel, baby.
[00:20:35.340 --> 00:20:36.180]   We've been aging.
[00:20:36.180 --> 00:20:37.020]   - So I didn't know that.
[00:20:37.020 --> 00:20:40.260]   We've been aging, which was the Samsung TV exploit
[00:20:40.260 --> 00:20:42.260]   developed in conjunction with MI5,
[00:20:42.260 --> 00:20:44.020]   the British spy agency,
[00:20:44.020 --> 00:20:45.900]   and the idea was you could put this on a TV.
[00:20:45.900 --> 00:20:48.100]   It's not clear if it was a remote exploit.
[00:20:48.100 --> 00:20:50.140]   It looked more like, best I could tell,
[00:20:50.140 --> 00:20:52.820]   and the information isn't that clear
[00:20:52.820 --> 00:20:54.700]   even in the WikiLeaks documents.
[00:20:54.700 --> 00:20:58.860]   It was designed to sit on an SD card or a thumb drive,
[00:20:58.860 --> 00:21:03.860]   and then when you get access to the subject's premises,
[00:21:03.900 --> 00:21:05.060]   besides-- - Like breaking into their house.
[00:21:05.060 --> 00:21:05.900]   - When you break into the house,
[00:21:05.900 --> 00:21:08.140]   besides putting a bug in the wall and in the light bulbs
[00:21:08.140 --> 00:21:09.940]   and in the phone, you can now put it on the TV.
[00:21:09.940 --> 00:21:11.820]   And the TV, even though it looks to be off,
[00:21:11.820 --> 00:21:16.420]   is still recording audio and video, which is nice, handy.
[00:21:16.420 --> 00:21:17.780]   But that's called Weeping Angel.
[00:21:17.780 --> 00:21:20.540]   What I didn't know is that that's a doctor.
[00:21:20.540 --> 00:21:21.860]   Who reference?
[00:21:21.860 --> 00:21:22.860]   - Oh yeah, don't link-- - Who will?
[00:21:22.860 --> 00:21:23.860]   Creepy episode. - Who will?
[00:21:23.860 --> 00:21:25.020]   - Creepy episode.
[00:21:25.020 --> 00:21:28.700]   - So that's why I think MI5 had more to do this with the CIA.
[00:21:28.700 --> 00:21:30.540]   - But then there's Ricky Bobby, which is a--
[00:21:30.540 --> 00:21:32.180]   - Ricky Bobby from Talladega Nights,
[00:21:32.180 --> 00:21:33.020]   a Will Ferrell reference.
[00:21:33.020 --> 00:21:35.460]   - It's a really American hero, Ricky Bobby.
[00:21:35.460 --> 00:21:36.980]   - What does Ricky Bobby do?
[00:21:36.980 --> 00:21:39.500]   It targets Windows computers.
[00:21:39.500 --> 00:21:41.660]   - It doesn't know what to do with its hands.
[00:21:41.660 --> 00:21:42.940]   (laughing)
[00:21:42.940 --> 00:21:43.780]   - Shake 'em big.
[00:21:43.780 --> 00:21:45.740]   (laughing)
[00:21:45.740 --> 00:21:47.260]   Sweet baby Jesus.
[00:21:47.260 --> 00:21:49.420]   Well-- - I'm gonna laugh about
[00:21:49.420 --> 00:21:50.660]   the erosion of civil liberties.
[00:21:50.660 --> 00:21:51.820]   It's hilarious. - It's like--
[00:21:51.820 --> 00:21:52.660]   - Well, what are you gonna do?
[00:21:52.660 --> 00:21:53.500]   What are you gonna do, baby?
[00:21:53.500 --> 00:21:56.380]   You can't cry for four years.
[00:21:56.380 --> 00:21:57.980]   You gotta sometimes-- - Oh.
[00:21:57.980 --> 00:22:00.700]   - You gotta look up and-- - And not being sarcastic
[00:22:00.700 --> 00:22:02.220]   in that comment, it's hilarious.
[00:22:02.220 --> 00:22:03.380]   - It is.
[00:22:03.380 --> 00:22:04.780]   It absolutely is.
[00:22:04.780 --> 00:22:08.020]   They did have code names, which I thought was interesting,
[00:22:08.020 --> 00:22:13.020]   for Windows itself, for Macintosh and for Linux.
[00:22:13.020 --> 00:22:16.740]   I'm trying to find the code names are hysterical,
[00:22:16.740 --> 00:22:17.820]   but I can't find them now.
[00:22:17.820 --> 00:22:19.460]   They have to do with parties, basically.
[00:22:19.460 --> 00:22:23.240]   It sounds like the CIA is having a very good time.
[00:22:23.240 --> 00:22:26.740]   - Let's all come up with code names for us.
[00:22:26.740 --> 00:22:29.260]   Like, I already have Cessedia, so I'm good.
[00:22:29.260 --> 00:22:31.140]   But like, what do you guys want for code names?
[00:22:31.140 --> 00:22:32.140]   - I said, yeah. - I wanna steal
[00:22:32.140 --> 00:22:33.500]   one of their code names for myself.
[00:22:33.500 --> 00:22:34.500]   - So Windows-- - So, Windows--
[00:22:34.500 --> 00:22:38.060]   - When those code names was bartender,
[00:22:38.060 --> 00:22:39.860]   I guess this is so you can,
[00:22:39.860 --> 00:22:43.340]   when you're communicating with other spooks,
[00:22:43.340 --> 00:22:48.100]   you can talk, you know, the goose is flying high
[00:22:48.100 --> 00:22:51.180]   on the bartender at midnight.
[00:22:51.180 --> 00:22:55.420]   Mac OS was Jukebox and Linux, as everyone knows,
[00:22:55.420 --> 00:22:57.740]   who's in open source, is the dance floor.
[00:22:57.740 --> 00:22:58.940]   (laughing)
[00:22:58.940 --> 00:23:00.820]   - Well, that's where all the crazy stuff goes down.
[00:23:00.820 --> 00:23:02.100]   On the dance floor. - On the dance floor.
[00:23:02.100 --> 00:23:05.060]   - On the dance floor. - And their configuration utilities,
[00:23:05.060 --> 00:23:07.380]   among others, are called Margarita.
[00:23:07.380 --> 00:23:09.140]   - And the Jukebox-- - And Mac OS is like,
[00:23:09.140 --> 00:23:11.260]   a Jukebox closed, it's a closed.
[00:23:11.260 --> 00:23:13.860]   - Oh, it's closed. - Very limited selection
[00:23:13.860 --> 00:23:15.660]   of opportunity, right? - Yeah, look at the selection.
[00:23:15.660 --> 00:23:17.940]   - They're gonna prescribe what music you wanna enjoy
[00:23:17.940 --> 00:23:19.140]   through a Jukebox.
[00:23:19.140 --> 00:23:19.980]   (laughing)
[00:23:19.980 --> 00:23:22.460]   - We've already fought more about this than the CIA has.
[00:23:22.460 --> 00:23:24.860]   - All those software updates just make you wanna get drunk.
[00:23:24.860 --> 00:23:26.260]   - Yeah, there you go. - There you go.
[00:23:26.260 --> 00:23:27.980]   - And the peanuts are free, though, yeah.
[00:23:27.980 --> 00:23:28.980]   - That's right, we should also get--
[00:23:28.980 --> 00:23:31.060]   - You can get barquets. - We should,
[00:23:31.060 --> 00:23:34.660]   this is like some basic trade craft 101 from the CIA,
[00:23:34.660 --> 00:23:37.900]   given you should speak in code, don't speak openly
[00:23:37.900 --> 00:23:39.860]   in even secure channels about what you're talking about,
[00:23:39.860 --> 00:23:40.940]   so we should come up with code names
[00:23:40.940 --> 00:23:42.260]   for all kinds of other stuff, too.
[00:23:42.260 --> 00:23:43.940]   This is a good lesson. - This story broke on Tuesday,
[00:23:43.940 --> 00:23:45.620]   and Steve Gibson, who didn't have time
[00:23:45.620 --> 00:23:46.700]   to really fully review it.
[00:23:46.700 --> 00:23:49.620]   I mean, it's 8,000 plus pages, says he will be talking
[00:23:49.620 --> 00:23:51.980]   about this Tuesday on security now.
[00:23:51.980 --> 00:23:54.620]   And I'm sure he'll look, not from the political point of view,
[00:23:54.620 --> 00:23:56.460]   or the capabilities point of view,
[00:23:56.460 --> 00:23:59.340]   but just look at each of these different exploits
[00:23:59.340 --> 00:24:01.580]   and tell us what they mean.
[00:24:01.580 --> 00:24:04.300]   WikiLeaks, to their credit, did not release code.
[00:24:04.300 --> 00:24:08.820]   They merely released the single page descriptions
[00:24:08.820 --> 00:24:10.660]   of a lot of these-- - Didn't they hint,
[00:24:10.660 --> 00:24:12.540]   what code was coming, though?
[00:24:12.540 --> 00:24:15.100]   - Yeah, WikiLeaks is good at hinting at things
[00:24:15.100 --> 00:24:16.580]   that are coming but never do.
[00:24:16.580 --> 00:24:19.940]   - Right. - And Zane, her last name
[00:24:19.940 --> 00:24:21.460]   always is-- - Too Ficky, too Ficky.
[00:24:21.460 --> 00:24:23.380]   - Too Ficky, too Ficky. - She's great.
[00:24:23.380 --> 00:24:27.060]   - Wrote for the New York Times and helps deflate
[00:24:27.060 --> 00:24:29.340]   the inflated bubble of alarm around this
[00:24:29.340 --> 00:24:31.140]   and just reminding people of how WikiLeaks
[00:24:31.140 --> 00:24:34.020]   has operated in the past with promises to deliver
[00:24:34.020 --> 00:24:35.100]   that never come through.
[00:24:35.100 --> 00:24:36.340]   And they don't need to release code.
[00:24:36.340 --> 00:24:38.900]   They really were trying to affect, again, to Mike's point,
[00:24:38.900 --> 00:24:42.700]   the news cycle, the political conversation.
[00:24:42.700 --> 00:24:44.860]   And we all know you don't need facts
[00:24:44.860 --> 00:24:47.780]   to affect the political conversation, especially these days.
[00:24:47.780 --> 00:24:49.620]   So WikiLeaks is playing the game the way
[00:24:49.620 --> 00:24:50.700]   it's been redesigned.
[00:24:50.700 --> 00:24:52.340]   They're really good at it.
[00:24:52.340 --> 00:24:54.580]   - Wait, wait, wait, wait. - She writes security experts
[00:24:54.580 --> 00:24:57.100]   "I spoke with stressed these techniques
[00:24:57.100 --> 00:25:00.380]   "appear to be mostly known methods.
[00:25:00.380 --> 00:25:01.940]   "Some of them learned from academic
[00:25:01.940 --> 00:25:04.020]   "and other open conferences.
[00:25:04.020 --> 00:25:06.020]   "And that among this trove of exploits
[00:25:06.020 --> 00:25:09.860]   "there were no big surprises or unexpected wizardry."
[00:25:09.860 --> 00:25:13.620]   So the-- - So make that big sense.
[00:25:13.620 --> 00:25:15.420]   I mean, it's like if your phone is compromised,
[00:25:15.420 --> 00:25:17.380]   if your phone is compromised-- - You're screwed.
[00:25:17.380 --> 00:25:19.980]   - Yeah, it's, I mean, everybody knows that.
[00:25:19.980 --> 00:25:21.900]   That's, you know, if your phone's been compromised
[00:25:21.900 --> 00:25:24.740]   then a lot of these methods have to do
[00:25:24.740 --> 00:25:27.060]   with having physical access to the device.
[00:25:27.060 --> 00:25:29.340]   Like there's so many of them that need physical access.
[00:25:29.340 --> 00:25:32.260]   So, you know, the thing that I worry the most about
[00:25:32.260 --> 00:25:35.620]   is the CIA uses these techniques for foreign agents
[00:25:35.620 --> 00:25:38.700]   and sometimes they'll sweep up US citizens in that.
[00:25:38.700 --> 00:25:40.600]   And that's not good.
[00:25:40.600 --> 00:25:44.660]   But I worry about foreign agents using this
[00:25:44.660 --> 00:25:48.860]   on US citizens who do not have up-to-date OSs
[00:25:48.860 --> 00:25:50.380]   out-of-date smartphones. - Right.
[00:25:50.380 --> 00:25:52.180]   - Poor security tech. - You know who's using
[00:25:52.180 --> 00:25:53.460]   an out-of-date smartphone? - Like somebody I know
[00:25:53.460 --> 00:25:55.380]   in the White House. - Yeah, he's using
[00:25:55.380 --> 00:25:58.140]   a Galaxy S3 as far as we can tell.
[00:25:58.140 --> 00:26:00.140]   I think it was, you guys had seen how to figure that out
[00:26:00.140 --> 00:26:02.420]   by zooming in center enhanced.
[00:26:02.420 --> 00:26:03.820]   - We said enhanced a lot.
[00:26:03.820 --> 00:26:05.260]   Yeah, there was a lot of enhancing.
[00:26:05.260 --> 00:26:06.260]   - Oh, like a spriture bird. - Yeah.
[00:26:06.260 --> 00:26:08.540]   - And of course, if you look it up,
[00:26:08.540 --> 00:26:10.620]   the S3 can't get past KitKat.
[00:26:10.620 --> 00:26:13.220]   It's using a very old version of Android
[00:26:13.220 --> 00:26:15.940]   that is in fact unsafe.
[00:26:15.940 --> 00:26:16.940]   - Yeah. - And it's just,
[00:26:16.940 --> 00:26:18.260]   that's the thing that worries me.
[00:26:18.260 --> 00:26:19.780]   I mean, it's like, I look at all of this
[00:26:19.780 --> 00:26:23.060]   and all I can think is there are people in our government
[00:26:23.060 --> 00:26:26.220]   who again are not tech savvy people
[00:26:26.220 --> 00:26:29.260]   and they use old cell phones with not updated
[00:26:29.260 --> 00:26:31.980]   operating systems and very unsafe practices.
[00:26:31.980 --> 00:26:34.660]   And that is the thing that concerns me the most
[00:26:34.660 --> 00:26:36.140]   about this Vault 7 dump.
[00:26:36.140 --> 00:26:38.980]   I mean, I do have concerns about obviously
[00:26:38.980 --> 00:26:41.980]   civil liberties and our privacy and all of these things.
[00:26:41.980 --> 00:26:45.420]   But to me, the big fear on my part,
[00:26:45.420 --> 00:26:48.540]   at least in my opinion, is that we have so many
[00:26:48.540 --> 00:26:51.500]   government officials who have phones
[00:26:51.500 --> 00:26:53.260]   that are very old and unsecured.
[00:26:53.260 --> 00:26:54.100]   - Yeah.
[00:26:54.100 --> 00:26:58.740]   So again, don't worry, Signal is still secure.
[00:26:58.740 --> 00:27:00.180]   WhatsApp is still secure,
[00:27:00.180 --> 00:27:02.180]   but the president's tweet phone is not.
[00:27:02.180 --> 00:27:03.020]   (laughing)
[00:27:03.020 --> 00:27:04.540]   - It's just not. - It's just not.
[00:27:04.540 --> 00:27:07.020]   Oh, actually, if you're one of the leakers
[00:27:07.020 --> 00:27:09.220]   in the White House who's using,
[00:27:09.220 --> 00:27:11.340]   what is it, collide, confide?
[00:27:11.340 --> 00:27:13.060]   - Confide. - Confide.
[00:27:13.060 --> 00:27:14.660]   Apparently that has been hacked.
[00:27:14.660 --> 00:27:16.300]   - That's right. - That is insecure.
[00:27:16.300 --> 00:27:18.420]   - That's not true. - So stop using
[00:27:18.420 --> 00:27:20.100]   that and go back to Signal.
[00:27:20.100 --> 00:27:21.740]   - You're gonna get spicy timed.
[00:27:21.740 --> 00:27:22.580]   - Hey, watch out.
[00:27:22.580 --> 00:27:25.940]   - The real problem with confide is not so much
[00:27:25.940 --> 00:27:27.900]   that a third party can intercept it,
[00:27:27.900 --> 00:27:30.340]   but the people who confide have access to the keys.
[00:27:30.340 --> 00:27:33.020]   And so they could either under-governed subpoena
[00:27:33.020 --> 00:27:34.860]   or a rogue employer, just 'cause they felt like it.
[00:27:34.860 --> 00:27:35.980]   Look at your messages.
[00:27:35.980 --> 00:27:37.260]   - Or because they got hacked.
[00:27:37.260 --> 00:27:38.660]   - Or 'cause they got hacked, right?
[00:27:38.660 --> 00:27:39.500]   - Right. - Right?
[00:27:39.500 --> 00:27:41.900]   Whoever has the master key ring is susceptible
[00:27:41.900 --> 00:27:43.740]   to compromise. - And how much do we know
[00:27:43.740 --> 00:27:46.420]   about confide as a company where they're located?
[00:27:46.420 --> 00:27:47.660]   Nothing, I mean, we know nothing.
[00:27:47.660 --> 00:27:49.180]   - I don't know why that became the standard
[00:27:49.180 --> 00:27:50.620]   for White House leakers.
[00:27:50.620 --> 00:27:51.980]   Is it really, it may not even be.
[00:27:51.980 --> 00:27:54.180]   It's just what I hear on this street.
[00:27:54.180 --> 00:27:55.380]   - I'm not on the board, yeah.
[00:27:55.380 --> 00:27:57.020]   (laughing)
[00:27:57.020 --> 00:27:58.780]   - So the short hasn't been supported.
[00:27:58.780 --> 00:27:59.780]   - Some people have said that.
[00:27:59.780 --> 00:28:00.620]   - I've heard.
[00:28:00.620 --> 00:28:02.500]   Many people say, yeah.
[00:28:02.500 --> 00:28:04.500]   - The CIA is being real CIA right now.
[00:28:04.500 --> 00:28:07.060]   That's basically-- - CIA, BCIA.
[00:28:07.060 --> 00:28:08.540]   - Yeah, yeah.
[00:28:08.540 --> 00:28:10.900]   CIA, real CIA.
[00:28:10.900 --> 00:28:13.100]   - I would say-- - No, you've gotta think
[00:28:13.100 --> 00:28:15.020]   that every hacker in the world is trying to figure out
[00:28:15.020 --> 00:28:18.780]   how to hack, if he really, if President Trump is using an S3,
[00:28:18.780 --> 00:28:20.420]   how to hack that phone?
[00:28:20.420 --> 00:28:23.060]   Not because they wanna see the tweets before they're posted,
[00:28:23.060 --> 00:28:27.220]   but did, for instance, the Secret Service take out
[00:28:27.220 --> 00:28:28.100]   anything else?
[00:28:28.100 --> 00:28:29.420]   Is there still a camera?
[00:28:29.420 --> 00:28:31.140]   Or is there a little piece of duct tape over it?
[00:28:31.140 --> 00:28:32.460]   Is there a microphone?
[00:28:32.460 --> 00:28:33.460]   Or did that get snipped?
[00:28:33.460 --> 00:28:37.980]   I mean, what exactly capabilities did that phone have?
[00:28:37.980 --> 00:28:40.020]   And I've gotta think at this point,
[00:28:40.020 --> 00:28:41.020]   it's secured, whatever it is.
[00:28:41.020 --> 00:28:42.980]   Or we would have heard something by now, right?
[00:28:42.980 --> 00:28:43.820]   I don't know.
[00:28:43.820 --> 00:28:45.020]   - Is it a jitterbug?
[00:28:45.020 --> 00:28:46.340]   Is that, we just give him that?
[00:28:46.340 --> 00:28:47.900]   - With the big keys. - With the big keys.
[00:28:47.900 --> 00:28:50.380]   - Yeah, yeah, we don't, he needs, he needs a cha-cha.
[00:28:50.380 --> 00:28:52.740]   Let's go get him one of the HTC cha-cha.
[00:28:52.740 --> 00:28:54.380]   It's only, but with a Twitter button
[00:28:54.380 --> 00:28:55.460]   instead of a Facebook button.
[00:28:55.460 --> 00:28:57.780]   - It's also possible that there's no risk there
[00:28:57.780 --> 00:28:59.220]   because we know he's at Mar-a-Lago,
[00:28:59.220 --> 00:29:00.900]   so we know his location.
[00:29:00.900 --> 00:29:01.940]   And what's gonna happen?
[00:29:01.940 --> 00:29:03.700]   What's some hacker gonna do?
[00:29:03.700 --> 00:29:05.980]   Tweet crazy things from the phone?
[00:29:05.980 --> 00:29:07.340]   - We would, we would be-- - How would we know
[00:29:07.340 --> 00:29:08.700]   that it was even hacked?
[00:29:08.700 --> 00:29:10.420]   - Oh, Lord, I-- - Sorry.
[00:29:10.420 --> 00:29:11.820]   - Walked right into that one.
[00:29:13.260 --> 00:29:15.380]   - All right, we're gonna take a little bit of a break.
[00:29:15.380 --> 00:29:18.180]   This is gonna be a fun, this is a fun panel.
[00:29:18.180 --> 00:29:20.460]   Mike Elgin is here, he writes, of course,
[00:29:20.460 --> 00:29:22.340]   for Computer World and--
[00:29:22.340 --> 00:29:23.460]   - The company of Fast.
[00:29:23.460 --> 00:29:25.780]   - Info World, Fast of the company.
[00:29:25.780 --> 00:29:27.860]   You also see him on Google+ still?
[00:29:27.860 --> 00:29:28.860]   No? - Sure.
[00:29:28.860 --> 00:29:30.060]   - No. - Oh yeah, really?
[00:29:30.060 --> 00:29:31.420]   - Yeah, okay.
[00:29:31.420 --> 00:29:33.700]   - I love Google+, after everybody left,
[00:29:33.700 --> 00:29:35.380]   it got really peaceful.
[00:29:35.380 --> 00:29:38.260]   It was always the best social network
[00:29:38.260 --> 00:29:40.620]   as a social network, but not the best place
[00:29:40.620 --> 00:29:42.100]   to find people. - Right.
[00:29:42.100 --> 00:29:44.740]   - Which is amazing because you use the word social,
[00:29:44.740 --> 00:29:46.820]   but then also said it was hard to find people.
[00:29:46.820 --> 00:29:49.980]   So I'd like to just point out that semantic disconnect there.
[00:29:49.980 --> 00:29:50.820]   - It seems like-- - Are you like,
[00:29:50.820 --> 00:29:51.560]   I am liking-- - They feel social
[00:29:51.560 --> 00:29:52.400]   those towns. - First people,
[00:29:52.400 --> 00:29:54.140]   Smith of Google+. (laughing)
[00:29:54.140 --> 00:29:55.140]   Just you and your dog.
[00:29:55.140 --> 00:29:57.940]   - Just having his dog wandering through the landscape.
[00:29:57.940 --> 00:29:59.220]   It goes to-- - It's spacious.
[00:29:59.220 --> 00:30:00.420]   - He goes home at night,
[00:30:00.420 --> 00:30:02.380]   'cause that's when the scary people come out.
[00:30:02.380 --> 00:30:05.980]   Actually, David Bryn, who's a science fiction writer,
[00:30:05.980 --> 00:30:08.020]   posts there a lot, Lauren Weinstein.
[00:30:08.020 --> 00:30:10.500]   There's great photographers, Bakers.
[00:30:10.500 --> 00:30:11.500]   - There. - There.
[00:30:11.500 --> 00:30:13.620]   - It's not, it's nice now.
[00:30:13.620 --> 00:30:16.340]   - If you have an obscure hobby, it's great.
[00:30:16.340 --> 00:30:18.860]   Because I guarantee you that your obscure hobby
[00:30:18.860 --> 00:30:21.340]   is gonna have an active community on Google+.
[00:30:21.340 --> 00:30:22.660]   - Like look, here's the Geeks community,
[00:30:22.660 --> 00:30:26.380]   70,000 members, foodies online, 74,000 members.
[00:30:26.380 --> 00:30:28.220]   - And there are literally thousands
[00:30:28.220 --> 00:30:29.980]   of food related communities.
[00:30:29.980 --> 00:30:30.820]   - Yeah.
[00:30:30.820 --> 00:30:34.340]   - There's like 100 bread baking communities.
[00:30:34.340 --> 00:30:36.300]   - Isn't that really where social media is best?
[00:30:36.300 --> 00:30:38.020]   Where it's not a massive people,
[00:30:38.020 --> 00:30:40.900]   but it's communities of narrow interest.
[00:30:40.900 --> 00:30:45.300]   - Anything, so I like to see it as a cross between Reddit
[00:30:45.300 --> 00:30:48.300]   and Instagram or something like that.
[00:30:48.300 --> 00:30:52.300]   Reddit, what's great about Reddit is very narrowly categorized.
[00:30:52.300 --> 00:30:55.900]   So you join a community that talks about some specific thing.
[00:30:55.900 --> 00:30:57.300]   And that's all that you want.
[00:30:57.300 --> 00:30:58.140]   - That's kind of what you want.
[00:30:58.140 --> 00:31:00.020]   - And Google+ is good for that kind of thing as well,
[00:31:00.020 --> 00:31:02.380]   but it's more visual instead of looking like--
[00:31:02.380 --> 00:31:03.700]   - We're also gonna see a picturesque--
[00:31:03.700 --> 00:31:05.300]   - Pinserist with words.
[00:31:05.300 --> 00:31:07.100]   - Yeah, in fact, doesn't it look a little like picturesque
[00:31:07.100 --> 00:31:08.460]   with words, yeah.
[00:31:08.460 --> 00:31:10.060]   We're also gonna see a picture of Adam West
[00:31:10.060 --> 00:31:12.420]   and Yvonne Craig on the set of Batman 1968.
[00:31:12.420 --> 00:31:13.260]   You're not.
[00:31:13.260 --> 00:31:14.460]   - Probably on Instagram.
[00:31:14.460 --> 00:31:16.020]   I'm just gonna take a while to guess.
[00:31:16.020 --> 00:31:17.540]   - Okay, all right, all right.
[00:31:17.540 --> 00:31:21.700]   God, I'm trying to give these guys some credit here.
[00:31:21.700 --> 00:31:23.100]   - I don't know that Google needs your help.
[00:31:23.100 --> 00:31:23.940]   I think they're doing--
[00:31:23.940 --> 00:31:24.780]   - They don't need my help.
[00:31:24.780 --> 00:31:25.620]   That's a great picture.
[00:31:25.620 --> 00:31:26.860]   - I think Google+ might need your help,
[00:31:26.860 --> 00:31:27.740]   but maybe not Google.
[00:31:27.740 --> 00:31:28.980]   - Yeah, yeah.
[00:31:28.980 --> 00:31:30.540]   - Why is he writing a stingray?
[00:31:30.540 --> 00:31:32.300]   That's why is he wearing a bathrobe?
[00:31:32.300 --> 00:31:33.740]   He's hiding that magnificent costume.
[00:31:33.740 --> 00:31:35.380]   - It gets chilly in that,
[00:31:35.380 --> 00:31:36.420]   it's chilly in that leotard.
[00:31:36.420 --> 00:31:37.900]   - The bat leotard?
[00:31:37.900 --> 00:31:38.740]   - Yep.
[00:31:38.740 --> 00:31:39.580]   - Also with his-- - It's real cold.
[00:31:39.580 --> 00:31:41.100]   - Let me try it again.
[00:31:41.100 --> 00:31:42.940]   Asha, asha.
[00:31:42.940 --> 00:31:44.340]   No, I can't say your first name.
[00:31:44.340 --> 00:31:45.180]   - You can do that.
[00:31:45.180 --> 00:31:46.340]   - That was nice, bye.
[00:31:46.340 --> 00:31:48.580]   - Ashley, ascheta.
[00:31:48.580 --> 00:31:49.420]   - Yes.
[00:31:49.420 --> 00:31:50.260]   - That was good.
[00:31:50.260 --> 00:31:52.060]   Ashley, ascheta.
[00:31:52.060 --> 00:31:53.020]   Senior editor at CNET,
[00:31:53.020 --> 00:31:54.100]   Baratunde Thurston,
[00:31:54.100 --> 00:31:56.220]   I don't know why I don't have trouble with your name.
[00:31:56.220 --> 00:31:58.340]   - 'Cause I've been around the way so many times now.
[00:31:58.340 --> 00:32:00.660]   I don't know, maybe this is my 12th visit here, 15.
[00:32:00.660 --> 00:32:01.860]   - I love having you on, dude.
[00:32:01.860 --> 00:32:02.700]   I actually-- - You could--
[00:32:02.700 --> 00:32:04.580]   - If I could get you on every time I would.
[00:32:04.580 --> 00:32:05.940]   I just always think you're great.
[00:32:05.940 --> 00:32:07.060]   All three of you.
[00:32:07.060 --> 00:32:07.900]   Thank you for being here.
[00:32:07.900 --> 00:32:09.940]   Our show is brought to you by my mattress.
[00:32:09.940 --> 00:32:12.980]   (laughing)
[00:32:12.980 --> 00:32:14.140]   Hey, you know what?
[00:32:14.140 --> 00:32:15.300]   - Your specific mattress.
[00:32:15.300 --> 00:32:16.140]   - My mattress.
[00:32:16.140 --> 00:32:17.380]   - When we get back,
[00:32:17.380 --> 00:32:19.980]   I wanna talk about this travesty,
[00:32:19.980 --> 00:32:21.420]   known as daylight saving time.
[00:32:21.420 --> 00:32:23.420]   - Yes, let's-- - But polish it.
[00:32:23.420 --> 00:32:25.420]   - Let's get, thank God I had my mattress
[00:32:25.420 --> 00:32:27.740]   'cause I lost an hour of sleep last night,
[00:32:27.740 --> 00:32:30.420]   but fortunately it was an hour on my Casper.
[00:32:30.420 --> 00:32:33.260]   And so I'm very much relaxed
[00:32:33.260 --> 00:32:35.260]   and not as exhausted as I would be.
[00:32:35.260 --> 00:32:37.860]   Casper makes the best darn mattresses
[00:32:37.860 --> 00:32:39.780]   and they sell 'em direct to you
[00:32:39.780 --> 00:32:42.340]   so you don't pay the middle person markup,
[00:32:42.340 --> 00:32:44.340]   the no resellers, no showrooms.
[00:32:44.340 --> 00:32:46.460]   They pass the savings directly onto you.
[00:32:46.460 --> 00:32:48.940]   Casper mattress, it's fun.
[00:32:48.940 --> 00:32:51.060]   On the website, they have the process they went through
[00:32:51.060 --> 00:32:52.980]   and they made hundreds of prototypes.
[00:32:52.980 --> 00:32:54.620]   They're obsessive about this.
[00:32:54.620 --> 00:32:56.540]   They engineered a mattress
[00:32:56.540 --> 00:32:59.300]   that they wanted to give you both support and give.
[00:32:59.300 --> 00:33:00.500]   This is a hard thing to do.
[00:33:00.500 --> 00:33:04.180]   But the great mattress is gonna support you.
[00:33:04.180 --> 00:33:05.340]   You don't want it to sag.
[00:33:05.340 --> 00:33:06.740]   You'll have a bad back in the morning.
[00:33:06.740 --> 00:33:08.980]   But at the same time, you don't want your hip bone
[00:33:08.980 --> 00:33:11.580]   to be like pressing into the thing.
[00:33:11.580 --> 00:33:12.580]   And they found a way.
[00:33:12.580 --> 00:33:16.100]   They made it a combination of supportive memory phones.
[00:33:16.100 --> 00:33:18.820]   So it's got just the right sync, just the right bounce.
[00:33:18.820 --> 00:33:19.900]   It's very breathable.
[00:33:19.900 --> 00:33:22.580]   Look at that, 3,240 hours of testing.
[00:33:22.580 --> 00:33:24.140]   Now that's not that much if you think
[00:33:24.140 --> 00:33:25.740]   they were sleeping on 'em,
[00:33:25.740 --> 00:33:28.660]   but I think that they do testing in other ways as well.
[00:33:28.660 --> 00:33:32.340]   It's breathable too, so you don't get hot.
[00:33:32.340 --> 00:33:33.980]   Now, summertime's coming
[00:33:33.980 --> 00:33:35.980]   and you know the worst thing in the world
[00:33:35.980 --> 00:33:37.300]   is a hot, sweaty night,
[00:33:37.300 --> 00:33:40.900]   but on a Casper you'll always sleep cool.
[00:33:40.900 --> 00:33:43.580]   Provides long lasting comfort and support.
[00:33:43.580 --> 00:33:44.460]   You can buy it online.
[00:33:44.460 --> 00:33:46.420]   Comes in a surprisingly compact box,
[00:33:46.420 --> 00:33:50.460]   which is great for those third floor walkups in Williamsburg.
[00:33:50.460 --> 00:33:53.820]   My son actually, we got him a Casper mattress
[00:33:53.820 --> 00:33:55.940]   for his dorm room and it was easy for him to get it in
[00:33:55.940 --> 00:33:57.380]   and then you open it up and it goes,
[00:33:57.380 --> 00:33:58.220]   (whooshing)
[00:33:58.220 --> 00:33:59.980]   and it becomes this beautiful, comfortable,
[00:33:59.980 --> 00:34:00.980]   luscious mattress.
[00:34:00.980 --> 00:34:02.460]   And I know your reluctance is,
[00:34:02.460 --> 00:34:04.020]   well Leo, I'm not gonna buy a mattress
[00:34:04.020 --> 00:34:05.260]   if I can't try before I buy it.
[00:34:05.260 --> 00:34:06.740]   Well, you can.
[00:34:06.740 --> 00:34:09.620]   Casper offers free delivery and painless returns
[00:34:09.620 --> 00:34:13.500]   for free with a hundred day trial period.
[00:34:13.500 --> 00:34:15.300]   So you can try it for a hundred days
[00:34:15.300 --> 00:34:17.180]   of any time in the first hundred nights.
[00:34:17.180 --> 00:34:18.780]   You say, "Yeah, that's not for me."
[00:34:18.780 --> 00:34:20.740]   You call 'em, they come, they pick it up,
[00:34:20.740 --> 00:34:23.900]   they get it out of your hair and they refund every penny.
[00:34:23.900 --> 00:34:25.980]   So this is so much better than trying it out in the showroom.
[00:34:25.980 --> 00:34:27.500]   You can try it out right now.
[00:34:27.500 --> 00:34:30.140]   Call 'em, get online, get a Casper,
[00:34:30.140 --> 00:34:32.420]   free shipping and returns in the US and Canada
[00:34:32.420 --> 00:34:34.380]   and you will save an additional $50
[00:34:34.380 --> 00:34:37.940]   on your mattress purchase if you go to Casper.com/twit
[00:34:37.940 --> 00:34:42.940]   and use the promo code twitcasper.com/twit promo code
[00:34:42.940 --> 00:34:46.100]   T-W-I-T terms and conditions apply.
[00:34:46.100 --> 00:34:47.080]   But I think you're gonna like it,
[00:34:47.080 --> 00:34:49.720]   Casper.com/twit.
[00:34:49.720 --> 00:34:54.340]   Our friend Clayton Morris is starting a movement
[00:34:54.340 --> 00:34:56.180]   to ban and daylight saving time.
[00:34:56.180 --> 00:34:59.620]   I do this every year and then by two weeks,
[00:34:59.620 --> 00:35:02.060]   we'll have forgotten and we're gonna live with this thing.
[00:35:02.060 --> 00:35:06.740]   There will be tomorrow 24% more heart attacks
[00:35:06.740 --> 00:35:07.980]   because we jumped forward.
[00:35:07.980 --> 00:35:09.860]   24%-- - Wait, really?
[00:35:09.860 --> 00:35:10.700]   - I like to know that.
[00:35:10.700 --> 00:35:12.340]   That's a terrible statistic.
[00:35:12.340 --> 00:35:14.700]   - It kills people.
[00:35:14.700 --> 00:35:18.100]   There will be a dramatic increase in traffic accidents.
[00:35:18.100 --> 00:35:21.820]   More people will put their hand in the drill press
[00:35:21.820 --> 00:35:22.660]   by accident.
[00:35:22.660 --> 00:35:24.380]   No, I'm making that one up.
[00:35:24.380 --> 00:35:25.740]   Probably true. - I was really horrified
[00:35:25.740 --> 00:35:26.580]   by that.
[00:35:26.580 --> 00:35:27.420]   I was like, "Leah, no."
[00:35:27.420 --> 00:35:28.580]   - No, 25% more.
[00:35:28.580 --> 00:35:31.460]   Yeah, I know, I just, but 25% more,
[00:35:31.460 --> 00:35:34.220]   24% more traffic accidents.
[00:35:34.220 --> 00:35:36.860]   It is heart attacks, I mean, heart attacks.
[00:35:36.860 --> 00:35:38.020]   Traffic accidents go up.
[00:35:38.020 --> 00:35:40.940]   Judges, get this.
[00:35:40.940 --> 00:35:43.380]   On the Monday after daylight saving time tomorrow,
[00:35:43.380 --> 00:35:44.820]   do not go to court.
[00:35:44.820 --> 00:35:48.460]   Judges dole out harsher sentences 'cause they're cranky.
[00:35:48.460 --> 00:35:49.860]   - They'll put you away.
[00:35:49.860 --> 00:35:51.140]   - And according to the New Yorker,
[00:35:51.140 --> 00:35:52.820]   employees are more likely to cyber loaf
[00:35:52.820 --> 00:35:54.140]   on the internet on Mondays.
[00:35:54.140 --> 00:35:55.140]   - Wow. - Daylight saving time.
[00:35:55.140 --> 00:35:56.140]   - Well, that's every Monday.
[00:35:56.140 --> 00:35:57.580]   (laughing)
[00:35:57.580 --> 00:35:58.420]   - I was gonna say I was like every Monday.
[00:35:58.420 --> 00:36:00.620]   - And then the funny thing is when we revert,
[00:36:00.620 --> 00:36:03.140]   making the sense that earlier, street crime goes up.
[00:36:03.140 --> 00:36:05.860]   Traffic accidents involving wildlife,
[00:36:05.860 --> 00:36:08.380]   it's the peak time, no laugh.
[00:36:08.380 --> 00:36:10.900]   It's the peak time for deer and elk migration.
[00:36:10.900 --> 00:36:14.020]   In fact, this is true.
[00:36:14.020 --> 00:36:14.820]   I read it in the New Yorker.
[00:36:14.820 --> 00:36:16.100]   They have fact checkers.
[00:36:16.100 --> 00:36:18.060]   Researchers in Australia have calculated
[00:36:18.060 --> 00:36:20.700]   ending daylight savings time there throughout the year.
[00:36:20.700 --> 00:36:24.780]   Would reduce the number of koalas killed by motorists
[00:36:24.780 --> 00:36:26.740]   by 8%.
[00:36:26.740 --> 00:36:27.580]   - That's not gonna help me.
[00:36:27.580 --> 00:36:28.500]   - Well, someone think of the koalas.
[00:36:28.500 --> 00:36:30.300]   - Think of the koalas.
[00:36:31.300 --> 00:36:33.300]   - And by the way, it doesn't save energy.
[00:36:33.300 --> 00:36:35.460]   - And so are your taxes though.
[00:36:35.460 --> 00:36:38.500]   Like if getting rid of daylight savings will lower taxes,
[00:36:38.500 --> 00:36:39.740]   everybody be forward in this country.
[00:36:39.740 --> 00:36:41.420]   - Everybody be in. - Got to sell this
[00:36:41.420 --> 00:36:42.260]   the right way.
[00:36:42.260 --> 00:36:43.420]   - The thing that really bugs me about it
[00:36:43.420 --> 00:36:45.980]   is this such an antiquated idea that we're all marching
[00:36:45.980 --> 00:36:47.820]   in lockstep to the same kind of schedule.
[00:36:47.820 --> 00:36:49.340]   People have all kinds of different schedules.
[00:36:49.340 --> 00:36:50.540]   And by the way, why don't we go ahead
[00:36:50.540 --> 00:36:51.980]   and abolish time zones as well?
[00:36:51.980 --> 00:36:54.820]   Why don't in the airline industry in any kind of aviation,
[00:36:54.820 --> 00:36:57.940]   they have something goes Zulu or what's the real name.
[00:36:57.940 --> 00:36:59.100]   - UTC. - UTC.
[00:36:59.100 --> 00:37:00.900]   We should all just be on UTC.
[00:37:00.900 --> 00:37:02.460]   - No, no, 'cause then you'd be like,
[00:37:02.460 --> 00:37:04.940]   this show would be like two in the morning.
[00:37:04.940 --> 00:37:06.180]   - Exactly, but when you said that,
[00:37:06.180 --> 00:37:07.500]   you wouldn't have to explain it.
[00:37:07.500 --> 00:37:08.620]   You wouldn't have to say, well, if you were there,
[00:37:08.620 --> 00:37:09.460]   it's a different time.
[00:37:09.460 --> 00:37:10.780]   - High vis-a-lour.
[00:37:10.780 --> 00:37:12.660]   - You call it two in the morning, actually.
[00:37:12.660 --> 00:37:14.780]   You just call it 2300.
[00:37:14.780 --> 00:37:16.300]   - Zulu. - Or actually 2200.
[00:37:16.300 --> 00:37:18.100]   - Yeah. - Well, that's another thing.
[00:37:18.100 --> 00:37:21.140]   'Cause I have to explain our time,
[00:37:21.140 --> 00:37:24.860]   because even though we do this show at 3 p.m. Pacific,
[00:37:24.860 --> 00:37:28.540]   that was 2300 UTC, but now we've changed what Pacific is.
[00:37:28.540 --> 00:37:30.780]   So the people in England who haven't changed yet
[00:37:30.780 --> 00:37:32.580]   have to know the show starts an hour earlier,
[00:37:32.580 --> 00:37:33.900]   and then their time will change.
[00:37:33.900 --> 00:37:35.340]   It's just-- - And there's some places
[00:37:35.340 --> 00:37:36.780]   that have a half an hour difference
[00:37:36.780 --> 00:37:38.100]   or like an hour and a half difference.
[00:37:38.100 --> 00:37:39.780]   - Well, those places shouldn't exist, first of all.
[00:37:39.780 --> 00:37:40.620]   They seem-- - Yeah.
[00:37:40.620 --> 00:37:41.540]   - They were asking for it.
[00:37:41.540 --> 00:37:42.620]   But I think-- - Just get rid of those.
[00:37:42.620 --> 00:37:44.260]   - I've been monitoring the chat room,
[00:37:44.260 --> 00:37:46.060]   and I'm so sorry to be so delayed,
[00:37:46.060 --> 00:37:47.860]   and given the chat room a shout out,
[00:37:47.860 --> 00:37:50.620]   someone over there, and maybe many,
[00:37:50.620 --> 00:37:52.420]   have a great idea, abolish daylight savings,
[00:37:52.420 --> 00:37:53.820]   and the electoral college.
[00:37:53.820 --> 00:37:56.700]   I would keep time, Zulu, if you were dealing with the electoral college.
[00:37:56.700 --> 00:37:59.100]   Okay, you get one thing for the farmers and one thing not.
[00:37:59.100 --> 00:38:00.460]   There you go, that's perfect.
[00:38:00.460 --> 00:38:02.700]   - Everybody can get something out of it, that's cool.
[00:38:02.700 --> 00:38:04.420]   - I just wanna know what the,
[00:38:04.420 --> 00:38:07.260]   give me a short list of honest benefits
[00:38:07.260 --> 00:38:10.180]   that I get as a person at a daylight saving time,
[00:38:10.180 --> 00:38:13.220]   'cause I can't find any.
[00:38:13.220 --> 00:38:15.980]   - Even the farmers, it was originally a save energy,
[00:38:15.980 --> 00:38:18.660]   but as it turns out, studies have shown it doesn't save energy
[00:38:18.660 --> 00:38:21.100]   'cause people spend more time with the air conditioning.
[00:38:21.100 --> 00:38:23.780]   And besides, yeah, you turn off the lights at the office,
[00:38:23.780 --> 00:38:25.180]   but you turn them on at home.
[00:38:25.180 --> 00:38:26.020]   So it doesn't-- - Turn them on at home.
[00:38:26.020 --> 00:38:27.260]   - It's a net zero.
[00:38:27.260 --> 00:38:30.220]   People said it's for the farmers.
[00:38:30.220 --> 00:38:31.580]   Well, I can tell you, we're in dairy country.
[00:38:31.580 --> 00:38:34.660]   The farmers hate it because the cows do not honor daylight saving time.
[00:38:34.660 --> 00:38:36.380]   - Or the koalas. - No, they don't know.
[00:38:36.380 --> 00:38:37.780]   They're not wearing watches. - The cows are saying,
[00:38:37.780 --> 00:38:38.780]   what are you doing here? - Wow.
[00:38:38.780 --> 00:38:40.260]   - It's not time. - Yeah.
[00:38:40.260 --> 00:38:42.860]   - I don't wanna be milked. - But wait,
[00:38:42.860 --> 00:38:45.540]   can I just be super simple minded about this for a moment?
[00:38:45.540 --> 00:38:47.660]   It's called daylight savings.
[00:38:47.660 --> 00:38:50.300]   Are we not saving daylight? - No, stay like saving.
[00:38:50.300 --> 00:38:51.620]   It's just one.
[00:38:51.620 --> 00:38:55.580]   I have a local radio DJ who is super adamant about this.
[00:38:55.580 --> 00:38:56.420]   - It's not just-- - It's not just--
[00:38:56.420 --> 00:38:57.260]   - It's not just-- - It's not just saving--
[00:38:57.260 --> 00:38:58.160]   - It's not just saving-- - You're just not saving--
[00:38:58.160 --> 00:38:59.200]   - It's actually-- - Saving daylight savings time.
[00:38:59.200 --> 00:39:00.040]   - It's adamant. - It's good.
[00:39:00.040 --> 00:39:00.880]   It's adamant.
[00:39:00.880 --> 00:39:03.220]   It's saving, there's only one. - I'm obsessed with savings.
[00:39:03.220 --> 00:39:05.260]   - We're only one saving. - Because I'm thinking about CASPER,
[00:39:05.260 --> 00:39:07.420]   I'm thinking about tax refunds, because it's coming through.
[00:39:07.420 --> 00:39:09.860]   - You're saving daylight. - Now, we may, finally,
[00:39:09.860 --> 00:39:11.860]   'cause I've been wailing about this for years.
[00:39:11.860 --> 00:39:15.500]   This, by the way, wasn't a national thing until 1966.
[00:39:15.500 --> 00:39:18.940]   So this did not become common in the United States until 1966.
[00:39:18.940 --> 00:39:20.900]   - People were on LSD in 1966. - What do they know?
[00:39:20.900 --> 00:39:22.980]   - There you go. - That's exactly why it happens to--
[00:39:23.820 --> 00:39:25.860]   - This country came through a lot of things late,
[00:39:25.860 --> 00:39:27.740]   like women voting, and black people having the right
[00:39:27.740 --> 00:39:29.340]   to walk down the street in the east.
[00:39:29.340 --> 00:39:33.340]   So I wouldn't knock lateness as a real thing against it.
[00:39:33.340 --> 00:39:34.860]   We gotta choose another problem with the euro.
[00:39:34.860 --> 00:39:37.980]   - But I think that decade, we can also attribute to,
[00:39:37.980 --> 00:39:41.900]   I mean, Fantasia, I think there was just a lot of drug use
[00:39:41.900 --> 00:39:43.300]   happening in the country. - Fantasia.
[00:39:43.300 --> 00:39:45.980]   - Just be able to contribute to saving time.
[00:39:45.980 --> 00:39:47.980]   - Incredible hippopotamuses and tutus.
[00:39:47.980 --> 00:39:49.820]   How? - How the LSD can explain it.
[00:39:49.820 --> 00:39:51.340]   - So apparently, at the state level,
[00:39:51.340 --> 00:39:53.540]   there are currently two dozen bills pending.
[00:39:53.540 --> 00:39:56.700]   Legislators in New Hampshire, Maine and Rhode Island,
[00:39:56.700 --> 00:40:00.860]   for instance, have suggested permanently moving New England
[00:40:00.860 --> 00:40:03.860]   from Eastern Standard Time to Atlantic Standard Time.
[00:40:03.860 --> 00:40:07.220]   They would be one hour ahead of New York
[00:40:07.220 --> 00:40:10.140]   and in sync with Nova Scotia and Labrador.
[00:40:10.140 --> 00:40:10.980]   - Oh, God.
[00:40:10.980 --> 00:40:13.820]   - Do you want to see them let them go, including from time?
[00:40:13.820 --> 00:40:16.340]   - And New Hampshire bills stipulates
[00:40:16.340 --> 00:40:19.580]   that it goes into effect only if Massachusetts does it too.
[00:40:19.580 --> 00:40:21.260]   Well, I'm not gonna do it.
[00:40:21.260 --> 00:40:23.660]   - If Massachusetts does it too, it's crazy.
[00:40:23.660 --> 00:40:26.420]   - I just, can't we, do we all want to just be free of time?
[00:40:26.420 --> 00:40:27.620]   Like time constraints?
[00:40:27.620 --> 00:40:28.460]   - Yeah, now we're talking, actually.
[00:40:28.460 --> 00:40:30.020]   - Just get rid of the concept of time.
[00:40:30.020 --> 00:40:32.140]   - Did the swatch create a swatch time
[00:40:32.140 --> 00:40:32.940]   and internet time or some kind?
[00:40:32.940 --> 00:40:34.460]   - Yeah, everybody ignored it.
[00:40:34.460 --> 00:40:36.060]   - Yeah, that was a terrible marketing.
[00:40:36.060 --> 00:40:37.540]   - But really, yeah, but the only,
[00:40:37.540 --> 00:40:40.740]   the main benefit of time is to synchronize activity.
[00:40:40.740 --> 00:40:42.340]   And that's why we don't need time zones.
[00:40:42.340 --> 00:40:45.500]   We just need to, we need a number that says at this point
[00:40:45.500 --> 00:40:48.780]   in the space time continuum, we can have our meeting
[00:40:48.780 --> 00:40:49.580]   or whatever.
[00:40:49.580 --> 00:40:52.020]   And that's it, all these time zones and like,
[00:40:52.020 --> 00:40:54.100]   eight o'clock in the morning is in the morning.
[00:40:54.100 --> 00:40:55.660]   Well, it kind of is depending on what part
[00:40:55.660 --> 00:40:56.500]   of the earth you're on.
[00:40:56.500 --> 00:40:59.700]   It's just, it's just antiquated beyond beliefs.
[00:40:59.700 --> 00:41:02.980]   - But Mike, this whole idea of abolishing time zones,
[00:41:02.980 --> 00:41:06.620]   don't time zones give us a sense of synchronicity
[00:41:06.620 --> 00:41:09.620]   with our regional neighbors providing an us versus them,
[00:41:09.620 --> 00:41:12.660]   which is a valuable tool to a critical hearing society,
[00:41:12.660 --> 00:41:14.380]   like East versus West.
[00:41:14.380 --> 00:41:15.580]   - It does. - Very strong.
[00:41:15.580 --> 00:41:16.900]   - It does, but it's a misleading one.
[00:41:16.900 --> 00:41:18.500]   - We need American time.
[00:41:18.500 --> 00:41:20.300]   - You're on Brooklyn time, right?
[00:41:20.300 --> 00:41:22.700]   So it's like we're having a live conversation.
[00:41:22.700 --> 00:41:23.540]   - Freedom time.
[00:41:23.540 --> 00:41:27.220]   - Live conversations, Brooklyn time, right?
[00:41:27.220 --> 00:41:28.340]   Keep going. - Yeah, right.
[00:41:28.340 --> 00:41:29.420]   Hard attacks go up.
[00:41:29.420 --> 00:41:31.820]   There's no increased risk to children in rural areas.
[00:41:31.820 --> 00:41:33.500]   Traffic accidents spike.
[00:41:33.500 --> 00:41:36.540]   Workplace injuries go up, strokes go up.
[00:41:36.540 --> 00:41:38.820]   - I'm gonna write something in defense of daylight saving,
[00:41:38.820 --> 00:41:40.340]   just to piss you guys off.
[00:41:40.340 --> 00:41:42.780]   - Workplace productivity goes down.
[00:41:42.780 --> 00:41:46.140]   Permanent daylight savings time will help decrease air pollution
[00:41:46.140 --> 00:41:49.300]   according to the Journal of Air and Waste Management Association.
[00:41:49.300 --> 00:41:51.860]   Clock changing according to the Wall Street Journal,
[00:41:51.860 --> 00:41:54.180]   harms relationships.
[00:41:54.180 --> 00:41:56.540]   - Well, if you've ever tried to watch your husband
[00:41:56.540 --> 00:41:58.900]   change a clock on a VCR, let me tell you,
[00:41:58.900 --> 00:42:00.460]   it does harm a relationship.
[00:42:00.460 --> 00:42:01.620]   - True.
[00:42:01.620 --> 00:42:02.900]   - Why yelling?
[00:42:02.900 --> 00:42:05.220]   - Getting, you have a VCR?
[00:42:05.220 --> 00:42:06.300]   - No, I don't.
[00:42:06.300 --> 00:42:07.140]   (laughing)
[00:42:07.140 --> 00:42:08.140]   - That sounds apocryphal.
[00:42:08.140 --> 00:42:10.140]   - That seems like a thing people would yell at each other.
[00:42:10.140 --> 00:42:12.260]   - Honey, it's blinking 12 again.
[00:42:12.260 --> 00:42:13.100]   - What do you think about it?
[00:42:13.100 --> 00:42:14.340]   - I fixed it last week.
[00:42:15.620 --> 00:42:20.260]   - So I found a, this is a scientific,
[00:42:20.260 --> 00:42:22.060]   what's on Stanford.edu, to me,
[00:42:22.060 --> 00:42:22.900]   - That's good.
[00:42:22.900 --> 00:42:23.740]   - That's a start.
[00:42:23.740 --> 00:42:25.900]   - It could just be a personal website
[00:42:25.900 --> 00:42:28.540]   and the benefits of daylight saving time,
[00:42:28.540 --> 00:42:30.260]   sorry, saving time, saving time.
[00:42:30.260 --> 00:42:32.180]   The chat room's killing me.
[00:42:32.180 --> 00:42:34.580]   It shifts summer daylights to evening hours
[00:42:34.580 --> 00:42:36.140]   when it can be enjoyed more.
[00:42:36.140 --> 00:42:37.660]   I think this is a good reason.
[00:42:37.660 --> 00:42:39.300]   So that's one.
[00:42:39.300 --> 00:42:41.260]   - No, we just stay on daylight savings.
[00:42:41.260 --> 00:42:42.100]   - I agree with that.
[00:42:42.100 --> 00:42:44.860]   We stay with what we have right now, which is long days.
[00:42:44.860 --> 00:42:46.620]   - I like long days.
[00:42:46.620 --> 00:42:48.740]   - No, it's not gonna change the length of the day
[00:42:48.740 --> 00:42:51.300]   is not governed by daylight saving time.
[00:42:51.300 --> 00:42:53.460]   - Sure, I mean, if we get rid of time though,
[00:42:53.460 --> 00:42:54.820]   that's just one step forward.
[00:42:54.820 --> 00:42:55.660]   - Here's the sun.
[00:42:55.660 --> 00:42:57.660]   - And here's the earth.
[00:42:57.660 --> 00:43:00.060]   And it goes, oh man.
[00:43:00.060 --> 00:43:02.940]   - I don't know, now Leo, I'm doubting everything.
[00:43:02.940 --> 00:43:04.660]   Science, facts, how about this?
[00:43:04.660 --> 00:43:06.380]   - This is all a simulation anyway, you guys.
[00:43:06.380 --> 00:43:07.220]   It doesn't even matter.
[00:43:07.220 --> 00:43:08.780]   - Here's the stuff, oh thank goodness.
[00:43:08.780 --> 00:43:11.380]   You know, lately, ever since Elon said that,
[00:43:11.380 --> 00:43:13.700]   Elon said chances are a billion to one
[00:43:13.700 --> 00:43:14.900]   were not in a simulation.
[00:43:14.900 --> 00:43:15.740]   This is a game.
[00:43:15.740 --> 00:43:16.900]   - Takes a lot of pressure off.
[00:43:16.900 --> 00:43:19.020]   - It does, Elon said.
[00:43:19.020 --> 00:43:21.220]   You know what next year, let's send two people to Mars.
[00:43:21.220 --> 00:43:22.060]   - Yeah.
[00:43:22.060 --> 00:43:22.900]   - Or the moon, we're gonna go around the moon.
[00:43:22.900 --> 00:43:24.180]   - Let's just do it for funsies.
[00:43:24.180 --> 00:43:25.180]   - Let's funsies.
[00:43:25.180 --> 00:43:26.260]   What could possibly go wrong?
[00:43:26.260 --> 00:43:27.740]   Who cares, it's simulation.
[00:43:27.740 --> 00:43:28.580]   - Probably tourists.
[00:43:28.580 --> 00:43:29.420]   - They're saying that.
[00:43:29.420 --> 00:43:30.260]   - It doesn't matter, they're just glitches
[00:43:30.260 --> 00:43:31.820]   in the system anyway, just send it over to the moon.
[00:43:31.820 --> 00:43:35.700]   - That is a mind worm, because ever since he said that now,
[00:43:35.700 --> 00:43:37.300]   I think that a lot.
[00:43:37.300 --> 00:43:39.060]   Like, oh, it's just a simulation.
[00:43:39.060 --> 00:43:40.140]   Like, ah.
[00:43:40.140 --> 00:43:42.260]   - I'm sorry guys, I gotta bring it back
[00:43:42.260 --> 00:43:43.180]   to daylight saving time for him.
[00:43:43.180 --> 00:43:44.020]   - Okay.
[00:43:44.020 --> 00:43:45.100]   - Here's my last.
[00:43:45.100 --> 00:43:46.940]   - And he's in a hurry too, 'cause we lost an hour.
[00:43:46.940 --> 00:43:49.620]   - No, no, we gotta hurry, hurry, get it all out.
[00:43:49.620 --> 00:43:51.540]   - First of all, last night I watched an episode
[00:43:51.540 --> 00:43:53.780]   of Twin Peaks, and then I looked at my clock,
[00:43:53.780 --> 00:43:56.380]   it was 3.45 in the morning, my house is so late,
[00:43:56.380 --> 00:43:58.700]   but it wasn't daylight saving stole something from me.
[00:43:58.700 --> 00:43:59.540]   - It stole something for me.
[00:43:59.540 --> 00:44:00.780]   - Which is my sense of reality.
[00:44:00.780 --> 00:44:01.620]   - Yeah.
[00:44:01.620 --> 00:44:03.740]   - Second, I asked Twin Peaks.
[00:44:03.740 --> 00:44:06.460]   - If we just have a single time zone,
[00:44:06.460 --> 00:44:10.420]   that means at any point in the world at this moment,
[00:44:10.420 --> 00:44:15.420]   it is like 22, 17, data or whatever.
[00:44:15.420 --> 00:44:19.860]   But I associate time with the position of the sun,
[00:44:19.860 --> 00:44:20.940]   wouldn't that ruin that?
[00:44:20.940 --> 00:44:23.500]   Like, we'd have to choose a point of primacy
[00:44:23.500 --> 00:44:24.380]   to determine that.
[00:44:24.380 --> 00:44:26.420]   - You'd still do that, but based on where you live,
[00:44:26.420 --> 00:44:29.300]   so you'd say, oh, the sun rises at 5 p.m.
[00:44:29.300 --> 00:44:31.020]   - Here in, yeah, here in Petalova,
[00:44:31.020 --> 00:44:33.620]   the sun comes up at 0.05, you just get used to it.
[00:44:33.620 --> 00:44:34.460]   - Yeah.
[00:44:34.460 --> 00:44:35.300]   - You get used to it.
[00:44:35.300 --> 00:44:37.140]   - 'Cause sun rises at 1,700.
[00:44:37.140 --> 00:44:38.020]   - Yeah.
[00:44:38.020 --> 00:44:39.860]   - That's insane.
[00:44:39.860 --> 00:44:41.220]   - It's only insane because you--
[00:44:41.220 --> 00:44:42.220]   - No, it's a number.
[00:44:42.220 --> 00:44:46.220]   - 'Cause you're so used to living by this weird arbitrary--
[00:44:46.220 --> 00:44:49.260]   - Look, I think Celsius temperatures are insane,
[00:44:49.260 --> 00:44:51.020]   so I understand your issue.
[00:44:51.020 --> 00:44:53.620]   But I think we get used to it.
[00:44:53.620 --> 00:44:54.780]   You know what, it's the kind of thing--
[00:44:54.780 --> 00:44:56.980]   - It'd be like if we switched to the metric system,
[00:44:56.980 --> 00:44:57.820]   which is gonna--
[00:44:57.820 --> 00:44:58.900]   - Now you're talking crazy.
[00:44:58.900 --> 00:45:00.740]   - A bullish, piloting pass.
[00:45:00.740 --> 00:45:01.580]   - We couldn't even--
[00:45:01.580 --> 00:45:03.380]   - And the MP's still says, "We couldn't even agree
[00:45:03.380 --> 00:45:04.300]   "to do that."
[00:45:04.300 --> 00:45:07.300]   - We are getting so much done for the world right now
[00:45:07.300 --> 00:45:08.140]   on this show.
[00:45:08.140 --> 00:45:09.380]   I am so excited.
[00:45:09.380 --> 00:45:11.300]   - Can I just take a moment,
[00:45:11.300 --> 00:45:12.820]   'cause I've never got the opportunity to do this,
[00:45:12.820 --> 00:45:16.180]   to defend the US not being on the metric system?
[00:45:16.180 --> 00:45:17.020]   - Okay.
[00:45:17.020 --> 00:45:19.140]   - And that is, as a writer,
[00:45:19.140 --> 00:45:24.140]   you can't use metric measurements in poetry or literature.
[00:45:24.140 --> 00:45:28.140]   You can't say, you won't be a song that's like 500 kilometers.
[00:45:28.140 --> 00:45:29.740]   - I would walk 500 kilometers.
[00:45:29.740 --> 00:45:30.580]   - Kilometers.
[00:45:30.580 --> 00:45:33.620]   - It says ruins the, it's terrible.
[00:45:33.620 --> 00:45:38.620]   You beat ennages and so on are poetic, sort of.
[00:45:38.620 --> 00:45:40.820]   - So here's a map of the world.
[00:45:40.820 --> 00:45:45.820]   In red, the three countries that still use the imperial system
[00:45:45.820 --> 00:45:49.180]   still use feet, miles, and Fahrenheit.
[00:45:49.180 --> 00:45:50.740]   - That is not a fair representation.
[00:45:50.740 --> 00:45:53.980]   You have to show a visual image that represents
[00:45:53.980 --> 00:45:57.100]   the amount of guns or nuclear weapons.
[00:45:57.100 --> 00:46:01.460]   And that will explain more the persistence of the imperials.
[00:46:01.460 --> 00:46:06.460]   - The United States, Myanmar, and Liberia.
[00:46:07.460 --> 00:46:08.980]   - Wow. - That's it.
[00:46:08.980 --> 00:46:10.900]   The last three, we're standing,
[00:46:10.900 --> 00:46:13.620]   this is the Alliance of Good.
[00:46:13.620 --> 00:46:15.860]   This is--
[00:46:15.860 --> 00:46:17.020]   - I'm gonna play these three countries
[00:46:17.020 --> 00:46:18.020]   in the next, so I have like risk.
[00:46:18.020 --> 00:46:19.340]   - Yes.
[00:46:19.340 --> 00:46:20.660]   - Oh boy. - I wanna be--
[00:46:20.660 --> 00:46:22.540]   - The imperial, the imperial axis.
[00:46:22.540 --> 00:46:24.700]   - So I apologize for bringing us back into a debate
[00:46:24.700 --> 00:46:27.220]   about time if you wanted to keep moving to the other stories.
[00:46:27.220 --> 00:46:28.220]   - No, don't apologize.
[00:46:28.220 --> 00:46:30.660]   There's no agenda here.
[00:46:30.660 --> 00:46:31.500]   - Okay.
[00:46:31.500 --> 00:46:34.420]   Are you gonna get sued by Devorek for saying that?
[00:46:34.420 --> 00:46:36.860]   - Yeah, probably, I just thought, oh crap.
[00:46:36.860 --> 00:46:37.860]   I'm in trouble now.
[00:46:37.860 --> 00:46:39.060]   (laughing)
[00:46:39.060 --> 00:46:41.260]   There is an agenda here.
[00:46:41.260 --> 00:46:43.420]   Anyway, I do hope this gets abandoned.
[00:46:43.420 --> 00:46:45.540]   I think it's terrible.
[00:46:45.540 --> 00:46:47.380]   There's actually a book called "Spring Forward,
[00:46:47.380 --> 00:46:49.500]   the Annual Madness of Daylight Savings Time."
[00:46:49.500 --> 00:46:52.740]   There's a website which, you know,
[00:46:52.740 --> 00:46:54.900]   you can get all these facts from if you want.
[00:46:54.900 --> 00:46:59.900]   That is sco.tt/timeending,
[00:46:59.900 --> 00:47:03.700]   changing the clocks for daylight saving time.
[00:47:03.700 --> 00:47:05.980]   I think that there's one problem
[00:47:05.980 --> 00:47:08.500]   is we'd have to debate whether you change the clocks to you,
[00:47:08.500 --> 00:47:10.460]   or, but I love the world time.
[00:47:10.460 --> 00:47:12.020]   I think we should just have a world time.
[00:47:12.020 --> 00:47:13.100]   I love that.
[00:47:13.100 --> 00:47:14.300]   - It's one step closer
[00:47:14.300 --> 00:47:16.180]   to the United Federation of Planets, you guys.
[00:47:16.180 --> 00:47:17.020]   That's all I'm saying.
[00:47:17.020 --> 00:47:18.500]   - It is, it's totally a science fiction trope.
[00:47:18.500 --> 00:47:19.660]   - We start having interstellar--
[00:47:19.660 --> 00:47:21.140]   - Very sci-fi.
[00:47:21.140 --> 00:47:23.900]   - Once we have interplanetary commerce and leisure
[00:47:23.900 --> 00:47:25.780]   and other activities, we will need--
[00:47:25.780 --> 00:47:26.620]   - Matching a more--
[00:47:26.620 --> 00:47:27.460]   - A more dynamic-- - A more dynamic.
[00:47:27.460 --> 00:47:28.300]   - A futuristic outfit.
[00:47:28.300 --> 00:47:30.340]   - You always know you're reading sci-fi
[00:47:30.340 --> 00:47:32.340]   when you see there's a black president.
[00:47:32.340 --> 00:47:35.940]   Then you know that this is the future, right?
[00:47:35.940 --> 00:47:37.660]   - Or the recent past.
[00:47:37.660 --> 00:47:38.660]   - The past.
[00:47:38.660 --> 00:47:39.980]   - Or the last--
[00:47:39.980 --> 00:47:42.580]   - What was exactly life in Akis asked to Barack Obama?
[00:47:42.580 --> 00:47:44.180]   How does it feel being the last black president?
[00:47:44.180 --> 00:47:46.140]   - He asked Hillary Clinton,
[00:47:46.140 --> 00:47:48.660]   "Are you concerned about being young people's
[00:47:48.660 --> 00:47:51.220]   "first white president or something like that?"
[00:47:51.220 --> 00:47:52.660]   - That's funny too.
[00:47:52.660 --> 00:47:54.700]   - But now apparently that wasn't a concern.
[00:47:54.700 --> 00:47:55.860]   - Your first orange president.
[00:47:55.860 --> 00:47:57.660]   - Yeah, that's good.
[00:47:57.660 --> 00:47:59.500]   Diversity.
[00:47:59.500 --> 00:48:01.020]   All right, so it's not gonna happen,
[00:48:01.020 --> 00:48:03.140]   but Clayton Morris is starting this
[00:48:03.140 --> 00:48:04.980]   and as well and he's getting behind it
[00:48:04.980 --> 00:48:07.180]   and I just agree, I think we should get rid of this.
[00:48:07.180 --> 00:48:10.420]   Here's another crusade that's completely hopeless.
[00:48:10.420 --> 00:48:13.340]   The inventor of the worldwide web, Tim Berners-Lee says,
[00:48:13.340 --> 00:48:16.300]   "Online political advertising should be regulated."
[00:48:16.300 --> 00:48:23.620]   - He thinks that the problem is the targeted advertisements
[00:48:23.620 --> 00:48:27.700]   on Facebook and Google that no one sees
[00:48:27.700 --> 00:48:30.300]   except the intended recipient, right?
[00:48:30.300 --> 00:48:33.740]   These carefully targeted advertising allows a campaign,
[00:48:33.740 --> 00:48:35.300]   he says, "To say completely different,
[00:48:35.300 --> 00:48:38.500]   "possibly conflicting things to different groups."
[00:48:38.500 --> 00:48:40.380]   Of course, I don't-- - At scale.
[00:48:40.380 --> 00:48:41.380]   - At scale.
[00:48:41.380 --> 00:48:43.340]   But who the hell's gonna regulate this?
[00:48:43.340 --> 00:48:44.780]   Exactly, you can't regulate it.
[00:48:44.780 --> 00:48:47.220]   - Well, I don't know, if only we had a functioning government
[00:48:47.220 --> 00:48:48.860]   there might be a role.
[00:48:48.860 --> 00:48:51.060]   We regulated a lot of other things about that.
[00:48:51.060 --> 00:48:53.060]   - It is called idea regulation.
[00:48:53.060 --> 00:48:55.820]   - They never get regulated, it's a free speech issue, right?
[00:48:55.820 --> 00:48:57.660]   - Is there value though in,
[00:48:57.660 --> 00:49:00.700]   so the fairness doctrine, which is a high?
[00:49:00.700 --> 00:49:01.900]   - Long gone, I remember it though,
[00:49:01.900 --> 00:49:03.060]   so I used to work in radio.
[00:49:03.060 --> 00:49:04.900]   - Yeah. - Cable news killed
[00:49:04.900 --> 00:49:06.020]   the fairness doctrine.
[00:49:06.020 --> 00:49:09.620]   But is there some value in revisiting this concept
[00:49:09.620 --> 00:49:10.540]   for the internet?
[00:49:10.540 --> 00:49:12.140]   Like, I don't know if that--
[00:49:12.140 --> 00:49:13.860]   - It's funny how your battles change
[00:49:13.860 --> 00:49:15.940]   because maybe a few years ago, you might have said,
[00:49:15.940 --> 00:49:17.500]   "We should bring back the fairness doctrine."
[00:49:17.500 --> 00:49:19.500]   Now we just like to bring back fairness.
[00:49:19.500 --> 00:49:20.700]   - Yeah. - Yeah.
[00:49:20.700 --> 00:49:23.220]   - The FCC is basically throwing out all regulations,
[00:49:23.220 --> 00:49:26.660]   including regulations that prohibit phone companies
[00:49:26.660 --> 00:49:28.140]   from stealing information about you
[00:49:28.140 --> 00:49:30.100]   and selling it to the highest bidder.
[00:49:30.100 --> 00:49:33.620]   That's gone, net neutrality, forget that.
[00:49:33.620 --> 00:49:37.700]   I mean, let me scare the pants off
[00:49:37.700 --> 00:49:38.740]   of everybody listening to the show.
[00:49:38.740 --> 00:49:41.100]   - Oh yes, please. - So you can't,
[00:49:41.100 --> 00:49:42.100]   I'm not wearing any pants.
[00:49:42.100 --> 00:49:43.340]   - I was gonna say, too late. - Everyone else,
[00:49:43.340 --> 00:49:45.340]   I should say. (laughing)
[00:49:45.340 --> 00:49:47.220]   But my pants are still on, you can scare me, Mike.
[00:49:47.220 --> 00:49:48.660]   - Thank you, thank you.
[00:49:48.660 --> 00:49:49.500]   - He's ready.
[00:49:49.500 --> 00:49:52.060]   - So you mentioned the column that I wrote
[00:49:52.060 --> 00:49:54.500]   that's on the rundown, this is essentially what it's about.
[00:49:54.500 --> 00:49:56.980]   So right now, there are lots of people
[00:49:56.980 --> 00:49:58.740]   looking at social posts.
[00:49:58.740 --> 00:50:00.620]   HR departments, insurance companies,
[00:50:00.620 --> 00:50:03.340]   the government wants, is actually talking about demanding
[00:50:03.340 --> 00:50:05.420]   that visitors from certain countries
[00:50:05.420 --> 00:50:07.940]   hand over their passwords to their social networks
[00:50:07.940 --> 00:50:09.980]   so they can see who you're following and what you're reading.
[00:50:09.980 --> 00:50:11.580]   - I believe that's happening here in the US, right?
[00:50:11.580 --> 00:50:12.700]   - Yeah, yes. - CBB.
[00:50:12.700 --> 00:50:16.180]   - Lots and lots of people, and remember that,
[00:50:16.180 --> 00:50:18.820]   people are looking at social, and it's not that effective
[00:50:18.820 --> 00:50:21.300]   because people are poor processors.
[00:50:21.300 --> 00:50:23.940]   So what we're entering into is an era
[00:50:23.940 --> 00:50:26.500]   where artificial intelligence will automatically identify
[00:50:26.500 --> 00:50:30.340]   which are your profiles, scan every post you've ever posted,
[00:50:30.340 --> 00:50:32.900]   every comment you've ever commented on,
[00:50:32.900 --> 00:50:34.540]   every person you've ever followed,
[00:50:34.540 --> 00:50:37.220]   everyone who follows you, crunch all that numbers,
[00:50:37.220 --> 00:50:39.260]   and profile you so specifically.
[00:50:39.260 --> 00:50:42.020]   So you get into political advertising,
[00:50:42.020 --> 00:50:46.300]   they will send each and every person a very customized ad
[00:50:46.300 --> 00:50:50.300]   pushing the exact one button that you really care about the most.
[00:50:50.300 --> 00:50:52.380]   And this is the threat.
[00:50:52.380 --> 00:50:56.060]   Artificial intelligence is gonna make profiling people
[00:50:56.060 --> 00:50:56.900]   very efficient.
[00:50:56.900 --> 00:50:58.100]   Now you look at what's happening in China,
[00:50:58.100 --> 00:51:00.460]   they have this thing called the social credit score.
[00:51:00.460 --> 00:51:03.620]   They have four areas where they give everybody a score.
[00:51:03.620 --> 00:51:05.100]   - So like at a black mirror?
[00:51:05.100 --> 00:51:06.300]   - It's out of black mirror, exactly.
[00:51:06.300 --> 00:51:08.380]   So what China's doing is like they look at your credit score,
[00:51:08.380 --> 00:51:10.020]   the financial stuff, they look at your debt,
[00:51:10.020 --> 00:51:11.300]   whatever is going on there.
[00:51:11.300 --> 00:51:13.500]   They look at your relationship with the law.
[00:51:13.500 --> 00:51:15.060]   If you had parking tickets, you've been arrested,
[00:51:15.060 --> 00:51:16.620]   you've been suspected, whatever,
[00:51:16.620 --> 00:51:18.660]   and they look at your social networking posts
[00:51:18.660 --> 00:51:19.860]   and they give you an overall score.
[00:51:19.860 --> 00:51:21.460]   So you can raise the score by saying nice things
[00:51:21.460 --> 00:51:23.220]   about the Chinese Communist Party.
[00:51:23.220 --> 00:51:25.740]   You get a lower score if you don't pay your debt on time
[00:51:25.740 --> 00:51:27.700]   or whatever, and they've already banned
[00:51:27.700 --> 00:51:31.660]   almost seven million people from writing the train in China
[00:51:31.660 --> 00:51:33.500]   because of the debts that they didn't pay.
[00:51:33.500 --> 00:51:34.340]   - Wow.
[00:51:34.340 --> 00:51:37.180]   - And they wanna make it so that people who are untrustworthy
[00:51:37.180 --> 00:51:39.580]   in general can't move, can't do anything,
[00:51:39.580 --> 00:51:41.260]   can't get a job, can't do all these things.
[00:51:41.260 --> 00:51:43.860]   This is the future because an artificial intelligence
[00:51:43.860 --> 00:51:47.140]   will radically accelerate the effectiveness
[00:51:47.140 --> 00:51:50.980]   of artificially intelligence-based trust metrics
[00:51:50.980 --> 00:51:52.220]   for every industry.
[00:51:52.220 --> 00:51:53.820]   So the insurance industry wants to know
[00:51:53.820 --> 00:51:55.540]   what kind of a risk you are.
[00:51:55.540 --> 00:51:58.740]   And the universities wanna know what kind of an academic you'll be.
[00:51:58.740 --> 00:52:00.460]   And they'll be able to custom tailor it
[00:52:00.460 --> 00:52:02.140]   in a way that's beyond our imagination.
[00:52:02.140 --> 00:52:04.180]   And yes, it is just like Black Mirror.
[00:52:04.180 --> 00:52:05.020]   - And if you're still--
[00:52:05.020 --> 00:52:06.940]   - Refiring genetic testing is another one.
[00:52:06.940 --> 00:52:08.900]   - Yeah, and if you still have your pants on,
[00:52:08.900 --> 00:52:12.860]   let me add to this, that these assessments,
[00:52:12.860 --> 00:52:15.980]   these scores are not just based on like you
[00:52:15.980 --> 00:52:19.460]   in a vacuum starting from the point of your birth.
[00:52:19.460 --> 00:52:21.540]   History is baked into all these scoreings.
[00:52:21.540 --> 00:52:23.460]   Who's more likely to be arrested?
[00:52:23.460 --> 00:52:25.220]   Who's less likely to have access to capital
[00:52:25.220 --> 00:52:26.100]   and run up debts?
[00:52:26.100 --> 00:52:29.380]   Who will more likely to have a prison history
[00:52:29.380 --> 00:52:31.020]   or some financial troubles?
[00:52:31.020 --> 00:52:33.820]   That skews heavily along class, gender,
[00:52:33.820 --> 00:52:35.940]   and racial lines, which goes beyond
[00:52:35.940 --> 00:52:37.740]   any individual single act.
[00:52:37.740 --> 00:52:39.260]   - In a way that would argue--
[00:52:39.260 --> 00:52:40.260]   - In a way that would argue--
[00:52:40.260 --> 00:52:43.140]   - Are gonna build on the historical profile
[00:52:43.140 --> 00:52:44.540]   and that we've already seen happen.
[00:52:44.540 --> 00:52:47.100]   So we're making a racist kind of.
[00:52:47.100 --> 00:52:48.500]   - In a way that would argue for you
[00:52:48.500 --> 00:52:50.740]   to actually create a social profile to put--
[00:52:50.740 --> 00:52:52.860]   - Those who will have the resources to do that?
[00:52:52.860 --> 00:52:54.460]   - Absent that.
[00:52:54.460 --> 00:52:55.940]   - People are gonna look at you and say,
[00:52:55.940 --> 00:52:59.140]   well, he looks like a terrorist.
[00:52:59.140 --> 00:53:01.380]   At least if you have a social media history
[00:53:01.380 --> 00:53:04.940]   and they at least are basing it on more information
[00:53:04.940 --> 00:53:08.020]   than the color of your skin or what kind of hat you wear.
[00:53:08.020 --> 00:53:10.940]   - The challenge is that all of these tools
[00:53:10.940 --> 00:53:12.300]   that Mike just talked about,
[00:53:12.300 --> 00:53:15.180]   they will be used to claim we're not discriminating
[00:53:15.180 --> 00:53:16.340]   based on skin color.
[00:53:16.340 --> 00:53:19.060]   'Cause they'll be like, no, it's a neutral science score.
[00:53:19.060 --> 00:53:21.260]   There's nothing that says black or African American.
[00:53:21.260 --> 00:53:22.740]   There's nothing that says Muslim
[00:53:22.740 --> 00:53:24.420]   or even Pakistani in there.
[00:53:24.420 --> 00:53:27.500]   But somehow all these indicators will be a proxy
[00:53:27.500 --> 00:53:29.020]   for black and Muslim.
[00:53:29.020 --> 00:53:29.860]   - Sure, and you buy--
[00:53:29.860 --> 00:53:30.700]   - It's a tremendous--
[00:53:30.700 --> 00:53:31.540]   - How much hummus have you bought?
[00:53:31.540 --> 00:53:33.580]   - The historical data caused by systematic oppression
[00:53:33.580 --> 00:53:36.460]   of people means that the system itself
[00:53:36.460 --> 00:53:38.940]   in the future will inherently be biased.
[00:53:38.940 --> 00:53:40.580]   - On the other hand, you quote here--
[00:53:40.580 --> 00:53:42.220]   - The first before it gets better.
[00:53:42.220 --> 00:53:43.820]   - You quote in your article, Mike,
[00:53:43.820 --> 00:53:46.300]   that according to a career builder survey,
[00:53:46.300 --> 00:53:50.060]   60% of employers look at social media posts
[00:53:50.060 --> 00:53:51.860]   and prospective employees.
[00:53:51.860 --> 00:53:52.780]   I mean, we do that.
[00:53:52.780 --> 00:53:53.620]   - Yep.
[00:53:53.620 --> 00:53:54.460]   - Yeah, but you're--
[00:53:54.460 --> 00:53:55.300]   - But you're--
[00:53:55.300 --> 00:53:56.140]   - But you're doing something wrong with doing that?
[00:53:56.140 --> 00:53:59.940]   - It's, you're not as, you're not very good at it
[00:53:59.940 --> 00:54:01.420]   because you're a human being.
[00:54:01.420 --> 00:54:02.260]   (laughing)
[00:54:02.260 --> 00:54:03.100]   Okay, so you can get--
[00:54:03.100 --> 00:54:04.540]   - Yeah, I just look at what you tweeted
[00:54:04.540 --> 00:54:06.460]   and what you face booked and that sounds funny.
[00:54:06.460 --> 00:54:09.100]   - But imagine, you're not profiling,
[00:54:09.100 --> 00:54:10.700]   you're getting a sense, are there any, you know,
[00:54:10.700 --> 00:54:11.900]   do I see anything in San Diego?
[00:54:11.900 --> 00:54:12.740]   - Is this crazy, whatever.
[00:54:12.740 --> 00:54:13.660]   - Is this crazy, what a much job are they, you know,
[00:54:13.660 --> 00:54:14.500]   spend every night drinking?
[00:54:14.500 --> 00:54:17.540]   - But profiling will take things that look super innocuous.
[00:54:17.540 --> 00:54:19.500]   This person likes this kind of tennis shoes
[00:54:19.500 --> 00:54:20.980]   and people who like this kind of tennis shoes
[00:54:20.980 --> 00:54:23.580]   and also like hummus, but also have been to Brooklyn.
[00:54:23.580 --> 00:54:26.660]   Those people are more likely, you know,
[00:54:26.660 --> 00:54:29.140]   20% more likely to do XYZ.
[00:54:29.140 --> 00:54:32.260]   It's like a human brain can't even begin to think like that,
[00:54:32.260 --> 00:54:33.900]   but here's one of the worst aspects of this.
[00:54:33.900 --> 00:54:37.460]   - You are saying in public though stuff about yourself.
[00:54:37.460 --> 00:54:38.300]   Yes, but you can't--
[00:54:38.300 --> 00:54:40.220]   - Yeah, but most of these statements, first of all,
[00:54:40.220 --> 00:54:41.500]   they're implicit.
[00:54:41.500 --> 00:54:45.100]   I'm making a statement basically by the geolocation
[00:54:45.100 --> 00:54:46.220]   of my phone.
[00:54:46.220 --> 00:54:49.140]   If I visit a mosque, I'm making a statement,
[00:54:49.140 --> 00:54:51.420]   but it's not a statement in the traditional definition
[00:54:51.420 --> 00:54:54.420]   of speech, if my mere existence is speech
[00:54:54.420 --> 00:54:56.460]   in a data rich networked world.
[00:54:56.460 --> 00:55:00.300]   And so we are being judged by statements.
[00:55:00.300 --> 00:55:01.820]   It's not just social media postings
[00:55:01.820 --> 00:55:04.860]   that are being roped in, it's behavior and presence,
[00:55:04.860 --> 00:55:08.380]   physical presence and association with other individuals.
[00:55:08.380 --> 00:55:09.860]   So they're gonna map, you know,
[00:55:09.860 --> 00:55:13.580]   Uber knows who Muslims are by their prayer breaks, you know,
[00:55:13.580 --> 00:55:16.060]   in terms of the time of day that they're offline
[00:55:16.060 --> 00:55:16.900]   from their routes.
[00:55:16.900 --> 00:55:19.020]   They didn't ask that question, but they inferred it.
[00:55:19.020 --> 00:55:21.140]   So did those drivers make a statement declaring
[00:55:21.140 --> 00:55:22.140]   their Islamic faith?
[00:55:22.140 --> 00:55:26.100]   - And AI, yeah, and AI will be able to make ghosts further.
[00:55:26.100 --> 00:55:29.020]   So they'll look at who you know and who they know.
[00:55:29.020 --> 00:55:30.860]   So people that you have never even met
[00:55:30.860 --> 00:55:32.660]   will affect your score.
[00:55:32.660 --> 00:55:35.860]   And one of the worst parts about this is that you'll never know.
[00:55:35.860 --> 00:55:37.860]   All of these, all this action will happen
[00:55:37.860 --> 00:55:38.700]   behind the scenes.
[00:55:38.700 --> 00:55:40.860]   When you don't get the job, you'll never know
[00:55:40.860 --> 00:55:43.700]   that it was an AI's judgment about your social posts
[00:55:43.700 --> 00:55:45.660]   that actually let you not getting the job.
[00:55:45.660 --> 00:55:49.500]   - The scariest part is that things like
[00:55:49.500 --> 00:55:53.300]   Google's one true answer are wrong often.
[00:55:53.300 --> 00:55:54.140]   - Yes, right, right.
[00:55:54.140 --> 00:55:57.580]   - And so we are not at a stage yet in artificial intelligence
[00:55:57.580 --> 00:56:01.100]   and deep machine learning to where they can make
[00:56:01.100 --> 00:56:04.140]   a truly accurate representation of who you are
[00:56:04.140 --> 00:56:05.020]   with that data.
[00:56:05.020 --> 00:56:07.460]   Like machines still make mistakes
[00:56:07.460 --> 00:56:09.580]   because they are programmed by people.
[00:56:09.580 --> 00:56:10.420]   - That's exactly right.
[00:56:10.420 --> 00:56:15.020]   But the people who run these machines don't realize that.
[00:56:15.020 --> 00:56:18.780]   Google won't accept the fact that their AI
[00:56:18.780 --> 00:56:21.100]   doesn't work often.
[00:56:21.100 --> 00:56:24.420]   - They realize that they're just willing to accept it.
[00:56:24.420 --> 00:56:26.420]   And if you want to deep,
[00:56:26.420 --> 00:56:28.860]   Cathy O'Neill's written a great book on this subject,
[00:56:28.860 --> 00:56:30.340]   Weapons of Math Destruction.
[00:56:30.340 --> 00:56:32.220]   - How did I have that up ready to go
[00:56:32.220 --> 00:56:33.940]   even before you said anything?
[00:56:33.940 --> 00:56:35.900]   - Because we abolish time zones,
[00:56:35.900 --> 00:56:37.340]   we're all in sync right now.
[00:56:37.340 --> 00:56:38.940]   - I was gonna bring this up
[00:56:38.940 --> 00:56:41.020]   'cause we interviewed a interviewer on triangulation.
[00:56:41.020 --> 00:56:43.340]   That's exactly the point of this book is that
[00:56:43.340 --> 00:56:46.860]   big data may be agnostic, but the silly algorithms
[00:56:46.860 --> 00:56:50.740]   we apply to it often express our own bias into the data
[00:56:50.740 --> 00:56:53.140]   and then the data can be used against us.
[00:56:53.140 --> 00:56:54.380]   - And how do you interpret it?
[00:56:54.380 --> 00:56:56.300]   - Right, I remember Microsoft's TAY.
[00:56:56.300 --> 00:56:57.560]   So they said, "Oh, we're gonna have this
[00:56:57.560 --> 00:56:59.740]   "artificial intelligent chat bot out there."
[00:56:59.740 --> 00:57:03.780]   And it will just harvest the sentiment of people
[00:57:03.780 --> 00:57:04.900]   who need to be racist.
[00:57:04.900 --> 00:57:05.740]   - And they taught--
[00:57:05.740 --> 00:57:07.540]   - Which is just that terrible idea.
[00:57:07.540 --> 00:57:10.060]   (laughing)
[00:57:10.060 --> 00:57:12.700]   - Yeah, everybody should read Weapons of Math Destruction.
[00:57:12.700 --> 00:57:13.740]   Cathy O'Neill's great book.
[00:57:13.740 --> 00:57:16.500]   And her blog talks more about this at Math Babe.
[00:57:17.060 --> 00:57:18.820]   She's a trained mathematician.
[00:57:18.820 --> 00:57:21.980]   She was a quant and realized working in Wall Street
[00:57:21.980 --> 00:57:25.540]   as a quant for a hedge fund that the numbers
[00:57:25.540 --> 00:57:28.340]   and the data were one thing, but the way it was interpreted
[00:57:28.340 --> 00:57:29.580]   was another thing entirely.
[00:57:29.580 --> 00:57:32.620]   And that so many people don't understand statistics
[00:57:32.620 --> 00:57:36.620]   and math and yet are quick to judge
[00:57:36.620 --> 00:57:39.700]   based on information that they see in the data.
[00:57:39.700 --> 00:57:42.340]   - Here's something that may emerge from this.
[00:57:42.340 --> 00:57:45.500]   First of all, I won't be able to wear pants again
[00:57:45.500 --> 00:57:46.340]   after this episode.
[00:57:46.340 --> 00:57:47.180]   That's weird.
[00:57:47.180 --> 00:57:49.180]   - Look at shorts, I've seen shorts.
[00:57:49.180 --> 00:57:50.020]   I know you.
[00:57:50.020 --> 00:57:52.540]   - Pantsless Baratunde is the future.
[00:57:52.540 --> 00:57:53.460]   Second is--
[00:57:53.460 --> 00:57:54.300]   - .com.
[00:57:54.300 --> 00:57:57.740]   - There's a, you know, getting to connect this like Google
[00:57:57.740 --> 00:58:01.700]   one answer, one false answer that actually brought up
[00:58:01.700 --> 00:58:04.420]   back to the Tim Berners-Lee regulation
[00:58:04.420 --> 00:58:06.500]   of political speech to ads.
[00:58:06.500 --> 00:58:10.060]   We're, it's like we're in this arms race
[00:58:10.060 --> 00:58:12.900]   that we as individuals have already lost
[00:58:12.900 --> 00:58:15.300]   for the next multiple generations.
[00:58:15.300 --> 00:58:17.900]   So if you're a big company, like you're in this game,
[00:58:17.900 --> 00:58:19.620]   you're trying to win your Amazon, your Google,
[00:58:19.620 --> 00:58:21.460]   your Facebook, your capital one,
[00:58:21.460 --> 00:58:23.220]   I'm naming no company in particular,
[00:58:23.220 --> 00:58:25.420]   but if you have a lot of resources and technology,
[00:58:25.420 --> 00:58:26.940]   you can bend this world to your will
[00:58:26.940 --> 00:58:30.700]   in a way that no individual person could ever counter.
[00:58:30.700 --> 00:58:34.300]   And so we would need some way to balance that power out,
[00:58:34.300 --> 00:58:36.860]   which is why we develop labor unions to begin with,
[00:58:36.860 --> 00:58:37.700]   for example, right?
[00:58:37.700 --> 00:58:41.700]   Like no individual worker could stand up to like the family
[00:58:41.700 --> 00:58:44.540]   that owned the plant and all the other plants in the country.
[00:58:44.540 --> 00:58:45.740]   So you have collective bargaining.
[00:58:45.740 --> 00:58:49.340]   Is there a version of collective, you know,
[00:58:49.340 --> 00:58:51.660]   rights holding, collective data integrity,
[00:58:51.660 --> 00:58:54.340]   collective transparency?
[00:58:54.340 --> 00:58:56.460]   And you know, all these bots that are going to be used
[00:58:56.460 --> 00:58:58.940]   against us like, do we just have to flood the zone
[00:58:58.940 --> 00:59:02.620]   with our own bots and basically obscure some of the reality
[00:59:02.620 --> 00:59:05.420]   of you're going to be auto magically profiling me,
[00:59:05.420 --> 00:59:07.540]   then I'm going to do as much as I can
[00:59:07.540 --> 00:59:10.420]   with the same tech tools and my colleagues
[00:59:10.420 --> 00:59:13.940]   to throw you off and have essentially like countermeasures
[00:59:13.940 --> 00:59:16.580]   to preserve some sense of individuality and freedom.
[00:59:16.580 --> 00:59:17.980]   'Cause ultimately, this is like,
[00:59:17.980 --> 00:59:19.780]   we're coming down to what freedom is at this point.
[00:59:19.780 --> 00:59:23.780]   If your future is prescribed by a score based on BS history
[00:59:23.780 --> 00:59:27.180]   and super imprecise science, that's not free
[00:59:27.180 --> 00:59:29.260]   and your choice is no longer your own.
[00:59:29.260 --> 00:59:30.940]   So this is like an epic battle
[00:59:30.940 --> 00:59:32.220]   and I'm not sure what we do about it,
[00:59:32.220 --> 00:59:35.020]   but it seems like some sort of organizing around
[00:59:35.020 --> 00:59:39.300]   and against the one-sided use of these weapons is in order.
[00:59:39.300 --> 00:59:42.740]   - So what you're saying in effect is that the ultimate defense
[00:59:42.740 --> 00:59:44.660]   in the future will be disinformation.
[00:59:44.660 --> 00:59:45.660]   - Yes.
[00:59:45.660 --> 00:59:47.380]   I said that all along though, you should cultivate
[00:59:47.380 --> 00:59:50.020]   your social presence to project the image
[00:59:50.020 --> 00:59:51.380]   that you wish to project.
[00:59:51.380 --> 00:59:52.220]   - Yeah.
[00:59:52.220 --> 00:59:54.900]   - But that's also so hard because when you promote disinformation,
[00:59:54.900 --> 00:59:58.100]   you also promote fake news, false facts.
[00:59:58.100 --> 00:59:59.500]   - No, only about you though.
[00:59:59.500 --> 01:00:00.340]   - It's so tough.
[01:00:00.340 --> 01:00:01.580]   - Only about you.
[01:00:01.580 --> 01:00:03.820]   I'm promoting false news about myself.
[01:00:03.820 --> 01:00:04.660]   That's okay.
[01:00:04.660 --> 01:00:06.540]   - Yeah, I mean, I don't think about, yeah,
[01:00:06.540 --> 01:00:08.700]   Leo, Leo's like I'm king of a small island nation.
[01:00:08.700 --> 01:00:10.060]   - Yeah, yeah.
[01:00:10.060 --> 01:00:10.900]   - Okay. - Okay.
[01:00:10.900 --> 01:00:11.740]   - I'm not saying anything about you.
[01:00:11.740 --> 01:00:14.620]   I'm not saying only about me and aren't I a great person,
[01:00:14.620 --> 01:00:15.460]   aren't I wonderful?
[01:00:15.460 --> 01:00:16.300]   Look at all these great things.
[01:00:16.300 --> 01:00:18.020]   I tell teenagers that all the time in high school.
[01:00:18.020 --> 01:00:20.100]   If you don't create, seriously, if you don't create--
[01:00:20.100 --> 01:00:21.620]   - Oh, I thought you made you told me that.
[01:00:21.620 --> 01:00:22.620]   - Well, they're very good at that.
[01:00:22.620 --> 01:00:24.100]   - I always tell them how great I am,
[01:00:24.100 --> 01:00:24.940]   but after I tell them that--
[01:00:24.940 --> 01:00:25.780]   - I love fellow kids.
[01:00:25.780 --> 01:00:26.620]   - Yes.
[01:00:26.620 --> 01:00:28.740]   - I hope I love fellow youths.
[01:00:28.740 --> 01:00:31.580]   - I tell the youths, you ought to have a website.
[01:00:31.580 --> 01:00:33.900]   You ought to be careful about what you're posting on Facebook.
[01:00:33.900 --> 01:00:37.020]   You ought to consider the fact that you're creating a persona.
[01:00:37.020 --> 01:00:37.860]   - Yeah.
[01:00:37.860 --> 01:00:38.860]   - And if you don't--
[01:00:38.860 --> 01:00:39.700]   - Create a database.
[01:00:39.700 --> 01:00:41.980]   - But the thing is, if you decide not to,
[01:00:41.980 --> 01:00:44.460]   if you say, "I'm only use Snapchat,"
[01:00:44.460 --> 01:00:48.060]   then that vacuum will be filled by whoever wants to fill it.
[01:00:48.060 --> 01:00:49.300]   That's even worse.
[01:00:49.300 --> 01:00:52.740]   So you need to get out there and present yourself, I think.
[01:00:52.740 --> 01:00:53.580]   - Yeah.
[01:00:53.580 --> 01:00:54.420]   - That's wonderful.
[01:00:54.420 --> 01:00:56.340]   - You might be leading them to the slaughter.
[01:00:56.340 --> 01:00:57.340]   - Really?
[01:00:57.340 --> 01:00:58.500]   What should they do? - Might be.
[01:00:58.500 --> 01:00:59.820]   - What should they do?
[01:00:59.820 --> 01:01:02.740]   - So-- - Delete your accounts.
[01:01:02.740 --> 01:01:05.100]   - No, because the absence of an account--
[01:01:05.100 --> 01:01:05.940]   - Yeah. - Then-- - It's suspicious.
[01:01:05.940 --> 01:01:07.500]   - Then when you're-- - It's like not having a credit.
[01:01:07.500 --> 01:01:09.180]   It's not like, it's like not having credit.
[01:01:09.180 --> 01:01:10.620]   It's like, "Oh, well, I can't give you--
[01:01:10.620 --> 01:01:13.420]   "I don't trust you, I don't know what you're even about at all."
[01:01:13.420 --> 01:01:14.860]   - No, because no, it's even worse than that,
[01:01:14.860 --> 01:01:16.660]   because the way Google works-- - It's just so black there.
[01:01:16.660 --> 01:01:18.020]   - It is really black there. - It is really black there.
[01:01:18.020 --> 01:01:20.340]   - Because let's say, okay, let's say I'm a smart kid.
[01:01:20.340 --> 01:01:22.220]   I have no Facebook, no Twitter.
[01:01:22.220 --> 01:01:24.940]   If I use anything, I use Snapchat, it gets dissolved.
[01:01:24.940 --> 01:01:28.620]   But then, my worst enemy from trigonometry
[01:01:28.620 --> 01:01:32.140]   decides to post a video of me peeing on a wall.
[01:01:32.140 --> 01:01:34.220]   That's what Google finds.
[01:01:34.220 --> 01:01:36.220]   So that means that somebody else is now
[01:01:36.220 --> 01:01:37.340]   in control of your reputation,
[01:01:37.340 --> 01:01:39.780]   because you did nothing to create a reputation.
[01:01:39.780 --> 01:01:42.780]   So that's my point, is that you don't create one,
[01:01:42.780 --> 01:01:44.380]   then anybody who says anything about you,
[01:01:44.380 --> 01:01:46.020]   that's now the Google result.
[01:01:46.020 --> 01:01:50.300]   - It's just a real terrible Sophie's Choice situation.
[01:01:50.300 --> 01:01:54.060]   - Yeah, and maybe when you talk to these teenagers,
[01:01:54.060 --> 01:01:56.020]   like you do on a regular basis for some reason,
[01:01:56.020 --> 01:02:01.020]   if you are also encouraging them to be as critical
[01:02:01.020 --> 01:02:05.620]   and as active in the creation of this world as possible.
[01:02:05.620 --> 01:02:08.900]   I think if we just tell people you need a website,
[01:02:08.900 --> 01:02:11.460]   you need a MySpace account, you need a Twitter account,
[01:02:11.460 --> 01:02:15.100]   you need an Oculus, that's the feeding to the slaughter
[01:02:15.100 --> 01:02:16.100]   that I'm concerned about.
[01:02:16.100 --> 01:02:16.940]   - Yeah, I understand.
[01:02:16.940 --> 01:02:19.620]   - Getting them used to filling up these data troughs
[01:02:19.620 --> 01:02:22.020]   for these companies without questioning what happens
[01:02:22.020 --> 01:02:24.860]   to that data without demanding a user bill of rights
[01:02:24.860 --> 01:02:26.300]   for your information.
[01:02:26.300 --> 01:02:29.700]   Then so pair that request to participate
[01:02:29.700 --> 01:02:31.460]   with what full participation means,
[01:02:31.460 --> 01:02:33.140]   which is just like democracy.
[01:02:33.140 --> 01:02:34.020]   You don't just get to live here.
[01:02:34.020 --> 01:02:36.060]   You have to vote, you gotta do jury duty.
[01:02:36.060 --> 01:02:37.660]   Like there's some active steps you gotta take.
[01:02:37.660 --> 01:02:39.300]   And so I think in the techy world,
[01:02:39.300 --> 01:02:42.140]   we should start demanding for my fellow youths
[01:02:42.140 --> 01:02:45.420]   some challenging and some criticism
[01:02:45.420 --> 01:02:48.820]   or they'll be feeding themselves to a mill that will chew them.
[01:02:48.820 --> 01:02:50.500]   - I will from now, actually they don't let me talk
[01:02:50.500 --> 01:02:52.620]   to teenagers anymore, but if I were,
[01:02:52.620 --> 01:02:56.820]   'cause my kids were teenagers once
[01:02:56.820 --> 01:02:58.300]   and I used to speak at the high school and stuff.
[01:02:58.300 --> 01:02:59.540]   And you know, they always ask tech people,
[01:02:59.540 --> 01:03:01.420]   can you talk to our kids about tech?
[01:03:01.420 --> 01:03:02.820]   'Cause the teachers don't--
[01:03:02.820 --> 01:03:04.180]   - And you go there and say, don't do it.
[01:03:04.180 --> 01:03:05.860]   - Well, I'd say-- - I don't.
[01:03:05.860 --> 01:03:07.460]   - I don't know what to say now, but actually,
[01:03:07.460 --> 01:03:09.620]   I think you actually say a very good thing.
[01:03:09.620 --> 01:03:12.180]   You should be an activist, you need to participate.
[01:03:12.180 --> 01:03:14.420]   And that's really important too,
[01:03:14.420 --> 01:03:16.260]   and make sure that people aren't misusing
[01:03:16.260 --> 01:03:17.500]   that information that you're posting.
[01:03:17.500 --> 01:03:19.300]   - Yeah, and that's probably healthier advice
[01:03:19.300 --> 01:03:22.740]   than a massive multi-sided disinformation campaign,
[01:03:22.740 --> 01:03:24.660]   which ensures a sense of truth, facts, and reality.
[01:03:24.660 --> 01:03:25.820]   - I didn't say they should lie.
[01:03:25.820 --> 01:03:26.660]   I should--
[01:03:26.660 --> 01:03:28.820]   - No, that was basically my implied advice.
[01:03:28.820 --> 01:03:30.500]   I'm sort of updating my testimony.
[01:03:30.500 --> 01:03:34.100]   I'll lodge obsessions to add that I'm not
[01:03:34.100 --> 01:03:36.140]   pro-mass disinformation.
[01:03:36.140 --> 01:03:38.020]   I'm just trying to think on my feet about--
[01:03:38.020 --> 01:03:39.020]   - No, you're actually right.
[01:03:39.020 --> 01:03:40.100]   - Don't-- - And we will amend
[01:03:40.100 --> 01:03:41.900]   the official transcript.
[01:03:41.900 --> 01:03:44.020]   - Don't lie, I agree with you, don't lie,
[01:03:44.020 --> 01:03:46.340]   but at the same time, if you don't post anything,
[01:03:46.340 --> 01:03:47.340]   then you're a little bit at risk.
[01:03:47.340 --> 01:03:48.700]   - And don't pee on the wall.
[01:03:48.700 --> 01:03:50.300]   And actually, probably, if you're gonna pee on the wall,
[01:03:50.300 --> 01:03:52.180]   make sure nobody around has a camera phone,
[01:03:52.180 --> 01:03:53.020]   which is pretty much impossible.
[01:03:53.020 --> 01:03:53.860]   - Which everybody does.
[01:03:53.860 --> 01:03:54.700]   - Good advice. - Don't do that.
[01:03:54.700 --> 01:03:56.300]   - And I didn't share that.
[01:03:56.300 --> 01:03:58.700]   - Find a nice bathroom for what I'm saying.
[01:03:58.700 --> 01:04:00.140]   - Our show today, and we're gonna take a break,
[01:04:00.140 --> 01:04:01.260]   come back with more.
[01:04:01.260 --> 01:04:02.460]   This is a good panel.
[01:04:02.460 --> 01:04:03.500]   There's a lot to talk about.
[01:04:03.500 --> 01:04:04.940]   Make up some-- find something else
[01:04:04.940 --> 01:04:07.660]   that we think will be a deep, rich subject
[01:04:07.660 --> 01:04:09.740]   for our conversation.
[01:04:09.740 --> 01:04:10.580]   - Okay. - Please.
[01:04:10.580 --> 01:04:11.420]   - All right.
[01:04:11.420 --> 01:04:14.140]   Our show today brought to you by the tracker,
[01:04:14.140 --> 01:04:16.180]   a coin-sized tracking device.
[01:04:16.180 --> 01:04:18.500]   Bluetooth is awesome.
[01:04:18.500 --> 01:04:19.740]   It pairs with your phone.
[01:04:19.740 --> 01:04:21.060]   - It's about a-- - Size of a quarter,
[01:04:21.060 --> 01:04:24.300]   lighter than a quarter, it's an anodized aluminum.
[01:04:24.300 --> 01:04:26.580]   It will go on a whole bunch of things.
[01:04:26.580 --> 01:04:29.140]   I certainly have one on my key chain,
[01:04:29.140 --> 01:04:30.540]   but you could put it on your bicycle,
[01:04:30.540 --> 01:04:31.740]   put it underneath a seat.
[01:04:31.740 --> 01:04:34.580]   You could put anywhere that you don't wanna lose something,
[01:04:34.580 --> 01:04:36.820]   and then you pair it to your phone.
[01:04:36.820 --> 01:04:39.460]   You can have up to 10 tracker devices paired to your phone.
[01:04:39.460 --> 01:04:41.140]   If they've got two-way separation alerts,
[01:04:41.140 --> 01:04:42.140]   this is all customizable.
[01:04:42.140 --> 01:04:44.180]   So for instance, if you leave your keys behind your phone
[01:04:44.180 --> 01:04:45.780]   house, you leave your phone behind,
[01:04:45.780 --> 01:04:47.540]   the tracker house, there's a button on the tracker
[01:04:47.540 --> 01:04:51.220]   you can press that will get your phone to go beep, beep, beep.
[01:04:51.220 --> 01:04:54.380]   If you really love the Find My iPhone feature,
[01:04:54.380 --> 01:04:55.580]   who doesn't, right?
[01:04:55.580 --> 01:04:56.860]   That's a great, brilliant feature.
[01:04:56.860 --> 01:04:58.180]   Android does it too.
[01:04:58.180 --> 01:05:00.700]   This is like that for everything.
[01:05:00.700 --> 01:05:02.860]   Now where everything is at any time.
[01:05:02.860 --> 01:05:05.180]   Now it is Bluetooth, so that means after 100 feet,
[01:05:05.180 --> 01:05:06.420]   you're gonna lose sight of your tracker.
[01:05:06.420 --> 01:05:07.500]   But here's the good news.
[01:05:07.500 --> 01:05:11.820]   Tracker has the world's largest crowd GPS networks.
[01:05:11.820 --> 01:05:14.420]   See, there's four and a half million trackers
[01:05:14.420 --> 01:05:17.580]   all over the world, and whenever you come within,
[01:05:17.580 --> 01:05:20.780]   your tracker comes within the purview of somebody
[01:05:20.780 --> 01:05:22.460]   who has the software running on their phone,
[01:05:22.460 --> 01:05:24.940]   another tracker owner, their phone will go,
[01:05:24.940 --> 01:05:26.700]   oh, I see Leo's tracker.
[01:05:26.700 --> 01:05:28.340]   Hey, and then ping my phone and say,
[01:05:28.340 --> 01:05:30.180]   hey, your keys, they're in Abu Dhabi.
[01:05:30.180 --> 01:05:31.140]   How'd they get there?
[01:05:31.140 --> 01:05:33.020]   I don't know, but that's where they are right now.
[01:05:33.020 --> 01:05:37.420]   And that is called crowd sourced tracking.
[01:05:37.420 --> 01:05:38.500]   It's awesome.
[01:05:38.500 --> 01:05:40.340]   We've got the custom laser engraving.
[01:05:40.340 --> 01:05:41.940]   That's, these are great if you put it on a pet.
[01:05:41.940 --> 01:05:43.540]   Small enough, light enough for a pet.
[01:05:43.540 --> 01:05:46.140]   They have a waterproof enclosure you can put on it.
[01:05:46.140 --> 01:05:47.460]   You can also have image printing.
[01:05:47.460 --> 01:05:49.620]   They use a really neat UV LED technology
[01:05:49.620 --> 01:05:51.780]   that will not rub off.
[01:05:51.780 --> 01:05:53.580]   They have a variety of other accessories.
[01:05:53.580 --> 01:05:55.340]   And here's a really great deal.
[01:05:56.220 --> 01:05:58.820]   If you go right now to the tracker.com
[01:05:58.820 --> 01:06:01.140]   and place your order, order as many trackers
[01:06:01.140 --> 01:06:02.820]   and other accessories as you need,
[01:06:02.820 --> 01:06:04.340]   and then enter the promo code TWIT,
[01:06:04.340 --> 01:06:06.100]   they're gonna throw in an extra tracker bravo
[01:06:06.100 --> 01:06:08.980]   with any order, an extra tracker bravo free
[01:06:08.980 --> 01:06:12.740]   with any order when you use the offer code TWIT.
[01:06:12.740 --> 01:06:15.540]   I love the tracker.
[01:06:15.540 --> 01:06:18.540]   You can, unlike some of these other devices,
[01:06:18.540 --> 01:06:19.660]   the battery is replaceable.
[01:06:19.660 --> 01:06:21.740]   You don't throw it out when the battery dies.
[01:06:21.740 --> 01:06:23.300]   You can get a new battery in just one of those
[01:06:23.300 --> 01:06:24.220]   little coin size batteries.
[01:06:24.220 --> 01:06:25.460]   You can get a drugstore.
[01:06:25.460 --> 01:06:26.620]   And that is a nice thing too.
[01:06:26.620 --> 01:06:28.060]   30 day money back guarantee,
[01:06:28.060 --> 01:06:29.660]   no reason not to give it a try.
[01:06:29.660 --> 01:06:33.060]   T-H-E-T-R-A, C-K-R.com and the promo code TWIT
[01:06:33.060 --> 01:06:35.980]   will get you a free tracker bravo.
[01:06:35.980 --> 01:06:37.820]   I put them in my suitcase in my luggage.
[01:06:37.820 --> 01:06:39.260]   That's also a great idea.
[01:06:39.260 --> 01:06:40.100]   - Yeah.
[01:06:40.100 --> 01:06:41.940]   - All right.
[01:06:41.940 --> 01:06:46.300]   There's many, many stories we could talk about.
[01:06:46.300 --> 01:06:51.380]   But we've had so much fun with the first two or three.
[01:06:51.380 --> 01:06:55.780]   - Well, can I quickly, I don't mean to plug an article I wrote.
[01:06:55.780 --> 01:06:56.900]   - Go right ahead.
[01:06:56.900 --> 01:06:59.140]   - But I discovered in writing an article,
[01:06:59.140 --> 01:07:01.940]   so as you know, I'm a digital nomad,
[01:07:01.940 --> 01:07:06.260]   I live nomadically, oftentimes abroad, sometimes in the US.
[01:07:06.260 --> 01:07:11.260]   And this lifestyle started in the 90s.
[01:07:11.260 --> 01:07:16.500]   The idea for it was arrived at by a Hitachi executive
[01:07:16.500 --> 01:07:18.100]   who wrote a book called Digital Nomad.
[01:07:18.100 --> 01:07:20.220]   And it was an obscure thing that book was ignored.
[01:07:20.220 --> 01:07:21.060]   Yeah.
[01:07:21.060 --> 01:07:23.300]   And then Tim Ferriss in "For Our Work Week"
[01:07:23.300 --> 01:07:25.540]   popularized the idea a lot more than he did.
[01:07:25.540 --> 01:07:28.300]   That was about 10 years ago now, that book was written.
[01:07:28.300 --> 01:07:29.780]   And now there's something that I call
[01:07:29.780 --> 01:07:31.580]   the digital nomad industrial complex.
[01:07:31.580 --> 01:07:34.740]   There are so many companies out there
[01:07:34.740 --> 01:07:37.340]   that provide all kinds of services for digital nomads,
[01:07:37.340 --> 01:07:40.340]   from incredible apps, and everybody can use these services.
[01:07:40.340 --> 01:07:42.220]   Anybody who travels.
[01:07:42.220 --> 01:07:45.420]   But, you know, incredible apps, incredible, like,
[01:07:45.420 --> 01:07:47.940]   the biggest thing is that you can be a digital nomad
[01:07:47.940 --> 01:07:51.940]   temporarily, like for a week or a month or two months.
[01:07:51.940 --> 01:07:54.300]   There's some where you take a train across Africa.
[01:07:54.300 --> 01:07:56.780]   There are others where you live with a bunch of people
[01:07:56.780 --> 01:07:57.980]   in different cities and you can switch.
[01:07:57.980 --> 01:08:03.220]   There's a service where you throw your house into the mix
[01:08:03.220 --> 01:08:06.260]   and then you can move every month to a new house
[01:08:06.260 --> 01:08:08.940]   of another member while other people live in your house.
[01:08:08.940 --> 01:08:10.700]   And when you're done, you call it quits
[01:08:10.700 --> 01:08:11.780]   and you go back to your house.
[01:08:11.780 --> 01:08:13.340]   You don't have to sell your house to live abroad
[01:08:13.340 --> 01:08:15.180]   for two years or something like that.
[01:08:15.180 --> 01:08:16.580]   There's so much creativity in this.
[01:08:16.580 --> 01:08:18.420]   There are all kinds of things where they give you,
[01:08:18.420 --> 01:08:22.540]   they'll rent you a ticket for $10 so you can enter a country
[01:08:22.540 --> 01:08:24.540]   without a return ticket, because a lot of countries
[01:08:24.540 --> 01:08:26.420]   don't let you enter if you don't have a return ticket.
[01:08:26.420 --> 01:08:28.580]   And, you know, it's a wonderful world.
[01:08:28.580 --> 01:08:30.220]   There's some fast company, you can find it
[01:08:30.220 --> 01:08:32.580]   and search for it and stuff like that.
[01:08:32.580 --> 01:08:37.100]   But it's just an amazing thing to check out,
[01:08:37.100 --> 01:08:39.460]   this world of digital nomad living.
[01:08:39.460 --> 01:08:41.420]   And if I can plug one thing, Leo--
[01:08:41.420 --> 01:08:42.220]   I would--
[01:08:42.220 --> 01:08:44.140]   So every time you talk about this, I want to do it.
[01:08:44.140 --> 01:08:45.820]   But unfortunately, I'm kind of stuck here.
[01:08:45.820 --> 01:08:47.700]   Well, I told you twice on this show, though,
[01:08:47.700 --> 01:08:49.100]   and I've been on the show that my wife is working
[01:08:49.100 --> 01:08:50.100]   on a secret project.
[01:08:50.100 --> 01:08:51.100]   Oh, yeah.
[01:08:51.100 --> 01:08:55.340]   And that secret project is called Gastronomad Experiences.
[01:08:55.340 --> 01:08:56.340]   And so she's--
[01:08:56.340 --> 01:08:57.340]   Why?
[01:08:57.340 --> 01:09:00.540]   You get to be a digital nomad foodie for about a week,
[01:09:00.540 --> 01:09:02.180]   give or take a couple days to pay on this idea.
[01:09:02.180 --> 01:09:03.180]   Oh, I like it.
[01:09:03.180 --> 01:09:04.180]   So go to Gastronomad.net.
[01:09:04.180 --> 01:09:06.580]   Please tell me Instagram is sponsoring your wife.
[01:09:06.580 --> 01:09:08.420]   Well, they're going to want you--
[01:09:08.420 --> 01:09:09.420]   They're going to want you--
[01:09:09.420 --> 01:09:10.820]   Pretty pictures of food around the world.
[01:09:10.820 --> 01:09:11.820]   Okay.
[01:09:11.820 --> 01:09:14.260]   So the next two are the Barcelona experience
[01:09:14.260 --> 01:09:15.620]   and the Morocco experience.
[01:09:15.620 --> 01:09:17.500]   So you're happening later this year.
[01:09:17.500 --> 01:09:18.780]   What's the website?
[01:09:18.780 --> 01:09:20.700]   Gastronomad.net.
[01:09:20.700 --> 01:09:21.900]   I want to go to there.
[01:09:21.900 --> 01:09:22.540]   Yes.
[01:09:22.540 --> 01:09:25.540]   So what-- as you know, my wife is a super foodie like--
[01:09:25.540 --> 01:09:26.180]   She's great.
[01:09:26.180 --> 01:09:27.500]   One of the best cooks I've ever been mad.
[01:09:27.500 --> 01:09:29.660]   She knows all these people in Barcelona, for example,
[01:09:29.660 --> 01:09:32.180]   are going to come and we're going to do cheese tasting.
[01:09:32.180 --> 01:09:33.180]   And whineries--
[01:09:33.180 --> 01:09:33.700]   What's this?
[01:09:33.700 --> 01:09:34.180]   I'm going.
[01:09:34.180 --> 01:09:34.940]   --wineries.
[01:09:34.940 --> 01:09:35.460]   We're going to--
[01:09:35.460 --> 01:09:36.300]   I'm on my way.
[01:09:36.300 --> 01:09:38.060]   We're going to have cooking classes.
[01:09:38.060 --> 01:09:40.620]   You learn to make paella and things like that.
[01:09:40.620 --> 01:09:47.820]   And so it's just a deep dive into Catalonia cooking, in that case,
[01:09:47.820 --> 01:09:50.500]   and Morocco, the Moroccan food scene in Fez.
[01:09:50.500 --> 01:09:51.940]   You know Fez is not just a hat.
[01:09:51.940 --> 01:09:52.940]   You know that, right?
[01:09:52.940 --> 01:09:54.980]   [LAUGHTER]
[01:09:54.980 --> 01:09:55.740]   And--
[01:09:55.740 --> 01:09:58.660]   Wait, is your wife basically letting everybody be Anthony Bourdain?
[01:09:58.660 --> 01:09:59.180]   Yeah.
[01:09:59.180 --> 01:09:59.700]   Exactly.
[01:09:59.700 --> 01:10:02.260]   I feel like we have just scaled Anthony Bourdain.
[01:10:02.260 --> 01:10:02.780]   Exactly.
[01:10:02.780 --> 01:10:03.940]   That's a dream.
[01:10:03.940 --> 01:10:06.420]   So if you watch his show, that's what it's all about.
[01:10:06.420 --> 01:10:07.860]   Because food is more than food.
[01:10:07.860 --> 01:10:10.300]   Food is a window into a culture.
[01:10:10.300 --> 01:10:11.820]   So this is really a new business for you.
[01:10:11.820 --> 01:10:12.820]   It's a new business.
[01:10:12.820 --> 01:10:14.500]   It's mostly my wife's business.
[01:10:14.500 --> 01:10:17.980]   And I'm sort of an employee of her business, to a certain extent.
[01:10:17.980 --> 01:10:20.020]   But it's a new business that she's launching.
[01:10:20.020 --> 01:10:21.180]   So you're going to--
[01:10:21.180 --> 01:10:22.380]   it'd be like a tour.
[01:10:22.380 --> 01:10:24.540]   People would buy this and go on tour with you.
[01:10:24.540 --> 01:10:25.900]   It's in one place.
[01:10:25.900 --> 01:10:26.980]   So it's focused on the city.
[01:10:26.980 --> 01:10:29.300]   So the Barcelona experience, we've already--
[01:10:29.300 --> 01:10:30.580]   she's already rented the place.
[01:10:30.580 --> 01:10:35.020]   It's a big, beautiful, old apartment house, well-appointed.
[01:10:35.020 --> 01:10:35.500]   Nice.
[01:10:35.500 --> 01:10:37.420]   Everybody goes and stays in the same place.
[01:10:37.420 --> 01:10:39.700]   From morning to night, it's like classes,
[01:10:39.700 --> 01:10:41.260]   adventures, go to places, do things.
[01:10:41.260 --> 01:10:43.300]   But it's all around and in the city.
[01:10:43.300 --> 01:10:44.420]   This is a great idea.
[01:10:44.420 --> 01:10:45.580]   Yeah, it's a great idea.
[01:10:45.580 --> 01:10:46.780]   It's going to be great.
[01:10:46.780 --> 01:10:49.260]   And it's also we have to do the research, right?
[01:10:49.260 --> 01:10:51.100]   So we're going to be going to Barcelona.
[01:10:51.100 --> 01:10:51.580]   Aw.
[01:10:51.580 --> 01:10:53.460]   A couple of months, we're going to be going to Morocco.
[01:10:53.460 --> 01:10:54.260]   To like we have to--
[01:10:54.260 --> 01:10:54.940]   A terrible--
[01:10:54.940 --> 01:10:55.900]   Terrible life, huh?
[01:10:55.900 --> 01:10:56.700]   It's all deductible.
[01:10:56.700 --> 01:10:57.780]   It's all deductible.
[01:10:57.780 --> 01:10:58.580]   They're suffering.
[01:10:58.580 --> 01:10:59.260]   This is work.
[01:10:59.260 --> 01:10:59.780]   Yes.
[01:10:59.780 --> 01:11:00.740]   We believe that.
[01:11:00.740 --> 01:11:03.660]   I think we should have a Williamsburg gastronomad.
[01:11:03.660 --> 01:11:08.020]   And you could have a gastronomad with the Baratunde Thurston.
[01:11:08.020 --> 01:11:09.180]   That'd be awesome.
[01:11:09.180 --> 01:11:10.380]   So just let me--
[01:11:10.380 --> 01:11:11.140]   I got to clarify.
[01:11:11.140 --> 01:11:12.740]   I don't want to give away my actual address.
[01:11:12.740 --> 01:11:14.100]   You have to wear pants, though.
[01:11:14.100 --> 01:11:14.980]   I do not.
[01:11:14.980 --> 01:11:17.060]   Nor have I ever lived in Williamsburg.
[01:11:17.060 --> 01:11:18.780]   I do live in Brooklyn.
[01:11:18.780 --> 01:11:19.940]   I just paid that up.
[01:11:19.940 --> 01:11:21.140]   I know you live in the Heights.
[01:11:21.140 --> 01:11:21.660]   I know.
[01:11:21.660 --> 01:11:21.980]   I know.
[01:11:21.980 --> 01:11:24.700]   Southern parts of Brooklyn.
[01:11:24.700 --> 01:11:25.980]   I live south of Williamsburg.
[01:11:25.980 --> 01:11:27.180]   I'll leave it at that.
[01:11:27.180 --> 01:11:27.700]   OK.
[01:11:27.700 --> 01:11:28.740]   Well, that's close enough.
[01:11:28.740 --> 01:11:30.500]   You look like a good Lin-Manuel Miranda, right?
[01:11:30.500 --> 01:11:31.900]   That's right.
[01:11:31.900 --> 01:11:33.980]   We're like this.
[01:11:33.980 --> 01:11:36.460]   You guys are all best friends of assuming this.
[01:11:36.460 --> 01:11:37.820]   Nonstop.
[01:11:37.820 --> 01:11:41.340]   So with the rest of the world, all of Brooklyn is of a piece.
[01:11:41.340 --> 01:11:44.620]   You guys in Brooklyn, you get all these different neighborhoods.
[01:11:44.620 --> 01:11:46.860]   It's Brooklyn to us.
[01:11:46.860 --> 01:11:48.140]   That's great.
[01:11:48.140 --> 01:11:51.420]   So is your wife working with Airbnb, onity of this, Mike?
[01:11:51.420 --> 01:11:53.180]   This sounds very--
[01:11:53.180 --> 01:11:55.100]   She is not working with the company,
[01:11:55.100 --> 01:11:57.020]   but she's working through Airbnb.
[01:11:57.020 --> 01:11:59.660]   She's like the Airbnb master.
[01:11:59.660 --> 01:12:02.540]   I mean, she spends enormous amounts of time on Airbnb,
[01:12:02.540 --> 01:12:04.660]   constantly looking for these amazing places.
[01:12:04.660 --> 01:12:05.300]   This isn't really.
[01:12:05.300 --> 01:12:06.300]   It looks like a lot of fun.
[01:12:06.300 --> 01:12:09.620]   Places that she's locked down for both Morocco
[01:12:09.620 --> 01:12:13.620]   and for Barcelona are fantastic.
[01:12:13.620 --> 01:12:16.020]   The place in Morocco is a 400-year-old Riyadh.
[01:12:16.020 --> 01:12:17.020]   Oh, wow.
[01:12:17.020 --> 01:12:18.020]   We're going to be standing.
[01:12:18.020 --> 01:12:18.740]   It is-- what's a Riyadh?
[01:12:18.740 --> 01:12:23.620]   A Riyadh is like a-- it's a Moroccan-style compound house.
[01:12:23.620 --> 01:12:26.820]   It's like a house where everything's around a central area
[01:12:26.820 --> 01:12:30.100]   and has very tall ceilings and very beautiful stuff.
[01:12:30.100 --> 01:12:32.100]   Riyadh was also a guy on my high school wrestling team.
[01:12:32.100 --> 01:12:33.500]   So there he is.
[01:12:33.500 --> 01:12:34.420]   It's not from a--
[01:12:34.420 --> 01:12:37.580]   So it's a house named after him or is he named after the house?
[01:12:37.580 --> 01:12:39.300]   He's apparently a bigger deal than I imagine.
[01:12:39.300 --> 01:12:41.540]   I should have been nicer to him.
[01:12:41.540 --> 01:12:42.580]   Oh, this says-- good idea.
[01:12:42.580 --> 01:12:43.740]   Mike, you're doing this.
[01:12:43.740 --> 01:12:44.900]   Yeah, and I'm really excited about it.
[01:12:44.900 --> 01:12:47.180]   Gastronomad.net, if you want to know more.
[01:12:47.180 --> 01:12:50.380]   And the first two are Barcelona in September.
[01:12:50.380 --> 01:12:51.620]   And when is Morocco going to be?
[01:12:51.620 --> 01:12:53.220]   Probably at the end of September.
[01:12:53.220 --> 01:12:56.180]   So probably going to bang those out in rapid succession.
[01:12:56.180 --> 01:12:57.380]   Yeah, very nice.
[01:12:57.380 --> 01:12:57.940]   Yeah.
[01:12:57.940 --> 01:12:59.820]   And they're already planning the ones for next year.
[01:12:59.820 --> 01:13:03.300]   So we're going to be going to Prosecco in a month
[01:13:03.300 --> 01:13:05.260]   and do deep research in Prosecco now.
[01:13:05.260 --> 01:13:09.060]   Prosecco is not an overwhelmed with tourists yet.
[01:13:09.060 --> 01:13:09.580]   Park.
[01:13:09.580 --> 01:13:10.080]   Good.
[01:13:10.080 --> 01:13:10.820]   She's a pork comes back.
[01:13:10.820 --> 01:13:11.620]   I love this guy.
[01:13:11.620 --> 01:13:18.340]   And so we're going to be deep work tasting wine.
[01:13:18.340 --> 01:13:21.100]   But we're staying in this ancient farmhouse
[01:13:21.100 --> 01:13:22.420]   and stuff like that.
[01:13:22.420 --> 01:13:24.140]   But this is what we're doing.
[01:13:24.140 --> 01:13:25.460]   And it's just really exciting.
[01:13:25.460 --> 01:13:29.380]   And we invite everybody to check it out and come along.
[01:13:29.380 --> 01:13:30.940]   And we want to get you and Lisa to--
[01:13:30.940 --> 01:13:32.260]   Yeah, I'm in.
[01:13:32.260 --> 01:13:32.860]   Well, comp it.
[01:13:32.860 --> 01:13:33.220]   I mean, no.
[01:13:33.220 --> 01:13:34.420]   No, no, no, don't comp it.
[01:13:34.420 --> 01:13:35.020]   But I'm in.
[01:13:35.020 --> 01:13:36.380]   That sounds a lot of fun.
[01:13:36.380 --> 01:13:36.820]   A lot of fun.
[01:13:36.820 --> 01:13:38.660]   Yeah.
[01:13:38.660 --> 01:13:41.020]   You guys want to talk about Uber?
[01:13:41.020 --> 01:13:41.900]   Oh, yeah.
[01:13:41.900 --> 01:13:43.340]   What's the other thing?
[01:13:43.340 --> 01:13:44.980]   What horrors have they inflicted?
[01:13:44.980 --> 01:13:45.900]   What have they done now?
[01:13:45.900 --> 01:13:46.900]   No, that's the news.
[01:13:46.900 --> 01:13:47.420]   This week--
[01:13:47.420 --> 01:13:48.020]   Have they hired the Uber?
[01:13:48.020 --> 01:13:48.420]   --this week?
[01:13:48.420 --> 01:13:49.060]   --is their CEO?
[01:13:49.060 --> 01:13:51.100]   There was no news about Uber this week.
[01:13:51.100 --> 01:13:52.100]   That's the story.
[01:13:52.100 --> 01:13:52.780]   That's the story.
[01:13:52.780 --> 01:13:53.540]   Oh, no.
[01:13:53.540 --> 01:13:54.700]   I don't believe you.
[01:13:54.700 --> 01:13:55.500]   I don't believe you.
[01:13:55.500 --> 01:13:59.420]   How many deletes do we have here?
[01:13:59.420 --> 01:14:02.780]   Oh, and I did it before it was fashionable.
[01:14:02.780 --> 01:14:03.780]   But before it was trending--
[01:14:03.780 --> 01:14:04.700]   That's a t-shirt.
[01:14:04.700 --> 01:14:07.180]   --before it was trending because--
[01:14:07.180 --> 01:14:08.180]   Yeah.
[01:14:08.180 --> 01:14:08.380]   Well--
[01:14:08.380 --> 01:14:10.580]   I deleted it over before it was cool.
[01:14:10.580 --> 01:14:12.820]   Business practices, man.
[01:14:12.820 --> 01:14:14.140]   I live in New York.
[01:14:14.140 --> 01:14:17.380]   Juneau gives a much better split to the drivers.
[01:14:17.380 --> 01:14:20.060]   Juneau only takes 10% commission versus a closer
[01:14:20.060 --> 01:14:22.580]   to 30% roughly for Uber.
[01:14:22.580 --> 01:14:24.020]   Juneau gives a driver a phone number
[01:14:24.020 --> 01:14:25.540]   they can call when they're experiencing issues
[01:14:25.540 --> 01:14:28.500]   rather than just forcing text messaging.
[01:14:28.500 --> 01:14:30.020]   And you can tip.
[01:14:30.020 --> 01:14:31.460]   And Lyft allows you to tip as well.
[01:14:31.460 --> 01:14:32.540]   I think it's really--
[01:14:32.540 --> 01:14:33.820]   if someone has gone above and beyond,
[01:14:33.820 --> 01:14:35.260]   which a lot of these drivers do because they're trying
[01:14:35.260 --> 01:14:37.140]   to maintain this five-star rating.
[01:14:37.140 --> 01:14:39.860]   So I've had drivers help me with my luggage,
[01:14:39.860 --> 01:14:43.460]   make sure I get safely into my house, do my taxes for me.
[01:14:43.460 --> 01:14:45.580]   These guys are doing a lot of extra work.
[01:14:45.580 --> 01:14:46.580]   And so I want to--
[01:14:46.580 --> 01:14:48.660]   I need that driver to call me.
[01:14:48.660 --> 01:14:49.660]   It's the luck of the job.
[01:14:49.660 --> 01:14:52.220]   But so if you can't represent that,
[01:14:52.220 --> 01:14:54.820]   if you can't account for that financially,
[01:14:54.820 --> 01:14:56.260]   it just sends a weird signal.
[01:14:56.260 --> 01:14:58.580]   And plus the early culture said all the stuff that's coming out
[01:14:58.580 --> 01:15:00.220]   later sort of validates it.
[01:15:00.220 --> 01:15:03.500]   But I think company culture is so important now.
[01:15:03.500 --> 01:15:07.020]   And we have the beauty, unlike our broadband environment,
[01:15:07.020 --> 01:15:09.300]   we have choices in most places.
[01:15:09.300 --> 01:15:11.940]   And certainly between Uber and Lyft in most places.
[01:15:11.940 --> 01:15:14.300]   And so I'm going to choose to spend my money in a place
[01:15:14.300 --> 01:15:17.340]   that is less horrifically misaligned with my values.
[01:15:17.340 --> 01:15:18.980]   I have to say, a lot of--
[01:15:18.980 --> 01:15:23.380]   so the first big Uber-free experiments going on right now
[01:15:23.380 --> 01:15:26.700]   in Austin, Texas, South by Southwest began this week.
[01:15:26.700 --> 01:15:30.620]   And already, there are other ride sharing solutions.
[01:15:30.620 --> 01:15:33.180]   Already, they're having massive problems.
[01:15:33.180 --> 01:15:36.460]   Ride Austin, which is one of the local ride hailing,
[01:15:36.460 --> 01:15:38.540]   alternatives was down for five hours.
[01:15:38.540 --> 01:15:44.860]   Here's Ryan Hoover of Product, and he spent spend an hour
[01:15:44.860 --> 01:15:45.660]   trying to find a ride.
[01:15:45.660 --> 01:15:48.100]   Austin is broken without Uber-R-Lift.
[01:15:48.100 --> 01:15:49.420]   I should point out the reason there
[01:15:49.420 --> 01:15:53.300]   is no Uber-R-Lift in Austin is because Austin didn't want him.
[01:15:53.300 --> 01:15:56.700]   And basically said, you can't be here,
[01:15:56.700 --> 01:15:57.900]   but there are other local--
[01:15:57.900 --> 01:16:00.460]   I like the idea of local ride sharing apps.
[01:16:00.460 --> 01:16:03.820]   You lose, I guess, some of the economies scale.
[01:16:03.820 --> 01:16:05.340]   Sure.
[01:16:05.340 --> 01:16:06.580]   Austin, you want to ride the Houstons?
[01:16:06.580 --> 01:16:07.860]   I don't even know, so I just have a car.
[01:16:07.860 --> 01:16:08.580]   It's like--
[01:16:08.580 --> 01:16:08.980]   Wait a minute.
[01:16:08.980 --> 01:16:09.500]   That's a--
[01:16:09.500 --> 01:16:10.500]   What?
[01:16:10.500 --> 01:16:12.860]   Yeah, I just drive myself.
[01:16:12.860 --> 01:16:14.060]   And it's super weird.
[01:16:14.060 --> 01:16:14.660]   I understand.
[01:16:14.660 --> 01:16:18.060]   When I hear other people say they would die without Uber or Lyft,
[01:16:18.060 --> 01:16:20.780]   I'm like, I can't remember the last time.
[01:16:20.780 --> 01:16:21.660]   So you drive yourself.
[01:16:21.660 --> 01:16:23.660]   It's a self-driving car.
[01:16:23.660 --> 01:16:24.660]   Self-driving car.
[01:16:24.660 --> 01:16:25.740]   Yeah, self-driving car.
[01:16:25.740 --> 01:16:29.780]   I am my car's own self-driver.
[01:16:29.780 --> 01:16:30.780]   That's it.
[01:16:30.780 --> 01:16:30.780]   I actually--
[01:16:30.780 --> 01:16:32.860]   I think I pre-ordered a Model 3 last year,
[01:16:32.860 --> 01:16:36.020]   so I'm dying for my robot car to take me in traffic.
[01:16:36.020 --> 01:16:37.020]   It'll drive you around.
[01:16:37.020 --> 01:16:37.540]   That's what I want.
[01:16:37.540 --> 01:16:38.540]   It'll drive you around.
[01:16:38.540 --> 01:16:41.220]   More than Uber or more than Lyft, guys,
[01:16:41.220 --> 01:16:44.660]   can we just lift the Jetsons and have my robot car take me to work?
[01:16:44.660 --> 01:16:45.420]   That's all I care about.
[01:16:45.420 --> 01:16:47.060]   And then fold up in your suitcase.
[01:16:47.060 --> 01:16:49.020]   Your robot car is going to take you to the moon.
[01:16:49.020 --> 01:16:50.220]   That's the trick.
[01:16:50.220 --> 01:16:52.100]   When Elon says we're going to the moon,
[01:16:52.100 --> 01:16:54.100]   he means like we, like people with his car.
[01:16:54.100 --> 01:16:57.420]   Look, see, if my Model 3 can make it to Trappist 1,
[01:16:57.420 --> 01:16:57.900]   God.
[01:16:57.900 --> 01:16:58.620]   Oh, yeah.
[01:16:58.620 --> 01:17:00.900]   That's the ones with the seven planets.
[01:17:00.900 --> 01:17:01.820]   Yeah, yeah.
[01:17:01.820 --> 01:17:03.260]   Well, did you see that thing in Wired?
[01:17:03.260 --> 01:17:05.500]   It was a concept for--
[01:17:05.500 --> 01:17:09.060]   I don't remember who was promoted in this concept.
[01:17:09.060 --> 01:17:10.420]   But they have these pods.
[01:17:10.420 --> 01:17:13.340]   And the pod goes on this chassis for a self-driving car.
[01:17:13.340 --> 01:17:17.100]   And then you go to the airport, and then a drone picks up the pod.
[01:17:17.100 --> 01:17:18.020]   And you don't even get out.
[01:17:18.020 --> 01:17:22.980]   You go from driving around to flying in the same pod.
[01:17:22.980 --> 01:17:23.980]   I love that idea.
[01:17:23.980 --> 01:17:24.820]   It's never going to happen.
[01:17:24.820 --> 01:17:25.500]   But I love that idea.
[01:17:25.500 --> 01:17:27.180]   But we just lift the Jetsons.
[01:17:27.180 --> 01:17:30.100]   Every day, this is the question I ask when I wake up.
[01:17:30.100 --> 01:17:31.180]   There it is.
[01:17:31.180 --> 01:17:32.020]   Podcar drone.
[01:17:32.020 --> 01:17:33.100]   There were swears on the--
[01:17:33.100 --> 01:17:36.900]   Podcar drone also coming to NBC this fall on "Pride Time."
[01:17:36.900 --> 01:17:37.740]   Yeah.
[01:17:37.740 --> 01:17:40.100]   Yeah.
[01:17:40.100 --> 01:17:42.180]   Well, the Podcar drone sounds like an update.
[01:17:42.180 --> 01:17:45.060]   I'm looking-- I see no bad stories about Uber this week,
[01:17:45.060 --> 01:17:47.340]   which in itself is a story since they've--
[01:17:47.340 --> 01:17:48.180]   Yeah.
[01:17:48.180 --> 01:17:51.660]   There was one story where the CEO was hiring a person
[01:17:51.660 --> 01:17:53.140]   to make him less of a--
[01:17:53.140 --> 01:17:54.300]   A COO.
[01:17:54.300 --> 01:17:55.300]   Yeah.
[01:17:55.300 --> 01:17:56.300]   A COO.
[01:17:56.300 --> 01:17:57.300]   I'm trying to see you.
[01:17:57.300 --> 01:17:58.300]   I'm trying to show you.
[01:17:58.300 --> 01:18:01.260]   He's like, I've realized I'm not such a great person sometimes.
[01:18:01.260 --> 01:18:03.220]   Well, that's a good thing.
[01:18:03.220 --> 01:18:06.700]   A COO, a chief operating officer to make sure
[01:18:06.700 --> 01:18:08.860]   that he operates not like a jerk.
[01:18:08.860 --> 01:18:10.300]   That's what I think that's--
[01:18:10.300 --> 01:18:11.100]   These headlines are--
[01:18:11.100 --> 01:18:12.260]   V-code is amazing.
[01:18:12.260 --> 01:18:15.100]   Uber CEO Travis Kalinik just told staff he's hiring a COO
[01:18:15.100 --> 01:18:16.140]   to help him.
[01:18:16.140 --> 01:18:17.140]   Well, that's fair.
[01:18:17.140 --> 01:18:18.140]   I just need some help.
[01:18:18.140 --> 01:18:19.140]   It sounds like--
[01:18:19.140 --> 01:18:20.140]   Maybe he just needs a life coach.
[01:18:20.140 --> 01:18:21.140]   He's a psychologist.
[01:18:21.140 --> 01:18:22.140]   He just needs a life coach.
[01:18:22.140 --> 01:18:23.140]   Maybe that's better.
[01:18:23.140 --> 01:18:24.140]   This is what Travis Kalinik said.
[01:18:24.140 --> 01:18:27.540]   Travis Kalinik, CEO of Uber said he's looking for a peer who
[01:18:27.540 --> 01:18:31.460]   can partner with me to write the next chapter in our journey.
[01:18:31.460 --> 01:18:32.460]   Maybe he needs an editor.
[01:18:32.460 --> 01:18:33.460]   Yeah.
[01:18:33.460 --> 01:18:34.460]   Right.
[01:18:34.460 --> 01:18:35.460]   Yeah, sure.
[01:18:35.460 --> 01:18:36.460]   Translation, don't let me be a jerk anymore.
[01:18:36.460 --> 01:18:37.460]   So it's a good quote, right?
[01:18:37.460 --> 01:18:38.460]   Because I want to get really, really rich.
[01:18:38.460 --> 01:18:40.820]   But Uber's not going away, is it?
[01:18:40.820 --> 01:18:41.820]   No.
[01:18:41.820 --> 01:18:42.820]   No.
[01:18:42.820 --> 01:18:45.220]   But you shared-- there were some articles about how-- so let me
[01:18:45.220 --> 01:18:46.220]   read everyone.
[01:18:46.220 --> 01:18:48.420]   I was speaking with somebody at a tech company who works at a tech
[01:18:48.420 --> 01:18:52.740]   company a few months ago talking about how change actually happens.
[01:18:52.740 --> 01:18:57.060]   And this person worked at a company that went through a public
[01:18:57.060 --> 01:19:00.580]   scolding and a lot of shame and a lot of negative headlines.
[01:19:00.580 --> 01:19:04.060]   And what changed it inside the company, what changed their practices,
[01:19:04.060 --> 01:19:06.060]   wasn't the public outcry.
[01:19:06.060 --> 01:19:08.500]   In fact, that made people dig in more.
[01:19:08.500 --> 01:19:09.500]   Yeah, that makes sense.
[01:19:09.500 --> 01:19:11.620]   And it was like us versus them.
[01:19:11.620 --> 01:19:12.860]   It was like time zones, right?
[01:19:12.860 --> 01:19:16.180]   The thing that's destroying humanity, Mike.
[01:19:16.180 --> 01:19:23.380]   And so what actually affected change was that the employees felt bad about working there.
[01:19:23.380 --> 01:19:26.180]   The news was so bad that it affected their morale.
[01:19:26.180 --> 01:19:31.340]   People were literally drinking at work, not in a fun way, not with beer pong on Fridays,
[01:19:31.340 --> 01:19:33.580]   like at their desk alone with whiskey.
[01:19:33.580 --> 01:19:36.380]   And they were ashamed to tell their friends where they were.
[01:19:36.380 --> 01:19:37.740]   It was in the newsroom.
[01:19:37.740 --> 01:19:40.420]   And so-- or the White House.
[01:19:40.420 --> 01:19:45.260]   So there's-- I think when you-- there's a tipping point sometimes in culture,
[01:19:45.260 --> 01:19:51.980]   where if you are part of the organization, you signed up, people joined Uber to make money,
[01:19:51.980 --> 01:19:54.940]   probably first and foremost, to be a part of some disruptive change,
[01:19:54.940 --> 01:19:59.180]   maybe like a limited scope of what disruption can mean in society.
[01:19:59.180 --> 01:20:04.780]   But they didn't sign up for like fully endorsed at the executive level,
[01:20:04.780 --> 01:20:06.900]   sexual harassment and dismissal.
[01:20:06.900 --> 01:20:11.700]   They didn't sign up for a CEO who berates his driving partner on camera
[01:20:11.700 --> 01:20:14.020]   and man spreads like ridiculous.
[01:20:14.020 --> 01:20:15.900]   Like that was the most offensive thing about that video to me.
[01:20:15.900 --> 01:20:18.980]   It was like, you're taking up like three seats, which is your three knees, dude.
[01:20:18.980 --> 01:20:24.340]   So if there's pressure building inside of Uber against these practices,
[01:20:24.340 --> 01:20:28.180]   like that's the thing to watch out for, because the trending topics and the, you know,
[01:20:28.180 --> 01:20:30.220]   the public outcry, that ebbs and flows.
[01:20:30.220 --> 01:20:32.700]   People protest and they stop.
[01:20:32.700 --> 01:20:33.700]   People have to go back to work.
[01:20:33.700 --> 01:20:35.900]   People have to use an Uber to get there sometimes.
[01:20:35.900 --> 01:20:40.340]   But if the employees of Uber are feeling frustrated, angry, upset and motivated
[01:20:40.340 --> 01:20:44.500]   to bring about change, then we'll probably see something shift much more than Travis's
[01:20:44.500 --> 01:20:47.420]   statements about trying to be a better person through hiring a COO.
[01:20:47.420 --> 01:20:49.580]   That's actually a really, I think, a student point.
[01:20:49.580 --> 01:20:51.660]   Because the change comes from the inside.
[01:20:51.660 --> 01:20:53.740]   We all learn this when we were in like kindergarten.
[01:20:53.740 --> 01:20:54.980]   And we can affect it from the outside.
[01:20:54.980 --> 01:20:57.740]   We in the media can use shame and ridicule.
[01:20:57.740 --> 01:20:58.860]   Yeah.
[01:20:58.860 --> 01:21:02.940]   Because without that external pressure, those employees probably wouldn't feel so bad.
[01:21:02.940 --> 01:21:03.460]   Right.
[01:21:03.460 --> 01:21:08.980]   But there's this moral point where you look up and you say, what am I a part of?
[01:21:08.980 --> 01:21:12.900]   And if you feel like I am part of something I didn't sign up for.
[01:21:12.900 --> 01:21:16.420]   And so the stories I was getting to that are coming out are other employees looking
[01:21:16.420 --> 01:21:19.740]   at people who excelled at Uber as like a negative mark.
[01:21:19.740 --> 01:21:22.580]   Like, wait, you tried in a culture of misogyny?
[01:21:22.580 --> 01:21:30.100]   I don't know if you're right for, you know, SpaceX or Gashro, no Nomad or whatever
[01:21:30.100 --> 01:21:31.100]   their company might be.
[01:21:31.100 --> 01:21:34.660]   You can't, though, and this is the information which broke this story
[01:21:34.660 --> 01:21:39.780]   Amir, a Friday writing, says that privately two Uber investors who spoke to the
[01:21:39.780 --> 01:21:42.220]   information expressed confidence in Mr.
[01:21:42.220 --> 01:21:43.940]   Kalank to write the ships at one of them.
[01:21:43.940 --> 01:21:47.580]   And I have to say, this is probably the feeling of a lot of investors and
[01:21:47.580 --> 01:21:52.860]   employees you can't ignore the sheer scale of what he's built and the strategy.
[01:21:52.860 --> 01:21:54.100]   Can he be radically changed?
[01:21:54.100 --> 01:21:54.700]   I think so.
[01:21:54.700 --> 01:21:57.260]   Can you bring in Sheryl Sandberg, for instance?
[01:21:57.260 --> 01:21:59.900]   She's Mark Zuckerberg's number two of Facebook.
[01:22:00.620 --> 01:22:01.620]   Yeah, absolutely.
[01:22:01.620 --> 01:22:04.020]   I'd go there before looking for a major change.
[01:22:04.020 --> 01:22:05.460]   Let things play out a little bit.
[01:22:05.460 --> 01:22:07.380]   There doesn't seem to be on the board anyway.
[01:22:07.380 --> 01:22:10.380]   Any interest at all are among investors in changing the leadership.
[01:22:10.380 --> 01:22:13.020]   Part of the, and they, I think they nailed one of the, you know, there's a
[01:22:13.020 --> 01:22:18.060]   part of the story here is that the things that make companies successful
[01:22:18.060 --> 01:22:21.340]   startups are the things that can kill them when they're big companies.
[01:22:21.340 --> 01:22:23.220]   Uber had to be pugnacious.
[01:22:23.220 --> 01:22:25.220]   They had to be gloves off.
[01:22:25.220 --> 01:22:26.340]   Don't care what the law is.
[01:22:26.340 --> 01:22:27.340]   Don't care what's right.
[01:22:27.340 --> 01:22:28.340]   Just get it done.
[01:22:28.340 --> 01:22:30.580]   And that's what put them on the map.
[01:22:30.580 --> 01:22:34.700]   But if they don't change that culture that made them possible, then they're
[01:22:34.700 --> 01:22:35.900]   going to, they're going to go away.
[01:22:35.900 --> 01:22:40.660]   So when you scale, when you scale a company culture, or when you scale a company,
[01:22:40.660 --> 01:22:41.980]   you also scale your culture.
[01:22:41.980 --> 01:22:45.860]   And that, that is why Uber is facing so many problems now because this is now a
[01:22:45.860 --> 01:22:52.060]   systematic problem throughout the company that has scaled to a, to an unmanageable
[01:22:52.060 --> 01:22:52.500]   level.
[01:22:52.500 --> 01:22:53.540]   Yes.
[01:22:53.540 --> 01:22:53.740]   Yeah.
[01:22:53.740 --> 01:22:55.660]   They, they got big break in rules.
[01:22:55.660 --> 01:22:56.660]   Like they were proud of it.
[01:22:56.860 --> 01:23:00.620]   You know, they, they would undermine, you know, governments who didn't want them
[01:23:00.620 --> 01:23:00.980]   there.
[01:23:00.980 --> 01:23:04.100]   They were hyped so aggressively competitive.
[01:23:04.100 --> 01:23:08.700]   And there's something admirable about it, honestly, like you, you get the killer
[01:23:08.700 --> 01:23:10.700]   instincts, like I admire it.
[01:23:10.700 --> 01:23:13.900]   By people watch sports is why people like winners in general.
[01:23:13.900 --> 01:23:15.660]   Oh, he breaks all the rules.
[01:23:15.660 --> 01:23:16.580]   Like it's exciting.
[01:23:16.580 --> 01:23:17.340]   Yeah.
[01:23:17.340 --> 01:23:20.700]   But then you're like five years in, you're like, wait, this dude's breaking a lot of
[01:23:20.700 --> 01:23:21.060]   rules.
[01:23:21.060 --> 01:23:22.660]   Yeah.
[01:23:22.660 --> 01:23:22.860]   Yeah.
[01:23:22.860 --> 01:23:23.780]   Exactly.
[01:23:23.780 --> 01:23:24.460]   Wait a minute.
[01:23:24.460 --> 01:23:26.100]   I don't like this now.
[01:23:26.620 --> 01:23:27.860]   Well, I thought it was really interesting.
[01:23:27.860 --> 01:23:31.620]   There was an article that said, um, to your point, Barrett, there was an article
[01:23:31.620 --> 01:23:37.060]   about how people were waiting to see how many people left Uber after they got their
[01:23:37.060 --> 01:23:38.500]   profit sharing bonuses.
[01:23:38.500 --> 01:23:39.660]   When is that profit sharing?
[01:23:39.660 --> 01:23:40.660]   I wonder when that is.
[01:23:40.660 --> 01:23:42.860]   I think it's like this week or next week.
[01:23:42.860 --> 01:23:43.900]   Like it's very.
[01:23:43.900 --> 01:23:45.180]   It's very on Uber right now.
[01:23:45.180 --> 01:23:45.860]   Hold on a second.
[01:23:45.860 --> 01:23:46.300]   I'm sorry.
[01:23:46.300 --> 01:23:47.300]   See me see news line.
[01:23:47.300 --> 01:23:49.780]   I'll play by the way.
[01:23:49.780 --> 01:23:52.820]   Can you tell your boss not to do it on scene at either?
[01:23:52.820 --> 01:23:55.220]   Because it's listen, listen, listen.
[01:23:55.460 --> 01:23:56.900]   She's the thing playing those.
[01:23:56.900 --> 01:23:57.500]   I know.
[01:23:57.500 --> 01:23:59.780]   At least that's real close to my heart here.
[01:23:59.780 --> 01:24:04.580]   At least if it's Ashley, a squetta, a squetta, a sketta, at least if it's
[01:24:04.580 --> 01:24:07.860]   Ashley, I can assure you that if it's a video with me that auto plays, you'll
[01:24:07.860 --> 01:24:09.060]   at least be entertained.
[01:24:09.060 --> 01:24:10.260]   I enjoy it.
[01:24:10.260 --> 01:24:11.300]   And that's the difference.
[01:24:11.300 --> 01:24:12.060]   Yeah, exactly.
[01:24:12.060 --> 01:24:14.700]   Uh, yeah.
[01:24:14.700 --> 01:24:18.420]   Tech veteran says he's, he's wary of some hiring someone who did well at Uber.
[01:24:18.420 --> 01:24:21.180]   I think that this is the other aspect of this is the reputate.
[01:24:21.180 --> 01:24:26.820]   And in order to write their reputation, they can't just be a normally ethical
[01:24:26.820 --> 01:24:28.300]   company, if that's an oxymoron.
[01:24:28.300 --> 01:24:30.860]   Uh, they have to be super, super ethical now.
[01:24:30.860 --> 01:24:31.580]   Look at Bill Gates.
[01:24:31.580 --> 01:24:35.980]   Bill Gates was people don't remember the Bill Gates when he wasn't so warm and fuzzy.
[01:24:35.980 --> 01:24:38.340]   He used to be the biggest jerk in, in tech.
[01:24:38.340 --> 01:24:41.300]   And he had a terrible rep, reputation for being more
[01:24:41.300 --> 01:24:44.140]   apacious and, and just hyper aggressive.
[01:24:44.140 --> 01:24:51.140]   And it took him, you know, curing major diseases and all of his
[01:24:51.140 --> 01:24:54.740]   money on saving lives for people to go, yeah, I guess he's okay.
[01:24:54.740 --> 01:24:55.740]   Yeah.
[01:24:55.740 --> 01:24:58.220]   So he had to shut a wipe out malaria.
[01:24:58.220 --> 01:24:58.780]   Malaria.
[01:24:58.780 --> 01:24:59.540]   That's what it took.
[01:24:59.540 --> 01:24:59.820]   He had it.
[01:24:59.820 --> 01:25:02.580]   He was when he started doing those Reddit secret Santa's.
[01:25:02.580 --> 01:25:04.020]   Let's all be amazing.
[01:25:04.020 --> 01:25:04.220]   Yeah.
[01:25:04.220 --> 01:25:05.180]   I'll be real here.
[01:25:05.180 --> 01:25:08.580]   That was his ungrinch moment.
[01:25:08.580 --> 01:25:10.260]   That was when his heart grew three sizes.
[01:25:10.260 --> 01:25:11.580]   The ungrinching.
[01:25:11.580 --> 01:25:12.540]   It's a process.
[01:25:12.540 --> 01:25:12.540]   Yeah.
[01:25:12.540 --> 01:25:13.860]   The ungrinching of Bill Gates.
[01:25:13.860 --> 01:25:17.020]   That's going to be the next book that I think he's ungrinched.
[01:25:17.020 --> 01:25:18.140]   We'll just call it ungrinched.
[01:25:18.140 --> 01:25:18.980]   Ungrinched.
[01:25:18.980 --> 01:25:19.980]   The story of Bill Gates.
[01:25:19.980 --> 01:25:20.980]   History of Bill Gates.
[01:25:20.980 --> 01:25:21.940]   So there is a precedent.
[01:25:21.940 --> 01:25:23.180]   It can happen.
[01:25:23.180 --> 01:25:25.580]   But yeah, Bill Gates doesn't run Microsoft anymore.
[01:25:25.580 --> 01:25:27.220]   So there's a clear direction.
[01:25:27.220 --> 01:25:27.420]   Yeah.
[01:25:27.420 --> 01:25:29.500]   Did you see the, oh, that was a funny video.
[01:25:29.500 --> 01:25:33.100]   Did we play this last week, Carson, Mark Zuckerberg and Bill Gates talking?
[01:25:33.100 --> 01:25:35.580]   Because Mark, as you know, so great.
[01:25:35.580 --> 01:25:36.700]   And we play it last week.
[01:25:36.700 --> 01:25:37.340]   Great acting.
[01:25:37.340 --> 01:25:38.300]   Truly great acting.
[01:25:38.300 --> 01:25:38.700]   Yes.
[01:25:38.700 --> 01:25:39.980]   We need to give the Oscar to this.
[01:25:39.980 --> 01:25:40.580]   Yes, we did.
[01:25:40.580 --> 01:25:41.020]   We did.
[01:25:41.020 --> 01:25:41.340]   All right.
[01:25:41.340 --> 01:25:42.860]   So you saw it last week.
[01:25:42.860 --> 01:25:47.300]   Mark and Bill sat down to eat some goldfish and talk about marks.
[01:25:47.300 --> 01:25:48.740]   Honorary degrees.
[01:25:48.740 --> 01:25:50.900]   Living goldfish to prove how tough they are.
[01:25:50.900 --> 01:25:54.100]   No, just we, I zoomed in to find out it was crackers.
[01:25:54.100 --> 01:25:55.100]   OK, good.
[01:25:55.100 --> 01:25:55.260]   Yeah.
[01:25:55.260 --> 01:25:55.940]   Just checking.
[01:25:55.940 --> 01:26:02.820]   Do you guys feel like he got that degree that that's got that honorary degree at Harvard?
[01:26:02.820 --> 01:26:05.540]   Because somebody at Snapchat did it first or.
[01:26:05.540 --> 01:26:07.380]   No, one's money.
[01:26:07.380 --> 01:26:09.020]   They can't be copying.
[01:26:09.020 --> 01:26:11.860]   Like maybe he gave Evan Spiegel an honorary degree.
[01:26:11.860 --> 01:26:15.300]   I would, I would love, I would love it so much.
[01:26:15.300 --> 01:26:18.740]   If I heard that Evan Spiegel had gotten an honorary degree at Harvard,
[01:26:18.740 --> 01:26:20.500]   Zuckerberg was like, I want one of those.
[01:26:20.500 --> 01:26:21.500]   I need that too.
[01:26:21.500 --> 01:26:22.260]   I need that too.
[01:26:22.260 --> 01:26:22.740]   How much?
[01:26:22.740 --> 01:26:23.460]   That does it.
[01:26:23.460 --> 01:26:23.980]   We're doing it.
[01:26:23.980 --> 01:26:24.860]   Just give me a number.
[01:26:24.860 --> 01:26:26.500]   How big a check do I have to write?
[01:26:26.500 --> 01:26:26.940]   That's right.
[01:26:26.940 --> 01:26:27.900]   How big is he?
[01:26:27.900 --> 01:26:28.340]   You're Harvard.
[01:26:28.340 --> 01:26:28.940]   You're Harvard.
[01:26:28.940 --> 01:26:33.460]   Do you, is there a Zuckerberg library or a Zuckerberg garden?
[01:26:33.460 --> 01:26:34.460]   Beritane or.
[01:26:34.460 --> 01:26:36.180]   Uh, maybe.
[01:26:36.180 --> 01:26:39.820]   As yeah, let me tap into the alumni.
[01:26:39.820 --> 01:26:41.500]   And you know everything, don't you?
[01:26:41.500 --> 01:26:42.020]   Sure.
[01:26:42.020 --> 01:26:43.060]   Tap into.
[01:26:43.340 --> 01:26:46.420]   No, as far as I know, there's nothing named after him on campus.
[01:26:46.420 --> 01:26:49.020]   I want to say that I'm very proud of Yale.
[01:26:49.020 --> 01:26:49.460]   Maybe they're.
[01:26:49.460 --> 01:26:54.060]   Now very proud of Yale because Yale renamed Calhoun College.
[01:26:54.060 --> 01:26:58.820]   Remember, Yale's had a college named after one of the John C.
[01:26:58.820 --> 01:27:01.980]   Calhoun, one of the worst proponents of slavery, member of Congress, John C.
[01:27:01.980 --> 01:27:05.100]   Calhoun, eventually people said, you know, we, maybe we should have this
[01:27:05.100 --> 01:27:06.140]   Calhoun college.
[01:27:06.140 --> 01:27:07.220]   And when did they name it?
[01:27:07.220 --> 01:27:07.780]   I loved it.
[01:27:07.780 --> 01:27:08.620]   They named it.
[01:27:08.620 --> 01:27:11.660]   Hopper, Hopper College.
[01:27:12.540 --> 01:27:13.860]   Grace Hopper after Grace Hopper.
[01:27:13.860 --> 01:27:17.020]   I think I don't know if it's the Grace Hopper College or Hopper College.
[01:27:17.020 --> 01:27:17.860]   Hopper College.
[01:27:17.860 --> 01:27:19.740]   I think they'd have a great intramural softball team.
[01:27:19.740 --> 01:27:20.780]   Yeah, they're called the Hoppers.
[01:27:20.780 --> 01:27:22.340]   I think it'd be awesome.
[01:27:22.340 --> 01:27:22.700]   Yeah.
[01:27:22.700 --> 01:27:25.500]   The entomology lab should have been named after Grace Hopper.
[01:27:25.500 --> 01:27:26.620]   She invented the bug.
[01:27:26.620 --> 01:27:27.420]   She invented the bug.
[01:27:27.420 --> 01:27:29.100]   All right.
[01:27:29.100 --> 01:27:31.540]   Who went out and bought a switch this week?
[01:27:31.540 --> 01:27:36.020]   I've been trying to buy a switch since December.
[01:27:36.020 --> 01:27:38.140]   Ashley, a thquether.
[01:27:38.140 --> 01:27:38.540]   I can't.
[01:27:38.540 --> 01:27:40.540]   How do you get one?
[01:27:40.540 --> 01:27:42.340]   It's really well once.
[01:27:42.340 --> 01:27:44.100]   I mean, we can drop that in digitally.
[01:27:44.100 --> 01:27:45.940]   My people are on it.
[01:27:45.940 --> 01:27:46.140]   Can't.
[01:27:46.140 --> 01:27:48.620]   I didn't get in line.
[01:27:48.620 --> 01:27:49.900]   I just went to eBay and bought it.
[01:27:49.900 --> 01:27:50.540]   Does that count?
[01:27:50.540 --> 01:27:52.060]   You eat, baby.
[01:27:52.060 --> 01:27:52.980]   No, that doesn't count.
[01:27:52.980 --> 01:27:54.020]   I didn't.
[01:27:54.020 --> 01:27:54.940]   I'm not a real gamer.
[01:27:54.940 --> 01:27:56.940]   I didn't pay my dues, but I did get one.
[01:27:56.940 --> 01:27:59.340]   And actually what is your process?
[01:27:59.340 --> 01:28:00.420]   How did you end up with this?
[01:28:00.420 --> 01:28:02.460]   Oh, Ashley.
[01:28:02.460 --> 01:28:02.860]   Yes.
[01:28:02.860 --> 01:28:06.940]   Stayed up late the night of the original event in January.
[01:28:06.940 --> 01:28:10.380]   And my best friend, Mike and I sort of knew that some preorder
[01:28:10.380 --> 01:28:11.540]   would open at some point.
[01:28:11.540 --> 01:28:15.420]   I think if it hadn't opened that night, we would have been extremely tired
[01:28:15.420 --> 01:28:19.620]   and not in a good place the next day, but we stayed up.
[01:28:19.620 --> 01:28:23.060]   And then I actually, I think I may have fallen asleep on the couch.
[01:28:23.060 --> 01:28:26.180]   And he, I left my ringer on because I knew he'd be awake.
[01:28:26.180 --> 01:28:28.060]   And then he texted me and said, they're up.
[01:28:28.060 --> 01:28:30.020]   So I actually preordered two.
[01:28:30.020 --> 01:28:34.820]   I got one for Amazon, one from Amazon and one from Best Buy for pickup,
[01:28:34.820 --> 01:28:35.980]   but I didn't trust Best Buy.
[01:28:35.980 --> 01:28:39.620]   So I left the Amazon preorder open and then it turned out Amazon had a
[01:28:39.620 --> 01:28:41.060]   bunch of delivery problems at the switch.
[01:28:41.060 --> 01:28:43.740]   So I did end up getting both though.
[01:28:43.740 --> 01:28:45.100]   So I went to the midnight.
[01:28:45.100 --> 01:28:50.060]   Well, I ended up selling one of them to my, one of my good friends who didn't
[01:28:50.060 --> 01:28:50.740]   get a preorder.
[01:28:50.740 --> 01:28:54.540]   So she had been really busy with work and was dying to have one on launch day for Zelda.
[01:28:54.540 --> 01:28:59.140]   So I had her take that one and then I went and picked up my neon one at Best Buy for
[01:28:59.140 --> 01:29:02.260]   at a mid-light launch, which I have to say, I was really impressed.
[01:29:02.260 --> 01:29:04.500]   The Best Buy launch was really smooth.
[01:29:04.500 --> 01:29:09.140]   They had three tables set up and they let the preorders walk in first
[01:29:09.340 --> 01:29:13.860]   about 15 minutes before midnight and pick out all of the extra accessories and amiibo
[01:29:13.860 --> 01:29:16.740]   and anything they had in stock, whatever.
[01:29:16.740 --> 01:29:20.740]   And yeah, and just say like, well, you know, if you need a pro controller or whatever,
[01:29:20.740 --> 01:29:21.580]   we have that here.
[01:29:21.580 --> 01:29:23.340]   I was able to buy a couple of things.
[01:29:23.340 --> 01:29:24.820]   I got a couple of pro controllers.
[01:29:24.820 --> 01:29:29.220]   I got some amiibo and I bought, I already had a case from Amazon coming.
[01:29:29.220 --> 01:29:33.220]   So I ended up buying all of that and then leaving it was a very easy process.
[01:29:33.220 --> 01:29:35.620]   So I was very impressed with the whole thing.
[01:29:35.620 --> 01:29:38.700]   And then, and then I went home and probably fell asleep because I'm an old woman.
[01:29:39.580 --> 01:29:43.020]   So I've heard vicious rumors that the screen gets scratch really easy.
[01:29:43.020 --> 01:29:44.140]   Is that true?
[01:29:44.140 --> 01:29:48.660]   So the doc, some of the docs are reported to be a little bit bent.
[01:29:48.660 --> 01:29:54.580]   So when you put in the actual switch into the doc, some people are reporting the
[01:29:54.580 --> 01:29:57.220]   bottom left in particular is getting scratched up.
[01:29:57.220 --> 01:30:00.220]   So just be really careful when you put your switch into the doc,
[01:30:00.220 --> 01:30:02.340]   don't fling it out and throw it back in there.
[01:30:02.340 --> 01:30:07.180]   And also, you know, a screen protector, I think is always a good idea for anything
[01:30:07.180 --> 01:30:08.700]   like the switch that you're carrying around.
[01:30:08.700 --> 01:30:14.100]   I mean, a phone like I think has kind of a little, I feel like I want to say that
[01:30:14.100 --> 01:30:17.900]   the screens on our cell phones are probably a little bit better in terms of quality,
[01:30:17.900 --> 01:30:21.060]   gorilla glass, things like that and better, a little more scratch proof.
[01:30:21.060 --> 01:30:24.380]   But yeah, I would say just throw a screen protector on it.
[01:30:24.380 --> 01:30:26.340]   If you're going to be, take it, thrown it in a bag.
[01:30:26.340 --> 01:30:28.180]   I'm not, I don't think I'm ever going to use the doc.
[01:30:28.180 --> 01:30:31.660]   I think I just see it as a portable device, not that I've been able to get my hands
[01:30:31.660 --> 01:30:31.860]   on it.
[01:30:31.860 --> 01:30:33.620]   My 14 year old took it and I haven't seen it since.
[01:30:33.620 --> 01:30:34.660]   You have never seen it.
[01:30:34.660 --> 01:30:36.220]   You'll never see it again because Zelda.
[01:30:36.220 --> 01:30:37.900]   You should have put a tracker on it, Leo.
[01:30:37.900 --> 01:30:38.460]   Yeah.
[01:30:38.460 --> 01:30:38.900]   There we go.
[01:30:38.900 --> 01:30:40.620]   Get a tracker, put it on the back.
[01:30:40.620 --> 01:30:42.180]   Techie, Techie question.
[01:30:42.180 --> 01:30:44.900]   So I, I misrepresented myself.
[01:30:44.900 --> 01:30:47.180]   I did not try to buy a switch in December.
[01:30:47.180 --> 01:30:48.100]   That was impossible.
[01:30:48.100 --> 01:30:50.300]   I tried to get the NES classic.
[01:30:50.300 --> 01:30:50.940]   Oh, yeah.
[01:30:50.940 --> 01:30:52.500]   Who did the little NES classic?
[01:30:52.500 --> 01:30:52.740]   Yeah.
[01:30:52.740 --> 01:30:53.860]   I, I gave up.
[01:30:53.860 --> 01:30:58.140]   What can someone walk me through the, what's the switch?
[01:30:58.140 --> 01:30:59.180]   What's the classic?
[01:30:59.180 --> 01:31:01.060]   What are these two Nintendo products I cannot get?
[01:31:01.060 --> 01:31:04.860]   So the, the classic is the little tiny NES.
[01:31:04.940 --> 01:31:11.340]   So it's, it's real small and you have actual old school NES controller that comes with it.
[01:31:11.340 --> 01:31:13.620]   And you can play 30 NES games.
[01:31:13.620 --> 01:31:15.460]   Is it made by Nintendo or is it a third?
[01:31:15.460 --> 01:31:16.420]   It's made by Nintendo.
[01:31:16.420 --> 01:31:16.860]   Oh, OK.
[01:31:16.860 --> 01:31:17.500]   Right.
[01:31:17.500 --> 01:31:20.980]   And that's the first one that we've seen that Nintendo has actually made.
[01:31:20.980 --> 01:31:25.460]   Manufactured like put out there for everybody to play old school NES games.
[01:31:25.460 --> 01:31:25.940]   It's cute.
[01:31:25.940 --> 01:31:27.380]   It's like a little NES.
[01:31:27.380 --> 01:31:28.140]   Yeah.
[01:31:28.140 --> 01:31:28.580]   It is.
[01:31:28.580 --> 01:31:32.980]   It's, it's actually, it's, it's adorable because it's, it's just so small.
[01:31:32.980 --> 01:31:34.740]   It's like a little kind of a hockey puck.
[01:31:34.740 --> 01:31:35.860]   It could say it's really adorable.
[01:31:35.860 --> 01:31:40.500]   Um, and then yeah, the controller is as wide as the system itself.
[01:31:40.500 --> 01:31:46.060]   Like the real normal sized NES controller is the same with as the NES classic, which is pretty cool.
[01:31:46.060 --> 01:31:48.980]   So, so yeah, that was the big thing.
[01:31:48.980 --> 01:31:50.460]   That was a huge holiday gift.
[01:31:50.460 --> 01:31:52.580]   Like you could not find one of these for the holidays.
[01:31:52.580 --> 01:31:53.580]   That was December.
[01:31:53.580 --> 01:31:56.500]   And I still, so then the switch is not that.
[01:31:56.500 --> 01:31:57.580]   The switch is a new thing.
[01:31:57.580 --> 01:31:58.180]   So new thing.
[01:31:58.180 --> 01:32:00.220]   The switch is Nintendo's new console.
[01:32:00.220 --> 01:32:04.700]   So this is a hybrid handheld and, uh, entertainment.
[01:32:05.060 --> 01:32:06.940]   Console that you can dock.
[01:32:06.940 --> 01:32:12.260]   There's a dock that you put a little kind of tablet into and then you can play on your television.
[01:32:12.260 --> 01:32:14.420]   But then it's actually really seamless.
[01:32:14.420 --> 01:32:18.700]   You just pull it out of the dock and it switches almost instantaneously to the actual switch.
[01:32:18.700 --> 01:32:23.300]   And then there are little controllers that can, you can remove from the sides called joy cons.
[01:32:23.300 --> 01:32:24.340]   They called joy cons.
[01:32:24.340 --> 01:32:25.580]   Like it's so shared the joy.
[01:32:25.580 --> 01:32:26.660]   That's a big thing.
[01:32:26.660 --> 01:32:28.420]   Um, and, uh, yeah.
[01:32:28.420 --> 01:32:34.180]   So I've been playing a legend of Zelda, Breath of the Wild on this, which has been quite fun and, and really delightful.
[01:32:34.420 --> 01:32:38.100]   And super interesting in terms of old open world Zelda games.
[01:32:38.100 --> 01:32:39.820]   But, um, yeah, I can you play it.
[01:32:39.820 --> 01:32:40.380]   Enjoying it.
[01:32:40.380 --> 01:32:42.820]   Can you play classics on the switch?
[01:32:42.820 --> 01:32:44.620]   No, so not yet.
[01:32:44.620 --> 01:32:50.100]   They have not yet opened up the virtual console function on the switch.
[01:32:50.100 --> 01:32:54.860]   They will at some point, I'm guessing probably maybe summer of this year.
[01:32:54.860 --> 01:33:00.180]   I know they'll probably want to have it up and running before the holiday, which is when they're going to want to sell a lot of switches.
[01:33:00.180 --> 01:33:04.020]   There's a new Mario game coming out in probably around November of this year.
[01:33:04.220 --> 01:33:09.140]   So, um, that'll be the big sort of push to sell the switch, but it did do better.
[01:33:09.140 --> 01:33:11.700]   It's the best console launch they've ever had.
[01:33:11.700 --> 01:33:15.580]   So, um, whoa, it doesn't mean it's going to be a really huge success.
[01:33:15.580 --> 01:33:15.900]   Yeah.
[01:33:15.900 --> 01:33:20.220]   Nick, when it feels like a sleeper hit at first, like people don't really know what it was.
[01:33:20.220 --> 01:33:22.900]   And then all of a sudden it sold over a hundred million units.
[01:33:22.900 --> 01:33:31.940]   Nick Wingfield, the, the failing New York Times, uh, interviewed, uh, the Nintendo of America president said it was the best two day sales in their history.
[01:33:32.260 --> 01:33:38.700]   And Zelda was the best selling standalone launch title, uh, Nintendo history beating Super Mario for the N64.
[01:33:38.700 --> 01:33:43.180]   So, uh, uh, that's the only good launch title they've really had since.
[01:33:43.180 --> 01:33:43.380]   Yeah.
[01:33:43.380 --> 01:33:46.660]   But I think it did hurt the switch that they only have that.
[01:33:46.660 --> 01:33:47.140]   They don't.
[01:33:47.140 --> 01:33:50.620]   It's not a lot of games yet, you know, there are some indie games.
[01:33:50.620 --> 01:33:52.100]   I mean, shovel night is really good.
[01:33:52.100 --> 01:33:54.500]   It's really fun, but a lot of people have already played that.
[01:33:54.500 --> 01:34:00.100]   And there's a lot of games that are indie games that people have already checked out on other consoles and other devices.
[01:34:00.100 --> 01:34:03.340]   So yeah, the, but Zelda is such a big game.
[01:34:03.340 --> 01:34:05.020]   How many acres is that open world?
[01:34:05.020 --> 01:34:07.140]   It's so massive.
[01:34:07.140 --> 01:34:07.900]   Thousands of acres.
[01:34:07.900 --> 01:34:21.060]   I was talking to, uh, Tanner last night, one of our, one of Michael's friends, he said he's been in a half an hour just walking, trying to get to like in real time, half an hour, walking, uh, to a tour over there where there was supposed to be something.
[01:34:21.060 --> 01:34:24.820]   And there was a guy who said something and it was useless and that was it.
[01:34:24.820 --> 01:34:26.500]   Now he has to walk back a half an hour.
[01:34:26.500 --> 01:34:27.140]   So it's big.
[01:34:28.100 --> 01:34:31.140]   It's a really big, just the game space is really big.
[01:34:31.140 --> 01:34:33.140]   And also I read that great story.
[01:34:33.140 --> 01:34:49.220]   I think it might have been on Kataku where Miyamoto, the guy who created Mario when he got to play Legend of Zelda for the first time, he actually spent just hours climbing trees in the game because you had never been able to climb before in a Legend of Zelda game.
[01:34:49.220 --> 01:34:49.700]   I can't.
[01:34:49.700 --> 01:34:52.820]   Some day I have to have a switch of my own.
[01:34:52.820 --> 01:34:54.540]   I've completely lost it.
[01:34:54.540 --> 01:34:57.060]   And yeah, Zelda is a guess a very, I'd never played.
[01:34:57.180 --> 01:35:04.900]   I shame to admit, but it's, I guess not surprising for a person who can't pronounce a Sketha, but I have never played Zelda.
[01:35:04.900 --> 01:35:06.620]   And yeah, yeah.
[01:35:06.620 --> 01:35:07.180]   Yeah.
[01:35:07.180 --> 01:35:11.500]   I mean, it's legendary game franchise, legendary game franchise.
[01:35:11.500 --> 01:35:15.420]   And, but this is really the first time we've seen a true kind of open world.
[01:35:15.420 --> 01:35:17.980]   Is this a, so for my first Zelda, is this a good one?
[01:35:17.980 --> 01:35:20.100]   I would say this is a great one.
[01:35:20.100 --> 01:35:20.620]   Okay, good.
[01:35:20.620 --> 01:35:22.340]   You might be spoiled for previous.
[01:35:22.340 --> 01:35:23.780]   So I can't go back now.
[01:35:23.780 --> 01:35:24.380]   Yeah, maybe I.
[01:35:24.380 --> 01:35:30.540]   I mean, there's still some, I mean, look, Ocarina of Time, Twilight Princess, they're all, there's so many amazing Zelda games.
[01:35:30.540 --> 01:35:34.620]   I mean, they're all almost, almost all of them are really, really good.
[01:35:34.620 --> 01:35:36.340]   Even the ones on DS are great.
[01:35:36.340 --> 01:35:42.140]   But I would say this one in particular is just, you can be so creative.
[01:35:42.140 --> 01:35:44.540]   I know I saw the other day on Twitter.
[01:35:44.540 --> 01:35:47.300]   So there's chickens in the game, but they're called Kookos.
[01:35:47.300 --> 01:35:54.300]   And so in this particular Legend of Zelda game, there, somebody posted a video of them throwing a chicken.
[01:35:54.380 --> 01:35:55.300]   At an enemy.
[01:35:55.300 --> 01:36:04.300]   And then the enemy using its AI swipes at the chicken and the chicken gets mad and the Kookos come in a big swarm and kill the enemy.
[01:36:04.300 --> 01:36:07.660]   Yeah, this is the best thing I've ever seen in a lego Zelda game.
[01:36:07.660 --> 01:36:10.220]   The guy is getting killed by chickens.
[01:36:10.220 --> 01:36:10.900]   I'm poultry.
[01:36:10.900 --> 01:36:15.300]   This is great, futuristic Kooko combat system.
[01:36:15.300 --> 01:36:17.220]   Like I'm here for it.
[01:36:17.220 --> 01:36:18.540]   I love the creativity in the game.
[01:36:18.540 --> 01:36:22.740]   People are finding all sorts of ways to defeat enemies, accomplish tasks, solve puzzles.
[01:36:22.740 --> 01:36:24.180]   I mean, it's, it's really, really fun.
[01:36:24.180 --> 01:36:25.780]   But also very overwhelming.
[01:36:25.780 --> 01:36:26.740]   It can be very overwhelming.
[01:36:26.740 --> 01:36:27.500]   There's a lot to do.
[01:36:27.500 --> 01:36:30.660]   I feel like I'm just going to get in bed and play it until the battery dies.
[01:36:30.660 --> 01:36:32.060]   Two and a half hours.
[01:36:32.060 --> 01:36:32.380]   Yeah.
[01:36:32.380 --> 01:36:34.020]   And then falsely, then falsely.
[01:36:34.020 --> 01:36:36.780]   Good.
[01:36:36.780 --> 01:36:37.700]   Thank you for that review.
[01:36:37.700 --> 01:36:40.180]   I'm excited about this and I'm glad Nintendo had a success.
[01:36:40.180 --> 01:36:43.940]   It's not like they're going to go anywhere, but they haven't had a lot of hardware success with the,
[01:36:43.940 --> 01:36:46.340]   since the Wii, the Wii U was kind of a flopping.
[01:36:46.340 --> 01:36:48.780]   It's nice to see them doing something that people are excited about.
[01:36:48.780 --> 01:36:52.380]   It's really a portable gaming system more than a console.
[01:36:52.380 --> 01:36:55.460]   I think so. I mean, when it's in the dock, it's, it's great.
[01:36:55.460 --> 01:36:58.740]   I love to play a game on my TV.
[01:36:58.740 --> 01:36:59.700]   It's fantastic.
[01:36:59.700 --> 01:37:03.540]   But the real beauty of this is being able to just pull it out of the dock.
[01:37:03.540 --> 01:37:06.380]   There are some really great auto saving features in it.
[01:37:06.380 --> 01:37:08.180]   Saves a lot and often.
[01:37:08.180 --> 01:37:12.780]   And you can just take it anywhere you want to go and just open it up and play Zelda.
[01:37:12.780 --> 01:37:19.380]   A console level and console quality Zelda game or any other, you know, Mario Odyssey will be out later this year.
[01:37:19.380 --> 01:37:20.780]   Splatoon, Mario Kart.
[01:37:20.780 --> 01:37:25.900]   I mean, there's a million games that you can play, but the one thing it doesn't have is it the Vita used to have
[01:37:25.900 --> 01:37:27.860]   cellular capabilities.
[01:37:27.860 --> 01:37:30.700]   So you're able to sort of connect on the go with this.
[01:37:30.700 --> 01:37:32.620]   You have to have Wi-Fi or you can.
[01:37:32.620 --> 01:37:33.660]   S Vida.
[01:37:33.660 --> 01:37:38.980]   I've been, I've been, I've been actually like tethering my switch to my phone.
[01:37:38.980 --> 01:37:39.420]   Wow.
[01:37:39.420 --> 01:37:40.220]   That's how I like.
[01:37:40.220 --> 01:37:41.380]   Wow.
[01:37:41.380 --> 01:37:43.580]   Can you play Zelda offline?
[01:37:43.580 --> 01:37:44.220]   There's not enough.
[01:37:44.220 --> 01:37:44.700]   You can.
[01:37:44.700 --> 01:37:45.060]   Oh, you can't.
[01:37:45.060 --> 01:37:46.260]   It's just a cartridge.
[01:37:46.260 --> 01:37:50.620]   But if I want to check my, if I want to go buy something in the store, the eShop or if I want to
[01:37:50.620 --> 01:37:53.020]   check my friend requests or things like that, I just.
[01:37:53.020 --> 01:37:55.820]   There is also something new for Nintendo.
[01:37:55.820 --> 01:37:57.580]   You can buy digital games.
[01:37:57.580 --> 01:37:58.700]   You can download games now.
[01:37:58.700 --> 01:38:00.860]   So you were able to do that on the Wii U.
[01:38:00.860 --> 01:38:03.820]   Yeah, the eShop has been around for a while.
[01:38:03.820 --> 01:38:08.340]   And, and so it's just, this is, I think it's a lot cleaner.
[01:38:08.340 --> 01:38:09.420]   It's a lot faster.
[01:38:09.420 --> 01:38:10.300]   I'll say that much.
[01:38:10.300 --> 01:38:13.180]   The eShop on Wii U was really slow.
[01:38:13.180 --> 01:38:16.180]   This, the loading screens were just brutal.
[01:38:16.180 --> 01:38:20.220]   But yeah, I think overall, like they're still really struggling.
[01:38:20.220 --> 01:38:24.820]   I think a little bit with software and Nintendo is a lot like Apple in a way in that they
[01:38:24.820 --> 01:38:28.980]   really like this kind of closed ecosystem that makes it sort of hard for developers
[01:38:28.980 --> 01:38:30.340]   that are third party.
[01:38:30.340 --> 01:38:31.660]   Yeah, it's a two bucks.
[01:38:31.660 --> 01:38:34.900]   It makes it hard for third party developers to sort of get in.
[01:38:34.900 --> 01:38:39.020]   But supposedly they have been opening the gates a little bit more to make it a little bit more
[01:38:39.020 --> 01:38:39.900]   developer friendly.
[01:38:39.900 --> 01:38:45.620]   And I hope that's the case because I love, I love good games from just about anybody, obviously.
[01:38:45.620 --> 01:38:47.540]   And so the more the merrier.
[01:38:47.860 --> 01:38:53.260]   It's an inch, they've got Skyrim coming, Splatoon, Minecraft, NBA 2K.
[01:38:53.260 --> 01:38:55.540]   They've got some interesting titles, but they're all later this year.
[01:38:55.540 --> 01:38:57.580]   The next one is going to be Mario Kart.
[01:38:57.580 --> 01:38:59.820]   I've got another technical question.
[01:38:59.820 --> 01:39:03.260]   One is I've discovered how to present myself very dramatically.
[01:39:03.260 --> 01:39:05.100]   Like I can go across the screen.
[01:39:05.100 --> 01:39:11.220]   You can also receive like into the dark is the head of better during day come to.
[01:39:11.220 --> 01:39:17.460]   More important than understanding how webcams work in the dark is do the, is it still a feature?
[01:39:17.780 --> 01:39:22.660]   Of the Nintendo Switch that you are forced to blow on the cartridge and high-ins.
[01:39:22.660 --> 01:39:23.380]   No longer.
[01:39:23.380 --> 01:39:23.700]   The game.
[01:39:23.700 --> 01:39:26.100]   And you should also let that go.
[01:39:26.100 --> 01:39:27.380]   They abandon that feature.
[01:39:27.380 --> 01:39:29.180]   You should also not lick them.
[01:39:29.180 --> 01:39:31.100]   This has been like this thing that's been going on.
[01:39:31.100 --> 01:39:37.140]   Apparently Nintendo coded their cartridges for the switch in some, some stuff that makes it
[01:39:37.140 --> 01:39:38.580]   taste incredibly bitter.
[01:39:38.580 --> 01:39:43.500]   I'm guessing that's probably to discourage like kids from putting it in their mouth because
[01:39:43.500 --> 01:39:45.740]   these cartridges are tiny.
[01:39:46.180 --> 01:39:51.420]   They're about the size of their, they're like a little bit thinner than a micro SD card.
[01:39:51.420 --> 01:39:54.620]   So they're really small.
[01:39:54.620 --> 01:39:56.900]   And so I licked one.
[01:39:56.900 --> 01:39:58.020]   I had to do it.
[01:39:58.020 --> 01:40:02.260]   It's yeah, it's it's bitter.
[01:40:02.260 --> 01:40:06.500]   And it's the same stuff that parents put on their kids thumbs so they won't suck them.
[01:40:06.500 --> 01:40:10.540]   In fact, it's dentitoneum benzoate if you're curious.
[01:40:10.820 --> 01:40:16.940]   And in fact, one of our hosts kind of had a kind of weird flashback to that when he used to
[01:40:16.940 --> 01:40:18.860]   suck his thumbs, he says, Oh my God, I hate that.
[01:40:18.860 --> 01:40:21.260]   I think it was Kevin Rose on the news.
[01:40:21.260 --> 01:40:25.500]   I'm going to grab my, I'm going to grab my switch real quick and show you guys the cartridge.
[01:40:25.500 --> 01:40:25.700]   All right.
[01:40:25.700 --> 01:40:27.180]   While you're doing that, we're going to take a break.
[01:40:27.180 --> 01:40:36.580]   Ashley, a sketch is together with us as long as Barrett, Sunday, fifth and Mike
[01:40:36.580 --> 01:40:36.980]   out again.
[01:40:36.980 --> 01:40:38.420]   Have you been sucking your thumb?
[01:40:38.420 --> 01:40:41.900]   I can't have it thucking my thumb and then the breath been though I had gotten to me.
[01:40:41.900 --> 01:40:44.260]   Our show today brought to you by texture.
[01:40:44.260 --> 01:40:47.780]   If you like magazines, who doesn't really some of the best writing in the world.
[01:40:47.780 --> 01:40:48.580]   I know.
[01:40:48.580 --> 01:40:49.540]   Thank God.
[01:40:49.540 --> 01:40:54.500]   Good journalism still happens in the Rolling Stone and Vanity Fair and, and but there's
[01:40:54.500 --> 01:40:57.620]   also consumer reports in this photo journalism from National Geographic.
[01:40:57.620 --> 01:41:02.020]   Here's a way to get them all without subscribing, without buying the new stand
[01:41:02.020 --> 01:41:05.700]   editions at their horrific prices and get them on your iPad or your iPhone or your
[01:41:05.700 --> 01:41:06.300]   Android device.
[01:41:06.300 --> 01:41:07.140]   It's called texture.
[01:41:07.540 --> 01:41:10.020]   Texture is Netflix for magazines.
[01:41:10.020 --> 01:41:13.500]   Unlimited access, 10, normally $10 a month.
[01:41:13.500 --> 01:41:14.940]   You get 200 magazines.
[01:41:14.940 --> 01:41:16.940]   New Yorkers in there.
[01:41:16.940 --> 01:41:21.580]   Vanity Fair, the Atlantic, some of the best investigative journalism.
[01:41:21.580 --> 01:41:26.660]   I know we're all obsessed with US politics, domestic and international news, but there's
[01:41:26.660 --> 01:41:27.100]   gossip.
[01:41:27.100 --> 01:41:31.060]   I got people magazine in there too, which is nice because I would feel guilty buying
[01:41:31.060 --> 01:41:31.340]   that.
[01:41:31.340 --> 01:41:35.580]   I try to like kind of quickly look at it when I'm in the grocery store, but nobody's
[01:41:35.580 --> 01:41:35.980]   watching.
[01:41:35.980 --> 01:41:37.060]   No, I can actually hear.
[01:41:37.060 --> 01:41:39.260]   Here's some of my texture magazines, Leo.
[01:41:39.260 --> 01:41:40.620]   We got we got Fast Company.
[01:41:40.620 --> 01:41:41.020]   Yep.
[01:41:41.020 --> 01:41:42.420]   We got we got Esquire.
[01:41:42.420 --> 01:41:43.380]   We got Ebony.
[01:41:43.380 --> 01:41:43.620]   Yeah.
[01:41:43.620 --> 01:41:47.300]   Well, yeah, and modern farmer and AARP.
[01:41:47.300 --> 01:41:48.700]   Wait a minute.
[01:41:48.700 --> 01:41:50.580]   My farmers are great publication.
[01:41:50.580 --> 01:41:51.380]   Yeah.
[01:41:51.380 --> 01:41:53.180]   I like to read about politics.
[01:41:53.180 --> 01:41:55.180]   So is teen Vogue included?
[01:41:55.180 --> 01:41:57.020]   Yes, I need that.
[01:41:57.020 --> 01:41:58.420]   So grown up Vogue is there.
[01:41:58.420 --> 01:41:59.980]   I don't know if teen Vogue is there.
[01:41:59.980 --> 01:42:01.580]   Lauren Duka, great writer.
[01:42:01.580 --> 01:42:03.180]   She is killing it.
[01:42:03.180 --> 01:42:04.500]   Thank you for brushing it.
[01:42:04.500 --> 01:42:05.140]   This is her body.
[01:42:05.140 --> 01:42:06.660]   You should follow Lauren Duka.
[01:42:06.660 --> 01:42:10.020]   She is murdering Twitter and also longer form texts.
[01:42:10.020 --> 01:42:11.340]   It's really amazing, isn't it?
[01:42:11.340 --> 01:42:13.340]   So you see, we love magazines.
[01:42:13.340 --> 01:42:15.460]   Your thing is it's clutter on the coffee table.
[01:42:15.460 --> 01:42:16.980]   If you subscribe, you feel guilty.
[01:42:16.980 --> 01:42:21.100]   I, you know, I used to subscribe to the New Yorker and it was like a assignment every
[01:42:21.100 --> 01:42:21.340]   week.
[01:42:21.340 --> 01:42:22.460]   They had to go through all this.
[01:42:22.460 --> 01:42:24.060]   I felt guilty if I didn't read it.
[01:42:24.060 --> 01:42:27.940]   But this way, you know, you get you can favorite your magazines.
[01:42:27.940 --> 01:42:28.780]   It'll auto download.
[01:42:28.780 --> 01:42:29.780]   You can read them offline.
[01:42:29.780 --> 01:42:33.460]   You could put them up on up to five devices so you can share it with the family.
[01:42:33.740 --> 01:42:37.620]   It's a one of Apple's top 2016 iPad apps, but it works on Android as well.
[01:42:37.620 --> 01:42:37.820]   Yeah.
[01:42:37.820 --> 01:42:40.940]   And this is a solution to the filter bubble problem.
[01:42:40.940 --> 01:42:41.340]   Yes.
[01:42:41.340 --> 01:42:45.340]   There are two problems open your eyes, getting your stuff, reading whatever comes
[01:42:45.340 --> 01:42:47.860]   down across your social media has two problems.
[01:42:47.860 --> 01:42:52.660]   One, there's a lot of garbage and two filter bubbles create themselves just
[01:42:52.660 --> 01:42:53.580]   through the algorithms.
[01:42:53.580 --> 01:42:55.260]   You subscribe to texture.
[01:42:55.260 --> 01:42:58.860]   You get the national review for the for the national for smart
[01:42:58.860 --> 01:43:01.140]   right wing politics.
[01:43:01.140 --> 01:43:01.420]   Yeah.
[01:43:01.540 --> 01:43:05.740]   You get the New Yorker for smart left wing politics and in between
[01:43:05.740 --> 01:43:09.580]   there's stuff that isn't political and you can just shatter your filter bubble
[01:43:09.580 --> 01:43:12.780]   and eliminate garbage content for your life and get the highest quality.
[01:43:12.780 --> 01:43:14.580]   Shatter the filter bubble.
[01:43:14.580 --> 01:43:15.580]   Boom.
[01:43:15.580 --> 01:43:16.540]   Boom.
[01:43:16.540 --> 01:43:19.940]   And you know, commercial within a commercial.
[01:43:19.940 --> 01:43:25.380]   I also like it that, you know, there's stuff that like variety and ad week and
[01:43:25.380 --> 01:43:29.060]   billboard that I like to read, but I wouldn't subscribe to the very expensive.
[01:43:29.060 --> 01:43:30.220]   And this way it's there.
[01:43:30.260 --> 01:43:32.180]   Make magazine, make is great.
[01:43:32.180 --> 01:43:33.220]   It's really straight.
[01:43:33.220 --> 01:43:35.220]   I plug scene at magazine.
[01:43:35.220 --> 01:43:35.900]   I saw there.
[01:43:35.900 --> 01:43:36.300]   TDA.
[01:43:36.300 --> 01:43:37.220]   Yay.
[01:43:37.220 --> 01:43:38.180]   See.
[01:43:38.180 --> 01:43:39.580]   So here's the deal.
[01:43:39.580 --> 01:43:41.460]   We got two weeks free for you right now.
[01:43:41.460 --> 01:43:43.620]   Fourteen day free trial.
[01:43:43.620 --> 01:43:44.860]   If you go to texture.
[01:43:44.860 --> 01:43:46.860]   Dot com slash to a texture.
[01:43:46.860 --> 01:43:49.820]   Dot com slash to it two weeks aren't going to be enough.
[01:43:49.820 --> 01:43:50.820]   But at least it gives you a start.
[01:43:50.820 --> 01:43:51.140]   Yep.
[01:43:51.140 --> 01:43:51.780]   I love it.
[01:43:51.780 --> 01:43:52.460]   I just love it.
[01:43:52.460 --> 01:43:57.300]   Uh, we had a great week, a fun week and we have a highlight reel that we've put
[01:43:57.300 --> 01:43:59.780]   together because we're all looking for work right now.
[01:43:59.780 --> 01:44:00.620]   Let's take a look.
[01:44:00.620 --> 01:44:02.500]   Previously on Twitter.
[01:44:02.500 --> 01:44:08.060]   Apparently, e-cigarette device batteries are also something that you need to keep an eye on
[01:44:08.060 --> 01:44:13.220]   or they might light your pants on fire in your defendant's arson case.
[01:44:13.220 --> 01:44:16.940]   The jury can't believe a lawyer who's clearly a liar, right?
[01:44:16.940 --> 01:44:19.020]   Triangulation.
[01:44:19.020 --> 01:44:21.860]   We've got a great one today.
[01:44:21.860 --> 01:44:23.260]   Cyber junkies here.
[01:44:23.260 --> 01:44:28.100]   Mark Rogers, the principal security researcher at CloudFlare.
[01:44:28.140 --> 01:44:30.260]   He's head of security at Defcon.
[01:44:30.260 --> 01:44:32.540]   That's got to be the toughest job in the world.
[01:44:32.540 --> 01:44:35.020]   If you really want to change the world, you do it as a white hat.
[01:44:35.020 --> 01:44:38.620]   When you look at the complex problems that nation states face, the only person that's
[01:44:38.620 --> 01:44:40.180]   going to be able to dig them out is a hacker.
[01:44:40.180 --> 01:44:42.220]   Tech news today.
[01:44:42.220 --> 01:44:43.940]   Everyone should have a dream.
[01:44:43.940 --> 01:44:48.980]   Justin Kobielka's dream was to create a snake with emoji on its scales.
[01:44:48.980 --> 01:44:51.020]   It's called the emoji ball python.
[01:44:51.020 --> 01:44:57.140]   Kobielka created it through breeding because recessive mutation causes this pattern.
[01:44:57.300 --> 01:45:01.940]   So it has two smiley emoji and one alien emoji.
[01:45:01.940 --> 01:45:02.940]   Very exciting.
[01:45:02.940 --> 01:45:06.740]   It's a Python story and a technology podcast that has nothing to do with Python.
[01:45:06.740 --> 01:45:07.220]   It's true.
[01:45:07.220 --> 01:45:07.700]   Yes.
[01:45:07.700 --> 01:45:08.220]   Twit.
[01:45:08.220 --> 01:45:10.220]   The happiest place on earth.
[01:45:10.220 --> 01:45:11.740]   Wow.
[01:45:11.740 --> 01:45:13.860]   Megan Moroni, that was a great week.
[01:45:13.860 --> 01:45:15.020]   What's coming up next week?
[01:45:15.020 --> 01:45:19.060]   Here's a look at just a few of the stories we'll be following in the week
[01:45:19.060 --> 01:45:24.100]   ahead, South by Southwest has already started and we'll continue through next week.
[01:45:24.220 --> 01:45:28.660]   Of course, this was the conference where Twitter, four square and Muircat were all
[01:45:28.660 --> 01:45:29.100]   born.
[01:45:29.100 --> 01:45:33.420]   So we'll be curious as to what to expect to come out of this conference where
[01:45:33.420 --> 01:45:39.140]   people will have to find some other way to get around besides Uber or Lyft, both
[01:45:39.140 --> 01:45:42.780]   of which were not allowed inside the Austin city limits.
[01:45:42.780 --> 01:45:45.300]   There are some other conferences going on this week.
[01:45:45.300 --> 01:45:50.580]   Also, ad tech in Sydney, the experimental technology conference in San Francisco and
[01:45:50.580 --> 01:45:56.620]   O'Reilly Strata plus Hadoop world in San Jose plus gaming site Twitch is finally
[01:45:56.620 --> 01:45:57.940]   getting a desktop app.
[01:45:57.940 --> 01:46:02.460]   It's a revamped version of a chat app called Curse that Twitch bought last year
[01:46:02.460 --> 01:46:05.700]   and it will launch this week on March 16th.
[01:46:05.700 --> 01:46:06.220]   There's my.
[01:46:06.220 --> 01:46:07.780]   Ever heard of Mule Soft?
[01:46:07.780 --> 01:46:08.580]   Me neither.
[01:46:08.580 --> 01:46:13.180]   They provide integration software for connecting applications, data and devices.
[01:46:13.180 --> 01:46:15.500]   And they are set to IPO this week.
[01:46:15.500 --> 01:46:20.180]   I'm guessing their initial public offering will be quite a little bit less
[01:46:20.180 --> 01:46:24.860]   buzzy than Snapchat's a few weeks ago, but I'm all for more software IPOs.
[01:46:24.860 --> 01:46:31.060]   And for every new startup that's born, it seems that another one closes its doors.
[01:46:31.060 --> 01:46:36.580]   The one time competitor to Twitter called AppNet will shut down this week on March 14th.
[01:46:36.580 --> 01:46:41.780]   The social network worked on the subscription model and your messages could be a whopping
[01:46:41.780 --> 01:46:44.060]   256 characters.
[01:46:44.060 --> 01:46:48.940]   The premium service never really worked out well for AppNet and they had to pivot to
[01:46:48.940 --> 01:46:52.900]   the premium service just a few months after launch and now they're closing down.
[01:46:52.900 --> 01:46:57.660]   And finally, this is the week that Google says they will purge millions of apps from
[01:46:57.660 --> 01:47:01.980]   the app store if they violate the Play Store's user data policy.
[01:47:01.980 --> 01:47:06.220]   Google first warned app developers last month and the deadline is now Wednesday,
[01:47:06.220 --> 01:47:07.460]   March 15th.
[01:47:07.460 --> 01:47:11.740]   According to a letter to developers, most apps merely need a valid privacy policies.
[01:47:11.740 --> 01:47:14.300]   So get your privacy policies in their developers.
[01:47:14.300 --> 01:47:18.860]   And that is a look at a few of the things we'll be tracking in the coming week.
[01:47:19.100 --> 01:47:23.300]   You can join Jason Howell and me on Tech News Today, every week day at 4 p.m.
[01:47:23.300 --> 01:47:24.940]   Pacific, 7 p.m.
[01:47:24.940 --> 01:47:27.260]   Eastern here on twit.tv.
[01:47:27.260 --> 01:47:29.340]   Thank you, Megan Maroney.
[01:47:29.340 --> 01:47:33.500]   And of course, we want to welcome a new member to the twit team.
[01:47:33.500 --> 01:47:36.660]   Nathan Oliveras Giles joins us on Monday.
[01:47:36.660 --> 01:47:38.220]   So that'll be a question about that.
[01:47:38.220 --> 01:47:39.700]   Yeah, that's a great hire.
[01:47:39.700 --> 01:47:40.620]   He is great.
[01:47:40.620 --> 01:47:43.740]   We needed some yute, yute on the on the steve.
[01:47:43.740 --> 01:47:44.540]   Bring in the yutes.
[01:47:44.540 --> 01:47:45.380]   Bring in the yutes.
[01:47:45.380 --> 01:47:47.620]   So is he commuting from San Francisco?
[01:47:47.620 --> 01:47:48.940]   Because I believe he lives in San Francisco.
[01:47:48.940 --> 01:47:49.820]   I believe he will be.
[01:47:49.820 --> 01:47:50.180]   Yeah.
[01:47:50.180 --> 01:47:50.460]   Wow.
[01:47:50.460 --> 01:47:51.300]   That's that's awesome.
[01:47:51.300 --> 01:47:52.380]   It's a brave boy.
[01:47:52.380 --> 01:47:52.820]   Yeah.
[01:47:52.820 --> 01:47:55.820]   But we really, yeah, we're really thrilled to get him.
[01:47:55.820 --> 01:47:57.420]   And we're working on new shows with him.
[01:47:57.420 --> 01:47:59.860]   And meanwhile, he'll be around for all of our shows.
[01:47:59.860 --> 01:48:01.260]   And it'd be great to have Nathan.
[01:48:01.260 --> 01:48:02.620]   Is he on next week?
[01:48:02.620 --> 01:48:03.860]   He might be on next week on twit.
[01:48:03.860 --> 01:48:06.140]   But anyway, we'll celebrate that.
[01:48:06.140 --> 01:48:06.860]   Yes, he is.
[01:48:06.860 --> 01:48:07.780]   It's terrified.
[01:48:07.780 --> 01:48:10.820]   I was going to have a BBC moment today where my dogs like came running in.
[01:48:10.820 --> 01:48:13.460]   Oh, that's another thing I wanted to talk about.
[01:48:13.460 --> 01:48:13.820]   Don't I?
[01:48:13.820 --> 01:48:14.420]   I forgot.
[01:48:14.780 --> 01:48:18.860]   Do you I didn't notice until the like 800 the time I watched that video?
[01:48:18.860 --> 01:48:22.420]   Did you notice that the the wife's pants are halfway down?
[01:48:22.420 --> 01:48:26.140]   So clearly she was going to the bathroom and her kids ran.
[01:48:26.140 --> 01:48:27.660]   Oh my God.
[01:48:27.660 --> 01:48:29.220]   She had to be going to the bathroom.
[01:48:29.220 --> 01:48:30.700]   And now we have to watch this.
[01:48:30.700 --> 01:48:31.740]   Wait a minute.
[01:48:31.740 --> 01:48:34.500]   That is that is I didn't realize that.
[01:48:34.500 --> 01:48:37.780]   So this guy is doing a BBC hit.
[01:48:37.780 --> 01:48:39.580]   He is about the Korean impeachment.
[01:48:39.580 --> 01:48:40.780]   Is he in Korea?
[01:48:40.780 --> 01:48:41.700]   He's in Korea.
[01:48:41.700 --> 01:48:43.820]   OK, wait, wait, wait, we'll scroll up to that little.
[01:48:44.180 --> 01:48:48.060]   Yeah, you can see when she runs in this like play by play, you can see.
[01:48:48.060 --> 01:48:48.980]   I love this girl.
[01:48:48.980 --> 01:48:50.540]   She's like, walk into the club.
[01:48:50.540 --> 01:48:51.140]   Dances.
[01:48:51.140 --> 01:48:57.300]   Now anybody like me and you and everybody else who's worked at home and done hits from home knows these things happen.
[01:48:57.300 --> 01:48:58.180]   Yes.
[01:48:58.180 --> 01:49:00.500]   Now I know the problem is it's the BBC.
[01:49:00.500 --> 01:49:02.580]   So you can't just say, Oh, there's my child.
[01:49:02.580 --> 01:49:04.780]   So he kind of gives her a little push.
[01:49:04.780 --> 01:49:06.060]   And I was like, get out of here.
[01:49:06.060 --> 01:49:07.060]   He's a stronger.
[01:49:07.060 --> 01:49:11.460]   He's like, Hey, listen, the baby with the with the
[01:49:12.100 --> 01:49:14.300]   you see, he's rolling.
[01:49:14.300 --> 01:49:16.780]   Oh my God.
[01:49:16.780 --> 01:49:18.780]   So that's why she's so low because her pants are down.
[01:49:18.780 --> 01:49:20.300]   Well, also, I think she doesn't.
[01:49:20.300 --> 01:49:21.380]   Oh, yeah, they are.
[01:49:21.380 --> 01:49:22.500]   They are not.
[01:49:22.500 --> 01:49:27.220]   I feel so bad for that lady because she had to have been going to the bathroom and then her kids wondered to the office.
[01:49:27.220 --> 01:49:28.780]   She's like, Oh my God.
[01:49:28.780 --> 01:49:38.860]   No, no, no, wait, I got it. We got to hear the audio on this because obviously at some point he's acknowledging that this happened. Let me turn up my sound.
[01:49:38.860 --> 01:49:44.500]   At some point he's acknowledging that this happened because at first he sounds like he's trying to pretend it didn't happen. Right?
[01:49:44.500 --> 01:49:45.940]   But then the presenter mentions it.
[01:49:45.940 --> 01:49:47.140]   Are you hearing it?
[01:49:47.140 --> 01:49:54.060]   I turned it off because of C net.
[01:49:55.460 --> 01:50:00.940]   I mean, shifting, shifting sands in the region. Do the relations with the North may change?
[01:50:00.940 --> 01:50:04.220]   I would be surprised if they do.
[01:50:04.220 --> 01:50:10.820]   And then she drags them out.
[01:50:10.820 --> 01:50:12.620]   Literally watching this.
[01:50:12.620 --> 01:50:15.820]   It is tight, but I'm sure I would just be laughing so hard at that point.
[01:50:15.820 --> 01:50:18.060]   Who doesn't have for the region?
[01:50:18.060 --> 01:50:20.380]   My apologies.
[01:50:20.380 --> 01:50:21.220]   North.
[01:50:24.740 --> 01:50:27.100]   North Korea. South Korea's policy.
[01:50:27.100 --> 01:50:30.420]   It's severely limited in the last six months.
[01:50:30.420 --> 01:50:34.100]   And the moral of the story is don't have kids.
[01:50:34.100 --> 01:50:40.820]   I guess we didn't get the whole clip because at some point the presenter says something right at the beginning.
[01:50:40.820 --> 01:50:44.180]   Actually, when the first kid comes in, he said it looks like one of your children.
[01:50:44.180 --> 01:50:46.580]   Oh, I feel bad because the guys on the BBC.
[01:50:46.580 --> 01:50:51.740]   Oh, see, see kids can come in and this happens all the time on Twitter all the time.
[01:50:52.140 --> 01:50:56.020]   Parents, kids come in, dogs come in, animals come in, and we always love it.
[01:50:56.020 --> 01:50:57.340]   But it is the BBC.
[01:50:57.340 --> 01:51:00.380]   And I guess the BBC, and he is talking about foreign policy.
[01:51:00.380 --> 01:51:02.580]   It's like the most serious thing.
[01:51:02.580 --> 01:51:07.380]   He's got a suit on in his home office because he wants to have that professional.
[01:51:07.380 --> 01:51:08.900]   He probably does that.
[01:51:08.900 --> 01:51:14.820]   And I guess she may not know also where the camera is.
[01:51:14.820 --> 01:51:16.820]   Right. She's hoping she can duck below it. He does.
[01:51:16.820 --> 01:51:17.940]   He's looking at the cameras.
[01:51:17.940 --> 01:51:19.740]   Like this whole thing is on.
[01:51:19.740 --> 01:51:23.220]   Blink is like that that side blink is really just my favorite.
[01:51:23.220 --> 01:51:33.300]   Steve, I love that little girl.
[01:51:33.300 --> 01:51:35.460]   I love her dance.
[01:51:35.460 --> 01:51:37.180]   She's in it. She loves it.
[01:51:37.180 --> 01:51:39.340]   I hope the guy is not.
[01:51:39.340 --> 01:51:45.220]   Shamed or you know, I mean, I hope he understands that this is that the world loves
[01:51:45.220 --> 01:51:45.460]   you.
[01:51:45.460 --> 01:51:46.140]   Having all the time.
[01:51:46.140 --> 01:51:48.740]   The question is how do you find those candles?
[01:51:49.140 --> 01:51:52.180]   And what will it mean for the wider region?
[01:51:52.180 --> 01:51:53.620]   I think I just walked in.
[01:51:53.620 --> 01:51:55.940]   I mean, shifting, shifting.
[01:51:55.940 --> 01:52:00.580]   That's unfortunately, that's the part where he doesn't doesn't reflect too well on him.
[01:52:00.580 --> 01:52:04.100]   Well, he should have done his grab his daughter and put her on his lap.
[01:52:04.100 --> 01:52:05.340]   Cool. Just sit on my lap.
[01:52:05.340 --> 01:52:06.380]   Yeah, he'd been the cool.
[01:52:06.380 --> 01:52:07.060]   My question.
[01:52:07.060 --> 01:52:11.100]   I'm curious how many times this guy's been on BBC because if it was it was within
[01:52:11.100 --> 01:52:13.980]   the first couple of times, you, of course, want to be asked back.
[01:52:13.980 --> 01:52:14.580]   Oh, yeah.
[01:52:14.580 --> 01:52:17.140]   And so I'm sure he was horrified if that was the case.
[01:52:17.140 --> 01:52:18.340]   I think that's really what's happening.
[01:52:18.340 --> 01:52:19.660]   He's going, oh, my God, this is the worst.
[01:52:19.660 --> 01:52:21.300]   I'm never going to ask back.
[01:52:21.300 --> 01:52:23.980]   It's also says something about TV versus this.
[01:52:23.980 --> 01:52:28.340]   Who is that from his wife, the sound or from the baby coming in?
[01:52:28.340 --> 01:52:29.020]   No.
[01:52:29.020 --> 01:52:31.860]   I think that's why I'm realizing.
[01:52:31.860 --> 01:52:32.860]   I think she's going.
[01:52:32.860 --> 01:52:34.460]   Oh, my God. Oh, my God.
[01:52:34.460 --> 01:52:36.580]   I would be surprised if they do.
[01:52:36.580 --> 01:52:38.300]   No.
[01:52:38.300 --> 01:52:43.860]   The slide is so.
[01:52:43.860 --> 01:52:44.260]   Tom.
[01:52:44.260 --> 01:52:46.500]   I love it.
[01:52:46.500 --> 01:52:47.500]   I love it so much.
[01:52:47.500 --> 01:52:51.140]   And I never noticed her pants are down.
[01:52:51.140 --> 01:52:53.100]   Oh, that poor woman.
[01:52:53.100 --> 01:52:55.060]   I just feel terrible for her.
[01:52:55.060 --> 01:52:57.700]   Can this marriage survive?
[01:52:57.700 --> 01:53:04.860]   Listen, man, if you have a wife that loves you that much, you're doing all right.
[01:53:04.860 --> 01:53:05.660]   I do all right.
[01:53:05.660 --> 01:53:06.820]   I love her.
[01:53:06.820 --> 01:53:09.740]   I love Professor is his name is Professor Kelly.
[01:53:09.740 --> 01:53:11.820]   He's on Twitter.
[01:53:11.820 --> 01:53:12.540]   She can't.
[01:53:12.540 --> 01:53:14.300]   Robert E. Kelly is a political is it?
[01:53:14.300 --> 01:53:18.180]   Sounds like he's an American political science professor at Pusan National University.
[01:53:18.180 --> 01:53:25.900]   He he by the way, he told his Twitter followers, oh, I'm going to be on the BBC.
[01:53:25.900 --> 01:53:27.020]   You might want to watch me.
[01:53:27.020 --> 01:53:31.620]   And by the way, no tweets subsequent to that, right?
[01:53:31.620 --> 01:53:33.220]   He's not heard from.
[01:53:33.220 --> 01:53:35.300]   He has not been heard from since.
[01:53:35.300 --> 01:53:40.580]   But Robert, the world loves you and your children and your wife.
[01:53:40.580 --> 01:53:48.500]   And of course, Ben Thompson did a did a frame by frame analysis.
[01:53:48.500 --> 01:53:52.020]   Well, he has first of all, he has kids.
[01:53:52.020 --> 01:53:54.020]   Yes, he does these things all the time.
[01:53:54.020 --> 01:53:54.500]   Yeah.
[01:53:54.500 --> 01:53:56.540]   What was I heard that he did that?
[01:53:56.540 --> 01:53:58.500]   Maybe he's just tired of writing about it.
[01:53:58.500 --> 01:53:59.860]   Yeah, it's on.
[01:53:59.860 --> 01:54:03.420]   It's on media goes through all the all the points.
[01:54:03.420 --> 01:54:08.020]   OK, first the first daughter walks in then the other one, then it's like and it's just
[01:54:08.020 --> 01:54:09.020]   hilarious.
[01:54:09.020 --> 01:54:09.620]   Right.
[01:54:09.620 --> 01:54:10.620]   Oh, yeah.
[01:54:10.620 --> 01:54:11.620]   Breaking down.
[01:54:11.620 --> 01:54:12.660]   This is so great.
[01:54:12.660 --> 01:54:16.260]   Breaking down the father on BBC being interrupted by his children.
[01:54:16.260 --> 01:54:18.620]   That's a play by play.
[01:54:18.620 --> 01:54:20.060]   Play by play.
[01:54:20.060 --> 01:54:22.300]   Oh, my God.
[01:54:22.300 --> 01:54:24.580]   I am uniquely qualified to break this video down.
[01:54:24.580 --> 01:54:25.860]   I've been on TV from a home office.
[01:54:25.860 --> 01:54:27.020]   I have children and crucially.
[01:54:27.020 --> 01:54:31.380]   I'm a man like Robert E. Kelly, our protagonist who lives in Asia.
[01:54:31.380 --> 01:54:34.700]   That is the key to understanding how this went down.
[01:54:34.700 --> 01:54:36.820]   I'll see that we're getting a perspective that we didn't get.
[01:54:37.180 --> 01:54:39.860]   The most important thing to notice about this quite nice home office, particularly
[01:54:39.860 --> 01:54:44.660]   for Asia is it's really big stack of books on the bed over Kelly's left shoulder.
[01:54:44.660 --> 01:54:45.460]   Oh, it's a bed.
[01:54:45.460 --> 01:54:48.940]   Oh, oh, these books aren't there by accident.
[01:54:48.940 --> 01:54:51.300]   Kelly almost certainly placed them for this interview.
[01:54:51.300 --> 01:54:55.100]   Sadly, given the terrible compression applied to Twitter video, I have no idea what books
[01:54:55.100 --> 01:54:58.900]   they are, but rest assured they are very befitting Kelly's position as a professor
[01:54:58.900 --> 01:54:59.780]   of political science.
[01:54:59.780 --> 01:55:04.740]   BBC expert, the map on the wall, a nice touch.
[01:55:05.420 --> 01:55:08.660]   This is a man who certainly knows his way around the globe, but the blank wall, no,
[01:55:08.660 --> 01:55:09.700]   doesn't play well on TV.
[01:55:09.700 --> 01:55:10.460]   So you're right.
[01:55:10.460 --> 01:55:12.460]   Then is really, they've really got this.
[01:55:12.460 --> 01:55:16.300]   There are two flaws, though, in Kelly's premeditated presentation.
[01:55:16.300 --> 01:55:19.260]   One, the door is a jar.
[01:55:19.260 --> 01:55:21.540]   Obviously that will figure prominently.
[01:55:21.540 --> 01:55:24.660]   Two on the left hand side of the screen.
[01:55:24.660 --> 01:55:27.300]   Something is protruding into the picture.
[01:55:27.300 --> 01:55:30.180]   What could that be?
[01:55:30.180 --> 01:55:31.420]   I have no idea what it is.
[01:55:31.420 --> 01:55:34.740]   It's just an excuse to explain that these interviews are done using the webcam
[01:55:35.100 --> 01:55:36.340]   in computer displays.
[01:55:36.340 --> 01:55:37.020]   It's true.
[01:55:37.020 --> 01:55:38.940]   There is no camera person there.
[01:55:38.940 --> 01:55:42.460]   Indeed, often you are looking into the camera and seeing nothing on your own screen.
[01:55:42.460 --> 01:55:43.460]   It's really disorienting.
[01:55:43.460 --> 01:55:47.860]   And one of the reasons I don't like doing these kinds of TV hits, which Ben does do for us.
[01:55:47.860 --> 01:55:49.260]   Although you're right.
[01:55:49.260 --> 01:55:50.220]   I don't think he likes it.
[01:55:50.220 --> 01:55:52.140]   He's always kind of.
[01:55:52.140 --> 01:55:55.700]   Robert E. Kelly, a handsome man.
[01:55:55.700 --> 01:55:58.500]   He's dressed for the occasion as soon find out he's obviously at home.
[01:55:58.500 --> 01:56:03.180]   So why is he wearing a suit and tie because he's going on the BBC?
[01:56:03.180 --> 01:56:03.660]   That's right.
[01:56:03.660 --> 01:56:04.580]   That's why.
[01:56:05.140 --> 01:56:05.900]   You got to be dressed up.
[01:56:05.900 --> 01:56:06.380]   Yep.
[01:56:06.380 --> 01:56:07.420]   Look your best.
[01:56:07.420 --> 01:56:12.700]   He is an academic PhD in political science from Ohio State, the Ohio State University.
[01:56:12.700 --> 01:56:17.140]   He says, Ben says being an academic is a very weird enterprise.
[01:56:17.140 --> 01:56:21.700]   Kelly went to Miami of Ohio and the Ohio State University for 12 years.
[01:56:21.700 --> 01:56:26.140]   He got his PhD, worked as a lecturer for two years of fairly miserable existence.
[01:56:26.140 --> 01:56:27.540]   That requires years of schooling.
[01:56:27.540 --> 01:56:31.380]   He earns a salary of a Starbucks barista, which is actually true.
[01:56:31.860 --> 01:56:35.060]   Then somehow Kelly hears a siren song of Asia and takes an associate
[01:56:35.060 --> 01:56:38.180]   professorship at Pusan National University in Busan, Korea.
[01:56:38.180 --> 01:56:41.740]   Fun fact, Pusan and Busan is the same world.
[01:56:41.740 --> 01:56:43.620]   Well, same word.
[01:56:43.620 --> 01:56:47.540]   Welcome to the wonderful world of romantic, Romanizing Eastern script languages.
[01:56:47.540 --> 01:56:49.780]   However, he is an expert.
[01:56:49.780 --> 01:56:52.060]   He contribute capital, the expert.
[01:56:52.060 --> 01:56:54.100]   He contributes to the economist newsweek that implement.
[01:56:54.100 --> 01:56:56.660]   And of course he appears in the BBC like a boss.
[01:56:56.660 --> 01:56:58.980]   We will get to the elders dance.
[01:56:58.980 --> 01:57:00.580]   Elder daughters dance in a moment.
[01:57:00.620 --> 01:57:04.860]   It's absolutely delightful in a way that can only be truly appreciated by those
[01:57:04.860 --> 01:57:05.980]   of us who have daughters.
[01:57:05.980 --> 01:57:08.580]   For now, the entrance.
[01:57:08.580 --> 01:57:09.660]   I love Ben.
[01:57:09.660 --> 01:57:10.780]   Ben, you're brilliant.
[01:57:10.780 --> 01:57:14.180]   I told you that open door was a problem.
[01:57:14.180 --> 01:57:19.660]   The yellow shirt, not a single person watching this clip can miss her appearance.
[01:57:19.660 --> 01:57:21.020]   You might as well have been wearing an arrow.
[01:57:21.020 --> 01:57:21.420]   Yeah.
[01:57:21.420 --> 01:57:22.860]   Look over here.
[01:57:22.860 --> 01:57:23.900]   There's a yellow thing.
[01:57:23.900 --> 01:57:26.780]   And finally, the obliviousness.
[01:57:26.780 --> 01:57:31.100]   Dad obviously has no idea about what's to come.
[01:57:31.100 --> 01:57:33.020]   The dance.
[01:57:33.020 --> 01:57:36.100]   I love her.
[01:57:36.100 --> 01:57:40.340]   I'm feeling myself.
[01:57:40.340 --> 01:57:45.060]   It's just she's maybe she probably just had a really delicious snack.
[01:57:45.060 --> 01:57:46.380]   Going to see dad.
[01:57:46.380 --> 01:57:49.540]   I think I want to know about her day as all I want.
[01:57:49.540 --> 01:57:51.340]   Such a happy little sunflower.
[01:57:51.340 --> 01:57:52.700]   Oh, she's great.
[01:57:52.700 --> 01:57:54.020]   The acknowledgement.
[01:57:54.020 --> 01:57:56.300]   This is the point where Kelly becomes aware of his progeny.
[01:57:56.780 --> 01:58:01.260]   He's standing three feet away from him horrifically, at least from his perspective.
[01:58:01.260 --> 01:58:03.900]   He's informed by the BBC anchor.
[01:58:03.900 --> 01:58:08.820]   This is where Kelly is getting the most grief on social media, the hand, the prevailing
[01:58:08.820 --> 01:58:12.140]   wisdom from folks who've never been on worldwide TV as a means of validating 12
[01:58:12.140 --> 01:58:13.140]   years of academia.
[01:58:13.140 --> 01:58:16.180]   That's all one word.
[01:58:16.180 --> 01:58:19.660]   I've made is that Kelly should have gracefully placed his daughter and his lap
[01:58:19.660 --> 01:58:22.100]   and continued on with the interview as if nothing had happened.
[01:58:22.100 --> 01:58:22.900]   Let's back up.
[01:58:23.740 --> 01:58:27.500]   What you may or may not know about these TV spots is you don't get paid a dime.
[01:58:27.500 --> 01:58:32.340]   Why then does the BBC or CNN or MSNBC or all the other channels have an endless
[01:58:32.340 --> 01:58:34.900]   array of experts who are willing to not just call in from their limit?
[01:58:34.900 --> 01:58:36.620]   They don't pay these guys.
[01:58:36.620 --> 01:58:38.220]   I've been doing something wrong.
[01:58:38.220 --> 01:58:41.700]   Have an endless array of experts who are willing not just to call in from their
[01:58:41.700 --> 01:58:44.380]   home office, but will also go to the trouble of putting on a suit and tie and
[01:58:44.380 --> 01:58:48.420]   arrange books just so because you're on TV.
[01:58:48.420 --> 01:58:50.180]   Here's the deal.
[01:58:50.180 --> 01:58:52.180]   The Mail Ego is both remarkably fragile
[01:58:52.820 --> 01:58:54.900]   and remarkably easy to satiate.
[01:58:54.900 --> 01:59:00.300]   Tell said ego, he'll be features as an expert in front of a national or global
[01:59:00.300 --> 01:59:00.660]   audience.
[01:59:00.660 --> 01:59:04.500]   He will do whatever it takes, including 12 years of academia and wearing a suit at
[01:59:04.500 --> 01:59:09.140]   home to ensure it's so the flip side though, potential level of embarrassment
[01:59:09.140 --> 01:59:10.620]   that is hard to fathom.
[01:59:10.620 --> 01:59:14.460]   In this case, Kelly is fulfilling his self selected destiny.
[01:59:14.460 --> 01:59:19.740]   He is appearing as an expert across the world and the BBC, but it is not going.
[01:59:19.740 --> 01:59:22.100]   Well, his daughter has appeared.
[01:59:22.460 --> 01:59:26.060]   And while he certainly loves her, he must must keep up appearances, thus the hand
[01:59:26.060 --> 01:59:27.420]   and not overt affection.
[01:59:27.420 --> 01:59:33.500]   Ignore the baby in the doorway, which is the most hilarious moment in one's
[01:59:33.500 --> 01:59:36.300]   first viewing, although not necessarily later.
[01:59:36.300 --> 01:59:38.780]   Oh, this is very funny.
[01:59:38.780 --> 01:59:42.220]   His is daughter DGA F.
[01:59:42.220 --> 01:59:46.060]   She doesn't give a F.
[01:59:46.060 --> 01:59:49.660]   She just got the hand and reacted not with shock, but with playing with her pen.
[01:59:49.660 --> 01:59:50.940]   She's awesome.
[01:59:52.220 --> 01:59:53.820]   We don't know if the second I don't need you.
[01:59:53.820 --> 01:59:54.820]   I got this pen.
[01:59:54.820 --> 01:59:55.620]   I got a pen.
[01:59:55.620 --> 01:59:56.620]   It's OK, dad.
[01:59:56.620 --> 02:00:00.260]   We don't know if the second born is a boy or girl, frankly, doesn't matter.
[02:00:00.260 --> 02:00:04.380]   All that we know is after valuing off his first born, who he loves.
[02:00:04.380 --> 02:00:09.460]   All of Kelly's efforts are undone by the second born that he probably doesn't
[02:00:09.460 --> 02:00:12.060]   pay enough attention to mimicking her older sister.
[02:00:12.060 --> 02:00:15.420]   It's basically the royal tenant bombs brought to life.
[02:00:15.420 --> 02:00:21.380]   This is a truly great commentary.
[02:00:21.380 --> 02:00:22.420]   This is why media makes this.
[02:00:22.420 --> 02:00:23.380]   Oh, I love it.
[02:00:23.380 --> 02:00:24.700]   Thank you, Ben Thompson.
[02:00:24.700 --> 02:00:26.020]   Oh, my God.
[02:00:26.020 --> 02:00:30.060]   This is the moment where this clip enters the pantheon of Internet viral videos.
[02:00:30.060 --> 02:00:34.580]   As usual, it's the woman, in this case, the mom who makes it legendary.
[02:00:34.580 --> 02:00:37.860]   But wait, was it the mom or was it a nanny?
[02:00:37.860 --> 02:00:40.060]   This has been a point of contention on social media.
[02:00:40.060 --> 02:00:41.340]   I'm pretty sure it's the mom.
[02:00:41.340 --> 02:00:44.260]   And now that I know they're pants are down, I'm definitely sure it's them.
[02:00:44.260 --> 02:00:48.740]   I have white American Asian mixed kids, so I'm kind of a subject matter expert.
[02:00:48.740 --> 02:00:49.940]   These look like mixed kids.
[02:00:50.140 --> 02:00:53.020]   Most maids in Korea, like Taiwan, where I live or foreign.
[02:00:53.020 --> 02:00:55.460]   This mom, though, absolutely looks East Asian Korean.
[02:00:55.460 --> 02:00:59.660]   In fact, and given that Kelly is paid an expertise, he probably can't afford a Korean
[02:00:59.660 --> 02:01:00.660]   maid.
[02:01:00.660 --> 02:01:05.260]   The desperation with which he enters the room is a desperation board of love, not
[02:01:05.260 --> 02:01:05.580]   duty.
[02:01:05.580 --> 02:01:06.540]   You can't deny it.
[02:01:06.540 --> 02:01:08.460]   She wants her husband to look good.
[02:01:08.460 --> 02:01:12.820]   That's why she flies in and frankly takes too long, getting the kids out of
[02:01:12.820 --> 02:01:14.740]   there because she's trying so hard.
[02:01:14.740 --> 02:01:17.900]   She cares too much above everyone else.
[02:01:17.900 --> 02:01:18.380]   She cares too much.
[02:01:18.380 --> 02:01:19.140]   She cares.
[02:01:19.140 --> 02:01:19.660]   Right.
[02:01:19.660 --> 02:01:21.140]   She cares too much.
[02:01:21.140 --> 02:01:23.700]   So much above everyone else.
[02:01:23.700 --> 02:01:24.580]   I'm going to mark that.
[02:01:24.580 --> 02:01:27.060]   Oh, I have to log in.
[02:01:27.060 --> 02:01:27.660]   Screw it.
[02:01:27.660 --> 02:01:28.700]   Never mind.
[02:01:28.700 --> 02:01:30.500]   I'm sorry.
[02:01:30.500 --> 02:01:31.900]   Hey, yeah, yeah, Karumba.
[02:01:31.900 --> 02:01:33.780]   There you go.
[02:01:33.780 --> 02:01:34.660]   Wait a minute.
[02:01:34.660 --> 02:01:36.060]   She cares too much there.
[02:01:36.060 --> 02:01:37.860]   Now it's highlighted above everyone else.
[02:01:37.860 --> 02:01:38.700]   I feel for the mom.
[02:01:38.700 --> 02:01:41.500]   I'm assuming it was the mom from here on out because she, yes, she was probably
[02:01:41.500 --> 02:01:44.980]   responsible for those kids during said call, but moms have a lot to do.
[02:01:44.980 --> 02:01:47.980]   And seriously, dad should have closed the damn door.
[02:01:48.500 --> 02:01:49.220]   She is true.
[02:01:49.220 --> 02:01:49.780]   Yes.
[02:01:49.780 --> 02:01:52.420]   She's going to feel absolutely awful for having upset his calling.
[02:01:52.420 --> 02:01:52.820]   You know what?
[02:01:52.820 --> 02:01:54.380]   I feel bad for her for feeling this way.
[02:01:54.380 --> 02:01:56.020]   It was almost certainly an honest mistake.
[02:01:56.020 --> 02:02:01.260]   Also her pants may not be completely pulled up as opposed to Kelly, who
[02:02:01.260 --> 02:02:03.940]   honestly may not be wearing any at all.
[02:02:03.940 --> 02:02:04.900]   Also true.
[02:02:04.900 --> 02:02:11.420]   Look, for all the sympathy I just gave mom, she deserves some kudos as well.
[02:02:11.420 --> 02:02:15.460]   She just moved into the room, grabbed both kids, then beat a retreat while
[02:02:15.460 --> 02:02:16.740]   barely showing her face.
[02:02:16.740 --> 02:02:18.340]   It's impressive stuff.
[02:02:19.340 --> 02:02:23.780]   Meanwhile, that is apologizing for the love of his life interfering with his ego men.
[02:02:23.780 --> 02:02:29.300]   Look, I got to say, like there's a couple comments about like male ego and
[02:02:29.300 --> 02:02:33.980]   like, oh, he said, if that had happened with my husband, like, I would be just as
[02:02:33.980 --> 02:02:34.380]   smart.
[02:02:34.380 --> 02:02:35.700]   I'd be horrified.
[02:02:35.700 --> 02:02:36.180]   I'd be horrified.
[02:02:36.180 --> 02:02:37.940]   My ego is the same.
[02:02:37.940 --> 02:02:38.260]   Yeah.
[02:02:38.260 --> 02:02:41.500]   When you're on camera, you're trying to put on a good presence.
[02:02:41.500 --> 02:02:43.700]   I'd be like strong arming my dog.
[02:02:43.700 --> 02:02:44.940]   Like, no.
[02:02:44.940 --> 02:02:47.180]   Well, that's the truth.
[02:02:47.180 --> 02:02:48.780]   The first time people are on, they always apologize.
[02:02:48.780 --> 02:02:49.140]   You did.
[02:02:49.140 --> 02:02:50.580]   You said, I'm glad my dog's in show.
[02:02:50.580 --> 02:02:52.860]   And I, and I really want to make that point.
[02:02:52.860 --> 02:02:53.780]   It's always welcome.
[02:02:53.780 --> 02:02:56.660]   Plus, you can't think in situations like that.
[02:02:56.660 --> 02:02:57.540]   That's another thing.
[02:02:57.540 --> 02:03:02.340]   You ended a great job of like pointing out how big it is to be on the BBC when
[02:03:02.340 --> 02:03:04.660]   you're an academic and establishing yourself as incredible.
[02:03:04.660 --> 02:03:08.060]   It's just the lights that the camera, it's like you can't even think.
[02:03:08.060 --> 02:03:09.940]   So I don't know.
[02:03:09.940 --> 02:03:13.140]   You're already nervous about the things you're saying, like making sure they're
[02:03:13.140 --> 02:03:15.820]   accurate and you're getting them out in your very focused.
[02:03:15.820 --> 02:03:20.380]   Your incidences and then you look into your skype and you see in the background,
[02:03:20.380 --> 02:03:25.900]   your, your yellow shirt of kid dancing up into your shot and you're just like, I,
[02:03:25.900 --> 02:03:27.860]   everything is, but my life is ending right now.
[02:03:27.860 --> 02:03:29.060]   It's just everything's falling apart.
[02:03:29.060 --> 02:03:29.700]   This is not great.
[02:03:29.700 --> 02:03:32.860]   Dad has just apologized multiple times for the interruption.
[02:03:32.860 --> 02:03:36.500]   While mom is desperately trying to let him shine, it really is the reach, though.
[02:03:36.500 --> 02:03:39.620]   That makes him so spectacular.
[02:03:39.620 --> 02:03:43.220]   And he retweets sports pickle who says, who did it better?
[02:03:43.220 --> 02:03:44.900]   Of course.
[02:03:45.220 --> 02:03:49.940]   Was that a deal back at junior or of the giants, the catch or is it the?
[02:03:49.940 --> 02:03:51.140]   Yeah, really it is.
[02:03:51.140 --> 02:03:54.580]   That's why I'm all in on mom.
[02:03:54.580 --> 02:03:56.020]   Nanny's don't lay it out like this.
[02:03:56.020 --> 02:03:56.860]   She loves her man.
[02:03:56.860 --> 02:04:02.500]   She's proud of his expertise and she's going to do everything she can to make him look good.
[02:04:02.500 --> 02:04:04.340]   Nice.
[02:04:04.340 --> 02:04:05.420]   Thank you, Ben.
[02:04:05.420 --> 02:04:07.260]   What a great, that is a, you're right.
[02:04:07.260 --> 02:04:10.780]   I had everybody told me, oh, you got to see Ben's a breakdown.
[02:04:10.780 --> 02:04:11.540]   That really was good.
[02:04:11.540 --> 02:04:12.780]   That's nice.
[02:04:12.780 --> 02:04:13.300]   Play by play.
[02:04:13.300 --> 02:04:13.860]   A lot of it.
[02:04:13.860 --> 02:04:14.540]   By play.
[02:04:14.540 --> 02:04:22.980]   I want to talk a little bit about Twitter and just a bet when we come back, a new feature that warns users of profiles with potentially sensitive content.
[02:04:22.980 --> 02:04:29.500]   And I have to say, I feel like they're on the right track with abuse, but I want to know what the panel thinks.
[02:04:29.500 --> 02:04:31.700]   First a word though from WordPress.
[02:04:31.700 --> 02:04:32.340]   Did you?
[02:04:32.340 --> 02:04:35.820]   I didn't know this WordPress runs 27% of the websites.
[02:04:35.820 --> 02:04:37.660]   I did not know that WordPress is.
[02:04:37.660 --> 02:04:38.220]   That is high.
[02:04:38.220 --> 02:04:38.660]   Huge.
[02:04:38.660 --> 02:04:41.780]   Yes, it is high percentage.
[02:04:42.140 --> 02:04:43.180]   And it's a great success.
[02:04:43.180 --> 02:04:47.300]   WordPress.com wants to salute all the small business owners out there during small business month.
[02:04:47.300 --> 02:04:50.620]   The tel, the, the toll belt toting.
[02:04:50.620 --> 02:04:51.820]   That's hard to say.
[02:04:51.820 --> 02:04:58.020]   That's harder to say than Ashley at the, the tool belt toting plumbers, the canine sweaters,
[02:04:58.020 --> 02:05:03.380]   stiches, the hornroom glasses wearing flat screen TV and stollers, the corny deli corner deli footlong.
[02:05:03.380 --> 02:05:11.940]   Deliverrs, the Williamsburg pundits and the mom through that one in for you, the non, the south of Williamsburg pundits.
[02:05:12.180 --> 02:05:15.020]   And the mom and pop lawyers look out for our best interests.
[02:05:15.020 --> 02:05:18.540]   And I, I, I have to say some of the best websites in the world.
[02:05:18.540 --> 02:05:23.940]   If you have a business and you are not on the web, you don't exist for most people.
[02:05:23.940 --> 02:05:28.020]   WordPress is quietly powering the sites and the websites for thousands of small businesses.
[02:05:28.020 --> 02:05:32.940]   More websites run on WordPress than any other platform with built in search engine optimization,
[02:05:32.940 --> 02:05:38.500]   mobile friendly design, your customers can find your website easily, access it from any device.
[02:05:39.260 --> 02:05:43.660]   If you, I swear it, you know, used to be, well, if you don't have a yellow page listing and a phone,
[02:05:43.660 --> 02:05:45.060]   you can't be in business now.
[02:05:45.060 --> 02:05:50.660]   I really think before I even hire a plumber or a dog sitter, I go and look at the website.
[02:05:50.660 --> 02:05:51.740]   That's where you learn about them.
[02:05:51.740 --> 02:05:57.500]   So if you want to make a big difference as a small business owner, you better get your site up and running.
[02:05:57.500 --> 02:05:58.380]   Go to WordPress.com.
[02:05:58.380 --> 02:05:59.860]   It's easy 24 seven support.
[02:05:59.860 --> 02:06:07.140]   You and right now, 15% off any new plan purchase, 15% off at wordpress.com/twit.
[02:06:07.500 --> 02:06:10.500]   We just have an election here in Los Angeles.
[02:06:10.500 --> 02:06:16.500]   And my local city had three people running for mayor and only one person had a website.
[02:06:16.500 --> 02:06:17.500]   Guess who I voted for?
[02:06:17.500 --> 02:06:17.500]   Wow.
[02:06:17.500 --> 02:06:18.500]   That's interesting.
[02:06:18.500 --> 02:06:18.500]   Yeah.
[02:06:18.500 --> 02:06:19.500]   Only one.
[02:06:19.500 --> 02:06:21.500]   And it was just, they had no other information online.
[02:06:21.500 --> 02:06:27.500]   It was just they, I guess they were relying on flyers and kind of more local.
[02:06:27.500 --> 02:06:29.500]   That seems like a kind of an oversight.
[02:06:29.500 --> 02:06:34.500]   But yeah, it just, there was only one person who had an official website.
[02:06:34.500 --> 02:06:35.500]   Was that Eric?
[02:06:35.500 --> 02:06:37.500]   Oh, I don't live in LA proper.
[02:06:37.500 --> 02:06:39.500]   Oh, you're in a little town.
[02:06:39.500 --> 02:06:39.500]   Yeah.
[02:06:39.500 --> 02:06:40.500]   Okay.
[02:06:40.500 --> 02:06:41.500]   Okay.
[02:06:41.500 --> 02:06:43.500]   You know, it's not just having a website.
[02:06:43.500 --> 02:06:44.500]   I love South of Williamsburg.
[02:06:44.500 --> 02:06:45.500]   Way Sast.
[02:06:45.500 --> 02:06:46.500]   Southwest.
[02:06:46.500 --> 02:06:48.500]   I think that is a neighborhood in LA.
[02:06:48.500 --> 02:06:56.500]   But it's important that it's human nature to look at a website and judge the entire company.
[02:06:56.500 --> 02:07:01.500]   If a website looks like it's stale from the 90s, you're thinking, okay, this company is going to be terrible.
[02:07:01.500 --> 02:07:06.500]   It's like a piece.
[02:07:06.500 --> 02:07:07.500]   Yeah.
[02:07:07.500 --> 02:07:08.500]   Yeah.
[02:07:08.500 --> 02:07:11.500]   I read coils at sites that looked like they were built on Geo City.
[02:07:11.500 --> 02:07:12.500]   So I get really upset.
[02:07:12.500 --> 02:07:14.500]   I just saw there was, what was it?
[02:07:14.500 --> 02:07:18.500]   There was a government website that looked like it was from 1995.
[02:07:18.500 --> 02:07:19.500]   Really?
[02:07:19.500 --> 02:07:20.500]   Oh, it probably is.
[02:07:20.500 --> 02:07:21.500]   Oh, I wish I could remember that.
[02:07:21.500 --> 02:07:23.500]   You know, it undermines your credibility.
[02:07:23.500 --> 02:07:24.500]   It's really, yeah.
[02:07:24.500 --> 02:07:25.500]   Yeah.
[02:07:25.500 --> 02:07:26.500]   It's crazy.
[02:07:26.500 --> 02:07:30.500]   Hey, hey, can I, can I make a point of privilege here, Leo?
[02:07:30.500 --> 02:07:32.500]   Pop this out, but Mike inspired me.
[02:07:32.500 --> 02:07:35.500]   He talked about this gastro nomad thing.
[02:07:35.500 --> 02:07:36.500]   Yes.
[02:07:36.500 --> 02:07:39.500]   And I don't have a wife, but I do have a girlfriend and she's up to cool stuff.
[02:07:39.500 --> 02:07:41.500]   By the way, that's a big story.
[02:07:41.500 --> 02:07:42.500]   We're breaking news.
[02:07:42.500 --> 02:07:46.500]   Barrett Tunde has a girlfriend.
[02:07:46.500 --> 02:07:47.500]   Don't do that.
[02:07:47.500 --> 02:07:48.500]   That's crazy.
[02:07:48.500 --> 02:07:49.500]   Breaking news.
[02:07:49.500 --> 02:07:51.500]   No, I know you do.
[02:07:51.500 --> 02:07:52.500]   You know why?
[02:07:52.500 --> 02:07:57.500]   Because you and your new lady came to the Arnek of the Woods.
[02:07:57.500 --> 02:07:58.500]   You were in Napa.
[02:07:58.500 --> 02:07:59.500]   And I begged you.
[02:07:59.500 --> 02:08:00.500]   I pleaded with you.
[02:08:00.500 --> 02:08:01.500]   I said, come here.
[02:08:01.500 --> 02:08:03.500]   He said, no, I got a girlfriend.
[02:08:03.500 --> 02:08:04.500]   I ignored your entry.
[02:08:04.500 --> 02:08:06.500]   It was not their own business.
[02:08:06.500 --> 02:08:09.500]   Hey, did you have a good time in Napa, by the way?
[02:08:09.500 --> 02:08:10.500]   We had a great time.
[02:08:10.500 --> 02:08:11.500]   I'd never been before.
[02:08:11.500 --> 02:08:12.500]   Isn't it beautiful?
[02:08:12.500 --> 02:08:13.500]   Yeah.
[02:08:13.500 --> 02:08:18.500]   We went to, there's a black family owned venue called Brown Estate, which had such an incredible
[02:08:18.500 --> 02:08:19.500]   story.
[02:08:19.500 --> 02:08:20.500]   I never heard of it.
[02:08:20.500 --> 02:08:21.500]   I never heard of it.
[02:08:21.500 --> 02:08:22.500]   Family, three kids.
[02:08:22.500 --> 02:08:25.500]   They're kind of up in the hills, like in Northern Napa, which means something apparently.
[02:08:25.500 --> 02:08:26.500]   It's all new to me.
[02:08:26.500 --> 02:08:27.500]   So I'm just like, you guys have wine.
[02:08:27.500 --> 02:08:28.500]   That's exciting.
[02:08:28.500 --> 02:08:31.500]   But the way they do it is cool.
[02:08:31.500 --> 02:08:34.500]   And we got to meet one of the owners who has left that.
[02:08:34.500 --> 02:08:36.500]   Most importantly, how's their wine?
[02:08:36.500 --> 02:08:38.500]   The wine is whiny and yummy.
[02:08:38.500 --> 02:08:40.500]   Here's how it is.
[02:08:40.500 --> 02:08:41.500]   The kids are whiny.
[02:08:41.500 --> 02:08:42.500]   I think they're good names.
[02:08:42.500 --> 02:08:43.500]   Chaos theory.
[02:08:43.500 --> 02:08:45.500]   I want some chaos theory.
[02:08:45.500 --> 02:08:46.500]   It's funky.
[02:08:46.500 --> 02:08:50.500]   So they make a lot of Zinfandel's, which apparently are like people like to talk a lot of trash about
[02:08:50.500 --> 02:08:51.500]   Zins.
[02:08:51.500 --> 02:08:52.500]   Oh no.
[02:08:52.500 --> 02:08:53.500]   Oh no.
[02:08:53.500 --> 02:08:54.500]   I love the Zins.
[02:08:54.500 --> 02:08:55.500]   I love the Zinfandel's.
[02:08:55.500 --> 02:08:56.500]   I love the Zinfandel's.
[02:08:56.500 --> 02:08:57.500]   I love the Zinfandel's.
[02:08:57.500 --> 02:08:58.500]   I love the Zinfandel's.
[02:08:58.500 --> 02:08:59.500]   I love the Zinfandel's.
[02:08:59.500 --> 02:09:00.500]   I love the Zinfandel's.
[02:09:00.500 --> 02:09:01.500]   I love the Zinfandel's.
[02:09:01.500 --> 02:09:02.500]   I love the Zinfandel's.
[02:09:02.500 --> 02:09:03.500]   I love the Zinfandel's.
[02:09:03.500 --> 02:09:04.500]   I love the Zinfandel's.
[02:09:04.500 --> 02:09:05.500]   I love the Zinfandel's.
[02:09:05.500 --> 02:09:06.500]   I love the Zinfandel's.
[02:09:06.500 --> 02:09:07.500]   I love the Zinfandel's.
[02:09:07.500 --> 02:09:08.500]   I love the Zinfandel's.
[02:09:08.500 --> 02:09:09.500]   I love the Zinfandel's.
[02:09:09.500 --> 02:09:10.500]   I love the Zinfandel's.
[02:09:10.500 --> 02:09:11.500]   I love the Zinfandel's.
[02:09:11.500 --> 02:09:12.500]   I love the Zinfandel's.
[02:09:12.500 --> 02:09:13.500]   I love the Zinfandel's.
[02:09:13.500 --> 02:09:14.500]   I love the Zinfandel's.
[02:09:14.500 --> 02:09:15.500]   I love the Zinfandel's.
[02:09:15.500 --> 02:09:16.500]   I love the Zinfandel's.
[02:09:16.500 --> 02:09:17.500]   I love the Zinfandel's.
[02:09:17.500 --> 02:09:18.500]   I love the Zinfandel's.
[02:09:18.500 --> 02:09:19.500]   I love the Zinfandel's.
[02:09:19.500 --> 02:09:20.500]   I love the Zinfandel's.
[02:09:20.500 --> 02:09:21.500]   I love the Zinfandel's.
[02:09:21.500 --> 02:09:22.500]   I love the Zinfandel's.
[02:09:22.500 --> 02:09:23.500]   I love the Zinfandel's.
[02:09:23.500 --> 02:09:24.500]   I love the Zinfandel's.
[02:09:24.500 --> 02:09:25.500]   I love the Zinfandel's.
[02:09:25.500 --> 02:09:26.500]   I love the Zinfandel's.
[02:09:26.500 --> 02:09:27.500]   I love the Zinfandel's.
[02:09:27.500 --> 02:09:28.500]   I love the Zinfandel's.
[02:09:28.500 --> 02:09:29.500]   I love the Zinfandel's.
[02:09:29.500 --> 02:09:30.500]   I love the Zinfandel's.
[02:09:30.500 --> 02:09:31.500]   I love the Zinfandel's.
[02:09:31.500 --> 02:09:32.500]   I love the Zinfandel's.
[02:09:32.500 --> 02:09:33.500]   I love the Zinfandel's.
[02:09:33.500 --> 02:09:34.500]   I love the Zinfandel's.
[02:09:34.500 --> 02:09:35.500]   I love the Zinfandel's.
[02:09:35.500 --> 02:09:36.500]   I love the Zinfandel's.
[02:09:36.500 --> 02:09:37.500]   I love the Zinfandel's.
[02:09:37.500 --> 02:09:38.500]   I love the Zinfandel's.
[02:09:38.500 --> 02:09:39.500]   I love the Zinfandel's.
[02:09:39.500 --> 02:09:40.500]   I love the Zinfandel's.
[02:09:40.500 --> 02:09:41.500]   I love the Zinfandel's.
[02:09:41.500 --> 02:09:42.500]   I love the Zinfandel's.
[02:09:42.500 --> 02:09:43.500]   I love the Zinfandel's.
[02:09:43.500 --> 02:09:44.500]   I love the Zinfandel's.
[02:09:44.500 --> 02:09:45.500]   I love the Zinfandel's.
[02:09:45.500 --> 02:09:46.500]   I love the Zinfandel's.
[02:09:46.500 --> 02:09:47.500]   I love the Zinfandel's.
[02:09:47.500 --> 02:09:48.500]   I love the Zinfandel's.
[02:09:48.500 --> 02:09:49.500]   I love the Zinfandel's.
[02:09:49.500 --> 02:09:50.500]   I love the Zinfandel's.
[02:09:50.500 --> 02:09:51.500]   I love the Zinfandel's.
[02:09:51.500 --> 02:09:52.500]   I love the Zinfandel's.
[02:09:52.500 --> 02:09:53.500]   I love the Zinfandel's.
[02:09:53.500 --> 02:09:54.500]   I love the Zinfandel's.
[02:09:54.500 --> 02:09:55.500]   I love the Zinfandel's.
[02:09:55.500 --> 02:09:56.500]   I love the Zinfandel's.
[02:09:56.500 --> 02:09:57.500]   I love the Zinfandel's.
[02:09:57.500 --> 02:09:58.500]   I love the Zinfandel's.
[02:09:58.500 --> 02:09:59.500]   I love the Zinfandel's.
[02:09:59.500 --> 02:10:00.500]   I love the Zinfandel's.
[02:10:00.500 --> 02:10:01.500]   I love the Zinfandel's.
[02:10:01.500 --> 02:10:02.500]   I love the Zinfandel's.
[02:10:02.500 --> 02:10:03.500]   I love the Zinfandel's.
[02:10:03.500 --> 02:10:04.500]   I love the Zinfandel's.
[02:10:04.500 --> 02:10:05.500]   I love the Zinfandel's.
[02:10:05.500 --> 02:10:06.500]   I love the Zinfandel's.
[02:10:06.500 --> 02:10:07.500]   I love the Zinfandel's.
[02:10:07.500 --> 02:10:08.500]   I love the Zinfandel's.
[02:10:08.500 --> 02:10:09.500]   I love the Zinfandel's.
[02:10:09.500 --> 02:10:10.500]   I love the Zinfandel's.
[02:10:10.500 --> 02:10:11.500]   I love the Zinfandel's.
[02:10:11.500 --> 02:10:12.500]   I love the Zinfandel's.
[02:10:12.500 --> 02:10:13.500]   I love the Zinfandel's.
[02:10:13.500 --> 02:10:14.500]   I love the Zinfandel's.
[02:10:14.500 --> 02:10:15.500]   I love the Zinfandel's.
[02:10:15.500 --> 02:10:16.500]   I love the Zinfandel's.
[02:10:16.500 --> 02:10:17.500]   I love the Zinfandel's.
[02:10:17.500 --> 02:10:18.500]   I love the Zinfandel's.
[02:10:18.500 --> 02:10:19.500]   I love the Zinfandel's.
[02:10:19.500 --> 02:10:20.500]   I love the Zinfandel's.
[02:10:20.500 --> 02:10:21.500]   I love the Zinfandel's.
[02:10:21.500 --> 02:10:22.500]   I love the Zinfandel's.
[02:10:22.500 --> 02:10:23.500]   I love the Zinfandel's.
[02:10:23.500 --> 02:10:24.500]   I love the Zinfandel's.
[02:10:24.500 --> 02:10:25.500]   I love the Zinfandel's.
[02:10:25.500 --> 02:10:26.500]   I love the Zinfandel's.
[02:10:26.500 --> 02:10:27.500]   I love the Zinfandel's.
[02:10:27.500 --> 02:10:28.500]   I love the Zinfandel's.
[02:10:28.500 --> 02:10:29.500]   I love the Zinfandel's.
[02:10:29.500 --> 02:10:30.500]   I love the Zinfandel's.
[02:10:30.500 --> 02:10:31.500]   I love the Zinfandel's.
[02:10:31.500 --> 02:10:32.500]   I love the Zinfandel's.
[02:10:32.500 --> 02:10:33.500]   I love the Zinfandel's.
[02:10:33.500 --> 02:10:34.500]   I love the Zinfandel's.
[02:10:34.500 --> 02:10:35.500]   I love the Zinfandel's.
[02:10:35.500 --> 02:10:36.500]   I love the Zinfandel's.
[02:10:36.500 --> 02:10:37.500]   I love the Zinfandel's.
[02:10:37.500 --> 02:10:38.500]   I love the Zinfandel's.
[02:10:38.500 --> 02:10:39.500]   I love the Zinfandel's.
[02:10:39.500 --> 02:10:40.500]   I love the Zinfandel's.
[02:10:40.500 --> 02:10:41.500]   I love the Zinfandel's.
[02:10:41.500 --> 02:10:42.500]   I love the Zinfandel's.
[02:10:42.500 --> 02:10:43.500]   I love the Zinfandel's.
[02:10:43.500 --> 02:10:44.500]   I love the Zinfandel's.
[02:10:44.500 --> 02:10:46.500]   I love the Zinfandel's.
[02:10:46.500 --> 02:10:47.500]   I love the Zinfandel's.
[02:10:47.500 --> 02:10:48.500]   I love the Zinfandel's.
[02:10:48.500 --> 02:10:49.500]   I love the Zinfandel's.
[02:10:49.500 --> 02:10:50.500]   I love the Zinfandel's.
[02:10:50.500 --> 02:10:51.500]   I love the Zinfandel's.
[02:10:51.500 --> 02:10:52.500]   I love the Zinfandel's.
[02:10:52.500 --> 02:10:53.500]   I love the Zinfandel's.
[02:10:53.500 --> 02:10:54.500]   I love the Zinfandel's.
[02:10:54.500 --> 02:10:55.500]   I love the Zinfandel's.
[02:10:55.500 --> 02:10:56.500]   I love the Zinfandel's.
[02:10:56.500 --> 02:10:57.500]   I love the Zinfandel's.
[02:10:57.500 --> 02:10:58.500]   I love the Zinfandel's.
[02:10:58.500 --> 02:10:59.500]   I love the Zinfandel's.
[02:10:59.500 --> 02:11:00.500]   I love the Zinfandel's.
[02:11:00.500 --> 02:11:01.500]   I love the Zinfandel's.
[02:11:01.500 --> 02:11:02.500]   I love the Zinfandel's.
[02:11:02.500 --> 02:11:03.500]   I love the Zinfandel's.
[02:11:03.500 --> 02:11:04.500]   I love the Zinfandel's.
[02:11:04.500 --> 02:11:05.500]   I love the Zinfandel's.
[02:11:05.500 --> 02:11:06.500]   I love the Zinfandel's.
[02:11:06.500 --> 02:11:07.500]   I love the Zinfandel's.
[02:11:07.500 --> 02:11:08.500]   I love the Zinfandel's.
[02:11:08.500 --> 02:11:09.500]   I love the Zinfandel's.
[02:11:09.500 --> 02:11:10.500]   I love the Zinfandel's.
[02:11:10.500 --> 02:11:11.500]   I love the Zinfandel's.
[02:11:11.500 --> 02:11:12.500]   I love the Zinfandel's.
[02:11:12.500 --> 02:11:13.500]   I love the Zinfandel's.
[02:11:13.500 --> 02:11:14.500]   I love the Zinfandel's.
[02:11:14.500 --> 02:11:15.500]   I love the Zinfandel's.
[02:11:15.500 --> 02:11:16.500]   I love the Zinfandel's.
[02:11:16.500 --> 02:11:17.500]   I love the Zinfandel's.
[02:11:17.500 --> 02:11:18.500]   I love the Zinfandel's.
[02:11:18.500 --> 02:11:19.500]   I love the Zinfandel's.
[02:11:19.500 --> 02:11:20.500]   I love the Zinfandel's.
[02:11:20.500 --> 02:11:21.500]   I love the Zinfandel's.
[02:11:21.500 --> 02:11:22.500]   I love the Zinfandel's.
[02:11:22.500 --> 02:11:23.500]   I love the Zinfandel's.
[02:11:23.500 --> 02:11:24.500]   I love the Zinfandel's.
[02:11:24.500 --> 02:11:25.500]   I love the Zinfandel's.
[02:11:25.500 --> 02:11:26.500]   I love the Zinfandel's.
[02:11:26.500 --> 02:11:27.500]   I love the Zinfandel's.
[02:11:27.500 --> 02:11:28.500]   I love the Zinfandel's.
[02:11:28.500 --> 02:11:29.500]   I love the Zinfandel's.
[02:11:29.500 --> 02:11:30.500]   I love the Zinfandel's.
[02:11:30.500 --> 02:11:31.500]   I love the Zinfandel's.
[02:11:31.500 --> 02:11:32.500]   I love the Zinfandel's.
[02:11:32.500 --> 02:11:33.500]   I love the Zinfandel's.
[02:11:33.500 --> 02:11:34.500]   I love the Zinfandel's.
[02:11:34.500 --> 02:11:35.500]   I love the Zinfandel's.
[02:11:35.500 --> 02:11:36.500]   I love the Zinfandel's.
[02:11:36.500 --> 02:11:37.500]   I love the Zinfandel's.
[02:11:37.500 --> 02:11:38.500]   I love the Zinfandel's.
[02:11:38.500 --> 02:11:39.500]   I love the Zinfandel's.
[02:11:39.500 --> 02:11:40.500]   I love the Zinfandel's.
[02:11:40.500 --> 02:11:41.500]   I love the Zinfandel's.
[02:11:41.500 --> 02:11:42.500]   I love the Zinfandel's.
[02:11:42.500 --> 02:11:43.500]   I love the Zinfandel's.
[02:11:43.500 --> 02:11:44.500]   I love the Zinfandel's.
[02:11:44.500 --> 02:11:45.500]   I love the Zinfandel's.
[02:11:45.500 --> 02:11:46.500]   I love the Zinfandel's.
[02:11:46.500 --> 02:11:47.500]   I love the Zinfandel's.
[02:11:47.500 --> 02:11:48.500]   I love the Zinfandel's.
[02:11:48.500 --> 02:11:49.500]   I love the Zinfandel's.
[02:11:49.500 --> 02:11:50.500]   I love the Zinfandel's.
[02:11:50.500 --> 02:11:51.500]   I love the Zinfandel's.
[02:11:51.500 --> 02:11:52.500]   I love the Zinfandel's.
[02:11:52.500 --> 02:11:53.500]   I love the Zinfandel's.
[02:11:53.500 --> 02:11:54.500]   I love the Zinfandel's.
[02:11:54.500 --> 02:11:55.500]   I love the Zinfandel's.
[02:11:55.500 --> 02:11:56.500]   I love the Zinfandel's.
[02:11:56.500 --> 02:11:57.500]   I love the Zinfandel's.
[02:11:57.500 --> 02:11:58.500]   I love the Zinfandel's.
[02:11:58.500 --> 02:11:59.500]   I love the Zinfandel's.
[02:11:59.500 --> 02:12:00.500]   I love the Zinfandel's.
[02:12:00.500 --> 02:12:01.500]   I love the Zinfandel's.
[02:12:01.500 --> 02:12:02.500]   I love the Zinfandel's.
[02:12:02.500 --> 02:12:03.500]   I love the Zinfandel's.
[02:12:03.500 --> 02:12:04.500]   I love the Zinfandel's.
[02:12:04.500 --> 02:12:05.500]   I love the Zinfandel's.
[02:12:05.500 --> 02:12:06.500]   I love the Zinfandel's.
[02:12:06.500 --> 02:12:07.500]   I love the Zinfandel's.
[02:12:07.500 --> 02:12:08.500]   I love the Zinfandel's.
[02:12:08.500 --> 02:12:09.500]   I love the Zinfandel's.
[02:12:09.500 --> 02:12:10.500]   I love the Zinfandel's.
[02:12:10.500 --> 02:12:11.500]   I love the Zinfandel's.
[02:12:11.500 --> 02:12:12.500]   I love the Zinfandel's.
[02:12:12.500 --> 02:12:13.500]   I love the Zinfandel's.
[02:12:13.500 --> 02:12:14.500]   I love the Zinfandel's.
[02:12:14.500 --> 02:12:15.500]   I love the Zinfandel's.
[02:12:15.500 --> 02:12:16.500]   I love the Zinfandel's.
[02:12:16.500 --> 02:12:17.500]   I love the Zinfandel's.
[02:12:17.500 --> 02:12:18.500]   I love the Zinfandel's.
[02:12:18.500 --> 02:12:19.500]   I love the Zinfandel's.
[02:12:19.500 --> 02:12:20.500]   I love the Zinfandel's.
[02:12:20.500 --> 02:12:21.500]   I love the Zinfandel's.
[02:12:21.500 --> 02:12:22.500]   I love the Zinfandel's.
[02:12:22.500 --> 02:12:23.500]   I love the Zinfandel's.
[02:12:23.500 --> 02:12:24.500]   I love the Zinfandel's.
[02:12:24.500 --> 02:12:25.500]   I love the Zinfandel's.
[02:12:25.500 --> 02:12:26.500]   I love the Zinfandel's.
[02:12:26.500 --> 02:12:27.500]   I love the Zinfandel's.
[02:12:27.500 --> 02:12:28.500]   I love the Zinfandel's.
[02:12:28.500 --> 02:12:29.500]   I love the Zinfandel's.
[02:12:29.500 --> 02:12:30.500]   I love the Zinfandel's.
[02:12:30.500 --> 02:12:31.500]   I love the Zinfandel's.
[02:12:31.500 --> 02:12:32.500]   I love the Zinfandel's.
[02:12:32.500 --> 02:12:33.500]   I love the Zinfandel's.
[02:12:33.500 --> 02:12:34.500]   I love the Zinfandel's.
[02:12:34.500 --> 02:12:35.500]   I love the Zinfandel's.
[02:12:35.500 --> 02:12:36.500]   I love the Zinfandel's.
[02:12:36.500 --> 02:12:37.500]   I love the Zinfandel's.
[02:12:37.500 --> 02:12:38.500]   I love the Zinfandel's.
[02:12:38.500 --> 02:12:39.500]   I love the Zinfandel's.
[02:12:39.500 --> 02:12:40.500]   I love the Zinfandel's.
[02:12:40.500 --> 02:12:41.500]   I love the Zinfandel's.
[02:12:41.500 --> 02:12:42.500]   I love the Zinfandel's.
[02:12:42.500 --> 02:12:43.500]   I love the Zinfandel's.
[02:12:43.500 --> 02:12:44.500]   I love the Zinfandel's.
[02:12:44.500 --> 02:12:45.500]   I love the Zinfandel's.
[02:12:45.500 --> 02:12:46.500]   I love the Zinfandel's.
[02:12:46.500 --> 02:12:47.500]   I love the Zinfandel's.
[02:12:47.500 --> 02:12:48.500]   I love the Zinfandel's.
[02:12:48.500 --> 02:12:49.500]   I love the Zinfandel's.
[02:12:49.500 --> 02:12:50.500]   I love the Zinfandel's.
[02:12:50.500 --> 02:12:51.500]   I love the Zinfandel's.
[02:12:51.500 --> 02:12:52.500]   I love the Zinfandel's.
[02:12:52.500 --> 02:12:53.500]   I love the Zinfandel's.
[02:12:53.500 --> 02:12:54.500]   I love the Zinfandel's.
[02:12:54.500 --> 02:12:55.500]   I love the Zinfandel's.
[02:12:55.500 --> 02:12:56.500]   I love the Zinfandel's.
[02:12:56.500 --> 02:12:57.500]   I love the Zinfandel's.
[02:12:57.500 --> 02:12:58.500]   I love the Zinfandel's.
[02:12:58.500 --> 02:12:59.500]   I love the Zinfandel's.
[02:12:59.500 --> 02:13:00.500]   I love the Zinfandel's.
[02:13:00.500 --> 02:13:01.500]   I love the Zinfandel's.
[02:13:01.500 --> 02:13:02.500]   I love the Zinfandel's.
[02:13:02.500 --> 02:13:03.500]   I love the Zinfandel's.
[02:13:03.500 --> 02:13:04.500]   I love the Zinfandel's.
[02:13:04.500 --> 02:13:05.500]   I love the Zinfandel's.
[02:13:05.500 --> 02:13:06.500]   I love the Zinfandel's.
[02:13:06.500 --> 02:13:07.500]   I love the Zinfandel's.
[02:13:07.500 --> 02:13:08.500]   I love the Zinfandel's.
[02:13:08.500 --> 02:13:09.500]   I love the Zinfandel's.
[02:13:09.500 --> 02:13:10.500]   I love the Zinfandel's.
[02:13:10.500 --> 02:13:11.500]   I love the Zinfandel's.
[02:13:11.500 --> 02:13:12.500]   I love the Zinfandel's.
[02:13:12.500 --> 02:13:13.500]   I love the Zinfandel's.
[02:13:13.500 --> 02:13:14.500]   I love the Zinfandel's.
[02:13:14.500 --> 02:13:15.500]   I love the Zinfandel's.
[02:13:15.500 --> 02:13:16.500]   I love the Zinfandel's.
[02:13:16.500 --> 02:13:17.500]   I love the Zinfandel's.
[02:13:17.500 --> 02:13:18.500]   I love the Zinfandel's.
[02:13:18.500 --> 02:13:19.500]   I love the Zinfandel's.
[02:13:19.500 --> 02:13:20.500]   I love the Zinfandel's.
[02:13:20.500 --> 02:13:21.500]   I love the Zinfandel's.
[02:13:21.500 --> 02:13:22.500]   I love the Zinfandel's.
[02:13:22.500 --> 02:13:23.500]   I love the Zinfandel's.
[02:13:23.500 --> 02:13:24.500]   I love the Zinfandel's.
[02:13:24.500 --> 02:13:25.500]   I love the Zinfandel's.
[02:13:25.500 --> 02:13:26.500]   I love the Zinfandel's.
[02:13:26.500 --> 02:13:27.500]   I love the Zinfandel's.
[02:13:27.500 --> 02:13:28.500]   I love the Zinfandel's.
[02:13:28.500 --> 02:13:29.500]   I love the Zinfandel's.
[02:13:29.500 --> 02:13:30.500]   I love the Zinfandel's.
[02:13:30.500 --> 02:13:31.500]   I love the Zinfandel's.
[02:13:31.500 --> 02:13:32.500]   I love the Zinfandel's.
[02:13:32.500 --> 02:13:33.500]   I love the Zinfandel's.
[02:13:33.500 --> 02:13:34.500]   I love the Zinfandel's.
[02:13:34.500 --> 02:13:35.500]   I love the Zinfandel's.
[02:13:35.500 --> 02:13:36.500]   I love the Zinfandel's.
[02:13:36.500 --> 02:13:37.500]   I love the Zinfandel's.
[02:13:37.500 --> 02:13:38.500]   I love the Zinfandel's.
[02:13:38.500 --> 02:13:39.500]   I love the Zinfandel's.
[02:13:39.500 --> 02:13:40.500]   I love the Zinfandel's.
[02:13:40.500 --> 02:13:41.500]   I love the Zinfandel's.
[02:13:41.500 --> 02:13:42.500]   I love the Zinfandel's.
[02:13:42.500 --> 02:13:43.500]   I love the Zinfandel's.
[02:13:43.500 --> 02:13:44.500]   I love the Zinfandel's.
[02:13:44.500 --> 02:13:45.500]   I love the Zinfandel's.
[02:13:45.500 --> 02:13:46.500]   I love the Zinfandel's.
[02:13:46.500 --> 02:13:47.500]   I love the Zinfandel's.
[02:13:47.500 --> 02:13:48.500]   I love the Zinfandel's.
[02:13:48.500 --> 02:13:49.500]   I love the Zinfandel's.
[02:13:49.500 --> 02:13:50.500]   I love the Zinfandel's.
[02:13:50.500 --> 02:13:51.500]   I love the Zinfandel's.
[02:13:51.500 --> 02:13:52.500]   I love the Zinfandel's.
[02:13:52.500 --> 02:13:53.500]   I love the Zinfandel's.
[02:13:53.500 --> 02:13:54.500]   I love the Zinfandel's.
[02:13:54.500 --> 02:13:55.500]   I love the Zinfandel's.
[02:13:55.500 --> 02:13:56.500]   I love the Zinfandel's.
[02:13:56.500 --> 02:13:57.500]   I love the Zinfandel's.
[02:13:57.500 --> 02:13:58.500]   I love the Zinfandel's.
[02:13:58.500 --> 02:13:59.500]   I love the Zinfandel's.
[02:13:59.500 --> 02:14:00.500]   I love the Zinfandel's.
[02:14:00.500 --> 02:14:01.500]   I love the Zinfandel's.
[02:14:01.500 --> 02:14:02.500]   I love the Zinfandel's.
[02:14:02.500 --> 02:14:03.500]   I love the Zinfandel's.
[02:14:03.500 --> 02:14:04.500]   I love the Zinfandel's.
[02:14:04.500 --> 02:14:05.500]   I love the Zinfandel's.
[02:14:05.500 --> 02:14:06.500]   I love the Zinfandel's.
[02:14:06.500 --> 02:14:07.500]   I love the Zinfandel's.
[02:14:07.500 --> 02:14:08.500]   I love the Zinfandel's.
[02:14:08.500 --> 02:14:09.500]   I love the Zinfandel's.
[02:14:09.500 --> 02:14:10.500]   I love the Zinfandel's.
[02:14:10.500 --> 02:14:11.500]   I love the Zinfandel's.
[02:14:11.500 --> 02:14:12.500]   I love the Zinfandel's.
[02:14:12.500 --> 02:14:13.500]   I love the Zinfandel's.
[02:14:13.500 --> 02:14:14.500]   I love the Zinfandel's.
[02:14:14.500 --> 02:14:15.500]   I love the Zinfandel's.
[02:14:15.500 --> 02:14:16.500]   I love the Zinfandel's.
[02:14:16.500 --> 02:14:17.500]   I love the Zinfandel's.
[02:14:17.500 --> 02:14:18.500]   I love the Zinfandel's.
[02:14:18.500 --> 02:14:19.500]   I love the Zinfandel's.
[02:14:19.500 --> 02:14:20.500]   I love the Zinfandel's.
[02:14:20.500 --> 02:14:21.500]   I love the Zinfandel's.
[02:14:21.500 --> 02:14:22.500]   I love the Zinfandel's.
[02:14:22.500 --> 02:14:23.500]   I love the Zinfandel's.
[02:14:23.500 --> 02:14:24.500]   I love the Zinfandel's.
[02:14:24.500 --> 02:14:25.500]   I love the Zinfandel's.
[02:14:25.500 --> 02:14:26.500]   I love the Zinfandel's.
[02:14:26.500 --> 02:14:27.500]   I love the Zinfandel's.
[02:14:27.500 --> 02:14:28.500]   I love the Zinfandel's.
[02:14:28.500 --> 02:14:29.500]   I love the Zinfandel's.
[02:14:29.500 --> 02:14:30.500]   I love the Zinfandel's.
[02:14:30.500 --> 02:14:31.500]   I love the Zinfandel's.
[02:14:31.500 --> 02:14:32.500]   I love the Zinfandel's.
[02:14:32.500 --> 02:14:33.500]   I love the Zinfandel's.
[02:14:33.500 --> 02:14:34.500]   I love the Zinfandel's.
[02:14:34.500 --> 02:14:35.500]   I love the Zinfandel's.
[02:14:35.500 --> 02:14:36.500]   I love the Zinfandel's.
[02:14:36.500 --> 02:14:37.500]   I love the Zinfandel's.
[02:14:37.500 --> 02:14:38.500]   I love the Zinfandel's.
[02:14:38.500 --> 02:14:39.500]   I love the Zinfandel's.
[02:14:39.500 --> 02:14:40.500]   I love the Zinfandel's.
[02:14:40.500 --> 02:14:41.500]   I love the Zinfandel's.
[02:14:41.500 --> 02:14:42.500]   I love the Zinfandel's.
[02:14:42.500 --> 02:14:43.500]   I love the Zinfandel's.
[02:14:43.500 --> 02:14:44.500]   I love the Zinfandel's.
[02:14:44.500 --> 02:14:45.500]   I love the Zinfandel's.
[02:14:45.500 --> 02:14:46.500]   I love the Zinfandel's.
[02:14:46.500 --> 02:14:47.500]   I love the Zinfandel's.
[02:14:47.500 --> 02:14:48.500]   I love the Zinfandel's.
[02:14:48.500 --> 02:14:49.500]   I love the Zinfandel's.
[02:14:49.500 --> 02:14:50.500]   I love the Zinfandel's.
[02:14:50.500 --> 02:14:51.500]   I love the Zinfandel's.
[02:14:51.500 --> 02:14:52.500]   I love the Zinfandel's.
[02:14:52.500 --> 02:14:53.500]   I love the Zinfandel's.
[02:14:53.500 --> 02:14:54.500]   I love the Zinfandel's.
[02:14:54.500 --> 02:14:55.500]   I love the Zinfandel's.
[02:14:55.500 --> 02:14:56.500]   I love the Zinfandel's.
[02:14:56.500 --> 02:14:57.500]   I love the Zinfandel's.
[02:14:57.500 --> 02:14:58.500]   I love the Zinfandel's.
[02:14:58.500 --> 02:14:59.500]   I love the Zinfandel's.
[02:14:59.500 --> 02:15:00.500]   I love the Zinfandel's.
[02:15:00.500 --> 02:15:01.500]   I love the Zinfandel's.
[02:15:01.500 --> 02:15:02.500]   I love the Zinfandel's.
[02:15:02.500 --> 02:15:03.500]   I love the Zinfandel's.
[02:15:03.500 --> 02:15:04.500]   I love the Zinfandel's.
[02:15:04.500 --> 02:15:05.500]   I love the Zinfandel's.
[02:15:05.500 --> 02:15:06.500]   I love the Zinfandel's.
[02:15:06.500 --> 02:15:07.500]   I love the Zinfandel's.
[02:15:07.500 --> 02:15:08.500]   I love the Zinfandel's.
[02:15:08.500 --> 02:15:09.500]   I love the Zinfandel's.
[02:15:09.500 --> 02:15:10.500]   I love the Zinfandel's.
[02:15:10.500 --> 02:15:11.500]   I love the Zinfandel's.
[02:15:11.500 --> 02:15:12.500]   I love the Zinfandel's.
[02:15:12.500 --> 02:15:13.500]   I love the Zinfandel's.
[02:15:13.500 --> 02:15:14.500]   I love the Zinfandel's.
[02:15:14.500 --> 02:15:15.500]   I love the Zinfandel's.
[02:15:15.500 --> 02:15:16.500]   I love the Zinfandel's.
[02:15:16.500 --> 02:15:17.500]   I love the Zinfandel's.
[02:15:17.500 --> 02:15:18.500]   I love the Zinfandel's.
[02:15:18.500 --> 02:15:19.500]   I love the Zinfandel's.
[02:15:19.500 --> 02:15:20.500]   I love the Zinfandel's.
[02:15:20.500 --> 02:15:21.500]   I love the Zinfandel's.
[02:15:21.500 --> 02:15:22.500]   I love the Zinfandel's.
[02:15:22.500 --> 02:15:23.500]   I love the Zinfandel's.
[02:15:23.500 --> 02:15:24.500]   I love the Zinfandel's.
[02:15:24.500 --> 02:15:25.500]   I love the Zinfandel's.
[02:15:25.500 --> 02:15:26.500]   I love the Zinfandel's.
[02:15:26.500 --> 02:15:27.500]   I love the Zinfandel's.
[02:15:27.500 --> 02:15:28.500]   I love the Zinfandel's.
[02:15:28.500 --> 02:15:29.500]   I love the Zinfandel's.
[02:15:29.500 --> 02:15:30.500]   I love the Zinfandel's.
[02:15:30.500 --> 02:15:31.500]   I love the Zinfandel's.
[02:15:31.500 --> 02:15:32.500]   I love the Zinfandel's.
[02:15:32.500 --> 02:15:33.500]   I love the Zinfandel's.
[02:15:33.500 --> 02:15:34.500]   I love the Zinfandel's.
[02:15:34.500 --> 02:15:35.500]   I love the Zinfandel's.
[02:15:35.500 --> 02:15:36.500]   I love the Zinfandel's.
[02:15:36.500 --> 02:15:37.500]   I love the Zinfandel's.
[02:15:37.500 --> 02:15:38.500]   I love the Zinfandel's.
[02:15:38.500 --> 02:15:39.500]   I love the Zinfandel's.
[02:15:39.500 --> 02:15:40.500]   I love the Zinfandel's.
[02:15:40.500 --> 02:15:41.500]   I love the Zinfandel's.
[02:15:41.500 --> 02:15:42.500]   I love the Zinfandel's.
[02:15:42.500 --> 02:15:43.500]   I love the Zinfandel's.
[02:15:43.500 --> 02:15:44.500]   I love the Zinfandel's.
[02:15:44.500 --> 02:15:45.500]   I love the Zinfandel's.
[02:15:45.500 --> 02:15:46.500]   I love the Zinfandel's.
[02:15:46.500 --> 02:15:47.500]   I love the Zinfandel's.
[02:15:47.500 --> 02:15:48.500]   I love the Zinfandel's.
[02:15:48.500 --> 02:15:49.500]   I love the Zinfandel's.
[02:15:49.500 --> 02:15:50.500]   I love the Zinfandel's.
[02:15:50.500 --> 02:15:51.500]   I love the Zinfandel's.
[02:15:51.500 --> 02:15:52.500]   I love the Zinfandel's.
[02:15:52.500 --> 02:15:53.500]   I love the Zinfandel's.
[02:15:53.500 --> 02:15:54.500]   I love the Zinfandel's.
[02:15:54.500 --> 02:15:55.500]   I love the Zinfandel's.
[02:15:55.500 --> 02:15:56.500]   I love the Zinfandel's.
[02:15:56.500 --> 02:15:57.500]   I love the Zinfandel's.
[02:15:57.500 --> 02:15:58.500]   I love the Zinfandel's.
[02:15:58.500 --> 02:15:59.500]   I love the Zinfandel's.
[02:15:59.500 --> 02:16:00.500]   I love the Zinfandel's.
[02:16:00.500 --> 02:16:01.500]   I love the Zinfandel's.
[02:16:01.500 --> 02:16:02.500]   I love the Zinfandel's.
[02:16:02.500 --> 02:16:03.500]   I love the Zinfandel's.
[02:16:03.500 --> 02:16:04.500]   I love the Zinfandel's.
[02:16:04.500 --> 02:16:05.500]   I love the Zinfandel's.
[02:16:05.500 --> 02:16:06.500]   I love the Zinfandel's.
[02:16:06.500 --> 02:16:07.500]   I love the Zinfandel's.
[02:16:07.500 --> 02:16:08.500]   I love the Zinfandel's.
[02:16:08.500 --> 02:16:09.500]   I love the Zinfandel's.
[02:16:09.500 --> 02:16:10.500]   I love the Zinfandel's.
[02:16:10.500 --> 02:16:11.500]   I love the Zinfandel's.
[02:16:11.500 --> 02:16:12.500]   I love the Zinfandel's.
[02:16:12.500 --> 02:16:13.500]   I love the Zinfandel's.
[02:16:13.500 --> 02:16:14.500]   I love the Zinfandel's.
[02:16:14.500 --> 02:16:15.500]   I love the Zinfandel's.
[02:16:15.500 --> 02:16:16.500]   I love the Zinfandel's.
[02:16:16.500 --> 02:16:17.500]   I love the Zinfandel's.
[02:16:17.500 --> 02:16:18.500]   I love the Zinfandel's.
[02:16:18.500 --> 02:16:19.500]   I love the Zinfandel's.
[02:16:19.500 --> 02:16:20.500]   I love the Zinfandel's.
[02:16:20.500 --> 02:16:21.500]   I love the Zinfandel's.
[02:16:21.500 --> 02:16:22.500]   I love the Zinfandel's.
[02:16:22.500 --> 02:16:23.500]   I love the Zinfandel's.
[02:16:23.500 --> 02:16:24.500]   I love the Zinfandel's.
[02:16:24.500 --> 02:16:25.500]   I love the Zinfandel's.
[02:16:25.500 --> 02:16:26.500]   I love the Zinfandel's.
[02:16:26.500 --> 02:16:27.500]   I love the Zinfandel's.
[02:16:27.500 --> 02:16:28.500]   I love the Zinfandel's.
[02:16:28.500 --> 02:16:29.500]   I love the Zinfandel's.
[02:16:29.500 --> 02:16:30.500]   I love the Zinfandel's.
[02:16:30.500 --> 02:16:31.500]   I love the Zinfandel's.
[02:16:31.500 --> 02:16:32.500]   I love the Zinfandel's.
[02:16:32.500 --> 02:16:33.500]   I love the Zinfandel's.
[02:16:33.500 --> 02:16:34.500]   I love the Zinfandel's.
[02:16:34.500 --> 02:16:35.500]   I love the Zinfandel's.
[02:16:35.500 --> 02:16:36.500]   I love the Zinfandel's.
[02:16:36.500 --> 02:16:37.500]   I love the Zinfandel's.
[02:16:37.500 --> 02:16:38.500]   I love the Zinfandel's.
[02:16:38.500 --> 02:16:39.500]   I love the Zinfandel's.
[02:16:39.500 --> 02:16:40.500]   I love the Zinfandel's.
[02:16:40.500 --> 02:16:41.500]   I love the Zinfandel's.
[02:16:41.500 --> 02:16:42.500]   I love the Zinfandel's.
[02:16:42.500 --> 02:16:43.500]   I love the Zinfandel's.
[02:16:43.500 --> 02:16:44.500]   I love the Zinfandel's.
[02:16:44.500 --> 02:16:45.500]   I love the Zinfandel's.
[02:16:45.500 --> 02:16:46.500]   I love the Zinfandel's.
[02:16:46.500 --> 02:16:47.500]   I love the Zinfandel's.
[02:16:47.500 --> 02:16:48.500]   I love the Zinfandel's.
[02:16:48.500 --> 02:16:49.500]   I love the Zinfandel's.
[02:16:49.500 --> 02:16:50.500]   I love the Zinfandel's.
[02:16:50.500 --> 02:16:51.500]   I love the Zinfandel's.
[02:16:51.500 --> 02:16:52.500]   I love the Zinfandel's.
[02:16:52.500 --> 02:16:53.500]   I love the Zinfandel's.
[02:16:53.500 --> 02:16:54.500]   I love the Zinfandel's.
[02:16:54.500 --> 02:16:55.500]   I love the Zinfandel's.
[02:16:55.500 --> 02:16:56.500]   I love the Zinfandel's.
[02:16:56.500 --> 02:16:57.500]   I love the Zinfandel's.
[02:16:57.500 --> 02:16:58.500]   I love the Zinfandel's.
[02:16:58.500 --> 02:16:59.500]   I love the Zinfandel's.
[02:16:59.500 --> 02:17:00.500]   I love the Zinfandel's.
[02:17:00.500 --> 02:17:01.500]   I love the Zinfandel's.
[02:17:01.500 --> 02:17:02.500]   I love the Zinfandel's.
[02:17:02.500 --> 02:17:03.500]   I love the Zinfandel's.
[02:17:03.500 --> 02:17:04.500]   I love the Zinfandel's.
[02:17:04.500 --> 02:17:05.500]   I love the Zinfandel's.
[02:17:05.500 --> 02:17:06.500]   I love the Zinfandel's.
[02:17:06.500 --> 02:17:07.500]   I love the Zinfandel's.
[02:17:07.500 --> 02:17:08.500]   I love the Zinfandel's.
[02:17:08.500 --> 02:17:09.500]   I love the Zinfandel's.
[02:17:09.500 --> 02:17:10.500]   I love the Zinfandel's.
[02:17:10.500 --> 02:17:11.500]   I love the Zinfandel's.
[02:17:11.500 --> 02:17:12.500]   I love the Zinfandel's.
[02:17:12.500 --> 02:17:13.500]   I love the Zinfandel's.
[02:17:13.500 --> 02:17:14.500]   I love the Zinfandel's.
[02:17:14.500 --> 02:17:15.500]   I love the Zinfandel's.
[02:17:15.500 --> 02:17:16.500]   I love the Zinfandel's.
[02:17:16.500 --> 02:17:17.500]   I love the Zinfandel's.
[02:17:17.500 --> 02:17:18.500]   I love the Zinfandel's.
[02:17:18.500 --> 02:17:19.500]   I love the Zinfandel's.
[02:17:19.500 --> 02:17:20.500]   I love the Zinfandel's.
[02:17:20.500 --> 02:17:21.500]   I love the Zinfandel's.
[02:17:21.500 --> 02:17:22.500]   I love the Zinfandel's.
[02:17:22.500 --> 02:17:23.500]   I love the Zinfandel's.
[02:17:23.500 --> 02:17:24.500]   I love the Zinfandel's.
[02:17:24.500 --> 02:17:25.500]   I love the Zinfandel's.
[02:17:25.500 --> 02:17:26.500]   I love the Zinfandel's.
[02:17:26.500 --> 02:17:27.500]   I love the Zinfandel's.
[02:17:27.500 --> 02:17:28.500]   I love the Zinfandel's.
[02:17:28.500 --> 02:17:29.500]   I love the Zinfandel's.
[02:17:29.500 --> 02:17:30.500]   I love the Zinfandel's.
[02:17:30.500 --> 02:17:31.500]   I love the Zinfandel's.
[02:17:31.500 --> 02:17:32.500]   I love the Zinfandel's.
[02:17:32.500 --> 02:17:33.500]   I love the Zinfandel's.
[02:17:33.500 --> 02:17:34.500]   I love the Zinfandel's.
[02:17:34.500 --> 02:17:35.500]   I love the Zinfandel's.
[02:17:35.500 --> 02:17:36.500]   I love the Zinfandel's.
[02:17:36.500 --> 02:17:37.500]   I love the Zinfandel's.
[02:17:37.500 --> 02:17:38.500]   I love the Zinfandel's.
[02:17:38.500 --> 02:17:39.500]   I love the Zinfandel's.
[02:17:39.500 --> 02:17:40.500]   I love the Zinfandel's.
[02:17:40.500 --> 02:17:41.500]   I love the Zinfandel's.
[02:17:41.500 --> 02:17:42.500]   I love the Zinfandel's.
[02:17:42.500 --> 02:17:43.500]   I love the Zinfandel's.
[02:17:43.500 --> 02:17:44.500]   I love the Zinfandel's.
[02:17:44.500 --> 02:17:45.500]   I love the Zinfandel's.
[02:17:45.500 --> 02:17:46.500]   I love the Zinfandel's.
[02:17:46.500 --> 02:17:47.500]   I love the Zinfandel's.
[02:17:47.500 --> 02:17:48.500]   I love the Zinfandel's.
[02:17:48.500 --> 02:17:49.500]   I love the Zinfandel's.
[02:17:49.500 --> 02:17:50.500]   I love the Zinfandel's.
[02:17:50.500 --> 02:17:51.500]   I love the Zinfandel's.
[02:17:51.500 --> 02:17:52.500]   I love the Zinfandel's.
[02:17:52.500 --> 02:17:53.500]   I love the Zinfandel's.
[02:17:53.500 --> 02:17:54.500]   I love the Zinfandel's.
[02:17:54.500 --> 02:17:55.500]   I love the Zinfandel's.
[02:17:55.500 --> 02:17:56.500]   I love the Zinfandel's.
[02:17:56.500 --> 02:17:57.500]   I love the Zinfandel's.
[02:17:57.500 --> 02:17:58.500]   I love the Zinfandel's.
[02:17:58.500 --> 02:17:59.500]   I love the Zinfandel's.
[02:17:59.500 --> 02:18:00.500]   I love the Zinfandel's.
[02:18:00.500 --> 02:18:01.500]   I love the Zinfandel's.
[02:18:01.500 --> 02:18:02.500]   I love the Zinfandel's.
[02:18:02.500 --> 02:18:03.500]   I love the Zinfandel's.
[02:18:03.500 --> 02:18:04.500]   I love the Zinfandel's.
[02:18:04.500 --> 02:18:05.500]   I love the Zinfandel's.
[02:18:05.500 --> 02:18:06.500]   I love the Zinfandel's.
[02:18:06.500 --> 02:18:07.500]   I love the Zinfandel's.
[02:18:07.500 --> 02:18:08.500]   I love the Zinfandel's.
[02:18:08.500 --> 02:18:09.500]   I love the Zinfandel's.
[02:18:09.500 --> 02:18:10.500]   I love the Zinfandel's.
[02:18:10.500 --> 02:18:11.500]   I love the Zinfandel's.
[02:18:11.500 --> 02:18:12.500]   I love the Zinfandel's.
[02:18:12.500 --> 02:18:13.500]   I love the Zinfandel's.
[02:18:13.500 --> 02:18:14.500]   I love the Zinfandel's.
[02:18:14.500 --> 02:18:15.500]   I love the Zinfandel's.
[02:18:15.500 --> 02:18:16.500]   I love the Zinfandel's.
[02:18:16.500 --> 02:18:17.500]   I love the Zinfandel's.
[02:18:17.500 --> 02:18:18.500]   I love the Zinfandel's.
[02:18:18.500 --> 02:18:19.500]   I love the Zinfandel's.
[02:18:19.500 --> 02:18:20.500]   I love the Zinfandel's.
[02:18:20.500 --> 02:18:21.500]   I love the Zinfandel's.
[02:18:21.500 --> 02:18:22.500]   I love the Zinfandel's.
[02:18:22.500 --> 02:18:23.500]   I love the Zinfandel's.
[02:18:23.500 --> 02:18:24.500]   I love the Zinfandel's.
[02:18:24.500 --> 02:18:25.500]   I love the Zinfandel's.
[02:18:25.500 --> 02:18:26.500]   I love the Zinfandel's.
[02:18:26.500 --> 02:18:27.500]   I love the Zinfandel's.
[02:18:27.500 --> 02:18:28.500]   I love the Zinfandel's.
[02:18:28.500 --> 02:18:29.500]   I love the Zinfandel's.
[02:18:29.500 --> 02:18:30.500]   I love the Zinfandel's.
[02:18:30.500 --> 02:18:31.500]   I love the Zinfandel's.
[02:18:31.500 --> 02:18:32.500]   I love the Zinfandel's.
[02:18:32.500 --> 02:18:33.500]   I love the Zinfandel's.
[02:18:33.500 --> 02:18:34.500]   I love the Zinfandel's.
[02:18:34.500 --> 02:18:35.500]   I love the Zinfandel's.
[02:18:35.500 --> 02:18:36.500]   I love the Zinfandel's.
[02:18:36.500 --> 02:18:37.500]   I love the Zinfandel's.
[02:18:37.500 --> 02:18:38.500]   I love the Zinfandel's.
[02:18:38.500 --> 02:18:39.500]   I love the Zinfandel's.
[02:18:39.500 --> 02:18:40.500]   I love the Zinfandel's.
[02:18:40.500 --> 02:18:41.500]   I love the Zinfandel's.
[02:18:41.500 --> 02:18:42.500]   I love the Zinfandel's.
[02:18:42.500 --> 02:18:43.500]   I love the Zinfandel's.
[02:18:43.500 --> 02:18:44.500]   I love the Zinfandel's.
[02:18:44.500 --> 02:18:45.500]   I love the Zinfandel's.
[02:18:45.500 --> 02:18:46.500]   I love the Zinfandel's.
[02:18:46.500 --> 02:18:47.500]   I love the Zinfandel's.
[02:18:47.500 --> 02:18:48.500]   I love the Zinfandel's.
[02:18:48.500 --> 02:18:49.500]   I love the Zinfandel's.
[02:18:49.500 --> 02:18:50.500]   I love the Zinfandel's.
[02:18:50.500 --> 02:18:51.500]   I love the Zinfandel's.
[02:18:51.500 --> 02:18:52.500]   I love the Zinfandel's.
[02:18:52.500 --> 02:18:53.500]   I love the Zinfandel's.
[02:18:53.500 --> 02:18:54.500]   I love the Zinfandel's.
[02:18:54.500 --> 02:18:55.500]   I love the Zinfandel's.
[02:18:55.500 --> 02:18:56.500]   I love the Zinfandel's.
[02:18:56.500 --> 02:18:57.500]   I love the Zinfandel's.
[02:18:57.500 --> 02:18:58.500]   I love the Zinfandel's.
[02:18:58.500 --> 02:18:59.500]   I love the Zinfandel's.
[02:18:59.500 --> 02:19:00.500]   I love the Zinfandel's.
[02:19:00.500 --> 02:19:01.500]   I love the Zinfandel's.
[02:19:01.500 --> 02:19:02.500]   I love the Zinfandel's.
[02:19:02.500 --> 02:19:03.500]   I love the Zinfandel's.
[02:19:03.500 --> 02:19:04.500]   I love the Zinfandel's.
[02:19:04.500 --> 02:19:05.500]   I love the Zinfandel's.
[02:19:05.500 --> 02:19:06.500]   I love the Zinfandel's.
[02:19:06.500 --> 02:19:07.500]   I love the Zinfandel's.
[02:19:07.500 --> 02:19:08.500]   I love the Zinfandel's.
[02:19:08.500 --> 02:19:09.500]   I love the Zinfandel's.
[02:19:09.500 --> 02:19:10.500]   I love the Zinfandel's.
[02:19:10.500 --> 02:19:11.500]   I love the Zinfandel's.
[02:19:11.500 --> 02:19:12.500]   I love the Zinfandel's.
[02:19:12.500 --> 02:19:13.500]   I love the Zinfandel's.
[02:19:13.500 --> 02:19:14.500]   I love the Zinfandel's.
[02:19:14.500 --> 02:19:15.500]   I love the Zinfandel's.
[02:19:15.500 --> 02:19:16.500]   I love the Zinfandel's.
[02:19:16.500 --> 02:19:17.500]   I love the Zinfandel's.
[02:19:17.500 --> 02:19:18.500]   I love the Zinfandel's.
[02:19:18.500 --> 02:19:19.500]   I love the Zinfandel's.
[02:19:19.500 --> 02:19:20.500]   I love the Zinfandel's.
[02:19:20.500 --> 02:19:21.500]   I love the Zinfandel's.
[02:19:21.500 --> 02:19:22.500]   I love the Zinfandel's.
[02:19:22.500 --> 02:19:23.500]   I love the Zinfandel's.
[02:19:23.500 --> 02:19:24.500]   I love the Zinfandel's.
[02:19:24.500 --> 02:19:25.500]   I love the Zinfandel's.
[02:19:25.500 --> 02:19:26.500]   I love the Zinfandel's.
[02:19:26.500 --> 02:19:27.500]   I love the Zinfandel's.
[02:19:27.500 --> 02:19:28.500]   I love the Zinfandel's.
[02:19:28.500 --> 02:19:29.500]   I love the Zinfandel's.
[02:19:29.500 --> 02:19:30.500]   I love the Zinfandel's.
[02:19:30.500 --> 02:19:31.500]   I love the Zinfandel's.
[02:19:31.500 --> 02:19:32.500]   I love the Zinfandel's.
[02:19:32.500 --> 02:19:33.500]   I love the Zinfandel's.
[02:19:33.500 --> 02:19:34.500]   I love the Zinfandel's.
[02:19:34.500 --> 02:19:35.500]   I love the Zinfandel's.
[02:19:35.500 --> 02:19:36.500]   I love the Zinfandel's.
[02:19:36.500 --> 02:19:37.500]   I love the Zinfandel's.
[02:19:37.500 --> 02:19:38.500]   I love the Zinfandel's.
[02:19:38.500 --> 02:19:39.500]   I love the Zinfandel's.
[02:19:39.500 --> 02:19:40.500]   I love the Zinfandel's.
[02:19:40.500 --> 02:19:41.500]   I love the Zinfandel's.
[02:19:41.500 --> 02:19:42.500]   I love the Zinfandel's.
[02:19:42.500 --> 02:19:43.500]   I love the Zinfandel's.
[02:19:43.500 --> 02:19:44.500]   I love the Zinfandel's.
[02:19:44.500 --> 02:19:45.500]   I love the Zinfandel's.
[02:19:45.500 --> 02:19:46.500]   I love the Zinfandel's.
[02:19:46.500 --> 02:19:47.500]   I love the Zinfandel's.
[02:19:47.500 --> 02:19:48.500]   I love the Zinfandel's.
[02:19:48.500 --> 02:19:49.500]   I love the Zinfandel's.
[02:19:49.500 --> 02:19:50.500]   I love the Zinfandel's.
[02:19:50.500 --> 02:19:51.500]   I love the Zinfandel's.
[02:19:51.500 --> 02:19:52.500]   I love the Zinfandel's.
[02:19:52.500 --> 02:19:53.500]   I love the Zinfandel's.
[02:19:53.500 --> 02:19:54.500]   I love the Zinfandel's.
[02:19:54.500 --> 02:19:55.500]   I love the Zinfandel's.
[02:19:55.500 --> 02:19:56.500]   I love the Zinfandel's.
[02:19:56.500 --> 02:19:57.500]   I love the Zinfandel's.
[02:19:57.500 --> 02:19:58.500]   I love the Zinfandel's.
[02:19:58.500 --> 02:19:59.500]   I love the Zinfandel's.
[02:19:59.500 --> 02:20:00.500]   I love the Zinfandel's.
[02:20:00.500 --> 02:20:01.500]   I love the Zinfandel's.
[02:20:01.500 --> 02:20:02.500]   I love the Zinfandel's.
[02:20:02.500 --> 02:20:03.500]   I love the Zinfandel's.
[02:20:03.500 --> 02:20:04.500]   I love the Zinfandel's.
[02:20:04.500 --> 02:20:05.500]   I love the Zinfandel's.
[02:20:05.500 --> 02:20:06.500]   I love the Zinfandel's.
[02:20:06.500 --> 02:20:07.500]   I love the Zinfandel's.
[02:20:07.500 --> 02:20:08.500]   I love the Zinfandel's.
[02:20:08.500 --> 02:20:09.500]   I love the Zinfandel's.
[02:20:09.500 --> 02:20:10.500]   I love the Zinfandel's.
[02:20:10.500 --> 02:20:11.500]   I love the Zinfandel's.
[02:20:11.500 --> 02:20:12.500]   I love the Zinfandel's.
[02:20:12.500 --> 02:20:13.500]   I love the Zinfandel's.
[02:20:13.500 --> 02:20:14.500]   I love the Zinfandel's.
[02:20:14.500 --> 02:20:15.500]   I love the Zinfandel's.
[02:20:15.500 --> 02:20:16.500]   I love the Zinfandel's.
[02:20:16.500 --> 02:20:17.500]   I love the Zinfandel's.
[02:20:17.500 --> 02:20:18.500]   I love the Zinfandel's.
[02:20:18.500 --> 02:20:19.500]   I love the Zinfandel's.
[02:20:19.500 --> 02:20:20.500]   I love the Zinfandel's.
[02:20:20.500 --> 02:20:21.500]   I love the Zinfandel's.
[02:20:21.500 --> 02:20:22.500]   I love the Zinfandel's.
[02:20:22.500 --> 02:20:23.500]   I love the Zinfandel's.
[02:20:23.500 --> 02:20:24.500]   I love the Zinfandel's.
[02:20:24.500 --> 02:20:25.500]   I love the Zinfandel's.
[02:20:25.500 --> 02:20:26.500]   I love the Zinfandel's.
[02:20:26.500 --> 02:20:27.500]   I love the Zinfandel's.
[02:20:27.500 --> 02:20:28.500]   I love the Zinfandel's.
[02:20:28.500 --> 02:20:29.500]   I love the Zinfandel's.
[02:20:29.500 --> 02:20:30.500]   I love the Zinfandel's.
[02:20:30.500 --> 02:20:31.500]   I love the Zinfandel's.
[02:20:31.500 --> 02:20:32.500]   I love the Zinfandel's.
[02:20:32.500 --> 02:20:33.500]   I love the Zinfandel's.
[02:20:33.500 --> 02:20:34.500]   I love the Zinfandel's.
[02:20:34.500 --> 02:20:35.500]   I love the Zinfandel's.
[02:20:35.500 --> 02:20:36.500]   I love the Zinfandel's.
[02:20:36.500 --> 02:20:37.500]   I love the Zinfandel's.
[02:20:37.500 --> 02:20:38.500]   I love the Zinfandel's.
[02:20:38.500 --> 02:20:39.500]   I love the Zinfandel's.
[02:20:39.500 --> 02:20:40.500]   I love the Zinfandel's.
[02:20:40.500 --> 02:20:41.500]   I love the Zinfandel's.
[02:20:41.500 --> 02:20:42.500]   I love the Zinfandel's.
[02:20:42.500 --> 02:20:43.500]   I love the Zinfandel's.
[02:20:43.500 --> 02:20:44.500]   I love the Zinfandel's.
[02:20:44.500 --> 02:20:45.500]   I love the Zinfandel's.
[02:20:45.500 --> 02:20:46.500]   I love the Zinfandel's.
[02:20:46.500 --> 02:20:47.500]   I love the Zinfandel's.
[02:20:47.500 --> 02:20:48.500]   I love the Zinfandel's.
[02:20:48.500 --> 02:20:49.500]   I love the Zinfandel's.
[02:20:49.500 --> 02:20:50.500]   I love the Zinfandel's.
[02:20:50.500 --> 02:20:51.500]   I love the Zinfandel's.
[02:20:51.500 --> 02:20:52.500]   I love the Zinfandel's.
[02:20:52.500 --> 02:20:53.500]   I love the Zinfandel's.
[02:20:53.500 --> 02:20:54.500]   I love the Zinfandel's.
[02:20:54.500 --> 02:20:55.500]   I love the Zinfandel's.
[02:20:55.500 --> 02:20:56.500]   I love the Zinfandel's.
[02:20:56.500 --> 02:20:57.500]   I love the Zinfandel's.
[02:20:57.500 --> 02:20:58.500]   I love the Zinfandel's.
[02:20:58.500 --> 02:20:59.500]   I love the Zinfandel's.
[02:20:59.500 --> 02:21:00.500]   I love the Zinfandel's.
[02:21:00.500 --> 02:21:01.500]   I love the Zinfandel's.
[02:21:01.500 --> 02:21:02.500]   I love the Zinfandel's.
[02:21:02.500 --> 02:21:03.500]   I love the Zinfandel's.
[02:21:03.500 --> 02:21:04.500]   I love the Zinfandel's.
[02:21:04.500 --> 02:21:05.500]   I love the Zinfandel's.
[02:21:05.500 --> 02:21:06.500]   I love the Zinfandel's.
[02:21:06.500 --> 02:21:07.500]   I love the Zinfandel's.
[02:21:07.500 --> 02:21:08.500]   I love the Zinfandel's.
[02:21:08.500 --> 02:21:09.500]   I love the Zinfandel's.
[02:21:09.500 --> 02:21:10.500]   I love the Zinfandel's.
[02:21:10.500 --> 02:21:11.500]   I love the Zinfandel's.
[02:21:11.500 --> 02:21:12.500]   I love the Zinfandel's.
[02:21:12.500 --> 02:21:13.500]   I love the Zinfandel's.
[02:21:13.500 --> 02:21:14.500]   I love the Zinfandel's.
[02:21:14.500 --> 02:21:15.500]   I love the Zinfandel's.
[02:21:15.500 --> 02:21:16.500]   I love the Zinfandel's.
[02:21:16.500 --> 02:21:17.500]   I love the Zinfandel's.
[02:21:17.500 --> 02:21:18.500]   I love the Zinfandel's.
[02:21:18.500 --> 02:21:19.500]   I love the Zinfandel's.
[02:21:19.500 --> 02:21:20.500]   I love the Zinfandel's.
[02:21:20.500 --> 02:21:21.500]   I love the Zinfandel's.
[02:21:21.500 --> 02:21:22.500]   I love the Zinfandel's.
[02:21:22.500 --> 02:21:23.500]   I love the Zinfandel's.
[02:21:23.500 --> 02:21:24.500]   I love the Zinfandel's.
[02:21:24.500 --> 02:21:25.500]   I love the Zinfandel's.
[02:21:25.500 --> 02:21:26.500]   I love the Zinfandel's.
[02:21:26.500 --> 02:21:27.500]   I love the Zinfandel's.
[02:21:27.500 --> 02:21:28.500]   I love the Zinfandel's.
[02:21:28.500 --> 02:21:29.500]   I love the Zinfandel's.
[02:21:29.500 --> 02:21:30.500]   I love the Zinfandel's.
[02:21:30.500 --> 02:21:31.500]   I love the Zinfandel's.
[02:21:31.500 --> 02:21:32.500]   I love the Zinfandel's.
[02:21:32.500 --> 02:21:33.500]   I love the Zinfandel's.
[02:21:33.500 --> 02:21:34.500]   I love the Zinfandel's.
[02:21:34.500 --> 02:21:35.500]   I love the Zinfandel's.
[02:21:35.500 --> 02:21:36.500]   I love the Zinfandel's.
[02:21:36.500 --> 02:21:37.500]   I love the Zinfandel's.
[02:21:37.500 --> 02:21:38.500]   I love the Zinfandel's.
[02:21:38.500 --> 02:21:39.500]   I love the Zinfandel's.
[02:21:39.500 --> 02:21:40.500]   I love the Zinfandel's.
[02:21:40.500 --> 02:21:41.500]   I love the Zinfandel's.
[02:21:41.500 --> 02:21:42.500]   I love the Zinfandel's.
[02:21:42.500 --> 02:21:43.500]   I love the Zinfandel's.
[02:21:43.500 --> 02:21:44.500]   I love the Zinfandel's.
[02:21:44.500 --> 02:21:45.500]   I love the Zinfandel's.
[02:21:45.500 --> 02:21:46.500]   I love the Zinfandel's.
[02:21:46.500 --> 02:21:47.500]   I love the Zinfandel's.
[02:21:47.500 --> 02:21:48.500]   I love the Zinfandel's.
[02:21:48.500 --> 02:21:49.500]   I love the Zinfandel's.
[02:21:49.500 --> 02:21:50.500]   I love the Zinfandel's.
[02:21:50.500 --> 02:21:51.500]   I love the Zinfandel's.
[02:21:51.500 --> 02:21:52.500]   I love the Zinfandel's.
[02:21:52.500 --> 02:21:53.500]   I love the Zinfandel's.
[02:21:53.500 --> 02:21:54.500]   I love the Zinfandel's.
[02:21:54.500 --> 02:21:55.500]   I love the Zinfandel's.
[02:21:55.500 --> 02:21:56.500]   I love the Zinfandel's.
[02:21:56.500 --> 02:21:57.500]   I love the Zinfandel's.
[02:21:57.500 --> 02:21:58.500]   I love the Zinfandel's.
[02:21:58.500 --> 02:21:59.500]   I love the Zinfandel's.
[02:21:59.500 --> 02:22:00.500]   I love the Zinfandel's.
[02:22:00.500 --> 02:22:01.500]   I love the Zinfandel's.
[02:22:01.500 --> 02:22:02.500]   I love the Zinfandel's.
[02:22:02.500 --> 02:22:03.500]   I love the Zinfandel's.
[02:22:03.500 --> 02:22:04.500]   I love the Zinfandel's.
[02:22:04.500 --> 02:22:05.500]   I love the Zinfandel's.
[02:22:05.500 --> 02:22:06.500]   I love the Zinfandel's.
[02:22:06.500 --> 02:22:07.500]   I love the Zinfandel's.
[02:22:07.500 --> 02:22:08.500]   I love the Zinfandel's.
[02:22:08.500 --> 02:22:09.500]   I love the Zinfandel's.
[02:22:09.500 --> 02:22:10.500]   I love the Zinfandel's.
[02:22:10.500 --> 02:22:11.500]   I love the Zinfandel's.
[02:22:11.500 --> 02:22:12.500]   I love the Zinfandel's.
[02:22:12.500 --> 02:22:13.500]   I love the Zinfandel's.
[02:22:13.500 --> 02:22:14.500]   I love the Zinfandel's.
[02:22:14.500 --> 02:22:15.500]   I love the Zinfandel's.
[02:22:15.500 --> 02:22:16.500]   I love the Zinfandel's.
[02:22:16.500 --> 02:22:17.500]   I love the Zinfandel's.
[02:22:17.500 --> 02:22:18.500]   I love the Zinfandel's.
[02:22:18.500 --> 02:22:19.500]   I love the Zinfandel's.
[02:22:19.500 --> 02:22:20.500]   I love the Zinfandel's.

