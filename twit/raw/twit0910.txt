;FFMETADATA1
title=It's a Myrkl
artist=Leo Laporte, Fr. Robert Ballecer, SJ, Paris Martineau, Connie Guglielmo
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2023-01-16
track=910
language=English
genre=Podcast
comment=CES 2023 Recap, ChatGPT and Plagiarism, Twitter API, 2016 Election and Twitter
encoded_by=Uniblab 5.3
date=2023
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:01.720]   It's time for Twit this weekend tech.
[00:00:01.720 --> 00:00:06.320]   Father Robert is here with all sorts of cool stuff.
[00:00:06.320 --> 00:00:09.680]   From CES, Connie Gullielmo, CNET's editor in chief,
[00:00:09.680 --> 00:00:11.160]   is also back from Vegas.
[00:00:11.160 --> 00:00:13.960]   She's got to look at some of the more important things
[00:00:13.960 --> 00:00:15.280]   she saw at CES.
[00:00:15.280 --> 00:00:18.320]   And then, of course, Paris Martyno from the information.
[00:00:18.320 --> 00:00:19.720]   There's a lot to talk about.
[00:00:19.720 --> 00:00:20.480]   Let's get started.
[00:00:20.480 --> 00:00:21.960]   Twit is next.
[00:00:21.960 --> 00:00:26.800]   Podcasts you love.
[00:00:26.800 --> 00:00:29.320]   From people you trust.
[00:00:29.320 --> 00:00:30.880]   This is Twit.
[00:00:30.880 --> 00:00:37.880]   This is Twit.
[00:00:37.880 --> 00:00:41.000]   This weekend tech, episode 910.
[00:00:41.000 --> 00:00:46.320]   For Sunday, January 15, 2023, it's a Merkle.
[00:00:46.320 --> 00:00:48.960]   This weekend tech is brought to you by Decisions.
[00:00:48.960 --> 00:00:52.160]   Don't let complexity block your company's growth.
[00:00:52.160 --> 00:00:56.240]   Decisions no code rules driven process automation software.
[00:00:56.240 --> 00:00:59.560]   It provides every tool you'll need to build custom workflows,
[00:00:59.560 --> 00:01:02.360]   empowering you to modernize legacy systems,
[00:01:02.360 --> 00:01:07.200]   ensure regulatory compliance, and renew the customer experience.
[00:01:07.200 --> 00:01:12.400]   Visit decisions.com/twit to learn how automating anything
[00:01:12.400 --> 00:01:14.640]   can change everything.
[00:01:14.640 --> 00:01:16.240]   And by Noom.
[00:01:16.240 --> 00:01:18.200]   Stay focused on what's important to you
[00:01:18.200 --> 00:01:20.600]   with Noomweight's psychology-based approach.
[00:01:20.600 --> 00:01:24.600]   And check out Noom's first-ever book, The Noom Mindset,
[00:01:24.600 --> 00:01:27.320]   a deep dive into the psychology of behavior change,
[00:01:27.320 --> 00:01:29.960]   available to buy now wherever books are sold.
[00:01:29.960 --> 00:01:34.800]   Sign up for your trial at noon.com/twit.
[00:01:34.800 --> 00:01:37.080]   And by ZipRecruiter.
[00:01:37.080 --> 00:01:39.200]   Your company has goals this year.
[00:01:39.200 --> 00:01:42.440]   Find the right people to help you achieve them with ZipRecruiter,
[00:01:42.440 --> 00:01:44.640]   where four out of five employers get a quality
[00:01:44.640 --> 00:01:46.560]   candidate within the first day.
[00:01:46.560 --> 00:01:50.920]   Try it free at ziprecruiter.com/twit.
[00:01:50.920 --> 00:01:53.120]   And by Mint Mobile.
[00:01:53.120 --> 00:01:57.480]   If saving more and spending less is one of your top goals for 2023,
[00:01:57.480 --> 00:02:01.200]   switching to Mint Mobile is the easiest way to save this year.
[00:02:01.200 --> 00:02:04.400]   Get your new wireless plan for just $15 a month.
[00:02:04.400 --> 00:02:07.120]   And get the plan shipped to your door for free.
[00:02:07.120 --> 00:02:10.000]   Go to mintmobile.com/twit.
[00:02:10.000 --> 00:02:12.480]   [MUSIC PLAYING]
[00:02:12.480 --> 00:02:19.360]   It's time for Twit this week in Tech, the show we cover the week's
[00:02:19.360 --> 00:02:20.400]   Tech News.
[00:02:20.400 --> 00:02:25.080]   We've got a great panel for you, including a bunch of stuff
[00:02:25.080 --> 00:02:27.040]   from the Padre Shopping Network.
[00:02:27.040 --> 00:02:30.760]   Before I get to that, let's introduce the editor-in-chief
[00:02:30.760 --> 00:02:32.200]   of Cinek Connie Guillamo.
[00:02:32.200 --> 00:02:33.480]   It's great to see you again.
[00:02:33.480 --> 00:02:35.800]   Thank you for joining us, Connie.
[00:02:35.800 --> 00:02:36.400]   My pleasure.
[00:02:36.400 --> 00:02:37.400]   Happy to be here.
[00:02:37.400 --> 00:02:38.600]   Wonderful to have you.
[00:02:38.600 --> 00:02:43.360]   You were at CES, and you're still standing.
[00:02:43.360 --> 00:02:44.840]   I did not get sick this year.
[00:02:44.840 --> 00:02:46.320]   I'm pressed.
[00:02:46.320 --> 00:02:47.440]   It was late this year.
[00:02:47.440 --> 00:02:50.360]   It started on Thursday, went through Sunday.
[00:02:50.360 --> 00:02:53.280]   But I will get your thoughts.
[00:02:53.280 --> 00:02:54.960]   Before that, though, let's say out of Paris,
[00:02:54.960 --> 00:02:57.400]   Martin O who did not go to CES, she
[00:02:57.400 --> 00:02:59.280]   is, of course, at the great information.
[00:02:59.280 --> 00:03:01.240]   We've been quoting you guys a lot lately.
[00:03:01.240 --> 00:03:02.160]   Hi, Paris.
[00:03:02.160 --> 00:03:04.200]   We've been doing a lot of great stuff here.
[00:03:04.200 --> 00:03:04.720]   Hi.
[00:03:04.720 --> 00:03:08.720]   Happy to be here just like the Oolot and Merkel.
[00:03:08.720 --> 00:03:10.560]   You mean, Merkel--
[00:03:10.560 --> 00:03:11.320]   Merkel!
[00:03:11.320 --> 00:03:13.600]   --the drug for drunks?
[00:03:13.600 --> 00:03:15.320]   That one?
[00:03:15.320 --> 00:03:16.480]   Yes.
[00:03:16.480 --> 00:03:17.480]   The one-- That one's the--
[00:03:17.480 --> 00:03:21.920]   The drug with the unaccountable Oolot over the M, that one?
[00:03:21.920 --> 00:03:25.000]   It's-- No vowels except for a Y unless you count that.
[00:03:25.000 --> 00:03:27.280]   Y-R-K-L.
[00:03:27.280 --> 00:03:28.480]   Father Robert brought this.
[00:03:28.480 --> 00:03:29.720]   Father Robert Ballis there.
[00:03:29.720 --> 00:03:31.960]   The digital Jesuit is here.
[00:03:31.960 --> 00:03:33.040]   It's great to see you.
[00:03:33.040 --> 00:03:35.440]   You were in Vegas as well.
[00:03:35.440 --> 00:03:36.400]   I was.
[00:03:36.400 --> 00:03:40.960]   And it was odd because I always come back from CES with something.
[00:03:40.960 --> 00:03:44.200]   Normally a cold or flu instead, Merkel.
[00:03:44.200 --> 00:03:44.960]   I had a Merkel.
[00:03:44.960 --> 00:03:45.800]   I got a Merkel.
[00:03:45.800 --> 00:03:47.400]   And we look at all this.
[00:03:47.400 --> 00:03:47.880]   Yep.
[00:03:47.880 --> 00:03:48.680]   Look at all this.
[00:03:48.680 --> 00:03:52.720]   Yeah, I kind of-- OK, I have to say, this is only the big stuff.
[00:03:52.720 --> 00:03:55.720]   I left most of it back in Las Vegas.
[00:03:55.720 --> 00:03:57.560]   So I never-- I don't know about you, Connie.
[00:03:57.560 --> 00:04:01.040]   I never come back with anything from CES except maybe a stress
[00:04:01.040 --> 00:04:02.000]   squeeze doll.
[00:04:02.000 --> 00:04:03.520]   I come back with everything.
[00:04:03.520 --> 00:04:04.480]   What?
[00:04:04.480 --> 00:04:08.520]   Leo, that's like the one point of going to CES is stuff.
[00:04:08.520 --> 00:04:08.960]   You've come like--
[00:04:08.960 --> 00:04:11.280]   I always come back with an icon bag.
[00:04:11.280 --> 00:04:12.360]   The yellow icon bag?
[00:04:12.360 --> 00:04:13.680]   Yeah, the yellow icon bag.
[00:04:13.680 --> 00:04:14.040]   Yeah.
[00:04:14.040 --> 00:04:15.040]   I kind of came back with--
[00:04:15.040 --> 00:04:17.840]   I see, I got-- on the table, there's three laptops,
[00:04:17.840 --> 00:04:21.000]   pair of shoes, bunch of socks, a couple hundred dollars
[00:04:21.000 --> 00:04:25.720]   with the SSDs and USBs, a pet vacuum, a really, really cool,
[00:04:25.720 --> 00:04:28.040]   super encrypted drive, some noise-canceling
[00:04:28.040 --> 00:04:29.680]   headsets and power products.
[00:04:29.680 --> 00:04:31.080]   We're going to have to figure out-- we'll get--
[00:04:31.080 --> 00:04:31.600]   we'll get it.
[00:04:31.600 --> 00:04:32.360]   --one every 10 minutes.
[00:04:32.360 --> 00:04:33.520]   This is a sleeping bag.
[00:04:33.520 --> 00:04:34.920]   That's right.
[00:04:34.920 --> 00:04:37.520]   They call it-- I think it's big glue.
[00:04:37.520 --> 00:04:38.440]   Big glue?
[00:04:38.440 --> 00:04:39.440]   Like big igloo.
[00:04:39.440 --> 00:04:39.960]   Big glue.
[00:04:39.960 --> 00:04:42.680]   It uses that aerogel stuff that I've always
[00:04:42.680 --> 00:04:43.560]   wanted to play with.
[00:04:43.560 --> 00:04:45.280]   It's super light.
[00:04:45.280 --> 00:04:46.040]   And it's great light.
[00:04:46.040 --> 00:04:47.480]   It's rated for minus 40 degrees.
[00:04:47.480 --> 00:04:49.080]   Oh, for this size sleeping bag, that's a bae.
[00:04:49.080 --> 00:04:49.960]   It's a mummy bag.
[00:04:49.960 --> 00:04:52.680]   So when you take that trip down to Antarctica--
[00:04:52.680 --> 00:04:53.040]   That's a big thing.
[00:04:53.040 --> 00:04:54.040]   I'm bringing my--
[00:04:54.040 --> 00:04:54.680]   What is it called?
[00:04:54.680 --> 00:04:57.240]   Big glue.
[00:04:57.240 --> 00:04:59.080]   I think in between each ad, read Leo,
[00:04:59.080 --> 00:05:02.480]   you've got to just like zip yourself up 25% more.
[00:05:02.480 --> 00:05:04.240]   By the end, it's just going to be your eyes.
[00:05:04.240 --> 00:05:05.520]   Sweat and bullets.
[00:05:05.520 --> 00:05:08.200]   But we were torn between doing that
[00:05:08.200 --> 00:05:11.160]   or taking this Merkel, which is designed
[00:05:11.160 --> 00:05:13.840]   for people who are about to drink heavily.
[00:05:13.840 --> 00:05:14.480]   Yep.
[00:05:14.480 --> 00:05:16.360]   And then having a shot every five minutes.
[00:05:16.360 --> 00:05:18.200]   It keeps your body supposedly.
[00:05:18.200 --> 00:05:20.320]   It keeps your body from absorbing that alcohol
[00:05:20.320 --> 00:05:22.080]   so you can get as torn as you want to
[00:05:22.080 --> 00:05:24.000]   without having the hangover.
[00:05:24.000 --> 00:05:26.360]   It's got electrolytes.
[00:05:26.360 --> 00:05:28.840]   It's what a body needs.
[00:05:28.840 --> 00:05:32.560]   She's inside the big glue.
[00:05:32.560 --> 00:05:34.480]   If you go to the white shot--
[00:05:34.480 --> 00:05:35.440]   Who's in the big?
[00:05:35.440 --> 00:05:36.160]   Oh, sorry.
[00:05:36.160 --> 00:05:36.680]   Oh, no.
[00:05:36.680 --> 00:05:37.920]   In the big glue.
[00:05:37.920 --> 00:05:38.440]   Sorry, Connie.
[00:05:38.440 --> 00:05:40.000]   That's going to be really warm, Connie.
[00:05:40.000 --> 00:05:41.920]   Is it B-I-G-L-O-U?
[00:05:41.920 --> 00:05:44.480]   It's B-I-I-G-L-O-O.
[00:05:44.480 --> 00:05:45.000]   Big glue.
[00:05:45.000 --> 00:05:46.800]   Big glue.
[00:05:46.800 --> 00:05:49.520]   Big glue.
[00:05:49.520 --> 00:05:52.360]   All right, put Big glue under the table for a bit.
[00:05:52.360 --> 00:05:54.680]   You never got the CES swag.
[00:05:54.680 --> 00:05:56.240]   I mean, that really is part of the fall.
[00:05:56.240 --> 00:05:58.400]   Seriously.
[00:05:58.400 --> 00:06:00.800]   I would get a lot of press releases.
[00:06:00.800 --> 00:06:02.080]   No, those go straight.
[00:06:02.080 --> 00:06:03.080]   They would never give me--
[00:06:03.080 --> 00:06:04.720]   The press releases are the opposite of swag.
[00:06:04.720 --> 00:06:06.120]   Yeah.
[00:06:06.120 --> 00:06:07.880]   You know, I was talking about this last week
[00:06:07.880 --> 00:06:09.920]   when Stacy was like, she was just back from CES.
[00:06:09.920 --> 00:06:13.120]   She used to be at CES in the main lobby there.
[00:06:13.120 --> 00:06:17.720]   There'd be a FedEx booth that would ship everything back for you.
[00:06:17.720 --> 00:06:19.920]   I have a feeling you carried this on.
[00:06:19.920 --> 00:06:24.800]   Well, yes, because 90% of that they didn't give it to me
[00:06:24.800 --> 00:06:27.240]   because I told them, please just ship it.
[00:06:27.240 --> 00:06:29.600]   Oh, so they shipped it to Rome.
[00:06:29.600 --> 00:06:32.960]   But these, I actually wanted to play with while I was
[00:06:32.960 --> 00:06:34.920]   in the United States.
[00:06:34.920 --> 00:06:38.720]   So I'm thinking-- Somewhere the Pope is receiving a VR headset.
[00:06:38.720 --> 00:06:39.720]   This.
[00:06:39.720 --> 00:06:41.120]   I don't know.
[00:06:41.120 --> 00:06:43.120]   Yeah, so half the stuff I sent to the Vatican,
[00:06:43.120 --> 00:06:44.120]   the Pope just takes.
[00:06:44.120 --> 00:06:45.120]   Like he's got a seven.
[00:06:45.120 --> 00:06:46.120]   No.
[00:06:46.120 --> 00:06:47.320]   He's got some VR goggles right now.
[00:06:47.320 --> 00:06:48.720]   He's got some great gaming laptops.
[00:06:48.720 --> 00:06:49.720]   Has he has the-- The Holy Father,
[00:06:49.720 --> 00:06:51.040]   has he ever played any VR games?
[00:06:51.040 --> 00:06:53.320]   Oh, he's really big in the cod.
[00:06:53.320 --> 00:06:54.720]   Call of duty.
[00:06:54.720 --> 00:06:58.400]   He's just sniping all the nautical levers.
[00:06:58.400 --> 00:07:00.120]   He only uses his knife.
[00:07:00.120 --> 00:07:01.200]   He just sneaks up on people.
[00:07:01.200 --> 00:07:02.520]   Oh, yeah, he's one of them.
[00:07:02.520 --> 00:07:03.360]   Very skilled.
[00:07:03.360 --> 00:07:05.240]   He's one of them.
[00:07:05.240 --> 00:07:07.600]   Does the Pope have an RTX 4090?
[00:07:07.600 --> 00:07:11.200]   Oh, I mean, no, he's got the next version, of course.
[00:07:11.200 --> 00:07:12.720]   So why shoes?
[00:07:12.720 --> 00:07:16.680]   OK, this is bothering people because there's shoes on our table.
[00:07:16.680 --> 00:07:17.440]   But they're clean.
[00:07:17.440 --> 00:07:18.440]   They've never been worn.
[00:07:18.440 --> 00:07:19.800]   Yeah, these have never been worn.
[00:07:19.800 --> 00:07:20.840]   The kizix.
[00:07:20.840 --> 00:07:23.000]   Now, last year, they sent me a pair
[00:07:23.000 --> 00:07:24.480]   and I thought this is going to be a joke.
[00:07:24.480 --> 00:07:27.640]   Why are you sending me shoes at a tech conference?
[00:07:27.640 --> 00:07:30.240]   But these are the-- you can just step into them.
[00:07:30.240 --> 00:07:31.120]   But they're not slip-ons.
[00:07:31.120 --> 00:07:32.720]   That's how most shoes work.
[00:07:32.720 --> 00:07:35.000]   No, no, but I mean, if you get--
[00:07:35.000 --> 00:07:35.720]   that's what I said.
[00:07:35.720 --> 00:07:39.920]   I've seen slip-ons before, except these are crazy comfortable.
[00:07:39.920 --> 00:07:43.520]   It's almost as if they remold your foot after you put your foot in.
[00:07:43.520 --> 00:07:44.640]   Is it his aerogel?
[00:07:44.640 --> 00:07:46.920]   No, no, but I mean, and they're crazy comfortable.
[00:07:46.920 --> 00:07:48.640]   No, thank goodness we have a space program
[00:07:48.640 --> 00:07:51.960]   so we can get shoes and big glues.
[00:07:51.960 --> 00:07:54.920]   Because otherwise, what would we do?
[00:07:54.920 --> 00:07:58.560]   These are-- so you wear like Birkenstocks.
[00:07:58.560 --> 00:08:00.920]   No, I actually wear a pair of black kizix.
[00:08:00.920 --> 00:08:01.320]   Really?
[00:08:01.320 --> 00:08:04.000]   My cats, my feral cats, have had the entire year
[00:08:04.000 --> 00:08:05.000]   to tear them up.
[00:08:05.000 --> 00:08:05.560]   The Vatican.
[00:08:05.560 --> 00:08:06.480]   And they still look fine.
[00:08:06.480 --> 00:08:07.240]   The Vatican.
[00:08:07.240 --> 00:08:09.040]   All right, well, the only reason I brought this one up
[00:08:09.040 --> 00:08:11.040]   is so I could take this off the table.
[00:08:11.040 --> 00:08:12.480]   Because it's disturbing people.
[00:08:12.480 --> 00:08:13.760]   I don't want to bother you.
[00:08:13.760 --> 00:08:14.920]   It is pretty upset.
[00:08:14.920 --> 00:08:16.280]   Connie, you've seen it--
[00:08:16.280 --> 00:08:21.200]   normally has a very big presence at CES, a big studio,
[00:08:21.200 --> 00:08:22.800]   and you do a lot of live programming and stuff.
[00:08:22.800 --> 00:08:24.760]   Not this year, though.
[00:08:24.760 --> 00:08:27.800]   No, this year was our first year back in person
[00:08:27.800 --> 00:08:29.520]   since the pandemic.
[00:08:29.520 --> 00:08:31.440]   And like everyone else, we were wanting
[00:08:31.440 --> 00:08:33.280]   to see what it was going to be about.
[00:08:33.280 --> 00:08:36.360]   And if there was going to be the same energy and momentum
[00:08:36.360 --> 00:08:38.240]   that you've seen in years past.
[00:08:38.240 --> 00:08:41.520]   And so we decided to send a very small crew.
[00:08:41.520 --> 00:08:43.560]   And I would say that was the right call.
[00:08:43.560 --> 00:08:46.040]   It was-- there were some announcements.
[00:08:46.040 --> 00:08:47.680]   And as always, there's crazy stuff
[00:08:47.680 --> 00:08:49.160]   that people write about--
[00:08:49.160 --> 00:08:55.200]   smart toilets and cars with all kinds of new camouflage gear
[00:08:55.200 --> 00:08:55.840]   and what have you.
[00:08:55.840 --> 00:09:00.760]   But generally speaking, it was a year of people just sort
[00:09:00.760 --> 00:09:06.160]   of getting back to it versus, you know, I think one of these years
[00:09:06.160 --> 00:09:08.000]   that it's going to go down in history as a moment.
[00:09:08.000 --> 00:09:09.360]   That's something amazing was introduced.
[00:09:09.360 --> 00:09:12.120]   There was no historic moments at CES this year.
[00:09:12.120 --> 00:09:13.640]   No, there was some interesting news.
[00:09:13.640 --> 00:09:17.280]   But Connie hit it right on the head, which was last year.
[00:09:17.280 --> 00:09:19.280]   Technically CES was back.
[00:09:19.280 --> 00:09:21.280]   But no, it was the COVID show.
[00:09:21.280 --> 00:09:25.840]   You had boots like LG that just had the outline of the booth
[00:09:25.840 --> 00:09:26.520]   on the floor.
[00:09:26.520 --> 00:09:28.120]   They didn't bring anybody.
[00:09:28.120 --> 00:09:29.440]   Sony brought no TVs.
[00:09:29.440 --> 00:09:30.440]   They just did a car.
[00:09:30.440 --> 00:09:31.440]   Right, right.
[00:09:31.440 --> 00:09:33.320]   This year, it felt like a CES.
[00:09:33.320 --> 00:09:35.640]   It wasn't like the full on CES where
[00:09:35.640 --> 00:09:37.240]   you were going to get some amazing announcements.
[00:09:37.240 --> 00:09:39.280]   But there were enough vendors there.
[00:09:39.280 --> 00:09:41.080]   They had spread into the West Hall
[00:09:41.080 --> 00:09:43.440]   that it kind of gave you that feeling of, OK, yeah,
[00:09:43.440 --> 00:09:44.320]   this is a CES.
[00:09:44.320 --> 00:09:46.200]   This is like an off-year CES.
[00:09:46.200 --> 00:09:50.000]   But it's still a CES versus last year, which was proof of concept
[00:09:50.000 --> 00:09:52.800]   that we can do this without having 100,000 infections.
[00:09:52.800 --> 00:09:56.760]   115,000 people showed up, which was actually a lot.
[00:09:56.760 --> 00:10:00.120]   Normal some years ago, it would have been 180,000.
[00:10:00.120 --> 00:10:01.440]   Did it feel crowded, Connie?
[00:10:01.440 --> 00:10:03.240]   Or was it kind of sparse?
[00:10:03.240 --> 00:10:05.520]   No, I mean, I think it felt pretty light.
[00:10:05.520 --> 00:10:08.880]   And the fact that the two of us didn't get sick, I don't know.
[00:10:08.880 --> 00:10:09.720]   That's amazing.
[00:10:09.720 --> 00:10:12.280]   Both of us wearing masks and maybe spraying everyone
[00:10:12.280 --> 00:10:14.120]   with anti-bacterial spray.
[00:10:14.120 --> 00:10:19.760]   But it felt like people were curious to see what was going on.
[00:10:19.760 --> 00:10:22.520]   And I think there's pent up interest in people traveling again
[00:10:22.520 --> 00:10:24.120]   and wanting to go to shows.
[00:10:24.120 --> 00:10:28.640]   But again, I don't think there was Schwartz and Ager spoke.
[00:10:28.640 --> 00:10:32.040]   What was Arnold there for?
[00:10:32.040 --> 00:10:33.840]   He was talking about--
[00:10:33.840 --> 00:10:35.200]   gosh, I can't even remember it.
[00:10:35.200 --> 00:10:36.320]   Look, that's not even that many.
[00:10:36.320 --> 00:10:39.320]   The very memorable Arnold Schwartz and Ager
[00:10:39.320 --> 00:10:43.160]   was talking about Jerry Mandling or something.
[00:10:43.160 --> 00:10:45.480]   No, he was looking at the next generation
[00:10:45.480 --> 00:10:49.080]   of a quadcopter transportation devices,
[00:10:49.080 --> 00:10:50.840]   just so he could say, get to the choppa.
[00:10:50.840 --> 00:10:52.240]   Get to the choppa.
[00:10:52.240 --> 00:10:52.740]   Sorry.
[00:10:52.740 --> 00:10:54.240]   That was a long way to go.
[00:10:54.240 --> 00:10:55.240]   That was a long way to go.
[00:10:55.240 --> 00:10:56.240]   A long walk.
[00:10:56.240 --> 00:10:57.880]   A long walk.
[00:10:57.880 --> 00:10:59.480]   I apologize.
[00:10:59.480 --> 00:11:02.960]   When was the last time you guys remember that CES really
[00:11:02.960 --> 00:11:03.680]   wowed you?
[00:11:03.680 --> 00:11:04.480]   Yeah, there's the concert.
[00:11:04.480 --> 00:11:06.560]   Or had something that was worth being at.
[00:11:06.560 --> 00:11:07.760]   Yeah.
[00:11:07.760 --> 00:11:10.280]   The Walkman was pretty awesome.
[00:11:10.280 --> 00:11:11.960]   No, there's a new Walkman.
[00:11:11.960 --> 00:11:14.480]   There's a new West Red Sony has a new Walkman.
[00:11:14.480 --> 00:11:18.440]   People on TikTok, the Gen Z is really into Walkman.
[00:11:18.440 --> 00:11:19.080]   Right?
[00:11:19.080 --> 00:11:20.360]   I don't get that.
[00:11:20.360 --> 00:11:22.320]   Don't you have a phone?
[00:11:22.320 --> 00:11:23.600]   But it's a Walkman.
[00:11:23.600 --> 00:11:24.880]   I mean, they're back in--
[00:11:24.880 --> 00:11:25.720]   They want experience.
[00:11:25.720 --> 00:11:26.600]   So it's an nostalgia?
[00:11:26.600 --> 00:11:27.240]   No, it's not.
[00:11:27.240 --> 00:11:28.720]   You can do everything on your phone,
[00:11:28.720 --> 00:11:30.280]   but isn't it more fun to have the point?
[00:11:30.280 --> 00:11:31.280]   That's the point.
[00:11:31.280 --> 00:11:35.760]   It sounds like something some TWE 20 something
[00:11:35.760 --> 00:11:37.240]   in Brooklyn would want it.
[00:11:37.240 --> 00:11:37.720]   That's true.
[00:11:37.720 --> 00:11:38.440]   I'm sorry, Paris.
[00:11:38.440 --> 00:11:39.800]   I don't know what you're talking about.
[00:11:39.800 --> 00:11:43.360]   [LAUGHTER]
[00:11:43.360 --> 00:11:47.120]   There was a TV that attaches--
[00:11:47.120 --> 00:11:49.760]   there were a number of wireless TVs.
[00:11:49.760 --> 00:11:55.160]   There was one, and I see a CNET story about it, a wireless TV
[00:11:55.160 --> 00:11:59.200]   that attaches to the wall with suction cups.
[00:11:59.200 --> 00:12:02.360]   What could possibly go wrong as we all know?
[00:12:02.360 --> 00:12:06.000]   Well, in fact, it turns out if the battery dies,
[00:12:06.000 --> 00:12:07.240]   TV falls off the wall.
[00:12:07.240 --> 00:12:08.640]   The wall!
[00:12:08.640 --> 00:12:09.360]   That's a--
[00:12:09.360 --> 00:12:13.000]   TV falls off the wall.
[00:12:13.000 --> 00:12:15.600]   So I'm not sure I really want this.
[00:12:15.600 --> 00:12:18.440]   LG had that TV that they brought out either last year
[00:12:18.440 --> 00:12:21.840]   or the year of the pandemic that rolls up and down.
[00:12:21.840 --> 00:12:23.720]   So they keep showing that every year.
[00:12:23.720 --> 00:12:25.080]   It's $100,000.
[00:12:25.080 --> 00:12:26.440]   It is expensive.
[00:12:26.440 --> 00:12:26.880]   Yeah.
[00:12:26.880 --> 00:12:27.920]   They finally are shipping.
[00:12:27.920 --> 00:12:29.160]   Yeah, that's--
[00:12:29.160 --> 00:12:30.320]   Oof.
[00:12:30.320 --> 00:12:33.600]   Oh, how about the lightyear car?
[00:12:33.600 --> 00:12:34.840]   Buzz lightyear?
[00:12:34.840 --> 00:12:36.000]   It was from a French company.
[00:12:36.000 --> 00:12:39.760]   They made an all-electric vehicle, super aerodynamic.
[00:12:39.760 --> 00:12:44.520]   It can get 47 miles just off the charge on the solar panels,
[00:12:44.520 --> 00:12:46.040]   the integrated solar panels of the car.
[00:12:46.040 --> 00:12:47.880]   And then you have to park it for four days.
[00:12:47.880 --> 00:12:48.480]   Well, no.
[00:12:48.480 --> 00:12:50.720]   So every day, 47 miles of range.
[00:12:50.720 --> 00:12:52.720]   And then you could plug it in for a full range.
[00:12:52.720 --> 00:12:55.880]   And it only costs $300,000.
[00:12:55.880 --> 00:12:56.800]   Oh, wow.
[00:12:56.800 --> 00:12:57.640]   It's bargain.
[00:12:57.640 --> 00:12:59.000]   I think all the money will save.
[00:12:59.000 --> 00:13:01.840]   I too?
[00:13:01.840 --> 00:13:04.960]   Yeah, I have to think that--
[00:13:04.960 --> 00:13:06.840]   so Connie, you think it will-- it's just--
[00:13:06.840 --> 00:13:08.520]   this is the year after the pandemic.
[00:13:08.520 --> 00:13:10.240]   And it will come back.
[00:13:10.240 --> 00:13:12.360]   Or I'm starting to think--
[00:13:12.360 --> 00:13:13.720]   I've been thinking this for some years--
[00:13:13.720 --> 00:13:17.080]   that big companies like Sony just say,
[00:13:17.080 --> 00:13:19.160]   we don't need this to show new products.
[00:13:19.160 --> 00:13:22.360]   We have our own way of doing that with our own line
[00:13:22.360 --> 00:13:24.320]   shows or whatever.
[00:13:24.320 --> 00:13:25.960]   Well, I mean, certainly you saw that
[00:13:25.960 --> 00:13:27.240]   happen during the pandemic.
[00:13:27.240 --> 00:13:29.760]   Apple can always have whatever event it wants.
[00:13:29.760 --> 00:13:31.240]   And it doesn't need to have it in person
[00:13:31.240 --> 00:13:32.640]   to get everyone to pay attention.
[00:13:32.640 --> 00:13:36.600]   But I would say your question about is CES back,
[00:13:36.600 --> 00:13:38.800]   and what's the most interesting stuff?
[00:13:38.800 --> 00:13:40.680]   CES is about those crazy products
[00:13:40.680 --> 00:13:41.640]   that you were talking about--
[00:13:41.640 --> 00:13:43.000]   million dollar flying car.
[00:13:43.000 --> 00:13:44.520]   That was another one.
[00:13:44.520 --> 00:13:47.600]   But that's not really what I go to the show to see.
[00:13:47.600 --> 00:13:49.920]   I go and see what some of the themes are
[00:13:49.920 --> 00:13:52.560]   that lots of people are glomming on to.
[00:13:52.560 --> 00:13:57.160]   And a couple of years ago, it was voice-activated assistants.
[00:13:57.160 --> 00:14:01.960]   You had Alexa in everything, like light switches and--
[00:14:01.960 --> 00:14:03.800]   How does that work out?
[00:14:03.800 --> 00:14:05.200]   People were laughing about it.
[00:14:05.200 --> 00:14:06.200]   I am happy that's it.
[00:14:06.200 --> 00:14:07.560]   But you're also voice activation and everything.
[00:14:07.560 --> 00:14:08.680]   Yeah.
[00:14:08.680 --> 00:14:12.000]   This year, we saw lots of themes around sustainability,
[00:14:12.000 --> 00:14:16.000]   people talking about using solar and having things not just
[00:14:16.000 --> 00:14:17.480]   being made with green tech.
[00:14:17.480 --> 00:14:18.720]   That's kind of at the low end.
[00:14:18.720 --> 00:14:22.280]   It's about building some intelligence into these devices
[00:14:22.280 --> 00:14:24.400]   so you can see how much energy they use,
[00:14:24.400 --> 00:14:27.080]   so that you can make it a call about whether you want
[00:14:27.080 --> 00:14:30.000]   to invest in that device or not.
[00:14:30.000 --> 00:14:32.480]   Wireless charging.
[00:14:32.480 --> 00:14:35.240]   That's always something that people want as an interest.
[00:14:35.240 --> 00:14:37.600]   How much of that sustainability stuff do you think
[00:14:37.600 --> 00:14:41.200]   is just marketing, like jumping on the bandwagon,
[00:14:41.200 --> 00:14:43.640]   and how much of it is actually legitimate?
[00:14:43.640 --> 00:14:45.280]   My concern is a lot of this stuff at CES
[00:14:45.280 --> 00:14:47.280]   will never see the way today.
[00:14:47.280 --> 00:14:48.800]   Well, you're absolutely right.
[00:14:48.800 --> 00:14:52.440]   A lot of the stuff we see as we'll never see the light of day.
[00:14:52.440 --> 00:14:54.040]   I mean, in Berkeley, California now,
[00:14:54.040 --> 00:14:58.320]   the city has asked that all sorts of green technology
[00:14:58.320 --> 00:14:59.880]   be built into new construction.
[00:14:59.880 --> 00:15:02.000]   So it's going to be solved.
[00:15:02.000 --> 00:15:02.920]   There is a business.
[00:15:02.920 --> 00:15:06.840]   Some of these questions about sustainability and green
[00:15:06.840 --> 00:15:12.600]   and mitigating climate will be mandatory through legislation.
[00:15:12.600 --> 00:15:15.200]   And so there will be a market of interest there.
[00:15:15.200 --> 00:15:17.720]   I know people in California are interested in solar.
[00:15:17.720 --> 00:15:21.280]   I just put in a solar system while there are federal subsidies
[00:15:21.280 --> 00:15:25.880]   in place, and while our local utility PG&E,
[00:15:25.880 --> 00:15:27.560]   it's grandfothering in.
[00:15:27.560 --> 00:15:30.240]   If you do it before April, a certain rate reimbursement
[00:15:30.240 --> 00:15:33.480]   that will go dramatically down starting in April.
[00:15:33.480 --> 00:15:35.640]   For those of you who want to follow the Public Utility
[00:15:35.640 --> 00:15:37.240]   Commission in California, like I do.
[00:15:37.240 --> 00:15:39.120]   Boy, I'm going to really hurt it.
[00:15:39.120 --> 00:15:41.560]   I didn't know that, yeah.
[00:15:41.560 --> 00:15:43.120]   It's going to hurt solar adoption,
[00:15:43.120 --> 00:15:45.720]   but there's interest in all those things.
[00:15:45.720 --> 00:15:47.920]   It's about what consumers want to do, right?
[00:15:47.920 --> 00:15:50.080]   It's where they want to spend their money.
[00:15:50.080 --> 00:15:54.280]   And if you ask someone, do you want to make the right choice,
[00:15:54.280 --> 00:15:55.720]   and would you spend more on something?
[00:15:55.720 --> 00:15:56.920]   That was better for the environment.
[00:15:56.920 --> 00:15:58.880]   They'll say, yeah, but they don't put their dollars on it.
[00:15:58.880 --> 00:15:59.560]   But do they?
[00:15:59.560 --> 00:16:00.080]   Yeah.
[00:16:00.080 --> 00:16:00.640]   They don't.
[00:16:00.640 --> 00:16:01.960]   We haven't seen that yet.
[00:16:01.960 --> 00:16:02.800]   But that could be true.
[00:16:02.800 --> 00:16:04.720]   To some degree, just like you're going there
[00:16:04.720 --> 00:16:06.040]   to put your finger to the wind, that's
[00:16:06.040 --> 00:16:08.000]   what manufacturers are doing as well.
[00:16:08.000 --> 00:16:11.000]   They're saying, well, what if we made this?
[00:16:11.000 --> 00:16:13.080]   What if we made Merkel?
[00:16:13.080 --> 00:16:14.680]   Would you buy it?
[00:16:14.680 --> 00:16:17.720]   And they're getting some gauge of interest
[00:16:17.720 --> 00:16:20.000]   before many of these things, before they even get made.
[00:16:20.000 --> 00:16:23.480]   What does this-- this looks like you bought a magic wand.
[00:16:23.480 --> 00:16:24.000]   No, that was--
[00:16:24.000 --> 00:16:24.440]   Wait a minute, don't tell me.
[00:16:24.440 --> 00:16:25.040]   Is there something--
[00:16:25.040 --> 00:16:26.440]   Yeah, no, can you figure it out?
[00:16:26.440 --> 00:16:28.680]   Can you figure out what that is?
[00:16:28.680 --> 00:16:30.040]   This looks like a wand.
[00:16:30.040 --> 00:16:31.040]   It's metal.
[00:16:31.040 --> 00:16:35.200]   It has a grommet at one end and a little plastic thing
[00:16:35.200 --> 00:16:35.600]   at the other.
[00:16:35.600 --> 00:16:36.920]   Don't say Ava Kadavra.
[00:16:36.920 --> 00:16:38.880]   Ava Kadavra.
[00:16:38.880 --> 00:16:40.400]   No, I just killed John.
[00:16:40.400 --> 00:16:40.960]   Whoa!
[00:16:40.960 --> 00:16:41.960]   Some of it's me.
[00:16:41.960 --> 00:16:42.400]   Hold on.
[00:16:42.400 --> 00:16:42.880]   Wait.
[00:16:42.880 --> 00:16:45.400]   Oh, it's a bottle washer.
[00:16:45.400 --> 00:16:46.400]   Wow.
[00:16:46.400 --> 00:16:46.400]   Wow.
[00:16:46.400 --> 00:16:49.120]   That's 20-first century technology.
[00:16:49.120 --> 00:16:55.320]   This is a modern blowpipe for the sanitation focused--
[00:16:55.320 --> 00:16:55.960]   Pig me.
[00:16:55.960 --> 00:16:58.000]   I mean, you're like part of the way there.
[00:16:58.000 --> 00:17:00.080]   This has a plastic mouthpiece.
[00:17:00.080 --> 00:17:01.000]   So is it a straw?
[00:17:01.000 --> 00:17:02.080]   It's a straw.
[00:17:02.080 --> 00:17:02.960]   Thank you.
[00:17:02.960 --> 00:17:04.680]   It's a super high tech straw.
[00:17:04.680 --> 00:17:05.680]   I just put my mouth on it.
[00:17:05.680 --> 00:17:06.400]   You know what I want.
[00:17:06.400 --> 00:17:07.400]   Well, that's what the piping is for.
[00:17:07.400 --> 00:17:09.880]   Super high tech.
[00:17:09.880 --> 00:17:11.040]   It's a straw.
[00:17:11.040 --> 00:17:12.600]   It's a metal straw.
[00:17:12.600 --> 00:17:13.600]   OK.
[00:17:13.600 --> 00:17:15.320]   It takes them a sustainability booth.
[00:17:15.320 --> 00:17:16.760]   But that's sustainability, right?
[00:17:16.760 --> 00:17:17.560]   That's what that's all about.
[00:17:17.560 --> 00:17:18.640]   That's what we were told.
[00:17:18.640 --> 00:17:21.600]   No plastics in the water.
[00:17:21.600 --> 00:17:24.320]   Except for the one on the mouthpiece, right?
[00:17:24.320 --> 00:17:25.840]   No, that's actually silicone.
[00:17:25.840 --> 00:17:27.800]   You know, because these are the clean.
[00:17:27.800 --> 00:17:29.560]   Ah, that's in Merkel.
[00:17:29.560 --> 00:17:31.560]   That's--
[00:17:31.560 --> 00:17:34.440]   That's actually the proper way to shoot a Merkel pill.
[00:17:34.440 --> 00:17:36.760]   You've got to put it the end of that straw.
[00:17:36.760 --> 00:17:38.200]   You know.
[00:17:38.200 --> 00:17:41.240]   Actually, that looks pretty good.
[00:17:41.240 --> 00:17:43.240]   You need a monocle.
[00:17:43.240 --> 00:17:44.240]   You do.
[00:17:44.240 --> 00:17:45.960]   One can be a--
[00:17:45.960 --> 00:17:50.880]   Whatever I'm in town, I use Merkel before I go out and drink.
[00:17:50.880 --> 00:17:51.680]   All right.
[00:17:51.680 --> 00:17:53.000]   You and the court man about town.
[00:17:53.000 --> 00:17:53.480]   Fine.
[00:17:53.480 --> 00:17:56.560]   That's-- that is very, very exciting.
[00:17:56.560 --> 00:18:01.040]   I mean, CES has been over now a week.
[00:18:01.040 --> 00:18:02.800]   Paris and I are going, wow.
[00:18:02.800 --> 00:18:04.800]   We really-- we merely missed a gym.
[00:18:04.800 --> 00:18:05.800]   You could have had a little--
[00:18:05.800 --> 00:18:09.720]   Just saying that's very exciting in a dry voice
[00:18:09.720 --> 00:18:11.040]   is how I feel about all of this.
[00:18:11.040 --> 00:18:12.040]   Yeah, that's it.
[00:18:12.040 --> 00:18:13.040]   That's it.
[00:18:13.040 --> 00:18:15.040]   Just absolutely no excitement, no levels.
[00:18:15.040 --> 00:18:17.200]   You know, Father Robert has a bunch of crap
[00:18:17.200 --> 00:18:19.400]   in the Padre shopping network.
[00:18:19.400 --> 00:18:20.800]   Show us one thing that we're going to go,
[00:18:20.800 --> 00:18:21.760]   oh, that's pretty good.
[00:18:21.760 --> 00:18:23.360]   I would use that.
[00:18:23.360 --> 00:18:24.360]   OK.
[00:18:24.360 --> 00:18:25.800]   I got to do this.
[00:18:25.800 --> 00:18:26.800]   OK.
[00:18:26.800 --> 00:18:28.360]   This is the iron team.
[00:18:28.360 --> 00:18:29.360]   Iron team.
[00:18:29.360 --> 00:18:30.360]   Iron team.
[00:18:30.360 --> 00:18:31.360]   This is their vault.
[00:18:31.360 --> 00:18:34.160]   So the whole idea is it's an encrypted SSD.
[00:18:34.160 --> 00:18:35.160]   So it's crazy fast.
[00:18:35.160 --> 00:18:37.400]   250 megabytes per second, either way.
[00:18:37.400 --> 00:18:38.400]   Solid state.
[00:18:38.400 --> 00:18:39.400]   Solid state drive.
[00:18:39.400 --> 00:18:40.400]   It's external.
[00:18:40.400 --> 00:18:41.400]   It's got its own encryption engine.
[00:18:41.400 --> 00:18:42.400]   Or is it Thunderbolt?
[00:18:42.400 --> 00:18:43.400]   Is it Thunderbolt?
[00:18:43.400 --> 00:18:44.400]   No, it's USB-C.
[00:18:44.400 --> 00:18:45.400]   It's USB-C.
[00:18:45.400 --> 00:18:46.400]   It's got its own encryption engine.
[00:18:46.400 --> 00:18:47.760]   So that speeds the throughput.
[00:18:47.760 --> 00:18:49.640]   But it also has, and this is something that's
[00:18:49.640 --> 00:18:51.840]   I'm really geeky about.
[00:18:51.840 --> 00:18:53.040]   Do you remember Bad USB?
[00:18:53.040 --> 00:18:58.160]   Yeah, that was a very nasty infection that you could get
[00:18:58.160 --> 00:18:59.960]   from going to trade shows.
[00:18:59.960 --> 00:19:01.680]   No, from Bad People.
[00:19:01.680 --> 00:19:02.680]   Actually, yes.
[00:19:02.680 --> 00:19:03.680]   From Candy Drops.
[00:19:03.680 --> 00:19:04.680]   That would be a really good place.
[00:19:04.680 --> 00:19:08.920]   So yeah, Bad USB infected the firmware of a USB device.
[00:19:08.920 --> 00:19:09.920]   Right.
[00:19:09.920 --> 00:19:12.520]   And then it would be Bad USB device.
[00:19:12.520 --> 00:19:14.200]   It'd be a bad USB because now we're here.
[00:19:14.200 --> 00:19:15.480]   There's no way to find it.
[00:19:15.480 --> 00:19:16.480]   Right.
[00:19:16.480 --> 00:19:19.160]   Because the firmware is responsible for reporting on the health of the device.
[00:19:19.160 --> 00:19:20.160]   Right.
[00:19:20.160 --> 00:19:23.480]   So if someone can install something into the firmware, you could forever have a compromised
[00:19:23.480 --> 00:19:24.480]   device.
[00:19:24.480 --> 00:19:27.320]   They've included a piece of hardware.
[00:19:27.320 --> 00:19:32.160]   It's hard-coded that checks the signature of the firmware every time the device turns
[00:19:32.160 --> 00:19:33.160]   on.
[00:19:33.160 --> 00:19:34.160]   Right.
[00:19:34.160 --> 00:19:36.280]   And it will not allow it to continue if it doesn't hit the check.
[00:19:36.280 --> 00:19:39.280]   So it kind of like Secure Boot on a Windows machine or the Chromebook.
[00:19:39.280 --> 00:19:40.280]   Right.
[00:19:40.280 --> 00:19:41.280]   Right.
[00:19:41.280 --> 00:19:42.280]   Wow, that's kind of cool.
[00:19:42.280 --> 00:19:43.280]   So I mean, it's how much?
[00:19:43.280 --> 00:19:44.280]   This is from Kingston.
[00:19:44.280 --> 00:19:45.280]   This is from Kingston.
[00:19:45.280 --> 00:19:47.920]   And they've got 480, they've got 960 gigabyte versions.
[00:19:47.920 --> 00:19:50.760]   Is it much more expensive because of the special?
[00:19:50.760 --> 00:19:52.920]   And it's got an LCD screen in there.
[00:19:52.920 --> 00:19:53.920]   Yeah.
[00:19:53.920 --> 00:19:55.960]   So this actually, when you powered up, it's got the interface.
[00:19:55.960 --> 00:19:58.680]   So you can set a password to encrypt it.
[00:19:58.680 --> 00:19:59.680]   You can set guests.
[00:19:59.680 --> 00:20:01.600]   I think I saw this like a James Bond.
[00:20:01.600 --> 00:20:03.120]   Yeah, it's kind of like that.
[00:20:03.120 --> 00:20:08.160]   But something you would like though, the password, you can set it so that the keyboard
[00:20:08.160 --> 00:20:12.040]   randomizes so that someone can't get your password just from looking away.
[00:20:12.040 --> 00:20:13.040]   You're pressing.
[00:20:13.040 --> 00:20:14.040]   Oh, yeah.
[00:20:14.040 --> 00:20:16.080]   Instead of one, two, three, four, five, six, seven, eight, nine, it's one, seven, three,
[00:20:16.080 --> 00:20:17.080]   four, nine, two, exactly.
[00:20:17.080 --> 00:20:18.720]   And it just changes every single time.
[00:20:18.720 --> 00:20:19.720]   That's a good idea.
[00:20:19.720 --> 00:20:21.680]   And otherwise you could see the fingerprints.
[00:20:21.680 --> 00:20:22.680]   Right.
[00:20:22.680 --> 00:20:23.680]   On these things.
[00:20:23.680 --> 00:20:24.680]   But you can do per user.
[00:20:24.680 --> 00:20:27.840]   So you can you can have the administrative user and then per users.
[00:20:27.840 --> 00:20:32.000]   And once they hit a certain number of attempts, it just locks a device.
[00:20:32.000 --> 00:20:33.000]   Oh, that's cool.
[00:20:33.000 --> 00:20:34.000]   Yeah.
[00:20:34.000 --> 00:20:35.000]   Yeah.
[00:20:35.000 --> 00:20:36.800]   I think that these kinds of things make a lot of sense.
[00:20:36.800 --> 00:20:38.560]   What is practical to me?
[00:20:38.560 --> 00:20:44.760]   Because I do travel a lot to places where our data is in demand.
[00:20:44.760 --> 00:20:50.520]   What happens when you get to the US border and the guy says, can you unlock your, yes,
[00:20:50.520 --> 00:20:54.800]   you use, you use one of the client IDs that has just innocuous information.
[00:20:54.800 --> 00:20:56.880]   You have plausible deniability function.
[00:20:56.880 --> 00:20:57.880]   There's stuff there.
[00:20:57.880 --> 00:20:58.880]   It's just nothing you want.
[00:20:58.880 --> 00:20:59.880]   It's really good.
[00:20:59.880 --> 00:21:00.880]   That's smart.
[00:21:00.880 --> 00:21:01.880]   All right.
[00:21:01.880 --> 00:21:02.880]   Watch out customs.
[00:21:02.880 --> 00:21:03.880]   I'm coming.
[00:21:03.880 --> 00:21:04.880]   I'm not coming for you.
[00:21:04.880 --> 00:21:08.840]   And if you get this now, we'll give you a free set of steak knives.
[00:21:08.840 --> 00:21:11.640]   Actually, it ties to a story that I was reading this week.
[00:21:11.640 --> 00:21:18.240]   A government watchdog agency was able to crack a federal agency's passwords in minutes
[00:21:18.240 --> 00:21:23.280]   as part of their, I guess, you know, security pen testing.
[00:21:23.280 --> 00:21:27.280]   They hired the Department of Interior.
[00:21:27.280 --> 00:21:31.400]   They hired somebody, the office and the inspector general for the Department of Interior hired
[00:21:31.400 --> 00:21:34.880]   somebody to test their security.
[00:21:34.880 --> 00:21:38.360]   The agency manages the country's federal land, national parks.
[00:21:38.360 --> 00:21:44.880]   It has a budget of billions of dollars and uses passwords to protect most of its systems.
[00:21:44.880 --> 00:21:45.880]   What a surprise.
[00:21:45.880 --> 00:21:47.760]   That's what we do, right?
[00:21:47.760 --> 00:21:53.720]   It has bucked nearly two decades of the government's own cybersecurity guidance, not using two
[00:21:53.720 --> 00:21:58.120]   factor or hardware keys or something like the iron key.
[00:21:58.120 --> 00:22:06.520]   So the inspector general spent 15 grand hired some bad guys who broke in within minutes.
[00:22:06.520 --> 00:22:09.440]   They built a password cracking rig for 15,000 dollars.
[00:22:09.440 --> 00:22:14.560]   They built their own hardware, a set up of high performance computer with a computing
[00:22:14.560 --> 00:22:20.440]   power designed to take on complex mathematical tasks within 90 minutes.
[00:22:20.440 --> 00:22:26.200]   They were able to recover 14,000 14,000 employee passwords.
[00:22:26.200 --> 00:22:31.280]   It's about 16% of all department accounts because the passwords were things like, remember,
[00:22:31.280 --> 00:22:38.040]   this is the Department of Interior, national parks 2014 and polar bear 65.
[00:22:38.040 --> 00:22:40.000]   Oh, shoot, excuse me.
[00:22:40.000 --> 00:22:41.000]   I got to go shoot.
[00:22:41.000 --> 00:22:43.400]   That's just a tiny bit better than monkey one, two, three, four.
[00:22:43.400 --> 00:22:45.040]   It's monkey one, two, three.
[00:22:45.040 --> 00:22:49.560]   The watchdog also recovered hundreds recovered hundreds of accounts belonging to senior government
[00:22:49.560 --> 00:22:54.720]   employees and other accounts with elevated security privileges for accessing sensitive
[00:22:54.720 --> 00:22:56.160]   data and systems.
[00:22:56.160 --> 00:22:57.800]   4,200 hash passwords.
[00:22:57.800 --> 00:23:02.640]   Oh, it took them a few weeks, but they were able to get in.
[00:23:02.640 --> 00:23:03.640]   So that's interesting.
[00:23:03.640 --> 00:23:05.760]   This is an interesting way to do pen testing.
[00:23:05.760 --> 00:23:09.840]   They built their own the Department of Interior built their own rig.
[00:23:09.840 --> 00:23:17.720]   Actually, it was two of them with eight GPUs each, running multiple open source containers.
[00:23:17.720 --> 00:23:28.280]   They can bring up to eight GPUs online, assign them tasks, benchmarks of 240 giga hashes
[00:23:28.280 --> 00:23:33.600]   per second, 240 billion hashes per second.
[00:23:33.600 --> 00:23:36.200]   It's basically a dictionary attack per second.
[00:23:36.200 --> 00:23:40.400]   Well, and the reason this comes up, of course, obviously, this is a good, I'm glad they've
[00:23:40.400 --> 00:23:44.520]   pen tested this, but the reason this comes up is because of the last pass breach.
[00:23:44.520 --> 00:23:49.620]   A lot of people are now starting to worry about their password manager and how well
[00:23:49.620 --> 00:23:53.320]   secure it is and whether they're using good passwords.
[00:23:53.320 --> 00:23:57.840]   You can't trust the hash anymore because what this team did was they actually did fieldwork
[00:23:57.840 --> 00:24:03.440]   before they did the attempt where they reverse engineered some common hashes.
[00:24:03.440 --> 00:24:05.600]   They did basically a rainbow table.
[00:24:05.600 --> 00:24:06.600]   Exactly.
[00:24:06.600 --> 00:24:07.600]   Yeah.
[00:24:07.600 --> 00:24:10.720]   So then they can just take that and they compare it against the hashes until they find the
[00:24:10.720 --> 00:24:13.440]   matches and then they'll, okay, this is probably part of that string.
[00:24:13.440 --> 00:24:15.080]   This is probably part of that string.
[00:24:15.080 --> 00:24:19.120]   Now, it should be said that the ones that were easiest to crack, of course, were the
[00:24:19.120 --> 00:24:24.240]   ones that were like, you know, monkey one, two, three, but the ones that were more sophisticated,
[00:24:24.240 --> 00:24:29.760]   they were still able to crack a couple of days and weeks later, which again means for
[00:24:29.760 --> 00:24:35.000]   $15,000, you can now build yourself a rig that can get you into pretty much every hash
[00:24:35.000 --> 00:24:36.400]   file that you need to get into.
[00:24:36.400 --> 00:24:39.360]   The first, Steve gives me one more time.
[00:24:39.360 --> 00:24:45.680]   The first thing crackers add to their password hash dictionaries is the top 1000 passwords
[00:24:45.680 --> 00:24:50.680]   and it turned out 5% of all the passwords in the Department of the Interior included some
[00:24:50.680 --> 00:24:53.240]   variation of the word password.
[00:24:53.240 --> 00:24:54.240]   No.
[00:24:54.240 --> 00:25:00.920]   Leo, I think we're about to have something warm here, but I falcon heavy.
[00:25:00.920 --> 00:25:04.880]   The space force mission is about to, there it goes.
[00:25:04.880 --> 00:25:05.880]   Wow.
[00:25:05.880 --> 00:25:06.880]   That was good timing.
[00:25:06.880 --> 00:25:09.320]   Thank you, Father Robert.
[00:25:09.320 --> 00:25:10.320]   This is this.
[00:25:10.320 --> 00:25:11.320]   What are they doing?
[00:25:11.320 --> 00:25:14.240]   This is a secret mission for the space force.
[00:25:14.240 --> 00:25:18.200]   Geosynchronous orbit, satellite to watch over us.
[00:25:18.200 --> 00:25:20.640]   So Steve Carroll is going to be saying that.
[00:25:20.640 --> 00:25:21.960]   Yeah, Steve Farrell's in there.
[00:25:21.960 --> 00:25:25.440]   Yeah, Jeff Bezos has just tied to the top.
[00:25:25.440 --> 00:25:28.400]   But this is the first, this is the second launch of the falcon heavy.
[00:25:28.400 --> 00:25:30.840]   We haven't seen too many of these second, right?
[00:25:30.840 --> 00:25:34.120]   You know, why don't we bring Artemis to the moon?
[00:25:34.120 --> 00:25:36.600]   No, this is a different one.
[00:25:36.600 --> 00:25:39.160]   I think this is delivering a Tesla to the moon.
[00:25:39.160 --> 00:25:40.160]   Thank you.
[00:25:40.160 --> 00:25:41.160]   Thank you.
[00:25:41.160 --> 00:25:42.800]   What is Elon up to these days?
[00:25:42.800 --> 00:25:43.800]   I haven't heard from him lately.
[00:25:43.800 --> 00:25:44.800]   Is he doing anything?
[00:25:44.800 --> 00:25:49.680]   Yeah, no, he's not running any businesses.
[00:25:49.680 --> 00:25:52.680]   That was another big story this week.
[00:25:52.680 --> 00:25:58.840]   It's unclear whether this was done on purpose or by accident.
[00:25:58.840 --> 00:26:05.360]   But according to Aaron Wu writing for the information, Twitter intentionally suspended
[00:26:05.360 --> 00:26:11.160]   third party apps, the API, including tweet bot Thursday night.
[00:26:11.160 --> 00:26:15.960]   I started seeing messages all over, especially in our Mastodon account, Twitter social saying,
[00:26:15.960 --> 00:26:17.240]   what the heck?
[00:26:17.240 --> 00:26:21.080]   My third party app is just not logging in.
[00:26:21.080 --> 00:26:29.680]   The information Aaron Wu got internal messages that lead one to believe that this was intentional
[00:26:29.680 --> 00:26:32.560]   on Twitter's part.
[00:26:32.560 --> 00:26:33.560]   My bots stopped working.
[00:26:33.560 --> 00:26:34.920]   No, you had a bot.
[00:26:34.920 --> 00:26:35.920]   I built a bot.
[00:26:35.920 --> 00:26:36.920]   You're right.
[00:26:36.920 --> 00:26:37.920]   I used the API.
[00:26:37.920 --> 00:26:42.800]   And some of it did screen scraping and it just started freaking out.
[00:26:42.800 --> 00:26:44.840]   It can no longer do its job.
[00:26:44.840 --> 00:26:46.760]   So I had to turn it off.
[00:26:46.760 --> 00:26:49.240]   Interestingly, but all the bots have been defeated.
[00:26:49.240 --> 00:26:52.880]   So, you know, it's ultimately turn off the API.
[00:26:52.880 --> 00:26:55.880]   Really smart.
[00:26:55.880 --> 00:27:00.020]   Twitter Riffic said it was still working, but many of the other ones, including tweet
[00:27:00.020 --> 00:27:05.360]   bot, which is very popular, Twitter Riffic.
[00:27:05.360 --> 00:27:09.980]   They said it was working, but then I've seen the information says it's not Phoenix for
[00:27:09.980 --> 00:27:13.180]   Twitter, Echo phone, tweet is down as well.
[00:27:13.180 --> 00:27:14.180]   Oh, it's good.
[00:27:14.180 --> 00:27:16.140]   I deleted all my tweets already.
[00:27:16.140 --> 00:27:17.140]   I know.
[00:27:17.140 --> 00:27:18.140]   It's quite bad.
[00:27:18.140 --> 00:27:21.140]   Well, there's a positive side to the story.
[00:27:21.140 --> 00:27:24.980]   And that's that it seems that Twitter did it on purpose rather than this accidentally
[00:27:24.980 --> 00:27:26.300]   happening because something they changed.
[00:27:26.300 --> 00:27:31.300]   Here's what the information learned.
[00:27:31.300 --> 00:27:33.380]   They saw an internal Slack message from a senior software engineer on Thursday night
[00:27:33.380 --> 00:27:39.580]   saying, quote, third party app and spec as suspensions are intentional.
[00:27:39.580 --> 00:27:44.300]   Yesterday, the information tried to contact that and for engineer.
[00:27:44.300 --> 00:27:46.620]   He refused comments.
[00:27:46.620 --> 00:27:50.860]   The internal messages I'm reading from Wu's story seen by the information also show that
[00:27:50.860 --> 00:27:55.220]   Twitter employees have been discussing when the decision would be announced publicly.
[00:27:55.220 --> 00:27:56.980]   Well, not yet.
[00:27:56.980 --> 00:27:59.380]   No one is one of those big mysteries.
[00:27:59.380 --> 00:28:00.740]   A Twitter employee working.
[00:28:00.740 --> 00:28:04.300]   I think part of it is who would be announcing these things?
[00:28:04.300 --> 00:28:08.140]   Twitter has a skeleton staff and almost nobody from comms.
[00:28:08.140 --> 00:28:09.140]   They have no.
[00:28:09.140 --> 00:28:10.540]   No one from comms is left.
[00:28:10.540 --> 00:28:11.540]   No PR.
[00:28:11.540 --> 00:28:12.540]   No comms.
[00:28:12.540 --> 00:28:15.860]   And apparently the API engineering team is mostly gone as well.
[00:28:15.860 --> 00:28:17.020]   So they were in the first round.
[00:28:17.020 --> 00:28:18.020]   Who would announce this?
[00:28:18.020 --> 00:28:19.020]   I don't know.
[00:28:19.020 --> 00:28:22.540]   A Twitter employee working on project product partnerships asked on Friday morning when
[00:28:22.540 --> 00:28:25.820]   employees could expect a list of approved talking points.
[00:28:25.820 --> 00:28:27.900]   You're all in comms now.
[00:28:27.900 --> 00:28:32.300]   For questions for partners related to third party clients revoked access.
[00:28:32.300 --> 00:28:37.060]   Do you want to talk about how the information gets this information, Paris or is that a
[00:28:37.060 --> 00:28:38.060]   state secret?
[00:28:38.060 --> 00:28:43.260]   I mean, I guess it's somewhat a state secret, but it's the same as all I think journalism
[00:28:43.260 --> 00:28:44.260]   happens.
[00:28:44.260 --> 00:28:49.700]   We have reporters who their job is to build up kind of networks of great sources.
[00:28:49.700 --> 00:28:54.820]   People either inside the company or people familiar with these decisions and they're
[00:28:54.820 --> 00:28:56.180]   in constant contact.
[00:28:56.180 --> 00:29:01.620]   And so I remember kind of seeing in certain groups with colleagues over the weekend of
[00:29:01.620 --> 00:29:06.460]   news breaking internally that this was happening and they turned that into a story.
[00:29:06.460 --> 00:29:12.220]   I think especially Aaron Wu, the reporter who did this has been producing really fantastic
[00:29:12.220 --> 00:29:14.540]   work for us on the Twitter beat.
[00:29:14.540 --> 00:29:18.820]   And I think that it's kind of, I mean, a lot of so many journalists have because it is
[00:29:18.820 --> 00:29:26.660]   such a, I mean, the story is ever changing and there are employees constantly on the
[00:29:26.660 --> 00:29:30.820]   ins and outs with Twitter leadership that are willing to talk to the press about what's
[00:29:30.820 --> 00:29:31.820]   going on.
[00:29:31.820 --> 00:29:32.820]   That's basically what's happening there.
[00:29:32.820 --> 00:29:33.820]   Yeah.
[00:29:33.820 --> 00:29:37.500]   And so you're seeing these Slack messages because they sent you screenshots or the like.
[00:29:37.500 --> 00:29:38.500]   Something like that.
[00:29:38.500 --> 00:29:39.500]   Yeah.
[00:29:39.500 --> 00:29:44.380]   Paul Hadad who works for TapBots and writes a tweet bot.
[00:29:44.380 --> 00:29:46.900]   "Tooted on Mastodon.
[00:29:46.900 --> 00:29:50.780]   Almost 24 hours later still no official unofficial info from inside Twitter.
[00:29:50.780 --> 00:29:55.060]   I'm going to continue as a vist as if this was all done on purpose."
[00:29:55.060 --> 00:29:57.060]   And Paul now there's evidence it was.
[00:29:57.060 --> 00:29:58.060]   What now?
[00:29:58.060 --> 00:30:02.420]   So TapBots has a Mastodon client which is in beta right now called Ivory.
[00:30:02.420 --> 00:30:05.500]   I don't use it, but a lot of people who use it say it's very good.
[00:30:05.500 --> 00:30:09.060]   He says, well, we're going to go into hyper mode with just the absolute minimum three to
[00:30:09.060 --> 00:30:13.260]   four things that have to be done, finished up and then off to Apple.
[00:30:13.260 --> 00:30:16.500]   In other words, to get an app approval so it can be in the app store.
[00:30:16.500 --> 00:30:19.140]   Probably going to be a bunch of things I'm not super happy with, but I guess we'll fix
[00:30:19.140 --> 00:30:20.980]   it in post.
[00:30:20.980 --> 00:30:26.380]   Hopefully everyone knows what we're capable of and can live with some hopefully not long
[00:30:26.380 --> 00:30:29.620]   live rush rough edges and missing features.
[00:30:29.620 --> 00:30:31.460]   You know, a tweet bot is amazing.
[00:30:31.460 --> 00:30:33.020]   Ivory will be amazing.
[00:30:33.020 --> 00:30:34.860]   But what's the long game here?
[00:30:34.860 --> 00:30:39.780]   So I mean, is this just because Musk wants to sell a third party app.
[00:30:39.780 --> 00:30:44.220]   He wants to reduce the amount of expenses for accessing for the API.
[00:30:44.220 --> 00:30:46.420]   I mean, what's the cause here?
[00:30:46.420 --> 00:30:50.060]   The third party support for Twitter has been something that really drove the adoption of
[00:30:50.060 --> 00:30:51.060]   Twitter.
[00:30:51.060 --> 00:30:52.820]   So are we just now saying, well, we're done.
[00:30:52.820 --> 00:30:54.380]   We've got all the audience we want.
[00:30:54.380 --> 00:30:55.380]   And thank you very much.
[00:30:55.380 --> 00:30:57.820]   Well, remember this is not the first time Twitter did this.
[00:30:57.820 --> 00:30:58.900]   They did it some years ago.
[00:30:58.900 --> 00:31:04.820]   And actually, I think Jack Dorsey has later said that was a huge mistake to cut off the
[00:31:04.820 --> 00:31:06.940]   third party API.
[00:31:06.940 --> 00:31:11.500]   I suspect it's just as simple as we want you to use our webpage and our app.
[00:31:11.500 --> 00:31:14.660]   And if you the new Twitter, we haven't talked about Twitter in some time.
[00:31:14.660 --> 00:31:15.660]   So I apologize.
[00:31:15.660 --> 00:31:17.820]   We both thought this was an Elon Musk free zone.
[00:31:17.820 --> 00:31:22.300]   But but occasionally we kind of have to we have to mention this.
[00:31:22.300 --> 00:31:23.620]   You smell that?
[00:31:23.620 --> 00:31:24.620]   That's the mosque.
[00:31:24.620 --> 00:31:28.180]   Oh, no, you've been sprayed.
[00:31:28.180 --> 00:31:30.660]   Well, and I don't use Twitter anymore.
[00:31:30.660 --> 00:31:34.380]   So I'll defer to the you're a you're a toot man now.
[00:31:34.380 --> 00:31:35.380]   I'm a tutor.
[00:31:35.380 --> 00:31:38.620]   We have our own mass tonight and since we have for years, quite nice.
[00:31:38.620 --> 00:31:44.260]   And I thought, well, you know, I don't I can easily leave Twitter without any consequence.
[00:31:44.260 --> 00:31:48.700]   Although I have more than half a million followers, some of them are actually humans.
[00:31:48.700 --> 00:31:54.820]   And the breaking point when mustard calling himself the chief to it was a big one wasn't
[00:31:54.820 --> 00:31:55.820]   happy.
[00:31:55.820 --> 00:32:00.300]   That's the name I've used on my socials since 2007.
[00:32:00.300 --> 00:32:03.260]   Somebody must have told Elon because he stopped pretty quickly.
[00:32:03.260 --> 00:32:07.880]   That didn't mean that he wasn't he isn't still being called that way mainstream media.
[00:32:07.880 --> 00:32:13.820]   So he changed it looks like at the top of the Twitter now used to be you could go chronological
[00:32:13.820 --> 00:32:21.080]   or latest or hold they change which was oh yeah, there's no more there that little twinkly
[00:32:21.080 --> 00:32:22.080]   button is gone.
[00:32:22.080 --> 00:32:29.820]   You know, have very tick tock like for you and following.
[00:32:29.820 --> 00:32:34.740]   And I mean, I don't know about if either of you guys who are using Twitter have the same
[00:32:34.740 --> 00:32:38.820]   issue, but for me, I spend too much time on Twitter.
[00:32:38.820 --> 00:32:43.900]   But my for you kind of feed is almost all people that I do not fall.
[00:32:43.900 --> 00:32:44.900]   It's all like that.
[00:32:44.900 --> 00:32:48.380]   We're seeing just likes from people I follow.
[00:32:48.380 --> 00:32:55.580]   So instead of popular tweets from accounts that I'm following, it is mostly, you know,
[00:32:55.580 --> 00:33:00.140]   it's liked by people I follow or recommended tweets from different categories.
[00:33:00.140 --> 00:33:04.980]   So in order basically to see anybody's tweets that I follow, I have to just do chronological,
[00:33:04.980 --> 00:33:07.180]   which is not what I want.
[00:33:07.180 --> 00:33:08.180]   Most of the time.
[00:33:08.180 --> 00:33:09.180]   Yeah.
[00:33:09.180 --> 00:33:14.740]   So let's talk about what's going on at Twitter because that's how you started this discussion.
[00:33:14.740 --> 00:33:18.900]   Elon Musk we've seen in the past two weeks has been the person on the planet who's lost
[00:33:18.900 --> 00:33:23.860]   more wealth than a short amount of time than anyone else $200 billion.
[00:33:23.860 --> 00:33:26.140]   The shares are tanking.
[00:33:26.140 --> 00:33:31.620]   Seen at wrote a story back in December, how lots of not lots, but there was a trend among
[00:33:31.620 --> 00:33:37.460]   Twi, Tesla owners who were just not going to renew their leases or backing away because
[00:33:37.460 --> 00:33:39.300]   they just didn't like what he was doing.
[00:33:39.300 --> 00:33:44.700]   And I think what you're saying is that he's, you know, it's easy Monday, Monday morning
[00:33:44.700 --> 00:33:48.740]   quarterback out of run a social media site when you're standing on the outside, but there's
[00:33:48.740 --> 00:33:53.780]   a totally different story when you're inside trying to make policy and do things.
[00:33:53.780 --> 00:33:59.380]   And so what we're seeing is the, the supposed genius of this man is not, you know, that
[00:33:59.380 --> 00:34:04.700]   genius when it comes to a social media site and either he's getting bored with it and,
[00:34:04.700 --> 00:34:08.900]   you know, or there's a communication breakdown where people are not quite sure what they
[00:34:08.900 --> 00:34:09.900]   need to do.
[00:34:09.900 --> 00:34:13.420]   I mean, he's supposedly looking for somebody else to run it, right?
[00:34:13.420 --> 00:34:17.140]   That's what we keep waiting to hear who's now going to step in and run it because the
[00:34:17.140 --> 00:34:19.100]   internet voted him out.
[00:34:19.100 --> 00:34:21.620]   So it's kind of like he's ignoring it.
[00:34:21.620 --> 00:34:25.500]   By the way, it seems like he's kind of ignoring the results of that poll.
[00:34:25.500 --> 00:34:29.260]   I think it's notable that even after that, he was like, yeah, if I find someone new to
[00:34:29.260 --> 00:34:32.500]   be CEO of Twitter, they'll be CEO, but I'm going to run all the tech.
[00:34:32.500 --> 00:34:34.500]   Yeah, I'm going to still run it.
[00:34:34.500 --> 00:34:35.500]   Yeah.
[00:34:35.500 --> 00:34:36.500]   Yeah.
[00:34:36.500 --> 00:34:37.500]   You know, CEO.
[00:34:37.500 --> 00:34:40.980]   So, um, scooter X in our chair, um, says to tell me if this is still the case, scooter
[00:34:40.980 --> 00:34:43.700]   X that some of these third party clients are working again.
[00:34:43.700 --> 00:34:45.140]   I see your tweet.
[00:34:45.140 --> 00:34:48.700]   Um, I, again, I, I don't have a dog in this hunt anymore.
[00:34:48.700 --> 00:34:54.940]   And I'm very happy that I don't, um, but I think there's still a lot of people who care
[00:34:54.940 --> 00:34:57.980]   deeply about what happens to Twitter, right?
[00:34:57.980 --> 00:34:58.980]   Absolutely.
[00:34:58.980 --> 00:34:59.980]   Yeah.
[00:34:59.980 --> 00:35:01.540]   And that's why you're getting leaks from the company.
[00:35:01.540 --> 00:35:06.740]   I mean, I'm a long time Apple reporter who in the early days when I was working at this
[00:35:06.740 --> 00:35:10.180]   place called Mac Week, we'd have all these great stories and people were like, why is
[00:35:10.180 --> 00:35:11.180]   all this stuff leaking?
[00:35:11.180 --> 00:35:13.780]   And it wasn't leaking because people were malicious.
[00:35:13.780 --> 00:35:15.740]   It's because they loved the company.
[00:35:15.740 --> 00:35:18.900]   And they wanted to see it get better and do better.
[00:35:18.900 --> 00:35:23.980]   And so you're seeing some people talking about what's happening inside Twitter, not because
[00:35:23.980 --> 00:35:25.140]   they want to tear it down.
[00:35:25.140 --> 00:35:26.140]   It's because they can't believe it.
[00:35:26.140 --> 00:35:31.500]   And I want someone to come and help save it or rescue or create enough outside momentum
[00:35:31.500 --> 00:35:34.300]   to get some of the crazy stuff stopped.
[00:35:34.300 --> 00:35:39.820]   You know, I stepped away entirely from Twitter in December leading up to CES for like six
[00:35:39.820 --> 00:35:42.620]   weeks and it was wonderful.
[00:35:42.620 --> 00:35:45.500]   It was so, I, I focused on Macedon on the, uh,
[00:35:45.500 --> 00:35:46.500]   I love you.
[00:35:46.500 --> 00:35:47.500]   I love you.
[00:35:47.500 --> 00:35:48.500]   I love you.
[00:35:48.500 --> 00:35:49.500]   I love you.
[00:35:49.500 --> 00:35:50.500]   And I'm a massive.
[00:35:50.500 --> 00:35:51.500]   Yeah.
[00:35:51.500 --> 00:35:52.500]   It's, it's, it's a fun community.
[00:35:52.500 --> 00:35:54.580]   When I came back, I didn't really miss, uh, having access to a larger audience.
[00:35:54.580 --> 00:36:00.620]   I did miss some of the members of the community that I had built up on Twitter.
[00:36:00.620 --> 00:36:04.100]   Now if they were to come over to Macedon, there would be no reason for me to go back
[00:36:04.100 --> 00:36:05.100]   to Twitter.
[00:36:05.100 --> 00:36:09.660]   That's the only reason why I still care about that company because there are some people
[00:36:09.660 --> 00:36:11.900]   who I can only connect with over Twitter.
[00:36:11.900 --> 00:36:12.900]   That's it.
[00:36:12.900 --> 00:36:16.260]   I feel like there's a lesson that needs to be learned here that we have.
[00:36:16.260 --> 00:36:21.700]   Many of us have, but some of us have not yet learned, which is that at least when it comes
[00:36:21.700 --> 00:36:27.860]   to social, this kind of centralized single owner company is ultimately not good for you.
[00:36:27.860 --> 00:36:30.660]   Whether it's Facebook, look what they're doing to Instagram.
[00:36:30.660 --> 00:36:33.700]   I, is anybody happy with the new Instagram?
[00:36:33.700 --> 00:36:39.780]   Uh, uh, Elon Musk at Twitter, I just, I feel like these companies, because their model
[00:36:39.780 --> 00:36:44.420]   is not to create a nice conversation.
[00:36:44.420 --> 00:36:52.140]   Their whole business model is to create, fewer or so that it's sticky, so it's engaging.
[00:36:52.140 --> 00:36:57.260]   And as a result, you get, uh, I think things that are bad for our polity.
[00:36:57.260 --> 00:36:58.780]   I think they're bad for society.
[00:36:58.780 --> 00:37:00.540]   I don't think they're good for us.
[00:37:00.540 --> 00:37:04.940]   Whereas these decentralized, and I think it's more than just decentralized social networks.
[00:37:04.940 --> 00:37:07.980]   Honestly, I think it's also open source.
[00:37:07.980 --> 00:37:10.500]   But this is maybe the watershed moment.
[00:37:10.500 --> 00:37:12.060]   Maybe I'm being a pie.
[00:37:12.060 --> 00:37:13.060]   I'd optimist.
[00:37:13.060 --> 00:37:19.220]   I also believe it was going to be the year of the links desktop in 1924, but, uh, I think,
[00:37:19.220 --> 00:37:25.180]   I think that this may be the watershed moment where we start to realize that computing should
[00:37:25.180 --> 00:37:28.220]   not be owned by any company.
[00:37:28.220 --> 00:37:29.220]   I would hope so.
[00:37:29.220 --> 00:37:31.260]   That blogs should proliferate.
[00:37:31.260 --> 00:37:32.500]   Everybody should have their own blog.
[00:37:32.500 --> 00:37:39.620]   But social networks should be diverse and federated that it doesn't make sense for one company
[00:37:39.620 --> 00:37:40.860]   to dominate.
[00:37:40.860 --> 00:37:42.180]   It's bad for us.
[00:37:42.180 --> 00:37:47.420]   Except, and we did a big meeting in the Vatican on this.
[00:37:47.420 --> 00:37:50.660]   We call it common good in the digital aid.
[00:37:50.660 --> 00:37:53.980]   If anybody should support open source, it's the Vatican.
[00:37:53.980 --> 00:37:55.260]   And actually they asked me about that.
[00:37:55.260 --> 00:38:00.180]   They said, what is so sticky about Facebook or Twitter or any of the other social media
[00:38:00.180 --> 00:38:01.380]   services?
[00:38:01.380 --> 00:38:03.260]   We had mass communications.
[00:38:03.260 --> 00:38:05.260]   Can you say Satan?
[00:38:05.260 --> 00:38:09.060]   No, the key word was, that's what came to mind.
[00:38:09.060 --> 00:38:10.060]   I'm sorry.
[00:38:10.060 --> 00:38:12.020]   The key word was outrage.
[00:38:12.020 --> 00:38:13.420]   Yeah, it is.
[00:38:13.420 --> 00:38:14.420]   It is.
[00:38:14.420 --> 00:38:15.420]   That's how they make you.
[00:38:15.420 --> 00:38:16.420]   That's how they make you.
[00:38:16.420 --> 00:38:18.900]   Cells on outrage because outrage spreads so fast.
[00:38:18.900 --> 00:38:24.020]   An outrage motivates more than anything else because if I can get righteously indignant about
[00:38:24.020 --> 00:38:30.100]   somebody else about what someone else did or what someone else said, that spreads.
[00:38:30.100 --> 00:38:31.100]   That spreads.
[00:38:31.100 --> 00:38:36.340]   I'm going to write this wonderful story about how there's a woman in Philadelphia who is
[00:38:36.340 --> 00:38:39.620]   taking care of homeless children.
[00:38:39.620 --> 00:38:41.500]   That will get maybe a day of coverage.
[00:38:41.500 --> 00:38:45.980]   But if I write about how there's a woman in Pennsylvania who has abused homeless children,
[00:38:45.980 --> 00:38:48.740]   oh my God, she will be the most famous person ever.
[00:38:48.740 --> 00:38:51.100]   Local news has never been about good news.
[00:38:51.100 --> 00:38:52.900]   Newspapers never been about good news.
[00:38:52.900 --> 00:39:00.140]   But if you reach, if you want people to read your paper or watch your TV show, you get
[00:39:00.140 --> 00:39:05.540]   them, it doesn't have to always be anger, but you get them revved up somehow.
[00:39:05.540 --> 00:39:09.180]   But the loop, the feedback cycle on social media, the fact that you can get that anger
[00:39:09.180 --> 00:39:11.540]   cycle so quickly.
[00:39:11.540 --> 00:39:14.140]   I mean, it's those little mini hits of dopamine.
[00:39:14.140 --> 00:39:15.660]   So I guess that's my question.
[00:39:15.660 --> 00:39:19.140]   Why are we trying to save Twitter?
[00:39:19.140 --> 00:39:20.140]   It's community.
[00:39:20.140 --> 00:39:21.500]   Honestly, it's the community.
[00:39:21.500 --> 00:39:23.340]   Because that's where your friends are.
[00:39:23.340 --> 00:39:28.860]   Now that's there, that's to me, that's their heroin dealers hook.
[00:39:28.860 --> 00:39:31.740]   That's what they're saying, well, you don't want to lose your friends.
[00:39:31.740 --> 00:39:34.940]   And honestly, all it would take is for us to move.
[00:39:34.940 --> 00:39:42.020]   It would take us, but some people, a lot of people are invested in the years, decades,
[00:39:42.020 --> 00:39:43.020]   for decades for some.
[00:39:43.020 --> 00:39:45.620]   Nobody wants to read your old tweets.
[00:39:45.620 --> 00:39:46.620]   Nobody does.
[00:39:46.620 --> 00:39:52.980]   But if I've got an account with 100,000 followers and I really put time into developing
[00:39:52.980 --> 00:39:55.420]   a 100,000 followers, I'm not going to just abandon it.
[00:39:55.420 --> 00:39:58.820]   Well, I'm sure for a brand Connie, that makes a big, that's a big part of it.
[00:39:58.820 --> 00:40:04.060]   I mean, I would love to see CNET say, no more Twitter, it's ridiculous, but you can't do
[00:40:04.060 --> 00:40:05.060]   that.
[00:40:05.060 --> 00:40:06.060]   We don't even do that.
[00:40:06.060 --> 00:40:07.060]   Twitter doesn't even do that.
[00:40:07.060 --> 00:40:08.060]   You tried to do that.
[00:40:08.060 --> 00:40:11.180]   I did it, but I can't get the company to do it.
[00:40:11.180 --> 00:40:16.060]   So as somebody who's been in the tech industry for a long time, things come and go, right?
[00:40:16.060 --> 00:40:18.740]   And right now, should we save Twitter?
[00:40:18.740 --> 00:40:19.740]   I don't know.
[00:40:19.740 --> 00:40:21.540]   I mean, yeah, am I used to it?
[00:40:21.540 --> 00:40:23.540]   Do I know how it works?
[00:40:23.540 --> 00:40:28.100]   Have brands built communities, but it's also, there's a lot of negativity around there.
[00:40:28.100 --> 00:40:33.900]   And we saw a lot of bad things happen to brands when anybody could get terrified, right?
[00:40:33.900 --> 00:40:34.900]   That's true.
[00:40:34.900 --> 00:40:35.900]   And started putting out misinformation.
[00:40:35.900 --> 00:40:38.020]   There are a few brands who wish they weren't on Twitter.
[00:40:38.020 --> 00:40:39.020]   Yeah.
[00:40:39.020 --> 00:40:40.020]   That's right.
[00:40:40.020 --> 00:40:44.980]   So I think what we're looking at, I agree with everything that's been said about the
[00:40:44.980 --> 00:40:49.540]   toxicity that brings that social media has brought to the world.
[00:40:49.540 --> 00:40:53.980]   And all of us spending way too much time looking down and being in these echo chambers that
[00:40:53.980 --> 00:40:59.780]   are being hijacked by disinformation and propagandists and outraged cycle drivers.
[00:40:59.780 --> 00:41:04.820]   So then the question becomes what is the next thing that might inspire and engage people?
[00:41:04.820 --> 00:41:07.940]   For a while, everyone thought it was going to be TikTok, just these short little moments
[00:41:07.940 --> 00:41:09.540]   that made you laugh.
[00:41:09.540 --> 00:41:11.740]   But then there's the Chinese government behind them.
[00:41:11.740 --> 00:41:14.420]   And who's collecting the data and for what purpose?
[00:41:14.420 --> 00:41:19.260]   I'm not saying TikTok is not going to be successful or continue to have a lot of traffic,
[00:41:19.260 --> 00:41:22.500]   but what's the idea behind it, right?
[00:41:22.500 --> 00:41:27.220]   And what's the next level of social engagement that we want to have or that we want to walk
[00:41:27.220 --> 00:41:28.220]   away from?
[00:41:28.220 --> 00:41:33.820]   So that's the discussions that I think are going to start, especially if more governments
[00:41:33.820 --> 00:41:38.620]   Europe will be ahead of us in the US start looking at these big tech giants and saying,
[00:41:38.620 --> 00:41:40.660]   no, we don't want you to have all that power.
[00:41:40.660 --> 00:41:43.780]   We want you to want to rein you in some areas.
[00:41:43.780 --> 00:41:45.980]   We're just at the beginning of that.
[00:41:45.980 --> 00:41:48.780]   Kind of, can I invite you to our next conference in the Vatican?
[00:41:48.780 --> 00:41:49.780]   Yeah.
[00:41:49.780 --> 00:41:50.780]   Okay.
[00:41:50.780 --> 00:41:51.780]   I would absolutely.
[00:41:51.780 --> 00:41:52.780]   I'd like to come.
[00:41:52.780 --> 00:41:53.780]   Okay.
[00:41:53.780 --> 00:41:54.900]   I've even gotten an apartment for you.
[00:41:54.900 --> 00:42:00.100]   I'll offer you the same apartment I've been offering Leo for the last five years.
[00:42:00.100 --> 00:42:01.980]   I'm happy to come.
[00:42:01.980 --> 00:42:06.020]   But look, technology, I say this all the time.
[00:42:06.020 --> 00:42:07.980]   Technology is a means to an end.
[00:42:07.980 --> 00:42:09.140]   It's not an end.
[00:42:09.140 --> 00:42:13.620]   And at the beginning, the promise of places like Twitter and Facebook was to connect people
[00:42:13.620 --> 00:42:19.740]   in a more easy way where you got out of touch with your high school classmates or your college
[00:42:19.740 --> 00:42:25.380]   classmates, and now you can get back in touch with them, or you want to create communities,
[00:42:25.380 --> 00:42:27.540]   who wants a good one movie night or have a bad luck?
[00:42:27.540 --> 00:42:28.540]   That was the promise.
[00:42:28.540 --> 00:42:33.140]   It's been co-opted by people for nefarious purposes.
[00:42:33.140 --> 00:42:36.300]   So the technology inherently isn't bad.
[00:42:36.300 --> 00:42:39.860]   It's how it's being co-opted and used by people.
[00:42:39.860 --> 00:42:42.500]   And part of that is that we've kind of let it happen.
[00:42:42.500 --> 00:42:44.580]   We just let it, whatever happens happens.
[00:42:44.580 --> 00:42:51.820]   I love the idea of sitting back like you're doing in the church and saying, "Well, let's
[00:42:51.820 --> 00:42:56.140]   think, let's be more conscious about what we do next and think about its impact."
[00:42:56.140 --> 00:43:00.860]   I hate to see, and I do think there's a certain amount of moral panic, for instance, around
[00:43:00.860 --> 00:43:05.940]   TikTok, I hate to see people say, "Well, it's big tech, so it's bad."
[00:43:05.940 --> 00:43:06.940]   Right.
[00:43:06.940 --> 00:43:10.860]   But at the same time, I think little tech is better.
[00:43:10.860 --> 00:43:12.420]   You know, I really do.
[00:43:12.420 --> 00:43:17.500]   I think personal tech is better, small scale is better, and maybe it's time to wean ourselves
[00:43:17.500 --> 00:43:25.700]   off of this adrenaline dopamine hit that we get from going to places like Twitter.
[00:43:25.700 --> 00:43:27.420]   And yeah, you know, you're going to mast it on.
[00:43:27.420 --> 00:43:29.500]   It's not quite so exciting.
[00:43:29.500 --> 00:43:32.140]   There's no buzz.
[00:43:32.140 --> 00:43:33.660]   It's just conversations.
[00:43:33.660 --> 00:43:35.860]   It's pictures of the vadicats.
[00:43:35.860 --> 00:43:39.740]   It's kind of pleasant in a way that Twitter isn't.
[00:43:39.740 --> 00:43:44.060]   Maybe we just need to get used to, you know, it's like a sugar addict.
[00:43:44.060 --> 00:43:47.700]   At first, it's very hard not to eat stuff late with sugar, but...
[00:43:47.700 --> 00:43:50.060]   I don't know.
[00:43:50.060 --> 00:43:51.740]   One of the issues is a better way.
[00:43:51.740 --> 00:43:53.100]   Is a one channel.
[00:43:53.100 --> 00:43:58.780]   So one channel was a strategy that has been developed by enterprise communications companies
[00:43:58.780 --> 00:44:04.100]   that allowed companies to have, quote unquote, "one channel" to touch bases with their customers.
[00:44:04.100 --> 00:44:08.180]   And that meant it combined the feeds from social media, from their own internal communication
[00:44:08.180 --> 00:44:09.860]   systems, emails, et cetera, et cetera.
[00:44:09.860 --> 00:44:11.220]   Internally, that's what they saw.
[00:44:11.220 --> 00:44:12.220]   Right.
[00:44:12.220 --> 00:44:16.340]   So they wanted the customer to be able to move from one type of communication to another,
[00:44:16.340 --> 00:44:17.940]   and you continue the conversation.
[00:44:17.940 --> 00:44:19.660]   Is that still going?
[00:44:19.660 --> 00:44:20.660]   That's still going.
[00:44:20.660 --> 00:44:21.660]   That's good.
[00:44:21.660 --> 00:44:22.660]   I like that idea.
[00:44:22.660 --> 00:44:27.460]   But social media, specifically Twitter, was a huge part of that one channel strategy.
[00:44:27.460 --> 00:44:31.580]   So if you lose that, that's billions of dollars that has been invested that they lose.
[00:44:31.580 --> 00:44:34.060]   So they're heavily invested.
[00:44:34.060 --> 00:44:35.740]   Of course, Twitter wants to silo it.
[00:44:35.740 --> 00:44:36.740]   Right.
[00:44:36.740 --> 00:44:37.740]   Twitter doesn't want you to have one channel.
[00:44:37.740 --> 00:44:38.740]   It's not going to pay you to pay that.
[00:44:38.740 --> 00:44:39.740]   It's not going to pay you to that.
[00:44:39.740 --> 00:44:40.740]   Yeah.
[00:44:40.740 --> 00:44:41.740]   Yeah.
[00:44:41.740 --> 00:44:42.740]   All right.
[00:44:42.740 --> 00:44:43.740]   Let's take a little break.
[00:44:43.740 --> 00:44:44.740]   Lots more to talk about.
[00:44:44.740 --> 00:44:47.820]   A lot of crappy gadgets still, including a pet vacuum.
[00:44:47.820 --> 00:44:48.820]   It's for Burke.
[00:44:48.820 --> 00:44:49.820]   This is good stuff.
[00:44:49.820 --> 00:44:50.820]   You need to hear a cut.
[00:44:50.820 --> 00:44:51.820]   I love it.
[00:44:51.820 --> 00:44:52.980]   Father Robert Ballis there.
[00:44:52.980 --> 00:44:54.940]   The digital Jesuit is here.
[00:44:54.940 --> 00:44:55.940]   Jesuit pilgrimage.
[00:44:55.940 --> 00:44:57.340]   This is your new app.
[00:44:57.340 --> 00:44:58.340]   Yeah.
[00:44:58.340 --> 00:45:00.260]   So we've been, we were working on this for a while.
[00:45:00.260 --> 00:45:03.620]   It just, it came out of an evening of, hey, we're bored.
[00:45:03.620 --> 00:45:04.940]   What do you want to do?
[00:45:04.940 --> 00:45:06.740]   And someone said, hey, why don't you?
[00:45:06.740 --> 00:45:09.900]   You and the Pope and some Cardinals sit around.
[00:45:09.900 --> 00:45:11.300]   Yeah, kind of.
[00:45:11.300 --> 00:45:12.780]   They wanted a digital project.
[00:45:12.780 --> 00:45:14.700]   I said, how about something super simple.
[00:45:14.700 --> 00:45:17.140]   At one point, someone wanted to go.
[00:45:17.140 --> 00:45:21.380]   This is actually the church trying to figure out how do we stay relevant in a digital age.
[00:45:21.380 --> 00:45:22.380]   Correct.
[00:45:22.380 --> 00:45:23.380]   Yeah.
[00:45:23.380 --> 00:45:24.380]   So we just, I said, let's make an app.
[00:45:24.380 --> 00:45:25.380]   Pokemon go wouldn't be bad.
[00:45:25.380 --> 00:45:26.380]   Yeah.
[00:45:26.380 --> 00:45:27.380]   Would you search for it?
[00:45:27.380 --> 00:45:29.060]   I'm not going to be throwing paint balls at saints.
[00:45:29.060 --> 00:45:30.060]   I mean, come on.
[00:45:30.060 --> 00:45:32.140]   I'm not going to catch them all.
[00:45:32.140 --> 00:45:36.700]   But it just took people through the different sites.
[00:45:36.700 --> 00:45:37.700]   Of the pilgrimage.
[00:45:37.700 --> 00:45:39.660]   Your name is on this.
[00:45:39.660 --> 00:45:40.660]   It is.
[00:45:40.660 --> 00:45:41.660]   It is.
[00:45:41.660 --> 00:45:42.660]   This is your app.
[00:45:42.660 --> 00:45:43.660]   I know.
[00:45:43.660 --> 00:45:44.660]   That actually.
[00:45:44.660 --> 00:45:45.660]   I've had an iPhone.
[00:45:45.660 --> 00:45:46.660]   I've had iPhone.
[00:45:46.660 --> 00:45:47.660]   It's on Android too.
[00:45:47.660 --> 00:45:48.660]   Of course there is.
[00:45:48.660 --> 00:45:50.020]   So what do you do?
[00:45:50.020 --> 00:45:52.020]   So we have, it, it geolocate.
[00:45:52.020 --> 00:45:53.020]   So it's someone.
[00:45:53.020 --> 00:45:54.020]   You have an app.
[00:45:54.020 --> 00:45:55.020]   You buried the lead.
[00:45:55.020 --> 00:45:56.020]   Yeah.
[00:45:56.020 --> 00:45:57.020]   I know, I know.
[00:45:57.020 --> 00:45:58.780]   I do lots of things.
[00:45:58.780 --> 00:46:02.740]   But let's say you're actually visiting the, the pilgrimage sites.
[00:46:02.740 --> 00:46:05.780]   The Apple automatically know that you're there and will bring up information about the
[00:46:05.780 --> 00:46:07.900]   site where you should go.
[00:46:07.900 --> 00:46:11.140]   It will give you the, the meditations that Saint Ignatius himself did.
[00:46:11.140 --> 00:46:12.140]   It will show you 360 views.
[00:46:12.140 --> 00:46:13.140]   Oh, as you're there.
[00:46:13.140 --> 00:46:14.900]   As you're there, right.
[00:46:14.900 --> 00:46:16.900]   That's kind of, when did Saint Ignatius live?
[00:46:16.900 --> 00:46:19.900]   Oh, back in the 1500s.
[00:46:19.900 --> 00:46:20.900]   Okay.
[00:46:20.900 --> 00:46:21.980]   So well, that's not that long ago.
[00:46:21.980 --> 00:46:24.260]   I mean, Jesus was a couple of thousands.
[00:46:24.260 --> 00:46:25.260]   Exactly.
[00:46:25.260 --> 00:46:26.260]   So yeah.
[00:46:26.260 --> 00:46:31.700]   So, and SI, the society of Jesus is founded by Saint Ignatius.
[00:46:31.700 --> 00:46:32.700]   Correct.
[00:46:32.700 --> 00:46:34.140]   So that was our founder.
[00:46:34.140 --> 00:46:37.780]   And actually, if you look through the app and you follow the pilgrimage sites that he was
[00:46:37.780 --> 00:46:41.420]   at, you kind of get an idea of why we ended up the way we are.
[00:46:41.420 --> 00:46:44.540]   Plus you're going to get some great Italian food.
[00:46:44.540 --> 00:46:48.060]   I should, you know, restaurants in this, it's an open ended development.
[00:46:48.060 --> 00:46:50.420]   And we've been thinking about what else we wanted to add.
[00:46:50.420 --> 00:46:52.620]   The core functionality works.
[00:46:52.620 --> 00:46:53.620]   It's not all in Italy.
[00:46:53.620 --> 00:46:54.620]   Some of it's.
[00:46:54.620 --> 00:46:56.620]   May I suggest a cook with the Pope?
[00:46:56.620 --> 00:46:57.620]   Cook with the Pope.
[00:46:57.620 --> 00:46:58.620]   Yeah.
[00:46:58.620 --> 00:46:59.620]   I could, I could go to the phone.
[00:46:59.620 --> 00:47:00.620]   Do that.
[00:47:00.620 --> 00:47:01.620]   Okay.
[00:47:01.620 --> 00:47:02.620]   Yeah.
[00:47:02.620 --> 00:47:03.620]   You can tell us.
[00:47:03.620 --> 00:47:04.620]   Oh, he's a holy father.
[00:47:04.620 --> 00:47:05.620]   I like to eat.
[00:47:05.620 --> 00:47:06.620]   He's okay.
[00:47:06.620 --> 00:47:08.380]   Well, he's Argentinian, right?
[00:47:08.380 --> 00:47:10.420]   And Argentinian food is beef.
[00:47:10.420 --> 00:47:11.420]   It's beef.
[00:47:11.420 --> 00:47:12.420]   He likes beef.
[00:47:12.420 --> 00:47:14.340]   He likes, he likes a good meat.
[00:47:14.340 --> 00:47:17.020]   What is the cheese dish where they bake the cheese?
[00:47:17.020 --> 00:47:19.020]   It's so good.
[00:47:19.020 --> 00:47:20.020]   Yes.
[00:47:20.020 --> 00:47:21.020]   We don't have that.
[00:47:21.020 --> 00:47:22.020]   It's too rich.
[00:47:22.020 --> 00:47:23.020]   Oh, yeah.
[00:47:23.020 --> 00:47:24.020]   It's too rich.
[00:47:24.020 --> 00:47:25.020]   Yeah.
[00:47:25.020 --> 00:47:27.980]   But he is, he honestly, and there's a chance that he might be in the house when you're there.
[00:47:27.980 --> 00:47:30.980]   He is one of the nicest, most unassuming people you've ever had.
[00:47:30.980 --> 00:47:32.460]   You've told me some stories.
[00:47:32.460 --> 00:47:34.380]   I'm sure not for public consumption.
[00:47:34.380 --> 00:47:37.140]   That really are like, wow, that's kind of cool.
[00:47:37.140 --> 00:47:40.660]   I'm still trying to get him on our Dungeons and Dragons crew.
[00:47:40.660 --> 00:47:41.660]   You guys go down in the camp.
[00:47:41.660 --> 00:47:43.860]   What class do you think the Pope?
[00:47:43.860 --> 00:47:46.660]   Oh, I mean, he's going to be a cleric.
[00:47:46.660 --> 00:47:47.660]   Yeah.
[00:47:47.660 --> 00:47:48.660]   That's a cleric.
[00:47:48.660 --> 00:47:49.660]   Absolutely.
[00:47:49.660 --> 00:47:50.660]   And he's.
[00:47:50.660 --> 00:47:51.660]   The Pope just decides barbarians.
[00:47:51.660 --> 00:47:55.500]   He likes to tank.
[00:47:55.500 --> 00:47:56.500]   You can't blame him.
[00:47:56.500 --> 00:47:57.500]   Yeah.
[00:47:57.500 --> 00:47:58.500]   Yeah.
[00:47:58.500 --> 00:47:59.500]   Yeah.
[00:47:59.500 --> 00:48:00.500]   Who doesn't?
[00:48:00.500 --> 00:48:01.500]   Right.
[00:48:01.500 --> 00:48:04.020]   He's going to be in the 20 sessions in an actual catacomb.
[00:48:04.020 --> 00:48:05.020]   Yeah.
[00:48:05.020 --> 00:48:09.820]   So if you told me that you told me once that you guys were down there and there's some
[00:48:09.820 --> 00:48:12.380]   priests, but there's some, are there Cardinals, bishops?
[00:48:12.380 --> 00:48:13.380]   Yeah.
[00:48:13.380 --> 00:48:14.380]   High ranking members of the church there.
[00:48:14.380 --> 00:48:16.500]   We just, you know, have plain old D&D.
[00:48:16.500 --> 00:48:17.700]   Who is the Dungeon Master?
[00:48:17.700 --> 00:48:19.220]   I was the GM.
[00:48:19.220 --> 00:48:20.220]   Okay.
[00:48:20.220 --> 00:48:21.220]   Yeah.
[00:48:21.220 --> 00:48:23.060]   And his Holy Father comes wandering by.
[00:48:23.060 --> 00:48:24.860]   We were a little loud.
[00:48:24.860 --> 00:48:26.020]   You were loud and he heard you.
[00:48:26.020 --> 00:48:27.020]   He heard us.
[00:48:27.020 --> 00:48:30.100]   And he came down to see what the ruckus was and know what was going on.
[00:48:30.100 --> 00:48:32.060]   Like, are they rising from the dead?
[00:48:32.060 --> 00:48:33.060]   What's going on?
[00:48:33.060 --> 00:48:36.340]   Well, because when you make noise down there, you don't know where it's coming up.
[00:48:36.340 --> 00:48:37.940]   Those tunnels go everywhere.
[00:48:37.940 --> 00:48:38.940]   Yeah.
[00:48:38.940 --> 00:48:42.100]   So he, he didn't like send a Swiss guard down.
[00:48:42.100 --> 00:48:45.180]   No, no, that would have ended differently and loudly with.
[00:48:45.180 --> 00:48:50.220]   He put his, he put his Pontifical slippers on, which are beautiful by the way.
[00:48:50.220 --> 00:48:51.220]   Yes.
[00:48:51.220 --> 00:48:52.220]   And came down himself.
[00:48:52.220 --> 00:48:53.220]   He wears ugs.
[00:48:53.220 --> 00:48:54.780]   No, stop it.
[00:48:54.780 --> 00:48:55.780]   Paper lugs.
[00:48:55.780 --> 00:48:56.780]   Paper lugs.
[00:48:56.780 --> 00:48:57.780]   And what did he say?
[00:48:57.780 --> 00:48:58.780]   Pugs.
[00:48:58.780 --> 00:48:59.780]   He didn't know what was going on.
[00:48:59.780 --> 00:49:00.780]   He's just smiling.
[00:49:00.780 --> 00:49:01.780]   I was like, okay.
[00:49:01.780 --> 00:49:02.780]   All right.
[00:49:02.780 --> 00:49:03.780]   Well, good night.
[00:49:03.780 --> 00:49:04.780]   Keep it down, boys.
[00:49:04.780 --> 00:49:13.780]   It was actually right before that one of the players had hit a D20 and did an impossible
[00:49:13.780 --> 00:49:14.780]   move.
[00:49:14.780 --> 00:49:17.740]   And so everyone was like, ah, right.
[00:49:17.740 --> 00:49:18.740]   Now he's a soccer fan.
[00:49:18.740 --> 00:49:21.060]   So he's, he's used to this kind of up.
[00:49:21.060 --> 00:49:22.060]   Argentina.
[00:49:22.060 --> 00:49:23.060]   Yeah.
[00:49:23.060 --> 00:49:24.060]   He's very happy right now.
[00:49:24.060 --> 00:49:25.060]   Very happy.
[00:49:25.060 --> 00:49:26.060]   Yeah.
[00:49:26.060 --> 00:49:27.060]   Did he watch the world?
[00:49:27.060 --> 00:49:28.060]   Oh, he did.
[00:49:28.060 --> 00:49:31.500]   Everyone in Italy watched it, even though Italy wasn't playing in the world.
[00:49:31.500 --> 00:49:32.500]   Yeah.
[00:49:32.500 --> 00:49:33.900]   But I forgot he was Argentinian.
[00:49:33.900 --> 00:49:37.260]   So he's really, he's a, he's a messy man.
[00:49:37.260 --> 00:49:38.260]   Oh, yeah.
[00:49:38.260 --> 00:49:43.540]   And you know, even the non Argentinian fans were happy like, look, messy deserved.
[00:49:43.540 --> 00:49:44.540]   Yeah.
[00:49:44.540 --> 00:49:46.260]   This is, this is the way to end his career.
[00:49:46.260 --> 00:49:47.260]   Yeah.
[00:49:47.260 --> 00:49:49.340]   But if he comes back next year, he's fair game.
[00:49:49.340 --> 00:49:50.340]   All right.
[00:49:50.340 --> 00:49:52.580]   We're going to take a little break.
[00:49:52.580 --> 00:49:57.860]   More stories of the Vatican catacombs coming up.
[00:49:57.860 --> 00:50:00.980]   It's so great to have Connie Gogoliamo here, editor and chief have seen it.
[00:50:00.980 --> 00:50:05.740]   Like the big shot, the man, the person in charge of the, I, so nice to have you.
[00:50:05.740 --> 00:50:08.780]   We really appreciate you taking some time to be with us.
[00:50:08.780 --> 00:50:15.180]   And of course, from beautiful Brooklyn, New York, where she has purple, what is it?
[00:50:15.180 --> 00:50:16.740]   Magenta plants binders.
[00:50:16.740 --> 00:50:17.740]   I like that.
[00:50:17.740 --> 00:50:20.940]   Listen, you know, I got a, got a little fun light back there.
[00:50:20.940 --> 00:50:21.940]   It's not a plan.
[00:50:21.940 --> 00:50:22.940]   It looks like your plan is.
[00:50:22.940 --> 00:50:24.500]   I mean, there is a plant.
[00:50:24.500 --> 00:50:28.100]   There is also kind of a, like a neon light back there.
[00:50:28.100 --> 00:50:29.100]   Oh, I see.
[00:50:29.100 --> 00:50:30.860]   It's melding with the plant.
[00:50:30.860 --> 00:50:33.580]   And then it looks like you have a shrine in your fireplace.
[00:50:33.580 --> 00:50:35.500]   I don't want to, I don't want to say anything.
[00:50:35.500 --> 00:50:41.500]   It's a little lamp that is in the shape of a man with a strategically placed light switch.
[00:50:41.500 --> 00:50:43.460]   Oh.
[00:50:43.460 --> 00:50:46.100]   So right now he is very on.
[00:50:46.100 --> 00:50:47.700]   He is so on.
[00:50:47.700 --> 00:50:48.700]   Okay.
[00:50:48.700 --> 00:50:50.700]   Got it.
[00:50:50.700 --> 00:50:54.700]   Paris Martenau from the information.
[00:50:54.700 --> 00:50:55.700]   We have more in just a bit.
[00:50:55.700 --> 00:50:58.780]   Our show today brought to you.
[00:50:58.780 --> 00:50:59.780]   Is it on his nose?
[00:50:59.780 --> 00:51:00.780]   On show.
[00:51:00.780 --> 00:51:01.780]   I like this.
[00:51:01.780 --> 00:51:03.260]   No, no, that is not his nose.
[00:51:03.260 --> 00:51:05.220]   Just think, think a little hard about it.
[00:51:05.220 --> 00:51:07.620]   You know, don't think too hard about it.
[00:51:07.620 --> 00:51:09.020]   No, no, no.
[00:51:09.020 --> 00:51:11.460]   Reject, reject a lot.
[00:51:11.460 --> 00:51:17.140]   This episode of Twit brought to you by a new sponsor welcoming decisions.
[00:51:17.140 --> 00:51:18.900]   Decisions is super cool.
[00:51:18.900 --> 00:51:24.340]   I spent some time with the decisions team and I really like this stuff.
[00:51:24.340 --> 00:51:29.900]   Decisions gives IT and business experts the tools they need to automate anything in your
[00:51:29.900 --> 00:51:35.820]   company all within one no code platform.
[00:51:35.820 --> 00:51:44.820]   Every business, every boss, every sea level executive says if I could just get this information
[00:51:44.820 --> 00:51:50.580]   automated, if they could just have, can I just have like a dashboard with this information?
[00:51:50.580 --> 00:51:54.500]   How do we get our business rules encapsulated in such a way that we can, we can incorporate
[00:51:54.500 --> 00:51:57.500]   this into our, and this is how you do it.
[00:51:57.500 --> 00:52:04.260]   Decisions, it can fix any business process and prepare you to withstand economic uncertainty.
[00:52:04.260 --> 00:52:09.740]   Resilience to the recession requires a deliberate management of resources and the flexibility
[00:52:09.740 --> 00:52:14.900]   to adapt at a moment's notice now is the time to take a look at decisions.
[00:52:14.900 --> 00:52:21.660]   There no code environment makes it easy for your team to get together, build workflows,
[00:52:21.660 --> 00:52:28.780]   adjust them, fine tune them dynamic forms, your decisioning processes, all your business
[00:52:28.780 --> 00:52:33.700]   rules to fit in with your unique and you know what, ever changing business needs because
[00:52:33.700 --> 00:52:36.820]   it's easy to adjust to adapt.
[00:52:36.820 --> 00:52:39.540]   This is really important with today's IT talent shortage, right?
[00:52:39.540 --> 00:52:43.180]   You can't just go downstairs and say, hey guys, could you code something up for me?
[00:52:43.180 --> 00:52:46.900]   No, not everybody has a Robert Ballis there, there.
[00:52:46.900 --> 00:52:51.220]   Decisions process automation software is a complete toolkit.
[00:52:51.220 --> 00:52:56.220]   So you know, in this business, so for so long you've got domain expertise and then you've
[00:52:56.220 --> 00:53:01.300]   got the technology expertise and it's often two different people and there's this issue
[00:53:01.300 --> 00:53:05.500]   where you communicate and it's not clear and you don't get quite what you wanted with
[00:53:05.500 --> 00:53:08.580]   decisions, you can do your own coding.
[00:53:08.580 --> 00:53:12.180]   If you're the domain expert, this is for you.
[00:53:12.180 --> 00:53:17.660]   There no code platform so powerful, it's got robust rules, workflow engines, a host
[00:53:17.660 --> 00:53:22.220]   of pre-built integrations and you know, you'll love these because you can connect to your
[00:53:22.220 --> 00:53:25.860]   legacy systems through their API.
[00:53:25.860 --> 00:53:29.220]   But you don't have to code it, you just drag and drop a visual interface design.
[00:53:29.220 --> 00:53:30.380]   So these integrations are great.
[00:53:30.380 --> 00:53:32.980]   You can say, well, let's pull from this, let's pull from that.
[00:53:32.980 --> 00:53:34.540]   Let's report to here.
[00:53:34.540 --> 00:53:39.380]   You can deploy it on prem or you can have decisions in the cloud.
[00:53:39.380 --> 00:53:40.380]   Decisions was very helpful.
[00:53:40.380 --> 00:53:45.540]   I have to tell you over the last few years during the pandemic, a lot of companies, you
[00:53:45.540 --> 00:53:48.780]   know, were caught flat-footed, but decisions customers, they could respond.
[00:53:48.780 --> 00:53:51.780]   I'll give you a perfect example.
[00:53:51.780 --> 00:53:55.180]   Remember the PPP loan thing you had like these banks were told, okay, we're going to
[00:53:55.180 --> 00:53:56.180]   do PPP loans.
[00:53:56.180 --> 00:53:57.180]   You ready?
[00:53:57.180 --> 00:53:58.700]   What do you mean you're ready?
[00:53:58.700 --> 00:54:02.060]   They're one of the largest private banks in the country.
[00:54:02.060 --> 00:54:06.860]   And this was announced, built an entire PPP loan application for small business in two
[00:54:06.860 --> 00:54:08.900]   days on decisions.
[00:54:08.900 --> 00:54:13.900]   As a result, they were first to market, issued a billion dollars in loans before anybody
[00:54:13.900 --> 00:54:17.060]   even started their app.
[00:54:17.060 --> 00:54:20.180]   That's the kind of thing this kind of nimble architecture could do for you.
[00:54:20.180 --> 00:54:26.620]   Two days, decisions, let's you customize workflows to automate the small decisions.
[00:54:26.620 --> 00:54:30.500]   That's why I guess they call it that producing faster results with greater accuracy, allowing
[00:54:30.500 --> 00:54:35.420]   your team to focus on all the important decisions, scale your business to better serve your
[00:54:35.420 --> 00:54:39.740]   customers while reducing operational costs, saving your team valuable time.
[00:54:39.740 --> 00:54:40.740]   I can go on and on.
[00:54:40.740 --> 00:54:43.340]   There's so many ways people are using decisions.
[00:54:43.340 --> 00:54:44.780]   So many things I'll give you an example.
[00:54:44.780 --> 00:54:45.940]   Otis elevator.
[00:54:45.940 --> 00:54:47.860]   You've heard of them.
[00:54:47.860 --> 00:54:49.340]   I didn't realize you were this big.
[00:54:49.340 --> 00:54:52.700]   Two million elevators all over the world.
[00:54:52.700 --> 00:54:56.220]   And of course, a lot of those elevators are using different automation systems.
[00:54:56.220 --> 00:54:58.380]   They don't talk to one another, right?
[00:54:58.380 --> 00:55:03.100]   It's needed a way to check every one of those two million elevators every single day.
[00:55:03.100 --> 00:55:07.900]   They call it a daily pulse check so that they will know ahead of time before an elevator
[00:55:07.900 --> 00:55:08.900]   is having problems.
[00:55:08.900 --> 00:55:11.820]   You don't want to find out after somebody's stuck in it or after the elevator fails.
[00:55:11.820 --> 00:55:15.380]   You want to know ahead of time so you can fix it and have a great uptime.
[00:55:15.380 --> 00:55:16.380]   So that's what they did.
[00:55:16.380 --> 00:55:20.380]   They used decisions to create automation software that handles all the integrations with the
[00:55:20.380 --> 00:55:22.820]   disparate systems.
[00:55:22.820 --> 00:55:27.020]   So they get their daily pulse check, two million units every single day, thanks to
[00:55:27.020 --> 00:55:28.020]   decisions.
[00:55:28.020 --> 00:55:32.700]   So that's a really good example of how this kind of software can transform your business
[00:55:32.700 --> 00:55:33.700]   process.
[00:55:33.700 --> 00:55:38.180]   And you'll be glad if you write in the notice elevator, you'll be glad to know they're keeping
[00:55:38.180 --> 00:55:39.860]   an eye on things, right?
[00:55:39.860 --> 00:55:44.500]   As the recession approaches, the durability of a business's foundational directly impact
[00:55:44.500 --> 00:55:46.500]   its performance and its ability to survive.
[00:55:46.500 --> 00:55:47.740]   How strong is your foundation?
[00:55:47.740 --> 00:55:49.700]   Are you ready?
[00:55:49.700 --> 00:55:55.220]   Even if even if everything goes great, there's always something, there's always something.
[00:55:55.220 --> 00:56:00.420]   It's automation platform provides a solution to any business challenge, automating anything,
[00:56:00.420 --> 00:56:05.900]   changing everything to improve your company's speed to market, improve your financial growth,
[00:56:05.900 --> 00:56:08.420]   your operational success.
[00:56:08.420 --> 00:56:12.420]   Decisions helps industry leaders alleviate bottlenecks and automate pain points in their
[00:56:12.420 --> 00:56:19.660]   business so you can do what's best to change the world and build your business.
[00:56:19.660 --> 00:56:23.220]   To learn more about decisions, no code automation platform.
[00:56:23.220 --> 00:56:24.540]   This is the one, by the way.
[00:56:24.540 --> 00:56:25.540]   This is amazing.
[00:56:25.540 --> 00:56:28.180]   Scope your free proof of concept.
[00:56:28.180 --> 00:56:30.260]   Just go to decisions.com/twit.
[00:56:30.260 --> 00:56:34.500]   D-E-C-I-S-I-O-N-S decisions, just like the word.
[00:56:34.500 --> 00:56:35.500]   .com/twit.
[00:56:35.500 --> 00:56:37.700]   We thank them so much for their support.
[00:56:37.700 --> 00:56:38.700]   I welcome them.
[00:56:38.700 --> 00:56:41.780]   I had a great conversation with this team and they blew me away.
[00:56:41.780 --> 00:56:43.340]   They show me example after example.
[00:56:43.340 --> 00:56:47.100]   You'll find out at the website, decisions.com/twit.
[00:56:47.100 --> 00:56:49.540]   I think you'll be very impressed.
[00:56:49.540 --> 00:56:52.740]   We thank them so much for supporting our show and thank you for supporting our show by going
[00:56:52.740 --> 00:56:53.940]   to that address so they know.
[00:56:53.940 --> 00:56:55.820]   They saw it on twit.
[00:56:55.820 --> 00:56:56.980]   Decisions.com/twit.
[00:56:56.980 --> 00:56:59.260]   That's very important to us.
[00:56:59.260 --> 00:57:00.260]   Thank your decisions.
[00:57:00.260 --> 00:57:03.060]   What else you got, Father Robert?
[00:57:03.060 --> 00:57:08.300]   I'm trying to do a commercial and he's setting up a vacuum cleaner.
[00:57:08.300 --> 00:57:14.060]   I do have to show this off because this was one of these things where the only reason
[00:57:14.060 --> 00:57:21.580]   why I went up to their suite was because they had one of the performers from NWA.
[00:57:21.580 --> 00:57:22.580]   He was up there.
[00:57:22.580 --> 00:57:23.580]   A rap star.
[00:57:23.580 --> 00:57:24.580]   A rap star.
[00:57:24.580 --> 00:57:29.220]   They had some really good food and I was looking for some evening entertainment.
[00:57:29.220 --> 00:57:30.220]   They did this.
[00:57:30.220 --> 00:57:31.860]   This is their P2.
[00:57:31.860 --> 00:57:35.220]   If you have pets, you know the one downside to a pet is what?
[00:57:35.220 --> 00:57:36.220]   Fur everywhere.
[00:57:36.220 --> 00:57:39.380]   Lots and lots of fur.
[00:57:39.380 --> 00:57:41.940]   They released this P1 early last year.
[00:57:41.940 --> 00:57:42.940]   It was a surprise hit.
[00:57:42.940 --> 00:57:44.860]   They sold like 50,000 units sold out the entire world.
[00:57:44.860 --> 00:57:45.780]   It's just for pets.
[00:57:45.780 --> 00:57:46.940]   It's just for pets.
[00:57:46.940 --> 00:57:48.140]   Not the pet itself.
[00:57:48.140 --> 00:57:49.140]   Not the pet itself.
[00:57:49.140 --> 00:57:50.140]   Pet owners.
[00:57:50.140 --> 00:57:51.140]   Pet owners.
[00:57:51.140 --> 00:57:55.380]   There's a bunch of attachments that connect to this thing that have a groomer, a clipper,
[00:57:55.380 --> 00:57:56.380]   a crush.
[00:57:56.380 --> 00:57:57.380]   Oh!
[00:57:57.380 --> 00:57:58.380]   Oh!
[00:57:58.380 --> 00:58:02.300]   And all the hair goes straight into the g
[00:58:02.300 --> 00:58:03.300]   Oh, I wanted it for Burke.
[00:58:03.300 --> 00:58:04.300]   Oh, Burke needs you to kind of shut it.
[00:58:04.300 --> 00:58:05.300]   Yeah, he's got a lot of hair.
[00:58:05.300 --> 00:58:06.300]   But the killer thing is when you turn this thing on,
[00:58:06.300 --> 00:58:07.460]   we get Burke hair everywhere.
[00:58:07.460 --> 00:58:09.300]   It's nearly silent.
[00:58:09.300 --> 00:58:10.940]   It's nearly silent.
[00:58:10.940 --> 00:58:13.300]   So you don't scare away the pets.
[00:58:13.300 --> 00:58:14.300]   Nice.
[00:58:14.300 --> 00:58:15.300]   I mean, come on.
[00:58:15.300 --> 00:58:16.300]   It's practical tech.
[00:58:16.300 --> 00:58:17.540]   Yeah, it's not earth shattering.
[00:58:17.540 --> 00:58:18.540]   Who's this from?
[00:58:18.540 --> 00:58:19.540]   What's the name that came out?
[00:58:19.540 --> 00:58:23.720]   N-A-K-A-S-A-N-E-A-K-A-S-A.
[00:58:23.720 --> 00:58:25.380]   Any Casa, Su Casa?
[00:58:25.380 --> 00:58:27.340]   Any Casa, Su Casa.
[00:58:27.340 --> 00:58:30.840]   And I think right now they're still doing their CES special thing.
[00:58:30.840 --> 00:58:33.660]   So you go on Amazon, it's like 129.
[00:58:33.660 --> 00:58:37.820]   And anyone who's ever bought a Dyson knows-- That's a good deal.
[00:58:37.820 --> 00:58:38.820]   That's a really good deal.
[00:58:38.820 --> 00:58:41.060]   You can't get a Dyson bag for 129.
[00:58:41.060 --> 00:58:42.060]   Right.
[00:58:42.060 --> 00:58:46.940]   But I've already played with one of these with the vadikats and they're feral, but they
[00:58:46.940 --> 00:58:47.940]   don't run from it.
[00:58:47.940 --> 00:58:48.940]   They're not scared of it.
[00:58:48.940 --> 00:58:52.220]   I thought they would be out of their minds.
[00:58:52.220 --> 00:58:53.220]   Go figure.
[00:58:53.220 --> 00:58:54.220]   Now--
[00:58:54.220 --> 00:58:55.220]   It's on Amazon?
[00:58:55.220 --> 00:58:56.220]   It's on Amazon.
[00:58:56.220 --> 00:58:58.220]   Nia-- just put P2.
[00:58:58.220 --> 00:58:59.220]   P2 vacuum.
[00:58:59.220 --> 00:59:00.220]   P2 pro.
[00:59:00.220 --> 00:59:02.020]   V-A-C-U-U-M.
[00:59:02.020 --> 00:59:07.460]   I don't-- it's-- remove the Nica-S-A.
[00:59:07.460 --> 00:59:08.460]   Don't do Nica-S-A.
[00:59:08.460 --> 00:59:10.700]   And it's N-E-A-K-A-S-A.
[00:59:10.700 --> 00:59:12.700]   N-E-A, Nia-Casa.
[00:59:12.700 --> 00:59:13.700]   Nia-Casa.
[00:59:13.700 --> 00:59:14.700]   Nia-Casa.
[00:59:14.700 --> 00:59:15.700]   Oh, I don't see it.
[00:59:15.700 --> 00:59:16.700]   Oh, where did it go?
[00:59:16.700 --> 00:59:17.700]   I know it's there somewhere.
[00:59:17.700 --> 00:59:21.500]   But this is problematic because I think what's happening is all the other vacuum cleaners
[00:59:21.500 --> 00:59:25.180]   have bought placement and you don't see them.
[00:59:25.180 --> 00:59:26.180]   Oh, there it is.
[00:59:26.180 --> 00:59:27.180]   Yeah.
[00:59:27.180 --> 00:59:28.180]   Nia-Casa.
[00:59:28.180 --> 00:59:29.180]   N-E-A-K-A-S-A.
[00:59:29.180 --> 00:59:30.180]   Oh, N-E-A.
[00:59:30.180 --> 00:59:31.180]   N-E-A.
[00:59:31.180 --> 00:59:34.180]   National Education Administration.
[00:59:34.180 --> 00:59:39.060]   Now, I was-- I really hoped Burke was going to be here because I kind of wanted to do a
[00:59:39.060 --> 00:59:40.060]   clipping.
[00:59:40.060 --> 00:59:42.500]   There's something wrong with my-- Amazon--
[00:59:42.500 --> 00:59:43.820]   Oh, it's one word.
[00:59:43.820 --> 00:59:45.540]   N-E-A-K-A-S-A.
[00:59:45.540 --> 00:59:46.540]   Okay.
[00:59:46.540 --> 00:59:48.260]   I'm so bad at this.
[00:59:48.260 --> 00:59:49.260]   K-A-S-A.
[00:59:49.260 --> 00:59:52.220]   Well, if they had a normal name, I could find it.
[00:59:52.220 --> 00:59:53.220]   Are they Japanese?
[00:59:53.220 --> 00:59:55.300]   No, they're located in Los Angeles.
[00:59:55.300 --> 00:59:59.820]   Why is it not-- I think Amazon is doing something here.
[00:59:59.820 --> 01:00:01.300]   I think Amazon doesn't want you to find it.
[01:00:01.300 --> 01:00:03.260]   Amazon does not want me to buy this.
[01:00:03.260 --> 01:00:04.260]   It's all my computer.
[01:00:04.260 --> 01:00:08.220]   How come it's coming up on yours and not online?
[01:00:08.220 --> 01:00:10.260]   You'd be too powerful if you had this-- Right.
[01:00:10.260 --> 01:00:11.260]   --if you had the ability to--
[01:00:11.260 --> 01:00:12.260]   Right.
[01:00:12.260 --> 01:00:13.260]   They don't want me to have the ability.
[01:00:13.260 --> 01:00:14.260]   Chatroop.
[01:00:14.260 --> 01:00:15.260]   Ant found it.
[01:00:15.260 --> 01:00:16.420]   Ant has two dogs.
[01:00:16.420 --> 01:00:17.420]   He needs it.
[01:00:17.420 --> 01:00:21.420]   I don't know what's wrong with my-- I kind of wanted to get one of these four--
[01:00:21.420 --> 01:00:22.420]   This tells me something.
[01:00:22.420 --> 01:00:28.500]   This tells me that Amazon is modifying the results for me, because I'm logged in.
[01:00:28.500 --> 01:00:29.500]   I saw it in real time.
[01:00:29.500 --> 01:00:30.500]   Yeah.
[01:00:30.500 --> 01:00:32.580]   It actually changed the term that you put in.
[01:00:32.580 --> 01:00:34.500]   That's a weird, weird, weird thing.
[01:00:34.500 --> 01:00:35.500]   129 bucks.
[01:00:35.500 --> 01:00:38.420]   The dog and the cat do not come with a back, by the way.
[01:00:38.420 --> 01:00:40.820]   So let me ask Connie and Paris this.
[01:00:40.820 --> 01:00:43.780]   Would this be a good anniversary gift for my wife?
[01:00:43.780 --> 01:00:45.300]   Absolutely not.
[01:00:45.300 --> 01:00:46.300]   I'm not going to ask them.
[01:00:46.300 --> 01:00:48.460]   Only if you want her to leave you.
[01:00:48.460 --> 01:00:49.460]   OK.
[01:00:49.460 --> 01:00:50.740]   I don't want that.
[01:00:50.740 --> 01:00:51.740]   OK.
[01:00:51.740 --> 01:00:52.740]   Never mind.
[01:00:52.740 --> 01:00:53.740]   Oh, my gosh.
[01:00:53.740 --> 01:00:54.740]   Honey, look what I got you.
[01:00:54.740 --> 01:00:55.740]   A vacuum.
[01:00:55.740 --> 01:00:57.740]   Wow, that sounds bad.
[01:00:57.740 --> 01:00:59.540]   That doesn't sound good.
[01:00:59.540 --> 01:01:03.100]   I'm celibate, and I know that's dangerous now.
[01:01:03.100 --> 01:01:05.900]   That's even the price knows that you like--
[01:01:05.900 --> 01:01:07.700]   Ooh, for your anniversary.
[01:01:07.700 --> 01:01:09.140]   I got you a new stove.
[01:01:09.140 --> 01:01:10.140]   It's the same kind of vibe.
[01:01:10.140 --> 01:01:13.980]   I was actually thinking-- Because I want to get an induction stove top.
[01:01:13.980 --> 01:01:16.660]   Wait, are you electric right now, or gas?
[01:01:16.660 --> 01:01:17.660]   I'm gas.
[01:01:17.660 --> 01:01:18.700]   You're gas, and you want to get induction.
[01:01:18.700 --> 01:01:19.700]   Wow.
[01:01:19.700 --> 01:01:22.340]   What do you have, Paris?
[01:01:22.340 --> 01:01:29.620]   I rent, so I have gas and get poisoned a bit every time I make any food.
[01:01:29.620 --> 01:01:31.340]   Today I tried to cook some French toast.
[01:01:31.340 --> 01:01:34.500]   My apartment smelled awful for a while afterwards.
[01:01:34.500 --> 01:01:37.100]   I'm probably losing brain cells.
[01:01:37.100 --> 01:01:39.460]   It's worse than the winter, because you can't open the windows, right?
[01:01:39.460 --> 01:01:40.460]   It's freezing.
[01:01:40.460 --> 01:01:41.460]   Is induction better?
[01:01:41.460 --> 01:01:43.460]   I thought induction was much better.
[01:01:43.460 --> 01:01:44.460]   Oh, the gas.
[01:01:44.460 --> 01:01:49.580]   Have you not-- OK, just because you guys are not on Twitter, you haven't seen the great
[01:01:49.580 --> 01:01:50.580]   gas debate.
[01:01:50.580 --> 01:01:52.100]   It's really on my way.
[01:01:52.100 --> 01:01:54.740]   I bet Ted Cruz has something to say about gas.
[01:01:54.740 --> 01:01:56.220]   Oh, I'm sure Ted.
[01:01:56.220 --> 01:01:59.580]   I'm sure Matt Gates has like seven tweets on gas right now.
[01:01:59.580 --> 01:02:00.580]   So what happened is there was--
[01:02:00.580 --> 01:02:02.220]   Actually, the scientist does.
[01:02:02.220 --> 01:02:09.500]   Ron DeSantis is going to pass along Florida banning the banning of gas.
[01:02:09.500 --> 01:02:11.420]   Can you ban a ban?
[01:02:11.420 --> 01:02:14.420]   OK, well, there was a study.
[01:02:14.420 --> 01:02:19.220]   So this came out of the-- I was at the-- who was it?
[01:02:19.220 --> 01:02:20.220]   Was it EPA?
[01:02:20.220 --> 01:02:27.460]   It was a study that is kind of weak that a certain percentage of childhood asthma, like
[01:02:27.460 --> 01:02:33.020]   16%, is caused by gas stoves, by natural gas.
[01:02:33.020 --> 01:02:39.300]   And the president actually had to put out a statement, "No, we are not banning gas stoves.
[01:02:39.300 --> 01:02:45.100]   Nevertheless, the loyal opposition has been jumping on this saying, 'You see, next they're
[01:02:45.100 --> 01:02:46.860]   going to come for the stoves.'"
[01:02:46.860 --> 01:02:48.580]   So let me get the straight.
[01:02:48.580 --> 01:02:54.100]   All the science pointing at masks and vaccinations being useful is not going to make a dent in
[01:02:54.100 --> 01:02:57.860]   his head, but a study about how gas causes asthma.
[01:02:57.860 --> 01:02:58.860]   Yeah.
[01:02:58.860 --> 01:02:59.860]   All right.
[01:02:59.860 --> 01:03:00.860]   Cool.
[01:03:00.860 --> 01:03:01.860]   I'm done.
[01:03:01.860 --> 01:03:04.380]   But honestly, I don't want to-- I would like to get rid of natural gas in my house for
[01:03:04.380 --> 01:03:05.460]   other reasons.
[01:03:05.460 --> 01:03:08.260]   And I want an induction stovetop.
[01:03:08.260 --> 01:03:11.060]   Like, Amazon won't let me find those either, so I don't know.
[01:03:11.060 --> 01:03:13.260]   I don't know what's going on with my Amazon.
[01:03:13.260 --> 01:03:14.260]   I don't know.
[01:03:14.260 --> 01:03:20.140]   Hey, ScooterX, did you check to see if your third-party tweets were going through or
[01:03:20.140 --> 01:03:21.140]   no?
[01:03:21.140 --> 01:03:23.140]   I'm just curious.
[01:03:23.140 --> 01:03:24.140]   All right.
[01:03:24.140 --> 01:03:28.900]   ScooterX, who is normally quite talkative, seems to have abandoned us.
[01:03:28.900 --> 01:03:31.820]   He's because he's cooking on his gas stove right now.
[01:03:31.820 --> 01:03:32.820]   ScooterX.
[01:03:32.820 --> 01:03:35.860]   He's passed out in his home right now.
[01:03:35.860 --> 01:03:40.540]   He's got asthma and has carbon monoxide poisoning in his home because of gas.
[01:03:40.540 --> 01:03:45.060]   Now, Connie, I don't want to put you on the spot.
[01:03:45.060 --> 01:03:50.060]   But since you're here, we should probably ask you about chat GPT.
[01:03:50.060 --> 01:03:51.060]   See, Net--
[01:03:51.060 --> 01:03:52.060]   Ooh.
[01:03:52.060 --> 01:03:56.260]   --used chat GPT to write-- no, you don't want to talk about this?
[01:03:56.260 --> 01:03:58.180]   No, no, I'm totally happy to talk about it.
[01:03:58.180 --> 01:03:59.780]   We didn't use chat GPT, though.
[01:03:59.780 --> 01:04:02.820]   Oh, use something else.
[01:04:02.820 --> 01:04:03.820]   You--
[01:04:03.820 --> 01:04:04.820]   Go ahead, man.
[01:04:04.820 --> 01:04:05.820]   --articles.
[01:04:05.820 --> 01:04:07.980]   This is the report, and that's why you're here.
[01:04:07.980 --> 01:04:09.180]   No, it's not why you're here.
[01:04:09.180 --> 01:04:14.100]   But now that you're here, I'm going to definitely ask you about it.
[01:04:14.100 --> 01:04:19.700]   Was AI of some sort was used to write articles about-- it was about personal finance.
[01:04:19.700 --> 01:04:26.620]   Now, I have to say, I think Scooter had handled it properly, saying, in fact, you know, they
[01:04:26.620 --> 01:04:29.420]   had a human review everything and all of that.
[01:04:29.420 --> 01:04:31.140]   Oh, here's your post.
[01:04:31.140 --> 01:04:32.140]   Look at that.
[01:04:32.140 --> 01:04:33.820]   Let's look at your post.
[01:04:33.820 --> 01:04:35.700]   And this is how it came out, I think.
[01:04:35.700 --> 01:04:36.700]   Yes.
[01:04:36.700 --> 01:04:37.700]   AI assists.
[01:04:37.700 --> 01:04:38.700]   OK, that's--
[01:04:38.700 --> 01:04:40.860]   So tell me what's going on.
[01:04:40.860 --> 01:04:50.060]   Yeah, so we have been using one team at Scooter, the personal money team, has been testing the
[01:04:50.060 --> 01:04:57.820]   use of an AI to write what we call basic explainers, like what is a credit card, what
[01:04:57.820 --> 01:05:02.660]   is compound interest, since the middle of November.
[01:05:02.660 --> 01:05:08.980]   And the stories had a byline, and if you clicked on it, it was seen at Money staff.
[01:05:08.980 --> 01:05:14.620]   And if you clicked on it, it said it was created in part with an automated technology
[01:05:14.620 --> 01:05:15.620]   AI agent.
[01:05:15.620 --> 01:05:16.620]   It says it right here.
[01:05:16.620 --> 01:05:17.620]   Yeah.
[01:05:17.620 --> 01:05:20.740]   Review, check, and edit it by our staff, so by humans.
[01:05:20.740 --> 01:05:24.780]   So we changed the-- it was a hover before.
[01:05:24.780 --> 01:05:28.420]   And then somebody, you know, found that we had been doing this.
[01:05:28.420 --> 01:05:30.540]   It wasn't a secret.
[01:05:30.540 --> 01:05:32.660]   But we didn't pre-announce that we were doing this.
[01:05:32.660 --> 01:05:33.900]   We didn't put out a press release.
[01:05:33.900 --> 01:05:35.820]   But that's a good way to test it, right?
[01:05:35.820 --> 01:05:37.460]   To see, you know.
[01:05:37.460 --> 01:05:39.820]   Well, that's-- it depends on your point of view.
[01:05:39.820 --> 01:05:40.820]   [LAUGHTER]
[01:05:40.820 --> 01:05:43.420]   But we did not pre-announce it.
[01:05:43.420 --> 01:05:47.900]   I mean, we told the staff internally that we were looking at an AI agent, and obviously
[01:05:47.900 --> 01:05:52.180]   the crew on the money team knew what was going on.
[01:05:52.180 --> 01:05:59.500]   And everything was checked and reviewed by an editor because the experiment that we're
[01:05:59.500 --> 01:06:05.180]   doing, which is ongoing, it's not done, is there's all this hype around this technology?
[01:06:05.180 --> 01:06:06.420]   How can it help you?
[01:06:06.420 --> 01:06:13.540]   And our model was, can it help for some kinds of stories where we don't have staff to write
[01:06:13.540 --> 01:06:16.780]   and does it actually save time for these editors?
[01:06:16.780 --> 01:06:19.100]   How long does it take to edit pieces?
[01:06:19.100 --> 01:06:24.620]   So we're going to be looking at all of that, like I think almost every media company is
[01:06:24.620 --> 01:06:28.140]   looking at different ways to get an assist from tech.
[01:06:28.140 --> 01:06:37.340]   And I will say as a longtime tech journalist, I worked at Bloomberg many a decade ago.
[01:06:37.340 --> 01:06:39.980]   There has been AI technology helping assist stories.
[01:06:39.980 --> 01:06:41.660]   It's just at various levels.
[01:06:41.660 --> 01:06:47.060]   Chat, chat, GBT is on this other extreme, which people have been talking about, like
[01:06:47.060 --> 01:06:50.300]   writing Shakespeare for you instead of Shakespeare.
[01:06:50.300 --> 01:06:52.980]   And that's not what I'm talking about here at all.
[01:06:52.980 --> 01:06:58.700]   But there have been stories that are auto written on the stock market, prices go up,
[01:06:58.700 --> 01:07:02.660]   prices go down, consumer index goes up, consumer index goes down.
[01:07:02.660 --> 01:07:05.220]   Those things haven't been going on for a very long time.
[01:07:05.220 --> 01:07:09.540]   Sports stories too have been written by computers for years.
[01:07:09.540 --> 01:07:16.060]   I mean, this has been going on for years, but that's because they're very mechanical.
[01:07:16.060 --> 01:07:18.060]   You can look at a box store and write that story.
[01:07:18.060 --> 01:07:19.540]   A human computer can write that story.
[01:07:19.540 --> 01:07:22.380]   It's anything with financial stories for the most part.
[01:07:22.380 --> 01:07:28.380]   So we don't know the answer yet to whether it's worthwhile, but we're trying to find
[01:07:28.380 --> 01:07:29.380]   a use case.
[01:07:29.380 --> 01:07:35.660]   And in this case, the use case was these basic explainers that we have a staff of really
[01:07:35.660 --> 01:07:40.100]   smart talented reporters and if I said to them, "Could you write a basic explainer
[01:07:40.100 --> 01:07:42.980]   or could you write an in-depth feature and go and interview people?"
[01:07:42.980 --> 01:07:48.020]   I know where they want to spend their time, but you have to have some of that other, those
[01:07:48.020 --> 01:07:52.460]   basic explainers are valuable, it's just a matter of resources.
[01:07:52.460 --> 01:07:57.180]   So that's what the test was and that's what I wrote in that blog post and anyone can read
[01:07:57.180 --> 01:07:58.180]   for themselves.
[01:07:58.180 --> 01:08:00.780]   Was this your idea?
[01:08:00.780 --> 01:08:03.380]   It was not my idea.
[01:08:03.380 --> 01:08:05.740]   I am like most journalists.
[01:08:05.740 --> 01:08:07.700]   I am slow to adopt new technology.
[01:08:07.700 --> 01:08:13.900]   I always like to pick the tires and test things and understand the implications, but we are
[01:08:13.900 --> 01:08:18.700]   out of that, the beginning of a process with some of this AI tech, like I said, to auto
[01:08:18.700 --> 01:08:21.580]   insert numbers and stories.
[01:08:21.580 --> 01:08:25.060]   We report on mortgage rates as part of that money team.
[01:08:25.060 --> 01:08:28.740]   Those numbers are auto insert and just stock prices are inserted.
[01:08:28.740 --> 01:08:34.260]   So it's part of a process of looking at that technology that I think warrants the same
[01:08:34.260 --> 01:08:37.460]   kind of scrutiny that CNET would give to any other technology.
[01:08:37.460 --> 01:08:42.860]   And I linked to some examples of stories there where we looked at duplex when it first came
[01:08:42.860 --> 01:08:46.700]   at and where like, "Is this Google duplex a good idea or not?"
[01:08:46.700 --> 01:08:51.540]   I went and looked at the magic leap, headset when it was announced.
[01:08:51.540 --> 01:08:53.700]   Is it BS or is it brilliant?
[01:08:53.700 --> 01:08:59.060]   This is what we do and I hope other people are doing as well because you can be afraid
[01:08:59.060 --> 01:09:05.140]   of the future and what tech might bring or you can be part of helping define how to usher
[01:09:05.140 --> 01:09:06.780]   it in.
[01:09:06.780 --> 01:09:08.500]   I found a use case.
[01:09:08.500 --> 01:09:09.500]   What's that?
[01:09:09.500 --> 01:09:14.620]   We actually wrote about it for Amy Webb's Future Today Institute.
[01:09:14.620 --> 01:09:19.100]   Using chat GPT-3, I was able to create a honey bot.
[01:09:19.100 --> 01:09:20.900]   So the code or?
[01:09:20.900 --> 01:09:21.900]   No, no.
[01:09:21.900 --> 01:09:22.900]   Yeah.
[01:09:22.900 --> 01:09:25.060]   So we use the bot and populated it.
[01:09:25.060 --> 01:09:26.740]   It's with content from chat.
[01:09:26.740 --> 01:09:31.140]   Will content specifically relating to network topology?
[01:09:31.140 --> 01:09:32.140]   Oh, interesting.
[01:09:32.140 --> 01:09:36.300]   So if someone was trying to hack the network rather than denying them like a traditional
[01:09:36.300 --> 01:09:39.900]   IPS would, just blocking them at the source so they can't get into the network, it would
[01:09:39.900 --> 01:09:42.620]   actually simulate an intrusion.
[01:09:42.620 --> 01:09:46.740]   So someone thinks they're in the network and it's entirely a fiction created by chat
[01:09:46.740 --> 01:09:47.740]   GPT-3.
[01:09:47.740 --> 01:09:49.740]   And it's plausible.
[01:09:49.740 --> 01:09:50.900]   It's plausible.
[01:09:50.900 --> 01:09:57.540]   And the instance I was using wasn't specifically tuned for that, but it still gave an incredible
[01:09:57.540 --> 01:10:00.140]   simulation of, "Yeah, this is what an intrusion would look like."
[01:10:00.140 --> 01:10:01.260]   So imagine that.
[01:10:01.260 --> 01:10:06.140]   Your network defense is just making up stuff on the fly so that someone attacking your
[01:10:06.140 --> 01:10:07.140]   network.
[01:10:07.140 --> 01:10:10.020]   Oh, I think there's lots of cool and appropriate uses for that.
[01:10:10.020 --> 01:10:13.580]   Do you want to talk about how you did it, Connie, or is that a state secret?
[01:10:13.580 --> 01:10:17.100]   Oh, we're not talking about it, Pian, what I wrote in that.
[01:10:17.100 --> 01:10:19.580]   Except that it was not chat GPT.
[01:10:19.580 --> 01:10:21.500]   No, it was.
[01:10:21.500 --> 01:10:26.420]   But there's a lot of tools like chat GPT is by no means unique.
[01:10:26.420 --> 01:10:29.220]   Paris as a reporter.
[01:10:29.220 --> 01:10:30.380]   What's your attitude towards this?
[01:10:30.380 --> 01:10:35.780]   I mean, were this might affect your living?
[01:10:35.780 --> 01:10:36.780]   Not really.
[01:10:36.780 --> 01:10:41.580]   I'm not particularly worried that it would affect my living because I think the sort of
[01:10:41.580 --> 01:10:42.580]   journalism.
[01:10:42.580 --> 01:10:44.180]   I think it's just what Connie said.
[01:10:44.180 --> 01:10:50.020]   Most reporters probably don't want to spend their time doing these sort of necessary,
[01:10:50.020 --> 01:10:54.540]   but maybe slightly more rote work and part of journalism.
[01:10:54.540 --> 01:10:58.460]   And instead they'd rather spend their time working on larger features or bigger reporting
[01:10:58.460 --> 01:10:59.460]   projects.
[01:10:59.460 --> 01:11:04.100]   And I think that these sort of tools can be a great way to augment your workflow, where
[01:11:04.100 --> 01:11:09.980]   instead of, you know, I had worked at publications where you'd have to not churn out a bunch
[01:11:09.980 --> 01:11:14.500]   of content, but for lack of a better word, churn out a bunch of content because that's
[01:11:14.500 --> 01:11:15.940]   part of the job.
[01:11:15.940 --> 01:11:21.460]   And if you had a way to do that very quickly, and then you could spend most of your hours
[01:11:21.460 --> 01:11:26.140]   working on the sort of stories that matter most to you, I think that's good.
[01:11:26.140 --> 01:11:31.620]   I have to wonder, are there any reporters who aren't, at least enlisting a little help
[01:11:31.620 --> 01:11:36.820]   from chat GPT on some of these boring, rote bits?
[01:11:36.820 --> 01:11:39.420]   I completely understand that.
[01:11:39.420 --> 01:11:41.580]   And Connie, you did the right thing.
[01:11:41.580 --> 01:11:43.060]   You've got a human reviewing it.
[01:11:43.060 --> 01:11:51.900]   The only issue with chat GPT is it's, sometimes it's confidently wrong, right?
[01:11:51.900 --> 01:11:57.660]   It says it was such assurance that you go, it must be right, and it isn't.
[01:11:57.660 --> 01:11:59.780]   And so you check that obviously.
[01:11:59.780 --> 01:12:03.820]   Again, I don't, I don't use chat GPT, so I can't speak to you.
[01:12:03.820 --> 01:12:04.780]   Oh, you got to try it.
[01:12:04.780 --> 01:12:05.780]   It's very, yeah.
[01:12:05.780 --> 01:12:06.780]   Exactly.
[01:12:06.780 --> 01:12:11.100]   Well, I watched, I'm sorry, I was going to say I watched Ryan Reynolds use it in his
[01:12:11.100 --> 01:12:12.100]   ad from his mobile.
[01:12:12.100 --> 01:12:13.100]   Wasn't that wild and mobile?
[01:12:13.100 --> 01:12:14.100]   Yeah.
[01:12:14.100 --> 01:12:20.140]   When I think the key to any time there's a new technology used, and certainly in this
[01:12:20.140 --> 01:12:26.340]   case where they're completely valid and legitimate concerns about, you know, is it going to
[01:12:26.340 --> 01:12:31.460]   take people's jobs away because I'm sure every tech takes people's jobs away, but it's to
[01:12:31.460 --> 01:12:32.860]   label the content.
[01:12:32.860 --> 01:12:35.420]   And we didn't label it as clearly.
[01:12:35.420 --> 01:12:37.340]   You had to hover and click to find out.
[01:12:37.340 --> 01:12:41.940]   So that changed this week where we said, well, just let's just say it and let's not
[01:12:41.940 --> 01:12:42.940]   back away.
[01:12:42.940 --> 01:12:47.660]   But our other publications that are using the technology today, being us forthright and
[01:12:47.660 --> 01:12:52.700]   labeling and being transparent about who created what content.
[01:12:52.700 --> 01:12:57.140]   That's something that has to happen as a discussion in the industry as a whole.
[01:12:57.140 --> 01:13:02.780]   So I'm not saying that, you know, like I said, that the jury's still out and how and what
[01:13:02.780 --> 01:13:08.180]   the use cases might be, but I think making sure that we're labeling this stuff and we're
[01:13:08.180 --> 01:13:13.860]   also not afraid to test it and try it as part of the path forward.
[01:13:13.860 --> 01:13:19.420]   You know, one of the reasons why this story has hit so hard is we did not expect the advancements
[01:13:19.420 --> 01:13:22.300]   in GPT to come as quickly as they did.
[01:13:22.300 --> 01:13:28.300]   If you look at text that has been written by GPT to, you can tell that it was auto generator
[01:13:28.300 --> 01:13:32.020]   because it will find a couple of facts, a couple of the nuggets that it wants to put
[01:13:32.020 --> 01:13:35.180]   in and then it just keeps repeating them in different ways.
[01:13:35.180 --> 01:13:39.740]   So it's a pretty easy way to figure out that this is an auto generator piece of content.
[01:13:39.740 --> 01:13:42.420]   Chat GPT three doesn't do that.
[01:13:42.420 --> 01:13:47.340]   It is an order of magnitude more sophisticated than GPT to and we did not expect that they'd
[01:13:47.340 --> 01:13:49.780]   be able to get to that level this quickly.
[01:13:49.780 --> 01:13:54.700]   Now the question is, well, when they release the next version that is using more than 175
[01:13:54.700 --> 01:13:59.340]   billion different parameters to do its predictive texting, what are we going to get?
[01:13:59.340 --> 01:14:05.300]   I mean, it's already at the point that I have had inquiries from some of our universities
[01:14:05.300 --> 01:14:09.220]   on how can we detect auto generated content from students?
[01:14:09.220 --> 01:14:12.980]   And I've told them, well, right now, until we come up with something more sophisticated,
[01:14:12.980 --> 01:14:16.260]   what you need to do is you have to get a baseline sample of the writing from the students at
[01:14:16.260 --> 01:14:18.020]   the very beginning of the course.
[01:14:18.020 --> 01:14:19.700]   Because that's the only way you're going to be able to tell.
[01:14:19.700 --> 01:14:22.700]   You're not going to find the errors in GPT three.
[01:14:22.700 --> 01:14:23.700]   Yeah.
[01:14:23.700 --> 01:14:29.860]   Jeff Jarvis has talked about a teacher who's going to use chat GPT in her English classes.
[01:14:29.860 --> 01:14:34.100]   And I think that's probably the case is that it's foolish to hide your head in the sand.
[01:14:34.100 --> 01:14:38.580]   And I agree with you, it feels like we are at an inflection point that there's some sort
[01:14:38.580 --> 01:14:46.140]   of Cambrian explosion going on with AI, not just text, but with the illustration as well.
[01:14:46.140 --> 01:14:49.820]   And AI voices have gotten better and better and better.
[01:14:49.820 --> 01:14:53.620]   And I think very, very interesting.
[01:14:53.620 --> 01:14:58.580]   So yeah, I'm not one of the people who was critical of seeing it at all.
[01:14:58.580 --> 01:15:01.900]   Because I think you did it the kind of, if you're going to do it the right way, and
[01:15:01.900 --> 01:15:04.460]   I think there is a good use case for it.
[01:15:04.460 --> 01:15:09.260]   And that people like Paris will always have work because no, somebody, I wish I could
[01:15:09.260 --> 01:15:10.260]   find the source.
[01:15:10.260 --> 01:15:14.860]   I think it was on our Twitter, Masson on somebody said, chat GPT is just basically the ultimate
[01:15:14.860 --> 01:15:16.980]   mansplaining.
[01:15:16.980 --> 01:15:24.460]   It's just this confident, patronizing voice saying, well, well, actually, actually, just
[01:15:24.460 --> 01:15:26.060]   in case you didn't know.
[01:15:26.060 --> 01:15:27.340]   And then it's confidently wrong.
[01:15:27.340 --> 01:15:31.860]   Stephen Wolfram of Wolfram Alpha, who is, I think arguably one of the geniuses of our
[01:15:31.860 --> 01:15:37.460]   time wrote a very interesting piece about how chat GPT might use Wolfram Alpha to correct
[01:15:37.460 --> 01:15:38.620]   the stuff that gets wrong.
[01:15:38.620 --> 01:15:45.300]   He talks about some of the confidently wrong conclusions chat GPT comes up with like this.
[01:15:45.300 --> 01:15:50.740]   How far is it from Tokyo to Chicago and chat GPT gets it wrong.
[01:15:50.740 --> 01:15:55.940]   It says, well, the distance is 76,000 miles, a very long distance would take a significant
[01:15:55.940 --> 01:15:58.140]   amount of time to travel one place the other.
[01:15:58.140 --> 01:16:01.580]   The flight to Tokyo from Chicago is about 16 hours.
[01:16:01.580 --> 01:16:04.020]   Well, it sounds pretty convincing, but it's wrong.
[01:16:04.020 --> 01:16:12.140]   Because if you ask Wolfram Alpha, instead of 7,600 miles, it's 6,313 miles.
[01:16:12.140 --> 01:16:19.500]   And he says, by the way, you can teach chat GPT by adding that information.
[01:16:19.500 --> 01:16:22.540]   And then chat GPT says, well, thank you for correcting me.
[01:16:22.540 --> 01:16:23.540]   You're correct.
[01:16:23.540 --> 01:16:29.540]   The distance from Chicago is 613,600, 13 miles.
[01:16:29.540 --> 01:16:31.020]   And then you can ask it again.
[01:16:31.020 --> 01:16:32.420]   And it will then get it right.
[01:16:32.420 --> 01:16:33.420]   Okay.
[01:16:33.420 --> 01:16:35.380]   So it's very important to learn which is very interesting.
[01:16:35.380 --> 01:16:40.700]   So his premise is there are things that because of the way Wolfram Alpha works, Wolfram Alpha
[01:16:40.700 --> 01:16:48.220]   knows that three to the power of 73, which is not 14 billion, but in fact, a different
[01:16:48.220 --> 01:16:55.260]   number, much larger, that it could be working with chat GPT to fix it.
[01:16:55.260 --> 01:17:00.100]   But people should be very careful about chat GPT, especially when it comes to factual matters.
[01:17:00.100 --> 01:17:01.100]   It is mansplaining.
[01:17:01.100 --> 01:17:07.260]   I just came up a pitch for a show, a new Twitch show with two hosts, and both of them are
[01:17:07.260 --> 01:17:10.500]   chat GPT-3 with text to speech enabled.
[01:17:10.500 --> 01:17:11.500]   I love it.
[01:17:11.500 --> 01:17:15.020]   I mean, I'm telling you right now, you could have a hit, just make it a 15 minute hit a
[01:17:15.020 --> 01:17:17.060]   day and just auto generates.
[01:17:17.060 --> 01:17:18.380]   I'll code it for you.
[01:17:18.380 --> 01:17:20.620]   Does that resonate Connie and Paris?
[01:17:20.620 --> 01:17:25.500]   Is chat GPT basically a mansplainer?
[01:17:25.500 --> 01:17:29.260]   I mean, I think that it's just...
[01:17:29.260 --> 01:17:33.740]   I think that these tools are useful for their very specific use case.
[01:17:33.740 --> 01:17:38.460]   It is taking a large amount of information, aggregating it and spitting that out.
[01:17:38.460 --> 01:17:42.540]   I think that in some cases it'll be right, in some cases it'll be wrong.
[01:17:42.540 --> 01:17:47.620]   The fact is it's taking in a large amount of information, and what you're getting is
[01:17:47.620 --> 01:17:53.580]   it's, you know, version of what it thinks is important and what it thinks is correct.
[01:17:53.580 --> 01:17:55.540]   So it's never going to reflect the world.
[01:17:55.540 --> 01:18:00.300]   It's never explaining anything in particular, it is just kind of synthesizing.
[01:18:00.300 --> 01:18:01.300]   It reminds me a lot of...
[01:18:01.300 --> 01:18:03.180]   I'm a big Redditor.
[01:18:03.180 --> 01:18:04.180]   It's been my...
[01:18:04.180 --> 01:18:07.780]   We're talking about social media lately, the social media network I guess I've been turning
[01:18:07.780 --> 01:18:10.260]   towards more lately as Twitter has died, is Reddit.
[01:18:10.260 --> 01:18:11.260]   I agree.
[01:18:11.260 --> 01:18:15.900]   And then all these little bots in there where it's like, "Oh, we're going to try and take
[01:18:15.900 --> 01:18:20.740]   the article that was posted and give you the TLDR if you've bought."
[01:18:20.740 --> 01:18:22.660]   And most of the time it's wrong.
[01:18:22.660 --> 01:18:23.660]   Sometimes it's right though.
[01:18:23.660 --> 01:18:28.020]   I think that's like a little fun experiment is seeing what does the computer think that
[01:18:28.020 --> 01:18:30.300]   this actually means.
[01:18:30.300 --> 01:18:35.060]   There's the other issue which is the people who created the original content that these
[01:18:35.060 --> 01:18:37.940]   AI are using, whether they're artists or writers.
[01:18:37.940 --> 01:18:42.020]   Our friend Alex Cantrowitz, who is a regular on the show and writes the big technology
[01:18:42.020 --> 01:18:47.660]   sub-stack, said, "A writer used AI to plagiarize me now what?"
[01:18:47.660 --> 01:18:50.580]   And I was taken in by the way, by this writer.
[01:18:50.580 --> 01:18:52.220]   Maybe you saw it.
[01:18:52.220 --> 01:19:00.580]   It's a sub-stack called "The Rationalist" which looks like it's written by a human, is not.
[01:19:00.580 --> 01:19:03.180]   It plagiarized one of his posts on the creator economy.
[01:19:03.180 --> 01:19:04.420]   I saw this post.
[01:19:04.420 --> 01:19:10.300]   It was on the front page of Hacker News, a post that said the 1% in the creator economy
[01:19:10.300 --> 01:19:11.700]   are taking all the money.
[01:19:11.700 --> 01:19:13.420]   There's no middle class.
[01:19:13.420 --> 01:19:18.140]   It turns out Alex had written this some days before.
[01:19:18.140 --> 01:19:20.300]   The rationalist, he says, is an odd publication.
[01:19:20.300 --> 01:19:25.140]   He has no mission, no named authors outside of Petra.
[01:19:25.140 --> 01:19:30.140]   It's been live for a week, yet two days after when Live was lifting passages directly from
[01:19:30.140 --> 01:19:34.140]   big technology and he has the smoking gun for that.
[01:19:34.140 --> 01:19:39.100]   The flashy headline, the creator economy, the top 1% and everyone else helped propel
[01:19:39.100 --> 01:19:42.740]   his story to the Hacker News front page.
[01:19:42.740 --> 01:19:43.740]   It was his story.
[01:19:43.740 --> 01:19:48.220]   This was the first thing that kind of came to my mind when you were asking earlier about
[01:19:48.220 --> 01:19:52.580]   what I thought about potentially, whether this is going to put journalists out of a job
[01:19:52.580 --> 01:19:57.780]   or something, is I feel like oftentimes in the news industry, we end up having these plagiarism
[01:19:57.780 --> 01:20:02.860]   scandals that, I mean in some cases obviously it's people taking huge sections of someone
[01:20:02.860 --> 01:20:08.620]   else's work, but oftentimes it's been like someone lifts a couple sentences or a paragraph.
[01:20:08.620 --> 01:20:16.260]   I think if you had publications running unchecked on AI generated content like this editorial
[01:20:16.260 --> 01:20:18.420]   oversight, that would happen all the time.
[01:20:18.420 --> 01:20:23.940]   This exact example because aggregating other people's information is going to result in
[01:20:23.940 --> 01:20:24.940]   plagiarism.
[01:20:24.940 --> 01:20:28.140]   It's kind of like what we're seeing with AI art right now.
[01:20:28.140 --> 01:20:29.380]   I was totally fooled by this.
[01:20:29.380 --> 01:20:31.180]   I booked Mark the Story.
[01:20:31.180 --> 01:20:35.220]   I talked about it on some of the shows.
[01:20:35.220 --> 01:20:40.660]   At no point does it say it's AI written, but it is.
[01:20:40.660 --> 01:20:42.660]   Was it lifting or was it transforming?
[01:20:42.660 --> 01:20:43.660]   Yeah.
[01:20:43.660 --> 01:20:46.740]   That's the story as I scroll through my social media feed.
[01:20:46.740 --> 01:20:49.180]   I am inundated with the carefully curated lives.
[01:20:49.180 --> 01:20:52.460]   It's quite well written by the way.
[01:20:52.460 --> 01:20:55.020]   It's a little bit scary.
[01:20:55.020 --> 01:21:00.100]   If it's a sub stack newsletter, it could conceivably make a lot of money.
[01:21:00.100 --> 01:21:06.820]   Although some of the commoners did note, this sounds like an artificial intelligence.
[01:21:06.820 --> 01:21:09.940]   We're getting better, aren't we, at detecting this stuff?
[01:21:09.940 --> 01:21:17.060]   I'm impressed because I didn't detect it, but I think some people are smart enough to pick
[01:21:17.060 --> 01:21:18.060]   it up.
[01:21:18.060 --> 01:21:23.820]   To me, this goes back to even the discussion about social media and what technology has
[01:21:23.820 --> 01:21:30.060]   caused in our culture, which is distressed of the people and news sources that are out
[01:21:30.060 --> 01:21:31.060]   there.
[01:21:31.060 --> 01:21:36.620]   If we could just all take a moment, hacker news, to vet who they're amplifying and do
[01:21:36.620 --> 01:21:39.820]   some due diligence and check.
[01:21:39.820 --> 01:21:45.420]   They don't say that it's an AI, but okay, have a whitelist of sites that you will pull
[01:21:45.420 --> 01:21:46.420]   from.
[01:21:46.420 --> 01:21:51.340]   If someone wants to join your whitelist, then have them apply to join your whitelist.
[01:21:51.340 --> 01:21:56.100]   This was an argument that came out years ago with Google News about, "Oh, we're feeding
[01:21:56.100 --> 01:21:57.740]   the disinformation cycle."
[01:21:57.740 --> 01:21:59.820]   I wrote a column proposing this.
[01:21:59.820 --> 01:22:02.300]   Don't label what you're putting out there as news.
[01:22:02.300 --> 01:22:04.180]   Don't put it in the Google News feed.
[01:22:04.180 --> 01:22:06.660]   Have a whitelist.
[01:22:06.660 --> 01:22:11.180]   Why people to join be very clear about what it takes to join that whitelist and be transparent
[01:22:11.180 --> 01:22:17.620]   about it so that at least people can trust that it's not being written by an AI or it's
[01:22:17.620 --> 01:22:21.740]   been plagiarized by someone else because I think we all have examples.
[01:22:21.740 --> 01:22:26.100]   Paris and I have our work showing up under someone else's byline very clearly.
[01:22:26.100 --> 01:22:27.100]   What is the recourse?
[01:22:27.100 --> 01:22:32.780]   If you work for a media organization, their legal department can send a takedown notice.
[01:22:32.780 --> 01:22:33.980]   Not everyone can do that.
[01:22:33.980 --> 01:22:35.660]   That's a process.
[01:22:35.660 --> 01:22:38.340]   We could hurt you in your business.
[01:22:38.340 --> 01:22:43.540]   We all have to get smarter about what we're reading and who we trust and how we consume
[01:22:43.540 --> 01:22:44.540]   this stuff.
[01:22:44.540 --> 01:22:49.020]   That's not something that happens today, but something I think that should be taught in
[01:22:49.020 --> 01:22:54.140]   schools starting from second or third grade or whatever makes sense.
[01:22:54.140 --> 01:23:00.700]   I'm not a teacher, but we need to be more conscious because there is a ripple effect.
[01:23:00.700 --> 01:23:06.180]   After it's plagiarized by an AI or another human being, Alex Kantruitz was screwed for
[01:23:06.180 --> 01:23:07.180]   somebody.
[01:23:07.180 --> 01:23:12.180]   At the end of the day, that's the message, that his work was co-opted.
[01:23:12.180 --> 01:23:14.660]   What is his recourse?
[01:23:14.660 --> 01:23:15.660]   He's the victim.
[01:23:15.660 --> 01:23:19.020]   Does he have to somehow defend himself?
[01:23:19.020 --> 01:23:21.300]   Why is he allowed to be victimized?
[01:23:21.300 --> 01:23:24.900]   How can we prevent the victimization, if you will?
[01:23:24.900 --> 01:23:32.300]   I think we're starting to see this question be asked and in some ways answered in the
[01:23:32.300 --> 01:23:36.940]   art world, given the proliferation of AI tools there.
[01:23:36.940 --> 01:23:42.060]   I believe just yesterday there was a class action filed against stability, AI, and
[01:23:42.060 --> 01:23:48.220]   attorney, and deviant art for DMCA violations, publicity violations, unlawful competition,
[01:23:48.220 --> 01:23:52.300]   and breach of terms of service by this large group of artists.
[01:23:52.300 --> 01:23:59.460]   Obviously, the work that is being generated by these companies or makers of AI tools is
[01:23:59.460 --> 01:24:04.860]   built off the back of artists who have their work on the internet.
[01:24:04.860 --> 01:24:13.260]   It's funny, I would have thought that deviant art was the sewer instead of one of the defendants,
[01:24:13.260 --> 01:24:16.380]   because most of the stuff on deviant art, at least until recently, was written, was done
[01:24:16.380 --> 01:24:17.380]   by humans.
[01:24:17.380 --> 01:24:21.100]   I would have thought, oh, those humans were upset about their art being, because that's
[01:24:21.100 --> 01:24:25.860]   exactly what stability is able to fuse these scrapes and all the other things.
[01:24:25.860 --> 01:24:30.980]   But I guess there's so much AI art appearing on deviant art now that they are--
[01:24:30.980 --> 01:24:35.700]   Apparently, so I didn't realize this, but apparently deviant art has this product dream
[01:24:35.700 --> 01:24:42.460]   up, the lawsuit claims unlawfully infringes in the rights of its own art community, I
[01:24:42.460 --> 01:24:45.180]   guess by generating AI art.
[01:24:45.180 --> 01:24:46.180]   Interesting.
[01:24:46.180 --> 01:24:53.860]   I mean, this is kind of the other side of this AI stuff is the machine learning comes
[01:24:53.860 --> 01:25:01.180]   from publicly available content, whether text or art or sound.
[01:25:01.180 --> 01:25:04.180]   That's how you train these giant models.
[01:25:04.180 --> 01:25:05.180]   That's going to be a big--
[01:25:05.180 --> 01:25:06.180]   That's the future.
[01:25:06.180 --> 01:25:08.260]   Let's take GPG-3 and get around it.
[01:25:08.260 --> 01:25:14.260]   It has 175 billion possible parameters that it can draw from when it's generating its
[01:25:14.260 --> 01:25:15.340]   content.
[01:25:15.340 --> 01:25:20.460]   So I could foresee them making some sort of regulations on what kind of data you can
[01:25:20.460 --> 01:25:23.980]   feed to a narrow AI.
[01:25:23.980 --> 01:25:28.500]   It can't just be, here's the internet, take it, because you're going to get so much misinformation,
[01:25:28.500 --> 01:25:32.180]   you're going to get so much copyrighted material, you're going to have to start seeing responsible
[01:25:32.180 --> 01:25:36.740]   companies saying, we've generated our own data set based on things that we've sampled
[01:25:36.740 --> 01:25:41.700]   and we know that it can generate content that is not copyrighted.
[01:25:41.700 --> 01:25:45.700]   We don't have that yet, but that's where we're going to be going if these start to catch
[01:25:45.700 --> 01:25:46.700]   on.
[01:25:46.700 --> 01:25:50.340]   If you actually start to see these being used in a professional environment, that's just
[01:25:50.340 --> 01:25:51.940]   going to be part of the legal due diligence.
[01:25:51.940 --> 01:25:59.260]   If you don't have a parameter set that is free from claim, it's not usable in a commercial
[01:25:59.260 --> 01:26:00.260]   setting.
[01:26:00.260 --> 01:26:01.260]   Yeah.
[01:26:01.260 --> 01:26:04.900]   I'm concerned because voice is the next frontier on this.
[01:26:04.900 --> 01:26:07.220]   It's completely possible to steal my voice.
[01:26:07.220 --> 01:26:08.220]   100%.
[01:26:08.220 --> 01:26:10.220]   Yeah, especially because there's many names.
[01:26:10.220 --> 01:26:12.220]   What you're saying, there's some samples of your voice.
[01:26:12.220 --> 01:26:14.260]   A few, maybe a few.
[01:26:14.260 --> 01:26:15.260]   And my image too.
[01:26:15.260 --> 01:26:21.740]   Now, I would love to use this myself to create a virtual Leo that I could then go home and
[01:26:21.740 --> 01:26:23.060]   let it take over the shows.
[01:26:23.060 --> 01:26:25.140]   And maybe then a few years, that is what we'll have.
[01:26:25.140 --> 01:26:27.780]   Would you trust Ant with virtual Leo?
[01:26:27.780 --> 01:26:29.900]   Yeah, I would.
[01:26:29.900 --> 01:26:35.380]   What we'd have to do is see that could be Padre's version of the show is that two co-hosts,
[01:26:35.380 --> 01:26:36.380]   it's both Leo.
[01:26:36.380 --> 01:26:39.380]   You would be dressed in claims and jerseys all year.
[01:26:39.380 --> 01:26:43.100]   This is a company called 11 Labs.
[01:26:43.100 --> 01:26:44.100]   This is from their blog.
[01:26:44.100 --> 01:26:45.220]   This voice doesn't exist.
[01:26:45.220 --> 01:26:51.220]   Genentry of voice AI taking people's existing voices.
[01:26:51.220 --> 01:26:52.220]   Google's been doing this.
[01:26:52.220 --> 01:26:58.540]   A lot of others are doing it and applying it to a synthesized voice so that you can,
[01:26:58.540 --> 01:27:03.180]   and Apple's now using AI voices in narration of some of its Apple books.
[01:27:03.180 --> 01:27:04.180]   They're quite good.
[01:27:04.180 --> 01:27:13.300]   But here's an example of, so the model lets you set things like the Voices Core identity,
[01:27:13.300 --> 01:27:16.900]   which is gender, age, accent, pitch, speaking style.
[01:27:16.900 --> 01:27:21.860]   And then you can generate a new voice out of this that never existed before.
[01:27:21.860 --> 01:27:22.860]   These are good.
[01:27:22.860 --> 01:27:23.860]   Let me play you one.
[01:27:23.860 --> 01:27:24.860]   Let me play you one.
[01:27:24.860 --> 01:27:25.860]   You want to hear this?
[01:27:25.860 --> 01:27:28.060]   I have to turn on my sound.
[01:27:28.060 --> 01:27:29.860]   Collaborating his 11th birthday.
[01:27:29.860 --> 01:27:32.940]   Oh, this is a passage from The Hobbit.
[01:27:32.940 --> 01:27:37.220]   Mr Bilbo Baggins of Bag End announced that he would shortly be celebrating his 11th
[01:27:37.220 --> 01:27:40.740]   first birthday with a party of special magnificence.
[01:27:40.740 --> 01:27:44.300]   There was much talk and excitement in Hobbiton.
[01:27:44.300 --> 01:27:50.140]   Bilbo was very rich and very peculiar and had been the wonder of the Shire for 60 years,
[01:27:50.140 --> 01:27:53.420]   ever since his remarkable disappearance and unexpected return.
[01:27:53.420 --> 01:27:54.420]   That's pretty damn good.
[01:27:54.420 --> 01:27:55.420]   Oh my God.
[01:27:55.420 --> 01:27:59.700]   I was trying to hear some artifacts and sound machinery.
[01:27:59.700 --> 01:28:02.620]   The pace was on and even the pauses.
[01:28:02.620 --> 01:28:05.860]   It sounded like, and this is what's really scary about chat TV.
[01:28:05.860 --> 01:28:06.860]   That's uncanny.
[01:28:06.860 --> 01:28:09.100]   It sounds like it understands what it's saying, right?
[01:28:09.100 --> 01:28:10.100]   Obviously it can't.
[01:28:10.100 --> 01:28:11.100]   It doesn't.
[01:28:11.100 --> 01:28:12.820]   Here's a conversational voice.
[01:28:12.820 --> 01:28:13.820]   Oh, okay.
[01:28:13.820 --> 01:28:14.820]   I see.
[01:28:14.820 --> 01:28:16.700]   You think this has nothing to do with you.
[01:28:16.700 --> 01:28:21.380]   You go to your closet and you select, I don't know, that lumpy blue sweater for instance,
[01:28:21.380 --> 01:28:25.460]   because you're trying to tell the world that you take yourself too seriously to care about
[01:28:25.460 --> 01:28:26.460]   what you put on your back.
[01:28:26.460 --> 01:28:27.460]   Oh my God.
[01:28:27.460 --> 01:28:28.460]   Even the inflections.
[01:28:28.460 --> 01:28:29.460]   Wow.
[01:28:29.460 --> 01:28:30.460]   This is good.
[01:28:30.460 --> 01:28:31.460]   She's a valid girl.
[01:28:31.460 --> 01:28:32.460]   Dad is really...
[01:28:32.460 --> 01:28:36.940]   I'm actually scared about that way more than I am about chat GPT-3.
[01:28:36.940 --> 01:28:38.380]   That's too realistic.
[01:28:38.380 --> 01:28:39.380]   Yeah.
[01:28:39.380 --> 01:28:41.380]   Well, imagine pairing that with chat GPT.
[01:28:41.380 --> 01:28:43.460]   Oh my goodness.
[01:28:43.460 --> 01:28:50.540]   So this is 11labs.io and they say starting next month, this is going to be released to
[01:28:50.540 --> 01:28:51.540]   the public.
[01:28:51.540 --> 01:28:52.940]   Oh my God.
[01:28:52.940 --> 01:28:56.620]   As part of their voice lab.
[01:28:56.620 --> 01:29:04.260]   There are certain classes of jobs that somebody like me might do like video game or book narration
[01:29:04.260 --> 01:29:08.860]   that probably are going to be going away.
[01:29:08.860 --> 01:29:12.260]   News readers, most news readers on radio stations are human right now.
[01:29:12.260 --> 01:29:14.180]   I don't think they deserve to be.
[01:29:14.180 --> 01:29:17.500]   I think they could easily be a machine.
[01:29:17.500 --> 01:29:18.500]   That's not text to speech.
[01:29:18.500 --> 01:29:20.700]   I know text to speech and I don't like text to speech.
[01:29:20.700 --> 01:29:22.620]   That's actual performance.
[01:29:22.620 --> 01:29:24.540]   It sounds more like performance doesn't.
[01:29:24.540 --> 01:29:26.780]   Now those are samples they generated.
[01:29:26.780 --> 01:29:28.980]   So let's see what happens when they put them out.
[01:29:28.980 --> 01:29:34.060]   I have to say it's very impressed too with Apple's narrators.
[01:29:34.060 --> 01:29:35.140]   But they sounded...
[01:29:35.140 --> 01:29:36.140]   You could tell.
[01:29:36.140 --> 01:29:37.140]   Right.
[01:29:37.140 --> 01:29:42.820]   No, it's like the Google voice and the Siri voice, they're okay.
[01:29:42.820 --> 01:29:45.540]   But I know what they sound like and I know they sound artificial.
[01:29:45.540 --> 01:29:49.820]   There was nothing in those two samples that sounded artificial.
[01:29:49.820 --> 01:29:51.020]   That kind of scares me.
[01:29:51.020 --> 01:29:54.300]   Let me see if I can find a sample of...
[01:29:54.300 --> 01:29:56.300]   Actually I have it on my phone.
[01:29:56.300 --> 01:29:57.820]   I've played this before.
[01:29:57.820 --> 01:30:01.580]   This is a book about lumberjacks.
[01:30:01.580 --> 01:30:05.620]   What app are you using for your audiobooks, Leo?
[01:30:05.620 --> 01:30:06.820]   I use Audible.
[01:30:06.820 --> 01:30:10.780]   But there are many better probably choices like Libro, FM and others.
[01:30:10.780 --> 01:30:12.740]   I have this terrible...
[01:30:12.740 --> 01:30:15.900]   Every audiobook I listen to, the narration is terrible.
[01:30:15.900 --> 01:30:17.700]   Oh, that's why Audible is good.
[01:30:17.700 --> 01:30:18.700]   Worse than text to speech.
[01:30:18.700 --> 01:30:19.700]   Yeah, you got a really...
[01:30:19.700 --> 01:30:20.700]   I mean I try it Audible.
[01:30:20.700 --> 01:30:23.660]   Well it depends on the book because everybody's different.
[01:30:23.660 --> 01:30:28.900]   I think the problem really is that some narrators are awful.
[01:30:28.900 --> 01:30:32.380]   I have listened to thousands of hours on Audible.
[01:30:32.380 --> 01:30:35.660]   Let me see if this fools you.
[01:30:35.660 --> 01:30:36.660]   Or not fools you.
[01:30:36.660 --> 01:30:37.940]   Is it going to be the lumberjack song?
[01:30:37.940 --> 01:30:38.940]   I'm a lumberjack.
[01:30:38.940 --> 01:30:39.940]   No, no, no.
[01:30:39.940 --> 01:30:40.940]   This is it.
[01:30:40.940 --> 01:30:43.300]   So this is quote narrated by Apple Books.
[01:30:43.300 --> 01:30:45.260]   This is a book called the lumberjack.
[01:30:45.260 --> 01:30:50.660]   It's probably no human would want to read because it's just the history of lumberjack.
[01:30:50.660 --> 01:30:53.260]   Let me play this.
[01:30:53.260 --> 01:30:55.460]   You tell me, I think you can tell the difference.
[01:30:55.460 --> 01:30:57.900]   Loggers in British Columbia.
[01:30:57.900 --> 01:31:03.300]   Of the three interwoven ages of Eastern Canadian logging, the first belonged to the bearded
[01:31:03.300 --> 01:31:09.140]   square timbermen who huge great balks of white and red pine and drove them in huge
[01:31:09.140 --> 01:31:12.020]   rafts down the rivers to Quebec City.
[01:31:12.020 --> 01:31:13.020]   From where they were shifting it.
[01:31:13.020 --> 01:31:14.020]   You used to imagine you doing the dishes.
[01:31:14.020 --> 01:31:16.420]   I think it's fine.
[01:31:16.420 --> 01:31:17.980]   It's fine but no, I can...
[01:31:17.980 --> 01:31:20.940]   There is a little bit of artifacting at the ends I sent to the sis.
[01:31:20.940 --> 01:31:24.700]   I think that's maybe though the bit rate and stuff.
[01:31:24.700 --> 01:31:25.700]   Maybe, maybe.
[01:31:25.700 --> 01:31:30.580]   I think that the samples on these are not as good maybe is...
[01:31:30.580 --> 01:31:31.380]   But it's not as good.
[01:31:31.380 --> 01:31:33.740]   I think as the 11 labs.
[01:31:33.740 --> 01:31:38.220]   What the 11 labs does is it speeds up and slows down which is a very human thing to do.
[01:31:38.220 --> 01:31:39.660]   Yeah, there was a very natural...
[01:31:39.660 --> 01:31:40.660]   This is more...
[01:31:40.660 --> 01:31:42.460]   It's the same speed even though there are pauses.
[01:31:42.460 --> 01:31:45.060]   They have a lot of romance novels written this way.
[01:31:45.060 --> 01:31:46.780]   Let me just...
[01:31:46.780 --> 01:31:48.780]   It was right of course.
[01:31:48.780 --> 01:31:51.500]   Lately she'd been distracted every time she looked out the window.
[01:31:51.500 --> 01:31:53.420]   Oh that one's very robotic.
[01:31:53.420 --> 01:31:55.420]   Yeah, that's one step above Sury.
[01:31:55.420 --> 01:31:56.420]   You guys would see...
[01:31:56.420 --> 01:31:57.420]   You would immediately know.
[01:31:57.420 --> 01:31:58.420]   Yeah.
[01:31:58.420 --> 01:31:59.420]   It was a small day.
[01:31:59.420 --> 01:32:02.420]   I mean I will say that's better than some of the human kids.
[01:32:02.420 --> 01:32:03.420]   Yes, that's not the most...
[01:32:03.420 --> 01:32:05.340]   Band-narrators, you're awful.
[01:32:05.340 --> 01:32:06.340]   Yeah.
[01:32:06.340 --> 01:32:10.860]   It feels like every book that I choose just the worst audio narrator in the world has
[01:32:10.860 --> 01:32:11.860]   been assigned to it.
[01:32:11.860 --> 01:32:13.340]   It is like they haven't even read the sentence.
[01:32:13.340 --> 01:32:16.740]   I wish that I will respond to that today because I could pick some very good...
[01:32:16.740 --> 01:32:19.900]   Audio books or some that really are well-narrated.
[01:32:19.900 --> 01:32:26.580]   I'm listening to Ian Banks' first book in his culture series, Consider Fleabus.
[01:32:26.580 --> 01:32:28.380]   And the narrator's wonderful.
[01:32:28.380 --> 01:32:30.460]   He's really doing a nice job to bring it to life.
[01:32:30.460 --> 01:32:31.460]   They're good books.
[01:32:31.460 --> 01:32:32.460]   But you've got to find them.
[01:32:32.460 --> 01:32:33.460]   There's a couple of...
[01:32:33.460 --> 01:32:34.460]   Who did...
[01:32:34.460 --> 01:32:35.460]   Love him.
[01:32:35.460 --> 01:32:36.460]   There's...
[01:32:36.460 --> 01:32:37.460]   I don't know.
[01:32:37.460 --> 01:32:38.460]   I don't know.
[01:32:38.460 --> 01:32:39.460]   Who did the Martian?
[01:32:39.460 --> 01:32:41.300]   Oh, he's so good.
[01:32:41.300 --> 01:32:42.300]   He's accepted.
[01:32:42.300 --> 01:32:43.900]   I've heard of him in so many books.
[01:32:43.900 --> 01:32:46.260]   So it's an interesting thing happened there I think.
[01:32:46.260 --> 01:32:49.700]   Which I talked to Andy Weir about this.
[01:32:49.700 --> 01:32:56.340]   He gave the rights for the audiobook too audible.
[01:32:56.340 --> 01:32:59.100]   So they recorded it.
[01:32:59.100 --> 01:33:03.860]   And the guy who originally did the Martian, I guess they lost him.
[01:33:03.860 --> 01:33:04.860]   Right.
[01:33:04.860 --> 01:33:05.860]   So the new version is Will Wheaton.
[01:33:05.860 --> 01:33:06.860]   Will Wheaton.
[01:33:06.860 --> 01:33:07.860]   Who is not as good?
[01:33:07.860 --> 01:33:08.860]   He's not as good.
[01:33:08.860 --> 01:33:09.860]   I heard Will Wheaton.
[01:33:09.860 --> 01:33:10.860]   I like Will.
[01:33:10.860 --> 01:33:11.860]   To Ready Player One.
[01:33:11.860 --> 01:33:12.860]   And he was okay in that.
[01:33:12.860 --> 01:33:13.860]   That's okay.
[01:33:13.860 --> 01:33:14.860]   But he's not...
[01:33:14.860 --> 01:33:15.860]   What was that guy's name?
[01:33:15.860 --> 01:33:18.460]   He Syfy in the Syfy genre.
[01:33:18.460 --> 01:33:22.940]   I have to ask Daniel when he's on Daniel Suarez who wrote one of your favorite books,
[01:33:22.940 --> 01:33:23.940]   Demon and Freedom.
[01:33:23.940 --> 01:33:24.940]   Yeah.
[01:33:24.940 --> 01:33:25.940]   His new book is coming out.
[01:33:25.940 --> 01:33:27.260]   And he uses the same...
[01:33:27.260 --> 01:33:33.100]   That's one of the things if you get good, you can have the same narrator again and again.
[01:33:33.100 --> 01:33:34.620]   And people start to...
[01:33:34.620 --> 01:33:37.020]   Here's this Jeff Gurner who I think sounds really...
[01:33:37.020 --> 01:33:38.020]   Oh, Gurner's fantastic.
[01:33:38.020 --> 01:33:39.580]   Really good.
[01:33:39.580 --> 01:33:42.420]   This is from Demon.
[01:33:42.420 --> 01:33:43.860]   Probably violating copyright.
[01:33:43.860 --> 01:33:44.860]   Penguin Audio Presents.
[01:33:44.860 --> 01:33:47.500]   Oh, this is the very beginning.
[01:33:47.500 --> 01:33:50.340]   So there's a little funny thing going on.
[01:33:50.340 --> 01:33:57.420]   My pitch, my startup pitch is that there should be a company that makes custom audiobooks.
[01:33:57.420 --> 01:34:01.620]   Perhaps they work with the author, put a little bit of effort in that in addition to just
[01:34:01.620 --> 01:34:05.980]   having a decent narrator, I guess this is my issue because I read a lot of nonfiction
[01:34:05.980 --> 01:34:06.980]   books.
[01:34:06.980 --> 01:34:12.260]   But just turn quotes around slightly so that you introduce who is saying the thing before
[01:34:12.260 --> 01:34:13.900]   you launch into a quote.
[01:34:13.900 --> 01:34:14.900]   My...
[01:34:14.900 --> 01:34:15.900]   It feels like my...
[01:34:15.900 --> 01:34:16.900]   Yeah.
[01:34:16.900 --> 01:34:20.540]   As Paris Martin said, and then quote, because sometimes I'll just be listening to a book
[01:34:20.540 --> 01:34:24.140]   in the driest, flatest voice.
[01:34:24.140 --> 01:34:28.020]   And then I'm like, "Oh, these past two sentences were a quote.
[01:34:28.020 --> 01:34:29.020]   Little did I am?"
[01:34:29.020 --> 01:34:30.020]   Yeah.
[01:34:30.020 --> 01:34:31.020]   Actually...
[01:34:31.020 --> 01:34:32.020]   I agree.
[01:34:32.020 --> 01:34:35.220]   There's a section of the Martian where he's hacking the rover.
[01:34:35.220 --> 01:34:38.780]   And in the text, when you're reading the book, it's fine because it has the code.
[01:34:38.780 --> 01:34:42.220]   But then he's reading out the code in real time.
[01:34:42.220 --> 01:34:43.220]   It's like...
[01:34:43.220 --> 01:34:44.220]   Slash, slash, slash.
[01:34:44.220 --> 01:34:45.220]   Yeah.
[01:34:45.220 --> 01:34:46.220]   You probably could have slipped there.
[01:34:46.220 --> 01:34:47.220]   Hex 566 slash...
[01:34:47.220 --> 01:34:48.220]   On the other hand.
[01:34:48.220 --> 01:34:54.500]   On the other hand, Andy's latest, which is Project Hail Mary.
[01:34:54.500 --> 01:34:55.500]   That's excellent.
[01:34:55.500 --> 01:34:58.060]   Really is well adapted to audio because there's an...
[01:34:58.060 --> 01:34:59.500]   Can I say this without spoiling it?
[01:34:59.500 --> 01:35:00.500]   There's an alien.
[01:35:00.500 --> 01:35:01.500]   I could say that.
[01:35:01.500 --> 01:35:02.500]   Yeah.
[01:35:02.500 --> 01:35:06.260]   And the alien speaks in a musical tone.
[01:35:06.260 --> 01:35:09.460]   And we're as reading it on the page, I don't even know what it looks like on the page because
[01:35:09.460 --> 01:35:10.620]   I only listen to it.
[01:35:10.620 --> 01:35:13.700]   But reading it on the page is not going to be that way.
[01:35:13.700 --> 01:35:14.700]   They produced it well.
[01:35:14.700 --> 01:35:15.700]   Yes.
[01:35:15.700 --> 01:35:16.700]   And it's a musical voice.
[01:35:16.700 --> 01:35:18.620]   And the alien has his own musical voice first.
[01:35:18.620 --> 01:35:19.620]   I read it first.
[01:35:19.620 --> 01:35:21.300]   And then I listen to the audio book.
[01:35:21.300 --> 01:35:23.060]   I'm like, "Oh yeah, it does."
[01:35:23.060 --> 01:35:24.060]   That's how I should have been hearing it.
[01:35:24.060 --> 01:35:25.060]   Yeah.
[01:35:25.060 --> 01:35:26.060]   It just depends, I guess.
[01:35:26.060 --> 01:35:27.060]   Hey, I got to take a break.
[01:35:27.060 --> 01:35:28.540]   We're way behind on our fine sponsors.
[01:35:28.540 --> 01:35:29.540]   We will get a lovely...
[01:35:29.540 --> 01:35:32.860]   You're telling me that wasn't an audible ad right there?
[01:35:32.860 --> 01:35:33.860]   Yeah.
[01:35:33.860 --> 01:35:35.740]   God, if I could only charge them for that.
[01:35:35.740 --> 01:35:36.740]   They are a sponsor.
[01:35:36.740 --> 01:35:38.620]   We do love them.
[01:35:38.620 --> 01:35:42.180]   We'll get another pick from CES from Father Robert in just a second.
[01:35:42.180 --> 01:35:43.500]   But first a word.
[01:35:43.500 --> 01:35:45.420]   Now this is a sponsor I live.
[01:35:45.420 --> 01:35:51.020]   In fact, because on New Year's Day I made a resolution, you ever hear of that?
[01:35:51.020 --> 01:35:54.180]   I had been overindulging a little bit and I said, "You know what?
[01:35:54.180 --> 01:35:55.980]   I'm getting back with Noom.
[01:35:55.980 --> 01:35:58.060]   I've been using Noom for more than a year.
[01:35:58.060 --> 01:36:00.140]   You've probably seen the ads on TV and so forth.
[01:36:00.140 --> 01:36:01.140]   It's a psychology.
[01:36:01.140 --> 01:36:03.180]   It's not a diet.
[01:36:03.180 --> 01:36:07.740]   Don't put me on a diet because I will then respond negatively, right?
[01:36:07.740 --> 01:36:11.700]   I will then go get a package of Oreos and say, "Screw you diet.
[01:36:11.700 --> 01:36:13.380]   I'm eating these Oreos."
[01:36:13.380 --> 01:36:14.380]   Not with Noom.
[01:36:14.380 --> 01:36:20.900]   Noom is a psychology-based approach that really is more about educating you about food and
[01:36:20.900 --> 01:36:26.340]   your relationship with food so you can break the cycle and change your habits for good.
[01:36:26.340 --> 01:36:27.740]   I started doing Noom about a year ago.
[01:36:27.740 --> 01:36:31.580]   Lisa, being a wonderful wife, said, "I'll do it too to support you.
[01:36:31.580 --> 01:36:33.540]   I don't have much weight to lose, but I'll do it."
[01:36:33.540 --> 01:36:37.700]   She is like the queen of Noom now.
[01:36:37.700 --> 01:36:41.740]   She not only lost the weight she got down below the weight she'd always wanted to be at.
[01:36:41.740 --> 01:36:46.220]   She got down to the weight she's always wanted to be at but never could reach and is maintaining
[01:36:46.220 --> 01:36:47.700]   it beautifully.
[01:36:47.700 --> 01:36:49.180]   It's amazing.
[01:36:49.180 --> 01:36:51.740]   Her health is great.
[01:36:51.740 --> 01:36:54.060]   Over the holidays, I may be eight or one or two.
[01:36:54.060 --> 01:36:56.100]   You probably did this too.
[01:36:56.100 --> 01:36:58.260]   Too many Christmas cookies.
[01:36:58.260 --> 01:37:01.580]   That box of C's candy was calling to me.
[01:37:01.580 --> 01:37:02.580]   But you know what?
[01:37:02.580 --> 01:37:04.260]   January 1st, Noom again.
[01:37:04.260 --> 01:37:05.860]   I went back and I love it.
[01:37:05.860 --> 01:37:09.860]   In fact, I actually reset my lessons to start over.
[01:37:09.860 --> 01:37:14.140]   I got the master's degree, got to the end of Noom and they have a great maintenance
[01:37:14.140 --> 01:37:15.140]   program.
[01:37:15.140 --> 01:37:18.540]   I thought, "I really want to re-engage myself."
[01:37:18.540 --> 01:37:19.900]   Losing weight starts with your brain.
[01:37:19.900 --> 01:37:22.020]   I hate even say losing weight.
[01:37:22.020 --> 01:37:26.940]   It's about learning how to change your relationship with food so it supports you.
[01:37:26.940 --> 01:37:28.500]   You have a healthy weight.
[01:37:28.500 --> 01:37:31.700]   Make the science behind your eating choices, why you've got cravings.
[01:37:31.700 --> 01:37:35.140]   I learned, for instance, that I am a fog eater.
[01:37:35.140 --> 01:37:37.580]   I eat in a blind fog.
[01:37:37.580 --> 01:37:39.780]   You could ask me five minutes later, "What did you just eat?
[01:37:39.780 --> 01:37:40.780]   How did it taste?"
[01:37:40.780 --> 01:37:41.780]   And I go, "What?
[01:37:41.780 --> 01:37:42.780]   What are you talking about?"
[01:37:42.780 --> 01:37:43.780]   I have no idea.
[01:37:43.780 --> 01:37:45.780]   Noom helped me learn that.
[01:37:45.780 --> 01:37:50.180]   The program helps you understand the science behind your eating choices, why you're doing
[01:37:50.180 --> 01:37:51.180]   that.
[01:37:51.180 --> 01:37:55.860]   4.6 million people to date have lost weight through Noom weight.
[01:37:55.860 --> 01:37:58.020]   But everybody's journey is different.
[01:37:58.020 --> 01:38:01.940]   So your daily lessons are personalized to you and your goals.
[01:38:01.940 --> 01:38:07.380]   They are using specific principles of psychology like cognitive behavioral therapy, maybe you
[01:38:07.380 --> 01:38:09.140]   heard of CBT.
[01:38:09.140 --> 01:38:10.740]   Really, really works.
[01:38:10.740 --> 01:38:12.580]   It's all about progress, not perfection.
[01:38:12.580 --> 01:38:14.420]   There are no bad foods.
[01:38:14.420 --> 01:38:15.580]   You don't have to give up carbs.
[01:38:15.580 --> 01:38:18.220]   You don't restrict yourself because restriction.
[01:38:18.220 --> 01:38:21.380]   As we've all learned, just leads to cravings, right?
[01:38:21.380 --> 01:38:25.540]   If you have cravings or food FOMO, Noom weight can help you lose weight while enjoying your
[01:38:25.540 --> 01:38:27.740]   favorite foods.
[01:38:27.740 --> 01:38:31.620]   And you can choose your level of support from five-minute daily check-ins to personal coaching.
[01:38:31.620 --> 01:38:34.620]   You've got groups and it's grounded in science.
[01:38:34.620 --> 01:38:36.180]   Now let me give you the facts.
[01:38:36.180 --> 01:38:39.980]   95% of customers say Noom weight is a good long-term solution.
[01:38:39.980 --> 01:38:40.980]   It absolutely was for me.
[01:38:40.980 --> 01:38:42.620]   I lost 20 pounds, kept it off.
[01:38:42.620 --> 01:38:44.100]   I'm ready for the next 20.
[01:38:44.100 --> 01:38:46.860]   Lisa lost 15 pounds, has kept it off.
[01:38:46.860 --> 01:38:47.860]   She can't lose anymore.
[01:38:47.860 --> 01:38:48.860]   I won't let her.
[01:38:48.860 --> 01:38:51.420]   But she's really loving it.
[01:38:51.420 --> 01:38:53.660]   We have listeners.
[01:38:53.660 --> 01:39:00.300]   I mentioned before one of our chatters was on the cruise with us in Alaska last summer.
[01:39:00.300 --> 01:39:01.300]   I said, "I'm going to know."
[01:39:01.300 --> 01:39:02.300]   I said, "Where are you?
[01:39:02.300 --> 01:39:03.300]   I thought you were going to be on the cruise.
[01:39:03.300 --> 01:39:04.300]   I'm standing right next to you.
[01:39:04.300 --> 01:39:05.820]   I did not recognize him.
[01:39:05.820 --> 01:39:08.700]   Lost 60 pounds and has kept it off.
[01:39:08.700 --> 01:39:09.700]   He looks great."
[01:39:09.700 --> 01:39:11.700]   Thanks to Noom.
[01:39:11.700 --> 01:39:14.820]   Brianna Wu, 100 pounds.
[01:39:14.820 --> 01:39:15.980]   Have you seen her lately?
[01:39:15.980 --> 01:39:16.980]   100 pounds.
[01:39:16.980 --> 01:39:18.740]   I don't even know what she had to lose on her.
[01:39:18.740 --> 01:39:21.220]   She loves Noom.
[01:39:21.220 --> 01:39:25.500]   They published more than 30 peer-reviewed scientific articles to inform users and practitioners
[01:39:25.500 --> 01:39:29.900]   and scientists and the public about their methods and effectiveness peer-reviewed.
[01:39:29.900 --> 01:39:32.300]   So it's not marketing materials.
[01:39:32.300 --> 01:39:35.340]   It's actual important stuff.
[01:39:35.340 --> 01:39:39.900]   Stay focused on what's important to you with Noom Waits Psychology-Based Approach.
[01:39:39.900 --> 01:39:41.220]   Sign up for your trial today.
[01:39:41.220 --> 01:39:42.220]   Noom.om.
[01:39:42.220 --> 01:39:44.020]   Noom.com/twit.
[01:39:44.020 --> 01:39:47.780]   I am a living symbol.
[01:39:47.780 --> 01:39:48.980]   I believe in it.
[01:39:48.980 --> 01:39:51.860]   Man, this thing is so great.
[01:39:51.860 --> 01:39:53.500]   It's so great.
[01:39:53.500 --> 01:39:55.300]   N-double-om.com/twit.
[01:39:55.300 --> 01:39:56.540]   Sign up for your trial today.
[01:39:56.540 --> 01:39:57.540]   Check out their book, too.
[01:39:57.540 --> 01:39:58.780]   They got their first book coming out.
[01:39:58.780 --> 01:39:59.780]   You can pre-order it.
[01:39:59.780 --> 01:40:01.460]   Oh, no, it's available now.
[01:40:01.460 --> 01:40:02.460]   Yay.
[01:40:02.460 --> 01:40:04.300]   Available to buy now wherever books are sold.
[01:40:04.300 --> 01:40:05.300]   Good.
[01:40:05.300 --> 01:40:06.300]   I'm going to get my copy.
[01:40:06.300 --> 01:40:07.300]   The Noom Mindset.
[01:40:07.300 --> 01:40:11.140]   A deep dive into the psychology of behavior change.
[01:40:11.140 --> 01:40:12.540]   It really works.
[01:40:12.540 --> 01:40:13.540]   Love them.
[01:40:13.540 --> 01:40:15.100]   Thank you, Noom.
[01:40:15.100 --> 01:40:19.460]   Noom and double-om.com/twit.
[01:40:19.460 --> 01:40:20.460]   All right.
[01:40:20.460 --> 01:40:21.940]   Make me--
[01:40:21.940 --> 01:40:23.420]   Am I losing 100 pounds?
[01:40:23.420 --> 01:40:25.220]   You can do it.
[01:40:25.220 --> 01:40:26.220]   I feel the--
[01:40:26.220 --> 01:40:28.740]   It's hard because you have to eat in a refectory where they're--
[01:40:28.740 --> 01:40:30.740]   they serve you day-old eggs.
[01:40:30.740 --> 01:40:32.260]   Oh, those eggs are awesome.
[01:40:32.260 --> 01:40:33.700]   I'm a Vatican egg.
[01:40:33.700 --> 01:40:34.700]   They're the bomb.
[01:40:34.700 --> 01:40:35.700]   Oh, the pasta.
[01:40:35.700 --> 01:40:36.860]   I've seen your pictures.
[01:40:36.860 --> 01:40:37.860]   They're bad.
[01:40:37.860 --> 01:40:40.620]   Actually, we just fired our entire kitchen staff.
[01:40:40.620 --> 01:40:41.620]   What?
[01:40:41.620 --> 01:40:43.420]   We got them-- you don't fire in Italy.
[01:40:43.420 --> 01:40:44.980]   We got them new jobs.
[01:40:44.980 --> 01:40:45.980]   And we've replaced them.
[01:40:45.980 --> 01:40:46.980]   Yeah, that's what they're saying.
[01:40:46.980 --> 01:40:48.780]   The Twitter folks who got fired in Europe saying,
[01:40:48.780 --> 01:40:49.780]   you can't fire us.
[01:40:49.780 --> 01:40:50.300]   No.
[01:40:50.300 --> 01:40:51.300]   No.
[01:40:51.300 --> 01:40:52.300]   This is Europe.
[01:40:52.300 --> 01:40:53.300]   Job protection is really really strong.
[01:40:53.300 --> 01:40:54.980]   They haven't paid them separate either, though.
[01:40:54.980 --> 01:40:56.620]   Yeah, I know.
[01:40:56.620 --> 01:40:58.660]   But the difference is that European courts
[01:40:58.660 --> 01:41:01.660]   will absolutely slam us for that.
[01:41:01.660 --> 01:41:02.180]   Yeah.
[01:41:02.180 --> 01:41:03.580]   They believe in--
[01:41:03.580 --> 01:41:05.820]   I have to think he's just looking for the escape
[01:41:05.820 --> 01:41:06.660]   hatch at this point.
[01:41:06.660 --> 01:41:07.260]   Basically, yeah.
[01:41:07.260 --> 01:41:08.940]   I mean, he has dumped in--
[01:41:08.940 --> 01:41:11.660]   aside from the purchase price and not including
[01:41:11.660 --> 01:41:13.580]   all the value that Tesla has lost,
[01:41:13.580 --> 01:41:17.620]   he's dumped in about $8 billion just to keep Twitter afloat.
[01:41:17.620 --> 01:41:19.180]   Over and above is $44 billion.
[01:41:19.180 --> 01:41:20.180]   Over and above.
[01:41:20.180 --> 01:41:22.740]   And he's got interest coming up of more than a billion.
[01:41:22.740 --> 01:41:25.540]   $1.4 billion is what the interest payment will be
[01:41:25.540 --> 01:41:27.020]   at the end of the year.
[01:41:27.020 --> 01:41:28.660]   He's got to feel trapped right now.
[01:41:28.660 --> 01:41:29.340]   He's very trapped.
[01:41:29.340 --> 01:41:30.700]   I know he's not tweeting as much.
[01:41:30.700 --> 01:41:31.180]   He's not.
[01:41:31.180 --> 01:41:33.820]   But I mean, if you look at it-- so 92% of his revenue
[01:41:33.820 --> 01:41:35.300]   came from ads.
[01:41:35.300 --> 01:41:38.420]   He was $200 million in the whole and Twitter's best year.
[01:41:38.420 --> 01:41:39.580]   It has not been their best year.
[01:41:39.580 --> 01:41:41.180]   He's lost about--
[01:41:41.180 --> 01:41:46.540]   they're conservatively 35% to 45% of his highest advertisers,
[01:41:46.540 --> 01:41:48.860]   which means that even with all the job cuts,
[01:41:48.860 --> 01:41:51.940]   if you include the debt that has been added on to Twitter,
[01:41:51.940 --> 01:41:55.940]   it's at minimum of $2 billion in the whole a year.
[01:41:55.940 --> 01:41:56.940]   And that doesn't--
[01:41:56.940 --> 01:41:57.940]   There's no way to make that money.
[01:41:57.940 --> 01:41:58.700]   There's zero way to make it.
[01:41:58.700 --> 01:42:01.100]   It is completely unsustainable.
[01:42:01.100 --> 01:42:02.500]   I'm sure he's looking for an escape hatch.
[01:42:02.500 --> 01:42:04.340]   He might be thinking about launching himself on a falcon.
[01:42:04.340 --> 01:42:05.140]   How do you do it in the moon?
[01:42:05.140 --> 01:42:06.740]   I don't know.
[01:42:06.740 --> 01:42:09.460]   His tweet an hour ago-- I think he's listening to the show--
[01:42:09.460 --> 01:42:11.020]   Instagram makes people depressed,
[01:42:11.020 --> 01:42:13.140]   and Twitter makes people angry, which is better.
[01:42:13.140 --> 01:42:15.820]   [LAUGHTER]
[01:42:15.820 --> 01:42:16.220]   You know--
[01:42:16.220 --> 01:42:17.940]   You must come on Twitter.
[01:42:17.940 --> 01:42:18.740]   I know, exactly.
[01:42:18.740 --> 01:42:19.340]   Come on, Guy.
[01:42:19.340 --> 01:42:20.340]   Explain your side of it.
[01:42:20.340 --> 01:42:21.620]   Tell us what your plan is.
[01:42:21.620 --> 01:42:24.460]   Yeah, Elon, meet the real chief Twitter.
[01:42:24.460 --> 01:42:25.460]   Yeah.
[01:42:25.460 --> 01:42:26.460]   Yeah.
[01:42:26.460 --> 01:42:27.980]   No, I don't think he wants to meet me.
[01:42:27.980 --> 01:42:30.420]   [LAUGHTER]
[01:42:30.420 --> 01:42:33.780]   Now, that's the-- see that big laptop, Leo?
[01:42:33.780 --> 01:42:35.700]   Yeah, one's the-- grab that one.
[01:42:35.700 --> 01:42:39.100]   So these are Chromebooks that Acer gave me.
[01:42:39.100 --> 01:42:39.940]   Chromebooks.
[01:42:39.940 --> 01:42:40.940]   These are not Windows machines.
[01:42:40.940 --> 01:42:41.980]   Those are not Windows machines.
[01:42:41.980 --> 01:42:42.540]   But this--
[01:42:42.540 --> 01:42:44.060]   It's a big--
[01:42:44.060 --> 01:42:46.020]   God, you can make a sandwich out of those.
[01:42:46.020 --> 01:42:46.860]   This is a backbeat.
[01:42:46.860 --> 01:42:48.820]   You've got like one either side.
[01:42:48.820 --> 01:42:50.020]   A 16-inch.
[01:42:50.020 --> 01:42:50.940]   Oh.
[01:42:50.940 --> 01:42:52.220]   It's a beautiful screen.
[01:42:52.220 --> 01:42:52.700]   It's a hundred--
[01:42:52.700 --> 01:42:53.500]   Not both Mario.
[01:42:53.500 --> 01:42:54.940]   Does it have Luigi?
[01:42:54.940 --> 01:42:57.740]   This is a gaming-- it's a gaming Chromebook.
[01:42:57.740 --> 01:42:59.140]   This is designed for gaming.
[01:42:59.140 --> 01:43:00.140]   Oh.
[01:43:00.140 --> 01:43:01.260]   It has have Luigi.
[01:43:01.260 --> 01:43:02.340]   It sounds good.
[01:43:02.340 --> 01:43:03.180]   It looks good.
[01:43:03.180 --> 01:43:04.660]   It's got that all day battery life.
[01:43:04.660 --> 01:43:06.380]   You know, 14 hours on a single charge.
[01:43:06.380 --> 01:43:08.180]   Is it an IPS screen?
[01:43:08.180 --> 01:43:09.180]   It looks really nice.
[01:43:09.180 --> 01:43:10.180]   That's an IPS screen.
[01:43:10.180 --> 01:43:11.180]   This one's got an I-5 in it.
[01:43:11.180 --> 01:43:13.700]   Look how it has the W-A-S-M lit up.
[01:43:13.700 --> 01:43:15.540]   So of course, you've got to get your Wasty.
[01:43:15.540 --> 01:43:16.820]   The WASD, yeah.
[01:43:16.820 --> 01:43:19.020]   Now, and it's, of course, it's an RGB keyboard.
[01:43:19.020 --> 01:43:21.700]   So in the night, you know exactly what you need to punch.
[01:43:21.700 --> 01:43:23.780]   It's not a touchscreen, but--
[01:43:23.780 --> 01:43:25.140]   I got to punch Luigi.
[01:43:25.140 --> 01:43:25.980]   No, who's that?
[01:43:25.980 --> 01:43:27.460]   I want to punch that other guy.
[01:43:27.460 --> 01:43:28.460]   I hate him.
[01:43:28.460 --> 01:43:29.300]   Oh, Bowser Bowser.
[01:43:29.300 --> 01:43:30.300]   Wow, real?
[01:43:30.300 --> 01:43:33.220]   Oh, Mario has no hero either, yeah.
[01:43:33.220 --> 01:43:33.860]   This is nice.
[01:43:33.860 --> 01:43:34.580]   That's a Chromebook.
[01:43:34.580 --> 01:43:35.580]   How much?
[01:43:35.580 --> 01:43:36.620]   The 600.
[01:43:36.620 --> 01:43:37.380]   That's not bad?
[01:43:37.380 --> 01:43:38.180]   That's not bad.
[01:43:38.180 --> 01:43:38.980]   And it's actually--
[01:43:38.980 --> 01:43:39.820]   It's a premium Chromebook.
[01:43:39.820 --> 01:43:41.300]   Very, very nice machine.
[01:43:41.300 --> 01:43:43.940]   I was surprised, because when I think of Chromebook,
[01:43:43.940 --> 01:43:45.260]   I think a cheap build--
[01:43:45.260 --> 01:43:46.580]   120 Hertz screen.
[01:43:46.580 --> 01:43:47.220]   Yeah.
[01:43:47.220 --> 01:43:48.660]   16 gigabytes of memory.
[01:43:48.660 --> 01:43:49.780]   It's got a 9-5 in it.
[01:43:49.780 --> 01:43:52.900]   It's got a 256 gigabyte NVMe SSD.
[01:43:52.900 --> 01:43:55.660]   It's an IPS screen that's running 25, 6, 2x, by 1600.
[01:43:55.660 --> 01:43:57.740]   You can now run Linux on Chromebooks.
[01:43:57.740 --> 01:43:58.500]   Yeah.
[01:43:58.500 --> 01:43:59.540]   This could be a great Linux box.
[01:43:59.540 --> 01:44:01.740]   This might be my new desktop.
[01:44:01.740 --> 01:44:02.380]   That's pretty nice.
[01:44:02.380 --> 01:44:05.060]   It's dedicated graphics, but it's--
[01:44:05.060 --> 01:44:05.660]   It's iris.
[01:44:05.660 --> 01:44:06.220]   It's dedicated.
[01:44:06.220 --> 01:44:07.740]   It's new iris.
[01:44:07.740 --> 01:44:10.620]   But they really sell this as sort of a cloud-based gaming
[01:44:10.620 --> 01:44:10.900]   book.
[01:44:10.900 --> 01:44:13.580]   So you've got the NVIDIA server, or the Amazon.
[01:44:13.580 --> 01:44:15.500]   Sorry, Stadia.
[01:44:15.500 --> 01:44:17.220]   Sorry, Stadia.
[01:44:17.220 --> 01:44:17.620]   Wait, wait.
[01:44:17.620 --> 01:44:18.820]   You had a Stadia, right?
[01:44:18.820 --> 01:44:19.260]   Yeah.
[01:44:19.260 --> 01:44:22.540]   Did they give you the parting gift?
[01:44:22.540 --> 01:44:24.860]   The Bluetooth upgrade to my Stadia controller.
[01:44:24.860 --> 01:44:26.180]   So they now can be used anywhere?
[01:44:26.180 --> 01:44:26.580]   Thank you.
[01:44:26.580 --> 01:44:27.700]   That was a good thing to do.
[01:44:27.700 --> 01:44:29.060]   And that worm game they gave us.
[01:44:29.060 --> 01:44:30.740]   They gave you the worms?
[01:44:30.740 --> 01:44:32.180]   It's not the worms.
[01:44:32.180 --> 01:44:33.500]   It's a worms.
[01:44:33.500 --> 01:44:36.540]   They gave it a worm game they were using to test Stadia.
[01:44:36.540 --> 01:44:38.140]   That was the final drop.
[01:44:38.140 --> 01:44:38.660]   Oh.
[01:44:38.660 --> 01:44:39.300]   That next week--
[01:44:39.300 --> 01:44:40.220]   So sad.
[01:44:40.220 --> 01:44:40.940]   It's over.
[01:44:40.940 --> 01:44:42.300]   But just look at that screen.
[01:44:42.300 --> 01:44:44.060]   Seriously, I remember when I thought
[01:44:44.060 --> 01:44:46.580]   that high refresh rate screens were a gimmick.
[01:44:46.580 --> 01:44:48.140]   No, 120 Hertz is a positive.
[01:44:48.140 --> 01:44:48.500]   Oh, my gosh.
[01:44:48.500 --> 01:44:50.180]   It makes it pretty good.
[01:44:50.180 --> 01:44:51.860]   It looks so nice.
[01:44:51.860 --> 01:44:55.020]   Would you game on this, Paris?
[01:44:55.020 --> 01:44:56.980]   No, I'm not really a computer gamer.
[01:44:56.980 --> 01:44:59.780]   I spend so much time looking at my computer for work
[01:44:59.780 --> 01:45:01.540]   that I want to look at.
[01:45:01.540 --> 01:45:03.820]   I am a switch person.
[01:45:03.820 --> 01:45:07.500]   I've been thinking about getting the Steam deck.
[01:45:07.500 --> 01:45:08.900]   As of late, I'm really excited.
[01:45:08.900 --> 01:45:10.380]   The new-- OK, I know.
[01:45:10.380 --> 01:45:10.860]   I know.
[01:45:10.860 --> 01:45:12.460]   Try and hold me aside where I should get--
[01:45:12.460 --> 01:45:13.980]   Don't get-- I had the Steam deck.
[01:45:13.980 --> 01:45:14.500]   We bought it.
[01:45:14.500 --> 01:45:15.980]   Actually, Micah bought it.
[01:45:15.980 --> 01:45:17.580]   And I played with it for a while.
[01:45:17.580 --> 01:45:18.060]   And it's big.
[01:45:18.060 --> 01:45:19.220]   It's heavy.
[01:45:19.220 --> 01:45:20.700]   But it's still a seven inch screen.
[01:45:20.700 --> 01:45:23.540]   If you're going to play those games, play them on a desktop.
[01:45:23.540 --> 01:45:24.940]   It's the nice thing about the Switch.
[01:45:24.940 --> 01:45:27.180]   Is this games designed for that platform?
[01:45:27.180 --> 01:45:27.940]   And they're great.
[01:45:27.940 --> 01:45:28.940]   What do you play right now?
[01:45:28.940 --> 01:45:31.580]   I mean, I'm really excited for the new Fire Emblem
[01:45:31.580 --> 01:45:33.540]   that's coming out, I think, either next week,
[01:45:33.540 --> 01:45:34.540]   within the next week or so.
[01:45:34.540 --> 01:45:36.220]   The Fire Emblem Engage.
[01:45:36.220 --> 01:45:37.460]   It's going to be on Switch, yes.
[01:45:37.460 --> 01:45:39.940]   I believe it's a Nintendo exclusive.
[01:45:39.940 --> 01:45:43.140]   This is going to be my next couple quarters of gaming.
[01:45:43.140 --> 01:45:44.860]   New Zelda is coming out in May.
[01:45:44.860 --> 01:45:45.700]   OK.
[01:45:45.700 --> 01:45:46.660]   Quite an exciting time.
[01:45:46.660 --> 01:45:49.580]   You were an animal crossing fan, were you not?
[01:45:49.580 --> 01:45:51.020]   I mean, I was certainly, I think,
[01:45:51.020 --> 01:45:52.540]   when Animal Crossing came out.
[01:45:52.540 --> 01:45:54.740]   That saved me for the first year of the pandemic.
[01:45:54.740 --> 01:45:55.300]   Yeah.
[01:45:55.300 --> 01:45:55.860]   That kept me alive.
[01:45:55.860 --> 01:45:57.220]   It was pretty fun.
[01:45:57.220 --> 01:46:01.300]   At least I had a little village I could go to with animals.
[01:46:01.300 --> 01:46:04.780]   I got really into disco Elysium a couple months ago.
[01:46:04.780 --> 01:46:07.340]   I know I'm like two years late to that game.
[01:46:07.340 --> 01:46:09.140]   But if you haven't played it--
[01:46:09.140 --> 01:46:15.780]   Connie is smiling, benignly at us like you nerds.
[01:46:15.780 --> 01:46:19.020]   I live in a family surrounded by games.
[01:46:19.020 --> 01:46:22.460]   I mean, there was that whole period of time
[01:46:22.460 --> 01:46:24.940]   when Uncharted was going on in the background.
[01:46:24.940 --> 01:46:28.660]   And then Last of Us, which I had to leave the room for.
[01:46:28.660 --> 01:46:31.940]   Personally, the game that I discovered during the pandemic
[01:46:31.940 --> 01:46:33.420]   was a deck of cards.
[01:46:33.420 --> 01:46:34.780]   Oh, that's nice.
[01:46:34.780 --> 01:46:36.420]   I never knew anywhere.
[01:46:36.420 --> 01:46:40.180]   So like on a Switch, a deck of cards on a Switch.
[01:46:40.180 --> 01:46:40.680]   No.
[01:46:40.680 --> 01:46:41.580]   On Xbox.
[01:46:41.580 --> 01:46:43.980]   A solitaire, the game on your phone.
[01:46:43.980 --> 01:46:47.660]   It's this thing Nintendo used to do about 100 years ago.
[01:46:47.660 --> 01:46:50.380]   They make card for playing cards.
[01:46:50.380 --> 01:46:52.260]   People don't realize that.
[01:46:52.260 --> 01:46:53.580]   I mentioned that fact once.
[01:46:53.580 --> 01:46:55.100]   And people are like, no, that's not true.
[01:46:55.100 --> 01:46:57.300]   Like, no, seriously, they used to make cards.
[01:46:57.300 --> 01:46:59.260]   Pokemon was a card game.
[01:46:59.260 --> 01:47:03.100]   So Connie, are your kids excited about the TV show The Last
[01:47:03.100 --> 01:47:06.540]   of Us, which comes out next week?
[01:47:06.540 --> 01:47:07.660]   So it would be my son.
[01:47:07.660 --> 01:47:10.300]   I think he's a little busy in school right now.
[01:47:10.300 --> 01:47:15.100]   I am curious the reviews have been mixed on it.
[01:47:15.100 --> 01:47:17.060]   There are things that have scared me in the past.
[01:47:17.060 --> 01:47:19.940]   And I have to say, just watching from afar that game.
[01:47:19.940 --> 01:47:20.940]   Scared me.
[01:47:20.940 --> 01:47:21.460]   Yeah.
[01:47:21.460 --> 01:47:22.020]   Scared me.
[01:47:22.020 --> 01:47:24.940]   So not on my list.
[01:47:24.940 --> 01:47:26.460]   It's a really good game.
[01:47:26.460 --> 01:47:29.060]   Leo, I discovered a game during the pandemic.
[01:47:29.060 --> 01:47:31.940]   And you want to read the number of hours
[01:47:31.940 --> 01:47:32.940]   that's been played?
[01:47:32.940 --> 01:47:35.500]   So he's showing me his steam log in.
[01:47:35.500 --> 01:47:36.540]   Six hours?
[01:47:36.540 --> 01:47:37.460]   Oh, no.
[01:47:37.460 --> 01:47:38.660]   Oh, 4 million.
[01:47:38.660 --> 01:47:42.060]   4,661.6.
[01:47:42.060 --> 01:47:43.980]   Oxygen not included.
[01:47:43.980 --> 01:47:45.460]   It's addictive.
[01:47:45.460 --> 01:47:47.140]   And what is the premise of it?
[01:47:47.140 --> 01:47:52.060]   It's basically just like a colonization simulator.
[01:47:52.060 --> 01:47:53.820]   You're not doing factorial anymore?
[01:47:53.820 --> 01:47:56.140]   I do factorial, but you know what?
[01:47:56.140 --> 01:47:58.900]   You had a Vatican factorial server.
[01:47:58.900 --> 01:47:59.580]   Yes.
[01:47:59.580 --> 01:48:02.140]   But see, that's again that requires active participation.
[01:48:02.140 --> 01:48:04.340]   Oxygen not included is more like an ant farm,
[01:48:04.340 --> 01:48:06.180]   where you could set a bunch of stuff up
[01:48:06.180 --> 01:48:08.620]   and then just let it run and see if it's going to survive.
[01:48:08.620 --> 01:48:09.660]   Oh, I like this.
[01:48:09.660 --> 01:48:10.180]   Yeah.
[01:48:10.180 --> 01:48:12.660]   So those fourth whatever million hours,
[01:48:12.660 --> 01:48:14.420]   you weren't sitting in front of the screen all the time.
[01:48:14.420 --> 01:48:14.780]   Correct.
[01:48:14.780 --> 01:48:16.740]   It would run overnight and I'd wake up in the morning.
[01:48:16.740 --> 01:48:17.500]   Oh, this is cool.
[01:48:17.500 --> 01:48:18.740]   It's kind of like factorial.
[01:48:18.740 --> 01:48:18.940]   Yeah.
[01:48:18.940 --> 01:48:20.780]   It looks like Fallout meets factorial.
[01:48:20.780 --> 01:48:21.420]   It's fun.
[01:48:21.420 --> 01:48:22.340]   It's really fun.
[01:48:22.340 --> 01:48:23.620]   It's single player only.
[01:48:23.620 --> 01:48:25.340]   So there's no holding still there.
[01:48:25.340 --> 01:48:26.260]   Challenge.
[01:48:26.260 --> 01:48:27.540]   Can I play it on the switch?
[01:48:27.540 --> 01:48:29.340]   Yes, you can.
[01:48:29.340 --> 01:48:30.860]   Oh, it's Linux.
[01:48:30.860 --> 01:48:34.340]   You can buy the use deck of cards from the kitchen.
[01:48:34.340 --> 01:48:38.300]   I'm going to get $1 for $1.
[01:48:38.300 --> 01:48:42.700]   What game, what game, the card game do you play, Connie?
[01:48:42.700 --> 01:48:44.260]   You know, sometimes you play war.
[01:48:44.260 --> 01:48:45.100]   Sometimes we play.
[01:48:45.100 --> 01:48:45.940]   Yeah.
[01:48:45.940 --> 01:48:46.940]   Come on.
[01:48:46.940 --> 01:48:47.940]   Spades.
[01:48:47.940 --> 01:48:48.940]   Spades.
[01:48:48.940 --> 01:48:50.460]   No, wait, Connie, you have four players.
[01:48:50.460 --> 01:48:52.660]   Can you play spades?
[01:48:52.660 --> 01:48:54.420]   You need four players.
[01:48:54.420 --> 01:48:54.740]   Yeah.
[01:48:54.740 --> 01:48:57.260]   No, it's usually my husband and myself traveling.
[01:48:57.260 --> 01:48:59.500]   And now we've made it a point going back
[01:48:59.500 --> 01:49:02.420]   to your app there about restaurants.
[01:49:02.420 --> 01:49:04.220]   Finding cafes where we go into town.
[01:49:04.220 --> 01:49:05.340]   It's a shopping place.
[01:49:05.340 --> 01:49:06.660]   That's what Lisa and I do.
[01:49:06.660 --> 01:49:08.020]   We always bring a deck of cards.
[01:49:08.020 --> 01:49:09.540]   We play cribbage.
[01:49:09.540 --> 01:49:11.260]   You ever play cribbage?
[01:49:11.260 --> 01:49:14.100]   There is an antiquated game.
[01:49:14.100 --> 01:49:18.540]   Now, my table game isn't so portable because I play mahjong.
[01:49:18.540 --> 01:49:19.540]   And that was part of it.
[01:49:19.540 --> 01:49:20.940]   I saw you played mahjong with your family.
[01:49:20.940 --> 01:49:22.860]   50 pounds of tiles to do that.
[01:49:22.860 --> 01:49:25.380]   Yeah, that was the cutest picture of you and your dad
[01:49:25.380 --> 01:49:28.300]   who's sitting there and your mom and you're playing my mom.
[01:49:28.300 --> 01:49:30.140]   My mom cheats.
[01:49:30.140 --> 01:49:31.580]   Cheats at mahjong right now.
[01:49:31.580 --> 01:49:32.780]   Mom, I know you're cheating.
[01:49:32.780 --> 01:49:33.220]   Don't cheat.
[01:49:33.220 --> 01:49:34.780]   I know you're cheating.
[01:49:34.780 --> 01:49:37.140]   She wins way too much to not be cheating.
[01:49:37.140 --> 01:49:39.140]   Connie, do you feel like at least good at cheating?
[01:49:39.140 --> 01:49:40.420]   Does she have a good blob?
[01:49:40.420 --> 01:49:41.820]   Oh, she is excellent.
[01:49:41.820 --> 01:49:43.140]   So, mahjong, you're sitting--
[01:49:43.140 --> 01:49:47.180]   I've just seen people play behind ivory tiles
[01:49:47.180 --> 01:49:49.700]   with Chinese characters and pictures of dragons and stuff
[01:49:49.700 --> 01:49:50.660]   on them.
[01:49:50.660 --> 01:49:52.060]   And then there's a pool in the middle.
[01:49:52.060 --> 01:49:53.460]   It kind of looks like Scrabble.
[01:49:53.460 --> 01:49:54.380]   It kind of looks like Scrabble.
[01:49:54.380 --> 01:49:56.620]   And it's a card game.
[01:49:56.620 --> 01:50:04.260]   So, the whole idea is to get five sets of three.
[01:50:04.260 --> 01:50:04.980]   You're trying to organize them.
[01:50:04.980 --> 01:50:06.260]   And then a two, a set of two.
[01:50:06.260 --> 01:50:07.260]   Yeah.
[01:50:07.260 --> 01:50:07.940]   Because you have--
[01:50:07.940 --> 01:50:10.260]   Right, and then so you throw tiles in and other people
[01:50:10.260 --> 01:50:11.700]   can take tiles down.
[01:50:11.700 --> 01:50:14.220]   OK, how could you cheat?
[01:50:14.220 --> 01:50:15.300]   You look at what's under the--
[01:50:15.300 --> 01:50:18.020]   What I'm trying to figure out.
[01:50:18.020 --> 01:50:19.380]   I mean, if it was easy--
[01:50:19.380 --> 01:50:21.700]   You just got to pick your mom up and give her a big kind
[01:50:21.700 --> 01:50:23.580]   of shaking, hard and see some tiles.
[01:50:23.580 --> 01:50:25.380]   Oh, it's far out there.
[01:50:25.380 --> 01:50:30.740]   And the worst thing about it is she's such a good winner
[01:50:30.740 --> 01:50:32.020]   that it's hard to be mad at her.
[01:50:32.020 --> 01:50:34.340]   She's like, oh, it looks like I won again.
[01:50:34.340 --> 01:50:36.540]   Oh, I'm sure you'll get it next time.
[01:50:36.540 --> 01:50:38.020]   I'm like, oh!
[01:50:38.020 --> 01:50:40.900]   Connie, have you ever played Cribbitch?
[01:50:40.900 --> 01:50:41.980]   I have not played Cribbitch.
[01:50:41.980 --> 01:50:43.660]   We are a backgammon family.
[01:50:43.660 --> 01:50:44.940]   Backgammon's nice.
[01:50:44.940 --> 01:50:48.940]   And then when you play cards, you play Rummy, Jin.
[01:50:48.940 --> 01:50:52.620]   We play all sorts of things.
[01:50:52.620 --> 01:50:54.100]   I mean, everything is fine.
[01:50:54.100 --> 01:50:55.540]   I'm telling you.
[01:50:55.540 --> 01:50:56.820]   I started playing Cribbitch in college
[01:50:56.820 --> 01:50:58.980]   because you could play it when you were really high.
[01:50:58.980 --> 01:51:01.100]   [LAUGHTER]
[01:51:01.100 --> 01:51:01.940]   It does no--
[01:51:01.940 --> 01:51:04.620]   So wait, did you use the pegs or were there something else
[01:51:04.620 --> 01:51:05.180]   that you put in those?
[01:51:05.180 --> 01:51:06.140]   Yeah, sure, you could do it.
[01:51:06.140 --> 01:51:09.260]   Well, we used to take bong hits on the turns, actually,
[01:51:09.260 --> 01:51:10.860]   that you mentioned it.
[01:51:10.860 --> 01:51:12.860]   The idea is you gain points.
[01:51:12.860 --> 01:51:14.020]   You have hands.
[01:51:14.020 --> 01:51:16.140]   You could play from two to six players.
[01:51:16.140 --> 01:51:19.220]   And you play the cards out, and then you count your hands.
[01:51:19.220 --> 01:51:20.980]   And you could do it pretty high.
[01:51:20.980 --> 01:51:25.140]   And then whoever wins this little pegging race.
[01:51:25.140 --> 01:51:25.980]   And it's really fun.
[01:51:25.980 --> 01:51:27.900]   That's not all courage boards look like the number two.
[01:51:27.900 --> 01:51:30.580]   You cannot play Ma Zhong Hai.
[01:51:30.580 --> 01:51:32.100]   Yeah, no, you couldn't.
[01:51:32.100 --> 01:51:35.500]   No, and that's what I'm looking for in a game, to be honest.
[01:51:35.500 --> 01:51:36.700]   Not anymore.
[01:51:36.700 --> 01:51:39.300]   No, I mean, Leo, maybe this will work.
[01:51:39.300 --> 01:51:40.300]   I need Merkel.
[01:51:40.300 --> 01:51:40.980]   You have?
[01:51:40.980 --> 01:51:41.980]   It's a Merkel.
[01:51:41.980 --> 01:51:42.500]   Huh?
[01:51:42.500 --> 01:51:42.980]   Merkel.
[01:51:42.980 --> 01:51:43.980]   It's a Merkel.
[01:51:43.980 --> 01:51:46.380]   It might also stop marijuana.
[01:51:46.380 --> 01:51:47.700]   I have--
[01:51:47.700 --> 01:51:49.100]   Might stop your heart, too.
[01:51:49.100 --> 01:51:50.620]   Might stop your heart.
[01:51:50.620 --> 01:51:51.460]   But you're not drunk.
[01:51:51.460 --> 01:51:51.980]   Exactly.
[01:51:51.980 --> 01:51:52.820]   On the bright side.
[01:51:52.820 --> 01:51:53.320]   True.
[01:51:53.320 --> 01:51:53.420]   You're dead.
[01:51:53.420 --> 01:51:55.460]   You don't have a hangover.
[01:51:55.460 --> 01:51:59.420]   So I wanted to show you, speaking of chat GPT and AI,
[01:51:59.420 --> 01:52:01.380]   I've been using a new search engine, which I'm starting
[01:52:01.380 --> 01:52:05.060]   to think might be my new permanent search engine to play
[01:52:05.060 --> 01:52:07.140]   school you pay for, five bucks a month.
[01:52:07.140 --> 01:52:08.300]   So there's no ads.
[01:52:08.300 --> 01:52:09.340]   It's called Niva.
[01:52:09.340 --> 01:52:10.580]   It's from former Google executives.
[01:52:10.580 --> 01:52:11.420]   But look at this.
[01:52:11.420 --> 01:52:13.060]   See this paragraph at the beginning?
[01:52:13.060 --> 01:52:17.420]   Instead of the Google knowledge box that's stolen from Wikipedia,
[01:52:17.420 --> 01:52:22.980]   it uses AI to generate a summary of a number of--
[01:52:22.980 --> 01:52:26.260]   and it gives you footnotes so you know where they came from.
[01:52:26.260 --> 01:52:28.900]   And this is actually a very good use of it.
[01:52:28.900 --> 01:52:30.380]   Give me something.
[01:52:30.380 --> 01:52:36.700]   Let's see, how does Pope get chosen?
[01:52:36.700 --> 01:52:38.860]   We all know the white smoke and all of that stuff.
[01:52:38.860 --> 01:52:40.740]   Let's see what it does here.
[01:52:40.740 --> 01:52:42.020]   Conclave, yeah.
[01:52:42.020 --> 01:52:45.380]   No, but it didn't generate an AI thing.
[01:52:45.380 --> 01:52:46.740]   Well, it does too--
[01:52:46.740 --> 01:52:49.060]   Maybe it's too-- yeah.
[01:52:49.060 --> 01:52:50.340]   How do I quit smoking?
[01:52:50.340 --> 01:52:55.780]   I don't know why I thought of white smoking smoking, but I did.
[01:52:55.780 --> 01:52:57.420]   I actually heard that Merkel is actually pretty good.
[01:52:57.420 --> 01:52:58.740]   Merkel would do that.
[01:52:58.740 --> 01:52:59.100]   Let's see.
[01:52:59.100 --> 01:53:00.260]   How do I quit drinking?
[01:53:00.260 --> 01:53:02.340]   And now it's-- oh, you know what?
[01:53:02.340 --> 01:53:04.260]   Maybe it's-- oh, it can never mind.
[01:53:04.260 --> 01:53:05.260]   It's never mind.
[01:53:05.260 --> 01:53:05.780]   It's interesting.
[01:53:05.780 --> 01:53:06.180]   Let's see.
[01:53:06.180 --> 01:53:08.140]   Does Merkel work well?
[01:53:08.140 --> 01:53:08.620]   Does--
[01:53:08.620 --> 01:53:10.100]   [LAUGHTER]
[01:53:10.100 --> 01:53:12.540]   Merkel work.
[01:53:12.540 --> 01:53:13.620]   Oh, you know what?
[01:53:13.620 --> 01:53:16.340]   It's auto-completing it.
[01:53:16.340 --> 01:53:17.060]   Oh, here it comes.
[01:53:17.060 --> 01:53:18.060]   Here it comes.
[01:53:18.060 --> 01:53:19.620]   Merkel is a free-thinking pill that's
[01:53:19.620 --> 01:53:22.900]   set to break down up to 70% of alcohol for 60 minutes.
[01:53:22.900 --> 01:53:24.780]   It's a probiotic supplement.
[01:53:24.780 --> 01:53:25.140]   Wow.
[01:53:25.140 --> 01:53:27.340]   And it's getting this from a variety of sources,
[01:53:27.340 --> 01:53:29.820]   including the sun.
[01:53:29.820 --> 01:53:32.060]   Oh, that's a great source there.
[01:53:32.060 --> 01:53:33.300]   Never anything wrong there.
[01:53:33.300 --> 01:53:35.820]   But they actually do a pretty good job of saying,
[01:53:35.820 --> 01:53:38.180]   when you're talking about COVID information, which is,
[01:53:38.180 --> 01:53:42.140]   let's see, does the COVID vaccine work?
[01:53:42.140 --> 01:53:42.540]   Let's see.
[01:53:42.540 --> 01:53:44.740]   This is a tough one for search engines, right?
[01:53:44.740 --> 01:53:47.580]   Let's see what it says here.
[01:53:47.580 --> 01:53:49.900]   I just-- I think it's very-- it's-- you know,
[01:53:49.900 --> 01:53:51.060]   notice it's a little slow.
[01:53:51.060 --> 01:53:52.220]   It's not as fast as Google.
[01:53:52.220 --> 01:53:53.100]   That's a hard thing to do.
[01:53:53.100 --> 01:53:54.340]   It's giving precedence to CDC.
[01:53:54.340 --> 01:53:54.980]   That's not bad.
[01:53:54.980 --> 01:53:57.540]   So and then what it does see these verified things,
[01:53:57.540 --> 01:54:01.780]   it's behind-- next to search results that are considered
[01:54:01.780 --> 01:54:06.380]   verified, you know, reliable, it puts a little verified link.
[01:54:06.380 --> 01:54:08.260]   So I think that's kind of interesting.
[01:54:08.260 --> 01:54:10.460]   Well, that means that Elon Musk was going to buy this,
[01:54:10.460 --> 01:54:12.180]   and they're going to be able to buy it very good.
[01:54:12.180 --> 01:54:12.180]   Very good.
[01:54:12.180 --> 01:54:13.180]   $8 a month.
[01:54:13.180 --> 01:54:13.680]   Yeah.
[01:54:13.680 --> 01:54:14.180]   Yeah.
[01:54:14.180 --> 01:54:14.660]   That's good stuff.
[01:54:14.660 --> 01:54:15.860]   Yeah.
[01:54:15.860 --> 01:54:18.780]   So you know what search engine was
[01:54:18.780 --> 01:54:21.460]   able to give me an answer to how does a pope get chosen?
[01:54:21.460 --> 01:54:22.540]   No, Bing.
[01:54:22.540 --> 01:54:23.540]   Bing.
[01:54:23.540 --> 01:54:25.220]   Got their pictures and everything.
[01:54:25.220 --> 01:54:25.780]   Am I the only--
[01:54:25.780 --> 01:54:26.980]   I think I'd be the only--
[01:54:26.980 --> 01:54:27.420]   You're the only--
[01:54:27.420 --> 01:54:27.740]   You're the only--
[01:54:27.740 --> 01:54:28.820]   --twizz person that uses Bing.
[01:54:28.820 --> 01:54:29.660]   You are definitely.
[01:54:29.660 --> 01:54:30.940]   It is my standard--
[01:54:30.940 --> 01:54:31.940]   Why?
[01:54:31.940 --> 01:54:34.140]   I just-- I like splitting up my data.
[01:54:34.140 --> 01:54:35.100]   How?
[01:54:35.100 --> 01:54:37.460]   Honestly, it gives me better results.
[01:54:37.460 --> 01:54:38.540]   I don't have to try it.
[01:54:38.540 --> 01:54:39.540]   Are you sure?
[01:54:39.540 --> 01:54:41.620]   I have been using it.
[01:54:41.620 --> 01:54:43.500]   I have been using it for eight years.
[01:54:43.500 --> 01:54:45.740]   Skepticism here, Father.
[01:54:45.740 --> 01:54:47.780]   Let's see what Niva says about Bing.
[01:54:47.780 --> 01:54:50.340]   Bing is a search engine developed by Microsoft.
[01:54:50.340 --> 01:54:52.700]   By the way, it gets its result from Google.
[01:54:52.700 --> 01:54:55.420]   It is designed to provide trusted search results
[01:54:55.420 --> 01:54:57.780]   fast, like Microsoft rewards points.
[01:54:57.780 --> 01:54:59.460]   That's one of my problems with the track topics
[01:54:59.460 --> 01:55:00.620]   and trending stories.
[01:55:00.620 --> 01:55:03.660]   Take control of user privacy.
[01:55:03.660 --> 01:55:04.700]   That's not a bad.
[01:55:04.700 --> 01:55:05.900]   They could say it, but we're better.
[01:55:05.900 --> 01:55:06.620]   But no, they don't.
[01:55:06.620 --> 01:55:07.540]   No.
[01:55:07.540 --> 01:55:10.260]   I just like-- and also, I like splitting up my data
[01:55:10.260 --> 01:55:11.860]   among some of the big players.
[01:55:11.860 --> 01:55:12.540]   Yeah, yeah.
[01:55:12.540 --> 01:55:13.660]   Well, that's why I want to use Niva.
[01:55:13.660 --> 01:55:14.740]   That's exactly right.
[01:55:14.740 --> 01:55:17.260]   Although Google can't figure me out
[01:55:17.260 --> 01:55:19.020]   because I fuzz all my data.
[01:55:19.020 --> 01:55:21.820]   It's got geo-located data in multiple languages
[01:55:21.820 --> 01:55:25.340]   from different parts of the world at the same time.
[01:55:25.340 --> 01:55:25.900]   Yeah.
[01:55:25.900 --> 01:55:26.980]   What else you got?
[01:55:26.980 --> 01:55:27.980]   Oh, here.
[01:55:27.980 --> 01:55:29.540]   You need this.
[01:55:29.540 --> 01:55:31.020]   Do I eat it or is it helping?
[01:55:31.020 --> 01:55:32.420]   It's just a positive drinking.
[01:55:32.420 --> 01:55:33.100]   Oh, I'm going to get you.
[01:55:33.100 --> 01:55:34.260]   Just put it right in there.
[01:55:34.260 --> 01:55:35.260]   No questions.
[01:55:35.260 --> 01:55:35.780]   Yeah.
[01:55:35.780 --> 01:55:36.280]   Yeah.
[01:55:36.280 --> 01:55:37.060]   So open it up.
[01:55:37.060 --> 01:55:38.220]   Open it up.
[01:55:38.220 --> 01:55:39.220]   These are the little earbuds.
[01:55:39.220 --> 01:55:40.060]   It says, quiet on.
[01:55:40.060 --> 01:55:40.980]   Quiet on.
[01:55:40.980 --> 01:55:42.460]   On the top of it.
[01:55:42.460 --> 01:55:45.260]   I know that you've played with a few of these before.
[01:55:45.260 --> 01:55:46.900]   These are just the bows.
[01:55:46.900 --> 01:55:49.100]   I use the bows-- or I tried the bows.
[01:55:49.100 --> 01:55:51.860]   I still have them, but I never really use them.
[01:55:51.860 --> 01:55:52.940]   But they were bows in years.
[01:55:52.940 --> 01:55:55.780]   They basically take their existing quiet comfort, probably
[01:55:55.780 --> 01:55:59.980]   the 35s, and turn off the ability to play music.
[01:55:59.980 --> 01:56:02.100]   And all I could do is play tracks from your bows
[01:56:02.100 --> 01:56:03.100]   out of the phone.
[01:56:03.100 --> 01:56:07.020]   And that's a problem because most of the sleeping buds,
[01:56:07.020 --> 01:56:09.500]   what they do is they give you white noise.
[01:56:09.500 --> 01:56:10.380]   Yeah.
[01:56:10.380 --> 01:56:11.300]   Or oceans.
[01:56:11.300 --> 01:56:11.940]   Or oceans.
[01:56:11.940 --> 01:56:12.700]   Or jungles.
[01:56:12.700 --> 01:56:16.260]   And they've actually shown that any sort of noise
[01:56:16.260 --> 01:56:17.300]   does disrupt the sleep.
[01:56:17.300 --> 01:56:19.300]   You may be able to fall asleep, but you're not falling
[01:56:19.300 --> 01:56:20.020]   into as deep as you like.
[01:56:20.020 --> 01:56:21.020]   I like about these ear.
[01:56:21.020 --> 01:56:22.460]   It's a lot smaller than the bows.
[01:56:22.460 --> 01:56:23.460]   Super small.
[01:56:23.460 --> 01:56:25.820]   And they fit into your ear well enough.
[01:56:25.820 --> 01:56:27.740]   Because I can't sleep with--
[01:56:27.740 --> 01:56:28.240]   Yes.
[01:56:28.240 --> 01:56:29.240]   --because I sit on my side.
[01:56:29.240 --> 01:56:30.240]   I can't sleep with these in.
[01:56:30.240 --> 01:56:32.260]   These are better than flush.
[01:56:32.260 --> 01:56:33.980]   So you can side sleep in these, and you're not
[01:56:33.980 --> 01:56:36.180]   going to feel them pressing into your ear.
[01:56:36.180 --> 01:56:38.540]   They use foam, so it gives you a nice seal.
[01:56:38.540 --> 01:56:42.340]   But instead of white noise, it's actual cancellation.
[01:56:42.340 --> 01:56:43.900]   So it's got little mics on the outside,
[01:56:43.900 --> 01:56:45.220]   and it's canceling the noise.
[01:56:45.220 --> 01:56:47.260]   Trade marks that because I think there's a toilet
[01:56:47.260 --> 01:56:50.300]   manufacturer who wants to use better than flush for a
[01:56:50.300 --> 01:56:51.860]   fair slicker.
[01:56:51.860 --> 01:56:54.020]   One of the urine detector sets or things.
[01:56:54.020 --> 01:56:56.060]   Did you try any of those?
[01:56:56.060 --> 01:56:59.460]   I mean, not on the show floor.
[01:56:59.460 --> 01:57:01.660]   No peeing on the show floor.
[01:57:01.660 --> 01:57:02.460]   They actually had a demo.
[01:57:02.460 --> 01:57:04.420]   And that's why it's always a good strategy just
[01:57:04.420 --> 01:57:07.180]   carry around a bottle of piss around.
[01:57:07.180 --> 01:57:08.460]   And so you're ready--
[01:57:08.460 --> 01:57:09.220]   Try everything out.
[01:57:09.220 --> 01:57:12.980]   --and say, try this as you do in my pregnant.
[01:57:12.980 --> 01:57:13.540]   Very important.
[01:57:13.540 --> 01:57:16.580]   And they go, father, I think you should expect something
[01:57:16.580 --> 01:57:18.020]   in the lightful in six months.
[01:57:18.020 --> 01:57:19.980]   You know, when I was still working at Twit,
[01:57:19.980 --> 01:57:23.420]   I would get blood work at the Quest Diagnostics here.
[01:57:23.420 --> 01:57:25.380]   Probably once every three months or so.
[01:57:25.380 --> 01:57:28.100]   And every single time I went, there was always someone who
[01:57:28.100 --> 01:57:29.940]   wanted to buy my urine.
[01:57:29.940 --> 01:57:30.460]   What?
[01:57:30.460 --> 01:57:30.980]   Out front?
[01:57:30.980 --> 01:57:32.180]   Yeah, out front?
[01:57:32.180 --> 01:57:32.980]   See me going in.
[01:57:32.980 --> 01:57:33.180]   Hey, man.
[01:57:33.180 --> 01:57:34.220]   They see a priest.
[01:57:34.220 --> 01:57:35.620]   No, no, no, not just like this.
[01:57:35.620 --> 01:57:36.980]   They just want to buy anyone's urine.
[01:57:36.980 --> 01:57:38.620]   I'm like, well, I know what you're trying to do.
[01:57:38.620 --> 01:57:41.660]   But can you pee in this bottle for me?
[01:57:41.660 --> 01:57:43.500]   I'll give you $100.
[01:57:43.500 --> 01:57:45.060]   When do you go behind the--
[01:57:45.060 --> 01:57:45.900]   --stand behind a bush?
[01:57:45.900 --> 01:57:47.180]   No, that's why--
[01:57:47.180 --> 01:57:49.300]   Now I just go out there with a bottle in my hand.
[01:57:49.300 --> 01:57:51.500]   I'm just like, it's cold, man.
[01:57:51.500 --> 01:57:53.500]   Can you warm that up, man?
[01:57:53.500 --> 01:57:54.580]   All right, I got to take a break.
[01:57:54.580 --> 01:57:55.820]   This is too much.
[01:57:55.820 --> 01:57:57.900]   Our show today brought to you by-- we'll have more
[01:57:57.900 --> 01:57:59.980]   with our fabulous panelist, Panalikon and Guillomo,
[01:57:59.980 --> 01:58:02.540]   editor in chief of CNET.
[01:58:02.540 --> 01:58:05.220]   She is slumming with us, but we're very glad to have her.
[01:58:05.220 --> 01:58:07.980]   Thank you for spending some time with us.
[01:58:07.980 --> 01:58:11.140]   Paris Martinau, who is the great reporter of the information.
[01:58:11.140 --> 01:58:14.020]   Man, Wayne Ma had some great Apple stories
[01:58:14.020 --> 01:58:14.900]   the last couple of weeks.
[01:58:14.900 --> 01:58:15.420]   You guys--
[01:58:15.420 --> 01:58:17.020]   Wayne is insane.
[01:58:17.020 --> 01:58:18.940]   Breaking news.
[01:58:18.940 --> 01:58:20.780]   Truly, one of the best reporters I've ever ever--
[01:58:20.780 --> 01:58:21.300]   I am.
[01:58:21.300 --> 01:58:21.780]   --had to watch a book.
[01:58:21.780 --> 01:58:24.060]   I happily pay for the information.
[01:58:24.060 --> 01:58:28.060]   I think I did back when Ms. Lezen started it.
[01:58:28.060 --> 01:58:30.820]   And I have never stopped because your stuff is so good.
[01:58:30.820 --> 01:58:31.980]   And I love your stuff, Paris.
[01:58:31.980 --> 01:58:33.580]   Yeah, we have a huge staff now.
[01:58:33.580 --> 01:58:35.100]   It's got big, hasn't it?
[01:58:35.100 --> 01:58:37.340]   We got so many people over the course of the pandemic.
[01:58:37.340 --> 01:58:41.700]   When I started in mid-2020, we had maybe two other people
[01:58:41.700 --> 01:58:42.740]   in New York.
[01:58:42.740 --> 01:58:45.780]   Now we have had such a large New York-based staff.
[01:58:45.780 --> 01:58:48.260]   We've had two open an office--
[01:58:48.260 --> 01:58:48.780]   Wow.
[01:58:48.780 --> 01:58:50.540]   --previously we're in a WeWork space.
[01:58:50.540 --> 01:58:51.860]   We outgrew that office.
[01:58:51.860 --> 01:58:53.060]   We had to renovate the floor below.
[01:58:53.060 --> 01:58:53.860]   Oh, I am so happy.
[01:58:53.860 --> 01:58:57.260]   And now we're pushing the limits of that.
[01:58:57.260 --> 01:58:59.900]   You've got a Mira Friday that has such great Google stuff.
[01:58:59.900 --> 01:59:01.420]   You've really got great people.
[01:59:01.420 --> 01:59:02.900]   Yeah.
[01:59:02.900 --> 01:59:05.220]   You know, when Jessica Lezen started this,
[01:59:05.220 --> 01:59:07.780]   this was a big jump, big leap.
[01:59:07.780 --> 01:59:12.940]   Like, can you make it with a kind of starting from scratch,
[01:59:12.940 --> 01:59:17.700]   $400 a year subscription news service?
[01:59:17.700 --> 01:59:21.620]   And I bet you most people thought, well, 50/50.
[01:59:21.620 --> 01:59:22.980]   And certainly there were a lot of people
[01:59:22.980 --> 01:59:27.060]   who failed around that, including Rupert Murdoch.
[01:59:27.060 --> 01:59:29.940]   But she's done such a great job.
[01:59:29.940 --> 01:59:32.340]   And now it's going to gangbusters.
[01:59:32.340 --> 01:59:32.700]   Yeah.
[01:59:32.700 --> 01:59:35.220]   I mean, now, of course, everyone in news
[01:59:35.220 --> 01:59:36.940]   is pivoting to the subscription model,
[01:59:36.940 --> 01:59:39.300]   because advertising isn't forever.
[01:59:39.300 --> 01:59:40.340]   Yep.
[01:59:40.340 --> 01:59:42.180]   Are there no ads on the information?
[01:59:42.180 --> 01:59:43.300]   I don't even notice.
[01:59:43.300 --> 01:59:44.860]   No, we don't have ads.
[01:59:44.860 --> 01:59:46.860]   I mean, I think that there are sometimes
[01:59:46.860 --> 01:59:50.060]   maybe like a message from a sponsor in a newsletter.
[01:59:50.060 --> 01:59:52.140]   But other than that, no ads.
[01:59:52.140 --> 01:59:52.700]   That's really good.
[01:59:52.700 --> 01:59:53.700]   This is--
[01:59:53.700 --> 01:59:55.180]   Wow, I'm so happy for you.
[01:59:55.180 --> 01:59:57.300]   That's fantastic.
[01:59:57.300 --> 01:59:59.900]   Very nice.
[01:59:59.900 --> 02:00:02.780]   Let's talk a little bit about getting a job.
[02:00:02.780 --> 02:00:04.380]   What do you say?
[02:00:04.380 --> 02:00:07.500]   This is an interesting time, isn't it?
[02:00:07.500 --> 02:00:09.500]   Our show today brought to you by ZipRecruiter,
[02:00:09.500 --> 02:00:12.820]   the smartest way to hire.
[02:00:12.820 --> 02:00:13.980]   This time of year is tough.
[02:00:13.980 --> 02:00:17.540]   For any business, you've got new goals for the new year,
[02:00:17.540 --> 02:00:20.780]   but you've got to find the right people to accomplish them.
[02:00:20.780 --> 02:00:24.700]   And weirdly, it's hard to find people.
[02:00:24.700 --> 02:00:27.060]   There is definitely a shortage of skilled jobs
[02:00:27.060 --> 02:00:29.500]   finding qualified candidates or adjusting
[02:00:29.500 --> 02:00:32.940]   to candidates' work preferences can be challenging.
[02:00:32.940 --> 02:00:34.900]   It's a challenge we all face.
[02:00:34.900 --> 02:00:38.020]   I could tell you what we use when it's time to hire.
[02:00:38.020 --> 02:00:38.940]   We use ZipRecruiter.
[02:00:38.940 --> 02:00:41.340]   And I have to say, when you are hiring,
[02:00:41.340 --> 02:00:43.580]   often that's the worst time to hire, in a way.
[02:00:43.580 --> 02:00:48.860]   Because somebody leaves, and then suddenly you're down a person.
[02:00:48.860 --> 02:00:51.660]   And at the same time as you're trying to hire somebody,
[02:00:51.660 --> 02:00:52.900]   you've got to get that work done.
[02:00:52.900 --> 02:00:54.660]   And it's just nuts.
[02:00:54.660 --> 02:00:59.420]   ZipRecruiter is the place to go to get your hiring done.
[02:00:59.420 --> 02:01:01.660]   And I could say that with absolute confidence,
[02:01:01.660 --> 02:01:02.860]   because it's what we use.
[02:01:02.860 --> 02:01:04.260]   And it's worked so well for us.
[02:01:04.260 --> 02:01:05.900]   Right now, you can try it free.
[02:01:05.900 --> 02:01:10.300]   ziprecruiter.com/twit.
[02:01:10.300 --> 02:01:14.660]   About six months ago, Ashley decided our wonderful continuity.
[02:01:14.660 --> 02:01:17.740]   A person decided to go somewhere else.
[02:01:17.740 --> 02:01:19.180]   I think she got a job closer to home.
[02:01:19.180 --> 02:01:21.060]   She didn't want to commute.
[02:01:21.060 --> 02:01:22.060]   Gave us notice.
[02:01:22.060 --> 02:01:25.220]   But we said, how are we going to replace Ashley?
[02:01:25.220 --> 02:01:27.660]   We placed a ad on ZipRecruiter.
[02:01:27.660 --> 02:01:28.740]   And one of the things that happens
[02:01:28.740 --> 02:01:30.540]   is ZipRecruiter, the first thing that happens,
[02:01:30.540 --> 02:01:32.980]   you're posting everywhere to more than 100 job sites
[02:01:32.980 --> 02:01:35.220]   to social networks everywhere.
[02:01:35.220 --> 02:01:37.020]   But then something amazing kind of happens.
[02:01:37.020 --> 02:01:39.700]   And I'll incidentally, don't fear posting all over the place,
[02:01:39.700 --> 02:01:41.780]   because why do you cast a net more likely?
[02:01:41.780 --> 02:01:44.380]   That perfect employee will see you're posting.
[02:01:44.380 --> 02:01:47.180]   But then you say, oh, I don't want 100 people calling me
[02:01:47.180 --> 02:01:49.540]   or emailing, putting email.
[02:01:49.540 --> 02:01:51.860]   And it all goes to the ZipRecruiter interface, all of it,
[02:01:51.860 --> 02:01:53.740]   including the resumes, which they reformat,
[02:01:53.740 --> 02:01:55.100]   so they're easy to scan.
[02:01:55.100 --> 02:01:57.140]   You can have automated screening questions
[02:01:57.140 --> 02:01:59.820]   to eliminate people who are just not right for the job.
[02:01:59.820 --> 02:02:01.620]   But then the magic happens.
[02:02:01.620 --> 02:02:03.860]   That's it, recruiter, because they have this technology.
[02:02:03.860 --> 02:02:06.700]   What they do is they match the requirements of your job
[02:02:06.700 --> 02:02:07.780]   to those resumes.
[02:02:07.780 --> 02:02:10.540]   And they find candidates who fit your needs
[02:02:10.540 --> 02:02:12.220]   and then tell you about them.
[02:02:12.220 --> 02:02:14.020]   At which point you get to decide,
[02:02:14.020 --> 02:02:14.940]   am I going to invite them?
[02:02:14.940 --> 02:02:16.780]   And I have to say, it's been our experience
[02:02:16.780 --> 02:02:18.380]   when you send out a personal invite,
[02:02:18.380 --> 02:02:20.300]   hey, you look like you'd be right for this job.
[02:02:20.300 --> 02:02:21.420]   Would you be interested?
[02:02:21.420 --> 02:02:23.740]   Those people respond, they come to the interviews.
[02:02:23.740 --> 02:02:25.900]   It's a whole different experience,
[02:02:25.900 --> 02:02:28.700]   because they're so happy to be welcomed in.
[02:02:28.700 --> 02:02:31.820]   And we found, and this is often the case,
[02:02:31.820 --> 02:02:33.380]   Lisa posted it at breakfast.
[02:02:33.380 --> 02:02:35.900]   By lunch, we had three or four great candidates.
[02:02:35.900 --> 02:02:37.740]   In fact, the only challenge for us
[02:02:37.740 --> 02:02:39.780]   was figuring out which of the four,
[02:02:39.780 --> 02:02:43.100]   I think they interviewed three or four people.
[02:02:43.100 --> 02:02:46.540]   We were going to hire, we hired Viva, she's fantastic.
[02:02:46.540 --> 02:02:49.040]   Thank you, ZipRecruiter.
[02:02:49.040 --> 02:02:52.100]   By the way, when you post ZipRecruiter offers
[02:02:52.100 --> 02:02:56.780]   attention grabbing labels that will let the applicants know
[02:02:56.780 --> 02:03:00.260]   that you are flexible, things like training provided,
[02:03:00.260 --> 02:03:02.660]   those kinds of things really help.
[02:03:02.660 --> 02:03:05.180]   ZipRecruiter also has a user friendly dashboard.
[02:03:05.180 --> 02:03:07.740]   Like I said, filter, review, rate your candidates
[02:03:07.740 --> 02:03:08.900]   in one place, fast.
[02:03:08.900 --> 02:03:11.340]   ZipRecruiter, let them find the best people
[02:03:11.340 --> 02:03:13.980]   for all your roles, four out of five employers
[02:03:13.980 --> 02:03:16.660]   who post on ZipRecruiter, get a quality candidate
[02:03:16.660 --> 02:03:18.060]   within the first day for us,
[02:03:18.060 --> 02:03:19.580]   usually within an hour or two.
[02:03:19.580 --> 02:03:20.620]   See for yourself.
[02:03:20.620 --> 02:03:23.660]   Go to our special address so you can try it for free,
[02:03:23.660 --> 02:03:28.660]   ziprecruiter.com/twitziprecruiter.com/twitziprecruiter.com/twit.
[02:03:28.660 --> 02:03:33.620]   T-W-I-T, ZipRecruiter, ZipRecruiter,
[02:03:33.620 --> 02:03:36.460]   Smartest Way to Hire, ZipRecruiter.
[02:03:36.460 --> 02:03:38.100]   Thank you, ZipRecruiter.
[02:03:38.100 --> 02:03:40.580]   I don't know why I'm making up a jingle for them.
[02:03:40.580 --> 02:03:45.140]   I wonder if I could use ZipRecruiter to get more priests.
[02:03:45.140 --> 02:03:46.900]   I bet you could.
[02:03:46.900 --> 02:03:51.340]   I remember going on Christmas Eve to a Mass many years ago,
[02:03:51.340 --> 02:03:52.900]   20 years ago, there's a little church,
[02:03:52.900 --> 02:03:54.100]   you probably know in San Francisco
[02:03:54.100 --> 02:03:55.700]   where they still do the Mass in Latin.
[02:03:55.700 --> 02:03:56.540]   Oh yeah, yeah.
[02:03:56.540 --> 02:03:57.380]   It's a French church.
[02:03:57.380 --> 02:03:59.300]   And I thought, oh, it'd be fun to hear the Mass
[02:03:59.300 --> 02:04:02.940]   in the high Latin in the old tongue.
[02:04:02.940 --> 02:04:06.940]   And the whole sermon was we need more priests.
[02:04:06.940 --> 02:04:08.620]   Anybody want to be a priest?
[02:04:08.620 --> 02:04:09.740]   We need more priests.
[02:04:09.740 --> 02:04:11.500]   And I thought, that's probably not the message
[02:04:11.500 --> 02:04:12.500]   you want to put up.
[02:04:12.500 --> 02:04:13.500]   It's kind of true.
[02:04:13.500 --> 02:04:14.340]   It's kind of true.
[02:04:14.340 --> 02:04:18.900]   I mean, when I entered the society in 1994,
[02:04:18.900 --> 02:04:20.180]   we had--
[02:04:20.180 --> 02:04:21.420]   Have you been a priest that--
[02:04:21.420 --> 02:04:23.260]   Well, you weren't a priest yet, but that's when you started.
[02:04:23.260 --> 02:04:24.100]   That's when I started.
[02:04:24.100 --> 02:04:24.940]   Holy cow.
[02:04:24.940 --> 02:04:25.780]   We had--
[02:04:25.780 --> 02:04:26.620]   Wait a minute.
[02:04:26.620 --> 02:04:27.460]   You were 12?
[02:04:27.460 --> 02:04:28.260]   (laughs)
[02:04:28.260 --> 02:04:29.260]   No, no, no.
[02:04:29.260 --> 02:04:30.500]   I was an undisclosed age.
[02:04:30.500 --> 02:04:31.380]   I was already older.
[02:04:31.380 --> 02:04:33.300]   And I had graduated from college.
[02:04:33.300 --> 02:04:35.060]   You and I-- people don't know this maybe about you,
[02:04:35.060 --> 02:04:36.300]   but you were an IT professional.
[02:04:36.300 --> 02:04:36.660]   Yes.
[02:04:36.660 --> 02:04:38.340]   Before you became a priest, that was your--
[02:04:38.340 --> 02:04:38.700]   That was your--
[02:04:38.700 --> 02:04:40.340]   So that's why you're so good at all this stuff.
[02:04:40.340 --> 02:04:40.780]   This is your--
[02:04:40.780 --> 02:04:41.780]   I brought it in love.
[02:04:41.780 --> 02:04:43.100]   I brought it in with me.
[02:04:43.100 --> 02:04:46.140]   But we had almost 30,000 Jesuits at that time
[02:04:46.140 --> 02:04:46.820]   around the world.
[02:04:46.820 --> 02:04:47.220]   Yeah.
[02:04:47.220 --> 02:04:49.540]   And now we have about 14,000.
[02:04:49.540 --> 02:04:51.580]   Oh, that is a crisis.
[02:04:51.580 --> 02:04:52.260]   That's not good.
[02:04:52.260 --> 02:04:53.740]   Have you talked to Father Guido Serti?
[02:04:53.740 --> 02:04:55.060]   (laughs)
[02:04:55.060 --> 02:04:56.300]   Maybe he could help.
[02:04:56.300 --> 02:04:57.220]   No, I mean, I'm just--
[02:04:57.220 --> 02:05:00.580]   I'm going to form a priest chat room.
[02:05:00.580 --> 02:05:02.060]   Here's my pitch.
[02:05:02.060 --> 02:05:03.940]   You get chat GPT in there.
[02:05:03.940 --> 02:05:06.220]   You get a couple of these monitors on wheels.
[02:05:06.220 --> 02:05:09.220]   Get some metaverse type things.
[02:05:09.220 --> 02:05:10.900]   You don't need legs to be a priest.
[02:05:10.900 --> 02:05:11.700]   I got a spot.
[02:05:11.700 --> 02:05:13.220]   Just hook up AI there.
[02:05:13.220 --> 02:05:17.060]   Are you really locked in on that whole thing
[02:05:17.060 --> 02:05:18.780]   if they can only be a celibate man?
[02:05:18.780 --> 02:05:22.580]   That's a lit-- to me.
[02:05:22.580 --> 02:05:23.540]   (laughs)
[02:05:23.540 --> 02:05:24.660]   That's a deal breaker.
[02:05:24.660 --> 02:05:27.580]   You know, five years ago, I could answer that question
[02:05:27.580 --> 02:05:28.700]   without fear of repercussion.
[02:05:28.700 --> 02:05:30.380]   Now it's not a positive issue.
[02:05:30.380 --> 02:05:31.220]   Okay.
[02:05:31.220 --> 02:05:32.340]   I will say this, I will say this,
[02:05:32.340 --> 02:05:36.940]   because there have been some very good discussions
[02:05:36.940 --> 02:05:39.300]   about the requirement for celibacy.
[02:05:39.300 --> 02:05:43.420]   Personally, and this is going to get me fired, I--
[02:05:43.420 --> 02:05:44.420]   No, don't say it.
[02:05:44.420 --> 02:05:47.820]   I think the idea of women as priests
[02:05:47.820 --> 02:05:49.300]   which should come faster.
[02:05:49.300 --> 02:05:50.580]   So it could come more quickly.
[02:05:50.580 --> 02:05:51.660]   Lisa's Episcopalian.
[02:05:51.660 --> 02:05:52.500]   Absolutely.
[02:05:52.500 --> 02:05:55.700]   A lot of female ministers in there, great.
[02:05:55.700 --> 02:05:56.540]   They're great.
[02:05:56.540 --> 02:05:58.860]   Yeah.
[02:05:58.860 --> 02:06:00.140]   But I mean, it all happens with disturbing--
[02:06:00.140 --> 02:06:00.980]   Connie, how are you?
[02:06:00.980 --> 02:06:01.820]   Over time.
[02:06:01.820 --> 02:06:04.780]   How conservative are you about all this stuff?
[02:06:04.780 --> 02:06:05.620]   You said--
[02:06:05.620 --> 02:06:08.660]   Oh, I think, you know, female priests is a great idea.
[02:06:08.660 --> 02:06:11.340]   Why would you cut off half the population of the world
[02:06:11.340 --> 02:06:12.180]   to serve?
[02:06:12.180 --> 02:06:14.100]   Yeah, that would help.
[02:06:14.100 --> 02:06:14.940]   It would help a lot.
[02:06:14.940 --> 02:06:15.780]   Yeah.
[02:06:15.780 --> 02:06:16.620]   It would help.
[02:06:16.620 --> 02:06:17.980]   And it's not just numbers for me.
[02:06:17.980 --> 02:06:22.340]   It's, you know, there is something that is very experiential
[02:06:22.340 --> 02:06:24.140]   about being man or being woman.
[02:06:24.140 --> 02:06:26.340]   And why would you cut out half of that?
[02:06:26.340 --> 02:06:27.340]   That's right.
[02:06:27.340 --> 02:06:29.100]   It's the same reason you want diversity
[02:06:29.100 --> 02:06:31.380]   in the boardroom, you want diversity
[02:06:31.380 --> 02:06:35.260]   in the design room, you want a variety of experience,
[02:06:35.260 --> 02:06:37.300]   not just male and female, you want a variety of experiences
[02:06:37.300 --> 02:06:41.100]   in all technology because you're going to be selling products
[02:06:41.100 --> 02:06:42.380]   to all kinds of people.
[02:06:42.380 --> 02:06:44.460]   Why would you just want a bunch of, you know,
[02:06:44.460 --> 02:06:47.060]   white tech bros designing this stuff?
[02:06:47.060 --> 02:06:47.900]   Yeah.
[02:06:47.900 --> 02:06:50.060]   Why the male thing?
[02:06:50.060 --> 02:06:53.540]   Is that obviously it's historic, but when did that start
[02:06:53.540 --> 02:06:54.380]   and why?
[02:06:54.380 --> 02:06:55.700]   I mean--
[02:06:55.700 --> 02:06:56.540]   It goes back man.
[02:06:56.540 --> 02:06:57.940]   Depends on who you ask.
[02:06:57.940 --> 02:06:59.020]   Yeah.
[02:06:59.020 --> 02:07:01.820]   A lot of it was based in patriarchy of the systems
[02:07:01.820 --> 02:07:03.860]   in which Catholicism was spreading.
[02:07:03.860 --> 02:07:05.260]   And so naturally that's--
[02:07:05.260 --> 02:07:07.940]   But I mean, if you go back far enough,
[02:07:07.940 --> 02:07:10.060]   you find communities in biblical times
[02:07:10.060 --> 02:07:10.940]   that were being led by women.
[02:07:10.940 --> 02:07:11.660]   Sure.
[02:07:11.660 --> 02:07:12.580]   So--
[02:07:12.580 --> 02:07:14.660]   The very earliest Christian communities, I'm sure.
[02:07:14.660 --> 02:07:16.420]   I don't want to kick off that debate.
[02:07:16.420 --> 02:07:20.100]   It's something that I think well reasoned and well
[02:07:20.100 --> 02:07:22.380]   intentioned people should speak about.
[02:07:22.380 --> 02:07:24.820]   If you come in thinking, I'm going to defend my position
[02:07:24.820 --> 02:07:26.660]   because I'm a male priest and therefore I always
[02:07:26.660 --> 02:07:28.180]   want male priests, it's not going
[02:07:28.180 --> 02:07:30.420]   to be beneficial to anybody.
[02:07:30.420 --> 02:07:32.740]   But you know, that's fine.
[02:07:32.740 --> 02:07:35.580]   It might come to the point where our hand gets forced.
[02:07:35.580 --> 02:07:37.100]   It's sort of like, OK, well, you only
[02:07:37.100 --> 02:07:38.020]   want to have male priests.
[02:07:38.020 --> 02:07:38.340]   Fine.
[02:07:38.340 --> 02:07:40.340]   Here's five around the world.
[02:07:40.340 --> 02:07:41.100]   What are you going to do?
[02:07:41.100 --> 02:07:42.020]   Right.
[02:07:42.020 --> 02:07:43.820]   Well, and I know these are discussions
[02:07:43.820 --> 02:07:46.380]   that go on within the church.
[02:07:46.380 --> 02:07:50.180]   There's a lot of politics, believe it or not,
[02:07:50.180 --> 02:07:51.020]   in all of this.
[02:07:51.020 --> 02:07:51.540]   Really?
[02:07:51.540 --> 02:07:52.380]   Do you know religion?
[02:07:52.380 --> 02:07:53.580]   I know, right?
[02:07:53.580 --> 02:07:54.100]   It's--
[02:07:54.100 --> 02:07:54.620]   Who knows?
[02:07:54.620 --> 02:07:55.220]   Go figure.
[02:07:55.220 --> 02:07:57.940]   I don't think so.
[02:07:57.940 --> 02:08:00.580]   Let's talk about the other religion.
[02:08:00.580 --> 02:08:01.260]   Apple?
[02:08:01.260 --> 02:08:01.900]   NFL.
[02:08:01.900 --> 02:08:03.540]   Oh, OK.
[02:08:03.540 --> 02:08:04.900]   But they were to say NFTs.
[02:08:04.900 --> 02:08:06.300]   NFTs.
[02:08:06.300 --> 02:08:08.380]   No, there's a little too much faith in that one.
[02:08:08.380 --> 02:08:09.300]   Yeah, I know.
[02:08:09.300 --> 02:08:09.860]   I'm not even--
[02:08:09.860 --> 02:08:10.860]   That'd be a fail, right?
[02:08:10.860 --> 02:08:11.300]   --the real touch on NFTs.
[02:08:11.300 --> 02:08:12.740]   That's a failed religion.
[02:08:12.740 --> 02:08:13.260]   Yeah.
[02:08:13.260 --> 02:08:13.620]   Is it?
[02:08:13.620 --> 02:08:14.940]   Can we write NFTs off?
[02:08:14.940 --> 02:08:16.500]   Is it done?
[02:08:16.500 --> 02:08:18.700]   The people who still are trying to unload NFTs--
[02:08:18.700 --> 02:08:19.900]   All the people who own NFTs--
[02:08:19.900 --> 02:08:20.860]   Want to keep it going?
[02:08:20.860 --> 02:08:22.740]   Yeah.
[02:08:22.740 --> 02:08:25.180]   I don't think people are buying them anymore.
[02:08:25.180 --> 02:08:31.140]   Well, there is still trade, but it's a dying trade.
[02:08:31.140 --> 02:08:33.540]   Basically, the people who are going to make money on NFTs
[02:08:33.540 --> 02:08:34.940]   have gotten their money.
[02:08:34.940 --> 02:08:36.540]   The people who are holding on to NFTs
[02:08:36.540 --> 02:08:38.380]   are hoping that it will bump a little bit
[02:08:38.380 --> 02:08:40.940]   so that they don't quite lose as much money.
[02:08:40.940 --> 02:08:45.020]   There's really no one getting into NFTs right now.
[02:08:45.020 --> 02:08:49.900]   Connie, you've been in this game a little while.
[02:08:49.900 --> 02:08:51.220]   It's one of the things that fascinates me.
[02:08:51.220 --> 02:08:53.620]   And one of the things I think as an old time
[02:08:53.620 --> 02:08:54.820]   are much older than you, obviously.
[02:08:54.820 --> 02:08:57.340]   But as an old timer, I bring to the table, which is,
[02:08:57.340 --> 02:08:59.820]   I've seen a lot of technologies come and go,
[02:08:59.820 --> 02:09:04.060]   that at the time, people said, this is the next big thing.
[02:09:04.060 --> 02:09:05.140]   Why can't FTS?
[02:09:05.140 --> 02:09:06.380]   You probably have had the same--
[02:09:06.380 --> 02:09:08.700]   you must have had the same experience over the years.
[02:09:08.700 --> 02:09:10.140]   You know, one of them--
[02:09:10.140 --> 02:09:10.700]   absolutely.
[02:09:10.700 --> 02:09:13.100]   One of the most interesting examples, though--
[02:09:13.100 --> 02:09:15.740]   I'm not ready to write off NFTs 100%
[02:09:15.740 --> 02:09:18.380]   because I think the use case in the future might be different.
[02:09:18.380 --> 02:09:21.460]   But I think about Corning--
[02:09:21.460 --> 02:09:24.700]   because I went and visited Corning in upstate New York
[02:09:24.700 --> 02:09:27.940]   several years ago on the fifth anniversary of the iPhone.
[02:09:27.940 --> 02:09:29.980]   Corning creates Gorilla Glass.
[02:09:29.980 --> 02:09:33.180]   That is the front of the iPhone.
[02:09:33.180 --> 02:09:35.220]   Steve Jobs went through their archives
[02:09:35.220 --> 02:09:37.140]   and found it in NASA and student formulation.
[02:09:37.140 --> 02:09:39.300]   And Gorilla Glass, if you don't know,
[02:09:39.300 --> 02:09:42.380]   was originally designed as the toughest, strongest glass
[02:09:42.380 --> 02:09:42.860]   possible.
[02:09:42.860 --> 02:09:44.580]   And they were going to use it in windshields.
[02:09:44.580 --> 02:09:46.860]   But it was so tough and so strong
[02:09:46.860 --> 02:09:48.260]   that it actually was a hazard.
[02:09:48.260 --> 02:09:51.020]   Because if you bumped into the windshield,
[02:09:51.020 --> 02:09:52.380]   you could not get out of your car.
[02:09:52.380 --> 02:09:53.260]   You could not escape.
[02:09:53.260 --> 02:09:54.180]   It didn't break.
[02:09:54.180 --> 02:09:54.540]   Wow.
[02:09:54.540 --> 02:09:59.260]   And so the use case for it for this tough, amazingly strong glass
[02:09:59.260 --> 02:09:59.980]   was wrong.
[02:09:59.980 --> 02:10:01.340]   But the glass was right.
[02:10:01.340 --> 02:10:04.380]   You actually want tempered glass or glass at temples, right?
[02:10:04.380 --> 02:10:07.740]   So that if you have to evacuate your car in an emergency,
[02:10:07.740 --> 02:10:11.820]   you are not trapped in a box of impenetrable glass.
[02:10:11.820 --> 02:10:14.740]   And so we took some in finding an application for it,
[02:10:14.740 --> 02:10:16.100]   whatever, 30, 40 years later.
[02:10:16.100 --> 02:10:20.700]   It's my understanding that they were about to shut the factory down.
[02:10:20.700 --> 02:10:24.340]   They were going out of the business.
[02:10:24.340 --> 02:10:25.180]   Who, Corning?
[02:10:25.180 --> 02:10:26.900]   Yeah, not out of business Corning,
[02:10:26.900 --> 02:10:28.780]   but out of the Gorilla Glass business.
[02:10:28.780 --> 02:10:30.780]   They couldn't find a market for it.
[02:10:30.780 --> 02:10:34.780]   Yeah, I don't think they really manufactured it in bulk at all.
[02:10:34.780 --> 02:10:37.420]   Their glass is used in a lot of things, Corning,
[02:10:37.420 --> 02:10:41.620]   and including LCD displays, which there's a big market for that.
[02:10:41.620 --> 02:10:44.900]   But anyway, my point is that sometimes people
[02:10:44.900 --> 02:10:47.780]   design products that are ahead of their time,
[02:10:47.780 --> 02:10:49.620]   because the use cases isn't there, right?
[02:10:49.620 --> 02:10:53.340]   The guy who invented the very weak glue at 3M
[02:10:53.340 --> 02:10:55.340]   that ended up being the right glue for the market.
[02:10:55.340 --> 02:10:55.860]   It was a ladder.
[02:10:55.860 --> 02:10:58.420]   It was going to be for the steps on the stepladder
[02:10:58.420 --> 02:11:00.140]   so you wouldn't slip off.
[02:11:00.140 --> 02:11:04.100]   But it didn't work so good.
[02:11:04.100 --> 02:11:08.180]   So what I'm saying is the use case for activities today
[02:11:08.180 --> 02:11:11.100]   as a vehicle to make people a lot of money
[02:11:11.100 --> 02:11:15.340]   and basically create a pyramid scheme I think we're all done with.
[02:11:15.340 --> 02:11:16.420]   And I think it's over.
[02:11:16.420 --> 02:11:20.340]   But I don't know what the future application of that tech
[02:11:20.340 --> 02:11:21.220]   could possibly be.
[02:11:21.220 --> 02:11:23.980]   And that's the interesting thing about technology
[02:11:23.980 --> 02:11:26.380]   is that somebody in the future can find
[02:11:26.380 --> 02:11:28.020]   in a new adaptive use for it.
[02:11:28.020 --> 02:11:30.340]   And so that's-- it is a joke today,
[02:11:30.340 --> 02:11:31.980]   but I think it's kind of interesting.
[02:11:31.980 --> 02:11:34.100]   And we'll see how it comes back.
[02:11:34.100 --> 02:11:37.540]   Maybe not in our lifetimes, Leo, but maybe.
[02:11:37.540 --> 02:11:43.260]   Steve Jobs told the story of going to Corning, New York,
[02:11:43.260 --> 02:11:46.180]   to meet with the CEO of Corning.
[02:11:46.180 --> 02:11:47.500]   Because at the time they were going
[02:11:47.500 --> 02:11:51.060]   to put the iPhone screen was going to be plastic.
[02:11:51.060 --> 02:11:52.900]   But it's scratched terribly.
[02:11:52.900 --> 02:11:55.180]   The problem was, yeah, you could replace it with glass,
[02:11:55.180 --> 02:11:57.100]   but glass shatters.
[02:11:57.100 --> 02:11:59.500]   I think we've learned that glass shatters.
[02:11:59.500 --> 02:12:02.140]   But at the time, people were very worried about that.
[02:12:02.140 --> 02:12:07.620]   So he went to Corning and he weeks the CEO Wendell weeks
[02:12:07.620 --> 02:12:09.420]   had told Jobs about Gorilla Glass,
[02:12:09.420 --> 02:12:11.740]   but he said, but I'm not set up to mass produce.
[02:12:11.740 --> 02:12:13.100]   So we don't have the factories.
[02:12:13.100 --> 02:12:15.980]   Jobs said, don't be afraid.
[02:12:15.980 --> 02:12:17.540]   You can do this.
[02:12:17.540 --> 02:12:21.620]   And basically, I think, paid them to open up a factory
[02:12:21.620 --> 02:12:26.860]   and make Gorilla Glass by ordering tons of it.
[02:12:26.860 --> 02:12:29.100]   For the longest time, they didn't admit it was Gorilla Glass,
[02:12:29.100 --> 02:12:29.940]   by the way.
[02:12:29.940 --> 02:12:30.460]   That's right.
[02:12:30.460 --> 02:12:31.460]   Apple didn't say it was Gorilla Glass.
[02:12:31.460 --> 02:12:32.780]   Didn't they call it Sapphire?
[02:12:32.780 --> 02:12:35.620]   Yeah, they had all sorts of names for it.
[02:12:35.620 --> 02:12:37.900]   But that was Gorilla Glass, then Gorilla Glass 2,
[02:12:37.900 --> 02:12:39.220]   and then Gorilla Glass 3.
[02:12:39.220 --> 02:12:41.060]   And we've gotten better and better and better.
[02:12:41.060 --> 02:12:44.420]   There was a CES that Corning came to just
[02:12:44.420 --> 02:12:47.380]   so they could tell people, no, we are the glass.
[02:12:47.380 --> 02:12:48.220]   That's right.
[02:12:48.220 --> 02:12:49.140]   That was their big marketing.
[02:12:49.140 --> 02:12:50.460]   Because Apple didn't want anybody to know.
[02:12:50.460 --> 02:12:52.860]   Oh no, we do it all ourselves.
[02:12:52.860 --> 02:12:54.060]   Yeah, that's the story.
[02:12:54.060 --> 02:12:54.940]   But yeah, that was a great--
[02:12:54.940 --> 02:12:57.180]   Designed in California.
[02:12:57.180 --> 02:12:58.540]   Yeah, yeah.
[02:12:58.540 --> 02:13:01.340]   Designed in Corning, New York.
[02:13:01.340 --> 02:13:04.060]   Yeah, in fact, we had Corning was a sponsor for some time.
[02:13:04.060 --> 02:13:06.380]   They made-- they make fiber optic cables.
[02:13:06.380 --> 02:13:08.060]   We had some of their fiber optic cables.
[02:13:08.060 --> 02:13:09.140]   Yeah, we had the Buntwaiit.
[02:13:09.140 --> 02:13:09.900]   Yeah, they were great.
[02:13:09.900 --> 02:13:10.820]   That was really cool.
[02:13:10.820 --> 02:13:11.900]   Yeah.
[02:13:11.900 --> 02:13:15.100]   Well, that funny story, Corningware, remember?
[02:13:15.100 --> 02:13:15.620]   Yeah.
[02:13:15.620 --> 02:13:19.260]   Baking your oven started out as missile cones.
[02:13:19.260 --> 02:13:21.420]   It was a pop of missiles.
[02:13:21.420 --> 02:13:24.740]   It was indestructible, and it was very, very heat resistant.
[02:13:24.740 --> 02:13:26.620]   And so then it ended up being turned into--
[02:13:26.620 --> 02:13:27.140]   That was cool.
[02:13:27.140 --> 02:13:28.140]   --a good idea.
[02:13:28.140 --> 02:13:28.340]   I had no idea.
[02:13:28.340 --> 02:13:29.740]   I love that.
[02:13:29.740 --> 02:13:31.140]   Isn't that hysterical?
[02:13:31.140 --> 02:13:33.980]   Now, on missiles, they just put iPhones on the--
[02:13:33.980 --> 02:13:35.300]   They're perfect for that.
[02:13:35.300 --> 02:13:35.780]   That's cool.
[02:13:35.780 --> 02:13:38.260]   Yeah.
[02:13:38.260 --> 02:13:39.340]   All right.
[02:13:39.340 --> 02:13:41.220]   I was going to talk about the NFL playoffs.
[02:13:41.220 --> 02:13:42.340]   Who cares?
[02:13:42.340 --> 02:13:43.940]   Football's going on this weekend.
[02:13:43.940 --> 02:13:44.660]   Yeah, sorry.
[02:13:44.660 --> 02:13:46.540]   We really derailed that later.
[02:13:46.540 --> 02:13:47.260]   Yeah, yeah.
[02:13:47.260 --> 02:13:49.140]   I probably was talking after a glass.
[02:13:49.140 --> 02:13:51.700]   The football fan in the studio is a little upset right now.
[02:13:51.700 --> 02:13:54.820]   One guy here, one guy.
[02:13:54.820 --> 02:13:59.860]   HDR 4K for the first time, especially the HDR.
[02:13:59.860 --> 02:14:00.380]   That's new.
[02:14:00.380 --> 02:14:02.580]   I think we had 4K in--
[02:14:02.580 --> 02:14:04.740]   We've had up 4K in other sports.
[02:14:04.740 --> 02:14:07.060]   It is 1080p up-converted.
[02:14:07.060 --> 02:14:07.560]   Yeah.
[02:14:07.560 --> 02:14:08.500]   See, that's the thing.
[02:14:08.500 --> 02:14:11.060]   Whenever they say they're broadcasting in 4K, they're not.
[02:14:11.060 --> 02:14:12.140]   Because they don't have the cameras.
[02:14:12.140 --> 02:14:14.060]   And more importantly, they don't have the truck.
[02:14:14.060 --> 02:14:14.560]   Yeah.
[02:14:14.560 --> 02:14:15.980]   Special truck that you have to have.
[02:14:15.980 --> 02:14:17.420]   And it's very different work.
[02:14:17.420 --> 02:14:19.180]   Well, I mean, once it gets to your distributor,
[02:14:19.180 --> 02:14:21.260]   they're going to sample it down because they don't
[02:14:21.260 --> 02:14:23.180]   want to use up all their bandwidth for multiple--
[02:14:23.180 --> 02:14:23.180]   Well.
[02:14:23.180 --> 02:14:24.140]   --for your streams.
[02:14:24.140 --> 02:14:26.700]   That's why Fox is doing it because they have that app.
[02:14:26.700 --> 02:14:27.180]   Yeah.
[02:14:27.180 --> 02:14:28.820]   And they do stream it in high quality app.
[02:14:28.820 --> 02:14:31.020]   And apparently, they've made deals with a lot of cable
[02:14:31.020 --> 02:14:32.180]   companies because, guess what?
[02:14:32.180 --> 02:14:35.020]   There are a lot of people with 4K HDR TVs
[02:14:35.020 --> 02:14:37.660]   that are a little miffed that they're watching these games
[02:14:37.660 --> 02:14:43.220]   at 720p, 30 frames a second, 42 cameras
[02:14:43.220 --> 02:14:45.380]   at the championship games that are going on this weekend.
[02:14:45.380 --> 02:14:48.260]   In fact, right now, don't go watch them stop.
[02:14:48.260 --> 02:14:51.660]   42 cameras with aerial cameras, sky cams,
[02:14:51.660 --> 02:14:55.220]   line to game cameras, double carts on both sidelines.
[02:14:55.220 --> 02:14:56.020]   You've seen those?
[02:14:56.020 --> 02:14:56.940]   Have you seen those?
[02:14:56.940 --> 02:15:00.500]   They actually have trucks with scissor lifts on them.
[02:15:00.500 --> 02:15:01.660]   Have you seen that, right?
[02:15:01.660 --> 02:15:04.500]   And they're going back and forth in the sideline?
[02:15:04.500 --> 02:15:05.740]   I love the USFL.
[02:15:05.740 --> 02:15:07.580]   They've got drone shots now.
[02:15:07.580 --> 02:15:09.380]   And the drones, it's weird on the USFL,
[02:15:09.380 --> 02:15:11.900]   which is coming in the spring, I think.
[02:15:11.900 --> 02:15:12.940]   I watched the last year.
[02:15:12.940 --> 02:15:14.780]   I think they should put a camera in the ball.
[02:15:14.780 --> 02:15:15.420]   That's my pitch.
[02:15:15.420 --> 02:15:16.300]   Oh, why don't they have--
[02:15:16.300 --> 02:15:17.180]   Someone on the sport.
[02:15:17.180 --> 02:15:18.180]   They have them in the pie wall.
[02:15:18.180 --> 02:15:18.780]   They have a camera right in there.
[02:15:18.780 --> 02:15:19.540]   Put it in the ball.
[02:15:19.540 --> 02:15:20.060]   You're right.
[02:15:20.060 --> 02:15:20.820]   Watch it.
[02:15:20.820 --> 02:15:22.380]   Ah!
[02:15:22.380 --> 02:15:23.300]   You can watch the ball go.
[02:15:23.300 --> 02:15:24.980]   In helmets.
[02:15:24.980 --> 02:15:25.860]   In people's helmets.
[02:15:25.860 --> 02:15:27.260]   They have bikes in helmets.
[02:15:27.260 --> 02:15:28.020]   Yeah, let's see it.
[02:15:28.020 --> 02:15:28.580]   Yeah.
[02:15:28.580 --> 02:15:29.220]   Camera in the house.
[02:15:29.220 --> 02:15:30.380]   This was weird on the USFL.
[02:15:30.380 --> 02:15:32.940]   The drone would fly into the huddle.
[02:15:32.940 --> 02:15:34.300]   They literally-- you could see this.
[02:15:34.300 --> 02:15:35.740]   There would be a drone in the huddle.
[02:15:35.740 --> 02:15:36.700]   And then they'd break.
[02:15:36.700 --> 02:15:37.940]   And then drone was--
[02:15:37.940 --> 02:15:39.340]   switch back.
[02:15:39.340 --> 02:15:40.780]   And then be right behind the quarterback
[02:15:40.780 --> 02:15:41.620]   and follow the play.
[02:15:41.620 --> 02:15:46.140]   I don't know if I want to drone flying next to my players.
[02:15:46.140 --> 02:15:47.180]   They're like--
[02:15:47.180 --> 02:15:48.180]   Hey.
[02:15:48.180 --> 02:15:48.660]   OK.
[02:15:48.660 --> 02:15:51.100]   I think they have helmet cams in the USFL as well.
[02:15:51.100 --> 02:15:52.340]   I think they're doing that.
[02:15:52.340 --> 02:15:55.140]   Because that's how you kind of jump on the bandwagon.
[02:15:55.140 --> 02:15:57.980]   I was a little disappointed that Apple did not
[02:15:57.980 --> 02:16:00.100]   score the Sunday ticket.
[02:16:00.100 --> 02:16:01.780]   And I think some of this was because Apple
[02:16:01.780 --> 02:16:03.980]   wanted to do some interesting things.
[02:16:03.980 --> 02:16:07.300]   And the NFL said, no, YouTube TV will have NFL Sunday
[02:16:07.300 --> 02:16:12.500]   ticket starting in the fall, the next NFL season.
[02:16:12.500 --> 02:16:14.740]   But there is a rumor now that Apple is trying
[02:16:14.740 --> 02:16:16.700]   to get Premier League.
[02:16:16.700 --> 02:16:22.940]   So Apple did get Major League Soccer, the US small time soccer
[02:16:22.940 --> 02:16:24.500]   for 10 years.
[02:16:24.500 --> 02:16:26.420]   And it's a good-- but now there's a rumor
[02:16:26.420 --> 02:16:31.020]   that Apple is going to bid for the English Premier League, which
[02:16:31.020 --> 02:16:36.100]   arguably is the no interest either in this either.
[02:16:36.100 --> 02:16:38.380]   Is that where Richmond AFC plays?
[02:16:38.380 --> 02:16:39.820]   Oh, is that rich?
[02:16:39.820 --> 02:16:42.740]   Is that Ted Lasso?
[02:16:42.740 --> 02:16:44.220]   That's a fake team, right?
[02:16:44.220 --> 02:16:46.020]   You almost got me there.
[02:16:46.020 --> 02:16:49.260]   Actually, Rexxham is the team that's owned by Ryan Reynolds.
[02:16:49.260 --> 02:16:49.660]   That's right.
[02:16:49.660 --> 02:16:50.180]   That's right.
[02:16:50.180 --> 02:16:51.460]   Well, it's Ryan Reynolds and--
[02:16:51.460 --> 02:16:54.980]   The guy from Philadelphia, Rob McLean.
[02:16:54.980 --> 02:16:59.620]   The Daily Mail, bastion of truth in journalism--
[02:16:59.620 --> 02:17:02.020]   OK, maybe not-- says Apple's gearing up
[02:17:02.020 --> 02:17:05.700]   to bid on a package of English Premier League football
[02:17:05.700 --> 02:17:09.740]   soccer streaming rights, which is about to come up for renewal.
[02:17:09.740 --> 02:17:10.740]   I think it's very interesting.
[02:17:10.740 --> 02:17:12.540]   I want these tech companies actually
[02:17:12.540 --> 02:17:15.660]   to show what technology can do in the coverage of these games.
[02:17:15.660 --> 02:17:19.220]   Apple failed miserably with Friday night baseball.
[02:17:19.220 --> 02:17:19.500]   It was--
[02:17:19.500 --> 02:17:20.300]   They did, yeah.
[02:17:20.300 --> 02:17:21.860]   God awful.
[02:17:21.860 --> 02:17:24.060]   But the deal will cost Apple--
[02:17:24.060 --> 02:17:26.580]   What do they do to mess up Friday night baseball?
[02:17:26.580 --> 02:17:27.780]   Make it more boring.
[02:17:27.780 --> 02:17:29.500]   They made it more boring.
[02:17:29.500 --> 02:17:30.500]   They just add more--
[02:17:30.500 --> 02:17:30.980]   They just add more--
[02:17:30.980 --> 02:17:31.140]   --and more effort.
[02:17:31.140 --> 02:17:31.660]   --and more effort.
[02:17:31.660 --> 02:17:32.620]   --like three hours.
[02:17:32.620 --> 02:17:33.740]   They made it longer.
[02:17:33.740 --> 02:17:36.500]   I've gotten used to the coverage that I get over in Europe,
[02:17:36.500 --> 02:17:36.500]   which--
[02:17:36.500 --> 02:17:37.180]   What's that like?
[02:17:37.180 --> 02:17:38.180]   Of baseball is not.
[02:17:38.180 --> 02:17:42.940]   No, no, but like of F1 and of soccer, where there's no commentator.
[02:17:42.940 --> 02:17:43.900]   You get the crowd sounds to that.
[02:17:43.900 --> 02:17:45.700]   They just show that I love that.
[02:17:45.700 --> 02:17:46.180]   I love that.
[02:17:46.180 --> 02:17:46.700]   I love that.
[02:17:46.700 --> 02:17:47.940]   You don't have Crofti?
[02:17:47.940 --> 02:17:48.660]   No.
[02:17:48.660 --> 02:17:51.220]   It's like that in Monza.
[02:17:51.220 --> 02:17:52.180]   No.
[02:17:52.180 --> 02:17:53.580]   That's the best part of F1.
[02:17:53.580 --> 02:17:57.580]   I mean, I like that on the replays, but for the race proper?
[02:17:57.580 --> 02:17:58.380]   It's so quiet.
[02:17:58.380 --> 02:18:01.380]   We're just watching the Costco round and round.
[02:18:01.380 --> 02:18:03.900]   The deal will cost Apple a quarter of a billion dollars
[02:18:03.900 --> 02:18:06.180]   a year, according to the Daily Mail.
[02:18:06.180 --> 02:18:10.140]   But that's for US only.
[02:18:10.140 --> 02:18:13.500]   Any English bid for domestic UK rights
[02:18:13.500 --> 02:18:15.700]   would be billions a year.
[02:18:15.700 --> 02:18:16.580]   This is the number one.
[02:18:16.580 --> 02:18:19.100]   Billions and billions and billions.
[02:18:19.100 --> 02:18:20.940]   Billions.
[02:18:20.940 --> 02:18:22.420]   That didn't gain any interest.
[02:18:22.420 --> 02:18:23.620]   Let's see what else I can do.
[02:18:23.620 --> 02:18:25.380]   Have you heard about Corning Glass?
[02:18:25.380 --> 02:18:27.940]   [LAUGHTER]
[02:18:27.940 --> 02:18:30.700]   Can I just tell you, if you are in upstate New York,
[02:18:30.700 --> 02:18:33.780]   you should go visit Corning because it is fascinating.
[02:18:33.780 --> 02:18:36.980]   Their claim to fame is that they made the machine that
[02:18:36.980 --> 02:18:39.380]   produced Thomas Edison's light bulbs.
[02:18:39.380 --> 02:18:41.140]   And the guy who created that machine
[02:18:41.140 --> 02:18:44.420]   to mass produce light bulbs created such a perfect machine
[02:18:44.420 --> 02:18:47.540]   that it is still the same machine that is used today.
[02:18:47.540 --> 02:18:51.460]   They haven't altered the design without fascinating glasses.
[02:18:51.460 --> 02:18:53.460]   Actually, on the other coast, there
[02:18:53.460 --> 02:18:56.060]   is another Edison-related story.
[02:18:56.060 --> 02:18:59.500]   There is one Edison bulb that has been burning for more
[02:18:59.500 --> 02:19:00.180]   than a century.
[02:19:00.180 --> 02:19:01.220]   It's the one in the firehouse.
[02:19:01.220 --> 02:19:03.500]   The firehouse in my hometown of Fremont.
[02:19:03.500 --> 02:19:04.340]   Is it still burning?
[02:19:04.340 --> 02:19:05.140]   It's still there.
[02:19:05.140 --> 02:19:06.980]   You can still visit it.
[02:19:06.980 --> 02:19:10.500]   This is 30 years ago when I was working in K&BR.
[02:19:10.500 --> 02:19:13.380]   We would do a weekly check to see if the wall was still on.
[02:19:13.380 --> 02:19:14.660]   It's still there.
[02:19:14.660 --> 02:19:15.380]   OK.
[02:19:15.380 --> 02:19:16.940]   I mean, unless the firehouse burst down.
[02:19:16.940 --> 02:19:21.380]   And my Phillips Hue is burning on us for like three years.
[02:19:21.380 --> 02:19:22.260]   Have you noticed that?
[02:19:22.260 --> 02:19:24.420]   I've got regular LED bulbs, and then I've
[02:19:24.420 --> 02:19:27.500]   got smart LED bulbs in Rome.
[02:19:27.500 --> 02:19:29.340]   And all of the smart ones have burnt out,
[02:19:29.340 --> 02:19:30.420]   like within three years.
[02:19:30.420 --> 02:19:33.300]   See, that's the thing is it hasn't like totally burnt out.
[02:19:33.300 --> 02:19:35.020]   You know, the Phillips Hue, the color ones,
[02:19:35.020 --> 02:19:37.140]   they have a range of colors.
[02:19:37.140 --> 02:19:40.220]   About half the range is gone, where it's just not really
[02:19:40.220 --> 02:19:43.420]   what you want, to where it's only kind of the awful light that
[02:19:43.420 --> 02:19:45.380]   makes you feel like you're in a cafeteria, which I think
[02:19:45.380 --> 02:19:48.140]   is the worst way for these bulbs to burn out.
[02:19:48.140 --> 02:19:50.180]   This is a good tangent for a conversation
[02:19:50.180 --> 02:19:54.300]   about sustainability, which is lots of products
[02:19:54.300 --> 02:19:59.260]   in the olden times were designed to last a long time.
[02:19:59.260 --> 02:20:01.820]   But in recent times, those products
[02:20:01.820 --> 02:20:04.540]   are designed to live a very short life.
[02:20:04.540 --> 02:20:05.180]   Well, of course.
[02:20:05.180 --> 02:20:06.820]   And tended to be disposable.
[02:20:06.820 --> 02:20:09.860]   So there is a movement in the tech industry.
[02:20:09.860 --> 02:20:12.860]   And some of the people at CS this year we're talking about
[02:20:12.860 --> 02:20:17.500]   is to create products that are replaced with replaceable parts
[02:20:17.500 --> 02:20:19.500]   so that you can actually replace the parts,
[02:20:19.500 --> 02:20:22.460]   or that are refurbishable, so that you could actually
[02:20:22.460 --> 02:20:25.860]   buy one without feeling guilty that you're buying an old gen,
[02:20:25.860 --> 02:20:26.620]   whatever.
[02:20:26.620 --> 02:20:30.420]   And this bit for nostalgia that somebody was talking about,
[02:20:30.420 --> 02:20:33.700]   old tech being interested, digital cameras are coming back
[02:20:33.700 --> 02:20:34.460]   into the floor.
[02:20:34.460 --> 02:20:41.740]   And the kids have like Instagram camera, not Instagram.
[02:20:41.740 --> 02:20:42.700]   What do they call it?
[02:20:42.700 --> 02:20:43.900]   You push the button in the phone.
[02:20:43.900 --> 02:20:44.860]   Polaroids.
[02:20:44.860 --> 02:20:45.620]   The Instax.
[02:20:45.620 --> 02:20:46.460]   Polaroids.
[02:20:46.460 --> 02:20:46.820]   Yes.
[02:20:46.820 --> 02:20:47.900]   Thank you.
[02:20:47.900 --> 02:20:51.820]   So what's old is not necessarily mean that it's bad,
[02:20:51.820 --> 02:20:56.380]   but your lipo problem is that if those lipo manufacturers
[02:20:56.380 --> 02:20:58.300]   created a light bulb that asked 30 years,
[02:20:58.300 --> 02:21:00.580]   they would be out of business after they saturated.
[02:21:00.580 --> 02:21:02.060]   I always thought there's a little bit of--
[02:21:02.060 --> 02:21:03.740]   I mean, they always said that, oh, yeah,
[02:21:03.740 --> 02:21:05.980]   they could make gasoline out of water.
[02:21:05.980 --> 02:21:06.940]   And they always say that.
[02:21:06.940 --> 02:21:09.380]   And I always wonder if that's--
[02:21:09.380 --> 02:21:12.420]   You can make combustibles out of air.
[02:21:12.420 --> 02:21:16.140]   There is a thing called solar jet that just uses heat and pressure
[02:21:16.140 --> 02:21:16.540]   to--
[02:21:16.540 --> 02:21:18.300]   When are we getting a Mr. Fusion?
[02:21:18.300 --> 02:21:21.220]   Well, the problem is the amount of energy that you have to put in
[02:21:21.220 --> 02:21:23.220]   is more than the energy that you get out.
[02:21:23.220 --> 02:21:25.460]   So anymore, the fusion.
[02:21:25.460 --> 02:21:28.620]   So that's the thing that people missed about that fusion story.
[02:21:28.620 --> 02:21:31.180]   Yes, it's nice to have a lot of energy that you're generating,
[02:21:31.180 --> 02:21:33.820]   but it's what that energy generation will allow you to do.
[02:21:33.820 --> 02:21:37.700]   You can then do efficient and inexpensive generation
[02:21:37.700 --> 02:21:39.860]   of fuel from atmospheric air.
[02:21:39.860 --> 02:21:43.180]   You can then move to a hydrogen-based fuel system.
[02:21:43.180 --> 02:21:44.460]   Take water from the ocean.
[02:21:44.460 --> 02:21:46.820]   Right, because it's really easy to electrolyte.
[02:21:46.820 --> 02:21:47.220]   That's right.
[02:21:47.220 --> 02:21:49.060]   So yeah, there's a knock on.
[02:21:49.060 --> 02:21:53.060]   I'm sorry to say I've gone to centennialbulb.org,
[02:21:53.060 --> 02:21:55.380]   which is the website that looks
[02:21:55.380 --> 02:21:58.380]   like it was designed in 1910.
[02:21:58.380 --> 02:22:00.340]   When a website's like this, you know it's
[02:22:00.340 --> 02:22:01.420]   going to be some good stuff.
[02:22:01.420 --> 02:22:01.980]   It's good.
[02:22:01.980 --> 02:22:03.340]   This is a time capsule.
[02:22:03.340 --> 02:22:07.260]   I have to say, though, there is a broken link here.
[02:22:07.260 --> 02:22:08.940]   I don't know if they're using flash,
[02:22:08.940 --> 02:22:10.860]   or if the light bulb has actually gone out.
[02:22:10.860 --> 02:22:12.380]   No, you know what it is.
[02:22:12.380 --> 02:22:15.340]   It's one of those little Logitech Quickball cams
[02:22:15.340 --> 02:22:16.820]   that used to use on Tech TV.
[02:22:16.820 --> 02:22:17.380]   Yeah, it's pretty old.
[02:22:17.380 --> 02:22:18.220]   That's probably what it's using.
[02:22:18.220 --> 02:22:22.300]   But you can email them at centennialbulb@hotmail.com.
[02:22:22.300 --> 02:22:24.220]   Just ask, hey, can you send me a picture of the bulb?
[02:22:24.220 --> 02:22:28.540]   I want to sign the guest book just to say I was here.
[02:22:28.540 --> 02:22:29.380]   Wow.
[02:22:29.380 --> 02:22:31.500]   The only thing missing from this website
[02:22:31.500 --> 02:22:35.580]   is in a mailbox with the animated opening and closing.
[02:22:35.580 --> 02:22:38.420]   Or how about at the bottom under construction,
[02:22:38.420 --> 02:22:39.420]   a guy with a jackhammer?
[02:22:39.420 --> 02:22:41.140]   Jackhammer.
[02:22:41.140 --> 02:22:43.220]   It's-- this is the top 5% of the web.
[02:22:43.220 --> 02:22:45.140]   I'm guessing, hey, you know, we all
[02:22:45.140 --> 02:22:47.380]   used to make sites like this 20 years ago.
[02:22:47.380 --> 02:22:47.820]   Oh, yeah.
[02:22:47.820 --> 02:22:49.060]   Look at that anime gift.
[02:22:49.060 --> 02:22:50.940]   And the lights here, look at that.
[02:22:50.940 --> 02:22:53.220]   The lights are lighten up down here.
[02:22:53.220 --> 02:22:54.620]   But the state of the art--
[02:22:54.620 --> 02:22:55.620]   It's lit, guys.
[02:22:55.620 --> 02:22:57.100]   That is state of the art.
[02:22:57.100 --> 02:22:58.820]   I think it was dead.
[02:22:58.820 --> 02:22:59.460]   Oh, my god.
[02:22:59.460 --> 02:23:00.940]   I think that site just gave me a virus.
[02:23:00.940 --> 02:23:01.580]   Not my computer.
[02:23:01.580 --> 02:23:02.340]   I think me.
[02:23:02.340 --> 02:23:03.820]   It gave me a virus.
[02:23:03.820 --> 02:23:04.340]   I'm sick.
[02:23:04.340 --> 02:23:05.980]   Yes, couldn't do it.
[02:23:05.980 --> 02:23:07.620]   But the light bulb--
[02:23:07.620 --> 02:23:10.860]   YouTube is, by the way, I was mentioning YouTube TV.
[02:23:10.860 --> 02:23:13.540]   In fact, I pay 20 bucks extra a month for 4K
[02:23:13.540 --> 02:23:16.380]   content that doesn't exist on YouTube TV.
[02:23:16.380 --> 02:23:17.420]   Wait, why?
[02:23:17.420 --> 02:23:17.940]   Why?
[02:23:17.940 --> 02:23:20.340]   It started back in the Olympics.
[02:23:20.340 --> 02:23:22.700]   Those are over for a long time.
[02:23:22.700 --> 02:23:24.660]   You can stop.
[02:23:24.660 --> 02:23:25.140]   I know.
[02:23:25.140 --> 02:23:27.340]   I'm just maybe it.
[02:23:27.340 --> 02:23:29.180]   Occasionally, but like this, they have a 4K.
[02:23:29.180 --> 02:23:30.380]   The Super Bowl is going to be in 4K.
[02:23:30.380 --> 02:23:33.060]   I'll be able to see it on my YouTube TV in 4K.
[02:23:33.060 --> 02:23:33.420]   Sort of.
[02:23:33.420 --> 02:23:35.460]   Leo, how many streaming subscriptions
[02:23:35.460 --> 02:23:36.740]   do you have active writing?
[02:23:36.740 --> 02:23:37.260]   How many?
[02:23:37.260 --> 02:23:38.620]   All of them?
[02:23:38.620 --> 02:23:38.860]   Yeah.
[02:23:38.860 --> 02:23:39.660]   All of them?
[02:23:39.660 --> 02:23:43.140]   Yeah, because if you could write it off as a business
[02:23:43.140 --> 02:23:45.940]   expense, you'd probably have them all, too.
[02:23:45.940 --> 02:23:48.380]   And Leo is actually the only person on the planet
[02:23:48.380 --> 02:23:50.180]   who isn't sharing passwords.
[02:23:50.180 --> 02:23:51.820]   He actually owns all those accounts.
[02:23:51.820 --> 02:23:53.260]   Yeah.
[02:23:53.260 --> 02:23:54.780]   I don't share anybody's passwords.
[02:23:54.780 --> 02:23:59.140]   I might be sharing my passwords with my children, who are just
[02:23:59.140 --> 02:24:00.660]   leeches.
[02:24:00.660 --> 02:24:04.220]   But that's another story for another day.
[02:24:04.220 --> 02:24:06.620]   You-- no.
[02:24:06.620 --> 02:24:07.900]   I don't know why.
[02:24:07.900 --> 02:24:08.260]   You know why?
[02:24:08.260 --> 02:24:11.220]   I think that my kids have my Netflix password,
[02:24:11.220 --> 02:24:15.020]   because every once in a while, it'll say, well, you only
[02:24:15.020 --> 02:24:17.740]   halfway through that reality show about naked people
[02:24:17.740 --> 02:24:18.740]   on an island.
[02:24:18.740 --> 02:24:20.020]   Would you like to watch some more?
[02:24:20.020 --> 02:24:20.860]   And I'm going, I don't think--
[02:24:20.860 --> 02:24:21.780]   Which one?
[02:24:21.780 --> 02:24:24.300]   I don't think I'm watching that one.
[02:24:24.300 --> 02:24:28.540]   Anyway, YouTube is testing a hub of free cable style channels.
[02:24:28.540 --> 02:24:31.900]   I think this has been a secret goal of Google all along.
[02:24:31.900 --> 02:24:33.340]   Yes.
[02:24:33.340 --> 02:24:33.940]   Already.
[02:24:33.940 --> 02:24:37.020]   That's why I need more content with ads.
[02:24:37.020 --> 02:24:40.100]   But they already have everybody under 30, right?
[02:24:40.100 --> 02:24:41.740]   That's where they watch TV nowadays.
[02:24:41.740 --> 02:24:46.260]   They're talking to media companies
[02:24:46.260 --> 02:24:50.100]   to feature their TV shows and films in a hub of, you guessed it,
[02:24:50.100 --> 02:24:54.740]   ad-supported channels.
[02:24:54.740 --> 02:24:58.700]   This is the hot new thing in the industry, fast, free ad
[02:24:58.700 --> 02:25:00.260]   supported TV.
[02:25:00.260 --> 02:25:01.220]   Roku's got it.
[02:25:01.220 --> 02:25:02.020]   There's 2B.
[02:25:02.020 --> 02:25:06.660]   That's a Fox entity Pluto, which is owned by Paramount.
[02:25:06.660 --> 02:25:12.660]   Free TV, which is Amazon's, answered all this.
[02:25:12.660 --> 02:25:17.660]   It's so funny, because we started watching Netflix,
[02:25:17.660 --> 02:25:20.420]   because there were no ads, right?
[02:25:20.420 --> 02:25:21.740]   You could watch the office.
[02:25:21.740 --> 02:25:23.340]   No ads.
[02:25:23.340 --> 02:25:24.220]   And the industry--
[02:25:24.220 --> 02:25:25.380]   No, you can't watch the office.
[02:25:25.380 --> 02:25:25.900]   No, you can't.
[02:25:25.900 --> 02:25:27.780]   You can't watch without ads.
[02:25:27.780 --> 02:25:31.180]   The industry has been doing everything they can to bring them back.
[02:25:31.180 --> 02:25:33.100]   To bring them back.
[02:25:33.100 --> 02:25:36.820]   The kicker for me was when Hulu started offering
[02:25:36.820 --> 02:25:40.220]   its subscription with the ads.
[02:25:40.220 --> 02:25:42.420]   And because that was the precursor for all the others.
[02:25:42.420 --> 02:25:43.500]   That was the test.
[02:25:43.500 --> 02:25:47.140]   Is this a low enough pain point that people will buy into it?
[02:25:47.140 --> 02:25:48.340]   And unfortunately, people did.
[02:25:48.340 --> 02:25:51.140]   They kept buying Hulu, and so therefore everyone does it now.
[02:25:51.140 --> 02:25:53.580]   But I'm wondering what is enough.
[02:25:53.580 --> 02:25:57.100]   For me, I've got Amazon Prime, because Amazon Prime in Europe
[02:25:57.100 --> 02:25:58.180]   is ridiculously cheap.
[02:25:58.180 --> 02:26:00.380]   It costs me $30 a month.
[02:26:00.380 --> 02:26:03.020]   Sorry, $30 a year to be Amazon Prime.
[02:26:03.020 --> 02:26:04.340]   Because you're a Prime member anyway,
[02:26:04.340 --> 02:26:07.020]   you get the two-day delivery.
[02:26:07.020 --> 02:26:09.580]   So the subscription in Europe is 30 euros.
[02:26:09.580 --> 02:26:10.620]   Just for the TV?
[02:26:10.620 --> 02:26:11.300]   No, for everything.
[02:26:11.300 --> 02:26:12.220]   For Amazon Prime.
[02:26:12.220 --> 02:26:12.940]   Right.
[02:26:12.940 --> 02:26:15.900]   But it's like, what, 130 bucks years?
[02:26:15.900 --> 02:26:16.380]   Yeah.
[02:26:16.380 --> 02:26:17.820]   But actually, no, I think, aren't we up?
[02:26:17.820 --> 02:26:18.620]   We're above that now, right?
[02:26:18.620 --> 02:26:20.700]   I think they just-- I think it's 140.
[02:26:20.700 --> 02:26:21.420]   And they just--
[02:26:21.420 --> 02:26:22.500]   Yeah, they just jacked it up.
[02:26:22.500 --> 02:26:23.100]   Holy cow.
[02:26:23.100 --> 02:26:23.740]   So I've got that.
[02:26:23.740 --> 02:26:25.140]   I mean, the thing is, they're trying
[02:26:25.140 --> 02:26:28.340]   to increase membership in places like Italy.
[02:26:28.340 --> 02:26:30.980]   And really, the only other place in Europe
[02:26:30.980 --> 02:26:34.900]   where Amazon is a big Prime subscriber base is Germany.
[02:26:34.900 --> 02:26:36.340]   Well, that's interesting.
[02:26:36.340 --> 02:26:39.340]   So we should mention Paris covers Amazon,
[02:26:39.340 --> 02:26:40.660]   so she knows about this stuff.
[02:26:40.660 --> 02:26:41.900]   It's true.
[02:26:41.900 --> 02:26:43.180]   149, checks on it.
[02:26:43.180 --> 02:26:45.860]   Which, by the way, in Italy, because of the way
[02:26:45.860 --> 02:26:48.020]   that the rights work, I get all of Paramount.
[02:26:48.020 --> 02:26:50.420]   So all the Star Trek stuff, that's
[02:26:50.420 --> 02:26:52.140]   part of my basic subscription.
[02:26:52.140 --> 02:26:53.540]   And it's great.
[02:26:53.540 --> 02:26:54.380]   I'm moving to Italy.
[02:26:54.380 --> 02:26:55.940]   I get pasta.
[02:26:55.940 --> 02:26:57.340]   You get Prosecco.
[02:26:57.340 --> 02:26:59.060]   And you get Star Wars.
[02:26:59.060 --> 02:27:00.980]   I've got a 10 gig line and a VPN.
[02:27:00.980 --> 02:27:02.380]   So I mean, I'm just--
[02:27:02.380 --> 02:27:03.260]   Oof.
[02:27:03.260 --> 02:27:04.220]   Just saying.
[02:27:04.220 --> 02:27:05.060]   Oh, geez.
[02:27:05.060 --> 02:27:06.460]   Just log into the Vatican.
[02:27:06.460 --> 02:27:07.420]   Log in.
[02:27:07.420 --> 02:27:09.980]   This guy in the Vatican's watching all these reality shows
[02:27:09.980 --> 02:27:11.820]   about making people on an island.
[02:27:11.820 --> 02:27:13.220]   What's going on?
[02:27:13.220 --> 02:27:15.220]   Now, the trick to watching with the VPN
[02:27:15.220 --> 02:27:17.060]   is you want to use one of the services
[02:27:17.060 --> 02:27:19.220]   that lets you download the entire episode.
[02:27:19.220 --> 02:27:21.340]   So you're not streaming it over the VPN.
[02:27:21.340 --> 02:27:22.260]   Oh, is that the secret?
[02:27:22.260 --> 02:27:23.220]   That's the secret.
[02:27:23.220 --> 02:27:24.220]   Thank you for sharing this.
[02:27:24.220 --> 02:27:26.980]   That makes a lot of sense.
[02:27:26.980 --> 02:27:28.380]   Because I've been having a lot of--
[02:27:28.380 --> 02:27:31.220]   it's VPN season upcoming for me.
[02:27:31.220 --> 02:27:34.340]   Because this new season of Love Island is about to start.
[02:27:34.340 --> 02:27:37.380]   Is that the one with naked people on an island?
[02:27:37.380 --> 02:27:38.220]   I mean--
[02:27:38.220 --> 02:27:40.060]   I thought that was naked and afraid.
[02:27:40.060 --> 02:27:41.460]   No, there are bikini--
[02:27:41.460 --> 02:27:42.380]   There's a lot of--
[02:27:42.380 --> 02:27:43.380]   There's a lot of--
[02:27:43.380 --> 02:27:44.220]   There's a lot of--
[02:27:44.220 --> 02:27:45.220]   Batchy-slash.
[02:27:45.220 --> 02:27:46.620]   That's the one I was talking about.
[02:27:46.620 --> 02:27:48.020]   Are you using my Netflix password?
[02:27:48.020 --> 02:27:49.620]   This one's kind of like big brother.
[02:27:49.620 --> 02:27:51.580]   I mean, only on weekends, Leo.
[02:27:51.580 --> 02:27:52.540]   You know?
[02:27:52.540 --> 02:27:54.580]   Only on weekends.
[02:27:54.580 --> 02:27:56.820]   So the whole idea is it's a bunch of good-looking young people
[02:27:56.820 --> 02:27:59.260]   in swimwear.
[02:27:59.260 --> 02:28:01.700]   In swimwear, but the thing that's interesting about it--
[02:28:01.700 --> 02:28:03.220]   I would not do well on the show.
[02:28:03.220 --> 02:28:04.780]   --is it is--
[02:28:04.780 --> 02:28:07.740]   it goes on for basically like 50 days straight.
[02:28:07.740 --> 02:28:10.020]   And they can have sex, right?
[02:28:10.020 --> 02:28:11.300]   Well, I mean, they could.
[02:28:11.300 --> 02:28:12.140]   That's a different one.
[02:28:12.140 --> 02:28:13.460]   That's called too hot to handle.
[02:28:13.460 --> 02:28:15.220]   It goes on the page channel.
[02:28:15.220 --> 02:28:16.060]   That's different.
[02:28:16.060 --> 02:28:18.460]   They are in essentially like a big brother house,
[02:28:18.460 --> 02:28:20.620]   like where there are cameras on every--
[02:28:20.620 --> 02:28:21.460]   like, inch and--
[02:28:21.460 --> 02:28:24.020]   And these people are filmed 24 hours a day.
[02:28:24.020 --> 02:28:25.460]   And you get--
[02:28:25.460 --> 02:28:28.300]   like, tomorrow we'll get the episode of what
[02:28:28.300 --> 02:28:30.980]   happened on Love Island, like right now.
[02:28:30.980 --> 02:28:32.340]   And so every single day--
[02:28:32.340 --> 02:28:32.860]   Oh, it's fantastic.
[02:28:32.860 --> 02:28:34.900]   --when you episode, it is vast--
[02:28:34.900 --> 02:28:35.460]   Oh, look, it's like--
[02:28:35.460 --> 02:28:36.580]   --between some days--
[02:28:36.580 --> 02:28:38.180]   There's 29 episodes.
[02:28:38.180 --> 02:28:38.740]   Holy cow.
[02:28:38.740 --> 02:28:42.100]   Because you get all the content for in the UK,
[02:28:42.100 --> 02:28:43.660]   like 55 days straight.
[02:28:43.660 --> 02:28:44.980]   And I think it's kind of interesting.
[02:28:44.980 --> 02:28:46.020]   It's not that edited.
[02:28:46.020 --> 02:28:48.380]   You know, I don't judge the content
[02:28:48.380 --> 02:28:49.540]   that other people watch, because I
[02:28:49.540 --> 02:28:51.340]   watch some pretty trashy content.
[02:28:51.340 --> 02:28:54.700]   So if you enjoy it and it runs--
[02:28:54.700 --> 02:28:57.220]   I thought there might be a lot coming in that.
[02:28:57.220 --> 02:28:58.540]   But no, no, no.
[02:28:58.540 --> 02:29:00.220]   This is-- I get it.
[02:29:00.220 --> 02:29:02.860]   I understand not high brown anyway,
[02:29:02.860 --> 02:29:05.780]   but it's kind of interesting to see,
[02:29:05.780 --> 02:29:07.820]   even from a editorial perspective,
[02:29:07.820 --> 02:29:10.300]   how you put together just live what
[02:29:10.300 --> 02:29:14.860]   is happening in a small villa for 50 days.
[02:29:14.860 --> 02:29:16.180]   Interesting.
[02:29:16.180 --> 02:29:18.060]   It is taking over television, isn't it?
[02:29:18.060 --> 02:29:18.860]   It's the last--
[02:29:18.860 --> 02:29:20.980]   It's terrible, because it's cheap of commercials.
[02:29:20.980 --> 02:29:22.180]   It's not just because it's cheap.
[02:29:22.180 --> 02:29:23.140]   It works.
[02:29:23.140 --> 02:29:24.700]   People watch it.
[02:29:24.700 --> 02:29:26.100]   Well, I got one.
[02:29:26.100 --> 02:29:29.980]   The border security shows that they have on Amazon,
[02:29:29.980 --> 02:29:31.820]   where they're basically showing you customs at an airport.
[02:29:31.820 --> 02:29:33.380]   That's a dystopian set.
[02:29:33.380 --> 02:29:34.660]   It's a terrible show.
[02:29:34.660 --> 02:29:35.820]   It shows on Amazon.
[02:29:35.820 --> 02:29:38.380]   It's terrible content, but I will have it on the background
[02:29:38.380 --> 02:29:41.300]   when I'm working on something, because it's
[02:29:41.300 --> 02:29:43.460]   a big shot of shodden Freud.
[02:29:43.460 --> 02:29:44.300]   What?
[02:29:44.300 --> 02:29:46.140]   It sounds like the German show.
[02:29:46.140 --> 02:29:47.420]   No, no, I'm dead serious.
[02:29:47.420 --> 02:29:49.180]   There's like five different versions of that,
[02:29:49.180 --> 02:29:51.580]   and they do like nine different countries.
[02:29:51.580 --> 02:29:52.580]   There's border security divide.
[02:29:52.580 --> 02:29:53.580]   Border security divide.
[02:29:53.580 --> 02:29:54.660]   Or in Canada.
[02:29:54.660 --> 02:29:56.460]   Phony tourists here to work.
[02:29:56.460 --> 02:29:59.100]   The Lidger and visitors smuggling contraband.
[02:29:59.100 --> 02:30:00.820]   Toys packed with heroin.
[02:30:00.820 --> 02:30:04.060]   It is absolute bottom feeder content, but it's a--
[02:30:04.060 --> 02:30:04.740]   Tatum.
[02:30:04.740 --> 02:30:06.340]   This is like cops.
[02:30:06.340 --> 02:30:08.020]   But like--
[02:30:08.020 --> 02:30:10.340]   Human bones are found inside luggage.
[02:30:10.340 --> 02:30:12.580]   So I mean, I watch this.
[02:30:12.580 --> 02:30:14.540]   So can I really criticize someone
[02:30:14.540 --> 02:30:17.100]   who wants to watch an island filled with attractive young
[02:30:17.100 --> 02:30:21.900]   border security, America's front line?
[02:30:21.900 --> 02:30:22.380]   Wow.
[02:30:22.380 --> 02:30:25.660]   Is there nothing that they won't turn into a reality?
[02:30:25.660 --> 02:30:27.220]   We haven't done it for the Vatican yet,
[02:30:27.220 --> 02:30:28.420]   although I tried to pitch it.
[02:30:28.420 --> 02:30:32.700]   That college of Cardinals, next time you got a vote,
[02:30:32.700 --> 02:30:34.420]   there have been a number of movies.
[02:30:34.420 --> 02:30:36.500]   She was the fisherman.
[02:30:36.500 --> 02:30:39.940]   There have been TV shows all dramatizing what goes on.
[02:30:39.940 --> 02:30:42.940]   I was actually just going to call it Love Island.
[02:30:42.940 --> 02:30:45.220]   But they were big on that.
[02:30:45.220 --> 02:30:49.220]   Cardinal Philippi, why do you want a vote for Cardinal Vaducci?
[02:30:49.220 --> 02:30:50.620]   I love him.
[02:30:50.620 --> 02:30:51.700]   It's going to be great.
[02:30:51.700 --> 02:30:53.380]   That quote from John the 23rd--
[02:30:53.380 --> 02:30:54.860]   I can't equate you.
[02:30:54.860 --> 02:30:57.260]   They asked him, how many people work in the Vatican?
[02:30:57.260 --> 02:30:58.340]   And he said about half.
[02:30:58.340 --> 02:31:04.340]   And said it's not an exaggeration.
[02:31:04.340 --> 02:31:05.580]   Oh, forget Tech News.
[02:31:05.580 --> 02:31:08.020]   What's the Synology bag over here?
[02:31:08.020 --> 02:31:09.700]   No, no, that was just one of the--
[02:31:09.700 --> 02:31:12.820]   You're teasing me, because I love my Synology.
[02:31:12.820 --> 02:31:14.780]   We're supposed to send me a NAS, and it didn't arrive.
[02:31:14.780 --> 02:31:19.820]   Instead, I got the SSDs that go into the new Synology.
[02:31:19.820 --> 02:31:20.940]   Well, that's cool.
[02:31:20.940 --> 02:31:22.500]   These are the things that really cost your money.
[02:31:22.500 --> 02:31:24.860]   You buy a Synology, you buy a bunch of hard drives,
[02:31:24.860 --> 02:31:26.900]   and they say, oh, one more thing.
[02:31:26.900 --> 02:31:28.700]   So they sent me the drives.
[02:31:28.700 --> 02:31:30.700]   Now, the cool thing is the new versions.
[02:31:30.700 --> 02:31:32.900]   They have a 10 gigabit ethernet connection.
[02:31:32.900 --> 02:31:33.580]   Oh, nice.
[02:31:33.580 --> 02:31:35.380]   And that's what you have in Italy.
[02:31:35.380 --> 02:31:37.620]   No, but they just-- when I went by the booth,
[02:31:37.620 --> 02:31:40.820]   they just gave me what is essentially a nice fixet kit.
[02:31:40.820 --> 02:31:41.740]   Oh, well, it's good.
[02:31:41.740 --> 02:31:42.340]   I love that.
[02:31:42.340 --> 02:31:42.980]   What else you got?
[02:31:42.980 --> 02:31:43.940]   Well, can we give me something?
[02:31:43.940 --> 02:31:44.700]   This is practical.
[02:31:44.700 --> 02:31:45.340]   This is practical.
[02:31:45.340 --> 02:31:46.700]   This is something you could use.
[02:31:46.700 --> 02:31:47.740]   I know you like to fan--
[02:31:47.740 --> 02:31:48.420]   Your man purse.
[02:31:48.420 --> 02:31:49.260]   It's a fanny pack.
[02:31:49.260 --> 02:31:50.900]   You would say it does seem like a fanny pack.
[02:31:50.900 --> 02:31:53.420]   It is a fanny pack, but I was looking for something
[02:31:53.420 --> 02:31:57.220]   that held all the tech, and I don't like a fanny pack.
[02:31:57.220 --> 02:31:58.660]   So this is a MRST.
[02:31:58.660 --> 02:31:59.540]   They call it a sling.
[02:31:59.540 --> 02:32:01.100]   This is a bolster.
[02:32:01.100 --> 02:32:02.340]   And yeah, it works.
[02:32:02.340 --> 02:32:04.500]   Actually, you know I'm a fan of bangs.
[02:32:04.500 --> 02:32:05.260]   I know, right?
[02:32:05.260 --> 02:32:06.580]   That's why I brought it in.
[02:32:06.580 --> 02:32:09.780]   So this goes over my-- it's like a messenger bag.
[02:32:09.780 --> 02:32:11.820]   You can go over the shoulder, or you can--
[02:32:11.820 --> 02:32:13.180]   there's another strap.
[02:32:13.180 --> 02:32:14.620]   You can go around your waist.
[02:32:14.620 --> 02:32:16.220]   So you just choose how you want to wear it.
[02:32:16.220 --> 02:32:18.180]   Looks like a man's ear to be honest with you.
[02:32:18.180 --> 02:32:19.940]   It's really designed to be diagonal.
[02:32:19.940 --> 02:32:23.300]   Maybe--
[02:32:23.300 --> 02:32:25.820]   Wow, you're really rocking that.
[02:32:25.820 --> 02:32:27.460]   Hey.
[02:32:27.460 --> 02:32:31.020]   I'm a tech pro, can you tell?
[02:32:31.020 --> 02:32:32.700]   So if you want, you can take that with you.
[02:32:32.700 --> 02:32:33.740]   You can use that in a row.
[02:32:33.740 --> 02:32:35.740]   No, no, I don't this way.
[02:32:35.740 --> 02:32:38.540]   You could use that to carry your 28 phones, Leo.
[02:32:38.540 --> 02:32:39.180]   Oh, that's true.
[02:32:39.180 --> 02:32:40.140]   Have them all in there.
[02:32:40.140 --> 02:32:42.100]   This wouldn't hold all my phones.
[02:32:42.100 --> 02:32:42.980]   It might--
[02:32:42.980 --> 02:32:44.100]   You could get another one.
[02:32:44.100 --> 02:32:45.540]   Actually, no, that's why you need this.
[02:32:45.540 --> 02:32:45.940]   This is the--
[02:32:45.940 --> 02:32:46.380]   The mags--
[02:32:46.380 --> 02:32:47.980]   This is the one thing I thought was really cool.
[02:32:47.980 --> 02:32:50.380]   You did this video piece for us last week
[02:32:50.380 --> 02:32:51.740]   and I asked the tech guys.
[02:32:51.740 --> 02:32:55.420]   And this of all the things, all the real cool gear,
[02:32:55.420 --> 02:32:56.900]   including the MR.
[02:32:56.900 --> 02:32:57.900]   Very cool.
[02:32:57.900 --> 02:32:59.140]   This was the one I was interested in.
[02:32:59.140 --> 02:33:00.500]   So this is a mags--
[02:33:00.500 --> 02:33:01.980]   It's a mag safe thing.
[02:33:01.980 --> 02:33:05.340]   So, OK, let me take my phone out so I can--
[02:33:05.340 --> 02:33:08.300]   so it just flips-- it hangs out of the phone.
[02:33:08.300 --> 02:33:10.500]   Is mag safe strong enough to put my wallet in there?
[02:33:10.500 --> 02:33:12.580]   I mean, Nick, should I trust that?
[02:33:12.580 --> 02:33:13.100]   Oh, yeah.
[02:33:13.100 --> 02:33:13.780]   Oh, yeah.
[02:33:13.780 --> 02:33:16.060]   You can actually hold it by the holder.
[02:33:16.060 --> 02:33:18.260]   It's got a little pop socket kind of.
[02:33:18.260 --> 02:33:19.820]   It does come off, but it's about--
[02:33:19.820 --> 02:33:21.340]   And so it just holds your cards?
[02:33:21.340 --> 02:33:22.620]   Well, no, yeah, holds your cards.
[02:33:22.620 --> 02:33:24.020]   But what I like about this--
[02:33:24.020 --> 02:33:25.820]   I use this at CES.
[02:33:25.820 --> 02:33:27.700]   This is an NFT device.
[02:33:27.700 --> 02:33:29.820]   So it has my business card on it.
[02:33:29.820 --> 02:33:30.820]   Really?
[02:33:30.820 --> 02:33:31.820]   NFT?
[02:33:31.820 --> 02:33:32.820]   Right.
[02:33:32.820 --> 02:33:33.820]   So rather than giving someone my business--
[02:33:33.820 --> 02:33:34.820]   And I've seen not NFT.
[02:33:34.820 --> 02:33:35.820]   Oh, sorry.
[02:33:35.820 --> 02:33:37.820]   And let's make that very cool.
[02:33:37.820 --> 02:33:38.820]   Whoa.
[02:33:38.820 --> 02:33:40.820]   How would you like to buy this?
[02:33:40.820 --> 02:33:41.820]   No, so you--
[02:33:41.820 --> 02:33:44.060]   You can put it on the block, Jim.
[02:33:44.060 --> 02:33:47.260]   You put your business card on it or no?
[02:33:47.260 --> 02:33:48.260]   Right, right.
[02:33:48.260 --> 02:33:49.260]   So you put a link to it.
[02:33:49.260 --> 02:33:50.260]   You put the link to it.
[02:33:50.260 --> 02:33:53.700]   And so you tap it to the back of someone's phone and they have their contact information,
[02:33:53.700 --> 02:33:55.660]   which is so much better than business cards.
[02:33:55.660 --> 02:33:56.660]   That's fun.
[02:33:56.660 --> 02:33:57.660]   Yeah, who wants all that?
[02:33:57.660 --> 02:33:58.660]   You must have done this.
[02:33:58.660 --> 02:34:00.660]   I just got back and started sorting all my business cards.
[02:34:00.660 --> 02:34:05.580]   And half of them I couldn't remember which representative belonged to which company.
[02:34:05.580 --> 02:34:06.580]   Yeah.
[02:34:06.580 --> 02:34:07.740]   Does it have to be purple?
[02:34:07.740 --> 02:34:10.900]   No, I just chose that because I like purple.
[02:34:10.900 --> 02:34:14.020]   Well, look, it matches the color right behind me.
[02:34:14.020 --> 02:34:15.020]   It's good.
[02:34:15.020 --> 02:34:16.020]   Oh.
[02:34:16.020 --> 02:34:20.460]   All right, I want to take a little break because it's getting late and Connie has places to
[02:34:20.460 --> 02:34:25.460]   be and things to do and a teenage son to monitor.
[02:34:25.460 --> 02:34:29.340]   But our show today I do want to mention is brought to you by we were talking about Ryan
[02:34:29.340 --> 02:34:30.340]   Reynolds.
[02:34:30.340 --> 02:34:32.060]   Oh, his chat GPT ad.
[02:34:32.060 --> 02:34:34.340]   Oh, which was hysterical.
[02:34:34.340 --> 02:34:36.780]   Mint mobile.
[02:34:36.780 --> 02:34:37.860]   Big fan of Mint mobile.
[02:34:37.860 --> 02:34:38.860]   You use you said you use it.
[02:34:38.860 --> 02:34:39.860]   I do.
[02:34:39.860 --> 02:34:40.860]   Not in Italy.
[02:34:40.860 --> 02:34:42.060]   Oh, I, but I need a new city at home.
[02:34:42.060 --> 02:34:43.260]   When you get home into the States.
[02:34:43.260 --> 02:34:44.260]   Yeah.
[02:34:44.260 --> 02:34:46.060]   Mint mobile is brilliant.
[02:34:46.060 --> 02:34:51.740]   It is a phone company with no stores, no physical presence, but they take all the money they
[02:34:51.740 --> 02:34:57.380]   save that and their cheesy ad campaign, they save a lot of money there and they put that
[02:34:57.380 --> 02:34:58.740]   money into your pocket.
[02:34:58.740 --> 02:35:03.660]   If you're saving more and spending less is one of your top goals for this year.
[02:35:03.660 --> 02:35:05.980]   That's a very good resolution.
[02:35:05.980 --> 02:35:09.620]   Why are you still paying insane amounts of money for your phone bill?
[02:35:09.620 --> 02:35:11.020]   Just think what your cell phone bill is.
[02:35:11.020 --> 02:35:14.020]   A hundred bucks a month, out of 20 bucks a month.
[02:35:14.020 --> 02:35:18.700]   Mine, you know, sneakily slowly has been inching up every month.
[02:35:18.700 --> 02:35:25.100]   It's getting close to 200 bucks a month, but Mint mobile, nope, $15 a month.
[02:35:25.100 --> 02:35:26.100]   All in.
[02:35:26.100 --> 02:35:31.500]   That's nationwide unlimited talking text plus high speed data delivered on the nation's
[02:35:31.500 --> 02:35:33.140]   largest 5G network.
[02:35:33.140 --> 02:35:34.940]   It's not a secret team mobile.
[02:35:34.940 --> 02:35:40.380]   So if you get good team mobile service where you are, this is absolutely a no brainer.
[02:35:40.380 --> 02:35:42.660]   Premium wireless for 15 bucks a month.
[02:35:42.660 --> 02:35:43.660]   And that's it.
[02:35:43.660 --> 02:35:45.820]   There's no secret fees, no added things.
[02:35:45.820 --> 02:35:47.060]   Oh, you got to pay for that.
[02:35:47.060 --> 02:35:48.540]   No, that's it.
[02:35:48.540 --> 02:35:49.620]   Because they're online only.
[02:35:49.620 --> 02:35:53.980]   They eliminate the traditional cost of retail and they could pass those savings on to you.
[02:35:53.980 --> 02:35:55.660]   You could bring your own phone.
[02:35:55.660 --> 02:35:57.300]   Mint mobile now supports eSim.
[02:35:57.300 --> 02:36:00.620]   So if you've got an eSim enabled phone, you don't even have to get them to send you a
[02:36:00.620 --> 02:36:01.620]   SIM card.
[02:36:01.620 --> 02:36:03.020]   But if you need one, they will send you one for free.
[02:36:03.020 --> 02:36:04.300]   They don't charge it.
[02:36:04.300 --> 02:36:06.940]   They also sell phones at amazing prices.
[02:36:06.940 --> 02:36:10.900]   I got an iPhone SE and Mint mobile complete.
[02:36:10.900 --> 02:36:11.980]   30 bucks a month.
[02:36:11.980 --> 02:36:14.460]   New phone and Mint mobile service.
[02:36:14.460 --> 02:36:16.780]   Four gigabytes of data for 15 bucks a month.
[02:36:16.780 --> 02:36:17.780]   Need more?
[02:36:17.780 --> 02:36:19.180]   20 bucks for 10 gigabytes.
[02:36:19.180 --> 02:36:21.380]   Nobody needs one, 10 gigabytes a month.
[02:36:21.380 --> 02:36:22.940]   Okay, 15 gigabytes.
[02:36:22.940 --> 02:36:25.140]   That's $25 a month.
[02:36:25.140 --> 02:36:26.140]   What are you paying?
[02:36:26.140 --> 02:36:28.180]   They even have an unlimited plan.
[02:36:28.180 --> 02:36:29.180]   Mint mobile.
[02:36:29.180 --> 02:36:33.020]   And they have that modern family plan that lets you mix and match data plans so everybody
[02:36:33.020 --> 02:36:35.460]   gets what's right for them.
[02:36:35.460 --> 02:36:38.020]   All you need is two lines and you don't even have to be in the same family.
[02:36:38.020 --> 02:36:39.260]   Just be good friends.
[02:36:39.260 --> 02:36:40.300]   Just be good friends.
[02:36:40.300 --> 02:36:43.620]   With Mint mobile, choose the amount of monthly data that's right for you and stop paying
[02:36:43.620 --> 02:36:46.860]   for data you never use.
[02:36:46.860 --> 02:36:49.060]   This is absolutely a no brainer.
[02:36:49.060 --> 02:36:53.500]   Mint mobile premium wireless service starts at 15 bucks a month.
[02:36:53.500 --> 02:36:58.420]   Get your new wireless plan for just 15 bucks a month and get the plan shipped to your door
[02:36:58.420 --> 02:36:59.420]   for free.
[02:36:59.420 --> 02:37:01.820]   Go to mintmobile.com/twit.
[02:37:01.820 --> 02:37:04.260]   Mintmobile.com/twit.
[02:37:04.260 --> 02:37:06.660]   Again, cut your wireless build.
[02:37:06.660 --> 02:37:10.980]   15 bucks a month and they'll ship it to you for free.
[02:37:10.980 --> 02:37:14.380]   I am such a huge fan of Mint mobile.
[02:37:14.380 --> 02:37:15.980]   It's like, why do you pay anymore?
[02:37:15.980 --> 02:37:21.140]   I feel like I have to have all the different carriers so I can tell people what's wrong
[02:37:21.140 --> 02:37:22.140]   with them all.
[02:37:22.140 --> 02:37:24.380]   I've never had to say things wrong with Mint mobile.
[02:37:24.380 --> 02:37:25.340]   It's just great.
[02:37:25.340 --> 02:37:27.580]   Mintmobile.com/twit.
[02:37:27.580 --> 02:37:32.420]   And if you can, they've been showing it on the football games and stuff.
[02:37:32.420 --> 02:37:36.340]   Ryan's chat GPT written ad.
[02:37:36.340 --> 02:37:37.820]   It's actually really good.
[02:37:37.820 --> 02:37:39.460]   He's entertaining.
[02:37:39.460 --> 02:37:41.420]   I think he's so funny.
[02:37:41.420 --> 02:37:43.980]   So what he did that was smart is he started an ad agency.
[02:37:43.980 --> 02:37:44.980]   He did.
[02:37:44.980 --> 02:37:45.980]   And that's brilliant.
[02:37:45.980 --> 02:37:48.740]   All these movie stars are buying tequila.
[02:37:48.740 --> 02:37:51.540]   He bought aviation gin.
[02:37:51.540 --> 02:37:53.540]   But then he said, I should start an ad agency.
[02:37:53.540 --> 02:37:55.020]   And he's actually, I think he's done better on that.
[02:37:55.020 --> 02:37:56.020]   He's starting a movie.
[02:37:56.020 --> 02:37:57.940]   He's really good at it.
[02:37:57.940 --> 02:37:59.700]   And he owns Mint mobile.
[02:37:59.700 --> 02:38:01.700]   Mintmobile.com/twit.
[02:38:01.700 --> 02:38:03.500]   At first, by the way, I did some research.
[02:38:03.500 --> 02:38:07.340]   I thought, oh, it's, you know, here, we'll give you 5% of the company.
[02:38:07.340 --> 02:38:08.500]   Do our ads or some.
[02:38:08.500 --> 02:38:09.860]   No, he owns more than 50%.
[02:38:09.860 --> 02:38:11.780]   He is literally a controlling owner.
[02:38:11.780 --> 02:38:15.180]   A Mint mobile, which is hysterical.
[02:38:15.180 --> 02:38:21.420]   What I like about when I made my first subscription to Mint mobile, they sent me two extra SIM
[02:38:21.420 --> 02:38:23.020]   cards.
[02:38:23.020 --> 02:38:24.580]   And I just keep those with me.
[02:38:24.580 --> 02:38:28.540]   So every time I come back into the United States, when I hit the US, I just pop the SIM
[02:38:28.540 --> 02:38:30.940]   in, I activate the card, and I'm good to go.
[02:38:30.940 --> 02:38:32.900]   And then they send me another card.
[02:38:32.900 --> 02:38:36.060]   So I only pay for the months that I'm actually in the United States.
[02:38:36.060 --> 02:38:37.060]   It's a great service.
[02:38:37.060 --> 02:38:39.140]   We had a great week this week on Twit.
[02:38:39.140 --> 02:38:40.140]   Did you see all of it?
[02:38:40.140 --> 02:38:44.380]   I bet you missed a few things, but fortunately we have a lovely little movie we've prepared
[02:38:44.380 --> 02:38:45.380]   for your entertainment.
[02:38:45.380 --> 02:38:51.240]   We're going to sit down and enjoy some quality time with the wonderful and the Stacey Higgin
[02:38:51.240 --> 02:38:54.180]   Bothem as we have our book club.
[02:38:54.180 --> 02:38:55.380]   Which is a slip through.
[02:38:55.380 --> 02:38:56.380]   It's a slip through.
[02:38:56.380 --> 02:38:57.380]   It's a handy weirce.
[02:38:57.380 --> 02:38:58.380]   I was supposed to be the whole mirror.
[02:38:58.380 --> 02:39:01.620]   I know we don't have alcohol, but we all have opinions.
[02:39:01.620 --> 02:39:02.620]   Yeah.
[02:39:02.620 --> 02:39:03.620]   So true.
[02:39:03.620 --> 02:39:04.620]   So let's just start off, Aunt.
[02:39:04.620 --> 02:39:05.620]   Did you hate this book?
[02:39:05.620 --> 02:39:06.620]   No.
[02:39:06.620 --> 02:39:07.620]   I...
[02:39:07.620 --> 02:39:08.620]   Oh, wow.
[02:39:08.620 --> 02:39:10.620]   So previously on Twit.
[02:39:10.620 --> 02:39:12.060]   Is that the first one you didn't hate?
[02:39:12.060 --> 02:39:13.060]   All about Android.
[02:39:13.060 --> 02:39:19.740]   Motorola, that's he has announced 30 years of the Lenovo ThinkPad.
[02:39:19.740 --> 02:39:22.180]   And now Motorola is releasing the ThinkPhone.
[02:39:22.180 --> 02:39:28.820]   That's kind of, you know, doing this like collaborative thing to give you serious ThinkPad
[02:39:28.820 --> 02:39:29.820]   vibes.
[02:39:29.820 --> 02:39:31.780]   iOS today.
[02:39:31.780 --> 02:39:38.580]   It's time to talk about some of the most productive, most creative, most useful apps.
[02:39:38.580 --> 02:39:40.460]   For your iPhone and your iPad.
[02:39:40.460 --> 02:39:41.460]   Eventually results.
[02:39:41.460 --> 02:39:42.460]   Security now.
[02:39:42.460 --> 02:39:45.620]   Rob tweeted to me, he said, "Alright Steve."
[02:39:45.620 --> 02:39:48.020]   You asked and I delivered.
[02:39:48.020 --> 02:39:54.260]   I wrote a PowerShell script to parse the XML file that is your last pass vault.
[02:39:54.260 --> 02:39:57.180]   So I replied, "Holy crap Rob.
[02:39:57.180 --> 02:39:58.980]   You're a PowerShell wizard."
[02:39:58.980 --> 02:40:05.100]   To which Rob replied, "Not sure I can claim the title of wizard though.
[02:40:05.100 --> 02:40:09.900]   I had chat GPT do most of the heavy lifting."
[02:40:09.900 --> 02:40:14.180]   "I mean chat GPT is a PowerShell wizard."
[02:40:14.180 --> 02:40:15.180]   Twit is.
[02:40:15.180 --> 02:40:17.260]   "Tech just like you like it."
[02:40:17.260 --> 02:40:19.620]   It's kind of amazing.
[02:40:19.620 --> 02:40:21.260]   PowerShell did all that.
[02:40:21.260 --> 02:40:24.300]   Couple of remaining stories that they sent to the bottom.
[02:40:24.300 --> 02:40:26.260]   Let's get them all in real quick.
[02:40:26.260 --> 02:40:27.260]   Yup.
[02:40:27.260 --> 02:40:32.660]   Goldman Sachs lost a billion dollars on the Apple card.
[02:40:32.660 --> 02:40:33.660]   Yup.
[02:40:33.660 --> 02:40:39.820]   How incompetent do you have to be to lose money on the Apple cards?
[02:40:39.820 --> 02:40:41.660]   So that's opportunity cost.
[02:40:41.660 --> 02:40:48.580]   Essentially, they have to set aside enough money to cover any bad loans that are being
[02:40:48.580 --> 02:40:49.580]   put onto the Apple card.
[02:40:49.580 --> 02:40:51.980]   It's so hard to get an Apple card.
[02:40:51.980 --> 02:40:52.980]   Right.
[02:40:52.980 --> 02:40:53.980]   You got to have perfect credit.
[02:40:53.980 --> 02:40:57.220]   It's hard to get even the credit limit above.
[02:40:57.220 --> 02:41:00.460]   I saw some people getting a credit limit of a couple hundred dollars.
[02:41:00.460 --> 02:41:02.420]   You can't buy anything at an Apple's birthday.
[02:41:02.420 --> 02:41:08.260]   That's the problem because most of those credit cards work on razor thin margins, but huge
[02:41:08.260 --> 02:41:10.500]   volumes and Apple card does not have that.
[02:41:10.500 --> 02:41:12.900]   They couldn't give them the volume thing, right?
[02:41:12.900 --> 02:41:13.900]   Interesting.
[02:41:13.900 --> 02:41:15.660]   It's kind of sad.
[02:41:15.660 --> 02:41:16.660]   It's part of a large story.
[02:41:16.660 --> 02:41:17.660]   I love my Apple card.
[02:41:17.660 --> 02:41:18.660]   Me too.
[02:41:18.660 --> 02:41:19.660]   I use it.
[02:41:19.660 --> 02:41:20.660]   I buy groceries with it.
[02:41:20.660 --> 02:41:22.700]   I don't think I can get one in Italy, right?
[02:41:22.700 --> 02:41:23.700]   They don't offer them without it.
[02:41:23.700 --> 02:41:24.700]   No.
[02:41:24.700 --> 02:41:25.700]   But I do on my watch.
[02:41:25.700 --> 02:41:27.420]   I just tap to pay everywhere.
[02:41:27.420 --> 02:41:28.420]   And it's all goes in the Apple card.
[02:41:28.420 --> 02:41:30.620]   It's like I'm not really paying anything.
[02:41:30.620 --> 02:41:31.620]   And then it comes out of my mind.
[02:41:31.620 --> 02:41:33.100]   And I didn't even know.
[02:41:33.100 --> 02:41:34.100]   Is that how credit?
[02:41:34.100 --> 02:41:35.100]   Credit works free.
[02:41:35.100 --> 02:41:36.100]   Yes.
[02:41:36.100 --> 02:41:37.100]   It's free.
[02:41:37.100 --> 02:41:38.100]   Have this sandwich.
[02:41:38.100 --> 02:41:39.100]   It's free.
[02:41:39.100 --> 02:41:40.100]   What do you mean?
[02:41:40.100 --> 02:41:42.340]   Tap your watch on here and we'll give it to you.
[02:41:42.340 --> 02:41:43.340]   Chat GPT.
[02:41:43.340 --> 02:41:44.500]   How do credit cards work?
[02:41:44.500 --> 02:41:46.340]   I thought it, please.
[02:41:46.340 --> 02:41:49.140]   It just says it's free.
[02:41:49.140 --> 02:41:50.140]   Loser.
[02:41:50.140 --> 02:41:51.500]   Apparently, loser.
[02:41:51.500 --> 02:41:55.020]   How many people got it just because it's a status symbol?
[02:41:55.020 --> 02:41:57.140]   I got it because it's very heavy.
[02:41:57.140 --> 02:41:58.140]   It's very heavy.
[02:41:58.140 --> 02:41:59.140]   It's nice.
[02:41:59.140 --> 02:42:03.260]   Are you going to use that over the card that gives you miles?
[02:42:03.260 --> 02:42:07.820]   I have a card that gives me miles and my Apple card.
[02:42:07.820 --> 02:42:14.060]   I use the Apple card whenever I'm paying with my phone or watch, which is a lot.
[02:42:14.060 --> 02:42:17.780]   And then I use my miles card for everything else.
[02:42:17.780 --> 02:42:21.620]   The Apple card gives you 3% on Apple purchases.
[02:42:21.620 --> 02:42:25.060]   That to me is thousands of dollars a year.
[02:42:25.060 --> 02:42:26.820]   Yes, that's true.
[02:42:26.820 --> 02:42:30.300]   Or that could be hundreds of thousands of miles.
[02:42:30.300 --> 02:42:32.660]   Which you can't use except for blackout dates.
[02:42:32.660 --> 02:42:34.300]   Oh, you can use it better.
[02:42:34.300 --> 02:42:36.060]   Do you fly here on miles?
[02:42:36.060 --> 02:42:37.060]   Adult, yes.
[02:42:37.060 --> 02:42:38.060]   And on which, on Delta?
[02:42:38.060 --> 02:42:39.060]   Delta.
[02:42:39.060 --> 02:42:40.060]   Yeah.
[02:42:40.060 --> 02:42:43.220]   When I was flying before I amassed something like 4 million miles, so I'm still working
[02:42:43.220 --> 02:42:44.220]   with those guys.
[02:42:44.220 --> 02:42:45.220]   Oh my God.
[02:42:45.220 --> 02:42:46.220]   Oh yeah.
[02:42:46.220 --> 02:42:47.220]   I have 150,000 United miles.
[02:42:47.220 --> 02:42:49.340]   I can't use to go anywhere I want.
[02:42:49.340 --> 02:42:51.300]   So it's like, thank you for nothing.
[02:42:51.300 --> 02:42:56.180]   The problem with Goldman Sachs is they've been really trying to become a consumer bank.
[02:42:56.180 --> 02:42:57.180]   Yes.
[02:42:57.180 --> 02:42:59.980]   And that is an expensive proposition.
[02:42:59.980 --> 02:43:03.260]   And Apple, the Apple card is not the only one that they're trying this with.
[02:43:03.260 --> 02:43:06.540]   They've actually lost 4 billion dollars since 2020.
[02:43:06.540 --> 02:43:07.540]   Apple accounts for 1 billion.
[02:43:07.540 --> 02:43:13.380]   So they're trying to do this whole niche market where you get higher income customers.
[02:43:13.380 --> 02:43:16.420]   They have a buy now pay later thing called green sky.
[02:43:16.420 --> 02:43:18.820]   By the way, didn't Apple announce BNPL?
[02:43:18.820 --> 02:43:21.700]   And did they ever put out buy now pay later?
[02:43:21.700 --> 02:43:26.140]   I think they do have it for Apple products because I've used it whenever I'm paying.
[02:43:26.140 --> 02:43:31.380]   I've purchased, I don't know, like a Mac book recently where it's just installments kind
[02:43:31.380 --> 02:43:34.500]   of baked into your Apple card, like zero APR.
[02:43:34.500 --> 02:43:36.260]   It was pretty easy.
[02:43:36.260 --> 02:43:38.660]   So is that internal or did they go through Goldman Sachs?
[02:43:38.660 --> 02:43:39.740]   I think that's Goldman as well.
[02:43:39.740 --> 02:43:41.620]   I think I don't know.
[02:43:41.620 --> 02:43:43.820]   Maybe that's where Goldman's taking the hit.
[02:43:43.820 --> 02:43:44.820]   Could be.
[02:43:44.820 --> 02:43:45.820]   Yeah.
[02:43:45.820 --> 02:43:46.820]   Probably.
[02:43:46.820 --> 02:43:48.260]   There was an app.
[02:43:48.260 --> 02:43:54.900]   There was an app called RetroPod, which looked just like an iPod until Apple realized
[02:43:54.900 --> 02:43:57.900]   it looked just like an iPod and they killed it.
[02:43:57.900 --> 02:43:58.900]   Oh, come on.
[02:43:58.900 --> 02:43:59.900]   Yep.
[02:43:59.900 --> 02:44:00.900]   Wait, why?
[02:44:00.900 --> 02:44:02.500]   Because it replicates functionality.
[02:44:02.500 --> 02:44:05.780]   It looks just like an iPod, which didn't even sell anymore.
[02:44:05.780 --> 02:44:10.340]   The app had been downloaded half a million times because of viral videos.
[02:44:10.340 --> 02:44:11.340]   That's fun.
[02:44:11.340 --> 02:44:12.340]   It's a fun little app.
[02:44:12.340 --> 02:44:14.580]   Approved and released in October.
[02:44:14.580 --> 02:44:15.580]   Get that.
[02:44:15.580 --> 02:44:21.460]   Neither Apple nor RetroPod has said why the app is removed, but it did come right after
[02:44:21.460 --> 02:44:22.820]   it got a spike.
[02:44:22.820 --> 02:44:23.820]   We can start.
[02:44:23.820 --> 02:44:24.820]   We'll buy it.
[02:44:24.820 --> 02:44:25.820]   Maybe Apple buy.
[02:44:25.820 --> 02:44:29.980]   I think Apple is going to do an anniversary re-release of the iPod so they don't want
[02:44:29.980 --> 02:44:31.540]   anything getting in the way of those sales.
[02:44:31.540 --> 02:44:34.980]   Actually, that's the other iPod story.
[02:44:34.980 --> 02:44:39.020]   Somebody has hacked the iPod.
[02:44:39.020 --> 02:44:40.020]   Like who cares?
[02:44:40.020 --> 02:44:41.820]   To do what?
[02:44:41.820 --> 02:44:43.460]   Anything you want.
[02:44:43.460 --> 02:44:45.100]   It's actually, I would recommend.
[02:44:45.100 --> 02:44:47.100]   Does it play Doom?
[02:44:47.100 --> 02:44:48.100]   You could play Doom.
[02:44:48.100 --> 02:44:49.100]   In fact, that was how it started.
[02:44:49.100 --> 02:44:51.380]   You wanted to put Linux and Doom.
[02:44:51.380 --> 02:44:58.540]   But what is actually is a great article I recommend at q3k.org because it's how you would go about
[02:44:58.540 --> 02:44:59.940]   cracking a device like this.
[02:44:59.940 --> 02:45:02.380]   It was very locked down firmware.
[02:45:02.380 --> 02:45:04.020]   That actually is impressive.
[02:45:04.020 --> 02:45:07.380]   It's an impressive hack, but also it's a fascinating hack.
[02:45:07.380 --> 02:45:09.100]   This has a secure boot ROM.
[02:45:09.100 --> 02:45:11.820]   You know, they get signed and all of that stuff.
[02:45:11.820 --> 02:45:14.260]   They really locked it down.
[02:45:14.260 --> 02:45:16.820]   This is a really wonderful article I thought I would do.
[02:45:16.820 --> 02:45:18.660]   First engineering, the boot ROM.
[02:45:18.660 --> 02:45:22.500]   He's actually looking at the code.
[02:45:22.500 --> 02:45:27.540]   Not because it's open source, but I guess because he compiled it.
[02:45:27.540 --> 02:45:28.540]   Disassembled it.
[02:45:28.540 --> 02:45:29.540]   I don't know where he got the symbol table.
[02:45:29.540 --> 02:45:30.940]   I guess he doesn't have it.
[02:45:30.940 --> 02:45:32.420]   And he was able, he's really great.
[02:45:32.420 --> 02:45:38.220]   It says things like, "Well, as you can see here, there's a bug in the USB.
[02:45:38.220 --> 02:45:39.460]   You see this right here?
[02:45:39.460 --> 02:45:40.460]   I'll trust you."
[02:45:40.460 --> 02:45:44.180]   You see where it says, "USB device request, G-State EP0-DMA."
[02:45:44.180 --> 02:45:45.340]   Well, obviously.
[02:45:45.340 --> 02:45:46.340]   Obviously.
[02:45:46.340 --> 02:45:49.180]   I could see that across the room, Leo.
[02:45:49.180 --> 02:45:54.900]   They're not sanitizing their inputs there.
[02:45:54.900 --> 02:45:55.900]   There it is.
[02:45:55.900 --> 02:45:56.900]   The bug's right there.
[02:45:56.900 --> 02:45:57.900]   Can you see it?
[02:45:57.900 --> 02:45:58.900]   That's right.
[02:45:58.900 --> 02:46:05.620]   If BM request type and per se, no X3 equals zero, the user controlled index populated from
[02:46:05.620 --> 02:46:10.020]   the lower byte of the Windex field of the setup packet is used as an index into the G-State
[02:46:10.020 --> 02:46:12.980]   USB handlers without any boundary checks.
[02:46:12.980 --> 02:46:18.260]   I don't know about the human narration on that article.
[02:46:18.260 --> 02:46:21.060]   Chat GPT will never be able to make it happen.
[02:46:21.060 --> 02:46:25.420]   You know what, don't count on it because now that it's written up, chat GPT will absorb
[02:46:25.420 --> 02:46:28.900]   it eventually and you could probably ask it how to hack something.
[02:46:28.900 --> 02:46:33.060]   Now, Connie, at CES, did you happen to pass by the Hall of Failures?
[02:46:33.060 --> 02:46:34.060]   No.
[02:46:34.060 --> 02:46:35.060]   That was fun.
[02:46:35.060 --> 02:46:36.060]   No.
[02:46:36.060 --> 02:46:37.620]   There's an actual Hall of Failures?
[02:46:37.620 --> 02:46:42.180]   So they made a bunch of cubicles, little cubicles with demonstrations of technologies
[02:46:42.180 --> 02:46:43.900]   that have failed over the years.
[02:46:43.900 --> 02:46:47.500]   So they had things like the Zoom and that hurt me because I love the Zoom.
[02:46:47.500 --> 02:46:48.500]   Yeah, I loved it.
[02:46:48.500 --> 02:46:50.180]   But well, the Zoom HD was actually good.
[02:46:50.180 --> 02:46:51.180]   Yes.
[02:46:51.180 --> 02:46:52.180]   Not the brown zoom.
[02:46:52.180 --> 02:46:53.180]   No.
[02:46:53.180 --> 02:46:54.180]   That was like the shoes.
[02:46:54.180 --> 02:46:55.180]   No, it's chocolate.
[02:46:55.180 --> 02:46:56.180]   It was chocolate.
[02:46:56.180 --> 02:46:57.180]   Chocolate.
[02:46:57.180 --> 02:46:58.180]   Not the crap zoom.
[02:46:58.180 --> 02:46:59.180]   Good news.
[02:46:59.180 --> 02:47:02.060]   You can swear on your YouTube videos, damn it.
[02:47:02.060 --> 02:47:06.020]   Did you know they were demonetizing videos with swearing?
[02:47:06.020 --> 02:47:12.820]   Not only just new videos, they were going back in time and looking for swearing.
[02:47:12.820 --> 02:47:14.380]   The profanity police.
[02:47:14.380 --> 02:47:15.380]   Only in English.
[02:47:15.380 --> 02:47:17.580]   Well, they didn't know French.
[02:47:17.580 --> 02:47:19.060]   She met Qua.
[02:47:19.060 --> 02:47:27.260]   You know, you have the brains of a baby calf, a father in your general direction and you
[02:47:27.260 --> 02:47:29.580]   can get that away with that, right?
[02:47:29.580 --> 02:47:35.620]   YouTube says, oops, some videos were flagged, others weren't.
[02:47:35.620 --> 02:47:38.100]   You were demonetizing.
[02:47:38.100 --> 02:47:41.580]   You only learned after you were demonetized.
[02:47:41.580 --> 02:47:43.820]   So YouTube hasn't said what it plans to change.
[02:47:43.820 --> 02:47:47.900]   It's not clear if the revised policy will turn it around.
[02:47:47.900 --> 02:47:49.820]   So just stop cursing.
[02:47:49.820 --> 02:47:53.820]   This could really, really affect some of the videos that I've made for Pope Francis.
[02:47:53.820 --> 02:47:55.300]   I've got to go back through that.
[02:47:55.300 --> 02:47:56.900]   Just so you know, the rule limits.
[02:47:56.900 --> 02:48:00.020]   You've got to just go back and just censor all of his curse words.
[02:48:00.020 --> 02:48:02.820]   You know, at least in the first 15 seconds.
[02:48:02.820 --> 02:48:04.420]   Shut the front door.
[02:48:04.420 --> 02:48:11.140]   The rule limits or removes ads on videos where someone swears within the first 15 seconds.
[02:48:11.140 --> 02:48:17.060]   So you could swear after that or has quote, focal usage.
[02:48:17.060 --> 02:48:21.780]   Maybe I mispronounce this is like FBI rules for listening to a call of rude words throughout
[02:48:21.780 --> 02:48:24.340]   and is guaranteed to completely demonetize a clip.
[02:48:24.340 --> 02:48:29.860]   If swearing occurs in the first seven seconds or dominates the content.
[02:48:29.860 --> 02:48:31.420]   Okay.
[02:48:31.420 --> 02:48:33.860]   I would love to know why they're doing this.
[02:48:33.860 --> 02:48:36.660]   Do people swear on the hot ones like when they eat the hot sauce?
[02:48:36.660 --> 02:48:39.380]   They go, Oh, but they blew the mouth mother fudger.
[02:48:39.380 --> 02:48:41.740]   Actually, so it's only the swears that make it through, right?
[02:48:41.740 --> 02:48:43.260]   If you're so sensitive, yeah, yeah.
[02:48:43.260 --> 02:48:45.220]   So I want to.
[02:48:45.220 --> 02:48:48.580]   I'm going to use this makes this is clearly why my YouTube channel.
[02:48:48.580 --> 02:48:51.740]   Yeah, it didn't off.
[02:48:51.740 --> 02:48:54.060]   So I was like, Hey guys, welcome to get.
[02:48:54.060 --> 02:48:58.020]   And YouTube was like, absolutely not today.
[02:48:58.020 --> 02:49:00.340]   We're going to use the word get in creative.
[02:49:00.340 --> 02:49:05.300]   Maybe hit that bell guys.
[02:49:05.300 --> 02:49:06.300]   Not today.
[02:49:06.300 --> 02:49:10.460]   I may be wrong, but I feel like almost all the YouTube videos are full of swearing.
[02:49:10.460 --> 02:49:14.420]   So yes, yes, I puzzled by that.
[02:49:14.420 --> 02:49:18.340]   Study says to do a Latin preamble for the first 15 seconds.
[02:49:18.340 --> 02:49:20.980]   I can I can create a custom Latin.
[02:49:20.980 --> 02:49:24.860]   Do they use the swear words from the good place and the Vatican like, you know, do they
[02:49:24.860 --> 02:49:29.440]   say, you know, like the good place had all those great swear words that weren't swear
[02:49:29.440 --> 02:49:30.440]   words.
[02:49:30.440 --> 02:49:36.180]   I have never even been seriously tempted to swear in Rome, which would be better because
[02:49:36.180 --> 02:49:37.380]   I swear all the time here.
[02:49:37.380 --> 02:49:43.340]   But over there, it just like pass into the air space and you're like, Zen is cleaned out.
[02:49:43.340 --> 02:49:44.500]   I'm just cleaned out.
[02:49:44.500 --> 02:49:45.700]   So it's like a swear.
[02:49:45.700 --> 02:49:48.120]   The F word becomes fork.
[02:49:48.120 --> 02:49:50.540]   The S word becomes shirt.
[02:49:50.540 --> 02:49:59.280]   The Batch becomes bench.
[02:49:59.280 --> 02:50:01.440]   You're high.
[02:50:01.440 --> 02:50:02.440]   And on and on.
[02:50:02.440 --> 02:50:03.440]   Okay.
[02:50:03.440 --> 02:50:04.440]   Well, now I have new swear words.
[02:50:04.440 --> 02:50:06.200]   Yeah, you might try that in the bad place.
[02:50:06.200 --> 02:50:07.200]   You can curse.
[02:50:07.200 --> 02:50:12.680]   Well, I mean, remember battle star Galactica use frack back in the 70s and they got away
[02:50:12.680 --> 02:50:13.680]   with it.
[02:50:13.680 --> 02:50:14.680]   Yeah.
[02:50:14.680 --> 02:50:15.680]   No, in fact, that was great.
[02:50:15.680 --> 02:50:16.680]   Yeah.
[02:50:16.680 --> 02:50:18.680]   And then the firefly used fake Chinese words.
[02:50:18.680 --> 02:50:19.680]   Yeah, like go ram.
[02:50:19.680 --> 02:50:20.680]   Yeah.
[02:50:20.680 --> 02:50:21.680]   I loved that.
[02:50:21.680 --> 02:50:26.960]   I thought that's really a way of getting the, you know, the anger out, but not study
[02:50:26.960 --> 02:50:28.560]   says no.
[02:50:28.560 --> 02:50:35.660]   And I think, you know, it's funny because this is maybe not how my people, the left wingers
[02:50:35.660 --> 02:50:37.320]   would like me to interpret it.
[02:50:37.320 --> 02:50:41.380]   The Russian trolls did not in fact impact the 26 of 16 election.
[02:50:41.380 --> 02:50:44.880]   And I thought that on the surface of it, even back then was a little absurd.
[02:50:44.880 --> 02:50:46.800]   Yeah, sure, they were there.
[02:50:46.800 --> 02:50:51.440]   But some people didn't read a tweet and then say, ah, I'm going to vote for Donald Trump.
[02:50:51.440 --> 02:50:58.480]   So this study, which was conducted, it's published in nature, long list of researchers
[02:50:58.480 --> 02:51:03.000]   looking at whether or not Russian trolls on social media had any impact on the 2016 election.
[02:51:03.000 --> 02:51:04.400]   No, they did not.
[02:51:04.400 --> 02:51:08.840]   Finally, they say we found no evidence of a meaningful relationship between exposure
[02:51:08.840 --> 02:51:13.200]   to the Russian foreign influence campaign, which no one denies existed and changes in
[02:51:13.200 --> 02:51:18.360]   attitudes, polarization or voting behavior.
[02:51:18.360 --> 02:51:19.360]   You know that.
[02:51:19.360 --> 02:51:24.280]   I mean, it reminds me of like with the whole news cycle around Cambridge Analytica, where
[02:51:24.280 --> 02:51:29.560]   everybody at first was like, oh, this has completely changed the face of reality.
[02:51:29.560 --> 02:51:34.320]   But then you look into it a bit more and it's like actually people looking at tweets.
[02:51:34.320 --> 02:51:37.480]   The tweets aren't the most impactful part of their day to day lives.
[02:51:37.480 --> 02:51:42.200]   It is not fully changing someone's thoughts and feelings about something.
[02:51:42.200 --> 02:51:46.320]   I mean, it's all been about self reinforcement of what you already believe.
[02:51:46.320 --> 02:51:50.880]   And that's that's actually what the trolls and the influence peddlers have done.
[02:51:50.880 --> 02:51:53.360]   They know they're not going to change anyone's mind.
[02:51:53.360 --> 02:51:57.440]   There's very few fence sitters who are going to be changing their vote based on a YouTube
[02:51:57.440 --> 02:51:58.920]   video or a tweet.
[02:51:58.920 --> 02:52:04.240]   However, what they can do is they can make any sort of useful discussion toxic, which,
[02:52:04.240 --> 02:52:10.240]   which that heads off a further discussion about important issues.
[02:52:10.240 --> 02:52:13.280]   So in that instance, that has made an effect.
[02:52:13.280 --> 02:52:16.160]   It just didn't change the outcome of the vote.
[02:52:16.160 --> 02:52:20.400]   It has changed the outcome of future votes because no one wants to talk about anything
[02:52:20.400 --> 02:52:23.680]   without becoming five levels of horrible.
[02:52:23.680 --> 02:52:24.680]   Yeah.
[02:52:24.680 --> 02:52:29.200]   I mean, I think that it really is amping up the polarization on both sides.
[02:52:29.200 --> 02:52:36.160]   I'm sure that one aspect of that is that your people are perhaps going to end up being
[02:52:36.160 --> 02:52:38.040]   more actionable on certain items.
[02:52:38.040 --> 02:52:42.720]   You know, someone who might not have donated to like far right campaign.
[02:52:42.720 --> 02:52:47.760]   If you see enough content, they're going to maybe send that five or $10.
[02:52:47.760 --> 02:52:48.760]   But that's so subtle.
[02:52:48.760 --> 02:52:51.120]   It's probably not measurable, right?
[02:52:51.120 --> 02:52:54.120]   Maybe that's why it's not it's not easily measured.
[02:52:54.120 --> 02:52:55.120]   Yeah.
[02:52:55.120 --> 02:52:58.200]   Yeah, because no one's opening up their books to show exactly how much they've received
[02:52:58.200 --> 02:53:02.440]   and donations after the last hate speech campaign.
[02:53:02.440 --> 02:53:04.680]   It can also though sway.
[02:53:04.680 --> 02:53:08.000]   What are the topics of conversation and push them in subtle ways?
[02:53:08.000 --> 02:53:09.000]   One direction or another.
[02:53:09.000 --> 02:53:12.040]   So the so-called Overton window gets shifted.
[02:53:12.040 --> 02:53:13.040]   Yeah.
[02:53:13.040 --> 02:53:14.040]   Yeah.
[02:53:14.040 --> 02:53:15.040]   Yes.
[02:53:15.040 --> 02:53:18.200]   Well, that concludes this thrilling gripping tradition.
[02:53:18.200 --> 02:53:19.200]   We ran out of news.
[02:53:19.200 --> 02:53:20.200]   We ran out of time.
[02:53:20.200 --> 02:53:21.200]   Oh, but almost three hours.
[02:53:21.200 --> 02:53:22.200]   Oh my goodness.
[02:53:22.200 --> 02:53:23.200]   Okay.
[02:53:23.200 --> 02:53:24.200]   I'm so sorry.
[02:53:24.200 --> 02:53:25.200]   I apologize to all in some.
[02:53:25.200 --> 02:53:26.920]   Have you noticed that I tend to be on the longest twits?
[02:53:26.920 --> 02:53:29.160]   You haven't even gotten half this crap you brought.
[02:53:29.160 --> 02:53:30.160]   Wait, yeah.
[02:53:30.160 --> 02:53:31.160]   Can we see another doodad?
[02:53:31.160 --> 02:53:32.160]   Doodad.
[02:53:32.160 --> 02:53:34.160]   What's the silliest one?
[02:53:34.160 --> 02:53:35.560]   Oh, no.
[02:53:35.560 --> 02:53:41.440]   The silliest ones I did not bring because they are not safe to be on the air at twit.
[02:53:41.440 --> 02:53:42.440]   You're in puck?
[02:53:42.440 --> 02:53:44.200]   No, no, but they do have to-
[02:53:44.200 --> 02:53:45.640]   You just bring a bottle of pee.
[02:53:45.640 --> 02:53:49.960]   You could have sold that to someone outside the studio for a hundred bucks.
[02:53:49.960 --> 02:53:53.960]   There was, okay, there was one from a company called Handy.
[02:53:53.960 --> 02:53:56.360]   Don't tell me that.
[02:53:56.360 --> 02:53:57.360]   Exactly.
[02:53:57.360 --> 02:53:58.360]   All right.
[02:53:58.360 --> 02:54:01.080]   I'll just leave that by Leo.
[02:54:01.080 --> 02:54:03.480]   I ignite.
[02:54:03.480 --> 02:54:04.760]   It's comfortable though, right?
[02:54:04.760 --> 02:54:05.760]   It's nice.
[02:54:05.760 --> 02:54:06.760]   It's shared.
[02:54:06.760 --> 02:54:07.760]   What is this material?
[02:54:07.760 --> 02:54:08.760]   This is-
[02:54:08.760 --> 02:54:09.760]   Aerogen.
[02:54:09.760 --> 02:54:10.760]   What does it do?
[02:54:10.760 --> 02:54:11.760]   What is it?
[02:54:11.760 --> 02:54:15.920]   So it's 99% air, so it's super light, but it's also one of the best insulators that
[02:54:15.920 --> 02:54:17.760]   NASA has been able to come up with.
[02:54:17.760 --> 02:54:18.760]   It feels very toasty.
[02:54:18.760 --> 02:54:19.760]   Yeah.
[02:54:19.760 --> 02:54:20.760]   It's very light.
[02:54:20.760 --> 02:54:21.760]   And it's comfy.
[02:54:21.760 --> 02:54:24.120]   It will retain almost all of your body heat.
[02:54:24.120 --> 02:54:29.440]   In fact, I used this when it was down at about 30 degrees, and it was too hot.
[02:54:29.440 --> 02:54:30.680]   I had to open it up.
[02:54:30.680 --> 02:54:31.680]   Yeah.
[02:54:31.680 --> 02:54:32.680]   Nice.
[02:54:32.680 --> 02:54:35.000]   It's available in your local REX.
[02:54:35.000 --> 02:54:36.000]   Oh, yes, yes.
[02:54:36.000 --> 02:54:37.000]   Eventually.
[02:54:37.000 --> 02:54:38.000]   But right now, it's Big Blue.
[02:54:38.000 --> 02:54:41.240]   Actually, that and the bolster are kick starters right now.
[02:54:41.240 --> 02:54:42.640]   It smells like Mars.
[02:54:42.640 --> 02:54:43.640]   Wait, what?
[02:54:43.640 --> 02:54:46.480]   So this is a Kickstarter, Big Blue?
[02:54:46.480 --> 02:54:47.480]   This is a Kickstarter.
[02:54:47.480 --> 02:54:48.480]   Oh, nay.
[02:54:48.480 --> 02:54:49.480]   It's kind of fun.
[02:54:49.480 --> 02:54:51.160]   I like having those companies back at CES.
[02:54:51.160 --> 02:54:57.240]   I spent so much time down in the Eureka Plaza, or Eureka Zone, down in the bottom floor of
[02:54:57.240 --> 02:54:58.240]   Venetian.
[02:54:58.240 --> 02:55:00.000]   That's where you find like the old CES.
[02:55:00.000 --> 02:55:01.000]   I'm going to say yes.
[02:55:01.000 --> 02:55:02.000]   I'm going to say yes.
[02:55:02.000 --> 02:55:03.000]   That's so cool.
[02:55:03.000 --> 02:55:05.320]   Eale, next time you come with me.
[02:55:05.320 --> 02:55:06.320]   I will.
[02:55:06.320 --> 02:55:07.320]   One day, just one day.
[02:55:07.320 --> 02:55:08.320]   I've been to the Eureka Zone.
[02:55:08.320 --> 02:55:09.320]   Yeah.
[02:55:09.320 --> 02:55:10.760]   I feel like I just jumped out of an airplane.
[02:55:10.760 --> 02:55:13.560]   I'm having trouble getting the parachute back in the park.
[02:55:13.560 --> 02:55:16.880]   I'm just pushing this out of the way.
[02:55:16.880 --> 02:55:18.440]   Oh, now it's in front of Connie.
[02:55:18.440 --> 02:55:19.440]   Oh, no.
[02:55:19.440 --> 02:55:21.320]   What am I going to do?
[02:55:21.320 --> 02:55:23.920]   Connie, what are you doing these days at CNET?
[02:55:23.920 --> 02:55:25.360]   Anything exciting coming up?
[02:55:25.360 --> 02:55:29.120]   Well, I told you we're looking at all that sustainability tech.
[02:55:29.120 --> 02:55:33.840]   I was actually really excited to see some of the themes and the conversations that people
[02:55:33.840 --> 02:55:34.840]   were having.
[02:55:34.840 --> 02:55:39.720]   One of the funnest products that I saw was basically a bread box that can keep your food.
[02:55:39.720 --> 02:55:42.960]   It is not in the refrigerator fresh for two months.
[02:55:42.960 --> 02:55:47.600]   Caltech was the company out of Japan.
[02:55:47.600 --> 02:55:51.560]   Most people think of a bread box as a bread box, but it was a way to minimize food waste.
[02:55:51.560 --> 02:55:54.440]   Was it like you see or how did it do that?
[02:55:54.440 --> 02:55:59.080]   It has a photo catalysis.
[02:55:59.080 --> 02:56:05.880]   The chemical procedure that's using the decontamination of water to keep bread and produce fresh.
[02:56:05.880 --> 02:56:06.880]   How interesting.
[02:56:06.880 --> 02:56:07.880]   How interesting.
[02:56:07.880 --> 02:56:08.880]   That's cool.
[02:56:08.880 --> 02:56:13.240]   Yeah, because I do, I will, if I have to freeze or put refrigerate bread, but it always takes
[02:56:13.240 --> 02:56:15.680]   some of the good flavor out of it.
[02:56:15.680 --> 02:56:18.520]   But on the other hand, it'll go mowly, at least in our house within a few days.
[02:56:18.520 --> 02:56:19.800]   So it's better than nothing.
[02:56:19.800 --> 02:56:26.640]   But if there were a box about the size of a, I don't know, bread box that I could put
[02:56:26.640 --> 02:56:29.760]   stuff into that wouldn't refrigerate it, but would keep it.
[02:56:29.760 --> 02:56:31.000]   That sounds great.
[02:56:31.000 --> 02:56:37.600]   You also had a very nice piece by Ty Pendelbury on the most ridiculous and weird tech gadgets.
[02:56:37.600 --> 02:56:38.600]   Like the Hushmi voice.
[02:56:38.600 --> 02:56:41.440]   That I don't understand that one.
[02:56:41.440 --> 02:56:42.960]   They tried, they tried selling me on it.
[02:56:42.960 --> 02:56:46.200]   I'm like, no, there seem to be a lot of products to cover your mouth.
[02:56:46.200 --> 02:56:47.760]   The Dyson air purifying.
[02:56:47.760 --> 02:56:49.760]   There were so many of those that are basically.
[02:56:49.760 --> 02:56:52.480]   Yeah, you're in a half too late.
[02:56:52.480 --> 02:56:53.480]   This was never a product.
[02:56:53.480 --> 02:56:57.000]   It's like the Sherman roll bot, but it got a lot of coverage because, and I've always
[02:56:57.000 --> 02:57:02.480]   said this, if you want coverage at CES, be the very first thing people see as they walk
[02:57:02.480 --> 02:57:05.000]   into the PEPCOM or show stoppers.
[02:57:05.000 --> 02:57:09.040]   All the press will stop, cover your item, and then go home because they just want to
[02:57:09.040 --> 02:57:10.640]   get the hell out of there.
[02:57:10.640 --> 02:57:11.640]   The smart tube.
[02:57:11.640 --> 02:57:14.760]   I love the TV that falls off a window when it runs out of power.
[02:57:14.760 --> 02:57:16.640]   That sounds like a great, terrible idea.
[02:57:16.640 --> 02:57:17.640]   It's really smart.
[02:57:17.640 --> 02:57:19.560]   It's totally going to get one of those.
[02:57:19.560 --> 02:57:25.560]   As soon as the power dies, the suction cups fail and your TV falls off the window.
[02:57:25.560 --> 02:57:27.920]   Who thinks this is a good idea?
[02:57:27.920 --> 02:57:31.600]   The first thing you're going to do is make sure it's always plugged in.
[02:57:31.600 --> 02:57:33.800]   So it doesn't fall off the windows.
[02:57:33.800 --> 02:57:36.520]   Anyway, all this great stuff at CNET.
[02:57:36.520 --> 02:57:37.520]   Another toothbrush?
[02:57:37.520 --> 02:57:38.520]   Man.
[02:57:38.520 --> 02:57:40.520]   How about a taser holster?
[02:57:40.520 --> 02:57:41.520]   A taser.
[02:57:41.520 --> 02:57:42.520]   That's great.
[02:57:42.520 --> 02:57:44.680]   I've been wondering where should I put my taser?
[02:57:44.680 --> 02:57:48.400]   Sure, like an animal you're holding in your hand or you're just having your pocket.
[02:57:48.400 --> 02:57:49.880]   Here's the PP pet dryer.
[02:57:49.880 --> 02:57:51.680]   Yeah, I saw that one.
[02:57:51.680 --> 02:57:52.680]   No.
[02:57:52.680 --> 02:57:53.680]   Well, it goes with your...
[02:57:53.680 --> 02:57:59.520]   I was going to say my cat would destroy.
[02:57:59.520 --> 02:58:00.520]   We remember this.
[02:58:00.520 --> 02:58:01.520]   This was the vibrating fork.
[02:58:01.520 --> 02:58:02.520]   Is that the spork?
[02:58:02.520 --> 02:58:03.520]   That happy fork.
[02:58:03.520 --> 02:58:04.520]   Another one in the front door.
[02:58:04.520 --> 02:58:06.520]   Look, that got covered eight years ago.
[02:58:06.520 --> 02:58:07.520]   It needs to stop.
[02:58:07.520 --> 02:58:09.680]   This is 25 years of bad stuff.
[02:58:09.680 --> 02:58:10.680]   Hush me.
[02:58:10.680 --> 02:58:11.680]   Yeah.
[02:58:11.680 --> 02:58:12.680]   Yeah.
[02:58:12.680 --> 02:58:13.680]   The belties.
[02:58:13.680 --> 02:58:14.680]   Smart panel holding device.
[02:58:14.680 --> 02:58:15.680]   Yeah, I remember that one.
[02:58:15.680 --> 02:58:16.680]   Wow.
[02:58:16.680 --> 02:58:18.200]   It adjusts granular changes in your foot.
[02:58:18.200 --> 02:58:19.200]   That was good.
[02:58:19.200 --> 02:58:20.200]   That was...
[02:58:20.200 --> 02:58:21.200]   Yeah.
[02:58:21.200 --> 02:58:23.840]   Anyway, there's also serious coverage at CNET.
[02:58:23.840 --> 02:58:24.840]   I agree with you.
[02:58:24.840 --> 02:58:25.840]   Sustainability.
[02:58:25.840 --> 02:58:29.880]   It's about time the tech industry started thinking about that, Connie, because I feel
[02:58:29.880 --> 02:58:30.880]   horrible.
[02:58:30.880 --> 02:58:32.200]   We throw this stuff out.
[02:58:32.200 --> 02:58:33.400]   It's terrible.
[02:58:33.400 --> 02:58:34.400]   Terrible.
[02:58:34.400 --> 02:58:35.400]   Yeah.
[02:58:35.400 --> 02:58:37.080]   It's right in the front page.
[02:58:37.080 --> 02:58:42.600]   CNET 0, everything you need to know about sustainability.
[02:58:42.600 --> 02:58:45.760]   This is going to be a permanent section now on the...
[02:58:45.760 --> 02:58:46.760]   Yes.
[02:58:46.760 --> 02:58:47.760]   It is a permanent section.
[02:58:47.760 --> 02:58:52.800]   It's been sending reporters to COP26, COP27.
[02:58:52.800 --> 02:58:57.640]   Like I said, there's going to be government regulation that steps in, but then people
[02:58:57.640 --> 02:59:00.520]   are going to want to make choices about what they're buying, and especially if they're
[02:59:00.520 --> 02:59:04.120]   not spending a lot of money on things and they want to be more deliberate.
[02:59:04.120 --> 02:59:05.120]   Good.
[02:59:05.120 --> 02:59:06.120]   And what they're choosing.
[02:59:06.120 --> 02:59:07.120]   Bravo.
[02:59:07.120 --> 02:59:08.120]   They need information.
[02:59:08.120 --> 02:59:09.120]   Bravo.
[02:59:09.120 --> 02:59:10.560]   Actually, this is another one of our big initiatives.
[02:59:10.560 --> 02:59:14.680]   We call it Care for the Common Home, but it's basically sustainability.
[02:59:14.680 --> 02:59:17.960]   That's another reason why I might call you to do a conference.
[02:59:17.960 --> 02:59:20.440]   We'll very much...
[02:59:20.440 --> 02:59:21.920]   My phone is open.
[02:59:21.920 --> 02:59:22.920]   Standing by.
[02:59:22.920 --> 02:59:28.360]   Connie Goyelmo, Editor-in-Chief of CNET at Tech Leads, LEDES on the Twitter.
[02:59:28.360 --> 02:59:29.360]   It's so nice to see you.
[02:59:29.360 --> 02:59:30.440]   It's nice to have you on.
[02:59:30.440 --> 02:59:34.120]   Thank you for taking this Sunday afternoon or evening to be with us.
[02:59:34.120 --> 02:59:36.120]   We appreciate it.
[02:59:36.120 --> 02:59:37.120]   My pleasure.
[02:59:37.120 --> 02:59:39.360]   CNET.com, kids.
[02:59:39.360 --> 02:59:44.480]   The information.com is where you'll find Paris Martenau.
[02:59:44.480 --> 02:59:47.680]   What's your favorite coffee shop in Brooklyn?
[02:59:47.680 --> 02:59:49.680]   Oh, that's hard.
[02:59:49.680 --> 02:59:52.680]   Do you have a hangout?
[02:59:52.680 --> 02:59:54.680]   I go to...
[02:59:54.680 --> 02:59:57.720]   I mean, in Brooklyn, I go to this place called the Good Batch.
[02:59:57.720 --> 03:00:00.520]   Often, they do really great, like little sweet pastries.
[03:00:00.520 --> 03:00:03.360]   It feels like that's just what you should do in Brooklyn.
[03:00:03.360 --> 03:00:04.360]   It is, yeah.
[03:00:04.360 --> 03:00:10.440]   I am strangely in a neighborhood where I am surrounded by like six different vegan bakery
[03:00:10.440 --> 03:00:11.440]   coffee shops.
[03:00:11.440 --> 03:00:18.200]   So, I've got to go to the one that uses animal parts at the very least.
[03:00:18.200 --> 03:00:24.080]   Just to make myself feel a little worse about my contributions to the world.
[03:00:24.080 --> 03:00:26.720]   Hey, the good thing about animals, they're sustainable.
[03:00:26.720 --> 03:00:27.720]   I mean...
[03:00:27.720 --> 03:00:28.720]   Not really.
[03:00:28.720 --> 03:00:29.720]   I mean...
[03:00:29.720 --> 03:00:36.720]   That is technically true.
[03:00:36.720 --> 03:00:38.280]   They're not good for the...
[03:00:38.280 --> 03:00:40.120]   Are use of them not good?
[03:00:40.120 --> 03:00:42.080]   Paris Martenau on Twitter.
[03:00:42.080 --> 03:00:43.080]   Yeah.
[03:00:43.080 --> 03:00:44.080]   Yeah.
[03:00:44.080 --> 03:00:45.080]   Find me there.
[03:00:45.080 --> 03:00:48.480]   If I were named Paris, I would be living in Paris right now.
[03:00:48.480 --> 03:00:53.540]   The thing is, you quickly learn that even if you speak excellent French, French people
[03:00:53.540 --> 03:00:57.840]   do not, will never understand the concept that your name is Paris.
[03:00:57.840 --> 03:00:58.840]   That's true.
[03:00:58.840 --> 03:01:02.760]   And no matter how great your French is, they'll immediately be like, "Switched to English."
[03:01:02.760 --> 03:01:05.240]   No, I asked you what your name is, not where we are.
[03:01:05.240 --> 03:01:06.440]   Oh my God.
[03:01:06.440 --> 03:01:07.920]   I was there for like a year.
[03:01:07.920 --> 03:01:11.160]   I had to go from my middle name, Gabrielle.
[03:01:11.160 --> 03:01:13.160]   Which is a beautiful name.
[03:01:13.160 --> 03:01:14.160]   It is, but I mean...
[03:01:14.160 --> 03:01:15.160]   Not my first name.
[03:01:15.160 --> 03:01:18.760]   When you're in France, do you call yourself Paris?
[03:01:18.760 --> 03:01:21.240]   I tried, but that didn't work either.
[03:01:21.240 --> 03:01:22.240]   I was confused.
[03:01:22.240 --> 03:01:23.240]   You get blank stares.
[03:01:23.240 --> 03:01:24.240]   They were just confused.
[03:01:24.240 --> 03:01:25.240]   I mean, it's Cleveland.
[03:01:25.240 --> 03:01:26.240]   The French are vicious.
[03:01:26.240 --> 03:01:27.240]   Yeah, this is all.
[03:01:27.240 --> 03:01:29.240]   You clearly don't understand.
[03:01:29.240 --> 03:01:30.240]   They said, "Sweetness."
[03:01:30.240 --> 03:01:31.240]   They go right in.
[03:01:31.240 --> 03:01:32.240]   Yeah.
[03:01:32.240 --> 03:01:34.240]   This is not my dog.
[03:01:34.240 --> 03:01:39.160]   Mr. Father, Reverend, whatever it is.
[03:01:39.160 --> 03:01:41.560]   The right Father Padre.
[03:01:41.560 --> 03:01:42.560]   Defender of the Face.
[03:01:42.560 --> 03:01:43.560]   Defender of the Face.
[03:01:43.560 --> 03:01:44.560]   Yes.
[03:01:44.560 --> 03:01:45.560]   Yes.
[03:01:45.560 --> 03:01:46.560]   Yes.
[03:01:46.560 --> 03:01:49.880]   No app is on the app store right now, Android, Google Play Store as well.
[03:01:49.880 --> 03:01:51.560]   Jeez, Jesuit pilgrimage.
[03:01:51.560 --> 03:01:52.560]   App.app.app.
[03:01:52.560 --> 03:01:58.400]   Yeah, and if you poke around, you can find the places where I recorded the audio for
[03:01:58.400 --> 03:02:02.080]   the meditations and they did not take me out.
[03:02:02.080 --> 03:02:04.640]   It was supposed to be a placeholder, but I'm still in there.
[03:02:04.640 --> 03:02:05.640]   Did you do it with commitment?
[03:02:05.640 --> 03:02:06.640]   Did you care?
[03:02:06.640 --> 03:02:07.640]   Of course.
[03:02:07.640 --> 03:02:08.640]   I care.
[03:02:08.640 --> 03:02:09.640]   So that's fun to produce it.
[03:02:09.640 --> 03:02:10.640]   I'm going to do it properly.
[03:02:10.640 --> 03:02:11.640]   Yeah.
[03:02:11.640 --> 03:02:12.640]   It's okay.
[03:02:12.640 --> 03:02:13.640]   It's good.
[03:02:13.640 --> 03:02:14.640]   Yeah.
[03:02:14.640 --> 03:02:15.640]   Good.
[03:02:15.640 --> 03:02:16.640]   And coming soon to that app, we're going to show off copy places in Rome.
[03:02:16.640 --> 03:02:17.640]   I would be awesome.
[03:02:17.640 --> 03:02:18.640]   Good places to eat.
[03:02:18.640 --> 03:02:19.640]   Good places.
[03:02:19.640 --> 03:02:20.640]   Yeah.
[03:02:20.640 --> 03:02:21.640]   The Jesuits.
[03:02:21.640 --> 03:02:22.640]   There you go.
[03:02:22.640 --> 03:02:23.640]   My name is Jelato.
[03:02:23.640 --> 03:02:24.640]   I'm a fan of the great places.
[03:02:24.640 --> 03:02:25.640]   I'm a fan of the great places.
[03:02:25.640 --> 03:02:26.640]   I'm a fan of the great places.
[03:02:26.640 --> 03:02:27.640]   I'm a fan of the great places.
[03:02:27.640 --> 03:02:28.640]   I'm a fan of the great places.
[03:02:28.640 --> 03:02:29.640]   I'm a fan of the great places.
[03:02:29.640 --> 03:02:30.640]   I'm a fan of the great places.
[03:02:30.640 --> 03:02:31.640]   I'm a fan of the great places.
[03:02:31.640 --> 03:02:32.640]   I'm a fan of the great places.
[03:02:32.640 --> 03:02:33.640]   I'm a fan of the great places.
[03:02:33.640 --> 03:02:34.640]   I'm a fan of the great places.
[03:02:34.640 --> 03:02:35.640]   I'm a fan of the great places.
[03:02:35.640 --> 03:02:36.640]   I'm a fan of the great places.
[03:02:36.640 --> 03:02:37.640]   I'm a fan of the great places.
[03:02:37.640 --> 03:02:38.640]   I'm a fan of the great places.
[03:02:38.640 --> 03:02:39.640]   I'm a fan of the great places.
[03:02:39.640 --> 03:02:40.640]   Oh, Jelato.
[03:02:40.640 --> 03:02:41.640]   Jelato.
[03:02:41.640 --> 03:02:42.640]   I know all the big Jelato places.
[03:02:42.640 --> 03:02:49.640]   I'm a fan of the great places.
[03:02:49.640 --> 03:02:57.640]   I'm a fan of the great places.
[03:02:57.640 --> 03:03:02.640]   I'm a fan of the great places.
[03:03:02.640 --> 03:03:07.640]   I'm a fan of the great places.
[03:03:07.640 --> 03:03:14.640]   Congratulations on that, by the way.
[03:03:14.640 --> 03:03:15.640]   Good.
[03:03:15.640 --> 03:03:16.640]   That's many, many years.
[03:03:16.640 --> 03:03:17.640]   Wow.
[03:03:17.640 --> 03:03:18.640]   19 years doing radio.
[03:03:18.640 --> 03:03:20.640]   I finally said, "If you're not going to pay me,
[03:03:20.640 --> 03:03:21.640]   I'm not going to do this."
[03:03:21.640 --> 03:03:26.640]   And so I'm doing it with Micah on Sundays.
[03:03:26.640 --> 03:03:27.640]   It's been so much fun.
[03:03:27.640 --> 03:03:28.640]   We've done a couple of shows.
[03:03:28.640 --> 03:03:30.640]   It's going to get better because you're getting --
[03:03:30.640 --> 03:03:31.640]   Yeah, you're fine.
[03:03:31.640 --> 03:03:32.640]   You're stried.
[03:03:32.640 --> 03:03:34.640]   Why shouldn't we be doing it for us instead of --
[03:03:34.640 --> 03:03:36.640]   It's the first time my whole life since I was 16
[03:03:36.640 --> 03:03:37.640]   and I was like, "I need a call."
[03:03:37.640 --> 03:03:38.640]   I can do that from Rome.
[03:03:38.640 --> 03:03:39.640]   Could you?
[03:03:39.640 --> 03:03:40.640]   Yes.
[03:03:40.640 --> 03:03:41.640]   I'll do some crank calls for you later.
[03:03:41.640 --> 03:03:42.640]   Would you please?
[03:03:42.640 --> 03:03:44.640]   That'd be awesome.
[03:03:44.640 --> 03:03:47.640]   I would love to moonlight with a person with a sound board
[03:03:47.640 --> 03:03:49.640]   just kind of make some toilet flushing noises.
[03:03:49.640 --> 03:03:52.640]   It would be great if you could do that.
[03:03:52.640 --> 03:03:55.640]   You'd have like a black dot over your face and have a voice
[03:03:55.640 --> 03:03:57.640]   changer at draw a group dish or whatever.
[03:03:57.640 --> 03:03:58.640]   That's right.
[03:03:58.640 --> 03:03:59.640]   And then we could say --
[03:03:59.640 --> 03:04:00.640]   Yeah, that's great.
[03:04:00.640 --> 03:04:03.640]   She or he is calling from inside the house or whatever.
[03:04:03.640 --> 03:04:04.640]   It'd be great.
[03:04:04.640 --> 03:04:05.640]   Yeah.
[03:04:05.640 --> 03:04:06.640]   I'm so fun with you.
[03:04:06.640 --> 03:04:07.640]   I think that'd be good.
[03:04:07.640 --> 03:04:08.640]   You're more than welcome to do that.
[03:04:08.640 --> 03:04:09.640]   We'd love to.
[03:04:09.640 --> 03:04:10.640]   You could use my catacombset.
[03:04:10.640 --> 03:04:11.640]   Yeah.
[03:04:11.640 --> 03:04:12.640]   Oh, wonderful.
[03:04:12.640 --> 03:04:14.640]   I'll just be like, " are your bones running?"
[03:04:14.640 --> 03:04:15.640]   What does that mean?
[03:04:15.640 --> 03:04:16.640]   What?
[03:04:16.640 --> 03:04:17.640]   What?
[03:04:17.640 --> 03:04:18.640]   Are your bones running?
[03:04:18.640 --> 03:04:23.640]   So during the pandemic, there was a wall, a retaining wall
[03:04:23.640 --> 03:04:25.640]   in one of the caves that was starting to crumble and I got
[03:04:25.640 --> 03:04:26.640]   permission to fix it.
[03:04:26.640 --> 03:04:29.640]   So they got me this apply so I could wall it back up.
[03:04:29.640 --> 03:04:32.640]   Wait, a retaining wall in the caves with the bones.
[03:04:32.640 --> 03:04:34.640]   Like Edgar Allen Poe the telltier heart.
[03:04:34.640 --> 03:04:35.640]   Yes.
[03:04:35.640 --> 03:04:36.640]   A trowel.
[03:04:36.640 --> 03:04:37.640]   A cask of a Monte auto.
[03:04:37.640 --> 03:04:39.640]   Which is exactly what I thought of.
[03:04:39.640 --> 03:04:45.640]   So I got a plastic skeleton and I put vestments on it and I walled it up.
[03:04:45.640 --> 03:04:48.640]   So a hundred years from now, some Jesuit's going to be going through
[03:04:48.640 --> 03:04:51.640]   that now crumbling wall and they're going to find a skeleton.
[03:04:51.640 --> 03:04:54.640]   And then they say, "What is it they were eating?
[03:04:54.640 --> 03:04:56.640]   That they had bones who were like a plastic."
[03:04:56.640 --> 03:05:00.640]   Yes, did you put a moon in its pocket?
[03:05:00.640 --> 03:05:01.640]   Oh, what is it?
[03:05:01.640 --> 03:05:02.640]   See?
[03:05:02.640 --> 03:05:03.640]   See?
[03:05:03.640 --> 03:05:04.640]   Oh, Sony Walkman.
[03:05:04.640 --> 03:05:08.640]   Something just really strange.
[03:05:08.640 --> 03:05:09.640]   Thank you all for being here.
[03:05:09.640 --> 03:05:10.640]   We love having you on.
[03:05:10.640 --> 03:05:14.640]   And thanks to all of our viewers and listeners, our Club Twit members.
[03:05:14.640 --> 03:05:16.640]   We really appreciate your watching the show.
[03:05:16.640 --> 03:05:19.640]   We do Twitch Sunday afternoons, 2 p.m. Pacific, 5 p.m. Eastern,
[03:05:19.640 --> 03:05:20.640]   2200 UTC.
[03:05:20.640 --> 03:05:22.640]   You can watch us do it live live.
[03:05:22.640 --> 03:05:23.640]   .twit.tv.
[03:05:23.640 --> 03:05:26.640]   Chat with us in the IRC or our Club Twit Discord.
[03:05:26.640 --> 03:05:29.640]   If you're not a member, 7 bucks a month, gets you ad free versions
[03:05:29.640 --> 03:05:31.640]   of all of our shows.
[03:05:31.640 --> 03:05:37.640]   To the Discord, access to the Twit Plus feed, it's so much fun.
[03:05:37.640 --> 03:05:41.640]   Where's the logo, Aunt?
[03:05:41.640 --> 03:05:46.640]   Aunt Pruitt is our Clubhouse community organizer.
[03:05:46.640 --> 03:05:51.640]   Next week, Inside Twit, Lisa and I will give you the Inside Story
[03:05:51.640 --> 03:05:52.640]   Club members only.
[03:05:52.640 --> 03:05:55.640]   Win two dows, fireside chat February 9th.
[03:05:55.640 --> 03:05:58.640]   And yes, I mentioned that interview we're going to do with the author of
[03:05:58.640 --> 03:06:01.640]   the Freedom TM as new book.
[03:06:01.640 --> 03:06:04.640]   Critical Mass comes out early February.
[03:06:04.640 --> 03:06:09.640]   Daniel Suarez will do a special club only interview on February 10th.
[03:06:09.640 --> 03:06:14.640]   7 bucks a month supports us, supports the work we do.
[03:06:14.640 --> 03:06:16.640]   Twit.tv/club.
[03:06:16.640 --> 03:06:18.640]   Twit, we thank you so much.
[03:06:18.640 --> 03:06:20.640]   We also appreciate if you take our survey.
[03:06:20.640 --> 03:06:22.640]   You only have a couple of weeks left to do that.
[03:06:22.640 --> 03:06:25.640]   It helps us sell ads so we know a little more about you.
[03:06:25.640 --> 03:06:27.640]   We don't want to spy on you, so this is completely voluntary.
[03:06:27.640 --> 03:06:28.640]   And it's not personal.
[03:06:28.640 --> 03:06:31.640]   We don't keep track of your email or anything like that.
[03:06:31.640 --> 03:06:34.640]   But it helps us in aggregates say, well, we have this many men, this many women
[03:06:34.640 --> 03:06:36.640]   college educated, all that stuff.
[03:06:36.640 --> 03:06:39.640]   What kind of laptops they use, what kind of operating system.
[03:06:39.640 --> 03:06:42.640]   Twit.tv/survey23.
[03:06:42.640 --> 03:06:45.640]   It also helps us understand you better so we can develop more programming.
[03:06:45.640 --> 03:06:48.640]   That's right up your...
[03:06:48.640 --> 03:06:49.640]   That's it for this episode.
[03:06:49.640 --> 03:06:50.640]   We'll see you next time.
[03:06:50.640 --> 03:06:53.640]   Another Twit is in the can.
[03:06:53.640 --> 03:07:03.640]   (music)

