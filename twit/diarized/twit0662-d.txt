;FFMETADATA1
title=Scraped On the Back End
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=662
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100
Failed to align segment (" Lindsay's also here and Lindsay brought her daughter."): backtrack failed, resorting to original...
Failed to align segment (" 13."): no characters in this segment found in model dictionary, resorting to original...
Start time: 1.25
End time: 172.82
Speaker: SPEAKER_05
Transcript:  It's time for Twit this week in Tech.  Amy Webb is here, our futurist, Lindsay Turrentine, editor in chief at CNET, Jason Hiner, editor  chief at Tech Republic.  We are going to talk about a lot of very deep philosophical things.  China versus the US in artificial intelligence, Mark Zuckerberg versus Congress, and Waymo  versus the citizens of Mountain View.  It's all coming up next on Twit.  This is Twit.  Bandwidth for this week in Tech is provided by Cashfly at C-A-C-H-E-F-L-Y dot com.  This is Twit This Week in Tech.  Episode 662, recorded Sunday, April 15, 2018, scraped on the back end.  This Week in Tech is brought to you by Aptiv.  Aptiv produces audio-based workouts created by certified personal trainers available through  a mobile app.  Get 30% off new annual memberships when you visit aptiv, A-A-P-T-I-V dot com slash twit.  And by Molecule.  Molecule is the world's first molecular air purifier that reduces symptoms for allergy  and asthma sufferers.  Seventy-five dollars off your first order when you visit Molecule dot com, M-O-L-E-K-U-L-E  dot com and enter the promo code TWIT.  And by Rocket Mortgage by Quicken Loans.  Home plays a big role in your life.  That's why Quicken Loans created Rocket Mortgage.  It lets you apply simply and understand the entire mortgage process fully so you can be  confident you're getting the right mortgage for you.  Get started at RocketMortgage.com slash twit too.  And by Audible.  For a free audiobook with a 30-day free trial, go to audible dot com slash twit or text TWIT  to 500-500.  It's time for TWIT This Week in Tech, the show where we get together with the best tech  journalists in the business and talk about the week's tech news.  And this is a special TWIT because April 17th, 2005, the very first TWIT was recorded with  Patrick Norton, Kevin Rose, Robert Heron, David Prager.  And we are so this is as close as you get to our 13th anniversary episode.  And you know what?  We put together a panel of people I love and cupcakes.  So we won't eat the cupcakes yet.  They are here.  But as soon as I introduce you, you may dive in.  We'll start all the way over to my right with the author of Follow the Geeks, Tech Republic's  editor in chief, my good buddy, the guy who got me elected president of the internet.  Jason Heiner, thank you, Jason, for being here.  A pleasure.  Very glad to be here.

Start time: 172.84
End time: 178.88
Speaker: SPEAKER_04
Transcript:  What brings you out to this coast?  I got some meetings at work with many of the awesome people at CBS Interactive.

Start time: 179.08
End time: 182.38
Speaker: SPEAKER_05
Transcript:  People like maybe Lindsay Turntine, editor in chief at CNET.com perhaps.

Start time: 182.90
End time: 186.26
Speaker: SPEAKER_02
Transcript:  I hope I get to be in a meeting with you.  Is this an annual?

Start time: 187.05
End time: 189.36
Speaker: SPEAKER_04
Transcript:  Yeah, let's make sure we do.  Oh, aren't they cute?

Start time: 189.40
End time: 194.44
Speaker: SPEAKER_05
Transcript:  Let's do it.  Break it up, you two.  Is this an annual thing for CBS Interactive?

Start time: 194.56
End time: 199.44
Speaker: SPEAKER_04
Transcript:  Actually, so I'm here for RSA.  Oh, RSA.  I'm like a couple days at RSA and a couple days in the office.

Start time: 199.58
End time: 211.72
Speaker: SPEAKER_05
Transcript:  RSA is a big security conference.  It is.  Sorry.  Yeah.  Yeah.  It's so nice to see how grown up your daughter is.  She disappeared.  She's back there.  She's got her iPad.

Start time: 212.40
End time: 217.25
Speaker: SPEAKER_02
Transcript:  She's here to see the, I called it nerd Hollywood.  Nerd Hollywood.

Start time: 218.04
End time: 235.48
Speaker: SPEAKER_05
Transcript:  Not nearly as fun as real Hollywood, I can assure you.  Also another book author and a good friend, Amy Webb is here.  She is the founder of the Future Today Institute, the author of a book.  This is how I met Amy, talking about her book, The Signals Are Talking, why today's fringe  is tomorrow's mainstream.  Hello, Amy Webb.

Start time: 236.13
End time: 238.25
Speaker: SPEAKER_03
Transcript:  Hello.  Congrats on the anniversary.  That's so cool.

Start time: 239.56
End time: 249.08
Speaker: SPEAKER_05
Transcript:  Can you believe it?  Man.  I mean, this podcasting began, really began in earnest in 2004, late 2004.  We started in the spring of 2005.  You were really at the beginning of all of this.

Start time: 249.32
End time: 249.83
Speaker: SPEAKER_03
Transcript:  Yeah, it's amazing.

Start time: 251.16
End time: 268.72
Speaker: SPEAKER_05
Transcript:  If you told me then that in 13 years you'll still be doing this show, I would have just,  I would have killed myself.  I would have said, oh, I hope we have cupcakes, please.  We got red velvet.  I'm sorry, Amy.  We don't have any way of sending them at East, but we have got red velvet.  I'm going to try one.  Attach one to an email.

Start time: 269.06
End time: 299.58
Speaker: SPEAKER_04
Transcript:  I want to get the H.  I remember being here for the 10th anniversary while I was writing my book.  I came here for the 10th anniversary.  That's right.  And what do we have?  Cupcakes.  You did have cupcakes.  That's right.  Should cupcakes be crunchy?  10 seemed like so amazing that this thing was still going strong after 10 years.  Now, to be fair, most of the podcasts that were going strong back then are long since  history.  But this one is, seems like it just keeps getting stronger.

Start time: 300.04
End time: 305.11
Speaker: SPEAKER_05
Transcript:  We've survived long enough to live through podcast renaissance, which is going on right  now.

Start time: 305.84
End time: 310.21
Speaker: SPEAKER_02
Transcript:  Multiple.  Yeah.  Yeah.  It's kind of funny.

Start time: 311.30
End time: 323.62
Speaker: SPEAKER_05
Transcript:  Yeah.  Well, in a way, I feel like we're now such old hat that all the new podcasts get all  the attention.  Cereal and all the WNYC stuff and gimlet media and all that stuff.

Start time: 323.68
End time: 324.64
Speaker: SPEAKER_02
Transcript:  But they don't have cupcakes.

Start time: 325.75
End time: 330.52
Speaker: SPEAKER_05
Transcript:  They will in 13 years.  Please, be my guest.  Red velvet, vanilla, chocolate.  All right, I'm taking a vanilla one.

Start time: 331.16
End time: 332.54
Speaker: SPEAKER_02
Transcript:  I'm taking the exclamation point.

Start time: 332.88
End time: 343.47
Speaker: SPEAKER_05
Transcript:  And your daughter, by the way, can have one.  You want to come have a cupcake?  No?  Yeah.  Burke.  Burke's going to have one.  That's for sure.  Excellent.

Start time: 343.96
End time: 345.96
Speaker: SPEAKER_02
Transcript:  Can I reach you a cupcake, Jason?

Start time: 346.44
End time: 349.06
Speaker: SPEAKER_04
Transcript:  I'm vegan, so I doubt that you know.  Oh, these aren't vegan.

Start time: 349.24
End time: 383.91
Speaker: SPEAKER_05
Transcript:  Are they vegan cupcakes?  The red velvet has coffee in them.  That's almost vegan.  All right.  I didn't realize you were vegan.  Yeah.  You know, the funny thing on YouTube, I think it was Zainab Tufiki, you noticed this in  an editorial in the New York Times a couple of weeks ago, that there's just a natural  thing in the algorithm.  Really, one of the things we talk a lot about these days is algorithms and how algorithms  are driving technology in kind of a weird way.  But one of the things about YouTube's algorithms is no matter what you look at, it pushes you  something more extreme.  So if you go to look, she mentioned this, a vegetarian video, it'll suggest a vegan  video.

Start time: 385.29
End time: 387.88
Speaker: SPEAKER_04
Transcript:  If it's vegan, it'll suggest a raw vegan.

Start time: 388.04
End time: 428.73
Speaker: SPEAKER_05
Transcript:  Raw vegan.  Right.  And then nuts.  You want a little on nuts?  Yeah, water.  Water and carrots.  Water and air?  But there is something that it's not that the engineers are doing that.  It's not that any humans are thinking about that.  It's just that this is what algorithms do.  Their algorithms are tuned to improve engagement.  And over time, they get better thanks to machine learning and big data.  And what they learn is this is how you engage people.  You get more and more extreme.  But unfortunately, it's not just in dietary things.  It's also in political and on and on.  Is that something that you and your research kind of noticed in the past?  Or is this something new and unexpected?

Start time: 429.92
End time: 459.34
Speaker: SPEAKER_03
Transcript:  Well, I mean, it's new in the digital realm, but it's certainly not unexpected.  So from the digital realm, attention is currency, right?  The way that you would liken this is to what's going to compel somebody to keep, I guess,  spending and in this case, be their time.  At some point, you reach a certain threshold and you need more, right?  Which is why we see gradients of everything from porn to...  Yeah, porn gets more extreme, doesn't it?

Start time: 459.60
End time: 459.74
Speaker: SPEAKER_05
Transcript:  Yeah.

Start time: 460.64
End time: 463.98
Speaker: SPEAKER_03
Transcript:  Right.  So I mean, it's just like we cognitively, like we need...  Stimulus.

Start time: 464.86
End time: 479.04
Speaker: SPEAKER_05
Transcript:  Yeah, all the time.  Yeah, actually, the prime example of this is television, which started fairly innocently  to Morton Downey Jr. and more and more extreme realism and reality shows.

Start time: 479.08
End time: 482.56
Speaker: SPEAKER_02
Transcript:  Or staged extreme realism.  Staged.  I think we know that it has to get more extreme.

Start time: 482.58
End time: 520.08
Speaker: SPEAKER_05
Transcript:  I mean, newspapers tend to get more sensationalistic.  They don't have to.  When it doesn't happen, it doesn't happen in TV when you get somebody like CBS's Edward  R. Murrow, who said, no, we're going to be the Tiffany Network.  We're not going to go down that road.  Or somebody like the New York Times who said, we're not going to go down that road.  Let the National Enquirer go down that road.  But it doesn't seem in tech that there's anybody saying, no, let's be responsible.  Let's not maximize 100% for attention.  Let's be more responsible.  I think the pressure is going to be on for YouTube, now that people know that they're  doing this, and Facebook and all these others to draw the line at some point.  That's the problem.  They're not drawing the line.

Start time: 520.14
End time: 531.49
Speaker: SPEAKER_02
Transcript:  But is there also a user responsibility part of that?  I mean, there is this sort of, if you're offered a platter of less extreme and more extreme  options...  We have to stop picking the extreme ones.

Start time: 532.54
End time: 534.42
Speaker: SPEAKER_05
Transcript:  I don't think...  Do you think humans can do that?

Start time: 534.48
End time: 558.06
Speaker: SPEAKER_02
Transcript:  You know, my son, who's not in the audience, well, he said the other day, he's like, oh,  I know what clickbait is.  And I know, he said, I just considered a clickbait tax.  And so about once a week, I decided I'm just going to go in on clickbait.  Like I know what this is.  I know it's ridiculous.  But it's a tax.  I'm just going to click on it and pay the tax and enjoy it and then limit myself in  the future.  Which I thought was an interesting way to look at it.

Start time: 558.16
End time: 569.96
Speaker: SPEAKER_03
Transcript:  It's not that simple of a transaction, though, because on the one hand, you're clicking and  absorbing whatever the content is, but you're still being scraped on the back end.  All of these systems, the business model for all of them is surveillance.

Start time: 569.96
End time: 572.52
Speaker: SPEAKER_05
Transcript:  That sounds painful.  I don't want to be scraped on the back end.

Start time: 576.10
End time: 578.39
Speaker: SPEAKER_02
Transcript:  Very few people do, but that's kind of extreme.  Some people do.

Start time: 581.29
End time: 610.25
Speaker: SPEAKER_05
Transcript:  I'm sure.  If you watch Pat on the back end videos, you'll get scraped on the back end videos later.  I'm sorry, Amy.  I should not have derailed that.  I do this every time.  No, but here's the example.  Mark Zuckerberg testifying in Congress.  Some members of Congress had different agendas, but a number of them wanted to know about  the, what do they call them, the dark dossiers that Facebook gathers on people who aren't  even members.  They're getting scraped on the back end.

Start time: 612.74
End time: 634.60
Speaker: SPEAKER_04
Transcript:  The interesting thing is, chasing the clicks is kind of what we're getting at.  It's ruined blogging.  You could say, certainly.  There's a really good post on this, I think it was on Facebook by somebody who's been  in the industry a long time, been on the show many times, Lance Yulanov.  Love Lance.  Great guy.

Start time: 634.96
End time: 644.28
Speaker: SPEAKER_05
Transcript:  Lance is kind of a victim of this, isn't he?  Yes.  And Mashable is the poster child for chasing the clicks.

Start time: 644.91
End time: 678.67
Speaker: SPEAKER_04
Transcript:  Or it was.  It was.  And then what happened?  And what happened, right?  And so Lance wrote this great post, very kind of introspective about the fact that I got  really good at doing this.  And he was one of the best.  We used to joke and he would send, sometimes we would do some really good, at the height  of when this was going on, we would do something really good.  I think one time we did 20 things to do that will lose your geek card or something.  Got a zillion pages in traffic.  And I remember Lance sending me a message saying, I just went in and excoriated my team  for not thinking of this idea first.

Start time: 682.22
End time: 707.34
Speaker: SPEAKER_05
Transcript:  I understand why you feel like you have a responsibility to your staff and your owners  that you need to generate revenue, that this is what they brought you here for.  And even somebody like Lance, who was editor in chief at PC Magazine, who really has real  strong journalistic credentials, got sucked in by this.  And in fact, this is kind of what this mea culpa in medium that he wrote is.  Exiting media, pondering new rules for an old profession.

Start time: 707.98
End time: 744.73
Speaker: SPEAKER_04
Transcript:  And the thing is, Mashable is kind of the prime example, but it's not just Mashable,  right?  The thing is that you follow the clicks and eventually what you find, and a lot of places  are finding or having their comeuppance on this, is that you can't monetize that.  There's a great quote there where Lance goes to his editor and his editor is like, they're  about to put up a paywall.  And he goes to him and said, you got to stop.  And he's like, why?  And he said, because everything that we have, you can find anywhere else.  Content is free.

Start time: 745.64
End time: 760.64
Speaker: SPEAKER_02
Transcript:  And here's the thing.  It used to be before algorithms started to rule publishing that the simple way to get  more traffic was to write more content.  It's almost like dumbly simple, but actually sort of no longer.

Start time: 761.00
End time: 776.44
Speaker: SPEAKER_05
Transcript:  That's kind of demand media, right?  That was a whole generation a couple of years back of sites that were created around Google  searches.  Like you monetize the search for tortoiseshell belt buckles and you write a dumb, meaningless  article, but you know you'll get traffic because people search for that.

Start time: 776.48
End time: 799.76
Speaker: SPEAKER_02
Transcript:  It's like WikiHow or any of the big how-to engines, which kind of got shut down algorithmically.  But here's the interesting thing to me.  I think that algorithms are very good at understanding what people want for a little while, but people  are the smartest algorithm and we start to burn out.  We all know exactly what a clickbait headline sounds like.  And we now are starting to get bored and move on.

Start time: 799.80
End time: 802.66
Speaker: SPEAKER_05
Transcript:  That's what hit Facebook.  That's why Facebook deprecated the publishers, right?

Start time: 803.10
End time: 810.94
Speaker: SPEAKER_03
Transcript:  I think it depends on how you define the we.  I mean, we, right?  We may understand what a clickbait headline is, but I mean.

Start time: 811.72
End time: 813.78
Speaker: SPEAKER_05
Transcript:  Well ultimately it only matters if traffic goes down.

Start time: 813.96
End time: 817.70
Speaker: SPEAKER_02
Transcript:  But I think the larger we is starting to understand what that looks like.

Start time: 818.28
End time: 831.50
Speaker: SPEAKER_03
Transcript:  The larger we totally got duped by fake news on Facebook.  So I'm not a big, you know, like, I don't know if I'll give a lot of credence to the  we here.  I think that the algorithms are much more powerful than we give them credit for.

Start time: 833.08
End time: 859.74
Speaker: SPEAKER_05
Transcript:  I don't know.  I think maybe you're right.  It worked.  But maybe we won't get fooled again.  Maybe now we go, oh, that didn't work.  I mean Mashable is gone effectively, right?  Facebook stopped deprecated link baiting.  And I think not because, I don't think Facebook did it altruistically because they want to  protect the.  Facebook does nothing altruistic.  No, they did it because it wasn't working anymore.  Right.  And I think it was trashing up the, it was polluting the stream.

Start time: 860.30
End time: 899.52
Speaker: SPEAKER_02
Transcript:  I actually don't give we credit and sort of I don't think that the larger we was is has  grown wiser necessarily.  I just think that humans are susceptible to trends.  We get bored very quickly.  We recognize trends very and then we move on to new ones.  And there's something else out there that is going to replace it.  And I think that there's a good reason people, if you spend much time on Facebook and have  continued to spend even before last week, Facebook's getting kind of dead.  It's just, it's just not that interesting anymore.  And I think people are starting to move on.  I mean, there's a reason that nobody under the age of 25 spends any time on Facebook.

Start time: 900.23
End time: 952.06
Speaker: SPEAKER_04
Transcript:  Yeah.  Yeah.  About five years ago.  So we sort of looked at this pretty hard because we were going, you know, we're like a smaller  niche player.  Right.  And so we're tech Republic.  Public.  Sorry.  Tech Republic is a smaller niche player.  ZDNet, the other site that I spend a lot of time on.  And we sort of got to this point where it's like, okay, we could go all in on like Lindsey  saying, like, get more, put more content out there and try to keep up with the rat race.  And what we decided at the time was to go in a different direction, was that our users  were just, we were, we don't want to produce more stuff.  Our conclusion was, and when we asked our users, we're pretty, we don't produce more  stuff that really doesn't have a lot of value.  So we did instead was really listen to what our users tell us, the stuff that we create  that gives, that brings them value.

Start time: 952.08
End time: 957.76
Speaker: SPEAKER_05
Transcript:  That's to me, responsible journalism.  But I gather, Amy, you don't feel like that's widespread.

Start time: 958.87
End time: 961.06
Speaker: SPEAKER_03
Transcript:  Well, no, I mean, I can tell you that trunk.

Start time: 961.74
End time: 962.84
Speaker: SPEAKER_05
Transcript:  Oh, God, trunk.

Start time: 963.28
End time: 1043.07
Speaker: SPEAKER_03
Transcript:  Lowercase trunk.  So under before Michael Farrow, who was the chairman left.  This was the old Chicago Tribune, right?  Right.  I'm originally from Chicago and I grew up with the Chicago, you know, like it was heartbreaking  watching this whole place get dismantled by somebody who had never worked inside of a  newsroom and quite frankly, knows very little about AI.  And the grand plan was that he had acquired over 100 AI patents that were going to be  used to automatically generate content because the business model was predicated on just  like barfing up a lot of news.  I remember the speech he gave to the troops.  Well, I'll tell you something.  I read every one of those patents and not only did basically none of them have any direct  applicability to anything that was happening at the Chicago Tribune, but any of the automation  that was being discussed, like it was better spelled out in Magic Leap.  You know, Amazon is already pretty far ahead.  Like everybody else was pretty far ahead.  But but in traditional media, I think there is still this idea that more like like creating  huge amounts of content automagically through the miracles and wonders of machine learning,  right, is somehow going to create enough traffic that that helps boost the numbers.  So you saw that at Tronk.

Start time: 1044.24
End time: 1047.28
Speaker: SPEAKER_05
Transcript:  I mean, so let me I got to show this because it's so crazy.

Start time: 1047.56
End time: 1048.62
Speaker: SPEAKER_03
Transcript:  That press release was insane.

Start time: 1048.70
End time: 1069.40
Speaker: SPEAKER_05
Transcript:  Well, let me just show you the Tronk video with Malcolm Cassell, who I know for you,  you've known for years.  This is the future of journalism.  See if you can identify any actual concrete ideas in this at all.

Start time: 1078.66
End time: 1088.50
Speaker: SPEAKER_00
Transcript:  We have great titles.  We produce tons of great content every single day.  We're really focused on how we deliver it to people in a way that they want to consume  it more and more.

Start time: 1088.64
End time: 1099.65
Speaker: SPEAKER_01
Transcript:  More and more.  The power of our journalism is to have a optimization group.  This Tronk team will work with all of the leaders of the world to make sure that we

Start time: 1102.64
End time: 1105.32
Speaker: SPEAKER_00
Transcript:  reach the biggest global audience possible.

Start time: 1117.56
End time: 1125.40
Speaker: SPEAKER_05
Transcript:  This is IOI.  We need to make our content really valuable to the broadest possible audience.  All right, that's enough of that.  Yeah, I can't take anymore.

Start time: 1125.56
End time: 1129.55
Speaker: SPEAKER_03
Transcript:  I'll tell you the opposite of that.  You know who's doing really well?  The information.

Start time: 1130.64
End time: 1133.29
Speaker: SPEAKER_05
Transcript:  I love the information.  Jessica Lesson is a genius.

Start time: 1133.92
End time: 1137.12
Speaker: SPEAKER_03
Transcript:  That's right.  And they're not trying to, you know, this is the opposite method, right?

Start time: 1137.26
End time: 1152.90
Speaker: SPEAKER_05
Transcript:  But this is that paywall.  They charge 400 bucks a year.  I pay it.  Yeah, I do.  They have some of the best journalists, right?  And they really focus not on link bait, but on really what you say.  They understand their users.  They're valuable content users.  Because you have to earn that 400 bucks.

Start time: 1153.74
End time: 1176.36
Speaker: SPEAKER_03
Transcript:  These big conglomerates, there was all this consolidation.  And so you have these huge like Tronk, you know, there are too many news organizations  within this big bubble and you just can't support all of them and they can't all be  the same thing to all people.  So the information, I think, is succeeding because it's not trying to be everything.  It's trying to do one thing exceptionally well.  And it does.  And so people are willing to pay for it and they're able to sustain that way.

Start time: 1176.46
End time: 1178.43
Speaker: SPEAKER_05
Transcript:  It doesn't feel like that's a model that can be used.

Start time: 1179.18
End time: 1204.44
Speaker: SPEAKER_02
Transcript:  It's a model that works for doing something specific.  And I think that Jessica is a genius also.  And she's really straightforward about what she's doing.  She has some real vision.  I'm really good at it.  And I think it's going to allow her to continue to do what she wants to do, which is pursue  serious journalism about the Valley with the caveat that that's probably never going to  extend beyond the Valley unless the same model gets applied to a different topic.

Start time: 1204.50
End time: 1227.39
Speaker: SPEAKER_05
Transcript:  It's kind of like what we do here.  We're not trying to get a mass audience, right?  She's not trying to get a mass audience.  But is there room for I mean, CNET is, Tech Republic is to some degree, I mean, you have  a focus.  Certainly CBS Interactive is.  There has to be room for mass media as well.  How does mass media, can it find its way without descending the link bait?  I think it has.

Start time: 1227.94
End time: 1247.54
Speaker: SPEAKER_02
Transcript:  I mean, if you look at what I mean, I'm obviously going to say this, but if you look at what  CBS Interactive has done, we have continued to serve an audience the content that they  want in a serious manner over time.  And that doesn't mean we don't expand.  We expand aggressively into lots of different parts of what that means.  We cover culture, we cover science.

Start time: 1247.68
End time: 1252.67
Speaker: SPEAKER_05
Transcript:  And you don't get pressure from CBS to drive numbers and stuff like that.  You must.

Start time: 1253.38
End time: 1271.95
Speaker: SPEAKER_02
Transcript:  We're always looking to grow, but we look to grow by pleasing a broad audience and talking  to them about what matters every single day and what matters to them.  The thing that is difficult is that what matters to them changes a lot.  People change, generations change.  We are constantly, constantly looking very closely.  We're looking at that now.  Oh, what's changing?

Start time: 1272.48
End time: 1301.86
Speaker: SPEAKER_05
Transcript:  Twitter is very different 13 years later.  And as a broadcaster, I always told broadcasters, don't chase the audience because it's chasing  your tail.  You can't.  So for me, and I guess for niche broadcasters or niche journalists like Jessica, having  a vision and pursuing that vision and hoping that what you're doing, being true to yourself,  true to that vision will generate enough revenue, enough of an audience that you can survive.  But it's very different from a mass marketer or a mass media enterprise, which really does  need to chase the audience, I guess.

Start time: 1301.88
End time: 1352.20
Speaker: SPEAKER_02
Transcript:  It needs to be nimble and understand what the audience wants.  And I think that there's, I think we fell down a rabbit hole where we started to think  as an industry.  And this is the Mashable topic that we're talking about, that we could tell the audience  what they wanted by almost beating them at their own game, right?  By using machines to tell us what they were going to want before they knew what they wanted.  And the reality is that everybody gets wise to that eventually and says, no, I'm interested  in something else now.  And circling all the way back to that Facebook issue that we were talking about a minute  ago, I noticed that somebody in the chat room said, I don't think Facebook is going away.  I have the same number of friends this week that I did last week.  But what I found is interesting is that, yeah, that's because people are just walking away.  They're wandering off somewhere else.  I actually removed the app from my phone.  Me too.  Yeah.  And my behavior radically changed within a week.

Start time: 1352.64
End time: 1353.37
Speaker: SPEAKER_05
Transcript:  So much happier.

Start time: 1353.64
End time: 1356.50
Speaker: SPEAKER_02
Transcript:  Right.  I can go back and find it on the desktop if I wanted to.

Start time: 1357.40
End time: 1359.65
Speaker: SPEAKER_03
Transcript:  Did everybody delete Instagram too?  No.

Start time: 1360.20
End time: 1363.07
Speaker: SPEAKER_02
Transcript:  And that's the thing.  I actually just switched right over to Instagram.  And I know.

Start time: 1363.74
End time: 1370.89
Speaker: SPEAKER_05
Transcript:  But Facebook's getting the same.  But they're not, Amy, they're not getting the same signals from Instagram that they  got from Facebook.  Not nearly the richness of information, are they?

Start time: 1372.52
End time: 1375.90
Speaker: SPEAKER_03
Transcript:  I don't.  Do any of us actually know for sure?  I am certain.

Start time: 1376.32
End time: 1386.25
Speaker: SPEAKER_02
Transcript:  I am certain that my day to day behavior, the things that I search for, the things that  I do online affects what shows up in my Instagram feed.  Sure.  I have to take Instagram.  Oh, yeah.

Start time: 1387.02
End time: 1392.78
Speaker: SPEAKER_05
Transcript:  Is three to four X.  I think any of the other social networks on ads.  Sure.  They're a click through.

Start time: 1393.02
End time: 1398.37
Speaker: SPEAKER_04
Transcript:  I don't presume that Instagram's not keeping a really close eye on what I'm doing.  I just that's where my friends are.

Start time: 1399.96
End time: 1409.94
Speaker: SPEAKER_02
Transcript:  They are not on Facebook.  Same.  It's very straightforward.  This is like so you do you guys use Snap?  No, not much.  But I'm not sure.  I'm not sure.

Start time: 1410.02
End time: 1412.31
Speaker: SPEAKER_03
Transcript:  I'm not sure.  I'm not sure.  I'm not sure.

Start time: 1413.47
End time: 1415.77
Speaker: SPEAKER_05
Transcript:  No, not much.  But I bet your daughter does.

Start time: 1417.51
End time: 1419.85
Speaker: SPEAKER_02
Transcript:  She's not allowed to.  You have the smartest daughter ever.

Start time: 1421.74
End time: 1423.64
Speaker: SPEAKER_05
Transcript:  My kids do, but they're, you know, they're in their 20s.

Start time: 1424.42
End time: 1429.36
Speaker: SPEAKER_04
Transcript:  This user thing is such a push pull thing because you obviously have to stay in tune.  What's wrong with Snap?

Start time: 1433.36
End time: 1475.87
Speaker: SPEAKER_03
Transcript:  Where should I start?  Oh, boy.  So, I think it was in 2016, 2014 or 2015.  Snap filed some very, very interesting patents.  I will see if I can pull them up.  But they had to do with a online advertising marketplace that used machine learning and  object recognition to automatically surface sellable things within a photo that others  could buy ads against.  And to me, they were also describing in this thing what that system would look like.  To me, that very, very much looked like the next generation of like auction based ads  for display.

Start time: 1476.70
End time: 1480.84
Speaker: SPEAKER_05
Transcript:  So, are you saying that Snap would look at things in your pictures?

Start time: 1481.63
End time: 1502.60
Speaker: SPEAKER_03
Transcript:  Yeah.  Yeah.  So, like you've got a bunch of cupcakes there.  They're going to start selling me cupcakes?  So yeah.  So, there may be filters that appear or instantly like stories like part of the feed where I'm  being targeted because or you're being targeted with something related to a cupcake or I'm  drinking cocheco.

Start time: 1502.72
End time: 1508.43
Speaker: SPEAKER_05
Transcript:  I've always suspected that the reason Amazon keeps trying to get cameras in my house is  that.  Right?

Start time: 1509.52
End time: 1560.68
Speaker: SPEAKER_02
Transcript:  You know, it's hard to note to what's driving the choices that Target makes.  But this is not just Instagram.  It's not just Snapchat.  I mean, I went on vacation to Hawaii last week, rented a Jeep.  I did it through Turo.  It's kind of like Airbnb for car rentals.  It was a great experience.  I know that I talked about Jeeps with my friends and on text and I was discussing it all the  time and taking pictures of the Jeep.  And now I am being advertised for Jeeps constantly in Twitter.  Yeah.  I mean, I wasn't, I don't think I actually tweeted about Jeeps.  I'm just saying that this is pervasive.  It's not all social.  I mean, it's not just Instagram.  It's not just Facebook.  It's all social media.  Well, in fact, I think there are a lot of companies saying, thank God, Mark is taking

Start time: 1560.76
End time: 1582.33
Speaker: SPEAKER_05
Transcript:  all the heat right now because we don't have to be, you know, we could just kind of, oh  yeah, that's too bad about that Facebook thing.  And I'm sure Google's number one on that list.  Here's a Zuckerberg.  I'm just going to play this.  This is risky, but I trust our chat room.  This is a Zuckerberg meme called smile.exe.  Let's see.

Start time: 1585.01
End time: 1587.97
Speaker: SPEAKER_00
Transcript:  See that guy over there?  That's a smile.

Start time: 1593.62
End time: 1594.33
Speaker: SPEAKER_05
Transcript:  Like the Terminator.

Start time: 1595.56
End time: 1597.68
Speaker: SPEAKER_06
Transcript:  He's trying out smiles.

Start time: 1603.14
End time: 1605.35
Speaker: SPEAKER_00
Transcript:  Maybe you could practice in front of a mirror or something.

Start time: 1608.99
End time: 1620.58
Speaker: SPEAKER_05
Transcript:  Okay.  I just had to watch that.  Zuck does have a somewhat robotic persona.  He's not exactly the poster boy for warm and fuzzy.  Although the stock went up after Zuck's testimony.

Start time: 1620.82
End time: 1629.74
Speaker: SPEAKER_02
Transcript:  He kept it so even keel.  It was impressive to me how able he was to just use the same answer over and over again,  apparently without shame.

Start time: 1630.04
End time: 1631.98
Speaker: SPEAKER_05
Transcript:  My team will get back to you on that, Senator.

Start time: 1632.18
End time: 1632.79
Speaker: SPEAKER_02
Transcript:  I don't know.

Start time: 1634.30
End time: 1643.42
Speaker: SPEAKER_04
Transcript:  I think there was a drinking game at Facebook on or maybe at Google on how many times he  said Senator or Congress man, Congresswoman.

Start time: 1644.16
End time: 1678.19
Speaker: SPEAKER_05
Transcript:  Here's a list of all of the things that Facebook's team will get back to.  I'm glad somebody was making a list.  There's quite a few.  Where are the Russians hiding?  If I delete my account, how long does Facebook keep my data?  Does Facebook delete the backups?  What apps did Facebook ban?  What about audits?  How many bots has Facebook taken down?  What regulations would Facebook collaborate with Congress on?  Does Facebook use cross device tracking?  Where do people affected live?  Who has the data that Cambridge Analytica has?  Who else has it?  What are you doing about Russian interference?  All of these.

Start time: 1679.78
End time: 1681.49
Speaker: SPEAKER_02
Transcript:  He knew the answers to most of those.

Start time: 1685.54
End time: 1693.94
Speaker: SPEAKER_05
Transcript:  So was it Congress that was at fault then?  Were the members of Congress who were at fault for not pursuing this?  Letting him off the hook, letting him say that?

Start time: 1694.34
End time: 1719.24
Speaker: SPEAKER_02
Transcript:  I think journalists spent a lot of time last week making fun of Congress people who didn't  understand how Facebook works.  I honestly think that the reason that happened is because Zach played it so cool.  He was so dispassionate and a little bit disingenuous about his answers that I think they didn't  even know.  There were people who wanted to make fun of somebody and turn to Congress.

Start time: 1720.26
End time: 1771.76
Speaker: SPEAKER_03
Transcript:  While everybody was busy playing on Twitter and making fun, legislation that Facebook  wrote went into effect or went up for a vote and looks like will go into effect in the  state of Maryland.  That all happened simultaneously.  Tell us about that.  What was that?  Right.  So if you'll remember, every big media outlet was touting their exclusive sit down with  Sheryl Sandberg and of course she was on a media tour.  Over and over again she talked about industry leading thoughts, industry leading ideas,  industry leading policies, which was all lobbyist code for regulation.  While she's doing this and days before Zuckerberg shows up on the hill, Facebook was meeting  with lawmakers in different states, one of them being Maryland.  I can find the link to this, but Facebook wrote the legislation.

Start time: 1772.56
End time: 1778.52
Speaker: SPEAKER_05
Transcript:  On the surface of this, this sounds like good legislation.  Plans to regulate political ads on Facebook.

Start time: 1779.69
End time: 1801.03
Speaker: SPEAKER_03
Transcript:  Right?  But they, so like nothing is, like everything that happened was Zuckerberg giving testimony  that was all for show.  That was all for show.  But, and so everybody was making fun of it and they were very distracted, but on the  back end, we were getting scraped on the back end.  We got scraped on the back end folks.

Start time: 1803.28
End time: 1819.32
Speaker: SPEAKER_05
Transcript:  So Will Castleberry, Facebook's vice president for state policy says, yeah, we helped draft  the Maryland legislation and we look forward to implementing it.  Now, that doesn't, that's not necessarily bad.  That means they want to get the heat off of them.  Maybe they found a way that they think will help.

Start time: 1819.36
End time: 1821.35
Speaker: SPEAKER_03
Transcript:  We believe, but Leo, look, go back.

Start time: 1822.32
End time: 1829.82
Speaker: SPEAKER_05
Transcript:  So this was the key thing.  We believe this bill will be a national model for the other 49 states to follow.  Avoiding, by the way, federal regulation, right?

Start time: 1830.46
End time: 1848.04
Speaker: SPEAKER_03
Transcript:  Right.  There's some regulation that gets started that takes all of the heat off of Zuckerberg  because technically nobody broke any laws.  So this is all about avoiding, this is all about showing up in public, keeping the share  price high and avoiding federal regulation.

Start time: 1848.92
End time: 1888.79
Speaker: SPEAKER_05
Transcript:  So part of the problem is that the laws that affect broadcasters about political ads that  they have to, for instance, reveal who bought the ad, don't apply to digital.  Right.  This is the federal laws, the Honest Ads Act.  Is Facebook supporting the Honest Ads Act?  I think they are or not.  This Maryland law looks a lot like the Honest Ads Act.  It says, this is an article from the Baltimore Sun.  It resembles legislation in Congress aimed at monitoring political advertising on social  media.  It would affect Google, by the way, as well as Facebook, New York, California, Connecticut,  also weighing their own measures.  We want to keep the platforms accountable.  I'm trying to find the part where it says what.

Start time: 1889.64
End time: 1972.48
Speaker: SPEAKER_04
Transcript:  Whether they are or not, they will have to.  Really what all of this is about at the end is that, and I know I've said this before  on the show, but there's three companies that know data better than anybody else and they're  eating the world, they're disrupting industries, and they are undermining the privacy of people  every single day more and more, right?  Facebook, Amazon, and Google.  They're doing it largely with a black box of data that they control and that data being  the new oil, they're using that to become three of the most powerful companies in the  history of humanity.  The transparency issue is a big part of the issue.  Facebook, the least transparent, Amazon somewhere in the middle, Google a little bit more transparent  of what they do with the data and all that.  All of these companies, you can bet over the coming years, are going to be under enormous  pressure to tell what data they're actually collecting, what they do with it, what it's  worth to them, and what they can do to actually empower people to better understand this and  take responsibility for it.

Start time: 1972.92
End time: 2021.60
Speaker: SPEAKER_02
Transcript:  It is so interesting.  I think what you said is such a great summary of what we're dealing with here.  The analogy of data as the new oil is a really compelling one.  What's fascinating about that is this is the first time probably in human history when  the oil, the diamonds, or the gold, or whatever it is, is actually us.  Yes.  We're being mined.  We're being mined.  We're being mined for our money.  It's basically an outgrowth of the advertising industry plus a lot more on top of that.  Shouldn't we at least know when we're being mined?  When we're offering up bits of ourselves to somebody who's going to then turn around and  sell to us.  It's almost like we're giving something away and then being asked to buy it back for purchases  that we make due to targeting.

Start time: 2021.62
End time: 2040.83
Speaker: SPEAKER_05
Transcript:  I have to say though that on the face of it, the idea that Facebook would work with Maryland  legislators to try to craft something that is both helpful and something that Facebook  could live with is not necessarily a bad thing.  That's how politics works, Amy, right?  You're trying to reach consensus.  Right, and it's not unprecedented.  Not at all.

Start time: 2041.56
End time: 2107.23
Speaker: SPEAKER_03
Transcript:  That is what lobbying is.  I think that my job is to collect data and to figure and to model it and to figure out  what all of it means and what the next order, risk, and opportunity is many, many years  into the future.  But one of the early signals that we look for are contradictions.  So to me, it was very, like these were some weak signals that I was paying attention to  over the past couple of weeks.  The fact that sort of quietly this legislation was being written, it potentially becomes  the model.  It eludes some regulatory challenges right around the same time that it becomes apparent  that our data is being continually mined, refined, and productized, but in ways that  we may not have thought through or intended.  All this sort of constellation of interesting facts and data over the past couple of weeks,  I think, points us in a direction that we should be concerned about.  But it's hard to be concerned and to really think through things when the spectacle is  so fascinating and fun.  I mean, it was fun to watch all of this happening, right?

Start time: 2108.28
End time: 2125.90
Speaker: SPEAKER_02
Transcript:  Was it fun for everybody though?  I mean, I think it was fun for us.  It looked like it was fun for Mark.  I think that most people, if you ask them, like, did you see what happened this week?  They'd be like, oh yeah, Mark Zuckerberg, he looks like data from Star Trek.  Yeah, yeah.  That's it.  That was it.  That's what we got out of that.  Mark Zuckerberg is boring.

Start time: 2126.00
End time: 2129.79
Speaker: SPEAKER_05
Transcript:  You think, Amy, that Mark walked away saying, yes, victory?

Start time: 2131.24
End time: 2192.30
Speaker: SPEAKER_03
Transcript:  I mean, I would have if I was him.  He escaped any serious questions.  Clearly, I mean, did you hear some of the questions?  I think it was Senator Orrin Hatch who was trying to suss out whether or not Facebook  and Twitter were kind of the same thing.  I think one of the questions, I might have him confused with Lindsey Graham, but somebody  asked the question, is Twitter the same as Facebook?  And it's like, it wasn't even rhetorical.  It wasn't. I mean, you know, so I mean, he escaped unscathed.  If he had come on, you know, if he had gone in front of people who wouldn't have had to  ask, you know, people were asking questions about like whether or not even if you log  out of Facebook, you're still being tracked.  It's a clear indication that they don't understand cookies.  Right. Yeah.  So like if he had actually faced people that that asked serious questions or if anybody  who was up there that didn't understand the tech could have and would have pressed on  the other sort of civil liberties piece of this, I think it would be different.

Start time: 2192.44
End time: 2235.56
Speaker: SPEAKER_05
Transcript:  I think the platform was designed not to even allow that chat if somebody wanted to.  And I observed this before it began.  I said, this is really just going to be a chance for a member of Congress to stand up,  say something that they can use in an ad later, because in the Senate, they got five  minutes in the House. They got four minutes.  There was no time for follow up.  Mark very cleverly used up the clock by doing longer answers, which many members of  Congress were at pains to interrupt trying to get their second question in.  Yeah. He even drank his water slowly.  Yeah. Whoever designed it, designed it with Facebook in mind, frankly, wasn't so I don't  know that I don't want to be I don't want to be Alex Jones here and a conspiracy

Start time: 2235.60
End time: 2240.60
Speaker: SPEAKER_04
Transcript:  theorist. But I don't think it's a conspiracy just to say that that, you know,

Start time: 2240.86
End time: 2244.48
Speaker: SPEAKER_05
Transcript:  there are in each other's pockets.  Well, they played the game.

Start time: 2244.64
End time: 2260.73
Speaker: SPEAKER_03
Transcript:  They literally relied on Facebook to get elected.  I mean, that was a good, you know, like how much money did each one of those?  There's a great story somewhere. Somebody.  They all got money from Mark and not just the tangible, not the obvious money, but every  one of them relied on Facebook to get elected.  Every one of them.

Start time: 2261.60
End time: 2319.90
Speaker: SPEAKER_05
Transcript:  That's a larger issue that probably isn't for us.  But there's the larger political issue.  We talked about this on Wednesday.  There's an economic theory that is called the Peltzman theory that there are three  constituents here. There's there's monopolies, big business, there's politicians and there's  users and they each have kind of differing goals.  The politicians want to get reelected.  The users want to pay less or, you know, in the case of Facebook where it's free, maybe,  I don't know, get spied on less.  And the big businesses want as minimal regulation as they can get to continue on with what they're  doing. And what happens is you get this kind of nice little feedback loop and everybody  gets kind of what they want.  Nobody is 100 percent happy.  But at the same time, we don't get any kind of the the voters really don't get any kind  of privacy protection or regulation of these companies because that's not what politicians  are looking for.  In fact, Facebook's very helpful to them.  They're not trying to shut down Facebook.

Start time: 2319.98
End time: 2385.04
Speaker: SPEAKER_02
Transcript:  No. And if there was somebody I wish I could remember who wrote this piece, but there was  a piece sort of documenting which politicians went up to Zuckerberg afterward and basically  fawned over him.  Yeah. We're so proud of what you started in your dorm room.  He's a kingmaker.  We can't this is this is the symbol of American success.  There was, I don't think, a lot of interest in actually angering or unsettling him outside  of that grandstanding.  Yeah, for sure.  But I think it would be interesting to talk for a second about whether or not people would  have the appetite to pay for a service like Facebook.  We were just talking about that.  They brought that up.  Journalism, they brought it up.  People have been bringing it up for the whole week.  Hey, what if we paid for it?  Do you need to change your business model?  Facebook.  And I think this is again, I keep coming back to this, but it's sort of a personal responsibility  thing.  I don't think that there's any actual appetite for paying for social media.  As soon as any service starts to bring up a fee, people freak out and walk away, which  is weird because we'll pay what like twelve, thirteen, fourteen dollars to go to the movies.  Yeah.  It's kind of confounding.

Start time: 2385.22
End time: 2396.28
Speaker: SPEAKER_04
Transcript:  As much time as people spend on it.  I mean, I agree completely.  I never thought people would pay for the information either, that it would survive more than a  year. But eventually.  Well, there's a key difference though.

Start time: 2396.42
End time: 2419.00
Speaker: SPEAKER_03
Transcript:  There have been plenty of studies.  The information was always a paid product.  Right.  The challenge is there's a cognitive bias.  Once it's free.  When something has been, when something was free and now you're being compelled for whatever  reason to pay, that feels like something is being taken away from us.  And historically speaking, regardless of what industry or field it is, we won't do it.

Start time: 2420.16
End time: 2438.54
Speaker: SPEAKER_04
Transcript:  It doesn't work sometimes.  Like think about with cell phones.  We completely destroyed the value of cell phones for about five or six years there.  And then eventually we got to the point where now we're paying, you know, whatever, forty  bucks a month or thirty bucks a month or, you know, having to buy one separately.

Start time: 2438.60
End time: 2442.36
Speaker: SPEAKER_03
Transcript:  But it was a different type of phone.  That the free you're talking about the free model.

Start time: 2443.12
End time: 2454.30
Speaker: SPEAKER_04
Transcript:  Right. Right.  Well, you know, when you used to be you get a free upgrade, you get, you know, you pay  two hundred dollars for your phone, which was really massively subsidized.  Now you're paying everybody's phones for free.

Start time: 2454.70
End time: 2488.60
Speaker: SPEAKER_03
Transcript:  You would get a free phone when I lived there, the early smartphones were free.  You just signed up for the service.  But once the truly smartphones hit.  So the not so like my the first smartphone that I had was an iMode from entity dog, which  was a totally different kind of phone.  Everything else was free.  But you had to pay for that.  You know, we've shifted over to the fancy models like the people pay for it because  there's never been an alternative.  There's never been a way not to pay for a brand new iPhone.

Start time: 2488.66
End time: 2507.14
Speaker: SPEAKER_02
Transcript:  There's also this sort of half paid model.  I mean, I live in Berkeley.  There's a regional news site called Berkley side, which I'm a huge fan of.  They've done a fantastic job creating a serious local publication that's on Internet only.  And it's first in the nation.  They just raised a million dollars from its readers in a direct public offering.

Start time: 2507.62
End time: 2512.01
Speaker: SPEAKER_05
Transcript:  Wow.  Interesting.  Small local news, high quality, totally free.

Start time: 2513.14
End time: 2526.74
Speaker: SPEAKER_02
Transcript:  That's still Berkeley.  There's something to be said, though, like you do a very good job and then you say, look,  it's kind of the NPR model to write like, please pay for this thing.  We're going to give it to you for free, but we're going to use guilt.

Start time: 2527.00
End time: 2529.72
Speaker: SPEAKER_04
Transcript:  Guilt works.  I mean, guilt absolutely works.

Start time: 2529.94
End time: 2558.44
Speaker: SPEAKER_05
Transcript:  It's not democratic, though.  I think it's fundamentally undemocratic.  And that's part of the problem I have is that news, especially I'm kind of the opinion  software, all software should be free, that the paid software model is a broken model.  And certainly social networks should all be free and news should be free.  You've got to find other ways to monetize it because it's undemocratic to say that only  people who can afford right news should be able to get the good news.  And the rest of you are going to get fake news and crappy news and link baiting news.  That's not right.

Start time: 2558.44
End time: 2576.66
Speaker: SPEAKER_04
Transcript:  And yet when freedom of the press started, like everybody had to pay to get that cheap.  You know, the broadsheet, right?  So one of the reasons we've never charged for it.  But one person bought it and then other people said they shared it, talked about it,  whatever, shared it around.  You know, so I think that it's kind of HBO model.

Start time: 2577.02
End time: 2582.26
Speaker: SPEAKER_02
Transcript:  Like, we know people steal it, but some of you are going to pay for it and it all works  out in the end.

Start time: 2582.86
End time: 2609.06
Speaker: SPEAKER_03
Transcript:  The LA Times accidentally ran a new business model experiment without their without even  realizing it.  A couple of weeks ago, their page loads times were like really, really slow and people  couldn't figure out what's going on.  And a friend of mine was taking was like poking around and somebody was using their site  to mine for bitcoins.  Oh, my God.  So they had been packed in a weird way.  But also maybe like a genius way to raise some cash.

Start time: 2609.14
End time: 2612.06
Speaker: SPEAKER_05
Transcript:  Yeah. Right. Just not for the LA Times, unfortunately.

Start time: 2613.06
End time: 2687.84
Speaker: SPEAKER_04
Transcript:  And to close the loop on the Facebook thing, I do think, you know, Facebook is primarily  over. And, you know, under 30, there's hardly any people, you know, that are actively  engaged on Facebook.  So what's next is the important question.  And for the hearings themselves, I think that you have to take what happened, not just  in the event itself, which was somewhat sad and disappointing and, you know, not what  it could have been or should have been.  But think of it as a first step or maybe second step, right, because they did call after  the election a few of these tech heads before the Congress to testify.  Again, it's about the scrutiny coming on to these folks about the way that they use  data. And while this wasn't ideal, it wasn't what it could have been or should have been.  It is a start. And you're going to increasingly in the coming years see more pressure on  them to be transparent.  And the Maryland legislation, I think, is another step in that direction.  They're going to be more transparent about what data they take, how they use it, how  much it's worth and then what they can do to give people control of their own

Start time: 2687.94
End time: 2711.00
Speaker: SPEAKER_02
Transcript:  data. And somebody in the chat room brought this up and maybe not exactly this way, but  also there's the possibility that a transparency here.  I'm going to sell your data to marketers.  You will see ads related to the things that you do on this platform.  If you would like to not receive these ads, it will cost you ten dollars to use a month  to use the platform.  I bet most people say fine.  I don't want to pay it. Yeah, I don't.

Start time: 2711.20
End time: 2744.64
Speaker: SPEAKER_05
Transcript:  I don't. Am I wrong?  I don't have a problem with Facebook using my information to sell ads.  That's not where the issue is.  The issue is more using my mood to take advantage of me to sell ads or selling my  information to a foreign government or using my information in kind of sleazier ways  than just straight up. You talked about Jeeps.  You should see Jeep ads. What would be wrong with that?  You're actually interested in Jeeps.  They're taking more data than what they're telling us.  The problem is they're taking more data and they're using it in ways that are kind of  not so nice.  And they're pushing the very same...

Start time: 2746.11
End time: 2773.92
Speaker: SPEAKER_03
Transcript:  We're talking about what's already happened.  You know, Facebook saying if at the end of all of this, the end result is we'll tell  you, you know, we'll give you the opportunity to opt out so that we won't use your data  to surface ads.  It's sort of like not that that sort of shields us from everything that's coming.  You know, the next social networks are going to be part of mixed reality, not text and  photo and video based social networks that we have right now.

Start time: 2774.06
End time: 3012.86
Speaker: SPEAKER_05
Transcript:  Now's the time that I get to work on social networks that don't rely on surveillance  capitalism to survive.  There must be some other way to create the next thing that doesn't require this kind  of skeezy invasion of privacy or is that not going to happen?  Tweetbook.  Tweetbook. I like it.  Let me take a little break.  I am so thrilled that you guys are here.  Great, smart people.  Amy Webb, the signals are talking.  The Future Today Institute.  Find out more at amywebb.io.  Lindsay Turrentine, editor in chief at CNET.  I mean, that's power.  That's power.  She is also at L. Turrentine on Twitter.  Yeah.  And of course, Jason Heiner from the Tech Republic and CBS, both CBS Interactive and  ZDNet.  Thank you all for being here.  I want to introduce a new sponsor, new not to this show, but not new to people who've  listened to me talk about this app for months because I love it.  It's the front page of my phone.  It's called Aptiv, A-A-P-T-I-V, and it is a trainer in your phone.  Aptiv is audio based workouts.  You put them in your ears created by certified personal trainers.  You get it on a mobile app.  I love the trainers.  There's a huge variety of trainers and a huge variety of training.  Everything from riding a bike, taking a walk, getting on a treadmill, lifting weights.  I have a medicine ball training I do on this thing.  I just love great music, really good trainers for all personalities.  I have a certain kind of trainer I like to use, somebody who kind of kicks my butt a  little bit and says, work a little bit harder, but maybe you don't want that.  There are more than 40 new classes every week in every kind of workout.  You know, if you've been getting on a stale climber, an elliptical, and just kind of doing  it for 20 minutes and not seeing a lot of results, what if you put a trainer in your  ear or on your speakers that said, okay, now I want you to step it up.  We're going to do some high intensity.  Now slow it down.  You can even get yoga and meditation in this.  Aptiv trainers guide you in a flexible audio format.  It is a great way to make fitness a lasting part of your routine and a lot less expensive  than hiring a, trust me, I know, than hiring a trainer or going to the gym.  Workouts for all fitness levels, beginning, intermediate, advanced, more than 2500 workouts.  You'll never get to the bottom of them.  And as I said, there's always new workouts, many more than you could ever take.  Every music genre, every difficulty, every duration.  And by the way, the Aptiv community is great.  And they're working on their fitness goals and they support you, you support them.  It's very affordable.  I got the year membership a couple of months ago, but you can start at $14.99 a month,  100 bucks for an annual membership.  And we've got a deal for you, 30% off.  So if you've been looking at Aptiv, you can try it for free and I would do that.  But $69.99, 30% off for a year of unlimited workouts.  Aptiv.com slash twit, A-A-P-T-I-V dot com slash twit.  I've been using this for several months now.  It is just a great, you know, as the weather turns and you can take walks, you can use  it to get out there and run.  They can walk you through a run or a walk.  Anything you could ever imagine.  And you never have to repeat.  You can always have a new workout every day.  Aptiv, I love it.  A-A-P-T-I-V dot com slash twit.  I was really pleased because I've been giving them free plugs for months.  I was really pleased when they said, hey, would you like to do an ad?  I said, yes, I'd be glad to.  We're talking, it feels like we've been talking about Facebook for the last three months.  It seems like also one of those conversations that doesn't have a logical end.  Like I don't know what to say, what you could even say.  We know we're not happy about it, but I don't think anything is ever going to change.

Start time: 3013.18
End time: 3017.28
Speaker: SPEAKER_04
Transcript:  So we just have to keep putting pressure on them, you know, to be more transparent.

Start time: 3017.36
End time: 3031.90
Speaker: SPEAKER_05
Transcript:  What about Twitter?  What about Google?  What about Amazon?  What about Microsoft?  Yeah.  Are they going to escape?  And by the way, there's more than 300 companies gathering information just like Facebook  that we don't even, you don't even know about.  Not to mention your internet service provider.

Start time: 3032.36
End time: 3036.90
Speaker: SPEAKER_04
Transcript:  Well, but they don't use it in the same way.  They're not smart.  And I mean, oh, no, I take, don't take that back.

Start time: 3037.34
End time: 3062.84
Speaker: SPEAKER_05
Transcript:  Comcast, Verizon, AT&T have all sold information that they gained from you using their services  to third parties.  They also, as we know, are a revolving door for the NSA and spy agencies.  They're glad to hand over all that information.  Thanks to a whistleblower, we know that the NSA had a room in San Francisco's AT&T headquarters  where they monitored everything on the internet and on the phone system.

Start time: 3063.02
End time: 3072.06
Speaker: SPEAKER_04
Transcript:  I mean, I'd be more worried about them if they had, you know, five to, you know, 10,000  engineers working on machine learning, but they don't.  That's true.

Start time: 3072.82
End time: 3075.16
Speaker: SPEAKER_05
Transcript:  Machine learning is a little scary because it's weaponizing this stuff.

Start time: 3075.56
End time: 3075.68
Speaker: SPEAKER_04
Transcript:  Yeah.

Start time: 3076.48
End time: 3079.36
Speaker: SPEAKER_05
Transcript:  And so who are you more afraid of government or industry business?

Start time: 3080.07
End time: 3095.88
Speaker: SPEAKER_04
Transcript:  Oh, 100%.  I mean, 100%.  They 100% both.  Well, yeah, that's true.  I'm scared.  I'm more, it's more, the commercial is more scary right now, especially because they have.

Start time: 3097.01
End time: 3102.46
Speaker: SPEAKER_05
Transcript:  See, I cannot use Facebook.  I don't have to use Facebook.  Right.  True.  I'm not moving out of the US.

Start time: 3102.54
End time: 3110.40
Speaker: SPEAKER_02
Transcript:  There are some people who really do have to use it though for their jobs or it is the  primary way that they communicate.  It's a free service.  A lot of people now use Messenger.

Start time: 3110.82
End time: 3117.72
Speaker: SPEAKER_05
Transcript:  Siva Vajanathan said that it's white privilege that allows us to quit Facebook.  It's some kind of privilege.  That might be going a little far, but.

Start time: 3118.42
End time: 3206.40
Speaker: SPEAKER_03
Transcript:  There are plenty of places around the world where for various reasons, you know, like  press is being undermined.  It's not free.  So Facebook is the one way that they're able to publish, you know, certain news.  But here's what I, so there are legitimate reasons why in some cases it works.  But here's what I would say.  Our entire future, if we are entering the third era of computing, and by the way, this  is my entire next book is, which is coming out.  The first one is all about this.  So we're entering the third era of computing.  Let's give us some background.  What are the first two?  So the first was tabulation and the second was programmable systems.  So the third era is AI, which has been in some form of development for the past 150  years.  So the challenge is that as we now move from, you know, artificial narrow intelligence into  what comes next, all of the primary research and work that's being done is all being done  in the commercial sector.  And so I, in the book, identify the big nine.  There are nine big companies that basically control our future on Earth and any other  planet and place that we may venture to.  Three of those companies are in China.  That's Tencent, Baidu and Alibaba.  And the other six are here in the United States.  Google and Amazon are the primary ones that matter, followed by Microsoft, Facebook, IBM  and to a far lesser degree, Apple.

Start time: 3207.03
End time: 3210.94
Speaker: SPEAKER_02
Transcript:  And what about Tesla?  Seriously?  And related?  Musk?

Start time: 3211.90
End time: 3222.24
Speaker: SPEAKER_03
Transcript:  Sure.  Tesla is not built.  Tesla doesn't have the, all of the primary and basic research that's being done is not  being done.  Tesla is not one of the primary.

Start time: 3222.80
End time: 3225.18
Speaker: SPEAKER_05
Transcript:  Way more more than Tesla, way more than Tesla.

Start time: 3226.18
End time: 3227.89
Speaker: SPEAKER_02
Transcript:  Here's the problem.

Start time: 3229.02
End time: 3242.78
Speaker: SPEAKER_03
Transcript:  The problem is that these companies have fiduciary responsibilities to their shareholders and  they are profit driven organizations.  And even in China, technically they're independent companies, but they are very much tied to  the Chinese government.

Start time: 3243.02
End time: 3282.30
Speaker: SPEAKER_05
Transcript:  Well, that's the thing that is, I'm very aware of is the fact that you could say Baidu and  Tencent, but especially as she consolidates power, there is a definite move towards, for  instance, putting communist party committees in these businesses requiring investment of  the Chinese government.  They're basically, this is an article from Bloomberg, it's an opinion piece, but basically  there's some evidence that they're effectively nationalizing the tech sector and they certainly  want to have a lot to say about artificial intelligence and they are using it against  their citizenry right now.

Start time: 3283.60
End time: 3377.04
Speaker: SPEAKER_03
Transcript:  That's right.  So just as an example, so there are two, SenseTime and Megvi are two enormous AI companies that  most people haven't heard of.  The former is now just got a $4.5 billion valuation last week, making it the most highly  valued AI tech startup in the entire world.  The AI ecosystem is predicated on data, on people.  And so the reason that people say data is the new oil is partially because like oil,  it has to be mined, refined and productized.  But if you think about it in terms of us, we are the data, we are creating the data,  then who's in charge of the largest natural resource going forward on earth?  It's China with 1.4 billion people and totally different ideas and restrictions around how  their data is used.  So the needs and desires of these companies often run counter to the needs and desires  and hopes of a democracy, not just in China, but in the United States.  And so my argument is that we ought to change the developmental direction and track that  AI is currently on.  But that's going to force us all to make a lot of really difficult and possibly uncomfortable  decisions.  But if we wait 20 years, we're going to find that life is going to look really strange  in ways that we don't like.  And we have some agency and say in changing that developmental track now, we just have  to decide we want a different future for ourselves.

Start time: 3377.40
End time: 3412.36
Speaker: SPEAKER_02
Transcript:  I would argue that life looks really strange in ways we don't like right now.  We're just waking up to it.  I just kind of get up every morning and go, what is this?  This is so weird.  The other thing that I think needs to be mentioned, I think all of those points are so germane  and smart.  However, despite the size of the Chinese population, that value is only as good as the wealth held  by the people who generate the data.  Because presumably, the data is used to manipulate the way that we distribute our own wealth.  That's why the data matters so much.

Start time: 3412.42
End time: 3412.99
Speaker: SPEAKER_05
Transcript:  The stuff we buy.

Start time: 3413.54
End time: 3420.70
Speaker: SPEAKER_02
Transcript:  And in some cases, right, our choices and that's why we're here talking about it because  of the elections.  There's also political power.

Start time: 3421.16
End time: 3442.54
Speaker: SPEAKER_05
Transcript:  In China, they're absolutely using this.  They have the social score and they're keeping you from buying houses, taking trains.  The social score is so crazy.  Amy, you're an expert on Asian cultural differences.  That's a cultural difference that seems something that would be very hard to do here in the  States but seems to be becoming rampant in China.

Start time: 3443.42
End time: 3485.28
Speaker: SPEAKER_03
Transcript:  This is why you have to connect the broader dots.  All of this facial and posture, I mean, face recognition is interesting but they're the  world leaders in posture recognition.  So it turns out everybody has a unique face print.  We have unique fingerprints but we also have unique face prints because the capillaries  beneath our skin are all slightly different, right?  We also have unique voice prints.  So not just the particular intonation of our and cadence, right, when we speak but all  of the other elements that go into our voices, they're also leading the field in voice print  recognition technology and also posture and gesture.  So, you know, you have to...

Start time: 3485.60
End time: 3490.26
Speaker: SPEAKER_05
Transcript:  Is all of this aimed at recognizing you with a camera?  So, yeah.  Even if you're facing the other way?

Start time: 3490.95
End time: 3553.58
Speaker: SPEAKER_03
Transcript:  That's right.  So, China, so if you look at all that, China has also been developing smart cameras which  are capable of identifying and locking onto somebody and then handing off...  You've seen this in the Bourne movies and on CSI but this is a real thing where the  cameras can lock onto somebody and follow them without a human in the loop, right?  So you're not supposed to jaywalk in China and if you do, that's frowned upon.  Well, now they've used all of this technology that I just described to identify you and  at intersections, they have electronic billboards and they will put your face up on the billboard  and say, you know, Mr. Wang just, you know, Jay walked across the street.  Here's where he works.  Here's, you know, here's his job.  They'll broadcast it out on Weibo, which is the Chinese version of Facebook, and make  life generally pretty uncomfortable for that person.  So it's not just about commerce, I guess is what I'm getting at.

Start time: 3554.16
End time: 3567.84
Speaker: SPEAKER_05
Transcript:  Let me see if I can...  You can tell me if you agree with this, codify this a little bit.  There's what Lindsay was talking about, which is using this information to manipulate people  into participating in the economy more vigorously, spending more money.

Start time: 3568.52
End time: 3571.88
Speaker: SPEAKER_02
Transcript:  Or potentially things like elections and social choices.

Start time: 3572.52
End time: 3613.62
Speaker: SPEAKER_05
Transcript:  Making social choices.  And then there's what governments like to do, partly social choices, but mostly what  a government is really all about is maintaining order, to maintain the status quo.  Let's be honest, that's all government has ever really been about, whether it's a king  or a congress, is maintaining the social order so that the people who got it can keep it.  So, and both, you can have both of those, they're not mutually incompatible, as you  point out Lindsay, but from the point of view of an American citizen, they have very different  import and means.  Are there other ways, would you say, that this is being used besides social control  and for economic purposes?

Start time: 3614.02
End time: 3625.66
Speaker: SPEAKER_04
Transcript:  I think I would like to give a shout out to the mayor of Louisville who says that cities  and governments are a platform for human potential.  That's what they should be.  That's interesting.  I love that concept.

Start time: 3625.76
End time: 3638.34
Speaker: SPEAKER_05
Transcript:  They can foster the population to be more actualized, more efficient, more productive,  happier.  That is a great vision.  I love that.

Start time: 3638.52
End time: 3640.40
Speaker: SPEAKER_04
Transcript:  I love that.  So shout out to Great Fish.

Start time: 3641.02
End time: 3643.39
Speaker: SPEAKER_05
Transcript:  So it could go that way, or it could go the other way.  Yeah.

Start time: 3643.96
End time: 3699.87
Speaker: SPEAKER_03
Transcript:  Well, there is another piece of this, which is that, so if AI is the next era of computing,  everything else is layered on top of that.  So I would argue that AI is not the most important technology going forward.  The biology is the most important technology platform of the whole 21st century.  We're about to enter this whole genomic revolution, aren't we?  Right.  So that's why it's so important to look at all these different things and connect dots.  Smart cities, Dubai and Saudi Arabia, are both doing really interesting things to change  the electric grid and to send power in new ways and optimize so that they're off traditional  power sources.  But that plugs into AI as well.  So there's a vested interest in becoming the, you know, China's quickly becoming the global  hegemon, which would mean that we're all much more reliant on China, not just for direct  investment, but potentially for things like power or the soft robots that will live inside  of our bodies.

Start time: 3700.38
End time: 3712.76
Speaker: SPEAKER_05
Transcript:  And maybe this is a stereotype.  Correct me if I'm completely mistaken.  But my sense of Americans is we're rugged individualists.  This nation was born on the notion of I'm going my own way.  I'm going to believe what I want.

Start time: 3713.04
End time: 3718.84
Speaker: SPEAKER_04
Transcript:  You can put that billboard up on America.  Let me like, so what?  Don't tread on me.  I cross the street.  So yeah, so what?

Start time: 3719.24
End time: 3724.24
Speaker: SPEAKER_02
Transcript:  Well, I think that to be fair, that depends on who you are.  Rugged individualism, as long as you look like me.

Start time: 3724.62
End time: 3755.07
Speaker: SPEAKER_05
Transcript:  Yeah, well, no, but that's part of it, too.  We have to face it.  America is a country that was built on slavery.  And so there is a kind of an endemic history of racism in this country that we have to  own up to.  But absolutely.  But there is this fundamental notion of the individual and individual rights.  Whereas I is this a complete stereotype, Amy, but I feel like China, because of Confucianism,  particularly, which really promoted the notion of society being the greater good, the individual  is less important than society.  Is that correct?

Start time: 3755.74
End time: 3768.20
Speaker: SPEAKER_03
Transcript:  Well, that's that is very true in places like Japan and China and Korea.  However, you know, there's one point four billion people in China.  So not everybody's on the exact same page all the time about everything.

Start time: 3768.20
End time: 3791.72
Speaker: SPEAKER_05
Transcript:  Yeah. And not all Americans are rugged individualists.  However, I think that the kinds of things we're talking about are anathema to rugged  individualists and fit right into the worldview of a country where the society is is is paramount  to the individual.  I think the thing with China we have to think of to do we want to live in a society like  that.  That's what I want to know.

Start time: 3791.84
End time: 3850.62
Speaker: SPEAKER_04
Transcript:  I don't.  You know, China has this important work they're doing in A.I.  Much of it is anathema to the values that that we have in the West in terms of privacy  and expectations of data security, all of these things.  But we also have to remember that China is happy serving one point four billion people  today and the companies there and the society.  So they they they're happy having a certain myopic viewpoint.  Collectivism has been very powerful for them.  Yes. And that myopic viewpoint works for them.  But they will it will get to a point where it will they will even if they if it works  perfectly, which I think you still have, there are still a lot of people to Amy's point in  China who are dissenters to that point of view of about, you know, the government having  such control over everybody's lives.

Start time: 3850.94
End time: 3879.78
Speaker: SPEAKER_05
Transcript:  Is it moving to collectivism or individualism?  I mean.  And what will these technologies do to them?  Wow.  You know, I would I would submit that the the the genomics revolution might move us more  towards individualism, but that's going to really exacerbate the difference in the haves  and the have nots. If I can if I can with enough money, make sure my kids are smarter,  faster, better than your kids.  But that's happening in China.

Start time: 3880.00
End time: 3899.58
Speaker: SPEAKER_02
Transcript:  Problematic. That's happening in China.  I think that we're so it's like elective collectivism.  Oh, boy. And it's I mean, we get really wonky here, but I feel like there's a way in which  we are moving beyond the bounds of typical government government because we're starting  to build our own communities.  We need to save the planet.

Start time: 3899.86
End time: 3903.60
Speaker: SPEAKER_05
Transcript:  That may end up being so important that we have to abandon individualism.

Start time: 3903.70
End time: 3931.60
Speaker: SPEAKER_02
Transcript:  Well, and it could be that we take individual cultures, apply them across regional boundaries  and physical boundaries.  There's been a lot of sci fi about this, right?  Yeah. This idea that we start to form nations that have to do more with our  ideologies and our interests than they have to do with our governments.  And to a certain degree, social media is kind of allowing us to do that and to block out  the ideas and interests of anyone else physically around us, which I think is super weird.

Start time: 3931.62
End time: 3935.04
Speaker: SPEAKER_05
Transcript:  It's collectivism as long as we don't pay attention to our neighbors.

Start time: 3935.14
End time: 3976.50
Speaker: SPEAKER_04
Transcript:  I mean, the East and West are becoming more and more integrated, right?  So so the individualism and collectivism are going to meet and find a, you know, a balance  in there naturally just by the fact that the world itself is becoming so much smaller.  It's becoming so much more integrated.  It's becoming so so influenced by one another.  And that's where I was getting to with China is while China is doing certain things with  data today, eventually those companies are going to want to become global companies and  those standards and those ways of dealing with people and their users are not going to be  acceptable globally.

Start time: 3977.10
End time: 3981.82
Speaker: SPEAKER_03
Transcript:  Which which companies are you talking about?  Tencent, Alibaba and Baidu?  Yes, yes.  They are global companies.

Start time: 3982.10
End time: 3988.80
Speaker: SPEAKER_04
Transcript:  Well, they are.  But well, are they?  I mean, not in the same way that Google, Baidu is not global.

Start time: 3989.76
End time: 4025.96
Speaker: SPEAKER_03
Transcript:  Google is not by revenue, by numbers.  Absolutely not.  Those by revenue and by numbers, those three companies are, you know, Alibaba is Amazon.  But it doesn't have a presence in the West.  Do they need to have?  Well, OK, so so then the question has to do with how we are valuing these organizations.  Right.  If these organizations are making as much or more in revenue and if they have as much or more  influence over their designated population, then what does it matter that they're not in every  single country around the world?

Start time: 4026.14
End time: 4066.28
Speaker: SPEAKER_04
Transcript:  What I'm saying is eventually they'll want to be.  You know, when I was there and I talked to them, I asked this question across the board because  they have products, they have very compelling things they've done.  They are innovating very quickly in a number of ways.  And I asked them, you know, in each one and got a very similar answer.  The question of, you know, when are you going to bring this to Europe?  What are you going to do in, you know, in the US and North America?  And the question, the answer at each case was right now, we're really focused on on China  other than Huawei.  Huawei is is actually and they've been at this longer as a global company.

Start time: 4066.40
End time: 4073.16
Speaker: SPEAKER_05
Transcript:  Same thing, though, with with Amazon, right?  Amazon's really focused on the US and to somewhat less a little bit to Europe.

Start time: 4073.72
End time: 4087.76
Speaker: SPEAKER_02
Transcript:  But Alibaba wants to be here so badly.  And I'm sure Jeff Bezos would love to be in China.  And we'll figure it out.  I actually think it's more I personally think they're going to be more likely that Alibaba  will end up here than Amazon will end up in China for regulatory reasons.

Start time: 4088.44
End time: 4114.86
Speaker: SPEAKER_03
Transcript:  I don't know. I given the tension right now, I have a feeling that they'll get hit with  regulation because the US government will be concerned about IP bleed and our personal  data. I mean, it's it I would you know, I would say that we would have a national security  interest in allowing Alibaba to gain a foothold in the United States, that that that would  take some debate and discussion from a national security standpoint.

Start time: 4115.10
End time: 4157.18
Speaker: SPEAKER_05
Transcript:  It's really unfortunate because currently this will change, but we don't have an  administration right now that shows any clear long term vision.  And you could just as easily see President Trump saying, yes, screw Jeff Bezos.  Come on in, Alibaba.  I mean, it's it could go any it could go any it could go any way.  Who knows what's going to change entirely in three years.  But I can imagine also a time when we have almost a clash between the East and West,  where you've got these economic interests centered in in Asia and centered in the West.  And and they both want the other.  And and there's a there's a massive clash between them.  A new kind of economic warfare.  I think it's less likely because there's so much.  What do you think that's going to happen?

Start time: 4158.12
End time: 4224.96
Speaker: SPEAKER_03
Transcript:  Well, that that would be the thing that I would be concerned about.  And when I when Trump was going on and on egging on China, not only was that a stupid  economic like he was making stupid economic arguments, but, you know, just displayed  this culture, this deep cultural insensitivity.  You can't challenge a Chinese man to a duel and think he's not going to show up.  You know, like that's that's not the way it works.  So absolutely. The wars of the few that this is.  And I. I can't say what I was going to say, so I won't.  Regarding some of the work that I do, which is a secret secret.  But here's what I would say.  We think, you know, we're our reference point for war is always what we've always seen  in the past or what we've seen in movies.  It's hard for us to conceive of something as being realistic or plausible when we've  never seen it before.  My models and my work would show that the wars that we're potentially headed to in the  future have different contours and aspects of them that are more economic in nature,  but could be, you know, very disastrous.

Start time: 4225.76
End time: 4237.70
Speaker: SPEAKER_05
Transcript:  There is, though, the argument to be made that free trade is is good for peace, that  when China relies on us for its economic well-being and we rely on China for our  economic well-being, they're much, much less likely to wage stability.

Start time: 4238.66
End time: 4301.18
Speaker: SPEAKER_04
Transcript:  That's right. That's right.  To be honest, you know, Trump standing up to China in trade is not not that he has  some good points because we let every country in the world dump cheap goods here and all  the other all of them are very strict about what goods they allow to go in.  So like we're all about free trade.  Everybody else is very circumspect about free trades, which means it's not really free  trade. The problem was, you know, you make the you know, you do the embargo to make a  point and then China's response was very measured.  It was like, look, we're not going to make a big deal about this.  You did 50. They follow international laws.  They're like, you know, you did 50 billion.  We're going to do 50 billion.  And then Trump comes back says, we're going to do 100 million.  And you just played into his hand.  He like, you look like the bad guy, you know, and now you made it even easier for you to  be the bad guy and everybody else, the rest of the world to say you're the you guys are  the ones that are.

Start time: 4301.26
End time: 4311.38
Speaker: SPEAKER_05
Transcript:  I hope that in the years to come, there'll be a little bit more of a rational back and  forth. I don't think right now we're in a rational period.  So I'm hoping that at some point, we're at the very beginning.

Start time: 4311.78
End time: 4326.38
Speaker: SPEAKER_03
Transcript:  I wonder if it's possible for us to return to rationality because we've already been  meant like sort of conditioned for craziness is, you know, can we go back in the other  direction? That's what we were talking about the very beginning.  I think so. It's a pendulum swing, right?

Start time: 4326.46
End time: 4327.54
Speaker: SPEAKER_04
Transcript:  Like you're the futurist.

Start time: 4327.60
End time: 4330.44
Speaker: SPEAKER_05
Transcript:  I hope you're wrong.  Society is always a pendulum.

Start time: 4331.10
End time: 4333.73
Speaker: SPEAKER_03
Transcript:  I was more just curious to see what you all think.  I don't know.

Start time: 4334.16
End time: 4342.52
Speaker: SPEAKER_04
Transcript:  Yes, it is absolutely possible because society is always a pendulum swing, right?  And because humans have this grass is always greener mentality.

Start time: 4342.58
End time: 4359.44
Speaker: SPEAKER_05
Transcript:  In fact, I would be I would go a step farther and to say that just as that there will be  a flight from irrationality, having experienced it will be the best lesson of all.  And then instead of conditioning us to irrationality, we will flee from it.  We will seek hyper rationality.

Start time: 4359.56
End time: 4380.73
Speaker: SPEAKER_02
Transcript:  I hope so. But I I am becoming convinced over time that humans we are simply irrational  because we're emotional creatures and that's being played to and that we may circle back  or we may be charmed by a leader who speaks more rationally because it seems like an  alternative. But that but the United States in which that happens may look completely  different.

Start time: 4381.02
End time: 4438.00
Speaker: SPEAKER_05
Transcript:  Sunday driver says we're in it.  We're in the cray cray zone and we're staying there.  Let's take a break.  I want to talk tech.  We've got we've got some tech stories.  I'm sure we do. We'll find them in just a second.  I love the deep philosophic stuff, though.  I really do. And when my favorite panel ever.  Well, I really love that.  I hope we're not turning people off because it is kind of amorphous.  But it is really I think these are the thoughts.  These are the things you might have to think about if you want to think about what our  future is to look like.  And if you're going to think about, well, what do we do about destructive social media?  You've got to think on that larger scale of what its impact is and what what is more  importantly, what is the world we want to live in?  Yes. And I guess that's what I was kind of bringing up is is is what is that world?  Is it the world of the rugged individualist?  Is it the world of collectivism?  Is there some third way?  What is the world we want to live in?  I don't know if we we have enough of that conversation, you know, in general in the  body politic.  I feel like that's an important conversation to have.

Start time: 4438.36
End time: 4457.32
Speaker: SPEAKER_02
Transcript:  I think it's hugely important.  And what I have noticed recently is that every once in a while coming back to the  original conversation about publishing every once in a while, somebody on the on the  CNET staff or seen it itself will tweet something or share something that is just  positive. Just like here's a great piece of news.

Start time: 4457.54
End time: 4461.78
Speaker: SPEAKER_05
Transcript:  Well, you don't have very much anymore to tell you how much appetite there is for that.

Start time: 4461.80
End time: 4471.92
Speaker: SPEAKER_02
Transcript:  Yeah, there's there's this like groundswell of excitement around something that is  positive. Get tired of that, too, though.  We we do. If it's Pollyanna is sure if it bleeds, it leads.

Start time: 4472.16
End time: 4474.16
Speaker: SPEAKER_05
Transcript:  But I think that there is a reminder for optimism.

Start time: 4475.12
End time: 4526.66
Speaker: SPEAKER_03
Transcript:  It's a good reminder, though, especially now when it feels like the world is crumbling and  life is just happening at us.  We forget that we all have the capability and the possibility and the skill set and the  tools to create the futures that we want.  The future doesn't just show up fully formed.  We are creating it in the present.  But we have to be willing to make some short term sacrifices for long term gain.  And that's the challenge. The challenge is that we tend to think in the now in the United  States and we think in the now and sort of short shrift ourselves in the future.  So, you know, I think it's a great idea for us all to be optimistic about the world that  we're creating. But then we have to put the wheels in motion to make that optimistic  future happen. Which is part of the problem.

Start time: 4526.98
End time: 4569.06
Speaker: SPEAKER_05
Transcript:  Is where I think we're living in the most affluent in general for not for everybody,  obviously, but in the most affluent times we've ever had that that most people, even  even relatively poor people, are living better than people have lived, you know, for  millennia. And maybe the thing to acknowledge is how good we have it right now.  Global poverty is an all time low.  Violence. Violence all time low.  This is this is the book I've been reading, The Better Angels of our better  angels of our better nature, angels of our better nature.  Bill Gates favorite book. Fascinating.  It really is. It's a it's a miraculous time we live in.  And so let's but let's not feel that way.

Start time: 4569.08
End time: 4584.62
Speaker: SPEAKER_04
Transcript:  It doesn't feel that way. We've got lots of unfinished work still.  And we're more conscious about it.  Right. We see it because we know what good looks like.  We're more conscious about the things that we see.  And we see a lot of unfinished work that we have to do as a country, as a people,  as a world.

Start time: 4584.64
End time: 4601.10
Speaker: SPEAKER_05
Transcript:  I think there's also a sense when you're when you're at the top.  That it looks like a long way down.  Sure. And that when things are going really well, then the most and most  predominant emotion is fear that you're going to lose it.

Start time: 4601.40
End time: 4619.14
Speaker: SPEAKER_02
Transcript:  Sure. And we also as humans respond to fear, that's why if it bleeds, it leads.  Right. Has always has been a truism for a long time.  But also, I think that we are so much more exposed through social media to what is going wrong,  even though we tend to personally give our rosiest visions of ourselves on social media.

Start time: 4619.30
End time: 4621.52
Speaker: SPEAKER_05
Transcript:  Just everybody's you know, my life is great.

Start time: 4621.76
End time: 4630.00
Speaker: SPEAKER_02
Transcript:  But we are also very eager to share what's happening that's wrong next to us.  Yeah. And we know when something bad happens to a friend.  We might know faster.

Start time: 4630.20
End time: 4635.68
Speaker: SPEAKER_05
Transcript:  Well, or even not friends, just any anything bad happening anywhere in the world.  We know it immediately.

Start time: 4636.08
End time: 4647.92
Speaker: SPEAKER_02
Transcript:  And sometimes they're very specific stories.  I don't want to say small because nothing is small when something tragic is happening to you.  But we learn about a lot of specific single stories that we might not have heard about before.

Start time: 4648.18
End time: 4658.46
Speaker: SPEAKER_04
Transcript:  In the future, you are in the past.  You would have never seen that. Right.  Right. You live in your village.  Conscious of you be aware of your bad things that were happening in small ways to people.  And who cares who's in the castle?

Start time: 4660.48
End time: 4675.24
Speaker: SPEAKER_05
Transcript:  You know, what does that mean to me?  You know, as long as they don't raise my taxes.  Amy Webb is here.  The future futurist her book, The Signals Are Talking.  And what's the new book going to be called?  When is it out? And when can I interview about it?  You about it?

Start time: 4676.04
End time: 4684.21
Speaker: SPEAKER_03
Transcript:  I'm not we were like on title revision number three, but it's a manifesto about the future of AI.  Written for everyday people out spring of 2019.

Start time: 4685.40
End time: 4694.04
Speaker: SPEAKER_05
Transcript:  This much. Oh, I have to wait a whole year.  This really is important.  I'm glad you're writing it.  Thanks. And it is a conversation we have a lot here on our.

Start time: 4694.12
End time: 4698.36
Speaker: SPEAKER_04
Transcript:  Absolutely. And it continue to have.  It's not going to get any.  It's not going to get any less important.

Start time: 4698.40
End time: 4932.40
Speaker: SPEAKER_05
Transcript:  No, Jason Hiner, he's the editor in chief of Tech Republic.  Lindsay Turrentine is also here from CNET.com, where she's editor in chief.  I got the editors in chief here.  Top brass.  Our show today brought to you by just take a take a smells good in here.  Smells a little bit like cupcakes, but it smells.  It smells good in here. That's because our air is pure.  We are breathing filtered air through molecule.  The world's first molecular air purifier.  We got our first molecule at home because Lisa was getting stuffed up  in headaches every morning from allergies.  We live out in the country. We got a molecule.  Headaches were gone.  In fact, I know it's real and not an imaginary thing because we had  we were away one night and we had a relative staying in our house.  He turned off the molecule. I don't know why.  We got home the next night. Lisa got a headache.  She said, what's wrong? Is the molecule broken?  It was turned off. We turn it on. She's better again.  It really works. Molecule is not a HEPA filter.  That HEPA filter technology you've heard about  has been used to clean your air since the 1940s.  There haven't been any major innovations since until now.  Molecules PECO technology.  It's photo electrochemical oxidation.  And it goes way beyond what a HEPA filter can do to capture and eliminate  not just allergens, but stuff a thousand times smaller  than what a HEPA filter can capture.  Mold, bacteria, viruses, VOCs, airborne chemicals.  We actually got one in here because of paint fumes  and then the smoke from the fires and then tar on the roof.  It was really this. There's no windows in this studio.  And this molecule has saved our lives.  Molecule makes it easier to cope with asthma and allergies.  Significantly reduces your symptoms.  One customer said after using a molecule in her home,  she was able to breathe through her nose for the first time in 15 years.  That was not Lisa, but it could have been.  Molecules technology funded by the EPA,  extensively tested by not only real people, but university laboratories  like the University of South Florida's Center for Biological Defense.  You can read all about this on the Molecule webpage.  The University of Minnesota's Particle Calibration Laboratory.  It's easy to use. It's beautiful.  It's kind of like the the Apple of air filters.  It's a solid aluminum shell and you can connect it to the Internet.  And when the filters get low, they'll automatically send you new filters.  I love that.  Although I have to say that doesn't happen.  It's not even monthly.  It happens every few months, depending, of course, on how dirty your air is.  But we've only changed filters once in about eight months, something like that.  Some users have said that the molecule is  is the one thing that's allowed them to breathe easy in their home.  It's great for offices where, you know, windows are sealed and you can't open  the windows. This fixes the sick, sick air in offices.  You don't have to use the Bluetooth or Wi-Fi if your privacy concerned or whatever.  You work just like a regular air freshener.  It's got a button on the top. You turn it on and so forth.  It has a silent mode. I really like that.  We use that in the bedroom so you don't even hear it.  It's whisper quiet.  But if you have a lot of air to clear, you can turn it on high.  You will love the molecule.  I want you to try it. We've got seventy five dollars off your first order.  If you go to Molecule.com, that's Molecule with a K.  M-O-L-E-K-U-L-E dot com and use the promo code twit.  Finally, technology has come to air purifiers.  This thing is so much better than anything you've ever tried before.  Molecule.com promo code twit.  And, you know, if you've got dangerous air in your house or your office,  this is a really good solution.  Molecule.com. Use the promo code twit at the checkout.  All right. Let's see here.  I don't have to admit, though, the molecule does not get rid of cupcake smell.

Start time: 4934.04
End time: 4937.38
Speaker: SPEAKER_06
Transcript:  And this is driving me crazy.  Oh, that's a good thing.  It smells so good.

Start time: 4937.74
End time: 4941.13
Speaker: SPEAKER_02
Transcript:  I don't know. Maybe it just knows.  Oh, it's so good. It knows.

Start time: 4942.02
End time: 4978.50
Speaker: SPEAKER_05
Transcript:  Why would you ever want to get rid of that?  It knows.  All right. I'm going to try to find something upbeat, something happy,  something something fun, an antidote.  And I can't.  I can't. I can't.  There's nothing.  The HomePod flop is the home part of flop.  It's not setting the world on fire.  The world of Mark Gurman, who's really got his finger on the pulse of Apple  news and Bloomberg technology, say inventory is piling up.  Low sales have pushed the company to cut orders with the company  that's manufacturing the HomePod.

Start time: 4979.66
End time: 4985.14
Speaker: SPEAKER_04
Transcript:  One ninety nine. It'll be dropped to one ninety nine pretty soon at one ninety nine.  It's a lot more interesting than at three.

Start time: 4985.42
End time: 4995.42
Speaker: SPEAKER_05
Transcript:  People thought maybe if people can go to the Apple store and listen to it,  sales will go up. It had really good preorders, which just fell off the cliff.  You know, I have one. I own one.

Start time: 4995.64
End time: 5004.84
Speaker: SPEAKER_02
Transcript:  I do, too. And, you know, I think for me, it I like it.  It works because I already was invested in Apple Music.  But I'm like, no one.

Start time: 5005.04
End time: 5006.10
Speaker: SPEAKER_05
Transcript:  It's the only. Yeah.

Start time: 5006.28
End time: 5011.42
Speaker: SPEAKER_03
Transcript:  You know, a really, really expensive way to listen to your overpriced Apple music.

Start time: 5012.74
End time: 5019.18
Speaker: SPEAKER_02
Transcript:  Thank you. That is all true.  However, I can corroborate.  It sounds great. It does sound really good.

Start time: 5019.32
End time: 5062.98
Speaker: SPEAKER_04
Transcript:  It sounds great. Although we cracked one open on Tech Republic,  which is also a CNET video.  So it's a yeah.  And, you know, we talked about comparing the products during that.  And, you know, better privacy because Apple's not very good at  AI, among other reasons.  But they also are committed to privacy.  Like, they're really smart about this.  They're like, look, we really stink at AI.  So let's just double down on privacy.  If we're going to be the company that's all about privacy, we're not going to,  you know, be the one that that takes advantage of your data to monetize you.  They weren't really doing that anyway.  But whatever, you know, give them some we'll give them some kudos.  But the product itself is it is a good product.  It just feels to me it's just it's too expensive.

Start time: 5063.14
End time: 5090.54
Speaker: SPEAKER_02
Transcript:  Well, I think and I think Apple tried to make it super luxury.  We're going to make this fantastic sounding thing.  It's going to have this luxury price like all.  I mean, this is an this is Apple to a T.  We're going to launch later than others with something that we are going to tell you.  And we really hope you believe is better.  We're just going to keep telling you that it's better.  But the reality is in this particular case, it's not better enough.  Better enough. And they better enough.  And Apple Music is the wedge.

Start time: 5090.92
End time: 5103.80
Speaker: SPEAKER_04
Transcript:  Yeah, they can't come in and pick off what they love to do.  They come in and pick off the most lucrative 10 percent of the market.  Right. And they're so good at it.  And they're the place where all the money is made.  They just come in and swoop that.  It's just not happening.

Start time: 5103.80
End time: 5115.36
Speaker: SPEAKER_02
Transcript:  Well, and that is the thing is that Sonos already did that.  That's true. Like if you go to the home of a wealthy person, the Bay Area,  they are full Sonos room to room to room.  And Sonos has its own problems as a business.

Start time: 5115.36
End time: 5150.28
Speaker: SPEAKER_03
Transcript:  I think the problem is that that the big tech companies didn't see this coming.  They didn't see Amazon's smart speaker coming and they didn't see it in a  meaningful way. So, you know,  Microsoft is still trying to get a smart speaker to market.  And they're, you know, they're late to market.  Apple was late to market.  And yes, you could say that that was their strategy.  There's always been their strategy.  But, you know, in this economy, it's you're going to have to provide some  seriously amazing value for a product that, you know, like Amazon,  you can now get like a sub fifty dollar.  Yeah. Version. Right.

Start time: 5150.52
End time: 5153.64
Speaker: SPEAKER_02
Transcript:  No, it sounds like it sounds terrible.  It does. I would say there are.

Start time: 5153.92
End time: 5161.84
Speaker: SPEAKER_05
Transcript:  Well, but you can also the Google Home Max, which most blind  testers say actually say sounds better than the HomePod, by the way.  It's a little more expensive.

Start time: 5162.06
End time: 5167.56
Speaker: SPEAKER_02
Transcript:  It's as big as this table.  It's like, and it depends on where you're sitting in the room.

Start time: 5167.74
End time: 5186.33
Speaker: SPEAKER_05
Transcript:  Well, that's part of the problem is that Apple does.  And this is actually I just read a really interesting article.  Apple designed a speaker that sounds good no matter where you sit.  It's the tweeters go all the way around and the subwoofer fires straight up.  That's fine in an environment where music is wallpaper.  But but if you're going to sit in front of speakers,  the Max actually sounds better.

Start time: 5187.00
End time: 5196.37
Speaker: SPEAKER_03
Transcript:  And the real question is, yeah, I mean, is the is the closed is Apple's  closed ecosystem model going to survive going forward?  Not for me. The reason.

Start time: 5197.20
End time: 5212.24
Speaker: SPEAKER_02
Transcript:  Well, I don't think it is for music and media.  I think that it has been too slow to all sorts of media.  And the same Apple's trying to make big moves when it comes to Hollywood,  when it comes to studio, it's late, it's well behind Netflix.  It's well behind established providers of content.  And that's where Apple's going to start to struggle.

Start time: 5212.56
End time: 5262.36
Speaker: SPEAKER_03
Transcript:  It's not just the content, though.  So are so all the modeling that I've done shows that 50 percent  of the interactions that people in the industrialized world have with machines  will be so doing their voice between now and the next five years from now.  So what that tells us is that, you know, this isn't like earth shattering news,  but we're moving into these zero based UIs where we're speaking to,  you know, talking is the new typing.  So talking is pretty high.  Sorry, go ahead. Go ahead.  Well, here's the argument that I'm laying out.  The speakers are just the beginning of this.  So having a speaker that connects to your phone to do certain things  is useful right now.  But the real question is, what does that ecosystem look like as it matures?  Because we could very well be heading into instead of are you a PC or a Mac?  You know, are you Amazon or that's right?  You know, probably not.

Start time: 5262.38
End time: 5280.40
Speaker: SPEAKER_05
Transcript:  Microsoft is recognizing that it's not about Windows versus Mac.  It's about cloud. It's about services.  It's about voice, the platform.  We're seeing a complete sea change in how and what technology,  how technology manifests in our home.  And I think, Amy, what you're talking about is ambient computing.

Start time: 5281.70
End time: 5305.76
Speaker: SPEAKER_03
Transcript:  Sure. I mean, I call it zero UI.  There's conversational, ambient, whatever you want.  But the fun, you know, speaking to and having  other adjacently related.  So like machine reading comprehension.  So Google this Ray Kurzweil at TED this week  debuted a new product.  You know, the Google search through books, have a conversation with books.  Wasn't that interesting?

Start time: 5305.88
End time: 5309.06
Speaker: SPEAKER_05
Transcript:  He said instead of searching for keywords, we're searching for ideas now.

Start time: 5309.42
End time: 5377.19
Speaker: SPEAKER_03
Transcript:  Right. Except that that's that's a that's an example of something called  machine reading comprehension, which within.  Yeah, it's that's not earth shattering brand new ideas or technology.  And in fact, Microsoft and Stanford were working on that a while ago.  But what's different here is that this allows us to have more of a conversation.  Right. So you're rather than getting a bunch of links returned,  machine reading comprehension, which is what that project is an example of,  allows us to have those those conversations with the devices.  So this just brings me back to the speakers.  So it's like, OK, great.  Apple has an expensive speaker that sounds really good playing music  in a particular circumstance.  But going forward, which, you know, as the ecosystem matures,  you know, Apple's going to have to do something besides make a cool  product that connects to your iPhone, that plays music pretty well,  given that its whole ecosystem is locked down and closed and everybody else.  You know, Amazon, you know, Amazon is inside of cars now.  Amazon is inside of banks.  You know, Amazon has this massive open platform.  Well, to be fair, serious inside of cars.  Yeah, yeah.

Start time: 5377.94
End time: 5412.06
Speaker: SPEAKER_02
Transcript:  That's no that's not that's not.  I don't think that most audiences understand the difference  that you're talking about.  And I mean, as a person who covers consumer technology day in and day out  and sees how consumers respond to things, Apple has a chance  with HomePod and any other AI,  as long as Apple can find the thing that people don't know they need to solve yet.  But look at, you know, Ness, like why did Ness beat all other connected thermostats?  They existed before. It wasn't a new thing.  They made it look good and they made it easy  and they identified that something needed to be fixed.  Now they've had problems since then.

Start time: 5412.12
End time: 5418.72
Speaker: SPEAKER_05
Transcript:  And because nobody wants to spend four hundred dollars on a thermostat  that didn't do significantly anything more better than the existing.

Start time: 5418.78
End time: 5422.48
Speaker: SPEAKER_02
Transcript:  If HomePod could solve a problem that we don't know, literally, it really solve it.

Start time: 5422.86
End time: 5424.12
Speaker: SPEAKER_05
Transcript:  Not just on the surface.

Start time: 5424.18
End time: 5430.08
Speaker: SPEAKER_04
Transcript:  Solve it. Sure. I do think that.  I just want to pick by the way, that's a big if that's a hard thing.

Start time: 5430.50
End time: 5448.44
Speaker: SPEAKER_05
Transcript:  It is a hard. Oh, I mean, I just think it can be done.  That's basically build a better mousetrap  and the world will be the path to your door.  Well, yeah, but that keeps happening.  Yeah, it keeps happening.  But also it also happens from unexpected.  It happens from unexpected quarters.  It's rarely the incumbent that comes up with the next thing. Right.

Start time: 5448.50
End time: 5476.50
Speaker: SPEAKER_04
Transcript:  It's always I want to talk about voice, though.  I want it for just a second and zero UI as Amy characterized it  and sort of ambient interface and all that,  because there's part of this that I feel like gets missed and gets overstated.  And that's I see a lot of these estimates, Amy, similar to like,  you know, 50 percent of all computing is going to be with,  you know, with your voice in the future.  And I take issue with that for a couple.

Start time: 5476.64
End time: 5483.42
Speaker: SPEAKER_03
Transcript:  I didn't say computing.  I said interactions with devices, which is not like the kind of computing  that you're doing with the laptop that you've got sitting in front of you.

Start time: 5484.10
End time: 5517.04
Speaker: SPEAKER_05
Transcript:  But this is why I prefer the term ambient, because what to me, what's happening.  And so you can see this is moving from the center to the edge,  computing, moving to the edge. Right.  And the idea that everything has some smarts and you interact with it  in a natural way, sometimes that's voice.  Sometimes it's tapping your ear.  Sometimes it's that the thermostat has intelligence.  And to me, that's why ambient computing is a better definition.  Certainly we will use speech, but it won't be.  It's not what we're talking about as the as like this is the future of computing.  The future of computing is is computing.  Those cupcakes will have processors in them.

Start time: 5517.04
End time: 5560.20
Speaker: SPEAKER_04
Transcript:  They'll have their own interface.  No. So that I like better because, you know, these things we naturally train  our users, right, because certain users that are new to computing  and there are still a lot of users that are still just on the on ramp. Right.  And some of those simpler interfaces appeal because it is a better on ramp.  But as those users become more sophisticated  and complex, they tend to become more what we think of today as like power users.  Right. And they don't want to use a voice interface.  They don't want to use the sort of the dumbed down interfaces.  They want to use the ones where they can be more efficient.

Start time: 5560.28
End time: 5592.50
Speaker: SPEAKER_05
Transcript:  Here's what I would say.  That is based on a out or what will soon be an outdated paradigm  that we have to adjust to the computer, that we have to adjust to the interface.  Yes. What I am hopeful for, we haven't gotten close to it yet,  but I'm hopeful for is an interface that adjusts to us and that we operate  at whatever, however we operate.  And this this would be critical for ambient computing to work.  We operate as we would.  And the technology is smart enough to respond to us appropriately.  We don't have to adjust ourselves.

Start time: 5592.56
End time: 5655.22
Speaker: SPEAKER_02
Transcript:  So last year I was interviewing Mark Spates, who's the head of product for Google.  And he works a lot on all the Google Home implementation,  all of their smart home, if you want to call it that work.  And he said exactly what you were saying, and then he thinks of the future  is all in anticipation of needs and preemption of those needs.  And it's not necessarily voice.  And the examples that he would give  and I don't remember the specifics, but really surrounded  what we expect to have happen in our home based on our patterns  and then have that happening without a lot of interaction from us,  simply through anticipating our needs.  So to take this all the way back to HomePod, if Apple were able  to create a HomePod that even though it cost three hundred fifty bucks,  when I walked in the front door said, you know, hey, Lindsey,  play your home started playing what I was listening to in the car  without me asking it to ask me if I wanted to keep the  relock the doors or keep them open, reminded me to do whatever it is  that I always forget to do when I get home.  That may be charming and useful enough to me.  And here's why I want it.

Start time: 5655.32
End time: 5681.84
Speaker: SPEAKER_05
Transcript:  Here's why it won't happen from Apple, because Apple is the king of the silo  and interoperability is exactly the opposite of what Apple is looking to do.  And so this that would only work if you had an Apple car  and an Apple music service, an Apple refrigerator and Apple.  And and so if that's going to work, it's going to more likely  come from somebody like Google. Absolutely.  That is more open to the idea of having everything work.  What is the name of the holding Apple back?  Oh, certainly.

Start time: 5682.02
End time: 5721.24
Speaker: SPEAKER_02
Transcript:  There's a name for this concept that organizations often  create products that look like the their organization.  So the old fashioned example of this is that you would  if the if the stereo on the dashboard seems totally isolated  and uninteroperable, if that a word with the rest of the car,  that's usually because a different department designed that there's  a totally different department within that auto manufacturer who designed that  and that the physical product ends up reflecting the organization's  organization. Where is that?  Where is that? I don't remember the name of it, but I'm going to Google  the heck out of it, just like Mark Zuckerberg.  It's interesting when I get out of here so I can share it with you.

Start time: 5721.30
End time: 5724.07
Speaker: SPEAKER_05
Transcript:  You should use the new Google Talk to Books.  Maybe it could help. Maybe.

Start time: 5724.52
End time: 5750.92
Speaker: SPEAKER_02
Transcript:  But it is a really interesting concept.  And I think that's what you're seeing happen with Apple  and what you're not seeing happening with Google.  That's very interesting.  Google has historically been very good at moving people around  within its organization over time.  That right. Like so you go into the Google HR organization  and end up doing content at YouTube and then you end up moving over  to a different part of Google because that's conscious.  And then Google ends up becoming less bifurcated as a result  because its organization is a little bit more organic.

Start time: 5751.58
End time: 5830.00
Speaker: SPEAKER_05
Transcript:  I think that's going to be a problem.  It's been it was a problem at Microsoft.  It's going to be a problem at Apple.  Is this kind of inward looking?  And you can even see it in the metaphor of Apple Spaceship Campus,  which is inward looking and is a barrier to the outside world  versus something like Amazon's downtown headquarters in Seattle,  which is integrated in with the city of Seattle and is part of Seattle.  There you know, I find that fascinating, this whole notion of a company  reproducing its own bias.  And yeah, I think that's really makes a lot of sense.  And it is it is something maybe that's really starting to harm Apple.  It's one of the reasons Siri hasn't really excelled.  This this talk to books thing.  See, what I feel like is that we're in baby steps mode  and that what we're seeing is slow.  You know, one of the reasons, for instance, that we don't like voice  assistance is we have to learn a peculiar syntax.  We have to learn how to ask them for what we want.  The same way you have to learn a command line.  Yeah. And it's not what it needs to do is artificial.  It needs to understand what we're saying.  It needs to be how nine thousand.  Well, that's a bad example, but it needs to.  It better not lock the pod door, but it needs to understand what we  it needs to intuit what we're looking for.  And I feel like this talk to books is interesting.  Did you think, Amy, that this was not that this was not compelling or

Start time: 5830.86
End time: 5857.59
Speaker: SPEAKER_03
Transcript:  well, I mean, Ray is compelling when he speaks, but the the project itself  is just an example of something called machine reading comprehension.  So right now, so so Google's gotten pretty good at semantic search.  You type in a search or you speak a search and it may or may not give you  the answer that you're looking for.  But that's different from asking a question like,  can I roller skate inside?  I don't know.

Start time: 5857.90
End time: 5880.96
Speaker: SPEAKER_05
Transcript:  Here, I've asked I've asked talk to books, which will triumph  collectivism or individualism?  And actually, yeah, I came up with some pretty good responses,  including Ayn Rand's Fountainhead, the Oxford Ham book  of Emotion, Social Cognition and Problem Solving.  Saving face in business and cultural differences in a globalizing world.

Start time: 5881.14
End time: 5913.65
Speaker: SPEAKER_02
Transcript:  Speaking of advanced giggling, before I forget, I found it.  Oh, good. It's called Conway's Law.  Oh, and I'll read it to you.  This is this is a law and is an adage named after computer programmer  Melvin Conway. I'm reading off of Wikipedia.  It was dubbed Conway's Law.  And states that organizations which design systems are constrained  to produce designs which are copies of communicate  of the communication structures of those organizations.  I love that. As an editor, I would say that those witches should have been vats.  But other than that, it's really interesting.

Start time: 5915.38
End time: 5916.17
Speaker: SPEAKER_03
Transcript:  That's really interesting.

Start time: 5916.82
End time: 5953.18
Speaker: SPEAKER_05
Transcript:  Well, it's probably a Britishism or something like that.  Isn't that really interesting?  I wonder if it holds true.  I mean, 1967.  I really wonder if it holds true.  Eric Raymond, who is, of course, well known among open source advocates,  restated Conway's Law in the New Hackers Dictionary.  He said the organization of the software and the organization  of the software team will be congruent.  The software team and the software itself will be congruent.  If you have four groups working on a compiler, you get a four pass compiler.

Start time: 5954.74
End time: 5961.10
Speaker: SPEAKER_03
Transcript:  But I think this is a really good argument for biodiversity.  Yes, diversity, diversity.

Start time: 5961.36
End time: 5962.20
Speaker: SPEAKER_05
Transcript:  Thank you. Yeah.

Start time: 5962.54
End time: 5983.24
Speaker: SPEAKER_03
Transcript:  I mean, honestly, unless you're only, you know,  and here's the mathematical explanation for that.  If you are only selling your product to like white dudes,  white dudes makes, you know, make up only a certain percentage  of the total population, which means that, you know,  you're you're you're addressable.  You're only addressing a tiny fraction of your addressable market.

Start time: 5983.26
End time: 6010.24
Speaker: SPEAKER_05
Transcript:  Although, as a white dude, I'm pretty happy about that.  That's why I love software so much.  It's the for us, buy us. Right.  FUBU. Here's here's Nigel Bevin, a usability expert.  His version of Conway's Law.  Organizations often produce websites with content and structure  that mirrors the internal concerns of the organization  rather than the needs of the users.  I think I don't know. That feels right to me.

Start time: 6010.56
End time: 6015.02
Speaker: SPEAKER_02
Transcript:  Yeah, there's something there feels right.  And in some personal experiences I've had, I say absolutely.

Start time: 6015.32
End time: 6017.16
Speaker: SPEAKER_05
Transcript:  That happens. It's completely unconscious.

Start time: 6017.30
End time: 6029.42
Speaker: SPEAKER_02
Transcript:  And sometimes you can look at and I love to use the dashboard example for this,  but you can look at a dashboard and be like, why on earth  does this knob exist over here when really it should be over here?  It's probably because that team was working over here.

Start time: 6029.88
End time: 6044.14
Speaker: SPEAKER_03
Transcript:  Yeah, there's a team for that knob.  They were over there. AirPods follow Conway's Law.  AirPods, I can guarantee I don't know who worked, who exactly was on that design  team, but I can guarantee I would feel very confident  that it was not a woman with curly hair, not a woman with long hair.

Start time: 6044.20
End time: 6050.30
Speaker: SPEAKER_05
Transcript:  Very good point.  You know, and there's one size fits all.  And my wife, who has smaller ear holes, she I can't wear AirPods.

Start time: 6050.34
End time: 6059.82
Speaker: SPEAKER_04
Transcript:  They're uncomfortable. Yeah, they don't fit.  They fall out of my ears.  The Apple earphones in general.  Most other if you have a small one for a lot of most other companies

Start time: 6059.84
End time: 6077.30
Speaker: SPEAKER_05
Transcript:  who make earbuds with the exception of Apple will give you multi sized.  Yeah. Yeah.  Rubber things.  And Apple's the only one, whether it's the iPhone, your your pods or the AirPods.  That's it. It better fit.  If it doesn't fit yet to see, you must get over it.

Start time: 6078.56
End time: 6089.20
Speaker: SPEAKER_03
Transcript:  I travel a lot for work, and so I'm seeing more and more people  walking around airports and walking around cities with these things in.  And they're all men.  I really haven't seen you wearing them yet.

Start time: 6089.52
End time: 6092.92
Speaker: SPEAKER_04
Transcript:  I've never seen a woman in the airport with AirPods.

Start time: 6092.92
End time: 6114.24
Speaker: SPEAKER_02
Transcript:  Oh, my gosh. I see it all the time. I'm sorry.  Yeah, because I am finding it.  I think they do fit me, but I just can't do it.  I guess it looks so bad.  And I realize that that's a bias that I'll probably get over time  because so many people are wearing them.  But I was actually in the airport last week, actively looking  and being like, look at all those ladies wearing AirPods.  So maybe it's shifting or I don't know.

Start time: 6114.66
End time: 6117.62
Speaker: SPEAKER_04
Transcript:  I'm going to look when I go to SFO, when I'm flying back, I will.

Start time: 6117.92
End time: 6140.56
Speaker: SPEAKER_05
Transcript:  It does feel like a pathology of a company, though, that can't see beyond.  It's actually been a problem in the computer industry since day one  that they say engineers design products they understood,  but that normal people didn't understand that they were really by engineers,  for engineers. And now it's by white male engineers.  You know, I think that that's I think outside of the gendered

Start time: 6141.20
End time: 6155.68
Speaker: SPEAKER_03
Transcript:  outside of the gender and diversity thing now, doesn't that sort of  I I don't know.  I keep finding it so interesting that in a lot of ways, our technology  has gotten more and more complicated and we have fewer and fewer user manuals.  You just sort of expected to understand how to use stuff.

Start time: 6155.72
End time: 6204.24
Speaker: SPEAKER_05
Transcript:  Yeah. I was talking about this on the radio show today because,  you know, on the on the radio show, I talked to normals  and they are in great pain.  It's not getting better.  You know, we always thought, oh, you know, it's the infancy of technology.  It'll get easier to use.  It'll be, you know, it's not getting better.  It's getting far worse.  And now people are struggling with trying to keep windows secure  over a network and they're adding Internet of Things devices  that are themselves insecure.  Their routers are misbehaving.  Nothing routers are the next frontier.  Your printer won't print routers.  You can't change the channel on your TV.  Nothing. It's it's a it's a it's a maze of complexity  that is not serving people at all.  I understand how people might just get fed up and so on.

Start time: 6204.28
End time: 6237.60
Speaker: SPEAKER_04
Transcript:  It's reminding us of this about China, though.  One one of the reasons that China does have a big advantage over  America in AI and other fields right now is they don't have  as much of a gender gap.  A model culture.  No, it's like they're they have they're close to 40 to almost all their companies  are close to 40 to 50 percent female.  All the big companies and their engineers.  That's interesting. And they're in leadership positions.  Yeah, really interesting leadership positions as well.

Start time: 6237.94
End time: 6244.94
Speaker: SPEAKER_03
Transcript:  Not as and they start young. Yeah.  Start young. There are schools popping up all over the country  where kids are like AI schools for kids.

Start time: 6245.08
End time: 6251.34
Speaker: SPEAKER_05
Transcript:  How do they do that?  Do they make a conscious effort?  Was it the communist math in math?

Start time: 6251.88
End time: 6266.00
Speaker: SPEAKER_04
Transcript:  That's right. Yeah.  The men and women compete are equally skilled.  There's no stigmas.  And it really starts with math.  So it was cultural and need needed for a workforce.

Start time: 6266.04
End time: 6269.64
Speaker: SPEAKER_02
Transcript:  I mean, the Chinese have and a huge workforce.

Start time: 6271.02
End time: 6313.50
Speaker: SPEAKER_04
Transcript:  So if you think about it in terms of, you know, in the US,  if we're maxed out with the amount of males, which may be that,  you know, can go into tech fields, right, we're not nearly maxed out  in our capacity and our available labor  of women to go into and hold those positions.  This is great. I had no idea.  And so because of that, and that's the best argument  that I've even been able to use on people who are real,  either threatened or skeptical about the gender gap in the US.  And I'm like, look, we're losing because we're not mobilizing enough women.  And so, of course, you know, it's fighting with one arm tied behind our back.

Start time: 6313.58
End time: 6314.72
Speaker: SPEAKER_05
Transcript:  Exactly. Right.

Start time: 6314.78
End time: 6353.74
Speaker: SPEAKER_03
Transcript:  And it's not just diversity for diversity's sake.  I mean, again, like this just this is an easy argument to make with numbers.  So you've got half the population.  So you're sort of plausible scenarios or either that that that  that half of the population is on the right side of the bell curve  towards the end, meaning that they are the most smart and the most capable,  which is statistically unlikely. Right.  Or the other alternative is that we've lopped off,  you know, a good chunk of our best and brightest.  And China has taken the attitude that, you know, gender sort of doesn't matter,  that they're just looking for the best and the brightest  and to push them as hard as they can to achieve global dominance.

Start time: 6355.54
End time: 6361.16
Speaker: SPEAKER_04
Transcript:  You know, I mean, it's an important note in the in the China US debate.  It's been an education.

Start time: 6361.22
End time: 6388.06
Speaker: SPEAKER_05
Transcript:  This is I got to say, I am sorry, but I have to interrupt.  We have to take a break.  Keep those goods, those brilliant thoughts coming.  We're not done yet.  But I did want to show you we made this little movie.  It's really cute.  I really wanted to show you from the week of things that we did this week  on Twitter, previously on Twitter.  Oh, I love that. Well, your foil cap.  It's my tin foil hat.  That's fantastic.  I'm a paranoid nut job.

Start time: 6388.48
End time: 6394.22
Speaker: SPEAKER_04
Transcript:  I don't think paranoid nut jobs admit that they're paranoid nut jobs.  So you're fine. You even paranoid have enemies.

Start time: 6394.84
End time: 6402.06
Speaker: SPEAKER_01
Transcript:  The new screensavers.  This is the ink display. Yes. Beautiful display.  It's about three quarters of an inch.  Is it can I call this a smart license plate?

Start time: 6402.28
End time: 6423.22
Speaker: SPEAKER_05
Transcript:  You can't calling server.  Yeah. Why is it? What's it doing?  It's it's going to change.  You've got the new sticker and you got the California background.  I think you're going to handle on the future.  I mean, I can really see that this at some point becomes kind of required,  right, for things like this.  This week in Google.  This is the it's the new doorbell from the Alphabet company.

Start time: 6423.34
End time: 6431.72
Speaker: SPEAKER_03
Transcript:  Nest. This is my family coming home right now.  Is that a balloon? That's a balloon.  It's my birthday.  Oh, I just spoiled their birthday.

Start time: 6432.70
End time: 6434.98
Speaker: SPEAKER_05
Transcript:  You don't have to tell me you invaded your privacy.

Start time: 6435.36
End time: 6436.74
Speaker: SPEAKER_06
Transcript:  Wait, did we see a cake? Hold on.

Start time: 6436.82
End time: 6439.74
Speaker: SPEAKER_05
Transcript:  No, stop looking. Stop. Stop.

Start time: 6440.66
End time: 6443.02
Speaker: SPEAKER_01
Transcript:  Tweet the happiest place on earth.

Start time: 6445.22
End time: 6452.62
Speaker: SPEAKER_05
Transcript:  Well, stolen. Yes.  How does it know?  Well, if you if it's detached from the vehicle, I like this.

Start time: 6455.60
End time: 6457.28
Speaker: SPEAKER_03
Transcript:  That's really cool. I didn't see that.

Start time: 6457.48
End time: 6458.41
Speaker: SPEAKER_05
Transcript:  Only in California.

Start time: 6459.20
End time: 6460.60
Speaker: SPEAKER_03
Transcript:  But are they legal? Are they being used?

Start time: 6460.72
End time: 6485.55
Speaker: SPEAKER_05
Transcript:  They're legal in California, Arizona.  Many states are looking at it.  There's actually a lot of good reason for the state to adopt it.  They're not cheap.  There are hundreds of dollars right now, but they make more of them.  It could do all sorts of interesting things.  They worked with California and the CH, the California Highway Patrol  to make sure it was, you know, compliant with everything the CHP needed.  It can actually put advertising, but not while you're driving,  only when you're legally parked.

Start time: 6486.18
End time: 6497.74
Speaker: SPEAKER_03
Transcript:  Oh, my gosh.  That's meant to be a replacement for your life.  Like, that's where it goes with your.  Yeah. So then you're just like.  So that's amazing.  But then also, like, you're being tracked at literally every night.  You're being tracked by your mobile and your car.

Start time: 6497.82
End time: 6498.86
Speaker: SPEAKER_05
Transcript:  Oh, yeah. It's got tracking.

Start time: 6499.00
End time: 6504.17
Speaker: SPEAKER_02
Transcript:  All I can think about is weather.  Like, what happens when I get wet?  What happens when I get hit?  No, it's IP67 waterproof.

Start time: 6506.02
End time: 6507.84
Speaker: SPEAKER_05
Transcript:  When it gets hit, well, it gets hit.  But so does your car.

Start time: 6507.94
End time: 6509.82
Speaker: SPEAKER_02
Transcript:  I mean, yeah, but bumpers are for bumping.

Start time: 6512.18
End time: 6515.84
Speaker: SPEAKER_04
Transcript:  When I was in when I was in Israel, car bumpers are not for bumping.

Start time: 6515.90
End time: 6526.29
Speaker: SPEAKER_05
Transcript:  I just want to say most times nowadays when it might be  you might have like a big rubber thing on your car.  But nowadays, cars collapse.  You hit you tap them. They go break.

Start time: 6527.44
End time: 6569.92
Speaker: SPEAKER_04
Transcript:  Yeah, it's true.  I had a bumper that broke lately.  I was in Israel last month, though, and they drive a bumper car.  They just did to do pin.  Every car has a pin in it.  So you not only I rented a car and they're like, here's your pin.  Which this is really interesting.  You know, the Israelis are so practical because they had a problem.  Problem with theft.  And so they were like, this is your pin for the car.  And they're like, you can't take that.  Just take just take your phone out and take a picture of it.  You know, and I'm like, OK.  And I take the pictures.  Yeah, when you get in the car, you got to enter the pin.  You got to enter that.  Yeah, you put it you put before you put the key in.  And then you have to enter the pin and then you can.  And then it lets you know.  Also, if you're drunk, it's hard.  And so that's true.  It does make it difficult.

Start time: 6569.94
End time: 6626.05
Speaker: SPEAKER_02
Transcript:  You know, it is really this is a little bit of a tangent,  but it's really hard to debug cars.  I drive I drive the Lexus CT200H, which is no longer made for a nice car,  which is very sad.  It's it's Lexus's baby junior hybrid tiny car.  It's built on the Prius drivetrain.  And I'm I'm leading you up to something, which is the key fob in my car  and my car and some combination of those things has this bug in which  everything's fine unless somebody who drives a Prius gets in my car with their key fob.  What? Yep.  And then, you know, and then my car thinks that my keys aren't there anymore.  It'll be like keys not in the car.  If my car engine is going, it will keep going.  If but if I haven't started my car yet, I actually have to make that person  take their key fob out of the car.  I need you to get out of the car.  Yeah, I need you to get out of the car.  So the Prius has priority.  The Prius apparently has priority.  And this is not I have a friend who has the same car.  And it happens to her car, too.

Start time: 6627.04
End time: 6629.88
Speaker: SPEAKER_05
Transcript:  So they've had her car as many years newer than mine.

Start time: 6630.00
End time: 6636.44
Speaker: SPEAKER_02
Transcript:  Wow. So Lexus has had this bug  for a long time and not fixed it.  It is super weird.  Of the Pious Prius.

Start time: 6636.86
End time: 6824.65
Speaker: SPEAKER_05
Transcript:  The Pious Prius.  Our show today brought to you by Rocket Mortgage from Quicken Loans.  When you buy a house, you have a choice.  You really do. You can go with the bank, which will treat it like, hey,  welcome back to the 19th century.  You've got to put on a tie, a nice dress, go into the bank, say, please, sir,  can I have some money?  He'll he'll look through it.  Really, it's Dickensian.  It looks like a sheaf of papers.  Well, I think you might qualify for this rate right here.  They'll give you a big stack of papers to fill out an application form.  You'll go back home. You'll have to go to the attic.  You'll have to find pay stubs.  You'll have to find bank statements.  You'll probably have to call your bank saying,  do you still have my bank statement from five years ago?  Do you? You'll have to find a fax machine  so that you can fax this stuff to Oliver Twist back at the office.  It's nuts. Or you can go with the future.  You can go with Quicken Loans, which is not only the biggest lender  in the country, they're the best number one in customer satisfaction.  Eight years in a row, according to JD Power and the most highly  technologically savvy.  Dan Harmon and his crew have always been.  I mean, they're really amazing.  They're revitalizing downtown Detroit.  Quicken Loans, amazing company.  And they realized that there was a better way because guess what?  Here in the 21st century, we have the Internet.  We have computers. So they created Rocket Mortgage.  You don't have to go to the bank.  No, you can do this on your phone. You whip out your phone.  Go to rocketmortgage.com slash twit to you don't even need a rocket mortgage app.  I like that. Just do it in your browser.  Rocketmortgage.com slash twit to answer a few simple questions.  You already know the answer to off the top of your head.  They go out because they have relationships with all the financial institutions.  They're Quicken Loans. They go out with your permission,  get the information they need, crunch the numbers,  and then based on income, assets and credit,  they will analyze all the loans for which you qualify for,  give you the choice.  You choose the rate, the term, the down payments completely transparent.  And you're approved. And all this took 10 minutes less.  Ten like you didn't even have to get up off the couch.  You could do this in an open house.  Rocketmortgage.com slash twit to the next time you're going to buy.  Or if you want to refi, they do refis to go to rocketmortgage.com slash twit to.  You'll apply simply. You'll understand fully.  You'll mortgage confidently.  Equal housing lender licensed in all 50 states and MLS consumer access dot org  number 30 30 book market rocketmortgage.com slash twit to, or you know what?  Even better, just go there and start the process so that you'll be ready.  If you go to open house tomorrow and you see something you like, boom,  you're minutes away from a home loan. You can show the realtor. It says here,  we're we're approved rocketmortgage.com slash twit to.  We thank them for their support of twit.  This is depressing. 80% of teenagers prefer iPhone to Android.  80% and by the way,  that's up from 78% last fall and 84% of teens say their  next phone will be an iPhone. 84%.

Start time: 6826.72
End time: 6843.68
Speaker: SPEAKER_03
Transcript:  I wonder if that has to do with their parents though, and not them, right?  Because there's hand-me-downs, right? So their first phone might've been a hand-me-down.  Right. So, you know, if they've,  if that's been their only experience and Apple's been so big in schools that  that they're more likely to encounter an iPad or an Apple product than a.

Start time: 6843.82
End time: 6851.24
Speaker: SPEAKER_02
Transcript:  I don't think that's true. Chromebooks are winning in schools by the way.  Chrome is huge in schools. Everywhere. Chromebooks, just Chromebooks.

Start time: 6851.48
End time: 6853.98
Speaker: SPEAKER_03
Transcript:  I think it depends on the school and the school system. No, no,

Start time: 6854.08
End time: 6855.52
Speaker: SPEAKER_02
Transcript:  actually stats bear this out. It is.

Start time: 6855.78
End time: 6863.54
Speaker: SPEAKER_04
Transcript:  Every class thing because every school district we go to are looking at Chromebooks.  A few, a few are looking at what those machines.

Start time: 6863.56
End time: 6866.18
Speaker: SPEAKER_05
Transcript:  Apple's education thing didn't change the landscape at all.

Start time: 6866.24
End time: 6901.98
Speaker: SPEAKER_04
Transcript:  No, I mean they're trying, but not yet.  So iPads do really well in like K through three.  Kids that are just coming in, right? Motor skills are an issue with keyboards  in those ages. Apps are often very customized  for those ages really well. But once they get into, you know,  elementary school, Chromebooks winning big time,  the only place that we see Apple making any headway is in private schools,  where in high schools they'll do Chromebooks up through eighth grade.  And then in high schools, they'll do Macs.

Start time: 6902.06
End time: 6906.12
Speaker: SPEAKER_05
Transcript:  To what do you attribute then this kind of complete dominance of Apple?

Start time: 6906.28
End time: 6912.18
Speaker: SPEAKER_02
Transcript:  I think that the hand me down issue is a huge one. I think you're right.  And I think hand me downs are a big part of it.

Start time: 6912.50
End time: 6918.20
Speaker: SPEAKER_05
Transcript:  So that would say that 80% of adults would be using iPhones too,  which I don't think is the case. I don't think so. But also,

Start time: 6919.74
End time: 6943.68
Speaker: SPEAKER_02
Transcript:  kids, peer pressure with friends, peer pressure, the cameras.  And I do think that there's I think kids say, oh, you're using a Samsung.  Ew. I don't know. I mean, again, this is parents always do this.  So I'm going to apologize and then do it. We always are like, well, my kid.  Right. And so my kid, she's sitting right there. So it's OK.  You're allowed. She may have taken a break.  But she left. She got bored with me.

Start time: 6943.86
End time: 6945.05
Speaker: SPEAKER_05
Transcript:  I said, I don't want to hear about it.

Start time: 6945.86
End time: 6977.33
Speaker: SPEAKER_02
Transcript:  No, my son is 14 and he has a little bit more agency over his own choice  and he has a pixel. Really? Good for him.  He's not 30 once. And he's like, I don't want those blue bubbles.  I don't want you to know when I'm typing.  That's very much him.  But I do think that the find my iPhone ubiquity is what has driven parents  to get iPhones for their kids, because even though there are apps  to do that on Android, it's easy to do.  It's easier to do it with a closed ecosystem of iPhones in your family  to know where your kids are and track them.  And I think parents love that.

Start time: 6978.82
End time: 6988.30
Speaker: SPEAKER_03
Transcript:  Wasn't there a study very recently that showed the decline of Apple among kids  is not seeing that as like a cool brand?  I'm trying to find it. Yes. And it's not true. Yeah.

Start time: 6988.96
End time: 6991.46
Speaker: SPEAKER_05
Transcript:  I think at least they're not putting their money where their brand is.

Start time: 6991.54
End time: 7021.56
Speaker: SPEAKER_04
Transcript:  You know, kids are more fashion conscious, especially at that age.  It's like the biggest thing that you one of the biggest things you think about  is what you look like and what you brands you wear and things like that.  And, you know, an iPhone is a brand that is just like fashion,  you know, in among kids.  Now, that said, those things change quickly.  And, you know, you have to expect that at some point, you know, brands  all run their life, have their life, you know, is there any chance

Start time: 7021.70
End time: 7029.30
Speaker: SPEAKER_05
Transcript:  the kids know that iPhones are more secure and more private and that they know?  No, no, no, no doubt.  No, no doubt.

Start time: 7029.50
End time: 7034.94
Speaker: SPEAKER_02
Transcript:  Also, you know what? I will I will.  Spoke in his parents, by the way.  Make the argument that they don't care.

Start time: 7035.24
End time: 7035.69
Speaker: SPEAKER_05
Transcript:  They don't care.

Start time: 7036.36
End time: 7045.28
Speaker: SPEAKER_02
Transcript:  I think that for a lot of the way, they don't care about their privacy.  Correct. That ship has sailed.  They don't they know they're like, yeah, I know that everybody's spying on me.

Start time: 7045.68
End time: 7056.04
Speaker: SPEAKER_03
Transcript:  I think they care deeply about their privacy from their parents.  I think they care deeply about privacy from certain clicks and kids at school.  But personal privacy, but talking about the kind of privacy

Start time: 7056.08
End time: 7062.04
Speaker: SPEAKER_02
Transcript:  we were discussing at the beginning of this show, right.  Data privacy.  I don't think they have any expectation of that.

Start time: 7064.20
End time: 7067.91
Speaker: SPEAKER_05
Transcript:  Dana Boyd.  Says it's complicated.

Start time: 7069.74
End time: 7071.48
Speaker: SPEAKER_02
Transcript:  It's never easy. It's interesting.

Start time: 7071.64
End time: 7094.12
Speaker: SPEAKER_05
Transcript:  She she makes it her business to study teenagers in privacy.  And you're right. You're both right.  She says teenagers understand how, you know, they aren't living privately.  But at the same and at the same time, they do many things to obfuscate.  You know, they they they don't use their real name on Facebook.

Start time: 7094.14
End time: 7098.64
Speaker: SPEAKER_02
Transcript:  They all have many different Instagram accounts and they only tell their parents  about one of them. Yeah. Yeah.

Start time: 7099.30
End time: 7111.56
Speaker: SPEAKER_05
Transcript:  So it's her.  I think her main point, I hope I'm not misstating it,  but I think her main point is that young people don't think about privacy  the same way as we think about privacy.

Start time: 7113.10
End time: 7117.98
Speaker: SPEAKER_03
Transcript:  Remember when a couple of months ago, Facebook was launching a product  for kids. Yeah.

Start time: 7118.58
End time: 7122.96
Speaker: SPEAKER_05
Transcript:  Facebook Messenger for the under 13 set.  Boy, I wonder what happened to that.

Start time: 7123.10
End time: 7128.11
Speaker: SPEAKER_02
Transcript:  That really is. They're not talking about it very much right now.  Yeah. We can't really get those.

Start time: 7128.82
End time: 7129.83
Speaker: SPEAKER_05
Transcript:  Get those kids. Yeah.

Start time: 7131.94
End time: 7140.96
Speaker: SPEAKER_03
Transcript:  It's just kind of amazing how quickly we live our lives these days, where,  you know, if you remember, that debate was raging on and on and on.  And it's like everybody's forgotten about it already.

Start time: 7142.16
End time: 7175.70
Speaker: SPEAKER_05
Transcript:  Boyd says, I've been overwhelmingly told kids these days don't care about privacy.  And yet when I wandered around talking to young people,  I found young people care deeply about privacy, even in an online environment.  But how they strive to achieve that privacy is sometimes puzzling to outsiders.  In other words, I think a lot of us look and say, well, you're using Snapchat nonstop.  What do you mean? What is the privacy?  They want privacy from authority figures, parents, teachers, social workers.  They don't need privacy with their peers.

Start time: 7177.18
End time: 7201.84
Speaker: SPEAKER_04
Transcript:  Well, the thing is, is this is very much the way it was,  you know, when previous generations, before there was social media,  you went to school and kind of what you did at school and said at school,  most of it kind of stayed there, right?  It was your sort of world. It was your kind of bubble.  And and there's there is a there's a little bit of a healthy part of that.  That is right. It's kids.

Start time: 7202.20
End time: 7203.90
Speaker: SPEAKER_02
Transcript:  Unless your parents are both teachers at your school.

Start time: 7204.00
End time: 7234.38
Speaker: SPEAKER_04
Transcript:  Well, that's rough.  That is rough.  If you know, kids have that little bit of space because it's part of them  developing their own identity, I develop being their own sense of self.  And in a social media world where everybody's aware of everything you're doing, right,  they do lose that.  And so you have to look at it in one sense of them recreating it in the world that we live in.  And that's a natural part of them establishing their own identity.

Start time: 7235.52
End time: 7271.33
Speaker: SPEAKER_05
Transcript:  I love this story.  Apple sent out a memo to employees saying, you know, you got to stop leaking information.  And in fact, last year we caught twenty nine leakers.  Twelve of them were arrested.  The memo said these people not only lose their jobs, they can face extreme difficulty  finding employment elsewhere.  I mean, this was a thinly veiled threat.  They pointed out that you could be prosecuted using federal laws against network intrusion.  You could face jail time, be convicted of a felony.  And of course, the memo was immediately leaked.

Start time: 7272.12
End time: 7286.86
Speaker: SPEAKER_03
Transcript:  What's the difference between like what I wonder what the line is?  And I don't know the answer to this, but what's the line between.  Whistleblowing, right, leaking and whistleblowing and like committing acts of corporate  espionage, we may find out.

Start time: 7287.14
End time: 7325.94
Speaker: SPEAKER_05
Transcript:  There's a Google employee who was dismissed because he released a memo that was a corporate  memo and he released it to the public.  It was caught.  I don't know. These companies are very smart about how they catch people.  And now he's suing, saying this is wrongful termination.  You are violating my free speech.  But I wonder how a court will react to that.  I don't think you have a right to free speech inside a company.  No, there's no there's corporate secrets.  But you raise a good point.  We also courts also have to protect the right of somebody to be a whistleblower, to

Start time: 7326.20
End time: 7346.90
Speaker: SPEAKER_02
Transcript:  release that. And it may come down.  You may be right. I think that's really an interesting question.  And it may come down to intent.  Why did you leak it?  Did you leak it because you just like being part of a rumor mill?  Did you leak it because you want to feel important or did you leak it because you think  that there's something seriously going wrong at the company where you are and you've  tried to deal with it internally?  Nobody has taken it seriously. So you go to the press.

Start time: 7348.02
End time: 7374.68
Speaker: SPEAKER_03
Transcript:  Is there any other moment in history when I feel like 2017,  2018 will partially be remembered as like the time we leaked?  Is that is there other times in history where it was like this prevalent?  The only thing I can't I can't think of any like other analogous times.  Are you talking about governmental leaks?  Are you talking about people just like people, which I guess is part of just being  alive in the age of social media?  Yeah, we just have better ways to leak.

Start time: 7375.06
End time: 7376.86
Speaker: SPEAKER_05
Transcript:  Yeah, we can leak all over the place.

Start time: 7380.00
End time: 7381.32
Speaker: SPEAKER_04
Transcript:  Unless you're getting scraped on the back end.

Start time: 7381.42
End time: 7414.68
Speaker: SPEAKER_05
Transcript:  Yeah. Well, you know, sometimes it's hard not to leak if you get scraped on the back end.  Here's in the Apple memo. I love this.  In many cases, in many cases, we understand, writes Apple, leakers don't set out to  leak. Instead, people who work for Apple are often targeted by press analysts.  I love this part.  Who prefer them on professional social networks like LinkedIn, Twitter and Facebook  and begin to pry for information.  Well, that may seem flattering to be approached.  It's important to remember you're getting played.

Start time: 7416.73
End time: 7418.64
Speaker: SPEAKER_02
Transcript:  I when I laughed out loud when I read this.

Start time: 7418.80
End time: 7433.48
Speaker: SPEAKER_05
Transcript:  Well, I have to think what's also funny is you could write this to members of the press,  analysts and bloggers who receive calls from Apple executives.  I just remember it might be flattering to get a call from an Apple executive, but  you're getting played.

Start time: 7434.10
End time: 7438.96
Speaker: SPEAKER_04
Transcript:  Oh, my. I read half that stuff on the news, those stories on the Wall Street Journal.  They're getting played.

Start time: 7440.94
End time: 7444.70
Speaker: SPEAKER_05
Transcript:  Apple leaks all the time, intentionally to the Wall Street Journal all the time.

Start time: 7445.12
End time: 7509.06
Speaker: SPEAKER_04
Transcript:  I think that's my conversation with the CEO.  You know, recently they were talking about how, you know, does Apple ever actually  leak anything to the press?  And I'm like, they are notorious.  I said, I'll give you an example.  If you remember when the Apple Watch was first coming out, there were all these crazy  analyst estimates. They're going to sell 30 billion or they're going to sell 30 million  in iPhones.  And I can't remember what year it was.  Twenty fifteen. Maybe it came out.  It was like, there's no way you looked at even like the numbers of Fitbits and other  things. And it was going to be a super set.  Right. It's a luxury version of that.  And it was like, there's no way.  And then all of a sudden, about, you know, a month before it was going to come out,  there was a there were some of the story in the Wall Street Journal about like Apple  reportedly internal has this internal memo that they only expect to sell 11 million or  something like that. I was like, they're they're leaking that because they want to  lower expectations so that they can define what success looks like.

Start time: 7509.20
End time: 7516.82
Speaker: SPEAKER_05
Transcript:  In fact, those of us who cover Apple pretty much can tell immediately from a Wall Street  Journal headline whether this is Apple's spin on it or this is something some digging

Start time: 7517.02
End time: 7532.80
Speaker: SPEAKER_02
Transcript:  that they've done. Yeah, I felt like that that and maybe part of the reason it was  leaked, that memo might have been who knows, it might have been intentionally leaked as  a leaked as a warning to anybody else and a barb and journalists.  And we want to control our message and you stop meddling with us.

Start time: 7532.86
End time: 7534.08
Speaker: SPEAKER_05
Transcript:  Are they playing me?

Start time: 7534.84
End time: 7537.24
Speaker: SPEAKER_02
Transcript:  And so that you can all see how seriously we take this.

Start time: 7537.42
End time: 7540.27
Speaker: SPEAKER_04
Transcript:  Twenty nine people.  Out of one hundred and twenty three thousand employees, by the way.

Start time: 7542.18
End time: 7545.72
Speaker: SPEAKER_05
Transcript:  Hey, twelve of them arrested.  The police came.

Start time: 7545.94
End time: 7562.02
Speaker: SPEAKER_02
Transcript:  I mean, it is true that Apple is really focused on controlling its supply chain.  Yeah. And what it says in that memo somewhere in that memo basically says, essentially,  if you leak what we're doing, then journalists get to say what we're doing instead of us  saying it better. Right.

Start time: 7562.68
End time: 7564.14
Speaker: SPEAKER_05
Transcript:  Yeah. And leave the leaking to us.

Start time: 7564.46
End time: 7566.92
Speaker: SPEAKER_02
Transcript:  You know, I mean, it is very important to them to control the message.

Start time: 7567.00
End time: 7570.46
Speaker: SPEAKER_05
Transcript:  Well, of course, every company, every company, especially Apple.

Start time: 7571.94
End time: 7586.34
Speaker: SPEAKER_04
Transcript:  They spend more time than any other company that I know crafting the way they're going  to tell their story. That's why they're better at it.  I mean, they are, frankly, better at it at telling their story than other companies.  And so that undermines them.  And they do have perspective.

Start time: 7586.56
End time: 7658.06
Speaker: SPEAKER_05
Transcript:  Pet journalist Matthew Panzerino of TechCrunch invited back to Apple last year.  He was part of the five who got invited for the Apple apology tour.  We made the Mac Pro, but we blew it.  We painted ourselves into a corner.  We can't make another one.  Not this year, but we're working on it.  Not this year. Panzerino got invited to.  Now, I don't I would love to know, Matthew, if you're watching.  Great reporting.  But I'd like to know if Apple called you and said, would you like to come to the campus  and see what we're doing in the Mac Pro or if Matthew did some digging?  In any event, he did go to the campus and was shown, you know,  all the work Apple's doing.  And Apple uses as an opportunity to say, and by the way, it's not coming out this year.  We're hoping not 2019.  Yeah. And on the one hand, Matthew said, well, you know, I'm  I'm glad that Apple's telling people who are now in this process of  thinking about what Mac to buy.  Don't wait. Buy it next year.  That's a good thing.  But it's also a very self-serving thing because Apple's saying, buy an iMac Pro right now  because we're going to have the Mac Pro for you.  It's really. Yeah.  I mean, it always cuts both ways.  And in this case, Apple's very much manipulating people saying,  Oh, yeah, don't wait.  Buy a Mac Pro now and we'll give you something next year to buy.

Start time: 7658.22
End time: 7664.84
Speaker: SPEAKER_04
Transcript:  They're not selling many iMac Pros, by the way.  Yeah. I mean, that's our audience.  You know, when. Yeah, I bought one, but that's five thousand.

Start time: 7664.88
End time: 7667.02
Speaker: SPEAKER_05
Transcript:  What kind of nut am I? Yeah. Crazy.

Start time: 7667.12
End time: 7670.16
Speaker: SPEAKER_04
Transcript:  But you did it for science, right?  You're not using it. I have to review it.

Start time: 7670.34
End time: 7681.92
Speaker: SPEAKER_05
Transcript:  But then I get the distinct pleasure of getting to use it.  Just what I need at home.  It runs Facebook really fast. 32 gigs of RAM.  You know what? It's not.  You can't tell it's fast.

Start time: 7681.92
End time: 7685.66
Speaker: SPEAKER_04
Transcript:  You don't run on Facebook anyway.  You killed Facebook. I killed for the last time.

Start time: 7685.90
End time: 7720.89
Speaker: SPEAKER_05
Transcript:  But I I hope, you know, OK, I'm going to be I'm going to be honest here.  So I have gone through several stages of grief with Facebook.  So a couple of weeks ago, I told you, I deleted my account.  You get two weeks.  And this is new.  This is the GDPR thing is that you can actually say, delete it.  And they give you two weeks to change your mind.  My wife said, I mentioned this last week,  but now I'm not married to anybody.  It just says I'm married, but not to anybody because my name's gone.  Right. So I said, oh, and I brought it back.  And then I went, no.  So I deleted it again.

Start time: 7722.08
End time: 7724.66
Speaker: SPEAKER_04
Transcript:  And then you get a new two weeks.  You get a new two weeks.

Start time: 7724.98
End time: 7778.02
Speaker: SPEAKER_05
Transcript:  Every time you do this, you get a new two weeks.  So then I thought, well, I shouldn't really delete it  because what if somebody steals my name or I don't know.  So I am now currently deactivated.  But it's it's pointless in every respect.  A, even if I deleted it, Facebook has my data.  It's too late. It's too late.  B, this is in any way register as a blip of any kind in Facebook's bottom line.  Absolutely not.  More people join Facebook in the time it took to tell you this  than everybody who quit totally so far.  Right. Delete in the delete Facebook movement.  So I've got I've accomplished nothing.  Mark Zuckerberg's not getting the signal.  I've accomplished nothing.  It just makes me feel better because I frankly.  It's purely emotional.  I think he's kind of creepy.  And I think Facebook's kind of creepy.  More so than anybody else, more than Google, more than anybody else.

Start time: 7778.52
End time: 7785.28
Speaker: SPEAKER_02
Transcript:  That's why I deleted the app from my phone.  It wasn't it wasn't out of protest.  No, it was out of it was a mental health move.  It's mental health. Yeah.

Start time: 7785.62
End time: 7800.62
Speaker: SPEAKER_04
Transcript:  I just don't go.  I haven't deleted my account, but I kind of just.  I've been deleting Facebook since 2010.  I'm proud. But I have been I have been, you know,  that's the place that I tell people to really be careful about what you do  more than any of the others.

Start time: 7800.84
End time: 7808.18
Speaker: SPEAKER_05
Transcript:  And every site you go to, whether you delete Facebook or not, registers,  you know, if it's got a Facebook like or a login, registers your presence.

Start time: 7808.30
End time: 7845.90
Speaker: SPEAKER_03
Transcript:  So I had it.  I just got to say, you know, over the past couple of weeks,  there have been all these how to guides, how to delete Facebook,  how to check to see if you were compromised, delete Facebook, other people.  My favorite one is how to how to have the talk. Yes.  If your data was stolen, how to have that talk with your friends.  We are literally talking about personal data in the same  using the same language in terms that we use to talk about STDs.  It is it is.  But, you know, we're not like engaging in  like the equivalent of safe sex when we, you know, we're not protecting ourselves  online in any real data hygiene.

Start time: 7846.24
End time: 7847.32
Speaker: SPEAKER_04
Transcript:  We definitely need data.

Start time: 7847.42
End time: 7852.12
Speaker: SPEAKER_05
Transcript:  It's like we're telling we're telling people how to say you've got chlamydia  without actually telling them how to use a condom.

Start time: 7852.14
End time: 7853.86
Speaker: SPEAKER_03
Transcript:  It's so funny. Is the new chlamydia.

Start time: 7854.20
End time: 7857.27
Speaker: SPEAKER_04
Transcript:  It's so funny.  This is exactly

Start time: 7858.42
End time: 7861.82
Speaker: SPEAKER_03
Transcript:  is exactly what I've been thinking about is scraped on the back end.

Start time: 7862.50
End time: 7891.16
Speaker: SPEAKER_04
Transcript:  Unless you get scraped on the back end.  This is exactly what I've been thinking about with this topic.  This is so funny because I was thinking that's the content that's needed is like  good data hygiene.  So we've actually been doing a little bit on this and planning to do more.  Because, yeah, that's what's needed, right, is the is the positive proactive angle.  What is good data hygiene look like online for an individual?  And then how do you teach that to kids?  Do you teach people how to write your account, deletion epitaph?

Start time: 7891.30
End time: 7928.64
Speaker: SPEAKER_02
Transcript:  And there is there's such a thirst for that knowledge  and that really important knowledge.  I mean, I just read a little for my friends, a little thing on Facebook  right after the Cambridge Analytica News started.  And I was like, hey, guys, here's something to know.  Like, if you ever want to take a quiz or any take anything that looks like it  is doing nothing in particular for itself, I was like, consider how that app  within Facebook makes its money.  Yeah, is it? Yes.  Is it obvious how this app is making its money?  If it's not obvious how it's making its money, it's making its money off of you.  Yes. And what you're sharing.  So just think about that every single time you use something.

Start time: 7928.76
End time: 7933.95
Speaker: SPEAKER_05
Transcript:  And when you have small children, you have to teach them how to wipe their Facebook.  I think that's important.

Start time: 7935.54
End time: 7941.76
Speaker: SPEAKER_02
Transcript:  But my friends were so thankful.  They were so like, oh, my gosh, I hadn't thought about it that way.  Yeah. Did you remind people how business works? Yeah.

Start time: 7942.14
End time: 7948.56
Speaker: SPEAKER_03
Transcript:  Do your friends post photos of their kids on Facebook?  Oh, sure. Yeah. All right.  So then what the I was then then

Start time: 7949.82
End time: 7954.70
Speaker: SPEAKER_05
Transcript:  kind of like we need to have the talk.  I've been posting your picture on Facebook for 13 years.

Start time: 7956.60
End time: 7988.18
Speaker: SPEAKER_03
Transcript:  Right. I mean, it's kind of like, you know, you don't put your picture  like if you're actually concerned about this stuff, then you have to exercise  some self-restraint and don't put pictures of your kids tushes  in the bathtub on the Facebook.  You know, I mean, it's part of this.  This has been sort of a threat, a through line for this entire show tonight.  But a lot of this just comes back to like life moves pretty fast.  Technology moves faster than we do.  And we got to, you know, stop and think about what we're doing.

Start time: 7988.32
End time: 8007.18
Speaker: SPEAKER_05
Transcript:  You know who else ought to move fast? People in Mountain View.  Because Waymo has just received a permit for no driver testing.  Oh, wow. California and Mountain View is the first place.  Watch out. There's Lexus is driving down the street.  There's nobody inside.  And I bet if it hits you, it just keeps going.

Start time: 8007.78
End time: 8010.48
Speaker: SPEAKER_03
Transcript:  So they're driving like they've got like a trailer car behind it.

Start time: 8011.26
End time: 8026.90
Speaker: SPEAKER_05
Transcript:  No, they they they talk about moving too fast.  We just, you know, had this Uber issue, the Tesla issue.  Waymo confirmed on Friday the California Department of Motor Vehicles  has approved its permit to test without a safety driver behind the wheel.

Start time: 8027.32
End time: 8032.26
Speaker: SPEAKER_03
Transcript:  That's lobbying at work. That's amazing.  Wow. And they don't have to have a. Yeah. Yeah.

Start time: 8032.46
End time: 8036.36
Speaker: SPEAKER_05
Transcript:  So if you see a Chrysler minivan with strange accoutrement on the roof

Start time: 8036.46
End time: 8055.43
Speaker: SPEAKER_03
Transcript:  coming at you, Ron, there's somebody at the wheel.  That's actually it's interesting, though.  I wonder. I bet you nobody at the California Department of Motor Vehicles  asked in depth questions about how secure the system is  and if it's vulnerable to intrusion outside in treatment.  No, I doubt it.

Start time: 8056.20
End time: 8072.26
Speaker: SPEAKER_05
Transcript:  I have to say, I mean, Waymo's done a lot better job than Uber with self-driving.  Uber, I think the Uber record  average was a driver had to take over every 13 miles, had to override the system.  Well, and Waymo is something like I can't remember what it was.

Start time: 8072.28
End time: 8076.92
Speaker: SPEAKER_03
Transcript:  It's hundreds of times. Well, Uber is having a hard time  with object and image recognition and making some mistakes.

Start time: 8077.08
End time: 8097.36
Speaker: SPEAKER_02
Transcript:  Yeah. So and I think this all comes back again.  Like Waymo is part of a data company. Yeah.  Uber is a transportation company that uses data. Right.  It's kind of interesting.  And I sort of wonder if part of Waymo's  lobbying effort was just like, well, look at the statistics.  We have many hours and miles of safe testing on a closed course.

Start time: 8098.10
End time: 8099.25
Speaker: SPEAKER_04
Transcript:  Yeah, they've been doing this for a long time.

Start time: 8100.86
End time: 8112.20
Speaker: SPEAKER_03
Transcript:  I let's all hand it to the California Department of Motor Vehicles.  That's probably literally the fastest they've ever moved on anything.  Right. So we know it can be done.  The next time we're all standing online, it's really true.

Start time: 8113.76
End time: 8124.44
Speaker: SPEAKER_05
Transcript:  Waymo says that on average, once every 5600 miles,  the safety driver has had to take over compared to Uber's every 13 miles.  It's pretty remarkable.  Yeah, let me get that. Pretty remarkable.

Start time: 8124.44
End time: 8135.75
Speaker: SPEAKER_04
Transcript:  Well, they've been at it for a long time, though.  Remember, this is a this is a secret project inside Google for a long time  before we knew about it.  And then we've also known about it for a long time.  Alphabet. Right. Before Google, Google's alphabet.  Thank you.

Start time: 8136.34
End time: 8143.20
Speaker: SPEAKER_05
Transcript:  I should point out, though, that with no safety driver,  there's not going to be every somebody there every 5600 miles to correct the car.

Start time: 8143.24
End time: 8154.74
Speaker: SPEAKER_03
Transcript:  I wonder who's I wonder who's insuring them because there's no actually  we don't have the insurance stuff figured out yet.  So I wonder how Google's probably self insuring.  Yeah, I was just thinking the same thing.  Google Insurance Company. I think so.

Start time: 8155.22
End time: 8156.29
Speaker: SPEAKER_02
Transcript:  Are we saying they have some money?

Start time: 8158.36
End time: 8257.54
Speaker: SPEAKER_05
Transcript:  Wow. So wow.  That's just that's wild. Let's take a break.  Surprise. Last ad.  And then we can say good night, because as much as I love talking to you,  this is probably gone on way too long.  Our show from T.V.  You know, I discovered something really cool.  I use Sonos. We're talking about Sonos.  And the Sonos app has now added Audible back in.  You can listen to your audio books on your Sonos this morning to celebrate.  I had Ready Player One playing throughout the entire house.  It was so awesome.  Audible makes great audio books, whether you like to listen to books  to get away from it all, like Ready Player One.  You like to get learn. I do that, too.  I love reading history.  I've been an Audible member since the year 2000.  18 years. That's kind of hard to believe.  18 years longer than I've been doing this show.  I've been an Audible member and I love Audible.  You will, too.  The selection on Audible is phenomenal.  Pretty much every book that comes out now comes out in audio as well as print  so that you can get it day and date on Audible.  I do that a lot. I'll pre-order books that I know are coming out.  I'm very excited about reading.  When Bill Gates said my favorite book was Steven Pinker's The Better...  What is it? Better Angel of Our...  Angels of Our Better Nature.  Angels of Our Better Nature. I immediately got it on Audible.  And that's another nice thing. You get a book immediately.  You go to audible.com slash twit and you can get a book for free right now.  And you're downloading it and you're listening within seconds.  That's pretty cool.  Jason, your book's on Audible.

Start time: 8257.94
End time: 8266.63
Speaker: SPEAKER_04
Transcript:  It is on Audible.  And as a matter of fact, if you go to Audible and you listen to the sample chapter,  it is the chapter number nine.  About me.

Start time: 8267.74
End time: 8270.05
Speaker: SPEAKER_05
Transcript:  Yeah. People are sick of that by now.

Start time: 8271.86
End time: 8275.37
Speaker: SPEAKER_04
Transcript:  That's adorable.  Read by yours truly as well.

Start time: 8276.70
End time: 8285.04
Speaker: SPEAKER_03
Transcript:  My book is also on there, but not read by me.  A professional person who knows how to read a book out loud to other people.

Start time: 8285.66
End time: 8309.45
Speaker: SPEAKER_05
Transcript:  Yeah. No, it's so good.  I have to say every book on Audible is something you learn, something you can enjoy,  something you can escape to.  I was just looking at my Audible library and I have a pretty good mix of fiction and nonfiction.  I learn a lot from Audible.  I'm going to Japan, so I'm just reading Haruki Murakami's Wind Up Bird Chronicle.  I don't know if you've read that, Amy, but it's really funny.

Start time: 8310.50
End time: 8318.96
Speaker: SPEAKER_03
Transcript:  Hey, can I ask a question since we're talking about books in Audible?  Yeah.  Is it what books has everybody?  I need I just finished Born by Jeff Vandermeer.

Start time: 8319.90
End time: 8321.62
Speaker: SPEAKER_05
Transcript:  I don't know that book. Tell me about that.

Start time: 8322.16
End time: 8332.43
Speaker: SPEAKER_03
Transcript:  It's weird and crazy.  He's the guy who wrote Annihilation.  Oh, so you want science fiction or horror?  Sort of dystopian futures.  You know, it's me.

Start time: 8333.84
End time: 8349.76
Speaker: SPEAKER_02
Transcript:  So I'm reading.  I went way back and I'm reading even Cowgirls Get the Blues.  Love that.  Oh, yeah.  Great book.  And you know what?  Like it's working for me right now.  It's totally escapist, but also the most fantastic use of metaphor I've ever encountered.  Like just the wildest.

Start time: 8349.96
End time: 8352.13
Speaker: SPEAKER_05
Transcript:  She had giant thumbs because she hitchhiked.

Start time: 8353.00
End time: 8355.39
Speaker: SPEAKER_02
Transcript:  She hitchhiked because she had giant thumbs.  Oh, vice versa.

Start time: 8355.82
End time: 8374.61
Speaker: SPEAKER_04
Transcript:  Yeah, that's a big distinction.  Interesting.  There's a new one that I'm about to do because the second season of Handmaid's Tale is about  to come out.  There's a new version.  It's Claire Danes who did a reading of the original, but this one is a performance version  where there's other voices as well.  I love those.

Start time: 8374.92
End time: 8382.20
Speaker: SPEAKER_05
Transcript:  When Audible does that, it's really cool because it brings a book to life.  I love Tom Robbins.  You know, you got me kind of in the mood.  I love Tom Robbins.  Yeah.

Start time: 8382.96
End time: 8385.22
Speaker: SPEAKER_03
Transcript:  Half a Sleep in Frog Pajamas is one of my favorite books of all time.

Start time: 8385.60
End time: 8392.30
Speaker: SPEAKER_05
Transcript:  I listened on Audible way back in 2010 to Fierce Invalids from Hot Climates, Home from  Hot Climates.  That was a great book.

Start time: 8392.32
End time: 8396.04
Speaker: SPEAKER_02
Transcript:  Tom Robbins on audio has got to be great.  Yeah, it is.  Did he read it himself?

Start time: 8396.68
End time: 8397.91
Speaker: SPEAKER_05
Transcript:  No, no, no, no.  Okay.

Start time: 8398.44
End time: 8401.24
Speaker: SPEAKER_02
Transcript:  Just the words, right?  It's such fun words to read.  Yeah.

Start time: 8402.14
End time: 8411.56
Speaker: SPEAKER_05
Transcript:  No, it's like, you know who else is great in Audible?  Vonnegut.  Kind of for the same reason.  They write like they speak, very naturally, and you can hear the voice.

Start time: 8412.38
End time: 8415.02
Speaker: SPEAKER_03
Transcript:  I want Jeff Bridges to read Tom Robbins' books now.

Start time: 8415.98
End time: 8419.75
Speaker: SPEAKER_05
Transcript:  The dude should read Tom Robbins.  He should, right?  Yeah, definitely.

Start time: 8420.20
End time: 8421.34
Speaker: SPEAKER_03
Transcript:  Or Vonnegut too.  Yeah.

Start time: 8422.22
End time: 8422.87
Speaker: SPEAKER_05
Transcript:  Yeah.

Start time: 8423.20
End time: 8458.34
Speaker: SPEAKER_04
Transcript:  I have another recommendation.  It's a nonfiction one though.  Whiplash by Joey Ito and Jeff Howe.  Love Joey Ito.  How to survive our faster future.  Yeah.  So a lot of this is how, you know, because we're in a world where we're absorbing so  much data and things are moving so much faster, you know, a lot of the laws and principles  that we've worked on in business and life and culture, you know, don't, they're, we're  breaking them and we have to be comfortable with that and think about them differently.  So whiplash.

Start time: 8458.66
End time: 8503.60
Speaker: SPEAKER_05
Transcript:  Listening to business books on Audible is really cool.  Yeah.  It's a great way to kind of take the time that you're in the car or walking the dog  or doing the dishes and make some use of it.  Get a little smarter.  Yeah, exactly.  You know what's cool about the Vonnegut books?  They have movie stars reading them all.  Audible's really good at choosing voices.  James Franco reads Slaughterhouse Five.  Tony Roberts reads Cat's Cradle.  I want to hear John Malkovich read Breakfast of Champions.  Wow.  Wow.  Wouldn't that be something?  Yeah.  So it goes.  I listened to Galapagos before I went to the Galapagos.  Turns out it's not really about the Galapagos, but it's still a great book.  I really enjoyed it.  And the Galapagos does figure in it.  It's just not a natural history or anything.

Start time: 8503.87
End time: 8506.50
Speaker: SPEAKER_03
Transcript:  It's not a travel guide.  I kind of feel like you should have a book club, Leo.

Start time: 8507.24
End time: 8582.24
Speaker: SPEAKER_05
Transcript:  I've always wanted to do an audio audible book club because I listen to so many audible  books.  Welcome to the Monnke House.  This is a dramatization with David Straithairn, Maria Tucci, Bill Irwin, Tony Roberts, and  Dylan Baker.  That would be awesome.  See, this is the fun part.  If you're an audible subscriber, when you get together with other audible subscribers,  which apparently we all are coincidentally, what you do is talk about what you hear lately.  What's a great book?  Audible facilitates this.  You can now send books, share books from your library with anyone.  If it's their first time, they listen free.  You could share audio excerpts.  I really like this from your favorite books.  So if you listen to something and say, oh, this is really good.  Jason's got to hear this.  I can send this to you.  A lot of people listen to our podcast faster.  You can do that with audible too or slower.  Get the narration you want.  If you're an Amazon Kindle user and you use WhisperSync, you can buy the book on the Kindle  as well as the audio book and watch as it reads or switch back and forth.  So listen.  You get home.  You can also, if you like to read books on a Kindle, audible members get a credit every  month good for any audio book, regardless of price.  Unused credits roll over.  Although I never have unused credits.  I look forward to my reset data, which is the 22nd of every month.  I immediately jump in because I have an audible wish list as long as my arm.

Start time: 8582.58
End time: 8593.09
Speaker: SPEAKER_04
Transcript:  They have a great feature too that I recently discovered.  If you use a credit on a book and you didn't like it, you can exchange that credit for  another book.  That's really nice.

Start time: 8594.68
End time: 8613.90
Speaker: SPEAKER_05
Transcript:  No questions asked.  No questions asked.  And with audible, you're not renting.  These books are yours to keep.  I have my library because I've been an audible member so long is hundreds and hundreds of  books and I often go back and reread favorites, especially when, you know, just I need a,  like I need, I need even Cal Groves get the blues to get me through the night.  And then I got it, which is really, really nice.

Start time: 8613.98
End time: 8617.08
Speaker: SPEAKER_03
Transcript:  I forgot.  I love that book.  I'm going to read it.  Me too.

Start time: 8618.06
End time: 8668.98
Speaker: SPEAKER_05
Transcript:  I did a lot of John Irving's too, like Cider House Rules.  For some reason they remind me.  The narrative.  They're great stories, but they're real and it's, they're fun.  Get a free audio book right now.  You get a 30 day free trial.  Here's two ways to do it.  You can go to audible.com slash twit.  We've got a new way.  If you, you know, most people listen audible on their phone, so you could just use your  phone and text twit, T W I T to 500 500.  That's the short code.  That's it.  That's as easy.  You can get, you get a link back, click.  That's it.  You're done.  You can go to 500 500 or go to a U D I B L E dot com slash twit audible dot com slash  twit or text twit to 500 500.  You'll get a link, a free book and a whole world of amazing literature awaits you.  That's how these people got so smart.  Now I know why you all are so darn smart.

Start time: 8669.53
End time: 8680.55
Speaker: SPEAKER_04
Transcript:  Oh, I forgot.  I just remembered another recommendation.  Hamilton, the revolution.  They did the, the story of how they created Hamilton.  Terrific audio book.  Gotta read that.

Start time: 8681.02
End time: 8683.63
Speaker: SPEAKER_02
Transcript:  Yeah.  I think you just made a great shout out to English majors.

Start time: 8685.46
End time: 8690.44
Speaker: SPEAKER_05
Transcript:  English majors are pretty much everybody because we couldn't get a real job.

Start time: 8691.10
End time: 8711.35
Speaker: SPEAKER_03
Transcript:  In the future, people, people who have, we all focus on STEM STEM STEM, but the people  who are going to fare pretty well going forward are people who have had very rigorous liberal  arts degrees with super concentrated abilities to do critical thinking and comparative reasoning  and logic.

Start time: 8711.98
End time: 8741.32
Speaker: SPEAKER_05
Transcript:  So analysis, I would, I would submit why I reject the notion that you're one of the other,  your left brain or right brain do both the most really the secret to my success in life.  And I bet you did to all of yours too, is that you understand technology, that you have  an affinity for STEM, for science, for technology, for engineering, for math, but you also can  talk or write and explicate.  And we really need that.  And I do think Amy, that STEM gives you a logic foundation in a way that no, no,

Start time: 8742.52
End time: 8763.43
Speaker: SPEAKER_03
Transcript:  Sure.  But not in exchange for comparative.  Like the best possible degree would be instead of algebra, like applied mathematics, more  practical applied mathematics.  That's what coding is.  Coding is applied mathematics.  Comparative and world religion.  And like that, that makes you a super, like a super powerful person if you're able to  do all of that.

Start time: 8763.84
End time: 8773.34
Speaker: SPEAKER_05
Transcript:  And you know, one thing that this whole panel represents is, is lifelong learners that you  got a good foundation and you never stopped learning that you still read, you still learn,  you're still inquisitive.

Start time: 8773.58
End time: 8780.50
Speaker: SPEAKER_03
Transcript:  That's really important.  Well, because no matter what happens, nobody can take away what you've learned.  Like nobody can take away your education, which is why education is paramount.

Start time: 8780.88
End time: 8787.29
Speaker: SPEAKER_05
Transcript:  I completely agree with you.  But take a coding class as well as a comparative religions class.  They're both great.

Start time: 8787.92
End time: 8790.55
Speaker: SPEAKER_02
Transcript:  Well, we should do it all.  That's the thing, right?  Do it all.

Start time: 8791.20
End time: 8792.55
Speaker: SPEAKER_05
Transcript:  Why say I can't do that?  I can't do that.

Start time: 8793.18
End time: 8800.36
Speaker: SPEAKER_02
Transcript:  That's why all good liberal arts schools and most big wonderful public universities require  you to take a number of different types of courses so that you can think that way.

Start time: 8800.66
End time: 8840.27
Speaker: SPEAKER_05
Transcript:  I am a big proponent of a lot of high school math curricula is not very good these days,  but there is good coding curriculum out there.  Learn math through coding.  It will help you learn math and logic and technology.  I interviewed a guy who's a professor of computer science at Brown University.  I'm trying to remember the name.  It was on triangulation.  The name of his they have a school curriculum that any math teacher can teach.  It doesn't matter if you don't know coding and it's really good and it's free and it's  available.

Start time: 8841.68
End time: 8866.38
Speaker: SPEAKER_02
Transcript:  While you're looking that up, I have kind of a funny story.  When I was in high school calculus, my high school calculus teacher, and I took this as  an insult at the time, he said, you're kind of like the best non math math student I've  had.  And now much later, I'm like, no, that was a compliment.  I'm going to take that because I know that I'm going to own that.  Yeah, that's non math.

Start time: 8867.10
End time: 8908.54
Speaker: SPEAKER_05
Transcript:  This is the pages, bootstrapworld.org.  And I really love this idea.  They have lesson plans.  They have actually classes that you can take as a teacher.  They've got ongoing support from the National Science Foundation.  It is a way to bring math, physics, and coding into the classroom for basically for high  schools.  I would say smart middle schooler could benefit from this as well.  And if you're, by the way, they're one of the largest providers of formal computer science  education to girls and underrepresented students nationwide.  They really do a great job of getting diversity.

Start time: 8909.93
End time: 8921.15
Speaker: SPEAKER_04
Transcript:  My calculus teacher said, you're the worst student I've ever had.  I don't know why you're taking calculus.  That's almost a direct quote.  That's really insulting.  Yeah, that's almost a direct quote.  So I dropped the class.

Start time: 8922.14
End time: 8970.34
Speaker: SPEAKER_03
Transcript:  It may not feel like a rigorous liberal arts program is going to prepare you for the job  market over the next three to five years, and it probably will not.  So I'm actually, I just want to clarify what I said.  I'm talking about 20 years out.  So I've got a seven year old and by virtue of her being seven and growing up in my household,  she's getting exposure to quite a bit of code and tech.  Good for her.  That's great.  But if you think about the hybrid skill sets and all the really interesting new kinds of  jobs that will never have existed before, but will need to exist 20 years from now,  some humans who have really great abilities to think critically, understand logic, write,  communicate.  I agree 100%.  That's going to be really important because a machine can't, is not going to be able to

Start time: 8970.40
End time: 8993.56
Speaker: SPEAKER_04
Transcript:  connect the dots.  That reminds me of something too.  We've been interviewing interns and we interviewed this young fella from Harvard and he told  me something that I thought was really interesting that they don't allow you to declare a major  now until your junior year.  Hallelujah.  And so, which I thought is great because most kids change three times by then, right?

Start time: 8993.76
End time: 8998.99
Speaker: SPEAKER_05
Transcript:  There was a reverse trend going on for a while where you had to declare before you got into  college.  I know.

Start time: 9000.03
End time: 9059.00
Speaker: SPEAKER_04
Transcript:  Terrible.  Which is actually similar to what Amy's saying is that they want you to come in and have,  whether you're going to major in computer science or drama or med, a medis pre-med or  whatever, they want you to come in and get a broad based exposure to different things.  And as a matter of fact, they require that you are involved in an activity that's part  of your credits.  And so, instead of having to do it on your own time, you have that built in, whether  it's Cheer Squad or the magazine or the newspaper, whatever it is.  And so, this fella that we were interviewing that was really smart, he said, I had to pick  something and so I picked a newspaper because I was like, well, that looks easy, right?  Which is something to tell an editor in an interview, you know?  I couldn't do calculus, so I'm here.  But he's like, I love it.

Start time: 9059.82
End time: 9063.31
Speaker: SPEAKER_02
Transcript:  Did he find out this is a Harvard kid?  So he was writing for the Crimson?  Yeah.

Start time: 9063.88
End time: 9110.16
Speaker: SPEAKER_04
Transcript:  He found out that he loved it.  And he not only did the newspaper, but he did the magazine too.  And so, very super cool.  And I thought that was a really good sign that at least one institution, and obviously  where Harvard goes, a lot of colleges tend to follow, was embracing this idea that no  matter what you learn, critical thinking, analysis, having a broad learning profile  is going to suit you really well.  What was your major?  My major?  It was journalism until I had these fights with my journalism professors about that all  the future was going to be online.  And they said, no, they tried that in Hypercar down in Florida and people just don't want  to read on screen.

Start time: 9110.24
End time: 9117.00
Speaker: SPEAKER_05
Transcript:  All people did in Florida with the interactive tests was buy stamps.  That shows you how long ago that was.

Start time: 9117.52
End time: 9149.95
Speaker: SPEAKER_04
Transcript:  The online thing is neat, but it's not going to ever happen.  I'm like, I'm like, this is with prodigy.  It's just not going to happen.  And so I'd had these. And finally, I was like, I just can't learn anything from these people.  In my very 18 year old way was like, I'm not going to learn anything from these people.  They're complete idiots, which was dumb.  So I changed to.  So I went to Indiana University and they have a thing that's called Create Your Own Major,  the College of Arts and Sciences.  Create.  So I did a mix of history and English and Middle Eastern studies.  That's really cool.  That's what a small world.

Start time: 9151.70
End time: 9152.48
Speaker: SPEAKER_03
Transcript:  Jason, where are you from?

Start time: 9153.36
End time: 9157.56
Speaker: SPEAKER_04
Transcript:  I'm from Fort Wayne, Indiana and Philadelphia, Pennsylvania.

Start time: 9158.34
End time: 9196.16
Speaker: SPEAKER_03
Transcript:  So I am a region rat.  I'm from northwest Indiana.  Yeah.  And I went I was on a full ride for the music school.  So I went to IU, somewhat against my will.  Got a couple of hoosiers here.  That's crazy. Yeah.  I was a my parents said I was allowed to go anywhere I wanted,  but I had to have the same deal, which, of course, I wasn't going to get.  Yeah. So I went to the music school.  I made it through my freshman year recital.  I was a clarinet performance major,  dropped out, didn't tell anybody,  and then quietly switched over.  And I did the same kind of degree that you did.  So mine was game theory, political science and economics.

Start time: 9196.44
End time: 9197.61
Speaker: SPEAKER_04
Transcript:  Nice. That's awesome.

Start time: 9198.24
End time: 9200.50
Speaker: SPEAKER_03
Transcript:  Yeah. That's crazy. Small world.  Very cool.

Start time: 9200.80
End time: 9223.68
Speaker: SPEAKER_02
Transcript:  I was an English major at Harvard at the time.  Did you work with the Crimson?  I did. I was a Crimson editor.  In fact, I coedited the magazine.  You were the editor of the Crimson?  No, I was the coeditor of 15 Minutes, which is the weekly magazine  of the Harvard Crimson.  But the point that I was getting to was that at the time,  Harvard was pretty snobby about vocational anything.  Like applied math was the only degree at Harvard.

Start time: 9223.78
End time: 9230.12
Speaker: SPEAKER_05
Transcript:  You're here to learn about the world.  Right. There was to be a leader.  There was very like you could take computer science at Harvard,

Start time: 9230.18
End time: 9275.56
Speaker: SPEAKER_02
Transcript:  but it was really, really abstract.  It wasn't very it wasn't very hands on.  But here was the interesting thing.  Because of that, the Crimson was it has nothing to do with Harvard University.  I mean, except obviously it has everything to do with Harvard University,  but it's not run by the university.  It's completely funded by the students.  We own our own presses, completely funded by the students, technically off campus.  And what was interesting was that we were running a full fledged website  at the time, even though it was brand new, because there was nobody to tell us not to.  Yeah. Right. It was the students kind of going like, we have to have this.  So we're going to start it. And that was.  Cool. It was like, OK, well, let's take that vocational part  and move it kind of off campus.  And I'm glad to hear that now they're kind of acknowledging that  and helping people move into it.

Start time: 9275.86
End time: 9296.80
Speaker: SPEAKER_05
Transcript:  So you see kids, you never know.  Just get that education. Be cool.  Stay in school.  And English is fine.  Yeah, English is fine.  It doesn't really matter.  Learn as much as you can for as long as you can.  Really. Yes. What a great panel.  Amy Webb, love having you on.  The signals are talking.  Why today's yes. Oh, sorry. Plug.

Start time: 9297.92
End time: 9305.23
Speaker: SPEAKER_03
Transcript:  I can I plug.  So our annual report just came out.  It's almost 300 pages long. It's free.  Where's mine? I sent one.  Oh, you did.

Start time: 9306.10
End time: 9311.31
Speaker: SPEAKER_05
Transcript:  Yeah. Karsten, are you are you are you  bogarting the annual report?  Don't go here.

Start time: 9312.20
End time: 9329.98
Speaker: SPEAKER_03
Transcript:  So it's our annual report on emerging tech trends for the coming year.  This year, there's 225 across 20 industries.  It's like and it's all free.  So you can get it online at our website.  And we printed like a handful of hard copies, but it debuted at South by Southwest.  And now it's everywhere.

Start time: 9330.22
End time: 9338.76
Speaker: SPEAKER_05
Transcript:  So future today, Institute Dotcom.  And downloading tech trends report available for download.

Start time: 9338.86
End time: 9342.12
Speaker: SPEAKER_02
Transcript:  How many months do you spend working on that?  I probably a lot. That looks hard.

Start time: 9342.78
End time: 9361.28
Speaker: SPEAKER_03
Transcript:  Now, I mean, we have this is our 11th annual, like our 11th edition.  So we've been doing this for 11 years.  You know, it takes a couple of months, but we're it's the research that we're always doing.  Last year, two years ago, I open sourced all of my methodology,  research tools and everything, because I want other people to use them and build on them.  So we give everything away for free.

Start time: 9361.78
End time: 9365.45
Speaker: SPEAKER_05
Transcript:  That's wow. That's amazing. Isn't that nice?  Look, here's your reading list.

Start time: 9366.46
End time: 9388.46
Speaker: SPEAKER_03
Transcript:  Oh, yeah, we put together our new ones coming out in two weeks.  So every we you know, I think pretty strongly that like if you want to understand the future,  you also have to pay attention to sci fi.  OK, I can live with that.  OK, we put together a reading and listening list  every quarter and encourage people to read and watch and listen.

Start time: 9389.02
End time: 9409.92
Speaker: SPEAKER_05
Transcript:  It's really cool, Amy.  You have you have not only created your own major,  you've created your own job, really.  And well done. Well done. Future Today Institute dot com.  Lindsay Turrentine took that that career at the Harvard Crimson  and brought it to us all editor in chief at CNET dot com.  Anything you want to plug that's going on?

Start time: 9410.30
End time: 9424.74
Speaker: SPEAKER_02
Transcript:  I want to vaguely plug what we're doing later this week  in the smart home territory, because it's a secret and I can't talk about it yet.  But I'll be able to talk about it later this week.  OK, so Thursday, check out CNET.  You won't be able to miss it. CNET dot com.

Start time: 9425.44
End time: 9428.06
Speaker: SPEAKER_05
Transcript:  Thursday, something is coming.

Start time: 9428.24
End time: 9430.32
Speaker: SPEAKER_02
Transcript:  Something's coming. How exciting.

Start time: 9431.10
End time: 9437.70
Speaker: SPEAKER_05
Transcript:  Jason Hiner, he's here for RSA.  You could find his work, of course, at Tech Republic.  He's editor in chief. Anything you want to plug?

Start time: 9438.04
End time: 9487.78
Speaker: SPEAKER_04
Transcript:  Yeah, every month, ZDNET and Tech Republic come together.  All of our editors across the globe.  We have editors and editors all over the world, contributors all over the world.  We come together and we have 10 features, essentially,  that we do on the most important topics in tech.  And so this month is cybersecurity.  And so you can you can go to ZDNET and go to  you can see it sort of on the front page there.  If you scroll down, all of our monthly features are there.  So if you come every month, you can get all the latest sort of our own research,  as well as our journalists on the ground.  You know, in all the English speaking parts of the world.  So, yeah, next month is the Internet of Things.  How exciting. The industrial Internet of Things.

Start time: 9487.80
End time: 9504.82
Speaker: SPEAKER_05
Transcript:  You guys are all doing such exciting, interesting work.  Now, I'm off for vacation.  I won't be here next week. Ian Thompson will be hosting.  Becky Worley will be hosting the week following.  So that'll be a lot of fun. I'll be back on May 6th, but I'll be  it'll be a fun one to watch.  I'll be just back. So I'll be incredibly jet lagged.

Start time: 9505.10
End time: 9507.82
Speaker: SPEAKER_02
Transcript:  And full of Japanese words and full of Japanese words.

Start time: 9508.08
End time: 9516.50
Speaker: SPEAKER_05
Transcript:  And I'm hoping sushi and maybe a few other things,  including a hot dog bun with brown spaghetti in it.  I don't know. Amy said I should. It's delicious.

Start time: 9518.16
End time: 9521.88
Speaker: SPEAKER_03
Transcript:  Eat one for me.  It sounds like the Japanese version of spaghetti tacos.

Start time: 9522.64
End time: 9525.14
Speaker: SPEAKER_02
Transcript:  Oh, which is like a kid favorite. Like a nightmare.

Start time: 9525.36
End time: 9599.20
Speaker: SPEAKER_05
Transcript:  But I'm going to try it because Amy Webb knows all and tells all.  And thank you all for being here.  We do tweet every Sunday afternoon, 3 p.m. Pacific, 6 p.m. Eastern.  2200 UTC. If you want to be in studio, we invite you to just email tickets at twit.tv.  We love our in studio audience. You guys are always great.  Michael O'Donnell is working on beating his record at the old screensaver show.  How many screensavers did you see? Over 100.  You're not close to that yet on Twitter, but you're getting there.  We love having him. You could follow him on Twitter at photo.  And he always posts fun photos from the episode.  So look for those at photo on Twitter.  If you can't be here in person, you can watch the stream live from wherever you are anywhere in the world.  Just go to twit.tv slash live.  If you do that, though, I invite you to join us in the chat room.  You could be the smart kids in the back of the class, the wise acres, the Weisenheimers.  The chat room is IRC dot twit dot TV.  And of course, if you're busy Sunday evenings, you can always get an on demand version of our show and listen at your leisure.  You'll find those at our website.  We'll go on all the way back to twit number one from April 17th, 2005.  13 years. Mark Zuckerberg in the frame, isn't it there?  I think I think that is. It's Mark Zuckerberg.

Start time: 9599.70
End time: 9600.93
Speaker: SPEAKER_03
Transcript:  He was just a eight year old at the time.

Start time: 9602.90
End time: 9619.46
Speaker: SPEAKER_05
Transcript:  Tweet dot TV. You'll find downloadable versions, audio and video there.  You can also subscribe and your favorite podcatcher.  In fact, I invite you to subscribe that way you won't miss a single episode.  Thanks for being here. I'll see you in a couple of weeks.  Another twit.

