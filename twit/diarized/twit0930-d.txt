;FFMETADATA1
title=Can You Smell What Tim is Cooking?
artist=Leo Laporte, Christina Warren, Dan Gillmor, Larry Magid
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2023-06-05
track=930
language=English
genre=Podcast
comment=<p>WWDC preview, AI scientist statement, virtual kidnapping</p>\

encoded_by=Uniblab 5.3
date=2023
encoder=Lavf58.76.100

Start time: 0.38
End time: 44.66
Speaker: Leo Laporte
Transcript:  It's time for Twit this week in tech. What a great panel we have for you. Christina Warren's here film girl from GitHub  We also have Dan Gilmore from the Walter Cronkite School of Journalism at ASU and  Connect safely Larry Magid Larry Magid is gonna tell the terrifying story of how he very nearly got scammed by a virtual kidnapping scheme  We'll also show you what to do to avoid that then we're gonna talk about Apple's big reveal tomorrow  Are you ready for a VR nerd helmet?  Maybe maybe not also AI of course in the news and we talked about that  Press release this week from AI scientists and leaders saying it's an extinction event watch out. Why would they do that?  It's all coming up next on twit

Start time: 47.92
End time: 50.56
Speaker: Intro
Transcript:  Podcasts you love from people you trust

Start time: 52.06
End time: 53.48
Speaker: Intro
Transcript:  This is twist

Start time: 61.11
End time: 143.02
Speaker: Leo Laporte
Transcript:  This is twit this week in tech episode 930  Recorded Sunday June 4th 2023. Can you smell what Tim is cooking?  This week in tech is brought to you by Express VPN  using the internet without Express VPNs like forgetting to mute yourself on zoom and  Then everyone hearing you trash-talking your boss protect your online privacy by visiting expressvpn.com slash twit  You can get three extra months free with a one-year package  And by collide collide is a device trust solution that ensures if a device isn't secure  It can't access your apps. It's zero trust for Okta visit collide.com  slash twit and book a demo today and by  AG one by athletic greens if you're looking for a simpler and cost-effective supplement routine  AG one is giving away a free one year supply of vitamin D and five free  Travel packs with your first purchase of a subscription go to athletic greens dot com slash twit and by  Cisco Meraki with employees working in different locations  Providing a unified work experience seems as easy as hurting cats  How do you reign in so many moving parts the Meraki cloud managed network?  That's how learn how your organization can make hybrid work work visit Meraki dot Cisco dot com slash twit

Start time: 145.68
End time: 148.52
Speaker: Leo Laporte
Transcript:  It's time for twit this week in tech the show we get together with the best journalists in the world

Start time: 151.31
End time: 212.04
Speaker: Leo Laporte
Transcript:  to talk about the week's tech news so that you'll know what's  Next Larry Maggott joins us from connect safely org. You had a tale to tell we'll talk about it  Boy that was a scary story about your wife getting kidnapped except she wasn't she wasn't she wasn't  Anyway, we'll we'll talk about that in a little bit  I guess we're not going away  Also with us legend dan gilmore founder of the asu news colab at the arizona states  Walter cronkite school of journalism is great to see you dan  Sure, you're my journalistic  Conscience I always always think of you and  I'm always thinking of you  I'm always thinking of you  Journalistic  Conscience I always always think of you and would dan approve that kind of thing  What would dan say  and  Yeah, you can you can say something now if you wish you can you know, I just say I was gonna say that's a

Start time: 212.72
End time: 213.99
Speaker: Dan Gillmor
Transcript:  sometimes questionable

Start time: 216.16
End time: 228.32
Speaker: Leo Laporte
Transcript:  And then it's a christina warren who has had a very busy couple of weeks she is of course  developer advocate at github  We love seeing you  And you were all over microsoft's build

Start time: 229.08
End time: 240.56
Speaker: Christina Warren
Transcript:  Broadcast. Yeah, sure was. Yeah, it was a good time  It was good to be back with people again. And um, it was uh,  They definitely they had me on my feet a lot for sure that goes without saying you were working hard

Start time: 241.68
End time: 262.22
Speaker: Leo Laporte
Transcript:  I did want to ask you though. I saw panos pane come out dressed traditionally in black  wearing his  Zebra chuck  Sneakers  Um, they really stood out with the black outfit. Yeah, um, I imagine you noticed that is he a sneaker head

Start time: 263.10
End time: 278.76
Speaker: Christina Warren
Transcript:  He is he is he's a massive sneaker head. That was actually the first time I ever met him in person  Um, I think that I got cool points because I commented on his shoes  He was wearing like a very specific like kind of like like rare type of shoe and I was like, oh, I like your shoe  They were fleecy. They were like

Start time: 279.90
End time: 284.06
Speaker: Leo Laporte
Transcript:  fleece wool  Sheep zebras or zee sheeps or something

Start time: 284.94
End time: 301.32
Speaker: Christina Warren
Transcript:  Yeah, no, he's a shoe person. I think that that his brother someone works  I don't know if it's at nike or if it's one of the other big um shoe manufacturers, but he is a fantastic shoe collection. So  People at home should always watch what panas's shoes are no matter what if any is that because they're always very very good

Start time: 302.12
End time: 349.12
Speaker: Leo Laporte
Transcript:  Uh, this was a rick owens collaboration with a converse the zebra print faux shearling  Hoppers with the signature exaggerated tongues. I didn't see the tongue  They were tucked into his pants, but I did note the weird toes the square toes  with vents  And that's how we were able to track it down. I have to give credit to a tie  In our marketing department who said oh it was easy. I just looked for  vented toes zebra print converse  And they came right up  And they came right up they're wild looking they honestly they they were more interesting than panos was panos, uh  Got robbed it turns out  You may not you don't you can you don't have to say anything if you don't want to talk about the gossip

Start time: 349.24
End time: 354.16
Speaker: Christina Warren
Transcript:  I'm like, no we can talk about I mean, but um, i'm missing the context here. I guess so, uh

Start time: 355.62
End time: 397.18
Speaker: Leo Laporte
Transcript:  I think it was paul therot who did the legwork and got it confirmed by a couple of sources  Uh that the material panos was going to give on day two. He did the day two keynote. We covered them both live  So that was fun  Uh was  essentially stolen by on day one  And so he was left with a keynote with nothing  Oh now much to talk about and it kind of felt that way i'll be honest  he waded into the audience and was really pumped about you know, how exciting things were but  I wasn't a whole lot to talk about and I think it turned out that he kind of it was it was unfortunate because he you know  He's a he's got his he's very enthusiastic. He's a good speaker  So he's a great speaker. He's a great speaker

Start time: 397.50
End time: 418.56
Speaker: Christina Warren
Transcript:  Um, yeah, this is this is the weird part when you're hosting the show like there are so many different moving parts of the live production  That I didn't know anything about who and what was supposed to say anything great, you know  So i'm sure that the the people in the control room did but I did not so  Um, that was I completely missed all of that. But well, I I have my notes from the keynote and um

Start time: 419.78
End time: 456.24
Speaker: Leo Laporte
Transcript:  It was the only couple lines panos pane revival meeting time  pumped  And what does it mean for us as people?  That was the entire  Though but but I do have to give a lot of credit to stevie batish  Who is a technical fellow?  At microsoft's applied sciences group  Who really gave I you tell me if you agree or disagree  I think the best rundown of what microsoft's plans are with ai and how ai is going to integrate into microsoft's products in the future  Yeah, how much of that did you get to see? I don't know if you got to see it. No, I well

Start time: 457.14
End time: 460.64
Speaker: Christina Warren
Transcript:  I have to catch up on on all the stuff afterwards because yeah, you're backstage

Start time: 461.72
End time: 471.38
Speaker: Leo Laporte
Transcript:  You're behind the scenes  And this was the very end of the day two keynote. So you're probably they're already probably going let's you know powder christina's nose  Okay, get ready, you know, yeah

Start time: 472.40
End time: 501.32
Speaker: Christina Warren
Transcript:  Yeah, I was like watching as much as I could and then I watched after the event  But no, you're you're exactly right like during those things when we're trying to go backstage and get places set up  Like I literally like had my phone like up and was like, you know watching stuff  But um, but what I could see in real time was was more limited like there were some instances when I was  Be backstage and interviewing people right after their you know talks and I could see like the last you know  Five or ten minutes or so but um would miss the earlier parts  And so I had to go back and watch a lot of stuff ai has been the non-stop

Start time: 503.44
End time: 534.98
Speaker: Leo Laporte
Transcript:  Subject of this show for the last probably eight weeks. I mean it is it is all we talk about  Um, and it was of course for microsoft the big really the big reveal microsoft is investor, uh an open ai  To the tune of 10 billion dollars, although that seems like a good deal of that is in kind  uh donation of azure time  Um, because of course ai these models take big cloud  massive clusters like yeah to create yeah, no it needs

Start time: 535.96
End time: 562.80
Speaker: Christina Warren
Transcript:  No, exactly. No, and the gpu like usage is insane. Um, especially when you're training the models  When you're running them, I mean they're working on ways to make that  Better but but even when you're running certain ones like gbt4 as example is very gpu intensive  Which is one of the reasons why it is constrained right now both for people who want to pay for access to the api  And um also why it's more expensive and so even if you pay for like chat gbt plus you're limited to the number of um

Start time: 563.24
End time: 599.92
Speaker: Leo Laporte
Transcript:  Queries you can use 20. I paid 20 bucks a month. I can only do 25 queries a day  Right, right, and it's just because in the last three weeks i've not done i've done none  Of those things where they wear off quickly dan it's also been a big part of your world I imagine because  Uh a number of journalistic entities including cnet have turned to ai to write their articles  And I think there's probably some concern among, uh, journalism students that they may not have a job when they graduate  Do you do you talk about that at all dan with your with your uh, your students I

Start time: 601.64
End time: 606.90
Speaker: Dan Gillmor
Transcript:  I've been bringing it in i'm i'm not teaching journalism these days. It's more media literacy

Start time: 608.06
End time: 620.22
Speaker: Leo Laporte
Transcript:  But well, it's even more important there because the first thing  I mean if you want to talk about the imminent hazards of ai it's  It's the disinformation pile that ai is going to create up to the 2024 elections

Start time: 622.52
End time: 670.38
Speaker: Dan Gillmor
Transcript:  the yeah, the authenticity is kind of important and  Uh  I I guess I have so many thoughts about this and i'm also trying really hard not to get caught up in the hype  because I think a whole lot of what's going on now is  uh a  What amounts to a transference of the cryptocurrency?  hype to uh and and  Investments boy put that in quotes  uh to  ai and  We're gonna see a whole bunch of new  Sleazy stuff and victims. It's I mean  It's it's it's like a repeat but that you know, wash rinse repeat is the way it goes in tech

Start time: 671.00
End time: 679.17
Speaker: Larry Magid
Transcript:  What do you know?  What do you make of sam altman being one of the many people who have a lot invested in ai going around calling it an  existential threat

Start time: 680.06
End time: 685.46
Speaker: Dan Gillmor
Transcript:  you know i'm  We're we're on a family show here so

Start time: 687.04
End time: 691.10
Speaker: Leo Laporte
Transcript:  You can use uh initials if you want to say bs for instance, you can say that

Start time: 691.78
End time: 703.38
Speaker: Dan Gillmor
Transcript:  Well, look, is it worse? This is there's there's so many things I would say about the guy  but you know first of all calling it open ai  Is one of that ought to go in quotes

Start time: 703.48
End time: 720.48
Speaker: Leo Laporte
Transcript:  Well, it was intended to be wasn't it when elon musk and sam and others founded it  The whole premise was we can't let google and microsoft and facebook  Own this space and do in a closed fashion. We've got to create an ai  Open development, but that didn't happen did it?

Start time: 721.60
End time: 765.00
Speaker: Dan Gillmor
Transcript:  well, if this is either one of the great bait and switches of all time or  uh that  You know amazingly they change their minds when a whole bunch of money shows up  and  I gotta go with both. I I think this is  It really bothered me and the idea of this guy running around the world  uh, the listening to her give me a break and  Goes to washington says regulate us before it's too late. What he means is regulate us before we have competition  So we are locked into place as the winner  That's what they're really doing with all this. Please regulate us a few days ago. There was a um

Start time: 766.26
End time: 855.71
Speaker: Leo Laporte
Transcript:  for the center for ai safety  Released a statement on ai risk signed by  Sam altman and a lot of people I highly respect the statement was short and sweet  Mitigate this is it mitigating the risk of extinction by the way  extinction  They don't say of whom but i'm presuming they mean our extinction from ai  Should be a global priority alongside  Other societal scale risks like pandemics  And nuclear war that's it  Signed by jeffrey hinton the google's retired google scientist who was one of the fathers of large language models sam altman's  On this list bill gates  signs this  Uh pretty much a who's who of scientists bill mckibben who is certainly up to date on extinction events  Uh, he was one of the first to talk about climate change as an extinction event  um  lauren's tribe from harvard  kevin scott the cto of microsoft peter norvig  from stanford, I mean some really  Rust rusty schweigert the apollo 9 astronaut  Uh are all worried about the extinction. I have to say when it comes to sam altman  Maybe i'm very cynical. It feels like maybe this is look that's not about regulatory capture  Maybe it is but I think more it's about like  See, this stuff really works

Start time: 856.56
End time: 883.96
Speaker: Christina Warren
Transcript:  like  I mean, I mean, I think you might be right but I  I'm going to take a cynical approach to even that statement. I think that that has been  I think it's been misconstrued  I mean, I think that really that is just saying that the same way that that nuclear and many other technologies can be used for bad  This is a very sanguine statement basically saying that  That ai especially as it evolves could be used for for bad purposes. I know but there also should be a global priority like

Start time: 886.06
End time: 902.39
Speaker: Leo Laporte
Transcript:  We should get a we should create a commission or something or I mean we probably should I mean we probably should I don't  Think so. I think I am so underwhelmed by what  Ai it's not ai. This is this is a lies on steroids. This is just a  chatty bs

Start time: 903.32
End time: 907.60
Speaker: Christina Warren
Transcript:  And uh, well the chat components are I mean some of the other stuff some of the general pilots very cool

Start time: 907.90
End time: 923.86
Speaker: Leo Laporte
Transcript:  Generally interesting your github copilot people have it's been out for a couple years now people use it  Um, you would never run code on unchecked  The no obviously not  Well, no, no, but is that obvious? I mean, I don't know. No, I mean, I well I think right now it is obvious

Start time: 923.88
End time: 1002.98
Speaker: Christina Warren
Transcript:  I mean, I think that in a couple of years when the models evolve  It might not be as obvious and that you might actually be running certain types of code that would be auto generated the same way  You have I mean for instance, um for several years now, uh market watch has done, you know, just like auto generated  Articles about the stock market that are very very inconsequential  So I think that for some boilerplate things where if you're generally running the same block of code every day  But a different, you know function is plugged in  Why people are already automating things that way already, right?  So I I don't think that it's that much of a stretch to say that you could be running something that was ai generated  Um, but I I think that  Whether it needs to be seen as this way whereas this is like this existential threat right now  I would agree with you probably not  But I I do feel like I don't know  I personally think that a lot of the framing around that simple letter which was in response to  a very hysterical  Petition that people put out which to me read as being like hey we missed out on this wave and now we want to stop  Other people from profiting off of it because we can't profit off of it. Uh, so let's pause everything for six months  I I just read this as  This should be treated the same way that we treat  other types of technology that have had  Incredibly consequential both positive and negative

Start time: 1003.68
End time: 1050.10
Speaker: Larry Magid
Transcript:  Impact on the world. I can't think of any technology beginning with the wheel and the fire  That doesn't have positive and negative implications, right? And it's really the question of how you use it  I I am not particularly worried about the dystopian notion that these machines are going to take over the world and kill their masters  I worry a lot about misinformation disinformation  And I think going into the 2024 election  It may be I wouldn't call it an extinction level event, but it could be very consequential  If people are led to believe things that aren't true  including the ability to create photographic or a recorded evidence of  Things that politicians may or may not have done  Uh that could be basically, you know, totally fabricated. So how do we know whether to believe our eyes?  When do we know when something's real and not real?

Start time: 1051.00
End time: 1090.26
Speaker: Leo Laporte
Transcript:  You know, it's really clearly hyperbole to say it's an extinction level of any kind extension level event  But I think there is a danger. I agree with you. I I completely agree with you with from disinformation  But but to me the real danger is not that it'll be persuasive  That people will change their vote because they saw a tweet  Of the pentagon on fire. That's not what the risk is. The risk is  That people won't trust anything. This is the right old soviet union technique of flooding the zone  with bs  Uh, I was thinking about to undermine trust in our institutions and our media because I can't believe anything  So i'm not gonna i'm just gonna stop looking I was thinking about this

Start time: 1090.42
End time: 1109.38
Speaker: Larry Magid
Transcript:  So, you know in the news this week there was this recording that apparently was unearthed  Trump essentially admitting that he had classified documents if I were trump's attorney  I would probably claim it's a fake. This is fake. How do we know this is really donald trump?  It sounds like donald trump, but it could be fake and of course it could be fake  uh, but and the only the only the only way

Start time: 1111.60
End time: 1230.26
Speaker: Dan Gillmor
Transcript:  Elon musk has already done that has yet, of course he has and yeah, they've they've already  Played the uh, maybe it's fake. So don't you can't trust it? Okay  It's a little more trustworthy because it came from uh trump's own people  But okay, yeah, well and and the judge the judge in the musk case said, you know, give me a break  No  and I think  but but  Yeah, this is going to be a really big deal the whole deep fake  Uh phenomenon that people have been talking about now gets more real and more  Uh confusing it's a confusion factor as you said, that's really the big one and we have to  work harder on  helping people be appropriately skeptical and  Think about context think about all sorts of things and we're going to have to come up with better ways to to detect  Uh, and to characterize what we're seeing and yeah, I  I'm part of a project. Um  that is  In full disclosure, it's a darpa funded project that's  working on  uh, some of these issues  and it it's  It's really difficult  but  People are looking at ways to counter somebody you ought to bring on to this program some days  uh from witness  that wonderful group that  puts  technology in the hands of people to record and  Care and save human rights abuses  Uh, uh, sam gregory is what i'm talking about and  they and others  A bunch of folks in this area have been looking at ways. Well, how do we?  How can we maybe start thinking about provenance of information? How can we?  Think think about something that has a watermark from the second it was created

Start time: 1231.40
End time: 1234.28
Speaker: Leo Laporte
Transcript:  Yeah, that's interesting. That might finally be used for nfts

Start time: 1237.17
End time: 1304.09
Speaker: Dan Gillmor
Transcript:  Tremendously. Well, it's it's kind of sort of  It's kind of sort of the nft thing but done  more correctly and  Without scams attached  uh and  We're not it's really difficult because it creates a whole set of other problems including kind of  perpetual copyright and control if  By the person created it does you want that? No  Uh, how how do you deal with the fact that every single bit of media?  Created today  Is at some level being?  uh  Changed as it's not the original. What is the original? What does that even mean?  when  And this is real ai stuff when ai has  Changed it from this from from the microsecond of creation into something that it wasn't you take a photo with your  any modern  camera  And it's not what you  Saw with your eyes. It's already been manipulated  It's kind of a heisenberg

Start time: 1304.72
End time: 1308.70
Speaker: Leo Laporte
Transcript:  Heisenberg's media uncertainty principle that the power so we're we're

Start time: 1310.24
End time: 1317.54
Speaker: Dan Gillmor
Transcript:  always ai is  It's going to be bad and we have to help people but I think you make a point though that it's we've always had a certain

Start time: 1317.62
End time: 1343.98
Speaker: Leo Laporte
Transcript:  amount of this. I mean the only thing that's  Really changes the quantity that ai can generate  at speed  Because we've always had a certain amount of disinformation  Russia, you know has famously had a troll farm building  You know disinformation using social media to do just disseminate it back in 2016. I mean  It's not new. It's it's just the quantity and the speed of it. That's new. Yes

Start time: 1344.80
End time: 1352.54
Speaker: Dan Gillmor
Transcript:  Well when you talk about quantity more people get misinformation watching fox news than probably all my point  twitter bots put together

Start time: 1353.58
End time: 1379.30
Speaker: Leo Laporte
Transcript:  so uh  I think it's a mistake to say all this existential threat from ai when you got fox news  Right  I mean, it's gonna be some people watching you see what are you talking about fox?  This is fair and balanced  Uh, and maybe maybe you feel it is I think the dan's larger point is absolutely well taken which is all media is essentially a creation  Uh, you know storytelling around what actually happened sure

Start time: 1380.16
End time: 1430.82
Speaker: Larry Magid
Transcript:  That's that's the nature of it and and no media tells the entire story  I mean, it's just it's it's not enough space  In any publication or broadcast to tell the entire story of anything  So even honest journalists have to pick and choose what they decide to emphasize around a story or what stories to cover  And you know it creates this that you know, we can create a sense of urgency about something that exists  But essentially doesn't isn't really an issue. So fox for example  Will take a case where maybe an illegal immigrant created committed a crime  And make it look as if you know immigrants are on our major threat to american law and order when in fact  Yes, there are cases where immigrants commit a crime  But why was that crime featured on national news when there were thousands of crimes?  That took place that day that weren't featured on national news and that is the process of journalism is picking and choosing right?

Start time: 1431.54
End time: 1436.44
Speaker: Leo Laporte
Transcript:  Right, uh, and you can say well journal go ahead. You're the you're the journalist. Go ahead. I'm sorry

Start time: 1437.62
End time: 1453.04
Speaker: Dan Gillmor
Transcript:  the idea that journalists do context is  Amusing to me because journalists don't do context as a rule  should they  Of course. Yeah, but it's never been part of the uh, except just the special cases just never been part of what people do

Start time: 1453.28
End time: 1481.54
Speaker: Larry Magid
Transcript:  Yeah, well, but journalists pick and choose so for example, if there was a random murder in sincernati  Chances are it wouldn't make to national news if some famous person were murdered. It would make the national news  It's still just a murder. I mean, it's not just a murder, but my point is it's the same crime  Right because it's a famous person. It's now national news  Um or because a person whoever committed the crime maybe elevates to national news  So that's the case where journalists do take some kind of in one of many examples where journalists make some kind of contextual decision

Start time: 1482.10
End time: 1521.14
Speaker: Leo Laporte
Transcript:  About what to emphasize. Well, let me ask this dan you're at the cronkite school  Uh, clearly walter cronkite who had 30 minutes a day to tell us what happened was making decisions  About what to report what not to report  We trusted him  Um, but perhaps we were deaf to the notion that he was in fact  Editorializing I mean that's  The process right?  Was it just our naivete that we thought well we could trust the new york times and walter cronkite and  Huntley and brinkley and we used to what we were a huntley brinkley family, but uh  But that maybe was our naivete at the time even

Start time: 1521.46
End time: 1521.48
Speaker: UNKNOWN
Transcript:  I

Start time: 1522.94
End time: 1528.68
Speaker: Leo Laporte
Transcript:  Mean the vietnam war didn't suddenly become a terrible war because walter cronkite. No suddenly noticed

Start time: 1529.90
End time: 1550.02
Speaker: Christina Warren
Transcript:  No, I mean if anything you could argue that the government which they did  I mean they did this repeatedly with edward armero. Sorry to interrupt dan  but like that, you know where they would intervene and try to you know  Take shift and take control over what the networks would allow  The the newsmen to say and i'm i'm sure that that conkite faced some of those same challenges

Start time: 1550.20
End time: 1557.28
Speaker: Leo Laporte
Transcript:  But maybe easier in fact to spread this information when there's only a handful of sources of information and they're all trusted

Start time: 1559.10
End time: 1570.74
Speaker: Larry Magid
Transcript:  Edward and murrell were an army uniform while reporting  I mean he was literally, you know in bed with the military. I'm not saying he wasn't a great journalist  But clearly that that had to have some influence on him. Yeah

Start time: 1571.46
End time: 1678.59
Speaker: Dan Gillmor
Transcript:  What do you think those were more naïve?  We were yeah, I think the 50s and 60s were more naïve times until the vietnam war  Got to the point where it couldn't be hidden  How bad it was and but can a lot of what?  In the sort of golden era of the three network model  They did try hard to do  A good job on what they did but a lot of  The problems were in what they didn't cover for example, they did not cover civil rights until they were forced  uh, so  the  but there was that there was a famous turning point with cronkite where  He basically said this is this is nuts about vietnam. This is crazy  We can't win this thing. We're we're we're being lied to and kind of sort of said that on the air. Yeah  And that that really  there's a famous story of linden johnson turning to somebody in the  White house and saying well if we've lost cronkite we're done and  It a lot of the rise of right-wing media stems from the  uh  Substantial part of the population certainly not a majority but a significant part that  Never trusted the three networks, right? Right through them new york liberals and  wanted and were  Advocating something different and from their perspective  better leavening of the  What they believed was this entirely  Liberal driven agenda was it it was 1974 so it'd be uh

Start time: 1684.01
End time: 1693.78
Speaker: Leo Laporte
Transcript:  50 almost 60 years ago 50 years ago. Here's walter cronkite, uh  And his this was what changed the fate of the war I think for it seems now more certain than ever

Start time: 1694.40
End time: 1714.66
Speaker: Clip from Walter Cronkite?
Transcript:  That the bloody experience of vietnam is to end in a stalemate  But it is increasingly clear to this reporter that the only rational way out then  Will be to negotiate not as victors  But as an honorable people who lived up to their pledge to defend democracy and did the best they could

Start time: 1715.98
End time: 1749.42
Speaker: Leo Laporte
Transcript:  He's basically saying let's get out of the war  And that was a watershed moment because he was so trusted but I again  Asked the question  Which is worse for disinformation when you have a hundred thousand news sources all of which are untrusted or three news sources of  Which are highly trusted  But may be just as prone to disinformation. I mean, I know they're trying  But but they're human it seems to me that that's actually more risky

Start time: 1751.74
End time: 1803.46
Speaker: Dan Gillmor
Transcript:  I agree with that if they're if they're controlled by  Other influences  in a  In a more direct way we ended up  There were other media and there always have been media the smaller outlets and people who  Got at news that the big ones didn't  and  it eventually would filter up into the public consciousness, but  We  And and you know me, you know that I think that a hundred thousand  Outlets is it's some level better  But we aren't doing a very good job of sorting it out  And helping other people is that our fault? That's really the problem as consumers. That's our job and that's what you're teaching basically

Start time: 1805.78
End time: 1805.86
Speaker: UNKNOWN
Transcript:  It's

Start time: 1808.10
End time: 1829.84
Speaker: Dan Gillmor
Transcript:  We all have we all have to take some responsibility for knowing what we're talking about and we're not  Generally doing that very well. It's it's  difficult and it's  It's going to be a process. It's going to take a long time  But we don't really have an alternative unless you prefer censorship, right? And then you're in a worse position than you were

Start time: 1830.80
End time: 1863.51
Speaker: Leo Laporte
Transcript:  so disinformation is one way that ai could I think extinction is such a strong word, but we'll  We'll stipulate that's okay extinction. Maybe that's one way  Uh, how well it's what what are they it seems to me? They've read too much science fiction  They've watched too many movies of people getting locked out of the pod bay and and uh whopper, you know  declaring nuclear war and I mean I you know, I don't know if ai  Poses a risk of extinction. That's that's  And if so, how?

Start time: 1865.90
End time: 1901.76
Speaker: Larry Magid
Transcript:  On the front cover of connect safely. I reprinted my mercury news column  Called ai makes the mistakes, but could it destroy us and and and my conclusion is it's not going to destroy us  And I I also think that we really do have to look at the possibility  I mean, maybe it's the eternal optimist in me, but we have to like any other technology weigh the benefits against the risk  And I think the benefits are enormous and I think the risk is substantial  But at the end of the day, I mean, I think we can I think we can manage this one  I'm not losing sleep over it. I lose a lot more sleep over climate change than I do over the eye

Start time: 1901.98
End time: 1940.66
Speaker: Leo Laporte
Transcript:  Yeah, if you want an extinction event guess what's barreling down the pipe at us  Increasingly rapid speed and I don't care how much you trust your favorite news source. No one's doing enough to  to stop it  I mean that's an extinction event, right? Exactly. And I think that's headed right our way  With no evidence that we're doing anything to stop it  I mean that doesn't mean you can't have more than one you can have more than one extinction events. I'm not  Saying that there's a lot of other bad stuff happening  But ai does not seem to rise to that level of danger and we have decades of evidence that climate change is coming

Start time: 1941.14
End time: 1946.34
Speaker: Larry Magid
Transcript:  And then it's extremely dangerous. I don't know what day it's gonna. Yeah, you know, and we continue to ignore it exactly. Yeah

Start time: 1948.34
End time: 2007.98
Speaker: Leo Laporte
Transcript:  All right  Let's take a break  Enough ai although there's a lot more ai stories  I guess I might have to throw them in  Uh, there was a chat bot designed to help eating disorders  They fired the entire team that was on this hotline  Uh  the uh  Neda the national eating disorders association  Uh had a website where people would go to get information about uh eating disorders and what to do to fight them  They decided we don't need people. Let's just get a bot named tessa  Tessa started giving people dieting advice, which is exactly what you don't give somebody who's suffering from an eating disorder  um  That's just an example of hit to me over  Promoting the the potential of ai. I don't think ai is all that

Start time: 2008.98
End time: 2018.68
Speaker: Larry Magid
Transcript:  I really don't it may have potential but it may but  Potential something may happen in the future was fooled by these stories and I think as a media organization

Start time: 2019.84
End time: 2028.64
Speaker: Leo Laporte
Transcript:  It's our responsibility to tell people no a chat bot should not be giving advice on eating disorders  Why would you even think that?

Start time: 2030.18
End time: 2055.78
Speaker: Larry Magid
Transcript:  Well, it's the reason why I don't rely on autopilot on my tesla  Although I do believe we will reach a day someday when cars can safely drive themselves. We just aren't there yet  But we need to be experimenting and building it to get to that point  So, you know the the question is, you know  Should we be drinking the kool-aid this quickly as opposed to simply supporting the fact that research and experimentation needs to happen  With the appropriate warnings and safeguards

Start time: 2058.22
End time: 2166.66
Speaker: Dan Gillmor
Transcript:  Okay, we can all have to think about the whole the whole I mean the the employment  Angle to it is really going to be key  Big business wants ai  In substantial part to get rid of human labor  that is the  fundamental  driving force behind  a lot of corporate and expensive adoption of ai and that that this is  uh  This is nirvana. You you can get higher return on capital by getting rid of these annoying humans  Who need health care who need money?  It's it's like  And we we if we don't really focus on a lot on that as part of this and put that  Not just in sort of by the way  They got the reason this idiot chat pod was giving bad advice is that they wanted to get rid of people, right?  Right, right and and and but make that really clearer and louder and the other thing about we've been using ai in  Making decisions for now a number of years in other contexts  It's now just starting to affect  The white middle class  Uh in a profound way when people have been having decisions made about them and for them  with ai  Augmented tools for years including redlining of mortgages  uh health care decisions  Who gets a job all sorts of stuff  Oh, and we didn't give a damn about any of them or we didn't give enough of a damn and suddenly it's hitting us  Oh gosh, this is really dangerous. Yeah, that's a really good point

Start time: 2166.76
End time: 2181.69
Speaker: Leo Laporte
Transcript:  All the job hunting sites have offered ai help in screening out candidates  Which ended up of course to disproportionately affect people of color and other minorities  Um, yeah, I mean this has been going on for years  Uh, Michael

Start time: 2182.58
End time: 2214.50
Speaker: Christina Warren
Transcript:  I mean totally I mean, I mean if you if you substitute ai for automation, which I know they're not exactly interchangeable  But in many ways that's how these things are being used. Yeah, um, I I think dan I think you're exactly right  these things and these algorithms have been used in very um  Negative ways both for for screening people for for loans as a great example. Um, uh for for job stuff  It could potentially be bad. That's why it's important that there are ethics boards  Um, and and you know, hopefully, um  Yeah, you know bias parties looking at these things

Start time: 2214.60
End time: 2237.70
Speaker: Leo Laporte
Transcript:  I'm sure you have the best health care in the world because you work at microsoft  But honestly, I know that our health care is very much influenced by I wouldn't call it ai  Uh, I know but I think the actuarial  Actuarial tables are a extinction level threat to mankind  Because they're just looking at statistics is the same thing  We can't get earthquake insurance in in california

Start time: 2238.54
End time: 2288.48
Speaker: Christina Warren
Transcript:  No, I mean and look I like my parents who are you know, um in their 70s, you know  Are healthy. I see the way that they are treated by doctors based on certain things  Yeah, no not at all  But but they are using but but ai will be used in some diagnostics criteria and in some cases that might actually be useful  Right like in some cases I could see that that might actually be useful than the current  Model which is that you have people who if you are over a certain age will immediately look at you or a certain gender  Or a certain race will immediately dismiss any of your concerns and will just make a diagnostic based on you know, um  Whatever they they they plugged into something. Um, whereas if something's more complex potentially some of these systems could help but no  You're not wrong. I mean like  Even when you have good health care getting you know, doctors to actually listen to you is very difficult. Yeah

Start time: 2289.32
End time: 2297.94
Speaker: Leo Laporte
Transcript:  Well, we have to do that we have to ration health care we don't have enough it's expensive right and  We can't all get good health care, you know only the rich I guess

Start time: 2299.24
End time: 2315.68
Speaker: Dan Gillmor
Transcript:  well if we took away that uh massive  portion of the spending that's going to  insurance companies, uh for the sole purpose of not giving us health care, uh, maybe we'd  Be able to afford more. I don't know call me crazy

Start time: 2316.78
End time: 2372.74
Speaker: Larry Magid
Transcript:  Yeah, the other thing about health care is I mean the more i've  experimented with various  You know tools to do diagnostics the more skeptical I get about the accuracy of diagnostic testing  I mean certain things are obvious like you can take an x-ray and see a cancer maybe but other things like sleep apnea  it's a lot of  I don't know. I wouldn't call it pseudoscience but  Approximation of determining what what constitutes a an illness and what doesn't there's just a lot  We don't know obviously the covet situation was one where we went through three years of kind of guessing we were talking earlier off camera  About you know washing our hands and washing our vegetables and things that we were led to believe by very credible knowledgeable. Well-meaning  Scientists were the right thing to do not because they were trying to fool us or manipulate us because they just didn't know  And and there's still a lot we don't know yeah third it's estimated that 30 percent of our health care spending goes to administrative costs

Start time: 2373.60
End time: 2375.00
Speaker: Leo Laporte
Transcript:  That's a significant portion

Start time: 2377.28
End time: 2398.66
Speaker: Dan Gillmor
Transcript:  Larry the scientific process is  Something to celebrate of course and yeah, we made a lot of mistakes early on and so did people we should have  Who should have done a better job?  world health organization being one of the top ones, but  Different than sort of willful. Oh, of course

Start time: 2400.32
End time: 2440.74
Speaker: Leo Laporte
Transcript:  Misinformation along the way there was I think though and I don't know for a fact, but i've seen it said that there was some bias  also  because the medical  Establishment had for so many centuries fought off the miasma  Theory of illness that you got sick because of bad air  They were very very reluctant to say that this disease was caused by aerosolized particles  And and it was that's a bias, right? That's a that's not scientific method. That's like, oh, no, we don't want to go there  And um, that's a good example of where the scientific method can be overruled

Start time: 2443.12
End time: 2486.58
Speaker: Larry Magid
Transcript:  By I think it's part of the scientific method is studying and restudying and reinvestigating it  I mean, why are drugs pulled off the market besides the political ones like, uh, you know the  abortion pill  But most drugs that are pulled off the market are because subsequent research has proven that they are less helpful  Than either they are more harmful than helpful and and that's part of the scientific process  And it didn't mean it was it was foolish for us to have taken those drugs when we believed they were helpful  But it just means that we had incomplete we were basing those decisions on what later turned out to be incomplete information  And and that's what's sort of scary to me when I think about all of the decisions that I make as a health care consumer  Based on what is clearly incomplete information. So do you think this is a place ai can help?  I do

Start time: 2488.06
End time: 2530.90
Speaker: Dan Gillmor
Transcript:  Eventually, I think ai can make is going to be great at making connections that we otherwise  Might not that's spot. That's what it seems the best at. Yeah, and it has been we've seen things being used that way  Uh  The issue as in that test  The you were just getting results from is  drawing definitive conclusions, right from connections where  Uh, you know the classic  uh correlation is not causation and and we  Sorting out the difference. I mean, I think ai could give us all kinds of  Wonderful things to investigate further

Start time: 2531.90
End time: 2554.16
Speaker: Leo Laporte
Transcript:  Well, we know one area that's huge is protein folding  Where ai is so much faster and so much more effective and has really been solving a problem  That is going to have a significant  Impact on health care  This is from science magazine. The game has changed ai triumphs of protein folding

Start time: 2554.34
End time: 2554.48
Speaker: UNKNOWN
Transcript:  Yeah

Start time: 2555.68
End time: 2570.50
Speaker: Leo Laporte
Transcript:  Remember folding at home where  Yep, you you could devote a portion of your computer idle computer time to solving these folding problems  ai has already done more than all folding at home  over the years put together

Start time: 2571.48
End time: 2581.76
Speaker: Christina Warren
Transcript:  Yeah, I think that study which was one of the things that get shut down last year actually  um, but yeah that that that's a great example of  Where ai is very very useful

Start time: 2582.56
End time: 2593.30
Speaker: Leo Laporte
Transcript:  So i'm not i'm not saying ai is useless, uh, i'm saying the the large language models are  For the most part seem to be uh, bullshit generators

Start time: 2594.16
End time: 2639.52
Speaker: Larry Magid
Transcript:  Um, but I think the large language model though if they have the right database underlying them  Can be useful and I think they can in health care  They can be useful also in doing the things that a lot of doctors do today  Which is to take a bunch of information and make a conclusion as to what the best course of action is  Yeah, and that's based essentially on  Actual intelligence the doctor knows this and that and has this data and makes this conclusion  But with an ai system that has access to a huge amount of data assuming the data is accurate  It might be able to make a better recommendation  Than than a typical human doctor could especially once you get out of the big cities when you got the big universities  You know you get into places where you can't get the world's greatest doctors if you can get ai that can simulate that kind of  Intelligent diagnosis it could benefit humankind

Start time: 2641.42
End time: 2647.14
Speaker: Dan Gillmor
Transcript:  All right, I want to take a break we're assuming it's accurate assuming it's accurate assuming it's accurate. Yeah, yeah, of course

Start time: 2647.94
End time: 2651.30
Speaker: Leo Laporte
Transcript:  Uh, and that's that's maybe one of the biggest challenges is figuring out

Start time: 2652.04
End time: 2673.96
Speaker: Larry Magid
Transcript:  But that's true with even current medical information with everything but humans are making the decisions of machines, right?  You've got to be look look at look at this information. I voted for xyz  Because I believe this and if this turns out to be false you just made a human decision that was based on bad data  and frankly, that's  How we could wind up with another trump term. Maybe we let ai fill out the medical forms

Start time: 2674.10
End time: 2720.52
Speaker: Leo Laporte
Transcript:  But not decide who gets a liver. How about how about that? I would agree with that. How about that?  Our show today brought to you by a great panel really good to have dan gilmore here from asu  Where he I love it that you're now working with people on media literacy. It's just a very important area  I think that's fantastic at dan gilmore on  mastodon d-a-n-g-i-double l-m-o-r  Great to have you larry maggot who is going to tell a horrific story in a little bit  President and ceo of connect safely.org something that happened to you  I wanted to get you on as soon as I read that but I knew we were having you soon  So thank you for being here and christina warren who has by every right to be completely exhausted  From a week at field and then a week last week you were in atlanta for for what?

Start time: 2721.50
End time: 2760.84
Speaker: Christina Warren
Transcript:  For render atl which is um, like a big kind of tech and a music conference  That is kind of focused on the southeast and a lot of the black tech community is there  Which is really great and just lots of different people from lots of different backgrounds  So it was a really really good time. Were you there in an official capacity or  Yeah, we had a booth for for github. I mean we we actually had a nail booth, which was really fun  So we were doing people's nails. We had um, um, like uh, nail wraps basically that had like little like octocats on them and then we had  Other colors too, which was really fun  but honestly like we I I went last year just like in a in a personal capacity and um  So there's a number of my colleagues and we just had a really good time and we just wanted to support the community

Start time: 2761.12
End time: 2766.54
Speaker: Leo Laporte
Transcript:  So what was the ai conversation there like I imagine it was fast and furious

Start time: 2767.38
End time: 2841.58
Speaker: Christina Warren
Transcript:  Yeah, I mean so what was interesting was that last year at render and there was a lot of  Web3 and and and blockchain talk and and this year  There interestingly there wasn't as much ai as I was expecting we were showing off github copilot  One of my colleagues rezelle scarlett who's amazing  She gave a talk on on github copilot and kind of showing, you know what it can do in terms of um helping you, you know  You know improve your productivity  And and get some some coding things done faster  um, but um  I think that there is still kind of a question for a lot of people's not similar to the conversation  We've been having here about what are the benefits? What are the challenges going to be?  Um, but I have to be honest. I mean there is also  And some of this is going to be negative  But there is a massive opportunity right now because of the hype and the excitement and and the fire  Around ai, you know, you see some really interesting  things being built up even if you don't believe that large language models are the  You know future. Um, there are still some really even if it's not going to save humanity  There are still going to be interesting things you can do and can benefit from  Um because of tools that people are building right now and I I personally find that exciting. Yeah

Start time: 2842.96
End time: 2848.88
Speaker: Leo Laporte
Transcript:  Render atl how fun well i'm yeah, I know you'd probably run asleep right now, but uh, thank you for staying

Start time: 2850.52
End time: 2853.90
Speaker: Christina Warren
Transcript:  Obviously well, hey look, it's not i'm not the one who is super early for so like

Start time: 2855.10
End time: 2860.54
Speaker: Leo Laporte
Transcript:  Yeah, I know it's this is normal time for you  Are you going to be home for the next couple of weeks?

Start time: 2861.50
End time: 2873.52
Speaker: Christina Warren
Transcript:  I think so. I might be going out of town, but if I do it's not for work  It'll be for like a concert. So, uh, I wonder who  No, no actually that that's that's in a little while. This would be a ben folds actually

Start time: 2874.42
End time: 2885.00
Speaker: Leo Laporte
Transcript:  I've just got the new ben folds album. That is he is so good  He's so good. Yeah, what happened to the five is just the ben folds one now. What is the well he goes back and forth

Start time: 2885.40
End time: 2889.98
Speaker: Christina Warren
Transcript:  Um, and and so like I think sometimes he does solo things. Sometimes he does it with the band, but yeah

Start time: 2890.56
End time: 2903.08
Speaker: Leo Laporte
Transcript:  I'm listening to it. I'm thinking this is like old people music  So i'm glad glad to know a young person likes ben folds. Micah likes ben folds, too  But I thought this is kind of kind of nice and sweet and you know

Start time: 2904.34
End time: 2924.12
Speaker: Christina Warren
Transcript:  Yeah, okay. I'm gonna say this  I think the best album one of my favorite albums of the the 2000s was the album he did with William Shatner  I'm not even joking. I'm being completely serious. It's called has been it came out in  2005 and  William Shatner produced by ben folds. It's a really really good record. So that that's my free. That's my free. That's my free

Start time: 2924.68
End time: 2930.70
Speaker: Leo Laporte
Transcript:  Advice to people that's your pick. I got something to listen to tonight. Wow, which is good because succession's over and i'm really reclaimed

Start time: 2931.16
End time: 2936.83
Speaker: Christina Warren
Transcript:  Oh my god, I we need to talk about that. We'll talk save save that I will save it. I will say  I gotta find something

Start time: 2939.44
End time: 3223.08
Speaker: Leo Laporte
Transcript:  Our show today brought to you by express vpn  They're really good these guys are coming up with analogies for using a vpn this is the best yet  Using the internet without express vpn  Is like forgetting this is very timely actually to our early conversation forgetting to mute yourself on zoom  And having your co-workers hear something you don't want them to hear  Well, it could just be a bit of harmless banner  But if it's about the boss and the boss overhears you well now you got a problem  See privacy isn't you know, we often hear them say well if you've got nothing to hide. What are you worried about?  everybody  Has something to hide right everybody closes the bathroom door  You need a vpn internet service providers are not only know everywhere you go and what you do on the internet. They're  Allowed to sell it on to marketers to data brokers  uh ad companies  That will then use your data to do all sorts of stuff target you follow you around  That's just one of many reasons a good vpn is important. The reason I use express vpn is because it is literally  The best vpn out there for several reasons  They do not track you in any way and they go the extra mile to prevent that they run  Their own software called trusted server which runs in ram sandbox  So it cannot write to the hard disk you press that button on your express vpn app  You launch the server it's running in ram and as soon as you close it as soon as you leave the server  It goes away with no trace left  But as if that weren't enough they even run a special debian distribution on all their servers  That went everyone every reboot wipes the drive and starts fresh  And they do that every day  This is this is how you protect people's privacy. There is nothing on express vpn servers. Not a thing  Very few other vpn companies can say that now express vpn is not free  But this is another reason I like express vpn, but they put that money into infrastructure  So they're fast, which means you can watch hd video on express vpn, which means you can use their you know geographic  You know variability to say let's say i'm in i'm in england and I can watch netflix england or i'm in japan  I can watch netflix japan  That it only works because they have enough bandwidth so you can watch that hd video  It also requires that they rotate their ip addresses fresh ip addresses all the time  So that your ip address is completely random and unrelated to you  that's how you stay safe and of course as  You would expect with express vpn all your traffic is tunneled through an encrypted tunnel  Nobody at a coffee shop or anywhere or your isp can see what you're doing. That's what you want rated number one by cnet  Tech radar it works everywhere. You do phones laptops. They sell routers very good routers with express vpn built in  So your whole house can be protected. It will also run on some existing routers. You can check express vpn's website for more information  I think express vpn is just  Head and shoulders above everybody else if it's time to protect your online privacy  I want you to go to express vpn.com slash twit today. You'll get an extra three months free with a one-year package  exp ress  vpn dot com slash  Twit, please use that address so they know you saw it here. You'll also get that extra three months free with a one-year package  That's your best deal again less than seven bucks a month for rock solid privacy at blazing speeds with no compromises express  vpn  Dot com slash twit. We thank them so much for their support of this week in tech  Uh our colleague michael sergeant  Uh, jason snell and others headed to cooperino tomorrow morning bright and early  Because it's uh, one of those nerd holidays apple does every once in a while  Wwdc the worldwide developers conference and this one might be uh  More important than a lot of apple events in years past it's expected they will announce  We don't know what the call the name of it will be uh, joanna stern at the wall street journal might call it their apple  nerd helmet  their  I'm calling them nerd helmets from now on the vr spectacles. Uh, uh, we don't or ar or mixed reality. We don't really know  Anything because apple says nothing but rumors have been pretty strong that apple will announce this  tomorrow  Uh, are you excited christina? You're the youngest person here this I know no

Start time: 3224.16
End time: 3263.38
Speaker: Christina Warren
Transcript:  Yeah, no, I am excited. Sorry. Sorry. Sorry. No, i'm i'm excited. I'm um, i'm  Okay, i'm like cautiously optimistic because the rumors we've been hearing about this for so long  I'm i'm trying to wrap my mind around this because on the one hand  On the one hand, we know this is a stupid category that nobody wants  Exactly on the other hand it's apple and if anybody can make me spend three thousand dollars on something I don't want it's them  So that's where i'm at the mask. That's where i'm at. Yeah, exactly that that's where i'm at  I'm i'm i'm at like the seams on every level to be absolutely dumb and a complete waste of time  And on the other hand i'm like, okay, but it's apple so that's what mark grumman said

Start time: 3263.54
End time: 3314.44
Speaker: Leo Laporte
Transcript:  He said obligated to get it. He says if anyone can make this product category a success. It's apple. That's fair  But i don't even know if apple has the  Horsepower to make make something that makes about 10 of its users nauseated that seems a strike  Against it has no killer app. No  No, real utility  Is very sexy the first time you use it but has a very  steep curve of  Lack loss of interest shall we say  We say  Um, I just don't see this uh taken off  I I really don't and that would be a big deal if apple were to put so and they've clearly put so much time money money  Blood and treasure into this if it were a flop  I think people would blame tim cook to be honest

Start time: 3315.40
End time: 3353.18
Speaker: Christina Warren
Transcript:  I mean as they should it well, yeah  Yeah, I mean I mean look and we don't know right but I think you're right  I mean, I think that if this is not a success, I think this has to be at his at his feet, right? Um  There there have been products they put out before I think i think apple tv is a good example where they've had to pivot  Apple watch I think was more successful right like it started out as a fashion object  And then they had to pivot the fitness and and I would argue that it owns basically the entire smartwatch category  Um, there are very few exceptions. I mean it is they basically have the whole thing sewn up  so

Start time: 3354.86
End time: 3358.14
Speaker: Leo Laporte
Transcript:  There you said you brought up apple tv as an example of something

Start time: 3358.30
End time: 3406.22
Speaker: Larry Magid
Transcript:  Well, I mean roku roku was an example of a company that  Nobody had ever heard of because it didn't exist until it hit the market way after apple hit with it with a household name  And it did much better in the tv market coming out with a product that was superior  To what apple came up and apple is still trying to catch up in in that regard  So it's not inevitable now. I have to admit even though  I've worked i've written a number of  guides for reality labs  Which is the division of meta that does the virtual reality headsets that there is a huge gap an opportunity  For someone to do this, right?  Christina you work for a company that's had a device on the market for years a pretty good device actually called hall lens  Yeah, which i'm not sure because the price or whatever reason it's just never become a big deal in the consumer market

Start time: 3407.30
End time: 3482.94
Speaker: Christina Warren
Transcript:  Yeah, I mean  They tried right they tried with the mixed reality headsets and it wasn't uh, it didn't work  I mean, I think this has been the the ongoing problem. There are very useful  Ways in industry to use, you know ar  Vr types of devices even google glass, which I mean, I think they finally were tired  But they found success in the industry that way absent was doing interesting things hollow lenses is a good example  But we I still haven't seen the killer app for vr. I think for a lot of us we thought it was gaming  If anybody was going to do that, I I'd still think that that meta with the meta quest devices have probably  Come the closest at breaking through on that, you know hgc and in steam have had the vibe  um, you know headsets but it's remained a niche thing and so  how do you how do you define kind of a  You know a killer app and and not only a killer app but a killer app where people are going to be willing to spend the reported  $3,000 I I don't know like those are my two big questions. It's it's it's the the price is the real thing that that has me  Going nah  You know, I I don't know. I don't know about this because if that price is to be believed  That just that feels like that's an instant  Loss, I just don't know how to do that

Start time: 3483.38
End time: 3514.08
Speaker: Larry Magid
Transcript:  One advantage of that price is you don't have to have a big installed base  To justify the fact that you're doing it. In fact, I remember very early in the days of the macintosh  Steve jobs who would compare the mac to the mercedes-benz and say sure the mercedes the most popular car in the road  No, it's just you know a great car and you know, they they built a reputation based on small market share  But high value to those who were able to afford to buy the product  So it's conceivable that apple could you know sell a small number of these but still gain some kind of traction apple has

Start time: 3514.66
End time: 3522.64
Speaker: Leo Laporte
Transcript:  You know a small  Less than half of the phone market globally  Uh, but but easily the lion's share of profits

Start time: 3523.64
End time: 3617.02
Speaker: Christina Warren
Transcript:  Right and easily the lion's share of profits for developers. That would be my question, right would be because you're not wrong  You can absolutely make a profit having and have a very good business for a small niche device  um  My question would be in the era we're at where we pay what we pay for applications for your phone for your tablet  Even for your game console  Are you going to be able to have enough volume where the people who could create these applications?  Could dedicate the resources that you put into them and that i'm not sure about right because even you know big triple a  You know game makers who have these massive budgets really struggle with that  What platforms should we support the mac is actually a great example there  there are not  real games on the mac the mac is not a gaming platform and it never has been and it probably never will be why because  There's just not the market for it and it's not worth the investment the companies that have put the money into it  Have not gotten that investment back where you do see it is for casual  You know types of games and and things that tend to be laden with  A lot of in-app purchases and and recurring subscriptions and things that apple likes a whole lot  But not necessarily that the you know, hardcore  You know gamers want but when you look at like the multi-trillion dollar kind of gaming business  Like the the big triple a titles aren't on mac products. So  They they could be a success even with a very small clientele. I just I worry  And that part like okay. Well, what about the people building on that platform, right? Because mercedes can be profitable but like  You know apple apple can make money out of it. What about anybody else?

Start time: 3618.25
End time: 3697.34
Speaker: Dan Gillmor
Transcript:  Right larry's when he brought up the early mac  That was a really good point and you think about  the but think about the single application that  carried the mac into  uh the the high popularity where it was  Profitable for everybody in this desktop publishing and  That required a number of things to come together including a laser printer that was affordable and  So maybe there's some if if these rumors are true and I find the three thousand dollar thing  I just don't believe it. I don't I just I think that's absurd but um  I think the there any  seriously interesting application  If the headset is  uh  Approach, you know wonderfully better than anything that's come so far  Is will sell enough to get the next generation going but  You know the killer app for vr is better headsets smaller lighter and that don't give you  nausea, right, you know vertigo, um, and  Once all that's settled i'll buy one  I want I want something that I can wear on an airplane and watch  Imax movies on an airplane totally that's that you know like like you guys that's the killer app

Start time: 3697.76
End time: 3723.00
Speaker: Larry Magid
Transcript:  I have a lot of gadgets including two  Vr headsets. I got both the quest and the quest pro  Many of my gadgets sit in drawers because I just don't get around to using them  Or I don't want to use them particularly in the case of the vr headset. I avoid using it  I actually don't enjoy it. I mean, it's it's a negative. I can't wait to get it off  And and that's not a very good sign for for loving it's not even that I even love the product  I just I really don't like it at all

Start time: 3723.64
End time: 3857.31
Speaker: Leo Laporte
Transcript:  I mean, it's it's a negative. I I play beat saber to lizzo's songs and I think that's kind of fun, but  For how long is great for how long?  Not not for half hour sessions. No, no, no, no, no  And I haven't picked it up lately. I got the quest pro because I want to say well, what's the best in the market today?  Uh, that was 16 hour bucks. It's now down to a thousand which tells you a little bit about the  its sales figures  Uh meta just announced the quest three for 499.99  Timing it of course the announcement perfectly to make sure that apple didn't steal its thunder  But meta's put a lot of money billions tens of billions of dollars into  Vr and yet to find a market for it  um  I just I feel like apple is sailing up  To the new world in their boat and then they look and they say oh look there's there's google on the rocks  Oh, oh dear. There's microsoft on the rocks. Oh my  Here's meta on the rocks. I don't know. Is there anywhere safe to land?  In this territory now I will be watching  We're going to stream it of course tomorrow morning 10 a.m pacific 1 p.m. Eastern at live.twit.tv  Uh, I will be watching very carefully the verbiage because I think  What we really want to know is what apples how apple's positioning?  This it's likely that it's a developer  Kit. Yeah, not even a consumer product but and it won't be out according to rumors until this fall  It's likely it's the the position. I expect their positioning will be  We are aiming at a product  down the road like  I don't know. This is the question is when can they do this that is lightweight spectacles like yes won't nauseate you  Is more of an ar product and i'm sure apple's doing this because they want to say well, what's next after the iphone?  I've seen some pundits say this is the next iphone  But that but the technologies aren't there yet for a long battery life  for a lightweight  Uh heads-up display that you can wear much like you would wear your spectacles. I think that's  five years away

Start time: 3858.12
End time: 3870.16
Speaker: Larry Magid
Transcript:  Four years and meta by the way, it said the same thing. They are also going for  developing a lightweight ar  Glasses, which I think is what most people think is the holy grail of this whole extended reality

Start time: 3870.94
End time: 3929.19
Speaker: Leo Laporte
Transcript:  You know, that's the oh, well, let's put it this way. It's the only thing we  Uh  dan aside watching his imax movie on an airplane is the only thing I can really  See as a mass market for this is something you could wear in lieu of spectacles  You know, they could even be corrective that have a heads-up display  That could that could that could you you're not going to get nauseous because you're still seeing the world  So that's going to solve the nausea problem, but you're getting additional information. It replaces your phone  You've got temple pieces  That can you know give you audio you have some way I don't know how of  Signaling of choosing of controlling it. I don't know if it's by blinking or where you look or maybe you have something in your pocket  You're clicking  You touched a temple. It's a you're you touch there. We it's you can imagine something like that, but the technologies are not there yet  Not yet, and that's it's like ai it's like you're you're you're you're throwing your dart into the distance  And hoping you can hit that target  You know the thing about

Start time: 3929.98
End time: 3952.90
Speaker: Larry Magid
Transcript:  What you're saying leo is actually very profound in a sense, you know  You give steve jobs a lot of credit for inventing the ipod or for being the ceo of apple when the ipod was invented  But really the credit goes to storage batteries  There's a lot of technologies  That made it possible to build the ipod it wasn't that you know  If he had had an idea for an ipod 20 years before that he could have conceived of it

Start time: 3953.36
End time: 3985.44
Speaker: Leo Laporte
Transcript:  But he couldn't have built it affordably, you know, the newton was john scully's vision for right?  And it wasn't it yet wasn't it this could be apple's newton for vr or ar or mixed reality  This could be that prototype  very clunky product  But you're kind of counting on a lot of technologies to develop now we should  You're right on that on the iphone, but apple also facilitated that they basically built a  the chinese  Ability to create those things with massive investment

Start time: 3986.50
End time: 3994.12
Speaker: Larry Magid
Transcript:  So it's that's true, but they but they didn't invent better batteries. I mean none of it facilitated it  Yeah, that technology had had to get here

Start time: 3995.10
End time: 4142.80
Speaker: Dan Gillmor
Transcript:  So all of this is back to moore's law and its equivalence  continuing  with uh  Things getting smaller and lighter and more powerful  in  exponential ways  So it isn't that hard  To look a few feet two years out and and think about how  Quickly micro led has come along true, which was which was a fantasy. Yeah, just several years ago  these the people who do the hardware are  Constantly doing stuff that blows my mind and it's really going to be the hardware people who  make possible  the software piece  to be overlaid on it and  As larry had said about the ipod originally and  I get  It may be closer than we think but positioning this thing  tomorrow  is really going to be interesting to watch because the  If they position it properly which is to say hey  We're taking a long-term view here and make that the central point  As opposed to all of the right?  Hurrah about what you know what you can do today, which isn't much  If they can get the public to understand and  I gotta say facebook meta didn't do a great job of that, right?  They they sort of presented it as a here and now when in fact they were looking long term and and  misplayed that but if apple and others in this market can  Really help the public understand that this is this is a play that's  Feels long term  But it genuinely is coming  uh, and and here's the  Here's the here are the building blocks and you can we can we can easily predict based on hardware  Improvements in the past that transfer into the future at the same kind of moore's law, etc rate  I the case can really be made  for  this  product tomorrow as the  the beachhead  That the public needs to understand where it's going to go. You know, there's really two audiences though

Start time: 4143.48
End time: 4183.16
Speaker: Leo Laporte
Transcript:  This is a developer conference. And so yes, they have to they have to convince the public  I think they have to they have to you're right downplay expectations for the public  because  They don't want people to say well that I don't want that  They they want people to think or to understand this is not what we're going to sell you  This is not for you  We're aiming down the road and then they also have to convince developers  This is something for you because down the road. This is going to be a world beater christina  You talk to developers all the time. How do you position that message?  To developers what if you were in apple's shoes?

Start time: 4184.74
End time: 4219.12
Speaker: Christina Warren
Transcript:  I mean I  I think you have to have some really good first party examples  As I as I think how you how you would have to position that I think you have to have some really  um a good uh, you know kind of first party examples of some things  That why the why this is worth investing in and why this is worth building on even though  The future that we're at right now might not be where we need to be right?  I think that's what you have to do. I think you have to kind of  Parlay that this is this is the step and show some of the exciting things that you can do now right now

Start time: 4219.78
End time: 4237.74
Speaker: Leo Laporte
Transcript:  There is right now there is speculation that no man's sky, which is a pc game that has been adapted for metas  quest  Uh will be there demonstrating their mac version of it  On this so that would be gaming but you'd have to do productivity. You'd have to do productivity

Start time: 4239.10
End time: 4317.62
Speaker: Christina Warren
Transcript:  Yep, I mean look I I can say like in my own mind when i'm trying to justify like how I would spend  $3,000 and and like dan I can't believe that price is real  Maybe if it's a developer kit then that would actually make sense  But but I can't think that that is what they would bring an actual consumer product out for  But in my mind I have to think okay  What if I could have like the equivalent of four high resolution, you know displays in my my field of vision  And I could control my mac that way that could be a productivity thing, right?  That could be something that I could really enjoy where I go  Okay, instead of having to have my 227 inch 5k monitors  I have you know this headset and I can have a really good job of  Of um, you know kind of working in that space and that means that even when i'm on the run  On the go like when i'm working remotely, which is not uncommon. I have access to all of that  So maybe that would be you know, um a productivity thing. Um  But yeah, I mean like gaming is obviously the very easy thing to kind of go out with  this space  This is why i'm excited to watch tomorrow because  One way or another this is going to be interesting. Um, either we're all going to become convinced  Even if it's only for the 90 minutes or however long the keynote is  or we're going to  Walk away and go still don't quite see it. And so either way those these two outcomes are really interesting

Start time: 4318.00
End time: 4346.17
Speaker: Leo Laporte
Transcript:  This will be a master class in expectation setting  Yes  For two different audiences consumer and developer  Uh, I uh, you know, I don't know if it'll be tim cook probably won't be tim cook might be avi  Uh, they have some very good technical people there. I'm not sure who it will be  Um, but I will be watching  You know, I will be deconstructing on the fly because I think there's going to be a lot between the lines as we listen  To apple position. Yes

Start time: 4346.90
End time: 4479.06
Speaker: Christina Warren
Transcript:  No, I agree with you. I mean what's interesting to me to look at as a comparison we were talking about, you know  The newton and we were talking about  The tv and some other things the ipad which obviously steve jobs introduced so that you know goes a lot further  What was interesting about that device was that it did have this massive expectation behind it  We had all wanted a tablet mac for a long time a lot of us still do  I still I I went from being a long time detractor and saying we don't need touchscreen max to now i'm  I've come all over i'm like we need touchscreen max even if that's not the primary interface  It's getting silly at this point  But what they did with the ipad which you know that original hardware was not that great  It was actually fairly limited. It only had I think 256 megabytes of ram and um, you know, uh,  The ipad 2 was a much better product and was was really killer  But what they did show off and what you could do with it  was so impressive that  No one else has even really been able to meaningfully enter the tablet space  I mean you have low end android tablets, but that's it everyone who tries to come in at a higher point  Can't do it and the ipad, you know, here we are what?  13 years later is um, it's fallen off. It's maybe not as it's not the iphone  but it still makes a substantial amount of money and so I I  the way that they were able to kind of show off and get you to see how it could be useful and fit into your life  And and opened up possibilities for developers to you know build things off of it  Was really interesting and so my my hope would be that they could they could kind of capture what they did with the ipad  Even though that initial device  Like even the one generation later was better and two generations later when they not not the third one  Which is the one that I bought and then they changed the connector  Immediately and and made the battery not as terrible. Um, but the retina model, you know  They made these iterative changes on that device very quickly  Um, and that lit up to the promise that they showed off, you know in in 2010  but we all saw what it was when it came out and um  That would be my my I think the best case scenario for them, you know, I think about about full self-driving

Start time: 4479.66
End time: 4528.46
Speaker: Larry Magid
Transcript:  So you've got tesla which is out there basically every other week claiming that only tomorrow we're going to have it  It's going to be perfect  You'll be able to sit in the back seat smoke a joint and then you have every other car company  With their head down working on towards full self-driving driver assisted and you know  Cadillacs doing a pretty good job ford's doing a pretty good job  Uh some of the european companies are doing a good job  None of them are making the kinds of claims that elon musk makes and none of them are saying that we're going to deliver this tomorrow  But you know that eventually  Every car or every everybody will be able to spend money and get a self-driving car  Um, because everything in these companies are invested in it and I think that there's a lesson to be learned in this now  Musk has done well  But actually not that many people are suckers like me that have paid in my case  I only paid seven grand for full self-driving now

Start time: 4529.32
End time: 4535.28
Speaker: Leo Laporte
Transcript:  If team did you ever get it?  Well, no, I mean i've got I paid five thousand and never got it

Start time: 4535.90
End time: 4543.36
Speaker: Larry Magid
Transcript:  Well, i've got the data but my car will be in the junkyard by the time the full  The true full self-driving is available. So we're suckers

Start time: 4544.22
End time: 4573.28
Speaker: Dan Gillmor
Transcript:  Yeah, of course what so what puzzles me here is that maybe the difference between  tesla and these other companies is that their ceos  take seriously  securities laws and and and actually think that they might get punished for  Bullshitting the public about things that are material to their  Results and but elon has demonstrated obviously not enforced against elon musk elon has demonstrated you don't have to

Start time: 4573.70
End time: 4598.10
Speaker: Leo Laporte
Transcript:  It's really we live in a really interesting time when it comes to normative values. Donald trump  Showed that you really can exceed the norm  Drastically and suffer no consequences at least up to this point elon's done the same  I think somewhat taking a page from the donald trump playbook  I I fear for a society where the norms are no longer  enforced  I think that that's a scary society

Start time: 4599.38
End time: 4611.50
Speaker: Larry Magid
Transcript:  I got an over-the-air update just a couple of days ago and it's gotten a lot better  I mean the the fsd today, would you trust it though? Would you trust it?  No, not completely. I always have my foot one inch over the brake. Yeah me too. Yeah, disable it

Start time: 4612.32
End time: 4614.96
Speaker: Dan Gillmor
Transcript:  But I just don't make it more stressful and not yes

Start time: 4615.92
End time: 4626.44
Speaker: Larry Magid
Transcript:  Absolutely, I gotta worry about my driving the other guy's driving in the car's driving. Sure. I'm now  Third person that could screw up. I and you're paying you're paying thousands of dollars

Start time: 4627.14
End time: 4638.02
Speaker: Dan Gillmor
Transcript:  To have more stress when you're in your car  Can you guys  Please explain that thinking there. I I have a ford maquis which has their blue cruise

Start time: 4638.70
End time: 4651.62
Speaker: Leo Laporte
Transcript:  It is hands-free, but it is very limited. It's only on highways. They've mapped it is not on local street  This is where elon I think really over  Estimated the capabilities of the system. You should not be doing that on city streets, right?

Start time: 4653.14
End time: 4657.70
Speaker: Larry Magid
Transcript:  I do but i'm again my foot's one inch over the brake. Yeah, that would terrify me blue cruise

Start time: 4657.84
End time: 4678.48
Speaker: Leo Laporte
Transcript:  I still have to pay attention but I feel a lot more  Sanguine and it turns off and beeps at you and says you need to take control when it gets to a situation  There is a curve going down to marin  That the tesla almost always would steer toward the divider. I would always have to say no no no no no  And the blue cruise turns off at that point says take control

Start time: 4678.90
End time: 4693.00
Speaker: Larry Magid
Transcript:  So there's something about that curve that cameras and well that's that's why I gave you that example because that's an example of a mature company  Taking a position that yes will eventually be usable technology  But we're going to roll it out gradually as opposed to elon who basically likes to blow things up

Start time: 4693.44
End time: 4704.64
Speaker: Leo Laporte
Transcript:  So my next car I think is going to be a bmwi 5  With full self-driving and they say you're going to be able to change lanes by looking in the side mirror

Start time: 4707.10
End time: 4709.84
Speaker: Larry Magid
Transcript:  How do you know that's the reason you're looking that's going to be a little scary

Start time: 4711.24
End time: 4712.68
Speaker: Leo Laporte
Transcript:  I might turn that feature off

Start time: 4713.66
End time: 4722.64
Speaker: Christina Warren
Transcript:  Yeah, that that doesn't seem like anybody has thought that through  Super well, but i'm looking the side mirror and I want to change lanes. Okay  I'm not looking for any other reason no

Start time: 4723.50
End time: 4740.02
Speaker: Larry Magid
Transcript:  If you leave the default on tesla will change lanes just on its own  I've been driving along having a great day and all of a sudden i'm finding myself changing lanes for for reasons that I can't quite understand  so  In some ways it may be better than at least what i've got. Oh lord. Anyway, uh tomorrow is going to be a big day

Start time: 4740.54
End time: 4799.54
Speaker: Leo Laporte
Transcript:  Uh, we're gonna smell what tim's cooking and uh, and uh, oh that's bad, but that's good  Yeah, we'll find out. Uh, I hope you will tune in for our live streaming coverage  Well, I was gonna do it with mica sergeant who got a last minute invite. So he's going down there  So just be me good job. Good job. Micah. Yeah, no kidding. He called his contact said hey, hey, what about me?  Uh, I call my contacts they go who are you so it's a different it's a different experience for mica  Uh, we will be here and we're gonna open up the club twit stage  So if you're a member of club twit get into the stage so because I don't have a co-host you're the co-host  I'd love to get the club twit members and your thoughts as we listen  Together to what tim's cooking  Uh, that's tomorrow 10 a.m pacific 1 p.m eastern for our live coverage. I think  Christina you've covered apple for years. I think I might stick around for the state of the union  I think that second keynote in the afternoon might be that's always my favorite. Yeah

Start time: 4800.10
End time: 4846.91
Speaker: Christina Warren
Transcript:  That's to be to be honest with you. That's always my favorite  um, like the the big keynote is always you know, the big pomp and circumstance and you get  The product announcements and you get to see the features and then the state of the union is when  Like you really get to nerd out and you really get to see okay  What can I take advantage of what are the things that were glossed over that that are really going to be interesting?  That's that's the one I think especially  With this rumored, you know xros or whatever it's going to be called that I think will really really be important to see  um, especially for anybody who has a  Whether you you code or not, um for those of us who do obviously think of a greater interest  but even if you don't just to kind of get  An idea of this is what people will be able to build on going forward and and these are some of the new things and so  um  That's exciting

Start time: 4847.98
End time: 4866.42
Speaker: Leo Laporte
Transcript:  Yeah, it's fun to kind of uh for me it's always been fun to take the next step and to kind of try to  Understand what the what the strategy?  Is you know, i'm a chess player. I like to kind of think about strategy and uh,  This is one where apple's gonna really have to step up. I think yes a lot different though

Start time: 4866.48
End time: 4881.78
Speaker: Larry Magid
Transcript:  It was when steve jobs was doing it. I remember I would always go to these events and I always one person  And i'd walk away say oh my god, i'm gonna buy that the moment it comes out. This is so amazing  And then the next day i'll think about it say well, maybe it wasn't as revolutionary famous reality distortion field, right?

Start time: 4882.10
End time: 4919.66
Speaker: Leo Laporte
Transcript:  It worked. Yep. We're done. Yeah  I still get that. I even got it during the uh, the microsoft keynote  I get excited by new technology and I always have to kind of pinch myself and say but how realistic?  Uh is this you know, I worked for years with uh, john c devorak who was famous for being the the  In fact, he even had a column in the back of mac user magazine called the anti editor  He was famous for whatever it is. I'm again it  And the funny thing is in technology, you know you do that 100% of the time and you're right about 80% of the time  most stuff isn't  Going to change the world, right?

Start time: 4920.02
End time: 4964.94
Speaker: Christina Warren
Transcript:  It's true. It's true  But you know, but there are those times when it does right like the iphone I think being like the most  You know kind of recent example that I can kind of think of where it literally did  You know change  um everything and  I don't know even if it doesn't it's still fun  I mean we're enthusiasts like I think it's fun even to be like brought into kind of the  The bubble of believing that this is going to be this revolutionary thing and then it's not  And then you have a whole bunch of like like all of us do a bunch of uh,  I have a very like just like you have a bunch of gadgets that are in boxes and all over my  My office. Yeah, don't work. And it's okay. It's it's a reminder. It's like  Okay, remember when we thought that was going to be the next big thing every six months. It's just kind of fun sometimes I have

Start time: 4965.22
End time: 5011.22
Speaker: Leo Laporte
Transcript:  Uh for the staff at leo's garage sale  I don't put prices on it. It's all free, but I pile up the conference room table with exactly that stuff christina stuff that I  alexis o'hanian during covid  Founded a company  That was going to be live music performances in your house since you can't go out  And he sold these wooden they were made of wood wooden speakers wooden they were wooden  They didn't you connected them to this box that was connected to the internet and then at four fifteen every evening  You would sit in front of these wooden speakers and there would be a live concert and the speakers were supposedly designed  For the live concert john just a little heads up. That's going to be on the table and leo's next yard sale

Start time: 5011.80
End time: 5011.82
Speaker: UNKNOWN
Transcript:  I

Start time: 5013.62
End time: 5019.14
Speaker: Leo Laporte
Transcript:  So many times i've fallen for these actually maybe I should put the quest pro on there too come to think of it  That didn't really

Start time: 5019.40
End time: 5022.10
Speaker: Larry Magid
Transcript:  No, I press pro is better than the quest 2. Yeah

Start time: 5023.30
End time: 5439.22
Speaker: Leo Laporte
Transcript:  No, you know, I that's why I spent that much money on it. I am not buying the apple device. So I don't care  I don't care  I don't I just can't bring myself to do that. I'm gonna i'm gonna wait jason howell's raising his hand jason  You want those wooden speakers? He's a he can have those  Let's take a little bit of a break  I'm kind of interested. I'm really interested in what's going to happen tomorrow. It's it's  Always fun to watch a company with a trillion dollar two trillion dollar  Valuation and hundreds of billions of dollars in cash  Tell us what's next  It's notoriously hard  For tech companies to figure out what's next they more often fail than not especially the incumbents  but on the other hand  apple  Apple something special out there  Uh, oh, sorry jason. You don't want the wooden speakers. You want the quest pro? Okay. Well, you can borrow the quest pro you don't have  You don't have to take it home our show today brought to you by colide  K o l i d e a device trust solution that ensures unsecured devices can't  access your apps  This is actually a really very very good point if you're an octa user you feel good, right? You're secure because  with octa  only  Known users can get into your network into your cloud into your apps  Octa really assures that the authentication is happening, but that zero trust architecture has a bit of a hole  because  Your identity provider lets known devices log into apps  But just because a device is known a user is known doesn't mean that device is in a secure state  device compliance is kind of the unsung  Problem in all of this many of the devices in your fleet probably shouldn't be trusted  They could be running out of date versions of the operating system on encrypted credentials could be in their download folder  They could have browsers that are out of date and on and on and on  There you remember the big password manager company  That got hacked because one of their devops guys was working at home on a laptop on a network  That was also running an old version of plex an unpatched version of plex with a known flaw  The hacker used that flaw to get into the network and then get into the devops guys laptop and steal his credentials  And then log into the password store, right?  So with devops credentials  And of course they were authenticated when they were logging in  But here's the problem  again  A device that isn't secure  Is the problem?  so  Here's how it works with collide you put the collide agent on all the endpoints, right if a device isn't compliant  And you set the rules what compliant means you get to say and it's or it's not running the agent  It just can't access the organization's sass apps  the device user cannot log into your company's cloud apps until  They fix the problem on their end. It's that simple and by the way, they fix the problem  That's the other thing I love about collide. It offloads your it team. It makes your users part of your security plan  Here's an example employee doesn't have an up-to-date browser, right? I just I forgot to get the last version of chrome  But that's a problem  So collide says dude  Fix your chrome or you can't get in end user remediates. It doesn't say dude it says here's the problem  Here's what's going on. Here's why you need to fix it  Here's how you fix it the user fixes it your it department doesn't get loaded up  And you get your fleet to 100 compliance. That's great  Without collide it teams just don't have a good way to solve these compliance issues or stop insecure devices from logging in with collide  You set you enforce compliance across your entire fleet and this is another thing I love about collide completely cross-platform windows mac  linux, absolutely  Collides unique because it makes device compliance  Part of the authentication process so a user logs in with octa collide alerts them to compliance issues  Prevents unsecured devices from logging in and gets the users to help you fix it  It's security you feel good about because collide puts transparency and respect for users  At the center of their product  Everybody's happy to sum it up collide's method means fewer support tickets less frustration  Most importantly a hundred percent fleet compliance  kolide collide.com  Slash twit you can learn more you can book a demo  kolide collide.com slash twit  These guys have been a sponsor for a long time. I really love this product collide.com slash twit. We thank them for their support  I wish that password company had been using them  Speaking of security. Oh, this is bad for gigabyte  Millions of pc motherboards sold with a firmware back door andy greenberg writing wired.com  These are gigabyte motherboards. They've been selling them for years a company called eclipsium  Which is a firmware focused cyber security company  So they've discovered a mechanism in the firmware of the motherboards sold by gigabyte  These are by the way great motherboards. I mean, they're really good. They're  Often used in gaming pcs and high-end computing  Whenever a computer with the affected gigabyte motherboard restarts  code within the motherboard's firmware invisibly initiates an updater program  That runs on the computer and then and then and then downloads and executes another piece of software from the internet  Now, I think this was a firmware update strategy, right?  Um, you know good idea, but researchers found it's insecure  Because the updater program is triggered from the computer's firmware outside the operating system very difficult to discover, right?  Your operating system isn't even running very difficult for you to remove it  Uh, and it is hijackable  Uh john locates who works at eclipsium leads strategy and research said if you have one of these gigabyte machines  You have to worry about the fact that it's basically grabbing something from the internet and running it  Without you being involved and it hasn't done this securely. Of course, it would have to be a supply side  Hack they'd have to get into the the data the gigabyte database 271 models of gigabyte motherboards affected  Um  so  Just something to be aware of  You know, I guess there's no commentary on that except

Start time: 5440.38
End time: 5523.40
Speaker: Christina Warren
Transcript:  Maybe you want to go it's frustrating. Well, it's it's frustrating that these things happen and on the one hand  You understand that they want to have these auto updating abilities within right? That's a good idea  Bios, right then that's a good idea. On the other hand, this is this is sort of the trade-off and so I I don't know  um  there has to be a better solution to be able to do this because  Ironically, I think that the reason that they have this backdoor is because um, and and it's just because their  Server I assume is not secure enough  But the reason they have this backdoor is to try to prevent people from having unpatched  Motherboards and and having other, you know exploits that that can um, it potentially be even worse  so it's uh, it's a challenge for sure, but  Um, the the number of devices that are impacted my I have a gigabyte motherboard  It is not on the list  But many others are and so I kind of have this question  So I had to I made a point to turn off and that is the thing you can do  You can turn off the auto update feature and I made a point to turn that off so that you know  This this is not going to  Um, hopefully affect me and if you haven't already been modified. Yeah, unless it's already right  Yeah, then you're out of life there's no evidence right yeah  But then there's no evidence that this has actually been modified in a while like this is this is at least right now  This is theoretical. So and and I haven't had the the computer hasn't been on in quite some time

Start time: 5523.58
End time: 5535.48
Speaker: Dan Gillmor
Transcript:  So i'm not concerned personally, but yeah, that's a good point. I don't know what it's gonna take for  uh  For companies to be held accountable for this kind of thing

Start time: 5536.76
End time: 5554.92
Speaker: Leo Laporte
Transcript:  But the good news is  Gigabyte has released a firmware update that they it's a beta but they think it will fix this so if you have a  A gigabyte motherboard you might want to check to see if there's a firmware update  It is hard for this is this is like that bloomberg story, which by the way has never been

Start time: 5555.82
End time: 5560.14
Speaker: Christina Warren
Transcript:  Confirmed but exactly we that's still a big asterisk on that. Yeah. Yeah

Start time: 5562.77
End time: 5593.28
Speaker: Dan Gillmor
Transcript:  Um, you know we still we have a situation where  Technology companies uniquely in our world get away with  uh  putting out crap products  that  Uh are insecure that that break and have no liability  I don't understand how  How they have evaded?  What would be standard liability questions in any other business, yeah

Start time: 5596.02
End time: 5613.58
Speaker: Leo Laporte
Transcript:  Uh  It raises an interesting point and uh, and i've we talked about this on twig  There's a new book. Uh just came out which by the way, I highly recommend  by uh, uh scott shapiro who is a  Both a computer scientist and a philosopher

Start time: 5614.06
End time: 5614.20
Speaker: UNKNOWN
Transcript:  Uh

Start time: 5615.56
End time: 5732.10
Speaker: Leo Laporte
Transcript:  But his new book is called fancy bear goes fishing  The dark history of the information age and five extraordinary hacks  It starts with robert tappen morris's very famous internet worm the first time we saw a worm  Take the internet down way back and I think was 1983  Highly recommend the book the very interesting description of  Uh the the mirai worm and the story behind it and the kid who created it  He was a rutgers student who was pissed off because only upper class computer science majors could get into the computer science classes  So he d dosed the entire system and brought it to its knees  Uh, he was kind of a wild child and eventually came up with the mirai botnet, which was a  The very first I think d dos as a service  system where uh script kiddies who didn't know anything about d dosing could rent  The hardware to d dos their favorite target  Uh, he eventually got caught the fbi caught him. They did they decided not to send him to jail  But instead to enlist his help as often happens  In fighting other hackers and he's now he says it reformed  And is very grateful to the fbi agent who caught him for teaching him  The right way. It's a it's a highly  great story, but  That's not why i'm bringing it up because  Scott and I may not this may be beyond my pay grade. Maybe yours too. Maybe uh, I don't know  maybe somebody will know but scott says because uh, these are  Essentially our computers are essentially touring machines  Which means they're designed in a way that they can solve any problem arbitrary problem  They have a general purpose hardware to do that. They cannot be  secured  Uh, jennifer willettes article in ars technica is cyber security an unsolvable problem scott sapiro chapiro says  Yes

Start time: 5736.22
End time: 5819.44
Speaker: Christina Warren
Transcript:  Any thoughts christina, um, I mean, yeah, I think I think that I don't think that is one of those things  It is one of those problems that I don't think that you can ever permanently solve, right?  like I think that it's one of those that is always a moving target and so, um,  Possibly when we reach the age of quantum, yes, you can maybe have uh, you know  The these systems that are they're not going to be hackable or or um, you know whatnot. I I don't really believe that  um, yeah, I think that it is kind of a it's always kind of a moving target and this is why  Good security funds. Um, you know firms rather can make so much money because this is an ongoing thing  the the targets and the things that are um,  Um,  Easy exploits today are not necessarily going to be the same exploits tomorrow. And so you can't just rest on your laurels  So yeah, I mean I think yeah, I I don't I don't know if this ever goes away  I think this is why we have to be vigilant, but we have to kind of expect uh, or not expect but we have to  Have the awareness there is the potential with any of the things that we use that it could be compromised  And that's why it's important to run updates and to you know, stay aware of things and to  You know pay attention and to audit code and have third parties auditing, you know  Your code as much as possible when it makes sense  Uh to try to prevent the fallout from this stuff. Yeah

Start time: 5820.24
End time: 5843.48
Speaker: Larry Magid
Transcript:  I think part of the problem is social engineering. I mean even if we could make perfect hardware and perfect software, which we can't  No, but we can't make perfect people 100% and there's a sucker born every minute  Yeah, it's hard and we're going to talk about later when we get into the situation what happened to me  Even very tech savvy people and be at risk of social engineering because the social engineers are very very smart

Start time: 5843.94
End time: 5888.20
Speaker: Christina Warren
Transcript:  Yeah, and absolutely and the thing is is that the thing with social engineering is that a you're right  Very tech savvy people can still be taken in that happens all the time  But b many times the people who are socially engineered are not us  It is customer service representatives for companies that control access to our devices  And so, you know that that's how most people have you know get sim shipped  It has something to do with whatever policies or security they have in place on their devices  It's just getting the customer service person from  You know one of those companies to to saying enough things to getting them to pass things over sometimes without even having information from the user themselves  So you're right. There is the people problem that I don't think we can ever solve even if we were able to build, you know, fully secure

Start time: 5888.96
End time: 5920.92
Speaker: Larry Magid
Transcript:  Um hardware devices and to expand on what you're saying is computer security is one area where you can be completely innocent  So for example, if your only crime were to have shopped at target right before their systems were hacked  Your information was with a bridge you didn't do anything wrong  There was nothing you could have possibly done to protect yourself except live under a rock, right?  Yet you were vulnerable and that's not true with most things  I mean it would be like an airplane falling out of the sky and hitting you at least if you die in a plane crash  Probably you bought the ticket on the plane and maybe i'm not saying you did anything wrong

Start time: 5921.58
End time: 5962.10
Speaker: Christina Warren
Transcript:  But you were you were at least involved you you at least had some agency in the decision to get on the plane to begin with  And you understood that there was a risk. No, you're exactly right. I mean I I with a target hack  It's so funny. It was like target. It was totally  There were like three of them in a row that I was victim of and I had to change my you know, uh credit card  Like three times and like a 14 month period of time  Which is very frustrating to then have to update all of your recurring charges, but you're right  You know just by and you could say okay, we'll use cash in most circumstances. That is not a reasonable  Expectation for most people right that that is not a reasonable thing that goes on  It is impossible in many places trying to drink in an airplane with cash, right? Absolutely. Yeah

Start time: 5963.64
End time: 6035.56
Speaker: Dan Gillmor
Transcript:  Yeah, and the other difference is that target  uh  Suffers essentially no  Uh liability no accountability  Whereas if there's a plane crash, right? Uh, there's a lot of money changes hands  And there's a lot of damage to the air to the carriers  we've  We again we've given people who do  software basically a complete pass  on  Liability and that doesn't seem right  You're right  It's complicated and I understand all these things about how software is is different but  Uh, and and it's the the supply chain of software is insane the whole  but but the  somehow the technology industry  Has persuaded  Uh, I don't it's pretty amazing that they've done it they persuaded  Legislators that  Doesn't matter how badly they behave  They have no liability, uh for what they do wrong. It's it's something's got to change there

Start time: 6036.22
End time: 6167.26
Speaker: Leo Laporte
Transcript:  Actually you boy you guys you don't have to read the book now  Because you came to the exact conclusion. Sapiro said I actually wrote this book three times the first time  I just wrote about the code and the hackers and then I realized well, there's a human element  To all of this so he rewrote it and then he said I realized there's a third element  There's a philosophical element  to this  Um, this is an interview from ours technica, uh, the interviewer, uh  Talks about the science and this goes back to our ai conversation  The scientific community of various disciplines has struggled with this in the past. There's an attitude of we're just doing the research  It's just a tool. It's morally neutral  uh scott says that  In fact, you cannot talk about hacking in a neutral way  He says i'm a philosopher. So my day job is teaching that  But it's a problem throughout all of stem the idea that tools are morally neutral  You're just making them and it's up to the end user  To use it in the right way  He says that's a reasonable attitude to have if you live in a culture that's doing the work of explaining  Why these tools ought to be used in one way rather than another?  But when we have a culture that doesn't do that and this kind of is also what you teach  Dan then it becomes a very morally problematic activity. We're now seeing a lot of hand-wringing about ai  We always see hand-wringing about every single new technology  There's the techno utopians and there's the techno dystopians  But a couple of years later, usually the cooler heads, uh prevail so he said it's important when you're talking about hacking  To to include the fact that it's morally reprehensible that it's wrong and it's bad  Uh, he says you're not going to get rid of it because as long as because humans as long as you got humans  Your cyber security is not primarily a technological problem that requires primarily an engineering solution  It's a human problem that requires an understanding of human behavior hacking is about humans  And he's calling for the death of solutionism because we do kind of come from that point of view that oh we can fix this  We can solve this  so

Start time: 6168.60
End time: 6246.47
Speaker: Larry Magid
Transcript:  Go ahead to dan's point. I mean I agree that legislators need to wake up and be more aware of what's going on  But there's also dan as you know, well intentioned  Legislation that that's bad  communications decency act was one example going back to 1998 or  This arkansas law that is going to essentially ban minors using social media without parental consent also a utah law  There's there's so much technique. There's so much  dystopian or I mean dystopian but over regulation  Because the regulators don't understand what's effective and what isn't right? And so that's what bothers that's what worries me whenever washington  Or now increasingly state legislators are getting their mitts on technology  If they really don't understand what they're regulating and what the real dangers are and one of the reasons why I started  Safekids.com and later connect safely  Was and again, we're very imperfect ourselves, but at least to try  to create sort of a conversation around  The relationship between industry government and consumers as to how we can use this technology in a more safe manner  We will never claim  Uh that we'll ever reach absolute safety, but you know make it safer  Uh, and and it's it requires a lot of you know, I hate to say it takes the village because that's become trite  but it really does take a village

Start time: 6247.82
End time: 6295.25
Speaker: Dan Gillmor
Transcript:  there's no question that that the  The uh problems that we can create by misguided regulation are are serious and and  that we have to be careful as we do this stuff, but  My only point in this context was  That we have given  A single  collection of people in our  economy  An exemption from  Liability for egregious  uh misconduct  And that doesn't seem right to me. I think we could we could start there  And I work on that right?

Start time: 6296.24
End time: 6380.50
Speaker: Christina Warren
Transcript:  I think you're right. I would point out and and I completely agree with you  Um is that the government itself is often the one who leaks information there have been numerous government hacks of  You know databases and whatnot, um, and and they also should not be exempt from those things. Um  It is an interesting thing  You know, I think about equifax and that fact that most people who were impacted by that again  I was we weren't even compensated like 20 dollars. We didn't get anything, you know  In fact, we're invited to spend more money with equifax. Exactly. Exactly. Exactly. And I was like, why would I give you any money?  You know, I why why would I trust anything that you've done?  And in that case and and I think what's interesting too if you didn't want to you know  To to larry's point, it's a difficult problem to solve  But I feel like there are some instances where it is flat out from any other circumstance  It would be pure negligence equifax being a great example  There are some supply chain types of attacks and other attacks where it can truly say, you know  This this was not something that we could conceive of happening because we didn't have control over what ultimately impacted our systems  But there are other instances where  You know, you're running outdated systems and you're not holding things up  Uh the the way that you should you're not doing the basic due diligence in those companies  um, or or you know still get government contracts or the government themselves are still able to  Force us to use their systems  And and we have no recourse and it's very frustrating

Start time: 6381.56
End time: 6425.72
Speaker: Dan Gillmor
Transcript:  There ought to be a corporate extinction. I mean corporate extinction level events ought to be more common  for for this kind of stuff and  the fact that the credit agencies  Do what they do and are are  notoriously incompetent willfully incompetent. Yes  Uh, because they're they don't see the point in spending the money to do it right and no they are  They have a point. No one does anything about it when they do it wrong. I I guess they're  If you're looking at their shareholder value, um  Hey screw the public it's worth, you know, we make more money doing it that way and nobody holds us accountable  It's it's what what a grift. It's amazing

Start time: 6426.78
End time: 6458.12
Speaker: Larry Magid
Transcript:  The thing about is you're absolutely right. I don't think I know anybody who doesn't have a credit reporting  Um story to tell about an inaccurate report maybe not getting a loan because of some because of some inaccurate but in aggregate  It serves lenders well because you know, they're going to make a lot of mistakes  But over the course of the millions of loans they give they're still going to make money on those loans  And so, you know again, it's not about you and me and the rest of the public. It's about the industry  And and that's who these credit bureaus are serving. They're not serving the public at all

Start time: 6458.66
End time: 6473.00
Speaker: Leo Laporte
Transcript:  No, in fact, if you want a credit card, you have to give them permission. You have to yeah  If you want to rent an apartment these days, you have to give them permission over and over  all of this stuff is uh  You don't have a choice. This is by the way in the aquifax with

Start time: 6473.54
End time: 6485.64
Speaker: Larry Magid
Transcript:  Another example where innocent people. Yes, I never I don't know anybody said gee i'm going to become an equifax customer  No, again, you don't have any you don't have any choice in the matter. I'm just just by existing society. Yeah, I have fraud alerts and all

Start time: 6486.84
End time: 6503.06
Speaker: Leo Laporte
Transcript:  Actually, there's more than the three. I think it's on on five different  Credit reporting agencies, but you get the free one, right? Yeah. Yeah now it's free used to be  They charge you to turn it off. Yeah  Exactly  Thank goodness federal legislation has stopped that scam

Start time: 6505.46
End time: 6538.02
Speaker: Dan Gillmor
Transcript:  To uh, hey anyone who's listening to this, please go freeze your credit  Right now. Yep. As soon as we're no wait wait till the show is over then  go and freeze your credit so that uh  At least you have partial  protection and it's it's easier to unfreeze when you need  To have someone look at your credit report on a specific thing. It's easier than you might think  Yeah, this is the issue has good guides on this. It was easy for me to do

Start time: 6539.36
End time: 6555.60
Speaker: Leo Laporte
Transcript:  Uh because i'm old and i'm not buying a new house and i'm not you know taking out loans and i'm not buying new credit cards  If you're young and you're you know, you're getting started in the world  Freezing your credit  Is an inconvenience but but I think it's a worthy inconvenience and so my daughter bought a car

Start time: 6556.44
End time: 6574.20
Speaker: Larry Magid
Transcript:  And the car salesman tried to convince her that she should take out a loan in order to build her credit  Now first of all, she already had good credit, right?  But they they actually made this kate and apparently there's some truth to that which surprised me when I actually did a little research  It seems absurd that your credit score would go up because you're in debt. It does. Yeah, it does

Start time: 6574.80
End time: 6602.70
Speaker: Christina Warren
Transcript:  It does. Yeah, i've had the same thing where when I try to look at my credit for various things like the thing  I'll be dinged with is that I don't have enough  You know, um outstanding I don't have any outstanding loans or I don't have enough, you know  Kind of open lines of credit, you know, you pay it off and whatnot and and it does seem counterintuitive but yet that's  You're guilty of paying your bills on time. Exactly. You're guilty of paying your bills on time and they're like, oh no, you know  This isn't that we will we don't know if you're trustworthy. Okay, you know

Start time: 6604.08
End time: 6608.52
Speaker: Larry Magid
Transcript:  Uh, you know like leo i'm old and I just pay my bills on time and I don't really worry about I don't need credit anymore

Start time: 6609.60
End time: 6653.24
Speaker: Leo Laporte
Transcript:  I've already i've already withdrawn from the economic life of this country  But if you want to freeze your credit, uh, yes consumer reports has a number of articles the ftc actually has a whole page  Devoted do not get fooled by credit locks  Do the credit freeze that really will protect you?  And the ftc consumer.ftc.gov has the details on how to do that. It's actually quite easy  And nowadays they can't charge you to unfreeze it  So, um, uh, you know you can freeze and unfreeze at will they don't make it easy  They're doing every they have crappy websites with complicated logins and all sorts of stuff  But once you get it down you can log in turn it on and off fairly quickly

Start time: 6653.34
End time: 6658.04
Speaker: Larry Magid
Transcript:  It can't be any harder than unsubscribing from a paid service. No, no, you're right. That's the hardest you're right

Start time: 6658.26
End time: 6658.75
Speaker: Leo Laporte
Transcript:  It's close

Start time: 6659.16
End time: 6669.60
Speaker: Larry Magid
Transcript:  But then by the way, why is it that when you get an email that you want to unsubscribe that the word unsubscribe?  Even the tiniest possible print imaginable at the bottom of the uh page. Oh, yeah

Start time: 6669.78
End time: 6673.84
Speaker: Leo Laporte
Transcript:  Well, because they don't want you to unsubscribe. What did you think? It's really hard to find that that link

Start time: 6674.78
End time: 6732.44
Speaker: Dan Gillmor
Transcript:  Web design to steer you to bad decisions is it's dark thing. I have a whole  part of my media literacy  teaching is in  There's one section where I talk about how  Uh, and and there's lots of good articles about this web  Designers trying to trick you into making decisions favoring the company  uh, you know, it's  you know the the  language like, you know  Yes, I uh, yes, I want to be a miserable human being for the rest of my life  If by not getting your emails every morning, you know that that's a  That's the choices they give you and that's and that's in uh,  You know one kind of bold thing and then the or no, that's  I forget how the the the one that they don't want you to click it's hidden. It's usually in gray on white

Start time: 6733.04
End time: 6766.52
Speaker: Leo Laporte
Transcript:  Yeah, like gray on white  There's a great website called deceptive  dot design  Deceptive dot design which talks about dark patterns  And has a whole hall of shame. So if you're looking  If you're looking for dark patterns, there are literally  448 examples in here of misleading  Uh buttons that don't work all sorts of stuff. Microsoft does add a little bit too not to slam your company, but

Start time: 6767.66
End time: 6783.00
Speaker: Christina Warren
Transcript:  Also a I work for github. I mean, okay, not the same. Yeah, okay  I i'm not here to defend anybody and you're right. They the the systems I I call that out too. It's not it's not  Oh, it's notorious. We talk about on windows weekly when microsoft policies cookie pause

Start time: 6783.40
End time: 6794.68
Speaker: Larry Magid
Transcript:  You need a master's degree to figure out in cookie management to figure out how to set your cookies  Why can't they make it really easy?  Some sites do say only necessary cookies and then of course they don't define what really are necessary

Start time: 6794.92
End time: 6800.80
Speaker: Leo Laporte
Transcript:  Right. Well, you have to set a cookie  to say  Don't show this cookie exactly

Start time: 6801.66
End time: 6811.84
Speaker: Christina Warren
Transcript:  I was gonna say I have in a I was gonna say in ublock, uh pro I have some sort of like cookie banner  No, no key banners. Yep. Yep. Exactly. I have that set

Start time: 6812.72
End time: 6852.18
Speaker: Dan Gillmor
Transcript:  Yeah, there's a firefox, uh  Thing they do now that basically it's there you watch it happen in real time. You go to a new place  and it it automatically brings up the  Dialogues watches them and says it selects everything to say no. Oh, that's nice  And and and you watch it go through your screen does it in front of you? It's wonderful. Is that an extension?  Or is it built into firefox? I think they built it in and that's nice one of the recent versions  It's sort of exciting to why I am a very happy firefox user. Yeah, I really like firefox. I really do

Start time: 6853.56
End time: 6920.44
Speaker: Leo Laporte
Transcript:  Uh, I want to take a break and we come back larry you mentioned your  Horrific story we actually had you on about a month ago on tech news weekly to describe this  But we've never had you on twitter to describe it and I want to show the video that you've also made  You call it virtual kidnapping scams  And it happened to you. So we'll talk about that when we come back  And just a little bit great to have larry maggot here from connect safely.org  Uh from the wonderful  Cronkite school of journalism. I just love that name at arizona state  He now teaches dan gilmore  Media literacy, which is even more important at the asu news colab  Thank you for being here dan. I appreciate it. It's great to have your intelligence  And of course, it's the wonderful film girl. They still call her that I guess around the office  Seeing senior dev advocate for github  Christina warren who i've known since she was knee-high to a grasshopper  I was thinking the other day about when I first saw you and I think it was at a mac world expo

Start time: 6921.52
End time: 6928.06
Speaker: Christina Warren
Transcript:  Yeah, yeah, you were there for mashable maybe or another no it no the unofficial apple web. Oh, yeah

Start time: 6932.28
End time: 7129.56
Speaker: Leo Laporte
Transcript:  And you were sitting on the floor with your colleagues covering mac world you were eating your lunch  I think I probably came up to you and said ah film girl  Something like that i've been a fan boy ever since great to have you and your sneakers  On the show our show today brought to you by  Well, I think I need it right now athletic greens. We're gonna take a little vitamin break everybody get together  Like many of you. I wanted to support my health  I have been taking literally my son. I  The other day I  This was I was visiting him at school  This actually a few years ago and I took a handful of vitamins and swallowed it and he was aghast  He said what are you doing? I said, well, I want to you know, I'll have to make sure i've got the proper  Nutrition. Well, it's a lot easier now  Thanks to a g1  It gives my body what it craves in one daily nutritional drink you do it before you eat  In the morning. It's actually a great way to start a g1 was founded in 2010  It's been part of millions of routines ever since in fact every time I talk about it  I hear from people saying oh, yeah, i've been doing this for years  I just discovered it. It's the best all-in-one solution for daily nutrition. It saves you time  Confusion and money each serving less than three dollars a day  It's a lot less than I was paying for supplements and it's not just vitamins minerals  It's also pro and pre-biotics it supports your gut health  It's got everything you need 75 high quality minerals vitamins pre and probiotics  You put it in 12 ounces of water. In fact, if you get the ag1 kit  You'll get the shaker that i'm using here. You get a scoop beautiful aluminum scoop and a canister to store your ag1 in  It dissolves very easily. You don't have to use hot water. This is cold water. You shake it up and it's a seamless  Daily habit one scoop of ag1 in the morning is everything  You need and oh by the way, i've tried other ones of these other  You know drinks that you can't you have to choke down. This is delicious. It's refreshing  I love it  If you're looking for a simpler cost-effective supplement routine  Look no farther ag1 by athletic greens if you order right now if you get a subscription  You'll get a free one year supply of vitamin d  D  And these travel packs that I was just using these are super convenient  You get five free travel packs with your first purchase of a subscription  athletic greens  Dot-com slash twit athletic greens dot-com  Slash twit. Thank you so much for their support. And thank you athletic greens for supporting my my my dietary needs  I drink that just to prove that it tastes delicious. I mean it really does it's really really good  Much better than that cup of coffee. I just had ag1  athletic greens dot-com slash twit  All right  I needed the fortification. Oh larry's gone for a moment. We'll just give him a  There he is  I needed the fortification larry because I knew you were going to tell a horrific story  Because I knew you were going to tell a horrific story  Tell us what happened  In your own words, mr. Magid

Start time: 7130.32
End time: 7363.88
Speaker: Larry Magid
Transcript:  so one day  Oh, I know but a month ago my cell phone rings and I pick it up  and there is a screaming or crying woman on the phone  and  It oh, I forgot to tell you the caller id  Looks like it's from my wife's phone. It's actually it turned out later  I found out it was one digit off, but it looks like her phone number  And I hear this person screaming and crying. It's a female voice and I say patty. What's the matter?  And she continues to cream and scream and crime and this is very unlike her. She's not an hysterical person, but you know, I  Was worried and then all of a sudden she gets off the phone and up comes officer. So and so a quote a police officer  The officer tells me that i'm with your wife  And before I can provide you with information, I need some information from you and I say come on get to it  I'm really  Sucked into at this point caller id looked like hers. I heard a voice in my head. I thought it was her  Anyway, so he asked me my name and her name which I would never ordinarily give him a fairly savvy guy, but I do  And the next thing he knows actually i'm not a police officer. I'm with a mexican drug cartel  And we have your wife  And uh, you know, and at that point I put my cell phone on on  Speaker and I still have a landline believe it or not. It's an internet phone umaphone  And uh, I called 9-1-1  And so they could hear the entire call. I didn't talk to the 911 operator. I just called them so they could overhear  And we the call went on with this person for 11 minutes  And at one point he said you need to get in the car right now and start driving to a walmart in san jose  But first you need to go to the bank and get five thousand dollars in cash  um  I kept it and I kind of played played along with him. I mean I was I wasn't  Sure, it was a real situation. I didn't know what it was, but I was I was emotionally  Really upset very so they get you screaming gets you like all and my wife was in san francisco  She was in san francisco that day, which is unusual normally, especially since covid  She you know, she's at home. I'm at home. So it's unusual for her not to be with me  And he said something about her being in san francisco. I'm not sure he started with that or he got it for me  I mean, there's a lot I don't know about my own action. Anyway, long story short  The call goes on for 11 minutes  Finally, I think he came to the realization. I was not going to comply  I didn't say I wouldn't comply but I kept asking for questions and things like that and he hung up  I later talked to the 911 operator who heard the entire thing who said that they took it seriously  So seriously that they sent the sfpd to check on my wife and by the way, I knew where she was  Because I have I track her with her permission. She and I track each other on google maps  So I knew she was at the embarcadero center, but that's a big place  Anyway point is it was a virtual kidnapping  Uh, I didn't pay the ransom but I have to tell you it was very painful. It was it was terrifying  I was so shaken that I actually got in got on the train  And visited her in san francisco. I needed to be with her because I was just so moved by this  At one point one of my colleagues called me up  And I said I have to hang up right now. My wife can kidnap it  Oh jeez  Based on this experience, uh, as you saw I wrote about it, uh on for the mercury news and also  On connect safely and then connect safely just recently put together  A uh a guide to virtual kidnapping and a video. I think he said you might want to show the video  If people need to be aware of that and and again, it's embarrassing for me to say this  And as I said at the end of my column knowledge  It's power but emotions can be stronger than knowledge and despite everything I know about computer technology and security i've written literally  Hundreds and hundreds of articles on various aspects of human engineering and computer security  I still I wouldn't say I fell for it, but I was still heavily impacted by it

Start time: 7364.58
End time: 7390.14
Speaker: Leo Laporte
Transcript:  And I you know, I think it's important to say that uh, we're all vulnerable  You know that it isn't uh on your part. I mean of all people you're not ignorant of all this stuff  You're very technologically literate  Um, but they use emotion to the point where you stop thinking  Yeah, they cut off your frontal lobe and uh, and and you're just acting on emotion  And you know, we do dumb things. You didn't really fall for it. You didn't send him 5 000

Start time: 7391.02
End time: 7412.86
Speaker: Larry Magid
Transcript:  I didn't take the five. I didn't give him the five grand, but believe me it it you know, it hurts still  um, and  You know, and as I said in a follow-up column, it's going to get worse because now we've got the ability to recreate our  Loved ones voice or they have the way to recreate your your loved one's voice and I think it's going to get worse  It's yeah, because this was just a screaming woman obviously a scam

Start time: 7413.56
End time: 7421.58
Speaker: Leo Laporte
Transcript:  Probably completely random  Uh, it sounds like he knew a few things but maybe that was just luck or or it wasn't clear what he knew and what he didn't know

Start time: 7421.60
End time: 7427.26
Speaker: Larry Magid
Transcript:  Yeah, yeah. Yeah. I mean one of the things I did is I changed all our passwords because maybe they hacked into our google account

Start time: 7427.92
End time: 7437.42
Speaker: Leo Laporte
Transcript:  Yep  Uh, should I play the video? I'll play the video. I'd like you to if you don't mind  Yeah, we'll play it into the we'll play it into the record as they say. This is just a couple of minutes

Start time: 7440.98
End time: 7591.53
Speaker: SPEAKER_02
Transcript:  Virtual kidnapping scams are an insidious form of fraud preying on our deepest fears  Let's talk through how this scam works  In simple terms a virtual kidnapping scam is a social engineering scam aimed at extorting money from unsuspecting people  By convincing them that a loved one has been kidnapped  These scammers employ techniques such as cloning phone numbers or even using artificial intelligence to mimic the voice of your loved one  Making their calls incredibly convincing  Detecting a virtual kidnapping scam can be challenging, especially when emotions are running high  Here are some key steps to keep in mind if you suspect you're being targeted  The FBI says that the best course of action in most cases is simply to hang up the phone  But if you do get reeled in into conversation with a scammer, here are some tips on what to do  One stay calm remember scammers rely on fear and panic to manipulate their victims try to slow the situation down  Two guard personal information  Regardless of who the caller claims to be avoid sharing any personally identifying details such as names locations or information about your loved one  Three seek help if possible have someone nearby call 911  If you're alone discreetly call 911 from another phone if possible and put the call on speaker for the operator to hear  four verify independently  Reach out to your loved one directly or have someone else call their phone or check their location if it's been shared  You want to confirm their safety?  five  Ask to speak to your loved one if the scammer insists on speaking for them ask a question that only they would know the answer to  Consider establishing a code word or phrase with your family members as an additional security measure  Prevention is always the best defense  So let's explore proactive steps to protect ourselves from virtual kidnapping scams  Discuss virtual kidnapping scams with your family members and loved ones ensuring they're aware of the threat and how to respond  Avoid sharing real-time location or travel plans on social media as this information can be exploited by scammers  Refrain from sharing your phone number or recordings of your voice online  Scammers can use this information to make their claims more convincing. I am so in utilize location sharing services  With their permission reciprocally share your cell phone location with loved ones using legitimate tracking services like google maps or apple's find my friends  Note physical details make a mental note or a written note of what your loved ones are wearing when they leave the house and where  They're going for more information visit connect safely.org  Nice

Start time: 7592.46
End time: 7595.94
Speaker: Leo Laporte
Transcript:  That's good. That's what can be simply does that's very well done. I like it very simple

Start time: 7596.04
End time: 7614.04
Speaker: Larry Magid
Transcript:  I'm by our media director chris lee and and I think if you want to share this and I recommend you share this especially  If you or people in your family are older because you know older people like me the ones that  Are targeted off into this. Uh, you can find this now in the upper right corner on connect safely connect safely.org

Start time: 7615.46
End time: 7620.74
Speaker: Leo Laporte
Transcript:  Or go directly there with connect safely.org  Virtual kidnapping how widespread is this?

Start time: 7621.46
End time: 7648.96
Speaker: Larry Magid
Transcript:  It's very widespread and it's growing and as I said, it's going to get a lot worse with ai  We talked about the existential threat. This is the threat that I worry about this kind of the use of ai to exploit people to commit crimes  I think it's going to get a lot worse and in a sense this was artificial emotional intelligence, but  Uh, it's going to get a lot it's going to get a lot worse as they're able to to clone people's voices  And I agree leo you and I are screwed when it comes to you know, having our voices on the internet, I mean

Start time: 7650.20
End time: 7666.58
Speaker: Leo Laporte
Transcript:  Somewhere a lot of people everything he said in there. I'm like, oh, yeah. Okay. Don't post where you are social  Oh, i'm dead meat, you know, but what we did do I know this is a possibility what I did do with my family members  Is set up a code a keyword, you know, uh, you know that I can use that they all know

Start time: 7667.38
End time: 7725.22
Speaker: Larry Magid
Transcript:  Um one by the way quick proscript. So yesterday I get a whatsapp message  Which comes from the congo and I said and it's talking about a kidnapping  They said ah, this is a scam. I'm not going to worry about then a minute later  I get the same I get a message and the person identifies himself  And it's a name that I know I actually have a colleague that lives in the congo. That's very active  African internet safety. So I said here can you approach to me?  You are who you say you are  And he sends me a photograph of him and me and my wife and his wife together when we last saw each other  And it turned out it was a real kidnapping. Oh my and I was almost going to write it off  But he needed my help to get a hold of people at meta to make sure that this person's  Account and luckily this person was rescued. I don't have all the details  But the point is that that was a rare case of a real kidnapping and that's one of the problems  You don't want to be immune to the actual danger  When when you're convinced that it's all going to be a scam. I do have and lisa and I both share our location apple

Start time: 7726.16
End time: 7748.48
Speaker: Leo Laporte
Transcript:  Lets you build that in and so I can see on the front page of my phone  Well, you don't have to show it but I guess yeah don't show it because it's our home but  I can see the leases at home  Uh, and that you know, that's pretty valuable. It's just like you have with yours  There was actually just an article I think in the new york times about people sharing their location and the pros and cons

Start time: 7749.12
End time: 7764.50
Speaker: Larry Magid
Transcript:  Of doing that with the family members and I think about google maps is it doesn't matter what operating, you know  You can use it. You can have a relative that's on iphone and you're on android or whatever  And so it goes across platforms. But yes, it is we do do that and it's very reassuring and again obviously with permission

Start time: 7765.50
End time: 7782.69
Speaker: Leo Laporte
Transcript:  Nobody's nobody's, you know, yeah, that's the problem is it looks a lot like  spousal stalking as well  Right agree on it. It has to be between people who trust one another and agree that this we're going to do this  But i'm really actually glad that lisa  Allows me to track her  So to speak

Start time: 7783.82
End time: 7789.70
Speaker: SPEAKER_03
Transcript:  And i need to get around the track of the doing yeah, there's an app called tice t i c e that

Start time: 7790.76
End time: 7831.08
Speaker: Dan Gillmor
Transcript:  Uh comes out of europe, uh, where data protection is  Privacy is better than the u.s. That's  Uh that they actively try not to do anything beyond  The location sharing between two people. That's it. No collection of  Cloud data no, none of the stuff that the big companies here do  so  In this category that's worth taking a look I have not  Fully taken a look but  uh  People I know in the security area have said that this looks really good to them

Start time: 7832.78
End time: 7847.14
Speaker: Leo Laporte
Transcript:  Yeah, this looks great  And I trust apple because lisa and I are both on iphones I can  Use that system and I trust them not to well, I don't know what they're doing with it  But I don't think they're selling it to data brokers. Do you do this with your husband christina or no?

Start time: 7847.94
End time: 7965.22
Speaker: Christina Warren
Transcript:  I don't but um  for various reasons, I I don't but um  That might change I have um, I have thought about using like find my friends with my mom before if we're places  and honestly like my concern is because at my age like i'm not concerned about like  Me being taken in by somebody like confused, you know calling me about my husband  uh being um, uh kidnapped or him being called about me, uh, we would text one another like  Our method of communication is different, but I am concerned about  People potentially targeting my parents  um and and  Like like everybody else on here. There's hundreds and hundreds and hundreds of hours of my voice on the internet. So  the ai can be trained to mimic my voice extremely well and  I am concerned with with that being used to potentially, you know, uh bait people in into  Baiting my parents into thinking that there was some sort of a scenario happening  And especially since I travel as much as I do like that would be a not  Inconsequential thing for them to be like well, I didn't even know that she was here. Well, okay  But she she might have been right like there there are just a a lot of things that make me i've been concerned about this for a  While i've heard of these scams before I I didn't know exactly how it worked  But they definitely play on you know your emotions as you were saying and  There are things that i've just done in my life and that if you're in any way sort of public  I think it makes you especially risky  Because there are things that we can't opt out of that, you know  Could be used to uh target the people that we love and and that's what I worry about like i'm not as  Concerned with sharing my like location with my husband right now. That doesn't make it a ton of sense for us  But but I understand respect other people who do it but I have in certain ways  Like I even ironically I post about my location when i'm at airports or things like that  To let my mom know where I am because she she would always you know worry  So there's there's like a catch-22 with all of it

Start time: 7966.24
End time: 7986.18
Speaker: Larry Magid
Transcript:  Um, I think it's important to point out that people your age are I don't know if anybody is targeted  But people your age are victimized and people your age have paid the ransom  Yes, the cnn did a story about virtual kidnapping recently and I think the person they gave as an example was not too much older  Than you are so I don't think anybody should be saying when just because they're not no, I agree with that

Start time: 7986.60
End time: 8015.94
Speaker: Christina Warren
Transcript:  No, I agree that i'm just saying like I tend to be like as a person I tend to have like  Much like you, you know  I have my blinders up and you weren't taken in and like the same thing with phishing things  I've certainly been the victim of a phishing thing before and then immediately almost instantly recognized what it is  But but my my fear is more  Not to say that I couldn't be taken in by something my fear is more  Okay, how how could my voice or how could my information be weaponized?  To go after people who are less tech savvy than me using emotions and all and and and actually using the tech as well

Start time: 8016.56
End time: 8023.99
Speaker: Larry Magid
Transcript:  I have to say the 20 minutes of sheer terror was probably worse than having paid a five thousand dollar ransom  Yeah, it was it was it was horrible

Start time: 8024.78
End time: 8081.02
Speaker: Dan Gillmor
Transcript:  I think what you're and what your description is going to be used in a more  Uh in a less dire  context but more convincing because we all have gotten emails and texts from  Supposed friends overseas who had their wallet stolen and needed to wire them some money  Well, their friend is going to call you right and it's going to sound exactly like your friend  And this is going to be have been well  Pre-programmed with lots of branching for whatever your response is  To say the right thing and ai is going to make that even more convincing. That's going to be  uh  interesting in a lot of ways to see how  How well the the bad guys game it out  For our responses to see if it's a real thing  That I mean it's going to get this is a real arms race

Start time: 8081.36
End time: 8094.26
Speaker: Larry Magid
Transcript:  And that's why it's important to either have a code word or at least say things and I don't know  Maybe they'll get a deal to scam this as well. But where did we meet? Where did you go to school? I mean questions that  They'd have to be very very sophisticated to be able to answer if they're scammers

Start time: 8094.52
End time: 8110.64
Speaker: Leo Laporte
Transcript:  I'm not saying I always ask what what what does wikipedia say my birthday is and if they  I'm screwed. I'm in deep trouble later  I have to go to b-sides deep tracks before I can get something people don't know about me

Start time: 8111.30
End time: 8115.46
Speaker: Larry Magid
Transcript:  Well, no, I mean every public figure takes that risk and you know, and the fact is that as public figures

Start time: 8116.38
End time: 8156.18
Speaker: Leo Laporte
Transcript:  You know our family members know I think yeah that we you know not to believe anything  Uh alia g and our discord is saying  Thanks to leaks of whatsapp data people are looking through whatsapp data for people named mom  And and using that information to scam moms  You know because yeah, I mean that makes a lot of sense  And I just I worry  That uh, i've always worried about this one of the things I used the radio show for as a way to kind of warn people  Against these scams, but it's just it's non-stop nowadays and maybe people are more sensitive to that

Start time: 8156.50
End time: 8171.28
Speaker: Larry Magid
Transcript:  I'm amazed at how many attractive women text me and send me whatsapp  You know, I just think it's because i'm good looking. Yeah, I mean I just I figure they just uh, they you know  I'm irresistible. What can I say? Apparently it's amazing how many young women are interested in older men

Start time: 8172.84
End time: 8196.88
Speaker: Christina Warren
Transcript:  I and I try to have these conversations with them because you know that they're they're scammers and like  I for whatever reason I really you engage them. I do I try to because it's fascinating me. I know what they're doing and um  Weirdly I have i've been I guess i'm i'm not saying the right things  Because I  Weirdly they they disengage the conversation relatively quickly. Yeah, it's a shame. It's hard to keep them online

Start time: 8197.44
End time: 8215.30
Speaker: Dan Gillmor
Transcript:  Listen, this will be this will be a really good thing to turn over to  ai bots  Pretending to be you and engaging of course, it'll be it'll be a scammer bot  And they can you know, they can talk forever. Oh, yeah, which is great. I love that

Start time: 8215.48
End time: 8220.06
Speaker: Leo Laporte
Transcript:  Just never give the ai bot access to your checking account. Otherwise, they might be suckered

Start time: 8221.16
End time: 8224.41
Speaker: Larry Magid
Transcript:  Well, how long are you gonna get the nigerian money? Why are you here?  right

Start time: 8226.04
End time: 8247.96
Speaker: Leo Laporte
Transcript:  Uh, what a world what a world what a world we live in. Let's take a little break finish this thing up  Great panel. Love you guys. It's so good to see you  uh, i've i've asked both christina and uh  And uh larry to plug something you your chance to plug something dan gilmore  Anything you want to promote anything you're up to you want to tell the world about?

Start time: 8250.58
End time: 8265.66
Speaker: Dan Gillmor
Transcript:  Um, not quite ready i've got a project in the works that I have not  uh  i'm still  Trying to raise the uh  Research funding for it. So I can't really talk about it yet. Nice

Start time: 8266.62
End time: 8279.46
Speaker: Leo Laporte
Transcript:  But I bet if you go to dan gilmore.com d-a-n-g-i-double-l-m-o-r  You'll keep up on what?  Dan has been up to and i'm sure he'll post it there. I guess i'm shamefully lax in my blog

Start time: 8280.98
End time: 8296.32
Speaker: Dan Gillmor
Transcript:  Who isn't right? Who is my my mastodon feed is more likely. Okay, relevant fair enough  I only I only use I haven't a twitter account still but that's just to prevent  somebody from taking my user name if I

Start time: 8297.40
End time: 8350.18
Speaker: Leo Laporte
Transcript:  Me too. I actually deleted everything on there  Um, I keep it so I can still see stuff  So nobody will be leo laporte and occasionally i'll dm people because there's still people the only way I can reach them  Is dming him. Let me show you if you're on mastodon. I'm on the on the uh advanced web interface right here  You just type in at dan gilmore and there he shows up right there. There's a lot of other ones  These are all retweet  Sites and you could tell because they don't have a icon but this one at mastodon.social. I think that's the real you  I'm already following you  Maybe this would be a good thing for you to add to your mast. I like to follow people like dan who  Actually post post interesting stuff. I follow you too larry and you too christina. You've been on you've been on mastodon quite a bit  Yeah, I like it. Yeah. Thank you. Yeah, I like mastodon. I'm a mastodon. I'm blue sky. Are you on blue sky too?

Start time: 8350.32
End time: 8377.82
Speaker: Christina Warren
Transcript:  I think I'm on blue sky. Yeah. Yeah, there's no underscore on blue sky. So i'm just film girl dot b sky dot social but um, I uh,  yeah, I  I'm probably never gonna be able to leave twitter to be honest, but I mean until you know, it literally falls apart which  Might be just a matter of months. We'll see  But yeah, i've been spending a lot more time on the other platforms, which is really great. Why is that?  What's your mastodon handle film underscore girl at mastodon dot social

Start time: 8378.60
End time: 8433.62
Speaker: Leo Laporte
Transcript:  Okay  So again, just go to your mastodon instance and at film underscore girl and it should be able to find that pretty quickly  That's there you are. Yeah, I found that's the easiest way to follow people. Yeah  And i'm following you on blue sky too. I I the the the  It's still out the jury's still out on blue sky. It's gotten a lot like twitter  My fear here's my fear, you know, the whole idea of blue sky is it's going to be federated just like mastodon is  Which is a good thing. I think  we've learned from the fact that twitter could be bought by a  crazed evil genius billionaire  That it's probably good not to be centralized into a single company's social  Um, but the problem I have at this point is because they haven't yet set up federation and there's more than 100 000 people  At the main blue sky instance  Federation may be just you know dead on arrival with blue sky

Start time: 8434.74
End time: 8495.94
Speaker: Christina Warren
Transcript:  I think it depends because I mean like I I think that that um  I think if you have a good default instance, then it can be  Good. I think that the way that search works if search can work around  I mean, they're still trying to figure out the federation aspects  But like if search can work across federations that you're part of and that would be a big improvement  That's one of my biggest I understand is there for ideological reasons. I disagree with those reasons  I'm mastodon, but that has been one of my my biggest kind of problems with mastodon is the fact that search isn't there and  and so, you know like that there are some clients that will cache things and do it, but that's a hack and  So, I don't know. I think we'll see I like the idea  Of being able to kind of exist in two different spaces because if that's the case  Like if i'm not going to lose out on the benefits of being on the main instance  I wouldn't mind having my own server, which I thought about doing with mastodon mastodon  I can't do that because I can't bring in my post over so you can migrate your username, but you can't take your post over and  The the team seems very not interested in doing that at all, which is frustrating

Start time: 8496.70
End time: 8500.18
Speaker: Dan Gillmor
Transcript:  But I think there are clients already being developed that will bring the posts over

Start time: 8501.74
End time: 8525.10
Speaker: Christina Warren
Transcript:  For mastodon. So yeah cal key cal key will do it  So there are some forks that do it but but other  Um, but in terms of like the core mastodon project  At least last time I checked which was like two weeks ago because people keep yelling at me about it because I keep yelling about it  They're like no you're wrong and i'm like i've read all the prs and i've read the discord stuff  They don't care  So should I agree?

Start time: 8525.92
End time: 8532.02
Speaker: Larry Magid
Transcript:  Has anybody written a really friendly user's guide to mastodon for people who you know need to learn the basics of it?

Start time: 8532.74
End time: 8550.50
Speaker: Dan Gillmor
Transcript:  There are a couple. Um, i'll have to dig them out but same  It's and it's a really rapidly  uh  The it's a moving target in a lot of ways  I think  I'll have i'll have to go find it, but I would I would go to mastodon.help

Start time: 8552.16
End time: 8598.42
Speaker: Leo Laporte
Transcript:  To start. Uh, this has been around since the beginning of mastodon. It's it's look it's not  Completely user-friendly because there's a lot of information  But uh, it does describe everything  Um, and there have been a number of attempts to make uh videos that explain it honestly  Don't tell anybody but I don't want to make it that easy  I  I kind of like it that there's a barrier to entry  in fact, we're our own mastodon instance, which is uh twit.social is  Uh, you have to apply, you know, you you don't get in automatically you have to say I want to  You know, and you have to know something about twit, uh, or i'm not going to let you in  And uh, I think by doing that we get a higher quality of people in there now I admit that's a perfect use case

Start time: 8598.64
End time: 8602.90
Speaker: Dan Gillmor
Transcript:  Yeah, but you're describing it really ideal the way it ought to work

Start time: 8603.18
End time: 8652.34
Speaker: Leo Laporte
Transcript:  Yeah, but I also understand that uh, you know, there are movements the arab spring  uh black twitter and so forth where  Ease of entry is very important to getting to building a critical mass in a community  And I understand that uh, and I hope solutions come along  Uh for that, you know mastodon could be a little prickly but remember mastodon is just a part of  The fedaverse the activity pub based fedaverse calkey is another  fedaverse clone, uh  Miski was calkey's based on miski then there are a lot of them. There's pixel fed. There's uh, I mean  Pluroma I can go on and on so I think that these underlying protocols are what's key  I think at proto the underlying protocol  For blue sky is in fact, I note that you maintain  a uh a github stars collection

Start time: 8653.24
End time: 8674.96
Speaker: Christina Warren
Transcript:  Yes for for for both. Yeah for both for both that i've blue sky goodness and i've mastodon goodness  Oh, that's awesome those so i'm trying to basically have collections  Of repos that I find on github of interesting things related to both projects and mastodon  I should probably rename activity pub goodness, but honestly like mast on is for better or worse  Everybody knows the name mastodon but I kind of I

Start time: 8676.58
End time: 8685.70
Speaker: Leo Laporte
Transcript:  I resent that a little bit because mastodon is just one example of what you could do with activity pub  I agree completely of activity pub in the fedaverse is it can be a lot of different things

Start time: 8686.36
End time: 8736.00
Speaker: Christina Warren
Transcript:  So no, I fully agree. I fully agree. I mean  I am too. I mean look I and I really think that the at proto the at protocol is very interesting and again  They're still working on things  But I think a lot of the decisions that they've made again  The most primary one for me being just the way that account  Portability works. I think it's superior to how it works in activity. It absolutely is 100%  And and and they would be very thoughtful about that. That's the chief difference frankly  It is and and and people are working on bridges to make the two work better together, which I think is really really good  micro.blog  My friend mantan's project that he's been working on for  God, I don't remember how long ago the the kickstarter was but I backed it on kickstarter. Yep. Um, and and and  You know because I wanted to support what it was doing. I don't even have an active account anymore

Start time: 8737.50
End time: 8743.36
Speaker: Leo Laporte
Transcript:  You could post on a mastodon via mic and blue sky and blue sky. Oh, I didn't know he had at proto

Start time: 8743.99
End time: 8779.92
Speaker: Christina Warren
Transcript:  Yeah, yeah  He added that several weeks ago like very early on which I thought was really interesting. And so that I  To me that's kind of like the perfect  Sort of things you can cross post to mastodon tumblr blue sky medium linkedin and flickr which is great  Um, and and I I love what you know what he and that team is is building  Because I think to your point, you know, it's it's easy to kind of do the the twitter clone  But if you can build these different types of experiences and stuff then you really have something  And for me having that control over my user data is really important

Start time: 8780.18
End time: 8811.76
Speaker: Larry Magid
Transcript:  So i'm going to say something that hopefully doesn't get me kicked off as a future guest on twitter  But based on the conversation that I just heard  This is clearly not ready for prime time and I I say that was great love and respect  Yeah for the three of you the reality the people who I write for  Wouldn't have a clue  Um, and if they're listening to this aspect is part of you know, they're going to need a translation  And I think that somehow if mastodon is to catch on or blue sky or anything else  It has to be made much more simple  Uh, it's not hard to sign up. I admit

Start time: 8812.34
End time: 8828.24
Speaker: Christina Warren
Transcript:  That's what blue sky is right now blue sky right now to be just like twitter is just like twitter  And the thing is and that team's goal is a little bit different than mastodon  I'm not gonna try to say one is better than the other because they're different  But they really don't want you to have to think about the federation properties about it at all

Start time: 8828.48
End time: 8832.66
Speaker: Larry Magid
Transcript:  And that was confusing for me when I thought right which which federation which do I join?

Start time: 8832.78
End time: 8864.48
Speaker: Christina Warren
Transcript:  I do annoy you. I know it's a very and and unfortunately a lot of people say it doesn't matter, but it does matter  Yeah, and so, um, I think that that that is the biggest barrier to entry for mastodon  But I do think that that is I think the blue sky which is still in in private beta has going for it  Is that I was I would venture to say that probably that a mastodon  A vast majority of users know and care about the federation aspects. That's important to them  I would say that i'm blue sky because i'm acting on both  The vast majority do not care and let's go

Start time: 8865.98
End time: 8966.02
Speaker: Dan Gillmor
Transcript:  Yeah, can we keep in I apologize sorry, I know you're fine  um  Keep in mind that it's really since november that  Anyone beyond a very small  community  Has cared at all about this the progress in just a few months has been astonishing  And we're going to see more the fact that mozilla  Has set up an instance and they clearly plan for it to be or are working on it being something that will be  Usable  In a fairly easy way by people they've they're they're carefully managing that process  um  Is point of development but you're not wrong larry. The thing is that  This is the moment. This is really the moment when  Uh some leverage applied wisely  Could produce incredible downstream effects and i'm i've been begging my philanthropist friends  to jump in yes and  to  to basically think about  the d the re  decentralized  internet as a mission  and to look for ways to help that happen  So if you're if you have a lot of money listening to this  and or at a  Foundation or a charity, please think about this. This is this is the moment  When you could put in what's a relatively small?  uh  Donation and and investment

Start time: 8967.14
End time: 9027.62
Speaker: Leo Laporte
Transcript:  Somebody like craig newmark amazing output. There are some really good people out there who care a lot about these things  Uh who could really make a big a big big difference  So you see another thing elon musk has really changed the world hasn't he yeah  And we're we're so grateful to elon for having let us know that a centralized  Social network is a bad idea  Um, i'm hopeful. Yeah, I know as you've stayed on twitter christina  Yeah, and i'm hopeful that twitter will  Get through this because really it is it has been a since 2006 a very valuable  part of the conversation  Uh, and and I grieve its loss  And I don't think it's necessarily over. I think elon it seems highly likely  uh, you know, uh  Was it fidelity just downgraded? Uh, yeah. Yeah, they declared their investment in twitter  Uh, not a total loss, but they basically said it's only really worth about 15 billion, which is a third right what elon

Start time: 9029.08
End time: 9067.88
Speaker: Christina Warren
Transcript:  Yeah, and and he he it was just you know, how it was like  I guess 50 less than what he claimed or yeah, even he thought it was only worth half  He thinks it's worth half and then it's it's really worth, you know, um half of that  so, you know, but but it's also worth what snap is worth and what uh pinterest are worth which  Honestly, it's probably fair. That's about right. No, but that's also probably that's also probably fair. Yeah  um, but I mean, you know like my my expectation  At this point and I don't want to make predictions because i've been wrong on all of them  Will be the he will he will sell at some point either sell or the banks will take it  Yes, I just don't know who buys it at this point is the real thing

Start time: 9068.18
End time: 9073.35
Speaker: Larry Magid
Transcript:  Yeah, I just don't know who buys it so elon will make a small fortune when he sells it because he bought it  With a big fortune

Start time: 9074.04
End time: 9093.92
Speaker: Leo Laporte
Transcript:  Yes, that's right  Actually, he he borrowed uh 13 billion from the banks. I think that's what's going to end up being the value of twitter  and the banks will just  Take it over when it goes bankrupt because I think that's what's going to happen. It's clearly not had  Positive direction as long as we're talking about go ahead if it matter what instance

Start time: 9094.30
End time: 9104.82
Speaker: Larry Magid
Transcript:  I mean, I know you want us to join twitter and but but from the standpoint of the user does it matter that much?  Which instance or community they join on mastodon you can follow anybody?

Start time: 9105.84
End time: 9211.56
Speaker: Leo Laporte
Transcript:  On any other mastodon instance unless the instance you're on has for some reason  Blocked it or as we call it de-federated it  I have de-federated a number of in fact, you can even see when you sign up or go to an instance  What other instances are blocked?  uh, I de-federated for instance  Russia just created its own mastodon instance called. Um,  Pravda.ru  Uh, I instantly de-federated it because it's clear that that was going to be a massive source of disinformation pumping into the network  This is by the way one of the strengths of federation is I as a as a person who runs my own mastodon server can say no  Nothing from pravda.ru yet on my server  But mastodon.social all of the normal big servers if just as I did I entered in your name  Dan and I found you and I added you it was no trouble at all  So I will see you in my home feed of people I follow  But what's cool about having an instance?  There's a local timeline the people on our twitter social local timeline are all twit listeners  They're all you know  Which makes it have it has a community of its very own  So this is the home which is people I follow this is the local timeline  I'm running the advanced interface. Not everybody runs that a lot of people like it to look like twitter  And this is the what they call the federated timeline. That's interesting because that's everybody  Followed by anybody on the local server. So that also has a friends of friends local  Context to it. So yes the server that you follow  Definitely impacts what the locals look like what the federated timeline looks like but you're in charge more than one

Start time: 9211.70
End time: 9214.92
Speaker: Larry Magid
Transcript:  Could I be at larry maggot on on your server as well as?

Start time: 9215.84
End time: 9219.66
Speaker: Christina Warren
Transcript:  No, not unless you want to maintain two different accounts because they're there you could

Start time: 9220.36
End time: 9274.12
Speaker: Leo Laporte
Transcript:  There's nothing to stop you from doing that. I have multiple accounts, but you want to have which you could switch  Larry maggot, I want you want to have one primary account  For discover ability but also because you it's non-portable the content you post so you really kind of if you can light at the right place  And stay there  You know microblogs interesting. I don't I i'm uh been paying three bucks a month forever to manton  So I really should take a look at using microblog to post. I'm at leo at leo.social  Is my mastodon or rather my fediverse name at?  Microblog and i'm at leo at twit.social  So I have those two but I only post on the twit.social one. I don't know I  I think let a thousand flowers bloom has happened  Uh, does there have to be one that we all follow? Well, there's an advantage to that  There's also a disadvantage to it

Start time: 9275.60
End time: 9296.18
Speaker: Larry Magid
Transcript:  Well, I like the idea that you know, you can decide  You know, you don't want dot ru on your on your server and that's your right to do that  You're not really censoring them. You're you're simply saying that they're i'm kind of saying they can't exist  Right you are you're not saying that they can't exist. You're saying they can't exist on my server, right?  So if you want dot ru you can go somewhere else and get them

Start time: 9297.00
End time: 9302.44
Speaker: Dan Gillmor
Transcript:  His you his server is his living room. He's not going to invite thugs in right? Yeah

Start time: 9302.98
End time: 9347.08
Speaker: Leo Laporte
Transcript:  And I block natsies and I block  You know  You know if there are griefing servers, which there are in the fedaverse those those are block. I block about 20  Servers and whenever there's a problem i'll consider it and so forth  But so far because and by the way, i'm one person  I might spend 15 20 minutes a day at most  Moderating I don't have to spend a lot of time because we have a tight-knit group  There is there are very good  Tools for an individual to block a feed or block a server themselves  So if I didn't block pravda, but you wanted to you could do that for yourself on your yeah  On your feed. I mean, I think there's pretty good tools  There's no quote tweet and there's no global search that that's

Start time: 9348.04
End time: 9401.74
Speaker: Dan Gillmor
Transcript:  I think the lack of quote tweets, which is less crucial, but the lack of search is a big deal to me  That that's got to be fixed and yeah  it's and it's really improving quickly though and the  People are doing forks that are still completely  Interoperable that do everything I want. I may I may end up on calc or something like that, but  This is really a wonderful  Fervent going on and isn't it great? Yeah. Yeah, I think something important's happening larry if you want some some  Personal advice on it. I've been doing  Mastodon now for six months and it's pretty great then  I have a third the number of followers I had at twitter and ten times the engagement  I have genuine serious engagement. It's it's it's astonishing

Start time: 9402.52
End time: 9408.62
Speaker: Larry Magid
Transcript:  Yeah, i'm on new fee. I just picked out kind of at random but um, that's fine. I haven't done much yet. Yeah

Start time: 9409.58
End time: 9466.71
Speaker: Leo Laporte
Transcript:  Just stick stay there. That's your community. Uh, and uh, it's a bunch of news people  So I think that's fine  Uh, how about reddit as long as we're talking social  Uh reddit which is owned by the massive magazine publisher. Conde. Nass the people publish the new yorker vanity fair  a bunch of other magazines  Uh has a has announced that they're going to start charging just as  twitter does for their api access and just as twitter had  Uh reddit has a number quite a few of third party clients  That don't show the ads  Uh and allow people to change their experience on reddit. This is one of them apollo  This is for ios. This is what I use on ios. Yep. Really really nice and the developer is very engaged  Uh, he encourages donations, but it's free  very powerful

Start time: 9467.50
End time: 9486.28
Speaker: Christina Warren
Transcript:  There's a paid version too. So it um, it yes there there's a subscription but he  Is but it has like I think a million and a half users  And many of them are free and then the people who do pay what he's charging  Um, the new changes that reddit is going to introduce will basically make him make it not sustainable even charging

Start time: 9486.56
End time: 9552.34
Speaker: Leo Laporte
Transcript:  It's so his name christian sellig. He uh was on a call now unlike elon who just cut off third party access  And at first denied it  Then said they broke the rules then said all right. Yeah, we're cutting it off  Which is his by the way, it's his privilege  He didn't do it very nicely, but it's his privilege because it does undermine, you know  The the the financial structure of twitter because ads are what pays for twitter  So I it's certainly within call condi nests  uh power and and it's appropriate for them to to say this  He talked to them. They have been unlike elon calling everybody talking to everybody  He talked to them and they explained well, I think it's twelve thousand dollars  For 500 000 accesses. I can't remember what it was  He did some math and based on the number of people that use apollo  He said it's going to cost me 20 million dollars a year to continue  my app  Uh, huge mistake. It's not sustainable  So if twitter does this it will put uh, apollo out of business joey out of business a lot of third-party apps

Start time: 9552.90
End time: 9599.54
Speaker: Christina Warren
Transcript:  There's already a mac app that I was using called uh stellar that I paid for actually  That has already announced that they are sunsetting it because  They had kind of a free freemium model and they basically have said that they  They're not making enough money to be profitable to change the upcoming changes  because  Like I personally don't have a problem with them charging for the api. I think the pricing is insane  um, especially given the fact that  So many of their power users who do a lot of free labor for them  Like this is unlike twitter in the sense that most of the things that make reddit work are the the admin or the mods rather  That are not paid and many of them rely almost entirely on third-party tools because  the regular reddit tools are not equipped for their needs and um, and so

Start time: 9601.54
End time: 9643.24
Speaker: Leo Laporte
Transcript:  It raises an interesting question because yes, they own reddit condi nass does they can monetize it  Anyway, they choose yet the content of reddit just like the content of twitter is created by its users for free  We we post on reddit  Uh, and that's what makes reddit exist and if users can't use third-party apps many users distraught. There is a boycott  Um are not a boycott exactly a protest that's going to happen. I think next month  uh where a lot of  Subreddits the the the groups on reddit will go dark next week. I think it's next week. Yeah, okay  Sorry, yeah, we'll go dark for several days and that will be interesting that might that might show how important this is to people

Start time: 9644.32
End time: 9693.57
Speaker: Dan Gillmor
Transcript:  Well, I I am the one benefit of all of these things is that we are getting  schooled  in the  kind of  nastiest possible way  About the dangers of centralized social media corporate owned and in you know  uh  bad guy owned in one case, uh  social media making capricious and and and  wildly counterproductive  moves  uh, and  I think maybe condi nass is expecting that this was a ploy  That they could then lower the price that and and get people to do it. I I think they've  made a kind of

Start time: 9694.36
End time: 9774.92
Speaker: Christina Warren
Transcript:  Drastic error in this case. No, I agree again like and christian has even said like he  um  Quinn nelson, um sassy q on youtube did a great interview with him that went up on youtube  I think it was yesterday. It's like 45 minutes long and you know, he even said that he does think that it's fair that he pays  You know some of his profits essentially to reddit  but the the split that they're wanting is is just not sustainable and  You know to me it would be much more honest if reddit would just say we don't want any third-party apps to exist  I mean at least elon did that like i'm not going to give the guy credit for anything  But at least he was honest at the end and and twitter as a company hadn't wanted third-party clients for a long time  Even before you know, he took it over  But but I think in reddit's case that the problem is is that you know  This really is a big part of how mods use their tools and they'd gone from actively  You know encouraging and using and and helping out the devs to this change  And I think that there are some devs who might not want to pay anything and that's okay  Some would but what's also what's so odd to me is that they don't let the ad aspects  Into their api like and twitter did the same thing  I get that you're saying okay, we're we're losing out on impressions and this and that okay  So make that part of the api and make it a requirement that clients use it

Start time: 9774.94
End time: 9801.36
Speaker: Leo Laporte
Transcript:  I don't think advertisers would support that for the same reason you don't see ads when you're watching  YouTube or some other rebroadcast of local  Channels, they don't carry the ads because the advertisers say no no, that's not part of what we're paying for  So I think that's why they don't do that. I think that's an advertiser mandated. I agree  It would be nice to be able to do that, but that's not going to happen  Advertisers don't they want to know exactly where their ad is going to be and they want to know how to count that

Start time: 9802.16
End time: 9847.62
Speaker: Dan Gillmor
Transcript:  but the  Again, the basic the basic thing going on is that  the centralized sites  Rely they count on these third party developers to to may help make them popular  And then the minute they have sufficient leverage  They cut them off. Yeah, remember even before elon twitter did this once before yes  Twice before twice before as as an investor in one of the companies twitter killed way back then I was I was  you know, I got i've been schooled in this a number of times but the  As a user to hell with it. I'll just go over and do stuff somewhere else. I don't I don't need the twitter fame anymore

Start time: 9847.74
End time: 9883.34
Speaker: Leo Laporte
Transcript:  That's the that's the beauty of this is there are many choices now  um june 12th through 15th here's the r slash r slash  Samsung as an example, uh, this subreddit will be going private june 12th through 15th in protest  uh many many, uh  subreddits will  um, and I think khan they all sit up and  Take notice. Maybe this is a negotiating ploy and they'll come back. In fact, they've already said oh, no, no  No, we weren't going to charge them. We would never charge them 20 million  We there'd be a way to do this. So maybe they'll come back with uh, something. I hope so it was it was interesting. Um,

Start time: 9884.66
End time: 9911.13
Speaker: Christina Warren
Transcript:  There was something else spurred me to look into this and I was just trying to think of like who has the most expensive api's  And I was shocked to look and find discover that imdb does now finally have an api  But their pricing  Is like the most obscene  Uh api pricing I I can I can recall  Seeing so this is like a relatively new thing. I think that they've had uh, and  Their pricing on their api starts at like 450 000 a month and that's before usage

Start time: 9914.30
End time: 9915.13
Speaker: Leo Laporte
Transcript:  Yeah, wow

Start time: 9915.62
End time: 9934.84
Speaker: Christina Warren
Transcript:  Which which is insane because I think I think the reason I looked into this was that  Somebody people were complaining about the new max app, which is awful  And it didn't have a lot of the credits listed and someone said well, why aren't they just using the imdb api?  And then I I I was like I had the same question and I looked into it and I was like  Oh because david's dazlov is very cheap. That's why

Start time: 9935.68
End time: 9942.86
Speaker: Dan Gillmor
Transcript:  There there that's that's just saying don't use this. That's absolutely. Oh 100 percent. Yeah. Yeah, so so the the essential metadata

Start time: 9943.72
End time: 9959.99
Speaker: Christina Warren
Transcript:  This is for um movies tv and over the top is 150 000 plus metered costs  uh, and then the complete data set is um, or excuse me, um,  The imdb box office mojo for movies tv over the top is 400 000 a month plus meter costs

Start time: 9962.16
End time: 9965.24
Speaker: Leo Laporte
Transcript:  Wow, pretty dumb imdb is owned by amazon, right?

Start time: 9966.18
End time: 9971.48
Speaker: Christina Warren
Transcript:  Yeah, they've owned them for I think 20 years now at this point. Yeah used to be this is a perfect example

Start time: 9972.83
End time: 10002.24
Speaker: Leo Laporte
Transcript:  uh  of there were a number of sites like this cddb was another one where  Users created it to put all they knew in there like a wiki or whatever  And as soon as it gained critical mass a company came in and bought them  And all the users said wait, what what?  So again a lesson learned, um  These you know, yeah, we're in late stage capitalism folks. If somebody calls you screaming  They want your money. Yes. Okay, that's just the way it works

Start time: 10003.28
End time: 10008.32
Speaker: Christina Warren
Transcript:  Let me take it. Unfortunately that that was going the tv db  Exists as an alternative. Oh good

Start time: 10009.00
End time: 10222.57
Speaker: Leo Laporte
Transcript:  Yeah, that's the way to solve this  Just create a and in fact, there's already a number of people creating reddit reddit clones hoping that they can  Uh take advantage of this. We'll see  Uh quick break and then we're gonna wrap things up with a panel. That's been very patient but awesome  Awesome our show today brought to you by cisco  Rocky the experts in cloud-based networking for hybrid work whether your employees are working at home  at a cabin in the mountains  Or a lounge chair at the beach. I choose the beach by the way a cloud  Managed network provides the same exceptional work experience no matter where they are and that's what you want  You may as well roll out the welcome at hybrid work is here to stay  We tried to get people to come back  No hybrid work works best in the cloud it has its perks for both employees and leaders workers can move faster  Deliver better results with a cloud managed network leaders can automate distributed operations build more sustainable work spaces  proactively protect the network  Idg market pulse research just put out a report that marrakech commissioned it highlighting top tier opportunities in supporting hybrid work  besides I mean  We workers love it, right? But hybrid work is a priority. Also, this is this kind of surprised me for 78  78 of c-suite executives because leaders want to drive collaboration forward  They they want to stay on top of or even boosts  productivity, of course security is always a concern  Hybrid work does have its challenges. The idg report raised a red flag about security  48 percent of leaders report cyber security threats  As a primary obstacle to improving workforce experiences the workforce wants it. How do we secure it?  Well always on security monitoring is part of what makes the cloud managed network. So awesome  It can use apps from marrakech's vast ecosystem of partners turnkey solutions built to work seamlessly with the marrakech cloud platform for asset  Tracking and location analytics and more you can actually use it if you're hybrid for work  The office too you can gather insights on how people are using the work provided workspaces  In a smart space environmental sensors can track activity and occupancy levels stay on top of cleanliness  Workers can reserve workspace based on vacancy and employee profiles, you know hot desking so employees can you know quickly find a place to work?  Locations in restricted environments can be both booked and advanced and include time-based door access  Again security becomes very important  And then of course you've always got mobile device management integrating devices and systems  So that it can manage update and troubleshoot company-owned devices even when the device and employee are on the beach  Turn any this is the whole point turn any space  into a place of productivity  Empower your organization with the same experience no matter where they work. How do you do it with marrakech?  And the cisco suite of technologies learn how your organization can make hybrid work work marrake  m e r a k i marrake.cisco.com  slash twit  Your workers want it you want it. Here's how you can do it safely and effectively marrake.cisco.com  slash twit  You did you dan or do you need to go I heard you squeal when I said we're almost done  I

Start time: 10225.40
End time: 10237.88
Speaker: Dan Gillmor
Transcript:  I I had I uh  I postponed it another call. Okay, we'll do it real quickly. We'll we'll wrap this up  Uh, now you we have till tomorrow. I'm fine. Oh, okay. Well that case

Start time: 10238.60
End time: 10250.38
Speaker: Leo Laporte
Transcript:  Here's what you missed this week on twit  Oh, you know the problem is I change where I part is that that's show me show a single I can't tell  I think the new one doesn't work. Oh really? Yeah, that that's

Start time: 10252.02
End time: 10255.00
Speaker: SPEAKER_00
Transcript:  Yeah, it's really unflattering for that side of your head

Start time: 10256.34
End time: 10269.08
Speaker: SPEAKER_06
Transcript:  Well, I wonder where he's going now  previously on twit  Ios today rosemary orchard and I mica sergeant are going to be covering final cut pro and logic pro which are now

Start time: 10269.82
End time: 10283.96
Speaker: SPEAKER_03
Transcript:  On ipad all about android today. I give my review of the one plus pad  I've got the stylo that uh snaps to the top and right away  I get the little notification that tells me that it's connected just like an overall package like I really

Start time: 10284.66
End time: 10312.84
Speaker: Leo Laporte
Transcript:  Was surprised at how much I like this keyboard case mac break weekly. Uh, by the way alex I think your uh,  Lsd addled nephew did in fact design the home page for  WWDC  it's uh  Trippy cool man to say the least  The melting apple  I think if you look at it on an iphone, uh, there's a vr  Oh, what's this?  Oh, he's found the apple. It's floating over my head

Start time: 10315.40
End time: 10317.96
Speaker: SPEAKER_03
Transcript:  Twit does indigestion keep you up at night?

Start time: 10322.18
End time: 10423.40
Speaker: Leo Laporte
Transcript:  Soothing your tech indigestion one show at a time  By the way, I don't know when this happened, but we seem to have replaced our professionally trained human announcer  Jim cutler with an ai voice of mine  So, I guess there's one more person that'll work. Thanks to ai. Sorry about that. Jim  Holy cow. He was doing it for free. Maybe  We just didn't we don't save money. We just  Uh, let's see. What else amazon's gonna pay 30 million dollars to settle fdc privacy complaints  Over their ring doorbell and amazon echo  There's been a number of judgments lately meta lost a big one. Was it 1.3 billion euros in uh,  In ireland, uh because it was spying on people and selling that information on good. I hope regulators crack down  Um notice though here in the united states. It's very it's very it's very quiet  No, don't don't mess with that  Uh intel is gonna put an ai engine in its new meteor lake systems on a chip. I learned that actually at build  Everybody's processors now have a a i engine in there  And this made me very sad the amazon echo is losing samuel jackson  and melissa mccarthy  I paid for those celebrity voices and I want them but no  Uh amazon will refund you, uh, but you have to contact customer service  It was really nice because samuel jackson you'd you'd say samuel. What's fun? Yeah, you say what's the weather and he would swear up a blue streak  If you asked him, why did he have you done this christina?  Ask samuel. Why does he swear so much?

Start time: 10424.42
End time: 10427.60
Speaker: Christina Warren
Transcript:  Oh, I haven't asked him that okay. I will I don't have to swear. I'm

Start time: 10428.46
End time: 10455.56
Speaker: Leo Laporte
Transcript:  It's very good. It's very good  Melissa mccarthy I would always I would ask samuel what the weather is gonna be and they'd say melissa  What's the weather gonna be and she would always say something cute. It was fun  99 cents at launch they were then four dollars and 99 cents  I think we always knew it was time limited. They're not gonna have an unlimited license to use uh celebrity voices  But amazon says after three years  We're gonna wind down the celebrity voices. You'll be able to continue using them for a limited time

Start time: 10456.70
End time: 10461.06
Speaker: Larry Magid
Transcript:  If you want your money back, you can just use ai to create their own celebrity voices. Yeah

Start time: 10462.06
End time: 10498.90
Speaker: Leo Laporte
Transcript:  Oh, yeah, well it was ai actually because samuel l jackson went in  He would record some stuff some of it would be act you could tell would actually be him  And then when he was saying the weather it would kind of be a little less lively  That was the only difference  Uh through june 7th for uh, well, that's golly. That's three days from now  for samuel l jackson  Melissa mccarthy and shakila. O'neill will continue through september 30th  I'm gonna miss that  Part of this is andy jesse saying  I'm losing money like crazy

Start time: 10499.78
End time: 10544.08
Speaker: Christina Warren
Transcript:  Yeah, and I can't imagine that the usage honestly was great because they were fun  It was a fun party trick, but I can't imagine that most people used it  So if you have to pay like and and also I also imagine that the celebrities when they're maybe being asked to renegotiate the contracts  Given all the stuff that um is uh, you know happening with the writers guild and I know that the screen actors guild was looking at things too  They wouldn't be wrong if they were wanting to maybe ask for more money. This is just my interpretation. I have no idea  but you know, I I could imagine that they would  Possibly be wanting to negotiate for more or similar terms and amazon might not once you give an usage being lower  So yeah, but andy it's cost cutting time and i'm sure he's looking at this like  Very few only christina and leo are using. Yeah, basically it's us basically. So

Start time: 10544.88
End time: 10546.66
Speaker: Leo Laporte
Transcript:  We're not gonna personal note from andy

Start time: 10548.44
End time: 10549.96
Speaker: SPEAKER_00
Transcript:  Right, we know you like you

Start time: 10551.72
End time: 10577.70
Speaker: Leo Laporte
Transcript:  Uh, honestly, i'm not in a hurry to go home. We this show would have been over an hour ago if succession we're on tonight, but  I know very sad  I love that. What a great show four seasons  Uh something like 40 episodes, which is if you think about I mean a movie is what two hours is 40 hours or more  of content  Uh, and yet this the standards were very high. I'm sure many emmy awards. They've already won 13

Start time: 10578.28
End time: 10587.24
Speaker: Larry Magid
Transcript:  I'm sure they'll win many more this year. It was 10 last so mrs. Maisel and succession over  I don't have anything to watch anymore. I know I was gonna say I was gonna say barry as well like

Start time: 10587.94
End time: 10663.70
Speaker: Christina Warren
Transcript:  just um  I watched succession. Um in a bar  Actually that is co-owned by cousin greg  And uh, it was no it was packed. It was I was it was in the lori side. It's called rays  It was amazing. Did greg show up see the screen. He did not he had his own thing  Yeah, yeah nicklaus. No, he had his own thing  But but the the place was packed and what we what we did because they were playing it over a sound system  Um, we couldn't see the screen. So I pulled up my phone  And we streamed it on my phone and put captions on and like a bunch of people were crowded around my phone watching it  um, but I have to say like watching the finale with like  I'm jealous other people literally crammed into this bar. It was great  And then because to just make it literally my perfect night the bar then turned into a taylor swift dance party  So it was genuinely like my around you  it really was like the venn diagram of people who care about those two things is  Larger than I thought it would be. Um, although a lot of the succession people left and a lot of the taylor swift people came in  um, but it's a different  A little bit. Um, but no, but it was uh, I bet willa willa would have stayed for both. I'm sure  Willa would have stayed for both. No, some people were wearing jerseys. I was like where my con heads at

Start time: 10665.84
End time: 10670.20
Speaker: Larry Magid
Transcript:  I'm sure greg would have kissed up to both sides as well. Oh, he would have absolutely kissed up to both sides

Start time: 10670.44
End time: 10693.94
Speaker: Leo Laporte
Transcript:  What's interesting is this?  Uh, so this is not as big a tv show as network television was in its heyday this  The show averaged 8.4 million viewers per episode, which is  pretty much nothing  Compared to 13 14 15 million  Uh that would watch a prime time tv show, you know every week mad men 30 30 million

Start time: 10694.96
End time: 10707.08
Speaker: Christina Warren
Transcript:  I mean, yeah, I used to get 40 million. Yeah, um, yeah, even the the sopranos, uh, you know  Much higher game of thrones much higher, but the I think the cultural impact of succession. Yes was

Start time: 10708.06
End time: 10717.16
Speaker: Leo Laporte
Transcript:  Outsized compared to the people who actually watched it. In other words you and I  I'm really influenced people bennie fear for a kid

Start time: 10718.08
End time: 10725.00
Speaker: Larry Magid
Transcript:  Sorry good pr for our friend caris wisher. I'd actually never listened to her podcast  But I always saw that on every episode that no kidding. She had a podcast. No

Start time: 10725.70
End time: 10730.28
Speaker: Christina Warren
Transcript:  She hosted which was great and yeah, she got good interviews and asked good questions. Yeah

Start time: 10730.44
End time: 10731.71
Speaker: Leo Laporte
Transcript:  You know like yeah, so

Start time: 10733.54
End time: 10765.29
Speaker: Dan Gillmor
Transcript:  It's very strange. I ended up watching the show and  Only because people keep reminding me it was on do I ever think about it in the week since it ended  uh  I just  I've never  Seen anything where  There was not a single  Character with any redeeming features except for the brother of the the uh  Uncle you uncle you

Start time: 10766.60
End time: 10776.12
Speaker: Leo Laporte
Transcript:  I don't know if he had redeeming features either  They were all awful  That was yeah, that's right. There was no hero is all anti-hero

Start time: 10777.04
End time: 10798.60
Speaker: Dan Gillmor
Transcript:  But but but they were these they were all loathsome. Yes, not just not just  not just sort of bad and  I just  Yeah, I don't that's not something I want to carry around in my warm memories. Sorry  I just I want to I just want to have it go into the past. I'm not even think about it

Start time: 10798.76
End time: 10804.76
Speaker: Larry Magid
Transcript:  You know with a documentary, right?  It was about the murdoch family. Yeah, that's exactly the murdochs and the red stones

Start time: 10805.80
End time: 10841.80
Speaker: Leo Laporte
Transcript:  Yeah, it was about it was about a few things. It was about late stage capitalism. It was about  control of mainstream media by a handful of  As you say evil people it was also though about family  And about how damaged these children were  By a father who was cruel and by all the excess they had growing up. So that made it more personal. I  You're right though. I think in in some ways the fact that there was no hero  Made it exceptional, uh  I I can't imagine if there was a good guy in this show. I would have wanted to watch it to be honest

Start time: 10842.12
End time: 10848.96
Speaker: Larry Magid
Transcript:  They're decent. I mean dad made a good point. I'm were there even anybody who's halfway decent?  Well, jerry was all right. Jerry was pretty jerry. Maybe

Start time: 10850.42
End time: 10855.36
Speaker: Christina Warren
Transcript:  Will I I I think willa was okay honestly the prostitute who ended up marrying the

Start time: 10857.64
End time: 10863.40
Speaker: Leo Laporte
Transcript:  So that he's presidential campaign  Would do better because he was married

Start time: 10864.18
End time: 10886.92
Speaker: Christina Warren
Transcript:  But also, you know his dad dies and he's and she still goes through with the wedding like  Yeah, could have called it off and he gave her that option, you know, like I think the money like everybody else in the show  It was all about the money. Absolutely  100. I mean, you know, you know, you're right like for a lot of people  This is not a show that they would enjoy and I totally understand that I personally loving the anti-hero. I really really did

Start time: 10887.26
End time: 10898.38
Speaker: Dan Gillmor
Transcript:  I think it was timely. I really I watched it. I watched it in total fascination. Yeah, not that I well  This is your business too. So in that sense, I enjoyed it. But I it  um

Start time: 10899.92
End time: 10932.84
Speaker: Leo Laporte
Transcript:  I don't I miss them all. I I don't know what i'm gonna do tonight. I'm so sad. I know  Which is hysterical  um, there was a good article in vanity fair i'm not sure I  Actually agree with the premise joy press writing will there be any successors to succession?  Is it the end of an era for hollywood or inspiration for a new beginning?  It's a reasonable question to ask. We don't all watch the same things anymore, right?  Right and even you know with succession 8.4 million viewers is a tiny fraction of the total audience

Start time: 10933.50
End time: 10948.10
Speaker: Christina Warren
Transcript:  Well, I mean but also to be clear that's like the live audience that they kind of are weak of audience  They capture we don't know how many people watched, you know and binging and other things are consumed  Well, it probably has a long tail. I don't know if that's what i'm saying if david zazlov will cancel it and move it to

Start time: 10948.80
End time: 10951.96
Speaker: Leo Laporte
Transcript:  You know roku channel or free or something but

Start time: 10952.48
End time: 10977.46
Speaker: Christina Warren
Transcript:  Honestly, that that's that's the big question, right?  Which is why I buy every season of it when it comes out because I  even before  um, he was  Installed I had my own concerns about that. I was like, oh  I don't know if this whole like era of let's just keep all the content here in our libraries to  You know boost the things for people like me is going to last  I bet they're going to take this back out again and try to sell it and they can make more money

Start time: 10977.66
End time: 10989.64
Speaker: Leo Laporte
Transcript:  And let's not forget the writers strike. I mean, uh, this was very much a writer's show  And without those writers, I mean, it's just going to be  Beverly hills housewives all the way down

Start time: 10990.80
End time: 11003.00
Speaker: Christina Warren
Transcript:  Okay in fairness in fairness this season the season finale and then the three part  We've only seen two of the parts of the vanderpump rules reunion is incredible television. So i'm not that's what I was afraid of

Start time: 11005.12
End time: 11052.31
Speaker: Leo Laporte
Transcript:  That's exactly what i'm thinking  um  There apparently is is a venn diagram of people who love succession and vanderpump rules and there's more than one person in that  Intersection  Uh, in fact, i've seen a lot of people say oh you should start watching vanderpump rules. I can't I can't I don't  I can't I can't  I am sorry. I apologize to dan. Uh, I hope your phone call wasn't important  I am thrilled that you spent some time with us  Thank you, dan kilmore  Your students are very lucky co-founder of the arizona state news colab  Uh professor at the walter cronkite school of journalism at arizona state  He's at dan gilmore on the mastodon  And I can't wait to hear what you're up to  with this new project

Start time: 11054.74
End time: 11061.46
Speaker: Dan Gillmor
Transcript:  I will uh  Let you know as soon as I great have something to right real nice

Start time: 11062.34
End time: 11074.68
Speaker: Leo Laporte
Transcript:  Actually, I realize we have uh, two people on the show have written for the mercury news chris. That's where I first met dan  Uh, and I guess uh larry you just published that article about the screaming woman on the mercury news

Start time: 11074.86
End time: 11085.32
Speaker: Larry Magid
Transcript:  So yeah, in fact dan I was dan's was sandwiched in between me writing for the mercury  And then they hired dan and I stopped writing for the mercury because he took over the main column and then somehow I got it back

Start time: 11085.52
End time: 11088.38
Speaker: Leo Laporte
Transcript:  I'm not sure why so you guys oh you even wrote the same column

Start time: 11089.36
End time: 11094.68
Speaker: Larry Magid
Transcript:  Sort of the main the main column in the business section on one day of the week. Yeah, I did not I'd like to think

Start time: 11095.58
End time: 11097.37
Speaker: Dan Gillmor
Transcript:  I'd like to think of it as feeding llms

Start time: 11100.70
End time: 11106.18
Speaker: Leo Laporte
Transcript:  Yes, all your columns have now been digested that's why there's so many inaccuracies now I get it I'm I'm I'm

Start time: 11107.96
End time: 11112.45
Speaker: Dan Gillmor
Transcript:  My my service as training data is  over temporarily

Start time: 11113.64
End time: 11151.60
Speaker: Leo Laporte
Transcript:  No more training data  Uh, I guess this is training data too though, right some llms might use audio  As well. I don't know. I don't know. Oh, yeah  Anybody who creates content should be worried  All right, we're going to stop feeding the llms now. Thank you larry maggot connect safely.org  That's where he is ceo and president and where you'll find uh that uh that victim, uh,  What is it? What do you call that the um, virtual kidnapping?  Virtual kidnapping, holy cow  Yeah, yeah, it's right there in the upper right, uh at larry majed on the twitter. Thank you larry

Start time: 11152.66
End time: 11154.92
Speaker: Larry Magid
Transcript:  My pleasure always always enjoyed. Oh, it's great to see you

Start time: 11155.76
End time: 11168.96
Speaker: Leo Laporte
Transcript:  When you've been you and dan and I guess christina too have all been with us for more than a decade  Yeah, isn't that amazing? I am so grateful. I i'm not i'm not kidding here. I'm just so grateful to the people who uh,

Start time: 11169.44
End time: 11180.94
Speaker: Larry Magid
Transcript:  Participate in our shows with us you i've actually known you leo for probably 25 years. It's amazing  Both young young upstarts in the media business a young pup  And eventually we'll figure out this craft

Start time: 11182.92
End time: 11191.88
Speaker: Leo Laporte
Transcript:  Thank you larry christina always great to see you christina warren senior dev advocate at github  Film underscore girl almost everywhere

Start time: 11192.70
End time: 11205.54
Speaker: Christina Warren
Transcript:  Almost everywhere. Uh, if i'm not film underscore girl someplace then it's film girl one word because the site doesn't support  underscores  Again, if i've been smarter about this, I would have been consistent and but I wasn't so here we are

Start time: 11205.84
End time: 11227.94
Speaker: Leo Laporte
Transcript:  I want to learn how to turn my micro blog into my uh, my uh, at proto  Site i'll have to see if I can figure that out  That's pretty cool. Yeah, i've got it. I've got it with the mastodoning  All right, i'll have to do some searching  That's a that's a nice plug for micro.blog and mantan reese's he's been he's been open web since the web was open

Start time: 11229.02
End time: 11258.01
Speaker: Christina Warren
Transcript:  Basically, I mean I was gonna say like one of the og kind of things  I when I think of the fedaverse, I really honestly think of micro blog  I agree. Yeah before anything else because it predated a lot of this other stuff and and uh,  I'm glad for him for for doing the work that he's done and and i'm glad to see so many other projects  You know come around  I mean actually if we really wanted to be honest, we could also give a  Shout out to dalton caldwell for the original app net which  You know had many of these same ideas, but obviously didn't work  so

Start time: 11259.02
End time: 11424.70
Speaker: Leo Laporte
Transcript:  Yeah, no, we ran we ran an identica  Server back in the day the duet army identica. Yes based on apt net the earliest version of activity pub  Uh, then when there was status net and there was a new social  Yeah, there were uh, friendica or something like that. Yep. Yep. Yep  Um, so we've been part of this  You know kind of alternative  Yeah social media for a long time i'm glad to see it's getting the attention it's long deserved  Thank you christina. Thank you dan. Thank you larry. Thank you all for being here  Especially thanks to our club members who make this show and everything we do  Possible, uh, I want to invite you to join if you're not yet a member seven dollars a month you get ad free versions  That means tracker free versions as well of everything we do plus shows. We don't put out  Anywhere else including the brand new scott wilkinson's home theater geeks hands on mac with michael sargent hands on windows with paul  therot the untitled linux show  Uh the giz fizz stacey's book club all of these are club only  Uh, we also have access to the discord. We have a club discord. That is honestly. I think this is discord is in many ways  the future of social  Um, and our discord is all made up of people who are in the club and we talk about not just what's going on in  The shows but all sorts of topics that any geek would be interested in plus we have special events ant pruett's our community manager there  And you get the twit plus feed which includes conversations like the weird one we had before the show  That no one else hears all that for seven bucks a month. I think it's the best deal possible  Just go to twit tv club twitter's annual memberships. There's  Family memberships corporate memberships as well, but your membership your members  You members really make a big difference and we thank you very much your membership dollars really help keep us on the air  It's a tough time for podcasting. I'll be honest  And if we're going to survive it's going to have to be with your help, please join  twit tv club  twit  We do this show every sunday. It's uh, 2 pm pacific 5 pm eastern 2100 utc right after ask the tech guys  You can watch us do it live as with all our shows almost all our shows at live.twit.tv  dot tv  If you're watching live chat live at irc dot twit dot tv or in the club twit discord after the fact  You can get the show at twit dot tv the website while you're there  I think it's what is it twit tv slash this week in tech?  Just you know click the button that says this week in tech. You'll see a youtube channel that has the video from every show  You'll also see links to various podcast players honestly subscribing  For any of our shows is probably the best way to get them that way you don't have to even think about it  There's audio or video feeds you choose subscribe, then you'll get it automatically and you'll have it

Start time: 11425.79
End time: 11425.83
Speaker: UNKNOWN
Transcript:  uh

Start time: 11426.46
End time: 11446.90
Speaker: Leo Laporte
Transcript:  For tomorrow don't forget. We will be here tomorrow  10 am pacific 1 pm eastern for wwdc the keynote and all our club twit members  Don't forget to go into the stage and you're going to be my co-hosts for that live stream. We'll see you in there  Thanks for joining us everybody. We'll see you next time  Another twit is in the can. Bye. Bye

Start time: 11452.05
End time: 11456.56
Speaker: UNKNOWN
Transcript:  Do the twit all right doing the twit baby doing the twit all right

