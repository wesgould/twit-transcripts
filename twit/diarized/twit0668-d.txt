;FFMETADATA1
title=How Many Cups in a Stone?
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=668
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" Or the state government or the federal or the state government?"): backtrack failed, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" It really doesn't have anything to do with tech news."): backtrack failed, resorting to original...
Failed to align segment (" I think when we first walked into the White House there was one laptop for the entire"): backtrack failed, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Start time: 1.35
End time: 32.42
Speaker: SPEAKER_07
Transcript:  It's time for Twitter. What a show we have today.  Candidate for Congress in California, Brian Ford.  He's a former advisor to President Obama on technology.  Matt Kotz, who's the current acting administrator at the US Digital Service.  And we're just going to throw in a Brit in the middle there.  Ian Thompson from the register.co.uk.  Lots to talk about, including the FBI's recommendation that you reboot your router now.  Facebook's shadow profiles, Amazon's face recognition,  and unintended consequences of the GDPR.  It's all coming up next on Twitter.

Start time: 35.86
End time: 37.08
Speaker: SPEAKER_06
Transcript:  Netcasts you love.

Start time: 37.92
End time: 39.00
Speaker: SPEAKER_00
Transcript:  From people you trust.

Start time: 43.02
End time: 142.90
Speaker: SPEAKER_07
Transcript:  This is Twitter.  Bandwidth for This Week in Tech is provided by Cashfly at c-a-c-h-e-f-l-y dot com.  This is Twitter. This Week in Tech, episode 668, recorded Sunday, May 27th, 2018.  How many cups in a stone?  This Week in Tech is brought to you by Betterment, the largest independent online financial advisor.  Sign up today at betterment.com slash twit and get up to one year managed free.  And by Quip, the first subscription electric toothbrush that can be bought at a dollar store.  And by Stamps.com, buy and print real US postage the instant you need it, right from your desk.  To get our special offer, go to Stamps.com, click on the microphone, and enter twit.  And by Molecule. Molecule is the world's first molecular air purifier.  It reduces symptoms for allergy and asthma sufferers, and for 75% of people with asthma.  It's a great way to get rid of your asthma.  And by Stamps.com, buy and print real US postage the instant you need it, right from your desk.  And for $75 off your first order, visit Molecule.com and enter the promo code twit.  It's time for Twit This Week in Tech, our Memorial Day episode.  And man, this is actually a very distinguished panel here.  I've got to kind of sit back and let the grown-ups run the show.  First of all, I want to really, I'm thrilled to welcome Matt Cutts back to the studio for the second time in his entire life.  It's great to see you, Matt.  Acting Administrator at the United States Digital Service still.  And what are you doing out here?

Start time: 143.88
End time: 155.86
Speaker: SPEAKER_05
Transcript:  So there's a lovely thing called the Code for America Summit.  I'll be out doing a little bit of public speaking and a lot of recruiting for software engineers, designers, product managers.  And so, said, as long as I'm out in California, I would love to see Leo.

Start time: 156.83
End time: 174.10
Speaker: SPEAKER_07
Transcript:  Well, yay! We're thrilled.  The Code for America Summit goes May 30th through June 1st.  And it's in Oakland. And that's cool.  This is actually kind of shares the mission with USDS.  Code for America is about getting coders to do things to help make America great again.

Start time: 174.40
End time: 182.40
Speaker: SPEAKER_05
Transcript:  That's right. The digital service is more...  Pardon the expression.  Well, we tackle the federal level and Code for America is often city and state level government.

Start time: 182.44
End time: 191.41
Speaker: SPEAKER_07
Transcript:  Awesome. Awesome. Great.  Also here, I want to welcome our friend Ian Thompson.  Always a pleasure.  You can help me with this esteemed panel.

Start time: 193.24
End time: 200.46
Speaker: SPEAKER_04
Transcript:  I was looking at the list of people who are on air and I was like, OK, you need to do your homework before you go on the show.  If you get this one wrong, that's going to count.

Start time: 201.24
End time: 223.34
Speaker: SPEAKER_07
Transcript:  Ian is at the register where he is now.  What is this? Editor?  News editor.  Big deal. Big deal.  And we're going to welcome a brand new member to the panel.  And it continues our policy of bringing great congressional candidates on Twitter to help get some smarts into Congress.  Brian Ford, it's great to have you. Welcome.

Start time: 224.23
End time: 228.14
Speaker: SPEAKER_02
Transcript:  It's awesome to be here. We need more technologists in Congress.  This is a great place to talk to them.

Start time: 228.40
End time: 238.84
Speaker: SPEAKER_07
Transcript:  Even though Brian doesn't know Matt's, he knew about Matt's because he worked in the Office of Science and Technology Policy during Obama's presidency.  And in fact, I think USDS was kind of one of the initiatives, you guys.

Start time: 239.50
End time: 255.90
Speaker: SPEAKER_02
Transcript:  Yeah. I mean, to just show you how far we came.  When I joined Team CTO, there was about six of us and I was the only one who could code.  And I'm a crap coder.  And then we get to a place where ultimately we have Matt Cutts leading USDS.  Isn't that awesome?  Yeah. That's how far we came.

Start time: 255.90
End time: 260.40
Speaker: SPEAKER_05
Transcript:  Well, and I am also a crap coder. But we have 175 other people who are very good coders and designers.

Start time: 260.92
End time: 281.98
Speaker: SPEAKER_07
Transcript:  Matt, an early employee at Google, took a leave of absence and now is full time at the USDS. It's really great to have you.  Brian is running for Congress in the California 45th District.  The incumbent there, Mimi Walters, is probably running unopposed in the primary, I would guess.  We're an open primary in California.  Oh, that's right. So you're all running together.

Start time: 282.70
End time: 283.98
Speaker: SPEAKER_02
Transcript:  Yeah. Against each other.

Start time: 284.44
End time: 321.90
Speaker: SPEAKER_07
Transcript:  Against each other. The primary is June, I want to say, 4th.  June 5th. Get out and vote.  Yep. I got my ballot. I vote by mail. That's why I don't know the exact date.  And so you're running and in theory, both Democrats could end up getting the top, being the top vote getters.  It's just kind of a weird thing in California. It's unknown.  Well, good luck. I think that's great.  Brian's got a great background, not only with the Office of Science and Technology Policy, but also led MIT's digital currency initiative.  So a blockchain and a bitcoin, probably not bitcoin expert, cryptocurrency expert would be a better way to put it.

Start time: 321.96
End time: 323.80
Speaker: SPEAKER_02
Transcript:  It used to be just bitcoin. I mean, that's just...

Start time: 324.65
End time: 325.90
Speaker: SPEAKER_07
Transcript:  That's just a tiny bit of it now, yeah.

Start time: 325.98
End time: 337.13
Speaker: SPEAKER_04
Transcript:  It would be nice to have someone in Congress writing these laws who actually understands what a computer is.  Wouldn't that be mind boggling?  I know, I know.  Just imagine.  There's so few compared to the lawyer count. It's ridiculous.  And Brian?

Start time: 337.70
End time: 354.94
Speaker: SPEAKER_02
Transcript:  To your point, more than 40% are lawyers, less than 4% have a technical background like me.  And we accept bitcoin. We live our values. We accept Ethereum.  And now we have members of Congress who accept bitcoin because they've seen us lead the way.  In fact, 20% of our contributions are in crypto.

Start time: 355.44
End time: 364.95
Speaker: SPEAKER_07
Transcript:  Wow.  If I could unlock my wallet, I have seven bitcoin. I'd be glad to pass along.  I just don't know the password anymore.  You go to crypto.ford.com.

Start time: 368.26
End time: 370.72
Speaker: SPEAKER_02
Transcript:  There are attack ads against us for accepting bitcoin.

Start time: 370.90
End time: 381.15
Speaker: SPEAKER_07
Transcript:  This is amazing. You also have the distinction of being the first candidate for Congress to be attacked over cryptocurrency.  That's right.  Okay. Wow.

Start time: 382.18
End time: 414.94
Speaker: SPEAKER_02
Transcript:  But this is literally the issue.  I am the technologist. I'm running against three lawyers.  And I think we need diversity in Congress for gender, for ethnicity, for religion.  But we also need to look at experience. We don't need another lawyer in Congress.  And I'm married to a lawyer. So I literally have a lawyer.  Let's be clear.  Maybe his friends are lawyers.  But at the same time, if you don't understand bitcoin and if you're going to think that anyone who uses bitcoin or Ethereum is a drug dealer or human trafficker,  then you should probably reconsider your capacity to lead in the 21st century.

Start time: 415.90
End time: 428.90
Speaker: SPEAKER_07
Transcript:  Well, and the thing that bugs me is I bet you your opponent, it's your democratic opponent who's paying for these ads, oddly enough.  But I bet your opponent is smart enough to know that that's not the case, but is playing on people's fears.  And that really is a problem, I think.

Start time: 429.60
End time: 431.40
Speaker: SPEAKER_02
Transcript:  That is a problem in politics. It's a problem in DC.

Start time: 431.98
End time: 452.40
Speaker: SPEAKER_07
Transcript:  Yeah. Fear, it turns out, is a very good motivator to get people to vote.  It's sad to say. And so unfortunately, politicians started using fear to motivate people.  And it really is a bad motivator and often is an inaccurate motivator, as in the case of cryptocurrency.  I'm sorry that that's going on, but maybe we have a few.

Start time: 452.48
End time: 464.40
Speaker: SPEAKER_02
Transcript:  It's a great example. It's why we need evidence-based policymaking.  It's why we need that in the four to five hundred other people that have come into DC, despite this.  It makes us a better government.

Start time: 465.22
End time: 487.86
Speaker: SPEAKER_07
Transcript:  I do. OK, so let me bring up the one thing that comes to mind.  You take Bitcoin donations and they can be a significant amount of money.  One up to $5,400 is the legal limit.  Well, but one of the advantages of Bitcoin is it's an anonymous, relatively anonymous way to...  Suit anonymous, let's be...  Suit anonymous, right?  Aren't there issues with election campaign?  I mean, you have to report your donors.

Start time: 487.90
End time: 510.24
Speaker: SPEAKER_02
Transcript:  Yeah. And we take the... it's just like filling out a credit card.  Like you've filled out the same exact information, your home address, your first name, your last name,  all the information we gave you, your solid address to make sure that it's going to that email address  and it's all documented and shared publicly through the FEC.  We follow all the rules and regulations, same as if we take a credit card or a check or cash.

Start time: 510.98
End time: 521.62
Speaker: SPEAKER_07
Transcript:  Well, yeah, we should point that out. Cash is truly anonymous.  Yep. And somebody could send you an envelope of cash.  So it's the same exact issue. It's just a matter of you keeping track of it.

Start time: 522.24
End time: 548.84
Speaker: SPEAKER_02
Transcript:  It was interesting when we started getting the attacks, former FEC...  Or sorry, former Department of Homeland Security and Department of Justice officials  in charge of prosecuting cyber crimes, the ones who actually prosecuted Ross Albrecht from the Silk Road,  said it's actually foolish for criminals to use Bitcoin because it's easier for us to track and prove you did what you did.  So it's actually more for them to use this old technology called cash.

Start time: 549.68
End time: 553.40
Speaker: SPEAKER_07
Transcript:  Yeah, if you really want to bribe a congressman, use cash. Everybody knows that.

Start time: 554.02
End time: 556.90
Speaker: SPEAKER_04
Transcript:  Oh no, don't do it the legal way. Call it a campaign contribution.

Start time: 557.02
End time: 586.88
Speaker: SPEAKER_07
Transcript:  Or a loan. Loans are great. Anyway, we're being facetious, but I really think it is an issue.  And certainly anybody who watches our shows or listens to our shows is technologically sophisticated enough  to know that scare tactics are a bad idea and we see a lot of it.  And I think you raise a really good point.  It's important, or maybe it was Matt, that our elected representatives understand this stuff  and not be using scare tactics, because you can't make policy on scare tactics.

Start time: 587.18
End time: 615.90
Speaker: SPEAKER_04
Transcript:  It's like the current meme that everyone on tour is interested in either buying or selling drugs on tour  or getting involved with child abuse or whatever.  The biggest use of tour at the moment is Facebook. It's people going on tour onto the Facebook.  Facebook has its own tour.  Yeah, they've got their own onion site and that's the biggest use of tour at the moment.  They reckon it's maybe about 10% of it is dodgy stuff, but I don't know.  It's perception of reality and we need people with a better idea of what the reality is.

Start time: 616.77
End time: 618.78
Speaker: SPEAKER_05
Transcript:  So wait, tour is for drug dealers to check Facebook?

Start time: 621.59
End time: 628.76
Speaker: SPEAKER_07
Transcript:  Whatever, I use Facebook.  Yeah.  Start off with story number one. The FBI says reboot your router.

Start time: 629.56
End time: 632.54
Speaker: SPEAKER_04
Transcript:  You might sort it out slightly.

Start time: 632.96
End time: 708.86
Speaker: SPEAKER_07
Transcript:  It's kind of an interesting story. There's a Russian, it turns out this is from Fancy Bear.  Fancy Bear, you may remember them from such amazing hacks as hacking John Podesta's account at the DNC.  Known to be a state-organized hacker. State-sponsored, yeah.  State-sponsored hacker. Apparently, according to the FBI, Fancy Bear has a bit of malware called VPN filter.  And it sits on your, despite its name, it sits on your router.  And it can be eliminated by rebooting the router.  As with a lot of router malware, it's not persistent.  It's because routers are dumb computers, they don't have a lot of storage.  But it does have a little bit of a stub that it stores in the firmware of the router.  That if you reboot your router, VPN filter will then, and the FBI discovered this because they found somebody in Pittsburgh,  a woman in Pittsburgh who said, okay, yeah, you can monitor my network. I have it.  You can monitor my network. So they monitored it and this is what they saw. Reboot the router.  The router then says, okay, goes to photo bucket where it looks for two images put there by Fancy Bear.  And I guess in the, I'm not, I wish there were a white paper. It's not really completely clear how this works.  But apparently in the metadata, there was sufficient information to reactivate the malware.

Start time: 709.10
End time: 717.90
Speaker: SPEAKER_04
Transcript:  Yeah. So what they're hoping is if everyone reboots their routers, it's all going to stop pinging the CNC pages.  They get a command control service and they can actually try and take it down.

Start time: 718.04
End time: 719.80
Speaker: SPEAKER_06
Transcript:  Well, this is what happens. We aren't out of the woods yet.

Start time: 720.22
End time: 784.82
Speaker: SPEAKER_07
Transcript:  No, but this is what happens. So the FBI took those, by analyzing the malware, they said, okay,  well, the first thing we're going to do is take those images off a photo bucket.  And then they watched and it went to, it has hard coded in its code, a site called to know all dot com.  And so it's the code says if you can't get your photos at photo bucket, go to to know all dot com.  FBI put a laid out warrant on VeriSign, which is the registrar for to know all dot com and took the DNS record over.  And so it is safe to reboot your router at this point because what will happen is your router will still be infected.  It'll go and it'll try to get the photos. Can't do it. Goes to know all.  And it will at that point give the FBI some information because at that point the FBI will be able to see the routers,  presumably the router manufacturers and gather some information about how it works.  Here's a list of the routers that are affected. Although this is from Symantec.  Although I would say this is a subset of the total.

Start time: 785.18
End time: 802.88
Speaker: SPEAKER_04
Transcript:  I was going to say Cisco's Talos team did a much better write up about this.  But they basically they they I think found that found the floor published and then the FBI came in and said,  this is actually a national security threat and we need to deal with it now because of the fancy bare connection.

Start time: 802.98
End time: 845.46
Speaker: SPEAKER_07
Transcript:  So they it's routers from micro tick. It's routers from Linksys.  That's a big name. Netgear, another big net gig.  TPLink, QNAP, which is a network attached storage device.  So, yeah, here's the Talos write up. It is. This is much, much more interesting.  What so the problem is we don't know all the routers, right?  So rebooting shouldn't just be limited to those. Frankly, I would if I were you, I know I'm going to go home and reboot tonight.  I tell everybody on your in your house. OK, the network's going down. Go to bed.  You kids rushes in the house. Just turn it off and on.  It'll be fine. But that's all you need to do. Right. Unplug it.

Start time: 846.14
End time: 848.86
Speaker: SPEAKER_04
Transcript:  Wait a second or leave it 15 seconds and then plug it back in.

Start time: 849.22
End time: 857.60
Speaker: SPEAKER_07
Transcript:  And that will purge VPN filter. Do we know what VPN filter was targeting?  Obviously, they were amassing a botnet. Yeah.

Start time: 858.78
End time: 884.82
Speaker: SPEAKER_04
Transcript:  It's the current style. Does your at the moment to go after the routers?  Because we've seen a couple of cases whereby these people worked out that if you want the gold standard when you break into a network is to get the administrators infected.  And it's the administrators who generally go on to the routers and do this work.  So there's a whole new family of malware which is targeting routers.  So it's spearfishing at trying to get administrators to get into the router. Exactly.

Start time: 884.90
End time: 889.48
Speaker: SPEAKER_07
Transcript:  So that's interesting. And then according to the FBI, they estimate half a million.

Start time: 889.92
End time: 891.68
Speaker: SPEAKER_04
Transcript:  Yeah. And that's a lowball estimate.

Start time: 891.92
End time: 919.48
Speaker: SPEAKER_07
Transcript:  But that's what I have to think is that we don't know.  And so it's a significant number. You build a botnet like that.  It's not this is a case where they're not trying to get your credentials or your information or not trying to get it probably into your company.  They're probably amassing a button to attack your network.  Yeah. Let's say the grid. Yeah.  As we know Russia did to Ukraine.  There's some very interesting malware coming through this week on just that area.  Yeah. It's looking like we're getting a lot of infrastructure hacking going on at the moment from groups outside.

Start time: 919.90
End time: 932.63
Speaker: SPEAKER_04
Transcript:  So this is cyber warfare.  Yeah. Well, you know, I mean, America started it.  So they can't really complain when people use it as well.  But that's like that was a little disturbed because I can't remember who it was.  But a couple of weeks ago, some of the people who were using it were using it.  We'll use it as well.

Start time: 932.98
End time: 949.88
Speaker: SPEAKER_07
Transcript:  But that's like that was a little disturbed because I can't remember who it was.  But a couple of weeks ago, somebody at the Pentagon said we they announced that we're going to have both an offensive and a defensive capability in cyber warfare.  And I I wonder if that's a good idea.  I mean, I guess it's too late. It's too late.

Start time: 950.00
End time: 963.36
Speaker: SPEAKER_04
Transcript:  I mean, it's when the NSA I mean, America didn't even used to have a code breaking unit until I think it was 1924 because the official excuse given almost Victorian was that gentlemen don't read other people's data.  Gentlemen don't read other people's other gentleman's letters.

Start time: 963.94
End time: 965.44
Speaker: SPEAKER_07
Transcript:  Yes, I think we should go back to that time.

Start time: 966.08
End time: 993.73
Speaker: SPEAKER_04
Transcript:  It would be nice.  But the Chinese and the Russians aren't playing ball.  So you need to have something in there.  But after Stuxnet came out, it became clear it was pretty much open season out there.  And, yeah, we're seeing this a really nasty set family of malware that's been used to infect a lot of Saudi things like Aramco and some of their major industries.  And that's now popping up in a slightly different form in the U.S.  So they're suggesting it may be Iranian based.  But yeah, it's going to be interesting times.  Stay safe, everyone.

Start time: 994.94
End time: 1015.50
Speaker: SPEAKER_07
Transcript:  You know, the timing's not great, but the White House eliminated the cybersecurity coordinator on the NSC a week and a half ago.  Yeah.  So, Brian, what's your I'm not going to ask you for a campaign position, but it seems to me that we are.  Do you feel like we're taking the cybersecurity threat seriously from nation states?

Start time: 1017.44
End time: 1059.90
Speaker: SPEAKER_02
Transcript:  I think the underlying agencies at the civil servant level are taking it seriously.  And I think we always have to distinguish that there are probably three million civil servants working hard that don't get any of the spotlight, that are doing incredible work for the country, regardless of who the president is.  And at the political level, yeah, I worry when you eliminate a position in charge of cybersecurity for the country.  I at a point when we're in the middle of negotiating with North Korea because you forgot to mention North Korea and the attack on Sony because they didn't like a movie.  Right. And it was an effective attack.

Start time: 1060.58
End time: 1064.10
Speaker: SPEAKER_04
Transcript:  I'm slightly skeptical about North Korea and that thing, but I'll let that one pass.

Start time: 1065.26
End time: 1094.90
Speaker: SPEAKER_07
Transcript:  Well, I'll give you another one.  We've thrown out the nuclear deal with Iran and this article in New York Times without the nuclear deal, US expects resurgence in Iranian cyber attacks as well.  And of course, we know that Stuxnet was designed to attack Iranian centrifuges where they concentrate uranium.  I don't know if Stuxnet was a US effort.  It's probably a US and Israeli.  Yeah, probably.  Project Olympic.  So, as you say, we've had offensive capability for a while and it would be I wouldn't be surprised if the Iranian said, well, all right.

Start time: 1094.90
End time: 1136.41
Speaker: SPEAKER_04
Transcript:  Well, there's even a story.  It's never been officially confirmed that this was done back in 1983.  They found that the then Soviets were trying to steal a gas control system software from a Canadian firm.  They said, fine, let them do it.  Inserted enough breaks into the code so that when they tried rolling out their own gas system, it caused the largest non-nuclear explosion yet seen.  That's good.  So, I mean, it's always it's always been on the cards as it were.  But it's it's we're going nuclear on it now.  Everyone with a little bit of skill and some store-bought malware can get into the game.  How well prepared are we for cyber warfare?

Start time: 1138.46
End time: 1157.78
Speaker: SPEAKER_05
Transcript:  The problem with cyber warfare is one mistake means that you are now vulnerable.  And so I think every country probably needs to do a lot more on trying to make sure that it's deeply secured and batten down the hatches.  But I mean, the fact of the matter is that there is there's a lot of work yet to be done on everybody's side.

Start time: 1157.90
End time: 1164.90
Speaker: SPEAKER_07
Transcript:  And we found malware on in our grid, right?  Our electric grid.  Our electric grid.

Start time: 1165.22
End time: 1212.55
Speaker: SPEAKER_02
Transcript:  And we also have to think about the impacts of the private sector as well.  According to a Harvard study with the Equifax hack that released all of our personal information,  So you that they gave out, you have enough information out there to be able to change the voter registration of individuals in 35 states.  Oh, geez.  So our election can be hacked.  And so this is not just about our electric grid.  This is not about protecting our companies and their private information or personal individuals and their personal information.  It's about our democracy.  But it's, of course, also about national security.  So we have to look at it from a variety of angles.  And it just blows my mind that we're in a time right now where we're actually having congressional hearings about the role of Russia and Facebook impacting our elections.  Yet we're eliminating the top cybersecurity position.

Start time: 1213.98
End time: 1246.90
Speaker: SPEAKER_07
Transcript:  Well, and I also I'll submit this and you can you can shoot me down.  I feel like Facebook and all this attention to Facebook is a little bit of a sideshow.  You know, yes, we know Russia bought ads and created fake groups and did all sorts of things to basically sow dissent and controversy and polarization in this country.  But it seems to me that the cyber attacks potentially have a much greater impact than fake news on Facebook.  Matt?

Start time: 1246.90
End time: 1277.44
Speaker: SPEAKER_05
Transcript:  It was interesting.  It was interesting.  In the rundown, there was an interview with the people at Facebook who care about fake news and trying to figure out misinformation.  And I do think that that is really important because if we can have trust in new sources and trust in the ability for people to know that they're getting information from reputable places, I think that does really help quite a bit.  So it's it's interesting because all these attacks are one matter.  But trying to make sure that people can get the best possible information.  I think that also matters a lot.

Start time: 1278.62
End time: 1291.78
Speaker: SPEAKER_07
Transcript:  I mean, it's all it's all it's not that we can't do both, obviously.  But I feel like sometimes the attention paid to Facebook is a little bit distracting when it comes to I mean, I don't know.

Start time: 1292.22
End time: 1361.82
Speaker: SPEAKER_02
Transcript:  I don't I feel like that is, you know, not everyone in America has deep technical experience.  And so what you oftentimes have to do with deep technical problems is highlight something that people can quickly understand and get their head around.  You know, we can talk about climate change, for example, and people won't make a connection between software and climate change.  But when you see that Volkswagen used software to get around the Clean Air Act, then they start to worry about software.  Or when you see that pro boards across this country are using software to determine the likelihood of someone recommitting a crime and then you show that that algorithm is systematically discriminating against black men.  Then they start to understand that algorithms and artificial intelligence is the next frontier of our civil rights or the democracy I gave with Equifax.  You have to tie national headlines that people are reading into the underlying technology that is making an impact.  Otherwise, people are not going to understand or care.  And a big part of this is making people care.

Start time: 1362.12
End time: 1402.87
Speaker: SPEAKER_07
Transcript:  Right. Although I think what ends up happening is people debate Facebook and Facebook ads when really the larger story, which is, I think, fairly clear at this point, is that Russia did a lot of things to try to influence the election and does a lot of things.  Currently to try to influence the United States, including Facebook, but not far from limited.  Maybe, you know, I mean, if you tell people there's malware on the computers at your local power station that was put there by Russians, that seems to me to something that would attract the attention of the average American voter.  I would hope so.

Start time: 1404.14
End time: 1420.90
Speaker: SPEAKER_02
Transcript:  Not until there's an actual power outage as a result of it.  You know, when we think about, you know, the example I have to go back to is when I think it was a power outage in Ohio that knocked New York off the grid.  Right. And then go, oh, wow, this is really interconnected and really important for us to think about.

Start time: 1421.10
End time: 1422.86
Speaker: SPEAKER_07
Transcript:  We didn't know that, did we? Yeah, that's right.

Start time: 1423.02
End time: 1439.90
Speaker: SPEAKER_04
Transcript:  Also, I mean, when it comes to voting, the state of voting machine security is just painfully bad.  I mean, I was at the DEFCON vote, you know, hack the voting machine thing.  They'd managed to hack one of these systems before the opening statements have been finished by the presenters.  I'm in.  You know, they're running Windows XP, Windows CE.

Start time: 1440.22
End time: 1444.90
Speaker: SPEAKER_07
Transcript:  Well, why are they even connected to the Internet is another question.  Yeah, I don't think they are.

Start time: 1445.38
End time: 1448.21
Speaker: SPEAKER_02
Transcript:  I think they were going through USB ports.  Oh, OK. Well, there were a variety of ways.

Start time: 1448.94
End time: 1449.90
Speaker: SPEAKER_07
Transcript:  There were actually, I think, some hacks.

Start time: 1450.44
End time: 1478.15
Speaker: SPEAKER_04
Transcript:  I mean, if you actually get physical access to the device in some cases, then it's over.  Yeah, it's over.  But it's just and there is legislation in front of Congress right now to say, look, we'll give a certain amount of money to secure these machines.  We'll get properly mandated people who get the software and security alerts.  And they still haven't moved on it.  It's like this is what democracy is about.  And this is how it's going to be.  You know, it's a pretty low state of affairs.  I'm hoping you can.

Start time: 1479.80
End time: 1502.80
Speaker: SPEAKER_07
Transcript:  Well, but I think that is so anybody who, again, who's a Twitter fan is sophisticated enough technologically to understand these issues and probably have an opinion about it.  So really, I think, Brian, you nailed it.  Really, the question is not whether this is happening, even maybe what to do with it, but how to convince the American voting public that this is important.  That's right. That probably is the most important thing.

Start time: 1503.48
End time: 1515.72
Speaker: SPEAKER_02
Transcript:  Yeah, I mean, Mark Zuckerberg's congressional hearing was one of the most helpful things to help emphasize an exclamation point on the fact that our members of Congress don't understand technology.

Start time: 1515.92
End time: 1516.55
Speaker: SPEAKER_07
Transcript:  That was obvious.

Start time: 1517.34
End time: 1518.64
Speaker: SPEAKER_04
Transcript:  It was a wee bit embarrassing, I've got to say.

Start time: 1518.90
End time: 1551.68
Speaker: SPEAKER_07
Transcript:  Although, and this is more subtle, I think the format also hurt them.  And a lot of what they were doing, sometimes grandstanding and monologuing, was because they only had five minutes.  So there was no opportunity for them to do any follow up of any kind.  It was a terrible format.  Yeah.  And that's a maybe more subtle problem that viewers didn't see.  So what you might have gotten is this impression, well, my member of Congress is just talking, talking, talking, asks one question to Mark that interrupts him.  Well, there was a reason for that.  They didn't have any time to follow up or anything.

Start time: 1551.90
End time: 1554.57
Speaker: SPEAKER_01
Transcript:  So what questions would you have asked Mark?

Start time: 1556.90
End time: 1612.21
Speaker: SPEAKER_07
Transcript:  You know, honestly, I don't think we need to ask Mark.  I think it's obvious.  I think and I don't think I've, Chris, I've never interviewed CEOs because I don't trust.  I don't think a CEO is ever going to get off point or off message.  It's almost as bad as interviewing politicians, Brian.  They know enough to answer the question they want to answer, not the question you asked.  It's very difficult.  But I and I also think we know we certainly know enough now.  The good news is whatever pressure has been put on Facebook is kind of paying off.  Facebook has released many of the ads now and we're getting to see what's going on.  GDPR has helped.  Facebook's been a little bit more responsible about maintaining your data and showing you what they know.  So Facebook's moving in the right direction.  A lot of that's because of the pressure.  But I don't think the actual tech.  So if I'm a member of Congress, I've got five minutes to ask a question of Mark Zuckerberg.  I don't know what you ask, Mark.  What are you going to do about this?  I don't know.

Start time: 1612.92
End time: 1650.10
Speaker: SPEAKER_05
Transcript:  I'd be asking about shadow profiles.  So the idea that they did a couple of times, and that's a huge one, but drilling in a little deeper.  You might have a corner asked about shadow profiles.  So what is shadow profiles?  Well, just the idea that, like, for example, not to.  OK, I'll say it.  I haven't had a Facebook account activated since like 2011.  Right. And so in theory, I have Chrome extensions that make sure that I block all the Facebook tracking.  And yet, if somebody knows me and is a friend of me, then Facebook could build up a profile of me even without me actively participating in any way.  So I think there's fair questions about, you know, how do you opt out?  How do you take care of those sorts of situations?  Yeah.

Start time: 1651.66
End time: 1676.90
Speaker: SPEAKER_07
Transcript:  Facebook, when asked, this is my point.  Zuckerberg said, well, we do collect data about people who haven't signed up for Facebook for security purposes.  I don't know what those security purposes might be.  And they said we don't have shadow profiles.  But of course they do.  And the like button follows you around everywhere you go on the Internet.

Start time: 1677.39
End time: 1695.56
Speaker: SPEAKER_04
Transcript:  Yeah.  So even also sort of sites of dubious coming.  We were talking about this in the office that pornography sites have the little like button.  And the only reason that it is there is to track data.  It's not as though your average porn watcher is going to be like, oh, I like this.  I'm going to share this with my granny.  This is my Facebook profile.

Start time: 1696.19
End time: 1718.11
Speaker: SPEAKER_07
Transcript:  I like it.  No, you're right. It's a tracking button.  It's not necessarily a like button.  But see, there's an example, Brian, of really the interesting question would be to ask Mark about the like button and what data they collect with a like button.  And what they do with that data.  The problem is that requires a grounding in the technology and understanding of what's going on.  And no, Mark Warner's not going to say, well, tell me about cookies because that's too complicated.

Start time: 1722.65
End time: 1744.90
Speaker: SPEAKER_05
Transcript:  Well, and it's also I think there was some issues where if you have five minutes to talk,  people might grandstand for three minutes before they do one question because you have to think about the tech savvy ability to do the follow up questions.  Right.  Because it didn't feel like everybody in that hearing was completely ready for the follow up question.  So they didn't want to maybe they didn't want follow up questions.  Well, or maybe they did.  And they just squandered the chance a little bit.

Start time: 1744.94
End time: 1768.88
Speaker: SPEAKER_04
Transcript:  Yeah, it was quite interesting watching that versus the EU presentation he gave where, again, it was the same sort of short time period format.  But Zuckerberg was kind of slightly more confident about the whole thing.  And eventually at the end, right, I think that just about wraps it up.  He said that.  You're just like, I'm done.  I don't think that's your role somehow.  But he's not even appearing at the UK Parliament.  They've asked him to turn up and he said no.

Start time: 1769.26
End time: 1782.90
Speaker: SPEAKER_07
Transcript:  So, you know, actually it was Ben Lujan of New Mexico who asked about shadow profile.  So let's give him some credit.  What would you how would you deal with that, Brian, if you're sitting on that panel, you've got five minutes.  You know, what would you do?

Start time: 1782.92
End time: 1837.84
Speaker: SPEAKER_02
Transcript:  I mean, there's a couple of questions.  I think, you know, his goal this year, you know, how each year he has a personal goal.  His goal this year was to understand cryptocurrencies and the role of decentralization.  And so I would ask him, you know, is there a future in which you will put personal information onto a blockchain that gives more people, more individuals control over the access to their data so that when that information is given to a place, to applications or sources like Cambridge Analytica, it gives the user control to pull that information back.  I mean, this is something that we did in my own research lab at MIT.  Not with social records, but with medical records.  And so I would be curious to know, you know, where's he going or where is he thinking about this?  I think the other thing every five minutes he said, I was going to solve something.  Oh, my question.  That's literally well, not literally, but that's a perfect example of kicking the can down the road.

Start time: 1838.00
End time: 1838.83
Speaker: SPEAKER_07
Transcript:  I want a unicorn pony pony tube.

Start time: 1840.96
End time: 1844.60
Speaker: SPEAKER_04
Transcript:  Yeah, it's just no, it's not going to happen.  I'll solve everything.

Start time: 1845.24
End time: 1846.19
Speaker: SPEAKER_07
Transcript:  I'll solve everything.

Start time: 1846.90
End time: 1914.46
Speaker: SPEAKER_02
Transcript:  You know, and so I'd say, well, you know, are we going to look at what DARPA is doing with explainable artificial intelligence so that we at least have some understanding of how artificial intelligence that there's no systematic biases and artificial intelligence that you're using.  I would ask him about privacy settings.  I know the incumbent that I'm running against asked him about two different screens and how it was complicated for privacy settings.  We'll think Snapchat is complicated for a lot of people, too.  But if you have the incentive to use it, you'll use it and you figure it out.  You know, I know every minute how my friends, my family are using my data because I see an alert on my phone that says, hey, someone shared something.  Hey, someone commented something, someone liked something.  So, you know, is there is there is there possible to put an option where it says, you know, hey, private company X has access to your data for advertising or for this or for that that if I think of America or the world knew how much of your personal information and how frequently it was being accessed by not your friends or not your family.  That would incentivize enough people to start reconfiguring their privacy pretty quickly, regardless of the interface.

Start time: 1915.10
End time: 1991.82
Speaker: SPEAKER_07
Transcript:  Yeah, I'm skeptical.  I'll give you an example that everybody knows this is happening and nobody cares about every time you use an app.  Facebook is one, but many, many apps on your phone and asks you, we would like to, you know, look for your friends.  Snapchat does you look to your friends, give us access to your contacts.  And most people say yes, because that's a useful thing.  Every time you do that, you're not just giving your information to this company.  You're giving every single person in your contact list over to them.  Talk about friends of friends.  You're you're literally snitching on everybody you know.  We do this.  We all know it happens.  We pay no attention to that.  And nobody's calling for this practice to go away.  You know, I remember Path remember Path, Dave Warren's company.  They got a lot of trouble because they asked for the contact list and they kept it.  And Dave said, well, yeah, of course we keep it because how else are we going to ping you when a friend joins Path?  The only way we could do this by looking at your friends.  But that and there was a and they got a lot of trouble for that.  But nobody says anything about the fact that you do it every single day.  You turn in your friends information, your phone number, their address.  Forget Equifax.  There is a massive leak of information.  And you did it to me.

Start time: 1992.80
End time: 2024.28
Speaker: SPEAKER_04
Transcript:  Well, honestly, it's going to say that was a very, I mean, everybody's doing it to everybody.  I feel the same way in that the office millennial was trying to get me to download Snapchat and use it.  And I looked at it's kind of like the office.  But and then looked at the amount of permissions it wanted.  It was like hell with that.  But you're one of the few.  Unfortunately, yeah.  And I've tried to, you know, I've got family members who love doing those with Star Trek character.  I quiz you on Facebook and you've tried to say to them, please, stop doing this.  Go ahead, Brian.

Start time: 2026.72
End time: 2040.63
Speaker: SPEAKER_02
Transcript:  Well, I would say that it's it's, you know, people kind of know that they're releasing this data.  They don't really know it's what they really want.  What would be really helpful in changing culture?  Because this is like tech is the easy part.  It's culture change.  That's the hard part.  That was my point.

Start time: 2041.12
End time: 2044.90
Speaker: SPEAKER_07
Transcript:  The people are doing this and they don't even think twice about it.

Start time: 2045.80
End time: 2089.88
Speaker: SPEAKER_02
Transcript:  And the only way you're going to change culture is by exposing having the option to be exposed to how often your personal data is being accessed.  By third parties or by Facebook.  And, you know, once you do that, then you have the opportunity for the user to be informed.  So they may say, hey, I am comfortable releasing this information to Facebook because I trust Facebook.  You may less people say that now than they did before.  But, you know, maybe Facebook's a trusted brand.  But maybe there's another brand that's accessing their information for whom they don't trust.  And when you have an alert on your phone that says, hey, XYZ company is accessing your information, then that's a whole different story.  And so what you really need should.  So my point is, is that we should know whoever is accessing our data.

Start time: 2091.74
End time: 2134.90
Speaker: SPEAKER_07
Transcript:  So when I give my address book to Snapchat, should Snapchat then go through my address book and notify everybody in it that Leo Laporte has just handed over your name, address, phone number, child's birth dates and ages, wife, place of work.  That that should be notified.  Snapchat says notify everybody in my contact list.  Do you know how many time if it would be fun if for one day every company did that because you would literally get thousands of pings every day.  Wouldn't you?  You would.  This goes on every day.  You know, talking about Facebook shadow profiles, that seems de minimis compared to the simple leak of data that happens every time you give your contact list to any company.

Start time: 2135.90
End time: 2156.90
Speaker: SPEAKER_04
Transcript:  This came up with the camera when they really Facebook had that tool for have you being caught up in the fake camera journalistic thing.  And if one person found out they had been, there was an immediate online witch hunt to find out who done the quiz and dumped them in it.  And I think just having a simple, you know, if you had a little simple button that said, do you or do you not wish your friends to be able to access this?  And of course, Facebook isn't going to do that because it cripples their business model.

Start time: 2157.95
End time: 2246.82
Speaker: SPEAKER_07
Transcript:  So I don't have any choice about whose address book I'm in.  Let me let me ask somebody in the chat.  Somebody in the chat says, well, that's why I never give up for my address book.  I bet you're one in a thousand.  How many I do it.  Anybody?  How many of you when this says, can we have your contacts?  Say, yeah, of course you do.  I mean, very few.  You'd have to be one of those tinfoil hat Steve Gibson types.  And I bet even he I bet even he does that.  And so we don't, you know, so we don't pay that much attention to that.  And and that's talking about shadow profiles.  There's a lot of information about me.  Oh, yeah.  Contact book, contact list.  Yeah.  Credit to Debbie Dingell of Michigan at the end.  And by the way, to kind of underscore your point, this got very little coverage, right?  We saw Mark saying, I'll ask my team about this, blah, blah, blah.  She she kind of reamed Mark.  She said, as a CEO, you don't know some key facts.  You don't know what a shadow profile was.  You don't know how many apps you need to audit.  You did not know how many other firms have been sold data by Cambridge Analytica.  You don't even know all the different kinds of information Facebook is collecting from its users.  Here's what I do know, says Representative Dingell.  You have trackers all over the web on practically every website.  We all see the Facebook like or share buttons.  And with the Facebook pixel, a hidden thought, people may not even see that Facebook logo.  It doesn't matter whether you have a Facebook account through these tools.  Facebook is able to collect information from all of us.  That's well said.  I don't think it got picked up by anybody.

Start time: 2247.12
End time: 2261.90
Speaker: SPEAKER_04
Transcript:  No, I mean, we mentioned it in our coverage of it, but it was just that was just because we were focused.  It was actually very easy to just to focus on tech savvy members of Congress because there are so few of them.  It's just like, oh, right.  OK, he's a pat on the back for that one.

Start time: 2262.00
End time: 2319.52
Speaker: SPEAKER_07
Transcript:  Let's take a little break when we come back.  I want to talk about the suitably dystopian named Amazon recognition with a K.  It sounds like something that Stasi would use.  We'll talk about that in just a second.  Brian Ford is here.  He's a candidate for Congress in the 45th of California.  And you should go to his website, F.O.R.D.E. .com and read all about his positions.  And if you're in Orange County, maybe you should think about going to the polls on June 5th.  What about what a thought.  I've got my ballot sitting sitting right there at my mail in ballot sitting right there.  I wish I could vote in the 45th.  But everybody, I think the good thing about that, I'll give you my endorsement.  I think everybody I think this particular primary and then the elections in November, everybody's going to have a chance.  Almost everybody's going to have a chance to make a difference and make a change.  This is going to be a big one.

Start time: 2320.14
End time: 2322.84
Speaker: SPEAKER_02
Transcript:  And as as technology, you just joined Jimmy Wales and Tim O'Reilly.

Start time: 2323.72
End time: 2343.04
Speaker: SPEAKER_07
Transcript:  Yeah, it's a good couple of people to join friends of both.  I think that I think that this is an opportunity for geeks who traditionally kind of government doesn't do anything.  I wash their hands.  You see opposite, don't you, Matt?  Sometimes you see the people say, I want to dig in.  I want to roll up my sleeves and make a difference.  Yeah.

Start time: 2343.90
End time: 2353.90
Speaker: SPEAKER_05
Transcript:  And you need that kind of thing because if people think they can just unplug and not pay attention to what's happening with government, guess what?  Government's going to affect you.  So you need to be in the discussion in the conversation.

Start time: 2353.92
End time: 2358.31
Speaker: SPEAKER_04
Transcript:  Yeah, who would have thought met neutrality would be an election issue?  But it's going to be.  I hope so.

Start time: 2358.96
End time: 2550.48
Speaker: SPEAKER_07
Transcript:  It's, you know, I hope so.  That would be that would be great news.  Our show today brought to you by that's Ian Thompson from the Register and that cuts from the United States Digital Service.  I gave Brian a plug, but I got to give you guys a plug, too.  It's great. It really is great to have you.  Our show today brought to you by Betterment, the largest independent online financial adviser.  And I want to tell you I'm strictly legal.  SEC regulations prohibit me from being a Betterment customer.  Isn't that weird?  I can't do an ad for Betterment if I'm a customer of Betterment.  OK, yeah, that's an SEC suitably bizarre.  This is a great way to invest.  You know you need to save.  You know you need to save.  You probably as a geek probably think, oh, I can do this all by myself.  If you've been doing this for any length of time, you kind of know you can't because who has time to pay attention?  Even if you and I was one of these people, I thought every quarter I'm going to go into my portfolio.  I'm going to rebalance. That's very important.  I'm going to pay attention. I see what I've invested in.  Make sure I'm not over invested in bonds or equities or whatever.  That's every quarter. That's every three months.  You can do something a lot better with Betterment.  Betterment's using technology to rebalance, to reinvest minute by minute if you need to.  And you know, when the stock market goes down, which it hasn't been for a while, but now that it's a little more volatile,  Betterment can take advantage of something called tax loss harvesting and actually improve your returns by taking advantage of losses.  It's complicated, but that's why you want Betterment to do it, by taking complex investing strategies, using technology to make them more efficient.  And then when you need it, providing access to unlimited personalized advice from licensed experts who are fiduciaries.  That's important. That's a big word, but it's important.  It's somebody working on your behalf. They don't get commissions.  They're not incentivized to recommend any particular fund.  They're not selling their own products.  And boy, I think a lot of places people go for financial advice, you're getting that kind of biased advice.  No, Betterment, they're fiduciaries. They work for you.  And by the way, and I love this, there are no hidden costs at Betterment.  You pay a low flat rate and it varies depending on what kind of account you want, but as low as 25 basis points.  0.25 percent of your investment per year.  And you get great information no matter who you are, no matter how much money you invest.  You're going to get everything for that low transparent management fee with no, there's no transaction costs.  And that means, by the way, that they can act on your behalf often, even during one day.  And there's no additional cost to you, which is fantastic.  Plus you get personalized advice, you get the suite of tools. The Betterment app is fantastic.  You'll know how you're doing. You can get other investments into the app so you get a total look at your portfolio.  It is awesome. Now I have to say this investment involves risk, but not investing also involves risk.  You can get up to a year managed free, not even 0.25 percent free.  If you go to Betterment.com slash twit, Betterment.com slash twit, Betterment.com slash twit.  I thought I'd do my mom a favor and take over her investments.  That was a mistake.

Start time: 2553.06
End time: 2555.13
Speaker: SPEAKER_04
Transcript:  It's like me doing tech support for my mom.

Start time: 2556.79
End time: 2617.90
Speaker: SPEAKER_07
Transcript:  Now I know why they charge so much.  Well now the market's gone down. Should I be, oh my God, mom, no, you should just sit still.  Sleep.  Sleep. Go to sleep, mom. I love you, mom.  But Betterment is better that she should call them. Better she should call them.  Let's talk about recognition. Amazon getting a little heat because apparently they're selling this face recognition to law enforcement.  And now I think this is a really interesting topic for us because it is useful for law enforcement.  So the Oregon, what is it, Orlando police department, it's right outside of Portland, I think, right?  They used it. What they did is they put all their mugshots in, mugshot database in, and they were able to immediately,  this is a great article in New York Times, immediately arrest somebody because it matched in the face recognition.  They were able to arrest somebody. They're touting this is a great success.  It's much, it's a cheap thing for them to do. They pay, I think it's a few hundred dollars set up fee and then it's a very inexpensive monthly fee.  This is a great service Amazon is offering.

Start time: 2619.25
End time: 2669.90
Speaker: SPEAKER_04
Transcript:  Yes, far be it from me. I'm sorry. We've tried this in the UK.  We've just had the results announced. South Wales police did it at some festivals.  98% failure rate. Well, yes.  And if you look at the stats that Amazon is pushing out, they're saying an 80% chance of identifying the person out of a group of 50 mugshots.  So the use case for this still isn't proven yet.  And I do worry that you're getting a lot of tech firms that Amazon is one is only one of them trying to push this technology at police where it produces far more false positives than it should.  And it's actively going to put people away from it.  Now, if you want to see how this has really been doing run being done right, go to China.  Because China has made enormous use of this.  They're very high end systems and yet it's letting them pull people off the street based on the photo on the image of a photo or denying them the ability to get a loan or buy train.

Start time: 2670.02
End time: 2675.90
Speaker: SPEAKER_07
Transcript:  Yeah, exactly.  Because they have this social credit system.  Sure, Elon Musk would approve.

Start time: 2675.94
End time: 2677.25
Speaker: SPEAKER_04
Transcript:  I think there are benefits to this.

Start time: 2679.34
End time: 2696.93
Speaker: SPEAKER_07
Transcript:  There's other issues, Brian, like the software that you mentioned that the prisons are using.  One of the things recognition does not do well with is people of color.  It's a very much higher failure rate with people of color.  They all look alike to recognition.  That's a problem.

Start time: 2699.64
End time: 2730.90
Speaker: SPEAKER_04
Transcript:  Yeah, I mean, as if people of color didn't have enough problems with being falsely arrested in this country.  But I mean, it's this is the problem.  It's the false positive rate.  It's kind of like when the antivirus industry first kicked off, people were turning their AV off because the false positive rate was so high and you get these little warning windows.  And I fear it's going to be the same with this.  I mean, OK, a false positive rate of 50 percent doesn't sound that bad until you're the person pulled out of strip search.  You know, it's like when they start putting on the shoulder marigold, then you know you'd really like that computer system to be accurate.

Start time: 2731.50
End time: 2743.52
Speaker: SPEAKER_07
Transcript:  It's ironic because in the New York Times article talking about this and the problems with it, they acknowledged that they used it during the royal wedding because they couldn't figure out which royals were which.  They all look the same, you know.

Start time: 2744.55
End time: 2754.15
Speaker: SPEAKER_04
Transcript:  Well, yes.  God bless the happy couple.  They'll bring some much needed genetic diversity to the royal family.  Oh, hi-yo.  Yeah, the next generation might actually have chins.

Start time: 2756.90
End time: 2807.82
Speaker: SPEAKER_07
Transcript:  Darker skinned women are, according to MIT, misidentified up to 35 percent of the time by facial recognition.  Not by Amazon specifically, but by generally by facial recognition software.  But there are some success stories.  In fact, the New York Times article talks about Madison Square Garden using it.  They have cameras.  When you enter Madison Square Garden and you go through the metal detector, there's a big camera on it.  And it's looking at you and matching you up to a database of known troublemakers so they can isolate people.  Hooligans.  You know about hooligans.  We're the hooligans.  Hooligans.  And keep them out of the concert.  I'm not sure I'm against that, but that's a little different because that's a use by a private company in a private setting where the right to pass is really controlled by that company.  It's not used by a government.  That's a...  Yeah, I mean, if it works, fine.

Start time: 2808.00
End time: 2808.81
Speaker: SPEAKER_04
Transcript:  But sorry, Brian.

Start time: 2810.41
End time: 2855.52
Speaker: SPEAKER_02
Transcript:  The question we're going to have to ask here is...  My first question Amazon would be, are you as a private company willing to be openly accessible through the Freedom of Information Act?  Or are you going to consider technology proprietary?  Oh, that's interesting.  Because this is the challenge that ProPublica had in figuring out whether the software that was being used by parole boards was actually systematically discriminating against someone.  It's a private company that was intellectual property and it was very hard for them to get access.  And this is the difference between private companies like Google and Facebook using software.  And I think it was Microsoft who put out a Twitbot or something like that.  And within 24 hours it became a racist engine.  Remember Taye.

Start time: 2856.16
End time: 2857.61
Speaker: SPEAKER_07
Transcript:  They did not see that coming.

Start time: 2860.18
End time: 2889.22
Speaker: SPEAKER_02
Transcript:  And so the difference between the government and a private company is that a government can garnish your wages.  A government can put you in jail.  Google and Facebook can do neither of those things.  And so because of that, the government has to be responsible to the people.  And that's why we have things like the Freedom of Information Act to do that.  But private companies aren't subjected to that.  And so really, it's great to see the ACLU standing up here because really this is our 21st century civil rights.

Start time: 2891.46
End time: 2931.88
Speaker: SPEAKER_05
Transcript:  Well, and it's also interesting to think about corner cases where it's not just people.  It's things like license plate recognition.  Because on one hand, you've got the privacy to drive around everywhere.  But if there's cameras at every large main street intersection that can do license plate recognition,  then you can back that out and figure out where people are going.  And then the really tricky question turns into, OK, some of this stuff is commercial service, but some of this is open source.  And so if this stuff is available as open source, should you say, OK, a company can use it, but then a government can't use it?  And under what conditions should you restrict the use of that?  Because you can imagine then a private company doing it and then licensing or selling those results to the government.

Start time: 2932.06
End time: 2955.80
Speaker: SPEAKER_07
Transcript:  Well, you were still at Google, I remember, when they announced that they had face recognition in Google Photos, I think it was.  And they said, but we're not going to let we're not let people use it to identify people on the street because of the very real threat of stalking and so forth.  Yeah. Yeah. That's the right way to approach this is to think about the ethical implications of what you're doing and try to try to limit the bad use cases, I would think.

Start time: 2956.42
End time: 2974.48
Speaker: SPEAKER_05
Transcript:  It helps. But you can never foresee all the different corner cases like somebody thinks they've anonymized data and it turns out somebody comes out with a completely new approach that people haven't thought of and they de-anonymize it.  And so it's a really tricky thing. And we might just have to say, you know, in 10 years, OK, we're living in a William Gibson novel.

Start time: 2974.94
End time: 2995.90
Speaker: SPEAKER_07
Transcript:  And I think we are already. I hate to say it. By the way, Google does have jails. You know that.  Only for your search results.  Matt, for years was the guy in charge of search and keeping spam out of search.  I heard that phrase and I was like, well, we have jails. It's a different kind of jail.  Think about it.  But you don't want to get in it. That's true.

Start time: 2996.00
End time: 3031.44
Speaker: SPEAKER_02
Transcript:  If I get if I apply for a credit card and I get denied because of something on my credit report, then I have a right.  And that right is to get access to that credit report and see if there are any errors on it.  And if there are, I have the right to go back to the bank and remove those errors.  And then I have the right to go back and apply for that credit and get access to the credit.  So my question then is what rights do we have with facial with private sector companies using facial recognition with the government?  Or what rights do we have with artificial intelligence when it's used to make so many decisions that impact our personal lives?

Start time: 3032.72
End time: 3080.16
Speaker: SPEAKER_05
Transcript:  Well, and if you to take Brian's point, I think the stuff that they do for credit, the Fair Credit Reporting Act is pretty good because you're actually able to say, OK, what information do you have?  And if something's inaccurate or wrong, then you can say, OK, this has to be corrected.  I think the tricky bit is when you take that a step further, whenever you have a transaction and there's something on someone on both sides of the transaction.  So you buy diapers from the grocery store.  Yes, you have bought those diapers.  But then the grocery store also knows that you've bought those diapers.  And so at what point do you say, OK, Pizza Hut, you're not allowed to sell information to other people?  Or maybe you make that a promise or a brand where you can say, OK, I will only use the companies that agree to like these higher ethical standards that say they're not going to sell the information to third parties, for example.  Is this the proper role for government?

Start time: 3080.90
End time: 3086.58
Speaker: SPEAKER_04
Transcript:  Europeans certainly think so.  Yeah, we're going to talk about you later on.

Start time: 3087.64
End time: 3091.86
Speaker: SPEAKER_07
Transcript:  This is the this is the week you got more privacy notices in your mailbox and the rest of your entire life.

Start time: 3091.90
End time: 3094.88
Speaker: SPEAKER_04
Transcript:  Some of them were pitiful.  Are we breaking up?  It's like, yes.

Start time: 3097.94
End time: 3132.37
Speaker: SPEAKER_07
Transcript:  We'll get to that in a second.  But no, I mean, it feels like so we have this debate a lot.  Should this be something that laws?  Is this something laws could take care of?  Is this something that a focus on ethics?  I know Microsoft this year at Build called for such an oil called for a kind of a focus on ethics among computer scientists to really think of the consequences of their actions.  Is it something Jeff Jarvis has always said?  You know, the best way to do this is with social mores, with just the kind of the standard in society.  You don't do this or you don't do that, that that would be wrong.  And there's some significant social pressure to behave.  All of those work.

Start time: 3133.22
End time: 3144.84
Speaker: SPEAKER_04
Transcript:  I mean, we've we've already seen I think it was last week with resignations from some of Google's AI team because they didn't want to be working with the military.  Three hundred.  Yeah, but I mean, no, I thought it was more like a dozen.  Yeah, I thought it was three.

Start time: 3144.92
End time: 3150.74
Speaker: SPEAKER_05
Transcript:  Oh, maybe.  So but but but people are willing to put their money where their mouth is news regarding what companies do.

Start time: 3151.38
End time: 3177.90
Speaker: SPEAKER_04
Transcript:  But the situation at the moment is so parlous.  We've seen with the Securus ISP stuff that was coming out, you know, companies are it's perfectly easy for law enforcement to buy your location data from private companies.  You know, but this is something I do think the government needs to step in and say, right, if you're going to do that, you've got to abide by certain data protection standards.  And there's got to be a certain level of civil civil liberties, civil liberties stuff built in as well.

Start time: 3178.28
End time: 3186.78
Speaker: SPEAKER_05
Transcript:  Yeah, of course, if I'm channeling my inner Jeff Jarvis, he would say, OK, there's all the scary stuff that could happen.  But what is the actual harm and what is the impact of the act?

Start time: 3187.30
End time: 3189.88
Speaker: SPEAKER_07
Transcript:  I like to ask that, too.  I think that's an important.

Start time: 3190.62
End time: 3277.44
Speaker: SPEAKER_02
Transcript:  I think when you kind of when you look back at the spam, for example, that was kind of a two prong approach.  We had the Cannes Spam Act, which governed what private sector could and could not do as it relates to email and put teeth and put teeth in it, which is important to put teeth into it.  But it didn't protect against like the Nigerian Prince scam.  Right. And that's where companies competed using innovation to have the best spam filters that had the least amount of false positives.  And so you had this two prong approach where you set the rules of the road for the legally abiding private sector.  And then you had tech companies and innovation to compete in the private sector to have the best spam filter.  And then the two of those things working together in collaboration.  So I never think it's an either or should government be involved in this or this is a private sector role.  You've got to think, well, as a community in the United States does not believe that our lives should be ruined by spam.  And so what are things that the private sector can do and what are things that the government can do in collaboration where they both have domains or both have levers?  Because one of the things that I always learned in the White House is that the private sector has a set of levers that the government does not have.  The government has a set of levers that the private sector doesn't have.  Academia has a set of levers that the other two don't have.  And so collectively, we have to decide on what are our values and what are our goals?  What does each group have that can help address this problem?  And how are we clear about that?  And then how do we work towards a collective solution to make society just a little bit better?  I think that's the right answer.

Start time: 3277.94
End time: 3333.90
Speaker: SPEAKER_05
Transcript:  Well, it's interesting, though, if you think about can spam.  I think it is good and important to have those roles of the road.  But if you think about it, something like Gmail often succeeded because it was really good at spotting spam and preventing it.  So I think to the degree it's possible, if you can have the things solved in the market where the companies can innovate on features that people actually care about  and make their lives better, then that's fantastic if you can solve it that way.  But because I always worried about, OK, if you legislate bad behavior, the unintended consequences, the corner cases, the things that people didn't write the laws,  the fact that the technology changes over time and so the laws can become out of date.  So to a first approximation, I always like to say, OK, let's see how far you can get using rational actors, hopefully on the private side.  And then if there's really bad folks, then yes, you can sue, you can have laws, all those sorts of stuff.

Start time: 3334.08
End time: 3338.90
Speaker: SPEAKER_07
Transcript:  Spoken as a true technologist.  Fair.  Technologists always think there's a technological solution to everything.

Start time: 3339.24
End time: 3342.17
Speaker: SPEAKER_05
Transcript:  Well, I have also seen a lot of bad laws here since I've been in D.C.  That's true.

Start time: 3342.90
End time: 3345.90
Speaker: SPEAKER_07
Transcript:  Government often thinks the solution is always government, too, right?

Start time: 3346.38
End time: 3374.12
Speaker: SPEAKER_02
Transcript:  Well, we've seen bad laws and we've seen bad actors in tech.  I think Uber is a classic example of a company who believes they can self-regulate themselves.  And then all of a sudden we consistently see how many times they themselves have chosen to be a bad actor.  And so this is where you need everyone to work together for the collective good.  And I think this goes towards what Tim O'Reilly has written about, which is algorithmic regulation, where the technology is going.

Start time: 3377.15
End time: 3379.88
Speaker: SPEAKER_07
Transcript:  What is algorithmic? On the face of it doesn't sound good.

Start time: 3380.32
End time: 3398.14
Speaker: SPEAKER_05
Transcript:  Well, no. So you could pass a regulatory reform bill for banks that's 1,100 pages, or you could imagine coming up with ways to set thresholds in a smart way that do the same amount with one or two pages of regulations like the Volcker Rule or something like that.  So that's one aspect. I don't know if, Brian, you want to add any more on algorithmic regulation?

Start time: 3399.52
End time: 3473.86
Speaker: SPEAKER_02
Transcript:  Yeah, I think just a more common example would be the speed limit on a highway.  Why does the speed limit exist? To reduce the number of deaths on the road.  And so if that's our collective goal, well, when we start to have seat belts, when we start to have airbags, when we start to have autonomous vehicles, or if there's higher density or lower density on the road, depending on the time of day or the day of the week or whatever it is, that speed limit should be changed.  It shouldn't be fixed at 65 miles an hour. That doesn't make sense.  And so as technology changes, as society changes, as things get safer, things should be more flexible and we should know what the ultimate goal is.  The ultimate goal is to lower the amount of deaths. The ultimate goal is to lower the amount of spam. The ultimate goal is whatever it is.  And algorithmically, you are shaping what your regulations are, applying to whatever challenge it is based on the current set of circumstances rather than fixed into law that continually needs to be updated that doesn't take into account any of the changes that are taking place in our world.  And, you know, there's 10 to 15 different emerging technologies that are going to radically change our society, our economy, our job market, etc.  And do you really think that any legislation that the government puts out over the next four to five years is going to be able to take into this account? It won't.

Start time: 3475.07
End time: 3509.56
Speaker: SPEAKER_07
Transcript:  Yeah, Tim writes about this in his most recent book, Beyond...  Actually, maybe not his most recent book. I think he's got a newer one, Beyond Transparency.  But he says the key to this is that government's job, law's job is to set a goal, to set a policy, to set an idea, to say this is what we're trying to get and that algorithms are regulations then that are...  Algorithms generate regulations that implement that goal, but those are more flexible and can change over time.  I like that idea. Again, it sounds like a technologist's solution, but I like that idea if we could implement that. That's a fascinating...

Start time: 3510.98
End time: 3556.09
Speaker: SPEAKER_05
Transcript:  We've seen an interesting case of success with the digital service where we worked with CMS, the Center for Medicare and Medicaid Services, and they had to issue some new regulations as a result of a law.  And so normally you would, you know, think for a year, put it out, have a public comment period, make some changes, and then you're done.  And what the team there did along with the U.S. Digital Service was take about one-fifth of the time, release the draft regulations, and then mock up how that would affect doctors and do a very fast cycle to iterate.  And they actually were able to iterate five times. And so...  Isn't that interesting. I love that.  Yeah, so by the time you issue the final regulations, it's much closer to what real people and real physicians and caregivers are actually going to need whenever they...  Brian, is this on your platform?

Start time: 3557.36
End time: 3561.78
Speaker: SPEAKER_02
Transcript:  Well, I think this is just consistent with evidence-based policymaking.  Right.  That's what we need to get to.

Start time: 3561.90
End time: 3574.84
Speaker: SPEAKER_07
Transcript:  Right. Yeah, Tim, actually, this is a great chapter, Chapter 22 and Beyond Transparency. And Tim's put it online, but it's interesting. He talks about actually reputation systems and how those could be valuable in guiding regulations.

Start time: 3575.73
End time: 3580.46
Speaker: SPEAKER_04
Transcript:  Yes, and of course Elon Musk throwing his Twitter toys at...  There's a pram going on about that.  I heard his reputation, I think.

Start time: 3581.06
End time: 3653.23
Speaker: SPEAKER_07
Transcript:  Oh, yeah.  He talks about the fact that you need to be able to measure. This goes back to your iteration.  You measure results and then you can iterate.  I think this is really interesting. I wasn't familiar with this. We'll get Tim on to talk about it.  I was going to talk about... We'll take a break. We'll come back. I was going to talk about Microsoft's response to Google Duplex.  Turns out... Remember the great demo that Google did that ended up being kind of controversial at Google I.O. of a bot making calls to humans and having seemingly real conversations with those humans. It was quite an impressive feat.  So Microsoft, in typical Microsoft fashion, said, oh, we've had that for a while. And apparently they do.  There's a bot called Xiao Ice that has made millions of calls in China. It has 500 million friends. And apparently she has her own TV show, writes poetry. She's kind of a celebrity in China.  And apparently one of the things she does is tell people she loves them.  Oh.  That there's something... And maybe this is more cultural. But I'll play it. I mean, if you don't speak Mandarin, this is not going to be impressive.  But this is Xiao Ice making a phone call.

Start time: 3656.90
End time: 3658.08
Speaker: SPEAKER_08
Transcript:  That's the robot voice.

Start time: 3661.90
End time: 3702.02
Speaker: SPEAKER_07
Transcript:  The robot is saying, hi, this is Xiao Ice. Are you feeling depressed now? I was worried about you.  And the human says, I'm feeling much better now. Thanks for calling me about talking with me about work earlier.  So it's midnight.  And by the way, the robot does a lot more talking than the human.  Yeah.  But apparently all of this culturally, according to this article on The Verge, is actually not at all foreign.  And they said they had a science reporter who's a Mandarin speaker who said this voice sounds really good. It did sound good. The pitch is artificially bright, kind of like a US version of a newscaster voice.

Start time: 3704.16
End time: 3711.70
Speaker: SPEAKER_05
Transcript:  So we can automate Leo Laporte's voice and have him call.  I've been waiting for this. I'll call you.  I heard you had a call.  I'm worried about you.  I just want to know you're OK.

Start time: 3711.90
End time: 3723.40
Speaker: SPEAKER_07
Transcript:  By the way, in the demo, Xiao Ice at one point interrupts the user mid-sentence. Interrupts!  Pushy robot as well.  And says, oh, I see there are strong winds. You should close the window before you go to bed.

Start time: 3724.77
End time: 3726.36
Speaker: SPEAKER_06
Transcript:  What the what?

Start time: 3727.04
End time: 3733.70
Speaker: SPEAKER_04
Transcript:  Yeah, I mean, I was in the audience at Google when they showed off that thing and I was not alone in being deeply creeped out by it.

Start time: 3733.90
End time: 3738.74
Speaker: SPEAKER_07
Transcript:  I wasn't. I thought I was turned on. I said, Google just passed the Turing test.  That's the difference.

Start time: 3738.90
End time: 3752.86
Speaker: SPEAKER_04
Transcript:  Well, you know, it's just I can't help feeling if you've got something like that, it should identify itself as a bot.  It will. I think Google's decided that that's going to do that.  Yeah. And I think that's that's much needed because you don't want to be wasting your time trying to empathize with the software system.

Start time: 3753.24
End time: 3786.58
Speaker: SPEAKER_07
Transcript:  But but and I talked about this a little bit on this week in Google.  So I apologize for anybody listening to that show.  Ultimately, don't you think in the next five, 10, 20 years, we'll be interacting all the time with devices that are not human.  Yeah. And at some point, we're not going to want to know or care.  We're not going to want. Oh, by the way, I'm not a human. Now let's have an interaction.  It's just going to happen. And the question is, is that OK with you?  Is that a future you you mind living in where where you don't always know whether you're interacting with a human or a computer?

Start time: 3786.90
End time: 3810.90
Speaker: SPEAKER_05
Transcript:  Well, keeping with the theme of this being a William Gibson novel.  I mean, to me, it seems like one of the next great startups is just software that you sell that acts like the emotional support companion.  You know what this is? Shall I say it? I mean, it's it's really just a matter of time before somebody's like, oh, I had a rough day and the bots telling you, I'm so sorry to hear that.  Tell me all about it. Exactly what you know.  The bot will put in the emotional labor and then you're good to go.

Start time: 3811.64
End time: 3814.88
Speaker: SPEAKER_07
Transcript:  Fortunately, you don't have to buy a ticket for on the plane. You just bring your in your phone.

Start time: 3815.26
End time: 3820.88
Speaker: SPEAKER_04
Transcript:  It's because I've got friends and relatives for that. But, you know, they don't want to hear how your day was every single day.

Start time: 3820.90
End time: 3824.97
Speaker: SPEAKER_05
Transcript:  Always wants to hear how your day was.  Amazon Echo will then send your conversations to other people.

Start time: 3826.10
End time: 3828.88
Speaker: SPEAKER_04
Transcript:  Oh, let's talk about that, too. We got a lot more to talk about.

Start time: 3829.48
End time: 4081.19
Speaker: SPEAKER_07
Transcript:  Great panel here, Ian Thompson from the register.co.uk.  Matt Cutts was at Google, of course, a good friend of the network.  We love having you on. He is now active.  We're also very proud acting administrator of the United States Digital Service, where he's looking for coders who want to help make the government operate better.  You turned over the completely turned around the V.A. website, for instance, really a great one of the great success stories in government service.  So thank you for doing that. I appreciate it, Matt.  It's great to have you here. And of course, our first timer, Brian Ford, who is running for Congress in the California 45th District, Orange County, F-O-R-D-E dot com.  And he's got a little bit of a track record, formerly at the M.I.T. Media Lab, working on cryptocurrency and the Obama White House.  So it's great to have you, Brian. Thank you for joining us this week.  Here's my smart toothbrush. How about a toothbrush with AI?  Goodness.  It doesn't talk to me. Well, it does a little bit.  Like most electric toothbrushes these days, it'll tell you every 30 seconds to do a different quadrant. You got to do that. Do you do that?  Lisa and I have this conversation. She says, Do you do that? I said, Yes.  30 seconds here, 30 seconds there. She says, No, I just kind of keep brushing till it stops.  Well, I guess that's OK.  The things couples fight about.  This is our new electric toothbrush. This is such a great toothbrush.  First of all, a lot less expensive. Twenty five dollars. Doesn't have a charger.  In fact, it comes with a great little the quip holder has a little sticky pad.  You can put it right on your mirror so you don't forget to brush.  And it uses a battery so you can try. It's a great travel brush because it comes with a nice little enclosure.  You put it in your Dopp kit and if you don't have to charge it, if it runs out of juice, you buy another battery.  It's like a triple A battery. You put it in and it goes for months.  Quip is brilliant.  Truth of the matter is most of us are brushing our teeth wrong, Lisa.  They're not doing it long enough.  You're not changing your brush head on time.  And almost every dentist I talk to, I know my dentist says absolutely electric toothbrush much better.  We've I've been using one so long I forgot to brush out of brush manually.  You have British teeth, he said.  That is me. That is mean.  This this is good for every mouth, including British teeth, especially British teeth.  No, the dentist always says your teeth are great. You use electric toothbrush.  I said yes, I do.  Actually, this is the first electric subscription electric toothbrush to be accepted by the ADA, the American Dental Association.  So this is great. You buy the brush is very inexpensive.  Go to if you go to get QIP get quip dot com slash twit starts at twenty five dollars.  They have different kinds.  And then the heads every three months, they deliver you a head for five dollars free shipping worldwide.  So you never have an old head on here.  You always have a nice fresh head, which is also important.  And everybody loves quip.  Did you know that quip is now on the Oprah O list?  Yes, it is.  Oprah loves quip.  It's named one of time's best inventions of the year and the first subscription electric toothbrush accepted by the ADA backed by a network of over 20,000 dentists and hygienists and hundreds of thousands of happy brushers.  We're big fans of the quip.  We actually they're so affordable.  We have three or four of them because our 15 year old has sleepovers and for some reason the kids never bring toothbrushes.  I wonder why that is.  Yeah.  Yeah. And Lisa is a big proponent of brushing your teeth every night.  So she's big on that.  So in fact, our 15 year old has never had a cavity because of it.  How about that?  So we got one for each of the kids and then each day we got different heads, which we write their names on so that there's always a toothbrush there for them.  Is that awesome?  Just twenty five dollars.  That is a great price for a great toothbrush.  And when you go to get quit dot com slash twit right now, you'll get your first refill pack free when you purchase any quip electric toothbrush.  First refill pack free.  Get quit dot com slash twit g e t q u i p dot com slash twit.  I love the quip.  I really do.  And doesn't it smell minty fresh?  Can you smell it?  Yes.  Kiss me.  Kiss me.

Start time: 4083.19
End time: 4084.74
Speaker: SPEAKER_04
Transcript:  I've got this thing I need to be doing.

Start time: 4085.70
End time: 4088.90
Speaker: SPEAKER_07
Transcript:  I keep quip at work because you never know when you need your breath to be kissing fresh.

Start time: 4089.16
End time: 4092.08
Speaker: SPEAKER_04
Transcript:  No, I mean, I always keep a razor and razor and razor at work just in case.  Yes.

Start time: 4093.17
End time: 4102.70
Speaker: SPEAKER_07
Transcript:  Would you like a quip?  I won't give you this quip.  I'll get you a fresh one.  It's awesome.  Keep it at work.  Oh, yeah.  That's great for your British mouth.  I'm sorry.  I shouldn't say that while you're drinking tea.

Start time: 4103.02
End time: 4108.49
Speaker: SPEAKER_04
Transcript:  You're tea all over the place.  OK, right.  That's moving swiftly on.  Moving on.

Start time: 4109.38
End time: 4120.90
Speaker: SPEAKER_07
Transcript:  What were we going to talk about?  There were so many things and I forgot.  Was it GDPR?  What?  What?  Echo?  Oh, yeah, we could do the Echo one too.  Should we start with the Echo?

Start time: 4121.41
End time: 4124.78
Speaker: SPEAKER_04
Transcript:  All right.  That was actually up in Portland as well.  So we have a sizable Portland contingent.

Start time: 4125.10
End time: 4283.40
Speaker: SPEAKER_07
Transcript:  For some reason, all the Portlanders here, maybe because they're afraid of their Echo  devices.  So Cairo Channel 7 got this story.  They talked to a woman, first name only Danielle.  I guess she wasn't called the station and said, OK, the weirdest thing just happened.  My husband and I were having a conversation.  There she is.  My husband and I were having a conversation.  And all of a sudden, we get a text from an employee of my husband who said, you know,  Echo just sent me a recording of your conversation.  And she said, shut the front door.  And he said, no, it did.  You were talking about hardwood floors, right?  And she said, yeah.  So that's weird, maybe even a little creepy.  But Amazon confirmed it because, you know, they log everything they know.  They probably even have I'm sure they have recordings of the whole thing.  So what happened, Amazon says, is somehow during their conversation, this recode got  the story, somehow during their conversation, they must have said the wake word, a L-E-X-A  in this case.  You can have different wake words, but that's the one.  And then without knowing it, the Echo heard after the wake word, sometime within a short  time, send a message.  Now, this is what Amazon says happened.  If you say send them, if I said send a message to Matt Cutts and you're in my contact list,  it probably would just start recording the message.  But in this case, they didn't say a name.  So the Echo said to whom?  Out loud.  I guess Danielle and her husband were talking loud.  They weren't paying attention for whatever reason.  They didn't hear that.  But weirdly enough, such a coincidence, they said something that was interpreted as a name  in their contact list.  At which point, again, Amazon's Echo spoke up again and said, name this name right.  And then somehow they heard right.  It heard right in the conversation.  Now, we've tried this and that's all you need.  If I said, if I said, Echo, send a message to Matt Cutts, it would then record and without  confirmation, send the message.  So Amazon says, yeah, as unlikely as this sounds, we think we can make this a little bit better.  Step one would be to say, did you just say to send this message to Matt Cutts would have been helpful.  Yeah.  Right.  They may have had, I think by default, is the bleep turned on or off by default?  When you say Echo, it goes bleep.  I think that's off by default, but I have it turned on online because you want to know.  We've all had the Echo respond.

Start time: 4283.90
End time: 4286.42
Speaker: SPEAKER_04
Transcript:  I refused to have one in the house and felt very smug this week.

Start time: 4287.86
End time: 4293.34
Speaker: SPEAKER_07
Transcript:  Well, I worry a little bit that there may be a little bit of techno panic here.  People go, oh my God, the thing is listening, because people think that anyway.

Start time: 4294.00
End time: 4299.90
Speaker: SPEAKER_04
Transcript:  Yeah.  Well, I mean, it is listening, but it isn't.  It's listening for certain things, but it's not recording bedroom conversations.

Start time: 4299.90
End time: 4325.90
Speaker: SPEAKER_07
Transcript:  Here's what I think Amazon could and should do.  They've got to give you a chance to have your own trigger word.  Yeah.  This fort to choose from is terrible.  We have a co-host, Alex, Alex Lindsay.  He says, I can't use it because it gets triggered whenever anybody says my name.  It gets triggered.  I said this morning I was talking about being lexically scoped and my Echo woke up.  So don't say lexically scoped.

Start time: 4326.32
End time: 4331.04
Speaker: SPEAKER_04
Transcript:  We can have to do xylophone.  Alhambra, al dente.

Start time: 4336.33
End time: 4354.64
Speaker: SPEAKER_07
Transcript:  So one thing would be to have, and in the Moto X you could do this.  It's the only phone I've ever had where you could do it.  And I had a Help Me Obi Wan Kenobi, and that seemed highly unlikely that actually that would ever happen.  That would be good.  Encourage people to train it.  You can train it, but you're not required to.  If it trained it to your voice, it would be less likely to happen to it.  It seems like they could fix this.

Start time: 4355.96
End time: 4366.58
Speaker: SPEAKER_05
Transcript:  But part of the problem is I think those code words, you can bake them into silicon where it can do that hot word detection with very low energy.  Whereas training it for your aerodynamic phrase is a little tougher.

Start time: 4367.10
End time: 4369.90
Speaker: SPEAKER_07
Transcript:  And the Moto X had a bigger processor and it had a bigger battery.

Start time: 4369.98
End time: 4375.80
Speaker: SPEAKER_05
Transcript:  On the other hand, throw a few more transistors at it because we want to say different things.

Start time: 4376.04
End time: 4378.50
Speaker: SPEAKER_07
Transcript:  So Brian, should there be a law?

Start time: 4379.67
End time: 4382.37
Speaker: SPEAKER_02
Transcript:  This is why we can't have nice things.  That's right.

Start time: 4383.34
End time: 4386.90
Speaker: SPEAKER_07
Transcript:  Exactly.  Do you have echoes in your house?

Start time: 4388.55
End time: 4389.90
Speaker: SPEAKER_02
Transcript:  We have an unplugged one in our closet.

Start time: 4390.02
End time: 4399.90
Speaker: SPEAKER_07
Transcript:  So this is what I hear most often is people like you and Ian say, well, I'm not going to have that in my house.  But do you carry a phone with a microphone and a GPS and a camera?

Start time: 4399.96
End time: 4405.18
Speaker: SPEAKER_04
Transcript:  The GPS is always off unless I absolutely need it.  And voice commands are locked down.  So no.

Start time: 4408.49
End time: 4414.44
Speaker: SPEAKER_07
Transcript:  OK, they're locked down.  But if I got a subpoena and I went to your carrier and I said, could you just turn on the microphone on Ian's phone?

Start time: 4414.94
End time: 4418.72
Speaker: SPEAKER_04
Transcript:  Oh, yeah, could be done perfectly easily.  Has been done in the past, will be done again.

Start time: 4418.90
End time: 4423.26
Speaker: SPEAKER_07
Transcript:  So the nightmare scenario of these devices is totally implementable on a smartphone.

Start time: 4424.47
End time: 4429.30
Speaker: SPEAKER_04
Transcript:  Oh, yeah.  So you carry that.  Well, yes, but they'd have to get a subpoena to actually get it.

Start time: 4430.08
End time: 4456.62
Speaker: SPEAKER_07
Transcript:  Well, they would, I'm sure with the Echo as well.  Unless you think Amazon, Jeff Bezos just, you know, I remember talking to Waz.  This is a bad story, but I'm going to tell anyone.  I remember talking to Waz.  Waz, as you know, quite a geek, a little bit of a prankster.  Before digital cell phones came out, it was fairly easy to spoof an analog phone.  Yeah.  He used to sit in his living room and listen in on people's conversations all the time.

Start time: 4457.33
End time: 4468.84
Speaker: SPEAKER_04
Transcript:  Yeah.  Now, I mean, that's that's how the whole Prince Charles, Camilla Parker Bolston came out.  Because there was a journalist sitting outside the Buckingham Palace with a receiver listening to these insane phone calls.  Because it wasn't encrypted. It was analog.

Start time: 4468.96
End time: 4473.18
Speaker: SPEAKER_07
Transcript:  It was just going through the air.  So Waz, I guess, was close enough to a cell site.

Start time: 4474.32
End time: 4480.36
Speaker: SPEAKER_05
Transcript:  And that's why we need strong encryption everywhere.  I'm sure everyone, every co-host agrees on this.  Oh, yes.

Start time: 4482.91
End time: 4483.50
Speaker: SPEAKER_06
Transcript:  I don't know.

Start time: 4484.58
End time: 4511.58
Speaker: SPEAKER_07
Transcript:  I feel like Google Home, particularly, which is about, I think, to kind of it's this was the first selling period that actually  sold the Echo and it's I think rapidly going to become eclipse the Echo and become the default device.  It's useful.  It's useful for people, not just normal, you know, people with normal uses like buying stuff or listening to music.  There's a whole category of people who aren't mobile, blind users who find this more than useful, almost a necessity.

Start time: 4512.26
End time: 4526.78
Speaker: SPEAKER_04
Transcript:  I've got to say, I did find it useful at a friend's place for translating between metric and imperial.  Because when you're cooking, you've got your hands full of flour.  You don't want to be going to the computer and you can just say it out loud and convert from freedom units into something which makes sense.

Start time: 4527.69
End time: 4529.74
Speaker: SPEAKER_05
Transcript:  But how many stones of sugar do I need?

Start time: 4530.16
End time: 4533.68
Speaker: SPEAKER_04
Transcript:  How many cups?  How many cups in a stone?

Start time: 4534.95
End time: 4541.66
Speaker: SPEAKER_06
Transcript:  It's just a lot.  Don't get me started.  I really want to ask my Echo.

Start time: 4541.90
End time: 4548.83
Speaker: SPEAKER_05
Transcript:  Yeah, I kind of do.  Kind of like pull out the squeeze version.  Yeah, the squeeze, the pixel squeeze.  See if we can.

Start time: 4549.90
End time: 4556.27
Speaker: SPEAKER_02
Transcript:  But wasn't the recording from a crime or something like that that was captured with Amazon?  No, there's another story there though.

Start time: 4557.00
End time: 4581.76
Speaker: SPEAKER_07
Transcript:  Yeah, there was the hot tub murders.  Oh yes, we talked about this.  Hardwood, Florida?  No, this is completely different.  I think it was Florida.  So this was a case where the law enforcement did actually subpoena Amazon and said there's been a murder and we want all the Amazon recordings just in case.  Just in case, I don't know what, the guy's going, Alexa, I was murdered by...

Start time: 4582.94
End time: 4584.46
Speaker: SPEAKER_06
Transcript:  I don't know what they would hope.

Start time: 4584.90
End time: 4587.40
Speaker: SPEAKER_05
Transcript:  Note to self, get murder weapons together with a tarp.

Start time: 4588.46
End time: 4615.91
Speaker: SPEAKER_07
Transcript:  Yeah, well in fact the guy ended up getting busted because he was unaccountably using a lot of water.  This was actually, law enforcement was very smart.  They also checked his water meter.  He was using a lot of water in the middle of the night, like gallons and gallons of it, apparently to wash away blood.  In any event, the whole thing went away because the guy's attorney said, okay, you can have the Amazon recordings, big deal.  But Amazon was fighting it for a while.  They didn't like this idea.

Start time: 4616.90
End time: 4633.58
Speaker: SPEAKER_05
Transcript:  Well, and I know when there's been subpoenas toward Google to get people's queries, they've been like, no.  No.  They push very hard on that.  As they should.  And so if you can get the local computer, that's, so be it.  But I think it's right and proper that companies push back on that.

Start time: 4634.14
End time: 4639.74
Speaker: SPEAKER_07
Transcript:  How many cups in a stone?  Here's what I found in the web.  How many cups are in a pound of fertilizer?

Start time: 4640.99
End time: 4641.54
Speaker: SPEAKER_04
Transcript:  Okay.

Start time: 4641.92
End time: 4645.66
Speaker: SPEAKER_05
Transcript:  You could use that.  You just need 14, multiply that by 14.  That's okay.

Start time: 4645.90
End time: 4660.49
Speaker: SPEAKER_07
Transcript:  I like how it's trying to do stuff.  How many cups of sugar in a stone?  A pound of powdered sugar contains approximately four cups.  There you go.  So how many?  56 cups.  Yeah, you make you do the math.  That's all.

Start time: 4660.94
End time: 4664.90
Speaker: SPEAKER_04
Transcript:  Well, I mean, there's even differences like an American pint is less than a British pint, for example.

Start time: 4665.71
End time: 4684.04
Speaker: SPEAKER_07
Transcript:  And the British pint always has beer in it, which is very good.  Well, Guinness, yes.  All right.  Yeah, I thought that was interesting.  I don't know if there's much to say about it.  I think that this reason this got a lot of attention and coverage everywhere is because I think already there's this paranoia about having like,  microphones and cameras, too, by the way, in your house.  Oh, yeah.

Start time: 4685.81
End time: 4696.88
Speaker: SPEAKER_04
Transcript:  I mean, it was just and it was the fact that Amazon confirmed it.  And I think, okay, this was either two things happen.  First off, they were doing a limited trial of Alexa being a lot more listening.

Start time: 4697.38
End time: 4699.57
Speaker: SPEAKER_07
Transcript:  They don't say that, but that's interesting.  Oh, yeah.

Start time: 4700.16
End time: 4710.68
Speaker: SPEAKER_04
Transcript:  I mean, if it was just somebody had accidentally got it turned up to 11 or something, but it may just have been that they were just trying in a few cases,  a sort of an enhanced listening mode.

Start time: 4711.26
End time: 4718.90
Speaker: SPEAKER_07
Transcript:  I think it's like, you know, the old adage, if you had an infinite number of monkeys typing on an infinite number of typewriters, eventually they'd produce the works of Shakespeare.

Start time: 4720.50
End time: 4727.90
Speaker: SPEAKER_05
Transcript:  Well, we used to, you know, at Google, we used to say if you have something that only happens one in a million times.  And we have a billion queries a minute.

Start time: 4727.92
End time: 4728.80
Speaker: SPEAKER_07
Transcript:  Or five billion if you want to take.

Start time: 4729.80
End time: 4738.38
Speaker: SPEAKER_05
Transcript:  So that's five thousand times a day that a one in a million thing happens.  So eventually somebody sounds like they're taking a message and send it to their friend, Bill Hardwood floors.

Start time: 4739.18
End time: 4746.80
Speaker: SPEAKER_07
Transcript:  It is. I mean, it is a little nerve wracking if you're Danielle to think that this employee could have received other things.  Who knows what kind of conversations go on?

Start time: 4746.90
End time: 4750.66
Speaker: SPEAKER_04
Transcript:  Well, they said they had them. They had a unit in every room in the house.  As I do.

Start time: 4751.38
End time: 4775.29
Speaker: SPEAKER_07
Transcript:  Yeah, I don't have just one unit.  I have multiple units because I have an Echo and a home and my Siri.  Lisa has just discovered she loves the home pod.  So now we're going to have more of those.  It's a really mess.  In a way, probably announcing that is opening myself up to hackers who might try to be.  But what are they going to get?  They're not going to get anything interesting.  Well, this was this.  Trust me, my conversations are not.  We were talking about this in the office.

Start time: 4775.92
End time: 4789.82
Speaker: SPEAKER_04
Transcript:  Well, I guess on one level, it's a bit scary.  But on the other hand, when you've been married for a few years, you think how mundane a lot of the conversations you have, it's all about who's picking up the cat or who's going shopping or why did you leave the toilet seat up?  You know, it's just.

Start time: 4789.90
End time: 4806.90
Speaker: SPEAKER_07
Transcript:  And this goes back.  We saw, I remember the stories when the NSA trove of hacks was released.  One of them was the ability to get a smart TV to listen.  Yeah.  You have to be a target of the NSA.  Who would be?  I mean, you know, it's not.

Start time: 4808.01
End time: 4808.88
Speaker: SPEAKER_04
Transcript:  They can pwn you anytime they want.

Start time: 4810.10
End time: 4854.86
Speaker: SPEAKER_02
Transcript:  It's also about people's personal actions and how they protect their accounts.  So I think people probably think that they should protect their bank account more than they should protect their Amazon account or the Ring doorbell account.  Good point.  But if you really ask someone, hey, do you really care about your bank transactions or do you care more about revealing what exactly you've bought on Amazon or all of the video that could be accessed on your ring account again owned by Amazon?  People would start to think twice about where they should put their two factor authentication.  And I bet if you were to look at it, the number that have it on their Amazon account versus things that are, you know, more innocuous like your bank account are a lot different.

Start time: 4855.24
End time: 4869.90
Speaker: SPEAKER_07
Transcript:  That's an excellent point.  Meanwhile, Jeff Bezos, his response, we got to go to the moon and this time we're going to stay there.  William Gibson novel.  Yeah, seem really engaged with the problem as a whole, does he?

Start time: 4870.26
End time: 4874.90
Speaker: SPEAKER_04
Transcript:  It does seem like a sort of fierce skylight issue from the Gibson side of things.

Start time: 4875.48
End time: 4883.90
Speaker: SPEAKER_07
Transcript:  He's selling a billion dollars of stock every year and putting into Blue Origin.  He said, I can't think of anything better to do with my lottery winnings.

Start time: 4884.40
End time: 4915.70
Speaker: SPEAKER_04
Transcript:  Yeah, I laid into him on that in an article that got a very arty email from Amazon's PR department.  Oh, yeah?  Yeah.  What did you say?  I was just pointing out that, you know, he's the world's richest man.  And yet his some of his employees are on food stamps, for goodness sake, which means we're paying to keep them alive.  Yeah, OK.  I support going to the moon.  I support going to Mars.  But you might want to stay as pay your staff a living wage before you start spouting off about, oh, I've got too much money.  Where was me?  And it's just like, just do the decent thing and pay your staff.

Start time: 4916.08
End time: 4919.90
Speaker: SPEAKER_07
Transcript:  And what possible retort with Amazon's PR have to that?

Start time: 4920.74
End time: 4929.90
Speaker: SPEAKER_04
Transcript:  Well, I think you'll find that if you average out staff part time and full time, we pay slightly more than is normal in the field.  And it's just like that's not the point.

Start time: 4930.22
End time: 4941.48
Speaker: SPEAKER_07
Transcript:  They should tell the truth, which is they pay the smallest wage they can get away with.  Well, yeah, and they paid no federal income tax last year.  But they're a business.  That's OK.  But just to be in defense, that's the system.

Start time: 4941.90
End time: 4946.90
Speaker: SPEAKER_06
Transcript:  Yeah.  That's how it works.  I know.  But that's what corporations do.  They maximize profit.

Start time: 4947.76
End time: 4952.90
Speaker: SPEAKER_04
Transcript:  Yeah, but they don't have the nerve to go whining about how they've got too much money and not be called out.  Well, that's why they should probably shut up.

Start time: 4953.02
End time: 5019.88
Speaker: SPEAKER_02
Transcript:  But you know, you just said you just said that their role is to maximize profit.  But, you know, Matt said earlier that we should trust the tech companies to try and push it as far as they can to solve these problems.  And so, you know, this is the juxtaposition that we're at right now where the American taxpayer is subsidizing through food stamps those employees who are not earning a living wage.  And these are the issues that we have to fight.  And the challenge that we have right now is that I don't know why you guys got into tech, but I got into tech because tech levels the playing field so that someone like me, a kid in a, you know, my bedroom in high school can build out tools that can take on the big guy.  But what we're seeing right now is tech scales inequality.  And Jeff Bezos throwing a billion dollars a year off to go to the moon because he can't think of anything greater like paying his employees a living wage or addressing homelessness or any of these other critical issues that we're trying to solve.  That's just bananas.  But that is the great example of, you know, our richest man in the world.  And that is the greatest example of how we're scaling inequality with tech.

Start time: 5021.27
End time: 5031.90
Speaker: SPEAKER_07
Transcript:  Excellent. Excellent point.  Although I, this is a larger problem, but America is based on a mythos.  Right. I mean, every country is to some degree.

Start time: 5032.22
End time: 5033.86
Speaker: SPEAKER_04
Transcript:  If anyone can make it.

Start time: 5034.04
End time: 5044.88
Speaker: SPEAKER_07
Transcript:  Yeah. But we have a very strong sense of individualism.  The Horatio Alger, anybody can make it.  The streets are paved with gold. We have a very strong sense of hands off.

Start time: 5045.52
End time: 5049.88
Speaker: SPEAKER_04
Transcript:  But it's a fantasy. Social mobility in the US is lower than the UK.  That's why I say myth.

Start time: 5050.43
End time: 5067.90
Speaker: SPEAKER_07
Transcript:  All myths are fantasies.  But they also, every country has to have every group and organization has to have a mythos that we all agree on.  Otherwise, we're not an organization. We're just a bunch of people.  So that's the American mythos. And that somewhat makes it difficult for us.

Start time: 5068.00
End time: 5071.78
Speaker: SPEAKER_04
Transcript:  I think what the British dream would be maybe a nice hot cup of tea and some Marmite toast.

Start time: 5072.90
End time: 5076.14
Speaker: SPEAKER_06
Transcript:  But that's really why it's gun control is difficult in this country.

Start time: 5076.98
End time: 5091.25
Speaker: SPEAKER_07
Transcript:  It's why it's difficult to reign in capitalism because there is this mythos that companies do a better job.  The free market does a better job of maximizing efficiencies.  I've seen it applied to. I think it was Mark Twain or Horatio Alger.

Start time: 5093.44
End time: 5105.90
Speaker: SPEAKER_04
Transcript:  One of these things was just that the reason socialism never took off in the US was because people convinced themselves that temporarily embarrassed millionaires, not poor.  You know, and it's so these kind of things can be actively, you know, they can be modified.

Start time: 5106.14
End time: 5116.62
Speaker: SPEAKER_07
Transcript:  And in fact, we are in a process actually, I believe, of deconstructing the American mythos in a very interesting and unusual way right now.  But since both of you want to be in government, I will stay away from that.

Start time: 5117.80
End time: 5151.90
Speaker: SPEAKER_05
Transcript:  Well, going back to tech for a second, it seems like tech was able to be optimistic for a very long time and have an attitude that we're just making the world a better place.  Because like you could, you know, trying to search the Internet before was awful.  And then you actually got some utility out of it.  And for a long time, that utility was so good that you didn't have to think about the second order consequences and the implications.  And I think what's healthy and right now is that a lot of companies are realizing the effect of goodwill and brand and all of your actions tie together in how people are willing to deal with you.

Start time: 5152.32
End time: 5156.90
Speaker: SPEAKER_07
Transcript:  And in fact, that maximizes profits in the long run as well. That's something to maximize.

Start time: 5157.26
End time: 5166.84
Speaker: SPEAKER_05
Transcript:  I don't know whether it's the right theory, but if you are in your enlightened self-interest trying to be better as a company because you think you'll get more long-term loyalty, I think that's a more sustainable plan, at least in my opinion.

Start time: 5167.24
End time: 5191.48
Speaker: SPEAKER_07
Transcript:  I agree. And you know, there's some structural reasons why that's difficult.  Companies are focused, especially public companies, are focused on quarterly results, not long-term results. Goodwill is hard to measure.  Yes.  But Bezos is the company, that's the company where their motto used to be, we're customer-centric. We focus on serving the customer.  That doesn't say much about the employees' wages, though, does it?  No.  It's not inconsistent with...

Start time: 5191.90
End time: 5197.90
Speaker: SPEAKER_04
Transcript:  Well, there was a big panic earlier in the week that Google might have taken the Don't Be Evil thing out of their mission statement. In fact, they just reordered it slightly.

Start time: 5197.96
End time: 5202.90
Speaker: SPEAKER_07
Transcript:  Yeah, let's talk about that, Matt, because you go back a little ways with Google. Don't Be Evil was the slogan when you started there, yeah?

Start time: 5203.74
End time: 5248.76
Speaker: SPEAKER_05
Transcript:  It was the unofficial motto. I think they've got lots of different ways of looking at it.  But it's interesting because even back in the early days, somebody wanted to reorder the values and say, you know what, let's make it do the right thing. Let's just take out Don't Be Evil.  I like that better.  Yeah, but there's a certain catchiness to Don't Be Evil. But I think they did still keep it.  I understand there's probably someone in the branding or the PR side of things that's like, wow, why are we emphasizing this negative?  Yeah.  Or, Don't Be Evil doesn't mean...  Be good, it just means don't be evil.  Yeah, just be neutral.  Right, so but do the right thing doesn't have the same catchy tone to it. And frankly, everybody's corporate values always say, you know, do the right thing for the environment and our customers and us.

Start time: 5248.96
End time: 5257.90
Speaker: SPEAKER_04
Transcript:  That was one of the things that made it so effective because when Google came out with this, you know, J.D. Juneau's like, you don't get many companies saying that, let's check these people out.

Start time: 5259.22
End time: 5268.58
Speaker: SPEAKER_07
Transcript:  It was when you're a small feisty little company and you got Larry and Sergey and you got a couple of servers in a tilt up and Mountain View, then it's kind of cool.

Start time: 5268.90
End time: 5288.88
Speaker: SPEAKER_05
Transcript:  Well, I can I can absolutely see the room with 12 people, including multiple communications experts in the room at Google that are saying, how do we put this at the very bottom of the statement so we still have it so we can still say we have it, but we're emphasizing these other things that we think are more important.  Like I can totally reconstruct that.  At least they did keep it in even though it's toward the bottom.

Start time: 5289.00
End time: 5293.65
Speaker: SPEAKER_07
Transcript:  Yeah. So is it chaotic evil or lawful evil?  Lawful evil.  Okay, just just.

Start time: 5295.71
End time: 5314.59
Speaker: SPEAKER_04
Transcript:  I kind of think Steve Bannon.  We're going to see Solo tonight. I'm excited about that.  Oh, really?  Yeah, they're doing a Boba Fett Origins movie.  Oh, it'll be called Boba?  I don't know, but it's just like it's just like Team Rodin.  Better than Fett.  Ring everything out of it.  Fett, the movie.

Start time: 5315.35
End time: 5327.02
Speaker: SPEAKER_07
Transcript:  Great Fett.  I'm going to take a little break and come back with more.  If you missed anything this week, we had a lot of fun.  I have made a I've commissioned a small movie to be made for your ed delectation.  Enjoy.

Start time: 5327.94
End time: 5329.64
Speaker: SPEAKER_04
Transcript:  Previously on Twit.

Start time: 5330.08
End time: 5334.79
Speaker: SPEAKER_00
Transcript:  Echo, send a message to Leo.  Ask a grown up to help set it up.  Ask a grown up.

Start time: 5336.84
End time: 5340.90
Speaker: SPEAKER_07
Transcript:  Hey kids, having trouble with privacy?  Ask a grown up.

Start time: 5341.54
End time: 5348.88
Speaker: SPEAKER_00
Transcript:  I wish I could set all these privacy policies on you and you would have to ask a grown up.  Before you say that thing that's in your head, ask a grown up.  That's a good idea.

Start time: 5349.94
End time: 5350.41
Speaker: SPEAKER_07
Transcript:  Windows Weekly.

Start time: 5351.46
End time: 5364.67
Speaker: SPEAKER_00
Transcript:  This week, Satya Nadella was in London giving an AI talk and most of the talk was a recap of what they said at Build about AI.  But then they did a demo there, which was Xiao Ice making a phone call.  This is Xiao Ice.

Start time: 5366.24
End time: 5387.86
Speaker: SPEAKER_07
Transcript:  Are you feeling less stressed now?  I was worried about you.  I'm feeling much better.  Thanks for talking with me about work earlier.  It's a little uncanny that it's, you know, showing concern like that.  The weirdest part about that conversation is the chat box doesn't shut up and the human being just says he's simple.  Okay.  The new screensavers.

Start time: 5387.90
End time: 5407.62
Speaker: SPEAKER_03
Transcript:  Today you're driving a Caddy.  Yeah, it's the Cadillac CT6.  And this is the version that has Super Cruise, which is GM's new partially automated driving system.  So yeah, you see the green bar there.  And I'm hands off.  Right.  So you can put your hands down on your lap.  But if you start to look away from the from the road,  Oh, he's going to.

Start time: 5408.02
End time: 5411.72
Speaker: SPEAKER_07
Transcript:  Okay.  So you have to look at the road again.  Yeah.  This is okay.

Start time: 5411.90
End time: 5413.33
Speaker: SPEAKER_06
Transcript:  Twitter hashtag pants check.

Start time: 5415.08
End time: 5427.76
Speaker: SPEAKER_07
Transcript:  This is one of the hazards of late night surfing.  Instagram ads seem somehow magically.  I buy the stupidest things.  So I saw this ad for underwear.  It's made out of eucalyptus trees.  No, you didn't.

Start time: 5427.90
End time: 5433.64
Speaker: SPEAKER_05
Transcript:  I'll be right back.  Let me go get that bag of magic beans.  Just buy an Instagram ad.

Start time: 5434.19
End time: 5439.63
Speaker: SPEAKER_07
Transcript:  I'll be there, baby.  I bought a knife last night.  I wake up.  It's my new thing.  It's a terrible thing.

Start time: 5439.90
End time: 5444.19
Speaker: SPEAKER_05
Transcript:  I'm in the middle of the night.  It's better than Kickstarter because you don't have to wait for four years.  I get it right away.  Or never.

Start time: 5444.90
End time: 5461.86
Speaker: SPEAKER_04
Transcript:  Or never get it.  This friend of mine got censored on the BBC about when you were on eBay.  eBay bought PayPal.  Yeah.  And he finished off the interview that he was giving the BBC say,  It's nice to know I'm not the only one that wakes up in the middle of the night after I've had a few and buy something I regret in the morning.  They censored that?  Yeah, apparently so.

Start time: 5461.94
End time: 5687.42
Speaker: SPEAKER_07
Transcript:  I think it's true.  Our show today brought to you by Stamps.com.  This is something you will want to buy.  If you do mailing in your business, if you send brochures or invoices, if you are an eBay or Amazon or Etsy seller, you send a lot of mail.  Why make a trip to the post office when you could do everything you do at the post office at your desk with Stamps.com?  I mean, it starts with buying and printing official U.S. postage for any letter, any package, any class of mail using your computer and your printer.  And then the mail carrier comes and picks it up.  You don't even have to get up to mail it.  That's awesome.  But you can do so much more.  Stamps.com, when you set up, we'll actually show you a great offer.  When you set this up, you're going to get a USB scale so you always know exactly the postage, no more guessing.  It will make recommendations on ways you can save.  You can even get discounts you can't get at the U.S. post office.  It is an amazing thing.  Plus, it does a lot of the work for you.  It will fill in the return address.  You could put your company logo on there.  It would take the address that you're sending it to from an address book, from a website.  So it automatically fills all of that in.  If you're sending internationally, mailing internationally, it will fill out the appropriate forms.  Express mail, same thing.  So this is a great way to use the U.S. Postal Service to great effect.  Click print mail and you're done.  It makes you look like you're a big company even if it's just you.  We actually have two accounts because we sometimes have to fight over it.  Stamps.com is awesome.  You can go there right now and set up an account with a special offer that includes up to $55 in free postage, a digital scale, I mentioned that, and a four-week trial.  Here's what happens.  Go to Stamps.com.  You're seeing the site on the page right now.  Click on the microphone.  There's a microphone, a kind of funny-looking radio microphone at the top right.  Enter TWIT as the offer code and you're going to get a special offer.  You don't get on the front page.  You'll know you got the right one when you see my face.  Stamps.com.  They've been a sponsor and we've been a customer for years and I'm a big fan.  Stamps.com.  And then when it asks you for the offer code, TWIT, if you will, that gives you up to $55 free postage, the digital scale, a four-week trial.  Stamps.com.  Click the mic and enter TWIT.  GDPR.  Wow.  This is a perfect, I really actually like this because it's a perfect example of both the benefits and the consequences of governmental regulation.  In some respects, I think we're all going to benefit worldwide, even though it's for EU only.  But I also think about what Friday was like.  Friday is the day GDPR went into effect.  And I know at my company, we had to spend probably 20 or 30 hours figuring out what the hell are we collecting?  We don't collect, we don't do anything, right?  What are we collecting?  We collect IP addresses, right?  That's just the way the web server works.  What the hell we're collecting, what our data retention policy is, how we can have people ask to be deleted.  For instance, if you sent me a note saying, please delete your record of IP address 68.32.1.1,  I would then have to go back to you and say, well, first of all, when?  Because you have a dynamic address.  What time?  And you have to prove to me that you have to go to your ISP and get a letter saying, yes, Joe was using that address at that time and day so that I can delete it.  But I still have to offer that service.  I have to re- we rewrote our entire privacy policy.  At 20, I probably was more like 40 or 50 man hours.  And that's for this little company.  I think about the millions and millions of man hours used, women hours, person hours used over the last few weeks.  And then there's the US newspapers.

Start time: 5687.90
End time: 5718.90
Speaker: SPEAKER_04
Transcript:  Oh, that was pathetic.  I'm sorry.  I mean, look, it's not that hard.  You know, GDPR doesn't involve massive- all you've got to be doing is what you should be doing already, which is encrypting your data at rest,  keeping an eye on what you've got when you've got it and knowing that you can take it on or off your system afterwards and occasionally asking your users permission to use it.  Every company should be doing that anyway.  And so when the US newspapers went dark, we were just looking at them like, wow, you really couldn't even be bothered to get it sorted at this stage.  Oh, well, more readers for us.

Start time: 5719.12
End time: 5725.88
Speaker: SPEAKER_07
Transcript:  That's actually what the GDP regulators said is that you've had two years.  Yeah.  We passed this in 2016 and said we won't put it in effect till May 25th, 2018.

Start time: 5726.04
End time: 5729.16
Speaker: SPEAKER_04
Transcript:  But if you think this is bad, look at ICANN and the Whois registry.

Start time: 5730.26
End time: 5736.88
Speaker: SPEAKER_07
Transcript:  Hold that because we're going to get there.  This is the Chicago Tribune's website.  If you went there via the EU, and it does seem like they're-

Start time: 5736.94
End time: 5738.83
Speaker: SPEAKER_04
Transcript:  Even outside the EU, if you're in Switzerland, for example, you got the same page.

Start time: 5739.90
End time: 5821.88
Speaker: SPEAKER_07
Transcript:  Because they're not that good at geolocation, right?  It's kind of a- they act as if it was something that hit them upside the head all of a sudden.  Unfortunately, our website is currently unavailable in most European countries.  Yeah, because we made it so well.  We are engaged on the issue and committed to looking at options that support our full range of digital offerings to the EU market.  We continue to identify technical compliance solutions that will provide all readers with our award-winning journalism.  It wasn't just the Chicago Tribune.  It was all of Tronk.  It was the LA Times.  It was the Arizona Daily Star.  I got a call on Saturday on the radio show.  I'm trying to post a link to an article in the Star on Facebook.  It was an article about this horrific practice of separating children from their parents when they're crossing the border.  Just horrific.  I said, well, I want you to post that.  That's important.  But she said, but I can't because I'm in Santa Cruz, California.  I'm posting this from the Arizona Star on Facebook.  And I got a pop-up that says, because of GDPR, we can't- you can't post that.  You can't post this.  We're blocking it.  So I don't know if the Star made a mistake on her geolocation or more likely decided, well, if we posted on Facebook, that might be seen by a European.  So we better not allow Facebook.  It's crazy.

Start time: 5822.04
End time: 5823.84
Speaker: SPEAKER_04
Transcript:  It's poor implementation.

Start time: 5824.12
End time: 5826.90
Speaker: SPEAKER_07
Transcript:  The New York Daily News, the Orlando Sentinel, the Baltimore Sun.

Start time: 5827.00
End time: 5843.28
Speaker: SPEAKER_04
Transcript:  You see, I gave a presentation about this to a bunch of venture capitalists in February, and they honestly thought I was joking when I told them what the fines were and what they'd have to do.  And it just- people just didn't seem to get it in this country.  Europe's been prepared for this.  And it went smoothly with- everyone just had to re-

Start time: 5844.04
End time: 5850.90
Speaker: SPEAKER_07
Transcript:  So the fine is 4% of your global revenue.  Yeah.  Or 20 million.  Yeah.  Gross, not net, not profit.

Start time: 5851.10
End time: 5856.90
Speaker: SPEAKER_04
Transcript:  Yeah.  It's either 2% or 4%, depending on the severity of the fine.  Or 20 million euros.  Or 20 million or 40 million euros.

Start time: 5857.30
End time: 5865.07
Speaker: SPEAKER_07
Transcript:  But I guess there's a legitimate question.  Are they going to go after me for 4% of my global revenue because I don't have a proper policy?  How- how- what?

Start time: 5866.22
End time: 5868.92
Speaker: SPEAKER_05
Transcript:  You saw that Facebook and Google have already been hit with $8.8 billion in lawsuits.

Start time: 5870.16
End time: 5871.88
Speaker: SPEAKER_04
Transcript:  Yeah, but that's just like Shrems being a wanker.

Start time: 5872.00
End time: 5874.06
Speaker: SPEAKER_05
Transcript:  Oh, but 8.8 billion.  Yeah.

Start time: 5875.32
End time: 5876.90
Speaker: SPEAKER_07
Transcript:  So this guy- tell me about Shrems.

Start time: 5877.69
End time: 5889.86
Speaker: SPEAKER_04
Transcript:  He's a privacy activist.  He brought down the agreement that the US and Europe had on data privacy.  Basically, he's a nice enough chap.  He obviously cares about what he's doing.

Start time: 5890.49
End time: 5893.00
Speaker: SPEAKER_05
Transcript:  But he's just a bit of a zealot about it.  But he's been successful in court.  Yeah.

Start time: 5894.34
End time: 5903.64
Speaker: SPEAKER_04
Transcript:  He has successfully argued that people should have a certain amount of rights over their data,  which is part of where GDPR came from.  So actually, we should say a bit of a thank you to him.  Well, that's the problem with this, isn't it?

Start time: 5903.92
End time: 5907.04
Speaker: SPEAKER_07
Transcript:  It both giveth and taketh away.  Yeah.

Start time: 5907.94
End time: 5916.90
Speaker: SPEAKER_05
Transcript:  I'm still angry that whenever I show up on any site in the UK, for example,  I get the, yes, I have cookies.  I have to find the X to close it.

Start time: 5916.96
End time: 5945.72
Speaker: SPEAKER_07
Transcript:  I think that's a very good example of how this regulation is dumb.  That kind of regulation accomplished nothing.  It just used up a lot of manpower time and my time and attention for something that does nothing.  Yes, okay, I accept your cookie policy.  And by the way, now everybody's doing it because GDPR has raised that awareness.  So, Brian, is this an example of regulation gone wrong or is this the right idea but badly implemented or is this all perfect?

Start time: 5947.38
End time: 6048.90
Speaker: SPEAKER_02
Transcript:  Well, I think it's clear to so many people that they need to be more aware and they need to care about their privacy and their personal information.  And I think if you consider data, I mean, people call data the new oil.  Well, there are liabilities.  If you're an oil company, you have an oil spill.  What are the liabilities in place?  What are the teeth that government might have or that citizens might have if companies have data spills, which are your 21st century oil spills?  I think, you know, is any legislation perfect?  No, it needs to continue to iterate to get better.  And so I think it's important that we're taking first steps and Europe is taking the plunge first.  And my hope is that here in California, they're coming up, there's a new they're pulling together some new legislation as well.  And so I think, you know, the good thing is, is that it was implemented across the European Union.  And I think the challenge is, is that when each country creates one set of legislation, another one creates a different, it makes it really hard and creates a lot of friction for small startups.  Now, companies like Facebook and Google, they have huge legal departments to be able to do this.  But, you know, Twitter, for example, you know, doesn't have as big of a legal department as those two companies.  And so my concern sometimes is that when you have how hard is this going to be for smaller startups?  And do we need to create regulatory sandboxes to allow for up to a certain amount of transactions or volume, et cetera,  until you need the full weight of the regulatory overhead that's being applied here so that Twitter is at a certain level, but Facebook and Google are at a much higher level?

Start time: 6051.16
End time: 6063.32
Speaker: SPEAKER_07
Transcript:  Yeah, I mean, I don't expect, you know, Martha Vestager to come to my house and give me a subpoena.  But I but what if somebody sued us? We'd have to respond to that, right?

Start time: 6065.20
End time: 6085.55
Speaker: SPEAKER_04
Transcript:  You have to within 72 hours give them the data, the data that you have on them, which isn't unreasonable.  I do think that they could possibly have done it in a slightly more organized way.  But, you know, the actual requirements of this, you say it took you about 30 to 40 hours to do it.  Not me, thank God.  Well, yes.

Start time: 6086.34
End time: 6091.86
Speaker: SPEAKER_07
Transcript:  And there are websites. I think we used a website where you do a bunch of checkboxes, you pay them a fee.  I mean, PR as a service.

Start time: 6091.90
End time: 6092.04
Speaker: SPEAKER_05
Transcript:  Yeah.

Start time: 6093.06
End time: 6099.90
Speaker: SPEAKER_04
Transcript:  A lot of small companies are doing that. They're basically, is my cloud provider GDPR compliant? Yes. Fine. Don't need to worry about it.

Start time: 6100.10
End time: 6146.90
Speaker: SPEAKER_07
Transcript:  Some have pointed out that if you're not gathering a lot of information, if you're not, if you are doing the right thing, this isn't onerous.  But there are some onerous things. For instance, if there's a data breach, and I'm kind of in favor of this, but I've heard that companies are not are a little troubled by it.  If there's a data breach, you have 72 hours to report it to your customers.  Oh, I'm all for that. I hate companies that have like Yahoo didn't tell anybody for months. Yeah. Equifax. Equifax. Yeah.  But at the same time, many companies think 72 hours is actually an unreasonable deadline, not merely for the difficulty, but also because of security issues.  It may not be appropriate to say this is happening until we've locked it down. We figured out what happened. And that's 72 hours is not enough time.  So I have mixed feelings about this. I guess some of this comes down to how it's how assiduously it will be enforced.

Start time: 6147.24
End time: 6170.90
Speaker: SPEAKER_04
Transcript:  That's going to be the key to it. And I think it'll it won't be used to based on past experience of where the EU has gone on this and with competition laws and various other things.  It won't be used against small businesses by and large. This will be if Facebook or Google or Twitter or one of the big companies mugs it up.  US regulators give them a pass as they always do. So the EU has to institute some fines. This is where it's going to be used.

Start time: 6172.46
End time: 6178.90
Speaker: SPEAKER_05
Transcript:  Do you think there's any risk that that might come across as more like anti-American tech company rather than and I'm just raising the question.

Start time: 6178.98
End time: 6190.84
Speaker: SPEAKER_04
Transcript:  Yeah, no, I honestly it's it's kind of a tricky question because most of the big tech firms are American.  But I think then they'd be more than willing to to go after that, go after European companies as well.

Start time: 6191.28
End time: 6234.86
Speaker: SPEAKER_07
Transcript:  It reminds me though a little bit of some of the controversy with Google over snippets and the shopping issue where it really felt like the EU was responding to the commercial interests of EU companies.  The snippets is a very good one where European publishers didn't like the fact that Google was using that content.  Of course, they changed their mind when Google delisted them in Spain. I remember that was a bit of a kind of a loss for Spanish publishers.  But that to me felt like the EU was responsive to commercial pressure from its own constituents to the detriment of a United of American companies that weren't constituents.

Start time: 6235.70
End time: 6269.72
Speaker: SPEAKER_04
Transcript:  Well, the Google shopping thing was in response to Microsoft actually complaining to the EU.  Even worse.  Microsoft sponsored EU organisations complaining. So I mean, it's a stick that American companies can use as well.  I mean, I guess there's always an element of this just as there have been with you know, as we saw with equation, the NSA's equation system being used to spy on European companies.  I mean, this has always gone on at some level, but I think the motives behind GDP are pure or as pure as they can be.  These are politicians we're dealing with after all.

Start time: 6269.90
End time: 6272.40
Speaker: SPEAKER_07
Transcript:  And no law is perfect. And so some of this will come out in the...

Start time: 6273.55
End time: 6280.47
Speaker: SPEAKER_04
Transcript:  Brian's like...  Yeah, no, no, not obviously not. President company accepted.  At what point do you become a politician, Brian?

Start time: 6282.47
End time: 6289.66
Speaker: SPEAKER_07
Transcript:  I got to be elected first.  Yeah, I think you're a technologist still. You're an aspiring politician, which some might question that.

Start time: 6289.90
End time: 6291.23
Speaker: SPEAKER_02
Transcript:  I hope to always be a technologist.

Start time: 6292.26
End time: 6302.84
Speaker: SPEAKER_07
Transcript:  That's one of the reasons I love that.  You know, we need to get people with some brains.  Brianna Wu is a regular on our shows as well.  We really need to get some people with some tech chops in Congress.

Start time: 6303.48
End time: 6306.14
Speaker: SPEAKER_02
Transcript:  Are you a government bureaucrat or are you a technologist?

Start time: 6307.75
End time: 6310.20
Speaker: SPEAKER_07
Transcript:  Matt, government bureaucrat or technologist?  Why not both?

Start time: 6312.14
End time: 6341.78
Speaker: SPEAKER_05
Transcript:  He's two. He's two.  I will say I used to use the word bureaucrat much more often before I joined government service.  And now I'm much more likely to say civil servant.  I agree.  Because when you're there seeing, you know, sometimes sausage getting made,  what you really see is a lot of incredibly dedicated people trying to do the very best that they can,  sometimes hampered by red tape.  And you know this, Brian, trying to get to the point of what are the best solutions that you can get to  given the constraints and regulations and laws and all those sorts of things.

Start time: 6342.30
End time: 6375.84
Speaker: SPEAKER_07
Transcript:  Yeah, you actually said it, Brian, earlier.  That it's the, I think when you sit in the White House you probably see that.  It's the people who are, who go from administration to administration year after year,  who are really doing the people's work.  And those are the people on the ground.  And I'm consistently impressed not by their commitment to doing the right thing  independent of parties and politics and party.  I think that's great.  You're right, they should be called civil servants.  But this is part of the American mythos that all bureaucrats are bad, right?

Start time: 6376.58
End time: 6452.86
Speaker: SPEAKER_02
Transcript:  Well, I think that was one of the most untouted accomplishments of the Obama administration  was the fact that, you know, you mentioned Todd Park earlier and what a great salesman he was.  And what he did is he just reframed the argument about why technologists should serve in our government.  And this goes back to the ethos that people have in tech companies about making the world a little bit better.  I remember that when I went into the White House and I was one of the early technologists to do it,  I got a lot of flak from my tech friends who said, why would you want to go into this monolithic bureaucracy?  What are you going to accomplish there?  My immediate retort was, how many users does your little app have?  Well, we got more than 300 million Americans and we have a much bigger platform than you.  And so there's a huge opportunity.  But it took Todd Park to literally reframe the conversation and say,  have you done your tour of duty in the U.S. government?  And don't make it about, you know, you're going to government, you're going to have to work there for 30 years.  You know, you're going in for a couple of years and you're going to make a really big impact.  And the question is, for everyone in the tech community, have you done your two years?  I did my two years when I served in the Peace Corps and I served in the White House.  But, you know, we should be asking every technologist, if you hope to make the world a better place,  have you done your time in the U.S. government?  That's absolutely true.

Start time: 6454.46
End time: 6464.90
Speaker: SPEAKER_07
Transcript:  I've always been in favor of compulsory service, not necessarily in the armed services,  but in the Peace Corps or in the USDS, some sort of service required of everybody coming out of college.

Start time: 6465.84
End time: 6501.90
Speaker: SPEAKER_05
Transcript:  Well, and leave out the compulsory part, just the fact that there are people who are willing to do this.  What I have seen is people often think they're going to go do six months or a year or two years of government service  and then go back to their company.  And what's fascinating to me is many of these folks end up making a change to their lives  where they do a left turn or a right turn from what they planned.  We've seen people who started the Massachusetts digital service, who helped start the California digital service.  We've seen people who did startups afterwards that try to improve things with civic tech.  So like it really opens up a completely different lens on how you view things.  And to exactly to Brian's point, the impact that you can have on people.

Start time: 6502.74
End time: 6527.70
Speaker: SPEAKER_07
Transcript:  I think a lot of geeks think it's cool to be arch, to be sardonic, to be cynical about government.  And there's plenty of things you can point at to government cheese, somebody just said in the chat room.  But let's make it cool to care about our country enough to serve it and to make a difference and to take some time.  I think that's where we should be headed.  Could I tell one one minute story?

Start time: 6527.94
End time: 6582.90
Speaker: SPEAKER_05
Transcript:  We had something at Veterans Affairs where veterans were trying to get their health benefits  and they had to use the right version of Internet Explorer and it had to be Internet Explorer.  It had to be Internet Explorer. You couldn't use another browser.  And you had to use the right version of Adobe Acrobat.  And if you didn't have the right version of both of those, it would tell you, you need to upgrade your version of Adobe Acrobat.  And that was wrong. You actually needed to downgrade your version of Adobe Acrobat,  which meant everybody ended up using the paper version of this form.  It's called the 1010EZ.  When you fill out the paper version of this form, you have to wait 137 days on average to get your health benefits.  So we implemented this crazy, revolutionary new technology along with the VA.  We call it a web form.  It's responsive, so it works on mobile phones.  It's accessible, so it works for blind users.  Now 50% of veterans find out whether they're eligible for their benefits in 10 minutes.  Isn't that awesome?  We just need more technologists and designers to do that.

Start time: 6583.44
End time: 6590.86
Speaker: SPEAKER_07
Transcript:  And half the people listening probably could code that in a couple of hours.  And we need the people.  Yeah.  And tech is bipartisan.

Start time: 6592.50
End time: 6617.90
Speaker: SPEAKER_02
Transcript:  So when we were in the CTO's office, we had bipartisan support because on the right and the left,  we all want to make our government more efficient, more effective, more transparent.  And in fact, the very last bill that President Obama signed was enshrining into law  the Presidential Innovation Fellowship Program, which was the precursor and the inspiration for the United States Digital Service.

Start time: 6619.38
End time: 6633.70
Speaker: SPEAKER_05
Transcript:  Yeah, this is nonpartisan work.  I've got $100 million projects that might go off the rails for lack of three engineers, two designers, and one product manager.  So USTS.gov slash join.  Sorry.

Start time: 6634.06
End time: 6666.27
Speaker: SPEAKER_04
Transcript:  No, no, I think it's a great idea.  The problem is when you've got students coming out of university with a bunch of student debt,  their first thought is get into private industry, make them a ton of money, pay off my debts,  and then I think it's going to be easier to actually pull them into government service.  But hey, you could even get a scheme whereby if you agree to serve with the government for two or three years,  they pay you college tuition.  I mean, it's definitely needed because the state of IT knowledge, IT infrastructure in the US government,  it makes the UK look good.  That takes some doing.

Start time: 6666.90
End time: 6691.27
Speaker: SPEAKER_05
Transcript:  Well, and what's fascinating to me is you see this movement around the world.  So it's not just the United States.  There's the Canadian Digital Service.  They just had an Amazon executive go to Italy to do the similar thing.  Of course, the UK is one of the originals because they have the government digital service,  which actually has the purse string.  So if you want to make any large IT project, you actually have to get approval by folks who know technology.  So you're seeing this progress around the world.  I love it.

Start time: 6693.45
End time: 6720.52
Speaker: SPEAKER_07
Transcript:  There are people who say, well, just privatize it.  Let private industry do it.  I think about the I think it was the Obamacare website, the website, which was HealthCare.gov was outsourced.  It's supposed to be privatized.  Yeah.  And that did not work so well.  In fact, didn't the I think the USDS road to the rescue.  Yes, that's right.  And that's how it was created, wasn't it?  That's a VCA's website.

Start time: 6721.14
End time: 6740.90
Speaker: SPEAKER_05
Transcript:  That's exactly right.  And it you know, I'm not saying that the digital service needs to do every government service.  No, not at all.  There's absolutely a place for contractors and there's a new wave of contractors that have happened after HealthCare.gov.  But you still need someone in government service who speaks both languages technology as well as how things work in government.  It translated even for contractors.

Start time: 6741.95
End time: 6768.88
Speaker: SPEAKER_07
Transcript:  Look, it's a responsive web form.  Go to USDS.Join even on your smartphone.  Right.  USDS.gov.  It'll work.  Yeah.  USDS.gov slash join.  Thank you.  Let's get it right.  And actually, it doesn't have to be a kid coming out of school.  I think probably your best employee employees, best people are people who come from a company like you did from Google with a lot of tenure, a lot of experience who want to take a little time off and help.

Start time: 6768.92
End time: 6780.86
Speaker: SPEAKER_05
Transcript:  Yeah, we actually look for people who are like five years into their career often.  And it's not a matter of time.  It's a matter of experience.  You want battle scars.  You want the experience setting up large web scale services and APIs and that sort of thing.

Start time: 6781.28
End time: 6791.14
Speaker: SPEAKER_04
Transcript:  I mean, given that IBM is currently firing or sorry resource allocating most of its older employees as well.  There's a vast reservoir of talent that could be tapped into.  Yeah.

Start time: 6792.25
End time: 6794.53
Speaker: SPEAKER_06
Transcript:  Let's fix this.  Yeah.  Yeah.

Start time: 6795.56
End time: 6815.80
Speaker: SPEAKER_07
Transcript:  USDS.gov slash join.  And while you're at it, F-O-R-D-E dot com.  If you're in the 45th District of California, you know what to do.  You know what to do.  The first.  Do you have you are you're dubbed by Bloomberg, the first crypto candidate for Congress.  Congress.  Do you like that title?

Start time: 6817.25
End time: 6818.88
Speaker: SPEAKER_01
Transcript:  I mean, what are you going to do?

Start time: 6818.92
End time: 6910.83
Speaker: SPEAKER_02
Transcript:  They gave me the name.  But I think, you know, what's important is, is that how can legislators hope to create laws on technology that they don't use?  And so invariably, our legislators are going to have to make laws on cryptocurrency, drones, autonomous vehicles, artificial intelligence, CRISPR, like name your technology.  It's all out there.  But have any of them use them?  Yeah.  And so, you know, I often say when I'm explaining Bitcoin and how people crazy think Bitcoin is, I say, well, you know, how many of you in this room could actually code a mobile application?  And they barely any hands go up.  And I said, well, how many of you have been in a situation where you confronted a problem with your coworkers or your colleagues?  And you said, well, we need a mobile application for that.  And use and why did you suggest that if you don't know how to build a mobile application?  Well, because you use mobile applications every single day.  You know that you can use the Internet as GPS.  You can take photos, you can do all kinds of things.  But if you're not using cryptocurrency or you're not using any of these other new technologies, you can use the Internet.  And I think the key question is, you know, if you're not using technology, how on earth are you going to be on the right side of history for technology and for our society?  If you've ever used this technology.  And I think what was most concerning to so many people in watching the congressional hearings with Mark Zuckerberg was that it was self evident to everyone that the legislators don't even use Facebook.

Start time: 6914.98
End time: 6915.87
Speaker: SPEAKER_01
Transcript:  And this is social media.

Start time: 6916.90
End time: 6925.83
Speaker: SPEAKER_02
Transcript:  What we want to do is we're not going to be a picture of what is going on in our areas if we believe that the future of our economy or society is going to be confronting 21st century problems.

Start time: 6929.90
End time: 6932.61
Speaker: SPEAKER_04
Transcript:  There was one senator who didn't even seem to know the difference between Facebook and Twitter.

Start time: 6934.51
End time: 6967.12
Speaker: SPEAKER_07
Transcript:  I remember.  Oh, right.  And the Instagram shout out as well.  What's app? Can Facebook see that?  Senator, no, WhatsApp is encrypted. We can't see any of that.  Yeah. But if I message someone about Black Panther on WhatsApp, will I get ads about Black Panther on Facebook?  No.  Actually, that's a pretty good question.  I don't know if that's the right answer.  But I don't know if it also came from a fundamental understanding.  Mr. Zuckerberg asked Chuck Grassley, what is a poke?  Oh, no.

Start time: 6968.59
End time: 6971.02
Speaker: SPEAKER_06
Transcript:  Ask your wife.  Yeah.  What?

Start time: 6972.39
End time: 7208.21
Speaker: SPEAKER_07
Transcript:  No, I don't know.  My son, Senator Corbin, my son is on Instagram.  Oh, that was cringe.  He asked me to mention that he is adjust glasses, Blaze Boy 420XX and no, no, I don't think that's the actual URL.  Our show today brought to you by our fresh air.  Are you enjoying the fresh air in the studio today?  Have you noticed? Have you noticed how clean it is?  No smell of volatile organic compounds, smoke, no, no, no black mold, nothing.  It's because we're clean air with molecule in the studio.  And actually, I love the molecule so much we have one in our bedroom at home and our son's bedroom at home.  Molecule is a brand new kind of air purifier.  Fifty years ago, actually more than that, in the 40s, the HEPA filter technology was invented.  This is just a very fine filter, but it doesn't doesn't really catch the smallest molecules.  That's why molecule invented the Pico technology, photo electrochemical oxidation to capture pollutants a thousand times smaller than those a HEPA filter can capture.  That includes allergens, mold, bacteria, viruses, airborne chemicals.  It makes it a lot easier to cope with asthma.  And I can vouch for allergies.  We live in an area where there's a lot of pollen and dust.  Our cats come in every morning covered in pollen, believe it or not.  And we have the molecule.  And ever since we put the molecule in the bedroom, my wife says she's not woken up with a headache.  She used to wake up with a headache every morning, nose all stuffed up.  The molecule is amazing.  Funded by the EPA, proud to say, extensively tested by real people, was verified by third parties in the university laboratories like the University of Southern Florida.  The University of Minnesota's Center for Biological Defense and the University of Minnesota's Particle Calibration Laboratory is a beautiful device.  It has kind of the apple of air purifiers.  It's a solid aluminum shell.  They have a filter subscription.  If you want, you don't have to.  You could put your molecule on Wi-Fi and then it will automatically request more filters when the filters get used up.  It's about we get about six months in our filter.  It's nice though that the filter comes automatically.  We just it's easy to put in.  You don't have to do that.  It has a button on the top.  You can turn it off and on for people who are paranoid about their air filter status being broadcast over the Internet or something.  I don't I don't think that's a problem.  But I love the molecule.  We're very happy.  We have a good deal for you to seventy five dollars off your first order.  If you visit molecule dot com, M O L E K U L E dot com and into the promo code tweet when we bought one in the bedroom.  It works so well.  We bought one for Michael and we bought one for the studio.  We actually really needed it during the fires up in Sonoma County where it's so smoky.  This this this makes a big difference for seventy five dollars off your first order molecule dot com promo code tweet in the early days.  I love this article in the outline in the early days of Twitter.  Only one celebrity could tweet at a time.  This is a great story about scaling.  But Evan Weaver, who is former technical lead and architect at Twitter, talked about the early days.  He said.  When Demi Moore and Ashton Kutcher, who were the first real celebrities, remember that?  Yeah.  Mr. and Mrs. Kutcher, when they when they would run in 2009, it was required that if either of them sent a tweet, it would take so long because they had so many followers that the whole thing would go down for minutes.  Nobody would literally nobody would be able to tweet for several minutes.  But he said we had to manually run a script on a laptop that would specifically check if they had tweeted to each other so that they would see it in real time.  OK.  Heller high water, he said.  We had to make sure nothing could go wrong.

Start time: 7210.32
End time: 7221.90
Speaker: SPEAKER_04
Transcript:  So that means there was one person at Twitter and it's like you're the Demi Moore, Maston Kutcher.  Yes, and Kutcher feature.  Yes, sit there and wait for them to brain fart and make sure it gets online quickly.

Start time: 7221.94
End time: 7240.84
Speaker: SPEAKER_07
Transcript:  You know, Jason Goldman, who is VP of product at Twitter between 2007 and 2010, said Twitter was held together by sheer force of will in those days and sometimes not even then.  And barely even remember the fail.  Well, I haven't seen that in a while.  I kind of miss the old the old fail whale.  Oh, my goodness.

Start time: 7240.92
End time: 7250.90
Speaker: SPEAKER_05
Transcript:  I know.  Well, you know, in the early days of Google, they used to update once a month.  They would have a monthly index, which is great until there's some new virus.  And suddenly that's breaking news.

Start time: 7251.87
End time: 7254.17
Speaker: SPEAKER_07
Transcript:  And the way your data is a month old.  Yeah.

Start time: 7254.90
End time: 7259.12
Speaker: SPEAKER_05
Transcript:  Oh, yeah.  And what we didn't have daily updates until like 2003.  Yeah.

Start time: 7259.98
End time: 7290.44
Speaker: SPEAKER_07
Transcript:  That's back when it was in a tilt up and it was Larry and Sergey and a couple of servers.  Yeah, I remember visiting Yahoo in the early days and Jerry's and Dave are sitting there.  It was literally a tilt up.  And you could go in a closet and say, yeah, there's the Yahoo server.  That's the one.  That's the one.  Akebono.  Yeah, that's it.  Lots of people complaining about 1803, not the year, the update to Windows 10.  Oh, the update from hell.

Start time: 7290.98
End time: 7293.70
Speaker: SPEAKER_04
Transcript:  Yes.  Delayed and buggy.  Two Chromebooks.

Start time: 7294.04
End time: 7305.74
Speaker: SPEAKER_05
Transcript:  Chromebooks.  It's a double Chromebook.  And not even a Pixelbook.  These are the classics.  These are the good ones.  Why don't you have a Pixelbook?  I tried it.  The screen's a little small.  Oh, you liked a little bit bigger.  I like a little bigger screen.  Actually, Acer announced...

Start time: 7305.90
End time: 7311.72
Speaker: SPEAKER_04
Transcript:  My lids will stick it.  So, I can't really...  That's why I get a new laptop because the sticker layers get too deep and I need to...

Start time: 7312.06
End time: 7315.72
Speaker: SPEAKER_07
Transcript:  Yeah, just peel it off in one layer and put it in the Smithsonian.  Future archeologists, yes.

Start time: 7315.96
End time: 7318.90
Speaker: SPEAKER_05
Transcript:  I'm using the Surface, much to my dismay, by the way, the Surface Studio.

Start time: 7318.90
End time: 7337.80
Speaker: SPEAKER_07
Transcript:  I love this computer and I love the screen and I love the touch.  But lately it's been getting a little wonky.  I think we're going to have to...  Maybe it's 20...  It could be 1803.  The update.  What are you using, Brian?  Are you on a Mac?  I'm on a MacBook.  Yeah, that's what I figured.  We are the only campaign in the country that has, out of 500, that has a CTO.  Oh, really?  That's kind of hard to believe.

Start time: 7338.06
End time: 7345.90
Speaker: SPEAKER_02
Transcript:  It's bizarre.  It's really not.  Oh, Campaign Tech is...  I remember walking into the White House.  White House.  What?  That was the gift we got from George Washington.

Start time: 7346.10
End time: 7347.74
Speaker: SPEAKER_06
Transcript:  That's true.  It was a great gift.

Start time: 7348.45
End time: 7348.90
Speaker: SPEAKER_08
Transcript:  It was a great gift.

Start time: 7348.90
End time: 7377.44
Speaker: SPEAKER_02
Transcript:  It was a great gift.  It was a great gift.  I remember, I mean, we would just bang our heads against the wall with the way that we  were building out technology.  And me walking into a campaign was just like White House Redux.  Just, oh my gosh, Campaign Tech is miserable.

Start time: 7378.70
End time: 7386.36
Speaker: SPEAKER_07
Transcript:  If a campaign doesn't have a CTO, what is it?  Uncle Joey's sister's brother is doing the stuff?  I mean, it's just like pre-digital.

Start time: 7386.76
End time: 7412.27
Speaker: SPEAKER_02
Transcript:  There's a couple of companies that kind of control it.  It's pretty bad.  And so we actually brought in a CTO, performed open heart surgery, went on, we use a different  platform instead of the standard platforms to really tackle the problem.  But one thing that we do do is we left source our software.  So all the software that we build out, we open up for free to other progressive campaigns.  Honestly.

Start time: 7414.05
End time: 7415.16
Speaker: SPEAKER_07
Transcript:  No Republicans allowed?

Start time: 7417.35
End time: 7418.99
Speaker: SPEAKER_02
Transcript:  Until they start fighting for net neutrality.  Hard one.

Start time: 7420.95
End time: 7423.21
Speaker: SPEAKER_05
Transcript:  Oh, I love it.  Salty.

Start time: 7424.68
End time: 7486.54
Speaker: SPEAKER_07
Transcript:  Comcast is now in the bidding war for Hulu.  Remember that 21st Century Fox went up for sale and Disney said we're going to offer  $52 billion for it.  Comcast has now confirmed that they are lining up a bid which could be as high as $60 billion.  I don't think I'm guessing it's not they don't get Fox News.  They don't get Fox Business Network.  No, I'm guessing it's not the Fox Sports Regional Networks.  But maybe that's what they're interested in.  There is a 39 percent ownership of Sky.  And I know that Comcast has been trying to buy Sky.  So that might be part of it.  The British satellite broadcaster.  But it would also and I think this might be more to it.  The point include Fox's 30 percent stake in Hulu.  Comcast already owns 30 percent of Hulu.  Just give it full control.  And of course you got to figure Comcast which is you know makes its money selling premium packages for television.  Is not a fan of Hulu.  So that would give them controlling interest in probably the number one.  I think it is the number one over the top video provider.

Start time: 7487.94
End time: 7495.36
Speaker: SPEAKER_04
Transcript:  Yeah, because you know media consolidation is what this country really needs at the moment.  It's unbelievable.  Far too few companies.  There's far too many companies getting involved with this media business.

Start time: 7496.39
End time: 7516.54
Speaker: SPEAKER_07
Transcript:  And don't forget Comcast already owns Universal.  Owns NBC.  It's really reaching its tentacles out.  And this is one of the reasons why you're not net neutrality is an issue.  Is because Comcast chief among everybody is doesn't want net neutrality.  They want to control all of this stuff.  And they're showing it with their acquisitions.

Start time: 7516.54
End time: 7526.52
Speaker: SPEAKER_04
Transcript:  I've just I've yet I've never in 10 years in living this country.  I've never met a satisfied Comcast customer.  You know one who actually enjoys the service they get from the company.

Start time: 7526.54
End time: 7533.48
Speaker: SPEAKER_07
Transcript:  The last survey I saw said that they asked people what they hate the most.  Comcast was worse than a heart attack.

Start time: 7535.81
End time: 7539.48
Speaker: SPEAKER_04
Transcript:  Probably caused a few.  The customer support team.  All right.

Start time: 7539.54
End time: 7540.54
Speaker: SPEAKER_07
Transcript:  I shouldn't get on my white horse about.

Start time: 7540.54
End time: 7565.67
Speaker: SPEAKER_04
Transcript:  Well I did learn one very interesting trick from a friend of mine though.  He said if you ever want to cancel a Comcast account.  They'll try and keep you on the phone for 20 30 minutes trying to talk you out of it.  The golden way to get out of that is just say.  Actually I just moved in with my girlfriend and she's already a customer.  And they're like oh OK that's fine.  We're still keeping you there.  So you know it's.  So if you want to cancel your account that's apparently the shibboleth phrase to get through.  That I'm still a customer I just not going to be me.

Start time: 7566.56
End time: 7614.17
Speaker: SPEAKER_07
Transcript:  It'll be my girlfriend.  That's sad that you have to do that.  So Pat Toomey Senator Toomey Senator Merkley apparently were impersonated during the net neutrality repeal and posted comments not them.  Somebody pretending to be them posted comments on the FCC fake comments on the FCC site against net neutrality.  And they're not happy.  They just sent a letter to Ajit Pai the chairman of the FCC saying can really you've got to investigate these phony.  Comments millions of them we know millions of them pro net neutrality comments and who put them there.  Why they're there and who would impersonate this.  This has been going on for a year.  It's really dumb.

Start time: 7615.75
End time: 7626.54
Speaker: SPEAKER_04
Transcript:  You know we've been complaining about the comments period at the FCC for a year.  And everyone was and then the minute two senators are just oh hang on our names are in there.  This is an outrage.  That's what it is.  This is an outrage.  That's what it is.

Start time: 7626.68
End time: 7629.54
Speaker: SPEAKER_07
Transcript:  And that's why I'm voting for Brian Ford for Congress.

Start time: 7630.68
End time: 7639.54
Speaker: SPEAKER_05
Transcript:  Well it's interesting because according to the Wall Street Journal five different federal agencies have seen impersonated comments or comments or something.

Start time: 7639.74
End time: 7643.54
Speaker: SPEAKER_04
Transcript:  So you're an expert in this.  It's easy to spam these systems surely.

Start time: 7644.44
End time: 7657.57
Speaker: SPEAKER_05
Transcript:  It is you know you have to take the proper precautions to prevent spam in general.  I'll just say if anybody wants to reach out you know the US Digital Service stands at the ready to help with thank you.  Please please I beg of you.

Start time: 7660.46
End time: 7663.78
Speaker: SPEAKER_02
Transcript:  And this is why I'll work to increase the budget for more people like Matt to help address this.  Yeah.

Start time: 7665.32
End time: 7667.09
Speaker: SPEAKER_07
Transcript:  All right.  The show's over.  Thank you.

Start time: 7667.74
End time: 7673.23
Speaker: SPEAKER_05
Transcript:  This is the point where I say as a federal employee the Hatch Act says that I cannot endorse anybody for.  That's right.

Start time: 7673.94
End time: 7694.54
Speaker: SPEAKER_07
Transcript:  However I can.  And I'm really glad you're running.  I wish I could vote in the 45th District Brian but if people want to know more for de dot com he's the crypto candidate.  But that that's that that sounds like a bad thing.  I wouldn't I wouldn't say that.  He is he is the intelligent choice.  And I do wish you luck.

Start time: 7695.43
End time: 7723.68
Speaker: SPEAKER_02
Transcript:  Do you remember thinking of bad words.  It's it's a crypto is not a bad word.  Crypto is a great word.  So is hacking in the ridge in the original origins.  Yeah I agree.  I remember when I first launched the first hackathon at the White House I got a nasty gram from another department inside the White House the National Security Council.  They said are you the one responsible for hosting a hackathon at the White House.  Oh Lord.  And so I just curtly said go look up the origins of hacking and get back to me.  Yeah.

Start time: 7724.60
End time: 7726.54
Speaker: SPEAKER_07
Transcript:  I hope you never heard from them again.

Start time: 7727.86
End time: 7762.22
Speaker: SPEAKER_05
Transcript:  Well we it's funny there is the US Civil Service did one of the first federal bug bounties over at the Pentagon and it's called Hack the Pentagon.  And the rumor was that somebody said well you can all right you're allowed to do this you have permission but whatever you do just just don't call it hack the Pentagon.  And so there's the guy at the Pentagon his name is Chris Lynch is like well that's definitely what we're calling it.  By the way it was a great success wasn't it.  Yeah yeah it really was.  In fact we've done something like seven now you get better results for cheaper and it happens faster.  You know why wouldn't you do bug bounties.

Start time: 7762.54
End time: 7776.36
Speaker: SPEAKER_07
Transcript:  You know sometimes there's some controversy over bug bounties.  I worry about bug bounties that there's a whole group of people who are withholding hacks or generating hacks hoping to make money during this pwnedown and other events.  Yeah true.

Start time: 7777.20
End time: 7802.42
Speaker: SPEAKER_05
Transcript:  But the fact is like those folks could already attack the government.  And so given an opportunity where people can be motivated either through civic pride or through a small amount of money like we've seen 17 year olds who have made forty thousand dollars just by you know by participating.  And so that that creates the odds that that 17 year old might want to do an internship in the government might try to help secure government systems like that.  That's a good thing overall in my book.

Start time: 7802.93
End time: 7824.42
Speaker: SPEAKER_04
Transcript:  Yeah.  It's logical they're going to hold some things back for the competitions but by and large you can make a pretty good living now doing bug bounty programs.  I mean it's all to Katie Massouris about this she can give you a chapter and verse on where this is going.  But it's a smart way to I mean if you paid private companies to do all this for you you know the bill would be in the millions and you still wouldn't be finished yet.

Start time: 7825.96
End time: 7834.54
Speaker: SPEAKER_05
Transcript:  Well and it's important for people to know these are white hat security researchers.  Yeah.  So yes the term hacker might sound scary if you're not familiar with the history but it's really very practical.

Start time: 7835.11
End time: 7840.76
Speaker: SPEAKER_07
Transcript:  Yeah.  Well I should also point out that many a white hat started with a different color on their head in the early days.  Right.

Start time: 7841.66
End time: 7845.54
Speaker: SPEAKER_04
Transcript:  So we all come on Steve Jobs Bill Gates who didn't hack.

Start time: 7845.74
End time: 8029.32
Speaker: SPEAKER_07
Transcript:  That's what that's what you do.  You're testing the limits you're seeing what code can do.  That's part of the fun of it.  And if you put those skills to a good use instead of malicious use more power to you talking about a malicious use.  I'm happy to say that those creeps who swatted and ended up getting somebody killed are have been charged and and may in fact face almost life in jail.  This was started with a dispute over a match in an online game on Call of Duty.  The World War Two pack.  A 19 year old from Wichita and another 18 year old had a falling out over a wager a dollar fifty wager.  So allegedly Shane Gaskill and Casey Viner.  Viner wanted to get back at Gaskill so he enlisted the help of another man again allegedly Tyler Barris.  Tyler's not the best guy in the world.  He's his handle on Twitter was swatistic.  And he bragged of swatting hundreds of schools and dozens of private residences.  I'm using the term swatting.  I think you probably all know that that means calling the police.  We've been swatted calling the police department.  Yeah somebody called the Petaluma Police Department.  I've heard the recording to call the police department said I have put bombs in the basement of the Tweet Brickhouse and I am going I am there now and I'm going to shoot people one by one and then blow the whole place up hoping the whole hope is that they're going to get killed.  The whole hope is that the highly armed really over armed in some cases swat teams from these police departments will come and really disrupt broadcast operations or whatever.  A lot of times with gamers they're hoping to see the swatting on the Twitch stream.  That kind of thing is very common on Twitch.  The good news is the Petaluma Police Department doesn't really have a swat squad.  So a couple of officers came over and said everything OK out here.  We said yeah why?  Well we got this call.  It was kind of cute actually they took it seriously enough that they said we called down to the Tamil Pious Police Department.  They're sending some dogs up.  Why don't you guys take the rest of the day off and we're just going to have the dogs sweep the place for bombs which was I thought appropriate.  Wow.  But that happens.  But that happens.  So this guy but this is a more serious one because eventually what happened is allegedly.  Barris called 911 operators in Wichita.  Viner had given him an address which wasn't his address.  Said I just shot my father in the head.  I'm holding my mom and sister at gunpoint.  I'm thinking about burning down the home.  Wichita police came to that address which was not in fact inhabited by anybody involved.  Sadly to say but by a 28 year old Andrew Finch it was his mom's house.  He walked out and was shot to death by Wichita police officers.  Party of two.  He didn't know the guys.  He wasn't even a gamer.  And there's plenty of record of them then saying hey did it work.  There's all these screenshots.

Start time: 8029.58
End time: 8033.62
Speaker: SPEAKER_04
Transcript:  And also panicking once they realized that this was now a death.  There was a death involved.  Yeah.

Start time: 8034.92
End time: 8047.83
Speaker: SPEAKER_07
Transcript:  And of course his attorney is saying well it's not his fault.  It's the police officer who pulled the trigger.  But the good news is and I think this is appropriate that Swatistic is facing significant jail time like the rest of his life.  Yeah.

Start time: 8049.50
End time: 8069.54
Speaker: SPEAKER_04
Transcript:  Well if he's guilty I hope he gets it because that's just swatting has just gone nuts.  Also last year's DEFCON there was a whole presentation about how easy it is to hack the phone system to make it look as though you know to cover up your location.  This is something else that you know we need some technologists in government to sort this stuff out.

Start time: 8069.70
End time: 8087.48
Speaker: SPEAKER_07
Transcript:  Yeah.  Well I talked to the police department.  They said well we have a phone number but we know it's certainly not the person's phone number.  We don't know his location.  I have heard the recording of the call.  Doesn't ring any bells.  I think I know who it was.  But without.  Yeah without proof.  Proof it's hard to do anything about it.

Start time: 8087.92
End time: 8089.65
Speaker: SPEAKER_04
Transcript:  Pop over for a week for tea in his toenails.

Start time: 8091.64
End time: 8118.30
Speaker: SPEAKER_07
Transcript:  That would be wrong.  Yes of course it would.  I'll get the pliers.  In any event I wanted to pass that along because we have been covering that story all along.  It was just a terrible story.  And you know Barris has admitted his role in many swattings including I think he swatted Brian Krebs and he's given an interview to Brian Krebs.  There's you know this is a story from Krebs on security.  Yeah Krebs has had a lot.

Start time: 8118.68
End time: 8122.40
Speaker: SPEAKER_04
Transcript:  Poor guy.  Heroin sent to his house.  He's been swatted a couple of times.

Start time: 8122.84
End time: 8159.44
Speaker: SPEAKER_07
Transcript:  The key on this of course is to call the local police departments.  Yeah.  Which we you know they're all know we do live streaming here and they're a little bit more aware of the whole.  Yeah.  I think we can wrap things up.  It's been a nice wonderful Memorial Day.  Thank you.  I'm really thrilled to have you all here.  Matt so great to see you.  I know you had some personal tragedy in your life but it sounds like you're doing well.  Good to see you.  We just love you.  Thank you for having me.  Yeah.  You're just the greatest.  I'm so glad to see you have fun at the conference.  Yeah.  Should be good.  I think that's going to be great.  Anything you want to say besides USDS.gov slash join.

Start time: 8160.24
End time: 8176.10
Speaker: SPEAKER_05
Transcript:  I'll try not to do too much of a plug but if you do want to check out that website there is a recent report to Congress.  So if you want to read the kinds of things that we do API development helping doctors helping small businesses helping veterans.  There's some really good work there.  And there's still support for what you're doing.

Start time: 8176.64
End time: 8181.54
Speaker: SPEAKER_07
Transcript:  Yeah.  That's awesome.  I think that's really important in your budget.  But just fine exists.

Start time: 8181.92
End time: 8185.14
Speaker: SPEAKER_05
Transcript:  What I need now is talented technologists designers product managers.

Start time: 8185.64
End time: 8208.38
Speaker: SPEAKER_07
Transcript:  That's you know people we're all we all love to complain.  Here's a chance to do something.  That's right.  Yeah.  And make a difference.  I think that's great.  USDS.gov slash join.  Thank you Matt.  Thank you to Ian Thompson.  Always a pleasure to have you here.  Always good fun.  I enjoy good NASA.  The register.co.uk for your daily dose of snark.  Your head.  Do you do your own headlines.

Start time: 8210.04
End time: 8232.21
Speaker: SPEAKER_04
Transcript:  We all every journalist will submit their own headlines but it's usually the editor which does the final thing.  That's you.  Well yes.  But I don't know the one I managed to sneak in recently was with the Amazon doing a recall on their power packs.  And it was like it was something along the lines of house fires chemical burns all come free with this Amazon power.  I love it.

Start time: 8234.30
End time: 8247.72
Speaker: SPEAKER_07
Transcript:  And you do it by the way the register has beefed up its reporting.  It is great.  It's always been really hard to read smart people.  They're doing a great job.  And I'm just it's a regular visit for me now.  Cheers.  And no paywall.  Nope.

Start time: 8249.38
End time: 8257.25
Speaker: SPEAKER_04
Transcript:  No no it's there will be there may be some developments on it.  We're toying with the idea of getting cryptocurrency involved somewhere along the line.  I'll donate.

Start time: 8257.87
End time: 8262.05
Speaker: SPEAKER_07
Transcript:  Yeah.  I got seven bitcoins sitting in a wallet I can't unlock.  Well I did I did worry Brian.

Start time: 8266.56
End time: 8273.54
Speaker: SPEAKER_04
Transcript:  You know it's when you said you were taking Bitcoin.  What happens if the price crashes two weeks before the election and it's just like our reserves they've all gone.

Start time: 8273.58
End time: 8278.15
Speaker: SPEAKER_07
Transcript:  What do you do do you immediately cash in the Bitcoin or you hold it or what do you do.  We have to do it.

Start time: 8278.54
End time: 8287.14
Speaker: SPEAKER_02
Transcript:  We have to do it.  We have to convert it to fiat and deposit into our bank account.  But we could take our cash on hand and let it ride a Bitcoin if we want to.  But we've chosen not to do that.

Start time: 8287.99
End time: 8296.99
Speaker: SPEAKER_07
Transcript:  Good.  Good.  By and ford.  Good luck to you.  The election is soon.  I can't believe it.  You're coming down to the wire here.  Is it exhausting.

Start time: 8297.78
End time: 8325.54
Speaker: SPEAKER_02
Transcript:  June 5th.  It couldn't be.  You know I think kind of Matt alluded to this that you know when you're in government you get out of bed every day because you're incredibly mission  driven and it's a little harder to have that mission driven when you're in the private sector.  And so you know I'm incredibly mission driven to have more technologists in Congress like me because it could not be any more important for the 21st century.  And my one campaign another campaign promise that I'll keep is that as soon as I'm elected I'll come back on the show.

Start time: 8326.43
End time: 8446.32
Speaker: SPEAKER_07
Transcript:  Oh you know what.  You're you're I'm looking at your issues page ford.com.  It checks every box every box right on.  You have my fervent endorsement and I and I wish you luck and I wish I could vote in the 45th.  I can't but everybody I won't I promise everybody should vote if you're if you've got a primary in your state coming up make sure you vote make sure you  participate volunteers stay informed donate to candidates who make a difference especially if they're savvy and technology.  And then of course November is going to be a very big and important election.  This is when we stand up for the things we believe in.  Brian thank you for being here. I appreciate it.  Thanks for having me.  We do tweet every Sunday evening 3 p.m. Pacific 6 p.m. Eastern Time 2200 UTC.  Come on by watch we stream it live and in fact get get here early and stay late because there's always stuff on either side of the show extra stuff that's always a lot of fun I think.  It's fun for me.  You just go to tweet TV slash live to watch live if you do that though join us in the chat room as well a great group of people that kind of I always think of them as the rowdies in the back of the auditorium.  Lots of fun IRC dot twit dot TV.  You can also be in studio in a great studio audience for a three day weekend.  I guess that's why maybe from all over the world.  Wonderful to have you all you have to do is email tickets at twit dot TV.  We'd be thrilled to have you here.  Just let us know ahead of time.  If you can't be here live or watch live don't worry you can watch on demand versions of everything we do live is great.  But you know in the can on schedule is probably a lot easier.  Just go to twit dot TV for downloadable audio and video from every show or find us in your favorite podcast application.  We're in every one of them and you can subscribe.  You can even ask your Amazon Echo to listen to any one of our shows and usually she'll respond without recording your audio and sending it to a friend.  Thanks for listening and we will see you next time.  Another twit is in the can.

